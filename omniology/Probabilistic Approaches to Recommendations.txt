Probabilistic Approaches
to Recommendations
Nicola Barbieri
Yahoo Labs, Barcelona, Spain
Giuseppe Manco
ICAR-CNR, Rende, Italy
Ettore Ritacco
ICAR-CNR, Rende, Italy
C
M
&
cLaypool
Morgan
publishers
&
SYNTHESIS LECTURES ON DATA MINING
AND KNOWLEDGE DISCOVERY #9

Copyright © 2014 by Morgan & Claypool
Probabilistic Approaches to Recommendations
Nicola Barbieri, Giuseppe Manco, and Ettore Ritacco
www.morganclaypool.com
ISBN: 9781627052573
paperback
ISBN: 9781627052580
ebook
DOI 10.2200/S00574ED1V01Y201403DMK009
A Publication in the Morgan & Claypool Publishers series
SYNTHESIS LECTURES ON DATA MINING AND KNOWLEDGE DISCOVERY
Lecture #9
Series Editors: Jiawei Han, University of Illinois at Urbana-Champaign
Lise Getoor, University of Maryland
Wei Wang, University of North Carolina, Chapel Hill
Johannes Gehrke, Cornell University
Robert Grossman, University of Chicago
Series ISSN
Print 2151-0067
Electronic 2151-0075

ABSTRACT
e importance of accurate recommender systems has been widely recognized by academia and
industry, and recommendation is rapidly becoming one of the most successful applications of data
mining and machine learning. Understanding and predicting the choices and preferences of users
is a challenging task: real-world scenarios involve users behaving in complex situations, where
prior beliefs, speciﬁc tendencies, and reciprocal inﬂuences jointly contribute to determining the
preferences of users toward huge amounts of information, services, and products. Probabilistic
modeling represents a robust formal mathematical framework to model these assumptions and
study their eﬀects in the recommendation process.
is book starts with a brief summary of the recommendation problem and its challenges
and a review of some widely used techniques Next, we introduce and discuss probabilistic ap-
proaches for modeling preference data. We focus our attention on methods based on latent fac-
tors, such as mixture models, probabilistic matrix factorization, and topic models, for explicit
and implicit preference data. ese methods represent a signiﬁcant advance in the research and
technology of recommendation. e resulting models allow us to identify complex patterns in
preference data, which can be exploited to predict future purchases eﬀectively.
e extreme sparsity of preference data poses serious challenges to the modeling of user
preferences, especially in the cases where few observations are available. Bayesian inference tech-
niques elegantly address the need for regularization, and their integration with latent factor mod-
eling helps to boost the performances of the basic techniques.
We summarize the strengths and weakness of several approaches by considering two diﬀer-
ent but related evaluation perspectives, namely, rating prediction and recommendation accuracy.
Furthermore, we describe how probabilistic methods based on latent factors enable the exploita-
tion of preference patterns in novel applications beyond rating prediction or recommendation
accuracy.
We ﬁnally discuss the application of probabilistic techniques in two additional scenarios,
characterized by the availability of side information besides preference data.
In summary, the book categorizes the myriad probabilistic approaches to recommendations
and provides guidelines for their adoption in real-world situations.
KEYWORDS
recommender systems, probability, inference, prediction, learning, latent factor mod-
els, maximum likelihood, mixture models, topic modeling, matrix factorization,
Bayesian modeling, cold start, social networks, inﬂuence, social contagion

Contents
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii
1
e Recommendation Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2
Formal Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2.1 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.2.2 Main Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1.3
Recommendation as information ﬁltering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.3.1 Demographic Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.3.2 Content-Based Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.4
Collaborative Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.4.1 Neighborhood-Based Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
1.4.2 Latent Factor Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
1.4.3 Baseline Models and Collaborative Filtering . . . . . . . . . . . . . . . . . . . . . . 21
2
Probabilistic Models for Collaborative Filtering . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.1
Predictive Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.2
Mixture Membership Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.2.1 Mixtures and Predictive Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.2.2 Model-Based Co-Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.3
Probabilistic Latent Semantic Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
2.3.1 Probabilistic Latent Semantic Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 46
2.3.2 Probabilistic Matrix Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
2.4
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
3
Bayesian Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
3.1
Bayesian Regularization and Model Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.2
Latent Dirichlet Allocation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
3.2.1 Inference and Parameter Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
3.2.2 Bayesian Topic Models for Recommendation . . . . . . . . . . . . . . . . . . . . . 64
3.3
Bayesian Co-Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69

3.3.1 Hierarchical Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
3.4
Bayesian Matrix Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
3.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4
Exploiting Probabilistic Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.1
Probabilistic Modeling and Decision eory . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.1.1 Minimizing the Prediction Error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
4.1.2 Recommendation Accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
4.2
Beyond Prediction Accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
4.2.1 Data Analysis with Topic Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
4.2.2 Pattern Discovery Using Co-Clusters . . . . . . . . . . . . . . . . . . . . . . . . . . 104
4.2.3 Diversiﬁcation with Topic Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5
Contextual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
5.1
Integrating Content Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
5.1.1 e Cold-Start Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
5.1.2 Modeling Text and Preferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.2
Sequential Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
5.2.1 Markov Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
5.2.2 Probabilistic Tensor Factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
6
Social Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
6.1
Modeling Social Rating Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
6.2
Probabilistic Approaches for Social Rating Networks . . . . . . . . . . . . . . . . . . . . 131
6.2.1 Network-Aware Topic Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
6.2.2 Social Probabilistic Matrix Factorization . . . . . . . . . . . . . . . . . . . . . . . . 134
6.2.3 Stochastic Block Models for Social Rating Networks . . . . . . . . . . . . . . 135
6.3
Inﬂuence in Social Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
6.3.1 Identifying Social Inﬂuence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
6.3.2 Inﬂuence Maximization and Viral Marketing . . . . . . . . . . . . . . . . . . . . 139
6.3.3 Exploiting Inﬂuence in Recommender Systems . . . . . . . . . . . . . . . . . . . 143
7
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
7.1
Application-Speciﬁc Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
7.2
Technological Challenges. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

A
Parameter Estimation and Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
A.1
e Expectation Maximization Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
A.2
Variational Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
A.3
Gibbs Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

Preface
Recommendation is a special form of information ﬁltering that extends the traditional concept
of search by modeling and understanding the personal preferences of users. e importance of
accurate recommender systems has been widely recognized by both academic and industrial eﬀorts
in the last two decades and recommender systems are rapidly becoming one of the most successful
applications of data-mining and machine-learning techniques.
Within this context, a rich body of research has been devoted to the study of probabilis-
tic methods for the analysis of the preferences and behavior of users. Real-world scenarios in-
volve users in complex situations, where prior beliefs, speciﬁc tendencies, and reciprocal inﬂuences
jointly contribute to determining the preferences of users toward huge amounts of information,
services, and products. Can we build simple yet sophisticated models to explain the way these
preferences occur? How can we identify and model the latent causes that guide and inﬂuence the
adoptions and preferences of users in complex systems? Probabilistic modeling represents a ro-
bust, formal mathematical framework upon which to model assumptions and study their eﬀects
in real-world scenarios.
In this book, we study and discuss the application of probabilistic modeling to preference
data provided by users. We draw from recent research in the ﬁeld and attempt to describe and
abstract the process adopted by the research community in the last ﬁve years. e increasing pop-
ularity of recommender systems (due also to the advent of the Netﬂix prize) led to an explosion of
research on generative approaches for modeling preference data. Within this scenario, an aware-
ness has grown that probabilistic models oﬀer more than traditional methods in terms of both
accuracy and exploitation. Hence the need for a systematic study aimed at categorizing the myriad
approaches and providing guidelines for their adoption in real-world situations.
We start by formally introducing the recommendation problem and summarizing well-
established techniques for the generation of personalized recommendations. We present an
overview of evaluation methods and open challenges in the recommendation process, and then
focus on collaborative ﬁltering approaches to recommendation.
e core of the book is the description of probabilistic approaches to recommendations. We
concentrate on probabilistic models based on latent factors, which have proved to be extremely
powerful and eﬀective in modeling and identifying patterns within high-dimensional (and ex-
tremely sparse) preference data. e probabilistic framework provides a powerful tool for the
analysis and characterization of complex relationships among users and items. Probabilistic mod-
els can enhance and strengthen traditional techniques as they oﬀer some signiﬁcant advantages.
Notably, they can: be tuned to optimize any of several loss functions; optimize the likelihood of
enabling the modeling of a distribution over rating values, which can be used to determine the

conﬁdence of the model in providing a recommendation; ﬁnally, they oﬀer the possibility of in-
cluding prior knowledge in the generative process, thus allowing a more eﬀective modeling of the
underlying data distribution.
Rooted in these backgrounds, this book focuses on the problem of eﬀectively adopting
probabilistic models for modeling preference data. Our contributions can be summarized in two
ways. First, we study the eﬀectiveness of probabilistic techniques in generating accurate and per-
sonalized recommendations. Notably, the interplay of several diﬀerent factors, such as the esti-
mate of the likelihood that the user will select an item, or the predicted preference value, provides
a fruitful degree of ﬂexibility. Secondly, we show how probabilistic methods based on latent fac-
tor modeling can eﬀectively capture interesting local and global patterns embedded in the high-
dimensional preference data, thereby enabling their exploitation in novel applications beyond
rating prediction.
e eﬀectiveness of probabilistic methods for recommendation has also been shown in
other scenarios. e ﬁrst concerns contextual information. Typically, preference data assumes a
“bag-of-words” representation, i.e. the order of the items a user chooses can be neglected. is as-
sumption allows us to concentrate on recurrent co-occurrence patterns and to disregard sequential
information that may characterize the choice of the user. However, there are several real-world
applications where contextual and side information play a crucial role. For example, content fea-
tures can help characterize the preferential likelihood of an item in extremely dynamic content
production systems. Also, there are some scenarios, such as web navigation logs or customer
purchase history, where data can be “naturally” interpreted as sequences. Ignoring the intrinsic
sequentiality of the data may result in poor modeling. By contrast, the focus should be on the
context within which a current user acts and expresses preferences, i.e., the environment, char-
acterized by side information, where the observations hold. e context enables a more reﬁned
modeling and, hence, more accurate recommendations.
Finally, the advent of social networking introduces new perspectives in recommendation.
Understanding how the adoptions of new practices, ideas, beliefs, technologies and products can
spread trough a population, driven by social inﬂuence, is a central issue for the social science and
recommendation communities. Taking into account the modular structure of the underlying so-
cial network provides further important insights into the phenomena known as social contagion
or information cascades. In particular, individuals tend to adopt the behavior of their social peers
so that information propagation triggers “viral” phenomena, which propagate within connected
clusters of people. erefore, the study of social contagion is intrinsically connected to the rec-
ommendation problem.
In this book, the interested reader will ﬁnd the mathematical tools that enable the under-
standing of the key aspects that characterize the main approaches for recommendation. is will
allow both the understanding of the opportunities of the current literature and the development
of ad-hoc methods for the solution of speciﬁc problems within the recommendation scenario.

e book is not self-comprehensive and a basic understanding probability and statistics, as well
as machine learning and data mining methods, is needed.
e dependencies between chapters are shown in the following ﬁgure, where an arrow from
one chapter to another indicates that the latter requires some knowledge of the ﬁrst.
Within this structure, the appendix contains a primer on the basic inference and estimation tools
used throughout the chapters and it should be considered as a reference tool.
Nicola Barbieri, Giuseppe Manco, and Ettore Ritacco
April 2014

C H A P T E R
1
e Recommendation Process
1.1
INTRODUCTION
With the increasing volume of information, products, services, and resources (or, more generally,
items) available on the Web, the role of recommender systems (RS) [162] and the importance of
highly accurate recommendation techniques have become major concerns both in e-commerce
and academic research. e goal of a RS is to provide users with recommendations that are non-
trivial, useful to directly experience potentially interesting items, and that the user may not ﬁnd on
her own. eir exploitation in e-commerce enables a better interaction between the users and the
system: RSs are widely adopted in diﬀerent contexts, from music (Last.fm¹) to books (Amazon²),
movies (Netﬂix³), and news (Google News⁴[49]), and they are quickly changing and reinventing
the world of e-commerce [176].
A recommender can be considered as a “push” system that provides users with a personalized
exploration of a wide catalog of possible choices. Search-based systems require a user to explicitly
express a query specifying what she is looking for. By contrast, in recommendation, the query is
implicit and corresponds to all past interactions of the user with the system. By collecting and
analyzing past users’ preferences in the form of explicit ratings or like/dislike products, the RSs
provide the user with smart and personalized suggestions, typically in the form of “customers who
bought this item also bought” or “customers who bought related items also bought.” e goal of
the service provider is not only to transform a regular user into a buyer, but also to make her
browsing experience more comfortable, thus building a strong loyalty bond. is idea is better
explained by JeﬀBezos, CEO of Amazon.com:
“If I have 3 million customers on the Web, I should have 3 million stores on the Web.”
e strategic importance of accurate recommendation techniques has motivated both aca-
demic and industrial research for over 15 years; this is witnessed by huge investments in the devel-
opment of personalized and highly accurate recommendation approaches. In October 2006, Net-
ﬂix, the leader in the American movie-rental market, promoted a competition, the Netﬂix Prize
⁵[27], with the goal of producing a 10% improvement on the prediction accuracy achieved by their
internal recommender system, Cinematch. e competition lasted three years and involved several
¹last.fm
²amazon.com
³netflix.com
⁴news.google.com
⁵netflixprize.com

2
1. THE RECOMMENDATION PROCESS
research groups from all over the world, improving and inspiring a fruitful research. During this
period, a huge number of recommendation approaches were proposed, creating a substantial ad-
vance in the literature, while simultaneously encouraging the emergence of new business models
based on RSs.
is chapter is aimed at providing an overview of the recommendation scenario from a
technical point of view. First, we provide a formal framework that speciﬁes some notations used
throughout the manuscript. e focus is the formal deﬁnition of a recommender system and
the evaluation of its capability to provide adequate recommendations. en we will introduce
and discuss some well-known recommendation approaches, with an emphasis on collaborative
ﬁltering.
1.2
FORMAL FRAMEWORK
Recommendation is a form of information ﬁltering that analyzes users’ past preferences on a
catalog of items to generate a personalized list of suggested items. In the following, we introduce
some basic notations to model users, items, and their associated preferences.
Let U D fu1; : : : ; uMg be a set of M users and I D fi1; : : : ; iN g a set of N items. For no-
tational convenience, in the following, we reserve letters u; v to denote users from U and letters
i; j to indicate items from I. Users and items can be characterized by means of speciﬁc prop-
erties, speciﬁed as atomic predicates in ﬁrst-order logic. Predicates can be related with either
discrete properties (such as Sex(u,male), Location(u,NYC), or Genre(i,comedy), Rating(i,PG) regarding
the user u and the item i), or numeric (such as Age(u,23) or Length(i, 175)). Users’ preferences can
be represented as a M  N matrix R, whose generic entry ru
i denotes the preference value (i.e.,
the degree of appreciation) assigned by user u to item i: User preference data can be classiﬁed as
implicit or explicit. Implicit data correspond to mere observations of co-occurrences of users and
items, which can be recorded by analyzing clicks, users’ web sessions, likes, or check-in. Hence,
the generic entry ru
i of the user-item rating matrix R is a binary value: ru
i D 0 means that u has
not yet experienced i, whereas by ru
i D 1 we denote that user u has been observed to experience
item i: By contrast, explicit data record the actual ratings explicitly expressed by individual users
on the experienced items. Ratings are typically collected by questionnaires in which a user is asked
to proactively evaluate the purchased/selected product on a given rating scale. Such feedback pro-
vides a user with a way to explicitly express their preferences. Implicit feedback is abundant but
often unreliable, as the true users’ evaluations are still hidden. Explicit feedback is generally more
accurate and can be either positive or negative, while implicit feedback is always positive.
Generally, explicit ratings can be encoded as scores in a (totally-ordered) numeric domain
V, represented as a ﬁxed rating scale that often includes a small number of interestingness levels.
In such cases, for each pair .u; i/, rating values ru
i fall within a limited range V D f0; : : : ; V g,
where 0 represents an unknown rating and V is the maximum degree of preference. Notation rR
denotes the average rating among all those ratings ru
i > 0. e number of users M; as well as the
number of items N; are very large (typically with M >> N) and, in real-world applications, the

1.2. FORMAL FRAMEWORK
3
rating matrix R is characterized by an exceptional sparseness, as individual users tend to rate a
limited number of items. In the following, we denote by hu; ii the enumeration of all those dyads
in R such that ru
i > 0; analogously hu; i; ri represents an enumeration of all the explicit ratings.
Again, speciﬁc properties in the form of ﬁrst-order predicates can be associated with either hu; ii
or hu; i; ri. Example properties can specify, e.g., the time period Period(hu; ii, evening), or even the
item experienced before Preceding(hu; ii, j). We denote the whole set of predicates relative to U; I
or U  I  V as F.
e set of items rated by user u is denoted by IR.u/ D fi 2 Ijhu; ii 2 Rg. Dually, UR.i/ D
fu 2 Ujhu; ii 2 Rg is the set of all those users, who rated item i: With an abuse of notation, we
use U.i/ and I.u/ when the rating matrix R is known from the context. Any user u with a rating
history, i.e., such that IR.u/ ¤ ;, is an active user. Both IR.u/ and UR.i/ can be empty. is
setting is known as cold start and it generally occurs whenever a new user or item is added to
the underlying information system. Cold start is generally problematic in recommender systems,
since these cannot provide suggestions for users or items in the absence of suﬃcient information.
e illustration in Fig 1.1 sketches a recommendation scenario with 10 users, 10 items and
explicit preferences. e set of users who rated item i2 is U.i2/ D fu1; u4; u8; u10g. Also, the set
of items rated by user u2 is I.u2/ D fi3; i5; i7; i9g. e rating value of user u2 over item i4, as well
as the ratings from u4 over i1 and i3, are unknown.
i1
i2
i3
i4
i5
i6
i7
i8
i9
i10
u1
u2
u3
u4
u5
u6
u7
u8
u9
u10
2
5
2
4
1
1
4
3
4
4
5
3
2
5
3
3
4
4
3
1
5
3
1
1
5
3
3
2
5
1
1
1
2
5
2
1
5
2
4
1
3
4
5
5
4
4
Figure 1.1: Example of users’ preference matrix.
Given an active user u, the goal of a RS is to provide u with a recommendation list Lu  I,
including unexperienced items (i.e., Lu \ IR.u/ D ;) that are expected to be of her interest. is
clearly involves predicting the interest of u toward unrated items: exploiting (implicit and/or
explicit) information about users’ past actions, the RS provides a scoring function pu
i W U  I !
R, which accurately estimates future preferences, and hence can be used to predict which are
the most likely products to be purchased in the future. A general framework for the generation
of Lu, is encoded by algorithm 1. Here, a subset C of candidate items is chosen according to
domain-speciﬁc criteria. For example, C may correspond to some items to promote, or even to

4
1. THE RECOMMENDATION PROCESS
the whole domain I. en, each item i in C is scored by pu
i , and the top-L items are selected for
the recommendation list.
Algorithm 1 Generation of recommendation list.
Require: A number of candidate items, D (positive integer such that D  N)
Require: e size of the recommendation list, L (positive integer such that L  D)
1: Choose C  I, according to a business-speciﬁc criterion, such that jCj D D and C \ IR.u/ D
;.
2: Associate each item i 2 C with a score pu
i , which represents the appreciation of u for i
3: Let Lu be the selection of the top L items in C with the highest values pu
i
4: Return Lu
1.2.1
EVALUATION
Diﬀerent measures have been proposed in order to evaluate the accuracy of a RS (for a detailed
survey see [79, 103]). As mentioned before, recommendations usually come in the form of a list
of the L items that the user might like the most. Intuitively, an accuracy metric should measure
how close the predicted list is to the actual preference list of a user or how close a predicted rating
is to its actual value.
e adoption of a recommender system requires a prior evaluation of its ability to provide
a positive impact on both a user’s experience and a provider’s revenues. Notably, the evaluation
is accomplished by applying a protocol that delivers some objective measures stating the quality
of the RS. ese measures allow for a comparison among the several algorithmic and modeling
alternatives. Two diﬀerent strategies can be pursued, namely oﬄine and online evaluation. Within
online evaluation, a small percentage of users are asked to test the recommendation engine and to
provide feedback about the main features. Online testing requires a careful design of the testing
protocol, in order for the evaluation to be fair and the results to be statistically sound. is includes
the selection of a representative subset of users and the features to be evaluated. Additionally, a
direct involvement of actual users is not advisable, as it could negatively aﬀect the experience of
the test users: negative judgements can bias a user toward an under-evaluation of the capabilities
of the recommendation engine.
By contrast, oﬄine evaluation simulates the online process by employing simple statisti-
cal indices (either on synthesized or historical data) to measure the performance of the system.
Indices make comparisons among alternative algorithms and schemes easier, and measure the
eﬀectiveness of a system at design time. Oﬄine evaluation protocols and metrics usually rely on
an evaluation framework where the rating matrix R is split into two matrices T and S, such that
the former is used to train a recommendation algorithm, while the latter is used for validation
purposes, to measure the predictive abilities of the system. e latter can be measured according
to diﬀerent perspectives, discussed in the following.

1.2. FORMAL FRAMEWORK
5
Prediction accuracy.
Historically, most CF techniques focused on the development of accurate
techniques for rating prediction. e recommendation problem has been interpreted as a missing
value prediction problem [174], in which, given an active user, the system is asked to predict
her preference for a set of items. In this respect, the score pu
i can be devised as a function of
the prediction provided by the RS. Predictive accuracy metrics measure how close the predicted
ratings are to the actual ratings. Let Oru
i denote the predicted rating on the dyad hu; ii. Prediction
accuracy is measured by means of statistical metrics that compare such predicted values with actual
ratings. Widely adopted measures are:
• e Mean Absolute Error (MAE), which measures the average absolute deviation between
a predicted and a real rating. It is an intuitive metric, easy to compute and widely used in
experimental studies:
MAE D 1
jSj
X
hu;ii 2 S
jru
i   Oru
i j :
(1.1)
• e Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). ese measure
the deviation of observed ratings from predicted values and, compared to MAE, emphasize
large errors. ey are deﬁned as
MSE D 1
jSj
X
hu;ii 2 S
 ru
i   Oru
i
2 ;
(1.2)
and
RMSE D
p
MSE:
(1.3)
• e Mean Prediction Error (MPE), expresses the percentage of predictions which diﬀer
from the actual rating values,
MPE D 1
jSj
X
hu;ii 2 S
1Jru
i ¤ Oru
i K;
(1.4)
where 1JbexprK is the indicator function which returns 1 if the boolean expression bexpr
holds and 0 otherwise. Notably, MPE resembles the classical accuracy measured on classi-
ﬁcation algorithms in machine learning and data mining. As such, it can be further reﬁned
into a confusion matrix denoting the misclassiﬁcations relative to each speciﬁc rating. Other
more reﬁned metrics relying on ROC analysis [56] can be devised, based on such a confusion
matrix.
Recommendation Accuracy.
e focus here is on the recommendation list Lu, and we are in-
terested in measuring the accuracy in building a list that matches the user’s preferences. If we
consider the problem from an information retrieval (IR) perspective [14], we can assume an ex-
plicit knowledge of u’s actual preferences through a speciﬁc list Tu. Classical IR measures can
then be adapted to measure the correspondence between the proposed and the actual list.

6
1. THE RECOMMENDATION PROCESS
Items in Tu represent the portion of the catalog that are likely to meet u’s preferences. With
implicit preferences, Tu can be any subset in IS: the assumption here is that the user only selects
relevant items. With explicit feedback, the relevance of an item can be further reﬁned by focusing
on those items in IS for which the evaluation is representative of high interest. For example, we
can ﬁx a threshold t (e.g., the average evaluation rT), and then select Tu as a random subset of
fi 2 IS.u/jru
i > tg.
Given Tu for each user u, the evaluation of a recommendation list built according to Al-
gorithm 1 can be measured through the standard precision and recall measures. In particular, the
quality of a system which generates recommendation lists of size L can be measured as
Recall.L/ D 1
M
X
u2U
jLu \ Tuj
jTuj
:
Precision.L/ D 1
M
X
u2U
jLu \ Tuj
jLuj
:
(1.5)
Precision and recall are conﬂicting measures. For instance, by increasing the size of the recom-
mendation list, recall is expected to increase but precision decreases. Typically, these measures
are combined into the F-score, a single measure representing their harmonic mean and balancing
both contributions:
F D 2  Precision  Recall
Precision C Recall:
(1.6)
Recall and precision can also be exploited in a more reﬁned evaluation protocol that relies
on the notion of hit rate. We can devise a random process where the recommendation list is built
by scoring a set made of both random elements and elements within Tu. en, hits represent
the elements in Lu that also belong to Tu. is testing protocol, called user satisfaction on the
recommendation list, was proposed by Cremonesi et al. in [47] and is illustrated in Algorithm 2.
Recall values relative to a user u can be adapted accordingly:
US-Recall.u; L/ D #hits
jTuj ;
(1.7)
and global values can be obtained by averaging overall users. As for precision, there is a diﬃculty
in considering false positives, which negatively inﬂuence the accuracy of the system. False positives
represent the amount of spurious items, which are not relevant for the user and by contrast are
scored high in the list. Clearly, the size L can aﬀect the amount of such items, and hence, a
suitable approximation for precision can be obtained by simply reweighting the recall to represent
the percentage of relevant items relative to the recommendation list,
US-Precision.u; L/ D
#hits
L  jTuj:
(1.8)
More reﬁned measures can be introduced that consider both the amount of spurious items and
the position of the relevant item within the list.

1.2. FORMAL FRAMEWORK
7
Algorithm 2 User satisfaction of user u for item i.
Require: An item i 2 Tu
Require: A number of candidate items, D (positive integer such that D  jIj)
Require: e size of the recommendation list, L (positive integer such that L  D)
1: Let C be a random subset of I, with size D, whose elements have not been rated by u
2: Add i in C
3: Assign to each item i 2 C a score pu
i , which represents the appreciation of u for i
4: Let Lu be the selection of the L items in C with the highest values pu
i
5: if i 2 Lu then
6:
return a hit
7: else
8:
return a miss
9: end if
Rank Accuracy.
e generation of a recommendation list is based on the generation of a scoring
function. In our basic framework, we assumed that users provide explicit feedback in terms of a
scoring value in a given range. However, an explicit feedback can also consist of an explicit ranking
of items for each user. at is, users can provide information on which items are better than others,
according to their preferences.
True ranking is unrealistic with huge item catalogs. Nevertheless, it allows us to deﬁne rank-
ing accuracy metrics that measure the adequacy of the RS in generating a personalized ordering
of items that matches with the true user’s ordering.
Typically, the predicted and observed orderings are compared by means of Kendall’s (K) or
Spearman’s () coeﬃcients. Let u be the full descendingly ordered ranking list for the user u and
let Ou denote the predicted ranking list, both deﬁned over the domain IS.u/. en:
K.u; Ou/ D
2
0
@ X
i;j 2I
1Ju.i/  u.j/ ^ Ou.j/  Ou.i/K
1
A
N.N   1/
(1.9)
.u; Ou/ D
X
i2I
.u.i/   Nu/.Ou.i/   NOu/
sX
i2I
.u.i/   Nu/2 X
i2I
.Ou.i/   NOu/2
(1.10)
where .i/ is the rank associated with the item i in the list , N is the average rank in the list ,
and i  j is the comparison operator to denote if i is ranked ahead of j. e index K, within
the range Œ 1; 1, measures the agreement between two rankings, which in this case are the real
ranked list and the predicted one. If the predicted ranked list matches perfectly with the observed
one, then K D 1. By contrast,  ranges within Œ 1; C1 and measures the correlation between
two ranked variables. Once again, the perfect matching yields  D 1.

8
1. THE RECOMMENDATION PROCESS
Other Evaluation Measures.
e aforesaid accuracy metrics are important for oﬄine evaluation
and provide viable mathematical frameworks to compare diﬀerent recommendation algorithms
and techniques. However, they are not focused on evaluating the output of a recommender, as
users really perceive it from a psychological standpoint. Several key dimensions, beyond accuracy,
are gaining increasing importance in the evaluation of the quality of recommendations:
Novelty. is is closely related to the utility of a RS, which should recommend items the user is
not already aware of. Recommending a new “Star Trek” movie to a Mr. Spock’s fan is not a
novel suggestion, since it is likely that the user is already aware of the movie.
Serendipity. is measures the extent to which the RS is able to suggest items that are both of
interest to the user and unexpected, surprising. Intuitively, assuming that a list of “obvious”
items to be recommended is available, serendipity can be measured as the ability of the RS
to avoid the recommendations of such items.
Diversity. is measures the capability of suggesting “diﬀerent” items. Most often, a real RS
provides focused suggestions, which are similar to each other, e.g., books by the same author.
Diversity should allow recommenders to include items that span, as much as possible, over
all of a user’s interests.
Coverage. is focuses on the domain of items which the RS is eﬀectively able to recommend to
users, and measures whether recommender systems are biased toward some speciﬁc subsets.
Limitations of Oﬀ-Line Evaluations.
Evaluating recommendations is still among the biggest
unsolved problems in RSs. Oﬄine evaluation does not necessarily align with actual results: oﬄine
metrics like prediction/recall, RMSE, and K are based on snapshots of the past activities of users,
and they cannot measure the real impact of recommendations on users’ purchasing activities. e
fact that a recommender matches past preferences does not necessarily mean that it is capable of
inﬂuencing a user’s behavior in the future. A strong issue is how to consider the unrated items.
Do users dislike them? Haven’t users experienced them yet? Do users know about their existence?
e limitations of oﬀ-line evaluation motivates the study of more sophisticated evaluation
protocols and accurately controlled experiments. In general, a more eﬀective evaluation should
focus on how the user perceives recommendations and on measuring their helpfulness. Current
research is investigating several aspects correlated with evaluation, such as the analysis of the
return of investment (ROI) in improving prediction and recommendation metrics and the proposal
of more convincing oﬄine evaluation metrics.
1.2.2
MAIN CHALLENGES
ere are a number of issues that the design of a recommendation algorithm is typically required
to deal with. ese are generally relative to the quality and the size of the data, and the security
and privacy issues that a recommendation engine may breach. A brief review of these challenges
is summarized next.

1.2. FORMAL FRAMEWORK
9
Sparsity and Cold Start.
Recommendation systems in e-commerce have to deal with a huge
number of items and users. Usually, even the most active users purchase only a limited frac-
tion of the available items. e sparsity problem poses a real challenge to recommendation tech-
niques. For example, the preference matrix might not provide enough information for particular
users/items. is problem is known as reduced coverage [175], and can seriously aﬀect the accu-
racy of recommendations. A wide range of methods have been proposed to deal with the sparsity
problem. Many of them use dimensionality reduction techniques to produce a low-dimensional
representation of the original customer-product space [175].
A related shortcoming is the inclusion of new items or new users. is problem is known
as cold-start [177] and has been formalized before. e recommendation engine cannot provide
suggestions to unknown users, or regarding unknown items. e cold-start new-user scenario can
be faced by soliciting information about her tastes via preference elicitation. For example, a new
user can be asked to rate a list of items in the registration phase. Selecting the most informative
items to propose is a challenge in this context [158], as this selection is crucial in order to obtain
an initial estimate of a user’s preferences. Other methods focus on the deﬁnition of transitive
properties between users via trust inferences [146], or by exploiting graph-theory [5].
More generally, cold start can be faced by means of hybrid approaches that consider both
the rating matrix and additional information about items and/or users. Demographic information
about the user [151] (such as age, sex, marital status) and item features (such as genre, rating,
year of release) [154], can be used to infer relationships between the new user (or new item) and
already registered users (or items in the catalog) for which the recommendation system already
has enough information.
Scalability.
Large user and item bases require robust computational resources. is is especially
true in recommender systems associated with e-commerce or web services, like Amazon.com or
Google News, which also require real-time response rates. e need to generate high-quality
suggestions in a few milliseconds calls for the adoption of scalable methods and sophisticated
data structures for data analysis, access, and indexing. Since the number of users is, typically, much
larger than the number of items (even diﬀerent orders of magnitude), scalable approaches focus on
the analysis of the item-to-item relationships [174] or tend to model single users in communities
[86]. Dimensionality reduction techniques [175], even in incremental versions [173], are used
as well, as they allow us to discriminate between a learning phase, to be processed oﬄine, and a
recommendation phase, which can be performed online.
Item Churn.
In dynamic systems, such as news recommenders, items are inserted and deleted
quickly. e obsolescence of the model in such situations is a big issue, and it calls for the need
to develop incremental model-maintenance techniques.
Privacy.
Recommender systems can pose serious threats to individual privacy. Personal data,
collected using the interactions of customers with the systems, is commonly sold when compa-
nies suﬀer bankruptcy [38] and, although recommendations are provided in an anonymous form,

10
1. THE RECOMMENDATION PROCESS
aggregations of user preferences can be exploited to identify information about a particular user
[157]. Sensitive information, like political and sexual orientations, were breached from the dataset
made public for the Netﬂix prize [141].
Privacy-preserving techniques for recommendation include randomized perturbation
methods [153] and user-community aggregations of preferences that do not expose individual
data [38, 39]. Experimental studies have shown that accurate recommendations are still possible
while preserving user privacy.
Security.
Collaborative recommender systems can be exposed to malicious users willing to in-
ﬂuence suggestions about items. An attacker can modify the original behavior of the systems by
using a set of attacker proﬁles [198], corresponding to ﬁctitious user identities. ree diﬀerent
attack intents have been identiﬁed [109]: the goal of an attacker is “pushing” a particular item by
raising its predicted ratings; or “nuking” competitor products by lowering predicted ratings; and,
in the worst case, damaging the whole recommender system. e works [109, 145, 171] study
the robustness of collaborative recommendation, as well as countermeasures for making attacks
ineﬀective. Recent studies [136, 198] have formalized the push/nuke attacks and, consequently,
they propose classiﬁcation techniques for detecting the attacking proﬁle. e general form of an
attack is composed of a target item (i.e., the item to push or nuke), a set of ratings over selected
items (chosen for their similarity respect to the target item), and a set of ratings on ﬁller items.
Each attack can be characterized by considering how the attackers identiﬁed the selected items,
what proportion of the remaining items they choose as ﬁller items, and how they assign speciﬁc
ratings to each set of items.
1.3
RECOMMENDATION AS INFORMATION FILTERING
e idea behind information ﬁltering is that human interests and preferences are essentially cor-
related, thus, it is likely that a target user tends to prefer what other like-minded users have
appreciated in the past. Hence, the basic approach to information ﬁltering consists of collecting
data about user interests and preferences to build reliable user proﬁles. ese allow us to predict
the interests of a target user based on the known preferences of similar users and, eventually, the
provision of suitable recommendations of potentially relevant items. Recommendations generated
by means of ﬁltering techniques can be divided into three main categories.
• Demographic ﬁltering approaches assume the possibility of partitioning the overall set of
users into a number of classes with speciﬁc demographic features. Customization is achieved
by exploiting manually-built, static rules that oﬀer recommendations to the target user on
the basis of the demographic features of the class she belongs to.
• Content-based ﬁltering techniques learn a model of users’ interests and preferences by
assuming that item and user features are collected and stored within databases’ information
systems. e aim is to provide the target user with recommendations of unexperienced
content items that are thematically similar to those she liked in the past.

1.3. RECOMMENDATION AS INFORMATION FILTERING
11
• Collaborative ﬁltering works by matching the target user with other users with similar
preferences and exploits the latter to generate recommendations.
We brieﬂy describe the ﬁrst two information ﬁltering techniques. Collaborative ﬁltering
approaches are the focus of the entire monograph and will be detailed in the next section.
1.3.1
DEMOGRAPHIC FILTERING
Demographic ﬁltering partitions users in U into a certain number of disjoint classes
U.1/; : : : ; U.C/ and then establishes relationships between items in I and the corresponding
class(es) of interested users. Personal demographic data is basically exploited to group users into
classes according to some partitioning criterion, such as the homogeneity of their purchasing
history or lifestyle characteristics [108]. A set P D fp.1/; : : : ; p.C/g of handcrafted rules [121]
is then exploited to specify the set of items recommendable to the users within the individual
classes. A generic rule p.c/ associates U.c/ with the corresponding subset I.c/, so that, for a given
user u in U.c/, the (binary) prediction criterion
Oru
i D
 1
if i 2 p.c/.u/
0
otherwise
(1.11)
can be devised.
Several disadvantages limit the eﬀectiveness of demographic ﬁltering. e assumption be-
hind recommender systems based on demographic ﬁltering is that users within the same demo-
graphic class are interested in the same items. However, in practice, demographic classes are too
broad and do not catch the actual diﬀerences in the interests, preferences, and expectations of the
involved users. is results in too vague recommendations. e collection of demographic data
raises privacy concerns that make users reluctant to provide personal information. Finally, consid-
erable eﬀort is required to manually specify and periodically update the set P of recommendation
rules.
1.3.2
CONTENT-BASED FILTERING
In content-based ﬁltering, each item is described by a set of keywords or attributes and each user
is associated with a user proﬁle that summarizes the features of the products she liked/purchased
in the past. Content-based recommendations are performed by ranking items according to a sim-
ilarity function that takes into account the proﬁle of the current user [110, 150]. We assume
a scenario where items can be annotated with textual features. Hence, in its most basic form,
content-based ﬁltering is essentially an application of information retrieval techniques to the do-
main of recommendation.
In particular, we assume that F embodies a set ff1; : : : ; fqg of common descriptive features
for the items in I, which summarize and index such textual content. ese features can be, for
example, keywords from the textual content associated with an item [14, 170], e.g., keywords

12
1. THE RECOMMENDATION PROCESS
extracted from the plot of the movie. Features can then be exploited to model items into a vector
representation„ that allows us to project them into a multidimensional Euclidean space. A feature
vector wi 2 Rq is associated with an item i 2 I, and wi;f represents the relevance of feature f for
the considered item. e weight wi;f can be either binary or numeric, depending on the adopted
representation format[14]. For example, TF/IDF [14, 170] is an established weighting scheme
that aims to penalize those features that frequently occur throughout I, since these do not allow
us to distinguish any particular item from the others.
Feature values can be exploited to predict the interest of the user for an unexperienced item.
In particular, machine-learning approaches based on classiﬁcation can be exploited by assuming
that the previous choices of a user u in the preference matrix R can be partitioned into disjoint
sets of positive and negative examples of her interests, i.e., I.u/ D IC.u/ [ I .u/: For example,
IC.u/ may consist of items with ratings above the average rating rR and, similarly, characterize
I .u/ as the set of items with ratings below the average. Partitioning the items allows us to build
a base set upon which to train a classiﬁer.
Besides classiﬁcation, content features can be also exploited to strengthen collaborative
ﬁltering approaches, described in the next section. For example, items can be deemed similar if a
suitable metric for measuring the proximity of their contents can be devised. Content similarity
has been studied in several scenarios, and the most common used metrics are the following.
• Minkowski distance [93] generalizes the notion of distance between two points in an Eu-
clidean space. Given the feature vectors wi and wj respectively associated to the items i and
j, it is deﬁned as
distM
p .i; j / D
 q
X
lD1
jwi;l   wj;ljp
! 1
p
:
Both the Euclidean and Manhattan distances originate from the above deﬁnition, for p D 2
and p D 1, respectively.
• Cosine similarity provides an alternative comparison for comparing items in I. It measures
the similarity of any two items in terms of the angle between their corresponding feature
vectors wi and wj:
simc.i; j/ D
wT
i  wj
kwik2  kwj k2
:
Due to its ease of interpretation and eﬀectiveness in dealing with sparse feature vectors [52],
cosine similarity is a commonly used measure.
• Jaccard similarity [189], originally conceived for boolean representations, tends to measure
how common features tend to be predominant in the whole set of features:
simJ .i; j / D
wT
i  wj
wT
i  wi C wT
j  wj   wT
i  wj
:

1.4. COLLABORATIVE FILTERING
13
Jaccard similarity exhibits aspects of both the Euclidean and cosine measures. In particular,
it tends to behave like the former (resp. the latter) if simJ .i; j/ ! 1 (resp. if simJ .i; j/ !
0).
Choosing among the above measures is essentially a matter of how sparsely items map in the fea-
ture space. [189] provides an extensive comparison of these measures and proposes some guide-
lines for their adoption.
1.4
COLLABORATIVE FILTERING
State-of-the-art recommendation methods have been largely approached from a Collaborative
Filtering (CF) perspective, which essentially consists of the posterior analysis of past interactions
between users and items, aimed at identifying suitable preference patterns in users’ preference
data. CF techniques aim at predicting the interest of users on given items, based exclusively on
previously observed preference. e assumption is that users who adopted the same behavior in
the past will tend to agree also in the future. e main advantage of using CF techniques is their
simplicity: only past ratings are used in the learning process, and no further information, like
demographic data or item descriptions, is needed. is solves some of the main drawbacks of
content-based and demographic approaches [114, 152].
• No personal information about users is needed; this guarantees a higher level of privacy.
• CF approaches are more general and re-usable in diﬀerent contexts, while content-based
techniques require the speciﬁcation of a complete proﬁle (a set of features) for each
user/item.
• Content-based techniques provide the user with a list of products with features “similar” to
the ones that she experienced in the past. is approach may imply the recommendations
of redundant items and the lack of novelty.
• e eﬀectiveness of recommendations increases as the user provides more feedback.
It is important to stress here that the term “collaborative” refers to the capability of sum-
marizing the experiences on multiple users and items. ere are other naive methods that still rely
on the preference matrix, but they only focus on individual entries and ignore their collaborative
features. Simple baselines are the item and user averages,
itemAvg.i/  Nri D
1
jU.i/j
X
u2U.i/
ru
i
(1.12)
userAvg.u/  Nru D
1
jI.u/j
X
i2I.u/
ru
i ;
(1.13)

14
1. THE RECOMMENDATION PROCESS
or more complex combinations, such as:
doubleCentering.u; i/ D ˛ Nri C .1   ˛/ Nru;
(1.14)
where 0  ˛  1 is a parameter that can be tuned to minimize the error in prediction. More
sophisticated baselines can be achieved by combining other components. In the following, we
shall refer to bu
i as any of these baseline models.
Users’ preference matrix
i 1
i 2
i 3
i 4
i 5
i 6
i 7
i 8
i 9
i 10
u 1
2
5
3
1
2
u 2
2
4
5
1
u 3
1
4
5
1
u 4
4
4
2
2
u 5
1
3
3
3
5
u 6
2
1
3
4
5
u 7
4
5
5
1
1
u 8
3
4
3
1
3
u 9
1
3
2
4
4
u 10
5
5
5
4
Memory-based RS
Data
Model
Model-base
RS
Recommendations
Figure 1.2: Memory-based vs. model-based approaches.
Collaborative ﬁltering approaches can be classiﬁed in two categories [36], namely memory-
based and model-based methods. Figure 1.2 provides a sketch of the diﬀerences between them.
Both categories rely on the preference matrix. However, memory-based methods infer the prefer-
ence of the active user for an item by using a database of previously recorded preferences. Among
memory-based approaches, a prominent role is played by neighborhood-based methods, which
are based on the deﬁnition of similarity between pairs of users/items. By contrast, model-based
approaches operate in two phases: in the oﬀ-line phase, the rating matrix is used to learn a com-
pact personalization model for each user; then, the model is used in an on-line phase to predict
the degree of interest of the user on candidate items.
Memory-based approaches are intuitive, as they directly transform stored preference data
into predictions. e drawback is that they need access to the whole dataset to make recom-
mendations, and, thus, they require speciﬁc indexing techniques, especially when the size of the
data increases. On the other hand, model-based approaches require access to only a compact
representation of the data, but the recommendation provided to the user may not be easily in-
terpretable. A fundamental distinction also relies on the kind of relationships among users and
items that they are able to exploit. Neighborhood models are eﬀective at detecting strong but local
relationships, as they explicitly model local similarities. Model-based approaches typically employ
dimensionality reduction techniques, and hence focus on the estimation of weak but global rela-
tionships. Probabilistic methods, which are the focus of this manuscript, represent a reﬁnement
of the model-based approach, which relies on probabilistic modeling both in the learning phase
and in the prediction phase.
In the next sections, we present a brief review of the most-used CF approaches for explicit
preference data. e remainder of the manuscript analyses probabilistic methods in detail.

1.4. COLLABORATIVE FILTERING
15
1.4.1
NEIGHBORHOOD-BASED APPROACHES
e idea behind neighborhood-based approaches [78, 174] is that similar users share common pref-
erences, and, hence, the predicted rating on a pair hu; ii can be generated by selecting the most-
similar users to u. Similar users are called neighbors, and their preferences on i can be aggregated
and combined to produce the prediction. In a real-life scenario, this would correspond to asking
friends for their opinions before purchasing a new product.
We consider here the K-nearest-neighbors (K-NN) approach. Within this framework, the
rating prediction Oru
i is computed following simple steps: (i) a similarity function allows us to
specify the degree of similarity of each a of users, thus enabling the identiﬁcation of the K users
most-similar to u; (ii) the rating prediction is computed as the average of the ratings given by the
neighbors on the same item, weighted by the similarity coeﬃcients. Formally, by denoting with
su;v the similarity between u and v and by N K.u/ the K most-similar neighbors of u, we have
Oru
i D
P
v2N K.u/ su;v  rv
i
P
v2N K.u/ su;v
:
(1.15)
Dually, one can consider an item-based approach [174]: e predicted rating for the pair
hu; ii can be computed by aggregating the ratings given by u on the K most-similar items to i:
e underlying assumption is that the user might prefer items more similar to the ones he liked
before, because they share similar features. Formally,
Oru
i D
P
j 2N K.iIu/ si;j  ru
j
P
j 2N K.iIu/ si;j
;
(1.16)
where si;j is the similarity coeﬃcient between i and j, and N K.iI u/ is the set of the K items
evaluated by u, which are most similar to i.
Similarity coeﬃcients play a central role, which is two-fold: they are used to identify the
neighbors, and they also act as weights in the prediction phase. In addition to the measures pre-
sented in Section 1.3.2, we can alternatively express the similarity by looking at the rating matrix.
In particular, two items (resp. users) can be deemed similar if the ratings they obtained (resp.
provided) are similar.
Let UR.i; j / denote the set of users who provided a rating for both i and j, i.e., UR.i; j/ D
UR.i/ \ UR.j/. Two standard deﬁnitions for the similarity coeﬃcients are the Pearson Correlation
or the Adjusted Cosine. e latter is an adaptation of the cosine similarity shown in Section 1.3.2
[174]:
Pearson.i; j / ,
P
u2UR.i;j/
 ru
i   ri



ru
j   rj

qP
u2UR.i;j/
 ru
i   ri
2
rP
u2UR.i;j/

ru
j   rj
2 I

16
1. THE RECOMMENDATION PROCESS
AdjCosine.i; j / ,
P
u2UR.i;j/
 ru
i   ru



ru
j   ru

qP
u2UR.i;j/
 ru
i   ru
2
rP
u2UR.i;j/

ru
j   ru
2 :
e basic prediction Equations 1.15 and 1.16 can be extended to include unbiased adjust-
ments. For example, the adoption of a composite baseline bu
i allows us to tune the predictions for
speciﬁc users:
Oru
i D bu
i C
P
j2N K.iIu/ si;j  .ru
j   bu
j /
P
j2N K.iIu/ si;j
:
Also, it is possible to generalize the weighting scheme in the equations. In particular, within
Equation 1.16, the term si;j = P
j 2N K.iIu/ si;j represents a weight associated with rating ru
j , and
it is ﬁxed. We can devise a more general formulation of the prediction function, as
Oru
i D
X
j 2N K.iIu/
wi;j  ru
j :
(1.17)
Here, the term wi;j represents a weight associated with the pair .i; j/, to be estimated. e
neighborhood relationship model [23, 25] provides an approach to compute them as the solution of
the optimization problem:
min
X
v2UR.i/
0
@rv
i  X
j 2N K.iIu;v/
wi;j  rv
j
1
A
2
s:t:
wi;j  0
X
j
wi;j D 1 8i; j 2 I:
Here, the set N K.iI u; v/ is deﬁned as the K items most similar to i, which are evaluated both
by u and v.
e K-NN approach is characterized by a relatively lightweight learning phase: we only
need to collect, for each user/item, a suﬃcient number of events that allow the computation
of pairwise similarities. Such similarities can be directly computed online during the prediction
phase. A big issue, however, is the computation of the similarity coeﬃcients for each user/item
pair. When the number of users and/or items is huge, computing such coeﬃcients can be ex-
tremely impractical. To alleviate this problems, indexing methods are needed, which makes the
search for neighbors more eﬃcient. [205] contains a detailed survey on the subject.
1.4.2
LATENT FACTOR MODELS
e assumption behind latent factor models is that the overall preference of the user can be de-
composed on a set of contributes that represent and weight the interaction between her tastes

1.4. COLLABORATIVE FILTERING
17
and the target item on a set of features. is approach has been widely adopted in information
retrieval. For example, the latent semantic indexing (LSI) [50] is a dimensionality reduction tech-
nique that assumes a latent structure in word usage across documents. LSI employes the singular
value decomposition to represent terms and documents in the features space: some of these fea-
ture components are very small and may be ignored, obtaining an approximate model. Given a
M  N matrix A with rank r, the singular value decomposition of A, denoted by SVD.A/ (see
Figure 1.3) , is deﬁned as:
SVD.A/ D U  ˙  V T ;
(1.18)
where:
• U is an M  M unitary matrix; the ﬁrst r columns of U are the eigenvectors of AAT (left
singular vectors of A);
• V is an N  N unitary matrix; the ﬁrst r columns of V are the eigenvectors of AT A (right
singular vectors of A);
• ˙˙˙
is a M  N
diagonal matrix with only r
nonzero values, such that: ˙˙˙ D
diag f1;    ; ng ; i  0 8 1  i < n; i  iC1; j D 0 8 j  r C 1;
• f1;    ; rg are the nonnegative square root of the eigenvalues of AT A and are called sin-
gular values of A.
N
A
U
V
∑
T
=
M
M
M
N
r
r
N
N
M
Singular Value
Figure 1.3: Singular value decomposition.
SVD has an important property: it provides the best low-rank linear approximation of the
original matrix A. Given a number k  r, called dimension of the decomposition, the matrix
Ak D Pk
iD1 uiivT
i minimizes the Frobenius norm kA   AkkF over all rank-k matrices. ere-
fore, focusing only on the ﬁrst k singular values of ˙˙˙ and reducing the matrices U and V, the
original matrix can be approximated using Ak:
A  Ak D Uk˙˙˙kV T
k ;
(1.19)

18
1. THE RECOMMENDATION PROCESS
where Uk is obtained by removing .M   k/ columns from the matrix U and V T
k is produced
by removing .N   k/ rows from the matrix V. An example of this approximation is given in
Figure 1.4. Considering the text analysis case, LSI factorizes the original term-document matrix
A
≈
≈
N
Left singular vector of A
Singular value
Right singular vector of A
M
M
k
k
k
k
N
k
k
T
V
k
k
k
T
V
∑
k
U
U
A
∑
k
k
x
Figure 1.4: k-rank approximation of A.
into the product of three matrices, which reﬂect the relationships between each single term and
document in the k features-space, where k is the number of considered features. e derived
matrix Ak is not the exact factorization of A: the procedure of selecting only the k largest single
values captures the underlying structure of A, removing the noise at the same time [29]. Menon
and Elkan in [132] provide a comparative study of the several methods for approximating the
decomposition in the case of large matrices.
Several works have studied the application of SVD in recommender systems [30, 175].
A low-rank approximation provides a low-dimensional representation of the original high-
dimensional rating matrix R, thereby disclosing the hidden relationships between users and prod-
ucts that could be used to infer a user’s preference on the considered item. If we consider a scenario
involving ratings given by users on a set of movies, then we can provide a high-level interpreta-
tion of the rows of both Uk and Vk. Intuitively, the row vector Uu 2 Rk maps a given user into
a k-dimensional space, representing the underlying factors that inﬂuence each user’s choice. By
analogy, the row vector Vi 2 Rk maps a movie i into the same k-dimensional space. An example
of what hidden factors might represent in this scenario is given by the movie genres. Assuming
the existence of a limited number of diﬀerent such genres (action, romance, comedy, etc.), the
rating can be inﬂuenced by the user’s preference on some genres and by the adherence of a movie
to those genres. Figure 1.5 depicts this example scenario by exploiting three hidden factors.
With an abuse of notation, in this section we will use a simpliﬁed but equivalent formaliza-
tion for the SVD, in which the original matrix is approximated as the product of two component

1.4. COLLABORATIVE FILTERING
19
Rating Matrix
User - Features Matrix
Commedy
0.48
3
u1
i1
i2
i3
u2
u3
i1
i2
i3
u4
u5
4
3
5
5
4
2
2
4
5
5
5
4
1
2
0.45
0.37
0.42
0.50
0.34
14.06
0.64
-0.35
0.54
-0.42
-0.72
0.54
0.84
-0.07
0.69
4.41
1.66
0
0
0
0
0
0
0.45
0.34
-0.58
-0.49
-0.72
0.56
0.19
0.24
-0.19
Action
Love
Commedy
Action
Love
Commedy
Action
Love
Features - Relevance
Item - Features Matrix
Matrix
Figure 1.5: Example of the application of SVD decomposition.
matrices with K features:
R 

UK
p
˙
T
K
 p
˙KV T
K

D U  V;
(1.20)
where U is a M  K matrix and V is a K  N. Intuitively, each user’s preference on an item
matrix is decomposed as the product of the dimensional projection of the users and items into
the K-dimensional feature space:
Oru
i D
K
X
kD1
Uu;k  Vk;i:
(1.21)
e direct application of standard SVD to the context of factorizing user preferences poses
some issues due to the extreme sparsity of the data. In fact, SVD requires a completely speciﬁed
matrix, where all of entries are ﬁt. In a CF scenario, missing data, i.e., unobserved user-item pairs
which represent that the user did not purchase the item, can be interpreted in several ways. For
instance, the user could already own the product and this purchase was not recorded on the system
or he could simply not be aware of it. In other words, “the absence of evidence is not evidence
of absence” and missing data requires special treatment that standard SVD does not perform. In
fact, by treating as zero the preference value corresponding to unobserved user-item pairs, and
applying SVD on the sparse preference matrix, the resulting model is biased toward producing
low scores for items that a user has not adopted before, which may not be an accurate assumption.
To address this issue, it is convenient to minimize the prediction/reconstruction error by
focusing exclusively on observed entries. Given the number of features K, and assuming that U
and V represent a low-rank approximation of the original rating matrix R, we can estimate the
feature matrices by solving this optimization problem:
.U; V/ D argmin
U;V
2
4 X
.u;i/2 T
 
ru
i  K
X
kD1
Uu;kVk;i
!23
5 :
(1.22)
is optimization problem has been extensively studied, both theoretically [185] and practically
[60]. For example, an incremental procedure to minimize the error of the model on observed

20
1. THE RECOMMENDATION PROCESS
ratings, based on gradient descent, has been proposed in [60]. is was one of the major con-
tributions achieved during the Netﬂix Prize. e feature matrices are randomly initialized and
updated as follows:
U0
u;k D Uu;k C 
 2eu;i  Vk;i

V 0
k;i D Vk;i C 
 2eu;i  Uu;k

;
(1.23)
where eu;i D Oru
i   ru
i is the prediction error on the pair hu; ii and  is the learning rate.
e optimization problem can be further reﬁned by constraining U and V: for example,
by forcing non-negativity and sparseness [88, 112]. Particular attention has been devoted to the
problem of capacity control and overﬁtting prevention. In a collaborative prediction setting, only
some of the entries of R are observed. As a consequence, the generalization capabilities of the
model can be compromised by the learning procedure, which can be trapped into local minima
and, in particular, can be inﬂuenced by extreme values. For example, some users or items could be
associated with too few observations. Regularization in this case aims at balancing the values of
the matrices by shrinking them to more controlled values. [160, 186] suggested a formulation of
this regularization termed Maximum Margin Matrix Factorization (MMMF). Roughly, MMMF
constrains the norms of U and V to a bounded value. is corresponds to constraining the overall
“strength” of the factors, rather than their number. at is, a potentially large number of factors is
allowed, but only a few of them are allowed to be very important. For example, “when modeling
movie ratings, there might be a very strong factor corresponding to the amount of violence in
the movie, slightly weaker factors corresponding to its comic and dramatic value, and additional
factors of decaying importance corresponding to more subtle features such as the magniﬁcence of
the scenery and appeal of the musical score” [160].
Mathematically, the regularization constraints can be speciﬁed within the optimization
function,
.U; V/ D argmin
U;V
2
4 X
.u;i/2 T
 
ru
i  K
X
kD1
Uu;kVk;i
!2
C U tr.UT U/ C V tr.V T V/
3
5 ;
(1.24)
where U and V are regularization coeﬃcients and tr.A/ denotes the trace of the square matrix
A. e above reformulation of the problem yields the new update rules that take into account the
regularization:
U0
u;k D Uu;k C 
 2eu;i  Vk;i   U  Uu;k

;
V 0
k;i D Vk;i C 

2eu;i  U0
u;k   V  Vk;i

:
(1.25)
Regularization is extremely important both theoretically and practically, and has several related
aspects. For example, the regularization terms can be adapted based on the popularity of users
and/or items. For instance, estimation for a user who has seen very few movies will likely suf-
fer from overﬁtting unless heavily regularized. Likewise, the number of ratings per movie varies
widely and the regularization should take this into account. [197] further reﬁnes the optimization

1.4. COLLABORATIVE FILTERING
21
of Equation 1.24 by taking these aspects into account. In practice, the regularization coeﬃcients
U and V should be adapted to users and items, for example, by taking into account the compo-
nent number of preference observation for user/item as a weighting component in the objective
function. We will discuss the probabilistic interpretation of this regularization in detail in Chap-
ter 3.
Several variations of the basic prediction rule 1.21 have been proposed. For example, the
basic model can be reﬁned by combining the baseline model with the SVD prediction [148]:
Oru
i D bu
i C
K
X
kD1
Uu;k  Vk;i:
An alternative formulation reduces the number of parameters to be learned by relating the user
matrix Uu to all the items preferred by u:
Uu;k /
X
i2 I.u/
Vk;i:
Koren [106] further extends this model by considering both a free-factor contribution and a
constrained contribution. e resulting SVD++ model thus proposes the prediction rule:
Oru
i D bu
i C
K
X
kD1
0
@Uu;k C ˛
X
i2 I.u/
Vk;i
1
A  Vk;i:
e gradient-descent algorithm can be tuned accordingly by plugging the above equation
into Equation 1.22.
In addition to these approaches, the general task of matrix factorization for recommender
systems has been widely explored and is surveyed in [107, 133]. e performance of latent factor
models based on the SVD decomposition strongly depends on the number of features and the
structure of the model, characterized by the presence of bias and baseline contributions. e
optimization procedure used in the learning phase also plays an important role: learning can
be incremental (one feature at the time) or in batch (all features are updated during the same
iteration). Incremental learning usually achieves better performances at the cost of higher learning
time.
1.4.3
BASELINE MODELS AND COLLABORATIVE FILTERING
We conclude this section by mentioning the relationships between the baseline methods and
collaborative ﬁltering. We discussed how the baseline methods still rely on the preference matrix,
but they only focus on individual entries and ignore the collaborative nature of the data.
Besides their predictive capabilities, baselines can be exploited to reﬁne collaborative meth-
ods, and we have seen some examples of this throughout this section. Alternatively, baselines can

22
1. THE RECOMMENDATION PROCESS
be used for preprocessing the data prior to the application of other techniques. e Global Eﬀects
Model has been introduced by Bell and Koren in the context of the Netﬂix Prize [24], and it is
considered an extremely eﬀective technique. e key idea is to adjust standard collaborative ﬁlter-
ing algorithms with simple models that identify systematic tendencies in rating data, called global
eﬀects. For example, some users might tend to assign higher or lower ratings to items with respect
to their average rating (user eﬀect), while some items tend to receive higher rating values than
others (item eﬀect). Other eﬀects can involve the time dimension: for example, temporal patterns
can cause user’s ratings to increase or decrease in speciﬁc periods of time, and, similarly, ratings
associated with some movies can decay soon after their release. Stepwise estimation and removal
of the global eﬀects provides a substantial advantage in terms of reduction of noise. As shown
in [24], adopting this pre-processing strategy enables the identiﬁcation of more precise models,
which are robust to the biases introduced by the global eﬀects.

C H A P T E R
2
Probabilistic Models for
Collaborative Filtering
e focus of this book is the adoption of tools and techniques from probability theory for mod-
eling users’ preference data and to tackle the recommendation problem. Probability theory can
be applied in several facets: for modeling past events (i.e., users’ choices on a catalog of items)
and making prediction about future ones; for decision theory; for model selection; etc. Clearly,
many of these aspects are not speciﬁc to recommender systems, and they can be rooted instead
in a more general machine-learning and statistical setting. Our focus, however, is on how the
wide variety of probabilistic models can be made suitable for the recommendation data and tasks.
To this purpose, next we describe both models and learning procedure and practical applications.
is book is not focused on probabilistic modeling and inference by itself. Other books cover the
ﬁeld in a thorough way (see, e.g., [31, 138]). What we propose here is a uniﬁed view of proba-
bilistic modeling in the context of a recommendation scenario, with particular attention to both
modeling and computational aspects.
In a probabilistic setting, users’ preferences are modeled as stochastic events. e analysis of
the statistical distributions of such events provides insights on the mathematical rules governing
users’ choices and preferences. e problem then becomes how to obtain a smooth and reliable
estimate of the distribution. In general, it is convenient to use a parametric model to estimate the
distribution when any constraints on the shape of the distribution are known. Given a random
variable X, the probability that X takes a given value x (denoted as P.X D x/, or just P.x/
for short), is parametric to a parameter set , i.e., P.x/ , P.xj/.¹ Random variables in our
framework may represent either users, items, or ratings, as well as combinations of them. For
example, we can model the distribution of ratings through a Gaussian distribution parameterized
by  D .; /, so that P.r/ , P.rj; /  N .; /, centered on  and with  variance.
ere are two problems we face in the following. Starting from a sample X of independent
and identically distributed (i.i.d.) observed values x1; x2; : : : ; xn, for a random variable X, we deal
with:
• Estimation of , that is, the speciﬁcation of the set of statistical parameters based on the
observed data X.
¹e notation , is used in the following to denote that the term in the left-hand side is a shorthand for the term in the
right-hand side.

24
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
• Inference of P. QxjX / for a given value Qx, based on the observed data.
e most natural and popular way to estimate parameters of the employed probabilistic
model is the maximum likelihood estimation (MLE), where the parameter values that are most
likely to generate the observed data are chosen. at is, given a likelihood function
L.jX / D P.x1; x2; : : : ; xnj/ D
n
Y
iD1
P.xij/;
(2.1)
MLE chooses the model parameter OML that maximizes L.jX /, i.e.,
OML D argmax

L.jX /:
e interpretation is that the desired probability distribution is the one that makes the observed
data “most likely” to be observed. When OML can be estimated, we can solve the inference problem
as well, by approximating P. QxjX / as
P. QxjX /  P. Qxj OML/:
We review some baseline methods presented in Chapter 1 and provide a probabilistic in-
terpretation for them. First of all, we assume that the set X of observations is based on the rating
matrix R. en, we can concentrate on two diﬀerent scenarios: implicit feedback or explicit ratings.
With implicit feedback, we assume that R is binary. In such cases we are interested in mod-
eling whether, for a given pair .u; i/, the property ru
i D 1 holds. We can assume a Bernoulli
model governed by a global parameter  , p; thus, the probability that ru
i D 1 can be modeled
as P.ru
i D 1j/ D p. Each observation in X is relative to a pair .u; i/ and denotes whether the
associated value is positive or not. e likelihood of the data is given by
L.jX / D
Y
u;i
pru
i .1   p/1 ru
i D pn.1   p/MN n;
where n D P
u;i 1Jru
i > 0K is the number of non-zero entries in R. e above likelihood yields
the MLE estimate
OpML D
n
M  N :
With explicit ratings, we still concentrate on a pair .u; i/, but the value ru
i ranges within
f0; : : : ; V g. We can consider two alternative modeling strategies:
• ru
i is sampled from a continuous distribution, e.g., a Gaussian distribution parameterized
by  , f; g.
• ru
i is sampled from a multinomial distribution parameterized by  , fp1; : : : ; pV g.

25
In both cases, we ignore zero values, which are interpreted as unrated items. us, the set X of
observed values is represented by all the pairs for which the preference value is greater than zero.
Denote such pairs as hu; ii: then, the likelihood can be expressed as
L.jX / D
Y
hu;ii
P.ru
i j/:
Optimizing the above with regards to  yields the following:
• for the Gaussian case:
O D 1
n
X
hu;ii
ru
i
O D 1
n
X
hu;ii
.ru
i   O/2;
• for the multinomial case:
pr D 1
n
X
hu;ii
1Jru
i D rK:
roughout the chapter, we shall use graphical models representing Bayesian networks to denote
variables and dependencies among elements [101]. Graphical models express the joint distribu-
tion of a system or phenomenon in terms of random variables and their conditional dependencies
in a Directed Acycling Graph (DAG). Nodes of this DAG represent random variables, while edges
correspond to causal dependencies that entail conditional probability distributions. Bayesian net-
works distinguish between evidence nodes (pictured with a gray background in the following),
which correspond to variables that are observed or assumed observed, and hidden nodes, which
correspond to latent variables. Many models are speciﬁed by replications of nodes that share par-
ents and/or children, e.g., to account for multiple observations from the same distribution or
mixture components. Such replications can be denoted by plates, which surround the subset of
nodes and have a replication count or a set declaration of the index variable at the lower right cor-
ner. Graphical models provide an intuitive description of an observed phenomenon as a so-called
generative model, which states how the observations could have been generated.
Consider the following graphical model:
.r.

.
N
.
M
.
is DAG speciﬁes a causal relationships between the latent random variable  and the observed
data r. e two plates respectively specify users (M) and items (N). A value r is associated with
each combination .u; i/ (expressed by the intersection of the boxes).

26
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
We can observe that the resulting estimations provide a probabilistic interpretation of the
OverallMean baseline method discussed in Chapter 1: in such a model we are interested in devising
a global behavior from the rating matrix R, upon which to base our predictions. However, we can
consider more reﬁned situations, where we can condition the observation r to the identity of
the user/item involved. For example, we can specialize the above estimations to resemble the
UserAvg method. is model assumes that the parameter set is speciﬁc to each user, i.e.,  ,
f1; : : : ; Mg, such that P.ru
i j/ , P.ru
i ju/.
.r.

.
N
.
M
.
Hence, X represents the rows of R, where each row comprises all the possible observations in-
volving a user u. In the case of implicit preferences, u represents a Bernoulli parameter pu, and
we can rewrite the likelihood as
L.jX / D
Y
u
Y
i
p
ru
i
u .1   pu/1 ru
i D
Y
u
pnu
u .1   pu/M nu;
which can be optimized with respect to each pu separately, yielding Opu D nu=M, where nu D
jI.u/j.
In the rest of the chapter we study probabilistic modeling by following an incremental ap-
proach. We start in Section 2.1, by reformulating the rating prediction problem in a probabilistic
setting and we propose a simple probabilistic framework that reconsiders and strengthens the
naive Gaussian and multinomial models shown, so far, in a regression perspective. We then in-
troduce latent factor modeling in Section 2.2, and gradually show how the latter can be exploited
to model more complex relationships which hold within preference data. It is worth noting that
most of the models described in the next sections are extremely important from a theoretical
point of view, as they represent simple yet mathematically robust alternative research directions
for modeling preferences. However, they should only be considered under a pedagogical perspec-
tive, since their predictive abilities were historically overcome by their reformulation in a Bayesian
setting, which we shall cover in details in Chapters 3 and 5.
2.1
PREDICTIVE MODELING
We assume three random variables X; Y; and R, ranging over U, I; and V. e event X D u; Y D
i; R D r represents the fact that R exhibits the value r in correspondence to row u and col-
umn i. is allows three possible modeling alternatives for prediction modeling: either, P.rju; i/,
P.r; iju/, or P.r; u; i/. Although there is strong relationship between these quantities, the un-
derlying models are diﬀerent and correspond to diﬀerent scenarios. e ﬁrst setting, called forced

2.1. PREDICTIVE MODELING
27
prediction [85], involves predicting a preference value for a particular item i, given the identity of
the user. In such a context, we are interested in the probability P.rju; i/ that user u will rate item
i with r. Based on the conditional probability, we can deﬁne a prediction function g.u; i/, which
depends on the probability P.rju; i/: for example, by associating g.u; i/ to a deterministic value
g.u; i/ D argmaxr P.rju; i/ or to the mean value g.u; i/ D
Z
r
r  P.rju; i/ dr. Hoﬀman denotes
this setting forced prediction because it mimics an experimental setup in which the response of a
user is solicited for a particular item and the user has no choice on which item to vote. is is the
relevant prediction mode in scenarios in which an item is presented to a user as a recommendation
and one is interested in predicting the user’s response.
e second choice, i.e., P.r; iju/, is called free prediction and it explains not only the ob-
served ratings, but also why item i is chosen to be rated by user u. By using the chain rule, we have
P.r; iju/ D P.rju; i/  P.iju/, thus decomposing the problem into the prediction of the selection
of the considered item (irrespective of the rating) and a prediction of the rating conditioned on
the (hypothetically) selected item. e probability P.iju/ corresponds to the likelihood of an im-
plicit preference, whereas P.rju; i/ corresponds to the probability of an explicit preference. us,
free prediction can incorporate both models and it achieves a more comprehensive modeling of
the preference phenomena. Moreover, Hoﬀman [85] highlights that the free prediction case is
a generalization of what is commonly referred to as the “recommendation” task, i.e., selecting a
set of items to present to the user. As a result, items that have been rated by many users will have
more impact on the model estimation than items that are only rated by a few users.
e third choice, i.e., P.r; u; i/, models the joint distribution between the three random
variables. Under this choice, the model is also concerned with the behavior of users (e.g., some
users tend to purchase and rate more items than the average). In particular, users with more ratings
tend to have a larger impact on the ﬁnal model than users that only rate a few items. By using
the chain rule, P.r; u; i/ D P.rju; i/P.iju/P.u/ and we can notice the role played by the prior
probability about user u.
Let us concentrate on forced prediction for the moment. e objective is to model the
probability P.rju; i/ that user u will rate item i with rating r. e pair .u; i/ can be characterized
by a set of features: these are elementary pieces of evidence that link aspects of what we observe
relative to .u; i/ with the rating r that we want to predict. Example features can be indicator
functions of the atomic properties in F described in Chapter 1, such as Sex(u,male) or Rating(i,PG),
or even their combination, such as Sex(u,male) ^ Rating(i,PG). In its most general form, a feature
can be considered as a function f W U  I 7! R associating a real value to an observation hu; ii.
In the above example, a relative feature can be encoded as 1JSex(u,male) ^ Rating(i,PG)K.
Features are important because they map an observation hu; i; ri to a multidimensional
numerical space. By selecting a ﬁxed set F D ff1; : : : ; fdg of features, each observation hu; ii
can be encoded as a d-dimensional vector, and then we can approach the prediction problem as
a regression problem. In particular, by interpreting r as a numerical value, we can introduce a set
of parameters  , fˇ1; : : : ; ˇd; g, and model the probability P.rju; i/ by means of a Gaussian

28
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
model:
P.rju; i; / D
1
p
2
exp

  1
22 .r   u;i/2

;
(2.2)
where
u;i D
d
X
kD1
ˇkfk.u; i/:
Analogously, by interpreting r as a discrete value, we can reﬁne the simple multinomial model
proposed in the beginning of this chapter, by assuming that the multinomial parameter pr is
speciﬁc to the observation hu; i; ri at hand. Consider a set of logistic factors  , fˇr;1; : : : ; ˇr;dg.
en we can deﬁne the probability of observing r relative to hu; ii by means of the log-linear model
P.rju; i; / D
1
Zu;i./ exp
(X
k
ˇr;kfk.u; i/
)
;
(2.3)
where Zu;i./ is a normalization factor, expressed as
Zu;i./ D
X
r2V
exp
(X
k
ˇr;kfk.u; i/
)
:
is simple yet powerful modeling has been studied extensively in the literature [28, 131, 149,
212].² In its most basic form, the model can be developed based on elementary features, relative to
the dimensions u and i of the preference [131]: fhui and fhii (where hi represents an enumeration
of features relative to users/items), can be deﬁned as simple indicator functions,
fhu0i.u; i/ D 1Ju D u0K
fhi0i.u; i/ D 1Ji D i0K;
and we can assume M  N features, which enable the corresponding regression factors. Figure 2.1
shows a toy preference matrix and the set of features associated with each observation. Some
patterns are clearly observable within the feature matrix: for example, f4 and f2 are associated
with low preference values.
Besides this naive modeling, it is possible to include even more complex features, repre-
senting, e.g., side information or dependency among users/items (see Chapter 6).
e estimation of the weights associated with the features can be accomplished by means
of MLE, by optimizing the log-likelihood LL.jX / D
X
hu;i;ri
log P.rju; i; /. In the Gaussian
²Log-linear models are presented in a more general notation in the current literature by assuming that feature functions also
embody the value to predict: that is, a generic fk W U  I  V 7! R is relative to the tuple .u; i; r/. e notation we propose
here is a particular case of this more general formulation, and it is simpliﬁed for highlighting the analogy with the Gaussian
model.

2.1. PREDICTIVE MODELING
29
1
1
1
u 1,i1,1
u 3,i1,1
u 2,i3,2
u 2,i4,2
u 1,i2,5
u 3,i3,4
1
f1
1
1
1
1
1
1
1
1
f2
f3
f4
f5
f6
f7
1
u 1
1
i1
2
2
i2
i3
i4
u 2
u 3
5
4
(a) Users’ preference matrix
(b) Features associated with observations
Figure 2.1: Users’ preference matrix and features.
case, we have
LL.jX / D  n
2 log    n log 
2
 1
22
X
hu;i;ri
 
r  X
k
ˇkfk.u; i/
!2
;
(2.4)
which yields the classical solution
Oβ D.ΦT Φ/ 1ΦT r;
(2.5)
O D1
n
X
hu;i;ri
 
r  X
k
Oˇkfk.u; i/
!2
;
(2.6)
where Φ is the m  d design matrix relative to all the features associated with all the observations
in X, and r is the vector of all ratings associated with such observations.
For the discrete case, consider the log-likelihood
LL.jX / D
X
hu;i;ri
X
k
ˇr;kfk.u; i/  X
u;i
log
X
r2V
exp
(X
k
ˇr;kfk.u; i/
)
:
Unfortunately, the summation inside the logarithm does not provide any closed formula, for the
ˇr;k parameters, so one has to resort to iterative methods in order to approximate the optimal
solution. Historically, the optimization problem has been approached by means of iterative scaling
techniques [48]. ese methods are specialized on log-linear models: they iteratively construct a
lower bound to the log-likelihood, and then optimize the bound. People have worked on many
variants of the bounding technique, and an eﬃcient variant is the Improved Iterative Scaling (IIS)
algorithm. Starting with an arbitrary solution , IIS iteratively searches for an improvement ır;k
for each ˇr;k, such that  C  now represents the parameters ˇr;k C ır;k, and this new parameter

30
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
set guarantees LL. C jX /  LL.jX /. We can observe the following:
LL. C jX / LL.jX /
D
X
hu;i;ri
X
k
.ˇr;k C ır;k/fk.u; i/  X
u;i
log
X
r2V
exp
(X
k
.ˇr;k C ık/fk.u; i/
)
 X
hu;i;ri
X
k
ˇr;kfk.u; i/ C
X
u;i
log
X
r2V
exp
(X
k
ˇr;kfk.u; i/
)
D
X
hu;i;ri
X
k
ır;kfk.u; i/  X
u;i
log
P
r2V exp
˚P
k.ˇr;k C ır;k/fk.u; i/
	
P
r2V exp
˚P
k ˇr;kfk.u; i/
	
:
We can apply the property log x  x   1, to obtain
LL. C jX / LL.jX /

X
hu;i;ri
X
k
ır;kfk.u; i/  X
u;i;r
exp
˚P
k.ˇr;k C ır;k/fk.u; i/
	
P
r2V exp
˚P
k ˇr;kfk.u; i/
	
D
X
hu;i;ri
X
k
ır;kfk.u; i/  X
u;i;r
P.rju; i; / exp
(X
k
ır;kfk.u; i/
)
:
e above formula can be further simpliﬁed by exploiting Jensen’s inequality³. By introducing
f #.u; i/ D P
k fk.u; i/, we have:
X
hu;i;ri
X
k
ır;kfk.u; i/  X
u;i;r
P.rju; i; / exp
(X
k
ır;kfk.u; i/
)
D
X
hu;i;ri
X
k
ır;kfk.u; i/  X
u;i;r
P.rju; i; / exp
(
f #.u; i/
X
k
ır;k
fk.u; i/
f #.u; i/
)

X
hu;i;ri
X
k
ır;kfk.u; i/  X
u;i;r
P.rju; i; /
X
k
fk.u; i/
f #.u; i/ exp
˚
f #.u; i/ır;k
	
, B.; /:
us, B.; / represents a lower bound of the diﬀerence LL. C jX /   LL.jX /. Hence, by
optimizing B.; / with respect to , we can guarantee an improvement of the likelihood. A nice
property of B.; / is that all the ır;k parameters are only bound by linear relationships, so that
optimizing B.; / separately for each ır;k is relatively easy. As a matter of fact, the optimization
of B.; / with respect to ır;k admits a closed formula. e overall IIS procedure can be ﬁnally
schematized as follows.
³e inequality states that, given a convex function f and a random variable X ranging over the domain of f , then EŒf .X/ 
f .EŒX/. Details can be found in [45, Section 2.6].

2.2. MIXTURE MEMBERSHIP MODELS
31
• Start with an initial arbitrary choice for each ˇ0
r;k;
• Repeat until convergence for increasing steps t:
1. Optimize B..t/; / with respect to ır;k, for each r and k;
2. Update ˇ.tC1/
r;k
D ˇ.t/
r;k C ır;k.
Iterative scaling methods have three main advantages. ey can easily incorporate feature
selection; furthermore, they scale up well in the number of features; ﬁnally feature dependencies
do not aﬀect the accuracy of the learned model. e biggest problem with these methods is that
the bound provided at each iteration can be loose. As a consequence, the rate of convergence can
be extremely slow. Improvements to the basic scaling scheme have been proposed [89, 99], which
provide tighter bounds and in general tend to increase the rate of convergence.
It is generally recognized that gradient-based optimization algorithms [144] are able to ﬁnd
the optimal parameters much faster than the iterative scaling methods. Among these, general-
purpose methods that use the Newton search direction have a fast rate of local convergence,
typically quadratic. e main drawback of these methods is the need for the Hessian matrix of
the log-likelihood. Explicit computation and inversion of this matrix can be problematic, when
the number of feature functions is high. Quasi-Newton methods provide a practical alternative, in
that they rely on an approximation of the Hessian, which can be computed incrementally, and still
attain a superlinear rate of convergence. Limited-memory quasi-Newton methods, like L-BFGS
[116], represent the current methods of choice for training log-linear models [120].
2.2
MIXTURE MEMBERSHIP MODELS
e exceptional sparsity of users’ preference data poses a main challenge for users’ proﬁling and
the generation of personalized recommendations. Clustering and, in general, dimensionality re-
duction techniques, allow us to abstract from the limited available data for a given user or item,
and identify preference patterns that can be associated with each user or item with a certain degree
of certainty. is is the underlying idea of mixture membership models: analyzing and detecting
similarities among users and/or items and introducing a set of latent variables, which identify a
ﬁxed number of more general preference patterns. Generally, the design of such models is driven
by the following considerations:
• Detection of similarity among users or items. In other words, given observed preference
data, how should we model and detect user or item similarity? For instance, similar-minded
users can be detected simply by considering the number of common purchased items, or by
considering their agreement on ratings. More complex similarity measures might highlight
the mutual relationships between similar users and similar items.

32
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
• Choice of causal relationships to be modeled. While entities to be modeled in the con-
text of preference data are ﬁxed, i.e., user, items, preference values, and, possibly, latent
variables, their causal relationships may vary. In a user-based modeling scenario, we are
interested in abstracting from the level of single users and identifying preference patterns
that are well-suited for a group of similar minded users. Symmetrically, in an item-based
perspective, the goal is to identify categories of items that tend to receive similar evaluations
from users. ese dependencies can be combined into more sophisticated models, which
allow simultaneous clustering on both dimensions and hierarchical relationships.
• Choice of the membership. Should each user/item be statically associated with a given
cluster, or should we allow fuzzy memberships? In the ﬁrst case, the model induces a par-
tition over the user set or the item set by identifying user communities or item categories.
In the second case, we assume that user/item can have several interests/aspects and, hence,
they can be associated with diﬀerent clusters simultaneously.
• emodelingofpreferencepatters,i.e.,thechoiceoftheappropriategenerativedistribu-
tion for preference values. Several choices can be taken to model rating patterns: if ratings
are discrete, as in the case of the typical 5 stars scale, a multinomial distribution can be em-
ployed to model the probability of observing a given rating value. If ratings are continuous,
the choice of a Gaussian distribution is more appropriate.
is section is aimed at reconsidering the basic models proposed in the beginning of this chapter
under a clustering perspective, according to the aforementioned dimensions.
In a nutshell, clustering can be interpreted in terms of a latent causal relationship that
inﬂuences a user’s choice or an item characteristic. Hence, latent factors can be exploited to model
similarities and to express the likelihood to observe a preference value in terms of such similarities.
e simple probabilistic models, proposed at the beginning of the chapter, can be specialized to
cover the case where a user’s choice is inﬂuenced by a latent factor. at is, a generic event x can be
conditioned to a variable y representing a latent state, so that P.x/ can be expressed as a mixture
P.x/ D
X
y
P.xjy/P.y/;
and we can concentrate on modeling both P.xjy/ and P.y/. More generally, a mixture model
[31] is a general probabilistic approach that introduces a set of latent factor variables to represent
a generative process in which data points may be generated according to a ﬁnite set of probability
distributions. e introduction of the latent variables allows the modeling of complex distribu-
tions in terms of simpler components.
A naive way of introducing mixtures within preference data is to consider that each user is
associated with a latent state, and, consequently, to model the probability P.ru
i / accordingly. We
can consider a M  K binary matrix Z, where each row zu is such that P
k zu;k D 1. We will also

2.2. MIXTURE MEMBERSHIP MODELS
33
use the single multinomial latent variable zu (or z, when u is clear from the context) with values
ranging in f1; : : : ; Kg, with zu D k denoting the fact that zu;k D 1.
e vector zu is associated with a user u, and, in particular, with a row ru of R. Intuitively, zu
represents the fact that user u is associated with the one factor k, such that zu;k D 1, and, hence, all
its preferences can be explained in terms of k. at is, the parameter set  can be decomposed into
1; : : : ; K, and the preferences of u are generated according to k. Graphically, the generative
process is expressed in Figure 2.2.
r
z
N
K
M
Figure 2.2: Graphical model for the mixture model.
Here, π is a multinomial distribution that models the prior probability P.zjπ/ relative to
a latent factor z. e underlying idea is that data are generated according to a stochastic process
governed by the underlying probability distributions. is process can be expressed as follows:
• For each user u pick a latent factor k  Disc.π/;
– For each item i pick a preference r  P.rjk/.
According to this model, the probability of observing ru is given by
P.ruj; π/ D
X
z
P.zjπ/P.rujz; / D
K
X
kD1
k
Y
iWhu;ii2R
P.ru
i jk/;
and consequently the likelihood can be expressed as
L.; πjX / D
Y
u
K
X
kD1
k
Y
hu;ii
P.ru
i jk/:
(2.7)

34
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
e optimization of the above likelihood is diﬃcult, and one has resort to iterative techniques,
based on numerical optimization. An alternative approach is given by resorting to the EM al-
gorithm [51]. Similar to the IIS scheme discussed before, the EM algorithm is based on the
speciﬁcation of a lower bound to the true likelihood, which hence can be exploited within an iter-
ative scheme. e EM approach (see Appendix A.1 for the mathematical basis of the algorithm)
consists of considering the complete-data expectation log-likelihood:
Q.; 0/ D
X
Z
P.ZjX ; 0/LL.jX ; Z/
D
X
u
K
X
kD1
u;k.0/
8
<
:log k C
X
hu;ii
log P.ru
i jk/
9
=
; ;
where the term u;k.0/ represents the posterior probability of the latent variable zu;k given 0
and u. Hence, the core of the algorithm is an iterative alternation between the expectation (E)
step, where we infer the term u;k, and the maximization (M) step, where we exploit the u;k
computed so far to optimize Q.; 0/ with respect to .
Notably, by properly instantiating P.ru
i jk/, we can obtain a complete speciﬁcation of
both the E and the M steps.⁴ Let us review the models proposed at the beginning of this chapter,
within a mixture-modeling framework.
Example 2.1 (Bernoulli model)
Events in this model are represented by the presence/absence
of a preference. Deﬁne k , pk, P.rjk/ D pk and let nu denote the number of items previously
purchased by the user u, i.e., nu D jI.u/j. en,
Q.; 0/ D
X
u
K
X
kD1
u;k.0/
˚log k C nu  log pk C .M   nu/  log.1   pk/
	
;
which deﬁnes the M-step as:
Opk D
P
u u;k  nu
M P
u u;k
:
Example 2.2 (Explicit preferences)
Adapting the framework is straightforward, as it just re-
quires re-deﬁning k , fk; kg (for the continuos/Gaussian case), or k , fpk;1; : : : ; pk;V g
(for the discrete case). Since the observations X are only relative to the rated items, we have:
⁴In particular, the term u;k can be inferred by means of Equation A.7, independently of the functional form of P.ru
i jk/.

2.2. MIXTURE MEMBERSHIP MODELS
35
• for the Gaussian case,
Q.0; 0/ /
X
u
K
X
kD1
u;k.0/
8
<
:log k   nu log k    2
k
X
iWru
i >0
.ru
i   k/2
9
=
; ;
and
Ok D
P
u;i u;k  ru
i
P
u u;k  nu
Ok D
P
hu;iiWru
i >0 u;k  .ru
i   Ok/2
P
u u;k  nu
I
• for the multinomial case,
Q.0; 0/ D
X
u
K
X
kD1
u;k.0/
8
<
:log k C
X
iWru
i >0
X
r
1Jru
i D rK log pk;r
9
=
; ;
with P
r pk;r D 1, and
pk;r D
P
u u;k  P
i 1Jru
i D rK
P
u u;k  nu
:
2.2.1
MIXTURES AND PREDICTIVE MODELING
Exploiting a mixture model for prediction is straightforward. For example, in the case of forced
prediction, we can decompose the probability distribution over ratings for the pair hu; ii as
P.rji; u; / D
X
z
P.zju; i; /  P.rjz; /:
Observe now that, in the models previously introduced, the latent factor is only associated with a
user, that is, P.zju; i; / D P.zju; /, which we can approximate by using the posterior prob-
ability u;k./, given the observations in X. Hence, a rating distribution can be obtained by
instantiating P.rjz; / with any of the models discussed so far.
is naive model can be further reﬁned in several ways. First of all, observe that, in this
model, the probability of a rating is governed by the component P.rjz; /, which expresses a
general trend relative to the ratings generated by all the users associated with a given latent factor
z. As a consequence, the model is not able to capture ﬁner distinctions that take into account
items. Consider the following example of a preference matrix.

36
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
1
1
1
1
1
1
1
1
3
3
5
5
2
2
2
2
2
2
2
2
2
3
3
4
Two clusters can be devised, which group users u1; u2; and u3; u4; u5. In particular, within the
second group, a general tendency is to provide low preference values, except for item ii, for which
both u3 and u4 provide a high preference. is observation highlights two diﬀerent preference
patterns within the second cluster: high values for item i1, and low values for the remaining items.
However, these two opposing patterns are not caught by either the multinomial nor the Gaussian
mixture model deﬁned in the previous section, as their parameters tend to average the ratings
according to the general trend.
To avoid such a drawback, it is convenient to model the prediction probability by enforcing
the dependency of the rating on both the latent factor and the proposed item [124] , as
P.rji; u; / D
X
z
P.zju; /  P.rjz; i; /:
Figure 2.3(a) adapts the simple multinomial mixture model to such a situation. Here, the latent
factor z is associated with a speciﬁc user and the rating is given by a multinomial probability
distribution i;k, which depends on both the status k of the latent variable and the user i under
observation. As a consequence, the likelihood relative to the parameter set  D fπ; ϵg can be
expressed as
P.X j/ D
Y
u
X
k
k
Y
hu;i;ri
P.rjϵi;k/:
e adaptation of procedure for learning ϵ, as well as the formulation of the Gaussian case,
are straightforward.
e User Communities Model (UCM, [21]) provides a further reﬁnement, by focusing on
free prediction and thus modeling the probability P.r; iju/. e underlying generative process is
shown in Figure 2.3(b) and can be expressed as follows.
• For each user u:
– Pick a latent factor z  Disc.π/;
– For j D 1 to nu:
select an item i  P.ijϕz/;
generate a preference value of the selected item r  P.rji;z/.

2.2. MIXTURE MEMBERSHIP MODELS
37
.r.
z
.

.

.
i
.
N
.
K  N
.
M
.
(a) Forced prediction
.z.
i
.
r
.

.

.

.
N
.
M
.
K
.
K  N
.
(b) Free prediction
Figure 2.3: Graphical model for the mixture model.
Here, ϕz denotes a multinomial probability fz;igi2I among items, and ϵi;z the parameter
set for the rating, relative to latent factor z when the observed item is i. P.rjϵi;k/ can be instan-
tiated either as a multinomial or a Gaussian distribution. e corresponding likelihood can be
expressed as
P.X j/ D
Y
u
X
k
k
Y
i
VY
rD1
˚
k;iP.rjϵi;k/
	1Jru
i >0K :
e EM framework provides an estimation of the model parameters. Predicting the likelihood
of a preference i; r for a given user u is straightforward:
P.r; iju; / D
X
z
P.zju; /  P.i; rjz; /
D
X
k
u;kk;iP.rjϵi;k/;
where we exploit the responsibility u;k representing the posterior probability of observing the
factor k given user u and the observations X.
As of now, we associated a latent variable to a user. Intuitively, this allows us to group users
in clusters of individuals with similar preferences, expressed by either similar ratings or similar
selections. It is also possible to model the opposite situation, where a latent variable allows us to
group items that received similar preferences. However, latent variables can be used to model more
complex situations, where both a user and an item can be associated with the same latent variable,
and all the components of an observation can be thought of as the result of a stochastic process.

38
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
e aspect model (AM, [86]) focuses on implicit preferences and explains both components of an
observation hu; ii in terms of a latent variable:
P.u; ij/ D
X
z
P.zjπ/  P.ujz; θ/  P.ijz; ϕ/:
Here, P.ujz; ϕ/ and P.ijz; ϕ/ are class-conditional multinomial distributions parameterized by
θz and ϕz, respectively. In practice, we assume that both a user u and an item i can be selected
to participate in the stochastic event. e underlying generative process, graphically depicted in
Figure 2.4(a), can be hence devised as follows.
• For each rating observation n:
– Pick a latent factor z  Disc.π/;
select a user u  Disc.θz/;
select an item i  Disc.ijϕz/.
e data likelihood can be accordingly expressed as
P.X j/ D
Y
hu;ii
P.u; ij/ D
Y
hu;ii
X
z
P.zjπ/  P.ujz; θ/  P.ijz; ϕ/:
By applying the EM framework, the complete data expectation log-likelihood can be expressed
as
Q.; 0/ D
X
hu;ii
X
k
u;i;k.0/
˚log k C log u;k C log i;k
	
;
which ﬁnally results in the update equations
u;i;k D
k  u;k  i;k
PK
j D1 j  u;j  i;j
;
u;k D
P
iWru
i >0 u;i;k
P
u0;iWru0
i >0 u0;i;k
;
i;k D
P
uWru
i >0 u;i;k
P
u;i0Wru
i0>0 u;i0;k
:
e adaptation of the aspect model to incorporate rating information is trivial and it can
be done in two diﬀerent ways: either by assuming that the rating is independent from the item,
P.u; i; rj/ D
X
z
P.zjπ/  P.ujz; θ/  P.ijz; ϕ/  P.rjz; ϵ/;
or vice versa, by correlating these two variables:
P.u; i; rj; π/ D
X
z
P.zjπ/  P.ujz; θ/  P.ijz; ϕ/  P.rji; z; ϵ/:
e corresponding graphical models are shown in ﬁgures 2.4(b) and 2.4(c).

2.2. MIXTURE MEMBERSHIP MODELS
39
.z.
u
.
i
.

.

.

.
K
.
K
.
n
.
(a) Implicit feedback
.z.
u
.
i
.
r
.

.

.

.

.
K
.
K
.
K
.
n
.
(b) Explicit feedback (generic ratings)
.z.
u
.
i
.
r
.

.

.

.

.
K
.
K
.
K  N
.
n
.
(c) Explicit preferences (item-based ratings)
Figure 2.4: Aspect model.
Unlike the clustering model shown in the previous section, where the joint probability for
a set of ratings by an individual user is modeled directly, the aspect model concentrates on the
joint probability P.u; i; r/ separately for each rated item. As a result, diﬀerent latent factors can be
exploited to explain the triplet hu; i; ri, whereas, the previous mixture models, all the observations
for a given user are generated by the same chosen latent factor. However, the aspect model only
introduces a single set of latent variables for items, users, and ratings. is essentially encodes the

40
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
clustering of users, items, and the correlation between them. A step further in this direction is to
try to provide multiple latent factors modeling each dimension separately.
2.2.2
MODEL-BASED CO-CLUSTERING
e approaches introduced so far focus on factorizing one single dimension of the preference
data matrix by identifying groups of similar-minded users or categories of similar products. Co-
clustering techniques aim at detecting homogenous blocks within the rating matrix, thus enforc-
ing a simultaneous clustering on both its dimensions. is highlights the mutual relationships
between users and items: similar users are detected by taking into account their ratings on sim-
ilar items, which in turn are identiﬁed by the ratings assigned by similar users. Capturing both
user and item similarities through latent variables provides more expressiveness and ﬂexibility.
Figure 2.5 shows a toy example of preference data co-clustered into blocks. In this example, the
coclustering induces a natural ordering among rows and columns, thus devising blocks in the
preference matrix with similar ratings. e discovery of such a structure is likely to induce in-
formation about the population and improve the personalized recommendations. Besides their
u1
i1
i2
i3
i4
i5
i6
i7
i8
i9
i10
u2
u3
u4
u5
u6
u7
u8
u9
u10
2
4
4
4
2
3
3
3
3
3
2
4
4
5
2
2
2
2
2
2
2
2
2
3
3
4
4
4
4
4
4
4
4
4
4
4
4
4
3
3
3
1
1
3
3
3
4
5
5
5
5
5
5
5
5
1
1
1
2
2
1
1
1
1
2
2
3
3
4
4
4
4
4
1
1
1
1
1
1
4
2
1
1
1
4
4
4
2
3
3
4
5
5
5
5
5
5
5
5
3
4
4
4
3
3
2
4
4
4
4
4
4
4
4
3
3
3
4
3
3
3
2
2
3
3
3
2
2
2
2
2
2
2
2
3
4
3
u1
i2
i3
i4
i1
i5
i7
i10
i6
i8
i9
u3
u5
u2
u4
u9
u6
u7
u8
u10
Users
Items
W1={i2,i3,i4}     W2={i1,i5,i7,i10}     W3={i6,i8,i9}
Z1={u1,u3,u5}     
Z2={u2,u4,u9}     
Z3={u6,u7,u8,u10,}     
}     
}     
}     
}     
}     
}     
Figure 2.5: Example co-clustering for preference data.
contribution to the minimization of the prediction error, these relationships are especially impor-
tant, as they can provide a faithful yet compact description of the data, which can be exploited
for better decision making.
Co-clustering approaches to latent-factor modeling for two-dimensional data have been
proposed in the literature, both from a matrix factorization perspective [63] and from a proba-
bilistic perspective [70]. Here we review the original mixture model formulation, introduced in the

2.2. MIXTURE MEMBERSHIP MODELS
41
beginning of the section, to model each preference observation as the result of a two-dimensional
stochastic process governed by latent variables.
In particular, we can focus on the aspect model and consider a simple extension (called two-
sided clustering model in [86]), which is based on the strong assumption that each person belongs
to exactly one user-community and each item belong to one group of items. e rating value is
independent of the user and item identities are given their respective cluster memberships. e
Flexible Mixture Model (FMM) [98] represents a full probabilistic reﬁnement of the above model
and can be summarized as follows. Let z and w denote latent variables ranging within the values
f1; : : : ; Kg and f1; : : : ; Hg, representing latent factors respectively for users and items. e joint
likelihood of an observation hu; i; ri can be formulated as
P.u; i; rj/ D
X
z
X
w
P.zjπ/  P.wjψ/  P.ujz; θ/  P.ijw; ϕ/  P.rjz; w; ϵ/:
e corresponding graphical model is shown in Figure 2.6(a). Here, the components π and ψ
represent the multinomial probabilities relative to the latent variables z and w. Also, θz and ϕw
encode the probabilities of observing users and items, respectively, given the respective latent
variables, and ﬁnally, ϵz:w encodes the probability of observing ratings given z and w.
.z.
w
.
u
.
i
.
r
.

.
 
.

.

.

.
n
.
K
.
L
.
K  L
.
(a) Flexible mixture model
.r.
z
.
w
.

.

.
 
.
N
.
K  L
.
M
.
(b) Block mixture model
Figure 2.6: Graphical models for co-clustering.

42
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
FMM is a specialization of a more general formulation
P.u; i; rj/ D
X
z
X
w
P.r; u; ijz; w; /  P.z; wj/;
where the conditional independence assumptions P.r; u; ijz; w; / D P.rjz; w; /  P.ujz; / 
P.ijw; / and P.z; wj/ D P.zj/  P.wj/ are exploited to simplify the expression and to
devise an EM strategy for learning the parameters.
is general formulation can also be adapted to forced prediction:
P.rju; i; / D
X
z
X
w
P.rjz; w; /  P.z; wju; i; /:
(2.8)
Within this formula, the term P.z; wju; i; / represents the posterior probability of the latent
factors, given user u and item i. Equation 2.8 resembles the mixture equation of the single dimen-
sional case, and an EM inference strategy can be devised as well. We adapt the results in [69, 70]
to illustrate this. We assume further that preferences are expressed in a continuous domain, i.e.,
a preference value is the result of a Gaussian stochastic process. e adaptation to the Bernoulli
or multinomial case is straightforward and we discuss it next.
A block mixture model (BMM) can be deﬁned by two latent matrices .Z; W / relative to
preference data, having the following characterizations:
• Z 2 f0; 1gMK and zu;k D 1 if u belongs to the cluster k, zero otherwise;
• W 2 f0; 1gNL and wi;l D 1 if the item i belongs to the cluster l, zero otherwise.
Given a rating matrix R, the latent variables zu;k and wi;l determine the block .k; l/ upon which
to interpret the rating ru
i associated with the pair. e underlying generative model is graphically
represented in Figure 2.6(b) and can be described as follows.
1. For each u generate zu  Disc.π/.
2. For each i generate wi  Disc.ψ/.
3. For each pair hu; ii:
• Detect k and l such that zu;k D 1 and wi;l D 1;
• Generate r  P.rjϵk;l/.
Notice that, in the above model, we assume that latent factors for items and users are in-
dependent. e corresponding data likelihood can be modeled as:
P.X ; Z; W j/ D
Y
u2U
Y
k

zu;k
k
Y
i2I
Y
l
 
wi;l
l
Y
hu;i;ri
Y
k;l
P.rjϵk;l/zu;kwi;l:

2.2. MIXTURE MEMBERSHIP MODELS
43
e estimation of the optimal parameters through a standard EM procedure is diﬃcult here, be-
cause it requires inferring P.Z; W jX ; / and, in particular, the term P.zu;kwi;l D 1ju; i; r; /
relative to an observation hu; i; ri in X. A solution is provided in [69], in terms of variational
approximation. e key idea is to approximate an intractable distribution P.jX / with a sim-
ple, but tractable, distribution Q.jX / and then to minimize their Kullback-Leibler divergence
KL.Q; P / (for a general introduction to variational inference see Appendix A.2). In this case,
we devise a generalized EM procedure by introducing a mathematically tractable approximation
q.Z; W / to the posterior P.Z; W jX ; /. By exploiting the factorization
q.Z; W / D P.ZjX ; /P.W jX ; /;
and using the notation cu;k , P.zu;k D 1ju; 0/, di;l , P.wi;l D 1ji; 0/, we can redeﬁne the
complete-data expectation log-likelihood Q.; 0/ as follows:
Q.; 0/ D
K
X
kD1
X
u
cu;k log k C
L
X
lD1
X
i
di;l log  l C
X
hu;i;ri
X
k
X
l
˚
cu;k  di;l log P.rjϵk;l/
	
:
e terms cu;k and di;l represent the standard responsibilities computed on a single dimension
(users for cu;k and columns for di;l).⁵ For the M step, instead of directly optimizing Q.; 0/, it
is convenient to look for a generic improvement O such that Q. O; 0/  Q.; 0/. is can be
done by decomposing Q.; 0/, by alternatively assuming that the pairs .c; / (resp. .d;  /) are
ﬁxed, and by optimizing the remaining parameters through a standard M step.
e core of the approach is the possibility of refactoring Q.; 0/ by exploiting suﬃcient
statistics for the computation of P.rjϵk;l/. As stated above, we assume a Gaussian distribution
for the ratings, so that ϵk;l , fl
k; l
kg, and P.rjϵk;l/ , N .rI l
k; l
k/. We can notice [18] that
the joint probability of a generic normal population fx1; : : : ; xng can be factored as:
n
Y
iD1
N .xiI ; / D h.x1; : : : ; xn/  '.u0; u1; u2I ; /;
where
h.x1; : : : ; xn/ D .2/ n=2;
'.u0; u1; u2I ; / D  u0  exp
2  u1     u2   u0  2
2  2

and u0 D n, u1 D P
i xi and u2 D P
i x2
i are the suﬃcient statistics. Based on the above obser-
vation, we can decompose Q.; 0/ as
Q.; 0/ D Q.; 0jd/ C
X
i2I
L
X
lD1
di;l log  l  X
u2U
X
i2I.u/
di;l
2 log.2/;
⁵ese terms can be determined by solving the corresponding equations adapted from Equation A.9. As described in Ap-
pendix A.2, this variational principle is equivalent to minimizing the KL-divergence between the approximation and the true
posterior distributions.

44
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
where
Q.; 0jd/ D
M
X
uD1
K
X
kD1
cuk
(
log.k/ C
L
X
lD1
log

'.u.u;l/
0
; u.u;l/
1
; u.u;l/
2
I l
k; l
k/
)
and
u.u;l/
0
D
X
i2I.u/
dilI
u.u;l/
1
D
X
i2I.u/
dilru
i I
u.u;l/
2
D
X
i2I.u/
dil.ru
i /2:
Analogously,
Q.; 0/
D
Q.; 0jc/ C
X
u2U
K
X
kD1
cu;k  log k  X
i2I
X
u2U.i/
cu;k
2 log.2/;
where
Q.; 0jc/ D
N
X
iD1
L
X
lD1
di;l 
(
log. l/ C
K
X
kD1
log

'.u.i;k/
0
; u.i;k/
1
; u.i;k/
2
I l
k; l
k/
)
and
u.i;k/
0
D
X
u2I.u/
cu;kI
u.i;k/
1
D
X
u2I.u/
cu;k  ru
i I
u.i;k/
2
D
X
u2I.u/
cu;k  .ru
i /2:
us, by assuming  and d constant, and optimizing Q.; 0/ with respect to the remaining
parameters, still guarantee a new value O such that Q. O; 0/  Q.0; 0/. Dually, assume  and
c are ﬁxed and obtain an improvement on the expectation-likelihood by updating the remaining
parameters.
e overall procedure can be summarized as follows.
• Start with initial values of c.0/; d.0/ and .0/.
• Iterate until convergence:
– Compute .c.tC1/; .tC1/; .t0// by optimizing Q.; .t/jd.t//;
– Compute .d.tC1/;  .tC1/; .tC1// by optimizing Q.; .t0/jc.tC1//.
e optimization steps are straightforward, and they are omitted here. e interested reader can
ﬁnd the details in [18].
Although the above model only focuses on Gaussian modeling, it can be generalized to
other probability distributions that can be expressed in terms of suﬃcient statistics. In particular,
Agarwal et al. [4] adapt the above model to a framework of generalized linear models, which
include commonly used regression models such as linear, logistic, and Poisson regression as special
cases.

2.3. PROBABILISTIC LATENT SEMANTIC MODELS
45
2.3
PROBABILISTIC LATENT SEMANTIC MODELS
Probabilistic topic models [32, 34, 188] include a suite of techniques widely used in text analysis:
they provide a low-dimensional representation of the given data, which allows the discovering
of semantic relationships. Given a collection, said corpus of macro entities to be modeled (textual
documents or users’ purchase logs), topic models are based upon the idea that each entity exhibits
a mixtures of topics, where a topic is a probability distribution over a ﬁnite set of elements (e.g.,
tokens or items). e underlying generative process assumes that, to generate an entity, we ﬁrst
sample a distribution over topics. Each single data observation, generally referred to as token,
can be generated by sampling a topic from the speciﬁc distribution and then emitting a token
by drawing upon the topic distribution. Bayesian inference techniques, discussed next, are used
to infer a set of topics from a collection of observations, by “reversing” the generative model and
hence determining the distributions that are more likely to generate the observed data.
User preferences on topics
Topics
Purchase-history
Die-Hard
Braveheart
history
thriller
action
Sci-fi
love
The 
matrix
Star
Wars
The lord of
the rings
Gladiator
JFK
The
Silence of
the Lambs
Figure 2.7: Latent class model for CF—generative process.
e adaptation of topic modeling to CF is quite natural. For example, Figure 2.7 illustrates
the interpretation of CF data in terms of topic modeling. Here, colors represent topics and the
histogram represents their distribution relative to a speciﬁc user. Although no prior conceptual

46
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
meaning can be associated to topics, in the case of CF data it is natural to assume that they cor-
respond to users’ interests. A proper deﬁnition of topics might be obtained by considering them
as “abstract preference pattern:” users, or items, participate in each preference pattern with a cer-
tain degree of involvement, and these membership weights project each user/item into the latent
factor space. We assume that there are a ﬁxed number of topics, and each user is characterized by
her own preference on genres. For example, in Figure 2.7, the considered user shows a particular
interest in action and historical movies, while her interest in romance is low. Each genre speciﬁes
the probability of observing each single item. Movies like “Independence Day” and “Die hard”
will have a higher probability of being observed given the “action” topic, than in the context of
“romance.” Given a user and her preferences on topics (which deﬁnes preferences on movies),
the corresponding purchasing history can be generated by choosing a topic and then drawing an
item from the corresponding distribution over items. In the example, the ﬁrst topic to be cho-
sen is “action,” which generates the movie “Die Hard;” the process of topic and item selection is
iteratively repeated to generate the complete purchase history of the current user.
We shall explore the exploitation of topic models to preference data in two respects. A ﬁrst
approach draws from the aspect model proposed before and focuses on an alternate, probabilistic
interpretation of Latent Semantic Indexing (LSI) in terms of topic modeling. is approach is
named Probabilistic Latent Semantic Analysis/Indexing (pLSA/pLSI). e intuition behind LSI is
to ﬁnd the latent structure of “topics” or “concepts” in a text corpus, which captures the meaning
of the text that is imagined to be obscured by “choice” noise. Applied to preference data, these
concepts can suitably model preference choice in terms of complex latent factor elements.
A generalization of the pLSA approach is the Latent Dirichlet allocation (LDA), introduced
by Blei et al. [34] and discussed in the next chapter. LDA overcomes the over-specialization
of pLSA (the topic mixture component is known only for those users u in the training set) by
providing a full generative semantic. e relationship between these two approaches is strong,
as it was shown that pLSA is a maximum a posteriori estimated LDA model under a uniform
Dirichlet prior [65].
e intuition behind PLSA is to reinterpret the probability of a preference P.rju; i/ in
terms of a mixture components, where each component encodes a speciﬁc parametric model. An
alternative view is to still model P.rju; i/ as a speciﬁc parametric distribution. However, it is
the parameters of this distribution that can be inﬂuenced by latent factors, so that the semantic
decoupling of the preference is focused on the parameter setting rather then on the probability
components. is is a second approach known in the literature as probabilistic matrix factorization,
which will be detailed in Section 2.3.2.
2.3.1
PROBABILISTIC LATENT SEMANTIC ANALYSIS
pLSA [81, 83] speciﬁes a co-occurrence data model in which the user u and item i are condi-
tionally independent, given the state of the latent factor z. In contrast to standard latent semantic
analysis based on SVD decomposition, pLSA deﬁnes a proper generative data model, which has

2.3. PROBABILISTIC LATENT SEMANTIC MODELS
47
several advantages. Statistical inference techniques, like likelihood maximization, can be easily
used to learn the model, to minimize directly the accuracy of predictions over a test set (as we
shall discuss in Chapter 4). Secondly, the probabilistic framework allows us to employ model se-
lection techniques to control the complexity and the ﬁtting of the model, and ﬁnally, experimental
results show that pLSI achieves substantial performance gains over LSA [81].
.i.
z
.

.

.
N
.
M
.
K
.
Figure 2.8: Probabilistic latent semantic analysis.
Figure 2.8 details the instantiation of pLSA to implicit preferences. Here, θ is a prior
distribution of topics associated to each user. For a given user u, a multinomial distribution θu
is deﬁned over the latent space of topics. Furthermore, each item is chosen from a multinomial
distribution ϕk, relative to the current topic k and ranging over all possible items.
It is important not to confuse the pLSA model with probabilistic clustering models. In
these models, a single latent factor is associated with each user. By contrast, the pLSA model
associates a latent variable with each observation triplet hu; i; ri. Hence, diﬀerent observations
for the same user can be explained by diﬀerent latent causes in pLSA, whereas a user cluster-
ing model assumes that all ratings involving the same user are linked to the same underlying
community/cluster. is is better illustrated by the underlying generative process:
• For each user u:
– Sample the number nu of item selections;
– For each selection s 2 f1; : : : ; nug:
1. Select a user proﬁle z  Disc.θu/;
2. Pick an item i  Disc.ϕz/.
pLSA shares many similarities with the aspect model discussed in the previous section.
Both models associate latent factors to single observations, rather than to users. Also, the proba-
bility of observing an adoption is governed in both models by a distribution over all the possible
items. However, the aspect model fucuses on free prediction and aims at directly modeling the
joint probability P.u; i/, whereas pLSA considers the probability P.iju/, which is modeled as a

48
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
mixture
P.iju/ D
X
k
k;uk;i:
Given a set X of observations, the likelihood can be speciﬁed by assuming a latent matrix Z,
where e generic entry zm 2 f1; : : : ; Kg is relative to the observation m D hu; ii and represents the
latent factor underlying such an observation. e joint likelihood can be expressed hence as
P.X ; Zj/ D P.X jZ; /P.Zj/;
where
P.X jZ; / D
Y
hu;ii
zu;i;i;
and
P.Zj/ D
Y
hu;ii
u;zu;i :
As usual, the likelihood can be obtained by marginalizing over all possible Z:
L.I X / D
X
Z
P.X ; Zj/ D
Y
hu;ii
X
k
u;k  k;i:
(2.9)
Again, the standard EM framework can be exploited to ﬁnd the optimal .
e adaptation of the model to explicit preferences can be modeled as well, in a way similar
to the AM discussed above. For example, we can adopt a multinomial distribution ϵk;i [82], such
that
P.rju; i/ D
K
X
kD1
i;k;r  u;k:
(2.10)
Alternatively, the Gaussian PLSA (G-PLSA) [84]) models k;i D .i;k; i;k/ as a Gaussian dis-
tribution. e corresponding rating probability is
P.rju; i/ D
K
X
kD1
N .rI i;k; i;k/  u;k:
(2.11)
It is well known that statistical models involving huge numbers of parameters are prone to
overﬁtting. pLSA represents one such model and, hence, it is not immune to this issue. Tradi-
tional model selection techniques can be employed to mitigate such a drawback, by ﬁtting models
by maximum likelihood and then determining the generalization performance of the model either
analytically, by directly exploiting MAP in place of maximum likelihood, or via empirical evalu-
ation using hold-out data or cross-validation. A more rigorous framework is oﬀered by Bayesian
learning and will be discussed in the next chapter.

2.3. PROBABILISTIC LATENT SEMANTIC MODELS
49
2.3.2
PROBABILISTIC MATRIX FACTORIZATION
We have seen that the basic intuition behind pLSA is to reinterpret the probability of a pref-
erence P.rju; i/ in terms of a mixture of components P.rju; i/ D P
z P.rji; z/P.zju/. Here,
z represents a latent factor and the mixture reinterprets the matrix approximation discussed in
Section 1.4.2, in probabilistic terms.
An alternative approach consists instead of “moving” the matrix approximation to the
parameter set. at is, we can still model P.rju; i/ as a speciﬁc parametric distribution
P.rju; i; u;i/. However, the parameter set u;i, in this case, can depend on some latent factors,
which hence inﬂuence the parametric distribution directly. Consider again the two alternatives.
For the continuous case, we can assume a Gaussian distribution,
P.rju; i/ D N .rI u;i; /;
where, for simplicity, we assume a single observation-speciﬁc parameter u;i. For the discrete
multinomial case, we can assume the multinomial probability fpu;i;vgv2V such that
P.rju; i/ D pu;i;r:
Let us focus on the continuos case for the moment. We can make explicit a dependency of the
parameter u;i from two continuous latent factors Pu; Qi 2 RK, so that u;i , P T
u Qi. is ap-
proach is called Probabilistic Matrix Factorization (PMF) and was introduced in [169]. Given
the latent user and item feature vectors Pu; Qi, the preference value is generated by assuming a
Gaussian distribution over rating values conditioned on the interactions between the user and the
considered item in the latent space, as shown below:
.r.

.
P
.
Q
.
M  N
.
M
.
N
.
To summarize, the continuous case P.rju; i/ is modeled as a Gaussian distribution, with mean
P T
u Qi and ﬁxed variance :
P.rju; i; P; Q/ D N .rI P T
u Qi; /:
(2.12)
Similarly, in the discrete case we can assume that the parameter pu;i;r depends on some latent fac-
tors Pr;u; Qr;i 2 RK, i.e., pu;i;r / P T
r;uQr;i. is yields to PMF reformulation of the probability

50
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
of a rating as
P.rju; i; P; Q/ D
exp
˚
P T
r;uQr;i
	
P
v2V exp
˚
P T
v;uQv;i
	:
(2.13)
ere is an interesting parallel between PMF and the predictive models shown in Sec-
tion 2.1. If we consider the equations 2.2 and 2.3 under a more general perspective, we can refor-
mulate them as depending on a functional 	.u; i; rI /, which can be embedded either into the
Gaussian or the logistic probability. For example, we can reformulate Equation 2.2 as
P.rju; i; / D
1
p
2
exp

  1
22 .r   	.u; i; rI //2

:
(2.14)
Under this perspective, PMF is just a diﬀerent instantiation of the functional 	.u; i; rI /. In-
deed, in Equation 2.2 we instantiated it as 	.u; i; rI / , P
j ˇj fj .u; i; r/, but, if we replace
this instantiation with 	.u; i; rI / , P T
u Qi, we can then observe that equations 2.14 and 2.12
are equivalent. e same parallel holds for the discrete case.
In the PMF formulation, the likelihood can be expressed as
P.X jP; Q; / D
Y
hu;i;ri
P.rju; i; P; Q/:
e estimation of the P and Q parameters via MLE can be accomplished again by resorting to
iterative methods, as discussed in Section 2.1. If we consider the log-likelihood of the Gaussian
case,
log P.X jP; Q; / D   1
2
X
hu;i;ri
.r   P T
u Qi/2   n log    n
2 log 2;
we can observe the equivalence between optimizing the latter and Equation 1.22. at is, the
Gaussian PMF provides a probabilistic interpretation of the matrix factorization discussed in
Chapter 1, which is based on minimizing the sum-of-squared-errors objective function with
quadratic regularization terms.
Diﬀerent extensions of the basic framework have been proposed: a constrained version
[169] of the PMF model is based on the assumption that users who have rated similar sets of
items are likely to exhibit similar preferences. Furthermore, Bayesian generalizations [168] and
extensions with side information [1, 180, 209] are characterized by a higher prediction accuracy.
We shall analyze them in the following chapter. Also, in Chapter 6 we shall review and further
extend the models proposed here to include side information.
2.4
SUMMARY
Within this chapter we investigated the diﬀerent approaches to model preference data in a prob-
abilistic setting. We started our treatment by distinguishing between forced prediction (aimed

2.4. SUMMARY
51
at modeling the probability P.rju; i/ and free prediction (aimed at modeling either P.r; iju/
or P.u; i; r/). e diﬀerence between these modeling choices resembles the diﬀerence between
discriminative and generative modeling. In general, discriminative modeling aims at focusing on
prediction accuracy. By converse, generative modeling is more general: a free prediction model
naturally induces a forced prediction model as well, as P.rju; i/ D P.r; iju/= P
i2I P r.r; i; u/.
us, the informative content of a generative model is richer, although at the price of a higher
computational learning cost and a lower accuracy in predicting the rating. us, a ﬁrst dimension
upon which to consider the modeling is either free or forced prediction, and diﬀerent choices
produce diﬀerent models.
Another prominent role is played by latent factor modeling. e underlying idea of latent
factor modeling is to reinterpret the data into a low-dimensional representation, which allows the
discovering of semantic relationships. is enables the detection of similarities among users and/or
items and, in general, allows the identiﬁcation of a ﬁxed number of more general preference
patterns. Again, latent factors can be exploited in two respects. Either in a “discrete” fashion, by
assuming that a latent factor represents a discrete state and a single preference can be observed in
any of these states; or, alternatively, in a continuous domain, as the result of a process that directly
aﬀects the parameters of the underlying data distribution.
e following table summarizes the approaches presented in this chapter under these two
dimensions.
Table 2.1: Summary
MMM
UCM
AM
BMM
FMM
pLSA
G-PLSA
PMF
P
Free
X
X
X
Forced
X
X
X
X
X
FD
User-based
X
X
X
X
X
X
Item-based
X
Joint
X
X
F
Discrete
X
X
X
X
X
X
X
Continuous
X
F
Hard
X
X
X
Soft
X
X
X
X
X
P
Implicit feedback
X
X
Explicit (Multinomial)
X
X
X
X
Explicit (Gaussian)
X
X
X
X
X
X
Within this table, we can see that several aspects characterize each dimension: for example, latent
topics can group users, items, or both dimensions. Also, the modeling of the explicit rating can
be either continuous or discrete. Again, some models naturally ﬁt in either the ﬁrst, the second,
or both of the modeling alternatives. As we will see in Chapter 4, probabilistic models that are
based on the estimate of Gaussian distributions over rating values outperform signiﬁcantly, in a
rating prediction scenario, approaches in which the generative distribution is multinomial.
A ﬁnal dimension to consider is the scope of the latent factor modeling. We have seen that
simple models associate a latent variable to a user; as a consequence, all preferences associated to
that user can be explained in terms of that latent variable. is is what we name a hard choice in

52
2. PROBABILISTIC MODELS FOR COLLABORATIVE FILTERING
the table. However, a diﬀerent alternative is to consider the inﬂuence of latent factors at the level
of a single preference, and all the components of an observation can be thought of as the result
of a stochastic process inﬂuenced by the latent factors. is is the soft scope.
e maximum likelihood estimation procedures corresponding to these models are easy to
implement. However, the two main drawbacks of the approaches described in this chapter are
the tendency to overﬁt and the sensitivity to the initial conditions in the learning procedure. For
the latter, two common practices are to perform several runs corresponding to diﬀerent random
initial conﬁgurations of parameters, or to determine a “good” initial setting of parameters. For the
former, it is common to observe that the ﬁtting procedures, which notably are guaranteed to per-
form iterative updates on the parameters of the considered model that increase the log likelihood
on training data, tend to deteriorate the performances on unseen data for increasing numbers
of iterations. Early stopping criteria, as well as model selection strategies, can be employed to
mitigate such phenomena from a practical point of view. A more rigorous framework is instead
oﬀered by a Bayesian treatment and will be discussed in the next chapter.

C H A P T E R
3
Bayesian Modeling
e methods introduced in the previous chapter rely on maximum likelihood estimation and make
no assumption on the likelihood of .at is, all  are equally probable and, thus, the optimal
parameter set is uniquely identiﬁed by the observed data. An alternative approach assumes that we
can incorporate prior knowledge about the domain of . Prior knowledge can be combined with
observed data to determine the ﬁnal optimal parameter set O. Rather than optimizing the likeli-
hood, we concentrate on the probability P.jX / and seek the set of parameters that maximizes
it. By exploiting Bayes’ theorem, the likelihood can be expressed as
P.jX / D
P.X j/P./
Z
P.X j/P./d
:
(3.1)
Since the optimal value only depends on the numerator, we can reformulate the solution of the
estimation problem as a maximum a posteriori probability (MAP) estimate:
OMAP D argmax

P.jX / D argmax

P.X j/P./;
the MAP estimate allows us to inject into the estimation calculation our prior beliefs regarding
the parameter values in . e integration of P./ realizes a Bayesian approach to data mod-
eling, where we can state beliefs on how “realistic” are some parameters with respect to others.
Bayesian modeling is particularly useful when observations X do not provide suﬃcient evidence:
in these cases, the estimate is driven by the prior component. Finally, given OMAP, we can solve
the prediction problem as:
P. QxjX /  P. Qxj OMAP/:
Let us consider again the simple example discussed at the beginning of Chapter 2. Recall
that observations X represent observations that can be obtained from the preference matrix R, and
a Bernoulli distribution governing the presence/absence of preference, parameterized by  , .
Within MAP estimation, we can instantiate P./ by using the Beta distribution P.ja; b/ D
B.a; b/ 1a.1   /b; which is the conjugate prior of the Bernoulli distribution [31, 62, Chapter
2]. A prior P./ and a posterior distribution P.jX / are conjugate distributions if they belong
to the same family; in this case the prior is said to be a conjugate prior for the likelihood function
P.X j/. e advantage in using conjugate priors relies on algebraic convenience, as the posterior
can be expressed in closed form. For instance, in our example, where the likelihood is modeled as

54
3. BAYESIAN MODELING
a Bernullian distribution and the prior as Beta, the posterior easily can be rewritten as
P.jX / D B.n C a; M  N   n C b/ 1nCa.1   /MN nCb;
which yields
OMAP D
n C a
M  N C a C b :
Here, B.a; b/ represents the Beta function. e Bayesian inference in the case of explicit prefer-
ence can be obtained in a similar way, by properly choosing the prior P./: e.g., by adopting a
normal prior in case of Gaussian likelihood, or a Dirichlet prior when the generative distribution
is multinomial [58].
ere is an immediate relationship between MAP and ML estimations, stated by Bayes’s
theorem:
posterior / likelihood  prior:
In both cases, the likelihood component plays a crucial role but the way in which it is used is
fundamentally diﬀerent in the two approaches. In a ML setting, the parameter set is considered
ﬁxed and the variability in the estimation can be evaluated by considering the distribution of
all possible observations, of which X represents a (possibly biased) sample. By contrast, from
a Bayesian perspective, the observations X are ﬁxed, and the uncertainty in the parameters is
expressed through a probability distribution over the parameter set . e advantage is that, by
incorporating the prior, we can mitigate the eﬀects of bias within X, typically due to sparsity
issues associated with the sample under consideration.
In this chapter, we review the modeling paradigms proposed in the previous chapter under
a Bayesian perspective. A ﬁrst advantage of a Bayesian modeling is that it allows a smoothing
of the estimation procedure. For example, it allows us to identify the eﬀective number of latent
factors, as well as deal with the sparsity of the preference matrix. In a sense, we are regularizing the
parameter set by constraining the optimal values in a speciﬁc range. Put in other terms, including
the prior in the estimation allows us a better control of the overﬁtting issues, thus resulting in
models with better generalization capabilities.
However, there’s more in Bayesian modeling than just regularization. Bayesian inference
extends the MAP approach by allowing a distribution over the parameter set , instead of mak-
ing a direct estimate. us, it is more informative: it still encodes the maximum (a posteriori)
value of the data-generated parameters, but it also incorporates expectation as another parameter
estimate. is enables the possibility to approach the prediction problem by more reliable infer-
ence approximations. A MAP estimator is popular in Bayesian analysis, in part, because it is often
computationally less demanding than computing the posterior mean or the median. e reason is
simple; to ﬁnd the maximum, the posterior need not to be fully speciﬁed. However, the posterior
is the ultimate experimental summary in a Bayesian perspective.

3.1. BAYESIAN REGULARIZATION AND MODEL SELECTION
55
3.1
BAYESIAN REGULARIZATION AND MODEL
SELECTION
A problem with maximum likelihood is the susceptibility to overﬁtting, especially when the data
at hand is sparse. Overﬁtting can be roughly deﬁned as an exceptionally good capability of a
model of describing the observations in X and, by the converse, poor predictive capability on
unseen samples Qx. e complexity of  could enforce overﬁtting. Complex parameter sets ex-
hibit larger degrees of freedom and, especially when the observations are sparse, this may lead to
poor estimations. For a given set of observations X, we can consider the “true” probability P.X /
independent of the parameter, i.e.
P.X / D
Z
P.X j/P./ d:
e “optimal” parameter set is the one that best approximates the integral on the right-hand
side. ML estimation provides an approximation by only looking at the likelihood P.X j/ and it
ignores the P./ component. By the converse, MAP estimation does a better job by also consid-
ering the smoothing eﬀect of the prior. is smoothing eﬀect also plays the role of regularizing
the choice of the optimal parameters, by binding them to reliable values.
Consider again the log-linear model discussed in Section 2.1. When the feature set F con-
tains an extremely huge number of features, then the number of parameters ˇr;k can be extremely
high. Combined with the sparsity of the feature matrix, this eﬀect is likely to produce situations
where the learned parameters are more sensitive to noise in the data. is may result in a poor
predictive capability of the resulting model. Prior probabilities can help in this setting, since they
allow us to encode a prior belief about the suitable values, and hence constrain the search space
in the parameter estimation phase. In particular, a huge feature space F can be characterized by
redundant and irrelevant features, and the learning phase should instead focus on the selection
of the smallest subset of such features that eﬀectively discriminate in the prediction process. is
can be achieved by modeling the fact that each weight ˇr;k should be close to zero, unless there
is strong evidence in the observation about its discriminative abilities. We can encode such an
intuition within a Gaussian prior with 0 mean and ﬁxed precision,
P.ˇr;k/  N .0; /;
thus obtaining the log posterior
log P.jX / / LL.jX /  1
22
X
r2V
q
X
kD1
ˇ2
r;k:
Here, the term  1=22 P
r;k ˇ2
r;k acts as a regularization term which penalizes the likelihood
when the components ˇr;k approach extreme values. Hence, optimizing this objective function
yields smooth values for the parameters, which are less prone to overﬁtting.

56
3. BAYESIAN MODELING
A similar regularization can be devised for the PMF models discussed in Section 2.3.2.
Consider again the likelihood
P.X jP; Q; / D
Y
hu;i;ri
P.rju; i; P; Q/:
Optimizing the above likelihood with respect to the matrices P and Q can readily lead to over-
ﬁtting. To avoid this, we can place zero-mean spherical Gaussian priors on user and item feature
vectors
P.PjU / D
M
Y
uD1
N .PuI 0; 2
U I/;
P.QjI/ D
N
Y
iD1
N .QiI 0; 2
I I/:
Combining the likelihood with the priors and taking the logarithm yields the log posterior:
log P.P; QjX ; ; U ; I/ D   1
2
X
hu;i;ri
.r   P T
u Qi/2
 1
2U
X
u
P T
u Pu  1
2I
X
u
QT
i Qi
  n log 2   MK log 2
U   NK log 2
I C C;
where C is a constant that does not depend on the parameters. By denoting U D 2=2
U and
I D 2=2
I , we can rewrite the negative log-posterior as:
E.P; Q/ D1
2
X
hu;i;ri
.r   P T
u Qi/2 C 1
2U
X
u
P T
u Pu C 1
2I
X
u
QT
i Qi;
thus obtaining an error function that resembles the one corresponding to the standard matrix
factorization approach introduced in Equation 1.24 of Chapter 1. An optimization based on the
gradient-descent of the above error function yields exactly the update Equations 1.25.
As part of the Bayesian framework, prior distributions describe the prior beliefs about the
properties of the function being modeled. ese beliefs are updated after taking into account
observational data by means of a likelihood function that connects the prior beliefs to the obser-
vations. Under this respect, priors can be accommodated to model diﬀerent situations according
to the known facts about data. For example, in the PMF approach, more complex priors can be
devised, by exploiting Gaussian distribution for more general means µU ; µI and covariance ma-
trices ΣU ; ΣI. is allows us to model more complex situations, like, e.g., the ones described
in [197], where regularization can be adapted to speciﬁc user/item cases. We shall discuss this
extension in detail in Section 3.4.
Bayesian regularization can also be exploited for model selection purposes. e Bayesian
view of model selection involves the use of probabilities to represent uncertainty in the choice of

3.1. BAYESIAN REGULARIZATION AND MODEL SELECTION
57
the model. Assume we can devise two alternative models 1 and 2, corresponding to a stochastic
process for which the observed data is given by X. e uncertainty in these models is given by
the prior probability P.i/, according to which the posterior can be written as
P.ijX / / P.X ji/P.i/:
e choice between 1 and 2 can be made by comparing their posteriors. e model of choice
is the one with the larger value of the posterior.
A speciﬁc example where Bayesian modeling supports model selection is given by the choice
of the number of components in latent factor models. Assume that  can be parametrized by K
factors, i.e., there are enumerable possible parameters
˚
.K/	
K0 and .K/ D f.K/
1
; : : : ; .K/
K g.
We also assume that P..K// D QK
kD1 P..K/
k
/. is yields the joint likelihood
log P.X ; .K// D log P.X j.K// C
K
X
kD1
log P..K/
k
/:
e above situation sheds some light on the role of the number of components in a Bayesian
perspective: the posterior depends on the likelihood and on the number of parameters. ese
dependencies can be made explicit by exploiting the improper prior¹ P..K/
k
/ / w ˛ with w
constant. is prior in the above equation can be rewritten by adding a penalization factor that
depends on the number of components and counterbalances the likelihood: as
log P.X ; .K// / log P.X j.K//   ˛K log w:
us, the best model can be devised as the one that provides the best compromise between the
number of components K and the likelihood of the data.
e selection of the optimal number K of components can be plugged even within the
EM framework itself. Consider the simple mixture model, where each user is associated to a
latent variable, and the observation associated to each user then can be explained in terms of the
associated model component. We rewrite the complete-likelihood as
P.X ; Z; / D P.X jZ; /  P.Zj/  P./;
(3.2)
where
P.X jZ; / D
Y
u2U
K
Y
kD1
P.ujk/zu;k
P.Zj/ D
Y
u2V
K
Y
kD1

zu;k
k
;
and P./ represents the prior for the parameter set . Figuereido and Jain [57] provide a general
framework to rewrite the expectation-maximization algorithm in a way that automatically detects
¹Improper priors are measures of uncertainty that do not necessarily represent probability densities [97]. For example, they can
be used to express a preference for structural properties of the parameter under analysis, for which inﬁnitely many values are
equally likely.

58
3. BAYESIAN MODELING
an estimation of the most likely number of parameters. e key aspect is the modeling of the prior
for the multinomial 1; : : : K: we can assume a large number K of components, and accept a
k-th component only if it is supported by a suﬃcient number of observations to justify the “cost”
of k. is can be encoded by penalizing the components on the basis of the complexity of the
associated parameter set k:
P./ /
K
Y
kD1
P.k/
  Nk
2
k
;
where P.k/ is any speciﬁc prior on the parameter set of the k-th factor, the term Q
k 
  Nk
2
k
represents an improper prior over parameters k and, ﬁnally, Nk D jkj. In the standard EM
framework (see Appendix A.1), the complete-data log likelihood can be expressed as
Q.I 0/ D
X
Z
P.ZjX ; 0/ log P.X ; Z; / C log P./
/
X
u2V
K
X
kD1
u;k
˚log P.ujk/ C log k
	
 K
X
kD1
Nk
2 log k C
K
X
kD1
log P.k/:
Here, the term PK
kD1 log P.k/ acts as a regularization term for the model parameters k. Fur-
thermore, the term PK
kD1 Nk log k enables a regularization on the multinomial parameters k:
optimizing Q.I 0/ with respect the latter yields the updated equation
k D
max
˚
0; P
u u;k   Nk=2
	
PK
kD1 max
˚
0; P
u u;k   Nk=2
	:
(3.3)
e eﬀect is that, within the EM algorithm, the estimation of the k parameters is adjusted and
some components can be “annihilated”: whenever a factor is not supported by a suﬃcient number
of observations anymore, it is suppressed.
Since the optimal number of factors can be automatically detected, we can start with an
arbitrary large initial value K, and then infer the ﬁnal number K by looking at the compo-
nents with non-zero priors. is is a general approach, which can be applied to any EM-based
estimation procedure.
3.2
LATENT DIRICHLET ALLOCATION
We have seen that both ML and MAP provide estimations of the parameter set, and the diﬀerence
between the two is given by the objective function: ML optimizes the likelihood P.X j/, whereas
MAP optimizes the posterior P.jX /. e strength of MAP over ML stems from the explicit
account of the prior P./. A full Bayesian approach focuses on a diﬀerent perspective, by directly
modeling the posterior distribution over the parameter set :
P.jX / D P.X j/P./
P.X /
:

3.2. LATENT DIRICHLET ALLOCATION
59
Table 3.1: Summary of notation
Model
SYMBOL
DESCRIPTION
M
number of users
N
number of items
R
M  N Rating Matrix
n
number of observed preference in R
X
Observations extracted from R, i.e., X D fx1;    ; xng
K
number of latent factors

a generic parameter set to be estimated
xm D hu; i; ri
the m-th observation in X
LDA
θ
fθugu2U
θu
K-vector fu;1; : : : u;Kg: mixing proportion of factors for user u
ϕ
fϕkgkD1;:::;K
ϕk
N-vector fk;1; : : : ; k;N g: mixing proportion of items for factor k
zm
latent factor associated with observation m D hu; ii
Z
M  N matrix: user-factor assignments for each rating observation
α
K- vector: Dirichlet priors over latent factors
β
N-vector: Dirichlet priors over items
nk
u;i
number of preferences where user u and item i were associated with factor k
(a dot generalizes over the corresponding dimension:
for example nk
u; denotes the number of preferences where
user u was associated with factor k)
n
u;i
fnk
u;igK
kD1
nk
u;
fnk
u;igN
iD1
URP, UCM
ϵ
fϵk;igkD1;:::;K;i2I
ϵk;i
V -vector fk;i;1; : : : ; k;i;V g: mixing proportion of ratings for factor k and item i
γ
V - vector: Dirichlet priors over ratings
nk
u;i;r
number of observations hu; i; ri associated with factor k
(a dot generalizes over the corresponding dimension)
Gaussian URP
m
M  N-matrix: mu;i represents the sum of the average ratings
observed for user u and item i
b
bias toward average ratings
φ
f'k;igk2f1;:::;Kg;i2I
'k;i
pair of Gaussian parameters fk;i; k;ig
η
variational Dirichlet parameters fηugu2U where η;u D fu;1; : : : ; u;kg
λ
variational multinomial parameters fλu; gu2U, where λu D fu;1; : : : ; u;kg
We can see the diﬀerence with MAP here: estimating the posterior requires calculating the evi-
dence
P.X / D
Z
P.X j/P./ d:
(3.4)
Provided that the above quantities can be computed, it is possible to reformulate both the esti-
mation and the prediction problems. In particular:

60
3. BAYESIAN MODELING
• Estimation can be accomplished by averaging over the whole parameter domain, O D
EŒjX  D
Z
P.jX / d, and
• Given Qx, we can compute its exact probability as
P. QxjX / D
Z
P. Qxj/P.jX / d:
Let us consider again the likelihood of the pLSA model in Equation 2.9. e evidence can be
expressed as:
P.X / D
X
Z
Z
P.X ; Zj/P./ d
D
Z 8
<
:
Y
hu;ii
X
k
u;k  k;i
9
=
; P./ d;
(3.5)
where Z is a M  N matrix that encodes the state of the latent variable for each observation
hu; ii 2 X, with zu;i 2 f1;    ; Kg, and P.X ; Zj/ D Q
hu;ii u;zu;i  zu;i;i. Here, the latent pa-
rameters are averaged using a prior probability P./. e tractability of the above integral (and,
in general, of the integral Equation 3.4) is a central issue. Besides numerical methods, an al-
ternative approach is to combine likelihood functions and prior distributions with convenient
mathematical properties, including tractable analytic solutions to the integral. ese families of
prior distributions are known as conjugate prior distributions.
Recall that a conjugate prior P./ of the likelihood p.X j/ is a distribution that results
in a posterior distribution, P.jX / with the same functional form as the prior, but diﬀerent
parameters. In practice, the eﬀect of likelihood on the posterior is only to “update” the prior
parameters and not to change the prior’s functional form.
e likelihood expressed by Equation 3.5,  consists of two parameter sets: fθugu2U and
fϕkgkD1;:::;K, where θu D fu;1; : : : u;Kg and ϕk D fk;1; : : : ; k;N g are multinomial distribu-
tions ranging over the latent factors and the items, respectively. A conjugate prior for a generic
multinomial distribution µ D f1; : : : ; ng is the Dirichlet Distribution Dir.α/ [31], parameter-
ized by α D f˛1; : : : ; ˛ng and deﬁned as
Dir.µI α/ , P.µjα/ D
1
.α/
n
Y
iD1
˛i 1
i
I
.α/ D
Qn
iD1   .˛i/
  .Pn
iD1 ˛i/:

3.2. LATENT DIRICHLET ALLOCATION
61
Exploiting the Dirichlet priors into Equation 3.5 yields
P.X ; Zjα; β/ D
Z

Z
˚
Y
hu;ii
u;kk;iP.θujα/P.ϕkjβ/ dΘ dΦ
D
Z

 Y
u
Y
k

nk
u;
u;k
!  Y
u
1
.α/
Y
k
˛k 1
u;k
!
d

Z
˚
 Y
k
Y
i

nk
;i
k;i
!  Y
k
1
.β/
Y
i
ˇi 1
k;i
d
!
˚
D
Y
u
1
.α/
Z
u
Y
k

nk
u;C˛k 1
u;k
du

Y
k
1
.β/
Z
k
Y
i

nk
;iCˇi 1
k;i
dk
D
Y
u
.α C n
u;:/
.α/

Y
k
.β C nk
:;/
.β/
;
(3.6)
where n
u;: represents the vector fnk
u;:gkD1;:::;K and, analogously, nk
:; represents the vector
fnk
:;igi2I. A summary of the notation adopted here is given in Table 3.1.
e above mathematical model has been proposed in [34] under the name latent Dirichlet
allocation (LDA). Originally introduced for modeling text, it easily can be adapted to preference
data. For example, in the case of implicit preferences, the generative process is characterized as
follows:
1. For each latent factor k D 1; : : : ; K sample a multinomial distribution ϕk  Dir.β/.
2. For each user u 2 U:
(a) Sample the number nu of item selections;
(b) Choose θu  Dir.α/;
(c) For each of the nu items to be generated:
i. Sample a topic z  Disc.θu/;
ii. Sample i  Disc.ϕz/.
LDA is closely linked to pLSA, as it still captures the essence of explaining speciﬁc prefer-
ence observations in terms of latent factors. However, the main diﬀerences lie in the role played
by the prior distributions. e graphical representation in Figure 3.2 illustrates such diﬀerences.
e adoption of the priors provides a better control of the parameters of the model, which are
not ﬁxed and are the result of a random process governed by ˛ and ˇ. As a result, inference and
prediction can be approached by averaging over all possible distributions θ and ϕ. is ultimately

62
3. BAYESIAN MODELING
.i.
z
.

.

.
˛
.
ˇ
.
nu
.
M
.
K
.
Figure 3.1: Graphical model for LDA.
results in better control over the sparsity of the data, and, hence, on overﬁtting issues, while still
retaining the original expressive power of the pLSA modeling.
3.2.1
INFERENCE AND PARAMETER ESTIMATION
In a maximum likelihood perspective, the estimation phase consists of extracting the optimal ˛
and ˇ that maximize
P.X jα; β/ D
X
Z
Y
u
.α C n
u;:/
.α/

Y
k
.β C nk
:;/
.β/
:
Although latent Dirichlet allocation is still a relatively simple model, exact inference is gen-
erally intractable, due to the exponential number of possible factor assignments Z. e solution
to this is to use approximate inference algorithms, such as mean-ﬁeld variational approximation
[34], expectation propagation [134], and Gibbs sampling [75, 188]. We concentrate on Gibbs
sampling and follow the presentation of [77]. e idea behind Gibbs sampling (a general intro-
duction can be found in appendix A.3 ) is to create a random walk, or Markov process, that has the
posterior P.ZjX / as its stationary distribution, and then to run the process long enough so that
the resulting sample closely approximates a sample from the true P.ZjX / [62]. ese samples
can be used directly for parameter inference and prediction. In particular, they can be exploited in
a stochastic variant of the EM algorithm where the E step consists in iteratively sampling Z using
the Markov Chain, and the M step uses the sampled Z for estimating both the hyperparameters
α and β (through ML), and the θ and ϕ (by averaging the corresponding posterior distributions).
Let us denote by m a pair hu; ii within X. en, X:m (resp. Z:m) denotes the set X (resp.
Z) where the reference to hu; ii is ignored. Finally, let zm denote the latent variable associated
with the pair hu; ii in Z. e intuition here is to deﬁne a Markov chain which approximates
P.ZjX ; α; β/ by a repeated sampling over the components P.zmjZ:m; X ; α; β/, for each m.

3.2. LATENT DIRICHLET ALLOCATION
63
We can observe the following.
P.zmjZ:m; X ; α; β/ D
P.Z; X jα; β/
P.Z:m; X jα; β/
D
P.Z; X jα; β/
P.Z:m; X:m; xmjα; β/
D
P.Z; X jα; β/
P.Z:m; X:mjα; β/P.xmjα; β/
/
P.Z; X jα; β/
P.Z:m; X:mjα; β/:
(3.7)
Exploiting Equation 3.6, and by algebraic manipulations, we obtain the sampling equation
P.zm D kjZ:m; X ; α; β/ /

nk
u; C ˛k   1


nk
;i C ˇi   1
P
j

nk
;j C ˇj

  1
;
(3.8)
which deﬁnes the E step. As for the M step, we notice that the predictive distributions θ and ϕ
can be characterized as
P.θujzu; α/ / P.zujθu/P.θujα/ D Dir.α C n
u;:/
P.ϕkjZ; X ; β/ / P.X jϕk; Z/P.ϕkjβ/ D Dir.β C nk
:;/;
for which we can infer the mean values
u;k D
nk
u; C ˛k
P
k0
 nk0
u; C ˛k0
(3.9)
k;i D
nk
;i C ˇi
P
j

nk
;j C ˇj
:
(3.10)
Also since Z is known, we have
log P.X ; Zjα; β/ D
X
u
K
X
kD1

log  
˛k C nk
u;:

  log   .˛k/

 X
u
 
log   
nu C
K
X
kD1
˛k
!
  log   K
X
kD1
˛k
!!
C
X
k
X
i

log  
ˇi C nk
:;i

  log   .ˇi/

 X
k
 
log   
nk C
X
i
ˇi
!
  log   X
i
ˇi
!!
:
(3.11)

64
3. BAYESIAN MODELING
Optimizing the above likelihood with respect to α; β requires numerical techniques. For example,
the optimal value of α can be obtained through the ﬁxed-point iteration [135]:
˛.tC1/
k
D ˛.t/
k
	

˛.t/
k C nk
u;:

   

˛.t/
k

P
u

	

nu C PK
kD1 ˛.t/
k

  	
PK
kD1 ˛.t/
k
;
(3.12)
where 	 is the derivative logarithmic of the gamma function. A pseudo-code for the overall
learning scheme is given in Algorithm 3.
Algorithm 3 Stochastic EM based on Gibbs sampling.
Require: e sets U D fu1; : : : ; uM g and I D fi1; : : : ; iN g
the rating observations X,the number of latent topics K, initial hyperparameters α and β.
1: initializeTopicAssignments() {Randomly assign topics}
2: iteration  0
3: converged  false
4: while iteration < nMaxIterations and :converged do
5:
for all hu; i; ri 2 R do
6:
z0
u;i  sampleTopic.u; i; r/ {According to Equation 3.7};
7:
update counts using the new topic for the observation hu; i; ri
8:
end for
9:
updateHyperParams() {By exploiting Equation 3.12}
10:
if (iteration > burn in) and (iteration%sample lag D 0) then
11:
sampleUserTopicsMixingProbabilities() {According to Equation 3.9 };
12:
sampleItemSelectionProbabilities() {According to Equation 3.10 };
13:
converged  checkConvergence()
14:
end if
15:
iteration  iteration C 1
16: end while
3.2.2
BAYESIAN TOPIC MODELS FOR RECOMMENDATION
e basic LDA model discussed so far essentially provides support for implicit preferences. In
particular, we can predict the preference for a pair hu; ii by relying on the hyperparameters,
P.iju; α; β/ D
X
k
Z
k;i  P.ϕkjβ/ dϕk 
Z
u;k  P.ujα/ dθu
D
X
k
.β C ei/
.β/
.α C ek/
.α/
;
where en is a vector where all en
j D 1 if j D n, and 0 otherwise. Alternatively, we can provide
the estimation through the inferred predictive distributions θ and ϕ deﬁned in Equations 3.9
and 3.10:
P.iju; θ; ϕ/ D
X
k
u;k  k;i:

3.2. LATENT DIRICHLET ALLOCATION
65
It is possible to reformulate the LDA for explicit preferences. e User Rating Proﬁle (URP [123])
focuses on forced prediction and it is represented in Figure 3.2.
.r.
z
.

.

.
˛
.

.
N
.
M
.
K  N
.
Figure 3.2: Graphical model for URP.
In this model, ϵk;i represents a multinomial distribution over the rating values in
f1; : : : ; V g, corresponding to a latent factor k and an item i. e likelihood can be expressed
as
P.X jα; γ/ D
Z 8
<
:
Y
hu;i;ri
X
k
u;kk;i;r
9
=
; P.jα; γ/ d;
for which a stochastic EM procedure similar to the one described by algorithm 3 can be devised
(see [16] for details). Also, the probability of a rating is given by
P.rju; i; θ; ϵ/ D
X
k
u;k  k;i;r;
(3.13)
or, alternatively, by solely relying on the α and γ hyperparameters.
Barbieri et al. further develop this line of research [17] by proposing a Bayesian reformula-
tion of the UCM model shown in Chapter 2, which explicitly models free prediction in a Bayesian
setting. Bayesian UCM relies on a generative process, which takes into account both item selection
and rating emission. Each user is modeled as a random mixture of topics, where the individual
topic is then characterized both by a distribution modeling item-popularity within the considered
user-community and by a distribution over preference values for those items. us, a user may be
pushed to experience a certain item because she belongs to a community in which the category
of that item occurs with a high probability, although this has no impact on the rating assigned to
the aforesaid item category. e probability of observing an item is independent from the rating
assigned, given the state of the latent variables.
e generative process behind the Bayesian UCM can be summarized as follows:

66
3. BAYESIAN MODELING
.˛.

.
z
.
i
.
r
.

.

.
ˇ
.

.
nu
.
M
.
K
.
K  N
.
Figure 3.3: Graphical model for BUCM.
1. For each latent factor z 2 f1;    ; Kg:
(a) Sample item selection components ϕz  Dir.β/;
(b) For each item i 2 I sample rating probabilities εz;i  Dir.γ/.
2. For each user u 2 U:
(a) Sample user community-mixture components θu  Dir.α/;
(b) Sample the number of items nu for the user u;
(c) For each of the nu items to select:
i. Sample a latent factor z  Disc.θu/;
ii. Choose an item i  Disc.ϕz/;
iii. Generate a rating value r  Disc.εz;i/.
e corresponding joint likelihood can be expressed by the graphical model in Figure 3.3.
Again, the adaptation of the stochastic EM framework for learning the parameters is relatively

3.2. LATENT DIRICHLET ALLOCATION
67
simple. e sampling equation is adapted to embody counters on both items and ratings,
p.zm D kjZ:m; X / /

nk
u;; C ˛k   1


nk
;i; C ˇi   1
PN
i0D1

nk
;i0; C ˇi0

  1

nk
;i;r C r   1
PV
r0D1.nk
;i;r0 C r0/   1
;
whereas the predictive distributions in the M step now also include the multinomial probability
for a rating
u;k D
nk
u;; C ˛k
nu C PK
kD1 ˛k
I
i;k D
nk
;i; C ˇi
PN
iD1 nk
;i; C ˇi
I
k;i;r D
nk
;ir C r
PV
r0D1 nk
;ir0 C r0
:
So far, all the proposed models represent extensions of the LDA basic model, and ratings
were modeled as discrete variables associated with a multinomial distribution . Continuous rat-
ings modeled through Gaussian distributions can be accommodated as well. Assume that, for a
given latent factor k and an item i, we can devise the parameter set k;i D fk;i; k;ig. en,
preference observations can be deemed as the result of the a process similar to the URP process
described before, as shown in Figure 3.4. Within this graphical model, user and item biases (in
particular, the baselines discussed in Section 1.4) can be made explicit to inﬂuence the rating, so
that the term mu;i represents a speciﬁc bias for user u and item i, and the probability of a rating
can be expressed as
P.rju; i; 'k;i; b/ D N
 rI k;i C b  mu;i; k;i

:
.r.
z
.

.
'
.
˛
.
m
.
b
.
N
.
M
.
K  N
.
M  N
.
Figure 3.4: Graphical model for Gaussian URP.
Inference and parameter estimation of this model still can be approached through stochas-
tic EM based on sampling. It is worth it to illustrate a diﬀerent approach based on variational

68
3. BAYESIAN MODELING
approximation. Let us consider the likelihood
P.X jα; b; φ/ D
Z Y
u
Dir.θujα/
Y
hu;i;ri
X
k
u;kP.rju; i; 'k;i; b/ dθu:
e idea behind variational inference is to provide an approximation Q.Z; θ/ to the posterior
probability P.Z; θjX ; φ; b/, which can be expressed in simpler mathematical forms. In our case,
Q can be factorized into smaller components,
Q.Z; θjη; λ/ D
Y
u
q.θujηu/q.zujλu/;
where η and λ represent the set of variational parameters of Q, and, in particular, η represents
the parameter of a Dirichlet distribution ranging over users, whereas λ represents a multinomial
distribution.
Let us denote the parameters fα; b; φg by P, and the variational parameters fη; λg by P0.
It can be shown (see Appendix A.2) that Q enables the lower bound
log P.X jP/  L.P; P0/;
where
L.P; P0/ D
X
Z
Z
Q.Z; θjP0/ log P.X ; Z; θjP/ dθ
C
X
Z
Z
Q.Z; θjP0/ log Q.Z; θjP0/ dθ:
at is to say, L.P; P0/ can be used to approximate the log likelihood. For a ﬁxed P, the bound
can be made tight by optimizing L.P; P0/ with respect to P0, or, alternatively, with respect to P.
It can be shown (see Appendix A.2) that the optimal value for λu can be obtained by imposing
the equality
log q.zujλu/ D
X
Z=zu
Z
log P.X ; Z; θjP/
Y
u
q.θujηu/
Y
u0¤u
q.zu0jλu0/ dθ C Const;
and solving for λu. Similarly, an optimal value for ηu can be obtained by imposing
log q.θujηu/ D
X
Z
Z
log P.X ; ZjP/
Y
u0¤u
q.θu0jηu0/
Y
u
q.zujλu/ dθu0¤u C Const;
and solving for ηu. Notably, the integral can be simpliﬁed into a function of the parameters in
P. is creates circular dependencies between P and P0, which naturally suggests an iterative
algorithm much like EM, were the parameters are computed in turn by ﬁrst estimating λ and η

3.3. BAYESIAN CO-CLUSTERING
69
as shown above, and then by exploiting the estimated value to optimize L.P; P0/ with respect to
P.
Notably, the variational hyperparameters λ can be interpreted as cluster membership and,
combined with the estimated parameters ϕ and b, they can be exploited for prediction: given a
pair u; i we can approximate the probability of rating r as
P.rju; i; λ; φ; b/ D
K
X
kD1
u;k  N .rI k;i C b mu;i; k:i/:
(3.14)
Variational inference and Gibbs sampling represent diﬀerent approaches to solve the infer-
ence and estimation problem with full Bayesian models. Variational inference is a deterministic
optimization method that is based on approximating the posterior distribution through a sur-
rogate function, which is typically simpler. In practice, the time for each iteration of variational
inference can be high, but, typically, the inference procedure converges fast. Also, the quality of
the result strongly depends on the accuracy of the surrogate in approximating the true posterior.
In fact, they can produce inaccurate results with overly simple approximations to the posterior.
By contrast, Gibbs sampling is based on statistical simulation. e Bayesian posterior dis-
tribution is computed here by sampling a reasonably large number of sampling points. Summing
of the resulting posterior distribution values yields an approximation of the true data likelihood
that asymptotically converge to the exact posterior. When the underlying distributions admit
conjugate priors, the sampling step is relatively fast and simple to devise. However, for the ap-
proximation to be reliable, the number of required sampling iterations is typically high and the
overall procedure is computationally demanding.
3.3
BAYESIAN CO-CLUSTERING
Collaborative ﬁltering data exhibit global patterns (i.e., tendencies of some products to be “uni-
versally” appreciated) as well as signiﬁcant local patterns (i.e., tendency of users belonging to a
speciﬁc community to express similar preference indicators on the same items). Local preferences
aﬀect the performance of RS especially when the number of users and items grows, and their im-
portance has been acknowledged by the current CF literature [161]. e interplay between local
and global patterns is the reason why two users might agree perfectly on one topic while disagree
completely on another.
We have seen in Section 2.2.2 that local patterns can be better detected by means of co-
clustering approaches. Unlike traditional CF techniques, which try to discover similarities be-
tween users or items using clustering techniques or matrix decomposition methods, co-clustering
approaches aim to partition data into homogenous blocks, enforcing a simultaneous clustering on
both dimensions of the preference data.
It is natural to ask whether co-clustering relationships can be modeled in a Bayesian frame-
work. And, in fact, several approaches that extend the basic LDA framework have been proposed

70
3. BAYESIAN MODELING
Table 3.2: Summary of notation
Model
SYMBOL
DESCRIPTION
Bi-LDA
K
number of latent factors involving users
L
number of latent factors involving items
ψ
fψigi2I
ψi
K-vector f i;1; : : :  i;Kg: mixing proportion of factors for item i
ϵ
fϵk;lgkD1;:::;K;lD1;:::;L
ϵk;l
V -vector fk;i;1; : : : ; k;i;V g: mixing proportion of ratings for factor k and item i
zm
user latent factor associated with observation m D hu; ii
wm
item latent factor associated with observation m D hu; ii
Z
M  N matrix: user-factor assignments for each rating observation
W
M  N matrix: item-factor assignments for each rating observation
α1; α2
K- vectors: Dirichlet priors over latent factors
γ
V -vector: Dirichlet priors over ratings
RBC
m
M  N-matrix: mu;i represents the sum of the average ratings
b
bias toward average ratings
φ
f'k;lgkD1;:::;K;lD1:::;L
'k;l
pair of Gaussian parameters fk;l; k;lg
η1; η2
variational Dirichlet parameters fη1;ugu2U and fη2;igi2I,
where η1;u D f1;u;1; : : : ; 1;u;kg and η2;i D f2;i;1; : : : ; 2;i;kg
λ1; λ2
variational multinomial parameters fλ1;u; gu2U and fλ2;i; gi2I, where
λ1;u D f1;u;1; : : : ; 1;u;kg and λ2;i D f2;i;1; : : : ; 2;i;kg
[155, 178, 179, 196]. e underlying idea is similar to the one discussed in Section 2.2.2. at
is, we assume two independent latent factors, namely z and w, where z models the intuition that
users can be grouped into communities, whereas w represents items groupings into categories.
erefore, each preference observation is associated with a pair hz; wi.
As an example, the Bi-LDA model, proposed in [155], extends the URP model by em-
ploying two interacting LDA models, thus enforcing a simultaneous clustering of users and items
in homogeneous groups.
ese relationships can be observed in the graphical models in Figure 3.5, which encodes
the following generative process:
1. For each user u 2 U sample θu  Dir.α1/.
2. For each item i 2 I sample ψi  Dir.α2/.
3. For each pair .k; l/ 2 f1; : : : ; Kg  f1; : : : ; Lg sample ϵk;l  Dir.γ/.
4. For each pair m D hu; ii:
(a) sample zm  Disc.θu/;
(b) sample wm  Disc.ψi/;
(c) sample r  Disc.zm;wm/.

3.3. BAYESIAN CO-CLUSTERING
71
.
˛1.

.
z
.
w
.
 
.
˛2
.
r
.

.
ˇ
.
N
.
M
.
K  L
.
Figure 3.5: Graphical model for Bi-LDA.
Prediction can be devised by marginalizing on both user and item factors, by means of the
estimated predictive distributions:
P.rju; i; ϵ; θ; ψ/ D
X
k
X
k
k;l;r  u;k   i;l:
(3.15)
Continuous modeling of explicit preferences can be accomplished in a similar way. e
residual Bayesian co-clustering (RBC) proposed in [181] extends the Gaussian URP model, dis-
cussed in the previous section, to include latent factors on both the user and the item dimensions.
e model is represented graphically in Figure 3.6. Within the model, the Gaussian parameters
can be speciﬁed on the user and item latent factors, i.e., 'k;l , fk;l; k;lg, and the probability
of observing a rating r for a pair hu; ii is given by
P.rju; i; 'k;l; b/ D N .rI k;l C b  mu;i; k;l/:
e main diﬀerence with the model shown in Figure 3.4 is the introduction of a latent variable
on items. As a consequence, inference and parameter estimation can be easily adapted: in [181],
a variational EM algorithm is proposed by introducing the variational distribution
Q.Z; W ; θ; ψjP0/ D
 Y
u
q.θujη1;u/
!  Y
i
q.ψijη2;i/
!

0
@Y
u;i
q.zu;ijλ1;u/q.wu;ijλ2;i/
1
A ;
where P0 D fη1; η2; λ1; λ2g represents the set of variational parameters of Q, η1; η2 represents
the parameters of a Dirichlet distribution, and λ1; λ2 represents parameters of a multinomial

72
3. BAYESIAN MODELING
.r.
m
.
'
.
b
.
z
.
w
.

.
 
.
˛1
.
˛2
.
N  M
.
K  L
.
M  N
.
M
.
N
.
Figure 3.6: Graphical model for RBC.
distribution, both ranging over users and items respectively. ese variational parameters, together
with the model parameters ϕ and b, are learned by the EM procedure and can be exploited in the
prediction equation directly adapted from Equation 3.14:
P.rju; i; λ1; λ2; φ; b/ D
K
X
kD1
L
X
lD1
1;u;k2;i;lN .rI k;l C b  mu;i/:
3.3.1
HIERARCHICAL MODELS
A major weakness of the current approaches to co-clustering is the static structure enforced by
ﬁxed row/column blocks where both users and items have to ﬁt. For example, the movies “Ti-
tanic” and “Avatar” are typically associated with diﬀerent categories: the former is about romance,
whereas the latter can be considered an action, sci-ﬁmovie. Assuming a global and unique par-
tition on the item-set, we can expect to see the movies in diﬀerent partitions. However, that
structure would fail to recognize a group of users who are fans of James Cameron, the director for
both the movies. Analogously, any method associating the two movies with the same partition
would fail in identifying the diﬀerence in genre.
e issue in the previous example is that diﬀerent user groups can infer diﬀerent interpreta-
tions of item categories. A more ﬂexible structure, where item categories are conditioned by user
communities, would better model such situations, e.g., by allowing “Titanic” and “Avatar” to be
observed in the same item category within the “Cameron fans” group, and in diﬀerent categories
outside. Notice that traditional clustering approaches are not aﬀected by this problem, as they
only concentrate on local patterns in one dimension of the rating matrix. e drawback, however,

3.3. BAYESIAN CO-CLUSTERING
73
Table 3.3: Summary of notation
Model
SYMBOL
DESCRIPTION
BH-Forced
ψ
parameter set fψi;kgkD1;:::;K;i2I
ψi;k
L-vector: mixing proportion for the item category l and the user-topic k
ϵ
parameter set ϵk;l
ϵk;l
V -vector: distribution over rating values for the co-cluster k; l
α1; α2
K- vector: Dirichlet priors on user communities and item categories
γ
V -vector: Dirichlet priors on rating values
BH-Free
ψ
parameter set fψkgkD1;:::;K
ψk
L-vector: mixing proportion for the user-topic k
ϕ
parameter set ϕk;l
ϕk;l
N-vector: mixing proportion for each item i in the co-cluster k; l
β
N-vector: Dirichlet priors on items
nk;l
u;i;r
number of times user u and item i are associated with
rating r corresponding to latent factors k; l
(a dot generalizes over the corresponding dimension)
n;:
u;:;:
fnk;:
u;:;:gkD1;:::;K
nk;
:;:;:
fnk;l
:;:;:glD1;:::;L
nk;l
:;:;
fnk;l
:;;rgrD1;:::;V
nk;l
:;;:
fnk;l
:;i;:gi2I
is that they ignore structural information in the other dimension, which by the converse can be
exploited both for more accurate prediction and user proﬁling.
Speciﬁc groups of users tend to be co-related according to diﬀerent subsets of features.
However, though semantically-related, two users with (possibly several) diﬀerences in their pref-
erences would hardly be recognized as actually similar by any global model imposing a ﬁxed struc-
ture for item categories. Individual users can be intended as a mixture of latent concepts, each of
which being a suitable collection of characterizing features. Accordingly, two users are consid-
ered as actually similar if both represent at least a same concept. Viewed in this perspective, the
identiﬁcation of local patterns, i.e., of proper combinations of users and items, would lead to the
discovery of natural clusters in the data, without incurring the aforesaid diﬃculties. Consider the
toy example in Figure 3.7, where homogenous blocks exhibiting similar rating patterns are high-
lighted. ere are seven users clustered in two main communities. Community 1 is characterized
by three main topics (with groups d11 D fi1; i2; i3g, d12 D fi4; i5; i6; i7g and d13 D fi8; i9; i10g),
whereas community 2 includes four main topics (with groups d21 D fi1; i4; i5g, d22 D fi2; i3; i7g,
d23 D fi6; i10g and d24 D fi8; i9g). e diﬀerence with respect to traditional co-clustering tech-
niques is that diﬀerent communities group the same items diﬀerently. is introduces a topic
hierarchy that, in principle, increases the semantic power of the overall model.
An extension of the Bayesian co-clustering framework to incorporate such ideas has been
made in [20]. e key idea is that there exists a set of user communities, each one describing
diﬀerent tastes of users and their corresponding rating patterns. Each user community is then

74
3. BAYESIAN MODELING
u1
i
1
1
1
5
5
1
1
1
4
4
1
1
4
4
4
4
4
4
4
4
4
4
3
3
3
3
3
2
2
2
2
2
2
1
1
1
1
1
1
5
5
5
5
5
5
5
4
5
5
5
5
5
5
1
i2
i3
i4
i5
i6
i7
i8
i9
i10
u2
u
Community 1
Community 2
3
u4
u5
u6
u7
d  = {i  ,i  ,i  }
1
1
2
3
d  = {i  ,i  ,i  }
1
1
4
5
d  = {i  ,i  ,i  }
2
2
3
7
d  = {i  ,i   }
3
9
10
d  = {i  ,i   }
3
6
10
d  = {i  ,i  }
4
8
9
d  = {i  ,i  ,i  ,i  }
2
4
5
6
7
Figure 3.7: Example of local pattern in CF data.
modeled as a random mixture over latent topics, which can be interpreted as item-categories.
Given a user u, we can foresee her preferences on a set of items I.u/ by choosing an appropriate
user community z and then choosing an item category w for each item in the list. e choice of
the item category w actually depends on the selected user community z. Finally, the preference
value is generated by considering the preference of users belonging to the group z on items of the
category w.
A ﬁrst coarse-grained generative process can be devised as an adaptation of the Bi-LDA
model, and it is graphically depicted in Figure 3.8:
.
˛1.

.
z
.
w
.
 
.
˛2
.
r
.

.

.
N  K
.
M
.
M  N
.
K  L
.
Figure 3.8: BH-forced generative model.
1. For each user u 2 U sample θu  Dir.α1/.
2. For each item i 2 I and user community z 2 f1; : : : ; Kg sample the mixture components
ψz;i  Dir.α2/.

3.3. BAYESIAN CO-CLUSTERING
75
3. For each topic w 2 f1; : : : ; Lg and user community z D f1;    ; Kg, sample rating prob-
abilities ϵz;w  Dir.γ/.
4. For each active pair m D hu; ii:
(a) Choose a user factor zm  Disc.θu/;
(b) Choose a topic wm  Disc.ψzm;i/;
(c) Generate a rating value r  Disc.ϵzm;wm/.
We name this model Bayesian hierarchical co-clustering focused on forced prediction (BH-
Forced). Figure 3.9 provides a possible hierarchical model for the data in Figure 3.7, where we
assume that K D 2 and L D 4. en, (a) represents assignments zm corresponding to each ob-
served pair m  hu; ii, whereas (b) represents assignments wm. Furthermore, (c) represents the
probability θ, and (d) and (e) represent ψ for the two communities associated with users. By
applying the generative process described above, the interested reader easily can verify that each
observed rating can be explained as the result of two latent factors in hierarchical relationships.
For example, let us consider the observation hu5; i5i. According to the devised generative pro-
cess, we ﬁrst pick user community 2 for u5, exploiting table (c). Next, we assign item category
1 to item i5, by drawing from the available categories according to the probability in table (e).
Finally, given the co-cluster h2; 1i, we observe rating 5 by picking randomly according to the
related rating distribution in table (f ).
e BH-forced approach focuses on forced-prediction, as it models the prediction of pref-
erence values for each observed user-item pair, and it does not explicitly take into account item
selection. It is also possible to accommodate the model to provide explicit support to the item
selection component. Figure 3.10 illustrates the Bayesian Hierarchical focused on Free Prediction
(BH-Free). Each user is modeled as a random mixture of topics, where the individual topic is
then characterized both by a distribution modeling item-popularity within the considered user-
community and by a distribution over preference values for those items. e distribution of items
given the topic variable w depends on the choice of the user community: this enforces an explicit
modeling of item popularity, both within a category and within a community, and hence provides
a high degree of ﬂexibility. e rating prediction components maintain almost the same structure
as in the BH-forced model, and hence, even the accuracy is almost the same.
e role of item selection within the new BH-free model can be noticed in the underlying
generative process:

76
3. BAYESIAN MODELING
Figure 3.9: Probabilistic modeling of local patterns.

3.3. BAYESIAN CO-CLUSTERING
77
.
˛1.

.
z
.
w
.
 
.
˛2
.
r
.
i
.

.

.

.
ˇ
.
K
.
M
.
n
.
K  L
.
K  L
.
Figure 3.10: Generative model for BH-free.
1. For each user u 2 U sample θu  Dir.α1/.
2. For each user community z 2 f1; : : : ; Kg sample the mixture components ψz  Dir.α/.
3. For each topic w 2 f1; : : : ; Lg and user community z D f1;    ; Kg;
(a) Sample item selection components ϕz:w  Dir.β/;
(b) Sample rating probabilities ϵz;w  Dir.γ/.
4. For each u 2 U:
(a) Sample the number of items nu;
(b) For m 2 f1; : : : ; nug:
i. Choose a user attitude zm  Disc.θu/;
ii. Choose a topic wm  Disc.ψzm/;
iii. Choose an item i  Disc.ϕzm;wm/;
iv. Generate a rating value r  Disc.ϵzm;wm/.
BH-free is aimed at inferring the tendency of a user to experience some items over oth-
ers, independent of her/his rating values. e model assumes that this tendency is inﬂuenced by
implicit and hidden factors that characterize each user community. is can be considered as an
extension of the UCM model discussed in Sections 2.2.1 and 3.2.2, for two main reasons: ﬁrst,
it adds a hierarchical co-clustering structure, thus complying to the original idea of modeling lo-
cal patterns; second, it accommodates a Bayesian modeling, which allows better control of data
sparseness.
e inference process is similar for both BH-forced and BH-free. Concerning the latter
model, there is a small overhead due to the explicit modeling of item selection. Hence, in the
following, we only sketch the derivation of the sampling equations for this model. e equations
for the forced version can be derived accordingly.

78
3. BAYESIAN MODELING
e notation used in our discussion is summarized in Table 3.3. Given the hyperparameters
α1, α1, β, and γ, the joint distribution of the observations X, and the assignments Z; W can be
factored as:
P.X ; Z; W jα1; α2; β; γ/ D
Z
P.Zjθ/P.θjα1/ dθ
Z
P.W jZ; ψ/P.ψjα2/ dψ

Z Z
P.X jZ; W ; ϕ; ϵ/P.ϕjβ/P.ϵjγ/ dϕ dθ:
By rearranging the components and grouping the conjugate distributions, the complete data like-
lihood can be expressed as:
P.X ; Z; W jα1; α2; β; γ/ D
M
Y
uD1
.n;:
u;:;: C α/
.α1/

K
Y
kD1
.nk;
:;:;: C α2/
.α2/

K
Y
kD1
L
Y
lD1
.nk;l
:;:; C γ/
.γ/

K
Y
kD1
L
Y
lD1
.nk;l
:;;: C β/
.β/
:
e latter is the starting point for the inference of all the topics underlying the generative process,
as the posterior on Z; W can be written as:
P.Z; W jX ; α1; α2; γ; β/ D P.Z; W ; X jα1; α2; γ; β/
P.X jα1; α2; γ; β/
:
As already mentioned, this formula is intractable because of its denominator. We can resort again
to Gibbs sampling by deﬁning a Markov chain, in which, at each step, inference can be accom-
plished by exploiting the full conditional P.zm D k; wm D ljZ:m; W:m; X ; α1; α2; γ; β/. As
usual, zm (resp. wm) is the assignment for the cell m of the matrix Z (resp. W ), and Z:m (W:m)
denotes the remaining latent factor assignments. e chain is hence deﬁned by iterating over
the available states m. e Gibbs sampling algorithm estimates the probability of assigning the
pair k; l to the m-th observation hu; i; ri, given the assignment corresponding to all other rating
observations:
P.zm D k; wm D ljZ:m; W:m;X ; α1; α2; γ; β/ /

nk;:
u;:;: C ˛1
k   1



nk;l
:;:;: C ˛2
l   1


nk;l
:;:;r C r   1
PV
r0D1.nk;l
:;:;rC C r/   1

nk;l
:;i;: C ˇi   1
PN
i0D1.nk;l
:;i0;: C ˇi/   1
:
(3.16)

3.4. BAYESIAN MATRIX FACTORIZATION
79
e above equation speciﬁes the E step in the Stochastic EM procedure. e M step pro-
vides an estimate of the model parameters:
u;k D
nk;:
u;:;: C ˛1
k
n:;:
u;:;: C PK
kD1 ˛1
k
I
 k;l D
nk;l
:;:;: C ˛2
l
nk;:
:;:;: C PL
lD1 ˛2
l
I
k;l;r D
nk;l
:;:;r C r
nk;l
:;:;: C PV
r0D1 r0
I
k;l;i D
nk;l
:;i;: C ˇi
nk;l
:;:;: C PN
i0D1 ˇi0
;
and the hyperparameter can be estimated by means of numerical methods.
Finally, given the pair hu; ii, we compute the probability of observing the rating value r in
a free prediction context:
p.r; iju; θ; ψ; ϕ; ϵ/ D
K
X
kD1
L
X
lD1
u;k   k;l  k;l;i  k;l;r:
(3.17)
Notice the explicit reference, in Equation 3.17, to the k;l;i component that models the prob-
ability of i being selected within co-cluster k; l. Such a component biases the ranking toward
relevant items, thus providing the required adjustment that makes the model suitable for both
prediction and recommendation accuracy. Compared to Equation 3.17, the prediction equation
for BH-forced does not include such a component and relies on a diﬀerent speciﬁcation of the ψ
distribution:
p.rju; i; θ; ψ; ϵ/ D
K
X
kD1
L
X
lD1
u;k   k:l;i  k;l;r:
(3.18)
3.4
BAYESIAN MATRIX FACTORIZATION
We can ﬁnally review the PMF model discussed in Section 2.3.2 under a Bayesian perspective.
We already have seen in Section 3.1 that the parameters P and Q are regularized using Gaussian
priors governed by the variance hyperparameters. us, the optimal values for the parameters are
obtained by MAP estimation.
We can take a step further and study more general Bayesian formulations for PMF. In
Section 3.1, we initially assumed a constant variance for the Gaussian prior: this implies that
the latent features are independent. We also discussed a more general formulation of the priors,
through multivariate Gaussian governed by the µU ; µI; ΣU ; ΣI hyperparameters. ese general
hyperparameters enable an adaptive regularization, as they can better model speciﬁc cases (e.g.,
users with less/more preferences) and dependencies among the latent factors. e general model
is graphically represented in Figure 3.11.
Since P and Q depend on the hyperparameters P D fµU ; µI; ΣU ; ΣIg, we can refor-
mulate the inference and parameter estimation in a more general way, by marginalizing over all

80
3. BAYESIAN MODELING
.r.

.
P
.
Q
.
˙U
.
U
.
˙I
.
I
.
N  M
.
M
.
N
.
Figure 3.11: A generalized PMF model.
possible values of such parameters, given the hyperparameters:
P.X jP; / D
Z Z Y
u
P.PujµU ; ΣU /
Y
i
P.QijµI; ΣI/
Y
hu;i;ri
P.rjP T
u Qi; / dP dQ: (3.19)
Here, we change the focus with respect to the original PMF, by focusing on the optimal hyperpa-
rameter set P, for which P and Q can be averaged in a Bayesian setting. is approach represents
a generalization of the PMF, named parametric PMF (PPMF) and has been investigated exten-
sively [91, 115, 180].
Inference and parameter estimation can be accomplished by means of a varia-
tional EM procedure, as follows. We can introduce a wider set of parameters P0 D
fλ1;u; ν1;u; λ2;i; ν2;igu2U;i2I, such that the posterior P.P; QjP; X / can be approximated by the
factorized variational distribution Q.P; QjP0/ deﬁned as
Q.P; QjP0/ D
Y
u
q.Pujλ1;u; diag.ν1;u//
Y
i
q.Qijλ2;i; diag.ν2;i//:
Here, the factor q represent a K-dimensional Gaussian distribution. Based on Q, we can express
the lower bound
L.P; P0/ D
Z
Q.P; QjP0/ log P.X ; P; QjP/ dP dQ
 Z
Q.P; QjP0/ log Q.P; QjP0/ dP dQ;
for the data likelihood, which enables the standard variational EM procedure where we alter-
natively optimize L.P; P0/ with respect to P and P0 (mathematical details can be devised in
Appendix A.2). Also, since Q is factorized, closed forms for the optimal values for P0 in the E

3.4. BAYESIAN MATRIX FACTORIZATION
81
step can be obtained by solving the equations
log q.Pujλ1;u; diag.ν1;u// D
Z
Q.P; QjP0/ log P.X ; P; QjP/ dP:u dQ C Const
log q.Qijλ2;i; diag.ν2;i// D
Z
Q.P; QjP0/ log P.X ; P; QjP/ dP dQ:i C Const;
for the given variables.
e variational parameters P0 can also be employed for solving the prediction problem. In
particular, since Q.Pu; QijP0/ approximates the true posterior P.Pu; QijX ; P/, we can derive
f OPu; OQig D argmax
Pu;Qi
P.Pu; QijX ; P/
 argmax
Pu;Qi
Q.Pu; QijP0/
D fλ1;u; λ2;ig;
and hence
P.rju; i; X ; P/  P.rju; i; λ1;u; λ2;i; / D N .rI λT
1;uλ2;i; /:
An alternative, full Bayesian treatment includes a further model averaging on the P pa-
rameters [168]. We can introduce the hyperparameters 0 , fµ0; ˇ0; W0; 0g, which can be ex-
ploited in a Gaussian-Wishart distribution. e latter are known to be conjugate to the Gaussian
multivariate distribution [31, Section 2.3.6], and is expressed as:
P.µ; Σj0/ D N .µj0; ˇ0Σ/W.ΣjW0; 0/;
where W.ΣjW0; 0/ represents the Wishart distribution with 0 degrees of freedom and scale
W0. en, by adopting the notation U , fµU ; µU g, I , fµV ; µV g, we can express the rating
probability as
P.rju; i; X ; 0/ D
Z
P.rjPu; Qi; /  P.Pu;QijX ; U ; I/
(3.20)
P.U ; Ij0/ dP dQ dU dI:
Usually, 0 is speciﬁed by means of constant values. For example, [168] suggests µ0 D 0, 0 D K
and W0 as the identity matrix. e dependencies among the variables of this full Bayesian matrix
factorization approach (BPMF in the following) are represented in Figure 3.12.
Exact evaluation of the predictive distribution in Equation 3.20 is analytically intractable,
due to the complexity of the posterior term P.Pu; QijX ; U ; I/. Hence, the need for approx-
imate inference, which is approached in [168] by adopting Gibbs sampling. In particular, the
predictive distribution is approximated as
P.rju; i; X ; 0/  1
T
T
X
tD1
P.rjP t; Qt; /;

82
3. BAYESIAN MODELING
.r.

.
P
.
Q
.
˙U
.
U
.
˙I
.
I
.
0; ˇ0
.
W0; 0
.
N  M
.
M
.
N
.
Figure 3.12: Graphical model for BPFM.
where the matrices fP t; QtgtD1;:::;T are computed by using a Markov chain whose stationary
distribution is the posterior of the model parameters fP; Q; U ; V g. e Gibbs sampling pro-
cedure is devised by the following learning steps:
1. Initialize fP 1; Q1g randomly.
2. For each t 2 f1; : : : ; T g:
(a) Sample t
U  P.U jP t; 0/ and t
I  P.IjQt; 0/;
(b) For each u 2 U sample P tC1
u
 P.PujX ; Qt; t
U /;
(c) For each i 2 I sample QtC1
i
 P.QijX ; P tC1; t
I/.
Within this sampling scheme, the adoption of conjugate priors eases the sampling steps.
In particular, P.PujX ; Qt; t
U / and P.QijX ; P tC1; t
I/ are still multivariate Gaussian, whereas
P.U jP t; 0/ and P.IjQt; 0/ are Gaussian-Wishart.

3.5. SUMMARY
83
3.5
SUMMARY
Techniques based on Bayesian modeling are better suited when the underlying data is charac-
terized by high sparsity (like in the case of recommender systems), as it allows a better control
of the priors that govern the model and it prevents overﬁtting. Moreover, the introduction of
informative priors allows us to exploit prior knowledge, as it easily can be encoded in the hy-
perparameters of the prior distributions. Bayesian methods have been successfully applied for
modeling preference data and in the following table, we provide a summary of the main features
of the approaches discussed in this chapter. All of them employ a soft membership policy, which
allows us to allocate diﬀerent latent factors to diﬀerent preference observations. LDA focuses
on the modeling of implicit data, hence, does not support the task of rating prediction. Also, it
is worth noticing that, although co-clustering and matrix factorization approaches employ latent
factor modeling on both the dimensions of the preference matrix, MF techniques model, for each
data observation, user and item factors independently. Table 3.4 summarizes the basic properties
of the proposed models according to the various dimensions.
Table 3.4: Summary
LDA
URP
BUCM
Bi-LDA
RBC
BH-Free
BH-Forced
PPMF
BPMF
P
Free
X
X
Forced
X
X
X
X
X
X
F
User-based
X
X
X
X
X
Item-based
X
X
Joint
X
X
Hierarchical
X
X
P
Discrete
X
X
X
X
X
X
Continuous
X
X
X
X
F
Hard
Soft
X
X
X
X
X
X
X
X
X
P
Implicit feedback
X
Explicit (Multinomial)
X
X
X
X
X
Explicit (Gaussian)
X
X
X
e practical advantages in employing Bayesian techniques over non-Bayesian approaches
in prediction accuracy are highlighted in Chapter 4. ere, we extensively compare the perfor-
mances in rating prediction and recommendation and discuss the capabilities of these methods.
e wide and successful application of Bayesian methods is mainly motivated by the devel-
opment of eﬀective approximate inference algorithms (such as variational inference and expec-
tation propagation) and sampling techniques (such as Markov chain Monte Carlo and collapsed
Gibbs sampling). ere is an ongoing debate over the choice of approximate inference techniques
over sampling methods. Variational inference techniques aim at providing deterministic approxi-
mations for the true posteriors; they are usually harder to derive than sampling-based techniques
and there is not a clear recipe to derive such approximations. eir main drawback is that the loose
approximation of posteriors tends to produce inaccurate results. Sampling-based methods aim at
approximating, by Monte Carlo simulations, the predictive distribution of the considered model;
the distributions that specify the model are iteratively updated by sampling from a Markov chain,
whose stationary distribution is an approximation of the posterior over the model parameters and

84
3. BAYESIAN MODELING
hyperparameters. is approximation asymptotically converges to the true posterior, but it is hard
to determine the convergence of the Markov chain.
e scalability of inference procedures is a main line of research that follows two main
directions. e ﬁrst one focuses on directly speeding up learning procedures by accelerating the
computation of the exact solution on a single machine. In this context, eﬀective speeding-up
techniques have been developed for the LDA collapsed Gibbs sampling. e main idea is to
reduce the time taken for sampling a topic for each observation. is sampling operation typically
involves the computation of the posterior probability of each topic given the current observation
and the remaining parameters (see Equation 3.8); hence, it is linear in K, the number of topics.
However, for any particular observation, the posterior distribution is frequently skewed, i.e., the
probability mass is concentrated on a small fraction of topics. It is possible [156] to exploit this
property by iterating the list of topics sorted by decreasing popularity, and computing iteratively
the probability that the sampled value, for a given observation, does not depend on the remaining
topics. is process allows us to relate each sample to a limited subset of topics, thus substantially
speeding up the learning phase without introducing approximations. It is shown in [156] that
this approach is eight times faster than standard collapsed Gibbs sampling for LDA.
e other line of research involves the development of parallel implementations of learn-
ing algorithms in a multiprocessor architecture and/or in a distributed setting. e expectation-
maximization algorithm (as well as variational EM) easily can be parallelized by considering that
responsibilities (or variational parameters) can be computed independently for each document (or
user). In a multiprocessor architecture [140], the E-step can be executed by using parallel threads,
and a join thread can aggregate the suﬃcient statistics produced by each thread and update the
model parameters in the M-step.
Similarly, in a master-slave distributed environment, it is possible to partition the collection
into blocks (subsets of documents) that are processed independently; the synchronization step is
performed by a master node, which receives all the suﬃcient statistics from other nodes, updates
the model, and writes it on the disk. e computation performed by the master node, which
is the main bottleneck in this approach, can be further parallelized. For example, in [206] the
authors propose an implementation of variational inference for LDA based on the Map-Reduce
framework. e computation is distributed across a set of mapper and reducer nodes: the former
process small subsets of data performing the variational E-step, while the latter aggregate the
partial results produced by mappers and update the model. e computational burden of the M-
step is addressed by the fact that each reducer receives and processes the statistics corresponding
to a single topic. A similar idea can be used to speed-up the learning phase of variational Bayesian
PMF[192].
e task of distributing and parallelizing learning algorithms based on Gibbs sampling has
an intrinsic diﬃculty that comes from the sequential nature of the sampling chain. In fact, the
asymptotical convergence to the stationary distribution requires the sequential updates of topic
assignments: the probability of sampling a topic for one observation depends on the topics as-

3.5. SUMMARY
85
signed to all the previous observations in the sampling chain. In [143], authors study a parallel
Gibbs sampling algorithm for LDA in which this dependency is relaxed. Each processor receives
the current status of global counts, performs Gibbs sampling on the assigned subset of data, and
updates its local table with topic assignments and counters. At the end of this computation, a syn-
chronization thread gathers local statistics from samplers and updates the global status of counts
by enforcing consistency. Despite having no formal convergence guarantees, due to the fact that
we are no longer sampling from the true posterior, this parallel (and approximate) implementation
works well in practice.
We conclude this chapter by mentioning that several implementations of scalable learning
algorithms for Bayesian probabilistic latent factor models are freely available. Among them we
recall the following.
• Mahout² provides an implementation of collapsed variational Bayes for LDA [191] on
Apache Hadoop using the map/reduce paradigm.
• Vowpal wabbit³ provides an online implementation of LDA based on [80]: training data is
divided in mini-batches, for each document in the current batch the algorithm computes
the E-step and updates the approximated topic distributions.
• GraphLab⁴ provides a parallel implementation of the collapsed Gibbs sampling for LDA
based on the work described in [6], which allows eﬀective synchronization and storage of
the state of latent variables and is able to ﬁt streaming data.
• Fast And Scalable Topic-Modeling Toolbox⁵ implements several parallel and distributed
algorithms for LDA, based on both fast collapsed variational Bayesian inference [13] and
collapsed Gibbs sampling [143, 156].
²https://mahout.apache.org/
³https://github.com/JohnLangford/vowpal_wabbit/wiki
⁴http://graphlab.org/projects/index.html
⁵http://www.ics.uci.edu/~asuncion/software/fast.htm

C H A P T E R
4
Exploiting Probabilistic Models
As discussed in Chapter 2, probabilistic approaches can be classiﬁed according to two alternative
ways of modeling preference observations:
• Forced prediction: is model provides the estimate of P.rju; i/, which represents the
conditional probability that user u assigns a rating value r given the item i;
• Free prediction: e process of item selection is included in this model, which is typically
based on the estimate of P.r; iju/. In this case, we are interested in predicting both the se-
lection of the item and the corresponding preference of the user. By applying the chain rule,
P.r; iju/ can be factorized as P.rji; u/P.iju/; this factorization still includes a component
of forced prediction, which, however, is weighted by the probability of selecting the item
and thus allows a more precise estimate of user’s preferences.
e exploitation of a probabilistic model in a recommendation scenario relies on the analysis of the
distribution over preference values expressed by the above probabilities. Given this distribution,
there are several methods for computing, for each user, a personalized ranking over items. In the
following, we will discuss possible instantiations of ranking functions that exploit the ﬂexibility
of the approaches analysed in the previous chapters.
Most CF techniques have focused on the development of accurate techniques for rating pre-
diction. e recommendation problem has been interpreted as a missing-value prediction problem
[174], in which, given an active user, the system is asked to predict her preferences on a set of
items. However, [47, 126] have shown that the focus on prediction accuracy does not necessarily
help in devising good recommender systems.
As the number of available customers increases, it is always more diﬃcult to understand,
proﬁle, and segment their behaviors and a similar consideration holds for the catalog of products.
Under this perspective, CF models should be considered in a broader sense, for their capability to
deeply understand the hidden relationships among users and the products they like. For example,
the high-dimensional preference matrix can be partitioned to detect user communities and item
categories; the analysis of the relationships between these two levels can provide a faithful, yet
compact, description of the data that can be exploited for better decision making.
4.1
PROBABILISTIC MODELING AND DECISION THEORY
e modeling of data observations with probability distribution that employ random variables
provides us with a mathematical framework for quantifying uncertainty. For instance, in a rec-

88
4. EXPLOITING PROBABILISTIC MODELS
ommendation scenario, the joint distribution P.u; i; r/ summarizes the degree of uncertainty
corresponding to the observation hu; i; ri. From an application perspective, we face the problem
of performing choices under uncertainty. at is, we are interested in exploiting this measure of
uncertainty to make practical decisions: given a probability distribution over ratings for each item
i not yet purchased by the current user, how do we select the next items to be recommended? is
can be seen as a two-step process: in the ﬁrst step, we make a speciﬁc prediction over the random
variable of interest (e.g., the predicted rating value for the pair hu; ii), while, in the second step,
we perform decisions based on such predictions.
e process can be formalized according to [138, Section 5.7], as follows. We are given
a set of observations X, and each observation x 2 X can be associated with an unknown state
y 2 Y. Decisions can be encoded as possible actions a 2 A, and a loss function L.y; a/ measures
the compatibility of action a relative to the hidden state y. Some example are, e.g., the 0/1 loss
L.y; / D 1Jy ¤ aK, the square loss L.y; a/ D .y   a/2, or the logarithm loss L.y; a/ D   log a.
For our purposes, we encode actions based on a speciﬁc parametric probabilistic model. Each
model M encodes a possible decision ı.x; M/ for a given observation x. is allows us to deﬁne
the notion of risk as
R.M/ D
X
x2X
L.y; ı.x; M//;
or, in more general terms,
QR.M/ D
X
x2X;y2Y
P.y; x/L.y; ı.x; M//:
We have mentioned, in the beginning of this chapter, that recommendation has been tradi-
tionally interpreted as missing rating prediction. In this context, x represents an observation .u; i/,
and an action ı..u; i/; M/ can correspond to optimal rating assignment for the observation, based
on the underlying model. In probabilistic terms, this can be encoded as ı..u; i/; M/ D Oru
i , and
Oru
i where
Oru
i D argmax
r
P.rju; i; M/;
(4.1)
or, alternatively,
Oru
i D EŒRju; iI  D
Z
rP.rju; i; M/ dr:
(4.2)
It can be shown [138] that, for a ﬁxed model M, Equation 4.1 is optimal for the 0/1 loss, and
Equation 4.2 is optimal for the square loss.
e risk function also can be used for parameter estimation, when actions represent an
estimation of some values on the data, and the loss function measures the diﬀerence between
estimated and true values. In such cases, there are some interesting connections between the
risk function and the likelihood functions described in Chapters 2 and 3. For example, if we
focus on preference observations and consider the PMF approach discussed in Section 2.3.2,

4.1. PROBABILISTIC MODELING AND DECISION THEORY
89
we can observe that the log likelihood corresponds to the empirical risk under the square loss,
with ı.hu; i; ri; M/ deﬁned as in Equation 4.2. More in general, we can adopt ı.hu; i; ri; M/ D
P.rju; i; M/. en, under a logarithm loss, we obtain
R.M/ D
X
x2X
L.y; ı.x; M//
D  X
hu;i;ri
log P.rju; i; M/
D   log P.X jM/:
In this case, maximizing the likelihood corresponds to minimizing the empirical risk. Besides
the relationships between likelihood and empirical risk, it is, in general, possible to reformulate
the learning problem as the minimization of application-speciﬁc losses: for example, in terms of
losses encoding RMSE [131] or ranking [130, 159].
We can summarize the above discussion in the following observations.
• On one side, we assume that models are given and learned in some manner, and we can
exploit the relationship between models and actions to compare models according to a given
criterion that is encoded by a loss function.
• On the other side, given a model, we can directly encode the decision process as dependent
on the model parameters. en, we can ﬁnd the optimal parameters that minimize the risk
associated with the decisions made under that model.
Given an estimate of the probability distributions that minimize some prediction loss, we next
turn our attention to the problem of making ﬁnal decisions. Although, in theory, the direct in-
ference of parameters that minimizes the considered risk function could be considered as the best
choice from an application-speciﬁc perspective, the choice of decoupling inference from decisions
is more suitable in several scenarios [31, Section 1.5]:
• Computational tractability. Even if we described above some situations in which mini-
mizing the risk corresponds to maximizing a formulation of the log likelihood, there are
settings, e.g., if we specify a loss function directly on the recommendation list, where opti-
mal decisions cannot be analytically derived or approximated.
• Flexibility. Generally, the estimate of the posterior distribution of the parameters of the
model-given observations provides us several ways of performing decisions; by addressing
inference and decisions at the same time, we focus exclusively on one way of exploiting the
model and this could essentially result in a loss of information.
• Revision and weighting of the loss function. If we consider a situation where the loss de-
pends on ﬁnancial expectations, and the latter are subjected to revision from time to time,
decisions easily can be adapted by tuning the decision surfaces rather than the set of param-
eters. More generally, the loss can depend on a weighting function that may change with

90
4. EXPLOITING PROBABILISTIC MODELS
time. us, separating decisions from inference allows us to tune the ﬁrst ones without
having to infer the model again.
• Multiple objective functions. We can consider the case where the risk function can break
into a number of components, each of which represents a separate subspace that can be
tackled separately. Rather than combine all of this heterogeneous information, it may be
more eﬀective to work on the diﬀerent pieces separately, by modeling the likelihood of each
subspace and then by combining them by exploiting ad-hoc decisions for each subspace.
• Model comparison. Given two models M1 and M2, comparing such models may depend
on the underlying loss function. In particular, there may be situations where M1 outper-
forms M2 in predicting the rating, while the latter provides a more accurate recommenda-
tion list. We shall see that, in such situations, relying on a single optimization strategy can
yield inappropriate decisions.
In the following, we evaluate the approaches presented in Chapters 2 and 3 in diﬀerent
settings, such as prediction and recommendation accuracy, which reﬂect diﬀerent risk functions.
More generally, probabilistic techniques oﬀer some renowned advantages: notably, they can be
tuned to optimize a variety of risk functions; moreover, optimizing the likelihood allows us to
model a distribution over rating values, which can be used to determine the conﬁdence of the
model in providing a recommendation and to implement a rejection policy where no decision can be
made with enough conﬁdence. Finally, they allow the possibility to include prior knowledge in the
generative process, thus allowing a more eﬀective modeling of the underlying data distribution.
Speciﬁcally, we are interested in detecting which models and assumptions better support
speciﬁc losses over others. Investigating such aspects allows us to deﬁne a key for better recom-
mendation according to the underlying scenario we are interested in modeling.
4.1.1
MINIMIZING THE PREDICTION ERROR
We base our analysis on the Movielens1M¹ benchmark dataset, which was collected in the context
of “e GroupLens Research Project” developed within the Department of Computer Science
and Engineering at the University of Minnesota. is dataset contains 1,000,209 anonymous
ratings on approximately 3,700 movies made by 6,040 users and it is widely used as a benchmark
for evaluating recommendations and CF techniques. is collection contains tuples hu; i; r; ti,
where u and i are, respectively, user and item identiﬁers, t is a timestamp, r 2 f1; : : : ; 5g is the
rating value, and each user has at least 20 ratings. Side information is also available, both for users
(gender, age, occupation, Zip-code) and movies (title, genre). Table 4.1 contains a summary of
the main properties of the data.
Figure 4.1 shows the cumulative distribution relative to the number of ratings per item
and user. In both cases, we can observe a extremely skewed distributions: a small percentage of
¹http://www.grouplens.org/datasets/movielens

4.1. PROBABILISTIC MODELING AND DECISION THEORY
91
Table 4.1: Movielens1M—statistics
#users
6,040
#items
3,706
#preferences
1,000,209
Avg #ratings user
166
Avg #ratings item
270
Min #ratings user
20
Max #ratings user
2,314
Min #ratings item
1
Max #ratings item
3,428
items/users is associated to a large majority of ratings. In particular, as shown in Figure 4.1(b),
10% of the items (resp. users) involve 40% of the ratings. Finally, Figure 4.2 shows the distribution
of ratings and highlights a clear bias toward 4 stars, and a general tendency to provide positive
evaluations.
In the following, we shall analyze the behavior of the algorithms described in the previous
chapters with regard to RMSE, which corresponds to computing the average risk relative to the
squared loss. In the following experiments, we perform a chronological split of the rating matrix,
by retaining the ﬁrst 80% of the triplets as training data for learning the models, and using the
remaining 20% as test data for measuring the performance.
Mixture Models and Rating Prediction.
In a ﬁrst set of experiments, we compare some basic
approaches based on latent factor modeling. ese include: the Mixture Model (MMM); User
Community Model (both Gaussian and multinomial; UCMG/UCMM); Probabilistic Latent Se-
mantic Analysis (GPLSA/PLSA); and Probabilistic Matrix Factorization (PMF).² For all these
methods, we study the performances in RSME for increasing numbers of latent factors. In par-
ticular, we range the latter within the values f2KgKD1;:::;7. Figure 4.3 reports both performances
in prediction accuracy and running times.
We can see a substantial diﬀerence between Gaussian and multinomial approaches. In par-
ticular, the latter tend to produce a higher error rate, especially with a high number of factors. On
the contrary, Gaussian models tend to outperform all the remaining approaches. e explanation
is twofold. First, the speciﬁcation of the likelihood in the Gaussian models tends to include a
component that relates to the RMSE directly. Hence, optimizing the likelihood corresponds to
optimizing the RMSE as well. Secondly, RMSE tends to penalize large errors in predictions:
that is, predicting four stars where the actual value is one has a higher impact on the RMSE than
predicting two stars. is eﬀect is not reﬂected in the log likelihood corresponding to multinomial
models, while it is fully considered by Gaussian models.
²e code for PMF is kindly provided by Russian Salakhutdinov at http://www.utstat.toronto.edu/~rsalakhu/code.
html.

92
4. EXPLOITING PROBABILISTIC MODELS



    






MovieLens1M - Items
Cumulative Frequency
Number of Occurences
10
10
2
10
3
1
10
10
2
10
3
1
 





MovieLens1M - Items
Cumulative Frequency
Number of Occurences
10
10
2
10
3
1
10
2
10
3
(a) Cumulative distributions
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
MovieLens1M−Items
% of ratings
% of items
0
20
40
60
80
100
0.1
1
10
100









MovieLens1M - Items
% of users
% of ratings
100
10
1
0
20
40
60
80
100
0.1
(b) Lift charts
Figure 4.1: Distribution of evaluations in MovieLens.
In an attempt to carefully analyze the rating prediction pitfalls, in Figure 4.3(b), we plot the
contribution to the RMSE in each single evaluation in V by the probabilistic techniques under
consideration and considering Item-Avg acts as baseline. Predictions exhibit a good accuracy for
values 3–4, and their performance is weak on border values, namely 1; 2; and 5. is is mainly
due to the nature of RMSE, which penalizes larger errors.
e learning time is shown in Figure 4.3(c). All methods scale linearly in the number of
topics, and the UCM approaches exhibit the largest overhead.
We now turn our attention to the co-clustering approaches, where latent factors compo-
nents exhibit a more complex structure. Notably, complex patterns can be better detected by
means of co-clustering approaches, as the latter aim at partitioning data into homogeneous blocks,
enforcing a simultaneous clustering on both dimensions of the preference data. is highlights
the mutual relationships between users and items. In this respect, co-clustering approaches should

4.1. PROBABILISTIC MODELING AND DECISION THEORY
93
Percentage of Ratings (%)
Rating Values
1
2
0
10
20
30
40
3
4
5
Figure 4.2: Distribution of ratings in MovieLens.
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
RMSE
Number of Topics
MMM
UCMM
UCMG
PLSA
GPLSA
PMF
2
4
0.90
0.95
1.00
1.05
8
16
32
64
128
(a) RMSE
RMSE
Rating Values
1
2
MMM(4)
UCMM(8)
UCMG(4)
PLSA(4)
GPLSA(4)
PMF(8)
0.0
0.5
1.0
1.5
2.0
3
4
5
(b) Analysis of prediction accuracy
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
Execution Time (secs)
Number of Topics
MMM
UCMM
UCMG
PLSA
GPLSA
PMF
2
4
0
10000
20000
30000
8
16
32
64
128
(c) Execution time (in seconds)
Figure 4.3: Performance on MovieLens.
be considered in a broader sense, for their capability to deeply understand the hidden relation-
ships among users and products they like. Examples in this respect are user communities, item
categories, and preference patterns within such groups. Besides their contribution to the mini-
mization of the prediction error, these relationships are especially important, as they can provide
a faithful yet compact description of the data, which can be exploited for better decision making.
Surprisingly, co-clustering approaches seem able to provide accurate predictions as well, and
they represent an upgrade of the basic latent factor methods. Figure 4.4 shows the contour plot
of both the BMM and the FMM for increasing values of user and item factors. e performance
of BMM clearly improves that of its uni-dimensional counterpart MMM, and is in line with
the performance of GPLSA and UCMG. On the other side, FMM provides extremely good
results for an increasing number of topics. is is a behavior we observed before, with GPLSA

94
4. EXPLOITING PROBABILISTIC MODELS
and UCMG as well, in Figure 4.5. Apparently, these methods give better results with more topics,
which, in a sense, is unsatisfying and intuitively not natural. We shall comment on this peculiarity
further in this chapter.
e computational overhead due to the complexity of the learning procedure is apparent
in Figures 4.4(c) and 4.4(d). In particular, the timings for the FMM model are extremely high.
is is somehow surprising, since FMM appears to be an upgrade of the PLSA model.
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
0.9290
RMSE
0.9245
0.9200
0.9155
0.9110
0.9065
0.9020
0.8975
0.8930
0.8885
0.8840
(a) RMSE for FMM
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
0.9290
RMSE
0.9286
0.9282
0.9278
0.9274
0.9270
0.9266
0.9262
0.9258
0.9254
0.9250
(b) RMSE for BMM
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
5038.60
Time
minutes
4535.01
4031.42
3527.83
3024.24
2520.65
2017.06
1513.47
1009.88
506.29
2.70
(c) Running time for FMM
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
7799.0
Time
seconds
7020.7
6242.4
5464.1
4685.8
3907.5
3129.2
2350.9
1572.6
794.3
16.0
(d) Running time for BMM
Figure 4.4: Performance of co-clustering approaches.
Bayesian Modeling and Rating Prediction.
In this section we analyze the Bayesian formulations
discussed in Chapter 3. While traditional factor modeling relies on maximum likelihood estima-
tion for model inference, the Bayesian formulations are better suited to the sparsity of the rating

4.1. PROBABILISTIC MODELING AND DECISION THEORY
95
matrix and less susceptible to overﬁtting. In this respect, we expect that the best performances
can be obtained by exploiting these models.
Once again, the methods based on matrix factorization outperform the other methods. As
already explained, the likelihood of these models has a direct correspondence with the squared loss
minimization. In addition, Bayesian marginalization plays a major role in improving the results.
is is evident if we compare the performance of PMF with those of BPMF³ and PPMF,⁴ which
are Bayesian upgrades of the former.
By contrast, neither URP nor BUCM exhibit competitive performances. As for the
BUCM, there are two aspects to consider. First, it provides a multinomial model for the ratings,
which we have already seen are weaker than Gaussian models. Second, the focus of this model is
on free prediction, and, hence, the resulting likelihood does not directly optimize the probability
p.rju; i/, which is, conversely, necessary for accurate predictions. Also, the performance of URP
is somehow disappointing, if we consider that the latter is aimed at optimizing the likelihood of
a forced prediction P.rju; i/ that is still modeled as a Gaussian.
As for what the scalability is concerned, it seems that the variational approximation in the
PPMF introduces a signiﬁcant overhead over the other methods, as we can see from Figure 4.3(c).
As for the URP, the overhead essentially is due to the fact that the sampling procedure does not
reach a fast convergence, and it is stopped after 3,000 iterations.
●
●
●
●
●
●
●
●
RMSE
Number of Topics
URP
BPMF
PPMF
BUCM
2
4
0.88
0.86
0.90
0.92
0.94
0.96
0.98
8
16
32
64
128
(a) RMSE
RMSE
Rating Values
1
2
URP(16)
BPMF(128)
PPMF(128)
BUCM(32)
0.0
0.5
1.0
1.5
2.0
3
4
5
(b) Analysis of prediction accuracy
●
●
●
●
●
●
●
●
Execution Time (secs)
Number of Topics
URP
BPMF
PPMF
BUCM
2
4
5000
0
10000
15000
20000
25000
8
16
32
64
128
(c) Execution time (in seconds)
Figure 4.5: Performance on MovieLens.
Finally, we present the performance of the Bayesian hierarchical methods in Figure 4.6.
Since these models were introduced to accommodate hierarchical modeling and rating prediction,
the predictive accuracy exhibited by both models over unobserved ratings is comparable and, in
some cases, even better than the other probabilistic approaches illustrated so far. Interestingly,
the general trend shown by the other co-clustering approaches is conﬁrmed. As for the BH-free
³e code is again provided by Russian Salakhutdinov in http://www.utstat.toronto.edu/~rsalakhu/code.html.
⁴Available at http://www-users.cs.umn.edu/~shan/ppmf_code.html.

96
4. EXPLOITING PROBABILISTIC MODELS
approach, it is worth noticing that it overcomes the BUCM approach: since both methods model
the rating in a similar manner, this result shows that the hierarchical structure provides substantial
information for boosting the accuracy of prediction. Again, these methods exhibit a signiﬁcant
computational overhead over “simpler” methods, as witnessed by the Figures 4.6(c) and 4.6(d).
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
0.969
RMSE
0.963
0.957
0.951
0.945
0.939
0.933
0.927
0.921
0.915
0.909
(a) RMSE for BH-free
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
1.0290
RMSE
1.0163
1.0036
0.9909
0.9782
0.9655
0.9528
0.9401
0.9274
0.9147
0.9020
(b) RMSE for BH-forced
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
4681.0
Time
minutes
4213.2
3745.4
3277.6
2809.8
2342.0
1874.2
1406.4
938.6
470.8
3.0
(c) Learning time for BH-free
128
64
32
16
8
4 
2
2
4
8
16
32
User Topics
Items Topics
64
128
5396.0
Time
minutes
4856.7
4317.4
3778.1
3238.8
2699.5
2160.2
1620.9
1081.6
542.3
3.0
(d) Learning time for BH-forced
Figure 4.6: Bayesian hierarchical co-clustering and RMSE.
We conclude this section by summarizing the results obtained in the above experiments:
Table 4.2 reports, for each method discussed in the section, the best RMSE achieved and the
required number of latent factors exploited.
4.1.2
RECOMMENDATION ACCURACY
e testing methodology based on the minimization of statistical error metrics such as RMSE has
important limitations, mainly because the assumption “improvements in RMSE would reﬂect into

4.1. PROBABILISTIC MODELING AND DECISION THEORY
97
Table 4.2: Summary results for RMSE
Model
Number of Topics
RMSE
MMM
4
0:9287
UCMM
8
0:9788
UCMG
4
0:9148
PLSA
4
0:9242
GPLSA
4
0:9241
URP
16
0:9159
PMF
8
0:8821
BPMF
128
0:8585
PPMF
128
0:8621
BUCM
32
0:9212
FMM
64  128
0:8843
BMM
16  4
0:9247
BH-Free
32  32
0:9085
BH-Forced
4  8
0:9025
better recommendations” does not necessarily hold. In [47], Cremonesi et al. review and compare
the most common CF approaches to recommendation in term of the accuracy of the recom-
mendation lists, rather than on the rating prediction accuracy based on RMSE. eir analysis
shows that cutting-edge approaches, characterized by low RMSE values, achieve performances
comparable to naive techniques, whereas simpler approaches, such as the pure SVD, consistently
outperform the other techniques. In an attempt to ﬁnd an explanation, the authors impute the
contrasting behavior with a
“limitation of RMSE testing, which concentrates only on the ratings that the user provided
to the system, [and consequently] misses much of the reality, where all items should count,
not only those actually rated by the user in the past.” [47]
Pure SVD rebuilds the whole preference matrix in terms of latent factors, by considering both ob-
served and unobserved preference values. is approach better identiﬁes the hidden relationships
between both users and items, which in turn results in a better estimation of the item selection.
In an attempt to better analyze this aspect, we can turn our attention again on the dis-
tinction between forced and free prediction and see how these alternative modeling choices can
impact the ranking pu
i exploited in the evaluation protocols discussed in Chapter 1, with partic-
ular reference to the Algorithm 1 and 2.
Predicted Rating.
When explicit preferences are available, the most intuitive way to provide
item ranking in the recommendation process relies on the analysis of the distribution over pref-
erence values P.rju; i/. Given this distribution, there are several methods for computing the

98
4. EXPLOITING PROBABILISTIC MODELS
ranking for each pair hu; ii; here again, we resort to the expected rating pu
i D EŒRju; i deﬁned
in Equation 4.2. e idea is that a recommendation list should contain only items that a user will
like. Hence, if two items achieve a diﬀerent expected rating, by comparing the latter we can pro-
vide a way to express preferences in the recommendation list. Alternative measures can consider
whether a given item will obtain a high preference, i.e.,
pu
i D P.r  tju; i/ D
Z C1
t
P.rju; i/ dr;
where t represent a rating threshold: for example, by setting t D rT, we can rank items by the
probability that they’ll get a rating higher than the mean rating.
Following [47], we consider Item-Avg and Top-Pop as baselines and compare some selected
approaches with respect to Pure-SVD matrix approximation with 50 factors. We then consider
again the PMF, BPMF, PLSA, URP, and BH-forced. All these methods are characterized by
their capability of computing the above mentioned ranking functions. By exploiting the respective
ranking, we then compute the recommendation accuracy by considering a sample size D D 1; 000
and an increasing size of the recommendation list. e behavior of these algorithms is shown
in Figure 4.7.
●●●●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●
●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
(a) User satisfaction
●●●●●●●●●●●●●●●●●●●●
●
●
●●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●●●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●
●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
(b) Precision/recall
Figure 4.7: Recommendation accuracy, exploiting the expected rating.
is brief analysis conﬁrms that there is no monotonic relationship between RMSE and
recommendation accuracy. Considering user satisfaction, almost all the probabilistic approaches
fall between the two baselines. Pure SVD signiﬁcantly outperforms the best probabilistic perform-
ers, namely BPMF and PLSA. e trend for probabilistic approaches does not change considering

4.1. PROBABILISTIC MODELING AND DECISION THEORY
99
recall and precision, but in this case not even the pure-SVD is able to outperform Top-Pop, which
exhibits a consistent gain over all the considered competitors. Also, it’s surprising that the PLSA
model, particularly weak in RMSE, outperforms the matrix factorization approaches.
In general, by comparing the approaches to the baselines, we can conclude that ranking by
the expected value does not seem an adequate tool for providing accurate recommendation lists,
nor does any variant of this approach.
In an attempt to carefully analyze the rating prediction pitfalls, we can consider again Fig-
ure 4.3(b). e penalization of border values clearly supports the thesis that low RMSE does not
necessarily induce good accuracy, as the latter is mainly inﬂuenced by the items in class 5 (where
the approaches are more prone to fail). It is clear that a better tuning of the ranking function
should take this component into account. Also, by looking at the distribution of the rating values,
we can see that the dataset is biased toward the mean values, and more generally the low rating
values represent a lower percentage. is explains the tendency of the expected value to ﬂatten
toward a mean value (and hence to fail in providing an accurate prediction). On the other hand,
low values are rarer in the dataset. at is, people are inclined to provide only good ratings, thus
making the ranking based on preference values less reliable.
Combining Item Selection and Relevance.
e rank pu
i necessary for a recommendation list, as
described in Chapter 1, does not necessarily depend on the prediction of an explicit rating value
Oru
i . In particular, for approaches based on the modeling of implicit preferences, the rank of each
item i, with regards to the user u, can be computed as the mixture:
pu
i , P.iju/ D
K
X
kD1
P.kju/P.ijk/;
(4.3)
where P.ijk/ is the probability of selecting i within the topic k.
When ratings are available, we can still boost the ranking of models that directly support
free selection, by forcing the selection process to concentrate on relevant items. For example, we
can upgrade either the expected rating,
pu
i ,
Z
r  p.r; iju/ dr D P.iju/EŒrju; i;
or the likelihood for a high preference,
pu
i , P.i; r > rTju/ D P.iju/P.r > rTju; i/:
(4.4)
In both cases, the rank of an item considers the probability that an item is selected, and, hence,
higher ranks are provided to items more likely to be selected.
Including the item selection component in the ranking has an apparent counter-intuitive
eﬀect: popular average-rated items are likely to get better ranking than niche, high-rated items.
Yet, explicit modeling of item selection plays a crucial role with accurate recommendation lists.

100
4. EXPLOITING PROBABILISTIC MODELS
is eﬀect has been studied in details in [17, 19, 20] and we summarize the main results in
Figure 4.8.
●●●●●●●●●●●●●●●●●●●●
●
●
●
●
●
●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●●●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●
●
●
●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●
●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
(a) User satisfaction
●●●●●●●●●●●●●●●●●●●●
●
●
●
●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●
●
●
●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●
●
●
●
●●●●●●●●●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
(b) Precision/recall
Figure 4.8: Recommendation accuracy achieved by probabilistic approaches considering item selec-
tion and relevance as ranking functions.
Figure 4.8 compares the recommendation accuracy achieved by probabilistic models that
employ item-selection (LDA, Equation 4.3) and item-selection & relevance (BUCM, UCM, and
BH-free, Equation 4.4). is evaluation conﬁrms the importance of the selection component in
the recommendation process. All the approaches signiﬁcantly outperform the pure SVD, and the
best result is obtained by the approach combining the item selection and relevance in a Bayesian
setting (Bayesian UCM). Notably, a quite simple model like LDA obtains a consistent gain with
regard to both the SVD and the Top-Pop. Compared to the results in Figure 4.7, these results
show the apparent mismatch between two opposed situations: the explicit modeling of item se-
lection boosts the accuracy of recommendation lists, although it seems to negatively impact on
prediction accuracy. e latter is mainly due to the underlying optimization strategy: optimizing
the likelihood in these models does not have a direct correspondence with the optimization of the
RMSE, like it happens, e.g., in the approaches based on matrix factorization. As a consequence,
these models are more general and they provide a better response in recommendation accuracy.
4.2
BEYOND PREDICTION ACCURACY
As discussed in Chapter 1, the accuracy of a recommender system is just one of the relevant dimen-
sions in evaluating its eﬀectiveness: concepts like novelty, serendipity, diversity, and coverage are

4.2. BEYOND PREDICTION ACCURACY
101
very important for the recommendation quality improvement and they are still a matter of study.
As users may exhibit interest in diﬀerent topics, it is important to provide them with recommen-
dation lists that cover their topics of interests, as well as to avoid monotonous recommendations
[207], by maximizing the diversity of the lists provided in each session.
Here, we focus on the application of probabilistic technique to the aforementioned dimen-
sions of analysis. As we show in Section 4.2.1, the latent variable modeling, exploited within a
probabilistic framework, oﬀers some important, and easily interpretable, insights into the users’
purchase and preference patterns. In Section 4.1.2 we study how the data analysis can be extended
to the case of co-clustering, and, ﬁnally, in Section 4.2.3 we discuss the application of probabilistic
topic models for the generation of diverse recommendations.
4.2.1
DATA ANALYSIS WITH TOPIC MODELS
Identifying groups of similar-minded users is a powerful tool for developing targeted marketing
campaigns for communities of users who exhibit the same preference patterns. One of the main
advantages of probabilistic latent factor models is to provide a compact representation of the data,
by highlighting hidden relationships between the modeled entities, which, in our case, are users
and items. In this respect, models can be used to summarize preference patterns in terms of latent
topics, which, in turn, can be exploited to detect communities of like-minded users or similar
items.
Towards this goal, we can apply the methodology proposed in [100], which focuses on
the analysis of implicit feedback (web sessions), by applying PLSA to (i) understand users’ pref-
erence and interests, (ii) infer the underlying task of a web-browsing session, and (iii) discover
hidden semantic relationships between users and resources (web pages, products, etc.). Assume
we have a dataset of implicit co-occurrence pairs hu; ii, where each pair encodes the fact that the
corresponding user u purchased/viewed/consumed resource i. Preference patterns easily can be
analyzed if the underlying probabilistic model enables the estimation of the components P.kju/
(representing the interest of the user in the k-th topic), P.ujk/ (representing the probability of
observing u relative to topic k), the dual P.ijk/ (representing the probability of observing u rela-
tive to topic k), and a prior probability P.k/ that a user is associated with topic k, which generally
can be obtained by marginalizing over users:
P.k/ D
X
u
P.kju/P.u/:
Labeling Topics.
Some speciﬁc topic models, such as PLSA or LDA, associate latent factors
with a speciﬁc predictive distribution over items, modeling an abstract preference pattern where
some items are most probable given a topic. However, these models do not associate any auto-
matic a priori meaning with the states of the latent factor variables. One of the most important
challenges in topic analysis is to associate each topic with a set of meaningful labels that can be
used to interpret the underlying semantic concept. e task of topic labeling is generally manual:

102
4. EXPLOITING PROBABILISTIC MODELS
the analyst subjectively selects a set of labels that match the category (theme, genre) of the more
likely items for each considered topic.
In the context of CF data, this task can be facilitated by exploiting the predictive distri-
bution in order to provide a selection of characteristic items. Intuitively, a characteristic item for
a given topic k is an item that exhibits a high probability of being observed, given the consid-
ered topic, and a low probability, given a diﬀerent topic. According to [100], we can rank items
according to the following score:
score.i; k/ D P.ijk/P.kji/;
where
P.kji/ D
P.ijk/P.k/
P
k0 P.ijk0/P.k0/:
en, characteristic items for the topic k are those items associated with the highest score. e
top-10 characteristic items for Movielens data are provided in Table 4.3.
e task of topic labeling can be also be cast as a discrete optimization problem [129]. Let
L be a list of items and assume that we can compute the probability P.ijL/. en, L is a good
representative set for k if the latter probability is a good approximation of P.ijk/ in terms of
Kullback-Leibler (KL) divergence:
KL.kjjL/ D  X
i
P.ijk/ P.ijk/
P.ijL/:
Now, P.ijL/ can be deﬁned by resorting to the set S.L/ D fu 2 UjIR.u/ \ L ¤ ;g of all users
that chose items in L before. en
P.ijL/ ,
1
jS.L/j
X
u2S.L/
X
k
P.ijk/P.kju/;
where the latter deﬁnition encodes the intuition that an item is probable in L if it is likely in all
users that adopted items in L before.
Identify Communities of Like-Minded Users.
e projection of each user proﬁle into the latent
topic space can be used to detect communities of users who exhibit the same preference patterns.
Given a set of K topics, we can directly partition users into homogenous groups by considering
the dominant topic of their observed preference proﬁle:
cluster.u/ D argmax
k
P.kju/:
For each user community, identiﬁed by a latent factor k, we can identify prototypical users by
scoring them according to the measure:
score.u; k/ D P.kju/P.ujk/:

4.2. BEYOND PREDICTION ACCURACY
103
Table 4.3: Top-10 characteristic movies for topic in Movielens1M—LDA(10)
Topic 1
Topic 2
Topic 3
Topic 4
Topic 5
Fly
American Beauty
Crying Game
Casablanca
Rock
Alien
Gladiator
Like Water for Chocolate
Chinatown
Total Recall
Rocky Horror Picture Show
Sixth Sense
Player
North by Northwest
Die Hard 2
Blade Runner
Austin Powers
Secrets and Lies
Maltese Falcon
Mission: Impossible
Alien 2
Mission: Impossible 2
Boys Don’t Cry
Annie Hall
Independence Day
Aliens
Erin Brockovich
Ice Storm
African Queen
Hunt for Red October
ing
American Pie
Dead Man Walking
Rear Window
True Lies
Twelve Monkeys
Being John Malkovich
Run Lola Run
e Graduate
Speed
Army of Darkness
e Patriot
Boogie Nights
Manchurian Candidate
Clear and Present Danger
Alien: Resurrection
X-Men
Big Night
Some Like It Hot
Fugitive
Topic 6
Topic 7
Topic 8
Topic 9
Topic 10
Rock
e Silence of the Lambs
Groundhog Day
Jerry Maguire
Beauty and the Beast
Total Recall
Fargo
Four Weddings and a Funeral
As Good As It Gets
Lion King
Die Hard 2
Star Wars V
Clueless
Titanic
Aladdin
Mission: Impossible
Star Wars IV
e Full Monty
Ghost
Snow White and the Seven Dwarfs
Independence Day
Shawshank Redemption
Shakespeare in Love
Forrest Gump
Little Mermaid
Hunt for Red October
Saving Private Ryan
Toy Story
American President
Fantasia
True Lies
Pulp Fiction
Forrest Gump
Speed
Lady and the Tramp
Speed
Raiders of the Lost Ark
ere’s Something About Mary
A Few Good Men
Cinderella
Clear and Present Danger
Schindler’s List
When Harry Met Sally
Sleepless in Seattle
Peter Pan
Fugitive
American Beauty
Wayne’s World
League of eir Own
Willy Wonka and the Chocolate Factory

104
4. EXPLOITING PROBABILISTIC MODELS
Alternatively, the latent topics can devise an alternate feature space upon which to map each
user. at is to say, we can exploit the predictive distribution θu D f#u;kgkD1;:::;K (where #u;k D
P.kju/) as an alternative representation of u in the latent space of the K factors. en, users can
be clustered in communities by measuring their similarity within this latent space:
dist.u; v/ D KL.θujjθv/ C KL.θvjjθu/;
where
KL.θujjθv/ D  X
k
#u;k log #u;k
#v;k
:
Clusters can then be formed using standard similarity-based approaches.
Online Task Discovery.
Probabilistic topic models can be exploited in e-commerce scenarios,
or, more generally, in situations where they exhibit a behavior partitioned into sessions. A typical
example is when the users browses a website looking for a book on a speciﬁc subject. In such a
case, the prediction of the underlying subject (represented by a latent factor here) is useful for a
more appropriate presentation of the available catalog, as well as to facilitate the search.
Speciﬁcally, we assume that IR.u/ can be partitioned into S1.u/; : : : ; SS.u/, where
Sj .u/  IR.u/ represents the j-th session in temporal order. Also, let w.u; i; j/ denote the
number of times that the user u chose item i within Sj .u/, and S<j .u/ D S
j 0<j Sj 0.u/ be the
set of all the previous web browsing sessions associated with same user. For a given user session j,
we can compute its distribution over topics by looking at the likelihood of the items in the current
session [194]:
P.kjSj .u/; u/ D
Q
i w.u; i; j/P.ijk/P.kjS<j .u/; u/
P
k0
Q
i w.u; i; j/P.ijk0/P.k0jS<j .u/; u/;
where
P.kjS<j .u/; u/ D
Q
i
P
0<j jw.u; i; j 0/P.ijk/P.k/
P
k0
Q
i
P
0<j jw.u; i; j 0/P.ijk0/P.k0/:
4.2.2
PATTERN DISCOVERY USING CO-CLUSTERS
e probabilistic formulation mixture model provides a powerful framework for discovering hid-
den relationships between users and items. As shown above, such relationships can have several
uses in users segmentation, product catalog analysis, etc. ose approaches can be further reﬁned
by considering a co-clustering structure, as proposed by approaches such as the FMM/BMM or
the Bayesian hierarchical models. In general, given two diﬀerent user clusters that group users
who have shown a similar preference behavior, a co-cluster allows the identiﬁcation of commonly
rated items and categories for which the preference values are diﬀerent. For example, two user
communities might agree on action movies while completely disagreeing on romance movies. e
identiﬁcation of the topics of interest and their sequential patterns for each user community lead

4.2. BEYOND PREDICTION ACCURACY
105
to an improvement of the quality of the recommendation list and provide the user with a more
personalized view of the system.
Co-Cluster Analysis.
Given a co-cluster hk; li, we can analyze the corresponding distribution
of rating values to infer the preference/interest of the users belonging to the community k on
an item of the category l. Figure 4.9 graphically shows a block mixture model with ten users
clusters and nine item clusters built on the MovieLens dataset. A hard clustering assignment
has been performed both on users and items: each user u has been assigned to the factor c such
that c D argmaxkD1; ;K P.kju/. Symmetrically, each item i has been assigned to the cluster
d D argmaxlD1; ;L P.lji/.
Figure 4.9: Blocks in the Movielens1M rating matrix.
e background color of each block hk; li describes both the density of ratings and the
average preference values given by the users (rows) belonging to the k-th group on items (columns)
of the l-th category: the background intensity increases with the average rating values of the co-
clusters, which are given in Table 4.4. Each point within the co-clusters represents a rating, and
again, a higher rating value corresponds to a more intense color.
e analysis shows interesting tendencies: for example, users belonging to the user commu-
nity c1 tend to assign higher rating values than the average, and items belonging to item category
d6 are the most appreciated. A zoom of portions of the block image is given in Figure 4.10. Here,
two blocks are characterized by opposite preference behaviors: the ﬁrst block contains few (low)
ratings, whereas the second block exhibits a higher density of high value ratings.

106
4. EXPLOITING PROBABILISTIC MODELS
Table 4.4: Gaussian means for each block
d1
d2
d3
d4
d5
d6
d7
d8
d9
c1
3:4
3:59
3:59
4
2:91
4:43
3:59
2:93
3:65
c2
2:23
2:2
2:92
2:79
2
3:45
2:07
1:80
2:51
c3
2:11
3:24
3
3:66
2
4:17
1
1:03
5
c4
2:45
2:69
2:54
3:2
2:43
3:74
2:51
2
2:56
c5
1
1:79
1
2:32
1
2:98
1:66
1
1:75
c6
2:93
3:07
3
3:57
2:20
4:09
2:9
2:3
3:16
c7
1
3:56
3:9
3:7
3:64
3:39
4
3:49
2
c8
2:25
2:26
1:62
3:27
1
4:17
4:54
1
2:45
c9
4:08
3:24
4:40
3:54
5
4
3:71
4:5
5
c10
1:91
2:82
1
2:7
4:3
2:2
1
4
2
(a) Co-cluster .c5; d8/: Mean rating 1
(b) Co-cluster .c1; d6/: Mean rating 4.43
Figure 4.10: Co-cluster analysis.
e tasks of labeling and task discovery easily can be adapted to blocks representing simul-
taneous co-clusters. For example, we can exploit genres associated with movies to characterize
item clusters, and, consequently, to associate a degree of interest of each community for the gen-
res associated with each item cluster.
Modeling Topic Transitions.
When preferences exhibit a temporal order, we can also detect
sequential connections among topics by analyzing, e.g., which item categories are likely to next
capture the interests of a user. Sequential patterns can be modeled by exploiting Markov models.
e latter are probabilistic models for discrete processes characterized by the Markov properties.
We adopt a Markov chain property here, i.e., a basic assumption that states that any future state
only depends from the present state. is property limits the “memory” of the chain, which can be
represented as a digraph where nodes represent the actual states and edges represent the possible
transitions among them.
Assuming that the last observed item category for the considered user is di, the user could
pick an item belonging to another topic dj with probability p.dj jdi/. We shall focus on a more
detailed treatment of Markov models in Chapter 6. For the moment, we provide a naive approach
for the estimation of the transition probabilities, starting from a jL C 1j x jL C 1j transition count

4.2. BEYOND PREDICTION ACCURACY
107
matrix Tc, where Tc.i; j / stores the number of times that category j follows i in the rating proﬁle
of the users.⁵
e estimation we provide is rather simple, corresponding to a simple frequency count:
p.dj jdi/ D
Tc.i; j/
PLC1
jD1 Tc.i; j 0/
:
Figure 4.11 represents the overall transition probability matrix, which highlights some
strong connections among given categories. For example, with item categories having drama as
the dominant genre, d4, d6, and d9 are highly correlated, as well as d2, d7, and d8, which corre-
spond to comedy movies.
d1
d1
d2
d3
d4
d5
d6
d7
d8
d9
β
³
d2
d3
d4
d5
d6
d7
d8
d9
Figure 4.11: Transition probabilities matrix.
It is interesting to compare how the transition probabilities change within diﬀerent user
communities. Figure 4.12 shows the transitions for three diﬀerent communities. Notice that,
besides common transition patterns, each community has some distinctive transitions that char-
acterize their population. For all the considered user communities, the most likely initial item
category is d6; while the ﬁrst and the last community reproduced in the example show a strong
attitude corresponding to the transition d8 ! d2, this is, instead, a weak pattern within c7. e
same consideration can be done for the transition d9 ! d7, which is strong for c7 and c10, while
users belonging to c3 are more prone to the transition toward d6.
e analysis of the transition probabilities can be exploited for generating new recommen-
dations enforcing topic diversity [211] in the top-K lists of items by taking into account not only
the current topic of interest, but even the ones that are more likely to be connected to it.
4.2.3
DIVERSIFICATION WITH TOPIC MODELS
Given that the spectrum of the user interest can be wide, recommendations should ideally cover
the latter as much as possible, by balancing accuracy and coverage in terms of abstract topics. is
design principle becomes more important if we consider that recommendations and purchases
⁵We assume two further states , representing the initial choice, and ˇ, representing the last choice.

108
4. EXPLOITING PROBABILISTIC MODELS
d1
d1
d2
d3
d4
d5
d6
d7
d8
d9
β
³
d2
d3
d4
d5
d6
d7
d8
d9
(a) User community c3
d1
d1
d2
d3
d4
d5
d6
d7
d8
d9
β
³
d2
d3
d4
d5
d6
d7
d8
d9
(b) User community c7
d1
d1
d2
d3
d4
d5
d6
d7
d8
d9
β
³
d2
d3
d4
d5
d6
d7
d8
d9
(c) User community c10
Figure 4.12: Transition probabilities matrix.
can be performed by households. It is clear that each member of the family can exhibit diﬀer-
ent interests, and their actual identity is hidden by the system, which just records a unique user
identiﬁer.
Traditional approaches to recommendation often fail in providing diverse recommenda-
tions, as they tend to gather similar items in the same recommendation list. Unfortunately, this
directly aﬀects the novelty of recommendations: as items to be recommended can be selected by
the ranking according to the highest mode of the user-speciﬁc distribution on interests/catalog
categories, the ﬁnal recommendation list will presumably contain very similar items. e lack
of diversiﬁcation enhances the online ﬁlter bubble [147], overplaying personalization, preventing
concept drifts and the discovery of novel items.
Diversity rapidly became one of the most important dimensions of analysis and evaluation
for recommendation techniques, attracting the attention of both academic and industry commu-
nities. e main challenge relies on the intrinsic evaluation of this measure. While prediction
and recommendation accuracy metrics assess the accuracy at each individual entry, to evaluate
diversity, we need to consider the whole recommendation list [126]. Assuming that a similarity
function between items is available, one way of enforcing diversity is to re-rank items by pro-
moting intra-list dissimilarity [211]. e goal of ensuring both diversity and accuracy for the
recommendation lists provided by the system can be achieved by modeling this setting as a binary
optimization problem [207].
Probabilistic techniques can be exploited to provide diverse recommendations. More specif-
ically, we can promote diversity in two principled ways, which is discussed next.
Proﬁle Partitioning.
e main idea, introduced in [208], is to partition the user proﬁles into
clusters of similar items, and then generate the recommendation lists by selecting items that better
match with each cluster. is approach can be nicely implemented by relying on probabilistic topic
models for preference data modeling. While in Section 4.1.2 the item ranking function in case of
topic models was obtained by marginalizing over all the topics, to enforce diversity, we can select

4.2. BEYOND PREDICTION ACCURACY
109
a subset of topics Zu  2K that best match the interests of the user u and then instantiate the
ranking as:
pu
i D argmax
k2Zu
P.ijk/:
Explicit Diversiﬁcation.
e recommendation list can be computed greedily, by iteratively se-
lecting the item that provides the best compromise between the probability of being selected by
the user and diversiﬁcation with respect to the current list. Following [194], given an item i and
a partial recommendation list L, the xQuaAD objective function [172] for explicit diversiﬁcation
can be instantiated as follows:
 P.iju/ C .1   /P.i; Lju/;
where the ﬁrst component promotes items that are likely to be selected by the user, while the
second one is the likelihood of observing the item i but not the other items in the current list.
e parameter 0    1 implements a tradeoﬀbetween item selection and diversity. Assuming
that, given a topic k, the observation of i is independent of the items already selected, we can
instantiate the latter component as:
P.i; Lju/ D
K
X
kD1
P.kju/P.ijk/
Y
j 2L
.1   P.j jk//:

C H A P T E R
5
Contextual Information
5.1
INTEGRATING CONTENT FEATURES
e previous chapters focused on collaborative ﬁltering techniques, which generate recommen-
dations that are based on the estimate of the correlation of historical rating data across the pop-
ulation of users/items. Content-based ﬁltering is an alternative paradigm that has been used for
recommending items, such as books, web pages, news, etc., that can be deﬁned by informative
content descriptors. It is natural to wonder whether the combination of collaborative and content
ﬁltering provides further advantages in terms of recommendation accuracy or additional applica-
tion scenarios, and whether probabilistic modeling can easily integrate both of these sources of
data. In a sense, collaborative and content-based ﬁltering are complementary views that should
be proﬁtably exploited in a common learning architecture.
In a general setting, we can assume a function 	 W U  I  V 7! Rd that associates each
preference observation hu; i; ri with a d-dimensional feature vector representing speciﬁc informa-
tion associated with the preference observation. Some features may only depend on the underlying
item (e.g., genre or category), or only on the user (such as demographic info like sex, city of resi-
dence, etc.), but, they may also combine aspects of both. e feature vector 	.u; i; r/ can hence
be exploited to provide better recommendations.
ere are several ways to cast the problem of predicting preference values when contextual
information is available as a standard classiﬁcation problem, or even as an ordinal regression prob-
lem. For example, the feature vector can be seen as a more general representation of the logistic
features fk introduced with the log-lineal model discussed in Chapter 2. us, the problem can
be expressed in terms of logistic regression with feature weights b D fˇ1; : : : ; ˇdg, and solved
accordingly. Alternatively, one could ﬁt a linear regression model, by assuming that the rating r
is sampled from a Gaussian distribution centered at bT 	.u; i; r/ with variance ﬁxed variance 2.
ese basic models can be further enhanced to incorporate latent factor information. For
example, in the case of explicit preference ratings, we can extend the basic PMF model shown in
Chapter 3: recall that this model deﬁnes the probability of observing a given rating for a pair hu; ii
as a Gaussian centered on P T
u Qi, where P and Q are the latent feature matrices. e extension
to accommodate content features can be accomplished by still considering the rating value as the
result of sampling from a Gaussian distribution, where, however, the center depends on both the
latent factors P and Q and the feature weights b:
P.rju; i; b; P; Q; / D N .rI P T
u Qi C bT 	.u; i; r/; 2/:

112
5. CONTEXTUAL INFORMATION
e discrete case can be approached in a similar way, but it requires a more reﬁned latent
feature modeling. Here, P and Q represents three-dimensional tensors and the matrix Pr (resp.
Qr) represents the set of latent features associated with rating r. en, the probability of a speciﬁc
rating r can be modeled as:
P.rju; i; b; P; Q; / D
1
Zu;i.b; P; Q/ exp
˚
P T
r;u  Qr;i C bT 	.u; i; r/
	
;
where Zu;i.b; P; Q/ is a normalization factor deﬁned as
Zu;i.b; P; Q/ D
X
r2V
exp
˚
P T
r;u  Qr;i C bT 	.u; i; r/
	
:
Menon and Elkan [131] study the predictive abilities of such models for a wide range of applica-
tions, including recommendation on the Movielens dataset.
e idea behind the models presented so far is the starting point of more advanced ap-
proaches that include side information to achieve better results in prediction accuracy and provide
tools for cold-start recommendation [3, 33, 187].
5.1.1
THE COLD-START PROBLEM
e exceptional sparseness of the rating matrix R poses serious challenges to the application of col-
laborative ﬁltering techniques. In a real-world scenario, observations are available only for a small
fraction of possible user/item pairs, and the distribution of observations is typically heavy-tailed
(see Figure 4.1). Notably, a small fraction of users/items typically accounts for a large fraction of
data, while the remaining are sparsely distributed among others.
Moreover, dynamic systems involve new users and/or items, and the prediction of prefer-
ences is required for these subjects as well. e problem of providing predictions for users/items
with little, or no, historical preference information, is commonly referred to as a cold-start prob-
lem (see Chapter 1). By contrast, warm-start refers to cases in which recommendations must be
provided to users/items for which a suﬃcient number of past preferences in the rating matrix R
is available.
Although eﬀective for warm-start, collaborative ﬁltering approaches fail to address the
cold-start problem. Hence, methods based on the idea shown above, which simultaneously in-
corporate feedback data and user/item features, can provide accurate predictions and smoothly
handle both cold-start and warm-start scenarios.
Following [2], it is convenient to specify 	.u; i; r/ in three components, namely
	.u; i; r/ D .vu; wi; su;i/. Here, vu 2 Rp represents the user-speciﬁc features, ci 2 Rq repre-
sents item-speciﬁc features, and su;i 2 Rs represents features relative to the dyad. en, we can
reﬁne the predictive model by assuming the existence of latent factors fα; β; P; Qg and regression
weights b, which govern the conditional probability of observing a rating value r associated to
the pair hu; ii:

5.1. INTEGRATING CONTENT FEATURES
113
(Continuous rating) r  N .mu;i; 2/, where
mu;i D sT
u;ib C ˛u C ˇi C P T
u QiI
(Discrete rating) r  Disc.fmu;i;rgr2V/, where
mu;i;r / expfsT
u;ib C ˛u C ˇi C P T
r;uQr;ig:
All latent factors can be expressed in terms of further probabilistic regression setting, as speciﬁed
by the following regression equations:
˛u D gT
0 vu C ˛
u;
˛
u  N .0; a˛/I
ˇi D dT
0 ci C ˇ
i ;
ˇ
i  N .0; aˇ/I
Pu D Gvu C U
u ;
U
u  N .0; ˙U /I
Qi D Dci C V
i ;
V
i  N .0; ˙V /:
e Linear Regression Factor Model (LRFM, [2]) implements this setting by assuming a two-stage
generative process. In the ﬁrst stage latent factors are sampled, while in the second stage latent
factors are exploited to generate rating values:
• For each hu; ii:
1. Sample the factors
˛u N .gT
0 vu; a˛/;
ˇi  N .dT
0 ci; aˇ/;
Pu N .Gvu; ˙U /;
Qi  N .Dci; ˙V /;
and compute mu;i D sT
u;ib C ˛u C ˇi C P T
u QiI
2. Sample the rating r:
r  N .mu;i; 2/:
e graphical model for LRFM, depicted in Figure 5.1, shows strong similarities with
the PMF model described in Chapter 2. And in fact, by simply enforcing the hyperparameters
G; D; g0, and d0 to zero we simplify the model to the standard PMF. Furthermore, if we assume,
instead, zero variance on factors, by assuming a˛; aˇ and the covariance matrices ˙U and ˙V to
be zero, the resulting model simpliﬁes to a standard regression model based on content features.
LRFM represents a robust combination of both content and collaborative ﬁltering based on
factor modeling and linear regression. As a result, the model is capable of handling both cold-start
and warm-start in a uniform way.

114
5. CONTEXTUAL INFORMATION
.r.

.
s
.
P
.
˛
.
a˛
.
G
.
g0
.
v
.
Q
.
ˇ
.
aˇ
.
D
.
d0
.
c
.
˙U
.
˙V
.
N  M
.
M
.
N
.
Figure 5.1: Graphical model for LRFM.
e complete data likelihood for a given set X of observations and latent factors  D
fα; β; P; Qg can be expressed as
P.X ; jD; G; g0; d0/ D
Y
hu;i;ri
P.rj; vu; ci; su;i/P.˛ujvu; g0/P.ˇijci; d0/
P.Pujvu; G/P.Qijci; D/:
(5.1)
is joint likelihood can be maximized by resorting to the Stochastic EM procedure (described
in Section A.3), where the E-step corresponds to sampling the  parameters by means of Gibbs
sampling. Posterior probabilities for the latent factors can be expressed in terms of Gaussian
distribution, thus enabling a simple Gibbs step. In addition, the M step consists of ﬁnding the
optimal hyperparameters D; G; g0; d0 given X and the  sampled in the E-step. Again, since
the underlying distributions are Gaussians, the resulting estimation procedure is straightforward
(see [2] for details).
5.1.2
MODELING TEXT AND PREFERENCES
A natural evolution of the modeling proposed so far is to consider the case where each item can
be characterized by meta data available as free text. Textual descriptions are a common in several
scenarios, e.g. content recommendation, and hence they can provide useful information that adds
up to other features naturally represented as vectors in a Euclidean space.
Furthermore, we can consider highly dynamic scenarios, such as recommendation of news
articles, where the notion of item is not even static. In these settings, the set I can be considered
as stream and continuous bursts of new items that need to be appropriately handled; hence, it
is convenient to represent each item through a set of features, and measure how these features

5.1. INTEGRATING CONTENT FEATURES
115
aﬀect the evaluation by users. Textual features in this respect may represent the most signiﬁcant
informative content that can be associated with items.
When dealing with text, it is convenient to abstract its representation to a set of latent
features. Given the bag-of-words representation wi corresponding to the item i, we can assume
that the vector zi represents the set of latent topics, where zi;j is the latent topic associated with
the word wi;j. By the term “words,” we denote any elementary information, such as textual tokens,
entities, etc.
In a matrix factorization setting, the rating associated to a dyad hu; ii can be modeled by
resorting to latent factors α; β; P; Q. In particular, Qi can be interpreted as a representation of
wi within the latent space. However, since wi is associated with zi, it is natural to enforce a
dependency between Qi and zi. Agarwal and Chen in [3] reformulate Qi as the vector Qzi. e
latter, in turn, depends on the topic assignments within zi as follows:
Qzi;k D
1
jwij
X
j
1Jzi;j D kK:
is reformulation leads to the deﬁnition of the fLDA model, shown graphically in Figure 5.2,
and it is a variation of LRFM. Notice that the left-hand side of the graphical model is identical to
LRFM. What diﬀers is the right-hand side, where item observations are modeled. is compo-
nent corresponds to an LDA model, where the sampled topics are exploited upon the generation
of the rating:
• For each hu; ii:
1. Sample the factors
˛u  N .gT
0 vu; a˛/;
ˇi  N .dT
0 ci; aˇ/;
Pu  N .Gvu; ˙U /I
2. For j D f1; : : : ; jwijg:
(a) sample zi;j  Dir./;
(b) sample wi;j  Disc.˚zi;j /;
3. Compute mu;i D sT
u;ib C ˛u C ˇi C P T
u zi;
4. Sample r  N .mu;i; 2/.
Parameter estimation can be accomplished as a variation of the Stochastic EM procedure
discussed above. In practice, the E step consists of a Markov chain where the components α; β
and P; Z are iteratively sampled.
Rather than embedding the LDA annotation within the matrix factorization process, it is
also possible to consider a direct extension of the URP model shown in Chapter 3, which ac-
counts for a textual description of the item. Following the standard topic modeling approach,

116
5. CONTEXTUAL INFORMATION
.r.
s
.

.
P
.
˛
.
a˛
.
G
.
g0
.
v
.
˙U
.
z
.
w
.
ˇ
.
c
.
aˇ
.
d0
.
Φ
.
θ
.

.

.
N  M
.
M
.
jwij
.
N
.
K  W
.
Figure 5.2: Graphical model for fLDA.
each preference observation is associated with a topic k 2 f1;    ; Kg. However, the rating dis-
tribution k;i depends upon the topic assignments relative to the underlying textual description
wi. e generative process can be described as follows:
• For each u 2 U sample θu  Dir.α/.
• For each i 2 I sample ϑi  Dir.λ/.
• For each k 2 f1; : : : ; Kg sample Φk  Dir.β/.
• For each hu; ii:
1. Sample zu  Disc.θu/;
2. For j D f1; : : : ; jwijg:
(a) sample zi;j  Disc.ϑi/;
(b) sample wi;j  Disc.Φzi;j /;
3. Compute mu;i D
1
ni
P
j µzu;zi;j ;
4. Sample r  N .mu;i; 2/.
5.2
SEQUENTIAL MODELING
All probabilistic approaches studied so far propose a data generation process that is based on
the bag-of-words assumption, i.e., such that the temporal order of the items accessed by a user
can be neglected and co-occurrence patterns are used to deﬁne the topic space. However, an

5.2. SEQUENTIAL MODELING
117
alternative view is that traces can be “naturally” interpreted as sequences where the temporal
order is relevant. Ignoring the intrinsic sequentiality of the data may result in poor modeling. So
far, all observations were assumed to be independent and identically distributed. On the other
hand, sequential data may express causality and dependency, and diﬀerent factors can be used
to characterize diﬀerent dependency likelihoods. e focus here is the context in which the user
acts and expresses preferences, i.e., the environment, characterized by side information, where
observations are recorded.
e analysis of sequential patterns has important applications in modern recommender
systems, especially when we are interested in achieving a balance between personalization and
contextualization. For example, in Internet-based streaming services for music or video (such as
Last.fm¹ and Videolectures.net²), the context of the user interaction with the system easily can
be interpreted by analyzing the content previously requested. e assumption here is that the
current item (and/or its genre) inﬂuences the next choice of the user. In particular, if a speciﬁc
user is in the “mood” for classical music (as observed in the current choice), it is unlikely that the
immediate subsequent choice will be a song of a completely diﬀerent genre. Being able to capture
such properties and exploit them in recommendation strategy can greatly improve the accuracy
of the recommendation.
5.2.1
MARKOV MODELS
Sequential correlation between observations can be modeled by relaxing the i.i.d. assumption, i.e.,
by enforcing a dependency between the current observation and the previous ones. In probabilistic
terms, we can assume a temporal ordering x1 : : : ; xN of observations in X, and then express the
probability by using the chain rule
P.X j/ D P.x1/
N
Y
iD2
P.xijx1; : : : ; xi 1; /:
Within this formula, a sequence can be modeled as a stationary ﬁrst-order Markov chain.
• A Markovian process naturally models the sequential nature of the data, where dependen-
cies among past and future tokens reﬂect changes over time that are still governed by similar
features;
• the chain is stationary, as a ﬁxed number of tokens is likely to appear frequently in sequences,
and their joint distribution is invariant with respect to shifts in time;
• the order of the chain is 1 because the possibility that two subsequent tokens share some
features is more likely than that of two tokens distant in time.³
¹http://last.fm
²http://videolectures.net
³It is also worth noticing that higher-order dependencies introduce an unpractical computational overhead, as the number of
parameters grows exponentially with the order of the chain [31, Chapter 13].

118
5. CONTEXTUAL INFORMATION
e simplest way to relax the i.i.d. assumption is to assume that the current observation is inde-
pendent from all the previous observations except the most recent, i.e.,
P.X j/ D P.x1/
N
Y
iD2
P.xijxi 1; /:
A ﬁrst order Markov chain represents a trade-oﬀbetween complexity and expressiveness. For ex-
ample, we can consider a Markovian extension of the multinomial mixture model shown in Fig-
ure 2.2, where the dependency is made explicit: in this model (depicted graphically in Figure 5.3),
we can assume a latent factor associated with a user. Such a latent factor deﬁnes a parameter set
Φ representing the probability of observing a rating given a previous rating. at is, k;r1:r2 rep-
resents the (multinomial) probability of observing r2, given that r1 was observed before and the
latent factor is k.
.r1.
r2
.
:::
.
:::
.
rn
.
z
.

.
Φ
.
K
.
M
.
Figure 5.3: Graphical model for the Markov Mixture Model.
Several variations of this simple model can be proposed. For example, if we restrict our
attention to implicit preferences only, we can assume that Φ models item selection, so that k;i:j
represents the probability that a user associated with topic k will select item j, given that her
previous choice was i. is model was proposed in [37], to analyze the navigation behavior of
users in a website.
In the following, we will still consider implicit preferences, and we focus on extensions
of the basic LDA framework that exploit Markovian dependencies. ese extensions have been
studied in the context of text modeling and natural language processing. In [195, 199], for exam-
ple, authors propose extensions of the LDA model that assume a ﬁrst-order Markov chain for the
word generation process. In the resulting Token-Bigram Model and Topical n-grams, the current

5.2. SEQUENTIAL MODELING
119
word depends on the current topic and the previous word observed in the sequence. We shall see
how such paradigms can be exploited for recommendation.
Bayesian Modeling
e starting point is to reconsider the general formulation of the LDA model. Figure 5.4(a)
provides an alternative graphical view of the latter, where all the selected items are unfolded.
.i1.
i2
.
:::
.
in
.
z1
.
z2
.
:::
.
zn
.
Θ
.
Φ
.
˛
.
ˇ
.
K
.
M
.
(a) LDA
.i1.
i2
.
:::
.
in
.
z1
.
z2
.
:::
.
zn
.
Θ
.
Φ
.
˛
.
ˇ
.
K
.
M
.
(b) Token Bigram
Figure 5.4: LDA and token bigram.
If we consider the observations X as sequences, where each sequence xu , wu;1  wu;2 
: : :  wu;nu is relative to a user u and wu;j is a token representing the j   th item chosen by u
in temporal order, Z encodes the latent topics relative to each selection, while ˚˚˚ and  are the
distribution functions governing the likelihood of X and Z (with respective priors β and α). e
complete likelihood can be expressed as:
P.X ; Z;;˚˚˚jα; β/ D P.X jZ;/P.jβ/P.Zj/P.jα/;

120
5. CONTEXTUAL INFORMATION
where
P.X jZ;/ D
Y
u2U
P.xujzu;/
P.Zj/ D
Y
u2U
P.zujθu/;
(5.2)
and P.Θjα/ P.Φjβ/ represent the usual Dirichlet priors. In the standard LDA setting where all
tokens are independent and exchangeable, the two components can be speciﬁed as
P.xujzu;˚˚˚/ D
Y
mhu;ii
'zm;i
P.zujθu/ D
Y
mhu;ii
#u;zm:
(5.3)
Relaxing the exchangeability assumptions in Equations 5.3 on either xu or zu allows us to
model diﬀerent sequential dependencies. A ﬁrst straightforward extension is to consider xu as a
ﬁrst-order Markov chain, where each token wu;j depends on the most recent token wu;j 1 ob-
served so far. is model was proposed in [195], and the probability of observing a trace becomes:
P.xujzu; ϕ/ D
Nd
Y
j D1
P.wu;j jwu;j 1; zu;j ; ϕ/:
(5.4)
In practice, a token wu;j is generated according to a multinomial distribution ϕzu;j ;wu;j 1, which
depends on both the current topic zu;j and the previous token wu;j  1.⁴ According to this model,
the conjugate prior β accounts for all the possible distributions fϕk;igkD1;:::;KIi2I. e diﬀerence
between the LDA and this token bigram model is shown in Figure 5.4, and the generative model
can be described as follows.
• For each user u 2 U sample the topic-mixture components θd  Dir.E˛/ and sequence
length nd  Poisson./.
• For each topic k 2 f1; : : : ; Kg and token i 2 I;
– Sample token selection components ϕk;i  Dir.β/.
• For each user u 2 U and j 2 f1; : : : ; nug;
– sample a topic zu;j  Disc.θu/;
– sample a token wu;j  Disc.ϕzu;j ;wu;j 1/.
An important aspect to consider is the choice for the Dirichlet prior β. In a general form,
we can assume a family β , fˇk;igk2f1;:::;KgIi2I of Dirichlet coeﬃcients. As shown in [195],
diﬀerent modeling strategies (e.g., shared priors ˇk;r:s D ˇs) can aﬀect the accuracy of the model.
⁴When j D 1, the previous token is empty and the multinomial resolves to Ezu;j , representing the initial status of a Markov
chain.

5.2. SEQUENTIAL MODELING
121
Plugging the above probability within the likelihood equation allows us to exploit the stan-
dard algebraic manipulation already studied for the LDA and its variants, so that the inference
phase can be obtained by means of the well-known stochastic EM strategy, where the E step con-
sists of a collapsed Gibbs sampling procedure for estimating Z, and the M step estimates both
the predictive distributions  and  and the hyperparameters α and β given Z. Within Gibbs
sampling, topics are iteratively sampled, according to the probability:
P.zu;j D kjZ .u;j/; X / /

nk
u;./ C ˛k   1


nk
./;r:s C ˇk;r:s   1
P
s02I nk
./;r:s0 C ˇk;r:s0   1
;
(5.5)
relative to the topic, to associate with the j-th token of u’s trace, where wu;j  1 D r and wu;j D s.
Given Z, the parameters θ and ϕ can be estimated according to the following equations:
#u;k D
nk
u;./ C ˛k
PK
k0D1.nk0
u;./ C ˛k0/
'k;r:s D
nk
./;r:s C ˇk;r:s
P
s02I.nk
./;r:s0 C ˇk;r:s0/
:
(5.6)
ese distributions can be directly exploited for recommendation purposes, by making explicit the
dependency of the current selection from the previous. By denoting with rank.i; u/ the degree of
interest that user u might express for i, we have:
rank.i; u/ D
K
X
kD1
P.ijzu;nuC1 D k; xu/P.zu;nuC1 D kjEd/ D
K
X
kD1
'k;r:i  #u;k;
where r D wu;nu is the last item selected by user u.
Hidden Markov Models
e bigram modeling can be extended by considering diﬀerent kind of dependencies among hid-
den states of the model. In particular, we can assume that the dependencies can occur at a hidden
state. Hidden Markov models (HMMs) [31, Chapter 13] are a general reference framework both
for modeling sequence data and for natural language processing [122]. HMMs assume that se-
quential data is generated by a Markov chain of latent variables, with each observation conditioned
on the state of the corresponding latent variable. e resulting likelihood can be interpreted as an
extension of a mixture model, where the choice of mixture components for each observation is not
selected independently but depends on the choice of components for the previous observation.
By looking again at the LDA model in Figure 5.4(a), we can enforce dependency between
topics, rather than tokens. In Figure 5.5 tokens are considered independent of each other and
related to a latent topic, while a topic depends on the previous ones. However, since topics rep-
resent the ultimate factors underlying a token appearance in the sequence, correlation between
topics can better model an evolution of the underlying themes. Assuming a ﬁrst-order Marko-
vian dependency, the topic bigram model reﬁnes the Equation 5.3 by modeling the probability of

122
5. CONTEXTUAL INFORMATION
.i1.
i2
.
:::
.
in
.
z1
.
z2
.
:::
.
zn
.
Θ
.
Φ
.
˛
.
ˇ
.
K
.
M
.
Figure 5.5: Topic bigram.
a sequence of latent topics as:
P.zujθu/ D
nu
Y
j D1
P.zu;j jzu;j  1; θu/:
(5.7)
e diﬀerence here relies on the distribution generating zu;j, which is a multinomial θu;zu;j  1
parameterized by both u and the previously sampled topic zu;j 1. Again, the generative process
follows straightforwardly.⁵
• For each user u 2 U and topic h 2 f0; : : : ; Kg sample topic-mixture components θu;h 
Dir.α/ and sequence length nu  Poisson./.
• For each topic k D 1; : : : ; K sample token selection components φk  Dir.β/.
• For each u 2 U and j 2 f1; : : : ; nug sequentially:
– sample a topic zu;j  Disc.θu;zu;j  1/;
– sample a token wu;j  Disc.ϕzu;j /.
⁵Here, h D 0 is a special topic that precedes the ﬁrst topic of each trace.

5.2. SEQUENTIAL MODELING
123
By algebraic manipulations we can obtain a closed formula for the joint distribution
P.X ; Zjα; β/, which is the basis for a stochastic EM procedure based on a Gibbs sampler. e
ranking function in the topic bigram model can be obtained by adapting the forward-backward
algorithm (see [31, Section 13.2] for details). It is necessary to build a recursive chain of proba-
bilities, representing a hypothetical random walk among the hidden topics:
rank.i; u/ D
K
X
kD1
P.wu;nuC1 D i; zu;nuC1 D kjxu/
/
K
X
kD1
P.wu;1    wu;nuC1 D i; zu;nuC1 D k/;
which requires solving P.wu;1    wu;nuC1; zu;nuC1/. By algebraic manipulations:
P.wu;1    wu;Nd ; zu;nu D k/ D P.wu;1    wu;Nujzu;Nu D k/P.zu;nu D k/
D 'k;wu;nu
X
h
P.wu;1    wu;Nu 1; zu;Nu 1 D h/#u;h:k:
e result is a recursive equation that can be simpliﬁed into the following  function:
k.xuI 1/ D 'k;wu;1I
k.xuI j/
D 'k;wu;j
X
h
h.xuI j   1/#u;h:k:
erefore, the ranking function can be formulated as:
rank.i; u/ /
K
X
kD1
k.xuI nu C 1/:
ere are several variations of the basic token and topic bigram models. [76] propose an
Hidden Topic Markov Model (HTMM) for text documents. HTTM deﬁnes a Markov chain over
latent topics of the document. e corresponding generative process, depicted in Figure 5.6(a),
assumes that all words in the same sentence share the same topic, while successive sentences can
either rely on the previous topic, or introduce a new one. Topics in a document form a Markov
chain with a transition probability that depends on a binary topic transition variable  . When
 D 1, a new topic is drawn for the n-th sentence, otherwise the same previous topic is used.
HTMM models topic cohesion at the level of single tokens (e.g., words within the same sentence
share the same latent topic), but does not model directly a smooth evolution between topics in
diﬀerent segments that frame a trace. Sequential LDA [54] is a variant of LDA which models a
sequential dependency between sub-topics: the topic of the current segment is closely related to
the topic of its antecedent and subsequent segments. is smooth evolution of the topic ﬂow is
modeled by using a Poisson-Dirichlet process.
e LDA Collocation Model [74] introduces a new set of random variables (for bigram sta-
tus) x, which denotes whether a bigram can be formed with the previous token. More speciﬁcally,

124
5. CONTEXTUAL INFORMATION
as represented in Figure 5.6(b), the generative process speciﬁes for each word both a topic and a
collocation status.
• if xi D 1 then wi is part of a collocation and thus is generated by sampling from a distri-
bution conditioned on the previous word P.wijwi 1; xi D 1/ ;
• otherwise, wi is sampled from a distribution associated to the current topic P.wijzi; xi D
0/.
e collocation status adds a more ﬂexible modeling than the token bigram model, which always
generates bigrams and, according to this formulation, the distribution on bigram does not depend
on the topic.
Finally, the token-bitopic model [22] assumes that tokens are still related to past events.
However, the assumption here is that a token depends on a chain of sequential topics, rather than
a single topic.
2
z1
w2
w1
wNd
z2
zNd
. . .
Nd
. . .
. . .
 
(a) HTTM
z1
w2
w1
wNd
z2
zNd
. . .
X1
X2
xNd
. . .
. . .
(b) Collocation
 
z1
w2
w1
wNd
z2
zNd
M
. . .
. . .
(c) Token-Bitopic
Figure 5.6: HTMM, collocation, and bitopic graphical model for the generation of a document.
5.2.2
PROBABILISTIC TENSOR FACTORIZATION
e sequential evolution of preferences and rating patterns can also be interpreted in terms of
“seasonality” of preference values. roughout this book, we have seen how latent factors are a
powerful tool for capturing the correlations among users and items in a probabilistic settings.
However, correlations can change within time intervals: a user might be interested in sci-ﬁbooks
in the evening, whereas, during the day, the same user can be interested in technical books on
computer science. In this case, trying to explain all the data with one ﬁxed global model would
be ineﬀective. On the other hand, concentrating on the recent choices still does not allow us to
capture a comprehensive behavioral model for the same user.
is notion of sequentiality can be captured by extending the PMF models shown in Chap-
ters 2 and 3. In addition to the factors that are used to characterize users and items, we can also

5.2. SEQUENTIAL MODELING
125
introduce factors for time periods. Intuitively, these factors are associated with a given time pe-
riod, and can represent a correlations among the given time periods and the preferences that users
can express. is approach is discussed in [200] and it is called probabilistic tensor factorization.
Formally, we can assume that observations in X still represent the preference r of user u
for item i, but we also assume that preferences can change over time intervals, so that a tuple
hu; i; r; ti represents the preference at interval t. We also assume that intervals are ﬁnite and they
represent seasonal time frames, i.e., t 2 f1; : : : Sg. e tensor factorization model assumes the
existence of the latent matrices P 2 RMK, Q 2 RNK, and T 2 RSK, so that a rating can be
expressed as:
P.rju; i; t; P; Q; T; / D N .rI
X
k
Pu;kQi;kTt;k; 2/:
e interpretation of the above factorization is that a rating depends not only on how similar a
user’s preferences and an item’s features are (as in PMF), but also on how much these prefer-
ences/features match with the current trend as reﬂected in the time feature vectors.
As in the PMF framework, the P and Q factor matrices can be regularized by imposing
Gaussian priors, i.e.,
Pu  N .u
u
u; ˙U /;
Qi  N .I; ˙I/:
As for the T matrix, we can assume that the seasonality can be expressed through a smooth
dependency between adjacent time intervals. at is to say, the values in Tt depend on the values
of its predecessor Tt 1:
T1  N .0; ˙0/;
Tt  N .Tt 1; ˙T /:
Inference and parameter estimation can be solved in a full Bayesian framework as in [168]: hy-
perparameters and the factor matrices are iteratively sampled according to a Gibbs sampling pro-
cedure that exploits appropriate conjugate priors to express the posteriors.

C H A P T E R
6
Social Recommender Systems
e evolution of the Web and information technologies has made it possible to broaden the
traditional concept of the diﬀusion of information, introducing a virtual environment where one
can exchange ideas, opinions, and information. e Social Web realizes such ideas, by allowing
diﬀerent kinds of interactions among people with similar tastes. Social contents/relationships
and microblogging features, such as following/follower relationships and sharing of “memes”¹ or
proﬁle updates, are quickly reshaping the idea of the Web, which is progressively moving from
the original concept of connecting documents/resources to the idea of connecting people. is is
witnessed by the incredible growth of Social Networks (SNs), both in terms of active accounts and
user-generated content:
• In the ﬁrst quarter of 2013, FaceBook² got over 1 billion monthly active users;³
• Google+⁴ registered over 500 million accounts;⁵
• Twitter⁶ produced over 9,000 tweets per second.⁷
SNs provide a new kind of complex and heterogenous data repository that can consistently im-
prove the quality of a recommendation system by allowing a more accurate and ﬁne-grained pro-
ﬁling of trends and users’ tastes. For instance, ratings or opinions shared by social peers can be
exploited to mitigate the sparsity of the user-item preference matrix. In a sense, our ﬁrst source of
recommendations is the social environment: we naturally ask friends for recommendations about
the next movie to watch, or restaurants to frequent. In a comparison between social ﬁltering and
information ﬁltering algorithms, recommendations from friends have been reported [184] to be
consistently better than those from online recommender systems.
On the other hand, a good recommender system can enhance the experience of the users of
the SN. e extremely dynamic stream of information and resources available in online networks
represents a serious case of information overload. Information, memes, and opinions quickly
spread across the network and produce new information, in an endless cycle. With the huge
¹A meme refers generally to short snippets of text, photos, audio, or videos.
²http://www.facebook.com/
³http://investor.fb.com/releasedetail.cfm?ReleaseID=761090
⁴http://plus.google.com/
⁵http://googleblog.blogspot.it/2012/12/google-communities-and-photos.html
⁶http://www.twitter.com/
⁷http://www.statisticbrain.com/twitter-statistics/

128
6. SOCIAL RECOMMENDER SYSTEMS
amount of available products/services/information in the SNs, recommendation techniques play
an important role in the detection of potentially interesting and attractive content for each user.
Social rating networks, which combine advantages of SNs and RSs, are emerging as collab-
orative platforms on which users discover and share opinions about items (movies, books, music,
etc.). Examples are:
• Last.fm,⁸ halfway between a music recommendation service and a social network.
• Flixster,⁹ a social network where users share ﬁlm reviews and ratings.
• e recent integration of TripAdvisor¹⁰ on popular third-party social networking sites, in-
cluding FaceBook, allows users to search for opinions about restaurants, hotels, and places
to visit, shared by their social connections.
e integration of social features and data into recommender systems oﬀers great opportunities,
but it also calls for novel recommendation models that deal with two main problems. First of
all, almost all current recommender systems are designed for speciﬁc domains and applications
without explicitly addressing the heterogeneity of the implicit and explicit preference information
available on SNs. Users’ feedback on items may come in diﬀerent format: implicit clicks, thumbs
up/down, textual reviews, or numerical ratings. Moreover, some contextual features, such as loca-
tion, time, or level of social engagement, can have varying importance on diﬀerent recommenda-
tion domains. Finally, traditional recommender systems assume that all the users are independent
and identically distributed, thus ignoring the existence of complex relationships between social
interaction and similarity [46].
Online SNs exhibit an interesting property: users tend to form social ties with people hav-
ing similar sociodemographic attributes, or tastes. In other words: “similarity breeds connection”
[127]. is property can be explained as the joint eﬀect of two processes, namely social inﬂu-
ence [59] and selection [127]. Each user tends to become similar to people he/she interacts with.
In the context of modeling users’ choices and tastes, the principle of social inﬂuence states that the
tendency of adopting a new product increases with the number of social peers who have already
adopted it. In this sense, social inﬂuence promotes homogeneity of tastes/adoptions within the
same community. Selection refers to the tendency to create social connection with similar people;
it therefore promotes fragmentation of the social network in well-separated, highly homogenous
modules. As a result, each user in a network exhibits a high degree of similarity with his/her
neighbors.
ese eﬀects have been studied in diﬀerent settings. For instance, in Wikipedia, people tend
to edit the same articles after contributing to the same discussion page [46], which is assumed to
represent the establishment of their social tie. Furthermore, Aiello et al. [7] found that, within
social media systems, users with neighboring relationships exhibit a high level of lexical and topical
⁸http://www.lastfm.com/
⁹http://www.flixster.com/
¹⁰http://www.tripadvisor.com/

6.1. MODELING SOCIAL RATING NETWORKS
129
alignment: that is, they tend to adopt the same tag, and to access similar groups of resources.
Empirical studies [167, 210] have also conﬁrmed the importance of social inﬂuence in social
recommender systems and empirically measured to what extent users’ choices are aﬀected by
their social peers.
Despite being relatively new, this ﬁeld of research is extremely promising, and several adap-
tations of the probabilistic techniques shown in the previous chapters have been proposed. In ad-
dition, new probabilistic models allow us to understand complex phenomena and to exploit them
in the recommendation scenario. We shall review these models and their applications in the next
sections.
6.1
MODELING SOCIAL RATING NETWORKS
A Social Rating Network (SRN) is a platform that allows users to establish social relationships and
share explicit opinions and preferences on a set of items. Opinions can be provided in diﬀerent
formats (e.g., positive/negative, explicit ratings, or in textual format), while social links can be
either directed (follower/following relationships) or undirected (mutual friendship), and, in the
case of trust networks [125], can be weighted with a numerical value that expresses the strength
of the trust relationship between two peers.
We assume the situation where users provide explicit numerical ratings on items of interest.
en, a SRN can be formalized as a tuple hG D .U; E/; R; I; Vi, where the set of vertices of the
social graph G coincides with the user-set U and E  U  U encodes the social relationships,
while R stores the numerical preferences, within a ﬁxed scale V, provided by users on the set of
items I. Let us introduce a binary friendship indicator eu;v, which is equal to 1 if .u; v/ 2 E,
zero otherwise. Moreover, let EC.u/ denote the set of users followed by u, i.e., EC.u/ D fv 2
U W .u; v/ 2 Eg, while symmetrically E .u/ denotes the set of user following u. A toy example
of a directed SRN is given in Figure 6.1. e underlying network includes ﬁve users and their
preferences expressed on a set of eight items. Both the social network and the preference data are
characterized by high sparsity. Table 6.1 lists some publicly available datasets that include both
user preferences and social connections.
Figure 6.1: Social rating network.

130
6. SOCIAL RECOMMENDER SYSTEMS
Table 6.1: Example of publicly available SNR datasets
Name
Domain
Social relations
Users’ feedback
URL dataset
Epinions
generic
explicit trust
ratings/textual
www.trustlet.org/wiki/Epinions_dataset
Flixster
movies
mutual friendship
ratings
www.sfu.ca/~sja25/datasets/
Douban
generic
mutual friendship
ratings
http://dl.dropbox.com/u/17517913/Douban.zip
Last.fm
music
mutual friendships
listening counts
www.grouplens.org/node/12
To characterize the behavior of users in online SRNs, we can resort to the analysis car-
ried out in [95]. Actions performed in a SRN context can be classiﬁed either as social actions
(in particular, for establishing a social connection) or item adoptions, where the latter involves
experiencing a product or providing an explicit feedback on an item. Notably, the creation of
social links can be modeled as the eﬀect of transitivity, i.e., the tendency of establishing social
relationships with people at a short distance in the network (friends of friends). Also, adoption
actions can be explained in terms of either social inﬂuence or other external factors. e evolution
and dynamics of a SRN can be analyzed by considering a stochastic model where a new action
can be characterized according to three aspects:
• the user performing the action;
• whether the user is performing a social or an adoption action; and
• the inﬂuencing factor for the target.
e stochastic model is depicted in Figure 6.2, and is characterized by the parameter set  D
f; '; ˝1; ˝2; ˝3; 1; 2; 3g. Within the model, ˝1 and ˝2 expresses the probability of observ-
ing a social action due to either transitivity or similarity, respectively. Similarly, 1 expresses the
probability of observing an adoption action due to social inﬂuence, whereas 2 is the strength of
adoptions based on similarity.
User
Selection
Existing
user
New user
Action
Selection
Social
Action
Friend of a 
friend
Similar user
Other
Other
Item rated by a
similar user
Item rated
by a friend
Adoption/
Rating Action
η
1-η
1-φ
Ω1
Ω2
Ω3
θ1
θ2
θ3
φ
Figure 6.2: Probabilistic model for users’ behavior in a SRN.

6.2. PROBABILISTIC APPROACHES FOR SOCIAL RATING NETWORKS
131
e study of the parameters ˝ and  allows us to understand how a SRN can evolve, and,
in particular, to evaluate the inﬂuence of social relationships on the behavior of the users. For
example, let St D fGt; Rtg denote the status of the network at time t and the log of all adoptions
performed by t. Assuming that, given the state of the SRN, social actions are i.i.d, the likelihood
of the social graph can be expressed as:
P.Gtjtrans; ssim; ext; !1; !2/ D
Y
hu;vi2Et
P.hu; vijt; trans; ssim; ext; !1; !2/
D
Y
hu;vi2Et
P.ujt/ f˝1  P.vjt; trans/ C ˝2  P.vjt; ssim/
C.1   ˝1   ˝2/  P.vjt; ext/g ;
where P.ujt/ represents the probability that a new social connection will be established by u at
time t, while trans, ssim, and ext are the parameters specifying the probabilities of v being the
target of the social connection due to transitivity, similarity, or external factors, respectively. e
likelihood for the adoption log Rt can be expressed similarly. Jamali and Ester in [95] ﬁt the
above model by MLE on two real-life datasets, and discover that both the creation of new social
connections and the adoption of new items are strongly motivated by social factors (˝1  0:9
and 1  0:55).
6.2
PROBABILISTIC APPROACHES FOR SOCIAL RATING
NETWORKS
In the context of a SRN, observations X can be partitioned into XR and XN, where the former
is concerned with adoptions and the latter is concerned with social connections. Most of the
techniques developed for rating prediction, and in general for modeling preference matrices, can
be applied directly for predicting missing data in network adjacency matrices, as the two tasks are
fundamentally the same. e latter setting, known as link prediction (for a survey see [9]), can be
formalized as follows: given a snapshot of a social network, can we infer which social interactions
are more likely to be established in the near future?
Here, we consider XN as side information that can help in improving the modeling of
users in those scenarios where XR is particularly poor in explicit preference observations (e.g., in
cold-start scenarios). Approaches to SRNs can be divided roughly into two classes, which corre-
spond to diﬀerent ways of modeling how the social interactions aﬀect the user behavior. e ﬁrst
class comprises all those methods which explicitly model dependency among users’ choices. ese
approaches relax the assumption that users are independent from each other, by modeling each
user’s choice as a function of the choices performed by her social peers. Two examples are ran-
dom walks on the friendship network and elicitation of inﬂuence among neighbors. e former
approaches assume that ratings expressed by trusted friends on similar items can be more reliable
than ratings expressed by far neighbors in the social network on the target item: TrustWalker [94],

132
6. SOCIAL RECOMMENDER SYSTEMS
for example, employs a random walk over the network to predict the user’s preference on a con-
sidered item by basing the prediction on the preferences expressed on similar items by social peers
at a short distance within the social graph. e latter approaches assume that the tendency of a
user to adopt an item is a monotone function of the number of his social peers who have already
adopted the same product. We shall consider in detail the study of inﬂuence within social network
in Section 6.3.
e second class of approaches is based on the idea of the joint modeling of social rela-
tionships and users’ preference to better deﬁne hidden relationships in the user latent space. is
is obtained by employing the same set of latent variables and ensures that the projections of two
users into the latent space will become closer if they share common friends or exhibit similar
preference patterns. An example is given by the social regularization [119] approach for matrix
factorization, in which the objective function is formulated to include a regularization parameter
that penalizes the distance between latent vectors of users who are connected in the network. e
remainder of the section is devoted to discuss how to reformulate a network-aware latent factor
modeling in a probabilistic setting.
6.2.1
NETWORK-AWARE TOPIC MODELS
In a topic-modeling scenario, one can think of directly exploiting the idea of regularization by
adding further constraints on the user-topic probabilities [128]. at is, the eﬀect of the social
connections on a model  is expressed by the fact that, for a given pair u and v, the probabilities
θu and θv must be similar when u and v are socially connected. e smoothing of the resulting
topic model can be obtained by considering the joint likelihood
P.XR; jG/ D P.XRj/P.jG/;
(6.1)
where the posterior P.jG/ expresses the above constraints, e.g.,
P.jG/ /
Y
hu;vi2E
exp
n u;k   v;k
T ˙ 1
u;v
 u;k   v;k
o
:
An alternative approach is to consider both item adoptions and social connections as the
result of a stochastic process governed by latent factor. For example, we can extend the LDA
to embody a probabilistic model for social links [55]. Figure 6.2.1 shows an example of such a
model, where the generation of links follows a process similar to the generation of items and the
user-speciﬁc distribution θu is used to sample latent topics for both adopted products and social
connections.
e generative model is described as follows.
1. For each latent factor k D 1; : : : ; K sample:
• a multinomial distribution over items ϕk  Dir.β/;

6.2. PROBABILISTIC APPROACHES FOR SOCIAL RATING NETWORKS
133
.i.
v
.
z
.
z
.

.

.
˛
.
ˇ
.
˝
.

.
nu
.
fu
.
M
.
K
.
K
.
Figure 6.3: Graphical model for Link-LDA. Here fu D jEC.u/j.
• a multinomial distribution over users Ωk  Dir.γ/.
2. For each user u 2 U:
(a) Choose θu  Dir.α/;
(b) Sample the number nu of item selections;
(c) For each of the nu items to be generated:
i. Sample a topic z  Disc.θu/;
ii. Sample i  Disc.ϕz/;
(d) Sample the number fu of social links;
(e) For each of the fu social links to be generated:
i. Sample a topic z  Disc.θu/;
ii. Sample a target user for the social link v  Disc.Ωz/.
Here, the state z of the latent variable identiﬁes both an abstract pattern of adoption and a social
community.
As usual, the joint likelihood can be expressed as:
P.X jα; β; γ/ D P.XRjα; β/  P.XN jα; γ/
D
Z Z Z Y
u
2
4 Y
i2I.u/
X
k
u;k k;i
3
5 
2
4
Y
v2EC.u/
X
k
u;k ˝k;v
3
5 
P.jα/P.jβ/P.˝jω/ d d˚ d˝
(6.2)
e shared latent variable ensures that users who share the same social connections and tend to
adopt the same items, will exhibit similar distributions over topics. It is noteworthy to compare

134
6. SOCIAL RECOMMENDER SYSTEMS
Equation 6.2 with the joint likelihood shown in Equation 6.1. Here, we assume that both XN is
the result of a stochastic process, where as in Equation 6.1 we assume that the network is ﬁxed.
Also, note that in this generative model social links are sampled from a multinomial distri-
bution which is deﬁned over the set of users. A more precise formulation would replace the multi-
nomial distribution with a multivariate hypergeometric distribution, which simulates the sampling,
without replacement, from a ﬁnite population whose elements can be classiﬁed in a set of dis-
joint classes. However, the multivariate hypergeometric distribution converges to the multinomial
when the size of the sampling population is large. As discussed in [42], the large number of users
in online SRNs makes the diﬀerence between the two distributions negligible, thus simplifying
the modeling.
6.2.2
SOCIAL PROBABILISTIC MATRIX FACTORIZATION
In this section, we reformulate the probabilistic modeling of adoptions and social connections by
exploiting matrix factorization techniques. For each pair hu; ii of observations, a matrix factor-
ization model assumes the existence of latent factors Pu and Qi such that ru
i  N
 P T
u Qi; ˙ 1.
However, the social connections in G can be expressed by an incidence matrix E such that eu;v D 1
if and only if .u; v/ 2 E. As a result, we can provide a matrix factorization interpretation for this
matrix as well. Moreover, since users are already projected into a latent factor space by means of
a matrix P, the same factor space can be exploited in the factorization of E.
e So-Rec factorization model [118], given graphically in Figure 6.4, assumes that the
generation of the network structure and the preference observations are governed by a shared
set of latent factors. is joint modeling promotes the projection into the same low-rank latent
feature space of users that exhibit similar social connections and/or rating behavior. e model is
speciﬁed by three sets of latent factors: P 2 RKM represents the interest of each user in following
other people or rating products; Q 2 RNK encodes relationships between items and topics; and,
ﬁnally, F 2 RKM represents the authoritativeness of each user (chance of being followed) in each
topic. Given latent factor vectors, the likelihood of the set X of observations can be expressed as:
P.X jP; Q; F/ D
Y
hu;i;ri2XR
P.rju; i; P; Q/
Y
hu;vi2XN
P.eu;vju; v; P; F/;
where P.rju; i; P; Q/ and P.eu;v D 1ju; v; P; F/ are instantiated as Gaussian/logistic density
functions that have been studied in the previous chapters. Plugging the above data likelihood
into the probabilistic matrix factorization framework allows us to solve the related inference and
prediction problems, e.g., by means of Gibbs sampling or variational inference.
A particular instantiation of the above models is the case where we enforce F D P T. Users
can be explained in terms of a unique mapping within the latent factor space, and the incidence
matrix E is explained in terms of the factorization P T P. A generic entry P T
u Pv of the latter
matrix can be interpreted as the cosine similarity of users within the latent factor space. Hence,

6.2. PROBABILISTIC APPROACHES FOR SOCIAL RATING NETWORKS
135
.r.
eu;v
.
R
.
G
.
F
.
P
.
Q
.
P
.
Q
.
F
.
M  N
.
M  M
.
M
.
N
.
M
.
Figure 6.4: Graphical model for So-Rec.
the factorization of E provides an explanation of symmetric networks in terms of similarity: two
users are likely to exhibit a connection if they share the same interests in the latent factor space.
6.2.3
STOCHASTIC BLOCK MODELS FOR SOCIAL RATING NETWORKS
We can generalize the joint factorization of both the social graph and the users’ preferences by
resorting to mixed membership stochastic blockmodels (MMSB) [8, 96]. Again, we assume that a
generic user can be associated with a topic distribution θu. Furthermore, we assume that items
can be associated with a topic distribution as well. Topic distributions inﬂuence item adoptions
and social connections. However, similar to the co-clustering models shown in Chapter 3, there
are two “roles” involved in each action, where each role refers to a speciﬁc topic. e generative
process of the Social-aware stochastic block model summarizing these concepts is shown below.
1. For each user u 2 U, sample the mixed membership proﬁle θu  Dir.α1/.
2. For each user i 2 I, sample the item membership vector ψi  Dir.α2/.
3. For each pair .z; w/ 2 f1; : : : Kg2 sample ˇz;w  Beta.a; b/.
4. For each pair .z; w/ 2 f1; : : : Kg  f1; : : : ; Lg sample ϵz;w  Dir./.
5. For each pair of user .u; v/ 2 U  U:
• Sample a group for the source node zl  Disc.θu/;
• Sample a group for the destination node wl  Disc.θv/;
• Generate the social relationship eu;v  Bernoulli.ˇzl;wl/.
6. For each user u 2 U, and for each item i 2 I.u/:

136
6. SOCIAL RECOMMENDER SYSTEMS
• Sample a group for the user za  Disc.θu/;
• Sample an item category for the item wa  Disc.Φi/;
• Generate a rating value ru
i  Disc.ϵza;wa/.
Each user is associated with a multinomial distribution that models her membership over a
ﬁnite set of K groups, while each item is associated with a multinomial distribution over a set of
L categories. e probability of observing a link among the members of two groups is governed
by a K  K matrix of Bernoulli rates. For each possible social link .u; v/, we sample: (i) a group
membership for the source node; (ii) a group membership for the target node; and, (iii) ﬁnally we
generate a link according to the Bernoulli distribution ˇ, which encodes the interactions among
the groups. Analogously, a preference is generated by choosing the topics za and wa associated
to each pair hu; ii; then we sample a rating by drawing upon the multinomial distribution that
governs preferences for users belonging to the group za, on items belonging to the category wa.
.
eu;v.
ru
i
.
ˇ
.
a
.
b
.
zl
.
wl
.

.
˛1
.
za
.
wa
.
 
.

.

.
˛2
.
M  M
.
K  K
.
M
.
N
.
M  N
.
K  L
.
Figure 6.5: Social-aware stochastic block model.
e joint likelihood is quite straightforward: by assuming that Za; Zl; W a, and W l repre-
sent the matrices of topic assignments,
P.X ; Za; Zl; W a; W ljˇ; ;  ; / D P.XN ; Zl; Wljˇ; /  P.XR; Za; W aj;  ; /;
where, in particular,
P.XN ; Zl; W ljˇ; / D
Y
.u;v/2UU
P.eu;vjzl
u;v; wl
u;v;ˇˇˇ/  P.zl
u;vju/  P.wl
u;vjv/;
(6.3)

6.3. INFLUENCE IN SOCIAL NETWORKS
137
and
P.eu;vjk; l; ˇ/ D ˇeu;v
k;l

 1   ˇk;l
1 eu;v :
e estimation of the parameters can be performed by either applying variational inference, or
by adapting the Gibbs sampling scheme illustrated in Chapter 3. Notice that the likelihood in
Equation 6.3 requires us to take into account the whole incidence matrix. As discussed in [68],
sampling techniques should be adopted to address the high computational burden of the learning
phase, which is strongly inﬂuenced by the structure of this component.
6.3
INFLUENCE IN SOCIAL NETWORKS
Understanding the dynamics characterizing social inﬂuence and the inﬂuence-driven diﬀusion of
information, also known as information cascades, in social networks has received growing attention
by both academic and industrial communities. e motivating idea is nicely expressed in the
seminal work by Gladwell [66]:
Ideas and products and messages and behaviors spread like viruses do.
is motivates a wide range of applications for social inﬂuence analysis: viral marketing, identify-
ing inﬂuencers and promoting their deeper engagement with the system, generating personalized
recommendations based on those inﬂuencers, and feed ranking, just to mention a few.
We are still interested in studying the social network hG D .U; E/; Ii discussed before,
where .u; v/ 2 E represents the fact that information can propagate from u to v, e.g., u can
inﬂuence v and I represents the items that can be adopted and that can spread along the net-
work. e set X of observations, however, now includes the cases where an individual performs
a certain action for the ﬁrst time: that is, triplets hu; i; ti denoting the fact that user u adopted
(purchased/rated/clicked) the item i at time t. We can also view the set of observations under a
diﬀerent perspective, i.e., as a set of observed propagation traces f˛1;    ; ˛N g over I, where each
trace ˛ contains the activation time of each node t˛.v/, where t˛.v/ D 1 if v does not become
active in trace ˛. us, ˛ induces a directed acyclic graph, where the parents of a node u are
par˛.u/ D fv W .v; u/ 2 E; t˛.v/ < t˛.u/g:
e setting described so far is the most general one, where we only observe users adopting some
products, without knowing who triggered the adoption, i.e., the actual inﬂuencer. For instance,
we may record the time at which a user rated a particular item and assume that this item has been
propagated from v to u if .v; u/ 2 E if u rates the item shortly after the rating by v. If we observe
this pattern several times, we can infer that v inﬂuences u.
Although providing a comprehensive review of the state-of-the-art of social inﬂuence anal-
ysis is out of the scope of this monograph (the interested reader may refer to [35] for an overview
of inﬂuence propagation in social networks), in the following, we summarize the main research
directions and their relationships to recommender systems.

138
6. SOCIAL RECOMMENDER SYSTEMS
6.3.1
IDENTIFYING SOCIAL INFLUENCE
Identifying and understanding social inﬂuence is a complex task. e simple observation of the
high correlation between activations of two social peers is not suﬃcient for devising social inﬂu-
ence. In fact, the statistical correlation among activations of connected peers in a social network
can be explained not only by social inﬂuence, but also as the product of homophily and/or con-
founding factors (external factors, such as the environment in which peers are embedded). Figure
6.6 illustrates how these components relate: when both u and v adopt the same item i, there can
be three diﬀerent explanations:
• e environment where these users are located “forces” them to choose the same adoptions
(e.g., they have access to a catalog which only makes i available).
• ey share common tastes and preferences, which are expressed by similar choices (ho-
mophily).
• v recognizes u as an authoritative source of inﬂuence, and hence, she tends to emulate u’s
behavior.
Environment
Homophily
Social Influence
Individual
Characteristics
Social
Connections
Confounding
Confounding
Figure 6.6: Sources of social correlations (adapted from [190]).
Identifying these settings in which social inﬂuence plays an important role in shaping users’
behavior is important to design viral marketing campaigns that exploit “word of mouth” phe-
nomena and the role of inﬂuential users. Distinguishing social inﬂuence from other sources of
correlation essentially boils down to distinguishing correlation from causality, which is a hard
statistical problem. In [11], authors propose two tests for deciding if inﬂuence is the source of
correlation. e general framework for modeling users’ activation is based on a logistic function:
the probability of becoming active is a monotone increasing function of the number of social peers
already active:
P.activation happens when a peers are already active/ D
expfˇ1 ln.a C 1/ C ˇ0g
1 C expfˇ1 ln.a C 1/ C ˇ0g;

6.3. INFLUENCE IN SOCIAL NETWORKS
139
where a is the number of active peers, ˇ1 measures social correlation, and ˇ0 is the intercept.
Regression coeﬃcients can be estimated by employing maximum likelihood estimation for the
logistic regression.
e ﬁrst test, called shuﬄe test, is based on the following idea: if adoptions are not due to
inﬂuence, then, while the probability of activation still depends on the number of friends that are
already active, the timings of these activations should be independent. More in details, the shuﬄe
test initially computes the value of ˇ1, which maximizes the likelihood of observing the real data.
If we assume that the activation time of each node is independent, identically distributed from a
distribution over the observation window, then the maximum likelihood estimation of ˇ1 is close
to its expected value, where the expectation is taken over the random choice of the time stamps.
at is, denoting by  a random permutation of the activation timestamps, the shuﬄe test declares
that the model exhibits no social inﬂuence if the values of ˇ1 and Qˇ1 are close to each other where
the latter is the regression coeﬃcient computed by considering the random permutation .
e edge-reversal test is based on the idea that, if correlation is due to homophily or con-
founding factors, then reversing the direction of edges should not aﬀect the estimate of the social
correlation signiﬁcantly. On the other hand, if inﬂuence is the cause of correlation, then reversing
the direction of the edges leads to a diﬀerent estimate of the social correlation parameter ˇ1.
Both tests are eﬀective in detecting instances in which inﬂuence is the source of correlation,
and they provide a qualitative indication of the existence of inﬂuence. Measuring the extent of
inﬂuence and handling the case where diﬀerent source of correlations may simultaneously aﬀect
users’ behavior however, require more reﬁned modeling.
6.3.2
INFLUENCE MAXIMIZATION AND VIRAL MARKETING
A natural scenario where social inﬂuence analysis and recommendation techniques ﬁnd an in-
tersection is viral marketing. e latter refers to marketing techniques aimed at exploiting social
media and communication channels to promote products or brands. For example, we might be in-
terested in devising, within the network G and for a speciﬁc item i, a minimal set of users to target
such that the number of adoptions triggered by peer-wise inﬂuence is maximized. is problem
was initially tackled by Domingos and Richardson [53, 163], who modeled the diﬀusion process
in terms of Markov random ﬁelds.
Later, Kempe et al. [104] proposed a formulation of the setting studied by Domingos and
Richardson in terms of a discrete optimization problem, focusing on two fundamental propa-
gation models: the Independent Cascade (IC) and Linear reshold (LT) models. Both focus on
binary infections: at a given timestamp, each node is either active (a user who already adopted
the item), or inactive, and an active node never becomes inactive again. Time unfolds determin-
istically in discrete steps and each node’s tendency to become active increases monotonically as
more of its neighbors become active. Under the IC model, each new active node v at time t is
considered contagious and has one chance of inﬂuencing each inactive neighbor u, independent
of the history thus far. e activation of u by v succeeds with Bernoullian probability pv;u; the

140
6. SOCIAL RECOMMENDER SYSTEMS
activation trial is unique, as u cannot make further attempts to activate u in subsequent rounds.
According to the LT model, each node u is inﬂuenced by each active neighbor v according to a
multinomial weight pv;u, such that the sum of incoming weights to u is no more than 1. Each
node u is associated with a “resistance” threshold u. At any timestamp t, if the total weight from
the active neighbors of an inactive node u is at least u, then u becomes active at timestamp t C 1.
In both cases, the process runs until no more activations are possible.
Given a propagation model m (either IC or LT) and a seed set S  V , the spread of S,
i.e., the expected number of active nodes at the end of the propagation process, is denoted by
m.S/. e inﬂuence maximization problem is to ﬁnd the set S  U, jSj D k, such that m.S/
is maximized. Under both the IC and LT propagation models, the problem was proved to be
NP-hard [104]. ere are however two nice properties of the m.S/ function:
• monotonicity, i.e., m.S/  m.T / whenever S  T , and
• submodularity, i.e., m.S [ fwg/   m.S/  m.T [ fwg/   m.T / whenever S  T .
Under these properties, the simple greedy algorithm that at each iteration greedily extends the set
of seeds with the node providing the largest marginal gain, as described in Algorithm 4, produces
a solution with a provable approximation guarantee .1   1=e/ [142].
Algorithm 4 Greedy algorithm for inﬂuence maximization.
Require: Network G, seed-set budget k, propagation model m.
Ensure: A seed set S, with jSj D k, of users to target.
1: S  ;
2: while jSj < k do
3:
u  arg maxw2V nS .m.S [ fwg/   m.S//
4:
S  S [ fug
5: end while
Computing the spread of a given seed set of nodes is #P-hard under both the IC and the LT
models. An accurate and more feasible estimation can be achieved by running Monte Carlo simu-
lations; as shown in [104] for any  > 0, there is a ı > 0 such that by using .1 C ı/-approximate
values of the expected spread, we can obtain a .1   1=e   /-approximation for the inﬂuence
maximization problem. Unfortunately, simulations are extremely costly on very large real-world
social networks and considerable eﬀort has been devoted to develop methods for improving the
eﬃciency of inﬂuence maximization [43, 44, 72, 105, 113, 165].
Learning Inﬂuence Probabilities
Approaches to inﬂuence maximization assume that the inﬂuence probabilities for each pair of
users are given as input. An accurate estimate of the inﬂuence weights is hence important. It is
worth noticing that the inﬂuence weights are not necessarily related to the degree of the nodes
[41], and they require ad-hoc estimation techniques by mining an observed set of information
cascades.

6.3. INFLUENCE IN SOCIAL NETWORKS
141
As described before, each propagation trace ˛ induces a directed acyclic graph, where each
link .v; u/ represent the fact that the information potentially propagated from v to u. In prac-
tice, the induced graph devises, for each user u, the set par˛.u/ of possible activators. To prune
episodes of propagations that are unlikely, we can introduce a temporal threshold . Let F C
˛;u be
the set of u’s neighbors that potentially inﬂuenced u’s activation in the trace ˛:
F C
˛;u D fv j .v; u/ 2 E; 0  t˛.u/   t˛.v/  g:
Also, consider the set Av!u D f˛ 2 X jv 2 F C
˛;ug of traces for which v is a potential inﬂuencer
of u, and the set Av D f˛ 2 X jt˛.v/ < 1g containing all the adoptions performed by v. Sim-
ple estimates of inﬂuence probabilities can be computed by relating the number of propagation
episodes [71], e.g.:
pv;u D jAv!uj
jAvj ;
or
pv;u D
jAv!uj
jAu [ Avj:
In both models, each node w in F C
˛;u takes the credit for the activation of u. Speciﬁc adjustments
can be obtained by adopting partial credit models [71] to quantify the importance of potential
inﬂuencers in triggering one activation. In particular, if jF C
˛;uj D 1, the unique potential inﬂuencer
should take all the credit for triggering u’s activation, while if jF C
˛;uj > 1, then the overall credit
should be shared. We can deﬁne the credit as follows:
creditv;u.˛/ D
(
0
if v 62 F C
˛;u
1
jF C
˛;uj
otherwise
;
and reformulate the estimates for inﬂuence probabilities as follows:
pv;u D
P
˛2D creditv;u.˛/
jAvj
;
or
pv;u D
P
˛2D creditv;u.˛/
jAu [ Avj
:
e estimation can also be formalized as a maximum likelihood problem [166], and solved
by exploiting the EM algorithm. Within the IC model, recall that multiple nodes may succeed
to activate, independently, the same node at the same time, and the activation attempt is unique.
Denote by F  ˛;u the set of u’s neighbors who deﬁnitely failed in inﬂuencing u on ˛:
F  ˛;u D fv j .v; u/ 2 E; t˛.u/   t˛.v/ > g;
and let Av¹u be the set of propagation traces for which v failed to inﬂuence u, i.e., Av¹u D f˛ 2
X jv 2 F  ˛;ug. Assuming i.i.d. propagation traces, the log-likelihood of the traces in X, given the
parameter set  (representing all the possible inﬂuence probabilities pu;v), can be expressed as
log L.X j / D
X
˛2D
log L˛./;

142
6. SOCIAL RECOMMENDER SYSTEMS
where the likelihood of a single trace ˛ is
L˛./ D
Y
u2U
2
641  Y
v2F C
˛;u
.1   pv;u/
3
75 
2
4 Y
v2F  ˛;u
.1   pv;u/
3
5 :
(6.4)
e ﬁrst term of Equation 6.4 represents the fact that, if u is active, then at least one of the
neighbors in F C
˛;u succeeded in triggering his activation. Dually, the second term models the fact
that none of the neighbors in F  ˛;u succeeded in activating u.
Let z˛Iv;u be the binary latent variable denoting the fact that v triggered the activation of
u in ˛, and let Z˛ be the set of all possible latent variables relative to ˛. We can reformulate
Equation 6.4 in terms of joint likelihood:
P.˛; Z˛j/ D
Y
u2U
2
64
Y
v2F C
˛;u
pz˛Iv;u
v;u
 .1   pv;u/1 z˛Iv;u
3
75 
2
4 Y
v2F  ˛;u
.1   pv;u/
3
5 ;
and P.X ; Zj/ D Q
˛2X P.˛; Z˛j/. Within the standard EM framework, the joint likelihood
induces the expectation log-likelihood
Q.I Q/ D
X
˛2D
X
u2V
8
ˆ<
ˆ:
X
v2F C
˛;u
 
'˛;v;u log pv;u C .1   '˛;v;u/ log .1   pv;u/
!
C
X
v2F  ˛;u
log .1   pv;u/
9
=
; ;
(6.5)
where '˛;v;u represents the probability that, in trace ˛, the activation of u was due to the success
of the activation trial performed by v. e optimization is achieved by alternating the following
steps until convergence:
E-Step: Estimate responsibilities as
'˛;v;u D
pv;u
1   Q
w2F C
˛;u.1 pw;u/
I
M-Step: Estimate inﬂuence probabilities as
pv;u D
1
jAv!uj C jAv¹uj
X
˛2Av!u
'˛;v;u:
Interesting variations of the above modeling consider the inclusion of latent topics in the
exertion of inﬂuence. In real-world scenarios, we naturally trust some people on some topics and

6.3. INFLUENCE IN SOCIAL NETWORKS
143
others on diﬀerent topics. Users authoritativeness, expertise, trust, and inﬂuence are clearly topic-
dependent and the characteristics of the item being the subject of the viral marketing campaign
should be considered to design better inﬂuence propagation models [117, 139].
6.3.3
EXPLOITING INFLUENCE IN RECOMMENDER SYSTEMS
How to exploit inﬂuence and “word-of-mouth” propagations in the context of RSs is still an
open research problem. e identiﬁcation of the inﬂuential peers for the user corresponding to
the current browsing session enables more eﬀective social explanations [183] in the form “Your
friend X likes this product.” Alternatively, one could provide incentives to inﬂuential people if
they proactively provide explicit suggestions of a product to their peers, in the form of “Suggest
to friends”.
In a SRN setting, both positive and negative opinions expressed by social peers play a role
in promoting or lowering the likelihood of adopting an item. Propagation models can be extended
easily to cope with such situations, as shown, e.g., in [182]. In practice, each user can have three
possible states relative to an item i, namely like, dislike, or stay inactive. e activation in this
case is either positive or negative, depending on the actual user’s preference on the considered
item. Inﬂuence can be exerted either positively or negatively: for example, in the LT model, a
user’s preference becomes negative if the weights of all her potential inﬂuencers who disliked the
product overcomes the weights of those neighbors who liked it, and, in general, the sum of such
weights is above a given threshold. Given an initial state, and the model parameters, we can study
the evolution of preferences, and then apply the result to predict the preferences of each user in
the network.
More generally, item adoptions can be expressed as a direct eﬀect of inﬂuence probabilities,
P.iju/ D
X
v2E .u/
P.ijv/pv;u;
thus relating the probabilities of adoptions to the eigenvectors of P. Starting from this simple
model, other more sophisticated models can be devised: for example, we can express the prob-
ability of adoption in a topic-wise fashion [203] according to the following generative process,
shown graphically in Figure 6.7:
1. For each preference observation to be generated:
(a) sample a user u  Disc.Π/;
(b) sample an inﬂuencer f  P. u/;
(c) sample a topic z  Disc.θf /;
(d) sample i  Disc.ϕz/.

144
6. SOCIAL RECOMMENDER SYSTEMS
.˘.
u
.
f
.
z
.
i
.

.
 
.
˚
.
N  M
.
M
.
K
.
M
.
Figure 6.7: Graphical model for social-inﬂuence-based recommendations.
Here we assume that each user is associated with a multinomial distribution  u over possi-
ble inﬂuencers; the probability of adoption of a particular item depends on the topic distribution
of the previously chosen inﬂuencer:
P.ijuI 	; ; ˚; ˘/ D P.i; uj	; ; ˚; ˘/
P.uj˘/
D
P
z
P
f p.i; u; f; zj	; ; ˚; ˘/
P.uj˘/
D
P.uj˘/ P
z
P
f p.f j u/P.zjf /P.ijz/
P.uj˘/
D
X
z
X
f
p.f j u/P.zjf /P.ijz/:
e connections between recommendation and inﬂuence also can be studied under an in-
ﬂuence maximization perspective [73]. Given a generic RS algorithm, we can reformulate the
inﬂuence maximization problem as the problem of identifying the seed set of inﬂuential users,
who, by providing high rating to a product, guarantee a maximum number of recommendations.
is problem has proven to be NP-Hard and the optimal solution cannot be approximated within
any reasonable factor. Goyal et al. in [73] propose several heuristics that are reported to work well
in practice on both user and item-based RSs.

C H A P T E R
7
Conclusions
ere is a recurring persuasion underlying the research covered in this book. Probabilistic methods
provide a robust and mathematically elegant tool for modeling preference data, and have revealed
extreme ﬂexibility to accommodate diﬀerent situations. It is worth clarifying that the main thesis
here is not the general superiority of probabilistic methods. It is well-known, e.g., from the Netﬂix
prize, that the best approaches count an ensemble of methods that cooperate for a best prediction.
Nevertheless, as also witnessed by the studies discussed in this book, probabilistic methods can
play a prominent role within such ensembles.
Probabilistic approaches oﬀer some advantages over other techniques, both in terms of
modeling and accuracy of the results. We have discussed, in Chapter 2, the capability to diﬀer-
entiate between free and forced prediction. Also, if we interpret the recommendation as missing
value prediction (matrix completion, where we are asked to estimate numerical users preference
values on unseen items), the use of Bayesian inference techniques, discussed in Chapter 3, is bet-
ter suited to handle the sparsity of preference data. Notably, techniques based on Bayesian matrix
factorization achieve the highest accuracy in rating prediction, as illustrated in Chapter 4.
Prediction accuracy is commonly used as a proxy metric to measure the eﬀectiveness of the
RS. However, recent studies have pointed out many limitations of this approach, showing that
higher prediction accuracy does not imply higher recommendation accuracy. We investigated this
aspect in Section 4.1.2: when measuring recommendation accuracy as precision and recall of the
recommendation lists provided to users, probabilistic models, equipped with the proper ranking
function, exhibit competitive advantages over state-of-the-art RSs. In particular, strategies based
on item selection guarantee high accuracy values, which can be further boosted by integrating a
relevance-ranking function estimating the probability that a user will play and like a given item.
is approach combines the beneﬁts of the modeling of preference values (explicit feedback) and
of the implicit users selection of items (implicit feedback).
Besides rating prediction and recommendation accuracy, there are other signiﬁcant advan-
tages in the adoption of probabilistic models for modeling preference data. A successful recom-
mendation should answer to the simple question “What is the user actually looking for?” which is
strictly tied with dynamic user proﬁling. Understanding user preferences enables better decision
making and targeted marketing campaigns. In this direction, probabilistic approaches enable the
discovery of topics and abstract preference patterns, as well as the identiﬁcation of homogenous
groups of similar-minded people or similar products. e high-dimensional preference data ex-
hibits both global and local patterns, which can be identiﬁed and characterized by employing

146
7. CONCLUSIONS
probabilistic co-clustering approaches. In general, co-clustering techniques are better suited to
model the mutual relationship between users and items: similar users are detected by taking into
account their ratings on similar items, which in turn are identiﬁed considering the ratings assigned
by similar users.
ese scenarios can be better illustrated by the schema in Figure 7.1. Each scenario here
is related to speciﬁc application requirements. For example, accurate rating prediction is crucial
in situations where the recommendation has to eﬀectively match the preferences of users. An
example in this setting is, e.g., a peer-review system, where the explicit preference represents the
conﬁdence of the reviewer on the subject relative to the item to review. In this scenario, it is
important to suggest, to the user, items that she is able to review with conﬁdence. By contrast,
the recommendation accuracy is a fundamental tool when the objective is to recommend products
that will likely capture the interest of a user, somewhat independently from the explicit preference
of the user. Finally, pattern discovery is aimed at a better knowledge of the customer base and/or
item catalog, whereas serendipity is aimed at implementing speciﬁc marketing strategies, which
may also depend on external factors (such as the objective to promote some products over others).
Recommendation Scenarios
Rating Prediction
Matrix Factorization
Bayesian Inference
Recommendation Accuracy
Pattern Discovery
Serendipity & Diversification
Mixture Models
Co-Clustering Approaches
Mixed Memberships Approaches
Item Selection and Relevance
Bayesian Inference
Figure 7.1: A schema of recommendation scenarios and the relative best-suited probabilistic ap-
proaches.
Another signiﬁcant advantage of probabilistic modeling is the capability to accommodate
both collaborative and content features in a uniﬁed mathematical framework, as we summarize
in Chapter 6. is is expected to increase the accuracy of the recommendations provided by the
system, and the background content information can be used to provide personalized recom-
mendations in cold-start scenarios. Side information can be exploited for a better identiﬁcation

7.1. APPLICATION-SPECIFIC CHALLENGES
147
and interpretation of user communities and item categories, and can be used for a more accurate
modeling of the preference data.
A speciﬁc context is represented by social connections. Users’ behavior on the Web is more
and more inﬂuenced by their social interactions with other users, and social recommender systems,
reviewed in Chapter 7, are emerging as a powerful combination of both recommendation and
social networking features. In these systems, people share content and information, interact with
their social peers, and express evaluations of them, typically in the form of thumbs up/down. is
implies a radical change in the recommendation perspective: while in traditional personalized
approaches we model users’ selections as a process that depends on her past purchase history, here
we have to model users’ choices as social process. Once again, stochastic processes based on latent
factors provide an accurate modeling capable of accommodating all these features in a uniﬁed
framework.
In an attempt to provide a uniﬁed picture of all the aspects covered in this book, Figure 7.2
provides a taxonomy of the approaches discussed so far. We can see ﬁve (possibly overlapping)
categories where each approach ﬁts, and a set of features characterizing each approach. Although
the survey provided in this book is not exhaustive, it has the ambition of being paradigmatic, as
it is likely to ﬁt any approach not covered here in the scheme provided by the ﬁgure, and hence,
to serve for the application scenarios illustrated in Figure 7.1.
We would like to conclude this book by presenting some open challenges that probabilistic
approaches to recommendation still pose, and whose solutions are the key to a successful aﬃrma-
tion of these approaches in an industrial setting.
7.1
APPLICATION-SPECIFIC CHALLENGES
Although desirable, it is quite diﬃcult to translate theoretical results into practice, and recom-
mender systems are no exception. In Chapter 1, we discussed some metrics for measuring the
eﬀectiveness of a recommender system, and, in Chapter 4, we have shown empirical results that
demonstrate how probabilistic methods can be tuned to provide optimal results for such metrics.
However, it is still an open question how industries can actually leverage the results of this research
and successfully deploy the techniques in a real-world scenario. We have discussed accuracy, pre-
cision, recall, and RMSE. ese measures are widely known by the machine learning researchers
and data-mining specialists. However, it is also important to develop economics-oriented mea-
sures that capture the business value of recommendations, such as return on investments (ROI)
and customer lifetime value (LTV) measures. Notably, companies are looking for ways to increase
their sales. Recommender systems are eﬀective under this perspective when:
• customers spend less time searching for products;
• customer satisfaction is increased;
• customer loyalty is increased;

148
7. CONCLUSIONS
Figure 7.2: A taxonomy of probabilistic approaches to collaborative ﬁltering.
• cross-selling is increased.
e gain of a recommender system depends on the expected increase in cross-selling, the expected
likelihood that an increase in customer satisfaction corresponds to an increase in purchases, and
the increase of customer loyalty. In order to evaluate such a gain, we need accurate methods to
map machine-learning speciﬁc metrics to the above expectations. Developing and studying these
aspects can help to better evaluate the impacts of the results illustrated in Chapter 4 on industrial
scenarios.
We can attempt an academic exercise on the results shown in Figure 4.8. Speciﬁcally, we
can (arbitrarily) assume that 10% of what is suggested in a recommendation list represents items
that a user would not have adopted otherwise. Hence, we can map the recall of a recommender
system directly to the expected increase in sales that it would produce. In particular, by comparing
the accuracies of PMF and LDA in Figures 4.7 and 4.8, we can conclude that the latter would
produce an increase of 4.4% over a 2.5% of the former, on a recommendation list of size 10.
However, as already mentioned, the above assumptions are deﬁnitely arbitrary, as we do not really
know the likelihood that a recommended product wouldn’t be adopted by the user anyway. Other

7.2. TECHNOLOGICAL CHALLENGES
149
studies [26, 40] propose some alternate protocols, but the whole issue still needs a more rigorous
mathematical treatment.
Besides the above mentioned challenge, there is a sort of reversed perspective that is chal-
lenging as well. We have argued in Chapter 1 that there are other metrics beyond prediction
accuracy that should be considered. Next, we have shown in Chapter 4 that probabilistic meth-
ods based on topic modeling can be proﬁtably exploited in scenarios where we are interested in
capturing concepts such as novelty, serendipity, and diversiﬁcation. Notably, probabilistic graph-
ical models provide several components which can be exploited fruitfully in focusing on the use-
fulness of the recommendation [126]. However, the objective measurement of concepts such as
non-triviality, serendipity, user-needs, and expectations is still an open issue. Although some ini-
tial attempts have been made in this respect [61, 111, 137, 193, 194], we still do not know how
and in what respect the methods proposed in Chapter 4 are eﬀective, and whether they can be
improved further by focusing on adequate loss functions.
Finally, an aspect we did not cover in this book is the relationship between recommenda-
tion and topical and geographical diversity. e advent of new technologies includes the user in a
mobile context, where a user can express diﬀerent expectations and needs depending on the geo-
graphical location. e capability to track a user through mobile devices represents an opportunity
for the recommender system to better tune the recommendations to the user needs, even by taking
into account the Markovian nature of a user’s location. Combining the probabilistic framework
for preference modeling with the ones proposed for geo-location can really project [87] recom-
mendation systems to a new dimension, where the geo-location context is better modeled.
7.2
TECHNOLOGICAL CHALLENGES
From a technological point of view, the aspect scalability of probabilistic methods deserves a more
deep analysis. e empirical study in Chapter 4 clearly denotes how the performance of some
methods, in terms of learning time, especially when Bayesian modeling is taken into account, are
particularly problematic.
is issue involves both the volume of preference data and the number of latent factors
employed in the learning phase. We would therefore like to have the tools to build latent factor
models that scale to large values. Traditional inference techniques, such as Gibbs sampling and
variational inference, do not scale easily to huge volume of data. In such cases it is very time-
consuming to run even a single iteration of the standard collapsed Gibbs sampling or variational
Bayesian inference algorithms. In such cases, it is mandatory to reformulate the learning algo-
rithms in terms of distributed processing based on scalable architectures.
Besides scalability, there are some issues concerned with the ﬁtting procedures. In fact,
the methods shown in this book do not account for incremental maintenance. As long as new
data is collected, the beliefs embodied in the models need to be revised, and the only revision
possible is to learn the model again. Again, the current literature is focusing on these problems

150
7. CONCLUSIONS
under diﬀerent perspectives: incremental and online learning [10, 15, 92, 202], topic evolution, and
dynamics [67, 164].
A further question that can be posed is how robust are the proposed methods of attack.
Robustness refers to the ability of a system to operate under stressful conditions [90]. ere are
several stresses that can be applied to a recommender system [136], the most signiﬁcant being the
dataset stress. is typically happens when the preference data is particularly noisy or erroneous. In
addition, preference data may be corrupted on purpose, for example by injecting ad-hoc proﬁles
to inﬂuence the overall performance of the system by pushing or nuking a product. Collaborative
recommender systems are extremely vulnerable to attacks that seek to manipulate recommenda-
tions made for target items. Hence, it is natural to investigate the vulnerability of probabilistic
methods, and to study countermeasures.
Finally, all latent factor models discussed in this book require the number of clusters, topics,
or, more generally, latent dimensions, to be speciﬁed a priori. e choice of the number of latent
factors is a delicate matter, as by increasing this number, we typically increase the quality of the
ﬁtting at the cost of a higher learning time and increasing the risk of overﬁtting. We have discussed
this aspect in Section 3.1, and have shown some solutions. Recently, Bayesian nonparametric
approaches, such as the Chinese restaurant or Indian buﬀet process (see [64] for a survey), address
this issue in a more general way, by automatically estimating how many latent dimensions are
needed to ﬁt the observed data, and by allowing the allocation of new clusters as new data is
observed. Recent works [201, 204] have shown that the application of nonparametric methods
to the recommendation scenario is both eﬀective and practical on large-scale datasets.

Parameter Estimation and
Inference
Let us consider a set X D fx1; : : : ; xN g of observations and a general latent parameter set Z, so
that the likelihood P.X j/ can be expressed in terms of the joint distribution P.X ; Zj/:
P.X j/ D
Z
P.X ; Zj/ dZ:
(A.1)
is appendix covers some mathematical tools for approaching both the parameter estimation
and the inference problems within such a framework. Most of the methods covered in this book
represent instantiations of the algorithms covered in the following, and the general approaches
introduced here can be considered as a prerequisite for understanding such methods.
A.1
THE EXPECTATION MAXIMIZATION ALGORITHM
e Expectation-Maximization (EM) algorithm is a general method for deriving maximum likeli-
hood parameter estimates from incomplete (i.e. partially unobserved) data. Within Equation A.1,
we are interested in estimating the optimal  that maximizes P.X j/. However, the likelihood is
expressed in terms of the components P.X ; Zj/, which in turn depend on the latent (unknown)
variable Z. In this setting, the EM algorithm deﬁnes an iterative procedure for estimating .
A typical example is given when the latent space Z is deﬁned over discrete latent factors
zi;k 2 f0; 1g, with i D 1; : : : ; N I k D 1; : : : ; K, such that the probability of observing xi depends
on a single latent factor. at is, P
k zi;k D 1 and each latent factor express a parameter space k
which deﬁnes P.xjk/ and
P.xijzi; 1; : : : ; K/ D
K
Y
kD1
P.xijk/zi;k:
In this case, the prior probability of observing a latent vector zi is given by a multinomial distri-
bution parameterized by π D f1; : : : ; Kg, that is,
P.zijπ/ D
K
Y
kD1

zi;k
k
:

152
A. PARAMETER ESTIMATION AND INFERENCE
us, denoting  , f1; : : : ; K; πg, we can deﬁne the join likelihood P.X ; Zj/ as:
P.X ; Zj/ D P.X jZ; /  P.Zjπ/
D
Y
i
K
Y
kD1
P.xijk/zi;k 
Y
i
K
Y
kD1

zi;k
k
;
and the data likelihood of Equation A.1 can be simpliﬁed into
P.X j/ D
X
Z
P.X ; Zj/
D
X
Z
Y
i
K
Y
kD1
P.xijk/zi;k  
zi;k
k
D
Y
i
K
X
kD1
P.xijk/k:
(A.2)
Optimizing this likelihood with respect to  can be diﬃcult, even for simple functional forms
of P.X jZ; /. As a consequence, one has to resort to iterative optimization methods in order to
estimate the optimal .
One such method is the EM algorithm, which iteratively computes a sequence
.0/; .1/; .2/; : : : ; .n/; : : :
such that, for each t, P.X j.t//  P.X j.t 1//. is approach focuses on the joint likelihood
P.X ; Zj/: If Z were known, we could rewrite the log-likelihood log P.X ; Zj/ in simpler
terms. In particular, in the example above we can express the latter as
log P.X ; Zj/ D
N
X
iD1
K
X
kD1
zi;k
˚log k C log P.xijk/
	
;
and we can see that, for tractable functional forms of P.xijk/, we can ﬁnd closed forms for the
optimization.
In practice, the latent space Z is unknown and we can only observe X. However, if the pos-
terior P.ZjX ; / is mathematically tractable, we can exploit the expectation of the log-likelihood
over all the possible latent states Z. If we assume a known prior value 0 for the parameter set,
the expectation of the joint likelihood associated to Z can be expressed as:
Q.; 0/ D
Z
P.ZjX ; 0/ log P.X ; Zj/ dZ:
(A.3)
ere is a substantial diﬀerence between Equation A.3 and the log-likelihood expressed starting
from Equation A.1. e latter exhibits an integral inside a logarithm,
log P.X j/ D log
Z
P.X ; Zj/ dZ

;

A.1. THE EXPECTATION MAXIMIZATION ALGORITHM
153
whereas in Equation A.3 we moved the integral outside the logarithm. e importance of the
expectation log-likelihood Q.; 0/ lies in two facts: ﬁrst, Q.; 0/ generally is easier to optimize
than log P.X j/. Second, a value O optimizing Q.; 0/ also improves the log likelihood. In
fact, whenever the property
Q.; 0/  Q.0; 0/
holds, then the related property
P.X j/  P.X j0/
holds as well. To see this, consider the diﬀerence log P.X j/   log P.X j0/. We observe that
log P.X j/   log P.X j0/ D log P.X j/
Z
P.ZjX ; 0/ dZ   log P.X j0/
Z
P.ZjX ; 0/ dZ
D
Z
P.ZjX ; 0/ log P.X j/ dZ  Z
P.ZjX ; 0/ log P.X j0/ dZ
D
Z
P.ZjX ; 0/

log P.X j/P.ZjX ; /
P.ZjX ; /

dZ
 Z
P.ZjX ; 0/

log P.X j0/P.ZjX ; 0/
P.ZjX ; 0/

dZ
D
Z
P.ZjX ; 0/ log
P.Z; X j/
P.ZjX ; /

dZ
 Z
P.ZjX ; 0/ log
P.Z; X j0/
P.ZjX ; 0/

dZ
D
Z
P.ZjX ; 0/ log
 P.Z; X j/
P.Z; X j0/

dZ
 Z
P.ZjX ; 0/ log
 P.ZjX ; /
P.ZjX ; 0/

dZ
DQ.; 0/   Q.0; 0/  Z
P.ZjX ; 0/ log
 P.ZjX ; /
P.ZjX ; 0/

dZ:
(A.4)
Consider now the term
Z
P.ZjX ; 0/ log
 P.ZjX ; /
P.ZjX ; 0/

dZ:
Recall Jensen inequality [45] stating that, for a concave function f , the following property holds:
EŒf .X/  f .EŒX/:

154
A. PARAMETER ESTIMATION AND INFERENCE
Since the logarithm is a concave function, we have
Z
P.ZjX ; 0/ log
 P.ZjX ; /
P.ZjX ; 0/

dZ
 log
Z
P.ZjX ; 0/ P.ZjX ; /
P.ZjX ; 0/ dZ

D log
Z
P.ZjX ; / dZ

D0:
(A.5)
Combining the equations A.4 and A.5, we ﬁnally obtain
log P.X j/   log P.X j0/  Q.; 0/   Q.0; 0/:
(A.6)
As a consequence, any improvement on Q.; 0/ represents an improvement on the data
likelihood, and we can devise an iterative procedure where, starting from an initial guess .0/, we
can proceed with iterative optimization steps over Q.; .t//, and the above property ensures that
these optimizations reﬂect on the likelihood as well. e expectation maximization optimization
procedure alternates two steps.
• Initialize .0/.
• Repeat until convergence, for increasing steps t:
E Step: Evaluate P.ZjX ; .t//;
M step: Evaluate .tC1/ as
.tC1/ D argmax

Q.; .t//:
Typically, the convergence is reached if the diﬀerence in log-likelihood is negligible. Also,
notice that the M step does not necessarily require an optimal solution. By inequality A.6, it
is suﬃcient to ﬁnd a value O that improves the value of Q. is enables a generalized (albeit
slower) approach to the optimization, which is particularly useful in those cases where the optimal
solution cannot be found but simple improvements are easier to ﬁnd in a closed form.
Turning attention back to the example in the beginning, we can see that Q.; .t// can be
expressed as:
Q.; .t// D
N
X
iD1
K
X
kD1
i;k..t//
˚log k C log P.xijk/
	
:

A.2. VARIATIONAL INFERENCE
155
Where the quantity i;k..t// is called the responsibility and represents the posterior probability
that observation xi is associated with latent factor k:
i;k./ D P.zu;k D 1jx; / D
P.xjk/k
PK
j D1 P.xjj /j
:
(A.7)
Equation A.7 speciﬁes the E step of the algorithm, which hence depends solely on the value .t/
previously computed and enables the speciﬁcation of the expectation log-likelihood to optimize.
A.2
VARIATIONAL INFERENCE
As we have seen, a central task in the application of probabilistic models is the evaluation of the
posterior distribution P.ZjX /. For many models of practical interest, computing such a posterior
distribution is unfeasible: for example, in the case of continuous variables, the required integra-
tions may not have closed-form analytical solutions, while the dimensionality of the space and
the complexity of the integrand may prohibit numerical integration. For discrete variables, the
marginalizations involve summing over all possible values of Z. Although this is always possible
in principle, in practical situations there can be exponentially many hidden states so that an exact
calculation is prohibitively expensive.
In such situations, we have to resort to two possible approximation schemes. Stochastic
approximations adopt sampling procedures, which we shall discuss in the next section. Here, we
provide a brief introduction to mean ﬁeld variational inference, extensively used throughout the
manuscript, and which represents an eﬀective deterministic approximation approach. A thorough
treatment can be found in [31, 102, 138].
To our purposes, variational approximation can be seen as a generalization of the expec-
tation maximization algorithm described above. Without loss of generality, we can assume Z
continuous and deﬁne the likelihood as:
P.X j/ D
Z
P.X ; Zj/ dZ:
Let us assume that we can express an approximation q.Z/ to the posterior distribution
P.ZjX ; /. To our purposes, we assume q.Z/ independent of . We can notice the following:
log P.X j/ D log
Z
P.X ; Zj/ dZ
D log
Z
q.Z/P.X ; Zj/
q.Z/
dZ

Z
q.Z/ log P.X ; Zj/ dZ  Z
q.Z/ log q.Z/ dZ
D EqŒlog P.X ; Zj/ C HŒq;
(A.8)
where EqŒf .X/ represents the expected value of f .X/ w.r.t. the distribution q, and HŒq denotes
the entropy of q. Again, the derivation follows from Jensen’s inequality and the concavity of the

156
A. PARAMETER ESTIMATION AND INFERENCE
logarithm. We denote the term EqŒlog P.X ; Zj/ C HŒq by L.q; /. It is possible to provide
a more detailed relationship between the data likelihood and the L.q; / term. We recall the
Kullback-Leibler divergence [45] between two density functions p and q,
KL.q; p/ D  Z
q.Z/ log p.Z/
q.Z/ dZ;
and deﬁne QPX; , P.ZjX ; / en, it can be easily veriﬁed that
log P.X j/ D L.q; / C KL.q; QPX;/:
Notice that Equation A.8 also follows from the fact that KL is a positive functional.
us, for a given parameter set , the term L.q; / expresses a lower bound of the likeli-
hood of the data, and, in particular, maximizing L.q; / with respect to q is equivalent to mini-
mizing the Kullback-Leibler divergence between q.Z/ and the posterior distribution P.ZjX ; /.
Also, when q is optimal, L.q; / represents the best possible approximation of log P.X j/, hence
optimizing EqŒlog P.X ; Zj/ with respect to  provides a suitable approximation of the optimal
parameter O that maximizes log P.X j/.
us, we can devise a variational EM procedure, where we alternatively optimize L.q; /:
• Initialize .0/;
• Iterate until convergence, for increasing steps t:
(E step) Given .t/, compute q.t/ D argmaxq L.q; .t//I
(M Step) Given q.t/, compute .tC1/ D argmax EqŒlog P.X ; Zj/:
ere are several similarities with the above procedure and the EM procedure discussed
in the previous section. In fact, when the posterior is tractable, the optimal value q is given by
imposing q.Z/ , P.ZjX ; /. In this case, the above procedure coincides with the standard EM
procedure outlined before. e problem arises when P.ZjX ; / is not tractable. In that case, q
represents an approximation that can be mathematically tractable. In particular, we can assume
a functional form q.Z/  q.ZjΛ/, which depends on some variational parameters Λ, and opti-
mize L.q; .t// with respect to such parameters. Exact equations for such optimizations can be
obtained when Z can be decomposed into Z1; : : : ; Zn, and we can provide a factorized deﬁnition
for q:
q.ZjΛ/ D
Y
i
qi.ZijΛi/;

A.2. VARIATIONAL INFERENCE
157
where Λ D fΛ1; : : : ; Λng. In such a case, for a generic index i, we can assume qj ﬁxed for all
j ¤ i, and rewrite L.q; / as:
L.q; / D
Z
qi.ZijΛi/
8
<
:
Z Y
j ¤i
qj .Zj jΛj / log P.Z; X j/ dZj
9
=
; dZi
 Z
qi.ZijΛi/
8
<
:
Z Y
j ¤i
qj .Zj jΛj /
8
<
:log qi.ZijΛi/ C
X
j ¤i
log qj .Zj jΛj /
9
=
; dZj
9
=
; dZi
D
Z
qi.ZijΛi/
8
<
:
Z Y
j ¤i
qj .Zj jΛj / log P.Z; X j/ dZj
9
=
; dZi
 Z
qi.ZijΛi/
8
<
:log qi.ZijΛi/
Z Y
j ¤i
qj .Zj jΛj / dZj
9
=
; dZi
 8
<
:
Z Y
j ¤i
qj .Zj jΛj /
X
j¤i
log qj .Zj jΛj / dZj
9
=
;
Z
qi.ZijΛi/ dZi
D
Z
qi.ZijΛi/
8
<
:
Z Y
j ¤i
qj .Zj jΛj / log P.Z; X j/ dZj
9
=
; dZi
 Z
qi.ZijΛi/ log qi.ZijΛi/ dZi
C const:
Consider now the term
Z Y
j ¤i
qj .Zj jΛj / log P.Z; X j/ dZj :
By introducing a density function fi.Zi; X j/ deﬁned by the relationship
fi.Zi; X j/ / exp
8
<
:
Z Y
j ¤i
qj .Zj jΛj / log P.Z; X j/ dZj
9
=
; ;
we can rewrite the above expression as:
L.q; / D
Z
qi.ZijΛi/
8
<
:
Z Y
j ¤i
qj .Zj jΛj / log P.Z; X j/ dZj
9
=
; dZi
 Z
qi.ZijΛi/ log qi.ZijΛi/ dZi C const
/
Z
qi.ZijΛi/ log fi.Zi; X j/ dZi  Z
qi.ZijΛi/ log qi.ZijΛi/ dZi
D   KL.qi; fi/:

158
A. PARAMETER ESTIMATION AND INFERENCE
at is to say, the component L.q; / can be interpreted in terms of the Kullback-Leibler diver-
gence between the factor qi and the density fi deﬁned above, provided that all the remaining qj
components with j ¤ i are ﬁxed. e minimal value for such divergence can be obtained when
qi D fi, i.e., by solving the equation
qi.ZijΛi/ D 1
Wi
exp
8
<
:
Z Y
j ¤i
qj .Zj jΛj / log P.Z; X j/ dZj
9
=
; :
(A.9)
Wi represents a normalization factor, and, in general, we can choose a functional form for qi
such that Equation A.9 admits a closed solution for the variational parameter Λi. Dependencies
amongst the Λi parameters can be solved by iterating the estimation, until convergence has been
reached.
A.3
GIBBS SAMPLING
An alternative approach to variational approximation is to approach the problem of estimating
P.ZjX ; / in a diﬀerent, stochastic way, by using sampling techniques. Suppose that, although
P.ZjX ; / cannot be computed analytically, it is possible to sample speciﬁc values
˚
Z.l/	
lD1;:::;L.
Recall that, by Jensen inequality,
log P.X j/ 
Z
P.ZjX ; / log P.X ; Zj/ dZ:
e latter inequality suggests that we generalize the EM approach by deﬁning the complete-data
expectation log-likelihood,
Q.; 0/ D
Z
P.ZjX ; 0/ log P.X ; Zj/ dZ;
and then alternating the optimization by inferring P.ZjX ; 0/ given 0 (E step), and subse-
quently by optimizing Q.; 0/ with respect to  given P.ZjX ; 0/. Since we are not able to
infer P.ZjX ; 0/, but we instead can sample
˚
Z.l/	
lD1;:::;L, we can approximate the complete-
data expectation log likelihood as:
Q.; 0/  1
L
L
X
lD1
log P.X ; Z.l/j/:
(A.10)
e latter does not depend on the posterior anymore, and hence can be approximated directly. In
practice, the stochastic sample Z.l/ is used in place of the posterior distribution, thus resolving the
complete data expectation likelihood in a stochastic version where the latent factors are statically
assigned. We can hence devise a general stochastic expectation maximization procedure, as follows.

A.3. GIBBS SAMPLING
159
• Initialize .0/;
• Iterate until convergence, for increasing steps t:
(E step) For l D 1; : : : ; L sample Z.l/  P.ZjX ; .t//I
(M Step) Compute .tC1/ D argmax 1=L P
l log P.X ; Z.l/j/:
Clearly, the core of the approach is the capability of sampling Z.l/ from the posterior dis-
tribution. Several methods can be employed in this settings [31, 138]. We shall concentrate on
Monte Carlo methods, and in particular with Gibbs sampling, which is a special case of Markov
chain Montecarlo (MCMC) approximation [12]. MCMC methods approximate the probability
P.x/ corresponding to a high-dimensional variable x , x1; : : : ; xn by a random walk on the state
space governed by a Markov chain. e underlying idea of the Gibbs sampling procedure is the
following. Assume an initial state x.0/
1 ; : : : ; x.0/
n
of the Markov chain. Each step of the Gibbs
sampling procedure involves replacing the value of one of the variables by a value drawn from the
distribution of that variable conditioned on the values of the remaining variables. at is, assum-
ing that the probability P.xijx1; : : : ; xi 1; xiC1; : : : ; xn/ is tractable, we can compute the next
state of the sampling process by iteratively sampling
x.t/
i
 P.xijx.t/
1 ; : : : ; x.t/
i 1; x.t 1/
iC1 ; : : : ; x.t 1/
n
/:
is procedure is repeated by cycling through the variables in some particular order.
To our purposes, the Gibbs sampler
can be applied to estimate the posterior
P.ZjX ; /. In this case, assuming that Z can be decomposed into z1; : : : ; zM and that
P.zijz1; : : : ; zi 1; ziC1; : : : ; zM; X ; / is tractable, the E step of the above procedure can be
reﬁned into the following steps.
(Initialization) Randomly initialize z1; : : : ; zM;
[(Burn-in) ] for t D 1; : : : ; T , iteratively compute
z.t/
i
 P.zijz.tC1/
1
; : : : ; z.tC1/
i 1 ; z.t/
iC1; : : : ; z.t/
M ; X ; /
to stabilize the initialization;
(E Step) Repeat the sampling process for each zi.

Bibliography
[1] R.P. Adams, G.E. Dahl, and I. Murray. Incorporating side information in probabilis-
tic matrix factorization with gaussian processes. In Proceedings of the 26th Conference on
Uncertainty in Artiﬁcial Intelligence, pages 1–9, 2010. 50
[2] D. Agarwal and B.C. Chen. Regression-based latent factor models. In Proceedings of the
15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
KDD ’09, pages 19–28, 2009. DOI: 10.1145/1557019.1557029. 112, 113, 114
[3] D. Agarwal and B.C. Chen. ﬂda: matrix factorization through latent dirichlet allocation.
In Proceedings of the 6th ACM International Conference on Web Search and Data Mining,
WSDM ’10, pages 91–100, 2010. DOI: 10.1145/1718487.1718499. 112, 115
[4] D. Agarwal and S. Merugu. Predictive discrete latent factor models for large scale dyadic
data. In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Dis-
covery and Data Mining, KDD ’07, pages 26–35, 2007. DOI: 10.1145/1281192.1281199.
44
[5] C.C. Aggarwal, J.L. Wolf, K.L. Wu, and P.S. Yu. Horting hatches an egg: a new graph-
theoretic approach to collaborative ﬁltering. In Proceedings of the 5th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining, KDD ’99, pages 201–212,
1999. DOI: 10.1145/312129.312230. 9
[6] A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in
latent variable models. In Proceedings of the 8th ACM International Conference on Web Search
and Data Mining, WSDM ’12, pages 123–132, 2012. DOI: 10.1145/2124295.2124312.
85
[7] L. M. Aiello, A. Barrat, R. Schifanella, C. Cattuto, B. Markines, and F. Menczer. Friend-
ship prediction and homophily in social media. ACM Transactions on the Web, 6(2):9:1–
9:33, 2012. DOI: 10.1145/2180861.2180866. 128
[8] E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing. Mixed membership stochastic
blockmodels. Journal of Machine Learning Research, 9:1981–2014, 2008. 135
[9] M. Al Hasan and M.J. Zaki. A survey of link prediction in social networks. In Social Net-
work Data Analytics, pages 243–275. Springer, 2011. DOI: 10.1007/978-1-4419-8462-
3_9. 131

162
BIBLIOGRAPHY
[10] L. AlSumait, D. Barbará, and C. Domeniconi. On-line lda: Adaptive topic models for
mining text streams with applications to topic detection and tracking. In Proceedings of the
8th IEEE International Conference on Data Mining, ICDM ’08, pages 3–12, 2008. DOI:
10.1109/ICDM.2008.140. 150
[11] A. Anagnostopoulos, R. Kumar, and M. Mahdian.
Inﬂuence and correlation in
social networks.
In Proceedings of the 14th ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining, KDD ’08, pages 7–15, 2008. DOI:
10.1145/1401890.1401897. 138
[12] C. Andrieu, N. de Freitas, A. Doucet, and Michael I. Jordan.
An introduc-
tion to mcmc for machine learning.
Machine Learning, 50(1-2):5–43, 2003. DOI:
10.1023/A:1020281327116. 159
[13] A. Asuncion, M. Welling, P. Smyth, and Y.W. Teh. On smoothing and inference for topic
models. In Proceedings of the 25th Conference on Uncertainty in Artiﬁcial Intelligence, UAI
’09, pages 27–34, 2009. 85
[14] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley
Longman Publishing Co., Inc., Boston, MA, USA, 1999. 5, 11, 12
[15] A. Banerjee and S. Basu. Topic models over text streams: A study of batch and online
unsupervised learning. In Proceedings of the 7th SIAM Conference on Data Mining, SDM
’07, pages 431–436, 2007. 150
[16] N. Barbieri. Regularized gibbs sampling for user proﬁling with soft constraints. In Pro-
ceeding of the International Conference on Advances in Social Networks Analysis and Mining,
ASONAM ’11, pages 129–136, 2011. DOI: 10.1109/ASONAM.2011.92. 65
[17] N. Barbieri, G. Costa, G. Manco, and R. Ortale.
Modeling item selection and
relevance for accurate recommendations: a bayesian approach.
In Proceedings of the
5th ACM Conference on Recommender Systems, RecSys ’11, pages 21–28, 2011. DOI:
10.1145/2043932.2043941. 65, 100
[18] N. Barbieri, G. Costa, G. Manco, and E. Ritacco. Characterizing relationships through
co-clustering - a probabilistic approach. In Proceedings of the International Conference on
Knowledge Discovery and Information Retrieval, KDIR ’11, pages 64–73, 2011. 43, 44
[19] N. Barbieri and G. Manco. An analysis of probabilistic methods for top-n recommenda-
tion in collaborative ﬁltering. In Proceedings of the European Conference on Machine learning
and Knowledge Discovery in Databases, ECML/PKDD ’11, pages 172–187, 2011. DOI:
10.1007/978-3-642-23780-5_21. 100

BIBLIOGRAPHY
163
[20] N. Barbieri, G. Manco, R. Ortale, and E. Ritacco. Balancing prediction and recommen-
dation accuracy: Hierarchical latent factors for preference data. In Proceedings of the 12th
SIAM International Conference on Data Mining, SDM ’12, pages 1035–1046, 2012. DOI:
10.1137/1.9781611972825.89. 73, 100
[21] N. Barbieri, G. Manco, and E. Ritacco.
A probabilistic hierarchical approach for
pattern discovery in collaborative ﬁltering data.
In Proceedings of the 11th SIAM
International Conference on Data Mining, SDM ’11, pages 630–621, 2011. DOI:
10.1137/1.9781611972818.54. 36
[22] N. Barbieri, G. Manco, E. Ritacco, M. Carnuccio, and A. Bevacqua. Probabilistic topic
models for sequence data. Machine Learning, pages 1–25, 2013. DOI: 10.1007/s10994-
013-5391-2. 124
[23] R. Bell, Y. Koren, and C. Volinsky. Modeling relationships at multiple scales to improve
accuracy of large recommender systems. In Proceedings of the 13th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining, KDD ’07, pages 95–104,
2007. DOI: 10.1145/1281192.1281206. 16
[24] R.M. Bell and Y. Koren.
Improved neighborhood-based collaborative ﬁltering.
In
Proceedings of the KDD Cup and Workshop in conjunction with KDD, 2007. DOI:
10.1016/j.patrec.2011.10.016. 22
[25] R.M. Bell and Y. Koren. Scalable collaborative ﬁltering with jointly derived neighborhood
interpolation weights. In Proceedings of the 7th IEEE International Conference on Data
Mining, ICDM ’07, pages 43–52, 2007. DOI: 10.1109/ICDM.2007.90. 16
[26] iago Belluf, Leopoldo Xavier, and Ricardo Giglio. Case study on the business value
impact of personalized recommendations on a large online retailer. In Proceedings of the
6th ACM Conference on Recommender Systems, RecSys ’12, pages 277–280, 2012. DOI:
10.1145/2365952.2366014. 149
[27] J. Bennett, S. Lanning, and Netﬂix. e netﬂix prize. In Proceedings of the KDD Cup and
Workshop in conjunction with KDD, 2007. 1
[28] A.L. Berger, S.A. Della Pietra, and V.J. Della Pietra. A maximum entropy approach to
natural language processing. Computational Linguistic, 22(1):39–71, 1996. 28
[29] M.W. Berry, S.T. Dumais, and G.W. O’Brien. Using linear algebra for intelligent infor-
mation retrieval. SIAM Review, 37(4):573–595, 1995. DOI: 10.1137/1037127. 18
[30] D. Billsus and M.J. Pazzani. Learning collaborative information ﬁlters. In Proceedings of
the 15th International Conference on Machine Learning, ICML ’98, pages 46–54, 1998. 18

164
BIBLIOGRAPHY
[31] C. M. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York,
Inc., 2006. 23, 32, 53, 60, 81, 89, 117, 121, 123, 155, 159
[32] D. M. Blei. Introduction to probabilistic topic models. Communications of the ACM, 2011.
DOI: 10.1145/2133806.2133826. 45
[33] D.M. Blei and J.D. Mcauliﬀe.
Supervised topic models.
In Proceedings of the annual
conference on Advances in Neural Information Processing Systems, NIPS ’08, 2008. 112
[34] D.M. Blei, A.Y. Ng, and M.I. Jordan. Latent dirichlet allocation. Journal of Machine
Learning Research, 3(1):993–1022, 2003. 45, 46, 61, 62
[35] F. Bonchi. Inﬂuence propagation in social networks: A data mining perspective. IEEE
Intelligent Informatics Bulletin, 12(1):8–16, 2011. DOI: 10.1109/WI-IAT.2011.286. 137
[36] J.S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms
for collaborative ﬁltering. In Proceedings of the 14th Conference on Uncertainty in Artiﬁcial
Intelligence, UAI ’98, pages 43–52, 1998. 14
[37] I. Cadez, D. Heckerman, C. Meek, P. Smyth, and S. White. Visualization of naviga-
tion patterns on a web site using model-based clustering. In Proceedings of the 6th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’00,
pages 280–284, 2000. 118
[38] J. Canny. Collaborative ﬁltering with privacy. In Proceedings of the IEEE Symposium on
Security and Privacy, SP ’02, pages 45+, 2002. DOI: 10.1145/347090.347151. 9, 10
[39] J. Canny. Collaborative ﬁltering with privacy via factor analysis. In Proceedings of the 25th
ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’02,
pages 238–245, 2002. DOI: 10.1145/564376.564419. 10
[40] M. Caraciolo. Recommendations and how to measure the roi with some metrics ? 149
[41] M. Cha, H. Haddadi, F. Benevenuto, and K.P. Gummadi. Measuring user inﬂuence in
twitter: e million follower fallacy. In Proceedings of the 4th AAAI Conference on Weblogs
and Social Media, ICWSM ’10, 2010. 140
[42] Youngchul Cha and Junghoo Cho. Social-network analysis using topic models. In Pro-
ceedings of the 35th ACM SIGIR Conference on Research and Development in Information
Retrieval, SIGIR ’12, pages 565–574, 2012. DOI: 10.1145/2348283.2348360. 134
[43] W. Chen, C. Wang, and Y. Wang. Scalable inﬂuence maximization for prevalent viral
marketing in large-scale social networks. In Proceedings of the 16th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining, KDD ’10, pages 1029–1038,
2010. DOI: 10.1145/1835804.1835934. 140

BIBLIOGRAPHY
165
[44] Y. Chen, W. Peng, and S. Lee.
Eﬃcient algorithms for inﬂuence maximization
in social networks.
Knowledge and Information Systems, 33(3):577–601, 2012. DOI:
10.1007/s10115-012-0540-7. 140
[45] T.M. Cover and J.A. omas. Elements of Information eory. Wiley-Interscience, New
York, NY, USA, 2006. 30, 153, 156
[46] D. Crandall, D. Cosley, D. Huttenlocher, J. Kleinberg, and S. Suri.
Feedback eﬀects
between similarity and social inﬂuence in online communities. In Proceedings of the 14th
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD
’08, pages 160–168, 2008. DOI: 10.1145/1401890.1401914. 128
[47] P. Cremonesi, Y. Koren, and R. Turrin. Performance of recommender algorithms on top-n
recommendation tasks. In Proceedings of the 4th ACM Conference on Recommender Systems,
RecSys ’10, pages 39–46, 2010. DOI: 10.1145/1864708.1864721. 6, 87, 97, 98
[48] J. N. Darroch and D. Ratcliﬀ. Generalized iterative scaling for log-linear models. e
Annals of Mathematical Statistics, 43:1470–1480, 1972. DOI: 10.1214/aoms/1177692379.
29
[49] A.S. Das, M. Datar, A. Garg, and S. Rajaram. Google news personalization: scalable
online collaborative ﬁltering. In Proceedings of the 16th international conference on World
Wide Web, WWW ’07, pages 271–280, 2007. DOI: 10.1145/1242572.1242610. 1
[50] S.C Deerwester, S.T. Dumais, T.K. Landauer, G.W. Furnas, and R.A. Harshman. In-
dexing by latent semantic analysis.
Journal of the American Society for Information Sci-
ence, 41(6):391–407, 1990. DOI: 10.1002/(SICI)1097-4571(199009)41:6%3C391::AID-
ASI1%3E3.0.CO;2-9. 17
[51] A.P. Dempster, N.M. Laird, and D.B. Rubin. Maximum likelihood from incomplete data
via the em algorithm. Journal of the Royal Statistical Society. Series B, 39(1):1–38, 1977. 34
[52] I.S. Dhillon and D.S. Modha. Concept decompositions for large sparse text data using
clustering. Machine Learning, 42(1-2):143–175, 2001. DOI: 10.1023/A:1007612920971.
12
[53] O. Domingos and M. Richardson. Mining the network value of customers. In Proceed-
ings of the 7th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, KDD ’01, pages 57–66, 2001. DOI: 10.1145/502512.502525. 139
[54] L. Du, W. L. Buntine, and H. Jin. Sequential latent dirichlet allocation: Discover underly-
ing topic structures within a document. In Proceedings of the 10th IEEE International Con-
ference on Data Mining, ICDM ’10, pages 148–157, 2010. DOI: 10.1109/ICDM.2010.51.
123

166
BIBLIOGRAPHY
[55] E. Erosheva, S. Fienberg, and J. Laﬀerty. Mixed-membership models of scientiﬁc pub-
lications.
Proceedings of the National Academy of Science, 101:5220–5227, 2004. DOI:
10.1073/pnas.0307760101. 132
[56] T. Fawcett. An introduction to roc analysis. Pattern Recognition Letters, 27(8):861–874,
2006. DOI: 10.1016/j.patrec.2005.10.010. 5
[57] M.A.T. Figueiredo and A.K. Jain. Unsupervised learning of ﬁnite mixture models. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 24(3):381–396, 2002. DOI:
10.1109/34.990138. 57
[58] D. Fink. A compendium of conjugate priors, 1997. 54
[59] N. E. Friedkin. A Structural eory of Social Inﬂuence. Cambridge University Press, 1998.
DOI: 10.1017/CBO9780511527524. 128
[60] S. Funk. Netﬂix update: Try this at home. URL:
http://sifter.org/ simon/Journal/20061211.html, 2006. 19, 20
[61] M. Ge, C. Delgado-Battenfeld, and D. Jannach. Beyond accuracy: evaluating recom-
mender systems by coverage and serendipity. In Proceedings of the 4th ACM Conference on
Recommender Systems, RecSys ’10, pages 257–260, 2010. DOI: 10.1145/1864708.1864761.
149
[62] A. Gelman, J.B. Carlin, H.S. Stern, and D.B. Rubin. Bayesian Data Analysis. Chapman
& ofHall/CRC Press, 2004. 53, 62
[63] T. George and S. Merugu.
A scalable collaborative ﬁltering framework based on co-
clustering. In Proceedings of the 5th IEEE International Conference on Data Mining, ICDM
’05, pages 625–628, 2005. DOI: 10.1109/ICDM.2005.14. 40
[64] S.J. Gershman and D.M. Blei. A tutorial on bayesian nonparametric models. Journal of
Mathematical Psychology, 56(1):1–12, 2012. DOI: 10.1016/j.jmp.2011.08.004. 150
[65] M. Girolami and A. Kabán. On an equivalence between plsi and lda. In Proceedings of the
26th ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR
’03, pages 433–434, 2003. DOI: 10.1145/860435.860537. 46
[66] Malcolm Gladwell. e tipping point: how little things can make a big diﬀerence. Little
Brown, 2000. 137
[67] A. Gohr, A. Hinneburg, R. Schult, and M. Spiliopoulou. Topic evolution in a stream of
documents. In Proceedings of the 9th SIAM Conference on Data Mining, SDM ’09, pages
859–872, 2009. 150

BIBLIOGRAPHY
167
[68] P. Gopalan, D.M. Mimno, S. Gerrish, M.J. Freedman, and D. M. Blei. Scalable inference
of overlapping communities. In Proceedings of the annual conference on Advances in Neural
Information Processing Systems, NIPS ’12, pages 2258–2266, 2012. 137
[69] G. Govaert and M. Nadif. Clustering with block mixture models. Pattern Recognition,
36(2):463–473, 2003. DOI: 10.1016/S0031-3203(02)00074-2. 42, 43
[70] G. Govaert and M. Nadif.
An em algorithm for the block mixture model.
IEEE
Transactions on Pattern Analysis and Machine Intelligence, 27(4):643–647, 2005. DOI:
10.1109/TPAMI.2005.69. 40, 42
[71] A. Goyal, F. Bonchi, and L. Lakshmanan. Learning inﬂuence probabilities in social net-
works. In Proceedings of the 6th ACM International Conference on Web Search and Data
Mining, WSDM ’10, pages 241–250, 2010. DOI: 10.1145/1718487.1718518. 141
[72] A. Goyal, F. Bonchi, and L.V.S. Lakshmanan. A data-based approach to social inﬂuence
maximization. Proceedings of the VLDB Endowment, 5(1):73–84, 2011. 140
[73] A. Goyal and L. Lakshmanan.
Recmax: exploiting recommender systems for fun
and proﬁt.
In Proceedings of the 18th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, KDD ’12, pages 1294–1302, 2012. DOI:
10.1145/2339530.2339731. 144
[74] T. L. Griﬃths, M. Steyvers, and J. B. Tenenbaum. Topics in semantic representation.
Psychological Review, 114, 2007. DOI: 10.1037/0033-295X.114.2.211. 123
[75] T.L. Griﬃths and M. Steyvers.
Finding scientiﬁc topics.
Proceedings of the National
Academy of Sciences, 101:5228–5235, 2004. DOI: 10.1073/pnas.0307752101. 62
[76] A. Gruber, Y. Weiss, and M. Rosen-Zvi. Hidden topic markov models. Journal of Machine
Learning Research, 2:162–170, 2007. 123
[77] G. Heinrich.
Parameter estimation for text analysis.
Technical report, University of
Leipzig, 2008. 62
[78] J. Herlocker, J.A. Konstan, and J. Riedl.
An empirical analysis of design choices in
neighborhood-based collaborative ﬁltering algorithms. Information Retrieval, 5(4):287–
310, 2002. DOI: 10.1023/A:1020443909834. 15
[79] J.L. Herlocker, J. A. Konstan, L.G. Terveen, and J. T. Riedl. Evaluating collaborative
ﬁltering recommender systems. ACM Transactions on Information Systems, 22(1):5–53,
2004. DOI: 10.1145/963770.963772. 4
[80] M.D. Hoﬀman, D.M. Blei, and F.R. Bach. Online learning for latent dirichlet allocation.
In Proceedings of the annual conference on Advances in Neural Information Processing Systems,
NIPS ’10, 2010. 85

168
BIBLIOGRAPHY
[81] T. Hofmann. Probabilistic latent semantic indexing. In Proceedings of the 22nd ACM SIGIR
Conference on Research and Development in Information Retrieval, SIGIR ’99, pages 50–57,
1999. DOI: 10.1145/312624.312649. 46, 47
[82] T. Hofmann. Learning what people (don’t) want. In Proceedings of the 12th European
Conference on Machine Learning, ECML ’01, pages 214–225. Springer-Verlag, 2001. DOI:
10.1023/A:1007617005950. 48
[83] T. Hofmann. Unsupervised learning by probabilistic latent semantic analysis. Machine
Learning, 42(1):177–196, 2001. DOI: 10.1023/A:1007617005950. 46
[84] T. Hofmann. Collaborative ﬁltering via gaussian probabilistic latent semantic analysis. In
Proceedings of the 26th ACM SIGIR Conference on Research and Development in Information
Retrieval, SIGIR ’03, pages 259–266, 2003. DOI: 10.1145/860435.860483. 48
[85] T. Hofmann. Latent semantic models for collaborative ﬁltering. ACM Transactions on
Information Systems, 22(1):89–115, 2004. DOI: 10.1145/963770.963774. 27
[86] T. Hofmann and J. Puzicha. Latent class models for collaborative ﬁltering. In Proceedings
of the 16th International Joint Conference on Artiﬁcial Intelligence, IJCAI ’99, pages 688–693.
Morgan Kaufmann Publishers Inc., 1999. 9, 38, 41
[87] L. Hong, A. Ahmed, S. Gurumurthy, A.J. Smola, and K. Tsioutsiouliklis. Discovering
geographical topics in the twitter stream. In Proceedings of the 21st International Conference
on World Wide Web, WWW ’12, pages 769–778, 2012. DOI: 10.1145/2187836.2187940.
149
[88] P.O. Hoyer. Non-negative matrix factorization with sparseness constraints. J. Mach. Learn.
Res., 5:1457–1469, 2004. 20
[89] F. Huang, C. Hsieh, K. Chan, and C. Lin. Iterative scaling and coordinate descent meth-
ods for maximum entropy models. Journal of Machine Learning Research, 11:815–848,
2010. 31
[90] N.J. Hurley, M.P. O’Mahony, and G.C.M. Silvestre.
Attacking recommender sys-
tems: A cost-beneﬁt analysis.
IEEE Intelligent Systems, 22(3):64–68, 2007. DOI:
10.1109/MIS.2007.44. 150
[91] A. Ilin and T. Raiko. Practical approaches to principal component analysis in the presence
of missing values. Journal of Machine Learning Research, 11(1):1957–2000, 2010. 80
[92] T. Iwata, T. Yamada, Y. Sakurai, and N Ueda. Online multiscale dynamic topic models.
In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, KDD ’10, pages 663–672, 2010. DOI: 10.1145/1835804.1835889. 150

BIBLIOGRAPHY
169
[93] A.K Jain, M.N. Murty, and P.J. Flynn. Data clustering: a review. ACM Computing Surveys,
31(3):264–323, 1999. DOI: 10.1145/331499.331504. 12
[94] M. Jamali and M. Ester. Trustwalker: a random walk model for combining trust-based
and item-based recommendation. In Proceedings of the 15th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, KDD ’09, pages 397–406, 2009.
DOI: 10.1145/1557019.1557067. 131
[95] M. Jamali, G. Haﬀari, and M. Ester. Modeling the temporal dynamics of social rating
networks using bidirectional eﬀects of social relations and rating patterns. In Proceedings
of the 20th International Conference on World Wide Web, WWW ’11, pages 527–536, 2011.
DOI: 10.1145/1963405.1963480. 130, 131
[96] M. Jamali, T. Huang, and M. Ester. A generalized stochastic block model for recommen-
dation in social rating networks. In Proceedings of the 5th ACM Conference on Recommender
Systems, RecSys ’11, pages 53–60, 2011. DOI: 10.1145/2043932.2043946. 135
[97] E. T. Jaynes. Prior probabilities. IEEE Transactions on Systems Science and Cybernetics,
4(3):227–241, 1968. DOI: 10.1109/TSSC.1968.300117. 57
[98] R. Jin, L. Si, and C. Zhai. A study of mixture models for collaborative ﬁltering. Information
Retrieval, 9(3):357–382, 2006. DOI: 10.1007/s10791-006-4651-1. 41
[99] R. Jin, R. Yan, Z. Jian, and A.G. Hauptmann. A faster iterative scaling algorithm for con-
ditional exponential model. In Proceedings of the 20th International Conference on Machine
Learning, ICML’03, pages 282–289, 2003. 31
[100] X. Jin, Y. Zhou, and B. Mobasher.
Web usage mining based on probabilistic la-
tent semantic analysis. In Proceedings of the 10th ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining, KDD ’04, pages 197–205, 2004. DOI:
10.1145/1014052.1014076. 101, 102
[101] M.I. Jordan.
Graphical models.
Statistical Science, 19:140–155, 2004. DOI:
10.1214/088342304000000026. 25
[102] M.I. Jordan, Z. Ghahramani, T.S. Jaakkola, and L.K. Saul.
An introduction to vari-
ational methods for graphical models.
Machine learning, 37(2):183–233, 1999. DOI:
10.1023/A:1007665907178. 155
[103] G. Karypis. Evaluation of item-based top-n recommendation algorithms. In Proceedings of
the 10th International Conference on Information and Knowledge Management, CIKM ’01,
pages 247–254, 2001. DOI: 10.1145/502585.502627. 4

170
BIBLIOGRAPHY
[104] D. Kempe, J. Kleinberg, and É. Tardos.
Maximizing the spread of inﬂuence through
a social network.
In Proceedings of the 9th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, KDD ’03, pages 137–146, 2003. DOI:
10.1145/956750.956769. 139, 140
[105] M. Kimura and K. Saito.
Tractable models for information diﬀusion in social net-
works.
In Proceedings of the European Conference on Machine learning and Knowledge
Discovery in Databases, volume 4213 of ECML/PKDD ’06, pages 259–271, 2006. DOI:
10.1007/11871637_27. 140
[106] Y. Koren.
Factorization meets the neighborhood: a multifaceted collaborative ﬁl-
tering model.
In Proceedings of the 14th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, KDD ’08, pages 426–434, 2008. DOI:
10.1145/1401890.1401944. 21
[107] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender
systems. IEEE Computer, 42(8):30–37, 2009. DOI: 10.1109/MC.2009.263. 21
[108] B. Krulwich and C. Burkey. Lifestyle ﬁnder: Intelligent user proﬁling using large-scale
demographic data. AI Magazine, 18(2):37–45, 1997. DOI: 10.1609/aimag.v18i2.1292.
11
[109] S.K. Lam and J. Riedl. Shilling recommender systems for fun and proﬁt. In Proceedings
of the 13th International Conference on World Wide Web, WWW ’04, pages 393–402, 2004.
DOI: 10.1145/988672.988726. 10
[110] K. Lang. Newsweeder: Learning to ﬁlter netnews. In Proceedings of the 17th International
Conference on Machine Learning, ICML ’00, 2000. 11
[111] N. Lathia, S. Hailes, L. Capra, and X. Amatriain. Temporal diversity in recommender sys-
tems. In Proceedings of the 33rd ACM SIGIR Conference on Research and Development in In-
formation Retrieval, SIGIR ’10, pages 210–217, 2010. DOI: 10.1145/1835449.1835486.
149
[112] D.D. Lee and H.S. Seung. Learning the parts of objects by nonnegative matrix factoriza-
tion. Nature, 401:788–791, 1999. DOI: 10.1038/46985. 20
[113] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, J. VanBriesen, and N. Glance. Cost-
eﬀective outbreak detection in networks. In Proceedings of the 13th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining, KDD ’07, pages 420–429,
2007. DOI: 10.1145/1281192.1281239. 140
[114] H. Lieberman. Letizia: An agent that assists web browsing. In Proceedings of the 12th
International Joint Conference on Artiﬁcial Intelligence, IJCAI ’95, pages 924 – 929, 1995.
13

BIBLIOGRAPHY
171
[115] Y.W. Lim and Y.W. Teh. Variational bayesian approach to movie rating prediction. In
Proceedings of KDD Cup and Workshop in conjunction with KDD, 2007. 80
[116] D. C. Liu and J. Nocedal. On the limited memory bfgs method for large scale optimization.
Mathematical Programming, 45(3):503–528, 1989. DOI: 10.1007/BF01589116. 31
[117] L. Liu, J. Tang, J. Han, M. Jiang, and S. Yang.
Mining topic-level inﬂuence in
heterogeneous networks.
In Proceedings of the 19th ACM International Conference
on Information and Knowledge Management, CIKM ’10, pages 199–208, 2010. DOI:
10.1145/1871437.1871467. 143
[118] H. Ma, H. Yang, M.R. Lyu, and I. King.
Sorec: social recommendation using prob-
abilistic matrix factorization.
In Proceedings of the 17th ACM International Conference
on Information and Knowledge Management, CIKM ’08, pages 931–940, 2008. DOI:
10.1145/1458082.1458205. 134
[119] H. Ma, D. Zhou, C. Liu, M. R. Lyu, and I. King. Recommender systems with social
regularization. In Proceedings of the 7th ACM International Conference on Web Search and
Data Mining, WSDM ’11, pages 287–296, 2011. DOI: 10.1145/1935826.1935877. 132
[120] R. Malouf. A comparison of algorithms for maximum entropy parameter estimation. In
Proceedings of the 6th Conference on Natural Language Learning, CoNLL, CoNLL ’02, pages
1–7, 2002. DOI: 10.3115/1118853.1118871. 31
[121] U. Manber, A. Patel, and J. Robison. Experience with personalization on yahoo! Commu-
nications of the ACM, 43(8):35–39, 2000. DOI: 10.1145/345124.345136. 11
[122] C. D. Manning and H. Schütze. Foundations of Statistical Natural Language Processing.
MIT Press, 1999. 121
[123] B. Marlin. Modeling user rating proﬁles for collaborative ﬁltering. In Proceedings of the
annual conference on Advances in Neural Information Processing Systems, NIPS ’03, 2003. 65
[124] B. Marlin.
Collaborative ﬁltering: A machine learning perspective.
Technical report,
Department of Computer Science University of Toronto, 2004. 36
[125] P. Massa and P. Avesani. Trust-aware bootstrapping of recommender systems. In Pro-
ceedings of the ECAI Workshop on Recommender Systems, pages 29–33, 2006. 129
[126] S. M. McNee, J. Riedl, and J.A. Konstan. Being accurate is not enough: how accuracy
metrics have hurt recommender systems. In Proceedings of the CHI ’06 Extended Abstracts
on Human Factors in Computing Systems, CHI EA ’06, pages 1097–1101, 2006. DOI:
10.1145/1125451.1125659. 87, 108, 149

172
BIBLIOGRAPHY
[127] M. McPherson, L. Smith-Lovin, and J. M. Cook.
Birds of a feather: Homophily in
social networks.
Annual Review of Sociology, 27(1):415–444, 2001. DOI: 10.1146/an-
nurev.soc.27.1.415. 128
[128] Q. Mei, D. Cai, D. Zhang, and C. Zhai. Topic modeling with network regularization.
In Proceedings of the 17th international conference on World Wide Web, WWW ’08, pages
101–110, 2008. DOI: 10.1145/1367497.1367512. 132
[129] Q. Mei, X. Shen, and C. Zhai. Automatic labeling of multinomial topic models. In
Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, KDD ’07, pages 490–499, 2007. DOI: 10.1145/1281192.1281246. 102
[130] A. K. Menon, X. Jiang, S. Vembu, C. Elkan, and L. Ohno-Machado. Predicting accurate
probabilities with a ranking loss. In Proceedings of the 29th International Conference on
Machine Learning, ICML ’12, 2012. 89
[131] A.K. Menon and C. Elkan. A log-linear model with latent features for dyadic prediction.
In Proceedings of the 10th IEEE International Conference on Data Mining, ICDM ’10, pages
364–373, 2010. DOI: 10.1109/ICDM.2010.148. 28, 89, 112
[132] A.K. Menon and C. Elkan. Fast algorithms for approximating the singular value decom-
position. ACM Transactions on Knowledge Discovery in Databases, 5(2):1–1:36, 2011. DOI:
10.1145/1921632.1921639. 18
[133] A.K. Menon and C. Elkan.
Link prediction via matrix factorization.
In Proceedings
of the European Conference on Machine learning and Knowledge Discovery in Databases,
ECML/PKDD ’11, pages 437–452, 2011. DOI: 10.1007/978-3-642-23783-6_28. 21
[134] T. Minka and J. Laﬀerty. Expectation-propagation for the generative aspect model. In
Proceedings of the 18th Conference on Uncertainty in Artiﬁcial Intelligence, UAI ’02, pages
352–359, 2002. 62
[135] T.P. Minka. Estimating a dirichlet distribution. Technical report, Microsoft Research,
2000. 64
[136] B. Mobasher, R. Burke, R. Bhaumik, and C. Williams. Toward trustworthy recommender
systems: An analysis of attack models and algorithm robustness. ACM Transactions on
Internet Technology, 7(4):23, 2007. DOI: 10.1145/1278366.1278372. 10, 150
[137] T. Murakami, K. Mori, and R. Orihara. Metrics for evaluating the serendipity of recom-
mendation lists. In Proceedings of the Conference on New frontiers in artiﬁcial intelligence,
JSAI ’07, pages 40–46, 2008. DOI: 10.1007/978-3-540-78197-4_5. 149
[138] K.P. Murphy. Machine Learning: A Probabilistic Perspective. e MIT Press, Cambridge,
MA, USA, 2012. 23, 88, 155, 159

BIBLIOGRAPHY
173
[139] G. Manco N. Barbieri, F. Bonchi. Topic-aware social inﬂuence propagation models. In
Proceedings of the 12nd IEEE International Conference on Data Mining, ICDM ’12, pages
81–90, 2012. DOI: 10.1109/ICDM.2012.122. 143
[140] R. Nallapati, W. Cohen, and J. Laﬀerty.
Parallelized variational em for latent
dirichlet allocation: An experimental evaluation of speed and scalability.
In Proceed-
ings of the Seventh IEEE ICDM Conference Workshops, pages 349–354, 2007. DOI:
10.1109/ICDMW.2007.70. 84
[141] A. Narayanan and V. Shmatikov. How to break anonymity of the netﬂix prize dataset.
CoRR, abs/cs/0610105, 2006. 10
[142] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An analysis of approximations for
maximizing submodular set functions - i. Mathematical Programming, 14(1):265–294,
1978. DOI: 10.1007/BF01588971. 140
[143] D. Newman, A. Asuncion, P. Smyth, and M. Welling. Distributed algorithms for topic
models. Journal of Machine Learning Research, 10:1801–1828, 2009. 85
[144] J. Nocedal and S.J. Wright. Numerical optimization. Springer series in operations research
and ﬁnancial engineering. Springer, 2006. 31
[145] M. O’Mahony, N. Hurley, N. Kushmerick, and G. Silvestre. Collaborative recommenda-
tion: A robustness analysis. ACM Transactions on Internet Technology, 4(4):344–377, 2004.
DOI: 10.1145/1031114.1031116. 10
[146] M. Papagelis, D. Plexousakis, and T. Kutsuras. Alleviating the sparsity problem of collab-
orative ﬁltering using trust inferences. In P. Herrmann, V. Issarny, and S. Shiu, editors,
New Trends in Applied Artiﬁcial Intelligence, volume 3477 of Lecture Notes in Computer Sci-
ence, pages 224–239. Springer Berlin Heidelberg, 2005. 9
[147] E. Pariser. e ﬁlter bubble : what the Internet is hiding from you. Penguin Press, 2011. 108
[148] A. Paterek. Improving regularized singular value decomposition for collaborative ﬁltering.
In Proceedings of the KDD Cup and Workshop in conjunction with KDD, 2007. 21
[149] D. Pavlov, E. Manavoglu, D.M. Pennock, and C.L. Giles.
Collaborative ﬁlter-
ing with maximum entropy.
IEEE Intelligent Systems, 19(6):40–48, 2004. DOI:
10.1109/MIS.2004.59. 28
[150] M. Pazzani, D. Billsus, S. Michalski, and J. Wnek. Learning and revising user proﬁles:
e identiﬁcation of interesting web sites. Machine Learning, 27(3):313–331, 1997. DOI:
10.1023/A:1007369909943. 11

174
BIBLIOGRAPHY
[151] M.J. Pazzani. A framework for collaborative, content-based and demographic ﬁltering.
Artiﬁcial Intelligence Review, 13(5):393–408, 1999. DOI: 10.1023/A:1006544522159. 9
[152] M.J. Pazzani and D. Billsus. Content-based recommendation systems. In P. Brusilovsky,
A. Kobsa, and W. Nejdl, editors, e Adaptive Web, pages 325–341. Springer-Verlag,
Berlin, Heidelberg, 2007. DOI: 10.1007/978-3-540-72079-9. 13
[153] H. Polat and W. Du. Privacy-preserving collaborative ﬁltering using randomized pertur-
bation techniques. In Proceedings of the 3rd IEEE International Conference on Data Mining,
ICDM ’03, pages 625–628, 2003. DOI: 10.1109/ICDM.2003.1250993. 10
[154] A. Popescul, L. Ungar, D. Pennock, and S. Lawrence. Probabilistic models for uniﬁed col-
laborative and content-based recommendation in sparse-data environments. In Proceedings
of the 17th Conference on Uncertainty in Artiﬁcial Intelligence, UAI’ 01, pages 437–444, 2001.
9
[155] I. Porteous, E. Bart, and M. Welling. Multi-hdp: a non parametric bayesian model for
tensor factorization. In Proceedings of the National Conference of the American Association for
Artiﬁcial Intelligence, AAAI ’08, pages 1487–1490, 2008. 70
[156] I. Porteous, D. Newman, A. Ihler, A. Asuncion, P. Smyth, and M. Welling. Fast collapsed
gibbs sampling for latent dirichlet allocation. In Proceedings of the 14th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, KDD ’08, pages 569–
577, 2008. DOI: 10.1145/1401890.1401960. 84, 85
[157] N. Ramakrishnan, B.J. Keller, B.J. Mirza, A.Y. Grama, and G. Karypis.
Privacy
risks in recommender systems.
IEEE Internet Computing, 5(6):54–62, 2001. DOI:
10.1109/4236.968832. 10
[158] A.M. Rashid, I. Albert, D. Cosley, S.K. Lam, S.M. McNee, J.A. Konstan, and J. Riedl.
Getting to know you: learning new user preferences in recommender systems. In Proceed-
ings of the 7th International Conference on Intelligent User Interfaces, IUI ’10, pages 127–134,
2002. DOI: 10.1145/502716.502737. 9
[159] S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-ieme. Bpr: Bayesian person-
alized ranking from implicit feedback. In Proceedings of the 25th Conference on Uncertainty
in Artiﬁcial Intelligence, UAI ’09, pages 452–461, 2009. 89
[160] J.D. M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative
prediction. In Proceedings of the 22nd International Conference on Machine Learning, ICML
’05, pages 713–719, 2005. DOI: 10.1145/1102351.1102441. 20
[161] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl. Grouplens: An open
architecture for collaborative ﬁltering of netnews. In Proceedings of the ACM Conference on

BIBLIOGRAPHY
175
Computer Supported Cooperative Work, CSCW ’94, pages 175–186, New York, NY, USA,
1994. ACM. DOI: 10.1145/192844.192905. 69
[162] F. Ricci, L. Rokach, B. Shapira, and P.B. Kantor, editors. Recommender Systems Handbook.
Springer-Verlag, New York, NY, USA, 2010. 1
[163] M. Richardson and P. Domingos. Mining knowledge-sharing sites for viral marketing. In
Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, KDD ’02, pages 61–70, 2002. DOI: 10.1145/775047.775057. 139
[164] A. Saha and V. Sindhwani. Learning evolving and emerging topics in social media: a
dynamic nmf approach with temporal regularization. In Proceedings of the 8th ACM In-
ternational Conference on Web Search and Data Mining, WSDM ’12, pages 693–702, 2012.
DOI: 10.1145/2124295.2124376. 150
[165] K. Saito, M. Kimura, K. Ohara, and H. Motoda. Eﬃcient discovery of inﬂuential nodes for
sis models in social networks. Knowledge and Information Systems, 30(3):613–635, 2012.
DOI: 10.1007/s10115-011-0396-2. 140
[166] K. Saito, R. Nakano, and M. Kimura. Prediction of information diﬀusion probabilities
for independent cascade model.
In Proceedings of the 12th International Conference on
Knowledge-Based Intelligent Information and Engineering Systems, KES ’08, pages 67–75,
2008. DOI: 10.1007/978-3-540-85567-5_9. 141
[167] Patty Sakunkoo and Nathan Sakunkoo. Analysis of social inﬂuence in online book reviews.
In Proceedings of the 3rd International Conference on Weblogs and Social Media, ICSWM ’09,
2009. 129
[168] R. Salakhutdinov and A. Mnih. Bayesian probabilistic matrix factorization using markov
chain monte carlo. In Proceedings of the 25th International Conference on Machine Learning,
ICML ’08, pages 880–887, 2008. DOI: 10.1145/1390156.1390267. 50, 81, 125
[169] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In Proceedings of the
annual conference on Advances in Neural Information Processing Systems, NIPS ’08, pages
1257–1264, 2008. 49, 50
[170] G. Salton and M.J. McGill. Introduction to Modern Information Retrieval. McGraw-Hill,
Inc., New York, NY, USA, 1986. 11, 12
[171] J.J. Sandvig, B. Mobasher, and R. Burke. Robustness of collaborative recommendation
based on association rule mining. In Proceedings of the 1st ACM Conference on Recommender
Systems, RecSys ’07, pages 105–112, 2007. DOI: 10.1145/1297231.1297249. 10

176
BIBLIOGRAPHY
[172] R. L.T. Santos, C. Macdonald, and I. Ounis. Exploiting query reformulations for web
search result diversiﬁcation. In Proceedings of the 19th International Conference on World
Wide Web, WWW ’10, pages 881–890, 2010. DOI: 10.1145/1772690.1772780. 109
[173] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Incremental singular value decomposition
algorithms for highly scalable recommender systems. In Proceedings of the 5th International
Conference on Computer and Information Science, ICIS ’02, pages 27–28, 2002. 9
[174] B.M. Sarwar, G. Karypis, J.A. Konstan, and J. Riedl. Item-based collaborative ﬁltering
recommendation algorithms. In Proceedings of the 10th International Conference on World
Wide Web, WWW ’01, pages 285–295, 2001. DOI: 10.1145/371920.372071. 5, 9, 15, 87
[175] B.M. Sarwar, G. Karypis, J.A. Konstan, and J.T. Riedl. Application of dimensionality
reduction in recommender systems: A case study. In Proceedings of the ACM WebKDD
Workshop, 2000. 9, 18
[176] J.B. Schafer, J.A. Konstan, and J. Riedl.
E-commerce recommendation appli-
cations.
Data Mining and Knowledge Discovery, 5(1-2):115–153, 2001. DOI:
10.1023/A:1009804230409. 1
[177] A.I. Schein, A. Popescul, L.H. Ungar, and D.M. Pennock. Methods and metrics for
cold-start recommendations. In Proceedings of the 25th ACM SIGIR Conference on Re-
search and Development in Information Retrieval, SIGIR ’02, pages 253–260, 2002. DOI:
10.1145/564376.564421. 9
[178] M.M. Shaﬁei and E.E. Milios. Latent dirichlet co-clustering. In Proceedings of the 6th
IEEE International Conference on Data Mining, ICDM ’06, pages 542–551, 2006. DOI:
10.1109/ICDM.2006.94. 70
[179] H. Shan and A. Banerjee.
Bayesian co-clustering.
In Proceedings of the 8th IEEE
International Conference on Data Mining, ICDM ’08, pages 530–539, 2008. DOI:
10.1109/ICDM.2008.91. 70
[180] H. Shan and A. Banerjee. Generalized probabilistic matrix factorizations for collaborative
ﬁltering. In Proceedings of the 10th IEEE International Conference on Data Mining, ICDM
’10, pages 1025–1030, 2010. DOI: 10.1109/ICDM.2010.116. 50, 80
[181] H. Shan and A. Banerjee. Residual bayesian co-clustering for matrix approximation. In
Proceedings of the 10th SIAM Conference on Data Mining, SDM ’10, pages 223–234, 2010.
DOI: 10.1137/1.9781611972801.20. 71
[182] Shang Shang, Pan Hui, Sanjeev R. Kulkarni, and Paul W. Cuﬀ. Wisdom of the crowd:
Incorporating social inﬂuence in recommendation models. In Proceedings of the 17th IEEE
International Conference on Parallel and Distributed Systems, ICPADS ’11, pages 835–840,
2011. DOI: 10.1109/ICPADS.2011.150. 143

BIBLIOGRAPHY
177
[183] Amit Sharma and Dan Cosley. Do social explanations work?: studying and modeling the
eﬀects of social explanations in recommender systems. In Proceedings of the 22nd Interna-
tional Conference on World Wide Web, WWW ’13, pages 1133–1144, 2013. 143
[184] Rashmi R. Sinha and Kirsten Swearingen. Comparing recommendations made by online
systems and friends. In DELOS Workshop: Personalisation and Recommender Systems in
Digital Libraries, 2001. 127
[185] N. Srebro and T. Jaakkola. Weighted low rank approximation. In Proceedings of the 20th
International Conference on Machine Learning, ICML ’03, 2003. 19
[186] N. Srebro, J.D. M. Rennie, and T.S. Jaakola. Maximum-margin matrix factorization. In
Proceedings of the annual conference on Advances in Neural Information Processing Systems,
NIPS ’05, pages 1329–1336, 2005. 20
[187] D.H. Stern, R. Herbrich, and T. Graepel. Matchbox: large scale online bayesian recom-
mendations. In Proceedings of the 18th International Conference on World Wide Web, WWW
’09, pages 111–120, 2009. DOI: 10.1145/1526709.1526725. 112
[188] M. Steyvers and T. Griﬃths. Latent Semantic Analysis: A Road to Meaning, chapter Prob-
abilistic topic models. Laurence Erlbaum, Mahwah, New Jersey, USA, 2007. 45, 62
[189] A. Strehl and J. Ghosh. Value-based customer grouping from large retail data-sets. In
Proc. of the SPIE Conference on Data Mining and Knowledge Discovery: eory, Tools, and
Technology, pages 33–42, 2000. 12, 13
[190] Lei Tang and Huan Liu. Community Detection and Mining in Social Media. Synthesis
Lectures on Data Mining and Knowledge Discovery. Morgan-Claypool, 2010. 138
[191] Y. W. Teh, D. Newman, and M. Welling. A collapsed variational bayesian inference al-
gorithm for latent dirichlet allocation. In Proceedings of the annual conference on Advances
in Neural Information Processing Systems, volume 6 of NIPS ’06, pages 1378–1385, 2006.
85
[192] N.C Tewari, H.M. Koduvely, S. Guha, A. Yadav, and G. David.
Mapreduce imple-
mentation of variational bayesian probabilistic matrix factorization algorithm. In Proceed-
ings of the 2013 IEEE International Conference on Big Data, pages 145–152, 2013. DOI:
10.1109/BigData.2013.6691747. 84
[193] S. Vargas and P. Castells. Rank and relevance in novelty and diversity metrics for rec-
ommender systems. In Proceedings of the 5th ACM Conference on Recommender Systems,
RecSys’ 11, pages 109–116, 2011. DOI: 10.1145/2043932.2043955. 149

178
BIBLIOGRAPHY
[194] S. Vargas and P. Castells. Exploiting the diversity of user preferences for recommendation.
In Proceedings of the 10th Conference on Open Research Areas in Information Retrieval, OAIR
’13, pages 129–136, 2013. 104, 109, 149
[195] Hanna M. Wallach. Topic modeling: Beyond bag-of-words. In Proceedings of the 23rd
International Conference on Machine Learning, ICML ’06, pages 977–984, 2006. DOI:
10.1145/1143844.1143967. 118, 120
[196] P. Wang, C. Domeniconi, and K.B. Laskey. Latent dirichlet bayesian co-clustering. In
Proceedings of the European Conference on Machine learning and Knowledge Discovery in
Databases, ECML/PKDD ’09, pages 522–537, 2009. DOI: 10.1007/978-3-642-04174-
7_34. 70
[197] M Weimer, A. Karatzoglou, and A.J. Smola. Improving maximum margin matrix fac-
torization. In Proceedings of the European Conference on Machine learning and Knowledge
Discovery in Databases, volume 5211 of Lecture Notes in Computer Science, 2008. DOI:
10.1007/978-3-540-87479-9_12. 20, 56
[198] C. Williams, B. Mobasher, and R. Burke. Defending recommender systems: detection of
proﬁle injection attacks. Service Oriented Computing and Applications, 1(3):157–170, 2007.
DOI: 10.1007/s11761-007-0013-0. 10
[199] A. McCallum X. Wang and X. Wei. Topical n-grams: Phrase and topic discovery, with an
application to information retrieval. In Proceedings of the 7th IEEE International Conference
on Data Mining, ICDM ’07, pages 697–702, 2007. DOI: 10.1109/ICDM.2007.86. 118
[200] L. Xiong, X. Chen, T. Huang, J.G. Schneider, and J.G. Carbonell. Temporal collaborative
ﬁltering with bayesian probabilistic tensor factorization. In Proceedings of the 10th SIAM
Conference on Data Mining, SDM ’10, pages 211–222, 2010. 125
[201] M. Xu, J. Zhu, and B. Zhang. Nonparametric max-margin matrix factorization for collab-
orative prediction. In Proceedings of the annual conference on Advances in Neural Information
Processing Systems, NIPS ’12, pages 64–72, 2012. 150
[202] L. Yao, D. Mimno, and A. McCallum. Eﬃcient methods for topic model inference on
streaming document collections. In Proceedings of the 15th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, KDD ’09, pages 937–946, 2009.
DOI: 10.1145/1557019.1557121. 150
[203] Mao Ye, Xingjie Liu, and Wang-Chien Lee. Exploring social inﬂuence for recommen-
dation: a generative model approach. In Proceedings of the 35th ACM SIGIR Conference
on Research and Development in Information Retrieval, SIGIR ’12, pages 671–680, 2012.
DOI: 10.1145/2348283.2348373. 143

BIBLIOGRAPHY
179
[204] K. Yu, S. Zhu, J. Laﬀerty, and Y. Gong.
Fast nonparametric matrix factorization for
large-scale collaborative ﬁltering. In Proceedings of the 32nd ACM SIGIR Conference on Re-
search and Development in Information Retrieval, SIGIR ’09, pages 211–218, 2009. DOI:
10.1145/1571941.1571979. 150
[205] P. Zezula, G. Amato, V. Dohnal, and M. Batko. Similarity Search: e Metric Space Ap-
proach (Advances in Database Systems). Springer-Verlag, Secaucus, NJ, USA, 2005. 16
[206] K. Zhai, J. Boyd-Graber, N. Asadi, and M.L. Alkhouja. Mr. lda: a ﬂexible large scale
topic modeling package using variational inference in mapreduce. In Proceedings of the
21st International Conference on World Wide Web, WWW ’12, pages 879–888, 2012. DOI:
10.1145/2187836.2187955. 84
[207] M. Zhang and N. Hurley. Avoiding monotony: improving the diversity of recommenda-
tion lists. In Proceedings of the 2rd ACM conference on Recommender systems, RecSys ’08,
pages 123–130, 2008. DOI: 10.1145/1454008.1454030. 101, 108
[208] M Zhang and N. Hurley.
Novel item recommendation by user proﬁle partitioning.
In Proceedings of theIEEE/WIC/ACM International Joint Conference on Web Intelligence
and Intelligent Agent Technology, WI-IAT ’09, pages 508–515, 2009. DOI: 10.1109/WI-
IAT.2009.85. 108
[209] T. Zhou, H. Shan, A. Banerjee, and G. Sapiro. Kernelized probabilistic matrix factoriza-
tion: Exploiting graphs and side information. In Proceedings of the 12th SIAM International
Conference on Data Mining, pages 403–414, 2012. 50
[210] Haiyi Zhu, Bernardo Huberman, and Yarun Luon.
To switch or not to switch: un-
derstanding social inﬂuence in online choices.
In Proceedings of the SIGCHI Confer-
ence on Human Factors in Computing Systems, CHI ’12, pages 2257–2266, 2012. DOI:
10.1145/2207676.2208383. 129
[211] C. Ziegler, S. M. McNee, J.A. Konstan, and G. Lausen. Improving recommendation lists
through topic diversiﬁcation. In Proceedings of the 14th International Conference on World
Wide Web, WWW ’05, pages 22–32, 2005. DOI: 10.1145/1060745.1060754. 107, 108
[212] C.L. Zitnick and T. Kanade. Maximum entropy for collaborative ﬁltering. In Proceedings
of the 20th Conference in Uncertainty in Artiﬁcial Intelligence, UAI ’04, pages 636–643, 2004.
28

