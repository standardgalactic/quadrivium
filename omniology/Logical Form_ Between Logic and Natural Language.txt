Synthese Library
Studies in Epistemology, Logic, Methodology,
and Philosophy of Science
393
Andrea Iacona
Logical 
Form
Between Logic and Natural Language

Synthese Library
Studies in Epistemology, Logic, Methodology,
and Philosophy of Science
Volume 393
Editor-in-Chief
Otávio Bueno, University of Miami, Department of Philosophy, USA
Editorial Board
Berit Brogaard, University of Miami, USA
Anjan Chakravartty, University of Notre Dame, USA
Steven French, University of Leeds, UK
Catarina Dutilh Novaes, University of Groningen, The Netherlands

The aim of Synthese Library is to provide a forum for the best current work in
the methodology and philosophy of science and in epistemology. A wide variety of
different approaches have traditionally been represented in the Library, and every
effort is made to maintain this variety, not for its own sake, but because we believe
that there are many fruitful and illuminating approaches to the philosophy of science
and related disciplines.
Special attention is paid to methodological studies which illustrate the interplay
of empirical and philosophical viewpoints and to contributions to the formal (logi-
cal,
set-theoretical,mathematical,
information-theoretical,
decision-theoretical,
etc.) methodology of empirical sciences. Likewise, the applications of logical meth-
ods to epistemology as well as philosophically and methodologically relevant stud-
ies in logic are strongly encouraged. The emphasis on logic will be tempered by
interest in the psychological, historical, and sociological aspects of science.
Besides monographs Synthese Library publishes thematically uniﬁed antholo-
gies and edited volumes with a well-deﬁned topical focus inside the aim and scope
of the book series. The contributions in the volumes are expected to be focused and
structurally organized in accordance with the central theme(s), and should be tied
together by an extensive editorial introduction or set of introductions if the volume
is divided into parts. An extensive bibliography and index are mandatory.
More information about this series at http://www.springer.com/series/6607

Andrea Iacona
Logical Form
Between Logic and Natural Language
123

Andrea Iacona
Center for Logic, Language, and Cognition,
Department of Philosophy and Education
University of Turin
Turin, Italy
Synthese Library
ISBN 978-3-319-74153-6
ISBN 978-3-319-74154-3
(eBook)
https://doi.org/10.1007/978-3-319-74154-3
Library of Congress Control Number: 2017964660
© Springer International Publishing AG 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, express or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
Logical form has always been a prime concern for philosophers belonging to the
analytic tradition. For at least one century, the study of logical form has been
widely adopted as a method of investigation, relying on its capacity to reveal the
structure of thoughts or the constitution of facts. This book focuses on the very
idea of logical form, which is directly relevant to any principled reﬂection on that
method. Its central thesis is that there is no such thing as a correct answer to the
question of what is logical form: two signiﬁcantly different notions of logical form
are needed to fulﬁl two major theoretical roles that pertain respectively to logic and
to semantics. This thesis has a negative and a positive side. The negative side is that
a deeply rooted presumption about logical form turns out to be overly optimistic:
there is no unique notion of logical form that can play both roles. The positive side
is that the distinction between two notions of logical form, once properly spelled
out, sheds light on some fundamental issues concerning the relation between logic
and language.
The book may be divided into three parts. The ﬁrst part (Chaps. 1, 2, and 3)
provides the historical background. The idea of logical form goes back to antiquity,
in that it stems from the recognition that a pattern of inference can be identiﬁed
by abstracting away from the speciﬁc content the sentences that instantiate it. The
most important developments of this idea took place in the twentieth century, as they
derive from some seminal works that mark the beginning of the analytic tradition.
Under the inﬂuence of those works, logical form became a separate object of inquiry
and started being regarded as crucial to philosophical investigation.
The second part (Chaps. 4, 5, and 6) is the core of the book. Its aim is to show
that, contrary to what is commonly taken for granted, no unique notion of logical
form can play the two theoretical roles that are usually associated with the use of
the term ‘logical form’. At least two notions of logical form must be distinguished:
according to one of them, logical form is a matter of syntactic structure; according
to the other, logical form is a matter of truth conditions. As will be suggested, in
the sense of ‘logical form’ that matters to logic, logical form is determined by truth
conditions.
v

vi
Preface
The third part (Chaps. 7, 8, and 9) develops the point made in the second part
and shows some of its implications. First it outlines an account of validity that
accords with the view that logical form is determined by truth conditions. Then
it shows that the distinction between two notions of logical form suggested in the
second part provides an interesting perspective on some debated issues concerning
quantiﬁcation. The case of quantiﬁed sentences is highly representative, because the
same distinction may be applied in similar way to other important issues.
Most of the ideas expressed in the book have been presented and discussed at
talks, seminars, and graduate classes at the Heinrich Heine University Düsseldorf,
the University of Aberdeen, the University of Barcelona, the University of Bochum,
the University of the Caribbean, the University of L’Aquila, the Hebrew University
of Jerusalem, the University of Milan, the National Autonomous University of
Mexico, the University of Padua, the University of Parma, the University of Rome
III, and the University of Turin. Some parts of the book actually emerged as answers
to questions posed by members of those audiences. In particular, I would like
to thank Axel Barceló Aspeitia, Andrea Bianchi, Victor Cantero Flores, Stefano
Caputo, José Díez, Christopher Gauker, Mario Gómez Torrente, Héctor Hernández
Ortíz, Dan López de Sa, Genoveva Martí, Manolo Martínez, Elisa Paganini, Roberto
Parra Dorantes, Victor Peralta Del Riego, Luis Rosa, Sven Rosenkranz, Gil Sagi,
Giuliano Torrengo, Achille Varzi, and Elia Zardini.
I am also especially grateful to Guido Bonino, Pasquale Frascolla, Diego
Marconi, Massimo Mugnai, Carlotta Pavese, Mark Sainsbury, Marco Santambro-
gio, Daniele Sgaravatti, Ori Simchen, Alessandro Torza, Alberto Voltolini, Tim
Williamson, and to various anonymous referees for their comments on parts of
previous versions of the manuscript. There was much to be learned from their
helpful and accurate remarks, and I really hope that I have learned enough.
The second and the third part of the book are drawn from published papers,
with the due adjustments, reﬁnements, and terminological changes. More specif-
ically, Chaps. 4 and 5 are based on “Two Notions of Logical Form,” Journal of
Philosophy (2016), which originates from elaborations of “Logical Form and Truth-
Conditions,” Theoria (2013). Some parts of Chap. 7 are derived from “Validity and
Interpretation,” Australasian Journal of Philosophy (2010). Chapter 8 is drawn
from “Quantiﬁcation and Logical Form,” published in the volume Quantiﬁers,
Quantiﬁers, and Quantiﬁers, Springer (2015). Finally, Chap. 9 is drawn from
“Vagueness and Quantiﬁcation,” Journal of Philosophical Logic (2016). I thank the
editors for their permission to use the materials of these papers, which are listed in
the ﬁnal bibliography, respectively, as Iacona (2010c, 2013, 2015, 2016a,b).
The last acknowledgment is the most important. My gratitude goes to Camila
and Leonardo, for all the time that I took away from them while I was absorbed in
writing this book. Words can hardly describe the strange sensation of emptiness that
I feel for not having been there even when I was there.
Andrea Iacona

Contents
1
The Early History of Logical Form ........................................
1
1.1
Preamble.................................................................
1
1.2
Aristotle .................................................................
2
1.3
The Stoics ...............................................................
4
1.4
Logic in the Middle Ages...............................................
6
1.5
Leibniz’s Dream.........................................................
8
2
The Ideal of Logical Perfection .............................................
11
2.1
Frege .....................................................................
11
2.2
Russell ...................................................................
16
2.3
Wittgenstein .............................................................
19
2.4
A Logically Perfect Language..........................................
22
2.5
The Old Conception of Logical Form..................................
24
3
Formal Languages and Natural Languages...............................
27
3.1
Tarski’s Method .........................................................
27
3.2
Davidson’s Program ....................................................
30
3.3
Montague Semantics ....................................................
32
3.4
The Current Conception of Logical Form .............................
34
3.5
Two Open Questions ....................................................
37
4
Logical Form and Syntactic Structure.....................................
39
4.1
The Uniqueness Thesis .................................................
39
4.2
Intrinsicalism ............................................................
40
4.3
LF ........................................................................
42
4.4
Semantic Structure ......................................................
44
4.5
Relationality in Formal Explanation ...................................
46
4.6
Further Clariﬁcations ...................................................
50
5
Logical Form and Truth Conditions .......................................
53
5.1
The Truth-Conditional Notion..........................................
53
5.2
Truth Conditions and Propositions .....................................
55
5.3
Adequate Formalization ................................................
58
vii

viii
Contents
5.4
A Truth-Conditional Account ..........................................
61
5.5
Logical Form as a Property of Propositions ...........................
63
5.6
Extrinsicalism ...........................................................
66
6
Logical Knowledge vs Knowledge of Logical Form ......................
69
6.1
Preliminaries ............................................................
69
6.2
Logical Identity and Logical Distinctness .............................
70
6.3
Distinct Objects Must Be Denoted by Distinct Names................
71
6.4
Distinct Names Must Denote Distinct Objects ........................
74
6.5
Logical Knowledge .....................................................
80
6.6
Linguistic Competence and Rationality................................
81
7
Validity ........................................................................
85
7.1
Interpretations of Arguments ...........................................
85
7.2
Validity and Formal Validity............................................
87
7.3
The Sorites ..............................................................
90
7.4
The Fallacy of Equivocation............................................
92
7.5
Context-Sensitive Arguments ..........................................
95
8
Quantiﬁed Sentences ........................................................
99
8.1
Two Questions About Quantiﬁed Sentences...........................
99
8.2
Quantiﬁers ............................................................... 102
8.3
Meaning and Truth Conditions ......................................... 104
8.4
The Issue of First Order Deﬁnability................................... 105
8.5
Two Kinds of Formal Variation ........................................ 108
8.6
Conclusion .............................................................. 110
9
Further Issues Concerning Quantiﬁcation ................................ 111
9.1
Two Kinds of Indeterminacy ........................................... 111
9.2
Precisiﬁcations of Quantiﬁer Expressions ............................. 113
9.3
First Order Deﬁnability Again.......................................... 117
9.4
Logicality................................................................ 120
9.5
Quantiﬁcation Over Absolutely Everything ........................... 123
9.6
Unrestricted Quantiﬁcation and Precision ............................. 124
Afterword ......................................................................... 127

Chapter 1
The Early History of Logical Form
Abstract The term ‘logical form’ is generally used to denote a property of sen-
tences. The property denoted is called ‘logical’ because it is regarded as important
from the logical point of view, and it is called ‘form’ because it is taken to be
distinct from the speciﬁc semantic features that constitute their matter. As a ﬁrst
approximation, we can say that one has a notion of logical form if one thinks
that there is such a property, independently of whether one deliberately employs
some expression that refers to that property. So it is reasonable to presume that
some understanding of logical form existed long before the term ‘logical form’ was
introduced in the philosophical lexicon. As this chapter will explain, the idea of
logical form is as old as logic itself. Its origin lies in the recognition of patterns of
inference that can be identiﬁed by schematizing some of the expressions that occur
in their instances.
1.1
Preamble
Logic developed in antiquity as an inquiry into the principles of correct reasoning.
The following deﬁnition, due to Aristotle, was intended to capture the essence of
correct reasoning:
Now a reasoning is an argument in which, certain things being laid down, something other
than these necessarily comes about through them.1
According to a widely shared reading of this passage, the distinctive feature of
correct reasoning is that it cannot take us from truth to falsity: if the things “being
laid down” are true, then the thing “other than these” must also be true. Logic is
traditionally understood as a theory of correct reasoning is this sense.
To employ more familiar terminology, two deﬁnitions will now be stated. The
ﬁrst is the usual deﬁnition of argument:
1Aristotle, Topics 100a25, in Aristotle (1958).
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_1
1

2
1
The Early History of Logical Form
Deﬁnition 1.1.1 An argument consists of a set of sentences, the premises, and a
sentence, the conclusion, which is inferred from them.
To make explicit the inference from the premises to the conclusion, an argument
may be stated either vertically, as a sequence of sentences where a horizontal
line separates the premises from the conclusion, or horizontally, as a sequence of
sentences where a semicolon separates the premises from the conclusion. When
there is no need to specify the premises, an argument may simply be indicated as
I ˛, where  is a set of premises and ˛ is a conclusion.
The second deﬁnition is the classical deﬁnition of validity as necessary truth
preservation:
Deﬁnition 1.1.2 An argument I ˛ is valid if and only if it is impossible that all the
sentences in  are true and ˛ is false.
Although the meaning of ‘impossible’ can be elucidated in different ways, it
is commonly taken for granted that validity, just as other fundamental logical
properties and logical relations, is deﬁnable in terms of possibility. The right-hand
side of the biconditional above can also be regarded as a deﬁniens of ‘ entails ˛’,
if it is assumed, as usual, that  entails ˛ if and only if I ˛ is valid.
Given Deﬁnitions 1.1.1 and 1.1.2, we can say that the main purpose of ancient
logicians was to provide a theory of valid arguments. The idea of logical form
emerges from the reﬂections guided by this purpose, since it originates in the
attempts to describe patterns of inference that characterize valid arguments.
1.2
Aristotle
Early attempts to attain generality in the description of patterns of inference
employed linguistic devices of various sorts. One option was to use common words,
such as ‘thing’. For example, in Plato’s Republic we read that “the same thing cannot
act or be acted upon in the same part or in relation to the same thing at the same
time in contrary ways”. Plato seems to say that it cannot be the case that a property
belongs and does not belong to the same object: whenever we ﬁnd that the property
belongs and does not belong, it is because different objects are involved. Thus, if a
man stands still but moves his hands, it would be wrong to say that the man is at the
same time at rest and in motion. We should rather say that a part of him is at rest
while a part of him is in motion.2
Another option was to avoid explicit formulations of general principles and
use ordinary sentences directly as illustrations of such principles. For example, in
Aristotle’s Topics we ﬁnd statements such as “if the honorable is pleasant, what is
not pleasant is not honorable”, where it is left to the reader to see the irrelevance
2Plato (1991), 436b–436d.

1.2
Aristotle
3
of the speciﬁc content of the sentences adopted. Aristotle requires us to understand
that the use of ‘honorable’ and ‘pleasant’ is not essential to the point he is making,
as these terms could be replaced by other terms of the same grammatical category.3
However, as long as the expressive resources employed were drawn from
ordinary language, they could hardly suit the standards of clarity and rigour required
by a systematic study of valid arguments. The use of common words would easily
generate long and clumsy formulations that were hardly understandable without
additional explanations, and the use of particular sentences as examples would leave
unspeciﬁed how the general principle could be obtained by abstraction from them.
A signiﬁcant progress was made by Aristotle in Prior Analytics, where he
outlined his theory of syllogism. A syllogism is a valid argument formed by
three sentences – two premises and one conclusion – each of which contains two
terms, expressions such as ‘man’, ‘animal’ or ‘mortal’. For example, the following
argument is a syllogism:
[A]
(1) Every animal is mortal
(2) Every man is an animal
(3) Every man is mortal
[A] is valid, because it is impossible that (1) and (2) are true but (3) is false. Its
validity depends on the relation between the terms ‘man’ and ‘mortal’, which occur
in the conclusion, and the term ‘animal’, which occurs in the premises. The term
‘animal’ is called the “middle term”.4
The method of exposition adopted in Prior Analytics differs in one crucial
respect from Aristotle’s previous works and from those of his predecessors. In Prior
Analytics, letters are used to formulate argument schemas. To illustrate, consider the
following syllogism:
[B]
(4) Every mammal is an animal
(5) Every whale is a mammal
(6) Every whale is an animal
[B] is structurally similar to [A], in that the relation that obtains in [B] between
‘mammal’, ‘animal’, and ‘whale’ is the same that obtains in [A] between ‘animal’,
‘mortal’, and ‘man’ in [A]. The validity of [A] and [B] can be explained in terms of
this relation. According to Aristotle, [A] and [B] are syllogisms of the same type, in
that they instantiate the same argument schema:
[C]
(7) Every A is B
(8) Every C is A
(9) Every C is B
3Aristotle (1958), 113b22.
4Aristotle (1949), 41b36. This is not exactly the way Aristotle phrased a syllogism, but the
differences of formulation will be ignored here and in what follows.

4
1
The Early History of Logical Form
Here ‘A’ stands for the middle term. If we replace ‘A’ with ‘animal’, ‘B’ with
‘mortal’ and ‘C’ with ‘man’, we obtain [A]. Similarly, if we replace ‘A’ with
‘mammal’, ‘B’ with ‘animal’ and ‘C’ with ‘whale’ we obtain [B].
Aristotle provides a classiﬁcation of syllogisms based on a distinction between
“ﬁgures”, which depend on the different relations in which the middle term stands
to the other two terms. [C] belongs to the ﬁrst ﬁgure, which includes four schemas
where the middle term is subject to one term and predicate to the other. The second
ﬁgure includes four schemas where the middle term is predicate to both the other
terms. Finally, the third ﬁgure includes six schemas where the middle term is subject
to both the other terms. Thus Aristotle distinguished fourteen types of syllogisms,
within the three ﬁgures, which later came to be called “moods”.5
The use of letters proved very fruitful in the formulation of the theory. This
device, which appears for the ﬁrst time in Prior Analytics, seems to be Aristotle’s
invention. Probably, the use of letters was suggested to Aristotle by a well
established practice in geometry, as is shown by the fact that letters are used to
name lines in Euclid’s Elements and in Aristotle’s own work.6
1.3
The Stoics
Stoic logic, initiated by Chrysippus, developed independently of Aristotelian logic,
pursuing different but equally important lines of investigation. While Aristotle
and his followers worked mainly on inference patterns that fall in the domain of
predicate logic, the Stoics focused on inference patterns that belong to propositional
logic. For example, the following argument is valid:
[D]
(10) If it is day, then it is light
(11) It is day
(12) It is light
Its validity depends on the fact that (10) is a conditional, (11) is the antecedent of
(10), and (12) is the consequent of (10).
The Stoics also employed different devices to describe argument schemas. They
did not use letters but ordinal numbers to refer to arbitrary sentences. For example,
the argument schema instantiated by [D] was described as follows:
[E]
(13) If the ﬁrst, then the second
(14) The ﬁrst
(15) The second
5In reality, the moods traditionally classiﬁed are four. Aristotle’s theory did include a fourth ﬁgure,
even though, due to differences of formulation, he did not recognize it as a separate ﬁgure.
6Euclid (2002), V, Aristotle (1934), 1132b.

1.3
The Stoics
5
The expressions ‘the ﬁrst’ and ‘the second’ occurring in [E] stand for arbitrary
sentences. Thus, if we replace ‘the ﬁrst’ with (11) and ‘the second’ with (12), we
obtain [D]. [E] is the valid propositional schema known as modus ponens.
Chrysippus recognized ﬁve argument schemas as basic. [E] is one of them. The
others are similar, in that they employ ordinal numbers for arbitrary sentences.
The ﬁve schemas have been handed down as “the indemonstrable moods”. This
terminology is explained at least in part by the project of constructing a deductive
system within which many demonstrable moods can be derived from a few primitive
patterns. Chrysippus did in fact elaborate a host of derivative moods from the ﬁve
basic schemas.7
Apart from the differences considered, the Aristotelian school and the Stoic
school agreed on the hypothesis that inference patterns may be expressed as
argument schemas. An argument schema is obtained from an argument by replacing
some of the expressions occurring in it with schematic expressions. Conversely,
an instance of the schema is an argument obtained by uniformly replacing the
schematic expressions with expressions of the appropriate syntactic category, where
‘uniformly’ means that each schematic expression is always replaced by the same
expression.
More generally, logic began with the study of paradigmatically valid arguments,
and developed from attempts to elucidate the structural properties of such argu-
ments. The thought that lies at the origin of logic may be summarized as follows.
Some arguments are clearly valid. If one observes these arguments, one will ﬁnd that
they have distinctive structural features, and if one observes other arguments with
the same features, one will ﬁnd that they are also valid. Since the structural features
in question can be identiﬁed as valid patterns of inference, the validity of many
arguments can be explained in terms of the validity of the patterns of inferences
they instantiate.
This original thought suggests a method of investigation: to get a theory of valid
arguments, one has to go through a systematic study of valid patterns of inference.
The most important contributions made by ancient logicians derive from the
employment of this method. More speciﬁcally, they derive from an understanding
of this method according to which valid patterns of inference are argument schemas
obtained from valid arguments by replacing expressions occurring in them with
schematic expressions.
The idea of logical form arises from the very same thought. Since arguments
are constituted by sentences, a structural description of an argument is ipso facto
a structural description of the sentences it contains. That is, if the structure of an
argument can be described as an argument schema, the structure of a sentence can
be described as a sentence schema. For example, on the assumption that the structure
of [A] is represented by [C], we get that the structure of (1) is represented by (7).
Similarly, on the assumption that the structure of [D] is represented by [E], we get
that the structure of (10) is represented by (13). The logical form of a sentence may
be understood as a structure so described.
7A detailed exposition of the system is provided in Kneale (1962), pp. 158–176, and in Mates
(1973). A more recent work that focuses on issues related to logical form is Barnes (2009).

6
1
The Early History of Logical Form
There is a clear sense in which a sentence schema expresses a property that
deserves to be called ‘logical’, namely, that in which it plays an essential role in
the explanation of the validity of the arguments in which its instances may occur.
Similarly, there is a clear sense in which the property expressed deserves to be called
‘form’, namely, that in which the sentence schema, as a result of an abstraction, is
independent of the speciﬁc meaning of the expressions that occur in its instances.
1.4
Logic in the Middle Ages
Medieval logicians adopted the method of representation of logical form that
they found in ancient logic. The medieval distinction between “categorematic”
and “sincategorematic” expressions provided a way to make sense of sentence
schemas: categorematic expressions are meaningful expressions that can be used
as subjects or predicates, whereas syncategorematic expressions signify nothing
by themselves, in that they indicate how the former are combined. For example,
in the argument schema [C] some expressions that occur in [A] and [B], such as
‘animal’, are replaced by schematic letters, while others, such as ‘every’ remain
constant. Medieval logicians explained this difference by saying that the former
expressions are categorematic, while the latter are sincategorematic. So the idea
was that the logical form of a sentence is displayed by a sentence schema obtained
from the sentence by keeping ﬁxed its syncategorematic expressions and replacing
its categorematic expressions with schematic letters.8
Although medieval logicians did not differ from ancient logicians with respect to
the method of representation of logical form, their attempts to elucidate the logical
properties of sentences produced signiﬁcant advances. In particular, medieval
logicians drew attention to some interesting ways in which logical form may
differ from surface grammar. Of course, ancient logicians were also aware that
surface grammar is not an infallible guide to logical form. Aristotle provided
various examples of fallacious arguments that bear superﬁcial resemblance to valid
arguments, and he knew that the premises and conclusions of syllogisms as he
phrased them could differ to some extent from the sentences used by ordinary
speakers. But in the Middle Ages the relation between logic and grammar became
object of more thorough and meticulous studies.
At least two important contributions deserve attention. The ﬁrst emerges from
Abelard’s treatment of “categorical sentences”, that is, sentences whose main
constituents are a subject and a predicate. For example, the following sentence is
categorical:
8According to Buridan (1976), 1.7.2, categorematic expressions provide the matter (materia) of
sentences, while syncategorematic expressions indicate their form (forma).

1.4
Logic in the Middle Ages
7
(16) Peter is a man
Abelard raises two crucial issues about categorical sentences. One concerns the
reducibility of non-categorical sentences to categorical sentences. Aristotle, in On
Interpretation, remarks that a verb such as ‘walks’, as it occurs in a sentence such
as ‘Socrates walks’, may be replaced by a phrase such as ‘is walking’. Following
that remark, Abelard takes categorical sentences as logically basic, and treats ‘is’
as a “copula”, that is, a link that joins the subject and the predicate. Obviously, he
recognizes that a statement can be made without the use of the verb ‘to be’, but he
says that other verbs can be paraphrased in the way indicated by Aristotle.9
The other issue concerns the existential import of ‘is’. Abelard claims that, when
‘is’ occurs in a categorical sentence, it does not involve a predication of existence.
From (16) we cannot infer that Peter exists. If ‘is’ did involve such predication, the
following sentence would be false instead of being true:
(17) The chimaera is imaginary
Abelard seems to suggest that (17) is misleading. Although it may appear that when
we utter (17) we are committed to the existence of a chimaera, in reality what we
say is that the soul of someone has an imagination of a chimaera.10
These two issues have been widely debated in the Middle Ages, although the
inﬂuence of the received Aristotelian view heavily limited the impact of Abelard’s
suggestions. In any case, two important thoughts seem to emerge from Abelard’s
remarks. One is that, at least in some cases, the logical form of a sentence is
expressed by a proper paraphrase of the sentence. The other is that, at least in some
cases, the logical form of a sentence is not what it appears. Both thoughts imply that
ordinary language may be misleading, so that a careful study of the words we use is
required for the purposes of logic.
The second important contribution on the relation between logical form and
surface grammar comes from a thesis advocated by Ockham, the thesis that there is
a mental language common to all human beings. For Ockham, the mental language
is a universal language that constitutes the ground of all spoken languages. This
grounding relation obtains because the expressions of any spoken language are
“subordinated” to “mental expressions”, that is, expressions that belong to the
mental language. In particular, spoken terms are subordinated to mental terms,
which may be called “concepts”. Mental terms, unlike spoken terms, signify things
in a natural way. That is, while the signiﬁcation of terms in spoken languages is
purely conventional and can be changed by mutual agreement, the signiﬁcation of
mental terms is established by nature, and cannot be changed at will.11
The mental language conjectured by Ockham is quite similar to a spoken
language. Its grammar is structurally analogous, and it includes expressions of some
9Abelard (1956), pp. 161 and 123.
10Abelard (1956), pp. 136–138, 162.
11Ockham (1974), p. 7.

8
1
The Early History of Logical Form
main categories that feature in spoken languages, such as nouns, verbs, adverbs,
connectives, prepositions and so on. Therefore, “mental sentences” are composed
by mental expressions in essentially the same way in which spoken sentences are
composed by spoken expressions. Nonetheless, the mental language is simpler than
a spoken language in at least two respects. First, its syntax is simpler, in that it is free
from grammatical accidents – such as Latin’s declensions – that characterize spoken
languages but are irrelevant for the expression of thought. Second, its semantics is
simpler, as it involves a more straightforward relation between words and things.
This is suggested by Ockham’s account of synonymy and ambiguity. Two spoken
terms are synonymous if they are subordinated to the same mental term. Conversely,
a single spoken term is ambiguous if it is subordinated to more than one mental
term.12
This obviously leaves open the question of whether the mental language itself
involves some form of redundancy, synonymy or ambiguity. It is not entirely clear
how Ockham would have answered that question, and a great deal of modern
secondary literature has been devoted to clarify his position. But independently
of that question, it is undeniable that Ockham regarded the mental language as
more suitable for logic than any spoken language. Therefore, his view reinforces the
attitude towards ordinary language that emerges from Abelard’s remarks. One way
to substantiate the thought that logical form is not immediately manifest in surface
grammar is to say that logical form is properly expressed in the mental language.
The logical form of a given sentence is the form of a corresponding mental sentence
that may differ to some extent from that sentence.13
1.5
Leibniz’s Dream
The reﬂections considered in Sect. 1.4 remained ineffective for long time, and
did not give rise to further elaborations of the idea of logical form. In the Early
Modern Period, several logical works were produced, some of which provided
signiﬁcant contributions to the development of logic. But none of them was
speciﬁcally concerned with logical form. The ancient idea of logical form, conveyed
by medieval logicians, remained unquestioned. In particular, a basic methodological
tenet that remained unquestioned is that logical form is represented by means of
expressions drawn from a natural language, such as Greek, Latin, or German. Of
course, it was widely believed that a natural language is not ready as it is to represent
logical form: some modiﬁcations were needed, such as the use of uncommon
grammatical constructions or the introduction of schematic expressions of some
kind. But the result of such modiﬁcations was still something very close to a natural
language.
12Ockham (1974), pp. 44–47.
13Spade and Panaccio (2011) provide more detailed accounts of Ockham’s position.

1.5
Leibniz’s Dream
9
A crucial turn occurred when an alternative line of thought started attracting the
attention of some logicians. According to that line of thought, the language we need
for the purposes of logic is neither a natural language nor a modiﬁed version of a
natural language, but an artiﬁcial language appropriately designed. Leibniz sketched
the project of such a language in De Arte Combinatoria (1666), and then elaborated
it in later works. His ultimate aim was to put reasoning on a ﬁrmer basis by reducing
it to a matter of calculation that many could grasp. The inspiration came from Lull’s
Ars Magna and Hobbes’ Computatio sive Logica. Lull claimed that a system of signs
could be deﬁned in such a way that all complex ideas are expressed in terms of the
combination of a set of fundamental signs, and Hobbes suggested that reasoning
could be reduced to a species of calculation.14
Leibniz thought that we can identify a set of primitive concepts by means of
analysis, and list each possible combination of such concepts. Once this is done,
we can construct an artiﬁcial language in the following way. First we introduce an
alphabet of primitive signs – which presumably includes arithmetical symbols –
to designate primitive concepts. Then we deﬁne a set of complex signs in such a
way that, for any complex concept, there is one and only one complex sign. Thus
we get a correspondence between signs and concepts: for each concept, simple or
complex, there is one and only one sign. Leibniz called characteristica universalis
the language so constructed, as he used the word ‘character’ to designate its signs.
He trusted that such a language would represent the world in a perfect way. Although
the signs that stand for primitive concepts may be chosen arbitrarily, there must be
an analogy between their relations and the relations of the elements they signify,
so that the name of each complex thing is its deﬁnition and the key to all its
properties.15
Leibniz’s view seems to be that, since the characteristica universalis perfectly
mirrors the structure of the world, it is able to exhibit the logical form of sentences
better than any natural language. He thought that a philosophically constructed
grammar could make formal reasoning easy by providing the framework for
a calculus ratiocinator, a mechanical or quasi-mechanical method of drawing
conclusions. He prophesied that, when such a language will be deﬁned, men of good
will desiring to settle a dispute on any subject will use their pens and calculate.16
The interest of Leibniz’s project lies in its underlying idea that a theory of
reasoning can be formulated as a deductive system based on an artiﬁcial language
that employs a symbolic apparatus drawn from mathematics. This idea indicated,
at least potentially, a coherent alternative to the traditional understanding of logical
form. If one could construct an artiﬁcial language that is suitable to exhibit the
14Leibniz (1875–1890), Lull (1609), Hobbes (1656).
15Leibniz (1875–1890), p. 184, Leibniz (1903), p. 30.
16Leibniz (1875–1890), p. 200.

10
1
The Early History of Logical Form
logical properties of sentences by means of mathematical symbols, one could
provide a method of representation of logical form that substantially differs from
that adopted by ancient and medieval logicians.17
However, the line of thought initiated by Leibniz could hardly gain wide accep-
tance in the seventeenth century. Although he put forward insightful suggestions on
how to construct the deductive system, he never provided a detailed exposition of
the language. This is due, among other reasons, to the impossibility of drawing up an
alphabet of human thought as he conceived it, and to the lack of mathematical tools
required by the level of abstraction he desired. In absence of a sufﬁciently detailed
proposal, the traditional method of representation of logical form maintained its
supremacy for a long time. Its inﬂuence extended until the end of the nineteenth
century, when modern logic developed in close connection with mathematics.
17This is not to say that Leibniz was the ﬁrst or the only author of his time who postulated such
a close connection between logic and mathematics. As Mugnai (2010) explains, different authors,
before or independently of Leibniz, had made attempts to express logic in mathematical form or to
use logic to give some ﬁrm ground to mathematical proofs.

Chapter 2
The Ideal of Logical Perfection
Abstract The rise of modern logic had a deep impact on the philosophical
reﬂection on logical form. This chapter explains how logical form became a primary
topic of interest between the end of the nineteenth century and the beginning of the
twentieth century. In particular, we will focus on Frege, Russell, and Wittgenstein.
Their works contributed in different ways to shape a thought that moulded the
beginning the analytic tradition, the thought that the logical form of the sentences
of natural language can at least in principle be displayed by sentences of a logically
perfect language.
2.1
Frege
Frege’s Begriffsschrift (1879) is conventionally taken to mark the beginning of
modern logic. The title of this work, which literally means “concept-script” and
is often translated as “ideography”, is the name of a formal system constituted by
a formal language and a deductive apparatus in that language. Frege describes the
ideography as a partial realization of Leibniz’s dream. Its language is conceived as
a language “for pure thought” in the spirit of Leibniz’s characteristica universalis,
and its deductive apparatus is intended to provide a calculus ratiocinator in which
all valid reasoning is reduced to steps that can be checked mechanically.1
The language of the ideography is the ﬁrst artiﬁcial language constructed in
a rigorous way. Its syntax is deﬁned by ﬁxing a set of elementary symbols and
specifying a set of rules for combining these symbols into complex expressions.
Its semantics is deﬁned by means of rules that determine the meanings of all
formulas, that is, of all well-formed expressions. Schematic letters are used to
express generality, according to the custom that goes back to Aristotle, and they
occur within diagrams formed by horizontal lines, vertical lines, and concavities
that are used to express negation, the conditional, and the universal quantiﬁer.
1Frege (1879). Boole’s important contribution to the birth of modern logic, Boole (1847), will not
be considered here.
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_2
11

12
2
The Ideal of Logical Perfection
According to Frege, this is the kind of artiﬁcial language that we need for the
purposes of logic. The language of the ideography is appropriate to express valid
patterns of reasoning, for it represents only what is essential to valid reasoning,
namely, “conceptual content”. The conceptual content of a sentence is roughly what
matters for its truth or falsity, and thus for the validity of the arguments in which it
may occur.2
The key of Frege’s method of formalization is the hypothesis that sentences
have function-argument structure. This hypothesis, which questions the ancient
method based on the grammatical division between subject and predicate, may be
illustrated by means of an analogy. Consider the successor function, represented by
the following equation:
(1) S.x/ D x C 1
Here ‘S’ indicates the successor function, and ‘x’ stands for any integer that may
occur as its argument. ‘S.x/’ is to be read as ‘the value of S for the argument x’. That
is, for any integer x, ‘S.x/’ denotes the successor of x. For example, ‘S.1/’ denotes
the number 2. Its denotation is the result of the combination of the denotation of ‘S’
with the denotation of ‘1’. Frege suggests that something similar holds for sentences
of natural language. Consider the following:
(2) Aristotle is rich
For Frege, (2) is analogous to ‘S.1/’: the name ‘Aristotle’ denotes Aristotle, and
the predicate ‘rich’ denotes a function that applies to Aristotle. More precisely, on
the assumption that there are two truth values, call them 1 and 0, ‘rich’ denotes
a function Rich such that, for any x, Rich.x/ D 1 if x is rich, and Rich.x/ D 0
otherwise. So the structure of (2) is the following:
(3) Rich(Aristotle)
The truth value of (2), which Frege identiﬁes with the denotation of (2), is the result
of the combination of the denotation of ‘Aristotle’ and the denotation of ‘rich’, for
it is the value that Rich takes for Aristotle as argument.3
To fully grasp the hypothesis that sentences have function-argument structure, it
must be taken into account that a function may have more than one argument. For
example, consider the addition function, represented by the following equation:
(4) A.x; y/ D x C y
Here ‘A’ indicates the addition function, while ‘x’ and ‘y’ stand for any two integers
that may occur as its arguments. For any ordered pair of integers hx; yi, ‘A.x; y/’
denotes the sum of x and y. Now consider the following sentence:
2In later works, Frege talks of the “thought” expressed by a sentence as the primary bearer of its
truth or falsity, see Frege (1918).
3The view that predicates denote functions from object to truth values is not explicitly stated in
Begriffsschrift, but becomes clear in Frege (1891).

2.1
Frege
13
(5) Aristotle admires Plato
According to Frege, the structure of (5) is the following:
(6) Admire(Aristotle, Plato)
Here Admire is a binary function from ordered pairs of objects to truth values, that
is, a function such that, for any pair hx; yi, Admire.x; y/ D 1 if x admires y, and
Admire.x; y/ D 0 otherwise. Note that the same structure can be ascribed to the
following sentence:
(7) Plato is admired by Aristotle
Although Frege recognizes that there may be a rhetorical difference between (5) and
(7), he takes their conceptual content to be the same. This example makes clear how
Frege differs from his predecessors. If (5) is analysed in terms of subject-predicate
structure, the distinction to be drawn is between ‘Aristotle’ and ‘admires Plato’.
Similarly, in (7) the distinction to be drawn is between ‘Plato’ and ‘is admired by
Aristotle’. So we end up with two different subject-predicate sentences, each with a
complex monadic predicate.
Frege’s method of formalization is based on the hypothesis that sentences have
function-argument structure in the sense that the formulas assigned to sentences are
intended to provide a formal representation of that structure. For example, when
one formalizes an argument in which (2) occurs, one will assign to (2) a formula
that provides a formal representation of its structure as stated in (3). Similarly, when
one formalizes an argument in which (5), or (7), occurs, one will assign to (5), or (7),
a formula that provides a formal representation of its structure as stated in (6). The
formula assigned expresses the logical form of the sentence, so it may be used to
express the pattern of reasoning instantiated by the argument in which the sentence
occurs.
The most important progress due to Frege’s method of formalization concerns the
analysis of quantiﬁed sentences, that is, sentences that contain quantiﬁer expressions
such as ‘all’, ‘every’, ‘some’ or ‘at least one’. Consider the following sentence:
(8) Everything is material
In the tradition that goes back to Aristotle’s syllogistic, ‘everything’ is assumed to
be a term. But Frege questions this assumption. If ‘material’ denotes a function
Material such that, for any x, Material.x/ D 1 if x is material, and Material.x/ D
0 otherwise, there is no obvious way to treat ‘everything’ as a term for some
object to which the function can apply. Frege claims instead that the denotation of
‘everything’ is itself a function. If we call ﬁrst-level functions the functions whose
arguments are objects and second-level functions the functions whose arguments
are ﬁrst-level functions, Frege’s claim is that ‘everything’ denotes a second-level
function whose values are 1 and 0. More precisely, it denotes a second-level
function Everything such that, for every ﬁrst-level function F, Everything. F/ D 1
if F.x/ D 1 for every x, and Everything. F/ D 0 otherwise. So the structure of (8)
is the following:

14
2
The Ideal of Logical Perfection
(9) Everything.Material/
In other terms, what is said by using (8) is that the predicate ‘material’ has the
property of being true of every object. To express this, Frege employs variables as
follows:
(10) For every x, x is material
Therefore, (8) can be formalized by using the universal quantiﬁer and the variable
‘x’. The same goes for the following sentence:
(11) All things are material
In accordance with the usual convention, (8) and (11) are assumed to be synony-
mous.
To grasp the potential of Frege’s analysis, at least two familiar cases must be
considered. The ﬁrst is that in which universal quantiﬁcation is explicitly restricted
by a predicate. Consider the following sentence:
(12) All philosophers are rich
What (12) says is that ‘richs’ has the property of being true of every philosopher,
that is of every object of which ‘philosopher’ is true. Accordingly, (12) can be
paraphrased as follows:
(13) For every x, if x is a philosopher, then x is rich
The same goes for the following sentence:
(14) Every philosopher is rich
Again, in accordance with the usual convention, (12) and (14) are assumed to be
synonymous.
The second case is that in which the quantiﬁcation is existential. Consider the
following sentence:
(15) Something is material
What (15) says is that the predicate ‘material’ has the property of being true of
some object. This is to say that, for some x, x is material, which is equivalent to
what follows:
(16) It is not the case that, for every x, it is not the case that x is material
So (15) can be formalized by using the universal quantiﬁer and negation. Similar
considerations hold for existentially quantiﬁed sentences such as
(17) Some philosopher is rich
This sentence can be phrased as follows:
(18) It is not the case that, for every x, if x is a philosopher, then it is not the case
that x is rich

2.1
Frege
15
The same goes for the sentence obtained from (17) by replacing ‘some’ with ‘at
least one’. In accordance with the usual convention, ‘some’ and ‘at least one’ are
assumed to be synonymous.
The notation invented by Frege can provide a clear formal representation of a
wide class of quantiﬁed sentences. This class includes the sentences traditionally
studied in Aristotelian logic, such as (12) or (17), and a variety of more complex
sentences whose logical properties had not been properly understood before. For
example, consider the following:
(19) Every philosopher has read some old book
On Frege’s account, (19) can be paraphrased as follows:
(20) For every x, if x is a philosopher, then for some y such that y is a book and y is
old, x has read y
This account makes clear that ‘has read some old book’ has quantiﬁcational
structure. The traditional method is unable to display such structure, as (19) turns
out to be a sentence of the form ‘Every A is B’. Consequently, it is unable to explain
why (19) entails the following sentence:
(21) Every philosopher has read some book
This entailment is easily explained if (21) is paraphrased as follows:
(22) For every x, if x is a philosopher, then for some y such that y is a book, x has
read y
More generally, any complex quantiﬁed sentence in which universal or existential
quantiﬁcation occurs within some predicate can adequately be represented in the
language of the ideography. The innovative force of the ideography crucially
depends on this capacity.4
The details of Frege’s notation do not concern us here. The cumbersome
diagrams it requires made it so hard to write that nobody else ever adopted it.
What matters for our purposes is that Frege’s method of formalization entails that
logical form may substantially differ from surface grammar. For example, although
(12) and (2) are superﬁcially similar, they have different logical forms. The logical
form of a sentence of natural language can adequately be represented only by a
sentence of an ideal formal language. In such a language, sentences exhibit function-
argument structures that differ from the grammatical structures of the sentences of
natural language. For Frege, the understanding of this difference is a philosophical
advancement of primary importance:
If it is one of the tasks of philosophy to break the domination of the word over the human
spirit by laying bare the misconceptions that through the use of language often almost
unavoidably arise concerning the relations between concepts and by freeing thought from
4Pietroski (2009), pp. 10–23, explains how Frege’s notation can solve some problematic cases that
emerged in connection with previous attempts.

16
2
The Ideal of Logical Perfection
that with which only the means of expression of ordinary language, constituted as they are,
saddle it, then my ideography, further developed for these purposes, can become a useful
tool for the philosopher.5
2.2
Russell
The attitude towards natural language that emerges from Russell’s article On
Denoting (1905) is essentially the same as Frege’s Begriffsschrift. Russell agrees
with Frege on the assumption that logical form may substantially differ from surface
grammar, and adopts the same kind of logical apparatus to elucidate that difference.
The main point on which he diverges from Frege concerns the analysis of a speciﬁc
class of expressions, deﬁnite descriptions. A deﬁnite description is an expression
that purports to refer to a particular object by stating a condition that is taken to
hold uniquely of that object. For example, ‘the author of Waverley’ is a deﬁnite
description. Its denotation is Walter Scott, the person that uniquely satisﬁes the
condition of being author of Waverley.6
Frege seems to think that, from a logical point of view, deﬁnite descriptions
do not signiﬁcantly differ from other expressions that purport to refer to particular
objects, such as names. The semantic role of all these expressions, which may be
called singular terms, is to denote objects to which predicates can apply. Consider
the following sentence:
(23) The author of Waverley is a man
On Frege’s account, ‘the author of Waverley’ is a singular term that denotes an
individual, Scott, and ‘man’ is a predicate that applies to that individual. Russell
questions this account: a deﬁnite description is not a genuine singular term, in that it
hides a more complex construction involving quantiﬁcation. More precisely, Russell
thinks that (23) is correctly paraphrased as follows:
(24) For some x, x is author of Waverley, and for every y, if y is author of Waverley
then y D x, and x is a man
Since (24) contains no singular term that refers to Scott, ‘the author of Waverley’
is a singular term only superﬁcially. In Russell’s words, deﬁnite descriptions do not
have meaning in isolation. They should not be regarded as “standing for genuine
constituents of the propositions in whose verbal expressions they occur”.7
Russell argues for his theory by drawing attention to the problems that seem
to arise if deﬁnite descriptions are treated as genuine singular terms. In particular,
he shows that at least four puzzles can be solved on the basis of the paraphrase
5Frege (1879), p. 7.
6Russell (1905).
7Russell (1905), p. 482.

2.2
Russell
17
he suggests. The ﬁrst puzzle is how can a sentence be meaningful if it contains
an empty deﬁnite description, that is, a deﬁnite description that does not denote
anything. Consider the following sentence:
(25) The present King of France is bald
(25) seems meaningful, just like (23). But it cannot be the case that (25) is
meaningful in virtue of picking out some particular individual and ascribing a
property to that individual, for ‘the present King of France’, unlike ‘the author
of Waverley’, does not denote any particular individual. So, unless we are willing
to deny that (25) is meaningful, which is highly implausible, some alternative
explanation must be provided. One might be tempted to say that ‘the present King
of France’ differs from ‘the author of Waverley’ only in that denotes a different kind
of object. More speciﬁcally, one might claim that empty deﬁnite descriptions denote
nonexistent objects, or simply stipulate that they denote the empty set. But no such
move seems promising to Russell. His view is that (25) is correctly paraphrased as
follows:
(26) For some x, x is King of France, and for every y, if y is King of France, then
y D x, and x is bald
Thus, (23) and (25) are meaningful in exactly the same way, although they have
different truth values. Since there is no King of France at present, the ﬁrst condition
stated in (26) is not satisﬁed, so (25) is false.8
The second puzzle is how can we make true negative existential claims by
using sentences that contain empty deﬁnite descriptions. Consider the following
sentence:
(27) The present King of France does not exist
Since ‘the present King of France’ does not denote any particular individual, (27)
is intuitively true. But if ‘the present King of France’ were a genuine singular
term, (27) would say that the denotation of ‘the present King of France’ does
not exist, which seems inconsistent. Note that it would not sufﬁce to hold that
existence, as opposed to “being” or “subsistence”, implies concreteness, and that
(27) consistently denies that a certain abstract object exists. If A is identical to B,
there is no such thing as the difference between A and B, so the difference between
A and B does not subsist. But again, if A is identical to B, ‘the difference between
A and B’ lacks denotation. Russell’s solution is that (27) is correctly paraphrased as
follows:
(28) It is not the case that for some x, x is King of France, and for every y, if y is
King of France, then y D x.9
8Russell (1905), pp. 482–484.
9Russell (1905), pp. 485–490.

18
2
The Ideal of Logical Perfection
The third puzzle, known as Frege’s puzzle, is how can it be the case that an
identity statement is both true and informative. Consider the following sentence:
(29) Scott is the author of Waverley
As far as we know, (29) is true. Moreover, (29) seems informative, given that
someone might learn something new upon reading it. But if it is assumed that (29)
contains two genuine singular terms which refer to the same person, Scott, then the
most plausible explanation is that the two expressions have some kind of meaning
over and above its referent, as suggested by Frege. Otherwise it must be conceded
that what is said is simply that Scott is identical to himself, which is trivial. Russell
has a different explanation: (29) does not really express an identity because ‘the
author of Waverley’ is not really a singular term. His paraphrase goes as follows:
(30) For some x, x is author of Wawerley, and for every y, if y is author of Wawerley,
then y D x, and x is the same as Scott.
Clearly, we learn something when we get to know that (30) is true.10
The fourth puzzle, which is closely related to the third, concerns substitutivity.
On the assumption that a singular term is meaningful in virtue of its denoting
role, one may expect that any two singular terms that have the same reference are
semantically equivalent: we could take any sentence containing one of them and
substitute it with the other, without changing the truth value of the sentence. But
consider the following sentences:
(31) George IV wants to know whether Scott is the author of Waverley
(32) George IV wants to know whether Scott is Scott
It may be the case that (31) is true but (32) is false, which means that ‘Scott’ and ‘the
author of Waverley’ are not substitutable salva veritate. Russell’s solution, again,
rests on his claim that ‘the author of Waverley’ is not a genuine singular term.
According to him, the desire ascribed to George IV in (31) is to know whether
(30) is true. So it is a different desire from that ascribed to George IV in (32).11
The implications of Russell’s theory of descriptions go far beyond the four
puzzles considered. According to this theory, the logical properties of a sentence
that contains a deﬁnite description are not immediately visible, but they can be
elucidated if the sentence is paraphrased in the appropriate way. For example, (23)
is misleading, in that it may appear that ‘the author of Waverley’ is a genuine
singular term. The correct reading of ‘the author of Waverley’ becomes clear in
(24). So the underlying idea is that the logical properties of a sentence can be
revealed by an appropriate paraphrase of the sentence. This idea, which is the core
of Russell’s conception of analysis, opens a wide-ranging perspective. If the method
of paraphrase can fruitfully be applied to sentences containing deﬁnite descriptions,
10Russell (1905), p. 492. Frege (1892) states the puzzle and draws a distinction between sense and
reference.
11Russell (1905), pp. 485–489.

2.3
Wittgenstein
19
it is natural to think that it can be extended to other kinds of sentences. Nothing
prevents one from thinking that other kinds of sentences may be misleading in
similar ways.
After On denoting, Russell worked in this direction, trying to elucidate the role of
the method of paraphrase within a broader theoretical framework. For some years,
he described analysis as a process whereby one reconstructs complex notions in
terms of simpler ones. The process would eventually result in a language whose
vocabulary includes only logical symbols, names standing for simple particulars and
predicates standing for properties or relations. In such a logically ideal language,
the simplest kind of sentence would be an “atomic sentence”, that is, a sentence
containing a single predicate and an appropriate number of names. The truth or
falsity of an atomic sentence would depend entirely on a corresponding “atomic
fact”, which consists either of a simple particular having a property, or of a number
of simple particulars standing in a relation. The other sentences of the language
would be formed either by combining atomic sentences using truth-functional
connectives, or by replacing constituents of a simpler sentence by variables and
preﬁxing a universal or existential quantiﬁer.12
The foregone outcome of this line of thought is that facts are represented
perspicuously only in a language – a logically ideal language – that radically differs
from any natural language, for it is plausible that no word of any natural language
can belong to such a language. This turns out clear if one thinks about ordinary
names, such as ‘Scott’. On the assumption that the only genuine singular terms are
symbols that denote simple particulars – the names of a logically ideal language –
we get that ordinary names are not genuine singular terms. Russell suggested that
every apparent name not occurring at the end of analysis is equivalent in meaning
to some deﬁnite description, so it can be paraphrased away.13
2.3
Wittgenstein
Wittgenstein’s Tractatus Logico-Philosophicus (1921) outlines a picture of the
relation between language and reality that has much in common with that advanced
by Russell. Wittgenstein claims that the world is ultimately constituted by a plurality
of simple facts, “atomic facts”, and that language describes the world by means of a
plurality of simple sentences, “elementary sentences”, which represent such facts.14
In the Tractatus, atomic facts are deﬁned as combinations of simple objects, and
elementary sentences are deﬁned as concatenations of simple expressions called
“names”. Each elementary sentence represents a “state of affairs” – a possible
12Russell used ‘proposition’ instead of ‘sentence’. But here it will be assumed that the two terms
are not synonymous.
13Russell (1998) advances this line of thought.
14Wittgenstein (1992). Like Russell, Wittgenstein uses ‘proposition’ instead of ‘sentence’.

20
2
The Ideal of Logical Perfection
combination of simple objects – because the names in the sentence denote simple
objects, and the way they are concatenated exhibits a way in which those objects
can be combined. In virtue of this representation, each elementary sentence asserts
the existence of an atomic fact, so it is true if and only if the fact exists, that is, if
and only if the objects denoted by its names are combined in the way exhibited.15
A central thesis of the Tractatus is that elementary sentences are “pictures” of
states of affairs. A picture is understood as a combination of elements, each of which
stands for some thing. The fact that the elements of the picture are combined in a
certain way represents that certain things are combined in that way. Wittgenstein
calls “structure” the way in which the elements of a picture are combined, and calls
“pictorial form” the possibility of the structure. Something possesses the pictorial
form required to depict a given situation if it is possible to arrange its elements in a
way that mirrors the relation between the constituents of that situation. The pictorial
form is the possibility of the arrangement, something that must be shared by picture
and situation. Therefore, an elementary sentence is a picture of a state of affairs
insofar as it shares with that state of affairs a pictorial form, which consists in the
possibility of a certain combination of simple objects exhibited by a concatenation
of names.16
The pictorial account of representation can be extended to all sentences. Wittgen-
stein claims that every non-elementary sentence has a unique analysis that reveals
it to be a truth function of elementary sentences. So it turns out that every sentence
is a truth function of elementary sentences: every complex sentence is a truth
function of the elementary sentences it contains, and every elementary sentence
is a truth function of itself. A truth function of elementary sentences, according to
Wittgenstein, is made true or false by a combination of states of affairs, namely, the
states of affairs pictured by the elementary sentences that feature as its arguments.
Therefore, every sentence represents reality in virtue of its being constituted by
sentences each of which is a picture of some state of affairs according to some form
of representation.17
In order to elucidate the kind of pictorial form involved in language, Wittgenstein
asks us to think about what all pictorial forms have in common, the possibility of
the structure in the most abstract sense. To characterize this sense, he uses the term
‘logical form’:
What every picture, of whatever form, must have in common with reality in order to be able
to represent it at all – rightly or falsely – is the logical form, that is, the form of reality.18
Wittgenstein’s idea is that in order for a picture to represent a situation, the picture
must have the same multiplicity as the situation, that is, the same number of
elements and the same combinatorial possibilities. Thus, whatever has pictorial form
15Wittgenstein (1992), pp. 31–35, 89.
16Wittgenstein (1992), pp. 39–41.
17Wittgenstein (1992). p. 103 and ff.
18Wittgenstein (1992), p. 41.

2.3
Wittgenstein
21
also has logical form, which means that every picture is also a “logical picture”.
However, some pictures deserve more than others to be called logical, namely, those
whose only pictorial form is logical form. Wittgenstein claims that a thought is a
logical picture in this sense. Since sentences express thoughts, he seems to suggest
that language represents the world by providing logical pictures of facts.19
Before the Tractatus, the term ‘logical form’ had been used by Russell in Theory
of Knowledge (1913) to phrase his multiple-relation theory of judgment. Consider
the following example:
(33) Othello believes that Desdemona loves Cassio
According to Russell, the content of (33) can be represented as B.s; ; a; R; b/. To
say that a subject s, Othello, believes that an object a, Desdemona, is in a relation
R, love, with another object b, Cassio, is to say that there is a belief B that involves
s, a, R, b, and a logical form . Russell does not explain what exactly is . He says
that a logical form is a “logical object”, and that we can refer to the logical form
of a complex aRb by using an expression ‘xXy’, where ‘x’, ‘X’ and ‘y’ replace the
linguistic expressions that refer to the constituents of the complex. So he seems to
understand a logical form as the way in which the constituents of a complex are put
together within a judgement. This is why he says that the logical form of a complex
is not itself a constituent of the complex, although it occurs as a constituent of the
judgement.20
Russell’s use of the term ‘logical form’ is motivated by considerations that
pertain to his multiple-relation theory of judgment. Presumably, the primary role
of logical form in that theory is to rule out meaningless judgments, things such
as Othello’s belief that loves Desdemona Cassio. On the assumption that a logical
form is necessary for the formation of a judgment, meaningless judgments can be
described as judgments for which no logical form is available. Thus, Othello’s belief
that loves Desdemona Cassio is meaningless because no logical form such as Xxy is
available, that is, it is not possible that there is a complex such as Rab.21
Even though this is not the kind of considerations that Wittgenstein had in mind,
Wittgenstein’s use of ‘structure’, which is closely related to his use of ‘logical
form’, may be regarded as a natural development of Russell’s use of ‘logical
form’. Wittgenstein extends the range of application of ‘logical form’ as used by
Russell in at least two directions. First, his use of ‘structure’ is not restricted to
complexes or states of affairs as they occur within an act of judgment, but it is
intended to designate an essential feature of any complex or state of affairs. Second,
while Russell’s use of ‘logical form’ involves no explicit reference to language,
Wittgenstein’s use of ‘structure’ implies that the term refers to something that can
be ascribed to sentences, although not only to sentences.
19Wittgenstein (1992), pp. 41–43.
20Russell (1913), p. 113. To explain that the logical form of a complex is not itself a constituent
of the complex, Russell says that the former is not an entity. But the distinction between object
and entity is not clear, and Russell does not provide conclusive arguments to the effect that logical
forms are not entities.
21Bonino (2008), pp. 170–192, explains Russell’s motivation.

22
2
The Ideal of Logical Perfection
The historical importance of Wittgenstein’s use of ‘logical form’ lies in this
extension of Russell’s use, which opened the way for further elaborations of its
meaning. The distinction between ‘structure’ and ‘logical form’ did not survive the
Tractatus, so ‘logical form’ became a term for ‘structure’. Although most of the
claims defended in the Tractatus were soon abandoned by Wittgenstein himself, the
inﬂuence of the Tractatus contributed to the circulation of the term ‘logical form’,
and at some point it became common for philosophers belonging to the analytic
tradition to talk of logical form as a property of sentences. So the current uses of
this term derive at least to some extent from Wittgenstein’s use.22
2.4
A Logically Perfect Language
The thought that emerges from the works considered in the foregoing sections is that
the logical properties of a sentence of natural language are elucidated by showing
how the sentence can be formalized in a logically perfect language. Therefore, a
crucial question that must be addressed in order to get a better understanding of
those works is what is it for a language to be logically perfect.
Frege, Russell and Wittgenstein seem to agree that a basic feature of a logically
perfect language, which makes it differ from natural language, is the following:
(LP)
Every sentence has deﬁnite truth conditions that are determined by its
semantic structure and reﬂected in its syntactic structure.
The syntactic structure of a sentence depends on the syntactic categories of the
expressions that occur in the sentence and the way they are combined. For our
purposes it may be assumed that two expressions e and e0 belong to the same
syntactic category if and only if, for every sentence containing e, the result of
replacing e by e0 is also a sentence. Similarly, the semantic structure of a sentence
depends on the semantic categories of the expressions that occur in the sentence
and the way they are combined. For our purposes it may be assumed that two
expressions e and e0 belong to the same semantic category if and only if they are
subject to the same interpretation rule, that is, the meaning assigned to e and the
meaning assigned to e0 are the same kind of entity. The verb ‘reﬂected’ indicates
coincidence of syntax and semantics, that is, for any syntactic category there is
a semantic category containing just the same expressions, and vice versa. If we
call perspicuous a language in which syntax and semantics coincide, (LP) implies
that a logically perfect language is perspicuous. So the idea seems to be that a
formalization of a sentence in a logically perfect language provides a perspicuous
representation of the sentence that displays its logical properties.23
22Wittgenstein himself, in Wittgenstein (1993), shows how some central claims of the Tractatus
can be abandoned without giving up the term ‘logical form’.
23This is the deﬁnition of perspicuity outlined in Sainsbury (1991), p. 344.

2.4
A Logically Perfect Language
23
Natural language does not satisfy (LP) for at least three reasons. First, natural
language is affected by vagueness. Consider the following sentence:
(34) Tom is bald
The predicate ‘bald’ is vague, because there are borderline cases of baldness, that
is, cases in which ‘bald’ neither clearly applies nor clearly does not apply. If Tom
is borderline bald, (34) is neither deﬁnitely true nor deﬁnitely false. Therefore,
(34) does not have deﬁnite truth conditions, at least on the plausible assumption
that having deﬁnite truth conditions entails being either deﬁnitely true or deﬁnitely
false. By contrast, a logically perfect language is precise. Every sentence of a
logically perfect language has deﬁnite truth conditions, so it is either deﬁnitely true
or deﬁnitely false.
Second, natural language is affected by ambiguity. A sentence of natural
language may be ambiguous, that is, it may have more than one meaning. This is
due either to ambiguity in its syntactic structure, or to ambiguity in some expression
occurring in it. Consider the following sentences:
(35) Everybody loves somebody
(36) Tom goes to the bank
(35) is structurally ambiguous because it can mean either that, for every x, there is at
least one y such that x loves y, or that there is at least one x such that, for every y, y
loves x. (36) is lexically ambiguous because ‘bank’ can refer either to a ﬁnancial
institution or to the edge of a river. Therefore, (35) and (36) lack deﬁnite truth
conditions in the obvious sense that they have different truth conditions on different
readings. By contrast, a logically perfect language is not ambiguous. Structural
ambiguity is ruled out because every sentence has a unique syntactic structure,
which reﬂects a unique semantic structure. Similarly, lexical ambiguity is ruled out
because any two distinct objects are denoted by distinct symbols.
Third, natural language is affected by context sensitivity. Consider the following
sentence:
(37) Tom is there
Since ‘there’ is context sensitive, (37) may have different truth conditions in
different contexts. Therefore, (37) does not have deﬁnite truth conditions. By
contrast, a logically perfect language is free from context sensitivity. Any variation
of truth conditions due to variation of context would constitute a semantic difference
not manifested in any syntactic difference.24
(LP) is a basic feature of a logically perfect language, so it is compatible with
more than one way to understand its syntax and its semantics. Frege, Russell and
Wittgenstein seem to agree on the assumption that a logically perfect language
24Here (34), (36) and (37) are described without taking into account the fact that names such as
‘Tom’ can also be affected by vagueness, ambiguity or context sensitivity. This is obviously a
simpliﬁcation, but it is harmless.

24
2
The Ideal of Logical Perfection
satisﬁes (LP), but their descriptions of such language differ in other respects. First,
as it turns out from Sects. 2.2 and 2.3, Russell and Wittgenstein claim that the simple
expressions of a logically perfect language – its names – refer to simple objects.
Frege, instead, does not place such constraint. Second, Russell and Wittgenstein
suggest that there is no synonymy in a logically perfect language, as any two
distinct names denote distinct objects. Frege, instead, leaves room for the possibility
that distinct symbols refer to the same object. Finally, Wittgenstein differs from
Frege and Russell on the analysis of quantiﬁcation. In the Tractatus, universally
quantiﬁed sentences are analyzed in terms of conjunctions of elementary sentences,
and existentially quantiﬁed sentences are analyzed in terms of disjunctions of
elementary sentences, contrary to the account endorsed by Frege and Russell.25
Independently of these differences, however, what emerges from the description
provided by Frege, Russell, and Wittgenstein is that a logically perfect language is
something radically different from natural language. So their line of thought clearly
differs from previous attempts to model the language of logic on natural language.
As we have seen in Sect. 1.4, Ockham held that the logical structure of our sentences
is expressible in a mental language. But the mental language he imagined was very
similar to natural language: its syntax and semantics were structurally analogous to
those of natural language. On the contrary, the language that Frege, Russell, and
Wittgenstein have in mind bears no close resemblance to natural language.
2.5
The Old Conception of Logical Form
From what has been said so far it turns out that Frege, Russell and Wittgenstein
shared three main claims about logical form, even though they did not state them by
using the term ‘logical form’:
(OC1)
Logical properties depend on logical form.
(OC2)
Logical form may not be visible in surface structure.
(OC3)
Logical form is exhibited in a logically perfect language.
The conjunction of (OC1)–(OC3) may be called the old conception of logical form.
(OC1) derives from the very thought that lies at the origin of logic, as explained in
Sect. 1.3: the logical properties of a sentence depend on its logical form in the sense
that a formal explanation of the validity of the arguments that include the sentence
involves a formal representation of the sentence. Similarly, the plausibility of (OC2)
has been recognized by many logicians before Frege, Russell, and Wittgenstein.
25The hypothesis that distinct names denote distinct objects will be considered in Sects. 6.2 and 6.4.
Wittgenstein’s claim about quantiﬁcation is expressed in Wittgenstein (1992), pp. 135 and 153.
In reality, his view is not so clear, given that he denies that universally quantiﬁed sentences are
conjunctions, and that existentially quantiﬁed sentences are disjunctions. Marconi (1995) provides
some elucidations about Wittgenstein’s claim, and the reasons that led him to abandon it after the
Tractatus.

2.5
The Old Conception of Logical Form
25
For example, Abelard’s remarks on the existential import of ‘is’ reported in Sect. 1.4
clearly entail (OC2). So the claim that characterizes the old conception of logical
form is (OC3). This claim implies that logical form is exhibited in a language that
satisﬁes (LP) and substantially differs from natural language.
As is natural to expect, the tenability of (OC3) crucially depends on the deﬁnition
of logically perfect language, for in order to give substance to (OC3) it must
be shown how the sentences of a logically perfect language exhibit the logical
form of the corresponding sentences of natural language. Russell and Wittgenstein
soon recognized that their idea of logically perfect language led them into serious
troubles. One well known problem concerns the requirement that a logically perfect
language includes a name for every object. Considerations of cardinality suggest
that the number of objects clearly exceeds the number of symbols of any language
we are familiar with. Another well known problem concerns the idea that the objects
named are simple. Since no ordinary object can be simple, it is hard to see how we
can get a real grasp of the semantic properties of the sentences of a logically perfect
language. More generally, if the constraints imposed on a logically perfect language
are too demanding, it turns out that no formal language that we are able to deﬁne in
a rigorous way can satisfy them. But then it is not clear how we can have epistemic
access to a logically perfect language, and its relation with natural language turns
out to be ineffable.26
26It is not entirely obvious that Russell and Wittgenstein have the second problem, as it is not
entirely obvious that they understand simplicity as an absolute property.

Chapter 3
Formal Languages and Natural Languages
Abstract The old conception of logical form did not survive the problems that
emerged in connection with the dichotomy between natural language and logically
perfect language. After Frege, Russell, and Wittgenstein, the ideal of logical
perfection lost traction. However, the spirit of that conception did not die with its
letter. Many philosophical works have been inspired by the thought that sentences
must be paraphrased in a suitable language to elucidate their logical form. This
chapter explains how the idea of logical form has evolved, as it dwells on two
far-reaching developments that marked the analytic tradition. One concerns the
characterization of the language that is expected to display logical form, the other
concerns the understanding of natural language itself.
3.1
Tarski’s Method
The ﬁrst development, which is the focus of this section, stems from Tarski’s
deﬁnitions of truth and logical consequence for ﬁrst order languages, the direct
descendants of Frege’s ideography. Let us consider a simple ﬁrst order language, L,
which will be employed in the rest of the book. The vocabulary of L is the following:
P; Q; R : : :
a; b; c : : :
; ; 8
x; y; z : : :
., /
P; Q; R : : : are predicate letters, which stand for arbitrary predicates. a; b; c : : :
are individual constants, which stand for arbitrary singular terms. ; ; 8 are
connectives, which mean respectively ‘not’, ‘if then’, ‘for every’. x; y; z : : : are
variables. Predicate letters and individual constants are nonlogical expressions,
connectives are logical constants, variables and brackets are auxiliary symbols.
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_3
27

28
3
Formal Languages and Natural Languages
Individual constants and variables are terms. The convention that will be adopted
from now on is that any expression of L may be used as a name of the expression
itself, thus avoiding quotation marks.
The formation rules of L are as follows:
Deﬁnition 3.1.1
1. If P is a n-place predicate letter and t1; : : : ; tn are terms, Pt1 : : : tn is a formula;
2. if ˛ is a formula,  ˛ is a formula;
3. if ˛ and ˇ are formulas, .˛  ˇ/ is a formula;
4. if ˛ is a formula and x is a variable, 8x˛ is a formula.
As usual, outer brackets will be omitted to simplify the notation. The syntactic
terminology will be standard. The scope of a connective in a formula ˛ is the
smallest formula that occurs in ˛ and contains the connective. An occurrence of a
variable is bound in a formula ˛ when it is in the scope of a quantiﬁer immediately
followed by the same variable, otherwise it is free in ˛. If all the occurrences of a
variable in a formula ˛ are bound we say that the variable is bound in ˛, otherwise
we say that the variable is free in ˛. A formula in which some variable is free is
open. A formula that is not open is closed.
Now we will show how truth and logical consequence for L can be deﬁned in
terms of satisfaction, the notion that characterizes Tarski’s method. The semantics
that will be provided is “model-theoretic”, in that it is based on the notion of model
deﬁned as follows:
Deﬁnition 3.1.2 A model M is an ordered pair hD; Ii such that D is a non-empty
set, and I is a function that assigns to every individual constant a member of D and
to every n-place predicate letter a set of n-uples of members of D.
D is the domain of M, and I is the interpretation function of M. To indicate
the values of I, we will use square brackets. Thus, if a is an individual constant,
ŒaM D I.a/. A model provides a meaning for all the nonlogical expressions of L, at
least if ‘meaning’ is understood as ‘extension’ and it is assumed that the extension
of a singular term is the object it denotes and the extension of a predicate is the
set of objects to which it applies. This is not exactly what Tarski had in mind.
The deﬁnitions he offered involve no relativization to domains, in that he took
the domain for granted. The same goes for Frege, Russell, and Wittgenstein, since
their characterization of a logically perfect language includes an intended domain
and, at least in the Tractatus, an assignment of reference to nonlogical expressions.
However, the deﬁnitions that will be provided here do not substantially differ from
Tarski’s deﬁnitions. The step that led from Tarski’s deﬁnitions to formal semantics
as is currently understood was rather short. Now it is common to deﬁne formal
languages as uninterpreted languages, in the sense that no speciﬁc interpretation of
their nonlogical expressions is taken for granted.1
1Tarski outlines his method in (1933) and in (1936).

3.1
Tarski’s Method
29
As it turns out from Deﬁnition 3.1.2, a model M leaves indeterminate the
denotation of the variables. Each variable x can denote different objects in M. This
is expressed by saying that x gets different values in different assignments in M:
Deﬁnition 3.1.3 In a model M, an assignment  is a function such that, for every
variable x, .x/ 2 D.
Since an assignment provides a denotation for the variables, the denotation of a term
t in M relative to , in symbols ŒtM;, is deﬁned as follows:
Deﬁnition 3.1.4
1. If t is an individual constant, ŒtM; D ŒtM;
2. if t is a variable, ŒtM; D .t/.
The satisfaction of a formula by an assignment  in a model M is deﬁned as
follows, assuming that an x-variant of  is an assignment that differs from  at
most in the value of x:
Deﬁnition 3.1.5
1.  satisﬁes Pt1 : : : tn if and only if hŒt1M;; : : : ; ŒtnM;i 2 Œ PMI
2.  satisﬁes  ˛ if and only if  does not satisfy ˛;
3.  satisﬁes ˛  ˇ if and only if  does not satisfy ˛ or  satisﬁes ˇ;
4.  satisﬁes 8x˛ if and only if every x-variant of  satisﬁes ˛.
One important consequence of Deﬁnition 3.1.5 is that, for any closed formula
˛, either every assignment satisﬁes ˛ or no assignment satisﬁes ˛. The reason is
that the following conditional is provable: if two assignments  and 0 are such
that .x/ D 0.x/ for every variable x free in a formula ˛, then  satisﬁes ˛ if and
only if 0 satisﬁes ˛. If we suppose that two assignments  and 0 are such that 
satisﬁes a formula ˛ but 0 does not satisfy ˛, from that conditional we can infer by
contraposition that ˛ contains at least one free variable x such that .x/ ¤ 0.x/.
But this rules out that ˛ is closed. Therefore, if ˛ is closed, it cannot be the case that
there are two assignments  and 0 such that  satisﬁes ˛ but 0 does not satisfy ˛.
Since Deﬁnition 3.1.5 entails that, for any closed formula ˛, either every
assignment satisﬁes ˛ or no assignment satisﬁes ˛, truth and falsity in a model
can be deﬁned in terms of satisfaction as follows:
Deﬁnition 3.1.6 Œ˛M D 1 if and only if all assignments in M satisfy ˛.
Deﬁnition 3.1.7 Œ˛M D 0 if and only if no assignment in M satisﬁes ˛.
Here Œ˛M indicates the truth value of ˛ in M. From Deﬁnitions 3.1.6 and 3.1.7 we
get that, for every closed formula ˛, either Œ˛M D 1 or Œ˛M D 0.
If  is a set of formulas and ˛ is a formula, the relation of logical consequence –
indicated by the symbol  – is deﬁned as follows:

30
3
Formal Languages and Natural Languages
Deﬁnition 3.1.8   ˛ if and only if, in every model, every assignment that
satisﬁes all the formulas in  satisﬁes ˛.
Let us conclude with some remarks about L’s potential to exhibit logical form.
L is not exactly a logically perfect language in the sense that Frege, Russell, and
Wittgenstein had in mind. In particular, a logically perfect language in that sense is
expected to satisfy the following constraint:
(LP)
Every sentence has deﬁnite truth conditions that are determined by its
semantic structure and reﬂected in its syntactic structure.
L does not satisfy (LP) for a simple reason. Since L is uninterpreted, its sentences –
that is, its closed formulas – do not have truth conditions simpliciter but only relative
to models. However, L satisﬁes a very similar constraint:
(LP*)
In every model, every sentence has deﬁnite truth conditions that are
determined by its semantic structure and reﬂected in its syntactic structure.
If we call logically perfect* a language that satisﬁes (LP*), there seems to be no
reason why a logically perfect* language should not able to exhibit logical form. A
logically perfect* language, just as a logically perfect language, is perspicuous in
the sense explained in Sect. 2.4. Since the semantics of a perspicuous language can
be deﬁned in a rigorous way by means of rules of interpretation that specify deﬁnite
truth conditions for each sentence, it is reasonable to think that logical perfection*,
rather than logical perfection, is what matters for representation of logical form.
After Tarski, it has become customary to assume that the logical form of a sentence
is to be represented in a language like L, that is, a formal language for which we can
provide model-theoretic deﬁnitions of truth and logical consequence.
3.2
Davidson’s Program
The second development that will be considered concerns the understanding of
natural language. Frege, Russell, Wittgenstein, and Tarski did not regard natural
language as intrinsically interesting, and this was due at least in part to their belief
that natural language is incapable of being studied in a rigorous and systematic way.
This attitude towards natural language prevailed until the middle of the twentieth
century, but then things changed. A ﬁrst step in the opposite direction was prompted
by the program of generative grammar, which gained popularity among linguists
towards the end of the 1950s. This program, fostered by Chomsky, hinges on the
view that there is a Universal Grammar, a system of syntactic rules that underlies all
natural languages. Chomsky suggested that natural languages differ essentially in
their lexicon and along a limited series of dimensions ruled by parameters, while
the rules of syntax are largely innate, as a biological component of the human
species. On this view, the syntax of natural language can be studied in a rigorous and
systematic way. A further step in the same direction was made between the 1960s
and the 1970s, when linguists and philosophers started working on the hypothesis

3.2
Davidson’s Program
31
that Tarski’s method for deﬁning truth and logical consequence can be applied to
natural language, contrary to what Tarski himself had claimed. This section and the
next explain how Davidson and Montague developed this hypothesis, initiating a
new approach to the semantics of natural language.
Davidson sketches a program of a theory of meaning, understood as a systematic
account of a natural language that enables a ﬁnite creature to understand every
sentence of the language. According to his proposal, the theory must be phrased
as a set of axioms that enables us to derive, for every sentence s of the language, a
theorem that speciﬁes the meaning of s. Since the language has a ﬁnite vocabulary
but an inﬁnite number of sentences, it must be assumed that the meaning of s
depends on the meanings of its parts, that is, on the meanings of the expressions
in s that belong to the vocabulary of the language. In other words, the theory that
Davidson has in mind is based on the principle of compositionality, which guided
Frege’s analysis of sentences in terms of function-argument structure:
(PC)
The meaning of a complex expression is determined by its structure and the
meaning of its constituents.
The central idea of Davidson’s program is that meaning is a matter of truth
conditions: to know the meaning of s is to know the conditions under which s is
true. Davidson suggests that the theorems of a theory of meaning are phrased as
instances of the schema ‘s is true if and only if p’, where ‘p’ is a translation of s
in the metalanguage. For example, “La neve è bianca’ is true if and only if snow
is white’. The predicate ‘is true’ that occurs in the schema is to be spelled out in
the way suggested by Tarski. That is, just as the truth conditions of a sentence of
L can be deﬁned in terms of satisfaction, as shown in Sect. 3.1, the truth conditions
of a sentence of a natural language can be deﬁned in similar way in terms of the
semantic properties of its constituent expressions.2
Davidson’s account of logical form essentially relies on his program. According
to this account, to give the logical form of a sentence is to describe its semantically
relevant features against the background of a theory of truth:
What should we ask of an adequate account of the logical form of a sentence? Above all,
I would say, such an account must lead us to see the semantic character of the sentence –
its truth or falsity – as owed to how it is composed, by a ﬁnite number of applications of
some of a ﬁnite number of devices that sufﬁce for the language as a whole, out of elements
drawn from a ﬁnite stock (the vocabulary) that sufﬁces for the language as a whole. To see
a sentence in this light is to see it in the light of a theory for its language, a theory that gives
the form of every sentence in that language.3
Davidson’s work had an enormous impact on the study of natural language,
as many philosopher after him adopted his perspective and tried to develop his
program. Yet Davidson himself did not provide a detailed treatment of signiﬁcant
portions of some natural language. Montague differs in this respect. On the assump-
2Davidson’s program is outlined in Davidson (1984).
3Davidson (1968), p. 131.

32
3
Formal Languages and Natural Languages
tion that there is no important theoretical difference between natural languages
and the artiﬁcial languages of logicians, Montague provided the ﬁrst proper formal
treatment of English based on Tarski’s method.4
3.3
Montague Semantics
Montague agrees with Davidson on the centrality of (PC), which he regards as the
key to a systematic relation between syntax and semantics. According to Montague,
a proper formal treatment of a fragment of English can be obtained as follows.
First, we specify a set of syntactic rules that enable us to construct all the complex
expressions of the fragment from a ﬁnite set of simple expressions. Then we provide
a translation of each of the simple expressions into a formal language and associate
a translation rule to each syntactic rule. If S is a syntactic rule that enables us to
combine the expressions ˛ and ˇ in a complex expression ˛ˇ and T is the translation
rule that corresponds to S, then T must specify how the translation of ˛ˇ can be
computed from the translations of ˛ and ˇ. Since truth in a model is deﬁned in the
formal language in accordance with Tarski’s method, we get that a sentence in the
fragment is true in a given interpretation just in case its translation is true in the
corresponding model. Similarly, logical consequence is deﬁned for the fragment in
terms of logical consequence in the formal language.5
Montague describes the syntax of English as a categorial grammar, assuming
that each expression belongs to some category, and that the category of each
complex expression ˛ˇ formed by two expressions ˛ and ˇ is determined by the
respective categories of ˛ and ˇ. In a categorial grammar there are two kinds of
categories: basic categories and derived categories. Each derived category is labelled
by a symbol of the form (A/B), where A and B are category symbols as well. An
expression of category (A/B) is an expression that, followed by an expression of
category B, produces an expression of category A. The basic rule of the grammar
can be phrased as a concatenation rule:
(CR)
If ˛ is an expression of category (A/B) and ˇ is an expression of category
B, then ˛ˇ is an expression of category A.6
Suppose that we are dealing with a very small fragment of English that contains only
the simple expressions ‘boy’, ‘horse’, ‘runs’, ‘sleeps’, ‘a’ and ‘every’. In this case
we have three basic categories: S, CN, and IV. S is the category of sentences, which
does not contain simple expressions. CN is the category of common nouns, which
4The assumption is explicitly stated in Montague (1970), p. 222.
5This is the method adopted in Montague (1973). The formal language employed by Montague is
unlike L in many respects: it is higher order, it is intensional, and it includes the lambda operator.
However, as far as the application of Tarski’s method is concerned, it is essentially like L.
6The categorial grammar adopted by Montague is a version of that originally proposed in
Ajdukiewicz (1935).

3.3
Montague Semantics
33
contains ‘boy’ and ‘horse’. IV is the category of intransitive verbs, which contains
‘runs’ and ‘sleeps’. Derived categories are obtained from basic categories. Among
these we ﬁnd the category ((S/IV)/CN), which contains ‘a’ and ‘every’. From an
expression of category ((S/IV)/CN) and an expression of category CN we get an
expression of category (S/IV). For example, from ‘every’ and ‘boy’ we get ‘every
boy’, which is an expression of category (S/IV). Similarly, from an expression of
category (S/IV) and an expression of category IV we get an expression of category
S. For example, from ‘every boy’ and ‘runs’ we get the following sentence:
(1) Every boy runs
If syntax is deﬁned in terms of (CR), semantics can be formulated in accordance
with (PC). A denotation can be assigned to the simple expressions in such a way
that the denotation of any complex expression is generated by means of a rule of
functional application:
(FA)
The denotation of an expression ˛ˇ is F(G), where F and G are respectively
the denotations of ˛ and ˇ.
Consider (1). In accordance with Frege’s analysis, we can assume that ‘boy’ denotes
a ﬁrst-level function B such that, for every x, B.x/ D 1 if x is a boy and B.x/ D 0
otherwise. Similarly, we can assume that ‘every’ denotes a function E from ﬁrst-
level functions to second-level functions such that, given any ﬁrst-level function F,
E. F/ is a second level function such that, for any ﬁrst-level function G, E. F/.G/ D
1 if, for every x, if F.x/ D 1 then G.x/ D 1, and E. F/.G/ D 0 otherwise. From
these two assumptions we get that ‘every boy’ denotes a second-level function E.B/
such that, for every ﬁrst-level function G, E.B/.G/ D 1 if G.x/ D 1 for every x that
is a boy, and E.B/.G/ D 0 otherwise. Thus, assuming that ‘runs’ denotes a ﬁrst-
level function R such that, for every x, R.x/ D 1 if x runs and R.x/ D 0 otherwise,
we get that the denotation of (1), its truth value, is the value that the function E.B/
takes for R as argument.
This is just an illustration of Montague semantics. Since the fragment of English
he studied is wider than that considered, his theory is more complex. Instead of a
single syntactic rule, he provided a set of syntactic rules that differ from (CR) in
various respects. Besides, he used ‘type’ instead of ‘level’. Starting from any non-
empty set, we can build an inﬁnite hierarchy of functions of increasing complexity,
where the complexity of each function depends on its type. However, the details
of Montague’s theory do not concern us. All that matters here is that his theory
entails that syntactic rules and semantic rules work in parallel: whenever a complex
expression ˛ˇ is formed by combining two expressions ˛ and ˇ, its denotation
is determined by applying the function denoted by ˛ to the denotation of ˇ. For
each category, there is a type that corresponds to that category, so every expression
that belongs to a given category has a denotation that belongs to the domain of the
corresponding type.
Montague’s approach to natural language – call it the formal approach – became
very inﬂuential. Many linguists and philosophers after him developed his ideas,
elaborating his theory and extending his methods to increasingly wider portions

34
3
Formal Languages and Natural Languages
of language. In this process, some of his assumptions were modiﬁed or abandoned,
while new notions and hypotheses were added. But the overall framework remained
the same. After Montague it became common to think that natural language can be
studied in a rigorous and systematic way, and that model-theoretic semantics can be
applied to it with or without the mediation of a formal language.
An important extension of Montague’s methods concerns the treatment of index-
icals and demonstratives, that is, context-sensitive expressions such as ‘I’, ‘you’,
‘now’, ‘this’, ‘that’ or ‘there’. As Lewis and Kaplan have suggested, a sentence that
contains indexicals or demonstratives may formally be described as a sentence that
has truth conditions relative to parameters, understood as sets of coordinates that
provide appropriate semantic values for the indexicals or demonstratives occurring
in the sentence. Following Lewis, we will call indices these parameters. Kaplan calls
them ‘contexts’, but we will use ‘context’ only as a non-technical term, to refer to a
possibly concrete situation in which a sentence can be used. Consider the example
of context sensitivity used in Sect. 2.4:
(2) Tom is there
If one assumes that a given index provides a denotation for ‘there’, one can say
that (2) is true or false relative to that index. On this account, the syntactic structure
of a sentence that contains indexicals or demonstratives is analogous to an open
formula, in that it contains expressions similar to free variables. Just as an open
formula cannot be evaluated as true or false unless a denotation is assigned to its free
variables, a sentence containing indexicals or demonstratives cannot be evaluated as
true or false unless an appropriate semantic value is assigned to its indexicals or
demonstratives.7
3.4
The Current Conception of Logical Form
Although the two developments considered in Sects. 3.1, 3.2, and 3.3 inexorably
eroded the old dichotomy between natural language and logically perfect language,
they did not affect the substance of the old conception of logical form. As we saw
in Sect. 2.5, that conception is the conjunction of three claims:
(OC1)
Logical properties depend on logical form.
(OC2)
Logical form may not be visible in surface structure.
(OC3)
Logical form is exhibited in a logically perfect language.
(OC1) is not in question. The revision of the dichotomy between natural language
and logically perfect language leaves untouched the idea that the logical properties
of a sentence depend on its logical form, for that idea does not rely on some speciﬁc
account of the relation between natural language and the language that is expected
to exhibit logical form.
7An account of indexicals and demonstratives along these lines was ﬁrst suggested in Bar-Hillel
(1954) and in Montague (1968), then developed in Lewis (1970), and in Kaplan (1977).

3.4
The Current Conception of Logical Form
35
(OC2) is not in question either. Even if one endorses the formal approach,
and maintains that natural language is analogous to a formal language, one may
coherently claim that logical form is not immediately visible in surface structure.
The formal approach leaves room for a distinction between surface structure and
“real” structure, where the latter is a formal representation postulated as the input
of the interpretation of the former. So the analogy is taken to hold at the level of
real structure, rather than at the level of surface structure. The distinction between
surface structure and real structure emerges clearly from Montague’s treatment of
ambiguity, which has become standard in the formal approach. Consider again the
following sentences:
(3) Everybody loves somebody
(4) Tom goes to the bank
According to Montague, (3) is ambiguous because it can be generated by applying
two different sequences of syntactic rules, and (4) is ambiguous because there are
two distinct syntactic items which correspond to the two meanings of ‘bank’. In both
cases, the ambiguity of the sentence consists in the fact that it can be associated with
two distinct structures, each of which is not itself ambiguous. More generally, real
structures are taken to be the bearers of semantic properties that can in principle
be associated with surface structures. Therefore, assuming that logical form is
determined by real structure, there is an important sense in which logical form may
be not visible in surface structure.
Finally, consider (OC3). In this case the claim is no longer accepted. But we saw
that (OC3) may be replaced by a very similar claim, namely, that the logical form of
a sentence is exhibited in a logically perfect* language. As explained in Sect. 3.1, a
logically perfect* language is such that, in every model, every sentence has deﬁnite
truth conditions that are determined by its semantic structure and reﬂected in its
syntactic structure.
In addition to the three claims considered, there is another claim about logical
form that is currently accepted as basic, due to the inﬂuence of the works considered
in Sects. 3.2 and 3.3. It is the claim that the meaning of a sentence depends on its
logical form. If one assumes that meaning is a function of semantic structure, in
accordance with (PC), and postulates a systematic connection between semantic
structure and logical form, one will be inclined to think that the logical form of
a sentence plays a crucial role in the determination of its meaning. Of course, the
claim that the meaning of a sentence depends on its logical form is not entirely new.
As we saw in Sect. 3.2, Frege’s analysis of sentences in terms of function-argument
structure relies on (PC). But this claim acquires a key importance when it becomes
part of a systematic study of the semantics of natural language.
Thus, the resulting conception of logical form may be stated as follows:
(CC1)
Logical properties depend on logical form.
(CC2)
Meaning depends on logical form.
(CC3)
Logical form may not be visible in surface structure.
(CC4)
Logical form is exhibited in a logically perfect* language.

36
3
Formal Languages and Natural Languages
The conjunction of (CC1)–(CC4), which may be called the current conception of
logical form, is the view that is most widely accepted nowadays. Since (CC2)
is rooted in Frege’s work, and (CC4) is very close to (OC3), this view does not
substantially differ from the old conception of logical form. Rather, it may be
regarded as the latest version of that conception.
A well known example of logical analysis framed within the current conception
of logical form is Davidson’s theory of action sentences. Consider the following
sentences:
(5) John buttered the toast in the bathroom at midnight
(6) John buttered the toast in the bathroom
(7) John buttered the toast at midnight
(8) John buttered the toast
It is evident that (5) entails (6)–(8). But it is not obvious how this entailment can
formally be explained, as the surface structure of (5)–(8) does not help much in
this respect. On the one hand, if ‘buttered in the bathroom at midnight’ in (5) is
represented as a two-place predicate that applies to John and the toast, then a similar
treatment must be given of (6)–(8), with the result that ‘buttered in the bathroom’,
‘buttered at midnight’ and ‘buttered’ are to be represented as different two-place
predicates. On the other, if ‘buttered’ in (5) is represented as a four-place predicate
that applies to John, the toast, the bathroom and midnight, then ‘buttered’ in (6)
and ‘buttered’ in (7) are to be represented as distinct three-place predicates, and
‘buttered’ in (8) is to be represented as a two-place predicate. In both cases, no
formal explanation is provided of the entailment from (5) to (6)–(8). According to
Davidson, this problem can be solved only if it is recognized that the logical form
of (5)–(8) is more complex than it appears. His suggestion is that sentences about
actions are to be understood in terms of quantiﬁcation over events. Thus, (5)–(8)
may be paraphrased as follows:
(9) There is an event x such that x is a buttering of the toast by John and x occurs
in the bathroom and x occurs at midnight
(10) There is an event x such that x is a buttering of the toast by John and x occurs
in the bathroom
(11) There is an event x such that x is a buttering of the toast by John and x occurs
at midnight
(12) There is an event x such that x is a buttering of the toast by John
It is easy to see that (9) entails (10)–(12), and that this entailment can formally be
represented in L.8
As this example shows, the current conception has much in common with the
old conception, in that it supports the same kind of paraphrase. Davidson’s theory
8Davidson (1967). Note that although it is plausible to assume that the inference from (5) to (6)–(8)
is formally valid, that assumption doesn’t single out Davidson’s account of logical form uniquely.
There may be alternative explanations that are no less formal.

3.5
Two Open Questions
37
of action sentences is similar to Russell’s theory of descriptions insofar as it implies
that some problems concerning action sentences can be solved if the content of such
sentences is elucidated by means of a paraphrase that exhibits a quantiﬁcational
structure that is hidden at the level of surface grammar. In this respect, the difference
between the old conception and the current conception is immaterial.9
3.5
Two Open Questions
The current conception of logical form is a cluster of claims, which leaves many
questions unsettled. This book mainly focuses on two of them. The ﬁrst question
concerns the individuation of logical form. If a sentence s can rightfully be said to
have a logical form f, then there must be some fact in virtue of which s has f, that
is, some fact that constitutes grounds for the ascription of f to s. So it may be asked
what kind of fact it is. In other words, the question is what it means for s to have f,
or equivalently, what it is for f to be the logical form of s.
Suppose that s is uttered by a certain speaker in a certain context. Then different
kinds of properties may be ascribed to s: a real structure, a meaning, a content
expressed, and so on. Some of these properties are intrinsic properties of s, in that
they are invariant properties that s possesses independently of how it is used in
this or that context, whereas others are extrinsic properties of s, in that they may
depend on how s is used in this or that context. Therefore, one way to address the
question of the individuation of logical form is to ask whether the logical form of
s is determined by intrinsic properties of s, or whether it is determined instead by
extrinsic properties of s.
The second question concerns the theoretical role of logical form. If f is ascribed
to s, that must be because it is assumed that the ascription of f to s can serve as part
of a theory that is able to explain some facts. Therefore, we may ask what kind of
theory it is, and what kind of facts it is able to explain. In other words, the question
is what is the point of ascribing f to s.
From the historical survey provided it turns out that two major theoretical roles
have been regarded as constitutive of a notion of logical form. The ﬁrst, which
goes back to the origin of logic, may be called the logical role, as it concerns
the formal explanation of logical properties and logical relations, such as validity
or contradiction. In this case the assumption is that a logical property or a logical
relation is formally explained if its obtaining or not in a given case is deduced from
some formal principle that applies to that case in virtue of the logical form of the
sentences involved. The second, which was initially articulated by Frege and became
central in the formal approach to natural language, may be called the semantic role,
in that it concerns the formulation of a compositional theory of meaning. In this case
the assumption is that an adequate theory of meaning must explain how the meaning
9Davidson defends his view of logical form in Davidson (1970).

38
3
Formal Languages and Natural Languages
of a sentence can be obtained by composition from the meanings of its constituent
expressions in virtue of its logical form. The two roles are clearly distinct, as is
shown by the fact that they underlie different claims about logical form, (CC1)
and (CC2). One thing is to provide a formal explanation of the logical properties
and relations involving certain sets of sentences, another thing is to provide a
compositional semantics that accounts for the meaning of those sentences.
Of course, the logical role and the semantic role are not the only ones. There
have been other motivations for developing a notion of logical form. But those
motivations are intimately connected with the logical role or with the semantic
role. At least two cases deserve to be mentioned. First, think about Quine’s thesis
that logical form reveals ontological commitment. This thesis heavily relies on the
logical role, in that it takes for granted that logical forms are ascribed to sentences
in accordance with the methods of logic. According to Quine, a theory’s ontological
commitments are to be judged by ﬁrst regimenting it into a ﬁrst order language and
then seeing what must exist for the existential quantiﬁcations to be true. Second,
think about the claim that logical form provides guidance to the psychological
mechanisms of language processing, which underlies Discourse Representation
Theory. This claim is closely related to the semantic role, in that it implies that
the ascription of formal representations to sentences is part of a systematic account
of the semantics of natural language.10
This book is intended to elucidate the relation between the question of the
individuation of logical form and the question of the theoretical role of logical form.
More speciﬁcally, in the next three chapters it will be argued that the ﬁrst question
crucially depends on the second, in that different theoretical roles require different
criteria of individuation. As will be suggested, a clear understanding of this relation
may shed light on some important issues that concern the relation between logic and
language.
10For the ﬁrst idea, the locus classicus is Quine (1948). For the second, see Kamp (2015),
where Discourse Representation Theory is presented as a theory that makes claims about the
psychological relevance of the forms in which language users compute and represent the semantic
content of sentences.

Chapter 4
Logical Form and Syntactic Structure
Abstract Two distinct theoretical roles may be regarded as constitutive of a notion
of logical form, the logical role and the semantic role. Therefore, one may ask
whether a single notion can fulﬁl both roles. Most of those who accept the current
conception of logical form seem to take for granted that the answer to this question
is afﬁrmative, namely, that there is a unique notion of logical form that fulﬁls both
roles. Their conﬁdence in the existence of such a notion rests on a widely accepted
view that will be outlined and criticized in this chapter, the view that logical form is
determined by intrinsic properties of sentences.
4.1
The Uniqueness Thesis
The following thesis, the uniqueness thesis, is commonly taken for granted:
(UT)
There is a unique notion of logical form that fulﬁls both the logical role and
the semantic role.
(UT) is a very general thesis, in that it does not say anything speciﬁc about the
notion itself. All that it says is that there is exactly one such notion. Nonetheless it is
a substantive thesis, at least in the obvious sense that its negation is consistent with
each of the claims that constitute the current conception of logical form:
(CC1)
Logical properties depend on logical form.
(CC2)
Meaning depends on logical form.
(CC3)
Logical form may not be visible in surface structure.
(CC4)
Logical form is exhibited in a perspicuous language.
In order for each of these claims to be true, each one must be true in virtue of some
notion of logical form. But this is consistent with there being no notion of logical
form that makes them all true, or with there being more than one such notion. Here
the focus will be on the existence condition, so the second possibility will not be
considered. More precisely, the question that will be addressed is whether there is
a notion of logical form that veriﬁes both (CC1) and (CC2). To deny that there is
such a notion is to say that the current conception of logical form is unstable, in that
(CC1)–(CC4) are not univocally true.
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_4
39

40
4
Logical Form and Syntactic Structure
As it turns out from Sect. 3.5, there are basically two ways in which logical form
may be individuated: either one assumes that logical form is determined by intrinsic
properties of sentences, or one assumes that logical form is determined by extrinsic
properties of sentences. Therefore, if (UT) is true, then either it is true in virtue of
some intrinsicalist notion of logical form, that is, some notion based on a criterion
of the ﬁrst kind, or it is true in virtue of some extrinsicalist notion of logical form,
that is, some notion based on a criterion of the second kind.
Of course, this is not to say that whoever endorses (UT) has a deﬁnite position
on the question of individuation. Although it is very likely that Frege, Russell, and
Wittgenstein endorsed (UT), no deﬁnite position on that question can rightfully be
ascribed to them. The same goes for many other philosophers who came after them.
More generally, one may think that (UT) is true without having a deﬁnite position
on the question of individuation, as long as one assumes that some notion of logical
form makes it true.
Yet the question is there, whether we answer it or not. To see its relevance, think
about sentences containing context-sensitive expressions, which provide a clear
illustration of the contrast between intrinsic and extrinsic properties. Consider again
the following sentence:
(1) Tom is there
Suppose that (UT) is true. Then the notion of logical form that makes it true must
involve some criterion of individuation. One option is to assume that the formal
representation of (1) depends on intrinsic features of (1), another is to assume that
it depends on extrinsic features of (1). In the ﬁrst case we get that the formal
representation of (1) does not vary from context to context, while in the second
we get that – at least in some sense – (1) may be represented in different ways
in different contexts. The difference between these two options cannot be ignored.
Presumably, Frege, Russell, and Wittgenstein did not provide clear indications in
this sense because they never engaged in a thorough reﬂection on the relation
between logical form and context sensitivity.
This chapter investigates the hypothesis that (UT) is true in virtue of some
intrinsicalist notion of logical form, which is by far the most common hypothesis
among those who endorse (UT). First, it will be explained how an intrinsicalist
notion of logical form can be understood. Then it will be argued that, contrary
to what is usually thought, such a notion is not ideal for the purpose of formal
explanation.
4.2
Intrinsicalism
The view that is usually taken to substantiate (UT) – intrinsicalism – is the view that
logical form is determined by intrinsic properties of sentences:
(I) There is a unique intrinsicalist notion of logical form that fulﬁls both the logical
role and the semantic role.

4.2
Intrinsicalism
41
Obviously, (I) entails (UT). Instead, (UT) does not entail (I), for (UT) does not say
anything speciﬁc about the individuation of logical form. The use of ‘determined’
– here and in what follows – is loose to some extent. To say that logical form is
determined by a property of a certain kind is to say that the ascription of logical
form to a sentence is grounded on the fact that the sentence has a property of that
kind. This does not entail that two sentences have the same logical form if and
only if they have exactly the same property of that kind. Determination is not to be
understood in terms of necessary and sufﬁcient conditions.
The most natural way to make sense of (I) is to assume that the intrinsic
properties involved in determining logical form are syntactic properties. In this
case the view is that logical form is determined by syntactic structure, where
syntactic structure is understood as real structure, as distinct from surface structure.
Accordingly, (UT) is taken to be true in virtue of what may be called the syntactic
notion. The syntactic notion is obviously an intrinsicalist notion.
Note that, if syntactic structure is understood as real structure, as distinct from
surface structure, then there is no one-to-one correspondence between sentences
and syntactic structures, because ambiguous sentences are described as surface
structures that can be associated with different real structures, as explained in
Sect. 3.4. However, the case of ambiguity may be ignored for present purposes. In
what follows we will restrict attention to nonambiguous sentences, so the claim to be
considered is that the logical form of a sentence is determined by its real structure.
The ﬁrst clear advocacy of the view that logical form is determined by syntactic
structure is due to Montague. According to Montague, the formal translation of
a sentence, which is derivable from the real structure of the sentence, serves two
purposes at once. On the one hand, it features as part of a compositional theory of
meaning for a fragment of the language to which the sentence belongs. On the other,
it explains the logical relations between the sentences of the fragment. As a matter
of fact, Montague did not distinguish between these two purposes:
The basic aim of semantics is to characterize the notions of a true sentence (under a given
interpretation) and of entailment, while that of syntax is to characterize the various syntactic
categories, especially the set of declarative sentences.1
After Montague, the view that logical form is determined by syntactic structure
has been taken for granted by all who have adopted the formal approach. In
particular, it has been taken for granted by Lewis and Kaplan as part of their
account of indexicals and demonstratives. On that account, contexts are represented
as indices, so the fact that the same sentence may express different contents in
different contexts is described by saying that the same sentence may have different
truth values relative to different indices. But relativity to indices do not affect logical
form. Lewis and Kaplan, following Montague, assume that the logical form of a
sentence that contains indexicals or demonstratives is determined by its syntactic
structure. Thus, (1) has a ﬁxed logical form, even though it expresses different
contents in different contexts.
1Montague (1970), p. 223, fn 2.

42
4
Logical Form and Syntactic Structure
Although it is now widely recognized that indexicals and demonstratives are
paradigmatic context-sensitive expressions, and that they can be handled in the way
suggested by Lewis and Kaplan, it is generally believed that the class of context-
sensitive expressions is much wider. Since there is no agreement on how to deal
with most of these expressions, context sensitivity is still an open issue. However,
the underlying view of logical form has not changed. Most of those who are
currently interested in context sensitivity, independently of whether they adopt the
formal approach, are inclined to think that logical form is determined by syntactic
structure.
4.3
LF
We have seen that, as far as determination of logical form is concerned, syntactic
structure is understood as real structure, as opposed to surface structure. The
term ‘real’, however, does not belong to the technical vocabulary of linguistics.
A more ﬁtting term is ‘Logical Form’, abbreviated ‘LF’. The use of this term
stems from the conviction that the derivation of a syntactic structure that displays
the logical properties of a sentence is continuous with the derivation of other
syntactic representations of the sentence. As this idea was developed initially by
Chomsky and May, the levels of syntactic representation included Deep Structure
(DS), Surface Structure (SS) and Logical Form (LF), with LF derived from SS by
the same sorts of transformational rules that derived SS from DS. The role and
signiﬁcance of DS then changed in various ways as Chomsky developed his theory,
and in his most recent works DS no longer features at all.2
Within current linguistic theories, LF is understood as a syntactic representation
that differs from surface structure and is the primary object of interpretation. To
illustrate, consider the following sentences:
(2) Every kid loves Spider Man
(3) Bob loves a superhero
(4) Every kid loves a superhero
The LF of (2) may be stated as follows:
(5) [every kid1Œt1 loves Spider Man]]
The square brackets in (5) are phrase markers, which indicate that (2) is formed by
combining the noun phrase ‘every kid’ with the verb phrase ‘loves Spider Man’.
The letter t indicates a “trace”, which is postulated because ‘every kid’ contains the
quantiﬁer expression ‘every’. The expression ‘t1 loves Spider Man’ is like an open
formula, falling in the scope ‘Every kid1’. The case of (3) is different:
2Harman (1970) initially argued for the logical relevance of DS. The notion of LF emerged in
Chomsky (1976) and May (1977), and was then elaborated in May (1985). The abandonment of
DS in favour of LF is marked by Chomsky (1995).

4.3
LF
43
(6) [a superhero1[Bob loves t1]]
In this case the expression ‘a superhero’ occurs in a position that is not that which
it occupies in the surface structure. This difference is explained as the effect of a
movement that holds for quantiﬁers expressions in general, but that is not visible in
the step from (2) to (5). Finally, (4) is structurally ambiguous, so two distinct LFs
may be associated with it,
(7) [every kid1[a superhero2[t1 loves t2]]]
(8) [a superhero2[every kid1[t1 loves t2]]]
(7) says that, for every kid x, there is a superhero y such that x loves y, whereas (8)
says that there is a superhero x such that, for every kid y, y loves x.
As these examples show, the syntactic representation that linguists call LF is not
a logical form in the traditional sense, that is, it is not a logical form in the sense
of ‘logical form’ that emerges from the historical survey provided in Chaps. 1, 2
and 3. The most striking difference is that a logical form in the traditional sense is
something that we express by means of a formula of a formal language. Therefore,
‘LF’ is not synonymous with ‘logical form’ as it has been used so far.
One might be tempted to say that what characterizes LF as distinct from logical
form is that LF is “descriptive” rather than “revisionary”. Stanley draws a distinction
along these lines:
Perhaps the most prevalent tradition of usage of the expression “logical form” in philosophy
is to express what one might call the revisionary conception of logical form. According to
the revisionary conception, natural language is defective in some fundamental way. Appeals
to logical form are appeals to a kind of linguistic representation which is intended to
replace natural language for the purposes of scientiﬁc or mathematical investigation. [...]
According to the second tradition of usage, which one might call the descriptive conception
of logical form, the logical form of a sentence is something like the ‘real structure’ of that
sentence. [...] On this approach, we may discover that the ‘real’ structure of a natural
language sentence is quite distinct from its surface grammatical form. Talk of logical
form in this sense involves attributing hidden complexity to sentences of natural language,
complexity which is ultimately revealed by empirical enquiry.3
However, this temptation must be resisted. First, it would be misleading to call
LF descriptive and logical form revisionary, because logical form is essentially
descriptive, or so it may be argued. Consider Russell’s theory of descriptions,
which should count as a paradigmatic example of revisionism. According to that
theory, the logical form of the judgement expressed by a sentence that contains
a deﬁnite description is “real”, it is something that we “discover”, it is quite
distinct from the “surface grammatical form” of the sentence, and it involves
attributing “hidden complexity” to the sentence. So it seems that being descriptive
cannot be the distinctive feature of LF. Rather, the crucial point seems to be that
the kind of considerations that Russell takes to justify his theory of descriptions
substantially differs from the kind of considerations that are normally invoked to
3Stanley (2000), pp. 391–392.

44
4
Logical Form and Syntactic Structure
justify ascriptions of LF. One thing is to solve philosophical puzzles, quite another
thing is to provide an empirically grounded explanation of linguistic data.4
Second, even if one adopts a purely linguistic perspective, and assumes that
“philosophical” considerations such as those invoked by Russell should be left aside,
one may still think that a distinction must be drawn between logical form and LF. In
a purely linguistic perspective, the logical properties of a sentence s may be speciﬁed
in at least two ways. One is to derive them directly from a LF associated with s, the
other is to derive them from a representation of that LF in a suitable formal language.
Since there may be independent reasons to prefer the second option to the ﬁrst, one
may coherently talk of logical form as a formal representation of LF.5
In any case, all that matters for the understanding of the syntactic notion
suggested here is that LF and logical form are not obviously the same thing.
Assuming that some principled distinction can be drawn between LF and logical
form, from now on it will be taken for granted that a natural construal of (I) is the
claim that logical form is determined by LF.6
4.4
Semantic Structure
Although the claim that logical form is determined by LF is a natural construal of
(I), it is not the only construal of (I). As we saw in Sect. 3.2, Davidson suggests that
the logical form of a sentence is the result of doing to the sentence what is necessary
to produce something accessible to a systematic semantic theory. He thinks that
accessibility to such theory is intimately connected with inference, as is shown by
the case of action sentences:
[...] we will have a deep explanation of why one sentence entails the other, an explanation
that draws on a systematic account of how the meaning of each sentence is a function of its
structure.7
Since the theorems of the theory that Davidson has in mind are Tarskian bicondi-
tionals, the intended relation between a sentence s and its logical form l seems to be
the following: l is the logical form of s if and only if s is preliminarily translated as
l and then the theory includes as a theorem a Tarskian biconditional that contains l.
This account of logical form is clearly intrinsicalist, in that it takes l to be an intrinsic
property of s.
4This is not to deny that an explanation of the latter kind may involve metaphysically loaded
assumptions. As Marconi (2006) suggests, we often ﬁnd such assumptions within the formal
approach.
5The advantages of the second option are particularly clear if LF is understood as a “functional
skeleton”, that is, if it is taken to be radically underspeciﬁed with respect to the content of its lexical
material, as in Chierchia (2013). In that case, it is reasonable to say that logical form pertains to a
different level of representation where the relations of identity or difference between lexical items
are recovered.
6This is the construal of (I) advocated, among others, in Neale (1993), Stanley (2000) and Borg
(2007).
7Davidson (1970), p. 144.

4.4
Semantic Structure
45
Among the authors that belong to the intrinsicalist cloud, many work within
a broadly Davidsonian perspective. For example, Lycan outlines an account of
meaning which seems to imply a non-syntactic reading of (I). Similarly, Lepore
and Ludwig claim that the logical form of a sentence is its “semantic form”, as
revealed in a compositional theory of meaning. Moreover, some works in event-
based semantics, such as those by Parsons and Pietroski, suggest that the same
notion of logical form that can provide an elegant compositional semantics for
various natural language constructions can also provide a formal explanation of the
validity of inferences such as those considered in Sect. 3.4.8
Davidson’s account of logical form may engender some perplexities. First, even
assuming that s is paraphrased into l and that a theory of truth provides a correct
semantic account of l, it is not entirely obvious why that account must apply to
s as well. After all, l may signiﬁcantly differ from s, as it happens in the case of
action sentences. Even granting that s and l are equivalent, in the sense that they
are true in the same circumstances, a claim of logical form of the kind suggested
by Davidson seems to require more than equivalence. For such a claim to hold it
should be possible to specify a relation between s and l that allows for the difference
between s and l but guarantees that a correct semantic account of l is thereby a
correct semantic account of s.9
Second, if l is a paraphrase of s, it is not a logical form in the traditional sense. But
it is hard to see how the inferences involving s can be explained in terms of principles
of ﬁrst order logic, as Davidson wants, unless a form in that sense is postulated. A
principle of ﬁrst order logic is a formal schema constituted by formulas of a formal
language, rather than a set of logical forms in Davidson’s sense. So it seems that a
full account of the logical properties of s requires that two logical forms l and l0 are
ascribed to s: l is a logical form in Davidson’s sense, while l0 is a logical form in the
traditional sense. Since l0 is a formal representation of l, it remains to be said how
exactly it relates to l.
Although these perplexities deserve serious consideration, we will leave them
aside. The details of Davidson’s account of logical form are irrelevant for our
purposes, because that account will be contemplated only insofar as it yields
a version of (I). Assuming that ‘semantic structure’ refers to logical form in
Davidson’s sense, and that the latter is susceptible of formal representation in the
traditional sense, the version of (I) to be considered is the claim that logical form is
determined by semantic structure.
Note that (I) may be endorsed even if no such connection is postulated between
logical form and semantic structure. According to Evans, logical form and semantic
structure are distinct properties, in that they may be deﬁned in different ways and
8Lycan (1986), Lepore and Ludwig (2002), Parsons (1990) and Pietroski (2005). The semantic
view of logical form defended in García-Carpintero (2004) may also be understood as a non-
syntactic construal of (I).
9This objection was initially raised in Cargile (1970), pp. 137–138, and then developed in
Sainsbury (2008), section 2.6.

46
4
Logical Form and Syntactic Structure
they account for different kinds of inferences. Nonetheless, he treats logical form
as an intrinsic property of sentences, which depends on the logical expressions that
occur in them.10
More generally, any view according to which logical form is determined by
intrinsic properties of sentences – syntactic or semantic – may be classiﬁed as
a version of intrinsicalism. Since the differences between the various versions of
intrinsicalism are not relevant for our purposes, we will simply talk of (I) without
further distinctions.
4.5
Relationality in Formal Explanation
Now (I) will be questioned on the basis of considerations concerning the formaliza-
tion of context-sensitive sentences. The case against (I) will be built by drawing
attention to some points about formalization and context sensitivity that seem
independently justiﬁed. None of these points, taken individually, is new or original.
On the contrary, they are mostly well known facts. The interest of the material that
will be presented lies rather in the way these points are spelled out and brought
together.
The problem that arises in connection with (I) may be stated as follows. If logical
form is determined by intrinsic properties of sentences, then every sentence has
its own logical form, independently of the content it expresses. That is, for every
sentence s, the formula that expresses the logical form of s is ﬁxed by s itself.
However, as we shall see, formal explanation requires that the formal representation
of sentences is relational, in that the formula assigned to a sentence s does not
depend simply on s itself but also on the semantic relations that s bears to other
sentences in virtue of the content it expresses. Therefore, an intrinsicalist notion of
logical form is not ideal for the purpose of formal explanation.11
To illustrate the point about relationality, let us start with some cases that can be
handled easily with an intrinsicalist notion of logical form. In what follows it will
be assumed that L is the language in which logical forms are exhibited. This is a
harmless assumption, as the point does not essentially depend on it.
Case 1. Consider the following argument:
[A]
(9) Plato is different from Aristotle
(10) There are at least two things
10Evans (1976). The notion of semantic structure introduced in Sect. 2.4 is in line with Evans’
deﬁnition.
11Szabó (2012) argues against a view that may be identiﬁed with (I), the view that “logical form
is an objective feature of a sentence and captures its logical character” (p. 105), on the basis of
considerations that are to a large extent independent of those provided here.

4.5
Relationality in Formal Explanation
47
There is a clear sense in which [A] is valid, namely, that in which it is impossible
that its premise is true and its conclusion is false. One obvious way to account for
this fact is to say that [A] has the following form:
[B]
(11) a ¤ b
(12) 9x9yx ¤ y
Since [B] is a valid form, given that (12) is a logical consequence of (11), the
apparent validity of [A] is formally explained.
Case 2. Consider the following argument:
[C]
(13) Plato is a philosopher
(14) Aristotle is a philosopher
There is a clear sense in which [C] is invalid, namely, that in which it is possible
that its premise is true and its conclusion is false. One obvious way to account for
this fact is to say that [C] has the following form:
[D]
(15) Fa
(16) Fb
Since [D] is not a valid form, given that there are models in which (15) is true and
(16) is false, the apparent invalidity of [C] is formally explained.12
Case 3. Consider the following sentences:
(17) Plato is a philosopher
(18) Plato is not a philosopher
If I utter (17) and you utter (18), there is a clear sense in which we are contradicting
each other, that is, the things we say cannot both be true, or both be false. One
obvious way to account for this fact is to represent (17) and (18) as Fa and Fa.
Since Fa and Fa are contradictory formulas, the apparent contradiction is formally
explained.
Case 4. Consider the following sentence
(19) Aristotle is not a philosopher
If I utter (17) and you utter (19), there is a clear sense in which we are not
contradicting each other, that is, the things we say can both be true, or both be
false. One obvious way to account for this fact is to represent (17) and (19) as Fa
and Fb. Since Fa and Fb are not contradictory formulas, the apparent lack of
contradiction is formally explained.
12As is well known, the fact that an argument instantiates an invalid form as represented in a given
formal language does not count as proof of its invalidity, because that language might be unable
to capture the structural properties of the argument that determine its validity. But for present
purposes we can leave this issue aside. In the case of [C] that possibility does not arise, and the
same goes for the other cases of invalidity that will be considered.

48
4
Logical Form and Syntactic Structure
The formal explanations provided in cases 1–4 are consistent with the assumption
that the logical form of the relevant sentences depends on their intrinsic properties.
For example, in case 1 it may be claimed that (9) and (10) are adequately formalized
as (11) and (12) because they have a certain syntactic structure. However, this kind
of convergence does not always hold. There are cases in which an intrinsicalist
notion of logical form is in contrast with the purpose of formal explanation. Here
are some such cases.
Case 5. Consider the following argument:
[E]
(20) This is different from this
(10) There are at least two things
Imagine that I utter [E] pointing my ﬁnger at Plato as I say ‘this’ the ﬁrst time
and at Aristotle as I say ‘this’ the second time. [E] seems valid when understood
in this way, and it is quite plausible to expect that its validity can be derived from
a structural analogy with [A]. But in order to represent [E] as structurally similar
to [A] – that is, in order to formalize [E] as [B] – (20) should be represented as
a ¤ b, which cannot be done if an intrinsicalist notion of logical form is adopted.
According to such a notion, the formal representation of (20) cannot depend on the
reference of ‘this’. Any individual constant that stands for ‘this’ must occur twice
in the formula that represents (20).
Case 6. Consider the following argument:
[F]
(21) This is a philosopher
(21) This is a philosopher
Imagine that I utter [F] while pointing my ﬁnger at Plato as I say ‘this’ the ﬁrst time
and at Aristotle as I say ‘this’ the second time. There is a clear sense in which [F] is
invalid when understood in this way, namely, the same sense in which [C] is invalid.
However, if the logical form of (21) depends only on its intrinsic properties, then [F]
cannot formalized as [D], for both occurrences of (21) must be represented by the
same formula. That is, if a stands for ‘this’, [F] must be formalized as follows:
[G]
(15) Fa
(15) Fa
Case 7. Consider the following sentences:
(22) I’m a philosopher
(23) You are not a philosopher
Imagine that I utter (22) and that you utter (23) pointing at me. There is a clear
sense in which we are contradicting each other, that is, the same sense in which
we are contradicting each other in case 3. But if the logical form of (22) and (23)
depends on their intrinsic properties, the formula assigned to (23) cannot be the
negation of the formula assigned to (22). If the formula assigned to (22) is Fa, then
the one assigned to (23) is the negation of a formula Fb that represents ‘You are a
philosopher’. So (22) and (23) are represented as Fa and Fb, which means that the
apparent contradiction is not formally explained.

4.5
Relationality in Formal Explanation
49
Case 8. Consider the following sentence:
(24) I’m not a philosopher
Imagine that I utter (22) and you utter (24). There is a clear sense in which we are not
contradicting each other, that is, the same sense in which we are not contradicting
each other in case 4. But if the logical form of (22) and (24) depends on their
intrinsic properties, then the formula assigned to (24) must be the negation of
the formula assigned to (22). For example, if Fa stands for (22), then (24) must
be represented as Fa. So the apparent absence of contradiction is not formally
explained.
As cases 5–8 show, formal explanation requires that the formula assigned to a
sentence s provides a representation of the content expressed by s which exhibits
the semantic relations that s bears to other sentences. Consider case 5. In order to
account for the apparent entailment, the formal representation of [E] must exhibit a
semantic relation between the content of (20) and the content of (10) that is captured
if (20) is rendered as a ¤ b. But such representation is not derivable from the
intrinsic properties of (20) and (10). The reason why different individual constants
a and b are assigned to the two occurrences of ‘this’ in (20) is that those occurrences
refer to different things. Now consider case 6. In order to account for the apparent
lack of entailment, the formal representation of [F] must exhibit a semantic relation
between the contents of the two occurrences of (21) that is captured if the ﬁrst is
rendered as Fa and the second is rendered as Fb. But what justiﬁes the assignment
of a in the ﬁrst case and b in the second is that ‘this’ refers to different things.
This is not something that can be detected from (21) itself. No analysis of the
intrinsic properties of (21) can justify the conclusion that the individual constant
to be assigned in the second case must differ from a. Similar considerations hold for
cases 7 and 8.
What has been said about cases 5–8 may easily be generalized. Cases 5–8 involve
indexicals or demonstratives, but similar examples may be provided with other kinds
of context-sensitive expressions. Consider the following sentences:
(25) All philosophers are rich
(26) Not all philosophers are rich
Imagine that you utter (25) to assert that all philosophers in the university U are
rich, while I utter (26) to assert that some philosophers in the university U0 are not
rich. As in case 8, there is an obvious sense in which we are not contradicting each
other. But if the formal representation of (25) and (26) does not take into account
the content they express, then the apparent absence of contradiction is not formally
explained, for the formula assigned to (26) must be the negation of that assigned
to (25). More generally, for any set of sentences  in which some context-sensitive
expression occur, in order to provide a formal explanation of the logical properties
and relations in , the formal representation of  must display the semantic relations
between the contents expressed by the sentences in . This cannot be done if an
intrinsicalist notion of logical form is adopted.

50
4
Logical Form and Syntactic Structure
4.6
Further Clariﬁcations
Some ﬁnal notes will help to elucidate the point about relationality. First, even
though there might be reasons to assume that context-sensitive expressions are
indexed at the level of syntactic structure, such assumption would not solve the
problem raised in connection with cases 5–8. The appeal to indexed syntactic items
could be motivated either by syntactic considerations or by semantic considerations.
One thing is to say that the syntactic structure of (20) includes two distinct items
‘this1’ and ‘this2’ because (20) includes two distinct occurrences of ‘this’, another
thing is to say that the syntactic structure of (20) includes two distinct items ‘this1’
and ‘this2’ because the two occurrences of ‘this’ refer to different objects. The
ﬁrst option would not solve the problem because the indexed structure postulated
would still be an intrinsic property of the sentence. If one assumes that (20) is to
represented as a ¤ b owing to the fact that it includes two occurrences of ‘this’, one
will not be able to explain the difference between case 5 and a different case in which
(20) is correctly represented as a ¤ a, that is, a case in which the two occurrences of
‘this’ refer to the same individual. The second option would not solve the problem
for the opposite reason. Arguably, if one wants to provide a general treatment of
context sensitivity in terms of indexed structures based on semantic considerations,
one will end up holding a radical view according to which context sensitivity reduces
to some nonstandard form of ambiguity, so that every difference of truth conditions
due to context sensitivity can be described in terms of a difference of syntactic
structure. Thus, one will claim that there is a distinct lexical item for each referent
of ‘this’, and so that inﬁnitely many syntactic structures can be associated to (20).
But that view could not be invoked to defend (I), as it implies that syntactic structure
in the relevant sense is not an intrinsic property of a sentence.13
Second, the point about relationality does not boil down to the usual point
that the real bearers of logical properties and the real terms of logical relations
are propositions rather than sentences. That point by itself does not entail a
formalization of the kind suggested. Suppose that in case 6 two distinct propositions
p1 and p2 are expressed by the two occurrences of (21). If logical forms are
understood as properties of propositions individuated in terms of some structural
feature that p1 and p2 share, such as being about an object that satisﬁes a condition,
and this feature is expressed by a given formula, then both occurrences of (21) are
represented by that formula. This is to say that it is consistent with the claim that
propositions are the bearers of logical properties and the terms of logical relations
to represent [F] as [G].
Third, the explanatory shortcoming illustrated by cases 5–8 arises not only if it
is supposed that the logical form of a sentence is expressed by a single formula, but
also if it is supposed, for some set of formulas, that the logical form of the sentence
is expressed by any member of the set, or by the set itself. As long as the semantic
13Gauker (2014) outlines a view of this kind.

4.6
Further Clariﬁcations
51
relations between the contents expressed by the relevant set of sentences are not
taken into account, there is no intelligible way to justify an appropriate choice of
members of the set. Take case 6 again. Even if the supposition is that the logical form
of (21) is expressed by a set of formulas fFa; Fb; : : :g, there is no way to justify an
assignment of different individual constants a and b to the two occurrences of (21).
No distinction can be drawn between [D] and [G] unless some semantic relation
between the two occurrences is taken into account.14
Finally, the point about relationality can hardly be dismissed by claiming that
cases 5–8 fall outside the domain of formal explanation. An advocate of (I) may
be tempted to reply as follows: certainly, an intrinsicalist notion of logical form
is unable to provide a formal explanation of some properties and relations that
are “broadly” logical, such as those involved in cases 5–8; but there is nothing
wrong with this, because we should not expect that all broadly logical properties and
relations are explained formally. What we should expect instead is that a restricted
class of properties and relations – call them “strictly” logical – are explained
formally, such as those involved in cases 1–4. Since an intrinsicalist notion of logical
form is able to handle cases of this kind, its logical signiﬁcance is not in question.
However, this reply is unsatisfactory for at least two reasons. One is that its
force is inversely proportional to the wideness of the class of cases that is taken
to fall outside the domain of formal explanation. Context sensitivity is a very
pervasive phenomenon. Its boundaries are so hard to demarcate that it is not even
uncontroversial that there are non-trivial cases of context insensitivity. Therefore, if
the class of cases that are taken to lack strict logicality is characterized in terms of
context sensitivity, then it is potentially unlimited. Obviously, one might be willing
to claim that context sensitivity affects only a very limited class of expressions. But
this would be a speciﬁc position within the debate on context sensitivity, for which
further arguments should be provided. Independently of the tenability of such a
position, it is sensible to assume that the issue of whether a certain notion of logical
form is suitable for the purpose of formal explanation should not depend on the
issue of which sentences are affected by context sensitivity.15
The other reason is that, even if a principled distinction were drawn between
cases involving context sensitivity and cases not involving context sensitivity, it
would not provide a good criterion for strict logicality, since at least some cases
involving context sensitivity can be handled with an intrinsicalist notion of logical
form. Consider the following argument:
14This is not quite the same thing as relationism about meaning, the view defended in Fine (2009).
According to Fine (2009), “the fact that two utterances say the same thing is not entirely a matter
of their intrinsic semantic features; it may also turn on semantic relationships among the utterances
or their parts which are not reducible to those features. We must, therefore, recognize that there
may be irreducible semantic relationships, ones not reducible to the intrinsic semantic features
of the expressions between which they hold” (p. 3). The individuation of the logical form of two
sentences may be relational even if their meaning is ﬁxed in some non-relational way.
15Borg (2007), pp. 62–73, openly defends (I) in combination with a view of context sensitivity of
the kind considered.

52
4
Logical Form and Syntactic Structure
[H]
(27) This is red
(28) Something is red
If [H] is represented as follows, the apparent validity of [H] is formally explained:
[I]
(29) Fa
(30) 9xFx
And it is easy to see that this formalization is compatible with the adoption of
an intrinsicalist notion of logical form, even though (27) contains a demonstrative.
Therefore, in order to defend (I), it should be maintained that some cases involving
context sensitivity deserve a formal explanation, whereas others do not. Still, it is
hard to see how such difference can be independently motivated.

Chapter 5
Logical Form and Truth Conditions
Abstract So far it has been argued that an intrinsicalist notion of logical form is
unable to explain some clear examples of logical properties and logical relations.
This is a reason to doubt intrinsicalism, yet it is not a decisive reason. Even if it were
granted that an intrinsicalist notion of logical form has a limited explanatory power,
it might still be contended that it is our best option, as no other notion can do better.
This chapter is intended to complete the case against intrinsicalism by showing that,
as far as the logical role is concerned, there is an intelligible extrinsicalist notion
of logical form that can do better, the truth-conditional notion. According to the
truth-conditional notion, logical form is determined by truth conditions.
5.1
The Truth-Conditional Notion
The understanding of truth conditions that underlies the truth-conditional notion can
be elucidated by means of three preliminary clariﬁcations. First, ‘truth conditions’
will not be used to refer to clauses by which a theory of meaning speciﬁes when
sentences are true, as suggested by Davidson. Truth conditions in the Davidsonian
sense are intrinsic properties of sentences that depend on their semantic structure.
Consider the following sentence:
(1) This is a philosopher
From the semantic structure of (1) it turns out that (1) is true in a context if and only
if the object demonstrated in the context has the property of being a philosopher.
But this is not the sense of ‘truth conditions’ that will be adopted here. As is
argued in Sect. 4.5, what matters to formal explanation is the content expressed
by a sentence rather than its semantic structure. The content expressed by (1) is
an extrinsic property of (1) that differs from its semantic structure. In the sense of
‘truth conditions’ that will be adopted here, to say that logical form is determined
by truth conditions is to say that sentences have logical form in virtue of the content
they express. As a ﬁrst approximation, the content expressed by a sentence is what
is said by uttering the sentence.
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_5
53

54
5
Logical Form and Truth Conditions
Second, truth conditions will not be understood as sets of possible worlds.
Sameness of content is hardly deﬁnable in terms of sameness of “modal proﬁle”, that
is, as truth in the same possible worlds. Sameness of modal proﬁle may be regarded
as a necessary condition for sameness of content, but it is clearly inadequate as a
sufﬁcient condition. This turns out clear if we consider logical equivalence, which
is a distinctive kind of sameness of modal proﬁle. While some pairs of logically
equivalent sentences may plausibly be taken to express the same content, others
clearly express different contents. Consider the following sentences:
(2) Plato is a philosopher and Aristotle is a philosopher
(3) Aristotle is a philosopher and Plato is a philosopher
It is plausible to hold that (2) and (3) say the same thing. By contrast, the following
sentences seem to say different things:
(4) Plato is a philosopher
(5) Either Plato is a philosopher, or Plato is a philosopher and Aristotle is a
philosopher
(4) is about Plato. Instead, (5) is about Plato and Aristotle, because it includes (2),
which is about Plato and Aristotle. Similarly, the following sentences seem to say
different things, in spite of the fact that they are both logically true:
(6) Either Plato is a philosopher or he is not
(7) Either Aristotle is a philosopher or he is not
(6) is about Plato, because it is formed by (4) and its negation, which are both about
Plato. Instead, (7) is about Aristotle, because it is formed by (8) and its negation,
which are both about Aristotle:
(8) Aristotle is a philosopher
Third, it will be assumed that truth conditions have something to do with
aboutness. As the examples (2)–(7) suggest, two necessarily equivalent sentences
express the same content only if they are about the same things. This is also clear
in the case of synonymy, which is a special case of necessary equivalence. If two
sentences are synonymous in virtue of simple grammatical transformations, as in
the example considered in Sect. 2.1, they are obviously about the same things:
(9) Aristotle admires Plato
(10) Plato is admired by Aristotle
Being about the same things may be regarded as a necessary condition for sameness
of content, even if it is not obvious that it is a sufﬁcient condition. Consider (4) and
the following sentence:
(11) The author of The Republic is a philosopher
(4) and (11) ascribe the same property to the same individual. But if Russell’s theory
of descriptions is right, they express different contents. Moreover, on the assumption
that sameness of modal proﬁle is necessary for sameness of content, (4) and (11)

5.2
Truth Conditions and Propositions
55
cannot have the same content, because they have different modal proﬁles. Note also
that a sentence and its negation are about the same things, but we don’t want to say
that they express the same content. For example, we don’t want to say that (4) and
its negation express the same content.
The three clariﬁcations just provided yield a very rough characterization of truth
conditions, in that they constrain truth conditions without settling the question of
what truth conditions are. As is well known, the pretheoretical notion of what is
said is irreducibly vague, and for our purposes it is not essential to make it precise
by specifying necessary and sufﬁcient conditions for sameness of truth conditions.
For example, intuitions can hardly provide a deﬁnite answer to the question whether
a sentence and its double negation say the same thing. But for our purposes it is
not essential to choose between the claim that a sentence and its double negation
express the same content and the claim that a sentence and its double negation
express different contents.
5.2
Truth Conditions and Propositions
In this section we ﬁll focus on two recently debated theory of propositions, to show
how the characterization of truth conditions just sketched can be substantiated by a
coherent account of content. Each of these two theories seems able to explain cases
of apparent sameness or difference of content such as those considered in Sect. 5.1.
Therefore, in both cases truth conditions can be identiﬁed with propositions,
assuming that two sentences have the same truth conditions if and only if they
express the same proposition.
Let us start with the naturalized propositions theory advocated by King. Accord-
ing to this theory, the proposition expressed by a sentence s in a context c is a
complex entity whose constituents – individuals, properties, and relations – are the
semantic values that the expressions occurring in s have in c. These constituents are
bound together by a relation, the “propositional relation”, which is deﬁned in terms
of the syntactic structure of s and the semantic relations that obtain between the
expressions occurring in s and their semantic values. For example, the proposition
expressed by (4) is a complex entity whose constituents, Plato and the property of
being a philosopher, are bound together by a relation that may stated as follows for
any x and y: for some context c, assignment g, and language L, there are two lexical
items a and b of L such that x is the semantic value of a relative to g and c, y is
the semantic value of b relative to g and c, a occurs at the left terminal node of the
sentential relation R that in L encodes ascription, and b occurs at R’s right terminal
node. It is in virtue of this propositional relation, which is interpreted by speakers as
ascribing the property of being a philosopher to Plato, that the proposition expressed
by (4) represents Plato as being a philosopher.1
1The theory is outlined in King (1995, 1996, 2007, 2013, 2014, 2016).

56
5
Logical Form and Truth Conditions
It is easy to see how the naturalized propositions theory explains the cases of
apparent difference of content considered in Sect. 5.1. The proposition expressed by
(1) in a context in which ‘this’ refers to Plato differs from the proposition expressed
by (1) in a context in which ‘this’ refers to Aristotle: the former contains Plato as
a constituent, whereas the latter contains Aristotle as a constituent. The proposition
expressed by (5) differs from the proposition expressed by (4) because it includes
additional constituents and additional relations. (6) and (7) express propositions that
have different constituents bound by different relations, and the same goes for (4)
and (11), and for (4) and its negation.
The explanation of the cases of apparent sameness of content considered in
Sect. 5 is less obvious, because it might seem that propositions are individuated too
ﬁnely. If we assume that the structure of the proposition expressed by a conjunction
is sensitive to the order of its conjuncts, we get that (2) and (3) express different
propositions. Similarly, if we assume that the structure of the proposition expressed
by a sentence is sensitive to its active or passive construction, we get that (9) and
(10) express different propositions. However, such assumptions are not essential
to the naturalized propositions theory. The propositional relation that characterizes
the proposition expressed by a sentence s in a context c can be deﬁned in at least
two ways: one option is to deﬁne it in terms of the syntactic structure of s, as
illustrated above; another option is to deﬁne it in terms of the syntactic structure of
some sentence which is like s as far as the ascription of the properties and relations
involved is concerned. That is, we may think of propositional relations as either
involving speciﬁc sentential relations, or as involving existential generalization over
sentential relations. In the second case (2) and (3) turn out to express the same
proposition, and the same goes for (9) and (10). So it is not obvious that propositions
are individuated too ﬁnely.2
Now let us consider the truthmaker theory advocated by Fine. According to this
theory, the proposition expressed by a sentence is a set of states, that is, possible
situations or fact-like entities that verify the sentence. As in the case of traditional
possible world semantics, the theory is extensional rather than structural, in that
propositions are deﬁned as sets of entities rather than as structured entities. But it
involves a more ﬁne-grained individuation of the set.3
2In King (2007, 2013) propositional relations are taken to involve speciﬁc sentential relations,
while in King (2014), p. 58, and King (2016) it is suggested that they can be deﬁned in terms
of existential generalization over sentential relations. Note that if one adopts the ﬁrst option, one
may still claim that propositions differ from truth conditions. Truth conditions could be deﬁned in
terms of some relation between propositions which is looser than identity but stricter than sameness
of modal proﬁle, assuming that two sentences have the same truth conditions if and only if they
express propositions that stand in that relation. In this case truth conditions would not be identiﬁed
with propositions, although they might still be equated with what is said. Thus, it is consistent with
the naturalized propositions theory to claim, as King (2007), pp. 101 and 767–768, that (2) and
(3) say the same thing, so they have the same truth conditions, even though they express different
propositions. Similar considerations hold for (9) and (10).
3The theory is outlined in Fine (2015a,b); Finems (2017). The deﬁnition of proposition suggested
here is not the only possible deﬁnition in the framework under consideration. Another way is to

5.2
Truth Conditions and Propositions
57
The truthmaker theory assumes that states stand in mereological relations to one
another. For any set of states S1; S2; S3 : : :, there is a state S1tS2tS3 : : : which is the
fusion of S1; S2; S3 : : : and has S1; S2; S3 : : : as parts. For example, given that there
are states of snow being white and of snow being cold, there is a state of snow being
white and cold, which is the fusion of them. To say that a state S veriﬁes a sentence
s is to say that S is relevant as a whole to the truth of s. This means that there is
no guarantee that any state that includes S as a part veriﬁes s as well. Conjunctions
and disjunctions are deﬁned in accordance with this notion of veriﬁcation. A state S
veriﬁes the conjunction of s1 and s2 if and only if S is a fusion S1 t S2 such that S1
and S2 respectively verify s1 and s2. Instead, S veriﬁes the disjunction of s1 and s2 if
and only if either S veriﬁes s1 or it veriﬁes s2.
If truth conditions are understood as truthmaking conditions, that is, if they are
identiﬁed with sets of states, then the examples considered in Sect. 5 can be handled
quite easily. The proposition expressed by (1) in a context in which ‘this’ refers to
Plato differs from the proposition expressed by (1) in a context in which ‘this’ refers
to Aristotle: the former contains states that include Plato or someone quite similar
to Plato, whereas the latter contains states that include Aristotle or someone quite
similar to Aristotle. (2) and (3) express the same proposition: if A is the proposition
expressed by (4) and B is the proposition expressed by (8), the proposition expressed
by (2) and (3) is fS1 t S2 W S1 2 A and S2 2 Bg. (4) and (5) express different
propositions. If A is the proposition expressed by (4) and B is the proposition
expressed by (8), then the proposition expressed by the second disjunct of (5) is a set
C that contains every state S1 tS2 such that S1 2 A and S2 2 B. So C ¤ A. It follows
that A [ C, the proposition expressed by (5), differs from A. (6) and (7) express
different propositions. Assuming that A and A are the propositions expressed by
(4) and its negation, and that B and B are the propositions expressed by (8) and its
negation, the proposition expressed by (6) is A [ A, whereas that expressed by (7)
is B[B. (9) and (10) express the same proposition because they are veriﬁed by the
same states. (4) and (11) express different propositions. The proposition expressed
by (4) does not contain the state that Aristotle is a philosopher, just as it does not
contain any state which includes that state. But it is plausible that the proposition
expressed by (11) does contain such a state, assuming that Aristotle could have
written The Republic instead of Plato, for it reasonable to grant that an existential
sentence is made true by the veriﬁers of its instances. The apparent difference of
content between (4) and its negation can also be explained in terms of different sets
of veriﬁers.
The naturalized propositions theory and the truthmaker theory are not the
only theories compatible with the characterization of truth conditions provided in
Sect. 5.1. What has been said about the naturalized propositions theory can be
extended to other theories that treat propositions as structured entities constituted
by the semantic values of the expressions occurring in the sentences that express
identify a proposition with an ordered pair formed by the set of its veriﬁers and the set of its
falsiﬁers. But the pros and cons of each option are beyond the scope of this section.

58
5
Logical Form and Truth Conditions
them. Similarly, what has been said about the truthmaker theory can be extended to
other theories that treat propositions as sets of entities that verify the sentences that
express them. In any case, for our purposes there is no need to endorse a speciﬁc
account of content, because what will be said about logical form does not essentially
depend on how ﬁne-grainedness is understood.4
5.3
Adequate Formalization
Let us call truth-conditional view the view that, in the sense of ‘logical form’
that matters to logic, logical form is determined by truth conditions. The truth-
conditional view stems from the idea that an adequate formalization of a set of
sentences provides a representation of their content. This idea may be illustrated by
means of an example. Suppose that we want to formalize in L (9) and (10). In this
case we will assign the same formula to (9) and (10), say Rab. Now suppose that we
want to formalize in L (9) and the following sentence:
(12) Aristotle admires Socrates
In this case we will assign different formulas to (9) and (12), say Rab and Rac. Why?
The obvious explanation is that (9) and (10) have the same truth conditions, while
(9) and (12) have different truth conditions. There is a clear sense in which (9) and
(10) say the same thing, while (9) and (12) say different things: (9) and (10) say that
Aristotle stands in a certain relation – admiration – with Plato, while (12) says that
Aristotle stands in that relation with Socrates.
The line of thought that substantiates the truth-conditional view rests on two main
assumptions. The ﬁrst expresses a basic constraint on adequate formalization. Let Nx
be an n-tuple hx1; : : : ; xni. Let x be an equivalence relation deﬁned for xs. Let it be
agreed that, for two n-tuples Nx and Ny, Ny mirrors Nx if and only if, for every i; k  n,
xi x xk if and only if yi y yk. The constraint is that, given an n-tuple of sentences
Ns with truth-conditions Nt, an n-tuple of formulas N˛ adequately formalizes Ns only if N˛
mirrors Nt. The meaning of ‘ N˛ mirrors Nt’ obviously depends on how t and ˛ are
deﬁned. We will take for granted that t is identity, namely that ti t tk just in case
ti D tk, and that ˛ is some equivalence relation stricter than logical equivalence,
namely, that if ˛i ˛ ˛k then ˛i and ˛k are true in the same models, but not the other
way round. Given the constraint just stated, the ﬁrst assumption may be phrased as
follows:
(A1) Formulas mirror truth conditions.
That is, for every Ns with truth conditions Nt and every N˛ that adequately formalizes Ns,
N˛ mirrors Nt.
4Other theories similar to the naturalized propositions theory are developed in Soames (1985,
1987, 1989) and Salmon (1986a,b, 1989a,b). Other theories similar to the truthmaker theory are
suggested in Yablo (2014) and Jago (2017). A signiﬁcantly different theory, which will not be
considered here, is the classiﬁcatory theory defended in Soames (2010, 2014) and Hanks (2015).

5.3
Adequate Formalization
59
Note that (A1) does not provide a precise criterion for adequate formalization,
because ˛ can be speciﬁed in more than one way, depending on how truth
conditions are understood. However, it is reasonable to expect that ˛ deﬁnitely
holds in some cases and that it deﬁnitely does not hold in other cases. For example,
˛i and ˛k are deﬁnitely strictly equivalent if ˛k is an alphabetic variant of ˛i, as
in the case of 8x8yRxy and 8x8zRxz, or if ˛k it is obtained from ˛i by applying
elementary syntactic transformations that involve simple order, as in the case of
Fa ^ Fb and Fb ^ Fa. Instead, ˛i and ˛k are deﬁnitely not strictly equivalent if ˛k is
the conjunction of ˛i and a long tautology. The rationale that is generally adopted is
that, in order to adequately formalize a set of sentences, one should choose formulas
whose complexity is exactly that required by a correct analysis of the content of the
sentences. Here ‘complexity’ refers to the number of connectives that occur in the
formula, and ‘correct analysis’ can be spelled out in more than one way.
The second assumption rests on the relatively uncontroversial claim that the
logical form of a set of sentences is expressed by an adequate formalization of the
set. The assumption may be stated as follows:
(A2) Logical forms mirror formulas.
That is, if Ns is adequately formalized by N˛, the logical form of each sentence in Ns
is expressed by the corresponding formula in N˛. This means that the same N˛ may
be regarded as a n-tuple of logical forms. (A2) amounts to a strict reading of the
uncontroversial claim, although it is not the only possible reading.5
Note that (A1) and (A2) are consistent with the claim that logical forms do not
mirror sentences. The reason is that truth conditions do not mirror sentences. Let
us assume that an interpretation of a sentence s ﬁxes a content for s in accordance
with the meaning of s. The content of s as used on a given occasion depends on the
intended interpretation of s, which is one among the possible interpretations of s.
For example, (13) uttered by me and (13) uttered by you express different contents,
while (14) uttered by me and (15) uttered by you, pointing at me, express the same
content.
(13) I’m a philosopher
(14) I’m not a philosopher
(15) You are not a philosopher
More generally, it is not the case that, for every Ns with truth conditions Nt, Nt mirrors
Ns. As in the case of truth conditions, we may take for granted that equivalence for
sentences amounts to identity, namely, that si s sk just in case si D sk. Since truth
conditions do not mirror sentences, from (A1) we get that formulas do not mirror
sentences: it is not the case that, for every Ns and every N˛ that adequately formalizes
5The understanding of adequate formalization suggested here is in line with Sainsbury (1991), pp.
161–162. Brun (2008), p. 27, and Baumgartner and Lampert (2008), p. 104, provide considerations
in support of the claim that the logical form of a set of sentences is expressed by an adequate
formalization of the set.

60
5
Logical Form and Truth Conditions
Ns, N˛ mirrors Ns. Mirroring is an equivalence relation, so if N˛ mirrors Nt but Nt does not
mirror Ns, then N˛ does not mirror Ns. From this and (A2) we get that logical forms
do not mirror sentences: it is not the case that for every Ns, every n-tuple of logical
forms exhibited by an adequate formalization of Ns mirrors Ns. This means that there
is no such thing as “the” logical form of a sentence. Sentences have logical form
relative to interpretations, because they have logical form in virtue of the content
they express.
Let it be granted that, for any n-tuple of sentences Ns, an interpretation of Ns is an
n-tuple Ni such that each term in Ni is an interpretation of the corresponding term in Ns.
A deﬁnition of logical form relative to interpretations may be stated as follows:
Deﬁnition 5.3.1 Ns has logical form N˛ in Ni if and only if Ns is adequately formalized
by N˛ in Ni.
For example, the case of the n-tuples h.9/; .10/i and h.9/; .12/i may be described
as follows: h.9/; .10/i has logical form hRab; Rabi in the intended interpretation
(just as in any interpretation), whereas h.9/; .12/i has logical form hRab; Raci in the
intended interpretation (just as in any interpretation). Note that if Ns has exactly one
term, we get that s has logical form ˛ in i if and only if s is adequately formalized
by ˛ in i.
Deﬁnition 5.3.1 leaves room for two senses in which a formula ˛ can be said
to display the logical form of a sentence s relative to an interpretation i. The ﬁrst
is that in which ˛, as distinct from some other formula, represents the content of s
relative to i, as distinct from some other content. For example, if (9) and (12) are
formalized as Rab and Rac, the fact that Rab and Rac contain different individual
constants b and c shows that (9) and (12) express different contents because ‘Plato’
and ‘Socrates’ refer to distinct individuals. The second is that in which ˛ represents
the structure of the content of s relative to i in virtue of its being a formula of a
certain kind. For example, Rab and Rac are both formulas of the form Pt1t2, where
P indicates any two-place predicate of L and t1 and t2 indicate any two terms of
L. In this sense it is plausible to say that (9) and (12) have the same logical form,
although they express different contents.6
Sameness of logical form in the second sense implies that there is a stable
property of sentences of the sort envisaged by those who rely on an intrinsicalist
notion of logical form. If the metalinguistic expression Pt1t2 exhibits a feature that
belongs to all the formulas that can be assigned to (9) relative to its interpretations,
then (9) has logical form Pt1t2 simpliciter. However, this is not quite the same thing
as to say that logical form is an intrinsic property of sentences. Any ascription
of logical form simpliciter to a sentence s depends on prior ascriptions of logical
form relative to interpretations of s, so it is based on the content that s has in those
interpretations. Moreover, this notion of sameness of logical form does not entail
6The use of metalinguistic expressions is not essential here. The sense in which (9) and (12) have
the same logical form equally emerges from the fact that they can both be represented as Rab, or
as Rac, if they are considered separately.

5.4
A Truth-Conditional Account
61
that every sentence has logical form simpliciter, or even that some sentence has
logical form simpliciter. It is consistent with it to maintain that some (or even
all) sentences do not have stable logical forms, as their logical form vary with
interpretation.
The view that emerges from the line of thought set out is truth conditional in that
it implies that the logical form of a sentence s in an interpretation i is determined
by the truth conditions that s has in i. As in the case of intrinsic properties,
determination is understood in terms of grounding, rather than in terms of necessary
and sufﬁcient conditions. To say that the logical form of s in i is determined by the
truth conditions that s has in i is to say that the ascription of logical form to s in i is
grounded on the fact that s has those truth conditions in i.
5.4
A Truth-Conditional Account
The truth-conditional view provides a straightforward account of the cases con-
sidered in Sect. 4.5. Let us begin with cases 1–4, which cause no trouble to an
intrinsicalist notion. Case 1 involves an apparently valid argument:
[A]
(16) Plato is different from Aristotle
(17) There are at least two things
We saw that the apparent validity of [A] is formally explained if h.16/; .17/i
is represented as ha ¤ b; 9x9yx ¤ yi. This representation is consistent with
Deﬁnition 5.3.1. Assuming that the intended interpretation of h.16/; .17/i is such
that ‘Plato’ refers to Plato and ‘Aristotle’ refers to Aristotle, in that interpretation
(16) and (17) are adequately formalized as a ¤ b and 9x9yx ¤ y.
Case 2 involves an apparently invalid argument:
[B]
(4) Plato is a philosopher
(8) Aristotle is a philosopher
We saw that the apparent invalidity of [B] is formally explained if h.4/; .8/i is
represented as hFa; Fbi. Again, it is easy to see that this formalization is consistent
with Deﬁnition 5.3.1, in that Fa and Fb displays the content of (4) and (8) in the
intended interpretation.
Cases 3 and 4 are analogous. Consider the negations of (4) and (8):
(18) Plato is not a philosopher
(19) Aristotle is not a philosopher
h.4/; .18/i can be represented as hFa; Fai, and h.4/; .19/i can be represented
as hFa; Fbi. Both representations are justiﬁed if it is assumed that the formula
assigned to each sentence displays its content.
Now let us consider cases 5–8, which do cause trouble to an intrinsicalist notion.
Case 5 involves an argument that seems valid if understood in the way described:

62
5
Logical Form and Truth Conditions
[C]
(20) This is different from this
(17) There are at least two things
Since the two occurrences of ‘this’ refer to different persons in the intended
interpretation of [C], it is consistent with Deﬁnition 5.3.1 to represent h.20/; .17/i as
ha ¤ b; 9x9yx ¤ yi in that interpretation. So the apparent validity of [C] is formally
explained exactly like the apparent validity of [A].
Case 6 involves an argument that seems invalid if understood in the way
described:
[D]
(1) This is a philosopher
(1) This is a philosopher
Again, since the two occurrences of ‘this’ refer to different persons in the intended
interpretation of [D], it is consistent with Deﬁnition 5.3.1 to represent h.1/; .1/i
as hFaI Fbi in that interpretation. So the apparent invalidity of [D] is formally
explained.
Cases 7 and 8 are analogous. If I utter (13) and you utter (15), pointing at me, the
sense in which we are contradicting each other is formally explained if h.13/; .15/i
is represented as hFa; Fai in the intended interpretation. Similarly, if I utter (13)
and you utter (14), the sense in which we are not contradicting each other is formally
explained if h.13/; .14/i is represented as hFa; Fbi in the intended interpretation.
Essentially, the truth-conditional notion provides a formal account of both cases
1–4 and cases 5–8. In cases 1–4 the kind of representation sustained by the truth-
conditional notion is the same as that sustained by an intrinsicalist notion. But in
cases 5–8 the truth-conditional notion sustains a kind of representation that cannot
be justiﬁed on the basis of an intrinsicalist notion. Even though cases 1–4 differ from
cases 5–8, at least if it is assumed that only the latter involve context sensitivity, the
method of formalization is exactly the same. As far as the truth-conditional notion
is concerned, no relevant distinction can be drawn between context-sensitive and
context-insensitive sentences. All that matters to formalization is that sentences have
truth conditions relative to interpretations.
The advantage of the truth-conditional notion over an intrinsicalist notion is not
just a matter of amount of cases explained. The fact that both kinds of cases are
explainable in terms of truth conditions suggests that an intrinsicalist notion might
get things wrong even when applied to cases of the ﬁrst kind. It suggests that the
real ground of the formal representations supported by such a notion is not really the
one that the intrinsicalist has in mind. For example, the intrinsicalist will be apt to
think that (16) and (17) are adequately formalized as a ¤ b and 9x9yx ¤ y because
they have a certain syntactic structure. But this might be questioned. Even though
that formalization is consistent with the hypothesis that logical form is determined
by syntactic structure, it is equally consistent with the hypothesis that logical form
is determined by truth conditions. According to the latter hypothesis, (16) and (17)
are adequately formalized as a ¤ b and 9x9yx ¤ y because they have certain truth
conditions.

5.5
Logical Form as a Property of Propositions
63
5.5
Logical Form as a Property of Propositions
The truth-conditional view is the view that, in the sense of ‘logical form’ that matters
to logic, logical form is determined by truth conditions. If truth conditions are
identiﬁed with propositions, as suggested in Sect. 5.2, this is to say that, in the sense
of ‘logical form’ that matters to logic, logical form is a property of propositions.
Sentences have logical form in virtue of the proposition they express.
The idea that logical form is a property of propositions might strike as uncon-
ventional. The truth-conditional notion is deﬁnitely less in vogue than the syntactic
notion. But it is at least as close to the notion that emerges from the old conception of
logical form. An emblematic case is Russell’s theory of descriptions, which may be
contrasted with Davidson’s theory of action sentences. Both Russell and Davidson
claim that some problems that arise in connection with certain sentences can be
solved if those sentences are paraphrased in a certain way. But while Davidson
takes the paraphrase to explain the meaning of the target sentences as part of a
theory of the language to which they belong, Russell takes the paraphrase to account
for the logical properties of the judgements expressed by the target sentences. For
Russell the primary constraint on logical form is imposed by the need to explain
the inferential relations between judgements, rather than by the need to explain the
syntactic or semantic properties of sentences. In this respect the truth-conditional
notion is deﬁnitely Russellian.7
The idea that logical form is a property of propositions may be illustrated by
means of an example. We saw that (4) is adequately formalized as Fa. This can be
explained by saying that Fa is a formal representation of the proposition expressed
by (4). Arguably, the way of being true of (4) depends on the kind of state of
affairs it describes as obtaining. Since (4) says that a certain individual, Plato, has
a certain property, being a philosopher, (4) is true if and only if that individual has
that property. The semantics of L provides a formal account of this way of being
true, in that the formula Fa is true in a model if and only if the object denoted by a
belongs to the extension of F.
The two theories of propositions outlined in Sect. 5.2 seem to square equally well
with the idea that logical form is a property of propositions. Consider the naturalized
propositions theory. If the proposition expressed by (4) is a structured entity that has
Plato and the property of being a philosopher as constituents, Fa may be regarded
as a formal representation of that entity. The way in which the predicate letter F and
the individual constant a are combined in the formula may be taken to indicate the
propositional relation that ties Plato and the property of being a philosopher in the
proposition expressed by (4).
7As Linsky (2002) explains, “Russell’s notion of logical form is clearly directly connected with
the truth-conditions, logical powers, and existential import of propositions, and indirectly if at all
with the syntactic features of sentences expressing those propositions”, p. 398. Sainsbury (2008),
section 2.5, spells out the differences between Russell and Davidson on logical form.

64
5
Logical Form and Truth Conditions
Now consider the truthmaker theory. If the proposition expressed by (4) is a set
of states each of which includes Plato, or someone quite similar to Plato, and the
property of being a philosopher, Fa may be regarded as a formal representation of
that kind of state. As in the case of naturalized propositions, the fact that Fa is true
in a model if and only if the object denoted by a belongs to the extension of F
represents an essential feature of the entity represented, which constitutes the way
of being true of (4).
The rest of this section dwells on two possible objections to the truth-conditional
view. The ﬁrst concerns logical equivalence. Consider (2) and (3). These two
sentences are equivalent for a purely logical reason, that is, the commutativity of
conjunction. Similarly, consider the following sentences:
(21) Not all Martians are green
(22) Some Martians are not green
The equivalence between (21) and (22) seems to hold for a purely logical reason,
that is, the interdeﬁnability of quantiﬁers. However, if logical form is determined by
truth conditions, then (2) and (3) must be represented by the same formula, and the
same goes for (21) and (22). Thus it turns out that these equivalences have a trivial
proof because they follow from the fact that every formula is logically equivalent to
itself.8
This objection can be resisted. Let us grant that (2) and (3) have the same
truth conditions, and that the same goes for (21) and (22). First of all, note that
the truth-conditional view does not entail that distinct sentences with the same
truth conditions must be represented by the same formula. It is consistent with
Deﬁnition 5.3.1 to formalize h.2/; .3/i as hRab ^ Rcb; Rcb ^ Rabi and h.21/; .22/i
as h8x.Fx  Gx/; 9x.Fx^  Gx/i. What the view does entail is that distinct
sentences with the same truth conditions can be represented by the same formula.
Now suppose that the same formula, say Rab ^ Rcb, is assigned to (2) and (3). It
is still questionable that the explanation of the equivalence between (2) and (3) is
trivial. The same logical reason that warrants the equivalence between Rab^Rcb and
Rcb^Rab justiﬁes the assignment of Rab^Rcb to (2) and (3) as part of the analysis
of (2) and (3). Similarly, suppose that the same formula, say 8x.Fx  Gx/,
is assigned to (21) and (22). It is still questionable that the explanation of the
equivalence between (21) and (22) is trivial. The same logical reason that warrants
the equivalence between 8x.Fx  Gx/ and 9x.Fx^  Gx/ justiﬁes the assignment
of 8x.Fx  Gx/ to (21) and (22) as part of the analysis of (21) and (22).
Moreover, independently of the triviality issue, it is not obvious that there is
something wrong with the supposition that the same formula represents (2) and
(3), or (21) and (22). Imagine a written logic exam in which students are asked to
8An objection along these lines is raised in Davidson (1980), p. 145, in Brun (2008), p. 12, and in
Baumgartner and Lampert (2008), pp. 101–102. In Brun (2008) and in Baumgartner and Lampert
(2008) the objection is intended to generalize to all equivalences, so it does not take into account
the possibility that two equivalent sentences express different contents.

5.5
Logical Form as a Property of Propositions
65
formalize an argument containing (2) and (3), and suppose that one of them uses the
formula Rab ^ Rcb to represent both sentences. In this case, it would be unfair for
the teacher to mark the formalization as mistaken. The same would go for a case in
which the student formalizes (21) and (22) as 8x.Fx  Gx/. After all, the student
might say, why should this difference matter, if it doesn’t matter to the validity or
invalidity of the argument?9
The second objection concerns synonymy. Consider the following sentences:
(23) Donald is a drake
(24) Donald is a male duck
Since (23) and (24) are synonymous, they have the same truth conditions. Therefore,
on the assumption that formulas represent truth conditions, (23) is adequately
formalized as Fa^Ga. This entails that the following argument is formally valid:
[E]
(23) Donald is a drake
(25) Donald is a duck
That is, [E] turns out to have the following form:
[F]
(26) Fa ^ Ga
(27) Ga
So is seems that the consequence we get is that materially valid arguments, which
should be counted as formally invalid, turn out trivially formally valid. Unless one
is willing to endorse the “Tractarian vision” according to which all validity is formal
validity, such a consequence must be avoided.10
This objection can be resisted as well. First of all, independently of the question
whether the Tractarian vision is really untenable, as the objection assumes, the truth-
conditional view does not entail that vision. Even if it is granted that some valid
arguments based on synonymy are formally valid, this is not to say that all valid
arguments are formally valid. It is consistent with the truth-conditional view to hold
that there are valid arguments that no amount of analysis can represent as formally
valid. For example, the following could be one of them:
[G]
(28) The sea is blue
(29) The sea is not yellow
9If the teacher weren’t moved, the student might quote from Frege, and invoke the notion of
“conceptual content” mentioned in Sect. 2.1. Note, among other things, that Rab ^ Rcb and
Rcb^Rab have the same complexity, and the same goes for 8x.Mx  Gx/ and 9x.Mx^  Gx/,
in accordance with the rationale considered in Sect. 5.3.
10This objection is raised in Brun (2008), pp. 12–13. The label ‘Tractarian vision’ comes from
Sainsbury (1991), pp. 348–355.

66
5
Logical Form and Truth Conditions
Moreover, it is not clear why [E] should not be formalized as [F]. Although [F] is a
trivially valid argument form, this does not mean that [E] is trivially valid, for it is
not trivial that [E] instantiates [F].11
Certainly, one might insist that [E] should not be counted as formally valid
because its validity depends on a semantic relation that can be revealed only
through conceptual analysis. But in order to defend such a position, one would
have to justify a hardly tenable claim, namely, that adequate formalization does
not involve conceptual analysis. It is widely recognized that many paradigmatic
cases of adequate formalization, such as Russell’s theory of descriptions, do involve
conceptual analysis at least to some extent, and it is easy to see that there is no
principled way to set a threshold for the amount of conceptual analysis needed.
5.6
Extrinsicalism
From the foregoing sections it turns out that the truth-conditional notion provides
a coherent account of a wide variety of examples of logical properties and logical
relations, and that its explanatory power is not subject to the limitations that affect
an intrinsicalist notion. This shows that intrinsicalism is ungrounded, given that
intrinsicalism, deﬁned as follows, entails that an intrinsicalist notion fuﬁls the
logical role:
(I) There is a unique intrinsicalist notion of logical form which fulﬁls both the
logical role and the semantic role.
We have seen that (I) is usually taken to substantiate the uniqueness thesis:
(UT)
There is a unique notion of logical form that fulﬁls both the logical role and
the semantic role.
So if (I) is ungrounded, it is reasonable to think that the same goes for (UT). Strictly
speaking, a denial of (I) does not entail a denial of (UT). But if (I) is rejected, it
seems that no viable alternative can be offered. The only alternative to (I) would be
extrinsicalism, the view that logical form is determined by extrinsic properties of
sentences:
(E) There is a unique extrinsicalist notion of logical form that fulﬁls both the logical
role and the semantic role.
However, (E) is untenable. An extrinsicalist notion of logical form, such as the truth-
conditional notion, can hardly fulﬁl the semantic role, for that role requires that
logical form features as part of a compositional theory of meaning. The meaning of
a sentence s is an intrinsic property of s that is determined by the conventions that
11Some arguments against the Tractarian vision are discussed in Sainsbury (1991), pp. 348–355,
and in Baumgartner and Lampert (2008), pp. 105–106.

5.6
Extrinsicalism
67
are constitutive of the language to which s belongs. Or at least, this holds for some
sense of ‘meaning’ in which meaning, as distinct from content, falls in the domain
of a compositional theory. Therefore, the meaning of s cannot be explained in terms
of the truth conditions of s, for the truth conditions of s are not intrinsic properties
of s. The truth-conditional view differs from (E) precisely in that it does not entail
that logical form is determined by truth conditions in the sense of ‘logical form’ that
matters to semantics.12
Of course, there is a reading of ‘truth conditions’ on which it may be correct
to say that meaning is explainable in terms of truth conditions: it is the reading on
which meaning is explainable in terms of semantic structure. However, as we saw
in Sect. 5.1, this is not the reading of ‘truth conditions’ that matters here. According
to the truth-conditional notion, logical form is determined by content rather than by
semantic structure. The distinction between semantic structure and content is crucial
because the former is intrinsic while the latter is extrinsic. Any account of meaning
that involves a notion of logical form deﬁned in terms of the former is inconsistent
with (E). To endorse (E), by contrast, is to hold the unjustiﬁed belief that a notion of
logical form deﬁned in terms of the latter can yield an account of meaning without
requiring other notions.
Note that the distinction between semantic structure and content does not imply
that content is not itself structured. The crux of the matter is that content is extrinsic,
not that it is unstructured. We saw that the truth-conditional view is consistent with
the claim that the content expressed by s is a structured proposition. But the point
remains that a notion of logical form deﬁned in terms of an extrinsic property of s
can hardly provide an account of the meaning of s without requiring other notions. If
one assumes that contents are structured propositions and deﬁnes logical form in the
way suggested in Sect. 5.3, one can offer at most a formal description of the kind of
proposition expressed by s, that is, a description of what the different propositions
expressed by s have in common. But in order to provide an account of the meaning
of s one should explain how the words occurring in s and the way they are combined
determine that kind of proposition. Therefore one would need a semantic description
of s that is not derivable from its logical form, which means that the notion of logical
form would not sufﬁce. Perhaps this is why structured proposition theorists typically
favour (I) rather than (E).13
To say that (UT) is ungrounded is to say that there is no reason to think that
a unique notion of logical form fulﬁls both the logical role and the semantic role.
(UT) is a Holy Grail sort of view. Traditionally, those who believe in (UT) tend to
think that, although logical form may be very hard to ﬁnd, once you ﬁnd it you will
get everything you want. All of your problems will be solved. In contrast, to reject
12Note that although it is almost trivial that the meaning of s is an intrinsic property of s in the
sense of ‘intrinsic’ adopted here, namely, the sense introduced in Sect. 3.5, it is not uncontroversial
that the meaning of s is an intrinsic property of s in other senses of ‘intrinsic’.
13The paradigmatic example is Kaplan, whose theory of indexicals and demonstratives combines
(I) with the idea that contents are structured propositions.

68
5
Logical Form and Truth Conditions
(UT) is to think that the Holy Grail does not exist. The use of the term ‘logical
form’ may be motivated by different theoretical purposes, and it should not be taken
for granted that a unique notion can satisfy all those purposes. Different problems
require different solutions.
The leading idea of this book is that, once (UT) is abandoned, it becomes clear
that different notions of logical form suit different roles. On the one hand, the
syntactic notion suits the semantic role, although it is unsuitable for the logical
role. On the other, the truth-conditional notion suits the logical role, although it
is unsuitable for the semantic role. This idea seems in the spirit of something that
Quine once said about syntactic structure and logical form:
Both are paraphrases of sentences of ordinary language; both are paraphrases that we
resort to for certain purposes of technical convenience. But the purposes are not the same.
The grammarian’s purpose is to put the sentence into a form that can be generated by a
grammatical tree in the most efﬁcient way. The logician’s purpose is to put the sentence
into a form that admits most efﬁciently of logical calculation, or show its implications and
conceptual afﬁnities most perspicuously, obviating fallacy and paradox.14
14Quine (1971), pp. 451–452.

Chapter 6
Logical Knowledge vs Knowledge of Logical
Form
Abstract This chapter spells out some major epistemological implications of the
truth-conditional view, which concern the relation between logical knowledge and
knowledge of logical form. The interesting fact that will emerge is that the truth-
conditional view provides a perspective on such relation that radically differs from
the approach traditionally associated with the syntactic notion.
6.1
Preliminaries
Logical knowledge is knowledge of logic. Since logic essentially concerns the
formal explanation of logical properties and logical relations, this is to say that
logical knowledge is knowledge of the formal principles that explain logical
properties and logical relations. For example, knowing that modus ponens is a valid
argument form is part of logical knowledge.
Knowledge of logical form, instead, concerns adequate formalization: to know
that an argument has a certain logical form in its intended interpretation is to know
that the argument is adequately formalized in a certain way in that interpretation.
Since arguments are n-tuples of sentences, knowledge of logical form may be
deﬁned in general terms as follows: one knows the logical form of an n-tuple of
sentences Ns relative to an interpretation Ni if and only if, for some n-tuple of formulas
N˛, one knows that Ns is adequately formalized as N˛ in Ni.
Logical knowledge and knowledge of logical form are often associated with
linguistic competence and rationality. According to a rather inﬂuential way of
thinking, which is congruous with the syntactic notion, knowledge of logical form
is intimately connected with logical knowledge, as part of the logical endowment
that we have as linguistically competent speakers and rational subjects. Just as in
normal circumstances we know – or at least we are in a position to know – that
certain argument forms are valid, in normal circumstances we know – or at least we
are in a position to know – whether the arguments we use instantiate those forms.
The truth-conditional view questions this way of thinking. On the truth-
conditional view, logical knowledge and knowledge of logical form are to a large
extent independent. Even though in normal circumstances we know – or at least we
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_6
69

70
6
Logical Knowledge vs Knowledge of Logical Form
are in a position to know – that certain argument forms are valid, it happens quite
often that we don’t know – and we are not in a position to know – whether the
arguments we use instantiate those forms.
In order to elucidate this point we will focus on the role of names in formal-
ization. Sections 6.2, 6.3, and 6.4 outline and defend two rules concerning names
that underlie the method of formalization suggested in Chap. 5: one is the rule that
distinct objects must be denoted by distinct names, the other is the rule that distinct
names must denote distinct objects. Sections 6.5 and 6.6 show the implications of
these two rules. What holds for names holds, mutatis mutandis, for predicates and
other kinds of expressions. But the case of names will sufﬁce for the purposes at
hand.
6.2
Logical Identity and Logical Distinctness
The two rules of formalization that will be considered imply a distinction between
grammatical appearance and logical reality that is consistent with the revisionary
spirit of the old conception of logical form. One thing is whether two names are
grammatically identical, another thing is whether they are logically identical. While
grammatical identity amounts to identity at the level of syntactic structure, logical
identity amounts to identity at the level of logical form.
Assuming that L is the language that exhibits logical form, logical identity will
be deﬁned as follows:
Deﬁnition 6.2.1 Two occurrences of names n1 and n2 are logically identical if
and only if they are represented by the same individual constant in an adequate
formalization of the sentences in which they occur.
Logical distinctness will be deﬁned in the same way:
Deﬁnition 6.2.2 Two occurrences of names n1 and n2 are logically distinct if
and only if they are represented by distinct individual constants in an adequate
formalization of the sentences in which they occur.
Deﬁnition 6.2.1 involves no reference to the syntactic properties of n1 and n2. More
speciﬁcally, it does not require that n1 and n2 instantiate the same graphic type. So
it leaves room for the possibility that n1 and n2 are logically identical even if they
are grammatically distinct, that is, even if they are occurrences of distinct syntactic
items. Similarly, Deﬁnition 6.2.2 involves no reference to the syntactic properties of
n1 and n2. More speciﬁcally, it does not require that n1 and n2 instantiate different
graphic types. So it leaves room for the possibility that n1 and n2 are logically
distinct even if they are grammatically identical.
The two rules of formalization that will be considered are deﬁned in terms of
logical identity and logical distinctness. The ﬁrst prescribes that distinct objects are
denoted by distinct names:

6.3
Distinct Objects Must Be Denoted by Distinct Names
71
(N1)
If n1 denotes x, n2 denotes y, and x ¤ y, then n1 and n2 are logically distinct.
Contrapositively, if n1 and n2 are logically identical, then they do not denote distinct
objects. So if n1 denotes x and n2 denotes y, then x D y. The second rule prescribes
that distinct names denote distinct objects:
(N2)
If n1 and n2 are logically distinct, n1 denotes x, and n2 denotes y, then x ¤ y.
Contrapositively, if x D y, then it is not the case that n1 and n2 are logically distinct,
n1 denotes x, and n2 denotes y. So, if n1 denotes x and n2 denotes y, then n1 and n2
are logically identical.1
(N1) and (N2) are deeply rooted in the old conception of logical form. (N1)
stems from the idea that a logically perfect language is not ambiguous. As we saw
in Sect. 2.4, Frege, Russell, and Wittgenstein ruled out the possibility that a name
of a logically perfect language refers to distinct objects. (N2) is reminiscent of the
hypothesis entertained by Russell and Wittgenstein that a logically perfect language
has exactly one name for every object. In The philosophy of logical atomism,
Russell says:
In a logically perfect language there will be one word and no more for every simple object.2
Similarly, in the Tractatus Wittgenstein says:
Identity of the object I express by identity of the sign and not by means of a sign of identity.
Difference of the objects by difference of the signs.3
Russell and Wittgenstein endorsed this hypothesis along with the old conception
of logical form, so they abandoned it as soon as they recognized that their ideal of
logical perfection was hardly realizable. Yet there seems to be nothing intrinsically
wrong in the idea that distinct names must denote distinct objects. The next two
sections are intended to show that (N1) and (N2) may coherently be justiﬁed.
6.3
Distinct Objects Must Be Denoted by Distinct Names
The main motivation for a rule of formalization lies in its explanatory power. This
section suggests that (N1), the rule that distinct objects must be denoted by distinct
names, provides a formal explanation of some plausible judgements concerning
validity. In particular, we will consider two cases of apparent invalidity to show
how (N1) can be employed.
1To be precise, (N1) should be phrased as the rule that distinct objects are denoted by distinct
names, if denoted at all, and (N1) should be phrased as the rule that distinct names must denote
distinct objects, if they denote at all. For the sake of simplicity, here and in what follows we will
use the shorter formulation.
2Russsell (1998), p. 58.
3Wittgenstein (1992), 5.53.

72
6
Logical Knowledge vs Knowledge of Logical Form
The ﬁrst case is a simple variation of cases 1 and 5 considered in Sects. 4.5
and 5.4. We saw that the following argument is apparently valid:
[A]
(1) Plato is different from Aristotle
(2) There are at least two things
This fact is formally explained if [A] is formalized as follows:
[B]
(3) a ¤ b
(4) 9x9yx ¤ y
We also saw that the following argument is apparently valid, if the ﬁrst occurrence
of ‘this’ refers to Plato and the second refers to ‘Aristotle’:
[C]
(5) This is different from this
(2) There are at least two things
Again, this fact is formally explained if [C] is formalized as [B]. Now let us imagine
that the following argument is so understood that the ﬁrst occurrence of ‘Plato’
refers to the famous philosopher, while the second refers to some homonymous
citizen of Athens unknown to us:
[D]
(6) Plato is different from Plato
(2) There are at least two things
As in cases 1 and 5, the argument is apparently valid, and this fact is formally
explained if [D] is formalized as [B]. The reason for assigning (3) to (6) is exactly
the same that justiﬁes the assignment of (3) to (1) and to (5), namely, that the two
expressions that ﬂank ‘is different from’ refer to different individuals. So, in this
case (N1) yields the result that it is plausible to expect: since the two occurrences of
‘Plato’ refer to different individuals, (N1) entails that they are logically distinct.
The second case, slightly more sophisticated, comes from a well-known thought
experiment due to Boghossian. Imagine that earth and twin earth are both actual, and
that Peter is a normal earthly speaker. One day, Peter goes hiking in the mountains
of New Zealand, comes across Lake Taupo and sees the famous tenor Pavarotti
ﬂoating on its waters. This experience gives rise to many subsequent memories,
and to beliefs based upon them. Some years later Peter is suddenly and unwittingly
transported to twin earth. He goes to sleep one night at home and wakes up the
day after in twin home, without perceiving any disruption in the continuity of his
mental life. Then, one day he goes to the opera and hears twin Pavarotti singing, so
he is moved to remember the occasion when he saw Pavarotti swimming in Lake
Taupo. He takes himself to be remembering scenes involving the same person he
is hearing now. But in reality his memories are about Pavarotti, not twin Pavarotti.
Consequently, Peter is unable to detect the invalidity of the following argument:
[E]
(7) Pavarotti once swam in Lake Taupo
(8) The singer I heard yesterday is Pavarotti
(9) The singer I heard yesterday once swam in Lake Taupo

6.3
Distinct Objects Must Be Denoted by Distinct Names
73
Peter regards [E] as valid, as he takes the two occurrences of ‘Pavarotti’ to
refer to the same person. But in the interpretation of [E] that seems correct, the
ﬁrst occurrence of ‘Pavarotti’ refers to Pavarotti, while the second refers to twin
Pavarotti. Therefore, (9) does not follow from (7) and (8).4
Boghossian uses this thought experiment to show that externalism is inconsistent
with the claim that mental contents are epistemically transparent. So it is essential
for the purpose of the experiment that Peter’s mental contents are individuated
externally. But what matters here is that Peter seems to reason invalidly because the
two occurrences of ‘Pavarotti’ in [E] refer to different individuals. In this respect
[E] is like [D], in that its apparent invalidity is formally explained if two distinct
individual constants a and b are assigned to the two occurrences of ‘Pavarotti’. [E]
can be formalized as follows:
[F]
(10) Fa
(11) 9x.Gx ^ 8y.Gy  y D x/ ^ x D b/
(12) 9x.Gx ^ 8y.Gy  y D x/ ^ Fx/
The invalidity of [F] explains the apparent invalidity of [E]. As in the previous case,
(N1) yields the result that it is plausible to expect: since the two occurrences of
‘Pavarotti’ refer to different individuals, (N1) entails that they are logically distinct.
It is important to recognize that the motivation for (N1) does not depend on some
speciﬁc conception of names. Names may be individuated in different ways. One
option is to individuate names morphologically, deﬁning them as pure graphic types.
Another option is to individuate names both morphologically and semantically,
treating them as graphic types endowed with referents. A third option, suggested by
Kaplan, is to individuate names historically, holding that their origin is essential to
their identity. So, the fact that ‘Plato’ refers to different individuals may be described
in different ways: one may say that ‘Plato’ is an indexical that refers to different
individuals in different contexts, or that it is an ambiguous expression that has a
distinct meaning for each referent, or that it is a “generic name” shared by distinct
“common currency names”. The same goes for ‘Pavarotti’. But the question of how
names are individuated is orthogonal to the question of how arguments such as [C]
or [E] are formalized. All that matters to the latter question is that the same graphic
types can refer to different individuals, which is something that anyone is willing to
grant.5
4Boghossian (1992), pp. 20–22.
5Kaplan outlines his view in Kaplan (1990). Voltolini (1997) discusses the hypothesis that an
identity sentence in which the same graphic type occurs twice but refers to different things is
formalized as a D b.

74
6
Logical Knowledge vs Knowledge of Logical Form
6.4
Distinct Names Must Denote Distinct Objects
This section suggests that (N2), the rule that distinct names must denote distinct
objects, provides a formal explanation of some plausible judgements concerning
validity. As in the previous section, we will start with a simple variation of a case
discussed in Chap. 5, then we will discuss some well-known examples.
Consider the following sentences:
(13) Aristotle admired Plato
(14) Plato was admired by Aristotle
(15) Aristotle admired Socrates
As suggested in Sect. 5.3, (13) and (14) are plausibly formalized as Rab, while (13)
and (15) are plausibly formalized as Rab and Rac. The reason is that (13) and (14)
say the same thing, while (13) and (15) say different things: (13) and (14) say that
Aristotle stands in a certain relation with Plato, while (15) says that Aristotle stands
in that relation with Socrates. Now consider the following sentence:
(16) The Stagirite admired Plato
On the assumption that ‘the Stagirite’ functions as a name rather than as a deﬁnite
description, we should expect that (13) and (16) are plausibly formalized as Rab,
for they say the same thing in exactly the same sense in which (13) and (14) say
the same thing, that is, they both say that Aristotle stands in a certain relation with
Plato. This expectation seems consistent with our evaluation of the arguments in
which (13) and (16) may occur. Suppose that you read the following passage in an
old-fashioned book on ancient philosophy:
If Aristotle spent twenty years in the Academy and studied extensively the Dialogues,
he admired Plato. But we know that he spent twenty years in the Academy and studied
extensively the Dialogues. Therefore, the Stagirite admired Plato.6
The author of the book seems to reason validly. The following argument, which
provides a simpliﬁed statement of the author’s reasoning, seems valid:
[G]
(17) If Aristotle spent etc., then Aristotle admired Plato
(18) Aristotle spent etc.
(16) The Stagirite admired Plato
The apparent validity of [G] is easily explained on the assumption that (13) and (16)
are adequately formalized as Rab:
[H]
(19) .Ta ^ Sad/  Rab
(20) Ta ^ Sad
(21) Rab
6The book is old-fashioned because almost nobody uses the epithet ‘the Stagirite’ nowadays.

6.4
Distinct Names Must Denote Distinct Objects
75
This formalization of [G] accords with (N2). Since ‘Aristotle’ and ‘the Stagirite’
denote the same individual, (N2) entails that they are logically identical.7
To put things another way, consider an argument that differs from [G] in that it
includes (13) instead of (16):
[I]
(17) If Aristotle spent etc., then Aristotle admired Plato
(18) Aristotle spent etc.
(13) Aristotle admired Plato
It would be equally plausible to phrase the author’s reasoning as [I], just because
‘Aristotle’ and ‘the Stagirite’ name the same individual. As is well known, there is
no unique way to state a reasoning: different formulations, which employ different
words, may be equally admissible. Since [I] is adequately formalized as [H], the
similarity between [G] and [I] suggests that [G] can also be formalized as [H].
Note that the analogy suggested above between (14) and (16) as alternative
but equivalent restatements of (13) is consistent with the fact that the kind of
information that is needed to know that (16) says the same thing as (13) signiﬁcantly
differs from the kind of information that is needed to know that (14) says the same
thing as (13): this difference does not rule out that (13) and (16) are alike as far as
the formalization of the arguments in which they may occur is concerned. One way
to see that the analogy holds is to compare [G] with an argument in which (16) is
replaced by (14):
[L]
(17) If Aristotle spent etc., then Aristotle admired Plato
(18) Aristotle spent etc.
(14) Plato was admired by Aristotle
If (16) were not analogous to (14), we would have to say that [L] is adequately
formalized as [H] whereas [G] is not adequately formalized as [H]. But it is plausible
to treat [G] and [L] as equally admissible formulations of the author’s reasoning, just
like [G] and [I].
The next two cases that will be considered are Kripke’s famous puzzles of
Londres and Paderewski. The ﬁrst puzzle is as follows. Imagine a normal French
speaker, Pierre, who has never left France and is purely monolingual. On the basis
of what he has heard of London, which he calls ‘Londres’, Pierre is inclined to think
that London is pretty. So he says, in French, ‘Londres est jolie’. Later, Pierre moves
to London, without realizing that it is the same city he calls ‘Londres’, and ends
up living in an unattractive neighbourhood with fairly uneducated inhabitants. He
learns English in the same way as native English speakers, not by translating words
from French into English, and picks up the name ‘London’ in connection with the
city he lives in. On the basis of his experience, he comes to believe that London is
not pretty. But how can he believe both that London is pretty and that London is not
7In Wittgenstein’s words, the individual constant a is a “real” name, what ‘Aristotle’ and ‘The
Stagirite’ have in common, see Wittgenstein (1992), 3.3411.

76
6
Logical Knowledge vs Knowledge of Logical Form
pretty? The puzzle may be phrased as a set of jointly inconsistent claims, each of
which seems well-grounded:
(L1) Pierre believes that London is pretty
(L2) Pierre believes that London is not pretty
(L3) The belief attributed in (L1) contradicts the belief attributed in (L2)
(L4) Pierre cannot tell that he has contradictory beliefs
(L5) If Pierre has contradictory beliefs, then he is in a position to know by reﬂection
that he has contradictory beliefs.8
This puzzle can be solved in accordance with (N2). Since ‘Londres’ and
‘London’ refer to the same city, they must be represented by the same individual
constant. Therefore, ‘Londres is pretty’ and ‘London is not pretty’ are adequately
formalized as Fa and  Fa. But Pierre is unable to realize that this formalization
is correct, because he doesn’t know that ‘Londres’ and ‘London’ refer to the same
city. So, while (L1)–(L4) are well-grounded, (L5) is not. Pierre is not in a position
to know by reﬂection that his beliefs about London are contradictory, because he is
not in a position to know by reﬂection the logical form of those beliefs.
Kripke seems to rule out the possibility that Pierre doesn’t know the logical form
of his beliefs:
We may suppose that Pierre, in spite of the unfortunate situation in which he now ﬁnds
himself, is a leading philosopher and logician. He would never let contradictory beliefs
pass. And surely anyone, leading logician or not, is in principle in a position to notice and
correct contradictory beliefs if he has them.9
But these remarks can hardly be regarded as a justiﬁcation of (L5). Kripke seems to
have in mind a transparency principle such as the following:
(T) If an n-tuple of sentences Ns is adequately formalized as N˛ (in a given interpre-
tation) then one is in a position to know that Ns is adequately formalized as N˛ (in
that interpretation).
Certainly, (T) makes sense on the intrinsicalist assumption that logical form is deter-
mined by syntactic structure. But the truth-conditional view rejects that assumption.
If logical form is determined by truth conditions, then (T) is ungrounded, for we
are not always in a position to know the truth conditions of the sentences we use.
Therefore, in the present discussion it would be hopeless to invoke (T) to defend
(L5).
The solution just presented sheds light on a related example discussed by Kripke.
Suppose that Pierre, in France, says ‘Si New York est jolie, Londres est jolie aussi’,
which means that if New York is pretty, so is London. Later he moves to London,
learns English, and says ‘London is not pretty’. In this case it seems that from two
premises, both of which appears to be among his beliefs, Pierre should be able
8Kripke (1979), pp. 254–265.
9Kripke (1979), p. 257.

6.4
Distinct Names Must Denote Distinct Objects
77
to conclude by modus tollens that New York is not pretty. That is, the following
argument seems valid:
[M]
(22) If New York is pretty, so is Londres
(23) London is not pretty
(24) New York is not pretty
But Pierre cannot make this inference, as long as he supposes that ‘Londres’ and
‘London’ may name two different cities.10
Again, the fact that Pierre does not see that [M] is valid can be explained in
accordance with (N2). Since ‘Londres’ and ‘London’ refer to the same city, [M] is
adequately formalized as follows:
[N]
(25) Fb  Fa
(26)  Fa
(27)  Fb
However, Pierre is not in a position to know that [M] instantiates [N], even though
he may know perfectly well that [N] is a valid form.
The second puzzle is a variant of the ﬁrst. Suppose that Peter learns that
‘Paderewski’ is the name of a famous pianist who gave many concerts in Europe
and the United States, and that he later comes to know that a Polish nationalist
leader and prime minister was named ‘Paderewski’. Peter never realizes that the
musician and the statesman are one and the same person. On the contrary, given
their different activities, he believes that they are distinct individuals. As a matter of
fact, Peter believes that politicians lack musical talent. Thus, it seems plausible to
attribute to Peter both the belief that Paderewski had musical talent and the belief
that Paderewski did not have musical talent. But how can he have both beliefs?
Again, the puzzle may be phrased as a set of jointly inconsistent claims, each of
which seems well-grounded:
(P1) Peter believes that Paderewski has musical talent
(P2) Peter believes that Paderewski lacks musical talent
(P3) The belief attributed in (P1) contradicts the belief attributed in (P2)
(P4) Peter cannot tell that he has contradictory beliefs
(P5) If Peter has contradictory beliefs, then he is in a position to know by reﬂection
that he has contradictory beliefs.11
This puzzle can be solved in the same way. If Peter accepts as true both
‘Paderewski has musical talent’ and ‘Paderewski lacks musical talent’, it is because
he does not realize that the two occurrences of ‘Paderewski’ refer to the same
person. Since they do refer to the same person, the two sentences are adequately
formalized as Fa and  Fa. This means that (P5) is wrong. Peter is not in a position
10Kripke (1979), pp. 257–258.
11Kripke (1979), pp. 265–266.

78
6
Logical Knowledge vs Knowledge of Logical Form
to know by reﬂection that his two beliefs about Paderewski are contradictory,
because he is not in a position to know by reﬂection the logical form of those
beliefs.12
As in the case of Londres, it is easy to see how Peter may fail to recognize an
argument as valid because he does not realize that two occurrences of ‘Paderewski’
refer to the same person. For example, the following argument seems valid:
[O]
(28) If Horowitz does not play Chopin, neither does Paderewski
(29) Paderewski plays Chopin
(30) Horowitz plays Chopin
But Peter cannot make this inference, as long as he supposes that the ﬁrst occurrence
of ‘Paderewski’ refers to the statesman while the second refers to the musician. As
in the case of [M], this fact can be explained in accordance with (N2). Since the two
occurrences of ‘Paderewski’ refer to the same person, [O] is adequately formalized
as follows:
[P]
(31)  Fb  Fa
(32) Fa
(33) Fb
However, Peter is not in a position to know that [O] instantiates [P], even though he
may know perfectly well that [P] is a valid form.
The rest of this section dwells on three objections that might be raised against
(N2). The ﬁrst goes as follows. According to (N2), both (34) and (35) are adequately
formalized as Fa:
(34) Hesperus is a star
(35) Phosphorus is a star
Consequently, we get that the following arguments are both formally valid:
[Q]
.34/ Hesperus is a star
.34/ Hesperus is a star
[R]
.34/ Hesperus is a star
.35/ Phosphorus is a star
This is an unwelcome result. [Q] and [R] are both valid, in the sense that they are
necessarily truth-preserving. But only [Q] should be classiﬁed as formally valid,
because only the validity of [Q] depends on purely structural properties of its
premise and conclusion.
This objection may be resisted. Contrary to what is usually believed, it is
questionable that [R] should not be classiﬁed as formally valid. Certainly, the
validity of [R] does not depend on purely structural properties of (34) and (35),
12MacFarlane (2004), p. 23, suggests a solution along these lines. Sainsbury and Tye (2012),
pp. 132–134, handles the puzzle in similar way, although it does not explicitly describe Peter’s
cognitive deﬁciency in terms of ignorance of logical form.

6.4
Distinct Names Must Denote Distinct Objects
79
in that it is not detectable from their syntactic or semantic structure. But this is
consistent with the claim that the validity of [R] depends on the logical form of (34)
and (35), if it is not assumed that the logical form of (34) and (35) is determined
by their syntactic or semantic structure. Of course, [R] signiﬁcantly differs from
[Q], in that in order to recognize that [R] is formally valid we need to know that
‘Hesperus’ and ‘Phosphorus’ refer to the same planet. However, as in the case of
‘Aristotle’ and ‘the Stagirite’, the crucial question is whether such difference matters
to formalization, and it is reasonable to say that it does not. Note also that it cannot
be contended that the truth-conditional view entails that formal validity reduces to
necessary truth preservation and so blurs the distinction between formal validity and
material validity, or between logical necessity and metaphysical necessity. As we
saw in Sect. 5.5, the truth-conditional view does not entail that all valid arguments
are formally valid. What it entails is at most that some necessarily truth preserving
arguments are formally tractable, which is something that anyone should accept.
The second objection goes as follows. If ‘Hesperus’ and ‘Phosphorus’ are
represented by a single individual constant a, as (N2) prescribes, the following
sentence has the form a D a:
(36) Hesperus is Phosphorus
More generally, every identity is expressed “by identity of the sign, and not by the
sign of identity”, to use Wittgenstein’s words. But then it is not clear what is the
point of having the symbol of identity.
This objection may also be resisted. First of all, note that (N2) does not rule out
that a D b is true in some model. L is absolutely standard from a semantic point
of view, as Sect. 3.1 shows, so it is simply false that distinct individual constants
denote distinct objects in every model. Even though the truth of such a formula in
some model is irrelevant for the purposes of formalization, it may be relevant for
other purposes. Moreover, and more importantly, the use of the symbol of identity
is not limited to formulas containing individual constants, such as a D b, given that
the symbol of identity can be combined with variables and complex terms which
include function symbols. To appreciate the importance of this fact, it sufﬁces to
think that Peano’s arithmetic is phrased by using one function symbol and one
individual constant, so the symbol of identity never occurs ﬂanked by distinct
individual constants.
The third objection goes as follows. Even if we grant the reply to the second
objection, we are left with Frege’s puzzle. Consider the following sentence:
(37) Hesperus is Hesperus
While one needs substantive empirical information to know that (36) is true, the
same does not hold for (37). But if (36) is formalized as a D a, it seems that no
account of this epistemic difference is provided, for both (36) and (37) turn out to
be trivially true in virtue of their form.
The reply to this objection is analogous to the reply to the objections considered
in Sect. 5.5. The claim that both (36) and (37) have the form a D a, so they are
true in virtue of that form, does not entail that both (36) and (37) are trivially true.

80
6
Logical Knowledge vs Knowledge of Logical Form
Since one needs substantive empirical information to know that ‘Hesperus’ and
‘Phosphorus’ refer to the same planet, one needs substantive empirical information
to know that (36) has the form a D a. The same does not hold for (37). So there is
an epistemic difference between (36) and (37), although it is not a difference that
can be expressed at the level of logical form.
6.5
Logical Knowledge
A crucial point that emerges from the cases presented in Sects. 6.3 and 6.4 is that
knowledge of logical form involves knowledge of reference. For any argument I ˛
that contains two occurrences of names n1 and n2, one can provide an adequate
formalization of I ˛ only if one knows whether n1 and n2 denote the same object
in the intended interpretation. This means that if one doesn’t know whether n1 and
n2 denote the same object in the intended interpretation, one is not in a position to
know the logical form of I ˛. Since one may easily lack knowledge of reference,
it may easily happen that one is not in a position to know the logical form of an
argument. Ignorance of logical form is a foreseeable possibility.
This, however, must not be regarded as a problem. First of all, it does not rule out
that in some cases, or even in most cases, we are in a position to know the logical
form of an argument. Of course, the possibility of being wrong about reference is
always there, so we can almost never be absolutely certain that an argument has a
given logical form. But knowledge does not require absolute certainty, or so it might
be argued. Similarly, knowledge does not require second-order knowledge, or so it
might be argued. Even if it is granted that we almost never know that we know that
an argument has a given logical form, it does not follow from this that we almost
never know that an argument has a given logical form.
Secondly, and more importantly, ignorance of logical form is consistent with
logical knowledge. One may fail to know that an argument instantiates a given valid
form even if one knows that that form is valid. Suppose that an argument I ˛ (in
its intended interpretation) is adequately formalized in L as I ˇ, and that I ˇ is a
valid form in the obvious sense that   ˇ. Suppose that a subject S has a perfect
mastery of ﬁrst order logic and knows that   ˇ. S may still fail to see that I ˛
(in its intended interpretation) is valid, because S is not in a position to know that
I ˛ (in its intended interpretation) is adequately formalized as I ˇ. In other words,
the logical information possessed by S is conditional: S knows that if an argument
instantiates I ˇ, then it is valid. But since S does not know whether I ˛ veriﬁes
the antecedent of the conditional, S is unable to tell whether it is valid.
The arguments [M] and [O] discussed in Sect. 6.4 provide a clear illustration of
this possibility. Although [M] is valid, Pierre is unable to see its validity, because
he is not in a position to know that it instantiates [N]. This is consistent with the
assumption that Pierre knows that [N] is a valid form. Similarly, although [O] is
valid, Peter is unable to see its validity, because he is not in a position to know that

6.6
Linguistic Competence and Rationality
81
it instantiates [P]. This is consistent with the assumption that Peter knows that [P] is
a valid form.
What holds for formal validity holds for formal invalidity. One may fail to know
that an argument instantiates a given invalid form even if one knows that that form is
invalid. Suppose that an argument I ˛ (in its intended interpretation) is adequately
formalized in L as I ˇ, and that  ² ˇ. Suppose that S is as before and knows
that  ² ˇ. S may still fail to see that I ˛ (in its intended interpretation) is invalid,
because S is not in a position to know that I ˛ (in its intended interpretation) is
adequately formalized as I ˇ.
The argument [E] discussed in Sect. 6.3 provides a clear illustration of this
possibility. Although [E] is invalid in that it instantiates [F], Peter is unable to see
its validity, because he is not in a position to know that it instantiates [F]. As far
as Peter knows, [E] instantiates a valid form in which the same individual constant
occurs both in the ﬁrst and in the second premise.
6.6
Linguistic Competence and Rationality
Just as ignorance of logical form is consistent with logical knowledge, it is con-
sistent with linguistic competence and rationality. Linguistic competence includes
syntactic competence, which is typically indicated by the capacity to distinguish
between grammatical and ungrammatical expressions, and semantic competence,
which is typically indicated by the capacity to grasp the meanings of the expressions
that occur in sentences and the way in which they are combined. It is often
assumed that semantic competence does not include knowledge of reference,
because knowledge of reference may require substantive empirical information. For
example, it is not necessary to know that ‘Hesperus’ and ‘Phosphorus’ refer to the
same planet in order to be semantically competent. Since knowledge of logical
form involves knowledge of reference, this means that ignorance of logical form
is consistent with linguistic competence.
Of course, linguistic competence may be deﬁned in more than one way, and it
is at least conceivable that semantic competence includes knowledge of the fact
that ‘Hesperus’ and ‘Phosphorus’ refer to the same planet. On the assumption that
linguistic competence is a gradable property, it might coherently be maintained that
the proper use of a sentence requires nothing but a reasonable degree of linguistic
competence, insofar as this does not rule out that there is a threshold below which an
utterance does not count as a proper use of that sentence. According to such a view,
what matters to language use is sufﬁcient competence rather than full competence.13
However, changing the deﬁnition of linguistic competence would not change
the substance of what has been said about ignorance of logical form. If semantic
13According to Wittgenstein (1992), 4.243, one cannot understand two names without knowing
whether they denote the same thing.

82
6
Logical Knowledge vs Knowledge of Logical Form
competence were so deﬁned as to include knowledge of the fact that ‘Hesperus’ and
‘Phosphorus’ refer to the same planet, then the cases in which one does not know
the logical form of a sentence in which ‘Hesperus’ and ‘Phosphorus’ occur could
be described as cases in which one is not fully competent. But since it had to be
granted that what matters to language use is sufﬁcient competence rather than full
competence, the point would remain that ignorance of logical form is consistent
with sufﬁcient competence.
The examples provided in Sects. 6.3 and 6.4 show how a linguistically competent
speaker can fail to know the logical form of an argument. Consider the case of
Pavarotti. The reason why Peter doesn’t know that the two occurrences of ‘Pavarotti’
refer to distinct individuals, which prevents him from knowing the logical form
of [E], is that he is unaware of his travel from earth to twin earth. Such lack of
information is clearly consistent with the assumption that Peter is linguistically
competent.
Similarly, consider the case of Paderewski. The reason why Peter doesn’t know
that the two occurrences of ‘Paderewski’ refer to the same individual, which
prevents him from knowing the logical form of [O], is that he is unaware that two
independent sets of properties he heard about belong to the same person. Again,
such lack of information is clearly consistent with the assumption that Peter is
linguistically competent.
Note that there is a crucial difference between the truth-conditional notion and
the syntactic notion. The former, unlike the latter, is not intended to provide an
explanation of how competent speakers grasp truth conditions. The method of
formalization suggested here does not imply that one has to “go through” the logical
form of a sentence s in order to grasp the truth conditions of s. On the contrary, it
is consistent with this method to hold that one can grasp the truth conditions of s
independently of any knowledge of the logical form of s. As we saw in Sect. 6.4,
the truth-conditional view leaves no room for transparency. The logical form of s, as
used on a given occasion, is not in principle detectable from the intrinsic properties
of s. This is to say that reﬂection or conceptual analysis may not sufﬁce. The
apprehension of the logical form of s may require substantive empirical information.
Let us now turn to rationality. Rationality may be deﬁned in different ways.
But one thing that is generally taken for granted about rationality is that it does
not entail infallibility or omniscience. Being rational does not prevent one from
having false beliefs, insofar as these beliefs are justiﬁed given one’s epistemic
condition. Therefore, it seems correct to assume that a subject S is rational if S
accepts arguments that are valid as far as S knows and does not accept arguments
that are invalid as far as S knows. On this assumption, if S falsely believes that an
argument is valid because S is not in a position to see that it instantiates an invalid
form, it is rational for S to accept the argument. Similarly, if S falsely believes that
an argument is invalid because S is not in a position to see that it instantiates a

6.6
Linguistic Competence and Rationality
83
valid form, it is rational for S to refrain from accepting the argument. In both cases,
ignorance of logical form is consistent with rationality.14
Consider again the case of Pavarotti. Peter accepts [E] because, as far as he
knows, [E] instantiates a valid form. He is justiﬁed in assuming that the two
occurrences of ‘Pavarotti’ in [E] refer to the same individual, because he has no
reason to believe that he has been switched from earth to twin earth. If we grant as
part of the description of the case that the very idea of switching has never occurred
to Peter, it would be entirely out of place for Peter to believe that he has been subject
to switching, just like it would be entirely out of place for any of us to believe such
a thing. Given the assumption that the two occurrences of ‘Pavarotti’ in [E] refer to
the same individual, it is correct to infer that [E] instantiates a valid form. So Peter
behaves rationally, in spite of the falsity of his beliefs.15
The case of Paderewski is analogous. Peter does not accept [O] because, as
far as he knows, [O] instantiates an invalid form. He is justiﬁed in assuming that
the two occurrences of ‘Paderewski’ refer to different individuals, since he has no
evidence of the contrary. Given the assumption that there are two individuals named
‘Paderewski’, it is correct to infer that [O] instantiates an invalid form. So Peter
behaves rationally, in spite of the falsity of his beliefs.16
Certainly, rationality might be so deﬁned as to rule out from the start the
possibility of ignorance of logical form. Boghossian envisages a deﬁnition along
these lines:
So, rationality is a function of a person’s ability and disposition to conform to the norms of
rationality on an a priori basis; and the norms of rationality are the norms of logic.17
For Boghossian, a rational subject must be able to know a priori the logical
properties of sentences. Accordingly, he takes the case of Pavarotti to exhibit a
tension between Peter’s apparent rationality and his incapacity to see that [E] is
invalid.
However, the issue can hardly be settled by deﬁnition. First of all, it is not
obvious that rationality should be deﬁned in terms of a priori knowledge of the
logical properties of sentences. The motivation for such a deﬁnition seems to come
at least in part from the acceptance of a transparency principle such as (T), which
is not warranted by the truth-conditional view. Moreover, even if rationality were so
deﬁned, it could still be maintained that there is a different but no less interesting
property – call it rationality* – which is understood along the lines suggested above
and is possessed by any intuitively blameless reasoner. Peter is rational*, in spite of
his incapacity to see that [E] is invalid. So the point would remain that ignorance of
logical form is consistent with rationality*.
14MacFarlane (2004), p. 22, aptly suggests that the normativity of logic is consistent with the
possibility that the logical form of an argument is not epistemically transparent.
15Here I follow Sainsbury and Tye (2012), p. 184.
16Here, again, I follow Sainsbury and Tye (2012), pp. 134–135.
17Boghossian (1994), p. 42.

Chapter 7
Validity
Abstract The suggestion that emerges from the discussion of the uniqueness thesis
is that two signiﬁcantly different notions of logical form may be contemplated: the
truth-conditional notion, which suits the logical role, and the syntactic notion, which
suits the semantic role. Since the suitability of the syntactic notion for the semantic
role is not in question, the best way to substantiate our suggestion is to develop the
idea that the truth-conditional notion fulﬁls the logical role. This chapter outlines an
account of validity that accords with the truth-conditional view. In order to show that
the account is independently justiﬁed, we will test it on three challenging problems:
the ﬁrst is the paradox of the sorites, the second concerns the fallacy of equivocation,
the third arises in connection with arguments affected by context sensitivity.
7.1
Interpretations of Arguments
Since natural language is vague, ambiguous, and context sensitive, as noted in
Sect. 2.4, an account of validity that applies to arguments in natural language must
deal with vagueness, ambiguity, and context sensitivity. This can be done if validity
is deﬁned in terms of interpretations of arguments understood as interpretations
of n-tuples of sentences. In order to spell out the notion of interpretation of an
argument, the notion of interpretation of a sentence may be deﬁned as follows:
Deﬁnition 7.1.1 An interpretation of a sentence s is an assignment of semantic
properties to the expressions of the language of s which is compatible with their
meaning and determines deﬁnite truth conditions for s.
For example, consider the following sentences:
(1) Tom is bald
(2) Tom goes to the bank
(3) Tom is there
An interpretation of (1) will assign a set of persons to ‘bald’, an interpretation of (2)
will provide a disambiguation for ‘bank’, and an interpretation of (3) will assign a
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_7
85

86
7
Validity
denotation to ‘there’. In other words, interpretations provide deﬁnite extensions for
vague expressions, ambiguous expressions, and context-sensitive expressions.
Note that the properties assigned to the expressions in s are semantic in a
somewhat loose sense. On the one hand, disambiguation is commonly regarded
as a “pre-semantic” process. In standard formal treatments of natural language,
the properties called “semantic” are assigned to nonambiguous lexical items at
the level of LF rather than to potentially ambiguous words at the level of surface
structure. On the other, many would say that contextual variation is “pragmatic” or
“post-semantic” rather than “semantic”, in that at least some effects of context on
truth conditions are not traceable to assignments of semantic values to elements of
LF. But such terminological issues may be left aside. All that matters for present
purposes is that the properties assigned to the expressions in s determine deﬁnite
truth conditions for s.
Note also that the semantic properties assigned to the expressions in s must be
compatible with the meaning of those expressions. For example, an assignment
according to which a person with 0 hairs does not belong to the set assigned to
‘bald’ is not admissible, given the way ‘bald’ is normally used. The same goes
for an assignment according to which ‘bank’ is read as ‘square root’, or for one
that includes an index whose value for ‘there’ is the speaker. In other words, an
admissible assignment provides a complete speciﬁcation of the truth conditions of s
in accordance with the meaning of the expressions in s.
Given Deﬁnition 7.1.1, truth in an interpretation can be deﬁned in the classical
way relative to a possible world. Consider (1). Let i an interpretation that assigns
Tom to ‘Tom’ and a set of persons to ‘bald’. For any world w, (1) will be true
in i in w if and only if Tom exists in w and belongs to that set. The truth of a
complex sentence depends on that of its constituents, in accordance with the usual
compositional rules. For example, if (1) is true in i in w and (2) is true in i in w, then
the conjunction of (1) and (2) will also be true in i in w. Moreover, bivalence holds
in any interpretation for any world: either (1) is true in i in w or it is false in i in w,
and the same goes for (2) or (3). As usual, the world parameter can be ignored when
the intended world is the actual world.
It is easy to see that interpretations so understood differ from models as deﬁned
in Sect. 3.1. In the case of interpretations the assignment of semantic properties to
the expressions of the language is assumed to be compatible with the meaning of
those expressions. By contrast, in the case of models there is no such constraint.
The only semantic constraints are imposed by the purported meaning of the logical
vocabulary. Moreover, interpretations determine truth conditions for the sentences
of the language. The truth values of interpreted sentences then depend on the worlds
in which they are evaluated. Instead, models determine truth values all at once.
Interpretations of arguments can be deﬁned in terms of interpretations of
sentences in accordance with the stipulation about n-tuples of sentences made in
Sect. 5.3. For any ﬁnite set of sentences  and any sentence ˛, there is an n-tuple of
sentences Ns such that fs1; : : : sn1g D  and sn D ˛. Therefore, an interpretation of
I ˛ is an interpretation of Ns, that is, an assignment of interpretations to s1; : : : sn. A
crucial feature of interpretations of arguments so deﬁned is that they are not required

7.2
Validity and Formal Validity
87
to be univocal: an interpretation of an argument that contains two sentences s1 and
s2 can include two interpretations i1 and i2 of s1 and s2 that differ as to an expression
that occur in s1 and in s2.
7.2
Validity and Formal Validity
Validity is basically a property of interpreted arguments. An argument is valid in an
interpretation when it necessarily preserves truth in the interpretation:
Deﬁnition 7.2.1 An argument I ˛ is valid in an interpretation i if and only if,
necessarily, if the sentences in  are all true in i then ˛ is true in i.
This deﬁnition may be regarded as a reﬁnement of Deﬁnition 1.1.2 that takes into
account the fact that sentences have truth conditions relative to interpretations.
There is also a derived sense in which validity can be ascribed to an argument,
the sense in which the argument is valid in a set of interpretations:
Deﬁnition 7.2.2 An argument I ˛ is valid in a set of interpretations I if and only
if, for every i 2 I, I ˛ is valid in i.
Validity simpliciter may be understood as validity in I for every I, that is, as validity
in all interpretations. As a matter of fact, validity simpliciter is not a criterion that
we adopt on all occasions. It is quite common to evaluate an argument having in
mind this or that way of understanding the expressions occurring in it. Therefore,
in many cases we assume that only a single interpretation or a restricted set of
interpretations is relevant to the evaluation. In other words, in many cases the
object of our evaluation is not really an argument but an interpreted argument or a
restricted set of interpreted arguments. Nonetheless, any argument can be considered
in isolation, by abstracting from the interpretations involved in its concrete use.
Validity simpliciter may be regarded as the property that is relevant at this level of
generality.
What holds for validity holds for formal validity. The idea that emerges from
the line of thought articulated in Chap. 4, 5, and 6 is that arguments instantiate
argument forms relative to interpretations. If  is a set of sentences, ˛ is a sentence,
 is a set of formulas and ˇ is a formula, then I ˛ instantiates I ˇ relative to
an interpretation i if and only if I ˛ is adequately formalized as I ˇ in i. So, an
argument can be deﬁned as formally valid in an interpretation:
Deﬁnition 7.2.3 An argument I ˛ is formally valid in an interpretation i if and
only if it instantiates a valid argument form in i.
The cases of ignorance of logical form discussed in Chap. 6 show clearly how an
argument can be formally valid in one interpretation but formally invalid in another
interpretation. Consider the case of Pavarotti. Peter takes the two occurrences of
‘Pavarotti’ in the following argument to refer to the same individual:

88
7
Validity
[A]
(4) Pavarotti once swam in Lake Taupo
(5) The singer I heard yesterday is Pavarotti
(6) The singer I heard yesterday once swam in Lake Taupo
But in the interpretation of [A] that seems correct, the ﬁrst occurrence of ‘Pavarotti’
refers to Pavarotti, while the second refers to twin Pavarotti. [A] is formally valid in
the ﬁrst interpretation, while it is formally invalid in the second:
[B]
(7) Fa
(8) 9x.Gx ^ 8y.Gy  y D x/ ^ x D a/
(9) 9x.Gx ^ 8y.Gy  y D x/ ^ Fx/
[C]
(7) Fa
(10) 9x.Gx ^ 8y.Gy  y D x/ ^ x D b/
(9) 9x.Gx ^ 8y.Gy  y D x/ ^ Fx/
Since Peter is unable to see that the two occurrences of ‘Pavarotti’ in [A] refer to
different individuals, he is unable to see that [A] instantiates [C]. As far as he knows,
[A] instantiates [B], so it is formally valid.
Now consider the case of Londres. Pierre believes that the names ‘Londres’ and
‘London’ in the following argument refer to different cities:
[D]
(11) If New York is pretty, so is Londres
(12) London is not pretty
(13) New York is not pretty
So in the interpretation of [D] that Pierre has in mind, [D] instantiates an invalid
form:
[E]
(14) Fb  Fa
(15)  Fc
(16)  Fb
But ‘Londres’ and ‘London’ refer to the same city, so the correct interpretation of
[D] is that in which [D] instantiates a valid form:
[F]
(14) Fb  Fa
(17)  Fa
(16)  Fb
The case of Paderewski is similar. The argument is formally invalid in one
interpretation but formally valid in another interpretation, and Peter falsely believes
that the ﬁrst interpretation is the right one.
As in the case of validity, there is a derived sense in which formal validity can be
ascribed to an argument, the sense in which the argument is formally valid in a set
of interpretations:

7.2
Validity and Formal Validity
89
Deﬁnition 7.2.4 An argument I ˛ is formally valid in a set of interpretations I if
and only if, for every i 2 I, it is formally valid in i.
Formal validity simpliciter may be understood as formal validity in I for every I,
that is, as formal validity in all interpretations. Note that what holds for formal
validity holds for logical consequence. It is usually assumed that the notion of
logical consequence deﬁned in Sect. 3.1 is extensionally correct in the sense that, for
any set of formulas  and any formula ˇ, I ˇ is a valid form expressible in L if and
only if   ˇ. On this assumption, we get that an argument I ˛ is formally valid
in an interpretation i if and only if ˛ is a logical consequence of  in i. Similarly, we
get that an argument I ˛ is formally valid in a set of interpretations I if and only if
˛ is a logical consequence of  in I.1
From Deﬁnitions 7.2.1–7.2.4 it turns out that formal validity entails validity, just
as we should expect. For any interpretation i, formal validity in i entails validity in
i. Suppose that I ˛ is formally valid in i. This means that I ˛ instantiates a valid
argument form in i. So it is necessary that, if the sentences in  are all true in i,
then ˛ is true in i. Similarly, for any set of interpretations I, formal validity in I
entails validity in I. Suppose that I ˛ is formally valid in I. This means that I ˛
instantiates a valid argument form in all interpretations in I. But for any i 2 I, if
I ˛ instantiates a valid argument form in i then it is impossible that  is true in i
and ˛ is false in i. Therefore, I ˛ necessarily preserves truth in all interpretations
in I.
The converse entailment is quite a different story. From Deﬁnitions 7.2.1
and 7.2.3 it does not follow that validity in a given interpretation entails formal
validity in that interpretation. Similarly, from Deﬁnitions 7.2.2 and 7.2.4 it does not
follow that validity in a given set of interpretations entails formal validity in that set
of interpretations. This is ﬁne. The question whether validity entails formal validity
has no clear answer, in that it depends on the tricky issue of whether there are cases
of necessary truth preservation that are not formally tractable. We saw that it is
consistent with the truth-conditional view to hold that the following argument is not
formally tractable:
[G]
(18) The sea is blue
(19) The sea is not yellow
Sometimes, cases such as this are dismissed by appealing to the indisputable
assumption that any formally invalid argument can be turned into a formally valid
one by adding some premise. Every argument of the form ˛I ˇ can be turned into
an argument of the form modus ponens by adding ˛  ˇ as a premise. But that
assumption must be handled with care. It is certainly right to say that, for every
formally invalid argument that is necessarily truth preserving, there is a formally
valid argument that is equivalent to it in some sense. Surely, whenever we can
1Kreisel (1967) provides an argument for the extensional correctness of Deﬁnition 3.1.8 that
depends on the completeness of ﬁrst order logic. See also Hanson (1997) and Gómez-Torrente
(2006).

90
7
Validity
ascribe [G] to a person, we can also ascribe to the same person an argument obtained
from [G] by adding ‘If the sea is blue then it is not yellow’ as a premise. However,
this is not the same thing as to say that every necessarily truth preserving argument
is formally valid. Even if a formally invalid argument can be turned into a formally
valid one by adding a given premise, it is still a formally invalid argument without
that premise.
7.3
The Sorites
The rest of this chapter is intended to show that the account of validity just outlined
is independently justiﬁed, in that it can proﬁtably be employed to handle three
distinct problems. The ﬁrst is the paradox of the sorites:
[H]
(20) 1000 grains make a heap
(21) If n grains make a heap, then n  1 grains make a heap
(22) 0 grains make a heap
Almost anyone would agree that there is something wrong with [H], because (20)
and (21) seem true, the step from (20) and (21) to (22) seems legitimate, but (22)
seems false. Since it is highly implausible to reject (20) or to accept (22), and
since it is hard to deny the validity of [H], the most natural option is to doubt (21).
However, it is not obvious why (21) should be rejected. (21) draws its appeal from
the vagueness of ‘heap’, which seems to justify the assumption that one grain cannot
make the difference between being a heap and not being a heap.
The solution that will be sketched here rests on the idea that the vagueness of a
language entails its capacity in principle to be made precise in more than one way.
For example, ‘bald’ does not have a deﬁnite extension, that is, there is no unique
set of objects to which it deﬁnitely applies. As is explained in Sect. 7.1, different
interpretations of a sentence in which ‘bald’ occurs determine different extensions
for ‘bald’. Each of them requires a precisiﬁcation of the language, that is, a precise
delimitation of the meaning of its expressions. In accordance with this idea, the
following assumption will be adopted:
(VP)
If an expression is vague, then it admits different precisiﬁcations.
Although (VP) is not universally accepted, is consistent with more than one view of
vagueness. In particular, it is consistent with supervaluationism, epistemicism, and
other views that differ both from supervaluationism and from epistemicism.2
2Supervaluationism is consistent with (VP) both in its standard version outlined in Fine (1975) and
in non-standard versions such as that provided in McGee and McLaughlin (1995). Epistemicism is
consistent with (VP) at least in the version advocated in Williamson (1994). Other views consistent
with (VP) are those suggested in Braun and Sider (2007) and in Iacona (2010a), which qualify as
neither supervaluationist nor epistemicist.

7.3
The Sorites
91
Given (VP), the paradox may be solved in accordance with Deﬁnition 7.2.1,
as is widely recognized. [H] is valid in every interpretation, for no matter how
the extension of ‘heap’ is delimited, it is impossible that (20) and (21) are true
and (22) is false. However, [H] is unsound in every interpretation, because every
interpretation falsiﬁes (21). Let i be an arbitrary interpretation of (21). Either (21)
is true in i or it is false in i, for bivalence holds in any interpretation. Since (21)
is equivalent to a list of 1000 conditionals, each of the conditionals in the list is
either true or false in i, hence the antecedent and the consequent of each of the
conditionals in the list are either true or false in i. This means that, for each of the
collections of grains in the series that goes from 1000 to 0, i determines whether
that collection belongs to the extension of ‘heap’. Moreover, i cannot determine that
every collection in the series is a heap, or that every collection in the series is not a
heap, for the admissibility condition on i requires that a collection of 1000 grains is
a heap according to i, and a collection of 0 grains is not a heap according to i. So
there must be a cut-off point in the series, a number n such that i determines that a
collection of n grains belongs to the extension of ‘heap’ while a collection of n  1
grains does not belong to it. It follows that one of the conditionals in the list is false
in i.
The intuitive appeal of (21) is due to the fact that we normally understand ‘heap’
without getting to the degree of precision required to falsify (21). Normally, ‘heap’
is understood in such a way that a collection of 1000 grains belongs to its extension,
while a collection of 0 grains does not belong to it. But such ways of understanding
‘heap’ do not involve a complete delimitation of its extension, that is, they are not
sensitive to differences of one grain. Normally, when we understand ‘heap’ in such
a way that a collection of n grains belongs to its extension, we do not have in mind
a delimitation which requires that a collection of n  1 grains does not belong to
it. Therefore, we tend to exclude the possibility that a collection of n grains is a
heap but a collection of n  1 grains is not a heap. In other words, what makes the
existence of a cut-off point for ‘heap’ unwelcome is that we normally do not ﬁx
such a point.3
One last thing must be noted. To say that [H] is valid in every interpretation is to
say that [H] is valid simpliciter, as it turns out from Deﬁnition 7.2.2. To borrow a
shared terminology, validity in this sense is “local” validity, as opposed to “global”
validity. A property of the latter kind could be deﬁned by saying that an argument
is valid just in case, necessarily, if its premises are true in all interpretations then
its conclusion is true in all interpretations. As has been widely shown, the adoption
of global validity leads to some problems with classical rules of inference, while
the same does not hold for local validity. This makes local validity preferable for
independent reasons.4
3Iacona (2010a) develops an account along these lines.
4See Williamson (1994), pp. 147–148, Keefe (2000), section 3, and Varzi (2007).

92
7
Validity
7.4
The Fallacy of Equivocation
The second problem stems from the following question: why is the fallacy of
equivocation a fallacy? It is common knowledge that an expression is used
equivocally when its intended meaning changes surreptitiously within a context,
and that an argument commits the fallacy of equivocation when it hinges on such a
shift of meaning. Here is a textbook example:
[I]
(23) The end of a thing is its perfection
(24) Death is the end of life
(25) Death is the perfection of life
[I] involves a confusion between two readings of ‘end’. One is suggested by (23),
which seems to say that the goal of a thing is its perfection. The other is suggested by
(24), which seems to say that death is the last event of life. Clearly, (23) and (24) so
construed provide no justiﬁcation for (25). But what is it that makes (I) fallacious?
An account of the fallacy of equivocation should explain why [I] is bad, due to an
equivocal use of ‘end’, and why it may seem good. Since it is plausible to assume
that here badness amounts to invalidity and goodness amounts to validity, this it to
say that an account of the fallacy of equivocation should explain why [I] is invalid,
and why it may seem valid. Contrary to what is commonly believed, the explanation
is far from obvious.5
One may be tempted to reason as follows. Since ‘end’ is ambiguous, the argument
expressed by [I] can be identiﬁed only by disambiguating (23) and (24). An
argument, properly speaking, is a set of propositions one of which is inferred from
the others. Thus if a sentence is used to phrase an argument on a given occasion,
the argument can be identiﬁed only by looking at the proposition expressed by
the sentence on that occasion. Let p.23/-p.25/ be the propositions expressed by
(23)–(25), and let [Ip] be the argument formed by p.23/-p.25/. Once it is clear that
[I] expresses [Ip], it becomes clear where the mistake is. Assuming that validity is
necessary truth preservation, [Ip] is invalid, since it is possible that p.23/ and p.24/
are true while p.25/ is false.6
However, this reasoning does not lead to the desired result. As long as [Ip]
is considered in isolation, that is, without taking into account the fact that it is
expressed by [I], there is no reason to describe [Ip] as an instance of the fallacy
of equivocation. Certainly, [Ip] is invalid. But it would be wrong to say that [Ip] is
invalid because it involves equivocality. There is no equivocality in [Ip]. Similarly,
5Logic textbooks do not help much in this sense, just as it happens with other fallacies. Usually,
logic textbooks introduce fallacies by drawing on a corpus of traditional examples accompanied
by standard comments. But in many cases it is not clear from the examples or from the comments
what is wrong with the argument.
6Fogelin and Sinnott-Armstrong (2001) provide an account of this kind. Note that it is not essential
to the account that the alleged real argument is deﬁned in terms of propositions. Any set of entities
– such as LFs – that ensure disambiguation will do.

7.4
The Fallacy of Equivocation
93
it would be wrong to say that [Ip] seems valid because it involves equivocality. [Ip]
does not even seem valid, at least no more than the argument obtained by replacing
p.24/ with the proposition that the earth is round. Apparently, the equivocality is
in [I], and this is why the fallacious argument seems to be [I] rather than [Ip]. So,
the fact that [Ip] is expressed by [I] must be taken into account in order to explain
how its invalidity may be concealed. But it is hard to see how this can be done
without abandoning the initial hypothesis that the fallacy of equivocation is a type
of argument. If the fact that [Ip] is expressed by [I] is essential for [Ip] to commit
the fallacy, then the fallacy does not lie in [Ip] itself but in that very fact. Were [Ip]
expressed by a set of sentences involving no equivocality, the fallacy wouldn’t occur.
This means that it is not the case that the fallacy occurs whenever [Ip] is expressed.7
A better account may be provided in accordance with Deﬁnition 7.2.1. Let [I1]
represent [I] on its intended reading, that is, on the reading that makes (23) and (24)
plausible:
[I1]
(23)1 The end1 of a thing is its perfection
(24)2 Death is the end2 of life
(25)1 Death is the perfection of life
(23)1 includes ‘end1’, which stands for ‘end’ read as ‘goal’. (24)2 includes ‘end2’,
which stands for ‘end’ read as ‘last event’. (25)1 includes neither of them, so there
is no difference between (25)1 and (25)2. The badness of [I] is explained by the fact
that [I1] does not necessarily preserve truth: (25)1 can be false even if (23)1 and
(24)2 are true. This is to say that [I] is invalid in the intended interpretation.8
The apparent goodness of [I] lies in its apparent validity. We are naturally apt to
read ‘end’ univocally in (23) and (24), that is, we are naturally apt to read [I] in one
of these two ways:
[I2]
(23)1 The end1 of a thing is its perfection
(24)1 Death is the end1 of life
(25)1 Death is the perfection of life
[I3]
(23)2 The end2 of a thing is its perfection
(24)2 Death is the end2 of life
(25)1 Death is the perfection of life
[I2] and [I3] are both valid, although (24)1 and (23)2 are highly implausible. The
reason why we are naturally apt to read ‘end’ univocally in (23) and (24) is that
we usually take univocality for granted. The question whether a set of sentences
containing ambiguous expressions is true is usually understood in terms of whether
7The same trouble arises if the fallacy is described in terms of a plurality of arguments disguised
as a single argument, as in Kirwan (1979) or in Woods and Walton (1979).
8The interpretation may be called ‘intended’ insofar as it makes plausible the premises of the
argument, but it is certainly not ‘intended’ in the sense that the proponent of the argument openly
recognizes the equivocality involved.

94
7
Validity
the sentences in it are all true on one and the same reading of those expressions.
Much less usual is to ask whether each of the sentences in the set is true on a different
reading of those expressions. Consider the following sentences:
(26) Visiting relatives can be boring
(27) Visiting relatives can be tiresome
Presumably, if one asks whether (26) and (27) are both true then either one wants
to know whether it can be boring and tiresome to visit relatives, or one wants to
know whether relative’s visits can be boring and tiresome. What one does not want
to know is, say, whether it can be boring to visit relatives but tiresome to receive
their visits. This is clear if we think that asking whether a set of sentences is true
amounts to asking whether their conjunction is true. Consider the following:
(28) Visiting relatives can be boring and visiting relatives can be tiresome
If one asks whether (28) is true, presumably one does not want to know whether
(26) and (27) are true on different readings of ‘visiting relatives’. Thus, when
an argument is under examination is natural to assume the following univocality
constraint:
(UC)
Any two occurrences of the same expression in an argument must be
interpreted in the same way.
In the case of [I], to assume (UC) is to restrict consideration to [I2] and [I3].
Therefore, [I] seems valid because it is valid in [I2] and [I3]. More generally, an
argument that commits the fallacy of equivocation is such that, for any univocal
interpretation, if its premises are true in that interpretation, then its conclusion must
be true in that interpretation.9
The account just outlined thus explains both the badness and the apparent
goodness of [I] in terms of the equivocal use of ‘end’. On the one hand, [I]
is bad because it is invalid in an interpretation that violates (UC), the intended
interpretation. On the other hand, [I] seems good because the violation of (UC)
may not be clear at ﬁrst sight, and this generates confusion between the intended
interpretation and those relative to which [I] is valid.
Note that the account also applies to the case of Pavarotti, since in that case
Peter commits a fallacy of equivocation. Consider again [D]. We saw that Peter
takes the two occurrences of ‘Pavarotti’ to refer to the same individual. But in
the interpretation of [D] that seems correct – the intended interpretation – the
ﬁrst occurrence of ‘Pavarotti’ refers to Pavarotti, while the second refers to twin
Pavarotti. The two interpretations may be represented as follows:
[D1]
(4)1 Pavarotti1 once swam in Lake Taupo
(5)1 The singer I heard yesterday is Pavarotti1
(6)1 The singer I heard yesterday once swam in Lake Taupo
9According to Church (1942), this is part of the very deﬁnition of the fallacy.

7.5
Context-Sensitive Arguments
95
[D2]
(4)1 Pavarotti1 once swam in Lake Taupo
(5)2 The singer I heard yesterday is Pavarotti2
(6)1 The singer I heard yesterday once swam in Lake Taupo
[D] is valid in the ﬁrst interpretation, just as it is valid in any interpretation that
satisﬁes (UC). However, [D] is invalid in the second interpretation, for (6)1 does not
follow from (4)1 and (5)2. Since Peter reasons in accordance with (UC), as is natural
to expect, he is inclined to read [D] as [D1] rather than as [D2].
7.5
Context-Sensitive Arguments
The third problem concerns arguments affected by context sensitivity. In Sects. 4.5
and 5.4 we considered an argument that contains two occurrences of the same
demonstrative:
[L]
(29) This is a philosopher
(29) This is a philosopher
Similar examples may be provided with indexicals:
[M]
(30) Socrates is walking now
(30) Socrates is walking now
Since (29) and (30) are context-sensitive sentences, it is legitimate to ask how this
affects the evaluation of [L] and [M]. Assuming that sentences containing indexicals
or demonstratives are true or false relative to indices, a standard way to deﬁne
validity, due to Kaplan, is the following:
(K) An argument I ˛ is valid if an only if, for any index, if the sentences in  are
all true relative to that index, ˛ must be true relative to that index.10
[L] and [M] are valid according to (K), because any index that makes their premise
true makes their conclusion true.11
However, as Sect. 4.5 shows, this strategy runs into a serious objection. If e is
a context-sensitive expression that occurs in an argument I ˛, there may be cases
in which the inference from  to ˛ is plausibly assessed as correct, or incorrect,
on a non-univocal reading of e. [L] is plausibly assessed as invalid if different
individuals are demonstrated, as in case 6 of Sect. 4.5. Similarly, [M] is plausibly
assessed as invalid if ‘now’ refers to different times: Socrates may be walking at
the time referred to in the premise but not at the time referred to in the conclusion.
10This deﬁnition goes back to Kaplan (1977). Predelli (2005), p. 83, and Braun (2001), Sect. 3.3,
regard (K) as “intuitive”.
11To be precise, [L] is valid according to (K) only insofar as the two occurrences of ‘this’ are
treated as occurrences of the same demonstrative (see Sect. 4.6).

96
7
Validity
A deﬁnition of validity that aims at the highest degree of generality should take into
account such cases, that is, it should imply that an argument I ˛ is valid only if the
inference from  to ˛ is always correct. (K) seems to entail that [L] and [M] are
valid even though the inference it involves is not always correct.12
The alternative route suggested here is that [L] and [M] are invalid, because
there are interpretations in which they are invalid. Two points must be clear
about this suggestion. The ﬁrst is that it does not depend on the assumption that
validity simpliciter is the best criterion for the assessment of arguments affected
by context sensitivity. As is explained in Sect. 7.2, it is quite common to evaluate
an argument having in mind this or that way of understanding the expressions
occurring in it. So it might coherently be argued that the primary criterion or the
most appropriate criterion for the assessment of arguments affected by context
sensitivity is validity relative to an interpretation. This is ﬁne, because our primary
deﬁnition is Deﬁnition 7.2.1. But since the standard route relies on (K), which is
a deﬁnition of validity simpliciter, we will rely on Deﬁnition 7.2.2 for the sake of
argument. The leading idea will be that validity consists in the capacity to guarantee
that truth is necessarily preserved no matter how those expressions are understood
in the relevant context.
The second point is that the route suggested here requires no departure from
classical logic. Kaplan has argued that if we allow that [L] and [M] are invalid due
to the possibility of index-shifts, then we get the undesirable result that the forms
they instantiate are invalid:
Thus even the most trivial of inferences, P therefore P, may appear invalid.13
Many would be willing to agree with Kaplan on the claim that [L] and [M] are valid,
in that they instantiates a valid form. Or at least, many would accept the following
conditional:
(31) If ˛I ˛ is a valid form, then [L] and [M] are valid.
Yagisawa has proposed an alternative account of validity that is consistent with (31):
he claims that [L] and [M] are invalid, for the reason considered, so that ˛I ˛ is
not a valid form. Therefore, Kaplan and Yagisawa seem to agree on the following
dilemma: either one claims that [L] and [M] are valid and maintains that ˛I ˛ is a
valid form, or one claims that [L] and [M] are invalid and denies that ˛I ˛ is a valid
form.14
This dilemma rests on (31). Without (31), the hypothesis that [L] and [M] are
invalid cannot be ruled out by contraposition, so Kaplan’s argument collapses.
12The problem surfaces in Kaplan (1989), pp. 586–587, and is addressed in Yagisawa (1993) and in
Georgi (2015). Here ‘non-univocal’ is not to be read as synonymous with ‘equivocal’. Equivocality
entails non-univocality, but it is not entailed by it. The two cases considered involve a non-univocal
use of a word, yet it is inappropriate to call that use equivocal.
13Kaplan (1989), pp. 584–585.
14Yagisawa (1993). Again, in the case of [L] the ascription of the form ˛I ˛ depends on the
assumption that one and the same demonstrative is involved.

7.5
Context-Sensitive Arguments
97
Similarly, Yagisawa’s departure from standard logic becomes unnecessary, for the
invalidity of the form ˛I ˛ is not a consequence of that hypothesis. However, it
is consistent with Deﬁnition 5.3.1 to deny (31). Let it be granted that ˛I ˛ is a
valid form. On the assumption that logical forms belong to arguments relative to
interpretations, this is to say that no argument has the form ˛I ˛ in an interpretation
but is invalid in that interpretation. Therefore, the supposition that ˛I ˛ is a valid
form is consistent with the claim that [L] and [M] are invalid in an interpretation
that involves some index-shift, for in such interpretation [L] and [M] do not have
the form ˛I ˛. Since validity simpliciter may be understood as validity in all
interpretations, the supposition that ˛I ˛ is a valid form is equally consistent.15
Since the account suggested here entails that [L] and [M] are invalid, it does not
have to deal with the problem outlined at the beginning of this section. What it has
to deal with, instead, is the rationale behind (K): there is something in [L] and [M]
that we tend to perceive as trivially correct, so it is natural to ask what it is. An
answer to this question may be given in terms of the constraint (UC) considered in
Sect. 7.4. When an argument containing context-sensitive expressions is considered,
it is quite common to assume that those expressions are understood in the same way.
Since the argument is valid relative to any such interpretation, we get an impression
of trivial correctness. In other words, what we perceive is that [L] and [M] are valid
relative to any set of interpretations that satisfy (UC).16
The property deﬁned in (K) may be understood as the result of combining
Deﬁnition 7.2.2 with (UC). Since in most case we assume (UC), in most cases we
evaluate arguments such as [L] and [M] by considering only interpretations that
satisfy (UC). This is equivalent to evaluating them in terms of truth preservation for
all indices, for (UC) rules out index shifts. So the property deﬁned in (K) is perfectly
intelligible. In this sense there is nothing wrong with it. What is wrong, according
to the account suggested here, is to identify it with validity.
15Iacona (2010b) provides a more thorough discussion of the standard view.
16Yagisawa (1993), p. 483, treats (UC) as a pragmatic principle that does not belong to logic.

Chapter 8
Quantiﬁed Sentences
Abstract The thesis that the logical role and the semantic role require two different
notions of logical form has a negative and a positive side. The negative side, as
we have seen, is that a deep-rooted presumption turns out to be overly optimistic:
there is no unique notion that suits both roles. The positive side is that the
distinction between the two notions, once properly spelled out, sheds light on
some fundamental issues concerning the relation between logic and language. This
chapter illustrates the positive side by showing how the truth-conditional notion and
the syntactic notion diverge with respect to the analysis of quantiﬁed sentences.
As will be suggested, a full understanding of this divergence discloses a new
perspective on the issue of quantiﬁcation, which has always been at the core of
any thorough reﬂection on logical form.
8.1
Two Questions About Quantiﬁed Sentences
The question of what is the logical form of quantiﬁed sentences may be construed
in two ways:
(Q1) How are quantiﬁed sentences to be formally represented in order to account
for the inferences involving them?
(Q2) How are quantiﬁed sentences to be formally represented in order to provide a
compositional account of their meaning?
Those who accept the uniqueness thesis are apt to think that there is a close
connection between (Q1) and (Q2), in that the same notion of logical form can
provide an answer to both. Here, instead, it will be suggested that (Q1) and (Q2) are
to a large extent independent: the truth-conditional notion is appropriate when the
question to be addressed is (Q1), while the syntactic notion is appropriate when the
question to be addressed is (Q2). So there is no univocal answer to the question of
what is the logical form of quantiﬁed sentences.
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_8
99

100
8
Quantiﬁed Sentences
Let us begin by presenting two ways of thinking that share the assumption that
(Q1) and (Q2) are closely connected: one is old, the other is new. According to the
old way of thinking, which goes back to Frege, (Q1) is prior to (Q2), in that the
notion of logical form that proves adequate to address (Q1) also provides an answer
to (Q2). Consider the following sentences:
(1) All philosophers are rich
(2) Aristotle is rich
As is explained in Sect. 2.1, Frege suggested that there is a crucial difference
between (1) and (2): although (1) is superﬁcially similar to (2), its logical form
substantially differs from that of (2). This difference turns out clear when we
represent (1) and (2) in L:
(3) 8x.Px  Rx/
(4) Pa
Moreover, he regarded the logical analysis that leads to (3) as a guide to a
compositional account of the meaning of (1). So the idea was that, once we have
an answer to (Q1), we also get an answer to (Q2).
This way of thinking is questionable for at least two reasons. First, it is not
clear how (3) can ﬁgure as part of a compositional account of the meaning of
(1), given that it does not explain the apparent semantic analogy between (1)
and (2). (1) contains a noun phrase, ‘all philosophers’, which in many respects
resembles ‘Aristotle’, while it does not contain the expression ‘if then’. There is
a patent mismatch between the sentential constituents of a quantiﬁed sentence and
the constituents of its standard representation in L.1
Second, even assuming that (3) is the real structure of (1), in spite of such
disanalogies, the question remains of how can we provide a compositional account
of (3). As Sect. 3.1 shows, if we follow Tarski’s method we can deﬁne the truth of
8x˛ in terms of the satisfaction conditions of ˛. However, this does not mean that
a semantics based on Tarski’s method is compositional. According to the principle
of compositionality, phrased in Sect. 3.2, if an expression e is formed by combining
two expressions e1 and e2, the meaning of e results from the combination of the
meaning of e1 with the meaning of e2. Since 8x˛ is formed by adding 8x to ˛, in
order for this condition to be satisﬁed the truth value of 8x˛ should result from the
combination of the meaning of 8x with the meaning of ˛. But it is consistent with
the deﬁnitions outlined in Sect. 3.1 to say that 8x, unlike ˛, does not have meaning
in isolation.
Note that no clear solution to this problem can be found in Frege’s notion of
second-level function. One might be tempted to say that 8x denotes a second-
level function Everything, so that the truth value of 8x˛ is obtained by combining
Everything with the meaning of ˛. But this is not a viable route. Let 8x˛ be 8xPx
and consider a variable y distinct from x. Do 8x and 8y denote the same function?
1Barwise and Cooper (1981), p. 165, emphasizes this mismatch.

8.1
Two Questions About Quantiﬁed Sentences
101
On the one hand, it seems that they should. If two functions assign the same values
to the same arguments, as it happens in this case, they are the same function. On the
other, however, it seems that they should not. If 8x and 8y have the same meaning,
then their meaning must be combinable in the same way with the meanings of other
expressions. But 8yPx cannot have the same meaning as 8xPx.
Alternatively, one might be tempted to say that 8 denotes the second-level
function Everything, while x does not have meaning in isolation. In other words,
the two occurrences of x in 8xPx allow the combination of the meaning of 8 with
the meaning of P, while such combination does not occur in 8yPx. In this case one
might consistently hold that there is a unique second-level function, Everything,
which can be combined with different ﬁrst-level functions in quantiﬁed sentences.
However, one would have to accept that 8 and P are not directly combinable, in that
they require expressions that do not have meaning in isolation. So we would be back
to the starting point, that the account is not rigorously compositional.
According to the new way of thinking, which is currently accepted within the
formal approach to natural language, (Q2) is prior to (Q1), in that the notion of
logical form that proves adequate to address (Q2) also provides an answer to (Q1).
As Sect. 4.3 explains, the LF of (1) and (2) may be represented as follows in order
to provide a compositional account of their meaning:
(5) [Every philosopher1[t1 is rich]]
(6) [Aristotle[is rich]]
In addition to this, many tend to think that the inferences involving (1) must be
explainable in terms of (5). This is why now it is quite common to claim, against
Frege, that the logical form of (1) does not substantially differ from that of (2).
However, the new way of thinking faces other problems. As Chaps. 4 and 5
show, it is not obvious that a notion of logical form deﬁned in terms of LF is able
to formally explain the logical properties of (1). The point may be illustrated by
recalling an example considered in Sect. 4.5. Suppose that you utter (1) with the
intention to assert that all the philosophers in the university U are rich, while I utter
the following sentence with the intention to assert that some philosophers in the
university U0 are not rich:
(7) Not all philosophers are rich
There is an obvious sense in which we are not contradicting each other. But if the
formal representation of (1) and (7) does not take into account the content they
express, the apparent absence of contradiction is not formally explained.
The old way of thinking and the new way of thinking agree on the uniqueness
thesis, as they both take for granted that the same notion of logical form can provide
answers to both (Q1) and (Q2). But we saw that the uniqueness thesis is ungrounded.
In what follows we will explore a third line of thought, according to which (Q1) and
(Q2) can be addressed on the basis of different notions, the truth-conditional notion
and the syntactic notion. As is natural to expect, we will focus on (Q1), assuming
that there is plenty of evidence in support of the claim that the syntactic notion may
proﬁtably be adopted to address (Q2).

102
8
Quantiﬁed Sentences
8.2
Quantiﬁers
Let us start with some terminology. First of all, as in the foregoing chapters, the term
‘quantiﬁer expression’ will be used to refer to expressions such as ‘all’ or ‘some’,
which occur in noun phrases as determiners of nominal expressions. In accordance
with this use, we will restrict attention to simple quantiﬁed sentences that contain
expression of this category, such as (1) or the following:
(8) Some philosophers are rich
Although this is a very restricted class of sentences, it is sufﬁciently representative
to deserve consideration on its own. Besides, most of what will be said about the
members of this class can be extended to more complex quantiﬁed sentences.
Second, the term ‘domain’ will be used to refer to the totality of things over which
a quantiﬁer expression is taken to range. In ordinary talk, quantiﬁer expressions
often carry a tacit restriction to a set of contextually relevant objects. For example,
on one occasion (1) may be used to assert that all philosophers in the university U
are rich, while on another occasion it may be used to assert that all philosophers in
the university U0 are rich. So it is plausible that in the ﬁrst case ‘all’ ranges over a set
of people working or studying in U, while in the second it ranges over a set of people
working or studying in U0. In order to take into account such contextual restrictions
it will be assumed that, whenever a quantiﬁer expression is used, some domain is
associated with its use, that is, the domain over which the quantiﬁer expression is
taken to range.
One thing that must be clear about this assumption is that it leaves unsettled
the question of how the restriction is determined in the context. To appreciate its
neutrality, it will sufﬁce to consider a debated issue which divides semantic accounts
of domain restriction. According to such accounts, domains are represented by some
sort of variable or parameter in the noun phrase. But it is controversial where exactly
the variable or parameter is located. For example, Westerståhl suggests that it is in
the determiner, while Stanley and Szabo suggests that it is in the noun. The picture
sketched in this chapter is compatible with both options, as it does not concern the
syntactic structure of quantiﬁed sentences.2
Another thing that must be clear about the assumption that quantiﬁer expressions
are used in association with domains is that it does not entail that, whenever one
uses a quantiﬁer expression, one has in mind a deﬁnite set of contextually relevant
objects. As a matter of fact, that almost never happens. Most of the time, the use of
a quantiﬁer expression involves either a partial or approximate speciﬁcation of a set,
2Westerståhl (1985a), Stanley and Szabo (2000). For simplicity we will not consider pragmatic
accounts of domain restriction, that is, accounts on which the determination of domains is left to
pragmatic factors that determine the communicated content as distinct from what is literally said,
such as that provided in Bach (1994, 2000).

8.2
Quantiﬁers
103
or no speciﬁcation at all. In the ﬁrst case no unique set is speciﬁed, in that the use
of the quantiﬁer expression is compatible with many such sets. In the second, no set
at all is speciﬁed, in that nothing is excluded as irrelevant.
Third, the term ‘quantiﬁer’ will be used to refer to functions from domains to
binary relations. Accordingly, the meaning of ‘all’ may be deﬁned as a quantiﬁer all,
that is, as a function that, for any domain D, denotes a binary relation that satisﬁes
the following condition:
Deﬁnition 8.2.1 allD.A; B/ if and only if A  B.
Here A and B are sets whose members belong to D, and the left-hand side is read as
‘the relation denoted by ‘all’ relative to D obtains between A and B’.
The meaning of ‘some’ may be deﬁned in similar way as a quantiﬁer some, that
is, as a function that, for any D, denotes a binary relation that satisﬁes the following
condition:
Deﬁnition 8.2.2 someD.A; B/ if and only if A \ B ¤ ;.3
The relativization to domains involved in Deﬁnitions 8.2.1 and 8.2.2 accounts for
the fact that the extension of a quantiﬁer expression may vary from occasion to
occasion, even though its meaning does not change. If e is a quantiﬁer expression
that means Q, then QD is the extension of e relative to D. Thus if D is a set of
people working or studying in U and D0 is a set of people working or studying
in U, ‘all’ denotes different relations relative to D and D0. So there is a sense in
which ‘all’ means the same thing on both occasions, yet the relations denoted differ.
The same goes for ‘some’. More generally, a distinction may be drawn between
global quantiﬁers and local quantiﬁers, that is, between quantiﬁers as functions from
domains to binary relations and quantiﬁers as values of such functions. If Q is a
global quantiﬁer and D is a domain, then QD is the local quantiﬁer assigned by Q to
D.4
If the meaning of quantiﬁer expressions is deﬁned in the way outlined, and it is
assumed that nominal expressions denote sets, the meaning of quantiﬁed sentences
is easily obtained by composition. Let A and B be sets denoted by ‘philosophers’
and ‘rich’ relative to D. For example, if D is a set of people working or studying in
U, A and B are subsets of that set. Given Deﬁnition 8.2.1, allD ﬁxes truth conditions
for (1) relative to D, that is, (1) is true if and only if A  B. So the meaning of (1)
may be described as a function from domains to truth conditions that results from
the combination of all with the meanings of ‘philosophers’ and ‘rich’. The case of
(8) is similar. Assuming that A and B are sets denoted by ‘philosophers’ and ‘rich’
relative to D, the meaning of (8) may be described as a function from domains to
3This is a standard deﬁnition, as in Peters and Westerståhl (2006), pp. 62–64.
4The distinction between global quantiﬁers and local quantiﬁers is drawn in Peters and Westerståhl
(2006), p. 48.

104
8
Quantiﬁed Sentences
truth conditions that results from the combination of some with the meanings of
‘philosophers’ and ‘rich’. More generally, the meaning of a quantiﬁed sentence s
that contains a quantiﬁer expression e that means Q is a function from domains to
truth conditions that is obtained by combining Q with the meaning of the nominal
expressions in s. The value of the function for each D is determined by QD, that is,
by the local quantiﬁer assigned by Q to D.
8.3
Meaning and Truth Conditions
The account of the meaning of quantiﬁed sentences just outlined can be combined
with the truth-conditional view. The hypothesis that will now be adopted is that
quantiﬁed sentences are adequately formalized in L by assigning them formulas
that represent their contents relative to interpretations. This is to say that quantiﬁed
sentences have logical form in virtue of their truth conditions.
To illustrate, consider (1). As it turns out from Sect. 8.2, (1) can be understood
in more than one way. The simplest case is that in which (1) is used without
restriction on the domain. Recall that the assumption that quantiﬁer expressions
are used in association with domains does not entail that, whenever one uses a
quantiﬁer expression, one has in mind a deﬁnite set of contextually relevant objects.
It is consistent with that assumption to say that there are contexts in which nothing
is excluded as irrelevant. The following formula represents (1) as used in such a
context, if P stands for ‘philosopher’ and R stands for ‘rich’:
(9) 8x.Px  Rx/
In order to deal with a context in which some things are excluded as irrelevant,
instead, P can be read as including the intended restriction. Suppose that (1) is used
to assert that all philosophers in U are rich. In this case (1) can be represented
as (9), where P stands for ‘philosopher in U’. So if two utterances of (1) differ
in the intended restriction on the domain, they may be represented by means of
different predicate letters. Suppose that (1) is used in one context to assert that all
philosophers in U are rich and in another context to assert that all philosophers in
U0 are rich. This difference may be represented in terms of the difference between
(9) and the following formula:
(10) 8x.Qx  Rx/
Here Q stands for ‘philosopher in U0’. Note that (9) and (10) are analogous to Fa and
Fb (see Sect. 5.3). On the one hand, (9) and (10) represent different contents insofar
as P and Q stand for different conditions. On the other, (9) and (10) are formulas
of the same kind, in that they differ only for a predicate letter. In this sense it is
plausible to say that they express the same logical form.

8.4
The Issue of First Order Deﬁnability
105
8.4
The Issue of First Order Deﬁnability
A major implication of the thesis that quantiﬁed sentences have logical form in
virtue of their truth conditions concerns a fact that is usually regarded as decisive
for the issue of the expressive power of ﬁrst order logic. The fact is that some
quantiﬁer expressions are not ﬁrst order deﬁnable, in the sense that they do not
denote quantiﬁers that satisfy the following condition:
Deﬁnition 8.4.1 A quantiﬁer Q is ﬁrst order deﬁnable if and only if there is a
formula ˛ of L containing two unary predicate letters such that, for every set D
and A; B  D, QD.A; B/ if and only if ˛ is true in a model with domain D where the
predicate letters in ˛ denote A and B.
Here ‘two’ means ‘exactly two’. As is easy to verify, ‘all’ is ﬁrst order deﬁnable,
because (9) is a formula of L containing two unary predicate letters such that, for
every set D and A; B  D, allD.A; B/ if and only if (9) is true in a model with domain
D where its predicate letters denote A and B. The same goes for ‘some’, given that
(8) can be represented as follows:
(11) 9x.Px ^ Rx/
However, not all quantiﬁer expressions are like ‘all’ and ‘some’. Consider the
following sentence, which contains the quantiﬁer expression ‘more than half of’:
(12) More than half of philosophers are rich
The quantiﬁer more than half of may be deﬁned as a function that, for any D,
denotes a binary relation that satisﬁes the following condition:
Deﬁnition 8.4.2 more than half ofD.A; B/ if and only if j A \ B j> 1=2 j A j
Although this deﬁnition differs from Deﬁnitions 8.2.1 and 8.2.2 in that it involves
a proportional relation that applies to the cardinality of A and B, more than half of
is a function from domains to binary relations exactly like all and some. So (12) is
semantically similar to (1) and (8), in that it is formed by expressions of the same
semantic categories combined in the same way. However, there is no formula of L
that translates (12) in the same sense in which (9) and (11) translate (1) and (8). This
means that ‘more than half of’ is not ﬁrst order deﬁnable.5
Many are inclined to think that this fact constitutes a serious limitation of the
expressive power of ﬁrst order logic. If it is assumed that formalization is a matter
of translation, understood as meaning preservation, then it is natural to think that
there is no way to formalize (12) in L. More generally, one may be tempted to think
that a quantiﬁed sentence can be formalized in L only if the quantiﬁer expressions
it contains are ﬁrst order deﬁnable.6
5Barwise and Cooper (1981), pp. 213–214, provides a proof of the ﬁrst order undeﬁnability of
‘more than half of’.
6As in Barwise and Cooper (1981), p. 159.

106
8
Quantiﬁed Sentences
Without that assumption, however, there is no reason to think that the ﬁrst order
undeﬁnability of more than half of’ rules out the possibility that (12) is formalized
in L. Certainly, it undermines the claim that there are sentences of L that have the
same meaning as (12). But if logical form is determined by truth conditions, such a
claim makes little sense anyway, even in the case of (1) and (8), for formalization is
representation of content rather than translation.
Instead of asking whether a quantiﬁer expression is ﬁrst order deﬁnable, one may
ask whether it is ﬁrst order expressible in the sense that it denotes a quantiﬁer that
satisﬁes the following condition:
Deﬁnition 8.4.3 A quantiﬁer Q is ﬁrst order expressible if and only if, for every set
D and A; B  D, there is an adequate formula ˛ of L containing two unary predicate
letters such that QD.A; B/ if and only if ˛ is true in a model with domain D where
the predicate letters denote A and B.
The sense in which ˛ is required to be adequate is the same sense in which a
formalization is expected to be adequate: ˛ must represent what is said, relative
to D, by a sentence that contains a quantiﬁer expression that denotes Q and two
predicates for A and B. Of course, adequacy is a vague notion, so it can hardly be
phrased in formal terms. But this does not prevent Deﬁnition 8.4.3 from playing a
role analogous to that of Deﬁnition 8.4.1. If one takes a case in which the notion of
adequacy deﬁnitely applies, and in which it is provable that the rest of the conditions
that constitute ﬁrst order expressibility are satisﬁed, then one can rightfully conclude
that Deﬁnition 8.4.3 applies. This is just the kind of case at issue. The formulas that
will be considered in our reasoning may be regarded as clear cases of adequacy.
To see how adequacy matters, it sufﬁces to think that a trivial proof of the
existence of ˛ can be provided if no such condition is imposed on ˛. It is easy to
ﬁnd some ˛ that has the required truth value in the model for independent reasons.
For example, if QD.A; B/ and ˛ is a logical truth, then QD.A; B/ if and only if ˛ is
true in the model. However, it is clear that in this case ˛ is not adequate. The same
goes for similar trivial proofs of the existence of ˛. What is not trivial, instead, is to
prove the existence of an adequate ˛. As will be shown, ‘more than half of’ is ﬁrst
order expressible, in that for every D and A; B  D, there is an adequate sentence ˛
of L containing two predicate letters such that more than half of D.A; B/ if and only
if ˛ is true in a model with domain D where the predicate letters denote A and B.
The adequacy assumption that will be made in order to prove that ‘more than
half of’ is ﬁrst order expressible is that, if what is said by s relative to D is that at
least n As are Bs, then a formula of L that contains n occurrences of 9 followed by
two unary predicates P and R can provide an adequate representation of s. Such a
formula will be indicated as follows:
(13) 9nx.Px ^ Rx/
For example, suppose that D includes some persons, and that three of them are
philosophers. Then what is said by (12) relative to D is that at least two philosophers
are rich, which is adequately represented by the formula 9x9y.Px ^ Qx ^ x ¤ y/.

8.4
The Issue of First Order Deﬁnability
107
A further assumption that will be made is that A and B are ﬁnite, as is natural
to expect given that ‘more than half of’ is normally used to state relations between
ﬁnite quantities. This is not to deny that ‘more than half of’ can be used in some
intelligible way for inﬁnite domains. Presumably, some technical or semi-technical
meaning can be speciﬁed for that purpose. However, inﬁnitary uses of ‘more than
half of’ will not be considered here. Independently of how such uses relate to the
ordinary understanding of the expression, the reasoning simply will not apply to
them.7
Given these two assumptions, the ﬁrst order expressibility of ‘more than half of’
can be proved as follows.
Theorem 8.4.1 For every D and A; B  D, there is an adequate formula ˛ of L that
contains two unary predicate letters such that more than half ofD.A; B/ if and only
if ˛ is true in a model with domain D where the predicate letters denote A and B.
Proof First of all, it will be shown that, if A; B  D, there is an n such that j B j>
1=2 j A j if and only if j B j n. Let F be a function deﬁned as follows. If m D 0,
then F.m/ D 1. If m > 0 and m is even, then
F.m/ D m C 2
2
If m > 0 and m is odd, then
F.m/ D m C 1
2
Let j A jD m and n D F.m/. n is such that j B j> 1=2 j A j if and only if j B j n.
Suppose that m D 0. Then 1=2 j A jD 0 and F.m/ D 1, so j B j> 0 if and only if
j B j 1. Suppose that m > 0 and m is even. Then there is a k such that m D 2k,
hence j B j> 1=2 j A j if and only if j B j> k. Moreover,
F.m/ D m C 2
2
D 2k C 2
2
D 2.k C 1/
2
D k C 1
Therefore, j B j> k if and only if j B j k C 1. Finally, suppose that m > 0 and m
is odd. Then there is a k such that m D 2k C 1, hence j B j> 1=2 j A j if and only if
j B j> k C 1=2. By hypothesis, j B j is a natural number, so j B j> k C 1=2 if and
only if j B j> k. Moreover,
F.m/ D m C 1
2
D 2k C 1 C 1
2
D 2.k C 1/
2
D k C 1
Therefore, j B j> k if and only if j B j k C 1.
7Barwise and Cooper (1981), p. 163, consider inﬁnitary uses of ‘more than half of’.

108
8
Quantiﬁed Sentences
Once it is shown that, if A; B  D, there is an n such that j B j> 1=2 j A j if
and only if j B j n, replacing B with A \ B it turns out that there is an n such that
j A \ B j> 1=2 j A j if and only if j A \ B j n. So, by Deﬁnition 8.4.2 there is an
n such that more than half of D.A; B/ if and only if j A \ B j n. The condition that
j A \ B j n is adequately expressed in L by (13). Moreover, (13) is true in a model
with domain D where P and R denote A and B, and more than half the As are Bs.8
In other words, although more than half of is characterized by a proportional
relation, more than half of D ﬁxes a non-proportional relation expressible in L for
each D. Theorem 8.4.1, accordingly, “squeezes” a proportional relation on a set of
non-proportional relations. So we get that, for any interpretation, (12) has a logical
form representable in L relative to that interpretation.
8.5
Two Kinds of Formal Variation
From what has been said so far it turns out that a quantiﬁed sentence can be
represented by different formulas in different interpretations. But there are basically
two ways in which the representation of a quantiﬁed sentence can vary as a function
of its interpretation. Consider (1) and (12). In Sect. 8.3 we saw that the following
formulas can represent (1) in different interpretations:
(9) 8x.Px  Rx/
(10) 8x.Qx  Rx/
Similarly, Sect. 8.4 shows how the following formulas can represent (12) in different
interpretations:
(14) 93x.Px ^ Rx/
(15) 94x.Px ^ Rx/
In the second case the difference seems more substantial: one thing is to say that
more than half of ﬁve things have a certain property, quite another thing is to say
that more than half of six things have that property.
The difference between these two kinds of variation may be spelled out in terms
of a notion of minimality based on the understanding of adequate formalization
suggested in Sect. 5.3. In order to adequately formalize a sentence s in a given
interpretation, a formula must provide a correct analysis of the content expressed
by s. This clearly leaves room for the possibility that different formulas adequately
formalize s in that interpretation. If the differences that obtain in such a case are
called minimal, then the two kind of variation in the representation of a sentence
may be deﬁned as follows:
8The number triangle method outlined by Peters and Westerståhl in 2006, pp. 160–161, provides a
clear visual representation of the fact that more than half determines an n on every ﬁnite domain.

8.5
Two Kinds of Formal Variation
109
Deﬁnition 8.5.1 A minimal variation in the representation of a sentence s is a
variation that involves some minimal difference in the formulas assigned to s.
Deﬁnition 8.5.2 A nonminimal variation in the representation of a sentence s is a
variation that involves some difference in the formulas assigned to s which is not
minimal.
The meaning of ‘minimal’ can be speciﬁed in more than one way. On the one hand,
any admissible deﬁnition of minimality must entail that certain differences between
formulas are minimal, in that they clearly do not affect adequate formalization. If
two formulas ˛ and ˇ differ only in that ˇ is obtained from ˛ by uniformly replacing
some nonlogical expression with another expression of the same category, as in the
case of Fa and Fb, the difference between them is deﬁnitely minimal. The same
goes if ˛ and ˇ are deﬁnitely strictly equivalent in the sense suggested in Sect. 5.3.
On the other hand, any admissible deﬁnition of minimality must entail that certain
differences between formulas are not minimal, in that they clearly affect adequate
formalization. If ˛ and ˇ are not logically equivalent, it cannot be the case that
they both adequately formalize the same sentence in the same interpretation. But
there are also intermediate cases in which it is not obvious whether a difference
between formulas should be classiﬁed as minimal. For example, the transformation
from 8x.˛ ^ ˇ/ to 8x˛ ^ 8xˇ might be minimal according to one admissible
understanding of minimality and not minimal according to another.
However, it is not essential for the purposes at hand that the meaning of ‘minimal’
is speciﬁed in this or that way, for the distinction between minimal and non minimal
variations is sufﬁciently clear in our case: the difference between (9) and (10) turns
out to be minimal on any admissible deﬁnition of minimality, while that between
(14) and (15) turns out to be nonminimal on any admissible deﬁnition of minimality.
This means that, given Deﬁnitions 8.5.1 and 8.5.2, the former may be described
in terms of minimal variation in the formal representation of (1), while the latter
may be described in terms of nonminimal variation in the formal representation
of (12).
Note that, in accordance with the suggestion provided in Sect. 5.3, sameness
of logical form can be deﬁned in terms of minimal variation in the formal
representation of a sentence.
Deﬁnition 8.5.3 A sentence s has the same logical form in two interpretations i and
i0 if and only if the difference between i and i0 entails at most minimal variation in
the formal representation of s.
Thus, (1) has the same logical form in the interpretations represented by (9) and
(10). By contrast, (12) does not have the same logical form in the interpretations
represented by (14) and (15).

110
8
Quantiﬁed Sentences
8.6
Conclusion
From the analysis of quantiﬁed sentences suggested in this chapter it turns out that
there is something right and something wrong in each of the two ways of thinking
considered in Sect. 8.1. On the one hand, there is a sense in which it is right to
say that (1) and (2) are structurally different, namely, that in which (1) and (2) are
adequately represented as (3) and (4) in order to formally explain the inferences
involving them. On the other, there is a sense in which it is right to say that (1)
and (2) are structurally similar, namely, that in which (1) and (2) are adequately
represented as (5) and (6) in order to provide a compositional account of their
meaning. What is wrong is to think that there must be a unique sense in which
either (1) and (2) are structurally different or they are structurally similar. According
to the notion that is suitable to address (Q1) – the truth-conditional notion – they are
structurally different, while according to the notion that is suitable to address (Q2)
– the syntactic notion – (1) and (2) are structurally similar. This is just another way
of saying that there is no unique answer to the question of what is the logical form
of quantiﬁed sentences.
The divergence between the truth-conditional notion and the syntactic notion
becomes strikingly evident in the case of (12). While according to the latter (12)
has a ﬁxed logical form, according to the former it has different logical forms in
different interpretations. Thus, the distinction between the two notions may be used
to explain the semantic similarities and the logical differences between (1) and (12).
Note that, once the distinction is granted, the account of (12) outlined in Sect. 8.4
cannot be questioned on the basis of considerations of intuitive plausibility or
empirical adequacy. As is observed in Sect. 6.6, the truth-conditional notion, unlike
the syntactic notion, does not provide an explanation of how speakers get to know
truth conditions. The account of (12) outlined in Sect. 8.4 by no means entails that
one has to “go through” the logical form of (12) in order to grasp its truth conditions.
Moreover, on this account there is no interesting sense in which logical form is
transparent. The logical form of (12) is not detectable from its syntactic structure.
Therefore, using (12) by no means entails being in a position to know its logical
form.

Chapter 9
Further Issues Concerning Quantiﬁcation
Abstract This chapter develops the analysis of quantiﬁed sentences sketched in
Chap. 8. First, it draws a distinction between two senses in which a quantiﬁer
expression can be said to be vague, and outlines an account of the distinction that
rests on independently grounded assumptions. Then it shows how the difference
between the two senses can be represented at the formal level, and it addresses
some debated issues concerning quantiﬁcation. Although the claims that will be
made have only a tangential bearing on the main theme of the book, some of them
may be regarded as interesting in themselves.
9.1
Two Kinds of Indeterminacy
The question of what it is for a quantiﬁer expression to be vague seems to admit
two kinds of answers. It is plausible to say that a quantiﬁer expression e (as used
on a given occasion) is vague if it is possible that a quantiﬁed sentence s in which e
occurs is neither clearly true nor clearly false – in a way of being neither clearly true
nor clearly false that is distinctive of vagueness – and this does not entirely depend
on the vagueness of other expressions in s. However, it seems that such unclarity
can have two different sources. Roughly speaking, the semantic role of e in s is to
specify a certain amount of things that belong to the domain over which e is taken
to range. So if it is unclear whether s is true or false, and this unclarity does not
entirely depend on other expressions in s, either there is indeterminacy about the
domain over which e is taken to range, or there is indeterminacy about the amount
speciﬁed.
To illustrate the ﬁrst kind of indeterminacy, consider the following sentences:
(1) All philosophers are rich
(2) Some philosophers are rich
(3) More than half of philosophers are rich
One may easily imagine circumstances in which it is unclear whether (1)–(3) are
true or false. Obviously, this is due at least in part to the fact that ‘philosophers’
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3_9
111

112
9
Further Issues Concerning Quantiﬁcation
and ‘rich’ do not have deﬁnite extensions. But even if ‘philosophers’ and ‘rich’
did have deﬁnite extensions, it could still be unclear whether (1)–(3) are true or
false. One source of unclarity is the fact mentioned in Sect. 8.2 that the use of a
quantiﬁer expression may involve only a very approximate speciﬁcation of a set of
contextually relevant objects: if no deﬁnite set is speciﬁed, there is a plurality of sets
such that it is indeterminate which of them is the intended set. Consider (1). Even
if ‘philosophers’ and ‘rich’ had deﬁnite extensions, it might still be unclear whether
(1) is true or false, because it might be unclear what exactly is the domain over which
‘all’ is taken to range. Suppose that (1) is uttered to assert that all philosophers in the
university U are rich, but no unique set of contextually relevant objects is speciﬁed.
In particular, suppose that D is a set of people working or studying in U, and D0
is a proper subset of D that differs from D only in that it does not include a certain
person whose afﬁliation to U is unclear for some reason. In this case it might happen
that (1) is neither clearly true nor clearly false. Similar examples can be provided
with (2) and (3).
One way to see that this kind of indeterminacy is correctly described as vagueness
is to see how it can be distinguished from context sensitivity. If ‘context’ is used
informally, as in the previous chapters, it is realistic to say that the use of a quantiﬁer
expression in a context may fail to specify a deﬁnite domain. Even if a restricting
condition is associated to the quantiﬁer expression – in virtue of contextual features
such as the speaker’s intentions, the conversational background, and so on –
the restricting condition is itself indeterminate. In the example considered, the
restricting condition is expressed by ‘people working or studying in U’, but it may
be unclear whether a certain person works or studies in U. Similar examples may be
provided with paradigmatically vague expressions: a restricting condition could be
expressed by ‘bald people’, ‘thin people’ or ‘tall people’, in which case it would
be evident that it involves the kind of unclarity that is distinctive of vagueness.
Obviously, one might introduce a ﬁner notion of context* by stipulating that a
context* is an n-tuple of parameters that includes a set of objects as domain. But
then one would have to grant the intelligibility of the informal notion of context,
and the point would still remain that the use of a quantiﬁer expression in a context
may fail to specify a deﬁnite context*.
To illustrate the second kind of indeterminacy, consider the following sen-
tences:
(4) Most philosophers are rich
(5) Few philosophers are rich
(6) Many philosophers are rich
It is easy to see that (4)–(6), just like (1)–(3), may be used without specifying a
deﬁnite set of contextually relevant objects. But in the case of (4)–(6) there is another
possible source of unclarity, the fact that a quantiﬁer expression may fail to specify
a deﬁnite amount of things that belong to a given domain. Consider (4). Even if
‘philosophers’ and ‘rich’ had deﬁnite extensions, it might still be unclear whether
(4) is true, because it might be unclear whether ‘most’ is to be read, say, as ‘more

9.2
Precisiﬁcations of Quantiﬁer Expressions
113
than 1/2’ or as ‘more than 2/3’. Similar considerations hold for (5) and (6), as ‘few’
and ‘many’ admit multiple readings in the same sense. By contrast, ‘all’, ‘some’
and ‘more than half of’ do not admit multiple readings in that sense. This suggests
that ‘most’, ‘few’ and ‘many’ are indeterminate in a way in which ‘all’, ‘some’
and ‘more than half of’ are not. While ‘all’, ‘some’ and ‘more than half’ provide a
deﬁnite speciﬁcation of a certain portion of the domain, ‘most’, ‘few’ and ‘many’
do not, as they can be understood in more than one way.
Again, one way to see that this kind of indeterminacy is correctly described
as vagueness is to see how it can be distinguished from context sensitivity, for it
is realistic to say that the use of a quantiﬁer expression in a context may fail to
determine a deﬁnite reading in the sense illustrated. For example, we may use ‘most’
without having in mind a speciﬁc reading such as ‘more than 1/2’ or ‘more than 2/3’.
The examples considered show that there are two ways in which the use of a
quantiﬁed sentence in a context may fail to ﬁx deﬁnite truth conditions. In the ﬁrst
case the sentence has no deﬁnite truth conditions because no deﬁnite domain is
ﬁxed. This may be called domain indeterminacy. In the second case the sentence
has no deﬁnite truth conditions because, given any domain, no deﬁnite binary
relation is ﬁxed on that domain. This may be called quantiﬁer indeterminacy.
Domain indeterminacy and quantiﬁer indeterminacy are clearly independent of each
other. On the one hand, it can be the case that a quantiﬁer expression (as used on
a given occasion) is indeterminate in the ﬁrst sense without being indeterminate
in the second. For example, ‘all’ always speciﬁes a determinate portion of the
intended domain, even if it may be indeterminate which is the intended domain.
On the other, it is conceivable that a quantiﬁer expression (as used on a given
occasion) is indeterminate in the second sense without being indeterminate in the
ﬁrst. For example, even assuming that ‘most’ ranges over a deﬁnite domain in a
given case, it still makes sense to say that it fails to specify a deﬁnite portion of
that domain. Therefore, domain indeterminacy and quantiﬁer indeterminacy can
be regarded as two ways of being vague. If a quantiﬁer expression (as used on a
given occasion) is vague, then it is affected either by quantiﬁer indeterminacy, or by
domain indeterminacy, or by both.
9.2
Precisiﬁcations of Quantiﬁer Expressions
This section outlines an account of domain indeterminacy and quantiﬁer indetermi-
nacy that conforms to the analysis of quantiﬁed sentences suggested in Chap. 8. The
account relies on the assumption about vagueness stated in Sect. 7.3:
(VP)
If an expression is vague, then it admits different precisiﬁcations.
As will be suggested, the distinction between quantiﬁer indeterminacy and domain
indeterminacy may be understood as a distinction between two kinds of variations
in the precisiﬁcations of a quantiﬁer expression.

114
9
Further Issues Concerning Quantiﬁcation
To show how domain indeterminacy may be described in terms of precisiﬁcations
we will assume, in accordance with what has been said in Sects. 8.3 and 8.4, that
domains are ﬁxed by interpretations of quantiﬁed sentences. On this assumption, a
case of domain indeterminacy may be described as one in which a quantiﬁed sen-
tence is used in a context, but a plurality of interpretations of the sentence are equally
admissible in the context. Each interpretation corresponds to a precisiﬁcation of the
quantiﬁer expression that occurs in the sentence.
To illustrate, suppose that (1) is uttered to assert that all philosophers in U are
rich, but no unique set of contextually relevant objects is speciﬁed. In particular,
suppose that D is a set of people working or studying in U, and D0 is a proper subset
of D that differs from D only in that it does not include a certain person whose
afﬁliation to U is unclear for some reason. Then there are two precisiﬁcations p1
and p2 such that p1 includes D and p2 includes D0. Consequently, it may be unclear
whether (1) is true, for (1) might have different truth values in p1 and in p2.
In order to describe quantiﬁer indeterminacy in terms of precisiﬁcations, the
meaning of ‘most’, ‘few’, and ‘many’ may be deﬁned along the lines suggested
in Sect. 8.2. In what follows we will consider some deﬁnitions. Since there is no
general agreement on the meaning of ‘most’, ‘few’, and ‘many’, it may be a matter
of controversy whether these deﬁnitions are correct. But nothing essential depends
on them. They are simply intended to show how ‘most’, ‘few’, and ‘many’ differ
from ‘all’, ‘some’, and ‘more than half of’.
Let us start with ‘most’. A basic fact about most seems to be that the condition
stated in Deﬁnition 8.4.2 must be satisﬁed for the intended relation to obtain. If
one says that most philosophers are rich, one says at least that more than half
of philosophers are rich. This may be regarded as a necessary condition on most.
Yet it is not a sufﬁcient condition. Certainly, we can imagine situations in which
‘most’ is used as synonymous of ‘more than half of’. But if the meaning of ‘most’
were exhausted by that condition, ‘most’ would not be indeterminate in the way
explained. The meaning of ‘most’ seems to allow for variation in the proportion
between the size of A \ B and the size of A. Suppose that there are exactly
1.000.000 philosophers on earth, and that exactly 501.000 of them are rich. In that
circumstance it might be unclear whether (4) is true, while it is clear that (3) is true.
In order to account for this variation, a deﬁnition of most may be given along the
following lines:
Deﬁnition 9.2.1 mostD.A; B/ if and only if j A \ B j> n=m j A j
Here 0 < n < m and n=m  1=2. For example, 1/2 and 2/3 are equally acceptable
values for n=m. In other words, most is deﬁned as a class of quantiﬁers rather than as
a single quantiﬁer. Consequently, the meaning of (4) may be described as a class of
functions from domains to truth conditions that is obtained by combining most with
the meanings of ‘philosophers’ and ‘rich’. This means that (4) differs from (1)–(3),
in that the determination of its truth conditions involves a parameter other than the
domain. Let A and B be the sets denoted by ‘philosophers’ and ‘rich’ relative to D.
Whether mostD obtains between A and B depends on the values assigned to n and m.
For example, if n D 2 and m D 3, then it obtains just in case j A \ B j> 2=3 j A j.

9.2
Precisiﬁcations of Quantiﬁer Expressions
115
In order to determine deﬁnite truth conditions for (4), we need both a domain and a
value of the additional parameter whose variation is allowed by the indeterminacy
of ‘most’.1
As in the case of ‘most’, the meaning of ‘few’ and ‘many’ may be deﬁned as a
class of quantiﬁers. But there is a signiﬁcant difference. While ‘most’ is clearly
proportional, it is at least prima facie acceptable that ‘few’ and ‘many’ behave
nonproportionally. Consider few. A basic fact about few seems to be that, for an
arbitrary D, to say that fewD holds between A and B is to set an upper bound on the
size of A\B. There are at least two ways to express this fact. The ﬁrst may be called
the absolute reading of ‘few’:
Deﬁnition 9.2.2 fewD.A; B/ if and only if j A \ B j n
This reading is absolute in the sense that the upper bound on the size of A \ B is
ﬁxed without reference to the size of A or B. The second reading, instead, may be
called the proportional reading of ‘few’, and comes in two versions:
Deﬁnition 9.2.3 fewD.A; B/ if and only if j A \ B j n=m j A j
Deﬁnition 9.2.4 fewD.A; B/ if and only if j A \ B j n=m j B j
Here n and m are such that 0 < n < m. Deﬁnition 9.2.3 may be appropriate for (5),
given that in (5) the number of rich philosophers is said to be small with respect to
the number of philosophers. The following sentence, instead, is naturally understood
in terms of Deﬁnition 9.2.4:
(7) Few cooks applied
What (7) says is that the number of applicant cooks is small with respect to the
number of applicants.
The case of many is analogous. A basic fact about many seems to be that, for an
arbitrary D, to say that manyD holds between A and B is to set a lower bound on the
size of A \ B. Again, there are at least two ways to express this fact. The ﬁrst may
be called the absolute reading of ‘many’:
Deﬁnition 9.2.5 manyD.A; B/ if and only if j A \ B j n
This reading is absolute in the sense that the lower bound on the size of A \ B is
ﬁxed without reference to the size of A or B. The second reading, instead, may be
called the proportional reading of ‘many’, and comes in two versions:
Deﬁnition 9.2.6 manyD.A; B/ if and only if j A \ B j n=m j A j
Deﬁnition 9.2.7 manyD.A; B/ if and only if j A \ B j n=m j B j
1Deﬁnition 9.2.1 is in line with Barwise and Cooper (1981), p. 163, and Westerståhl (1985b),
pp. 405–406. In the latter work, two readings of ‘most’ are considered. But if Deﬁnition 9.2.1 is
adopted there seems to be no reason to do that.

116
9
Further Issues Concerning Quantiﬁcation
Deﬁnition 9.2.6 may be appropriate for (6), given that in (6) the number of rich
philosophers is said to be big with respect to the number of philosophers. The
following sentence, instead, is naturally understood in terms of Deﬁnition 9.2.7:
(8) Many Scandinavians have won the Nobel Prize
What (8) says is that the number of Scandinavian Nobel Prize winners is big with
respect to the number of Nobel Prize winners.2
The absolute reading and the proportional reading of ‘few’ and ‘many’ might be
regarded either as two distinct meanings that ‘few’ and ‘many’ can take depending
on the occasion, or as two different hypotheses about their unique meaning. In any
case, the meaning of (5) and (6) is obtained by combining few and many with the
meanings of ‘philosophers’ and ‘rich’, so it turns out to be a class of functions from
domains to truth conditions.3
If the meaning of ‘most’, ‘few’, and ‘many’ is deﬁned in the way suggested,
quantiﬁer indeterminacy may be described in terms of precisiﬁcations. Consider
Deﬁnition 9.2.1. The variables n and m that occur in this deﬁnition indicate the
variability of the proportion between j A \ B j and j A j, which constitutes the
quantiﬁer indeterminacy of ‘most’. Each assignment of values to n and m amounts
to a way of sharpening the meaning of ‘most’. So it may be assumed that a
precisiﬁcation of ‘most’ involves such an assignment, in addition to the domain
parameter. For example, one precisiﬁcation of ‘most’ is that according to which
n D 2 and m D 3, so the proportion is j A \ B j> 2=3 j A j. Deﬁnitions 9.2.2–
9.2.7 are similar in this respect. Each of them – no matter whether the reading
is absolute or proportional – entails that the quantiﬁer expression deﬁned admits
precisiﬁcations that differ in the same way. As in the case of domain indeterminacy,
the precisiﬁcations of a quantiﬁer expression determine interpretations of the
quantiﬁed sentence in which it occurs.
From what has been said so far it turns out that the distinction between domain
indeterminacy and quantiﬁer indeterminacy may be described in terms of two
kinds of variations in the precisiﬁcations of a quantiﬁer expression. On the one
hand, if a quantiﬁer expression (as used on a given occasion) exhibits domain
indeterminacy, then it admits precisiﬁcations that involve domain variation. On the
other, if a quantiﬁer expression (as used on a given occasion) exhibits quantiﬁer
indeterminacy, then it admits precisiﬁcations that involve quantiﬁer variation.
Since interpretations of quantiﬁed sentences correspond to precisiﬁcations of the
quantiﬁer expressions that occur in them, the same distinction may be drawn with
respect to interpretations of quantiﬁed sentences.
2The examples (7) and (8) are discussed in Peters and Westerståhl (2006), pp. 213.
3The hypothesis that ‘most’, ‘few’ and ‘many’ can be treated along the lines suggested is adopted
in Barwise and Cooper (1981) and in Westerståhl (1985b). Instead, Keenan and Stavi (1986) and
Lappin (2000) provide different accounts of ‘few’ and ‘many’.

9.3
First Order Deﬁnability Again
117
9.3
First Order Deﬁnability Again
This section and the next show how the distinction between domain indeterminacy
and quantiﬁer indeterminacy can be framed at the formal level. As in the case of
(3), we will address the issue of ﬁrst order deﬁnability to show that (4)–(6) can
be formalized in L. Since it is provable that ‘most’, ‘few’, and ‘many’ are not
ﬁrst order deﬁnable, it might be contended that ﬁrst order logic does not have the
expressive resources to handle (4)–(6). For example, Lepore and Ludwig claim that
sentences such as (4)–(6) are emblematic of the difﬁculty philosophers have been
led into by thinking of paraphrase into a ﬁrst order language as the proper way
to exhibit logical form. However, this attitude relies on the questionable assumption
that formalization is a matter of translation, understood as meaning preservation. On
the truth-conditional view, (4)–(6) can be formalized in L independently of whether
‘most’, ‘few’, and ‘many’ are ﬁrst order deﬁnable. What matters is that ‘most’,
‘few’, and ‘many’ are ﬁrst order expressible.4
To show that (4) can be formalized in L, we will prove a squeezing result similar
to Theorem 8.4.1. As in the case of Theorem 8.4.1, the reasoning essentially depends
on the adequacy assumption and the ﬁniteness assumption considered in Sect. 8.4.
Theorem 9.3.1 For every D and A; B  D, there is an adequate formula ˛ of L that
contains two unary predicate letters such that mostD.A; B/ if and only if ˛ is true in
a model with domain D where the two predicate letters denote A and B.
Proof First of all, it will be shown that, if A; B  D and 0 < n < m, there is a k
such that j B j> n=m j A j if and only if j B j k. Take any n and m such that
0 < n < m. A function F similar to that employed in the proof of Theorem 8.4.1
can be constructed in the following way. If j D 0, then F. j/ D 1. If j > 0 and j is
divisible by m, then
F. j/ D n
mj C 1
If j > 0 and j is not divisible by m, then F. j/ is the smallest integer such that
F. j/ > n
mi
Let j A jD j and k D F. j/. k is such that j B j> n=m j A j if and only if j B j k.
Suppose that j D 0. Then n=m j A jD 0 and F. j/ D 1, so j B j> 0 if and only if
j B j 1. Suppose that j > 0 and j is divisible by m. Then j B j> n=m. j/ if and only
if j B j n=m. j/ C 1. Finally, suppose that j > 0 and j is not divisible by m. By
hypothesis j B j is a natural number, hence j B j> n=m. j/ if and only if j B j F. j/.
4Lepore and Ludwig (2002), p. 70. Peters and Westerståhl, in 2006, pp. 466–468, outline a proof
method that can be employed to show that ‘most’, ‘few’, and ‘many’ are not ﬁrst order deﬁnable.

118
9
Further Issues Concerning Quantiﬁcation
Once it is shown that, if A; B  D and 0 < n < m, there is a k such that
j B j> n=m j A j if and only if j B j k, replacing B with A \ B it turns out that
there is a k such that j A \ B j> n=m j A j if and only if j A \ B j k. Therefore,
mostD.A; B/ if and only if j A \ B j k. This means that the following formula, for
n D k, can be used to express in L the claim that mostD.A; B/:
(9) 9nx.Px ^ Rx/
For (9) is true in a model with domain D where P and R denote A and B.
ut
Now consider (5) and (6). Although ‘few’ and ‘many’ admit both an absolute
reading and a proportional reading, the difference between the two readings does not
really matter as far as formalization in L is concerned. The two readings certainly
differ with respect to ﬁrst order deﬁnability, for few and many turn out ﬁrst order
deﬁnable on the absolute reading but not on the proportional reading. However,
what matters to formalization in L is ﬁrst order expressibility. As in the case of
most, a squeezing argument can be provided to the effect that few and many are ﬁrst
order expressible.
Theorem 9.3.2 For every D and A; B  D, there is an adequate formula ˛ of L that
contains two unary predicate letters such that fewD.A; B/ if and only if ˛ is true in
a model with domain D where the two predicate letters denote A and B.
Proof For n > 0, let the symbol 9n be used to abbreviate formulas of L in the same
way as 9n. For a set D, let A; B  D. If we assume Deﬁnition 9.2.2, fewD.A; B/ if
and only if j A \ B j n. Therefore, fewD.A; B/ if and only if the following formula
is true in a model with domain D where P and Q denote A and B:
(10) 9nx.Px ^ Rx/
If we assume Deﬁnition 9.2.3, fewD.A; B/ if and only if j A \ B j n=m j A j. But
a result similar to Theorem 9.3.1 can be proved in similar way, that is, if A; B  D
and 0 < n < m, there is a k such that j B j n=m j A j if and only if j B j k.
Therefore, fewD.A; B/ if and only if (10) is true in a model with domain D where P
and R denote A and B. The same goes if we assume Deﬁnition 9.2.4.
ut
Theorem 9.3.3 For every D and A; B  D, there is an adequate formula ˛ of L that
contains two unary predicate letters such that manyD.A; B/ if and only if ˛ is true
in a model with domain D where the two predicate letters denote A and B.
Proof Let A; B  D. If we assume Deﬁnition 9.2.5, manyD.A; B/ if and only if
j A\B j n. Therefore, manyD.A; B/ if and only if (9) is true in a model with domain
D where P and Q denote A and B. If we assume Deﬁnition 9.2.6, manyD.A; B/ if
and only if j A \ B j n=m j A j. But a theorem similar to Theorem 9.3.1 can be
proved in similar way, that is, if A; B  D and 0 < n < m, there is a k such that
j B j n=m j A j if and only if j B j k. Therefore, we get that manyD.A; B/ if and
only if (9) is true in a model with domain D where P and R denote A and B. The
same goes if we assume Deﬁnition 9.2.7.
ut

9.3
First Order Deﬁnability Again
119
From Theorems 9.3.1–9.3.3 it turns out that (4)–(6) can be formalized in L.
For every precisiﬁcation of the quantiﬁer expressions that occur in (4)–(6), there
is a formula of L that represents the content of (4)–(6). On the assumption that
interpretations of quantiﬁed sentences include precisiﬁcations of the quantiﬁer
expressions that occur in them, this means that for every interpretation of (4)–(6),
there is a formula of L that represents the content of (4)–(6).
In Sect. 8.5 we saw that there are two ways in which the representation of a
quantiﬁed sentence can vary as a function of its interpretation. For example, in the
case of (1) the variation is minimal, as between the following formulas:
(11) 8x.Px  Rx/
(12) 8x.Qx  Rx/
Instead, in the case of (3) the variation is nonminimal, as between the following
formulas:
(13) 93x.Px ^ Rx/
(14) 94x.Px ^ Rx/
The notion of minimality may be employed to characterize domain indeterminacy
and quantiﬁer indeterminacy. First, it seems correct to say that domain indeter-
minacy entails minimal variation. If a quantiﬁer expression e (as used on a given
occasion) exhibits domain indeterminacy and s is a quantiﬁed sentence containing e,
then it is indeterminate which is the set of contextually relevant objects over which e
is taken to range. That is, there are two sets D and D0 such that it is not clear whether
e ranges over D or D0. But then there are two precisiﬁcations p1 and p2 such that the
difference between p1 and p2 entails minimal variation in the representation of s, for
different predicate letters must be employed to represent in L the difference between
D and D0. Therefore, there are two interpretations which require two minimally
different formulas of L.5
Second, it seems correct to say that quantiﬁer indeterminacy entails nonminimal
variation. If a quantiﬁer expression e (as used on a given occasion) is affected by
quantiﬁer indeterminacy and s is a quantiﬁed sentence containing e, then there
are two precisiﬁcations p1 and p2 such that the difference between p1 and p2
entails nonminimal variation in the representation of s, for the deﬁnition of the
meaning of e must include some variables such that, for any domain, different
values of those variables determine different binary relations on that domain (no
matter whether e is understood as proportional or nonproportional). So if p1 and
5Here it is assumed that contextual restrictions are formally represented in the way suggested in
Sect. 8.3. But note that we would get the same result if we adopted a formal representation in which
a separate predicate letter expresses the restricting condition, since in that case (11) and (12) would
be replaced by two formulas 8x.Qx  .Px  Rx// and 8x.Sx  .Px  Rx// which differ in the
ﬁrst predicate letter.

120
9
Further Issues Concerning Quantiﬁcation
p2 are precisiﬁcations that differ in such values, the formulas assigned to s in the
corresponding interpretations must differ in nonminimal way.6
9.4
Logicality
The rest of this chapter dwells on three related issues. The ﬁrst concerns the
distinction between logical and nonlogical quantiﬁer expressions. It is customary
to classify some quantiﬁer expressions as logical, assuming that their meaning has
a special signiﬁcance for logic. Therefore, one may wonder whether a principled
distinction can be drawn between logical and nonlogical quantiﬁer expressions.
More speciﬁcally, one may ask whether such a distinction holds for the quantiﬁer
expressions that occur in (1)–(6). This section suggests that there is a coherent
answer to the latter question, although it makes no attempt to provide a comprehen-
sive account of logicality. On the account of the distinction that will be sketched,
which applies to the restricted class of quantiﬁer expressions considered so far,
logicality and vagueness are independent properties.
The question may be framed as follows. On the one hand, it is seems that not all
the quantiﬁer expressions that occur in (1)–(6) should be classiﬁed as logical. More
speciﬁcally, it seems that ‘all’ and ‘some’ are logical, whereas ‘more than half of’,
‘most’, ‘few’ and ‘many’ are nonlogical. As Barwise and Cooper have observed,
it would be wrong to think that the meaning of every quantiﬁer expression must
be “built into the logic”. On the other hand, however, it might be argued that the
distinction between logical and nonlogical quantiﬁer expressions misses something
important, namely, that nonlogical quantiﬁer expressions may play some logically
interesting role in inferences. For example, the validity of the following argument
depends on the fact that ‘most’ occurs in the premise:
(4) Most philosophers are rich
(2) Some philosophers are rich
[A]
As Peters and Westerståhl point out, if we switch the predicates in [A], we still
have a valid inference, while if we switch the quantiﬁer expressions, the entailment
is lost. This shows, according to them, that ‘most’ is constant in a way in which
‘philosophers’ is not. A worked out and improved version of this notion of constancy
is provided by Bonnay and Westerståhl, where it is suggested that, on a suitable
6Note that the converse entailment clearly does not hold, for it may be the case that the sentences
containing a quantiﬁer expression e (as used on a given occasion) admit nonminimal variation in
formal representation even if e does not exhibit quantiﬁer indeterminacy. This is shown by the case
of ‘more than half of’, which does not exhibit quantiﬁer indeterminacy even though (3) may be
represented as (13) or (14).

9.4
Logicality
121
understanding of interpretations, a quantiﬁer expression is constant if at least one
argument in which it occurs is valid in one interpretation but becomes invalid in
another interpretation.7
As will be shown, this apparent conﬂict can be resolved in accordance with
the method of formalization adopted here: a meaningful distinction can be drawn
between logical and nonlogical quantiﬁer expressions, without leaving unexplained
the inferential role of nonlogical quantiﬁer expressions. Given Deﬁnition 8.5.3,
logicality may be deﬁned as follows:
Deﬁnition 9.4.1 A quantiﬁer expression e is logical if and only if, for every sentence
s in which e occurs and for every pair of interpretations i and i0 such that i0 differs
from i in the domain assigned to e, s has the same logical form in i and i0.8
From Deﬁnition 9.4.1 it turns out that ‘all’ is logical. Let s be a sentence that contains
‘all’, and let i and i0 be interpretations of s that differ at most in the domain assigned
to ‘all’. Since the difference between i and i0 is represented by assigning to s two
formulas which differ in the ﬁrst predicate letter, as in the case of (11) and (12),
s has the same logical form in i and i0. Similar considerations hold for ‘some’. By
contrast, ‘more than half of’, ‘most’, ‘few’, and ‘many’ are nonlogical. As has been
shown in the case of (3)–(6), two interpretations that differ in the domain assigned to
‘more than half of’, ‘most’, ‘few’, and ‘many’ can determine a difference of logical
form. This characterization of logicality entails that logicality and vagueness are
independent properties. A quantiﬁer expression (as used on a given occasion) may
or may not be vague – in either of the two senses considered – independently of
whether it is logical or nonlogical.
While logicality and vagueness are independent properties, there is a straightfor-
ward relation between logicality and ﬁrst order deﬁnability:
Theorem 9.4.1 Every logical quantiﬁer expression is ﬁrst order deﬁnable
Proof Let us assume that e is a logical quantiﬁer expression that denotes a quantiﬁer
Q, and that s is a quantiﬁed sentence in which e occurs. Let ˛ be a formula of L that
contains two predicate letters and represents the content of s in an interpretation i
with domain D. Then it must be the case that, for A; B  D, QD.A; B/ if and only
if ˛ is true in a model with domain D where the predicate letters in ˛ denote A and
B. Now take any domain D0. For some interpretation i0 which differs from i in that
its domain is D0, there is a formula ˛0 of L such that ˛0 represents the content of s
in i0, so that, for A0; B0  D0, QD0.A0; B0/ if and only if ˛0 is true in a model with
domain D0 where the predicate letters in ˛0 denote A0 and B0. But since e is logical,
7Barwise and Cooper (1981), p. 162, Peters and Westerståhl (2006), pp. 334–335, Bonnay and
Westerståhl (2012), section 8.
8Note that, given the restriction mentioned in Sect. 8.2, ‘sentence’ refers to simple quantiﬁed
sentences such as (1)–(6).

122
9
Further Issues Concerning Quantiﬁcation
s has the same logical form in i and i0. This means that ˛ and ˛0 differ minimally.
Therefore, ˛0 is true in a model with domain D0 where the predicate letters in ˛0
denote A0 and B0 if and only if ˛ is true in a model with domain D0 where the
predicate letters in ˛ denote A0 and B0. This is to say that ˛ satisﬁes the condition
required by Deﬁnition 8.4.1, so that e is ﬁrst order deﬁnable.

Theorem 9.4.1 provides a partial characterization of logicality in terms of ﬁrst order
deﬁnability, in that it states that ﬁrst order deﬁnability is necessary for logicality.
This characterization entails that every quantiﬁer expression that is not ﬁrst order
deﬁnable is not logical. So, the point about the distinction between ﬁrst order
deﬁnability and ﬁrst order expressibility made in the previous sections may be
reﬁned as follows. Quantiﬁer expressions such as ‘more than half of’, ‘most’,
‘few’, and ‘many’ are not ﬁrst order deﬁnable. But this does not entail that the
quantiﬁed sentences in which they occur cannot be formalized in a classical ﬁrst
order language. What it entails is at most that they are not logical.9
Once it is clear how the quantiﬁer expressions that occur in (1)–(6) can be
distinguished, it remains to be said how the inferential role of nonlogical quantiﬁer
expressions can be explained. Consider [A]. Given Deﬁnition 5.3.1, it is consistent
to hold that an argument can have different forms in different interpretations, each
of which is valid. This is precisely what happens in the case of [A]. Since (4)
has different logical forms in different interpretations, [A] has different forms in
different interpretations. Suppose for example that (13) and (14) express the logical
form of (4) as understood on two different occasions. Then there are two different
but equally valid forms for [A], that is,
(13) 93x.Px ^ Rx/
(15) 9x.Px ^ Rx/
[B]
(14) 94x.Px ^ Rx/
(15) 9x.Px ^ Rx/
[C]
More generally, the validity of [A] can be explained in terms of formal validity by
using standard principles of ﬁrst order logic. In this respect, there is no difference
between [A] and any argument that involves logical quantiﬁer expressions.
It is easy to see how other apparently valid arguments can be treated in similar
way. In particular, an explanation along the lines suggested seems to hold for a
considerably wide class of valid arguments formed by sentences containing either
‘most’ or ‘some’. Note, however, that this does not mean that every argument con-
taining ‘most’ that is valid in some interpretation must be valid in all interpretations.
For example, consider the following:
9There is an interesting convergence between the account of logical quantiﬁer expressions
suggested here and the independently motivated account outlined in Feferman (2015), see p. 140.
As is noticed in that work, pp. 144–145, it is not as obvious as it might seem that the converse of
Theorem 9.4.1 holds.

9.5
Quantiﬁcation Over Absolutely Everything
123
(16) Most beers are cool
(17) At least four beers are cool
[D]
If (13) and (14) express the logical form of (4) as understood on two different occa-
sions, then [D] is valid in some interpretations but invalid in other interpretations.
Therefore, the explanation of the validity of arguments such as [A] is consistent
with the hypothesis that ‘most’ is constant in the sense spelled out by Bonnay
and Westerståhl, although the explanation itself does not appeal to constancy so
understood. In the perspective adopted here, logicality and constancy may be
regarded as distinct properties of quantiﬁer expressions.10
9.5
Quantiﬁcation Over Absolutely Everything
The second issue concerns the possibility of unrestricted quantiﬁcation. Although
quantiﬁer expressions often carry a tacit restriction to a set of contextually relevant
objects, it is legitimate to ask whether they can coherently be used without such
restriction, that is, whether it is possible to quantify over absolutely everything.
Some uses of quantiﬁer expressions are plausibly interpreted as involving unre-
stricted quantiﬁcation. For example, if one uses the word ‘everything’, which is
equivalent to ‘all things’, to state a general metaphysical claim, presumably one
does not want to exclude some things as contextually irrelevant.
Of course, this does not mean that we can provide a coherent formal account
of unrestricted quantiﬁcation. As it turns out from Sect. 3.1, in standard ﬁrst order
semantics each model includes a set as its domain, so when formulas are interpreted
in the model, the symbol 8 is read as restricted to the members of that set.
But according to set theory there is no universal set, that is, there is no set of
which everything is a member. The naive idea that there is such a set is proved
inconsistent by the Russell paradox. Therefore, in order to provide a formal account
of unrestricted quantiﬁcation, some alternative semantics must be given.
Williamson has argued that there is a viable alternative to standard ﬁrst order
semantics. His point is that, even though a Russell-like paradox can arise if we
assume that interpretations can be quantiﬁed over like other things, that is, with ﬁrst
order quantiﬁcation, no such paradox can arise if we give up that assumption and
recognize that the semantics must be phrased in an irreducibly second order way.
Others, instead, are not convinced by his line of argument and continue to claim
that quantiﬁcation over everything is incoherent. However, this question will not
be addressed here. In what follows we will simply grant that, since at least some
10Moss (2008), section 8.2, provides a complete axiomatization of a class of inferences involving
sentences containing either ‘most’ or ‘some’. The explanation suggested here seems to hold at least
for that class.

124
9
Further Issues Concerning Quantiﬁcation
uses of quantiﬁer expressions are plausibly interpreted as involving unrestricted
quantiﬁcation, the possibility of unrestricted quantiﬁcation must be taken into
account.11
To see that Deﬁnitions 8.2.1–8.4.2 and 9.2.1–9.2.7 are compatible with unre-
stricted quantiﬁcation, recall that, as explained in Sect. 8.2, the use of a quantiﬁer
expression may or may not involve an intended delimitation of the domain: there
are contexts in which some things are excluded as irrelevant on the basis of some
intended condition, and contexts in which nothing is excluded as irrelevant. The
distinction between restricted and unrestricted quantiﬁcation may be understood in
terms of these two cases. That is, the contexts of the second kind may be understood
as contexts in which the domain is the totality of everything.
Note that, since there is no universal set, if the domain associated to a given use
of a quantiﬁer expression is the totality of everything, that domain is not a set. So
it cannot in general be assumed that domains are sets. But this is compatible with
Deﬁnitions 8.2.1–8.4.2 and 9.2.1–9.2.7, as Deﬁnitions 8.2.1–8.4.2 and 9.2.1–9.2.7
do not depend on that assumption. A domain may or may not be a set. All that
matters is that, on each domain, a quantiﬁer expression denotes a binary relation
over the domain.12
9.6
Unrestricted Quantiﬁcation and Precision
The third issue concerns a claim that has been discussed in connection with
some metaphysical disputes about unrestricted mereological composition and four-
dimensionalism:
(UP)
If ‘all’ and ‘some’ are unrestricted, then they are precise.
The main argument for (UP), ﬁrst sketched by Lewis and then elaborated by Sider,
rests on (VP), the assumption about vagueness considered in Sect. 9.2. The argument
is intended to show that, given (VP), it is inconsistent to suppose that ‘all’ or ‘some’
are unrestricted and admit different precisiﬁcations. Consider ‘all’. If ‘all’ were
vague, there would be two precisiﬁcations p1 and p2 such that, for some x, it is
determinately the case that ‘all’ ranges over x according to p1 but not according to
p2. But since ‘all’ is unrestricted, if there is such an x then ‘all’ ranges over x. So it is
not determinately the case that ‘all’ ranges over x according to p1 but not according
to p2. The same goes for ‘some’.13
11Williamson (2003), pp. 424–427 and 452–460. Glanzberg (2004) argues against Williamson
that, for every domain purporting to contain everything, there are in fact things falling outside
the domain.
12Peters and Westerståhl, among others, assume that domains are sets, see p. 48. In Sect. 8.4 the
same assumption is adopted for the sake of argument.
13Lewis (1986), p. 213, Sider (2001), pp. 128–129, Sider (2003), pp. 137–142.

9.6
Unrestricted Quantiﬁcation and Precision
125
The Lewis-Sider argument has been widely discussed. Some ﬁnd it compelling,
others do not. So it is controversial whether (UP) is justiﬁed. But it is at least
reasonable to assume that (UP) deserves consideration, so it may be worth to dwell
on its relation with the account of quantiﬁer expressions provided in the previous
sections. As will be explained, what has been said so far is consistent with (UP).14
First of all, it must be noted that here quantiﬁer indeterminacy is not at issue:
since ‘all’ and ‘some’ are not vague in that sense, (UP) is clearly safe from quantiﬁer
indeterminacy. So the crucial question is whether the fact that ‘all’ or ‘some’
can exhibit domain indeterminacy is compatible with (UP). The answer to this
question is afﬁrmative, on the assumption that domain indeterminacy arises only
in connection with restricted quantiﬁcation. That is, one may consistently claim
that domain indeterminacy concerns the speciﬁcation of a restricting condition, so
that it does not arise if no restricting condition is speciﬁed. Thus if (1) is used
on a certain occasion and ‘all’ exhibits domain indeterminacy, that is, there are
different precisiﬁcations p1 and p2 which involve different sets as domains, then
its indeterminacy may be understood in terms of different logical forms such as (11)
and (12) being ascribed to (1) in different interpretations. By contrast, the same kind
of ambivalence does not arise when ‘all’ is used unrestrictedly.15
At least two interesting corollaries may be drawn from what has been said so
far. The ﬁrst concerns the distinction between the quantiﬁer expressions ‘all’ and
‘some’, which belong to English, and the symbols 8 and 9, which belong to L.
In the debate on the Lewis-Sider argument, both the advocates of (UP) and their
opponents tend to use the two kinds of expressions interchangeably, as if there were
a straightforward connection between quantiﬁed sentences and their logical form.
But according to the method of formalization adopted here, the connection is not so
straightforward. Even if ‘all’ and ‘some’ may be vague in some sense, in that they
may involve domain indeterminacy, there is no sense in which the symbols 8 and 9
may be vague.
The second corollary is that domain indeterminacy, unlike quantiﬁer indeter-
minacy, is a property that concerns the use of a quantiﬁer expression, rather than
the expression itself. In other terms, while quantiﬁer indeterminacy is an intrinsic
property of quantiﬁer expressions, domain indeterminacy is an extrinsic property of
quantiﬁer expressions, in that it arises only in connection with restricting conditions
that may be associated with them. Perhaps one might be tempted to conclude that
domain indeterminacy is not a genuine property of quantiﬁer expressions, namely,
that the only sense in which quantiﬁer expressions may be vague is that in which
14Lopez De Sa (2006) and Sider (2009) elaborate and defend the argument. Liebesman and Eklund
(2007) and Torza (2014), argue against it.
15Note, however, that it might be unclear whether ‘all’ is used unrestrictedly, in which case a
similar kind of indeterminacy would arise. Note also that, just like ‘all’ may involve a restriction,
the same goes for the general term ‘thing’ as it occurs in ‘all things’. As Lopez de Sa (2006), pp.
405–406, makes clear, (UP) is compatible with recognizing that there might be restricted uses of
‘thing’ that are vague. In that case, quantifying over every thing in that sense is not the same thing
as quantifying over absolutely everything.

126
9
Further Issues Concerning Quantiﬁcation
they may involve quantiﬁer indeterminacy. But much depends on what ‘genuine’
is taken to mean. In any case, even if domain indeterminacy were not classiﬁed as
genuine because it is not an intrinsic property of quantiﬁer expressions, its existence
could hardly be denied. All that matters here is that there is a kind of indeterminacy
that arises in connection with the use of quantiﬁer expressions and differs from
quantiﬁer indeterminacy in the way suggested.
A different question that might be raised in connection with this second corollary
is the following: if the domain indeterminacy that affects a quantiﬁer expression
e as used on a certain occasion depends on the restricting condition associated
with e on that occasion, doesn’t it follow that domain indeterminacy is reducible
to indeterminacy of expressions other than e, the expressions that are tacitly taken
to ﬁx that condition? The answer to this question is that strictly speaking it does
not follow. At least two further issues seems relevant to the justiﬁcation of such
conclusion. One is whether every restriction is ﬁxed – or can in principle be ﬁxed –
by some description. The other is the issue mentioned in Sect. 8.2, that is, whether
the restriction depends on some variable or parameter in the determiner or in the
noun. Since neither of these two issues need be addressed here, the reducibility
question may be left unsettled. In any case, nothing important hinges on that
question. Again, all that matters here is that there is a kind of indeterminacy that
arises in connection with the use of quantiﬁer expressions and differs from quantiﬁer
indeterminacy in the way suggested.

Afterword
The central thesis of this book is that there is no such thing as a correct answer to the
question of what is logical form: two signiﬁcantly different notions of logical form,
the syntactic notion and the truth-conditional notion, are needed to fulﬁl two major
theoretical roles, the semantic role and the logical role. The analysis of quantiﬁed
sentences outlined in Chaps. 8 and 9 provides a clear illustration of the philosophical
import of this thesis, as it shows how the distinction between the two notions can
shed light on some fundamental problems. The methodological moral to be drawn
is that, when we deal with issues that concern logical form, we must carefully
reﬂect on how logical form is understood. In order to properly assess the arguments
provided in support or against a given claim, it must be clear what notion of logical
form is to be considered, depending on the intended purposes.
This is nothing but a trace that indicates a line of investigation, so it leaves
open some important questions about logical form. In particular, it leaves open
three strictly interrelated issues. The ﬁrst is the issue of logical constants. We saw
that the vocabulary of L includes two kinds of symbols: logical constants and
nonlogical expressions. The distinction between logical constants and nonlogical
expressions, which is crucial to the deﬁnition of logical consequence for L, is
intended to capture an analogous distinction that holds for natural languages. So
it is legitimate to ask how the latter distinction can be drawn in the ﬁrst place.
Although it is generally agreed that some expressions – such as ‘not’ or ‘all’ –
deﬁnitely belong to the class of logical constants, and that others – such as ‘red’
or ‘Aristotle’ – deﬁnitely do not, there is little consensus about the basis for the
distinction. The main proposals for demarcating logical constants have sought to
identify some property – grammatical particlehood, topic neutrality, permutation
invariance, characterizability by inferential rules – as necessary and sufﬁcient
for logical constancy. But each of them seems vulnerable to counterexamples.
Moreover, it is not even obvious that a criterion of the kind proposed can be found.
© Springer International Publishing AG 2018
A. Iacona, Logical Form, Synthese Library 393,
https://doi.org/10.1007/978-3-319-74154-3
127

128
Afterword
One might think that the pursuit of a principled distinction is itself misguided, and
that the problem of logical constants is not a genuine problem.1
What has been said so far does not settle this issue, as it is consistent with
different views of logical constants. Certainly, Sect. 9.4 draws a distinction between
logical and nonlogical quantiﬁer expressions. But that distinction, as we have seen,
is intended to apply to the restricted class of sentences considered in Chap. 9, so it
is not to be regarded as an attempt to provide a comprehensive account of logicality.
Note also the sense of ‘logical’ speciﬁed by Deﬁnition 9.4.1 is essentially relative,
in that it depends on the vocabulary of the language in which logical forms are
expressed. So the deﬁnition leaves open the question whether an absolute criterion
of logical constancy can be spelled out in a non-circular way. If the answer to that
question is afﬁrmative, then it is reasonable to expect that we can provide some
independent justiﬁcation of the choice of logical constants that underlies L. If it is
negative, instead, then the choice of logical constants that underlies L is itself in
need of justiﬁcation, so an account of logicality based on L is deﬁnitely circular.
Even though it is arguable that only in the ﬁrst case we can get an interesting
distinction between logical and nonlogical quantiﬁer expressions, in any case the
relativity involved in Deﬁnition 9.4.1 causes no trouble by itself.
The second issue, which is intimately connected with the ﬁrst, is the issue of
the plurality of formal representations. Logical forms are expressed by formulas
that we assign to sentences in order to represent them. But since a sentence can be
represented by formulas of different languages, or by different formulas of the same
language, it is legitimate to ask whether it makes sense to talk of “the” logical form
of the sentence. For example, consider the following sentence:
(1) Aristotle is a philosopher
(1) is represented in L as Fa, while in a propositional language it gets a sentential
variable. Similarly, consider the following sentence:
(2) Aristotle is younger than Plato
(2) can be represented in L both as Fa, where F stands for ‘younger than Plato’, and
as Rab, where R stands for ‘younger than’. On the basis of examples of this sort,
one may be tempted to think that there is no such thing as “the” logical form of a
sentence, because the sentence has different logical forms relative to different kinds
of formal representation.2
It is not obvious whether relativist arguments of this ilk are sound. The relativist
maintains that there are at least two equal representations of the same sentence, yet
much depends on what ‘equal’ is supposed to mean. It might be contended that a
representation of (1) in L and a representation of (1) in a propositional language
are not equal: the ﬁrst is ﬁner, in that it displays the structure of the content of (1).
1MacFarlane (2015), section 8, spells out the main approaches to the problem of logical constants.
2Arguments of this kind are provided in Davidson (1970), p. 142, Grandy (1974), pp. 162–163,
and in Brun (2008), p. 6.

Afterword
129
Similarly, it might be contended that Fa and Rab are not equal representations of
(2): Rab is ﬁner, in that it makes explicit the relational character of the property
ascribed to Aristotle. But independently of whether relativity to kinds of formal
representation obtains, the truth-conditional view does not entail that it obtains.
Note that relativity to interpretations is not the same thing as relativity to kinds of
formal representations. In Sect. 5.3 it is claimed that there is no such thing as “the”
logical form of a sentence in the sense that sentences have logical form relative to
interpretations. But this is not the same thing as to say that sentences have logical
form relative to kinds of formal representations. One may coherently accept the
line of thought outlined in Sect. 5.3 and hold that there is such a thing as the ﬁnest
representation of a sentence.
The third issue, which is intimately connected with the second, is the issue of
the ultimate reality of logical form. Some of the authors mentioned in the previous
chapters, such as Frege and Russell, seem to think that logical form is a real thing
that exists independently of the formal languages that we employ to express it. On
this view, it is natural to think that a formal representation can be correct in some
important sense. Others, instead, such as Quine and Davidson, seem to think that
logical form is just a theoretical tool that enables us to account for the validity of
arguments in natural language, so that it essentially depends on the formal languages
that we employ to express it. On this view, it makes no sense to think that a formal
representation can be correct in some important sense.
Although one might get the impression that the central thesis of this book implies
an antirealist attitude about logical form, what has been said so far is consistent with
the thought that logical form is a real thing that exists independently of the formal
languages that we employ to express it. The truth-conditional notion may coherently
be associated with the idea that a formal representation of a sentence can be correct
in some important sense. The same goes, mutatis mutandis, for the syntactic notion:
LFs or semantic structures may be entities that exist independently of the languages
that are used to express them. In substance, to say that there are two signiﬁcantly
different notions of logical form is not to deny that logical forms are real. Logical
forms may be real even though they are not unique in the sense explained.
Bibliography
Abelard, P. (1956). Dialectica. Van Gorcum: Assen.
Ajdukiewicz, K. (1935). Die syntaktische Konnexität. Studia Philosophica, 1, 1–27.
Aristotle. (1934). The Nicomachean ethics (Aristotle in 23 Volumes, Vol. 19). Cambridge: Harvard
University Press.
Aristotle. (1949). Prior and posterior analytics. Oxford: Oxford University Press.
Aristotle. (1958). Topica et Sophistici Elenchi. Oxford: Oxford University Press.
Bach, K. (1994). Conversational implicature. Mind and Language, 9, 124–162.
Bach, K. (2000). Quantiﬁcation, qualiﬁcation, and context: A reply to Stanley and Szabo. Mind
and Language, 15, 262–283.
Bar-Hillel, Y. (1954). Indexical expressions. Mind, 63, 359–379.

130
Afterword
Barnes, J. (2009). Truth, etc: Six lectures on ancient logic. Oxford: Oxford University Press.
Barwise, J., & Cooper, R. (1981). Generalized quantiﬁers and natural language. Linguistics and
Philosophy, 4, 159–219.
Baumgartner, M., & Lampert, T. (2008). Adequate formalization. Synthese, 164, 93–115.
Boghossian, P. (1992). Externalism and inference. Philosophical Issues, 2, 11–28.
Boghossian, P. (1994). The transparency of mental content. Philosophical Perspectives, 8, 33–50.
Bonino, G. (2008). The arrow and the point. Frankfurt am Main: Ontos Verlag.
Bonnay, D., & Westerståhl, D. (2012). Consequence mining: Constants versus consequence
relations. Journal of Philosophical Logic, 41, 671–709.
Boole, G. (1951). The mathematical analysis of logic. Oxford: Blackwell.
Borg, E. (2007). Minimal semantics. Oxford: Blackwell.
Braun, D. (2001). Indexicals. In E. N. Zalta (Ed.), Stanford encyclopedia of philosophy. Stanford
University. http://plato.stanford.edu/entries/indexicals/.
Braun, D., & Sider, T. (2007). Vague, so untrue. Noûs, 41, 133–156.
Brun, G. (2008). Formalization and the objects of logic. Erkenntnis, 69, 1–30.
Buridan, J. (1976). Tractatus de Consequentiis. Louvain: Publications Universitaires.
Cargile, J. (1970). Davidson’s notion of logical form. Inquiry, 13, 129–139.
Chierchia, G. (2013). Logic in grammar. Oxford: Oxford University Press.
Chomsky, N. (1976). Conditions on rules of grammar. Linguistic Analysis, 2, 303–351.
Chomsky, N. (1995). The minimalist program. Cambridge: MIT Press.
Church, A. (1942). Equivocation. In D. D. Runes (Ed.), The dictionary of philosophy. New York:
Philosophical Library.
Davidson, D. (1967). The logical form of action sentences. In N. Rescher (Ed.), The logic of
decision and action (pp. 81–95). Pittsburgh: University of Pittsburgh Press.
Davidson, D. (1968). On saying that. Synthese, 19, 130–146.
Davidson, D. (1970). V. Action and reaction. Inquiry, 13, 140–148.
Davidson, D. (1980). Essays on actions and events. Oxford: Clarendon Press.
Davidson, D. (1984). Inquiries into truth and interpretation. Oxford: Clarendon Press.
Euclid. (2002). Elements. Ann Arbor, Michigan: Green Lion Press.
Evans, G. (1985). Semantic structure and logical form 1976. In Collected papers (pp. 49–75).
Oxford University Press.
Feferman, S. (2015). Which quantiﬁers are logical? A combined semantical and inferential
criterion. In A. Torza (Ed.), Quantiﬁers, quantiﬁers, and quantiﬁers. Cham: Springer.
Fine, K. (1975). Vagueness, truth and logic. Synthese, 30, 265–300.
Fine, K. (2009). Semantic relationism. Malden: Blackwell.
Fine, K. (2015). Truthconditional content – Part I. published online https://nyu.academia.edu/
KitFine.
Fine, K. (2015). Truthconditional content – Part II. published online https://nyu.academia.edu/
KitFine.
Fine, K. (2017). Truthmaker semantics. forthcoming in the Blackwell philosophy of language
handbook. Wiley
Fogelin, R. J., & Sinnott-Armstrong, W. (2001). Understanding Arguments. Forth Worth: Harcourt.
Frege, G. (1879). Concept script, a formal language of pure thought modelled upon that of
arithmetic. In J. van Heijenoort (Ed.), From Frege to Godel: A sourcebook in mathematical
logic, (chapter Begriffsschrift, pp. 5–82). Cambridge, MA: Harvard University Press. 1967.
Frege, G. (1891). Function and concept. In P. Geach & M. Black (Eds.), Translations from the
philosophical writings of Gottlob Frege. Blackwell. 1980.
Frege, G. (1892). On sense and meaning. In B. McGuinness (Ed.), Collected papers on mathemat-
ics, logic and philosophy (pp. 157–177). Blackwell. 1984.
Frege, G. (1918). Thoughts In B. McGuinness (Ed.), Collected papers on mathematics, logic and
philosophy (pp. 351–372). Blackwell. 1984.
García-Carpintero, M. (2004). Logical form: Syntax and semantics. In A. Coliva & E. Picardi
(Eds.), Wittgenstein today (pp. 63–87). Il Poligrafo.

Afterword
131
Gauker, C. (2014). How many bare demonstratives are there in English. Linguistics and Philoso-
phy, 37, 291–314.
Georgi, G. (2015). Logic for languages containing referentially promiscuous expressions. Journal
of Philosophical Logic, 44, 429–451.
Glanzberg, M. (2004). Quantiﬁcation and Realism. Philosophy and Phenomenological Research,
69, 541–72.
Gómez-Torrente, M. (2006). Logical truth. In E. N. Zalta (Ed.), Stanford encyclopedia of
philosophy. Stanford University. http://plato.stanford.edu/entries/.
Grandy, R. E. (1974). Some remarks about logical form. Noûs, 8, 157–164.
Hanks, P. (2015). Propositional content. Oxford: Oxford University Press.
Hanson, W. H. (1997). The concept of logical consequence. Philosophical Review, 106, 365–409.
Harman, G. (1970). Deep structure as logical form. Synthese, 21, 275–297.
Hobbes, T. (1656). Elements of philosophy concerning body. London: Leybourn for Andrew
Crooke.
Iacona, A. (2010a). Saying more (or less) than one thing. In R. Dietz & S. Moruzzi (Eds.), Cuts and
clouds: Vagueness, its nature and its logic (pp. 289–303). Oxford: Oxford University Press.
Iacona, A. (2010b). Truth preservation in any context. American Philosophical Quarterly, 47, 191–
199.
Iacona, A. (2010c). Validity and interpretation. Australasian Journal of Philosophy, 88, 247–264.
Iacona, A. (2013). Logical form and truth conditions. Theoria, 28, 439–457.
Iacona, A. (2015). Quantiﬁcation and logical form. In A. Torza (Ed.), Quantiﬁers, quantiﬁers, and
quantiﬁers (pp. 125–140). Cham: Springer.
Iacona, A. (2016a). Two notions of logical form. Journal of Philosophy, 113, 617–643.
Iacona, A. (2016b). Vagueness and quantiﬁcation. Journal of Philosophical Logic, 45, 579–602.
Jago, M. (2017). Propositions as Truthmaking conditions. Argumenta, 2, 293–308.
Kamp, H. (2015). Using proper names as intermediaries between labelled entity representations.
Erkenntnis, 80, 263–312.
Kaplan, D. (1977). Demonstratives. In J. Perry, J. Almog, & H. Wettstein (Eds.), Themes from
Kaplan (pp. 481–563). New York: Oxford University Press. 1989.
Kaplan, D. (1989). Afterthoughts. In J. Perry, J. Almog, & H. Wettstein (Eds.), Themes from
Kaplan (pp. 565–614). New York: Oxford University Press.
Kaplan, D. (1990). Words. Proceedings of the Aristotelian Society, 64, 93–119.
Keefe, R. (2000). Supervaluation and validity. Philosophical Topics, 28, 93–106.
Keenan, E. L., & Stavi, J. (1986). A semantic characterization of natural language determiners.
Linguistics and Philosophy, 9, 253–326.
King, J. C. (1995). Structured propositions and complex predicates. Noûs, 29, 516–535.
King, J. C. (1996). Structured propositions and sentence structure. Journal of Philosophical Logic,
25, 495–521.
King, J. C. (2007). The nature and structure of content. Oxford: Oxford University Press.
King, J. C. (2013). On ﬁneness of grain. Philosophical Studies, 163, 763–781.
King, J. C. (2014). Naturalized propositions. In J. Speaks, J. C. King, & S. Soames (Eds.), New
thinking about propositions (pp. 47–70). Oxford: Oxford University Press.
King, J. C. (2016). On propositions and ﬁneness of grain (again!). Synthese.
Kirwan, C. (1979). Aristotle and the so-called fallacy of equivocation. Philosophical Quarterly,
29, 35–46.
Kneale, W., & Kneale, M. (1962). The development of logic. Oxford: Oxford University Press.
Kreisel, G. (1967). Informal rigour and completeness proofs. In I. Lakatos (Ed.), Problems in the
philosophy of mathematics (pp. 138–186). Amsterdam: North-Holland.
Kripke, S. (1979). A puzzle about belief. In A. Margalit (Ed.), Meaning and use (pp. 239–283).
Dordrecht: D. Reidel.
Lappin, S. (2000). An intensional parametric semantics for vague quantiﬁers. Linguistics and
Philosophy, 23, 599–620.
Leibniz, G. W. (1875–1890). Die philosophischen Schriften von G. W. Leibniz. C. I. Gerhardt.
Berlin : Weidman.

132
Afterword
Leibniz, G. W. (1903). Opuscules et fragments inédits de Leibniz. L. Couturat. Paris: Alcan
Lepore, E., & Ludwig, K. (2002). What is logical form? In G. Preyer & G. Peter (Eds.), Logical
form and language (pp. 54–90). Oxford: Oxford University Press.
Lewis, D. (1970). General semantics. In Philosophical papers (Vol. I, pp. 189–229). Oxford:
Oxford University Press. 1983.
Lewis, D. (1986). On the plurality of worlds. Oxford: Blackwell.
Liebesman, D., & Eklund, M. (2007). Sider on existence. Noûs, 41, 519–528.
Linsky, B. (2002). Russell’s logical form, LF, and truth-conditions. In G. Preyer & G. Peter (Eds.),
Logical form and language (pp. 391–408). Oxford: Oxford University Press.
López De Sa, D. (2006). Is ‘Everything’ precise? Dialectica, 60, 397–409.
Lull, R. (1609). Raymundi Lullii Opera ea.... Argentorati: Zetzner.
Lycan, W. G. (1986). Logical form in natural language. Cambridge: MIT Press.
MacFarlane, J. (2004). In what sense (if any) is logic normative for thought? unpublished draft.
MacFarlane, J. (2015). Logical constants. In E. N. Zalta (Ed.), Stanford encyclopedia of philosophy.
Stanford University. https://plato.stanford.edu/entries/logical-constants/.
Marconi, D. (1995). Predicate logic in Wittgenstein’s Tractatus. Logique et Analyse, 38, 179–190.
Marconi, D. (2006). Le ambigue virtù della forma logica. Rivista di estetica, 46, 7–20.
Mates, B. (1973). Stoic logic. Berkeley: University of California Press.
May, R. (1977). The grammar of quantiﬁcation. Ph.D. dissertation. Garland Publishing.
May, R. (1985). Logical form. Cambridge: MIT Press.
McGee, V., & McLaughlin, B. (1995). Distincions without a difference. Southern Journal of
Philosophy, 33, 203–251.
Montague, R. (1968). Pragmatics. In Formal philosophy (pp. 95–118). New Haven: Yale University
Press. 1974.
Montague, R. (1970). Universal grammar. In Formal philosophy (pp. 222–246). New Haven: Yale
University Press, 1974.
Montague, R. (1973). The proper treatment of quantiﬁcation in ordinary English. In Formal
philosophy (pp. 247–270). New Haven: Yale University Press. 1974.
Moss, L. S. (2008). Completeness theorems for syllogistic fragments. In F. Hamm & S. Kepser
(Eds.), Logics for linguistic structures (pp. 143–173). Berlin/New York: Mouton de Gruyter.
Mugnai, M. (2010). Logic and mathematics in the seventeenth century. History and Philosophy of
Logic, 31, 297–314.
Neale, S. (1993). Logical form and LF. In C. Otero (Ed.), Noam Chomsky: Critical assessments
(pp. 788–838). London: Routledge.
Ockham, W. (1974). Summa logicae. In S. Brown, P. Boehner, & G. Gàl (Eds.), Opera philosophica
et theologica. St. Bonaventure: The Franciscan Institute.
Parsons, T. (1990). Events in the semantics of English: A study in subatomics semantics.
Cambridge: MIT Press.
Peters, S., & Westerståhl, D. (2006). Quantiﬁers in language and logic. Oxford: Oxford University
Press.
Pietroski, P. (2005). Events and semantic architecture. Oxford: Oxford University Press.
Pietroski, P. (2009). Logical form. In Stanford encyclopedia of philosophy. Stanford University.
https://plato.stanford.edu/entries/logical-form/.
Plato. (1991). The Republic: The complete and unabriged Jowett translation. New York: Vintage
Book.
Predelli, S. (2005). Contexts. Oxford: Oxford University Press.
Quine, W. V. O. (1948). On what there is. Review of Metaphysics, 2, 21–36.
Quine, W. V. O. (1971). Methodological reﬂections on current linguistic theory. In D. Davidson &
G. Harman (Eds.), Semantics of natural language. Dordrecht: Reidel.
Russell, B. (1905). On denoting. Mind, 14, 479–493.
Russell, B. (1984). Theory of knowledge. In Collected papers (Vol. VI). Allen and Unwin.
Russell, B. (1998). The philosophy of logical atomism. La Salle: Open Court.
Sainsbury, M. (1991). Logical forms. Oxford: Blackwell.

Afterword
133
Sainsbury, M. (2008). Philosophical logic. In D. Moran (Ed.), The Routledge companion to
twentieth century philosophy (pp. 347–381). London: Routledge.
Sainsbury, M., & Tye, M. (2012). Seven puzzles of thought and how to solve them. New York:
Oxford University Press.
Salmon, N. (1986a). Frege’s puzzle. Cambridge: MIT Press.
Salmon, N. (1986b). Reﬂexivity. Notre Dame Journal of Formal Logic, 27, 401–429.
Salmon, N. (1989a). Illogical belief. In Philosophical perspectives 3: Philosophy of mind and
action theory (pp. 243–285). Atascadero: Ridgeview.
Salmon, N. (1989b). Tense and singular propositions. In J. Perry, J. Almog, & H. Wettstein (Eds.),
Themes from Kaplan (pp. 391–392). New York: Oxford University Press.
Sider, T. (2001). Four dimensionalism. Oxford: Clarendon Press.
Sider, T. (2003). Against vague existence. Philosophical Studies, 114, 135–146.
Sider, T. (2009). Against vague and unnatural existence: Reply to Liebesman and Eklund. Noûs,
43, 557–567.
Soames, S. (1985). Lost innocence. Linguistic and Philosophy, 8, 59–71.
Soames, S. (1987). Direct reference, propositional attitudes and semantic content. Philosophical
Topics, 15, 47–87.
Soames, S. (1989). Semantics and semantic competence. In Philosophical perspectives 3: Philos-
ophy of mind and action theory (pp. 575–596). Atascadero: Ridgeview.
Soames, S. (2010). What is meaning? Princeton: Princeton University Press.
Soames, S. (2014). Cognitive propositions. In J. Speaks J. C. King, & S. Soames (Eds.), New
thinking about propositions (pp. 91–124). Oxford: Oxford University Press.
Spade, P. V., & Panaccio, C. (2011). William of Ockham. In Stanford encyclopedia of philosophy.
Stanford University. http://plato.stanford.edu/entries/.
Stanley, J. (2000). Context and logical form. Linguistics and Philosophy, 23, 391–434.
Stanley, J., & Szabó, Z. G. (2000). On quantiﬁer domain restriction. Mind and Language, 15, 219–
261.
Szabó, Z. G. (2012). Against logical form. In G. Preyer (Ed.), Donald Davidson on truth, meaning
and the mental (pp. 105–126). Oxford: Oxford University Press.
Tarski, A. (1936). On the concept of logical consequence. In Logic, semantics, metamathematics
(pp. 409–420). Indianapolis: Hackett. 1983.
Tarski, A. (1933). The concept of truth in formalized languages. In Logic, semantics, metamathe-
matics (pp. 152–278). Indianapolis: Hackett. 1983.
Torza, A. (2014). Vague existence. In Bennett K. y Zimmerman D. (eds.), Oxford Studies in
Metaphysics, 10, 201–33.
Varzi, A. (2007). Supervaluationism and its logics. Mind, 116, 633–675.
Voltolini, A. (1997). Contingent and necessary identities. Acta Analytica, 19, 73–98.
Westerståhl, D. (1985a). Determiners and context sets. In J. van Benthem & A. ter Meulen (Eds.),
Generalized quantiﬁers in natural language (pp. 45–71). Dordrecht: Foris Publications.
Westerståhl, D. (1985b). Logical constants in quantiﬁer languages. Linguistics and Philosophy, 8,
387–413.
Williamson, T. (1994). Vagueness. London: Routledge.
Williamson, T. (2003). Everything. Philosophical Perspectives, 17, 415–465.
Wittgenstein, L. (1992). Tractatus logico-philosophicus. London: Routledge.
Wittgenstein, L. (1993). Some remarks on logical form. In J. Klagge & A. Nordmann (Eds.),
Philosophical occasions (pp. 29–35). Indianapolis: Hackett.
Woods, J., & Walton, D. N. (1979). Equivocation and practical logic. Ratio, 21, 31–43.
Yablo, S. (2014). Aboutness. Princeton: Princeton University Press.
Yagisawa, T. (1993). Logic puriﬁed. Nous, 27, 470–486.

