INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS I

Informatics in Control, Automation
and Robotics I
Edited by
JOSÉ BRAZ
HELDER  ARAÚJO
University of Coimbra, Portugal
ALVES VIEIRA
and
BRUNO ENCARNAÇÃO
INSTICC - Institute for Systems and Technologies of Information,
Control and Communication, Setúbal, Portugal
Escola Superior de Tecnologia de Setúbal, Portugal
Escola Superior de Tecnologia de Setúbal, Portugal

A C.I.P. Catalogue record for this book is available from the Library of Congress.
ISBN-10  1-4020-4136-5 (HB)
ISBN-13  978-1-4020-4136-5 (HB)
ISBN-10  1-4020-4543-3 (e-books)
ISBN-13  978-1-4020-4543-1 (e-books)
Published by Springer,
P.O. Box 17, 3300 AA Dordrecht, The Netherlands.
www.springer.com
Printed on acid-free paper
All Rights Reserved
© 2006 Springer 
No part of this work may be reproduced, stored in a retrieval system, or transmitted
in any form or by any means, electronic, mechanical, photocopying, microfilming, recording
or otherwise, without written permission from the Publisher, with the exception
of any material supplied specifically for the purpose of being entered
and executed on a computer system, for exclusive use by the purchaser of the work.
Printed in the Netherlands.

TABLE OF CONTENTS 
Preface .................................................................................................................................................ix
Conference Committee .......................................................................................................................xi
INVITED SPEAKERS 
Kevin Warwick...............................................................................................................................................................3 
INDUSTRIAL AND REAL WORLD APPLICATIONS OF ARTIFICIAL NEURAL  
NETWORKS - Illusion or reality?
Kurosh Madani ............................................................................................................................................................11 
THE DIGITAL FACTORY - Planning and simulation of production in automotive industry
F. Wolfgang Arndt.......................................................................................................................................................27 
WHAT'S REAL IN "REAL-TIME CONTROL SYSTEMS"? Applying formal verification  
methods and real-time rule-based systems to control systems and robotics 
Albert M. K. Cheng.....................................................................................................................................................31 
SUFFICIENT CONDITIONS FOR THE STABILIZABILITY OF MULTI-STATE  
UNCERTAIN SYSTEMS, UNDER INFORMATION CONSTRAINTS
Nuno C. Martins, Munther A. Dahleh and Nicola Elia.............................................................................................37 
PART 1 – INTELLIGENT CONTROL SYSTEMS AND OPTIMIZATION 
DEVICE INTEGRATION INTO AUTOMATION SYSTEMS WITH CONFIGURABLE  
DEVICE  HANDLER
Anton Scheibelmasser, Udo Traussnigg, Georg Schindin and Ivo Derado......................................................................53 
NON LINEAR SPECTRAL SDP METHOD FOR BMI-CONSTRAINED PROBLEMS: 
APPLICATIONS TO CONTROL DESIGN
Jean-Baptiste Thevenet, Dominikus Noll and Pierre Apkarian ....................................................................................61 
A STOCHASTIC OFF LINE PLANNER OF OPTIMAL DYNAMIC MOTIONS FOR  
ROBOTIC MANIPULATORS
ROBOT-HUMAN INTERACTION: Practical experiments with a cyborg
Taha Chettibi, Moussa Haddad, Samir Rebai and Abd Elfath Hentout ....................................................................73 

FUZZY MODEL BASED CONTROL APPLIED TO IMAGE-BASED VISUAL SERVOING
AN EVOLUTIONARY APPROACH TO NONLINEAR DISCRETE - TIME OPTIMAL 
CONTROL WITH TERMINAL CONSTRAINTS
Yechiel Crispin .............................................................................................................................................................89 
A DISTURBANCE COMPENSATION CONTROL FOR AN ACTIVE MAGNETIC  
BEARING SYSTEM BY A MULTIPLE FXLMS ALGORITHM
Min Sig Kang and Joon Lyou.......................................................................................................................................99 
AN INTELLIGENT RECOMMENDATION SYSTEM BASED ON FUZZY LOGIC
Shi Xiaowei................................................................................................................................................................105 
MODEL REFERENCE CONTROL IN INVENTORY AND SUPPLY CHAIN  
MANAGEMENT - The implementation of a more suitable cost function
Heikki Rasku, Juuso Rantala and Hannu Koivisto...................................................................................................111 
AN LMI OPTIMIZATION APPROACH FOR GUARANTEED COST CONTROL OF  
SYSTEMS WITH STATE AND INPUT DELAYS
Olga I. Kosmidou, Y. S. Boutalis and Ch. Hatzis......................................................................................................117 
USING A DISCRETE-EVENT SYSTEM FORMALISM FOR THE MULTI-AGENT  
CONTROL OF MANUFACTURING SYSTEMS
Guido Maione and David Naso.................................................................................................................................125 
PART 2 – ROBOTICS AND AUTOMATION 
FORCE RIPPLE COMPENSATOR FOR A VECTOR CONTROLLED PM LINEAR 
SYNCHRONOUS MOTOR
Markus Hirvonen, Heikki Handroos and Olli Pyrhönen...........................................................................................135 
HYBRID CONTROL DESIGN FOR A ROBOT MANIPULATOR IN A SHIELD  
TUNNELING MACHINE
Jelmer Braaksma, Ben Klaassens, Robert Babu ka and Cees de Keizer.......................................................................143 
vi
Table of Contents
MOCONT LOCATION MODULE: A CONTAINER LOCATION SYSTEM BASED ON 
DR/DGNSS INTEGRATION
Joseba Landaluze, Victoria del Río, Carlos F. Nicolás, José M. Ezkerra and Ana Martínez ...................................151 
PARTIAL VIEWS MATCHING USING A METHOD BASED ON PRINCIPAL  
COMPONENTS
Santiago Salamanca Miño, Carlos Cerrada Somolinos, Antonio Adán Oliver and Miguel Adán Oliver ....................159 
TOWARDS A CONCEPTUAL FRAMEWORK- BASED ARCHITECTURE FOR  
UNMANNED SYSTEMS
Norbert Oswald..........................................................................................................................................................167 
š
Paulo Jorge Sequeira Gonçalves, Luís F. Mendonça, João M. Sousa and João R. Caldas Pinto......................................81 

A INTERPOLATION-BASED APPROACH TO MOTION GENERATION FOR  
HUMANOID ROBOTS
Koshiro Noritake, Shohei Kato and Hidenori Itoh......................................................................................................179 
REALISTIC DYNAMIC SIMULATION OF AN INDUSTRIAL ROBOT WITH JOINT  
FRICTION
A NEW PARADIGM FOR SHIP HULL INSPECTION USING A HOLONOMIC  
HOVER-CAPABLE AUV
Robert Damus, Samuel Desset, James Morash, Victor Polidoro, Franz Hover, Chrys Chryssostomidis,  
Jerome Vaganay and Scott Willcox.............................................................................................................................195 
DIMSART: A REAL TIME - DEVICE INDEPENDENT MODULAR SOFTWARE 
ARCHITECTURE FOR ROBOTIC AND TELEROBOTIC APPLICATIONS
Jordi Artigas, Detlef Reintsema, Carsten Preusche and Gerhard Hirzinger.................................................................201 
ON MODELING AND CONTROL OF DISCRETE TIMED EVENT GRAPHS WITH 
MULTIPLIERS USING (MIN, +) ALGEBRA
Samir Hamaci, Jean-Louis Boimond and Sébastien Lahaye........................................................................................211 
MODEL PREDICTIVE CONTROL FOR HYBRID SYSTEMS UNDER A STATE  
PARTITION BASED MLD APPROACH (SPMLD)
Jean Thomas, Didier Dumur, Jean Buisson and Herve Guéguen.................................................................................217 
EFFICIENT SYSTEM IDENTIFICATION FOR MODEL PREDICTIVE CONTROL  
WITH THE ISIAC SOFTWARE
Paolino Tona and Jean-Marc Bader............................................................................................................................225 
IMPROVING PERFORMANCE OF THE DECODER FOR TWO-DIMENSIONAL
BARCODE SYMBOLOGY PDF417
Hee Il Hahn and Jung Goo Jung................................................................................................................................233 
Paolo Lombardi, Virginio Cantoni and Bertrand Zavidovique ...................................................................................239 
vii
Table of Contents
DYNAMIC STRUCTURE CELLULAR AUTOMATA IN A FIRE SPREADING  
APPLICATION
SPEAKER VERIFICATION SYSTEM Based on the stochastic modeling
MOMENT-LINEAR STOCHASTIC SYSTEMS
Sandip Roy, George C. Verghese and Bernard C. Lesieutre........................................................................................263 
Ronald G.K.M. Aarts, Ben J.B. Jonker and Rob R. Waiboer...................................................................................187 
PART 3 – SIGNAL PROCESSING, SYSTEMS MODELING AND CONTROL 
Alexandre Muzy, Eric Innocenti, Antoine Aïello, Jean-François Santucci, Paul-Antoine Santoni  
Valiantsin Rakush and Rauf Kh. Sadykhov..............................................................................................................255 
and David R.C. Hill .................................................................................................................................................247 
CONTEXT IN ROBOTIC VISION: Control for real-time adaptation

ACTIVE ACOUSTIC NOISE CONTROL IN DUCTS
Filipe Morais and J. M. Sá da Costa .........................................................................................................................273 
HYBRID UML COMPONENTS FOR THE DESIGN OF COMPLEX SELF-OPTIMIZING 
MECHATRONIC SYSTEMS
Sven Burmester, Holger Giese and Oliver Oberschelp ..................................................................................................281 
viii
Table of Contents
AUTHOR INDEX ................................................................................................................................................289

PREFACE
The present book includes a set of selected papers from the first “International Conference on 
Informatics in Control Automation and Robotics” (ICINCO 2004), held in Setúbal, Portugal, from 25 to 
28 August 2004. 
The conference was organized in three simultaneous tracks: “Intelligent Control Systems and 
Optimization”, “Robotics and Automation” and “Systems Modeling, Signal Processing and Control”. The book is 
based on the same structure.  
Although ICINCO 2004 received 311 paper submissions, from 51 different countries in all 
continents, only 115 where accepted as full papers. From those, only 29 were selected for inclusion in 
this book, based on the classifications provided by the Program Committee. The selected papers also 
reflect the interdisciplinary nature of the conference. The diversity of topics is an importante feature of 
this conference, enabling an overall perception of several important scientific and technological trends. 
These high quality standards will be maintained and reinforced at ICINCO 2005, to be held in Barcelona, 
Spain, and in future editions of this conference. 
Furthermore, ICINCO 2004 included 6 plenary keynote lectures and 2 tutorials, given by 
internationally recognized researchers. Their presentations represented an important contribution to 
increasing the overall quality of the conference, and are partially included in the first section of the book. 
We would like to express our appreciation to all the invited keynote speakers, namely, in alphabetical 
order: Wolfgang Arndt (Steinbeis Foundation for Industrial Cooperation/Germany), Albert Cheng 
(University of Houston/USA), Kurosh Madani (Senart Institute of Technology/France), Nuno Martins 
(MIT/USA), Rosalind Picard (MIT/USA) and Kevin Warwick (University of Reading, UK). 
On behalf of the conference organizing committee, we would like to thank all participants. First of all 
to the authors, whose quality work is the essence of the conference and to the members of the program 
committee, who helped us with their expertise and time. 
As we all know, producing a conference requires the effort of many individuals. We wish to thank all 
the members of our organizing committee, whose work and commitment were invaluable. Special thanks 
to Joaquim Filipe, Paula Miranda, Marina Carvalho and Vitor Pedrosa. 
José Braz 
Helder Araújo 
Alves Vieira 
Bruno Encarnação 

CONFERENCE COMMITTEE 
Conference Chair 
Joaquim Filipe, Escola Superior de Tecnologia de Setúbal, Portugal 
Program Co-Chairs 
Helder Araújo, I.S.R. Coimbra, Portugal 
Alves Vieira, Escola Superior de Tecnologia de Setúbal, Portugal 
Program Committee Chair 
José Braz, Escola Superior de Tecnologia de Setúbal, Portugal 
Secretariat
Marina Carvalho, INSTICC, Portugal 
Bruno Encarnação, INSTICC, Portugal  
Programme Committee 
Aguirre, L. (BRAZIL) 
Allgöwer, F. (GERMANY) 
Arató, P.(HUNGARY) 
Arsénio, A. (U.S.A.) 
Asama, H. (JAPAN) 
Babuska, R. (THE NETHERLANDS)
Balas, M. (U.S.A.) 
Balestrino, A. (ITALY) 
Bandyopadhyay, B. (INDIA) 
Bars, R. (HUNGARY) 
Bemporad, A. (ITALY) 
Birk, A. (GERMANY) 
Bonyuet, D.(U.S.A.) 
Boucher, P.(FRANCE) 
Bulsari, A. (FINLAND) 
Burke, E. (U.K.) 
Burn, K. (U.K.) 
Burrows, C. (U.K.) 
Buss, M. (GERMANY) 
Camarinha-Matos, L. (PORTUGAL) 
Campi, M. (ITALY) 
Cañete, J. (SPAIN) 
Carvalho, J. (PORTUGAL) 
Cassandras, C. (U.S.A.) 
Chatila, R. (FRANCE) 
Chen, T. (CANADA) 
Cheng, A. (U.S.A.) 
Choras, R. (POLAND) 
Christensen, H. (SWEDEN) 
Cichocki, A. (JAPAN) 
Coello, C. (MEXICO) 
Cordeiro, J. (PORTUGAL) 
Correia, L. (PORTUGAL) 
Costeira, J. (PORTUGAL) 
Couto, C. (PORTUGAL) 
Crispin, Y. (U.S.A.) 
Custódio, L. (PORTUGAL)  
Dillmann, R. (GERMANY) 
Dochain, D. (BELGIUM) 
Dourado, A. (PORTUGAL) 
Duch, W. (POLAND) 
Erbe, H. (GERMANY) 
Espinosa-Perez, G. (MEXICO) 
Feliachi, A. (U.S.A.) 
Feng, D. (HONG KONG) 
Ferrier, J. (FRANCE) 
Ferrier, N. (U.S.A.) 
Figueroa, G. (MEXICO) 
Filip, F. (ROMANIA) 
Filipe, J. (PORTUGAL) 
Fyfe, C. (U.K.) 
Gamberger, D. (CROATIA) 
Garção, A. (PORTUGAL) 
Gheorghe, L. (ROMANIA)  

Ghorbel, F. (U.S.A.) 
Gini, M. (U.S.A.) 
Goldenberg, A. (CANADA) 
Gomes, L.(PORTUGAL) 
Gonçalves, J. (U.S.A.) 
Gray, J. (U.K.) 
Gustafsson, T.(SWEDEN) 
Halang, W. (GERMANY) 
Hallam, J.(U.K.) 
Hammoud, R. (U.S.A.) 
Hanebeck, U. (GERMANY) 
Henrich, D. (GERMANY) 
Hespanha, J. (U.S.A.) 
Ho, W. (SINGAPORE) 
Imiya, A. (JAPAN) 
Jämsä-Jounela, S. (FINLAND) 
Jarvis, R. (AUSTRALIA) 
Jezernik, K. (SLOVENIA) 
Jonker, B. (THE NETHERLANDS) 
Juhas, G. (GERMANY) 
Karcanias, N. (U.K.) 
Karray, F. (CANADA) 
Katayama, T. (JAPAN) 
Katic, D. (YUGOSLAVIA) 
Kavraki, L. (U.S.A.) 
Kawano, H. (JAPAN) 
Kaynak, O. (TURKEY) 
Kiencke, U. (GERMANY) 
Kihl, M. (SWEDEN) 
King, R. (GERMANY) 
Kinnaert, M. (BELGIUM) 
Khessal, N. (SINGAPORE) 
Koivisto, H. (FINLAND) 
Korbicz, J. (POLAND)  
Kosko, B. (U.S.A.) 
Kosuge, K. (JAPAN)
Kovacic, Z. (CROATIA) 
Kunt, M. (SWITZERLAND) 
Latombe, J. (U.S.A.) 
Leite, F. (PORTUGAL) 
Leitner, J. (U.S.A.) 
Leiviska, K. (U.S.A.) 
Lightbody, G. (IRELAND) 
Ligus, J. (SLOVAKIA) 
Lin, Z. (U.S.A.) 
Ljungn, L. (SWEDEN) 
Lückel, J. (GERMANY) 
Maione, B. (ITALY) 
Maire, F. (AUSTRALIA) 
Malik, O. (CANADA) 
Mañdziuk, J. (POLAND) 
Meirelles, M. (BRAZIL) 
Meng, M. (CANADA) 
Mertzios, B. (GREECE) 
Molina, A. (SPAIN)  
Monostori, L. (HUNGARY) 
Morari, M. (SWITZERLAND) 
Mostýn, V. (CZECH REPUBLIC) 
Murray-Smith, D. (U.K.) 
Muske, K. (U.S.A.) 
Nedevschi, S. (ROMANIA) 
Nijmeijer, H. (THE NETHERLANDS)
Ouelhadj, D. (U.K.) 
Papageorgiou, M. (GREECE) 
Parisini, T. (ITALY) 
Pasi, G. (ITALY) 
Pereira, C. (BRAZIL) 
Pérez, M. (MEXICO)  
Pires, J. (PORTUGAL) 
Polycarpou, M. (CYPRUS) 
Pons, M. (FRANCE) 
Rana, O. (NEW ZEALAND) 
Reed, J. (U.K.) 
Ribeiro, M. (PORTUGAL) 
Richardson, R. (U.K.) 
Ringwood, J. (IRELAND)  
Rist, T. (GERMANY) 
Roffel, B. (THE NETHERLANDS)  
Rosa, A. (PORTUGAL) 
Rossi, D. (ITALY)  
Ruano, A. (PORTUGAL) 
Sala, A. (SPAIN) 
Sanz, R. (SPAIN) 
Sarkar, N. (U.S.A.) 
Sasiadek, J. (CANADA) 
Scherer, C. (THE NETHERLANDS) 
Schilling, K. (GERMANY) 
Sentieiro, J. (PORTUGAL)  
Sequeira, J. (PORTUGAL) 
Sessa, R. (ITALY) 
xii
Conference Committee

Siciliano, B. (ITALY)  
Silva, C. (CANADA) 
Spong, M. (U.S.A.) 
Stahre, J. (SWEDEN) 
van Straten, G. (THE NETHERLANDS) 
Sznaier, M. (U.S.A.) 
Tarasiewicz, S. (CANADA) 
Tettamanzi, A. (ITALY) 
Thalmann, D. (SWITZERLAND) 
Valavani, L. (U.S.A.) 
Valverde, N. (MEXICO) 
van Hulle, M.  (BELGIUM) 
Varkonyi-Koczy, A. (HUNGARY) 
Veloso, M. (U.S.A.) 
Vlacic, L. (GERMANY) 
Wang, J. (CHINA) 
Wang, L. (SINGAPORE) 
Yakovlev, A. (U.K.) 
Yen, G. (U.S.A.) 
Yoshizawa, S. (JAPAN) 
Zhang, Y. (U.S.A.) 
Zomaya, A. (AUSTRALIA) 
Zuehlke, D. (GERMANY)
Invited Speakers 
Kevin Warwick,  University of Reading, UK 
Kurosh Madani, PARIS XII University, France 
F. Wolfgang Arndt, Fachhochschule Konstanz, Germany 
Albert Cheng, University of Houston, USA 
Rosalind Picard, Massachusetts Institute of Technology, USA 
Nuno Martins, Massachusetts Institute of Technology, USA 
xiii
Conference Committee

INVITED SPEAKERS

ROBOT-HUMAN INTERACTION 
Kevin Warwick 
Department of Cybernetics, University of Reading,  
Whiteknights, Reading, RG6 6AY, UK 
Email: k.warwick@reading.ac.uk 
Abstract:  
This paper presents results to indicate the potential applications of a direct connection between the human 
nervous system and a computer network. Actual experimental results obtained from a human subject study 
are given, with emphasis placed on the direct interaction between the human nervous system and possible 
extra-sensory input. An brief overview of the general state of neural implants is given, as well as a range of 
application areas considered. An overall view is also taken as to what may be possible with implant tech-
nology as a general purpose human-computer interface for the future. 
1 INTRODUCTION 
There are a number of ways in which biological 
signals can be recorded and subsequently acted upon 
to bring about the control or manipulation of an item 
of technology, (Penny et al., 2000, Roberts et al., 
1999). Conversely it may be desired simply to moni-
tor the signals occurring for either medical or scien-
tific purposes. In most cases, these signals are col-
lected externally to the body and, whilst this is posi-
tive from the viewpoint of non-intrusion into the 
body with its potential medical side-effects such as 
infection, it does present enormous problems in 
deciphering and understanding the signals observed 
(Wolpaw et al., 1991, Kubler et al., 1999). Noise 
can be a particular problem in this domain and in-
deed it can override all other signals, especially 
when compound/collective signals are all that can be 
recorded, as is invariably the case with external 
recordings which include neural signals. 
     A critical issue becomes that of selecting exactly 
which signals contain useful information and which 
are noise, and this is something which may not be 
reliably achieved. Additionally, when specific, tar-
geted stimulation of the nervous system is required, 
this is not possible in a meaningful way for control 
purposes merely with external connections. The 
main reason for this is the strength of signal re-
quired, which makes stimulation of unique or even 
small subpopulations of sensory receptor or motor 
unit channels unachievable by such a method. 
     A number of research groups have concentrated 
on animal (non-human) studies, and these have 
certainly provided results that contribute generally 
to the knowledge base in the field. Unfortunately 
actual human studies involving implants are rela-
tively limited in number, although it could be said 
that research into wearable computers has provided 
some evidence of what can be done technically with 
bio-signals. We have to be honest and say that pro-
jects which involve augmenting shoes and glasses 
with microcomputers (Thorp, 1997) are perhaps not 
directly useful for our studies, however monitoring 
indications of stress or alertness by this means can 
be helpful in that it can give us an idea of what 
might be subsequently achievable by means of an 
implant. Of relevance here are though studies in 
which a miniature computer screen was fitted onto a 
standard pair of glasses. In this research the wearer 
was given a form of augmented/remote vision 
(Mann, 1997), where information about a remote 
scene could be relayed back to the wearer, thereby 
affecting their overall capabilities. However, in 
general, wearable computers require some form of 
signal conversion to take place in order to interface 
external technology with specific human sensory 
receptors. What are clearly of far more interest to 
our own studies are investigations in which a direct 
electrical link is formed between the nervous system 
and technology. 
Quite a number of relevant animal studies have 
been carried out, see (Warwick, 2004) for a review. 
As an example, in one study the extracted brain of a 
lamprey was used to control the movement of a 
small-wheeled robot to which it was attached (Reger 
et al., 2000). The innate response of a lamprey is to 
position itself in water by detecting and reacting to 
external light on the surface of the water. The lam-
Practical experiments with a cyborg
© 2006 Springer. Printed in the Netherlands.
3
J. Braz 
(eds.), Informatics in Control, Automation and Robotics I, 1–10. 
et al. 

prey robot was surrounded by a ring of lights and 
the innate behaviour was employed to cause the 
robot to move swiftly towards the active light 
source, when different lights were switched on and 
off.
Rats have been the subjects of several studies. In 
one (Chapin et al., 1999), rats were trained to pull a 
lever in order that they received a liquid reward for 
their efforts. Electrodes were chronically implanted 
into the motor cortex of the rats’ brains to directly 
detect neural signals generated when each rat (it is 
claimed) thought about pulling the lever, but, impor-
tantly, before any physical movement occurred. The 
signals measured immediately prior to the physical 
action necessary for lever pulling were used to di-
rectly release the reward before a rat actually carried 
out the physical action of pulling the lever itself. 
Over the time of the study, which lasted for a few 
days, four of the six implanted rats learned that they 
need not actually initiate any action in order to ob-
tain the reward; merely thinking about the action 
was sufficient. One problem area that needs to be 
highlighted with this is that although the research is 
certainly of value, because rats were employed in 
the trial we cannot be sure what they were actually 
thinking about in order to receive the reward, or 
indeed whether the nature of their thoughts changed 
during the trial.
In another study carried out by the same group 
(Talwar et al., 2002), the brains of a number of rats 
were stimulated via electrodes in order to teach them 
to be able to carry out a maze solving problem. Re-
inforcement learning was used in the sense that, as it 
is claimed, pleasurable stimuli were evoked when a 
rat moved in the correct direction. Although the 
project proved to be successful, we cannot be sure 
of the actual feelings perceived by the rats, whether 
they were at all pleasurable when successful or un-
pleasant when a negative route was taken. 
1.1 Human Integration 
Studies which focus, in some sense, on integrating 
technology with the Human Central Nervous System 
range from those considered to be diagnostic (De-
neslic et al., 1994), to those which are clearly aimed 
solely at the amelioration of symptoms (Poboronuic 
et al., 2002, Popovic et al., 1998, Yu et al., 2001) to 
those which are directed towards the augmentation 
of senses (Cohen et al., 1999, Butz et al., 1999). By 
far the most widely reported research with human 
subjects however, is that involving the development 
of an artificial retina (Kanda et al., 1999). In this 
case small arrays have been attached directly onto a 
functioning optic nerve, but where the person con-
cerned has no operational vision. By means of 
stimulation of the nerve with appropriate signal 
sequences the user has been able to perceive shapes 
and letters indicated by bright light patterns. Al-
though relatively successful thus far, the research 
does appear to still have a long way to go, in that 
considerable software modification and tailoring is 
required in order to make the system operative for 
one individual. 
Electronic neural stimulation has proved to be ex-
tremely successful in other areas which can be 
loosely termed as being restorative. In this class, 
applications range from cochlea implants to the 
treatment of Parkinson’s disease symptoms. The 
most relevant to our study here however is the use of 
a single electrode brain implant, enabling a brain-
stem stroke victim to control the movement of a 
cursor on a computer screen (Kennedy et al., 2000). 
In the first instance extensive functional magnetic 
resonance imaging (fMRI) of the subject’s brain was 
carried out. The subject was asked to think about 
moving his hand and the fMRI scanner was used to 
determine where neural activity was most pro-
nounced. A hollow glass electrode cone containing 
two gold wires was subsequently positioned into the 
motor cortex, centrally located in the area of maxi-
mum-recorded activity. When the patient thought 
about moving his hand, the output from the elec-
trode was amplified and transmitted by a radio link 
to a computer where the signals were translated into 
control signals to bring about movement of the cur-
sor. The subject learnt to move the cursor around by 
thinking about different hand movements. No signs 
of rejection of the implant were observed whilst it 
was in position (Kennedy et al., 2000).
In the human studies described thus far, the main 
aim is to use technology to achieve some restorative 
functions where a physical problem of some kind 
exists, even if this results in an alternative ability 
being generated. Although such an end result is 
certainly of interest, one of the main directions of 
the study reported in this paper is to investigate the 
possibility of giving a human extra capabilities, over 
and above those initially in place. 
In the section which follows a MicroElectrode 
Array (MEA) of the spiked electrode type is de-
scribed. An array of this type was implanted into a 
human nervous system to act as an electrical sili-
con/biological interface between the human nervous 
system and a computer. As an example, a pilot study 
is described in which the output signals from the 
array are used to drive a range of technological 
entities, such as mobile robots and a wheelchair. 
These are introduced merely as an indication of 
what is possible. A report is then also given of a 
continuation of the study involving the feeding of 
signals obtained from ultrasonic sensors down onto 
the nervous system, to bring about sensory en-
4
K. Warwick

hancement, i.e. giving a human an ultrasonic sense. 
It is worth emphasising here that what is described 
in this article is an actual application study rather 
than a computer simulation or mere speculation. 
2 INVASIVE NEURAL 
INTERFACE
There are, in general, two approaches for peripheral 
nerve interfaces when a direct technological connec-
tion is required: Extraneural and Intraneural. In 
practical terms, the cuff electrode is by far the most 
commonly encountered extraneural device. A cuff 
electrode is fitted tightly around the nerve trunk, 
such that it is possible to record the sum of the sin-
gle fibre action potentials apparent, this being 
known as the compound action potential (CAP). In 
other words, a cuff electrode is suitable only if an 
overall compound signal from the nerve fibres is 
required. It is not suitable for obtaining individual or 
specific signals. It can though also be used for 
crudely selective neural stimulation of a large region 
of the nerve trunk. In some cases the cuff can con-
tain a second or more electrodes, thereby allowing 
for an approximate measurement of signal speed 
travelling along the nerve fibres.
For applications which require a much finer 
granularity for both selective monitoring and stimu-
lation however, an intraneural interface such as 
single electrodes either inserted individually or in 
groups can be employed. To open up even more 
possibilities a MicroElectrode Array (MEA) is well 
suited. MEAs can take on a number of forms, for 
example they can be etched arrays that lie flat 
against a neural surface (Nam et al., 2004) or spiked 
arrays with electrode tips. The MEA employed in 
this study is of this latter type and contains a total of 
100 electrodes which, when implanted, become 
distributed within the nerve fascicle. In this way, it 
is possible to gain direct access to nerve fibres from 
muscle spindles, motor neural signals to particular 
motor units or sensory receptors. Essentially, such a 
device allows a bi-directional link between the hu-
man nervous system and a computer (Gasson et al., 
2002, Branner et al., 2001, Warwick et al., 2003).  
2.1 Surgical Procedure 
On 14 March 2002, during a 2 hour procedure at the 
Radcliffe Infirmary, Oxford, a MEA was surgically 
implanted into the median nerve fibres of my left 
arm. The array measured 4mm x 4mm with each of 
the electrodes being 1.5mm in length. Each elec-
trode was individually wired via a 20cm wire bundle 
to an electrical connector pad. A distal skin incision 
marked at the distal wrist crease medial to the pal-
maris longus tendon was extended approximately 4 
cm into the forearm. Dissection was performed to 
identify the median nerve. In order that the risk of 
infection in close proximity to the nerve was re-
duced, the wire bundle was run subcutaneously for 
16 cm before exiting percutaneously. For this exit a 
second proximal skin incision was made distal to the 
elbow 4 cm into the forearm. A modified plastic 
Figure 1: A 100 electrode, 4X4mm MicroElectrode Array, shown on a UK 1 pence piece for scale.
5
Robot-Human Interaction

shunt passer was inserted subcutaneously between 
the two incisions by means of a tunnelling proce-
dure. The MEA was introduced to the more proxi-
mal incision and pushed distally along the passer to 
the distal skin incision such that the wire bundle 
connected to the MEA ran within it. By removing 
the passer, the MEA remained adjacent to the ex-
posed median nerve at the point of the first incision 
with the wire bundle running subcutaneously, exit-
ing at the second incision. At the exit point, the wire 
bundle linked to the electrical connector pad which 
remained external to the arm. 
The perineurium of the median nerve (its outer 
protective sheath) was dissected under microscope 
to facilitate the insertion of electrodes and to ensure 
that the electrodes penetrated the nerve fibres to an 
adequate depth. Following dissection of the per-
ineurium, a pneumatic high velocity impact inserter 
was positioned such that the MEA was under a light 
pressure to help align insertion direction. The MEA 
was pneumatically inserted into the radial side of the 
median nerve allowing the MEA to sit adjacent to 
the nerve fibres with the electrodes penetrating into 
a fascicle. The median nerve fascicle was estimated 
to be approximately 4 mm in diameter. Penetration 
was confirmed under microscope. Two Pt/Ir refer-
ence wires were also positioned in the fluids sur-
rounding the nerve. 
The arrangements described remained perma-
nently in place for 96 days, until 18th June 2002, at 
which time the implant was removed. 
2.2 Neural Stimulation and Neural 
Recordings
Once it was in position, the array acted as a bi-
directional neural interface. Signals could be trans-
mitted directly from a computer, by means of either 
a hard wire connection or through a radio transmit-
ter/receiver unit, to the array and thence to directly 
bring about a stimulation of the nervous system. In 
addition, signals from neural activity could be de-
tected by the electrodes and sent to the computer and 
thence onto the internet. During experimentation, it 
was found that typical activity on the median nerve 
fibres occurs around a centroid frequency of ap-
proximately 1 KHz with signals of apparent interest 
occurring well below 3.5 KHz. However noise is a 
distinct problem due to inductive pickup on the 
wires, so had to be severely reduced. To this end a 
fifth order band limited Butterworth filter was used 
with corner frequencies of flow= 250 Hz and fhigh =
7.5 KHz. 
To allow freedom of movement, a small wearable 
signal processing unit with Radio Frequency com-
munications was developed to be worn on a gauntlet 
around the wrist. This custom hardware consisted of 
a 20 way multiplexer, two independent filters, two 
10bit A/D converters, a microcontroller and an FM 
radio transceiver module. Either 1 or 2 electrodes 
from the array could be quasi-statically selected, 
digitised and sent over the radio link to a corre-
sponding receiver connected to a PC. At this point 
they could either be recorded or transmitted further 
in order to operate networked technology, as de-
scribed in the following section. Onward transmis-
sion of the signal was via an encrypted TCP/IP tun-
nel, over the local area network, or wider internet. 
Remote configuration of various parameters on the 
wearable device was also possible via the radio link 
from the local PC or the remote PC via the en-
crypted tunnel. 
Stimulation of the nervous system by means of 
the array was especially problematic due to the lim-
ited nature of existing results prior to the study re-
ported here, using this type of interface. Published 
work is restricted largely to a respectably thorough 
but short term study into the stimulation of the sci-
atic nerve in cats (Branner et al., 2001). Much ex-
perimental time was therefore required, on a trial 
and error basis, to ascertain what voltage/current 
relationships would produce a reasonable (i.e. per-
ceivable but not painful) level of nerve stimulation. 
Further factors which may well emerge to be rele-
vant, but were not possible to predict in this experi-
mental session were firstly the plastic, adaptable 
nature of the human nervous system, especially the 
brain – even over relatively short periods, and sec-
ondly the effects of movement of the array in rela-
tion to the nerve fibres, hence the connection and 
associated input impedance of the nervous system 
was not completely stable. 
After experimentation lasting for approximately 6 
weeks, it was found that injecting currents below 
80µA onto the median nerve fibres had little per-
ceivable effect. Between 80µA and 100µA all the 
functional electrodes were able to produce a recog-
nisable stimulation, with an applied voltage of 
around 20 volts peak to peak, dependant on the 
series electrode impedance. Increasing the current 
above 100µA had little additional effect; the stimu-
lation switching mechanisms in the median nerve 
fascicle exhibited a non-linear thresholding charac-
teristic.
In all successful trials, the current was applied as 
a bi-phasic signal with pulse duration of 200µsec 
and an inter-phase delay of 100µsec. A typical 
stimulation waveform of constant current being 
applied to one of the MEAs implanted electrodes is 
shown in Fig. 2. 
6
K. Warwick

Figure 2: Voltage profile during one bi-phasic stimulation 
It was therefore possible to create alternative sen-
sations via this new input route to the nervous sys-
tem, thereby by-passing the normal sensory inputs. 
The reasons for the 6 weeks necessary for successful 
nerve stimulation, in the sense of stimulation signals 
being correctly recognised, can be due to a number 
of factors such as (1) suitable pulse characteristics, 
(i.e. amplitude, frequency etc) required to bring 
about a perceivable stimulation were determined 
experimentally during this time, (2) my brain had to 
adapt to recognise the new signals it was receiving, 
and (3) the bond between my nervous system and 
the implant was physically changing. 
3 NEURAL INTERACTION WITH 
TECHNOLOGY
It is apparent that the neural signals obtained 
through the implant can be used for a wide variety 
of purposes. One of the key aims of the research 
was, in fact, to assess the feasibility of the implant 
for use with individuals who have limited functions 
due to a spinal injury. Hence in experimental tests, 
neural signals were employed to control the func-
tioning of a robotic hand and to drive an electric 
wheelchair around successfully (Gasson et al., 2002, 
Warwick et al., 2003). The robotic hand was also 
controlled, via the internet, at a remote location 
In these applications, data collected via the neural 
implant were directly employed for control pur-
poses, removing the need for any external control 
devices or for switches or buttons to be used. Essen-
tially signals taken directly from my nervous system 
were used to operate the technology. To control the 
electric wheelchair, a sequential-state machine was 
incorporated. Neural signals were used as a real-
time command to halt the cycle at the intended 
wheelchair action, e.g. drive forwards. In this way 
overall control of the chair was extremely simple to 
ensure, thereby proving the general potential use of 
such an interface. 
Initially selective processing of the neural signals 
obtained via the implant was carried out in order to 
produce discrete direction control signals. With only 
a small learning period I was able to control not only 
the direction but also the velocity of a fully autono-
mous, remote mobile platform. On board sensors 
allowed the robot to override my commands in order 
to safely navigate local objects in the environment.  
Once stimulation of the nervous system had been 
achieved, as described in section 2, the bi-directional 
nature of the implant could be more fully experi-
mented with. Stimulation of the nervous system was 
activated by taking signals from fingertips sensors 
on the robotic hand. So as the robotic hand gripped 
an object, in response to outgoing neural signals via 
the implant, signals from the fingertips of the robotic 
hand brought about stimulation. As the robotic hand 
applied more pressure the frequency of stimulation 
increased. The robotic hand was, in this experiment, 
acting as a remote, extra hand.   
By passing the neural signals not simply from 
computer to the robot hand, and vice versa, but also 
via the internet, so the hand could actually be lo-
7
Figure 3: Intelligent anthropomorphic hand prosthesis. 
pulse cycle with a constant current of 80µA. 
(Warwick et al., 2004). 
Robot-Human Interaction

signals were transmitted between Columbia Univer-
sity in New York City and Reading University in the 
UK, with myself being in New York and the robot 
hand in the UK. Effectively this can be regarded as 
extending the human nervous system via the inter-
net. To all intents and purposes my nervous system 
did not stop at the end of my body, as is the usual 
case, but rather went as far as the internet would 
take it, in this case across the Atlantic Ocean. 
In another experiment, signals were obtained 
from ultrasonic sensors fitted to a baseball cap. The 
output from these sensors directly affected the rate 
of neural stimulation. With a blindfold on, I was 
able to walk around in a cluttered environment 
whilst detecting objects in the vicinity through the 
(extra) ultrasonic sense. With no objects nearby, no 
neural stimulation occurred. As an object moved 
relatively closer, so the stimulation increased pro-
It is clear that just about any technology, which 
can be networked in some way, can be switched on 
and off and ultimately controlled directly by means 
of neural signals through an interface such as the 
implant used in this experimentation. Not only that, 
but because a bi-directional link has been formed, 
feedback directly to the brain can increase the range 
of sensory capabilities. Potential application areas 
are therefore considerable. 
4 CONCLUSIONS 
Partly this study was carried out in order to assess 
the implant interface technology in terms of its use-
fulness in helping those with a spinal injury. As a 
positive result in this sense it can be reported that 
during the course of the study there was no sign of 
infection or rejection. In fact, rather than reject the 
implant, my body appeared to accept the device 
implicitly to the extent that its acceptance may well 
have been improving over time. 
Clearly the implant would appear to allow for the 
restoration of some movement and the return of 
body functions in the case of a spinally injured pa-
tient. It would also appear to allow for the patient to 
control technology around them merely by neural 
signals alone. Further human experimentation is 
though clearly necessary to provide further evidence 
in this area.
Such implanted interface technology would how-
ever appear to open up many more opportunities. In 
the case of the experiments described, an articulated 
robot hand was controlled directly by neural signals. 
8
Figure 4: Experimentation and testing of the ultrasonic baseball cap. 
portionally (Gasson et al., 2005). 
cated remotely. In a test (Warwick et al., 2004) 
K. Warwick

For someone who has had their original hand ampu-
tated this opens up the possibility of them ultimately 
controlling an articulated hand, as though it were 
their own, by the power of their own thought. 
Much more than this though, the study opens up 
the distinct possibility of humans being technically 
enhanced and upgraded, rather than merely repaired. 
One example of this was the extra sensory (ultra 
sonic) experiment that was far more successful than 
had been expected. Although this does open up a 
number of distinct ethical questions, as to what up-
grades are acceptable and for whom, it also opens up 
an exciting period of experimentation to see how far 
the human brain can be expanded in a technical 
sense.
The author accepts the fact that this is a one off 
study based on only one implant recipient. It may be 
that other recipients react in other ways and the 
experiments carried out would not be so successful 
with an alternative recipient. In that sense the author 
wishes this study to be seen as evidence that the 
concept can work well, although it is acknowledged 
that further human trials will be necessary to inves-
tigate the extent of usefulness. 
As far as an implant interface is concerned, what 
has been achieved is a very rudimentary and primi-
tive first step. It may well prove to be the case that 
implants of the type used here are not ultimately 
those selected for a good link between a computer 
and the human brain. Nevertheless the results ob-
tained are felt to be extremely encouraging. 
ACKNOWLEDGEMENTS
Ethical approval for this research to proceed was 
obtained from the Ethics and Research Committee at 
the University of Reading and, with regard to the 
neurosurgery, by the Oxfordshire National Health 
Trust Board overseeing the Radcliffe Infirmary, 
Oxford, UK. 
My thanks go to Mr. Peter Teddy and Mr. Amjad 
Shad who performed the neurosurgery at the Rad-
cliffe Infirmary and ensured the medical success of 
the project. My gratitude is also extended to NSIC, 
Stoke Mandeville and to the David Tolkien Trust for 
their support. 
REFERENCES
Penny, W., Roberts, S., Curran, E., and Stokes, M., 2000, 
“EEG-based communication: A pattern recognition 
approach”, IEEE Transactions on Rehabilitation Engi-
neering., Vol. 8, Issue.2, pp. 214-215.
Roberts, S., Penny, W., and Rezek, I., 1999, “Temporal 
and spatial complexity measures for electroencephalo-
gram based brain-computer interfacing”, Medical and 
Biological Engineering and Computing, Vol. 37, Is-
Wolpaw, J., McFarland, D., Neat, G. and Forneris, C., 
1991, “An EEG based brain-computer interface for 
cursor control”, Electroencephalography and Clinical 
Neurophysiology, Vol. 78, Issue.3, pp. 252-259. 
Kubler, A., Kotchoubey, B., Hinterberger, T., Ghanayim, 
N., Perelmouter, J., Schauer, M., Fritsch, C., Taub, E. 
and Birbaumer, N., 1999, “The Thought Translation 
device: a neurophysiological approach to communica-
tion in total motor paralysis”, Experimental Brain Re-
search, Vol. 124, Issue.2, pp. 223-232. 
Thorp, E., “The invention of the first wearable computer”, 
1997, In Proceedings of the Second IEEE Interna-
tional Symposium on Wearable Computers, pp. 4–8, 
Pittsburgh.
Mann, S., 1997, “Wearable Computing: A first step to-
wards personal imaging”, Computer, Vol. 30, Issue.2, 
pp. 25-32. 
Warwick, K., 2004, “I, Cyborg”, University of Illinois 
Press.  
Reger, B., Fleming, K., Sanguineti, V., Simon Alford, S., 
Mussa-Ivaldi, F., 2000, “Connecting Brains to Robots: 
The Development of a Hybrid System for the Study of 
Learning in Neural Tissues”, Artificial Life VII, Port-
land, Oregon. 
Chapin, J., Markowitz, R., Moxon, K., and Nicolelis, M., 
1999, “Real-time control of a robot arm using simul-
taneously recorded neurons in the motor cortex”. Na-
ture Neuroscience, Vol. 2, Issue.7, pp. 664-670. 
Talwar, S., Xu, S., Hawley, E., Weiss, S., Moxon, K., 
Chapin, J., 2002, “Rat navigation guided by remote 
control”. Nature, Vol. 417, pp. 37-38. 
Denislic, M., Meh, D., 1994, “Neurophysiological as-
sessment of peripheral neuropathy in primary 
Sjögren’s syndrome”, Journal of Clinical Investiga-
tion, Vol. 72, 822-829. 
Poboroniuc, M.S., Fuhr, T., Riener, R., Donaldson, N., 
2002, “Closed-Loop Control for FES-Supported 
Standing Up and Sitting Down”, Proc. 7th Conf. of the 
IFESS, Ljubljana, Slovenia, pp. 307-309. 
Popovic, M. R., Keller, T., Moran, M., Dietz, V., 1998, 
“Neural prosthesis for spinal cord injured subjects”, 
Journal Bioworld, Vol. 1, pp. 6-9. 
Yu, N., Chen, J., Ju, M.; 2001, “Closed-Loop Control of 
Quadriceps/Hamstring activation for FES-Induced 
Standing-Up Movement of Paraplegics”, Journal of 
Musculoskeletal Research, Vol. 5, No.3. 
Cohen, M., Herder, J. and Martens, W.; 1999, “Cyberspa-
tial Audio Technology”, JAESJ, J. Acoustical Society 
of Japan (English), Vol. 20, No. 6, pp. 389-395, No-
vember.
Butz, A., Hollerer, T., Feiner, S., McIntyre, B., Beshers, 
C., 1999, “Enveloping users and computers in a col-
9
Robot-Human Interaction
sue.1, pp. 93-98. 

laborative 3D augmented reality”, IWAR99, San Fran-
cisco, pp. 35-44. 
Kanda, H., Yogi, T., Ito, Y., Tanaka, S., Watanabe, M and 
Uchikawa, Y., 1999, “Efficient stimulation inducing 
neural activity in a retinal implant”, Proc. IEEE Inter-
national Conference on Systems, Man and Cybernet-
ics, Vol 4, pp. 409-413. 
Kennedy, P., Bakay, R., Moore, M., Adams, K. and 
Goldwaithe, J., 2000, “Direct control of a computer 
from the human central nervous system”, IEEE Trans-
actions on Rehabilitation Engineering, Vol. 8, pp. 
198-202.
Nam, Y., Chang, J.C.., Wheeler, B.C. and Brewer, G.J., 
2004, “Gold-coated microelectrode array with Thiol 
linked self-assembled monolayers for engineering 
neuronal cultures”, IEEE Transactions on Biomedical 
Engineering,  Vol. 51, No. 1, pp. 158-165.
Gasson, M.., Hutt, B., Goodhew, I., Kyberd, P. and War-
wick, K; 2002, “Bi-directional human machine inter-
face via direct neural connection”, Proc. IEEE Work-
shop on Robot and Human Interactive Communica-
tion, Berlin, German, pp. 265-270. 
Branner, A., Stein, R. B. and Normann, E.A., 2001, “Se-
lective “Stimulation of a Cat Sciatic Nerve Using an 
Array of Varying-Length Micro electrodes”, Journal 
of Neurophysiology, Vol. 54, No. 4, pp. 1585-1594. 
Warwick, K., Gasson, M., Hutt, B., Goodhew, I., Kyberd, 
P., Andrews, B, Teddy, P and Shad. A, 2003, “The 
Application of Implant Technology for Cybernetic 
Systems”, Archives of Neurology, Vol. 60, No.10, pp. 
1369-1373.
Warwick, K., Gasson, M., Hutt, B., Goodhew, I., Kyberd, 
K., Schulzrinne, H. and Wu, X., 2004, “Thought 
Communication and Control: A First Step using Ra-
diotelegraphy”, IEE Proceedings-Communications, 
Vol. 151, No. 3, pp. 185-189. 
Gasson, M., Hutt, B., Goodhew, I., Kyberd, P. and War-
wick, K., 2005, “Invasive Neural Prosthesis for Neural 
Signal detection and Nerve Stimulation”, International 
Journal of Adaptive Control and Signal Processing, 
Vol. 19.
10
K. Warwick

INDUSTRIAL AND REAL WORLD APPLICATIONS OF 
ARTIFICIAL NEURAL NETWORKS 
Illusion or reality? 
Kurosh Madani 
Intelligence in Instrumentation and Systems Lab. (I2S Lab.),  
PARIS XII University, Senart Institute of Technology, Pierre Point avenue, F-77127 Lieusaint, France 
Email: madani@univ-paris12.fr
Keywords: 
Artificial Neural Networks (ANN), Industrial applications, Real-world applications. 
Abstract: 
Inspired from biological nervous systems and brain structure, Artificial Neural Networks (ANN) could be 
seen as information processing systems, which allow elaboration of many original techniques covering a 
large field of applications. Among their most appealing properties, one can quote their learning and 
generalization capabilities. If a large number of works have concerned theoretical and implementation 
aspects of ANN, only a few are available with reference to their real world industrial application 
capabilities. In fact, applicability of an available academic solution in industrial environment requires 
additional conditions due to industrial specificities, which could sometimes appear antagonistic with 
theoretical (academic) considerations. The main goal of this paper is to present, through some of main ANN 
models and based techniques, their real application capability in real industrial dilemmas. Several examples 
dealing with industrial and real world applications have been presented and discussed covering "intelligent 
adaptive control", "fault detection and diagnosis", "decision support", "complex systems identification" and 
"image processing". 
1 INTRODUCTION 
Real world dilemmas, and especially industry related 
ones, are set apart from academic ones from several 
basic points of views. The difference appears since 
definition of the “problem’s solution” notion. In fact, 
academic 
(called 
also 
sometime 
theoretical) 
approach to solve a given problem often begins by 
problem’s constraints simplification in order to 
obtain a “solvable” model (here, solvable model 
means a set of mathematically solvable relations or 
equations describing a behavior, phenomena, etc…). 
step to study a given problem’s solvability, in the 
case of a very large number of real world dilemmas, 
it doesn’t lead to a solvable or realistic solution. A 
significant example is the modeling of complex 
behavior, where conventional theoretical approaches 
show very soon their limitations. Difficulty could be 
related to several issues among which: 
- large number of parameters to be taken into 
account (influencing the behavior) making 
conventional mathematical tools inefficient,   
- strong nonlinearity of the system (or behavior), 
leading to unsolvable equations, 
- partial or total inaccessibility of system’s 
relevant 
features, 
making 
the 
model 
insignificant,
- subjective nature of relevant features, parameters 
or data, making the processing of such data or 
parameters difficult in the frame of conventional 
quantification,
- necessity of expert’s knowledge, or heuristic 
information consideration, 
- imprecise information or data leakage. 
Examples 
illustrating 
the 
above-mentioned 
difficulties are numerous and may concern various 
areas of real world or industrial applications. As first 
example, one can emphasize difficulties related to 
economical and financial modeling and prediction, 
where the large number of parameters, on the one 
hand, and human related factors, on the other hand, 
make related real world problems among the most 
difficult to solve. Another example could be given in 
the 
frame 
of 
the 
industrial 
processes 
and 
manufacturing where strong nonlinearities related to 
complex nature of manufactured products affect 
controllability and stability of production plants and 
processes. Finally, one can note the difficult 
dilemma of complex pattern and signal recognition 
and analysis, especially when processed patterns or 
11
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.),  Informatics in Control, Automation and Robotics I, 11–26. 
If the theoretical consideration is an indispensable 

signals are strongly noisy or deal with incomplete 
data.
Over the past decades, Artificial Neural 
Networks (ANN) and issued approaches have 
allowed the elaboration of many original techniques 
(covering a large field of applications) overcoming 
some of mentioned difficulties (Nelles, 1995) 
(Faller, 1995) (Maidon, 1996), (Madani, 1997) 
(Sachenco, 2000). Their learning and generalization 
capabilities make them potentially promising for 
industrial applications for which conventional 
approaches show their failure. However, even if 
ANN and issued approaches offer an attractive 
potential for industrial world, their usage should 
always satisfy industrial “specificities”. In the 
context of the present paper, the word “specificity” 
intends characteristic or criterion channelling 
industrial preference for a strategy, option or 
solution as an alternative to the others. 
In fact, several specificities distinguish the 
industrial world and related constraints from the 
others. Of course, here the goal is not to analyse all 
those specificities but to overview briefly the most 
pertinent ones. As a first specificity one could 
mention the “reproducibility”. That means that an 
industrial solution (process, product, etc…) should 
be reproducible. This property is also called solution 
stability. 
A 
second 
industrial 
specificity 
is 
“viability”, 
which 
means 
implementation 
(realization) possibility. That signifies that an 
industrial solution should be adequate to available 
technology and achievable in reasonable delay 
(designable, 
realizable). 
Another 
industrial 
specificity is “saleability”, which means that an 
industrial solution should recover a well identified 
field of needs. Finally, an additional important 
specificity is “marketability” making a proposed 
industrial solution attractive and concurrent (from 
the point of view of cost, price-quality ratio, etc…) 
to other available products (or solutions) concerning 
the same area. 
Another key point to emphasize is related to the 
real world constraints consideration. In fact, dealing 
with real world environment and related realities, it 
is not always possible to put away the lower degree 
phenomena’s influence or to neglect secondary 
parameters. That’s why a well known solved 
academic problem could sometime appear as an 
unachieved (unbearable) solution in the case of an 
industry related dilemma. In the same way a viable 
and marketable industrial solution may appear as 
primitive from academic point of view. 
The main goal of this paper is to present, through 
main ANN models and based techniques, the 
effectiveness of such approaches in real world 
industrial problems solution. Several examples 
through real world industrial applications have been 
shown and discussed. The present paper has been 
organized as follows: the next section will present 
the general principle of Artificial Neural Networks 
relating it to biological considerations. In the same 
section two classes of neural models will be 
introduced and discussed: Multi-layer Perceptron 
and Kernel Functions based Neural Networks. The 
section 3 and related sub-sections will illustrate real 
world examples of application of such techniques. 
Finally, the last section will conclude the paper. 
2 FROM NATURAL TO 
ARTIFICIAL 
As mentions Andersen (Anderson, 1995): "It is not 
absolutely necessary to believe that neural network 
models have anything to do with the nervous system, 
but it helps. Because, if they do, we are able to use a 
large body of ideas, experiments, and facts from 
cognitive science and neuroscience to design, 
construct, and test networks. Otherwise, we would 
have to suggest functions and mechanism for 
intelligent behavior without any examples of 
successful operation". 
Much is still unknown about how the brain trains 
itself to process information, so theories abound. It 
is admitted that in the biological systems (human or 
animal brain), a typical neuron collects signals from 
others through a host of fine structures called 
dendrites. Figure 1 shows a simplified bloc diagram 
of biological neural system comparing it to the 
artificial neuron. The neuron sends out spikes of 
electrical activity through a long, thin stand known 
as an axon, which splits into thousands of branches. 
At the end of each branch, a structure called a 
synapse converts the activity from the axon into 
electrical effects that inhibit or excite activity from 
the axon into electrical effects that inhibit or excite 
activity in the connected neurones. When a neuron 
receives excitatory input that is sufficiently large 
compared with its inhibitory input, it sends a spike 
of electrical activity down its axon. Learning occurs 
by changing the effectiveness of the synapses so that 
the influence of one neuron on another changes. 
Inspired from biological neuron, artificial neuron 
reproduces a simplified functionality of that 
complex biological neuron. The neuron’s operation 
could be seen as following: a neuron updates its 
output from weighted inputs received from all 
neurons connected to that neuron. The decision to 
update or not the actual state of the neuron is 
performed 
thank 
to 
the
“decision 
function” 
depending to activity of those connected neurons. 
Let us consider a neuron with its state denoted by xi
(as it is shown in figure 1) connected to M other  
12
K. Madani

Xj
x1
xN
Neuron i
Si
Wij
6
Activation 
Function
neurons,  and  let  xj represent the state  (response) 
of the j-th neuron interconnected to that neuron with 
^
`
M
j
,
,1 

. Let 
ij
W
be the weight (called also, 
synaptic weight) between j-th and i-th neurons. In 
this case, the activity of all connected neurons to the 
i-th neuron, formalized through the “synaptic 
potential” of that neuron, is defined by relation (1). 
Fall back on its synaptic potential (and sometimes to 
other control parameters), the neuron’s decision 
function will putout (decide) the new state of the 
neuron according to the relation (2). One of the most 
commonly 
used 
decision 
functions 
is 
the 
“sigmoidal” function given by relation (3) where K
is a control parameter acting on decision strictness 
or softness, called also “learning rate”. 
¦
 
 
 
M
j
j
j
ij
i
x
W
V
1
.
(1)


¸¸
¹
·
¨¨
©
§
 
 
¦
 
 
M
j
j
j
ij
i
i
i
i
x
W
x
F
V
x
F
S
1
.
,
,
(2)
 
K
x
e
x
F


 
1
1
  
(3)
Also referred to as connectionist architectures, 
parallel distributed processing, and neuromorphic 
systems, an artificial neural network (ANN) is an 
information-processing paradigm inspired by the 
densely interconnected, parallel structure of the 
mammalian brain information processes. Artificial 
neural networks are collections of mathematical 
models that emulate some of the observed properties 
of biological nervous systems and draw on the 
analogies 
of 
adaptive 
biological 
learning 
mechanisms. The key element of the ANN paradigm 
is the novel structure of the information processing 
system. It is supposed to be composed of a large 
number 
of 
highly 
interconnected 
processing 
elements that are analogous to neurons and are tied 
together with weighted connections that are 
analogous to synapses. However, a large number of 
proposed architectures involve a limited number of 
neurones. 
Biologically, neural networks are constructed in 
a 
three 
dimensional 
way 
from 
microscopic 
components. These neurons seem capable of nearly 
unrestricted interconnections. This is not true in any 
artificial network. Artificial neural networks are the 
simple clustering of the primitive artificial neurons. 
This clustering occurs by creating layers, which are 
then connected to one another. How these layers 
connect may also vary. Basically, all artificial neural 
networks have a similar structure or topology. Some 
of their neurons interface the real world to receive its 
inputs and other neurons provide the real world with 
the network’s outputs. All the rest of the neurons are 
hidden form view. Figure 2 shows an artificial 
neural network’s general bloc-diagram. 
Input Layer
Layer_h
Output Layer
1
j
1
k
M
P
N
Si
i
1
S1
SM
X1
Xj
XM
Wk j
Wi k
Figure 2: Artificial neural network simplified bloc-
In general, the input layer consists of neurons 
that receive input form the external environment. 
The 
output 
layer 
consists 
of 
neurons 
that 
communicate the output of the system to the user or 
external environment. There are usually a number of 
hidden layers between these two layers. When the 
input layer receives the input its neurons produce 
output, which becomes input to the other layers of 
the system. The process continues until a certain 
condition is satisfied or until the output layer is 
invoked and fires their output to the external 
environment.
Let us consider a 3 layers standard neural 
network, including an input layer, a hidden layer and 
an output layer, conformably to the figure 2. Let us 
suppose that the input layer includes M neurons,  
13
diagrams.
output
layer 
includes 
N 
neurons. 
Let 
the hidden layer includes P neurons and the  
Figure 1: Biological (left) and artificial (right) neurons simplified bloc-diagrams.
Industrial and Real World Applications of Artificial Neural Networks


T
M
j
1
X
,
,
X
,
,
X


 
X
 represents the input vectors, 
with
^
`
M
,
,1
j


, 
 represents 
the hidden layer’s output with 
 and 
the 
output 
vector 
with 
. Let us note 
 and 
 synaptic 
matrixes elements, corresponding to input-hidden 
layers 
and 
hidden-output 
layers 
respectively. 
Neurons are supposed to have a non-linear decision 
function (activation function) F(.). 
 and 
, 
defined by relation (4), will represent the synaptic 
potential vectors components of hidden and output 
neurons, 
respectively 
(e.g. 
vectors 
and 
components). 
Taking 
into 
account 
such 
considerations, the k-th hidden and the i-th output 
neurons outputs will be given by relations (5). 


T
P
k
H
,
,
H
,
,
H


1
 
H
^
`
P
,
,1
k



T
N
i
1
S
,
,
S
,
,
S


 
S

`
^
N
,
,1
i


H
kj
W
S
ik
W
H
k
V
S
i
V
H
V
S
V
   
 and 
  
 
(4) 
¦
 
 
 
M
j
1
j
j
H
kj
H
k
x
.
W
V
¦
 
 
 
P
k
k
k
S
ik
S
i
h
W
V
1
.
       


H
k
k
V
F
H  
 and 


S
i
i
V
F
S  
  
(5) 
As it has been mentioned above, learning in 
biological systems involves adjustments to the 
synaptic connections that exist between the neurons. 
This is valid for ANNs as well. Learning typically 
occurs by example through training, or exposure to a 
set of input/output data (called also, learning 
database) where the training algorithm iteratively 
adjusts the connection weights (synapses). These 
connection weights store the knowledge necessary to 
solve specific problems. The strength of connection 
between the neurons is stored as a weight-value for 
the specific connection. The system learns new 
knowledge by adjusting these connection weights. 
The learning process could be performed in “on-
line” or in “off-line” mode. In the off-line learning 
methods, once the systems enters into the operation 
mode, its weights are fixed and do not change any 
more. Most of the networks are of the off-line 
learning type. In on-line or real time learning, when 
the system is in operating mode (recall), it continues 
to learn while being used as a decision tool. This 
type of learning needs a more complex design 
structure.
The learning ability of a neural network is 
determined by its architecture (network’s topology, 
artificial neurons nature) and by the algorithmic 
method chosen for training (called also, “learning 
rule”). In a general way, learning mechanisms 
(learning processes) could be categorized in two 
classes: “supervised learning” (Arbib, 2003) (Hebb, 
1949) 
(Rumelhart, 
1986) 
and 
“unsupervised 
learning” (Kohonen, 1984) (Arbib, 2003). The 
supervised learning works on reinforcement from 
the outside. The connections among the neurons in 
the hidden layer are randomly arranged, then 
reshuffled according to the used learning rule in 
order to solving the problem. In general an “error” 
(or “cost”) based criterion is used to determine when 
stop the learning process: the goal is to minimize 
that error. It is called supervised learning, because it 
requires a teacher. The teacher may be a training set 
of data or an observer who grades the performance 
of the network results (from which the network’s 
output error is obtained). In the case where the 
unsupervised learning procedure is applied to adjust 
the ANN’s behaviour, the hidden neurons must find 
a way to organize themselves without help from the 
outside. In this approach, no sample outputs are 
provided to the network against which it can 
measure its predictive performance for a given 
vector of inputs. In general, a “distance” based 
criterion is used assembling the most resembling 
data. After a learning process, the neural network 
acts 
as 
some 
non-linear 
function 
identifier 
minimizing the output errors. 
ANNs learning dilemma have been the central 
interest of a large number research investigations 
during the two past decades, leading to a large 
number of learning rules (learning processes).  The 
next sub-sections will give a brief overview of the 
most usual of them: “Back-Propagation” (BP) based 
learning rule neural network, known also as “Multi-
Layer Perceptron and “Kernel Functions” based 
learning rule based neural networks trough one of 
their particular cases which are “Radial Basis 
Functions” (RBF-like neural networks). 
2.1 Back-Propagation Learning Rule 
and Multi-Layer Perceptron
Back-Propagation (Bigot, 1993) (Rumelhart, 1986) 
(Bogdan, 1994) based neural models, called also 
Back-Propagation based “Multi-Layer Perceptron” 
(MLP) are multi-layer neural network (conformably 
to the general bloc-diagram shown in figure 2). A 
neuron in this kind of neural network operates 
conformably to the general ANN’s operation frame 
e.g. according to equations (1), (2) and (3). The 
specificity of this class of neural network appears in 
the learning procedure, called “Back-Propagation of 
error gradient”.  
The principle of the BP learning rule is based on 
adjusting synaptic weights proportionally to the 
neural network’s output error. Examples (patterns 
from learning database) are presented to the neural 
network, then, for each of learning patterns, the 
neural network’s output is compared to the desired 
14
K. Madani

one and an “error vector” is evaluated. Then all 
synaptic 
weights 
are 
corrected 
(adjusted) 
proportionally to the evaluated output error. 
Synaptic weights correction is performed layer by 
layer from the output layer to the input layer. So, 
output error is back-propagated in order to correct 
synaptic weights. Generally, a quadratic error 
criterion, given by equation (6), is used. In this 
relation Si
represents the i-th output vector’s 
component and 
 represents the desired value of 
this component. Synaptic weights are modified 
according to relation (7), where 
 represents 
the synaptic variation (modification) of the synaptic 
weight connecting the j-th neurone and i-th neuron 
between two adjacent layers (layer h and layer h-1). 
K is a real coefficient called also “learning rate”. 
d
iS
h
j
i
dW ,

2
2
1
d
i
i
i
S
S 
 
H
   
 
 
(6) 
 
H
W
h
j
i
dW
grad
Șx

 
,
  
(7) 
The learning rate parameter is decreased 
progressively during the learning process. The 
learning process stops when the output error reaches 
some acceptable value. 
2.2 Kernel Functions Based Neural 
Models
This kind of neural models belong to the class of 
“evolutionary” 
learning 
strategy 
based 
ANN 
(Reyneri, 1995)  (Arbib, 2003)  (Tremiolles, 1996). 
That means that the neural network’s structure is 
completed during the learning process. Generally, 
such kind of ANNs includes three layers: an input 
layer, a hidden layer and an output layer. Figure 3 
represents the bloc-diagram of such neural net. The 
number of neurons in input layer corresponds to the 
processed patterns dimensionality e.g. to the 
problem’s feature space dimension.  
The output layer represents a set of categories 
associated to the input data. Connections between 
hidden and output layers are established dynamically 
during the learning phase. It is the hidden layer 
which is modified during the learning phase. A 
neuron from hidden layer is characterized by its 
“centre” representing a point in an N dimensional 
space (if the input vector is an N-D vector) and some 
decision function, called also neuron’s “Region Of 
Influence” (ROI). ROI is a kernel function, defining 
some “action shape” for neurons in treated 
problem’s feature space. In this way, a new learning 
pattern is characterized by a point and an influence 
field (shape) in the problem’s N-D feature space. In 
the other words, the solution is mapped thank to 
learning examples in problem’s N-D feature space. 
The goal of the learning phase is to partition the 
input space associating prototypes with a categories 
and an influence field, a part of the input space 
around the prototype where generalization is 
possible. When a prototype is memorized, ROI of 
neighbouring neurons are adjusted to avoid conflict 
between neurons and related categories. The neural 
network’s response is obtained from relation (8) 
where 
Cj
represents 
a 
“category”, 
>
@
T
N
V
V
V
V

2
1
 
is 
the 
input 
vector,  
>
@
T
j
N
j
j
j
p
p
p
P

2
1
 
represents 
the 
j-th 
“prototype” memorized (learned) thanks to creation 
of the neuron j in the hidden layer, and O j the ROI  
associated to this neuron (neuron j). F(.) is the 
neuron’s activation (decision) function which is a 
radial basis function (a Gaussian function for 
example). 
V1
V2
Output Layer
Category
Input Layer
VN
C1
C2
Hidden Layer 
(Prototypes)
CM
Pj
V1
V2
c1
c2
V1
V1
V2
V2
c1
P1
P1
P2
P1
2
P2
1
P1
1
P2
2
P1
2
P1
1
V1
V2
Figure 3: Radial Basis Functions based ANN’s bloc-diagram (left). Example of learning process in 2-D feature space 
15
(right).
Industrial and Real World Applications of Artificial Neural Networks









j
j
j
j
j
j
j
P
V
dist
If
C
P
V
dist
If
P
V
dist
F
C
O
O
!
 
d
 
,
0
,
,
  
 
 
 
(8) 
n
i
n
j
ip
i
V
dist
¦

 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
(9) 
with


j
i
i
i
i
j
i
i
i
j
i
i
p
V
p
V
p
V

d
¸
¹
·
¨
©
§

d

¦
¦
max
2
1
2
  
 
 
 
 
 
(10) 
The choice of the distance calculation (choice of 
the used norm) is one of the main parameters in the 
case of the RCE-KNN like neural models (and 
derived approaches). The most usual function used 
to evaluate the distance between two patterns is the 
Minkowski function expressed by relation (9), where 
is the i-th component of the input vector and 
 
the i-th component of the j-th memorized pattern 
(learned pattern). Manhattan distance (
, called 
also L1 norm) and Euclidean distance (
Vi
j
ip
n  1
n  2 ) are 
particular cases of the Minkowski function and the 
most applied distance evaluation criterions. One can 
write relation (10). 
3 ANN BASED SOLUTIONS FOR 
INDUSTRIAL ENVIRONMENT 
If the problem’s complexity and the solution 
consistency, appearing through theoretical tools 
(modeling or conceptual complexity) needing to 
solve it, are of central challenges for applicability of 
a 
proposed 
concepts, 
another 
key 
points 
characterizing application design, especially in 
industrial environment, is related to implementation 
requirements. 
In 
fact, 
constraints 
related 
to 
production conditions, quality, etc. set the above-
mentioned point as a chief purpose to earn solution’s 
viability. That is why in the next subsections, 
dealing with real-world, and industrial applications 
of 
above-presented 
ANN 
models, 
the 
implementation 
issues 
will 
be 
of 
central 
considerations. Moreover, progress accomplished 
during the lasts decades concerning electrical 
engineering, especially in the microprocessors area, 
offers new perspectives for real time execution 
capabilities and enlarges the field for solution 
implementation ability. 
3.1 MLP Based Adaptive Controller  
Two 
meaningful 
difficulties 
characterize 
the 
controller dilemma, making controllers design one 
of the most challenging tasks: the first one is the 
plant parameters identification, and the second one 
is related to the consideration of interactions 
between real world (environment) and control 
system, especially in the case of real-world 
applications where controlled phenomena and 
related parameters deal with strong nonlinearities. 
Neural models and issued approaches offer original 
perspectives to overcome these two difficulties. 
However, beside these two difficulties, another chief 
condition for conventional or unconventional control 
is related to the controller’s implementation which 
deals with real-time execution capability. Recent 
progresses accomplished on the one hand, in the 
microprocessor design and architecture, and on the 
other hand, in microelectronics technology and 
manufacturing, leaded to availability of powerful 
microprocessors, offering new perspectives for 
software or hardware implementation, enlarging the 
field in real time execution capability. 
Finally, it should always be taken into account 
that proposed solution to a control dilemma (and so, 
the issued controller) emerges on the basis of former 
available equipments (plants, processes, factory, 
etc.). That’s why, with respect to above-discussed 
industrial specificities, preferentially it should not 
lead to a substantial modification of the still existent 
materials. In fact, in the most of real industrial 
control problems, the solution should enhance 
existent equipments and be adaptable to an earlier 
technological environment. 
3.1.1 General Frame and Formalization of 
Control Dilemma
The two usual strategies in conventional control are 
open-loop and feed-back loop (known also as feed-
16
K. Madani

back loop regulation) controllers. Figure 4 gives the 
general bloc-diagram of these two controllers, were 
Ek is the “input vector” (called also “order” vector), 
is 
the 
“output 
vector” (plant’s or system’s state or response) and 
is the “command 
vector”. k represents the discrete time variable. The 
output vector is defined as a vector which 
components are the m last system’s outputs. In the 
same way, the command vector is defined as a 
vector which components are the n last commands. 
Such vectors define output and command feature 
spaces of the system. Taking into account the 
general control bloc diagram (figure 4), the goal of 
the command is to make converge the system’s 
output with respect to some “desired output” noted 
Y

T
m
k
k
k
k
y
y
y
Y


 

1



T
n
k
k
k
k
u
u
u
U


 

1
d. If the command vector is a subject to some 
modifications, then the output vector will be 
modified. The output modification will be performed 
with respect to the system’s (plant, process or 
system under control) characteristics according to 
equation (11), where J represents the Jacobean 
matrix of the system. 
k
k
dU
dY
J
 
  
 
(11)
So, considering that the actual instant is k, it 
appears that to have an appropriated output (Y k+1 =
Y d), the output should be corrected according to the 
output error defined by: dYk = Yk – Yd. In the frame 
of such formulation, supposing that one could 
compute 
the 
system’s 
reverse 
Jacobean 
the 
command correction making system’s output to 
converge to the desired state (or response) will be 
conform to relation (12). 
k
k
dY
dU
1

 J
  
 
(12)
System’s Jacobean is related to plant’s features 
(parameters) involving difficulties mentioned before. 
Moreover, system’s reverse Jacobean computation is 
not a trivial task. In the real world applications, only 
in very few cases (as linear transfer functions) the 
system’s reverse Jacobean is available. So, typically 
a rough approximation of this matrix is obtained. 
3.1.2 ANN Based Controller  
Let us consider a neural network approximating 
(learning) a given system (process or plant). Let Y 
be the system’s output, U be the system’s command 
(U becomes also the neural network’s output), Wij
be synaptic weights of the neural network andHbe 
the output error representing some perturbation 
occurring on output. The part of output perturbation 
(output error) due to the variation of a given synaptic 
weight (Wij) of the neural network noted as 
ij
W
w
wH
could be written conformably to relation (13).  
ij
ij
W
u
u
y
y
W
w
w
w
w
w
w
 
w
w
H
H
(13)
One can remark that 
u
y
w
w
is the system’s 
Jacobean element and 
ij
W
u w
w
could be interpreted as 
the “neural network’s Jacobean” element. As the 
output error is related to the system’s controller 
characteristics (represented by system’s Jacobean), 
so the modification of synaptic weights with respect 
to the measured error (e.g. the neural network 
appropriated training) will lead to the correction of 
the command (dU) minimizing the output error. 
Several Neural Network based adaptive control 
architectures have still been proposed. However, 
taking into account the above-discussed industrial 
specificities, the most effective scheme is the hybrid 
neuro-controller (Hormel, 1992) (Miller, 1987) 
(Madani, 1996) (Albus, 1975) (Comoglio, 1992). 
This solution operates according to a Neural 
Network based correction of a conventional 
controller. Figure 5 shows the bloc diagram of such 
approach.
     
ORDER
CONTROLLER
SYSTEM 
or PLANT
Y(t)
E(t)
U(t)
ORDER
CONTROLLER
SYSTEM 
or PLANT
Y(t)
E(t)
U(t)
-
+
Figure 4: General bloc-diagrams of control strategies showing open-loop controller (left) and feed-back loop controller 
17
(Right) principles. 
Industrial and Real World Applications of Artificial Neural Networks

As one can see in our ANN based control 
strategy, the command U(t) is corrected thanks to the 
additional correction dU, generated by neural device 
and added to the conventional command component. 
The Neural Network’s learning could be performed 
on-line or off-line. 
Several advantages characterize the proposed 
strategy. The first one is related to the control 
system stability. En fact, in the worst case the 
controlled plant will operate according to the 
conventional control loop performances and so, will 
ensure the control system’s stability. The second 
advantage of such strategy is related to the fact that 
the proposed architecture acts as a hybrid control 
system where usual tasks are performed by a 
conventional operator and unusual operations (such 
as highly non linear operations or those which are 
difficult to be modelled by conventional approaches) 
are realized by neural network based component. 
This second advantage leads to another main welfare 
which is the implementation facility and so, the real-
time execution capability. Finally, the presented 
solution takes into account industrial environment 
reality where most of control problems are related to 
existent plants behaviours enhancement dealing with 
an available (still implemented) conventional 
controller. This last advantage of the proposed 
solution makes it a viable option for industrial 
environment. 
3.1.3 MLP Based Adaptive Controller 
Driving Turning Machine 
The above-exposed neural based hybrid controller 
has been used to enhance the conventional vector-
control driving a synchronous 3-phased alternative 
motor. The goal of a vector control or field-oriented 
control is to drive a 3-phased alternative motor like 
an independent excitation D.C motor. This consists 
to control the field excitation current and the torque 
generating current separately (Madani, 1999). The 
input currents of the motor should provide an 
electromagnetic 
torque 
corresponding 
to 
the 
command specified by the velocity regulator. For 
synchronous motor, the secondary magnetic flux 
(rotor) rotates at the same speed and in the same 
direction as the primary flux (stator). To achieve the 
above-mentioned goal, the three phases must be 
transformed into two equivalent perpendicular 
phases by using the Park transformation which needs 
the rotor position, determined by a transducer or a 
tachometer. In synchronous machine, the main 
parameters are Ld (inductance of d-phase), Lq 
(inductance of q-phase), and Rs (statoric resistor), 
which vary in relation with currents (Id and Iq), 
voltages (Vd and Vq), mechanical torque and speed 
(of such machine). The relations between voltages or 
currents depend on these three parameters defining 
the motor’s model. However, these parameters are 
not easily available because of their strongly 
nonlinear dependence to the environment conditions 
and high number of influent conditions. 
The neural network is able to identify these 
parameters and to correct the machine’s reference 
model, feeding back their real values through the 
control loop. Parameters are related to voltages, 
currents, speed and position. The command error 
(measured as voltage error) could be linked to the 
plant’s parameters values error. In the first step, the 
command is computed using nominal theoretical 
plant parameters. The neural network learns the 
plant’s behaviour comparing outputs voltages (Vd 
,Vq), extracted from an impedance reference model, 
with measured voltages (Vdm,Vqm). In the second 
step when the system is learned, the neural network 
gives the estimated plant’s parameters to the 
controller (Madani, 1999). 
18
Figure 5: General bloc-diagrams hybrid neuro-controller. 
K. Madani

DC LOAD
MAIN PLANT
 E
Leg 2
Leg 1
Leg 3
Inverter
PW M
D SP C ard
C om puter
A D C
A D C
A D C
A D C
PW M
PW M
Inverter legs
com m and
rotor
permanent
magnets
statoric
measurement
currents
resolver
position measurement(12 bits)
is1
is2
stator
Synchronous m achine
Normalized 
Ld
Order index in the learning data base 
Experimental Speed Evolution During
the Operation Phase
Time (sec)
SPEED
ORDER
75 (rad/sec)
Output SPEED
with
Neural Controller
Output SPEED
with Conventional
Vector controller
Figure 7: Experimental plant parameters identification by neural net (left). Experimental  measured speed when the plant is 
The complete system, including the intelligent 
neuro-controller, a power interface and a permanent 
synchronous magnet motor (plant), has been 
implemented according to the bloc diagram of figure 
6. Our intelligent neuro-controller has been 
implemented on a DSP based board.  In this board, 
the main processor is the TMS C330 DSP from 
Texas Instruments. The learning data base includes 
675 different values of measurement extracted 
motor’s parameters (Ld and Lq). Different values of 
measurable parameters (currents, voltages, speed 
and position), leading to motor’s parameters 
extraction, have been obtained for different 
operation modes of the experimental plant, used to 
validate our concepts. The ANN learning is shifted 
for 4 seconds after power supply application to 
avoid unstable data in the starting phase of the 
motor. 
Figures 7 gives experimental results relative to 
the motor’s internal parameter evolution and the 
plant’s measured speed, respectively. One can 
remark from those figures that: 
- Internal plant model’s parameters are identified 
by the neural network. 
- Such neural based controller compensates the 
inefficiency of the conventional control loop 
(achieving a 74 rad/sec angular speed). 
3.2 Kernel Functions ANN Based 
Image Processing for Industrial 
Applications
Characterization by a point and an influence field 
(shape) in the problem’s N-D feature space of a 
learned becomes particularly attractive when the 
problem’s feature space could be reduced to a 2-D 
space. In fact, in this case, the learning process, in 
the frame of kernel functions ANN, could be 
interpreted by a simple mapping model. In the case 
of images the bi-dimensionality (2-D nature) is a 
natural property. That’s why, such kind of neural 
models and issued techniques become very attractive 
for image processing issues. Moreover, their relative 
implementation facility makes them powerful 
candidates to overcome a large class of industrial 
requirements dealing with image processing and 
image analysis. 
Before 
presenting 
the 
related 
industrial 
applications, let focus the next sub-section on a brief 
19
Figure 6: View of the main plant and the load coupled to the main motor (left). Implementation block diagram (right). 
unloaded (right). 
Industrial and Real World Applications of Artificial Neural Networks

description of ZISC-036 neuro-processor from IBM, 
which implements some of kernel functions ANN 
based models. 
3.2.1 IBM ZISC-036 Neuro-Processor  
The IBM ZISC-036 (Tremiolles, 1996) (Tremiolles, 
1997) is a parallel neural processor based on the 
RCE and KNN algorithms. Each chip is capable of 
performing up to 250 000 recognitions per second. 
Thanks to the integration of an incremental learning 
algorithm, this circuit is very easy to program in 
order to develop applications; a very few number of 
functions (about ten functions) are necessary to 
control it. Each ZISC-036 like neuron implements 
two kinds of distance metrics called L1 and LSUP 
respectively. Relations (14) and (15) define the 
above-mentioned distance metrics were Pi represents 
the memorized prototype and Vi is the input pattern. 
The first one (L1) corresponds to a polyhedral 
volume influence field and the second (LSUP) to a 
hyper-cubical influence field. 
    L1: dist  
Vi  Pi
i 0
n
¦
  
(14) 
LSUP: dist  max
i 0...n Vi  Pi   
(15) 
Figure 8 gives the ZISC-036 chip’s bloc diagram 
and an example of input feature space mapping in a 
2-D space.  A 16 bit data bus handles input vectors 
as well as other data transfers (such as category and 
distance), and chip controls.  Within the chip, 
controlled access to various data in the network is 
performed through a 6-bit address bus. ZISC-036 is 
composed of 36 neurons. This chip is fully 
cascadable which allows the use of as many neurons 
as the user needs (a PCI board is available with a 
684 neurons). A neuron is an element, which is able 
to:
x
memorize a prototype (64 components coded 
on 8 bits), the associated category (14 bits), 
an influence field (14 bits) and a context (7 
bits),
x
compute the distance, based on the selected 
norm (norm L1 given by relation or LSUP) 
between its memorized prototype and the 
input vector (the distance is coded on fourteen 
bits),
x
compare the computed distance with the 
influence fields, 
x
communicate with other neurons (in order to 
find the minimum distance, category, etc.), 
x
adjust its influence field (during learning 
phase). 
Two kinds of registers hold information in ZISC-
O36 architecture: global registers and neuron 
registers. Global registers hold information for the 
device or for the full network (when several devices 
are cascaded). There are four global registers 
implemented in ZISC-036: a 16-bits Control & 
Status Register (CSR), a 8-bits Global Context 
Register (GCR), a 14-bits Min. Influence Field 
register (MIF) and a 14-bits Max. Influence Field 
register (MAF). Neuron registers hold local data for 
each neuron. Each neuron includes five neuron 
registers: Neuron Weight Register (NWR), which is 
a 64-by-8 bytes register, a 8-bits Neuron Context 
Register (NCR), Category register (CAT), Distance 
register (DIST) and Neuron Actual Influence Field 
register (NAIF). The last three registers are both 14-
bites registers. Association of a context to neurons is 
an interesting concept, which allows the network to 
be divided in several subsets of neurons. Global 
Context Register (GCR) and Neuron Context 
Register (NCR) hold information relative to such 
subdivision 
at 
network 
and 
neuron 
levels 
respectively. Up to 127 contexts can be defined. 
Figure 8: IBM ZISC-036 chip’s bloc diagram (left) and an example of input feature space mapping in a 2-D space using 
20
ROI and 1-NN modes, using norm L1 (right).
K. Madani
V2
V1
V2
V1
(a)
(b)

3.2.2 Application in Media and Movie 
Production Industry 
The first class of applications concerns image 
enhancement in order to: restore old movies (noise 
reduction, focus correction, etc.), improve digital 
television, or handle images which require adaptive 
processing (medical images, spatial images, special 
effects, etc.). 
The used principle is based on an image's 
physics phenomenon which states that when looking 
at an image through a small window, there exist 
several kinds of shapes that no one can ever see due 
to their proximity and high gradient (because, the 
number of existing shapes that can be seen with the 
human eye is limited). ZISC-036 is used to learn as 
many shapes as possible that could exist in an 
image, and then to replace inconsistent points by the 
value of the closest memorized example. The 
learning phase consists of memorizing small blocks 
of an image (as an example 5x5) and associating to 
each the middle pixel’s value as a category. These 
blocks must be chosen in such a way that they 
represent the maximum number of possible 
configurations in an image. To determine them, the 
proposed solution consists of computing the 
distances between all the blocks and keeping only 
the most different. 
The learning algorithm used here incorporates a 
threshold and learning criteria (Learn_Crit (V)). The 
learning criteria is the criteria given by relation (16) 
where V
represents the l-th component of the input 
vector V
l
k
k , Pl
j represents the l-th component of the 
j-th memorized prototype, C
k
represents the 
category value associated to the input vector V
k ,
C
j
is the category value associated to the 
memorized prototype P
j and, D and E are real 
coefficients adjusted empirically. 


j
k
l
j
l
k
l
k
C
C
P
V
V
Crit
Learn



 ¦
E
D
_
    (16) 
An example (pattern) from the learning base is 
chosen and the learning criterion for that example is 
calculated.  If the value of the learning criteria is 
greater than the threshold, then a neuron is engaged 
(added). If the learning criteria’s value is less than 
the 
threshold, 
no 
neuron 
is 
engaged. 
The 
aforementioned threshold is decreased progressively.  
Once learning database is learned the training phase 
is stopped. Figure 9 shows a pattern-to-category 
association learning example and the generalization 
(application) phase for the case of an image 
enhancement process. 
The image enhancement or noise reduction 
principles are the same as described above. The 
main difference lies in the pixel value associated to 
each memorized example. In noise reduction, the 
learned input of the neural network is a noisy form 
of the original image associated with the correct 
value (or form). For example, in the figure 9 
learning process example, for each learned pattern (a 
block of 5x5) from the input image (degraded one), 
the middle pixel of the corresponding block from the 
output image (correct one) is used as the "corrected 
pixel value" and is memorized as the associated 
category. After having learned about one thousand 
five hundred examples, the ZISC-036 based system 
is able to enhance an unlearned image. 
Figure 10 gives results corresponding to movie 
sequences coloration. In this application unlearned 
scenes of a same sequence are collared (restored) by 
learning a representative (sample) scene of the same 
sequence. For both cases of image restoration and 
coloration it has been shown (Tremiolles, 1998) 
(Madani, 2003) that the same neural concept could 
perform different tasks as noise reduction, image 
enhancement and image coloration which are 
necessary to restore a degraded movie. Quantitative 
comparative studies established and analysed in 
above-mentioned references show pertinence of such 
techniques. 
WTA
(a) 
(b) 
WTA
Figure 9: Image enhancement learning process using association of regions from the degraded and correct images (left) and 
21
image enhancement operation in generalization phase using an unlearned image (right). 
Industrial and Real World Applications of Artificial Neural Networks

Figure 10: Result concerning movie coloration showing from left to right the image used to train the neural network and the 
result obtained on coloration of an unlearned scene (left). Blue component cross sections comparison between the coloured 
Production
One of the main steps in VLSI circuit production is 
the testing step. This step verifies if the final product 
(VLSI circuit) operates correctly or not. The 
verification is performed thank to a set of 
characteristic input signals (stimulus) and associated 
responses obtained from the circuit under test. A set 
of such stimulus signals and associated circuit’s 
responses are called test vectors. Test vectors are 
delivered to the circuit and the circuit’s responses to 
those inputs are catch through standard or test 
dedicated Input-Output pads (I/O pads) called also 
vias. As in the testing step, the circuit is not yet 
packaged the test task is performed by units, which 
are called probers including a set of probes 
performing the communication with the circuit. 
Figure 11 shows a picture of probes relative to such 
probers. The problem is related to the fact that the 
probes of the prober may damage the circuit under 
test. So, an additional step consists of inspecting the 
circuit’s area to verify vias (I/O pads) status after 
circuit’s testing: this operation is called developed 
Probe Mark Inspection (PMI). Figure 11 shows a 
view of an industrial prober and examples of faulty 
and correct vias. 
Many prober constructors had already developed 
PMI software based on conventional pattern 
recognition algorithms with little success]. The 
difficulty is related to the compromise between real 
time execution (production constraints) and methods 
reliability. In fact, even sophisticated hardware 
implementations using DSPs and ASICs specialized 
in image processing are not able to perform 
sufficiently well to convince industrials to switch 
from human operator (expert) defects recognition to 
electronically automatic PMI. That’s why a neural 
network based solution has been developed and 
implemented on ZISC-036 neuro-processor, for the 
IBM Essonnes plant. The main advantages of 
developed solutions are real-time control and high 
reliability in fault detection and classification tasks. 
Our automatic intelligent PMI application, detailed 
in (Tremiolles, 1997) and (Madani, 2003, a), 
consists of software and a PC equipped with this 
neural board, a video acquisition board connected to 
a camera and a GPIB control board connected to a 
wafer prober system. Its goal is image analysis and 
prober control. 
The process of analyzing a probe mark can be 
described as following: the PC controls the prober to 
move the chuck so that the via to inspect is precisely 
located under the camera; an image of the via is 
taken through the video acquisition board, then, the 
ZISC-036 based PMI: 
x
finds the via on the image, 
x
checks the integrity of the border (for 
damage) of via, 
x
locates the impact in the via and estimates its 
surface for statistics. 
Figure 11: Photograph giving an example of probes in industrial prober (left). Example of probe impact: correct and faulty 
22
(reconstructed) and the original images in generalization phase (right).
(right).
3.2.3  Probe Mark Inspection in VLSI Chips 
K. Madani

pixels
Grey Level
  
 
Profile
Category
Faulty
OK
Profile
Category
OK
OK
Faulty
Faulty
Figure 12: Example of profiles extraction after via centring process (left). Example of profiles to category association  
during the learning phase (right). 
  
 
Figure 13: Profiles extraction for size and localization of the probe mark (left). Experimental result showing a fault 
detection and its localization in the via (right). 
All vias of a tested wafer are inspected and 
analysed. At the end of the process, the system 
shows a wafer map which presents the results and 
statistics on the probe quality and its alignment with 
the wafer. All the defects are memorized in a log 
file. In summary, the detection and classification 
tasks of our PMI application are done in three steps: 
via localization in the acquired image, mark size 
estimation and probe impact classification (good, 
bad or none). 
The method, which was retained, is based on 
profiles analysis using kennel functions based ANN. 
Each extracted profile of the image (using a square 
shape, figures 12 and 13) is compared to a reference 
learned database in which each profile is associated 
with its appropriated category. Different categories, 
related to different needed features (as: size, 
functional signature, etc). 
Experiments on different kinds of chips and on 
various probe defects have proven the efficiency of 
the neural approach to this kind of perception 
problem. The developed intelligent PMI system 
outperformed 
the 
best 
solutions 
offered 
by 
competitors by 30%: the best response time per via 
obtained using other wafer probers was about 600 
ms and our neural based system analyzes one via 
every 400 ms, 300 of which were taken for the 
mechanical movements. Measures showed that the 
defect recognition neural module’s execution time 
was negligible compared to the time spent for 
mechanical movements, as well as for the image 
acquisition (a ratio of 12 to 1 on any via). This 
application is presently inserted on a high throughput
 production line. 
3.3 Bio-inspired Multiple Neural 
Networks Based Process 
Identification
The identification task involves two essential steps: 
structure selection and parameter estimation. These 
two steps are linked and generally have to be 
realized in order to achieve the best compromise 
between error minimization and the total number of 
parameters in the final global model. In real world 
applications (situations), strong linearity, large 
number of related parameters and data nature 
complexity make the realization of those steps 
challenging, and so, the identification task difficult. 
To overcome mentioned difficulties, one of the 
key points on which one can act is the complexity 
reduction. It may concern not only the problem 
representation level (data) but also may appear at 
processing procedure level. An issue could be model 
complexity reduction by splitting a complex 
problem into a set of simpler problems: multi-
modelling where a set of simple models is used to 
23
Industrial and Real World Applications of Artificial Neural Networks

sculpt a complex behaviour (Murray, 1997). On this 
basis and inspired from animal brain structure (left 
picture of figure 14, showing the left side of a bird’s 
brain scheme and it’s auditory and motor pathways 
involved in the recognition and the production of 
song), we have designed an ANN based data driven 
treelike Multiple Model generator, that we called T-
DTS (Treelike Divide To Simplify).This data driven 
neural networks based Multiple Processing (multiple 
model) structure is able to reduce complexity on 
both data and processing levels (Madani, 2003, b) 
(right picture of figure 14). T-DTS and associated 
algorithm construct a treelike evolutionary neural 
architecture automatically where nodes, called also 
"
Supervisor/Scheduler Units" (SU) are decision 
units and leafs called also 
"
Neural Network based 
Models" (NNM) correspond to neural based 
processing units. 
The T-DTS includes two main operation modes. 
The first is the learning phase, when T-DTS system 
decomposes the input data and provides processing 
sub-structures and tools for decomposed sets of data. 
The second phase is the operation phase (usage the 
system to process unlearned data). There could be 
also a pre-processing phase at the beginning, which 
arranges (prepare) data to be processed. Pre-
processing phase could include several steps 
(conventional or neural stages). The learning phase 
is an important phase during which T-DTS performs 
several key operations: splitting the learning 
database into several sub-databases, constructing 
(dynamically) a treelike Supervision/Scheduling 
Unit (SSU) and building a set of sub-models (NNM) 
corresponding to each sub-database. Figure 15 
represents the division and NNM construction bloc 
diagrams.  As shown in this figure, if a neural based 
model cannot be built for an obtained sub-database, 
then, a new decomposition will be performed 
dividing the concerned sub-space into several other 
sub-spaces. 
The second operation mode corresponds to the 
use of the constructed neural based Multi-model 
system for processing unlearned (work) data. The 
SSU, constructed during the learning phase, receives 
data and classifies that data (pattern). Then, the most 
appropriated NNM is authorized (activated) to 
process that pattern. 
  
 
Output-1 
Input
Control Path
Data Path
N.N.M. 
k
N.N.M. 
M
N.N.M. 
1
Supervisor 
Scheduler 
Unit
Output-k 
Output-M 
Y1
Yk
YM
Figure 14: Left side of a bird’s brain scheme and it’s auditory and motor pathways involved in the recognition and the 
production of song (left) and inspired T-DTS multiple model generator's general bloc-diagram (right).
NNM
NNM
SU
NNM 
NNM
SU 
NNM
SU
SU
Pahth Generation  Steps 
SU 
Models Generation Time 
NNM
NNM
NNM
NNM
NNM
Number of Generated Models  




N
0
T2 
T1 
T3 
W
W
WN
NNM 
NNM 
NNM
NNM
SU
Slave Neural Net  
Scheduler Unit 
Figure 15: General bloc diagram of T-DTS learning phase, 
We have applied T-DTS based Identifier to a 
real world industrial process identification and 
control problem. The process is a drilling rubber 
process used in plastic manufacturing industry. 
Several 
non-linear 
parameters 
influence 
the 
manufacturing process. To perform an efficient 
control of the manufacturing quality (process 
quality), one should identify the global process 
(Chebira, 2003). 
Controller 
Process 
T-DTS based 
Identifier 
Multi-Model 
Control 
Plant  
Output
+
-
-
+
Plant
Internal 
parameters
Conventional Feedback Loop 
24
splitting and NNM generation process.
Figure 16: Industrial processing loop bloc diagram. 
K. Madani

Figure 17: Process identification results showing the 
A Kohonen SOM based SU with a 4x3 grid 
generates and supervises 12 NNM trained from 
learning database. Figures 16 and 17 show the bloc 
diagram of industrial processing loop and the 
identification 
result 
in 
the 
working 
phase, 
respectively. One can conclude that the predicted 
output is in accord with the measured one, obtained 
from the real plant. 
4 CONCLUSION 
Advances accomplished during last decades in 
Artificial 
Neural 
Networks 
area 
and 
issued 
techniques made possible to approach solution of a 
large number of difficult problems related to 
optimization, 
modeling, 
decision 
making, 
classification, data mining or nonlinear functions 
(behavior) approximation. Inspired from biological 
nervous systems and brain structure, these models 
take 
advantage 
from 
their 
learning 
and 
generalization capabilities, overcoming difficulties 
and limitations related to conventional techniques. 
Today, conjunction of these new techniques with 
recent computational technologies offers attractive 
potential for designing and implementation of real-
time intelligent industrial solutions. The main goal 
of the present paper was focused on ANN based 
techniques and their application to solve real-world 
and industrial problems. Of course, the presented 
models and applications don’t give an exhaustive 
state of art concerning huge potential offered by 
such approaches, but they could give, through 
above-presented ANN based applications, a good 
idea of promising capabilities of ANN based 
solutions to solve difficult future industrial changes. 
ACKNOWLEDGEMENTS
Reported works were sponsored and supported by 
several research projects and industrial partners 
among which, French Ministry of Education, French 
Ministry of Research and IBM-France Company. 
Author whish thank especially Dr. P. Tanhoff, and 
Dr. G. Detremiolles from IBM-France for their 
partnership and joint collaboration. I would also 
acknowledge Dr. V. Amarger, Dr. A. Chebira and 
Dr. A. Chohra from my research team (I2S Lab.) 
involved in presented works. I would thank Dr. G. 
Mercier from PARIS XII University, who worked 
with me, during his Ph.D. and during several years 
in my lab, on intelligent adaptive control dilemma. 
Finally, I would express my gratitude to Mr. M. 
Rybnik, my Ph.D. student, working on aspects 
related to T-DTS, for useful discussions concerning 
the last part of this paper. 
REFERENCES
Nelles, O., 1995. On the identification with neural 
networks as series-parallel and parallel models. In 
ICANN’95, International Conference on Artificial 
Neural Networks, Paris, France.
Faller W., Schreck S., 1995. Real-Time Prediction Of 
Unsteady Aerodynamics : Application for Aircraft 
Control and Manoeuvrability Enhancement. In IEEE
Transac. on Neural Networks, Vol. 6, N¡ 6, Nov. 95.
Maidon Y., Jervis B. W., Dutton N., Lesage S., 1996. 
Multifault Diagnosis of Analogue Circuits Using 
Multilayer Perceptrons. In IEEE European Test 
Workshop 96, Montpellier, June 12-14, 1996.
Anderson C.W., Devulapalli S.V., Stolz E.A., 1995. 
Determining Mental State from EEG Signals Using 
Parallel Implementations of Neural Networks. In 
Scientific Programming, Special Issue on Applications 
Analysis, 4, 3, Fall, pp. 171-183.
Madani K., Bengharbi A., Amarger V., 1997. Neural Fault 
Diagnosis Techniques for Nonlinear Analog Circuit. 
In SPIE Vol. 3077, pp 491-502, Orlando, Florida, 
U.S.A., April 21 to 24, 1997.
Sachenko A., Kochan V., Turchenko V., Golovko V., 
Savitsky J., Dunets A., Laopoulos T., 2000. Sensor 
errors 
prediction 
using 
neural 
networks. 
In 
Proceedings IJCNN'2000, Jul 24-Jul 27 2000, Como, 
Italy, pp. 441-446.
Arbib M.A., 2003. Handbook of Brain Theory and Neural 
Networks” 2ed. M.I.T. Press. 2003.
25
plant’s output prediction in the working phase.
Industrial and Real World Applications of Artificial Neural Networks

Kohonen T., 1984. Self-Organization and Associative 
Memory, Springer-Verlag, Germany, 1984.
Rumelhart D., Hinton G., Williams R., 1986. Learning 
Internal Representations by Error Propagation". 
Parallel Distributed Processing: Explorations in the 
Microstructure of Cognition, MIT Press, MA, 1986.
Bigot P., Cosnard M., 1993. Probabilistic Decision Trees 
and Multilayered Perceptrons. In Proc. of the Europ. 
Symp. on A. N. N., ESANN'93, pp. 91-96, 1993.
Bogdan M., Speakman H., Rosenstiel W., 1994. Kobold: 
A neural Coprocessor for Back-propagation with on-
line learning. In Proc. NeuroMicro 94, Torino, Italy, 
pp. 110-117.
Reyneri L.M., 1995. Weighted Radial Basis Functions for 
Improved Pattern Recognition and Signal Processing. 
Neural Processing Letters, Vol. 2, No. 3, pp. 2-6, May 
1995.
Trémiolles G., Madani K., Tannhof P., 1996. A New 
Approach to Radial Basis Function’s like Artificial 
Neural Networks. In NeuroFuzzy'96, IEEE European 
Workshop, Vol. 6 N° 2, pp. 735-745, April 16 to 18, 
Prague, Czech Republic, 1996. 
Hormel M.A., 1992. Self-organizing associative memory 
system for control applications. Advances Neural 
Information processing Systems 2,Touretzky Ed. Los 
Miller W.T, 1987. Sensor based control of robotic 
manipulators using a general learning algorithm, IEEE
J. of Robotics and Automation,  pp. 157-165.
Madani K., Mercier G., Chebira A., Duchesne S., 1996. 
Implementation of Neural Network Based Real Time 
Process Control on IBM Zero Instruction Set 
Computer. In SPIE AeroSense'96, Applications and 
Science of Artificial Neural Networks , Orlando, USA, 
SPIE Proc. Vol. 2760, pp. 250-261.
Albus J.S., 1975. A new Approach to Manipulator  
Control, Transa of ASME, Sept. 1975 pp. 220-227.
Comoglio R.F, 1992. CMAC Neural network Architecture 
of Autonomous Undersea Vehicle.  In SPIE vol 1709. 
527, 1992. 
Madani K., Mercier G., Dinarvand M., Depecker JC, 
1999. A Neuro-Vector based electrical machines 
driver combining a neural plant identifier and a 
conventional vector controller. In SPIE Intern. Symp. 
AeroSense’99, Orlando, Florida, USA, April 1999.
Trémiolles G., Tannhof P., Plougonven B., Demarigny C., 
Madani K., 1997. Visual Probe Mark Inspection, using 
Hardware 
Implementation 
of 
Artificial 
Neural 
Networks, in VLSI Production. In LNCS. Biological 
and Artificial Computation:From Neuroscience to 
Technology, Ed.: J. Mira, R.M. Diaz and J. Cabestany 
- Springer Verlag Berlin Heidelberg, pp. 1374-1383, 
1997.
Tremiolles G, 1998. Contribution to the theoretical study 
of neuromimetic models and to their experimental 
validation: use in industrial applications. Ph.D.
Report, University of PARIS XII – Val de Marne.
Madani K., Tremiolles G., Tanhoff P., 2003 - a. Image 
processing using RBF like neural networks: A ZISC-
036 based fully parallel implementation solving real 
world and real complexity industrial problems. In 
Journal of Applied Intelligence N°18, 2003, Kluwer 
Academic Publishers, pp. 195-231.
Murray-Smith R., Johansen T.A., 1997. Multiple Model 
Approaches to Modeling and Control. Taylor & 
Francis Publishers, 1997, ISBN 0-7484-0595-X. 
Madani K., Chebira A., Rybnik M., 2003 - b. Data Driven 
Multiple Neural Network Models Generator Based on 
a Tree-like Scheduler, LNCS "Computational Methods 
in Neural Modeling", Ed. J. Mira, J.R. Alvarez - 
Springer Verlag 2003, ISBN 3-540-40210-1, pp. 382-
389.
26
K. Madani
Hebb S., 1949. The Organization of Behaviour, Wiley and 
Sons, New-York, U.S.A., 1949.
Altos ,CA: Morgan Kaufmann,1992 pp. 332-339.
Applications of artificial Neural Networks III, pp. 517-

THE DIGITAL FACTORY  
Planning and simulation of production in automotive industry 
F. Wolfgang Arndt 
Fachhochschule Konstanz, Fachbereich Informatik, Brauneggerstr. 55, 76xxx Konstanz, Germany 
Email: arndt@fh-konstanz,de; wolfgang@ppgia.pucpr.bru 
Keywords: 
simulation, digital factory, automotive industry. 
Abstract: 
To improve and to shorten product and production planning as well as to get a higher planning and product 
quality the idea of the Digital Factory was invented. Digital Factory means a general digital support of 
planning following the process chain from SURGXFW development over process and product planning to 
production by using virtual working techniques. It follows that the whole process of developing a new 
product with its associated production equipment has to be completely simulated before starting any 
realisation. That calls for the integration of heterogeneous processes and a reorganisation of the whole 
factory. The Digital Factory will be one of the core future technologies and revolutionize all research, 
development and production activities in mechanical and electrical industries. International enterprises like 
DaimlerChrysler and Toyota are making a considerable effort to introduce this technique as soon as possible 
in their factories. It will give them a significant advance in time and costs.
1 INTRODUCTION 
Automotive industry is in many areas of automation 
a forerunner. This is due to some special 
characteristics of this industrial area. To make profit 
each type of a car must be produced in a great 
number of pieces, which makes it worth to automate 
production as much as possible. The competition on 
the automotive market is very hard and forces low 
retail prices. Larger design changes of one type of a 
car necessitate a complete rebuilt of the production 
line in the body shop and partially in the assembly 
area.
But changes of a production line are expensive, 
because a lot of special equipment is needed and the 
installation of new equipment is very labour 
intensive.  Investments available to rebuild or to 
change production lines are limited. Therefore any 
modification of a production line must be planed 
very carefully. The planning procedure involves a 
lot of different departments and is a relatively time 
consuming task. 
 On the other hand at the beginning of the 
planning activities the day, when the new production 
has to be started, the date of SOP (start of 
production) is already fixed. All planning suffers 
therefore from a limited amount of investments and 
a lack of time to do planning in detail. To overcome 
these problems intensive engineering should be done 
using simulation tools. A large variety of tools is 
today available on the market. Nearly every activity 
can be simulated by a special tool as digital mock-up 
(car assembly), work place optimisation and 
workflow management. 
But the traditional use of simulation tools deals 
only with isolated, limited problems. A conveyor 
systems can be optimised, the optimal way to mount 
front 
windows 
investigated 
or 
the 
optimal 
distribution 
of 
work 
among 
several 
robots 
determined. But the final goal is the digital factory.
2 DEFINITION 
The term digital factory means simulation of all 
activities, which are taking place in the area of R&D 
as well as in the production area of a factory. The 
digital factory involves the use of digital simulation 
along the entire process chain, from developing of 
new product, planning the associated production 
equipment and organizing mass production. 
The digital factory involves therefore much more 
than only the use of simulation tools. It imposes new 
types of organisation of the factory and an intensive 
collaboration between the car manufacturer and his 
subcontractors. All activities in the plant – that 
means the whole workflow - have to be standar-
27
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.),  Informatics in Control, Automation and Robotics I, 27–29. 

dized. The data outcome of every step of the work-
flow has to be specified and measures have to be  
taken, that the data of the workflow, when a step is 
finished, are immediately stored into a global factory 
wide database. The final target is to start develop-
ment and production -that means- any realisation 
only, if the simulation shows, that product and 
production will met the given investments, the 
predefined time schedule and the necessary quality. 
3 GLOBAL DATA BASE 
The success of simulation depends on the quality 
and actuality of the available data. At any moment 
simulation must have access to the actual data of 
development and planning. The quality of the simu-
lation results depends on the quality and actuality of 
the available data.  
There are in every factory two different types of 
data, the geometric or engineering data, which are 
produced, when a new product is developed and the 
associated production line is planed, and the com-
mercial and administrative data, which are used by 
the purchase, sales and controlling departments. 
First of all these both areas have to be to inte-
grated. To optimise e.g. the planning of a production 
line engineering and commercial data are needed. 
Special data structures have to be implemented to 
enable a data flow between these two areas. The data 
structures must be able to stores both types of data 
and to store all data, which the engineering and 
commercial departments need. 
The design of theses structures is of paramount 
importance for the well working of the digital 
factory. They must de designed to store all data and 
to permit an effective and fast access to the data. 
When the data structures are defined, it must be 
assured that they always contain actual data.  
4 WORKFLOW MANAGEMENT 
In an automotive factory at any moment a large 
number of activities are taking place. These 
activities are embedded in different workflows. A 
workflow consists of a sequence of different process 
steps. The activities of each step and the sequence of 
the different activities must be defined. Every 
employee must respect the factory specific workflow 
directions.
 For every process step the data outcome has to 
be defined. As soon as a step is executed the 
generated data are stored in the global database. That 
assures, that the global database always contains the 
actual data. 
There are standardized workflows and order or 
client specific ones. The data outcome of the special 
workflow cannot be defined in advance, because the 
activities or the workflow respectively depends on 
the work to do. Therefore it is very important to 
reduce the number of special workflows. They must 
be converted to standard workflows or integrated 
into existing standard ones. 
Every activity will be computer based. Each 
process step has to be supported by a computer 
system. There are different software systems 
available on the market like Delmia Process 
Engineer of Dassault Systémes. That assures that the 
defined sequence of steps of a workflow is 
respected. A new step can only be initiated, if the 
previous one has been completed. After the 
definition of the workflows and the outcome of each 
step, the management of the workflows is done by 
computer. 
5 SUBCONTRACTORS AND 
COLLABORATIVE 
ENDINEERING
Generally the production of a car manufacturer is 
limited to the car body, the engine, the gearbox and 
the assembly of the whole car. Therefore a large part 
of the car components has to be developed and 
produced by subcontractors. But the concept of a 
digital factory requires the simulation of the whole 
vehicle and consequently the integration of the 
subcontractors.
The exchange of information between car manu-
facturer and subcontractors has to be started, before 
a component is completely developed. Both sides 
have to inform each other of the daily progress of 
work. That calls for collaborative engineering. 
Something like a virtual team has to be created. The 
team members are working in different places, but 
there is a permanent information exchange between 
them. If the development of the car body and the 
engine is terminated, all components will be also 
available.
This gives to the subcontractors tremendous 
problems. They have to dispose of the same simu-
lation tools as the car manufacturer, which will 
cause high investments. They have to standardize 
their workflows, to deliver to the car manufacturer 
continuously information about the work in 
progress. They need to use the similar data structures 
to store engineering and commercial data. Every 
28
F.W. Arndt

the other participants. As subcontractors normally 
are working for different car manufacturers, who are 
using different simulation tools and have different 
data structures, they will face considerable problems 
in the future. 
6 DANGER AND UNRESOLVED 
PROBLEMS
Such a close collaboration needs a very intensive 
data interconnection, which brings with out doubts 
considerable dangers. There are still today no mea-
sures to protect data networks against foreigners 
with an absolute security. 
There are unresolved problems like how the own 
data can be protected against competitors, how a 
furnisher can be hindered from passing secret 
information to another car manufacturer, how to 
secret services can be prevented to seize data or 
hackers to destroy them.  
7 SUMMARY  
Concept and realisation of the digital factory form a 
key technology and will revolutionize significantly 
the way development and planning is done in 
mechanical and electrical industry. It will help to re-
duce significantly the production costs and speed up 
the product live cycle. But it will also increase the 
interdependence between the automotive industry or 
leading companies respectively and their sub-
contractors and make companies more vulnerable.  
REFERENCES
Schiller, E.; Seuffert, W.-P. Digitale Fabrik bei 
Sonderdruck
29
The Digital Factory
Automobil Produktion  
 2/2002, 2002.  
partner must give to access to his engineering data to 
DaimlerChrys 
In
ler .

Applying formal verification methods and real-time
rule-based systems to control systems and robotics 
Albert M. K. Cheng 
cheng@cs.uh.edu 
University of Houston, Texas 
USA
1 INTRODUCTION 
Engineers focus on the dynamics of control systems 
and 
robotics, 
addressing 
issues 
such 
as 
controllability, safety, and stability.  To facilitate the 
control of increasingly complex physical systems 
such as drive-by-wire automobiles and fly-by-wire 
airplanes, high-performance networked computer 
systems with numerous hardware and software 
components are increasingly required. However, this 
complexity also leads to more potential errors and 
faults, during both the design/implementation phase 
and the deployment/runtime phase.  It is therefore 
essential to manage the control system's complexity 
with the help of smart information systems and to 
increase its reliability with the aid of mechanical 
verification 
tools. 
Software 
control 
programs 
provide greater flexibility, higher precision, and 
better complexity management. However, these 
safety-critical real-time software must themselves be 
formally analyzed and verified to meet logical and 
timing correctness specifications. 
This keynote explores the use of rule-based systems 
in control systems and robotics, and describes the 
latest computer-aided verification tools for checking 
their correctness and safety.  
2 MODEL CHECKING 
To verify the logical and timing correctness of a 
control program or system, we need to show that it 
meets the designer's specification. One way is to 
manually construct a proof using axioms and 
inference rules in a deductive system such as 
temporal logic, a first-order logic capable of 
expressing relative ordering of events. 
This traditional approach toconcurrent program 
verification is tedious and error-prone even for small 
programs. For finite-state systems and restricted 
classes of infinite-state systems, we can use model 
checking (first developed by Clarke, Emerson, and 
Sistla in the 1980s) instead of proof construction to 
check 
their 
correctness 
relative 
to 
their 
specifications.
We represent the control system as a finite-state 
graph. The specification or safety assertion is 
expressed in propositional temporal logic formulas. 
We can then check whether the system meets its 
specification using an algorithm called a model 
checker, which determines whether the finite-state 
graph is a model of the formula(s).  Several model 
checkers are available and they vary in code and 
runtime complexity, and performance: 
(1) explicit-state, [Clarke, Emerson, and Sistla 
1986], (2) symbolic (using Binary Decision 
Diagrams or BDDs) [Burch, Clarke, McMillan, Dill, 
and Hwang 1990], and (3) model checkers with real-
time extensions. 
In Clarke, Emerson, and Sistla's approach, the 
system to be checked is represented by a labeled 
finite-state graph and the specification is written in a 
propositional, branching-time temporal logic called 
computation tree logic (CTL). 
The use of linear-time temporal logic, which can 
express fairness properties, is ruled out since a 
model checker for such as logic has high 
complexity. 
Instead, fairness requirements are moved into the 
semantics of CTL. 
3 VISUAL FORMALISM, 
STATECHARTS, AND 
STATEMATE
Model checking uses finite state machines (FSMs) to 
represent the control system's specification, as is the 
case in the specification and analysis of many 
computer-based as well as non-computer-based 
WHAT'S REAL IN "REAL-TIME CONTROL SYSTEMS"? 
31
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 31–35. 

systems, ranging from electronic circuits to 
enterprise models. They can model in detail the 
behavior of a system and several algorithms exist to 
perform the analysis. Unfortunately, classical state 
machines as those employed in the standard, 
explicit-state CTL model-checking approach lack 
support for modularity and suffer from exponential 
state explosion. The first problem often arises when 
FSMs are used to model complex systems which 
contain similar subsystems. The second problem is 
evident in systems where the addition of a few 
variables or components can substantially increase 
the number of states and transitions, and hence the 
size of the FSM. Furthermore, the inability to 
specify absolute time and time intervals limit the 
usability of classical FSMs for the specification of 
real-time systems. 
We can introduce modular and hierarchical features 
to classical FSMs to solve the first two problems.  
called Statecharts to solve these two problems as 
well as the problem of specifying reactive systems. 
Reactive systems are complex control-driven 
mechanisms that interact with discrete occurrences 
in the environment in which they are embedded. 
They 
include 
real-time 
computer 
systems, 
communication devices, control plants, VLSI 
circuits, robotics, and airplane avionics. The reactive 
behavior of these systems cannot be captured by 
specifying the corresponding outputs resulting from 
every possible set of inputs. Instead, this behavior 
has to be described by specifying the relationship of 
inputs, outputs, and system state over time under a 
set of system- and environment-dependent timing 
and communication constraints. 
Graphic features (labeled boxes) in the Statecharts 
language are used to denote states (or sets of states) 
and transitions between states. A transition from one 
state to another state takes place when the associated 
event(s) and condition(s) are enabled. A state can be 
decomposed into lower-level states via refinement, 
and a set of states can be combined into a higher-
level 
state 
via 
clustering. 
This 
hierarchical 
specification approach makes it possible for the 
specifier to zoom-in and zoom-out of a section of the 
Statecharts specification, thus partially remedying 
the exponential state explosion problem in classical 
FSMs. Furthermore, AND and OR clustering 
relations, together with the notions of state 
exclusivity and orthogonality, can readily support 
concurrency 
and 
independence 
in 
system 
specification. These features dramatically reduce the 
state explosion problem by not considering all states 
in a classical FSM at once.  The entire specification 
and 
development 
environment 
is 
known 
as 
STATEMATE. 
To develop a comprehensive tool capable of not 
extended the work on Statecharts, which is capable 
of behavioral description,
to derive high-level 
languages 
for 
structural 
and 
functional 
specifications. The language module-charts is used 
to describe a structural view with a graphical display 
of the components of the system. The language 
activity-charts is used to describe a functional view 
with a graphical display of the functions of the 
system. They also added mechanisms that provide a 
friendly user interface, simulated system executions, 
dynamic analysis, code generation, and rapid 
prototyping. 
4 TIMED AUTOMATA 
Finite automata and temporal logics have been used 
extensively to formally verify qualitative properties 
of concurrent systems. The properties include 
deadlock 
or 
livelock-freedom, 
the 
eventual 
occurrence of an event, and the satisfaction of a 
predicate. The need to reason with absolute time is 
unnecessary in these applications, whose correctness 
depends only on the relative ordering of the 
associated events and actions. These automata-
theoretic and temporal logic techniques using finite-
state graphs are practical in a variety of verification 
problems in network protocols, electronic circuits, 
and concurrent programs. More recently, several 
researchers have extended these techniques to timed 
or real-time systems while retaining many of the 
desirable features of their untimed counterparts. 
Two popular automata-theoretic techniques based on 
timed automata are the Lynch-Vaandrager approach 
and the Alur-Dill approach. The Lynch-Vaandrager
approach (1991, 1994) is more general and can 
specification can be difficult to write and understand 
even for relatively small systems. The Alur-Dill 
approach (1994) is less ambitious and is based on 
finite automata, but it offers an automated tool for 
verification of desirable properties. Its dense-time 
model can handle time values selected from the set 
of real numbers whereas discrete-time models such 
as those in Statecharts and Modecharts use only 
integer time values.  
32
only system specification, Harel et al., in 1990 
Harel et al., in 1987 developed a visual formalism 
A. M.K. Cheng
verification mechanism 
Its 
.
an 
automati c
lack
handle finite and infinite state systems, but it 

5 REAL-TIME LOGIC, GRAPH-
THEORETIC ANALYSIS, AND 
MODECHART
A real-time control system can be specified in one of 
two ways. The first is to structurally and functionally 
describe the system by specifying its mechanical, 
electrical, and electronic components. This type of 
specification shows how the components of the 
system work as well as their functions and 
operations.  The second is to describe the behavior 
of the system in response to actions and events. 
Here, the specification tells sequences of events 
allowed by the system. For instance, a structural-
functional specification of the real-time anti-lock 
braking system in an automobile describes the 
braking system components and sensors, how they 
are interconnected, and how the actions of each 
component affects each other. This specification 
shows, for example, how to connect the wheel 
sensors to the central decision-making computer 
which controls the brake mechanism. 
In contrast, a behavioral specification only shows 
the response of each braking system component in 
response to an internal or external event, but does 
not describe how one can build such a system. For 
instance, this specification shows that when the 
wheel sensors detect wet road condition, the 
decision-making computer will instruct the brake 
mechanism to pump the brakes at a higher frequency 
within 80 milliseconds. Since we are interested in 
the timing properties of the system, a behavioral 
specification without the complexity of the structural 
specification often suffices for verifying the 
more, to reduce specification and analysis 
complexity, we restrict the specification language to 
handle only timing relations. This is a departure 
from 
techniques 
which 
employ 
specification 
languages capable of describing logical as well as 
timing relations such as real-time CTL. 
To show that a system or program meets certain 
safety properties, we can relate the specification of 
the system to the safety assertion representing the 
desired safety properties. This assumes that the 
actual implementation of the system is faithful to the 
specification. Note that even though a behavioral 
specification does not show how one can build the 
specified system, one can certainly show that the 
implemented system, built from the structural-
functional specification, satisfy the behavioral 
specification.
One of the following three cases may result from the 
analysis relating the specification and the safety 
assertion. (1) The safety assertion is a theorem 
derivable from the specification, thus the system is 
safe with respect to the behavior denoted by the 
safety assertion. (2) The safety assertion is 
unsatisfiable with respect to the specification, so the 
system is inherently unsafe since the specification 
will cause the safety assertion to be violated. (3) The 
negation of the safety assertion is satisfiable under 
certain 
conditions, 
meaning 
that 
additional 
constraints must be added to the system to ensure its 
safety.
The specification and the safety assertion can be 
written in one of several real-time specification 
languages. The choice of language would in turn 
determine the algorithms that can be used for the 
analysis and verification. The first-order logic called 
Real-Time Logic (RTL) [Jahanian and Mok 1986] 
has been developed for writing specifications and 
safety assertions. For a restricted but practical class 
of RTL formulas, an efficient graph-theoretic 
analysis can be applied to perform verification. 
Modechart is a graphical tool based on RTL for 
specifying real-time control systems.   
Timed Petri Nets: 
Petri nets provide an operational formalism for 
specifying untimed concurrent systems. They can 
show concurrent activities by depicting control and 
data flows in different parts of the modeled system. 
A Petri net gives a dynamic representation of the 
state of a system through the use of moving tokens. 
The original, classical, untimed Petri nets have been 
used successfully to model a variety of industrial 
systems. More recently, time extensions of Petri nets 
have been developed to model and analyze time-
dependent or real-time systems. The fact that Petri 
nets can show the different active components of the 
modeled system at different stages of execution or at 
different instants of time makes this formalism 
especially attractive for modeling embedded systems 
that interact with the external environment. 
6 PROCESS ALGEBRA 
A computer process is a program or section of a 
program (such as a function) in execution. It may be 
in one of the following states: ready, running, 
waiting, or terminated. A process algebra is a 
concise language for describing the possible 
execution steps of computer processes. It has a set of 
operators and syntactic rules for specifying a process 
using simple, atomic components. It is usually not a 
logic-based language. 
33
What’s Real in “Real-Time Control Systems”? 
satisfaction of many timing constraints. ferther- 

Central to process algebras is the notion of 
equivalence, which is used to show that two 
processes have the same behavior. Well-established 
process algebras such as Hoare's Communicating 
Sequential Processes (CSP) (1978, 1985), Milner's 
Calculus of Communicating Systems (CCS) (1980, 
1989), and Bergstra and Klop's Algebra of 
Communicating Processes (ACP) (1985) have been 
used to specify and analyze concurrent processes 
with interprocess communication. These are untimed 
algebras since they only allow one to reason about 
the relative ordering of the execution steps and 
events. 
To use a process algebra or a process-algebraic 
approach to specify and analyze a system, we write 
the requirements specification of the system as an 
abstract process and the design specification as a 
detailed process. We then show that these two 
processes are equivalent, thus showing the design 
specification is correct with respect to the 
requirements specification. Here, the requirements 
specification may include the desired safety 
properties.
7 REAL-TIME RULE-BASED 
DECISION SYSTEMS 
As the complexity of control systems increases,
 it
 is 
obvious  
that  
more 
intelligent
 
decision/monitoring/control 
software 
must 
be 
developed and installed to monitor and control these 
control systems. Real-time decision systems must 
react torrr events in the external environment by 
making decisions based on sensor inputs and state 
information  sufficiently fast to meet environment-
imposed timing constraints. They are used in 
applications that would require human expertise if 
such decision systems are not available. Human 
beings tend to be overwhelmed by a transient 
information overload resulting from an emergency 
situation, thus expert systems are increasingly used 
under 
many 
circumstances 
to 
assist 
human 
operators.   
These  embedded control systems include airplane 
avionics navigation systems, automatic vehicle 
control systems fly-by-wire Airbus 330/340/380 and 
Boeing 777/7E7, smart robots (e.g., the Autonomous 
Land Vehicle), space vehicles (e.g., unmanned 
spacecrafts), the Space Shuttle and satellites, and the 
International 
Space 
Station), 
electric 
and 
communication grid monitoring centers, portable 
wireless devices and hospital patient-monitoring 
devices.  
Since the solutions to many of these decision 
problems are often nondeterministic or cannot be 
easily 
expressed 
in 
algorithmic 
form, 
these 
applications increasingly employ rule-based (or 
knowledge-based) expert systems. In recent years, 
such systems are also increasingly used to monitor 
and control the operations of complex safety-critical 
real-time systems. 
8 REAL-TIME DECISION 
SYSTEMS
A real-time decision system interacts with the 
external environment by taking sensor readings and 
computing control decisions based on sensor 
readings and stored state information. We can 
characterize a real-time decision system by the 
following model with 7 components: 
  (1) a sensor vector x in X,  
  (2) a decision vector y in Y, 
  (3) a system state vector s in S,  
  (4) a set of environmental constraints A,  
  (5) a decision map D, D: S * X -> S * Y,  
  (6) a set of timing constraints T, and  
  (7) a set of integrity constraints I. 
In this model, X is the space of sensor input values, 
Y is the space of decision values, and S is the space 
of system state values. (We shall use x(t) to denote 
the value of the sensor input x at time t, etc.) 
The environmental constraints A are relations over 
X, Y, S and are assertions about the effect of a 
control decision on the external world which in turn 
affect future sensor input values. Environmental 
constraints are usually imposed by the physical 
environment in which the real-time decision system 
functions.
The decision map D relates y(t+1), s(t+1) to x(t), 
s(t), i.e., given the current system state and sensor 
input, D determines the next decisions and system 
state values. For our purpose, decision maps are 
implemented by rule-based programs. 
The decisions specified by D must conform to a set 
of integrity constraints I. Integrity constraints are 
relations over X, S, Y and are assertions that the 
decision map D must satisfy in order to ensure safe 
operation of the physical system under control. The 
implementation of the decision map D is subject to a 
set of timing constraints T which are assertions 
about how fast the map D has to be performed.  Let 
34
A. M.K. Cheng

us consider a simple example of a real-time decision 
system. Suppose we want to automate a toy race car 
so that it will drive itself around a track as fast as 
possible. The sensor vector consists of variables 
denoting the position of the car and the distance of 
the next obstacle ahead. The decision vector consists 
of two variables: one variable to indicate whether to 
accelerate, decelerate or maintain the same speed, 
another variable to indicate whether to turn left, right 
or keep the same heading. The system state vector 
consists of variables denoting the current speed and 
heading of the car. The set of environmental 
constraints consists of assertions that express the 
physical laws governing where the next position of 
the car will be, given its current position, velocity, 
and acceleration. The integrity constraints are 
assertions restricting the acceleration and heading of 
the car so that it will stay on the race track and not to 
run into an obstacle. The decision map may be 
implemented 
by 
some 
equational 
rule-based 
program. The input and decision variables of this 
program are respectively the sensor vector and 
decision vectors. The timing constraint consists of a 
bound on the length of the monitor-decide cycle of 
the program, i.e., the maximum number of rule 
firings before a fixed point is reached. 
There are two practical problems of interest with 
respect to this model:    Analysis problem: Does a 
given rule-based decision program satisfy   the 
integrity and timing constraints of the real-time 
control system? 
  Synthesis problem: Given a rule-based decision 
program that 
  satisfies the integrity constraints but is not fast 
enough to meet 
  the timing constraints, can we transform the given 
program into one 
  which meets both the integrity and timing 
constraints? 
In view of the safety-critical functions that 
computers and software are beginning to be relied 
upon to perform in real time, it is incumbent upon us 
to ensure that some acceptable performance level 
can be provided by a rule-based program, subject to 
reasonable assumptions about the quality of the 
input.
35
What’s Real in “Real-Time Control Systems”? 

SUFFICIENT CONDITIONS FOR THE STABILIZABILITY OF
MULTI-STATE UNCERTAIN SYSTEMS, UNDER INFORMATION
CONSTRAINTS
Massashusetts Institute of Technology
77, Massachusetts Avenue, Cambridge - MA
Email: nmartins@mit.edu
Nicola Elia
Iowa State University
Keywords:
Information Theory, Control, Stabilization, Uncertainty
Abstract:
We study the stabilizability of uncertain stochastic systems in the presence of ﬁnite capacity feedback. Mo-
tivated by the structure of communication networks, we consider a stochastic digital link that sends words
whose size is governed by a random process. Such link is used to transmit state measurements between the
plant and the controller. We extend previous results by deriving sufﬁcient conditions for internal and external
stabilizability of multi-state linear and time-invariant plants. In accordance with previous publications, stabi-
lizability of unstable plants is possible if the link’s average transmission rate is above a positive critical value.
In our formulation the plant and the link can be stochastic. In addition, stability in the presence of uncertainty
in the plant is studied using a small-gain argument.
1
INTRODUCTION
Various publications in this ﬁeld have introduced nec-
essary and sufﬁcient conditions for the stabilizability
of unstable plants in the presence of data-rate con-
straints. The construction of a stabilizing controller
requires that the data-rate of the feedback loop is
above a non-zero critical value (Tatikonda, 2000b;
Tatikonda, 2000a; G. Nair, 2000; Sahai, 1998; Liber-
zon, 2003). Different notions of stability have been
investigated, such as containability (W. S. Wong,
1997; W. S. Wong, 1999), moment stability (Sa-
hai, 1998) and stability in the almost sure sense
(Tatikonda, 2000b). The last two are different when
the state is a random variable. That happens when
disturbances are random or if the communication link
is stochastic. In (Tatikonda, 2000b) it is shown that
the necessary and sufﬁcient condition for almost sure
stabilizability of ﬁnite dimensional linear and time-
invariant systems is given by an inequality of the type
C > R. The parameter C represents the average data-
rate of the feedback loop and R is a quantity that de-
pends on the eigenvalues of A, the dynamic matrix
of the system. If a well deﬁned channel is present in
the feedback loop then C may be taken as the Shan-
non Capacity. If it is a digital link then C is the av-
erage transmission rate. Different notions of stabil-
ity may lead to distinct requirements for stabiliza-
tion. For tighter notions of stability, such as in the
m-th moment sense, the knowledge of C may not suf-
ﬁce. More informative notions, such as higher mo-
ments or any-time capacity (Sahai, 1998), are neces-
sary. Results for the problem of state estimation in the
presence of information constraints can be found in
(W. S. Wong, 1997), (Sahai, 2001) and (X. Li, 1996).
The design problem was investigated in (Borkar and
Mitter, 1997).
1.1
In this paper we study the moment stabilizability of
uncertain time-varying stochastic systems in the pres-
ence of a stochastic digital link.
In contrast with
(G. Nair, 2003), we consider systems whose time-
variation is governed by an identically and indepen-
dently distributed (i.i.d.) process which may be de-
ﬁned over a continuous and unbounded alphabet. We
also provide complementary results to (G. Nair, 2003;
Elia, 2002; Elia, 2003; R. Jain, 2002) because we use
a different problem formulation where we consider
external disturbances and uncertainty on the plant and
a stochastic digital link.
In order to focus on the fundamental issues and
keep clarity, we start by deriving our results for ﬁrst
order linear systems (N. Martins and Dahleh, 2004).
Subsequently, we provide an extension to a class of
Nuno C. Martins, Munther A. Dahleh
Main Contributions of the Paper
37
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 37–50. 

multi-state linear systems. Necessary conditions for
the multi-state case can also be found in (N. Martins
and Dahleh, 2004). As pointed out in (G. Nair, 2003),
non-commutativity creates difﬁculties in the study of
arbitrary time-varying stochastic systems. Results for
the fully-observed Markovian case over ﬁnite alpha-
bets, in the presence of a deterministic link, can be
found in (G. Nair, 2003).
Besides the introduction, the paper has 3 sections:
section 2 comprises the problem formulation and pre-
liminary deﬁnitions; in section 3 we prove sufﬁ-
ciency conditions by constructing a stabilizing feed-
back scheme for ﬁrst order systems and section 4 ex-
tends the sufﬁcient conditions to a class of multi-state
linear systems.
The following notation is adopted:
• Whenever that is clear from the context we refer to
a sequence of real numbers x(k) simply as x. In
such cases we may add that x ∈R∞.
• Random variables are represented using boldface
letters, such as w
• if w(k) is a stochastic process, then we use w(k)
to indicate a speciﬁc realization.
According to
the convention used for sequences, we may denote
w(k) just as w and w(k) as w.
• the expectation operator over w is written as E[w]
• if E is a probabilistic event, then its probability is
indicated as P(E)
• we write log2(.) simply as log(.)
• if x ∈R∞, then
∥x∥1 =
∞

i=0
|x(i)|
∥x∥∞= sup
i∈N
|x(i)|
Deﬁnition 1.1 Let ϱ ∈N+
{∞} be an upper-
bound for the memory horizon of an operator.
If
Gf : R∞→R∞is a causal operator then we de-
ﬁne ∥Gf∥∞(ϱ) as:
∥Gf∥∞(ϱ) =
sup
k≥0,x̸=0
|Gf(x)(k)|
maxj∈{k−ϱ+1,...,k} |x(j)|
(1)
Note that, since Gf is causal, ∥Gf∥∞(∞) is just the
inﬁnity induced norm of Gf:
∥Gf∥∞(∞) = ∥Gf∥∞= supx̸=0
∥Gf(x)∥∞
∥x∥∞
2
PROBLEM FORMULATION
We study the stabilizability of uncertain stochastic
systems under communication constraints. Motivated
by the type of constraints that arise in most computer
networks, we consider the following class of stochas-
tic links:
Deﬁnition 2.1 (Stochastic Link) Consider a link
that, at every instant k, transmits r(k) bits. We de-
ﬁne it to be a stochastic link, provided that r(k) ∈
{0, . . . , ¯r} is an independent and identically distrib-
uted (i.i.d.) random process satisfying:
r(k) = C −rδ(k)
(2)
where E[rδ(k)] = 0 and C ≥0. The term rδ(k)
represents a ﬂuctuation in the transfer rate of the link.
More speciﬁcally, the link is a stochastic truncation
operator Fl
k : {0, 1}¯r →¯r
i=0{0, 1}i deﬁned as:
Fl
k (b1, . . . , b¯r) = (b1, . . . , br(k))
(3)
where bi ∈{0, 1}.
Given x(0) ∈[−1
2, 1
2] and ¯d ≥0, we consider nomi-
nal systems of the form:
x(k + 1) = a(k)x(k) + u(k) + d(k)
(4)
with |d(k)| ≤¯d and x(i) = 0 for i < 0.
2.1
Description of Uncertainty in the
Plant
Let ϱ ∈N+
{∞}, ¯zf ∈[0, 1) and ¯za ∈[0, 1) be
given constants, along with the stochastic process za
and the operator Gf : R∞→R∞satisfying:
|za(k)| ≤¯za
(5)
Gf causal and ∥Gf∥∞(ϱ) ≤¯zf
(6)
Given x(0) ∈[−1
2, 1
2] and ¯d ≥0, we study the
existence of stabilizing feedback schemes for the fol-
lowing perturbed plant:
x(k + 1) = a(k) (1 + za(k)) x(k) + u(k)
+Gf(x)(k) + d(k)
(7)
where the perturbation processes za and Gf(x) sat-
isfy (5)-(6). Notice that za(k) may represent uncer-
tainty in the knowledge of a(k), while Gf(x)(k) is
the output of the feedback uncertainty block Gf. We
chose this structure because it allows the representa-
tion of a wide class of model uncertainty. It is also al-
lows the construction of a suitable stabilizing scheme.
Example 2.1 If Gf(x)(k)
=
µ0x(k) + . . . +
µn−1x(k −n + 1) then ∥Gf∥∞(ϱ) =  |µi| for
ϱ ≥n.
In general, the operator Gf may be nonlinear and
time-varying.
38
N.C. Martins, M.A. Dahleh and N. Elia

2.2
Statistical Description of a(k)
The process a(k) is i.i.d. and independent of r(k) and
x(0), meaning that it carries no information about the
link nor the initial state. In addition, for convenience,
we use the same representation as in (2) and write:
log(|a(k)|) = R + lδ
a(k)
(8)
where E[lδ
a(k)] = 0. Notice that lδ
a(k) is responsible
for the stochastic behavior, if any, of the plant. Since
a(k) is ergodic, we also assume that P (a(k) = 0) =
0, otherwise the system is trivially stable. Such as-
sumption is also realistic if we assume that (7) comes
from the discretization of a continuous-time system.
2.3
Functional Structure of the
Feedback Interconnection
In the subsequent text we describe the feedback loop
structure, which might also be designated as informa-
tion pattern (Witsenhausen, 1971). Besides the plant,
there are two blocks denoted as encoder and controller
which are stochastic operators. At any given time k,
we assume that both the encoder and the controller
have access to a(0), . . . , a(k) and r(k −1) as well as
the constants ϱ, ¯zf, ¯za and ¯d. The encoder and the
controller are described as:
• The encoder is a function Fe
k : Rk+1 →{0, 1}¯r
that has the following dependence on observations:
Fe
k(x(0), . . . , x(k)) = (b1, . . . , b¯r)
(9)
• The control action results from a map, not necessar-
ily memoryless, Fc
k : ¯r
i=0{0, 1}i →R exhibiting
the following functional dependence:
u(k) = Fc
k(⃗b(k))
(10)
where ⃗b(k) are the bits successfully transmitted
through the link, i.e.:
⃗b(k) = Fl
k (b1, . . . , b¯r) =

b1, . . . , br(k)

(11)
As such, u(k) can be equivalently expressed as
u(k) = (Fc
k ◦Fl
k ◦Fe
k)(x(0), . . . , x(k))
Deﬁnition 2.2 ( Feedback Scheme) We deﬁne a feed-
back scheme as the collection of a controller Fc
k and
an encoder Fe
k.
2.4
Problem Statement and M-th
Moment Stability
Deﬁnition 2.3 (Worst Case Envelope) Let x(k) be
the solution to (7) under a given feedback scheme.
Given any realization of the random variables r(k),
a(k), Gf(x)(k), za(k) and d(k), the worst case en-
velope ¯x(k) is the random variable whose realization
is deﬁned by:
¯x(k) =
sup
x(0)∈[−1
2 , 1
2 ]
|x(k)|
(12)
Consequently, ¯x(k) is the smallest envelope that con-
tains every trajectory generated by an initial condi-
tion in the interval x(0) ∈[−1
2, 1
2]. We adopted the
interval [−1
2, 1
2] to make the paper more readable. All
results are valid if it is replaced by any other symmet-
ric bounded interval.
Our problem consists in determining sufﬁcient con-
ditions that guarantee the existence of a stabilizing
feedback scheme. The results must be derived for the
following notion of stability.
Deﬁnition 2.4 (m-th Moment Robust Stability) Let
m > 0, ϱ ∈N+
{∞}, ¯zf ∈[0, 1), ¯za ∈[0, 1) and
¯d ≥0 be given. The system (7), under a given feed-
back scheme, is m-th moment (robustly) stable pro-
vided that the following holds:
limk→∞E [¯x(k)m] = 0
¯zf = ¯d = 0
∃b > 0, lim supk→∞E [¯x(k)m] < b
otherwise
(13)
The
ﬁrst
limit
in
(13)
is
an
internal
stabil-
ity condition while the second establishes exter-
nal stability.
The constant b must be such that
lim supk→∞E [¯x(k)m] < b holds for all allowable
perturbations za and Gf(x) satisfying (5)-(6).
2.5
Motivation for our Deﬁnition of
Stochastic Link and Further
Comments on the Information
Pattern
The purpose of this section1 is to motivate the trun-
cation operator of deﬁnition 2.1. In addition, details
of the synchronization between the encoder and the
decoder are discussed in subsection 2.5.1.
Consider that we want to use a wireless medium
to transmit information between nodes A and B. In
our formulation, node A represents a central station,
which measures the state of the plant. The goal of the
transmission system is to send information, about the
state, from node A to node B, which represents a con-
troller that has access to the plant. Notice that node A
maybe a communication center which may communi-
cate to several other nodes, but we assume that node
B only communicates with node A. Accordingly, we
will concentrate on the communication problem be-
tween nodes A and B only, without loss of generality.
1This section is not essential for understanding the suf-
ﬁciency theorems of sections 3 and 4.
39
Sufficient Conditions for the Stabilizability of Multi-State Uncertain Systems

Deﬁnition 2.5 (Basic
Communication
Scheme)
We assume the existence of an external time-
synchronization variable, denoted as k. The interval
between k and k + 1 is of T seconds, of which
TT < T is reserved for transmission. We also denote
the number of bits in each packet as Π, excluding
headers. In order to submit an ordered set of packets
for transmission, we consider the following basic
communication protocol, at the media access control
level:
(Initialization) A variable denoted by c(k) is used
to count how many packets are sent in the interval
t ∈[kT, kT + TT ]. We consider yet another counter
p, which is used to count the number of periods for
which no packet is sent. The variables are initialized
as k = 0, p = 0 and c(0) = 0.
(For node A)
(Synchronization) If k changes to k := k + 1 then
step 1 is activated.
• Step1 The packets to be submitted for transmis-
sion are numbered according to their priority; 0
is the highest priority. The order of each packet
is included in the header of the packet. The vari-
able c(k) is initialized to c(k) = 0 and p is in-
cremented to p := p + 1. The ﬁrst packet (packet
number 0) has an extra header, comprising the pair
(c(k −p −1), p). Move to step 2.
• Step 2: Stands by until it can send packet number
c(k). If such opportunity occurs, move to step 3.
• Step 3: Node A sends packet number c(k) to node
B and waits for an ACK signal from node B. If node
A receives an ACK signal then c(k) := c(k) + 1,
p = 0 and move back to step 2. If time-out then go
back to Step 2.
The time-out decision may be derived from several
events: a ﬁxed waiting time; a random timer or a new
opportunity to send a packet.
(For node B)
• Step 1: Node B stands by until it receives a packet
from node A. Once a packet is received, check if it
is a ﬁrst packet: if so, extract (c(k −p −1), p) and
construct rdec(i), with i ∈{k −p −1, . . . , k −1},
according to:
(If p ≥1)
rdec(k −p −1) = c(k −p −1)Π
(14)
rdec(i) = 0, i ∈{k −p, . . . , k −1}
(15)
(If p = 0)
rdec(k −1) = c(k −1)Π
(16)
where Π is the size of the packets, excluding the
header. If the packet is not duplicated then make
the packet available to the controller. Move to step
2.
• Step 2: Wait until it can send an ACK signal to
node A. Once ACK is sent, go to step 1.
The scheme of deﬁnition 2.5 is the simplest version
of a class of media access control (MAC) protocols,
denoted as Carrier Sense Multiple Access (CSMA).
A recent discussion and source of references about
CSMA is (M. Heusse, 2003). Such scheme also de-
scribes the MAC operation for a wireless communi-
cation network between two nodes. Also, we adopt
the following strong assumptions:
• Every time node A sends a packet to node B: either
it is sent without error or it is lost. This assumption
means that we are not dealing with, what is com-
monly referred to as, a noisy channel.
• Every ACK signal sent by node B will reach node
A before k changes to k + 1.
This assumption
is critical to guarantee that no packets are wasted.
Notice that node B can use the whole interval
t ∈(kT + TT , (k + 1)T) to send the last ACK.
During this period, the controller is not expecting
new packets.
The controller will generate u(k)
using the packets that were sent in the interval
t ∈[kT, kT + TT ]. Consequently, such ACK is
not important in the generation of u(k). It will be
critical only for u(i) for i > k.
We adopt k, the discrete-time unit, as a reference.
According to the usual framework of digital control,
k will correspond to the discrete time unit obtained
by partitioning the continuous-time in periods of du-
ration T. Denote by TT < T the period allocated
for transmission.
Now, consider that the aim of a
discrete-time controller is to control a continuous-
time linear system, which admits2 a discretization of
the form xc((k + 1)T) = A(k)xc(kT) + u(k). The
discretization is such that u(k) represents the effect
of the control action over t ∈(kT + TT , (k + 1)T).
Information about x(k) = xc(kT), the state of the
plant at the sampling instant t = kT, is transmitted
during t ∈[kT, kT + TT ]. Whenever k changes, we
construct a new queue and assume that the cycle of
deﬁnition 2.5 is reset to step 1.
2.5.1
Denote by renc
coder has successfully sent between k and k + 1, i.e.,
the number of bits for which the encoder has received
an ACK. The variable renc(k) is used by the encoder
to keep track of how many bits were sent. The cor-
responding variable at the decoder is represented as
rdec(k). From deﬁnition 2.5, we infer that rdec(k−1)
2A controllable linear and time-invariant system admits
a discretization of the required form. If the system is sto-
chastic an equivalent condition has to be imposed
40
Synchronization Between the Encoder and
(k) the total number of bits that the en-
the Decoder
N.C. Martins, M.A. Dahleh and N. Elia

may not be available at all times. On the other hand,
we emphasize that the following holds:
c(k) ̸= 0 =⇒rdec(i) = renc(i), i ∈{0, . . . , k −1}
(17)
In section 3, the stabilizing control is constructed in
a way that: if no packet goes through between k and
k + 1, i.e., c(k) = 0 then u(k) = 0. That shows
that rdec(k −1) is not available only when it is not
needed. That motivated us to adopt the simplifying
assumption that r(k −1) = renc(k −1) = rdec(k −
1). We denote by r(k) the random variable which
represents the total number of bits that are transmitted
in the time interval t ∈[kT, kT + TT ]. The r(k)
transmitted bits are used by the controller to generate
u(k). Notice that our scheme does not pressupose
an extra delay, because the control action will act, in
continuous time, in the interval t ∈(kT + TT , (k +
1)T).
2.5.2
Encoding and Decoding for First Order
Systems
Given the transmission scheme described above, the
only remaining degrees of freedom are how to en-
code the measurement of the state and how to con-
struct the queue. From the proofs of theorems 3.2 and
3.4, we infer that a sufﬁcient condition for stabiliza-
tion is the ability to transmit, between nodes A and B,
an estimate of the state ˆx(k) with an accuracy lower-
bounded3 by E[|ˆx(k)−x(k)|m] < 2−R, where R > 0
is a given constant that depends on the state-space rep-
resentation of the plant. Since the received packets
preserve the original order of the queue, we infer that
the best way to construct the queues, at each k, is to
compute the binary expansion of x(k) and position
the packets so that the bits corresponding to higher
powers of 2 are sent ﬁrst. The lost packets will al-
ways4 be the less important. The abstraction of such
procedure is given by the truncation operator of deﬁ-
nition 2.1. The random behavior of r(k) arises from
random time-out, the existence of collisions generated
by other nodes trying to communicate with node A or
from the fading that occurs if node B is moving. The
fading fenomena may also occur from interference.
3This observation was already reported in (Tatikonda,
2000a)
4The situation were the packets lost are in random posi-
tions is characteristic of large networks where packets travel
through different routers.
3
SUFFICIENCY CONDITIONS
FOR THE ROBUST
STABILIZATION OF FIRST
ORDER LINEAR SYSTEMS
In this section, we derive constructive sufﬁcient con-
ditions for the existence of a stabilizing feedback
scheme. We start with the deterministic case in sub-
section 3.1, while 3.2 deals with random r and a. We
stress that our proofs hold under the framework of
section 2. The strength of our assumptions can be
accessed from the discussion in section 2.5.
The following deﬁnition introduces the main idea
behind the construction of a stabilizing feedback
scheme.
Deﬁnition 3.1 (Upper-bound Sequence) Let ¯zf
∈
[0, 1), ¯za ∈[0, 1), ¯d ≥0 and ϱ ∈N+
{∞} be
given. Deﬁne the upper-bound sequence as:
v(k + 1) = |a(k)|2−re(k)v(k)
+ ¯zf max{v(k −ϱ + 1), . . . , v(k)} + ¯d,
(18)
where v(i) = 0 for i < 0, v(0) = 1
2 and re(k) is an
effective rate given by:
re(k) = −log(2−r(k) + ¯za)
(19)
Deﬁnition 3.2 Following the representation for r(k)
we also deﬁne Ce and rδ
e(k) such that:
re(k) = Ce −rδ
e(k)
(20)
where E[rδ
e(k)] = 0.
We adopt v(0) =
1
2 to guarantee that |x(0)| ≤
v(0). If x(0) = 0 then we can select v(0) = 0. Notice
that the multiplicative uncertainty ¯za acts by reduc-
ing the effective rate re(k). After inspecting (19), we
ﬁnd that re(k) ≤min{r(k), −log(¯za)}. Also, notice
that:
¯za = 0 =⇒(re(k) = r(k), rδ
e(k) = rδ(k), C = Ce)
(21)
Deﬁnition 3.3 (Stabilizing feedback scheme) We
make use of the sequence speciﬁed in deﬁnition 3.1.
Notice that v(k) can be constructed at the controller
and the encoder because both have access to ϱ, ¯zf,
¯za, ¯d, r(k −1) and a(k −1).
The feedback scheme is deﬁned as:
• Encoder: Measures x(k) and computes bi ∈{0, 1}
such that:
(b1, . . . , b¯r) = arg
max
¯r
i=1 bi 1
2i ≤(
x(k)
2v(k) + 1
2)
¯r

i=1
bi
1
2i
(22)
41
Sufficient Conditions for the Stabilizability of Multi-State Uncertain Systems
Σ

Place (b1, . . . , b¯r) for transmission.
For any
r(k) ∈{0, . . . , ¯r}, the above construction pro-
vides the following centroid approximation ˆx(k)
for x(k) ∈[−v(k), v(k)]:
ˆx(k) = 2v(k)(
r(k)

i=1
bi
1
2i +
1
2r(k)+1 −1
2)
(23)
which satisﬁes |x(k) −ˆx(k)| ≤2−r(k)v(k).
• Controller: From the ¯r bits placed for transmission
in the stochastic link, only r(k) bits go through.
Compute u(k) as:
u(k) = −a(k)ˆx(k)
(24)
As expected, the transmission of state information
through a ﬁnite capacity medium requires quantiza-
tion. The encoding scheme of deﬁnition 3.3 is not an
exception and is structurally identical to the ones used
by (R. W. Brocket, 2000; Tatikonda, 2000b), where
sequences were already used to upper-bound the state
of the plant.
The following lemma suggests that, in the con-
struction of stabilizing controllers, we may choose to
focus on the dynamics of the sequence v(k). That
simpliﬁes the analysis in the presence of uncertainty
because the dynamics of v(k) is described by a ﬁrst-
order difference equation.
Lemma 3.1 Let ¯zf ∈[0, 1), ¯za ∈[0, 1) and ¯d ≥0 be
given. If x(k) is the solution of (7) under the feedback
scheme of deﬁnition 3.3, then the following holds:
¯x(k) ≤v(k)
for all ϱ ∈N+
{∞}, every choice Gf ∈∆f,ϱ and
|za(k)| ≤¯za, where
∆f,ϱ = {Gf : R∞→R∞: ∥Gf∥∞(ϱ) ≤¯zf} (25)
Proof:
We proceed by induction, assuming that
¯x(i) ≤v(i) for i ∈{0, . . . , k} and proving that
¯x(k + 1) ≤v(k + 1). From (7), we get:
|x(k + 1)| ≤|a(k)||x(k) + u(k)
a(k)|
+|za(k)||a(k)||x(k)| + |Gf(x)(k)| + |d(k)|
(26)
The way the encoder constructs the binary expansion
of the state, as well as (24), allow us to conclude that
|x(k) + u(k)
a(k)| ≤2−r(k)v(k)
Now we recall that |za(k)| ≤¯za, |Gf(x)(k)| ≤
¯zf max{v(k −ϱ + 1), . . . , v(k)} and that |d(k)| ≤¯d,
so that (26) implies:
|x(k + 1)| ≤|a(k)|(2−r(k) + ¯za)v(k)
+ ¯zf max{v(k −ϱ + 1), . . . , v(k)} + ¯d
(27)
The proof is concluded once we realize that |x(0)| ≤
v(0).
□
3.1
The Deterministic Case
We start by deriving a sufﬁcient condition for the ex-
istence of a stabilizing feedback scheme in the deter-
ministic case, i.e., r(k) = C and log(|a(k)|) = R.
Subsequently, we move for the stochastic case where
we derive a sufﬁcient condition for stabilizability.
Theorem 3.2 (Sufﬁciency conditions for Robust
Stability) Let ϱ ∈N+
{∞}, ¯zf ∈[0, 1), ¯za ∈[0, 1)
and ¯d ≥0 be given and h(k) be deﬁned as
h(k) = 2k(R−Ce), k ≥0
where Ce = re = −log(2−C + ¯za).
Consider that x(k) is the solution of (7) under the
feedback scheme of deﬁnition 3.3 as well as the fol-
lowing conditions:
• (C 1) Ce > R
• (C 2) ¯zf∥h∥1 < 1
If conditions (C 1) and (C 2) are satisﬁed then the
following holds for all |d(t)| ≤¯d, Gf ∈∆f,ϱ and
|za(k)| ≤¯za:
¯x(k) ≤∥h∥1

¯zf
∥h∥1 ¯d + 1
2
1 −∥h∥1¯zf
+ ¯d

+ h(k)1
2 (28)
where ∆f,ϱ is given by:
∆f,ϱ = {Gf : R∞→R∞: ∥Gf∥∞(ϱ) ≤¯zf} (29)
Proof: From deﬁnition 3.1, we know that, for arbi-
trary ϱ ∈N+
{∞}, the following is true:
v(k + 1) = 2R−Cev(k)
+¯zf max{v(k −ϱ + 1), . . . , v(k)} + ¯d
(30)
Solving the difference equation gives:
v(k) = 2k(R−Ce)v(0)
+
k−1

i=0
2(k−i−1)(R−Ce)
×
¯zf max{v(i −ϱ + 1), . . . , v(i)} + ¯d

(31)
which, using ∥Πkv∥∞
=
max{v(0), . . . , v(k)},
leads to:
v(k) ≤∥h∥1(¯zf∥Πkv∥∞+ ¯d)+2k(R−Ce)v(0) (32)
But we also know that 2k(R−Ce) is a decreasing func-
tion of k, so that:
∥Πkv∥∞≤∥h∥1(¯zf∥Πkv∥∞+ ¯d) + v(0)
(33)
which implies:
∥Πkv∥∞≤∥h∥1 ¯d + v(0)
1 −∥h∥1¯zf
(34)
Direct substitution of (34) in (32) leads to:
v(k) ≤∥h∥1

¯zf
∥h∥1 ¯d + v(0)
1 −∥h∥1¯zf
+ ¯d

+2k(R−Ce)v(0)
(35)
The proof is complete once we make v(0) = 1
2 and
use lemma 3.1 to conclude that ¯x(k) ≤v(k).
□
42
N.C. Martins, M.A. Dahleh and N. Elia

3.2
Sufﬁcient Condition for the
Stochastic Case
The following lemma provides a sequence, denoted
by vm(k), which is an upper-bound for the m-th mo-
ment of ¯x(k). We show that vm is propagated accord-
ing to a ﬁrst-order difference equation that is suitable
for the analysis in the presence of uncertainty.
Lemma 3.3 (M-th moment boundedness) Let ϱ ∈
N+, ¯zf ∈[0, 1), ¯za ∈[0, 1) and ¯d ≥0 be given
along with the following set:
∆f,ϱ = {Gf : R∞→R∞: ∥Gf∥∞(ϱ) ≤¯zf} (36)
Given m, consider the following sequence:
vm(k) = hm(k)vm(0)
+
k−1

i=0
hm(k −i −1)
×
	
ϱ
1
m ¯zf max{vm(i −ϱ + 1), . . . , vm(i)} + ¯d

(37)
where vm(i) = 0 for i < 0, vm(0) = 1
2, hm(k) is the
impulse response given by:
hm(k) =
	
E[2m(log(|a(k)|)−re(k))]

 k
m , k ≥0 (38)
and re(k) = −log

2−r(k) + ¯za

. If x(k) is the so-
lution of (7) under the feedback scheme of deﬁnition
3.3, then the following holds
E[¯x(k)m] ≤vm(k)m
for all |d(t)| ≤¯d, Gf ∈∆f,ϱ and |za(k)| ≤¯za.
Proof: Since lemma 3.1 guarantees that ¯x(k+1) ≤
v(k+1), we only need to show that E[v(k+1)m]
1
m ≤
vm(k + 1).
Again, we proceed by induction by
noticing that v(0) = vm(0) and by assuming that
E[v(i)m]
1
m ≤vm(i) for i ∈{1, . . . , k}. The in-
duction hypothesis is proven once we establish that
E[v(k + 1)m]
1
m ≤vm(k + 1). From deﬁnition 3.1,
we know that:
E[v(k + 1)m]
1
m = E[
	
2log(|a(k)|)−re(k)v(k)
+¯zf max{v(k −ϱ + 1), . . . , v(k)} + ¯d
m]
1
m
(39)
Using Minkowsky’s inequality (Halmos, 1974) as
well as the fact that v(i) is independent of a(j) and
re(j) for j ≥i, we get:
E[v(k + 1)m]
1
m
≤E[2m(log(|a(k)|)−re(k))]
1
m E[v(k)m]
1
m
+ ¯zfE[max{v(k −ϱ + 1), . . . , v(k)}m]
1
m + ¯d (40)
which, using the inductive assumption, implies the
following inequality:
E[v(k + 1)m]
1
m
≤E[2m(log(|a(k)|)−re(k))]
1
m vm(k)
+ϱ
1
m ¯zf max{vm(k −ϱ + 1), . . . , vm(k)} + ¯d
(41)
where we used the fact that, for arbitrary random vari-
ables s1, . . . , sn, the following holds:
E[max{|s1|, . . . , |sn|}m] ≤E[
n

i=1
|si|m]
≤n max{E[|s1|m], . . . , E[|sn|m]}
(42)
The proof follows once we notice that the right hand
side of (41) is just vm(k + 1).
□
Theorem 3.4 (Sufﬁcient Condition) Let m , ϱ ∈
N+, ¯zf ∈[0, 1), ¯za ∈[0, 1) and ¯d ≥0 be given
along with the quantities bellow:
β(m) = 1
m log E

2mlδ
a(k)
αe(m) = 1
m log E

2mrδ
e(k)
hm(k) = 2k(R+β(m)+αe(m)−¯Ce), k ≥0
where rδ
e comes from (20). Consider that x(k) is the
solution of (7) under the feedback scheme of deﬁnition
3.3 as well as the following conditions:
• (C 3) Ce > R + β(m) + αe(m)
• (C 4) ϱ
1
m ¯zf∥hm∥1 < 1
If conditions (C 3) and (C 4) are satisﬁed, then the
following holds for all |d(t)| ≤¯d, Gf ∈∆f,ϱ and
|za(k)| ≤¯za:
E[¯x(k)m]
1
m
≤∥hm∥1

ϱ
1
m ¯zf
∥hm∥1 ¯d + 1
2
1 −ϱ
1
m ¯zf∥hm∥1
+ ¯d

+ hm(k)1
2
(43)
where ∆f,ϱ is given by:
∆f,ϱ = {Gf : R∞→R∞: ∥Gf∥∞(ϱ) ≤¯zf} (44)
Proof: Using vm from lemma 3.3, we arrive at:
vm(k) ≤hm(k)vm(0)
+∥hm∥1
	
ϱ
1
m ¯zf∥Πkvm∥∞+ ¯d

(45)
where we use
∥Πkvm∥∞= max{vm(0), . . . , vm(k)}
43
Sufficient Conditions for the Stabilizability of Multi-State Uncertain Systems

But from (45), we conclude that:
∥Πkvm∥∞≤vm(0)+∥hm∥1
	
ϱ
1
m ¯zf∥Πkvm∥∞+ ¯d

(46)
or equivalently:
∥Πkvm∥∞≤vm(0) + ∥hm∥1 ¯d
1 −∥hm∥1ϱ
1
m ¯zf
(47)
Substituting (47) in (45), gives:
vm(k) ≤hm(k)vm(0)
+∥hm∥1

ϱ
1
m ¯zf
vm(0) + ∥hm∥1 ¯d
1 −∥hm∥1ϱ
1
m ¯zf
+ ¯d

(48)
The proof follows from lemma 3.3 and by noticing
that hm(k) can be rewritten as:
hm(k) =
	
E[2m(log(|a(k)|)−re(k))
 k
m
= 2k(R+β(m)+αe(m)−Ce), k ≥0
(49)
□
4
SUFFICIENT CONDITIONS
FOR A CLASS OF SYSTEMS OF
ORDER HIGHER THAN ONE
The results, derived in section 3, can be extended, in
speciﬁc cases, to systems of order higher than one
(see section 4.1). In the subsequent analysis, we out-
line how and suggest a few cases when such exten-
sion can be attained. Our results do not generalize to
arbitrary stochastic systems of order n > 1. We em-
phasize that the proofs in this section are brief as they
follow the same structure of the proofs of section 3 5.
We use n as the order of a linear system whose state
is indicated by x(k) ∈Rn. The following is a list
of the adaptations, of the notation and deﬁnitions of
section 1, to the multi-state case:
• if x ∈Rn then we indicate its components by [x]i,
with i ∈{1, . . . , n}. In a similar way, if M is a
matrix then we represent the element located in the
i-th row and j-th column as [M]ij. We also use |M|
to indicate the matrix whose elements are obtained
as [|M|]ij = |[M]ij|.
• Rn×∞is used to represent the set of sequences
of n-dimensional vectors, i.e., x ∈Rn×∞
=⇒
x(k) ∈Rn, k ∈N.
• the inﬁnity norm in Rn×∞is deﬁned as:
∥x∥∞= sup
i
max
j
|[x(i)]j|
5The authors suggest the reading of section 3 ﬁrst.
It follows that if x
∈
Rn then ∥x∥∞
=
maxj∈{1,...,n} |[x]j|. Accordingly, if x ∈Rn×∞
we use ∥x(k)∥∞= maxj∈{1,...,n} |[x(k)]j| to in-
dicate the norm of a single vector, at time k, in con-
trast with ∥x∥∞= supi maxj |[x(i)]j|.
• the convention for random variables remains un-
changed, e.g., [x(k)]j is the jth component of a n-
dimensional random sequence whose realizations
lie on Rn×∞
• If H is a sequence of matrices, with H(k) ∈Rn×n,
then
∥H∥1 = max
i
∞

k=0
n

j=1
|[H(k)]ij|
For an arbitrary vector x
∈
Rn we use Hx
to represent the sequence H(k)x.
For a par-
ticular matrix H(k), we also use ∥H(k)∥1
=
maxi
n
j=1 |[H(k)]ij|.
• we use ⃗1 ∈Rn to indicate a vector of ones, i.e.,
[⃗1]j = 1 for j ∈{1, . . . , n}.
4.1
In this section, we introduce the state-space represen-
tation of the nominal discrete-time plant, for which
we want to determine robust stabilizability. We also
provide a condition, under which the stabilizability, of
such state-space representation, can be inferred from
the stabilizability of another representation which is
more convenient. The condition is stated in Proposi-
tion 4.1 and a few examples are listed in remark 4.2.
Such equivalent representation is used in section 4.2
as way to obtain stability conditions that depend ex-
plicitly on the eigenvalues of the dynamic matrix.
Consider the following nominal state-space realiza-
tion:
˜x(k + 1) = ˜A(k)˜x(k) + ˜u(k) + ˜d(k)
(50)
where ∥˜d∥∞≤¯˜d and ¯˜d is a pre-speciﬁed constant.
We also consider that ˜A is a real Jordan form with
a structure given by:
˜A(k) = diag(J1(k), . . . , Jq(k)(k))
(51)
where Ji(k) are real Jordan blocks(R. Horn, 1985)
with multiplicity qi satisfying 
i qi = n.
The state-space representation of a linear and time-
invariant system can always be transformed in a way
that ˜A is in real Jordan form. The discretization of
a controllable continuous-time and time-invariant lin-
ear system can always be expressed in the form (50),
i.e., with B = I. If the system is not controllable,
44
Description of the Nominal Plant
and Equivalent Representations
N.C. Martins, M.A. Dahleh and N. Elia

but stabilizable, then we can ignore the stable dynam-
ics and consider only the unstable part which can be
written in the form (50).
If the system is stochastic then, in general, there is
no state transformation leading to A(k) in real Jor-
dan form. The following is a list of conditions, un-
der which a state-space representation of the form
x(k + 1) = A(k)x(k) + u(k) can be transformed
in a new one, for which ˜A is in real Jordan form:
• When the original dynamic matrices are already in
real Jordan form. A particular instance of that are
the second order stochastic systems with complex
poles.
• A collection of systems with a state-space realiza-
tion of the type x(k+1) = J(k)x(k)+u(k) which
connected in a shift-invariant topology. Here we
used the fact that if several copies of the same sys-
tem are connected in a shift-invariant topology then
they can be decoupled by means of a time-invariant
transformation (N. C. Martins, 2001).
Still, the representation (50)-(51) cannot be stud-
ied directly due to the fact that it may have com-
plex eigenvalues. We will use the idea in (Tatikonda,
2000a) and show that, under certain conditions, there
exists a transformation which leads to a more conve-
nient state-space representation. Such representation
has a dynamic matrix which is upper-triangular and
has a diagonal with elements given by |λi( ˜A(k))|.
If we denote R(θ) as the following rotation:
R(θ) =

cos(θ)
sin(θ)
−sin(θ)
cos(θ)

(52)
then the general structure of Ji(k) ∈Rqi is:
(If ηi(k) is real)
Ji(k) =


ηi(k)
1
· · ·
0
ηi(k)
1
...
...
...
0
0
0


(53)
(otherwise)
Ji(k)
=


|ηi(k)|R(θi(k))
I
· · ·
0
0
|ηi(k)|R(θi(k))
I
0
...
...


(54)
We start by following (Tatikonda, 2000a) and deﬁn-
ing the following matrix:
Deﬁnition 4.1 (Rotation dynamics) Let the real Jor-
dan form ˜A(k) of (50) be given by (51). We deﬁne the
rotation dynamics R ˜
A(k) as the following matrix:
R ˜
A(k) = diag(JR
1 (k), . . . , JR
q (k))
(55)
where JR
i (k) ∈Rqi are given by:
JR
i (k) =
sgn(ηi(k))I
ηi(k) ∈R
diag(R(θi(k)), . . . , R(θi(k))) otherwise
(56)
For
technical
reasons,
we
use
the
idea
of
(Tatikonda, 2000a) and study the stability of x given
by:
x(k) = R ˜
A(k −1)−1 · · · R ˜
A(0)−1˜x(k)
(57)
Remark 4.1 The motivation for such time-varying
transformation is that, by multiplying (50) on the left
by R ˜
A(k)−1 · · · R ˜
A(0)−1, the nominal dynamics of
x is given by:
x(k + 1) = A(k)x(k) + d(k) + u(k)
(58)
where d(k)
=
R ˜
A(k −1)−1 · · · R ˜
A(0)−1˜d(k),
u(k) = R ˜
A(k −1)−1 · · · R ˜
A(0)−1˜u(k) and A(k)
is the following upper-triangular matrix6:
A(k) = R ˜
A(k)−1 ˜A(k)
=


|λ1( ˜A(k))|
· · ·
0
...
...
0
0
|λn( ˜A(k))|


(59)
The following proposition is a direct consequence
of the previous discussion:
Proposition 4.1 (Condition for equivalence of repre-
sentations) Let ˜A(k) be such that R ˜
A(k) satisﬁes:
sup
k
∥R ˜
A(k)−1 · · · R ˜
A(0)−1∥1 ≤Γ1 < ∞
(60)
sup
k
∥

R ˜
A(k)−1 · · · R ˜
A(0)−1−1 ∥1 ≤Γ2 < ∞
(61)
Under the above conditions, the stabilization of (58)-
(59) and the stabilization of (50)-(51) are equivalent
in the sense of (62)-(63).
lim sup
k→∞
∥x(k)∥∞≤Γ1 lim sup
k→∞
∥˜x(k)∥∞
≤Γ1Γ2 lim sup
k→∞
∥x(k)∥∞
(62)
lim sup
k→∞
E[∥x(k)∥m
∞] ≤Γm
1 lim sup
k→∞
E[∥˜x(k)∥m
∞]
≤Γm
1 Γm
2 lim sup
k→∞
E[∥x(k)∥m
∞]
(63)
6Here we use an immediate modiﬁcation of lemma
3.4.1, from (Tatikonda, 2000a).
It can be shown that,
if ˜A(k) is a real Jordan form then R ˜
A(j)−1 ˜A(k) =
˜A(k)R ˜
A(j)−1 holds for any j, k. This follows from the
fact thatR(θ1)R(θ2) = R(θ1 + θ2) = R(θ2)R(θ1) holds
for arbitrary θ1 and θ2.
45
Sufficient Conditions for the Stabilizability of Multi-State Uncertain Systems

Remark 4.2 Examples of ˜A(k) for which (60)-(61)
hold are:
• all time-invariant ˜A
• ˜A(k) = diag(J1(k), . . . , Jq(k)) where qi are in-
variant.
• all 2-dimensional A(k). In this case R ˜
A(k) is al-
ways a rotation matrix, which includes the iden-
tity as a special case. Under such condition, the
bounds in (60)-(61) are given by
sup
k
∥R ˜
A(k)−1 · · · R ˜
A(0)−1∥1 ≤2
sup
k
∥

R ˜
A(k)−1 · · · R ˜
A(0)−1−1 ∥1 ≤2
4.2
Let ϱ ∈N+
{∞}, ¯d ≥0, ¯zf ∈[0, 1) and ¯za > 0
be given constants then we study the stabilizability of
x(k+1) = A(k)(I +Za(k))x(k)+u(k)+d(k)
+ Gf(x)(k)
(64)
A(k) =


|λ1(A(k))|
· · ·
0
...
...
0
0
|λn(A(k))|


(65)
where ∥d∥∞≤¯d, |[Za(k)]ij| ≤¯za and ∥Gf∥∞(ϱ) ≤
¯zf. Recall, from Proposition 4.1, that the stabilizabil-
ity of a state-space representation of the form (50),
satisfying (60)-(61), can be studied in the equivalent
form where (65) holds.
A given feedback scheme is robustly stabilizing if
it satisﬁes the following deﬁnition.
Deﬁnition 4.2 (m-th Moment Robust Stability) Let
m > 0, ϱ ∈N+
{∞}, ¯zf ∈[0, 1), ¯za ∈[0, 1) and
¯d ≥0 be given. The system (64), under a given feed-
back scheme, is m-th moment (robustly) stable pro-
vided that the following holds:
(if ¯zf = ¯d = 0)
lim
k→∞E [∥¯x(k)∥m
∞] = 0
(66)
(Otherwise)
∃b ∈R+ s.t. lim sup
k→∞
E [∥¯x(k)∥m
∞] < b
(67)
where ¯x(k) is given by:
[¯x(k)]i =
sup
x(0)∈[−1/2,1/2]n |[x(k)]i|
4.3
In order to study the stabilization of systems of order
higher than one, we assume the existence of a channel
allocation ⃗r(k) ∈{0, . . . , ¯r}n satisfying:
n

j=1
[⃗r(k)]j = r(k)
(68)
where r(k) is the instantaneous rate sequence as de-
scribed in section 2.5.1. We also emphasize that A(k)
and ⃗r(k) are i.i.d and independent of each other.
Using the same notation of section 1, we deﬁne Cj
and [⃗rδ(k)]j as:
[⃗r(k)]j = Cj −[⃗rδ(k)]j
(69)
Similarly, we also deﬁne αi(m) as:
αi(m) = 1
m log E[2m[⃗rδ(k)]i]
(70)
In the general case, the allocation problem is dif-
ﬁcult because it entails a change of the encoding
process described in section 2.5.2. The encoding must
be such that each [⃗rδ(k)]i corresponds to the instanta-
neous rate of a truncation operator. In section 4.8 we
solve the allocation problem for a class of stochastic
systems in the presence of a stochastic link.
As in the one dimensional case, we assume that
both the encoder and the controller have access to
A(0), . . . , A(k) and ⃗r(k −1) as well as the constants
ϱ, ¯zf, ¯za and ¯d. The encoder and the controller are
described as:
• The encoder is a function Fe
k
: Rn×(k+1) →
{0, 1}n×¯r that has the following dependence on ob-
servations:
Fe
k(x(0), . . . , x(k)) = (b1, . . . , b¯r)
(71)
where bi ∈{0, 1}n.
• The control action results from a map, not neces-
sarily memoryless, Fc
k : ¯r
i=0{0, 1}n×i →R ex-
hibiting the following functional dependence:
u(k) = Fc
k(⃗b(k))
(72)
where ⃗b(k) is the vector for which, each compo-
nent [⃗b(k)]j, comprises a string of [⃗r(k)]j bits suc-
cessfully transmitted through the link, i.e.:
[⃗b(k)]j = [Fl
k (b1, . . . , b¯r)]j
=

[b1]j, . . . , [b[⃗r(k)]j]j

(73)
As such, u(k) can be equivalently expressed as
u(k) = (Fc
k ◦Fl
k ◦Fe
k)(x(0), . . . , x(k))
46
Feedback Structure and Channel
Usage Assumptions
Description of Uncertainty and
the following uncertain system:
Robust Stability
N.C. Martins, M.A. Dahleh and N. Elia

4.4
The construction of a stabilizing scheme follows the
same steps used in section 3. The following is the de-
ﬁnition of a multidimensional upper-bound sequence.
Deﬁnition 4.3 (Upper-bound Sequence) Let ¯zx
f
∈
[0, 1), ¯za ∈[0, 1), ¯d ≥0 and ϱ ∈N+
{∞} be
given. Deﬁne the upper-bound sequence v(k), with
v(k) ∈Rn, as:
v(k + 1) = Acl(k)v(k)
+ ¯zf max{∥v(k −ϱ + 1)∥∞, . . . , ∥v(k)∥∞}⃗1 + ¯d⃗1,
(74)
where [|A(k)|]ij = |[A(k)]ij|, v(i) = 0 for i < 0,
[v(0)]j = 1
2 and Acl(k) is given by:
Acl(k)
= |A(k)|
	
diag(2−[⃗r(k)]1, . . . , 2−[⃗r(k)]n) + ¯za⃗1⃗1T 
(75)
Adopt the feedback scheme of deﬁnition 3.3, mu-
tatis mutandis, for the multi-dimensional case. By
measuring the state x(k) and using [⃗r(k)]j bits, at
time k, to encode each component [x(k)]j, we con-
struct [ˆx(k)]j such that
|[x(k)]j −[ˆx(k)]j| ≤2−[⃗r(k)]j[v(k)]j
(76)
Accordingly, u(k) is deﬁned as:
u(k) = −A(k)ˆx(k)
(77)
The following lemma establishes that the stabiliza-
tion of v(k) is sufﬁcient for the stabilization of x(k).
Lemma 4.2 Let ¯zf ∈[0, 1), ¯za ∈[0, 1) and ¯d ≥0 be
given. If x(k) is the solution of (64) under the feed-
back scheme given by (76)-(77), then the following
holds:
[¯x(k)]j ≤[v(k)]j
for all ϱ ∈N+
{∞}, ∥d(k)∥∞≤¯d, every choice
|[Za]ij| ≤¯za and ∥Gf∥∞(ϱ) ≤¯zf.
Proof: The proof follows the same steps as in lemma
3.1. We start by assuming that [¯x(i)]j ≤[v(i)]j for
i ∈{0, . . . , k} and proceed to prove that [¯x(k+1)]j ≤
[v(k +1)]j. From (64) and the feedback scheme (76)-
(77), we ﬁnd that:


|[x(k + 1)]1|
...
|[x(k + 1)]n|


≤
element−wise
|A(k)|


|[v(k)]1|2−⃗r1(k)
...
|[v(k)]n|2−⃗rn(k)


+|A(k)| |Za(k)|


|[v(k)]1|
...
|[v(k)]n|

+ ¯d⃗1
+ ¯zf⃗1 max{∥v(k −ϱ + 1)∥∞, . . . , ∥v(k)∥∞}
(78)
□
4.5 Sufﬁciency for the
Accordingly, the following theorem establishes the
multi-dimensional analog to theorem 3.2.
Theorem 4.3 (Sufﬁciency conditions for Robust
Stability) Let A be the dynamic matrix of (64), ϱ ∈
N+
{∞}, ¯zf ∈[0, 1), ¯za ∈[0, 1) and ¯d ≥0 be
given and H(k) be deﬁned as
H(k) = Ak
cl, k ≥0
where Acl = |A|
	
diag(2−C1, . . . , 2−Cn) + ¯za⃗1⃗1T 
and [|A|]ij = |[A]ij|. Consider that x(k) is the solu-
tion of (64) under the feedback scheme of (76)-(77) as
well as the following conditions:
• (C 1) maxi λi(Acl) < 1
• (C 2) ¯zf∥H∥1 < 1
If conditions (C 1) and (C 2) are satisﬁed then the
following holds:
∥¯x(k)∥∞
≤∥H∥1

¯zf
∥H∥1 ¯d + ∥˜g∥∞1
2
1 −¯zf∥H∥1
+ ¯d

+ ∥˜g(k)∥∞
1
2
(79)
where ˜g(k) = Ak
cl⃗1.
Proof: We start by noticing that the condition (C1)
is necessary and sufﬁcient to guarantee that ∥H∥1 is
ﬁnite. Following the same steps, used in the proof of
theorem 3.2, from deﬁnition 4.3, we have that:
v(k) = Ak
clv(0) +
k−1

i=0
Ak−i−1
cl
×
	
¯zf max{∥v(i −ϱ + 1)∥∞, . . . , ∥v(i)∥∞}⃗1 + ¯d⃗1

(80)
47
Sufficient Conditions for the Stabilizability of Multi-State Uncertain Systems
Construction of a Stabilizing
Feedback Scheme
Deterministic/Time-InvariantCase

∥πkv∥∞≤∥˜g∥∞
1
2 +∥H∥∞(¯zf∥πkv∥∞+ ¯d) (81)
where
we
use
∥πkv∥∞
=
max{∥v(0)∥∞, . . . , ∥v(k)∥∞} and ˜g(k) = Ak
cl⃗1. By
means of lemma 4.2, the formula (79) is obtained by
isolating ∥πkv∥∞in (81) and substituting it back in
(80).□
4.5.1
Interpretation for ¯za = 0
If ¯za = 0 then Acl, of Theorem 4.3, can be written as:
Acl =


|λ1(A)|2−C1
· · ·
0
...
...
0
0
|λn(A)|2−Cn

(82)
The increase of Ci causes the decrease of λi(Acl) and
∥H∥1. Accordingly, conditions (C1) and (C2), from
theorem 4.3, lead to the conclusion that the increase
in Ci gives a guarantee that the feedback loop is sta-
ble under larger uncertainty, as measured by ¯zf. In
addition, if we denote Ri = log(|λi(A)|) then we can
cast condition (C1) as:
Ci > Ri
(83)
4.6
We derive the multi-dimensional version of the suf-
ﬁciency results in section 3.2. The results presented
below are the direct generalizations of lemma 3.3 and
theorem 3.4.
Deﬁnition 4.4 (Upper-bound sequence for the sto-
chastic case) Let ϱ ∈N+, ¯zf ∈[0, 1), ¯za ∈[0, 1)
and ¯d ≥0 be given. Given m, consider the following
sequence:
vm(k + 1) = Acl,mvm(k) +⃗1
	
d + (nϱ)
1
m ¯zf
×max{∥vm(k −ϱ + 1)∥∞, . . . , ∥vm(k)∥∞})
(84)
where vm(i) = 0 for i < 0, vm(0) = 1
2⃗1 and Acl,m is
deﬁned as
Acl,m = Am
	
¯za⃗1⃗1T
+ diag(2−C1+α1(m), . . . , 2−Cn+αn(m))

(85)
and
[Am]ij = E[|[A(k)]ij|m]
1
m
Lemma 4.4 (M-th moment boundedness)
If x(k) is the solution of (64) under the feedback
scheme of (76)-(77), then the following holds
E[[¯x(k)]m
i ]
1
m ≤[vm(k)]i
Proof: We start by showing that E[[v(k)]m
i ]
1
m
≤
[vm(k)]i. We proceed by induction, by assuming that
E[[v(j)]m
i ]
1
m ≤[vm(j)]i holds for j ∈{0, . . . , k}
and proving that E[[v(k + 1)]m
i ]
1
m ≤[vm(k + 1)]i.
Let z, s and g be random variables with z indepen-
dent of s. By means of the Minkovsky inequality, we
know that E[|zs + g|m]
1
m ≤E[|z|m]
1
m E[|s|m]
1
m +
E[|g|m]
1
m .
Using such property, the following in-
equality is a consequence of (74):


E[[v(k + 1)]m
1 ]
1
m
...
E[[v(k + 1)]m
n ]
1
m


≤
element−wise
Acl,m


E[[v(k)]m
1 ]
1
m
...
E[[v(k)]m
n ]
1
m

+ ¯d⃗1
+ ¯zfE[max{∥v(k −ϱ + 1)∥∞, . . . , ∥v(k)∥∞}m]
1
m⃗1
(86)
But
using
the
inductive
assumption
that
E[[v(j)]m
i ]
1
m ≤[vm(j)]i holds for j ∈{0, . . . , k}
and that:
E[max{∥v(k −ϱ + 1)∥∞, . . . , ∥v(k)∥∞}m]
1
m
≤(nϱ)
1
m
max
j∈[k−ϱ+1,k] max
i∈[1,n] E[[v(j)]m
i ]
1
m
(87)
we can rewrite (86) as:


E[[v(k + 1)]m
1 ]
1
m
...
E[[v(k + 1)]m
n ]
1
m


≤
element−wise Acl,mvm(k)
+⃗1
	
¯d + (nϱ)
1
m ¯zf
×max{∥vm(k −ϱ + 1)∥∞, . . . , ∥vm(k)∥∞})
(88)
Since the induction hypothesis is veriﬁed, we can
use lemma 4.2 to ﬁnalize the proof. □
Theorem 4.5 (Sufﬁciency conditions for Robust m-
th moment Stability) Let A be the dynamic matrix of
(64), ϱ ∈N+, ¯zf ∈[0, 1), ¯za ∈[0, 1) and ¯d ≥0 be
given and Hm(k) be deﬁned as
Hm(k) = Ak
cl,m, k ≥0
where
Acl,m = Am
	
¯za⃗1⃗1T
+ diag(2−C1+α1(m), . . . , 2−Cn+αn(m))

(89)
[Am]ij = E [|[A(k)]ij|m]
1
m and [|A|]ij = |[A]ij|.
Consider that x(k) is the solution of (64) under the
feedback scheme of (76)-(77) as well as the following
conditions:
48
Sufﬁciency for the StochasticCase
N.C. Martins, M.A. Dahleh and N. Elia

• (C 1) maxi λi(Acl,m) < 1
• (C 2) (nϱ)
1
m ¯zf∥Hm∥1 < 1
If conditions (C 1) and (C 2) are satisﬁed then the
following holds:
E[[¯x(k)]m
i ]
1
m ≤∥˜gm(k)∥∞
1
2
∥Hm∥1

(nϱ)
1
m ¯zf
∥Hm∥1 ¯d + ∥˜gm∥∞1
2
1 −(nϱ)
1
m ¯zf∥Hm∥1
+ ¯d

(90)
where ˜gm(k) = Ak
cl,m⃗1.
Proof: We start by noticing that the condition (C1) is
necessary and sufﬁcient to guarantee that ∥Hm∥1 is
ﬁnite. From deﬁnition 4.4, we have that:
vm(k) = Ak
cl,mv(0)+⃗1
k−1

i=0
Ak−i−1
cl,m
	
¯d + (nϱ)
1
m
× ¯zf max{∥vm(i −ϱ + 1)∥∞, . . . , ∥vm(i)∥∞})
(91)
∥πkvm∥∞
≤∥˜gm∥∞
1
2 + ∥Hm∥1
	
(nϱ)
1
m ¯zf∥πkvm∥∞+ ¯d

(92)
where
we
use
∥πkvm∥∞
=
max{∥vm(0)∥∞, . . . , ∥vm(k)∥∞} and ˜gm(k)
=
Ak
cl,m⃗1. By means of lemma 4.4, the formula (90)
is obtained by isolating ∥πkvm∥∞in (92) and
substituting it back in (91).□
4.7
Sufﬁciency for the case ¯za = 0
If we deﬁne
βi(m) = 1
m log(E[2m(log(|λi(A(k))|)−Ri)])
where Ri = E[log(|λi(A(k))|)], then, after a few al-
gebraic manipulations, condition (C1) of Theorem 4.5
can be written as:
Ci > Ri + αi(m) + βi(m)
(93)
Also, from condition (C2), we ﬁnd that by increasing
the difference Ci −(Ri + αi(m) + βi(m)) we reduce
∥Hm∥1 and that improves robustness to uncertainty
as measured by ¯zf.
4.8
Solving the Allocation Problem
for a Class of Stochastic Systems
Given ¯d > 0, ϱ ∈N+ and ¯zf ∈[0, 1), consider the
following n-th order state-space representation:
x(k + 1) = J(k)x(k) + u(k) + d(k) + Gf(x)(k)
(94)
where Gf is a causal operator satisfying ∥Gf∥∞(ϱ) ≤
¯zf, ∥d∥∞≤¯d and J(k) is a real Jordan block of the
form:
if a(k) is real
J(k) =


a(k)
1
· · ·
0
0
0
a(k)
1
...
0
...
...
...
0
0
0
0
a(k)


(95)
otherwise
J(k) =


|a(k)|Rot(k)
I
· · ·
0
0
|a(k)|Rot(k)
I
...
...
...


(96)
where Rot is an i.i.d.sequence of random rotation
matrices.
Take the scheme of section 2.5 as a starting point.
Assume also that r(l) is always a multiple of n, i.e.,
r(l) ∈{0, n, 2n, . . . , ¯r}. In order to satisfy this as-
sumption, we only need to adapt the scheme of sec-
tion 2.5 by selecting packets whose size is a multi-
ple of n. By doing so, we can modify the encod-
ing/decoding scheme of section 2.5.2 and include in
each packet an equal number of bits from each [⃗r(l)]i.
By including the most important bits in the highest
priority packets, we guarantee that each [⃗r(l)]i corre-
sponds to the instantaneous rate of a truncation oper-
ator. As such, we adopt the following allocation:
[⃗r(l)]i = r(l)
n
(97)
where we also use Ci and deﬁne the zero mean i.i.d.
random variable [⃗rδ(l)]i, satisfying:
[⃗r(l)]i = Ci −[⃗rδ(l)]i
(98)
From the deﬁnition of αi(m) and α(m), the para-
meters characterizing the allocation (97) and r(l) are
related through:
αi(m) = 1
m log E[2−m[⃗rδ(l)]i]
= 1
n
n
m log E[2−m
n rδ(l)] = 1
nα(m
n )
(99)
Ci = 1
nC
(100)
We also adopt β(m) according to section 4.7:
β(m) = 1
m log E[2mlδ
a(k)]
(101)
where log |a(k)| = R + lδ
a(k).
The following Proposition shows that, under the
previous assumptions, the necessary condition de-
rived in (N. Martins and Dahleh, 2004) is not con-
servative.
49
Sufficient Conditions for the Stabilizability of Multi-State Uncertain Systems

Proposition 4.6 Let ϱ ∈N+ be a given constant. If
C −α( m
n ) > nβ(m)+nR then there exists constants
¯d > 0 and ¯zf ∈[0, 1) such that the state-space rep-
resentation (94) can be robustly stabilized in the m-th
moment sense.
Proof: From Proposition 4.1, we know that (94) can
be written in the form (64)-(65). From section 4.7 we
know that we can use Theorem 4.5 to guarantee that
the following is a sufﬁcient condition for the existence
of ¯d > 0 and ¯zf ∈[0, 1) such that (94) is robustly
stabilizable:
Ci > αi(m) + βi(m) + Ri
(102)
where, in this case, Ri = R and βi(m) = β(m) is
given by (101). On the other hand, by means of (99)-
(100), the assumption C −α( m
n ) > nβ(m)+nR can
be written as (102). □
The authors would like to thank Prof.
Sekhar
Tatikonda (Yale University) for providing pre-print
papers comprising some of his most recent results.
We also would like to thank Prof.
Sanjoy Mitter
(M.I.T.) for interesting discussions. This work was
sponsored by the University of California - Los Ange-
les, MURI project title: “Cooperative Control of Dis-
tributed Autonomous Vehicles in Adversarial Environ-
ments”, award: 0205-G-CB222.
Nuno C. Martins
was supported by the Portuguese Foundation for Sci-
ence and Technology and the European Social Fund,
PRAXIS SFRH/BPD/19008/2004/JS74. Nicola Elia
has been supported by NSF under the Career Award
grant number ECS-0093950.
REFERENCES
Borkar, V. S. and Mitter, S. K. (1997).
Lqg control
with communication constraints. In Communications,
Computation, Control and Signal Processing:a tribute
to Thomas Kailath. Kluwer Academic Publishers.
Elia, N. (2002). Stabilization of systems with erasure ac-
tuation and sensory channels. In Proceedings of 40th
Allerton Conference. UIUC.
Elia, N. (2003). Stabilization in the presence of fading chan-
nels. In Proceedings of the American Control Confer-
ence. ACC.
G. Nair, R. J. E. (2000). Stabilization with data-rate-limited
feedback: Tightest attainable bounds. In Systems and
Control Letters, Vol 41, pp. 49-76.
G. Nair, S. Dey, R. J. E. (2003). Inﬁmum data rates for sta-
bilizing markov jump linear systems. In Proc. IEEE
Conference on Decision and Control, pp. 1176-81.
IEEE.
Halmos, P. R. (1974). Measure Theory. Springer Verlag.
Liberzon, D. (2003).
On stabilization of linear systems
with limited information.
In IEEE Transactions on
Automation and Control, Vol 48(2), pp. 304-7.
M. Heusse, F. Rousseau, G. B.-S. A. D. (2003). sperfor-
mance anomaly of 802.11b. In Proc. IEEE Infocom.
IEEE.
N. C. Martins, S. Venkatesh, M. A. D. (2001). Controller
design and implementation for large scale systems,
a block decoupling approach. In Proceedings of the
American Control Conference. ACC.
N. Martins, N. E. and Dahleh, M. A. (2004).
Feedback
stabilization of uncertain systems using a stochastic
digital link. In Proceedings of the IEEE Conference
on Decision and Control. IEEE.
R. Horn, C. J. (1985). Matrix Analysis. Cambridge Univer-
sity Press, New York, NY:, 2nd edition.
R. Jain, T. Simsek, P. V. (2002). Control under communi-
cation constraints. In Proc. IEEE Conference on De-
cision and Control, Vol. 5, pp. 3209-15. IEEE.
R. W. Brocket, D. L. (2000).
Quantized feedback stabi-
lization of linear systems. In IEEE Trans. Automat.
Control, vol 45, pp. 1279-1289. IEEE.
Sahai, A. (1998). Evaluating channels for control: Capacity
reconsidered. In Proceedings of the American Control
Conference. ACC.
Sahai, A. (2001). Anytime information theory. In Ph.D.
Dissertation. M.I.T.
Tatikonda, S. (2000a). Control under communication con-
straints. In Ph.D. Dissertation. M.I.T.
Tatikonda, S. (2000b). Control under communication con-
straints: Part i and ii. In IEEE Trans. Automat. Control
(submitted). IEEE.
W. S. Wong, R. W. B. (1997). Systems with ﬁnite com-
munication bandwidth constraints -i: State estimation
problems. In IEEE Trans. Automat. Control, Vol 42,
pp. 1294-1298. IEEE.
W. S. Wong, R. W. B. (1999). Systems with ﬁnite commu-
nication bandwidth constraints -ii: Stabilization with
limited information feedback.
In IEEE Trans. Au-
tomat. Control, Vol 44, No. 5 pp. 1049-1053. IEEE.
Witsenhausen, H. (November 1971). Separation of estima-
tion and control for discrete-time systems. In Proceed-
ing of the IEEE, Volume 59, No 11. IEEE.
X. Li, W. S. W. (1996). State estimation with communica-
tion constraints. In Systems and Control Letters 28,
pp. 49-54.
50
ACKNOWLEDGEMENTS
N.C. Martins, M.A. Dahleh and N. Elia

PART 1 
Intelligent Control Systems
and Optimization 

DEVICE INTEGRATION INTO AUTOMATION SYSTEMS WITH 
CONFIGURABLE DEVICE  HANDLER 
Anton Scheibelmasser, Udo Traussnigg 
Department of Automation Technology,CAMPUS 02, Körblergasse 111, Graz, Austria 
Email: : anton.scheibelmasser@campus02.at, udo.traussnigg@campus02.at  
Georg Schindin, Ivo Derado 
Test Bed Automation and Control Systems, AVL List GmbH, Hans List Platz 1, Graz, Austria 
Email: georg.schindin@avl.com, ivo.derado@avl.com   
Keywords: 
Measurement device, automation system, Configurable Device Handler, test bed. 
Abstract: 
One of the most important topics in the field of automation systems is the integration of sensors, actuators, 
measurement devices and automation subsystems. Especially automation systems like test beds in the 
automotive industry impose high requirements regarding flexibility and reduced setup and integration time 
for new devices and operating modes. The core function of any automation system is the acquisition, 
evaluation and control of data received by sensors and sent to actuators.  Sensors and actuators can be 
connected directly to the automation systems. In this case they are parameterised using specific software 
components, which determine the characteristics of every channel. In contrast to this, smart sensors, 
measurement devices or complex subsystems have to be integrated by means of different physical 
communication lines and protocols. The challenge for the automation system is to provide an integration 
platform, which will offer easy and flexible way for the integration of this type of devices. On the one hand, 
a sophisticated interface to the automation system should trigger, synchronise and evaluate values of 
different devices. On the other hand, a simple user interface for device integration should facilitate the 
flexible and straightforward device integration procedure for the customer. Configurable Device Handler is 
a software layer in the automation system, which offers a best trade-off between the complex functionality 
of intelligent devices and their integration in a simple, fast and flexible way. Due to a straightforward 
integration procedure, it is possible to integrate new devices and operation modes in a minimum of time by 
focusing on device functions and configuring the automation system, rather than writing software for 
specific device subsystems. This article gives an overview of Configurable Device Handler, which was 
implemented in the test bed automation system PUMA Open developed at the AVL. It provides an insight 
into the architecture of the Configurable Device Handler and shows the principles and the ideas behind it. 
Finally, new aspects and future developments are discussed. 
1 INTRODUCTION 
The general task of an automation system is to 
control a system in a defined mode of operation. In 
order for the automation system to perform this task, 
a number of sensors and actuators have to be 
evaluated and controlled. Since the timing of the 
automation system is critical, its software has to 
establish real time data acquisition and control.  A 
further requirement is to evaluate and calculate 
results based on the acquired data and to store them. 
Particularly, automation systems used in the field of 
CAT (Computer Aided Testing, e.g. combustion 
engine development), called test beds, have to store 
the acquired data during the test run into a database, 
so that the developer can calculate specific quantities 
for quality assurance or optimisation. Systems under 
test are monitored and controlled by various devices 
connected to the automation systems. 
Concerning 
the 
complexity 
of 
the 
data 
acquisition and control, devices can be divided into 
two categories. The first category of devices can be 
described as simple actuators (e.g. valves) or sensors 
(e.g. temperature sensor Pt100), which are connected 
to an input/output system as part of the automation 
53
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 53–60. 

system. Since the sensors and actuators are under the
control of the real time system, they are usually
completely integrated into the automation system.
Depending on the use of the sensor/actuator, specific
parameterisation (e.g. acquisition rate, filtering or 
buffering) has to be performed by the customer.
The second category could be described as
intelligent subsystems (e.g. measurement devices).
In contrast to the first category, they are controlled
by a local microprocessor, which provides functions
comparable to those of the automation system (e.g.
real time data acquisition or statistical calculation).
Devices of this group could be qualified as finite
automata with several internal states and transitions.
Usually they are connected to the automation system 
via 
physical 
line 
(e.g. 
RS232, 
Ethernet).
Consequently, data acquisition and control is
possible only via this physical line and by using
diverse communication protocols on it.
These various types of devices have to be
uniformly integrated into the automation system, so
that data acquisition and device control can be
performed in a common way. Thus, automation
systems typically contain a software layer, with the
main task to make device specific functions
available via standard automation interfaces. We 
refer to this software layer as Device Handler (see
figure
1). Specifically, there are two main
automation interfaces in PUMA Open (AVL, 2004),
which are used by Device Handler, i.e., Platform
Adapter and Device Framework.
The former interface offers functions compatible
to those of the ASAM-GDI Platform Adapter
(ASAM, 2001). There are two main advantages of
the Platform Adapter. Firstly, it abstracts the
complexity of lower ISO/OSI layers 1-6 (ISO, 1990)
and it provides to the client a generic interface where
common read/write commands from/to the device
are independent from the specific lower ISO/OSI
layers (TCP/IP over Ethernet, RS232, CAN, etc.).
Secondly, it provides standard OS-services (e.g. 
memory handling and synchronisation) and thus
enables the client to be independent from the
specific OS. Consequently, the client, i.e. the Device
Handler, deals exclusively with device specific
functions and it is therefore robust to changes of 
lower communication layers and/or OS’s.
The later interface must be implemented by the
Device Handler and it contains services that are to 
be used by the automation system, i.e., user. This
comprises services, such as: handling of device
channels 
(System
Channels),
device
parameterisation, support of the standard Device
Handler’s state machine, data storage, etc.
2 DEVICE HANDLER TYPES
One of the most important aspects of the automation
system is the synchronisation of all test bed
components (software and hardware) in order to
perform specific control and/or measurement tasks
(e.g. power-up all devices or get ready to start the 
measurement of the system under test). As
mentioned in the previous chapter, all devices are
synchronised due to the fact that all Device Handlers
behave in a uniform way, which is ensured by
supporting the state machine, i.e., states and 
transitions of the Device Framework interface. For 
instance, if the automation system wants to perform
a measurement, it simply invokes the transition
StartMeasurement of each Device Handler. The
Device Handler interprets this command in a device
specific way and accordingly sends one or more
protocol frames to the device. Depending on the
physical connection (e.g. RS232, CAN), the protocol
mode (e.g. bus, peer to peer), the communication
mode (e.g.
master-slave, burst-mode) and the
functionality (e.g. measure, calibrate), one could
distinguish between various families of devices, i.e.,
Device Handlers.
Device2
Automation System
Device Framework
Device Handler
Device1
Device3
Platform Adapter
As a result of this, the device is switched to the
intended state (e.g. measurement mode) and is able
to perform the specific activities. Acquired data are
analysed and accordingly the transition is performed,
the values of System Channels are updated, etc.
54
Figure 1: Device Handler.
A. Scheibelmasser et al.

A vital part of the Device Handler is its 
visualisation, or graphical user interface (GUI).
Typically, it is implemented as a separate
component and provides a visualisation for services,
such as device parameterisation, maintenance, or
visualisation of on-line values.
From the implementation’spoint of view, we can
identify two types of Device Handler (see figure 2).
In case of very specific and high complex devices,
with sophisticated GUI requirements, it is hardly
possible to specify the device functions in a generic
manner. For this kind of devices, it is more
appropriate 
and 
efficient 
to 
implement 
the
corresponding Device Handler within traditional
software development projects. This implies that all 
device functions (e.g. protocol, logic, GUI, state-
machine) are implemented hard-coded at compile
time. Therefore, the functions of the handler are 
fixed. In case of changing customer requirements or
firmware changes on the device, the software has to 
be modified and compiled again. Hence, there is no
flexibility concerning customer or application
specific modification. Only device parameters which
are handled in the automation system as System
Channels, can be customized.
Moreover, 
a 
person
responsible 
for 
the
integration of the device into the automation system
has to be not only familiar with the device specifics,
but also with programming language and the
software
object
model behind the automation
interfaces.
2.2 Configurable Device Handler 
The idea behind the Configurable Device Handler
(CDH) is to simplify and speed up the integration of
devices by configuring the automation systems and
thus allowing the responsible person (e.g. customer)
to focus on device functions and not on object
models behind automation interfaces. In order to 
achieve this, a generic Device Handler was
implemented, which can cover
general device
functions, such as RS232 or TCP/IP connection,
master-slave protocol, ASCII protocol, etc.  During
the 
configuration
procedure 
specific 
device
functions are identified. The mapping of device
functions 
to 
automation 
interfaces 
is 
done
automatically with the instantiation of the generic
Device 
Handler
including 
device
specific
information. Therefore, there is no need for 
programming or learning a programming language
and object models behind automation interfaces. The
information 
gained
during 
the 
configuration
procedure is stored in a so called Measurement
Device Description (MDD) file. As the content of
this file incorporates only the necessary device
specific information, platform independent device
integration is achieved. The MDD file can be saved
as an ASCII file and it could be used on other
operating system platforms, if similar generic
handlers are installed.
Device 2
Automation System
Device Framework
Device 1
Device 3
Platform Adapter
Device Specific
Handler
CDH
(Configurable
Device Handler)
The generated MDD file is stored together with
all the other parameters in the automation system’s
database.
For each MDD file in the database exists a 
corresponding instance
of the generic Device
Handler, which is instantiated at start-up time of the
automation system. The automation system does not
distinguish between generic and specific Device
Handlers.
In the past the integration of devices in automation
systems was performed typically by developing the
device
handler in the
specific programming
language and development environment. This work
was done as a part of the service provided by the
developer of the automation system. The cost of the
integration was significant, especially if the device
was developed by the customer or third party.
In the 90s the scripting technology (Clark, 1999)
(Schneider, 2001) (Wall, 2000) (Hetland, 2002)
emerged in
most automation systems in the
55
Device Integration into Automation Systems
Figure 2: Device Handler types.
2.1 Device Specific Handler 
2.3 Related Work 

automotive industry. Its popularity was primarily
due to the fact that the customisation of automation
systems was possible at the customer site. However,
although the flexibility has increased, the costs of
the integration were lower only at the first sight. The
changes done in the automation system, at the 
customer site, had to be integrated back into the
product, i.e., the product development process had to
be followed to support the customer also in the
maintenance phase. In addition, the changes could
only
be
done by
people with the skills in 
programming and automation system, which is again
the personal of the provider of the automation
system.
Exactly these problems were the motivation for 
the development of the CDH. The authors are not
aware of any similar concept for the integration of
devices in any other automation system, i.e., in test
beds, especially in the automotive industry.
The concepts, as introduced in the product
LabVIEW
(National Instruments, 2003) with the
graphical programming language G or TestPoint
(Capital Equipment Corporation, 2003), offers an
easy-to-use graphical environment to the customer
for the development of instrumentation panels,
device drivers and monitors of technical processes
on the PC-based platform. Nevertheless, these tools
are suitable only for the development of simple
automation systems and not for the integration in 
large automation systems. Moreover, the graphical
programming languages
require more than a
moderate amount of programming skills.
Standards, such as ASAM-GDI or IVI (IVI
Foundation, 2003), specify interfaces between the
Device Handler and the automation system. The art
of the development of Device Handlers is out of the
scope of these standards. CDH is compatible with 
these standards, because it identifies similar
interfaces and functions in the automation system. In 
the chapter 6.5 we discuss the possibility of CDH
supporting the ASAM-GDI standard.
3 CDH DEVICE INTEGRATION
Figure 3 shows the component view of the CDH. It
comprises the following components: Configurable
Device Generator (CDG), Configurable Device
Engine (CDE), Configurable Device Panel (CDP),
and finally the MDD file. The main features of these
components are described in the following sections.
In order to achieve a device integration using the
CDH, first the configuration procedure has to be
performed, i.e., the device functions must be defined
and saved in the MDD file. There are two main
prerequisites for this task to be fulfilled. Firstly, the
person responsible for the device integration (in the
following: device integrator)
has to
have the
knowledge about the device functions. This implies
that the device states, the intended device modes and
the necessary protocol frames are well known.
Secondly, it is necessary to understand the standard
Device Handler’s state machine (see fig. 5) defined
within the Device Framework in order to integrate
the device functions into the automation system
appropriately. 
This 
enables 
the 
correct
synchronisation of the device by the automation
system. With the help of the CDG component, the
device integrator can perform the creative part of the
device integration in a straightforward manner.
Device 2
Automation System
Device Framework
Device 1
Device 3
Platform Adapter
ConfigurableDevice Handler (CDH)
Engine (CDE)
Generator (CDG)
Panel (CDP)
Measurement
Device
Description
File (MDD)
4 OFFLINE CONFIGURATION
The main part of the device integration using the
CDH is the configuration procedure, where the
device specifics are defined and saved in form of the
MDD file. These activities are supported with the
CDG, which conducts the device integrator by
dividing the integration in several precise and clear
defined steps. Hence, the configuration procedure
can be mastered after a short time and in an intuitive
way, and it is therefore especially suitable for 
customers with good knowledge of the device, but
less of the automation system.  At the beginning, the
CDG steps are followed in a sequential way. Later 
as the configuration procedure progresses, it makes
sense to use these steps interchangeably. In the
56
Figure 3: CDH components.
A. Scheibelmasser et al.

following sections the steps are described in more 
details. However, it is out of the scope of this 
document to describe each attribute and feature, and 
therefore only excerpts are shown. 
4.1 Physical Line 
First, the device name used internally in the 
automation system is specified, followed by the 
definition of the parameters for the physical line 
(e.g. RS232). The following structure shows an 
example for the RS232 parameter definition. 
Type: RS232 
Baudrate: 9600 
Bits: 8 
Parity: None 
Stop bit: One 
Port number: COM1 
TimeOut: 1000 [msec]
An excerpt from the definition of a physical line 
4.2 Device Variables 
For every value from the physical device, which 
should be available in the automation system, a 
name and several characteristics, such as Unit, 
Minimum, Maximum, data Type, and Initial Value 
have to be defined. The following description gives 
an example: 
Value: FB_Temperature 
  Unit: °C 
  I/O-Type: Output 
  Type: Float 
  Initial Value: 0 
  Minimum: -10 
  Maximum: 70 
An excerpt from the definition of a Device Variable 
The attribute I/O-Type denotes the device 
variable either as Output (device defines its value) or 
Input (device needs a value from the automation 
system, i.e., from some other SW or HW 
component). This attribute is set automatically by 
the CDG as described in the following section 4.3.  
4.3 Telegrams
Since the access to the physical device occurs 
exclusively via the communication line, each value 
and command has to be transmitted by the 
appropriate communication telegram. Therefore, 
each telegram, which is used for control or data 
acquisition has to be defined in this configuration 
step. The following example shows the definition 
structure of a command and a data inquiry telegram, 
using AK protocol commands (Arbeitskreis, 1991): 
Telegram: SetToRemote 
Type: Send and receive 
Send: <02> SREM K0<03> 
Receive: <02> SREM  #ERROR_Status# 
$AK_Error$<03>
Telegram: GetMeasResult 
Type: Send and receive 
Send: <02> AERG K0<03> 
Receive: <02> AERG #ERROR_Status# 
#FB_MeasCycle# #ignore# 
#FB_MeasTime# #FB_MeasWeight#<03> 
Simplified example for two telegrams 
The telegram definition can contain the definition 
for two protocol frames (one to send and one to 
receive), or for only one (only send or only receive).  
A minimum syntax is used to define a protocol 
frame. This includes, e.g., the definition of fixed (# 
#) and optional ($ $) position for a device variable’s 
value and the definition of not-readable ASCII 
characters (< >). This syntax could be extended with 
the more powerful pattern-matching techniques for 
text processing, such as regular expressions (Friedl, 
2002). 
A device variable is denoted as an Output variable, 
if it used exclusively in receive protocol frames, 
otherwise it is an Input variable (see 4.2).  
Using telegram definitions, CDH can send, receive 
and analyse protocol frames at run-time. Failures in 
terms of transmission timeout or parsing error are 
handled within the execution model of the CDH 
(within CDE) and are mapped to an error handler as 
described later. 
4.4 Sequences 
Transitions in the Device Framework’s state 
machine that trigger and synchronise complex 
device activities are usually implemented by the 
Device Handler with more than one communication 
telegram. The order of the different telegrams and 
their correct invocation ensures the right device 
behaviour. Therefore, there is a need to define the 
logical order.  
From the programming point of view three 
elementary software constructs are sufficient to 
support this, i.e., the commands, the conditional 
branches, and the jump commands or loops. 
57
Device Integration into Automation Systems

According to this fact, the CDG offers elements to 
define telegram invocation orders without the need
for classic programming.
Figure 4: Simplified model of the Sequence execution.
Moreover, to facilitate the typical order patterns
in the automation, the telegram invocation order is
organised in three blocks, which together constitute
the CDH Sequence (see fig. 4).
The first block called Start defines a sequence of
telegrams, which is executed only once. The second 
block, called
Cyclic, allows the execution
of
telegrams cyclically until the end loop condition is 
fulfilled. A third, optional End block is used to
concatenate Sequences, depending on whether a
current Sequence ended with success or failure. The
End block and Global Conditions (see section 4.5),
support the error handling in the CDH handler.
At run-time, the invoked transition in the Device
Framework triggers the execution of the Sequence
by the CDE component. The execution is done
according to the execution model for the MDD 
structures (Sequence, telegram,…). The description
of the execution model is out of the scope of this
document. Hence, the Sequences specified by the
user are actually implementations of the transitions
in the Device Framework’s state machine. The
following description gives an example for a
Sequence Measure, which is invoked, when the
automation 
system
triggers 
the 
start 
of 
a 
measurement:
 Sequence: Measure 
Start Block: 
 If Condition:
  IF RequestArgument <= 0 THEN
  Invoke Sequence NotOk AND
  Display INFO Message:
   “Measurement mode not supported” 
 Function:
SetChannelValue(PARA_MeasTime,
#RequestArgument)
Cyclic Block: 
 If Condition:
H
START
CYCLIC
End Condition
fulfilled?
No
END
Yes
H
  IF FT_ControlSystem < 0 THEN
 Invoke Telegram ADAT_cascade 
 Cycle Time: 1000 msec 
 End Condition: TIME = PARA_MeasTime 
End Block: 
Sequence if OK: Online 
Sequence if NOT OK: AnalyseFailure 
Example of a Sequence
4.5 Global Conditions
A number of protocol frames require the same
reactions (e.g. error handling). Therefore, every
protocol frame has to be checked whether, e.g., an
exception has occurred or not. In order to reduce the
effort of writing a number of same conditions, the 
CDG offers an additional definition step called 
Global Condition.
Conditions defined in this step are checked
automatically at run-time whenever a telegram is 
executed.  If the condition is true the corresponding
reaction is invoked (e.g. telegram or Sequence
execution).
5 ON-LINE USAGE 
At run-time the automation system loads MDD files
from the database and generates a CDH instance for
each of them. The communication to the device is
established according to the parameters of the
corresponding physical line. Every state transition in 
the Device Handler’s state machine triggers the
execution of the corresponding CDH Sequence.
Figure 5 shows the simplified description of the state
machine.
The CDE component interprets the content of the
corresponding MDD file and executes Sequences
according to the specified execution
model.
Consequently, the defined telegrams, conditions and
functions are executed, in order to control the
physical device appropriately. Additionally, for
every device variable defined in the MDD file, the
CDE generates a System Channel if needed, and
provides them with values received
from the 
telegram frames.
58
A. Scheibelmasser et al.

The CDP component provides a graphical view
on active System Channels and their values and the
possibility to trigger each Sequence manually. As 
shown in figure 6, the CDP offers a common GUI
for all CDH instances, which can be used for service
or maintenance reasons.
6 FURTHER DEVELOPMENT 
The
first implementations of the CDH
were
successfully done for a number of measurement
devices and subsystems with RS232 or Ethernet
(TCP/IP,
UDP/IP) 
connection. 
The 
common
protocol of these devices was restricted to ASCII
protocol communication. Experience gained with the
integration of these devices was the base for the
further development issues described in the
following sections.
Running
Not Ready
Ready
Idle
Remote
Busy
Initialise
Release
Measure
Complete
StartDevice
StopDevice
Connect
Device Handler instantiated
Parameters loaded
Device Handler connected to
device
Device Handler ready
Device Handler polls device
Device in remote control mode
Device executes function
6.1 Calculation Capability
The execution model of the CDE is restricted on 
simple value extraction or insertion in protocol
frames. Since there are a number of protocols, which
use checksums or CRC’s, because of data security, it
is necessary to perform such calculations inside the
Device Handler.
An additional aspect is the
arithmetical calculation of different device values.
By introducing a formula interpreter in the CDH, 
both examples can be solved.
6.2 Automatic Detection of Devices
The idea behind the automatic detection of devices
is to automatically detect known devices on different
communication lines. This feature reduces the
logistical effort on test beds and it enables users to
hook up optional devices on demand.
This requirement is fulfilled by introducing an
appropriate Sequence in the CDH, which allows the
automation system to detect known devices on
arbitrary 
lines. 
Depending
on 
the 
device
identification, the automation system is able to link
the appropriate Device Handler to the port where the
device is connected. 
6.3 Multi-Line Connection
At the moment, every CDH instance can be
connected to the physical device only via one
communication line. In order to support devices and
subsystems, which communicate over more than one
line (e.g. the communication
via TCP/IP and 
UDP/IP port), it should be possible to define
telegrams for different communication lines.
6.4 Binary Protocols
Currently, the CDH supports only ASCII protocol
frames. Since there are a number of devices, which
communicate with a binary protocol, this family of
devices cannot be integrated using the CDH.
Extending CDH with a capability to support binary
protocol frames would significantly increase its
versatility.
59
Device Integration into Automation Systems
Figure 5: Simplified Device Handler’s state machine.
Figure 6: CDP visualisation.

6.5 Capability Profiles 
The CDH provides a minimum set of Sequences 
mapped to the transitions of the standard state 
machine of the Device Handler via the Device 
Framework 
interface, 
which 
is 
enough 
to 
synchronise devices (e.g. connect, start cyclic data 
acquisition, start/stop measurement). However, 
additional standard Sequences could be provided 
that would support standard profiles, such as device 
independent profiles (ASAM-DIP, 2002) defined by 
ASAM-GDI standard. This profile defines a general 
state model of a test run and the required transitions. 
Implementing this profile would imply that the 
Device Handler is interoperable on test bed systems 
of different vendors supporting this standard.  
7 CONCLUSION
The integration of devices in automation systems is 
typically a complex procedure that requires not only 
a good knowledge of the device and the automation 
system, but also requires programming skills. 
The concept of the CDH offers an alternative 
approach for the integration of less complex devices. 
The device integrator is able to focus on device 
functions and to integrate them into the automation 
system using a simple configuration procedure 
described in this document. Not only that the 
integration can be done at the customer site, but also 
the customer himself is in the position to integrate 
his or a third-party device and to maintain it.  
The CDH was implemented in the automation 
system PUMA Open developed at AVL and has 
shown excellent results in the practice. The major 
number 
of 
in-house 
devices, 
specifically 
measurement devices, were integrated into the 
PUMA Open using the CDH and are productively in 
use by a number of OEM’s and suppliers in the 
automotive industry. Moreover, customers have also 
integrated devices by means of the CDH by 
themselves and are using them in research and 
production.  
The costs and the effort for the integration were 
significantly reduced and, at the same time, the 
quality of the integration has increased, since it was 
possible to focus on device capabilities and to work 
in the office with a device emulator. 
Using this integration method, the device 
integration got very easy, if the device integrator 
understands the device well! 
REFERENCES
Arbeitskreis der deutschen Automobilindustrie, 1991. UA 
Schnittstelle und Leitrechner, V24/RS232 Schnittstelle 
ASAM e.v., 2001. Introduction to ASAM-GDI, rev. 10,
ASAM e.v., 2001. ASAM-GDI Part A: Specification of the 
Device Capability Description of an ASAM-GDI 
ASAM e.v., 2001. ASAM-GDI Part B: Specification of the  
ASAM e.v., 2002. Device Independent Profile (DIP)  
AVL List GmbH, 2004. PUMAopen Test Bed Automation 
Capital Equipment Corporation, 2003. Test Point, version 
Clark, S., 1999. VBScript : Programmer’s Reference,
Friedl, J.E.F, 2002. Mastering Regular Expressions, 2nd
Hetland, M.L., 2002. Practical Python, 1st ed., APress 
ISO, 1990. Overview and Architecture,  IEEE Std 802-
IVI Foundation, 2003. Driver Architecture Specification, 
National Instruments, 2003. LabVIEW, version 7, 
Schneider, F., 2001. T.A. Powell, JavaScript: The 
Wall, L., Christiansen, T., Orwant, J., 2000. Programming
Perl, 3rd
60
 ed., O’Reilly & Associates. 
Complete Reference, McGraw-Hill Osborne Media. 
www.labview.com/labview. 
rev. 1.2,  www.ivifoundation.org.  
1990.
ed., O’Reilly & Associates. 
Wrox.
5, www.cec488.com. 
Software, www.avl.com. 
Specification, rev. 4.2. 
Interface of an ASAM-GDI Driver, rev. 4.2. 
Driver, rev. 4.2.
www.asam.net/03_standards_05.php. 
– Grundsätzliches.
A. Scheibelmasser et al.

NON LINEAR SPECTRAL SDP METHOD FOR BMI-CONSTRAINED
PROBLEMS : APPLICATIONS TO CONTROL DESIGN
Jean-Baptiste Thevenet
ONERA-CERT, 2 av. Edouard Belin, 31055 Toulouse, France
and UPS-MIP (Mathmatiques pour l’Industrie et la Physique), CNRS UMR 5640
118, route de Narbonne 31062 Toulouse, France, thevenet@cert.fr
Dominikus Noll
UPS-MIP, noll@mip.ups-tlse.fr
Pierre Apkarian
ONERA-CERT and UPS-MIP, apkarian@cert.fr
Keywords:
Bilinear matrix inequality, spectral penalty function, trust-region, control synthesis.
Abstract:
The purpose of this paper is to examine a nonlinear spectral semideﬁnite programming method to solve prob-
lems with bilinear matrix inequality (BMI) constraints. Such optimization programs arise frequently in au-
tomatic control and are difﬁcult to solve due to the inherent non-convexity. The method we discuss here is
of augmented Lagrangian type and uses a succession of unconstrained subproblems to approximate the BMI
optimization program. These tangent programs are solved by a trust region strategy. The method is tested
against several difﬁcult examples in feedback control synthesis.
1
INTRODUCTION
Minimizing a linear objective function subject to bi-
linear matrix inequality (BMI) constraints is a useful
way to describe many robust control synthesis prob-
lems. Many other problems in automatic control lead
to BMI feasibility and optimization programs, such as
ﬁltering problems, synthesis of structured or reduced-
order feedback controllers, simultaneous stabilization
problems and many others. Formally, these problems
may be described as
minimize
cT x, x ∈Rn
subject to
B(x) ⪯0,
(1)
where ⪯0 means negative semi-deﬁnite and
B(x) = A0 +
n

i=1
xiAi +

1≤i<j≤n
xixjBij
(2)
is
a
bilinear
matrix-valued
operator
with
data
Ai, Bij ∈Sm.
The importance of BMIs was recognized over the
past decade and different solution strategies have been
proposed. The earliest ideas use interior point meth-
ods, imported from semideﬁnite programming (SDP),
concave programming or coordinate descent meth-
ods employing successions of SDP subproblems. The
success of these methods is up to now very limited,
and even moderately sized programs with no more
than 100 variables usually make such methods fail.
Signiﬁcant progress was achieved by two recent ap-
proaches, both using successions of SDP tangent sub-
problems. In (Fares et al., 2002), a sequential semi-
deﬁnite is used, programming (S-SDP) algorithm,
expanding on the sequential quadratic programming
(SQP) technique in traditional nonlinear program-
ming. In (Noll et al., 2002; Apkarian et al., 2003;
Fares et al., 2001) an augmented Lagrangian strategy
is proposed, which was since then successfully tested
against a considerable number of difﬁcult synthesis
problems (Fares et al., 2000; Apkarian et al., 2002;
Apkarian et al., 2004; Noll et al., 2002). This ap-
proach is particularly suited when BMI problems are
transformed to LMI-constrained programs with an ad-
ditional nonlinear equality constraints:
minimize
cT x, x ∈Rn
subject to
A(x) ⪯0
g(x) = 0.
(3)
Here A is an afﬁne operator (i.e., (2) with Bij = 0)
with values in Sm, and g : Rn →Rp incorporates
a ﬁnite number of equality constraints. Notice that
every BMI problem may in principle be transformed
to the form (3), but the change will only be fruitful if
it is motivated from the control point of view. The lat-
ter is for instance the case in robust or reduced order
synthesis, where the projection lemma is successfully
brought into play.
For semideﬁnite programming,
(Zibulevsky, 1996; Ben-Tal and Zibulevsky, 1997)
propose a modiﬁed augmented Lagrangian method,
61
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 61–72. 

which in (Kocvara and Stingl, 2003) has been used to
build a software tool for SDP called PENNON. The
idea is further expanded in (Henrion et al., 2003) to
include BMI-problems.
The present paper addresses cases where the pas-
sage from (1) to (3) seems less suited and a direct
approach is required. Our algorithm solves (1) by a
sequence of unconstrained subproblems via a trust re-
gion technique. Using trust regions is of the essence,
since we have to bear in mind that (1) is usually highly
non-convex. In consequence, local optimal methods
risk failure by getting stalled at a local minimum of
constraint violation. This refers to points x satisfy-
ing B(x)̸ ⪯0, where the algorithm makes no further
progress. Such a case means failure to solve the un-
derlying control problem, which requires at least x
with B(x) ⪯0. This phenomenon may be avoided
(or at least signiﬁcantly reduced) with genuine second
order strategies. In particular, trust region techniques
do not require convexiﬁcation of the tangent problem
Hessian, a major advantage over line search methods.
(Notice that in this situation, any approach to (1) us-
ing a succession of SDPs is bound to face similar dif-
ﬁculties due to the need to convexify the Hessian. On
the other hand, if LMI-constrained subproblems with
non-convex quadratic objectives f(x) can be handled,
such an approach is promising. This idea has been de-
veloped successfully in (Apkarian et al., 2004).
While our technique could be applied basically to
any BMI-constrained program, we presently focus on
automatic control issues. In particular, we give ap-
plications in static output feedback control under H2,
H∞or mixed H∞/H2 performance indicies. Two
other difﬁcult cases, multi-model and multi-objective
synthesis, and synthesis of structured controllers, are
presented.
The structure of the paper is as follows. In sec-
tion 2, we present our spectral SDP method and dis-
cuss its principal features.
Section 3 presents the-
ory needed to compute ﬁrst and second derivatives of
spectral functions. Finally, in section 4, numerical ex-
periments on automatic control issues are examined.
NOTATION
Our notation is standard. We let Sm denote the set
of m × m symmetric matrices, M T the transpose
of the matrix M and Tr M its trace. We equip Sm
with the euclidean scalar product ⟨X, Y ⟩= X • Y =
Tr (XY ). For symmetric matrices , M ≻N means
that M −N is positive deﬁnite and M ⪰N means
that M −N is positive semi-deﬁnite. The symbol
⊗stands for the usual Kronecker product of matrices
and vec stands for the columnwise vectorization on
matrices. We shall make use of the properties:
vec (AXB)
=
(BT ⊗A) vec X,
(4)
Tr (AB)
=
vec T AT vec B,
(5)
which hold for matrices A, X and B of compatible di-
mensions. The Hadamard or Schur product is deﬁned
as
A ◦B = ((AijBij)).
(6)
The following holds for matrices of the same dimen-
sion:
vec A ◦vec B = diag(vec A)vec B,
(7)
where the operator diag forms a diagonal matrix with
vec A on the main diagonal.
2
NONLINEAR SPECTRAL SDP
METHOD
In this chapter we present and discuss our method to
solve BMI-constrained optimization problems. Sec-
tion 2.1 gives the general out-set, while the subse-
quent sections discuss theoretical and implementa-
tional aspects of the method.
2.1
The method we are about to present applies to more
general classes of objective functions than (1). We
shall consider matrix inequality constrained programs
of the form
minimize
f(x), x ∈Rn
subject to
F(x) ⪯0,
(8)
where f is a class C2 function, F : Rn →Sm a class
C2 operator. We will use the symbol B whenever we
wish to specialize to bilinear operators (2) or to the
form (1), and we use A for afﬁne operators.
Our method is a penalty/barrier multiplier algo-
rithm as proposed in (Zibulevsky, 1996; Mosheyev
and Zibulevsky, 2000). According to that terminol-
ogy, a spectral penalty (SP) function for (1) is deﬁned
as
F(x, p) = f(x) + Tr Φp(F(x)),
(9)
where ϕp : R →R is a parametrized family of scalar
functions, which generates a family of matrix-valued
operators Φp : Sm →Sm upon deﬁning:
Φp(X) := Sdiag [ϕp (λi(X))] ST .
(10)
Here λi(X) stands for the ith eigenvalue of X ∈Sm
and S is an orthonormal matrix of associated eigen-
vectors. An alternative expression for (9) using (10)
is:
F(x, p) = f(x) +
m

i=1
ϕp(λi(F(x)) .
(11)
62
General Outline
J.-B. Thevenet et al.

As ϕp is chosen strictly increasing and satisﬁes
ϕp(0) = 0, each of the following programs (parame-
trized through p > 0)
minimize
f(x), x ∈Rn
subject to
Φp(F(x)) ⪯0
(12)
is equivalent to (8).
Thus, F(x, p) may be under-
stood as a penalty function for (8). Forcing p →0,
we expect the solutions to the unconstrained program
minx F(x, p) to converge to a solution of (8).
It is well-known that pure penalty methods run into
numerical difﬁculties as soon as penalty constants get
large. Similarly, using pure SP functions as in (9)
would lead to ill-conditioning for small p > 0. The
epoch-making idea of Hestenes (Hestenes, 1969) and
Powell (Powell, 1969), known as the augmented La-
grangian approach, was to avoid this phenomenon by
including a linear term carrying a Lagrange multiplier
estimate into the objective. In the present context, we
follow the same line, but incorporate Lagrange multi-
plier information by a nonlinear term. We deﬁne the
augmented Lagrangian function associated with the
matrix inequality constraints in (1) as
L(x, V, p)
=
f(x) + Tr Φp(V T F(x)V ) ,
(13)
=
f(x) +
m

i=1
ϕp(λi(V T F(x)V )).
In this expression, the matrix variable V has the same
dimension as F(x) ∈Sm and serves as a factor of the
Lagrange multiplier variable U ∈Sm, U = V V T (for
instance, a Cholesky factor). This has the immediate
advantage of maintaining non-negativity of U ⪰0. In
contrast with classical augmented Lagrangians, how-
ever, the Lagrange multiplier U is not involved lin-
early in (13). We nevertheless reserve the name of
an augmented Lagrangian for L(x, V, p), as its prop-
erties resemble those of the classical augmented La-
grangian. Surprisingly, the non-linear dependence of
L(x, V, p) on V is not at all troublesome and a suit-
able ﬁrst-order update formula V →V +, generaliz-
ing the classical one, will be readily derived in section
3.2.
Let us mention that the convergence theory for an
augmented Lagrangian method like the present one
splits into a local and a global branch. Global the-
ory gives weak convergence of the method towards
critical points from arbitrary starting points x, if nec-
essary by driving p →0. An important complement
is provided by local theory, which shows that as soon
as the iterates reach a neighbourhood of attraction of
one of those critical points predicted by global theory,
and if this critical point happens to be a local mini-
mum satisfying the sufﬁcient second order optimality
conditions, then the sequence will stay in this neigh-
bourhood, converge to the minimum in question, and
the user will not have to push the parameter p below
a certain threshold ¯p > 0. Proofs for global and local
convergence of the augmented Lagrangian (AL) ex-
ist in traditional nonlinear programming (see for in-
stance (Conn et al., 1991; Conn et al., 1996; Conn
et al., 1993b; Conn et al., 1993a; Bertsekas, 1982)).
Convergence theory for matrix inequality constraints
is still a somewhat unexplored ﬁeld. A global con-
vergence result which could be adapted to the present
context is given in (Noll et al., 2002). Local theory for
the present approach covering a large class of penalty
functions ϕp will be presented in a forthcoming ar-
ticle. Notice that in the convex case a convergence
result has been published in (Zibulevsky, 1996). It is
based on Rockafellar’s idea relating the AL method
to a proximal point algorithm. Our present testing
of nonconvex programs (1) shows a similar picture.
Even without convexity the method converges most
of the time and the penalty parameter is in the end
stably away from 0, p ≥¯p.
Schematically, the augmented Lagrangian tech-
nique is as follows:
Spectral augmented Lagrangian algorithm
1. Initial phase.
Set constants γ > 0, ρ < 1.
Initialize the algorithm with x0, V0 and a penalty
parameter p0 > 0.
2. Optimization phase. For ﬁxed Vj and pj solve
the unconstrained subproblem
minimizex∈Rn
L(x, Vj, pj)
(14)
Let xj+1 be the solution. Use the previous iterate
xj as a starting value for the inner optimization.
3. Update penalty and multiplier. Apply ﬁrst-
order rule to estimate Lagrange multiplier:
Vj+1V T
j+1 = VjS

diagϕ′
p

λi

V T
j
·F(xj+1)Vj))] ST V T
j ,
(15)
where S diagonalizes V T
j F(xj+1)Vj.
Update the penalty parameter using:
pj+1 =
 ρpj,
if λmax(0, F(xj+1))
> γ λmax(0, F(xj))
pj,
else
(16)
Increase j and go back to step 2.
In our implementation, following the recommenda-
tion in (Mosheyev and Zibulevsky, 2000), we have
used the log-quadratic penalty function ϕp(t)
=
pϕ1(t/p) where
ϕ1(t) =

t + 1
2t2
if
t ≥−1
2
−1
4 log(−2t) −3
8
if
t < −1
2,
(17)
63
Non Linear Spectral SDP Method for BMI-Constrained Problems

but other choices could be used (see for instance
(Zibulevsky, 1996) for an extended list).
The multiplier update formula (15) requires the full
machinery of differentiability of the spectral function
Tr Φp and will be derived in section 3.2. Algorithmic
aspects of the subproblem in step 2 will be discussed
in section 3.3. We start by analyzing the idea of the
spectral AL-method.
2.2
In order to understand the rationale behind the AL-
algorithm, it may be instructive to consider classical
nonlinear programming, which is a special case of
the scheme if the values of the operator F are di-
agonal matrices: F(x) = diag [c1(x), . . . , cm(x)].
Then the Lagrange multiplier U and its factor V may
also be restricted to the space of diagonal matrices,
U = diag ui, V = diag vi, and we recover the situa-
tion of classical polyhedral constraints. Switching to
a more convenient notation, the problem becomes
minimize
f(x)
subject to
cj(x) ≤0, j = 1, . . . , m
With ui = v2
i , we obtain the analogue of the aug-
mented Lagrangian (13):
L(x, v, p) = f(x) +
m

i=1
pϕ1(v2
i ci(x)/p).
Here we use (17) or another choice from the list in
(Zibulevsky, 1996).
Computing derivatives is easy
here and we obtain
∇L(x, v, p) = ∇f(x)
+
m

i=1
ϕ′
1(v2
i ci(x)/p)v2
i ∇ci(x).
If we compare with the Lagrangian:
L(x, u) = f(x) + uT c(x),
and its gradient:
∇L(x, u) = ∇f(x) + m
i=1 ui∇ci(x),
the following update formula readily appears:
u+
i = v+2
i
= v2
i ϕ′
1(v2
i ci(x+)/p),
the scalar analogue of (15). Suppose now that ϕ1 has
the form (17). Then for sufﬁciently small v2
i ci(x) we
expect v2
i ci(x)/p > −1
2, so
p ϕ1(v2
i ci(x)/p)
=
p

v2
i ci(x)/p
+1
2v4
i ci(x)2/p2
=
uici(x) + 1
2(v4
i /p)ci(x)2.
If we recall the form of the classical augmented La-
grangian for inequality constraints (cf.
(Bertsekas,
1982))
L(x, u, µ) = f(x)
+ µ
2
m

i=1
	
max [0, ui + ci(x)/µ]2 −u2
i

,
we can see that the term v4
i /p takes the place of
the penalty parameter 1/µ as long as the v′
is remain
bounded. This suggests that the method should be-
have similarly to the classical augmented Lagrangian
method in a neighbourhood of attraction of a local
minimum. In consequence, close to a minimum the
updating strategy for p should resemble that for the
classical parameter µ. In contrast, the algorithm may
perform very differently when iterates are far away
from local minima. Here the smoothness of the func-
tions ϕ1 may play favorably. We propose the update
(16) for the penalty parameter, but other possibilities
exist, see for instance Conn et al., and need to be
tested and compared in the case of matrix inequality
constraints.
3
DERIVATIVES OF SP
FUNCTIONS
In this section we obtain formulas for the ﬁrst-
and second-order derivatives of the augmented La-
grangian function (13). This part is based on the dif-
ferentiability theory for spectral functions developed
by Lewis et al. (Lewis, 1996; Lewis, 2001; Lewis and
S.Sendov, 2002). To begin with, recall the following
Deﬁnition 3.1 Let λ : Sm →Rm denote the eigen-
value map λ(X) := (λ1(X), . . . , λm(X)).
For a
symmetric function ψ : Rm →R, the spectral func-
tion Ψ associated with ψ is deﬁned as Ψ : Sm →R,
Ψ = ψ ◦λ.
First order differentiability theory for spectral func-
tions is covered by (Lewis, 1996). We will need the
following result from (Lewis, 1996):
Lemma 3.2 Let ψ be a symmetric function deﬁned on
an open subset D of Rn. Let Ψ = ψ◦λ be the spectral
function associated with ψ. Let X ∈Sm and suppose
λ(X) ∈D. Then Ψ is differentiable at X if and only
if ψ is differentiable at λ(X). In that case we have
the formula:
∇Ψ(X) = ∇(ψ ◦λ)(X) = S diag ∇ψ (λ(X)) ST
for every orthogonal matrix S satisfying
X = S diagλ(X) ST .
□
64
J.-B. Thevenet et al.
The mechanism of the Algorithm
deﬁnition from (Lewis and S. Sendov, 2002).

The gradient ∇Ψ(X) is a (dual) element of Sm,
which we distinguish from the differential, dΨ(X).
The latter acts as a linear form on tangent vectors
dX ∈Sm as
dΨ(X)[dX]
=
∇Ψ(X) • dX
=
Tr

S diag ∇ψ (λ(X))ST dX

.
It is now straightforward to compute the ﬁrst deriva-
tive of a composite spectral functions Ψ ◦F, where
F : Rn →Sm is sufﬁciently smooth. We obtain
∇(Ψ ◦F) (x) = dF(x)∗[∇Ψ (F(x))] ∈Rn, (18)
where dF(x) is a linear operator mapping Rn →Sm,
and dF(x)∗its adjoint, mapping Sm →Rn. With the
standing notation
F := F(x),
Fi := ∂F(x)
∂xi
∈Sm,
we obtain the representations
dF(x)[δx]
=
n

i=1
Fiδxi,
dF(x)∗[dX]
=
(F1 • dX, . . . , Fn • dX) .
Then the ith element of the gradient is
(∇(Ψ ◦F) (x))i
= Tr

FiSdiag∇ψ (λ(F)) ST 
.
(19)
Observe that Fi = Ai+
j<i Bjixj+
i<j Bijxj
if B is of the form (2), Fi = Ai for afﬁne operators
A.
We are now ready for the ﬁrst derivative of the aug-
mented Lagrangian function L(x, V, p). We consider
a special class of symmetric functions ψ : Rn →R,
ψ(x) =
n

i=1
ϕ(xi),
(20)
generated by a single scalar function ϕ : R →R.
Here the spectral function Ψ = ψ ◦λ is of the form
Ψ = Tr Φ with Φ : Sm →Sm the matrix-valued
operator
Φ(X) = S diag ϕ (λ(X)) ST ,
S being an orthogonal matrix diagonalizing X. Using
ϕp, ψp and Ψp instead of ϕ, ψ and Ψ, the penalty term
in (13) takes the form
Ψp(V T F(x)V ))
=
ψp ◦λ(V T F(x)V ))
=
m

i=1
ϕp(λi(V T F(x)V ))
=
Tr Φp(V T F(x)V ),
where Φp is given in (10). Now we apply Lemma
3.2, respectively formula (18) or even (19) to Ψp =
Tr Φp and the operator F(x) = V T F(x)V , where
we observe en passant that
d F(x)∗[X]
=
d

V T FV

(x)
∗[X]
=
dF(x)∗[V XV T ],
or put differently, Fi = V T FiV . This gives the fol-
lowing
Proposition 3.3 With the above notations the gradi-
ent of L(x, V, p) is given as
∂
∂xi
L(x, V, p) =
∂
∂xi
f(x)
+ Tr

Fi V S diag [ϕ′
p(λi(V T FV ))] ST V T 
.
In vector notation
∇L(x, V, p) = ∇f(x)+[vec (F1), . . . , vec (Fn)]T
· vec

V S diag [ϕ′
p(λi(V T FV ))] ST V T 
,
where S is orthogonal and diagonalizes V T FV .
□
3.1
The second order theory of spectral function is more
involved and presented in (Lewis, 2001; Lewis and
S.Sendov, 2002). We require the following central ob-
servation.
Lemma 3.4 With the same notations as above, Ψ =
ψ ◦λ is twice differentiable at X ∈Sm if and only if
ψ is twice differentiable at λ(X) ∈D.
□
We specialize again to the class of spectral func-
tions Ψ = Tr Φ generated by a single scalar function
ϕ, see (20). Then we have the following result im-
ported from (Shapiro, 2002):
Lemma 3.5 Let ϕ : R →R be a function on the real
line, and let ψ be the symmetric function on Rn gener-
ated by (20) above. Let Ψ = Tr Φ denote the spectral
function associated with ψ. Suppose ϕ is twice differ-
entiable on an open interval I. Then Ψ is twice differ-
entiable at X whenever λi = λi(X) ∈I for every i.
Moreover, if we deﬁne the matrix ϕ
′[1] = ϕ
′[1](X) ∈
Sm as:
ϕ
′[1]
ij
:=

ϕ′(λi)−ϕ′(λj)
λi−λj
if
λi ̸= λj
ϕ′′(λi)
if
λi = λj
,
then the following formula deﬁnes the second order
derivative of Ψ at X
d2Ψ(X))[dX, dX] = Tr (ST dXSϕ
′[1]◦{ST dXS}),
where S is orthogonal and diagonalizes X.
□
65
Non Linear Spectral SDP Method for BMI-Constrained Problems
Second Derivatives

In order to obtain second derivatives of composite
functions, Ψ◦F, we will require the chain rule, which
for the second differential forms d2Ψ(X)[dX, dX] of
Ψ and d2F(x)[δx, δx] of F amounts to:
d2 (Ψ ◦F) (x)[δx, δx]
= dΨ (F(x))

d2F(x)[δx, δx]

+ d2Ψ (F(x)) [dF(x)[δx], dF(x)[δx]] .
(21)
For bilinear B, the second order form d2B(x) is of
course independent of x and given as
d2B(x)[δx, δx] =

i<j
δxiδxjBij.
In particular, d2A = 0 for afﬁne operators A. During
the following we shall use these results to obtain sec-
ond derivatives of the augmented Lagrangian function
L(x, V, p).
As in the previous section, we apply the results to
Ψp = Tr Φp generated by ϕp and to the operator
F(x) = V T F(x)V . As we have already seen, for
F we have the formula
d F(x)[δx]
=
n

i=1
V T FiV δxi
=
V T
n

i=1
FiδxiV
=
V T dFV.
Therefore, using Lemma 3.5, the second term in (21)
becomes
d2Ψp(V T FV ) [V T dF V, V T dF V ]
= Tr
	
ST V T dF V S ϕ
′[1]
p
◦{ST V T dF V S}

,
where S is orthogonal and diagonalizes V T FV and
ϕ
′[1]
p
= ϕ
′[1]
p (V T FV ). This may now be transformed
to vector-matrix form using the operator vec and the
relations (4) - (7).
d2Ψp(V T FV )[V T dF V, V T dF V ]
= vec T ((V S)T dF (V S))
· vec (ϕ
′[1]
p
◦{(V S)T dF (V S)})
= vec T (dF) Kp vec (dF) ,
(22)
where the matrix Kp is
Kp = [(V S) ⊗(V S)]diag

vec ϕ
′[1]
p

· [(V S)T ⊗(V S)T ].
Using dF = n
i=1 Fiδxi, the last line in (22) gives
d2Ψp(V T FV )[V T dF V, V T dF V ]
= δxT [vec (F1), . . . , vec (Fn)]T Kp
· [vec (F1), . . . , vec (Fn)] δx,
so we are led to retain the symmetric n × n matrix
H1 = [vec (F1), . . . , vec (Fn)]T Kp
· [vec (F1), . . . , vec (Fn)] .
(23)
Let us now consider the second part of the
Hessian
∇2L(x, V, p),
coming
from
the
term
dΨ (F(x))

d2F(x)[δx, δx]

in (21).
First observe
that trivially
d2 F(x)[δx, δx]
=
d2{V T FV }(x)[δx, δx]
=
V T d2F(x)[δx, δx] V.
Hence
dΨp(V T FV )

V T d2F(x)[δx, δx]V

= Tr

S diag ϕ′
p

λi(V T FV )

ST
·V T d2F(x)[δx, δx]V

= Tr

V S diag ϕ′
p

λi(V T FV )

ST V T
·d2F(x)[δx, δx]

.
(24)
Introducing matrices Fij = Fij(x) ∈Sm to repre-
sent
d2F(x)[δx, δx] =
n

i,j=1
Fijδxiδxj,
relation (24) may be written as
dΨp(V T FV )

V T d2F(x)[δx, δx]V

=
n

i,j=1
δxiδxjTr

FijV S diag ϕ′
p

λi(V T
·FV )) ST V T 
.
Hence the interest to deﬁne a second symmetric n×n
matrix H2 by
(H2)ij = Tr

FijV Sdiagϕ′
p

λi(V T FV )

ST V T 
,
(25)
where as before S is orthogonal and diagonalizes
V T FV . We summarize by the following
Proposition 3.6 The Hessian of the augmented La-
grangian function L(x, V, p) is of the form
∇2L(x, V, p) = ∇2f(x) + H1 + H2,
where H1, given by (23), is positive semideﬁnite. H2
is given by (25).
Proof. The only element which remains to be proved
is non-negativity of H1, which hinges on the non-
negativity of Kp, and hence on that of ϕ
′[1]
p . The latter
is a consequence of the convexity of ϕp, hence the re-
sult.
□
66
J.-B. Thevenet et al.

3.2
The ﬁrst-order multiplier update rule is derived sim-
ilarly to the classical case of polyhedral constraints.
For our analysis we will require the traditional La-
grangian of problem (8), which is
L(x, U) = f(x) + U • F(x).
(26)
Suppose x+ is the solution of problem (14) in step
2 of our algorithm. Let U = V V T the current La-
grange multiplier estimate.
A new multiplier U +
and therefore a new factor estimate V + with U + =
V +V +T is then obtained by equating the gradients
of the augmented Lagrangian in (13) and the tradi-
tional Lagrangian of problem (1). Writing L(x, U) =
f(x) + Tr (UF(x)) = f(x) + Tr (V V T F(x)) =
f(x) + Tr (V T F(x)V ), and computing its gradient
at x+ and U + = V +V +T implies
∇L(x+, U +) = ∇f(x+)
+ [vec (F1), . . . , vec (Fn)]T vec (V +V +T ).
Comparing with
∇L(x+, V +, p)
= ∇f(x+) + [vec (F1), . . . , vec (Fn)]T
· vec

V S diag ϕ′
p(λi(V T F(x+)V )ST V T 
suggests the update rule
V +V +T = V S [diag ϕ′
p(λi(V T F(x+)V ))] (V S)T ,
(27)
where S is orthogonal and diagonalizes V T F(x+)V .
This was already presented in our algorithm. The ar-
gument suggests the equality to hold only modulo the
null space of [vec (F1), . . . , vec (Fn)]T , but the limit-
ing case gives more information. Notice that equality
∇L(¯x, ¯U) = ∇L(¯x, ¯V , p)
holds at a Karush-Kuhn-Tucker pair (¯x, ¯U) and ¯U =
¯V ¯V T for every p > 0, a formula whose analogue
in the classical case is well-known. That means we
would expect (27) to hold at x+ = ¯x, V = V + =
¯V . This is indeed the case since by complementarity,
¯V T F(¯x) ¯V = 0. With ϕ′
p(0) = 1 for every p >
0, the right hand side in (27) is ¯V T ST S ¯V = ¯V T ¯V ,
hence equals the left hand side. We may therefore
read (27) as some sort of ﬁxed-point relation, which
is satisﬁed in the limit V = V + if iterates converge.
Notice, however, that convergence has to be proved by
an extra argument, because (27) is not of contraction
type.
Notice that by construction the right hand term in
(27) is indeed positive deﬁnite, so V + could for in-
stance be chosen as a Cholesky factor.
3.3
Efﬁcient minimization of L(x, Vj, pj) for ﬁxed Vj, pj
is at the core of our approach and our implementation
is based on a Newton trust region method, following
the lines of Lin and Mor´e (Lin and More, 1998). As
compared to Newton line search algorithms or other
descent direction methods, trust regions can take bet-
ter advantage of second-order information. This is
witnessed by the fact that negative curvature in the
tangent problem Hessian, frequently arising in BMI-
minimization when iterates are still far away from any
neighbourhood of local convergence, may be taken
into account. Furthermore, trust region methods of-
ten (miraculously) ﬁnd good local minima, leaving
the bad ones behind.
This additional beneﬁt is in
contrast with what line search methods achieve, and
is explained to some extent by the fact that, at least
over the horizon speciﬁed by the current trust region
radius, the minimization in the tangent problem is a
global one.
As part of our testing, and at an early stage of the
development, we studied the behavior of our code on
a class of LMI problems, where we compared line
search and trust region approaches. Even in that situa-
tion, where line search is supposedly at its best due to
convexity, the trust region variant appeared to be more
robust, though often slower. This is signiﬁcant when
problems get ill-conditioned, which is often the case
in automatic control applications. Then the Newton
direction, giving descent in theory, often fails to do so
due to ill-conditioning. In that event recourse to ﬁrst-
order methods has to be taken. This is where a trust
region strategy continues to perform reasonably well.
As currently implemented, both the trust region and
line search variant of our method apply a Cholesky
factorization to the tangent problem Hessian. This
serves either to build an efﬁcient preconditioner, or
to compute the Newton direction in the second case.
When the Hessian is close to becoming indeﬁnite, a
modiﬁed Cholesky factorization is used (∇2L + E =
JJT , with J a lower triangular matrix and E a shift
matrix of minimal norm). This is a critical point of
the algorithm, particularly for our hard problems, be-
cause the condition number of the shifted Hessian has
to be reasonable to avoid large computational round-
off errors. However, trading a larger condition num-
ber may be often desirable, for example when the
Hessian at the solution is ill-conditioned. We found
that the revised modiﬁed Cholesky algorithm pro-
posed by (Schnabel and Eskow, 1999) achieves this
goal fairly well.
There are a few more features of our approach,
which in our opinion merit special attention as they
seem to be typical for automatic control applications.
67
Non Linear Spectral SDP Method for BMI-Constrained Problems
Multiplier Update Rule
Solving the Subproblem -
Implementational Issues

A ﬁrst issue is the magnitude of the decision vari-
ables, which may vary greatly within a given prob-
lem. In particular the range of the Lyapunov variables
may show differences of several orders of magnitude,
a phenomenon which is difﬁcult to predict in advance,
as the physical meaning of the Lyapunov variables
is often lacking. Properly scaling these variables is
therefore difﬁcult in general.
A similar issue is to give prior bounds on the con-
troller gains. This is mandatory because these values
are to be useful in the hard-ware implementations of
the theoretically computed controllers. Exceedingly
large gains would bear the risk to amplify measure-
ment noise and thwart the process. This may also be
understood as a quest on the well-posedness of the
initial control problem, which should include explicit
gain bound constraints.
Incomplete knowledge about the numerical range
of the different variables is in our opinion the source
of most numerical difﬁculties and a method to balance
data is extremely important.
4
NUMERICAL EXAMPLES
In this section we test our code on a variety of difﬁcult
applications in automatic control. The ﬁrst part uses
examples from static output feedback control.
We
then discuss applications like sparse linear constant
output-feedback design, simultaneous state-feedback
stabilization with limits on feedback gains and ﬁnally
multi-objective H2/H∞-controller design. Here we
import examples from (Hassibi et al., 1999). In all
these cases our method achieves closed-loop stability,
while performance indicies like H∞, H2 or mixed
performances previously published in the literature
are signiﬁcantly improved. We always start our algo-
rithm at x0 = 0 in order to capture a realistic scenario,
where no such prior information is available.
4.1
We ﬁrst recall a BMI characterization of the classical
output feedback synthesis problem. To this end let
P(s) be an LTI (Linear Time Invariant) system with
state-space equations:
P(s) :
 ˙x
z
y
 
=
 A
B1
B2
C1
D11
D12
C2
D21
D22
 x
w
u
 
, (28)
where
• x ∈Rn1 is the state vector,
• u ∈Rm2 is the vector of control inputs,
• w ∈Rm1 is a vector of exogenous inputs,
• y ∈Rp2 is the vector of measurements,
• z ∈Rp1 is the controlled or performance vector.
• D22 = 0 is assumed without loss of generality.
Let Tw,z(s) denote the closed-loop transfer functions
from w to z for some static output-feedback control
law:
u = Ky .
(29)
u
w
y
z
P(s)
K(s)
Figure 1: Output-feedback Linear Fractional Transform.
Our aim is to compute K subject to the following con-
straints:
• internal stability: for w = 0 the state vector of the
closed-loop system (28) and (29) tends to zero as
time goes to inﬁnity.
• performance: the H∞norm ∥Tw,z(s)∥∞, respec-
tively the H2 norm ∥Tw,z(s)∥2, is minimized
where the closed-loop transfer Tw,z(s) is described
as:

˙x = (A + B2KC2)x + (B1 + B2KD21)w
z = (C1 + D12KC2)x + (D11 + D12KD21)w.
Recall that in the H2 case, some feedthrough terms
must be nonexistent in order for the H2 performance
to be well deﬁned.
We have to assume D11
=
0,
D21 = 0 for the plant in (28).
This guaran-
teed, both static H∞and H2 indicies are then trans-
formed into a matrix inequality condition using the
bounded real lemma (Anderson and Vongpanitlerd,
1973). This leads to well-know characterizations:
Proposition 4.1 A stabilizing static output feedback
controller K with H∞gain ∥Tw,z(s)∥∞≤γ exists
provided there exists X ∈Sn1 such that:
 (A+B2KC2) T X+ ∗
∗
∗
(B1+B2KD21)T X
−γI
∗
(C1+D12KC2)
(D11+D12KD21) −γI

≺0
(30)
X ≻0.
(31)
68
J.-B. Thevenet et al.
Static Output Feedback
Controller Synthesis

Proposition 4.2 A stabilizing static output feedback
controller K with H2 performance ∥Tw,z(s)∥2 ≤√γ
exists provided there exist X, M ∈Sn1 such that:

(A+B2KC2) T X+ ∗
∗
(C1+D12KC2)
−I

≺
0
(32)

M
∗
X (B1+B2KD21) X

≻
0
(33)
Tr (M) ≤γ.
(34)
In order to convert these programs to the form (1), we
have to replace strict inequalities ≺0 by ⪯−ϵ for
a suitable threshold. The choice of ϵ > 0 poses no
problem in practice.
4.1.1
We consider the design of a static H∞controller for
a transport airplane from (Gangsaas et al., 1986). Our
algorithm computes a static controller K after solving
29 unconstrained minimization subproblems (14):
K∞=


0.69788
−0.64050
−0.83794
0.09769
1.57062


T
.
The associated H∞performance is 2.22 and repre-
sents 30% improvement over the result in (Leibfritz,
1998).
4.1.2
The state-space data of the VTOL helicopter are bor-
rowed from (Keel et al., 1988). They are obtained
by linearizing the helicopter rigid body dynamics at
given ﬂight conditions. This leads to a fourth-order
model. Both H∞and H2 static controllers are com-
puted with the spectral SDP method. The algorithm
converges after solving 29 tangent problems (14):
K∞=

0.50750
10.00000

.
The ﬁnal H∞performance is 1.59e-1, which is about
40% improvement over the performance obtained in
(Leibfritz, 1998).
K2 =

0.13105
5.95163

,
which gives a H2 performance of 9.54e-2 after solv-
ing 28 subproblems.
4.1.3
A model description for the chemical reactor can be
found in (Hung and MacFarlane, 1982). Both H∞
Problem
n
m
iter
cpu
index
TA
(H∞)
51
30
29
39
2.22
VH
(H∞)
13
12
29
0.3
1.59e-1
VH
(H2)
16
13
28
0.5
9.54e-2
CR
(H∞)
15
18
28
1.3
1.17
CR
(H2)
25
19
41
24.6
1.94
PA
(H∞)
19
13
30
13.5
2.19e-3
Table 1: Static output feedback synthesis. n and m
give size of (1), iter counts instances of (14), cpu in
seconds, index gives the corresponding H∞or H2
performance.
and H2 static controllers are computed with the spec-
tral SDP method, which requires solving respectively
28 and 41 subproblems. The resulting gains are:
K∞=

−10.17039
−31.54413
−26.01021
−100.00000

,
with H∞-performance ∥Tw,z(s)∥∞= 1.17.
K2 =

0.35714
−2.62418
2.58159
0.77642

,
with H2 performance ∥Tw,z(s)∥2 = 1.94.
4.1.4
In this section, we consider the design of a static con-
troller for a piezoelectric actuator system. A compre-
hensive presentation of this system can be found in
(Chen, 1998). Our algorithm computes a static H∞
controller after solving 30 instances of (14):
K∞= [0.09659
−1.45023
−100.00] .
The computed H∞-performance 2.19e-3 improves
signiﬁcantly over the value 0.785 given in (Leibfritz,
1998).
4.2
4.2.1
In many applications it is of importance to design
sparse controllers with a small number of nonzero en-
tries. This is for instance the case when it is manda-
tory to limit the number of arithmetic operations in
69
Non Linear Spectral SDP Method for BMI-Constrained Problems
Transport Airplane (TA)
VTOL Helicopter (VH)
Chemical Reactor (CR)
Sparse Linear Constant Output-Feedback
Design
Piezoelectric Actuator (PA)
Miscellaneous Examples

the control law, or when reducing the number of sen-
sor/actuator devices is critical. In such a case one may
attempt to synthesize a controller with an imposed
sparsity structure. A more ﬂexible idea is to let the
problem ﬁnd its own sparsity structure by using a ℓ1-
norm cost function. We solve the following (BMI)
problem:
min
1≤i≤n
1≤j≤n
, |Kij|,
s. t.
P ⪰ϵI
(A + B K C) T P + P(A + B K C)
⪯−2 αP −ϵI
where ϵ is the usual threshold to adapt strict inequali-
ties to the form (1) or (8). This corresponds to design-
ing a sparse linear constant output feedback control
u = Ky for the system ˙x = Ax + Bu, y = Cx with
an imposed decay rate of at least α in the closed-loop
system.
Minimizing the ℓ1-norm of the feedback gain is a
good heuristic for obtaining sparse feedback gain ma-
trices. This may be explained by the fact that the func-
tion φ(t) = |t| is the natural continuous interpolant
of the counting function c(t) = ⌊t⌋. Minimizing the
function 
ij ⌊Kij⌋or even counting the nonzero en-
tries Kij in K is what we would really like to do, but
this is a discrete optimization problem subject to ma-
trix inequality constraints.
There are many more applications to this heuristic.
Finding sparse feedback gain matrices is also a good
way of solving the actuator/sensor placement or con-
troller topology design problems. In our example the
method works nicely and a sparsity pattern is appar-
ent. If small but nonzero values occur, one may set
these values to zero if below a certain threshold, de-
rive a sparsity pattern, and attempt a structured design
with that pattern imposed. This leads to another class
of BMI problems.
In our example, the system is initially unstable with
rate of α0 = −0.2832. This value is obtained by com-
puting the smallest negative real part of the eigenval-
ues of A (data available from (Hassibi et al., 1999)).
In a ﬁrst test similar to the one in (Hassibi et al.,
1999), we seek a sparse K so that the decay rate of the
closed-loop system is not less than 0.35. We obtain
the following gain matrix:
K∞=


0.2278
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.3269
0.0000
0.0000

,
with only two non-zeros elements.
The path-
following method presented in (Hassibi et al., 1999)
gives 3 non-zeros elements.
The spectral method
gives once again a signiﬁcant improvement, while
maintaining the closed-loop stability.
If now in a second test a higher decay rate (α ≥
0.5) (and so a better damped closed-loop system), is
required, our method computes
K∞=


0.1072
0.0000
0.0000
0.0000
−0.0224
0.0000
0.0000
0.0000
0.3547
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0186
0.1502
0.0000
0.0000

,
with 5 non-zeros entries. As expected, the sparsity
decreases when α increases.
4.2.2
One attempts here to stabilize three different lin-
ear systems using a common linear constant state-
feedback law with limits on the feedback gains.
Speciﬁcally, suppose that:
˙x = Ak x + Bk u, u = K x , k = 1, 2, 3.
The goal is to compute K such that |Kij| ≤Kij,max
and the three closed-loop systems:
˙x = (Ak + Bk K ) x , k = 1, 2, 3 ,
are stable. Under these constraints the worst decay-
rate of the closed-loop systems is maximized.
Proposition 4.3 The feedback gain K stabilizes the
above systems simultaneously if and only if there exist
Pk ≻0, αk > 0, k = 1, 2, 3 such that
(Ak + BkK)T Pk + Pk(Ak + BkK) ≺−2αkPk,
k = 1, 2, 3.
Introducing our usual threshold parameter ϵ > 0,
we have to check whether the value of the following
BMI program is positive:
maximize
mink=1,2,3αk
subject to
|Kij| ≤Kij,max ,
(Ak + BkK)T Pk + Pk(Ak + BkK)
⪯−2 αkPk −ϵI
Pk ⪰ϵI, k = 1, 2, 3.
By looking in (Hassibi et al., 1999) and computing
the corresponding eigenvalues, the reader will notice
that all three systems are unstable. We chose, as pro-
posed by Hassibi, How and Boyd, Kij,max = 50. We
obtained a solution after 19 unconstrained minimiza-
tion subproblems, in 1.8 seconds. This experiment
gave the best improvement among our present tests.
The worst decay-rate was increased to α = 6.55, an
improvement of more than 500% over the value 1.05
obtained in (Hassibi et al., 1999). The corresponding
gain matrix is the following:
K∞=

−17.1926
−29.8319
−50
50
18.7823
−5.3255

.
70
J.-B. Thevenet et al.
Simultaneous State-Feedback Stabilization
with Limits on Feedback Gains
¦

4.2.3
H2/H∞
Mixed H2/H∞-performance indicies represent one of
those prominent cases where the projection Lemma
fails and direct BMI-techniques are required. Here we
consider the case where a static state-feedback con-
troller u = Kx for the open loop system
˙x = Ax + B1w + Bu
z1 = C1x + D1u
z2 = C2x + D2u
is sought for. The purpose is to ﬁnd K such that the
H2 norm w →z2 is minimized, while the H∞-norm
w →z1 is ﬁxed below a performance level γ. After
introducing our usual threshold ϵ > 0, the following
matrix inequality optimization problem arises:
minimize
η2
subject to
(A + B K) T P1 + P1(A + B K)
+ (C1 + D1 K) T (C1 + D1 K)
∗
B1
T P1
−γ 2 I
⪯−ϵI
(A + B K) T P2 + P2(A + B K)
∗
BT
1 P2
−I
⪯−ϵI
P2
∗
C2 + D2 K
Z
⪰ϵI,
Tr (Z) ≤η2 ,
P1 ⪰ϵI ,
P2 ⪰ϵI.
The ﬁrst block contains quadratic terms, which may
be converted to BMI-from using a Schur complement.
With γ = 2, the algorithm needs 21 instances of (14)
to compute the compensator:
K2,∞= [1.9313
0.3791
−0.2038] ,
with corresponding H2-norm 0.7489. While the au-
thors mention a performance of 0.3286, the compen-
sator provided in (Hassibi et al., 1999) gives to us a
H2-norm of 0.8933. In this case the improvement
over the result in (Hassibi et al., 1999) is negligible,
which we interpret in the sense that this result was al-
ready close to the global optimum. (Nota bene, one
cannot have any guarantee as to the truth of this state-
ment. Indeed, in this example we found that many
other local minima could be computed).
5
CONCLUSION
A spectral penalty augmented Lagrangian method for
matrix inequality constrained nonlinear optimization
programs was presented and applied to a number of
small to medium-size test problems in automatic con-
trol.
Problem
n
m
iter
cpu
Sparse design 1
56
51
29
2.9
Sparse design 2
56
51
19
7.3
Simult. stab.
28
34
19
1.8
H2/H∞
17
27
21
0.8
Table 2: Miscellaneaous examples.
The algorithm performs robustly if parameters are
carefully tuned. This refers to the choice of the initial
penalty value, p, the control of the condition number
of the tangent problem Hessian ∇2L(x, V, p) in (14),
and to the stopping tests (complementarity, stationar-
ity), where we followed the lines of (Henrion et al.,
2003). For the updates p →p+ and V →V + we
found that it is vital to avoid drastic changes, since the
new subproblem (14) may be much more difﬁcult to
solve. This is particularly so for the nonconvex BMI
case.
We remind the reader that similar to our previous
approaches, the proposed algorithm is a local opti-
mization method, which gives no certiﬁcate as to ﬁnd-
ing the global optimal solution of the control prob-
lem. If fact, such a method may in principle even
fail completely by converging to a local minimum of
constraint violation. For all that, our general expe-
rience, conﬁrmed in the present testing, is that this
type of failure rarely occurs. We consider the local
approach largely superior for instance to a very typi-
cal class of methods in automatic control, where hard
problems are solved by a tower of LMI problems with
growing size, N, where a solution is guaranteed as
N →∞. Such a situation is often useless, since the
size of the LMI problem needed to solve the under-
lying hard problem is beyond reach, and since a prior
estimate is not available or too pessimistic. The major
advantage of local methods is that the subproblems,
on whose succession the problem rests, all have the
same dimension.
We ﬁnally point out that the local convergence of
the algorithm will be proved in a forthcoming article.
REFERENCES
Anderson, B. and Vongpanitlerd, S. (1973). Network analy-
sis and synthesis: a modern systems theory approach.
Prentice-Hall.
Apkarian, P., Noll, D., Thevenet, J. B., and Tuan, H. D.
(2004). A Spectral Quadratic-SDP Method with Ap-
plications to Fixed-Order H2 and H∞Synthesis. In
Asian Control Conference, to be published in Euro-
pean Journal of Control.
Apkarian, P., Noll, D., and Tuan, H. D. (2002).
Fixed-
order H∞control design via an augmented La-
grangian method .
Rapport Interne 02-13, MIP,
71
Non Linear Spectral SDP Method for BMI-Constrained Problems
Controller Design
]
]
]
]

UMR 5640, Maths. Dept. - Paul Sabatier University .
http://mip.ups-tlse.fr/publi/publi.html.
Apkarian, P., Noll, D., and Tuan, H. D. (2003). Fixed-order
H∞control design via an augmented Lagrangian
method .
Int. J. Robust and Nonlinear Control,
13(12):1137–1148.
Ben-Tal, A. and Zibulevsky, M. (1997).
Penalty/barrier
multiplier methods for convex programming prob-
lems. SIAM J. on Optimization, 7:347–366.
Bertsekas, D. P. (1982.). Constrained optimization and La-
grange multiplier methods. Academic Press, London.
Chen, B. M. (1998). H∞Control and Its Applications, vol-
ume 235 of Lectures Notes in Control and Informa-
tion Sciences. Springer Verlag, New York, Heidelberg,
Berlin.
Conn, A. R., Gould, N., and Toint, P. L. (1991). A globally
convergent augmented Lagrangian algorithm for opti-
mization with general constraints and simple bounds.
SIAM J. Numer. Anal., 28(2):545 – 572.
Conn, A. R., Gould, N. I. M., Sartenaer, A., and Toint, P. L.
(1993a). Global Convergence of two Augmented La-
grangian Algorithms for Optimization with a Com-
bination of General Equality and Linear Constraints.
Technical Report TR/PA/93/26, CERFACS, Toulouse,
France.
Conn, A. R., Gould, N. I. M., Sartenaer, A., and Toint, P. L.
(1993b). Local convergence properties of two aug-
mented Lagrangian algorithms for optimization with a
combination of general equality and linear constraints.
Technical Report TR/PA/93/27, CERFACS, Toulouse,
France.
Conn, A. R., Gould, N. I. M., Sartenaer, A., and Toint, P. L.
(1996). Convergence properties of an augmented La-
grangian algorithm for optimization with a combina-
tion of general equality and linear constraints. SIAM
J. on Optimization, 6(3):674 – 703.
Fares, B., Apkarian, P., and Noll, D. (2000). An Augmented
Lagrangian Method for a Class of LMI-Constrained
Problems in Robust Control Theory. In Proc. Amer-
ican Control Conf., pages 3702–3705, Chicago, Illi-
nois.
Fares, B., Apkarian, P., and Noll, D. (2001). An Augmented
Lagrangian Method for a Class of LMI-Constrained
Problems in Robust Control Theory. Int. J. Control,
74(4):348–360.
Fares, B., Noll, D., and Apkarian, P. (2002). Robust Control
via Sequential Semideﬁnite Programming. SIAM J. on
Control and Optimization, 40(6):1791–1820.
Gangsaas, D., Bruce, K., Blight, J., and Ly, U.-L. (1986).
Application of modern synthesis to aircraft control:
Three case studies. IEEE Trans. Aut. Control, AC-
31(11):995–1014.
Hassibi, A., How, J., and Boyd, S. (1999). A path-following
method for solving bmi problems in control. In Proc.
American Control Conf., pages 1385–1389.
Henrion, D., M.Kocvara, and Stingl, M. (2003). Solving
simultaneous stabilization BMI problems with PEN-
NON. In IFIP Conference on System Modeling and
Optimization, volume 7, Sophia Antipolis, France.
Hestenes, M. R. (1969). Multiplier and gradient method. J.
Optim. Theory Appl., 4:303 – 320.
Hung, Y. S. and MacFarlane, A. G. J. (1982). Multivari-
able feedback: A classical approach. Lectures Notes
in Control and Information Sciences. Springer Verlag,
New York, Heidelberg, Berlin.
Keel, L. H., Bhattacharyya, S. P., and Howze, J. W. (1988).
Robust control with structured perturbations.
IEEE
Trans. Aut. Control, 36:68–77.
Kocvara, M. and Stingl, M. (2003). A Code for Convex
Nonlinear and Semideﬁnite Programming. Optimiza-
tion Methods and Software, 18(3):317–333.
Leibfritz, F. (1998).
Computational design of stabiliz-
ing static output feedback controller. Rapports 1 et
2 Mathematik/Informatik, Forschungsbericht 99-02,
Universitt Trier.
Lewis, A. (1996). Derivatives of spectral functions. Math-
ematics of Operations Research, 21:576–588.
Lewis, A. (2001). Twice differentiable spectral functions.
SIAM J. on Matrix Analysis and Applications, 23:368–
386.
Lewis, A. and S.Sendov, H. (2002).
Quadratic expan-
sions of spectral functions. Linear Algebra and Appl.,
340:97–121.
Lin, C. and More, J. (1998). Newton’s method for large
bound–constrained optimization problems.
Techni-
cal Report ANL/MCS-P724–0898, Mathematics and
Computer Sciences Division, Argonne National Lab-
oratory.
Mosheyev, L. and Zibulevsky, M. (2000). Penalty/barrier
multiplier algorithm for semideﬁnite programming.
Optimization Methods and Software, 13(4):235–261.
Noll, D., Torki, M., and Apkarian, P. (2002).
Partially
Augmented Lagrangian Method for Matrix Inequality
Constraints. submitted. Rapport Interne , MIP, UMR
5640, Maths. Dept. - Paul Sabatier University.
Powell, M. J. D. (1969). A method for nonlinear constraints
in minimization problem. In Fletcher, R., editor, Op-
timization. Academic Press, London, New York.
Schnabel, R. B. and Eskow, E. (1999). A revised modiﬁed
cholesky factorization algorithm. SIAM J. on Opti-
mization, 9(4):1135–1148.
Shapiro, A. (2002). On differentiability of symmetric ma-
trix valued functions. School of Industrial and Sys-
tems Engineering, Georgia Institute of Technology.
Preprint.
Zibulevsky, M. (1996). Penalty/Barrier Multiplier Methods
for Large-Scale Nonlinear and Semideﬁnite Program-
ming. Ph. D. Thesis, Technion Isral Institute of Tech-
nology.
72
J.-B. Thevenet et al.

A STOCHASTIC OFF LINE PLANNER OF OPTIMAL DYNAMIC 
MOTIONS FOR ROBOTIC MANIPULATORS 
Taha Chettibi, Moussa Haddad, Samir Rebai 
Mechanical Laboratory of Structures, EMP, B.E.B., BP17, 16111, Algiers, Algeria 
Email: tahachettibi@yahoo.fr, moussa.haddad@caramail.com, srebai@yahoo.fr  
Abd Elfath Hentout 
Laboratory of applied mathematics, EMP, B.E.B., BP17, 16111, Algiers, Algeria 
Email: Hentout@hotmail.com
Keywords: 
Robotic manipulator, Motion planning, Stochastic optimization, Obstacles avoidance. 
Abstract:
We propose a general and simple method that handles free (or point-to-point) motion planning problem for 
redundant and non-redundant serial robots.  The problem consists of linking two points in the operational 
space, under constraints on joint torques, jerks, accelerations, velocities and positions while minimizing a 
cost function involving significant physical parameters such as transfer time and joint torque quadratic 
average.  The basic idea is to dissociate the search of optimal transfer time T from that of optimal motion 
parameters.  Inherent constraints are then easily translated to bounds on the value of T.  Furthermore, a 
stochastic optimization method is used which not only may find a better approximation of the global 
optimal motion than is usually obtained via traditional techniques but that also handles more complicated 
problems such as those involving discontinuous friction efforts and obstacle avoidance. 
1 INTRODUCTION 
Motion planning constitutes a primordial phase in 
the process of robotic system exploitation.  It is a 
challenging task because the robot behaviour is 
governed by highly non linear models and is 
subjected to numerous geometric, kinematic and 
dynamic constraints (Latombe, 1991) (Angeles, 
1997) (Chettibi, 2001).  Two categories of motions 
can be distinguished (Angeles, 1997) (Chettibi, 
2000).  The first covers motions along prescribed 
geometric path and correspond, for example, to 
continuous welding or glowing operations (Bobrow, 
1985) (Kang, 1986) (Pfeiffer, 1987) (Chettibi, 
2001b).  The second, which is the focus of this 
paper, concerns point-to-point (or free) motions 
involved, for example, in discrete welding or pick-
and-place operations (Bessonnet, 1992) (Mitsi, 
1995) (Lazrak, 1996) (Danes, 1998) (Chettibi, 
2001a).   In general, many different ways are 
possible to perform the same task.  This freedom of 
choice can be exploited judiciously to optimize a 
given performance criterion.  Hence, motion 
generation becomes an optimization problem.  It is 
here referred to as the optimal free motion planning 
problem (OFMPP). 
In the specialized literature, various resolutions 
methods have been proposed to handle the OFMPP.  
They can be grouped in two main families; namely: 
direct and indirect methods (Hull, 1997) (Betts, 
1998).  The indirect methods are, in general, 
applications of optimal control theory and in 
particular Pontryagin Maximum Principle (PMP) 
(Pontryagin, 1965).  Optimality conditions are stated 
under the form of a boundary value problem that is 
generaly too difficult to solve (Bessonnet, 1992) 
(Lazrak, 1996) (Chettibi, 2000).  Several techniques, 
such as the phase plane method (Bobrow, 1985) 
(Kang, 1986) (Jaques, 1986) (Pfeiffer, 1987), exploit 
the structure only of the optimal solution given by 
PMP and get numerical solutions via other means.  
In general, such techniques are applied to limited 
cases and have several drawbacks resumed below: 
 They require the solution of a N.L multi-point 
shooting problem (David, 1997) (John, 1998 ), 
 They require analytical computing of gradients 
(Lazrak, 1996) (Bessonnet, 1992), 
73
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 73–80. 

 The region of convergence may be small 
(Chettibi, 2001) (Lazrak, 1996), 
 Path inequality are difficult to handle (Danes, 
1998), 
 They introduce new variables known as co-state 
variables that are, in general, difficult to estimate 
(Lazrak, 1996) (Bessonnet, 1992) (Danes, 1998) 
(Pontryagin, 1965). 
 In minimum time transfer problems, they lead to 
discontinuous controls (bang-bang) that may 
create many practical problems (Ola, 1994) 
(Chettibi, 2001a).  In fact, the controller must 
work in saturation for long periods.  The optimal 
control leaves no control authority to compensate 
for any tracking error caused by either unmodeled 
dynamics or delays introduced by the on-line 
feedback controller 
To overcome these difficulties, direct methods have 
been proposed.  They are based on discretisation of 
dynamic variables (states, controls).  They seek to 
solve directly a parameter optimization problem.  
Then, N.L. programming (Tan, 1988) (Martin, 1997) 
(Martin, 1999) (Chettibi, 2001a) or stochastic 
optimization techniques (Chettibi, 2002b) are 
applied to compute optimal values of parameters.  
Other ways of discretisation can be found in 
(Richard,  1993)  (Macfarlane,  2001).  These 
techniques 
suffer, 
however, 
from 
numerical 
explosion when treating high dimension problems. 
Although they have been used successfully to solve 
a large variety of problems, techniques based on 
N.L. programming (Fletcher, 1987) (David, 1997) 
(Danes, 1998) (John, 1998) (Chettibi, 2000) have 
two essential drawbacks: 
They are easily attracted by local minima ; 
They generally require information on gradiant and 
hessian that are difficult to get analytically.  In 
addition, continuity of second order must be 
ensured, while realistic physical models may 
include some discontinuous terms (frictions). 
In parallel to these methods, that take into 
account both kinematics and dynamics aspects of the 
problem, numerous pure geometric planners have 
been proposed to find solutions for the simplified 
problem that consists of finding only feasible 
geometric paths (Piano movers problem) (Latombe, 
1991) 
(Overmars, 
1992) 
(Barraquand, 
1992) 
(Kavraki, 1994) (Barraquand, 1996) (Kavraki, 1996) 
(Latombe, 1999) (Garber, 2002).  In spite of this 
simplification, the problem still remains quite 
complex with exponential computational time in the 
degree of freedom (d.o.f.).  Of course, any extension 
(presence of obstacles, for example) adds in 
computational complexity.  Even so, various 
practical planners have been proposed.  Reference 
(Latombe, 1991) gives an excellent overview of 
early methods (before 1991) such as: potential field, 
cell decomposition and roadmap methods, some of 
which have shown their limits.  For instance, a 
potential field based planner is quickly attracted by 
local minima (Khatib, 1986) (Latombe, 1991) 
(Barraquand, 1992). Cell decomposition methods 
often require difficult and quite expensive geometric 
computations and data structures tend to be very 
large (Latombe, 1991) (Overmars, 1992).  The key 
issue for roadmap methods is the construction of the 
roadmap.  Various techniques have been proposed 
that produce different sorts of roadmaps based on 
visibility and Voronoi graphs (Latombe, 1991).    
During the last decade, interest was given to 
stochastic techniques to solve various forms of 
optimal motion planning problems.  In particular, 
powerful algorithms were proposed to solve the 
basic geometric problem.  Probabilistic roadmaps 
(PRM) or Probabilistic Path Planners (PPP) were 
introduced in (Overmars, 1992) (Barraquand, 1996) 
(Kavraki, 1994) (Kavraki, 1996) and applied 
successfully to complex situations.  They are 
generally executed in two steps: first a roadmap is 
constructed, according to a stochastic process, then 
the motion planning query is treated.  Due to the 
power of this kind of schemes, many perspectives 
are expected as shown in (Latombe, 1999).  
However, there are few attempts to apply them to 
solve the complete OFMPP.  References (LaValle, 
1998) (LaValle, 1999) propose the method of 
Rapidly exploring Random Trees (RRTs) as an 
extention of PPP to optimize feasible trajectories for 
NL systems.  Dynamic model and inherent 
constraints are taken into account.   
In (Chettibi, 2002a), we introduced a different 
scheme using a sequential stochastic technique to 
solve the OFMPP.  We present here this simple and 
versatile method and how it can be used to handle 
complex situations involving both friction efforts 
and obstacle avoidance. 
2 PROBLEM STATEMENT  
Let us consider a serial redundant or non-redundant 
manipulator with n d.o.f.. Motion equations can be 
derived using Lagrange's formalism or Newton-
Euler formalism (Dombre, 1988) (Angeles, 1997): 
 


 
W
 


q
G
q
q
Q
q
q
M


,
     (1a),
q,
 and 
are respectively joints position, velocity, 
acceleration vectors.
M(q) is the inertia matrix. 
Q(
) is the vector of centrifugal and Coriolis
forces in which joints velocities appear under a 
q
q
q
q ,
74
T. Chettibi et al.

quadratic form.   G(q) is the vector of potential 
forces and W ҏis the vector of actuator efforts. 
In order to make the dynamic model more realistic, 
we may introduce, for the ith joint, friction efforts as 
follows: 
)
(
))
(
(
)
(
))
(
(
))
(
),
(
(
)
(
))
(
(
1
t
t
q
sign
F
t
q
F
t
q
G
t
q
t
q
Q
t
q
t
q
M
i
s
i
v
i
i
i
n
j
j
ij
W
 




¦
 




(1b),
V
iF and
are, respectively, sec and viscous 
friction coefficients of the ith joint.  
s
iF
The robot is required to move freely from an initial 
state Pi to a final state Pf, both of which are specified 
in the operational space.  In addition to solving for 
W(t) and transfer time T, we must find the trajectory 
defined by q(t) such as the initial and the final state 
are matched, constraints are respected and a cost 
function is minimized.   
The cost function adopted here is a balance 
between transfer time T and the quadratic average of 
actuator efforts: 
³¦
 
¸¸
¹
·
¨¨
©
§


 
T
n
i
max
i
i
obj
dt
)
t(
T
F
0
1
2
2
1
W
W
P
P
 
(2). 
P is a weighting coefficient chosen from [0,1] and 
according to the relative importance we would like 
to give to the minimization of T or to the quadratic 
average 
of 
actuator 
efforts. 
The 
case
 
P corresponds to the optimal time free motion 
planning problem. 
Constraints that must be satisfied during the 
entire transfer (0 d t d T) are summarized bellow:    
 for  i = 1, …, n  we have bounds on: 
-
Joint torques: 
 
max
i
i t
W
W
d
              
 
(3a);
-
Joint jerks : 
 
 
max
i
i
q
t
q


d
 
 
      
(3b);
-
Joint accelerations: 
 
max
i
i
q
t
q


d
              
      
(3c);
-
Joint velocities:   
 
max
i
i
q
t
q


d
          
            (3d);
-
Joint positions:  
 
max
i
i
q
t
q
d
                                   (3e).
Of course, non-symmetrical bounds on the above 
physical quantities can also be handled without any 
new difficulty.   
Relations (3a, b, c, d and e) traduce the fact that 
not all motions are tolerable and that power 
resources are limited and must be used rationally in 
order to control correctly the robot dynamic 
behavior.  Also, since joint position tracking errors 
increase with jerk, constraints (3b) are introduced to 
limit excessive wear and hence to extend the robot 
life-span 
(Latombe, 
1991) 
(Piazzi, 
1998) 
(Macfarlane, 2001).   
In the case where obstacles are present in the 
robot workspace, motion must be planned in such a 
way collision is avoided between links and 
obstacles.  Therefore, the following constraint has to 
be satisfied : 
 
C(q)=False 
 
          (3f).
The Boolean function C indicates whether or not the 
robot at configuration q is in collision with an 
obstacle.  This function uses a distance function 
D(q) that supplies for any robotic configuration the 
minimal distance to obstacles.   
3 REFORMULATION OF THE 
PROBLEM 
The normalization of the time scale, initially used to 
make the problem with fixed final time, is exploited 
to reformulate the problem and to make it propitious 
for a stochastic optimization strategy. Details are 
shown bellow.  
3.1 Scaling 
We introduce a normalized time scale as follows: 
T.x
t  
     with     
 
       (4). 
>
@1,0

x
Hereafter, we will use the prime symbol to indicate 
derivations with respect to x : 
 
 
,
"
,
'
2
2
dx
x
q
d
q
dx
x
dq
q
 
 
 
3
3
'"
dx
x
q
d
q  
(5). 
Relations (1a) and (1b) can be written as follows:  
(1a)          
 
i
i
i
G
H
T
x

 
2
1
\
                   (6a)
(1b) 
)
(
1
1
2
q
sign
F
q
F
T
G
H
T
s
i
i
v
i
i
i
i
c

c


 
\
    (6b)
where:       
 
 
max
i
i
i
x
x
W
W
\
 
,
max
i
ij
ij
M
M
W
 
,
max
i
i
i
Q
Q
W
 
,
max
i
i
i
G
G
W
 
,
=
i
H
i
n
j
j
ij
Q
q
M

¦
 1
"
           (7)
and:
max
i
v
i
v
i
F
F
W
 
,
max
i
s
i
s
i
F
F
W
 
                    (8)
75
A Stochastic off Line Planner of Optimal Dynamic Motions 

With the previous notations, the cost function (2) 
becomes without friction efforts:  
¸
¹
·
¨
©
§


 
4
4
2
2
0
T
S
T
S
S
T
Fobj
     
       (9), 
Where S0, S2 and S4 are given by: 


³¦
³¦
³¦
 
 
 

 

 


 
1
0
1
2
4
1
0
1
2
1
0
1
2
0
2
1
1
2
1
dx
H
S
dx
G
H
S
dx
G
S
n
i
i
n
i
i
i
n
i
i
P
P
P
P
(10). 
  It must be noted that S0, S2 and S4 are real 
coefficients that do depend on the joint evolution 
profile q(x) but that do not depend on T.  Also, S0
and
S4 are always positive.  Expression (9) 
represents a family of curves whose general shape, 
for any feasible motion, is shown in figure 1a.  The 
minimum of each of these curves is reached when T
takes on the value T = Tm  given by : 
2
/
1
0
4
0
2
2
2
2
12
¸¸
¸
¹
·
¨¨
¨
©
§


 
S
S
S
S
S
Tm
    
 (11). 
If friction efforts are taken into account, we 
introduce the following quantities: 
q
F
K
v
i
i
c
 
,
)
(q
sign
F
G
G
s
i
i
i
c

 
          (12) 
The expression of (2) becomes then : 
¸¸
¹
·
¨¨
©
§




 
4
4
3
3
2
2
1
0
T
S
T
S
T
S
T
S
S
T
Fobj
     (13)  
where: 


³ ¦
³ ¦
³ ¦
³ ¦
³ ¦
 
 
 
 
 

 

 


 

 


 
1
0
1
2
4
1
0
1
3
1
0
1
2
2
1
0
1
1
1
0
1
2
0
2
1
)
1
(
2
2
1
)
1
(
2
1
O
P
O
P
O
P
O
P
O
P
P
d
H
S
d
K
H
S
d
G
H
K
S
d
G
K
S
d
G
S
n
i
i
n
i
i
i
n
i
i
i
i
n
i
i
i
n
i
i
   (14) 
For a given profile q(x), (13) represents a family of 
curves whose general shape is shown in figure 1b,
but now the asymptotic line intersects the time axis 
at
.  Furthermore, Tm has to be 
computed numerically since (11) is no longer 
applicable. 
0
1 /S
S
 -
 
T  
Constraints imposed on the robot motion will be 
handled sequentially within the iterative process of 
minimization described in the next section.  Already, 
we can group constraints into several categories 
according to the stage of the iterative process at 
which they will be handled. 
In the first category, we have constraints that will 
not add any restriction on the value of T.  For 
example, joint position constraints (3e) become:
 
>
@
n
i
x
q
x
q
i
i
,
,1
1,0
max

 


d
     (15), 
and those due to obstacles presence (3f) become :
  C(q(x))=False   
>
@1,0

x
 
         (16) 
In both cases, only the joint position profiles q(x) are 
determinant. 
In the second category, we have constraints that can 
be transformed into explicit lower bounds on T.  For 
example joint velocity constraints lead to:    
 
 
n
i
q
x
q
T
q
x
q
T
i
i
i
i
,...,
1
'
'
1
max
max
 
t

d


so:     
,
v
T
T t
>
@
 
»
»
¼
º
«
«
¬
ª
 
 
max
1,
0
,
,1
'
max
max
i
i
n
i
v
q
x
q
T


        (17). 
Joint 
acceleration 
and 
jerk 
constraints 
are 
transformed in the same way to give: 
Figure 1: General shape of the cost function; (a) without 
Fob
Fobj
j
T
Tm
Tm
  -S4/S0
Fig. 1b
T
Fig. 1a
76
3.2 Cost Function 
3.3 Effects of Constraints 
3.3.a Constraints of the First Category 
friction efforts , (b) with friction efforts.
T. Chettibi et al.
3.3.b Constraints of Second Category 

For accelerations:                     
TtTa  ,    
>
@
 
»
»
¼
º
«
«
¬
ª
¸¸
¹
·
¨¨
©
§
 
 
2
/
1
max
1,0
,
,1
"
max
max
i
i
n
i
a
q
x
q
T
         (18), 
Figure 3: New exploration region defined by a new 
lower value of F
T2
T1
T
Fobj
Last  
Fbest
Tm


and for jerks: 
TtTJ 
,  
>
@
 
»
»
¼
º
«
«
¬
ª
¸¸
¹
·
¨¨
©
§
 
 
3
/
1
max
1,0
,
,1
"'
max
max
i
i
n
i
J
q
x
q
T
 
  (19). 


Thus, (17), (18) and (19) define three lower bounds 
on transfer period.  In consequence; T must satisfy 
the following condition:  
Tt T* ,          T*=max(Tv, Ta, TJ)             
(20),                                           
This type of constraints defines a forbidden region 
as shown in figure 2.  Note that two cases are 
possible.  
                           
In the third category, we have constraints that can be 
transformed into explicit bilateral bounds on T.  For 
example those imposed on the value of joint torques 
(3a) define, in general, bracketing bounds on T,
namely: TL and TR.  In consequence, 
T[TL, TR] 
 
    (21). 
A fourth category might be included and would 
concern any other constraint that does add 
restrictions on T  but that cannot be easily translated 
into simple bounds on T.
4 STRATEGY OF RESOLUTION 
The iterative process of minimization proposed here 
includes the following steps: 
Step 1: Generate a random (or guessed) temporal 
evolution shape qi(x) for each of the joint variables, 
taking into account any constraints of the first 
category (15), (16) as well as any conditions 
imposed on the initial and the final state.  
Step 2:  Get the S coefficients from (10) or (14) and 
Tm from (11) or by numerical means.  If F(Tm) is 
greater than Fbest obtained so far, then there is no 
need to continue and hence, return to Step 1. 
Otherwise, a first bracketing interval [T1, T2] is 
deduced (Fig. 3) in which F is decreasing from T1 to 
Tm and increasing from Tm to T2.
The remaining steps will simply consist of changing 
T1, Tm or T2 while keeping this bracketing.   
Step 3: Get Ta, Tv, Tj from (17, 18, 19) and T* from 
(20).  If T* > T2 then return to Step 1 else modify T1
and/or Tm according to Fig. 2.  That is: in case (a) T1
m T*  while in (b) T1 m T* and Tm m T*.  
Step 4:  Get [TL, TR] from (21).  If TL > T2 or TR < T1
then return to Step 1.  Otherwise, we have a 
new improved Fbest :
If  Tm  [TL, TR]  then
      Fbest m F(Tm)
Else if  Tm < TL  then
      Fbest m F(TL)
Else
      Fbest m F(TR)
End if 
The above steps can be imbedded in a stochastic 
optimization strategy to determine better profiles 
qi(x), i = 1,… n, leading to lower values of the 
objective function. 
One way to get a guessed temporal evolution shape 
qi(x) for the joint variables, at any stage of 
optimization process, is to use randomly generated 
clamped 
cubic 
spline 
functions 
with 
nodes 
distributed for x  [0,1] (Fig. 4).   
Tm
T*
T
Fobj
Forbidden 
region
Figure 2: Bounds on transfer time value due to   
Case a: T* <Tm
Tm T*
T
Fobj
Case b: T* >Tm
Forbidden 
region
77
A Stochastic off Line Planner of Optimal Dynamic Motions 
constraints of second category.
best.
3.3.c Constraints of Third Category 

qi(x)
x
1
0
Free Nodes uniformly 
distributed
Figure 4: Approximation of joint position temporal 
- i
max
max
q
qi
Admissible interval  
5 NUMERICAL RESULTS 
We consider here a redundant planar robot 
constituted of four links connected by revolute 
joints. The corresponding geometric and inertial 
characteristics are listed in Appendix A. It is asked 
to move among two static obstacles disposed in it’s 
work space at respectively (2, 1.5) and (-1.5, 1.5) 
with both unity radius. The robot begin at (S/4, -S/2, 
S/4, 0) and stops at  (S/2, 0, 0, 0). Boundary 
velocities are null. The numerical results are 
obtained with P for both cases:  with and 
without friction efforts. The corresponding optimal 
motions are depicted in Figures 5a, b, c, d, e and f. 
In fact, without introducing friction effort we get : 
Fobj = 2.7745(s)  and  Topt = 4.9693 (s).In the 
presence of friction efforts we get a different result: 
Fobj = 3.1119 (s)  and Topt = 5.3745 (s). Hence, to 
achieve the same task, we need more time and more 
effort in the presence of friction efforts.  
6 CONCLUSION 
In this paper we have presented a simple trajectory 
planner of point-to-point motions for robotic arms. 
The problem is highly non-linear due first to the 
complex robot dynamic model that must be verified 
during the entire transfer, then to the non-linearity of 
-30
-20
-10
0
10
20
30
40
0
2
4
Figure 5e: Evolution of joint torques without 
-3
-2
-1
0
1
2
3
0
1
2
3
4
5
Figure  5f: Evolution of joint positions without 
-3
-2
-1
0
1
2
0
2
4
1
q2
q3
q4
Figure  5d. Evolution of joint positions with friction 
3
q
-40
-30
-20
-10
0
10
20
30
0
2
4
W1
W3
W2
W4
Figure 5c: Evolution of joint torques with friction 
78
effect.
effect.
evolution.
Figure 5a: Aspect of motion without friction effect. 
Figure 5b: Aspect of motion with friction effect. 
friction effect. 
T. Chettibi et al.
friction effect. 

the cost function to be minimized and finally to 
numerous 
constraints 
to 
be 
simultaneously 
respected. The OFMPP is originally an optimal 
control one and has been transformed into a 
parametric optimization problem. The optimization 
parameters are time transfer T and the position of 
nodes defining the shape of joint variables. The 
research of T has been separated from that of the 
others parameters in order to make the computing 
process efficient and to handle constraints easily by 
transforming them into explicit bounds on T possible 
values. In fact, the various possible constraints have 
been regrouped in four families according to their 
possible effects on T values and then have been 
handled sequentially during each optimization step. 
Nodes, defining q(x) shape, are connected by cubic 
spline functions and their positions are perturbed 
inside a stochastic process until the objective 
function value is sufficiently reduced while all 
constraints are all satisfied. This ensured smoothness 
of resulted profiles.  The objective function has been 
written under a weighting form permitting to make 
balance between reducing T and magnitude of 
implied torques.  
Numerical examples, where a stochastic 
optimization process, implementing the proposed 
approach, has been used along with cubic spline 
approximations, 
and 
dealing 
with 
complex 
problems, such as those involving discontinuous 
friction efforts and obstacle avoidance, have been 
presented to show the efficiency of this technique. 
Others successful tests have been made in parallel 
for complex robotic architectures, like biped robots, 
will be presented in a future paper.   
We thank Prof. H. E. Lehtihet for his suggestions 
and helpful discussions.  
REFERENCES
Angeles J., 1997, Fundamentals of robotic mechanical 
systems. Theory, methods, and algorithms,” Springer 
Edition.  
Barraquand J., Langlois B., Latomb J. C., 1992, Numerical 
Potential Field Techniques for robot path planning, 
IEEE Tr. On Sys., Man, and Cyb., 22(2):224-241. 
Barraquand J., Kavraki L., Latombe J. C., Li T. Y., 
Motwani R., Raghavan P., 1996, A random Sampling 
Scheme for path planning, 7th Int. conf. on Rob. 
Research ISRR.
Bobrow J.E., Dubowsky S., Gibson J.S., 1985, Time-
Optimal Control of robotic manipulators along 
specified paths, The Int. Jour. of Rob. Res., 4 (3), pp. 
3-16.
Bessonnet G., 1992, Optimisation dynamique des 
mouvements point à point de robots manipulateurs,
Thèse d’état, Université de Poitiers, France. 
Betts J. T., 1998, Survey of numerical methods for 
trajectory optimization, J. Of Guidance, Cont. & Dyn.,
21(2), 193-207. 
Chen Y., Desrochers A., 1990, A proof of the structure of 
the minimum time control of robotic manipulators 
using Hamiltonian formulation, IEEE Trans. On Rob. 
Chettibi T., 2000, Contribution à l'exploitation optimale 
des bras manipulateurs, Magister thesis, EMP, 
Algiers, Algeria. 
Chettibi T., 2001a, Optimal motion planning of robotic 
manipulators, Maghrebine Conference of Electric 
Engineering, Constantine, Algeria. 
Chettibi T., Yousnadj A., 2001b, Optimal motion planning 
of robotic manipulators along specified geometric 
path, International Conference on productic, Algiers. 
Chettibi T., Lehtihet H. E., 2002a, A new approach for 
point to point optimal motion planning problems of 
robotic 
manipulators, 
6th 
Biennial 
Conf. 
on 
Engineering Syst. Design and Analysis (ASME ),
Turkey, APM10. 
Chettibi T., 2002b, Research of optimal free motions of 
manipulator 
robots 
by 
non-linear 
optimization, 
Séminaire international sur le génie Mécanique, Oran, 
Algeria. 
Danes F., 1998, Critères et contraintes pour la synthèse 
optimale des mouvements de robots manipulateurs. 
Application à l’évitement d’obstacles, Thèse d’état, 
Université de Poitiers. 
Dombre E. & Khalil W., 1988, Modélisation et commande 
des robots, First Edition, Hermes. 
Fletcher R., 1987, Practical methods of optimization,
Second Edition, Wiley Interscience Publication. 
Garber M., Lin. M.C., 2002, Constrained based motion 
planning for virtual prototyping, SM’02,  Germany. 
Glass K., Colbaugh R., Lim D., Seradji H., 1995, Real 
time collision avoidance for redundant manipulators, 
Hull D. G., 1997, Conversion of optimal control problems 
into parameter optimization problems, J. Of Guidance, 
Cont. & Dyn., 20(1), 57-62. 
Jaques J., Soltine E., Yang H. S., 1989, Improving the 
efficiency of time-optimal path following algorithms, 
IEEE Trans. on Rob. & Aut., 5 (1). 
Kang G. S., McKay D. N., 1986, Selection of near 
minimum 
time 
geometric 
paths 
for 
robotic 
manipulators, IEEE Trans. on Aut. & Contr., AC31(6), 
pp. 501-512. 
Kavraki 
L., 
Latombe 
J. 
C., 
1994, 
Randomized 
Preprocessing of Configuration Space for Fast Path 
Planning, Proc. Of IEEE Int. Conf. on Rob. & Aut., pp. 
2138-2139, San Diego.  
Kavraki L., Svesta P., Latombe J. C., Overmars M., 1996, 
Probabilistic Roadmaps for Path Planning in High 
Dimensional Configuration space, IEEE trans. Robot. 
Aut., 12:566-580.  
79
A Stochastic off Line Planner of Optimal Dynamic Motions 
& Aut. 6(3), pp. 388-393. 
IEEE Trans. on Rob. & Aut., 11(3), pp. 448-457. 
ACKNOWLEDGEMENTS 

Khatib O., 1986, Real-time Obstacle Avoidance for 
Manipulators and Mobile Robots, Int. Jour. of Rob. 
Research, vol. 5(1). 
Latombe J. C., 1991, Robot Motion Planning,  Kluwer 
Academic Publishers. 
Latombe J. C., 1999, Motion planning: A journey of, 
molecules, digital actors and other artifacts, Int. Jour. 
LaValle S. M., 1998, Rapidly exploring random trees: A 
new tool for path planning, TR98-11, Computer 
Science 
Dept., 
Iowa 
State 
University.
 
http://janowiec.cs.iastate.edu/papers/rrt.ps. 
LaValle S. M., Kuffner J. J., 1999, Randomized 
kinodynamic planning, Proc. IEEE Int. Conf. On Rob. 
Lazrak M., 1996, Nouvelle approche de commande 
optimale en temps final libre et construction 
d’algorithmes de commande de systèmes articulés,
Thèse d’état, Université de Poitiers. 
Macfarlane S., Croft E. A., 2001, Design of jerk bounded 
trajectories for on-line industrial robot applications, 
984.
Martin B. J., Bobrow J. E., 1997, Minimum effort motions 
for open chain manipulators with task dependent end-
effector constraints, Proc. IEEE Int. Conf. Rob. & Aut.
Martin B. J., Bobrow J. E., 1999, Minimum effort motions 
for open chain manipulators with task dependent end-
effector constraints, Int. Jour. Rob. of Research, 18(2), 
Mao Z. , Hsia T. C., 1997, Obstacle avoidance inverse 
kinematics solution of redundant robots by neural 
networks, Robotica, 15, 3-10.
Mayorga R. V., 1995, A framework for the path planning 
of robot manipulators, IASTED third Int. Conf. on 
Mitsi S., Bouzakis K. D., Mansour G., 1995, Optimization 
of robot links motion in inverse kinematics solution 
considering collision avoidance and joints limits, 
Ola D., 1994, Path-Constrained robot control with limited 
torques. Experimental evaluation, IEEE Trans. On 
Overmars M. H., 1992, A random Approach to motion 
planning, Technical report RUU-CS-92-32, Utrecht 
University. 
Piazzi A., Visioli A., 1998, Global minimum time 
trajectory planning of mechanical manipulators using 
internal analysis, Int. J. Cont., 71(4), 631-652. 
Pfeiffer F., Rainer J., 1987, A concept for manipulator 
trajectory planning, IEEE J. of  Rob. & Aut., Ra-3 (3): 
115-123.
Powell M. J., 1984, Algorithm for non-linear constraints 
that 
use 
Lagrangian 
functions, 
Mathematical 
programming, 14, 224-248. 
Pontryagin 
L., 
Boltianski 
V., 
Gamkrelidze 
R., 
Michtchenko E., 1965, Théorie mathématique des 
processus optimaux, Edition Mir. 
Rana A.S.,  Zalazala A. M. S., 1996, Near time optimal 
collision free motion planning of robotic manipulators 
632.
Richard M. J., Dufourn F., Tarasiewicz S., 1993, 
Commande 
des 
robots 
manipulateurs 
par 
la 
programmation dynamique, Mech. Mach. Theory,
28(3), 301-316.  
Rebai S., Bouabdallah A., Chettibi T., 2002, Recherche 
stochastique des mouvements libres optimaux des bras 
manipulateurs, Premier congrès international de génie 
mécanique, Constantine, Algérie. 
Tan H. H., Potts R. B., 1988, Minimum time trajectory 
planner for the discrete dynamic robot model with 
dynamic constraints, IEEE Jour. Of Rob. & Aut. 4(2), 
174-185.
Appendix A: Characteristics of the 4R robot 
Joint N° 
1
2
3
4
D (rad) 
0
0
0
0
d(m) 
0
1
1
1
r(m) 
0
0
0
0
a(m) 
0
0
0
0
M(kg)
5
4
3
2
Izz(kg.m2)
1
0.85
0
0
W(N.m) 
25
20
15
5
Fs (N.m) 
0.7
0.2
0.5
0.2
Fv (N.m.s) 
1
0.2
0.5
0.2
80
Of  Rob. Research, 18(11), pp. 1119-1128. 
& Aut., pp. 473-479. 
Proceeding of IEEE Int. Conf. on rob. &  Aut. pp. 979-
Albuquerque, New Mexico, pp. 2044-2049. 
pp. 213-224.
Rob. and Manufacturing, pp. 61-66. 
Mach. & Mec. Theory,30 (5), pp. 653-663. 
using an evolutionary algorithm, Robotica, 14, pp. 621-
T. Chettibi et al.
Rob. & Aut., 10(5), pp. 658-668.   

FUZZY MODEL BASED CONTROL APPLIED TO IMAGE-BASED
VISUAL SERVOING
Paulo J. Sequeira Gonc¸alves
Escola Superior de Tecnologia de Castelo Branco
Av. Empres´ario, 6000-767 Castelo Branco, Portugal
Email: pgoncalves@est.ipcb.pt
Technical University of Lisbon, IDMEC / IST
Av. Rovisco Pais, 1049-001 Lisboa, Portugal
{mendonca,j.sousa,jcpinto}@dem.ist.utl.pt
Keywords:
visual servoing, robotic manipulators, inverse fuzzy control, fuzzy compensation, fuzzy modeling.
Abstract:
A new approach to eye-in-hand image-based visual servoing based on fuzzy modeling and control is proposed
in this paper. Fuzzy modeling is applied to obtain an inverse model of the mapping between image features
velocities and joints velocities, avoiding the necessity of inverting the Jacobian. An inverse model is identiﬁed
for each trajectory using measurements data of a robotic manipulator, and it is directly used as a controller.
As the inversion is not exact, steady-state errors must be compensated. This paper proposes the use of a
fuzzy compensator to deal with this problem. The control scheme contains an inverse fuzzy model and a
fuzzy compensator, which are applied to a robotic manipulator performing visual servoing, for a given proﬁle
of image features velocities. The obtained results show the effectiveness of the proposed control scheme:
the fuzzy controller can follow a point-to-point pre-deﬁned trajectory faster (or smoother) than the classic
approach.
1
INTRODUCTION
In eye-in-hand image-based visual servoing, the Jaco-
bian plays a decisive role in the convergence of the
control, due to its analytical model dependency on
the selected image features. Moreover, the Jacobian
must be inverted on-line, at each iteration of the con-
trol scheme. Nowadays, the research community tries
to ﬁnd the right image features to obtain a diagonal
Jacobian (Tahri and Chaumette, 2003). The obtained
results only guarantee the decoupling from the posi-
tion and the orientation of the velocity screw. This
is still a hot research topic, as stated very recently in
(Tahri and Chaumette, 2003).
In this paper, the previous related problems in the
Jacobian are addressed using fuzzy techniques, to ob-
tain a controller capable to control the system. First, a
fuzzy model to derive the inverse model of the robot is
used to compute the joints and end-effector velocities
in a straightforward manner. Second, the control ac-
tion obtained from the inverse model is compensated
to nullify a possible steady-state error by using a fuzzy
compensation.
A two degrees of freedom planar robotic manipu-
lator is controlled, based on eye-in-hand image-based
visual servoing using fuzzy control systems.
The paper is organized as follows. Section 2 de-
scribes brieﬂy the concept of image-based visual ser-
voing. The problem statement for the control prob-
lem tackled in this paper is presented in Section 3.
Section 4 presents fuzzy modeling and identiﬁca-
tion. Fuzzy compensation of steady-state errors is de-
scribed in Section 5. Section 6 presents the experi-
mental setup. The obtained results are presented in
Section 7. Finally, Section 8 present the conclusions
and the possible future research.
2
IMAGE-BASED VISUAL
SERVOING
In image-based visual servoing (Hutchinson et al.,
1996), the controlled variables are the image features,
extracted from the image containing the object. The
choice of different image features induces different
control laws, and its number depends also on the num-
ber of degrees of freedom (DOF) of the robotic ma-
nipulator under control. The robotic manipulator used
as test-bed in this paper is depicted in Fig. 1, and it has
2 DOF. Thus, only two features are needed to perform
the control. The image features, s, used are the coor-
dinates x and y of one image point.
L.F. Mendonc¸a, J.M. Sousa, J.R. Caldas Pinto
81
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 81–88. 

Z0
X0
Y0
q1
-q2
Zc
Xc
Yc
Figure 1:
Planar robotic manipulator with eye-in-hand,
camera looking down, with joint coordinates, and world and
camera frames.
2.1
Modeling the Image-Based
Visual Servoing System
In this paper, the image-based visual servoing sys-
tem used is the eye-in-hand system, where the camera
is ﬁxed at the robotic manipulator end-effector. The
kinematic modeling of the transformation between
the image features velocities and the joints velocities
is deﬁned as follows. Let eP be the pose of the end-
effector (translation and rotation), and cP be the pose
of the camera. Both depend on the robot joint vari-
ables q. Thus, the transformation from the camera
velocities and the end-effector velocities (Gonc¸alves
and Pinto, 2003a) is given by:
c ˙P = cWe · e ˙P ,
(1)
where
cWe =

cRe
S (cte) · cRe
03×3
cRe

(2)
and S(cte), is the skew-symmetric matrix associated
with the translation vector cte, and cRe is the rotation
matrix between the camera and end-effector frames
needed to be measured.
The joint and end-effector velocities are related in
the end-effector frame by:
e ˙P = eJR(q) · ˙q
(3)
where eJR is the robot Jacobian for the planar ro-
botic manipulator (Gonc¸alves and Pinto, 2003a), and
is given by:
eJR (q) =
l1 · sin(q2)
l2 + l1 · cos(q2)
0
0
0
1
0
l2
0
0
0
1
T
(4)
and li, with i = 1, 2 are the lengths of the robot links.
The image features velocity, ˙s and the camera veloc-
ity, c ˙P are related by:
˙s = Ji(x, y, Z) · c ˙P
(5)
where Ji(x, y, Z) is the image Jacobian, which is
derived using the pin-hole camera model and a sin-
gle image point as the image feature (Gonc¸alves and
Figure 2: Control loop of image-based visual servoing, us-
ing a PD control law.
Pinto, 2003a), s , and is deﬁned as
Ji(x, y, Z) =
−1
Z
0
x
Z
x · y
−
1 + x2
y
0
−1
Z
y
Z
1 + y2
−x · y
−x
(6)
where Z is the distance between the camera and the
object frames.
The relation between the image features velocity
and the joints velocities can now be easily derived
from (1), (3) and (5):
˙s = J(x, y, Z, q) · ˙q ,
(7)
where J is the total Jacobian, deﬁned as:
J(x, y, Z, q) = Ji(x, y, Z) · cWe · eJR (q)
(8)
2.2
Controlling the Image-Based
Visual Servoing System
One of the classic control scheme of robotic manip-
ulators using information from the vision system, is
presented in (Espiau et al., 1992). The global control
architecture is shown in Fig. 2, where the block Robot
inner loop law is a PD control law.
The robot joint velocities ˙q to move the robot to a
predeﬁned point in the image, s∗are derived using
the Visual control law, (Gonc¸alves and Pinto, 2003a),
where an exponential decayment of the image fea-
tures error is speciﬁed:
˙q = −Kp · ˆJ−1(x, y, Z, q) · (s −s∗) .
(9)
Kp is a positive gain, that is used to increase or de-
crease the decayment of the error velocity.
3
PROBLEM STATEMENT
To derive an accurate global Jacobian, J, a perfect
modeling of the camera, the image features, the posi-
tion of the camera related to the end-effector, and the
depth of the target related to the camera frame must
be accurately determined.
Even when a perfect model of the Jacobian is avail-
able, it can contain singularities, which hampers the
application of a control law. To overcome these difﬁ-
culties, a new type of differential relationship between
the features and camera velocities was proposed in
82
P.J.S. Gon alves et al. 
ç
]
]


)
)

(Suh and Kim, 1994). This approach estimates the
variation of the image features, when an increment in
the camera position is given, by using a relation G.
This relation is divided into G1 which relates the po-
sition of the camera and the image features, and F1
which relates their respective variation:
s + δs = G(cP + δcP) = G1(cP) + F1(cP, δcP)
(10)
The image features velocity, ˙s, depends on the camera
velocity screw, c ˙P, and the previous position of the
image features, s, as shown in Section 2. Considering
only the variations in (10):
δs = F1(cP, δcP),
(11)
let the relation between the camera position variation
δcP, the joint position variation, δq and the previous
position of the robot q be given by:
δcP = F2(δq, q).
(12)
The equations (11) and (12) can be inverted if a one-
to-one mapping can be guaranteed. Assuming that
this inversion is possible, the inverted models are
given by:
δcP = F −1
1
(δs, cP)
(13)
and
δq = F −1
2
(δcP, q)
(14)
The two previous equations can be composed be-
cause the camera is rigidly attached to the robot end-
effector, i.e., knowing q, cP can easily be obtained
from the robot direct kinematics, cRe and cte. Thus,
an inverse function F −1 is given by:
δq = F −1(δs, q) ,
(15)
and it states that the joint velocities depends on the
image features velocities and the previous position
of the robot manipulator. Equation (15) can be dis-
cretized as
δq(k) = F −1
k (δs(k + 1), q(k)).
(16)
In image-based visual servoing, the goal is to obtain a
joint velocity, δq(k), capable of driving the robot ac-
cording to a desired image feature position, s(k + 1),
with an also desired image feature velocity, δs(k+1),
from any position in the joint spaces. This goal can be
accomplished by modeling the inverse function F −1
k ,
using inverse fuzzy modeling as presented in section
4. This new approach to image-based visual servoing
allows to overcome the problems stated previously re-
garding the Jacobian inverse, the Jacobian singulari-
ties and the depth estimation, Z.
4
INVERSE FUZZY MODELING
4.1
Fuzzy Modeling
Fuzzy modeling often follows the approach of encod-
ing expert knowledge expressed in a verbal form in
a collection of if–then rules, creating an initial model
structure. Parameters in this structure can be adapted
using input-output data. When no prior knowledge
about the system is available, a fuzzy model can be
constructed entirely on the basis of systems measure-
ments.
In the following, we consider data-driven
modeling based on fuzzy clustering (Sousa et al.,
2003).
We consider rule-based models of the Takagi-
Sugeno (TS) type. It consists of fuzzy rules which
each describe a local input-output relation, typically
in a linear form:
Ri : If x1 is Ai1and . . . and xn is Ain
then yi = aix + bi ,
i = 1, 2, . . . , K.
(17)
Here Ri is the ith rule, x = [x1, . . . , xn]T are the in-
put (antecedent) variable, Ai1, . . . , Ain are fuzzy sets
deﬁned in the antecedent space, and yi is the rule out-
put variable. K denotes the number of rules in the
rule base, and the aggregated output of the model, ˆy,
is calculated by taking the weighted average of the
rule consequents:
ˆy =
K
i=1 βiyi
K
i=1 wiβi
,
(18)
where βi is the degree of activation of the ith rule:
βi
= Πn
j=1µAij(xj),
i = 1, 2, . . . , K, and
µAij(xj) : R →[0, 1] is the membership function
of the fuzzy set Aij in the antecedent of Ri.
To identify the model in (17), the regression ma-
trix X and an output vector y are constructed from
the available data:
XT
=
[x1, . . . , xN], yT
=
[y1, . . . , yN], where N ≫n is the number of sam-
ples used for identiﬁcation.
The number of rules,
K, the antecedent fuzzy sets, Aij, and the conse-
quent parameters, ai, bi are determined by means of
fuzzy clustering in the product space of the inputs
and the outputs (Babuˇska, 1998).
Hence, the data
set Z to be clustered is composed from X and y:
ZT = [X, y]. Given Z and an estimated number of
clusters K, the Gustafson-Kessel fuzzy clustering al-
gorithm (Gustafson and Kessel, 1979) is applied to
compute the fuzzy partition matrix U.
The fuzzy sets in the antecedent of the rules are
obtained from the partition matrix U, whose ikth el-
ement µik ∈[0, 1] is the membership degree of the
data object zk in cluster i. One-dimensional fuzzy
sets Aij are obtained from the multidimensional fuzzy
sets deﬁned point-wise in the ith row of the partition
matrix by projections onto the space of the input vari-
ables xj. The point-wise deﬁned fuzzy sets Aij are
approximated by suitable parametric functions in or-
der to compute µAij(xj) for any value of xj.
The consequent parameters for each rule are ob-
tained as a weighted ordinary least-square estimate.
Let θT
i
=

aT
i ; bi

, let Xe denote the matrix [X; 1]
83
Fuzzy Model Based Control Applied to Image-Based Visual Servoing

Figure 3: Robot-camera conﬁguration for model identiﬁca-
tion.
and let Wi denote a diagonal matrix in R N×N hav-
ing the degree of activation, βi(xk), as its kth diag-
onal element. Assuming that the columns of Xe are
linearly independent and βi(xk) > 0 for 1 ≤k ≤N,
the weighted least-squares solution of y = Xeθ + ϵ
becomes
θi =

XT
e WiXe
−1 XT
e Wiy .
(19)
4.2
For the robotic application in this paper, the inverse
model is identiﬁed using input-output data from the
inputs ˙q(k), outputs δs(k+1) and the state of the sys-
tem q(k). A commonly used procedure in robotics is
to learn the trajectory that must be followed by the ro-
bot. From an initial position, deﬁned by the joint posi-
tions, the robotic manipulator moves to the predeﬁned
end position, following an also predeﬁned trajectory,
by means of a PID joint position controller. This spe-
cialized procedure has the drawback of requiring the
identiﬁcation of a new model for each new trajectory.
However, this procedure revealed to be quite simple
and fast. Moreover, this specialized identiﬁcation pro-
cedure is able to alleviate in a large scale the prob-
lems derived from the close-loop identiﬁcation pro-
cedure. The identiﬁcation data is obtained using the
robot-camera conﬁguration shown in Fig. 3.
Note that we are interested in the identiﬁcation of
the inverse model in (16). Fuzzy modeling is used
to identify an inverse model, as e.g. in (Sousa et al.,
2003). In this technique, only one of the states of
the original model, ˙q(k), becomes an output of the
inverted model and the other state, q(k), together
with the original output, δs(k + 1), are the inputs of
the inverted model. This model is then used as the
main controller in the visual servoing control scheme.
Therefore, the inverse model must be able to ﬁnd a
joint velocity, ˙q(k), capable to drive the robot fol-
lowing a desired image feature velocity in the image
space, δs(k + 1), departing from previous joint posi-
tions, q(k).
5
FUZZY COMPENSATION OF
STEADY-STATE ERRORS
Control techniques based on a nonlinear process
model such as Model Based Predictive Control or
control based on the inversion of a model, (Sousa
et al., 2003), can effectively cope with the dynam-
ics of nonlinear systems. However, steady-state er-
rors may occur at the output of the system as a result
of disturbances or a model-plant mismatch. A scheme
is needed to compensate for these steady-state errors.
A classical approach is the use of an integral control
action. However, this type of action is not suitable
for highly nonlinear systems because it needs differ-
ent parameters for different operating regions of the
system.
Therefore, this paper develops a new solution,
called fuzzy compensation. The fuzzy compensator
intends to compensate steady-state errors based on the
information contained in the model of the system and
allows the compensation action to change smoothly
from an active to an inactive state. Taking the local
derivative of the model with respect to the control ac-
tion, it is possible to achieve compensation with only
one parameter to be tuned (similar to the integral gain
of a PID controller). For the sake of simplicity, the
method is presented for nonlinear discrete-time SISO
systems, but it is easily extended to MIMO systems.
Note that this is the case of the 2-DOF robotic system
in this paper.
5.1
In this section it is convenient to delay one step the
model for notation simplicity. The discrete-time SISO
regression model of the system under control is then
given by:
y(k) = f(x(k −1)) ,
(20)
where x(k −1) is the state containing the lagged
model outputs, inputs and states of the system. Fuzzy
compensation uses a correction action called uc(k),
which is added to the action derived from an inverse
model-based controller, um(k), as shown in Fig. 4.
The total control signal applied to the process is thus
given by,
u(k) = um(k) + uc(k).
(21)
Note that the controller in Fig. 4 is an inverse model-
based controller for the robotic application in this pa-
per, but it could be any controller able to control the
system, such as a predictive controller.
Taking into account the noise and a (small) off-
set error, a fuzzy set SS deﬁnes the region where
the compensation is active, see Fig. 5.
The error
84
P.J.S. Gon alves et al. 
ç
Inverse Modeling
Derivation of Fuzzy
Compensation

Figure 4: Fuzzy model-based compensation scheme.
Figure 5: Deﬁnition of the fuzzy boundary SS where fuzzy
compensation is active.
is deﬁned as e(k) = r(k) −y(k), and the mem-
bership function µSS(e(k)) is designed to allow for
steady-state error compensation whenever the support
of µSS(e(k)) is not zero. The value of B that deter-
mines the width of the core(µSS) should be an upper
limit of the absolute value of the possible steady-state
errors. Fuzzy compensation is fully active in the in-
terval [−B, B]. The support of µSS(e(k)) should be
chosen such that it allows for a smooth transition from
enabled to disabled compensation. This smoothness
of µSS induces smoothness on the fuzzy compensa-
tion action uc(k), and avoids abrupt changes in the
control action u(k).
The compensation action uc(k) at time k is given
by
uc(k) = µSS(e(k))
k−1

i=0
uc(i) + K e(k) f −1
u

,
(22)
where µSS(e(k)) is the error membership degree at
time k, Kc is a constant parameter to be determined
and
fu =

∂f
∂u(k −1)

x(k−1)
(23)
is the partial derivative of the function f in (20) with
respect to the control action u(k −1), for the present
state of the system x(k −1).
6
EXPERIMENTAL SETUP
The experimental setup can be divided in two subsys-
tems, the vision system and the robotic manipulator
system. The vision system acquires and process im-
ages at 50Hz, and sends image features, in pixels, to
the robotic manipulator system via a RS-232 serial
port, also at 50 Hz. The robotic manipulator system
controls the 2 dof planar robotic manipulator, Fig. 6
and Fig. 1 using the image data sent from the vision
system.
6.1
Vision System
The vision system performs image acquisition and
processing under software developed in Visual
C++T M and running in an Intel Pentium IVT M, at 1.7
GHz, using a Matrox MeteorT M frame-grabber. The
CCD video camera, Costar, is ﬁxed in the robot end-
effector looking up and with its optical axis perpen-
dicular to the plane of the robotic manipulator. The
planar target is parallel to the plane of the robot, and
is above it. This conﬁguration allows deﬁning the Z
variable as pre-measured constant in the image Jaco-
bian (6) calculation, Z = 1. The target consists of one
light emitting diode (LED), in order to ease the image
processing and consequently diminish its processing
time, because we are mainly concerned in control al-
gorithms.
Following the work in (Reis et al., 2000) the im-
age acquisition is performed at 50 Hz.
It is well
known that the PAL video signal has a frame rate of
25 frames/second. However, the signal is interlaced,
i.e., odd lines and even lines of the image are codiﬁed
in two separate blocks, known as ﬁelds. These ﬁelds
are sampled immediately before each one is sent to
the video signal stream. This means that each ﬁeld
is an image with half the vertical resolution, and the
application can work with a rate of 50 frames/second.
The two image ﬁelds were considered as separate im-
ages thus providing a visual sampling rate of 50 Hz.
When performing the centroid evaluation at 50 Hz,
an error on its vertical coordinate will arise, due to
the use of only half of the lines at each sample time.
Multiplying the vertical coordinate by two, we obtain
a simple approximation of this coordinate.
The implemented image processing routines ex-
tract the centroid of the led image. Heuristics to track
this centroid, can be applied very easily (Gonc¸alves
and Pinto, 2003b). These techniques allow us to cal-
culate the image features vector s, i.e., the two im-
age coordinates of the centroid. The image process-
ing routines and the sending commands via the RS-
232 requires less than 20ms to perform in our system.
The RS-232 serial port is set to transmit at 115200
bits/second. When a new image is acquired, the pre-
85
Fuzzy Model Based Control Applied to Image-Based Visual Servoing

Figure 6: : Experimental Setup, Planar Robotic Manipula-
tor with eye-in-hand, camera looking up.
vious one was already processed and the image data
sent via RS-232 to the robotic manipulator system.
6.2
Robotic Manipulator System
The robot system consists of a 2 dof planar ro-
botic manipulator (Baptista et al., 2001) moving in
a horizontal plane, the power ampliﬁers and an In-
tel PentiumT M 200MHz, with a ServoToGoT M I/O
card. The planar robotic manipulator has two revolute
joints driven by Harmonic Drive Actuators - HDSH-
14. Each actuator has an electric d.c. motor, a har-
monic drive, an encoder and a tachogenerator. The
power ampliﬁers are conﬁgured to operate as current
ampliﬁers. In this functioning mode, the input con-
trol signal is a voltage in the range ±10V with cur-
rent ratings in the interval [−2; 2]V . The signals are
processed through a low cost ISA-bus I/O card from
ServoToGo, INC. The I/O board device drivers were
developed at the Mechanical Engineering Department
from Instituto Superior T´ecnico. The referred PC is
called in our overall system as the Target PC. It re-
ceives the image data from the vision system via RS-
232, each 20 ms, and performs, during the 20 ms of
the visual sample time, the visual servoing algorithms
developed in the Host-PC.
It is worth to be noted that the robot manipulator
joint limits are: q ∈[−π
2 ; π
2 ].
6.3
Systems Integration
The control algorithms for the robotic manipulator
are developed in a third PC, called Host-PC. An exe-
cutable ﬁle containing the control algorithms is then
created for running in the Target-PC. The executable
ﬁle created, containing the control algorithm, is then
downloaded, via TCP/IP, to the Target-PC, where all
the control is performed. After a pre-deﬁned time for
execution, all the results can be uploaded to the Host-
PC for analysis. During execution the vision system
sends to the Target PC the actual image features as a
visual feedback for the visual servoing control algo-
rithm, using the RS-232 serial port.
7
RESULTS
This section presents the simulation results obtained
for the robotic manipulator, presented in Section 6.
First, the identiﬁcation of the inverse fuzzy model of
the robot is described. Then, the control results using
the fuzzy model based controller introduced in this
paper, i.e. the combination of inverse fuzzy control
and fuzzy compensation, are presented.
7.1
Inverse Fuzzy Modeling
In order to apply the controller described in this paper,
ﬁrst an inverse fuzzy controller must be identiﬁed.
Recall that a model must be identiﬁed for each trajec-
tory. This trajectory is presented in Fig. 10. The pro-
ﬁle chosen for the image features velocity moves the
robot from the initial joints position q = [−1.5; 0.3]
to the ﬁnal position q = [−1.51; 1.52], in one sec-
ond, starting and ending with zero velocity. An in-
verse fuzzy model (16) for this trajectory is identiﬁed
using the fuzzy modeling procedure described in Sec-
tion 4.1. The measurements data is obtained from a
simulation of the planar robotic manipulator eye-in-
hand system.
0
50
100
150
200
250
−2
−1
0
1
2
No samples [20 ms]
Joint Positions [rad]
Inverse Fuzzy Model Input Data
0
50
100
150
200
250
−0.1
−0.05
0
0.05
0.1
No samples [20 ms]
Image features velocity [m/s]
Figure 7: Input data for fuzzy identiﬁcation. Top: joint po-
sitions, q. Bottom: image feature velocity, δs.
The set of identiﬁcation data used to build the in-
verse fuzzy model contains 250 samples, with a sam-
ple time of 20ms. Figure 7 presents the input data,
which are the joint positions q1(k) and q2(k), and the
image features velocities δsx(k) and δsy(k), used for
identiﬁcation.
86
P.J.S. Gon alves et al. 
ç

Note that to identify the inverse model, one cannot
simply feed the inputs as outputs and the outputs as
inputs. Since the inverse model (16) is a non-causal
model, the output of the inverse model must be shifted
one step, see (Sousa et al., 2003). The validation of
the inverse fuzzy model is shown in Fig. 8, where the
joint velocities δq are depicted. Note that two fuzzy
models are identiﬁed, one for each velocity. It is clear
that the model is quite good. Considering, e.g. the
performance criteria variance accounted for (VAF),
the models have the VAFs of 70.2% and 99.7%. When
a perfect match occur, this measure has the value of
100%. Then, the inverse model for the joint velocity
δq2 is very accurate, but the inverse model for δq1 is
not so good. This was expectable as the joint velocity
δq1 varies much more than δq2. However, this model
will be sufﬁcient to obtain an accurate controller, as is
shown in Section 7.2.
0
50
100
150
200
250
−0.05
0
0.05
No samples [20 ms]
Joint 1 Velocity [rad/s]
Inverse Fuzzy Model Validation
0
50
100
150
200
250
−2
−1
0
1
2
No samples [20 ms]
Joint 2 Velocity [rad/s]
Figure 8: Validation of the inverse fuzzy model (joint veloc-
ities δq). Solid – real output data, and dash-dotted – output
of the inverse fuzzy model.
In terms of parameters, four rules (clusters) re-
vealed to be sufﬁcient for each output, and thus the
inverse fuzzy model has 8 rules, 4 for each output, δq1
and δq2. The clusters are projected into the product-
space of the space variables and the fuzzy sets Aij are
determined.
7.2
This section presents the obtained control results, us-
sented in Section 2, and the fuzzy model-based con-
trol scheme combining inverse model control pre-
sented
in Section
4, and
fuzzy compensation
oped in a simulation of the planar robotic manipula-
tor eye-in-hand system. This simulation was devel-
oped and validated in real experiments, using clas-
sic visual servoing techniques, by the authors. Re-
0
10
20
30
40
50
60
70
80
90
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
No samples [20 ms]
Image Features Position [m]
Comparison of Image Features Position versus Trajectory
Figure 9: Image features trajectory, s. Solid – fuzzy visual
servo control; dashed – classical visual servo control, and
dash-dotted – desired trajectory.
−20
−10
0
10
20
30
40
50
60
−60
−50
−40
−30
−20
−10
0
10
20
30
40
Comparison of Image Features Trajectory
u [pixel]
v [pixel]
Figure 10: Image features trajectory s, in the image plane.
Solid – inverse fuzzy model control, and dash-dotted – clas-
sical visual servo control.
call that the chosen proﬁle for the image features ve-
locity moves the robot from the initial joints position
q = [−1.5; 0.3] to the ﬁnal position q = [−1.51; 1.52]
in one second, starting and ending with zero velocity.
The comparison of the image features trajectory for
both the classic and the fuzzy visual servoing con-
trollers is presented in Fig. 9. In this ﬁgure, it is shown
that the classical controller follows the trajectory with
a better accuracy than the fuzzy controller. However,
the fuzzy controller is slightly faster, and reaches the
vicinity of the target position before the classical con-
troller. The image features trajectory in the image
plane is presented in Fig. 10, which shows that both
controllers can achieve the goal position (the times,
×, sign in the image) with a very small error. This
ﬁgure shows also that the trajectory obtained with the
inverse fuzzy model controller is smoother. There-
fore, it is necessary to check the joint velocities in
order to check their smoothness. Thus the joint veloc-
87
Fuzzy Model Based Control Applied to Image-Based Visual Servoing
Control Results
describedin Sec tion 5.The implementation wasdevel-
ing the classical image-based visual servoing pre-

0
10
20
30
40
50
60
70
80
90
−2
−1
0
1
2
3
4
No samples [20 ms]
Joint Velocity [rad/s]
Comparison of Joint Velocities
Figure 11: Joint velocities, δq. Solid – fuzzy visual servo,
and dashed – classical visual servo.
ities are depicted in Fig. 11, where it is clear that the
classical controller presents undesirable and danger-
ous oscillations in the joint velocities. This fact is due
to the high proportional gain that the classical con-
troller must have to follow the trajectory, which de-
mands high velocity. This effect is easily removed by
slowing down the classical controller. But in this case,
the fuzzy controller clearly outperforms the classical
controller. The classical controller can only follow
the trajectory without oscillations in the joint veloc-
ities if the robot takes 1.5s to move from one point
to the other. In this case, the classical controller is
about 50% slower than the fuzzy model-based con-
troller proposed in this paper.
8
CONCLUSIONS
This paper introduces an eye-in-hand image-based vi-
sual servoing scheme based on fuzzy modeling and
control. The fuzzy modeling approach was applied
to obtain an inverse model of the mapping between
image features velocities and joints velocities. This
inverse model is added to a fuzzy compensator to be
directly used as controller of a robotic manipulator
performing visual servoing, for a given image features
velocity proﬁle.
The obtained results showed that both the classi-
cal and the fuzzy controllers can follow the image
features velocity proﬁle. However, the proportional
gain of the classic visual servoing must be very high.
This fact justiﬁes the oscillations veriﬁed in the joint
velocities, which are completely undesirable in robot
control. For that reason, the inverse fuzzy control pro-
posed in this paper performs better.
As future work, the proposed fuzzy model based
control scheme will be implemented in the experi-
mental test-bed. Note that an off-line identiﬁcation
of the inverse fuzzy model must ﬁrst be performed.
The complete automation of this identiﬁcation step is
also under study.
ACKNOWLEDGEMENTS
This work is supported by the “Programa de Financia-
mento Plurianual de Unidades de I&D (POCTI) do Quadro
Comunit´ario de Apoio III”, by program FEDER, by the
FCT project POCTI/EME/39946/2001, and by the “Pro-
grama do FSE-UE, PRODEP III, acc¸˜ao 5.3, no ˆambito do
III Quadro Comunit´ario de apoio”.
REFERENCES
Babuˇska, R. (1998). Fuzzy Modeling for Control. Kluwer
Academic Publishers, Boston.
Baptista, L., Sousa, J. M., and da Costa, J. S. (2001). Fuzzy
predictive algorithms applied to real-time force con-
trol. Control Engineering Practice, pages 411–423.
Espiau, B., Chaumette, F., and Rives, P. (1992).
A new
approach to visual servoing in robotics. IEEE Trans-
actions on Robotics and Automation, 8(3):313–326.
Gonc¸alves, P. S. and Pinto, J. C. (2003a).
Camera con-
ﬁgurations of a visual servoing setup, for a 2 dof
planar robot.
In Proceedings of the 7th Interna-
tional IFAC Symposium on Robot Control, Wroclaw,
Poland., pages 181–187, Wroclaw, Poland.
Gonc¸alves, P. S. and Pinto, J. C. (2003b).
An experi-
mental testbed for visual servo control of robotic ma-
nipulators. In Proceedings of the IEEE Conference
on Emerging Technologies and Factory Automation,
pages 377–382, Lisbon, Portugal.
Gustafson, D. E. and Kessel, W. C. (1979). Fuzzy clustering
with a fuzzy covariance matrix. In Proceedings IEEE
CDC, pages 761–766, San Diego, USA.
Hutchinson, S., Hager, G., and Corke, P. (1996). A tutorial
on visual servo control. IEEE Transactions on Robot-
ics and Automation, 12(5):651–670.
Reis, J., Ramalho, M., Pinto, J. C., and S´a da Costa, J.
(2000). Dynamical characterization of ﬂexible robot
links using machine vision. In Proceedings of the 5th
Ibero American Symposium on Pattern Recognition,
pages 487–492, Lisbon, Portugal.
Sousa, J. M., Silva, C., and S´a da Costa, J. (2003). Fuzzy
active noise modeling and control. International Jour-
nal of Approximate Reasoning, 33:51–70.
Suh, I. and Kim, T. (1994). Fuzzy membership function
based neural networks with applications to the visual
servoing of robot manipulators. IEEE Transactions on
Fuzzy Systems, 2(3):203–220.
Tahri, O. and Chaumette, F. (2003). Application of moment
invariants to visual servoing. In Proceedings of the
IEEE Int. Conf. on Robotics and Automation, pages
4276–4281, Taipeh, Taiwan.
88
P.J.S. Gon alves et al. 
ç

AN EVOLUTIONARY APPROACH TO NONLINEAR
DISCRETE-TIME OPTIMAL CONTROL WITH
TERMINAL CONSTRAINTS
Yechiel Crispin
Department of Aerospace Engineering
Embry-Riddle University
Daytona Beach, FL 32114
crispinj@erau.edu
Keywords:    Optimal Control, Genetic Algorithms
Abstract:     The nonlinear discrete-time optimal control problem with terminal constraints is treated using a new evolutionary
approach which combines a genetic search for finding the control sequence with a solution of the initial value
problem for the state variables. The main advantage of the method is that it does not require to obtain the
solution of the adjoint problem which usually leads to a two-point boundary value problem combined with an
optimality condition for finding the control sequence. The method is verified by solving the problem of discrete
velocity direction programming with the effects of gravity and thrust and a terminal constraint on the final
vertical position. The solution compared favorably with the results of gradient methods.
1   INTRODUCTION
A continuous-time optimal control problem consists
of finding the time histories of the controls and the
state variables such as to maximize (or minimize) an
integral performance index over a finite period of
time, subject to dynamical constraints in the form of
a system of ordinary differential equations (Bryson,
1975). In a discrete-time optimal control problem,
the time period is divided into a finite number of
time intervals of equal time duration 
. The
";
controls are kept constant over each time interval.
This results in a considerable simplification of the
continuous time problem, since the ordinary
differential equations can be reduced to difference
equations and the integral performance index can be
reduced to a finite sum over the discrete time
counter 
(Bryson, 
1999). 
In 
some problems,
additional constraints may be prescribed on the final
states of the system. In this paper, we concentrate on
the discrete-time optimal control problem with
terminal constraints.Modern methods for solving the
optimal control problem are extensions of the
classical methods of the calculus of variations (Fox,
1950).
 These methods are known as indirect methods and
are based on the maximum principle of Pontryagin,
which is astatement of the first order necessary
conditions for optimality, and results in a two-point
boundary value problem (TPBVP) for the state and
adjoint variables (Pontryagin, 1962). It has been
known, however, that the TPBVP is much more
difficult to solve than the initial value problem
(IVP). As a consequence, a second class of solutions,
known as the direct method has evolved.
For example, attempts have been made to recast the
original dynamic problem as a static optimization
problem, also known as a nonlinear programming
(NLP) problem.
This can be achieved by parameterisation of the
state variables or the controls, or both. In this way,
the original dynamical differential equations or
difference equations are reduced to algebraic
equality constraints. The problems with this
approach is that it might result in a large scale NLP
problem which has stability and convergence
problems and might require excessive computing
time. Also, the parameterisation might introduce
spurious local minima which are not present in the
original problem.
89
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 89–97. 

     Several gradient based methods have been
proposed for solving the discrete-time optimal
control problem (Mayne, 1966). For example,
Murray 
and 
Yakowitz 
(Murray, 
1984) 
and
(Yakowitz, 1984) developed a differential dynamic
programming and Newton's method for the solution
of discrete optimal control problems, see also the
book of Jacobson and Mayne (Jacobson, 1970),
(Ohno, 1978), (Pantoja, 1988) and (Dunn, 1989).
Similar methods have been further developed by
Liao and Shoemaker (Liao, 1991). Another method,
the trust region method, was proposed by Coleman
and Liao (Coleman, 1995) for the solution of
unconstrained 
discrete-time 
optimal 
control
problems. Although confined to the unconstrained
problem, this method works for large scale
minimization and is capable of handling the so
called hard case problem.
     Each method, whether direct or indirect,
gradient-based or direct search based, has its own
advantages and disadvantages. However, with the
advent of computing power and the progress made
in methods that are based on optimization analogies
from nature, it became possible to achieve a remedy
to some of the above mentioned disadvantages
through the use of global methods of optimization.
These include stochastic methods, such as simulated
annealing (Laarhoven, 1989), (Kirkpatrick, 1983)
and evolutionary computation methods (Fogel,
1998), (Schwefel, 1995) such as genetic algorithms
(GA) (Michalewicz, 1992a), see also (Michalewicz,
1992b) for an interesting treatment of the linear
discrete-time problem.
    Genetic algorithms provide a powerful
mechanism towards a global search for the
optimum, but in many cases, the convergence is very
slow. However, as will be shown in this paper, if the
GA is supplemented by problem specific heuristics,
the convergence can be accelerated significantly. It
is well known that GAs are based on a guided
random search through the genetic operators and
evolution by artificial selection. This process is
inherently very slow, because the search space is
very large and evolution progresses step by step,
exploring many regions with solutions of low
fitness. What is proposed here, is to guide the search
further, by incorporating qualitative knowledge
about potential good solutions. In many problems,
this might involve simple heuristics, which when
combined with the genetic search, provide a
powerful tool for finding the optimum very quickly.
    The purpose of the present work, then, is to
incorporate problem specific heuristic arguments,
which when combined with a modified hybrid GA,
can solve the discrete-time optimal control problem
very easily. There are significant advantages to this
approach. First, the need to solve the two-point
boundary value problem (TPBVP) is completely
avoided. Instead, only initial value problems (IVP)
are solved. Second, after finding an optimal
solution, we verify that it approximately satisfies the
first-order necessary conditions for a stationary
solution, so the mathematical soundness of the
traditional 
necessary 
conditions 
is 
retained.
Furthermore, after obtaining a solution by direct
genetic search, the static and dynamic Lagrange
multipliers (the adjoint variables) can be computed
and compared with the results from a gradient
method. All this is achieved without directly solving
the TPBVP. There is a  price to be paid, however,
since, in the process, we are solving many initial
value problems (IVPs). This might present a
challenge in advanced difficult problems, where the
dynamics are described by a higher order system of
ordinary differential equations, or when the
equations are difficult to integrate over the required
time interval and special methods are required. On
the other hand, if the system is described by
discrete-time difference equations that are relatively
well behaved and easy to iterate, the need to solve
the initial value problem many times does not
represent a serious problem. For instance, the
example problem presented here , the discrete
velocity programming problem (DVDP) with the
combined effects of gravity, thrust and drag,
together with a terminal constraint (Bryson, 1999),
runs on a 1.6 GHz pentium 4 processor in less than
a minute of CPU time.
     In the next section, a mathematical formulation
of the optimal control problem is given. The
evolutionary approach to the solution is then
described. In order to illustrate the method, a
specific example, the discrete velocity direction
programming (DVDP) is solved and results are
presented and compared with the results of an
indirect gradient method developed by Bryson
(Bryson, 1999).
2   OPTIMAL CONTROL OF
NONLINEAR DISCRETE TIME
DYNAMICAL SYSTEMS
In this section, we describe a formulation of the
nonlinear discrete-time optimal control problem
90
Y. Crispin

subject to terminal constraints. Consider the
nonlinear discrete-time dynamical system described
by a system of difference equations with initial
conditions
(1)  %
 %
"
² b ³ ~
´ ²³Á
²³Á µ
(2)  %
%
²³ ~

where 
 is the vector of state variables,
%  s
" 
Á   
s  
 is the vector of control variables and
  ´Á 5 c µ is a discrete time counter. The
function 
 is a nonlinear function of the state

vector, the control vector and the discrete time ,
i.e., 
 x 
 x 
. Define a performance
 ¢
ª
s
s
s
s



index
(3)
1´ ²³Á
²³Á Á 5µ ~
´ ²5³µ
b
3´ ²³Á
²
%
"
%
%
"


~
5c
³Á µ
where

s
s
s
s
s
s
¢
ª
3 ¢
ª



,       
 x 
 x 
Here  is the Lagrangian function and 
 is a
3
´ ²5³µ
 %
function of the terminal value of the state vector
%²5³. Terminal constraints in the form of
additional functions 
 of the state variables are

prescribed as
(4)  

´ ²5³µ ~ 
¢
ª
  
%
s
s


The optimal control problem consists of finding the
control sequence 
 such as to maximize (or
"²³
minimize) the performance index  defined by (3),
subject to the dynamical equations (1) with initial
conditions (2) and terminal constraints (4). This is
known as the Bolza problem in the calculus of
variations (Bolza, 1904).
In an alternative formulation, due to Mayer, the
state vector 
(
) is augmented by an
% Á   Á 

additional variable 
 which satisfies the
%b
following initial value problem:
(5)  %
² b ³ ~ %
²³ b 3´ ²³Á
²³Á µ
b
b
%
"
(6)  %
²³ ~ 
b
The performance index can then be written as
(7)
1²5³ ~
´ ²5³µ b %
²5³ 
´
²5³µ


%
%
b


where 
 is the augmented state
%
%
 ~ ´
%
µ
b ;
vector and 
 the augmented performance function.

In this paper, the Meyer formulation is used.
    Define an augmented performance index with
adjoint constraints 
 and adjoint dynamical

constraints 
(
)
, with
 %
"
%
²³Á
²³Á  c
² b ³ ~ 
static and dynamical Lagrange multipliers  and ,


respectively.
(8)  1 ~
b
b
²³´
c
²³µ

;
;




%
%

b
² b ³¸ ´ ²³Á
²³Á µ c
² b ³¹

~
5c
;

 %
"
%
Define the Hamiltonian function as
(9)  /²³ ~
² b ³ ´ ²³Á
²³Á µ
;
 %
"
Rewriting the augmented performance index in
terms of the Hamiltonian, we get
(10)
1 ~
b
c
²5³ ²5³ b
²³

;
;
;

 


%
%
b
´/²³ c
²³ ²³µ

~
5c
;

%
A first order necessary condition for 
 to reach a
1
stationary solution is given by the discrete version of
the Euler-Lagrange equations
(11)


;
;
²³ ~ / ²³ ~
² b ³
´ ²³Á
²³Á µ
%
%
 %
"
with final conditions
(12)  


;
;
%
²5³ ~
b

%
and the control sequence 
 satisfies the
"²³
optimality condition:
(13)  / ²³ ~
² b ³
´ ²³Á
²³Á µ ~ 
"
"
;
 %
"
Define an augmented function  as
)
(14)  )

~
b 

;
91
An Evolutionary Approach to Nonlinear Discrete-Time Optimal Control

Then, the adjoint equations for the dynamical
multipliers are given by
(15)


;
;
²³ ~ / ²³ ~
² b ³
´ ²³Á
²³Á µ
%
%
 %
"
and the final conditions can be written in terms of
the augmented function )
(16)  


;
;
²5³ ~
~
b
)

%
%
%
If the indirect approach to optimal control is used,
the state equations (1) with initial conditions (2)
need to be solved together with the adjoint equations
(15) and the final conditions (16), where the control
sequence 
 is to be determined from the
"²³
optimality condition (13). This represents a coupled
system of nonlinear difference equations with part of
the boundary conditions specified at the initial time
 ~  and the rest of the boundary conditions
specified at the final time 
. This is a nonlinear
 ~ 5
two-point boundary value problem (TPBVP) in
difference equations. Except for special simplified
cases, it is usually very difficult to obtain solutions
for such nonlinear TPBVPs. Therefore, many
numerical methods have been developed to tackle
this problem, see the introduction for several
references.
     In the proposed approach, the optimality
condition (13) and the adjoint equations (15)
together with their final conditions (16) are not used
in order to obtain the optimum solution. Instead, the
optimal values of the control sequence 
 are
"²³
found by genetic search starting with an initial
population of solutions with values of 
 randomly
"²³
distributed within a given domain. During the
search, approximate, less than optimal values of the
solutions 
 are available for each generation.
"²³
With these approximate values known, the state
equations (1) together with their initial conditions
(2) are very easy to solve, by a straightforward
iteration of the difference equations from 
 to
 ~ 
 ~ 5 c . At the end of this iterative process, the
final values 
 are obtained, and the fitness
%²5³
function can be determined. The search than seeks
to maximize the fitness function 
 such as to fulfill
-
the goal of the evolution, which is to maximize
1 ²5³, as given by the following Eq.(17), subject to
the terminal constraints 
, as defined
´ ²5³µ ~ 
%
by Eq.(18).
(17)   maximize 1²5³ ~
´ ²5³µ
 %
subject to the dynamical equality constraints, Eqs.
(1-2) and to the terminal constraints (4), which are
repeated here for convenience as Eq.(18)
(18) 

´ ²5³µ ~ 
¢
ª
  
%
s
s


Since we are using a direct search method, condition
(18) can also be stated as a search for a maximum,
namely we can set a goal which is equivalent to (18)
in the form
(19)  maximize   1 ²5³ ~ c
´ ²5³µ ´ ²5³µ



T %
%
The fitness function  can now be defined by
-
(20)  - ²5³ ~
1²5³ b ² c
³1 ²5³



~
´ ²5³µ c ² c
³
´ ²5³µ ´ ²5³µ


%
%
%
 
,


T
with 
 and 
 determined from the
  ´Á µ
²5³
%
following dynamical equality constraints:
(21)  
,
%
 %
"
² b ³ ~
´ ²³Á
²³Á µ
  ´Á 5 c µ
(22)  %
%
²³ ~

3   DISCRETE VELOCITY
DIRECTION    PROGRAMMING
FOR MAXIMUM RANGE WITH
GRAVITY AND THRUST
In this section, the above formulation is applied to a
specific example, namely, the problem of finding the
trajectory of a point mass subjected to gravity and
thrust and a terminal constraint such as to achieve
maximum horizontal distance, with the direction of
the velocity used to control the motion. This
problem has its roots in the calculus of variations
and is related to the classical Brachistochrone
problem, in which the shape of a wire is sought
along which a bead slides without friction, under the
action of gravity alone, from an initial point ²% Á & ³


to a final point 
 in minimum time 
. The
²% Á & ³
!



dual problem to the Brachistochrone problem
consists of finding the shape of the wire such as the
bead will reach a maximum horizontal distance %
in a prescribed time 
. Here, we treat the dual
!
92
Y. Crispin

problem with the added effects of thrust and a
terminal constraint where the final vertical position
& is prescribed. The more difficult problem, where
the body is moving in a viscous fluid and the effect
of drag is taken into account was also solved, but
due to lack of space, the results will be presented
elsewhere. The reader interested in these problems
can find an extensive discussion in Bryson's book
(Bryson,1999).
    Let point O be the origin of a cartesian system of
coordinates in which  is pointing to the right and 
%
&
is pointing down. A constant thrust force 
 is
-
acting along the path on a particle of mass 
 which

moves in a medium without friction. A constant
gravity field with acceleration  is acting downward

in the positive  direction.  The thrust acts in the
&
direction of the velocity vector 
 and its magnitude
=
is 
, i.e. 
 times the weight 
. The
- ~ 


velocity vector 
 acts at an angle  with respect to
=

the positive direction of 
. The angle 
, which
%

serves as the control variable, is positive when =
points downward from the horizontal. The problem
is to find the control sequence 
 to maximize the
²!³
horizontal range 
 in a given time 
, provided the
%
!


particle ends at the vertical location 
. In other
&
words, the velocity direction 
 is to be
²!³
programmed such as to achieve maximum range
and fulfill the terminal constraint 
.  The equations
&
of motion are
(23) = °! ~ ² b   ²!³³

(24) %°! ~ =  ²!³

(25) &°! ~ =   ²!³

with initial conditions
(26)  
, 
 
= ²³ ~  %²³ ~ Á &²³ ~ 
and final constraint
(27) 
.
&²! ³ ~ &


We would like to formulate a discrete time version
of this problem. The trajectory is divided into a
finite number 
 of straight line segments of fixed
5
time duration 
, along which the
"; ~ ! °5

direction  is constant. We can increase 
 such as

5
to approach the solution of the continuous trajectory.
The velocity 
 is increasing under the influence of
=
a constant thrust 
and gravity
. The problem

 
is to determine the control sequence 
 at points 
²³

along the trajectory, where 
, such as to
  ´Á 5 c µ
maximize  at time , arriving at the same time at a
%
!
prescribed  elevation 
. The time at the end of each
&
segment is given by 
, so  can be viewed
!²³ ~ 
;

"
as a time step counter at  point . Integrating the

first equation of motion, Eq.(17) from a time
!²³ ~ 
;
!² b ³ ~ ² b ³
;
"
"
 to 
, we get
(28)  = ² b ³ ~ = ²³ b ´ b   ²³µ
;

"
Integrating the velocity 
over a time interval 
,
=
;
"
we obtain the length of the segment "²³
connecting the points  and 
.

 b 
(29)
"
"

"
²³ ~ = ²³
; b
´ b   ²³µ²
;³



Once 
 is determined, it is easy to obtain the
"²³
coordinates  and  as
%
&
(30)  %² b ³ ~ %²³ b
²³ ²³
"

~ %²³ b = ²³ ²³
;

"
b
´ b   ²³µ ²³²
;³





"
(31)  &² b ³ ~ &²³ b
²³  ²³
"

~ &²³ b = ²³  ²³
;

"
b
´ b   ²³µ  ²³²
;³





"
We now develop the equations in nondimensional
form. Introduce the following nondimensional
variables denoted by primes:
(32) 
,  
,  
,
! ~ ! !
= ~ ! =
% ~ ! %

Z
Z

Z


& ~ ! &


Z
Since 
, the nondimensional time is
!²³ ~ ! °5

! ²³ ~ °5
Z
. The time interval was defined as
"
"
; ~ ! °5 ~ ! ²
; ³


Z,   so the nondimensional
time interval becomes 
. Substituting
²
; ³ ~ °5
"
Z
the nondimensional variables in the discrete
equations of motion and omitting the prime
notation, we obtain the nondimensional state
equations:
93
An Evolutionary Approach to Nonlinear Discrete-Time Optimal Control

(33)  = ² b ³ ~ = ²³ b ´ b   ²³µ°5

(34)  %² b ³ ~ %²³ b = ²³ ²³°5

b
´ b   ²³µ ²³°5





(35)  &² b ³ ~ &²³ b = ²³  ²³°5

b
´ b   ²³µ  ²³°5





with initial conditions
(36)  
, 
 
= ²³ ~  %²³ ~ Á &²³ ~ 
and terminal constraint
(37)  &²5³ ~ &
The optimal control problem now consists of finding
the sequence 
 such as to maximize the range
²³
%²5³, subject to the dynamical constraints (33-35),
the initial conditions (36) and the terminal
constraint (37), where 
 is in units of 
 and the
&
!



final time  is given.
!
4   NECESSARY CONDITIONS FOR
AN OPTIMUM
In this section we present the traditional indirect
approach to the solution of the optimal control
problem, which is based on the first order necessary
conditions for an optimum. First, we derive the
Hamiltonian function for the above DVDP problem.
We then derive the adjoint dynamical equations for
the adjoint variables (the Lagrange multipliers) and
the optimality condition that needs to be satisfied by
the control sequence 
. Since we have used the
²³
symbol  for the horizontal coordinate, we denote
%
the state variables by . So the state vector for this

problem is
 ~ ´= % &µ;
The performance index and the terminal constraint
are given by
(38)  1²5³ ~
´ ²5³µ ~ %²5³
 
(39)  

²5³ ~
´ ²5³µ ~ &²5³ c & ~ 


The Hamiltonian 
 is defined by
/²³
(40)
/²³ ~
² b ³¸= ²³ b ´ b   ²³µ°5¹


=
b
² b ³¸%²³ b = ²³ ²³°5


%
b
´ b   ²³µ ²³°5 ¹





b
² b ³¸&²³ b = ²³  ²³°5


&
b
´ b   ²³µ  ²³°5 ¹





The augmented performance index is given by
(41)  )


~
b
~ %²5³ b ´&²5³ c & µ


;

The discrete Euler-Lagrange equations are derived
from the Hamiltonian function:
(42)  

=
=
=
²³ ~ / ²³ ~
² b ³
b  ²³
² b ³°5 b   ²³
² b ³°5




%
&
(43)  

%
%
%
²³ ~ / ²³ ~
² b ³
(44)  

&
&
&
²³ ~ / ²³ ~
² b ³
It follows from the last two equations that the
multipliers 
 and 
 are constant. The final


%
&
²³
²³
conditions for the multipliers are obtained from the
augmented function .
)
(45)

)

 
=
=
=
=
²5³ ~
²5³ ~
²5³ b
²5³ ~ 

)

 
%
%
%
%
²5³ ~
²5³ ~
²5³ b
²5³ ~ 

)

 

&
&
&
&
²5³ ~
²5³ ~
²5³ b
²5³ ~
Since 
 and 
 are constant, they can be set equal


%
&
to their final values:
94
Y. Crispin

(46)  
,


%
%
²³ ~
²5³ ~ 



&
&
²³ ~
²5³ ~
With the values given in (46), the equation for = ²³
becomes
(47)





=
=
²³ ~
² b ³ b  ²³°5 b   ²³°5
with final condition
(48)  = ²5³ ~ 
The required control sequence 
is determined
²³
from the optimality condition
(49)
/ ²³ ~
² b ³ ²³°5c=²³ 
²³°




=
5 c   ²³°²5 ³ b  ² ²³³°²5 ³




b = ²³ ²³°5 b  ²³°²5 ³





b  ² ²³³°²5 ³ ~ 



= ² b ³ is determined by the adjoint equation (47)
and the Lagrange multiplier  is determined from

the terminal equality constraint 
.
&²5³ ~ &
5  AN EVOLUTIONARY
APPROACH TO OPTIMAL
CONTROL
We now describe the direct approach using genetic
search. As was mentioned in Sec. , there is no need
to solve the two-point boundary value problem
described by the state equations (33-35) and the
adjoint equation (47), together with the initial
conditions (36), the final condition (48), the
terminal constraint (37) together with the optimality
condition (49) for the optimal control 
. Instead,
²³
the direct evolutionary method allows us to evolve a
population of solutions such as to maximize the
objective function or fitness function 
. The
-²5³
initial population is built by generating a random
population 
of 
solutions 
, 
,
²³
  ´Á 5 c µ
uniformly distributed within a domain 
,


 ´ min



max
max
µ
~
°
. Typical values are
 and either



min
min
~ c
°
~ 
 or 
 depending on the
problem. The genetic algorithm evolves this initial
population using the operations of selection,
mutation and crossover over many generations such
as to maximize the fitness function:
(50)  - ²5³ ~
1²5³ b ² c
³1 ²5³



~
´ ²5³µ c ² c
³
´ ²5³µ ´ ²5³µ



 
 
 
,
T
with 
 and 
 and 
 given by:
  ´Á µ
1 ²5³
1 ²5³

(51)  1²5³ ~
´ ²5³µ ~ %²5³
 
(52)  1 ²5³ ~
´ ²5³µ ~ ²&²5³ c & ³




 
For each member in the population of solutions, the
fitness function depends on the final values %²5³
and 
, which are determined  by solving the
&²5³
initial value problem defined by the state equations
(33-35) together with the initial conditions (36).
This process is repeated over many generations.
Here, we run the genetic algorithm for a
predetermined number of generations and then we
check if the terminal constraint (52) is fulfilled. If
the constraint is not fulfilled, we can either increase
the number of generations or readjust the weight
  ´Á µ. After obtaining an optimal solution , we
can check the first order necessary conditions by
first solving the adjoint equation (47) with its final
condition (48). Once the control sequence is known,
the solution of (47-48) is obtained by direct iteration
backwards in time. We then check to what extent
the optimality condition (49) is fulfilled by
determining 
 for 
 and
/ ²³ ~ ²³
  ´Á 5 c µ

plotting the result as an error 
measuring the
²³
deviation from zero.
The results for the DVDP problem with gravity and
thrust, with 
 and the terminal constraint
 ~ À	
& ~ c À

 are shown in Figs.(1-3). A value of
 ~ À was used. Fig.1 shows the evolution of the
solution over 50 generations. The best fitness and
the average fitness of the population are given. In all
calculations the size of the population was 50
members.
     The control sequence 
, the velocity 
 and
²³
= ²³
the optimal trajectory are given in Fig.2 where the
sign of 
 is reversed for plotting. The trajectory
&
obtained here was compared to that obtained by
Bryson (Bryson, 1999) using a gradient method and
the results  are  similar.  In  Fig. 3 
we  plot 
the expression  for  
 as  given  by
/° ²³

the
 right-hand side of  Eq. (49). Ideally,  this  should
be equal to zero at every point . However, since we

95
An Evolutionary Approach to Nonlinear Discrete-Time Optimal Control

96
Y. Crispin
are not  using (49) to determine the control
sequence, we obtain a small deviation from zero in
our calculation. Finally, after determining the
optimal solution, i.e. after the control and the
trajectory are known, the adjoint variable 
  can
= ²³
be estimated by using Eqs.(47-48). The result is
shown in Fig.3.
0
10
20
30
40
50
-3.22
-3.2
-3.18
x 10
-3
Best  f
0
10
20
30
40
50
-3.5
-3
-2.5
-2 x 10
-3
Generations
Average  f
Figure 1: Convergence of the DVDP solution with gravity
and thrust,  
 and  terminal constraint 
 ~ À	
& ~ c À

0
10
20
30
40
50
60
-1
-0.5
0
0.5
1
i
gama / (pi/2)
10
20
30
40
50
60
0
0.2
0.4
0.6
i
V / g tf
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
-0.1
-0.05
0
0.05
0.1
x / (g tf
2)
y / (g tf
2)
the optimal trajectory for the DVDP problem with gravity

 ~ À	
& ~ c À
,  thrust 
and terminal constraint
.

10
20
30
40
50
60
-0.02
-0.01
0
0.01
0.02
i
e
10
20
30
40
50
60
0
0.5
1
1.5
i
LambdaV
optimality condition 
 from zero, and the
/ ²³ ~ ²³

adjoint variable 
 as a function of the discrete-time
= ²³
counter . DVDP with gravity and thrust, 
. Here

 ~ À	
6  CONCLUSIONS
A new method for solving the discrete-time optimal
control problem with terminal constraints was
developed. The method seeks the best control
sequence diretly by genetic search and does not
make use of the first-order necessary conditions to
find the optimum. As a consequence, the need to
develop a Hamiltonian formulation and the need to
solve a difficult two-point boundary value problem
for finding the adjoint variables is completely
avoided. This has a significant advantage in more
advanced and higher order problems where it is
difficult to solve the TPBVP with large systems of
differential equations, but when it is still easy to
solve the initial value problem (IVP) for the state
variables. The method was demonstrated by solving
a discrete-time optimal control problem, namely, the
DVDP 
or 
the 
discrete 
velocity 
direction
programming problem that was pioneered by Bryson
using both analytical and gradient methods. This
problem includes the effects of gravity and thrust
and was solved easily using the proposed approach.
The results compared favorably with those of
5 ~ 
 time steps.
À
The sign of & is reversed for plotting.
Figure 3:  The error ²³ measuring the deviation of the
Figure 2:  The control sequence ²³, the velocity = ²³ and

Bryson, 
who 
used 
analytical 
and 
gradient
techniques.
REFERENCES
Bryson, A. E. and Ho, Y. C., Applied Optimal Control,
Hemisphere, Washington, D.C., 1975.
Bryson, A.E., Dynamic Optimization, Addison-Wesley
Longman, Menlo Park, CA, 1999.
Coleman, T.F. and Liao, A., An efficient trust region
method for unconstrained discrete-time optimal
control problems, Computational Optimization and
Applications, 4, pp. 47-66, 1995.
Dunn, J., and Bertsekas, D.P., Efficient dynamic
programming implementations of Newton's method for
unconstrained optimal control problems, J. of
Optimization Theory and Applications, 63 (1989), pp.
23-38.
Fogel, D.B., Evolutionary Computation, The Fossil
Record, IEEE Press, New York, 1998.
Fox, C., An Introduction to the Calculus of Variations,
Oxford University Press, London, 1950.
Jacobson, D. and Mayne, D. , Differential Dynamic
Programming, Elsevier Science Publishers, 1970.
Kirkpatrick, and Gelatt, C.D. and Vecchi, Optimization
by Simulated Annealing, Science, 220, 671-680,
1983.
Laarhoven, 
P.J.M. 
and 
Aarts, 
E.H.L., 
Simulated
Annealing: 
Theory 
and 
Applications, 
Kluwer
Academic, 1989.
Liao, L.Z. and Shoemaker, C.A., Convergence in
unconstrained 
discrete-time 
differential 
dynamic
programming, IEEE Trans. Automat. Contr., 36, pp.
692-706, 1991.
Mayne, D., A second-order gradient method for
determining optimal trajectories of non-linear discrete
time systems, Intnl. J. Control, 3 (1966), pp. 85-95.
Michalewicz, Z., Genetic Algorithms + Data Structures =
Evolution Programs, Springer-Verlag, Berlin, 1992a.
Michalewicz, Z., Janikow, C.Z. and Krawczyk, J.B., A
Modified Genetic Algorithm for Optimal Control
Problems, Computers Math. Applications, 23(12), pp.
83-94, 1992b.
Murray, D.M. and Yakowitz, S.J., Differential dynamic
programming and Newton's method for discrete
optimal control problems, J. of Optimization Theory
and Applications, 43, pp. 395-414, 1984.
Ohno, K., A new approach of differential dynamic
programming for discrete time systems, IEEE Trans.
Automat. Contr., 23 (1978), pp. 37-47.
Pantoja, J.F.A. de O. , Differential Dynamic Programming
and Newton's Method, International Journal of
Control, 53: 1539-1553, 1988.
Pontryagin, L. S. Boltyanskii, V. G., Gamkrelidze, R. V.
and Mishchenko, E. F., The Mathematical Theory of
Optimal Processes, Moscow, 1961, translated by
Trirogoff, K. N. Neustadt, L. W. (Ed.), Interscience,
New York, 1962.
Schwefel H.P., Evolution and Optimum Seeking, Wiley,
New York, 1995.
Yakowitz, S.J.,  and Rutherford, B., Computational
aspects of discrete-time optimal control, Appl. Math.
Comput., 15 (1984), pp. 29-45.
97
An Evolutionary Approach to Nonlinear Discrete-Time Optimal Control

A DISTURBANCE COMPENSATION CONTROL FOR AN 
ACTIVE MAGNETIC BEARING SYSTEM BY A MULTIPLE 
FXLMS ALGORITHM 
Min Sig Kang
Department of mechanical engineering, Kyungwon University, Sungnam, Kyunggido, KOREA 
Email: mskang@kyungwon.ac.kr 
Joon Lyou
Dept. of  Electronics Eng., Chungnam National Univ., Daejeon 305-764, KOREA 
Email: jlyou@cnu.ac.kr 
Keywords: 
Active magnetic bearing, Multiple filtered-x least mean square algorithm, Acceleration feedforward 
compensation. 
Abstract: 
In this paper, a design technique is proposed for a disturbance feedforward compensation control to 
attenuate disturbance responses in an active magnetic bearing system, which is subject to base motion. To 
eliminate the sensitivity of model accuracy to disturbance responses, the proposed design technique is an 
experimental feedforward compensator, developed from an adaptive estimation, by means of the Multiple 
Filtered-x least mean square (MFXLMS) algorithm. The compensation control is applied to a 2-DOF active 
magnetic bearing system subject to base motion. The feasibility of the proposed technique is illustrated, and 
the results of an experimental demonstration are shown. 
1 INTRODUCTION 
Active magnetic bearing (AMB) systems are 
increasingly used in industrial applications. Unlike 
conventional 
bearings, 
AMB 
systems 
utilize 
magnetic fields to levitate and support a shaft in an 
air-gap within the bearing stator. When compared to 
conventional mechanical bearings, AMB offers the 
following 
unique 
advantages: 
non-contact, 
elimination of lubrication, low power loss, and 
controllability of bearing dynamic characteristics.  
Recently, interest has increased regarding the 
application 
of 
AMB 
systems 
to 
the 
sight 
stabilization systems mounted on moving vehicles. 
When a vehicle is undergoing angular motion, the 
mirror axis of sight rotates relative to the vehicle, to 
stabilize the line of sight. In such systems, the 
friction of mechanical bearings that support the 
mirror axis may cause tracking errors and, hence, 
may deteriorate the quality of an image obtained 
through electro-optical equipment. To eliminate the 
undesirable effects of friction, an AMB system is 
used instead of mechanical bearings. 
The main problem of a sight system levitated 
and stabilized by an AMB is the image scattering 
caused by base motion. One solution for reducing 
the effects of base motion is to expand the 
bandwidth of the control system by using feedback 
controls (Cole, 1998) such as PID control, state 
feedback control, 
f
H
control, and so on. A 
controller with a wider bandwidth, however, 
requires a higher sampling frequency, which often 
induces a mechanical resonance.  
An 
alternative 
approach 
for 
disturbance 
attenuation is a feedforward compensation of the 
base acceleration. The effectiveness of this approach 
has been demonstrated in the field of hard disk 
drives, which are also subject to base motion 
(Jinzenji, 
2001). 
Suzuki 
(1998) 
developed 
feedforward compensation based on a dynamic 
model of the AMB system and showed that 
increases in the vibration rejection can be achieved. 
In practice, however, a dynamic model is not 
reliably accurate, because of many problems 
associated with it, such as the non-linearity of AMB, 
approximation errors of the discrete equivalent to a 
continuous transfer function, and sensor dynamics.  
Motivated to overcome these problems, in this 
work an alternative technique is proposed: a non-
model based acceleration feedforward compensation 
control developed from an adaptive estimation, by 
means of the multiple filtered-x least mean square 
© 2006 Springer. Printed in the Netherlands.
99
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 99–104. 

(MFXLMS) algorithm (Kuo, 1996; White, 1997). 
The performance and the effectiveness of the 
proposed technique are demonstrated on a 2-DOF 
AMB system subject to base motion.
2 SYSTEM MODEL 
The test rig used in this paper is an AMB system of 
2-DOF shown in Fig. 1. Figure 2 is the photograph 
of the test rig. The test rig consists of two sets of 
AMB(left AMB: AMB-1, right AMB:AMB-2) and a 
circular shaft. Each end of the shaft is tied up by 
string wire such that the shaft moves only in the 
vertical plane. Each electromagnet is attached rigidly 
to each shaker(B&K-4808), which generates base 
motion resembling the vehicle motion. Two non-
contacting proximity displacement sensors(AEC-
5505) measure each air gap between the probe tip 
and the shaft surface, and the vertical acceleration of 
each 
electromagnet 
is 
measured 
by 
each 
accelerometer(Crossbow, CX04LP1Z).  
Displacement
     Sensor
Accelerometer
Shaker 2
Shaker 1
- I
1i
Io 
1i
Io 
2i
Io 
2i
Io 

From the free-body diagram of the system in Fig. 
1
2
1
2
1
2
1
2
2
1
2
1
2
1
2
1
2
1
2
4
4
1
1
2
y
y
z
z
y
y
z
z
m
J
y
y
z
z
y
y
z
z
a
f
mg
f







­
½
­

®
¾
®






¯
¿
¯
­
½
­ ½

 
® ¾
®
¾
¯ ¿
¯
¿
















½
¾
¿   (1) 
where m and J are the mass and the mass moment of 
inertia about the mass center of the shaft. y ,
and
z
f  mean the air gap, the vertical acceleration and the 
actuating force, respectively. The subscripts 1 and 2 
denote the positions of the AMB-1 and the AMB-2, 
respectively. This definition is consistent hereafter. 

z1
z2
y1
y2
f1
f2
a
a
J
The magnetic attractive force is approximately 
proportional to the square of the coil current and 
inversely proportional to the square of gap. However 
the nonlinearity of the magnetic attractive force 
against the coil current is decreased with the bias 
current added to the coil current. Consequently the 
linearized model is given by  
c
d
i c
f
K y
K i
 

(2)  
             
 
where 
y  is the displacement stiffness and 
 is 
the current stiffness. 
K
i
K
 Since the time constant of the power amplifier-
magnet coil can be designed to be small enough by 
current feedback control, the control current ci  can 
be assumed to be proportional to the applied voltage, 
, to the amplifier, i.e. 
cu
c
a
i
K u
 
c
(3)  
 
         
 
where 
 is the gain of the amplifier.  
a
Substituting eqs. (2) and (3) into eq. (1) gives the 
linearized AMB system model as follows: 
K
2
2
1
2
1
1
2
2
2
2
1
2
2
2
1
2
1
1
2
2
2
2
1
2
(
)
(
)
1
(
)
(
)
(
)
(
)
(
)
(
)
d
d
d
d
i
i
a
i
i
K
J
ma
K
J
ma
y
y
y
y
mJ
K
J
ma
K
J
ma
K
J
ma
K
J
ma
u
z
g
K
u
z
g
mJ
K
J
ma
K
J
ma
ª
º


­
½
­
½
«
»

®
¾
®
¾
«
»


¯
¿
¯
¿
¬
¼
ª
º



­
½
­
½
«
»
 

®
¾
®
¾

«
»


¯
¿
¯
¿
¬
¼




 (4)  
100
Figure 2: Photograph of test rig. 
Figure 3: Free-body diagram of the levitated axis. 
3, the equation of motion is given by. 
Figure 1: Schematic diagram of test rig. 
M.S. Kang and J. Lyou

It is clear from eq.(4) that the system is open-
loop unstable, and the base acceleration and the 
gravitational force disturb the system. 
3 CONTROLLER DESIGN 
The system model in eq. (4) can be represented by 
the state space equation as  
g
a
f
d
Bu
Aq
q



 

  
 
 
 
 
 
      (5) 
^
`
1
2
1
2
T
q
y
y
y
y
 


,
^
`
T
u
u
u
2
1
 
1
2
0 0
T
a
d
z
z
 ª
º
¬
¼
 
,
0 0
T
gf
g g
 ª
º
¬
¼
  
 
    (6) 
Since this system has no integrator, the state 
feedback control with integral is applied to eliminate 
the steady state error due to the gravity force.  
K
ik
Kq
u


 
 
(7) 
where K and 
ik  are the state feedback gain vectors, 
and K  is the integration of y1 and y2, i.e., 
.
^
`
1
2
T
y
y
K  

The feedback gains in eq. (7) can be design from 
various kinds of schemes. The closed-loop system 
stabilized by eq. (7) can be represented in discrete 
time domain as  
1
1
1
1
1
11
1
12
2
1
1
11
1
12
2
1
1
1
2
2
21
1
22
2
1
1
21
1
22
2
(
)
( )
(
)
( )
(
)
( )
(
)
( )
(
)
( )
(
)
( )
(
)
( )
(
)
( )
(
)
( )
(
)
( )
A q
y k
B
q
u k
B
q
u
k
C
q
d k
C
q
d
k
A q
y
k
B
q
u k
B
q
u
k
C
q
d k
C
q
d
k










 



 



  (8) 
where  variables with the index k mean the sampled 
variables. 
1
(
)
iA q
,
1
(
ij
B
q
)

 and 
 are the 
system polynomials. 
is the one step delay 
operator. 
1
(
)
ij
C
q
1

q
A general compensator for the system in eq.(8) is 
defined by 
1
1
1
11
1
12
2
1
1
2
21
1
22
2
( )
(
)
( )
(
)
( )
( )
(
)
( )
(
)
( )
u k
W
q
d k
W
q
d
k
u
k
W
q
d k
W
q
d
k




 

 

 
   (9) 
Applying the compensator, eq. (9), to the system, 
eq. (8), yields the compensated system of the form 
1 1
11 11
12
21
11
1
11 12
12
22
12
2
( )
( )
( )
A y k
B W
B W
C
d k
B W
B W
C
d
k
 


ª
º
¬
¼



ª
º
¬
¼
2 2
21 11
22
21
21
1
21 12
22
22
22
2
( )
( )
( )
A y
k
B W
B W
C
d k
B W
B W
C
d
k
 


ª
º
¬
¼



ª
º
¬
¼
 
  (10)
Obviously, the perfect disturbance cancelling 
compensators 
, 
, 
, 
are derived from  
*
11
W
*
21
W
*
12
W
*
22
W
*
11
*
21
*
12
*
22
W
W
W
W
­
½
°
°
°
°
°
°  
®
¾
°
°
°
°
°
°
¯
¿
22 11
12 21
21 11
11 21
22 12
12 22
11 22
12 21
21 12
11 22
1
B
C
B C
B C
B C
B
C
B C
B B
B B
B C
B C

­
½
°
°


°
°
®
¾


°
°
°
°


¯
¿
 
(11)
Since the compensators given in eq. (11) are 
designed from the system model, the compensation  
performance should be sensitive to the accuracy of 
the model. In practice, however, this kind of perfect 
cancelling based on the model is not expected 
because of the problems such as inaccuracy of 
dynamic model, approximation error of a discrete 
equivalent to a continuous transfer function, and 
sensor dynamics. Motivated by these problems, an 
explicit optimal feedforward compensator design 
technique is proposed in this paper. By this 
technique, the feedforward compensator design can 
be separated into two parts. 
1) Disturbance cancelling control for single 
harmonic base motion 
It is clear from eq. (11) that the response to a 
harmonic base motion of the frequency 
r
Z can be 
exactly nullified by choosing the polynomial 
1
(
)
ij
W
q
as the first order polynomial satisfying the 
relation 
1
2
1
*
, ,
1,2
jw T
jw T
r
r
ij
ij
ij
ij
q e
q e
W
w
w q
W
i j

 
 
ª
º
 

 
 
¬
¼
  (12)
where 
is the sampling interval. 
T
Nullifying 
disturbance 
response 
by 
using 
feedforward 
compensator 
means 
physically 
matching the impedance from the base motion to the 
air-gap with the impedances from the base motions 
to the air-gaps through the AMB dynamics and of 
the 
feedforward 
compensators, 
so 
that 
the 
disturbance can be perfectly cancelled. However 
compensator design from the model is not suitable 
for practical applications. To get rid of the problems 
associated with the inaccurate model, adaptation of 
the feedforward compensator is proposed. This 
technique is an explicit design through experiments 
by using a multiple-FXLMS algorithm. The FXLMS 
101
An Active Magnetic Bearing System by  a Multiple FXLMS Algorithm

1985)). Figure 4 shows an example of the multiple-
FXLMS algorithm to estimate the compensator 
polynomial 
. 
The 
parameters 
of 
the 
compensators are estimated from the following 
update equation. 
*
11
W
Figure 4: MFLMS algorithm for estimating 
).
(
1
11

q
W
1
1
1
1
1
2
2
1
2
2
2
2
2
2
ˆ ( )
ˆ
(
1)
( )
(
1)
( )
( )
(
1)
( )
ˆ ( )
ˆ (
1)
( )
( )
ˆ
ˆ
ˆ
ˆ
( )
( )
(
1) ,
( )
( ), , ,
1
ˆ
j
i
j
ij
ij
i
ij
j
ij
ij
i
j
i
j
i
ij
j
i
ij
m
m
m
m
ij
ij
ij
ij
m
i
d
k
w
k
w
k
d
k
y k
D
k
w
k
w
k
d
k
d
k
y
k
D
k
B
D
k
d
k
d
k
d
k
d
k
i j m
A
P
K
­
½
°
°
®
¾
­
½
­
½
°
°


°
°
°
°
¯
¿
 

®
¾
®
¾
°
°
°
°

¯
¿
¯
¿
­
½
°
°
®
¾
°
°

¯
¿

 


 
 ,2
  (13) 
where 
ij
P and
ij
K are the update gains, 
1
ˆ (
)
iA q
 and  
are the estimated system polynomials.  All 
the 
compensator 
polynomials 
are 
estimated 
simultaneously from eq. (13). 
1
ˆ (
)
ij
B
q
By applying the MFXLMS algorithm meanwhile 
the exciters generate a stationary single harmonic 
base motion, the control parameters 
 and 
 in 
eq. (13) are estimated.  
1
ij
w
2
ij
w
Since the base motion is single harmonic of 
frequency 
r
Z , the Fourier transforms 
1(
r)
D
jZ
 and 
2(
r)
D
jZ
of 
 and 
 , respectively, would yield the 
relation 
1
2
r
1
d
2
d
(
)
(
r
)
D
j
D
j
Z
D
Z
 
, where D is a complex 
number which represents the magnitude and phase 
relations between 
1
d
 and 
2.  The estimated 
polynomials are not unique but satisfy two 
independent relations in the following 
d
*
*
11
12
11
12
1
*
*
2
21
22
21
22
ˆ
ˆ
ˆ
ˆ
W
W
W
W
W
W
W
W
E
D
D
E
­
½
­
½
­
½
­
½
­
½
°
°
°
°
°
°
°
°

 

 
®
¾
®
¾
®
¾
®
¾
®
¾
¯
¿
°
°
°
°
°
°
°
°
¯
¿
¯
¿
¯
¿
¯
¿
      (14) 
Thus it is necessary to have at least two sets of 
polynomials estimated from the experiments where 
1  and 
2  have the same frequency but have 
different relations. For example, if a set of 
polynomials is estimated from the experiment where 
1
d
d
D
D
 
 then one can determine 
1
E  and 
2
E  from 
1
11
12
1
1
1
2
21
22
ˆ
ˆ
ˆ
ˆ
W
W
W
W
E
D
E
­
½
­
½
­
½
°
°
°
°
°
°

 
®
¾
®
¾
®
¾
°
°
°
°
°
°
¯
¿
¯
¿
¯
¿
 
(15) 
1
11
ˆ
ˆ
A
B
2
21
ˆ
ˆ
A
B
MFXLMS 
)
(
1 k
y
)
(
2 k
y
)
(
11 k
u
)
(
ˆ1
11 k
d
)
(
ˆ1
21 k
d
1
2
11
1
11
1
11
)
(
ˆ



 
q
w
w
q
W
1( )
sin
r
d k
M
k
T
Z
 
Similarly, from another set of estimated 
polynomials obtained from another experiment 
where 
2
1
D
D
D
 
z
,
1
E  and 
2
E  are obtained as 
2
11
12
1
2
2
2
21
22
ˆ
ˆ
ˆ
ˆ
W
W
W
W
E
D
E
­
½
­
½
­
½
°
°
°
°
°
°

 
®
¾
®
¾
®
¾
°
°
°
°
°
°
¯
¿
¯
¿
¯
¿
 
(16) 
From 
eqns. 
(14)-(16), 
the 
compensator 
polynomials that perfectly cancel any stationary 
harmonic 
base 
disturbance 
of 
the 
specified 
frequency 
r
Z  can be determined as 
*
1
1
11
1
1
*
1
21
1
2
*
2
12
1
*
2
2
22
2
0
1 0
0
0 1
0
1 0
0
0 1
W
W
W
W
2
E
D
D
E
D
E
D
E

­
½
­
ª
º
½
°
°
°
«
»
°
°
°
°
°
°
°
«
»
 
°
°
®
¾
«
»
®
¾
°
°
°
«
»
°
°
°
°
«
»
¬
¼
°
°
°
°
¯
¿
¯
¿°
j  
 
(17) 
Repeating the above experimental procedures by 
changing the base motion frequency, sets of perfect 
cancelling compensator polynomials for each 
frequency are obtained. 
2) Model fitting  in frequency domain 
From the sets of compensator parameters for each 
specified frequency, the FRF(frequency response 
function) of the disturbance cancelling feedforward 
compensators can be calculated. Based on this FRF, 
the compensators in eq. (9) are determined so as to 
minimize the cost function J


2
*
1
1
1
ˆ
(
)
(
)
, ,
1,2
j
T
k
n
ij
ij
k
ij
ij
q e
k
J
W
q
W
q
i
Z
O
Z


 
 
ª
º
 

«
»
¬
¼
¦
(18) 
where 
lm
k
(
)
O
Z
W
q
is the frequency weighting and 
lm
*
1
ˆ
(
)

is the estimated compensator obtained in 
the first step and 
lm
W
q 1
(
)

is the compensator to be 
determined. 
To 
avoid 
unstable 
compensator, 
lm
1
(
)
W
q
can have the form of FIR(finite impulse 
response) filter. 
102
eq. (14) as
M.S. Kang and J. Lyou
algorithm has been extensively used in the field of 
active noise control(Kuo, 1996; Widrow and Stearns, 

4 EXPERIMENTS  
To verify the effectiveness of the proposed control 
scheme, experiments were conducted using the test 
apparatus shown in Fig. 2. All control algorithms 
were implemented on a digital computer equipped 
with a DSP(TI-DS-1104)) board. Throughout the 
experiments, the sampling frequency was kept at 
2000Hz. 
A pole placement feedback (FB) control was 
designed to have a closed-loop system with a 
damping ratio of 
8.0
 
9
 and natural frequency of 
80
n
Hz
Z  
 in 
consideration 
of 
the 
spectral 
characteristics of the base motion. The vehicle 
motion is characterized by a band-limited random 
process of bandwidth 15Hz-60Hz.  
To evaluate the convergence of the estimated 
compensator parameters and the corresponding 
disturbance rejection performance, a sequence of 
simple harmonic of frequency 30Hz was delivered to 
the shakers. The resultant base motion kept the 
relation 
1
2
(
)
1.023
(
)
D
j
D
j
Z
Z
 
.
Figs. 5 and 6 show the estimated compensator 
parameters of 
11
W
and the corresponding air-gap 
responses, respectively. We confirmed that all 
estimated parameters converged to their final values 
after 50 s. These figures reveal that the air-gap 
responses were consequently reduced, as the 
estimated parameters converged to their final values. 
The aforementioned convergence property and the 
disturbance rejection performance exhibit the 
feasibility of the proposed compensation control by 
means of the MFXLMS algorithm.  
ˆ
As explained in the above, at least, one more set 
of compensator parameters is necessary to determine 
the unique compensator polynomials which cancel 
the disturbance responses  perfectly at 
30
f
Hz
 
.
The MFXLMS algorithm was applied to obtain 
another set of compensator parameters under the 
different base motion profile kept the relation 
1
2
/ 2
(
)
1.465
(
)
j
D
j
e
D
j
S
Z
Z
 
,
30
f
Hz
 
.
 
Similar 
convergence and disturbance rejection properties to 
Figs. 6 and 7 were confirmed. 
From the two sets of the parameters obtained, the 
FRF of the disturbance neutralizing compensator at 
30
f
Hz
 
 was determined. The disturbance rejection 
performance of this compensator was evaluated 
under the base motion yielding the relation 
/ 4
1
2
(
)
D
j
0.69
(
)
j
e
D
j
S
Z
Z

 
,
30
f
Hz
 
.
Fig. 7 shows the air-gap responses of the FB-
control by itself and the FB with the compensation 
control. Fig. 7 reveals that the compensation control 
can almost neutralize any base motion responses of 
frequency 30Hz. Surprisingly, it was found that the 
control effort is reduced when the compensation was 
employed. The air-gap responses that remained after 
employing the compensation came mainly from the 
inability of the shakers to produce a pure sinusoidal 
tone of motion. 
Repeating the experiment, while changing the 
harmonic base motion frequency, sets of disturbance 
neutralizing compensator parameters for each 
frequency were obtained. The FRF 
11
W
 calculated 
from the estimated parameters is shown as an 
example in Fig. 8. Based on the FRF in Fig. 8, the 
best-fit compensator was determined to be the third-
order polynomials.  
ˆ
Figure 5: Estimated coefficients of W
.
)
(
1
11

q
Figure 6: Air-gap responses during estimation by 
To investigate the efficiency of the designed 
compensator, a comparison was made between the 
air-gap response with the compensation and without 
the compensation. During the control experiments, a 
sequence of band-limited random signals of 
bandwidth 15-60Hz was delivered to the shaker and 
the resultant base motion resembled that of the real 
vehicle.  
As shown in Fig. 9, the air-gap responses were 
greatly reduced by applying the feedforward 
103
An Active Magnetic Bearing System by  a Multiple FXLMS Algorithm
MFXLMS algorithm. 
Figure 7: Compensated air gap responses. 

compensation. For y1, the standard deviations of the 
air-gap 
with 
compensation 
and 
without
 
compensation were calculated to be 
and
,  respectively. For y2, the standard deviations 
of the air-gap with compensation and without 
compensation were calculated to be
 and 
,  respectively. The control voltages were 
slightly reduced after employing compensation. 
Figure 10 shows the spectra of the air-gap responses 
in Fig. 9. The disturbance attenuation ratio is 
approximately–20db within the frequency band of 
the base motion.
m
P
V
53
.
14
 
m
P
43
.1
m
P
V
13
.
13
 
Figure 8: Measured and fitted FRF of ˆW
Figure 10: Spectra of air-gap with and without 
5 CONCLUSION 
In 
this 
work, 
an 
experimental 
feedforward 
compensator design technique, developed from an 
adaptive estimation by means of the Multiple 
Filtered-x least mean square (MFXLMS) algorithm 
has been proposed. The feasibility of the proposed 
technique has been verified by an experimental 
study, by using a 2-DOF active magnetic bearing 
system subject to base motion. The experimental 
results showed that the standard deviation of the 
compensated response was reduced to less than 10% 
of that by feedback control alone. 
ACKNOWLEDGEMENTS 
This work was supported by grant no.( R01-2003-
000-10857-0) from the Basic Research Program of 
the Korea Science & Engineering Foundation.   
REFERENCES
Brunet, M., 1998. Practical Applications of Active 
Magnetic Bearing to the Industrial World. 1’st 
International Symposium on Magnetic Bearing. Zurich, 
Cole, M. O. T., Keogh, P. S. and Burrows, C. R. ,  1998. 
Control 
and 
Non-linear 
Compensation 
of 
a 
Rotor/Magnetic Bearing System Subject to base 
Motion. 6th Int. Symposium on Magnetic Bearings.
Jinzenji, A., Sasamoto, T., Aikawa, K., Yoshida, S. and 
Aruga, K., 2001. Acceleration feedforward control 
Against Rotational Disturbance in hard Disk Drives. 
Kasada, M.E., Clements, J., Wicks, A. L., Hall, C. D., and 
Kirk, R. G., 2000, Effect of sinusoidal base motion on 
a 
magnetic 
bearing, 
Proc. 
IEEE 
International 
Conference on Control Applications, pp. 144-149. 
Kuo, S. M. and Morgan, D. R., 1996. Active Noise Control 
Systems. A Wiley-Interscience Publication, John Wiley 
Sons, Inc. 
Suzuki, Y., 1998. Acceleration Feedforward Control for 
Active Magnetic Bearing Excited by Ground Motion.
Wang, A.K. and Ren, W., 1999, Convergence analysis of 
the multiple-variable filtered-x LMS algorithm with 
application to active noise control, IEEE Trans. On 
Signal Processing, Vol. 47, No. 4, pp. 1166-1169. 
White, M. T. and Tomizuka, M., 1997. Increased 
Disturbance Rejection in Magnetic Disk Drives by 
Acceleration Feedforward Control and Parameter 
pp. 741-751.
Widrow, B. and Stearns, S. D., 1985. Adaptive Signal 
Processing. Prentice Hall. Englewood Cliffs, NJ. 
104
1.08Pm
Figure 9: Air-gap responses w/ and w/o compensation. 
11.
compensation.
pp. 225-244.
Cambridge, MA, pp. 618-627. 
M.S. Kang and J. Lyou
IEEE Trans. On Magnetics. Vol. 37, No. 2, pp. 888-893. 
Adaptation. Control Engineering Practice. vol. 5, no. 6. 
IEEE Proc. Control Theory Appl. Vol. 145, pp. 113-118. 

AN INTELLIGENT RECOMMENDATION SYSTEM BASED ON 
FUZZY LOGIC 
Shi Xiaowei
Philips (China) Investment Co.,Ltd. Shanghai R&D Centre 
38F,Tower1 Kerry Everbright City     218 Tian Mu Xi Road     Shanghai, P.R.C.200070 
Email: nancy.shi@philips.com    Tel.: 86-21-63541088-5917      Fax: 86-21-63544954 
Keywords: 
Recommendation, User profile, Fuzzy-logic, Multi-agent, Metadata  
Abstract: 
An intelligent recommendation system for a plurality of users based on fuzzy logic is presented. The 
architecture of a multi-agent recommendation system is described. How the system simulates human 
intelligence to provide recommendation to users is explained. The recommendation system is based on the 
fuzzy user profile, fuzzy filtering and recommendation agents. The user profile is updated dynamically 
based on the feedback information. Fuzzy logic is used in fuzzy filtering to integrate different types of 
features together for a better simulation of human intelligence. Ambiguity problems can be solved 
successfully in this system, e.g., deducing whether a programme with both interesting features and 
uninteresting features is worth recommending or not. The application scenario shows that it is more 
convenient for users to find programmes of their interest with the proposed recommendation system. 
1 INTRODUCTION 
Due to the digitalisation of television, in the near 
future we will be able to receive hundreds of 
channels via satellites, terrestrial antenna, cable and 
even phone lines. At the same time, it is becoming 
increasingly challenging for television viewers to 
identify television programmes of their interest. 
Recommendation systems, such as TV-Advisor, 
Personal TV, etc, have been studied to help viewers 
to find, personalize, and organize the contents 
[1,2,3,4,5]. 
The following recommendation process is 
considered: matching Electronic Programme Guide 
(EPG) metadata to the user preference knowledge, 
filtering 
out 
the 
tedious 
programmes 
and 
recommending interesting programmes to users, and 
updating the user profiles based on feedback 
information. 
The traditional methods to evaluate if a 
programme is good enough to be recommended are 
based on the explicit (i.e. non-fuzzy) inference. In 
other words, the programme evaluation result can 
either be “interesting” or “non-interesting”. As we 
know, explicit mathematics cannot intelligently 
simulate human’s flexible inference. Especially, it is 
difficult to decide whether a programme with both 
interesting features and uninteresting features should 
be recommended by the existing filtering and 
recommendation methods. 
This paper presents an algorithm about the 
integration of fuzzy logic into a multi-agent 
recommendation system to better recommend 
interesting programmes to users. The architecture of 
the fuzzy recommendation system is described. 
Moreover, the reason why fuzzy logic is adopted in 
the recommendation system is explained. The fuzzy 
recommendation algorithm is also developed. 
Finally, the recommendation process is illustrated 
with an example. 
2 RECOMMENDATION SYSTEM 
2.1 System Architecture  
The recommendation system is provided to generate 
programme recommendations for multiple users 
based on programme metadata and user profiles. The 
architecture of this system is illustrated in Figure 1. 
The system uses a central recommendation server 
unit that includes a Fuzzy User Profile Database, 
Fuzzy Filtering Agent, Fuzzy Recommendation 
Agent, Profiling Agent, and Interface Agent.  
105
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 105–109. 

Figure 1: System architecture.
x
Fuzzy Filtering means to gather and make the
incoming live programme broadcasted based on
programme metadata match to fuzzy user
profiles, which is based on fuzzy logic, and then
filter the programmes based on fuzzy threshold;
x
Fuzzy Recommendation generates an optimal
recommendation list to every user according to
the learned user preference knowledge, and
transmits it to user terminals;
x
Profiling updates the user profile based on both
the explicit and implicit feedback information
from the Interface Agent;
x
The Interface Agent handles the interactions
with the user. 
2.2 Information Description
In the context of TV-Anytime [7], metadata consists
of two kinds of information: (a) content description
metadata; (b) consumer metadata. Programme
content description metadata includes attributes of a
television programme, such as the title, genre, list of
actors/actresses, language, etc. These data are used
to make a search.
The user profile metadata in this system defines
the details of a user’s preferences and aversion.
These descriptions are closely correlated with media
descriptions, and thus enable the user to search, 
filter, select and consume the desired content
efficiently.
2.3 Application of Fuzzy Logic 
Control Theory in a 
Recommendation System 
There are many factors that influence a user if he/she
wants to view a programme or not. The user’s
attitude to a programme is the result of some
complicated reaction. In other words, it is difficult
for a user to describe their emotion about a 
programme in quantity. Fuzzy theory can simulate
human intelligence. It owns the advantage of
describing this kind of indefinite object, providing a
possibleway to solve theproblem. Hence, fuzzy
5HFRPPHQGDWL RQ3URFHVV
8VHU
3URJUDPV0HWDGDWD
)X]]\8VHU3URIL O H'DWDEDVH
)X]]\)L O WHUL QJ$JHQW
)X]]\5HFRPPHQGDWL RQ$JHQW
5HFRPPHQGDWL RQ
/L VW
)HHGEDFN
,QIRUPDWL RQ
3URIL O L QJ$JHQW
,QWHUIDFH$JHQW
.QRZO HGJH EDVH
'HI X]]L I L FDW L RQ
'HFL VL RQ
PDNL QJ
)X]]L I L FDW L RQ
3URFHVV
L QSXW
RXW SXW
)X]]\
Figure 2: General structure of fuzzy inference system .  
theory
 is used in programme recommendation in this paper.
Fuzzy theory includes a series of procedures for 
representing
set 
membership, 
attributes, 
and
relationships that cannot be described by single point
numeric estimates. The structure
of a fuzzy
inference system is shown in Figure 2. 
Where,
Knowledge base: parameters of membership
functions and definitions of rules;
Fuzzification: transformation of crisp inputs
into membership values;
Decision-making: fuzzy inference operations on 
the rules;
Defuzzification: transformation of the fuzzy
result of the inference into a crisp output
3 FUZZY RECOMMENDATION
3.1 Fuzzy Information Database
3.1.1 The Fuzzy User Profile 
The user profile, UP, can be represented by a vector 
of these 3-tuples. If there are 
 distinct terms in the
profile, it will be represented by:
m
))
,
,
(
).....,
,
,
),....(
,
,
((
1
1
1
m
m
m
i
i
Where:
 is a term;
i
ld  is the “Like_degree” of 
term
i ;
i  is the Weight of term
; i  is the order of
 in the profile.
i
(3-1)
w
ld
t
w
ld
t
w
ld
t
UP  
it
t
w
it
it
The fuzzy user profile transforms the crisp 
parameters 
(“Like_degree”,
Weight) 
into
membership values.
“Like_degree” means the 
degree the user likes a feature. The shape and
location may be different for different problems. If
1 and
2 represent “Like_degree” and “Weight”
respectively, the fuzzy memberships can be
described as Figure 3. It is known from Figure 3 that
e
e
Figure 3: The fuzzy membership function of user profile. 
106
S. Xiaowei

2e  is always greater than 0. A larger
2  indicates
that this feature is more important. When
1
, it 
means “like” and a larger
1means the user likes the
feature more; if
1
, it indicates that the user 
“dislike” this feature and the smaller
, the more
the user dislikes it.
e
0
ุ
e
e
t
t
t
t
C  
e
0
ื
1e
3.1.2 EPG Metadata
A programme can be represented by a vector of size
n
)
,...
,...,
,
(
2
1
n
i
Where
is the i
(3-2)
it
th feature of the programme.
3.2 Similarity Matching
The Fuzzy Filtering Agent calculates the similarity
between the programme and the user profile. If the
calculated similarity is above the preset threshold,
the user is considered to be interested in the
programme; then the
programme
metadata is
transferred to the Recommendation Agent.
In this system, the fuzzy similarity matching
process can be divided into two steps:
x
Feature matching;
x
Programme matching.
3.2.1 Feature Matching
Feature matching decides how a feature of a
programme is related to a user’s preference. In order
to get the feature “interest_degree”᧨ the procedures
is executed as shown in Figure 2. 
Here, Like_degree and Weight are set as input
and the feature of “interest_degree”, which means
how much a user likes the programme, is set as 
output.
The step of decision making is based on the
fuzzy inference rules such as following,
I.If Like_degree is “dislike” And Weight is 
“secondary“ Then
 is “disgusted”;
i
II.If Like_degree is “dislike” And Weight is
“important” Then
 is “very disgusted”;
f
i
III.If Like_degree is “neutral” And Weight is 
“important” Then
 is “neutral”;
f
if
…
The method of “centre of gravity” takes more
useful factors into consideration. It is adopted in this
system to defuzzicate the feature’s interest_degree.
3.2.2 Programme Matching
Programme matching is to evaluate the programme
interest_degree. It can be calculated by the average
interest_degree of the features related with the
programme.
3.3 Filtering & Ranking 
Next step is to set a threshold to filter the coming
programme
metadata, 
select 
the 
interesting
programme, and then rank and recommend them
based on the programme interest_degree. In this
system, ranking and recommendation processes are
performed by the Fuzzy Recommendation Agent.
A threshold is set in the Fuzzy Filtering Agent.
The threshold can be a crisp value, or a fuzzy value
such as “how much does the user like”. If the
programme interest_degree is greater than the
threshold, which means the programme is what the
user wants to watch, then the Filtering Agent will 
transfer the programme metadata to the Fuzzy
Recommendation Agent.
Based 
on 
the 
learned 
user 
preference
knowledge, the Fuzzy Recommendation Agent
generates an optimal recommendation list and sends 
it to the user according to interest_degree.
3.4 Profiling Agent
In the system, the feedback can be explicitly given
by the user or implicitly derived from observations
of the users’ reaction to a recommended programme.
So, the Profiling Agent revises the user profile based
on
both the explicit and implicit feedback
information. In this section, how to update the user
profile by the implicit feedback information is
mainly explained.
For a recommended
programme, the
user
always has two attitudes to it: skipping over, or
watching. In other words, the user will skip (delete)
the 
programme 
he/she 
dislikes,
watch 
the
programme he/she likes or he/she is not sure. If the
user has watched the programme for a period of
time, the user’s profile will be refined and revised
based on the viewing behaviour.
In this system, for programme
, the algorithm
for updating user profile is depicted as follows:
i
i
i
i
i
RD
WD
Weight
t
Weigh
)
-
(
T
D x

 
c
(3-3)
107
An Intelligent Recommendation System Based on Fuzzy Logic
dislike neutral
like
secondary
neutral
important
0
-0.5-0.25
0
0.25 0.5
0
0.25 0.5 0.75
1
e2(W)
e1(ld )
1

i
i
i
i
RD
WD
e
Like_degre
e
Like_degre
)
-
(
T
E x

 
c
(3-4)
Where,
i : The time duration watched;
i : The real time duration of the
programme;
WD
RD
T : The threshold of the time duration. If 
i is less than
WD
T , that means the user is 
not interested in that programme;
D and E : are less than 1. They are used to
slow down the change of Weight and
Like_degree. Because Weight is more
stable than Like_degree,
E
D ื
.
If
 is larger than its higher-boundary, let
;
it
Weigh c
ndary
higher_bou
Weight'i  
If
 is less than its lower-boundary, let
;
it
Weigh c
dary
lower_boun
Weight'i  
If
 is larger than its higher-boundary,
let
;
ie
Like_degre c
ndary
higher_bou
e'
Like_degre
i  
If
 is less than its lower-boundary,
let
.
ie
Like_degre c
dary
lower_boun
e'
Like_degre
i  
4 EXAMPLE 
4.1 Similarity Matching and 
Preference Learning Example 
Table 1 shows an assumed user profile A and
upcoming programme. The problem to be solved is
to determine whether the user likes the programme
and how much he/she does.
Based on the above described procedures, the
programme fuzzy filtering inference
can
be
illustrated as Figure 4.
For the user profile, the actor LiQinqin’s
Like_degree is -0.125, which indicates the user’s
emotion about him is between  “dislike” and 
“neutral”. In this case, both values of 
neutral
=
ld
P
and
dislike
=
ld
P
are 0.5. In addition, the feature of “Actor” 's
Weight is 0.8, so this feature is “important” and
1
important  
P
.
Matching by fuzzy logic rules, the
actor
LiQinqin meets both rule II and III. For rule II᧨
fi
P
is 0.5, which means the user is “very disgust” at this
feature; for rule III,
fi
P  is 0.5 and the user feels
“neutral” about this feature.
Through defuzzification, interest_degree
2  for
the actor LiQinqin is about -0.4. It shows that the
user’s emotion about this feature is mainly “much
disgusted”;
f
Considering other features, the calculated value
of the programme interest_degree P is 0.45. From
Figure 4, when P (0.45) is mapped into its fuzzy
Table 1: Initial conditions. 
User profile A 
Programme”Cala
is a dog” 
Genre
Weight=0.9
(Movie   Like_degree=0.5
…);
Actor
Weight=0.8
(Ge you   Like_degree=0.5
…..
LiQinqin
Like_degree=-0.125);
Genre is movie
Actors are
GeYou, LiQinqin
 Duration=2hour
membership᧨the emotion of the user can be
obtained. In the case discussed, it is between “much
interested” 
and 
“interested” 
( 
2.0
ป
interested
P
,
8.0
ป
interested
h
).
muc
P
According to the user’s behaviour, the user
profile is updated. For the discussed programme,
duration
i is 2 hours. Assumed, the threshold of
the watching time duration
RD
20
 
T
minutes, the time 
duration watched
=2 hours,
i
WD
D =0.01᧨E =0.1,
then:
83
.0
)
-
(
 
i
i
RD
WD
T
For the fuzzy model of user profile A assumed,
the user profile is updated as following:
Genre 
Weight=0.9083
(Movie 
Like_degree=0.5083
Comedy 
Like_degree=0.3
News 
Like_degree=-0.2);
Actor 
Weight=0.8083
(XuJing 
Like_degree=0.1
GeYou 
Like_degree=0.583=0.5
LiQinqin
Like_degree=-0.125+0.083=-0.042);
4.2 Application Scenario
An application scenario is provided. Figure 5 shows
the main user interface of the fuzzy recommendation 
system. Functions are listed in the left column. A 
programme recommendation list is on the topside of
middle column. The description of a selected
programme is presented in the bottom of middle
column. For a selected programme, three choices are
provided to the user, which are “Display”, “Delete”, 
and “Skip”. 
5 CONCLUSION 
An 
intelligent 
Multi-agent  
recommendation
provide
programme
108
is
 
developed
 
to
system
S. Xiaowei

recommendations for multiple users based
on
programme metadata and fuzzy user profiles.
Figure 4: The programme filtering inference.
Different from traditional methods, the user profile
is not based on the viewing history but on a compact
and low-cost structure, including all terms that user
“likes” and “dislikes”. The user profile is updated
dynamically, e.g. “increase” or “decrease” the 
corresponding preference parameters according to
the feedback information. The filtering agent uses 
fuzzy logic to integrate different types of features
together for
a better simulation
of
human
intelligence. This system shows a better capability in
solving problems of ambiguities in programme
recommendation, 
e.g., 
deducing
whether 
a
programme with both the interesting features and 
uninteresting features is worth recommending or not.
The 
application 
scenario 
shows 
that 
this 
recommendation system can help users enjoy life 
more freely.
Figure 5: Main interface. 
REFERENCES
Kaushal Kurapati, Srinivas Gutta, 2001. A Multi-Agent 
TV 
Recommender. 
http://www.di.unito.it/~liliana/
)
(
1 ld
e
GL VO L NH QHXWUDO
O L NH
P


P
if







YHU\
GL VJXVWHG
PXFK
GL VJXVWHG
QHXWUDO
L QWHUHVWHG
YHU\
L QWHUHVWHG
GL VJXVWHG
PXFK
L QWHUHVWHG








P
P

YHU\
GL VJXVWHG
PXFK
GL VJXVWHG
QHXWUDO
L QWHUHVWHG
YHU\
L QWHUHVWHG
GL VJXVWHG
PXFK
L QWHUHVWHG






)X]]L IL FDWL RQRI
IHDWXUH/L 4L QTL Q
)HDWXUH/L
4L QTL Q
VL PL O DUL W\
L QIHUHQFH
3URJUDP
VL PL O DUL W\
L QIHUHQFH
Belkin, N.J. & Croft, W.B., 1994. Information filtering
and information retrieval: two sides of the same coin.
Foltz, P. W. and Dumais, S. T., 1992. Personalized
information delivery: An analysis of information
Ardissono, L. and Buczak, 2002. A. Personalisation in
future TV”. Proceedings of TV’02, the 2nd workshop 
on personalization in future TV. 
Masthoff, J., 2002. Modeling a group of television
viewers, Proceedings of the workshop Future TV, 
Babuska, R.,
1998. Fuzzy
Modeling for
Control”.
International Series in Intelligent Technologies,
TV-Anytime Forum, 2003. Metadata Specification S-3 
Part 
A: 
Metadata 
Schemas, 
Version 
1.3, 
http://www,tv-anytime.org
109
An Intelligent Recommendation System Based on Fuzzy Logic
UM01/kurapati.pdf.
Communications of the ACM,1994.
filtering methods. Communications of the ACM, 1992.
2002.
Kluwer Academic Publishers.

MODEL REFERENCE CONTROL IN INVENTORY AND SUPPLY 
CHAIN MANAGEMENT 
The implementation of a more suitable cost function 
Heikki Rasku, Juuso Rantala, Hannu Koivisto 
Institute of Automation and Control, Tampere University of Technology, P.O. Box 692, Tampere, Finland  
Email: heikki.rasku@tut.fi, juuso.rantala@tut.fi, hannu.koivisto@tut.fi 
Keywords: 
Model reference control, model predictive control, inventory management. 
Abstract: 
A method of model reference control is investigated in this study in order to present a more suitable method 
of controlling an inventory or a supply chain. The problem of difficult determining of the cost of change 
made in the control in supply chain related systems is studied and a solution presented. Both model 
predictive controller and a model reference controller are implemented in order to simulate results. 
Advantages of model reference control in supply chain related control are presented. Also a new way of 
implementing supply chain simulators is presented and used in the simulations. 
1 INTRODUCTION 
In recent years model predictive control (MPC) has 
gained a lot of attention in supply chain management 
and in inventory control. It has been found to be a 
suitable method to control business related systems 
and very promising results has been shown in many 
studies. The main idea in MPC has remained the 
same in most studies but many variations of the cost 
function can be found. Basically these cost 
functions, used in studies concerning MPC in supply 
chain management, can be separated in two different 
categories: quadratic and linear cost functions. The 
use of a linear cost function can be seen appropriate 
as it can take advantage of actual unit costs 
determined in the case. On the other hand these costs 
need to be fairly accurate to result as an effective 
control. Examples of studies using linear cost 
functions in supply chain control can be found in 
(Ydstie, Grossmann et al., 2003) and (Hennet, 
2003). In this study we will no longer study the 
linear form of the cost function but concentrate on 
the quadratic form. The quadratic form of the cost 
function is used in, for example, (Tzafestas et al.,
1997) and (Rivera et al., 2003). In supply chain 
management the question is not only about how to 
control the chain but also about what is being 
controlled. The traditional quadratic form of the cost 
function used in MPC has one difficulty when it 
comes to controlling an inventory or a supply chain. 
The quadratic form involves penalizing of changes 
in the controlled variable. Whether this variable is 
the order rate or the inventory level or some other 
actual variable in the business, it is always very 
difficult to determine the actual cost of making a 
change in this variable. In this study we present an 
effective way of controlling an inventory with MPC 
without the problem of determining the cost of 
changing the controlled variable. The method of 
model reference control will be demonstrated in 
inventory control and results presented. The 
structure of this paper is as follows. In Chapter 2 we 
will take a closer view on model predictive control 
and on the theory behind model reference control. In 
Chapter 3 we present simulations with both model 
predictive control and model reference control and 
do some comparisons between those two. Finally we 
conclude the results from our study in the last 
chapter, Chapter 4. 
2 MODEL PREDICTIVE 
CONTROL
Model predictive control originated in the late 
seventies and has become more and more popular 
ever since. MPC itself is not an actual control 
strategy, but a very wide range of control methods 
which make use of a model of the process. MPC was 
originally developed for the use of process control 
but has diversified to a number of other areas of 
control, including supply chain management and 
111
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 111–116. 

inventory control in which it has gained a lot of 
attention. Today MPC is the only modern control
method to have gained success in real world 
applications. 
(Camacho 
and 
Bordons 
2002),
As stated earlier, Model Predictive Control is a set
of control algorithms that use optimization to design
an optimal control law by minimizing an objective
function. The basic form of the objective function
can be written as 


 
u
N
N
N
J
,
,
2
1
(1)
>
@
¦
 



2
1
2
)
(
)
|
(ˆ
)
(
N
N
j
j
t
w
t
j
t
y
j
G
>
@
¦
 


'

j
j
t
u
j
1
2
)1
(
)
(
O
u
N
,
 where N1 and N2 are the minimum and maximum
cost horizons and Nu is the control horizon. G(j) and
O(j) can be seen as the unit costs of the control. w(t),
ǔ(t) and 'u(t) are the reference trajectory, the
predicted outputs and the change between current
predicted control signal and previous predicted
control signal, respectively. (Camacho and Bordons
2002).
The algorithm consists of two main elements, an 
optimization tool and a model of the system. The
optimizer contains a cost function with constraints
and receives a reference trajectory w(t) to which it
tries to lead the outputs as presented in Figure 1. The
actual forecasting in MPC is done with the model
which is used to predict future outputs ǔ(t) on the
basis of the previous inputs uP(t) and future inputs
u(t) the optimizerhas solved as presented in Figure 1.
Theseforecasts are then used to evaluate the
control and a next optimization on the horizon is
made. After all the control signals on the horizon are 
evaluated, only the first control signal is used in the 
process and the rest of the future control signals are
rejected. This is done because on the next optimizing
instant, the previous output from the process is 
already known and therefore a new, more accurate
forecast can be made due to new information being
available. This is the key point in the receding
horizon technique as the prediction gets more
accurate on every step of the horizon but also is the
source of heavy computing in MPC. The receding
horizon technique also allows the algorithm to 
handle long time delays. (Camacho and Bordons
As presented in equation 1, the basic form of a MPC
cost function penalizes changes made in control
weighted with a certain parameter O. This kind of
damping is not very suitable for controlling an
inventory or a supply chain due to the difficulty of
determining the parameter O as it usually is either
the cost of change in inventory level or the cost of
change in ordering. On the other hand the parameter
O cannot be disregarded as it results as minimum-
variance control which most definitely is not the
control desired. Another problem with the basic
form of MPC used in inventory control is the fact
that it penalizes the changes made in ordering and 
not in inventory levels, which can cause unnecessary
variations in the inventory level as will be shown
later in this study.
In this studywe present a more suitableway to form 
the cost function used in a model predictive
controller. The problematic penalizing of changes in
the control is replaced with a similar way to the one
)
(t
w
)
(
ˆ t
y
)
(t
u
  Input Horizon
Prediction Horizon
Past
Future
Model
Optimization
)
(t
w
)
(ˆ t
y
)
(t
u
)
(t
uP
Figure 1: The main idea and the implementation of MPC.
112
H. Rasku, J. Rantala and H. Koivisto
(Maciejowski 2002). 
2002).
2.1 Implementing the Cost Function 

presented in, for example, (Lambert, 1987) and used,
for example, in (Koivisto et al., 1991). An inverted
discrete filter is implemented in the cost function so
that the resulting cost function can be written as 


¦
 



 
2
1
2
1
*
)
(ˆ
)
(
)
(
N
N
i
i
y
q
P
i
y
J
(2)
,
 where
y*(i) = Target output,
ǔ(i)
= Predicted output
 
P(q-1) = Inverted discrete filter
 
P(q
 
 
The filter P(q-1) used can be written as 
 
The filter P(q


-1) = Inverted discrete filter
-1) used can be written as 










 



2
1
2
2
1
1
1
1
1
p
p
q
p
q
p
q
P
(3)
As can be seen, the number of tuneable parameters
can be reduced as the simplest form of the cost
function consists of only one tuneable parameter, p1
which is used in the filter. Naturally the reduction of
tuneable parameters is a definite improvement it
self.
Thedampeningperformed by the model reference
control is also an advantage concerning bullwhip
effect as over ordering has been found one of the
major causes of this problem. (Towill, 1996) When
the model reference control is applied to an 
inventory level controller the most basic form of the
cost function results as 


¦
 



 
2
1
2
1
*
)
(ˆ
)
(
)
(
N
N
i
i
I
q
P
i
I
J
 
(4)
,
 where I*(i) = Desired inventory level
Î(i)
= Predicted inventory level
P(q-1) = Inverted discrete filter as in
equation (3)
3 SIMULATIONS
The simulations in this study were made using
MATLAB®
and Simulink®. The
goal in the
simulations was to show the advantages of a model
reference controller in inventory control compared
to a traditional model predictive controller. To 
construct the simulators a set of universal supply
chain blocks was used. The main idea in these
blocks is the ability to construct any supply chain
desired without programming the whole chain from
scratch. The basic structure of a desired chain can be
implemented with basic drag and drop operations
and actual dynamics can be programmed afterwards.
The set of blocks consists of three different elements
which are inventory block, production block and a
so called dummy supplier block. These blocks are
the actual interface for programming each individual
element. With these blocks the whole supply chain 
can be constructed and simulated with a high level
of visibility and clarity. 
The main idea in the universal production block can 
be seen in Figure 2. The submodules Stock, Control
and Demand forecast can all be implemented
Production
Inventory
Demand
Forecast
Control
Demand
Order
Inflow
Outflow
Material flow
Universal
production
block
Order
Demand
Information flow
Inflow
Outflow
Figure 2: Structure of the universal production block.
113
3.1 Simulator Implementation Tool
Model Reference Control in Inventory and Supply Chain Management

Universal production
block
uniquely. For example the Inventory block can be
constructed to operate linearly in order to test more
theoretical control methods or it can even be
implemented as realistic as possible to study the
performance of a real world supply chain. The
inventory element represents an end product
inventory of a production plant. Also different
control and demand forecasting methods can be
tested and tuned via the Control and Demand
forecast elements in the block, respectively. The
universal 
production 
block 
has 
naturally 
a 
submodule called Production which consists of
production dynamics in the simulated factory. 
The universal inventoryblock isbasically the
universal 
production 
block 
but 
without
the
Production submodule. The universal inventory
block can be used as a traditional warehouse or as a
whole saler or even as a material inventory for a
production plant. As it consists of the same control
related elements as the universal production block, it
can have a control method and a inventory policy of
its own independently from the production plant.
The dummysupplier blockis very differentfromthe
rest of the set. It is used to solve the problem of long
supply chains. Usually one does not want to model
the whole supply chain as it can consist of tens of
companies. Most of the upstream companies are also 
irrelevant in the simulations from the end products
point of view. Therefore it is necessary to replace
the companies in the upstream of the chain with a
dummy supplier block. This block takes the order
from its customer as an input and supplies this order
with certain alterations as an output. These
alterations can be anything from basic delay to
consideration of decay. Once again, this block can 
be seen as an interface for the programmer who can 
decide the actual operations within the block.
To present the advantages in the model reference
control used in inventory control, a very simple
model was constructed using the universal block set
presented earlier. The structure of the simulator can
be seen in Figure 3. Both the universal production
block and the dummy supplier block are as
presented earlier. To keep the model as simple as
possible, all delays in the model are constant. Each
block in the model consists of a unit delay so that
total delay in the model is 3 units. Also no major
plant-model mismatch is involved in the controller
and no constraints are set. Both controllers also
receive identical accurate demand forecasts. With
this model we present two simulations with different
demand patterns.
For the traditional model predictive controlled
inventory 
the 
following 
cost 
function
was
implemented




¦
 
¸¹
·
¨©
§
'


 
2
1
2
2
*
)
(
)
(ˆ
)
(
N
N
i
i
O
i
I
i
I
J
O
G
 (5)
,
 where
I*(i) = Desired inventory level
Î(i)
= Predicted inventory level
'O(i)= Change in order rate
G, O = Weight parameters
For model reference controlled inventory we used
the cost function presented in equation 4 with the
most basic form of the filter so that the only
parameter to tune is p1. As mentioned earlier, the
number of tunable parameters in model reference
control is reduced by one when compared to the
Order
Demand
Outflow
Inflow
Dummy
supplier
block
Delay
Material flow
Information flow
Figure 3: The structure of the simulator used in this study.
114
H. Rasku, J. Rantala and H. Koivisto
3.2 Inventory Control Simulations

simulation, as the cost function used in model
reference controller has only one parameter p1
instead of the two parameters, G and O included in
the model predictive controller.
The first simulation was a basic step response test
which demonstrated the difference between a model
refence controlled inventory and a traditional model
predictive controlled inventory. The step was 
implemented in both demand and target inventory
levels at the same time to cause a major change in
the system. In other words, target inventory level
was set to follow the demand so that every day the
company had products in stock worth one day’s sale. 
In this simulation the controller parameters were 
chosen to be as follows: G = 0.1, O = 0.9 and p1 = 
0.8, with the control horizon of 10 days. The results
can be seen in Figure 4 where a step in demand has
occured at the moment of 50 days. As can be seen, 
the response of the model reference controller is 
much more smoother than the step response of a
traditional form of the model predictive controller.
This is due to the fact that the model reference
controller dampens directly the changes made in the
inventory level instead of dampening the changes
made in ordering. Model predictive controller is
forced to start ordering excessively in advance to the 
step due to the limitations in changing the control
action. The more reasonably implemented model
reference controller
orders exactly the amount
needed every instant. It becomes obvious that the
penalizing of control actions is not a suitable way to 
control supply chain related tasks as it causes 
additional variations in the system. Model reference
control is much more efficient in achieving what
was beeing pursued in this study – smooth control
method which is simple to tune and implement.
Figure 4: Step responses of an MPC-controlled inventory. In the left-hand figure the cost function is in the form 
presented in equation 5, and in the right-hand figure the cost function is in the form presented in equation 4.
A more practical simulation was also completed
with more realistic demand pattern and forecasting
error. The demand involved also noise which made
the control task even more realistic. The control
horizon was kept at 10 days in both controllers but
the parameters G and O needed to be retuned as the
parameters G and O used in the previous simulation
resulted as very poor responses. New parameters
were chosen as follows: G = 0.3 and O = 0.7. The
model reference controller did not need any retuning
as it survived both simulations very satisfyingly with 
same parameter p1 = 0.8. The target inventory level
was kept constant in the level of 100 units. This is
propably
not the most
cost efficient way of
managing an inventory but was used nevertheless to
keep the results easy to understand.
The demand curve and inventory response can be
seen in Figure 5. The demand curve is identical in 
both pictures but as can be seen there were major
differences in inventory levels. Inventory levels in
the model predictive controlled case showed major
variations at the same time as demand rapidly
increased. No such variations were found in the
model reference case. Once again the penaling of
control actions forced the controller to order
excessive amounts in order to avoid stock-out.
115
3.3 Step Response Simulations 
3.4 Simulations with a More Realistic 
Demand Pattern
Model Reference Control in Inventory and Supply Chain Management
traditional model predictive control. This is obvious
when we look at the cost functions presented in this

Figure 5: The inventory responses of both controllers to a  gaussian-shaped demand pattern.
4 CONCLUSIONS
In this study we presented a solution to the
problematic determining of the cost parameter
penalizing changes made in the control in model
predictive controller used in business related 
systems. The model reference control was studied
and simulations performed to demonstrate the
abilities and advanteges of this control method. It
has been shown, that the model reference control
method is an effective way to control an inventory
and most of all that the method allows us to avoid
the problematic parameter O  in the equation 1. This
reduction of a very problematic parameter is most
definitely inevitable if any kind of practical solutions
are ever desired. Therefore all future research
concerning business related control should concider
this. It should also be kept in mind that any
reduction of tuneable parameters can be seen as an 
advantage.
Also we showed in thisstudy that the model
reference control is at least as applicable in 
inventory control as model predictive control if not
even better. The simple, yet effective and smooth
response model reference control provides suits
perfectly to the unstable and variating environment
of business related systems. It can also be said that 
the filter-like behaviour is desireable in order to
reduce the bullwhip behaviour, but further research
is needed on this field.
presented and used in the simulations of this study.
The set of universal supply chain blocks gives an
opportunity of testing and simulating the perforance
of different control methods or even different forms
of supply chains without reprogramming the basic
elements of inventory and production.
REFERENCES
Camacho, E. F. and Bordons, C., 2002, Model Predictive
Control. Springer-Verlag London Limited 
Hennet, J.-C., 2003. A bimodal scheme for multi-stage
production and inventory control. In Automatica, Vol
39, pp. 793-805.
Koivisto, H., Kimpimäki, P., Koivo, H., 1991. Neural
predictive control – a case study. In 1991 IEEE 
International Symposium on Intelligent Control. IEEE
Press.
Lambert, E. P., 1987. Process Control Applications of 
Long-Range Prediction. PhD Thesis, University of
Oxford. Trinity.
Maciejowski, J. M., 2002, Predictive Control with
Constraints. Pearson Education Limited
Rivera, D. E., Braun, M. W., Flores, M. E., Carlyle, W.
M., Kempf, K. G., 2003. A Model predictive control 
framework for robust management of multi-product,
multi-echelon demand networks. In Annual Reviews in 
Control, Vol. 27, pp. 229-245.
Towill, D. R., 1996. Industrial dynamics modeling of
supply chains. In International Journal of Physical
Distribution & Logistics Management, Vol. 26, No. 2,
pp.23-42.
Tzafestas, S., Kapsiotis, G., Kyriannakis, E., 1997. Model-
based predictive control for generalized production
problems. In Computers in Industry, Vol. 34, pp. 201-
210.
Ydstie, B. E., Grossmann, I. E., Perea-López, E., 2003, A 
Model predictive control strategy for supply chain
optimization. 
In 
Computers 
and 
Chemical
116
H. Rasku, J. Rantala and H. Koivisto
A new supply chain simulator interfacewas also 
Engineering, Vol. 27, pp. 1202-1218.

AN LMI OPTIMIZATION APPROACH FOR GUARANTEED COST
CONTROL OF SYSTEMS WITH STATE AND INPUT DELAYS
O.I. Kosmidou, Y.S. Boutalis and Ch. Hatzis
Department of Electrical and Computer Engineering Democritus University of Thrace
67100 Xanthi, Greece
kosmidou@ee.duth.gr
Keywords:
Uncertain systems, time-delays, optimal control, guaranteed cost control, LMI.
Abstract:
The robust control problem for linear systems with parameter uncertainties and time-varying delays is exam-
ined. By using an appropriate uncertainty description, a linear state feedback control law is found ensuring
the closed-loop system’s stability and a performance measure, in terms of the guaranteed cost. An LMI ob-
jective minimization approach allows to determine the ”optimal” choice of free parameters in the uncertainty
description, leading to the minimal guaranteed cost.
1
INTRODUCTION
Model uncertainties and time-delays are frequently
encountered in physical processes and may cause per-
formance degradation and even instability of control
systems (Malek-Zavarei and Jamshidi, 1987), (Mah-
moud, 2000), (Niculescu, 2001).
Hence, stability
analysis and robust control problems of uncertain dy-
namic systems with delayed states have been studied
in recent control systems literature; for details and
references see e.g.
(Niculescu et al., 1998), (Kol-
manovskii et al., 1999), (Richard, 2003). Since con-
trol input delays are often imposed by process design
demands as in the case of transmission lines in hy-
draulic or electric networks, it is necessary to consider
uncertain systems with both, state and input time-
delays. Moreover, when the delays are imperfectly
known, one has to consider uncertainty on the delay
terms, as well. In recent years, LMIs are used to solve
complex analysis and control problems for uncertain
delay systems (e.g. (Li and de Souza, 1997), (Li et al.,
1998), (Tarbouriech and da Silva Jr., 2000), (Bliman,
2001), (Kim, 2001), and related references).
The purpose of the present paper is to design con-
trol laws for systems with uncertain parameters and
uncertain time-delays affecting the state and the con-
trol input.
Although the uncertainties are assumed
to enter linearly in the system description, it is well
known that they may be time-varying and nonlinear
in nature, in most physical systems. Consequently,
the closed-loop system’s stability has to be studied
in the Lyapunov-Krasovskii framework; the notion
of quadratic stability is then extended to the class of
time-delay systems (Barmish, 1985),(Malek-Zavarei
and Jamshidi, 1987). On the other hand, it is desir-
able to ensure some performance measure despite un-
certainty and time-delay, in terms of guaranteed up-
per bounds of the performance index associated with
the dynamic system. The latter speciﬁcation leads to
the guaranteed cost control (Chang and Peng, 1972),
(Kosmidou and Bertrand, 1987).
In the proposed approach the uncertain parameters af-
fecting the state, input, and delay matrices are allowed
to vary into a pre-speciﬁed range. They enter into
the system description in terms of the so-called uncer-
tainty matrices which have a given structure. Differ-
ent unity rank decompositions of the uncertainty ma-
trices are possible, by means of appropriate scaling.
This description is convenient for many physical sys-
tem representations (Barmish, 1994). An LMI opti-
mization solution (Boyd et al., 1994)is then sought in
order to determine the appropriate uncertainty decom-
position; the resulting guaranteed cost control law
ensures the minimal upper bound. The closed-loop
system’s quadratic stability follows as a direct conse-
quence.
The paper is organized as follows: The problem for-
mulation and basic notions are given in Section 2.
Computation of the solution in the LMI framework is
presented in Section 3. Section 4 presents a numerical
example. Finally, conclusions are given in Section 5.
117
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 117–123. 

2
PROBLEM STATEMENT AND
DEFINITIONS
Consider the uncertain time-delay system described
in state-space form,
˙x(t) = [A1 + ∆A1(t)]x(t)
+[A2 + ∆A2(t)]x(t −d1(t)) +[B1+ ∆B1(t)]u(t)
+[B2 + ∆B2(t)]u(t −d2(t))
(1)
for t ∈[0, ∞) and with x(t) = φ(t) for t < 0.
In the above description, x(t) ∈Rn is the state
vector, u(t) ∈Rm is the control vector and A1, A2
∈Rn×n, B1, B2 ∈Rn×m are constant matrices.
The
model
uncertainty
is
introduced
in
terms
of
∆A1(t) =
k1

i=1
A1ir1i(t),
| r1i(t) |≤¯r1
∆A2(t) =
k2

i=1
A2ir2i(t),
| r2i(t) |≤¯r2
∆B1(t) =
l1

i=1
B1ip1i(t),
| p1i(t) |≤¯p1
∆B2(t) =
l2

i=1
B2ip2i(t),
| p2i(t) |≤¯p2 (2)
where A1i, A2i, B1i, B2i are given matrices with con-
stant elements determining the uncertainty structure
in the state, input, and delay terms.
The uncertain parameters r1i, r2i, p1i, p2i are
Lebesgue
measurable
functions,
possibly
time-
varying,
that belong into pre-speciﬁed bounded
ranges (2), where ¯r1, ¯r2, ¯p1, ¯p2 are positive scalars;
since their values can be taken into account by the
respective uncertainty matrices, it is assumed that
¯r1 = ¯r2 = ¯p1 = ¯p2 = 1, without loss of generality.
Moreover, the advantage of the afﬁne type uncertainty
description (2) is that it allows the uncertainty matri-
ces to have unity rank and thus to be written in form
of vector products of appropriate dimensions,
A1i = d1ieT
1i,
i = 1, ..., k1
A2i = d2ieT
2i,
i = 1, ..., k2
B1i = f1igT
1i,
i = 1, ..., l1
B2i = f2igT
2i,
i = 1, ..., l2
(3)
Obviously, the above decomposition is not unique;
hence, the designer has several degrees of freedom in
choosing the vector products, in order to achieve the
design objectives. By using the vectors in (3), deﬁne
the matrices,
D1 := [d11...d1k1],
E1 := [e11...e1k1]
D2 := [d21...d2k2],
E2 := [e21...e2k2]
F1 := [f11...f1l1],
G1 := [g11...g1l1]
F2 := [f21...f2l2],
G2 := [g21...g2l2]
(4)
which will be useful in the proposed guaranteed cost
approach.
The time delays in (1) are such that,
0 ≤d1(t) ≤¯d1 < ∞,
˙d1(t) ≤β1 < 1
0 ≤d2(t) ≤¯d2 < ∞,
˙d2(t) ≤β2 < 1
(5)
∀t ≥0.
Associated with system (1) is the quadratic cost
function
J(x(t), t) =
! ∞
0
[xT (t)Qx(t)+uT (t)Ru(t)]dt (6)
with Q > 0, R > 0, which is to be minimized for a
linear constant gain feedback control law of the form
u(t) = Kx(t)
(7)
by
assuming
(A1, B1)
stabilizable,
(Q1/2, A1)
detectable and the full state vector x(t) available for
feedback.
In the absence of uncertainty and time-delay, the
above formulation reduces to the optimal quadratic
regulator problem (Anderson and Moore, 1990).
Since uncertainties and time-delays are to be taken
into account, the notions of quadratic stability and
guaranteed cost control have to be considered. The
following deﬁnitions are given.
Deﬁnition 2.1
The uncertain time-delay system (1)-(5) is quadrat-
ically stabilizable independent of delay, if there ex-
ists a static linear feedback control of the form of
(7), a constant θ > 0 and positive deﬁnite matrices
P ∈Rn×n, R1 ∈Rn×n and R2 ∈Rm×m, such
that the time derivative of the Lyapunov-Krasovskii
functional
L(x(t), t) = xT (t)Px(t)
+
! t
t−d1(t)
xT (τ)R1x(τ)dτ
+
! t
t−d2(t)
uT (τ)R2u(τ)dτ
(8)
satisﬁes the condition
˙L(x(t), t) = dL(x(t), t)
dt
≤−θ ∥x(t) ∥2
(9)
118
O.J. Kosmidou, Y.S. Boutalis and Ch. Hatzis

along solutions x(t) of (1) with u(t) = Kx(t), for
all x(t) and for all admissible uncertainties and time-
delays, i.e. consistent with (2), (3) and (5), respec-
tively.
The resulting closed-loop system is called quadrati-
cally stable and u(t) = Kx(t) is a quadratically sta-
bilizing control law.
Deﬁnition 2.2
Given the uncertain time-delay system (1)-(5) with
quadratic cost (6), a control law of the form of (7)
is called a guaranteed cost control, if there exists a
positive number V(x(0), φ(−¯d1), φ(−¯d2)), such that
J(x(t), t) ≤V(x(0), φ(−¯d1), φ(−¯d2))
(10)
for all x(t) and for all admissible uncertainties and
time-delays. The upper bound V(.) is then called a
guaranteed cost.
The following Proposition provides a sufﬁcient
condition for quadratic stability and guaranteed cost
control.
Proposition 2.3
Consider the uncertain time-delay system (1)-(5) with
quadratic cost (6).
Let a control law of the form
of (7) be such that the derivative of the Lyapunov-
Krasovskii functional (8) satisﬁes the condition
˙L(x(t), t) ≤−xT (t)[Q + KT RK]x(t)
(11)
for all x(t) and for all admissible uncertainties and
time-delays. Then, (7) is a guaranteed cost control
law and
V(x(0), φ(−¯d1), φ(−¯d2)) = xT (0)Px(0)
+
! 0
−¯d1
φT (τ)R1φ(τ)dτ
+
! 0
−¯d2
φT (τ)KT R2Kφ(τ)dτ
(12)
is a guaranteed cost for (6). Moreover, the closed-loop
system is quadratically stable.
Proof
By integrating both sides of (11) one obtains
! T
0
˙L(x(t), t)dt ≤−
! T
0
[xT (t)Qx(t)+uT (t)Ru(t)]dt
(13)
and thus
L(x(T), T) −L(x(0), 0) = xT (T)Px(T)
+
! T
T −d1(t)
xT (τ)R1x(τ)dτ
+
! T
T −d2(t)
xT (τ)KT R2Kx(τ)dτ
−xT (0)Px(0) −
! 0
−d1(t)
xT (τ)R1x(τ)dτ
−
! 0
−d2(t)
xT (τ)KT R2Kx(τ)dτ ≤
−
! T
0
[xT (t)Qx(t) + uT (t)Ru(t)]dt
(14)
Since (11) is satisﬁed for L > 0, it follows from Def-
inition 2.1 that (9) is also satisﬁed for θ = λmin(Q +
KT RK). Consequently u(t) = Kx(t) is a quadrati-
cally stabilizing control law and thus L(x(t), t) →0
as T →∞along solutions x(.) of system (1). Conse-
quently, the above inequality yields
! ∞
0
[xT (t)Qx(t) + uT (t)Ru(t)]dt
≤xT (0)Px(0) +
! 0
−¯d1
φT (τ)R1φ(τ)dτ
+
! 0
−¯d2
φT (τ)KT R2Kφ(τ)dτ
(15)
and thus
J(x(t), t) ≤V(x(0), φ(−¯d1), φ(−¯d2))
(16)
for V(x(0), φ(−¯d1), φ(−¯d2)) given by (12).
Remark 2.4
The condition resulting from Proposition 2.3 is a
delay-independent condition. It is well known (Li and
de Souza, 1997), (Kolmanovskii et al., 1999)that con-
trol laws arising from delay-independent conditions
are likely to be conservative. Besides, quadratic sta-
bility and guaranteed cost approaches provide conser-
vative solutions, as well. A means to reduce conser-
vatism consists in minimizing the upper bound of the
quadratic performance index by ﬁnding the appropri-
ate guaranteed cost control law. Such a solution will
be sought in the next Section.
3
SOLUTION IN THE LMI
FRAMEWORK
In order to determine the unity rank uncertainty de-
composition in an ”optimal” way such that the guar-
anteed cost control law minimizes the corresponding
119
An LMI Optimization Approach for Guaranteed Cost Control of Systems

guaranteed cost bound, an LMI objective minimiza-
tion problem will be solved. The uncertainty decom-
position (3) can be written as (Fishman et al., 1996),
A1i = (s1/2
1i d1i)(s−1/2
1i
e1i)T
i = 1, ..., k1
A2i = (s1/2
2i d2i)(s−1/2
2i
e2i)T
i = 1, ..., k2
B1i = (t1/2
1i f1i)(t−1/2
1i
g1i)T
i = 1, ..., l1
B2i = (t1/2
2i f2i)(t−1/2
2i
g2i)T
i = 1, ..., l2(17)
where sij, tij are positive scalars to be determined
during the design procedure. For this purpose, diago-
nal positive deﬁnite matrices are deﬁned,
S1 := diag(s11, ..., s1k1)
S2 := diag(s21, ..., s2k2)
T1 := diag(t11, ..., t1k1)
T2 := diag(t21, ..., t2k2)
(18)
The existence of a solution to the guaranteed cost con-
trol problem is obtained by solving an LMI feasibility
problem. The following Theorem is presented:
Theorem 3.1
Consider the uncertain time-delay system (1)-(5)
with quadratic cost (6). Suppose there exist positive
deﬁnite matrices S1, S2, T1, T2, W, ¯R1, ¯R2, such
that the LMI
Λ(.)
WE1
WE2
B1R−1G1
ET
1 W
−S1
0
0
ET
2 W
0
−S2
0
GT
1 R−1BT
1
0
0
−T1
GT
2 R−1BT
1
0
0
0
R−1BT
1
0
0
0
W
0
0
0
W
0
0
0
B1R−1G2
B1R−1
W
W
0
0
0
0
0
0
0
0
0
0
0
0
−T2
0
0
0
0
−1
β2 ¯R2
0
0
0
0
−1
β1 ¯R1
0
0
0
0
−ˆQ
< 0
(19)
where
Λ(.) = A1W + WAT
1 −B1R−1BT
1 + A2AT
2
+B2BT
2 + D1S1DT
1 + D2S2DT
2 + F1T1F T
1
+F2T2F T
2 + B1R−1R−1BT
1
(20)
and
ˆQ = (In + Q)−1
(21)
¯R1 = R−1
1
(22)
¯R2 = R−1
2
(23)
admits a feasible solution (S1, S2, T1, T2, W, ¯R1,
¯R2). Then, the control law
u(t) = −R−1BT
1 Px(t)
(24)
with
P := W −1
(25)
is a guaranteed cost control law. The corresponding
guaranteed cost is
V(x(0), φ(−¯d1), φ(−¯d2)) = xT (0)Px(0)
+
! 0
−¯d1
φT (τ)R1φ(τ)dτ
+
! 0
−¯d2
φT (τ)PB1R−1R2R−1BT
1 Pφ(τ)dτ (26)
Proof
The time derivative of the Lyapunov-Krasovskii func-
tional is
˙L(x(t), t) = 2xT (t)P ˙x(t) + xT (t)R1x(t)
−(1 −˙d1(t))xT (t −d1(t))R1x(t −d1(t))
+xT (t)KT R2Kx(t) −(1 −˙d2(t))
xT (t −d2(t))KT R2Kx(t −d2(t))
(27)
By using (1), (5) and (17), one obtains the inequality
˙L(x(t), t) ≤2xT (t)P {[A1 + ∆A1(t)]x(t)
+ [A2 + ∆A2(t)]x(t −d1(t))
−[B1 + ∆B1(t)]R−1BT
1 P x(t)
−[B2 + ∆B2(t)]R−1BT
1 P x(t −d2(t))}
+ xT (t)R1x(t) −(1 −β1)xT (t −d1(t))R1x(t −d1(t))
+ xT (t)P B1R−1R2R−1BT
1 P x(t) −(1 −β2)
xT (t −d2(t))P B1R−1R2R−1BT
1 P x(t −d2(t))
(28)
which is to be veriﬁed for all x(.) ∈Rn. Further-
more, by using the identity 2 | ab |≤a2 + b2, for
any a, b, ∈Rn, as well as (2)-(4), (17) and (18), the
following quadratic upper bounding functions are de-
120
O.J. Kosmidou, Y.S. Boutalis and Ch. Hatzis

rived,
2xT (t)P∆A1(t)x(t) ≤| 2xT (t)P∆A1(t)x(t) |
≤
k1

i=1
| 2xT (t)PA1ir1i(t)x(t) |
≤
k1

i=1
| 2xT (t)P(d1is1/2
1i )(e1is−1/2
1i
)T x(t) |
≤xT (t)P
k1

i=1
s1id1idT
1iPx(t)
+ xT (t)
k1

i=1
s−1
1i e1ieT
1ix(t)
= xT (t)PD1S1DT
1 Px(t)
+ xT (t)E1S−1
1 ET
1 x(t)
(29)
∀x(.) ∈Rn. In a similar way one obtains
2xT (t)PA2x(t −d1(t)) ≤xT (t)PA2AT
2 Px(t)
+xT (t −d1(t))x(t −d1(t))
(30)
2xT (t)P∆A2(t)x(t −d1(t))
≤xT (t)PD2S2DT
2 Px(t)
+ xT (t −d1(t))E2S−1
2 ET
2 x(t −d1(t))
(31)
−2xT (t)P∆B1(t)R−1BT
1 Px(t)
≤xT (t)PF1T1F T
1 Px(t)
+ xT (t)PB1R−1G1T −1
1
GT
1 R−1BT
1 Px(t)(32)
−2xT (t)PB2R−1BT
1 Px(t −d2(t))
≤xT (t)PB2R−1BT
2 Px(t)
+ xT (t −d2(t))PB1R−1BT
1 Px(t−d2(t))(33)
−2xT (t)P∆B2(t)R−1BT
1 Px(t −d2(t))
≤xT (t)PF2T2F T
2 Px(t) +
xT (t −d2(t))PB1R−1G2T −1
2
GT
2 R−1BT
1 P
x(t −d2(t))
(34)
The above inequalities are true ∀x(.) ∈Rn. By us-
ing these quadratic upper bounding functions, it is
straightforward to show that the guaranteed cost con-
dition (11) is satisﬁed if
A1 + AT
1 P −PB1R−1BT
1 P + Q
+P[D1S1DT
1 + F1T1F T
1 + D2S2DT
2
+F2T2F T
2 + A2AT
2 + B2BT
2 ]P
+
PB1R−1[G1T −1
1
GT
1 + G2T −1
2
GT
2
+
Im + β2R2]R−1BT
1 P + In
+E1S−1
1 ET
1 + E2S−1
2 ET
2 + β1R1 < 0 (35)
By multiplying every term of the above matrix
inequality on the left and on the right by P −1 := W
and by applying Shur complements, the LMI form
(19) is obtained.
In the sequel, a minimum value of the guaran-
teed cost is sought, for an ”optimal” choice of the
rank-1 uncertainty decomposition. For this purpose,
the minimization of the guaranteed cost is obtained
by solving an objective minimization LMI problem.
Theorem 3.2
Consider the uncertain time-delay system (1)-(5) with
quadratic cost (6). Suppose there exist positive deﬁ-
nite matrices S1, S2, T1, T2, W, ¯
R1, ¯
R2, M1, M2,
M3, such that the following LMI objective minimiza-
tion problem
minX ¯J = minX (Tr(M1) + Tr(M2) + Tr(M3))
(36)
X = (S1, S2, T1, T2, W, ¯
R1, ¯
R2, M1, M2, M3), with
LMI constraints (19) and

−M1
In
In
−W

< 0
(37)

−M2
In
In
−¯R1

< 0
(38)

−M3
Im
Im
−¯R2

< 0
(39)
has a solution X(.). Then, the control law
u(t) = −R−1BT
1 Px(t)
(40)
with
P := W −1
(41)
is a guaranteed cost control law. The corresponding
guaranteed cost
V(x(0), φ(−¯d1), φ(−¯d2)) = xT (0)Px(0)
+
! 0
−¯d1
φT (τ)R1φ(τ)dτ
+
! 0
−¯d2
φT (τ)PB1R−1R2R−1BT
1 Pφ(τ)dτ (42)
is minimized over all possible solutions.
Proof
According to Theorem (3.1), the guaranteed cost (42)
for the uncertain time-delay system (1)-(5) is ensured
by any feasible solution (S1, S2, T1, T2, W, ¯R1, ¯R2)
of the convex set deﬁned by (19). Furthermore, by
taking the Shur complement of (37) one has −M1 +
W −1 < 0 =⇒M1 > W −1 = P =⇒Trace(M1) >
121
An LMI Optimization Approach for Guaranteed Cost Control of Systems

Trace(P). Consequently, minimization of the trace
of M1 implies minimization of the trace of P.
In
a similar way it can be shown that minimization of
the traces of M2 and M3 implies minimization of the
traces of R1 and R2, respectively. Thus, minimiza-
tion of ¯J in (36) implies minimization of the guaran-
teed cost of the uncertain time-delay system (1)-(5)
with performance index (6). The optimality of the so-
lution of the optimization problem (36) follows from
the convexity of the objective function and of the con-
straints.
4
EXAMPLE
Consider the second order system of the form of
equation (1)with nominal matrices,
A1
=

−2
1
0
1

,
A2
=

−0.2
0.1
0
0.1

,
B1 =

0
1

, B2 =

0
0.1

The uncertainty matrices on the state and con-
trol as well as on the delay matrices are according to
(2),
∆A1 =

0
0
0.1
0.1

, ∆A2 =

0
0
0.03
0.03

,
∆B1 =

0
0.1

, ∆B2 =

0
0.03

and hence,
the rank-1 decomposition
may be
chosen such that,
D1 =

0
0.1

, D2 =

0
0.03

, E1 = E2 =

1
1

,
F1 =

0
0.1

, F2 =

0
0.03

, G1 = G2 = 1
The
state
and
control
weighting
matrices
are,
respectively, Q = I2, R = 4.
It is β1 = 0.3,
β2 = 0.2.
By solving the LMI objective minimization problem
one obtains the guaranteed cost
¯J
=
25.1417.
The
optimal
rank-1
decomposition
is
obtained
with s1 = 0.6664, s2 = 2.2212, t1 = 2.5000,
t2 = 8.3333. Finally, the corresponding control gain
is K = [−0.2470 −6.0400].
5
CONCLUSIONS
In the previous sections, the problem of guaranteed
cost control has been studied for the class of uncertain
linear systems with state and input time varying de-
lays. A constant gain linear state feedback control law
has been obtained by solving an LMI feasibility prob-
lem. The closed-loop system is then quadratically sta-
ble and preserves acceptable performance for all para-
meter uncertainties and time varying delays of a given
class. The system performance deviates from the op-
timal one, in the sense of LQR design of the nominal
system, due to uncertainties and time delays. How-
ever, the performance deterioration is limited and this
is expressed in terms of a performance upper bound,
namely the guaranteed cost. In order to make the GC
as small as possible, one has to solve an LMI mini-
mization problem. The minimal upper bound corre-
sponds to the
”
optimal” rank-1 decomposition of the
uncertainty matrices.
REFERENCES
Anderson, B. and Moore, J. (1990). Optimal Control:Linear
Quadratic Methods. Prentice Hall, Englewood Cliffs,
N.J., 2nd edition.
Barmish, B. (1985).
Necessary and sufﬁcient conditions
for quadratic stabilizability of uncertain linear sys-
tems. Journal of Optimization Theory and Applica-
Barmish, B. (1994). New tools for robustness of linear sys-
tems. Macmillan, NY.
Bliman, P.-A. (2001).
Solvability of a lyapunov equa-
tion for characterization of asymptotic stability of lin-
ear delay systems.
In Proceedings of the ECC ’01
European Control Conference,Porto, Portugal, pages
3006–3011. ICEIS Press.
Boyd, S., Ghaoui, L. E., Feron, E., and Balakrishnan, V.
(1994). Linear matrix inequalities in system and con-
trol theory. SIAM Studies in Applied Mathematics,
Philadelphia.
Chang, S. and Peng, T. (1972). Adaptive guaranteed cost
control of systems with uncertain parameters. I.E.E.E.
Trans.on Automatic Control.
Fishman, A., Dion, J.-M., Dugard, L., and Troﬁno-Neto,
A. (1996).
A linear matrix inequality approach for
guaranteed cost control. In Proceedings of the 13th
Kim, J.-H. (2001).
Delay and its time-derivative depen-
dent robust stability of time-delayed linear systems
with uncertainty. I.E.E.E. Trans.on Automatic Con-
Kolmanovskii, V., Nikulescu, S., and Richard, J.-P. (1999).
On the liapunov-krasovskii functionals for stability
analysis oﬂinear delay systems. International Journal
Kosmidou, O. and Bertrand, P. (1987). Robust controller
design for systems with large parameter variations. In-
Li, H., Niculescu, S.-I., Dugard, L., and Dion, J.-M., edi-
tors (1998). Robust guaranteed cost control for un-
certain linear time-delay systems, pages 283–301. In
122
O.J. Kosmidou, Y.S. Boutalis and Ch. Hatzis
ternational Journal of Control, 45: 927–938.
of Control, 72: 374–384.
trol, 46: 789–792.
IFAC World Congress, San Francisco, USA.
tion, 46: 399–408.

Stability and control of time-delay systems. Springer-
Verlag, London.
Li, X. and de Souza, C. (1997). Delay-dependent robust
stability and stabilization of uncertain linear delay
systems: a linear matrix inequality approach. IEEE
Mahmoud, M. (2000). Robust control and ﬁltering for time-
delay systems. Marcel Dekker, NY.
Malek-Zavarei, M. and Jamshidi, M. (1987).
Time-
delay systems:analysis, optimization and applica-
tions. North Holland, Amsterdam.
Niculescu, S. (2001). Delay effects on stability. Springer-
Verlag, London.
Niculescu, S., Verriest, E., Dugard, L., and Dion, J.-M., edi-
tors (1998). Stability and robust stability of time-delay
systems: A guided tour, pages 1–71. In Stability and
control of time-delay systems. Springer-Verlag, Lon-
don.
Richard, J.-P. (2003). Time-delay systems: an overview of
some recent advances and open problems. Automat-
Tarbouriech, S. and da Silva Jr., J. G. (2000). Synthesis
of controllers for continuous-time delay systems with
saturating controls via lmi’s. IEEE Trans. on Auto-
123
Trans. on Automatic Control, 42: 1144–1148.
matic Control, 45: 105–111.
ica, 39: 1667–1694.
An LMI Optimization Approach for Guaranteed Cost Control of Systems

USING A DISCRETE-EVENT SYSTEM FORMALISM FOR THE
MULTI-AGENT CONTROL OF MANUFACTURING SYSTEMS 
Guido Maione 
DIASS, Politecnico di Bari, Viale del Turismo, 8, 74100, Taranto, Italy 
Email: gmaione@poliba.it 
David Naso 
DEE, Politecnico di Bari, Via Re David, 200, 70125, Bari, Italy 
Email: naso@deemail.poliba.it 
Keywords: 
Multi-Agent Systems, Discrete Event Dynamic Systems, Distributed Manufacturing Control, Heterarchical 
Manufacturing Systems. 
Abstract: 
In the area of Heterarchical Manufacturing Systems modelling and control, a relatively new paradigm is that 
of Multi-Agent Systems. Many efforts have been made to define the autonomous agents concurrently 
operating in the system and the relations between them. But few results in the current literature define a 
formal and unambiguous way to model a Multi-Agent System, which can be used for the real-time 
simulation and control of flexible manufacturing environments. To this aim, this paper extends and develops 
some results previously obtained by the same authors, to define a discrete event system model of the main 
distributed agents controlling a manufacturing system. The main mechanism of interaction between three 
classes of agents is presented. 
1 INTRODUCTION 
Nowadays, the study of appropriate tools for 
modelling and designing Multi-Agent Systems 
(MAS) technologies is a key-issue involving all their 
application areas, including telecommunication and 
computer networks, communities of intelligent 
robots, web-based agents for information retrieval, 
to mention a few. Moreover, considerable research 
efforts have been devoted to the definition of 
standards and to the development of platforms for 
unambiguous agent specification, especially in the 
context of software engineering. 
Focusing on the specific context of industrial 
manufacturing, this paper proposes an approach 
based on the Discrete EVent System (DEVS) 
specification (Zeigler et al., 2000) to obtain a 
complete and unambiguous characterization of a 
multi-agent control system. By using the DEVS 
formalism, we describe agents as atomic dynamic 
systems, subject to external inputs from (and 
generating outputs to) other agents. Furthermore, we 
directly obtain the model of the entire network of 
agents by specifying the relationships between the 
atomic agents. The DEVS technique is fully 
compatible with the heterarchical design principles, 
and leads to MAS where all information and control 
functions are distributed across autonomous entities. 
In particular, the DEVS formalism is an interesting 
alternative to other recently proposed tools for MAS 
specification, e.g. the UML (Huhns and Stephens, 
2001), Petri Nets (Lin and Norrie, 2001). The 
success of this formalism is due to its suitability for 
developing useful models both for discrete event 
simulation, and for implementation of the software 
controllers on plant’s operating system. Namely, the 
DEVS formalism can effectively model many recent 
MAS architectures, such as part-driven heterarchical 
manufacturing systems (Duffie and Prabhu, 1996, 
Prabhu and Duffie, 1999) and schemes inspired by 
the Contract Net protocol (Smith, 1980, Parunak, 
1994, Sousa and Ramos, 1999). 
As in most MAS for manufacturing control 
(Heragu, 2002, Shen and Norrie, 1999), in our 
model all the agents use decision algorithms 
emulating micro-economic environments. Each 
agent uses a fictitious currency to buy services from 
other seller agents which, on their turn, use pricing 
strategies. Sellers and buyers have to reach an 
equilibrium between conflicting objectives, i.e. to 
maximize profit and to minimize costs, respectively. 
125
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 125–132. 

Recently, there have been efforts to develop 
analytical models of negotiation processes using, for 
instance, Petri nets (Hsieh, 2004), underlining the 
need of a systematical analysis and validation 
method for distributed networks of autonomous 
control entities. Many other researches have focused 
on the experimental validation of MAS on 
distributed simulation platforms (Shattenberg and 
Uhrmacher, 2001, Logan and Theodoropoulos, 
2001), 
which 
allow 
to 
perform 
detailed 
investigations on the interaction schemes. Sharing 
the same motivations with the mentioned researches, 
our work focuses on the development of DEVS 
models of MAS, which combines the rigor of a tool 
suitable for performing the theoretical analysis of 
structural properties of the MAS, with its efficiency 
in directly translating the model in a detailed 
simulation environment, and its flexibility in testing 
both the individual and collective dynamics of the 
autonomous entities. Namely, our main goal is to 
find a multi-agent design platform that allows users 
to assess the relative effectiveness of agents’ 
decision and interaction strategies, with special 
interest to adaptive learning mechanisms that allow 
agents to improve their performance during their 
operation (Maione and Naso, 2003a). 
In this paper, we develop a detailed model of the 
interactions between the 
main agents in a 
manufacturing system. This contribution extends 
previous researches by the authors, in which, for 
sake of simplicity, the interactions with transport 
units were not considered in detail, and illustrates 
the basic mechanisms of the modelling procedure. 
The paper also outlines other main directions of the 
research in progress. Section 2 introduces the basic 
components of the proposed MAS, and specifies 
their roles and relations. Section 3 specifies how to 
model agents as atomic DEVS. Section 4 focuses on 
the main interactions between agents, describing the 
negotiation for a manufacturing process on a part. 
Sections 5 and 6 give some experimental results, 
overview the advantages of the approach, and 
enlighten the issues open for further research. 
2 THE MULTI-AGENT SYSTEMS 
CONTROL APPROACH 
We consider each Part Agent (PA) as a control unit 
connected to the corresponding physical part (piece) 
flowing through the system. In accordance with the 
related literature (Duffie and Prabhu, 1996, Heragu, 
2002, Prabhu and Duffie, 1999), we associate each 
part into a batch of identical items in process with a 
PA that identifies in real-time (i.e. shortly before a 
part is ready for a new process) the most suitable 
workstation for the imminent operation on that part 
and, consequently, the most suitable vehicle to 
transfer it to the station. The selection is based on 
real-time updated information directly received from 
the alternative stations and transport vehicles, 
through an exchange of messages with other agents. 
Namely, a Workstation Agent (WA) is a software 
entity controlling a workstation or a cell of machines 
performing the same operations, and a Transport 
Agent (TA) is associated with the transport system 
or with a single or group of transport units. 
At each operation step, by interacting with WAs 
and TAs, a PA chooses the machine servicing the 
associated part and the transport device moving the 
piece from its current position (the output buffer of 
the occupied machine) to the chosen workstation. 
In this framework, one can consider also specific 
agents designed to execute other tasks necessary for 
the global operation of the manufacturing plant 
(Maione and Naso, 2003b). In particular, one can 
associate an Order Agent (OA) with each different 
order issued by the management level. The OA 
retains information on quantity and type of products 
to be processed. Similarly, one can define a Loading 
Agent (LA) to manage the loading/unloading station 
where the raw/completed parts enter/exit the system. 
The global control of the manufacturing floor 
emerges from the concurrent actions of the various 
agents in the system. The careful analysis of their 
interactions is fundamental to understand how to 
obtain the desired global behaviour. For instance, the 
OA interacts with PAs to control the release of the 
quantity and type of raw parts necessary to realize 
that order. The PAs interact with the LA to negotiate 
the loading/unloading of raw/completed parts. Here, 
we concentrate on the interactions between a PA and 
WAs and TAs when a part is ready for a new 
process and its PA has to decide the resources 
(workstation and transport device) necessary to fulfil 
the operations, among a set of available alternatives. 
The high-level agents’ decisions are executed by 
low-level plant controllers that are not modelled 
here. One can also view the network of interacting 
agents as a distributed controller supervising and 
synchronizing the underlying physical hardware. 
3 THE DISCRETE-EVENT 
MODELLING FRAMEWORK 
The agents operating in our MAS model interact one 
with another by exchanging event messages. Outputs 
from an agent become inputs for other agents. The 
agent state is updated by external input events 
(inputs) and internal events. Each event in the life of 
an agent is considered an instantaneous or “atomic” 
126
G. Maione and D. Naso

action without duration. Time-consuming actions are 
represented by a pair of events, the first denoting its 
start and the second denoting its finish. 
So, unambiguous models for the agents in the 
system are identified by all the classified events 
which affect the dynamics of each type of agent. The 
internal events are generated by the internal 
dynamics of the agent, and the exogenous events are 
inputs which are not determined by the agent. 
Finally, the external output events (or outputs)
represent the reaction of the agents. Then, it is 
important to define the sequential state of each 
agent. Namely, events change the state. An agent 
stays in a state until either it receives an input, or an 
amount of time determined by a time advance 
function elapses. In the latter case, an internal event 
occurs to change state according to a specified 
internal transition function. Otherwise, if an agent 
receives an input, an external transition function 
specifies the state transition according to the current 
total state of the agent, defined by the sequential 
state, the time elapsed since the last transition and 
some 
additional 
information. 
Finally, 
agents 
generate outputs according to an output function. 
Delays and faults in the communication process are 
also considered in our model. Although the effects 
of these phenomena are often neglected in technical 
literature, we evaluate their effects both on overall 
production performance and on the efficiency of the 
MAS, expressed by ad-hoc performance measures. 
This allows us to track, monitor and optimize the 
interaction among agents. 
To conclude, each agent may be modeled as an 
atomic DEVS as follows: 
 
A = < X, Y, S, Gint, Gext, O, ta > 
(1) 
where X is the set of inputs, Y is the set of outputs, S
is the set of sequential states, Gint: SoS is the 
internal transition function, Gext: QuXoS is the 
external transition function, O: SoY is the output 
function, ta: So0
+ is the time advance function 
(0
+ set of positive real numbers with 0 included), 
Q = ^(s,e,DL) _ sS,0dedta(s)` is the total state set. 
The sequential state s contains the main 
information on the status, specifying the condition 
of an agent between two successive events. Other 
data strictly depend on the type of the agent. E.g., 
for a PA, one can consider the current residual 
sequence of operation steps necessary to complete 
the procedure, the set of available machines for the 
negotiated operation, and prospected time in current 
state before the next internal event. For a WA, s
includes the queues of the requests received from 
PAs for availability, information and confirmation of 
negotiated operations (see below), and the time 
before the next internal event. For a TA, s may 
contain similar queues of requests received from 
PAs, and the time before the next internal event. 
The total state q depends on s, the time e elapsed 
since the last transition and the decision law DL
used by the agent to select and rank the offers 
received from other agents and to decide its action. 
Usually, to build the models, one observes that 
each agent may require or offer a service to other 
agents. A precise mechanism usually defines the 
negotiation protocols working according to a cycle 
“announce-offer-reward-confirm”: an agent starts a 
bid by requiring availability for a service to one or 
more 
agents, 
requests 
the 
available 
agents 
information representing an offer for the negotiated 
service, collects the replies from the queried agents, 
selects the best offer, sends a rewarding message, 
waits for a confirmation and finally acquires the 
service from the rewarded agent. 
In this paper, we focus on the interactions of a 
PA with WAs and TAs when contracting for an 
operation in the procedure to be accomplished for a 
part in process. We describe the main part of the PA 
DEVS model, by concentrating on the mechanism 
ruling the status-transitions of a PA, which are 
triggered by inputs or internal events, and the 
outputs generated for each status. We don’t go into 
the details of the DL used by each agent. To this 
aim, we exploit the models already defined and 
developed in precedent papers (Maione and Naso, 
2003a,b) for PAs, WAs and TAs, but we expand and 
better clarify them to put them together. 
4 THE INTERACTIONS OF A PA 
WITH WAS AND TAS 
To accomplish the manufacturing tasks, each PA 
interacts with WAs to choose the workstation for the 
next operation and with TAs to select the vehicle 
moving the part from the station currently occupied 
to the next one. We assume that the PA firstly 
communicates exclusively with WAs, then with TAs 
only. 
For t<tP0 let the PA associated with a generic 
part, say P, be in a quiescent status (QUIESC) and 
let it begin its activity at tP0 (event XP0). Then P
spends the interval [tP0, tP1] to send outputs YP01,
YP02,…, YP0w at instants t01>tP0, t02,…, t0w=tP1. These 
messages request the availability to all the WAs of 
the alternative stations (w in number) that can serve 
the part. The sequence of requests cannot be 
interrupted by any internal or external occurrence. 
For sake of simplicity, instead of modelling a 
sequence of w status-values, we refer to REQWAV 
for the whole duration of the activity and assume 
that P makes transition at tP1 (event IP1).
In [tP1, tP2] P waits for answers (WAIWAV). 
Namely, the request P transmits to each WA may 
127
The Multi-Agent Control of Manufacturing Systems

queue up with similar ones sent by other PAs. Next 
transition occurs at tP2 when either P receives all the 
answers from the queried WAs (XP1), or a specified 
time-out of WAIWAV expires before P receives all 
the answers. In case it receives no reply within the 
timeout (IP2), P returns to REQWAV and repeats the 
request procedure. In case of time-out expiration and 
some replies received (IP3), P considers only the 
received answers to proceed. The repeated lack of 
valid replies may occur for system congestion, for 
machine failures or communication faults, or for 
other unpredictable circumstances. In all cases 
permanent waits or deadlocks may occur. To avoid 
further congestion and improve system fault-
tolerance, we use time-outs and let P repeat the 
cycle REQWAV-WAIWAV only a finite number of 
times, after which P is unloaded from the system. 
If all or some replies are received before the 
time-out expiration, P starts requesting service to the 
mdw available WAs at tP2. In [tP2, tP3] P requests 
information to these WAs by sending them YP11,
YP12, …, YP1m at instants t11>tP2, t12,…, t1m=tP3. If the 
sequence of requests cannot be interrupted, we refer 
to REQWSE for the whole activity. We assume that 
at tP3 P makes transition (IP4). 
Then, P spends [tP3, tP4] waiting for offers from 
the available WAs (WAIWOF), as the request P
transmits to each WA may queue up with those sent 
by other PAs. Next transition occurs at tP4 when 
either P receives all the answers from the queried 
WAs (XP2) or a time-out of WAIWOF expires. In 
case it receives no reply within the timeout (IP5), P
returns to REQWSE and repeats the procedure. In 
case of time-out expiration and some replies are 
received (IP6), P considers only the received offers to 
select the next server. Again, to avoid congestion, P
repeats the cycle REQWSE-WAIWOF a finite 
number of times, then it is discharged. 
Once received the offers from WAs, P utilizes 
[tP4, tP5] to take a decision for selecting the 
workstation (TAKWDE). At tP5 the decision 
algorithm ends (IP7), after selecting a WA and 
building a queue to rank all the offers of other WAs. 
Subsequently, P reserves the chosen machine by 
transmitting a booking message (YP2) to the 
corresponding WA. So P
takes [tP5, tP6] for 
communicating the choice to the WA (COMCHW). 
At tP6 the communication ends (IP8). Now, the WA 
has to send a rejection if there is a conflict with 
another PA or a booking confirmation (XP5). Hence, 
P uses [tP6, tP7] to wait for a confirmation from the 
selected WA (WAIWCO). The confirmation is 
necessary because during the decision interval the 
condition of the plant can be modified by actions of 
other PAs, and the selected server can be no longer 
available. If P receives a rejection (XP3), or does not 
receive any reply within a time-out (IP9), it returns to 
COMCHW, sends a new request of confirmation to 
the second WA in the decision rank. If P has no 
other alternative destinations and the rejection (XP4)
or the time-out (IP10) occurs, it returns to REQWAV 
and repeats the negotiation. Also WAIWCO, 
WAIWAV and WAIWOF cannot lead to deadlocks, 
thanks to the time-out. 
At tP7, after receiving a confirmation from the 
selected WA, P starts the negotiation with TAs for a 
device to carry the part from the current position to 
the input buffer of the selected workstation, where 
the last negotiated operation is to be made. Then P
opens the bid and spends [tP7, tP8] to send YP31, YP32,
…, YP3v at instants t31>tP7, t32,…, t3v=tP8 to all the v
possible 
TAs 
to 
request 
their 
availability 
(REQTAV). In [tP8, tP9] after the end of transmission 
(IP11), P waits for availability-answers (WAITAV) 
until a time-out expires: if no reply is received, P
gets back to REQTAV (IP12) to repeat the request. 
Otherwise, if all replies are received before the time-
out expiration (XP6) or udv replies are received and 
the time-out expires (IP13), at tP9 P starts requesting 
service to the u available TAs (REQTSE). 
Then P uses [tP9, tP10] to send outputs YP41, YP42,
…, YP4u at instants t41>tP9, t42,…, t4u=tP10 to all the 
available TAs and, after the transmission is 
completed (IP14), P waits for offers from TAs 
(WAITOF) in [tP10, tP11] until a time-out expires. If 
no offer is received (IP15), the PA repeats the request. 
If only some offers arrive and the time-out expires 
(IP16) or all offers arrive before the time-out (XP7), P
can take a transport-decision (TAKTDE) for 
selecting the best offering TA in [tP11, tP12]. After 
selection (IP17), in [tP12, tP13] P communicates its 
choice by sending YP5 to this TA (COMCHT). After 
this communication (IP18), P waits for a rejection or 
a confirmation from the selected TA (WAITCO) 
until a time-out expires. If no reply is received in the 
waiting period [tP13, tP14] and a time-out expires (IP19)
or a rejection is received (XP8), in case other offers 
from TAs are available P gets back to COMCHT 
and selects a new TA; in case no other TA is 
available and there is a time-out expiration (IP20) or a 
rejection (XP9), the availability request is repeated 
and P gets back to REQTAV. 
If a confirmation is received (XP10), P makes a 
transition to issue a transport command (TRANSP). 
It takes the interval [tP14, tP15] to issue the command 
YP6 to load the part on the vehicle associated with 
the selected TA and to start the transport process. 
When, at time tP15, the command is complete (IP21),
P gets back to QUIESC. In case of the last 
operation, YP6 also signals the completion of the 
working procedure to a controller, which influences 
and adapts the DL the PA uses for ranking the offers 
(Maione and Naso, 2003a). In this case, P leaves the 
system. 
128
G. Maione and D. Naso

In general, from tP15 to the beginning of the next 
operation (if any), P stops making decisions, 
receiving and sending messages and remains 
quiescent. The associated part is loaded on the 
transport vehicle and transferred to the next 
workstation where it is downloaded in the input 
buffer. Here, it waits in queue until receiving 
service, after a proper set-up. After the operation, the 
part reaches the output buffer and is ready for the 
next destination. All the above processes are driven 
by low-level controllers and do not involve agent 
activities. So, only when the processes are over, P is 
again ready to start a new negotiation phase. If for 
t>tP15 faults occur to the selected machine or vehicle, 
P remains in QUIESC and there is no need to restart 
negotiations with WAs or TAs. In fact, the plant 
controllers manage the repair process: when the 
normal operating conditions are restored, the part is 
transported to the selected machine. 
Note that, after the negotiation cycle is complete, 
when the chosen and confirmed WA (or TA) signals 
to the PA the end of the operation (or transport) 
process, the PA can take into account its new 
availability. If, at this time, the PA is requesting or 
waiting for availability or information from other 
WAs (or TAs), or is taking a decision for operation 
(transport) on other parts, the received messages 
from the past-selected WA (or TA) wait in a queue 
until the PA gets to REQWSE (or REQTSE). In this 
case, the PA will send an output YP1m+1 (or YP4u+1)
also to this new available WA (TA). 
Figure 1 depicts all this complex interaction 
dynamics. Circles represent the PA status-values, 
arrows represent the events, and the outputs, directly 
associated with status-values, are encapsulated into 
the circles. As the figure shows, the PA may receive 
confirmation from a WA (or a TA) after several 
successive 
couples 
COMCHW-WAIWCO 
(or 
COMCHT-WAITCO). Also, time-outs can bring the 
PA back to REQWAV (from WAIWAV when no 
answer is received from WAs or from WAIWCO 
after a WA-rejection) or to REQTAV (from 
WAITAV when no answer is received from TAs or 
from WAITCO after a TA-rejection). 
Figure 1: dynamics of a PA when negotiating with WAs and TAs.
QUIESC 
COMCHW 
YP2
WAIWAV 
WAIWOF
TAKWDE
REQWSE
YP11…YP1
REQWAV
YP01…YP0w
WAIWCO 
m
WAITAV 
REQTAV
YP31…YP3v
[tP0, tP1]
[tP13, tP14]
[tP8, tP9]
[tP12, tP13]
[tP11, tP12]
[tP10, tP11]
[tP9, tP10]
[tP1, tP2]
[tP2, tP3]
[tP3, tP4]
[tP4, tP5]
[tP5, tP6]
[tP6, tP7]
[tP7, tP8]
XP0
(tP0)
IP1
(tP1)
IP2
(tP2)
XP1 / IP3
(tP2)
IP4
(tP3)
IP5
(tP4)
XP2 / IP6
(tP4)
IP7
(tP5)
IP8
(tP6)
XP3 / IP9
(tP7)
XP4 / IP10
(tP7)
XP5
(tP7)
[tP14, tP15]
COMCHT
YP5
TRANSP
YP6
WAITOF
TAKTDE
REQTSE 
YP41…YP4u
WAITCO 
XP7 / IP16
(tP11)
IP11
(tP8)
IP12
(tP9)
XP6 / IP13
(tP9)
IP15
(tP11)
IP14
(tP10)
XP9 / IP20
(tP14)
IP17
(tP12)
IP18
(tP13)
XP8 / IP19
(tP14)
XP10
(tP14)
IP21
(tP15)
129
The Multi-Agent Control of Manufacturing Systems

On one hand, one could simplify the model by 
merging REQWAV, WAIWAV, REQWSE and 
WAIWOF, i.e. by considering the PA sending 
requests for availability and information all together. 
So, each WA would offer availability and the 
information necessary to the PA decision at the same 
time. Only two status-values would be necessary, 
the first for the request, the second for the wait. The 
same reduction is possible for REQTAV, WAITAV, 
REQTSE and WAITOF. 
On the other hand, the more detailed model of 
the PA activities, which considers two different 
time-outs for the two different waiting conditions 
previously defined, can be more effective in 
reducing the PA waiting times and in avoiding 
deadlocks. In fact, the effect of delays and losses of 
messages 
due 
to 
workstation 
or 
transport 
unavailability (faults, malfunctions, overloaded 
workstations, etc.) and to communication faults are 
reduced. Also, the cyclic repetition of requests and 
waits and the consequent delays in the decision 
processes are limited. As a consequence, the risk of 
discharging PAs from the system is reduced. 
To better enlighten the negotiation mechanism, 
we summarize in Tables I-III the status-values, 
inputs, internal events and outputs. 
Status
Agent’s Activity Description 
QUIESC 
Agent inactive 
REQWAV
Request availability to all possible WAs 
WAIWAV 
Wait for availability signal from WAs 
REQWSE
Request service to available WAs 
WAIWOF 
Wait for offers from available WAs 
TAKWDE 
Take decision for the best WA offer 
COMCHW 
Communicate choice to selected WA 
WAIWCO 
Wait confirm./reject. from selected WA 
REQTAV 
Request availability to all possible TAs 
WAITAV 
Wait for availability signal from TAs 
REQTSE 
Request service to available TAs 
WAITOF 
Wait for offers from available TAs 
TAKTDE 
Take decision for the best TA offer 
COMCHT
Communicate choice to selected TA 
WAITCO 
Wait confirm./reject. from selected TA 
TRANSP
Command selected TA to move the part 
Figure 1 shows that the negotiation mechanism 
maintains a well defined structure with other agents 
participating to a negotiation process. 
In a similar way, a DEVS model can be defined 
for other interactions between classes of agents 
(Maione and Naso, 2003b). The common structure 
of the negotiation mechanism is advantageous for 
building up complex models in a modular way. 
The DEVS model of the agents’ interactions is 
particularly suitable for developing a complete 
simulation platform for the analysis of the dynamics 
of the complex MAS controlling a manufacturing 
plant. In particular, our model allows the simulation 
of both the plant processes and their macroscopic 
hardware components (machines, AGVs, parts, etc.), 
and the details of the control activities performed by 
agents (inputs, outputs, states, time-outs). So, we can 
evaluate the classical indices of a manufacturing 
system 
performance 
(throughput, 
number 
of 
completed items, lateness, etc.), but also the effects 
of agents and their decision policies and the MAS 
efficiency (number of negotiation cycles, number of 
requests). Also, we can measure the agents’ behavior 
in steady-state operating conditions and their 
adaptation to abrupt disturbances (shortages of 
materials, workload changes, hardware faults, etc.). 
In this sense, we made all these measures when 
agents were using different decision policies, to see 
how they dynamically react to disturbances (Maione 
and Naso, 2003a,c). We compared other MAS that 
use conventional decision heuristics (based on the 
delivery time of parts to machines, the distance to 
the next workstation, the required set-up time) with 
our MAS, both with and without adaptation. We let 
agents use a set of decision rules for a limited 
amount of time (the agent life-cycle) and then we 
replace the rules by using the most successful ones. 
The replacement at the end of life-cycle was guided 
by a mechanism emulating the ‘survival of the 
fittest’ natural selection process and propagating the 
fittest rules to the next population of agents. The 
fitness of each decision rule was the average lateness 
of the parts controlled (Maione and Naso, 2003a). 
Inputs Time Description
Outputs
Description
XP0
tP0
Start negotiation for a new operation 
YP01 YP02 … YP0w
Requests of availability 
XP1
tP2
Last reply for WA availability received 
YP11 YP12 … YP1m Requests of service to available WAs 
XP2
tP4
Last reply for WA offer received 
YP2
Choice communication to the selected WA 
XP3
tP7
Rejection & alternative WAs in the PA rank 
YP31 YP32 … YP3v
Requests of availability TAs 
XP4
tP7
Rejection & no alternative WA in the PA rank 
YP41 YP42 … YP4u
Requests of service to available TAs 
XP5
tP7
Confirmation from a WA 
YP5
Choice communication to the selected TA 
XP6
tP9
Last reply for TA availability 
YP6
Transport command 
XP7
tP11
Last reply for TA offer 
XP8
tP14
Rejection & alternative TAs in the PA rank 
XP9
tP14
Rejection & no alternative TA in the PA rank 
XP10
tP14
Confirmation from a TA 
130
G. Maione and D. Naso
Table I: status-values for a Part Agent. 
Table II: inputs received and outputs sent by a PA when negotiating with WAs and TAs.

Internal Event 
Time
Description
IP1
tP1
End of WA availability request process 
IP2
tP2
Time-out and no availability signal received from WAs 
IP3
tP2
Time-out and some (m) availability signals received from WAs 
IP4
tP3
End of WA service request process 
IP5
tP4
Time-out and no offer received from the m available WAs 
IP6
tP4
Time-out and some offers (o<m) received from the available WAs 
IP7
tP5
End of workstation-decision process 
IP8
tP6
End of choice communication to the selected WA 
IP9
tP7
Time-out and no confirmation received from the selected WA when other ranked WA offers are available 
IP10
tP7
Time-out and no confirmation received from the selected WA when no other ranked WA offers are available
IP11
tP8
End of TA availability request process 
IP12
tP9
Time-out and no availability signal received from TAs 
IP13
tP9
Time-out and some (u) availability signals received from TAs 
IP14
tP10
End of TA service request process 
IP15
tP11
Time-out and no offer received from the u available TAs 
IP16
tP11
Time-out and some offers (o<u) received from the available TAs 
IP17
tP12
End of transport-decision process 
IP18
tP13
End of choice communication to the selected TA 
IP19
tP14
Time-out and no confirmation received from the selected TA when other ranked TA offers are available 
IP20
tP14
Time-out and no confirmation received from the selected TA when no other ranked TA offers are available 
IP21
tP15
End of transport command 
5 SOME EXPERIMENTAL 
RESULTS AND FUTURE PLANS
The DEVS model is particularly suitable for 
developing a simulation platform for the analysis of 
the complex dynamics of distributed multi-agent 
control systems. Differently from traditional discrete 
event models of manufacturing plants, mainly 
devoted to simulate the macroscopic components, 
our model considers also the detailed dynamics of 
the software agents (exchanged event messages, 
internal events and outputs). In this way, we may 
study also the effects of hardware faults, congestion 
of the communication network, message losses or 
similar circumstances. 
For instance, it is possible to compare various 
decision policies used by the various agents to 
negotiate operations in a detailed simulation model, 
as done in (Maione and Naso, 2003a). 
The simulation model also allows us to perform 
comparative analysis in dynamic conditions, and 
define reactive policies that minimize the effects of 
disturbances, e.g. a workstation fault. For example 
Figure 2 compares four different agents’ decision 
policies by throughput: minimizing the distance 
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
x 10
5
2
2.1
2.2
2.3
2.4
2.5
2.6
2.7
2.8
2.9
3
Comparison by Average Throughput
time  [s]
Throughput [parts/min]
D [8]
C
B
A
Figure 2: comparison of performance in dynamic conditions (workstation fault at t = 1 0^5 s). 
131
The Multi-Agent Control of Manufacturing Systems
Table III: internal events of a PA when negotiating with WAs and TAs. 

between consecutive workstations (A), minimizing 
the wait for set-up of the workstation (B), 
minimizing the wait in queue at the workstation (C), 
and using a learning strategy (D). It can be noted 
how the reactive policy (D), designed with the aid of 
the DEVS model, outperforms the common (static) 
decision rules using MAS. 
Future research aims at applying the proposed 
approach to other complex distributed control and 
optimization problems, such as those involved in 
large-scale logistic or supply chains. 
6 CONCLUDING REMARKS 
In this paper, we used the DEVS formalism to 
specify the model of the main agents operating in a 
MAS 
controlling 
part-driven 
heterarchical 
manufacturing systems. In this context, we detailed 
the interactions guiding the negotiations related to a 
generic step in a working procedure associated with 
a part process. The model respects heterarchical 
principles and can be used in a simulation platform 
which allows us to analyze both the classical 
performance indices of a manufacturing system and 
the effectiveness of the MAS, using decision 
policies which implement adaptation strategies. 
The proposed method leaves many interesting 
issues open for further research. The next step 
toward the experimentation of the multi-agent 
control system on an automated manufacturing 
plant, is to test the DEVS model on a distributed 
network of computers, each hosting one or more of 
the agents in the heterarchical network. This aims at 
investigating and properly addressing the critical 
issues related to distributed autonomous controllers 
that cannot be examined when simulating the whole 
set of agents on a centralized platform. 
REFERENCES
Duffie, N.A., Prabhu, V.V., 1996. Heterarchical control of 
highly 
distributed 
manufacturing 
systems. 
International 
Journal 
of 
Computer 
Integrated 
Manufacturing, Vol. 9, No. 4, pp. 270-281. 
Han, W., Jafari, M.A., 2003. Component and Agent-Based 
FMS Modeling and Controller Synthesis. IEEE Trans. 
Sys., Man, and Cybernetics – Part C, Vol. 33, No. 2, 
pp. 193-206. 
Heragu, S.S., Graves, R.J., Kim, B.-I., Onge, A.St., 2002. 
Intelligent Agent Based Framework for Manufacturing 
Systems Control. IEEE Trans. Sys., Man, and Cyber. - 
Part A, Vol. 32, No. 5. 
Hsieh, 
F.-S., 
2004. 
Model 
and 
control 
holonic 
manufacturing systems based on fusion of contract 
nets and Petri nets. Automatica, 40, pp. 51-57. 
Huhns, M.N., Stephens, L.M., 2001. Automating supply 
chains. IEEE Int. Comput., Vol. 5, No. 4, pp. 90-93. 
Kotak, D., Wu, S., Fleetwood, M., Tamoto, H., 2003. 
Agent-based 
holonic 
design 
and 
operations 
environment for distributed manufacturing. Computers 
in Industry, 52, pp. 95-108. 
Lee, J.S., Hsu, P.L., 2004. Design and Implementation of 
the SNMP Agents for Remote Monitoring and Control 
via UML and Petri Nets. IEEE Trans. Control Sys. 
Lin, F., Norrie, D.H., 2001. Schema-based conversation 
modeling for agent-oriented manufacturing systems. 
Computers in Industry, Vol. 46, pp. 259-274. 
Logan, B., Theodoropoulos, G., 2001. The distributed 
Simulation of Multiagent systems. Proceedings of the 
IEEE, Vol. 89, No.2, pp. 174-185. 
Maione, G., Naso, D., 2003a. A Genetic Approach for 
Adaptive 
Multi-Agent 
Control 
in 
Heterachical 
Manufacturing Systems. IEEE Trans. Sys., Man, and 
Cyb. – Part A: Spec. Issue Collective Intelligence in 
Multi-Agent Systems, Vol. 33, No. 5, pp. 573-588. 
Maione, G., Naso, D., 2003b. A Discrete-Event System 
Model for Multi-Agent Control of Automated 
Manufacturing Systems. In IEEE SMC’03, Int. Conf. 
on Sys., Man and Cyb., Washington D.C., USA. 
Maione, G., Naso, D., 2003c. A Soft Computing Approach 
for Task Contracting in Multi-Agent Manufacturing 
Control. Comp. Ind., Vol. 52, No. 3, pp. 199-219. 
Parunak, H.V.D., 1994. Applications of Distributed 
Artificial Intelligence in Industry. In O’Hare, 
Jennings, (Eds.), Foundations of Distributed Artificial 
Intelligence, Wiley-Inter-Science. 
Prabhu, V., Duffie, N., 1999. Nonlinear dynamics in 
distributed arrival time control of heterarchical 
manufacturing systems, IEEE Trans. Control Systems 
Technology, Vol. 7, No. 6, pp. 724-730. 
Shattenberg, B., Uhrmacher, A.M., 2001. Planning Agents 
in James. Proc. of the IEEE, Vol. 89, No. 2, pp. 158-
173.
Shen, W., Norrie, D.H., 1999. Agent-Based Systems for 
Intelligent Manufacturing: A State-of-the-Art Survey, 
Knowledge and Information Systems, an International 
Journal, Vol. 1, No. 2, pp. 129-156. 
Smith, R.G., 1980. The Contract Net Protocol: High Level 
Communication and Control in a Distributed Problem 
Solver. IEEE Trans. Computers, Vol. 29, No. 12, pp. 
1104-1113.
Sousa, P., Ramos, C., 1999. A distributed architecture and 
negotiation protocol for scheduling in manufacturing 
systems. Computers in Industry, Vol. 38, pp. 103-113. 
Zeigler, B.P., Praehofer, H., Kim, T.G., 2000. Theory of 
132
G. Maione and D. Naso
Techn., Vol. 12, No. 2, pp. 293-302. 
Modelling and Simulation, Academic Press, 2nd edit. 

PART 2 
Robotics and Automation 

FORCE RIPPLE COMPENSATOR FOR A VECTOR 
CONTROLLED PM LINEAR SYNCHRONOUS MOTOR 
Markus Hirvonen and Heikki Handroos 
Institute of Mechatronics and Virtual Engineering, Lappeenranta University of Technology, Lappeenranta, Finland 
E-mail: markus.hirvonen@lut.fi, heikki.handroos@lut.fi 
Olli Pyrhönen 
Department of Electrical Engineering, Lappeenranta University of Technology, Lappeenranta, Finland 
E-mail: olli.pyrhonen@lut.fi 
Keywords: 
Cogging, Disturbance Observation, Linear Motor, Velocity Control, Vibration Suppression. 
Abstract: 
A dynamic model including non-idealities for a permanent magnet linear synchronous motor (PMLSM) is 
postulated and verified. The non-idealities acting on the physical linear motor are measured and analyzed. 
These experimental results are utilized in the model. The verified simulation model is used in developing a 
force disturbance compensator for the velocity controller of the motor. The force non-idealities, such as the 
cogging force, friction and load force variation, are estimated using a disturbance observer. The acceleration
signal in the observer is derived through the use of a low-acceleration estimator. The significant effects of 
the disturbance compensator on the simulated and measured dynamics of the motor are shown.
1 INTRODUCTION 
The linear motor is an old invention but it is only 
recently that, as a result of the development of 
permanent magnets and their decreased costs, 
permanent magnet linear motors have become a 
viable alternative to rotating motors fitted with linear 
transmissions. 
In 
machine 
automation, 
linear 
movement has traditionally been transmitted from a 
rotary actuator by means of a ball screw, rack and 
pinion or belt. The linear motor simplifies the 
mechanical structure, eliminating the contact-type 
nonlinearities caused by backlash, friction, and 
compliance. In addition, the main benefits of a linear 
motor include its high-power density, reliability and 
efficiency.
Nowadays, 
the 
controllers 
commercially 
available, mainly PID algorithms with fixed gains, 
are unable to compensate for the undesirable 
phenomena that reduce the precision of motion such 
as backlash, static friction, load variations etc. Large 
controller gains are needed in order to maintain the 
stiff control required when suppressing load 
disturbances that tend to reduce the stability of a 
system. Therefore, extended methods for the 
compensation of disturbance have become an 
important topic of research. By compensating for an 
unknown time-varying force based on the estimation 
of such a force, faster speed responses and smaller 
speed ripples can be achieved. 
In disturbance compensation, the compensation 
technique itself is a very simple feed-forward 
control, but the difference arises from the different 
disturbance estimation algorithms. In (Castillo-
Castaneda et al., 2001), the friction compensation 
has been studied using model-based estimation. One 
disadvantage of this technique is that it is suitable 
for tracking only, since the desired velocity must be 
known in advance. Kim et al. (2002) and Tan et al.
(2002) have studied sliding mode estimators in 
compensation feedback, while Godler et al. (1999), 
Deur et al. (2000), Bassi et al. (1999) and Hong et 
al. (1998) have studied the disturbance observer of a 
more general algorithm. Godler et al. (1999) 
compared load disturbance compensation with an 
acceleration control loop inside a speed loop. They 
have found that control implemented using an 
acceleration control loop can better tolerate 
parameter variation as well as disturbance in 
comparison to robust control with a disturbance 
observer. On the other hand, Deur et al. (2000) 
suggested the use of a disturbance observer in 
industrial 
applications 
due 
to 
its 
simple 
135
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 135–142. 

implementation as well as simple design which has
no robustness constraints.
The motor model discussed in the
above-
mentioned papers is a simplified model. The
development of computers and software has made it
feasible to simulate the more detailed dynamical
behavior of machine systems. This paper discusses
the use of a more detailed non-linear dynamic model
for the analysis of a linear transmission system. The 
motor studied in this paper is a commercial three-
phase linear synchronous motor application. The
moving part (the mover) consists of a slotted
armature and a three phase windings, while the
surface permanent magnets (the SPMs) are mounted
along the whole length of the path (the stator).
Figure 1: The structure of the studied linear motor.
First of all, the equations for modelling the
vector-controlled motor drive and non-idealities are 
derived. Then, the simulation model is verified with
the measurements from
physical linear motor
applications, and the comparison of the responses is
shown in the study. Finally, a disturbance observer
based on (Hong et al., 1998), (Godler et al., 1999),
(Deur et al., 2000), and (Bassi et al., 1999) is
implemented in the physical motor system after 
being tested in the simulation model, and the results
and conclusions are presented.
2 SIMULATION MODEL
2.1 Model of LSM
The modeling of the
dynamics of the linear
synchronous motor examined in this paper is based 
on the space-vector theory. The time-varying
parameters are eliminated and all the variables
expressed on orthogonal or mutually decoupled
direct and quadrature axes, which move at a 
synchronous speed of Zs. The d- and q-axes
equivalent to the circuit of the PMLSM are shown in
figure 2, and the corresponding equations are (1) and
(2), respectively.
The voltage equations for the synchronous
machines are 
Figure 2:  Two axial models of the linear synchronous
motor.
d d
u
Ri
s
d
ad
dt
q
\
Z \
 


, 
(1)
d
d
q
u
Ri
q
aq
s
dt
\
Z \
 


, 
(2)
where ud and uq are the d- and q-axis components of
the terminal voltage, iad and iaq the d- and q-axis
components of the armature current, R is the
armature winding resistance and \d, \q are the d- 
and q-axis flux linkage components of the armature
windings. The synchronous speed can be expressed
as Zs=Svs/W, where vs is the linear synchronous
velocity and W the pole pitch. Although the physical
system does not contain a damper, which in PMLSM
usually takes the form of an aluminum cover on the
PMs, virtual damping must be included in the
model, due to eddy currents. The voltage equations
of the short-circuited damper winding are
0
d
D
R i
D D
dt
 

\
, 
(3)
0
Q
R i
Q Q
dt
d\
 

, 
(4)
where RD and RQ are the d- and q-axis components
of the damper winding resistance and iD and iQ the d- 
and q-axis components of the damper winding
current. The armature and damper winding flux
linkages in the above equations are 
136
M. Hirvonen, H. Handroos and O. Pyrh nen
ö

L
i
L
i
d
ad ad
md D
pm
\
 

\
,
(5)
L
i
L
i
q
aq aq
mq Q
\
 

, 
(6)
, 
(6)
L
i
L i
q
aq aq
mq Q
\
 

L
i
L i
D
md ad
D D
pm
\
\
 


, 
(7)
L
i
L i
Q
mq aq
Q Q
\
 

, 
(8)
where Lad and Laq are the d- and q-axis components
of the armature self-inductance, LD and LQ the d- and
q-axis 
components 
of 
the 
damper 
winding
inductance,
Lmd and Lmq the d- and q-axis
components of the magnetizing inductance and \pm
is the flux linkage per phase of the permanent
magnet. By solving the flux linkage differential 
equations from (1) to (4) and substituting the current
equations from (5) to (8) into these equations, the
equations for the simulation model of the linear 
motor can be derived. The electromagnetic thrust of
a PMLSM is (Morimoto et al., 1997)
(
)
pe
F
i
dx
d aq
q ad
vs
S \
\
W
 
 

,
i
(9)
where pe is the electrical power.
2.2Non-idealities of PMLSM 
The force ripple of the PMLSM is larger than that of
rotary motors because of the finite length of the
stator or mover and the wide slot opening. In the 
PMLSM, the thrust ripple is caused mainly by the 
detent force generated between the PMs and the
armature. This type of force can be divided into two
components, for tooth- and core-type detent force. In
the tooth  detent force, the force component is
generated between the PMs and the primary teeth, 
while the core-type detent force component is 
generated between PMs and the primary core. The
wavelength of the core component is usually one
pole pitch, while that of the teeth component is one
slot pitch. The core-type detent force can be
efficiently reduced by optimizing the length of the
moving part or smooth-forming the edges of the
mover, and the tooth-type detent force can be 
reduced by skewing the magnets and chamfering the
edges of the teeth (Jung et al., 2002), (Hyun et al.,
1999), (Inoue et al., 2000), (Zhu et al., 1997), (Hor 
et al., 1998).
The detent force effect tends to move the mover
to a position in which the energy of the magnetic
circuit is at its minimum. This phenomenon attempts
to stall the mover at the stator pole positions and is 
n when no current is flowing
through the motor coils (Otten et al., 1997). The
ripple of the detent force produces both vibrations
d reduces controllability (Chun et al.,
rce ripple is dominant at low velocities
and accelerations. At higher velocities, the cogging
force is relatively small and the influence of 
eleration and deceleration) is 
more dominant (Otten et al., 2000). In this study, the
detent force was measured in the reference system.
The force ripple can be described by sinusoidal
functions of the load position, x, with a period of M
and an amplitude of A
always present, eve
and noise an
2000). The fo
dynamic effects (acc
r, i.e., 
sin(
)
sin(
)
1
1
1
2
2
F
A
x
A
A
ripple
r
r
r
M
M x
ª
º
 

¬
¼ . 
(10)
In figure 3, the results of the simulation are
compared with those measured in the reference
system.
Figure 3:  Comparison of measured and simulated detent
forces.
The reluctance force is another phenomenon that
occurs in linear synchronous motors. A lot of 
research has been carried out into the reluctance in 
linear induction machines, in which the phenomenon
depends on velocity. The reluctance force in
PMLSMs has been studied to a lesser extent. The
reluctance force is due to the variations in the self-
inductance of the windings with respect to the 
relative position between the mover and the magnets
(Tan et al., 2002). The reluctance force was 
observed to be relatively small in the reference 
system and, therefore, has not been included in the 
model.
137
A Vector Controlled PM Linear Synchronous Motor

friction. Friction is very important for control
engineering, for example, in the design of drive
systems, high-precision servomechanisms, robots,
pneumatic and hydraulic systems and anti-lock
brakes for cars. Friction is highly nonlinear and may
result in steady-state errors, limit cycles and poor
performance (Olsson et al., 1998). Friction was
modeled using the simple gradient method in which
the linear motor system was set in a tilted position 
and the moving part allowed to slide down freely.
Friction was measured at several tilt angles and the 
results obtained were used to plot the friction 
function as a function of speed. The friction model
took into account the Coulomb (static) and viscous
(dynamic) components
 
( )
F
sign v
F
abs v F
coulomb
viscous
P
ª
 

¬
º¼ , 
(11)
where v is the velocity of the motor. The friction 
function was incorporated into the simulation model
in such a way that it acts between the stator and the
mover. In the simulation, the smoothing of the
friction function was used to obtain a numerically
efficient model in order to improve simulation rate. 
The effect of load variation was also taken into
consideration. This was carried out using a forced
vibrating non-homogenous two-mass model, where
the load force variation 'Fl is calculated using a 
spring-mass equation, which is the sum of the spring 
force, Fs, and the damping force, Fd. The equation of
motion for such a system is 
(
)
(
)
1
2
1
2
2 2
F
F
F
k x
x
c x
x
m x
l
s
d
'
 

 



 


 ,(12)
where k is the spring constant, c the damping
coefficient, and 
i ,
i and
i are the displacement,
velocity and acceleration of masses m
x x
x
i, respectively. 
The total disturbance force equation can be
described using the equations of detent force,
friction force and load force variation; i.e., the
disturbance force, Fdist, is 
F
F
F
dist
ripple
l
P
 

 F
'
(13)
This resultant disturbance force component is
added to the electromotive force to influence the
dynamical behavior of the linear motor system.
2.3 Current Controller of the Linear 
Motor
The current control of the system is implemented in 
the form of vector control. Vector control is based 
on the space vector theory of electrical machines
and, therefore, can be easily implemented in the
motor model that is also based on the space vector
theory. Vector control is suitable for the force
(torque) control of both induction and synchronous
motors. Generally in the vector control theory, the
force and flux components are analyzed separately
from the motor currents using the mathematical
model of the machine, and control algorithms
control these components separately. In the vector
control used in this study, the direct axis current, iad,
is set to zero (iad=0) assuming that it does not
influence the generation of force; i.e. equation (9)
transforms to 
(
)
F
i
dx
d aq
S \
W
 
. 
(14)
This means that angle \, between the armature
current and q-axis, always remains at 0q and that the 
thrust is proportional to the armature current, ia=iaq.
The drawback of vector control is its low robustness
for changes in the machine
parameters. The 
resistance values change considerably due to
temperature variations, and the inductances rapidly
reach their saturation levels. However, a vector
controller is appropriate for applications in which 
good dynamics and/or accurate velocity control is 
needed.
In literature, vector control is presented in many
ways. In this study, we have used a simulation
principle in which the incoming thrust command,
F*, is converted to the iq current component by
dividing the force value by the force constant of the
motor, Km. The current control algorithms are 
executed in the rotor flux coordinates and the
outputs of the controllers are transformed back into
the stator reference frame, and these values, usa, usb,
and usc, are the inputs of the control inverter. In the
simulation model, the modulation technique used is
sinusoidal pulse width modulation (SPWM) with
ideal switches. 
2.4 Verification of the Simulation 
Model
The simulation model was implemented and
analyzed in the MatLab/Simulink£ software using
the previously mentioned equations. The PWM
138
M. Hirvonen, H. Handroos and O. Pyrh nen
ö
The model also takes into account the effect of 

Figure 4: The Simulink model of the motor system.
inverter is modeled as an ideal voltage source and
common Simulink blocks are used for the model.
The time step of the integrator in the analysis was 10 
Ps, except for the velocity controller, which had a
time step of 1 ms. The parameters used in the
simulation are introduced in table I in the appendix.
Figure 4 shows the Simulink model of the system.
The simulation results were compared with those
measured in the reference system. The motor studied 
in this paper is a commercial three-phase linear 
synchronous motor application with a rated force of
675 N. The moving part is set up on an aluminum
base with four recirculating roller bearing blocks on 
steel rails. The position of the linear motor was 
measured using an optical linear encoder with a
resolution of approximately one micrometer. The
parameters of the linear motor are given in table II in
the appendix.
The spring-mass mechanism was built on a tool
base in order to act as a flexible tool (for example, a 
picker that increases the level of excitation). The
mechanism consists of a moving mass, which can be
altered in order to change the natural frequency of 
the mechanism and a break spring, which is 
connected to the moving mass on the guide. The
purpose of the mechanism is to increase the level of 
excitation when the motor’s vibrational frequency is
equal to the mechanism’s natural frequency, which
was calculated at being 9.1 Hz for a mass of 4 kg.
The motion of the moving mass was measured using
an accelerometer.
The physical linear motor application was driven
in such a way that the PI velocity controller was 
implemented in Simulink to gain the desired velocity
reference. The derived algorithm was transferred to
C code for dSpace’s digital signal processor (DSP)
to use in real-time. The force command, F*, was fed
into the drive of the linear motor using a DS1103 
I/O card. The computational time step for the 
velocity controller was 1 ms, while the current
controller cycle was 31.25 Ps. The measured and
simulated velocity responses and force generating
quadrature currents are compared in figure 5. Sine
and step functions were used as the reference
velocity.
(a)
(b)
Figure 5: A comparison of the measured and simulated
quadrature currents and velocity responses in the case of
(a) a sine velocity reference and (b) a step velocity 
reference.
139
A Vector Controlled PM Linear Synchronous Motor

3 DISTURBANCE 
COMPENSATION
Disturbance compensation is applied to the motor
model to reduce a detrimental force ripple. Force
ripple compensation improves the speed response
and robustness of the system. The force ripple, i.e.
the detent force, friction, and load variation, is
estimated using a disturbance observer, or in other
words, a load force observer. Figure 6 shows the
construction of the compensator.
Figure 6:  Disturbance compensation scheme utilizing load
force estimation.
The concept of the observer is based on the
comparison of the actual input force with the ideal 
one. This gives rise to an error, which after proper
filtering, is used to produce the compensation 
current, icomp. The filter implemented in this study is 
a second-order Butterworth digital low-pass filter 
with a cut off frequency of 50 Hz. The main function
of the filter is to reduce high-frequency noise due to 
input signal derivation but also break the algebraic
loop in the simulation model between the currents 
iref and icomp. Unfortunately, the time delay of the 
filter also limits the performance of robust control, 
since it delays the estimated force disturbance
(Godler
et al., 1999); therefore, the cut-off
frequency should be as high as possible. Hong et al.
(1998) suggested that an artificial delay be used in
the filtering bath of the observer in order to improve
dynamic behavior.
The limitations of this method are highlighted by
the fact that acceleration, which is needed in the 
disturbance observer, is generally not available.
Usually, acceleration is calculated as the time
derivative of the output of the pulse encoder,
although the signal becomes easily erroneous due to
the high noise ratio in the encoder signal, and the
filtering
of this kind
of signal increases the 
undesirable time delay, which leads to an unstable
response. In this study, acceleration is estimated
using an acceleration estimator, which is based on
the construction introduced in (Lee et al., 2001).
This so-called low-acceleration estimator is based on
the fact that the displacement signal from the 
encoder is accurate and
numerical integration 
provides more stable and accurate results than does
numerical differentiation.
Figure
7 shows the
structure of the accelerated estimator.
Figure 7: Structure of low-acceleration estimator.
The estimation of acceleration, ae, is calculated
from the displacement signal, x, of the encoder using
a double integrator. The estimator takes the form of 
a 
PD 
controller, 
in 
which 
the 
estimated
displacement,
xe, is set to follow the actual
displacement, x; i.e. the acceleration estimate is 


1
2
dxe
a
K
x
x
K
e
e
dt
 


 
(15)
and the transfer function from x to xe is 
2
1
2
2
2
2
1
x
K
e
b
x
s
K s
K
s
s
b
b
Z
2
]Z
Z
 
 




, 
(16)
where
Zb represents the bandwidth of the
acceleration estimator and ] is the damping ratio. 
Gains K1 and K2 from the PD controller can be
determined from the required bandwidth of the
estimator. Lee et al. (2001) propose that a good
guideline for the damping ratio is 0.707, which
corresponds to critical damping.
The proposed disturbance regulator has been
tested in the simulation model introduced earlier and 
implemented in the physical application. The
algorithm of the controller was run in real-time with 
a frequency of 1 kHz. The damping ratio of the
acceleration estimator,
],
was
0.707 and the
bandwidth Zb 1000 Hz, i.e. the gains are K1=10e5
and K2=1414. Figure 8 shows a comparison of the
velocity errors between the reference and actual
velocities in compensated and non-compensated
systems, when the amplitude of the reference
velocity sine signal was 0.1 m/s.
140
M. Hirvonen, H. Handroos and O. Pyrh nen
ö

Figure 8: The error between the actual and reference
velocities in the compensated and non-compensated
systems, when the reference velocity signal is sine with an
amplitude of 0.1 m/s. 
4 CONCLUSION 
This paper presented and verified a dynamic model
for a PMLSM including non-idealities. The model
appeared to be an effective tool for designing the
controller of such a system. A disturbance estimator,
which included a low-acceleration estimator, was
proposed and successfully implemented in the
control of the motor. By means of an accurate
simulation model, it was possible to design and test 
the controller without fear of physical damage. The
implementation of the proposed controller was
easily carried out by using a DSP system that
supported the used simulation software. Preliminary
parameter tuning was performed by using the
simulation model and final tuning was carried out in
the physical linear motor application.
It was observed that mechanical non-idealities
have important effect on the dynamics of the motor
system. This effect can be reduced by constructional
modifications and/or a suitable control algorithm. As
mentioned
before, the acceleration signal for 
disturbance estimation or another control algorithm
is not usually available. The double derivation of the
encoder signal produces a very noisy signal, and 
filtering this kind of signal leads to undesirable
stability problems. With the proposed method,
acceleration can easily be estimated from the
position signal.
APPENDIX
REFERENCES
Bassi, E.,  Benzi, F., Buja, G. and Moro, F., 1999.  “Force
disturbance compensation for an A.C. brushless linear
motor,” in Conf. Rec. ISIE’99, Bled, Slovenia, 1999,
pp.1350-1354.
Castillo-Castaneda, E. and Okazaki, Y., 2001. ”Static
friction compensation approach to improve motion
accuracy 
of 
machine 
tool 
linear 
stages,”
Instrumentation and development, vol. 5, no. 1, March
2001.
Chun, J.-S., Jung, H.-K. and Jung, J.-S., 2000.  “Analysis
of the end-effect of permanent magnet linear
synchronous motor energized by partially exited
primary,” 
ICEM, 
International 
Conference 
on
Electrical Machines, Espoo, Finland,  vol. 1, pp. 333-
337, 2000.
141
A Vector Controlled PM Linear Synchronous Motor

observer and with acceleration control loop,” in Conf. 
Raton, USA: CRC, 2001. 
Hong, K. and Nam, K., 1998. ”A Load torque 
compensation scheme under the speed measurement 
delay,” IEEE Trans. Ind. Electron., vol. 4, no. 2, April 
1998.
Hor, P. J.,  Zhu., Z. Q., Howe, D. and Rees-Jones, J., 
1998. “Minimization of cogging force in a linear 
permanent magnet motor”, IEEE Trans. Magn., vol. 
34, no. 5, pp. 3544-3547, Sept. 1998. 
Hyun, D.-S., Jung, I.-S., Shim, J.-H. and Yoon, S.-B., 
1999. “Analysis of forces in a short primary type 
permanent magnet linear synchronous motor,” IEEE 
Trans. Energy Conversion, vol. 14, no. 4, pp. 1265-
1270, 1999. 
Inoue, M. and Sato, K., 2000. “An approach to a suitable 
stator length for minimizing the detent force of 
permanent magnet linear synchronous motors,” IEEE 
Trans. Magn., vol. 36, no. 4, pp. 1890-1893, July 2000. 
Jung, S.-Y. and Jung, H.-K., 2002. ”Reduction of force 
ripples in permanent magnet linear synchronous 
motor,” Proceeding of International Conference on 
2002.
142
M. Hirvonen, H. Handroos and O. Pyrh nen
ö
Deur, J. and Peric, N., 2000. ”A Comparative study of
servosystems with acceleration feedback,” IEEE Ind. 
Applicat. Conf., Italy, 2000, pp. 1533-1540.
Godler, I., Inoue, M. and Ninomiya, T., 1999. “Robustness 
comparison of control schemes with disturbance
Kim, B. K., Chung, W. K. and Oh, S. R., 2002.  
“Disturbance Observer Based Approach to the Design 
of Sliding Mode Controller for High Performance 
Positioning Systems,” 15th IFAC World Congress on 
Automatic Control, 2002. 
Lee, S.-H. and Song, J.-B., 2001. “Acceleration estimator 
for low-velocity and low-acceleration regions based on 
encoder 
position 
data,” 
IEEE/ASME 
Trans. 
Mechatron., vol. 6, no. 1, March 2001. 
Morimoto, S., Sanada, M. and Takeda, Y., 1997. “Interior 
Permanent Magnet Synchronous Motor for High 
Performance Drives,” IEEE Trans. Ind. Applicat., vol. 
33, Issue 4, July-Aug. 1997. 
Olsson, H.,  Åström, K. J., de Wit, C. C.,  Gäfvert, M. and 
Olsson, P. L., 1998. “Friction Models and Friction 
Compensation,” European Journal of Control, 1998, 
Otten, G., de Vries, T.J.A., van Amorengen, J., Rankers, 
A.M. and Gaal, E.W., 1997. “Linear motor motion 
control using a learning feedforward controller,” 
IEEE/ASME Trans. Mechatron., vol. 2, no. 3, pp. 179-
187, 1997. 
Tan, K. K., Huang, S. N.  and Lee, T. H., 2002. ”Robust 
adaptive numerical compensation for friction and force 
ripple in permanent-magnet linear motors,” IEEE 
Trans. Magn., vol. 38, no. 1, January 2002. 
Zhu, Z. Q., Xia, Z. P., Howe, D. and Mellor, P. H., 1997. 
“Reduction of cogging force in slotless linear 
permanent magnet motors”, Proc.IEEE Electr. Power 
Appl., vol. 144, no. 4, pp. 277-282, July 1997. 
Vol. 4, No. 3. 
Electrical Machines, Brugge, Belgium pp. 452, Aug 
Gieras, J. F. and Piech, Z. J., 2001. Linear Synchronous 
Motors: Transportation and Automation Systems. Boca 
Rec. ISIE’99, Slovenia, 1999, pp. 1035-1040. 

HYBRID CONTROL DESIGN FOR A ROBOT MANIPULATOR
IN A SHIELD TUNNELING MACHINE
Jelmer Braaksma, Ben Klaassens, Robert Babuˇska
Delft Center for Systems and Control, Delft University of Technology
Mekelweg 2, 2628 CD Delft, the Netherlands, e-mail: r.babuska@dcsc.tudelft.nl
Cees de Keizer
IHC Systems B.V., P.O. Box 41, 3360 AA Sliedrecht, the Netherlands
Keywords:
Robotic manipulator, shield tunneling, hybrid control, collision, environment model, feedback linearization.
Abstract:
In a novel shield tunneling method, the tunnel lining is produced by an extrusion process with continuous
shield advance. A robotic manipulator is used to build the tunnel supporting formwork, consisting of rings
of steel segments. As the shield of the tunnel-boring machine advances, concrete is continuously injected in
the space between the formwork and the surrounding soil. This technology requires a fully automated ma-
nipulator, since potential human errors may jeopardize the continuity of the tunneling process. Moreover, the
environment is hazardous for human operators. The manipulator has a linked structure with seven degrees of
freedom and it is equipped with a head that can clamp the formwork segment. To design and test the controller,
a dynamic model of the manipulator and its environment was ﬁrst developed. Then, a feedback-linearizing hy-
brid position-force controller was designed. The design was validated through simulation in Matlab/Simulink.
Virtual reality visualization was used to demonstrate the compliance properties of the controlled system.
1
INTRODUCTION
With conventional shield tunnel boring machines
(TBM), the tunnel lining is built of pre-fabricated
concrete segments (Tanaka, 1995; K. Kosuge et al.,
1996). These segments must be transported from the
factory to the construction site, which requires con-
siderable logistics effort. Delays in delivery and dam-
age of the segments during their transport are not un-
common.
To improve the process, IHC Tunneling Systems
are developing a novel shield tunneling method in
which the tunnel lining is produced by extruding con-
crete in the space between the drilled hole and the
supporting steel formwork. This formwork is built of
rings, each consisting of eight segments.
The main functions of the formwork are: i) sup-
port the extruded concrete tunnel lining until it is
hardened and becomes self-supporting, ii) provide the
thrust force to the TBM shield which actually exca-
vates the tunnel. The thrust is supplied by 16 indi-
vidually controlled hydraulic thrust cylinders, evenly
spread around the shield’s circumference.
A robotic manipulator (erector) is used to place the
segments at the desired position.
The erector is a
linked robot mounted such that it can rotate around
the TBM spine, see Fig. 1. It is equipped with a head
that clamps the segment and picks it up from the con-
veyer. At the back end of the TBM, the concrete is al-
ready hardened and the formwork can be dismantled
by a similar manipulator (derector). The segments
are cleaned and inspected for possible damage before
they can be transported to the front end of the TBM
and re-used.
As in the proposed method the tunnel-boring
process is continuous (maximum speed of 2 m/h), the
segments have to be placed within a limited time
interval, and simultaneously with the TBM forward
movement. To comply with the stringent timing re-
quirements and to ensure the continuity of the boring
process, the erector must be controlled automatically
(as opposed to the current practice of using operator-
controlled manipulators). By automating the process,
the probability of a human error is limited and also
the hazard for the operator is considerably reduced.
The controller of the erector must guarantee stable
and safe operation in three different modes (Fig. 2):
1. The segment is in free space and the main task is to
bring it close to the desired position.
2. The segment is in contact with the hydraulic thrust
cylinders which push it toward the already placed
formwork ring.
143
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 143–150. 

erector
conveyer
derector
formwork
hydraulic thrust cylinders
spine
shield
concrete
Figure 1: Cross-section of the shield tunneling machine. Two working conﬁgurations of the derector are shown.
3. The segment is in contact with the hydraulic thrust
cylinders and the formwork ring. The force deliv-
ered by the thrust cylinders will align the segment
in the desired position.
While the ﬁrst mode is characterized by traditional
trajectory-following control, the latter two modes re-
quire compliant control, capable of limiting the con-
tact forces and correcting a possible mis-alignment
due to a different orientation of the segment and the
already placed ring. Note that no absolute measure-
ment of the segment position is available, it can only
be indirectly derived from the measurements of the
individual angles of the manipulator links.
To analyze the process and to design the control
system, a detailed dynamic model of the erector has
been developed. This model includes collision mod-
els for operation modes 2 and 3. A hybrid control
scheme is then applied to control certain DOFs by
a position control law and the remaining ones by a
force control law. Input-output feedback linearization
is applied in the joint space coordinates. Simulation
results are reported.
2
MODELING
The mathematical model consists of three parts: the
manipulator, the environment and the hydraulic thrust
cylinders. This section describes these elements one
by one.
2.1
The erector was designed as a linked structure with
three arms and a ﬁne-positioning head, see Fig. 3. The
ﬁrst arm is attached to the base ring (body0) that can
rotate around the spine. This ring is actuated by an
electric motor. The arms are actuated by hydraulic
Hydraulic push actuators
Manipulator
Segment to be placed
Ring, already built
Figure 2: The erector manipulates segments in three differ-
ent modes: in free space (top), in contact with the hydraulic
thrust cylinders (middle), in contact with the trust cylinders
and the segment ring (bottom).
144
J. Braaksma et al.
Manipulator Model

actuators (not modeled here). At the top of the third
arm (body3), the head is attached, which has three de-
grees of freedom (DOF). The entire manipulator has
seven DOF (q0 to q6) in total.
q2
q0
q1
q3(pitch)
q6(yaw)
q5(roll)
q4
y
x
z
Spine
body2
body1
body0
body3
head
Figure 3: The structure and the corresponding degrees of
freedom of the erector.
The bodies are assumed rigid bodies and the DOF
in body0 is not taken into account. This is justiﬁed,
as the rotation around the spine is ﬁxed during the
positioning of the head. Angle q0 is still an input to
the model, ﬁxed to a value between 0 and 2 π rad. The
control inputs of the robot are assumed to be perfect
torque/force generators in the joints.
The dynamic equation for the manipulator is:
D(q)¨q + C(q, ˙q) ˙q + Fv ˙q + φ(q) = τ −Jb4
0 (q)
T f
(1)
where f is the vector of contact forces between the
hydraulic thrust cylinders and the segment plus the
contact forces between the segment and the ring. The
matrix D(q) is the inertia matrix, C(q, ˙q) is the Cori-
olis and centrifugal matrix, Fv is the friction matrix
and φ(q) is the gravity vector. Jb4
0
is the Jacobian
from frame b4 to frame 0, and q is the vector of the
joint angles.
The manipulator is actuated with the
torque/force vector τ.
2.2
The environment consists of the segment ring (Fig. 4).
An accurate environment model, very important to
the contact tasks in robotics, is usually difﬁcult to
obtain in an analytic form.
In the literature, usu-
ally a simpliﬁed linear model is used (Vukobratovi´c,
Figure 4: Two consecutive rings of the formwork. Each ring
consists of eight segments.
1994). The environment is modeled as a mass-spring-
damper-system. The surface of the segment’s side is
considered ﬂat and only the normal force acting on the
side of the segment is taken into account. Tangential
friction forces are neglected. The collision detection
is implemented with the following smooth switching
function
g(x) = 1
π atan(α(x −xe)) + 1
2
(2)
where α is the steepness of the function, x is the po-
sition of the segment and xe is the position of the en-
vironment. The environment force is described by the
following equation:
fe = g(x)(Ke(x −xe) + De( ˙x −˙xe))
(3)
For stationary environments, equation (3) can be sim-
pliﬁed by taking ˙xe = 0. Ke is the stiffness and De
is the damping.
hydraulic
push actuators
COG
fe
f
segment
formwork ring
{
}
Ca1
r
{
}
Ca2
f
Figure 5: Decomposition of contact force fe.
In the Cartesian space, the dynamic behavior de-
pends on the direction vector of the force and the lo-
cation of the collision. Fig. 5 shows an unaligned col-
lision of the segment with the formwork ring. In this
145
Hybrid Control Design for a Robot Manipulator in a Shield Tunneling Machine
Environment Model

ﬁgure, a transformation is applied, which decomposes
a force fe into a force fl and torque τ acting on the
center of gravity (COG). The following formulas can
be applied.
fl = fe
(4)
τ = r × fe
(5)
where r points to the place where the force acts. The
above derivation is valid for a body moving in free
space. The transformation of the force and torque to
the joint torque is achieved using the principle of vir-
tual work, see (Spong and Vidyasagar, 1989). The
following formula for the joint torques can be derived
τ e = J0(q)T

Rb4
0
0
0
Rb4
0

f
with f =

fl
τ

(6)
where Rb4
0 transforms the force expressed in the seg-
ment body frame to the base frame, J0(q) is the Ja-
cobian which transforms the joint speeds to the lin-
ear/rotational speeds in the base frame and τ e is a
vector with joint torques/forces.
2.3
The model consists of a collision model and a hy-
draulic model. The collision model must detect the
collision between the hydraulic thrust cylinders and
the formwork ring, which means that the model must
detect whether the tips are contacting the segment
body (body4). If there is a collision, the magnitude of
the force can be calculated with the scheme explained
in Section 2.2.
The shape of a segment is illustrated in Fig. 6. The
segment (body4) is a part of a hollow cylinder. For
a controlled collision, the y coordinate of tip of the
hydraulic thrust cylinders must be between the inner
radius r1 and the outer radius r2, and within the range
ϕ, see Fig. 6. The kinematic transformation of two
hydraulic thrust cylinders tips to the Cb4 frame is used
to detect collision.
xb4
{Cb4}
zb4
r1
r2

xb4
zb4
y
side view
body4
Figure 6: The dimensions of the segment (body4).
When the actuators come into contact with the seg-
ment, this will result in a force and torque as ex-
plained in Fig. 5. Only the normal force acting on the
segment is simulated. The error between the segment
and the thrust cylinders is at most 3 degrees, satisfying
the assumption to neglect the tangential force. The
force and torque in the Cb4 frame, are calculated with
the following equations. Let Hb4
a1 and Hb4
a2 be the ho-
mogeneous transformations from the thrust cylinder
frames (Ca1, Ca2) to Cb4. The two force and torque
vectors can be calculated as follows
fa1 = |fa1|[0 1 0]T
ra1 = (Ha1
b4 [0 0 0 1]T )123
τ a1 = ra1 × fa1
(7)
fa2 = |fa2|[0 1 0]T
ra2 = (Ha2
b4 [0 0 0 1]T )123
τ a2 = ra2 × fa2.
(8)
where the subscript 123 refers to the ﬁrst three ele-
ments. These forces and torques in the body frame
can be transformed to the joint torques by means of
the principle of virtual work (6).
3
HYBRID CONTROLLER
The manipulator in free space is position controlled,
but when it is in contact with the environment, the lat-
eral motion and rotation become constrained. When
the segment is pushed by the hydraulic thrust cylin-
ders, stable contact between the thrust cylinders and
the segment is maintained by controlling the contact
force (Fig. 7). When the segment comes into contact
with the segment ring, it aligns to the desired orienta-
tion and position. During the transition between the
modes it is required that the contact forces are lim-
ited. An impedance controller gives the manipulator
the desired compliant behavior (Hogan, 1985).
Hydraulic
push
actuators
yc
yc
zc
zc
Segment
Segment
ring
{Ca1}
{Ca2}
Figure 7: Top view of the segment.
146
J. Braaksma et al.
Hydraulic Thrust Cylinders

A control scheme known as a hybrid position force
controller of (Raibert and Craig, 1981) allows to spec-
ify for each DOF the type of control. The frame in
which the segment is controlled is positioned such
that the direction, in which the position is controlled,
is perpendicular to the direction in which the force is
controlled. This frame is called the constraint frame.
In our case the constraint frame is aligned with the
two thrust cylinder frames (see Fig. 7). In this sit-
uation, the yaw, y, and the pitch, z, DOFs are con-
strained. We choose for the y degree of freedom a
force controller to assure contact. For the other po-
sition constrained degrees of freedom an impedance
controller is chosen which guarantees compliant be-
havior.
The controller consists of four blocks: feedback
linearization, transformation of sensor data (kinemat-
ics, Jacobian and coordinate transform), selection ma-
trix and the controllers (see Fig. 8).
The coordinate-transform block transforms the data
f, x, R, v and ω from the base frame to the constraint
frame and vice versa, where f is the measured force, x
is the position of the segment, R is the rotation matrix
which deﬁnes the orientation of the segment, v is the
linear speed of the segment and ω is the angular speed
of the segment. The inputs of the force controller are
fd and ˙fd, which are the desired force and it’s deriva-
tive. The inputs of the position controller are xd, ˙xd
and ¨xd, which are the desired position, velocity and
acceleration respectively. The vector a is the resolved
acceleration vector and τ is the torque/force vector
for the manipulator.
3.1
The following controller is used for feedback lin-
earization (Siciliano and Villani, 1999)
τ = ˆD(q)u + ˆC(q, ˙q) ˙q + ˆFv ˙q + ˆφ(q) + Jb4
0 (q)
T f
(9)
where u is the new acceleration control input. Sub-
stituting (9) into (1) and assuming perfect modeling
results in the following system
¨q = u
(10)
The goal of the controller is to control the manipulator
in the constraint frame to its desired values.
The Jacobian transforms the joint velocities to the
linear and rotational speeds. The Jacobian is given by

vb4
0
ωb4
0

= Jb4
0 (q) ˙q
(11)
Differentiating (11) gives
 ˙vb4
0
˙ωb4
0

= ¨x = Jb4
0 (q)¨q + ˙Jb4
0 (q) ˙q
(12)
which represents the relationship between the joint
acceleration and the segment’s linear and rotational
speed. A new control input can now be chosen as
u = (Jb4
0 (q))−1 	
a −˙Jb4
0 (q) ˙q

.
(13)
Substitute (13) into (10) and the result into (12), as-
suming perfect modeling and perfect force measure-
ment, leads to the following total plant model
¨x = a = ap + af
(14)
where a is the resolved acceleration in the base frame
and ap, af are the outputs of the position controller
and force controller in the base frame. The vector ap
can be partitioned into linear acceleration al and an-
gular acceleration ao. Likewise, af can be partitioned
into linear acceleration afl and angular acceleration
aft:
ap =

al
ao

af =

afl
aft

.
(15)
3.2
The different positions and speeds are measured in the
joints of the manipulator. The force is measured us-
ing a force sensor, located in the manipulator head. To
control the manipulator in Cartesian space these mea-
surements must be transformed to a Cartesian frame.
This is done with the kinematic matrix and the Jaco-
bian matrix. The frame in which the manipulator is
controlled is the constraint frame.
3.3
The DOF for position control and for force control
can be selected.
This is done by multiplying the
force/torque vector by a diagonal selection matrix S
and the position/velocity vector by I −S, with I the
identity matrix. For a DOF that is position controlled
Si = 0 and for a force controlled DOF Si = 1. For a
manipulator moving in free space the selection matrix
is a zero matrix, meaning position control.
To make sure that the switch between the two sit-
uations is in a controlled manner, the switch function
of the selection matrix must be smooth. The time of
switching in unknown, so the switch should be trig-
gered by the contact force (Zhang et al., 2001).
Φi(fi) =
 fi −f i
ref1,
if fi ≥0
f i
ref2 −fi,
if fi < 0
(16)
The smooth switch function can now be deﬁned as
Si =

0,
if Φi(fi) < 0
1 −sech(αΦi(fi)),
otherwise
(17)
147
Hybrid Control Design for a Robot Manipulator in a Shield Tunneling Machine
Feedback Linearization
Selection Matrix
Transformation of Sensor Data

Feedback
linearization &
Cartesian to joint
space transformation
Coordinate
transform
Manipulator
+
Environment
Coordinate
transform
Position
controller
Selection
matrix
Selection
matrix
Force
controller
Coordinate
transform
Kinematics
+
Jacobian
Selection
matrix
Selection
matrix
f
x, R
v, 
+
+

q.q
a
fd
.
fd
..xd.xd
xd
Figure 8: Block diagram of the hybrid position force controller.
with
sech(x) =
2
ex + e−x
(18)
The value α determines the steepness of the curve,
and f i
ref1, f i
ref2 are the upper and lower threshold
values respectively. The steepness α should be chosen
such that the Si = 1, when the desired contact force
is reached. The force in the y DOF (in the constraint
frame) is chosen to switch from position control to
force/impedance control.
3.4
For the linear and decoupled system (14), the follow-
ing control can be used in order to give the system the
desired dynamics (Siciliano and Villani, 1999).
al = ¨xd + Dl( ˙xd −˙x) + Pl(xd −x)
(19)
ao = ˙ωd + Do(ωd −ω) + PoRc
b4ϵd
b4
(20)
This is a PD controller for the position controlled
DOF, where Rc
b4 transforms the quarternion error ϵd
b4
from the Cb4 frame to the constraint frame. The ma-
trices Dl and Do are the diagonal damping matri-
ces, and Pl and Po are the proportional gain matrices.
Substituting (19) and (20) into (14) assuming perfect
modeling gives the total plant model
¨x = S
¨xd + Dl( ˙xd −˙x) + Pl(xd −x)
˙ωd + Do(ωd −ω) + PoRe
2ϵde
e

(21)
3.5
The force controller has an inner position/orientation
loop within the force loop. For the position loop, the
following PD-controller is chosen (Siciliano and Vil-
lani, 1999).
af = −Df ˙x + Pfp(xc −x)
(22)
where xc −x is the difference between xc the
output of the force loop and the measured posi-
tion/orientation x and Pfp is the proportional matrix
gain and Df is damping gain. For the force loop a
proportional-integral (PI) control is chosen
xc = P −1
fp

Pf(fd −f) + PI
! t
0
(fd −f)dς

(23)
where Pf is the proportional gain, PI is the inte-
gral gain, fd is the desired force and f is the measured
force. The P −1
fp in (23) has been introduced to make
the resulting force and moment control action in (22)
independent of the choice of the proportional gain on
the position and orientation.
3.6
For the impedance controlled DOF the following con-
trol law can be chosen (Siciliano and Villani, 1999)
af =

¨xd + M −1
li (Dli( ˙xd −˙x) + Pli(xd −x) −fl)
˙ωd + M −1
oi (Doi(ωd −ω) + PoiRc
b4ϵd
b4 −ft)

(24)
with Mli and Moi positive deﬁnite matrix gains,
leading to
Mli(¨xd −¨x) + Dli( ˙xd −˙x) + Pli(xd −x) = fl
(25)
Moi( ˙ωd −˙ω) + Doi(ωd −ω) + PoiRc
b4ϵd
b4 = ft
(26)
Equations (25) and (26) allow specifying the manipu-
lator dynamics through the desired impedance, where
the translational impedance is speciﬁed by Mli, Dli
and Pli and the rotational impedance is speciﬁed by
Moi, Doi and Poi.
148
J. Braaksma et al.
Position Control
Impedance Control
Force Control

3.7
The rotation around the spine is ﬁxed during ﬁne po-
sitioning at q0 = 0. The segment ring has a different
orientation than the segment; it is rotated around the
yaw axis by 0.05 radians. In order to take model un-
certainties into account, errors are introduced in the
model. For the dynamic parameters such as inertia an
error of 10% is introduced and for length and posi-
tions an error of 1% is introduced. As it is impossible
to simulate all combination of parameter errors, the
errors are randomly chosen for every simulation.
In the position loop, the P-gain is chosen Pl = 10I.
This corresponds with a natural frequency of 3.2 rad/s
and for the D-gain Dl = 6.3I and this corresponds
to a damping ratio of 1. For the pitch and roll axes
the same gains Po = 10I and Do = 6.3 are used.
The desired force input is 500 N. The position loop in
the force controller has also a P-gain of Pfp = 10I
and a D-gain of Df = 6.3I. The P-gain of the force
controller is Pfp = 5 · 10−3I and the I-gain is set
PI = 5 · 10−3I. The parameters of the impedance-
controlled DOFs are given by Mli = 100I, Dli =
250I and Pli = 500I for the z DOF and Moi = 300I,
Doi = 50000I and Poi = 100I for rotational DOF.
At t=0 s the manipulator is in position control, and
there is no contact between the segment and the envi-
ronment. The thrust cylinders start moving and get in
contact with the segment at t=4.8 s. The manipulator
switches to force/impedance control and moves fur-
ther with the same speed as the hydraulic thrust cylin-
ders (see Fig. 9). The y position of the environment is
at y = 0.25 m. When the segment contacts the envi-
ronment at t = 8 s, the segment aligns with the envi-
ronment as shown in Fig. 10. This contact gives rise to
a torque τx of 800 Nm in the head, which is measured
by the force sensor (Fig. 11). This torque is caused by
the damping term in the impedance controller. The
rotational speed is 0.0017 rad/s the damping term is
50000, the torque is then 0.0017 × 50000 = 833 Nm.
The simulations are repeated 50 times, each time
the parameters in the controller’s internal model are
chosen randomly. In Fig. 11 and Fig. 12, the measure-
ments of the force sensor are plotted. The magnitude
of the force in the y DOF is not inﬂuenced; the time
of impact varies due to the parameter changes. The
torque around the z axis is inﬂuenced by the parame-
ter change.
4
CONCLUSIONS
A dynamic model of the manipulator and its environ-
ment has been successfully derived and implemented
in Matlab/Simulink. The control requirements have
5
10
15
20
25
30
4.2
4.3
4.4
x[m]
time(s)
Position of segment Center of Grafity
5
10
15
20
25
30
0
0.1
0.2
y[m]
time(s)
5
10
15
20
25
30
−0.1
−0.05
0
0.05
0.1
z[m]
time(s)
Figure 9: Position of the segment.
5
10
15
20
25
30
0
0.02
0.04
Roll[rad]
time(s)
Roll Pitch and Yaw angles of the segment
5
10
15
20
25
30
−0.04
−0.02
0
Pitch[rad]
time(s)
5
10
15
20
25
30
0
0.02
0.04
Yaw[rad]
time(s)
Figure 10: Orientation of the segment.
0
5
10
15
20
25
30
0
200
400
600
800
1000
1200
1400
Linear force[N]
time(s)
0
5
10
15
20
25
30
−400
−200
0
200
400
600
800
1000
Torque[Nm]
time(s)
fy
τx
τz
Figure 11: Force measurement in the segment force sensor
(one simulation run).
149
Hybrid Control Design for a Robot Manipulator in a Shield Tunneling Machine
Simulation Results

Figure 12: Force measurement in the segment force sensor
(50 simulation runs).
been met by using a combination of a force con-
troller, an impedance controller and a position con-
troller. The position precision is 0.01 m and for the
orientation the precision is 0.005 rad (0.3 degrees)
The hybrid controller is based on feedback lin-
earization to make the system linear and decoupled.
The feedback linearization is an inverse model of the
manipulator. If the dynamic parameters in the feed-
back linearization are within 10% accuracy and the
dimensional parameter are within 1% accuracy, a sta-
ble hybrid controller is obtained in simulations.
The position loops in the hybrid controller consist
of a PD-controller. The P and the D gains are tuned
by applying the following rules. When the natural fre-
quency ω and the damping ratio ζ are known, then the
P-gain is deﬁned by ω2 and the D-gain is deﬁned by
2ζω.
It is assumed that the manipulator head is equipped
with a six DOF force sensor. If this is not possible
in the mechanical design, the possibility must be in-
vestigated of estimating the force, by measuring the
pressures in the hydraulic actuators.
REFERENCES
Hogan, N. (1985). Impedance control: An approach to ma-
nipulation: Part i - theory, part ii - implementation,
part iii - applications. ASME Journal of Dynamic Sys-
K. Kosuge et al. (1996). Assembly of segments for shield
tunnel excavation system using task-oriented force
control of parallel link mechanism. IEEE.
Raibert, M. and Craig, J. (1981). Hybrid position/force con-
trol of manipulators. J of Dyn Sys, Meas, and Cont.
Siciliano, B. and Villani, L. (1999). Robot Force Control.
Kluwer Academic Publishers.
Spong, M. W. and Vidyasagar, M. (1989). Robot Dynamics
and Control. John Wiley & Sons.
Tanaka, Y. (1995). Automatic segment assembly robot for
shield tunneling machine.
Microcomputers in Civil
Engineering, 10:325–337.
Vukobratovi´c, M. (1994). Contact control concepts in ma-
nipulation robotics-an overview.
In IEEE Transac-
tions on industrial electronics, vol. 41, no. 1, pages
12–24.
Zhang, H., Zhen, Z., Wei, Q., and Chang, W. (2001).
The position/ force control with self-adjusting select-
matrix for robot manipulators. In Proceedings of the
2001 IEEE International Conference on Robotics &
Automation. Department of Automatic Control, Na-
tional University of Defense Technology.
150
J. Braaksma et al.
tems, Measurement, and Control, 107: 1–24.

MOCONT LOCATION MODULE: A CONTAINER LOCATION 
SYSTEM BASED ON DR/DGNSS INTEGRATION 
Joseba Landaluze, Victoria del Río, Carlos F. Nicolás, José M. Ezkerra, Ana Martínez 
IKERLAN Research Centre, Arizmendiarrieta 2, 20500 Arrasate/Mondragon, The Basque Country (Spain) 
Email: jlandaluze@ikerlan.es
Keywords: 
DR/DGNSS, DR, GPS, DGPS, inertial navigation system, location system. 
Abstract: 
The problem of identifying and adequately positioning containers in the terminal yard during handling with 
Reach Stackers still remains to be solved in an appropriate manner, while this is extremely important in 
making the identification and positioning operations automatic. A precise knowledge in the Terminal 
Operating System (TOS) of such data in Real Time would have considerable economic impact on the 
logistic treatment of operations. The MOCONT system sets out to provide a solution to this lack. In 
particular, the MOCONT Location Module establishes the position of the container in the yard while it is 
being handled by a Reach Stacker. This system is based on the integration of the Differential Global 
Navigation Satellite System (DGNSS) with a Dead Reckoning (DR) inertial system. This article presents the 
general characteristics of the MOCONT Location Module, its structure, and the structure of data fusion, 
besides some results obtained experimentally. 
1 INTRODUCTION 
The problem of localising the containers in the yard 
of container terminals had been partially solved for 
terminals equipped with huge machines, such as 
Rubber Tyre (RTG) and Rail Mounted Gantry 
Cranes (RNG) or even Straddle Carriers, but is still a 
problem for those terminals equipped with Reach 
Stackers or Front Loaders. Moreover, the automatic 
identification of containers on board the handling 
machine is still a problem remaining to be solved. 
The European projects MOCONT (“Monitoring 
the yard in container terminals”, IST-1999-10057) 
and MOCONT-II (“Monitoring the yard in container 
terminals – Trials”, IST-2001-34186), aimed at 
providing a system to track the containers in the yard 
in Real Time. The projects aimed at developing a 
system that automatically identified containers and 
localised them when moved by small machines, 
called Reach Stackers. 
This paper presents the Location Module of the 
MOCONT system, developed in said European 
projects, and more particularly, the development of 
the inertial navigation system or Dead Reckoning 
(DR) system. The Location Module is based on the 
integration of a Differential Global Navigation 
Satellite System (DGNSS) and an inertial DR 
system. Data are integrated by means of a Kalman 
Filter. This system reckons the position of the 
vehicle at all times, improving estimates supplied by 
the DGNSS. The exact position of the container is 
determined by means of a transformation of 
coordinates from the vehicle body since the length 
and angle of inclination of the boom are known. The 
system is particularly useful when the GNSS does 
not supply quality data or is interrupted, due to few 
satellites being accessible, multipath phenomena or 
due to working inside container canyons or in dark 
areas. The DR inertial system is able to continue 
estimating vehicle position with precision for short 
time intervals, with bounded errors, until GNSS 
signals with sufficient quality are available. 
In the literature, different structures of inertial 
systems appear for land vehicles. The most common 
case is the use of a sensor for rotation speed of yaw 
angle and odometric information obtained from 
vehicle wheels (Aono, 1999; Ramjattan, 1995). 
Other redundant sensors are often used to help, each 
being different depending on the type of vehicle and 
application in question (Aono, 1999; Zhang, 1999). 
In some cases, especially in vehicles for agricultural 
purposes, a digital compass or a geomagnetic 
direction sensor are used instead of a yaw angle 
speed gyroscope (Benson, 1998; Zhang, 1999). In 
order to avoid errors, which may be introduced by 
odometric sensors on wheels due to slipping, 
Sukkarieh (1999) proposes an Inertial Measurement 
Unit (IMU), comprising three accelerometers, three 
151
© 2006 Springer. Printed in the Netherlands.
J. Braz et al.  (eds.), Informatics in Control, Automation and Robotics I, 151–158. 

YARD
Ship Gate
Buffer
Rail Gate
Buffer
Truck Gate
Figure 1: Overall scheme of a container terminal and Reach Stacher container handling machine. 
gyroscopes and two pendular gyroscopes, by which 
vehicle acceleration and yaw and tilt rotation speeds 
are obtained.  Rogers (1999) presents an inertial 
system consisting of a low cost fibre optic rate 
gyroscope and of a radar ground speed sensor. 
Due to the specifications of the MOCONT 
project, according to which it was not possible to 
change the structure of the Reach Stacker machines 
and nor was it possible to install encoders in the 
wheels to obtain odometric information, initially a 
structure based on a triad of accelerometers and a 
triad of solid state gyroscopes was selected. 
Although this set up may be valid for on-road 
vehicles, once field data were obtained for a Reach 
Stacker in normal work tasks, it was concluded that 
this set up was not valid for such a machine; due to 
the low speeds and considerable degree of vibration 
to which this machine is subject during operations, 
the accelerometers did not provide information on 
machine movements on the yard, and only the yaw 
rate ant tilt rate gyroscope signals could be used 
(Landaluze, 2003). Therefore, a sensor structure 
similar to that proposed in (Rogers, 1999) was 
chosen. Finally, since a subcentimetric receiver was 
replaced by a submetric receiver, and taking into 
account the “non-collocation” between the Reach 
Stacker chassis sensors and the GPS antenna, fitted 
on the highest point of the Reach Stacker boom, 
sensoring was completed with a digital compass. 
This paper firstly presents an overview of the 
MOCONT project, followed by an explanation of 
the structure of the Location Module in the 
MOCONT system. Then follows a description of the 
DR 
inertia 
system 
and 
the 
Kalman 
Filter 
implemented. Lastly, some experimental results are 
shown, as well as a statistical evaluation of the 
results obtained by the Location Module of the 
MOCONT system in the course of the MOCONT-II 
project.
2 OVERVIEW OF THE MOCONT 
SYSTEM
The MOCONT project was presented as a new 
landmark in the application of telematics in 
intermodal transport, especially in the control of 
container terminals. The main objective of the 
project was to develop a system to identify the 
position of containers in the yard in Real Time. 
Although said follow-up problem had already been 
partially solved in the case of large loading and 
unloading cranes (Rubber Tyre RTD, Rail Mounted 
Gantry Crane RMG, Straddle Carriers), this was and 
is a problem in terminals with Reach Stacker 
machines. It was in these machines, therefore, where 
the project comes to bear (Figure 1). 
The Reach Stacker is an off-road machine used 
to handle containers in the terminal yard. It is 
characterised by a small body with an extensible 
boom (the arm) mounted over of the operator cabin. 
It is equipped with a spreader, namely the handling 
device used to pick and keep containers by the 
machine itself. The Reach Stacker can stack up to 
the fourth height (up to the fifth height in case of 
empty containers).  
Taking into account the main objective of the 
project, the MOCONT system should perform the 
following operations: 
x
Identify the container, reading the identification 
code when picked up by each Reach Stacker. 
x
Follow each movement of the container in the 
terminal yard while being handled by the Reach 
Stacker, recording (i.e., the position of the 
container in the yard – row, column, height) 
where the container is picked up or released. 
x
Inform on the position of the container and its 
identification without the intervention of human 
operators. 
152
J. Landaluze et al.

Terminal Operating System (TOS) 
DR Inertial 
Navigation
 DGNSS 
Visual Identification
Synchronisation and 
   Communication 
        Middleware 
LM
VIM
MOCONT
SCM
Figure 2: MOCONT functional architecture. 
GNSS
Processing 
Unit 
Port DTM
Ag132 GPS 
Receiver 
DR
Processing 
Unit 
Display
MOCONT 
    DR 
 sensors
 Boom 
sensors
Figure 3: Scheme and flow data of the Location Module.
x
In Real Time, update the position of any 
container handled by a Reach Stacker in the 
Terminal Operating System (TOS). 
In order to obtain the objectives proposed, the 
MOCONT system incorporates three different 
modules (Figure 2): the Location Module, the Visual 
Identification Module and the Synchronisation and 
Communication Module. The Location Module 
determines the position of the container in the 
terminal yard; the Visual Identification Module 
reads the container’s identification code; the 
Synchronisation 
and 
Communication 
Module 
acquires the identification and position data on the 
container and informs the TOS.
3 STRUCTURE OF THE 
LOCATION MODULE 
The Location Module consists of two subsystems: 
the DR subsystem and the DGNSS subsystem. This 
last one has two different parts: the GPS receiver 
and the GNSS Processing Module. 
In the final MOCONT Location Module 
Trimble’s Ag132 GPS receiver is used at the heart of 
the GNSS and, therefore, of the location system, for 
the positioning of the Reach Stacker.  The Ag132 
GPS receiver combines high-performance GNSS 
reception with radio-beacon DGNSS capability in a 
single durable waterproof housing, ideal for use in 
the yard environment.  The receiver uses differential 
GNSS to provide sub-metre accuracy.  
Differential GNSS requires two or more 
receivers.  One receiver, called the reference or base 
station, is located at a known point to determine the 
GNSS measurement errors.  This could be housed on 
the roof of the main administration buildings, to 
allow easy access and constant monitoring. An 
unlimited number of AgGPS receivers, sometimes 
called rovers, collect GNSS data at unknown 
locations onboard each Reach Stacker.  Over a radio 
band, the reference station broadcasts correction 
values, which are applied to the Ag132 GPS receiver 
positions. Errors common at both the reference and 
rover receivers and then removed from the solution. 
The performance of the Ag132 GPS receiver is 
improved by direct GNSS augmentation with height 
aiding.  Height aiding improves the solution by 
enhancing satellite visibility, and reducing the 
positioning challenge from a three-dimensional to a 
two dimensional problem. Using a DTM of the port 
and the current location of the Reach Stacker, an 
interpolation 
algorithm 
provides 
an 
accurate 
measure of the current ground height.  With 
knowledge of the Reach Stacker geometry, the boom 
extension and boom inclination, the height of the 
GNSS antenna on board the vehicle, and indeed the 
height of the container carried by the Reach Stacker, 
can be continually computed. 
In addition, the Location Module provides 
complimentary DR augmentation for periods when 
GNSS positioning with height aiding is not possible.  
The DR subsystem consists of a Processing Unit and 
some DR sensors, by means of which the Reach 
Stacker position is continuously estimated. The 
GNSS Processing Module continually provides the 
DR subsystem with the current position from the 
Ag132 
GPS 
receiver 
(in 
projected 
UTM 
coordinates) and some indication of the quality of 
that position fix (by means of a covariance matrix of 
the computed parameters). In return the DR 
subsystem continually updates the GNSS Processing 
Module with the best estimate of the current 
position. 
The GNSS Processing Module will then pass the 
position information to the driver and the rest of the 
MOCONT system. 
The GNSS Processing Module, which interfaces 
with the Ag132 GPS receiver, the DR subsystem, 
153
A Container Location System Based on DR/DGNSS Integration

Gyro 
Radar 
Sensor 
Stop/direct 
   Sensor 
  Laptop 
Computer 
    PC/104 
      DR 
Proc. Module
    AgGPS 170  
         GNSS 
Processing  Module
     Ag132 
GPS receiver
24 V 
24 V 
CAN 
CAN 
CAN 
CAN 
RS-232 
DR subsystem 
GNSS subsystem 
MOCONT 
  Digital 
Compass 
Figure 4: Elements of the Location Module. 
Figure 5: Heading box and Location Module box. 
the boom sensors and the Synchronisation and 
Communication Module, has been developed using 
the robust and compact AgGPS 170 Field Computer. 
The AgGPS 170 is designed to withstand the 
environmental extremes that are typical of the 
container port environment. 
A scheme of the Location Module, with its 
components and the flow of data, is shown in Figure 
3 and Figure 4. As can be observed, the 
communication between the two subsystems of the 
Location Module is by means of a CAN bus. The 
communication between the GNSS subsystem and 
the Synchronisation and Communication Module is 
also by another CAN bus (Figure 4). The values 
measured by the boom sensors are supplied by the 
MOCONT middle-ware through this bus. 
4 DR SUBSYSTEM DESIGN 
Although initially different sensorings were tested 
for the DR subsystem, a sensor structure similar to 
that proposed by Rogers (1999) was finally selected. 
Likewise, replacing the MS750 subcentimetric GPS 
receiver in the final structure of the Location 
Module with an Ag132 submetric receiver, made it 
necessary to complete sensoring in the DR 
subsystem with a digital compass. As a result of 
these changes, the final structure used for the DR 
subsystem was as follows: 
x
The DR Processing Module, which consisted of 
a sandwich of three PC/104 boards: a CPU 
based on a 233 MHz Pentium Processor, an I/O 
data acquisition board and a 2-channel CAN 
communication board.  
x
The DR sensor set. This included the following 
sensors: a solid state gyroscope to measure the 
speed of rotation around the yaw axis; a radar 
technology Ground Speed Sensor, which 
provided the forward/backward speed of the 
vehicle; a stop/direction sensor, in order to 
detect if the vehicle is stopped or not, as well as 
the movement direction of the vehicle, forward 
or backward; a digital compass, to measure the 
vehicle heading angle. 
Figure 4 shows the main elements of the 
Location Module and the structure of the DR 
subsystem. A laptop computer was used to monitor 
and configure the DR subsystem, as well as to 
collect raw data. Most of the elements of the DR 
subsystem were included in two boxes, the Location 
Module box and the Heading box, as they appear in 
Figure 5. 
Although different data fusion algorithms were 
tested, a kinematical Kalman Filter was finally 
chosen due to its simplicity and the good results 
obtained. For the navigation equations, it is assumed 
that the vehicle is moving on a tangent-plane, as it 
was a point, so the positioning involves locating the 
vehicle in cardinal directions: N-S-E-W. Figure 6 
shows the local level geographic navigation and the 
N
E
X
Y
\
154
J. Landaluze et al.
4.1 Description of the DR Subsystem
4.2 DR/DGNSS Integration 
Figure 6: Local level geographic and body frames. 

DGPS
Receiver
  Radio 
Modem 
  Radio 
Modem 
Gyroscope 
Speed sensor 
Stop/dir sensor 
          GNSS 
Processing Module
n, e, R
UTC,),O,h,
PDOP, #sat, 
GPS quality 
\
v
\ˆ
,ˆ,ˆ e
n
DGPS 
Receiver 
Base Station 
Rover Unit 
DR Software Implementation
Compass
\
Extended Kalman Filter
 Boom 
sensors
body reference frames. It is assumed that the only 
transformation between these two frames is via the 
heading angle \.
The DR navigation system implements a 
distance travelled (integrated velocity) and a travel 
direction. The distance travelled is referenced to the 
body frame, which is then transformed into a local 
level geographic navigation frame through the angle 
\. This implementation assumes that other vehicle 
attitudes, i.e., roll and pitch, are sufficiently small as 
to be ignored. 
The body referenced velocity is represented as a 
nominal velocity v, defined such that the X-
component is along the primary direction of travel, 
plus velocity errors as a result of speed sensor scale 
factors
vH .
The computed body referenced velocity is 
represented as 
v
B
v
v
v
H


 
 
 
(1)
where v is the measured or estimated vehicle 
velocity.
Assuming that the body to navigation frame 
transformation and body-referenced velocity are 
approximately constant over a small time interval, 
the sampling time, it can be written: 
\
H
\
\
\
H
\
\
sin
sin
sin
cos
cos
cos




 

 




 

 
v
B
v
B
v
v
v
e
v
v
v
n


(2)
where 
 and 
 are the velocities in the local frame 
and v is the measured vehicle velocity. 
n
e
The heading angle rate could be expressed as 
follows:
Figure 7: DR/DGNSS integration scheme. 
\
\
\
\
\
H
D
\
b
V
V




 

  
(3)
where 
\
D : gyroscope gain 
\
H
: gyroscope scale factor error 
\
b : gyroscope bias 
\
V : measured gyroscope voltage 
 
The speed sensor scale factor error 
v
H , the 
gyroscope scale factor error 
\
H
and the gyroscope 
bias 
 are modelled as random-walk processes. 
From equations (1), (2) and (3) the continuous-time 
state-space realisation for the DR/DGPS is deduced: 
\
b
v
x
h
y
w
u
x
f
x

 

 
)
(
)
,
(

  
(4)
where 
>
@c
 
\
V
v
u
,
>
@c
 
\
\
H
\
H
b
e
n
x
v
and w and v are random variables. The augmented 
state equations for the DR subsystem can be stated 
in direct form or in terms of residual errors, and 
therefore the structure of the Extended Kalman Filter 
can be deduced, the measurement vectors being: 
155
A Container Location System Based on DR/DGNSS Integration

»
¼
º
«
¬
ª
 
\
V
v
k
u
)
(
 with a frequency of 200 Hz 
»
»
»
¼
º
«
«
«
¬
ª
 
\
e
n
k
z
)
(
 with a frequency of 2 Hz 
Figure 7 shows the DR/DGNSS integration 
scheme. As outputs of the prediction steps of the 
Extended Kalman Filter, a vehicle position estimate 
is obtained with a frequency of 200 Hz, although the 
correction of state estimate is applied with a 
frequency of 2 Hz. 
5 EXPERIMENTAL RESULTS 
Figure 8 shows how all the MOCONT Location 
Module elements are fitted in a Reach Stacker. In 
the course of the MOCONT project, a system 
prototype was tested at the Terminal Darsena 
Toscana (TDT) in Livorno (Italy). In the MOCONT-
II project, however, the system was implemented on 
8 prototypes tested intensively over a six-month 
period at the TDT and at the VTE terminal in Genoa 
(Italy), taking a considerable number of data for 
statistical analysis. 
The main objective of the Location Module is to 
locate precisely the container in the terminal yard. 
The yard is the surface of the terminal dedicated to 
the container storage. It is subdivided into modules, 
each one composed of corridors (carriageways used 
to move containers within a module and between 
different modules) and groups of slots. A group of 
slot is referred to as a lane. Lanes are numbered 
using capital letters, starting from A. One slot is 
uniquely identified within a lane by its yard 
coordinates: row, column and height (Figure 1). 
Therefore, 
the 
container 
position 
in 
the 
corresponding slot should be accurately estimated. 
During the project MOCONT-II more than 5600 
container position messages were collected. Results 
presented in the Final Public Report (MOCONT-II, 
2004) led to the conclusion that the performance of 
the MOCONT Location Module was 99.7% of 
correct localisation resulting from the wide set of 
trials carried out. 
Figure 8: Installation of all elements of the MOCONT Location Module on a Reach Stacker. 
The advantages of the DR subsystem are 
highlighted during the work inside container 
canyons, and generally, in the work near high stacks 
of containers which, on the other hand, are the most 
important 
moments 
for 
the 
correct 
position 
identification as this is when the Reach Stacker is 
picking up or releasing a container in a given slot. 
Figure 9 shows typical results of a Reach Stacker 
handling a container. It corresponds to data collected 
in Livorno, where the cases of container canyons 
were quite common. The figure shows the GNSS 
estimate for the position of the vehicle chassis and 
the estimate conducted by the DR subsystem, which 
156
J. Landaluze et al.

is transmitted to the GNSS on a frequency of 2 Hz. 
North and east relative position components, with 
respect to the starting point O, appear. The vehicle 
moves forward from the origin O to point A (instant 
28 s). It then moves backward to point B (instant 30 
s) from where it moves forward once again to point 
E (instant 85 s), after having passed through points 
C (instant 40 s) and D. It is at point E until instant 91 
s, when it then moves backward to point F (instant 
104 s). Covariance is not very good (always greater 
than 1), but also, between points C and D, it is 
approximately 3. As shown in the graph of Figure 9, 
when the covariance of the GNSS estimate is 
relatively low (about 1), the DR estimate continues 
to be in line with that of the GNSS. When the value 
of the covariance is large, particularly in the D-E-F 
stretch, the DR estimate is based mainly on the 
information provided by its own sensors.
In Figure 10 a detail of results obtained in Genoa 
is shown. In Genoa true container canyons rarely 
appeared, but sometimes the influence of high stacks 
of containers was evident, as in the case shown in 
the figure. The movement of the Reach Stacker 
starts at the point O, point considered as the origin of 
coordinates. The vehicles moves forward to point A 
(instant 12 s) and it is stopped at that point until 
instant 74 s, when it then moves backward to point B 
(instant 78 s). The Reach Stacker is at point B until 
instant 106 s. Then it goes forward to point C 
(instant 110 s) and after 17 s at that point the vehicle 
moves backward to point D (instant 130 s). After 11 
s it continues going backward to point E (instant 153 
s), changes movement direction and moves forward 
to point F (instant 188 s) and then it continues its 
travel. As it can be deduced from the figure, the 
Reach Stacker performed operations with containers 
at points A and C. A container was picked up from a 
slot at point A and then it was released in other slot 
at point C. 
Figure 9: Example of experimental results at the TDT terminal in Livorno. 
The GNSS data covariance was very bad from 
instant 6 s until instant 78 s and from instant 106 s 
until instant 110 s (east covariance value higher than 
3.5 and north covariance value higher than 9). 
Therefore, from point A to point C the GNSS 
estimates have poor quality, as it can be observed in 
Figure 10, but DR estimates show very well the 
movement carried out. 
6 CONCLUSIONS 
Analysis of a large number of experimental data 
obtained in the course of the MOCONT-II project 
has proven the success of the MOCONT Location 
Module in tasks involving tracking the position of 
containers in terminal yards while these are being 
handled by the Reach Stackers, recording the slot 
(row, column, tier), where the container is picked up 
or released. Integration of the Differential Global 
157
A Container Location System Based on DR/DGNSS Integration

Navigation Satellite System (DGNSS) with a Dead 
Reckoning 
(DR) 
inertial 
system 
has 
been 
demonstrated to be effective in estimating the 
position of the vehicle and of the container. 
Positioning is effective even when working in 
container canyons, on the condition that it be for a 
limited movement time of some 40 s. Apart from the 
general characteristics of the MOCONT system, the 
structure of the MOCONT Location Module has 
been presented as well as the data fusion diagram. 
Likewise, typical experimental data and the final 
evaluation of effectiveness are also presented. 
ACKNOWLEDGEMENTS
The material in this paper has been partially funded 
by the European Union under the scope of the 
Information 
Society 
Technologies 
programme 
(research projects MOCONT: IST-1999-10057 and 
MOCONT-II: IST-2001-34186). 
REFERENCES
Aono, T., K. Fujii and S. Hatsumoto. 1999. Positioning of 
a Vehicle con Undulating Ground Using GPS and 
Internal Sensors. T. SICE, vol. 35, no. 8, pp. 
1004/1001.
Benson, E.R., T.S. Stombaugh, N. Noguchi, J.D. Will and 
J.F. Reid. 1998. An evaluation of a geomagnetic 
direction sensor for vehicle guidance in precision 
agriculture applications. ASAE paper 983203.
Figure 10: Example of experimental results at the VTE terminal in Genoa. 
Landaluze, J., V. del Río, A. Milo, J. M. Ezkerra and A. 
Martínez. 2003. Desarrollo de un sistema de 
localización DR/DGPS para vehículos “off-road”. 5ª 
Semana Geomática. Barcelona, 11-14 febrero.
MOCONT-II. 
2004. 
Final 
Public 
Report.
www.mocont.org.
Ramjattan, A.N. and P.A. Cross. 1995. A Kalman Filter 
Model for an Integrated Land Vehicle Navigation 
System. Amy 1995, vol. 48 (no.2), pp. 293-302. 
Rogers, R.M. 1999. Integrated DR/DGPS using Low Cost 
Gyro and Speed Sensor. ION National Technical 
Meeting.
Sukkarieh, S., E.M. Nebot and H.F. Durrant-Whyte. 1999. 
A High Integrity IMU/GPS Navigation Loop for 
Autonomous 
Land Vehicle Applications. IEEE 
Transactions on Robotics and Automation, vol. 15, no. 
3.
Zhang, Q, J.F. Reid and N. Noguchi. 1999. Agricultural 
Vehicle Navigation Using Multiple Guidance Sensors. 
FSR'99 International Conference on Field and Service 
Robotics.
158
J. Landaluze et al.

PARTIAL VIEWS MATCHING USING A METHOD BASED ON
PRINCIPAL COMPONENTS
Santiago Salamanca Mi˜no
Universidad de Extremadura (UEX)
Escuela de Ingenir´ıas Industriales. Badajoz. Spain
Email: ssalaman@unex.es
Carlos Cerrada Somolinos
Universidad Nacional de Educaci´on a Distancia (UNED)
Escuela T´ecnica Superior de Ingenier´ıa Industrial. Madrid. Spain
Email: ccerrada@ieec.uned.es
Antonio Ad´an Oliver
Universidad de Castilla la Mancha (UCLM)
Escuela Superior de Ingenier´ıa Inform´atica. Ciudad Real. Spain
Email: Antonio.Adan@uclm.es
Miguel Ad´an Oliver
Universidad de Castilla la Mancha (UCLM)
Escuela Universitaria de Ingenier´ıa T´ecnica Agr´ıcola. Ciudad Real. Spain
Email: Miguel.Adan@uclm.es
Keywords:
Matching, recognition, unstructured range data, 3D computer vision.
Abstract:
This paper presents a method to estimate the pose (position and orientation) associated to the range data of an
object partial view with respect to the complete object reference system. A database storing the principal com-
ponents of the different partial views of an object, which are generated virtually, is created in advance in order
to make a comparison between the values computed in a real view and the stored values. It allows obtaining
a ﬁrst approximation to the searched pose transformation, which will be afterwards reﬁned by applying the
Iterative Closest Point (ICP) algorithm.
The proposed method obtains very good pose estimations achieving very low failure rate, even in the case of
the existence of occlusions. The paper describes the method and demonstrates these conclusions by presenting
a set of experimental results obtained with real range data.
1
INTRODUCTION
Relative pose of the partial view of an object in a
scene with respect to the reference system attached to
the object can be determined by using matching tech-
niques. This work is concerned with the problem of
matching 3D range data of a partial view over the 3D
data of the complete object. Resolution of this prob-
lem is of utmost practical interest because it can be
used in applications like industrial robotics, mobile
robots navigation, visual inspection, etc.
A standard way of dealing with this problem is to
generating a model from the data, which allows ex-
tracting and representing some information associated
to the source data. There are two basic classes of rep-
resentation (Mamic and Bennamoun, 2002): object
based representations and view based representations.
In the ﬁrst class, models are created by extracting
representative features of the objects. This type can be
divided into four major categories: boundaries repre-
sentations, generalized cylinders, surface representa-
tions and volumetric representations, being the third
one the mostly used. In this case, a surface is ﬁtted
from the range data and then certain features are ex-
tracted from the ﬁtted surface. Spherical representa-
tions belong to this category, being the Simplex An-
gle Image (SAI) representation (Higuchi et al., 1994;
Hebert et al., 1995; Ad´an et al., 2001b; Ad´an et al.,
2001a) an important example of this type of surface
representation. In general terms, object based repre-
sentations are not the most suitable ones for applica-
tion in partial views matching.
Concerning to the view based representations they
try to generate the model as a function of the di-
verse appearances of the object from different points
of view. There exist a lot of techniques that belong to
159
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 159–166. 

this class (Mamic and Bennamoun, 2002). Let us re-
mark the methods based in principal components (PC)
(Campbell and Flynn, 1999; Skocaj and Leonardis,
2001), which use them in the matching process as dis-
criminant parameters to reduce the initial range im-
ages database of an object generated from all possible
viewpoints.
The method presented in this paper can be classi-
ﬁed halfway of the two classes because the appear-
ance of the object from all the possible points of view
are not stored and managed.
Instead of that, only
some features of each view are stored and handled.
More speciﬁcally, just three critical distances are es-
tablished from each point of view. These distances
are determined by means of the principal components
computation. A ﬁrst approach to the transformation
matrix between the partial view and the complete ob-
ject can be obtained from this computation. The de-
ﬁnitive transformation is ﬁnally achieved by apply-
ing a particular version of the Iterative Closest Point
(ICP) algorithm (Besl and McKay, 1992) to the gross
transformation obtained in the previous stage. A com-
parative study of different variants of the ICP algo-
rithm can be seen in (Rusinkiewicz and Levoy, 2001).
The paper is organized as follows. A general de-
scription of the overall method is exposed in the next
section. The method developed to obtain the database
with the principal components from all the possible
viewpoints are described is section 3. Section 4 is de-
voted to present the matching algorithm built on top
of the principal components database. A set of exper-
imental results is shown in section 5 and conclusions
are stated in section 6.
2
OVERALL DESCRIPTION OF
THE METHOD
As it has been mentioned, the ﬁrst stage of the pro-
posed method is based on the computation of the prin-
cipal components from the range data corresponding
to a partial view. Let us call X to this partial view.
Principal components are deﬁned as the set of eigen-
values and eigenvectors {(λi,˜ei) |i = 1, . . . , m} of
the Q covariance matrix:
Q = XcXT
c
(1)
where Xc represents the range data translated with
respect to the geometric center.
In the particular case we are considering, Xc is a
matrix of dimension n × 3 and there are three eigen-
vectors that point to the three existing principal direc-
tions. The ﬁrst eigenvector points to the spatial di-
rection where the data variance is maximum. From
a geometrical point of view, and assuming that the
range data is homogeneously distributed, it means
that the distance between the most extreme points pro-
jected over the ﬁrst direction is the maximum among
all possible Xc couple of points. The second vec-
tor points to another direction, normal to the previ-
ous one, in which the variance is maximum for all the
possible normal directions. It means again that the
distance between the most extreme points projected
over the second direction is the maximum among all
the possible directions normal to the ﬁrst vector. The
third vector makes a right-handed reference system
with the two others.
The eigenvalues represent a
quantitative measurement of the maximum distances
in each respective direction.
From the point of view of its application to the
matching problem it is important to remark ﬁrstly that
the eigenvalues are invariant to rotations and trans-
lations and the eigenvectors invariant to translations,
and secondly that the frame formed by the eigenvec-
tors represents a reference system ﬁxed to the own
range data. The ﬁrst remark can be helpful in the
process of determining which portion of the complete
object is being sensed in a given partial view, i.e. the
recognition process. The second one gives an initial
estimation of the searched transformation matrix that
matches the partial view with the complete object in
the right pose. In fact, it is only valid to estimate the
rotation matrix because the origins of the reference
systems do not coincide.
To implement the recognition process it is neces-
sary to evaluate, in a previous stage, all the possible
partial views that can be generated for a given com-
plete object. We propose a method that considers a
discretized space of the viewpoints around the object.
Then a Virtual Partial View (VPV) is generated for
all the discretized viewpoints using a z-buffer based
technique. Principal components of each one of these
VPV are then computed and stored, such that they can
be used in the recognition process.
Initial information of the possible candidate zones
to matching a sample partial view to the complete ob-
ject can be extracted by comparing the eigenvalues of
the sample with the stored values. Nevertheless, this
is only global information and it only concerns to ori-
entation estimation. A second process must be imple-
mented in order to obtain a ﬁne estimate of the ﬁnal
transformation matrix. We use the ICP algorithm ap-
plied to the set of candidates extracted in the previous
process. The transformation matrix estimated from
the eigenvectors is used as the initial approximation
required by the ICP algorithm. The ﬁnal matching
zone is selected as the one that minimizes the ICP er-
ror. Figure 1 shows a schematic block diagram of the
entire developed method. More implementation de-
tails are explained in next sections.
160
S.S. Mino et al.
˜

Transformation
computation
process
Range data of
the sample
partial view PV
PV  principal
components
computation
Eigenvalues
comparison
(View Point
estimation)
Initial
Transformation
matrix
estimation
ICP algorithm
application.
Final
transformation
matrix
computation
Model
generation process
(off-line)
Range data of
the complete
object
Virtual Partial
Views ( VPV )
computation
Principal
Components
of the VPV
computation
Eigenvalues
storage
Eigenvectors
storage
Figure 1: Block Diagram of the proposed method to ﬁnd
the best match of a given range data partial view with the
complete object.
Range  data of
the complete
object
(input  data)
Principal
Components
of the VPV
computation
Repeat  for all the view points around the object
Multipixel
image
generation
z-buffer
algorithm
application
Data filtering
Virtual Partial View (VPV) computation
Figure 2: Block diagram of the process followed to generate
the principal components database.
3
PRINCIPAL COMPONENTS
DATABASE GENERATE
A database storing the principal components of all the
possible partial views that can be generated from the
range data of a given complete object must be com-
puted in an off-line previous stage. Figure 2 shows
the steps followed in this process.
Range data of the complete object is ﬁrstly trans-
lated to its geometric center and then normalized to
the unit value. Therefore, we will start to work with
the following normalized range data:
Mn =
M −c
max (∥M −c∥)
(2)
where M is the range data of the complete object, c
is the geometric center, max is the maximum function
and || · || is the Euclidean distance. At this point, as
can be observed in Figure 2, the most important step
of the method is the computation of the virtual partial
views (VPV) described in the next subsection.
3.1
Virtual Partial Views
Computation
A VPV can be deﬁned as a subset of range data points
O ⊂Mn virtually generated from a speciﬁc view-
point VP, and that can be approximated to the real par-
tial view obtained with a range sensor from the same
VP.
Notice that in this deﬁnition it is necessary to con-
sider, apart from the object range data itself, the view-
point from which to look at the object. In order to
Figure 3: Visual space discretization around the complete
object range data. Each sphere node constitutes a different
viewpoint from which a VPV is estimated.
take into account all the possible viewpoints, a dis-
cretization of the visual space around the object must
be considered. A tessellated sphere circumscribed to
the object is used for that and each node of the sphere
can be considered as a different and homogeneously
distributed viewpoint from where to generate a VPV
(see Figure 3).
For a speciﬁc VP its corresponding virtual partial
view is obtained by applying the z-buffer algorithm.
This algorithm is widely used in 3D computer graph-
ics applications and it allows deﬁning those mesh
patches that can be viewed from a given viewpoint.
Speciﬁcally, only the facets with the highest value of
the z component will be visible, corresponding the Z-
axis with the viewing direction.
This method is designed to apply when there is
information about the surfaces to visualize, but not
when just the rough 3D data points are available.
Some kind of data conversion must be done previous
to use the algorithm as it is. We have performed this
conversion by generating the named multipixel matrix
of the range data. This matrix can be obtained as fol-
lows. First a data projection over a plane normal to
the viewing direction is performed:
M′
n = UMn
(3)
where U is the matrix representing such projection.
This transformation involves a change from the orig-
inal reference system S = {O, X, Y, Z} to the new
one S′ = {OX′Y ′Z′} where the Z’ component, de-
noted as z’, directly represents the depth value. From
these new data an image can be obtained by discretiz-
ing the X’Y’ plane in as many pixels as required, and
by assigning the z’ coordinate of each point as the im-
age value. Notice that in this process several points
can be associated to the same pixel if they have the
161
Partial Views Matching Using a Method Based on Principal Components

Projected
2D points
Depth
3D points  with the
same 2D projection
Figure 5: Visualization of each one of the planes of the mul-
same (x’,y’) coordinate values. To avoid depth infor-
mation loss in these cases, the image values are stored
in a three dimensional matrix. For that reason the cre-
ated structure is denoted as multipixel matrix.
Figure 4 shows a typical scheme of this matrix. On
the other hand, ﬁgure 5 shows as a grey-scaled image
and in a compacted manner all the two-dimensional
matrices that conform this structure. Pixels next to
white color represent higher z’ values. Figure 6 shows
an image obtained by selecting for each pixel the
maximum of its associated z’ values. If the data points
corresponding to these selected z’ values are denoted
as O′ ⊂M′
n, then the VPV can be obtained by ap-
plying the inverse of the U transformation deﬁned in
equation (3), i.e.:
O = U−1O′
(4)
The set of range data points corresponding to a
VPV obtained after the application of the described
process to a sample case can be seen in the ﬁgure 7 (a)
and (b). It can be observed that results are generally
acceptable but some spurious data appear. These val-
ues were already noticeable from ﬁgure 6 where they
look like a salt-pepper noise effect. Due to this fact,
a median ﬁlter (see ﬁgure 8) is applied to the image
before evaluating the equation (4), in order to obtain
the deﬁnitive range data points of the searched VPV
(ﬁgure 9).
Figure 6: Intensity image associated to the maximum value
of z′ at each pixel.
(b)
Spurious  data
(a)
Figure 7: Range data points corresponding to a Virtual Par-
tial View. They are shown from two different points of view
to improve their visualization. In (b) the existence of spuri-
ous data are more evident.
Figure 8: Image obtained after applying a median ﬁlter to
162
tipixel matrix as a compacted intensity image.
Figure 4: Multipixel matrix representation.
S.S. Mino et al.
˜
the image shown in ﬁgure 6.

Figure 9: Deﬁnitive range data of a VPV. It can be observed,
comparing with the ﬁgure 7(b), that the noise has been re-
X
Y
Z
X
Y
Z
X
Y
Z
Y
Z
X
Figure 10: Four ambiguous frames for direction combina-
3.2
Principal Components of VPV
Computation
Once the range data points of a VPV have been de-
termined the associated principal components can be
computed from them. They will be the eigenvectors
and the eigenvalues of the covariance matrix at (1),
where Xc is now O.
Due to the fact that the eigenvectors only provide
information about the line vectors but not about their
directions, some uncertainties can appear in the ul-
terior matching process.
For example, using right
handed coordinate systems like in ﬁgure 10, if no di-
rection is ﬁxed in advance there are four ambiguous
possibilities for frame orientation. It can be also seen
in the ﬁgure 10 that when one of the line directions is
ﬁxed only two possibilities appear, being related one
to the other by a rotation of π radians around the ﬁxed
axis. For that reason, before storing the VPV eigen-
vectors, following steps are applied:
1. Verify if the third eigenvector forms an angle
smaller than π/2 with the viewing direction. If not,
we take the opposite direction for this eigenvector.
2. The ﬁrst eigenvector direction is taken to build to-
gether with the two others a right-handed frame.
After these steps, principal components of the VPV
are stored in the database for posterior use in the
matching process.
Figure 11 shows the deﬁnitive
principal components of a given VPV.
Figure 11: Deﬁnitive eigenvectors computed from the range
data of a VPV. The ﬁrst one is represented in red, second in
green and the third in blue.
4
MATCHING PROCESS
The developed matching process is divided in four
stages (see ﬁgure 1):
1. Principal components computation of the acquired
partial view.
2. eigenvalues comparison and initial candidates
zones selection.
3. Initial transformation estimation by using the
eigenvectors.
4. ICP algorithm application to determine the ﬁnal
transformation.
The method developed to carry out the three ﬁrst
stages is described in the next subsection. Then we
will explain how the ICP algorithm is applied to ob-
tain the ﬁnal result.
4.1
Initial Transformation Matrix
Computation
The ﬁrst thing to do is to compute the eigenvectors
and eigenvalues of the acquired range partial view.
To maintain equivalent initial conditions than in the
VPV computation we must apply the same steps ap-
plied to the complete object range data: normalization
with respect to the geometric center of the complete
object, M; multipixel matrix generation; z-buffer al-
gorithm application and, ﬁnally, data ﬁltering. In this
case the main objective is to try the handled data being
the most similar possible to those used in the principal
component computation of the VPV.
After that, the principal components are computed
and the deﬁnitive vector directions are established fol-
lowing the steps described in subsection 3.2. Then the
eigenvalues of the acquired view are compared with
the eigenvalues of all the stored VPV by evaluating
the following error measurement:
163
moved.
tions.
Partial Views Matching Using a Method Based on Principal Components

(a)
(b)
(c)
Figure 12: Results of the comparing eigenvectors algo-
rithm. (a) Visualization of the acquired range data partial
view. (b) Five selected candidate viewpoints from eλ error
eλ = ||Λv −Λr||
(5)
where Λv = {λv
1, λv
2, λv
3} is the vector formed by the
eigenvalues of a VPV, Λr = {λr
1, λr
2, λr
3} is the vector
formed by the eigenvalues of the real partial view and
|| · || is the Euclidean distance.
Notice that a given VPV can achieve the minimum
value of eλ and not being the best candidate. This
is because the feature we are using is a global one.
For that reason we take a set of selected candidates to
compute the possible initial transformation. Speciﬁ-
cally, we are selecting the ﬁve VPV candidates with
less error.
These initial transformations do not give the exact
required rotation to coupling the eigenvector because
the original data are not normalized with respect the
same geometric center. Mathematically, what we are
computing is the rotation matrix R such that applied
to the eigenvectors of the real partial view, Er, gives a
set of eigenvectors coincident with the VPV ones, Ev.
Because both Er and Ev represent orthonormal ma-
trices, the searched rotation matrix can be computed
from the next expression:
R = Er (Ev)−1 = Er (Ev)T
(6)
Because of the ambiguity of the two possible di-
rections existing in the eigenvectors deﬁnition, the ﬁ-
nal matrix can be the directly obtained in (6) or an-
other one obtained after rotating an angle of π radians
around the third eigenvector.
Figure 12 shows the results of the comparing eigen-
vectors algorithm.
In (a) the real partial view is
shown. The ﬁve selected candidates with less eλ er-
ror values are remarked over the sphere in part (b).
An arrow indicates the ﬁrst candidate, i.e. the corre-
sponding to the minimum eλ value. The approximate
R matrix obtained as a result of equation (6) evalua-
tion can be observed in (c). In this case the result cor-
responds to the VPV associated to the ﬁrst candidate
viewpoint. Deﬁnitive matrix will be obtained after a
reﬁnement process by means of the ICP algorithm ap-
plication.
Summarizing, the resulting product of this phase is
a transformation matrix T whose sub matrix R is ob-
tained from equation (6) and whose translation vector
is t = [0, 0, 0]T .
4.2
ICP Algorithm Application
The Iterative Closest Point (ICP) (Besl and McKay,
1992) is an algorithm that minimizes the medium
quadratic error
e(k) = 1
n

||P −P′||2
(7)
among the n data points of an unknown object P’,
called scene data, and the corresponding data of the
database object P, called model data. In our particu-
lar case, the scene data are the range data of the real
partial view, Xc, normalized and transformed by the
T matrix, and the model data are the subset of points
of the complete object Mn that are the nearest to each
of the scene points. The latest will change at each it-
eration step.
Once the model data subset in a given iteration step
k are established, and assuming that the error e(k) is
still bigger than the ﬁnishing error, it is necessary to
determine the transformation matrix that makes min-
imum the error e(k). Solution for the translation part,
the t vector, is obtained from the expression (Forsyth
and Ponce, 2002):
t = 1
n
n

i=1
ri −1
n
n

i=1
r′
i
(8)
where ri and r′
i are the coordinates of the model data
points and scene data points respectively.
With respect to the rotation part, the rotation matrix
R that minimizes the error, we have used the Horn
approximation (Horn, 1988), in which R is formed by
the eigenvectors of the matrix M deﬁned as:
M = P (P′)T
(9)
This approximation gives a closed-form solution
for that computation, which accelerates signiﬁcantly
the ICP algorithm.
The algorithm just described is applied to the ﬁve
candidates selected in the previous phase. The chosen
ﬁnal transformation matrix will be that one for which
the ﬁnishing ICP error given by expression (7) is the
smaller one.
Figure 13 shows the results for the same data points
of ﬁgure 11 after application of the ICP algorithm.
Partial view after applying the ﬁnal transformation
matrix matched over the object and the complete ob-
ject range data are plotted together. Plots from two
different points of view are shown to improve the vi-
sualization of the obtained results.
164
computation. (c) Rotated data results for the ﬁrst candidate.
S.S. Mino et al.
˜

Figure 13: Final results of the overall matching algorithm
Figure 14: Set of objects used to test the presented algo-
5
EXPERIMENTAL RESULT
The algorithm proposed in the present work has been
tested over a set of 21 objects. Range data of these ob-
jects have been acquired by means of a GRF-2 range
sensor which provides an average resolution of ap-
proximately 1 mm. Real size of the used objects goes
from 5 to 10 cm. height and there are both polyhedral
shaped and free form objects (see ﬁgure 14).
We have used a sphere with 1280 nodes to com-
pute the principal components for the complete ob-
ject. Some tests have been made with a mesh of 5120
nodes, but the associated increment of the computa-
tion time does not bring as a counterpart any improve-
ment in the obtained matching results.
With respect to the multipixel matrix, sizes around
22x22 pixels have empirically given good results. The
matrix size can be critical in the method functionality
because high value implies poor VPV generation, and
low value involves a reduction in the number of range
data points that conform the VPV, making unaccept-
able the principal components computation.
Once the principal components database was gen-
erated for all the considered objects we have checked
the matching algorithm.
Three partial views have
been tested for each object, making a total of 63 stud-
ied cases. The success rate has been the 90,67%, what
(a)
(b)
(c)
(d)
Object 1
(a)
(b)
(c)
(d)
Object 2
Figure 15: Some results over polyhedral objects of the pro-
(a)
(b)
(c)
(d)
Object 3
(a)
(b)
(c)
(d)
Objeto  4
Figure 16: Some results over free form objects of the pro-
demonstrates the validity of the method.
The average computation time invested by the algo-
rithm has been 75 seconds, programmed over a Pen-
tium 4 at 2.4 GHz. computer under Matlab environ-
ment. The time for the phase of eigenvalues com-
parison and better candidates’ selection is very small,
around 1 sec. The remaining time is consumed in the
computation of the principal components of the real
partial view and, mainly, in the application of the ICP
algorithm to the ﬁve candidates: ﬁve times for the di-
rect computation of the R matrix from equation (6),
and another ﬁve times due to the direction ambigu-
ity existing in the eigenvectors deﬁnition described in
subsection 3.2.
Figures 15 and 16 show the results obtained with
several polyhedral and free-form objects respectively.
Apart from the intensity image of the object, sub-
plot (a) presents the range data of the complete ob-
ject, subplot (b) shows the partial view set of points,
subplot (c) shows the data transformed after eigen-
values comparison, and subplot (d) contains the ﬁnal
results after ICP algorithm application. Some plots
have been rotated to enhance data visualization.
Finally it is important to remark that the devel-
oped algorithm can handle partial views with auto-
occlusions. Figure 17 shows an example of this case.
165
visualized from two different points of view.
posed method.
rithm.
posed method.
Partial Views Matching Using a Method Based on Principal Components

(a)
(b)
(c)
(d)
Object 4
Figure 17: Results of the method in a free form object with
6
CONCLUSIONS
A method to ﬁnd the best matching of a range data
partial view with the complete object range data has
been presented in this work. The method takes ad-
vantage of the principal components concept.
The
eigenvalues comparison allows determining the most
probable matching zones among the partial view and
the complete object. The corresponding eigenvectors
are used to compute an initial transformation matrix.
Applying the ICP algorithm reﬁnes this one and the
deﬁnitive transformation is obtained.
For the comparison purposes a database of prin-
cipal components must be generated in advance. A
procedure has been designed and described to virtu-
ally generate all the possible partial views of a given
complete object and then to compute the associated
principal components. The procedure is based on the
z-buffer algorithm.
The method has been tested over a database con-
taining 21 objects, both polyhedral and free form, in a
63 case study (three different views for each object).
The success rate has been the 90,67%. The method
has proven its robustness to auto-occlusions. Some
improvements can still to be made in a future concern-
ing to the candidate selection step. Several candidates
appear at the same zone and they could be grouped
into the same one for the following step of ICP appli-
cation.
Finally it is important to remark that the pre-
sented method has very good performance in the
shown matching problem but it can also be applied
in recognition applications with similar expected per-
formance.
ACKNOWLEDGEMENTS
This work has been developed under support of the
Spanish Government through the CICYT DPI2002-
03999-C02-02 contract.
REFERENCES
Ad´an, A., Cerrada, C., and Feliu, V. (2001a). Automatic
pose determination of 3D shapes based on modeling
wave sets: a new data structure for object modeling.
Ad´an, A., Cerrada, C., and Feliu, V. (2001b). Global shape
invariants: a solution for 3D free-form object discrim-
ination/identiﬁcation problem.
Pattern Recognition,
34(7):1331–1348.
Besl, P. and McKay, N. (1992). A method for registration
of 3-D shapes. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 14(2):239–256.
Campbell, R. J. and Flynn, P. J. (1999). Eigenshapes for 3D
object recognition in range data. In Proc. of the IEEE
Conference on Computer Vision and Pattern Recogni-
tion, volume 2, pages 2505–2510.
Forsyth, D. A. and Ponce, J. (2002). Computer Vision: A
Modern Approach. Prentice Hall.
Hebert, M., Ikeuchi, K., and Delingette, H. (1995).
A
spherical representation for recognition of free-form
surfaces. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 17(7):681–690.
Higuchi, K., Hebert, M., and Ikeuchi, K. (1994). Merg-
ing multiple views using a spherical representation. In
IEEE CAD-Based Vision Workshop, pages 124–131.
Horn, B. K. (1988). Closed form solutions of absolute ori-
entation using orthonormal matrices. Journal of the
Optical Society A, 5(7):1127–1135.
Mamic, G. and Bennamoun, M. (2002). Representation and
recognition of 3D free-form objects. Digital Signal
Processing, 12(1):47–76.
Rusinkiewicz, S. and Levoy, M. (2001). Efﬁcient variants
of the ICP algorithm. In Proceeding of the Third Inter-
national Conference on 3D Digital Imaging and Mod-
eling (3DIM01), pages 145–152, Quebec, Canada.
Skocaj, D. and Leonardis, A. (2001). Robust recognition
and pose determination of 3-D objects using range im-
age in eigenspace approach.
In Proc. of 3DIM’01,
pages 171–178.
166
existence of auto occlusions.
S.S. Mino et al.
˜
Image and Vision Computing, 19(12): 867–890.

TOWARDS A CONCEPTUAL FRAMEWORK-BASED
ARCHITECTURE FOR UNMANNED SYSTEMS
Norbert Oswald
European Aeronautic Defence and Space Company - EADS,
Military Aircraft, 81663 Munich, Germany
norbert.oswald@m.eads.net
Keywords:
Software architecture, autonomous system, modelling.
Abstract:
Future unmanned aerial systems demand capabilities to perform missions automatically to the greatest possi-
ble extent. Missions like reconnaissance, surveillance, combat, or SEAD usually consist of recurring phases
and contain resembling or identical portions such as autonomous ﬂight control, sensor processing, data trans-
mission, communication or emergency procedures. To avoid implementing many similar singular solutions,
a systematic approach for the design of an unmanned avionic software architecture is needed. Current ap-
proaches focus on a coarse system design, do not integrate off-the-shelf middleware, and do not consider the
needs for having on-board intelligence.
This paper presents a reference software architecture to design and implement typical missions of unmanned
aerial vehicles based on a CORBA middleware. The architecture is composed of identical components and
rests upon the peer-to-peer architectural style. It describes the internal structure of a single component with re-
spect to autonomous requirements and provides a framework for the rapid development and implementation of
new components. The framework separates functionality and middleware by hiding ORB speciﬁc statements
from components. Experimental tests simulating a reconnaissance mission using various ORB implementa-
tions indicate the beneﬁts of having an architectural design supporting multi-lingual multi-process distributed
applications.
1
INTRODUCTION
As a result of technological advances in many dis-
ciplines like ﬂight control, data and signal process-
ing, sensor engineering, communication links, and
integrated modular avionics, the development of un-
manned aerial systems is currently of great interest
in the domain of military aircrafts.
Such systems
raise the possibility to conduct military operations in
a more efﬁcient and less risky fashion than before but
require robustness and reliability. Because of its dy-
namic, stochastic, and largely unknown environment,
the execution of missions needs software systems that
are able to act autonomously especially in situations
were no remote control is possible.
Missions like reconnaissance, surveillance, com-
bat, suppression of enemy air defence, or air-to-air
contain a number of components that can be recycled.
From the software point of view a mission typically
consists of a mission independent and a mission de-
pendent part. Tasks of the mission independent part
like takeoff, landing, or autonomous ﬂight recur for
various missions. But also in the independent part re-
sembling or identical portions such as data transmis-
sion, communication or emergency procedures occur.
This suggests to design and build a unique software
architecture facilitating to cover demands of most
missions. To do so, one has to incorporate features
of today’s avionic systems. Characteristic for avionic
applications are their heterogeneous and distributed
environment with various platforms as well as exist-
ing and approved multi-lingual legacy code. As re-
design, porting and testing of software to new plat-
forms is costly and time-consuming, one needs a soft-
ware architecture that integrates existing code written
for particular platforms, in various languages, for dif-
ferent operating systems as well as COTS products.
Desirable would be an open platform that enables dis-
tributed computing, dynamic algorithm plug-in, and a
rapid algorithm switching, also incorporating aspects
such as real-time, fault tolerance and security.
When dealing with the development of such a soft-
ware architecture one has to consider the work done
so far from three subject areas, the military sector, the
167
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 167–177. 

artiﬁcial intelligence community and the ﬁeld of ar-
chitecture description languages (ADL). In the mili-
tary sector, there is still a primary focus on the de-
sign of physical platforms, low-level control systems
and sensing.
Recently, there has been some work
started in order to build so-called open source plat-
forms. OCP is a joint venture from Boeing, Georgia
Institute of Technologies and Honeywell Laboratories
to build an open control platform designed to give fu-
ture UAVs more capable ﬂight control systems and in-
tegrates interdisciplinary systems that enables recon-
ﬁgurable control (Schrage and Vachtsevanos, 1999)
(Wills et al., 2001). A prototype of OCP was lately
tested on a UAV helicopter. JAUS is another example
of a joint venture to design an architecture for future
unmanned systems. The main focus of this project
is based upon building an architecture for various
unmanned systems that tries to become independent
from technological trends (JAUS, 2004) (Hansen,
2003). A third initiative is the avionics architecture
description language (AADL) which is expected to
pass as a standard soon. The AADL has be designed
to support a model-based architecture-driven devel-
opment of large-scale systems with an emphasis on
concepts that address performance-critical embedded
systems concerns like timing and performance (Feiler
et al., 2003) (Dissaux, 2004).
Building of software architectures has a long tradi-
tion in the artiﬁcial intelligence community. The ﬁrst
important developments go back to the early 80s with
the deliberative architectures from (Nilsson, 1980)
that are characterised through predictable and prede-
termined communication between layers.
Reactive
behaviour-based architectures introduced by (Brooks,
1986) that emphasised parallelism over hierarchy ap-
peared later. Intelligent behaviour in such an archi-
tecture emerges from the interactions of multiple be-
haviours and the real world. To combine the beneﬁts
of both approaches and thus enabling reactive behav-
iour and planning capabilities a multitude of hybrid
architectures have been introduced over the interven-
ing years. An overview about various architectures
in AI applications can be found e.g. in (Kortenkamp
et al., 1998). Currently, distributed agent architec-
tures are under investigation. A sample architecture is
the Open Agent Architecture, a domain-independent
framework for integrating heterogeneous agents in a
distributed environment based on the interagent com-
munication language (Cheyer and Martin, 2001).
Architecture description languages have become an
area of intense research in the software engineering
community.
They deﬁne software architectures as
reusable and transferable abstractions of software sys-
tems (Clements et al., 2002), composed of compo-
nents, connectors, and conﬁgurations to deﬁne locus,
interaction, and topology (Garlan and Shaw, 1993).
In general, software architectures are used to describe
the structure of software systems. Support exists from
a number of architectural description languages like
Adage (Coglianese and Szymanski, 1993), C2 (Med-
vidoc et al., 1996) (Medvidoc, 1999), Meta-H (Binns
and Vestal, 1993), or ACME (Garlan et al., 2000) to
name but a few. xADL, another ADL, has been eval-
uated by a number of projects like AWACS aircraft
software system or Mission Data System (Dashofy
et al., 2002). It can be used in a ﬂexible manner to
develop new styles and architectures on a coarse de-
scription level, suited even for families of architec-
tures.
An extensive comparison of the various de-
scription languages can be found in (Medvidovic and
Taylor, 2000). Although used in a variety of applica-
tions, each ADL has its particular justiﬁcation but so
far none of them has accomplished as being a stan-
dard.
At present, most of the propagated approaches lack
on the one hand of support for integrating off-the-
shell middleware (Nitto and Rosenblum, 1999) and
consider on the other hand only the design of coarser-
grained architectural elements. Instead of ignoring
the results that practitioners have achieved in the de-
ﬁnition of middlewares, the design of a software ar-
chitecture should incorporate both, the beneﬁts of
top-down and bottom-up approaches. Some research
concerning the integration of middleware has already
To
build
systems
with
capabilities
for
self-
dependent acting requires a ﬁne-grained design. This
regards in particular the internal architecture of sin-
gle architectural elements like components or connec-
tors. To support this, the present article describes an
integrated view to the design of a reference software
architecture for the domain of unmanned aerial ve-
hicles regarding coarse-grained and ﬁne-grained as-
pects with respect to autonomous requirements. Com-
ponents are considered as architectural elements that
encapsulate functionality in a blackboard style. That
means, the way of providing a service is of no con-
sideration as long as a reasonable result is returned
and each component therefore possesses mechanisms
to ensure the required quality of service.
2
DESCRIPTION OF THE
SOFTWARE ARCHITECTURE
The reference software architecture is an abstract
model that may be substantiated for a multiplicity of
missions. It consists of identical constructed compo-
nents, so-called autonomous entities (AEs), covering
roles and functionalities, connectors that contain var-
ious ORB middleware implementations, and conﬁgu-
rations that describe potential connection structures.
168
N. Oswald
been started (e.g. (Dashofy et al., 1999)).

peer approach meaning that peers respectively AEs
may exist independently from each other.
A pri-
ori, no deﬁned hierarchies exist, but resulting from
the selected AE during setup inherent hierarchies
might appear. The proposed hybrid architecture com-
bines behaviour-based and functional-based aspects
and thus provides deliberative and reactive system be-
haviour. The proposed architecture assists coopera-
Unmanned System two
Unmanned System one
AE
AE
AE
AE
AE
AE
AE
AE
AE
AE
AE
AE
Ground Station
AE        Autonomous Entity
tion not only between AEs of a single system but also
in a group of unmanned systems. Figure 1 shows the
design and conﬁguration of the software architecture
in a single system as well as in a more complex con-
text, being a part of a compound systems, e.g. with a
ground station and another unmanned system.
2.1
In the following, the architectural elements are iden-
tiﬁed and described at domain level. This is done in a
non-formal way but with respect to standard ADLs.
2.1.1
Components
Components respectively AEs are major ingredients
including the functionalities that sum up to the sys-
tem capabilities. They work concurrently, synchro-
nously, or asynchronously and adopt certain roles ac-
cording to the embedded functionality. AEs are iden-
tiﬁed through the process of decomposing missions
in order to locate recurring conceptual formulations.
At this level of abstraction, the internal representation
of an AE is up to the blackboard style known from
artiﬁcial intelligence technologies. To grant access,
AEs provide ﬁxed interfaces for their services to the
general public. These so-called service interfaces are
a generalisation of their embedded functionality, that
is to say, they contain no explicit implementation de-
tails.
At design time, own service interfaces are made
available but the precise implementation of an AE’s
functionality is unknown. Because of that, there ex-
ist no information about possibly required service in-
terfaces from other AEs. Thus, there exist no a pri-
ori knowledge about connections between AEs at this
level.
2.1.2
Connectors
Connectors are used to model the communication be-
tween AEs in ADL. In the above software architec-
ture, the CORBA middleware is separated from the
AEs and embedded into the connectors by hiding all
ORB speciﬁc activities. If using exclusively TCP/IP-
based communication, it is possible to join the con-
nectors to constitute a communication network based
on CORBA middleware. To do so with heterogeneous
mediums, some effort to implement pluggable proto-
cols is required (see e.g. (Ryan et al., 2000)). Resolv-
ing known services to the locations of their providing
AEs require either a central component similar to the
yellow pages or numerous communications between
AEs performing sophisticated protocols. In terms of
efﬁciency, a Service Broker is used that manages the
connectors by resolving their requests and keeping
their services and thus assists a component to ﬁnd a
particular service in the network. An AE accesses a
service simply by calling connect(name). The con-
nector forwards this call to the Service Broker which
resolves the request and returns a CORBA object. The
latter is narrowed by the connector and returned to the
client in form of a usual object reference. This proce-
dure applies too for the access of service interfaces
beyond the particular system.
2.1.3
Conﬁguration
The conﬁguration is used to describe how a system is
built-up. As a consequence of using the framework
that hides the middleware, the coupling between AEs
and connectors during design time requires only one
identical interface, namely connect(name) with name
specifying the name of the service interface. Thus, an
explicit modelling of the relationship between AEs
and connectors is reduced to a single recurring de-
scription.
As a matter of fact, a linking between AEs occurs
through claiming of general public service interfaces.
A concrete conﬁguration will be chosen only at the
beginning of a session. An operator selects from a set
of available AEs the one, that provide the required
mission functionality. The connection structure for
the concrete mission emerges not until the system was
instantiated. Nevertheless, dynamically added AEs
to the running system may be integrated into the con-
nection structure if a dependency to functionalities of
other AEs exists.
169
The design of the architecture follows a peer-to-
Figure 1: Design of the software architecture.
Architectural Elements
Towards a Conceptual Framework-Based Architecture for Unmanned Systems

2.2
Off-the-shelf middleware provides useful mecha-
nisms to enable communication among several pos-
sibly distributed components together with a number
of services like transactional communication or event-
based interactions. In order to use these beneﬁts with-
out having dependencies onto the chosen middleware,
a framework was developed, that encapsulates ORB
speciﬁc functionality into the connectors. Essential
elements in the framework are the structure of ser-
vices and the Service Broker.
2.2.1
Basic element of the architecture is the service, as
communication between AE is mainly based upon
the use of services.
Services are deﬁned by IDL
interfaces describing how to access a particular func-
<component name="Navigator">
<interfaces>
<implements>
<type>IDL:AE navigatorI/INavigator</type>
<optional>
<parameter name="Planner">
<type>IDL:AE navigator/IPlanner</type>
</parameter>
<parameter name="Time limit"></parameter>
</optional>
<attribute name="latency" value="100" />
</implements>
</interfaces>
<dependencies>
<depends>IDL:AE flightControllerI/IFlightController
</depends>
</dependencies>
<subcomponents>
<subcomponent>IDL:AE navigator/IPlanner</subcomponent>
</subcomponents>
</component>
tionality. To access a service, the name of the ser-
vice interface has to be known. At run-time, an AE
must know about the service interface it provides and
about the service interfaces it requires. These infor-
mations are covered in XML notation for each AE.
Figure 2 shows a sample description of the service in-
terface INavigator provided by the component Navi-
gator. The implements tag indicates that INavigator is
the service interface of the AE. In order to be able to
provide a service, an AE may depend upon additional
service providers. Such dependencies are tagged by
dependencies. In the above example, the AE needs
optionally an implementation for the interface IPlan-
ner and depends on an AE that provides the service
interface IFlightController.
To separate implementation details from the deﬁ-
nition of the service interface, a service uses only a
single parameter of type string. That means, the im-
plementation part is hidden in a textual context, need-
ing a description on how to interpret it. The para-
meters can be required or optional like Planner, and
inform clients of which information they need to pro-
vide in order to use the service. The parameters may
just be simple data or they may be complete object
references. Attributes tell the client something about
the properties of a service. For example, a service
may have a latency attribute which tells the client how
slow to respond the service is likely to be. This al-
lows the client to make an intelligent selection from
the available services and the best to be chosen. All
the attributes and parameters that might be requested
by a service are prediﬁned in the component deﬁni-
tion ﬁle in order to maintain consistent semantics.
2.2.2
Service Broker
The Service Broker enables the access to a partic-
ular service. It’s functionality is similar to the one
the Broker Pattern described in (Douglass, 2002) pro-
vides. The Service Broker fulﬁls two roles: ﬁrstly,
that of a name server. It allows service interfaces to
be mapped to a predeﬁned name, which is known to
other components in the system at design-time. This
name can then be resolved to a concrete object refer-
ence, allowing components to ﬁnd each other at run-
time. Secondly, the Service Broker allows compo-
nent to be registered by the interfaces they implement.
For each interface, the Service Broker maintains a list
of references to components currently running on the
network which implement the interface. Other com-
ponents can query the Service Broker to ﬁnd this list.
Figure 3 shows the class diagram for the Service
Broker. Each time a new component starts it registers
with the Service Broker and submits a service descrip-
tion of itself by calling addService(). This description
complies with the XML notation of ﬁgure 2. When an
AE needs to ﬁnd a service provider with a particular
service interface, it asks the Service Broker by call-
ing connect(INavigator), which in that case returns a
reference to the component that provides INavigator.
Establishing a connection is a task of the connector
for which the latter calls ﬁndService(). Because the
Service Broker possesses a reference to the service
description, the callee receives a description of the re-
quired service interface too.
170
N. Oswald
Middleware-Based Framework
Structure of a Service
Figure 2: Describing a service to an AE.

3
DESIGN OF AN AUTONOMOUS
ENTITY
The coarse-grained design of the architecture is build
from a set of identical AE without specifying their
internal structure. However, the architectural design
of an AE is of major importance with regard to the
building of an unmanned system because that requires
to have autonomous capabilities. While (Maes, 1994)
demands from an autonomous system to be adaptive,
robust and effective, we use a similar interpretation
but with different terms. A component is called to be
an autonomous entity, when the following four major
characteristics are fulﬁlled. It must be able
• to perceive,
• to plan,
• to decide, and
• to act.
Perceiving and acting are parts of today’s avionics
systems. Some of these systems already include plan-
ning and deciding capabilities without human inter-
vention, but the deﬁnitive decision-making process
during a mission is still incumbent upon the pilot. To
automize this in order to build the capability of self-
dependent acting requires to have several executable
options. This means, that instead of using a single
algorithm, an AE should comprise of a set of algo-
rithms that solve the same task. To push that claim,
we distinguish between two kinds of components in
the software architecture. An AE on the one hand
provides autonomous capabilities and builds a visible
brick in the architecture. On the other hand, there are
so-called concrete service provider (CSP) that quote
implementations of basic functionality. These com-
ponents are encapsulated into single AEs and hidden
to public access.
3.1
Structure of an AE
Robustness and reliability requirements force un-
manned systems to allocate mechanisms that enable
support for deciding and planning tasks. To do so,
we divide an AE into a Head and a Body and distin-
guish between allocating basic functionality and func-
tionality that enable intelligent support. The Body
is responsible for providing the basic functionality of
the AE and thus covers the execution of the function-
ality only. The Head is responsible for building the
AE’s capability to act autonomously and covers plan-
ning, modelling and decision aspects. Both parts of
an AE can be regarded as building blocks, with the
Head being on top of the Body.
3.1.1
The Head
The Head provide means that enables an AE to act
independently. The ability to effectively control the
behaviour of an AE indeed depends on the allocated
functionality for the Head. In case there is no in-
telligent support available for the Head, an AE acts
like a conventional component without any decision,
planning or learning capabilities simply based on the
functionality of the Body. To provide responsibility,
the Head requires of intelligent support that allow for
plausible decisions in dynamic situations. Such a de-
cision support which can be considered as a build-
ing block inside the Head is needed in various cases,
among other things for
1. the selection of algorithms to use,
2. the evaluation of calculated results,
3. the synthesis of results, and
4. the handling of exceptional circumstances.
The ﬁrst task of the Head is a central one with respect
to administrate a set of CSPs. This exercise occurs
each time when there exists more than one implemen-
tation for a problem. Decisions on what algorithm to
select are required for the Body, the evaluation and
the synthesis. Certainly, one could also select the se-
lection, but for this essay, we assume having loaded
a selection algorithm at design-time. The second task
mentions methods which are required to inspect the
plausibility of calculated results. If provisionally re-
sults appear, the Head has to decide how to proceed
171
Figure 3: Service Broker.
Towards a Conceptual Framework-Based Architecture for Unmanned Systems

in order to guarantee a service. This might lead to a
change in the selection of the native algorithm, im-
provements of a learning component, an update of
model knowledge, or instructions to other AEs. The
third task regards a situation where several algorithms
work in parallel. To build a result for the client, data
have to be fused in an appropriated way. Therefore,
the Head comprises of a number of CSPs allocat-
ing fusion functionality. Task four is of major impor-
tance to the Head because of the AE’s claim to act
autonomously which requires robustness and reliabil-
ity. The Head has to try all feasibilities like using
several implementations in order to execute a given
task reliable. This task does not consider replication
aspects as these should be hidden to the components
and reside inside the connectors. The above list of
tasks for the Head shows minimum requirements and
may be extended on demand without affecting the ar-
chitecture due to their modular design.
3.1.2
The Body
The task of the Body is to provide the functionality,
that an AE has registered with the Service Broker.
Therefore, the Body implements the propagated ser-
vice interface according to ﬁgure 4. The service in-
terface ServiceInterface is visible to all other AEs.
Usually, the Body core itself contains no service im-
plementations. These are provided from the CSP in-
troduced in 3.2. That means, to solve requests that
belong to the same problem domain, a Body has a
number of CSPs at it’s disposal. This indirect access
to the real implementation offers a number of advan-
tages, it allows
• to administrate several identical sources,
• to group services of the same type, and
• to provide distributed processing.
Although the CSP wraps the native interface of
an algorithm to the service interface, the required in-
put parameter may differ. As described in the service
structure 2.2, some of the input parameters are ﬁxed
others are optional, that means they will be collected
at run-time. To meet all requirements, the Body re-
solves all variable parameters needed to run a CSP.
The Body communicates with the Head, when-
ever a decision, an evaluation or a synthesis is re-
quired. Also, the Body may appear in the role of a
client to other AEs, if the current task requires addi-
tional services. That means, the Body communicates
with other Heads until a reference to another service
provider, CSP or Body has been selected.
3.2
While an AE provides services without containing a
concrete implementation, a CSP provides an imple-
mentation of a single algorithm. CSPs are indepen-
dent components of the software architecture that be-
long typically to one particular AE. They can be ac-
cessed only indirectly by accessing an AE’s service
interface.
Services from CSP are provided according to ﬁg-
ure 6. A CSP provides an implementation of the in-
terface ManagedServiceInterface. The CSP registers
that service interface, which is tagged by implements,
with the Service Broker as well as a description on
how to use that particular algorithm. In the example
of ﬁgure 5 the component AStar provides the interface
IPlanner. As ManagedServiceInterface is not a gen-
eral public service interface, it is invisible to all AEs
except the one that depends on that concrete service
marked with the dependency tag.
172
N. Oswald
Provider of Concrete Services
Figure 4: Provision of a service by an AE
Figure 6: Provision of a service by an CSP
Figure 5: CSP providing a service.
.
.
<component name="AStar">
<interfaces>
<implements>AE navigator/IPlanner</implements>
</interfaces>
</component>

As already mentioned, there are a number of algo-
rithms in the aeronautics domain, that belong to the
same problem domain. Although they solve the same
task, algorithms differ in their native interface, their
behaviour, or may have different constraints. Import-
ing a native interface from legacy code will usually
not meet the service interface. Thus, the CSP wraps
the native interface of the legacy code to the service
interface.
3.3
Retrieving CSPs
An AE provides neither particular basic functional-
ity nor particular intelligent support and thus requires
of having a number of CSP. Each CSP implements
external functionality that belongs either to the Head
or to the Body. As CSPs are part of an AE the lat-
ter can be considered as an application independent
skeleton or frame that provides, among other things,
a mechanism for a purposive access to one or several
CSPs. To do so, we have built the Algorithm Se-
lection pattern shown in ﬁgure 7. The scope of this
pattern is to return a list of references to implemen-
tations of algorithms that shall be executed. It con-
stitutes a proposal for the ﬁrst task of the Head in-
troduced in 3.1.1. The Algorithm Selection pattern is
used both from the Body to ﬁnd a CSP that provides
the required basic functionality and from the Head
to retrieve CSPs that allocate intelligent support like
evaluation and synthesis.
The Algorithm Selection pattern is a collection of
other patterns, namely Factory, Strategy, Adapter, It-
erator and Proxy. It works in the following manner: a
client, either a Head or a Body, tries to resolve refer-
ences for a given task. First, it calls the Service Bro-
ker to return an appropriated list of currently available
CSPs on the net together with their constraints. From
that list, it then decides with the pre-selected decision
algorithm what CSP to use and returns one or several
references.
3.4
After having introduced the construction of an AE,
interactions to provide a service are focused now by
means of the sequence diagram shown in ﬁgure 8. An
AE in its role as a client tries to access a particular
service by calling connect(AE X). The connector of
the receiving AE then calls the initialize() method of
the Head of the AE, named as AE XHead in the di-
agram. At that stage, the Head builds a reference to
its Body and returns that reference to the client. The
client now calls the Body directly with one of the pro-
vided service interfaces. When doing that, the Body
either executes directly a pre-selected CSP or it asks
the Head ﬁrst to select CSPs according to the Algo-
rithm Selection pattern. The result of AlgorithmXCSP
is returned to the Body which calls the Head for eval-
uation. If several results were calculated it might be
required to use a fusion algorithm. The Body asks
the Head to take care of the fusion. In both cases, the
result of these calculations is returned to the Body.
The latter returns the result to the client. For evalu-
ate() and synthesize() the selection of algorithms fol-
lows according to the Algorithm Selection pattern. To
ﬁnish a connection or to choose other selection algo-
rithms the client calls disconnect().
The selection of CSPs according to the Algorithm
Selection pattern works as explained in Fig. 9. Af-
ter having received SelectAlgorithm the Head calls
select() to the selection algorithm. There, a ﬁndSer-
vice() call is made to the Service Broker. This re-
trieves a list of currently available algorithms respec-
tively CSPs on the net. From that list, the selection
algorithm chooses one or more appropriate CSPs
and return those to the Head. The Head then ini-
tialises the chosen CSPs and returns those references
to the Body.
4
EXPERIMENTAL RESULTS
To test the framework we have designed an engineer-
ing platform for autonomous systems (EPAS). This
platform builds the hardware and software infrastruc-
ture to develop, implement and test the behaviour of
constructed software architectures. It consists on the
one hand of a number of different hardware compo-
nents, operating systems and various ORB implemen-
tations. On the other hand, there exists a repository of
already constructed AEs and CSPs. Although AEs
in the repository have default settings, they can be
adapted to current mission purposes simply by reas-
signing the set of CSPs for each AE. The status quo
of EPAS is shown in the table of ﬁgure 10. In total,
four operating systems, seven ORB implementations
and three languages are supported currently together
with a number of pre-designed AE bricks as well as
two simulators.
To rapidly construct software architectures, we
have developed a graphical user interface, the so-
called System Designer as shown in ﬁgure 11. Ac-
cording to mission requirements, a user selects AE
from the repository shown as boxes in the System De-
signer, or he creates new components. For each AE
the user then assigns the CSPs that resolve the pro-
posed service interfaces. A minimal design is com-
plete when all dependencies are resolved. Currently,
the are no intelligent decision algorithms involved.
Their behaviour is simulated by a simple but ﬂex-
ible decision technique.
So far, no system aspects
were considered for the developed software architec-
ture. To do so, the System Designer allows to do a
173
Provision of Services
Towards a Conceptual Framework-Based Architecture for Unmanned Systems

174
N. Oswald
Figure 7: Algorithm Selection pattern.
Figure 8: Sequence diagram for service provision.

conﬁguration for each AE and each CSP. Conﬁg-
uration parameters include aspects like what ORB to
use and on what machine to run a service. These in-
formations are stored in an XML-based conﬁguration
ﬁle. From the chosen conﬁguration a start-up script is
build that sets up the whole system. At ﬁrst, the Ser-
vice Broker is started. Then, components are started
as independent peers without any interactions except
that they register their services with the Service Bro-
ker. So far, there exist no connection structures in the
real application. The resolving of dependencies for an
AE starts with the connect() call. Components check
dependencies on demand and may resolves them by
querying the Service Broker.
5
CONCLUSIONS
We introduced a reference software architecture based
on a component framework to design and implement
typical missions of unmanned aerial vehicles. The
framework separates functionality and middleware by
encapsulating CORBA into connectors and thus sup-
ports, at no expenses for the developer, using the het-
erogeneous avionics environment with various plat-
forms, multi-lingual software, and different operat-
ing systems. Furthermore, the framework provides a
unique architectural skeleton for a single autonomous
entity to meet the requirements for self-dependent act-
175
Figure 10: Infrastructure provided by EPAS.
Figure 9: Sequence diagram for algorithm selection.
ing. A software architecture for a particular mission
emerges from the composition of autonomous entities
Towards a Conceptual Framework-Based Architecture for Unmanned Systems

• cost saving over a variety of missions because of
reusable design technologies and fast turnaround
times,
• reuse of existing and tested software,
• rapid system analysis of the composed mission ar-
chitecture,
• dramatic reduction in mission completion time, and
• using of COTS and open source components.
Experiments in an appropriate engineering platform
for autonomous systems containing various ORB im-
plementations showed the rapid development process
to build and test a software architecture. By means
of a system designer, autonomous entities can be cus-
tomised, combined and distributed at design-time in a
ﬂexible manner.
REFERENCES
Binns, P. and Vestal, S. (1993).
Formal real-time archi-
tecture speciﬁcation and analysis. In In Tenth IEEE
Workshop on Real-Time Operating Systems and Soft-
ware, New York.
Brooks, R. (1986). A layered control system for a mobile
robot. 3rd Symposium. MIT Press, pages 367–372.
Cheyer, A. and Martin, D. (2001). The open agent architec-
ture. Journal of Autonomous Agents and Multi-Agent
Clements, P., Kazman, R., and Klein, M. (2002). Evaluat-
ing software architectures: Methods and case studies.
Technical report, SEI, Series in Software Engineering.
Coglianese, L. and Szymanski, R. (1993). Dssa-adage: An
environment for architecture-based avionics develop-
ment. In AGARD’93.
Dashofy, E., Hoek, A., and Taylor, R. (2002). An infrastruc-
ture for the rapid development of xml-based architec-
ture description languages. In The 24th International
Conference on Software Engineering, Orlando.
Dashofy, E., Medvidoc, N., and Taylor, R. (1999).
Us-
ing off-the-shelf middleware to implement connectors
in distributed software architectures. In International
Conference on Software Engineering, Los Angeles.
Dissaux, P. (2004). Using the aadl for mission critical soft-
ware development. In ERTS conference, Toulouse.
Douglass, B. (2002). Real-Time Design Pattern. Addison
Wesley.
Feiler, P., Lewis, B., and Vestal, S. (2003). The sae avion-
ics architecture description language (aadl) standard:
A basis for model-based architecture-driven embed-
ded systems engineering. In RTAS 2003, Washington.
vorhanden.
176
N. Oswald
Figure 11: System Designer.
covering different functionality and interacting ana-
logue to peers. Advantages of the presented approach
are
Systems, 4(1): 143–148. OAA.

Garlan, D., Monroe, R., and Wile, D. (2000). Acme: Ar-
chitectural description of component-based systems.
Technical report, CMU, Software Engineering Insti-
tute.
Garlan, D. and Shaw, M. (1993). An introduction to soft-
ware architecture. In Ambriola, V. and Tortora, G., ed-
itors, Advances in Software Engineering and Knowl-
edge Engineering.
Hansen, S. (2003). Integration of autonomous system com-
ponents using the jaus architecture.
In AUVSI Un-
manned Systems 2003, Baltimore.
JAUS (2004).
Joint architecture for unmanned systems.
http://www.jauswg.org.
Kortenkamp, D., Bonassao, R., and Murphy, R., editors
(1998).
Artiﬁcial Intelligence and Mobile Robots.
MIT Press.
Maes, P. (1994). Mmodelling adaptive autonomous agents.
Medvidoc, N. (1999).
Architecture-based Speciﬁ-cation-
Time Software Evolution. PhD thesis, University of
California.
Medvidoc, N., Oreizy, P., Robbins, J., and Taylor, R.
(1996). Using object-oriented typing to support archi-
tectural design in the c2 style. In SIGSOFT’96. ACM
Press.
Medvidovic, N. and Taylor, R. N. (2000).
A classiﬁca-
tion and comparison framework for software archi-
tecture description languages. Software Engineering,
Nilsson, N. (1980).
Principles of Artiﬁcial Intelligence.
Tioga Press.
Nitto, E. D. and Rosenblum, D. (1999). Exploiting ADLs
to specify architectural styles induced by middleware
infrastructures. In Int. Conf. on Software Engineering,
pages 13–22.
Ryan, C., Kuhns, F., Schmidt, D., Othman, O., and Par-
sons, J. (2000). The design and performance of a plug-
gable protocol framework for real-time distributed ob-
ject computing middleware. In ACM/IFIP, editor, Pro-
ceedings of the Middelware 2000 Conference.
Schrage, D. P. and Vachtsevanos, G. (1999). Software en-
abled control for intelligent UAVs. In 1999 IEEE In-
ternational Conference on Control Applications.
Wills, L., Kannan, S., Sanders, S., Guler, M., Heck, B.,
Prasad, J., Schrage, D., and Vachtsevanos, G. (2001).
An open platform for reconﬁgurable control. IEEE
Control Systems Magazine, 21(3).
177
Artiﬁcial Life, 1(1): 135–162.
26(1): 70–93.
Towards a Conceptual Framework-Based Architecture for Unmanned Systems

A INTERPOLATION-BASED APPROACH TO MOTION
GENERATION FOR HUMANOID ROBOTS
Koshiro Noritake, Shohei Kato and Hidenori Itoh
Dept. of Intelligence and Computer Science
Nagoya Institute of Technology
Gokiso-cho, Showa-ku, Nagoya 466-8555, Japan
Email: {noritake, shohey, itoh}@ics.nitech.ac.jp
Keywords:
Humanoid robot, motion generation, Tai Chi Chuan, balance checking.
Abstract:
This paper proposes a static posture based motion generation system for humanoid robots. The system gener-
ates a sequence of motion from given several postures, and the motion is smooth and stable in the balance. We
have produced all the motions of Tai Chi Chuan by the system. Motion generation for humanoids has been
studied mainly based on the dynamics. Dynamic based method has, however, some defects: e.g., numerous
parameters which can not be always prepared, expensive computational cost and no guarantee that the motions
are stable in balance. We have, thus, studied less dependent-on-dynamics approach. A motion is described as
a sequence of postures. Our system ﬁgure out if we need extra postures to insert for stability. This method
enables humanoid robot, HOAP-1 to do Tai Chi Chuan.
1
INTRODUCTION
In recent years, robotics has greatly developed, es-
pecially, research for humanoid robots has attracted
much attention (e.g,(Nishiwaki et al., 2002), (Sug-
ihara et al., 2002), (Huang et al., 2001), (Yam-
aguchi et al., 1993), (Li et al., 1993), (Kagami et al.,
2001), (Kuffner et al., 2001), (Kuffner et al., 2002),
(Kuwayama et al., 2003)). Existing methods of mo-
tion generation for humanoid robots are mostly based
on the dynamic control theory and the optimization
technique.
These methods are often specialized in
some particular motions, such as walk and standing,
which are simple, symmetric or cyclic. This presents
an obstacle to general-purpose. These methods may
require the mastery of dynamic for use. The method-
ologies based on the dynamics often require highly
expensive computational cost, and the motion control
for unconstraint motions is still hard problem. Me-
chanical characteristic of humanoid robot is an in-
crease in DOFs. There is, however, few studies for
motion control such that the DOFs are fully utilized.
In this research, we, thus, take an intelligent soft-
ware approach to motion control with useful interface
and application for various motions. In this paper,
we propose a motion generation system for humanoid
robots. Our system generates a sequence of motion
from given several postures, and the motion is smooth
and stable in the balance.
We have produced all the motions of Tai Chi Chuan
by the system. All motions have been performed by a
humanoid robot.
2
HUMANOID ROBOT AND THE
TARGET MOTIONS
2.1
Humanoid Robot
In this paper, we consider the motion control of a hu-
manoid robot, HOAP-1 (Humanoid for Open Archi-
tecture Platform) produced by Fujitsu(Murase et al.,
2001), shown in Figure 1. The total weight is 6 (kg)
and the height is 48 (cm).
HOAP-1 has 20 DOFs
in total, 6 in each leg and 4 in each arm. The link
structure is shown in Figure 2. The sensor architec-
ture of HOAP-1 is consisted of 4 pressure sensors on
each sole and angular rate and acceleration sensors
mounted in breast. HOAP-1 is controlled with RT-
Linux OS on itself or computer connected with USB.
2.2
Tai Chi Chuan
We consider Tai Chi Chuan as the target motion for
humanoid robots. Tai chi has several styles. In this
paper, we adopted Tai Chi 48. Tai Chi motions have
various movement of entire body. Tai Chi motions are
179
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 179–185. 

Figure 3: Data ﬂow in our motion generation system.
Figure 1: HOAP-1.
Figure 2:
The link
structure of HOAP-1.
performed slowly, softly and with smooth and even
transitions between them. Tai Chi motions require
sophisticated balance control for robots. In addition
to stability or energy consumption, Tai Chi Chuan re-
quires concinnous forms. Unlike to walking, Tai Chi
motions should not be changed markedly in appear-
ance even for the stability.
3
MOTION GENERATION
SYSTEM
3.1
Interpolation-based Motion
Generation
The section describes a motion generation system
for humanoid robots.
Figure 3 shows the out-
line of the system.
Input to the system is a se-
quence of postures P
= P0, P1, · · · , Pn, (called
key-postures).
Each key-posture has characteristic
form of a motion to generate.
In this system, we
suppose that each key-posture is statically stable in
balance. This supposition is supported by the key-
posture adjustment, such that the center of mass
(COM) of the upper body is positioned just above
the ankle of the supporting leg.
Output from the
system is a motion sequence M = M0, M0, · · · ,
Mm.
The basic function of motion generation is the
smooth interpolation between two postures, Pi and
Pi+1.
The interpolated motions, needless to say,
should be stable in balance for humanoid robots. Bal-
ance Checker evaluates the distance between Pi and
Pi+1 in balance space, and then, inserts a few inter-
mediate postures (corresponding to Ai
j in Figure 3) if
the distance is over a threshold. It is, in general, dif-
ﬁcult to calculate the distance of postures in balance
space. We have, thus, made a rough approximation
described in the following section.
3.2
Classiﬁcation of the Postures in
Balance Space
Tai Chi Chuan, our target motion, has wide variation
in posture. Interpolation-based motion generation is,
however, vulnerable to wide or quick variation in pos-
tures. It is, thus, important to consider some relation
between two postures to be interpolated. The admissi-
bility of the interpolated motion may be estimated by
the relation. In this research, we consider the distance
in balance space as the admissibility.
To calculate the distance of postures in balance
space is hard problem. In this research, we give this
problem an audacious consideration that postures of
180
K. Noritake, S. Kato and H. Itoh 

1
2
3
4
5
6
7
8
13
9
10
11
12
Right Leg Standing 
Both Leg Standing
Height of Tue 
of Idling Leg
(1~4, 10~13)
High
Low
Height of COM
((5, 6, 9), 7, 8)
High
Low
Right Foot
Position of COM
(5, 6, 9)
Left Foot
Left Leg Standing 
Figure 4: The directed graph of 13 posture classes.
Tai Chi motion are classiﬁed into 13 groups (posture
class, or simply class) and these groups are connected
by 26 arcs in the balance space. The balance space
is represented by a directed graph shown in Figure 4.
The classiﬁcation is based on the relative position of
COM and the relation of the supporting and idling
legs. Firstly, postures are classiﬁed into three classes:
both leg standing, right leg standing and left leg stand-
ing. Single leg standing is classiﬁed into four classes
according to the height of the idling leg in relation to
the supporting leg (see Figure 4):
• lower than the ankle (#4 and #10),
• higher or equal than the ankle and lower than the
knee (#3 and #11),
• higher or equal than the knee and lower than the hip
(#2 and #12),
• higher or equal than the hip (#1 and #13).
Both leg standing is classiﬁed into ﬁve classes accord-
ing to the position of the COM in relation to the COM
of the erect posture (see Figure 4):
• the vertical component is less than 80% (#8),
• the vertical component is more or equal than 80%
and less than 90% (#7),
• the vertical component is more or equal than 90%
and,
the horizontal component leans to right more
than 20% (#5),
the horizontal component leans to left more than
20% (#9),
the horizontal component is within 20% from the
center of the both feet (#6).
The classiﬁcation enables our system to approxi-
mate the distance of two postures. Let a and b be
arbitrary postures to be interpolated, and let ga to gb
be the classes which a and b belong to, respectively.
The distance between a and b is given by the distance
between ga and gb: the length of the path from ga to
gb. We, therefore, can estimate the admissibility of
the interpolated motion from a to b by the distance
between ga and gb.
The balance checker in our system utilizes the di-
rected graph in Figure 4 for the decision to insert an
intermediate posture or not. The directed graph give
a constraint for the stability in balance on the motion
generator. The constraint is that two postures to be in-
terpolated should belong to one class or adjoining two
classes. For example, interpolation from a posture in
class #6 to a posture in class #4 has the risk of tum-
ble. A posture in class #5 should be inserted between
them.
181
A Interpolation-Based Approach to Motion Generation for Humanoid Robots
•
•
•

11
12
13
14
15
16
17
18
19
20
1
2
3
4
5
 6 
 9 
10
 6 
 5 
 9 
 6 
 7 
 6 
 6 
 6 
 5 
 4 
 6 
 6 
Figure 5: The snapshot of Tai Chi #7 motion by HOAP-1.
1
2
3
4
5
6
7
8
9
10
 9 
 4 
 5 
 6 
 6 
 9 
10
 6 
 7 
 8 
Figure 6: The snapshot of Tai Chi #17 motion by HOAP-1.
182
K. Noritake, S. Kato and H. Itoh 

2
1
3
4
5
6
7
8
9
10
13
11
 2 
 3 
 4 
 5 
 6 
 9 
10
 6 
 9 
10
13
11
12
12
Figure 7: The snapshot of Tai Chi #44 motion by HOAP-1.
4
EXPERIMENT
We have produced all the motions of Tai Chi Chuan
without tipping over.
Firstly for data input to our
motion generation system, we have prepared key-
postures for 48 Tai Chi motions, from a tutorial book
(Defang, 1999). The system has, secondly, generated
the control sequences of servomotors for all the mo-
tions. In this particular examples, all motions are well
performed by HOAP-1. Table 1 and 2 show the listing
of Tai Chi motions and the numerical relation between
input and output postures by our system.
4.1
Performance Results
Figure 5, 6 and 7 show the snapshots of Tai Chi #07,
#17 and #44 motion by HOAP-1, respectively. Tai
Chi #7 composed of the basic walking motion, called
shang bu. This is easy one in Tai Chi, however, it oc-
curs tipping over without our system. Tai Chi #17
composed of the motion keeping robot’s head low,
called pu hu.
This motion HOAP is imbalance in
backward and forward movement. Tai Chi #44, which
contains high kick called bai lian, requires high skill
balance control of robot. This is one of the most difﬁ-
cult motions. HOAP-1 can support its weight with
one leg skillfully, although the imbalance becomes
very high. In these ﬁgures, the number in the lower
right of the each snapshot means the class which the
posture belongs to. The transition of classes satisﬁes
all constraints by the directed graph shown in Fig-
ure 4.
CW
COMz=0
LeftBottom(Pl,Wl)
RightBottom(Pr,Wr)
Figure 8: Components for balance quantiﬁcation.
4.2
Effectiveness of Balance Checker
To verify the effectiveness of our system, we have
evaluate the balancing performance for the motions.
In this paper, we suppose the quantity of balance as
follows. Let COM be the center of mass of whole ro-
bot, let COMz be the vertical component of COM,
and let COMz=0 be the projection of COM on the
ﬂoor. Further, let Pl and Pr be the position of the
left and right sole, and let Wl and Wr be the weight
on the left and right sole, respectively (see Figure 8).
The balance is quantiﬁed as the following equation:
imbalance = |COMz=0 −CW| · COMz,
(1)
where
CW = Pr · Wr + Pl · Wl
Wr + Wl
.
(2)
Figure
9,
10
and
11
show
the
trajectories
imbalance of two Tai Chi by HOAP-1: our method
and without Balance-Checker for Tai Chi #7, #17 and
183
A Interpolation-Based Approach to Motion Generation for Humanoid Robots

postures
postures
#
name
after
by
balance
tutorial
checker
book
(0)
qi shi
4
4
1
bai he liang chi
5
4
2
zuo lou xi ao bu
4
4
3
zuo dan bian
20
10
4
zuo pi pa shi
4
3
5
lu ji shi
26
15
6
zuo ban lan chui
13
7
7
zuo peng lu ji an
19
11
8
xie shen kao
8
4
9
zhou di chui
11
7
10
dao juan gong
29
12
11
zhuan shen tui zhang
18
13
12
you pi pa shi
4
3
13
lou xi zai chui
9
6
14
bai she tu xin
9
6
15
pai jiao fu hu
31
18
16
zuo pie shen chui
11
5
17
chuan quan xia shi
9
4
18
du li cheng zhang
14
6
19
you dan bian
20
10
20
you yun shou
25
12
21
you zuo fen zong
13
7
22
gao tan ma
5
3
23
you deng jiao
10
6
24
shuang feng guan er
5
3
#44 motions, respectively. The result indicates that
our system can generate a stable Tai Chi motion for
HOAP-1, while the robot loses the balance without
our balance checker. In the ﬁgures, the numbers over
the graph correspond to the frame labeled the same
number in snapshots shown in Figure 5, 6 and 7. All
motions without balance check tipped over, and after
that, the imbalance is not accurate because sensors are
not calibrated.
5
CONCLUSION
In this paper, we proposed a motion generation sys-
tem for humanoid robot. The motion generated by our
system is smooth and stable in the balance. Humanoid
robot, HOAP-1 with our system has performed whole
48 Tai Chi motions in good balance. Our system per-
forms various and unrestricted motions for humanoid
robots without hard problem in dynamics. Our sys-
tem still has some constraints, that is, platform de-
pendent, interpolation interval, and at least one sole
on the ﬂoor.
postures
postures
#
name
after
by
balance
tutorial
checker
book
25
zuo deng jiao
8
4
26
yan shou liao quan
7
3
27
hai di zhen
6
3
28
shan tong bei
5
2
29
you zuo fen jiao
21
9
30
lou xi ao bu
15
7
31
shang bu qin da
10
4
32
ru feng shi bi
7
4
33
zuo yun shou
25
11
34
you pie hen chui
11
5
35
zuo you chuan suo
33
16
36
tui bu chuan zhang
5
2
37
xu bu ya zhang
6
2
38
du li tuo zhang
2
1
39
ma bu kao
9
3
40
zhuan shen da lu
9
5
41
liao zhang xia shi
11
7
42
shang bu qi xing
4
2
43
du li kua hu
7
4
44
zhuan shen bai lian
12
4
45
wan gong she hu
6
4
46
you ban lan chui
16
7
47
you peng lu ji an
19
11
48
shi zi shou
5
3
(49)
shou shi
3
3
The future work will focus on three phases. Firstly,
we will deal with the automatic choreographing the
postures to insert. Secondly, we will dedicate to the
more generalized control of the motion generation.
Especially, it is important to let system free from in-
terpolating interval. Our system often makes motions
sprawly in time-axis. This is caused by our policy
that stability is more important than speed.
There
are, however, scenes that speed is important, too. We
will respond to this tradeoff. Thirdly, we will dedi-
cate to some interpolation methods specialized to Tai
Chi Chuan. The value of the Tai Chi motion is not
only stability and speed, but also aesthetic sense and
smoothness of the motions. In this phase, we will
ﬁrstly focus on ﬁnding ordinality in the rhythm of Tai
Chi Chuan.
This work was supported in part by Artiﬁcial Intelli-
gence Research Promotion Foundation and Ministry
of Education, Science, Sports and Culture, Grant–in–
Aid for Scientiﬁc Research under grant #14780307.
184
K. Noritake, S. Kato and H. Itoh 
Table 1: Key Postures of Tai Chi Generated by Our System.
Table 2: Key Postures of Tai Chi (continued).
ACKNOWLEDGEMENTS

 3000
 6000
 9000  12000  15000  18000
 21000  24000  27000  30000
 0
 0.01
 0.02
 0.03
 0.04
 0.05
 0.06
Tai Chi #7
Tai Chi #7 without balance check
1 2 3 4 5 6
7 8
9
10 11 12 13
14 15 16 17 18
19
20
time(ms)
imbalance(m^2)
original posture from the Tai Chi tutorial 
intermediate posture by balance checker
Figure 9: The imbalance of Tai Chi #7.
 0.01
 0.02
 0.03
 0.04
 0.05
 0.06
 3000
 4500
 6000
 7500
 9000  10500  12000  13500  15000  16500
Tai Chi #17
Tai Chi #17 without balance check
1
2
3
4
5
6
7
8
9
10
time(ms)
imbalance(m^2)
original posture from the Tai Chi tutorial 
intermediate posture by balance checker
Figure 10: The imbalance of Tai Chi #17.
REFERENCES
Defang, L. (1999). Introduction to Tai Chi consist of 48
motions. BAB Japan.
Huang, Q., Yokoi, K., Kajita, S., Kaneko, K., Arai, H., Koy-
achi, N., and Tanie, K. (2001). Planning walking pat-
terns for a biped robot. IEEE Transactions on robotics
and automation, 17(3).
Kagami, S., Kanehiro, F., Tamiya, Y., Inaba, M., and Inoue,
H. (2001). Autobalancer: An online dynamic balance
compensation scheme for humanoid robots. In Robot-
ics: The Algorithmic Perspective, Workshop on Algo-
rithmic Foundations on Robotics, pages 329–340.
Kuffner, J. J., Nishiwaki, K., Kagami, S., Inaba, M., and
Inoue, H. (2001). Motion planning for humanoid ro-
bots under obstacle and dynamic balance constraints.
In Proc. of the IEEE Int’l Conf. on Robotics and Au-
tomation (ICRA’2001), pages 692–698.
Kuffner, J. J., Nishiwaki, K., Kagami, S., Kuniyoshi, Y.,
Inaba, M., and Inoue, H. (2002). Self-collision de-
tection and prevention for humanoid robots. In Proc.
 0.01
 0.02
 0.03
 0.04
 0.05
 0.06
 3000  4500  6000  7500  9000  10500  12000  13500  15000  16500  18000  19500  21000
Tai Chi #44
Tai Chi #44 without balance check
1
2
3
4
5
6
7
8
9
10
11
12
13
time(ms)
imbalance(m^2)
original posture from the Tai Chi tutorial 
intermediate posture by balance checker
Figure 11: The imbalance of Tai Chi #44.
of the IEEE Int’l Conf. on Robotics and Automation
(ICRA’2002), pages 2265–2270.
Kuwayama, K., Kato, S., Seki, H., Yamakita, T., and Itoh,
H. (2003). Motion control for humanoid robots based
on the concept learning. In Proc. of International Sym-
posium on Micromechatoronics and Human Science,
pages 259–263.
Li, Q., Takanishi, A., and Kato, I. (1993). Learning control
for a biped walking robot with a trunk. In Proc. of
the IEEE/RSJ International Conference on Intelligent
Robot and Systems, page 1771.
Murase, Y., Yasukawa, Y., Sakai, K., and et al. (2001).
Design of a compact humanoid robot as a plat-
form.
In Proc. of the 19-th conf. of Robotics
Society of Japan, pages 789–790.
(in Japanese),
http://pr.fujitsu.com/en/news/2001/09/10.html.
Nishiwaki, K., Kagami, S., Kuniyoshi, Y., Inaba, M., and
Inoue, H. (2002).
Online generation of humanoid
walking motion based on a fast generation method of
motion pattern that follows desired zmp. In Proc. of
the 2002 IEEE/RSJ International Conference on Intel-
ligent Robots and Systems, pages 2684–2689.
Sugihara, T., Nakamura, Y., and Inoue, H. (2002). Realtime
humanoid motion generation through zmp manipula-
tion based on inverted pendulum control. In Proc. of
IEEE International Conference on Robotics and Au-
tomation (ICRA2002), volume 2, pages 1404–1409,
Washington D.C., U.S.A.
Yamaguchi, J., Takanishi, A., and Kato, I. (1993).
De-
velopment of biped walking robot compensating for
three-axis moment by trunk motion. In Proc. of the
IEEE/RSJ International Conference on Intelligent Ro-
bot and Systems, page 561.
185
A Interpolation-Based Approach to Motion Generation for Humanoid Robots

REALISTIC DYNAMIC SIMULATION OF AN INDUSTRIAL ROBOT
WITH JOINT FRICTION
Ronald G.K.M. Aarts, Ben J.B. Jonker
University of Twente, Faculty of Engineering Technology
Enschede, The Netherlands
Email: R.G.K.M.Aarts@utwente.nl, J.B.Jonker@utwente.nl
Rob R. Waiboer
Netherlands Institute for Metals Research
Delft, The Netherlands
Email: R.R.Waiboer@utwente.nl
Keywords:
Realistic closed-loop trajectory simulation, Industrial robot, Perturbation method, Friction modelling.
Abstract:
This paper presents a realistic dynamic simulation of the closed-loop tip motion of a rigid-link manipulator
with joint friction. The results from two simulation techniques are compared with experimental results. A
six-axis industrial St¨aubli robot is modelled. The LuGre friction model is used to account both for the sliding
and pre-sliding regime. The manipulation task implies transferring a laser spot along a straight line with a
trapezoidal velocity proﬁle.
Firstly, a non-linear ﬁnite element method is used to formulate the dynamic equations of the manipulator
mechanism. In a closed-loop simulation the driving torques are generated by the control system. The computed
trajectory tracking errors agree well with the experimental results. Unfortunately, the simulation is very time-
consuming due to the small time step of the discrete-time controller.
Secondly, a perturbation method has been applied. In this method the perturbed motion of the manipulator is
modelled as a ﬁrst-order perturbation of the nominal manipulator motion. Friction torques at the actuator joints
are introduced at the stage of perturbed dynamics. A substantial reduction of the computer time is achieved
without loss of accuracy.
1
INTRODUCTION
Robotic manipulators for laser welding must pro-
vide accurate path tracking performance of 0.1 mm
and less at relatively high tracking speed exceed-
ing 100 mm/s. High speed manipulator motions are
accompanied by high-frequency vibrations of small
magnitudes whereas velocity reversals in the joints
lead to complicated joint friction effects. These dy-
namic phenomena may signiﬁcantly effect the weld
quality, since laser welding is sensitive to small varia-
tions in the processing conditions like welding speed
as well as to disturbances of the position of the laser
spot with respect to the seam to be welded. To study
the applicability of industrial robotic manipulators as
in Fig. 1 for laser welding tasks, a framework for real-
istic dynamic simulations of the robot motion is being
developed. Such a simulation should predict the path
tracking accuracies, thereby taking into account the
dynamic limitations of the robotic manipulator such
as joint ﬂexibility, friction and limits of the drive sys-
tem like the maximum actuator torques. Obviously
the accuracy of the simulation has to be sufﬁciently
high with respect to the allowable path deviations.
Unfortunately, closed-loop dynamic simulations
with a sufﬁcient degree of accuracy are computation-
ally expensive and time consuming especially when
static friction, high-frequency elastic modes and a
digital controller operating with small discrete time
steps are involved. In an earlier paper we discussed
a so-called perturbation method (Jonker and Aarts,
2001) which proved to be accurate and computation-
ally efﬁcient for simulations of robotic manipulators
with ﬂexible links. In this paper a similar perturbation
scheme is presented for the closed-loop dynamic sim-
ulation of a rigid-link manipulator with joint friction.
The extension to an industrial robot with elastic joints
is still a topic of ongoing research.
We consider the motion of a six axes industrial
robot (St¨aubli RX90B), Fig. 1.
The unknown ro-
bot manipulator parameters, such as inertias of the
manipulator arms, the stiffness and the pretension
of a gravity compensation spring are determined by
means of parameter identiﬁcation techniques.
The
friction characteristics are identiﬁed separately. The
controller model is based on manufacturer’s data and
has been veriﬁed experimentally using system identi-
ﬁcation techniques. Details of the identiﬁcation tech-
187
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 187–194. 

Axis 1
Axis 2
Axis 3
Axis 4
Axis 5
Axis 6
¨
Hinge 1 (q1)
Hinge 2 (q2)
Hinge 3 (q3)
Hinge 4 (q4)
Hinge 5 (q5)
Hinge 6 (q6)
End-effector
Base
Beam 1
Beam 2
Beam 3
Beam 4
Beam 5
Beam 6
Truss 1 (ks, σ(c,0))
Figure 2: The 6 DOF Finite Element Model.
niques are outside the scope of this paper and will be
outlined elsewhere (Waiboer, 2004).
The present paper will focus on two simulation
techniques and a comparison of numerical and exper-
imental results. At ﬁrst, a non-linear ﬁnite element
method (Jonker, 1990) is used to formulate the dy-
namic equations of the manipulator mechanism, sec-
tion 2. The ﬁnite element formulation and the pro-
posed solution method are implemented in the pro-
gram SPACAR (Jonker and Meijaard, 1990). An inter-
face to MATLAB is available and the closed-loop sim-
ulations are carried out using SIMULINK’s graphical
user interface. A driving system is added to the ma-
nipulator model, section 3, and the inﬂuence of joint
friction is taken into account, section 4. The LuGre
friction model (Wit et al., 1995) has been used as it
accounts for both the sliding and pre-sliding regimes.
Finally the closed-loop model is assembled by includ-
ing the control system, section 5.
The second approach is the so-called perturbation
method, section 6. The differences between the actual
manipulator motion and the nominal (desired) motion
are modelled as ﬁrst order perturbations of that nomi-
nal motion. The computation of the perturbed motion
is carried out in two steps. In the ﬁrst step, the ﬁnite
element method permits the generation of locally lin-
earised models (Jonker and Aarts, 2001). In the sec-
ond step, the linearised model can simulate the per-
turbed motion of the manipulator accurately as long
as it remains sufﬁciently close to the nominal path.
The perturbation method is computationally more ef-
ﬁcient as the non-linear model only has to solved dur-
ing the ﬁrst step in a limited number of points along
the nominal trajectory. This is the solution of an in-
verse dynamic analysis along a known path, so with
only algebraic equations. The friction torques at the
actuator joints and the control system are introduced
at the stage of perturbed dynamics in the second step.
In section 7, the simulation results will be compared
with the experimental results. Also results acquired
with the perturbation method will be compared with
those obtained from a full non-linear dynamic simu-
lation.
2
FINITE ELEMENT
REPRESENTATION OF THE
MANIPULATOR
In the non-linear ﬁnite element method, a manipu-
lator mechanism is modelled as an assembly of ﬁ-
nite elements interconnected by joint elements such
as hinge elements and (slider) truss elements. This
is illustrated in Fig. 2, where the St¨aubli robot with
six degrees of freedom is modelled by three different
types of elements. The gravity compensation spring
is modelled as a slider-truss element. The manipu-
lator arms are modelled by beam elements. Finally,
the joints are represented by six cylindrical hinge ele-
ments, which are actuated by torque servos. The ma-
nipulator mechanism is assembled by allowing the el-
ements to have nodal points in common. The con-
ﬁguration of the manipulator is then described by the
vector of nodal coordinates x, some of which may
be the Cartesian coordinates, while others describe
the orientation of orthogonal triads rigidly attached
at the element nodes. The motion of the manipulator
mechanism is described by relative degrees of free-
dom which are the actuator joint angles denoted by
the vector q. By means of the geometric transfer func-
tions F(x) and F(e,c), the nodal coordinates x and the
elongation of the gravity compensating spring e(c) are
expressed as functions of the joint angles q
x = F(x) (q)
(1)
and
e(c) = F(e,c) (q) .
(2)
188
R.G.K.M. Aarts, B.J.B. Jonker and R.R. Waiboer
Figure 1: The six axes Staubli RX90B Industrial robot.

Differentiating the transfer functions with respect to
time gives
˙x = DF(x) ˙q
(3)
and
˙e(c) = DF(e,c) ˙q,
(4)
where the differentiation operator D represents partial
differentiation with respect to the degrees of freedom.
The acceleration vector ¨x is obtained by differentiat-
ing (3) again with respect to time,
¨x = DF(x) ¨q + (D2F(x) ˙q) ˙q.
(5)
The geometric transfer functions F(x) and F(e,c) are
determined numerically in an iterative way (Jonker,
1990).
The inertia properties of the concentrated and dis-
tributed mass of the elements are described with the
aid of lumped mass matrices. Let M(x) be the global
mass matrix, obtained by assembling the mass matri-
ces of the individual elements and let f(x, ˙x, t) be
the global force vector including gravity forces and
the velocity dependent inertia forces. Then the equa-
tions of motion described in the dynamic degrees of
freedom are given by
¯M¨q + DF(x)T 
M(D2F(x) ˙q) ˙q −f

+ DF(e,c)T σ(c) = τ,
(6)
where ¯M = DF(x)T MDF(x) is the reduced mass
matrix and σ(c) is the total stress in the gravity com-
pensating spring. The vector τ represents the joint
driving torques. The constitutive relation for the grav-
ity compensating spring is described by
σ(c) = σ(c,0) + ks e(c),
(7)
where σc,0 and ks denote the pre-stress and the stiff-
ness coefﬁcients of the spring, respectively.
This ﬁnite element method has been implemented
in the SPACAR software program (Jonker and Mei-
jaard, 1990).
3
THE DRIVING SYSTEM
The robot is driven by servo motors connected via
gear boxes to the robot joints. The inputs for the drive
system are the servo currents ij and the outputs are the
joint torques τj, where the subscript j = 1..6 denotes
either the motor or the joint number. A schematic
model of the drives of joints 1 to 4 is shown in Fig. 3.
The relations between the vector of motor angles ϕ,
the vector of joint angles q and their time derivatives
are given by
ϕ = Tq,
(8)
˙ϕ = T ˙q,
(9)
¨ϕ = T¨q,
(10)
qj
c(m)
j
ϕj
J(m)
j
nj
ij
τj
τ (f)
j
Figure 3: Schematic representation of the drives for joints 1
to 4.
where T is the transmission model for the joints. For
joints j = 1..5 only the respective gear ratio nj of the
joint plays a role. The drives for the wrist of the robot,
drives 5 and 6, are coupled. This causes an extra term
leading to
T =


n1
0
0
0
0
0
0
n2
0
0
0
0
0
0
n3
0
0
0
0
0
0
n4
0
0
0
0
0
0
n5
0
0
0
0
0
n6
n6


.
(11)
The friction torque in each joint is denoted τ (f)
j
with
j = 1..6. Due to the coupling in the wrist, an addi-
tional friction torque τ (f)
7
is identiﬁed on the axis of
motor 6. The vector of joint friction torques is then
deﬁned as
τ (f) =

τ (f)
1
, τ (f)
2
, τ (f)
3
, τ (f)
4
, · · ·
τ (f)
5 +τ (f)
7
, τ (f)
6 +τ (f)
7
T
.
(12)
The joint friction modelling is continued in section 4.
The drives are equipped with permanent magnet,
three-phase synchronous motors, yielding a linear re-
lation between motor currents and torque. The vector
of joint driving torques τ is then given by
τ = TT C(m)i −TT J(m) ¨ϕ −τ (f) ,
(13)
where the matrices C(m) and J(m) are diagonal ma-
trices with the motor constants c(m)
j
and rotor inertias
J(m)
j
, respectively. Substitution of (10) and (13) into
(6) and some rearranging yields
¯M(n) ¨q + DF(x)T 
M(D2F(x) ˙q) ˙q −f

+ DF(e,c)T σ(c) = τ (n),
(14)
where the mass matrix ¯M(n) is deﬁned by
¯M(n) = ¯M + TT J(m)T ,
(15)
as the rotor inertias TT J(m)T obviously have to be
added to the reduced mass matrix ¯M in the equations
of motion (6). Furthermore, the vector of net joint
torques is deﬁned as
τ (n) = TT C(m)i −τ (f).
(16)
The inertia properties and spring coefﬁcients have
been found by means of parameter identiﬁcation tech-
niques (Waiboer, 2004).
189
Realistic Dynamic Simulation of an Industrial Robot with Joint Friction

4
JOINT FRICTION MODEL
For feed-forward dynamic compensation purposes
and robot inertia identiﬁcation techniques it is com-
mon to model friction in robot joints as a torque τ (f)
which consists of a Coulomb friction torque and an
additional viscous friction torque for non-zero veloc-
ities (Swevers et al., 1996; Calaﬁore et al., 2001).
These so-called static or kinematic friction models
are valid only at sufﬁciently high velocities because
they ignore the presliding regime. At zero velocity
they show a discontinuity in the friction torque which
gives rise to numerical integration problems in a for-
ward dynamic simulation. To avoid this problem we
apply the LuGre friction model (Wit et al., 1995), that
accounts for both the friction in the sliding and in the
presliding regime.
In the LuGre friction model there is an internal state
z that describes the average presliding displacement,
as introduced by Heassig et al. (Haessig and Fried-
land, 1991). The state equations with a differential
equation for the state z and an output equation for the
friction moment τ (f) are
˙z = ˙q −| ˙q |
g( ˙q)z,
(17)
τ (f) = c(0) z + c(1) ˙z + c(2) ˙q .
(18)
Note that a subscript j = 1 . . . 7 should be added to all
variables to distinguish between the separate friction
torques in the robot model, but it is omitted here for
better readability. For each joint friction model with
j = 1..6 the input velocity equals the joint velocity ˙qj.
For the extra friction model τ (f)
7
the input velocity is
deﬁned as the sum of the joint velocities of joints 5
and 6.
In general, the friction torque in the pre-sliding
regime is described by a non-linear spring-damper
system that is modelled with an equivalent stiffness
c(0) for the position–torque relationship at velocity re-
versal and a micro-viscous damping coefﬁcient c(1).
At zero velocity, the deformation of the non-linear
spring torque is related to the joint (micro) rotation
q.
The viscous friction torque in the sliding regime is
modelled by c(2) ˙q, where c(2) is the viscous friction
coefﬁcient. In addition, at a non-zero constant veloc-
ity ˙q, the internal state z, so the average deformation,
will approach a steady state value equal to c(0) g( ˙q).
The function g( ˙q) can be any function that represents
the constant velocity behaviour in the sliding regime.
In this paper the Stribeck model will be used, which
models the development of a lubricating ﬁlm between
the contact surfaces as the relative velocity increases
from zero. The Stribeck model is given by
c(0) g( ˙q) = τ (c) + (τ (s) −τ (c))e−(| ˙q|/ωs)δ,
(19)
where τ (c) is known as Coulomb friction torque, τ (s)
is the static friction torque and ωs and δ are shaping
parameters. The values for the static friction torque
τ (s) and Coulomb friction torque τ (c) may be differ-
ent for positive and negative velocities and are there-
fore distinguished by the subscripts + and −, respec-
tively.
For each friction torque in the robot model, the
parameters describing the sliding regime of the Lu-
Gre friction model are estimated separately using
dedicated joint torque measurements combined with
non-linear parameter optimisation techniques (Wai-
boer, 2004).
The parameters describing the pre-
sliding regime are approximated by comparing the
pre-sliding behaviour in simulation with measure-
ments.
5
CLOSED-LOOP ROBOT
MODEL
The SPACAR model of the manipulator mechanism,
the controller, the friction models and the robot drives
are assembled into a complete model of the closed-
loop robot system, Fig. 4.
The CS7B controller used in the St¨aubli RX90B
is an industrial PID controller based on the Adept
V+ operating- and motion control system. The con-
troller includes six SISO controllers, one for each
servo-motor. A trajectory generator computes the set-
points ¨q(r), ˙q(r) and q(r) at a rate of 1 kHz. The
actual joint position q is compared with the set-point
q(r) and the error ϵ is fed into the PI-block of the
controller, which includes the proportional part and
the integrator part. The acceleration set-points ¨q(r)
and velocity set-points ˙q(r) are used for accelera-
tion feed-forward and friction compensation, both in-
cluded in the FF-block. The friction compensation
includes both Coulomb and viscous friction. The ve-
locity feedback ˙q is fed into the D-block, represent-
ing the differential part of the control scheme. The
block C represents the current loop, including the
power ampliﬁer.
Note that the position loop runs
at f (1)
s
= 1 kHz and the velocity loop and current
loop run at f (2)
s
= 4 kHz.
The transfer functions
of the different blocks have been identiﬁed and im-
plemented in a SIMULINK block scheme of the robot
controller (Waiboer, 2004).
The current vector i is fed into the drive model
where the joint torques are computed.
The LuGre
friction models compute the friction torques from
the joint velocities ˙q. The net joint torque τ (n) in
(14) is the input for the non-linear manipulator model
(SPACAR). The output of the manipulator model con-
tains the joint positions, and velocities, denoted by q
190
R.G.K.M. Aarts, B.J.B. Jonker and R.R. Waiboer
and ˙q, respectively.

+ +
+
+
+
−
−
−
q(r)
˙q(r) ¨q(r)
q ˙q
˙q
q
ϵ
τ(n)
τ(f)
f(1)
s
=1kHz
f(2)
s
=4kHz
i
F F
P I
D
C
Drives
Friction
SPACAR
Figure 4: Assembly of the closed-loop robot model for a simulation with the non-linear ﬁnite element method (SPACAR
block).
+ +
+
+
+
+
+
+
−
−
−
−
q(r)
˙q(r) ¨q(r)
q ˙q
˙q
q
ϵ
F F
P I
D
C
i
Drives
Friction
τ(n)
τ(f)
fs =1kHz
fs =4kHz
y0
read y0
δy
δτ(n)
τ0(n)
read τ0
LT V
Figure 5: Perturbation scheme with the linearised equations of motion (LTV block).
6
PERTURBATION METHOD
In the presented closed-loop model, both the SPACAR
model and the friction model are continuous in time,
while the controller sections are discrete and running
at 1 kHz and 4 kHz, respectively. In SIMULINK this
implies that the SPACAR model is simulated at a time
step equal to 0.25 ms or even smaller if this is re-
quired by SIMULINK’s integrator. Due to the fact that
the position, computed within the SPACAR simulation
model, is obtained in an iterative way, the computa-
tion effort is quite elaborate. This results in long sim-
ulation times. In order to overcome this drawback,
the perturbation method (Jonker and Aarts, 2001) is
applied.
In the perturbation method, deviations from the
(nominal) desired motion (q0, ˙q0, ¨q0) due to joint
friction and errors of the control system are modelled
as ﬁrst-order perturbations (δq, δ ˙q, δ ¨q) of the nomi-
nal motion, such that the actual variables are of the
form:
q = q0 + δq,
(20)
˙q = ˙q0 + δ ˙q,
(21)
¨q = ¨q0 + δ ¨q,
(22)
where the preﬁx δ denotes a perturbation. Expanding
(1) and (3) in their Taylor series expansion and disre-
garding second and higher order terms results in the
linear approximations
δx = DF0·δq,
(23)
δ ˙x = DF0·δ ˙q + (D2F0· ˙q0)·δq.
(24)
The subscript 0 refers to the nominal trajectory.
The nominal motion is computed ﬁrst and is de-
scribed by the non-linear manipulator model.
The
non-linear equations of motion (14) for the nominal
motion become
¯M(n)
0
¨q0
+ DqFT
0

M0(D2F0·( ˙q0))·( ˙q0) −f

+ DF(e,c)
0
σ(c)
0
= τ (n)
0 ,
(25)
where σ(c)
0
= σ(c,0) + ks e(c)
0 . The right hand side
vector τ (n)
0
represents the nominal net input torque
necessary to move the manipulator along the nomi-
nal (desired) trajectory. It is determined from an in-
verse dynamic analysis based on (25). Note that τ (n)
0
is computed without the presence of friction. Obvi-
ously, the desired nominal motion (¨q0, ˙q0, q0) equals
the reference motion (¨q(r), ˙q(r), q(r)) of the closed
loop system.
Next the perturbed motion is described by a set
of linear time-varying equations of motion, which
are obtained by linearising the equations of motion
around a number of points on the nominal trajectory.
The resulting equations of motion for the perturba-
tions of the degrees of freedom δq are
¯M(n)
0 δ ¨q + C0δ ˙q + ¯K0δq = δτ (n),
(26)
where ¯M(n)
0
is the reduced system mass matrix as in
(14), C0 is the velocity sensitivity matrix. Matrix ¯K0
is a shorthand notation for the combined stiffness ma-
trices
¯K0 = K0 + N0 + G0,
(27)
191
Realistic Dynamic Simulation of an Industrial Robot with Joint Friction

where K0 denotes the structural stiffness matrix, N0
and G0 are the dynamic stiffening matrix and the geo-
metric stiffening matrix, respectively. The matrices
¯M(n)
0 , K0 and G0 are symmetric, but C0 and N0
need not to be symmetrical. Expressions for these
matrices are given in (Jonker and Aarts, 2001).
Fig. 5 shows the block scheme of the closed-loop
perturbation model. Note that the non-linear manip-
ulator model (SPACAR) is replaced by the LTV-block
which solves (26). Its input δτ (n) is computed ac-
cording to
δτ (n) = τ (n) −τ (n)
0 ,
(28)
where τ (n) represents the vector of the net joint
torques as deﬁned by (16). The perturbed output vec-
tor δy is added to the output vector y0 of the nominal
model, yielding the actual output y. This output vec-
tor will be discussed below.
Within the SIMULINK framework the LTV block
represents a linear time-varying state space represen-
tation of a system
˙xss = Assxss + Bssuss
yss = Cssxss
(29)
where uss, yss and xss are the input, output and state
vectors, respectively, and Ass, Bss and Css are the
time-varying state space matrices. Equation (26) is
written in this representation by deﬁning the state and
input vectors
xss = [δ ˙q, δq]T ,
uss = δτ (n).
(30)
The state space matrices Ass and Bss are then com-
puted from the matrices in (26) using a straightfor-
ward procedure :
Ass =

0
I
−¯M(n)
0
−1 ¯K0
−¯M(n)
0
−1 C0
 
,
Bss =

0
¯M(n)
0
−1
 
.
(31)
The output matrix Css depends on the output vector
yss that is deﬁned by the user. It may consist of (ﬁrst
derivatives of) the degrees of freedom δq present in
xss or (ﬁrst derivatives of) nodal coordinates δx that
are computed from xss using (23) and (24). E.g. the
coordinates δx in yss are computed using
Css = [ DF0
0 ] .
(32)
For a practical implementation of the perturba-
tion method the total trajectory time T is divided
into intervals. The state space matrices and the vec-
tors τ 0 and y0 are computed during a preprocess-
ing run at a number N of discrete time steps t = ti
(i = 0, 1, 2, ..., N) and stored in a ﬁle. During the
Figure 6: The simulated straight line path and the path ve-
locity.
simulation runs the matrices and vectors are then read
back from this ﬁle. Between two time steps the co-
efﬁcients of the state space matrices are interpolated
linearly. Cubic interpolation is used for the vectors τ 0
and y0.
7
SIMULATION RESULTS
In Fig. 6 an experiment is deﬁned in which a straight
line motion of the robot tip has to be performed in the
horizontal plane with a velocity proﬁle as presented
in the insert. The welding head remains in the vertical
position as shown in Fig. 6. The joint set-points are
computed with the inverse kinematics module of the
SPACAR software. The joint velocities are shown in
Fig. 7. The ﬁgures show clearly the non-linear behav-
iour of the robot. Note the velocity reversal of joints
2 and 3 nearly halfway the trajectory.
First, the trajectory will be simulated with the non-
linear model. The simulation has been performed in
SIMULINK using the ode23tb integration scheme,
which is one of the stiff integrators in SIMULINK.
The stiff integration scheme is needed due to the high
equivalent stiffness in the pre-sliding part of the fric-
tion model (18).
The path performance as predicted by the model
will be compared to measurements carried out on the
actual robot. In both the measurements and simula-
tions, the path position is based on joint axis positions
and the nominal kinematic model. In Fig. 8, the hor-
izontal and vertical path deviations are shown. The
results show that the agreement between the simu-
lated prediction and the measurement is within 20 µm
192
R.G.K.M. Aarts, B.J.B. Jonker and R.R. Waiboer

0
2
4
6
8
10
12
14
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
time [s]
V elocity [rad/s]
q1
q2
q3
q4
q5
q6
Figure 7: The joint velocity.
which is well within the range of accuracy required
for laser welding. At about 600 mm on the trajec-
tory, at the velocity reversal in joints 2 and 3, there is
a jump of the friction force, resulting in a relatively
large path error.
During the experiment the motor currents were
recorded. In Fig. 9 the measured motor currents of
joint 3 is compared with the simulated motor current
as an example. The simulation shows good agreement
with the measurements. It can be observed that the
motor currents are predicted quite accurately in the
sliding regime and near the velocity reversal. How-
ever, the model is unable to predict the stick-torques
with a high level of accuracy. This can be explained
by the fact that the stiction torque can be anywhere be-
tween τ (s)
−
and τ (s)
+
over a very small position range
of tenths of µrad, due to the high equivalent stiffness
c(0) in (18).
The required simulation time with the non-linear
simulation model was about 70 minutes on a 2.4 GHz
Pentium 4 PC, which indicates that it is computation-
ally quite intensive. This is caused by the small time
steps at which the manipulator conﬁguration, see (1)
and (2), needs to be solved by an iterative method. To
overcome this drawback, the perturbation approach
will be used next.
For the perturbation method the number of points
along the trajectory N at which the system is lin-
earised is taken to be 400. The simulation results of
the perturbation method and the non-linear simulation
have been compared. Fig 10 shows the path accuracy
along the trajectory. There is no noticeable difference
between the results at this scale. The error stays well
below 10 µm and is mostly less than 2 µm. Also the
agreement between the simulated motor currents for
both the non-linear simulation and the perturbation
method is good, especially when the manipulator is in
motion. At rest, the torques in the stick or pre-sliding
regime shows some differences as before. A signiﬁ-
cant reduction of simulation time by about a factor 10
has been achieved.
0
200
400
600
800
1000
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
Measurement
Simulation
position [mm]
deviation [mm]
a. Horizontal deviation
0
200
400
600
800
1000
0.08
0.06
0.04
0.02
0
−0.02
−0.04
Measurement
Simulation
position [mm]
deviation [mm]
b. Vertical deviation
Figure 8: Simulated and measured path deviation.
8
CONCLUSIONS
In this paper a realistic dynamic simulation of a rigid
industrial robot has been presented. The following
components are essential for the closed-loop simula-
tion:
• A ﬁnite element-based robot model has been used
to model the mechanical part of the robot. Robot
identiﬁcation has been applied to ﬁnd the model pa-
rameters accurately.
• Furthermore, joint friction has been modelled using
the LuGre friction model.
• Finally, a controller model has been identiﬁed and
implemented.
The complete closed-loop model has been used for
the simulation of the motion of the robot tip along
a prescribed trajectory. The simulation results show
good agreement with the measurements. It was found
that a closed-loop simulation with the non-linear ro-
bot model was very time consuming due to the small
time step imposed by the discrete controller. Appli-
cation of the perturbation method with the linearised
model yields a substantial reduction in computer time
without any loss of accuracy. The non-linear ﬁnite
193
Realistic Dynamic Simulation of an Industrial Robot with Joint Friction

0
2
4
6
8
10
12
14
−900
−800
−700
−600
−500
−400
−300
−200
−100
0
100
time [s]
Current [Counts]
Measurement
Simulation
Figure 9: Measured and simulated motor current for joint 3.
element model and the perturbation method can rela-
tively easy be extended to account for ﬂexibilities in
the robot.
This work was carried out under the project num-
ber MC8.00073 in the framework of the Strate-
gic Research programme of the Netherlands In-
stitute for Metals Research in the Netherlands
(http://www.nimr.nl/).
The authors acknowledge the work carried out on
the identiﬁcation of the controller, inertia parameters
and friction parameters by W. Holterman, T. Harde-
man and A. Kool, respectively.
REFERENCES
Calaﬁore, G., Indri, M., and Bona, B. (2001). Robot dy-
namic calibration: Optimal excitation trajectories and
experimental parameter estimation.
Journal of Ro-
botic Systems, 18(2):55–68.
Haessig, D. and Friedland, B. (1991).
On the modeling
and simulation of friction. Transactions of the ASME,
Journal of Dynamic Systems, Measurement and Con-
trol, 113(3):354–362.
Jonker, J. (1990). A ﬁnite element dynamic analysis of ﬂex-
ible manipulators. International Journal of Robotics
Research, 9(4):59–74.
Jonker, J. and Aarts, R. (2001). A perturbation method for
dynamic analysis and simulation of ﬂexible manipu-
lators. Multibody System Dynamics, 6(3):245–266.
Jonker, J. and Meijaard, J. (1990). Spacar-computer pro-
gram for dynamic analysis of ﬂexible spatial mech-
anisms and manipulators.
In Schiehlen, W., ed-
itor, Multibody systems handbook, pages 123–143.
Springer-Verlag, Berlin.
0
200
400
600
800
1000
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
Non-linear
perturbation
position[mm]
deviation[mm]
a. Horizontal deviation
0
200
400
600
800
1000
0.08
0.06
0.04
0.02
0
−0.02
−0.04
Non-linear
perturbation
position[mm]
deviation[mm]
b. Vertical deviation
Figure 10: Simulated path deviation (non-linear versus per-
turbation method).
Swevers, J., Ganseman, C., Schutter, J. D., and Brussel,
H. V. (1996). Experimental robot identiﬁcation using
optimised periodic trajectories. Mechanical Systems
and Signal Processing, 10(5):561–577.
Waiboer, R. R. (to be published, 2004). Dynamic robot sim-
ulation and identiﬁcation – for Off-Line Programming
in robotised laser welding. PhD thesis, University of
Twente, The Netherlands.
Wit, C. d., Olsson, H., ˚Astr¨om, K., and Lischinsky, P.
(1995).
A new model for control of systems with
friction.
IEEE Transactions on Automatic Control,
40(3):419–425.
194
R.G.K.M. Aarts, B.J.B. Jonker and R.R. Waiboer
ACKNOWLEDGEMENTS

A NEW PARADIGM FOR SHIP HULL INSPECTION USING A 
HOLONOMIC HOVER-CAPABLE AUV 
Robert Damus, Samuel Desset, James Morash, Victor Polidoro, Franz Hover, Chrys Chryssostomidis 
Sea Grant Autonomous Underwater Vehicles Lab, Massachusetts Institute of Technology, Cambridge, MA, USA 
Email: auvs@mit.edu
Jerome Vaganay, Scott Willcox 
Bluefin Robotics Corporation, Cambridge, MA, USA 
Email: vaganay@bluefinrobotics.com, swillcox@bluefinrobotics.com  
Keywords:  
Autonomous Underwater Vehicle, hovering, feature-relative navigation, inspection. 
Abstract:   
The MIT Sea Grant AUV Lab, in association with Bluefin Robotics Corporation, has undertaken the task of 
designing a new autonomous underwater vehicle, a holonomic hover-capable robot capable of performing 
missions where an inspection capability similar to that of a remotely operated vehicle is the primary goal.  
One of the primary issues in this mode of operating AUVs is how the robot perceives its environment and 
thus navigates.  The predominant methods for navigating in close proximity to large iron structures, which 
precludes accurate compass measurements, require the AUV to receive position information updates from 
an outside source, typically an acoustic LBL or USBL system.  The new paradigm we present in this paper 
divorces the navigation routine from any absolute reference frame; motions are referenced directly to the 
hull.  We argue that this technique offers some substantial benefits over the conventional approaches, and 
will present the current status of our project. 
1 INTRODUCTION AND 
EXISTING CAPABILITIES 
The majority of existing autonomous underwater 
vehicles (AUVs) are of a simple, torpedo-like 
design. Easy to build and control, the torpedo-
shaped AUV has proven useful in many applications 
where a vehicle needs to efficiently and accurately 
survey a wide area at low cost. As the field of 
underwater robotics continues to grow, however, 
new applications for AUVs are demanding higher 
performance: in maneuvering, precision, and sensor 
coverage.  In particular, the ability to hover in place 
and execute precise maneuvers in close quarters is 
now desirable for a variety of AUV missions. 
Military applications include hull inspection and 
mine 
countermeasures, 
while 
the 
scientific 
community might use a hovering platform for 
monitoring coral reefs, exploring the crevices under 
Antarctic ice sheets, or close-up inspection in deep-
sea archaeology. An autonomous hovering platform 
has great potential for industrial applications in areas 
currently 
dominated 
by 
work-class 
remotely 
operated vehicles (i.e., tethered, ROVs): subsea 
rescue, intervention, and construction, including 
salvage and wellhead operations. 
Frequent hull inspection is a critical maintenance 
task that is becoming increasingly important in these 
security-conscious times. Most ships (whether 
civilian or military) are only inspected by hand, in 
dry-dock, and thus rarely - certainly not while they 
are in active service. Standards do exist for UWILD 
(Underwater Inspection in Lieu of Drydock), but 
divers 
have 
typically 
performed 
underwater 
inspections, a time-consuming, hazardous job. 
Additionally, there is a high probability of divers 
missing something important, because it is so 
difficult for a human being to navigate accurately 
over the hull of a ship, with their hands, and often in 
poor visibility.  With a loaded draft on the order of 
30m and a beam of 70m for a large vessel, 
debilitating mines can be as small as 20cm in size, 
and in this scale discrepancy lies the primary 
challenge of routine hull inspection. 
195
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 195–200. 

     The simplest inspection is a visual examination 
of the hull surface.  Underwater however, 
(particularly in harbors and at anchor in coastal 
waters) a visual inspection must be performed very 
close to the ship. The health of a ship’s skin may 
also be judged by measuring plating thickness, or 
checking for chemical evidence of corrosion.  For 
security purposes, a sonar image may be adequate 
because of larger target size.  For instance, the US 
Customs Service currently uses a towfish sidescan 
sonar to check hulls (Wilcox, 2003). 
Some military vessels are now using small, free-
swimming ROVs for in-situ inspection (Harris & 
Slate, 1999). This method eliminates the safety 
hazard of diver work, but retains the disadvantage of 
uncertain navigation and human load.  The only 
commercial hull inspection robot, at the time of this 
writing, is the Imetrix Lamp Ray. Lamp Ray is a 
small ROV designed to crawl over the hull surface. 
The ROV is deployed from the vessel under 
inspection; the vehicle swims in and closes with the 
hull under human control, then holds itself in place 
using front-mounted thrusters for suction. The 
operator then drives the ROV over the hull surface 
on wheels. This limits the survey to flat areas of the 
hull; more complex geometry around e.g. sonar 
domes, propeller shafts, etc. must still be visually 
inspected with a free-swimming ROV. The Cetus II
AUV is an example of a free-swimming autonomous 
system that has also conducted ship hull surveys 
(Trimble & Belcher, 2002). Using altimeters to 
maintain a constant relative distance from the hull, 
and the AquaMap long baseline navigation system 
(DesertStar, Inc.), Cetus II records globally-
referenced position information, and this (with depth 
and bearing to the hull) is the primary navigation 
sensor used to ensure and assess full coverage.  The 
AquaMap system uses a transponder net deployed in 
the vicinity of the ship being inspected (see URL in 
References); clearly, a long baseline acoustic system 
could be used for any vehicle.   
Our vehicle program has three unique aspects to 
address 
the 
needs 
of 
ship hull 
inspection:  
development of a small autonomous vehicle 
optimized for hovering, and of a hull-relative 
navigation procedure, wherein dependence on a 
deployed acoustic navigation system is avoided.  
The data product this vehicle will produce is a high-
resolution sonar mosaic of a ship hull, using the 
DIDSON 
imaging 
sonar 
(University 
of 
Washington’s Applied Physics Laboratory) as a 
nominal payload (Belcher et al., 2003). 
2 PHYSICAL VEHICLE 
OVERVIEW
The hovering AUV (HAUV, Figure 1) has eight 
hubless, bi-directional DC brushless thrusters, one 
main electronics housing, and one payload module. 
The symmetrical placement of the large number of 
thrusters makes the vehicle agile in responding to 
wave disturbances, and capable of precise flight 
maneuvers, such as orbiting targets for inspection or 
hovering steadily in place.  The vehicle is intended 
to operate in water depths ranging from the Surf 
Zone (SZ) through Very Shallow Water (VSW) and 
beyond, up to depths of 100 meters; and to perform 
in waves up to Sea State Three. 
Onboard non-payload instruments include a 
Doppler velocity log (DVL), inertial measurement 
unit (IMU), depth sensor, and acoustic modem for 
supervisory control.  While we do carry a magnetic 
compass, this cannot be expected to work well in 
close proximity to a metal hull.  As noted above, the 
nominal payload at this writing is the DIDSON 
imaging sonar.  Both the DIDSON and the DVL are 
mounted on independent pitching servos at the front 
of the vehicle, because the DIDSON produces good 
imagery at an incidence angle greater than 45 
degrees, while the DVL needs to maintain a normal 
orientation to the hull.  The DVL can also be pointed 
down for a bottom-locked velocity measurement.   
The vehicle is strongly passively stable, with a 
gravity-buoyancy separation of about 3cm.  It has 
approximate dimensions of 100cm long, 80cm wide, 
and 30cm tall; it displaces about 45kg.  Of this 
weight, about 12kg are for a 1.5kWh battery. 
3 OUR APPROACH TO HULL 
NAVIGATION
We have chosen to attack this problem from a 
feature-relative navigation standpoint, as this has 
some advantages compared to current approaches.  
Our basic strategy is to measure tangential velocity 
relative to the hull being inspected using a Doppler 
velocity log (DVL), and to servo a desired distance 
from the hull, and orientation, using the individual 
ranges from acoustic beams. 
The immediate impact of this functionality is the 
elimination of support gear for the robot itself; no 
localized network setup like LBL is needed.  This 
reduces complexity and provides a simple, quick 
deployment where the robot can operate unattended; 
our long-term goal is that the mission focus could 
196
R. Damus et al. 

Figure 1:  The HAUV, showing DIDSON (light 
brown) and DVL (dark blue) on the front, yellow
flotation in the mid-body, and a large battery at the
stern. Thruster locations are reconfigurable; the main
can be deployed quickly to respond to developing
situations below the waterline. 
As a second benefit, the proposed feature-
relative control schemes should work when the ship
being inspected is fixed within a close berth (where
LBL navigation could be poor), anchored and
moving slowly about its mooring, or moving freely
at very low speed, e.g., adrift.
The key technical point to note about navigating
relative to a fixed hull surface is that the vehicle is 
constrained absolutely in the DOF normal to the
hull, but not tangentially.  A featureless hull is a 
poor candidate for visual or sonar image serving,
and the use of DVL velocity measurements for
positioning invokes an obvious drift error over time.
3.1 Suitability of the DVL for this 
Task
The DVL (RD Instruments; see URL in References)
comprises four narrow beam transducers, arranged
uniformly at a spread angle of 30 degrees, and
operating broadband in the frequency range of
1200kHz.  The Doppler shift is measured for each 
beam, and an average sensor-relative tangential
velocity vector is computed. We also have available
the four ranges from the individual transducers: the
device provides range by using the return times from
each sensor and the speed of sound in water.
Complete 
(four-transducer) 
measurements 
are
available at a bandwidth of 3-8Hz, depending on
signal quality and range.
Figure 2: DVL performance when towed along the hull of
We performed a series of tests with the DVL,
with the specific goal of determining suitability for
the hull-relative inspection task.  Specifically, we 
have considered:  a) what is the drift rate of the
integrated velocities?  b) What
is
the noise
characteristic 
of 
the 
independent 
range
measurements?  c) What is the effect of a metal hull,
with biofouling?
d) Does the DIDSON acoustic
imaging system interfere with the DVL?
x
On a cement and glass wall at the MIT
Ocean Engineering Testing Tank, the
position error in integrating velocity was 
confirmed to be about 0.5 percent of
distance traveled.  The error goes up 
substantially when the sensor is oriented
more than 30 degrees from normal to the 
hull.
x
We performed field tests along the hull of
the
USS Cassin Young,
at the Navy
Shipyard in Charlestown, Massachusetts.
As shown in Figure 2, the range and 
velocity measurements are well behaved.
x
We performed controlled tests at the
Testing Tank, with simultaneous operation
of the DIDSON and the DVL.  DIDSON
images (at 5fps) show the DVL pings as a
197
A New Paradigm for Ship Hull Inspection 
electronics housing is underneath the foam. 
the USS Cassin Young.
shift towards analyzing the data collected.  The lack 
of a shipboard system presence also means the craft 

faint flash, but the image is by no means
unusable.  Conversely, there is a slight
degradation 
of
the 
DVL’s 
velocity
performance.  The drift rate approximately
doubles, but remains below 1cm per meter
of distance traveled, which is sufficiently
low enough to satisfy our concept of 
operations.
Figure 3: The horizontal slice method; the vehicle makes 
3.2 Two Approaches Using “Slicing”
The DVL can be used to servo both orientation and
distance to the hull (through the four independent
range measurements) and to estimate the distance
traveled, with reasonable accuracy. When coupled
with an absolute depth measurement, two plausible
inspection scenarios emerge for the majority of a
large ship’s surface: vertical and horizontal
“slicing.”
For the purposes of this paper, we
confine our discussion to the large, relatively smooth
surface of the hull sides, bottom, and bow.  As with
other existing automated inspection methods, the
stern area with propellers, rudders, shafting and
bosses cannot be easily encompassed within our
scheme.
In the case of horizontal slicing (Figures 3 and
4), paths in the horizontal plane are performed.  The
absolute depth provides bounded cross-track error
measurement, while the integrated velocity provides
the along-track estimate of position.  This along-
track position, with depth, is recorded for each 
image.
Defining the end of a track at a given depth is a
sensing challenge to which we see several possible
approaches.  First, there may be landmarks, such as
weld lines, protuberances, or sharp edges as found
near the bow or stern areas.  These landmarks,
especially if they occur at many depths, can be used
to put limits on the search area, and to re-zero the
integrated velocity error.  Certainly prior knowledge
of the ship’s lines and these features can be
incorporated into the mapping strategy at some
level.
On the other hand, the complete absence of 
features is workable also:  operate at a given depth
until the integrated velocity safely exceeds the
circumference of the vessel, then move to another
depth.
When an object of interest is detected, 
immediate surfacing must occur in this scenario
since location along the hull would be poorly
known.
The horizontal slice method is very good for the
sides and bow of a vessel.  Many vessels, for
example, large crude carriers (LCC’s) have flat
bottoms, which must also be inspected. Here, aside
from the fact that the vehicle or the imaging sensor
and DVL must be reoriented to look up, there is no 
cross-track error available, since the depth is roughly
constant.  Long tracks parallel to the hull centerline
would be subject to accrued errors on the order of
several meters.  The vertical slice approach (Figure
5) addresses this problem, by making paths down the
sides of the hull and then underneath, in a plane
normal to the hull centerline.
Once at the
centerline, options are to turn around and come back
up on the same side, or to continue all the way under
the hull to surface on the other side, after a 180-
degree turn in place (which must be constructed 
based on rate gyro information only).  In either case, 
the important property here is that the path length is
limited, so that the cross-track errors are limited, and
overlap can be applied as necessary.  For instance,
using a vertical path length of 130m implies a cross-
track error on the order of 65cm, which is easily
covered by overlapping images with field of view
several meters, assuming no systematic bias.
Convex or concave, two-axis curvature of the
hull also requires some overlap.  For instance, in the
extreme case of a spherical hull and the vertical
survey, like ribbons around a ball, the imaged path
lines converge at the bottom.  These cases will 
require further study and mission design at a high
level.
3.3 Role of Low- and Mid-Level
Control
Dynamically, the vehicle is equipped with high-
performance thrusters so as to operate in shallow
waters, waves, and in proximity to hulls.  The
primary sensor we have available, the
DVL,
however, is a comparatively low bandwidth device,
which cannot provide robust measurements for 
direct control – the
noise properties may be
unpredictable, timing may vary, and missed data are
not uncommon.
Furthermore, loss of contact with
the hull can occur in regular operation, and even be
exploited as a landmark.
198
R. Damus et al. 
passes at constant depth.

Figure 4:  Operation during horizontal survey, looking at 
the side of the vessel.  The vehicle is shown in blue, with
the four DVL footprints in yellow on the hull.  The
DIDSON images (green) are taken looking downward as
In waves, the depth sensor also fails as a high-
bandwidth navigation sensor.  As a consequence of
these facts, the vehicle has to be capable of short-
term autonomous navigation, through a high-end
inertial measurement unit, and an integrated low-
level control system. The division of control can be
stated as follows:  The low-level controller depends
only on the core sensors of the IMU, while a mid-
level layer incorporates the DVL and depth sensor,
and a high-level controller manages the mission and
desired pathlines.  This multi-level control system is
to be of the inner-outer loop type, with the DVL and
depth sensor providing
setpoints for higher-
bandwidth inner loops.  As in most cases of inner-
outer design, the outer loop bandwidth should be at
least 3-5 times slower than the inner loop.
Consider for example the case of yaw control
relative to the hull. At the innermost level, a yaw
rate servo runs at maximum update frequency and
closed-loop bandwidth, employing a model-based
estimator, i.e., a Kalman Filter for handling vehicle
dynamics and sensor channels that are coupled due
to gravity.  The mid-level control has coupling, due
to the fact that the DVL is like a velocity sensor on a 
moment arm, so that yaw and sway at the wall are
kinematically coupled.
This is one of many
concepts from visual servoing that are appropriate
here (e.g., Hutchison et al., 1996).
 Figure 6 gives
an illustration of hull servoing using nested low- and
mid-level control, and DVL data. 
4 SUMMARY
Doppler velocimetry with ranging facilitates a new
feature-relative approach for autonomous ship hull
inspection,
one which allows several intuitive
strategies that can account for the majority of the 
hull surface.  The use of landmarks and ship’s lines,
as well as survey techniques for complex stern 
arrangements are still open questions.
Support is acknowledgedfrom the Office of Naval
Research (Dr. T.F. Swean) under Grant N00014-02-
1-0946, and from NOAA and the Sea Grant College
Program, Grant NA 16RG2255.
Figure 5:  Vertical slice survey; the vehicle makes depth 
Figure 6:  Example of low- (PID) and mid-level (LQG) 
coupled control in the yaw-sway hull positioning problem.
Vehicle initially is at a 42 degree bearing, 3m range; final
position is zero degrees bearing, 1.7m range.  The
controller keeps the tangential velocity small while
reorienting, so that the excursion of the DVL “pointer” on 
REFERENCES
Belcher, E., B. Matsuyama, and G. Trimble, 2003. Object
Identification 
with 
Acoustic 
Lenses. 
http://www.apl.washington.edu/programs/DIDSON/M
199
A New Paradigm for Ship Hull Inspection 
the vehicle moves. 
passes with zero sway velocity.
the wall (line on right hand side) is 12cm.
edia/object_ident.pdf.

Harris, S.E. and E.V. Slate, 1999.  Lamp Ray: Ship Hull 
Assessment for Value, Safety and Readiness. Proc. 
IEEE/MTS Oceans. 
Hutchinson, S., G.D. Hager, and P.I. Corke, 1996.   A 
tutorial on visual servo control.  IEEE Trans. Robotics 
and Automation, 12:651-670.  
RD Instruments DVL, http://www.dvlnav.com. 
Ship 
Hull 
Inspections 
with 
AquaMap 
http://www.desertstar.com/newsite/positioning/shiphul
l/manuals/Ship%20Hull%20Inspections.pdf.
Trimble, G. and E. Belcher, 2002. Ship Berthing and Hull 
Inspection Using the CetusII AUV and MIRIS High-
Resolution 
Sonar, 
Proc. 
IEEE/MTS 
Oceans. 
http://www.perrymare.com/presentations/Oceans%202
002%20Homeland%20Defense.pdf.
See 
also: 
http://web.nps.navy.mil/~brutzman/Savage/Submersib
les/UnmannedUnderwaterVehicles/CetusFlyerMarch2
001.pdf.
Wilcox, T., 2003.  Marine Sonic Technologies Ltd.,
Personal communication. 
200
R. Damus et al. 

DIMSART: A REAL TIME - DEVICE INDEPENDENT MODULAR
SOFTWARE ARCHITECTURE FOR ROBOTIC AND TELEROBOTIC
APPLICATIONS
Jordi Artigas, Detlef Reintsema, Carsten Preusche, Gerhard Hirzinger
Institute of Robotics and Mechatronics, DLR (German Aerospace Center)
Oberpfaffenhofen, Germany
Email: ﬁrstname.lastname@dlr.de
Keywords:
Telepresence, Distributed Control, Indpendency, Robotic, Telerobotic, DIMSART, RTLinux, VxWorks.
Abstract:
In this paper a software architecture for robotic and telerobotic applications will be described. The software
is device and platform independent, and is distributed control orientated. Thus, the package is suitable for
any real time system conﬁguration. The architecture allows designers to easily build complex control schemes
for any hardware device, easily control and manage them, and communicate with other devices with a plug-
in/plug-out modular concept. The need to create a platform where control engineers/designers could freely
implement their algorithms, without needing to worry about the device driver and programming related issues,
further motivated this project. Implementing a new control algorithm with the software architecture described
here, requires that the designer simply follow a template where the necessary code is reduced to only those
functions having to do with the controller. We conducted several teleoperation schemes, one of which will be
presented here as a conﬁguration example.
1
INTRODUCTION
Control methods are nowadays totally related to soft
computing techniques. From this relationship a new
area in software engineering is emerging, which ex-
plores the interplay between the control theory and
software engineering worlds. It is in this research di-
rection that the authors found the need of building a
robotic control software architecture. Among other
things, the architecture should facilitate the develop-
ment of robotic and telerobotic control schemes by
deﬁning beneﬁcial constraints on the design and im-
plementation of the speciﬁc application, without be-
ing too restrictive.
Keeping this goal in mind, the
DIMSART has been developed by the Telepresence
group of the Institute of Robotics and Mechatronics
to provide a practical, convenient and original solu-
tion.
1.1
Telepresence Environment
The focus of the DIMSART is the development of
Telepresence systems. Telepresence is an extension
of the telerobotics concept in which a human operator
is coupled with as much sensory information as possi-
ble to a remote environment through a robot, in order
to produce an intuitive and realistic interaction with
that environment. The range of senses can encom-
pass vision, tactile, auditory, and even smell and taste
senses. Our interest is focused on the haptic chan-
nel, therefore the type of information which is sent
is motion and force data. From the control point of
view, such systems are often referred to as bilateral
control schemes (see ﬁg.1), because two controls are
simultaneously performed in the telepresence global
closed loop, one on the master side (controlling the
master device), and one on the slave side (controlling
the slave device).
A telepresence system developed by the Telepres-
ence research group from DLR Oberpfaffenhofen will
be used in this article to show the needs and require-
ments of the architecture, and thus, motivate the de-
velopment of the DIMSART to the reader. Its extrap-
olation to
”
mono-lateral” robotics applications will be
straightforward.
Figure 1: Telepresence Scheme.
201
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 201–208. 

1.2
Control and Software
engineering Interplay
A not less signiﬁcant goal is the creation of an har-
mony between the computer science world and the
control engineering world. Not rarely, control engi-
neers are faced with obstacles arising from the pro-
gramming work required for controlling and driving
hardware
devices. The software architecture de-
scribed here allows a control engineer to forget about
issues related to device drivers, real time program-
ming, concurrencies or thread programming. Thus,
he/she only needs to concentrate on the speciﬁc con-
trol algorithm.
As it will be seen, by using this
software platform, the designer is only faced with
the creation a
”
module”, for which a template-based
methodology is used. This goal will result in a pro-
gramming time saving for the control designer and
thus the consequence of investing the whole energy
in the control design itself.
1.3
Existing Architectures
The generalized needs of facilitating efﬁcient robotic
system designs and implementations resulted in
the development of several software architectures.
In (`Eve Coste-Mani`ere and Redi Simmons, 2000)
these general needs are formalized. Furthermore, the
importance of making the right architecture choice
is noted, and some architectures are compared and
contrasted.
Some architectures for robotic systems are very
complete packages which consider the overall struc-
ture for controlling a robot, including all possible
levels of competence in a robotic system (sensing,
mapping, modeling, planning, AI, task execution,
motor control, etc...) either in a hierarchical layered
style (Albu et al., 1988), in a behavioral one (Brooks,
1986), or in an hybrid one (Borrelly et al., 1998),
(Schneider et al., 1998), (RTI, 2004), (Volpe et al.,
2001). However these kind of architectures are more
appropriate for autonomous robot vehicles where
a control at high level or, alternatively, a Decision
Layer, as mentioned in (Volpe et al., 2001), is of high
importance.
Other architectures are not so concerned with
layered structures and emphasize instead the real
time operation as a sequence of control components
executed at a lower level. These architectures tend to
be simpler but more ﬂexible (Scholl, 2001), (Stasse
and Kuniyoshi, 2000).
The DIMSART architecture shines for its simplic-
ity, ﬂexibility and portability. It can be included to the
second group of architectures, but it is more focused
in the automatic control level. Furthermore, it can
be easily embedded in other architectures or systems
with almost any Linux/Unix operating system type:
Linux, Solaris, RTLinux, VxWorks.
The outline of this paper is as follows. We ﬁrst
present, in section 2, a chapter dedicated to general
robotic control concepts with a particular scheme ex-
ample which will be used in the subsequent sections
to introduce the DIMSART architecture. We then de-
scribe the software platform and its main parts in sec-
tion 3. Section 4 introduces a complete experimen-
tal setup as a DIMSART conﬁguration example. Fi-
nally, in section 5, some concluding remarks and fu-
ture lines are given.
2
ROBOT CONTROL
We will make use of a telepresence control scheme
example to focus our interest in three aspects: distrib-
uted control, the data ﬂow and the deﬁnition of the
acting regions of our framework. Also in this chap-
ter, a more abstract view of a general robotic control
scheme will be introduced, and later it will be speci-
ﬁed within the mentioned example.
2.1
Wave Variables Scheme as
Bilateral Control Example
In ﬁg.2 a block diagram of a Wave Variable control
scheme can be seen.
The Wave Variables Theory
is a common approach to minimize the degradative
effects of time-delayed communication channels
in telepresence systems.
For detailed information
about this theory refer to (Niemeyer, 1996) and
(Artigas, 2003) . It is not the aim of this paper to
detail the control theory behind the scheme. Rather,
it is intended to be used as a reference point for the
DIMSART approach. We will refer to this example
in some of the following sections to give support to
the theoretical explanations of the architecture.
Figure 2: Global control software is decoupled from hard-
202
J. Artigas et al. 
ware device, driver and communication.

Distributed Control
In telepresence scenarios the concept of distributed
control becomes an important issue. Although from
the hardware point of view both master and slave de-
vices can be quite different, from the control point of
view they are not so dissimilar. The main idea of dis-
tributed control is to divide the global control task of
the system in n identical or quasi identical local con-
trol components. The nature of a bilateral control is
to distribute the control task between both sides, mas-
ter and slave. The control component, -henceforth re-
ferred to as module-, will have to be sufﬁciently pow-
erful to support
1. The existing differences between master and slave
robots/environments characteristics (for instance,
controller constants, input/output variables, algo-
rithm differences, etc...)
2. Possible different OS platforms. For example, the
master could be controlled by a RTLinux machine,
and the slave by a VxWorks one.
In our bilateral control scheme, the control task is
distributed between master and slave sides through
the Wave Transformer and PD Controller blocks.
The two blocks on each side of the system in
ﬁg.2, PD Controller and Wave Transformer, can be
viewed, from the software point of view, as a chain of
algorithms with similar characteristics sequentially
called.
This reasoning leads to an object-oriented
direction, in which a Module Template class can be
constructed and from which different objects (the
control elements) can be deﬁned.
Modularity will
facilitate a Top-down design methodology, as well as
code reuse.
By deﬁning the operating boundaries shown in
ﬁg.2, the independence from the hardware driver and
the communication channel will be preserved, or, in
other words, the control task will be uncoupled (from
the software point of view) from the rest of the sys-
tem. Portability and independence are direct conse-
quences. That is, portability to other robotic systems
can be achieved, independently of the robot and com-
munication channel.
2.2
General Robot Control setup
Fig.3 skews the components of a general robotic sys-
tem. On the lowest level, we ﬁnd the sensors and ac-
tuators of the haptic/robot device. The driver, which
is in charge of initializing and closing the device, and
reading and writing data from/to it, is part of what
we call the frame. The frame encompasses elements
located between the low level control layer, the hard-
ware I/O layer and the network communication layer.
The high level control layer deals with non-real time
control such as task planning or behavioral control.
Our framework will be focused on the low level con-
trol layer and its relationship with the frame.
HIGH LEVEL CTRL
LOW LEVEL CTRL
SENSORS
HW I/O
ACTU−
ATORS
NETWORK
COMM
FRAME
SCHEDULER
DRIVER
Some of the tasks of the frame include the commu-
nication between the software architecture, the hard-
ware device and the network, and the real time read-
ing, processing and writing scheduling.
The fol-
lowing code exempliﬁes the master’s main operation
of the example depicted in ﬁg.2 for a mono-thread
frame:
dev_open(&Phantom);
dev_init(&Phantom);
main_interrupt_thread(arg){ /*called every 1 ms*/
/* Some inis*/
Read_Comm(in_waves);
Robot_read(local_pos);
/*---------- Control ---------*/
exec_PDctrl(local_pos,
prev_des_pos,
out_force);
exec_WaveTrans(in_waves,
out_waves,
des_pos);
/* context save:*/
prev_des_pos=des_pos;
/*----------------------------*/
Write_Comm(out_data);
Robot_Command(force);
}
dev_close(&Phantom);
Often, the low level controlling task is performed
by the same frame in the real time main interrupt.
However, deﬁning the boundaries indicated in ﬁg.2,
and thus isolating the control task from the rest of the
system, would bring signiﬁcant beneﬁts. The DIM-
203
DIMSART
Figure 3: Components of a general robot control setup.
Main Operation and Data Flow
Defining Operating Boundaries

SART architecture provides the needed mechanisms
for this job.
2.3
Bilateral Control Scheme with
At this point, we are ready to concretely deﬁne
speciﬁc requirements for the architecture, as well
as its location in a robotic scheme.
Fig.4 shows
the introduced bilateral control example with a
DIMSART on each side. Each DIMSART performs
the control for each side and could be running in
different operating systems.
Figure 4: Bilateral control scheme with two DIMSART: one
on the master side, one on the slave side.
Requirements
1. OS independency.
2. Device independency. This implies that the archi-
tecture can be set for any DoF1, I/O data types and
sampling rate.
3. Modular. Permits a Top-down control scheme de-
sign methodology. Flexibility upon the design.
4. Dynamic. Only one compilation must be needed
to construct any control scheme conﬁguration.
5. Must allow distributed control.
3
ARCHITECTURE OVERVIEW
The DIMSART can be deﬁned as a real time device
independent software architecture for distributed con-
trol in robotic and telerobotic applications. The cen-
tral point of the DIMSART consist of a dynamic Data
Base. Around the Data Base, there is a frame and
modules. These two kind of elements interact with
the Data Base by writing data to it or reading from
it. A module, which implements a speciﬁc control al-
gorithm, gets its input from the Data Base and writes
its output to it. The device driver (frame) also reads
and writes from and to the Data Base in a similar
manner.
The modules are sequentially called by a
Module Engine and transform the input data to
produce their output. The following subsections de-
scribe each element mentioned above. Fig.5 is a block
1DoF: Degrees of Freedom
diagram of the DIMSART overview. Furthermore, in
a higher layer, a GUI has been developed to conﬁgure
the robotic control scheme. The user can choose from
a list of read-to-use modules which ones to activate,
and conﬁguration parameters can also be set for each
module.
Figure 5: DIMSART Concept Diagram. ”data x” stands for
data types.
3.1
Modules
In this framework, a Module is a piece of software
intended to perform real time operations. As already
mentioned, the module is the data processing unit of
the DIMSART. The range of possible functionalities
of a module is quite wide. Some examples are control
algorithms such as P, PD, PID controllers for robots
or haptic devices; simulation of an environment
such as a virtual wall; a magnitude converter such
as a data normalizer for sending data through a
network; a numerical integrator or derivator such as a
velocity-to-position converter; a wave transformer as
the one shown in ﬁg.2.
There are two types of data with which the Module
interacts: internal local data, which stores conﬁg-
uration parameters of the module and is located in
the same module, and the data to process, which
is stored in the Data Base. The real time main op-
erations of a module can be synthesized in three steps:
1) Read: read data from the Data Base.
2) Compute: process the data to perform the control.
3) Write: write the output data to the Data Base.
The type or types of data which the module
extracts from the Data Base, and later the types to be
written, are deﬁned in its activate function. There,
the module tells the Data Base the data type or types
which need to be read, and the type or types which
are to be written.
204
J. Artigas et al. 
DIMSART Embedded

Moreover, as it will be seen in section 3.3, the
Module Engine provides a mechanism for com-
municating with the active modules.
By means of
a Command interface, the user will be able to send
commands from the frame space to a speciﬁc mod-
ule. These commands are internally deﬁned in the
module, and they are thought to set the conﬁguration
parameters of the module (in the previous example, a
Command could be used to set the constants of the
PD Controller, or to specify the conﬁguration of the
Wave Transformer).
Once the DIMSART is loaded in a robotic system,
any control engineer can easily implement a module
by simply following a module pattern in a pure ”write
your code here” style. The aim of the DIMSART is to
create a list of modules, from which control engineers
will be able to build complex control schemes by
choosing and combining modules from this list.
Thus, a chain or sequence of modules will be created
to perform the control task of a robotic application.
As it will be seen in the following subsections, after
a module ”library” is created, the user will be able to
activate and deactivate modules in a plug-in/ plug-out
methodology.
Module Template
As already stated, every control block has simi-
lar characteristics. The Module Template formalizes
the base of every module in an object oriented way.
The class2 struct Module is declared here with a
group of functions and some attributes (see ﬁg.6).
2Simulated class in C code
3.1.1
Initialization and Activation
Initialization of a module means that its internal
memory is allocated, and its internal variables and
constants are initialized.
This process takes place
for every module belonging to the modules list
(attributed in the Module Engine, see ﬁg.6),
during the initialization process of the DIMSART.
On the other hand, only the desired modules
for the speciﬁc control scheme will be activated.
Activate means to insert the input and output data
types needed by the module under consideration into
the Data Base.
Thus the Data Base will dynam-
ically grow by means of each module activation.
The Module Engine,
or more precisely,
the
Module Step function (which will be called at
every time step), will act by calling the Compute
function of each active module.
It is important to note the differences between the
tasks of the initialization and activation processes.
In order to make the DIMSART compatible with
most operating systems, the conception of these ini-
tial processes is based on a kernel/modules3 model of
operating systems like Unix or Linux (Corbet, 2001).
A kernel module in RTLinux, for instance, allocates
its memory during its insertion process.
Once the
RTLinux module is inserted it should not allocate
more memory.
3.2
The Data Base
The core of the Data Base is a dynamic list which
stores the incoming data from each active module,
and the data coming from the frame (which comes
from the hardware device).
Furthermore, the Data
Base incorporates a set of mechanisms for the data
interaction between the active modules and the
dynamic list. Its construction is performed during the
initialization of the Module Engine and at each
module activation processes.
During the initialization the dynamic list is created
according to a Device Descriptor of the hardware
device. In this descriptor, characteristics such as the
DoF and input and output data types are enclosed.
After the initialization process, the Data Base is
created. At this point, each time a module is activated
new data ﬁelds are created in accordance with the
data types needed by the module.
Modules can
be inserted or removed at any time during system
operation (which in turn will insert or remove input
and output types into the Data Base).
3Unix/Linux kernel modules
205
DIMSART
Figure 6: Class-like Diagram of the DIMSART.

Types Matching Check
The matching check function performs a test to val-
idate the coherency of the relationship between the in-
put and output types of a constructed scheme. Fig.7
presents a closer view of the master side of the ex-
ample in section 2.1. It shows the data interactions
between the blocks in the master side. The PD Con-
troller, for instance, requires position and desired po-
sition as data inputs and outputs desired force. After
the scheme is constructed, the Types matching check
ensures that some other module provides the required
data. In our example, the Wave Transformer provides
desired position to the PD Controller, and the frame
position.
Figure 7: Detailed view of the control scheme in the master
3.3
The Module Engine
The Module Engine is the software layer between
the driver and the Data Base and modules. Through
it, a set of capabilities are provided to control and
schedule the engine of the DIMSART from the
frame.
A description of the main functionalities
and attributes follows. Refer to ﬁg.6 to locate each
function and attribute described here.
Frame Descriptor: The
frame
provides
to
the
Module Engine a descriptor of the robot in the
Module Engine initialization function.
This
descriptor contains information about the DoF of
the device, number of input and output data types,
and which types are needed by the device. With
this information, the Module Engine initializes
the Data Base.
List of Modules: During the initialization step, a list
of modules is created with all the included mod-
ules in the DIMSART software architecture from
which, the user chooses which ones to activate.
Module Step: This is the beating heart of the
Module Engine. This is the function that the
main loop of the frame calls at every time step. The
Module Step sequentially calls the Compute func-
tion of each activated Module. This is how each
one of the activated modules performs its real time
computation.
Module Command: An interface to send commands
to the DIMSART from the frame space is also pro-
vided in the Module Engine. A command can
be sent to the Module Engine, or to a speciﬁc
module as seen in section 3.1. By sending com-
mands to the Module Engine, the user will be
able to set the conﬁguration of the control scheme.
Some of the most representative commands are the
activation and deactivation of a module, the reset
of a module, or the initialization or the close of the
DIMSART.
Frame Communication: The hardware driver or a
user space (the frame) communicates with the Data
Base in a similar way as the modules do. These
communication mechanisms are also provided in
the Module Engine.
3.4
The Frame
The frame, as indicated in section 2.2, is a space
which joins elements belonging to the hardware de-
vice communication, to the network communication,
and to the DIMSART architecture. The main func-
tions of a frame are outlined here.
- Initialization of the hardware device.
- Initialization of the DIMSART.
- Interaction with the Data Base.
- Call of the Module Step (see sec. 3.3) in every
time step.
- Close the DIMSART.
- Close the hardware device.
The initialization of the DIMSART needs to know
the device characteristics. This is done through the
Device Descriptor (deﬁned in the frame), in which
the following data is enclosed: number of degrees of
freedom of the device; input data types needed by
the frame, which is the data to be commanded to the
device; and output data types, which is the data to be
processed by the active modules in the DIMSART.
The interaction with the Data Base is the read and
write mechanisms for the frame. Two ”external” func-
tions are provided for this purpose. To review the
above concepts, the following code corresponding to
the example presented in section 2.1, shows how a de-
vice driver with a DIMSART embedded should look
like.
init_funct(DevDescr){
dev_open(&Phantom);
dev_init(&Phantom);
initModLib(&DevDescr); /*ini DataBase*/
initModules(&initarg); /*ini all mods*/
cmd.ModNr=MOD_ENGINE;
cmd.ParamNr=MOD_ON;
206
J. Artigas et al. 
side.

cmd.Value=PDctrl;
ModuleCmd(&cmd); /*Activates PD ctlr*/
/*Other mod activations go here*/.
}
main_interrupt_thread(arg){
/* Some inis */
Read_Comm(inwaves);
Robot_read(pos);
DB_ext_write(pos,inwaves);
Module_Step(); /*compute active mods*/
DB_ext_read(force,outwaves);
Write_Comm();
Robot_Command(force);
}
DB ext write : Writes the device output data to the
Data Base (position in the example).
Module Step : function which schedules all active
modules (in the previous example the compute
function of the modules PD Controller and Wave
Transformer are called).
DB ext read : Reads the device input data from the
Data Base (desired force in the example.)
The data coming from the robot is no longer in the
driver, but instead in a data container, from which
other elements will be able to read. Thus, a software
boundary between the frame and the DIMSART is de-
ﬁned.
4
EXAMPLE
Fig.8 shows the complete scheme for the above pre-
sented Wave Variables scheme example, and table 1
its Commands conﬁguration. The system is distrib-
uted within two computers, each one running a DIM-
SART architecture. The computer governing the mas-
ter is equipped with a RTLinux OS. The slave runs
under Linux.
On the master side there is a frame
driving a PHANToM 3DoF (Massie and Salisbury,
1994) as a master device with a DIMSART conﬁgura-
tion. The communication between master and slave is
performed through UDP sockets . On the slave side, a
user frame governing a DIMSART is used to simulate
a slave robot and a virtual environment. This speciﬁc
scheme was built for testing the performance of the
Wave Variables control scheme as well as for verify-
ing the modular container approach of the DIMSART.
As it can be seen, the communication between the
two sides is performed through some dedicated mod-
ules. These two modules provide the interface be-
tween the DIMSART and the communication chan-
nel.
Table 1: Master and slave Commands conﬁguration. Dest
is destination. m&s means master and slave. MOD ON, for
instance, activates the module.
Dest.
Module
Command
Value
m&s
COMM RXMOD
CRX ADD DATA
CH2 WAVES
m&s
MOD ENG
MOD ON
COMM RXMOD
m&s
WTRANSF MOD
B PARAM
10
master
WTRANSF MOD
CONF MODE
MASTER
slave
WTRANSF MOD
CONF MODE
SLAVE
m&s
MOD ENG
MOD ON
WTRANSF MOD
master
PDCTRL MOD
K PARAM
3000
slave
PDCTRL MOD
K PARAM
5000
m&s
MOD ENG
MOD ON
PDCTRL MOD
master
TIMEDELAY MOD
TD PARAM
10
master
MOD ENG
MOD ON
TIMEDELAY MOD
m&s
COMM TXMOD
CTX ADD DATA
CH1 TD WAVES
m&s
MOD ENG
MOD ON
COMM TXMOD
m&s
MOD ENG
MATCHING CHECK
/
5
CONCLUDING REMARKS AND
REMAINING ASPECTS
The DIMSART has been presented in this pa-
per.
It provides a solution to embed a robotic or
telerobotic control scheme in a hardware device-
OS-communication channel conﬁguration. Indepen-
dence, distributed control, dynamics and ﬂexibility
are values provided to the architecture. The system
performance depends on several parameters which
may vary in every particular scheme. The number of
degrees of freedom, the number of active modules
and the length of the active modules inﬂuence the
system performance.
The system has been tested
in several robotic and telerobotic contexts and has
shown good performance.
One of them has been
presented in this paper as an example and as a tool to
describe the DIMSART architecture to the reader. A
very representative application is the ROKVISS4, a
Telepresence experiment in which a force feedback
joystick on Earth is to be controlled with the DIM-
SART architecture, and a 2 DoF robot, which will be
mounted on the ISS is also to be controlled with the
same architecture. For detailed information about the
ROKVISS experiment see (Preusche et al., 2003).
Future work for DIMSART will include several as-
pects. ”Online” module compilation and the exten-
sion of the Data Base to multiple data formats and
dimensions are issues which are already being devel-
oped.
Future lines could extend the DIMSART to
high level control and multi-thread architectures.
4Robotic Component Veriﬁcation on the International
Space Station (ISS)
207
DIMSART

DataBase
FORCE POS DataBase
CH1_WAVES
CH1_TD_WAVES
CH2_WAVES
CH1_TD_WAVES
TIMEDELAY
CommTXMod
CommRXMod
CH2_WAVES
CommRXMod
CH1_WAVES
CommTXMod
DEVICE FRAME
USER FRAME
u wave
v wave
(Comm channel)
Master Side (RTLinux)
Slave Side (Linux)
PDCTRL
WTRANSF
CH1_WAVE, POS
POS
CH1_WAVE, FORCE
POS
VIRTUAL WALL
ROBOTSIM
PDCTRL
POS, DES_POS
POS, CH2_WAVES
CH1_WAVES, DES_POS
WTRANSF
DES_FORCE, FORCE
FORCE
DES_FORCE
POS
POS, CH2_WAVES
DIMSART: WAVE VARIABLES SCHEME
artigas 30/10/03
REFERENCES
Albu, J., Lumia, R., and McCain, H. (1988). Hierarchical
control of intelligent machines applied to space station
telerobots. Transactions on Aerospace and Electronic
Systems, 24(24):535–541.
Artigas, J. (2003).
Development and implementation of
bilateral control using the wave variables therory in
the rokviss experiment.
Internal publication, DLR
(German Aerospace Center) - Insitute of Robotics and
Mechatronics.
Borrelly, J.-J., ´Eve Coste-Mani`ere, Espiau, B., Kapellos, K.,
Pissard-Gibollet, R., Simon, D., and Turro, N. (1998).
The orccad architecture. The International Journal of
Brooks, R. A. (1986). A robust layered control system for a
mobile robot. IEEE Journal of Robotics and Automa-
tion, 2(1):14–23.
Number 0-59600-008-1.
`Eve Coste-Mani`ere and Redi Simmons (2000). Architec-
ture, the backbone of robotic systems. In Proceedings
of the 2000 IEEE International Conference on Robot-
ics and Automation, San Francisco, CA.
Massie, T. and Salisbury, J. (1994). The phantom haptic in-
terface: A device for probing virtual objects. In Pro-
ceedings of the ASME International Mechanical En-
gineering Congress and Exhibition, pages 295–302,
Chicago.
Niemeyer, G. (1996). Using Wave Variables in Time De-
layed force Reﬂecting Teleoperation.
PhD thesis,
Massachussetts Institute of Technology.
Preusche, C., Reintsema, D., Landzettel, K., and Hirzinger,
G. (2003). Rokviss - towards telepresence control in
advanced space missions. In Humanoids 2003 - The
Third IEEE International Conference on Humanoid
Robots, Munich, Karlsruhe (Germany).
RTI (2004). Constellation. www.rti.com/products/ constel-
lation/index.html.
Schneider, S. A., Chen, V. W., Pardo-Castellote, G.,
and Wang, H. H. (1998).
Controlshell:
A soft-
ware architecture for complex electromechanical sys-
tems. The International Journal of Robotics Research,
17(4):360–380.
Scholl, K.-U. (2001). MCA2 (Modular Controller Architec-
ture). Software platform. http://mca2.sourceforge.net.
Stasse, O. and Kuniyoshi, Y. (2000). Predn: Achieving efﬁ-
ciency and code re-usability in a programming system
for complex robotic applications. In Proceedings of
the 2000 IEEE International Conference on Robotics
and Automation, San Francisco, CA.
Volpe, R., Nesnas, I., Estlin, T., Mutz, D., Petras, R., and
Das, H. (2001). The claraty architecture for robotic
autonomy. In 2001 Aerospace Conference IEEE Pro-
ceedings, pages 1/121–1/132.
208
J. Artigas et al. 
Figure 8: A real bilateral DIMSART setup.
Corbet, A. R.J. (2001). Linux Device Drivers, 2nd Edition.
Robotics Research, 17(4): 338–359.

PART 3 
Signal Processing,
Systems Modeling and Control 

ON MODELING AND CONTROL OF DISCRETE TIMED EVENT
GRAPHS WITH MULTIPLIERS USING (MIN, +) ALGEBRA
Jean-
´
LIS
62 avenue Notre Dame du Lac - Angers, France
Keywords:
Discrete timed event graphs with multipliers, timed weighted marked graphs, dioid, (min, +) algebra, Resid-
uation, just-in-time control.
Abstract:
Timed event graphs with multipliers, also called timed weighted marked graphs, constitute a subclass of Petri
nets well adapted to model discrete event systems involving synchronization and saturation phenomena. Their
dynamic behaviors can be modeled by using a particular algebra of operators. A just in time control method
of these graphs based on Residuation theory is proposed.
1
INTRODUCTION
Petri nets are widely used to model and analyze
discrete-event systems.
We consider in this paper
timed event graphs1 with multipliers (TEGM’s). Such
graphs are well adapted for modeling synchronization
and saturation phenomena. The use of multipliers as-
sociated with arcs is natural to model a large num-
ber of systems, for example when the achievement
of a speciﬁc task requires several units of a same re-
source, or when an assembly operation requires sev-
eral units of a same part.
Note that TEGM’s can
not be easily transformed into (ordinary) TEG’s. It
turns out that the proposed transformation methods
suppose that graphs are strongly connected under par-
ticular server semantics hypothesis (single server in
(Munier, 1993), or inﬁnite server in (Nakamura and
Silva, 1999)) and lead to a duplication of transitions
and places.
This paper deals with just in time control, i.e., ﬁre
input transitions at the latest so that the ﬁrings of out-
put transitions occur at the latest before the desired
ones. In a production context, such a control input
minimizes the work in process while satisfying the
customer demand. To our knowledge, works on this
tracking problem only concern timed event graphs
without multipliers (Baccelli et al., 1992, §5.6), (Co-
hen et al., 1989), (Cottenceau et al., 2001).
1Petri nets for which each place has exactly one up-
stream and one downstream transition.
TEGM’s can be handled in a particular algebraic
structure, called dioid, in order to do analogies with
conventional system theory. More precisely, we use
an algebra of operators mainly inspired by (Cohen
et al., 1998a), (Cohen et al., 1998b), and deﬁned
on a set of operators endowed with pointwise min-
imum operation as addition and composition opera-
tion as multiplication.
The presence of multipliers
in the graphs implies the presence of inferior integer
parts in order to preserve integrity of discrete vari-
ables used in the models.
Moreover, the resulting
models are non linear which prevents from using a
classical transfer approach to obtain the just in time
control law of TEGM’s. As alternative, we propose a
control method based on ”backward” equations.
The paper is organized as follows. A description of
TEGM’s by using recurrent equations is proposed in
Section 2. An algebra of operators, inspired by (Co-
hen et al., 1998a), (Cohen et al., 1998b), is introduced
in Section 3 to model these graphs by using a state
representation. In addition to operators γ, δ usually
used to model discrete timed event graphs (without
multipliers), we add the operator µ to allow multi-
pliers on arcs. The just in time control method of
TEGM’s is proposed in Section 4 and is mainly based
on Residuation theory (Blyth and Janowitz, 1972).
After recalling basic elements of this theory, we recall
the residuals of operators γ, δ, and give the residual of
operator µ which involves using the superior integer
part. The just in time control is expressed as the great-
Samir Hamaci
Louis Boimond
Email: [hamaci, boimond,lahaye]@istia.univ-angers.fr,
Sebastien Lahaye
211
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 211–216. 

est solution of a system of ”backward” equations. We
give a short example before concluding.
2
RECURRENT EQUATIONS OF
TEGM’s
We assume the reader is familiar with the structure,
ﬁring rules, and basic properties of Petri nets, see
(Murata, 1989) for details.
Consider a TEGM deﬁned as a valued bipartite
graph given by a ﬁve-tuple (P, T, M, m, τ) in which:
- P represents the ﬁnite set of places, T represents
the ﬁnite set of transitions;
- a multiplier M is associated with each arc. Given
q ∈T and p ∈P, the multiplier Mpq (respectively,
Mqp) speciﬁes the weight (in N) of the arc from tran-
sition q to place p (respectively, from place p to tran-
sition q) (a zero value for M codes an absence of arc);
- with each place is associated an initial marking
(mp assigns an initial number of tokens (in N) in place
p) and a holding time (τp gives the minimal time a
token must spend in place p before it can contribute
to the enabling of its downstream transitions).
We denote by •q (resp. q•) the set of places up-
stream (resp.
downstream) transition q. Similarly,
•p (resp. p•) denotes the set of transitions upstream
(resp. downstream) place p.
In the following, we assume that TEGM’s func-
tion according to the earliest ﬁring rule: a transition
q ﬁres as soon as all its upstream places {p ∈•q}
contain enough tokens (Mqp) having spent at least τp
units of time in place p (by convention, the tokens
of the initial marking are present since time −∞, so
that they are immediately available at time 0). When
the transition q ﬁres, it consumes Mqp tokens in each
upstream place p and produces Mp′q tokens in each
downstream place p′ ∈q•.
Remark 1 We disregard without loss of generality
ﬁring times associated with transitions of a discrete
event graph because they can always be transformed
into holding times on places (Baccelli et al., 1992,
§2.5).
Deﬁnition 1 (Counter variable) With each transi-
tion is associated a counter variable: xq is an increas-
ing map from Z to Z ∪{±∞}, t →xq(t) which de-
notes the cumulated number of ﬁrings of transition q
up to time t.
Assertion 1 The counter variables of a TEGM (under
the earliest ﬁring rule) satisfy the following transition
to transition equation:
xq(t) =
min
p∈•q, q′∈•p⌊M −1
qp (mp + Mpq′xq′(t −τp))⌋.
(1)
Note the presence of inferior integer part to pre-
serve integrity of Eq. (1). In general, a transition q
may have several upstream transitions ({q′ ∈••q})
which implies that its associated counter variable is
given by the min of transition to transition equations
obtained for each upstream transition.
Example 1 The counter variable associated with
transition q described in Fig. 1 satisﬁes the follow-
ing equation:
xq(t) = ⌊a−1(m + b xq′(t −τ))⌋.










Figure 1: A simple TEGM.
Example 2 Let us consider TEGM depicted in Fig.
2.
The corresponding counter variables satisfy the
following equations:









x1(t)
= min(3 + x3(t −2), u(t)),
x2(t)
= min(⌊2x1(t−2)
3
⌋, ⌊6+2x3(t−2)
3
⌋),
x3(t)
= 3x2(t −1),
y(t)
= x2(t).
















Figure 2: A TEGM.
3
DIOID, OPERATORIAL
REPRESENTATION
Let us brieﬂy deﬁne dioid and algebraic tools needed
to handle the dynamics of TEGM’s, see (Baccelli
et al., 1992) for details.
Deﬁnition 2 (Dioid) A dioid (D, ⊕, ⊗) is a semiring
in which the addition ⊕is idempotent (∀a, a ⊕a =
a). Neutral elements of ⊕and ⊗are denoted ε and e
respectively.
212
S. Hamaci, J.-L. Boimond and S. Lahaye 

A dioid is commutative when the product ⊗is com-
mutative. Symbol ⊗is often omitted.
Due to idempotency of ⊕, a dioid can be endowed
with a natural order relation deﬁned by a ⪯b ⇔b =
a⊕b (the least upper bound of {a,b} is equal to a⊕b).
A dioid D is complete if every subset A of D admits
a least upper bound denoted 
x∈A x, and if ⊗left
and right distributes over inﬁnite sums.
The greatest element noted ⊤of a complete dioid
D is equal to 
x∈D x. The greatest lower bound of
every subset X of a complete dioid always exists and
is noted 
x∈X x.
Example 3 • The set Z∪{±∞}, endowed with min
as ⊕and usual addition as ⊗, is a complete dioid
noted Zmin with neutral elements ε = +∞, e = 0
and ⊤= −∞.
• Starting from a
’
scalar’ dioid D, let us consider p×
p matrices with entries in D. The sum and product
of matrices are deﬁned conventionally after the sum
and product of scalars in D:
(A⊕B)ij = Aij⊕Bij and (A⊗B)ij =
p
k=1
Aik⊗Bkj.
The set of square matrices endowed with these two
operations is also a dioid denoted D p×p.
Counter variables associated with transitions are
also called signals by analogy with conventional sys-
tem theory. The set of signal is endowed with a kind
of module structure, called min-plus semimodule; the
two associated operations are:
• pointwise minimum of time functions to add sig-
nals:
∀t, (u ⊕v)(t) = u(t) ⊕v(t) = min(u(t), v(t));
• addition of a constant (∈Zmin) to play the role of
external product of a signal by a scalar:
∀t, ∀λ ∈Z∪{±∞}, (λ.u)(t) = λ⊗u(t) = λ+u(t).
A modeling method based on operators is used in
(Cohen et al., 1998a), (Cohen et al., 1998b), a similar
approach is proposed here to model TEGM’s. Let us
recall the deﬁnition of operator.
Deﬁnition 3 (Operator, linear operator) An opera-
tor is a map from the set of signals to the set of sig-
nals. An operator H is linear if it preserves the min-
plus semimodule structure, i.e., for all signals u, v and
constant λ,
H(u ⊕v) = H(u) ⊕H(v) (additive property),
H(λ ⊗u) = λ ⊗H(u) (homogeneity property).
Let us introduce operators γ, δ, µ which are central
for the modeling of TEGM’s:
1. Operator γν represents a shift of ν units in
counting (ν
∈Z ∪{±∞}) and is deﬁned as
γνx(t) = x(t) + ν. It veriﬁes the following rela-
tions:

γν ⊕γν′ = γmin(ν, ν′),
γν ⊗γν′ = γν+ν′.
2. Operator δτ
represents a shift of τ units in
dating (τ
∈
Z ∪{±∞}) and is deﬁned as
δτx(t) = x(t −τ). It veriﬁes the following rela-
tions:

δτ ⊕δτ ′ = δmax(τ, τ ′),
δτ ⊗δτ ′ = δτ+τ ′.
3. Operator µr represents a scaling of factor r and is
deﬁned as µrx(t) = ⌊r × x(t)⌋in which r ∈Q+
(r is equal to a ratio of elements in N). It veriﬁes
the following relation: µr ⊕µr′ = µmin(r, r′). Note
that µr ⊗µr′ can be different from µ(r×r′).
See Fig.3.a-3.c for a graphical interpretation of op-
erators γ, δ, µ respectively.
We note that operators
γ, δ are linear while operator µ is only additive. We
have the following properties:
1. γνδτ = δτγν, µrδτ = δτµr (commutative proper-
ties),
2. Let a, b ∈N, we have µa−1µb = µ(a−1b).
Let us introduce dioid Dmin[[δ]]. First, we denote
by Dmin the (noncommutative) dioid of ﬁnite sums
of operators {µr, γν} endowed with pointwise min
(⊕) and composition (⊗) operations, with neutral ele-
ments ε = µ+∞γ+∞and e = µ1γ0. Thus, an ele-
ment in Dmin is a map p = k
i=1 µriγνi such that
∀t ∈Z, p (x(t)) = min
1≤i≤k(⌊ri(νi + x(t))⌋).
Operator δ is considered separately from the other
operators in order to allow the deﬁnition of a dioid of
formal power series. With each value of time delay τ
(i.e., with each operator δτ) is associated an element
of Dmin. More formally, we deﬁne a map
g : Z →Dmin, τ →g(τ) in which
g(τ) = kτ
i=1 µrτ
i γντ
i .
Such an application can be represented by a formal
power series in the indeterminate δ. Let the series
G(δ) associated with map g deﬁned by:
G(δ) =

τ∈Z
g(τ) δτ.
The set of these formal power series endowed with
the two following operations:
F(δ) ⊕G(δ) : (f ⊕g)(τ)
=
f(τ) ⊕g(τ)
=
min(f(τ), g(τ)),
F(δ) ⊗G(δ) : (f ⊗g)(τ)
=

i∈Z
f(i) ⊗g(τ −i)
=
inf
i∈Z(f(i) + g(τ −i)),
is a dioid noted Dmin[[δ]] with neutral elements
ε = µ+∞γ+∞δ−∞and e = µ1γ0δ0.
213
On Modeling and Control of Discrete Timed Event Graphs

Elements of Dmin[[δ]] allow modeling the transfer
between two transitions of a TEGM. A signal x can
be also represented by a formal series of Dmin[[δ]]
(X(δ) = 
τ∈Z x(τ) δτ), simply due to the fact
that it is also equal to x ⊗e (by deﬁnition of neu-
tral element e of Dmin). For example, the graph de-
picted in Fig. 1 is represented by equation Xq(δ) =
µa−1γmδτµbXq′(δ) where Xq(δ) and Xq′(δ) denote
elements of Dmin[[δ]] associated with transitions q and
q′ respectively.
  
  
  




   


Figure 3: Graphs corresponding to operators γ, δ, µ.
In the following, matrices or scalars with elements
in dioid Dmin[[δ]] are denoted by upper case letters,
i.e., X is a shorter notation for X(δ).
Let us extend the product notation to compose ma-
trices of operators with vectors of signals (with com-
patible dimensions). Given a matrix of operators A
and a vector of signals X with elements in Dmin[[δ]],
we set (AX)i
def
= 
jAij(Xj).
Assertion 2 The counter variables of a TEGM satisfy
the following state equations:
	 X
=
AX ⊕BU,
Y
=
CX ⊕DU,
(2)
in which state X, input U and output Y vectors are
composed of signals, entries of matrices A, B, C, D
belong to dioid Dmin[[δ]].
Example 4 TEGM depicted in Fig.
2 admits the
following state equations:






































X1
X2
X3




=






ε
ε
γ3 δ2
µ1/3 δ2µ2
ε
µ1/3 γ6 δ2µ2
ε
δµ3
ε











X1
X2
X3




⊕





e
ε
ε




U,
Y
=
ε
e
ε





X1
X2
X3




⊕εU.
(3)
4
JUST IN TIME CONTROL
4.1
Residuation Theory
Laws ⊕and ⊗of a dioid are not reversible in general.
Nevertheless Residuation is a general notion in lat-
tice theory which allows deﬁning ”pseudo-inverses”
of some isotone maps (f is isotone if a ⪯b ⇒f(a) ⪯
f(b)). Let us recall some basic results on this theory,
see (Blyth and Janowitz, 1972) for details.
Deﬁnition 4 (Residual of map) An isotone map f :
D →C in which D and C are ordered sets is residu-
ated if there exists an isotone map h : C →D such
that f ◦h ⪯IdC and h ◦f ⪰IdD (IdC and IdD are
identity maps on C and D respectively). Map h, also
noted f ♯, is unique and is called the residual of map
f.
If f is residuated then ∀y ∈C, the least upper
bound of subset {x ∈D | f(x) ⪯y} exists and
belongs to this subset. This greatest ”subsolution” is
equal to f ♯(y).
Let D be a complete dioid and consider the isotone
map La : x →a ⊗x from D into D. The greatest
solution to inequation a ⊗x ⪯b exists and is equal to
L♯
a(b), also noted
b
a . Some results related to this map
and used later on are given in the following proposi-
tion.
Proposition 1 ((Baccelli et al., 1992, §4.4, 4.5.4,
4.6))
Let maps La : D →D, x →a ⊗x and Lb : D →
D, x →b ⊗x.
1. ∀a, b, x ∈D,
L♯
ab(x) = (La ◦Lb)♯(x) = (L♯
b ◦L♯
a)(x).
More generally, if maps f : D →C and g : C →B
are residuated, then g ◦f is also residuated and
(g ◦f)♯= f ♯◦g♯.
2. ∀a, x ∈D, x ⪰a x ⇔x ⪯
x
a .
3. Let A ∈D n×p, B ∈D n×q,
B
A ∈D p×q
and ( B
A )ij = ∧n
l=1
Blj
Ali , 1 ≤i ≤p, 1 ≤j ≤q.
Proposition 2 The residuals of operators γ, δ, µ are
given by:
γν♯: {x(t)}t∈Z →{x(t) −ν}t∈Z in which ν ∈Z ∪
{+∞},
δτ ♯: {x(t)}t∈Z →{x(t + τ)}t∈Z in which τ ∈Z,
µ♯
r : {x(t)}t∈Z →{⌈1
r × x(t)⌉}t∈Z in which r ∈
Q+ (⌈α⌉stands for the superior integer part of real
number α).
Proof
Expressions of residuals of operators γ, δ are classical
(Baccelli et al., 1992, Chap.
4), (Menguy, 1997,
Chap. 4).
214
S. Hamaci, J.-L. Boimond and S. Lahaye 

Relatively to residuation of operator µ, let us express
that µr = Pµ′
rI in which
I : (Z ∪{±∞})Z →(R ∪{±∞})Z,
{x(t)}t∈Z →{x(t)}t∈Z,
µ′
r : (R ∪{±∞})Z →(R ∪{±∞})Z,
{x(t)}t∈Z →{r × x(t)}t∈Z
and P : (R ∪{±∞})Z →(Z ∪{±∞})Z,
{x(t)}t∈Z →{⌊x(t)⌋}t∈Z.
Operator I is residuated, its residual is deﬁned by
I♯: (R ∪{±∞})Z →(Z ∪{±∞})Z,
{x(t)}t∈Z →{⌈x(t)⌉}t∈Z.
Operator P is residuated, its residual is deﬁned by
P ♯: (Z ∪{±∞})Z →(R ∪{±∞})Z,
{x(t)}t∈Z →{x(t)}t∈Z, we have P ♯= I.
Residuations of I and P are proven directly from
Def. 4. Indeed I, P, I♯and P ♯are isotone, moreover,
∀t ∈Z,
∀x ∈(R ∪{±∞})Z, I I♯(x(t)) = I(⌈x(t)⌉) ⪯x(t)
and ∀x ∈(Z ∪{±∞})Z, I♯I(x(t)) = ⌈x(t)⌉= x(t);
∀x ∈(Z ∪{±∞})Z, PP ♯(x(t)) = PI(x(t)) =
⌊x(t)⌋= x(t) and ∀x ∈(R∪{±∞})Z, P ♯P(x(t)) =
IP(x(t)) = ⌊x(t)⌋⪰x(t).
Residual of operator µ′ is classical, it is deﬁned by
µ′
r
♯: (R ∪{±∞})Z →(R ∪{±∞})Z,
{x(t)}t∈Z
→
{ 1
r × x(t)}t∈Z. Hence, we can
deduce the residuation of operator µ. We have
µ♯
r = (Pµ′
rI)♯= I♯µ′
r
♯P ♯thanks to Prop. 1.1, i.e.,
∀x ∈(Z ∪{±∞})Z, µ♯
rx(t) = ⌈µ′
r
♯I(x(t))⌉=
⌈1
r × x(t)⌉.
4.2
Control Problem Statement
Let us consider a TEGM described by Eqs. (2). The
just in time control consists in ﬁring input transitions
(u) at the latest so that the ﬁrings of output transitions
(y) occur at the latest before the desired ones. Let us
deﬁne reference input z as the counter of the desired
outputs: zi(t) = n means that the ﬁring numbered
n of the output transition yi is desired at the latest at
time t. More formally, the just in time control noted
uopt is the greatest solution (with respect to the order
relation ⪯) to Eqs. (2) such that y ⪯z (with respect
to the usual order relation ≤, uopt is the lowest control
such that y ≥z).
Its expression is deduced from the following result
based on Residuation theory.
Proposition 3 Control uopt of TEGM described by
Eqs. (2) is the greatest solution (with respect to the
order relation ⪯) to the following equations:
ξ
=
ξ
A ∧
Z
C ,
U
=
ξ
B ∧
Z
D .
ξ is the greatest solution of the ﬁrst equation and
corresponds to the latest ﬁrings of state transition X
(ξ ⪰X).
Proof We deduce from Eqs. (2) that state X and
output Y are such that
X
⪰AX
(i)
X
⪰BU
(2i) and
Y
⪰CX
Y
⪰DU . Moreover, we look for control U such
that Y
⪯Z which leads to
Z
⪰CX
(3i)
Z
⪰DU
(4i) .
The greatest solution to Eq.
(3i) is equal to
Z
C .
Hence we deduce thanks to Prop. 1.2 that the greatest
solution noted ξ verifying Eqs. (i) and (3i) is equal
to ξ =
ξ
A ∧
Z
C (sizes of ξ and X are equal). So
the greatest solution verifying Eqs. (2i) and (4i) (in
which ξ replaces X) is equal to
ξ
B ∧
Z
D .
For example let us consider the TEGM depicted in
Fig. 2 and modeled by Eqs. (3). Let us give the ex-
pression of the just in time control, which leads to cal-
culating the greatest solution of the following equa-
tions:
























ξ1
ξ2
ξ3





=







ξ2
µ(1/3)δ2µ2
ξ3
δµ3 ∧Z
ξ1
γ3δ2 ∧
ξ2
µ(1/3)γ6δ2µ2







,
U
=
ξ1.
Let us express these equations in usual counter set-
ting. The recursive equations are backwards in time
numbering and are supposed to start at some ﬁnite
time, noted tf, which means that system is only con-
trolled until this time. So let us consider the following
”
initial conditions”:
z(t) = z(tf) and ξ(t) = ξ(tf), ∀t > tf.
For all t ∈Z , we have:






















ξ1(t)
ξ2(t)
ξ3(t)





=





⌈3/2 × ξ2(t + 2)⌉
max(⌈1/3 × ξ3(t + 1)⌉, z(t))
max(ξ1(t + 2) −3, ⌈3/2 × ξ2(t + 2) −3⌉)




,
u(t)
=
ξ1(t).
Reference input z and output y are represented in
Fig.4, z is such that z(t) = z(tf), ∀t > tf = 15.
Control u is represented in Fig.5 and is as late as pos-
sible so that desired behavior of output transition is
satisﬁed (y ⪯z). Moreover, control u is such that
components of ξ are greater than or equal to those of
x (x ⪯ξ).
5
CONCLUSION
Most works on dioid deal with discrete timed event
graphs without multipliers. We aim at showing here
215
On Modeling and Control of Discrete Timed Event Graphs

the efﬁciency of dioid theory to also just in time con-
trol TEGM’s without additional difﬁculties. The pro-
posed method is mainly based on Residuation the-
ory and the control is the greatest solution of
”
back-
ward” equations.
A possible development of this
work would consist in considering hybrid systems or
more complex control objectives.













Figure 4: Output y (thin line) and reference input z (dotted
line).














Figure 5: Control u.
REFERENCES
Baccelli, F.,Cohen, G., Olsder, G., and Quadrat, J.-P.
(1992). Synchronization and Linearity:
n
lgebra
for Discrete
vent Systems. Wiley.
Blyth, T. and Janowitz, M. (1972).
”
esiduation Theory”.
Pergamon Press, Oxford.
Cohen, G., Gaubert, S., and Quadrat, J.-P. (1998a).
”
l-
gebraic System nalysis of Timed Petri Nets”. pages
145-170, In: Idempotency,J. Gunawardena Ed., Col-
lection of the Isaac Newton Institute, Cambridge Uni-
versity Press. ISBN 0-521-55344-X.
Cohen, G., Gaubert, S., and Quadrat, J.-P. (1998b). Timed-
Event Graphs with Multipliers and Homogeneous
Min-Plus Systems” . I T C, 43(9):1296–1302.
Cohen, G., Moller, P., Quadrat, J.-P., and Viot, M. (1989).
”
Algebraic Tools for the Performance Evaluation
of Discrete Event Systems” .
I
Proceedings,
58.
Cottenceau, B., Hardouin, L., Boimond, J.-L., and Ferrier,
J.-L. (2001).
”
Model Reference Control for Timed
Event Graphs in Dioids” . utomatica, 37:1451 1458.
Menguy, E. (1997).
”
Contribution `a la commande des
syst`emes lin´eaires dans les dio¨ıdes”. PhD thesis, Uni-
versit´e d Angers, Angers, France.
Munier, A. (1993).
R´egime asymptotique optimal d’un
graphe d’´ev´enements temporis´e g´en´eralis´e : Applica-
tion `a un probl`eme d’assemblage.
In
IPO- PII,
volume 27(5), pages 487 513.
Murata, T. (1989).
”
Petri Nets: Properties, Analysis and
Applications” . I
Proceedings, 77(4):541–580.
Nakamura, M. and Silva, M. (1999). Cycle Time Compu-
tation in Deterministically Timed Weighted Marked
Graphs. In
I
- T , pages 1037 1046.
216
S. Hamaci, J.-L. Boimond and S. Lahaye 
”
77(1):39–
–
’
–
–

MODEL PREDICTIVE CONTROL FOR HYBRID SYSTEMS 
UNDER A STATE PARTITION BASED MLD APPROACH 
(SPMLD)
Jean Thomas, Didier Dumur 
Supélec, F 91192 Gif sur Yvette cedex, France 
  Phone : +33 (0)1 69 85 13 75 
Email: jean.thomas@supelec.fr, didier.dumur@supelec.fr
Jean Buisson, Herve Guéguen 
Supélec, F 35 511 Cesson-Sévigné cedex, France      Phone : +33 (0)2 99 84 45 43 
Email: jean.buisson@supelec.fr, herve.gueguen@supelec.fr 
Keywords: 
Hybrid dynamical systems, Mixed Logical Dynamical systems (MLD), Piecewise Affine systems (PWA), 
Model Predictive Control (MPC) 
Abstract 
This paper presents the State Partition based Mixed Logical Dynamical (SPMLD) formalism as a new 
modeling technique for a class of discrete-time hybrid systems, where the system is defined by different 
modes with continuous and logical control inputs and state variables, each model subject to linear 
constraints. The reformulation of the predictive strategy for hybrid systems under the SPMLD approach is 
then developed. This technique enables to considerably reduce the computation time (with respect to the 
classical MPC approaches for PWA and MLD models), as a positive feature for real time implementation. 
This strategy is applied in simulation to the control of a three tanks benchmark. 
1 INTRODUCTION 
Hybrid systems become an attractive field of 
research for engineers as it appears in many control 
applications in industry. They include both continu-
ous and discrete variables, discrete variables coming 
from parts described by logic such as for example 
on/off switches or valves. Various approaches have 
been proposed for modeling hybrid systems (Brani-
cky et al., 1998), like Automata, Petri nets, Linear 
Complementary (LC), Piecewise Affine (PWA) 
(Sontag, 1981), Mixed Logical Dynamical (MLD) 
models (Bemporad, and Morari, 1999). 
This paper examines a class of discrete-time 
hybrid systems, which consists of several models 
with different dynamics according to the feasible 
state space partition. Each model is described with 
continuous and logical states and control inputs. 
Consequently, the dynamic of the system depends 
on the model selected in relation to linear constraints 
over the states and on the inputs values. 
On the other hand, model predictive control 
(MPC) appears to be an efficient strategy to control 
hybrid systems. Considering the previous particular 
class of hybrid systems, implementing MPC leads to 
a problem including at each prediction step the states 
and inputs vectors (both continuous and discrete
variables), the dynamic equation and linear 
constraints, for which a quadratic cost function has 
to be optimized. Two classical approaches exist for 
solving this optimization problem. 
First, all possible logical combinations can be 
studied at each prediction time, which leads solving 
a great number of QPs. Each of these QPs is related 
to a particular scenario of logical inputs and modes. 
This is the PWA approach. The number of QPs can 
be reduced by reachability considerations (Pena et 
al., 2003). 
The second moves the initial problem through 
the MLD formalism to a single general model used 
at each prediction step. This MLD formalism 
introduces many auxiliary logical and continuous 
variables and linear constraints. At each prediction 
step, all the MLD model variables have to be solved 
(even if some of them are not active). However, the 
MLD transformation allows utilizing the Branch and 
Bound (B&B) technique (Fletcher and Leyffer, 
1995), reducing the number of QPs solved. 
This paper develops a technique which aims at 
implementing MPC strategy for the considered class 
of hybrid systems, as a mixed solution of the two 
classical structures presented before. It is based on a 
217
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 217–224. 

new modeling technique, called State Partition based 
MLD approach (SPMLD) formalism, combining the 
PWA and MLD models. The complexity of this 
formalism is compared to that obtained with the 
usual PWA and MLD forms, which can also model 
this class of hybrid systems as well. 
The paper is organized as follows. Section 2 
presents a short description of the PWA and MLD 
hybrid systems. General consideration about model 
predictive 
control 
(MPC) 
and 
its 
classical 
application to PWA and MLD systems are 
summarized in Section 3. Section 4 develops the 
State Partition based MLD approach (SPMLD) and 
examines the application of MPC to hybrid systems 
under this formalism. Section 5 gives an application 
of this strategy to water level control of a three tanks 
benchmark. Section 6 gives final conclusions. 
2 HYBRID SYSTEMS MODELING 
The MLD model appears as a suitable formalism for 
various classes of hybrid systems, like linear hybrid 
or constrained linear systems. It describes the sys-
tems by linear dynamic equations subject to linear 
inequalities involving real and integer variables, 
under the form (Bemporad and Morari, 1999) 
5
4
1
3
2
3
2
1
3
2
1
1
E
x
E
u
E
z
E
į
E
z
D
į
D
u
D
Cx
y
z
B
į
B
u
B
Ax
x


d




 



 

k
k
k
k
k
k
k
k
k
k
k
k
k
k
 
(1) 
where 
^ ` l
c
n
n
l
c
1,0
u


¸¸
¹
·
¨¨
©
§
 x
x
x
,
^ `
l
c
m
m
l
c
1,0
u


¸¸
¹
·
¨¨
©
§
 u
u
u
,
^ ` l
c
p
p
l
c
1,0
u


¸¸
¹
·
¨¨
©
§
 y
y
y
,
^ ` lr
1,0

į
,    
cr


z
are respectively the vectors of continuous and binary 
states of the system, of continuous and binary 
(on/off) control inputs, of output signals, of auxiliary 
binary and continuous variables. 
Discrete/ Digital 
Continuous dynamic 
system 
D/A 
A/D 
0
else
1
if
 
 
d
G
G
b
ax
2
2
1
1
else
1
if
b
x
a
z
b
x
a
z

 

 
 
G
The auxiliary variables are introduced when 
translating propositional logic into linear inequalities 
as described in Figure 1. All matrices appearing in 
(1) can be obtained through the specification 
language HYSDEL (Hybrid System Description 
Language), see (Torrisi et al., 2000). 
Another framework for discrete time hybrid systems 
is the PWA model (Sontag, 1981), defined as 
°¿
°¾
½
°¯
°®
­

 


 

i
k
i
k
i
k
i
k
i
k
i
S
g
x
C
y
f
u
B
x
A
x
1
:
, for: 
i
k
k
F

»¼
º
«¬
ª
u
x
 (2) 
where ^ `s
i
i
1
 
F
 is the polyhedral partition of the state 
and input spaces (s being the number of subsystems 
within the partition). Each 
i
F  is given by 
°¿
°¾
½
°¯
°®
­
d
»¼
º
«¬
ª
»¼
º
«¬
ª
 
i
k
k
i
k
k
i
q
u
x
Q
u
x
F
 
(3) 
where 
k
k
k
y
u
x
,
,
 denote the state, input and output 
vector respectively at instant k . Each subsystem 
i
S
defined by the 7-uple 
,
,
,
,
,
,
,
i
i
i
i
i
i
i
q
Q
g
f
C
B
A

s
i
,
,2,1


 is a component of the PWA system 
(2). 


m
n
p
i
n
p
i
m
n
i
n
n
i
i

u
u
u








Q
C
B
A
,
,
,
and
i
i
i
q
g
f
,
,
 are suitable constant vectors or 
matrices, where n ,
m ,
p  are respectively the 
number of states, inputs, outputs, and 
ip  is the 
number of hyperplanes defining the i -polyhedral. In 
this formalism, a logical control input is considered 
by developing an affine model for each input value 
(1/0), defining linear inequality constraints linking 
the model with the relevant input value. 
It has been shown in (Bemporad et al., 2000), 
that MLD and PWA models are equivalent, which 
enables transformation from one model to the other. 
A MLD model can be transferred to a PWA model 
with the number of subsystems inside the polyhedral 
partition equal to all possible combination of all the 
integer variables of the MLD model (Bemporad et
al., 2000) (a technique for avoiding empty region is 
presented in (Bemporad, 2003)) 
l
l
l
r
m
n
s


 2
 
(4) 
3 MODEL PREDICTIVE CONTROL
Model predictive control (MPC) has proved to 
efficiently control a wide range of applications in 
industry, including systems with long delay times, 
non-minimum phase, unstable, multivariable and 
constrained systems. 
The main idea of predictive control is the use of 
a plant model to predict future outputs of the system. 
Based on this prediction, at each sampling period, a 
sequence of future control values is elaborated 
218
2.2 Piecewise Affine Model 
2.1 Mixed Logical Dynamical Model 
Figure 1: MLD model structure. 
J. Thomas et al.

through an on-line optimization process, which 
maximizes the tracking performance while satisfying 
constraints. Only the first value of this optimal 
sequence is applied to the plant according to the 
‘receding’ horizon strategy (Dumur and Boucher, 
1998). 
Considering the particular class of hybrid 
systems previously described, implementing MPC 
leads to a problem including at each prediction step 
the states vector, the inputs vector (both continuous 
and discrete), the dynamic equation and linear 
constraints, for which a quadratic cost function has 
to be optimized. Two classical approaches exist for 
solving this optimization problem, the Branch and 
Bound technique that can be used with the MLD 
formalism and the enumeration of all possible 
logical system combinations at each prediction time 
corresponding to all particular scenarios of logical 
inputs and modes used with the PWA formalism. 
For a MLD system of the form (1), the following 
model predictive control problem is considered. Let 
k  be the current time, 
k
x  the current state, 
)
,
(
e
e u
x
 an equilibrium pair or a reference 
trajectory value, 
N
k 
 the final time, find 


1
1




 
N
k
k
N
k
k
u
u
u

 the sequence which 
moves the state from 
k
x  to 
e
x  and minimizes 
2
/
2
/
1
2
/
2
/
1
0
2
1
5
4
3
2
1
1
)
,
(
min
Q
Q
Q
Q
Q
y
y
x
x
z
z
į
į
u
x
u
u
e
k
i
k
e
k
i
k
e
k
i
k
e
k
i
k
N
i
e
i
k
k
N
k
k
u
J
N
k
k









 






 



¦


 (5) 
subject to (1), where N  is the prediction horizon, 
e
į ,
e
z  are the auxiliary variables of the equilibrium 
point or the reference trajectory value, calculated by 
solving a MILP problem for the inequality equation 
of (1). 
k
i
k
/

x
 denotes the predicted state vector at 
time 
i
k  , obtained by applying the input sequence 
1

N
k
k
u
 to model (1) starting from the current state 
k
x  (same for the other input and output variables), 
0
' !
 
i
i
Q
Q
,
4,1
for
 
i
, and 
0
' t
 
i
i
Q
Q
, for 
5,3,2
 
i
.
The optimization procedure of (5) leads to MIQP 
problems with the following optimization vector 
T
1
1
1
]
,
,
,
,
,
,
,
,
[






 
N
k
k
N
k
k
N
k
k
z
z
į
į
u
u
Ȥ



 
(6) 
The number of binary optimization variables is 


l
l
r
m
N
L

 
. In the worst case, the maximum 
number of solved QP problems is 
 
No of QPs
1
2
1 
 

L
 
(7) 
So the main drawback of this MLD formalism 
remains the computational burden related to the 
complexity of the derived Mixed Integer Quadratic 
Programming (MIQPs) problems. Indeed MIQPs 
problems are classified as NP-complete, so that in 
the worst case, the optimization time grows expo-
nentially with the problem size, even if branch and 
bounds methods (B&B) may reduce this solution 
time (Fletcher and Leyffer, 1995). 
Considering the PWA system under the form (2), 
assuming that the current state 
k
x  is known the 
model predictive control requires solving at each 
time step (Pena et al., 2003). 
max
min
1
0
2
1
2
/
1
:
s.t.
)
,
(
min
1
u
u
u
u
w
y
x
u
u
d
d


 


 

 




¦
¦


i
k
N
i
i
k
ii
N
i
i
k
k
i
k
ii
k
N
k
k
r
q
J
N
k
k
 (8) 
where N  is the prediction horizon, 
i
k
w
 is the 
output reference, and 
k
i
k
/

y
 denotes the predicted 
output vector at time 
i
k  , obtained by applying the 
input sequence 


1
1




 
N
k
k
N
k
k
u
u
u

 to the 
system starting from the current state 
k
x .
ii
ii r
q ,
 are 
the elements of 
R
Q,
 weighting diagonal matrices. 
In order to solve this equation the model applied 
at each instant has to be determined and all potential 
sequences of subsystems 
^
`
1
1
,
,
,



 
N
k
k
k
I
I
I
I

have to be examined, where 
i
kI   is one sub-region 
among the s subsystems at prediction time i  for 
1
,
,2,1

 
N
i

. As for each model the value of the 
logical variable is fixed, the MPC problem is solved 
by a QP for each potential sequence. As the current 
state
k
x  is known, the starting region according to 
the state partition is identified. But the initial sub-
region related to the current input control is not 
known as it appears in the domain definition (3). 
Similarly, the next steps subsystems are also 
unknown, depending on the applied control 
sequence. In general, all potential sequences of 
subsystems I  have to be examined, which increases 
the computation burden. If no constraints are 
considered, the number of possible sequences for a 
prediction horizon N  is 
1

N
p s
m
, where 
p
m  is the 
number of all possible sub-regions at instant k
219
3.1 Model Predictive Control for the 
MLD Systems 
3.2 Model Predictive Control for the 
PWA Systems 
Model Predictive Control for Hybrid Systems under SPMLD

according to the input space partition. In order to 
solve the MPC problem of (8), the number of 
quadratic programming problems to be solved is 
 
No QPs 
1

 
N
p s
m
 
(9) 
4 MPC FOR STATE PARTITION 
BASED MLD (SPMLD) 
FORMALISM 
The SPMLD model is a mixed approach where in 
each region of the feasible space a simple MLD 
model is developed. Starting from the MLD model, 
the auxiliary binary variables are divided into two 
groups 
>
@T
2
1
į
į
į  
. Where 
^ ` 2
1,0
2
lr

į
 is 
chosen in order to include the G  variables that are 
not directly depending on the state variables (the 
inequalities that define G  variables are not 
depending on x ), and 
^ ` 1
1,0
1
lr

į
 depending on x .
This partition will be further justified. The SPMLD 
model is then developed by giving 
1
į  a constant 
value: for each possible combination of 
1
į  a sub-
region is defined with the corresponding 
i
i q
Q ,
constraints as in (3). As some logical combinations 
may not be feasible, the number of sub-regions of 
the polyhedral partition is 
1
2 lr
s d
 
(10) 
Consequently, this model requires a smaller number 
of sub-regions than the classical PWA model for the 
same modeled system. Each sub-region has its own 
dynamic described in the same way as (1) but with a 
simpler MLD model that represents the system 
behavior in this sub-region and includes only the 
active variables in this sub-region. This partition 
always implies a reduction in the size of z  and/or 
u . For example, some control variables may not be 
active in sub-regions and the auxiliary continuous 
variables z  depending on the 
1
į  variables may 
disappear or become fixed as 
1
į  is fixed where: 
¯
®
­
 
 
 
o
 
1
if
)
(
0
if
0
)
(
G
G
G
x
f
z
x
f
z
 
(11) 
Consequently, simplified sub-regions models can be 
derived, an example of this simplification is given in 
the application section. 
The system is thus globally modeled as 
i
k
i
k
i
k
i
k
i
k
i
k
i
k
i
k
i
k
k
i
k
i
k
i
k
i
k
5
4
1
3
2
3
2
1
3
2
1
1
E
x
E
u
E
z
E
į
E
z
D
į
D
u
D
x
C
y
z
B
į
B
u
B
x
A
x


d




 



 

 
(12) 
i
i
i
i
i
5
1
3
1
3
1
,
,
,
,



E
D
C
B
A
 are the matrices of the ith
MLD model defining the dynamics into that sub-
region. 
i
i q
Q ,
 constraints has to be included in (12). 
At this stage, the MPC technique developed for the 
PWA formalism must be rewritten to fit the new 
SPMLD model. Consider the initial subsystem 
k
I
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
z
D
į
D
u
D
x
C
y
z
B
į
B
u
B
x
A
x
3
2
1
3
2
1
1



 



 

 (13) 
with
k
k
k
k
k
k
k
k
k
į
E
E
x
E
z
E
u
E
2
5
4
3
1


d


Where 
k
A  will now denote for simplification 
purposes the 
i
A  matrix of model i  at instant k  (the 
same notations are used for 
k
k
k
k
5
1
3
1
3
1
,
,
,



E
D
C
B
). 
For a given sequence over the prediction horizon N
i.e. for 
^
`
1
1
,
,
,



 
N
k
k
k
I
I
I
I

, the system is 
recursively defined as follows 
z
G
į
P
u
H
x
F
y
z
G
į
P
u
H
x
F
x
y
y
y
k
y
x
x
x
k
x



 



 
 
(14) 
Where 
>
@ ,
T
2
1
N
k
k
k



 
x
x
x
x

>
@
>
@T
1
T
1
,




 
 
N
k
k
N
k
k
y
y
y
u
u
u


>
@
>
@T
1
T
1
,




 
 
N
k
k
N
k
k
į
į
į
z
z
z


»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 
»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 








k
N
k
N
k
k
k
k
k
N
k
k
k
k
A
A
C
A
C
C
F
A
A
A
A
A
F
y
x




2
1
1
1
1
,
»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 











1
1
1
1
2
1
1
1
1
1
1
1
1
1
0
0
0
N
k
k
k
N
k
k
k
N
k
k
k
k
k
B
B
A
A
B
A
A
B
B
A
B
H x









»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 











1
3
1
3
2
1
3
1
1
1
3
3
1
3
0
0
0
N
k
k
k
N
k
k
k
N
k
k
k
k
k
B
B
A
A
B
A
A
B
B
A
B
G x









»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 











1
2
1
2
2
1
2
1
1
1
2
2
1
2
0
0
0
N
k
k
k
N
k
k
k
N
k
k
k
k
k
B
B
A
A
B
A
A
B
B
A
B
Px









»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 















1
1
1
1
2
2
1
1
1
2
1
1
1
1
1
1
0
0
0
N
k
k
k
N
k
N
k
k
k
N
k
N
k
k
k
k
k
D
B
A
A
C
B
A
A
C
D
B
C
D
Hy









»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 















1
3
1
3
2
2
1
3
1
2
1
1
3
3
1
3
0
0
0
N
k
k
k
N
k
N
k
k
k
N
k
N
k
k
k
k
k
D
B
A
A
C
B
A
A
C
D
B
C
D
Gy









220
J. Thomas et al.
4.1 The SPMLD Formalism 
4.2 Reformulation of the MPC Solution 

»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª
 















1
2
1
2
2
2
1
2
1
2
1
1
2
2
1
2
0
0
0
N
k
k
k
N
k
N
k
k
k
N
k
N
k
k
k
k
k
D
B
A
A
C
B
A
A
C
D
B
C
D
Py









Then the MPC optimization problem (8) leads to the 
following cost function 
>
@
o
o
o
g
į
z
u
f
į
z
u
H
į
z
u
J

»
»
»
¼
º
«
«
«
¬
ª

»
»
»
¼
º
«
«
«
¬
ª
 
2
 
(15)
where 
»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª

 
y
T
y
T
y
T
y
T
y
T
y
T
y
T
y
T
y
T
o
y
y
y
y
y
y
y
y
y
P
Q
P
G
Q
P
H
Q
P
P
Q
G
G
Q
G
H
Q
G
P
Q
H
G
Q
H
R
H
Q
H
H
T
y
T
y
T
y
T
k
y
T
y
T
y
T
k
y
T
y
T
y
T
k
o
»
»
»
»
¼
º
«
«
«
«
¬
ª



 
P
Q
w
P
Q
F
x
G
Q
w
G
Q
F
x
H
Q
w
H
Q
F
x
f
]
2
[
w
Q
w
x
F
Q
w
x
F
Q
F
x
g
T
k
y
T
k
y
T
y
T
k
o


 
> @ 

>
@ 

0
,
diag
0
,
diag
 
 
T
ii
T
ii
q
r
Q
Q
Q
R
R
R
 
 
 
 
This technique allows choosing different weighting 
factors for each sub-region according to its priority. 
The constraints over the state and input domains 
for each sub-region are included in the inequality 
equation of the MLD model of that sub-region using 
the HYSDEL program. The MPC optimization 
problem (15) is solved subject to the constraints 
>
@
N
į
z
u
M
M
M
d
»
»
»
¼
º
«
«
«
¬
ª
2
3
1
 
(16) 
where 
»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª



 








1
5
2
1
4
1
5
1
4
5
4
N
k
k
k
N
k
N
k
k
k
k
k
k
k
k
E
x
A
A
E
E
x
A
E
E
x
E
N


»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª






 















1
1
1
1
2
2
1
4
1
1
2
1
4
1
1
1
1
4
1
1
0
0
0
0
N
k
k
k
N
k
N
k
k
k
N
k
N
k
k
k
k
k
E
B
A
A
E
B
A
A
E
E
B
E
E
M








»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª



 













1
2
2
2
1
4
2
1
2
1
4
1
2
2
1
4
2
2
0
0
0
0
N
k
N
k
N
k
k
k
N
k
N
k
k
k
k
k
E
B
E
B
A
A
E
E
B
E
E
M







»
»
»
»
»
¼
º
«
«
«
«
«
¬
ª



 













1
3
2
3
1
4
3
1
2
1
4
1
3
3
1
4
3
3
0
0
0
0
N
k
N
k
N
k
k
k
N
k
N
k
k
k
k
k
E
B
E
B
A
A
E
E
B
E
E
M







The number of binary optimization variables, with 
1
į  known and constant, is given by the relation 
^
`
s
j
r
m
L
N
i
i
j
l
i
lj
,
,2,1
,
1
0
2



 ¦

 
 
(17) 
Where 
i
j
l
i
lj r
m
2
,
 are the number of modeled logical 
control and 
2
į  elements respectively in the jth sub-
region at prediction time i .
Therefore, if the sequence I  is fixed, the 
problem can be solved minimizing (15) subject to 
the constraints of (16). But, as only 
kI  is known 
(where 
)
(k
x
 is considered as known, and 
)
(
1 k
į
depends on 
)
(k
x
), all possible sequences as in 
Figure 2 have to be solved. So the number of 
possible sequences is 
1

N
s
. The optimal solution is 
provided by the resolution of these 
1

N
s
 MIQPs. In 
order to find the solution more quickly, these 
problems are not solved independently and the 
optimal value of the criterion provided by the solved 
MIQP is used to bind the result of the others. It can 
then be used by the B&B algorithm to cut branches. 
>
@
,*,*
k
I
1
2
Ik
s
1
2
s
1
2
s
1
2
s
>
@
,*
,
1

k
k I
I
>
@
2
1,
,


k
k
k
I
I
I
Figure 2: State transition graph of the MPC optimization 
The global complexity of the MPC resolution with 
systems under the SPMLD form is reduced. First the 
related number of subsystems s  is smaller than that 
with the classical PWA model. Then, the B&B 
technique considerably decreases the number of 
solved QPs. The index sequence I  imposes the 
successive values of 
1
į  over the prediction horizon 
and then the succession of region on the state space 
partition the state has to reach. This leads to non 
feasible solutions in many sub-problems, effectively 
reducing the number of solved QPs according to the 
B&B technique. This is why we partition į  vector. 
First, the SPMLD technique is faster than the 
classical MLD because for a known sequence of 
index I , only 
)1
(
1
2

N
rl
 simple B&B trees with only 
z
į
u
,
,
2
 optimization variables have to be solved; 
i.e. smaller number of optimization binary variables 
L (17), and simpler MLD models as previously 
explained. Moreover, as explained, the optimization 
algorithm just has to look for the control sequence 
that could force the system to follow the index I
and optimize the cost function with respect to all the 
associated constraints. In many root nodes at level F 
(Figure 3), this leads to non-feasible solution (more 
221
4.3 Compared Computational Burden 
problem for a system under the SPMLD form ( N  3 ).
Model Predictive Control for Hybrid Systems under SPMLD

frequent than in classical MLD approach), due to 
non feasible sequence whatever the value of the 
control inputs are, thus that MIQP will then quickly 
be eliminated. Furthermore, if there is a solution for 
a B&B tree at level F, it is considered as an upper 
bound for the global optimized solution for all the 
following B&B trees, which reduces the number of 
solved QPs according to B&B technique. 
)
(k
l
u
)1
( 
k
l
u
)1
(

 N
k
l
u
>
@)1
(
)1
(
)
(
1
1
1



N
k
k
k
į
į
į

F
Then, the SPMLD technique is obviously faster than 
the classical PWA technique. First the initial index 
kI  is completely known as the space partition only 
depends on 
)
(k
x
 and not on u  (as in the PWA 
model where 
p
m  possible subsystems at instant k
have to be examined). In addition, SPMLD models 
use the B&B technique, which considerably reduces 
the number of solved QPs while in classical PWA 
systems all the QPs must be solved. 
Two different techniques can be considered to 
reduce the computation load for real time 
applications. The first one introduces the control 
horizon 
u
N , which reduces the number of unknown 
future control values, i.e. 
)
(
i
k 
u
 is constant for 
u
N
i t
. This decreases the number of binary optimi-
zation variables (17) and the optimization time 
^
`
s
j
r
m
L
N
i
i
j
l
N
i
i
lj
N
u
u
,
,2,1
,
1
0
2
1
0



 
¦
¦

 

 
(18) 
The second one, called the reach set, aims at 
determining the set of possible regions that can be 
reached from the actual region in next few sampling 
times (Kerrigan, 2000). That is, all sequences that 
cannot be obtained are not considered. 
5 APPLICATION 
The proposed control strategy is applied on the three 
tanks benchmark used in (Bemporad et al., 1999). 
The simplified physical description of the three 
tanks system proposed by COSY as a standard 
benchmark for control and fault detection problems 
is presented in Figure 4 (Dolanc et al., 1997). 
The system consists of three tanks, filled by two 
independent pumps acting on tanks 1 and 2, 
continuously manipulated from 0 up to a maximum 
flow 
1
Q  and 
2
Q  respectively. Four switching 
valves 
1
V ,
2
V ,
13
V
 and 
23
V
 control the flow 
between the tanks, those valves are assumed to be 
either completely opened or closed (
0
or
1
 
i
V
respectively). The 
3
L
V
 manual valve controls the 
nominal outflow of the middle tank. It is assumed in 
further simulations that the 
1
L
V
 and 
2
L
V
 valves are 
always closed and 
3
L
V
 is open. The liquid levels to 
be controlled are denoted 
1
h ,
2
h  and 
3
h  for each 
tank respectively. The conservation of mass in the 
tanks provides the following differential equations 
)
23
23
2
23
13
13
1
13
(
1
3
)
23
23
2
23
2
(
1
2
)
13
13
1
13
1
(
1
1
N
Q
V
Q
V
Q
V
Q
V
Q
A
h
V
Q
V
Q
Q
A
h
V
Q
V
Q
Q
A
h




 


 


 



(19) 
where the Qs denote the flows and A is the cross-
sectional area of each of the tanks. A MLD model is 
derived as developed in (Bemporad et al., 1999), 
introducing the following variables 
']
23
13
2
1
03
02
01
[
']
03
02
01
[
']
23
13
2
1
2
1
[
']
3
2
1
[
  z
  z
  z
  z
  z
  z
z
į
į
į
  V
  V
  V
  V
  Q
Q
  h
  h
h
 
 
 
 
z
į
u
x
 
(20) 
where 
>
@
>
@






2,1
)
(
)
(
2,1
)
(
)
(
)
(
3,2,1
)
(
)
(
)
(
3,2,1
)
(
1
)
(
3
3
3
03
0
0
0
0
 

 
 

 
 

 
 
t
l
 
i
h
t
h
V
t
z
i
t
z
t
z
V
t
z
i
h
t
h
t
t
z
i
h
t
h
t
i
i
i
i
i
i
v
i
i
i
v
i
i
G
G
5.2 Application of MPC for the 
In this system, 
į
į  
1
 since the three introduced 
auxiliary binary variables depend on the states, thus 
l
l
r
r
 
1
 and the number of sub-systems is 
8
2 1  
 
lr
s
 
(21) 
222
J. Thomas et al.
4.4 Further Improvements of the 
Optimization Time 
5.1 Description of the Benchmark 
Figure 3: B&B trees for optimization with SPMLD. 
Figure 4: COSY three tanks benchmark system. 
SPMLD Formalism 

Inside each sub-region, a simple MLD model is 
developed, that takes into account only the system 
dynamics in this sub-region. In some sub-regions a 
reduction in the size of u  and z  appears; for 
example in the sub-region where 
>
@
0
0
0
'
1  
į
 it 
clearly appears that the two valves 
1
V  and 
2
V  of the 
input vector are not in progress, as the liquid level in 
this region is always less than the valves level. 
Consequently, the continuous auxiliary variables 
^
`
3,2,1
0
 
i
i
z
 and ^ `
2,1
 
i
iz
 corresponding to the flows 
that pass through the upper pipes are useless. It 
results from this a simple model with: 
']
23
13
[
1
']
23
13
2
1
[
,']
3
2
1
[
  z
 z
  V
 V
  Q
Q
  h
  h
h
 
 
 
z
u
x
 
(22) 
Let us consider now the following specification: 
starting from zero levels (the three tanks being 
completely empty), the objective of the control 
strategy is to reach the liquid levels 
m
5.0
1  
h
,
m
5.0
2  
h
 and 
m
1.0
3  
h
. The MPC technique for 
a SPMLD model has been implemented in 
simulation to reach the level specification with 
2
 
N
. The results are presented on Figure 5 for the 
tanks levels and on Figure 6 for the control signals. 
10
20
30
0
0.2
0.4
0.6
0
10
20
30
0
0.2
0.4
0.6
0.8
0
10
20
30
0
0.05
0.1
0.15
0.2
0
10
20
30
0
0.2
0.4
0.6
0.8
Level of the frist tank 
Level of the third tank 
Level of the second tank 
The level of three tanks 
Sampling instants 
Sampling instants 
0
10
20
30
0
2
x 10
-4
The flow (m3/5)
0
10
20
30
0
2
x 10
-4
0
10
20
30
0
0.5
1
The valve position
1 (open) - 0 (close)
0
10
20
30
0
0.5
1
0
10
20
30
0
0.5
1
0
10
20
30
0
0.5
1
Input Q1 
Input Q2 
V1 
V2 
V13 
V23 
Sampling instants 
Sampling instants 
The level of the third tank oscillates around 0.1 as 
1.0
3  
h
 does not correspond to an equilibrium 
point. Consequently, the system opens and closes the 
two valves 
1
V  and 
2
V  to maintain the level in the 
third tank around the desired level of 0.1m. 
As a comparison purpose between the SPMLD 
model, the classical MLD model and the classical 
PWA model strategies, the same previous level 
specification has been considered with 
2
 
N
. The 
MLD model described in (Bemporad et al., 1999) 
has been used for the three tanks modeled by (20); 
this MLD model transfers to a PWA model with 
128
 
s
 subsystems (with 28 empty regions). The 
classical PWA model has not been developed as it 
needs 100 sub-models and is in fact not required to 
compare complexity. For that comparison, looking 
at the number of QPs that have to be solved during 
optimization is sufficient. 
Table 1 illustrates for 
2
 
N
the total time 
required to reach the specification level, the total 
number of QPs solved, and the maximum time and 
maximum QPs to find the optimized solution at each 
iteration. It can be seen that the difference between 
the SPMLD technique and the other classical 
techniques is quite large, the SPMLD model 
allowing real time implementation and avoiding 
exponential explosion of the algorithm (the sampling 
time of the three tanks benchmark is 10 s.). All data 
given above were obtained using the MIQP Matlab 
code (Bemporad and Mignone, 2000), on a 1.8 MHz 
PC with 256 Mo of ram. Same comparisons are 
presented with 
3
 
N
 in table 2. 
Table 1. Comparison of performances obtained with the 
SPMLD model, the classical MLD model and the classical 
PWA model for 
2
 
N
.
Approach
No of 
QPs
solved 
Max.
No. QPs 
/ step 
Total 
time 
Max.
time / 
step 
Classical 
PWA
8 800 
1 600 
* 
* 
Classical 
MLD
11 130 
2 089 
822.97 s 
138.97 s 
SPMLD 
832 
218 
15.28 s 
3.90 s 
Table 2. Comparison of performances obtained with the 
Approach
No of QPs 
solved 
Max. No.
QPs / step 
Total 
time 
Max.
time / 
step 
Classical 
PWA
880 000 
160 000 
* 
* 
Classical 
MLD
25 606 
6 867 
5243.6
s
1 147.80 
s
SPMLD 
3 738 
1 054 
137.54 s 
37.65 s 
223
5.3 Comparison of the Approaches 
Figure 5: Water levels in the three tanks. 
Figure 6: Controlled variables. 
SPMLD, MLD and PWA models for N  3.
Model Predictive Control for Hybrid Systems under SPMLD

this case. But it must be noticed that the results in 
table 1 and 2 for the SPMLD model are achieved 
without applying techniques described in section 
4.4. For example using a prediction horizon 
3
 
N
and a control horizon 
1
 
u
N
 leads to the following 
results enabling real time implementation 
No QPs solved = 1224, Max. No QPs/step = 326 
Total optimization time = 29.24 s., Max. time/step = 7.92 s.
The technique of MPC for SPMLD systems has 
been examined also with a simple automata, where 
automata of Figure 7 have been added to 
1
V  and 
2
V
valves of the three tanks benchmark. We assumed 
for a simplification purpose that 
0
03  
G
 i.e. the 
level in the third tank is always behind the hv level. 
V1
open
Wait 
V2
open
a 
b 
close 
close 
close 
a
b
The automata of Figure 7 can be presented as follows 
close
Wait
b
V
b
wait
V
a
V
a
wait
V
open
open
open
open
 
 
 
)
&
(
)
&
(
)
&
(
)
&
(
2
2
1
1
 
(23) 
The SPMLD technique succeeds to reduce the total 
optimization time to arrive to the specifications, 
from 5691.4 s for the classical MLD technique to a 
173.5 s, solving 3990 QPs instead of 60468 QPs 
where for each sequence I, į  variables as well as 
the logical control variables that control the 
automata are known. 
6 CONCLUSION 
This paper presents the SPMLD formalism. It is 
developed by partitioning the feasible region 
according to the auxiliary binary elements 
1
į  of the 
MLD model that depends on the state variables. A 
reformulation of the MPC strategy for this 
formalism has been presented. It is shown that the 
SPMLD 
model 
successfully 
improves 
the 
computational problem of the mixed Logical 
Dynamical (MLD) model and Piecewise Affine 
(PWA) model. Moreover, the partition into several 
sub-regions enables to define particular weighting 
factors according to the priority of each region. 
Future work may consider examining į  variables 
that depends on the control inputs, by partitioning 
the feasible region according to those variables also 
instead of leaving them free included in the 
optimization vector. 
REFERENCES
Bemporad, A., 2003. “A Recursive Algorithm for 
Converting Mixed Logical Dynamical Systems into an 
Equivalent Piecewise Affine Form”, IEEE Trans. 
Autom. Contr. 
Bemporad, A., Ferrari-Trecate G., and Morari M., 2000. 
Observability and controllability of piecewise affine 
and hybrid systems. IEEE Trans. Automatic Control, 
Bemporad, A., and Mignone, D., 2000.: Miqp.m: A 
Matlab function for solving mixed integer quadratic 
programs. Technical Report.
Bemporad, A., Mignone, D. and Morari, M., 1999. 
Moving horizon estimation for hybrid systems and 
fault detection. In Proceedings of the American 
Control Conference, San Diego.
Bemporad, A. and Morari, M., march 1999. Control of 
systems integrating logical, dynamics, and constraints. 
Branicky, M.S., Borkar, V.S. and Mitter, S.K., January 
1998. A unified framework for hybrid control: model 
and optimal control theory. IEEE Transaction. on 
Automatic. Control, 43(1): 31-45.
Dolanc, G., Juricic D., Rakar A., Petrovcic J. and Vrancic, 
D., 1998. Three-tank Benchmark Test. Technical 
Report Copernicus Project Report CT94-02337. 
Dumur, D. and Boucher, P.,1998. A Review Introduction 
to Linear GPC and Applications. Journal A, 39(4), 
pp. 21-35.
Fletcher, R. and Leyffer, S., 1995. Numerical experience 
with lower bounds for MIQP branch and bound. 
Technical report, Dept. of Mathematics, University of 
Dundee, Scotland.
Kerrigan, E., 2000. Robust Constraint Satisfaction: 
Invariant sets and predictive control. PhD thesis 
University of Cambridge.
systems for solving model predictive control of 
piecewise affine system. IFAC conference, Hybrid 
system analysis and design Saint Malo, France.
Sontag, E.D., April 1981: Nonlinear regulation: the 
piecewise linear approach. IEEE Transaction. on 
Torrisi, F., Bemporad, A. and Mignone, D., 2000. Hysdel 
– a tool for generating hybrid models. Technical 
report, AUT00-03, Automatic control laboratory, ETH 
Zuerich.
224
J. Thomas et al.
This table shows that no real time implementation is 
possible with 
3
 
N
 for the SPMLD form, although 
Figure 7: Added Automata to the three tanks benchmark.
45(10): 1864–1876.
Automatica, 35(3): 407-427.
Pena, M., Camacho, E. F. and Pinon, S., 2003. Hybrid 
Automatic. Control, 26(2): 346-358.
the maximum time per iteration is much smaller in 

EFFICIENT SYSTEM IDENTIFICATION FOR MODEL
PREDICTIVE CONTROL WITH THE ISIAC SOFTWARE
Paolino Tona
Institut Franc¸ais du P´etrole
1 & 4, avenue de Bois-Pr´eau, 92852 Rueil-Malmaison Cedex - France
paolino.tona@ifp.fr
Jean-Marc Bader
Axens
BP 50802 - 89, boulevard Franklin Roosevelt, 92508 Rueil-Malmaison Cedex - France
jean-marc.bader@axens.net
Keywords:
System identiﬁcation, model predictive control.
Abstract:
ISIAC (as Industrial System Identiﬁcation for Advanced Control) is a new software package geared to meet
the requirements of system identiﬁcation for model predictive control and the needs of practicing advanced
process control (APC) engineers. It has been designed to naturally lead the user through the different steps of
system identiﬁcation, from experiment planning to ready-to-use models. Each phase can be performed with
minimal user intervention and maximum speed, yet the user has every freedom to experiment with the many
options available. The underlying estimation approaches, based on high-order ARX estimation followed by
model reduction, and on subspace methods, have been selected for their capacity to treat the large dimensional
problems commonly found in system identiﬁcation for process control, and to produce fast and robust results.
Models describing parts of a larger system can be combined into a composite model describing the whole
system. This gives the user the ﬂexibility to handle complex model predictive control conﬁgurations, such as
schemes involving intermediate process variables.
1
INTRODUCTION
It is generally acknowledged that ﬁnding a dynamic
process model for control purposes is the most cum-
bersome and time-consuming step in model predic-
tive control (MPC) commissioning. This is mainly
due to special requirements of process industries that
make for difﬁcult experimental conditions, but also
to the relatively high level of expertise needed to ob-
tain empirical models through the techniques of sys-
tem identiﬁcation. The vast majority of MPC vendors
(and a few independent companies) have recognized
the need for efﬁcient system identiﬁcation and model
building tools and started providing software and fa-
cilities to ease this task.
In these pages, we present ISIAC (as Industrial
System Identiﬁcation for Advanced Control), a prod-
uct of the Institut Franc¸ais du P´etrole (IFP). This new
software package is geared to meet the requirements
of system identiﬁcation for model predictive control
and the needs of practicing advanced process control
(APC) engineers.
In section 2, we discuss the peculiarities of system
identiﬁcation for process control. Then we explain
how these peculiarities have been taken into account
in ISIAC design (section 3). Section 4 illustrates the
user workﬂow in ISIAC. Finally, section 5 presents
an example taken from an industrial MPC applica-
tion, carried out by Axens, process licensor ans ser-
vice provider for the reﬁning and petrochemical sec-
tors.
2
SYSTEM IDENTIFICATION
AND MODEL PREDICTIVE
CONTROL
With several thousands applications reported in the
literature, model predictive control (Richalet et al.,
1978; Cutler and Ramaker, 1980) technology has
been widely and successfully adopted in the process
industries, and more particularly, in the petrochemical
sector (see (Qin and Badgwell, 2003) for an overview
of modern MPC techniques).
The basic ingredients of any MPC algorithm are:
• a dynamic model, which is used to make an open-
loop prediction of process behavior over a chosen
future interval (the control model);
• an optimal control problem, which is solved at each
225
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 225–232. 

control step, via constrained optimization, to min-
imize the difference between the predicted process
response and the desired trajectory;
• a receding horizon approach (only the ﬁrst step of
the optimal control sequence is applied).
Most commonly, control models employed by in-
dustrial MPC algorithms are linear time-invariant
(LTI) models, or, in same cases, combinations of LTI
models and static nonlinearities. The vast majority
of reported industrial applications have been obtained
utilizing ﬁnite impulse response (FIR) or ﬁnite step
response (FSR) models. Modern MPC packages are
more likely to use state-space, transfer function ma-
trix, or autoregressive with exogenous input (ARX)
models. Linear models of dynamic process behav-
ior can be obtained from a linearized ﬁrst-principles
model, or more commonly, from experimental mod-
eling, applying system identiﬁcation (Ljung, 1999)
techniques to obtain black-box models from input-
output data gathered from the process. Those mod-
els can be subsequently converted to the speciﬁc form
required by the MPC algorithm.
Several researchers have pointed out that process
identiﬁcation is the most challenging and demanding
part of a MPC project ((Richalet, 1993; Ogunnaike,
1996)).
Although system identiﬁcation techniques
are basically domain independent, process industries
have special features and requirements that compli-
cate their use: slow dominant plant dynamics, large
scale units with many, strongly interacting, manipu-
lated inputs and controlled outputs, unmeasured dis-
turbances, stringent operating constraints. This makes
for difﬁcult experimental conditions, long test dura-
tions and barely informative data. But even the sub-
sequent step of performing system identiﬁcation us-
ing one of the available software packages may prove
lengthy and laborious, especially when the relatively
high level of expertise needed is not at hand.
Designing such software for efﬁciency and man-
ageability requires taking into account the peculiari-
ties of system identiﬁcation for process control.
• System identiﬁcation is a complex process involv-
ing several steps (see Fig. 1). The user should be
guided through it with a correct balance between
structure and suppleness.
• When identifying an industrial process, a signiﬁ-
cant number of data records must be dealt with.
Data may contain thousands of samples of tens
(or hundreds) measured variables. Several differ-
ent multivariable models can be identiﬁed for the
whole process, or for parts of it. It is important to
allow the user to handle multiple models and data
sets of any size, to seamlessly visualize, evaluate,
compare and combine them, to arrange and keep
track of the work done during an identiﬁcation ses-
sion.
Figure 1:
Steps of the system identiﬁcation process
• Estimation and validation methods at the heart of
the identiﬁcation process must be chosen care-
fully. When dealing with multi-input multi-output
(MIMO) models, model structure choice and para-
metrization may prove challenging even for experi-
enced users. Moreover, large data and model sizes,
utterly common in the context of system identiﬁ-
cation for process control, may easily lead to nu-
merical difﬁculties and unacceptable computation
times. Methodologies giving systematic answers
to these problems exist (Juricek et al., 1998; Zhu,
1998) and have been incorporated into some com-
mercial packages (Larimore, 2000; Zhu, 2000).
• MPC algorithms usually need more information to
deﬁne their internal control structure, than a plain
linear model. As a minimum, the user has to sort
model inputs into manipulated variables (MV) and
disturbance variables (DV), and to choose which
model outputs are to be kept as controlled vari-
ables (CV). With modern MPC packages, control
conﬁguration may become really complex, includ-
ing observers and unmeasured disturbance models,
which can be used, among other things, to take into
account the presence of intermediate variables
trolled variables) for control calculation. Without
a suitable control model building tool, supplying
the additional pieces of information turns out to be
a laborious task, even for mildly complex control
conﬁgurations.
226
P. Tona and J.-M. Bader
(adapted from (Ljung, 1999)).
i. e., measured output variables that inﬂuence con-

3
ISIAC
ISIAC is primarily meant to support the model-based
predictive multivariable controller MVAC, a part of
the APC suite developed by IFP and its afﬁliate RSI.
MVAC has ﬁrst been validated on a challenging
pilot process unit licensed by IFP (Couenne et al.,
2001), and is currently under application in several
reﬁneries world-wide. Its main features are:
• state-space formulation;
• observer to take into account unmeasured distur-
bances, intermediate variables, integrating behav-
ior;
• ranked soft and hard constraints;
• advanced speciﬁcation of trajectories (funnels, set-
ranges);
• static optimization of process variables.
Though ISIAC is intended to be the natural com-
panion tool to MVAC, it is actually ﬂexible enough
to be used as a full-ﬂedged system identiﬁcation and
model building tool or to support other APC pack-
ages.
3.1
The model estimation approaches selected for inclu-
sion in ISIAC combine accuracy and feasibility, both
in term of computational requirements and of user
choices. We have decided to favor non-iterative meth-
ods over prediction error methods (Ljung, 1999), to
avoid problems originating from a demanding mini-
mization routine and a complicated underlying para-
metrization.
3.1.1
The beneﬁts of high-order ARX estimation in indus-
trial situations have been advocated by several re-
searchers ((Zhu, 2001; Rivera and Jun, 2000)). In-
deed, using a model order high enough, and with
sufﬁciently informative data, ARX estimation yields
models that can approximate any linear system arbi-
trarily well (Ljung, 1999). Ljung’s asymptotic black-
box theory also provides (asymptotic) expressions for
the transfer function covariance which can be used for
model validation purposes.
A model reduction step is necessary to use these
models as process control models, since they usually
are over-parameterized (i.e., an unbiased model with
much lower order can be found) and have high vari-
ance (which is roughly proportional to model order).
Different schemes have been proposed ((Hsia, 1977;
Wahlberg, 1989; Zhu, 1998; Rivera and Jun, 2000;
Tj¨arnstr¨om and Ljung, 2003)) to perform model re-
duction. For a class of reduction schemes (Tj¨arnstr¨om
and Ljung, 2003), it has been demonstrated that the
reduction step actually implies variance reduction,
and a resulting variance which is nearly optimal (that
is, close to the Cramer-Rao bound).
In ISIAC, truly multi-input multi-output (MIMO)
ARX estimation is possible, using the structure
A(q)y(t)
=
B(q)u(t) + e(t)
where y(t) is the p-dimensional vector of outputs
at time t, u(t) is the m-dimensional vector of in-
puts at time t, e(t) is a p-dimensional white noise
vector, A(q) and B(q) polynomial matrices respec-
tively of dimensions p × p and p × m. For faster
results, in the two-stage method, the least-square es-
timation problem is decomposed into p multi-input
single-output (MISO) problems. The Akaike infor-
mation criterion (AIC) (Ljung, 1999) is used to ﬁnd
a “high enough” order in the ﬁrst step, and the re-
sulting model is tested for unbiasedness (whiteness
of the residuals and of the inputs-residuals cross-
correlation). To ﬁnd a reduced order model, we adopt
a frequency-weighted balanced truncation (FWBT)
technique (Varga, 1991). The calculated asymptotic
variance is used to set the weights and to automat-
ically choose the order of the reduced model, fol-
lowing an approach inspired by (Wahlberg, 1989).
The obtained model is already in the state-space form
needed by the MPC algorithm.
As a result, we get an estimation method which
is totally automated, and provides accurate results in
most practical situations, with both open-loop and
closed-loop data. Yet, this method might not work
correctly when dealing with short data sets and (very)
ill-conditioned systems.
3.1.2
The term subspace identiﬁcation methods (SIM)
refers to a class of algorithms whose main charac-
teristic is the approximation of subspaces generated
by the rows or columns of some block matrices of
the input/output data (see (Bauer, 2003) for a recent
overview). The underlying model structure is a state-
space representation with white noise (innovations)
entering the state equation through a Kalman ﬁlter
and the output equation directly
x(t + 1)
=
Ax(t) + Bu(t) + Ke(t)
y(t)
=
Cx(t) + Du(t) + e(t)
Simplifying (more than) a bit a fairly complex theory,
input and output data are used to build an extended
state-space system, where both data and model infor-
mation are represented as matrices, and not just vec-
tor and matrices. Kalman ﬁlter state sequences are
then identiﬁed and used to estimate system matrices
A, C, and, if a disturbance model is needed, K (B and
D can be subsequently estimated in several different
227
Efficient System Identification For Model Predictive Control
Approaches to Model Estimation
Automated Subspace Estimation
Two-Stage Method

ways). This can be assimilated (Ljung, 2003) to the
estimation of a high-order ARX model, which is then
reduced using weighted Hankel-norm model reduc-
tion. The three most well-known algorithms, CVA,
N4SID and MOESP, can be studied under an uni-
ﬁed framework (Van Overschee and DeMoor, 1996),
where each algorithm stems from a different choice
of weightings in the model reduction part. Subspace
identiﬁcation methods can handle the large dimen-
sional problems commonly found in system identiﬁ-
cation for process control, producing (very) fast and
robust results. However, it must be pointed out that
their estimates are generally less accurate than those
from prediction error methods and that standard SIM
algorithms are biased under closed-loop conditions.
Even though a lower accuracy is to be expected, it
is important to have a viable alternative to the two-
step method. This is why, we have implemented in
ISIAC two estimation procedures based on subspace
algorithms taken from control and systems library
SLICOT (Benner et al., 1999):
• a combined method, where MOESP is used to es-
timate A and C and N4SID is used to estimate B
and D;
• a simulation method, where MOESP is used to es-
timate A and C and linear regression is used to es-
timate B and D.
The second method is usually more accurate (though
a little slower) and is presented as the default choice.
High-level design parameters for these two method-
ologies are the ﬁnal model order n, and the prediction
horizon r used in the model reduction step. ISIAC
can select both parameters automatically: the latter
using a modiﬁed AIC criterion based on a high-order
ARX estimation, the former using a combined crite-
rion taking into account the relative importance of sin-
gular values and errors on simulated outputs (output
errors).
3.2
Fig. 2 shows ISIAC graphical user interface (GUI).
The tree on the left (the session tree) highlights the
relationships between the different elements the user
deals with during a typical system identiﬁcation ses-
sion.
• A System object representing the whole process the
user is working on. It includes a list of process
Variables and a list of Subsystems, which can be
used to store partial measurements and dynamic
models relating groups of input and output vari-
ables.
• Data objects in two ﬂavors: Raw Data and IO
Data. The former are deﬁned from raw process
data records and do not carry any structure infor-
mation. They are mainly used for preliminary ap-
praisal and processing of available data sets. IO
data are deﬁned by selecting subsets of ﬁelds of raw
data objects, and can be used for system identiﬁca-
tion. Notice that data objects in ISIAC may include
measurements coming from different experiments
(multi-batch data).
• Models include all the dynamic models estimated
or deﬁned during a session.
ISIAC handles
discrete-time state-space, transfer function (ma-
trix), FIR, ARX and general polynomial models.
State-space and transfer function models are also
available in continuous time. Simple process mod-
els, such as ﬁrst-order plus time delay (FOPTD)
models in gain-time constant-delay form, are han-
dled as specializations of transfer function models.
This structure provide a powerful and ﬂexible sup-
port to the user:
• no restriction is put on the number of models and
data objects, nor on their sizes;
• system identiﬁcation of the whole process can be
decomposed in smaller problems whose results can
be later recombined;
• it is straightforward to keep track of all the work
done during an identiﬁcation session.
Three special windows are dedicated to deﬁnition
and basic handling of system, data and model objects.
The Input Design Window is intended to help the user
to design appropriate test signals for system identiﬁ-
cation. More advanced operations on data and mod-
els are available in the Data Processing Window and
in the Model Processing Window. The most impor-
tant window is certainly the Data To Models Window,
where model estimation and validation take place.
Last, the ISIAC To MVAC Window hosts the graphi-
cal control model builder.
228
P. Tona and J.-M. Bader
Figure 2: ISIAC GUI.
General Structure and Layout

ISIAC GUI implements a multi-document inter-
face (MDI) approach: it is possible to have several
windows opened at once in the child window area.
Furthermore, thanks to drag-and-drop operations and
pop-up menus, the same action (say, plotting a model
time response) is accessible from different locations.
This means that, although ISIAC layout clearly under-
lines the different steps of the identiﬁcation process,
the user is never stuck into a ﬁxed workﬂow.
4
WORKING WITH ISIAC
4.1
Whenever the APC engineer has the freedom to
choose other input moves than classical step-testing
(not often, unfortunately), ISIAC offers support to
generate test signals which are more likely to yield
informative data. The Input Design Window lets the
user design signals such as pseudo-random binary sig-
nals (PRBS), using few high level parameters.
4.2
As mentioned before, ISIAC data objects provide a
structure to handle measurements of process vari-
ables. Input ﬁles containing raw measurements do
not need to carry any special information (other than
including delimited columns of values), and can be
imported without any external spreadsheet macro,
since data object formatting is done interactively into
ISIAC Data Window. Data visualization tools, which
include stacked plots, single-axis plots and various
statistical plots, have been designed with particular
care.
The more advanced functions of the Data Process-
ing Window are those commonly found in industrial
system identiﬁcation packages: normalization, de-
trending, de-noising, re-sampling, ﬁltering, nonlinear
transformations, data slicing, data merging. Notice
that a set of these data processing operations is incor-
porated in the automated model identiﬁcation proce-
dure (see section 4.4).
4.3
Most commonly, dynamic process models in ISIAC
are estimated from data or obtained combining or
processing existing (estimated) models. Models can
be also directly deﬁned by the user (in FOPTD
form, for instance) or imported from other packages.
ISIAC Model Window also provides transformations
between different LTI representations and time do-
main conversions, as well as several analysis and vi-
sualization tools. Model response plots, both in time
domain and in frequency domain, are extremely ﬂex-
ible. An unlimited number of models (not necessarily
sharing the same inputs or outputs) can be compared
on the same chart, and an unlimited number of chart-
ing windows can be opened at once.
Advanced model processing (in the Model Process-
ing Window) includes model reduction and model
building tools.
Time domain techniques (step re-
sponse ﬁtting of simple process models, see Fig. 3) or
frequency weighted model reduction techniques are
available. Model building can be performed through
simple connections (cascade, parallel) or through a
full-ﬂedged graphical model builder which closely re-
sembles the one described in section 4.5.
4.4
Model estimation must be preceded by some amount
of data processing, namely offset removal, normal-
ization and detrending (that is, removal of drifts and
low frequency disturbances). In ISIAC, these basic
but essential transformation are automatically applied
(unless the user does not want to), in a transparent
manner, before model estimation. Actually the Data
Processing Window, is only necessary when more ad-
vanced data processing is needed. Moreover, prior in-
formation about certain characteristics of the system
(integrating behavior, input-output delay) can be also
incorporated to help the estimation algorithms.
As explained in section 3.1, the default estima-
tion method in ISIAC is the two-stage method. This
method, combined with the transparent basic data
processing, results in a “click&go” approach that is
greatly appreciated by industrial practitioners. The in-
dustrial example of Fig. 4 shows that with this method
the user can really make the most of the available data,
even when the inputs are not very informative. Alter-
natively, subspace estimation can be selected. It is
229
Efficient System Identification For Model Predictive Control
Experiment Design
Working with Data
Working with Models
Estimating and Validating
Models
Figure 3: Step response ﬁtting.

also possible to estimate FIR models or general ARX
models.
Beside the comparison between measured outputs
and simulated outputs (as in Fig. 4), model validation
can be performed by checking the conﬁdence bounds
and visualizing and comparing time and frequency re-
sponses.
Figure 4: Model validation through simulation (simulated
4.5
One of the most interesting features of ISIAC is
the graphical control model builder, in the ISIAC To
MVAC Window (Fig. 5). With a few mouse clicks,
it is possible to build a complex control model from
a combination of sub-models, identiﬁed from differ-
ent data sets or extracted from existing models. The
user is only required to indicate the role of each input
and output in the control scheme. The model graph
can be then translated into a control model with the
appropriate format, or into a plant model for off-line
simulations. The resulting plant model can be also
transferred back to ISIAC workspace and applied to
the existing data sets to verify its correctness.
The model builder proves particularly helpful when
intermediate process variables are to be included. In
ﬁgure 5, which depicts part of the control conﬁgura-
tion for a unit involving cascaded reactors, the vari-
able denoted S HDT 1 is one of those variables.
5
AN INDUSTRIAL
APPLICATION: MODEL
PREDICTIVE CONTROL OF A
MTBE UNIT
To prove the usefulness of ISIAC in an industrial con-
text, we examine some aspects of a model predictive
control project, carried out by IFP afﬁliate Axens on
a petrochemical process unit.
The process under consideration is an etheriﬁca-
tion unit producing methyl-tert-butyl ether (MTBE),
from a reaction between isobutene (IB) and methanol
(MeOH).
The key control objectives are:
• maximize MTBE yield;
• increase IB recovery;
• reduce steam consumption;
• control MTBE purity.
The MVAC-based control system includes 7 MVs,
3 DVs, 6 CVs, with 5 intermediate variables. In the
following, we only consider a subset corresponding
to the control of MeOH percentage in MTBE (last
item of the objective list). Fig. 7 shows, from a sys-
tem viewpoint, how the controlled variable MEOH
IN MTBE is inﬂuenced by others process variables
of the control conﬁguration:
• feed ﬂow, MeOH ﬂow and sensitive temperature of
the catalytic column as CVs;
230
P. Tona and J.-M. Bader
outputs in white).
Building the Control Model
Figure 6: The MTBE unit.
Figure 5: The graphical control model builder.

• IB and MeOH percentages in feed to ﬁrst reactor as
DVs;
• the ratios of MeOH over IB, respectively entering
the ﬁrst reactor and the catalytic column, as inter-
mediate variables.
There are several avantages in introducing interme-
diate variables in the control conﬁguration, instead of
considering only direct transfer functions between in-
put variables (MVs plus DVs) and the CV:
• intermediate variables can be bounded, for tighter
control;
• unavoidable uncertainties in cascaded models (up-
stream from intermediate variables) can be com-
pensated for;
• deviations from predicted behavior can be detected
long before they affect the CV.
Figure 8: Frequency response of an identiﬁed model for
ISIAC has been used for data visualization and
analysis, as well as for identiﬁcation of sub-models
later included in the overall control conﬁguration. As
an example, we present some identiﬁcation results re-
lating to subsystem SYS1 of Fig. 7. Fig. 8 shows
the frequency response of a high order ARX model
together with its error bounds. The estimates of the
ﬁrst two transfer functions (MV1 →iPV1, MV2 →
iPV1) appear to be fairly accurate, since their error
bounds are comparatively quite small. The overall
quality of estimation is conﬁrmed by the comparison
between measured and predicted output (ﬁgure 9).
Figure 9: Measured vs. predicted (white) output for subsys-
As for control model building, Fig. 10 shows how
naturally the dedicated graphical tool translates block
diagrams like the one in Fig. 7. From this graphical
representation, it takes only one mouse-click to gen-
erate scripts for simulation purposes or for ﬁnal MPC
implementation.
6
CONCLUSION
ISIAC proposes a modern, ﬂexible and efﬁcient
framework to perform system identiﬁcation for ad-
vanced process control. Its main strengths are:
• a graphical user interface which emphasizes the
multi-step nature of the identiﬁcation process,
without trapping the user into a ﬁxed workﬂow;
• fast and robust estimation methods requiring mini-
mal user intervention;
• no restriction on the number or on the size of data
sets and models the user can work with;
• full support for the speciﬁcation of complex model
predictive control schemes, by means of block dia-
gram combination of (linear) models.
Through an exemple taken from an industrial MPC
application, we have illustrated the advantages of us-
ing our software in a concrete situation.
Figure 10: Building the partial MTBE control scheme in
231
Efficient System Identification For Model Predictive Control
Figure 7: Part of the MTBE control scheme.
subsystem SYS1.
ISIAC.
tem SYS1.

REFERENCES
Bauer, D. (2003). Subspace algorithms. In Proc. of the 13th
IFAC Symposium on System Identiﬁcation, Rotterdam,
NL.
Benner, P., Mehrmann, V., Sima, V., Van Huffel, S., and
Varga, A. (1999). SLICOT, a subroutine library in sys-
tems and control theory. Applied and Computational
Couenne, N., Humeau, D., Bornard, G., and Chebassier,
J. (2001).
Contrˆole multivariable d’une unit´e de
s´eparation des xyl`enes par lit mobile simul´e. Revue
de l’Electricit´e et de l’Electronique, 7-8.
Cutler, C. R. and Ramaker, B. L. (1980). Dynamic matrix
control: a computer control algorithm.
In Proc. of
the American Control Conference, San Francisco, CA,
USA.
Hsia, T. C. (1977). Identiﬁcation: Least Square Methods.
Lexington Books, Lexington, Mass., USA.
Juricek, B. C., Larimore, W. E., and Seborg, D. E. (1998).
Reduced-rank ARX and subspace system identiﬁca-
tion for process control. In Proc. IFAC DYCOPS Sym-
pos., Corfu, Greece.
Larimore, W. (2000). The ADAPTx software for automated
multivariable system identiﬁcation.
In Proc. of the
12th IFAC Symposium on System Identiﬁcation, Santa
Barbara, CA, USA.
Ljung, L. (1999).
System Identiﬁcation, Theory for the
User. Prentice-Hall, Englewood Cliffs, NJ, USA, sec-
ond edition.
Ljung, L. (2003). Aspects and experiences of user choices
in subspace identiﬁcation methods.
In Proc. of the
13th IFAC Symposium on System Identiﬁcation, Rot-
terdam, NL.
Ogunnaike, B. A. (1996). A contemporary industrial per-
spective on process control theory and practice.
A.
Qin, S. J. and Badgwell, T. A. (2003). A survey of indus-
trial model predictive control technology. Control En-
Richalet, J. (1993). Industrial applications of model based
Richalet, J., Rault, A., Testud, J. L., and Papon, J. (1978).
Model predictive heuristic control: applications to in-
Rivera, D. E. and Jun, K. S. (2000). An integrated identiﬁca-
tion and control design methodology for multivariable
process system applications. IEEE Control Systems
Tj¨arnstr¨om, F. and Ljung, L. (2003). Variance properties
of a two-step ARX estimation procedure. European
Van Overschee, P. and DeMoor, B. (1996). Subspace Iden-
tiﬁcation of Linear Systems: Theory, Implementation,
Applications. Kluwer Academic Publishers.
Varga, A. (1991). Balancing-free square-root algorithm for
computing singular perturbation approximations. In
Proc. of 30th IEEE CDC, Brighton, UK.
Wahlberg, B. (1989). Model reduction of high-order esti-
mated models: The asymptotic ML approach. Inter-
Zhu, Y. (1998).
Multivariable process identiﬁcation for
MPC: the asymptotic method and its applications.
Zhu, Y. (2000). Tai-Ji ID: Automatic closed-loop identiﬁca-
tion package for model based process control. In Proc.
of the 12th IFAC Symposium on System Identiﬁcation,
Santa Barbara, CA, USA.
Zhu, Y. (2001).
Multivariable System Identiﬁcation for
Process Control. Elsevier Science Ltd.
232
P. Tona and J.-M. Bader
Control, Signals and Circuits, 1: 499–539.
Rev. Control, 20: 1–8.
gineering Practice, 11: 733–764.
dustrial systems. Automatica, 14: 414–428.
Magazine, 20: 2537.
Journal of Control, 9: 400 –408.
national Journal of Control, 49: 169–192.
Journal of Process Control, 8(2): 101–115.
predictive control. Automatica, 29(5): 1251–1274.

Hee Il Hahn and Jung Goo Jung 
Department of Information and Communications Eng., Hankuk University of Foreign Studies, Korea  
Email: hihahn@hufs.ac.kr, jgchong@hanmail.net 
Keywords: 
Two-dimensional barcode, Segmentation, Error correction code, Warping  
Abstract: 
In this paper we introduce a method to extract the bar-space patterns directly from the gray-level two-
dimensional barcode images, which employs the location and the distance between extreme points of 
profiles scanned from the barcode image. This algorithm proves to be very robust from the high 
convolutional distortion environments such as defocussing and warping, even under badly illuminating 
condition. The proposed algorithm shows excellent performance and is implemented in real-time.   
1 INTRODUCTION 
Linear barcodes have been used globally in the 
various fields such as supermarkets and other stores 
for several decades. Usually, they do not have 
detailed information but just carry a key to database, 
because they can hold only several bytes of 
information. The need to increase the amount of data 
in a symbol brought the introduction of a new form 
of barcodes with much higher density called the 
two-dimensional (2-D) barcodes. They have been 
introduced since 1990’s. While conventional or one-
dimensional barcodes usually function as keys to 
databases, the new or two-dimensional barcodes 
meet a need to encode significantly more data than 
the conventional codes and would act as a portable 
data file because the information could be retrieved 
without access to a database. They have additional 
features such as error correction and the ability to 
encode in various languages like English, Korean 
and Chinese, etc., besides their increased capacity. 
Thus, the traditional concept of barcode as a key to a 
database is changing  towards a “portable data file” 
in which all the relevant information accompanies 
the item without access to a database.  
There are two types of 2-D symbologies - stacked 
and matrix-type symbologies. The stacked barcodes, 
to which Code49, PDF417, etc. belong, have the 
structure of rectangular block comprising numbers 
of rows, each of which is like 1-D symbology. The 
matrix-type barcodes are essentially a form of binary 
encoding in which a black or white cell can 
represent either binary 1 or 0. These cells are 
arranged in an array structured on a grid of 
rectangular block. DataMatrix, Maxicode, and QR 
code, 
etc. 
are 
representative 
of 
Matrix-type 
symbology (Pavlidis, 1992).  
     
In this paper, we focuss only on PDF417 (AIM 
USA, 1994), known as the most widely used 2-D 
stacked symbology. PDF417 is a multi-row, 
variable-length symbology offering high data 
capacity and error-correction capability. A PDF417 
symbol is capable of encoding more than 1,100 
bytes, 1,800 ASCII characters, or 2,700 digits, 
depending on the selected data compaction mode. 
Every PDF417 symbol is composed of a stack of 
rows, from a minimum of 3 to a maximum of 90 
rows. Each PDF417 row contains start and stop 
patterns, left and right row indicators. Fig. 1 shows 
the high-density scanned barcode image of PDF417 
code. 
We explain about our barcode decoder and 
propose a novel method of extracting codewords 
directly from gray-level barcode image by analyzing 
their profiles instead of binarizing the image. 
2 LOCALIZING THE DATA 
REGION
The data region is localized to extract the bar-space 
patterns and to detect the codewords, in the 
following way. Firstly, the start pattern or stop 
pattern, 
or 
both 
are 
searched 
by 
scanning 
horizontally and vertically. The start pattern is 
81111113 and the stop pattern is 711311121, both 
beginning with bar. Fig. 2 shows the segments 
TWO-DIMENSIONAL BARCODE SYMBOLOGY PDF417
IMPROVING PERFORMANCE OF THE DECODER FOR 
233
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 233–237. 

corresponding to the start patterns, which are 
extracted from the clear barcode image and the
highly blurred, high-density one
respectively,
together with their profiles. Although the start
patterns shown in Fig. 2-(a) can be easily identified,
it might not be easy to detect them in case of Fig. 2-
(b) because the width of one module is less than 1.5
pixels and the dynamic range of the profile at the
region corresponding to narrow bar or space is
severely reduced due to convolution with the point
spread function of the camera. After the start pattern
and/or stop pattern are detected, line equations
corresponding to them are estimated through line
fitting to localize left and/or right row indicators.
Secondly, the header information such as the
number of rows and columns, error correction level,
row number, error correction level and the width of
module, etc. are obtained by extracting and decoding
the left and/or right row indicators (Hahn, 2002).
Finally, four vertices of the data region are detected
by scanning in the directions perpendicular to the
start pattern line and the stop pattern line. To ensure
the vertices obtained are correct, row numbers are 
checked by decoding the left or right row indicators
around 
the 
vertices. 
If 
the 
row 
numbers
corresponding to the detected four vertices are not
the first row or the last row, the true four vertices are
predicted by considering the proportion of the row
number to the number of row, as depicted in Fig. 3.
Since barcode image is usually scanned using a
digital camera, it should be warped due to the
nonlinearity of lens and the viewing angle of the
camera. In this paper, Affine transform is adopted to
warp the data region
of the scanned image
(Gonzalez, 1993). Fig. 4 shows the warped result of
the data region inside the barcode in Fig. 1.
3 DECODING CODEWORDS
FROM BAR-SPACE PATTERNS
After the data region is localized and warped as 
mentioned above, bar-space patterns are extracted
from the data region and are decoded to obtain the
corresponding codewords. The problem is how we
get bar-space pattern from the barcode data region.
Usually, image thresholding is employed for this
goal. Many researchers developed
the image
thresholding algorithms,most of which reported
(a)
(b)
Figure 2: Profiles and segments corresponding to the start
patterns of the scanned barcode, which are excerpted from 
(a) clear image and (b) highly blurred, high-density image.
optimal thresholds has remained a challenge over
decades. However, they can not be applied to decode
the barcode images, because the widths of bars or
spaces can be 2 pixels or even less in case of high-
density barcode images and even slight variation of
threshold can cause severe errors (Eugene, 1991).
Figure 3: Locating true vertices by checking row numbers. 
Fig. 5 shows the segmented bar-space patterns and
their corresponding profiles obtained from the
focussed clean image and the outfocussed image.
Although the widths of bars and spaces of Fig. 5-(a)
234
H.L. Hahn and J.G. Jung
Figure 1: The scanned PDF-417 barcode image. 
analysis 
using
information-theoretic
histogram
to date are based on edge information or 
approaches (Parker,1991). The selection of

can be easily measured, it might not be a simple
matter to measure them in case of Fig. 5-(b) and the
obvious thing is single global threshold can not even
discriminate them. Fig. 6 shows the intensity profile 
of the codeword ( 824 : 1, 5, 1, 2, 1, 1, 1, 5 )
comprised of four bars and four spaces, together
with their widths and classification results.
As shown in Fig. 6-(a), it is impossible to select
the single optimal threshold for detecting the widths
of four bars and four spaces because the pixel values
change dynamically according to the widths of bars
and spaces.
Figure 4: Warping the data region of Fig. 2 using Affine 
transform.
The widths and peaks of narrow bars or spaces
corresponding to 1 or 2 module values get smaller
compared to the wide ones even under the same
illumination, due to convolution with the point
spread function. The proposed algorithm employs
the high curvature points and local extreme points to 
extract four bars and four spaces from the warped
barcode image. The points of high curvature on the
waveform represent the midpoints of the bar or
space, whereas the local extreme points are
estimates of their centers.
Figure 5: Segmented bar-space patterns and their 
corresponding profiles obtained from (a) the focussed
image, (b) the outfocussed image.
At first, our algorithm localizes four local minimum
points and four local maximum points by scanning
the profile of each bar-space pattern, as shown in Fig. 
6-(b). The local minimum point whose value is large
compared to the other minimum points or the
maximum point smaller than the adjacent ones are
compensated to increase their dynamic range as
depicted in Fig. 6-(c). Then, the break regions are
detected between the compensated extreme points,
where the break region means the region whose
profile is horizontal. The regions marked as 
rectangular box in Fig. 6-(d) represent the break
regions. Finally, the break regions are partitioned
according to the following rules. Usually, the edges
between bars and spaces lie in the break regions. In 
Fig. 7, we define
a
'
= x2 – x1 and
= x3 – x2.
If
b
'
a
' is greater than
b
' , the more part of the break
region belongs to the space region, vice versa. The
ratios are obtained by experimenting with several
hundreds of bar-space patterns, extracted from the 
various barcode images scanned under varying
conditions. Thus, the widths of bars and spaces are 
represented as real values rather than integer ones to
measure the bar-space patterns as correctly as
possible.
4 EXPERIMENTAL RESULTS
The “edge to similar edge” estimation method is
employed to check whether the detected bar-space
pattern is correct. The detected bar-space patterns
can be converted to the encoded codewords by using
the lookup table specified in (AIM USA, 1994). The
codewords are checked whether there are any errors
through Reed-Solomon error correction coding
algorithm. Given the error-corrected codewords,
they are decoded in the manner as specified in (AIM
USA, 1994), to get the message.
In order to verify our algorithm , we benchmark-
tested our decoder with the test barcode images. Our
database is composed of 153 barcode images, which
were taken  under various conditions. In other words,
they are rotated, outfocussed, warped or even
severely damaged by cutting off some region, as
shown in Fig. 8. Almost of them are taken under
badly illuminated conditions. At first, 2,000 pieces
of profiles corresponding to the bar-space patterns
are extracted from our database. Each profile is
tested to extract the bar-space pattern and decode the
corresponding codeword.
Among them,
1,466
profiles are detected correctly. As an example, the 
image of Fig. 8-(a) is obtained by hardcopying the
barcode image several times, whose upper part is
severely degraded. When it is applied to our decoder,
42 erasures and 32 errors are detected among total
329 codewords, which can be decoded correctly
through Reed-Solomon error correction algorithm.
Fig. 8-(b) is an image reassembled but aligned
incorrectly after tearing it into two parts. Fig. 8-(c) is
obtained from Fig. 8-(a) by cutting off the right part
of it and Fig. 8-(d) are taken outfocussed under too
bright 
illuminating 
condition.
Our 
algorithm
decoded 138 images correctly among total 153
images. This result is expected to be good for
235
Improving Performance of the Decoder

manufacturing purpose although there might be no
public images for benchmarking test.
5 CONCLUSION
We have proposed algorithms to decode two-
dimensional barcode symbology PDF417 and
implemented a barcode reader in real-time using
ARM core. Our decoder employs a method to
extract the bar-space patterns directly from the 
profiles of the gray-level barcode image. Our
algorithm shows performance improved further than
the method of extracting the bar-space patterns after
binarizing the barcode image, when we experiment
with the test images of variable resolution and error
correction 
levels. 
In
order 
to 
improve 
the
performance further, it is needed to extract bar-space
patterns more accurately from the barcode image,
which might be defocused or taken under badly
illuminating conditions.
(a)
(b ) 
(c ) 
  (d )
Figure 6: The intensity profiles of the codeword comprised 
of four bars and four spaces
Figure 7: Partition of break region according to the ratio
of
a
'
to
b
'
Figure 8: Sample images for measuring the performance
of our decoder.
REFERENCES
AIM USA, 1994. Uniform Symbology Specification
PDF417.
236
H.L. Hahn and J.G. Jung

Eugene Joseph and Theo Pavlidis, 1991. Waveform 
Recognition with Application to Barcodes, Symbol
Technologies Inc. 116 Wilbur Place, Bohemia, NY.  
R. C. Gonzalez, R.E.Woods, 1993. The book, Digital 
Image Processing, Addison Wesley. 
Hee Il Hahn, Joung Goo Joung, 2002. Implementation of 
Algorithm to Decode Two-Dimensional Barcode PDF-
417, 
6th 
International 
Conference 
on 
Signal 
Processing ICSP’02.
J. R. Parker, 1991. Gray level thresholding in badly 
T. Pavlidis, J. Swartz, Y. P. Wang, 1992. Information 
encoding with two-dimensional barcodes, IEEE 
Computer.
237
Improving Performance of the Decoder
No. 8. 
illuminated images, IEEE Trans. on PAMI, vol. 13, 

CONTEXT IN ROBOTIC VISION 
Paolo Lombardi 
Istituto Trentino di Cultura ITC-irst, via Sommarive 18, Trento, Italy 
(formerly with Dip. Informatica e Sistemistica, Università di Pavia)
Email:lombardi@itc.it 
Virginio Cantoni 
Dip. Informatica e Sistemistica, Università di Pavia, via Ferrata 1, Pavia, Italy 
Email:virginio.cantoni@unipv.it
Bertrand Zavidovique 
Institut d’Electronique Fondamentale, Université de Paris Sud-11, bât. 220, Campus d’Orsay, Orsay, France 
Email: zavido@ief.u-psud.fr 
Keywords: 
computer vision, contextual adaptation, context definition, Bayesian opportunistic switching. 
Abstract: 
Nowadays, the computer vision community conducts an effort to produce canny systems able to tackle 
unconstrained environments. However, the information contained in images is so massive that fast and 
reliable knowledge extraction is impossible without restricting the range of expected meaningful signals. 
Inserting a priori knowledge on the operative “context” and adding expectations on object appearances are 
recognized today as a feasible solution to the problem. This paper attempts to define “context” in robotic 
vision by introducing a summarizing formalization of previous contributions by multiple authors. Starting 
from this formalization, we analyze one possible solution to introduce context-dependency in vision: an 
opportunistic switching strategy that selects the best fitted scenario among a set of pre-compiled 
configurations. We provide a theoretical framework for “context switching” named Context Commutation,
grounded on Bayesian theory. Finally, we describe a sample application of the above ideas to improve video 
surveillance systems based on background subtraction methods. 
1 INTRODUCTION 
Computer vision was always considered a promising 
sensor for autonomous robots (e.g. domestic 
assistant 
robots, 
autonomous 
vehicles, 
video 
surveillance robotic systems, and outdoor robotics in 
general). Such applications require fast and reliable 
image processing to ensure real-time reaction to 
other agents around. Meanwhile, robots operating in 
varying and unpredictable environments need 
flexible perceptive systems able to cope with sudden 
context changes. To a certain extent, in robotics 
flexibility and robustness may be intended as 
synonyms. 
Conciliating real-time operation and flexibility is 
a major interest for the vision community today. 
Traditionally, flexibility has been tackled by 
increasing the complexity and variety of processing 
stages. Voting schemes and other data fusion 
methods have been widely experimented. Still, such 
methods often achieve flexibility at the expense of 
real time. 
Contextual information may open possibilities to 
improving system adaptability within real-time 
constraints. A priori information on the current 
world-state, scene geometry, object appearances, 
global dynamics, etc may support a concentration of 
system computational and analytical resources on 
meaningful components of images and video 
sequences. The recognition of the current operative 
“context” may allow a reconfiguration of internal 
parameters and active processing algorithms so as to 
maximize the potential of extractable information, 
meanwhile constraining the total computational 
load. Hence, “context” recognition and managing 
has attracted much interest from the robotic vision 
community in the last two decades. 
Control for real-time adaptation
239
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 239–246. 

A 
necessary 
step 
to 
implement 
context-
dependency in practical vision system is defining the 
notion of “context” in robotic vision. Various 
authors have covered different aspects of this matter. 
A summarizing operative definition may serve as an 
interesting contribution and a reference for future 
work. Furthermore, it helps in identifying possible 
“context changes” that a system should cope with. 
Overall, 
context 
managing 
represents 
a 
replacement of parallel image processing with less 
computationally expensive control. Controlling 
internal models and observational modalities by 
swapping among a finite set of pre-compiled 
configurations is probably the fastest and yet more 
realistically realizable solution. 
In Section 2, we present a wide range of works 
related to “context” in computer vision. Section 3 
details our proposal of formalization of such 
contributions by describing an operative definition. 
Then, Section 4 applies these concepts to a realistic 
implementation of real-time context-dependent 
adaptation within the scope of Bayesian theory. 
Finally, Section 5 concludes by suggesting some 
discussion and presenting future work.  
2 CONTEXT IN COMPUTER 
VISION
In earlier works, contextual information referred to 
image morphology in pixel neighborhoods, both 
spatial and temporal. Methods integrating this 
information include Markov Random Fields (Dubes, 
1989), and probabilistic relaxation (Rosenfeld, 
1976). More recent works have moved the concept 
to embrace environmental and modeling aspects 
rather than raw signal morphology. General 
typologies of “context” definitions include: 
1.
physical 
world 
models: 
mathematical 
description 
of 
geometry, 
photometry 
or 
radiometry, reflectance, etc – e.g. (Strat, 1993), 
(Merlo, 1988). 
2.
temporal 
information: 
tracking, 
temporal 
filtering 
(e.g. 
Kalman), 
previous 
stable 
interpretations of images in a sequence, motion 
behavior of objects, etc – e.g. (Kittler, 1995), 
(Tissainayagam, 2003). 
3.
site knowledge: specific location knowledge, 
geography, terrain morphology, topological 
maps, expectations on occurrence of objects 
and events, etc – e.g. (Coutelle, 1995), 
(Torralba, 2003).  
4.
scene 
knowledge: 
scene-specific 
priors, 
illumination, accidental events (e.g. current 
weather, wind, shadows), obstacles in the 
viewfield, etc – e.g. (Strat, 1993). 
5.
interpretative models and frames: object 
representations 
(3d-geometry-based, 
appearance-based), object databases, event 
databases, color models, etc – e.g. (Kruppa, 
2001). 
6.
relations 
among 
agents 
and 
objects:
geometrical relationships, possible actions on 
objects, 
relative 
motion, 
split-and-merge 
combinations, intentional vs. random event 
distinctions, etc – e.g. (Crowley, 2002). 
7.
acquisition-device 
parameters: 
photo-
grammetric parameters (intrinsic and extrinsic), 
camera 
model, 
resolution, 
acquisition 
conditions, daylight/infrared images, date and 
time of day, etc – e.g. (Strat, 1993), (Shekhar,
1996). 
8.
observed variables: observed cues, local vs. 
global features, original image vs. transformed 
image analysis, etc – e.g. (Kittler, 1995). 
9.
image understanding algorithms: observation 
processes, operator intrinsic characteristics, 
environmental specialization of individual 
algorithms, etc – e.g. (Horswill, 1995). 
10. intermediate 
processing 
results: 
image 
processing 
quality, 
algorithm 
reliability 
measures, system self-assessment, etc – e.g. 
(Draper, 1999), (Rimey, 1993), (Toyama, 
2000). 
11. task-related planning and control: observation 
tasks, 
global 
scene 
interpretation 
vs. 
specialized target or event detection, target 
tracking, prediction of scene evolution, etc – 
e.g. (Draper, 1999), (Strat, 1993). 
12. operation-related issues: computational time, 
response 
delay, 
hardware 
breakdown 
probabilities, etc – e.g. (Strat, 1993). 
13. classification 
and 
decision 
techniques:
situation-dependent 
decision 
strategies, 
features and objects classifiers, decision trees, 
etc – e.g. (Roli, 2001). 
Despite definitions of “context” in machine 
vision have appeared under multiple forms, they all 
present “context” as an interpretation framework for 
perceptive 
inputs, 
grounding 
perception 
with 
expectation.
Probably a definition of context in computer 
vision, yet rather a non-operative one, could be 
given by dividing a perceptive system into an 
invariant part and a variable part. The invariant 
part includes structure, behaviors and evolutions that 
are inherent to the system itself, and that are not 
subject to a possible change, substitution or control. 
Examples may be the system very hardware, 
acquisition sensors, and fixed links between them, 
etc.; basic sub-goals like survival; age, endemic 
breakdowns, mobility constraints, etc. The variable 
240
P. Lombardi, V. Cantoni and B. Zavidovique

part is all parameters, behaviors, and relations 
between components, which can be controlled. By 
means of these parts, the system may acquire 
dependence from the outer world and situation, with 
the purpose of better interacting with other agents 
and objects. In this view, context is what imposes 
changes to the variable part of a system. When 
mapped into the system through its variable parts, 
context becomes a particular configuration of 
internal parameters. 
3 AN OPERATIVE DEFINITION 
OF CONTEXT 
Inspired by the partial definitions from the previous 
references, we propose the following formalization 
(see (Lombardi, 2003) for details). 
Definition D.1: Context Q in computer vision is a 
triplet Q = (M, Z, D), where: 
x
M is the model set of object classes in the 
environment; 
x
Z is the operator set, i.e. the set of visual 
modules used in the observation process; 
x
D is the decision policy to distinguish 
between different classes of objects. 
The rationale is that in perceptive systems, elements 
that can be parameterized and thus controlled are 
prior models of external objects, models of system 
components, and the relations among them. In short, 
D includes all prior assumptions on the strategy
characterization. Essentially, it stands for point 13 in 
the above list. Hereafter, we further specify the 
definitions of M and Z.
3.1 Model Set M  
The model set M contains all a priori knowledge of 
the system regarding the outer scene, object/agent 
appearances, and relations among objects, agents 
and events (essentially, points 1-6). We explicitly 
list three groups of knowledge inside M.
Definition D.2: A model set is a triplet M = ({m}, 
P{m}, V{m}), where: 
x
{m} is the entity knowledge describing their 
appearance; 
x
P{m} is the prior expectation of occurrence 
in the scenario; 
x
V{m} is the evolution functions describing 
the dynamics. 
 
Entity knowledge m indicates the set of features 
and/or attributes that characterize an object type. 
Here, we call “entity” (Crowley, 2002) any object, 
agent, relation, or global scene configuration that is 
known, and thus recognizable, by the perceptive 
system. The set of all entity descriptions {m} is the 
total scene-interpretation capability of the system, 
namely the set of all available a priori models of 
object classes that the system can give semantics to 
raw data with. Minsky frames and state vectors 
containing geometrical information are examples of 
descriptors. Moreover, the image itself can be 
thought of as an object, thus {m} includes a 
description of global scene properties. 
Pm is the prior expectations on the presence of entity 
m in the scene. We distinguish Pm from m because 
object descriptions are inherently attached to an 
entity, while its probability of occurrence depends 
on causes external to objects. Evolution functions
V{m} indicate the set of evolution dynamics of an 
entity state parameters, e.g. object motion models. 
3.2 Operator Set Z  
The operator set Z gathers all prior self-knowledge 
on the perceptive system, available algorithms and 
hardware, feature extraction and measurement 
methods, observation matrixes, etc (points 7-12). We 
explicitly list three descriptors in Z.
Definition D.3: An operator set is a triplet Z = ({z},
H{z}, C{z}), where: 
x
{z} is the operator knowledge describing 
their mechanisms; 
x
H{z} are the operative assumptions of
operators; 
x
C{z} is the operation cost paid by system 
performance to run operators. 
 
Operator knowledge z contains all parameters, 
extracted features, tractable elaboration noise, and 
other relevant features of a given visual operator. 
The set {z} spans all visual modules in a system and 
their 
relative 
connections 
and 
dependencies. 
Operators constitute a grammar that allows matching 
data and semantics (model set M). Set {z} includes 
logical operators, relation operators (e.g. detectors of 
couples), and events detectors.  
 
Operative assumptions Hz is the set of hypotheses 
for the correct working of a visual module z. Implicit 
assumptions are present in almost every vision 
operator (Horswill, 1995). A misuse of z in 
situations where Hz do not hold true may cause 
abrupt performance degradation. Parameter Cz is a 
metrics depending on average performance ratings 
(e.g. computational time, delay, etc) useful to 
optimize system resources. 
241
Context in Robotic Vision
for 
inter-class 
separation
 
and 
intra-class 

3.3 Contextual Changes  
The explicit formulation of D.1 allows for a deeper 
understanding of contextual adaptability problems 
and of “context changes”. 
Definition D.4: A context change is a change in any 
component of a context Q, and we write it with ¨Q =
(¨{m}|| ¨P{m} || ¨V{m} || ¨{z} || ¨H{z} || ¨C{z} || ¨D), 
where || is a logical or. 
 
Each component of ¨Q generates a class of 
adaptability problems analyzed in the literature 
under an application-specific definition of “context 
change”. Here follow some examples: 
a)
¨{m} may occur when i) the camera 
dramatically changes its point of view, ii) a 
perceptive system enters a completely different 
environment of which it lacks some object 
knowledge, iii) object description criteria 
become inappropriate. 
b)
¨P{m} means that the frequency of an entity
class occurrence has changed, e.g. i) a camera 
enters a new geographical environment, ii) 
stochastic processes of object occurrence are 
non-stationary in time. 
c)
¨V{m} 
may 
occur 
when 
agents 
change 
trajectory so that hybrid tracking is needed – 
see (Tissainayagam, 2003), (Dessoude, 1993). 
d)
¨{z}may consist in i) inappropriate modeling 
of operator mechanisms, ii) inappropriate self-
assessment measures, etc. 
e)
¨H{z} indicates a failure of assumptions 
underlying {z}. For instance, a skin color 
detector whose color model is inappropriate to 
lighting conditions – see (Kruppa, 2001). 
f)
¨C{z} turns into a resource management 
problem. 
Dynamic 
programming, 
task 
planning, parametric control are examples of 
methods to find the best resource reallocation 
or sequencing. 
g)
¨D may occur when i) assumptions for 
separation 
of 
object 
classes 
become 
inappropriate, ii) critical observed feature 
become unavailable, iii). 
Definition D.5: The problem of insuring reliable 
system processing in presence of a context change is 
called an adaptability problem.
4 BAYESIAN CONTEXT 
SWITCHING 
Two are the solutions to cope with context changes:
i) a system has available alternative perceptive 
modalities; ii) a system can develop new perceptive 
modalities. The latter solution would involve on-line 
learning and trial-and-error strategies. Although 
some works have been presented – e.g. genetic 
programming of visual operators (Ebner, 1999) –, 
this approach is likely beyond the implementation 
level at present. 
The first solution may be implemented either by 
using “parallelism” or by “opportunistic switching” 
to a valid configuration. “Parallelism” consists in 
introducing redundancy and data fusion by means of 
alternative algorithms, so that failures of one 
procedure be balanced by others working correctly. 
However, parallelism is today often simulated on 
standard processors, with the inevitable effect of 
dramatically increasing the computational load at the 
expense of real time. This feature conflicts with the 
requirements of machine vision for robotics. 
“Opportunistic switching” consists in evaluating the 
applicability of a visual module or in pointing out a 
change in the environmental context, to commuting 
the system configuration accordingly. Opposite to 
parallelism and data fusion, this swapping strategy 
conciliates robustness and real time. Here we further 
develop the latter option (4.1), we describe a 
Bayesian implementation of it (4.2), and finally we 
exemplify an application to contextual video 
surveillance (4.3). 
4.1 Opportunistic Switching  
Opportunistic switching among a set of optimized 
configurations may ensure acceptable performance 
over a finite range N of pre-identified situations (i.e. 
“contexts”). 
Definition D.6: Designing a system for context-
dependent opportunistic switching consists in 
building and efficiently controlling a mapping ȗ
between a set of contexts Q and a set of sub-systems 
S, i.e. (1). The switching is triggered by context
changes D.4. 
ȗ : Q(t) ĺ S(t)  
 
 
 
 
 
 
 
(1) 
 
Building the map is an application-dependent 
engineering task: for each typical situation, the 
perceptive system must be engineered to deliver 
acceptable results. Control is performed by detecting 
the current context Q(t), or equivalently by detecting
context changes ¨Q. A context-adaptable system 
must be endowed with context-receptive processing, 
i.e. routines capable of classifying N different. 
context states {q1, q2,... qN}. Essentially, such 
routines detect “context features”, and context
recognition can be thought of as an object
242
P. Lombardi, V. Cantoni and B. Zavidovique

Figure 1: An oriented graph may easily accommodate all the elements of an opportunistic switching structure as defined in
Section 3: context/sub-system pairs in nodes, and events in arcs. Daemons trigger global state change.
recognition task. The design of such routines
appears to be an application-dependent design issue
Definition D.7: Let us name daemon an algorithm or
sensor į exclusively dedicated to estimating context
states q.
Opportunistic switching has two advantageous
features: i) flexibility and real-time, because multiple
configurations run one at a time, and ii) software
reuse, because an increased flexibility can be
achieved by integrating current software with ad-hoc
configurations for uncovered contexts. Assumptions
for its use are: i) there exists a rigid (static) mapping
from problems to solutions, ii) reliable context
detection.
4.2 Context Commutation
The mapping ȗ and its control may assume the form 
of parametric control, of knowledge-based algorithm
selection, of neural network controlled systems, etc.
Hereafter we present a Bayesian implementation of
the opportunistic switching strategy, named Context
Commutation (CC) (Lombardi, 2003). It is inspired
by hybrid tracking –e.g. (Dessoude, 1993) –, where
a swapping among multiple Kalman filters improves
tracking of a target moving according to changing
regimes.
Context 
Commutation 
represents 
context
switching by means of a Hidden Markov Model –
e.g. (Rabiner, 1989) –, where the hidden process is
context evolution in time, and the stochastic
observation function is provided by appropriate
probabilistic sensor models of daemons. Time is
ruled by a discrete clock t. Each clock step
corresponds to a new processed frame.
Definition D.8: Context Commutation represents
context evolution by means of a discrete, first-order
HMM with the following components (Figure 1): 
1. A set of states Q = {q1, q2, ...qN }. Each state qi
corresponds to a context and gets an associated
optimized system configuration si. For every i, si
is such that the perceptive system
works
satisfactorily in qi = {Mi, Zi, Di} i.e. Mi, Zi, Di are
the appropriate models, operators and decision
policies in the i-th situation.
2. An observation feature space ĭ composed of 
daemon outputs ĳ. If there are K daemons, ĳ is a 
K-dimensional vector. 
3. A transition matrix E, where elements Eij
correspond to the a priori probability of
transition from qi to qj, i.e. (2).
Eij = P[eij] = P[Q(t) = qj | Q(t-1) = qi]  
 
(2)
4. An observation probability distribution bi(ĳ) for
each context qi, defined in (3). Thus, the N
different bi(ĳ) define the global daemon sensor
model of Bayesian signal analysis theory.
)
)
(
|
)
(
(
)
(
i
i
q
t
Q
t
P
b
 
 
)
 
M
M
 
 
(3)
5. An initial state distribution function ʌ = {ʌ1, ʌ2,
...ʌN}, where ʌi  [0, 1] for i = 1, 2, ...N, and (4) 
holds true.
 
 
(4)
¦
 
 
N
i
i
1
1
S
q1
q2
q3
s1
s2
s3
į1
į2
į3
Daemons
e11
e12
e21
e23
e31
e22
243
Context in Robotic Vision

 (a)
 (b) 
 (c) 
 (d)
 (e)
 (f) 
Figure 2: When a reliable background reference model is available (a), background subtraction methods deliver more
meaningful motion information (b) than simple frame differencing (c). However, if the lighting conditions suddenly change,
e.g. an artificial light is turned off (d), BS fails (e) while FD still works properly.
Figure 3: The simple CC system for “light switch” problems has two states and one daemon. The picture shows the 
transition matrix E used in the experiments (top left), and a representation of daemon models (next to the si boxes). 
6.
The current context qȞ is estimated by the
Maximum A Posteriori on Ȍ(t) (5), (6).
Ȍ(t) = (P(q1), P(q2), …P(qN))
 
 
(5)
Ȟ = argmaxi [Ȍ i(t)]
 
 
(6)
As a final illustration, we demonstrate an application
of Context Commutation to tackle the “light switch”
problem affecting background subtraction (BS) for
motion detection in automatic video surveillance. In 
indoor environments, when artificial lights are 
turned on or off, the reference background model
used in BS looses validity in one frame-time.
Modern 
time-adaptive
background 
systems
(Stauffer, 1999) usually take around 10y100 frames
to recover. An alternative solution involves the use
of a second algorithm that degrades less its 
performance in case of abruptly changing lighting
conditions. For instance, frame differencing (FD)
algorithms deliver motion information like BS does,
and they recover from “light switch” just after 1 
frame (Figure 2).
A 
context-adaptable 
system 
based 
on
opportunistic switching would feature two system
states: i) using BS when appropriate, ii) using FD 
otherwise. In the general case, BS delivers a more
informing motion map than FD. However, when
lighting conditions are unstable, the system swaps to
FD – which recovers more quickly.
Here, we design a CC system as shown in Table 1 
and Figure 3. The two contexts, corresponding to
“stable” and “unstable” global lighting, cope with a
context change ¨Hbs which corresponds to a failure
of a basic operative assumption founding BS’s
correct working – i.e. stable lighting –. The daemon
į1 apt to detecting ¨Hbs is modeled with two 
truncated Gaussians of the kind shown in Figure 3,
with parameters tuned by training. Daemon į1
counts the pixels na and nb showing a luminance
change that breaks thresholds
șį1
and -șį1,
respectively: na+nb represents all pixels showing 
substantial luminance change. The output (7) is then
a measure of the luminance unbalance over the last
two images. In stable lighting conditions ĳ1 would
s(2)
q1
q2
s(1)
0
1
0
1
Stable
lighting
Unstable
lighting
¸¸
¹
·
¨¨
©
§
 
3.0
7.0
4.0
6.0
E
244
P. Lombardi, V. Cantoni and B. Zavidovique
4.3 A Practical Implementation

be 0. The closer ĳ1 to 1, the more likely switched the
light.
1
)
,
max(
2
1


 
b
a
b
a
n
n
n
n
M
 
(7)
Table 1
Q
Situation
S
q1
stable lighting
BS active if in ready state
FD active if BS in recovering state
q2
unstable
lighting
FD active
To assess context estimation performance, į1 was 
tested on over 1500 images containing about 50 light
switches. The test was done on sequences indexed
by a human operator. Figure 4 shows the results on 
one test sequence: when the confidence rating breaks
0.5, q2 is estimated. Bold dots on the top line show
the
ground truth for
q2 occurrence. Model
parameters Gi~(µi, ıi) in qi are in Table 2.
Table 2 
µ1
µ2
ı1
ı2
į1
0.09
0.71
0.17
0.36
We measured an average correct estimation rate 
of 0.95. The percentage goes up to 0.98 if a 3-frame-
range error is allowed in locating the contextual
switch. In effect, this error allowance accounts for
human mistakes in indexing the test videos.
The motion detection system with and without
CC was tested on several sequences. No tracking 
was performed, only motion detection. The graph of
Figure 5 shows the improvement provided by CC in
terms of such distance (when BS failed because of
inappropriate background model – e.g. Figure 2 –,
the corresponding estimation error was set to 100).
Figure 6 shows some results for one sequence where
light switches twice: on-off on frame 327, and off-on
on frame 713. The distance of the barycentre of 
motion between automatic detection and human
labeling was computed for BS only, and for BS/FD
combined by means of CC.
0
0,5
1
0
100
200
300
400
500
Frame
Probability
Motion Barycenter Estimation
-50
0
50
100
200
400
600
800
1000
1200
Frame Number
Improvement
Figures 4, 5: Probability that the current context state be q2 as estimated by į1 in a test sequence (left). Improvement in the 
estimation error provided by context switching (CC) with respect to BS alone (right).
Figure 5: Frames no. 322, 332, 702, and 932 from a test sequence: original images (first row), motion detection by BS and
FD managed opportunistically by CC (second row).
245
Context in Robotic Vision

5 CONCLUSIONS 
In this paper we foster deeper studies in the 
management of contextual information in robotic 
vision. In the first part, we proposed an operative 
definition of “context” to identify the variable parts 
of a perceptive system susceptible of becoming 
inappropriate in case of contextual changes: models, 
operators, and decision policies. 
 
In the second part, we described a novel Bayesian 
framework (i.e. Context Commutation) to implement 
contextual 
opportunistic 
switching. 
Dedicated 
algorithms, 
called 
daemons, 
observe 
some 
environmental features showing a correlation with 
system performance ratings rather than with the 
target signal (e.g. people tracking). When such 
features change, the system commutes its state to a 
more reliable configuration. 
 
Critical points in Context Commutation are 
mainly 
related 
to 
its 
Bayesian 
framework. 
Parameters like sensor models of daemons and 
coefficients of the transition matrix need thorough 
tuning and massive training data. An error in such 
parameters 
would 
corrupt 
correct 
contextual 
switching. 
Possible points for future work are: i) exploring 
switching reliability with incorrect parameters, ii) 
studying Context Commutation with more than eight 
states, iii) extending the framework to perceptive 
systems including sensors other than solely vision. 
REFERENCES
Coutelle, C., 1995. Conception d’un système à base 
d’opérateurs de vision rapides, PhD thesis (in French), 
Université de Paris Sud (Paris 11), Paris, France. 
Crowley, J.L., J. Coutaz, G. Rey, P. Reignier, 2002. 
Perceptual 
Components 
for 
Context 
Aware 
Computing. In Proc. UBICOMP2002, Sweden, 
available at http://citeseer.nj.nec.com/541415.html. 
Dessoude, O., 1993. Contrôle Perceptif en milieu hostile: 
allocation de ressources automatique pour un système 
multicapteur,  PhD thesis (in French), Université de 
Paris Sud (Paris 11), Paris, France. 
Draper, B.A., J.Bins, K.Baek, 1999. ADORE: Adaptive 
Object Recognition. In Proc. ICVS99, pp. 522-537. 
Dubes, R. C., Jain, A. K., 1989. Random Field Models in 
131-164.
Ebner, M., A. Zell, 1999. Evolving a task specific image 
operator. 
In 
Proc. 
1st 
European 
Wshops 
on 
Evolutionary Image Analysis, Signal Processing and 
Telecommunications, Göteborg, Sweden, Springer-
Verlag, pp. 74-89. 
Horswill, 
I., 
1995. 
Analysis 
of 
Adaptation 
and 
1-30, 1995. 
Kittler, J.,  J. Matas, M. Bober, L. Nguyen, 1995. Image 
interpretation: Exploiting multiple cues. In Proc. Int. 
Conf. Image Processing and Applications, Edinburgh, 
UK, pp. 1-5. 
Kruppa, H., M. Spengler, B. Schiele, 2001. Context-driven 
Model Switching for Visual Tracking. In Proc. 9th Int. 
Symp. Intell. Robotics Sys., Toulouse, France. 
Lombardi, P., 2003. A Model of Adaptive Vision System: 
Application to Pedestrian Detection by Autonomous 
Vehicles. PhD thesis (in English), Università di Pavia 
(Italy) and Université de Paris XI (France). 
Merlo, X., 1988. Techniques probabilistes d’intégration et 
de contrôle de la perception en vue de son exploitation 
par le système de décision d’un robot, PhD thesis (in 
French), Université de Paris Sud (Paris 11), Paris, 
France. 
Rabiner, L.R., 1989. A tutorial on hidden Markov models. 
InProceedings of the IEEE, V. 77, pp. 257-286. 
Rimey, R.D., 1993. Control of Selective Perception using 
Bayes Nets and Decision Theory. Available at http:// 
citeseer.nj.nec.com/rimey93control.html. 
Roli, F., G. Giacinto, S.B. Serpico, 2001. Classifier Fusion 
for Multisensor Image Recognition. In Image and 
Signal Processing for Remote Sensing VI, Sebastiano 
B. Serpico, Editor, Proceedings of SPIE, V. 4170, 
pp.103-110.
Rosenfeld, A., R.A. Hummel, S.W. Zucker, 1976. Scene 
labeling by relaxation operations. In IEEE Trans. Syst. 
Man Cybern., V. 6, pp. 420-433. 
Shekhar, 
C., 
S. 
Kuttikkad, 
R. 
Chellappa, 
1996. 
KnowledgeBased Integration of IU Algorithms. In 
Proc. Image Understanding Workshop, ARPA, V. 2, 
pp. 1525-1532, 1996. 
Stauffer, C., W.E.L. Grimson, 1999. Adaptive Background 
Mixture Models for Real-Time Tracking. In Proc.
IEEE Conf. Comp. Vis. Patt. Rec. CVPR99, pp. 246-
252.
Strat, T.M., 1993. Employing Contextual Information in 
Computer Vision. In Proc. DARPA93, pp. 217-229. 
Tissainayagam, P., D. Suter, 2003. Contour tracking with 
automatic motion model switching. In Pattern 
Recognition.
Torralba, A., K.P. Murphy, W.T. Freeman, M.A. Rubin, 
2003. Context-based vision system for place and 
object recognition. In Proc. ICCV’03, available at 
http://citeseer.nj.nec.com/torralba03contextbased.html. 
Toyama, K., E.Horvitz, 2000. Bayesian Modality Fusion: 
Probabilistic 
Integration 
of 
Multiple 
Vision 
Algorithms for Head Tracking. In Proc. ACCV’00, 4th
Asian Conf. Comp. Vision, Tapei, Taiwan, 2000.
246
P. Lombardi, V. Cantoni and B. Zavidovique
Image Analysis. In J. Applied Statistics, V. 16, pp. 
Environment. In Artificial Intelligence, V. 73(1-2), pp. 

DYNAMIC STRUCTURE CELLULAR AUTOMATA 
IN A FIRE SPREADING APPLICATION 
Alexandre Muzy, Eric Innocenti, Antoine Aïello, Jean-François Santucci, Paul-Antoine Santoni 
University of Corsica 
SPE – UMR CNRS 6134 
B.P. 52, Campus Grossetti, 20250 Corti. FRANCE.
Email: a.muzy@univ-corse.fr 
David R.C. Hill 
ISIMA/LIMOS UMR CNRS 6158 
Blaise Pascal University 
Campus des Cézeaux BP 10125, 63177 Aubière Cedex. FRANCE.
Email: drch@isima.fr
Keywords: 
Systems modeling, Discrete event systems, Multi-formalism, Fire spread, cellular automata. 
Abstract: 
Studying complex propagation phenomena is usually performed through cellular simulation models. 
Usually cellular models are specific cellular automata developed by non-computer specialists. We attempt 
to present here a mathematical specification of a new kind of CA. The latter allows to soundly specify 
cellular models using a discrete time base, avoiding basic CA limitations (infinite lattice, neighborhood and 
rules uniformity of the cells, closure of the system to external events, static structure, etc.). Object-oriented 
techniques and discrete event simulation are used to achieve this goal. The approach is validated through a 
fire spreading application. 
1 INTRODUCTION 
When modeling real systems, scientists cut off 
pieces of a biggest system: the world surrounding us. 
Global understanding of that world necessitates 
connecting all these pieces (or subsystems), 
referencing some of them in space. When the whole 
system is complex, the only way to study its 
dynamics is simulation. 
Propagation phenomena as fire, swelling, gas 
propagation, (…) are complex systems. Studying 
these phenomena generally leads to divide the 
propagation space in cells, thus defining a cellular 
system. 
Developed from the General Systems Theory 
(Mesarovic and Takahara, 1975), the Discrete Event 
Structure Specification (DEVS) formalism (Zeigler 
et al., 2000) offers a theoretical framework to map 
systems 
specifications 
into 
most 
classes 
of 
simulation 
models 
(differential 
equations, 
asynchronous cellular automata, etc.). For each 
model class, one DEVS sub-formalism will allow to 
faithfully specify one simulation model. As 
specification of complex systems often needs to 
grasp 
different 
kinds 
of 
simulation 
models, 
connections between the models can be performed 
using DEVS multi-formalism concepts.  
Another DEVS advantage relates to its ability in 
providing discrete event simulation techniques, thus 
enabling to concentrate the simulation on active 
components 
and 
resulting 
in 
performance 
improvements. 
Precise and sound definition of propagation 
needs to use models from physics as Partial 
Differential Equations (PDEs). These equations are 
then discretized leading to discrete time simulation 
models. These models are generally simulated from 
scientists by using specific Cellular Automata (CA). 
As defined in (Wolfram, 1994), standard CA consist 
of an infinite lattice of discrete identical sites, each 
site taking on a finite site of, for instance, integer 
values. The values of the sites evolve in discrete 
time steps according to deterministic rules that 
specify the value of each site in terms of the values 
of neighboring sites. CA may thus be considered as 
discrete idealizations of PDEs. CA are models where 
space, time and states are discrete (Jen, 1990).  
However, definition of basic CA is too limited to 
specify complicated simulations (infinite lattice, 
neighborhood and rules uniformity of the cells, 
247
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 247–254. 

closure of the system to external events, discrete 
state of the cells, etc.). Scientists often need to 
modify CA’s structure for simulation purposes 
(Worsch, 1999). 
We extend here basic CA capabilities by using 
object-oriented 
techniques 
and discrete event 
simulation 
(Hill, 
1996). 
A 
mathematical 
specification of the approach is defined using the 
Dynamic 
Structure 
Discrete 
Time 
System 
Specification (DSDTSS) formalism (Barros, 1997). 
This formalism allows dynamically changing the 
structure of discrete time systems during the 
simulation. These new CA are called the Dynamic 
Structure Cellular Automata (DSCA). 
DSCA have been introduced in (Barros and 
Mendes, 1997) as a formal approach allowing to 
dynamically 
change 
network 
structures 
of 
asynchronous CA. Using an asynchronous time 
base, cells were dynamically instantiated or 
destroyed during a fire spread simulation. 
The scope here is to extend basic CA capabilities 
using a discrete time base. If previous DSCA were 
dedicated 
to 
discrete 
event 
cellular 
system 
specification, we extend here the DSCA definition to 
discrete time cellular system specification.  
Table 1 sums up the advantages of the DSCA in 
relation to basic CA. In DSCA, each cell can contain 
different 
behaviors, 
neighborhoods 
and 
state 
variables. Rules and neighborhoods of the cells can 
dynamically change during the simulation. Each cell 
can receive external events. During the simulation, 
the computing of state changes is limited to active. 
Finally, a global transition function allows the 
specification of the DSCA global behaviors. 
Table 1: DSCA extensions 
Basic CA 
DSCA 
Time 
discrete 
Discrete 
Space 
discrete 
Discrete 
State 
discrete 
Continuous 
Closure to 
external events 
- 
+ 
Different 
variables per 
cell
- 
+ 
Rules
uniformity* 
- 
+ 
Neighborhood 
uniformity* 
- 
+ 
Activity
tracking*
-
+
Global function 
- 
+ 
     *at simulation time 
The DSCA definition is validated against a fire 
spreading application. Recent forest fires in Europe 
(Portugal, France and Corsica) and in the United 
States (California) unfortunately pinpoint the 
necessity of increasing research efforts in this 
domain. Fires are economical, ecological and human 
catastrophes. Especially as we know that present 
rising of wild land surfaces and climate warming 
will increase forest fires. 
Modeling such a huge and complex phenomenon 
obviously 
leads 
to 
simulation 
performance 
overloadings 
and 
design 
problems. 
Simulation model reusability has to face to the 
complicated aspects of both model implementations 
and model modifications. Despite a large number of 
cells, simulation has to respect real time deadlines to 
predict actual fire propagations. Hence, this kind of 
simulation 
application 
provides 
a 
powerful 
validation to our work. 
This study is organized as follows. First some 
formalisms background is provided. Then two 
sections present the DSCA modeling and simulation 
principles. After, simulation results of a fire 
spreading application are provided. Finally, we 
conclude and make some prospects. 
2 BACKGROUND 
A formalism is a mathematical description of a 
system allowing to guide a modeler in the 
specification task. The more a formalism fits to a 
system class, the more simple and accurate it will be.  
Efficiently modeling complex systems often 
implies the need to define subsystems using different 
formalisms. Connections between the different 
formalisms can then be achieved through a multi-
formalism 
to 
perform 
the 
whole 
system 
specification.
In this study, subsystems are specified using 
DEVS, DTSS (Discrete Time System Specification) 
and DSDTSS formalisms. Connections between the 
different models are achieved using a Multi-
formalism Network (MFN). A structure description 
of each model is provided hereafter. 
A DEVS atomic model is a structure:  
DEVS = (X, Y, Q, q0, įint, įext, Ȝ, ta)
where X is the input events set, Q is the set of state, 
q0 is the initial state, Y is the output events set, įint:
Q Æ Q is the internal transition function, įext: Q×X 
Æ Q is the external transition function, O : Q Æ Y
the output function,  ta is the time advance function.  
248
A. Muzy et al.

DSDTSS basic models are DTSS atomic model: 
DTSS = (X, Y, Q, q0,G, O, h) 
where X, Y are the input and output sets, Q is the 
set of state, q0 is the initial state,  
G : Q×X Æ Q is 
the state transition function,  
O : Q Æ Y is the 
output function (considering a Moore machine) and 
h is a constant time advance. 
 
At a periodic rate, this model checks its inputs 
and, based on its state information, produces an 
output and changes its internal state.
The network of simple DTSS models is referred 
to as a Dynamic Structure Discrete Time Network 
(DSDTN) (Barros, 1997). We introduce here input 
and output sets to allow connections with the 
network. Formally, a DSDTN is a 4-tuple:  
DSDTN = (XDSDTN,YDSDTN,F, MF)
where XDSDTN is the network input values set, YDSDTN
is the network input values set, F is the name of the 
DSDTN executive, MF is the model of the executive
F.
The model of the executive is a modified DTSS
defined by the 8-tuple: 
MF = (XF,QF, q0,F, YF, J, 6*, GF, OF ) 
where J : QFÆ 6* is the structure function, and 6* is
the set of network structures. The transition function 
GF computes the executive state qF. The network 
executive structure 6, at the state qF  QF is given by 
6 =  J (qF) = (D, {Mi}, {Ii}, {Zi,j}), for all i  D, Mi = 
(Xi, Qi, q0,i, Yi, Gi, Oi  ), where D is the set of model 
references,  Ii is the set of influencers of model i, and
Zi,j is the i to j translation function. 
Because the network coupling information is 
located in the state of the executive, transition 
functions can change this state and, in consequence, 
change the structure of the network. Changes in 
structure include changes in model interconnections, 
changes in system definition, and the addition or 
deletion of system models. 
Formally, a multiformalism network (Zeigler et 
al., 2000) is defined by the 7-tuple: 
MFN = (XMFN,YMFN, D, {Mi}, {Ii}, {Zi,j},select) 
where XMFN=Xdiscr×Xcont is the network input values 
set, Xdiscr and Xcont are discrete and continuous input 
sets, YMFN=Ydiscr×Ycont is the network input values 
set, Ydiscr and Ycont are discrete and continuous output 
sets, D is the set of model references, 
For each i  D, 
 Mi is are DEVS, DEVN, DTSN, DTSS, 
DESS, DEV&DESS or other MFN models. 
As DSDTSS proved to be closed under 
coupling, Mi can also be dynamic structure 
models or networks, 
Ii is the set of influencers of model i,
Zi,j is the i to j translation function,
select is the tie-breaking function. 
3 DSCA MODELLING 
Models composing a DSCA are specified here using 
the previous model definitions. As described in the 
modeling part of Figure 1, external events are 
simulated using a DEVS atomic model: the 
Generator. The latter can asynchronously generate 
data information to the DSCA during the simulation. 
The cell space is embedded in a DSDTN. Each cell 
is defined as a DTSS model. Using its transition 
function, the DSCA executive model (containing 
every cells) achieves changes in structure directly 
accessing to the attributes of cells. A mathematical 
description of each model is provided here after. 
We define the MFN by the structure:
MFN = (XMFN,YMFN, D, {Mi}, {Ii}, {Zi,j}, select) 
where D={G,DSDTN}, MG = (XG, QG, q0,G, YG, GG,
OG, ĲG), MDSDTN=DSDTN, IG={}, IDSDTN={G}, and
ZDSDTN,MFN: YDSDTNÆYMFN, ZG,DSDTN: YGÆXDSDTN.
We define the DSDTN by the structure: 
DSDTN = (XDSDTN, YDSDTN, DSCA, MDSCA)
where 6 = J (q0,F) = (D, {Mi}, {Ii}, {Zi,j}), where 
D={(i,j) / (i,j) 
2
 }, MDSCA = (XDSCA, QDSCA,
q0,DSCA, YDSCA, GDSCA, ODSCA),
IDSCA={DSDTN},
Icell={celln,DSDTN}. Where Icell = {Ikl / k  [0,m], l 
 [0,n]} is the neighbourhood set (or the set of 
influencers) of the cell as defined in (Wainer and 
Giambiasi, 2001). It is a list of pairs defining the 
relative position between the neighbours and the 
origin cell. Ikl = {(ip,jp) /   p  Icell, p  [1,Șkl], ip,jp
 Z ; |k- ip|  0   |l- jp|  0  Șkl  Icell }, and Ș 
Icell is the neighborhood size. 
Zcell,DSCA: 
YcellÆYDSCA, 
ZDSCA,DSDTN:
YDSCAÆYDSDTN, 
ZDSDTN,DSCA: 
XDSDTNÆXDSCA,
ZDSCA,cell: XDSCAÆXcell.
For the implementation, ports are defined: 
 
PyG=PxDSDTN=PxDSCA={data} 
249
Dynamic Structure Cellular Automata in a Fire Spreading Application

 
PyDSCA=PyDSDTN=PyMFN={state} 
 
Pxcell=Pycell={(i,j)} 
We specify each cell as a special case of DTSS 
model: 
cell=(Xcell, Qcell, q0,cell, Ycell, Gcell, Ocell ) 
where Xcell is an arbitrary set of input values, Ycell is 
an arbitrary set of output values, q0,cell is the initial 
state of the cell and  
q  Qcell is given by:  
q=((i,j), state, N,  phase), 
 
(i,j) 
2
 , is the position of the cell, 
 
state is the state of the cell, 
N = {Nkl / k  [0,m], l  [0,n]}. N is a list of 
states Nkl of the neighboring cells of coordinates 
(k,l),
phase = {passive, active} corresponds to the 
name of the corresponding dynamic behavior. 
For numerous adjacent active cells, the active
phase can be decomposed in ‘testing’ and 
‘nonTesting’ phases. The use of these phase is 
detailed in section 5.
Gcell : Qcell×Xcell Æ Qcell
Ȝcell : Qcell Æ Ycell
4 DSCA SIMULATION 
As depicted in Figure 2, implementation of discrete 
event models consists in dividing a transition 
function Gd of a model according to event types evn
issued from a set of possible event types Sd. The 
transition function then depends on the event types 
the model receives. 
  Model d
 
Sd = {ev1, ev2, … , evn}
Gd (Sd)
 
 
case Sd
 
 
ev1 : call event-routine1
 
 
ev2 : call event-routine2…
 
 
evn : call event-routinen
Figure 2: Discrete event model implementation  
(Zeigler et al., 2000) 
The DSCA receives data from the Generator.
These data represent external influences of the 
DSCA. During the simulation, information is 
embedded in messages and transits through the data
and state ports. Messages have fields [Message type, 
Time, Source processor, Destination port, Content],
where Content is a vector of triplets [Event type, 
Value, Coordinate port]. When a DSCA receives a 
message on its data port, the corresponding 
Aggregated Network Simulator (AN Simulator) 
scans the Content vector and according to the 
Coordinate port, sends the [Event type, Value] pairs 
to the concerned cells. A vector of pairs [Event type, 
Value] can be sent to a cell port. Then, according to 
the Event type a cell receives, it will update the 
concerned attributes, executing the concerned 
transition function. 
The simulation tree hierarchy is described in the 
simulation part on the right side of Figure 1. Except 
for the Root and DTSS interface, all nodes of the tree 
are processors attached to models. The processors 
manage with message exchanges and execution of 
model functions. Each processor is automatically 
generated when the simulation starts. 
The Coordinator pilots the MFN model, the 
simulator SimG pilots the Generator, the DSDTN 
model and the DSDTN models are piloted by the 
Aggregated Network Simulator (AN Simulator).
Algorithms of the DSCA simulators can be found in 
(Muzy et al., 2003). Algorithms of basic DEVS 
simulators and DTSS interfaces can be found in 
(Zeigler et al., 2000). 
The Root processor supervises the whole 
simulation loop. It updates the simulation time and 
activates messages at each time step. For the 
Coordinator, the DTSS interface makes the 
Aggregated Network simulator seen as a DEVS 
atomic simulator. This is done by storing all 
messages arriving at the same time step and then by 
calculating the new state and output of the DSCA 
when receiving an internal transition message. The 
simulation tree thus respects the DEVS bus 
principle. That means that whatever DEVS model 
can be appended to the simulation tree. 
5 ACTIVITY TRACKING
Using discrete event cellular models, activity 
tracking can be easily achieved (Nutaro et al., 2003). 
Active cells send significant events to be reactivated 
or to activate neighbors at next time step. However, 
pure discrete event models proved to be inefficient 
for discrete time system simulation (Muzy et al., 
2002). 
Interface 
configurations 
and 
message 
management 
produce 
simulation 
overheads, 
especially for numerous active components.  
For discrete time systems, we know that each 
component will be activated at each time step. 
Moreover, in CA, states of cells directly depend on 
250
A. Muzy et al.

Coordinator 
SimG 
DTSS-interface
Root 
AN Simulator
DSDTN 
MFN 
Generator 
data 
data 
states
DSCA 
Cell 
…
states 
(0,0) 
(m,n) 
modelling 
simulation 
the states of their neighbors. To optimize the simulation, 
messages between the cells have to be canceled and 
simulation time advance has to be discrete. However, a 
new algorithm has to be defined to track active cells. 
To focus the simulation on active cells, we use 
the basic principles exposed in (Zeigler et al., 2000) 
to predict whether a cell will possibly change state 
or will definitely be left unchanged in a next global 
state transition: “a cell will not change state if none 
of its neighboring cells changed state at the current 
state transition time”.
Nevertheless, to obtain optimum performance the 
entire set of cells cannot be tested. Thereby, an 
algorithm, which consists in testing only the 
neighborhood of the active bordering cells of a 
propagation domain, has been defined for this type 
of phenomena.  
To be well designed, a simulation model should 
be structured so that all information relevant to a 
particular design can be found in the same place. 
This principle enhances models modularity and 
reusability making easier further modifications. 
Pure discrete event cells are all containing a 
micro algorithm, which allows to focus the whole 
simulation loop on active cells. We pinpointed 
above the inefficiency of such an implementation for 
discrete time simulation. An intuitive and efficient 
way to achieve activity tracking in discrete time 
simulation is to specify this particular design at one 
place. As depicted in Figure 3, the activity tracking 
algorithm is located in the global transition function 
of the DSCA, in charge of the structure evolution of 
the cell space.  
Cells are in ‘testing’ phases when located at the 
edge of the propagation domain, ‘nonTesting’ when 
not tested at each state transition and ‘quiescent’
when inactive. 
A propagation example is sketched in Figure 4 
for cardinal and adjacent neighborhoods. In our 
algorithm, only the bordering cells test their 
neighborhood, this allows to reduce the number of 
testing cells.
The 
result 
of 
the 
spreadTest(i,j,nextState)
function of Figure 3, depends on the state of the 
tested cells. If this state fulfils a certain condition 
defined by the user, the cell becomes ‘nonTesting’
and new tested neighboring are added to the set of 
active cells. The transition function receives xȤ
messages from the Generator corresponding to 
external events. The xȤ messages contain the 
coordinates of the cells influenced by the external 
event. If the coordinates are located in the domain 
calculation, the state of the cell is changed by 
activating its transition function with the new value. 
Otherwise, new cells are added to the propagation 
domain. 
//’Q’ is for the quiescent phase,
//’T’ for the testing one and ‘N’ for //the nonTesting 
one
Transition Function(xȤ)
For each cell(i,j) Do     
 
If(cellPhase(i,j)==’Q’) Then
   removeCell(i,j)
Endif
If(cellPhase(i,j)==’T’) Then
If (cellNearToBorder(i,j)) Then
    setSpreadStateCell(i,j,’N’)
Else
If(spreadTest(i,j,nextState))Then
     setCellPhase(i,j,‘N’)
     addQuiescentNeighboringCells(i,j) 
EndIf
EndIf
  EndIf 
 EndFor 
If(xȤ message is not empty) 
If(cells in the propagation domain) Then
    
cell(i,j).transitionF(newState) 
 
//change the cell states 
Else
   addNewCells() 
EndIf
EndIf
EndTransitionFunction()
251
Figure 1: DSCA modeling and simulation. 
Figure 3: Transition function of the DSCA. 
Dynamic Structure Cellular Automata in a Fire Spreading Application

For efficiency reasons, the simulation engine we 
developed has been implemented in C++ and 
dynamic allocation has been suppressed for some 
classes. Indeed, for significant numbers of object 
instantiation/deletion 
dynamic 
allocation 
is 
inefficient and we have designed a specialized static 
allocation (Stroustrup, 2000). A pre-dimensioning 
via large static arrays can be easily achieved thanks 
to current modern computer memory capabilities. 
The state of the executive model is a matrix of 
cellular objects. References on active cells are stored 
in a vector container. A start-pointer and an end-
pointer are delimiting the current calculation domain 
on the vector. Thus initial active cells that are 
completely burned during a simulation run can be 
dynamically ignored in the main loop. At each time 
step, by modifying the position of pointers, new 
tested cells can be added to the calculation domain 
and cells that return in a quiescent state are removed 
from the former. 
6 FIRE SPREADING 
APPLICATION 
The simulation engine we use has been proved to 
achieve real-time simulation (Muzy et al., 2003). 
Moreover, we use a mathematical fire spread model 
already validated and presented in (Balbi et al., 
1998). In this model, a Partial Differential Equation 
(PDE) represents the temperature of each cell. A CA 
is obtained after discretizing the PDE. Using the 
finite difference method leads to the following 
algebraic equation: 
(1)
where Tij is the grid node temperature. The 
coefficients a, b, c and d depend on the time step and 
mesh size considered, t is the real time, tig the real 
ignition time (the time the cell is ignited) and VQ,0 is 
the initial combustible mass.
Figure 5 depicts a simplified temperature curve 
of a cell in the domain. We consider that above a 
threshold temperature Tig, the combustion occurs and 
below a temperature Tf , the combustion is finished. 
The end of the real curve is purposely neglected 
to save simulation time. Four states corresponding to 
the behavior of each cell behavior are defined from 
these assumptions. The four states are: ‘unburned’,
‘heating’, ‘onFire’ and ‘burned’.
 t 
 (Ta, tig)
 Tf  = 333 K
 Tig = 573 K 
 T (Kelvin) 
  heating 
  burned 
onFire 
  unburned 
Figure 6 depicts a fire spreading in a Corsican 
valley, generated using the OpenGL graphics 
library. By looking at this picture we easily 
understand that simulation has to focus only on a 
small part of the whole land. Actually, areas of 
activity just correspond to the fire front, and to the 
cells in front of the latter (corresponding to cells in 
one of the following states: ‘heating’ or ‘onFire’ ) 
During a fire spreading, flying brands ignite new 
part of lands away from the fire. This is an important 
cause of fire spreading. However, tracking activity 
of flying brands is difficult. Firstly, because flying 
brands occur whenever during the simulation time.  
t
t+h
t+2h
?
?
?
?
?
?
?
?
?
?
?
quiescent
non testing
testing
active
k
j
i
t
t
v
k
j
i
k
j
i
k
j
i
k
j
i
k
j
i
dT
e
T
T
b
T
T
a
T
ig
,
)
(
0
,
1
,
1
,
,1
,1
1
,
)
(
)
(





 







D
V
252
A. Muzy et al.
Figure 4: Calculation domain evolution. 
Figure 5: Simplified temperature curve of a cell behavior. 
Figure 6: 3D Visualization of fire spreading. 

Secondly, because they occur far away from the 
calculation domain, thus new calculation allocations 
need to be created dynamically. 
Figure 7 represents a case of multi-ignitions 
during the simulation. Simulation starts with one 
ignition on the center of the propagation domain. 
Then, at time t=7s, a second ignition occurs on the 
top right corner of the propagation domain. Finally, 
at t=12s, two new ignitions occur on the right and 
left bottom of the propagation domain. The last 
picture shows the multiple fire fronts positions at 
t=70s.
Figure 8 describes the DSCA state transitions in a 
fire spread simulation. First the simulation starts 
with the first ignition, which is simulated by an 
output external event of the Generator of Figure 1. 
Then the main simulation loop calculating the fire 
front position is activated. The latter consists in 
calculating the temperature of cells. After, according 
to the calculated temperatures, the calculation 
domain is updated. For each cell of the calculation 
domain, the temperature is calculated using equation 
(1), according to the state of the cells. The 
calculation domain is updated using the algorithm 
described in Figures 3 and 4. Phase transitions 
depend on the temperature of cells.  
At the initialization, only one calculation domain 
corresponding to the one described in Figure 4 is 
generated. Bordering cells of the calculation domain 
are in a ‘testing’ phase and non-bordering cells in a 
‘nonTesting’ one. Remaining cells are ‘quiescent’. If 
the temperature of a ‘testing’ cell fulfills a certain 
threshold temperature Tt, the testing cell will pass in 
the ‘nonTesting’ phase and neighboring ‘testing’
cells will be added to the calculation domain. In the 
fire spread case, this threshold can be fixed slightly 
over the ambient temperature. 
 
During the simulation, the Generator simulates 
the flying brands by sending external events. When 
the DSCA receives the events and updates the 
calculation domain. 
The resulting activity tracking is showed in 
Figure 9. We can notice that active cells correspond 
to the fire front lines, not to the burned and non-
heated areas. 
ignition
!endSimulationTime
or
!inactivity
igniting
activity
tracking
new cells'
temperature
inactive
testing
non
testing
remove
cell
add
neighbors
unburned
burning
burned
bordering cell
non bordering cell
T <= Tf
T >= Tt
T >= Tig
T <= Tf
T >= Tt
k
j
i
k
j
i
k
j
i
k
j
i
k
j
i
k
j
i
dT
T
T
b
T
T
a
T
,
1
,
1
,
,1
,1
1
,
)
(
)
(




 





)
(
0
,
1
,
1
,
,1
,1
1
,
.
)
(
)
(
tig
t
k
j
i
k
j
i
k
j
i
k
j
i
k
j
i
k
j
i
e
dT
T
T
b
T
T
a
T












 
D
X
V
a
j
i
T
T
 
,
calculating
cells'
temperature
Calculating
flame front
position
Internal input
t
t
t
'

 
253
Figure 7: Fire ignitions and propagation. 
Figure 8: Transition state diagram. 
Dynamic Structure Cellular Automata in a Fire Spreading Application

7 CONCLUSION 
Considering the previous discrete event DSCA 
(Barros and Mendes, 1997), new well-designed and 
complementary discrete time DSCA have been 
defined here. These two methodologies allow to 
faithfully guide modelers for modeling and 
simulating discrete event and discrete time cellular 
simulation models. 
DSCA allow to simulate a large range of 
complicated cellular models. Complex phenomena 
can be simulated thanks to basic CA simplicity. We 
hope that even more complex phenomena will be 
able to be simulated thanks to DSCA. To be well 
understood and widely applied, DSCA definition has 
to be as clear and simple as possible. Clearness and 
simplification of DSCA specification will remain 
our objective. 
Another objective will be to improve DSCA 
specification using new experiments. To achieve this 
goal, complexity of fire spread remains an infinite 
challenge for DSCA simulation.  We plan now to 
extend the DSCA specification to the simulation of 
implicit-time models. 
Another important validation of our approach 
concerns network structure changes. Here again, a 
fire spread model taking into account wind effects 
(Simeoni et al., 2003) will allow us to validate 
DSCA network structure changes. This model 
actually 
needs 
to 
dynamically 
change 
the 
neighborhood of burning cells according to the fire 
front shape. 
We would like to thank our research assistant 
Mathieu Joubert, for his technical support and for his 
C++ implementation of the 3D visualization tool 
using OpenGL. 
REFERENCES
Balbi, J. H., P. A. Santoni, and J. L. Dupuy, 1998. 
Dynamic modelling of fire spread across a fuel bed. 
Int. J. Wildland Fire, p. 275-284. 
Barros, F. J., 1997. Modelling Formalisms for Dynamic 
Structure Systems. ACM Transactions on Modelling 
and Computer Simulation, v. 7, p. 501-515. 
Barros, F. J., and M. T. Mendes, 1997. Forest fire 
modelling and simulation in the DELTA environment. 
Simulation Practice and Theory, v. 5, p. 185-197. 
Hill, D. R. C., 1996. Object-oriented analysis and 
simulation, Addison-Wisley Longman, UK, 291 p. 
Jen, E., 1990. A periodicity in one-dimensional cellular 
automata. Physica, v. 45, p. 3-18. 
Mesarovic, M. D., and Y. Takahara, 1975. General
Systems 
Theory: 
A 
mathematical 
foundation,
Academic Press. New York. 
Muzy, A., E. Innocenti, F. Barros, A. Aïello, and J. F. 
Santucci, 2003. Efficient simulation of large-scale 
dynamic structure cell spaces. Summer Computer 
Simulation Conference, p. 378-383. 
Muzy, A., G. Wainer, E. Innocenti, A. Aiello, and J. F. 
Santucci, 2002. Comparing simulation methods for 
fire spreading across a fuel bed. AIS 2002 - Simulation 
and planning in high autonomy systems conference, p. 
219-224.
Nutaro, J., B. P. Zeigler, R. Jammalamadaka, and S. 
Akrekar, 2003. Discrete event solution of gaz 
dynamics winthin the DEVS framework: exploiting 
spatiotemporal heterogeneity. Intrnational conference 
for computational science.
Simeoni, A., P. A. Santoni, M. Larini, and J. H. Balbi, 
2003. Reduction of a multiphase formulation to 
include a simplified flow in a semi-physical 
model of fire spread across a fuel bed. 
International Journal of Thermal Sciences, v. 42, p. 
95–105.
Stroustrup, B., 2000. The C++ Programming Language,
1029 p. 
Wainer, G., and N. Giambiasi, 2001. Application of the 
Cell-DEVS paradigm for cell spaces modeling and 
simulation. Simulation, v. 76, p. 22-39. 
Wolfram, S., 1994. Cellular automata and complexity: 
Collected papers, Addison-Wesly. 
Worsch, T., 1999. Simulation of cellular automata. Future 
Generation Computer Systems, v. 16, p. 157-170. 
Zeigler, B. P., H. Praehofer, and T. G. Kim, 2000. Theory 
of modelling and simulation, Academic Press. 
X(cells)
Y(cells)
25
50
75
100
10
20
30
40
50
60
70
80
90
100
254
A. Muzy et al.
Figure 9: Activity tracking.
ACKNOWLEDGEMENTS

SPEAKER VERIFICATION SYSTEM 
Based on the stochastic modeling 
Valiantsin Rakush, Rauf Kh. Sadykhov 
Byelorusian State University of Informatics and Radioelectronics, 6, P. Brovka str., Minsk, Belarus 
Email: rsadykhov@gw.bsuir.unibel.by 
Keywords: 
Speaker verification, vector quantization, Gaussian mixture models. 
Abstract: 
In this paper we propose a new speaker verification system where the new training and classification 
algorithms for vector quantization and Gaussian mixture models are introduced. The vector quantizer is 
used to model sub-word speech components. The code books are created for both training and test 
utterances. We propose new approaches to normalize distortion of the training and test code books. The test 
code book quantized over the training code book. The normalization technique includes assigning the equal 
distortion for training and test code books, distortion normalization and cluster weights.  Also the LBG and 
K-means algorithms usually employed for vector quantization are implemented to train Gaussian mixture 
models. And finally, we use the information provided by two different models to increase verification 
performance. The performance of the proposed system has  been tested on the Speaker Recognition 
database, which consists of telephone speech from 8 participants. The additional experiments has been 
performed on the subset of the NIST 1996 Speaker Recognition database which include.  
1 INTRODUCTION 
The speaker verification systems so far has been 
based on the different methods. There is a category of 
the algorithms that are using back-end models to 
facilitate the speaker traits extraction (Roberts, W.J.J. 
et al., 1999) (Burton, D., 1987) (Pelecanos, J. et al., 
2000) (Homayounpour, M.M., Challet, G., 1995). 
The neural networks, vector quantization (VQ), and 
Gaussian mixture models (GMM) are constructed 
directly or indirectly for subword or subspeech units 
modeling. Those units can be compared to make a 
verification decision. Also there is a class of the 
speaker verification systems that employ long term 
statistics computation over the speech phrase (Zilca, 
R.D., 2001) (Moonsar, V., Venayagamorthy, G.K., 
2001).  In some systems authors use a combination of 
the methods to improve system performance. The 
methods can be combined in two ways. First way is 
to use one model to improve performance of another 
one (Chun-Nan Hsu et al., 2003) (Singh, G. et al., 
2003) (Sadykhov et al., 2003). Second way is to use 
recognition decision from both models to perform a 
data fusion to calculate a final score (Farrell, K. R. et 
al., 1998) (Farrell, K. R. et al., 1997). The data fusion 
methods can be interpreted using normalization 
and/or Bayessian approach. 
Units comparison requires normalization to be 
applied. In case of VQ models the test and the 
reference 
codebooks 
have 
different 
structure, 
different distortion as well as units of measure for 
distortion. To compare two codebooks, which were 
created on different phrases, we need to normalize 
distortions and their units of measure. In the (Rakush 
V.V., Sadykhov R.H., 1999) authors proposed to 
create reference and test codebooks with equal 
distortion. Here we investigate two additional 
approaches that transform distortions so they can be 
compared. 
The GMM model has the problem with 
parameters initialization. We propose to solve that 
problem using VQ codebook or applying LBG 
algorithm to split Gaussian mixture model starting 
from the single component. Also we use VQ 
codebook for GMM parameters initialization. 
This paper is organized as follows. The following 
section describes modelling approach using VQ and 
GMM models. We will propose new algorithms 
combining VQ and GMM. Then we will discuss 
several techniques for data normalization and fusion, 
and will describe the structure of the experimental 
system, speech corpus and performance measures. 
Finally, we will show our experimental results, that 
will be followed by summary and conclusions.  
255
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 255–261. 

The 
sub-word 
units, 
created 
during 
signal 
transformation from scalar to vector representation 
can be used as structural elements of the speaker 
voice model. Let 
T
N
x
x
x
x
]
,...,
,
[
2
1
 
 - N-
dimensional 
vector, 
coordinates 
of 
which 
^
`
N
k
xk
d
d
1
,
 are real random values and 
represent temporal speech spectrum. It can be 
displayed into N-dimensional vector y . The set  
^
`
M
i
y
Y
i
d
d
 
1
,
 is the code book, where M  - 
the code book size and ^ `
iy
- the set of code vectors.
The N-dimensional space of vectors x  is divided on 
M areas 
M
i
ci
d
d
1,
 to create the code book. The 
vector
iy  corresponds to each area 
ic . If 
ix  lays in 
ic , then 
ix  is quantized to a value of code vector 
iy . It is evident, that we get the error of 
quantization. The deviation x  from y  can be 
determined by a measure of closeness 
)
,
(
y
x
d
¦
 

 


 
K
i
i
i
T
y
x
N
y
x
y
x
N
y
x
d
1
2)
(
1
)
(
)
(
1
)
,
(
,   
         
            (1) 
where N – dimension of the parameters vector. 
The basic idea of the VQ based verification system is 
to build two codebooks using the reference and test 
phrases. Definitely, reference and test phrases will be 
similar in the linguistic sense and will be modeling 
the features of the speaker voice. We assume that 
codebook clusters are modeling the sub-word units of 
speech so the test and reference codebooks should 
have approximately similar clusters for the two 
phrases 
pronounced 
by 
same 
speaker. 
The 
verification decision can be made comparing two 
codebooks using following expression 


¦¦
 
 

 
M
i
K
j
j
i
compare
z
y
MK
D
1
1
2
1
,                 
 
 
(2) 
where 
^
`
M
i
y
Y
i
d
d
 
1
,
 - set of code vectors 
for reference codebook; 
^
`
K
j
z
Z
i
d
d
 
1
,
 - set 
of code vectors for test codebook; 
compare
D
 - 
quantization distortion of test on the reference code 
book.In case of the speaker verification, if the 
codebooks distortion does not exceed predefined 
threshold, then test and training utterances belong to 
the same person.  When the recognition is applied to 
arbitrary speech then duration of the reference and 
test phrases has a huge difference. The reference 
phrase should contain as much as possible linguistic 
material from the speaker. The test phrase should be 
as small as possible but enough to provide acceptable 
verification performance. The reference code book 
should have more code vectors, and the test code 
book should have variable number of vectors K ,
depending  on duration and linguistic content of the 
test phrase. Based on the idea that every cluster 
models sub-word component we assume that 
reference codebook presents model of all possible 
pronunciations for given speaker. We will quantize 
test codebook over reference codebook using 
expression (2) and will expect that distortion for right 
speaker will be minimal. Unfortunately, the distortion 
for the shortest test phrase can be smaller. Also the 
linguistic content of the phrase can influence on the 
distortion value. The distortion will be smaller for 
phrase with less sub-word  components. To avoid 
phrase duration and content impact we propose the  
normalization techniques. First approach Fig. 1 
described in (Rakush V.V., Sadykhov R.H., 1999) is 
based on the equal distortion for the reference and 
test code books. It has main assumption that two 
different code books with equal distortion do model 
same sub-word components.  
Second approach is to use test codebook distortion 
for normalization. In that approach when test 
codebook created on the test phrase the final 
distortion is stored together with code vectors and 
used for decision normalization  
256
V. Rakush and R.K. Sadykhov
VQ-VERIFICATION 
2 BASIC IDEA OF THE 
Figure 1: Normalization using predefined distortion value. 

norm
compare
final
D
D
D
 
  
 
 
 
 
 
 
    (3) 
The Fig.2 shows algorithm for normalization using 
distortion of the test phrase code book. 
Figure 2: Normalization using the test codebook distortion 
value.
The third and last approach is to use number of 
vectors distributed in codebook clusters as a weight 
coefficients 
for 
normalization. 
The 
empirical 
theoretical assumption for that type of normalization 
can be defined as follows. If one cluster has more 
vectors then another one then it should have greater 
weight. Therefore test vectors that fall into it should 
be more meaningful and more significant for 
verification.  This approach is not a pure 
normalization but can increase performance of the 
system because it uses more information from the 
code book then previous ones. The Figure 3 shows 
this normalization method. The VQ algorithm is 
 
used to calculate code book vectors. It is modified to 
produce cluster weights which will be stored along 
with cluster’s center vector and will be used to
 
weighted distance during testing phase. 
Figure 3: Normalization using cluster weigths 
3 THE GMM BASED SPEAKER 
VERIFICATION
The Gaussian mixture model is given by equation  


 
¦
 
 
M
i
i
i
x
b
p
x
p
1
O
,   
 
 
 
                        (4) 
where O  - defines a Gaussian mixture density, x -
N -dimensional feature vector, 
 
M
i
x
bi
,...,
1
,  
-
probability 
distribution 
functions 
for 
model 
components, 
and 
M
i
pi
,...,
1
,  
- 
components 
weights. Every component is a D -dimensional 
Gaussian probability distribution function 
 






¿¾½
¯®­

c


 

i
i
i
i
D
i
x
x
x
b
P
G
P
G
S
1
2
/
1
2
/
2
1
exp
2
1
     
 
(5) 
where 
i
P - mean vectors, 
iG - covariance matrixes. 
The mixture weights values are constrained by the 
equality
1
1
 
¦  
M
i
ip
  
 
 
 
 
 
                             (6) 
The GMM is a good tool, which can virtually 
approximate almost any statistical distribution. Due 
to that property mixture models are widely used to 
create speaker recognition systems. Unfortunately, 
the expectation-maximization (EM) algorithm has 
huge computational time so training procedure takes 
long time. The EM algorithm needs  parameters to be 
257
Speaker Verification System

initialized  also. The number of components of the 
GMM is the same for all speaker voices stored in the 
system. Those are serious disadvantages of the EM 
algorithm that can fixed by applying vector 
quantization technique to GMM models training. 
The initialization step is based on the vector 
quantization algorithm and uses codebook to 
initialize parameters of the GMM.  There is another 
algorithm useful for initializing GMM. Initially that 
algorithm was developed for vector quantization and 
had name LBG algorithm. We will introduce new 
implementation of that algorithm for Gaussian 
mixture models. 
The initial GMM model has only one component. 
The component, which gives maximum probability is 
split into two parts and new model parameters are 
estimated. 
Step 1. Initialization
Component weight 
1
p =1. The mean vector is the 
mean 
of 
all 
feature 
vectors 
¦
 
 
N
i
ix
N
1
1
1
P
.
Covariance matrix is a diagonal matrix of variances 
calculated from the training set of feature vectors.  
Step 2. Splitting component 
Select the mixture component which has 
maximum probability. Increment the mean vector 
parameters on small value 
P
'
 will give two mean 
vectors.
P
P
P
'

 
1
2
     
 
 
 
 
                            (7) 
Step 3. Optimization 
Using EM algorithm estimate new GMM model. 
The EM algorithm can use fixed number of iterations 
or threshold condition. 
Step 3. Iteration 
Steps 2 and 3 can be performed until some 
threshold will be reached.  
Both LBG and K -means initialization algorithms 
showed good performance acceptable for ASV 
systems. The system built on combination of  the 
LBG and EM algorithms are shown on Figure 1.  
4 EXPERIMENTAL RESULTS 
The experiments have been performed on two 
speaker recognition databases. First one is the speech 
database proposed by the Centre of Spoken Language 
Understanding of the Oregon Institute of Science and 
Technology. The data set had 4 female and 4 male 
speakers with 50 utterances for each speaker.  The 
speech was recorded on telephone channel with 
sampling rate 8 kHz. The duration of the test and 
train utterances was approximately equal 10 sec. The 
second database is the SWITCHBOARD speaker 
recognition corpus created by the National Institute 
of Technology in 1996. This database represents data 
in the Microsoft WAV files compressed using 
law

P
. The subset of the development including 20 
males and 20 females  
The preliminary step used linear prediction 
coding and cepstral analysis to build vectors of 
spectral features. Analysis used 30 ms Hamming 
window with 10 ms shift to weight original speech 
signal. There were used vectors with 24 cepstral 
coefficients. 
Also 
as 
recommended 
in 
(Homayounpour, M.M., Challet, G., 1995) first 
derivative and second derivative of the cepstral 
coefficients have been used along with cepstr.  The 
resulting feature vector had size N=72 parameters. 
Figure 4: The structure of the speaker verification system. 
The GMM models had maximum 32 components. 
The code book for GMM initialization and for 
verification had 32 and 256 clusters correspondingly. 
The system is working in two modes: training and 
testing mode. In training mode parameter vectors 
from both models are used to build the code book and 
GMM model for every speaker. In the test mode 
those models are used to verify speaker identity. 
Normalization and data fusion module uses following 
expression to combine results from both models. 
 
 
¦
 
 
n
i
i
i
x
p
x
P
1
D
,   
 
      (8) 
where 
 
x
P
 is a probability of combined system, 
i
D are weights, 
 
x
pi
 is a probability output of the  
258
V. Rakush and R.K. Sadykhov

 0.001
 0.01
 0.1
 1
 0.01
 0.1
 1
False Accepted Rate
False Rejected Rate
Error Expectation Rate
Data fusion
VQ
GMM
th
i
model, and n  is a number of models (two 
models in our case).  
The GMM and code book models weights have 
values 
545
,0
1  
D
and
455
,0
2  
D
. Experimental 
results shown almost identical  performance for VQ 
and GMM algorithms. The data fusion of both 
algorithms improved overall performance of the 
system. The DET curve for LBG initialization and 
EM algorithm is shown on Figure 5. 
In the second section of this paper we were 
discussing the normalization approaches to the 
vector quantization based speaker verification. The 
experimental results for the first approach with equal 
distortion for reference and test codebooks has been 
described in (Rakush V.V., Sadykhov R.H., 1999). 
In this paper we provide experimental result 
comparing 
second 
and 
third 
normalization 
approaches on figure 6. 
Additional experiment using NIST 1996 Speaker 
Verification database SWITCHBOARD shown 
results printed on the figure 7. 
 0.001
 0.01
 0.1
 1
 0.01
 0.1
 1
False Accepted Rate
False Rejected Rate
Error Expectation Rate
w/ norm
w/ norm
w/o norm
w/o norm
259
Speaker Verification System
Figure 5: The DET curve of the ASV system performance. 
Figure 6: The DET curve for weight normalization. 

Figure 7: The weight normalization results tested on the SWITCHBOARD’96 corpus. 
5 CONCLUSION 
The first conclusion is that the speaker verification 
system based on voice modeling is showing 
acceptable performance even for speech degraded 
with telephone channel.  Both VQ and GMM 
models are suitable for different statistical noise 
reduction techniques such as mean cepstral 
subtraction. That makes both algorithms are good 
choice for building automatic speaker verification 
systems for noisy signal. 
The performance measure for the NIST speaker 
detection tasks is the Detection Cost Function 
(DCT) defined as a weighted sum of  probability of 
the False Accepted Rate (FAR) and the probability 
of the False Rejected Rate (FRR) (NIST, 2002)  
FAR
FRR
C Norm
9,0
1,0

 
  
 
 
 
 
 
      (9) 
The minimal value for the DCF has been obtained 
for the best possible detection threshold and has 
value 0,1 for verification system created with data 
fusion methods and value 0,269 for verification 
system created with VQ algorithms only. 
It is obvious from experiments that VQ speaker 
modeling performance is comparable to the GMM 
performance but time required for training is much 
less. In case of the VQ based modeling the number 
of clusters can be determined automatically from 
quantization distortion.
REFERENCES
Roberts, W.J.J., Wilmore J.P., 1999. Automatic speaker 
recognition using Gaussian mixture models. In 
Proceedings of Information, Decision and Control,
IDC 99. 
Farrell, K., Kosonocky, S., Mammone, R., 1994. Neural 
tree 
network/vector 
quantization 
probability 
estimators for speaker recognition. In Proceedings of 
the Neural Networks for Signal Processing, IEEE 
Workshop.
Burton, D., 1987. Text-dependent speaker verification 
using 
vector 
quantization 
source 
coding. 
In 
Acoustics, Speech, and Signal Processing, IEEE 
Transactions.
Zilca, R.D., 2001. Text-independent speaker verification 
using covariance modeling. In Signal Proceesing 
Letters, IEEE. 
Moonsar, 
V., 
Venayagamorthy, 
G.K., 
2001. 
A 
committee of neural networks for automatic speaker 
recognition (ASR) systems. In Proceedings of 
International Joint Conference on Neural Networks,
IJCNN’01.
Pelecanos, J., Myers, S., Shridharan, S., Chandran, V., 
2000. Vector quantization based Gaussian modeling 
 0.01
 0.1
 1
 0.001
 0.01
 0.1
 1
False Rejected Rate
False Accepted Rate
Error Expectation Rate
VQ w/o normalization
VQ w/ normalization
260
V. Rakush and R.K. Sadykhov

for speaker verification, In Proceedings of 15th
International Conference on Pattern Recognition.
Chun-Nan Hsu, Hau-Chang Yu, Bo-Han Yang, 2003. 
Speaker verification without background speaker 
models, 
In 
Acoustics, 
Speech, 
and 
Signal 
Processing, 
IEEE 
International 
Conference, 
ICASSP’03.
Homayounpour, M.M., Challet, G., 1995. Neural net 
approach to speaker verification: comparison with 
second order statistics measures, In Acoustics,
Speech, and Signal Processing, IEEE International 
conference, ICASSP-95. 
Singh, G., Panda, A., Bhattacharyga, S., Srikanthan, T., 
2003. Vector quantization techniques for GMM 
based speaker verification, In Acoustics, Speech, and 
Signal Processing, IEEE International Conference, 
ICASSP’03.
Farrell, K. R., Ramachandran, R.P., Mammone, R.J., 
1998. An analysis of data fusion methods for speaker 
verification, In Acoustics, Speech, and Signal 
Processing, 
IEEE 
International 
Conference, 
ICASSP’98.
Farrell, K.R., Ramachandran, R.P., Sharman, M., 
Mammone, 
R.J., 
1997. 
Sub-word 
speaker 
verification using data fusion methods. In Neural 
Networks for Signal Processing, Proceedings of the 
IEEE Workshop.
Sadykhov, R. Kh., Rakush, V.V., 2003, Training 
Gaussian models with vector quantization for 
speaker verification, In Proceedings of the 3rd
International Conference on Neural Networks and 
Artificial Intelligence. 
Rakush 
V.V., 
Sadykhov 
R.H., 
1999, 
Speaker 
Identification System on Arbitrary Speech  In
Pattern Recognition and Information Processing.
Proc. Of 5th  International Conference. 
The NIST year 2002 speaker recognition evaluation 
plan,
 
2002, http://www.nist.gov/speech/tests/spk/2002/doc.
261
Speaker Verification System

MOMENT-LINEAR STOCHASTIC SYSTEMS
Sandip Roy
Washington State University, Pullman, WA
sroy@eecs.wsu.edu
George C. Verghese
Massachusetts Institute of Technology, Cambridge, MA
verghese@mit.edu
Bernard C. Lesieutre
Lawrence Berkeley National Laboratory, Berkeley, CA
BCLesieutre@lbl.gov
Keywords:
jump-linear systems, linear state estimation and control, stochastic network models.
Abstract:
We introduce a class of quasi-linear models for stochastic dynamics, called moment-linear stochastic systems
(MLSS). We formulate MLSS and analyze their dynamics, as well as discussing common stochastic models
that can be represented as MLSS. Further studies, including development of optimal estimators and controllers,
are summarized. We discuss the reformulation of a common stochastic hybrid system—the Markovian jump-
linear system (MJLS)—as an MLSS, and show that the MLSS formulation can be used to develop some
new analyses for MJLS. Finally, we brieﬂy discuss the use of MLSS in modeling certain stochastic network
dynamics. Our studies suggest that MLSS hold promise in providing a framework for modeling interesting
stochastic dynamics in a tractable manner.
1
INTRODUCTION
As critical networked infrastructures such as air trafﬁc
systems, electric power systems, and communication
networks have become more interdependent, the need
for models for large-scale and hybrid network dynam-
ics has grown. While the dramatic improvement in
computer processing speeds in recent years has some-
times facilitated predictive simulation of these net-
works’ dynamics, the development of models that al-
low not only prediction of dynamics but also network
control and design remains a challenge in several ap-
plication areas (see, e.g., (Bose, 2003)). In this ar-
ticle, we introduce and give the basic analysis for a
class of models called moment-linear stochastic sys-
tems (MLSS) that can represent some interesting sto-
chastic and hybrid system/network dynamics, and yet
are sufﬁciently structured to allow computationally-
attractive analyses of dynamics, state estimation, and
control. Our studies suggest that MLSS hold promise
as a modeling tool for a variety of stochastic and
hybrid dynamics, especially because they provide a
framework for several common stochastic and/or hy-
brid models in the literature, and because they can
capture some network dynamics in a tractable man-
ner.
Our research is partially concerned with hybrid
(mixed continuous- and discrete-state) dynamics.
Stochastic hybrid models whose dynamics are con-
strained to Markovian switching between a ﬁnite
number of linear time-invariant models have been
studied in detail, under several names (e.g., Markov-
ian jump-linear systems (MJLS) and linear jump-
Markov systems) (Loparo et al., 1991; Mazor et al.,
1998).
Techniques for analyzing the dynamics of
MJLS, and for developing estimators and controllers,
are well-known (e.g., (Fang and Loparo, 2002; Costa,
1994; Mazor et al., 1998)). Of particular interest to us,
a linear minimum-mean-square error (LMMSE) esti-
mator for the continuous state of an MJLS was devel-
oped by (Costa, 1994), and quadratic controllers have
been developed by, e.g., (Chizeck and Ji, 1988). We
will show that similar estimation and control analyses
can be developed for MLSS, and hence can be applied
to a wider range of stochastic dynamics.
We are also interested in modeling stochastic net-
work interactions. There is wide literature on stochas-
tic network models that is largely beyond the scope of
this article. Of particular interest to us, several mod-
els from the literature on queueing and stochastic au-
tomata can be viewed as stochastic hybrid networks
(see (Kelly, 1979; Rothman and Zaleski, 1997; Dur-
rett, 1981) for a few examples). By and large, the
aims of the analyses for these models differ from our
aims, in that transient dynamics are not characterized,
and estimators and controllers are not developed. One
263
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 263–271. 

class of stochastic automata of particular interest to
us are Hybrid Bayesian Networks (e.g., (Heskes and
Zoeter, 2003)). These are graphical models (i.e., mod-
els in which stochastic interactions are speciﬁed using
edges on a graph) with hybrid (i.e., mixed continuous-
state and discrete-state) nodal variables.
Dynamic
analysis, inference (estimation), and parameter learn-
ing have been considered for such networks, but com-
putationally feasible methods are approximate.
We observe that stochastic systems models with
certain linear or quasi-linear structures (e.g., linear
systems driven by additive white Gaussian noise,
MJLS) are often widely tractable: statistics of tran-
sient dynamics can be analyzed, and LMMSE esti-
mators and optimal quadratic controllers can be con-
structed.
Several stochastic network models with
quasi-linear interaction structures have also been
proposed—examples include the voter model or inva-
sion process (Durrett, 1981), and our inﬂuence model
(Asavathiratham, 2000). For these network models,
the quasi-linear structure permits partial characteriza-
tion of state occupancy probabilities using low-order
recursions. In this article, we view these various lin-
ear and quasi-linear models as examples of moment-
linear models—i.e., models in which successive mo-
ments of the state at particular times can be inferred
from equal and lower moments at previous times us-
ing linear recursions.
This common representation
for quasi-linear system and network dynamics moti-
vates our formulation of MLSS, which are similarly
tractable to the examples listed above. The MLSS
formulation is further useful, in that it suggests some
new analyses for particular examples and elucidates
some other types of stochastic interactions that can be
tractably modeled.
The remainder of the article is organized as fol-
lows: in Section 2, we describe the formulation and
basic analysis—namely, the recursive computation of
state statistics—of MLSS. We also list common mod-
els, and types of stochastic interactions, that can be
captured using MLSS. Section 3 contains a summary
of further results on MLSS. In Section 4, we refor-
mulate the MJLS as an MLSS, and apply the MLSS
analyses to this model. We also list other common hy-
brid models that can be modeled as MLSS. Section 5
summarizes our studies on using MLSS to model net-
work dynamics. In this context, a discrete-time ﬂow
network model is developed in some detail.
2
MLSS: FORMULATION AND
BASIC ANALYSIS
An MLSS is a discrete-time Markov model in which
the conditional distribution for the next state given
the current state is specially constrained at each time-
step. These conditional distributions are constrained
so that successive moments and cross-moments of
state variables at each time-step can be found as lin-
ear functions of equal and lower moments and cross-
moments of state variables at the previous time-step,
and hence can be found recursively.
Formally, consider a discrete-time Markov process
with an m-component real state vector. The state (i.e.,
state vector) of the process at time k is denoted by
s[k]. We write {s[k]} to represent the state sequence
s[0], s[1], . . . and si[k] to denote the ith element of
the state vector at time k. We stress that we do not
in general enforce any structure on the state variables,
other than that they be real; the state vector may be
continuous-valued, discrete-valued, or hybrid.
For this Markov process, we consider the con-
ditional expectation E(s[k + 1]⊗r | s[k]), for r =
1, 2, . . ., where the notation s[k + 1]⊗r refers to the
Kronecker product of the vector s[k + 1] with it-
self r times and is termed the rth-order state vec-
tor at time k. This expectation vector contains all
rth moments and cross-moments of the state variables
s1[k + 1], . . . , sn[k + 1] given s[k], and so we call the
vector the conditional rth (vector) moment for s[k+1]
given s[k].
We say that the process {s[k]} is rth-
moment linear at time k if the conditional rth moment
for s[k + 1] given s[k] can be written as follows:
E(s[k + 1]⊗r | s[k]) = Hr,0[k] +
r

i=1
Hr,i[k]s[k]⊗i,
(1)
for some set of matrices Hr,0[k], . . . , Hr,r[k].
The Markov process {s[k]} is called a moment-
linear stochastic system (MLSS) of degree "r if it is
rth-moment linear for all r ≤"r, and for all times
k. If a Markov model is moment linear for all r and
k, we simply call the model an MLSS. We call the
constraint (1) the rth-moment linearity condition at
time k, and call the matrices Hr,0[k], . . . , Hr,r[k] the
rth-moment recursion matrices at time k. These re-
cursion matrices feature prominently in our analysis
of the temporal evolution of MLSS.
MLSS are amenable to analysis, in that we can ﬁnd
statistics of the state s[k] (i.e., moments and cross-
moments of state variables) using linear recursions.
In particular, for an MLSS of degree "r, E(s[k +1]⊗r)
(called the rth moment of s[k + 1]) can be found in
terms of the ﬁrst r moments of s[k] for any r ≤"r. To
ﬁnd these rth moments, we use the law of iterated ex-
pectations and then invoke the rth-moment linearity
264
S. Roy, G.C. Verghese and B.C. Lesieutre

condition:
E(s[k + 1]⊗r) = E(E(s[k + 1]⊗r | s[k]))
(2)
= E(Hr,0[k] +
r

i=1
Hr,i[k]s[k]⊗i)
= Hr,0[k] +
r

i=1
Hr,i[k]E(s[k]⊗i).
We call (2) the rth-moment recursion at time k. Con-
sidering equations of the form (2), we see that the ﬁrst
r moments of s[k + 1] can be found as a linear func-
tion of the ﬁrst r moments of s[k]. Thus, by applying
the moment recursions iteratively, the rth moment of
s[k] can be written in terms of the ﬁrst r moments of
the initial state s[0].
The recursions developed in equations of the
form (2) can be rewritten in a more concise form,
by stacking rth and lower moment vectors into a
single vector.
In particular, deﬁning s′
(r)[k]
=

s′[k]⊗r
. . .
s′[k]⊗1
1

, we ﬁnd that
E(s(r)[k + 1]) = ˜H(r)[k]E(s(r)[k]),
(3)
where
˜
H(r)[k] =
(4)
Hr,r[k]
Hr,r−1[k]
. . .
Hr,1[k]
Hr,0[k]
0
Hr−1,r−1[k]
. . .
Hr−1,1[k]
Hr−1,0[k]
...
...
...
...
...
0
. . .
0
H1,1[k]
H1,0[k]
0
. . .
0
0
1
.
Interactions and Examples Captured by MLSS
MLSS provide a convenient framework for represent-
ing several models that are prevalent in the literature.
These MLSS reformulations are valuable in that they
expose similarity in the moment structure of several
types of stochastic interactions, and in that they per-
mit new analyses (e.g., development of linear state es-
timators, or characterization of higher moments) in
the context of these examples. Common models that
can be represented as MLSS are listed:
• A linear system driven by independent, identically
distributed noise samples with known statistics is
an MLSS.
• A ﬁnite-state Markov chain can be formulated as
an MLSS, by deﬁning the MLSS state to be a 0–1
indicator vector of the state of the Markov chain.
• An MJLS is a hybrid model that can be reformu-
lated as an MLSS. This reformulation of an MJLS
is described in Section 4.
• A Markov-modulated Poisson process (MMPP) is
a stochastic model that has commonly been used
to represent sources in communications and man-
ufacturing systems (e.g., (Baiocchi et al., 1991),
(Nagarajan et al., 1991), (Ching, 1997)). It con-
sists of a ﬁnite-state underlying Markov chain, as
well as a Poisson arrival process with (stochastic)
rate modulated by the underlying chain. An MMPP
can be formulated as an MLSS using a state vector
the indicates the underlying Markov chain’s state
and also tracks the number of arrivals over time
(see (Roy, 2003) for details).
The MLSS refor-
mulation of MMPPs highlights that certain state-
parametrized stochastic updates, such as a Pois-
son generator with mean speciﬁed as a linear func-
tion of the current state, can be represented using
MLSS. More generally, various stochastic updates
with state-dependent noise can be represented.
• Certain inﬁnite server queues can be represented as
MLSS (see (Roy, 2003) for details).
Observations and Inputs
Observations and exter-
nal inputs are naturally incorporated in MLSS. These
are structured so as to preserve the moment-linear
structure of the dynamics, and hence to allow devel-
opment of recursive linear estimators and controllers
for MLSS.
At each time k, we observe a real vector z[k] that
is independent of the past history of the system, (i.e.,
s[0], . . . , s[k −1] and z[0], . . . , z[k −1]), given the
current state s[k]. The observation z[k] is assumed to
be ﬁrst- and second-moment linear given s[k]. That
is, z[k] is generated from s[k] in such a way that the
ﬁrst moment (mean) for z[k] given s[k] can be written
as an afﬁne function of s[k]:
E(z[k] | s[k]) = C1,1s[k] + C1,0
(5)
for some C1,1 and C1,0, and the second moment for
z[k] given s[k] can be written as an afﬁne function of
s[k] and s[k]⊗2:
E(z[k]⊗2 | s[k]) = C2,2s[k]⊗2+C2,1s[k]+C2,0 (6)
for some C2,2, C2,1, and C2,0.
We have restricted observations to a form for which
analytical expressions for LMMSE estimators can be
found, yet relevant stochastic interactions that are not
purely linear can be captured.
Observation gener-
ation from the state in MLSS admits the same va-
riety of stochastic interactions—e.g., linear interac-
tions, ﬁnite-state Markovian transitions, certain state-
parameterized stochastic updates—as captured by the
MLSS state update.
This generality allows us to
model, e.g., Hidden Markov Model observations (Ra-
biner, 1986), random selection among multiple lin-
ear observations, and observations of a Poisson arrival
process with mean modulated by the state.
The inputs in our model are structured in such a
way that the next state is ﬁrst- and second-moment
265
Moment-Linear Stochastic Systems
»
»
»
»
»
¼
º
»
»
»
»
»
¼
º

linear with respect to both the current state and the
current input. Speciﬁcally, a system is a 2nd-degree
MLSS with state sequence {s[k]} and input {u[k]}
if the conditional distribution for the next state is in-
dependent of the past history of the system, given
the current state and input, and if there exist matri-
ces H1,1, D1,1, H1,0, H2,2, G2,2, D2,2, H2,1, D2,1,
and H2,0 such that
E(s[k+1] | s[k], u[k]) = H1,1s[k]+D1,1u[k]+H1,0
and
E(s[k + 1]⊗2 | s[k], u[k])
= H2,2s[k]⊗2 + G2,2(s[k] ⊗u[k]) + D2,2u[k]⊗2
+H2,1s[k] + D2,1u[k] + H2,0.
(7)
That is, a Markov process is a 2nd-degree MLSS with
input u[k] if the ﬁrst and second moments and cross-
moments of the next state, given the current state and
input, are ﬁrst- and second-degree polynomials, re-
spectively, of current state and input variables.
We have restricted MLSS inputs to a form for
which analytical expressions for optimal quadratic
controllers can be found, yet several relevant types
of input interactions can nevertherless be represented.
The dependence of the state on the input has the same
generality as the state update.
3
FURTHER RESULTS
In the following paragraphs, we summarize four re-
sults on MLSS that are elaborated further in (Roy,
2003).
Cross Moments
Cross-moments of state variables
across multiple time-steps can be calculated, by re-
cursively rewriting cross-moments across time-steps
as linear functions of moments and cross-moments at
single times. Our expressions for cross-moments are
similar in ﬂavor to the Kronecker product-based ex-
pressions for higher-order statistics of linear systems
given by, e.g., (Mendel, 1975; Swami and Mendel,
1990), but apply to MLSS.
Asymptotics
We develop necessary and sufﬁcient
conditions for convergence (approach to a steady-
state value) of MLSS moments1 in (Roy, 2003). Con-
ditions for moment convergence are useful because
they can help to characterize asymptotic dynamics:
they can in some instances be used to prove conver-
gence of the state itself, or to prove distributional con-
vergence, for example.
1Our study of moment convergence is limited to the state
update of an MLSS; input-output stability has not yet been
considered.
Because the moments satisfy linear recursions,
conditions for convergence can straightforwardly be
expressed in terms of the modes of the moment recur-
sion matrices. However, we note that redundancy in
the moment vectors, which is inherent to the MLSS
formulation, complicates development of good con-
vergence conditions because it allows introduction of
spurious unstable modes that do not actually alter the
moments. We therefore develop reduced forms of the
moment recursions to construct the necessary and suf-
ﬁcient conditions for moment convergence. Details
are in (Roy, 2003).
Estimation
We have developed a recursive al-
gorithm for linear minimum mean square error
(LMMSE) ﬁltering of MLSS. Because tractability of
estimation and control is a primary goal in our formu-
lation of MLSS, it is worthwhile for us to present our
estimator, and to connect it to related literature.
Our LMMSE ﬁlter for an MLSS is a generalization
of the discrete-time Kalman ﬁlter (see, e.g., (Catlin,
1989)), in which the state update and observation
processes are constrained to be moment-linear rather
than purely linear. Equivalently, we can view our ﬁl-
ter as applying to a linear system in which certain
quasi-linear state-dependence of state and observation
noise is permitted.
From this viewpoint, our ﬁlter
is related to the LMMSE ﬁlter introduced in (Zehn-
wirth, 1988), which allows for state-dependent ob-
servation variance. Also of interest to us are linear
estimation techniques for arrival processes whose un-
derlying rate processes are themselves random, and/or
arrival-dependent (e.g., (Snyder, 1972),(Segall et al.,
1975)). Segall and Kailath describe a broad class of
arrival processes of this type, for which a martingale
formulation facilitates nonlinear recursive estimation
(Segall et al., 1975). We also can capture some ar-
rival processes with stochastic rates (e.g., MMPPs),
and hence develop recursive state estimators for these
processes. The arrival processes that are MLSS are a
subset of those in (Segall et al., 1975), but for which
linear ﬁltering is possible, and hence exact ﬁnite-
dimensional estimators can be constructed.
The derivation of our LMMSE ﬁlter for MLSS,
which closely follows the derivation of the discrete-
time Kalman ﬁlter, can be found in (Roy, 2003).
Here, we only present the results of our analysis.
We use the following notation: we deﬁne "sk|k as
the LMMSE estimate for s[k] given z[0], . . . , z[k],
and deﬁne Σk|k
△= E

(s[k] −"sk|k)(s[k] −"sk|k)′
as the error covariance of this estimate.
Also, we
deﬁne "sk+1|k as the LMMSE estimate for s[k +
1] given z[0], . . . , z[k], and let deﬁne Σk+1|k
△=
E

(s[k + 1] −"sk+1|k)(s[k + 1] −"sk|k)′
as the er-
ror covariance of this estimate.
266
S. Roy, G.C. Verghese and B.C. Lesieutre

As with the Kalman ﬁlter, the estimates are found
recursively, in two steps. First, a next-state update is
used to determine "sk+1|k and Σk|k in terms of "sk|k,
Σk|k, and the a priori statistics of s[k]. The next-state
update for our ﬁlter is
"sk+1|k = H1,1"sk|k + H1,0
(8)
Σk+1|k
= H1,1Σk|kH′
1,1 + Mk(E(s[k], E(s[k]⊗2)) (9)
In (9), Mk(E(s[k], E(s[k]⊗2)) is the (a priori) expec-
tation for the conditional variance of z[k] given s[k];
an explicit expression is given in (Roy, 2003).
Second, a measurement update is used to determine
"sk|k and Σk|k in terms of z[k], "sk|k−1, Σk|k−1, and the
a priori statistics of s[k]. The measurement update for
our ﬁlter is
"sk|k = "sk|k−1 + Σk|k−1C′
1,1(C1,1Σk|k−1C′
1,1
+Nk(E(s[k], E(s[k]⊗2)))−1(z[k]−C1,1"sk|k−1
−
C1,0)
Σk|k = Σk|k−1
−Σk|k−1C′
1,1(C1,1Σk|k−1C′
1,1
+Nk

E(s[k]), E(s[k]⊗2)

)−1C1,1Σk|k−1.
(10)
In (10), Nk

E(s[k]), E(s[k]⊗2)

is the a priori ex-
pectation for the conditional variation of s[k+1] given
s[k]; an explicit expression is given in (Roy, 2003).
Control
Considering the duality between linear es-
timation and quadratic control, it is not surprising that
optimal dynamic quadratic control can be achieved
for MLSS, given full state information.
In (Roy,
2003), we use a dynamic programming formulation
for the quadratic control problem to ﬁnd a closed-
form recursion for the optimal control. The optimal
control at each time is linear with respect to the cur-
rent state, in analogy to the optimal quadratic control
for a linear system. The reader is referred to (Roy,
2003) for presentation and discussion of the optimal
controller, as well as a description of relevant litera-
ture.
4
EXAMPLE: MJLS
We describe the reformulation of MJLS as MLSS,
and then present some analyses of MJLS using the
MLSS formulation.
For simplicity, we only detail
the reformulation of a Markovian jump-linear state-
update equation here; reformulation of the entire
input-output dynamics is a straightforward extension.
Let’s consider the update equation
x[k + 1] = A(q[k])x[k] + bk(q[k]),
(11)
where {q[k]} is a 0–1 indicator vector sequence rep-
resentation for an underlying Markov chain with ﬁ-
nite state-space. We denote the transition matrix for
the underlying Markov chain by Θ = [θij]. We de-
note the number of components of x[k] as n, and the
number of statuses in the underlying Markov chain as
m.
For convenience, we rewrite (11) in an extended
form as
˜x[k + 1] = ˜A(q[k])˜x[k],
(12)
where
˜x[k]
=

x[k]
1

and
˜A(q[k])
=

A(q[k])
b(q[k])
0
1

.
To reformulate the jump-linear system as an MLSS,
we deﬁne a state vector that captures both the con-
tinuous state and underlying Markov dynamics of the
jump-linear system. In particular, we deﬁne the state
vector as s[k] = q[k] ⊗˜x[k], and consider the ﬁrst
conditional vector moment E(s[k + 1] | s[k]). Since
s[k] uniquely speciﬁes x[k] and q[k], we can deter-
mine this ﬁrst conditional vector moment as follows:
E(s[k + 1] | s[k]) = E(s[k + 1] | q[k], x[k])(13)
= E(q[k + 1] ⊗˜x[k + 1] | x[k], q[k])
= E(q[k + 1] | q[k]) ⊗˜A(q[k])˜x[k]
= Θ′q[k] ⊗˜A(q[k])˜x[k]
With a little bit of algebra, we can rewrite Equation
13 as
E(s[k + 1] | s[k]) =
(14)
θ11 ˜
A(q[k] = e(1))
. . .
θm1 ˜
A(q[k] = e(m))
...
...
...
θ1m ˜
A(q[k] = e(1))
. . .
θmm ˜
A(q[k] = e(n))
s[k],
where e(i) is an indicator vector with the ith entry
equal to 1.
Equation (14) shows that the ﬁrst-moment lin-
earity condition holds for {s[k]}.
To justify that
higher-moment linearity conditions hold, let’s con-
sider entries of the rth-conditional moment vec-
tor E(s[k + 1]⊗r | s[k]) = E((q[k + 1] ⊗˜x[k +
1])⊗r | x[k], q[k]). Because q[k] is an indicator, the
non-zero entries of the rth-conditional moment vector
can all be written in the form E(qi[k+1] #n
i=1 xi[k+
1]αi | x[k], q[k]), where each αi ≥0, and n
i=1 αi =
"r ≤r.
Given that q[k] = e(i), 1 ≤i ≤m,
E(#n
i=1 xi[k+1]αi | x[k], q[k]) is an "rth degree poly-
nomial of x1[k], . . . , xn[k], say pi[k].
Using that
q[k] is an indicator vector, we can rewrite E(qi[k +
1] #n
i=1 xi[k + 1]αi | x[k], q[k]) as m
i=1 qi[k]pi[k].
Hence, we see that each entry in the rth-conditional
moment vector is linear with respect to the entries in
s[k]⊗r = (q[k + 1] ⊗˜x[k + 1])⊗r, and so the state
vector is rth-moment linear. Some bookkeeping is
267
Moment-Linear Stochastic Systems



required to express the higher-moment linearity con-
ditions in vector form; these expressions are omitted.
We believe that the MLSS reformulation of MJLS
is valuable, because it places MJLS in the context of a
broader class of models, and because it facilitates sev-
eral analyses of MJLS dynamics. Some analyses of
MJLS dynamics that can be achieved using the MLSS
formulation are listed below. Our analyses are illus-
trated using an example MJLS with a two-status un-
derlying Markov chain and scalar continuous-valued
state. The underlying Markov chain for this example
has transition matrix Θ =

0.9
0.1
0.3
0.7

. The scalar
continuous state is updated as follows: if the Markov
chain is in the ﬁrst status at time k, then the time-
(k+1) continuous state is x[k+1] = −0.9x[k]+0.5;
if the Markov chain is in the second status, the time-
(k + 1) continuous state is x[k + 1] = x[k] + 1.
The MLSS formulation allows us to compute
statistics (moments and cross-moments) for both
the continuous-valued state and underlying Markov
status,
as well as conditional statistics for the
continuous-valued state given the underlying Markov
status (at one or several times). Recursions for the
ﬁrst- and second-moments of the continuous-valued
state are well-known (see, e.g., (Costa, 1994)), though
our second-moment recursion differs in form from the
recursion on the covariance matrix that is common
in the literature. We have not seen general compu-
tations of higher-order statistics, or of statistics across
time-steps: the MLSS formulation provides a concise
notation in which to develop recursions for these sta-
tistics. The higher-moment recursions are especially
valuable because they can provide characterizations
for MJLS asymptotics.
We can specify conditions
for δ-moment stability (see, e.g., (Fang et al., 1991))
for all even integer δ in terms of the eigenvalues of
the higher moment recursions. We can also charac-
terize the asymptotics of MJLS in which the state it-
self does not stabilize, by checking for convergence of
moments (to non-zero values). We are currently ex-
ploring whether the methods of (Meyn and Tweedie,
1994) can be used to prove distributional convergence
from moment convergence.
For illustration, ﬁrst- and second-order statistics
of the example MLSS are shown along with a ﬁfty
time-step simulation in Fig. 1.
Additionally, the
steady-state values for the ﬁrst three moments of the
continuous-valued state have been obtained from the
moment recursions, and are shown along with the cor-
responding steady-state distribution. We note that the
ﬁrst three moments provide signiﬁcant information
about the steady-state distribution and, in this exam-
ple, require much less effort to compute than the full
distribution.
The MLSS formulation allows us to develop con-
ditions for moment convergence in MJLS. In (Roy,
0
5
10
15
20
25
30
35
40
45
50
−10
−5
0
5
10 Continuous−Valued State: Sample Run and Statistics
Time
Sample Run, Mean, 
and 2 σ Bounds
0
5
10
15
20
25
30
35
40
45
50
0
0.2
0.4
0.6
0.8
1
Underlying Markov Chain Status
Time
Sample Run and 
Prob. of Status "1"
−20
−15
−10
−5
0
5
10
15
20
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
Steady−State Distribution
Continuous−Valued State
Probability Distribution
Mean = 0.92
St. Dev.=3.4
Skewness=3.8
Figure 1: This ﬁgure illustrates the MLSS-based analy-
sis of moments for an example MJLS. The top plot in
this ﬁgure speciﬁes the continuous-valued state during a 50
time-step simulation, along with the computed mean value
and two standard deviation intervals for this continuous-
valued state. The middle plot indicates the status of the
underlying Markov chain during the simulation and also
shows the probability that the Markov chain is in status “1”.
The bottom plot shows the steady-state distribution for the
continuous-valued state (found through iteration of the dis-
tribution) and lists the moments of this continuous-valued
state (found with much less computation using the moment
recursions).
2003), we have presented necessary and sufﬁcient
conditions for moment convergence of an MJLS with
scalar continuous-valued state and two-status under-
lying Markov chain, in terms of its parameters. Our
example MJLS, with statistics shown in Fig. 1, can
be shown to be moment-convergent.
Our study of
moment convergence complements stability studies
for MJLS (e.g., (Fang and Loparo, 2002)), by allow-
ing identiﬁcation of MJLS whose moments reach a
steady-state but that are not stable (in the sense that
state itself does not reach a steady-state).
268
S. Roy, G.C. Verghese and B.C. Lesieutre

The MLSS reformulation can be used to develop
LMMSE estimators for MJLS. LMMSE estimation of
the continuous-valued state of an MJLS from noisy
observations has been considered by (Costa, 1994).
The observation structure (i.e., the generator of the
observation from the concurrent state) assumed by
(Costa, 1994) can be captured using our MLSS for-
mulation, and in that case our estimator is nearly iden-
tical to that of (Costa, 1994); only the squared error
that is minimized by the two estimators is slightly dif-
ferent.
Our MLSS formulation allows for estimation for a
variety of observation structures. For instance, we can
capture observations that are Poisson random vari-
ables, with parameter equal to a linear function of
the state variables. (Such an observation model may
be realistic, for example, if the state process modu-
lates an observed Poisson arrival process.) We can
also capture other types of state-dependent noise in
the observation process, as well as various discrete
and continuous-valued state-independent noise. Fur-
ther, hybrids of multiple observation structures can be
captured in the MLSS formulation.
Another potential advantage of the MLSS formula-
tion is that, because the underlying Markov status is
part of the state vector, this underlying status can be
estimated. The accuracy of our estimator for the un-
derlying state remains to be assessed. A direction for
future study is to compare our estimator for the un-
derlying status with the nonlinear estimators of, e.g.,
(Sworder et al., 2000; Mazor et al., 1998).
For illustration, we have developed an LMMSE
ﬁlter for our example MJLS. Here, we observe the
(scalar) continuous-valued state upon corruption by
additive white Gaussian noise. Fig. 2 illustrates the
performance of the LMMSE estimator, for a partic-
ular sample run. Our analysis shows that the error
covariance of our estimate is about half the measure-
ment error covariance, verifying that our estimate is
usually a more accurate estimate for the state than the
unﬁltered observation sequence.
5
MLSS MODELS FOR
NETWORK DYNAMICS:
SUMMARY
We believe that MLSS representations for networks
are of special interest because analysis of stochastic
network dynamics is quite often computationally in-
tensive (e.g., exponential in the number of vertices),
while MLSS representations can permit analysis at
much lower computational cost. Below, we summa-
rize our studies of MLSS representations for network
dynamics. More detailed description of MLSS mod-
els for network dynamics can be found in (Roy, 2003).
0
5
10
15
20
25
30
35
40
45
50
−8
−6
−4
−2
0
2
4
6
8
10
Time
x[k] and y[k]
Continuous State and Observations
State x[k]
Observation y[k]
0
5
10
15
20
25
30
35
40
45
50
−8
−6
−4
−2
0
2
4
6
8
Time
x[k] and \hat{x}[k]
Continuous State and Estimate
State x[k]
Estimate \hat{x}[k]
Figure 2: In the left plot, the continuous-valued state and
observations during a 50 time-step simulation of the exam-
ple MJLS are shown. In the right plot, the LMMSE estimate
for the continuous-valued state is compared with the actual
continuous-valued state. The LMMSE estimate is a better
approximation for the continuous-valued state than the ob-
servation sequence.
The following are examples of MLSS models for
network dynamics that we have considered.
• The inﬂuence model was introduced in (Asavathi-
ratham, 2000) as a network of interacting ﬁnite-
state Markov chains, and is developed and mo-
tivated in some detail in (Asavathiratham et al.,
2001). We refer the reader to (Basu et al., 2001)
for one practical application, as a model for con-
versation in a group. The inﬂuence model consists
of sites with discrete-valued statuses that evolve in
time through stochastic interaction. The inﬂuence
model’s structured stochastic update permits for-
mulation of the model as an MLSS, using 0–1 in-
dicator vector representations for each site’s status.
The rth moment recursion permits computation of
269
Moment-Linear Stochastic Systems

the joint probabilities of the statuses of groups of r
sites, and hence the conﬁgurations of small groups
of sites can be characterized using low-order re-
cursions. The MLSS formulation for the inﬂuence
model can also be used to develop good state esti-
mators for the model, and to prove certain results
on the convergence of the model.
• MLSS can be used to represent single-server
queueing networks with linear queue length-
dependent arrival and service rates, operating under
heavy-trafﬁc conditions. The MLSS formulation
allows us to ﬁnd statistics and cross-statistics of the
queue lengths. Of particular interest is the possi-
bility for using the MLSS formulation to develop
queue-length estimators for these state-dependent
models and, indirectly, for Jackson networks (see,
e.g., (Kelly, 1979)).
• In (Roy et al., 2004), we have developed an MLSS
model for aircraft counts in regions of the U.S.
airspace, and have used the MLSS formulation to
compute statistics of aircraft counts in regions. In
the context of this MLSS model, we have also de-
veloped techniques for parameter estimation from
data.
REFERENCES
Asavathiratham, C. (2000).
The Inﬂuence Model:
A
Tractable Representation for the Dynamics of Net-
worked Markov Chains, Ph.D. Thesis. EECS Depart-
ment, Massachusetts Institute of Technology.
Asavathiratham, C., Roy, S., Lesieutre, B. C., and Verghese,
G. C. (2001). The inﬂuence model. IEEE Control
Systems Magazine.
Baiocchi, A., Melazzi, N. B., Listani, M., Roveri, A., and
Winkler, R. (1991).
Loss performance analysis of
an ATM multiplexer loaded with high-speed on off
sources. IEEE Journal on Selected Areas of Commu-
nications, 9:388–393.
Basu, S., Choudhury, T., Clarkson, B., and Pentland, A.
(2001). Learning human interactions with the inﬂu-
ence model.
MIT Media Lab Vision and Modeling
TR#539.
Bose, A. (2003). Power system stability: new opportuni-
ties for control. Stability and Control of Dynamical
Systems with Applications.
Catlin, D. E. (1989). Estimation, Control, and the Discrete
Kalman Filter. Springer-Verlag, New York.
Ching, W. K. (1997). Markov-modulated Poisson processes
for multi-location inventory problems. International
Journal of Production Economics, 52:217–233.
Chizeck, N. J. and Ji, Y. (1988). Optimal quadratic con-
trol of jump linear systems with Gaussian noise in
discrete-time. Proceedings of the 27th IEEE Confer-
ence on Decision and Control, pages 1989–1999.
Costa, O. L. V. (1994). Linear minimum mean square er-
ror estimation for discrete-time markovian jump lin-
ear systems. IEEE Transactions on Automatic Con-
trol, 39:1685–1689.
Durrett, R. (1981). An introduction to inﬁnite particle sys-
tems.
Stochastic Processes and their Applications,
11:109–150.
Fang, Y. and Loparo, K. A. (2002).
Stabilization of
continuous-time jump linear systems. IEEE Transac-
tions on Automatic Control, 47:1590–1603.
Fang, Y., Loparo, K. A., and Feng, X. (1991). Modeling is-
sues for the control systems with communication de-
lays. Ford Motor Co., SCP Research Report.
Heskes, T. and Zoeter, O. (2003). Generalized belief propa-
gation for approximate inference in hybrid bayesian
networks.
Proceedings of the Ninth International
Workshop on Artiﬁcial Intelligence and Statistics.
Kelly, F. P. (1979). Reversibility and Stochastic Networks.
John Wiley and Sons, New York.
Loparo, K. A., Buchner, M. R., and Vasuveda, K. (1991).
Leak detection in an experimental heat exchanger
process: a multiple model approach. IEEE Transa-
tions on Automatic Control, 36.
Mazor, E., Averbuch, A., Bar-Shalom, Y., and Dayan, J.
(1998). Interacting multiple model methods in target
tracking: a survey. IEEE Transactions on aerospace
and electronic systems, 34(1):103–123.
Mendel, J. M. (1975). Tutorial on higher-order statistics
(spectra) in signal processing and system theory: the-
oretical results and some applications. Proceedings of
the IEEE, 3:278–305.
Meyn,
S.
and
Tweedie,
R.
(1994).
Markov
Chains
and
Stochastic
Stability.
http://black.csl.uiuc.edu/ meyn/pages/TOC.html.
Nagarajan, R., Kurose, J. F., and Towsley, D. (1991). Ap-
proximation techniques for computing packet loss in
ﬁnite-buffered voice multiplexers. IEEE Journal on
Selected Areas of Communications, 9:368–377.
Rabiner, L. R. (1986). A tutorial on hidden markov models
and selected applications in speech recognition. Pro-
ceedings of the IEEE, 77(2):257–285.
Rothman, D. and Zaleski, S. (1997). Lattice-Gas Cellular
Automata: Simple Models of Complex Hydrodynam-
ics. Cambridge University Press, New York.
Roy, S. (2003).
Moment-Linear Stochastic Systems and
their Applications. EECS Department, Massachusetts
Institute of Technology.
Roy, S., Verghese, G. C., and Lesieutre, B. C. (2004).
Moment-linear stochastic systems and networks. Sub-
mitted to the Hybrid Systems Computation and Con-
trol conference.
Segall, A., Davis, M. H., and Kailath, T. (1975). Nonlinear
ﬁltering with counting observations. IEEE Transac-
tions on Information Theory, IT-21(2).
Snyder, D. L. (1972). Filtering and detection of doubly sto-
chastic poisson processes. IEEE Transactions on In-
formation Theory, IT-18:91–102.
270
S. Roy, G.C. Verghese and B.C. Lesieutre

Swami, A. and Mendel, J. M. (1990).
Time and lag re-
cursive computation of cumulants from a state space
model.
IEEE Transactions on Automatic Control,
35:4–17.
Sworder, D. D., Boyd, J. E., and Elliot, R. J. (2000). Modal
estimation in hybrid systems. Journal of Mathemati-
cal Analysis and Applications, 245:225–247.
Zehnwirth, B. (1988). A generalization of the Kalman ﬁl-
ter for models with state-dependent observation vari-
ance. Journal of the American Statistical Association,
83(401):164–167.
271
Moment-Linear Stochastic Systems

ACTIVE ACOUSTIC NOISE CONTROL IN DUCTS 
Filipe Morais and J. M. Sá da Costa 
Instituto Superior Técnico,  Technical University of Lisbon,
Dept. of Mechanical Engineering / GCAR - IDMEC
Av. Rovisco Pais, 1049-001Lisboa, Portugal
Email: morais@dem.ist.utl.pt , sadacosta@dem.ist.utl.pt
Keywords:
Active noise control, feedforward control, filtered-reference LMS, modified filtered-reference
LMS, filtered-u, frequency domain filtered-reference LMS.
Abstract:
In this paper existing classical and advanced techniques of active acoustic noise cancellation (ANC) in ducts 
are collected and compared. The laboratory plant used in experience showed a linear behaviour and so the 
advanced techniques were not used. Due to delay on the plant, the feedback classical techniques could not 
be applied. The best results were obtained with the modified filtered-reference LMS (MFX-LMS) and 
filtered-u techniques. A very important conclusion is that the quadratic normalisation is needed to maintain
the algorithms always stable. In this paper 18dB of attenuation of white noise and 35 dB of attenuation of
tonal noise were achieved. Thus, ANC can be applied in a real situation resulting in important noise
attenuations.
1 INTRODUCTION 
Acoustic noise is since a long time considered as 
pollution due to the diverse problems that it causes in 
the human being, both physical, as for instance
deafness, and psychological. As a consequence,
competent authorities tend to enforce restrictive laws 
on the allowed sound levels, and it is thus necessary 
to look for solutions leading to its fulfilment. On the
other hand, acoustic noise is a cause of lack of
productivity. By these reasons, there is a pressing 
need to solve the problem of acoustic noise.
In practice passive solutions for the cancellation
of acoustic noise can be found by simple use of
absorption and reflection phenomena. However, they
are of little use for frequencies below 1000Hz. In
these other cases acoustic noise cancellation (ANC)
based on the principle of interference, should be
used.
The idea of the ANC is 70 years old. One of the
first references remounts to 1934 when P. Lueg
patented some ideas on the subject (Elliot, 2001 and
Tokhi et al., 1992). Lueg addressed ANC in ducts
and in the three-dimensional space. For ducts, Lueg 
considered a microphone that captured the acoustic
noise. The signal from the microphone would pass
through the controller and feed the loudspeaker as
shown in fig. 1. The controller would result in
acoustic waves emitted by the loudspeaker with the
same amplitude of the acoustic noise but in phase
opposition, so that the two waves would cancel each 
other (interference principle). This configuration is
nowadays the most used in ANC applications in
ducts.
Controller
Loudspeaker
Figure 1: Single-channel feedforward control in a duct. 
The purpose of using ANC in ducts is to cancel
the plane waves that are propagated in the duct due to
fans, like in an air conditioner installation. The ANC
mostly used techniques were developed to control
stochastic disturbances, because acoustic noise can
be considered as a disturbance with significant
spectral 
richness. 
Furthermore, 
techniques 
for
stochastic
disturbances 
can
be 
applied 
in
deterministic disturbances but the inverse is not
feasible. ANC techniques for stochastic disturbances
can be divided into two main groups: classical or
advanced. Those of the first group are based on plant
linearity, and consequent validity of the superposition
principle (Ogata, 1997).
Linear techniques can also be applied to 
nonlinear systems, but they usually have bad
performance. Advanced techniques were developed
273
© 2006 Springer. Printed in the Netherlands.
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 273–280. 

to nonlinear plants, although they can be applied to 
linear systems with good performance. However,
they are also more complex and demand more
computational power than the classic ones. For that
reason advanced techniques are not preferred instead 
of classic ones when linear plants are concerned.
Both classic and advanced techniques can be
divided according to the type of control: feedforward
or feedback. In the feedforward control information
is collected in advance about the disturbance and so
the controller can act in anticipation; while the
feedback control has no information in advance
about the disturbance and thus the controller reacts to 
the disturbance. The feedback control is useful when
the acoustic noise is created by several different
sources, or by distributed sources, or when it is not
practical or possible to get information in advance
concerning all the noise sources. However, this is not
the case of ducts because the noise source is well 
defined and acoustic waves are plane and travel in a 
single direction.
In this paper existing feedforward techniques for
ANC in ducts are compared to assess the
performance of these techniques in a real situation. 
In ducts it is possible to have only plane acoustic
waves, rending ANC much simpler since some
acoustic effects are not to be found, as for instance
the diffraction of acoustic waves. In this work the
range of frequencies to be deal with ANC is limited
to the interval [200 Hz; 1000 Hz] since ANC is not
effective for frequencies above 1000 Hz and the
actual set-up used does not allow to go below 200
Hz.
Digital Controller
+
-
+
s(n)
+
x(n)+
G (z)
G (z)
G (z)
+
W(z)
u(n)
e(n)
d(n)
f(n)
s
f
f
Figure 2: Block diagram of feedforward control. 
2 FEEDFORWARD CONTROL 
The general block diagram of the feedforward
control of acoustic plane waves in a duct is found in
fig. 2. The signal x(n) is the reference signal
measured by the reference microphone, d(n) is the
primary noise signal passed through the primary
path, e(n) is the error signal given by the error
microphone, and Gs(z) is the secondary path between
the secondary source and the error sensor. It is 
assumed that the controller is digitally implemented
and made up by a direct filter W(z) and a feedback
filter Ƣf(z). The feedback filter consists of an
estimation of the natural feedback path of the system
Gf(z), i.e., reproduces the influence of the secondary
source to the reference sensor. When Ƣf(z) = Gf(z),
the two feedback loops cancel each other and the
signal that feeds the controller is equal to x(n). In this
situation the control is purely feedforward. In the
situation in which the estimate of Gf(z) is not perfect,
a residue appears from the cancellation of two loops.
If Ƣf(z) is a good estimate of the path Gf(z), the 
residue has a small value and will not affect the
performance of the control. If the estimate of Gf(z) is
poor, this can influence the performance of the
control, that may become unstable. In this situation it
might be necessary to use feedback control
techniques to improve the performance or to stabilize
the control (Elliot, 2001).
Assuming that the two feedback loops cancel
each other completely and that the plants are linear 
and time invariant (LTI), so that the filter W(z) and 
the 
discrete 
transfer
function
Gs(z) 
can 
be
interchanged, the error signal e(n) comes
,
 (1)
T
( )
( )
( )
( )
( )T
e n
d n
n
d n
n
 

 

w r
r
w
where w is a vector with the coefficients of the filter 
and r(n) the vector with the last samples of the 
iltered reference signal r(n) given by:
f
,
(2)
¦

 

 
1
0
)
(
)
(
I
i
i
i
n
x
g
n
r
where the gi are the I coefficients of the discrete 
transfer function Gs(z), assuming that has a FIR
structure.
2.1 Filtered-reference LMS (FX-LMS) 
Algorithm
This algorithm is based on the steepest descent
algorithm, which is mostly used for adapting FIR 
controllers
(Elliot, 2001). The expression for 
adapting the coefficients of controller W(z) of fig. 2 is
iven by:
g
(
1)
( )
J
n
n
P w

 

w
w
w
w
(3)
where J is a quadratic index of performance, equal to
the error signal squared e2(n), and ·/w is the
radient:
g
>
2
( ) ( )
J
@
E
n e n
w
 
w
r
w
 (4)
For this algorithm a simpler version than the one
given by eq. (4) is used, since the expected value of
the product is not reckoned, but only the current
alue of the gradient. Thus,
v
274
F. Morais and J.M. S  da Costa
á

2( )
( )
2 ( )
2 ( ) ( )
e
n
e n
e n
e n
n
w
w
 
 
w
w
r
w
w
 
(5)
The expression for adapting the coefficients of the
controller is given by:
ˆ
(
1)
( )
( ) (
n
n
n e
)
n
D

 

w
w
r
 
(6)
where D = P is the convergence coefficient and
 is the estimate of the filtered reference signal,
obtained with the estimate of the G
ˆ( )
r n
s(z) model. The
algorithm is called filtered-reference LMS because
the filtered reference signal is used to adapt the
coefficients. The block diagram of the algorithm is in
iven in fig. 3.
g
u(n)
x
G (z)
s
e(n)
+
r(n)
G (z)
s
w(n)
+
x(n)
d(n)
Figure 3: Block diagram for FX-LMS algorithm.
If the reference signal x(n) were used instead of the 
filtered reference r(n) to adapt the coefficients, the
adaptation would be wrong because there is a time
shift between the signal x(n) and the error signal 
e(n). This is a consequence of the existence of a time
delay in Gs(z). This algorithm is rather simple to
implement and is numerically stable, being therefore
frequently used (Elliot, 2001).
2.2
In the previous approach the adaptation of the
coefficients
of the controller
W(z) is directly
proportional to the coefficient of convergence D and 
the vector r(n). Sometimes, when r(n) has large
values, the FX-LMS algorithm has a problem of 
amplification of the gradient noise (Haykin, 2002).
The coefficients of the vector r(n) are normalized in
order to solve this problem. Haykin (2002) suggests
dividing the coefficients by the Euclidean norm of 
vector
r(n). The expression for adapting the
coefficients becomes:
2
(
1)
( )
( ) ( )
( )
n
n
n e
n
n
D
G
  


w
w
r
r

 
(7)
where G it is a very small and positive number. This
term allows preventing numerical difficulties when
r(n) is small because the Euclidean norm takes small
values. Elliot (2001) suggests another solution where
the coefficients of vector r(n) are divided by the
inner product of vector r(n), rTr. Whatever the
option is, algorithm NFX-LMS presents the
following advantages over algorithm FX-LMS: faster 
convergence rate and sometimes better performance
of the obtained controller; the algorithm is more
stable when there is a change of the spectral richness
of the reference signal x(n). This normalization of the
filtered reference signal can be applied to other
algorithms.
2.3
For this algorithm another index
of quadratic
performance is used:
 
(8)
2
2
( )
J
E e
n
E
ª
º
 

¬
¼
w w
T
n e n
where E is a positive constant. This performance
index weighs both the average of the error signal e(n)
squared as well as the sum of the squares of the
coefficients of the controller. This performance index
prevents the coefficients of the controller from taking
large values that can render the algorithm unstable
when both the amplitude of the reference signal, x(n),
and its spectral components
undergo variations
Elliot, 2001). The adaptation becomes:
(
ˆ
(
1)
(1
)
( )
( ) ( )
n
n
DE
D

 


w
w
r
. 
(9)
Eq. (9) is different for the FX-LMS algorithm
because of term (1-DE), which is called leakage
factor. This term must take values between 0 and 1
and is normally 1. When it takes another value the
error signal e(n) is not zero and the value of
coefficients decreases with each iteration. Adding the
term (1-DE) to the coefficients adapting equation
allows the increasing of the robustness of the
algorithm. On the other hand the term (1-DE)
reduces the noise attenuation that can be reached.
Thus, the choice of the value for beta must take into
account the robustness of the algorithm and the
reduction of the attenuation. In most applications, the 
use of a small value of beta allows a sufficient
increase of robustness and the attenuation of the
acoustic noise suffers little (Elliot, 2001). The
modification introduced in the FX-LMS algorithm
can also be implemented in the other algorithms.
2.4
The FX-LMS algorithm requires a rather slow
adaptation compared with the plant dynamics so that
the error may be given by eq. (1). This is because
adapting the coefficients is somehow a nonlinearity
which influence depends on the speed of adaptation
(Elliot, 2001). Thus, to make this influence negligible
the adaptation of the coefficients must be very slow 
when compared with the dynamics of the plant. This
275
Leaky LMS Algorithm 
Algorithm (NFX-LMS)
Algorithm (MFX-LMS)
Active Acoustic Noise Control in Ducts
Normalized Filtered-reference LMS 
Modified Filtered-reference LMS 

should be regarded as a disadvantage. The
arrangement shown in fig. 4 allows overcoming this
limitation. In this scheme, the estimated filtered 
reference signal,
, in the adaptation path of the
controller is common to the adaptive filter and to the
adaptation, and has no time shift in relation to the
modified error, e’
ˆ( )
r n
m(n).
-
+
+
+
w(n)
x
r(n)
G (z)
u(n)
G (z)
+
G (z)
w(n)
+
e(n)
x(n)
Controller
Adaptive
filter
s
s
s
e' (n)
m
d(n)
Figure 4: Block diagram for MFX-LMS algorithm.
For this algorithm the adaptation is given by:
ˆ
(
1)
( )
( )
(
m
n
n
n e
)
n
D

 

w
w
r
 
(10)
where em(n) is the modified error, given by:
. 
(11) 
1
1
0
0
ˆ
ˆ
( )
( )
( )
(
)
I
J
m
i
j
i
j
e
n
d n
w n g x n
i
j


 
 
 

 
¦¦
The modified error can be seen as a prediction of the
error for the case where the coefficients of the
controller do not change at each instant. The MFX-
LMS algorithm usually presents convergence rates
larger than those of the FX-LMS algorithm (Elliot,
2001). This is because the adaptive filter and the
plant estimate were interchanged and thus the delay
between the exit of the controller and the error signal
was eliminated. For this reason it is no longer
necessary to consider the delay in the restriction of
the convergence coefficient, and larger steps may be 
used with the MFX-LMS algorithm. However the
MFX-LMS algorithm has the disadvantage
of
requiring more computational means.
2.5
For the FX-LMS algorithm the estimate of the
gradient of eq. (5) was used to adapt the coefficients
of the controller. The estimate of the gradient will be
assumed to be given by the average of the product
r(n)e(n) during N instants. Thus, the adaptation is 
given by:
1
(
)
( )
( ) ( )
n N
l n
n
N
n
l e l
N
D


 

 

¦
w
w
r
 
(12)
In this case, the adaptation is carried only after N
time samples. The use of the average of the product
r(n)e(n) during N instants can be considered as a
more precise estimate of the gradient than the use of
the product r(n)e(n) for each time sample. In practice
adaptation with eq. (12) has a convergence rate very 
similar to the FX-LMS algorithm, since though the
adaptation for eq. (12) has a lower frequency, the
value of the update of the coefficients is larger
(Elliot, 2001). The summation in eq. (12) can be
thought of as an estimate of the crossed correlation
between the filtered reference r(n) and the error
signal e(n). The estimate must be reckoned from
i = 
0 up to I-1, where I is the number of coefficients of
the adaptive filter. For long filters the reckoning of 
the estimate can be inefficient in the time domain,
requiring a large computational effort. For large 
values of I it is more efficient to calculate the cross
correlation in the frequency domain. If discrete
Fourier transform (DFT) with 2N points for the
signals e(n) and r(n) are considered, an estimate of
the cross spectral density can be calculated through:
 
(13)
*
ˆ ( )
( ) ( )
re
S
k
R k E k
 
where k is the index of discrete frequency and *
means the complex conjugate. Some care must be 
taken to prevent the effect of circular convolution.
Thus, before reckoning the DFT of the error signal,
e(n), with 2N points, in the block with 2N points of
the error signal the first N points must be zero. This
will eliminate the non-causal part of the cross
correlation (Elliot, 2001). The expression that gives
he adaptation of the coefficients is: 
t
^
`
*
(
1)
( )
( )
( )
m
m
m
m
IFFT R
k E
k
D


 

w
w
 (14)
where { }+ means the causal part of the cross 
correlation, IFFT is the inverse fast Fourier transform
and D is the convergence coefficient. Rm(k) is directly
obtained multiplying the DFT of the reference signal
X(k) by the frequency response estimate of the
system. This algorithm is called fast LMS. Fig. 5
shows the block diagram of this algorithm.
The advantage of the fast LMS algorithm over
the FX-LMS is that it requires few computations.
Assuming that the implementation of the DFT
requires
2
2
log 2
N
N
multiplications, the FX-LMS 
algorithm requires 2N2 calculations per iteration
hile fast LMS needs
w
2
(16
6log 2
)
N N

.
276
F. Morais and J.M. S  da Costa
á
LMS Algorithm (FX-LMS Freq) 
Frequency Domain Filtered-reference 

s
W(z)
G (z)
e(n)
d(n)
+
+
E(k)
H
R (k)
R(k)
X(k)
x(n)
^G(k)
Conjugate
Get
first N 
points
D
IFFT
FFT
x
x
e
0
Insert Zero
Block
FFT
Concatenate
two blocs
Figure 5: Block diagram for FX-LMS Freq algorithm.
2.6 Filtered-u Algorithm
Up to now Finite Impulse Response (FIR) filters 
have been considered to build the controllers.
However, Infinite Impulse Response (IIR) filters can
be used as well. In this case, the equivalent to fig.2
for IIR controllers is shown in fig. 6.
t(n)
H(z)
+
1-A(z)
B(z)
u(n)
f
s
G (z)
G (z)
e(n)
d(n)
s(n)
x(n)
+
+
+
+
Figure 6: Block diagram for IIR controller.
Compared with the block diagram of fig. 2 for the
FIR controllers, we can notice that this does not
possess a specific feedback to cancel the natural 
feedback path of the system. In this case the 
recursive characteristic of IIR controllers is assumed
to deal with the feedback path problem. However,
practice shows that if this estimation is included
numerical 
stability
is
guaranteed 
and 
the
performance is improved.
The filtered-u algorithm uses IIR filter as 
controller. It is based on the recursive LMS (RLMS)
algorithm (see Elliot (2001) or Haykin (2002)). Fig. 
7 shows the block
diagram of the filtered-u
algorithm. The adaptation of the coefficients aj and bi
is given by:
1
1
(
1)
( )
( ) (
n
n
e n
)
n
J
D

 

a
a
t
)
n
 
(15)
2
2
(
1)
( )
( ) (
n
n
e n
J
D

 

b
b
r
 
(16)
where D1, D2 are the convergence coefficients, t(n)
and r(n) are respectively the filtered output and the
filtered reference, and J1 and J2 are the forgetting
factors.
H(z)
u(n)
f
i
j
G (z)
G (z)
a (n)
b (n)
G'(z)
G'(z)
e(n)
d(n)
t(n)
r(n)
s(n)
x(n)
+
+
+
+
+
+
s
Figure 7: Block diagram for filtered-u algorithm.
The use of different convergence coefficients may be
shown in practice to allow for higher convergence
rates and the use of leakage factors slightly under 1
allows for a greater robustness of the algorithm
(Elliot, 2001). The plants modified response, G'(z), is
equal to Gs(z). For that purpose, the coefficients of
the controller H(z) are assumed to be very slowly
adapted in comparison to the dynamics of the system 
of the system Gs(z). The same had already been
assumed for the adaptation of the FIR controller, but
for the adaptation of the IIR controller this is even
more necessary since the controller is recursive. One
of the interesting characteristics of the filtered-u
algorithm
is that it presents a self-stabilising
behaviour that is also to be found in RLMS
algorithms (Elliot, 2001). During the adaptation of
the controller, if a pole leaves the unit-radius circle, 
the natural evolution of filtered-u algorithm brings it
back inside. Although some researchers have
addressed this behaviour, still it was not possible to 
discover the mechanism that results in this self-
stabilising 
property 
(Elliot, 
2001). 
The 
self-
stabilising behaviour is found in many practical
applications, and that is why the filtered-u algorithm
is the most used in active cancellation of noise
applications (Elliot, 2001).
3 EXPERIMENTAL SET-UP
The experimental set-up used is shown in Fig. 8. A
PVC pipe with 0.125 m of diameter and 3 m of
length was used for simulating the cylindrical duct.
Given the diameter of the duct, the cut-on frequency,
which is the frequency above which waves may no 
longer be considered plane, is 1360 Hz. To simulate
the acoustic noise to
cancel a conventional
loudspeaker was placed in one of the ends of the
duct. At 1.25 m away from this end two loudspeakers
are placed to act as source of acoustics waves for 
noise cancellation. For the detection of acoustic noise
a microphone, placed 0.08 m away from the primary
noise source, is used. The error microphone is placed
t the opposite end of the primary noise source.
a
277
Active Acoustic Noise Control in Ducts

Windows - Matlab
xPC Target
NI-DAQ 6024E
A/D
20dB
0dB
Amp.
2
1
2
1
D/A
Fc = 1050Hz
Low-Pass Filter
Pre-Amp
Slave Computer
Master Computer
Reference
Mic.
Source
Cancellation
Error
Mic.
Noise
Source
Figure 8: Block diagram of experimental setup.
Besides the duct, loudspeakers and microphones,
the experimental set-up consists of: four low-pass
filters that allow filtering the signals to remove the
effects of aliasing and zero-order-hold; an amplifier
that allows amplifying the signals that feed the
loudspeakers; pre-amplifiers for the microphones;
and two computers, one the slave act has a digital
controller and the other the master is used for data
analysis. The slave computer is a Pentium III 
733MHz with 512MB of RAM memory, running on
xPC Target, having a data acquisition board NI-DAQ
6024E. Algorithms have been implemented as S-
Functions in the Matlab/Simulink environment.
Due to hardware restrictions on the cancellation
source this set-up cannot generate relevant signals
for frequencies
below
200 Hz. Therefore,
the
frequency range where acoustic noise cancellation is
intended is restricted to the frequency bandwidth of 
[200 Hz - 1000 Hz].
4 IDENTIFICATION
The models used are discrete in time since the
implementation of the controller is made using a
digital computer. Therefore, the simulations will be
based on discrete models. This requires the models to
include the devices associated with the discretisation
and restoration
of the signals,
A/D
and D/A
conversions, anti-aliasing and reconstruction filters, 
and the dynamic of the microphones, loudspeakers
and amplifiers associated to the experimental set-up. 
Assuming that the behaviour of these devices is
linear, then each one can be represented by a discrete
ransference function. The necessary models are: 
t
Gs(z) - secondary acoustic path: includes computer - 
secondary source - error microphone - computer;
Gf(z) - acoustic feedback path: includes computer-
secondary source - reference microphone-computer.
Models have been obtained for the sampling
frequency of 2500 Hz (sampling time 0.4ms) because
that allows the Nyquist frequency of 1250Hz, to be
slightly larger than the superior limit of the frequency
range to cancel, 1000 Hz. FIR and ARX models have
been obtained. Variance account for (VAF) criterion
and root mean square (RMS) have been used for
models validation. Table 1 shows the results obtained
in these identifications.
Table 1:  Order, VAF and RMS of the obtained models. 
Order
FIR
ARX
VAF (%)
RMS (V) 
Model
I
na
nb
FIR
ARX
FIR
ARX
Gs(z)
500
150
150
99.96 99.94
0.0193
0.0195
GF(z)
450
150
150
99.60 99.57
0.0363
0.0373
As shown above the obtained models have
excellent performances. This shows the plant to have
a linear behaviour being unnecessary to appeal to
ANC advanced techniques.
5 EXPERIMENTAL RESULTS
The previously mentioned algorithms have been
implemented and test for different noise conditions in
the duct. However, before presenting the results it
must be point out that the use of the normalisation of
the filtered reference signal was very important.
Experiences have shown that the normalised LMS 
technique has a significant influence in the behaviour
of the algorithms. In fig. 9 the evolution of the
attenuation is shown for the FX-LMS algorithm
when the variance of white noise changed, for the
following cases: the filtered reference signal was not
normalized, was normalised using the Euclidean
norm, 
and 
was 
normalised 
using 
quadratic
normalization. The behaviour of the other algorithms
is similar. In the figures that follow, attenuation is 
iven by the expression
g
2
10
2
 (
)
10log
E e
Attenuation dB
E d
§
ª
º
¬
¼
¨
 
¨
¸
ª
º
¬
¼
©
¹
·
¸ 
(18)
where e is the error signal, d the disturbance and E[ ]
is the expected value operator. In this case the
expected value is given by the average of last 50 
samples.
278
F. Morais and J.M. S  da Costa
á

0
50
100
150
200
-25
-20
-15
-10
-5
0
5
10
15
Time (s)
Attenuation (dB)
Without normal.
Quadratic norm
Euclidean norm
Figure 9: Evolution of attenuation for the FX-LMS
algorithm.
As can be observed the normalization of the
filtered reference signal allows obtaining higher
attenuations. The quadratic norm is the only one that
ensures the stability of the algorithms when the
spectral power changes. If this were not the case
different adaptation steps would have to be used to
keep the algorithms stable.
For the comparison of the algorithms two types
of disturbances had been considered: white noise and
pure tones. The frequency range of the white noise is 
[200 Hz; 1000 Hz], for the reason explained before.
Tones under 200 Hz have also not been used.
Parameters in the algorithms were chosen based
upon other experiences that had shown the influence
of parameters in algorithms performance. These
alues are: 
v
x FX-LMS: w = 200, P = 0.10; 
x MFX-LMS: w = 400, P = 0.1;
x Filtered-u: na = 150, nb = 100, Pa = 0.01,
Pb = 0.025;
x FX-LMS Freq: w = 256, P = 0.16.
Common to all the algorithms are the leakage factor, 
equal to one, and the normalization method, which
was the quadratic norm.
Results are shown in fig. 10-13 for different
types of noise to be cancelled, and Table 2 that
indicates the computational burden for the white
oise case. 
n
x
White noise
0
50
100
150
200
250
300
-20
-18
-16
-14
-12
-10
-8
-6
-4
-2
0
Time (s)
Attenuation (dB)
FX-LMS
Mod FX-LMS
Filtered-U
FX-LMS Freq
Figure 10: Evolution of attenuation for white noise.
Table 2: Execution time of each iteration for the white
noise case.
Algorithm
FX-
LMS
MFX-
LMS
Filtered
-u
FX-LMS
Freq
Average time (ms)
0.044
0.067
0.081
0.027
Maximum time (ms)
0.047
0.081
0.089
0.065
x
Pure tones: 320 Hz + 640 Hz + 960Hz.
All pure tones have the same spectral power. The
adaptation steps of FX-LMS and FX-LMS Freq
algorithms had to be reduced so that they would
remain stable. Steps used were P = 0,03 for the FX-
LMS and P = 0,06 for the FX-LMS Freq.
0
5
10
15
20
25
30
-40
-35
-30
-25
-20
-15
-10
-5
0
Time (s)
Attenuation (dB)
FX-LMS
MFX-LMS
Filtered-u
FX-LMS Freq
The two previous figures show that the MFX-
LMS algorithm obtains a larger attenuation sooner
but the filtered-u algorithm obtains slightly larger
attenuations. These two algorithms get the best
performances of the four. Worst of them all is the
FX-LMS Freq, even though it presents the most
reduced average time for executing each iteration.
This shows how efficient algorithms are in the 
frequency domain. However, the execution time of 
each iteration is not important in this case since all
times are clearly under the sampling time of 0.4ms.
279
Active Acoustic Noise Control in Ducts
Figure 11: Evolution of attenuation for pure tones.

This is because of the high computational power of
the slave computer.
Robustness to the variations of the model of the
eedback path
f
An important question is the robustness to the
degradation of the model of the acoustic feedback
path Gf(z), since when this model becomes poor the
simplification assumed on point 2.1 (that the model
cancels the feedback path exactly) is no longer
verified. If the residual of the cancellation is large,
the performance of the algorithms based on scheme
of Fig. 2 will degrade and may even be unstable.
The filtered-u algorithm can deal with the
feedback path problem. However, using the model of
Fig. 6, this algorithm has revealed to be unstable on
start. To solve this problem the adaptation steps had
to be reduced, and thus, have a slower evolution of
attenuation. Using the scheme of fig. 2 with filtered-
u algorithm has proved to be more robust and have a
faster and more regular evolution of attenuation.
That is why two experiences have been carried
out in which the performance of estimated model of 
Gf(z) was reduced. In the two following figures the
results for the MFX-LMS algorithms and filtered-u
algorithms are shown. Only those are shown because
they are the ones with better performances, as was
seen above. Parameters used in the algorithms are 
those given above.
Figures 12 and 13 show that the filtered-u
algorithm is more robust to variations of the
estimated model of Gf(z) model even though it leads
to more irregular evolutions. This shows that the
filtered-u algorithm is the one that should be applied
in practice since it has a performance identical to the
MFX-LMS but is more robust to modelling errors.
0
50
100
150
200
250
300
-20
-18
-16
-14
-12
-10
-8
-6
-4
-2
0
Time (s)
Attenuation (dB)
VAF = 99.6%
VAF = 99.0%
VAF = 95.0%
VAF = 90.0%
Figure 12: Evolution of attenuation for MFX-LMS 
algorithm for different estimated models of Gf(z).
0
50
100
150
200
250
300
-20
-18
-16
-14
-12
-10
-8
-6
-4
-2
0
Time (s)
Attenuation (dB)
VAF = 99.6%
VAF = 99.0%
VAF = 95.0%
VAF = 90.0%
Figure 13: Evolution of attenuation for filtered-u algorithm
for different estimated models of Gf(z).
6 CONCLUSIONS 
This paper evaluates the use of feedforward ANC to
cancel noise in ducts. The FX-LMS, NFX-LMS, Leaky
LMS, MFX-LMS, FX-LMS Freq and the Filtered-u
algorithms 
have 
been 
considered.
The 
best
performance was achieved with the
filtered-u
algorithm. Active cancellation of acoustic noise was
seen to be possible in practice since attenuations
obtained were about 18 dB for white noise and 35 dB
for pure tones. Moreover, algorithms were seen to be
robust when models degrade.
In what concerns the algorithms it was shown
that the normalization of the filtered reference signal
is of extreme importance allowing to ensure the
stability of the algorithms as well as better
attenuations. However this happens only for the
quadratic norm.
REFERENCES
Elliot, S. J., 2001.  Signal Processing  for  Active 
Haykin, Simon, 2002. Adaptive Filter Theory. Prentice
Hall, New Jersey, 4th edition.
Ogata, Katsuhiko, 1997. Modern Control Engineering.
Prentice Hall, New Jersey, 3rd edition. 
Oppenheim, Alan V., Schafer, Ronald W. and Buck, John 
R., 1999. Discrete-time Signal Processing. Prentice
Hall, New Jersey, 2nd edition. 
Tokhi, M. and Leitch, R. R., 1992. Active Noise Control.
Oxford University Press, New York.
280
F. Morais and J.M. S  da Costa
á
Control.
 Academic Press, London.

HYBRID UML COMPONENTS FOR THE DESIGN OF
COMPLEX SELF-OPTIMIZING MECHATRONIC SYSTEMS∗
† and
ngineering Group, University of Paderborn
burmi@upb.de, hg@upb.de
Pohlweg 98, D-33098 Paderborn, Germany
Oliver.Oberschelp@mlap.de
Keywords:
Mechatronic, Self-optimization, Control, Hybrid Systems, Components, Reconﬁguration, Uniﬁed Modelling
Language (UML), Real-Time
Abstract:
Complex technical systems, such as mechatronic systems, can exploit the computational power available to-
day to achieve an automatic improvement of the technical system performance at run-time by means of self-
optimization. To realize this vision appropriate means for the design of such systems are required. To support
self-optimization it is not enough just to permit to alter some free parameters of the controllers. Furthermore,
support for the modular reconﬁguration of the internal structures of the controllers is required. Thereby it
makes sense to ﬁnd a representation for reconﬁgurable systems which includes classical, non-reconﬁgurable
block diagrams. We therefore propose hybrid components and a related hybrid Statechart extension for the
Uniﬁed Modeling Language (UML); it is to support the design of self-optimizing mechatronic systems by al-
lowing speciﬁcation of the necessary ﬂexible reconﬁguration of the system as well as of its hybrid subsystems
in a modular manner.
1
INTRODUCTION
Mechatronic systems are technical systems whose be-
havior is actively controlled with the help of computer
technology. The design of these systems is marked by
a combination of technologies used in mechanical and
electrical engineering as well as in computer science.
The focus of the development is on the technical sys-
tem whose motion behavior is controlled by software.
The increasing efﬁciency of microelectronics, par-
ticularly in embedded systems, allows the develop-
ment of mechatronic systems that besides the re-
quired control use computational resources to im-
prove their long term performance.
These forms of
self-optimization allow an automatic improvement of
a technical system during operation which increases
the operating efﬁciency of the system and reduces the
operating costs.
∗This work was developed in the course of the Spe-
cial Research Initiative 614 - Self-optimizing Concepts and
Structures in Mechanical Engineering - University of Pader-
born, and was published on its behalf and funded by the
Deutsche Forschungsgemeinschaft.
†Supported by the International Graduate School of Dy-
namic Intelligent Systems. University of Paderborn
A generally accepted deﬁnition of the term self-
optimization is difﬁcult to ﬁnd. In our view, the core
function of self-optimization in technical systems is
generally an automatic improvement of the behavior
of the technical system at run-time with respect to de-
ﬁned target criteria. In a self-optimizing design, de-
velopment decisions are being shifted from the design
phase to the system run-time.
There are two opportunities of optimization during
runtime. The ﬁrst is to optimize parameters (Li and
Horowitz, 1997) the second is to optimize the struc-
ture. However, alteration of the free parameters of the
system will not lead very far because many charac-
teristics, in particular those of the controller, can be
altered only in the internal structures and not just by
a modiﬁcation of parameters (F¨ollinger et al., 1994;
Isermann et al., 1992).
While most approaches to hybrid modeling (Hen-
zinger et al., 1995; Bender et al., 2002; Alur et al.,
2001) describe how the continuous behavior can be
modiﬁed when the discrete control state of the sys-
tem is altered, we need an approach that allows the
continuous behavior as well as its topology to be al-
tered in a modular manner to support the design of
self-optimizing systems.
Sven Burmester
Warburger Str. 100, D-33098 Paderborn, Germany
Holger Giese
Oliver Oberschelp
281
© 2006 Springer. Printed in the Netherlands.
Software E
Mechatronic Laboratory Paderborn, University of Paderborn
J. Braz et al. (eds.), Informatics in Control, Automation and Robotics I, 281–288. 

Our suggestion is to integrate methods used in me-
chanical engineering and software engineering to sup-
port the design of mechatronic systems with self-
optimization. We therefore combine component di-
agrams and state machines as proposed in the forth-
coming UML 2.0 (UML, 2003) with block diagrams
(F¨ollinger et al., 1994) usually employed by control
engineers. The proposed component-based approach
thus allows a decoupling of the domains: A control
engineer can develop the continuous controllers as
well as their reconﬁguration and switching in form of
hybrid components. A software engineer on the other
hand can integrate these components in his design of
the real-time coordination. As this paper focusses the
modeling aspect we set simulation aside. Simulation
results can be found in (Liu-Henke et al., 2000).
In Section 2 we will examine related work. Section
3 discusses problems resulting from reconﬁguration
by means of an application example. In Section 4,
our approach to hybrid modeling with an extension of
UML components and Statecharts will be described.
Thereafter we describe our model’s runtime platform
in Section 5 and sum up in Section 6 with a ﬁnal con-
clusion and an outlook on future work.
2
RELATED WORK
A couple of modeling languages have been proposed
to support the design of hybrid systems (Alur et al.,
1995; Lamport, 1993; Wieting, 1996). Most of these
approaches provide models, like linear hybrid au-
tomata (Alur et al., 1995), that enable the use of ef-
ﬁcient formal analysis methods, but lack of methods
for structured, modular design, that is indispensable
in a practical application (M¨uller and Rake, 1999).
To overcome this limitation, hybrid automata have
been extended to hybrid Statecharts in (Kesten and
Pnueli, 1992). Hybrid Statecharts reduce the visual
complexity of a hybrid automaton through the use of
high-level constructs like hierarchy and parallelism,
but for more complex systems further concepts for
modularization are required.
The hybrid extensions HyROOM (Stauner et al.,
2001), HyCharts (Grosu et al., 1998; Stauner, 2001)
and Hybrid Sequence Charts (Grosu et al., 1999) of
ROOM/UML-RT integrate domain speciﬁc model-
ing techniques. The software’s architecture is spec-
iﬁed similar to ROOM/UML-RT and the behavior
is speciﬁed by statecharts whose states are asso-
ciated with systems of ordinary differential equa-
tions and differential constraints (HyCharts) or Mat-
lab/Simulink block diagrams (HyROOM). HyROOM
models can be mapped to HyCharts (Stauner et al.,
2001). Through adding tolerances to the continuous
behavior this interesting speciﬁcation technique en-
ables automatic implementation, but support for the
modular reconﬁguration is not given.
In (Conrad et al., 1998) guiding principles for the
design of hybrid systems are sketched. It describes
how to apply techniques that are used in automo-
tive engineering, like the combination of statecharts,
blockdiagrams and commercial tools. Following this
approach hybrid systems need to be decoupled into
discrete and continuous systems in the early design
phases. Therefore a seamless support and a common
model are not provided.
Within the Fresco project the description language
Masaccio (Henzinger, 2000) which permits hierar-
chical, parallelized, and serially composed discrete
and continuous components has been developed. A
Masaccio model can be mapped to a Giotto (Hen-
zinger et al., 2003) model, that contains sufﬁcient in-
formation about tasks, frequencies, etc. to provide an
implementaion. The project provides a seamless sup-
port for modeling, veriﬁcation and implementation,
but our needs for advanced modeling techniques that
support dynamic reconﬁguration are not addressed.
3
MODELING
RECONFIGURATION
We will use the switching between three controller
structures as a running example to outline the result-
ing modeling problems. The concrete example is an
active vehicle suspension system with its controller
which stems from the Neue Bahntechnik Paderborn3
research project. The project has been initiated and
worked upon by several departments of the Univer-
sity of Paderborn and the Heinz Nixdorf Institute. In
the project, a modular rail system will be developed;
it is to combine modern chassis technology with the
advantages of the Transrapid4 and the use of existing
rail tracks. The interaction between information tech-
nology and sensor/actuator technology paves the way
for an entirely new type of mechatronic rail system.
The vehicles designed apply the linear drive technol-
ogy used in the Transrapid, but travel on existing rail
tracks. The use of existing rail tracks will eliminate an
essential barrier to the proliferation of new railbound
transport systems (L¨uckel et al., 1999).
Figure 1 shows a schema of the physical model of
the active vehicle suspension system.
The suspen-
sion system of railway vehicles is based on air springs
which can be damped actively by a displacement of
their bases. The active spring-based displacement is
effected by hydraulic cylinders. Three vertical hy-
draulic cylinders, arranged on a plane, move the bases
3http://www-nbp.upb.de/en
4http://www.transrapid.de/en
282
S. Burmester, H. Giese and O. Oberschelp

A
B
C
prop.- valves
A / D
controller
D / A
sensors
hydr. pump
car body
hydr. actuators
air springs
to the
actuators
z
y
a
of the air springs via an intermediate frame, the sus-
pension frame. This arrangement allows a damping of
forces in lateral and vertical directions. In addition, it
is also possible to regulate the level of the coach and
add active tilting of the coach body. Three additional
hydraulic cylinders allow a simulation of vertical and
lateral rail excitation (Hestermeyer et al., 2002). The
vital task for the control system is to control the dy-
namical behavior of the coach body. In our example,
we will focus only on the vertical dynamic behavior of
the coach body. The overall controller structure com-
prises different feedback controllers, e.g., for control-
ling the hydraulic cylinder position and the dynamics
of the car body.
reference overall
lateral acceleration
vertical acceleration
decoupling
tuning
forces
coupling
DT
DT
DT
XZ, A
XZ, B
XZ, C
Yairsp
Zairsp, L
Z airsp, R
Y
a
Z
Z
.
Y
.
a.
Flift
M tilt
F lat.
XZ, A, ref.
XZ, B, ref.
XZ, C, ref.
Yref. Zref.
a ref.
reference values
to cylinder A, B, C
(local controller)
}
x..
abs.
z..
abs.
M tilt
tilt torque
Flift
lift force
F lat.
lateral force
Y,
a
Z,
body coordinates
airsp
L
R,
Y, Z , Z
airspring positions
XZ, A, B, C
cylinder positions
The schema of the reference controller for the over-
all body controller is depicted in Figure 2. The sub-
ordinated controller is not displayed here for reasons
of clarity. The controller essentially consists of the
blocks decoupling, tuning forces, and coupling. In the
block decoupling the kinematics of the cylinders is
converted into Cartesian coordinates for the descrip-
tion of the body motion. The actual control algorithm
is in the block tuning forces. Here the forces are com-
puted which are to affect the mechanical structure.
In the block coupling the forces and torques are con-
verted again into reference values for the subordinated
cylinder controller (Liu-Henke et al., 2000).
A common representation for the modeling of
mechatronic systems which have been employed here
are hierarchical block diagrams. This kind of repre-
sentation has its seeds in control engineering, where
it is used to represent mathematic transfer functions
graphically.
It is widely-used in different CAE-
tools. Block diagrams consist generally of function
blocks, specifying function resp. behavior and hier-
archy blocks grouping function and hierarchy blocks.
This allows a structured draft and reduces the over-
all complexity of a block diagram. Between single
blocks exists connections or couplings, which can
have the shape of directed or non-directed links. With
directed links data is exchanged whereas non-directed
ones often describe functional relations or physical
links, such as a link between mass and spring in multi-
body system representation. While parameter opti-
mization can be described using simply an additional
connection for the parameter, the static structure of
block diagrams does not permit to model structural
modiﬁcations (Isermann et al., 1992).
We can, however, use special switches or fading
blocks to describe the required behavior. The con-
troller in our example has two normal modes: Ref-
erence and absolute. The controller reference uses a
given trajectory that describes the motion of the coach
body zref = f(x) and the absolute velocity of the
coach body ˙zabs (derived from ¨zabs). The zref tra-
jectory is given for each single track section. A track
section’s registry communicates this reference trajec-
tory to the vehicle. In case a reference trajectory is
not available, another controller which requires only
the absolute velocity of the coach body ˙zabs for the
damping of the coach-body motion has to be used.
Besides the regular modes another controller
named robust is required for an emergency; it must be
able to operate even if neither the reference trajectory
nor the measurement of the coach-body acceleration
are available (see Figure 3).
z..z
Zref.
abs.
XZ, A, ref.
XZ, B, ref.
XZ, C, ref.
normal
“reference”
“absolute”
failure
“robust”
body control
common
inputs
t0
tend
1
0
f
(t)
Switch
1-f
(t)
Switch
blending curves
For a switching between two controllers one must
distinguish between two different cases:
atomic
switching and cross fading.5 In the case of atomic
5The structure and type of cross fading depends on the
283
Hybrid UML Components for the Design of Complex Self-Optimizing Mechatronic Systems
Figure 1: Scheme of the suspension/tilt module.
Figure 2: Reference controller.
Figure 3: Fading between different control modes.

switching the change can take place between two
computation steps. To start the new controller up, it
is often necessary to initialize its states on the basis
of the states of the old controller. In our example, the
switching from the normal block to the failure block
(see Figure 3) can be processed atomically because
the robust controller actually has no state. Different
theoretical works deal with the veriﬁcation of stabil-
ity in systems with any desired switching processes
(Lygeros et al., 2003). In the simple case of a switch
to a robust controller, stability can be maintained with
the help of condition monitoring (Deppe and Ober-
schelp, 2000).
If, however, the operating points of the controllers
are not identical it will be necessary to cross-fade be-
tween the two controllers. This handling is required in
the normal block depicted in Figure 3, where a transi-
tion between the reference and the absolute controller
is realized. The cross fading itself is speciﬁed by a
fading function fswitch(t) and an additional parame-
ter which determines the duration of the cross fading.
While the outlined modeling style allows to de-
scribe the required behavior, the result is inadequate
because of the following two problems: (1) the differ-
ent operation modes and the possible transitions be-
tween them are more appropriately modeled using a
techniques for ﬁnite state systems rather than a set
of blocks scattered all around in the block diagrams
and (2) this style of modeling would require to exe-
cute all alternative controllers in parallel even though
a straight forward analysis of the state space of the re-
sulting ﬁnite state system would permit to run only the
blocks which realize the currently active controllers.
To overcome these problems, hybrid modeling ap-
proaches such as hybrid automata (Henzinger et al.,
1995) can be employed. When modeling the fading
and switching between the different controllers in our
example according to Figure 3, a hybrid automaton
with at least three discrete states – one for each of the
controllers– might be used. These are the locations
Robust, Absolute and Reference in Figure 4.
The
locations’ continuous behavior is represented by the
associated controllers.
Contrary to the white-ﬁlled
arrows, black-ﬁlled ones denote the common inputs
which are always available and required by all con-
trollers.
When the automaton resides in the start location
Robust and for instance the ¨zabs signal becomes avail-
able (as indicated by the discrete zAbsOK signal),
the location and the controller change to the absolute
mode. As this change requires cross fading an addi-
tional location (FadeRobAbs) is introduced in which
the cross fading is comprised. To specify a fading du-
ration d1 = [d1
low, d1
up] an additional state variable
controller types and could lead to complex structures. In
our example we use only output fading.
<Ref
Abs>
<Abs
Ref>
common input
special input
Legend:
common output
<Rob
Abs>
<Rob
Ref>
FadeRobRef
Robust
<Rob>
zRefFailure
Absolute
Reference
zRefOK
zRefOK
FadeRobAbs
FadeRefAbs
<Ref>
FadeAbsRef
<Abs>
zAbsFailure
zAbsFailure
zAbsOK
zAbsFailure
zAbsFailure
zAbsFailure
zRefFailure
zAbsFailure
zAbsOK
zref
¨zabs
t0 ≤d4
up
d4
low ≤t0 ≤d4
up
d1
low ≤t0 ≤d1
up
t0 = 0
t0 ≤d1
up
zref
¨zabs
zref
¨zabs
zref
¨zabs
¨zabs
¨zabs
t0 ≤d2
up
t0 ≤d3
up
d3
low ≤t0 ≤d3
up
t0 = 0
d2
low ≤t0 ≤d2
up
t0 = 0
t0 = 0
tc with ˙tc = 1 is introduced. The reset when en-
tering the fading location FadeRobAbs, its invariant
tc ≤d1
up and the transition’s guard d1
low ≤tc ≤d1
up
guarantee that the fading will take d1
low at a minimum
and d1
up at a maximum. After completing the fading,
the target location Absolute is entered. The duration
of the other fading transitions is speciﬁed similarly. If
the ¨zabs signal is lost during fading or during the use
of the absolute-controller, the default location with its
robust control is entered immediately (cf. Figure 4).
In an appropriate self-optimizing design the aim
must be to use the most comfortable controller while
still maintaining the shuttle’s safety. If, for instance,
the absolute controller is in use and the related sensor
fails, the controller may become instable. Thus there
is need for a discrete control monitor which ensures
that only safe conﬁgurations are allowed. The moni-
tor which controls the correct transition between the
discrete controller modes must also be coordinated
with the overall real-time processing. In our example,
the reference controller can only be employed when
the data about the track characteristics has been re-
ceived in time by the real-time shuttle control soft-
ware. Trying to also integrate these additional dis-
crete state elements into our hybrid description of the
body control would obviously result in a overly com-
plex description by means of a single hybrid State-
chart which lacks modularity.
4
THE APPROACH
To support the design of complex mechatronic sys-
tems and to overcome the problems of the available
modeling techniques as outlined in the preceding sec-
tion, we introduce in the following informally our ap-
proach for modeling with the UML in Section 4.1,
our notion for hybrid Statecharts in Section 4.2, our
284
S. Burmester, H. Giese and O. Oberschelp
Figure 4: Hybrid body control with fading locations.

notion for hybrid components in Section 4.3, and the
modular reconﬁguration in Section 4.4. The exact for-
malization is presented in (Giese et al., 2004).
4.1
Hybrid UML Model
In Figure 5c the overall structural view of our exam-
ple is presented by means of a UML component di-
agram. The Monitor component, that embeds three
components, communicates with the Registry compo-
nent through ports and a communication channel. The
Shuttle-Registration pattern speciﬁes the communica-
tion protocol between Monitor and Registry. The be-
havior of the track section registry which is frequently
contacted by the monitor to obtain the required zref
is depicted in Figure 5b. In Figure 5a the sensor’s be-
havior is described by a Statechart.
:Registry
:Monitor
storage : Storage
:BC
:Sensor
Registration
Shuttle−
Pattern
c) Component diagram
a) Sensor
On
Off
/ monitor.ok
/ monitor.failure
b) Registry
Default
Proceed
shuttle.requestInfo /
Vector zRef)
/ shuttle.sendInfo(
The embedded components communicate continu-
ous signals through so called continuous ports, de-
picted by framed triangles whose orientation indicates
the direction of the signal ﬂow, and discrete events
through discrete, non-ﬁlled ports.
4.2
Hybrid Statecharts
A look at the hybrid automaton from Figure 4 re-
veals that the explicit fading locations considerably
increase the number of visible locations of the au-
tomaton and make it unnecessarily difﬁcult to under-
stand.
Therefore we propose an extension of UML State-
charts towards Hybrid Statecharts that provide a
short-form to describe the fading.
The short-form
contains the following parameters: A source- and a
target-location, a guard and an event trigger, informa-
tion on whether or not it is an atomic switch, and,
in the latter case, a fading strategy (here cross fad-
ing is used for all fading transitions), a fading func-
tion (ffade) and the required fading duration interval
d = [dlow, dup] specifying the minimum and maxi-
mum duration of the fading. This short-form is dis-
played in Figure 6. The fading-transitions are visual-
ized by thick arrows while atomic switches have the
shape of regular arrows.
zAbsFailure
zAbsOK
Robust
Reference
Absolute
zRefOK
zAbsFailure
zAbsOK
zRefFailure
<Abs>
<Ref>
<Rob>
d4
d2
ffade2
ffade1
¨zabs
¨zabs
zref
d1
d3
ffade3
ffade4
An atomic transition, leaving the source or the tar-
get state of a currently active fading transition, inter-
rupts the execution of the fading transition. In case
of conﬂicting atomic transitions of the source and tar-
get state, the source state’s transitions have priority by
default.
4.3
Hybrid Components
One serious limitation of today’s approaches for hy-
brid systems is due to the fact that the continuous part
of each location has to have the same set of required
input and provided output variables (continuous in-
terface). To foster the reconﬁguration we propose to
describe the different externally relevant continuous
interfaces as well as the transition between them us-
ing hybrid interface Statecharts.
zRefOK
zAbsFailure
zAbsOK
zRefFailure
zAbsOK
[Robust]
[Absolute]
zAbsFailure
[Reference]
d2
d3
d1
d4
¨zabs
zref
¨zabs
The related interface Statechart of the body control
component of Figure 6 is displayed in Figure 7. It
shows that the body control component has three pos-
sible different interfaces. The (continous) ports that
are required in each of the three interfaces are ﬁlled
black, the ones that are only used in a subset of the
states are ﬁlled white. For all possible state changes,
only the externally relevant information, such as du-
rations and the signals to initiate and to break the tran-
285
Figure 5: Monitor and its environment (incl. behavior).
Figure 6: Behavior of the body control component.
Figure 7: Interface Statechart of the BC component.
Hybrid UML Components for the Design of Complex Self-Optimizing Mechatronic Systems

sitions, are present.
Interface Statecharts can be employed to ab-
stract from realization details of a component.
A
component in our approach can thus be described
as a UML component – with ports with distinct
quasi-continuous and discrete signals and events– by
• a hybrid interface Statechart which is a correct
abstraction of the component behavior (cf. (Giese
et al., 2004)) which determines what signals are
used in what state,
• the
dependency
relation
between
the
output
and input signals of a component per state of
the interface Statechart in order to ensure only
acyclic dependencies between the components, and
• the behavior of the component usually described
by a single Hybrid Statechart and its embedded
subcomponents (see Section 4.4).
In our example, the BC component is described by
its hybrid interface Statechart presented in Figure 7,
the additionally required information on which de-
pendencies between output and input variables exist
which is not displayed in Figure 7, and its behavior
described by the Hybrid Statechart of Figure 6 where
the required quasi-continuous behavior is speciﬁed by
controllers.
4.4
Modular Reconﬁguration
The hybrid statechart from Figure 6, which supports
state-dependent continuous interfaces, does still not
include the case that the employed controllers show
hybrid behavior themselves. Instead, complete sep-
aration of discrete and continuous behavior like in
(Alur et al., 2001; Bender et al., 2002; Henzinger
et al., 1995; K¨uhl et al., 2002) is still present.
basic block
basic block
basic block
interchange,
reconfiguration
basic block
hierarchy
hierarchy
hierarchy
A
B
To overcome this limitation, we propose to assign
the required conﬁguration of embedded subcompo-
nents (not only quasi-continuous blocks) to each state
of a Hybrid Statechart by means of UML instance di-
agrams.
This idea is motivated by the observation
that the topology of hierarchical block diagrams could
be seen as a tree. With the leafs of this tree repre-
senting the behavior whereas the inner nodes describe
the structure of the system. This distinction between
structure (hierarchy) and function (block) can be used
for the required modular reconﬁgurable systems. In
our context, a reconﬁguration can be understood as a
change in the structure resp. substructure of a block
diagram. It alters the topology of the system; func-
tions are added and/or interlinked anew. Thus to real-
ize modular reconﬁguration we only have to provide
a solution to alter the hierarchical elements (cf. Fig.
8). In this manner the required coordination of aggre-
gated components can be described using a modular
Hybrid statechart which alter the conﬁgurations of its
hybrid subcomponents (see Figure 9).
:Sensor[Off]
:BC[Robust]
storage:Storage
:Sensor[On]
:BC[Reference]
:Sensor[On]
:BC[Absolute]
:BC[Robust]
:Sensor[Off]
when(next
Segment)
noData? /
when(nextSegment)
data(Vector zRef)?
when(
!storage.isEmpty())
/ data(Vector zRef)!
after(20)
/ registry.
requestInfo
RefNon
Available
/ noData!
registry.sendInfo(zRef) / storage.add(zRef)
Ref
Available
when(storage.isEmpty())
when(nextSegment)
data(Vector zRef)? /
sensor.ok
RefAvailable
NoneAvailable
sensor.failure
sensor.ok
data(Vector zRef)?
noData?
AbsAvailable
AllAvailable
sensor.failure
when(nextSegment)
data(Vector zRef)? /
db
dd
da
dc
Figure 9: Monitor behavior with modular reconﬁguration
Figure 9 speciﬁes the behavior of the control mon-
itor software. The upper AND-state consists of four
locations indicating which of the two signals ¨zabs and
zref are available. Some transitions can ﬁre imme-
diately, others are associated with a deadline interval
d = [dlow, dup] specifying how much time a transi-
tion may take minimal and maximal. These transi-
tions are thicker and marked with an arrow and the
intervals (da, . . . , dd). The lower branch of the mod-
ular Hybrid statechart communicates with the track
section registry (Figure 5c), frequently requests the
zref function, and puts it in the storage.
In the Hybrid Statechart, every discrete state has
been associated with a conﬁguration of the subcom-
ponents (BC, Sensor, Storage). In the design of these
associations, only the interface description of the em-
bedded component BC (see Figure 7) is relevant and
286
S. Burmester, H. Giese and O. Oberschelp
of the subcomponent BC
Figure 8: Reconﬁgurable block diagram.
.

the inner structure can be neglected. Therefore, as
shown in Figure 9, we can assign to each location of
the upper AND-state of the statechart the BC compo-
nent in the appropriate state. E.g., the BC component
instance in state Reference has been (via a visual em-
bedding) assigned to the location AllAvailable of the
monitor where zref as well as ¨zabs are available. The
required structure is speciﬁed by instances of the Sen-
sor and the Storage component and the communica-
tion links.
The Hybrid Statechart of Figure 9 deﬁnes a map-
ping of states to required conﬁgurations of the sub-
components. The required synchronization between
the components is accomplished through explicit rais-
ing of the discrete signals deﬁned in Figure 7.
5
RUN-TIME ARCHITECTURE
In order to reach interoperability for mechatronic sys-
tems, which are only alterable within certain limits,
one can use appropriate middleware solutions like
IPANEMA (Honekamp, 1998), which allows abstrac-
tion from hardware details.
IPANEMA is a plat-
form concept for distributed real-time execution and
simulation to support rapid prototyping.
It allows
a modular-hierarchical organization of tasks or pro-
cesses on distributed hardware.
In order to make interoperability possible also for
hybrid components, which contain the kinds of alter-
ation capability described above, the support of alter-
ation capability by the middleware must be consider-
ably extended. First it is necessary to generate the
models in accordance to their modular-hierarchical
structure. This is the basis for a reconﬁguration.
In each discrete location of the system the equa-
tions, that implement the currently active controllers,
have to be employed to compute the correct continu-
ous behavior. Thus in every location of this kind only
the relevant equations have to be evaluated. To reach
this aim, the architecture provides means for every
component to adjust the set of active equation blocks
in such a way that the required reconﬁguration of the
component system is efﬁciently managed.
In the modular execution framework outlined, the
required execution order results from the local eval-
uation dependencies within each component as well
as from their interconnection. It must thus be deter-
mined at deployment-time or run-time.
The continuous nonlinear differential equations are
solved by applying suitable numeric solvers. Com-
putation is time-discrete. Incrementation depends on
the solver and the dynamics of the continuous system.
A time-accurate detection of a continuous condition
is not possible if the controller is coupled with a real
technical system. Thus, we restrict the urgent reaction
to continuous conditions in the hybrid statecharts to a
detection within the desired time slot (cf. (Henzinger
et al., 2003; Stauner, 2002)).
6
CONCLUSION AND FUTURE
WORK
Complex mechatronic systems with self-optimization
are hybrid systems which reconﬁgure themselves at
run-time. As outlined in the paper, their modeling
can hardly be done by the approaches currently avail-
able. Therefore, we propose an extension of UML
components and Statecharts towards reconﬁgurable
hybrid systems which supports the modular hierarchi-
cal modeling of reconﬁgurable systems with hybrid
components and hybrid Statecharts.
The presented approach permits that the needed
discrete coordination can be designed by a software
engineer with extended Statecharts. In parallel, a con-
trol engineer can construct the advanced controller
component which offers the technical feasible recon-
ﬁguration steps. These two views can then be inte-
grated using only the component interface of the con-
troller component.
It is planned to support the presented concepts by
both the CAE tool CAMeL (Richert, 1996) and the
CASE tool Fujaba (Giese et al., 2003). With both
tools, the result of every design activity will be a hy-
brid component. Each of these hybrid components it-
self can integrate hybrid components. The integration
only requires the information given by the component
interface.
Additional automatic and modular code
generation for the hybrid models and run-time sup-
port for the reconﬁguration will thus result in support
for the modular and component-based development of
self-optimizing mechatronic systems from the model
level down to the ﬁnal code.
REFERENCES
(2003). U
L 2.0 Superstructure Speciﬁcation. Object Man-
agement Group. Document ptc/03-08-02.
Alur, R., Courcoubetis, C., Halbwachs, N., Henzinger, T.,
Ho, P.-H., Nicollin, X., Olivero, A., Sifakis, J., and
Yovine, S. (1995). The algorithmic analysis of hybrid
systems. Theoretical Computer Science, 138(3-34).
Alur, R., Dang, T., Esposito, J., Fierro, R., Hur, Y., Ivan-
cic, F., Kumar, V., Lee, I., Mishra, P., Pappas, G., and
Sokolsky, O. (2001). Hierarchical Hybrid Modeling of
Embedded Systems. In
irst Workshop on
mbedded
Software.
Bender, K., Broy, M., Peter, I., Pretschner, A., and Stauner,
T. (2002). Model based development of hybrid sys-
tems. In
odelling,
nalysis, and Design of Hybrid
287
Hybrid UML Components for the Design of Complex Self-Optimizing Mechatronic Systems

Systems, volume 279 of Lecture Notes on Control and
Information Sciences, pages 37–52. Springer Verlag.
Conrad, M., Weber, M., and Mueller, O. (1998). Towards
a methodology for the design of hybrid systems in
automotive electronics. In Proc. of the International
Symposium on
utomotive Technology and
utoma-
tion (IS T ’98).
Deppe, M. and Oberschelp, O. (2000).
Real-Time Sup-
port For Online Controller Supervision And Optimi-
sation. In Proc. of DIP S 2000. Workshop on Dis-
tributed and Parallel
mbedded Systems,
echatron-
ics Laboratory Paderborn, University of Paderborn.
F¨ollinger, O., D¨orscheid, F., and Klittich, M. (1994).
egelungstechnik -
inf¨uhrung in die
ethoden und
ihre
nwendung. H¨uthig.
Giese, H., Burmester, S., Sch¨afer, W., and Oberschelp,
O. (2004).
Modular Design and Veriﬁcation of
Component-Based Mechatronic Systems with Online-
Reconﬁguration.
In Proc. of 12th
C
SIGSO T
oundations of Software
ngineering 2004 ( S
2004), Newport Beach, US . ACM. (accepted).
Giese, H., Tichy, M., Burmester, S., Sch¨afer, W., and Flake,
S. (2003). Towards the Compositional Veriﬁcation of
Real-Time UML Designs. In Proc. of the
uropean
Software
ngineering Conference ( S C), Helsinki,
inland. Copyright 2003 by ACM, Inc.
Grosu, R., Krueger, I., and Stauner, T. (1999). Hybrid se-
quence charts. Technical Report TUM-I9914, Techni-
cal University Munich, Munich.
Grosu, R., Stauner, T., and Broy, M. (1998). A modular
visual model for hybrid systems. In Proc. of
ormal
Techniques in
eal-Time and
ault-Tolerant Systems
( T T T’98), LNCS 1486. Springer-Verlag.
Henzinger, T. A. (2000). Masaccio: A Formal Model for
Embedded Components. In Proceedings of the
irst
I IP International Conference on Theoretical Com-
puter Science (TCS), Lecture Notes in Computer Sci-
ence 1872, Springer-Verlag, 2000, pp. 549-563.
Henzinger, T. A., Ho, P.-H., and Wong-Toi, H. (1995).
HyTech: The Next Generation. In Proc. of the 16th
I eal-Time Symposium. IEEE Computer Press.
Henzinger, T. A., Kirsch, C. M., Sanvido, M. A., and Pree,
W. (2003). From Control Models to Real-Time Code
Using Giotto.
In I
Control Systems
agazine
23(1):50-64, 2003.
Hestermeyer, T., Schlautmann, P., and Ettingshausen,
C. (2002).
Active suspension system for railway
vehicles-system design and kinematics. In Proc. of
the 2nd I
C - Confecence on mechatronic systems,
Berkeley, California, USA.
Honekamp, U. (1998).
IP N
- Verteilte
chtzeit-
Informationsverarbeitung in mechatronischen Syste-
men. PhD thesis, Universit¨at Paderborn, D¨usseldorf.
Isermann, R., Lachmann, K.-H., and Matko, D. (1992).
daptive
Control Systems.
Prentice Hall, Herford-
shire.
Kesten, Y. and Pnueli, A. (1992).
Timed and hybrid
statecharts and their textual representation. In Proc.
ormal Techniques in
eal-Time and
ault-Tolerant
Systems, 2nd International Symposium, LNCS 571.
Springer-Verlag.
K¨uhl, M., Reichmann, C., Pr¨otel, I., and M¨uller-Glaser,
K. D. (2002).
From object-oriented modeling to
code generation for rapid prototyping of embedded
electronic systems.
In Proc. of the 13th I
In-
ternational Workshop on
apid System Prototyping
(SP’02), Darmstadt, Germany.
Lamport, L. (1993). Hybrid systems in tla+. Springer.
L¨uckel, J., Grotstollen, H., J¨aker, K.-P., Henke, M., and
Liu, X. (1999). Mechatronic design of a modular rail-
way carriage. In Proc. of the 1999 I
/ S
Inter-
national Conference on
dvanced Intelligent
echa-
tronics ( I
99), Atlanta, GA, USA.
Li, P. Y. and Horowitz, R. (1997). Self-optimizing control.
In Proc. of the 36th I
Conference on Decision and
Control (CDC), pages 1228–1233, San Diego, USA.
Liu-Henke, X., L¨uckel, J., and J¨aker, K.-P. (2000).
De-
velopment of an Active Suspension/Tilt System for
a Mechatronic Railway Carriage. In Proc. of the 1st
I C-Conference
on
echatronics Systems (echa-
tronics 2000), Darmstadt, Germany.
Lygeros, J., Johansson, K. H., Simic´, S. N., Zhang, J., and
Sastry, S. S. (2003).
Dynamical Properties of Hy-
brid Automata. In
I T
NS CTIONS ON UTO-
TIC CONT OL, VOL. 48, NO. 1, J NU
Y 2003,
volume 48.
M¨uller, C. and Rake, H. (1999). Automatische Synthese von
Steuerungskorrekturen.
In KONDISK-Kolloquium
,
Berlin.
Richert, J. (1996). Integration of mechatronic design tools
with camel, exempliﬁed by vehicle convoy control de-
sign. In Proc. of
the I International Symposium
on Computer
ided Control System Design, Dearborn,
Michigan, USA.
Stauner, T. (2001). Systematic Development of Hybrid Sys-
tems. PhD thesis, Technical University Munich.
Stauner, T. (2002).
Discrete-time reﬁnement of hybrid
automata.
In Tomlin, C. and Greenstreet, M., edi-
tors, Proceedings of the 5th International Workshop
on Hybrid Systems: Computation and Control (HSCC
2002), volume 2289 of Lecture Notes in Computer
Science, page 407ff, Stanford, CA, USA.
Stauner, T., Pretschner, A., and P´eter, I. (2001).
Ap-
proaching a Discrete-Continuous UML: Tool Support
and Formalization. In Proc. U
L’2001 workshop on
Practical U
L-Based
igorous Development
eth-
ods – Countering or Integrating the eXtremists, pages
242–257, Toronto, Canada.
Wieting, R. (1996). Hybrid high-level nets. In Proceedings
of the1996 Winter Simulation Conference, pages 848–
855, Coronado, CA, USA.
288
S. Burmester, H. Giese and O. Oberschelp

AUTHOR INDEX 
Aarts, R. ............................................187 
Aïello, A. ...........................................247 
Apkarian, P. ........................................61 
Arndt, F. ..............................................27 
Artigas, J. ..........................................201 
Babuska, R. .......................................143 
Bader, J. ............................................225 
Boimond, J. .......................................211 
Boutalis, Y. .......................................117 
Braaksma, J. ......................................143 
Buisson, J. .........................................217 
Burmester, S. .....................................281 
Cantoni, V. ........................................239 
Cheng, A. ............................................31 
Chettibi, T. ..........................................73 
Chryssostomidis, C. ..........................195 
Costa, J. .............................................273 
Crispin, Y. ...........................................89 
Dahleh, M. ..........................................37 
Damus, R. .........................................195 
Derado, I. ............................................53 
Desset, S. ...........................................195 
Dumur, D. .........................................217 
Elia, N. ................................................37 
Ezkerra, J. .........................................151 
Giese, H. ...........................................281 
Gonçalves, P. ......................................81 
Haddad, M. .........................................73 
Hahn, H. ............................................233 
Hamaci, S. .........................................211 
Handroos, H. .....................................135 
Hatzis, C. ...........................................117 
Hentout , A. .........................................73 
Herve Guéguen, H. ...........................217 
Hill, D. ..............................................247 
Hirvonen, M. .....................................135 
Hirzinger, G. .....................................201 
Hover, F. ...........................................195 
Innocenti, E. ......................................247 
Itoh, H. ..............................................179 
Jonker, B. ..........................................187 
Jung, J. ..............................................233 
Kang, M. .............................................99 
Kato, S. .............................................179 
Keizer, C. ..........................................143 
Klaassens, B. .....................................143 
Koivisto, H. .......................................111 
Kosmidou, O. ....................................117 
Lahaye, S. ..........................................211 
Landaluze, J. ......................................151 
Lesieutre, B. ......................................263 
Lombardi, P. ......................................239 
Lyou, J. ................................................99 
Madani, K. ...........................................11 
Maione, G. .........................................125 
Martínez, A. ......................................151 
Martins, N. ..........................................37 
Mendonça, L. ......................................81 
Miño, S. .............................................159 
Morais, F. ..........................................273 
Morash, J. ..........................................195 
Muzy, A. ............................................247 
Naso, D. .............................................125 
Nicolás, C. .........................................151 
Noll, D. ................................................61 
Noritake, K. .......................................179 
Oberschelp, O. ...................................281 
Oliver, A. ...........................................159 
Oliver, M. ..........................................159 
Oswald, N. .........................................167 
Pinto, J. ................................................81 
Polidoro, V. .......................................195 
Preusche, C. .......................................201 
Pyrhönen, O. ......................................135 
Rakush, V. .........................................255 
Rantala, J. ..........................................111 
Rasku, H. ...........................................111 
Rebai, S. ..............................................73 
Reintsema, D. ....................................201 
Río, V. ...............................................151 
Roy, S. ...............................................263 
Sadykhov, R. .....................................255 
Santoni, P. .........................................247 
Santucci, J. ........................................247 
Scheibelmasser, A. ..............................53 
Schindin, G. .........................................53 
Somolinos, C. ....................................159 
Sousa, J. ...............................................81 
Thevenet, J. .........................................61 
Thomas, J. .........................................217 
289

Tona, P. .............................................225 
Traussnigg, U. .....................................53 
Vaganay, J. ........................................195 
Verghese, G. .....................................263 
Waiboer, R. .......................................187 
Warwick, K. ..........................................3 
Willcox, S. ........................................195 
Xiaowei, S. ........................................105 
Zavidovique, B. .................................239 
290
Author Index

