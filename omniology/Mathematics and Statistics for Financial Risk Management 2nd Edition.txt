

Mathematics and 
Statistics for 
Financial Risk 
Management

Founded in 1807, John Wiley & Sons is the oldest independent publishing com-
pany in the United States. With offices in North America, Europe, Australia, and 
Asia, Wiley is globally committed to developing and marketing print and electronic 
products and services for our customers’ professional and personal knowledge and 
understanding.
The Wiley Finance series contains books written specifically for finance and in-
vestment professionals as well as sophisticated individual investors and their finan-
cial advisors. Book topics range from portfolio management to e-commerce, risk 
management, financial engineering, valuation, and financial instrument analysis, as 
well as much more.
For a list of available titles, visit our website at www.WileyFinance.com. 

Second Edition
Michael B. Miller
Mathematics and 
Statistics for 
Financial Risk 
Management

Cover Design: Wiley 
Cover Image, top: © Epoxy / Jupiter Images
Cover Image, bottom: © iStockphoto.com / Georgijevic
Copyright © 2014 by Michael B. Miller. All rights reserved.
Published by John Wiley & Sons, Inc., Hoboken, New Jersey.
Published simultaneously in Canada.
No part of this publication may be reproduced, stored in a retrieval system, or 
transmitted in any form or by any means, electronic, mechanical, photocopying, 
recording, scanning, or otherwise, except as permitted under Section 107 or 108 of 
the 1976 United States Copyright Act, without either the prior written permission 
of the Publisher, or authorization through payment of the appropriate per-copy 
fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 
01923, (978) 750-8400, fax (978) 646-8600, or on the Web at www.copyright.com. 
Requests to the Publisher for permission should be addressed to the Permissions 
Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 
748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have 
used their best efforts in preparing this book, they make no representations 
or warranties with respect to the accuracy or completeness of the contents of 
this book and specifically disclaim any implied warranties of merchantability 
or fitness for a particular purpose. No warranty may be created or extended 
by sales representatives or written sales materials. The advice and strategies 
contained herein may not be suitable for your situation. You should consult with a 
professional where appropriate. Neither the publisher nor author shall be liable for 
any loss of profit or any other commercial damages, including but not limited to 
special, incidental, consequential, or other damages.
For general information on our other products and services or for technical support, 
please contact our Customer Care Department within the United States at (800) 
762-2974, outside the United States at (317) 572-3993 or fax (317) ­572-4002.
Wiley publishes in a variety of print and electronic formats and by print-on-
demand. Some material included with standard print versions of this book may 
not be included in e-books or in print-on-demand. If this book refers to media 
such as a CD or DVD that is not included in the version you purchased, you may 
download this material at http://booksupport.wiley.com. For more information 
about Wiley products, visit www.wiley.com.
Library of Congress Cataloging-in-Publication Data:
Miller, Michael B. (Michael Bernard), 1973–
  Mathematics and statistics for financial risk management / Michael B. Miller. — 
2nd Edition.
    pages cm. — (Wiley finance)
  Includes bibliographical references and index.
  ISBN 978-1-118-75029-2 (hardback); ISBN 978-1-118-757555-0 (ebk); ISBN 
978-1-118-75764-2 (ebk)  1.  Risk management—Mathematical models.  2.  Risk 
management—Statistical methods.  I.  Title. 
  HD61.M537  2013
  332.01’5195—dc23

2013027322
Printed in the United States of America
10  9  8  7  6  5  4  3  2  1

v
Preface
ix
What’s New in the Second Edition
xi
Acknowledgments
xiii
Chapter 1
Some Basic Math
1
Logarithms
1
Log Returns
2
Compounding
3
Limited Liability
4
Graphing Log Returns
5
Continuously Compounded Returns
6
Combinatorics
8
Discount Factors
9
Geometric Series
9
Problems
14
Chapter 2
Probabilities
15
Discrete Random Variables
15
Continuous Random Variables
15
Mutually Exclusive Events
21
Independent Events
22
Probability Matrices
22
Conditional Probability
24
Problems
26
Chapter 3
Basic Statistics
29
Averages
29
Expectations
34
Variance and Standard Deviation
39
Standardized Variables
41
Covariance
42
Contents

vi
Contents
Correlation
43
Application: Portfolio Variance and Hedging
44
Moments
47
Skewness
48
Kurtosis
51
Coskewness and Cokurtosis
53
Best Linear Unbiased Estimator (BLUE)
57
Problems
58
Chapter 4
Distributions
61
Parametric Distributions
61
Uniform Distribution
61
Bernoulli Distribution
63
Binomial Distribution
65
Poisson Distribution
68
Normal Distribution
69
Lognormal Distribution
72
Central Limit Theorem
73
Application: Monte Carlo Simulations  
Part I: Creating Normal Random Variables
76
Chi-Squared Distribution
77
Student’s t Distribution
78
F-Distribution
79
Triangular Distribution
81
Beta Distribution
82
Mixture Distributions
83
Problems
86
Chapter 5
Multivariate Distributions and Copulas
89
Multivariate Distributions
89
Copulas
97
Problems
111
Chapter 6
Bayesian Analysis
113
Overview
113
Bayes’ Theorem
113
Bayes versus Frequentists
119
Many-State Problems
120
Continuous Distributions
124
Bayesian Networks
128
Bayesian Networks versus Correlation Matrices
130
Problems
132

﻿Contents
vii
Chapter 7
Hypothesis Testing and Confidence Intervals
135
Sample Mean Revisited
135
Sample Variance Revisited
137
Confidence Intervals
137
Hypothesis Testing
139
Chebyshev’s Inequality
142
Application: VaR
142
Problems
152
Chapter 8
Matrix Algebra
155
Matrix Notation
155
Matrix Operations
156
Application: Transition Matrices
163
Application: Monte Carlo Simulations  
Part II: Cholesky Decomposition
165
Problems
168
Chapter 9
Vector Spaces
169
Vectors Revisited
169
Orthogonality
172
Rotation
177
Principal Component Analysis
181
Application: The Dynamic Term Structure of Interest Rates
185
Application: The Structure of Global Equity Markets
191
Problems
193
Chapter 10
Linear Regression Analysis
195
Linear Regression (One Regressor)
195
Linear Regression (Multivariate)
203
Application: Factor Analysis
208
Application: Stress Testing
211
Problems
212
Chapter 11
Time Series Models
215
Random Walks
215
Drift-Diffusion Model
216
Autoregression
217
Variance and Autocorrelation
222
Stationarity
223
Moving Average
227

viii
Contents
Continuous Models
228
Application: GARCH
230
Application: Jump-Diffusion Model
232
Application: Interest Rate Models
232
Problems
234
Chapter 12
Decay Factors
237
Mean
237
Variance
243
Weighted Least Squares
244
Other Possibilities
245
Application: Hybrid VaR
245
Problems
247
Appendix A
Binary Numbers
249
Appendix B
Taylor Expansions
251
Appendix C
Vector Spaces
253
Appendix D
Greek Alphabet
255
Appendix E
Common Abbreviations
257
Appendix F
Copulas
259
Answers
263
References
303
About the Author
305
About the Companion Website
307
Index
309

ix
T
he recent financial crisis and its impact on the broader economy underscores the 
importance of financial risk management in today’s world. At the same time, fi-
nancial products and investment strategies are becoming increasingly complex. It 
is more important than ever that risk managers possess a sound understanding of 
mathematics and statistics.
Mathematics and Statistics for Financial Risk Management is a guide to modern 
financial risk management for both practitioners and academics. Risk management 
has made great strides in recent years. Many of the mathematical and statistical tools 
used in risk management today were originally adapted from other fields. As the 
field has matured, risk managers have refined these tools and developed their own 
vocabulary for characterizing risk. As the field continues to mature, these tools and 
vocabulary are becoming increasingly standardized. By focusing on the application 
of mathematics and statistics to actual risk management problems, this book helps 
bridge the gap between mathematics and statistics in theory and risk management 
in practice.
Each chapter in this book introduces a different topic in mathematics or statis-
tics. As different techniques are introduced, sample problems and application sec-
tions demonstrate how these techniques can be applied to actual risk management 
problems. Exercises at the end of each chapter, and the accompanying solutions at 
the end of the book, allow readers to practice the techniques learned and to monitor 
their progress.
This book assumes that readers have a solid grasp of algebra and at least a basic 
understanding of calculus. Even though most chapters start out at a very basic level, 
the pace is necessarily fast. For those who are already familiar with the topic, the 
beginning of each chapter serves as a quick review and as an introduction to selected 
vocabulary terms and conventions. Readers who are new to these topics may find 
they need to spend more time in the initial sections.
Risk management in practice often requires building models using spreadsheets 
or other financial software. Many of the topics in this book are accompanied by an  
icon, as shown here.
These icons indicate that Excel examples can be found at John Wiley & Sons’ 
companion website for Mathematics and Statistics for Financial Risk Management, 
Second edition at www.wiley.com/go/millerfinance2e.
You can also visit the author’s website, www.risk256.com, for the latest financial 
risk management articles, code samples, and more. To provide feedback, contact the 
author at mike@risk256.com.
Preface


xi
T
he biggest change to the second edition is the addition of two new chapters. 
The first new chapter, Chapter 5: Multivariate Distributions, explores impor-
tant ­concepts for measuring the risk of portfolios, including joint distributions and 
­copulas. The other new chapter, Chapter 6: Bayesian Analysis, expands on what was 
a short ­section in the first edition. The breadth and depth of this new chapter more 
accurately reflect the importance of Bayesian statistics in risk management today. 
Finally, the second edition includes many new problems, corrections, and small im-
provements to topics covered in the first edition. These included expanded ­sections 
on value at risk model validation, and generalized auto-regressive ­conditional 
­heteroscedasticity (GARCH).
What’s New in the Second Edition


xiii
T
his book would not have been possible without the help of many individuals. I 
would like to thank Jeffrey Garnett, Steve Lerit, Riyad Maznavi, Hyunsuk Moon, 
Elliot Noma, Eldar Radovici, and Barry Schachter for taking the time to read early 
drafts. The book is certainly better for their comments and feedback.
I would also like to thank everybody at John Wiley & Sons for their help in 
bringing this book together.
Finally, and most importantly, I would like to thank my wife, Amy, who not only 
read over early drafts and talked me through a number of decisions, but also put up 
with countless nights and weekends of typing and editing. For this and much, much 
more, thank you.
Acknowledgments


1
I
n this chapter we review three math topics—logarithms, combinatorics, and geo-
metric series—and one financial topic, discount factors. Emphasis is given to the 
specific aspects of these topics that are most relevant to risk management.
Logarithms
In mathematics, logarithms, or logs, are related to exponents, as follows:
	
a
x
a
b
logb
x
=
⇔
=

(1.1)
We say, “The log of a, base b, equals x, which implies that a equals b to the x and vice 
versa.” If we take the log of the right-hand side of Equation 1.1 and use the identity 
from the left-hand side of the equation, we can show that:
	
logb(bx) = logb a = x

(1.2)
logb(bx) = x
Taking the log of bx effectively cancels out the exponentiation, leaving us with x.
An important property of logarithms is that the logarithm of the product of two 
variables is equal to the sum of the logarithms of those two variables. For two vari-
ables, X and Y:
	
XY
X
Y
log (
)
log
log
b
b
b
=
+

(1.3)
Similarly, the logarithm of the ratio of two variables is equal to the difference of 
their logarithms:
	
X
Y
X
Y
log
log
log
b
b
b
=
−

(1.4)
If we replace Y with X in Equation 1.3, we get:
	
X
X
log (
)
2log
b
b
2 =

(1.5)
We can generalize this result to get the following power rule:
	
X
n
X
log (
)
log
b
n
b
=

(1.6)
Chapter 1
Some Basic Math

2
Mathematics and Statistics for Financial Risk Management
In general, the base of the logarithm, b, can have any value. Base 10 and base 2 
are popular bases in certain fields, but in many fields, and especially in finance, e, 
Euler’s number, is by far the most popular. Base e is so popular that mathematicians 
have given it its own name and notation. When the base of a logarithm is e, we refer 
to it as a natural logarithm. In formulas, we write:
	
a
x
a
e
ln( )
x
=
⇔
=

(1.7)
From this point on, unless noted otherwise, assume that any mention of loga-
rithms refers to natural logarithms.
Logarithms are defined for all real numbers greater than or equal to zero. Ex-
hibit 1.1 shows a plot of the logarithm function. The logarithm of zero is negative 
infinity, and the logarithm of one is zero. The function grows without bound; that is, 
as X approaches infinity, the ln(X) approaches infinity as well.
Log Returns
One of the most common applications of logarithms in finance is computing log 
returns. Log returns are defined as follows:
	
rt ≡ ln(1 + Rt)  where  R
P
P
P
t
t
t
t
1
1
=
−
−
−

(1.8)
Exhibit 1.1 
Natural Logarithm
 
–5
–4
–3
–2
–1
0
1
2
3
4
5
0
1
2
3
4
5
6
7
8
9
10
11
12
X
ln(X )

Some Basic Math
3
Here rt is the log return at time t, Rt is the standard or simple return, and Pt is the 
price of the security at time t. We use this convention of capital R for simple returns 
and lowercase r for log returns throughout the rest of the book. This convention is 
popular, but by no means universal. Also, be careful: Despite the name, the log return 
is not the log of Rt, but the log of (1 + Rt).
For small values, log returns and simple returns will be very close in size. A sim-
ple return of 0% translates exactly to a log return of 0%. A simple return of 10% 
translates to a log return of 9.53%. That the values are so close is convenient for 
checking data and preventing operational errors. Exhibit 1.2 shows some additional 
simple returns along with their corresponding log returns.
To get a more precise estimate of the relationship between standard returns and 
log returns, we can use the following approximation:1
	
r
R
R
1
2
2
≈
−

(1.9)
As long as R is small, the second term on the right-hand side of Equation 1.9 will 
be negligible, and the log return and the simple return will have very similar values.
Compounding
Log returns might seem more complex than simple returns, but they have a number 
of advantages over simple returns in financial applications. One of the most useful 
features of log returns has to do with compounding returns. To get the return of a 
security for two periods using simple returns, we have to do something that is not 
very intuitive, namely adding one to each of the returns, multiplying, and then sub-
tracting one:
	
R
P
P
P
R
R
(1
)(1
)
1
t
t
t
t
t
t
2,
2
2
1,
1,
1
=
−
=
+
+
−
−
−
−

(1.10)
Here the first subscript on R denotes the length of the return, and the second sub-
script is the traditional time subscript. With log returns, calculating multiperiod re-
turns is much simpler; we simply add:
	
r
r
r
t
t
t
2,
1,
1,
1
=
+
−
(1.11)
Exhibit 1.2 
Log Returns and Simple Returns
R
ln(1 + R)
  1.00%
  1.00%
  5.00%
  4.88%
10.00%
  9.53%
20.00%
18.23%
1 This approximation can be derived by taking the Taylor expansion of Equation 1.8 around 
zero. Though we have not yet covered the topic, for the interested reader a brief review of 
Taylor expansions can be found in Appendix B.

4
Mathematics and Statistics for Financial Risk Management
By substituting Equation 1.8 into Equation 1.10 and Equation 1.11, you can see 
that these definitions are equivalent. It is also fairly straightforward to generalize this 
notation to any return length.
Sample Problem
Question:
Using Equation 1.8 and Equation 1.10, generalize Equation 1.11 to ­returns 
of any length.
Answer:
R
P
P
P
P
P
P
P
P
P
n t
t
t n
t n
t
t n
t
t
t
t
, =
−
=
−
=
−
−
−
−
−
−
1
1
1
2
... P
P
R
R
R
R
t n
t n
n t
t
t
−+
−
−
−
=
+
+
+
1
1
1
1
1
1
1
1
,
,
,
(
)(
)
(
...
1
1
1
1
1
1
1
1
1
1
,
,
,
,
)
(
)
(
)(
)
(
t n
n t
t
t
R
R
R
−+
−
−
+
=
+
+
...
+
=
+
+
+
−+
−
−+
R
r
r
r
r
t n
n t
t
t
t n
1
1
1
1
1
1
1
,
,
,
,
,
)
...
To get to the last line, we took the logs of both sides of the previous equa-
tion, using the fact that the log of the product of any two variables is equal to 
the sum of their logs, as given in Equation 1.3.
Limited Liability
Another useful feature of log returns relates to limited liability. For many financial 
assets, including equities and bonds, the most that you can lose is the amount that 
you’ve put into them. For example, if you purchase a share of XYZ Corporation for 
$100, the most you can lose is that $100. This is known as limited liability. Today, 
limited liability is such a common feature of financial instruments that it is easy to 
take it for granted, but this was not always the case. Indeed, the widespread adop-
tion of limited liability in the nineteenth century made possible the large publicly 
traded companies that are so important to our modern economy, and the vast finan-
cial markets that accompany them.
That you can lose only your initial investment is equivalent to saying that the 
minimum possible return on your investment is −100%. At the other end of the 
spectrum, there is no upper limit to the amount you can make in an investment. The 
maximum possible return is, in theory, infinite. This range for simple returns, −100% 
to infinity, translates to a range of negative infinity to positive infinity for log returns.
	
R
r
R
r
100%
min
min
max
max
= −
⇒
= −∞
= +∞⇒
= +∞

(1.12)
As we will see in the following chapters, when it comes to mathematical and 
computer models in finance it is often much easier to work with variables that are 

Some Basic Math
5
unbounded—that is, variables that can range from negative infinity to positive 
­infinity. This makes log returns a natural choice for many financial models.
Graphing Log Returns
Another useful feature of log returns is how they relate to log prices. By rearranging 
Equation 1.10 and taking logs, it is easy to see that:
	
r
p
p
t
t
t 1
=
−
−
(1.13)
where pt is the log of Pt, the price at time t. To calculate log returns, rather than 
taking the log of one plus the simple return, we can simply calculate the logs of the 
prices and subtract.
Logarithms are also useful for charting time series that grow exponentially. 
Many computer applications allow you to chart data on a logarithmic scale. For an 
asset whose price grows exponentially, a logarithmic scale prevents the compression 
of data at low levels. Also, by rearranging Equation 1.13, we can easily see that the 
change in the log price over time is equal to the log return:
	
p
p
p
r
t
t
t
t
1
∆
=
−
=
−

(1.14)
It follows that, for an asset whose return is constant, the change in the log price 
will also be constant over time. On a chart, this constant rate of change over time 
will translate into a constant slope. Exhibits 1.3 and 1.4 both show an asset whose 
50
150
250
350
450
550
650
0
1
2
3
4
5
6
7
8
9
10
Time
Price
Exhibit 1.3 
Normal Prices

6
Mathematics and Statistics for Financial Risk Management
price is increasing by 20% each year. The y-axis for the first chart shows the price; 
the y-axis for the second chart displays the log price.
For the chart in Exhibit 1.3, it is hard to tell if the rate of return is increasing or 
decreasing over time. For the chart in Exhibit 1.4, the fact that the line is straight is 
equivalent to saying that the line has a constant slope. From Equation 1.14 we know 
that this constant slope is equivalent to a constant rate of return.
In Exhibit 1.4, we could have shown actual prices on the y-axis, but having 
the log prices allows us to do something else. Using Equation 1.14, we can eas-
ily estimate the average return for the asset. In the graph, the log price increases 
from approximately 4.6 to 6.4 over 10 periods. Subtracting and dividing gives us 
(6.4 − 4.6)/10 = 18%. So the log return is 18% per period, which—because log re-
turns and simple returns are very close for small values—is very close to the actual 
simple return of 20%.
Continuously Compounded Returns
Another topic related to the idea of log returns is continuously compounded returns. 
For many financial products, including bonds, mortgages, and credit cards, interest 
rates are often quoted on an annualized periodic or nominal basis. At each payment 
date, the amount to be paid is equal to this nominal rate, divided by the number of 
periods, multiplied by some notional amount. For example, a bond with monthly 
coupon payments, a nominal rate of 6%, and a notional value of $1,000 would pay 
a coupon of $5 each month: (6% × $1,000)/12 = $5.
4.0
4.5
5.0
5.5
6.0
6.5
7.0
0
1
2
3
4
5
6
7
8
9
10
Time
Log(Price)
Exhibit 1.4 
Log Prices

Some Basic Math
7
How do we compare two instruments with different payment frequencies? Are 
you better off paying 5% on an annual basis or 4.5% on a monthly basis? One solu-
tion is to turn the nominal rate into an annualized rate:
	
R
R
n
1
1
n
Annual
Nominal
=
+
−
(1.15)
where n is the number of periods per year for the instrument.
If we hold RAnnual constant as n increases, RNominal gets smaller, but at a decreas-
ing rate. Though the proof is omitted here, using L’Hôpital’s rule, we can prove 
that, at the limit, as n approaches infinity, RNominal converges to the log rate. As n 
approaches infinity, it is as if the instrument is making infinitesimal payments on a 
continuous basis. Because of this, when used to define interest rates the log rate is 
often referred to as the continuously compounded rate, or simply the continuous 
rate. We can also compare two financial products with different payment periods by 
comparing their continuous rates.
Sample Problem
Question:
You are presented with two bonds. The first has a nominal rate of 20% 
paid on a semiannual basis. The second has a nominal rate of 19% paid on 
a monthly basis. Calculate the equivalent continuously compounded rate for 
each bond. Assuming both bonds can be purchased at the same price, have the 
same credit quality, and are the same in all other respects, which is the better 
investment?
Answer:
First, we compute the annual yield for both bonds:
R
R
1
20%
2
1
21.00%
1
19%
12
1
20.75%
1, Annual
2
2, Annual
12
=
+
−
=
=
+
−
=
Next, we convert these annualized returns into continuously compounded 
returns:
r
R
r
R
ln(1
)
19.06%
ln(1
)
18.85%
1
1, Annual
2
2, Annual
=
+
=
=
+
=
All other things being equal, the first bond is a better investment. We 
could base this on a comparison of either the annual rates or the continuously 
­compounded rates.

8
Mathematics and Statistics for Financial Risk Management
Combinatorics
In elementary combinatorics, one typically learns about combinations and permuta-
tions. Combinations tell us how many ways we can arrange a number of objects, 
regardless of the order, whereas permutations tell us how many ways we can arrange 
a number of objects, taking into account the order.
As an example, assume we have three hedge funds, denoted X, Y, and Z. We 
want to invest in two of the funds. How many different ways can we invest? We can 
invest in X and Y, X and Z, or Y and Z. That’s it.
In general, if we have n objects and we want to choose k of those objects, the 
number of combinations, C(n, k), can be expressed as:
	
C n k
n
k
n
k n
k
( , )
!
!(
)!
=
=
−

(1.16)
where n! is n factorial, such that:
	
n
n n
n
n
n
!
1
(
1)(
2)...1     
0
0
=
−
−
=
>

(1.17)
In our example with the three hedge funds, we would substitute n = 3 and k = 2 to 
get three possible combinations.
What if the order mattered? What if instead of just choosing two funds, we 
needed to choose a first-place fund and a second-place fund? How many ways could 
we do that? The answer is the number of permutations, which we express as:
	
P n k
n
n
k
( , )
!
(
)!
=
−

(1.18)
For each combination, there are k! ways in which the elements of that combina-
tion can be arranged. In our example, each time we choose two funds, there are two 
ways that we can order them, so we would expect twice as many permutations. This 
is indeed the case. Substituting n = 3 and k = 2 into Equation 1.18, we get six permu-
tations, which is twice the number of combinations computed previously.
Combinations arise in a number of risk management applications. The binomial 
distribution, which we will introduce in Chapter 4, is defined using combinations. 
The binomial distribution, in turn, can be used to model defaults in simple bond 
portfolios or to backtest value at risk (VaR) models, as we will see in Chapter 7.
Combinations are also central to the binomial theorem. Given two variables, x 
and y, and a positive integer, n, the binomial theorem states:
	
(
)
x
y
n
k x
y
n
n k
k
k
n
+
=
−
=∑
0

(1.19)
For example:
	
x
y
x
x y
xy
y
(
)
3
3
3
3
2
2
3
+
=
+
+
+

(1.20)
The binomial theorem can be useful when computing statistics such as variance, 
skewness, and kurtosis, which will be discussed in Chapter 3.

Some Basic Math
9
Discount Factors
Most people have a preference for present income over future income. They would 
rather have a dollar today than a dollar one year from now. This is why banks charge 
interest on loans, and why investors expect positive returns on their investments. 
Even in the absence of inflation, a rational person should prefer a dollar today to a 
dollar tomorrow. Looked at another way, we should require more than one dollar in 
the future to replace one dollar today.
In finance we often talk of discounting cash flows or future values. If we are 
discounting at a fixed rate, R, then the present value and future value are related as 
follows:
	
V
V
R
(1
)
t
t n
n
=
+
+

(1.21)
where Vt is the value of the asset at time t and Vt + n is the value of the asset at time 
t + n. Because R is positive, Vt will necessarily be less than Vt + n. All else being equal, 
a higher discount rate will lead to a lower present value. Similarly, if the cash flow 
is further in the future—that is, n is greater—then the present value will also be 
lower.
Rather than work with the discount rate, R, it is sometimes easier to work with 
a discount factor. In order to obtain the present value, we simply multiply the future 
value by the discount factor:
	
V
R
V
V
t
n
t n
n
t n
=
+
=
+
+
1
1
δ

(1.22)
Because the discount factor δ is less than one, Vt will necessarily be less than 
Vt + n. Different authors refer to δ or δn as the discount factor. The concept is the 
same, and which convention to use should be clear from the context.
Geometric Series
In the following two subsections we introduce geometric series. We start with series 
of infinite length. It may seem counterintuitive, but it is often easier to work with se-
ries of infinite length. With results in hand, we then move on to series of finite length 
in the second subsection.
Infinite Series
The ancient Greek philosopher Zeno, in one of his famous paradoxes, tried to prove 
that motion was an illusion. He reasoned that in order to get anywhere, you first 
had to travel half the distance to your ultimate destination. Once you made it to the 
halfway point, though, you would still have to travel half the remaining distance. 
No matter how many of these half journeys you completed, there would always be 
another half journey left. You could never possibly reach your ­destination.

10
Mathematics and Statistics for Financial Risk Management
While Zeno’s reasoning turned out to be wrong, he was wrong in a very profound 
way. The infinitely decreasing distances that Zeno struggled with ­foreshadowed 
­calculus, with its concept of change on an infinitesimal scale. Also, infinite series of a 
variety of types turn up in any number of fields. In finance, we are often faced with 
series that can be treated as infinite. Even when the series is long but clearly finite, the 
same basic tools that we develop to handle infinite series can be deployed.
In the case of the original paradox, we are basically trying to calculate the 
­following summation:
	
S =
+
+
+
1
2
1
4
1
8
... 
(1.23)
What is S equal to? If we tried the brute force approach, adding up all the terms, 
we would literally be working on the problem forever. Luckily, there is an easier way. 
The trick is to notice that multiplying both sides of the equation by ½ has the exact 
same effect as subtracting ½ from both sides:
Multiply both sides by ½:
Subtract ½ from both sides:
S
S
=
+
+
+
=
+
+
+
1
2
1
4
1
8
1
2
1
4
1
8
1
16
...
...
S
S
=
+
+
+
−
=
+
+
+
1
2
1
4
1
8
1
2
1
4
1
8
1
16
...
...
The right-hand sides of the final line of both equations are the same, so the left-
hand sides of both equations must also be equal. Taking the left-hand sides of both 
equations, and solving:
	
S
S
S
S
S
S
1
2
1
2
1
2
1
2
1
2
1
2
1
−
=
−
=
=
=

(1.24)
The fact that the infinite series adds up to one tells us that Zeno was wrong. 
If we keep covering half the distance but do it an infinite number of times, eventu-
ally we will cover the entire distance. The sum of all the half trips equals one full 
trip.
To generalize Zeno’s paradox, assume we have the following series:
	
S
i
i
=
=
∞
∑δ
1

(1.25)
In Zeno’s case, δ was ½. Because the members of the series are all powers of the 
same constant, we refer to these types of series as geometric series. As long as |δ| is 

Some Basic Math
11
less than one, the sum will be finite and we can employ the same basic strategy as 
before, this time multiplying both sides by δ.
	
δS
S
S
S
S
i
i
=
=
−
=
−
=
−
+
=
∞
∑δ
δ
δ
δ
δ
δ
δ
1
1
1
1
(
)

(1.26)
Substituting ½ for δ, we see that the general equation agrees with our previously 
obtained result for Zeno’s paradox.
Before deriving Equation 1.26, we stipulated that |δ| had to be less than one. 
The reason that |δ| has to be less than one may not be obvious. If δ is equal to one, 
we are simply adding together an infinite number of ones, and the sum is infinite. In 
this case, even though it requires us to divide by zero, Equation 1.26 will produce 
the correct answer.
If δ is greater than one, the sum is also infinite, but Equation 1.26 will give you 
the wrong answer. The reason is subtle. If δ is less than one, then δ∞ converges to 
zero. When we multiplied both sides of the original equation by δ, in effect we added 
a δ∞ + 1 term to the end of the original equation. If |δ| is less than one, this term is 
zero, and the sum is unaltered. If |δ| is greater than one, however, this final term is 
itself infinitely large, and we can no longer assume that the sum is unaltered. If this 
is at all unclear, wait until the end of the following section on finite series, where we 
will revisit the issue. If δ is less than −1, the series will oscillate between increasingly 
large negative and positive values and will not converge. Finally, if δ equals −1, the 
series will flip back and forth between −1 and +1, and the sum will oscillate between 
−1 and 0.
One note of caution: In certain financial problems, you will come across geo-
metric series that are very similar to Equation 1.25 except the first term is one, not 
δ. This is equivalent to setting the starting index of the summation to zero (δ0 = 1). 
Adding one to our previous result, we obtain the following equation:
	
S
i
i
=
=
−
=
∞
∑
0
1
1
δ
δ 
(1.27)
As you can see, the change from i = 0 to i = 1 is very subtle, but has a very real 
impact on the sum.
Sample Problem
Question:
A perpetuity is a security that pays a fixed coupon for eternity. Determine 
the present value of a perpetuity that pays a $5 coupon annually. Assume a 
constant 4% discount rate.

12
Mathematics and Statistics for Financial Risk Management
Finite Series
In many financial scenarios—including perpetuities and discount models for 
stocks and real estate—it is often convenient to treat an extremely long series of 
payments as if it were infinite. In other circumstances we are faced with very long 
but clearly finite series. In these circumstances the infinite series solution might 
provide us with a good approximation, but ultimately we will want a more precise 
answer.
The basic technique for summing a long but finite geometric series is the same 
as for an infinite geometric series. The only difference is that the terminal terms no 
longer converge to zero.
	
S
S
S
S
i
i
n
i
i
n
n
n
=
=
=
−
+
=
−
−
=
−
+
=
−
∑
∑
δ
δ
δ
δ
δ
δ
δ
0
1
1
0
1
0
1
1

(1.28)
We can see that for |δ| less than one, as n approaches infinity δn goes to zero, and 
Equation 1.28 converges to Equation 1.27.
In finance, we will mostly be interested in situations where |δ| is less than one, 
but Equation 1.28, unlike Equation 1.27, is still valid for values of |δ| greater than 
one (check this for yourself). We did not need to rely on the final term converging to 
zero this time. If δ is greater than one, and we substitute infinity for n, we get:
	
S =
−
−
=
−∞
−
= −∞
−
= ∞
∞
1
1
1
1
1
δ
δ
δ
δ

(1.29)
For the last step, we rely on the fact that (1 − δ) is negative for δ greater than 
one. As promised in the preceding subsection, for δ greater than one, the sum of the 
infinite geometric series is indeed infinite.
Answer:
V
V
i
i
i
i
=
=
=
=
∞
=
∞
∑
∑
$
( .
)
$
.
$
.
5
1 04
5
1
1 04
5
1
1
1
1
04
1
1
1 04
5
1
1 04
1
5 25
125
−
=
−
=
=
⋅
.
$
.
$
$
V

Some Basic Math
13
Sample Problem
Question:
What is the present value of a newly issued 20-year bond with a notional 
value of $100 and a 5% annual coupon? Assume a constant 4% discount rate 
and no risk of default.
Answer:
This question utilizes discount factors and finite geometric series.
The bond will pay 20 coupons of $5, starting in a year’s time. In addition, 
the notional value of the bond will be returned with the final coupon payment 
in 20 years. The present value, V, is then:
V
$5
(1.04)
$100
(1.04)
$5
1
(1.04)
$100
(1.04)
i
i
i
i
1
20
20
1
20
20
∑
∑
=
+
=
+
=
=
We start by evaluating the summation, using a discount factor of  
δ = 1/1.04 ≈ 0.96:
S
i
i
i
=
(
)
=
=
=
+
+
+
+
1
1 04
1
1 04
2
19
20
.
.
δ
δ
δ
δ
δ
...
i
i
i
S
S
S
−
=
=
∑
∑
∑
=
+
+
+
+
=
1
20
1
20
1
20
2
3
20
21
δ
δ
δ
δ
δ
δ
...
−
+
−
=
−
=
−
−
=
δ
δ
δ
δ
δ
δ
δ
δ
21
21
21
1
1
13 59
S
S
S
(
)
.
Inserting this result into the initial equation, we obtain our final result:
V
$5
13.59
$100
(1.04)
$113.59
20
=
×
+
=
Note that the present value of the bond, $113.59, is greater than the no-
tional value of the bond, $100. In general, if there is no risk of default and the 
coupon rate on the bond is higher than the discount rate, then the present value 
of the bond will be greater than the notional value of the bond.
When the price of a bond is less than the notional value of the bond, 
we say that the bond is selling at a discount. When the price of the bond is 
greater than the notional value, as in this example, we say that it is selling at a 
­premium. When the price is exactly the same as the notional value we say that 
it is selling at par.

14
Mathematics and Statistics for Financial Risk Management
Problems
	 1.	Solve for y, where:
a.	 y = ln(e5)
b.	y = ln(1/e)
c.	 y = ln(10e)
	 2.	The nominal monthly rate for a loan is quoted at 5%. What is the equivalent 
annual rate? Semiannual rate? Continuous rate?
	 3.	Over the course of a year, the log return on a stock market index is 11.2%. The 
starting value of the index is 100. What is the value at the end of the year?
	 4.	You have a portfolio of 10 bonds. In how many different ways can exactly two 
bonds default? Assume the order in which the bonds default is unimportant.
	 5.	What is the present value of a perpetuity that pays $100 per year? Use an annual 
discount rate of 4%, and assume the first payment will be made in exactly one 
year.
	 6.	ABC stock will pay a $1 dividend in one year. Assume the dividend will continue 
to be paid annually forever and the dividend payments will increase in size at a 
rate of 5%. Value this stream of dividends using a 6% annual discount rate.
	 7.	What is the present value of a 10-year bond with a $100 face value, which pays 
a 6% coupon annually? Use an 8% annual discount rate.
	 8.	Solve for x, where e
10
ex =
.
	 9.	Calculate the value of the following summation: 
( 0.5)
i
i
0
9
∑−
=
	10.	The risk department of your firm has 10 analysts. You need to select four ana-
lysts to serve on a special audit committee. How many possible groupings of 
four analysts can be put together?
	11.	What is the present value of a newly issued 10-year bond with a notional value 
of $100 and a 2% annual coupon? Assume a constant 5% annual discount rate 
and no risk of default.

15
I
n this chapter we explore the application of probabilities to risk management. We 
also introduce basic terminology and notations that will be used throughout the 
rest of this book.
Discrete Random Variables
The concept of probability is central to risk management. Many concepts associ-
ated with probability are deceptively simple. The basics are easy, but there are many 
potential pitfalls.
In this chapter, we will be working with both discrete and continuous ­random 
variables. Discrete random variables can take on only a countable number of 
­values—for example, a coin, which can be only heads or tails, or a bond, which can 
have only one of several letter ratings (AAA, AA, A, BBB, etc.). Assume we have a 
discrete random variable X, which can take various values, xi. Further assume that 
the probability of any given xi occurring is pi. We write:
	
P X
x
p
x
x x
x
[
]
s.t.
{
,
, ...,
}
i
i
i
n
1
2
=
=
∈

(2.1)
where P[ ]⋅ is our probability operator.1
An important property of a random variable is that the sum of all the prob-
abilities must equal one. In other words, the probability of any event occurring must 
equal one. Something has to happen. Using our current notation, we have:
	
p
1
i
i i
n
∑
=
=

(2.2)
Continuous Random Variables
In contrast to a discrete random variable, a continuous random variable can 
take on any value within a given range. A good example of a continuous random 
Chapter 2
Probabilities
1 “s.t.” is shorthand for “such that”. The final term indicates that xi is a member of a set that 
includes n possible values, x1, x2, .  .  ., xn. You could read the full equation as: “The probability 
that X equals xi is equal to pi, such that xi is a member of the set x1, x2, to xn.”

16
Mathematics and Statistics for Financial Risk Management
­variable is the return of a stock index. If the level of the index can be any real num-
ber between zero and infinity, then the return of the index can be any real number 
greater than −1.
Even if the range that the continuous variable occupies is finite, the number of 
values that it can take is infinite. For this reason, for a continuous variable, the prob-
ability of any specific value occurring is zero.
Even though we cannot talk about the probability of a specific value occurring, 
we can talk about the probability of a variable being within a certain range. Take, for 
example, the return on a stock market index over the next year. We can talk about 
the probability of the index return being between 6% and 7%, but talking about the 
probability of the return being exactly 6.001% is meaningless. Between 6% and 7% 
there are an infinite number of possible values. The probability of any one of those 
infinite values occurring is zero.
For a continuous random variable X, then, we can write:
	
P[r1 < X < r2] = p
(2.3)
which states that the probability of our random variable, X, being between r1 and 
r2 is equal to p.
Probability Density Functions
For a continuous random variable, the probability of a specific event occurring is not 
well defined, but some events are still more likely to occur than others. Using annual 
stock market returns as an example, if we look at 50 years of data, we might notice 
that there are more data points between 0% and 10% than there are between 10% 
and 20%. That is, the density of points between 0% and 10% is higher than the 
density of points between 10% and 20%.
For a continuous random variable we can define a probability density function 
(PDF), which tells us the likelihood of outcomes occurring between any two points. 
Given our random variable, X, with a probability p of being between r1 and r2, we 
can define our density function, f(x), such that:
	
f x dx
p
( )
r
r
1
2
∫
=

(2.4)
The probability density function is often referred to as the probability distribu-
tion function. Both terms are correct, and, conveniently, both can be abbreviated 
PDF.
As with discrete random variables, the probability of any value occurring must 
be one:
	
f x dx
( )
1
r
r
min
max
∫
=

(2.5)
where rmin and rmax define the lower and upper bounds of f(x).

Probabilities
17
Sample Problem
Question:
Define the probability density function for the price of a zero coupon bond 
with a notional value of $10 as:
f x
x
x
( )
50 s.t. 0
10
=
≤
≤
where x is the price of the bond. What is the probability that the price of the 
bond is between $8 and $9?
Answer:
First, note that this is a legitimate probability function. By integrating the 
PDF from its minimum to its maximum, we can show that the probability of 
any value occurring is indeed one:
x dx
xdx
x
50
1
50
1
50
1
2
1
100(10
0 )
1
0
10
0
10
2
0
10
2
2
∫
∫
=
=
=
−
=
0.0
0.1
0.2
0
2
4
6
8
10
x
f(x)
Exhibit 2.1 
Probability Density Function
If we graph the function, as in Exhibit 2.1, we can also see that the area 
under the curve is one. Using simple geometry:
Area of triangle
Base Height
=
=
=
⋅
⋅
⋅⋅
1
2
1
2 10 0 2
1
.

18
Mathematics and Statistics for Financial Risk Management
Cumulative Distribution Functions
Closely related to the concept of a probability density function is the concept of 
a cumulative distribution function or cumulative density function (both abbrevi-
ated CDF). A cumulative distribution function tells us the probability of a random 
variable being less than a certain value. The CDF can be found by integrating the 
­probability density function from its lower bound. Traditionally, the cumulative 
distribution function is denoted by the capital letter of the corresponding density 
­function. For a random variable X with a probability density function f(x), then, the 
cumulative distribution function, F(x), could be calculated as follows:
	
F a
f x dx
P X
a
( )
( )
[
]
a
∫
=
=
≤
−∞

(2.6)
As illustrated in Exhibit 2.2, the cumulative distribution function corresponds to 
the area under the probability density function, to the left of a.
To answer the question, we simply integrate the probability density func-
tion between 8 and 9:
x dx
x
50
1
100
1
100(9
8 )
17
100
17%
2
8
9
2
2
8
9
∫
=
=
−
=
=
The probability of the price ending up between $8 and $9 is 17%.
Exhibit 2.2 
Relationship between Cumulative Distribution Function and Probability Density 
Function
0.1
0.0
0.2
0
2
4
6
8
10
x
f (x)
CDF(a = 7)

Probabilities
19
By definition, the cumulative distribution function varies from 0 to 1 and is non-
decreasing. At the minimum value of the probability density function, the CDF must 
be zero. There is no probability of the variable being less than the minimum. At the 
other end, all values are less than the maximum of the PDF. The probability is 100% 
(CDF = 1) that the random variable will be less than or equal to the maximum. In 
between, the function is nondecreasing. The reason that the CDF is nondecreasing is 
that, at a minimum, the probability of a random variable being between two points 
is zero. If the CDF of a random variable at 5 is 50%, then the lowest it could be at 6 
is 50%, which would imply 0% probability of finding the variable between 5 and 6. 
There is no way the CDF at 6 could be less than the CDF at 5.
Just as we can get the cumulative distribution from the probability density func-
tion by integrating, we can get the PDF from the CDF by taking the first derivative 
of the CDF:
	
f x
dF x
dx
( )
( )
=

(2.7)
That the CDF is nondecreasing is another way of saying that the PDF cannot be 
negative.
If instead of wanting to know the probability that a random variable is less than 
a certain value, what if we want to know the probability that it is greater than a 
certain value, or between two values? We can handle both cases by adding and sub-
tracting cumulative distribution functions. To find the probability that a variable is 
between two values, a and b, assuming b is greater than a, we subtract:
	
P a
X
b
f x dx
F b
F a
[
]
( )
( )
( )
a
b
∫
<
≤
=
=
−

(2.8)
To get the probability that a variable is greater than a certain value, we simply 
subtract from 1:
	
P[X > a] = 1 − F(a)
(2.9)
This result can be obtained by substituting infinity for b in the previous equa-
tion, remembering that the CDF at infinity must be 1.
Sample Problem
Question:
Calculate the cumulative distribution function for the probability density 
function from the previous problem:
	
f x
x
x
( )
50 s.t. 0
10
=
≤
≤

(2.10)
Then answer the previous problem: What is the probability that the price 
of the bond is between $8 and $9?

20
Mathematics and Statistics for Financial Risk Management
Inverse Cumulative Distribution Functions
The inverse of the cumulative distribution can also be useful. For example, we might 
want to know that there is a 5% probability that a given equity index will return less 
than −10.6%, or that there is a 1% probability of interest rates increasing by more 
than 2% over a month.
More formally, if F(a) is a cumulative distribution function, then we define F–1(p), 
the inverse cumulative distribution, as follows:
	
F a
p
F
p
a
p
( )
( )
s.t. 0
1
1
=
⇔
=
≤
≤
−

(2.11)
As we will see in Chapter 4, while some popular distributions have very simple 
inverse cumulative distribution functions, for other distributions no explicit inverse 
exists.
Answer:
The CDF can be found by integrating the PDF:
F a
f x dx
x dx
xdx
x
a
( )
( )
50
1
50
1
50
1
2
100
a
a
a
a
0
0
0
2
0
2
∫
∫
∫
=
=
=
=
=
To get the answer to the question, we simply evaluate the CDF at $8 and 
$9 and subtract:
P
x
F
F
[$8
$9]
(9)
(8)
9
100
8
100
81
100
64
100
17
100
17%
2
2
<
≤
=
−
=
−
=
−
=
=
As before, the probability of the price ending up between $8 and $9 is 17%.
Sample Problem
Question:
Given the cumulative distribution from the previous sample problem:
F a
a
a
( )
100 s.t. 0
10
2
=
≤
≤
Calculate the inverse cumulative distribution function. Find the value of a 
such that 25% of the distribution is less than or equal to a.
Answer:
We have:
F a
p
a
( )
100
2
=
=

Probabilities
21
Mutually Exclusive Events
For a given random variable, the probability of any of two mutually exclusive events 
occurring is just the sum of their individual probabilities. In statistics notation, we 
can write:
	
P A
B
P A
P B
[
]
[ ]
[ ]
∪
=
+

(2.12)
where A
B
[
]
∪
 is the union of A and B. This is the probability of either A or B 
­occurring. This is true only of mutually exclusive events.
This is a very simple rule, but, as mentioned at the beginning of the chapter, 
­probability can be deceptively simple, and this property is easy to confuse. The 
­confusion stems from the fact that and is synonymous with addition. If you say it 
this way, then the probability that A or B occurs is equal to the probability of A and 
the probability of B. It is not terribly difficult, but you can see where this could lead 
to a mistake.
This property of mutually exclusive events can be extended to any number of 
events. The probability that any of n mutually exclusive events occurs is simply the 
sum of the probabilities of those n events.
Solving for p:
a
p
10
=
Therefore, the inverse CDF is:
F
p
p
( )
10
1
=
−
We can quickly check that p = 0 and p = 1, return 0 and 10, the minimum 
and maximum of the distribution. For p = 25% we have:
F−
=
=
=
⋅
1 0 25
10 0 25
10 0 5
5
( .
)
.
.
So 25% of the distribution is less than or equal to 5.
Sample Problem
Question:
Calculate the probability that a stock return is either below −10% or 
above 10%, given:
P R
P R
[
10%]
14%
[
10%]
17%
< −
=
> +
=
Answer:
Note that the two events are mutually exclusive; the return cannot be below 
−10% and above 10% at the same time. The answer is: 14% + 17% = 31%.

22
Mathematics and Statistics for Financial Risk Management
Independent Events
In the preceding example, we were talking about one random variable and two 
mutually exclusive events, but what happens when we have more than one random 
variable? What is the probability that it rains tomorrow and the return on stock 
XYZ is greater than 5%? The answer depends crucially on whether the two random 
variables influence each other. If the outcome of one random variable is not influ-
enced by the outcome of the other random variable, then we say those variables are 
independent. If stock market returns are independent of the weather, then the stock 
market should be just as likely to be up on rainy days as it is on sunny days.
Assuming that the stock market and the weather are independent random 
variables, then the probability of the market being up and rain is just the product 
of the probabilities of the two events occurring individually. We can write this as 
follows:
	
P
P
[
[
rain and market up]
rain
market up]
=
∩
= P
P
[rain]
[market up]
⋅
 (2.13)
We often refer to the probability of two events occurring together as their joint 
probability.
Sample Problem
Question:
According to the most recent weather forecast, there is a 20% chance of 
rain tomorrow. The probability that stock XYZ returns more than 5% on any 
given day is 40%. The two events are independent. What is the probability that 
it rains and stock XYZ returns more than 5% tomorrow?
Answer:
Since the two events are independent, the probability that it rains and 
stock XYZ returns more than 5% is just the product of the two probabilities. 
The answer is: 20% × 40% = 8%.
Probability Matrices
When dealing with the joint probabilities of two variables, it is often convenient to 
summarize the various probabilities in a probability matrix or probability table. 
For example, pretend we are investigating a company that has issued both bonds 
and stock. The bonds can be downgraded, upgraded, or have no change in rating. 
The stock can either outperform the market or underperform the market. 
In Exhibit 2.3, the probability of both the company’s stock outperforming the 
market and the bonds being upgraded is 15%. Similarly, the probability of the stock 
underperforming the market and the bonds having no change in rating is 25%. 
We can also see the unconditional probabilities, by adding across a row or down a 

Probabilities
23
­column. The probability of the bonds being upgraded, irrespective of the stock’s per-
formance, is: 15% + 5% = 20%. Similarly, the probability of the equity outperform-
ing the market is: 15% + 30% + 5% = 50%. Importantly, all of the joint probabilities 
add to 100%. Given all the possible events, one of them must happen.
Exhibit 2.3 
Bonds versus Stock Matrix
Stock
Outperform
Underperform
Bonds
Upgrade
15%
5%
20%
No Change
30%
25%
55%
Downgrade
5%
20%
25%
50%
50%
100%
Sample Problem
Question:
You are investigating a second company. As with our previous example, 
the company has issued both bonds and stock. The bonds can be downgraded, 
upgraded, or have no change in rating. The stock can either outperform the 
market or underperform the market. You are given the probability matrix 
shown in Exhibit 2.4, which is missing three probabilities, X, Y, and Z. Calcu-
late values for the missing probabilities.
Exhibit 2.4 
Bonds versus Stock Matrix
Stock
Outperform
Underperform
Bonds
Upgrade
5%
0%
5%
No Change
40%
Y
Z
Downgrade
X
30%
35%
50%
50%
100%
Answer:
All of the values in the first column must add to 50%, the probability of 
the stock outperforming the market; therefore, we have:
5% + 40% + X = 50%
	
X = 5%
We can check our answer for X by summing across the third row:  
5% + 30% = 35%.

24
Mathematics and Statistics for Financial Risk Management
Conditional Probability
The concept of independence is closely related to the concept of conditional prob-
ability. Rather than trying to determine the probability of the market being up and 
having rain, we can ask, “What is the probability that the stock market is up given 
that it is raining?” We can write this as a conditional probability:
	
P[market up | rain] = p 
(2.14)
The vertical bar signals that the probability of the first argument is conditional on 
the second. You would read Equation 2.14 as “The probability of ‘market up’ given 
‘rain’ is equal to p.”
Using the conditional probability, we can calculate the probability that it will 
rain and that the market will be up.
	
P[market up and rain] = P[market up | rain] ∙ P[rain]
(2.15)
For example, if there is a 10% probability that it will rain tomorrow and the prob-
ability that the market will be up given that it is raining is 40%, then the probability 
of rain and the market being up is 4%: 40% × 10% = 4%.
From a statistics standpoint, it is just as valid to calculate the probability that it 
will rain and that the market will be up as follows:
	
P[market up and rain] = P[rain | market up] ∙ P[market up]
(2.16)
As we will see in Chapter 6 when we discuss Bayesian analysis, even though the 
right-hand sides of Equations 2.15 and 2.16 are mathematically equivalent, how we 
interpret them can often be different.
We can also use conditional probabilities to calculate unconditional probabili-
ties. On any given day, either it rains or it does not rain. The probability that the 
market will be up, then, is simply the probability of the market being up when it is 
raining plus the probability of the market being up when it is not raining. We have:
P[market up] = P[market up and rain] + P[market up and rain]
P[market up] = P[market up | rain] ∙ P[rain] + P[market up | rain] ∙ P[rain] 

(2.17)
Looking down the second column, we see that Y is equal to 20%:
0% + Y + 30% = 50%
	
Y = 20%
Finally, knowing that Y = 20%, we can sum across the second row to get Z:
40% + Y = 40% + 20% = Z
	
Z = 60%

Probabilities
25
Here we have used a line over rain to signify logical negation; rain can be read as 
“not rain.”
In general, if a random variable X has n possible values, x1, x2, .  .  ., xn, then the 
unconditional probability of Y can be calculated as:
	
P Y
P Y x
P x
[ ]
[
] [
]
i
i
i
n
1∑
=
|
=

(2.18)
If the probability of the market being up on a rainy day is the same as the prob-
ability of the market being up on a day with no rain, then we say that the market 
is conditionally independent of rain. If the market is conditionally independent of 
rain, then the probability that the market is up given that it is raining must be equal 
to the unconditional probability of the market being up. To see why this is true, 
we replace the conditional probability of the market being up given no rain with 
the conditional probability of the market being up given rain in Equation 2.17 (we 
can do this because we are assuming that these two conditional probabilities are 
equal).
P[market up] = P[market up | rain] ∙ P[rain] + P[market up | rain] ∙ P[rain]
P[market up] = P[market up | rain] ∙ (P[rain] + P[rain])
P[market up] = P[market up | rain]
(2.19)
In the last line of Equation 2.19, we rely on the fact that the probability of rain plus 
the probability of no rain is equal to one. Either it rains or it does not rain.
In Equation 2.19 we could just have easily replaced the conditional probability 
of the market being up given rain with the conditional probability of the market 
being up given no rain. If the market is conditionally independent of rain, then it is 
also true that the probability that the market is up given that it is not raining must 
be equal to the unconditional probability of the market being up:
	
P[market up] = P[market up | rain]
(2.20)
In the previous section, we noted that if the market is independent of rain, then 
the probability that the market will be up and that it will rain must be equal to 
the probability of the market being up multiplied by the probability of rain. To 
see why this must be true, we simply substitute the last line of Equation 2.19 into 
Equation 2.15:
P[market up and rain] = P[market up | rain] ∙ P[rain]
	
P[market up and rain] = P[market up] ∙ P[rain]
(2.21)
Remember that Equation 2.21 is true only if the market being up and rain are 
­independent. If the weather somehow affects the stock market, however, then the 
conditional probabilities might not be equal. We could have a situation where:
	
P[market up | rain] ≠ P[market up | rain]
(2.22)

26
Mathematics and Statistics for Financial Risk Management
In this case, the weather and the stock market are no longer independent. We can no 
longer multiply their probabilities together to get their joint probability.
Problems
	 1.	You are invested in two hedge funds. The probability that hedge fund Alpha 
­generates positive returns in any given year is 60%. The probability that hedge 
fund Omega generates positive returns in any given year is 70%. Assume the 
­returns are independent. What is the probability that both funds generate 
­positive ­returns in a given year? What is the probability that both funds lose 
money?
	 2.	Corporation ABC issues $100 million of bonds. The bonds are rated BBB. The 
probability that the rating on the bonds is upgraded within the year is 8%. 
The probability of a downgrade is 4%. What is the probability that the rating 
­remains unchanged?
	 3.	Stock XYZ has a 20% chance of losing more than 10% in a given month. 
There is also a 30% probability that XYZ gains more than 10%. What is the 
­probability that stock XYZ either loses more than 10% or gains more than 
10%?
	 4.	There is a 30% chance that oil prices will increase over the next six months. If 
oil prices increase, there is a 60% chance that the stock market will be down. 
What is the probability that oil prices increase and the stock market is down 
over the next six months?
	 5.	Given the following density function:
f x
c
x
x
( )
(100
) for
10
10
0
otherwise
2
=
−
−
≤
≤
	
	 Calculate the value of c. 
	 6.	Given the following cumulative distribution function, F(x), for 0 ≤ x ≤ 10: 
F x
x
x
( )
100(20
)
=
−
	
	 Check that this is a valid CDF; that is, show that F(0) = 0 and F(10) = 1. ­Calculate 
the probability density function, f(x).
	 7.	Given the probability density function, f(x):
f x
c
x
( ) =
	
	 where 1 ≤ x ≤ e. Calculate the cumulative distribution function, F(x), and solve 
for the constant c.
	 8.	You own two bonds. Both bonds have a 30% probability of defaulting. Their 
default probabilities are statistically independent. What is the probability that 
both bonds default? What is the probability that only one bond defaults? What 
is the probability that neither bond defaults?

Probabilities
27
	 9.	The following table is a one-year ratings transition matrix. Given a bond’s rating 
now, the matrix gives the probability associated with the bond having a given 
rating in a year’s time. For example, a bond that starts the year with an A rating 
has a 90% chance of maintaining that rating and an 8% chance of migrating to 
a B rating. Given a B-rated bond, what is the probability that the bond defaults 
(D rating) over one year? What is the probability that the bond defaults over two 
years? 
To a rating of:
A
B
C
D
From a 
rating of:
A
90%
8%
2%
0%
B
10%
80%
8%
2%
C
0%
25%
60%
15%
D
0%
0%
0%
100%
	10.	Your firm forecasts that there is a 50% probability that the market will be up 
significantly next year, a 20% probability that the market will be down signifi-
cantly next year, and a 30% probability that the market will be flat, neither up 
or down significantly. You are asked to evaluate the prospects of a new portfolio 
manager. The manager has a long bias and is likely to perform better in an up 
market. Based on past data, you believe that the probability that the manager 
will be up if the market is up significantly is 80%, and that the probability that 
the manager will be up if the market is down significantly is only 10%. If the 
market is flat, the manager is just as likely to be up as to be down. What is the 
unconditional probability that the manager is up next year?


29
I
n this chapter we will learn how to describe a collection of data in precise statisti-
cal terms. Many of the concepts will be familiar, but the notation and terminology 
might be new. This notation and terminology will be used throughout the rest of the 
book.
Averages
Everybody knows what an average is. We come across averages every day, ­whether 
they are earned run averages in baseball or grade point averages in school. In statis-
tics there are actually three different types of averages: means, modes, and medians. 
By far the most commonly used average in risk management is the mean.
Population and Sample Data
If you wanted to know the mean age of people working in your firm, you would 
simply ask every person in the firm his or her age, add the ages together, and divide 
by the number of people in the firm. Assuming there are n employees and ai is the age 
of the ith employee, then the mean, µ, is simply:
	
µ =
=
+
+
+
+
=
−
∑
1
1
1
1
2
1
n
a
n a
a
a
a
i
n
i
n
n
(
...
) 
(3.1)
It is important at this stage to differentiate between population statistics and 
sample statistics. In this example, µ is the population mean. Assuming nobody lied 
about his or her age, and forgetting about rounding errors and other trivial details, 
we know the mean age of the people in your firm exactly. We have a complete data 
set of everybody in your firm; we’ve surveyed the entire population.
This state of absolute certainty is, unfortunately, quite rare in finance. More 
often, we are faced with a situation such as this: estimate the mean return of stock 
ABC, given the most recent year of daily returns. In a situation like this, we assume 
there is some underlying data-generating process, whose statistical properties are 
constant over time. The underlying process has a true mean, but we cannot observe 
Chapter 3
Basic Statistics

30
Mathematics and Statistics for Financial Risk Management
it directly. We can only estimate the true mean based on our limited data sample. In 
our example, assuming n returns, we estimate the mean using the same formula as 
before:
	
ˆ
...
µ =
=
+
+
+
+
(
)
=
−
∑
1
1
1
1
2
1
n
r
n r
r
r
r
i
i
n
n
n 
(3.2)
where ˆµ  (pronounced “mu hat”) is our estimate of the true mean, µ, based on our 
sample of n returns. We call this the sample mean.
The median and mode are also types of averages. They are used less frequently in 
finance, but both can be useful. The median represents the center of a group of data; 
within the group, half the data points will be less than the median, and half will be 
greater. The mode is the value that occurs most frequently.
Sample Problem
Question:
Calculate the mean, median, and mode of the following data set:
−20%, −10%, −5%, −5%, 0%, 10%, 10%, 10%, 19%
Answer:
Mean = 1
9(−20% − 10% − 5% − 5% + 0% + 10% + 10% + 10% + 19%) = 1%
Mode = 10%
Median = 0%
If there is an even number of data points, the median is found by averaging the 
two centermost points. In the following series:
5%, 10%, 20%, 25%
the median is 15%. The median can be useful for summarizing data that is asym-
metrical or contains significant outliers.
A data set can also have more than one mode. If the maximum frequency is 
shared by two or more values, all of those values are considered modes. In the fol-
lowing example, the modes are 10% and 20%:
5%, 10%, 10%, 10%, 14%, 16%, 20%, 20%, 20%, 24%
In calculating the mean in Equation 3.1 and Equation 3.2, each data point 
was counted exactly once. In certain situations, we might want to give more or 

Basic Statistics
31
less weight to certain data points. In calculating the average return of stocks in an 
equity index, we might want to give more weight to larger firms, perhaps weight-
ing their returns in proportion to their market capitalizations. Given n data points, 
xi = x1, x2,  .  .  ., xn, with corresponding weights, wi, we can define the weighted 
mean, µw, as:
	
µw
i
n
i
i
i
n
i
w x
w
=
=
=
∑
∑
1
1

(3.3)
The standard mean from Equation 3.1 can be viewed as a special case of the 
weighted mean, where all the values have equal weight.
Discrete Random Variables
For a discrete random variable, we can also calculate the mean, median, and mode. 
For a random variable, X, with possible values, xi, and corresponding probabilities, 
pi, we define the mean, µ, as:
	
µ =
=∑
i
n
i
i
p x
1

(3.4)
The equation for the mean of a discrete random variable is a special case of the 
weighted mean, where the outcomes are weighted by their probabilities, and the sum 
of the weights is equal to one.
The median of a discrete random variable is the value such that the probabil-
ity that a value is less than or equal to the median is equal to 50%. Working from 
the other end of the distribution, we can also define the median such that 50% of 
the values are greater than or equal to the median. For a random variable, X, if we 
­denote the median as m, we have:
	
P[X ≥ m] = P[X ≤ m] = 0.50
(3.5)
For a discrete random variable, the mode is the value associated with the highest 
probability. As with population and sample data sets, the mode of a discrete random 
variable need not be unique.
Sample Problem
Question:
At the start of the year, a bond portfolio consists of two bonds, each worth 
$100. At the end of the year, if a bond defaults, it will be worth $20. If it does 
not default, the bond will be worth $100. The probability that both bonds de-
fault is 20%. The probability that neither bond defaults is 45%. What are the 
mean, median, and mode of the year-end portfolio value?

32
Mathematics and Statistics for Financial Risk Management
Continuous Random Variables
We can also define the mean, median, and mode for a continuous random variable. 
To find the mean of a continuous random variable, we simply integrate the product 
of the variable and its probability density function (PDF). In the limit, this is equiva-
lent to our approach to calculating the mean of a discrete random variable. For a 
continuous random variable, X, with a PDF, f(x), the mean, µ, is then:
	
µ = ∫
x
x
xf x dx
min
max
( )

(3.6)
The median of a continuous random variable is defined exactly as it is for a 
discrete random variable, such that there is a 50% probability that values are less 
than or equal to, or greater than or equal to, the median. If we define the median as 
m, then:
	
f x dx
f x dx
( )
( )
0.50
x
m
m
x
min
max
∫
∫
=
=

(3.7)
Alternatively, we can define the median in terms of the cumulative distribution 
function. Given the cumulative distribution function, F(x), and the median, m, we 
have:
	
F(m) = 0.50
(3.8)
The mode of a continuous random variable corresponds to the maximum of the 
density function. As before, the mode need not be unique.
Answer:
We are given the probability for two outcomes:
P[V = $40] = 20%
P[V = $200] = 45%
At year-end, the value of the portfolio, V, can have only one of three 
­values, and the sum of all the probabilities must sum to 100%. This allows us 
to ­calculate the final probability:
P[V = $120] = 100% − 20% − 45% = 35%
The mean of V is then $140:
µ = 0.20 ∙ $40 + 0.35 ∙ $120 + 0.45 ∙ $200 = $140
The mode of the distribution is $200; this is the most likely single out-
come. The median of the distribution is $120; half of the outcomes are less 
than or equal to $120.

Basic Statistics
33
Sample Problem
Question:
Using the now-familiar probability density function from Chapter 2,
f x
x
x
( )
50 s.t. 0
10
=
≤
≤
what are the mean, median, and mode of x?
Answer:
As we saw in a previous example, this probability density function is a 
triangle, between x = 0 and x = 10, and zero everywhere else. See Exhibit 3.1.
Exhibit 3.1 
Probability Density Function
0.0
0.1
0.2
0
2
4
6
8
10
x
f(x)
For a continuous distribution, the mode corresponds to the maximum of 
the PDF. By inspection of the graph, we can see that the mode of f(x) is equal 
to 10.
To calculate the median, we need to find m, such that the integral of f(x) 
from the lower bound of f(x), zero, to m is equal to 0.50. That is, we need to 
find:
∫
=
x dx
50
0.50
m
0

34
Mathematics and Statistics for Financial Risk Management
Expectations
On January 15, 2005, the Huygens space probe landed on the surface of Titan, the 
largest moon of Saturn. This was the culmination of a seven-year-long mission. Dur-
ing its descent and for over an hour after touching down on the surface, Huygens 
sent back detailed images, scientific readings, and even sounds from a strange world. 
There are liquid oceans on Titan, the landing site was littered with “rocks” com-
posed of water ice, and weather on the moon includes methane rain. The Huygens 
probe was named after Christiaan Huygens, a Dutch polymath who first discovered 
Titan in 1655. In addition to astronomy and physics, Huygens had more prosaic 
interests, including probability theory. Originally published in Latin in 1657, De 
Ratiociniis in Ludo Aleae, or On the Logic of Games of Chance, was one of the first 
texts to formally explore one of the most important concepts in probability theory, 
namely expectations.
First we solve the left-hand side of the equation:
x dx
xdx
x
m
m
50
1
50
1
50
1
2
1
100(
0)
100
m
m
m
0
0
2
0
2
2
∫
∫
=
=
=
−
=
Setting this result equal to 0.50 and solving for m, we obtain our final 
answer:
m
m
m
100
0.50
50
50
7.07
2
2
=
=
=
=
In the last step we can ignore the negative root. If we hadn’t calculated 
the median, looking at the graph it might be tempting to guess that the me-
dian is 5, the midpoint of the range of the distribution. This is a common 
mistake. Because lower values have less weight, the median ends up being 
greater than 5.
The mean is approximately 6.67:
μ =
=
=
=
∫
∫
0
10
0
10
2
3
0
10
50
1
50
1
50
1
3
1
x x dx
x dx
x
,
.
000
150
20
3
6 67
=
=
As with the median, it is a common mistake, based on inspection of the 
PDF, to guess that the mean is 5. However, what the PDF is telling us is that 
outcomes between 5 and 10 are much more likely than values between 0 and 
5 (the PDF is higher between 5 and 10 than between 0 and 5). This is why the 
mean is greater than 5.

Basic Statistics
35
Like many of his contemporaries, Huygens was interested in games of chance. 
As he described it, if a game has a 50% probability of paying $3 and a 50% prob-
ability of paying $7, then this is, in a way, equivalent to having $5 with certainty. 
This is because we expect, on average, to win $5 in this game:
	
50% ∙ $3 + 50% ∙ $7 = $5
(3.9)
As one can already see, the concepts of expectations and averages are very ­closely 
linked. In the current example, if we play the game only once, there is no chance of 
winning exactly $5; we can win only $3 or $7. Still, even if we play the game only 
once, we say that the expected value of the game is $5. That we are talking about the 
mean of all the potential payouts is understood.
We can express the concept of expectations more formally using the expectation 
operator. We could state that the random variable, X, has an expected value of $5 
as follows:
	
E[X] = 0.50 ∙ $3 + 0.50 ∙ $7 = $5
(3.10)
where E[∙] is the expectation operator.1
In this example, the mean and the expected value have the same numeric value, 
$5. The same is true for discrete and continuous random variables. The expected 
value of a random variable is equal to the mean of the random variable.
While the value of the mean and the expected value may be the same in many situ-
ations, the two concepts are not exactly the same. In many situations in finance and 
risk management, the terms can be used interchangeably. The difference is often subtle.
As the name suggests, expectations are often thought of as being forward-­
looking. Pretend we have a financial asset for which next year’s mean annual return 
is known and equal to 15%. This is not an estimate; in this hypothetical scenario, 
we actually know that the mean is 15%. We say that the expected value of the return 
next year is 15%. We expect the return to be 15%, because the probability-weighted 
mean of all the possible outcomes is 15%.
Now pretend that we don’t actually know what the mean return of the asset is, 
but we have 10 years’ worth of historical data for which the mean is 15%. In this 
case the expected value may or may not be 15%. If we decide that the expected value 
is equal to 15%, based on the data, then we are making two assumptions: first, we 
are assuming that the returns in our sample were generated by the same random 
process over the entire sample period; second, we are assuming that the returns will 
continue to be generated by this same process in the future. These are very strong as-
sumptions. If we have other information that leads us to believe that one or both of 
these assumptions are false, then we may decide that the expected value is something 
other than 15%. In finance and risk management, we often assume that the data we 
are interested in are being generated by a consistent, unchanging process. Testing the 
validity of this assumption can be an important part of risk management in practice.
1 Those of you with a background in physics might be more familiar with the term expectation 
value and the notation 〈X〉 rather than E[X]. This is a matter of convention. Throughout this 
book we use the term expected value and E[ ], which are currently more popular in finance 
and econometrics. Risk managers should be familiar with both conventions.

36
Mathematics and Statistics for Financial Risk Management
The concept of expectations is also a much more general concept than the con-
cept of the mean. Using the expectation operator, we can derive the expected value of 
functions of random variables. As we will see in subsequent sections, the concept of 
expectations underpins the definitions of other population statistics (variance, skew-
ness, kurtosis), and is important in understanding regression analysis and time series 
analysis. In these cases, even when we could use the mean to describe a calculation, 
in practice we tend to talk exclusively in terms of expectations.
Sample Problem
Question:
At the start of the year, you are asked to price a newly issued zero coupon 
bond. The bond has a notional of $100. You believe there is a 20% chance that 
the bond will default, in which case it will be worth $40 at the end of the year. 
There is also a 30% chance that the bond will be downgraded, in which case 
it will be worth $90 in a year’s time. If the bond does not default and is not 
downgraded, it will be worth $100. Use a continuous interest rate of 5% to 
determine the current price of the bond.
Answer:
We first need to determine the expected future value of the bond—that is, 
the expected value of the bond in one year’s time. We are given the following:
P[Vt+1 = $40] = 0.20
P[Vt+1 = $90] = 0.30
Because there are only three possible outcomes, the probability of no 
downgrade and no default must be 50%:
P[Vt+1 = $100] = 1 − 0.20 − 0.30 = 0.50
The expected value of the bond in one year is then:
E[Vt+1] = 0.20 ∙ $40 + 0.30 ∙ $90 + 0.50 ∙ $100 = $85
To get the current price of the bond we then discount this expected future 
value:
E[Vt] = e−0.05E[Vt+1] = e−0.05$85 = $80.85
The current price of the bond, in this case $80.85, is often referred to as the 
present value or fair value of the bond. The price is considered fair because the 
discounted expected value of the bond is the price that a risk-neutral investor 
would pay for the bond.

Basic Statistics
37
The expectation operator is linear. That is, for two random variables, X and Y, 
and a constant, c, the following two equations are true:
	
E[X + Y] = E[X] + E[Y]
	
E[cX ] = cE[X]

(3.11)
If the expected value of one option, A, is $10, and the expected value of option B 
is $20, then the expected value of a portfolio containing A and B is $30, and the 
expected value of a portfolio containing five contracts of option A is $50.
Be very careful, though; the expectation operator is not multiplicative. The ex-
pected value of the product of two random variables is not necessarily the same as 
the product of their expected values:
	
E[XY] ≠ E[X]E[Y]
(3.12)
Imagine we have two binary options. Each pays either $100 or nothing, depend-
ing on the value of some underlying asset at expiration. The probability of receiving 
$100 is 50% for both options. Further, assume that it is always the case that if the 
first option pays $100, the second pays $0, and vice versa. The expected value of 
each option separately is clearly $50. If we denote the payout of the first option as X 
and the payout of the second as Y, we have:
	
E[X ] = E[Y ] = 0.50 ∙ $100 + 0.50 ∙ $0 = $50
(3.13)
It follows that E[X]E[Y] = $50 × $50 = $2,500. In each scenario, though, one 
­option is valued at zero, so the product of the payouts is always zero: $100 ∙ $0 = $0 ∙ 
$100 = $0. The expected value of the product of the two option payouts is:
	
E[XY ] = 0.50 ∙ $100 ∙ $0 + 0.50 ∙ $0 ∙ $100 = $0
(3.14)
In this case, the product of the expected values and the expected value of the 
product are clearly not equal. In the special case where E[XY] = E[X]E[Y], we say 
that X and Y are independent.
If the expected value of the product of two variables does not necessarily equal 
the product of the expectations of those variables, it follows that the expected value 
of the product of a variable with itself does not necessarily equal the product of the 
expectation of that variable with itself; that is:
	
E[X2] ≠ E[X]2
(3.15)
Imagine we have a fair coin. Assign heads a value of +1 and tails a value of −1. 
We can write the probabilities of the outcomes as follows:
	
P[X = +1] = P[X = −1] = 0.50
(3.16)

38
Mathematics and Statistics for Financial Risk Management
The expected value of any coin flip is zero, but the expected value of X2 is +1, 
not zero:
	
E[X ] = 0.50 ∙ (+1) + 0.50 ∙ (−1) = 0
E[X]2 = 02 = 0
E[X2] = 0.50 ∙ (+12) + 0.50 ∙ (−12) = 1

(3.17)
As simple as this example is, this distinction is very important. As we will see, 
the difference between E[X2] and E[X]2 is central to our definition of variance and 
standard deviation.
Sample Problem
Question:
Given the following equation,
y = (x + 5)3 + x2 + 10x
what is the expected value of y? Assume the following:
E[x ] = 4
E[x2] = 9
E[x3] = 12
Answer:
Note that E[x2] and E[x3] cannot be derived from knowledge of E[x]. In 
this problem, E[x2] ≠ E[x]2 and E[x3] ≠ E[x]3. 
To find the expected value of y, then, we first expand the term (x + 5)3 
within the expectation operator:
E[y] = E[(x + 5)3 + x2 + 10x] = E[x3 + 16x2 + 85x + 125]
Because the expectation operator is linear, we can separate the terms in the 
summation and move the constants outside the expectation operator:
E[y] = E[x3] + E[16x2] + E[85x] + E[125]
= E[x3] + 16E[x2] + 85E[x] + 125
At this point, we can substitute in the values for E[x], E[x2], and E[x3], 
which were given at the start of the exercise:
E[Y ] = 12 + 16 ∙ 9 + 85 ∙ 4 + 125 = 621
This gives us the final answer, 621.

Basic Statistics
39
Variance and Standard Deviation
The variance of a random variable measures how noisy or unpredictable that ran-
dom variable is. Variance is defined as the expected value of the difference between 
the variable and its mean squared:
	
σ2 = E[(X − µ)2]
(3.18)
where σ2 is the variance of the random variable X with mean µ.
The square root of variance, typically denoted by σ, is called standard deviation. 
In finance we often refer to standard deviation as volatility. This is analogous to 
referring to the mean as the average. Standard deviation is a mathematically precise 
term, whereas volatility is a more general concept.
Sample Problem
Question:
A derivative has a 50/50 chance of being worth either +10 or −10 at expiry. 
What is the standard deviation of the derivative’s value?
Answer:
µ = 0.50 ∙ 10 + 0.50 ∙ (−10) = 0
σ2 = 0.50 ∙ (10 − 0)2 + 0.50 ∙ (−10 − 0)2 = 0.5 ∙ 100 + 0.5 ∙ 100 = 100
σ = 10
In the previous example, we were calculating the population variance and stand-
ard deviation. All of the possible outcomes for the derivative were known.
To calculate the sample variance of a random variable X based on n observa-
tions, x1, x2,  .  .  ., xn, we can use the following formula:
	
ˆ
(
ˆ )
[ ˆ ]
σ
µ
σ
σ
2
1
2
2
1
1
x
i
x
i
n
x
x
n
x
E
=
−
−
=
=∑

(3.19)
where ˆµx is the sample mean as in Equation 3.2. Given that we have n data points, 
it might seem odd that we are dividing the sum by (n − 1) and not n. The reason 
has to do with the fact that ˆµx itself is an estimate of the true mean, which also 
contains a fraction of each xi. We leave the proof for a problem at the end of the 
chapter, but it turns out that dividing by (n − 1), not n, produces an unbiased es-
timate of σ 2. If the mean is known or we are calculating the population variance, 
then we divide by n. If instead the mean is also being estimated, then we divide 
by n − 1.

40
Mathematics and Statistics for Financial Risk Management
Equation 3.18 can easily be rearranged as follows (the proof of this equation is 
also left as an exercise):
	
σ
µ
2
2
2
2
2
=
−
=
−
E X
E X
E X
[
]
[
]
[
] 
(3.20)
Note that variance can be nonzero only if E[X]2 ≠ E[X]2.
When writing computer programs, this last version of the variance formula is of-
ten useful, since it allows us to calculate the mean and the variance in the same loop. 
In finance it is often convenient to assume that the mean of a random variable 
is equal to zero. For example, based on theory, we might expect the spread between 
two equity indexes to have a mean of zero in the long run. In this case, the variance 
is simply the mean of the squared returns.
Sample Problem
Question:
Assume that the mean of daily Standard & Poor’s (S&P) 500 Index returns 
is zero. You observe the following returns over the course of 10 days:
7% – 4% 11% 8%
3%
9% –21% 10% –9% –1%
Estimate the standard deviation of daily S&P 500 Index returns.
Answer:
The sample mean is not exactly zero, but we are told to assume that the 
population mean is zero; therefore:
ˆ
(
)
ˆ
.
σ
σ
r
i
i
i
n
i
n
r
n
r
n
r
2
2
2
2
1
1
2
1
0
1
1
100 09
=
−
=
=
=
=
∑
∑
63
0 00963
9 8
=
=
.
ˆ
. %
σr
Note, because we were told to assume the mean was known, we divide by 
n = 10, not (n − 1) = 9.
As with the mean, for a continuous random variable we can calculate the vari-
ance by integrating with the probability density function. For a continuous random 
variable, X, with a probability density function, f(x), the variance can be calculated 
as:
	
σ
µ
2
2
=
−
∫
x
x
x
f x dx
min
max
(
)
( )

(3.21)

Basic Statistics
41
It is not difficult to prove that, for either a discrete or a continuous random 
variable, multiplying by a constant will increase the standard deviation by the same 
factor:
	
σ
σ
[
]
[
]
cX
c
X
=

(3.22)
In other words, if you own $10 of an equity with a standard deviation of $2, then 
$100 of the same equity will have a standard deviation of $20.
Adding a constant to a random variable, however, does not alter the standard 
deviation or the variance:
	
σ
σ
[
]
[
]
X
c
X
+
=

(3.23)
This is because the impact of c on the mean is the same as the impact of c on any 
draw of the random variable, leaving the deviation from the mean for any draw 
unchanged. In theory, a risk-free asset should have zero variance and standard 
­deviation. If you own a portfolio with a standard deviation of $20, and then you 
add $1,000 of cash to that portfolio, the standard deviation of the portfolio should 
still be $20.
Standardized Variables
It is often convenient to work with variables where the mean is zero and the stand-
ard deviation is one. From the preceding section it is not difficult to prove that, given 
a random variable X with mean µ and standard deviation σ, we can define a second 
random variable Y:
	
Y
X
=
−µ
σ

(3.24)
such that Y will have a mean of zero and a standard deviation of one. We say that 
X has been standardized, or that Y is a standard random variable. In practice, if we 
have a data set and we want to standardize it, we first compute the sample mean and 
the standard deviation. Then, for each data point, we subtract the mean and divide 
by the standard deviation.
The inverse transformation can also be very useful when it comes to creating 
computer simulations. Simulations often begin with standardized variables, which 
need to be transformed into variables with a specific mean and standard deviation. 
In this case, we simply take the output from the standardized variable, multiply 
by the desired standard deviation, and then add the desired mean. The order is 
important. Adding a constant to a random variable will not change the standard 
deviation, but multiplying a non-mean-zero variable by a constant will change the 
mean.

42
Mathematics and Statistics for Financial Risk Management
Sample Problem
Question:
Assume that a random variable Y has a mean of zero and a standard devia-
tion of one. Given two constants, µ and σ, calculate the expected values of X1 
and X2, where X1 and X2 are defined as:
X1 = σY + µ
X2 = σ(Y + µ)
Answer:
The expected value of X1 is µ:
E[X1] = E[σY + µ] = σE[Y] + E[µ] = σ ∙ 0 + µ = µ
The expected value of X2 is σµ:
E[X2] = E[σ(Y + µ)] = E[σY + σµ] = σE[Y] + σµ = σ ∙ 0 + σµ = σµ
As warned in the previous section, multiplying a standard normal variable 
by a constant and then adding another constant produces a different result 
than if we first add and then multiply.
Covariance
Up until now we have mostly been looking at statistics that summarize one variable. 
In risk management, we often want to describe the relationship between two random 
variables. For example, is there a relationship between the returns of an equity and 
the returns of a market index?
Covariance is analogous to variance, but instead of looking at the deviation 
from the mean of one variable, we are going to look at the relationship between the 
deviations of two variables:
	
σ
µ
µ
XY
X
Y
E X
Y
=
−
−
[(
)(
)]
(3.25)
where σXY is the covariance between two random variables, X and Y, with means µX 
and µY, respectively. As you can see from the definition, variance is just a special case 
of covariance. Variance is the covariance of a variable with itself.
If X tends to be above µX when Y is above µY (both deviations are positive) 
and X tends to be below µX when Y is below µY (both deviations are negative), 
then the covariance will be positive (a positive number multiplied by a posi-
tive number is positive; likewise, for two negative numbers). If the opposite is 
true and the ­deviations tend to be of opposite sign, then the covariance will be 

Basic Statistics
43
­negative. If the deviations have no discernible relationship, then the covariance 
will be zero.
Earlier in this chapter, we cautioned that the expectation operator is not gener-
ally multiplicative. This fact turns out to be closely related to the concept of covari-
ance. Just as we rewrote our variance equation earlier, we can rewrite Equation 3.25 
as follows:
	
σ
µ
µ
µ µ
XY
X
Y
X
Y
E X
Y
E XY
E XY
E X E
=
−
−
=
−
=
−
[(
)(
)]
[
]
[
]
[
] [Y]
(3.26)
In the special case where the covariance between X and Y is zero, the expected 
value of XY is equal to the expected value of X multiplied by the expected value of Y:
	
σXY
E XY
E X E Y
=
⇒
=
0
[
]
[
] [ ] 
(3.27)
If the covariance is anything other than zero, then the two sides of this equation 
cannot be equal. Unless we know that the covariance between two variables is zero, 
we cannot assume that the expectation operator is multiplicative.
In order to calculate the covariance between two random variables, X and Y, 
assuming the means of both variables are known, we can use the following formula:
	
ˆ
(
)(
)
,
σ
µ
µ
X Y
i
X
i
Y
i
n
n
x
y
=
−
−
=∑
1
1

(3.28)
If the means are unknown and must also be estimated, we replace n with (n − 1):
	
ˆ
(
ˆ )(
ˆ )
,
σ
µ
µ
X Y
i
X
i
Y
i
n
n
x
y
=
−
−
−
=∑
1
1
1

(3.29)
If we replaced yi in these formulas with xi, calculating the covariance of X with 
itself, the resulting equations would be the same as the equations for calculating vari-
ance from the previous section.
Correlation
Closely related to the concept of covariance is correlation. To get the correlation 
of two variables, we simply divide their covariance by their respective standard 
­deviations:
	
ρ
σ
σ σ
XY
XY
X
Y
=

(3.30)
Correlation has the nice property that it varies between −1 and +1. If two vari-
ables have a correlation of +1, then we say they are perfectly correlated. If the ratio 
of one variable to another is always the same and positive, then the two variables 
will be perfectly correlated.
If two variables are highly correlated, it is often the case that one variable causes 
the other variable, or that both variables share a common underlying driver. We will 
see in later chapters, though, that it is very easy for two random variables with no 

44
Mathematics and Statistics for Financial Risk Management
causal link to be highly correlated. Correlation does not prove causation. Similarly, if 
two variables are uncorrelated, it does not necessarily follow that they are unrelated. 
For example, a random variable that is symmetrical around zero and the square of 
that variable will have zero correlation.
Sample Problem
Question:
X is a random variable. X has an equal probability of being −1, 0, or +1. 
What is the correlation between X and Y if Y = X2?
Answer:
We have:
P X
P X
P X
Y
X
[
1]
[
0]
[
1]
1
3
2
= −
=
=
=
=
=
=
First, we calculate the mean of both variables:
E X
E Y
[
]
1
3( 1)
1
3(0)
1
3(1)
0
[ ]
1
3( 1 )
1
3(0 )
1
3(1 )
1
3(1)
1
3(0)
1
3(1)
2
3
2
2
2
=
−
+
+
=
=
−
+
+
=
+
+
=
The covariance can be found as:
X Y
E X
E X
Y
E Y
X Y
Cov[
,
]
[(
[
])(
[ ])]
Cov[
,
]
1
3( 1
0) 1
2
3
1
3(0
0) 0
2
3
1
3(1
0) 1
2
3
0
=
−
−
=
−−
−
+
−
−
+
−
−
=
Because the covariance is zero, the correlation is also zero. There is no need 
to calculate the variances or standard deviations.
As forewarned, even though X and Y are clearly related, their correlation 
is zero.
Application: Portfolio Variance and Hedging
If we have a portfolio of securities and we wish to determine the variance of that 
portfolio, all we need to know is the variance of the underlying securities and their 
respective correlations.

Basic Statistics
45
For example, if we have two securities with random returns XA and XB, with 
means µA and µB and standard deviations σA and σB, respectively, we can calculate 
the variance of XA plus XB as follows:
	
σ
σ
σ
ρ
σ σ
A B
A
B
AB
A
B
+
=
+
+
2
2
2
2

(3.31)
where ρAB is the correlation between XA and XB. The proof is left as an exercise. No-
tice that the last term can either increase or decrease the total variance. Both stand-
ard deviations must be positive; therefore, if the correlation is positive, the overall 
variance will be higher than in the case where the correlation is negative.
If the variance of both securities is equal, then Equation 3.31 simplifies to:
	
σ
σ
ρ
σ
σ
σ
A B
AB
A
B
+
=
+
=
=
2
2
2
2
2
2
1(
)   where

(3.32)
We know that the correlation can vary between –1 and +1, so, substituting into 
our new equation, the portfolio variance must be bound by 0 and 4σ2. If we take the 
square root of both sides of the equation, we see that the standard deviation is bound 
by 0 and 2σ. Intuitively, this should make sense. If, on the one hand, we own one 
share of an equity with a standard deviation of $10 and then purchase another share 
of the same equity, then the standard deviation of our two-share portfolio must be 
$20 (trivially, the correlation of a random variable with itself must be one). On the 
other hand, if we own one share of this equity and then purchase another security 
that always generates the exact opposite return, the portfolio is perfectly balanced. 
The returns are always zero, which implies a standard deviation of zero.
In the special case where the correlation between the two securities is zero, we 
can further simplify our equation. For the standard deviation:
	
ρ
σ
σ
AB
A B
=
⇒
=
+
0
2

(3.33)
We can extend Equation 3.31 to any number of variables:
	
Y
X
i
n
i
Y
i
n
j
n
ij
i
j
=
=
=
=
=
∑
∑∑
1
2
1
1
σ
ρ σ σ

(3.34)
In the case where all of the Xi’s are uncorrelated and all the variances are equal 
to σ, Equation 3.32 simplifies to:
	
σ
σ
ρ
Y
ij
n
iff
i
j
=
=
∀
≠
0

(3.35)
This is the famous square root rule for the addition of uncorrelated variables. 
There are many situations in statistics in which we come across collections of ran-
dom variables that are independent and have the same statistical properties. We term 
these variables independent and identically distributed (i.i.d.). In risk ­management 

46
Mathematics and Statistics for Financial Risk Management
we might have a large portfolio of securities, which can be approximated as a 
­collection of i.i.d. variables. As we will see in subsequent chapters, this i.i.d. assump-
tion also plays an important role in estimating the uncertainty inherent in statistics 
derived from sampling, and in the analysis of time series. In each of these situations, 
we will come back to this square root rule.
By combining Equation 3.31 with Equation 3.22, we arrive at an equation for 
calculating the variance of a linear combination of variables. If Y is a linear combina-
tion of XA and XB, such that:
	
=
+
Y
aX
bX
A
B 
(3.36)
then, using our standard notation, we have:
	
σ
σ
σ
ρ
σ σ
Y
A
B
AB
A
B
a
b
ab
2
2
2
2
2
2
=
+
+

(3.37)
Correlation is central to the problem of hedging. Using the same notation as be-
fore, imagine we have $1 of Security A, and we wish to hedge it with $h of ­Security B 
(if h is positive, we are buying the security; if h is negative, we are shorting the secu-
rity). In other words, h is the hedge ratio. We introduce the random variable P for 
our hedged portfolio. We can easily compute the variance of the hedged portfolio 
using Equation 3.37:
	
P
X
hX
h
h
A
B
P
A
B
AB
A
B
=
+
=
+
+
σ
σ
σ
ρ
σ σ
2
2
2
2
2

(3.38)
As a risk manager, we might be interested to know what hedge ratio would 
achieve the portfolio with the least variance. To find this minimum variance hedge 
ratio, we simply take the derivative of our equation for the portfolio variance with 
respect to h, and set it equal to zero:
	
d
dh
h
h
P
B
AB
A
B
AB
A
B
σ
σ
ρ
σ σ
ρ
σ
σ
2
2
2
2
=
+
= −
*

(3.39)
You can check that this is indeed a minimum by calculating the second derivative. 
Substituting h∗ back into our original equation, we see that the smallest variance 
we can achieve is:
	
min[
]
(
)
σ
σ
ρ
P
A
AB
2
2
2
1
=
−

(3.40)
At the extremes, where ρAB equals −1 or +1, we can reduce the portfolio vola-
tility to zero by buying or selling the hedge asset in proportion to the standard 

Basic Statistics
47
­deviation of the assets. In between these two extremes we will always be left with 
some positive portfolio variance. This risk that we cannot hedge is referred to as 
­idiosyncratic risk.
If the two securities in the portfolio are positively correlated, then selling $h of 
Security B will reduce the portfolio’s variance to the minimum possible level. Sell any 
less and the portfolio will be underhedged. Sell any more and the portfolio will be 
over hedged. In risk management it is possible to have too much of a good thing. A 
common mistake made by portfolio managers is to over hedge with a low-correlation 
instrument.
Notice that when ρAB equals zero (i.e., when the two securities are uncorrelated), 
the optimal hedge ratio is zero. You cannot hedge one security with another security 
if they are uncorrelated. Adding an uncorrelated security to a portfolio will always 
increase its variance.
This last statement is not an argument against diversification. If your entire 
portfolio consists of $100 invested in Security A and you add any amount of an 
uncorrelated Security B to the portfolio, the dollar standard deviation of the port-
folio will increase. Alternatively, if Security A and Security B are uncorrelated and 
have the same standard deviation, then replacing some of Security A with Security 
B will decrease the dollar standard deviation of the portfolio. For example, $80 of 
Security A plus $20 of Security B will have a lower standard deviation than $100 of 
­Security A, but $100 of Security A plus $20 of Security B will have a higher standard 
­deviation—again, assuming Security A and Security B are uncorrelated and have the 
same standard deviation.
Moments
Previously, we defined the mean of a variable X as:
µ = E[X]
It turns out that we can generalize this concept as follows:
	
=
m
E X
[
]
k
k 
(3.41)
We refer to mk as the kth moment of X. The mean of X is also the first moment of X.
Similarly, we can generalize the concept of variance as follows:
	
µ
µ
k
k
E X
=
−
[(
) ]
(3.42)
We refer to µk as the kth central moment of X. We say that the moment is 
central because it is centered on the mean. Variance is simply the second central 
moment.
While we can easily calculate any central moment, in risk management it is very 
rare that we are interested in anything beyond the fourth central moment.

48
Mathematics and Statistics for Financial Risk Management
Skewness
The second central moment, variance, tells us how spread out a random variable is 
around the mean. The third central moment tells us how symmetrical the distribu-
tion is around the mean. Rather than working with the third central moment di-
rectly, by convention we first standardize the statistic. This standardized third central 
moment is known as skewness:
	
Skewness =
−
E X
[(
) ]
µ
σ
3
3

(3.43)
where σ is the standard deviation of X, and µ is the mean of X.
By standardizing the central moment, it is much easier to compare two random 
variables. Multiplying a random variable by a constant will not change the skewness.
A random variable that is symmetrical about its mean will have zero skewness. If 
the skewness of the random variable is positive, we say that the random variable exhib-
its positive skew. Exhibits 3.2 and 3.3 show examples of positive and negative skewness.
Skewness is a very important concept in risk management. If the distributions 
of returns of two investments are the same in all respects, with the same mean and 
standard deviation, but different skews, then the investment with more negative 
skew is generally considered to be more risky. Historical data suggest that many 
financial assets exhibit negative skew.
As with variance, the equation for skewness differs depending on whether we 
are calculating the population skewness or the sample skewness. For the population 
Positive Skew
No Skew
Exhibit 3.2 
Positive Skew

Basic Statistics
49
statistic, the skewness of a random variable X, based on n observations, x1, x2,  .  .  . , 
xn, can be calculated as:
	
ˆs
n
xi
i
n
=
−
=∑
1
1
3
μ
σ

(3.44)
where µ is the population mean and σ is the population standard deviation. Similar 
to our calculation of sample variance, if we are calculating the sample skewness 
there is going to be an overlap with the calculation of the sample mean and sample 
standard deviation. We need to correct for that. The sample skewness can be calcu-
lated as:
	
˜s
n
n
n
xi
i
n
=
−
−
−
=∑
(
)(
)
ˆ
ˆ
1
2
1
3
μ
σ

(3.45)
Based on Equation 3.20, for variance, it is tempting to guess that the formula for 
the third central moment can be written simply in terms of E[X3] and µ. Be careful, 
as the two sides of this equation are not equal:
	
E X
E X
k
[(
) ]
[
]
−
≠
−
µ
µ
3
3
(3.46)
The correct equation is:
	
E X
E X
[(
) ]
[
]
−
=
−
−
µ
µσ
µ
3
3
2
3
3

(3.47)
Negative Skew
No Skew
Exhibit 3.3 
Negative Skew

50
Mathematics and Statistics for Financial Risk Management
Sample Problem
Question:
Prove that the left-hand side of Equation 3.47 is indeed equal to the right-
hand side of the equation.
Answer:
We start by multiplying out the terms inside the expectation. This is not 
too difficult to do, but, as a shortcut, we could use the binomial theorem as 
mentioned in Chapter 1:
E X
E X
X
X
[(
) ]
[
]
−
=
−
+
−
µ
µ
µ
µ
3
3
2
2
3
3
3
Next, we separate the terms inside the expectation operator and move any 
­constants, namely µ, outside the operator:
E X
X
X
E X
E X
E X
[
]
[
]
[
]
[
]
3
2
2
3
3
2
2
3
3
3
3
3
−
+
−
=
−
+
−
µ
µ
µ
µ
µ
µ
E[X] is simply the mean, µ. For E[X2], we reorganize our equation for 
variance, Equation 3.20, as follows:
σ
µ
σ
µ
2
2
2
2
2
2
=
−
=
+
E X
E X
[
]
[
]
Substituting these results into our equation and collecting terms, we arrive 
at the final equation:
E X
E X
E X
[(
) ]
[
]
(
)
[(
) ]
−
=
−
+
+
−
−
=
µ
µ σ
µ
µ µ
µ
µ
3
3
2
2
2
3
3
3
3
E X
[
]
3
2
3
3
−
−
µσ
µ
For many symmetrical continuous distributions, the mean, median, and mode 
all have the same value. Many continuous distributions with negative skew have 
a mean that is less than the median, which is less than the mode. For example, it 
might be that a certain derivative is just as likely to produce positive returns as it 
is to produce negative returns (the median is zero), but there are more big negative 
returns than big positive returns (the distribution is skewed), so the mean is less than 
zero. As a risk manager, understanding the impact of skew on the mean relative to 
the median and mode can be useful. Be careful, though, as this rule of thumb does 
not always work. Many practitioners mistakenly believe that this rule of thumb is in 
fact always true. It is not, and it is very easy to produce a distribution that violates 
this rule.

Basic Statistics
51
Kurtosis
The fourth central moment is similar to the second central moment, in that it tells us 
how spread out a random variable is, but it puts more weight on extreme points. As 
with skewness, rather than working with the central moment directly, we typically 
work with a standardized statistic. This standardized fourth central moment is known 
as kurtosis. For a random variable X, we can define the kurtosis as K, where:
	
K
E X
=
−
[(
) ]
µ
σ
4
4

(3.48)
where σ is the standard deviation of X, and µ is its mean.
By standardizing the central moment, it is much easier to compare two random 
variables. As with skewness, multiplying a random variable by a constant will not 
change the kurtosis.
The following two populations have the same mean, variance, and skewness. 
The second population has a higher kurtosis.
Population 1: {–17, –17, 17, 17}
Population 2: {–23, –7, 7, 23}
Notice, to balance out the variance, when we moved the outer two points out six 
units, we had to move the inner two points in 10 units. Because the random variable 
with higher kurtosis has points further from the mean, we often refer to distribution 
with high kurtosis as fat-tailed. Exhibits 3.4 and 3.5 show examples of continuous 
distributions with high and low kurtosis.
High Kurtosis
No Excess
Exhibit 3.4 
High Kurtosis

52
Mathematics and Statistics for Financial Risk Management
Like skewness, kurtosis is an important concept in risk management. Many 
­financial assets exhibit high levels of kurtosis. If the distribution of returns of two 
assets have the same mean, variance, and skewness but different kurtosis, then the 
distribution with the higher kurtosis will tend to have more extreme points, and be 
considered more risky.
As with variance and skewness, the equation for kurtosis differs depending on 
whether we are calculating the population kurtosis or the sample kurtosis. For the 
population statistic, the kurtosis of a random variable X can be calculated as:
	
ˆK
n
xi
i
n
=
−
=∑
1
1
4
μ
σ

(3.49)
where µ is the population mean and σ is the population standard deviation. Similar 
to our calculation of sample variance, if we are calculating the sample kurtosis there 
is going to be an overlap with the calculation of the sample mean and sample stand-
ard deviation. We need to correct for that. The sample kurtosis can be calculated as:
	
˜K
n n
n
n
n
xi
i
n
=
+
−
−
−
−
=∑
(
)
(
)(
)(
)
ˆ
ˆ
1
1
2
3
1
4
μ
σ

(3.50)
In the next chapter we will study the normal distribution, which has a kurtosis 
of 3. Because normal distributions are so common, many people refer to “excess 
kurtosis,” which is simply the kurtosis minus 3.
	
Kexcess = K − 3
(3.51)
Low Kurtosis
No Excess
Exhibit 3.5 
Low Kurtosis

Basic Statistics
53
In this way, the normal distribution has an excess kurtosis of 0. Distributions 
with positive excess kurtosis are termed leptokurtotic. Distributions with negative 
excess kurtosis are termed platykurtotic. Be careful; by default, many applications 
calculate excess kurtosis, not kurtosis.
When we are also estimating the mean and variance, calculating the sample 
excess kurtosis is somewhat more complicated than just subtracting 3. If we have n 
points, then the correct formula is:
	
K
K
n
n
n
3
(
1)
(
2)(
3)
excess
2


=
−
−
−
−

(3.52)
where K is the sample kurtosis from Equation 3.50. As n increases, the last term on 
the right-hand side converges to 3.
Coskewness and Cokurtosis
Just as we generalized the concept of mean and variance to moments and central 
moments, we can generalize the concept of covariance to cross central moments. 
The third and fourth standardized cross central moments are referred to as coskew-
ness and cokurtosis, respectively. Though used less frequently, higher-order cross 
moments can be very important in risk management.
As an example of how higher-order cross moments can impact risk assess-
ment, take the series of returns shown in Exhibit 3.6 for four fund managers, A, B, 
C, and D.
In this admittedly contrived setup, each manager has produced exactly the 
same set of returns; only the order in which the returns were produced is different. 
It follows that the mean, standard deviation, skew, and kurtosis of the returns are 
exactly the same for each manager. In this example it is also the case that the covari-
ance between managers A and B is the same as the covariance between managers 
C and D.
If we combine A and B in an equally weighted portfolio and combine C and D 
in a separate equally weighted portfolio, we get the returns shown in Exhibit 3.7.
Exhibit 3.6 
Fund Returns
Time
A
B
C
D
1
0.0%
−3.8%
−15.3%
−15.3%
2
−3.8%
−15.3%
−7.2%
−7.2%
3
−15.3%
3.8%
0.0%
−3.8%
4
−7.2%
−7.2%
−3.8%
15.3%
5
3.8%
0.0%
3.8%
0.0%
6
7.2%
7.2%
7.2%
7.2%
7
15.3%
15.3%
15.3%
3.8%

54
Mathematics and Statistics for Financial Risk Management
Exhibit 3.7 
Combined Fund Returns
Time
A + B
C + D
1
−1.9%
−15.3%
2
−9.5%
−7.2%
3
−5.8%
−1.9%
4
−7.2%
5.8%
5
1.9%
1.9%
6
7.2%
7.2%
7
15.3%
9.5%
The two portfolios have the same mean and standard deviation, but the skews of 
the portfolios are different. Whereas the worst return for A + B is −9.5%, the worst 
return for C + D is −15.3%. As a risk manager, knowing that the worst outcome for 
portfolio C + D is more than 1.6 times as bad as the worst outcome for A + B could 
be very important.
So how did two portfolios whose constituents seemed so similar end up being 
so different? One way to understand what is happening is to graph the two sets of 
returns for each portfolio against each other, as shown in Exhibits 3.8 and 3.9.
The two charts share a certain symmetry, but are clearly different. In the first 
portfolio, A + B, the two managers’ best positive returns occur during the same time 
period, but their worst negative returns occur in different periods. This causes the 
distribution of points to be skewed toward the top-right of the chart. The situation 
–20%
–15%
–10%
–5%
0%
5%
10%
15%
20%
–20%
–15%
–10%
–5%
0%
5%
10%
15%
20%
A
B
Exhibit 3.8 
Funds A and B

Basic Statistics
55
is reversed for managers C and D: their worst negative returns occur in the same 
period, but their best positive returns occur in different periods. In the second chart, 
the points are skewed toward the bottom-left of the chart.
The reason the charts look different, and the reason the returns of the two port-
folios are different, is because the coskewness between the managers in each of the 
portfolios is different. For two random variables, there are actually two nontrivial 
coskewness statistics. For example, for managers A and B, we have:
	
S
E A
B
S
E A
B
AAB
A
B
A
B
ABB
A
=
−
−
=
−
−
[(
) (
)] /
[(
)(
µ
µ
σ σ
µ
2
2
µ
σ σ
B
A
B
) ] /
2
2 
(3.53)
The complete set of sample coskewness statistics for the sets of managers is 
shown in Exhibit 3.10.
Both coskewness values for A and B are positive, whereas they are both negative 
for C and D. Just as with skewness, negative values of coskewness tend to be associ-
ated with greater risk.
–20%
–15%
–10%
–5%
0%
5%
10%
15%
20%
–20%
–15%
–10%
–5%
0%
5%
10%
15%
20%
C
D
Exhibit 3.9 
Funds C and D
Exhibit 3.10 
Sample Coskewness
A + B
C + D
SXXY
0.99
−0.58
SXYY
0.58
−0.99

56
Mathematics and Statistics for Financial Risk Management
In general, for n random variables, the number of nontrivial cross central mo-
ments of order m is:
	
=
+
−
−
−
k
m
n
m n
n
(
1)!
!(
1)!

(3.54)
In this case, nontrivial means that we have excluded the cross moments that 
involve only one variable (i.e., our standard skewness and kurtosis). To include the 
nontrivial moments, we would simply add n to the preceding result.
For coskewness, Equation 3.54 simplifies to:
	
=
+
+
−
k
n
n
n
n
(
2)(
1)
6
3

(3.55)
Despite their obvious relevance to risk management, many standard risk 
­models do not explicitly define coskewness or cokurtosis. One reason that many 
models avoid these higher-order cross moments is practical. As the number of vari-
ables increases, the number of nontrivial cross moments increases rapidly. With 
10 variables there are 30 coskewness parameters and 65 cokurtosis parameters. 
With 100 variables, these numbers increase to 171,600 and over 4 million, respec-
tively. ­Exhibit 3.11 compares the number of nontrivial cross moments for a variety 
of sample sizes. In most cases there is simply not enough data to calculate all of 
these cross moments.
Risk models with time-varying volatility (e.g., GARCH; see Chapter 11) or 
time-varying correlation can display a wide range of behaviors with very few free 
parameters. Copulas (see Chapter 5) can also be used to describe complex interac-
tions between variables that go beyond covariances, and have become popular in 
risk management in recent years. All of these approaches capture the essence of 
coskewness and cokurtosis, but in a more tractable framework. As a risk manager, 
it is important to differentiate between these models—which address the higher-
order cross moments indirectly—and models that simply omit these risk factors 
altogether.
Exhibit 3.11 
Number of Nontrivial Cross Moments
n
Covariance
Coskewness
Cokurtosis
2
1
2
3
5
10
30
65
10
45
210
705
20
190
1,520
8,835
30
435
4,930
40,890
100
4,950
171,600
4,421,175

Basic Statistics
57
Best Linear Unbiased Estimator (BLUE)
In this chapter we have been careful to differentiate between the true parameters of 
a distribution and estimates of those parameters based on a sample of population 
data. In statistics we refer to these parameter estimates, or to the method of obtain-
ing the estimate, as an estimator. For example, at the start of the chapter, we intro-
duced an estimator for the sample mean:
	
ˆµ =
=∑
1
1
n
xi
i
n

(3.56)
This formula for computing the mean is so popular that we’re likely to take 
it for granted. Why this equation, though? One justification that we gave earlier 
is that this particular estimator provides an unbiased estimate of the true mean. 
That is:
	
E[ ˆ ]
µ
µ
=

(3.57)
Clearly, a good estimator should be unbiased. That said, for a given data set, 
we could imagine any number of unbiased estimators of the mean. For example, 
assuming there are three data points in our sample, x1, x2, and x3, the following 
equation:
	
µ =
+
+
0 75
0 25
0 00
1
2
3
.
.
.
x
x
x 
(3.58)
is also an unbiased estimator of the mean. Intuitively, this new estimator seems 
strange; we have put three times as much weight on x1 as on x2, and we have 
put no weight on x3. There is no reason, as we have described the problem, to 
believe that any one data point is better than any other, so distributing the weight 
equally might seem more logical. Still, the estimator in Equation 3.58 is unbi-
ased, and our criterion for judging this estimator to be strange seems rather sub-
jective. What we need is an objective measure for comparing different ­unbiased 
estimators.
As we will see in coming chapters, just as we can measure the variance of ran-
dom variables, we can measure the variance of parameter estimators as well. For 
example, if we measure the sample mean of a random variable several times, we 
can get a different answer each time. Imagine rolling a die 10 times and taking the 
average of all the rolls. Then repeat this process again and again. The sample mean 
is potentially different for each sample of 10 rolls. It turns out that this variability of 
the sample mean, or any other distribution parameter, is a function not only of the 
underlying variable, but of the form of the estimator as well.
When choosing among all the unbiased estimators, statisticians typically try to 
come up with the estimator with the minimum variance. In other words, we want 
to choose a formula that produces estimates for the parameter that are ­consistently 

58
Mathematics and Statistics for Financial Risk Management
close to the true value of the parameter. If we limit ourselves to estimators that can 
be written as a linear combination of the data, we can often prove that a particu-
lar candidate has the minimum variance among all the potential unbiased estima-
tors. We call an estimator with these properties the best linear unbiased estimator, 
or BLUE. All of the estimators that we produced in this chapter for the mean, 
variance, covariance, skewness, and kurtosis are either BLUE or the ratio of BLUE 
­estimators.
Problems
	 1.	Compute the mean and the median of the following series of returns:
12%
5%
–8%
20%
4%
10%
2%
	 2.	Compute the sample mean and the standard deviation of the following returns:
7%
2%
6%
−4%
−4%
3%
0%
18%
−1%
	 3.	Prove that Equation 3.2 is an unbiased estimator of the mean. That is, show that 
E[ ˆ ]
µ
µ
=
.
	 4.	What is the standard deviation of the estimator in Equation 3.2? Assume the 
various data points are i.i.d.
	 5.	Calculate the population covariance and correlation of the following series:
Series #1
21%
53%
83%
19%
Series #2
20%
32%
80%
40%
	 6.	Calculate the population mean, standard deviation, and skewness of each of the 
following two series:
Series #1
−51
−21
21
51
Series #2
−61
−7
33
35
	 7.	Calculate the population mean, standard deviation, and kurtosis for each of the 
following two series:
Series #1
−23
−7
7
23
Series #2
−17
−17
17
17
	 8.	Given the probability density function for a random variable X,
f x
x
x
( )
18 for 0
6
=
≤
≤
	
find the variance of X.

Basic Statistics
59
	 9.	Prove that Equation 3.19, reproduced here, is an unbiased estimator of variance.
ˆ
ˆ
σ
µ
2
1
1
1
x
i
x
i
n
n
x
=
−
−
(
)
=∑
E
x
x
[ ˆ ]
σ
σ
2
2
=
	10.	Given two random variables, XA and XB, with corresponding means µA and µB 
and standard deviations σA and σB, prove that the variance of XA plus XB is:
Var[
]
X
X
A
B
A
B
AB
A
B
+
=
+
+
σ
σ
ρ
σ σ
2
2
2
where ρAB is the correlation between XA and XB.
	11.	A $100 notional, zero coupon bond has one year to expiry. The probability of 
default is 10%. In the event of default, assume that the recovery rate is 40%. The 
continuously compounded discount rate is 5%. What is the present value of this 
bond?


61
I
n Chapter 2, we were introduced to random variables. In nature and in finance, 
random variables tend to follow certain patterns, or distributions. In this chapter 
we will learn about some of the most widely used probability distributions in risk 
management.
Parametric Distributions
Distributions can be divided into two broad categories: parametric distributions 
and nonparametric distributions. A parametric distribution can be described by a 
mathematical function. In the following sections we explore a number of paramet-
ric distributions, including the uniform distribution and the normal distribution. A 
nonparametric distribution cannot be summarized by a mathematical formula. In its 
simplest form, a nonparametric distribution is just a collection of data. An example 
of a nonparametric distribution would be a collection of historical returns for a 
security.
Parametric distributions are often easier to work with, but they force us to make 
assumptions, which may not be supported by real-world data. Nonparametric distri-
butions can fit the observed data perfectly. The drawback of nonparametric distribu-
tions is that they are potentially too specific, which can make it difficult to draw any 
general conclusions.
Uniform Distribution
For a continuous random variable, X, recall that the probability of an outcome 
­occurring between b1 and b2 can be found by integrating as follows:
P b
X
b
f x dx
[
]
( )
b
b
1
2
1
2
∫
≤
≤
=
where f(x) is the probability density function (PDF) of X.
Chapter 4
Distributions

62
Mathematics and Statistics for Financial Risk Management
The uniform distribution is one of the most fundamental distributions in 
­statistics. The probability density function is given by the following formula:
	
=
∀
≤
≤
∀
>
>
>
u b b
c
b
x
b
b
x
b
b
b
(
,
)
0
s.t.
1
2
1
2
1
2
2
1
(4.1)
In other words, the probability density is constant and equal to c between b1 and 
b2, and zero everywhere else. Exhibit 4.1 shows the plot of a uniform distribution’s 
probability density function.
Because the probability of any outcome occurring must be one, we can find the 
value of c as follows:
	
∫
∫
∫
∫
∫
∫
∫
=
=
+
+
=
=
=
−
=
=
−
−∞
+∞
−∞
+∞
−∞
+∞
u b b dx
u b b dx
dx
cdx
dx
cdx
cdx
cx
c b
b
c
b
b
(
,
)
1
(
,
)
0
0
[
]
(
)
1
1
b
b
b
b
b
b
b
b
b
b
1
2
1
2
2
1
2
1
1
1
2
2
1
2
1
2
1
2

(4.2)
c
b1
b2
Exhibit 4.1 
Probability Density Function of a Uniform Distribution

Distributions
63
On reflection, this result should be obvious from the graph of the density 
­function. That the probability of any outcome occurring must be one is equivalent to 
saying that the area under the probability density function must be equal to one. In 
Exhibit 4.1, we only need to know that the area of a rectangle is equal to the product 
of its width and its height to determine that c is equal to 1/(b2 − b1).
With the probability density function in hand, we can proceed to calculate the 
mean and the variance. For the mean:
	
µ =
=
+
∫
b
b
cxdx
b
b
1
2
1
2
2
1
(
) 
(4.3)
In other words, the mean is just the average of the start and end values of the 
­distribution.
Similarly, for the variance, we have:
	
σ
µ
2
2
2
1
2
1
2
1
12
=
−
=
−
∫
b
b
c x
dx
b
b
(
)
(
) 
(4.4)
This result is not as intuitive. The proof of both results is left as an exercise at the 
end of the chapter.
For the special case where b1 = 0 and b2 = 1, we refer to the distribution as a 
standard uniform distribution. Standard uniform distributions are extremely com-
mon. The default random number generator in most computer programs (technically 
a pseudo random number generator) is typically a standard uniform random vari-
able. Because these random number generators are so ubiquitous, uniform distribu-
tions often serve as the building blocks for computer models in finance.
To calculate the cumulative distribution function (CDF) of the uniform distribu-
tion, we simply integrate the PDF. Again, assuming a lower bound of b1 and an upper 
bound of b2, we have:
	
P X
a
cdz
c z
a
b
b
b
[
]
[ ]
b
a
b
a
1
2
1
1
1
∫
≤
=
=
=
−
−

(4.5)
As required, when a equals b1, we are at the minimum, and the CDF is zero. 
Similarly, when a equals b2, we are at the maximum, and the CDF equals one.
As we will see later, we can use combinations of uniform distributions to ap-
proximate other more complex distributions. As we will see in the next section, uni-
form distributions can also serve as the basis of other simple distributions, including 
the Bernoulli distribution.
Bernoulli Distribution
Bernoulli’s principle explains how the flow of fluids or gases leads to changes in 
­pressure. It can be used to explain a number of phenomena, including how the wings 
of airplanes provide lift. Without it, modern aviation would be impossible. ­Bernoulli’s 
principle is named after Daniel Bernoulli, an eighteenth-century ­Dutch-Swiss 

64
Mathematics and Statistics for Financial Risk Management
­mathematician and scientist. Daniel came from a family of accomplished mathema-
ticians. Daniel and his cousin Nicolas Bernoulli first described and presented a proof 
for the St. Petersburg paradox. But it is not Daniel or Nicolas, but rather their uncle, 
Jacob Bernoulli, for whom the Bernoulli distribution is named. In addition to the 
Bernoulli distribution, Jacob is credited with first describing the concept of continu-
ously compounded returns, and, along the way, discovering Euler’s number, e, both 
of which we explored in Chapter 1.
The Bernoulli distribution is incredibly simple. A Bernoulli random variable is 
equal to either zero or one. If we define p as the probability that X equals one, we have:
	
P[X = 1] = p  and  P[X = 0] = 1 − p
(4.6) 
We can easily calculate the mean and variance of a Bernoulli variable:
	
µ
σ
=
+
−
=
=
−
+
−
−
=
⋅
⋅
⋅
⋅
p
p
p
p
p
p
p
p
1
1
0
1
1
0
1
2
2
2
(
)
(
)
(
) (
)
( −p) 
(4.7) 
Binary outcomes are quite common in finance: a bond can default or not default; 
the return of a stock can be positive or negative; a central bank can decide to raise 
rates or not to raise rates.
In a computer simulation, one way to model a Bernoulli variable is to start 
with a standard uniform variable. Conveniently, both the standard uniform variable 
and our Bernoulli probability, p, range between zero and one. If the draw from the 
standard uniform variable is less than p, we set our Bernoulli variable equal to one; 
likewise, if the draw is greater than or equal to p, we set the Bernoulli variable to 
zero (see Exhibit 4.2).
Exhibit 4.2 
How to Generate a Bernoulli Distribution from a Uniform Distribution
Random Number Generator
Standard Uniform Random
Variable
U
Evaluate
U
U ≥ p
X = 1
X = 0
U < p

Distributions
65
Binomial Distribution
A binomial distribution can be thought of as a collection of Bernoulli random vari-
ables. If we have two independent bonds and the probability of default for both is 
10%, then there are three possible outcomes: no bond defaults, one bond defaults, 
or both bonds default. Labeling the number of defaults K:
P K
P K
[
]
(
%)
%
[
]
% (
%)
%
=
=
−
=
=
=
−
=
⋅
⋅
0
1 10
81
1
2 10
1
10
18
2
P K
[
]
%
%
=
=
=
2
10
1
2
Notice that for K = 1 we have multiplied the probability of a bond defaulting, 
10%, and the probability of a bond not defaulting, 1 − 10%, by 2. This is because 
there are two ways in which exactly one bond can default: The first bond defaults 
and the second does not, or the second bond defaults and the first does not.
If we now have three bonds, still independent and with a 10% chance of 
­defaulting, then:
P K
P K
[
]
(
%)
. %
[
]
% (
%)
=
=
−
=
=
=
−
=
⋅
⋅
0
1 10
72 9
1
3 10
1
10
3
2
24 3
2
3 10
1
10
2 7
3
10
2
3
. %
[
]
%
(
%)
. %
[
]
%
P K
P K
=
=
−
=
=
=
⋅
⋅
= 0 1
. %
Notice that there are three ways in which we can get exactly one default and 
three ways in which we can get exactly two defaults.
We can extend this logic to any number of bonds. If we have n bonds, the num-
ber of ways in which k of those bonds can default is given by the number of combi-
nations:
	
n
k
n
k n
k
=
−
!
!(
)!

(4.8) 
Similarly, if the probability of one bond defaulting is p, then the probability of 
any particular k bonds defaulting is simply p
p
(1
)
k
n k
−
−. Putting these two together, 
we can calculate the probability of any k bonds defaulting as:
	
P
n
k
p
p
n
k
k
(
[
)
K
k
=
=
−
−
]
1

(4.9) 
This is the probability density function for the binomial distribution. You should 
check that this equation produces the same result as our examples with two and 
three bonds. While the general proof is somewhat complicated, it is not difficult to 
prove that the probabilities sum to one for n = 2 or n = 3, no matter what value p 
takes. It is a common mistake when calculating these probabilities to leave out the 
combinatorial term.

66
Mathematics and Statistics for Financial Risk Management
For the formulation in Equation 4.9, the mean of random variable K is equal to 
np. So for a bond portfolio with 40 bonds, each with a 20% chance of defaulting, 
we would expect eight bonds (8 = 20 × 0.40) to default on average. The variance of 
a binomial distribution is np(1 − p).
Sample Problem
Question:
Assume we have four bonds, each with a 10% probability of defaulting 
over the next year. The event of default for any given bond is independent of 
the other bonds defaulting. What is the probability that zero, one, two, three, 
or all of the bonds default? What is the mean number of defaults? The standard 
deviation?
Answer:
We can calculate the probability of each possible outcome as follows:
# of Defaults
n
k
p
p
(1
)
k
n k
−
−
Probability
0
1
65.61%
65.61%
1
4
7.29%
29.16%
2
6
0.81%
4.86%
3
4
0.09%
0.36%
4
1
0.01%
0.01%
100.00%
We can calculate the mean number of defaults two ways. The first is to use 
our formula for the mean:
µ =
=
=
⋅
np
4 10
0 40
%
.
On average there are 0.40 defaults. The other way we could arrive at this 
result is to use the probabilities from the table. We get:
µ =
=
+
+
+
=∑
⋅
⋅
⋅
i
i
i
p x
0
4
65 61
0
29 16
1
4 86
2
0 36
.
%
.
%
.
%
.
%⋅
⋅
+
=
3
4
0 40
0 01
 
.
.
%
This is consistent with our earlier result.

Distributions
67
Exhibit 4.3 shows binomial distributions with p = 0.50, for n = 4, 16, and 64. 
The highest point of each distribution occurs in the middle. In other words, when 
p = 0.50, the most likely outcome for a binomial random variable, the mode, is n/2 
when n is even, or the whole numbers either side of n/2 when n is odd.
To calculate the standard deviation, we also have two choices. Using our 
formula for variance, we have:
σ
σ
2
1
4 10
1
10
0 36
0 60
=
−
=
−
=
=
⋅
np
p
(
)
%(
%)
.
.
As with the mean, we could also use the probabilities from the table:
σ
µ
σ
2
0
4
2
2
65 61
0 16
29 16
0 36
=
−
=
+
=∑
⋅
⋅
i
i
i
p x
(
)
.
%
.
.
%
.
++
+
+
=
=
⋅
⋅
⋅
4 86
2 56
0 36
6 76
0 01
12 96
0 36
0
.
%
.
.
%
.
.
%
.
.
σ
.60
Again, this is consistent with our earlier result.
n = 4
n = 16
n = 64
Exhibit 4.3 
Binomial Probability Density Functions

68
Mathematics and Statistics for Financial Risk Management
Poisson Distribution
Another useful discrete distribution is the Poisson distribution, named for the French 
mathematician Simeon Denis Poisson.
For a Poisson random variable X,
	
P X
n
n e
n
[
]
!
=
=
−
λ
λ 
(4.10)
for some constant λ, it turns out that both the mean and variance of X are equal to 
λ. Exhibit 4.4 shows the probability density functions for three Poisson distributions.
The Poisson distribution is often used to model the occurrence of events over 
time—for example, the number of bond defaults in a portfolio or the number of 
crashes in equity markets. In this case, n is the number of events that occur in an 
interval, and λ is the expected number of events in the interval. Poisson distributions 
are often used to model jumps in jump-diffusion models.
If the rate at which events occur over time is constant, and the probability of any 
one event occurring is independent of all other events, then we say that the events 
follow a Poisson process, where:
	
P X
n
t
n
e
n
t
[
]
(
)
!
=
=
−
λ
λ 
(4.11)
where t is the amount of time elapsed. In other words, the expected number of events 
before time t is equal to λt.
Exhibit 4.4 
Poisson Probability Density Functions
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0
2
4
6
8
10
12
14
16
18
20
Lambda = 2
Lambda = 4
Lambda = 8

Distributions
69
Normal Distribution
The normal distribution is probably the most widely used distribution in statistics, 
and is extremely popular in finance. The normal distribution occurs in a large num-
ber of settings, and is extremely easy to work with.
In popular literature, the normal distribution is often referred to as the bell curve 
because of the shape of its probability density function (see Exhibit 4.5).
Sample Problem
Question:
Assume that defaults in a large bond portfolio follow a Poisson process. 
The expected number of defaults each month is four. What is the probability 
that there are exactly three defaults over the course of one month? Over two 
months?
Answer:
For the first question, we solve the following:
P X
t
n
e
e
n
t
[
]
(
)
!
(
)
!
. %
=
=
=
=
−
−
⋅
⋅
3
4 1
3
19 5
3
4 1
λ
λ
Over two months, the answer is:
P X
t
n
e
e
n
t
[
]
(
)
!
(
)
!
. %
=
=
=
=
−
−
⋅
⋅
3
4 2
3
2 9
3
4 2
λ
λ
Exhibit 4.5 
Normal Distribution Probability Density Function

70
Mathematics and Statistics for Financial Risk Management
The probability density function of the normal distribution is symmetrical, with 
the mean and median coinciding with the highest point of the PDF. Because it is sym-
metrical, the skew of a normal distribution is always zero. The kurtosis of a normal 
distribution is always 3. By definition, the excess kurtosis of a normal distribution 
is zero.
In some fields it is more common to refer to the normal distribution as the 
Gaussian distribution, after the famous German mathematician Johann Gauss, who 
is credited with some of the earliest work with the distribution. It is not the case that 
one name is more precise than the other as is the case with mean and average. Both 
normal distribution and Gaussian distribution are acceptable terms.
For a random variable X, the probability density function for the normal distri-
bution is:
	
f x
e
x
( ) =
−
−
1
2
1
2
2
σ
π
μ
σ

(4.12)
The distribution is described by two parameters, µ and σ; µ is the mean of the 
distribution and σ is the standard deviation. We leave the proofs of these statements 
for the exercises at the end of the chapter.
Rather than writing out the entire density function, when a variable is normally 
distributed it is the convention to write:
	
X
N
∼
( ,
)
µ σ 2 
(4.13)
This would be read “X is normally distributed with a mean of µ and variance 
of σ2.”
One reason that normal distributions are easy to work with is that any linear 
combination of independent normal variables is also normal. If we have two nor-
mally distributed variables, X and Y, and two constants, a and b, then Z is also 
normally distributed:
	
Z
aX
bY
Z
N a
b
a
b
X
Y
X
Y
=
+
∼
+
+
s.t.
(
,
)
µ
µ
σ
σ
2
2
2
2 
(4.14)
This is very convenient. For example, if the log returns of individual stocks are 
independent and normally distributed, then the average return of those stocks will 
also be normally distributed.
When a normal distribution has a mean of zero and a standard deviation of one, 
it is referred to as a standard normal distribution.
	
φ
π
=
−
1
2
1
2
2
e
x 
(4.15)
It is the convention to denote the standard normal PDF by φ, and the cumulative 
standard normal distribution by Φ.
Because a linear combination of independent normal distributions is also nor-
mal, standard normal distributions are the building blocks of many financial models. 
To get a normal variable with a standard deviation of σ and a mean of µ, we simply 
multiply the standard normal variable by σ and add µ.
	
X
X
N
=
+
⇒
∼
µ
σφ
µ σ
( ,
)
2 
(4.16)

Distributions
71
To create two correlated normal variables, we can combine three independent 
standard normal variables, X1, X2, and X3, as follows:
	
X
X
X
X
X
X
A
B
=
+
−
=
+
−
ρ
ρ
ρ
ρ
1
2
1
3
1
1

(4.17)
In this formulation, XA and XB are also standard normal variables, but with a 
correlation of ρ. The proof is left for an exercise at the end of the chapter.
Normal distributions are used throughout finance and risk management. In the 
first chapter, we suggested that log returns are extremely useful in financial mod-
eling. One attribute that makes log returns particularly attractive is that they can 
be modeled using normal distributions. Normal distributions can generate numbers 
from negative infinity to positive infinity. For a particular normal distribution, the 
most extreme values might be extremely unlikely, but they can occur. This poses a 
problem for standard returns, which typically cannot be less than −100%. For log 
returns, though, there is no such constraint. Log returns also can range from negative 
to positive infinity.
Normally distributed log returns are widely used in financial simulations, and 
form the basis of a number of financial models, including the Black-Scholes option 
pricing model. As we will see in the coming chapters, while this normal assumption 
is often a convenient starting point, much of risk management is focused on address-
ing departures from this normality assumption.
There is no explicit solution for the cumulative standard normal distribution, 
or for its inverse. That said, most statistical packages will be able to calculate values 
for both functions. To calculate values for the CDF or inverse CDF for the normal 
distribution, there are a number of well-known numerical approximations.
Because the normal distribution is so widely used, most practitioners are ex-
pected to have at least a rough idea of how much of the distribution falls within 
one, two, or three standard deviations. In risk management it is also useful to know 
how many standard deviations are needed to encompass 95% or 99% of outcomes. 
Exhibit 4.6 lists some common values. Notice that for each row in the table, there is 
a “one-tailed” and “two-tailed” column. If we want to know how far we have to go 
to encompass 95% of the mass in the density function, the one-tailed value tells us 
Exhibit 4.6 
Normal Distribution Confidence Intervals
One-Tailed
Two-Tailed
1.0%
−2.33
−2.58
2.5%
−1.96
−2.24
5.0%
−1.64
−1.96
10.0%
−1.28
−1.64
90.0%
1.28
1.64
95.0%
1.64
1.96
97.5%
1.96
2.24
99.0%
2.33
2.58

72
Mathematics and Statistics for Financial Risk Management
that 95% of the values are less than 1.64 standard deviations above the mean. Be-
cause the normal distribution is symmetrical, it follows that 5% of the values are less 
than 1.64 standard deviations below the mean. The two-tailed value, in turn, tells us 
that 95% of the mass is within +/−1.96 standard deviations of the mean. It follows 
that 2.5% of the outcomes are less than −1.96 standard deviations from the mean, 
and 2.5% are greater than +1.96 standard deviations from the mean. Rather than 
one-tailed and two-tailed, some authors refer to “one-sided” and “two-sided” values.
Lognormal Distribution
It’s natural to ask: if we assume that log returns are normally distributed, then how 
are standard returns distributed? To put it another way: rather than modeling log re-
turns with a normal distribution, can we use another distribution and model stand-
ard returns directly?
The answer to these questions lies in the lognormal distribution, whose density 
function is given by:
	
f x
x
e
x
( )
ln
=
−
−
1
2
1
2
2
σ
π
μ
σ

(4.18) 
If a variable has a lognormal distribution, then the log of that variable has a 
normal distribution. So, if log returns are assumed to be normally distributed, then 
one plus the standard return will be lognormally distributed.
Unlike the normal distribution, which ranges from negative infinity to positive 
infinity, the lognormal distribution is undefined, or zero, for negative values. Given 
an asset with a standard return, R, if we model (1 + R) using the lognormal distribu-
tion, then R will have a minimum value of −100%. As mentioned in Chapter 1, this 
feature, which we associate with limited liability, is common to most financial assets. 
Using the lognormal distribution provides an easy way to ensure that we avoid re-
turns less than −100%. The probability density function for a lognormal distribution 
is shown in Exhibit 4.7.
Equation 4.18 looks almost exactly like the equation for the normal distribu-
tion, Equation 4.12, with x replaced by ln(x). Be careful, though, as there is also the 
x in the denominator of the leading fraction. At first it might not be clear what the 
x is doing there. By carefully rearranging Equation 4.18, we can get something that, 
while slightly longer, looks more like the normal distribution in form:
	
f x
e
e
x
( )
ln
(
)
=
−
−
−
−
1
2
1
2
2
2
2
1
2
σ
μ
σ
μ
σ
σ
π

(4.19) 
While not as pretty, this starts to hint at what we’ve actually done. Rather than 
being symmetrical around µ, as in the normal distribution, the lognormal distribu-
tion is asymmetrical and peaks at exp(µ − σ2).
Given µ and σ, the mean is given by:
	
E X
e
[
] =
+
µ
σ
1
2
2

(4.20)

Distributions
73
This result looks very similar to the Taylor expansion of the natural logarithm 
around one. Remember from Chapter 1, if R is a standard return and r the corre-
sponding log return, then:
	
r
R
R
1
2
2
≈
−

(4.21)
Be careful: Because these equations are somewhat similar, it is very easy to get 
the signs in front of σ2 and R2 backward.
The variance of the lognormal distribution is given by:
	
E X
E X
e
e
[(
[
]) ]
(
)
−
=
−
+
2
2
2
2
1
σ
µ σ 
(4.22)
The equations for the mean and the variance hint at the difficulty of working 
with lognormal distributions directly. It is convenient to be able to describe the re-
turns of a financial instrument as being lognormally distributed, rather than having 
to say the log returns of that instrument are normally distributed. When it comes to 
modeling, though, even though they are equivalent, it is often easier to work with 
log returns and normal distributions than with standard returns and lognormal dis-
tributions.
Central Limit Theorem
Assume we have an index made up of a large number of equities, or a bond port-
folio that contains a large number of similar bonds. In these situations and many 
more, it is often convenient to assume that the constituent elements—the equities 
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Exhibit 4.7 
Lognormal Probability Density Function

74
Mathematics and Statistics for Financial Risk Management
or bonds—are made up of statistically identical random variables, and that these 
variables are uncorrelated with each other. As mentioned previously, in statistics we 
term these variables independent and identically distributed (i.i.d.). If the constituent 
elements are i.i.d., it turns out we can say a lot about the distribution of the popula-
tion, even if the distribution of the individual elements is unknown.
We already know that if we add two i.i.d. normal distributions together we 
get a normal distribution, but what happens if we add two i.i.d. uniform variables 
together? Looking at the graph of the uniform distribution (Exhibit 4.1), you might 
think that we would get another uniform distribution, but this isn’t the case. In fact, 
the probability density function resembles a triangle.
Assume we have two defaulted bonds, each with a face value of $100. The re-
covery rate for each bond is assumed to be uniform, between $0 and $100. At best 
we recover the full face value of the bond; at worst we get nothing. Further, assume 
the recovery rate for each bond is independent of the other. In other words, the 
bonds are i.i.d. uniform, between $0 and $100. What is the distribution for the port-
folio of the two bonds? In the worst-case scenario, we recover $0 from both bonds, 
and the total recovery is $0. In the best-case scenario, we recover the full amount 
for both bonds, $200 for the portfolio. Because the bonds are independent, these 
extremes are actually very unlikely. The most likely scenario is right in the middle, 
where we recover $100. This could happen if we recover $40 from the first bond 
and $60 from the second, $90 from the first and $10 from the second, or any of an 
infinite number of combinations. Exhibit 4.8 shows the distribution of values for the 
portfolio of two i.i.d. bonds.
With three bonds, the distribution ranges from $0 to $300, with the mode at 
$150. With four bonds, the distribution ranges from $0 to $400, with the mode at 
Exhibit 4.8 
Sum of Two i.i.d. Uniform Distributions
0.000
0.002
0.004
0.006
0.008
0.010
0
50
100
150
200

Distributions
75
$200. As we continue to add more bonds, the shape of the distribution function 
­continues to change. Exhibit 4.9 shows the density functions for the sums of 4, 8, 
and 16 i.i.d. uniform variables, scaled to have the same range.
Oddly enough, even though we started with uniform variables, the distribution 
is starting to look increasingly like a normal distribution. The resemblance is not 
just superficial; it turns out that as we add more and more variables, the distribution 
actually converges to a normal distribution. What’s more, this is not just true if we 
start out with uniform distributions; it applies to any distributions with finite vari-
ance.1 This result is known as the central limit theorem.
More formally, if we have n i.i.d. random variables, X1, X2,  .  .  ., Xn, each with mean 
µ and standard deviation σ, and we define Sn as the sum of those n variables, then:
	
lim
n
n
S
N n
n
→∞
∼
(
,
)
µ
σ 2 
(4.23)
In other words, as n approaches infinity, the sum converges to a normal distribu-
tion. This result is one of the most important results in statistics and is the reason 
why the normal distribution is so ubiquitous. In risk, as in a number of other fields, 
we are often presented with data that either is i.i.d. by construction or is assumed 
to be i.i.d. Even when the underlying variables are not normal—which is rare in 
practice—the i.i.d. assumption, combined with the central limit theorem, allows us 
1 Even though we have not yet encountered any distributions with infinite variance, they can 
exist. The Cauchy distribution is an example of a parametric distribution with infinite vari-
ance. While rare in finance, it’s good to know that these distributions can exist.
Exhibit 4.9 
Sums of Various i.i.d. Uniform Distributions
4
8
16

76
Mathematics and Statistics for Financial Risk Management
to approximate a large collection of data using a normal distribution. The central 
limit theorem is often used to justify the approximation of financial variables by a 
normal distribution.
Application: Monte Carlo Simulations Part I: Creating 
Normal Random Variables
While some problems in risk management have explicit analytic solutions, many 
problems have no exact mathematical solution. In these cases, we can often approxi-
mate a solution by creating a Monte Carlo simulation. A Monte Carlo simulation 
consists of a number of trials. For each trial we feed random inputs into a system of 
equations. By collecting the outputs from the system of equations for a large number 
of trials, we can estimate the statistical properties of the output variables.
Even in cases where explicit solutions might exist, a Monte Carlo solution might 
be preferable in practice if the explicit solution is difficult to derive or extremely 
complex. In some cases a simple Monte Carlo simulation can be easier to under-
stand, thereby reducing operational risk.
As an example of a situation where we might use a Monte Carlo simulation, pre-
tend we are asked to evaluate the mean and standard deviation of the profits from 
a fixed-strike arithmetic Asian option, where the value of the option, V, at expiry is:
	
V
T
S
X
max 1
,0
t
t
T
1∑
=
−
=

(4.24) 
Here X is the strike price, St is the closing price of the underlying asset at time 
t, and T is the number of periods in the life of the option. In other words, the value 
of the option at expiry is the greater of zero or the average price of the underlying 
asset less the strike price.
Assume there are 200 days until expiry. Further, we are told that the returns of 
the underlying asset are lognormal, with a mean of 10% and a standard deviation of 
20%. The input to our Monte Carlo simulation would be lognormal variables with 
the appropriate mean and standard deviation. For each trial, we would generate 200 
random daily returns, use the returns to calculate a series of random prices, calculate 
the average of the price series, and use the average to calculate the value of the op-
tion. We would repeat this process again and again, using a different ­realization of 
the random returns each time, and each time calculating a new value for the option.
The initial step in the Monte Carlo simulation, generating the random inputs, 
can itself be very complex. In Chapter 8, we will learn how to create correlated nor-
mally distributed random variables from a set of uncorrelated normally distributed 
random variables. How do we create the uncorrelated normally distributed random 
variables to start with? Many special-purpose statistical packages contain functions 
that will generate random draws from normal distributions. If the application we 
are using does not have this feature, but does have a standard random number gen-
erator, which generates a standard uniform distribution, there are two ways we can 
­generate random normal variables. The first is to use an inverse normal transforma-
tion. As mentioned previously, there is no explicit formula for the inverse normal 
transformation, but there are a number of good approximations.

Distributions
77
The second approach takes advantage of the central limit theorem. By adding 
together a large number of i.i.d. uniform distributions and then multiplying and 
adding the correct constants, a good approximation to any normal variable can be 
formed. A classic approach is to simply add 12 standard uniform variables together, 
and subtract 6:
	
X
U
i
i
=
−
=∑
1
12
6 
(4.25)
Because the mean of a standard uniform variable is ½ and the variance is 1∕12, 
this produces a good approximation to a standard normal variable, with mean zero 
and standard deviation of one. By utilizing a greater number of uniform variables, 
we could increase the accuracy of our approximation, but for most applications, this 
approximation is more than adequate.
Chi-Squared Distribution
If we have k independent standard normal variables, Z1, Z2, .  .  ., Zk, then the sum of 
their squares, S, has a chi-squared distribution. We write:
	
S
Z
S
i
k
i
k
=
∼
=∑
1
2
2
χ

(4.26)
The variable k is commonly referred to as the degrees of freedom. It follows 
that the sum of two independent chi-squared variables, with k1 and k2 degrees of 
freedom, will follow a chi-squared distribution, with (k1 + k2) degrees of freedom.
Because the chi-squared variable is the sum of squared values, it can take on 
only nonnegative values and is asymmetrical. The mean of the distribution is k, and 
the variance is 2k. As k increases, the chi-squared distribution becomes increasingly 
symmetrical. As k approaches infinity, the chi-squared distribution converges to the 
normal distribution. Exhibit 4.10 shows the probability density functions for some 
chi-squared distributions with different values for k.
For positive values of x, the probability density function for the chi-squared 
distribution is:
	
f x
k
x
e
( )
1
2
( / 2)
k
k
x
/2
2 1
2
=
Γ
−
−

(4.27)
where Γ is the gamma function:
	
Γ( )
n
x
e
dx
n
x
=
∞
−
−
∫
0
1

(4.28)
The chi-squared distribution is widely used in risk management, and in statistics 
in general, for hypothesis testing.

78
Mathematics and Statistics for Financial Risk Management
Student’s t Distribution
Another extremely popular distribution in statistics and in risk management is Stu-
dent’s t distribution. The distribution was first described in English, in 1908, by 
William Sealy Gosset, an employee at the Guinness brewery in Dublin. In order 
to comply with his firm’s policy on publishing in public journals, he submitted his 
work under the pseudonym Student. The distribution has been known as Student’s t 
distribution ever since. In practice, it is often referred to simply as the t distribution.
If Z is a standard normal variable and U is a chi-square variable with k degrees 
of freedom, which is independent of Z, then the random variable X,
	
X
Z
U k
=
/

(4.29)
follows a t distribution with k degrees of freedom.
Mathematically, the distribution is quite complicated. The probability density 
function can be written:
	
f x
k
k
k
x
k
k
( )
(
=
+
+
−
+
Γ
Γ
1
2
2
1
2
1
π
)
2

(4.30) 
where k is the degrees of freedom and Γ is the gamma function.
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0
2
4
6
8
10
12
k = 1
k = 2
k = 4
Exhibit 4.10 
Chi-Squared Probability Density Functions

Distributions
79
Very few risk managers will memorize this PDF equation, but it is important to 
understand the basic shape of the distribution and how it changes with k. Exhibit 4.11 
shows the probability density function for three Student’s t distributions. Notice how 
changing the value of k changes the shape of the distribution, specifically the tails.
The t distribution is symmetrical around its mean, which is equal to zero. For 
low values of k, the t distribution looks very similar to a standard normal distribu-
tion, except that it displays excess kurtosis. As k increases, this excess kurtosis de-
creases. In fact, as k approaches infinity, the t distribution converges to a standard 
normal distribution.
The variance of the t distribution for k > 2 is k/(k − 2). You can see that as k 
increases, the variance of the t distribution converges to one, the variance of the 
standard normal distribution.
As we will see in the following chapter, the t distribution’s popularity derives 
mainly from its use in hypothesis testing. The t distribution is also a popular choice 
for modeling the returns of financial assets, since it displays excess kurtosis.
F-Distribution
If U1 and U2 are two independent chi-squared distributions with k1 and k2 degrees 
of freedom, respectively, then X,
	
X
U
k
U
k
F k k
/
/
(
,
)
1
1
2
2
1
2
=
∼

(4.31)
follows an F-distribution with parameters k1 and k2.
0.0
0.1
0.2
0.3
0.4
–3
–2
–1
0
1
2
3
k = 1
k = 5
k = 10
Exhibit 4.11 
Student’s t Probability Density Functions

80
Mathematics and Statistics for Financial Risk Management
The probability density function of the F-distribution, as with the chi-squared 
distribution, is rather complicated:
	
f x
k x
k
k x
k
xB k
k
( )
(
)
(
)
2 , 2
k
k
k
k
1
2
1
2
1
2
1
2
1
2
=
+
+

(4.32) 
where B(x, y) is the beta function:
	
∫
=
−
−
−
B x y
z
z
dz
( , )
(1
)
x
y
0
1
1
1

(4.33)
As with the chi-squared and Student’s t distributions, memorizing the ­probability 
density function is probably not something most risk managers would be expected 
to do; rather, it is important to understand the general shape and some properties of 
the distribution.
Exhibit 4.12 shows the probability density functions for several F-distributions. 
Because the chi-squared PDF is zero for negative values, the F-distribution’s density 
function is also zero for negative values. The mean and variance of the F-distribution 
are as follows:
	
µ
σ
=
−
>
=
+
−
−
k
k
k
k k
k
k k
k
2
2
2
2
2
2
1
2
1
2
2
2
2
2
2
2
2
for
(
)
(
) (
−
>
4
4
2
) for k

(4.34) 
0.0
0.5
1.0
1.5
0.0
k1 = 2, k2 = 2
k1 = 4, k2 = 2
k1 = 64, k2 = 64
0.5
1.0
1.5
2.0
2.5
3.0
Exhibit 4.12 
F-Distribution Probability Density Functions

Distributions
81
As k1 and k2 increase, the mean and mode converge to one. As k1 and k2 ­approach 
infinity, the F-distribution converges to a normal distribution.
There is also a nice relationship between Student’s t distribution and the 
F-­distribution. From the description of the t distribution, Equation 4.29, it is easy 
to see that the square of a variable with a t distribution has an F-distribution. More 
specifically, if X is a random variable with a t distribution with k degrees of freedom, 
then X2 has an F-distribution with 1 and k degrees of freedom:
	
X
F
k
(1, )
2 ∼

(4.35)
Triangular Distribution
It is often useful in risk management to have a distribution with a fixed minimum 
and maximum—for example, when modeling default rates and recovery rates, which 
by definition cannot be less than zero or greater than one. The uniform distribution 
is an example of a continuous distribution with a finite range. While the uniform 
distribution is extremely simple to work with (it is completely described by two 
parameters), it is rather limited in that the probability of an event is constant over 
its entire range.
The triangular distribution is a distribution whose PDF is a triangle. As with the 
uniform distribution, it has a finite range. Mathematically, the triangular distribution 
is only slightly more complex than a uniform distribution, but much more flexible. 
The triangular distribution has a unique mode, and can be symmetric, positively 
skewed, or negatively skewed.
The PDF for a triangular distribution with a minimum of a, a maximum of b, 
and a mode of c is described by the following two-part function:
	
f x
x
a
b
a c
a
a
x
c
b
x
b
a b
c
c
x
b
( )
2(
)
(
)(
)
2(
)
(
)(
)
=
−
−
−
≤
≤
−
−
−
<
≤

(4.36)
Exhibit 4.13 shows a triangular distribution where a, b, and c are 0.0, 1.0, and 
0.8, respectively.
It is easily verified that the PDF is zero at both a and b, and that the value of f(x) 
reaches a maximum, 2/(b − a), at c. Because the area of a triangle is simply one half 
the base multiplied by the height, it is also easy to confirm that the area under the 
PDF is equal to one. 
The mean, µ, and variance, σ2, of a triangular distribution are given by:
	
µ
σ
=
+
+
=
+
+
−
−
−
a
b
c
a
b
c
ab
ac
bc
3
18
2
2
2
2

(4.37)

82
Mathematics and Statistics for Financial Risk Management
Beta Distribution
The beta distribution is another distribution with a finite range. It is more ­complicated 
than the triangular distribution mathematically, but it is also much more flexible.
As with the triangular distribution, the beta distribution can be used to model 
default rates and recovery rates. As we will see in Chapter 6, the beta distribution is 
also extremely useful in Bayesian analysis.
The beta distribution is defined on the interval from zero to one. The PDF is 
defined as follows, where a and b are two positive constants:
	
f x
B a b x
x
x
( )
1
( , )
(1
)
0
1
a
b
1
1
=
−
≤
≤
−
−

(4.38)
where B(a,b) is the beta function as described earlier for the F-distribution. The 
uniform distribution is a special case of the beta distribution, where both a and b 
are equal to one. Exhibit 4.14 shows four different parameterizations of the beta 
distribution. 
The mean, µ, and variance, σ2, of a beta distribution are given by:
	
µ
σ
=
+
=
+
+
+
a
a
b
ab
a
b
a
b
2
2
1
(
) (
)

(4.39)
Exhibit 4.13 
Triangular Distribution Probability Density Function
0
1
2
0.0
0.2
0.4
0.6
0.8
1.0

Distributions
83
Mixture Distributions
Imagine a stock whose log returns follow a normal distribution with low volatility 
90% of the time, and a normal distribution with high volatility 10% of the time. 
Most of the time the world is relatively dull, and the stock just bounces along. Oc-
casionally, though—maybe there is an earnings announcement or some other news 
event—the stock’s behavior is more extreme. We could write the combined density 
function as:
	
=
+
f x
w f
x
w
f
x
( )
( )
( )
L
L
H
H

(4.40)
where wL = 0.90 is the probability of the return coming from the low-volatility 
distribution, fL(x), and wH = 0.10 is the probability of the return coming from the 
high-volatility distribution fH(x). We can think of this as a two-step process. First, 
we randomly choose the high or low distribution, with a 90% chance of picking 
the low distribution. Second, we generate a random return from the chosen nor-
mal distribution. The final distribution, f(x), is a legitimate probability distribu-
tion in its own right, and although it is equally valid to describe a random draw 
directly from this distribution, it is often helpful to think in terms of this two-step 
process.
Note that the two-step process is not the same as the process described in a 
previous section for adding two random variables together. An example of adding 
two random variables together is a portfolio of two stocks. At each point in time, 
Exhibit 4.14 
Beta Distribution Probability Density Functions
0
1
2
3
0
.
1
5
.
0
0
.
0
0.5,0.5
5,5
2,6
4,1

84
Mathematics and Statistics for Financial Risk Management
each stock generates a random return, and the portfolio return is the sum of both 
returns. In the case we are describing now, the return appears to come from either 
the ­low-volatility distribution or the high-volatility distribution.
The distribution that results from a weighted average distribution of ­density 
functions is known as a mixture distribution. More generally, we can create a 
­distribution:
	
∑
∑
=
=
=
=
f x
w f x
w
( )
( ) s.t.
1
i
i
i
i
n
i
n
1
1

(4.41)
where the various fi(x)’s are known as the component distributions, and the wi’s are 
known as the mixing proportions or weights. Notice that in order for the result-
ing mixture distribution to be a legitimate distribution, the sum of the component 
weights must equal one.
Mixture distributions are extremely flexible. In a sense they occupy a realm 
between parametric distributions and nonparametric distributions. In a typical 
mixture distribution, the component distributions are parametric, but the weights 
are based on empirical data, which is nonparametric. Just as there is a trade-off 
between parametric distributions and nonparametric distributions, there is a trade-
off between using a low number and a high number of component distributions. 
By adding more and more component distributions, we can approximate any data 
set with increasing precision. At the same time, as we add more and more compo-
nent distributions, the conclusions that we can draw tend to become less general 
in nature.
Just by adding two normal distributions together, we can develop a large num-
ber of interesting distributions. Similar to the previous example, if we combine two 
normal distributions with the same mean but different variances, we can get a sym-
metrical mixture distribution that displays excess kurtosis. By shifting the mean of 
one distribution, we can also create a distribution with positive or negative skew. 
Exhibit 4.15 shows an example of a skewed mixture distribution created from two 
normal distributions.
Finally, if we move the means far enough apart, the resulting mixture distribu-
tion will be bimodal; that is, the PDF will have two distinct maxima, as shown in 
Exhibit 4.16.
Mixture distributions can be extremely useful in risk management. Securities 
whose return distributions are skewed or have excess kurtosis are often consid-
ered riskier than those with normal distributions, since extreme events can occur 
more frequently. Mixture distributions provide a ready method for modeling these 
attributes.
A bimodal distribution can be extremely risky. If one component of a security’s 
returns has an extremely low mixing weight, we might be tempted to ignore that 
component. If the component has an extremely negative mean, though, ignoring 
it could lead us to severely underestimate the risk of the security. Equity market 
crashes are a perfect example of an extremely low-probability, highly negative mean 
event.

Distributions
85
Exhibit 4.15 
Skewed Mixture Distribution
Skewed Density Function
0.5N(0,1) + 0.5N(–1,4)
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
–8
–6
–4
–2
0
2
4
6
Bimodal Density Function
0.5N(2,1) + 0.5N(–2,1)
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
–6
–4
–2
0
2
4
6
Exhibit 4.16 
Bimodal Mixture Distribution

86
Mathematics and Statistics for Financial Risk Management
Problems
	 1.	XYZ Corporation announces its earnings four times per year. Based on histori-
cal data, you estimate that in any given quarter the probability that XYZ Cor-
poration’s earnings will exceed consensus estimates is 30%. Also, the probability 
Sample Problem
Question:
Assume we have a mixture distribution with two independent components 
with equal variance. Prove that the variance of the mixture distribution must 
be greater than or equal to the variance of the two component distributions.
Answer:
Assume the two random variables, X1 and X2, have variance σ2. The means 
are µ1 and µ2, with corresponding weights w and (1 − w).
The mean of the mixture distribution, X, is just the weighted average of 
the two means:
µ
µ
µ
=
=
+
=
+
−
E X
w E X
w E X
w
w
[
]
[
]
[
]
(
)
1
1
2
2
1
2
1
The variance is then:
E X
w E X
w E X
[(
) )]
[(
) )]
(
) [(
) ]
−
=
−
+
−
−
µ
µ
µ
2
1
1
2
2
2
1
First, we solve for one term on the right-hand side:
E X
E X
w
w
E X
[(
) ]
[(
(
)
) ]
[(
(
1
2
1
1
2
2
1
1
1
1
−
=
−
−
−
=
−
−
µ
µ
µ
µ
−
−
=
−
−
−
−
−
w
E X
X
w
)(
)) ]
[(
)
(
)(
)(
µ
µ
µ
µ
µ
2
1
2
1
1
2
1
1
2
2
1
µ
µ
µ
σ
µ
µ
1
2
2
1
2
2
2
1
2
2
1
1
)
(
) (
) ]
(
) (
)
+
−
−
=
+
−
−
w
w
Similarly for the second term:
E X
w
[(
) ]
(
)
2
2
2
2
1
2
2
−
=
+
−
µ
σ
µ
µ
Substituting back into our original equation for variance:
E X
w
w
[(
) )]
(
)(
)
−
=
+
−
−
µ
σ
µ
µ
2
2
1
2
2
1
Because w and (1 − w) are always positive and (µ1 − µ2)2 has a minimum of 
zero, w(1 − w)(µ1 − µ2)2 must be greater than or equal to zero. Therefore, the 
variance of the mixture distribution must always be greater than or equal to σ2.

Distributions
87
of exceeding the consensus in any one quarter is independent of the outcome in 
any other quarter. What is the probability that XYZ Corporation will exceed 
estimates three times in a given year?
	 2.	The market risk group at your firm has developed a value at risk (VaR) model. 
In Chapter 7 we examine VaR models more closely. In the meantime, assume the 
probability of an exceedance event on any given day is 5%, and the probability 
of an exceedance event occurring on any given day is independent of an exceed-
ance event having occurred on any previous day. What is the probability that 
there are two exceedances over 20 days?
	 3.	Assume the annual returns of Fund A are normally distributed with a mean and 
standard deviation of 30%. The annual returns of Fund B are also normally dis-
tributed, but with a mean and standard deviation of 40%. The returns of both 
funds are independent of each other. What is the mean and standard deviation of 
the difference of the returns of the two funds, Fund B minus Fund A? At the end 
of the year, Fund B has returned 80%, and Fund A has lost 12%. How likely is 
it that Fund B outperforms Fund A by this much or more?
	 4.	The number of defaults per month in a large bond portfolio follows a Poisson 
process. On average, there are two defaults per month. The number of defaults 
is independent from one month to the next. What is the probability that there 
are five defaults over five months? Ten defaults? Fifteen defaults?
	 5.	The annual returns of an emerging markets bond fund have a mean return 
of 10% and a standard deviation of 15%. Your firm invests $200 million 
into the fund. What is the probability of losing more than $18.4 million? 
Assume the returns are normally distributed, and ignore the limited liability 
constraint (i.e., the impossibility of losing more than the initial $200 million 
investment).
	 6.	The annual returns of an emerging markets exchange-traded fund (ETF) have an 
expected return of 20.60% and a standard deviation of 30.85%. You are asked 
to estimate the likelihood of extreme return scenarios. Assume the returns are 
normally distributed. What is the probability that returns are worse than −30%?
	 7.	For a uniform distribution with a lower bound x1 and an upper bound x2, prove 
that the formulas for calculating the mean and variance are:
µ
σ
=
+
=
−
1
2
1
12
2
1
2
2
1
2
(
)
(
)
x
x
x
x
	 8.	Prove that the normal distribution is a proper probability distribution. That is, 
show that:
−∞
∞
−
−
∫
=
1
2
1
2
2
2
2
πσ
µ
σ
e
dx
x
(
)
You may find it necessary to use the Gaussian integral:
−∞
∞
−
∫
=
e
dx
x2
π

88
Mathematics and Statistics for Financial Risk Management
	 9.	Prove that the mean of the normal distribution, as specified in Equation 4.12, is 
µ. That is, show that:
−∞
∞
−
−
∫
=
x
e
dx
x
1
2
2
2
2
2
πσ
µ
µ
σ
(
)
	10.	Prove that the variance of a normal distribution, as specified in Equation 4.12, 
is σ2. You may find the following result useful:
−∞
∞
−
∫
=
x e
dx
x
2
2
1
2
π
	11.	Prove that the correlation between XA and XB is ρ, where:
X
X
X
X
X
X
A
B
=
+
−
=
+
−
ρ
ρ
ρ
ρ
1
2
1
3
1
1
and X1, X2, and X3 are uncorrelated standard normal variables.
	12.	Imagine we have two independent uniform distributions, A and B. A ranges be-
tween −2 and −1, and is zero everywhere else. B ranges between +1 and +2, and 
is zero everywhere else. What are the mean and standard deviation of a portfolio 
that consists of 50% A and 50% B? What are the mean and standard deviation 
of a portfolio where the return is a 50/50 mixture distribution of A and B?

89
Chapter 5
Multivariate Distributions 
and Copulas
I
n this chapter we explore distributions involving more than one variable, and pro-
vide a brief overview of copulas. Multivariate distributions are an important tool 
for modeling portfolios.
Multivariate Distributions
A multivariate distribution or joint distribution is a distribution involving two or 
more variables. We begin our exploration of multivariate distributions by examining 
discrete distributions, before moving on to continuous distributions.
Discrete Distributions
A probability matrix is an example of a discrete multivariate distribution. The fol-
lowing probability matrix from Chapter 2 lists various probabilities for the perfor-
mance of the equity and bonds of a company. 
This is a discrete joint distribution with two random variables, one for the per-
formance of the equity and one for the performance of the bonds. A joint distribu-
tion with two random variables can also be referred to as a bivariate distribution. In 
Exhibit 5.1 there are six distinct joint probabilities. For example, the joint probabil-
ity of both equity outperforming and bonds being downgraded is 5%. As is required 
of any distribution, the sum of all the probabilities is equal to 100%.
We can easily create a joint distribution for any number of random variables, 
though displaying the results in a simple probability matrix would be difficult for 
Exhibit 5.1 
Probability Matrix
Equity
Outperform
Underperform
Bonds
Upgrade
15%
5%
No Change
30%
25%
Downgrade
5%
20%

90
Mathematics and Statistics for Financial Risk Management
more than two variables. No matter how many variables there are, the basic idea is 
the same: To define a discrete distribution, we assign a probability to every possible 
joint outcome, and the sum of those probabilities must add up to 100%. 
As another example, pretend we are interested in three mutual funds, Fund A, 
Fund B, and Fund C; furthermore, assume we are interested only in the probability 
of the funds generating returns that are under or over a particular benchmark. With 
three funds and two possible outcomes for each fund, there is a total of eight distinct 
outcomes, each with an associated joint probability. We could list them in a table as 
in Exhibit 5.2.
Rather than increasing the number of variables, we could increase the number 
of possible outcomes for each variable. In Exhibit 5.3 we have the joint distribution 
for two bonds, each of which can have one of eight possible letter ratings at the end 
of the year. This gives us a total of 64 possible outcomes.
In theory, we could create a matrix of any size. As the number of possible out-
comes approaches infinity, the discrete multivariate distribution converges to a con-
tinuous multivariate distribution, or continuous joint distribution.
Exhibit 5.2 
Joint Probabilities Table
Fund A
Fund B
Fund C
Probability
Under
Under
Under
1%
Under
Under
Over
2%
Under
Over
Under
8%
Under
Over
Over
22%
Over
Under
Under
35%
Over
Under
Over
22%
Over
Over
Under
8%
Over
Over
Over
2%
100%
Exhibit 5.3 
Joint Distribution Matrix
Bond #1
AAA
AA
A
BBB
BB
B
C
D
Bond #2
AAA
0.0%
0.2%
0.2%
0.4%
0.2%
0.1%
0.0%
0.0%
AA
0.1%
0.6%
1.8%
2.9%
1.8%
0.4%
0.2%
0.1%
A
0.2%
1.8%
5.3%
8.3%
5.3%
1.5%
0.3%
0.2%
BBB
0.3%
2.9%
8.3%
13.0%
8.3%
2.6%
0.4%
0.0%
BB
0.2%
1.8%
5.0%
8.0%
5.3%
1.8%
0.1%
0.1%
B
0.1%
0.5%
1.8%
2.6%
1.3%
0.6%
0.1%
0.0%
C
0.1%
0.1%
0.3%
0.6%
0.5%
0.3%
0.0%
0.0%
D
0.0%
0.1%
0.2%
0.4%
0.2%
0.2%
0.0%
0.0%

Multivariate Distributions and Copulas
91
Continuous Distributions
Just as with a single random variable, we can define a continuous joint distribution 
based on its probability density function (PDF). If we have two random variables, X 
and Y, for example, we could define the joint PDF, f(x,y), such that the probability 
of finding X between x1 and x2 and at the same time finding Y between y1 and y2 is 
given by:
	
P x
X
x
y
Y
y
f x y dxdy
y
y
x
x
[
,
]
( , )
1
2
1
2
1
2
1
2
≤
≤
≤
≤
=
∫
∫

(5.1)
where x1 < x2 and y1 < y2. As with any distribution, some event has to occur, and if 
we integrate over all possible values of X and Y, the total must be 1:
	
f x y dxdy
y
x
( , )
=
∫
∫
1
(5.2)
For a joint distribution, we can also define a cumulative distribution function 
(CDF), F(x,y):
	
F x y
P X
x Y
Y
f t u dtdu
y
x
( , )
[
,
]
( , )
=
≤
≤
=
−∞
−∞∫
∫

(5.3)
To go from a joint cumulative distribution to a joint probability density func-
tion, we simply take the partial derivative with respect to all the underlying vari-
ables. For our bivariate distribution, we have:
	
f x y
F x y
x y
( , )
( , )
= ∂
∂∂
2

(5.4)
The right-hand side of Equation 5.4 is the second-order cross partial derivative 
of F(x,y). 
Sample Problem
Question:
Imagine we have two bonds, whose value can vary between $0 and $100. 
Assume the joint distribution function for the value of the bonds is a joint uni-
form distribution, such that f(x,y) equals c, a constant, for all values of X and 
Y between $0 and $100, and is zero everywhere else. That is:
f x y
c
( , ) =
∀ 0 > X > 100,0 > Y > 100
∀ 0 ≤ X ≤ 100,0 ≤ Y ≤ 100
0
Find c.
Answer:
Integrating over all possible values, it must be the case that:
cdxdy =
∫
∫
1
0
100
0
100

92
Mathematics and Statistics for Financial Risk Management
Solving, we have:
cdxdy
c xy
c
x
y
x
y
=
=
∫
∫
=
=
=
=
[
]
(
,
,
0
100
0
100
0
0
100
100
100 100
0 0
10 000
10 000
1
1
10 000
⋅
⋅
−
=
=
=
)
,
,
,
c
c
c
We can define joint probability density functions and joint cumulative distribu-
tion functions for any number of variables. For example, with n variables, X1, X2, 
.  .  ., Xn, the joint cumulative distribution, F(x1, x2, .  .  ., xn), in terms of the probability 
density function, f(x1, x2, .  .  ., xn), would be:
	
F x x
x
P X
x X
x
X
x
f y y
y
dy dy
dy
(
,
,...,
)
[
,
,...,
]
...
(
,
,...,
)
... 
n
n
n
n
x
n
x
x
1
2
1
1
2
2
1
2
1
2
n
2
1
∫
∫
∫
=
≤
≤
≤
=
−∞
−∞
−∞

(5.5)
Visualization
Just as we can graph the probability density function for one variable in two dimen-
sions, we can graph the probability density function for a joint distribution of two 
variables in three dimensions. Exhibit 5.4 shows the probability density function 
from the previous sample problem. Here, the value of the density function corre-
sponds to the distance along the z-axis, or the height of the distribution. 
z
x
100
100
0.0001
y
Exhibit 5.4 
Joint Uniform Probability Density Function

Multivariate Distributions and Copulas
93
As we might expect, the joint PDF resembles a box, whose volume is equal 
to one.
Exhibit 5.5 shows a bivariate normal distribution. In this case it is a joint 
standard normal distribution, where both variables, X and Y, are standard normal 
variables.
Three-dimensional charts look nice, but the perspective can hide details. An al-
ternative way to visualize a joint distribution of two variables is by using a contour 
graph. In a contour graph it is as if we are looking at the three-dimensional graph 
from directly overhead. Exhibit 5.6 is a contour graph corresponding to the joint 
normal PDF in Exhibit 5.5. Different shades of gray represent different values for 
the density function. The borders between different regions are called isolines or 
isoquants, because all of the points on one isoquant have the same value.
Beyond two variables, visualization becomes more difficult. Even when more 
variables are involved, starting with the two-variable case can be convenient for 
purposes of exposition or for gaining intuition. 
Correlation
Up until this point, we have not said anything about correlation. How would we 
recognize correlation in a joint distribution? One way would be to examine the 
contour graph of the distribution. Notice in Exhibit 5.6 how the distribution is sym-
metric across both axes. This tells us that, for a given value of X, positive values and 
negative values of Y are equally likely, and vice versa. This suggests that X and Y are 
uncorrelated.
–2.50
–1.25
0.00
1.25
2.50
0.00
0.04
0.08
0.12
0.16
–2.50
–1.25
0.00
1.25
2.50
Exhibit 5.5 
Bivariate Standard Normal PDF

94
Mathematics and Statistics for Financial Risk Management
Now look at Exhibit 5.7. Rather than forming concentric circles around the 
origin, the contour lines in this chart form ellipses. This graph is symmetric, but not 
about the x- and y-axes. As it turns out, this graph is also based on the PDF of a joint 
standard normal distribution. The only difference between this joint distribution and 
the previous joint distribution is the correlation between X and Y.
–2.50
–1.25
0.00
1.25
2.50
–2.50
–1.25
0.00
1.25
2.50
0.15–0.20
0.10–0.15
0.05–0.10
0.00–0.05
Exhibit 5.6 
Bivariate Standard Normal PDF Contour Graph
–2.50
–1.25
0.00
1.25
2.50
–2.50
2.50
–1.25
1.25
0.00
0.15–0.20
0.10–0.15
0.05–0.10
0.00–0.05
Exhibit 5.7 
Joint Standard Normal Distribution with Positive Correlation

Multivariate Distributions and Copulas
95
In Exhibit 5.7 we can see from the contour graph that X is more likely to be 
positive when Y is positive (the density function is higher), and X is more likely to 
be negative when Y is negative. In other words, X and Y are positively correlated.
If X and Y were negatively correlated, the contour graph would be deformed in 
the opposite way. Exhibit 5.8 shows a contour graph of the PDF of two negatively 
correlated standard normal variables. 
Marginal Distributions
Given a joint distribution, we can easily recover the distribution for each of the un-
derlying random variables. In this context the individual univariate distributions are 
known as marginal distributions.
We illustrate this first with discrete distributions. The probability matrix from 
the beginning of the chapter is reproduced here as Exhibit 5.9 with the addition of 
subtotals for the rows and columns. These subtotals form the marginal distributions.
By adding up the columns of the matrix, we see that there is a 50% chance 
that the equity outperforms the market and a 50% chance that the equity under-
performs the market. This is the marginal distribution of the equity. Notice that 
these probabilities are unconditional; they do not depend on what happens to the 
bonds. ­Likewise, the marginal distribution of the bonds has three possible states, 
whose probabilities can be found by summing across each row. The probability of 
an upgrade is 20%, the probability of no change is 55%, and the probability of a 
downgrade is 25%. The marginal distributions are proper distributions in and of 
themselves. In both cases, the probabilities of the marginal distributions sum to one.
We can summarize this process for obtaining marginal distributions mathemati-
cally. For a discrete joint distribution of two random variables, X and Y, with a joint 
–2.50
–1.25
0.00
1.25
2.50
–2.50
–1.25
0.00
1.25
2.50
0.15–0.20
0.10–0.15
0.05–0.10
0.00–0.05
Exhibit 5.8 
Joint Standard Normal Distribution with Negative Correlation

96
Mathematics and Statistics for Financial Risk Management
Exhibit 5.9 
Probability Matrix with Subtotals
Equity
Outperform
Underperform
Bonds
Upgrade
15%
5%
20%
No Change
30%
25%
55%
Downgrade
5%
20%
25%
50%
50%
probability density function, f(x,y), the marginal probability density function of X, 
fx(x), can be found as follows: 
	
f
x
f x y
x
y
( )
( , )
= ∑

(5.6)
In other words, to get the value of the marginal PDF of X for a given value of 
X, x, we simply sum over all values of Y, with X set equal to x. To get the marginal 
distribution of Y, we simply reverse variables, summing over all possible values of X 
for a given value of Y.
For a continuous joint distribution, the analogous process involves integrating 
over all possible values of the other variable. For a continuous joint distribution of 
two random variables, X and Y, with a joint probability density function, f(x,y), the 
marginal probability density function of X, fx(x), can be found as follows:
	
f
x
f x t dt
x
y
( )
( , )
= ∫

(5.7)
As before, we can reverse the variables to obtain the marginal distribution for Y.
We can also obtain the marginal distribution from the joint cumulative distri-
bution by taking the derivative of the joint distribution. For a joint distribution of 
two variables, X and Y, we can obtain the marginal distribution of X by taking the 
derivative of the joint distribution with respect to X:
	
f
x
F x y
x
x( )
( , )
= ∂
∂

(5.8)
There is an important link between the marginal distributions and independ-
ence. If two random variables, X and Y, are independent, then the joint PDF will be 
equal to the product of the marginal PDFs. The reverse is also true: If the joint PDF 
is equal to the product of the marginal PDFs, then X and Y are independent:
	
f(x,y) = fx(x)fy(y) ⇔ X and Y are independent 
(5.9)
If two random variables are independent, then the product of their cumulative 
distribution functions is also equal to the CDF of their joint distribution.

Multivariate Distributions and Copulas
97
Sample Problem
Question:
Given the following joint probability density function, prove that X and Y 
are independent:
f x y
c
( , ) =
∀ 0 > X > 100,0 > Y > 100
∀ 0 ≤ X ≤ 100,0 ≤ Y ≤ 100
0
where c is equal to 1/10,000.
Answer:
We start by calculating the marginal distribution of X:
f
x
f x t dt
dt
cdt
dt
f
x
y
( )
( , )
=
=
+
+
∞
−∞
∫
∫
∫
∫
0
0
110
0
100
0
x
x
x
cdt
f
x
cdt
c t
c
( )
( )
[ ]
=
+
+
=
=
=
∫
∫
0
0
0
100
0
100
0
100
(
)
( )
100
0
100
1
100
1
100
−
=
=
=
c
f
x
x
Because f(x,y) only involves a constant, it is not surprising that we get the 
same answer for the marginal distribution of Y:
f
x
f t y dt
cdt
c t
c
y
x
( )
( , )
[ ]
(
)
=
=
=
=
−
∫
∫
0
100
0
100
100
0 =
=
100
1
100
c
Putting the two together, we can see that the product of the marginal dis-
tributions is equal to the joint distribution.
f x y
f
x f
y
x
y
( , )
,
( )
( )
=
=
=
1
10 000
1
100
1
100
Because the joint PDF is equal to the product of the marginal PDFs, it fol-
lows that X and Y must be independent.
Copulas
In this section we introduce the concept of the copula. In statistics, copulas are used 
to describe various types of multivariate distributions. 
What Is a Copula?
In the previous section we showed three graphs of joint normal distributions, one 
where the two variables were uncorrelated, one where the two variables were 
positively correlated, and one where the two variables were negatively correlated. So 
what about Exhibit 5.10?

98
Mathematics and Statistics for Financial Risk Management
It turns out that Exhibit 5.10 is also a joint normal distribution. Unlike the pre-
vious three examples where the contour lines were all ellipses (circles being special 
types of ellipses), this new chart has more of a teardrop shape. In this new graph, it 
appears that extreme negative-negative results are more likely than extreme positive-
positive results. 
The graph in Exhibit 5.10 was produced using a special function known as a 
copula. In everyday parlance, a copula is simply something that joins or couples. In 
statistics, a copula is a function used to combine two or more cumulative distribu-
tion functions in order to produce one joint cumulative distribution function.
In many fields, when it comes to joint distributions, ellipses are all that you will 
see. In finance, assuming a joint distribution is elliptical when in fact it is not can 
lead to a serious underestimation of risk. In Chapter 3, we saw how coskewness 
and cokurtosis could impact the risk of a portfolio. Though we did not recognize it 
as such at the time, the sample distributions with extreme coskewness in Chapter 3 
were nonelliptical. Copulas provide us with a method for producing and describing 
nonelliptical joint distributions.
There is an infinite number of ways in which two distributions can be related 
to each other, but statisticians have found it useful to describe a few prototypical 
patterns. Examples include the Gaussian, t, Gumbel, Frank, and Clayton copulas. 
The last three copulas—the Gumbel, Frank, and Clayton copulas—are members of 
a class of copulas known as the Archimedean copulas. Each of these named copu-
las has a characteristic way of distorting the relationship between two variables. 
Exhibit 5.10 is an example of a joint distribution based on the Clayton copula. The 
Clayton copula exhibits greater dependence in the negative tail than in the positive 
tail, a not-uncommon feature of financial returns, making it a popular choice in risk 
management. Appendix F contains a brief summary of several popular copulas.
–2.50
0.00
2.50
2.50
0.00
–2.50
0.20–0.25
0.15–0.20
0.10–0.15
0.05–0.10
0.00–0.05
Exhibit 5.10 
Bivariate Standard Normal PDF with Clayton Copula

Multivariate Distributions and Copulas
99
A copula only defines a relationship between univariate distributions. The un-
derlying distributions themselves can be any shape or size. For instance, we can talk 
about a normal Gumbel copula, meaning the marginal distributions are all normal, 
and we can talk about a lognormal Gumbel copula, meaning the marginal distribu-
tions are lognormal. We can even talk about a normal-lognormal Gumbel copula, 
meaning one of the marginal distributions is normal and one is lognormal.
Mechanically, copulas take as their inputs two or more cumulative distribu-
tions and output a joint cumulative distribution. The advantage of working with 
cumulative distributions is that the range is always the same. No matter what the 
distribution is, the output of a cumulative distribution always ranges from 0% 
to 100%.
We typically represent cumulative distributions with capital letters, for example 
F(x). In order to make the formulas more readable, when describing copulas we 
­often use lowercase letters instead. For example, given two cumulative distributions, 
u and v, and a constant, α, we can write Frank’s copula as:
	
C u v
e
e
e
v
u
( , )
(
)
)
(
=
+
−
−
−
1
1
1
1
1
α
α
α
α
ln

(5.10)
As used in Equation 5.10, α determines the shape of the joint cumulative distri-
bution, C(u,v). In the case of Frank’s copula, it is fairly easy to see that when both 
u and v are 100%, C(u,v) is also 100%. In other words, if an outcome for the first 
variable is certain, and another outcome is certain for the second variable, then the 
chance of both outcomes occurring is also certain. It’s slightly more difficult to see, 
but in the limit, as both u and v go to zero, C(u,v) also goes to zero.
Sample Problem
Question:
Assume we have two standard uniform random variables, X and Y, whose 
joint distribution is defined by Frank’s copula. What is the formula for the 
cumulative distribution of the two variables? What is the formula for the prob-
ability density function for α = 1?
Answer:
If X is a standard uniform variable, then its cumulative distribution func-
tion is defined as:
F x
x
( ) =
∀ 0 > x > 1
∀ 0 ≤ x ≤ 1
0
Y is defined similarly. Using Equation 5.10, and setting F(x) equal to u and 
F(Y) equal to v, for values of X and Y less than 0 or greater than 1, we have:
F x y
e
e
e
( , )
(
)(
)
=
+
−
−
−
=
1
1
1
1
1
1
1
0
0
α
α
α
α
α
ln
ln
+
−
−
−
=
=
(
)(
)
[ ]
1
1 1
1
1
1
0
1
eα
α ln

100
Mathematics and Statistics for Financial Risk Management
For values of X and Y between 0 and 1, we have:
F x y
e
e
e
y
x
( , )
(
)
)
(
=
+
−
−
−
1
1
1
1
1
α
α
α
α
ln
For α = 1, this simplifies to:
F x y
e
e
e
e
e
e
e
e
( , )
ln 1
(
1)(
1)
1
ln
)
(
ln
1
(
)
x
y
x y
x
y
=
+
−
−
−
=
−
−
+
−
−
+
We can quickly check that for x = y = 0, we have F(x,y) = 0; and for  
x = y = 1, we have F(x,y) = 1.
To get the probability density function, we need to calculate the second 
partial derivative with respect to x and then y:
f x y
F x y
x y
y
e
e
e
e
e
e
x y
x
x y
x
y
( , )
( , )
(
= ∂
∂∂
= ∂
∂
−
−
−
+
+
+
2
)
( , )
(
)
(
)
=
−
−
+
−
−
+
+
+
f x y
e
e
e
e
e
e
e
x y
x y
x
y
x y
y
)
(
)
(
( , )
(
)
(
e
e
e
e
e
e
f x y
e
e
e
x y
x
x y
x
y
x y
+
+
+
−
−
−
+
=
−
2
1
x y
x
y
e
e
e
+ −
−
+ )2
The joint distribution is shown in Exhibit 5.11.
–2.50
0.00
2.50
0.00
2.50
–2.50
0.15–0.20
0.10–0.15
0.05–0.10
0.00–0.05
Exhibit 5.11 
Frank’s Joint Standard Uniform PDF, α = 1

Multivariate Distributions and Copulas
101
In the preceding sample problem, in order to calculate the joint PDF we first 
calculated the joint CDF. There is another way we could proceed. Assume we have 
two cumulative distributions, u = F(x) and v = F(y); then, making use of the chain 
rule, we have:
	
f x y
C u v
x y
C u v
u v
u
dx
v
dy
c
( , )
( , )
( , )
(
= ∂
∂∂
= ∂
∂∂
∂
∂
=
2
2
u, ) ( ) ( )
v f x f y 
(5.11)
Here we have denoted the second cross partial derivative of C(u,v) by c(u,v); c(u,v) 
is often referred to as the density function of the copula. Because c(u,v) depends on 
only the copula and not the marginal distributions, we can calculate c(u,v) once and 
then apply it to many different problems. 
Sample Problem
Question:
Calculate the density function for Frank’s copula when α = 1. Use the 
results to calculate the joint probability density function for two standard uni-
form variables.
Answer:
We start by rearranging our formulas for Frank’s copula:
C u v
e
e
e
u
v
( , )
(
)(
)
(
=
+
−
−
−
=
1
1
1
1
1
1
α
α
α
α
α
ln
ln e
e
e
e
e
u v
u
v
α
α
α
α
α
α
+
−
−
−
−
+
(
)
)
(
)
1
1
ln
Next, we calculate the density function for Frank’s copula by taking the 
partial derivative with respect to u and v. The order is not important. We can 
take the derivative with respect to u and then v, or v and then u:
c u v
C u v
u v
c u v
u
e
e
u v
( , )
( , )
( , )
(
)
= ∂
∂∂
= ∂
∂
−
+
2
1
α
α
α
α
αv
u v
u
v
u v
v
e
e
e
e
u
e
e
(
)
(
)
(
)
α
α
α
α
α
α
+
−
−
= ∂
∂
−
+
+
(
)
(
( , )
(
(
)
(
)
e
e
e
e
c u v
e
u v
v
u
u v
α
α
α
α
α
α
+
−
−
=
+
+
e
e
e
e
e
e
e
u v
u
v
u v
v
u v
α
α
α
α
α
α
α
α
+
−
−
−
−
+
+
+
(
)
(
)
(
)
)
(
)(
−
+
−
−
=
+
+
α
α
α
α
α
α
α
α
e
e
e
e
e
c u v
e
u
u v
u
v
u v
)
)
(
( , )
(
)
(
)
2
(
)
(
)
(
)
e
e
e
e
e
u v
u
v
α
α
α
α
α
−
+
−
−
+
1
2
 (5.12)
As in the previous sample problem, we use two standard uniform vari-
ables, X and Y, where the CDFs between 0 and 1 are x and y, respectively. 
Substituting x and y for u and v, and setting α = 1, we have:
c x y
e
e
e
e
e
e
x y
x y
x
y
( , )
(
)
(
)
(
)
(
)
=
−
+
−
−
+
+
1
2

102
Mathematics and Statistics for Financial Risk Management
Finally, to get the joint PDF, using Equation 5.11, we multiply the density 
function by the PDFs for X and Y, f(x) and f(y), respectively. Because both vari-
ables are standard uniform random variables, their PDFs are equal to 1.
f x y
c u v f x f y
c u v
e
e
e
x y
( , )
( , ) ( ) ( )
( , )
(
)
(
(
)
=
=
=
−
+
+
1
e
e
e
x y
x
y
(
)
)
+
−
−
2
To check the result, we note that the final equation matches the result from 
the previous sample problem.
Graphing Copulas
Exhibit 5.12 shows the joint PDF for a standard normal Frank’s copula. As you can 
see from the exhibit, Frank’s copula displays symmetric tail dependence. How do 
we actually go about creating one of these graphs? One of the easiest ways is to use 
Equation 5.11. For any point on the graph, (x,y), we first calculate values for both 
the PDF and the CDF of X and Y. We use the CDFs to calculate the copula density 
function, and then multiply this value by the value of the PDFs to determine the 
value of the joint distribution at that point. 
For example, suppose that we want to graph the joint PDF of a Frank’s copula 
for two standard normal variables with α = 2. To determine the height of the graph 
at (x,y) = (0,0), we start by calculating the cumulative distribution for both vari-
ables. At 0, the cumulative distribution for a standard normal variable is equal to 
0.50. We can calculate this in Excel by using the NORMSDIST function. Plugging 
0.50 into the copula’s density function, Equation 5.12, for both x and y gives us 
a value of 1.08. Next, we multiply this by the value of the standard normal PDF, 
which for 0 is 0.40. You can get this in Excel by using the NORMDIST function, 
setting the cumulative option to false. Our final answer for the height of the distri-
bution is then 0.17: 
f x y
c u v f x f y
e
e
e
e
u v
( , )
( , ) ( ) ( )
(
)
(
(
)
(
=
=
−
+
+
α α
α
α
α
1
u v
u
v
e
e
f x f y
f x y
e
+
+
−
−
=
)
( .
. )
)
( ) ( )
( , )
(
α
α
2
2 0 5 0 5
2
e
e
e
e
e
0 5
2
2 0 5 0 5
2 0 5
2 0 5 2
1
0 4
.
( .
. )
.
.
)
(
)
.
−
+
−
−
+
⋅
⋅
⋅
0 0 40
1 08 0 40 0 40
0 17
⋅
⋅
⋅
=
=
.
.
.
.
.
To complete the graph, we would continue to calculate values of the PDF for 
various combinations of X and Y. Exhibit 5.12 was drawn using 441 evenly spaced 
(x,y) pairs.
Because Equation 5.11 allows us to separate the copula density function and the 
marginal distributions, going from a normal-normal Frank’s distribution to, say, a 
uniform-uniform Frank’s distribution is relatively easy; we simply change the PDF 
and CDF functions from normal to uniform.
An Excel spreadsheet with several examples is available online.

Multivariate Distributions and Copulas
103
Using Copulas in Simulations
In this section, we demonstrate how copulas can be used in Monte Carlo simula-
tions. Our example uses two random variables, but the same basic methodology can 
be extended to any number of variables.
In order to use copulas in a Monte Carlo simulation, we need to calculate the 
inverse marginal CDFs for the copula. To determine the marginal CDFs of a copula, 
we take the first derivative of the copula function with respect to one of the under-
lying distributions. For two cumulative distributions u and v, the marginal CDFs 
would be:
	
C
C
u
c u v dv
C
C
v
c u v dv
1
2
= ∂
∂
=
= ∂
∂
=
∫
∫
( , )
( , )

(5.13)
For example, for Frank’s copula the marginal CDF for u would be:
	
C
C
u
e
e
e
e
e
u
v
v
u
1
1
1
1
1
= ∂
∂
=
−
−
+
−
−
−
−
−
−
(
)(
)
(
)
(
)(
α
α
α
α
−
−
−
+
−
α
α
v
e
1
1
)
(
) 
(5.14)
C1 is a proper CDF, and varies between 0% and 100%. To determine the inverse of 
C1, we solve for v:
	
v
C e
C
e
u
= −
+
−
+
−
−
−
−
1
1
1
1
1
1
1
1
α
α
α
ln
)
(
(
)
)
(

(5.15)
–2.50
0.00
2.50
2.50
0.00
–2.50
0.15–0.20
0.10–0.15
0.05–0.10
0.00–0.05
Exhibit 5.12 
Bivariate Standard Normal PDF with Frank’s Copula, α = 2

104
Mathematics and Statistics for Financial Risk Management
Each iteration in the Monte Carlo simulation then involves three steps: 
	 1.	Generate two independent random draws from a standard uniform distribution. 
These are the values for u and C1.
	 2.	Use the inverse CDF of the copula to determine v. This is the essential step. De-
pending on the copula, different values of v will be more or less likely, given u.
	 3.	Calculate values for x and y, using inverse cumulative distribution functions for 
the underlying distributions. For example, if the underlying distributions are 
normal, use the inverse normal CDF to calculate x and y based on u and v.
The easiest way to understand this process is to see it in action. We provide a 
brief example here. There is also an Excel example available online.
Sample Problem
Question:
Assume we are using the Frank copula in a Monte Carlo simulation, with 
α = 3. The underlying distributions of u and v are both standard normal dis-
tributions. For any given u and value of the marginal CDF, we want to deter-
mine the corresponding value of v. If our random number generator produces 
u = 0.20 and C1 = 0.50, what are the values of our underlying random variables 
X and Y?
Answer:
First we determine v using Equation 5.15:
v
e
e
= −
+
−
+
−
−
−
−⋅
1
3
1
0 50
1
1
1 1
0 50
3
3 0 20
ln
.
(
)
(
)(
.
)
.
= 0 32
.
Notice that u, v, and C1 are all between 0% and 100%. We then use an 
inverse standard normal function, NORMSINV() in Excel, to calculate x and 
y from u and v. We get: x = −0.84 and y = −0.48. Notice that even though C1 
was 0.50, right in the center of its distribution, y is negative. This is because x 
is negative, and negative-negative pairs are more likely with the Frank copula.
Parameterization of Copulas
Given a copula, we know how to calculate values for that copula, but how do we 
know which copula to use in the first place? The answer is a mixture of art and 
­science. 
In picking which type of copula to use, there are quantitative methods we could 
use, but in practice this choice is often based on the general characteristics of the 
data. If the data seem to exhibit increased correlation in crashes, then you should 
choose a copula that displays a higher probability in the negative-negative region 
such as the Clayton copula. Choosing a copula is often where the art comes into play.

Multivariate Distributions and Copulas
105
Once we know which type of copula we are going to use, we need to determine 
the parameters of the copula. Take for example the Farlie-Gumbel-Morgenstern 
(FGM) copula, given by:
	
C = uv[1 + α(1 – u)(1 – v)]
(5.16)
As with most copulas, there is a single parameter, α, which needs to be determined, 
and this parameter is related to how closely the two underlying random variables 
are related to each other.
In statistics, the most popular method for measuring how closely two variables 
are related to each other is correlation. For two random variables, X and Y, with 
standard deviation σX and σY, respectively, correlation is defined as follows:
	
Correlation =
−
−
E X
E X
Y
E Y
X
Y
[(
[
])(
[ ])]
σ σ

(5.17)
To avoid any ambiguity, this standard correlation is often referred to as Pear-
son’s correlation or linear correlation. While this measure is extremely popular, there 
are other ways to quantify the relationship between two variables, and when work-
ing with copulas, two of these measures, Kendall’s tau and Spearman’s rho, are of-
ten preferred. Rather than being based directly on the values of the variables, both 
Kendall’s tau and Spearman’s rho are based on the order or rank of the variables. We 
start by exploring Kendall’s tau.
Two data sets are presented in Exhibit 5.13. Both sets contain three points, 
A, B, and C. In Data Set #1, the variables X and Y are both perfectly correlated, 
Y increases in exact proportion to X, always equal to 5 times X. It turns out that 
Kendall’s tau is also equal to 100% for Data Set #1. Now look at Data Set #2. The Y 
value of point C has changed. In Data Set #2 the correlation is less than 100%, but 
Kendall’s tau is still 100%. This is because, even though the value of Y for point C 
has changed, the rank of Y for point C has not changed. The value of Y for point C 
is the highest for all the points in both data sets, and only the ranks of the variables 
are relevant for Kendall’s tau. 
Interestingly, within both data sets if the X value of one point is greater than the 
X value of another point, then the Y value is also greater. Likewise, if the X value of 
one point is less than the X value of another point, then the Y value is also less. When 
the X and Y values of one point are both greater than or both less than the X and Y 
values of another point, we say that the two points are concordant. If two points are 
Exhibit 5.13 
Comparing Two Data Sets
Data Set #1
Data Set #2
X
Y
Rank[X]
Rank[Y]
X
Y
Rank[X]
Rank[Y]
A
1
5
3
3
A
1
5
3
3
B
2
10
2
2
B
2
10
2
2
C
3
15
1
1
C
3
18
1
1

106
Mathematics and Statistics for Financial Risk Management
not concordant, we say they are discordant. More formally, for two distinct points 
i and j we have:
	
Concordance: Xi > Xj and Yi > Yj or Xi < Xj and Yi < Yj
	
Disconcordance: Xi < Xj and Yi > Yj or Xi > Xj and Yi < Yj
(5.18)
Kendall’s tau is defined as the probability of concordance minus the probability of 
discordance.
τ = P[concordance] – P[discordance]
If P[concordance] is 100%, then P[discordance] must be 0%. Similarly, if P[discordance] 
is 100%, P[concordance] must be 0%. Because of this, like our standard correlation 
measure, Kendall’s tau must vary between −100% and +100%.
To measure Kendall’s tau in a given data set, we simply need to compare every 
possible pair of points and count how many are concordant and how many are 
discordant. In a data set with n points, the number of unique combinations of two 
points is as follows (see Chapter 1):
n
n
n
n n
2
2 2
1
2
1
=
−
−
=
!
(
)! !
)
(
For example, in Exhibit 5.13 each data set has three points, A, B, and C, and there 
are three possible combinations of two points: A and B, A and C, and B and C. For 
a given data set, then, Kendall’s tau is:
	
τ =
−#
#of concordant points
of discordant points
n
2

(5.19)
A potentially interesting feature of Kendall’s tau is that it is less sensitive to 
outliers than Pearson’s correlation. In Exhibit 5.13, as long as the Y value of point 
C is greater than 10, all of the points will be concordant and Kendall’s tau will be 
unchanged. It could be 11 or 11,000. In this way, measures of dependence based on 
rank are analogous to the median when measuring averages.
Sample Problem
Question:
Given the following data set, calculate Kendall’s tau:
X
Y
A
76
6
B
89
51
C
63
56
D
50
1

Multivariate Distributions and Copulas
107
Answer:
Kendall’s tau is 33%. 
In this data set there are four data points, giving us six possible pairings: 
0.5 × 4 × 3 = 6. The first pair, A and B, is concordant; 89 is greater than 76, and 
51 is greater than 6. We determine each pair in turn:
Pair
Concordant = +1,  
Discordant = −1
A, B
+1
A, C
–1
A, D
+1
B, C
–1
B, D
+1
C, D
+1
In all, there are four concordant pairs and two discordant pairs, giving us 
our final answer:
τ =
−
=
=
4
2
6
1
3
33%
As the number of points grows, the number of unique pairings increases 
rapidly. For 100 points there are 4,950 unique pairings. For large data sets, you 
will need to use a computer to calculate Kendall’s tau.
We have not said anything yet about how to approach ties—that is, if  
xi = xj or yi = yj. There is no universally agreed upon approach. The simplest 
solution is to ignore ties, but there are more complex methods. These different 
methods are often referred to as tau-a, tau-b, et cetera.
Besides being robust to outliers, measures of dependence based on rank are in-
variant under strictly increasing transformations. This is a fancy way of saying that 
we can stretch and twist our data set in certain ways, and, as long as we don’t change 
the relative order of the points, Kendall’s tau will not change. As an example, take 
a look at Exhibit 5.14, in which we have graphed two data sets. In both cases the 
relationship between the Y values and the X values is deterministic. In the first series, 
represented by circles, y´ = 4x. In the second series, represented by ×’s, y* = sin(2πx). 
The second series can be viewed as a transformation of the first, y* = sin(0.5πy´ ) for 
all values of X. Importantly, while we have moved the points, we have not changed 
the concordance; in both series a higher value of X implies a higher value of Y. Be-
cause of this, Kendall’s tau for both series is 100%.
Even though both relationships are deterministic, the correlation is 100% only 
for the first series, not for the second. In general, if the relationship between two 
variables can be described by a deterministic linear equation, then the correlation 
will be ±100%. If the correlation is deterministic but nonlinear, this will not be the 
case. This is why we describe our standard measure of correlation as being a linear 
measure of association.

108
Mathematics and Statistics for Financial Risk Management
–1.00
–0.50
0.00
0.50
1.00
5
2
.
0
0
0
.
0
–0.25
y
x
Y'
Y*
Exhibit 5.14 
Example of Transformed Data
As it turns out, for many copulas, changing the value of the shape parameter, 
α, will transform the data in a way that is similar to the way the data was trans-
formed in Exhibit 5.14. Changing α will change the shape of the data, but it will 
not change the order. For a given type of copula, then, Kendall’s tau is often a func-
tion of the copula’s parameter, α, and does not depend on what type of marginal 
distributions are being used. For example, for the FGM copula, Equation 5.16, 
Kendall’s tau is equal to 2α/9. This leads to a simple method for setting the param-
eter of the copula. First, calculate Kendall’s tau, and then set the shape parameter 
based on the appropriate formula for that copula relating Kendall’s tau and the 
shape parameter. 
Given an equation for a copula, C(u,v) and its density function c(u,v), Kendall’s 
tau can be determined as follows:
	
τ =
−
=
−
∫
∫
4
1
4
1
0
1
0
1
E C u v
C u v c u v dudv
[ ( , )]
( , ) ( , )

(5.20)
Formulas for copulas and their density functions are not always compact. Us-
ing Equation 5.20 to calculate Kendall’s tau can be tedious, but once you’ve gone 
through the calculation you can use the result again and again. Appendix F in-
cludes formulas defining the relationship between Kendall’s tau for several named 
copulas.

Multivariate Distributions and Copulas
109
Sample Problem
Question:
Using Equation 5.20, prove that Kendall’s tau for the FGM distribution 
is equal to 2α/9. What would alpha be for a data set where Kendall’s tau was 
equal to 10%?
Answer:
The FGM copula is defined by:
C = uv[1 + α (1 – u)(1 – v)] = uv + α(v – v2)(u – u2)
We first determine the density function, c, as follows:
∂
∂
=
+
−
−
= ∂
∂
=
+
−
−
C
u
v
v
v
u
c
C
udv
v
α
α
(
)(
)
(
)(
2
2
1
2
1
1
2
1
2u)
To determine Kendall’s tau, we need to integrate the product of the 
copula and the density function. There are a number of ways we could do 
this. It looks complicated, but simply by multiplying and rearranging terms 
we get:
Cc = uv[1 + α(1 – u)(1 – v)][1 + α(1 – 2u)(1 – 2v)]
Cc = [v + αv(2 – 3v)]u + αv(5v – 3)u2 + α2v(1 – 3v + 2v2)(u – 3u2 – 2u3)
To get Kendall’s tau, we need to integrate with respect to u and v. Starting 
with u, we get:
Ccdu
v
v
v u
v v
u
=
+
−
+
−
∫
1
2
2
3
1
3
5
3
3
2
0
1
(
(
))
)
(
α
α
(
)
+
−
+
−
−
α 2
2
2
3
4
1
3
2
1
2
1
2
v
v
v
u
u
u
0
1
Ccdu
v
v
v
v v
v
v
v
=
+
−
+
−
+
−
+
1
2
2
3
1
3
5
3
1
3
2
2
2
(
(
))
(
)
(
α
α
α
)
[
1
2
1
1
2
0
1
−
−
−
∫
0
0
0
+
+ ]
Ccdu
v
v
v
=
−
+
+
−
∫
1
2
1
6
2
3
2
2
2
2
3
0
1
α
α
α
α

110
Mathematics and Statistics for Financial Risk Management
Using this result, we can calculate the following double integral:
Ccdudv
v
v
v
=
−
+
+
−
1
2
1
6
3
2
2
2
2
2 3
α
α
α
α
=
−
+
∫
∫
∫
dv
Ccdudv
v
0
1
0
1
0
1
2
2
1
2
1
2
1
3
1
6
α
α
α
α
+
−
=
∫
∫
3
1
2
1
2
3
2 4
0
1
0
1
0
1
v
v
Ccdudv
4
1
18
0
1
0
1
+
∫
∫
α
We then use this to calculate Kendall’s tau:
α
τ
α
=
−
=
+
−
=
∫
∫
4
1
4 1
4
1
18
1
2
9
0
1
0
1
Ccdudv
As expected, Kendall’s tau for the FGM copula is equal to 2α/9.
We can rearrange this result to express alpha in terms of Kendall’s tau:
α
τ
= 9
2
If τ is equal to 10%, then α = 0.45.
α =
=
=
9
2
1
10
9
20
0 45
.
The preceding process of choosing a copula and then determining the pa-
rameter of the copula based on Kendall’s tau is extremely flexible. As we men-
tioned at the beginning of the section, there is another measure of dependence 
based on rank, Spearman’s rho. Both Kendall’s tau and Spearman’s rho range 
between −1 and +1, and their values are often very similar. To calculate Spear-
man’s rho from sample data, we simply calculate our standard correlation meas-
ure using the ranks of the data. We can also calculate Spearman’s rho from a 
copula function:
	
ρs
C u v dudv
=
−
∫
∫
12
3
0
1
0
1
( , )

(5.21)
In many situations, we can use either Kendall’s tau or Spearman’s rho. Both 
are valid. The choice often comes down to familiarity and to which is easier to 
calculate. For some copulas there is no discrete solution for Spearman’s rho. 
That said, when such a solution does exist, it is often easier to calculate Spear-
man’s rho.

Multivariate Distributions and Copulas
111
Problems
	 1.	Given the following joint probability density function, determine if X and Y are 
independent:
f x y
c
x
y
Y
X
X
( , )
(
)  
,
,
=
−
−
−>
>
−
>
>
−≤
≤
−≤
0
8
2
2
2
2
2
2
2
2
2
Y ≤2
	
	 where c is equal to 3/256.
	 2.	Calculate Kendall’s tau and Spearman’s rho for the following data set:
X
Y
A
70%
5%
B
40%
35%
C
20%
10%
	 3.	Calculate Kendall’s tau for the independent copula, C(u,v), given by the ­following 
formula:
C(u, v) = uv
	 4.	Calculate Spearman’s rho for the FGM copula, Equation 5.16, in terms of α.


113
Chapter 6
Bayesian Analysis
B
ayesian analysis is an extremely broad topic. In this chapter we introduce Bayes’ 
theorem and other concepts related to Bayesian analysis. We will begin to see how 
Bayesian analysis can help us tackle some very difficult problems in risk manage-
ment.
Overview
The foundation of Bayesian analysis is Bayes’ theorem. Bayes’ theorem is named af-
ter the eighteenth-century English mathematician Thomas Bayes, who first described 
the theorem. During his life, Bayes never actually publicized his eponymous theorem. 
Bayes’ theorem might have been confined to the dustheap of history had not a friend 
submitted it to the Royal Society two years after his death. 
Bayes’ theorem itself is incredibly simple. For two random variables, A and B, 
Bayes’ theorem states that:
	
P A B
P B A
P A
P B
[
|
]
[
|
]
[ ]
[ ]
=
⋅

(6.1)
In the next section we’ll derive Bayes’ theorem and explain how to interpret 
Equation 6.1. As we will see, the simplicity of Bayes’ theorem is deceptive. Bayes’ 
theorem can be applied to a wide range of problems, and its application can often 
be quite complex.
Bayesian analysis is used in a number of fields. It is most often associated with 
computer science and artificial intelligence, where it is used in everything from spam 
filters to machine translation and to the software that controls self-driving cars. The 
use of Bayesian analysis in finance and risk management has grown in recent years, 
and will likely continue to grow. 
What follows makes heavy use of joint and conditional probabilities. If you have 
not already done so and you are not familiar with these topics, you can review them 
in Chapter 2.
Bayes’ Theorem
Assume we have two bonds, Bond A and Bond B, each with a 10% probability of 
defaulting over the next year. Further assume that the probability that both bonds 

114
Mathematics and Statistics for Financial Risk Management
default is 6%, and that the probability that neither bond defaults is 86%. It follows 
that the probability that only Bond A or Bond B defaults is 4%. We can summarize 
all of this information in a probability matrix as shown in Exhibit 6.1.
As required, the rows and columns of the matrix add up, and the sum of all the 
probabilities is equal to 100%. 
In the probability matrix, notice that the probability of both bonds defaulting 
is 6%. This is higher than the 1% probability we would expect if the default events 
were independent (10% × 10% = 1%). The probability that neither bond defaults, 
86%, is also higher than what we would expect if the defaults were independent 
(90% × 90% = 81%). Because bond issuers are often sensitive to broad economic 
trends, bond defaults are often highly correlated.
We can also express features of the probability matrix in terms of conditional 
probabilities. What is the probability that Bond A defaults, given that Bond B has 
defaulted? Bond B defaults in 10% of the scenarios, but the probability that both 
Bond A and Bond B default is only 6%. In other words, Bond A defaults in 60% of 
the scenarios in which Bond B defaults. We write this as follows:
	
P A B
P A
B
P B
[
|
]
[
]
[ ]
%
%
%
=
∩
=
=
6
10
60

(6.2)
Notice that the conditional probability is different from the unconditional probabil-
ity. The unconditional probability of default is 10%.
	
P A
P A B
[ ]
%
%
[
|
]
=
≠
=
10
60

(6.3)
It turns out that Equation 6.2 is true in general. More often the equation is written 
as follows:
	
P A
B
P A B
P B
[
]
[
|
]
[ ]
∩
=
⋅

(6.4)
In other words, the probability of both A and B occurring is just the probability that 
A occurs, given B, multiplied by the probability of B occurring. What’s more, the 
ordering of A and B doesn’t matter. We could just as easily write:
	
P A
B
P B A
P A
[
]
[
|
]
[ ]
∩
=
⋅

(6.5)
Exhibit 6.1 
Probability Matrix
Bond A
No Default
Default
Bond B
No Default
86%
4%
90%
Default
4%
6%
10%
90%
10%
100%

Bayesian Analysis
115
Combining the right-hand side of both of these equations and rearranging terms 
leads us to Bayes’ theorem:
	
P A B
P B A
P A
P B
[
|
]
[
|
]
[ ]
[ ]
=
⋅

(6.6)
The following sample problem shows how Bayes’ theorem can be applied to a 
very interesting statistical question.
Sample Problem
Question:
Imagine there is a disease that afflicts just 1 in every 100 people in the 
population. A new test has been developed to detect the disease that is 99% 
accurate. That is, for people with the disease, the test correctly indicates that 
they have the disease in 99% of cases. Similarly, for those who do not have the 
disease, the test correctly indicates that they do not have the disease in 99% 
of cases.
If a person takes the test and the result of the test is positive, what is the 
probability that he or she actually has the disease?
Answer:
While not exactly financial risk, this is a classic example of how condition-
al probability can be far from intuitive. This type of problem is also far from 
being an academic curiosity. A number of studies have asked doctors similar 
questions; see, for example, Gigerenzer and Edwards (2003). The results are 
often discouraging. The physicians’ answers vary widely and are often far from 
correct.
If the test is 99% accurate, it is tempting to guess that there is a 99% 
chance that the person who tests positive actually has the disease. 99% is in 
fact a very bad guess. The correct answer is that there is only a 50% chance 
that the person who tests positive actually has the disease.
To calculate the correct answer, we first need to calculate the uncondi-
tional probability of a positive test. Remember from Chapter 2 that this is 
simply the probability of a positive test being produced by somebody with 
the disease plus the probability of a positive test being produced by somebody 
without the disease. Using a “+” to represent a positive test result, this can be 
calculated as:
P
P
P
P
[ ]
[
]
[
+ =
+ ∩
+
+ ∩
+
have disease]
[
have disease
]
[
|
]
[
]
[
|
=
+
+
+
⋅
P
P
P
have disease
have disease
have disease
have disease
]
[
]
[ ]
%
%
%
⋅
⋅
⋅
+ =
+
P
P
99
1
1
99
2
99
%
[ ]
%
%
P + =
⋅

116
Mathematics and Statistics for Financial Risk Management
Here we use the line above “have disease” to represent logical negation. In 
other words, P[
]
have disease  is the probability of not having the disease.
We can then calculate the probability of having the disease given a positive 
test using Bayes’ theorem:
P
P
P
[
|
]
[
|
]
[
have disease
have disease
have
+ =
+
⋅
disease
have disease
]
[ ]
[
|
]
%
%
%
%
P
P
+
+ =
⋅
⋅
99
1
2
99
= 50%
The reason the answer is 50% and not 99% is because the disease is so 
rare. Most people don’t have the disease, so even a small number of false posi-
tives overwhelms the number of actual positives. It is easy to see this in a ma-
trix. Assume 10,000 trials:
Actual
+
−
Test
+
99
99
198
−
1
9,801
9,802
100
9,900
10,000
If you check the numbers, you’ll see that they work out exactly as de-
scribed: 1% of the population with the disease, and 99% accuracy in each 
column. In the end, though, the number of positive test results is identical for 
the two populations, 99 in each. This is why the probability of actually having 
the disease given a positive test is 50%. 
In order for a test for a rare disease to be meaningful, it has to be extremely 
accurate. In the case just described, 99% accuracy was not nearly accurate 
enough.
Bayes’ theorem is often described as a procedure for updating beliefs about the 
world when presented with new information. For example, pretend you had a coin 
that you believed was fair, with a 50% chance of landing heads or tails when flipped. 
If you flip the coin 10 times and it lands heads each time, you might start to suspect 
that the coin is not fair. Ten heads in a row could happen, but the odds of seeing 10 
heads in a row is only 1:1,024 for a fair coin, (1/2)10 = 1/1,024. How do you update 
your beliefs after seeing 10 heads? If you believed there was a 90% probability that 
the coin was fair before you started flipping, then after seeing 10 heads your belief 
that the coin is fair should probably be somewhere between 0% and 90%. You 
believe it is less likely that the coin is fair after seeing 10 heads (so less than 90%), 
but there is still some probability that the coin is fair (so greater than 0%). As the 
following sample problem will make clear, Bayes’ theorem provides a framework for 
deciding exactly what our new beliefs should be.

Bayesian Analysis
117
Sample Problem
Question:
You are an analyst at Astra Fund of Funds. Based on an examination of his-
torical data, you determine that all fund managers fall into one of two groups. 
Stars are the best managers. The probability that a star will beat the market in 
any given year is 75%. Ordinary, nonstar managers, by contrast, are just as ­likely 
to beat the market as they are to underperform it. For both types of managers, 
the probability of beating the market is independent from one year to the next.
Stars are rare. Of a given pool of managers, only 16% turn out to be stars. 
A new manager was added to your portfolio three years ago. Since then, the 
new manager has beaten the market every year. What was the probability that 
the manager was a star when the manager was first added to the portfolio? 
What is the probability that this manager is a star now? After observing the 
manager beat the market over the past three years, what is the probability that 
the manager will beat the market next year?
Answer:
We start by summarizing the information from the problem and introduc-
ing some notation. The probability that a manager beats the market given that 
the manager is a star is 75%:
P B S
[
| ]
75%
3
4
=
=
The probability that a nonstar manager will beat the market is 50%:
P B S
[
|
]
%
=
=
50
1
2
At the time the new manager was added to the portfolio, the probability 
that the manager was a star was just the probability of any manager being a 
star, 16%, the unconditional probability:
P S
[ ]
%
=
=
16
4
25
To answer the second part of the question, we need to find P[S | 3B], the 
probability that the manager is a star, given that the manager has beaten the 
market three years in a row. We can find this probability using Bayes’ theorem:
P S
B
P
B S P S
P
B
[ | 3 ]
3
|
[ ]
[3 ]
[
]
=
We already know P[S]. Because outperformance is independent from one 
year to the next, the other part of the numerator, P[3B | S], is just the probabil-
ity that a star beats the market in any given year to the third power:
P
B S
[3
| ]
3
4
27
64
3
=
=

118
Mathematics and Statistics for Financial Risk Management
The denominator is the unconditional probability of beating the market 
for three years. This is just the weighted average probability of three market-
beating years over both types of managers:
P
B
P
B S P S
P
B S P S
P
B
[3 ]
[3
| ] [ ]
[3
|
] [ ]
[3 ]
3
4
4
25
1
2
21
25
27
64
4
25
1
8
21
25
69
400
3
3
=
+
=
+
=
+
=
Putting it all together, we get our final result:
P S
B
[ | 3 ]
27
64
4
25
69
400
9
23
39%
=
=
=
Our updated belief about the manager being a star, having seen the man-
ager beat the market three times, is 39%, a significant increase from our prior 
belief of 16%. A star is much more likely to beat the market three years in a 
row—more than three times as likely—so it makes sense that we believe our 
manager is more likely to be a star now.
Even though it is much more likely that a star will beat the market three 
years in a row, we are still far from certain that this manager is a star. In fact, at 
39% the odds are more likely that the manager is not a star. As was the case in 
the medical test example, the reason has to do with the overwhelming number 
of false positives. There are so many nonstar managers that some of them are 
bound to beat the market three years in a row. The real stars are simply out-
numbered by these lucky nonstar managers.
Next, we answer the final part of the question. The probability that the 
manager beats the market next year is just the probability that a star would 
beat the market plus the probability that a nonstar would beat the market, 
weighted by our new beliefs. Our updated belief about the manager being a 
star is 39% = 9/23, so the probability that the manager is not a star must be 
61% = 14/23:
P B
P B S
P S
P B S
P S
P B
[ ]
[
| ]
[ ]
[
|
]
[ ]
[ ]
=
+
=
+
⋅
⋅
⋅
⋅
3
4
9
23
1
2
14
23
60
P B
[ ]
%
=
The probability that the manager will beat the market next year falls some-
where between the probability for a nonstar, 50%, and for a star, 75%, but 
is closer to the probability for a nonstar. This is consistent with our updated 
belief that there is only a 39% probability that the manager is a star.

Bayesian Analysis
119
When using Bayes’ theorem to update beliefs, we often refer to prior and poste-
rior beliefs and probabilities. In the preceding sample problem, the prior probability 
was 16%. That is, before seeing the manager beat the market three times, our belief 
that the manager was a star was 16%. The posterior probability for the sample 
problem was 39%. That is, after seeing the manager beat the market three times, our 
belief that the manager was a star was 39%.
We often use the terms evidence and likelihood when referring to the conditional 
probability on the right-hand side of Bayes’ theorem. In the sample problem, the 
probability of beating the market, assuming that the manager was a star, P[3B | S] = 
27/64, was the likelihood. In other words, the likelihood of the manager beating the 
market three times, assuming that the manager was a star, was 27/64. 
	
posterior
prior
likelihood
P[S  3B] =
P[3B]
P[3B  S]P[S]

(6.7)
Bayes versus Frequentists
Pretend that as an analyst you are given daily profit data for a fund, and that the 
fund has had positive returns for 560 of the past 1,000 trading days. What is the 
probability that the fund will generate a positive return tomorrow? Without any 
further instructions, it is tempting to say that the probability is 56%, (560/1,000 = 
56%). In the previous sample problem, though, we were presented with a portfolio 
manager who beat the market three years in a row. Shouldn’t we have concluded 
that the probability that the portfolio manager would beat the market the following 
year was 100% (3/3 = 100%), and not 60%? How can both answers be correct?
The last approach, taking three out of three positive results and concluding that 
the probability of a positive result next year is 100%, is known as the frequentist 
approach. The conclusion is based only on the observed frequency of positive results. 
Prior to this chapter we had been using the frequentist approach to calculate prob-
abilities and other parameters.
The Bayesian approach, which we have been exploring in this chapter, also 
counts the number of positive results. The conclusion is different because the Bayes-
ian approach starts with a prior belief about the probability.
Which approach is better? It’s hard to say. Within the statistics community there 
are those who believe that the frequentist approach is always correct. On the other end 
of the spectrum, there are those who believe the Bayesian approach is always superior. 
Proponents of Bayesian analysis often point to the absurdity of the frequentist 
approach when applied to small data sets. Observing three out of three positive 
results and concluding that the probability of a positive result next year is 100% 
suggests that we are absolutely certain and that there is absolutely no possibility of 
a negative result. Clearly this certainty is unjustified.
Proponents of the frequentist approach often point to the arbitrariness of 
Bayesian priors. In the portfolio manager example, we started our analysis with the 
assumption that 16% of managers were stars. In a previous example we assumed 

120
Mathematics and Statistics for Financial Risk Management
that there was a 90% probability that a coin was fair. How did we arrive at these 
priors? In most cases the prior is either subjective or based on frequentist analysis. 
Perhaps unsurprisingly, most practitioners tend to take a more balanced view, 
realizing that there are situations that lend themselves to frequentist analysis and 
others that lend themselves to Bayesian analysis. Situations in which there is very 
little data, or in which the signal-to-noise ratio is extremely low, often lend them-
selves to Bayesian analysis. When we have lots of data, the conclusions of frequentist 
analysis and Bayesian analysis are often very similar, and the frequentist results are 
often easier to calculate. 
In the example with the portfolio manager, we had only three data points. Using 
the Bayesian approach for this problem made sense. In the example where we had 
1,000 data points, most practitioners would probably utilize frequentist analysis. 
In risk management, performance analysis and stress testing are examples of areas 
where we often have very little data, and the data we do have is very noisy. These 
areas are likely to lend themselves to Bayesian analysis. 
Many-State Problems
In the two previous sample problems, each variable could exist in only one of two 
states: a person either had the disease or did not have the disease; a manager was 
either a star or a nonstar. We can easily extend Bayesian analysis to any number of 
possible outcomes. For example, suppose rather than stars and nonstars, we believe 
there are three types of managers: underperformers, in-line performers, and out-
performers. The underperformers beat the market only 25% of the time, the in-line 
performers beat the market 50% of the time, and the outperformers beat the market 
75% of the time. Initially we believe that a given manager is most likely to be an in-
line performer, and is less likely to be an underperformer or an outperformer. More 
specifically, our prior belief is that a manager has a 60% probability of being an 
in-line performer, a 20% chance of being an underperformer, and a 20% chance of 
being an outperformer. We can summarize this as:
	
P p
P p
P p
[
.
]
%
[
.
]
%
[
.
]
%
=
=
=
=
=
=
0 25
20
0 50
60
0 75
20

(6.8)
Now suppose the manager beats the market two years in a row. What should 
our updated beliefs be? We start by calculating the likelihoods, the probability of 
beating the market two years in a row, for each type of manager:
	
P
B p
P
B p
P
B p
[2
|
0.25]
1
4
1
16
[2
|
0.50]
1
2
1
4
4
16
[2
|
0.75]
3
4
9
16
2
2
2
=
=
=
=
=
=
=
=
=
=

(6.9)

Bayesian Analysis
121
The unconditional probability of observing the manager beat the market two 
years in a row, given our prior beliefs about p, is:
	
P
B
P
B
[
]
%
%
%
[
]
2
20
1
16
60
4
16
20
9
16
2
2
10
1
16
6
10
4
=
+
+
=
+
16
2
10
9
16
44
160
27 5
+
=
=
. %

(6.10)
Putting this all together and using Bayes’ theorem, we can calculate our posterior 
belief that the manager is an underperformer:
	
P p
B
P
B p
P p
P
B
[
0.25 | 2 ]
[2
|
0.25] [
0.25]
[2 ]
1
16
2
10
44
160
2
44
1
22
4.55%
=
=
=
=
=
=
=
=
 (6.11)
Similarly, we can show that the posterior probability that the manager is an in-line 
performer is 54.55%: 
	 P p
B
P
B p
P p
P
B
[
0.50 | 2 ]
[2
|
0.50] [
0.50]
[2 ]
4
16
6
10
44
160
24
44
12
22
54.55%
=
=
=
=
=
=
=
=
 (6.12)
and that the posterior probability that the manager is an outperformer is 40.91%:
	 P p
B
P
B p
P p
P
B
[
0.75 | 2 ]
[2
|
0.75] [
0.75]
[2 ]
9
16
2
10
44
160
18
44
9
22
40.91%
=
=
=
=
=
=
=
=
 (6.13)
As we would expect, given that the manager beat the market two years in a 
row, the posterior probability that the manager is an outperformer has increased, 
from 20% to 40.91%, and the posterior probability that the manager is an under-
performer has decreased, from 20% to 4.55%. Even though the probabilities have 
changed, the sum of the probabilities is still equal to 100% (the percentages seem to 
add to 100.01%, but that is only a rounding error):
	
1
22
12
22
9
22
22
22
1
+
+
=
=

(6.14)
At this point it is worth noting a useful shortcut. Notice that for each type of 
manager, the posterior probability was calculated as:
	
P p
x
B
P
B p
x P p
x
P
B
[
|
]
|
[
]
[
]
=
=
=
[
]
=
2
2
2

(6.15)
In each case, the denominator on the right-hand side is the same, P[2B], or 44/160. 
We can then rewrite this equation in terms of a constant, c:
	
P p
x
B
c P
B p
x P p
x
[
|
]
[
|
] [
]
=
=
=
=
⋅
2
2

(6.16)

122
Mathematics and Statistics for Financial Risk Management
We also know that the sum of all the posterior probabilities must equal one:
	
c P
B p
x P p
x
c
P
B p
x P p
x
i
i
i
i
i
⋅
=
=
=
=
=
=
=
[
|
] [
]
[
|
] [
]
2
2
1
1
3
1
3
∑
∑
=
i

(6.17)
In our current example we have:
	
c
c
c
1
16
2
10
4
16
6
10
9
16
2
10
2
24
18
160
44
+
+
=
+
+
=
160
1
160
44
=
=
c

(6.18)
We then use this to calculate each of the posterior probabilities. For example, the 
posterior probability that the manager is an underperformer is:
	
P p
B
c P
B p
P p
[
.
|
]
[
|
.
] [
.
]
=
=
=
=
=
⋅
0 25 2
2
0 25
0 25
160
44
1
16
2
10
2
44
1
22
=
=
 (6.19)
In the current example this might not seem like much of a shortcut, but, as we 
will see, with continuous distributions this approach can make seemingly intractable 
problems very easy to solve. 
Sample Problem
Question:
Using the same prior distributions as in the preceding example, what would 
the posterior probabilities be for an underperformer, an in-line performer, or an 
outperformer if instead of beating the market two years in a row, the manager 
beat the market in 6 of the next 10 years?
Answer:
For each possible type of manager, the likelihood of beating the market 
6 times out of 10 can be determined using a binomial distribution (see Chapter 4):
P
B
p
p
p
[
|
(
]
)
6
10
6
1
4
6
=
−
Using our shortcut, we first calculate the posterior probabilities in terms of an 
arbitrary constant, c. If the manager is an underperformer:
P p
B
c P
B p
P p
P p
[
.
|
]
[
|
.
]
.
[
]
[
.
=
=
=
=
=
⋅
⋅
0 25 6
6
0 25
0 25
0 25 6
10
6
1
4
3
4
2
10
4
6
|
]
[
c
B
P
=
⋅
⋅
p
B
p
c
=
=
⋅
⋅
0 25 6
10
6
2 3
10 4
4
10
.
|
]

Bayesian Analysis
123
Similarly, if the manager is an in-line performer or outperformer, we have:
P p
c
B
P p
[
.
|
]
[
.
|
=
=
=
⋅
⋅
0 50 6
10
6
6 2
10 4
0 75
10
10
6
10
6
2 3
10 4
6
10
B
c
] =
⋅
⋅
Because all of the posterior probabilities sum to one, we have:
P p
B
P p
B
P p
B
c
[
.
]
[
.
]
[
.
]
=
+
=
+
=
=
0 25 6
0 50 6
0 75 6
1
10
6
+
+
=
⋅
⋅
⋅
⋅
2 3
10 4
3
2
1
3
10
6
2 3
10
10
3
10
5)
(
c
4
1 294
1
1
10
6
10 4
2 3
1
1 294
10
10
,
,
=
=
⋅
⋅
c
This may look unwieldy, but, as we will see, many of the terms will cancel out 
before we arrive at the final answers. Substituting back into the equations for 
the posterior probabilities, we have:
P p
B
c
[
.
|
]
,
=
=
=
=
⋅
⋅
0 25 6
10
6
2 3
10 4
3
1 294
2
4
10
3
7
1 294
2 09
0 50 6
10
6
6 2
10
10
,
%
.
[
.
|
]
=
=
=
⋅
P p
B
c
⋅
=
=
=
=
4
2
1 294
1 024
1 294
79 13
0 75 6
10
10
,
,
,
%
.
[
.
|
P p
B]
,
,
=
=
=
=
⋅
⋅
c 10
6
2 3
10 4
3
1 294
243
1 294
18
6
10
5
.
%
.78
In this case, the probability that the manager is an in-line performer has 
increased from 60% to 79.13%. The probability that the manager is an out-
performer decreased slightly from 20% to 18.78%. It now seems very unlikely 
that the manager is an underperformer (2.09% probability compared to our 
prior belief of 20%).
While the calculations looked rather complicated, using our shortcut saved 
us from actually having to calculate many of the more complicated terms. For 
more complex problems, and especially for problems involving continuous dis-
tributions, this shortcut can be extremely useful.

124
Mathematics and Statistics for Financial Risk Management
This sample problem involved three possible states. The basic approach 
for solving a problem with four, five, or any finite number of states is exactly 
the same, only the number of calculations increases. The end-of-chapter prob-
lems include one question with four possible states. Because the calculations are 
­highly repetitive, it is often much easier to solve these problems using a spread-
sheet or computer program. The online content includes an example involving 
11 ­possible states. 
Continuous Distributions
In the limit, as we increase the number of possible states, our prior and posterior dis-
tributions converge to continuous distributions. Our fundamental equation, Bayes’ 
theorem, remains the same, only now the prior and posterior probabilities are re-
placed with prior and posterior probability density functions (PDFs):
	
P A B
P B A P A
P B
f A B
g B A f A
g B
[
|
]
[
|
] [ ]
[ ]
(
|
)
(
|
) ( )
(
|
=
→
=
A f A dA
) ( )
−∞
+∞
∫

(6.20)
Here f(A) is the prior probability density function, and f(A | B) is the pos-
terior PDF. g(B | A) is the likelihood. We can also mix discrete and continuous 
distributions. If the prior distribution is continuous, then the posterior distribu-
tion will almost always be continuous, but the likelihood can easily be discrete or 
continuous. Finally, the integral in the denominator represents the unconditional 
probability of B, P[B]. Calculating P[B] through integration is analogous to how 
we calculated P[B] for a discrete distribution by summing across all of the pos-
sible states.
Just as we did for the discrete case, we can rewrite Equation 6.20 using our 
shortcut from the previous section. For a constant, c, it must be true that:
	
f A B
c g B A f A
(
|
)
(
|
) ( )
= ⋅

(6.21)
For a discrete posterior distribution, it is necessary that all of the possible pos-
terior distributions sum to one. In the continuous case, the analogous requirement is 
that the integral of the posterior PDF over the relevant range be equal to one:
	
f A B dA
(
|
)
=
−∞
+∞
∫
1 
(6.22)
In other words, we require that the posterior distribution be a proper distribution. 
Substituting Equation 6.21 into Equation 6.22, we have:
	
c
g B A f A dA
(
|
) ( )
=
−∞
+∞
∫
1 
(6.23)
We will put this result to use in the following sample problem. 

Bayesian Analysis
125
Sample Problem
Question:
As in the preceding sample problem, assume that we observe a portfolio 
manager beat the market in 6 out of 10 years. Instead of assuming that there 
are two or three types of managers, though, we assume that the manager can 
beat the market anywhere between 0% and 100% of the time. Prior to observ-
ing the manager, we believed that the manager was equally likely to be any-
where between 0% and 100%. That is, our prior distribution was a uniform 
distribution between 0% and 100%. Our PDF, f(p), is:
f p
p
( )
  
=
≤
≤
1 0
1
What is the posterior distribution after observing the manager beat the market 
in 6 out of 10 years?
Answer:
As in the preceding sample problem, the likelihood is described by a bino-
mial distribution:
g
B
p
p
p
(
|
(
)
)
6
10
6
1
4
6
=
−
In the preceding equation and what follows, we assume 0 ≤ p ≤ 1. For a con-
stant, c, the posterior probability density function is then:
f p
B
c g
B p f p
f p
c
B
p
( |
)
(
| )
)
(
( |
(
)
6
6
6
10
6
6
=
=
⋅
⋅
1
1
1
6
10
6
1
4
4
6
−
=
−
⋅
⋅
p
f p
c
B
p
p
)
( |
(
)
)
Next, we note that the number of combinations is independent of p. 
­Because of this, we can rewrite the posterior distribution in terms of a new 
constant, k:
f p
B
k p
p
k
c
( |
)
(
)    
6
1
10
6
6
4
=
−
= ⋅
⋅
where
The next step is the tricky part. Remember from Chapter 4 that the PDF 
for the beta distribution can be written as:
β( ; , )
( , )
(
)
 
p a b
B a b p
p
p
a
b
=
−
≤
≤
−
−
1
1
0
1
1
1

126
Mathematics and Statistics for Financial Risk Management
Both our posterior distribution and the beta distribution are nonzero from 
zero to one, and, because they are distributions, the integral of their PDFs over 
this range must be equal to one:
k p
p dp
B a b p
p
dp
a
b
⋅
−
=
=
−
−
−
∫
∫
6
4
1
1
0
1
0
1
1
1
1
1
(
)
( , )
(
)
Taking the constants out of the integrals and rewriting the exponents, we 
have:
k
p
p
dp
B a b
p
p
dp
a
b
7 1
5 1
1
1
0
1
0
1
1
1
1
−
−
−
−
−
=
−
∫
∫
(
)
( , )
(
)
If we set a equal to 7 and b equal to 5, it is clear that k must equal 1/B(7,5) 
in order for the two sides of the equation to be equal. Replacing k in our previ-
ous equation for the posterior distribution, we arrive at our final answer. The 
posterior distribution of our beliefs after seeing the manager beat the market in 
6 out of 10 years is a beta distribution, β(p; 7,5):
f p
B
B
p
p
( |
)
( , )
(
)
6
1
7 5
1
6
4
=
−
The prior and posterior distributions are shown in Exhibit 6.2.
0
1
2
3
0
.
1
5
.
0
0
.
0
U(0,1)
Beta(x; 7,5)
Exhibit 6.2 
Prior and Posterior Distributions
The posterior distribution has a mode of 0.60 and a mean of 0.58. Extreme 
values (below 0.2 and above 0.9) are very unlikely for the posterior distribution. 

Bayesian Analysis
127
Sample Problem
Question:
As in the previous sample problem, assume we are observing a portfo-
lio manager whose probability of beating the market can range from 0% to 
100%. Instead of believing that all probabilities are equally likely, though, our 
prior distribution puts more weight on probabilities closer to 50%. More spe-
cifically, our prior distribution is a beta distribution, β(x; 2,2), as depicted in 
Exhibit 6.3. After 20 years, the portfolio manager has beaten the market only 
9 times. What is the posterior distribution for the portfolio manager?
Answer:
Even though the problem seems complex, almost no calculation is required 
in this case. Adding the number of successes, 9, to the first parameter, and the 
number of failures, 11, to the second parameter, we arrive at our final answer, 
a posterior distribution of β(x; 11,13).
0
1
2
3
4
0.0
0.5
1.0
Beta(x; 2,2)
Beta(x; 11,13)
Exhibit 6.3 
Beta Distribution
Remember from Chapter 4 that the uniform distribution is a special case of the beta 
distribution, where both parameters, a and b, are equal to one. In the sample problem, 
then, both the prior and posterior distributions are beta distributions. This is not a co­
incidence. In general, if the prior distribution is a beta distribution and the likelihood 
­function follows a binomial distribution, then the posterior distribution will be a beta 
distribution. More precisely, if we start with a beta distribution β(x; a,b) and then observe 
n trials, of which k are successful and (n − k) are unsuccessful, the posterior ­distribution 
will be β(x; a + k, b + n − k). We simply add the number of successful trials to the first pa-
rameter of the beta distribution and add the number of unsuccessful trials to the second.

128
Mathematics and Statistics for Financial Risk Management
It is not always the case that the prior and posterior distributions are of the 
same type. When both the prior and posterior distributions are of the same type, 
we say that they are conjugate distributions. As we just saw, the beta distribution is 
the conjugate distribution for the binomial likelihood distribution. Here is another 
useful set of conjugates: The normal distribution is the conjugate distribution for the 
normal likelihood when we are trying to estimate the distribution of the mean, and 
the variance is known.
Conjugate distributions are extremely easy to work with and make calculating 
posterior distributions very simple. This latter fact was extremely appealing before 
the widespread use of computers. Unfortunately, real-world problems need not in-
volve conjugate distributions. The real world is not obligated to make our statistical 
calculations easy. In practice, prior and posterior distributions may be nonparamet-
ric and require numerical methods to solve. While all of this makes Bayesian analysis 
involving continuous distributions more complex, these are problems that are easily 
solved by computers. One reason for the increasing popularity of Bayesian analysis 
has to do with the rapidly increasing power of computers in recent decades.
Bayesian Networks
A Bayesian network illustrates the causal relationship between different random 
variables. Exhibit 6.4 shows a Bayesian network with two nodes that represent the 
economy, E, and a stock, S. The arrow between them indicates that E causes S. If the 
arrow were pointing the other way, then the relationship would be reversed, with S 
causing E.
In this simple example, both E and S are discrete random variables, which can 
be either up or down. Exhibit 6.4 also shows three probabilities: the probability that 
E is up, P[E]; the probability that S is up given that E is up, P S E
[ |
]; and the prob-
ability that S is up given that E is not up, P S E
[ |
]. Three other probabilities, P E
[ ], 
P S E
[
|
], and P S E
[
|
], can easily be determined using the first three probabilities. For 
example, P E
[ ], the probability that E is not up, is just 1−P E
[ ], or 50%. Similarly, 
P S E
[
|
]
%,
= 20
 and P S E
[
|
]
%.
= 75
As expected, the posterior distribution has a mean and median below 50%, 
and the most extreme probabilities are even less likely than they were prior to 
the observations.
Exhibit 6.4 
Bayesian Network with Two Nodes
S
E
P[E] = 50%
P[S|E] = 80%
P[S| ] = 25%
E

Bayesian Analysis
129
Using Bayes’ theorem, we can also calculate P E S
[
| ]. This is the probability that 
E is up given that we have observed S being up:
	
P E S
P S E P E
P S
P S E P E
P S E P E
[
| ]
[ |
] [ ]
[ ]
[ |
] [ ]
[ |
] [ ]
=
=
+ P S E P E
[ |
] [ ]

(6.24)
P E S
[
| ] is the reverse probability of P S E
[ |
]. Even though we can easily calculate 
both P S E
[ |
] and P E S
[
| ], most people find the concept of P E S
[
| ], the reverse prob-
ability, to be less intuitive. This is because human brains are wired to move from 
causes to effects, and not the other way around. If we believe that the state of the 
economy determines the performance of stocks, then it seems much more logical to 
ask, “What is the probability that the stock will be up, given that the economy is 
up?” It seems strange to ask the reverse, “What is the probability that the economy 
was up, given that the stock is up?” Our hunter-gatherer ancestors were more likely 
to ask, “What is the probability that the woolly mammoth will die if I hit it with a 
spear?” than to ask, “What is the probability that I hit the woolly mammoth with a 
spear, given that it is dead?” In Bayesian statistics we refer to these two alternative 
modes of evaluating a network as causal reasoning and diagnostic reasoning. Causal 
reasoning, P S E
[ |
], follows the cause-and-effect arrow of our Bayesian network. Di-
agnostic reasoning, P E S
[
| ], works in reverse.
For most people, causal reasoning is much more intuitive than diagnostic rea-
soning. Diagnostic reasoning is one reason why people often find Bayesian logic to 
be confusing. Bayesian networks do not eliminate this problem, but they do implic-
itly model cause and effect, allowing us to differentiate easily between causal and 
diagnostic relationships. 
Bayesian networks are extremely flexible. Exhibit 6.5 shows a network with 
­seven nodes. Nodes can have multiple inputs and multiple outputs. For example, node 
B influences both nodes D and E, and node F is influenced by both nodes C and D.
In a network with n nodes, where each node can be in one of two states (for 
example, up or down), there are a total of 2n possible states for the network. As we 
will see, an advantage of Bayesian networks is that we will rarely have to specify 2n 
probabilities in order to define the network. For example, in Exhibit 6.4 with two 
nodes, there are four possible states for the network, but we only had to define three 
probabilities.
C
A
D
B
E
F
G
Exhibit 6.5 
Bayesian Network with Seven Nodes

130
Mathematics and Statistics for Financial Risk Management
Bayesian Networks versus Correlation Matrices
Exhibit 6.6 shows two networks, each with three nodes. In each network E is the 
economy and S1 and S2 are two stocks. In the first network, on the left, S1 and S2 
are directly influenced by the economy. In the second network, on the right, S1 is 
still directly influenced by the economy, but S2 is only indirectly influenced by the 
economy, being directly influenced only by S1. In the first example, we might imagine 
that S1 and S2 represent the stocks of large, diverse corporations whose performance 
is largely determined by the state of the economy. In the second example, we might 
imagine that S1 is still the stock of a large, diverse company, but that S2 is now the 
stock of a supplier whose largest customer is S1. In the second network, S2 is still 
influenced by E, but the influence is indirect.
For each network in Exhibit 6.6 there are eight possible states: 23 = 8. Given 
the probabilities supplied, we can figure out the entire joint distribution for each 
network; that is, we can figure out the probability of each state. For example, in the 
first network, the probability of E, S1, and S2 all occurring is 25.20%:
	
P E S
S
P E P S
E P S
E
[ ,
,
]
[ ] [
|
] [
|
]
%
%
%
1
2
1
2
60
70
60
2
=
=
=
⋅
⋅
5 20
.
%
(6.25)
Exhibit 6.7 shows all eight probabilities for both networks. In the table, the 
occurrence of an event is signified by a 1, and an event not occurring by a 0. For 
example, the probability of E, S1, and S2 occurring, P[E,S1,S2], can be found in 
the last row of the table where E, S1, and S2 are all equal to 1. You should check 
all of the remaining values in the table to ensure that you understand how they are 
calculated.
As with any random variable, we can calculate the mean, standard deviation, 
and variance of E, S1, and S2. Also, because we know the joint distribution of all 
three variables, we can calculate their covariances and correlations as well. For ex-
ample, the mean of S1 in both networks is 50%:
	
E S
E S
E P E
E S
E P E
E S
[
]
[
|
] [ ]
[
|
] [ ]
[
]
%
%
1
1
1
1
70
60
=
+
=
+
⋅
20
1
60
1
50
% (
%)
[
]
%
⋅
−
=
E S

(6.26)
S2
S1
E
P[E] = 60%
P[S1|E] = 70%
P[S1| ] = 20%
P[S2|E] = 50%
P[S2| ] = 35%
E
S1
S2
P[E] = 60%
P[S1|E] = 70%
P[S1| ] = 20%
P[S2|E] = 60%
P[S2| ] = 40%
E
E
E
E
Exhibit 6.6 
Two Bayesian Networks with Three Nodes Each

Bayesian Analysis
131
Sample Problem
Question:
Using the probabilities for the first network in Exhibit 6.6, calculate the 
covariance between E and S1.
Answer:
Using our equation for covariance from Chapter 3, the covariance of E 
and S1 is:
σ E S
E E
E E
S
E S
E E S
E E E S
,
[(
[ ])(
[
])]
[
]
[ ] [
1
1
1
1
=
−
−
=
−
⋅
1]
We already know E[S1] from Equation 6.26. We could calculate E[E] in 
a similar fashion. Alternatively, we could read the values and probabilities 
straight from the joint probability distribution in Exhibit 6.7. The equation is 
longer, but the process is more mechanical and much easier to automate:
E E
[ ]
.
%
.
%
.
%
.
%
.
=
+
+
+
+
⋅
⋅
⋅
⋅
19 20
0
12 80
0
4 80
0
3 20
0
7 20%
%
.
%
.
%
.
%
[ ]
.
%
⋅
⋅
⋅
⋅
+
+
+
=
+
1
10 80
1
16 80
1
25 20
1
7 20
1
E E
0 80
16 80
25 20
60
.
%
.
%
.
%
[ ]
%
+
+
=
E E
In the second line of the preceding equation, we see that calculating E[E] 
is equivalent to adding up all the probabilities in Exhibit 6.7 where E is equal 
to 1. We can calculate E[E  ∙  S1] in a similar fashion. E  ∙  S1 is equal to 1 only 
if both E and S are equal to 1, which is true for only the last two lines of 
­Exhibit 6.7. Therefore:
E E S
[
]
.
%
.
%
.
%
⋅
=
+
=
1
16 80
25 20
42 00
Putting this all together, we have our final answer:
σE S
E E S
E E E S
,
[
]
[ ] [
]
.
%
.
%
.
1
1
1
42 00
60 00
50 00
=
−
=
−
⋅
⋅
%
.
%
= 12 00
Exhibit 6.7 
Probabilities of Networks
E
S1
S2
Network 1
Network 2
0
0
0
19.20%
20.80%
0
0
1
12.80%
11.20%
0
1
0
4.80%
4.00%
0
1
1
3.20%
4.00%
1
0
0
7.20%
11.70%
1
0
1
10.80%
6.30%
1
1
0
16.80%
21.00%
1
1
1
25.20%
21.00%
100.00%
100.00%

132
Mathematics and Statistics for Financial Risk Management
The complete covariance matrices are provided in Exhibit 6.8. Calculating these 
covariance matrices and the corresponding correlation matrices is left as an exercise 
at the end of the chapter.
Not surprisingly, given the similarity of the Bayesian networks from which they 
were derived, the covariance matrices are very similar to each other. E, S1, and S2 are 
all positively correlated with each other in both cases. 
One advantage of Bayesian networks is that they can be specified with very few 
parameters, relative to other approaches. In the preceding example, we were able to 
specify each network using only five probabilities, but each covariance matrix con-
tains six nontrivial entries, and the joint probability table, Exhibit 6.7, contains eight 
entries for each network. As networks grow in size, this advantage tends to become 
even more dramatic.
Another advantage of Bayesian networks is that they are more intuitive. It is 
hard to have much intuition for entries in a covariance matrix or a joint probability 
table. Given the scenarios described in this example, it makes sense that the entries in 
the covariance matrices are positive, but beyond that it is difficult to say much. What 
if we were worried that we had accidentally reversed the data for the two networks? 
An equity analyst covering the two companies represented by S1 and S2 might be 
able to look at the Bayesian networks and say that the linkages and probabilities 
seem reasonable, but the analyst is unlikely to be able to say the same about the two 
covariance matrices.
Because Bayesian networks are more intuitive, they might be easier to update in 
the face of a structural change or regime change. In the second network, where we 
have described S2 as being a supplier to S1, suppose that S2 announces that it has 
signed a contract to supply another large firm, thereby making it less reliant on S1? 
With the help of our equity analyst, we might be able to update the Bayesian network 
immediately (for example, by decreasing the probabilities P S
S
[
|
]
2
1  and P S
S
[
|
]
2
1 ), 
but it is not as obvious how we would directly update the covariance matrices.
Problems
	 1.	The probability that gross domestic product (GDP) decreases is 20%. The prob-
ability that unemployment increases is 10%. The probability that unemploy-
ment increases given that GDP has decreased is 40%. What is the probability 
that GDP decreases given that unemployment has increased?
	 2.	An analyst develops a model for forecasting bond defaults. The model is 90% 
accurate. In other words, of the bonds that actually default, the model identifies 
Exhibit 6.8 
Covariance Matrices
Network 1
Network 2
E
S1
S2
E
S1
S2
E
24%
12%
5%
E
24%
12%
2%
S1
12%
25%
2%
S1
12%
25%
4%
S2
5%
2%
25%
S2
2%
4%
24%

Bayesian Analysis
133
90% of them; likewise, of the bonds that do not default, the model correctly pre-
dicts that 90% will not default. You have a portfolio of bonds, each with a 5% 
probability of defaulting. Given that the model predicts that a bond will default, 
what is the probability that it actually defaults?
	 3.	As a risk analyst, you are asked to look at EB Corporation, which has issued 
both equity and bonds. The bonds can either be downgraded, be upgraded, or 
have no change in rating. The stock can either outperform the market or un-
derperform the market. You are given the following probability matrix from an 
analyst who had worked on the company previously, but some of the values are 
missing. Fill in the missing values. What is the conditional probability that the 
bonds are downgraded given that the equity has underperformed?
Equity
Outperform
Underperform
Bonds
Upgrade
W
5%
15%
No Change
45%
X
65%
Downgrade
Y
15%
Z
60%
40%
	 4.	Your firm is testing a new quantitative strategy. The analyst who developed the 
strategy claims that there is a 55% probability that the strategy will generate 
positive returns on any given day. After 20 days the strategy has generated a 
profit only 10 times. What is the probability that the analyst is right and the 
actual probability of positive returns for the strategy is 55%? Assume that there 
are only two possible states of the world: Either the analyst is correct, or there 
the strategy is equally likely to gain or lose money on any given day. Your prior 
assumption was that these two states of the world were equally likely. 
	 5.	Your firm has created two equity baskets. One is procyclical, and the other is 
countercyclical. The procyclical basket has a 75% probability of being up in 
years when the economy is up, and a 25% probability of being up when the 
economy is down or flat. The probability of the economy being down or flat in 
any given year is only 20%. Given that the procyclical index is up, what is the 
probability that the economy is also up?
	 6.	You are an analyst at Astra Fund of Funds, but instead of believing that there 
are two or three types of portfolio managers, your latest model classifies man-
agers into four categories. Managers can be underperformers, in-line perform-
ers, stars, or superstars. In any given year, these managers have a 40%, 50%, 
60%, and 80% chance of beating the market, respectively. In general, you be-
lieve that managers are equally likely to be any one of the four types of manag-
ers. After observing a manager beat the market in three out of five years, what 
do you believe the probability is that the manager belongs in each of the four 
categories?
	 7.	You have a model that classifies Federal Reserve statements as either bullish or 
bearish. When the Fed makes a bullish announcement, you expect the market to 
be up 75% of the time. The market is just as likely to be up as it is to be down 

134
Mathematics and Statistics for Financial Risk Management
or flat, but the Fed makes bullish announcements 60% of the time. What is the 
probability that the Fed made a bearish announcement, given that the market 
was up?
	 8.	You are monitoring a new strategy. Initially, you believed that the strategy was 
just as likely to be up as it was to be down or flat on any given day, and that the 
probability of being up was fairly close to 50%. More specifically, your initial 
assumption was that the probability of being up, p, could be described by a beta 
distribution, β(4,4). Over the past 100 days, the strategy has been up 60 times. 
What is your new estimate for the distribution of the parameter p? What is the 
probability that the strategy will be up the next day?
	 9.	For the Bayesian network in Exhibit 6.9, each node can be in one of three states: 
up, down, or no change. How many possible states are there for the entire net-
work? What is the minimum number of probabilities needed to completely de-
fine the network?
C
A
B
Exhibit 6.9 
Three-State Network
	10.	Calculate the correlation matrix for Network 1, the network on the left, in Ex-
hibit 6.6. Start by calculating the covariance matrix for the network.
	11.	Calculate the correlation matrix for Network 2, the network on the right, in 
Exhibit 6.6. Start by calculating the covariance matrix for the network.

135
Chapter 7
Hypothesis Testing and 
Confidence Intervals
I
n this chapter we explore two closely related topics, confidence intervals and hy-
pothesis testing. At the end of the chapter, we explore applications, including value 
at risk (VaR).
Sample Mean Revisited
Imagine taking the output from a standard random number generator on a com-
puter, and multiply it by 100. The resulting data-generating process (DGP) is a 
uniform random variable, which ranges between 0 and 100, with a mean of 50. 
If we generate 20 draws from this DGP and calculate the sample mean of those 
20 draws, it is unlikely that the sample mean will be exactly 50. The sample mean 
might round to 50, say 50.03906724, but exactly 50 is next to impossible. In fact, 
given that we have only 20 data points, the sample mean might not even be close 
to the true mean.
The sample mean is actually a random variable itself. If we continue to repeat 
the experiment—generating 20 data points and calculating the sample mean each 
time—the calculated sample mean will be different every time. As we proved in 
Chapter 3, even though we never get exactly 50, the expected value of each sample 
mean is in fact 50. It might sound strange to say it, but the mean of our sample mean 
is the true mean of the distribution. Using our standard notation:
	
E[ ˆ ]
µ
µ
=

(7.1)
If instead of 20 data points, what if we generate 1,000 data points? With 
1,000 data points, the expected value of our sample mean is still 50, just as it was 
with 20 data points. While we still don’t expect our sample mean to be exactly 50, 
our sample mean will tend to be closer when we are using 1,000 data points. The 
reason is simple: A single outlier won’t have nearly the impact in a pool of 1,000 
data points that it will in a pool of 20. If we continue to generate sets of 1,000 
data points, it stands to reason that the standard deviation of our sample mean 
will be lower with 1,000 data points than it would be if our sets contained only 
20 data points.
It turns out that the variance of our sample mean doesn’t just decrease with the 
sample size; it decreases in a predictable way, in proportion to the sample size. If 

136
Mathematics and Statistics for Financial Risk Management
our sample size is n and the true variance of our DGP is σ2, then the variance of the 
sample mean is:
	
σ
σ
µˆ
2
2
= n

(7.2)
It follows that the standard deviation of the sample mean decreases with the 
square root of n. This square root is important. In order to reduce the standard devi-
ation of the mean by a factor of 2, we need 4 times as many data points. To reduce it 
by a factor of 10, we need 100 times as much data. This is yet another example of the 
famous square root rule for independent and identically distributed (i.i.d.) variables.
In our current example, because the DGP follows a uniform distribution, we can 
easily calculate the variance of each data point using Equation 4.4. The variance of 
each data point is 833.33, (100 – 0)2/12 = 833.33. This is equivalent to a standard 
deviation of 28.87. For 20 data points, the standard deviation of the mean will 
then be 28 87
20
6 45
.
/
.
,
=
 and for 1,000 data points, the standard deviation will 
be 28 87
1 000
0 91
.
/
,
.
.
=
We have the mean and the standard deviation of our sample mean, but what 
about the shape of the distribution? You might think that the shape of the distribu-
tion would depend on the shape of the underlying distribution of the DGP. If we 
recast our formula for the sample mean slightly, though:
	
ˆµ =
=
=
=
∑
∑
1
1
1
1
n
x
n x
i
i
i
n
i
n

(7.3)
and regard each of the (1/n)xi’s as a random variable in its own right, we see that 
our sample mean is equivalent to the sum of n i.i.d. random variables, each with a 
mean of µ/n and a standard deviation of σ/n. Using the central limit theorem, we 
claim that the distribution of the sample mean converges to a normal distribution. 
For large values of n, the distribution of the sample mean will be extremely close to 
a normal distribution. Practitioners will often assume that the sample mean is nor-
mally distributed.
Sample Problem
Question:
You are given 10 years of monthly returns for a portfolio manager. The 
mean monthly return is 2.3%, and the standard deviation of the return series 
is 3.6%. What is the standard deviation of the mean?
The portfolio manager is being compared against a benchmark with a 
mean monthly return of 1.5%. What is the probability that the portfolio man-
ager’s mean return exceeds the benchmark? Assume the sample mean is nor-
mally distributed.

Hypothesis Testing and Confidence Intervals
137
Sample Variance Revisited
Just as with the sample mean, we can treat the sample variance as a random variable. 
For a given DGP if we repeatedly calculate the sample variance, the expected value 
of the sample variance will equal the true variance, and the variance of the sample 
variance will equal:
	
E
n
ex
n
[( ˆ
) ]
σ
σ
σ
κ
2
2 2
4
2
1
=
−
−
+

(7.4)
where n is the sample size, and κ ex is the excess kurtosis.
If the DGP has a normal distribution, then we can also say something about the 
shape of the distribution of the sample variance. If we have n sample points and ˆσ 2 
is the sample variance, then our estimator will follow a chi-squared distribution with 
(n − 1) degrees of freedom:
	
(
) ˆ
n
n
−
−
1
2
2
1
2
σ
σ
χ
∼

(7.5)
where σ2 is the population variance. Note that this is true only when the DGP has a 
normal distribution. Unfortunately, unlike the case of the sample mean, we cannot 
apply the central limit theorem here. Even when the sample size is large, if the under-
lying distribution is nonnormal, the statistic in Equation 7.5 can vary significantly 
from a chi-squared distribution.
Confidence Intervals
In our discussion of the sample mean, we assumed that the standard deviation of the 
underlying distribution was known. In practice, the true standard deviation is likely 
to be unknown. At the same time we are measuring the sample mean, we will typi-
cally be measuring the sample variance as well.
Answer:
There is a total of 120 data points in the sample (10 years × 12 months per 
year). The standard deviation of the mean is then 0.33%:
σ
σ
µˆ
. %
.
%
=
=
=
n
3 6
120
0 33
The distance between the portfolio manager’s mean return and the bench-
mark is −2.43 standard deviations: (1.50% − 2.30%)/0.33% = −2.43. For a 
normal distribution, 99.25% of the distribution lies above −2.43 standard 
deviations, and only 0.75% lies below. The difference between the portfolio 
manager and the benchmark is highly significant.

138
Mathematics and Statistics for Financial Risk Management
It turns out that if we first standardize our estimate of the sample mean using the 
sample standard deviation, the new random variable follows a Student’s t distribu-
tion with (n − 1) degrees of freedom:
	
t
n
=
−
ˆ
ˆ /
µ
µ
σ

(7.6)
Here the numerator is simply the difference between the sample mean and the 
population mean, while the denominator is the sample standard deviation divided 
by the square root of the sample size. To see why this new variable follows a t dis-
tribution, we simply need to divide both the numerator and the denominator by 
the population standard deviation. This creates a standard normal variable in the 
numerator, and the square root of a chi-square variable in the denominator with the 
appropriate constant. We know from the previous chapter on distributions that this 
combination of random variables follows a t distribution. This standardized version 
of the population mean is so frequently used that it is referred to as a t-statistic, or 
simply a t-stat.
Technically, this result requires that the underlying distribution be normally 
distributed. As was the case with the sample variance, the denominator may not 
follow a chi-squared distribution if the underlying distribution is nonnormal. 
Oddly enough, for large sample sizes the overall t-statistic still converges to a 
t distribution. However, if the sample size is small and the data distribution is 
nonnormal, the t-statistic, as defined here, may not be well approximated by a t 
distribution.
By looking up the appropriate values for the t distribution, we can establish the 
probability that our t-statistic is contained within a certain range:
	
x
P
n
xU
L ≤
−
≤
=
ˆ
ˆ /
μ
μ
σ
γ 
(7.7)
where xL and xU are constants, which, respectively, define the lower and upper 
bounds of the range within the t distribution, and γ  is the probability that our 
t-statistic will be found within that range. Typically γ  is referred to as the confidence 
level. Rather than working directly with the confidence level, we often work with the 
quantity 1 – γ , which is known as the significance level and is often denoted by α. 
The smaller the confidence level is, the higher the significance level.
In practice, the population mean, µ, is often unknown. By rearranging the previ-
ous equation we come to an equation with a more interesting form:
	
P
x
n
x
n
U
L
ˆ
ˆ
ˆ
ˆ
μ
σ
μ
μ
σ
γ
≤
−
+
≤
=

(7.8)
Looked at this way, we are now giving the probability that the population mean 
will be contained within the defined range. When it is formulated this way, we call 
this range the confidence interval for the population mean. Confidence intervals are 
not limited to the population mean. Though it may not be as simple, in theory we 
can define a confidence level for any distribution parameter.

Hypothesis Testing and Confidence Intervals
139
Hypothesis Testing
One problem with confidence intervals is that they require us to settle on an arbi-
trary confidence level. While 95% and 99% are common choices for the confidence 
level in risk management, there is nothing sacred about these numbers. It would be 
perfectly legitimate to construct a 74.92% confidence interval. At the same time, we 
are often concerned with the probability that a certain variable exceeds a threshold. 
For example, given the observed returns of a mutual fund, what is the probability 
that the standard deviation of those returns is less than 20%?
In a sense, we want to turn the confidence interval around. Rather than saying 
there is an x% probability that the population mean is contained within a given in-
terval, we want to know what the probability is that the population mean is greater 
than y. When we pose the question this way, we are in the realm of hypothesis testing.
Traditionally the question is put in the form of a null hypothesis. If we are inter-
ested in knowing whether the expected return of a portfolio manager is greater than 
10%, we would write:
	
H
r
0
10
:
%
µ >

(7.9)
where H0 is known as the null hypothesis. Even though the true population mean is un-
known, for the hypothesis test we assume that the population mean is 10%. In effect, we 
are asking, if the true population mean is 10%, what is the probability that we would see 
a given sample mean? With our null hypothesis in hand, we gather our data, calculate the 
sample mean, and form the appropriate t-statistic. In this case, the appropriate t-statistic is:
	
t
n
=
−
µ
σ
10%
/

(7.10)
We can then look up the corresponding probability from the t distribution.
In addition to the null hypothesis, we can offer an alternative hypothesis. In the pre-
vious example, where our null hypothesis is that the expected return is greater than 10%, 
the logical alternative would be that the expected return is less than or equal to 10%:
	
H
r
1
10
:
%
µ ≤

(7.11)
In principle, we could test any number of hypotheses. In practice, as long as the 
alternative is trivial, we tend to limit ourselves to stating the null hypothesis.
Which Way to Test?
If we want to know if the expected return of a portfolio manager is greater than 
10%, the obvious statement of the null hypothesis might seem to be µr > 10%. 
But we could just have easily have started with the alternative hypothesis, that 
µr ≤ 10%. Finding that the first is true and finding that the second is false are logically 
equivalent.
Many practitioners construct the null hypothesis so that the desired result is 
false. If we are an investor trying to find good portfolio managers, then we would 
make the null hypothesis µr ≤ 10%. That we want the expected return to be greater 
than 10% but we are testing for the opposite makes us seem objective. Unfortunately, 
in the case where there is a high probability that the manager’s expected return is 

140
Mathematics and Statistics for Financial Risk Management
greater than 10% (a good result), we have to say, “We reject the null hypothesis that 
the manager’s expected return is less than or equal to 10% at the x% level.” This is 
very close to a double negative. Like a medical test where the good outcome is nega-
tive and the bad outcome is positive, we often find that the desired outcome for a 
null hypothesis is rejection.
To make matters more complicated, what happens if the portfolio manager 
doesn’t seem to be that good? If we rejected the null hypothesis when there was a 
high probability that the portfolio manager’s expected return was greater than 10%, 
should we accept the null hypothesis when there is a high probability that the ex-
pected return is less than 10%? In the realm of statistics, outright acceptance seems 
too certain. In practice, we can do two things. First, we can state that the probability 
of rejecting the null hypothesis is low (e.g., “The probability of rejecting the null hy-
pothesis is only 4.2%”). More often, we say that we fail to reject the null hypothesis 
(e.g., “We fail to reject the null hypothesis at the 95.8% level”).
Sample Problem
Question:
At the start of the year, you believed that the annualized volatility of XYZ 
Corporation’s equity was 45%. At the end of the year, you have collected a 
year of daily returns, 256 business days’ worth. You calculate the standard 
deviation, annualize it, and come up with a value of 48%. Can you reject the 
null hypothesis, H0: σ = 45%, at the 95% confidence level?
Answer:
The appropriate test statistic is:
( – ) ˆ
(
– ) .
.
.
n
1
256
1 0 48
0 45
290 13
2
2
2
2
255
2
σ
σ
χ
=
=
∼
Notice that annualizing the standard deviation has no impact on the test 
statistic. The same factor would appear in the numerator and the denominator, 
leaving the ratio unchanged. For a chi-squared distribution with 255 degrees 
of freedom, 290.13 corresponds to a probability of 6.44%. We fail to reject the 
null hypothesis at the 95% confidence level.
One Tail or Two?
Novice statisticians often get confused about the choice between one-tailed and two-
tailed critical values. In many scientific fields where positive and negative deviations 
are equally important, two-tailed confidence levels are more prevalent. In risk man-
agement, more often than not we are more concerned with the probability of extreme 
negative outcomes, and this concern naturally leads to one-tailed tests.
A two-tailed null hypothesis could take the form:
	
H
H
0
1
0
0
:
:
µ
µ
=
≠

(7.12)

Hypothesis Testing and Confidence Intervals
141
In this case, H1 implies that extreme positive or negative values would cause us 
to reject the null hypothesis. If we are concerned with both sides of the distribution 
(both tails), we should choose a two-tailed test.
A one-tailed test could be of the form:
	
H
c
H
c
0
1
:
:
µ
µ
>
≤

(7.13)
In this case, we will reject H0 only if the estimate of µ is significantly less than c. 
If we are only concerned with deviations in one direction, we should use a one-tailed 
test. As long as the null hypothesis is clearly stated, the choice of a one-tailed or two-
tailed confidence level should be obvious.
The 95% confidence level is a very popular choice for confidence levels, both 
in risk management and in the sciences. Many non–risk managers remember from 
their science classes that a 95% confidence level is equivalent to approximately 1.96 
standard deviations. For a two-tailed test this is correct; for a normal distribution 
95% of the mass is within +/–1.96 standard deviations. For a one-tailed test, though, 
95% of the mass is within either +1.64 or –1.64 standard deviations. Using 1.96 
instead of 1.64 is a common mistake for people new to risk management.
Exhibit 7.1 shows common critical values for t-tests of varying degrees of free-
dom and for a normal distribution. Notice that all distributions are symmetrical. For 
small sample sizes, extreme values are more likely, but as the sample size increases, 
the t distribution converges to the normal distribution. For 5% significance with 100 
degrees of freedom, the difference between our rule of thumb based on the normal 
distribution, 1.64 standard deviations, is very close to the actual value of 1.66.
The Confidence Level Returns
As we stated at the beginning of this section, one of the great things about a hy-
pothesis test is that we are not required to choose an arbitrary confidence level. 
In practice, though, 95% and 99% confidence levels are such gold standards that 
we often end up referring back to them. If we can reject a null hypothesis at the 
96.3% confidence level, some practitioners will simply say that the hypothesis was 
rejected at the 95% confidence level. The implication is that, even though we may 
be more confident, 95% is enough. This convention can be convenient when testing 
Exhibit 7.1 
Common Critical Values for Student’s t Distribution
t10
t100
t1,000
N
1.0%
−2.76
−2.36
−2.33
−2.33
2.5%
−2.23
−1.98
−1.96
−1.96
5.0%
−1.81
−1.66
−1.65
−1.64
10.0%
−1.37
−1.29
−1.28
−1.28
90.0%
1.37
1.29
1.28
1.28
95.0%
1.81
1.66
1.65
1.64
97.5%
2.23
1.98
1.96
1.96
99.0%
2.76
2.36
2.33
2.33

142
Mathematics and Statistics for Financial Risk Management
a hypothesis repeatedly. As an example, we might want to test the validity of a risk 
model against new market data every day and be alerted only when the hypothesis 
cannot be rejected at the 95% confidence level. In the end, our inability to decide on 
a universal confidence level should serve as a reminder that, in statistics, there is no 
such thing as a sure bet; there is no such thing as absolute certainty.
Chebyshev’s Inequality
In the preceding sections, we were working with sample statistics where the shape of 
the distribution was known. Amazingly, even if we do not know the entire distribu-
tion of a random variable, we can form a confidence interval, as long as we know the 
variance of the variable. For a random variable, X, with a standard deviation of σ, the 
probability that X is within n standard deviations of µ is less than or equal to 1/n2:
	
P X
n
n
[|
|
]
−
≥
≤
µ
σ
1
2 
(7.14)
This is a result of what is known as Chebyshev’s inequality.
For a given level of variance, Chebyshev’s inequality places an upper limit on 
the probability of a variable being more than a certain distance from its mean. For a 
given distribution, the actual probability may be considerably less. Take, for exam-
ple, a standard normal variable. Chebyshev’s inequality tells us that the probability 
of being greater than two standard deviations from the mean is less than or equal to 
25%. The exact probability for a standard normal variable is closer to 5%, which is 
indeed less than 25%.
Chebyshev’s inequality makes clear how assuming normality can be very anti-
conservative. If a variable is normally distributed, the probability of a three standard 
deviation event is very small, 0.27%. If we assume normality, we will assume that 
three standard deviation events are very rare. For other distributions, though, Che-
byshev’s inequality tells us that the probability could be as high as 1∕9, or approxi-
mately 11%. Eleven percent is hardly a rare occurrence. Assuming normality when 
a random variable is in fact not normal can lead to a severe underestimation of risk. 
Risk managers take note!
Application: VaR
Value at risk (VaR) is one of the most widely used risk measures in finance. VaR was 
popularized by J.P. Morgan in the 1990s. The executives at J.P. Morgan wanted their 
risk managers to generate one statistic at the end of each day, which summarized the 
risk of the firm’s entire portfolio. What they came up with was VaR.
If the 95% VaR of a portfolio is $400, then we expect the portfolio will lose 
$400 or less in 95% of the scenarios, and lose more than $400 in 5% of the scenar-
ios. We can define VaR for any confidence level, but 95% has become an extremely 
popular choice in finance. The time horizon also needs to be specified for VaR. On 
trading desks, with liquid portfolios, it is common to measure the one-day 95% VaR. 
In other settings, in which less liquid assets may be involved, time frames of up to 
one year are not uncommon. VaR is decidedly a one-tailed confidence interval.

Hypothesis Testing and Confidence Intervals
143
If an actual loss equals or exceeds the predicted VaR threshold, that event is 
known as an exceedance. Another way to explain VaR is to say that for a one-day 
95% VaR, the probability of an exceedance event on any given day is 5%.
Exhibit 7.2 provides a graphical representation of VaR at the 95% confidence 
level. The exhibit shows the probability density function for the returns of a portfo-
lio. Because VaR is being measured at the 95% confidence level, 5% of the distribu-
tion is to the left of the VaR level, and 95% is to the right. 
In order to formally define VaR, we begin by defining a random variable L, 
which represents the loss to our portfolio. L is simply the negative of the return to 
our portfolio. If the return of our portfolio is −$600, then the loss, L, is +$600. For 
a given confidence level, γ , then, we can define value at risk as:
	
P L ≥
=
−
VaRγ
γ
1

(7.15)
 If a risk manager says that the one-day 95% VaR of a portfolio is $400, this 
means that there is a 5% probability that the portfolio will lose $400 or more on any 
given day (that L will be more than $400). 
We can also define VaR directly in terms of returns. If we multiply both sides 
of the inequality in Equation 7.15 by −1, and replace −L with R, we come up with 
Equation 7.16:
	
P R ≤−
=
−
VaRγ
γ
1

(7.16)
5%
VaR
Exhibit 7.2 
Example of 95% Value at Risk

144
Mathematics and Statistics for Financial Risk Management
Equations 7.15 and 7.16 are equivalent. A loss of $400 or more and a return of 
−$400 or less are exactly the same. 
While Equations 7.15 and 7.16 are equivalent, you should know that some risk 
managers go one step further and drop the negative sign from Equation 7.16. What 
we have described as a VaR of $400 they would describe as a VaR of −$400. The 
convention we have described is more popular. It has the advantage that for reason-
able confidence levels for most portfolios, VaR will almost always be a positive num-
ber. The alternative convention is attractive because the VaR and returns will have 
the same sign. Under the alternative convention, if your VaR is −$400, then a return 
of −$400 is just at the VaR threshold. In practice, rather than just saying that your 
VaR is $400, it is often best to resolve any ambiguity by stating that your VaR is a 
loss of $400 or that your VaR is a return of −$400.
Sample Problem
Question:
The probability density function (PDF) for daily profits at Triangle Asset 
Management can be described by the following function (see Exhibit 7.3):
p
p
=
+
−
≤
≤
=
−
<
≤
1
10
1
100
10
0
1
10
1
100
0
10
π
π
π
π
  
  
0.00
0.10
–12
–10
–8
–6
–4
–2
0
2
4
6
8
10
12
p
π
Exhibit 7.3 
Triangular Probability Density Function

Hypothesis Testing and Confidence Intervals
145
What is the one-day 95% VaR for Triangle Asset Management?
Answer:
To find the 95% VaR, we need to find a, such that:
−∫
=
10
0 05
a
pdπ
.
By inspection, half the distribution is below zero, so we need only bother 
with the first half of the function:
1
10
1
100
1
10
1
200
10
2
10
+
=
+
−
−
∫
π
π
π
π
d
a
a
a
d
a
a
1
10
1
100
1
10
1
200
0 50
0
10
2
+
=
+
=
+
−∫
π
π
.
.
.05
20
2
a +
a
=
+ 90
0
Using the quadratic formula, we can solve for a:
a = −
±
−
= −
±
⋅
20
400
4 90
2
10
10
Because the distribution is not defined for π < −10, we can ignore the nega-
tive, giving us the final answer:
a = −
+
= −
10
10
6 84
.
The one-day 95% VaR for Triangle Asset Management is a loss of 6.84.
Backtesting
An obvious concern when using VaR is choosing the appropriate confidence interval. 
As mentioned, 95% has become a very popular choice in risk management. In some 
settings there may be a natural choice for the confidence level, but most of the time 
the exact choice is arbitrary.
A common mistake for newcomers is to choose a confidence level that is too 
high. Naturally, a higher confidence level sounds more conservative. A risk manager 
who measures one-day VaR at the 95% confidence level will, on average, experi-
ence an exceedance event every 20 days. A risk manager who measures VaR at the 
99.9% confidence level expects to see an exceedance only once every 1,000 days. Is 
an event that happens once every 20 days really something that we need to worry 
about? It is tempting to believe that the risk manager using the 99.9% confidence 
level is concerned with more serious, riskier outcomes, and is therefore doing a 
better job.

146
Mathematics and Statistics for Financial Risk Management
The problem is that, as we go further and further out into the tail of the dis-
tribution, we become less and less certain of the shape of the distribution. In most 
cases, the assumed distribution of returns for our portfolio will be based on histori-
cal data. If we have 1,000 data points, then there are 50 data points to back up our 
95% confidence level, but only one to back up our 99.9% confidence level. As with 
any distribution parameter, the variance of our estimate of the parameter decreases 
with the sample size. One data point is hardly a good sample size on which to base 
a parameter estimate.
A related problem has to do with backtesting. Good risk managers should regu-
larly backtest their models. Backtesting entails checking the predicted outcome of a 
model against actual data. Any model parameter can be backtested.
In the case of VaR, backtesting is easy. As we saw in a problem at the end of 
Chapter 4, when assessing a VaR model, each period can be viewed as a Bernoulli 
trial. In the case of one-day 95% VaR, there is a 5% chance of an exceedance event 
each day, and a 95% chance that there is no exceedance. Because exceedance events 
are independent, over the course of n days the distribution of exceedances follows a 
binomial distribution:
	
P
n
k
p
p
n
k
k
(
[
)
K
k
=
=
−
−
1
]

(7.17)
Here, n is the number of periods that we are using in our backtest, k is the number 
of exceedances, and (1 − p) is our confidence level.
Sample Problem
Question:
As a risk manager, you are tasked with calculating a daily 95% VaR statis-
tic for a large fixed income portfolio. Over the past 100 days, there have been 
four exceedances. How many exceedances should you have expected? What 
was the probability of exactly four exceedances during this time? The prob-
ability of four or less? Four or more?
Answer:
Over 100 days we would expect to see five exceedances: (1 – 95%) × 
100 = 5. The probability of exactly four exceedances is 17.81%:
P
.
[
(
.
.
)
K
=
=
=
−
−
4]
100
4
0 05 1
0 0
0
5
1781
4
100 4
Remember, by convention, for a 95% VaR the probability of an exceed-
ance is 5%, not 95%.
The probability of four or fewer exceedances is 43.60%. Here we 
simply do the same calculation as in the first part of the problem, but for 

Hypothesis Testing and Confidence Intervals
147
zero, one, two, three, and four exceedances. It’s important not to forget  
zero:
P
k
P
k
k
k
.
[
(
.
)
[
K
K
≤
=
−
−
=∑
4]
100 0 05 1
0 05 100
0
4
≤
=
+
+
+
+
≤
4]
0 0059
0 0312
0 0812
0 1396
0 1781
.
.
.
.
.
[
P K
4] = 0 4360
.
For the final result, we could use the brute force approach and calculate 
the probability for k = 4, 5, 6, . . . , 99, 100, a total of 97 calculations. Instead we 
realize that the sum of all probabilities from 0 to 100 must be 100%; therefore, 
if the probability of K ≤ 4 is 43.60%, then the probability of K > 4 must be 
100% – 43.60% = 56.40%. Be careful, though, as what we want is the prob-
ability for K ≥ 4. To get this, we simply add the probability that K = 4, from the 
first part of our question, to get the final answer, 74.21%:
P K
P K
P K
P K
[
]
[
]
[
]
[
]
.
.
.
≥
=
>
+
=
≥
=
+
=
4
4
4
4
0 5640
0 1781
0 7412
The probability of a VaR exceedance should be conditionally independent of all 
available information at the time the forecast is made. In other words, if we are cal-
culating the 95% VaR for a portfolio, then the probability of an exceedance should 
always be 5%. The probability shouldn’t be different because today is Tuesday, be-
cause it was sunny yesterday, or because your firm has been having a good month. 
Importantly, the probability should not vary because there was an exceedance the 
previous day, or because risk levels are elevated. 
A common problem with VaR models in practice is that exceedances often end 
up being serially correlated. When exceedances are serially correlated, you are more 
likely to see another exceedance in the period immediately after an exceedance than 
expected. To test for serial correlation in exceedances, we can look at the periods 
immediately following any exceedance events. The number of exceedances in these 
periods should also follow a binomial distribution. For example, pretend we are 
calculating the one-day 95% VaR for a portfolio, and we observed 40 exceedances 
over the past 800 days. To test for serial correlation in the exceedances, we look at 
the 40 days immediately following the exceedance events, and count how many of 
those were also exceedances. In other words, we count the number of back-to-back 
exceedances. Because we are calculating VaR at the 95% confidence level, of the 40 
day-after days, we would expect that 2 of them, 5% × 40 = 2, would also be exceed-
ances. The actual number of these day-after exceedances should follow a binomial 
distribution with n = 40 and p = 5%.
Another common problem with VaR models in practice is that exceedances tend 
to be correlated with the level of risk. It may seem counterintuitive, but we should be 
no more or less likely to see VaR exceedances in years when market volatility is high 

148
Mathematics and Statistics for Financial Risk Management
compared to when it is low. Positive correlation between exceedances and risk levels 
can happen when a model does not react quickly enough to changes in risk levels. 
Negative correlation can happen when model windows are too short. To test for cor-
relation between exceedances and the level of risk, we can divide our exceedances 
into two or more buckets, based on the level of risk. As an example, pretend we have 
been calculating the one-day 95% VaR for a portfolio over the past 800 days. We di-
vide the sample period in two, placing the 400 days with the highest forecasted VaR 
in one bucket and the 400 days with the lowest forecasted VaR in the other. After 
sorting the days, we would expect each 400-day bucket to contain 20 exceedances: 
5% × 400 = 20. The actual number of exceedances in each bucket should follow a 
binomial distribution with n = 400, and p = 5%.
Subadditivity
There is a reason VaR has become so popular in risk management. The appeal of 
VaR is its simplicity. Because VaR can be calculated for any portfolio, it allows us to 
easily compare the risk of different portfolios. Because it boils risk down to a single 
number, VaR provides us with a convenient way to track the risk of a portfolio over 
time. Finally, the concept of VaR is intuitive, even to those not versed in statistics.
Because it is so popular, VaR has come under a lot of criticism. The criticism 
generally falls into one of three categories.
At a very high level, financial institutions have been criticized for being overly 
reliant on VaR. This is not so much a criticism of VaR as it is a criticism of financial 
institutions for trying to make risk too simple.
At the other end of the spectrum, many experts have criticized how VaR is meas-
ured in practice. This is not so much a criticism of VaR as it is a criticism of specific im-
plementations of VaR. For example, in the early days of finance it was popular to make 
what is known as a delta-normal assumption. That is, when measuring VaR, you would 
assume that all asset returns were normally distributed, and that all options could be ap-
proximated by their delta exposures. Further, the relationship between assets was based 
entirely on a covariance matrix (no coskewness or cokurtosis). These assumptions made 
calculating VaR very easy, even for large portfolios, but the results were often disap-
pointing. As computing power became cheaper and more widespread, this approach 
quickly fell out of favor. Today VaR models can be extremely complex, but many people 
outside of risk management still remember when delta-normal was the standard ap-
proach, and mistakenly believe that this is a fundamental shortcoming of VaR.
In between, there are more sophisticated criticisms. One such criticism is that 
VaR is not a subadditive risk measure. It is generally accepted that a logical risk 
measure should have certain properties; see, for example, Artzner, Delbaen, Eber, 
and Heath (1999). One such property is known as subadditivity. Subadditivity is 
basically a fancy way of saying that diversification is good, and a good risk measure 
should reflect that.
Assume that our risk measure is a function f that takes as its input a random 
variable representing an asset or portfolio of assets. Higher values of the risk meas-
ure are associated with greater risk. If we have two risky portfolios, X and Y, then f 
is said to be subadditive if:
	
f X
Y
f X
f Y
(
)
( )
( )
+
≤
+

(7.18)

Hypothesis Testing and Confidence Intervals
149
In other words, the risk of the combined portfolio, X + Y, is less than or equal to 
the sum of the risks of the separate portfolios. Variance and standard deviation are 
subadditive risk measures.
While there is a lot to recommend VaR, unfortunately it does not always satisfy 
the requirement of subadditivity. The following example demonstrates a violation of 
subadditivity.
Sample Problem
Question:
Imagine a portfolio with two bonds, each with a 4% probability of de-
faulting. Assume that default events are uncorrelated and that the recovery 
rate of both bonds is 0%. If a bond defaults, it is worth $0; if it does not, it is 
worth $100. What is the 95% VaR of each bond separately? What is the 95% 
VaR of the bond portfolio?
Answer:
For each bond separately, the 95% VaR is $0. For an individual bond, in 
(over) 95% of scenarios, there is no loss.
In the combined portfolio, however, there are three possibilities, with the 
following probabilities:
P[x]
x
0.16%
–$200
7.68%
–$100
92.16%
$0
As we can easily see, there are no defaults in only 92.16% of the scenarios, 
(1 – 4%)2 = 92.16%. In the other 7.84% of scenarios, the loss is greater than 
or equal to $100. The 95% VaR of the portfolio is therefore $100.
For this portfolio, VaR is not subadditive. Because the VaR of the com-
bined portfolio is greater than the sum of the VaRs of the separate portfolios, 
VaR seems to suggest that there is no diversification benefit, even though the 
bonds are uncorrelated. It seems to suggest that holding $200 of either bond 
would be less risky than holding a portfolio with $100 of each. Clearly this is 
not correct.
This example makes clear that when assets have payout functions that are dis-
continuous near the VaR critical level, we are likely to have problems with subad-
ditivity. By the same token, if the payout functions of the assets in a portfolio are 
continuous, then VaR will be subadditive. In many settings this is not an onerous 
assumption. In between, we have large, diverse portfolios, which contain some assets 
with discontinuous payout functions. For these portfolios subadditivity will likely be 
only a minor issue.

150
Mathematics and Statistics for Financial Risk Management
Sample Problem
Question:
In a previous example, the probability density function of Triangle Asset 
Management’s daily profits could be described by the following function:
p
p
=
+
−
≤
≤
=
−
<
≤
1
10
1
100
10
0
1
10
1
100
0
10
π
π
π
π
   
   
The PDF is also shown in Exhibit 7.4. We calculated Triangle’s one-day 
95% VaR as a loss of (
)
.
.
10
10
6 84
−
=
 For the same confidence level and time 
horizon, what is the expected shortfall?
Expected Shortfall
Another criticism of VaR is that it does not tell us anything about the tail of the 
distribution. Two portfolios could have the exact same 95% VaR but very different 
distributions beyond the 95% confidence level.
More than VaR, then, what we really want to know is how big the loss will be 
when we have an exceedance event. Using the concept of conditional probability, we 
can define the expected value of a loss, given an exceedance, as follows:
	
E L L
S
[
|
]
≥
=
VaRγ

(7.19)
We refer to this conditional expected loss, S, as the expected shortfall.
If the profit function has a probability density function given by f(x), and VaR is 
the VaR at the γ  confidence level, we can find the expected shortfall as:
	
S
xf x dx
= −
−
−∞
∫
1
1
γ
( )
VaR

(7.20)
As with VaR, we have defined expected shortfall in terms of losses. Just as VaR 
tends to be positive for reasonable confidence levels for most portfolios, expected 
shortfall, as we have defined it in Equation 7.20, will also tend to positive. As with 
VaR, this convention is not universal, and risk managers should be careful to avoid 
ambiguity when quoting expected shortfall numbers.
Expected shortfall does answer an important question. What’s more, expected 
shortfall turns out to be subadditive, thereby avoiding one of the major criticisms of 
VaR. As our discussion on backtesting suggests, though, because it is concerned with 
the tail of the distribution, the reliability of our expected shortfall measure may be 
difficult to gauge.

Hypothesis Testing and Confidence Intervals
151
0.00
0.10
–12
–10
–8
–6
–4
–2
0
2
4
6
8
10
12
p
ES
VaR
π
Exhibit 7.4 
Triangular PDF, VaR, and Expected Shortfall
Answer:
Because the VaR occurs in the region where π < 0, we need to utilize only 
the first half of the function. Using Equation 7.20, we have:
S
pd
=
=
+
−
−∫
1
0 05
20
1
10
1
100
10
10
.
π
π
π
π
Va
V
R
aR
∫
∫
=
+
=
+
−
−
d
S
d
π
π
π
π
π
π
2
5
1
15
2
10
3
2
VaR
10
2
3
2
10
10
1
15
10
10
10
VaR
S =
−
+
+
−
+
−
−
(
) +
−
= −
+
= −
1
15
10
10
2
3 10
7 89
3)
(
.
S
Thus, the expected shortfall is a loss of 7.89. Intuitively this should make 
sense. The expected shortfall must be greater than the VaR, 6.84, but less than 
the maximum loss of 10. Because extreme events are less likely (the height of 
the PDF decreases away from the center), it also makes sense that the expected 
shortfall is closer to the VaR than it is to the maximum loss.

152
Mathematics and Statistics for Financial Risk Management
Problems
	 1.	Given the following data sample, how confident can we be that the mean is 
greater than 40?
64
70
20
3
58
13
74
84
47
17
	 2.	You are given the following sample of annual returns for a portfolio manager. 
If you believe that the distribution of returns has been stable over time and will 
continue to be stable over time, how confident should you be that the portfolio 
manager will continue to produce positive returns?
–7%
7%
19%
23%
–18%
–12%
49%
34%
–6%
–20%
	 3.	You are presented with an investment strategy with a mean return of 20% and 
a standard deviation of 10%. What is the probability of a negative return if the 
returns are normally distributed? What if the distribution is symmetrical, but 
otherwise unknown?
	 4.	Suppose you invest in a product whose returns follow a uniform distribution 
between −40% and +60%. What is the expected return? What is the 95% VaR? 
The expected shortfall?
	 5.	You are the risk manager for a portfolio with a mean daily return of 0.40% and 
a daily standard deviation of 2.3%. Assume the returns are normally distributed 
(not a good assumption to make, in general). What is the 95% VaR?
	 6.	You are told that the log annual returns of a commodities index are normally 
distributed with a standard deviation of 40%. You have 33 years of data, from 
which you calculate the sample variance. What is the standard deviation of this 
estimate of the sample variance?
	 7.	In the previous question, you were told that the actual standard deviation was 
40%. If, instead of 40%, the measured standard deviation turns out to be 50%, 
how confident can you be in the initial assumption? State a null hypothesis and 
calculate the corresponding probability.
	 8.	A hedge fund targets a mean annual return of 15% with a 10% standard devia-
tion. Last year, the fund returned –5%. What is the probability of a result this 
bad or worse happening, given the target mean and standard deviation? Assume 
the distribution is symmetrical.
	 9.	A fund of funds has investments in 36 hedge funds. At the end of the year, the 
mean return of the constituent hedge funds was 18%. The standard deviation of 
the funds’ returns was 12%. The benchmark return for the fund of funds was 
14%. Is the difference between the average return and the benchmark return 
statistically significant at the 95% confidence level?
	10.	The probability density function for daily profits at Box Asset Management can 
be described by the following function (see Exhibit 7.5):
p
p
=
−
≤
≤
=
−
>
>
1
200
100
100
0
100
100
  
  
π
π
	
	 What is the one-day 95% VaR of Box Asset Management?

Hypothesis Testing and Confidence Intervals
153
0.00
0.005
–120 –100 –80
–60
–40
–20
0
20
40
60
80
100
120
p
π
Exhibit 7.5 
Probability Density Function for Box Asset Management
0.00
0.05
–25
–20
–15
–10
–5
0
5
10
15
20
25
p
π
Exhibit 7.6 
Probability Density Function for Pyramid Asset Management

154
Mathematics and Statistics for Financial Risk Management
	11.	Continuing with our example of Box Asset Management, find the expected 
shortfall, using the same PDF and the calculated VaR from the previous question.
	12.	The probability density function for daily profits at Pyramid Asset Management 
can be described by the following functions (see Exhibit 7.6):
p
p
=
+
−
≤
≤
=
−
<
≤
3
80
1
400
15
5
5
80
1
400
5
25
π
π
π
π
  
  
	
	 The density function is zero for all other values of π. What is the one-day 95% 
VaR for Pyramid Asset Management?

155
Chapter 8
Matrix Algebra
T
his chapter starts with a brief review of matrix notation and operations. We then 
explore the application of matrix algebra to risk management.
Matrix Notation
A matrix is a two-dimensional array of numbers, or variables. By convention, the 
size of a matrix is denoted by the number of rows, and then by the number of col-
umns. For example, the following is a 3 × 2 matrix (pronounced “three by two”):
	
A = −
5
3
3
9
10
8

(8.1)
Matrices with only one column are also known as vectors. The following is a 
4 × 1 vector:
	
b = −
43
17
56
64

(8.2)
In matrix algebra, we typically refer to ordinary real numbers or variables as 
scalars. The elements of matrices A and b shown here are all scalars. Traditionally, 
as here, matrices are denoted by bold letters. Matrices with more than one column 
are designated by bold capital letters, whereas vectors (i.e., one-column matrices) are 
designated by bold lowercase letters. Scalars, including the elements of a matrix, are 
denoted by nonbold lowercase letters.
The various elements of a matrix are differentiated by subscripts, which indicate 
first the row and then the column of the element. For example:
	
C =
c
c
c
c
1 1
1 2
2 1
2 2
,
,
,
,

(8.3)

156
Mathematics and Statistics for Financial Risk Management
In the case of a vector like b, if it does not cause any ambiguity, we often just use 
a single subscript for each of the elements:
	
b =
b
b
b
b
1
2
3
4

(8.4)
Matrices like C with the same number of rows and columns are known as square 
matrices. The main diagonal of a square matrix consists of the entries running down the 
diagonal from the top-left corner to the bottom-right corner. In other words, all the en-
tries xi,j, where i = j. If all of the entries above the main diagonal are zero, then a matrix 
is said to be a lower triangular matrix. The following is a 3 × 3 lower triangular matrix:
	
L =
l
l
l
l
l
l
1 1
2 1
2 2
3 1
3 2
3 3
0
0
0
,
,
,
,
,
,

(8.5)
Similarly, a matrix in which all of the entries below the main diagonal are zero 
is said to be an upper triangular matrix. The following is a 3 × 3 upper diagonal 
matrix:
	
U =
u
u
u
u
u
u
1 1
1 2
1 3
2 2
2 3
3 3
0
0
0
,
,
,
,
,
,

(8.6)
If all of the entries both above and below the main diagonal are zero, then the 
matrix is said to be diagonal. The following are all diagonal matrices:
	
15
0
0
0
9
0
0
0
2
5 6
0
0
23 9
47
0
0
0
0
0
−
.
.
0
0
3

(8.7)
Matrix Operations
The following sections introduce some basic matrix operations. Just as we can add, 
subtract, and multiply scalars, we can also add, subtract, and multiply matrices. We 
rarely talk about matrix division, but there is inversion, which is analogous. Finally, 
there are operations, such as transposition, that are unique to matrices.
Addition and Subtraction
To add two matrices together, we simply add the corresponding elements in each 
matrix together. Matrix addition can occur only between matrices with the same 

Matrix Algebra
157
number of rows and columns. As an example, suppose we have two matrices, D 
and E:
	
E
D = −
=
−
32
51
10
0
25
21
1
3
4 
(8.8)
We could add them together as follows:
	
D
E
+
=
+
+
+
+
(
)
(
)
(
)
(
,
,
,
,
,
,
,
d
e
d
e
d
e
d
1 1
1 1
1 2
1 2
2 1
2 1
2 2
e2 2
57
30
7
14
, ) = −

(8.9)
Matrix addition is commutative; that is, the order of the matrices does not mat-
ter when we are adding:
	
D
E
E
D
+
=
+

(8.10)
Matrix addition is also associative. If we want to add together more than two 
matrices, the order in which we carry out the addition is not important. Given three 
matrices, D, E, and F, all the same size:
	
D
E
F
D
E
F
+
+
=
+
+
(
)
(
)

(8.11)
In other words, we can add E and F together first, and then add the result to D, or 
we can add D and E first and add that to F. The result is the same.
We can also multiply a matrix by a scalar. The result is a new matrix, the same 
size as the original, but with all the elements multiplied by the scalar value. Using the 
matrix A, from before, and a scalar, s = 10:
	
sA =
−
= −
10
3
9
10
5
3
8
30
90
100
50
30
80

(8.12)
To subtract one matrix from another matrix, we simply subtract the correspond-
ing elements in each matrix. Again the matrices must be of the same size. Using our 
matrices D and E:
	
D
E
D
E
−
= −
−
−
−
=
−
32
51
10
0
25
21
1
3
4
32
25 51
21
10
3
0
14
7
72
13
14
+
−
−
−
−
= −
−
D
E

(8.13)

158
Mathematics and Statistics for Financial Risk Management
Subtraction is equivalent to adding a matrix to a second matrix multiplied by –1. 
It’s slightly more complicated, but we get the same result:
	
D
E
D
E
−
= −
+ −
−
−
=
32
51
10
0
1 25
21
1
3
4
32
(
)
51
10
0
25
21
3
14
7
72
13
14
−
+ −
−
−
−
= −
−
D
E

(8.14)
Because matrix subtraction can also be turned into matrix addition, matrix sub-
traction is also commutative and associative.
Multiplication
We can also multiply two matrices together. In order to multiply two matrices to-
gether, the number of columns in the first matrix must be equal to the number of 
rows in the second matrix. The resulting matrix has the same number of rows as 
the first matrix and the same number of columns as the second. For example, the 
product of a 3 × 2 matrix and a 2 × 5 matrix is a 3 × 5 matrix. To determine each 
entry in the new matrix, we multiply the corresponding elements from the same row 
in the first matrix by the corresponding elements in the same column in the second 
matrix. For example, for the following matrices, G and H, to get the first element 
of the product matrix, J = GH, we go across the first row of G and down the first 
column of H:
	
=
⋅
+
⋅
=
=
=
=
=
?
?
?
20
?
?
?
8
1
2
6
4
8
3
2
5
9
1
6
4
8
3
2
5
9
1
6
GH
J
H
G

(8.15)
Similarly, to get the first entry in the second row, we go across the second row of 
G and down the first column of H:
	
=
⋅
+
⋅
⋅
+
⋅
=
=
=
?
58
?
20
?
8
5
2
9
?
8
1
2
6
4
8
3
2
5
9
1
6
GH
GJ

(8.16)
To get the second entry in the first row, we go across the first row of G and down 
the second column of H:
	
=
⋅
+
⋅
⋅
+
⋅
⋅
+
⋅
=
=
=
?
58
22
20
?
8
5
2
9
4
1
3
6
8
1
2
6
4
8
3
2
5
9
1
6
GH
J

(8.17)

Matrix Algebra
159
Finally, to get the last entry in J, we go across the second row of G, and down 
the second column of H:
	
=
⋅
+
⋅
⋅
+
⋅
⋅
+
⋅
⋅
+
⋅
=
=
47
58
22
20
4
5
3
9
8
5
2
9
4
1
3
6
8
1
2
6
4
8
3
2
5
9
1
6
J

(8.18)
More formally, for the entry in J in the ith row and jth column, ji,j, we have:
	
j
g
h
i j
k
i k k j
,
,
,
=
=∑
1
2

(8.19)
We can generalize this to larger matrices. Assuming G is m × n and H is n × p, 
we would obtain an m × p matrix J = GH, as follows:
	
GH =
g
g
g
g
g
g
g
g
g
n
n
m
m
1 1
1 2
1
2 1
2 2
2
1
2
,
,
,
,
,
,
,
,
m n
p
h
h
h
h
h
h
,
,
,
,
,
,
,
1 1
1 2
1
2 1
2 2
2 p
n
n
n p
i
i
h
h
h
g
h
,
,
,
,
,
1
2
1
=
GH
1
1
1
2
1
1
1
2
1
i
n
i
i
i
n
i
i p
i
n
i
i
i
g
h
g
h
g
h
=
=
=
∑
∑
∑
,
,
,
,
,
,
=
=
=
∑
∑
∑
1
2
2
1
2
1
n
i
i
i
n
i
i p
i
n
m i
i
g
h
g
h
g
h
,
,
,
,
,
,1
1
2
1
1
i
n
m i
i
i
n
m i
i p
i
n
g
h
g
h
=
=
=
∑
∑
∑
,
,
,
,

(8.20)
As with matrix addition, matrix multiplication is associative. If we have three 
matrices of the appropriate size, G, H, and J, it does not matter if we multiply H and 
J together first or multiply G and H together first. That is:
	
G HJ
GH J
(
)
(
)
=

(8.21)
Be careful, though; unlike matrix addition or scalar multiplication, the order of 
matrix multiplication does matter. Matrix multiplication is not commutative.
	
GH
HG
≠

(8.22)
Clearly, this is true for matrices that are of different size. We can multiply a  
10 × 5 matrix by a 5 × 6 matrix, but if we try to reverse the order and multiply a  
5 × 6 matrix by a 10 × 5 matrix, the number of columns and rows will not match. 
Even if the matrices are square and we can reverse the order of multiplication, the 
result will not necessarily be the same.

160
Mathematics and Statistics for Financial Risk Management
Sample Problem
Question:
Given the following matrices M and N, find the products MN and NM:
N
M =
=
3
5
9
8
6
2
5
1
Answer:
MN =
+
+
+
+
=
⋅
⋅
⋅
⋅
⋅
⋅
⋅
⋅
3 2
5 1
3 6
5 5
9 2
8 1
9 6
8 5
11
43
26
94
2 3
6 9
2 5
6 8
1 3
5 9
1 5
5 8
=
+
+
+
+
⋅
⋅
⋅
⋅
⋅
⋅
⋅
⋅
NM
= 60
58
48
45
As you might have guessed, in this case, MN does not equal NM.
Because a square matrix has the same number of rows and columns, a square 
matrix can always be multiplied by itself. Because the resulting matrix has the same 
dimensions, we can multiply the resulting product matrix by the original square ma-
trix. We can continue doing this as many times as we want. Just as with scalars, we 
denote this repeated multiplication, or exponentiation, with an exponent:
	
MM
M
MMM
M
=
=
2
3


(8.23)
There is a distributive law for matrix multiplication, too. Assuming the matrices 
are of the correct size, we have:
	
F D
E
FD
FE
M
N P
MP
NP
(
)
(
)
+
=
+
+
=
+

(8.24)
Because multiplication is involved, it is important that we have preserved the order 
of the matrices. In the first line, F is always before D and E, and in the second line, P 
remains after M and N.
One matrix that comes up again and again in matrix algebra is the identity ma-
trix. The identity matrix is a diagonal matrix with 1’s along its main diagonal. An 
identity matrix with n rows and columns is typically denoted In, or simply by I if the 
number or rows and columns can be inferred.
	
I
I
2
3
=
=
1
0
0
1
1
0
0
0
1
0
0
0
1

(8.25)

Matrix Algebra
161
When we multiply a matrix by the appropriately sized identity matrix, the result 
is the original matrix. If we have an r × c matrix A, then:
	
AI
I A
A
c
r
=
=

(8.26)
The identity matrix leads us to define the inverse of a matrix. The inverse of a 
matrix A is denoted A−1. If we multiply a matrix by its inverse, we get an identity 
matrix:
	
AA
A
A
I
−
−
=
=
1
1

(8.27)
Sample Problem
Question:
The following matrices, A and A−1, are inverses of each other. Prove this 
by showing that the products AA−1 and A−1A are both equal to the identity 
matrix.
A
A
=
=
−
−
−
1
4
2
9
4
9
1
2
1
Answer:
AA 1
−=
+
−
−
+
+
−
−
+
⋅
⋅
⋅
⋅
⋅
⋅
⋅
1 9
4
2
1
4
4 1
2 9
9
2
2
4
9
(
)
(
)
(
)
(
)
⋅
⋅
⋅
⋅
=
=
+ −
+ −
−
1
0
1
1
0
9 1
4
2
9 4
4
A
A
1
(
)
(
)⋅
⋅
⋅
⋅
⋅
−
+
−
+
=
9
2 1
1 2
2 4
1 9
0
1
1
0
(
)
In the preceding example, if the inverse matrix hadn’t been given to us, how would 
we calculate it? There are well-established methods for finding the inverse of a matrix. 
For relatively small matrices, these methods are straightforward, and can often be car-
ried out by hand. For even moderately sized matrices, these methods grow quickly in 
complexity. Finding the inverse of a 4 × 4 matrix by hand might be possible, but it will 
certainly be tedious. For large matrices, calculating the inverse can be very complex. 
Because of the potentially large number of steps involved, a simple algorithm is likely 
to be very slow and susceptible to rounding errors. A good statistics software pack-
age will use algorithms that are both accurate and efficient, but often very complex. 
While both the simple and the complex methods are interesting, in practice most risk 
management applications will involve large matrices, which will necessitate using a 
statistics program to calculate inverses. In practice, understanding the properties of 
a matrix is much more important. Because there is a possibility of rounding error, it 
never hurts to check the output of a statistical package by making sure that the prod-
uct of a matrix and the calculated inverse is, in fact, equal to an identity matrix.

162
Mathematics and Statistics for Financial Risk Management
It is important to note that not every matrix has an inverse. Take, for example, 
the following matrix:
	
U =
1
1
1
1

(8.28)
There is no matrix with which we can multiply U to get an identity matrix. U has 
no inverse. While this is easy to see with U, it is not always obvious when matrices 
are noninvertible.
Zero Matrix
In addition to the identity matrix, we will often find it convenient to define a zero ma-
trix, where all the entries are zero. We will denote the zero matrix with a bold zero, 0.
The zero matrix has similar properties to its scalar equivalent. First, if we multi-
ply anything by an appropriately sized zero matrix, we get the zero matrix:
	
0
0
0
A
A
=
=

(8.29)
Second, if we add the zero matrix to anything, we get back the original matrix. 
Again, assuming the matrices are of the appropriate size:
	
0
A
A
0
A
+
=
+
=

(8.30)
Because of this last relationship, some texts refer to 0 as the additive identity 
matrix, and to I as the multiplicative identity matrix. From here on out, we will refer 
to 0 as a zero matrix, and continue to refer to I as an identity matrix. The zero matrix 
is another example of a noninvertible matrix.
Transpose
The transpose of a matrix can be formed by swapping the columns and rows of the 
original matrix. For a matrix A, we denote its transpose by A′ (pronounced “A prime” 
or “A transpose”).1 We can easily determine each element of the transpose matrix by 
reversing the row index and column index of each element of the original matrix:
	
a
a
ij
ji
′ =

(8.31)
The following are examples of matrices and their transposes:
	
A
A
M
= −
=
−
=
3
9
10
5
3
8
3
5
9
3
10
8
3
5
9
8
′
=
M′
3
9
5
8

(8.32)
1 Another common way to denote the transpose of a matrix is with a superscript T, as in AT. 
In finance and economics, the prime notation seems to be more popular, and we will use that 
convention throughout the rest of the book.

Matrix Algebra
163
Note that for a square matrix, taking the transpose can be thought of as reflect-
ing the matrix across the main diagonal.
If we reverse the row and column indexes of an element and then reverse them 
again, we get back our original indexes. This means that if we take the transpose of 
a transpose, we get back the original matrix:
	
(
)
A
A
′ ′ =

(8.33)
A square matrix that is equal to its own transpose is said to be symmetrical. The 
following matrices are both symmetrical:
	
S
S
1
2
=
−
−
−
=
−
6
7
7
6
9
5
8
5
3
2
8
2
14

(8.34)
In the second application section, we will work with covariance matrices. 
­Covariance and correlation matrices are examples of symmetrical matrices.
Application: Transition Matrices
A ratings transition matrix provides the probability that a bond’s rating will change 
or stay the same over a given time period, given its rating at the start of the period. 
At the end of Chapter 2, we looked at the following problem: Given the following 
one-year ratings transition matrix, what is the probability that a bond that starts 
with a B rating defaults over two years?
1-Year
To a rating of:
A
B
C
D
From a  
rating of:
A
90%
8%
2%
0%
B
10%
80%
8%
2%
C
0%
25%
60%
15%
D
0%
0%
0%
100%
For a bond with a B rating, over the first year the probability of migrating to A 
is 10%, the probability of staying at B is 80%, the probability of migrating to C is 
8%, and the probability of defaulting is 2%. Over two years, there are four ways in 
which the bond could default: It could migrate to A in the first year and then default; 
it could remain at B during the first year and then default; it could migrate to C 
and then default; or it could default the first year and stay defaulted. We can easily 

164
Mathematics and Statistics for Financial Risk Management
calculate each of these probabilities. For example, the probability of migrating from 
B to C to D is just the probability of migrating from B to C, multiplied by the prob-
ability of migrating from C to D, or 8% × 15% = 1.2%. The probability of the bond 
migrating from B to D over two years is just the sum of the probabilities of the four 
possible paths. The following set of equations shows this calculation, with the final 
result, 4.80%.
P[B→D] = P[B→A→D] + P[B→B→D] + P[B→C→D] + P[B→D→D]
= x21x14	
+ x22x24	
+ x23x34	
+ x24x44
= 10% ∙ 0%	 + 80% ∙ 2%	 + 8% ∙ 15%	 + 2% ∙ 100% = 4.80%
In the second row, we have expressed the problem in terms of our standard 
matrix notation. Notice that for the first element in each product, we are just going 
across the second row of the transition matrix, and for the second element in each 
product we are going down the fourth column. This is exactly what we would do 
to get the element in the second row and fourth column if we were multiplying the 
transition matrix by itself. This is no coincidence. It turns out rather conveniently 
that we can calculate the complete two-year transition matrix by multiplying the 
one-year transition matrix by itself. If T1 is our one-year transition matrix, and T2 is 
our two-year transition matrix, then:
T
T T
T
2
1
1
1
2
=
=
Interested readers should check this for themselves by calculating additional values 
for the two-year matrix.
What is even more convenient is that we can generalize this formula. To calcu-
late the n-year transition matrix, we simply raise T1 to the nth power:
T
T
n
n
=
1
The following would be the five-year transition matrix based on the one-year 
transition matrix:
5-Year
To a rating of:
A
B
C
D
From a 
rating of:
A
64.7%
24.8%
6.7%
3.7%
B
28.1%
46.0%
12.1%
13.8%
C
11.8%
35.0%
14.3%
39.0%
D
0.0%
0.0%
0.0%
100.0%
In this example, A-rated bonds have a high probability of maintaining their 
rating and zero probability of defaulting over one year. Over five years, though, 
they have a much lower probability of staying at the same rating and a much higher 
probability of defaulting. 

Matrix Algebra
165
Application: Monte Carlo Simulations Part II: 
Cholesky Decomposition
In risk management, it is often useful to generate simulations in which we can specify 
the covariance between different variables. Imagine that we wanted to create a Mon-
te Carlo simulation of a portfolio containing N stocks. The variance of the portfolio 
will be a function of the variance of each of the stocks, the position sizes, and the 
covariances between the stocks. In Chapter 4, we saw how we could create uncor-
related normally distributed random variables. We also saw how we could create 
two correlated normal variables using linear combinations of uncorrelated normal 
variables. We can use matrix algebra to extend this approach to a large number of 
variables.
Imagine that we have N random variables, X1, X2,  .  .  ., XN, representing the re-
turns of different stocks. In order to describe the relationships between each of the 
variables, we could form an N × N covariance matrix, where each element, σi,j, cor-
responds to the covariance between the ith and jth random variables:
	
∑=
σ
σ
σ
σ
σ
σ
σ
σ
σ
1 1
1 2
1
2 1
2 2
2
1
2
,
,
,
,
,
,
,
,
n
n
n
n
n,
,
[(
[
])(
n
i j
i
i
j
E X
E X
X
E
=
−
−
s.t. σ
[
])]
Xj

(8.35)
Each of the elements along the main diagonal represents the covariance of a ran-
dom variable with itself, which is simply that variable’s variance. For the off-­diagonal 
elements, because σi,j = σj,i, the covariance matrix is necessarily symmetrical.
If the covariance matrix satisfies certain minimum requirements, we can decom-
pose the covariance matrix, rewriting it in terms of a lower triangular matrix, L, and 
its transpose, L′, which is an upper triangular matrix:
	
′
∑= LL 
(8.36)
This is what is known as a Cholesky decomposition.
It turns out that if we take the matrix L from our Cholesky decomposition and 
multiply it by a vector of i.i.d. standard normal variables, we will obtain a new vec-
tor of normal variables that satisfy the original covariance matrix, Σ. To see why this 
is the case, designate an N × 1 vector of i.i.d. standard normal variables as Φ, and 
the resulting product as C:
	
L
C
Φ =

(8.37)
As with any matrix product, we can write any element of C as follows:
	
c
l
i
j
N
i j i
=
=∑
1
, φ 
(8.38)

166
Mathematics and Statistics for Financial Risk Management
We can see that the ci’s are normally distributed random variables, because each is 
a linear combination of independent normal variables; furthermore, it is easy to see 
that the expected value of each ci is zero:
	
E c
l
E
l
E
l
i
i
m m
m
N
i m
m
m
N
i
[
]
]
[
,
,
,
=
=
=
=
=
∑
∑
ϕ
ϕ
1
1
m
j
N
⋅
=
=∑
0
0
1

(8.39)
For the last step, we were able to set E
m
[
]
φ
 equal to zero, since the mean of any 
standard normal variable is zero by definition.
Now that we have the means of each of the ci’s, we can easily calculate the co-
variance between any two elements:
	
Cov
Cov
[
]
[
]
[
] [
]
[
]
[
c c
E c c
E c E c
E c c
c c
i j
i j
i
j
i j
i
−
=
=
j
i m m
m
N
j n n
n
N
i j
E
l
l
c c
]
[
]
,
,
=
=
=
=
∑
∑
ϕ
ϕ
1
1
Cov
E
l
l
l
l
i m j m m
m
N
i m j n m n
n m
m
N
,
,
,
, ϕ
ϕ
ϕ
2
1
1
+
≠
=
= ∑
∑
∑
=
+
=∑
Cov[
]
[
]
,
,
,
,
c c
l
l
E
l
l
E
i k
i m j m
m
m
N
i m j n
ϕ2
1
[
]
[
[
]
,
,
ϕ
ϕ
n
m
n m
m
N
i j
i m j m
m
N
c c
l
l
l
≠
=
=
∑
∑
∑
=
+
⋅
1
1
1
Cov
i m j n
n m
m
N
i k
i m j m
m
N
l
c c
l
l
,
,
,
,
[
]
⋅
≠
=
=
∑
∑
∑
=
=
0
1
1
Cov
σi k
,

(8.40)
For the second to last row we relied on the fact that the variance of a standard 
normal variable is 1, and the covariance between any two i.i.d. variables is, by defini-
tion, 0. The last line follows from our initial decomposition of Σ into LL′.
Given Σ, how do we go about getting L and L′ in the first place, though? Many 
statistical packages will perform a Cholesky decomposition, and, in practice, that 
might be the best solution. That said, there is a simple algorithm that can be used to 
perform the decomposition. Given our covariance matrix Σ, with entries σi,j, we can 
calculate entries in L, li,j, proceeding row by row, from left to right:
	
l
l
l
l
l
l
i i
i i
i m
m
i
i j
j j
i j
i m j
,
,
,
,
,
,
,
=
−
=
−
=
−
∑
σ
σ
2
1
1
1
,
,
m
m
j
i j
j
i
l
i
j
=
−
∑
∀>
=
∀<
1
1
0

(8.41)

Matrix Algebra
167
Sample Problem
Question:
Given the following covariance matrix, Σ, develop a set of equations that con-
verts three uncorrelated normal variables into three correlated normal variables:
16
8
12
8
29
26
12
26
61
∑=
Answer:
We can use our Cholesky algorithm to calculate the entries of a lower 
triangular matrix, L:
l
l
l
l
1 1
2 1
2 2
2
3 1
16
4
1
4 8
2
29
2
5
1
4 12
,
,
,
,
( )
(
=
=
=
=
=
−
=
=
)
(
)
,
,
=
=
−
=
=
−
−
=
⋅
3
1
5 26
3 2
4
61
3
4
6
3 2
3 3
2
2
l
l
Next, place the entries in a matrix:
L =
4
0
0
2
5
0
3
4
6
Given a vector of three uncorrelated standard normal variables, Φ, and 
using Equation 8.37,
L
C
Φ =
we can create a vector of correlated random variables, C. The elements of C 
are:
c
c
c
1
1
2
1
2
3
1
2
3
4
2
5
3
4
6
=
=
+
=
+
+
φ
φ
φ
φ
φ
φ

168
Mathematics and Statistics for Financial Risk Management
Problems
	 1.	Given the following matrices, what is A + B? BC? CB?
B
A
C
= −
=
=
−
−
10
8
9
7
2
1
9
1
5
10
7
7
	 2.	Using the same matrices from problem 1, what is B + (A + C)? What is B(A – C)?
	 3.	Using the same matrices from problem 1, what is the transpose of A? Of C?
	 4.	Given the following matrices, what is F + G? FG′? F′G?
G
F =
−
−
−
−
=
−
−
−
6
8
6
1
2
3
5
0
8
0
1
7
	 5.	Given the following matrices, what is UI? I2? U2? AU?
U
A
I
=
−
=
=
 
 
  
  
  
10
8
9
7
1
1
1
1
1
0
0
1
	 6.	Given the following matrices, prove that J is the inverse of K.
J
K
=
= −
−
4
9
1
2
2
9
1
4
   
  
  
	 7.	Given the matrix M, what is M5?
M = 2
0
0
2
	 8.	You are the risk manager for a large corporate bond portfolio. At the start of the 
year, 60% of the bonds in the portfolio are rated A, and 40% are rated B. Given 
the following one-year rating transition matrix, what is the expected distribu-
tion of ratings after one year?
1-Year
To
A 
B 
C 
D
From
A 
95% 
4% 
1%
0%
B
10%
85%
4%
1%
C
0% 
20%
65%
15%
D 
0% 
0%
0%
100%
	 9.	Using the one-year rating transition matrix from the previous question, calculate 
the corresponding two-year transition matrix.
	10.	Calculate the Cholesky decomposition for the following covariance matrix:
∑=
4
14
16
14
50
58
16
58
132

169
I
n this chapter we introduce the concept of vector spaces. At the end of the chap-
ter we introduce principal component analysis and explore its application to risk 
management.
Vectors Revisited
In the previous chapter we stated that matrices with a single column could be re-
ferred to as vectors. While not necessary, it is often convenient to represent vectors 
graphically. For example, the elements of a 2 × 1 matrix can be thought of as repre-
senting a point or a vector in two dimensions,1 as shown in Exhibit 9.1.
	
v1 = 10
2 	
(9.1)
Similarly, a 3 × 1 matrix can be thought of as representing a point or vector in 
three dimensions, as shown in Exhibit 9.2.
	
v2 =
5
10
4
	
(9.2)
While it is difficult to visualize a point in higher dimensions, we can still speak 
of an n × 1 vector as representing a point or vector in n dimensions, for any positive 
value of n.
In addition to the operations of addition and scalar multiplication that we ex-
plored in the previous chapter, with vectors we can also compute the Euclidean inner 
product, often simply referred to as the inner product. For two vectors, the Euclidean 
1 In physics, a vector has both magnitude and direction. In a graph, a vector is represented 
by an arrow connecting two points, the direction indicated by the head of the arrow. In risk 
management, we are unlikely to encounter problems where this concept of direction has any 
real physical meaning. Still, the concept of a vector can be useful when working through the 
problems. For our purposes, whether we imagine a collection of data to represent a point or 
a vector, the math will be the same.
chapter 9     
Vector Spaces

170
Mathematics and Statistics for Financial Risk Management
Exhibit 9.1 
Two-Dimensional Vector
–10
–5
0
5
10
–10
–5
0
5
10
Exhibit 9.2 
Three-Dimensional Vector
y
x
z

Vector Spaces
171
inner product is defined as the sum of the product of the corresponding elements in 
the vector. For two vectors, a and b, we denote the inner product as a ∙ b:
	
a b⋅
=
+
+
+
a b
a b
a b
n n
1 1
2 2

	
(9.3)
We can also refer to the inner product as a dot product, so referred to because of 
the dot between the two vectors.2 The inner product is equal to the matrix multipli-
cation of the transpose of the first vector and the second vector:
	
a b
a b
⋅
= ′
	
(9.4)
We can use the inner product to calculate the length of a vector. To calculate the 
length of a vector, we simply take the square root of the inner product of the vector 
with itself:
	
||
||
a
a a
=
⋅
	
(9.5)
The length of a vector is alternatively referred to as the norm, the Euclidean length, 
or the magnitude of the vector.
Every vector exists within a vector space. A vector space is a mathematical 
construct consisting of a set of related vectors that obey certain axioms. For the 
interested reader, a more formal definition of a vector space is provided in Appendix 
C. In risk management we are almost always working in a space Rn, which consists 
of all of the vectors of length n, whose elements are real numbers.
2 In physics and other fields, the inner product of two vectors is often denoted not with a 
dot, but with pointy brackets. Under this convention, the inner product of a and b would be 
denoted <a,b>. The term dot product can be applied to any ordered collection of numbers, 
not just vectors, while an inner product is defined relative to a vector space. For our purposes, 
when talking about vectors, the terms can be used interchangeably.
Sample Problem
Question:
Given the following vectors in R3,
b
a
c
= −
=
=
5
2
4
10
6
1
4
0
4
find the following:
1.	 a ⋅ b
2.	 b ⋅ c
3.	 The magnitude of c

172
Mathematics and Statistics for Financial Risk Management
Orthogonality
We can use matrix addition and scalar multiplication to combine vectors in a linear 
combination. The result is a new vector in the same space. For example, in R4, com-
bining three vectors, v, w, and x, and three scalars, s1, s2, and s3, we get y:
	
s
s
s
s
v
v
v
v
s
w
w
w
1
2
1
3
1
2
3
4
2
1
2
3
v
w
x
+
+
=
+
w
s
x
x
x
x
y
y
4
3
1
2
3
4
1
2
+
= y
y
3
4
= y	
(9.6)
Rather than viewing this equation as creating y, we can read the equation in reverse, 
and imagine decomposing y into a linear combination of other vectors.
A set of n vectors, v1, v2, .  .  ., vn, is said to be linearly independent if, and only if, 
given the scalars c1, c2, .  .  ., cn, the solution to the equation:
	
c
c
cn
n
1 1
2
2
0
v
v
v
+
+
+
=

	
(9.7)
has only the trivial solution, c1 = c2 = .  .  . = cn = 0. A corollary to this definition is that 
if a set of vectors is linearly independent, then it is impossible to express any vector 
in the set as a linear combination of the other vectors in the set.
Sample Problem
Question:
Given a set of linear independent vectors, S = {v1, v2, .  .  ., vn}, and a set of 
constants, c1, c2, .  .  ., cn, prove that the equation:
c
c
cn
n
1 1
2
2
0
v
v
v
+
+
+
=
...
has a nontrivial solution if any of the vectors in S can be expressed as a linear 
combination of the other vectors in the set.
Answer:
1.	 a b⋅
⋅
⋅
⋅
=
+ −
+
=
5 10
2
6
4 1
42
(
)
2.	 b c⋅
⋅
⋅
⋅
=
+
+
=
10 4
6 0
1 4
44
3.	 ||
||
c
c c
=
=
+
+
=
=
⋅
⋅
⋅
⋅
4 4
0 0
4 4
32
4 2

Vector Spaces
173
We can use the concept of linear independence to define a basis for a vector 
space, V. A basis is a set of linearly independent vectors, S = {v1, v2,  .  .  ., vn}, such that 
every vector within V can be expressed as a unique linear combination of the vectors 
in S. As an example, we provide the following set of two vectors, which form a basis, 
B1 = {v1, v2}, for R2:
	
v
v1 =
=
1
0
0
1
2
	
(9.8)
Answer:
Let us start by assuming that the first vector, v1, can be expressed as a 
­linear combination of the vectors v2, v3,  .  .  ., vm, where m < n; that is:
v
v
v
1
2
2
=
+
+
k
kn
m

where k2,  .  .  ., kn, are constants. We can rearrange this equation as:
v
v
v
1
2
2
0
−
−
−
=
k
kn
m

Now if we set all the constants, cm+1, cm+2,  .  .  ., cn, to zero, for the other 
­vectors we have:
c
c
c
m
m
m
m
n
n
+
+
+
+
+
+
+
=
1
1
2
2
0
v
v
v

Combining the two equations, we have:
v
v
v
v
v
1
2
2
1
1
0
0
0
−
−
−
+
+
+
=
+
=
+
+
k
k
c
c
m
m
m
m
n
n


This then is a nontrivial solution for the original equation. In terms of the 
original constants, the solution is:
c
c
k c
k
c
k
c
c
c
m
m
m
m
1
2
2
3
3
1
2
1
0
0
=
= −
= −
= −
=
=
+
+
,
,
,
,
,
,
…
…
n = 0
Moreover, this is a general proof, and not limited to the case where v1 can 
be expressed as a linear combination of v2, v3,  .  .  ., vm. Because matrix addition 
is commutative, the order of the addition is not important. The result would 
have been the same if any one vector had been expressible as a linear combina-
tion of any subset of the other vectors.

174
Mathematics and Statistics for Financial Risk Management
First, note that the vectors are linearly independent. We cannot multiply either 
vector by a constant to get the other vector. Next, note that any vector in R2, [x y]′, 
can be expressed as a linear combination of the two vectors:
	
x
y
y
x
+
=
v
v1
2
(9.9)
The scalars on the right-hand side of this equation, x and y, are known as the 
coordinates of the vector. We can arrange these coordinates in a vector to form a 
coordinate vector.
	
c =
=
c
c
x
y
1
2

(9.10)
In this case, the vector and the coordinate vector are the same, but this need not 
be the case.
As another example, take the following basis, B2 = {w1, w2}, for R2:
	
w
w1 =
=
7
0
0
10
2

(9.11)
These vectors are still linearly independent, and we can create any vector, [x y]′, from 
a linear combination of w1 and w2. In this case, however, the coordinate vector is not 
the same as the original vector. To find the coordinate vector, we solve the following 
equation for c1 and c2 in terms of x and y:
	
x
y
c
c
c
c
=
+
=
+
=
1
2
1
2
2
7
0
0
10
7
w
w
1
c
c
1
2
10

(9.12)
Therefore, x = 7c1 and y = 10c2. Solving for c1 and c2, we get our coordinate vector 
relative to the new basis:
	
c =
=
c
c
x
y
1
2
7
10

(9.13)
Finally, the following set of vectors, B3 = {x1, x2}, would also be a legitimate basis 
for R2:
	
x
x1 =
=
1
2
1
2
0
1
2

(9.14)
These vectors are also linearly independent. For this third basis, the coordinate vec-
tor for a vector, [x y]′, would be:
	
c =
−
2x
x
y

(9.15)
Of the three bases, is one preferable to the others? We can’t really say that one 
basis is the best—this would be subjective—but we can describe certain features of a 
basis, which may make them more or less interesting in certain applications.

Vector Spaces
175
The first way to characterize a basis is to measure the length of its vectors. Note 
that the vectors in B2 are really just scalar multiples of the vector in B1.
	
=
=
w
v
w
v
7
10
1
1
2
2
	
(9.16)
This is not a coincidence. For any vector space, we can create a new basis 
simply by multiplying some or all the vectors in one basis by nonzero scalars. 
Multiplying a vector by a scalar doesn’t change the vector’s orientation in space; 
it just changes the vector’s length. We can see this if we plot both sets of vectors as 
in Exhibit 9.3.
If the lengths of the vectors in a basis don’t matter, then one logical choice is to 
set all the vectors to unit length, ||v|| = 1. A vector of unit length is said to be normal 
or normalized.
The second way to characterize a basis has to do with how the vectors in the 
basis are oriented with respect to each other. The vectors in B3 are also of unit 
length, but, as we can see in Exhibit 9.4, if we plot the vectors, the vectors in B1 
are at right angles to each other, whereas the vectors in B3 form a 45-degree angle.
When vectors are at right angles to each other, we say that they are orthogonal 
to each other. One way to test for orthogonality is to calculate the inner product 
between two vectors. If two vectors are orthogonal, then their inner product will be 
equal to zero. For B1 and B3, then:
	
v
v
x
x
1
2
1
2
1 0
0 1
0
1
2
0
1
2
1
1
2
⋅
⋅
⋅
⋅
⋅
⋅
=
+
=
=
+
=
	
(9.17)
Exhibit 9.3 
Vectors with Same Orientation but Different Lengths
–2
0
2
4
6
8
10
–2
0
2
4
6
8
10
v1
v2
w1
w2

176
Mathematics and Statistics for Financial Risk Management
While it is easy to picture vectors being orthogonal to each other in two or 
three dimensions, orthogonality is a general concept, extending to any number of 
dimensions. Even if we can’t picture it in higher dimensions, if two vectors are or-
thogonal, we still describe them as being at right angles, or perpendicular to each 
other.
In many applications it is convenient to work with a basis where all the vec-
tors in the basis are orthogonal to each other. When all of the vectors in a basis 
are of unit length and all are orthogonal to each other, we say that the basis is 
orthonormal.
Exhibit 9.4 
Orthogonal and Nonorthogonal Vectors
B3
–1
1
–1
1
B1
–1
1
–1
1

Vector Spaces
177
Rotation
In the preceding section, we saw that the following set of vectors formed an ortho-
normal basis for R2:
	
v
v1 =
=
1
0
0
1
2
	
(9.18)
This basis is known as the standard basis for R2. In general, for the space Rn, the 
standard basis is defined as the set of vectors:
	
v
v
v
2
1
1
0
0
0
1
0
0
=
=
=
n
0
1
	
(9.19)
where the ith element of the ith vector is equal to one, and all other elements are 
zero. The standard basis for each space is an orthonormal basis. The standard bases 
are not the only orthonormal bases for these spaces, though. For R2, the following is 
also an orthonormal basis:
	
z
z
2
1 =
=
−
1
2
1
2
1
2
1
2
	
(9.20)
Sample Problem
Question:
Prove that the following basis is orthonormal:
	
z
z
2
1 =
=
−
1
2
1
2
1
2
1
2

(9.21)
Answer:
First, we show that the length of each vector is equal to one:
	
||
||
||
||
z
z
z
z
z
z
1
1
1
2
2
=
=
=
+
=
+
=
=
⋅
⋅
1
2
1
2
1
2
1
2
1
2
1
2
1
1
2
−
=
−
=
+
=
+
=
1
2
1
2
1
2
1
2
1
2
1
2
1
1

(9.22)

178
Mathematics and Statistics for Financial Risk Management
The difference between the standard basis for R2 and our new basis can be 
viewed as a rotation about the origin, as shown in Exhibit 9.5.
It is common to describe a change from one orthonormal basis to another as a 
rotation in higher dimensions as well.
It is often convenient to form a matrix from the vectors of a basis, where each col-
umn of the matrix corresponds to a vector of the basis. If the vectors v1, v2, .  .  ., vn form 
an orthonormal basis, and we denote the jth element of the ith vector, vi, as vi,j, we have:
	
v
V
v
v2
1
=
]
[
=
n
v
v
v
v
v
v
v
v
n
n
n
v
11
21
1
21
22
2
1
2
vnn

(9.24)
Exhibit 9.5 
Basis Rotation
–1
1
–1
1
Next, we show that the two vectors are orthogonal to each other, by show-
ing that their inner product is equal to zero:
	
z
z
2
1⋅
−
=
=
+
−
+
=
1
2
1
2
1
2
1
2
1
2
1
2
0
(9.23)
All of the vectors are of unitary length and are orthogonal to each other; 
therefore, the basis is orthonormal.

Vector Spaces
179
For an orthonormal basis, this matrix has the interesting property that its trans-
pose and its inverse are the same.
	
′ =
=
−
VV
VV
I
1

(9.25)
The proof is not difficult. If we multiply V by its transpose, every element along 
the diagonal is the inner product of a basis vector with itself. This is just the length 
of the vector, which by definition is equal to one. The off-diagonal elements are the 
inner product of different vectors in the basis with each other. Because they are or-
thogonal, these inner products will be zero. In other words, the matrix that results 
from multiplying V by V′ is the identity matrix, so V′ must be the inverse of V.
This property makes calculating the coordinate vector for an orthonormal basis 
relatively simple. Given a vector x of length n, and the matrix V, whose columns 
form an orthonormal basis in Rn, the corresponding coordinate vector can be found 
as follows:
	
=
=
′
−
c
V
x
V x
1
	
(9.26)
The first part of the equation, c = V–1x, would be true even for a nonorthonormal basis.
Rather than picture the basis as rotating and the vector as remaining still, it 
would be equally valid to picture a change of basis as a rotation of a vector, as in 
Exhibit 9.6.
If we premultiply both sides of this Equation 9.26 by V, we have Vc = V V′x = 
Ix = x. In other words, if V′ rotates x into the new vector space, then multiplying 
by V performs the reverse transformation, rotating c back into the original vector 
space. It stands to reason that V′ is also an orthonormal basis. If the vectors of a 
matrix form an orthonormal basis in Rn, then the rows of that matrix also form an 
orthonormal basis in Rn. It is also true that if the columns of a square matrix are 
orthogonal, then the rows are orthogonal, too. Because of this, rather than saying 
the columns and rows of a matrix are orthogonal or orthonormal, it is enough to say 
that the matrix is orthogonal or orthonormal.
Sample Problem
Question:
Given the following basis for R2,
z
z
2
1 =
=
−
1
2
1
2
1
2
1
2
find the coordinate vector for the vector x, where x′ = [9 4].

180
Mathematics and Statistics for Financial Risk Management
Answer:
c
Z x =
=
−
=
−
′
1
2
1
2
1
2
1
2
9
4
13
2
5
2
We can verify this result as follows:
c
c
2
1
13
2
1
2
1
2
5
2
1
2
1
2
z
z
2
1
=
+
−
−
=
+
+
−
=
c
c
2
1
13
2
5
2
13
2
5
2
z
z
2
1
9
4 = x
Exhibit 9.6 
Change of Basis
–2
0
2
4
6
–2
0
2
4
6
–2
0
2
4
6
–2
0
2
4
6

Vector Spaces
181
Exhibit 9.7 
Fund Returns Using Standard Basis
–20%
–10%
0%
10%
20%
–20%
–10%
0%
10%
20%
X
Y
Principal Component Analysis
For any given vector space, there is potentially an infinite number of orthonormal 
bases. Can we say that one orthonormal basis is better than another? As before, the 
decision is ultimately subjective, but there are factors we could take into considera-
tion when trying to decide on a suitable basis. Due to its simplicity, the standard basis 
would seem to be an obvious choice in many cases. Another approach is to choose 
a basis based on the data being considered. This is the basic idea behind principal 
component analysis (PCA). In risk management, PCA can be used to examine the 
underlying structure of financial markets. Common applications, which we explore 
at the end of the chapter, include the development of equity indexes for factor analy-
sis, and describing the dynamics of yield curves.
In PCA, a basis is chosen so that the first vector in the basis, now called the first 
principal component, explains as much of the variance in the data being considered 
as possible. For example, we have plotted annual returns over 10 years for two hedge 
funds, Fund X and Fund Y, in Exhibit 9.7 using the standard basis and in Exhibit 9.8 
using an alternative basis. The returns are also presented in Exhibit 9.9. As can be 
seen in the chart, the returns in Exhibit 9.7 are highly correlated. On the right-hand 
side of Exhibit 9.9 and in Exhibit 9.8, we have transformed the data using the basis 
from the previous example (readers should verify this). In effect, we’ve rotated the 
data 45 degrees. Now almost all of the variance in the data is along the X′-axis.
By transforming the data, we are calling attention to the underlying structure of the 
data. In this case, the X and Y data are highly correlated, and almost all of the variance 
in the data can be described by variance in X′, our first principal ­component. It might 
be that the linear transformation we used to construct X′ ­corresponds to an underlying 
process, which is generating the data. In this case, maybe both funds are invested in 
some of the same securities, or maybe both funds have similar investment styles.

182
Mathematics and Statistics for Financial Risk Management
Exhibit 9.9 
Change of Basis
Standard Basis
Alternative Basis
s
s
2
1
1
0
0
1
=
=
z
z
2
1
=
=
1
1
1
1
2
2
2
2
t
X
Y
  t
X′
Y′
1
13.00%
13.00%
  1
18.38%
0.00%
2
9.00%
10.00%
  2
13.44%
0.71%
3
10.00%
9.00%
  3
13.44%
−0.71%
4
6.00%
8.00%
  4
9.90%
1.41%
5
8.00%
6.00%
  5
9.90%
−1.41%
6
−13.00%
−13.00%
  6
−18.38%
0.00%
7
−9.00%
−10.00%
  7
−13.44%
−0.71%
8
−10.00%
−9.00%
  8
−13.44%
0.71%
9
−6.00%
−8.00%
  9
−9.90%
−1.41%
10
−8.00%
−6.00%
10
−9.90%
1.41%
Mean
0.00%
0.00%
Mean
0.00%
0.00%
Variance
1.00%
1.00%
Variance
1.99%
0.01%
Std. dev.
10.00%
10.00%
Std. dev.
14.10%
1.05%
Exhibit 9.8 
Fund Returns Using Alternative Basis
–20%
–10%
0%
10%
20%
–20%
–10%
0%
10%
20%
X'
Y'

Vector Spaces
183
The transformed data can also be used to create an index to analyze the origi-
nal data. In this case, we could use the transformed data along the first principal 
­component as our index (possibly scaled). This index could then be used to bench-
mark the performances of both funds.
Tracking the index over time might also be interesting, in and of itself. For a 
summary report, we might not need to know how each fund is performing. With 
the index, rather than tracking two data points every period, we only have to track 
one. This reduction in the number of data points is an example of dimensionality 
reduction. In effect we have taken what was a two-dimensional problem (tracking 
two funds) and reduced it to a one-dimensional problem (tracking one index). Many 
problems in risk management can be viewed as exercises in dimensionality reduc-
tion—taking complex problems and simplifying them.
Sample Problem
Question:
Using the first principal component from the previous example, construct 
an index with the same standard deviation as the original series. Calculate the 
tracking error of each fund in each period.
Answer:
In order to construct the index, we simply multiply each value of the first 
component of the transformed data, X′, by the ratio of the standard devia-
tion of the original series to X′: 10.00%/14.10%. The tracking error for the 
original series is then found by subtracting the index values from the original 
series.
Index
Error[X]
Error[Y]
13.04%
−0.04%
−0.04%
9.53%
−0.53%
0.47%
9.53%
0.47%
−0.53%
7.02%
−1.02%
0.98%
7.02%
0.98%
−1.02%
−13.04%
0.04%
0.04%
−9.53%
0.53%
−0.47%
−9.53%
−0.47%
0.53%
−7.02%
1.02%
−0.98%
−7.02%
−0.98%
1.02%
Mean
0.00%
0.00%
0.00%
Variance
1.00%
0.01%
0.01%
Std. dev.
10.00%
0.75%
0.75%

184
Mathematics and Statistics for Financial Risk Management
We can easily extend the concept of PCA to higher dimensions using the 
techniques we have covered in this chapter. In higher dimensions, each successive 
principal component explains the maximum amount of variance in the residual 
data, after taking into account all of the preceding components. Just as the first 
principal component explained as much of the variance in the data as possible, 
the second principal component explains as much of the variance in the residu-
als, after taking out the variance explained by the first component. Similarly, 
the third principal component explains the maximum amount of variance in 
the residuals, after taking out the variance explained by the first and second 
components.
Now that we understand the properties of principal components, how do we 
actually go about calculating them? A general approach to PCA involves three steps:
	 1.	Transform the raw data.
	 2.	Calculate a covariance matrix of the transformed data.
	 3.	Decompose the covariance matrix.
Assume we have a T × N matrix of data, where each column represents a dif-
ferent random variable, and each row represents a set of observations of those vari-
ables. For example, we might have the daily returns of N different equity indexes 
over T days. The first step is to transform the data so that the mean of each series is 
zero. This is often referred to as centering the data. To do this, we simply calculate 
the mean of each series and subtract that value from each point in that series. In 
certain situations we may also want to standardize the variance of each of the series. 
To do this, we calculate the standard deviation of each series, and divide each point 
in the series by that value. Imagine that one of our series is much more volatile than 
all of the other series. Because PCA is trying to account for the maximum amount of 
variance in the data, the first principal component might be dominated by this highly 
volatile series. If we want to call attention to the relative volatility of different series, 
this may be fine and we do not need to standardize the variance. However, if we are 
more interested in the correlation between the series, the high variance of this one 
series would be a distraction, and we should fully standardize the data.
Next, we need to calculate the covariance matrix of our transformed data. De-
note the T × N matrix of transformed data as X. Because the data is centered, the 
covariance matrix, Σ, can be found as follows:
	
1
N X X
′
∑=

(9.27)
Here we assume that we are calculating the population covariance, and divide by N. 
If instead we wish to calculate the sample covariance, we can divide by (N − 1). If we 
had standardized the variance of each series, then this matrix would be equivalent to 
the correlation matrix of the original series.
For the third and final step, we need to rely on the fact that Σ is a symmetrical 
matrix. It turns out that any symmetrical matrix, where all of the entries are real num-
bers, can be diagonalized; that is, it can be expressed as the product of three matrices:
	
PDP′
∑=

(9.28)

Vector Spaces
185
where the N × N matrix P is orthonormal, and the N × N matrix D is diagonal.3 
Combining the two equations and rearranging, we have:
	
′ =
′
=
−
N
X
PDP X
PDM
1
	
(9.29)
where M = NP ′ X–1. If we order the column vectors of P so that the first column 
explains most of the variance in X, the second column vector explains most of the 
residual variance, and so on, then this is the PCA decomposition of X. The column 
vectors of P are now viewed as the principal components, and serve as the basis for 
our new vector space.
To transform the original matrix X, we simply multiply by the matrix P:
	
=
Y
XP 	
(9.30)
As we will see in the following application sections, the values of the elements of 
the matrix, P, often hint at the underlying structure of the original data.
Application: The Dynamic Term Structure of Interest Rates
A yield curve plots the relationship between yield to maturity and time to maturity 
for a given issuer or group of issuers. A typical yield curve is concave and upward-
sloping. An example is shown in Exhibit 9.10.
Over time, as interest rates change, the shape of the yield curve will change, too. 
At times, the yield curve can be close to flat, or even inverted (downward-sloping). 
Examples of flat and inverted yield curves are shown in Exhibits 9.11 and 9.12.
Because the points along a yield curve are driven by the same or similar 
fundamental factors, they tend to be highly correlated. Points that are closer to-
gether on the yield curve and have similar maturities tend to be even more highly 
correlated.
Because the points along the yield curve tend to be highly correlated, the ways 
in which the yield curve can move are limited. Practitioners tend to classify move-
ments in yield curves as a combination of shifts, tilts, or twists. A shift in the yield 
curve occurs when all of the points along the curve increase or decrease by an equal 
amount. A tilt occurs when the yield curve either steepens (points further out on the 
curve increase relative to those closer in) or flattens (points further out decrease rela-
tive to those closer in). The yield curve is said to twist when the points in the middle 
of the curve move up or down relative to the points on either end of the curve. 
Exhibits 9.13, 9.14, and 9.15 show examples of these dynamics.
These three prototypical patterns—shifting, tilting, and twisting—can often be 
seen in PCA. The following is a principal component matrix obtained from daily U.S. 
government rates from March 2000 through August 2000. For each day, there were 
3 We have not formally introduced the concept of eigenvalues and eigenvectors. For the reader 
familiar with these concepts, the columns of P are the eigenvectors of Σ, and the entries along 
the diagonal of D are the corresponding eigenvalues. For small matrices, it is possible to calcu-
late the eigenvectors and eigenvalues by hand. In practice, as with matrix inversion, for large 
matrices this step almost always involves the use of commercial software packages.

186
Mathematics and Statistics for Financial Risk Management
Exhibit 9.11 
Flat Yield Curve
2%
3%
4%
5%
6%
7%
0
5
10
15
20
25
30
Exhibit 9.10 
Upward-Sloping Yield Curve
2%
3%
4%
5%
6%
7%
0
5
10
15
20
25
30

Vector Spaces
187
Exhibit 9.12 
Inverted Yield Curve
2%
3%
4%
5%
6%
7%
0
5
10
15
20
25
30
Exhibit 9.13 
Shift
2%
3%
4%
5%
6%
7%
0
5
10
15
20
25
30

188
Mathematics and Statistics for Financial Risk Management
Exhibit 9.15 
Twist
2%
3%
4%
5%
6%
7%
0
5
10
15
20
25
30
Exhibit 9.14 
Tilt
2%
3%
4%
5%
6%
7%
0
5
10
15
20
25
30

Vector Spaces
189
six points on the curve representing maturities of 1, 2, 3, 5, 10, and 30 years. Before 
calculating the covariance matrix, all of the data were centered and standardized.
=
−
−
−
−
−
−
−
−
−
−
−
−
−
−
P
0.39104
0.53351
0.61017
0.33671
0.22609
0.16020
0.42206
0.26300
0.03012
0.30876
0.26758
0.76476
0.42685
0.16318
0.19812
0.35626
0.49491
0.61649
0.42853
0.01135
0.46043
0.17988
0.75388
0.05958
0.41861
0.29495
0.31521
0.75553
0.24862
0.07604
0.35761
0.72969
0.52554
0.24737
0.04696
0.00916
 (9.31)
The first column of the matrix is the first principal component. Notice that all of 
the elements are positive and of similar size. We can see this if we plot the elements 
in a chart, as in Exhibit 9.16. This flat, equal weighting represents the shift of the 
yield curve. A movement in this component increases or decreases all of the points 
on the yield curve by the same amount (actually, because we standardized all of the 
data, it shifts them in proportion to their standard deviation). Similarly, the second 
principal component shows an upward trend. A movement in this component tends 
to tilt the yield curve. Finally, if we plot the third principal component, it is bowed, 
high in the center and low on the ends. A shift in this component tends to twist the 
yield curve.
Exhibit 9.16 
First Three Principal Components of the Yield Curve
–0.80
–0.60
–0.40
–0.20
0.00
0.20
0.40
0.60
0.80
1
2
3
5
10
30
1
2
3

190
Mathematics and Statistics for Financial Risk Management
Exhibit 9.17 
Actual and Approximate 1-Year Rates
3.0%
3.5%
4.0%
4.5%
5.0%
5.5%
6.0%
6.5%
3/20/00
6/20/00
9/20/00
12/20/00
3/20/01
6/20/01
Actual 1
Approximate 1
It’s worth pointing out that, if we wanted to, we could change the sign of any 
principal component. That is, we could multiply all of the elements in one column 
of the principal component matrix, P, by −1. As we saw previously, we can always 
multiply a vector in a basis by a nonzero scalar to form a new basis. Multiplying by 
−1 won’t change the length of a vector, just the direction; therefore, if our original 
matrix is orthonormal, the matrix that results from changing the sign of one or more 
columns will still be an orthonormal matrix. Normally, the justification for doing 
this is purely aesthetic. For example, our first principal component could be com-
posed of all positive elements or all negative elements. The analysis is perfectly valid 
either way, but many practitioners would have a preference for all positive elements.
Not only can we see the shift, tilt, and twist in the principal components, but we 
can also see their relative importance in explaining the variability of interest rates. In 
this example, the first principal component explains 90% of the variance in interest 
rates. As is often the case, these interest rates are highly correlated with each other, 
and parallel shifts explain most of the evolution of the yield curve over time. If we 
incorporate the second and third principal components, fully 99.9% of the variance 
is explained. The two charts in Exhibits 9.17 and 9.18 show approximations to the 
1-year and 30-year rates, using just the first three principal components. The dif-
ferences between the actual rates and the approximations are extremely small. The 
actual and approximate series are almost indistinguishable.
Because the first three principal components explain so much of the dynamics of 
the yield curve, they could serve as a basis for an interest rate model or as the basis 
for a risk report. A portfolio’s correlation with these principal components might 
also be a meaningful risk metric. We explore this idea in more depth in our discus-
sion of factor analysis in Chapter 10.

Vector Spaces
191
Application: The Structure of Global Equity Markets
Principal component analysis can be used in many different ways when analyzing 
equity markets. At the highest level, we can analyze the relationship between dif-
ferent market indexes in different countries. Global equity markets are increasingly 
linked. Due to similarities in their economies or because of trade relationships, eq-
uity markets in different countries will be more or less correlated. PCA can highlight 
these relationships.
Within countries, PCA can be used to describe the relationships between groups of 
companies in industries or sectors. In a novel application of PCA, Kritzman, Li, Page, 
and Rigobon (2010) suggest that the amount of variance explained by the first princi-
pal components can be used to gauge systemic risk within an economy. The basic idea 
is that as more and more of the variance is explained by fewer and fewer principal com-
ponents, the economy is becoming less robust and more susceptible to systemic shocks. 
In a similar vein, Meucci (2009) proposes a general measure of portfolio diversification 
based in part on principal component analysis. In this case, a portfolio can range from 
undiversified (all the variance is explained by the first principal component) to fully 
diversified (each of the principal components explains an equal amount of variance).
In many cases, PCA analysis of equity markets is similar to the analysis of yield 
curves: The results are simply confirming and quantifying structures that we already 
believed existed. PCA can be most interesting, however, when it points to relation-
ships that we were previously unaware of. For example, as the economy changes 
over time, new industries form and business relationships change. We can perform 
PCA on individual stocks to try to tease out these relationships.
Exhibit 9.18 
Actual and Approximate 30-Year Rates
3.0%
3.5%
4.0%
4.5%
5.0%
5.5%
6.0%
6.5%
3/20/00
6/20/00
9/20/00
12/20/00
3/20/01
6/20/01
Actual 30
Approximate 30

192
Mathematics and Statistics for Financial Risk Management
The following matrix is the principal component matrix formed from the analy-
sis of nine broad equity market indexes, three each from North America, Europe, 
and Asia. The original data consisted of monthly log returns from January 2000 
through April 2011. The returns were centered and standardized.
	
=
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
P
0.3604
0.3302
0.3323
0.3520
0.3472
0.3426
0.2844
0.3157
0.3290
0.1257
0.0197
0.2712
0.3821
0.2431
0.4185
0.6528
0.2887
0.1433
0.0716
0.4953
0.3359
0.2090
0.1883
0.1158
0.4863
0.4238
0.3581
0.1862
0.4909
0.2548
0.1022
0.1496
0.0804
0.1116
0.7781
−0.0472
0.1158
2.1320
0.2298
0.1805
0.2024
0.3707
0.4782
0.0365
0.6688
0.1244
0.4577
0.5841
0.0014
0.3918
0.0675
0.0489
0.1590
0.4982
0.4159
0.2073
0.4897
0.2457
0.5264
0.3916
0.1138
0.0459
0.1964
0.7806
0.3189
0.0670
0.0339
0.5277
0.0322
0.0055
0.0548
0.0281
0.0579
0.0689
0.0095
0.7628
0.1120
0.6256
0.0013
0.0141
0.0765
	
(9.32)
As before, we can graph the first, second, and third principal components. In 
Exhibit 9.19, the different elements have been labeled with either N, E, or A for 
North America, Europe, and Asia, respectively.
As before, the first principal component appears to be composed of an approxi-
mately equal weighting of all the component time series. This suggests that these 
equity markets are highly integrated, and most of their movement is being driven by 
Exhibit 9.19 
First Three Principal Components for Equity Indexes
–0.60
–0.40
–0.20
0.00
0.20
0.40
0.60
0.80
N1
N2
N3
E1
E2
E3
A1
A2
A3
1
2
3

Vector Spaces
193
a common factor. The first component explains just over 75% of the total variance 
in the data. Diversifying a portfolio across different countries might not prove as 
risk-reducing as one might hope.
The second factor could be described as long North America and Asia and short 
Europe. Going long or short this spread might be an interesting strategy for some-
body with a portfolio that is highly correlated with the first principal component. 
Because the two components are uncorrelated by definition, investing in both may 
provide good diversification. That said, the pattern for the second principal compo-
nent certainly is not as distinct as the patterns we saw in the yield curve example. 
For the equity indexes, the second component explains only an additional 7% of the 
variance.
By the time we get to the third principal component, it is difficult to posit any 
fundamental rationale for the component weights. Unlike our yield curve example, 
in which the first three components explained 99.9% of the variance in the series, in 
this example the first three components explain only 87% of the total variance. This 
is still a lot, but it suggests that these equity returns are much more distinct.
Trying to ascribe a fundamental explanation to the third and possibly even the 
second principal component highlights one potential pitfall of PCA analysis: iden-
tification. When the principal components account for a large part of the variance 
and conform to our prior expectations, they likely correspond to real fundamental 
risk factors. When the principal components account for less variance and we can-
not associate them with any known risk factors, they are more likely to be spurious. 
Unfortunately, it is these components, which do not correspond to any previously 
known risk factors, which we are often hoping that PCA will identify.
Another closely related problem is stability. If we are going to use PCA for risk 
analysis, we will likely want to update our principal component matrix on a regular 
basis. The changing weights of the components over time might be interesting, illu-
minating how the structure of a market is changing. Unfortunately, nearby compo-
nents will often change place, the second becoming the third and the third becoming 
the second, for example. If the weights are too unstable, tracking components over 
time can be difficult or impossible.
Problems
	 1.	Given the following vectors, a, b, and c, are a and b orthogonal? Are b and c 
orthogonal?
b
a
c
−
=
=
−
=
10
5
4
6
2
4
5
5
10
	 2.	Find x such that A is an orthonormal basis:
A =
x
1
3
1
3
2
2
3

194
Mathematics and Statistics for Financial Risk Management
	 3.	Find x and y such that B is an orthonormal basis:
B =
x
y
1
5
6
2
5
	 4.	Given the following matrix B, whose columns are orthonormal and form a vec-
tor space in R2, find the coordinate vector for the vector x:
x
B =
−
=
1
2
1
2
1
2
1
2
6
4
	 5.	Given the following matrix B, whose columns form a vector space in R3, find the 
coordinate vector for the vector x:
x
B =
−
−
−
=
−
−
2
4
46
1
1
1
8
2
5
37
170
19
165

195
T
his chapter provides a basic introduction to linear regression models. At the end 
of the chapter, we will explore two risk management applications, factor analysis 
and stress testing.
Linear Regression (One Regressor)
One of the most popular models in statistics is the linear regression model. Given 
two constants, α and β, and a random error term, ε, in its simplest form the model 
posits a relationship between two variables, X and Y:
	
Y
X
=
+
+
α
β
ε 	
(10.1)
As specified, X is known as the regressor or independent variable. Similarly, Y is 
known as the regressand or dependent variable. As dependent implies, traditionally 
we think of X as causing Y. This relationship is not necessary, and in practice, es-
pecially in finance, this cause-and-effect relationship is either ambiguous or entirely 
absent. In finance, it is often the case that both X and Y are being driven by a com-
mon underlying factor.
The linear regression relationship is often represented graphically as a plot of 
Y against X, as shown in Exhibit 10.1. The solid line in the chart represents the de-
terministic portion of the linear regression equation, Y = α + βX. For any particular 
point, the distance above or below the line is the error, ε, for that point.
Because there is only one regressor, this model is often referred to as a univari-
ate regression. Mainly, this is to differentiate it from the multivariate model, with 
more than one regressor, which we will explore later in this chapter. While every-
body agrees that a model with two or more regressors is multivariate, not everybody 
agrees that a model with one regressor is univariate. Even though the univariate 
model has one regressor, X, it has two variables, X and Y, which has led some people 
to refer to Equation 10.1 as a bivariate model. The former convention seems to be 
more common within financial risk management. From here on out, we will refer to 
Equation 10.1 as a univariate model.
In Equation 10.1, α and β are constants. In the univariate model, α is typically 
referred to as the intercept, and β is often referred to as the slope. β is referred to as 
chapter 10     
Linear Regression Analysis

196
Mathematics and Statistics for Financial Risk Management
the slope because it measures the slope of the solid line when Y is plotted against X. 
We can see this by taking the derivative of Y with respect to X:
	
dY
dX = β 	
(10.2)
The final term in Equation 10.1, ε, represents a random error, or residual. The 
error term allows us to specify a relationship between X and Y even when that 
relationship is not exact. In effect, the model is incomplete; it is an approximation. 
Changes in X may drive changes in Y, but there are other variables, which we are 
not modeling, that also impact Y. These unmodeled variables cause X and Y to de-
viate from a purely deterministic relationship. That deviation is captured by ε, our 
residual.
In risk management, this division of the world into two parts, a part that can 
be explained by the model and a part that cannot, is a common dichotomy. We refer 
to risk that can be explained by our model as systematic risk, and to the part that 
cannot be explained by the model as idiosyncratic risk. In our regression model, Y 
is divided into a systematic component, α + βX, and an idiosyncratic component, ε.
	
X
Y =
+
+
α
β
systematic
idiosyncratic
ε
	
(10.3)
Which component of the overall risk is more important? It depends on what our 
objective is. As we will see, portfolio managers who wish to hedge certain risks in 
their portfolios are basically trying to reduce or eliminate systematic risk. Portfolio 
Exhibit 10.1 
Linear Regression Example
–20%
–10%
0%
10%
20%
–20%
–10%
0%
10%
20%
X
Y

Linear Regression Analysis
197
managers who try to mimic the returns of an index, on the other hand, can be viewed 
as trying to minimize idiosyncratic risk.
Ordinary Least Squares
The univariate regression model is conceptually simple. In order to uniquely deter-
mine the parameters in the model, though, we need to make some assumption about 
our variables. While relatively simple, these assumptions allow us to derive some 
very powerful statistical results.
By far the most popular linear regression model is ordinary least squares (OLS). 
The objective of OLS is to explain as much of the variation in Y as possible, based on 
the constants α and β. This is equivalent to minimizing the role of ε, the error term. 
More specifically, OLS attempts to minimize the sum of the squared error terms 
(hence “least squares”).
OLS makes several assumptions about the form of the regression model, which 
can be summarized as follows:
A1: The relationship between the regressor and the regressand is linear.
A2: E
X
[ |
]
ε
= 0
A3: Var[ |
]
ε
σ
X =
2
A4: Cov[
, 
]
 
ε
ε
i
j
i
j
=
∀≠
0
A5: ε
σ
ε
i
i
N
∼
∀
( ,
) 
0
2
A6: The regressor is nonstochastic.
We examine each assumption in turn.
The first assumption A1 really just reiterates what Equation 10.1 implies, that 
we are assuming a linear relationship between X and Y. This assumption is not 
nearly as restrictive as it sounds. Suppose we suspect that default rates are related to 
interest rates in the following way:
	
D
R
=
+
+
α
β
ε
3 4
	
(10.4)
Because of the exponent on R, the relationship between D and R is clearly nonlin-
ear. Still, the relationship between D and R3/4 is linear. Though not necessary, it is 
perfectly legitimate to substitute X, where X = R3/4, into the equation to make this 
explicit.
As specified, the model implies that the linear relationship should be true for all 
values of D and R. In practice, we often only require that the relationship is linear 
within a given range. In this example, we don’t have to assume that the model is true 
for negative interest rates or rates over 500%. As long as we can restrict ourselves to 
a range within which the relationship is linear, this is not a problem. What could be a 
problem is if the relationship takes one form over most of the range, but changes for 
extreme but plausible values. In our example, maybe interest rates tend to vary be-
tween 0% and 15%; there is a linear relationship between D and R3/4 in this range, 
but beyond 15% the relationship becomes highly nonlinear. As risk managers, these 
extreme but plausible outcomes are what we are most interested in. We will return 
to this topic at the end of the chapter when we discuss stress testing.

198
Mathematics and Statistics for Financial Risk Management
Assumption A2 states that for any realization of X, the expected value of ε is 
zero. From a very practical standpoint, this assumption resolves any ambiguity be-
tween α and ε. Imagine ε could be modeled as:
	
ε
α
ε
=
′ + ′ 	
(10.5)
where α′ is a nonzero constant and ε′ is mean zero. By substituting this equation into 
Equation 10.1, we have:
	
Y
X
=
+
′ +
+ ′
(
)
α
α
β
ε 	
(10.6)
In practice, there is no way to differentiate between α and α′, and it is the combined 
term (α + α′), that is our constant.
Using assumption A2 and taking the expectation of both sides of Equation 10.1, 
we arrive at our first result for the OLS model, namely:
	
E Y X
X
[
|
] =
+
α
β
	
(10.7)
Given X, the expected value of Y is fully determined by α and β. In other words, the 
model provides a very simple linear and unbiased estimator of Y.
Assumption A2 also implies that the error term is independent of X. We can 
express this as:
	
Cov[
, ]
X ε = 0	
(10.8)
This result will prove useful in deriving other properties of the OLS model.
Assumption A3 states that the variance of the error term is constant. This prop-
erty of constant variance is known as homoscedasticity, in contrast to heteroscedas-
ticity, where the variance is nonconstant. This assumption means that the variance 
of the error term does not vary over time or depending on the level of the regressor. 
In finance, many models that appear to be linear often violate this assumption. As 
we will see in the next chapter, interest rate models often specify an error term that 
varies in relation to the level of interest rates.
Assumption A4 states that the error terms for various data points should be 
uncorrelated with each other. As we will also see in the next chapter, this assump-
tion is often violated in time series models, where today’s error is correlated with the 
previous day’s error. Assumptions A3 and A4 are often combined. A random variable 
that has constant variance and is uncorrelated with itself is termed spherical. OLS 
assumes spherical errors.
Combining assumptions A2 and A3 allows us to derive a very useful relation-
ship, which is widely used in finance. Given X and Y in Equation 10.1:
	
β
σ
ρ
σ
σ
=
[
] =
Cov X Y
X
XY
Y
X
,
2
	
(10.9)
where σ X and σ Y are the standard deviation of X and Y, respectively, and ρXY is 
the correlation between the two. The proof is left as an exercise at the end of the 
chapter.

Linear Regression Analysis
199
One of the most popular uses of regression analysis in finance is to regress stock 
returns against market index returns. As specified in Equation 10.1, index returns 
are represented by X, and stock returns by Y. This regression is so popular that we 
frequently speak of a stock’s beta, which is simply β from the regression equation. 
While there are other ways to calculate a stock’s beta, the functional form given in 
Equation 10.9 is extremely popular, as it relates two values, σX and σY, with which 
traders and risk managers are often familiar, to two other terms, ρXY and β, which 
should be rather intuitive.
Optimal Hedging Revisited
In Chapter 3, we determined that the optimal hedge ratio for two assets, A and 
B, was given by:
	
h
AB
A
B
* = −ρ
σ
σ
	
where σA is the standard deviation of the returns of asset A, σB is the standard 
deviation of the returns of asset B, and ρAB is the correlation between the 
returns of A and B.
Although we didn’t know it at the time, our optimal hedge ratio is just the 
negative of our slope from the following regression:
	
r
r
h
A
B
=
+
+
= −
α
β
ε
β
*
	
(10.10)
In other words, in order to minimize the variance of the portfolio, we need to 
short β units of asset B. This completely negates the βrB term in the portfolio, 
leaving us with a constant, α, and the idiosyncratic residual, ε, which cannot 
be hedged:
r
r
A
B
−
=
+
β
α
ε
This is the minimum variance portfolio.
As an example, pretend we are monitoring a portfolio with $100 million 
worth of assets, and the portfolio manager wishes to hedge the portfolio’s 
exposure to fluctuations in the price of oil. We perform an OLS analysis and 
obtain the following regression equation, where rportfolio is the portfolio’s per-
centage return, and roil is the return associated with the price of oil: 
r
r
portfolio
oil
=
+
+
0 01
0 43
.
.
ε
This tells us that for every unit of the portfolio, the optimal hedge would be to 
short 0.43 units of oil. For the entire $100 million portfolio, the hedge would 
be –$43 million of oil.

200
Mathematics and Statistics for Financial Risk Management
Assumption A5 states that the error terms in the model should be normally dis-
tributed. Many of the results of the OLS model are true, regardless of this assump-
tion. This assumption is most useful when it comes to defining confidence levels for 
the model parameters.
Finally, assumption A6 assumes that the regressor is nonstochastic, or nonran-
dom. In science, the regressor is often carefully controlled by an experimenter. A 
researcher might vary the amount of a drug given to mice, to determine the impact 
of the drug on their weight. One mouse gets one unit of the drug each day, the next 
gets two, the next three, and so on. Afterward, the regressand, the weight of each 
mouse, is measured. Ignoring measurement errors, the amount of the drug given to 
the mice is nonrandom. The experiment could be repeated, with another researcher 
providing the exact same dosages as in the initial experiment. Unfortunately, the 
ability to carefully control the independent variable and repeat experiments is rare 
in finance. More often than not, all of the variables of interest are random. Take, for 
example, the regression of stock returns on index returns. As the model is specified, 
we are basically stating that the index’s return causes the stock’s return. In reality, 
both the index’s return and the stock’s return are random variables, determined by 
a number of factors, some of which they might have in common. At some point, the 
discussion around assumption A6 tends to become deeply philosophical. From a 
practical standpoint, most of the results of OLS hold true, regardless of assumption 
A6. In many cases the conclusion needs to be modified only slightly.
Estimating the Parameters
Now that we have the model, how do we go about determining the constants, α and 
β? In the case of OLS, we need only find the combination of constants that minimizes 
the squared errors. In other words, given a sample of regressands, y1, y2, .  .  ., yn, and 
a set of corresponding regressors, x1, x2,  .  .  ., xn, we want to minimize the following 
sum:
	
RSS =
=
−
−
=
=
∑
∑
i
n
i
i
n
i
i
y
x
1
2
1
2
ε
α
β
(
) 	
(10.11)
where RSS is the commonly used acronym for the residual sum of squares (sum of 
squared residuals would probably be a more accurate description, but RSS is the 
convention). In order to minimize this equation, we first take its derivative with 
respect to α and β separately. We set the derivatives to zero and solve the resulting 
simultaneous equations. The result is the equations for OLS parameters:
	
α
β
β
=
−
=
−
−
=
=
∑
∑
Y
X
x y
nYX
x
nX
i
i
i
n
i
i
n
1
2
1
2
	
(10.12)
where X andY are the sample mean of X and Y, respectively. The proof is left for an 
exercise at the end of the chapter.

Linear Regression Analysis
201
Evaluating the Regression
Unlike a controlled laboratory experiment, the real world is a very noisy and com-
plicated place. In finance it is rare that a simple univariate regression model is going 
to completely explain a large data set. In many cases, the data are so noisy that we 
must ask ourselves if the model is explaining anything at all. Even when a relation-
ship appears to exist, we are likely to want some quantitative measure of just how 
strong that relationship is.
Probably the most popular statistic for describing linear regressions is the coef-
ficient of determination, commonly known as R-squared, or just R2. R2 is often de-
scribed as the goodness of fit of the linear regression. When R2 is one, the regression 
model completely explains the data. If R2 is one, all the residuals are zero, and the 
residual sum of squares (RSS) is zero. At the other end of the spectrum, if R2 is zero, 
the model does not explain any variation in the observed data. In other words, Y 
does not vary with X, and β is zero.
To calculate the coefficient of determination, we need to define two additional 
terms: the total sum of squares (TSS) and the explained sum of squares (ESS). They 
are defined as:
	
TSS
ESS
=
−
(
)
=
−
(
) =
+
−
(
)
=
=
∑
∑
y
Y
y
Y
x
Y
i
i
n
i
i
n
i
2
1
2
1
ˆ
α
β
2
1
i
n
=∑
	
(10.13)
Here, as before,Y is the sample mean of Y. 
These two sums are related to the previously encountered residual sum of 
squares, as follows:
	
TSS
ESS
RSS
=
+
	
(10.14)
In other words, the total variation in our regressand, TSS, can be broken down into 
two components, the part the model can explain, ESS, and the part the model can-
not, RSS. These sums can be used to compute R2:
	
R
ESS
TSS
1
RSS
TSS
2 =
=
−
	
(10.15)
As promised, when there are no residual errors, when RSS is zero, R2 is one. 
Also, when ESS is zero, or when the variation in the errors is equal to TSS, R2 is zero. 
It turns out that for the univariate linear regression model, R2 is also equal to the 
correlation between X and Y, squared. If X and Y are perfectly correlated (ρxy = 1) 
or perfectly negatively correlated (ρxy = −1), then R2 will equal one.
Estimates of the regression parameters are just like the parameter estimates we 
examined in the preceding chapter, and subject to hypothesis testing. In regression 
analysis, the most common null hypothesis is that the slope parameter, β, is zero. If 
β is zero, then the regression model does not explain any variation in the regressand.
In finance, we often want to know if α is significantly different from zero, but for 
different reasons. In modern finance, alpha has become synonymous with the abil-
ity of a portfolio manager to generate excess returns. This is because, in a regression 

202
Mathematics and Statistics for Financial Risk Management
equation modeling the returns of a portfolio manager, after we remove all the 
randomness, ε, and the influence of the explanatory variable, X, if α is still positive, 
then it is suggested that the portfolio manager is producing positive excess returns, 
something that should be very difficult in efficient markets. Of course, it’s not just 
enough that α is positive; we require that the α be positive and statistically significant.
In order to test the significance of the regression parameters, we first need 
to calculate the variance of α and β, which we can obtain from the following 
formulas:
	
ˆ
(
)
ˆ
ˆ
ˆ
(
σ
σ
σ
σ
α
ε
β
ε
2
2
1
2
1
2
2
2
=
−
=
−
=
=
∑
∑
x
n
x
x
x
i
i
n
i
i
n
i
x
n
i
n
i
i
n
)
ˆ
2
1
2
2
1
2
=
=
∑
∑
=
−
σ
ε
ε
	
(10.16)
where the last formula gives the variance of the error term, ε, which is simply the 
RSS divided by the degrees of freedom for the regression. Using the equations for the 
variance of our estimators, we can then form an appropriate t-statistic. For example, 
for β we would have:
	
ˆ
ˆ
~
β
β
σβ
−
−
tn 2 	
(10.17)
The most common null hypothesis when testing regression parameters is that 
the parameters are equal to zero. More often than not, we do not care if the pa-
rameters are significantly greater than or less than zero; we just care that they are 
significantly different. Because of this, rather than using the standard t-statistics as in 
Equation 10.17, some practitioners prefer to use the absolute value of the t-statistic. 
Some software packages also follow this convention.
Sample Problem
Question:
As a risk manager and expert on statistics, you are asked to evaluate the 
performance of a long/short equity portfolio manager. You are given 10 years 
of monthly return data. You regress the log returns of the portfolio manager 
against the log returns of a market index.
r
r
portfolio_manager
market
=
+
+
α
β
ε

Linear Regression Analysis
203
In the preceding example, both regression parameters were statistically signifi-
cant, even though the R2 was fairly modest. Which is more important, R2 or the 
significance of the regression parameters? Of course this is a subjective question and 
both measures are useful, but in finance one is tempted to say that the t-statistics, and 
not R2, are more useful. For many who are new to finance, this is surprising. Many 
of us first encounter regression analysis in the sciences. In a scientific experiment 
where conditions can be precisely controlled, it is not unusual to see R2 above 90%. 
In finance, where so much is not being measured, the error term tends to dominate, 
and R2 is typically much lower. That β can be statistically significant even with a low 
R2 may seem surprising, but in finance this is often the case.
Linear Regression (Multivariate)
Univariate regression models are extremely common in finance and risk manage-
ment, but sometimes we require a slightly more complicated model. In these cases, 
Assume both series are normally distributed and homoscedastic. From 
this analysis, you obtain the following regression results:
Constant
Beta
Value
1.13%
20.39%
Standard deviation
0.48%
9.71%
R2
8.11%
What can we say about the performance of the portfolio manager?
Answer:
The R2 for the regression is low. Only 8.11% of the variation in the port-
folio manager’s returns can be explained by the constant, beta, and variation 
in the market. The rest is idiosyncratic risk, and is unexplained by the model.
That said, both the constant and the beta seem to be statistically significant 
(i.e., they are statistically different from zero). We can get the t-statistic by dividing 
the value of the coefficient by its standard deviation. For the constant, we have:
ˆ
ˆ
.
%
%
.
%
.
α
α
σα
−
=
−
=
1 13
0
0 48
2 36
Similarly, for beta we have a t-statistic of 2.10. Using a statistical package, 
we calculate the corresponding probability associated with each t-statistic. This 
should be a two-tailed test with 118 degrees of freedom (10 years × 12 months 
per year – 2 parameters). We can reject the hypothesis that the constant and 
slope are zero at the 2% level and the 4% level, respectively. In other words, 
there seems to be a significant market component to the fund manager’s return, 
but the manager is also generating statistically significant excess returns.

204
Mathematics and Statistics for Financial Risk Management
we might use a multivariate regression model. The basic idea is the same, but instead 
of one regressand and one regressor, we have one regressand and multiple regressors. 
Our basic equation will look something like the following:
	
Y
X
X
X
n
n
=
+
+
+
+
β
β
β
β
1
2
2
3
3

	
(10.18)
Notice that rather than denoting the first constant with α, we chose to go with β1. 
This is the more common convention in multivariate regression. To make the equa-
tion even more regular, we can assume that there is an X1, which, unlike the other X’s, 
is constant and always equal to one. This convention allows us to easily express a set 
of observations in matrix form. For t observations and n regressands, we can write:
	
y
y
y
x
x
x
x
x
x
t
t
t
1
2
11
21
1
12
22
2
=
x
x
x
n
n
tn
n
1
2
1
2 +
β
β
β
ε1
2
ε
εt
	
(10.19)
where the first column of the X matrix—x11, x21,  .  .  ., xt1—is understood to consist 
entirely of ones. The entire equation can be written more succinctly as:
	
Y
X
=
+
ββ
εε 	
(10.20)
where, as before, we have used bold letters to denote matrices.
Multicollinearity
In order to determine the parameters of the multivariate regression, we again turn 
to our OLS assumptions. In the multivariate case, the assumptions are the same as 
before, but with one addition. In the multivariate case, we require that all of the 
independent variables be linearly independent of each other. We say that the inde-
pendent variables must lack multicollinearity:
A7: The independent variables have no multicollinearity.
To say that the independent variables lack multicollinearity means that it is impossi-
ble to express one of the independent variables as a linear combination of the others.
This additional assumption is required to remove ambiguity. To see why this is 
the case, imagine that we attempt a regression with two independent variables where 
the second independent variable, X3, can be expressed as a linear function of the first 
independent variable, X2:
	
Y
X
X
X
X
=
+
+
+
=
+
+
β
β
β
ε
λ
λ
ε
1
2
2
3
3
1
3
1
2
2
2
	
(10.21)
If we substitute the second line of Equation 10.21 into the first, we get:
	
Y
X
Y
X
=
+
+
+
+
+
=
+
+
(
)
(
)
(
)
β
β λ
β
βλ
β ε
ε
β
β
ε
1
3 1
2
2
2
3 2
1
4
5
2
3
	
(10.22)

Linear Regression Analysis
205
In the second line, we have simplified by introducing new constants and a new 
error term. We have replaced (β1 + β3λ1) with β4, replaced (β2 + β3λ2) with β5, and 
replaced (β3ε2 + ε1) with ε3. β5 can be uniquely determined in a univariate regres-
sion, but there is an infinite number of combinations of β2, β3, and λ2 that we could 
choose to equal β5. If β5 = 10, any of the following combinations would work:
	
β
β
λ
β
β
λ
β
β
2
3
2
2
3
2
2
3
10
0
100
0
10
1
500
=
=
=
=
=
=
=
= −
,
,
,
,
,
49
10
2
,
λ =
	
(10.23)
In other words, β2 and β3 are ambiguous in the initial equation. This ambiguity is 
why we want to avoid multicollinearity.
Even in the presence of multicollinearity, the regression model still works in a 
sense. In the preceding example, even though β2 and β3 are ambiguous, any combi-
nation where (β2 + β3λ2) equals β5 will produce the same value of Y for a given set 
of X’s. If our only objective is to predict Y, then the regression model still works. The 
problem is that the value of the parameters will be unstable. A slightly different data 
set can cause wild swings in the value of the parameter estimates, and may even flip 
the signs of the parameters. A variable that we expect to be positively correlated with 
the regressand may end up with a large negative beta. This makes interpreting the 
model difficult. Parameter instability is often a sign of multicollinearity.
There is no well-accepted procedure for dealing with multicollinearity. The easi-
est course of action is often simply to eliminate a variable from the regression. While 
easy, this is hardly satisfactory.
Another possibility is to transform the variables, to create uncorrelated variables 
out of linear combinations of the existing variables. In the previous example, even 
though X3 is correlated with X2, X3 − λ2X2 is uncorrelated with X2.
	
X
X
X
X
X
X
3
2
2
1
3
2
3
2
2
2
1
3
−
=
+
−
=
+
=
λ
λ
ε
λ
λ
ε
Cov
Cov
[
,
]
[
,
]
Cov[
,
]
X2
3
0
ε
=
	
(10.24)
One potential problem with this approach is similar to what we saw with prin-
cipal component analysis (which is really just another method for creating uncor-
related variables from linear combinations of correlated variables). If we are lucky, 
a linear combination of variables will have a simple economic interpretation. For 
example, if X2 and X3 are two equity indexes, then their difference might correspond 
to a familiar spread. Similarly, if the two variables are interest rates, their difference 
might bear some relation to the shape of the yield curve. Other linear combinations 
might be difficult to interpret, and if the relationship is not readily identifiable, then 
the relationship is more likely to be unstable or spurious.
Global financial markets are becoming increasingly integrated. More now than 
ever before, multicollinearity is a problem that risk managers need to be aware of.
Estimating the Parameters
Assuming our variables meet all of the OLS assumptions, how do we go about 
estimating the parameters of our multivariate model? The math is a bit more 

206
Mathematics and Statistics for Financial Risk Management
complicated, but the process is the same as in the univariate case. Using our re-
gression equation, we calculate the residual sum of squares and seek to minimize 
its value through the choice of our parameters. The result is our OLS estimator 
for ββ, ˆββ:
	
ˆββ =
′
′
−
(X X)
X Y
1
	
(10.25)
Where we had two parameters in the univariate case, now we have a vector of n 
parameters, which define our regression equation.
Given the OLS assumptions—actually, we don’t even need assumption A6, that 
the regressors are nonstochastic— ˆββ is the best linear unbiased estimator of ββ. This 
result is known as the Gauss-Markov theorem.
Evaluating the Regression
Just as with the univariate model, once we have calculated the parameters of our 
multivariate model, we need to be able to evaluate how well the model explains 
the data.
We can use the same process that we used in the univariate case to calculate 
R2 for the multivariate regression. All of the necessary sums, RSS, ESS, and TSS, 
can be calculated without further complication. As in the univariate case, in the 
multivariate model, R2 varies between zero and one, and indicates how much 
of the dependent variable is being explained by the model. One problem in the 
multivariate setting is that R2 tends to increase as we add independent variables 
to our regression. In fact, adding variables to a regression can never decrease the 
R2. At worst, R2 stays the same. This might seem to suggest that adding variables 
to a regression is always a good thing, even if they have little or no explanatory 
power. Clearly there should be some penalty for adding variables to a regression. 
An attempt to rectify this situation is the adjusted R2, which is typically denoted 
by R ,
2 and defined as:
	
R
R
t
t
n
1
(1
)
1
2
2
=
−
−
−
−
	
(10.26)
where t is the number of sample points and n is the number of regressors, including 
the constant term. While there is clearly a penalty for adding independent variables 
and increasing n, one odd thing about R2  is that the value can turn negative in 
certain situations.
Just as with the univariate model, we can calculate the variance of the error 
term. Given t data points and n regressors, the variance of the error term is:
	
ˆσ
ε
ε
2
2
1
=
−
=∑
i
i
t
t
n
	
(10.27)
The variance of the ith estimator is then:
	
ˆ
ˆ [
] ,
σ
σε
i
i i
2
2
=
′
−
(X X) 1
	
(10.28)

Linear Regression Analysis
207
where the final term on the right-hand side is the ith diagonal element of the matrix 
(X′X)–1. We can then use this to form an appropriate t-statistic, with t − n degrees 
of freedom:
	
ˆ
ˆ
~
β
β
σ
i
i
i
t n
t
−
−	
(10.29)
Instead of just testing one parameter, we can actually test the significance of all 
of the parameters, excluding the constant, using what is known as an F-test. The 
F-statistic can be calculated using R2:
	
R
n
R
t
n
Fn
t n
2
2
1
1
1
/ (
)
(
) / (
) ~
,
−
−
−
−
−	
(10.30)
As the name implies, the F-statistic follows an F-distribution with n − 1 and 
t − n degrees of freedom. Not surprisingly, if the R2 is zero, the F-statistic will be 
zero as well.
Exhibit 10.2 shows 5% and 10% critical values for the F-distribution for vari-
ous values of n and t, where the appropriate degrees of freedom are n − 1 and t − n. 
For a univariate regression, n = 2, with a large number of data points, a good rule of 
thumb is that values over 4.00 will be significant at the 5% level.
In general, we want to keep our models as simple as possible. We don’t want 
to add variables just for the sake of adding variables. This principle is known as 
parsimony.R2, t-tests, and F-tests are often used in deciding whether to include an 
additional variable in a regression. In the case of R2, a variable will be added only if 
it improves R2. In finance, even when the statistical significance of the betas is high, 
R2 and R2 are often very low. For this reason, it is common to evaluate the addition 
of a variable on the basis of its t-statistic. If the t-statistic of the additional variable 
is statistically significant, then it is kept in the model. It is less common, but it is pos-
sible to have a collection of variables, none of which are statistically significant by 
themselves, but which are jointly significant. This is why it is important to monitor 
the F-statistic as well. When applied systematically, this process of adding or remov-
ing variables from a regression model is referred to as stepwise regression.
Exhibit 10.2 
F-Distribution Critical Values
n
t
5%
10%
2
20
4.41
3.01
2
50
4.04
2.81
2
100
3.94
2.76
2
1,000
3.85
2.71
4
20
3.24
2.46
4
50
2.81
2.21
4
100
2.70
2.14
4
1,000
2.61
2.09

208
Mathematics and Statistics for Financial Risk Management
Application: Factor Analysis
In risk management, factor analysis is a form of risk attribution, which attempts 
to identify and measure common sources of risk within large, complex portfolios.1 
These underlying sources of risk are known as factors. Factors can include equity 
market risk, sector risk, region risk, country risk, interest rate risk, inflation risk, or 
style risk (large-cap versus small-cap, value versus growth, momentum, etc.). Factor 
analysis is most popular for equity portfolios, but can be applied to any asset class 
or strategy.
In a large, complex portfolio, it is sometimes far from obvious how much 
exposure a portfolio has to a given factor. Depending on a portfolio manager’s 
objectives, it may be desirable to minimize certain factor exposures or to keep 
the amount of risk from certain factors within a given range. It typically falls to 
risk management to ensure that the factor exposures are maintained at acceptable 
levels.
The classic approach to factor analysis can best be described as risk taxonomy. 
For each type of factor, each security would be associated with one and only one fac-
tor. If we were trying to measure country exposures, each security would be assigned 
to a specific country—France, South Korea, the United States, and so on. If we were 
trying to measure sector exposures, each security would similarly be assigned to an 
industry, such as technology, manufacturing, or retail. After we had categorized all 
of the securities, we would simply add up the exposures of the various securities to 
get our portfolio-level exposures. Exhibit 10.3 shows how a portfolio’s exposure to 
different regions and countries could be broken down.
1  In statistics, factor analysis can also refer to a specific method of data analysis, similar to 
principal component analysis (PCA). What we are exploring in this section might be more 
formally referred to as risk factor analysis. Risk factor analysis is a much more general con-
cept, which might utilize statistical factor analysis, regression analysis, PCA, or any number 
of statistical methods.
Exhibit 10.3 
Geographic Exposures
Market Value
Asia
China
$359
Japan
$3,349
Europe
Germany
–$823
Ireland
$500
North America
United States
$4,865
Mexico
$2,393
Total
$10,643

Linear Regression Analysis
209
In this portfolio, which has a total value of $10,643, there is $359 of exposure 
to China and a net –$323 of exposure to Europe. Importantly, the classic approach is 
binary. A security is an investment in either China or Germany; it is either in utilities or 
in agriculture. It can’t be one-third in Russia and two-thirds in Poland, or just 42% in 
value stocks. This creates a problem in the real world. What do you do with a company 
that is headquartered in France, has all of its manufacturing capacity in China, sells its 
products in North America, and has listed shares on both NASDAQ and the London 
Stock Exchange? Is a company that sells electronics a technology company or a retailer?
These kinds of obvious questions led to the development of various statistical 
approaches to factor analysis. One very popular approach is to associate each fac-
tor with an index, and then to use that index in a regression analysis to measure a 
portfolio’s exposure to that factor. For example, if we want to measure a portfolio’s 
exposure to Japan, we would run a regression of our portfolio’s returns against the 
returns of a Japanese index:
	
r
r
portfolio
index
=
+
+
α
β
ε 	
(10.31)
The Japanese index could be a publicly available index, such as the Nikkei, or 
it could be an index of our own construction based on a basket of Japanese securi-
ties. The return series for our portfolio should reflect what the returns of the current 
portfolio would have been, given the current holdings of the portfolio. This type 
of return series is often referred to as a what-if or backcast return series. This is as 
opposed to the actual return series, which would be impacted by the changing com-
position of the portfolio over time. Of course this analysis assumes that both return 
series obey all the OLS assumptions.
In Equation 10.31, β now represents our factor exposure. The exposure will be 
in the same units as the portfolio returns. If the portfolio returns are in U.S. dollars, 
the exposure will be in U.S. dollars, too. From this equation, we would already be 
able to predict that if the index return was –10%, then the impact on the portfolio’s 
return would be –0.10β. Being able to summarize the risk of a large, complex port-
folio in such simple terms is what makes regression analysis so powerful.
Another nice thing about factor analysis is that the factor exposures can be 
added across portfolios. If Portfolio A has $100 of exposure to technology, and Port-
folio B has $200 of exposure to the same factor, then a combined portfolio, Portfolio 
A + B, would have $300 of exposure to technology. This result can be obtained by 
simply adding together the regression equations of Portfolio A and Portfolio B:
	
r
r
r
r
r
A =
+
+
=
+
+
=
+
+
α
β
ε
α
β
ε
α
A
A inde
A
x
B
B
B inde
B
x
A B
A
(
α
β
ε
β
ε
B
A
B
index
A
B
)
(
(
)
)
+
+
+
+
r
	
(10.32)
Because factor exposures are additive, this makes hedging a factor exposure 
relatively simple. If we have $300 of exposure to technology, and assuming the tech-
nology index is tradable, we can hedge this factor by shorting $300 of the technol-
ogy index; $300 less $300 leaves us with $0 of factor exposure.
Exhibit 10.4 shows a sample exposure breakdown for an unspecified factor. 
Notice how the factor exposures are not necessarily proportional to the market 
values or even of the same sign. Even though there is not a fixed relationship between 

210
Mathematics and Statistics for Financial Risk Management
market value and factor exposure across portfolios, the market values and the factor 
exposures can each be added up separately to arrive at their respective totals.
In addition to giving us the factor exposure, the factor analysis allows us to di-
vide the risk of a portfolio into systematic and idiosyncratic components. In this case, 
systematic risk refers to the risk in a portfolio that can be attributed to a factor. The 
risk that is not systematic (i.e., that cannot be attributed to a factor) is referred to as 
idiosyncratic risk. In an equity portfolio, this is often referred to as stock-specific risk. 
From our OLS assumptions, we know that rindex and ε are not correlated. Calculating 
the variance of rportfolio in Equation 10.31, we arrive at the following:
	
σ
β σ
σε
portfolio
index
2
2
2
2
=
+
	
(10.33)
In other words, the variance of the portfolio can be broken into two compo-
nents, β σ
2
2
index, the systematic component, and σε
2, the idiosyncratic component. As 
mentioned previously, depending on the objective of the portfolio, we might consider 
more or less idiosyncratic variance desirable. If our objective is to replicate an index, 
we might want to minimize idiosyncratic risk. If our goal is to produce portfolio 
returns that are uncorrelated with the market, we would want to minimize the sys-
tematic risk in the portfolio.
In theory, there is no reason why we cannot extend our factor analysis using 
multivariate regression analysis. In practice, many of the factors we are interested in 
will be highly correlated (most equity indexes are highly correlated with each other). 
This leads naturally to the use of spreads between indexes for secondary factors in 
order to avoid multicollinearity. For example, if we are using a broad market index 
as a primary factor, then the spread between that index and a country factor might 
be an interesting secondary factor. As outlined in the section on multicollinearity, 
we can use the residuals from the regression of our secondary index on the primary 
index to construct a return series that is uncorrelated with the primary series. 
In theory, factors can be based on almost any kind of return series. The advan-
tage of indexes based on publicly traded securities is that it makes hedging very 
straightforward. At the same time, there might be some risks that are not captured 
by any publicly traded index. Some risk managers have attempted to resolve this 
problem by using statistical techniques, such as principal component analysis (PCA) 
or cluster analysis, to develop more robust factors. Besides the fact that these factors 
might be difficult to hedge, they might also be unstable, and it might be difficult to 
associate these factors with any identifiable macroeconomic variable. Even using 
these statistical techniques, there is always the possibility that we have failed to 
identify a factor that is an important source of risk for our portfolio. Factor analysis 
is a very powerful tool, but it is not without its shortcomings.
Exhibit 10.4 
Adding Factor Exposures across Portfolios
Market Value
Factor Exposure
Portfolio A
$9,378
–$30,592
Portfolio B
$39,348
$45,829
Portfolio C
–$2,938
–$2,674
Total
$45,788
$12,563

Linear Regression Analysis
211
Application: Stress Testing
In risk management, stress testing assesses the likely impact of an extreme, but plau-
sible, scenario on a portfolio. There is no universally accepted method for perform-
ing stress tests. One popular approach, which we consider here, is closely related to 
factor analysis.
The first step in stress testing is defining a scenario. Scenarios can be either ad hoc 
or based on a historical episode. An ad hoc scenario might assume that equity mar-
kets decline 20% or that interest rates jump 5%, for example. A historical scenario 
might examine the Russian debt crisis of 1998 or the Asian currency crisis of 1997. 
Black Monday, the equity market crash of 1987, is probably one of the most popular 
scenarios for historical stress tests. For both the ad hoc and the historical approaches, 
we want to quantify our scenario by specifying the returns of a few key instruments, 
or factors. For the 5% jump in interest rates, we might specify that 10-year U.S. 
Treasury rates increase by 5%, BBB credit spreads increase 2%, and the Standard & 
Poor’s 500 index decreases 10%. In the Black Monday scenario, we might choose to 
focus on the change in the Dow Jones Industrial Average, the price of gold, and the 
London Interbank Offered Rate (LIBOR). Just as with our factor analysis, we need to 
be careful that the instruments defining our scenario are not highly correlated.
In the second step, we need to define how all other underlying financial instru-
ments react, given our scenario. In order to do this, we construct multivariate re-
gressions. We regress the returns of each underlying financial instrument against the 
returns of the instruments that define our scenario. What might seem strange is that, 
even in the case of the historical scenarios, we use recent returns in our regression. In 
the case of the historical scenarios, why don’t we just use the actual returns from that 
period? The reason we use current returns and not returns from the historical episode 
is partly practical. Consider Black Monday, 1987. Credit default swaps didn’t exist 
in 1987. The euro, the world’s second largest currency, didn’t exist. Many of today’s 
largest companies didn’t exist, including Google (IPO in 2004) and Exxon Mobil 
(Exxon and Mobil did not merge until 1999). If our current portfolio holds any of 
these securities and we tried to use actual returns from the stress period, we would 
have no data to use for those securities. Even if we did have historical returns for all 
of the securities in our portfolio, would we want to use them? The world has changed 
significantly over the past 30 years. Companies and relationships between companies 
are likely to be very different now than they were 30 years ago. To put it another way, 
we choose a specific historical episode not because we expect that event to repeat 
exactly, in every detail, but because we expect something like that event could happen 
again. As Mark Twain was supposed to have said, “History does not repeat itself, but 
it often rhymes.”
In the final step, after we have generated the returns for all of the underlying 
financial instruments, we price any options or other derivatives. This last step is im-
portant. While using delta approximations might have been acceptable for calculat-
ing value at risk statistics at one point in time, it should never have been acceptable 
for stress testing. By definition, stress testing is the examination of extreme events, 
and the accurate pricing of nonlinear instruments is critical.
As an example of how a stress test might work in practice, let’s imagine a sce-
nario that we’ll call Simple Oil Crisis. In this scenario, crude oil prices increase 20% 
and the Standard & Poor’s 500 index decreases by 10%. Imagine that our portfolio 

212
Mathematics and Statistics for Financial Risk Management
consists solely of $100 worth of shares in Exxon Mobil. To see how Exxon Mobil 
reacts, we would construct the following regression:
	
r
r
r
Exxon_Mobil
oil
equity_index
=
+
+
+
β
β
β
ε
1
2
3
	
(10.34)
where the returns would be based on recent historical data, say the past year of daily 
returns. In order to avoid issues with multicollinearity, we’ll assume that roil and 
requity_index are uncorrelated. Assume that the OLS regression produces the following 
equation describing Exxon Mobil’s returns:
 	
r
r
r
Exxon_Mobil
oil
equit
=
+
+
0 0000
0 0899
0 7727
.
.
.
y_index + ε 	
(10.35)
Based on this equation, we expect Exxon Mobil to return –5.93% in our stress 
scenario:
	
r
E
Exxon_Mobil stress =
+
+
⋅
0 0000
0 0899 0 20
.
.
.
0 7727
0 10
0 0
.
(
)
.
.
⋅−
= −
r
E
Exxon_Mobil stress
593
	
(10.36)
Given our starting value of $100, we would expect to lose $5.93 in this scenario. 
To evaluate the expected return of a portfolio with multiple securities, we could 
proceed stepwise, evaluating each security in turn and adding up the gains or losses. 
Alternatively, we could calculate the backcast dollar return series for the entire port-
folio, and use this series in our regression analysis to calculate the expected portfolio 
return directly.
Earlier in the chapter, when we were reviewing the assumptions of the OLS 
model, we noted that the model assumes that the linear relationship between the re-
gressand and regressors is true over the entire range being considered. We cautioned 
that this assumption could be problematic if the relationship takes one form over 
most of the range, but changes for extreme but plausible values. Stress testing is, by 
definition, about extreme but plausible values. In Chapter 12, we discuss some alter-
native approaches to regression that may be better suited to the analysis of extreme 
returns. Regardless of which form of regression analysis we settle on, the other steps 
in constructing the stress test remain the same.
Problems
	 1.	The following regression equation describes the daily returns of stock XYZ, 
rXYZ, in terms of an index return, rindex, and a mean zero disturbance term, ε:
r
r
XYZ =
+
+
α
β
ε
index
	
	 where α and β are constants, ε is mean zero with a standard deviation of 
1.0%, α is 0.01%, and β is 1.20. If the index return on a given day is 5%, what 
is the expected return of XYZ?
	 2.	In addition to the assumptions in the previous question, assume rindex has a mean 
of 0.05% and a standard deviation of 1.5%. What is the expected value of rXYZ? 
What is the standard deviation of rXYZ?

Linear Regression Analysis
213
	 3.	Using all the information from the previous two questions, determine the cor-
relation between the index returns and the returns of XYZ.
	 4.	You perform a regression analysis of a hedge fund’s returns against an industry 
benchmark. You have 50 data points. The total sum of squares (TSS) is 13.50%. 
The residual sum of squares (RSS) is 10.80%. What is the R2?
	 5.	In the previous question, what is the critical value for the F-test? Is the F-statistic 
significant at the 95% confidence level?
	 6.	An initial univariate regression produces an R2 of 60%. There are 20 data points. 
In an effort to improve the model, two additional regressors are added, which 
boost the R2 to 64%. Determine which model is better based on adjusted R2.
	 7.	Based on your analysis of Company ABC’s stock returns, rABC, you develop the 
following OLS regression model:
r
r
r
A
B
ABC =
+
+
+
0 01
1 25
0 34
.
.
.
ε
	
	 where rA and rB are two uncorrelated indexes, and ε is a mean zero disturbance 
term. If rA = 10% and rB = 50%, what is the expected value of rABC?
	 8.	You perform the following multivariate regression:
r
X
X
=
+
+
+
β
β
β
ε
1
2
2
3
3
1
	
	 Upon closer inspection you notice that X2 and X3 are, in fact, correlated. Their 
relationship can be described in the following regression:
X
X
3
4
5
2
2
=
+
+
β
β
ε
	
	 Suggest a new model that avoids the problem of multicollinearity.
	 9.	Prove Equation 10.9. That is, given the standard univariate regression,
Y
X
=
+
+
α
β
ε
	
	 prove that:
β
σ
ρ
σ
σ
=
=
Cov[
,
]
X Y
X
XY
Y
X
2
	
	 where σX and σY are the standard deviations of X and Y, respectively, and ρXY 
is the correlation between the two. Hint: Start by calculating the covariance 
between X and Y.
	10.	The equation for the residual sum of squares (RSS) of the univariate regression 
model is:
RSS =
=
−
−
=
=
∑
∑
i
n
i
i
n
i
i
y
x
1
2
1
2
ε
α
β
(
)
	
	 Take the derivatives of this equation, first with respect to α, then with respect 
to β. Set the two resulting equations to zero, and solve to get the standard equa-
tions for the OLS regression parameters, Equation 10.12. Technically, we should 
also prove that this solution is a minimum and not a maximum, but that is be-
yond the scope of this book.


215
I
n this chapter, we provide an introduction to time series analysis. Time series 
describe how random variables evolve over time and form the basis of many 
financial models.
Random Walks
A time series is an equation or set of equations describing how a random variable or 
variables evolve over time. Probably the most basic time series is the random walk. 
For a random variable X, with a realization xt at time t, the following conditions 
describe a random walk:
	
x
x
E
E
E
s
t
t
t
t
t
t
s t
=
+
=
=
=
∀≠
−1
2
2
0
0
ε
ε
ε
σ
ε ε
[
]
[
]
[
]
 

(11.1)
In other words, X is equal to its value from the previous period, plus a random 
disturbance, εt; εt is mean zero, with a constant variance. The last condition in Equa-
tion 11.1, combined with the fact that εt is mean zero, tells us that the ε’s from differ-
ent periods will be uncorrelated with each other. In time series analysis, we typically 
refer to xt−1 as the first lagged value of xt, or just the first lag of xt. By this convention, 
xt−2 would be the second lag, xt−3 the third, and so on.
We can also think in terms of changes in X. Subtracting xt−1 from both sides of 
our initial equation:
	
Δ xt = xt − xt−1 = εt	
(11.2)
In this basic random walk, ∆xt has all of the properties of our stochastic term, 
εt. Both are mean zero. Both have a constant variance, σ2. Most important, the error 
terms are uncorrelated with each other. This system is not affected by its past. This is 
the defining feature of a random walk.
chapter 11     
Time Series Models

216
Mathematics and Statistics for Financial Risk Management
How does the system evolve over time? Note that Equation 11.1 is true for all 
time periods. All of the following equations are valid:
	
x
x
x
x
x
x
t
t
t
t
t
t
t i
t i
t i
=
+
=
+
=
+
−
−
−
−
−
−−
−
1
1
2
1
1
ε
ε
ε

	
(11.3)
By substituting the equation into itself, we can see how the equation evolves over 
multiple periods:
	
x
x
x
x
t
t
t
t
t
t
i
t
i
=
+
=
+
+
=
+
−
−
−
=∑
1
2
1
0
1
ε
ε
ε
ε 	
(11.4)
At time t, X is simply the sum of its initial value, x0, plus a series of random 
steps. Using this formula, it is easy to calculate the conditional mean and variance 
of xt:
	
E x x
x
x x
t
t
t
[
|
]
[
|
]
0
0
0
2
=
=
Var
σ 	
(11.5)
If the variance increases proportionally with t, then the standard deviation in-
creases with the square root of t. This is our familiar square root rule for independ-
ent and identically distributed (i.i.d.) variables. For a random walk, our best guess 
for the future value of the variable is simply the current value, but the probability of 
finding it near the current value becomes increasingly small.
Though the proof is omitted here, it is not difficult to show that, for a random 
walk, skewness is proportional to t−0.5 and kurtosis is proportional to t−1. In other 
words, while variance, and standard deviation increase over longer time spans, 
skewness and kurtosis become smaller.
The simple random walk is not a great model for equities, where we expect 
prices to increase over time, or for interest rates, which cannot be negative. With 
some rather trivial modification, though, we can accommodate both of these 
requirements.
Drift-Diffusion Model
One simple modification we can make to the random walk is to add a constant term, 
in the following way:
	
pt = α + pt−1 + εt	
(11.6)
Now the current realization of our random variable pt is a function of a con-
stant, α, its previous value, pt–1, and our random disturbance, εt. Just as before, the 
variance of εt is constant over time, and the various εt’s are uncorrelated with each 
other.

Time Series Models
217
The choice of pt for our random variable is intentional. If pt is the log price, then 
rearranging terms, we obtain an equation for the log return:
	
rt = Δpt = α + εt
(11.7)
The constant term, α, is often referred to as the drift term, for reasons that will 
become apparent. In these cases, εt is typically referred to as the diffusion term. 
Outside of finance, these types of models are most famously used in physics to de-
scribe the motion of particles. We can imagine a bunch of particles starting out close 
together, randomly drifting about, and filling a space, or diffusing. Putting these two 
terms together, the entire equation is known as a drift-diffusion model.
When equity returns follow a drift-diffusion process, we say that equity markets 
are perfectly efficient. We say they are efficient because the return is impossible 
to forecast based on past prices or returns. Put another way, the conditional and 
unconditional returns are equal. Mathematically:
	
E r r
E r
t
t
t
[ |
]
[ ]
−
=
=
1
α 
(11.8)
If this was not the case—if there was some information in the past that suggested 
that tomorrow’s return should be higher than average—then buyers should enter the 
market to buy the security, in the process pushing up the price. In a perfectly efficient 
market, this process would continue until there was no opportunity for excess profit, 
until tomorrow’s expected return was no higher or lower than the unconditional 
mean return.
As with the random walk equation, we can iteratively substitute the drift-­
diffusion model into itself:
	
p
p
t
p
t
t
t
t
i
t
i
=
+
+
+
=
+
+
−
−
=∑
2
2
1
0
1
α
ε
ε
α
ε 
(11.9)
And just as before, we can calculate the conditional mean and variance of our 
drift-diffusion model:
	
E p p
p
t
p p
t
t
t
[
|
]
[
|
]
0
0
0
2
=
+
=
α
σ
Var

(11.10)
As with the random walk, the variance of the drift-diffusion process is propor-
tional to t. This time, however, the mean is not constant. The expected value of pt 
continues to increase or decrease steadily, to drift, as time goes by, at a rate of α. This 
is why α is known as the drift term.
Autoregression
The next modification we’ll make to our time series model is to multiply the lagged 
term by a constant:
	
rt = α + λrt−1 + εt
(11.11)

218
Mathematics and Statistics for Financial Risk Management
Here, both α and λ are constants. Depending on the value of λ, the behavior of 
this model can vary greatly. As we’ll see, when |λ| is less than one, this model can 
produce a stable time series. Exhibit 11.1 shows the results of a Monte Carlo simula-
tion based on Equation 11.11, with α = 0.50 and λ = 0.90. As we will see later in the 
chapter, models similar to this can be used to model interest rates.
Equation 11.11 is known as an autoregressive (AR) model. More specifically, 
Equation 11.11 is known as an AR(1) model, since rt depends only on its first lag. 
The random walk is then just a special case of the AR(1) model, where α is zero and 
λ is equal to one. Although our main focus will be on AR(1) models, we can easily 
construct an AR(n) model as follows:
	
rt = α + λ1rt−1 + λ2rt−2 + .  .  . + λnrt−n + εt	
(11.12)
where α and the λ’s are all constants.
How does the addition of λ to our equation change the behavior of rt? To find 
out, just as we did before, we can iteratively substitute our AR(1) model into itself to 
obtain the following equation:
	
r
r
t
i
n
i
n
t n
i
n
i
t i
=
+
+
=
−
−
=
−
−
∑
∑
α
λ
λ
λ ε
0
1
0
1
	
(11.13)
Exhibit 11.1 
Mean Reversion (α = 0.50; λ = 0.90)
0
1
2
3
4
5
6
7
8
0
10
20
30
40
50
60
t
r

Time Series Models
219
To proceed further, we can use methods developed in Chapter 1 for summing 
geometric series. The conditional mean and variance are now:
	
E r r
r
r r
t
t n
n
n
t n
t
t n
[ |
]
[ |
]
−
−
−
=
−
−
+
=
−
1
1
1
2
λ
λ α
λ
λ
Var
n
1
2
2
−λ
σ
	
(11.14)
As you might expect, for values of |λ| greater than one, the variance of rt ­increases 
exponentially as n increases. We say that the series diverges or that it is unstable. For 
values of |λ| greater than one, r will tend to move further and further away from its 
starting value as n increases. Exhibit 11.2 shows the results of a Monte Carlo simula-
tion based on Equation 11.11, with α = –0.10 and λ = 1.02. The standard deviation 
of the error term is 0.50.
For values of |λ| less than one, notice that the impact of rt–n on the expected value 
of rt decreases as n increases, but never goes to zero. This may seem a bit strange. It’s 
as if the system has infinite memory. If we use this as an interest rate model, then a 
spike in rates from 100 years ago would still be impacting current rates. In practical 
terms, the impact would be so small as to be negligible, but it is a potential criticism 
of autoregressive models.
Exhibit 11.2 
Divergent Series (α = –0.10; λ = 1.02; σ = 0.50)
0
1
2
3
4
5
6
0
10
20
30
40
50
60
t
r

220
Mathematics and Statistics for Financial Risk Management
For values of |λ| less than one, the AR(1) process is stable. If we continue to ex-
tend the series back in time, as n approaches infinity, λn becomes increasingly small, 
causing λnrt–n to approach zero. In this case:
	
rt
i
i
t i
=
−
+
=
∞
−
∑
1
1
0
λ α
λ ε

(11.15)
Continuing to use our geometric series techniques, we then arrive at the following 
results for the mean and variance:
	
E r
r
t
t
[ ]
[ ]
=
−
=
−
1
1
1
1
2
2
λ α
λ σ
Var

(11.16)
So, for values of |λ| less than one, as n approaches infinity, the initial state 
of the system ceases to matter. The mean and variance are only a function of the 
constants.
For a random walk, the conditional and unconditional means are equal. This is 
not the case for an AR(1) process. For an AR(1) process, because this period’s value 
is a function of the previous period’s value, knowing the value from the previous 
period will impact our expectation of the value in this period.
Using these results suggests an interesting way to reformulate our original AR(1) 
equation. We define two new constants, µ and θ, and rewrite Equation 11.11 as 
follows:
	
θ
λ
µ
α
θ
θµ
θ
ε
=
−
=
=
+
−
+
−
(
)
(
)
1
1
1
r
r
t
t
t

(11.17)
Viewed this way, our AR(1) equation can now be seen as a weighted average of its 
mean and its lagged value. Our previous restriction that |λ| is less than one is now 
replaced by a new restriction, 0 < θ < 2.
We can get some idea of the dynamic behavior of rt by subtracting rt–1 from both 
sides of the equation:
	
∆
∆
r
r
E
r
r
t
t
t
t
t
=
−
+
=
−
−
−
θ µ
ε
θ µ
(
)
[
]
(
)
1
1

(11.18)
If θ is between zero and two, then the expected value of Δrt will always be the 
same sign as (µ – rt–1). If rt−1 is less than the mean, Δrt will be positive; if rt−1 is greater 
than the mean, Δrt will be negative. In other words, rt is always moving back toward 
its mean. This helps explain why the system is stable.
Looking even closer, we see that the behavior of the system is different if θ is 
between zero and one than if it is between one and two. Between zero and one, at 
each step, the expected value of Δrt is a fraction of the distance between rt−1 and µ. 

Time Series Models
221
For 0 < θ < 1, r tends to move closer to the mean with each step. This property is 
known as mean reversion and is thought to be a common feature of many financial 
time series. For 1 < θ < 2, the series tends to overshoot the mean. If θ = 1.5, we ex-
pect that Δrt will be 1.5 times (µ – rt−1), so r will tend to overshoot µ by 0.5 times 
(µ – rt−1). Exhibit 11.3 shows the results of a Monte Carlo simulation based on 
Equation 11.17, which exhibits mean reversion with overshooting. This system is 
stable, but this constant overshooting is unusual in practice. In finance, more often 
than not, for AR(1) systems, we expect θ to be between zero and one, and for the 
system to exhibit mean reversion.
We can quantify the level of mean reversion by calculating the correlation of 
rt with its first lag. This is known as autocorrelation or serial correlation. For our 
AR(1) series, we have:
	
ρ
θ
λ
t t, −=
−
=
1
1

(11.19)
The proof is left as an exercise. Clearly this makes sense only when |λ| is less than 
one. Remember that covariance and correlation look at expected deviations from the 
mean. In light of our discussion of the dynamics of AR(1) systems, this result should 
make sense. For 0 < θ < 1, if rt−1 is below the mean, we expect rt to also be below the 
mean, and the autocorrelation is positive. Similarly, for 1 < θ < 2, if rt–1 is below 
the mean, we expect the process to overshoot, causing rt to be above the mean, and 
the autocorrelation is negative.
Exhibit 11.3 
Mean Reversion with Overshooting (µ = 5.0; λ = –0.90; θ = 1.90)
0
1
2
3
4
5
6
7
8
0
10
20
30
40
50
60
t
r

222
Mathematics and Statistics for Financial Risk Management
Variance and Autocorrelation
Autocorrelation has a very important impact on variance as we look at longer and 
longer time periods. For our random walk, as we look at longer and longer periods, 
the variance grows in proportion to the length of time.
Assume returns follow a random walk:
	
rt
t
= ε 
(11.20)
where εt is an i.i.d. disturbance term. Now define yn,t as an n period return; that is:
	
y
r
n t
i
n
t i
i
n
t i
, =
=
=
−
−
=
−
−
∑
∑
0
1
0
1
ε

(11.21)
As stated before, the variance of yn,t is proportional to n:
	
Var[
]
,
y
n
n t = σε
2 
(11.22)
and the standard deviation of yn,t is proportional to the square root of n. In other 
words, if the daily standard deviation of an equity index is 1% and the returns of the 
index follow a random walk, then the standard deviation of 25-day returns will be 
5%, and the standard deviation of 100-day returns will be 10%.
When we introduce autocorrelation, this square root rule no longer holds. In-
stead of a random walk, assume returns follow an AR(1) series:
	
r
r
t
t
t
i
i
t i
=
+
+
=
−
+
−
=
∞
−
∑
α
λ
ε
α
λ
λ ε
1
0
1

(11.23)
Now define a two-period return:
	
y
r
r
t
t
t
t
i
i
t i
2
1
0
1
2
1
1
,
(
)
=
+
=
−
+
+
+
−
=
∞
−−
∑
α
λ
ε
λ
λ ε

(11.24)
With just two periods, the introduction of autocorrelation has already made the 
description of our multiperiod return noticeably more complicated. The variance of 
this series is now:
	
Var[
]
,
y
t
2
2
2
1
=
−λ σε 
(11.25)
If λ is zero, then our time series is equivalent to a random walk and our new 
variance formula gives the correct answer: that the variance is still proportional to 
the length of our multiperiod return. If λ is greater than zero, and serial correlation 
is positive, then the two-period variance will be more than twice as great as the 

Time Series Models
223
single-period variance. If λ is less than zero, and the serial correlation is negative, 
then the two-period variance will be less than twice the single-period variance. This 
makes sense. For series with negative serial correlation, a large positive excess return 
will tend to be followed by a negative excess return, pulling the series back toward 
its mean, thereby reducing the multiperiod variance. The opposite is true for series 
with positive serial correlation.
Time series with slightly positive or negative serial correlation abound in fi-
nance. It is a common mistake to assume that variance is linear in time, when in 
fact it is not. Assuming no serial correlation when it does exist can lead to a serious 
overestimation or underestimation of risk.
Stationarity
In the preceding section we discussed unstable series whose means and variances 
tend to grow without bound. There are many series in the real world that tend 
to grow exponentially—stock market indexes and gross domestic product (GDP), 
for example—while other series such as interest rates, inflation, and exchange rates 
typically fluctuate in narrow bands. This dichotomy, between series that tend to 
grow without limit and those series that tend to fluctuate around a constant level, 
is extremely important in statistics. We call series that tend to fluctuate around a 
constant level stationary time series. In contrast, series that are divergent are known 
as nonstationary. Determining whether a series is stationary is often the first step in 
time series analysis.
To be more precise, we say that a random variable X is stationary if for all 
t and n:
	 1.	E[xt] = µ and | µ | < ∞
	 2.	Var[xt] = σ2 and | σ2 | < ∞
(11.26)
	 3.	Cov[xt, xt−n] = σt, t−n
where µ, σ2, and σt,t–n are constants. These three conditions state that the mean, 
variance, and serial correlation should be constant over time. We also require 
that the mean and variance be finite. In addition, some statisticians include the 
­condition that the distribution of X is stable over time. This is often called strong 
stationarity, as opposed to weak stationarity when only the first three conditions 
are met.
While we can calculate a sample mean or variance for a nonstationary series, 
these statistics are not very useful. Because the mean and variance are changing, by 
definition, these sample statistics will not tell us anything about the mean and vari-
ance of the distribution in general.
Regression analysis on nonstationary series is likely to be even more mean-
ingless. If a series is nonstationary because its volatility varies over time, then it 
violates the ordinary least squares (OLS) requirement of homoscedasticity. Even if 
the variance is constant, but the mean is drifting, any conclusions we might draw 
about the relationship between two nonstationary series will almost certainly be 
spurious.

224
Mathematics and Statistics for Financial Risk Management
Sample Problem
As an example of this type of spurious correlation, imagine two AR(1) series 
with nonzero drifts. To make the calculations easier, we also assume that both 
series start at zero:
p
p
p
q
q
t
p
t
p t
p
t
q
t
q
=
+
+
≠
=
=
+
+
−
−
α
ε
α
α
ε
1
0
1
0
0
,
,
where
,
,
t
q
q
where
α
≠
=
0
0
0
We assume that both disturbance terms are mean zero and uncorrelated, 
which can be summarized as:
E
E
E
p t
q t
p t q t
[
]
[
]
[
]
,
,
,
,
ε
ε
ε
ε
=
=
=
0
0
The two series are independent by design; pt is not a function of qt, nor is qt 
a function of pt; pt might be a model of milk prices in Germany, and qt a model 
of life expectancy in Singapore. The two series have no causal relationship.
At any given point in time, the expected value of p is just tαp:
p
p
n
p
t
t
p
t
p t
p
t n
p t i
i
n
p
=
+
+
=
+
+
=
+
−
−
−
=
−
∑
α
ε
α
ε
α
1
0
1
,
,
ε
ε
α
p t i
i
t
p
t
p t i
i
t
E p
t
E
,
,
[
]
−
=
−
−
=
−
∑
∑
+
=
0
1
0
1
= t
p
α
Imagine that we tried to calculate the mean of p between 0 and t:

∑
=
+
=
p
t
p
1
1
i
i
t
0
It is quite simple to calculate the expected value of this sample mean:
E p
t
E p
t
i
E p
t
i
i
t
p
i
t
p
[ ]
[
]
[ ]


=
+
=
+
=
+
=
=
∑
∑
1
1
1
1
0
0
α
α
1
1
1
2
2
0
i
t
t t
E p
t
i
t
p
p
= +
+
=
=
=∑
α
α
(
)
[ ]
As expected, the sample mean is not independent of t. The result for our 
second series, q, is similar, only replacing αp with αq. If we take these sample 
means as given, we could try to construct a sample covariance:



σ p q
i
i
i
t
i
i
i
t
t
p q
E p E q
t
p q
,
[ ] [ ]
=
+
−
=
+
=
=
∑
1
1
1
1
0
0∑
−α α
p
q
t2
4

Time Series Models
225
To calculate the expected value of this series, we need to know that the 
sum of series, 0, 1, 4, 9,  .  .  . (t – 1)2, t2 is equal to t(t + 1)(2t + 1)/6:
E
t
t
p q
p
q
[
]
,
σ
α α
=
+
2
2
12
Clearly, if both αp and αq are nonzero, then this sample covariance esti-
mator will also be nonzero, despite the fact that the series are uncorrelated 
by design. We could imagine trying to calculate a similar variance estimator 
(variance is just the covariance of a variable with itself) and using the result to 
create an estimate of the slope in a regression of p on q:
β
σ
σ
α α
α
α
α
=
=
+
+
=


p q
p
p
q
p
q
p
t
t
t
t
,
2
2
2
2
2
12
2
12
Though it was a long time in coming, this result is rather intuitive. If αp 
is twice the value of αq, then at any point in time we will expect p to be twice 
the value of q. 
Exhibit 11.4 shows one iteration from a Monte Carlo simulation with 
αp = 2, αq = 1. If we plotted these two series against each other, the points 
would tend to line up along a line with a slope equal to 2. 
–50
0
50
100
150
200
0
4
8
12
16
20
24
28
32
36
40
44
48
52
56
60
64
68
72
76
80
84
88
92
96
100
p
q
t
Exhibit 11.4 
Two Nonstationary Time Series
This should all seem very wrong. If two variables are independent, we ex-
pect them to have zero covariance, but because these series both have nonzero 
drift terms, the sample covariance and beta will also tend to be nonzero. The 
results are clearly spurious.

226
Mathematics and Statistics for Financial Risk Management
In a situation such as our sample problem, you could argue that even though 
the two AR(1) series are independent, the positive sample covariance is telling us 
something meaningful: that both series have nonzero drift terms. How meaningful 
is this? Not very, as it turns out. Any random variable with a nonzero mean can be 
turned into a nonstationary series. Log returns of equities tend to be stationary, but 
the addition of those returns over time, log prices, are nonstationary.
To show just how silly all of this can get, in a classic example, Hendry (1980) 
showed how, if statistical analysis is done incorrectly, you might conclude that cu-
mulative rainfall in the United Kingdom and the UK price index where causally 
related. In most stable economies, inflation tends to be slightly positive on average, 
and stationary. The accumulation of this inflation over time results in ever-increasing 
prices. Rainfall, which in any given year will be equal to or greater than zero—al-
most certainly greater than zero in the United Kingdom—can also safely be assumed 
to be a stationary series. But if we plot the cumulative rainfall in the United Kingdom 
since 1900, say, this series will be constantly growing, and nonstationary. Rainfall 
doesn’t cause inflation, or the opposite way around, but if done improperly, statisti-
cal analysis might make you think it did.
Exhibit 11.5 shows a regression of cumulative rainfall and the log price index 
in the United Kingdom between 1949 and 2010. We use the log price level to ensure 
that the relationship is linear (remember from Chapter 1: plotted on a logarithmic 
scale, a series whose growth rate is constant over time will have a constant slope and 
appear as a straight line). The two series are highly correlated, but only because both 
series are increasing over time.
Exhibit 11.5 
United Kingdom: Log Price Level and Cumulative Rainfall, 1949–2010
Sources: Met Office and Office for National Statistics, United Kingdom.
0.0
1.0
2.0
3.0
4.0
5.0
6.0
7.0
0
1,000
2,000
3,000
4,000
5,000
Cumulative Rainfall (cm)
Log Price Level

Time Series Models
227
The remedy for stationarity in statistical analysis is clear. Just as we can con-
struct a nonstationary series from a stationary one by summing over time, we can 
usually create a stationary series from a nonstationary series by taking its difference. 
Transforming a price series into returns is by now a familiar example. Occasionally 
additional steps will need to be taken (e.g., differencing twice), but for most financial 
and economic series, this will suffice.
Exhibit 11.6 shows a regression based on the same data set we used in Exhibit 
11.5, only now instead of cumulative rainfall we are using annual rainfall, and in-
stead of the log price level we are using changes in the log price index. This new 
chart looks very different. The regression line is very close to being flat, and the slope 
parameter is in fact not significant. In other words, rainfall has no meaningful impact 
on inflation, just as we would expect.
Ascribing a causal relationship when none exists is a serious mistake. Unfortu-
nately, in this day and age, it is easy to gather massive amounts of data and perform 
a quick regression analysis. When performing statistical analysis of time series data, 
it is important to check for stationarity.
Moving Average
Besides autoregressive (AR) series, the other major class of time series is moving 
averages (MAs). An MA(n) series takes the form:
	
xt
t
t
n t n
=
+
+
+
−
−
ε
θ ε
θ ε
1
1
...
	
(11.27)
Exhibit 11.6 
United Kingdom: Change in Log Price Level and Annual Rainfall, 1949–2010
Sources: Met Office and Office for National Statistics, United Kingdom.
–5%
0%
5%
10%
15%
20%
25%
0
20
40
60
80
100
120
Annual Rainfall (cm)
Change in Log Price Level

228
Mathematics and Statistics for Financial Risk Management
Moving average series can be combined with autoregressive series to form 
ARMA(p,q) processes:
	
x
x
x
x
t
t
t
p
t p
t
t
=
+
+
+
+
+
+
+
−
−
−
−
λ
λ
λ
ε
θ ε
θ
1
1
2
2
1
1
...
...
q t q
ε −
(11.28)
Moving averages and ARMA processes are important in statistics, but are less 
common in finance.
Continuous Models
Up until now, our time series models have all assumed discrete time intervals. From 
time t – 1 to t to t + 1, our models progressed in uniform intervals. Time just jumped 
from one instance to the next. By contrast, continuous time series models define a 
system as a function of a continuous time variable.
A continuous time series model can be thought of as a discrete time series model, 
where the time interval is infinitely short. To see how this works, we can start with a 
discrete random walk. This time we specify that there are n discrete steps of length 
h between t = 0 and t = T:
	
p
p
t
h
h
h
nh
nh
T
t
t
t
=
+
=
=
−1
0
2
3
ε
, ,
,
...

(11.29)
Unlike in previous examples where the disturbance term was continuous, we 
imagine that the disturbance term is also discrete. At the start of each time interval, 
the time series jumps by positive or negative Δ, with equal probability:
	
   [
]
.
[
]
.
P
P
t
t
ε
ε
=
=
= −
=
∆
∆
0 5
0 5
(11.30)
In a discrete model, what happens between t and (t + 1) is unknown. To make 
our model continuous, we only need to specify what happens in this interval. We 
start by assuming the model is constant between jumps. In other words, plotted over 
time, the series would look something like Exhibit 11.7.
This type of process is often described as a step function. We can write the rela-
tionship between the discrete and continuous series formally as:
	
p t
p
( )
n
t h
[ / ]
=

(11.31)
Here, pn(t) is a continuous function defined for any real value of t between 0 and 
T. The square brackets, [∙], signify the greatest integer function. For example, if our 
time interval is two units, for t = 8.648 we get: [8.648/2] = [4.324] = 5. This series, 
pn(t), is continuous but not differentiable.
At the time t = T, the mean and variance of pn(t) are:
	
E p T
p t
T
h
n
n
[
( )]
[
( )]
=
=
0
2
Var
∆

(11.32)

Time Series Models
229
To make this process both continuous and differentiable, we imagine shrinking 
h down to zero, which is equivalent to letting n go to infinity. The trick is to define 
Δ in such a way that the variance is well behaved (i.e., finite) as n goes to infinity. It 
would also be nice if the variance was linear in time; therefore, we specify:
	
Var[
( )]
p t
T
h
T
n
=
=
∆2
2
σ
	
(11.33)
We can solve for Δ to get:
	
∆= σ
h 	
(11.34)
In the limit, as h goes to zero, Δ remains proportional to the square root of h. In 
the limit, this process is referred to as a Wiener process, or Brownian motion. When 
the mean is zero and the variance is one, we refer to the process as standard Brown-
ian motion, which is often denoted as B(t). The proof is beyond the scope of this 
book, but it might not be surprising to learn that Brownian motion is also normally 
distributed.1 We can summarize this as:
	
B t
N
( )
(0,1)
∼

(11.35)
Standard Brownian motion forms the basis for a more general class of processes 
known as arithmetic Brownian motion, which can be formulated as:
	
p t
t
B t
( )
( )
=
+
µ
σ

(11.36)
1 For a more formal version of this derivation and an excellent introduction to stochastic dif-
ferential equations, see Campbell, Lo, and MacKinlay (1996).
Exhibit 11.7 
Step Function
–2
–1
0
1
2
3
0
1h
2h
3h
4h
5h
6h
7h
8h
9h

230
Mathematics and Statistics for Financial Risk Management
This process is also normally distributed, but with a mean of µ and a standard devia-
tion of σ. If we take the exponent of p(t), we get geometric Brownian motion:
	
P t
e
( )
p t( )
=
	
(11.37)
Here, p(t) is arithmetic Brownian motion, and P(t) is geometric Brownian motion. 
One of the most celebrated uses of geometric Brownian motion is in the derivation 
of the Black-Scholes equation for options pricing. In the Black-Scholes option pric-
ing model, it is assumed that the stock price follows geometric Brownian motion.
Continuous time series models offer both advantages and disadvantages com-
pared to discrete models. Continuous time series models can provide closed-form 
solutions to some extremely difficult problems. When these solutions exist, they 
can provide answers to problems that would be difficult or impossible to solve 
with discrete models. Unfortunately, the mathematics for these solutions is often 
very difficult. Discrete models are extremely flexible, and—as we’ve seen—their 
behavior is often easy to analyze using our standard statistical toolbox. Digital 
computers are inherently discrete, making discrete time series models a logical 
choice for computer simulations. As computers become increasingly powerful, 
they are gradually eliminating a major advantage of continuous models, namely 
computational speed.
Application: GARCH
Up until this point, all of our time series models have assumed that the variance 
of the disturbance term remains constant over time. In financial markets, variance 
appears to be far from constant. Both prolonged periods of high variance and pro-
longed periods of low variance are observed. While the transition from low to high 
variance can be sudden, more often we observe serial correlation in variance, with 
gradual mean reversion. When this is the case, periods of above-average variance 
are more likely to be followed by periods of above-average variance, and periods 
of below-average variance are likely to be followed by periods of below-average 
variance. For risk managers, this is one of the most important features of financial 
markets. It implies that risk varies over time, and that this variation in risk is, in part, 
predictable.
Exhibit 11.8 shows the rolling annualized 60-day standard deviation of the S&P 
500 index between 1928 and 2008. Notice how the level of the standard deviation 
is far from random. There are periods of sustained high volatility (e.g., 1996–2003) 
and periods of sustained low volatility (e.g., 1964–1969).
One of the most popular models of time-varying volatility is the autoregressive 
conditional heteroscedasticity (ARCH) model. We start by defining a disturbance 
term at time t, εt, in terms of an independent and identically distributed (i.i.d.) stand-
ard normal variable, ut, and a time varying standard deviation, σt:
	
ε
σ
t
t
tu
=

(11.38)
Because the standard deviation of ut is 1, the standard deviation of εt must be 
σt. With the exception of the degenerate case, where σt is constant, εt will not be 

Time Series Models
231
i.i.d. This is a departure from all of the models that we have seen up until now. In the 
simplest ARCH model, we can model the evolution of the variance as:
	
σ
α σ
α σ
α σ
α ε
t
t
t
t
u
2
0
2
1
1
2
1
2
0
2
1
1
2
=
+
=
+
−
−
−	
(11.39)
where α0 and α1 are constants, and σ_2 is the long-run variance. To ensure that σ2 
remains positive, we square ut−1 and εt−1 and require α0 > 0, α1 ≥ 0, andσ0
2
0
> .
For σ2 to be stable over time, we require that α0 + α1 = 1. Because ut is stand-
ard normal, the expected value of ut−1
2
is equal to 1. Because ut is mean zero and 
independent of σt, we also know that 
u
E
E
E
u
t
t
t
t
σ
σ
−
−
−
−
=
1
2
1
2
1
2
1
2
. Putting this 
altogether, we have:
	
E
E
t
t
α
σ
α
σ
σ
2
0
2
1
1
2
+
=
−
	
(11.40)
The requirement that α0 + α1 = 1 is then equivalent to requiring that the expected 
value of the variance equal the long-run variance, 
E
E
t
t
σ
σ
σ
2
1
2
2
=
=
−
. 
Notice how σt is influenced by the lagged value of the disturbance term, εt−1. If 
there is a large disturbance (positive or negative) and α1 is greater than zero, then σt 
will be greater than when the disturbance is small. This leads to serial correlation in 
our disturbance term. High volatility begets high volatility. Equation 11.39 is typi-
cally referred to as an ARCH(1) model. By adding more lagged terms containing σ2 
and u2, we can generalize to an ARCH(n) specification.
	
σ
α σ
α σ
t
i
t i
t i
i
n
u
2
0
2
2
2
1
=
+
−
−
=
∑
	
(11.41)
Exhibit 11.8 
S&P 500, Annualized 60-Day Return Standard Deviation, 1928–2008
0%
10%
20%
30%
40%
50%
60%
70%
80%
3/28/1928
3/28/1938
3/28/1948
3/28/1958
3/28/1968
3/28/1978
3/28/1988
3/28/1998
3/28/2008
Return Volatility

232
Mathematics and Statistics for Financial Risk Management
Besides the additional disturbance terms, we can also add lags of σ2 itself to the 
equation. In this form, the process is known as generalized autoregressive condi-
tional heteroscedasticity (GARCH). The following describes a GARCH(1,1) process:
	
σ
α σ
α σ
βσ
t
t
t
t
u
2
0
2
1
1
2
1
2
1
2
=
+
+
−
−
−	
(11.42)
For the GARCH(1,1) to be stable, we require that α0 + α1 + β  = 1. Just as 
with the ARCH model, by adding additional terms we can build a more general 
GARCH(n,m) process.
Application: Jump-Diffusion Model
In the GARCH model, volatility changes gradually over time. In financial markets 
we do observe this sort of behavior, but we also see extreme events that seem to 
come out of nowhere. For example, on February 27, 2007, in the midst of otherwise 
calm markets, rumors that the Chinese central bank might raise interest rates, along 
with some bad economic news in the United States, contributed to what, by some 
measures, was a –8 standard deviation move in U.S. equity markets. A move of this 
many standard deviations would be extremely rare in most standard parametric 
distributions.
One popular way to generate this type of extreme return is to add a so-called 
jump term to our standard time series model. This can be done by adding a second 
disturbance term:
	
r
I u
t
t
t
t
=
+
+
α
ε
[
]

(11.43)
Here, rt is the market return at time t, α is a constant drift term, and εt is our stand-
ard mean zero diffusion term. As specified, our jump term has two components: [It], 
an indicator variable that is either zero or one, and ut, an additional disturbance 
term. Not surprisingly, as specified, this time series model is referred to as a jump-
diffusion model.
The jump-diffusion model is really just a mixture model. To get the type of be-
havior we want—moderate volatility punctuated by rare extreme events—we can 
set the variance of εt to relatively modest levels. We then specify the probability of 
[It] equaling one at some relatively low level, and set the variance of ut at a relatively 
high level. If we believe that extreme negative returns are more likely than extreme 
positive returns, we can also make the distribution of ut asymmetrical.
GARCH and jump-diffusion are not mutually exclusive. By combining GARCH 
and jump-diffusion, we can model and understand a wide range of market environ-
ments and dynamics.
Application: Interest Rate Models
In our discussion of autoregressive processes, we mentioned that these models, or 
models similar to them, might be used to model interest rates. In this section we give 
a very brief introduction to quantitative interest rate models. Most of these models 

Time Series Models
233
were originally developed as continuous time models, but it is easy enough to de-
scribe discrete time counterparts for each. The availability of cheap computer power 
and the use of more complex derivatives has made these discrete models increasingly 
popular. For these reasons and for consistency with the rest of this chapter, we pre-
sent the interest rate models in their discrete form, without further comment.
The simplest interest rate models are known as one-factor models. They de-
scribe the evolution of one interest rate, typically the short rate (the current, con-
tinuously compounded interest rate). The rest of the interest rate curve can then be 
derived from the short rate. Though less rigorous, most interest rate models can be 
used to model an interest rate of a specific term directly. If all you are interested in 
is the 10-year Treasury rate, then there is no need to model the whole interest rate 
curve.
One popular interest rate model, known as the Vasicek model, simply describes 
interest rates as an AR(1) process:
	
r
r
r
N
t
t
t
t
=
+
−
+
≤
≤
−
−
λ
λ θ
σ
ε
ε
λ
1
1
12
1
0 1 0
1
(
)
( , ),
∼

(11.44)
Here, we’ve split our disturbance term into two parts. Now ε is a standard normal 
variable, and we’re multiplying it by a constant, σ, to alter the standard deviation of 
the disturbance term. This is entirely equivalent to having a disturbance term with 
a standard deviation of σ. Neither way of representing the disturbance term is nec-
essarily better, but this functional form is popular in finance, and very popular for 
interest rate models.
As with any AR(1) process, the expected value of the process, the expected inter-
est rate, is θ. Also, λ determines how quickly the process mean reverts. In this case a 
value of λ closer to zero causes the interest rate to move more quickly back toward 
the mean level, θ. A value closer to one implies that the interest rate is closer to a 
random walk, and reverts more slowly to the mean.
One problem with the Vasicek model is that it allows interest rates to take on 
negative values. In the real world, nominal interest rates are almost never negative. 
In practice, if θ is high enough and σ is low, the probability of generating negative 
rates can be kept very low. If a negative interest rate is generated, we can discard 
it or override it with some very small nonnegative value. This solution is not very 
elegant, and it will alter the statistical properties of the model, but in certain settings 
this may be acceptable.
A slightly more complex model known as the Cox-Ingersoll-Ross (CIR) model 
aims to solve the negative interest rate problem by varying the disturbance term as 
the level of the interest rate changes. As the interest rate approaches zero, the mag-
nitude of the disturbance term becomes smaller and smaller. This is accomplished by 
adding one additional term to the Vasicek model:
	
r
r
r
N
t
t
t
t
=
+
−
+
≤
≤
−
−
λ
λ θ
σ
ε
ε
λ
1
1
12
1
0 1 0
1
(
)
  
( , ),
∼

(11.45)
As you can see, the disturbance term is now proportional to the square root 
of the interest rate. As interest rates approach zero, the volatility of interest rates 
declines. In the continuous case, this is enough to keep interest rates from ever be-
coming zero. In the discrete case, rates can still become negative, but it is much less 
likely to happen.

234
Mathematics and Statistics for Financial Risk Management
Modifying the disturbance term in this way solves one problem, but it is not 
without its drawbacks. Chief among the drawbacks is that our standard trick of 
iteratively substituting the model into itself will no longer work. In order to derive 
the statistical properties of this process—the mean and variance, for example—we 
would need to use other methods.
Besides preventing interest rates from becoming negative, the CIR model is ap-
pealing because the volatility of interest rates does appear to vary with the level of 
interest rates. When interest rates are high—say 15% to 20%—they are likely to be 
much more volatile than when they are low—say 0% to 5%. This pattern can be 
observed historically, between countries, and between different financial instruments 
within countries.
Interest rate volatility tends to increase as interest rates rise, but does it vary ex-
actly with the square root of interest rates as implied by the CIR model? This square 
root rule has some theoretical advantages, but might seem arbitrary. The obvious 
solution is to make the exponent in the disturbance term variable as well:
	
r
r
r
N
t
t
t
t
=
+
−
+
≤
≤
−
−
λ
λ θ
σ
ε
ε
λ
φ
1
1
1
0 1 0
1
(
)
  
( , ),
∼
	
(11.46)
This is known as the constant elasticity of volatility (CEV) model. For a particu-
lar instrument, the new parameter, φ, can be determined by examining interest rate 
data over time. As it turns out, many empirical studies have ended up with values for φ 
very close to 0.5. This has led some practitioners to stick with the simpler CIR model.
To avoid negative rates, the Black-Karasinski interest rate model utilizes log 
rates:
	
ln( )
ln(
)
(
)
  
( , ),
r
r
N
t
t
t
=
+
−
+
≤
≤
−
λ
λ θ
σε
ε
λ
1
1
0 1 0
1
∼
	
(11.47)
Note that this is not the log of (1 + r), but simply the log of r. Unlike the use of log 
returns in equity models, where we want to ensure that returns are greater than 
−100%, here we want to ensure that rates are greater than zero. Unfortunately, while 
the log of (1 + r) is very close in value to r, the log of r is nothing like r. For example, 
the log of 4% is approximately –3.22.
One-factor interest rate models display a wide variety of adaptations aimed at 
solving real-world problems. They begin to hint at the flexibility and complexity of 
time series modeling in practice.
Problems
	 1.	Classify each of the following time series models in terms of the random variable rt:
a.	 rt = α + λ1rt−1 + λ2rt−2 + εt
b.	rt = θµ + (1 − θ)rt−1 + εt
c.	 rt = λ1rt−1 + λ2rt−2 + εt + θ1εt−1
d.	rt = α + εt
	 2.	You are given the following time series model. What is the long-term expected 
value of rt?
rt = 0.02 + 0.8rt−1 + εt

Time Series Models
235
	 3.	Assume that a credit spread evolves according to the following time series equation:
rt = 0.01 + 0.30rt−1 − 0.20rt−2 + εt
	
	 Further, assume rt was 2% during the most recent period, and 4% during the pe-
riod before that. What is the expected value of rt in the next period? The period 
after that?
	 4.	Assume that daily stock returns for RW Corporation can be described by the 
following equation:
rt = Δpt = εt
	
	 where rt is a log return, and the error term, εt, is i.i.d., with a mean of zero and 
a standard deviation of 1.5%. What is the expected log return over one year? 
What is the standard deviation of this annual log return? Ignore weekends, and 
assume 256 business days per year.
	 5.	Assume that daily stock returns for Drift Corporation can be described by the 
following equation:
rt = Δpt = α + εt
	
	 where rt is a log return; the error term, εt, is i.i.d., with a mean of zero and a 
standard deviation of 1.5%; and α is a constant equal to 0.10%. What is the 
expected log return over one year? What is the standard deviation of this annual 
log return? Ignore weekends, and assume 256 business days per year.
	 6.	Assume that daily stock returns for Reversion Corporation can be described by 
the following time series equation:
rt = α + λrt−1 + εt
	
	 where rt is a log return; the error term, εt, is i.i.d., with a mean of zero and a 
standard deviation of 1.5%; α is a constant equal to 0.10%; and λ is a constant 
equal to 0.50. What is the expected log return over two days? What is the stand-
ard deviation of this two-day return? Ignore weekends, and assume that rt was 
equal to zero in the distant past. What would the mean and standard deviation 
of the two-day return be if λ was equal to –0.50?
	 7.	Assume that interest rates evolve according to the following Vasicek model:
	
	 rt = λrt−1 + (1 − λ)θ + σεt    ε ∼ N(0,1)
	
	 λ = 0.50
	
	 θ = 0.04
	
	 σ = 0.02
	
	 What is the unconditional expected value of rt? Assuming interest rates are 
currently 6%, what is the conditional expected value of rt over the next three 
p­eriods?

236
Mathematics and Statistics for Financial Risk Management
	 8.	Assume the spread between two equity indexes can be described by the follow-
ing time series equation:
rt = ρrt−1 + εt    ε ∼ N(0,σ2), | ρ | ≤ 1
Cov[εt−i, εt−j] = 0    ∀i ≠ j
	
	 Derive equations for the unconditional mean and variance of this process.
	 9.	For the time series equation in the previous problem, what is the correlation 
between rt and a previous return, rt–n?
	10.	Given our AR(1) process, Equation 11.11,
rt = α + λ r t−1 + εt
	
	 prove that the serial correlation is equal to λ.
	11.	You are provided with 10 years of monthly log returns for a mutual fund. The 
mean monthly log return is 2.0%, the standard deviation of the returns is 1.5%, 
the skewness is –1.0, and the kurtosis is 2.4. Assuming the log returns are i.i.d., 
what are the expected annualized mean, standard deviation, skewness, and kur-
tosis of the log returns?

237
I
n this chapter we explore a class of estimators that has become very popular in 
finance and risk management for analyzing historical data. These models hint at 
the limitations of the type of analysis that we have explored in previous chapters.
Mean
In previous chapters, we showed that the best linear unbiased estimator (BLUE) for 
the sample mean of a random variable was given by:
	
ˆµ =
−
=
−
∑
1
0
1
n
xt i
i
n

(12.1)
For a practitioner, this formula immediately raises the question of what value 
to use for n. Because this chapter is concerned with historical data, what value to 
choose for n is equivalent to asking how far back in time we should look for data. 
Should we use 10 years of data? One year? Thirty days? A popular choice in many 
fields is simply to use all available data. If we have only 20 days of data, use 20 days; 
if we have 80 years, use 80 years. While this can be a sensible approach in some 
circumstances, it is much less common in modern finance. Using all available data 
has three potential drawbacks. First, the amount of available data for different vari-
ables may vary dramatically. If we are trying to calculate the mean return for two 
fixed-income portfolio managers, and we have 20 years of data for one and only 
two years of data for another, and the last two years have been particularly good 
years for fixed-income portfolio managers, a direct comparison of the means will 
naturally favor the manager with only two years of data. We could limit ourselves to 
the length of the shortest series, but there are potential drawbacks to this approach 
as well.
The second problem that arises when we use all available data is that our ­series 
length changes over time. If we have 500 days of data today, we will have 501 
­tomorrow, 502 the day after that, and so on. This is not necessarily a bad thing—
more data may lead to a more accurate forecast—but, in practice, it is often con-
venient to maintain a constant window length. Among other advantages, a constant 
window length makes it easier to compare the accuracy of models over time.
Finally, there is the problem that the world is constantly changing. The Dow 
Jones Industrial Average has been available since 1896. There were initially just 
chapter 12     
Decay Factors

238
Mathematics and Statistics for Financial Risk Management
12 companies in the index, including American Cotton Oil Company and Distilling 
& Cattle Feeding Company. That same year, Utah became the 45th U.S. state, and 
Queen Victoria became the longest-ruling monarch in British history. Forget com-
puters; in 1896, the Model T had not yet been introduced (1908), and the Wright 
Brothers’ famous flight at Kitty Hawk was still some years off (1903). Does it make 
any sense to use stock market data from 1896 to evaluate the risk of a securities 
portfolio today? It is easy to argue that the world was so different in the distant 
past—and in finance, the distant past is not necessarily that distant—that using ex-
tremely old data makes little sense.
If we are not going to use all available data, then a logical alternative is a con-
stant window length. This is not without its own problems. If we use Equation 12.1 
with a constant window length, then in each successive period, we add the most 
recent point to our data set and drop the oldest. The first objection to this method 
is philosophical. How can it be that the oldest point in our data set is considered 
just as legitimate as all the other points in our data set today (they have the same 
weight), yet in the very next period, the oldest point becomes completely illegitimate 
(zero weight)?
The second objection is more aesthetic. As extreme points enter and leave our 
data set, this can cause dramatic changes in our estimator. Exhibit 12.1 shows a 
sample time series. Notice the outlier in the series at time t = 50. Exhibit 12.2 shows 
the rolling 40-day mean for the series.
Notice how the spike in the original time series causes a sudden rise and drop in 
our estimate of the mean in Exhibit 12.2. Because of its appearance, this phenomenon 
Exhibit 12.1 
Time Series with Spike
0
5
10
15
20
25
30
35
0
10
20
30
40
50
60
70
80
90
100
110
t
y

Decay Factors
239
is often referred to as plateauing. Technically, there is nothing wrong with plateau-
ing, but many practitioners find this type of behavior unappealing.
In the end, the window length chosen is often arbitrary. Rarely in risk manage-
ment are we presented with an obvious right choice for window length. Practitioners 
often choose windows that correspond to standard calendar units (one week, one 
month, one year) or round numbers (100 days, 500 days). While they are convenient 
and widely used, it is difficult to see why these common window lengths are better 
than, say, one year plus five days or 142 days.
One approach that addresses many of these objections is known as an exponen-
tially weighted moving average (EWMA). An EWMA is a weighted mean in which 
the weights decrease exponentially as we go back in time. The EWMA estimator of 
the mean can be formulated as:
	
ˆµ
δ
δ
δ
t
n
i
t i
i
n
x
=
−
−
−
=
−
∑
1
1
0
1

(12.2)
Here, δ is a decay factor, where 0 < δ < 1. For the remainder of this chapter, unless 
noted otherwise, assume that any decay factor, δ, is between zero and one. The term 
in front of the summation is the—by now familiar—inverse of the summation of δ 
from 0 to n − 1.
In the EWMA, more weight is placed on more recent events. For example, if we 
have 10 sample points and a decay factor of 0.90, then the first point gets approxi-
mately 15% of the total weight, and the last point gets less than 6%. Exhibit 12.3 
shows the weights for all 10 points.
Exhibit 12.2 
Rolling Mean of Time Series with Spike
4.0
4.2
4.4
4.6
4.8
5.0
5.2
5.4
5.6
5.8
6.0
0
10
20
30
40
50
60
70
80
90
100
110
t
40-Day Mean

240
Mathematics and Statistics for Financial Risk Management
Exhibit 12.4 plots these weights against time, as well as the corresponding 
weights for the standard equally weighted BLUE.
As you can see, the EWMA weights form a smooth exponential curve that fades 
at a constant rate as we go back in time. By contrast, because of the shape of the 
chart, we often refer to the equally weighted estimator as a rectangular window.
Exhibit 12.3 
Example of EWMA Weights
Age
δi
Weight
0
1.00
15.35%
1
0.90
13.82%
2
0.81
12.44%
3
0.73
11.19%
4
0.66
10.07%
5
0.59
9.07%
6
0.53
8.16%
7
0.48
7.34%
8
0.43
6.61%
9
0.39
5.95%
Total
6.51
100.00%
Exhibit 12.4 
EWMA versus Rectangular Weights
4%
6%
8%
10%
12%
14%
16%
0
1
2
3
4
5
6
7
8
9
10
11
12
Age
Weight
Rectangular
Decay = 0.90

Decay Factors
241
One way we can characterize an EWMA is by its half-life. Half of the weight 
of the average comes before the half-life, and half after. We can find the half-life by 
solving for h in the following equation:
	
i
h
i
i
n
i
=
−
=
−
∑
∑
=
0
1
0
1
1
2
δ
δ 	
(12.3)
The solution is:
	
h
n
=
+
ln( .
.
)
ln( )
0 5
0 5δ
δ
	
(12.4)
For a sample of 250 data points and a decay factor of 0.98, the half-life is ap-
proximately 34. In other words, half of the weight of the estimator would be cap-
tured by the most recent 34 data points, and half in the remaining 216. A rectangular 
window of 250 data points, by comparison, would have a half-life of 125. Looked 
at another way, the EWMA with 250 data points and a decay factor of 0.98 has the 
same half-life as a rectangular window with 68 data points.
The EWMA can solve the problem of plateauing. The addition of an extreme 
data point to our data set can still cause a sudden change in our estimator, but the 
impact of that data point will slowly fade over time. Just before it exits the data set, 
the weight on the data point is likely to be so small that its removal will hardly be 
noticed. Exhibit 12.5 shows the same series as we saw in Exhibit 12.2. In addition 
to the estimator based on an equally weighted 40-day window, we have added an 
estimator based on a 40-day window with a decay factor of 0.95. As you can see, for 
the series with the decay factor, the second transition is much more gradual.
Exhibit 12.5 
Rolling Mean, EWMA versus Rectangular Window
4.0
4.5
5.0
5.5
6.0
6.5
0
10
20
30
40
50
60
70
80
90
100
110
t
40-Day Mean
Rectangular
Decay = 0.96

242
Mathematics and Statistics for Financial Risk Management
Besides addressing the aesthetic issue of plateauing, the EWMA estimator also 
addresses our philosophical objection to fixed windows. Rather than suddenly 
dropping out of the data set, the weight on any point is slowly reduced over time.
Finally, a fixed window length with a decay factor can be viewed as a compro-
mise between a rectangular window of arbitrary length and using all available data. 
Because |δ| is less than one, as n goes to infinity, Equation 12.2 can be rewritten as:
	
ˆ
(
)
µ
δ
δ
t
i
t i
i
x
=
−
−
=
∞
∑
1
0

(12.5)
Clearly an infinite series, if it did exist, would be using all available data. In prac-
tice, though, for reasonable decay factors, there will be very little weight on points 
from the distant past. Because of this, we can use a finite window length, but capture 
almost all of the weight of the infinite series. Using our geometric series math:
	
Weight of finite series
Weight of infinite series =
−
−
−
=
−
 1
1
1
1
1
δ
δ
δ
δ
n
n 
(12.6)
For a decay factor of 0.98, if our window length is 250, we would capture 
99.4% of the weight of the infinite series. Ultimately, the window length is still arbi-
trary, but the precise choice becomes less important. Whether we choose a window 
length that captures 99% of the weight or 99.9% will typically have little impact on 
our estimator.
By carefully rearranging Equation 12.5, we can express the EWMA estimator as 
a weighted average of its previous value and the most recent observation:
	
ˆ
(
)
(
)
µ
δ
δ
δ
δ
δ
t
i
t i
i
t
i
t i
i
x
x
x
=
−
=
−
+
−
=
∞
−−
=
∞
∑
∑
1
1
0
1
0
=
−
+
−
(
)
ˆ
1
1
δ
δµ
xt
t

(12.7)
Viewed this way, our EWMA is a formula for updating our beliefs about the mean 
over time. As new data become available, we slowly refine our estimate of the mean. 
This updating approach seems very logical, and could be used as a justification for 
the EWMA approach.
While the use of a decay factor addresses many practical and aesthetic problems 
associated with the standard equally weighted estimator, there may be little theoreti-
cal justification for the precise form of the EWMA estimator. If our data-generating 
process is constant over time, then the standard estimator is still the best linear un-
biased estimator.
If the world is constantly changing, then the distributions of the variables we 
are interested in—stock returns, interest rates, and so on—will also be changing 
over time. It’s not necessarily the case, but if the variables we are interested in are 
constantly changing, then the parameters that describe these variables may be more 
similar to their recent values than to their values in the distant past. While there is 
a certain logic to this changing world justification, most of the models that we have 
developed up until now assume constant parameters, not parameters that slowly 
change over time. This approach represents a significant departure from the methods 
we have explored in previous chapters.

Decay Factors
243
Variance
Just as we used a decay factor when calculating the mean, we can use a decay factor 
when calculating other estimators. For an estimator of the sample variance, when the 
mean is known, the following is an unbiased estimator:
	
ˆ
 
σ
δ
δ
δ
µ
δ
t
n
i
t i
i
n
r
2
2
0
1
1
1
0
1
=
−
−
−
(
)
<
<
−
=
−
∑

(12.8)
If we imagine an estimator of infinite length, then the term δn goes to zero, and 
we have:
	
ˆ
(
)
σ
δ
δ
µ
δ
t
i
t i
i
r
2
2
0
1
0
1
=
−
−
(
)
<
<
−
=
∞
∑

(12.9)
This formula, in turn, leads to a useful updating rule:
	
ˆ
(
)
ˆ
σ
δ
µ
δσ
t
t
t
r
2
2
1
2
1
=
−
−
(
) +
−
(12.10)
As with our estimator of the mean, using a decay factor is equivalent to an updating 
rule. In this case, the new value of our estimator is a weighted average of the previous 
estimator and the most recent squared deviation.
As mentioned in connection with the standard estimator for variance, it is not 
uncommon in finance for the mean to be close to zero and much smaller than the 
standard deviation of returns. If we assume the mean is zero, then our updating rule 
simplifies even further to:
	
ˆ
(
)
ˆ
σ
δ
δσ
t
t
t
r
2
2
1
2
1
=
−
+
−
(12.11)
Remember that the preceding formula is valid only if we assume the mean is known 
and equal to zero.
In the case where the mean is unknown and must also be estimated, our estima-
tor takes on a slightly more complicated form:
	
ˆ
ˆ
σ
δ
µ
t
i
t i
i
n
t
A
r
B
2
2
0
1
2
=
−
−
=
−
∑

(12.12)
where ˆµt is our estimator of the sample mean, based on the same decay factor, δ, and 
A and B are constants defined as:
	
A
S
S
S
B
S A
S
S
n
n
=
−
=
=
−
−
=
−
−
1
1
2
2
1
1
2
2
2
1
1
1
1
δ
δ
δ
δ

(12.13)

244
Mathematics and Statistics for Financial Risk Management
Though these constants should look familiar by now, the addition of a decay factor 
has certainly made our variance estimator more complicated.
It is not too difficult to prove that in the limit, as δ approaches one—that is, as 
our estimator becomes a rectangular window—A approaches 1/(n − 1) and B con-
verges to n/(n − 1). Just as we would expect, in the limit our new estimator converges 
to the standard variance estimator.
If we wish to know the standard deviation of a time series using a decay factor, 
we can simply take the square root of the appropriate estimator of the variance. No 
additional steps are required.
Weighted Least Squares
To apply the same decay factor logic to linear regression analysis, we simply need to 
multiply all of the sample data, both the regressors and regressands, by the appro-
priate decay factors. Recall from Chapter 10 that, for a multivariate regression, the 
ordinary least squares (OLS) estimator is defined as:
	
ˆββ =
−
(X X)
X Y
1
′
′

(12.14)
where X is a t × n matrix for our regressor, and Y is a t × 1 matrix for our regressand. 
To integrate our decay factor into this analysis, we start by defining λ as the square 
root of our decay factor, δ. Next, we construct a diagonal weight matrix, W, whose 
diagonal elements are a geometric progression of λ:
	
W =
−
λ
λ
n 1
0
0
0
0
0
0
0
0
0
0
1

(12.15)
We can then form a new estimator for our regression parameters:
	
ββ =
−
(X W WX)
X W WY
1
′
′
′
′
	
(12.16)
This estimator is known as the weighted least squares estimator.
One way to view what we are doing is to redefine our regressors and regressands 
as follows:
	
=
=
X
WX
Y
WY
*
*

(12.17)
The new matrices take our original data, and multiply the data at time t − i by 
λi. The effect is to make data points from the distant past smaller, which decreases 

Decay Factors
245
their variance and decreases their impact on our parameter estimates. With these 
new matrices in hand, our weighted least squares estimator can now be written as:
	
ββ =
−
(X X )
X
Y
1
*
*
*
*
′
′

(12.18)
In this way, our weighted least squares estimator can be viewed as the OLS estimator 
of our transformed data.
One potential problem with the weighted least squares approach, as described 
here, involves heteroscedasticity. If the initial data set is homoscedastic, then clearly 
the transformed data will be heteroscedastic. As with our mean and variance estima-
tors, when we use a decay factor, the resulting estimator will be unbiased, but it will 
not be the BLUE.
Why did we choose to define W using the square root of δ, and not δ itself? By 
defining W this way, we are being consistent with the way we defined our variance 
estimator in the previous section.
Other Possibilities
So far we have explored two weighting schemes for estimating population param-
eters. The traditional approach applies an equal weight to all data points, while our 
decay factor approach applies weights that decline at a constant rate as we go back 
in time. In theory, there is an infinite number of possible weighting schemes we could 
use, but one novel approach pioneered by Philip Hua and Paul Wilmott is worth 
mentioning (Hua and Wilmott 1997).
As risk managers, if we are ultimately concerned with extreme markets, then the 
suggestion is that we should be placing more weight on data from extreme markets, 
and little or no weight on data from normal markets. This approach seems particu-
larly appropriate for stress testing, where, by definition, we are dealing with extreme 
events.
One way to implement this approach would be to define a cutoff return that 
separates extreme markets and normal markets, and use only the data from ex-
treme markets to calculate statistics (weights are zero or one). Alternatively, we 
could define weights as a function of how extreme the returns are (e.g., the weights 
are equal to the square of the return of a given index). When applied to stress 
testing or value at risk (VaR), Hua and Wilmott refer to this as the CrashMetrics 
approach. Looked at more generally, it provides a novel third way of calculating 
sample parameters.
Application: Hybrid VaR
One of the simplest approaches to estimating value at risk (VaR) is the historical 
method or historical simulation. In this approach, we calculate the backcast returns 
of a portfolio of assets, and take these as the portfolio’s return distribution. To cal-
culate the 95th percentile VaR, we would simply find the least worst of the worst 

246
Mathematics and Statistics for Financial Risk Management
5% of returns. For example, suppose we have 100 returns, ranked from lowest to 
highest:
Worst
1
−1.40%
2
−0.82%
3
−0.75%
4
−0.73%
5
−0.68%
6
−0.66%
 
7
−0.65%
 
.  .  .
.  .  .
 
97
0.93%
 
98
0.95%
 
99
1.17%
Best
100
1.52%
Here the 95th percentile VaR would correspond to the fifth return, −0.68%.
Instead of giving equal weight to all data, we can use a decay factor to weight 
more recent data more heavily. Rather than finding the fifth worst return, we would 
order the returns and find the point where we have 5% of the total weight. Using the 
same returns as in the preceding example:
 
Rank
Return
Weight
Percentage of 
Total Weight
Worst
1
−1.40%
0.83
1.9%
 
2
−0.82%
0.27
2.5%
 
3
−0.75%
0.42
3.5%
 
4
−0.73%
0.87
5.5%
 
5
−0.68%
0.52
6.7%
 
6
−0.66%
0.74
8.4%
 
7
−0.65%
0.31
9.1%
 
.  .  .
.  .  .
.  .  .
.  .  .
 
97
0.93%
0.16
96.4%
 
98
0.95%
0.63
97.9%
 
99
1.17%
0.25
98.5%
Best
100
1.52%
0.67
100.0%
In this case, we get to 5% of the total weight between the third and fourth 
returns. At this point there are two approaches. The more conservative approach 
is to take the third return, −0.75%. The alternative is to interpolate between 
the third and fourth returns, to come up with −0.74%. Unless there is a strong 

Decay Factors
247
justification for choosing the interpolation method, the conservative approach is 
recommended.
This general approach, using historical returns with decreasing weights, is often 
called the hybrid approach because it combines aspects of standard historical simu-
lation and weighted parametric approaches; see, for example, Allen, Boudoukh, and 
Saunders (2004).
Problems
	 1.	For an estimator based on n data points, with a decay factor of δ, prove that the 
half-life, h, is given by:
h
n
=
+
ln( .
.
)
ln( )
0 5
0 5δ
δ
	 2.	Using a decay factor of 0.95, calculate the mean, sample variance, and sample 
standard deviation of the following series. Assume t = 7 is the most recent data 
point, and use all eight points:
t
0
1
2
3
4
5
6
7
x 11 84 30 73 56 58 52 35
	 3.	Given the following set of data, calculate the mean using no decay factor 
(­rectangular window), a decay factor of 0.99, and a decay factor of 0.90. ­Assume 
time t = 10 is the most recent data point, and use all 11 points:
t
0
1
2
3
4
5
6
7
8
9
10
x
0.04
0.84
0.28
0.62
0.42
0.46
0.66
0.69
0.39
0.99
0.37
	 4.	Calculate the sample standard deviation for the data set in problem 3, also using 
no decay factor, a decay factor of 0.99, and a decay factor of 0.90.
	 5.	You are estimating the expected value of the annual return of a stock market 
index using an EWMA estimator with a decay factor of 0.98. The current es-
timate of the mean is 10%. Over the next three years, the index returns 15%, 
−4%, and finally 8%. Recalculate the estimate of the mean in each of these 
three years.
	 6.	What is the half-life for an estimator with a decay factor of 0.95 and 200 data 
points? What is the half-life for the same decay factor with 1,000 data points?
	 7.	What is the half-life of an EWMA estimator with a decay factor of 0.96 and 32 
data points? What is the length of a rectangular window with the most similar 
half-life?
	 8.	Assume we have an EWMA estimator with a decay factor of 0.96 and 50 data 
points. What percentage of the weight is captured with this estimator, compared 
to an estimator with the same decay factor and an infinite length?

248
Mathematics and Statistics for Financial Risk Management
	 9.	Assume that the mean of a data-generating process is known and equal to 10%. 
The initial estimate of the standard deviation is 20%, when you observe a return 
of 15%. What is your updated estimate of the mean? Assume the data series is 
of infinite length, and use a decay factor of 0.97.
	10.	Assume that the mean of a data generating process is known and equal to zero. 
Your initial estimate of the standard deviation is 10%. You observe the follow-
ing returns (t = 6 is the most recent period). Assume that the initial estimator was 
generated from an infinitely long series, and use a decay factor of 0.95. What is 
your updated estimate of the standard deviation?
t
1
2
3
4
5
6
r
−5%
18%
16%
−2%
5%
−10%

249
B
inary numbers are important in risk management for two reasons. First, most 
of the mathematics and statistics in this book will end up being implemented on 
computers. Implementation can often be as difficult as, if not more difficult than, 
the theoretical aspects of a problem. Even if you’re not doing the programming 
yourself, understanding programming can make the transition from theory to work-
ing systems easier. Understanding programming means understanding computers, 
and binary is the language that computers speak. The second reason that binary 
numbers are of interest is that—just by chance—they provide a very useful shortcut 
for doing some very common risk management calculations. Even if you’re building 
highly complex systems, you’ll often need to perform these back-of-the-envelope 
­calculations. 
Ordinarily, when we’re doing arithmetic, we’re using decimal numbers. If you 
see 157, this is usually shorthand for:
1 10
5 10
7 10
2
1
0
⋅
⋅
⋅
+
+
We say that decimal is base 10. Binary, by contrast, is base 2. In binary, 1,001 is 
shorthand for:
1 2
0 2
0 2
1 2
3
2
1
0
⋅
⋅
⋅
⋅
+
+
+
If you work this out, you’ll see that binary 1,001 is equivalent to decimal 9.
Computers work in binary. The standard unit for most computers is the byte, 
which consists of 8 bits. Coincidentally, 210 is 1,024, which is very close to 1,000. This 
is why kilobytes are 1,024 bytes, not 1,000 bytes. Megabytes are 220 = 1,048,576 
bytes, not 1 million bytes. Knowing that 210 is close to 1,000 is very useful.
Just as 210 turns out to be very close to 1,000, 28 equals 256, which is very close 
to the number of business days in a year. It is often the case that we need to con-
vert from daily standard deviations to annualized standard deviation, or vice versa. 
If returns are independent and identically distributed (i.i.d.), then translating daily 
standard deviations into annualized standard deviations requires multiplying by the 
square root of the number of business days in a year. If we use 256 business days 
per year as an approximation, then we would annualize daily standard deviations 
by multiplying by 16:
256
2
2
2
16 16
8
4
4
=
=
=
⋅
⋅
Appendix A 
Binary Numbers

250
Appendix A
So if the daily standard deviation of a stock is 1%, then the annualized standard 
deviation is close to 16%. If the annualized standard deviation is close to 48%, then 
the daily standard deviation is close to 3%. This is a very useful approximation to 
be familiar with.
If returns are normally distributed—not an assumption you should make 
­lightly—then the 95% value at risk (VaR) of a security will be approximately 1.6 
standard deviations. Combining this with our approximate annualization factor, it is 
very easy to see why the one-day VaR should be close to one-tenth of the annualized 
standard deviation. A stock with a quoted annualized standard deviation of 43% 
will often have a one-day 95% VaR close to 4.3%. You should always be careful 
when using this kind of approximation, but being able to perform this calculation 
quickly can be very useful.

251
Appendix B 
Taylor Expansions
A 
Taylor series expansion can be used to provide approximations to a function. 
Given a function f(x), assuming the necessary derivatives exist, we can define the 
Taylor series:
f x
f a
f a x
a
f
a x
a
f
( )
( )
( )(
)
!
( )(
)
!
(
=
+
−
+
−
+
′
′′
1
2
1
3
2
3)
( )
( )(
)
...
!
( )(
)
...
a x
a
n f
a x
a
n
n
−
+
+
−
+
3
1
where f ′, f ′′, and f (3) are, respectively, the first, second, and third derivatives of f(x) 
with respect to x.
We can talk about an nth-order Taylor series expansion, which would extend to 
the nth term,
n f
a x
a
1
!
( )(
)
n
n
( )
−
As an example, take the exponential function. The corresponding Taylor series 
expansion is:
e
e
e
x
a
e
x
a
e
x
a
x
a
a
a
a
≈
+
−
+
−
+
−
+
+
(
)
!
(
)
!
(
)
...
1
2
1
3
1
2
3
n e
x
a
a
n
!
(
)
−
An obvious choice for a is a = 0, which would give us ea = 1. In this case, we say 
that we are expanding ex around zero. The expansion then simplifies to:
e
x
x
x
n x
x
n
≈
+
+
+
+
+
1
1
2
1
3
1
2
3
!
!
...
!
Exhibit B.1 shows the first few approximations for ex, expanded around zero, 
for various values of x.
The last row is the exact value of the function, which would be equal to the 
infinite expansion. Notice that as we add more terms, the approximation gets closer 
and closer to the real value. Also notice that the closer x is to the expansion point, 
the better the approximation. Be careful: While many functions exhibit this type of 

252
APPENDIX B
convergence, this need not be the case. One important counterexample is the natural 
logarithm. The Taylor expansion for ln(x) around one is:
ln( )
(
)
(
)
(
)
...
(
)
(
x
x
x
x
n x
n
=
−
−
−
+
−
−
−−
1
1
2
1
1
3
1
1
1
2
3
−
+
1)
...
n
In this case, for values x such that 0 < x ≤ 2, the Taylor series expansion con-
verges as we increase the order of the approximation. As can be seen in Exhibit B.2, 
however, for values of x greater than 2, increasing the order of the approximation 
can actually make matters worse.
Exhibit B.1 
Taylor Approximations for ex
 
x
Order
−0.5
0.5
1
2
1
0.50
1.50
2.00
3.00
2
0.63
1.63
2.50
5.00
3
0.60
1.65
2.67
6.33
4
0.61
1.65
2.71
7.00
5
0.61
1.65
2.72
7.27
Exact
0.61
1.65
2.72
7.39
Exhibit B.2 
Taylor Approximations for ln(x)
 
x
Order
−0.5
1.5
2
3
1
−0.50
0.50
1.00
2.00
2
−0.63
0.38
0.50
0.00
3
−0.67
0.42
0.83
2.67
4
−0.68
0.40
0.58
−1.33
5
−0.68
0.39
0.38
−7.73
Exact
−0.69
0.41
0.69
1.10

253
Appendix C 
Vector Spaces
W
e can define a vector space more formally. Given three vectors, v, w, and x, and 
two scalars, s and t, we begin by defining two operations:
	 1.	Addition, v + w, which produces a sum.
	 2.	Scalar multiplication, sv, which produces a scalar multiple.
In the most general definition of a vector space, these operations need not con-
form to the standard definitions we have explored in real vector spaces, Rn. What we 
do require is that the following 10 axioms are satisfied:
	 1.	If v and w exist in V, then v + w exists in V as well.
	 2.	v + w = w + v.
	 3.	u + (v + w) = (u + v) + w.
	 4.	There is a zero vector in V, 0, such that 0 + v = v + 0 = v for all v.
	 5.	For every v, there is a negative of v, –v, such that v + (–v) = (–v) + v = 0.
	 6.	For any scalar, s, and any vector in V, v, sv is also in V.
	 7.	s(v + w) = sv + sw.
	 8.	(s + t)v = sv + tv.
	 9.	s(tv) = (st)v.
	10.	1v = v.


255
Appendix D 
Greek Alphabet
A
α
Alpha
N
 
Nu
B
β
Beta
Ξ
ξ
Xi
Γ
γ
Gamma
O
ο
Omicron
Δ
δ
Delta
Π
π
Pi
E
ε
Epsilon
P
ρ
Rho
Z
ζ
Zeta
Σ
σ
Sigma
H
η
Eta
Τ
τ
Tau
Θ
θ
Theta
Y
υ
Upsilon
I
ι
Iota

φ
Phi
K
κ
Kappa
X
χ
Chi
Λ
λ
Lambda
Ψ
ψ
Psi
M
µ
Mu
Ω
ω
Omega


257
Appendix E 
Common Abbreviations
D
oes your DGP produce a PDF that leads to an MSE of e? What follows is a list of 
some common abbreviations from statistics and risk management:
avg.:
average
BLUE:
best linear unbiased estimator
CDF:
cumulative density function or cumulative distribution 
­function
DGP:
data-generating process
ESS:
explained sum of squares
EWMA:
exponentially weighted moving average
i.i.d.:
independent and identically distributed
MSE:
mean squared error
OLS:
ordinary least squares
PDF: 
­probability density function or probability distribution 
function
RNG:
random number generator
RSS:
residual sum of squares
s.d. or std. dev.:
standard deviation
s.t.:
such that
TSS:
total sum of squares
Var or var:
variance
VaR:
value at risk


259
Appendix F 
Copulas
T
he following is a summary of the properties of various named copulas. Formulas 
are given in terms of two cumulative distribution functions (CDFs), but these 
definitions can be extended to any number of variables. The following notation is 
used for each copula:
■
■g: the generator function for the copula
■
■g–1: inverse of the generator function
■
■C: the copula in terms of two CDFs, u and v
■
■C1: the marginal CDF of the copula, ∂
∂
c
u
■
■c: the copula’s density function
■
■τ: Kendall’s tau
■
■ρ: Spearman’s rho
Clayton
g−1 = (1 + t)−1
α
g = t−α − 1
C = (u−α + v−α − 1)−1
α
C
C
u
u
u
v
1
1
1
1
= ∂
∂
=
+
−
−
+
−
−
−+
(
)(
)
α
α
α
α
α
u
v
u
C
+
=
−
−+
−
1
1
1
1
α
α
α
α
c
uv
u
v
=
+
+
−
−
+
−
−
−+
(
)(
)
(
)
(
)
1
1
1
1 2
α
α
α
α
α
α
α > 0
τ
α
α
=
+ 2

260
APPENDIX F
Farlie-Gumbel-Morgenstern (FGM)
C = uv[1 + α(1 − u)(1 − v)]
C1 = v(1 + α − 2αu) + v2α (2u − 1)
c = 1 + α (1 − 2u)(1 − 2v)
−1 ≤ α ≤ + 1
τ
α
= 2
9
ρ
α
= 1
3
Frank
g
e
e t
−
−
=
−
−
1
1
1
1
α
α
ln[
(
)
]
g
e
e
t
= −
−
−
ln 1
1
α
α
C
e
e
e
v
u
=
+
−
−
−
1
1
1
1
1
α
α
α
α
ln
)
(
)
(
C
C
u
e
e
e
e
e
u
v
v
u
v
1
1
1
1
1
1
= ∂
∂
=
−
−
+
−
−
−
(
)(
)
(
)
(
)(
α
α
α
α
α
)
(
)
+
−
eα
1
v =
+
1
1
α ln
C e
−1
1
α
)
(
C
e u −
+
−
1
1
1
1
α
)
(
)
(
c
e
e
e
e
e
u v
u
v
=
−
−
−
+
−
+
α
α
α
α
α
α
(
)[(
)(
)
(
)]
(
)
1
1
1
1 2
α ≠0
τ
α
α
+
=
+
−
∫
1
4 1
1
1
0
t
e
dt
t
−α
ρ
α
α
α
−
=
+
−
∫
1
12
1
1
1
2
2
0
t
dt
t
e
dt
t
−1
et
∫0
−α
−α
Gumbel
g
e t
−
−
=
1
1
α
g
t
= −
(
)
ln
α
C
e
u
v
=
−−
+ −
[(
)
(
) ]
ln
ln
α
α
α
1
C
C
u
u
u
C
u
v
1
1
1
1
= ∂
∂
=
−
−
+ −
−
−
(
)
[(
)
(
) ]
ln
ln
ln
α
α
α
α
α

Copulas
261
c
uv
u
v
C
u
v
−
=
+ −
−
−
1
1
1 2
(
)(
)
)
(
)
(
ln
ln
ln
ln
α
α
α
α
α
α
α
α
α −
+
−
+ −
1
1
((
)
(
)
)
ln
lnv
u
α ≥ 1
τ
α
α
=
−1
Independent
g−1 = e−t
g = −ln t
C = uv
C
C
u
v
1 = ∂
∂
=
v = C1
c = 1
τ = 0
ρ = 0
Joe
g
e t
−
−
=
−
−
1
1
1
1(
)α
g = −ln[1 − (1 − t)α]
C
u
v
u
v
D
=
−
−
+
−
−
−
−
=
−
1
1
1
1
1
1
1
1
[(
)
(
)
(
) (
) ]
α
α
α
α α
α
c
u
v
D
D
=
−
−
−
−
−
−
−
(
)
(
)
(
)
1
1
1
1
1
1 2
α
α
α
α
α
α ≥ 0
τ
α
α
=
−
+
−
+
=
∞
∑
1
4
1
2
1
2
1 i
i
i
i
(
)( (
)
)


263
Answers
Chapter 1
	 1.	a.	y = 5
	
	 b.	y = ln(1) – ln(e) = 0 – 1 = –1
	
	 c.	 y = ln(10) + ln(e) = ln(10) + 1 = 3.3026
	 2.	Annual rate = 5.12%; semiannual rate = 5.05%; continuous rate = 4.99%.
	 3.	 100
111 85
0 112
⋅
=
e .
.
	 4.	C(
, )
!
!(
)!
!
!
!
10 2
10
2
10
2 10
2
10 9 8
8
2
=
=
−
=
⋅⋅
⋅
=
=
=
⋅
10 9
2
45
	 5.	V
i
i
=
=
=
−
=
100
1 04
100
1
1 04
100
1
1 04
1
1
1 04
.
.
.
.
100
1
1 04
1
$2,500
1
1
.
−
=
=
∞
=
∞
∑
∑
i
i
	 6.	V
+
=
+
+
+
=
1 00
1 06
1 05
1 06
1 05
1 06
1
1 06 1
1
2
2
3
.
.
.
.
.
.
.
.05
1 06
1 05
1 06
1
1 06
1
1
1 05
1 0
2
2
.
.
.
.
.
.
+
+
=
−
V
6
1
1 06
1 06
0 01
$100
=
=
.
.
.
	 7.	 V =
+
+
+
=
+
⋅
6
1 08
6
1 08
6
1 08
106
1 08
6 6 71
46
2
9
10
.
.
.
.
.
.

32
86 58
= $
.
	 8.	ln(ln(10)) = 0.8340
	 9.	 S
i
i
=
−
=
+ −
+ −
+
+ −
+
=∑
0
9
2
8
0 5
1
0 5
0 5
0 5
(
. )
(
. )
(
. )
(
. )
(

−0 5 9
. )
−
= −
+ −
+
−
+ −
0 5
0 5
0 5
0 5
0 5
2
9
10
.
(
. )
(
. )
(
. )
(
. )
S

=
−
+ −
S
1
0 5 10
(
. )
S =
−−
=
−
=
=
1
0 5
1 5
1
1
1 024
1 5
1 023
1 536
0 67
10
(
. )
.
,
.
,
,
.
	10.	 10
4
10
4 6
210
=
=
!
! !

264
Answers
	11.	The bond will pay 10 coupons of $2, starting in a year’s time. In addition, the 
notional value of the bond will be returned with the final coupon payment in 
10 years. The present value, V, is then:
V
i
i
i
=
+
=
=
=
∑
∑
1
10
10
1
10
2
1 05
100
1 05
2
1
1
$
( .
)
$
( .
)
$
( .05
100
1 05 10
)
$
( .
)
i +
We start by evaluating the summation, using a discount factor of δ = 1/ 
1.05 ≈ 0.95:
S
i
i
i
i
i
i
=
=
=
=
=
=
∑
∑
1
1 05
1
1 05
1
10
1
10
1
10
( .
.
)
δ
∑
=
+
+
+
+
=
+
+
+
+
=
−
+
δ
δ
δ
δ
δ
δ
δ
δ
δ
δ
δ
9
2
10
2
3
10
11
11
S
S
S(
)
.
1
1
7 72
11
11
−
=
−
=
−
−
=
δ
δ
δ
δ
δ
δ
S
	
	 Inserting this result into the initial equation, we obtain our final result:
V =
×
+
=
$
.
$
( .
)
$
.
2
7 72
100
1 05
76 83
10
Note that the present value of the bond, $76.83, is less than the notional 
value of the bond, $100. This is what we would expect, given that there is no 
risk of default, and the coupon rate is less than the discount rate.
Chapter 2
	 1.	Probability that both generate positive returns = 60% × 70% = 42%.
	
	 Probability that both funds lose money = (1 – 60%) × (1 – 70%) = 40% × 30% = 
12%.
	 2.	88%. The sum of all three events—upgrade, downgrade, and no change—must 
sum to one. There is no other possible outcome. 88% + 8% + 4% = 100%.
	 3.	50%. The outcomes are mutually exclusive; therefore, 20% + 30% = 50%.
	 4.	 P
P
[
]
[
oil up
stock market down
stock market
∩
=
down oil up
oil up
|
]
[
]
⋅P
	
	 P[
]
%
%
%
oil up
stock market down
∩
=
=
⋅
60
30
18
	 5.	Given the density function, we can find c by noting that the sum of probabilities 
must be equal to one:
f x dx
c
x dx
c
x
x
( )
(
)
−∞
∞
−
∫
=
−
−
=
100
100
1
3
3
2
10
10
10
10
3
4 000
−∫
=
c
,

Answers
265
	 6.	First we check that this is a valid CDF, by calculating the value of the CDF for 
the minimum and maximum values of x:
F
F
( )
(
)
(
)
(
)
0
0
100 20
0
0
10
10
100 20
10
1
=
−
=
=
−
=
Next we calculate the PDF by taking the first derivative of the CDF:
f x
d
dx F x
x
x
( )
( )
(
)
=
=
−
=
−
20
100
2
100
1
50 10
	 7.	We first calculate the CDF by integrating the PDF:
F x
f t dt
c
t dt
c
t
c
x
x
x
x
( )
( )
[ln ]
ln
=
=
=
=
∫
∫
1
1
1
We first try to find c using the fact that the CDF is zero at the minimum value 
of x, x = 0.
F
c
c
( )
ln( )
0
1
0
0
=
=
=
⋅
As it turns out, any value of c will satisfy this constraint, and we cannot use this 
to determine c.
If we use the fact that the CDF is 1 for the maximum value of x, x = e, we 
find that c = 1:
F e
c
e
c
c
c
( )
ln( )
 
=
=
=
∴=
⋅1
1
The CDF can then be expressed simply as:
F x
x
( )
ln( )
=
	 8.	P[both bonds default]  = 30% × 30% = 9%.
P[one defaults]  = 2 × 30% × (1 − 30%) = 42%.
P[neither defaults] = (1 − 30%) × (1 − 30%) = 49%.
For the second part of the question, remember that there are two scenarios 
in which only one bond defaults: Either the first defaults and the second does 
not, or the second defaults and the first does not.
	 9.	The probability that a B-rated bond defaults over one year is 2%. This can be 
read directly from the last column of the second row of the ratings transition 
matrix.
The probability of default over two years is 4.8%. During the first year, a 
B-rated bond can either be upgraded to an A rating, stay at B, be downgraded 
to C, or default. From the transition matrix, we know that the probability of 

266
Answers
these events is 10%, 80%, 8%, and 2%, respectively. If the bond is upgraded to 
A, then there is zero probability of default in the second year (the last column 
of the first row of the matrix is 0%). If it remains at B, there is a 2% probability 
of default in the second year, the same as in the first year. If it is downgraded 
to C, there is a 15% probability of default in the second year. Finally, if a bond 
defaulted in the first year, it stays defaulted (the last column of the last row is 
100%). Putting all this together, we have:
P[
]
%
%
%
%
%
%
%
%
.
default =
×
+
×
+
×
+
×
=
10
0
80
2
8
15
2
100
4 8%
	10.	Using M to represent the market and X to represent the portfolio manager, we 
are given the following information:
P[Mup] = 50%
P[Mdn] = 20%
P[Mflat] = 30%
P[Xup | Mup] = 80%
P[Xup | Mdn] = 10%
P[Xup | Mflat] = 50%
The unconditional probability that the manager is up next year, P[Xup], is 
then 57%:
P[Xup] = P[Xup | Mup] ∙ P[Mup] + P[Xup | Mdn] ∙ P[Mdn] + P[Xup | Mflat] ∙ P[Mflat]
P[Xup] = 80% ∙ 50% + 10% ∙ 20% + 50% ∙ 30%
P[Xup] = 40% + 2% + 15% = 57%
Chapter 3
	 1.	Mean = 6.43%; median = 5%.
	 2.	Mean = 3%; standard deviation = 6.84%.
	 3.	 ˆµ =
=
+
+
+
+
(
)
=
−
∑
1
1
1
1
2
1
n
r
n r
r
r
r
i
i
n
n
n

E
n
E r
n
n n
i
i
n
i
n
[ ˆ ]
[ ]
µ
µ
µ
µ
=
=
=
=
=
=
∑
∑
⋅⋅
1
1
1
1
1
	 4.	Using the results of question 3, we first calculate the variance of the estimator of 
the mean:
E
E
n
r
E
n
i
i
n
[( ˆ
) ]
(
μ
μ
μ
=
−
−
=
=∑
2
1
2
1
1
ri
i
n
−
=∑
μ)
1
2

Answers
267
E
n
r
E
r
r
i
i
n
j
i
i j
[( ˆ
) ]
(
)
(
)
)
(
μ
μ
μ
μ
μ
=
−
+
−
−
−
≠
=∑
2
2
2
1
1
∑
∑
∑
=
=
=
−
−
i
n
i
i
n
E
n
r
E
1
2
2
2
1
1
[( ˆ
) ]
)
(
μ
μ
μ
−
+
−
≠
= ∑
∑
1
2
1
n
r
E
r
E
j
i
i j
i
n
)
(
)
(
[(
μ
μ
ˆ
) ]
[(
) ]
[(
)(
μ
μ
μ
μ
=
−
+
−
−
−
=∑
2
2
2
1
2
1
1
n
E r
n
E r
r
i
i
n
j
i
μ
μ
μ
σ
)]
[( ˆ
]
)
i j
i
n
i
n
i j
E
n
n
≠
=
≠
=
∑
∑
∑
∑
=
−
+
1
2
2
2
2
1
1
1
0
i
n
E
n n
n
=∑
−
=
=
1
2
2
2
2
1
[( ˆ
) ]
μ
μ
σ
σ
where σ is the standard deviation of r. In the second to last line, we rely on the 
fact that, because the data points are i.i.d., the covariance between different data 
points is zero. We obtain the final answer by taking the square root of the vari-
ance of the estimator:
σ
σ
σ
µˆ =
=
2
n
n
	 5.	Covariance = 0.0487; correlation = 82.40%.
	 6.	Series #1: Mean = 0, standard deviation = 39, skewness = 0.
	
	 Series #2: Mean = 0, standard deviation = 39, skewness = –0.63.
	 7.	Series #1: Mean = 0, standard deviation = 17, kurtosis = 1.69.
	
	 Series #2: Mean = 0, standard deviation = 17, kurtosis = 1.
	 8.	The mean, µ, is 
μ
=
=
=
−
=
⋅
⋅
⋅
∫x x dx
x
18
3 18
6
3 18
0
3 18
6
3
0
6
0
6
3
3
2
3
4
2 =
The variance, σ 2, is then:
σ
σ
2
2
0
6
3
2
0
6
2
4
18
1
18
8
16
1
1
=
−
=
−
+
=
∫
∫
(
)
)
(
x
x dx
x
x
x dx
8
1
4
8
3
8
6
18
1
4 6
8
3
8
6
4
3
2
0
6
2
2
x
x
x
−
+
−
=
+
=
−
+
=
σ 2
2 9
16
8
2
(
)
	 9.	We start by expanding the mean:
ˆ
(
ˆ )
μ
σ
i
x
x
i
n
j
i
j i
n
x
n
n
n
x
n
x
2
2
1
1
1
1
1
1
1
=
−
=
−
−
−
−
≠
=
∑
∑
=∑
i
n
1
2

268
Answers
By carefully rearranging terms, we are left with:
ˆ
(
)
σ x
i
i
j
j i
i
n
i
n
n
x
n n
x x
2
2
1
1
1
1
1
=
−
−
≠
=
=
∑
∑
∑
Assuming that all the different values of X are uncorrelated with each other, we 
can use the following two relationships:
E xi
[
]
2
2
2
=
+
σ
µ
E x x
iff
i
j
i
j
i
j
ij
[
]
 
 
=
=
∀
≠
µ µ
σ
0
Then:
E
n n
n n
n n
x
[ ˆ ]
(
)
(
) (
)
σ
σ
µ
µ
σ
2
2
2
2
2
1
1
1
1
=
+
−
−
−
=
	10.	First we note that the expected value of XA plus XB is just the sum of the means:
E X
X
E X
E X
A
B
A
B
A
B
[
]
[
]
[
]
+
=
+
=
+
µ
µ
Substituting into our equation for variance, and rearranging, we get:
Var[
]
[(
[
]) ]
[((
)
X
X
E X
X
E X
X
E
X
A
B
A
B
A
B
A
A
+
=
+
−
+
=
−
+
2
µ
(
)) ]
XB
B
−µ
2
Expanding the squared term and solving:
Var[
]
[(
)
(
)
(
)(
X
X
E X
X
X
X
A
B
A
A
B
B
A
A
B
+
=
−
+
−
+
−
−
µ
µ
µ
2
2
2
µB)]
Var[
]
[(
) ]
[(
) ]
[(
X
X
E X
E X
E X
A
B
A
A
B
B
A
+
=
−
+
−
+
−
µ
µ
µ
2
2
2
A
B
B
X
)(
)]
−µ
Var
Cov
[
]
[
]
,
X
X
X X
A
B
A
B
A
B
+
=
+
+
σ
σ
2
2
2
Using our definition of covariance, we arrive at our final answer:
Var[
]
X
X
A
B
A
B
AB
A
B
+
=
+
+
σ
σ
ρ
σ σ
2
2
2
	11.	If the bond does not default, you will receive $100. If the bond does default, you 
will receive 40% × $100 = $40. The future value, the expected value of the bond 
at the end of the year, is then $94:
E V
[
]
.
$
.
$
$
=
+
=
⋅
⋅
0 90
100
0 10
40
94
	
	 The present value of the bond is approximately $89.42:
PV
e
=
=
−0 05 94
89 42
.
$
$
.

Answers
269
Chapter 4
	 1.	The number of times XYZ Corporation exceeds consensus estimates follows a 
binomial distribution; therefore:
P X
]
[
.
.
.
.
.
=
=
=
=
⋅
⋅
3
4
3 0 30 0 70
4 0 30
0 70
7 56
3
1
3
%
	 2.	The number of exceedance events follows a binomial distribution; therefore:
P X
]
[
.
.
%
.
=
=
=
2
20
2 0 05 0 95
18 87
2
18
	 3.	Because the annual returns of both funds are normally distributed and inde-
pendent, the difference in their returns is also normally distributed:
R
N
B A
B
A
A
B
−
−
+
∼
(
,
)
µ
µ
σ
σ
2
2
The mean of this distribution is 10%, and the standard deviation is 50%. At the 
end of the year, the difference in the expected returns is 92%. This is 82% above 
the mean, or 1.64 standard deviations. Using Excel or consulting the table of 
confidence levels in the chapter, we see that this is a rare event. The probability 
of more than a 1.64 standard deviation event is only 5%.
	 4.	The average number of defaults over five months is 10; therefore:
P x
e
P x
e
[
]
!
.
%
[
]
!
=
=
=
=
=
=
−
−
5
10
5
3 78
10
10
10
1
5
10
10
10
2 51
15
10
15
3 47
15
10
.
%
[
]
!
.
%
P x
e
=
=
=
−
	 5.	If the returns of the fund are normally distributed with a mean of 10% and a 
standard deviation of 15%, then the returns of $200 million invested in the fund 
are also normally distributed, but with an expected return of $20 million and 
a standard deviation of $30 million. A loss of $18.4 million represents a –1.28 
standard deviation move:
z = −
−
= −
$
.
$
$
.
18 4
20
30
1 28
This is a one-tailed problem. By consulting the table of confidence intervals or 
using a spreadsheet, we determine that just 10% of the normal distribution lies 
below –1.28 standard deviations.
	 6.	The return of –30% is approximately a –1.64 standard deviation event:
z = −
−
= −
30
20 60
30 85
1 64
%
.
%
.
%
.

270
Answers
According to the table of confidence intervals, 5% of the normal distribution lies 
below –1.64 standard deviations. The probability of a return less than –30% is 
then 5%.
	 7.	For the mean:
μ =
=
=
=
∫
∫cxdx
c
xdx
x
c
c
x
x
x
x
x
x
x
1
2
1
2
2
1
2
1
2
1
2
( 2
2
1
2
−x )
From a previous example, we know that c = 1/(x2 – x1); therefore:
µ =
−
−
=
−
+
−
1
2
1
2
2
2
1
2
2
1
2
1
2
1
2
1
(
)
(
)
(
)(
)
(
x
x
x
x
x
x
x
x
x
x )
(
)
=
+
1
2
2
1
x
x
For the variance:
μ
σ
μ
μ
μ
2
2
2
2
2
3
1
2
2
1
3
−
=
−
=
=
+
+
−
∫c x
dx
x
c
d
x
c
x
x
x
x
x
)
(
)
(
μ2
1
2
1
2
x
x
x
x
x
∫
Substituting in for c and µ from above:
σ 2
2
1
2
3
1
3
2
1
2
2
1
2
1
1
3
1
2
1
4
=
−
−
−
+
−
+
x
x
x
x
x
x
x
x
(
)
(
)(
)
(x
x
x
x
x2
1
2
1
2 −
+
) (
)
For the final step, we need to know that:
x
x
x
x
x
x
x x
2
3
1
3
2
1
2
2
1
2
1 2
−
=
−
+
+
(
)(
)
Substituting in and solving, we have:
σ 2
2
1
2
1
12
=
−
(
)
x
x
	 8.	Using integration by substitution, define a new variable y and solve:
y
x
dx
dy
=
−
=
µ
σ
σ
2
2
1
2
1
1
1
2
2
2
2
σ
π
π
π
π
µ
σ
e
dx
e
dy
x
y
−
−
−∞
∞
−
−∞
∞
∫
∫
=
=
=
(
)
	 9.	Using the same substitution as in the previous question:
y
x
dx
dy
x
e
dx
y
x
=
−
=
=
−
−
−∞
∞
∫
µ
σ
σ
σ
π
π
σ
µ
σ
2
2
1
2
1
2
2
2
2
(
)
(
+
−
−∞
∞
∫
µ)e
dy
y2

Answers
271
x
e
dx
ye
dy
e
x
y
y
1
2
2
2
2
2
2
σ
π
σ
π
µ
π
µ
σ
−
−
−∞
∞
−
−∞
∞
−
∫
∫
=
+
(
)
2
2
2
2
1
2
2
2
2
dy
x
e
dx
ye
x
y
−∞
∞
−
−
−∞
∞
−
∫
∫
=
−
σ
π
σ
π
µ
σ
(
)
[
]−∞
∞
−
−
−∞
∞
+
=
∫
µ
σ
π
µ
µ
σ
x
e
dx
x
1
2
2
2
2
(
)
	10.	Using the same substitution as before:
y
x
=
−µ
σ
2
dx
dy
= σ
2
Var[ ]
(
)
(
)
x
x
e
dx
y e
x
=
−
=
−∞
∞
−
−
−
∫
µ
σ
π
σ
π
µ
σ
2
2
2
2
1
2
2
2
2
y dy
2
−∞
∞
∫
For the final step, we need to know that:
x e
dx
x
2
2
1
2
−
−∞
∞
∫
=
π
Using this result, we achieve the desired result:
Var[ ]
x =
=
2
1
2
2
2
σ
π
π
σ
	11.	First we note that the mean of XA is zero:
E X
E
X
X
E X
E X
A
[
]
[
]
[
]
[
]
=
+
−
=
+
−
=
+
−
⋅
⋅
ρ
ρ
ρ
ρ
ρ
ρ
1
2
1
2
1
1
0
1
0
0
=
Similarly, the mean of XB is zero.
Next, we want to calculate the variance. In order to do that, it will be useful 
to know two relationships. First we rearrange the equation for variance, Equa-
tion 3.20, to get:
E X
X
E X
i
i
i
i
[
]
[
]
[
]
 
, ,
2
2
2
1
0
1
1 2 3
=
+
=
+
=
=
Var
for 
Similarly, we can rearrange our equation for covariance, Equation 3.26, to  
get:
E X X
X X
E X E X
i
j
i
j
i
j
i
j
[
]
[
,
]
[
] [
]
 
 
=
+
=
+
=
∀
≠
⋅
Cov
0
0 0
0

272
Answers
With these results in hand, we now show that the variance of XA is one:
Var
Var
[
]
[
]
[
]
[
]
[
]
[
X
E X
E X
E X
X
E
X
A
A
A
A
A
=
−
=
=
+
2
2
2
1
2
ρ
2
1
1
2
1
1
2
2
2
1
2
ρ
ρ
ρ
ρ
ρ
(
)
(
)
]
[
]
[
]
(
−
+
−
=
+
−
X X
X
X
E X
A
Var
ρ
ρ
ρ
ρ
ρ
) [
]
(
) [
]
[
]
(
)
E X X
E X
XA
1
2
2
2
1
1
2
1
0
+
−
=
+
−
⋅
⋅
Var
+
−
=
⋅
(
)
1
1
1
ρ
The variance of XB is similarly 1. Next we calculate the covariance of XA and XB:
Cov
Cov
[
,
]
[
]
[
] [
]
[
]
[
X
X
E X X
E X
E X
E X X
X
A
B
A
B
A
B
A
B
A
=
−
=
,
]
[
(
)
(
)
]
[
X
E
X
X X
X X
X X
B =
+
−
+
+
−
ρ
ρ
ρ
ρ
1
2
1
2
1
3
2
3
1
1
Cov X
X
E X
E X X
E X X
A
B
,
]
[
]
( [
]
[
])
(
)
=
+
−
+
+
−
ρ
ρ
ρ
ρ
1
2
1
2
1
3
1
1
E X X
X
X
A
B
[
]
[
,
]
(
)
(
)
2
3
1
1
0
0
1
0
Cov
=
+
−
+
+
−
=
⋅
⋅
ρ
ρ
ρ
ρ
ρ
Putting the last two results together completes the proof:
Corr
Cov
Var
Var
[
,
]
[
,
]
[
]
[
]
X
X
X
X
X
X
A
B
A
B
A
B
=
=
=
⋅
⋅
ρ
1 1
ρ
	12.	For the portfolio consisting of 50% A and 50% B, we can proceed two ways. 
The PDF of the portfolio is a triangle, from –0.5 to +0.5, with height of 2.0 at 0. 
We can argue that the mean is zero based on geometric arguments. Also, because 
both distributions are just standard uniform variables shifted by a constant, they 
must have variance of 1/12; 50% of each asset would have a variance of 1/4 this 
amount, and—only because the variables are independent—we can add the vari-
ance of the variables, giving us:
σ 2
2 1
4
1
12
1
24
=
=
σ
=
=
1
24
1
2
1
6
Alternatively, we could calculate the mean and variance by integration:
+
=
−
+
+
=
−
+∫
∫
x
x
dx
x
x
dx
x
x
)
(
)
(
.
.
4
2
4
2
4
3
0 5
0
0
0 5
3
2
−
+
=
+
=
−
+
0 5
0
3
2
0
0 5
2
2
4
3
0
4
2
.
.
)
(
x
x
x
x
σ
dx
x
x
dx
x
x
−
+
−
∫
∫
−
+
+
=
0 5
0
2
0
0 5
3
2
4
4
2
2
3
.
.
)
(
σ
0 5
0
4
3
0
0 5
2
3
1
24
.
.
−
+
=
+
x
x
μ
μ
This confirms our earlier answer.

Answers
273
For the 50/50 mixture distribution, the PDF is bimodal and symmetrical 
around zero, giving a mean of zero:
μ =
+
=
−
−
+
+
−
−
∫
∫
0 5
0 5
0 5
1
2
2
1
1
2
2
2
1
.
.
.
xdx
xdx
x
+
=
−
+
−)
(
=
1
2
0 51
2 1
4
4
1
0
2
1
2
x
μ
.
For the variance we have:
σ
2
2
2
1
2
1
2
3
2
0 5
0 5
1
3
+
=
=
−
−
+
+
−
∫
∫
.
.
x d
x
x
dx
x
−
+
+
+
−
=
+
+
−
=
1
3
1
2
2
1
3
1
6
1
8
8
1
7
3
x
σ
σ
)
(
=
7
3
Notice that, while the mean is the same, the variance for the mixture distri-
bution is significantly higher.
Chapter 5
	 1.	The shape of the PDF resembles a truncated parabola.
–2.00
0.00
2.00
0.0
2.0
4.0
6.0
8.0
–2.00
0.00
2.00
6.0–8.0
4.0–6.0
2.0–4.0
0.0–2.0
Exhibit 5.A1 
Joint Probability Density Function

274
Answers
To see if X and Y are independent, we start by calculating the marginal distribu-
tion of X:
f
x
f x t dt
c
x
t
dt
c
t
tx
t
x( )
( , )
(
)
=
=
−
−
=
−
−
8
8
1
3
2
2
2
3
−
=
−
+
−
+∫
∫
2
2
2
2
2
4
20
3
x
c
y
The marginal distribution of Y is:
f
y
f t y dt
c
t
y dt
c
t
ty
t
y( )
( , )
(
)
=
=
−
−
=
−
−
8
8
1
3
2
2
2
3
−
=
−
+
−
+∫
∫
2
2
2
2
2
4
20
3
y
c
x
Putting the two together, we can see that the product of the marginal distribu-
tions does not equal the joint distribution.
f
x f
y
c
x
y
x
y
( )
( ) =
−
−
=
16
20
3
20
3
1
16
2
2
2
3
2
2
2
2
400
60
60
9
)
(
( , )
−
−
≠
+
x
y
x y
f x y
We conclude that X and Y are not independent.
	 2.	Kendall’s tau is −33% and Spearman’s rho is −50%. 
To calculate Kendall’s tau, we start by examining the concordance of all 
possible pairs of points. With three points there are three distinct pairs:
Pair
Concordant = +1,  
Discordant = −1
A, B
−1
A, C
−1
B, C
+1
One pair is concordant and two are discordant; therefore, Kendall’s tau is  
−33%:
τ =
−
#
#
of concordant points
of discordant points
n
2
1
2
3
33
=
−
= −
%
To calculate Spearman’s rho, we start by calculating the rank of each data  
point:
X
Y
Rank[X]
Rank[Y]
A
70%
5%
1
3
B
40%
35%
2
1
C
20%
10%
3
2

Answers
275
The general formula for correlation is:
Corr[
,
]
(
)
)
(
X Y
x
x
y
y
x
x
y
y
i
i
i
n
i
i
n
i
=
−
−
−
(
)
−
=
=
∑
∑
1
2
1
(
)
=
∑
2
1
i
n
where x and y are the mean of X and Y respectively. To calculate Spearman’s 
rho, we use not X and Y values, but their ranks. The mean of both Rank[X] and 
Rank[Y] is 2; therefore:
ρs =
−
−
+
−
−
+
−
−
−
+
(
)(
)
(
)(
)
(
)(
)
(
)
(
1
2 3
2
2
2 1
2
3
2 2
2
1
2 2
2
2
3
2
3
2
1
2
2
2
1
0
2
2
2
2
2
−
+
−
−
+
−
+
−
=
−
+
+
)
(
)
(
)
(
)
(
)
(
)
ρs
0
1
0
1 1
1
0
1
2 2
1
2
50
+
+
+
+
=
−
= −= −
%
In this example, Spearman’s rho and Kendall’s tau share the same sign, but they 
are not equal.
	 3.	We start by calculating the copula’s density function, c(u,v):
c u v
C u v
u v
u v uv
u u
( , )
( , )
= ∂
∂∂
=
∂
∂∂
= ∂
∂
=
2
2
1
We next calculate the expected value of the copula:
C u v c u v dudv
uvdudv
C
v c
( , ) ( , )
( , ) (
=
∫
∫
∫
∫
0
1
0
1
0
1
0
1
u
u v dudv
u v
dv
C u v c u
, )
(
) (
=
∫
∫
∫
0
1
0
1
2
0
1
0
1 1
2
,
, )
v dudv
vd
v
v
=
=
=
∫
∫
∫
0
1
0
1
2
0
1
0
1
1
2
1
2
1
2
1
4
Substituting into our equation for Kendall’s tau:
τ =
−
=
−
=
∫
∫
4
1
4 1
4
1
0
0
1
0
1
C u v c u v dudv
( , ) ( , )
Not surprisingly for something called the independent copula, Kendall’s tau is 
zero.
	 4.	To calculate Spearman’s rho, we first integrate the copula, C(u,v), function with 
respect to u:
C u v du
uv
u
v du
C u v du
( , )
[
(
)(
)]
( , )
=
+
−
−
=
∫
∫
1
1
1
0
1
0
1
α
[
(
)
)
(
]
v
u
v
v
u
v
v du
+
−
(
)
−
−
∫
∫
α
α
1
1
2
0
1
0
1

276
Answers
C u v du
u
v
v
v
u
v
v
( , )
(
(
)
)
=
+
−
(
)
−
−
1
2
1
1
3
1
3
2
0
α
α
1
0
1
1
2
1
1
3
1
∫
=
+
−
(
) −
−
C u v du
v
v
v
v
v
( , )
(
)
(
)
α
α
−
−
−
=
+
−
∫
∫
]
[
( , )
0
0
1
2
1
6
1
6
0
1
2
0
1C u v du
v
v
α
α
Next we integrate this result with respect to v:
C u v dudv
v
v
( , )
0
1
2
0
1
0
1
2
1
6
1
6
∫
∫
=
+
−
α
α
1
0
1
3
2
1
2
1
2
1
6
1
18
∫
∫
=
+
−
dv
C u v dudv
v
v
( , )
α
α
=
+
−
∫
∫
0
1
0
1
0
1
1
2
1
2
1
6
1
18
C u v dudv
( , )
α
α
α
−
−
=
+
∫
∫
∫
0
1
0
1
0
1
0
0
1
4
1
36
]
[
( , )
C u v dudv
Finally, we use this result to calculate Spearman’s rho:
ρ
α
ρ
−
=
+
=
−
=
∫
∫
12
3
12 1
4
1
36
3
1
0
1
0
1
C u v dudv
( , )
3α
Chapter 6
	 1.		
P[
]
GDP down|unemployment up =
P
P
P
[
|
]
[
]
[
unemployment up GDP down
GDP down
un
⋅
employment up]
P[
]
%
%
%
%
GDP down|unemployment up =
=
⋅
40
20
10
80
	 2.	32.14%. By applying Bayes’ theorem, we can calculate the result:
P
P
P
[
|
]
[
|
]
[
actual
D model
D
model
D actual
D
a
=
=
=
=
=
⋅
ctual
D
model
D
actual
D model
D
=
=
=
=
=
⋅
]
[
]
[
|
]
%
P
P
90
5
90
5
10
95
32 14
%
%
%
%
%
.
%
⋅
⋅
+
=

Answers
277
Even though the model is 90% accurate, 95% of the bonds don’t default, and 
of those 95% the model predicts that 10% of them will default. Within the 
bond portfolio, the model identifies 9.5% of the bonds as likely to default, even 
though they won’t. Of the 5% of bonds that actually default, the model correctly 
identifies 90%, or 4.5% of the portfolio. This 4.5% correctly identified is over-
whelmed by the 9.5% incorrectly identified.
Actual
D
No D
Model
D
4.5
9.5
14.0
No D
0.5
85.5
86.0
5.0
95.0
100.0
	 3.	We can start by summing across the first row to get W:
W
W
+
=
=
5
15
10
%
%
%
In a similar fashion, we can find X by summing across the second row:
45
65
20
%
%
%
+
=
=
X
X
To calculate Y, we can sum down the first column, using our previously calcu-
lated value for W:
W
Y
Y
Y
+
+
=
+
+
=
=
45
10
45
60
5
%
%
%
%
%
Using this result, we can sum across the third row to get Z:
Y
Z
Z
+
=
+
=
=
15
5
15
20
%
%
%
%
The completed probability matrix is:
Equity
Outperform
Underperform
Bonds
Upgrade
10%
5%
15%
No Change
45%
20%
65%
Downgrade
5%
15%
20%
60%
40%
100%
The last part of the question asks us to find the conditional probability, which 
we can express as:
P[
|
]
Downgrade Underperform

278
Answers
We can solve this by taking values from the completed probability matrix. The 
equity underperforms in 40% of scenarios. The equity underperforms and the 
bonds are downgraded in 15% of scenarios. Dividing, we get our final answer, 
37.5%.
P
P
[
[
Downgrade | Underperform]
Downgrade
Und
=
∩
erperform]
Underperform]
Downgrade | Und
P
P
[
[
erperform] =
=
15
40
37 5
%
%
. %
	 4.	The prior probabilities are:
P p
P p
[
.
]
%
[
.
]
%
=
=
=
=
0 55
50
0 50
50
The probability of the strategy generating 10 positive returns over 20 days 
if the analyst is correct is:
P
p
[
 
.
]
.
.
10
0 55
20
10 0 55 0 45
10
10
+
=
=
|
The unconditional probability of 10 positive returns is:
P
P
p
P p
P
p
[
]
[
.
] [
.
]
[
 
.
10
10
0 55
0 55
10
0
+ =
+
=
=
+
+
=
|
|
50
0 50
10
20
10 0 55 0 45
10
10
] [
]
.
[
]
.
.
P p
P
=
+ =
⋅0 50
20
10 0 50 0 50
0 50
10
0 5
10
10
.
.
.
.
[
]
.
+
+ =
⋅
P
0 20
10
0 55 0 45
0 50 0 50
10
10
10
10
+
( .
.
.
.
)
To get our final answer, the probability that p = 0.55 given the 10 positive re-
turns, we use Bayes’ theorem:
P p
P
p
P p
P
[
.
.
] [
.
]
[
=
+
=
=
0 55 10
0 55
0 55
1
|
|
] =
[10 +
0
0 55 10
0 55 0 45
10
10
+
+
=
⋅
]
[
.
 
.
.
P p
|
] =
20
10
0 50
0 50 20
10
0 55 0 45
0 50 0 50
10
10
10
.
(
.
.
.
.
.
+
10
10
10
0 55 10
0 45
0 55 0 45
)
[
.
 
.
( .
.
P p =
+
|
] =
0.5510
10
10
10
0 50 0 50
0 55 10
+
=
+
.
.
)
[
.
 
P p
|
] =
1
1+ 100
99
=
10
47 49
.
%

Answers
279
The final answer is 47.49%. The strategy generated a profit in only 10 out of 
20 days, so our belief in the analyst’s claim has decreased. That said, with only 
20 data points, it is hard to tell the difference between a strategy that generates 
profits 55% of the time and a strategy that generates profits 50% of the time. 
Our belief decreased, but not by much.
	 5.	The final answer is 92.31%. Use + to signify the procyclical index being up, G 
to signify that the economy is up (growing), and G to signify that the economy 
is down or flat (not growing). We are given the following information:
P
G
P
G
P G
[  
]
%
[  
]
%
[
]
%
+
=
+
=
=
|
|
75
25
20
We are asked to find P[G | +]. Using Bayes’ theorem, we have:
P G
P
G P G
P
[
]
[
] [
]
[ ]
|
|
+ =
+
+
We were not given P[G], but we know the economy must be either growing or 
not growing; therefore:
P G
P G
[
]
[
]
%
=
−
=
1
80
We can also calculate the unconditional probability that the index is up,  
P[+]:
P
P
G P G
P
G P G
P
[ ]
[
] [
]
[
] [
]
[ ]
%
%
+ =
+
+
+
+ =
+
⋅
|
|
75
80
25
20
60
5
65
%
%
[ ]
%
%
%
⋅
+ =
+
=
P
Putting it all together, we arrive at our final answer:
P G
P
G P G
P
P G
[
]
[
] [
]
[ ]
%
%
%
[
|
|
|
+ =
+
+
=
+
⋅
75
80
65
]
%
%
.
%
=
=
60
65
92 31
	 6.	The prior beliefs for beating the market in any given year are:
P p
P p
P p
P p
[
.
]
[
.
]
[
.
]
[
.
=
=
=
=
=
=
=
0 40
1
4
0 50
1
4
0 60
1
4
0 80
1
4
] =

280
Answers
The probability of beating the market three out of five years is:
P
B p
p
p
pi
i
i
[
]
3
5
3
1
3
2
|
=
=
−
)
(
Given a constant, c, the posterior probability can be defined as:
P p
p
B
c P
B p
p
P
p
p
P p
p
i
i
i
i
[
]
]
[
]
[
[
=
=
=
=
=
⋅
⋅
|
|
|
3
3
3
5
3
1
1
4
3
2
B
c
p
p
i
i
] =
−
(
) ⋅
⋅
We know that all of the posterior probabilities must add to one:
P p
p
B
c
p
p
i
i
i
i
]
[
(
)
=
=
=
−
=∑
⋅
⋅
| 3
1
5
3
1
4
1
1
4
2
3
1
4
5
3
1
1
4
3
1
4
2
i
i
i
i
c
p
p
=
=
∑
∑
=
−
)
(
The posterior probabilities are then:
P p
p
B
p
p
i
i
i
i
[
]
(
)
=
=
−
=
∑
⋅
| 3
4
5
3
1
5
3
3
2
1
4
−
=
=
−
⋅
p
p
P p
B
p
p
p
p
i
i
i
i
i
i
2
3
3
2
3
1
1
4
3
1
)
(
]
[
(
)
|
(
)
1
2
1
4
−
=
∑
pi
i
To get the final answer, we simply substitute in the four possible values for 
pi. For example, the posterior probability that the manager is an underper-
former is:
P p
B
p
p
i
i
i
[
.
]
.
(
.
)
(
)
=
=
−
−
=
0 40 3
0 40 1
0 40
1
3
2
3
2
1
4
|
∑
=
=
+
P p
B
[
.
]
.
.
.
.
.
0 40 3
0 40 0 60
0 40 0 60
0 50
3
2
3
2
3
|
0 50
0 60 0 40
0 80 0 20
0 40 3
2
3
3
2
2
.
.
.
.
.
[
.
]
+
+
=
=
P p
B
|
4 6
4 6
5 5
6 4
8 2
0 40 3
2 30
3 2
3 2
3 2
3
2
3 2
+
+
+
=
=
P p
B
[
.
]
,
|
4
10 933
21 1
,
. %
=

Answers
281
The other three probabilities can be found in a similar fashion. The final 
answer is that the posterior probabilities of the manager being an underper-
former, an in-line performer, a star, or a superstar are 21.1%, 28.6%, 31.6%, 
and 18.7%, respectively. Interestingly, even though the manager beat the market 
60% of the time, the manager is almost as likely to be an underperformer or 
an in-line performer (49.7% probability) as a star or a superstar (50.3% prob-
ability). 
	 7.	10%. You are given the following:
P
Bull
P
P Bull
[
]
%
[ ]
%
[
]
%
+
=
+ =
=
|
75
50
60
You are asked to find P[Bear | +]. A direct application of Bayes’ theorem will 
not work. Instead we need to use the fact that the Federal Reserve’s statement 
must be either bearish or bullish, no matter what the market does; therefore:
P Bear
P Bull
P
Bull P Bu
[
]
[
]
[
] [
|
|
|
+ =
−
+ =
−
+
1
1
ll
P
P Bear
P
]
[ ]
[
]
%
%
%
[
+
+ =
−
=
−
⋅
|
1
75
60
50
1
3
4
3
5
1
2
Bear | + =
−
=
]
%
1
9
10
10
	 8.	Because the prior distribution is a beta distribution and the likelihood can be de-
scribed by a binomial distribution, we know the posterior distribution must also 
be a beta distribution. Further, we know that the parameters of the posterior dis-
tribution can be found by adding the number of successes to the first parameter, 
and the number of failures to the second. In this problem the initial distribution 
was β(4,4) and there were 60 successes (up days), and 100 – 60 = 40 failures. 
Therefore, the final distribution is β(64,44). The mean of a beta distribution, 
β(a,b), is simply a  ̸(a + b). The mean of our posterior distribution is then:
µ =
+
=
+
=
=
a
a
b
64
64
44
64
108
59 26
.
%
We therefore believe there is a 59.26% probability that the strategy will be up 
tomorrow.
	 9.	There are 27 possible states for the network: 33 = 27. The minimum number of 
probabilities needed to define the network is 22. As an example, we could define 
P[A = up], and P[A = unchanged] for node A, which would allow us to calculate 
P[A = down] = 1 − P[A = up] − P[A = unchanged]. Similarly, we could define two 
probabilities for node B. For node C, there are nine possible input combinations 
(each of three possible states for A can be combined with three possible states 
from B). For each combination, we can define two conditional probabilities 

282
Answers
and infer the third. For example, we could define P[C = up | A = up, B = up] 
and P[C = unchanged | A = up, B = up], which would allow us to calculate  
P[C = down | A = up, B = up] = 1 − P[C = up | A = up, B = up] − P[C = unchanged 
| A = up, B = up]. This gives us a total of 22 probabilities that we need to define: 
2 + 2 + 9 × 2 = 22.
	10.	The correlation matrix for the first network is:
Network 1
E
S1
S2
E
100%
49%
20%
S1
49%
100%
10%
S2
20%
10%
100%
	11.	The correlation matrix for the second network is:
Network 2
E
S1
S2
E
100%
49%
7%
S1
49%
100%
15%
S2
7%
15%
100%
Chapter 7
	 1.	Mean = 45.0; standard deviation = 29.3; standard deviation of mean = 9.3. For 
the hypothesis that the mean is greater than 40, the appropriate t-statistic has 
a value of 0.54. For a one-sided t-test with 9 degrees of freedom, the associated 
probability is 70%. There is a 30% chance that the true mean is found below 40, 
and a 70% chance that it is greater than 40.
	 2.	The mean is 6.9% and the standard deviation of the returns is 23.5%, giving a 
standard deviation of the mean of 7.4%. The t-statistic is 0.93. With 9 degrees of 
freedom, a one-sided t-test produces a probability of 81%. In other words, even 
though the sample mean is positive, there is a 19% chance that the true mean is 
negative.
	 3.	A negative return would be greater than two standard deviations below the 
mean. For a normal distribution, the probability (one-tailed) is approximately 
2.28%. If we do not know the distribution, then, by Chebyshev’s inequality, the 
probability of a negative return could be as high as 12.5% = 1/2 × 1/(22). There 
could be a 25% probability of a +/–2 standard deviation event, but we’re inter-
ested only in the negative tail, so we multiply by ½. We can perform this last step 
only because we were told the distribution is symmetrical.
	 4.	The expected return is +10%. The 95% VaR is 35% (i.e., 5% of the returns are 
expected to be worse than –35%). The expected shortfall is 37.5% (again the 
negative is implied).

Answers
283
	 5.	For a normal distribution, 5% of the weight is less than –1.64 standard devia-
tions from the mean. The 95% VaR can be found as: 0.40% – 1.64 ∙ 2.30% = 
–3.38%. Because of our quoting convention for VaR, the final answer is VaR = 
3.38%.
	 6.	We can use Equation 7.4 to calculate the expected variance of the sample vari-
ances. Because we are told the underlying distribution is normal, the excess kur-
tosis can be assumed to equal zero and n = 33; therefore:
E
n
n
[( ˆ
) ]
.
σ
σ
σ
2
2 2
4
4
2
1
0 40
2
32
−
=
−
+
=
=
=
= 0 16
4
0 04
2
2
2
.
.
κex
The standard deviation of the sample variances is then 4.0%.
	 7.	An appropriate null hypothesis would be: H0: σ = 40%. The appropriate test 
statistic is:
(
) .
.
33
1 0 50
0 40
50
2
2
−
=
Using a spreadsheet or other program, we calculate the corresponding probabil-
ity for a chi-squared distribution with 32 degrees of freedom. Only 2.23% of 
the distribution is greater than 50. At a 95% confidence level, we would reject 
the null hypothesis.
	 8.	The answer is 12.5%. This is a –2 standard deviation event. According to Che-
byshev’s inequality, the probability of being more than two standard deviations 
from the mean is less than or equal to 25%.
P X
n
n
P X
[
]
[
%
%]
%
|
|
|
|
−
≥
≤
−
≥
≤
=
⋅
µ
σ
1
15
2 10
1
2
25
2
2
Because the distribution of returns is symmetrical, half of these extreme returns 
are greater than +2 standard deviations, and half are less than –2 standard devia-
tions. This leads to the final result, 12.5%.
	 9.	The standard deviation of the mean is 2%:
σ µ =
=
12
36
2
%
%
This makes the difference between the average fund return and the benchmark, 
18% – 14% = 4%, a +2 standard deviation event. For a t distribution with 35 
degrees of freedom, the probability of being more than +2 standard deviations 
is just 2.67%. We can reject the null hypothesis, H0: µ = 14%, at the 95% 
confidence level. The difference between the average return and the benchmark 
return is statistically significant.
	10.	To find the 95% VaR, we need to find v, such that:
pd
v
π =
−∫
0 05
100
.

284
Answers
Solving, we have:
1
200
200
100
200
0 05
100
100
d
v
v
v
v
π
π
−
−
∫
=
=
+
= .
= −90
The VaR is a loss of 90. Alternatively, we could have used geometric arguments 
to arrive at the same conclusion. In this problem, the PDF describes a rectangle 
whose base is 200 units and whose height is 1/200. As required, the total area 
under the PDF, base multiplied by height, is equal to one. The leftmost fraction 
of the rectangle, from –100 to –90, is also a rectangle, with a base of 10 units 
and the same height, giving an area of 1/20, or 5% of the total area. The edge of 
this area is our VaR, as previously found by integration.
	11.	In the previous question we found that the VaR, v, was equal to –90. To find the 
expected shortfall, we need to solve the following equation:
ES
pd
=
−
−
∫
1
0 05 100
90
.
π
π
Solving, we find:
ES
d
d
=
=
=
−
−
−
−
1
0 05
1
200
1
20
2
1
20
2
100
90
100
.
[
]
π
π
π
π
π
90
100
90
2
2
1
20
90
100
95
∫
∫
−
−
=
−
−−
= −
((
)
(
) )
The final answer, a loss of 95 for the expected shortfall, makes sense. The 
PDF in this problem is a uniform distribution, with a minimum at –100. Because 
it is a uniform distribution, all losses between the (negative) VaR, –90, and the 
minimum, –100, are equally likely; therefore, the average loss, given a VaR ex-
ceedance, is halfway between –90 and –100.
	12.	To find the 95% VaR, we need to find v, such that:
pd
v
π =
−∫
0 05
15
.
By inspection, half the distribution is below 5, so we need only bother with the 
first half of the function:
3
80
1
400
3
80
1
800
2
15
15
+
=
+
−
−
π
π
π
π
d
v
v
∫
=
+
(
)
3
80
15
v
+
−
=
+
+
=
1
800
225
0 05
30
185
0
2
2
)
(
.
v
v
v

Answers
285
We can use the solution to the quadratic equation:
v = −
±
−
= −
±
⋅
30
900
4 185
2
15
2 10
Because the distribution is not defined for π < –15, we can ignore the negative, 
giving us the final answer:
v = −
+
= −
15
2 10
8 68
.
The one-day 95% VaR for Pyramid Asset Management is approximately 8.68.
Chapter 8
	 1.	A
B
BC
+
= −
+
= −
=
10
8
9
7
2
1
9
1
8
9
18
8
2
1
9
1
5
10
7
7
100
15
77
14
−
−
= −
−
CBB =
−
−
=
−
−
−
−
5
10
7
7
2
1
9
1
3
13
38
83
	 2.	For the first part of the question, because matrix addition is commutative and 
associative, the order in which we perform the operations does not matter:
B
A
C
A
B
C
+
+
=
+
+
=
−
+
+
−
(
)
10
8
9
7
2
1
9
1
5
10
7
7
13
1
25
15
−
=
−
−
B A
C)
(
=
−
−
−
−
−
2
1
9
1
10
8
9
7
5
10
7
7
=
−
=
2
1
9
1
5
18
2
0
1522
13
4
2
	 3.	
′ = −
′ =
−
−
A
C
10
9
8
7
5
7
10
7

286
Answers
	 4.	F
G =
+
−
−
−
−
+
−
−
−
6
8
6
1
2
3
5
0
8
0
1
7
=
−
−
−
−
′ =
−
−
−
−
1
8
14
1
1
10
6
8
6
1
2
3
FG
−
−
−
=
−
−
−
−
−
5
0
0
1
8
7
30
40
30
1
2
3
41
50
69
′
= −
−
−
−
−
−
−
F G
6
1
8
2
6
3
5
0
8
0
1
7
= 18
29
50
19
	 5.	A matrix multiplied by an appropriately sized identity matrix is itself.
UI
U =
=
1
1
1
1
This is true when the identity matrix is multiplied by itself, too.
I
I I
I
2
=
=
= 1
0
0
1
For U2:
U2 =
=
1
1
1
1
1
1
1
1
2
2
2
2
For AU:
AU = −
=
−
−
10
8
9
7
1
1
1
1
1
15
1
15
	 6.	To prove that J is the inverse of K, we need to show that the two matrices mul-
tiplied together produce an identity matrix.
JK =
−
−
=
4
9
1
2
2
9
1
4
1
0
0
1
	 7.	To solve this problem, we could multiply M by itself five times. Alternatively, we 
can reexpress M as the product of a constant and an identity matrix:
M5 =
=
=
2
0
0
2
2 1
0
0
1
2
1
5
5
5
0
0
1
32 1
0
0
1
32
0
0
32
5
=
=

Answers
287
	 8.	At the end of the year, it is expected that 61% of the bonds will have an A rating, 
36.4% B, 2.2% C, and 0.4% D. To get the answer, we can proceed one rating at 
a time. Of the 60% of bonds that are rated A at the start of the year, we expect 
95% will still be rated A at the end of the year. Of the 40% of bonds that are 
rated B at the start of the year, we expect 10% to have been upgraded to A by 
the end of the year. Putting the two together, we have:
60% × 95% + 40% × 10% = 57% + 4% = 61%
We can calculate the other three ratings similarly:
60% × 4% + 40% × 85% = 2.4% + 34% = 36.4%
60% × 1% + 40% × 4% = 0.6% + 1.6% = 2.2%
60% × 0% + 40% × 1% = 0% + 0.4% = 0.4%
We can check our answer by noting that the sum of the answers is 100%. At 
the end of the year each bond must be either A, B, C, or D; therefore, the sum of 
the expected values must be 100%.
	 9.	To calculate the two-year transition matrix, we simply square the one-year ma-
trix. Using T1 and T2 to denote our one-year and two-year matrices, respectively, 
we have:
T
T T
1
2
=
=
1
0 95
0 10
0 00
0 00
0 04
0 85
0 20
0 00
0 0
.
.
.
.
.
.
.
.
. 1
0 04
0 65
0 00
0 00
0 01
0 15
1 00
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 95
0 10
0 00
0 00
0 04
0 85
0 20
0 00
0 01
0 04
0 65
0 00
0 00
0 01
0 15
1 00
.
.
.
.
.
.
T2 =
0 9065
0 1800
0 0200
0 0000
0 0740
0
.
.
.
.
.
.
.
.
.
.
.
.
7345
0 3000
0 0000
0 0176
0 0610
0 4305
0 0000
0.
.
.
.
0019
0 0245
0 2495
1 0000
Though not necessary, we can reformat this to match the original one-year 
matrix:
2-year
To
A
B
C
D
From
A
90.65%
7.40%
1.76%
0.19%
B
18.00%
73.45%
6.10%
2.45%
C
2.00%
30.00%
43.05%
24.95%
D
0.00%
0.00%
0.00%
100.00%

288
Answers
	10.	We can use our Cholesky algorithm to find the elements of the matrix:
l
l
l
l
l
1 1
11
2 1
11
21
2 2
22
4
2
1
1
2 14
7
,
,
,
(
)
=
=
=
=
=
=
=
−
σ
σ
σ
2 1
2
2
3 1
1 1
3 1
3 2
50
7
1
1
1
2 16
8
,
,
,
,
,
(
)
(
)
=
−
=
=
=
=
=
l
l
l
σ
1
1
1 58
8 7
2
2 2
3 2
3 1 2 1
3 3
33
l
l
l
l
,
,
,
,
,
(
)
(
)
σ
σ
−
=
−
=
=
−
⋅
l
l
3 1
2
3 2
2
2
2
132
8
2
8
,
,
−
=
−
−
=
We can express the full lower triangular matrix as:
L =
2
7
8
0
1
2
0
0
8
We can verify this answer by noting that LL′ is indeed equal to our original 
covariance matrix, Σ.
Chapter 9
	 1.	Vectors a and b are not orthogonal, but b and c are orthogonal. We know this 
from their inner products, which we can calculate as follows:
a b
⋅
⋅
⋅
−
=
−
=
+ −
10
5
4
6
2
4
10 6
5
(
)
(
)
⋅
⋅
+
−
=
−
−
=
≠
2
4
4
60
10
16
3
0
4
b c
⋅
⋅
⋅
⋅
=
−
=
+
+
6
2
4
5
5
10
6 5
2 5
(−
=
+
−
=
⋅
4 10
30
10
4
0
0
)
	 2.	In order for A to be an orthonormal basis, we require that the column vectors 
are orthogonal and have a magnitude of one. For the two column vectors to be 
orthogonal, we require that their inner product is zero:
a
a
2
1⋅
⋅
⋅
=
+
=
x
x
1
3
1
3
2 2
3
1
3
1
3⋅
=
= −
2 2
3
0
2 2
3
x

Answers
289
We next check that the column vectors have a magnitude of one:
 ||
|| 
a
a
a
1
1
1 =
=
−
−
⋅
⋅
2 2
3
1
3
2 2
3
1
3
=
+
=
=
=
⋅
8
9
1
9
1
1
3
2 2
3
||
|| 
a
a
a
2
2
2
=
+
=
⋅
1
3
2 2
3
1
9
8
9
1
Both vectors are normal; therefore, the solution,
= −
x
2 2
3
makes A an orthonormal basis.
	 3.	In order for B to be an orthonormal basis, we require that the column vectors 
are orthogonal and have a magnitude of one. For the two column vectors to be 
orthogonal, we require that their inner product is zero:
b
b
2
1⋅
⋅
⋅
⋅
=
+
=
x
y
y
x
1
5
2 6
5
1
5
2 6
5
=
= −
0
2 6y
x
Using the fact that the magnitude of the first column vector must be one:
b
b
b
1
1
1
2
2
2
2
1
1
=
=
+
=
+
=
⋅
x
y
x
y
Substituting in our previous result:
−(
) +
=
+
=
=
= ±
2 6
24
1
1
25
1
5
2
2
2
2
2
y
y
y
y
y
y
Both the positive root and the negative root are legitimate solutions. There 
are actually two possible final answers.
Solution 1:
Solution 2:
y
x
y
= +
= −
= −
1
5
2 6
5
1
5
;
; x = + 2 6
5

290
Answers
	 4.	Because B is an orthonormal basis, we can find the coordinate vector for x:
c
B x
=
′
=
−
=
−
1
2
1
2
1
2
1
2
6
4
10
2
2
2
	 5.	A coordinate vector, c, for x should satisfy the following equation:
c
c
c
2
1
3
4
1
5
2
18
2
46
1
37
−
+
+
−
−
=
−
−
170
19
165
Working through produces three simultaneous equations:
4
2
46
170
18
19
5
2
37
1
2
3
1
2
3
1
2
3
c
c
c
c
c
c
c
c
c
+
−
= −
−
−
=
+
+
= 165
By solving and substituting in, we arrive at the final answer: c1 = 3, c2 = 1, c3 = 4.
Chapter 10
	 1.	The expected return of XYZ is 6.01%:
E r
r
E
r
r
E
r
[
]
[(
)
]
[
XYZ
index
index
index
in
=
+
+
=
α
β
ε
α
dex
index
index
index
ind
]
[
]
[
]
[
+
+
β
ε
E r
r
E
r
E r
r
XYZ
ex
index
]
.
%
.
. %
.
%
=
+
=
+
=
⋅
α
βr
0 01
1 20 5 0
6 01
	 2.	The expected value of rXYZ is 0.07%:
E r
E
r
E
E r
E
[
]
[
]
[ ]
[
]
[ ]
XYZ =
+
+
=
+
+
α
β
ε
α
β
ε
inde
i
x
ndex
E r
E r
[
]
[
]
.
%
.
.
%
.
XYZ =
+
=
+
=
⋅
α
β
index
0 01
1 20 0 05
0 07%
%
The variance of rXYZ is:
Var[
]
[(
[
]) ]
[( (
[
r
E r
E r
E
r
E
XYZ
XYZ
XYZ
index
=
−
=
−
2
β
r
r
E
r
E r
index
XYZ
index
inde
])
]
)
[
]
[
(
[
+
=
−
ε
β
2
2
Var
x
index
index
XYZ
])
(
[
])
]
[
]
2
2
2
2
+
−
+
=
βε
ε
β
r
E r
r
Var
E r
E r
E r
E
[(
[
]) ]
[
]
 
[
index
index
index
−
+
−
2
2
2
β
ε
β
ε] [
]
[
]
[
]
[
]
E r
E
r
r
index
XYZ
index
+
=
+
ε
β
2
2
Var
Var
Var[
]
.
ε2
0 000424
=

Answers
291
To get to the last line, we use the fact that the covariance between the regressor 
and the disturbance term is zero in a linear regression, which implies:
Cov[ ,
]
[
]
[ ] [
]
[
ε
ε
ε
ε
r
E r
E
E r
E r
index
index
index
=
−
=
index] = 0
Taking the square root of the variance, we get a standard deviation of 2.06%.
	 3.	We start by calculating the covariance:
Cov
index
index
[
,
]
[(
[
])(
[
r
r
E r
E r
r
E
XYZ
XYZ
XYZ
=
−
−
r
E
r
E r
r
index
index
index
index
])]
[( (
[
])
)(
=
−
+ ε
β
−
=
−
E r
r
r
E
r
E
[
])]
[
,
]
[ (
[
index
index
index
Cov
XYZ
β
r
r
E r
r
r
index
index
index
ind
Cov[
])
[
]]
,
2 +
−ε
ε
XYZ
ex
index
index
index
]
[ (
[
]) ]
[
]
[
=
−
+
−
E
r
E r
E r
E r
ε
β
2
index
index
index
Cov
] [ ]
[(
[
]) ]
[
E
E r
E r
r
ε
β
−
=
2
XYZ,
]
[
]
r
r
index
index
Var
= β
The correlation is then:
ρ
β
=
=
Cov
Var
Var
Var
[
,
]
[
]
[
]
r
r
r
r
XYZ
index
index
XYZ
[
]
[
]
[
]
[
]
r
r
r
r
index
index
XYZ
index
Var
Var
Var
V
= β
ar[
]
.
.
%
.
%
.
%
rXYZ
=
=
1 201 50
2 06
87 42
	 4.	The R2 is 20%:
R2
1
1
10 80
13 50
20
=
−
=
−
=
RSS
TSS
.
%
.
%
%
	 5.	The corresponding F-statistic is 12:
R
n
R
t
n
2
2
1
1
20
2
1
1
20
50
2
/ (
)
(
) / (
)
% / (
)
(
%) / (
−
−
−
=
−
−
−) = 12
Using a spreadsheet or other program, we see that the probability associ-
ated with this F-statistic is 0.11%; that is, there is only a 0.11% chance that an 
F-statistic of this magnitude (or greater) would have happened by chance. The 
F-statistic is significant at the 95% confidence level.
	 6.	We compute the adjusted R2 for each model. The univariate model has two re-
gressors, including the constant. The second model has four:
R
R
2
2
4
2
1
1
0 60 20
1
20
2
57 78
1
1
0 64
=
−
−
−
−
=
=
−
−
(
.
)
.
%
(
.
) 20
1
20
4
57 25
−
−
=
.
%
On this basis, the original univariate model is slightly better.

292
Answers
	 7.	30.5%:
E r
r
r
E
r
r
r
A
B
A
B
A
[
,
]
[ .
.
.
ABC |
|
=
+
+
+
0 01
1 25
0 34
ε
,
]
                         
.
.
r
r
B
A
=
+
+
0 01
1 25
0.
  [
,
]
.
.
%
.
34
0 01
1 25 10
0 34 5
r
E r
r
r
B
A
B
ABC |
=
+
+
⋅
⋅0
0 01
0 125
0 17
%
                         
.
.
.
=
+
+
= 30 5
. %
	 8.	One possible solution is to drop X3 from the model:
r
X
=
+
+
β
β
ε
1
2
2
1
Another possibility, if the spread between X2 and X3 is of interest, is:
r
X
X
X
=
+
+
−
+
β
β
β
β
ε
6
7
2
8
3
5
2
(
)
where β5 is taken from the regression of X2 on X3. Based on the assumption of 
the OLS model, the term in parentheses will be uncorrelated with X2.
	 9.	We start by writing the equation for the covariance of X and Y:
Cov[
,
]
[(
[
])(
[ ])]
X Y
E X
E X
Y
E Y
=
−
−
Using our linear regression equation and making use of the OLS assumptions, 
we see that the second term can be expressed in terms of X, β, and ε:
Y
E Y
X
E X
E
−
=
+
+
−
+
+
[ ]
(
)
(
[
]
[ ])
α
β
ε
α
β
ε
Y
E Y
X
E X
E
−
=
−
+
−
[ ]
(
[
])
(
[ ])
β
ε
ε
Substituting this into our covariance equation:
Cov
Cov
[
,
]
[(
[
])( (
[
])
(
[ ]))]
X Y
E X
E X
X
E X
E
=
−
−
+
−
β
ε
ε
[
,
]
[ (
[
])
(
[
])(
[ ])]
[
,
X Y
E
X
E X
X
E X
E
X
=
−
+
−
−
β
ε
ε
2
Cov
Y
E X
E X
E X
E X
E
X
]
[(
[
]) ]
[(
[
])(
[ ])]
[
,
=
−
+
−
−
β
ε
ε
2
Cov
Y
X
X
X
]
[
, ]
=
+
=
βσ
ε
βσ
2
2
Cov
All that remains is to divide both sides by the variance of X, and to expand the 
correlation term:
β
σ
ρ
σ σ
σ
ρ
σ
σ
=
=
=
Cov
2
[
,
]
X Y
XY
X
Y
X
XY
Y
X
X
2
	10.	First, we find the optimal value of α, α*:
∂
= −
−
−
−
−
=
=
=
∑
∑
RSS
d
y
x
y
x
i
i
i
n
i
i
i
n
α
α
β
α
β
2
0
1
1
(
)
(
*
 
)

Answers
293
(
)
*
*
*
(
)
y
x
n
n
y
x
i
i
i
n
i
n
i
i
i
n
−
=
=
=
−
=
=
=
∑
∑
∑
β
α
α
α
β
1
1
1
1
=
−
=
−
=
=
∑
∑
1
1
1
1
n
y
n
x
Y
X
i
i
n
i
i
n
β
α
β
*
Next, we solve for β:
∂
= −
−
−
−
−
=
=
=
∑
RSS
d
x y
x
x y
x
i
i
n
i
i
i
i
i
i
β
α
β
α
β
2
0
1
(
)
(
*
)
1
2
1
1
1
n
i
i
i
i
i
n
i
n
i
n
x y
x
x
∑
∑
∑
∑
−
=
=
=
=
α
β*
At this point we substitute in our optimal value of α, α*:
x y
Y
X nX
x
x y
nYX
i
i
i
n
i
i
n
i
i
i
=
=
=
∑
∑
−
−
=
=
−
1
2
1
(
*
)
*
*
β
β
β
1
2
1
2
n
i
i
n
x
nX
∑
∑
=
−
Chapter 11
	 1.	The models are:
	
a.	 AR(2)
	
b.	AR(1)
	
c.	 ARMA(2,1)
	
d.	Drift-diffusion
	 2.	 E rt
[ ]
.
.
.
=
−
=
−
=
1
1
1
1
0 80 02
0 10
λ α
	 3.	The expected value of rt is 0.80% the next period, and 0.84% the following 
period:
E r r
r
r
r
t
t
t
t
t
[
,
]
.
.
.
.
−
−
−
−
=
+
−
=
+
1
2
1
2
0 01
0 30
0 20
0 01
0 30 0 02
0 20 0 04
0 0080
.
.
.
.
.
⋅
⋅
−
=

294
Answers
To get the two-period-ahead forecast, we can use the previous result:
E r r
r
t
t
t
[
,
]
.
.
.
.
.
−
−
=
+
−
=
⋅
⋅
1
2
0 01
0 30 0 0080
0 20 0 02
0.0084
Alternatively, we can substitute the original equation into itself to get rt in terms 
of rt–2 and rt–3:
r
r
r
r
t
t
t
t
t
=
+
−
+
=
+
−
−
0 01
0 30
0 20
0 01
0 30 0
1
2
.
.
.
.
.
( .
ε
01
0 30
0 20
0 20
0
2
3
1
2
+
−
+
−
+
=
−
−
−
−
.
.
)
.
r
r
r
r
t
t
t
t
t
t
ε
ε
.
.
.
[
,
013
0 11
0 06
030
2
3
1
2
−
−
+
+
−
−
−
−
r
r
E r r
t
t
t
t
t
t
ε
ε
r
r
r
t
t
t
−
−
−
=
−
−
3
2
3
0 013
0 11
0 06
]
.
.
.
                      
.
.
.
.
.
.
=
−
−
=
⋅
⋅
0 013
0 11 0 02
0 06 0 04
0 0084
	 4.	The expected log return over one year is 0.0%. The standard deviation of the 
annual log return is 24%.
We can get this result by recognizing the annual return as a collection of 
i.i.d. variables, and using our square root rule to calculate the standard devia-
tion. More formally, we can construct the annual return series (remember, log 
returns are additive):
r
r
t
t i
i
t i
i
256
0
255
0
255
, =
=
−
=
−
=
∑
∑ε
where r256,t is our 256-day annual return. We can find the expected value as fol-
lows:
r
E
E
E
t
t
i
i
i
t
i
256
0
255
0
25
,
=
=
]
[
−
=
−
=
∑
ε
ε
5
0
255
0
0
∑
∑
=
=
=
i
We can then calculate the variance as follows:
Var
E
r
E
r
E
r
r
t
t
t
256
256
256
2
25
,
,
,
[
(
])
−
=
=
6
2
256
0
255
2
,
,
t
t
t
i
i
E
r
=
−
=∑
Var
ε
=
−
−
=
= ∑
∑
E
t i
j
t
j
i
ε
ε
0
255
0
255
Var r
E
r
t
t
i t
j
j i
i
i
t
i
256
255
0
255
2
,
+
=
−
−
≠
=
−
=
∑
∑
ε
ε
ε
0
255
256
∑
=
−
−
≠
Var
E
r
t
t
i t
j
j
,
ε
ε
i
i
t i
i
E
255
0
255
2
0
255
∑
∑
∑
=
−
=
+
ε

Answers
295
For each term in the final summation, we can determine the value by noting the 
following:
Var[
]
[(
[
]) ]
[
]
ε
ε
ε
ε
t
t
t
t
E
E
E
=
−
=
2
2
Cov[
,
]
[(
[
])(
[
])]
[
]
ε
ε
ε
ε
ε
ε
ε ε
s
t
s
s
t
t
s t
E
E
E
E
=
−
−
=
= 0 
 
∀
≠
s
t
Now we have:
Var[
Var[
]
Var[
]
r
t
i
t
j i
256
0
255
0
256
, ] =
+
=
=
≠
∑
⋅
ε
ε
t
255
0
255
∑
∑
=
i
The variance of the annual returns is 256 times as great as the variance of the 
daily returns. To get the standard deviation, we just take the square root of both 
sides:
σ
ε
σε
256
256
16
16 1 5
24
=
[
] =
=
=
⋅
⋅
Var
t
. %
%
	 5.	The expected log return over one year is 25.6%. The standard deviation of the 
annual log return is 24%.
As before, we can get this result by recognizing the annual return as a collec-
tion of i.i.d. variables, and using our square root rule to calculate the standard 
deviation. More formally, we can construct the annual return series (remember, 
log returns are additive):
r
r
t
t i
i
t i
i
t
256
0
255
0
255
256
,
(
)
=
=
+
=
+
−
=
−
=
−
∑
∑α
ε
α
ε
i
i=∑
0
255
where r256,t is our 256-day annual return. We can find the expected value as fol-
lows:
E r
E
E
t
t
i
i
]
[
( [
,
256
0
255
256
256
+
=
+
=
−
=∑
α
ε
ε
α
t i
i
i
−
=
=
∑
∑
=
+
=
=
])
%
.
0
255
0
255
256
0
256
25 6
α
α
Using this result, we can then calculate the variance as follows:
Var[
]
[(
[
]) ]
,
,
,
r
E
E
r
E
r
t
t
t
t
256
256
256
2
256
−
=
+
=
α
ε −
=
−
=
∑
i
i
t
E
r
256
0
255
2
256
α
Var[
]
,
εt i
i
−
=∑
0
255
2

296
Answers
This is exactly the same as what we had in the previous question. The ad-
dition of the drift term does not impact the variance or standard deviation. The 
final result is the same as before:
σ
ε
σε
256
256
16
16 1 5
24
=
=
=
=
⋅
⋅
Var[
]
. %
%
t
	 6.	The expected log return over two days is 0.40%. The standard deviation of the 
two returns is 3.0%. For the case where λ equals –0.50, the mean of the two-day 
return would be approximately 0.13%, and the standard deviation would be 
approximately 1.73%.
We start by expressing the original AR(1) equation as an infinite sum of lags 
of the disturbance term:
r
r
r
t
t
t
i
i
n
n
t n
i
t i
i
=
+
+
=
+
+
−
−
=
−
−
−
=
∑
α
λ
ε
α
λ
λ
λ ε
1
1
0
1
0
n
t
i
t i
i
r
−
−
=
∞
∑
∑
=
−
+
1
0
1
1
α
λ
λ ε
Constructing the two-period return is fairly straightforward. Paying careful at-
tention to the time subscripts, we can group the disturbance terms into one 
summation:
r
r
r
t
t
t
t
i
t i
i
2
1
1
0
2
1
1
1
,
(
)
=
+
=
−
+
+
+
−
−−
=
∞
∑
α
λ
ε
λ
λ ε
where r2,t is our two-day return. We can find the expected value as follows:
µ
α
λ
ε
λ
λ
ε
2
2
1
0
2
1
1
1
=
=
−
+
+
+
−−
=
E r
E
E
t
t
i
t i
i
[
]
[
]
(
)
[
]
,
∞
∑
=
−
2
1
1
α
λ
We then proceed to find the variance:
Var
Var
[
]
[
]
]
[
[
]
,
,
,
,
r
E r
E r
r
E
t
t
t
t
2
2
2
2
2
2
2
2
=
−
=
+ ε
μ
t
i
t i
i
t
2
2
1
0
2
2
1
2
+
+
+
+
−−
=
∞
∑
(
)
(
λ
λ
μ
ε
ε
μ 1
2
1
1
0
1
0
+
+
+
−−
=
∞
−−
=
∞
∑
∑
λ
λ ε
ε
λ
λ ε
)
(
)
i
t i
t
i
i
t i
i
−
=
+
+
−−
=
∞
∑
μ
ε
λ
λ ε
2
2
2
2
2
1
0
1
Var[
]
[
]
(
)
,
r
E
E
t
t
i
t i
i
+
−
−−
=
∞
∑
2
1
0
2 1(
)
]
[
λ
λ
ε ε
i
t t i
i
E
Var[
]
(
)
,
r
E
t
i
t i
i
j
t i
t
2
2
2
2
1
2
1
1
=
+
+
+
−−
−−
−
λ
σ
λ ε
λ λ ε
ε
ε
j
j i
i
i
t
r
−
≠
∞
=
∞
=
∞
∑
∑
∑
+
=
1
0
0
2
2
0
1
Var[
]
,
σε
2
σε
+
+
=
−
=
∞
∑
(
)
2
1
1
1
2
2
0
λ
λ
λ
i
i

Answers
297
The standard deviation of the two-day return is then:
σ
σ
λ
σ
λ
2
2
2
1
1
2
1
=
−
=
−
ε
ε
	 7.	The unconditional mean of the model is equal to θ, 4%. If interest rates start out 
at 6%, then we would expect interest rates to be 5.00%, then 4.50%, and then 
4.25% over the next three periods. This result is obtained by noting that the 
conditional expectation for the next period’s interest rate is, in this case, simply 
the average of the previous period’s rate and the long-term mean of 4%:
E r
r
r
E
E r
r
t
t
t
t
t
t
[
]
.
(
. )
%
[
]
[
|
|
−
−
=
+
−
+
⋅
1
1
0 5
1
0 5
4
σ
ε
−
−
=
+
1
1
0 5
4
]
. (
%)
rt
	 8.	By iteratively substituting the equation into itself, we see that this process can be 
written as an infinite moving average:
r
r
r
r
t
t
t
t
t
t
n
t n
i
t i
i
n
=
+
=
+
+
=
+
−
−
−
−
=
ρ
ε
ρ
ρε
ε
ρ
ρ ε
1
2
2
0
−
−
=
∞
∑
∑
=
1
0
ρ ε
i
t i
i
The unconditional mean is 0:
E r
E
E
t
i
t i
i
i
t i
i
i
[ ]
[
]
=
=
=
=
−
=
∞
−
=
∑
⋅
ρ ε
ρ
ε
ρ
0
0
0
0
0
∞
=
∞
∑
∑
i
Similarly, we can find the unconditional variance. First we note that, because 
the covariance between different disturbance terms is zero and the expected 
value of any individual disturbance terms is zero, we have the following:
Cov[
,
]
[
]
[
] [
]
ε
ε
ε
ε
ε
ε
t i
t
j
t i t
j
t i
t
j
E
E
E
E
−
−
−
−
−
−
=
+
=
[
]
 
ε
ε
t i t
j
i
j
−
−
=
∀≠
0
Using this and the fact that the unconditional mean is also zero:
Var[ ]
[
]
[ ]
[
]
r
E r
E r
E r
E
t
t
t
t
i
j
t i
j
t
j
=
+
=
=
−
−
2
2
2
ρ ρ
ε
ε
=
∞
=
∞
−
=
∞
∑
∑
∑
=
+
0
0
2
2
0
i
t
i
t i
i
r
E
Var[ ]
[
]
ρ
ε
ρ ρ
ε
ε
ρ
σ
σ
i
j
t i t
j
j i
i
i
i
E[
]
−
−
≠
∞
=
∞
=
∞
∑
∑
∑
=
=
−
2
2
0
0
2
1
1
ρ2
	 9.	Using the results from the previous question, we first derive an expression for the 
covariance:
Cov[
]
,
]
[
[ ]
]
[
[
r r
r
E
E
r
E
r
E
r
r r
t
t
t
n
n
t
t
t
t
n
t
−
−
−
−
+
=
=
n
i
t i
i
j
t
j n
j
E
]
=
−
=
∞
−
−
=
∞
∑
∑ρ ε
ρ ε
0
0

298
Answers
Cov[ ,
]
r r
E
t
t n
i
t i
i
t i
i n
i
n
−
−
−
=
∞
=
−
+
=
∑
∑ρ ε
ρ ε
0
1
=
−−
=
∞
−
−
∑ρ ε
ρ ε
j
t
j n
j
t
t n
i
t
r r
E
0
Cov[ ,
]
i
n
i
t i n
i
i
n
j
t
j n
j
+
−−
=
∞
=
−
−−
=
∞
∑
∑
ρ
ρ
ρ
ε
ε
0
0
1
0∑
+
=
−
−
−−
=
Cov[ ,
]
r r
E
t
t n
j
t i
i
t
j n
n
j
ε
ρ
ρ ε
ρ
0
0
0
0
0
1
∞
−−
−−
=
∞
=
∞
=
−
∑
∑
∑
∑
ρ ρ
ε
ε
i
j
t i n t
n
j
j
i
i
n
=
−
−
−
−−
=
∞
= ∑
Cov[ ,
]
r r
E
t
t n
i
n
j
t i n t
j n
j
i
ρ
ρ
ε
ρ
ε
0
0
∞
∑
= ρn
tr
Var[ ]
For the last line we were able to eliminate the first term in the expectations 
by noting that all the products contained different disturbance terms. From the 
preceding problem we know that the expected value of these cross products is 
zero. Because the unconditional variance is the same for both rt and rt–n, finding 
the correlation is just a matter of dividing Var[rt]:
Corr
Var
Var
Var
Var
[ ,
]
[ ]
[ ]
[ ]
r r
r
r
r
t
t n
n
t
t
t
n
−
=
=
ρ
ρ
[ ]
[ ]
r
r
t
t
n
Var
= ρ
	10.	We start by expressing both rt, and rt–1 as infinite series:
r
r
t
i
t i
i
t
i
t i
i
=
−
+
=
−
+
+
−
=
∞
−−
=
∞
∑
∑
α
λ
λ ε
α
λ
ε
λ
λ ε
1
1
0
1
0
t
i
t i
i
−
−−
=
∞
=
−
+∑
1
1
0
1
α
λ
λ ε
Next we find the mean of both series:
E r
E r
t
t
[ ]
[
]
=
=
−
−1
1
α
λ
Because the error terms are uncorrelated, we know that:
E
s
t
s t
[
]
  
 
ε ε
=
∀
≠
0
Using this and the previous results, we calculate the variances and covariance:
Var[ ]
E
rt
i
t i
i
=
=
−
−
=
∞
∑λ ε
σ
λ
ε
0
2
2
2
1
Var[
]
E
rt
i
t i
i
−
−
−
=
∞
=
=
∑
1
1
0
2
λ ε
σε2
2
1
1
0
1−
+
=
−
−
−
=
∞
∑
λ
ε
λ
λ ε
Cov[
]
,
r r
E
t
t
t
i
t i
i
λ ε
λσ
λ
ε
i
t i
i
−−
=
∞
∑
=
−
1
0
2
2
1

Answers
299
Finally, the correlation is:
Corr
Cov
Var
Var
[ ,
]
[ ,
]
[ ]
[
]
r r
r r
r
r
t
t
t
t
t
t
−
−
−
=
=
1
1
1
λ
	11.	To annualize the log return, we simply multiply by the number of months in a 
year, 12. To get the annualized standard deviation, we multiply by the square 
root of the number of periods. For skewness and kurtosis, we divide by the 
square root of 12 and 12, respectively. This gives: mean = 24%; standard devia-
tion = 5.20%; skewness = –0.29; kurtosis = 0.20.
Chapter 12
	 1.	We need to find h, such that:
δ
δ
δ
δ
δ
δ
i
i
h
i
i
n
n
h
=
−
=
−
∑
∑
=
=
−
−
=
−
−
0
1
0
1
1
2
1
2
1
1
1
1
Solving, we find:
0 5 1
1
0 5
1
0 5
0 5
. (
)
. (
)
( )
( .
.
−
=
−
=
+
=
+
δ
δ
δ
δ
δ
n
h
h
n
h ln
ln
δ
δ
δ
n
n
h
)
ln( .
.
)
ln( )
=
+
0 5
0 5
Alternatively, the formula for the half-life can be expressed as:
h
n
=
+
+
ln
ln
ln( )
( . )
(
)
0 5
1
δ
δ
	 2.	We start by computing decay factors and values for x2:
t
0
1
2
3
4
5
6
7
x
11
84
30
73
56
58
52
35
δ
0.6983
0.7351
0.7738
0.8145
0.8574
0.9025
0.9500
1.0000
x2
121
7,056
900
5,329
3,136
3,364
2,704
1,225
For the mean, using Equation 12.2, we have:
ˆ
.
.
.
µ
δ
δ
δ
t
n
i
t i
i
n
x
=
−
−
=
×
=
−
=
−
∑
1
1
0 15
336 86
50 04
0
1

300
Answers
For the variance, using Equation 12.12, we have:
ˆ
ˆ
.
.
.
σ
δ
µ
t
i
t i
i
n
t
A
x
B
2
2
0
1
2
0 17
19826 75
1
=
−
=
×
−
−
=
−
∑
15
50 04
505 18
2
×
=
.
.
Finally, we can take the square root of our answer for the variance, to get the 
standard deviation, 22.48.
	 3.	We start by calculating the following values:
t
0
1
2
3
4
5
x
0.04
0.84
0.28
0.62
0.42
0.46
δ 1
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
δ 2
0.9044
0.9135
0.9227
0.9321
0.9415
0.9510
δ 3
0.3487
0.3874
0.4305
0.4783
0.5314
0.5905
t
6
7
8
9
10
x
0.66
0.69
0.39
0.99
0.37
δ 1
1.0000
1.0000
1.0000
1.0000
1.0000
δ 2
0.9606
0.9703
0.9801
0.9900
1.0000
δ 3
0.6561
0.7290
0.8100
0.9000
1.0000
We then use Equation 12.2 to calculate our estimates of the mean: mean (no 
decay) = 0.5236; mean (decay = 0.99) = 0.5263; mean (decay = 0.90) = 0.5486.
	 4.	We start by expanding the table from our answer to question 3:
t
0
1
2
3
4
5
x
0.04
0.84
0.28
0.62
0.42
0.46
δ 1
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
δ 2
0.9044
0.9135
0.9227
0.9321
0.9415
0.9510
δ 3
0.3487
0.3874
0.4305
0.4783
0.5314
0.5905
x2
0.0016
0.7056
0.0784
0.3844
0.1764
0.2116
(x – E[x1])2 0.233904 0.100086 0.059359 0.009286 0.01074
0.00405
t
6
7
8
9
10
x
0.66
0.69
0.39
0.99
0.37
δ 1
1.0000
1.0000
1.0000
1.0000
1.0000
δ 2
0.9606
0.9703
0.9801
0.9900
1.0000
δ 3
0.6561
0.7290
0.8100
0.9000
1.0000
x2
0.4356
0.4761
0.1521
0.9801
0.1369
(x – E[x1])2
0.018595
0.027677
0.017859
0.217495
0.023604
In the last line, we have used our estimate of the mean (no decay) from the previ-
ous problem.

Answers
301
For the first estimator with no decay factor, we can use Equation 3.19 to 
calculate the variance:
ˆ
(
ˆ )
.
.
σ
µ
1
2
2
1
1
1
0 7227
11
1
0 0723
n
xi
x
i
n
−
−
=
−
=
=∑
For the second and third estimators, we use Equation 12.12 and our estimates 
of the mean from the previous question:
ˆ
ˆ
.
.
.
σ
δ
µ
2
2
2
0
1
2
0 11
10 47
1 10
=
−
=
×
−
×
−
=
−
∑
A
x
B
i
t i
i
n
t
0 5263
0 0716
0
2
3
2
2
0
1
2
.
.
ˆ
ˆ
=
=
−
=
−
=
−
∑
σ
δ
µ
A
x
B
i
t i
i
n
t
.
.
.
.
.
16
6 86
1 11
0 5486
0 2610
2
×
−
×
=
Taking the square root of the variances, we arrive at our final answers: standard 
deviation (no decay) = 0.2688; standard deviation (decay = 0.99) = 0.2676; 
standard deviation (decay = 0.90) = 0.2610.
	 5.	The new estimates are 10.10%, 9.82%, and finally 9.78%. These can be found 
as follows:
ˆ
.
.
ˆ
ˆ
.
%
.
%
µ
µ
µ
t
t
t
x
=
+
=
+
=
−
⋅
⋅
0 02
0 98
0 02 15
0 98 10
1
1
1
0 10
0 02
4
0 98 12 8
9 82
0 02
2
3
.
%
ˆ
.
%
.
. %
.
%
ˆ
.
µ
µ
=
−
+
=
=
⋅
⋅
⋅
⋅
+
=
8
0 98 11 744
9 78
%
.
.
%
.
%
	 6.	The half-lives are:
h
h
200
200
1
0 5
0 5
0 95
0 95
13 5127
=
+
×
=
ln( .
.
.
)
ln( .
)
.
,000
1 000
0 5
0 5
0 95
0 95
13 5134
=
+
×
=
ln( .
.
.
)
ln( .
)
.
,
	 7.	The half-life of the EWMA estimator is approximately 11.11 days. A rectangu-
lar window with 22 days would have the most similar half-life, 11 days.
h32
32
0 5
0 5
0 96
0 96
11 11
=
+
×
=
ln( .
.
.
)
ln( .
)
.
	 8.	1 – 0.9650 = 87%
	 9.	Approximately 19.72%. We first update our estimate of the variance, and then 
take the square root:
ˆ
(
)(
)
ˆ
ˆ
(
.
)(
%
σ
δ
µ
δσ
σ
t
t
t
t
r
2
2
1
2
2
1
1
0 97 15
=
−
−
+
=
−
−
−
10
0 97 20
0 038875
19 72
2
2
2
%)
.
%
ˆ
.
ˆ
.
%
+
=
=
⋅
σ
σ
t
t

302
Answers
	10.	Approximately 10.25%. We can use our updating rule,
	
	
ˆ
(
)
ˆ
σ
δ
δσ
t
t
t
r
2
2
1
2
1
=
−
+
−
	
	 to calculate successive estimates of the variance. The estimate of the standard 
deviation is just the square root of the variance estimator:
t
0
1
2
3
4
5
6
r
−5%
18%
16%
−2%
5%
−10%
E[σ 2]
0.010000 0.009625 0.010764 0.011506 0.010950 0.010528 0.010501
E[σ]
10%
9.81%
10.37%
10.73%
10.46%
10.26%
10.25%

303
Allen, Linda, Jacob Boudoukh, and Anthony Saunders. 2004. Understanding Market, Credit, 
and Operational Risk: The Value at Risk Approach. Malden, MA: Blackwell Publishing.
Artzner, Philippe, Freddy Delbaen, Jean-Marc Eber, and David Heath. 1999. “Coherent Meas-
ures of Risk.” Mathematical Finance 9 (3): 203–228.
Campbell, John, Andrew Lo, and A. Craig MacKinlay. 1996. The Econometrics of Financial 
Markets. Princeton, NJ: Princeton University Press.
Gigerenzer, Gerd, and Adrian Edwards. 2003. “Simple Tools for Understanding Risks: From 
Innumeracy to Insight.” BMJ 327: 74a–744.
Hendry, David. 1980. “Econometrics—Alchemy or Science?” Economica 47 (188): 387–406.
Hua, Philip, and Paul Wilmott. 1997. “Crash Courses.” Risk 10 (June): 64–67.
Kritzman, Mark, Yuanzhen Li, Sebastien Page, and Roberto Rigobon. 2010. “Principal 
­Components as a Measure of Systemic Risk.” MIT Sloan Research Paper No. 4785–10 
(June 30).
Meucci, Attilio. 2009. “Managing Diversification.” Risk 22 (May): 74–79.
References


305
About the Author
M
ichael B. Miller studied economics at the American University of Paris and 
the University of Oxford before starting a career in finance.  He is currently 
the CEO of Northstar Risk Corp. Before that he was the Chief Risk Officer for 
­Tremblant Capital, and prior to that Head of Quantitative Risk Management at For-
tress Investment Group. Mr. Miller is also a certified FRM and an adjunct professor 
at Rutgers Business School.


307
About the Companion Website
M
any of the topics in this book are accompanied by an icon, as shown here. 
The icon indicates that Excel examples can be found on this book’s companion 
­website, www.wiley.com/go/millerfinance2e. Enter password: mathstats159 to access 
the site.


309
Index
A
Abbreviations, 258
Addition, matrix, 156–158
Adjusted R2, 206–207 
Alpha, in finance, 201–202
Alphabet, Greek, 255
Alternative basis, 192
AR. See Autoregression (AR)
ARCH, Autoregressive conditional 
heteroscedasticity, 230–232
Archimedean copulas, 98
Arithmetic Brownian motion, 229–230
Autocorrelation, variance and, 222–223
Autoregression (AR), 217–221
Autoregressive conditional 
heteroscedasticity (ARCH) model, 
230–232
Averages:
continuous random variables, 32–34
discrete random variables, 31–32
moving, 227–228
population and sample data, 29–31
B
Backtesting, 145–148
Basic math:
combinatorics, 8
compounding, 3–4
continuously compounded returns, 
6–7
discount factors, 9
geometric series, 9–13
limited liability, 4–5
logarithms, 1–2
log returns, 2–3, 5–6
problems, 14
Basic statistics:
averages, 29–34
best linear unbiased estimator (BLUE), 
57–58
cokurtosis, 53–57
correlation, 43–44
coskewness, 53–57
covariance, 42–43
expectations, 34–38
kurtosis, 51–53
moments, 47
problems, 58–59
skewness, 48–50
standard deviation, 39–41
standardized variables, 41–42
variance, 39–41, 44–47
Basis:
alternative, 192
change of, 180, 192
standard, 181
Basis rotation, 178
Bayes, Thomas, 113
Bayesian analysis. See also Bayesian 
networks
Bayes’ theorem, 113–119
continuous distributions, 124–128
frequentists and, 119–120
many-state problems, 120–124
overview of, 113
problems, 132–134
Bayesian networks:
versus correlation matrices, 130–132
overview of, 126–127
three-state, 134
Bayes’ theorem, 113-119
Bernoulli distribution, 63–64
Best linear unbiased estimator (BLUE), 
57–58
Beta, of stock, 199
Beta distribution, 82–83, 125–126, 127, 
128
Beta function, 80, 82
Bimodal mixture distribution, 85
Binary numbers, 249–250

310
Index
Binomial distribution, 8, 65–67
Binomial theorem, combinatorics and, 8
Bivariate standard normal probability 
density function, 93
Black-Karasinski interest rate model, 
234
Black Monday, 211
Black-Scholes equations, 230
BLUE. See Best linear unbiased 
estimator (BLUE)
Bond ratings, 15
Brownian motion, 229–230
C
Cauchy distribution, 75
Causal relationship, 226, 227
CDF. See Cumulative distribution 
functions (CDF)
Central limit theorem:
i.i.d. distributions and, 73–76
sample mean and, 136
Central moments. See also Moments
fourth (see Kurtosis)
second (see Variance)
third (see Skewness)
CEV. See Constant elasticity of volatility 
(CEV) model
Change of basis, 180, 192
Chebyshev’s inequality, 142
Chi-squared distribution, 77–78
Cholesky decomposition, 165–167
CIR. See Cox-Ingersoll-Ross (CIR) 
model
Clayton Copula, 98, 104, 259
Coefficient of determination. See R2
Coin flip examples, 35–36
Cokurtosis, 53–56
Combinatorics, 8
Component distributions, 84
Compounding, 3–4
Computer simulations, 41
Conditional probability:
expected shortfall and, 150
unconditional probabilities and, 
24–26
Confidence intervals:
confidence level and, 139
population mean and, 138
problems, 152–154
sample mean and, 137–138
Constant elasticity of volatility (CEV) 
model, 234
Continuous distributions, 124–128
Continuously compounded returns, 6–7
Continuous models, 228–230
Continuous random variables:
cumulative distribution functions, 
18–20
example of, 15–16
inverse cumulative distribution 
functions, 20–21
mean, median, mode of, 32–34
probability density functions, 16–18
Continuous time series models, 228–
230
Coordinate vectors, 174, 179
Copulas:
Archimedean, 98
definition, 97–102
Frank’s (see Frank’s copula)
graphing, 102–103
Gumbel, 98, 99–100, 260
independent, 261
Joe, 261
parameterization of, 104–110
problems, 111
in simulations, 103–104
summary of properties of, 259–261
t-copula, 98
Correlation:
causation and, 43–44
multivariate distributions and, 93–95
Correlation matrices, 130–132
Coskewness, 53–56
Covariance, 42–43. See also Variance
Covariance matrices, 132
Cox-Ingersoll-Ross (CIR) model, 
233–234
CrashMetrics approach, 245
Cross moments, higher-order, 53
Cumulative distribution functions 
(CDF), 18–20
D
Data-generating process (DGP), 135, 
136, 137

Index
311
Decay factors:
application, 245–247
CrashMetrics approach, 245
hybrid VaR, 245–247
mean, 237–242
problems, 247–248
variance, 243–244
weighted least squares, 244–245
window length and, 237, 238, 239, 242
DGP. See Data-generating process 
(DGP)
Diagonal matrix, 156
Diffusion:
drift-diffusion, 216–217
jump-diffusion, 232
Discount factors, 9
Discrete models, 228, 230, 233
Discrete random variables, 31–32
Distribution functions:
cumulative, 18–20
inverse cumulative, 20–21
Distributions:
application, 76–77
Bernoulli, 63–64
beta, 82–83
bimodal mixture, 85
binomial, 8, 65–67
Cauchy, 75
central limit theorem, 73–76
chi-squared, 77–78
component, 84
continuous, 124–128
creating normal random variables, 
76–77
cumulative distribution functions, 
18–20
F-distribution, 79–81
Gaussian, 70
lognormal, 72–73
mixture, 83–86
Monte Carlo simulations, 76–77
Multivariate (see Multivariate 
distributions)
nonparametric, 61
normal, 69–72
parametric, 61
Poisson, 68–69
problems, 86–88
skewness and, 48
standard uniform, 63
Student’s t, 78–79, 138
triangular, 81–82
uniform, 61–63
Diversification, 47, 148
Dot product, 171
Drift-diffusion model, 216–217
Dynamic term structure of interest 
rates, 185–191
E
Eigenvalues, 185
Eigenvectors, 185
Equity markets:
crashes in, 68, 211
structure of, 191–193
ESS. See Explained sum of squares (ESS)
Estimator. See Best linear unbiased 
estimator (BLUE)
Euclidean inner product, 169–171
Events:
independent, 22
mutually exclusive, 21
EWMA. See Exponentially weighted 
moving average
Exceedances, 146–148
Excel examples:
NORMSDIST function, 102
NORMSINV() function, 104
Expectation operator:
expectations concept and, 35
as linear, 37
not multiplicative, 37, 43
random variables and, 36
in sample problem, 38, 50
Expectations, 34–38
Expected shortfall, 150–151
Expected value. See Expectations
Explained sum of squares (ESS), 201
Exponentially weighted moving average 
(EWMA), 239–242
F
Factor analysis, 208–210
Farlie-Gumbel-Morgenstern (FGM) 
copula, 105, 109–110, 260
F-distribution, 79–81

312
Index
FGM. See Farlie-Gumbel-Morgenstern 
(FGM) copula
Finite series, 12–13
Flat yield curve, 186
Frank’s copula:
as Archimedean copula, 98
graphing, 102–103
properties of, 260
sample problem, 99–100, 101–102, 104
F-tests, 207
G
GARCH, Generalized autoregressive 
conditional heteroscedasticity, 
230–232
Gaussian copula, 98
Gaussian distribution, 70
Gaussian integral, 87
Gauss-Markov theorem, 206
GDP. See Gross domestic product (GDP)
Generalized autoregressive conditional 
heteroscedasticity (GARCH) model
Geometric Brownian motion, 230
Geometric series:
decay factors, 242
finite series, 12–13
infinite series, 9–12
math basics, 9–13
time series models, 238–239
Global equity markets, structure of, 
191–193
Gosset, William Sealy, 78
Graphing log returns, 5–6
Greek alphabet, 255
Gumbel copula, 98, 99–100, 260
H
Half-life, 241
Hedge ratio, 46
Hedging:
optimal, revisited, 199
portfolio variance and, 44–47
Heteroscedasticity, 198, 245. See also 
ARCH, Autoregressive conditional 
heteroscedasticity; GARCH, 
Generalized autoregressive 
conditional heteroscedasticity
Higher-order cross moments, 53
Homoscedasticity, 198, 223
Hua, Philip, 245
Huygens, Christiaan, 34–35
Hybrid VaR, 245–247
Hypothesis, null, 139–140
Hypothesis testing:
confidence level returns, 141–142
one tail or two, 140–141
overview of, 139
problems, 152–154
which way to test, 139–140
I
Identity matrix, 160–161
Idiosyncratic risk, 47
Independence, 24
Independent and identically distributed 
(i.i.d.) variables:
central limit theorem, 74–75, 77
definition, 45
GARCH and, 230
random walks, 216
uncertainty and, 46
variance and autocorrelation, 222
Independent copula, 261
Independent events, 22
Infinite series, 9–12, 242
Inner product, 169–171
Interest rates:
continuously compounded returns, 6–7
dynamic term structure of, 185–191
random walks and, 216
stress testing and, 211
Inverse cumulative distribution 
functions, 20–21
Inverse standard normal function, 104
Inversion, matrix, 156
Inverted yield curve, 187
J
Joe copula, 261
Joint uniform probability density 
function, 92
Jump-diffusion, 232
K
Kendall’s tau, 105, 106–107, 109–110
Kurtosis, 51–53. See also Cokurtosis

Index
313
L
Leptokurtotic distributions, 53
Liability, limited, 4–5
Limited liability, 4–5
Linear independence, 173–174
Linear regression analysis:
applications, 208–212
evaluating the regression, 201–203, 
206–207
factor analysis, 208–210
multicollinearity, 204–205
multivariate, 203–207
one regressor, 195–203
ordinary least squares, 197–200
parameters, estimating, 200,  
205–206
problems, 212–213
stress testing, 211–212
univariate, 195–196, 197, 201, 
203–204, 207
Logarithms:
definition, 1–2
time series, charting, 5–6
Lognormal distribution, 72–73
Log returns:
definition of, 2
graphing, 5–6
and simple returns, 3
M
Marginal distributions, 95–97
MAs. See Moving averages (MAs)
Math, basic. See Basic math
Matrix:
correlation, 130–132
covariance, 132
diagonal, 156
identity, 160–161
inversion, 156
ratings transition, 163–164
transition, 163–164
triangular, 156
upper diagonal, 156
zero, 162
Matrix algebra:
applications, 163–167
Cholesky decomposition, 165–167
matrix notation, 155–156
matrix operations (see Matrix 
operations)
Monte Carlo simulations, 165–167
problems, 168
transition matrices, 163–164
Matrix notation, 155–156
Matrix operations:
addition, 156–158
inversion, 156
multiplication, 158–162
subtraction, 156–158
transpose, 162–163
zero matrix, 162
Mean. See also Sample mean
decay factors and, 237–242
expected value and, 35, 36
moment and, 47
population, 138
Mean reversion, 218, 221
Median, 30
Mixture distributions, 83–86
Mode, 30
Moments:
central (see Central moments)
definition, 47
higher-order cross, 53
Monte Carlo simulations:
Cholesky decompositions and, 
165–167
copulas in, 103–104
normal random variables, creating, 
76–77
time series models, 218–221
Morgan, J. P., 142
Moving averages (MAs), 227–228
Multicollinearity, 204–205
Multiplication, matrix, 158–162
Multivariate distributions:
continuous distributions, 91–92
correlation, 93–95
discrete distributions, 89–90
marginal distributions, 95–97
problems, 111
visualization, 92–93
Multivariate regression. See also Linear 
regression analysis
applications, 208–212
evaluating the regression, 206–208

314
Index
Multivariate regression (continued)
factor analysis and, 208–210
multicollinearity, 204–205
OLS estimator, 244
overview of, 203–204
parameters, estimating, 205–206
stress testing and, 211–212
Mutually exclusive events, 21
N
Natural logarithms, 2
Negative skew, 48, 49
Nonelliptical joint distributions. See 
Copulas
Nonparametric distributions, 61
Normal distribution, 69–72
NORMSDIST function, 102
NORMSINV() function, 104
Notional value, 13
Null hypothesis:
one-tailed, 141
two-tailed, 140–141
which way to test, 139–140
Numbers, binary, 249–250
O
OLS. See Ordinary least squares (OLS)
One-column matrices, 155
One-tailed hypothesis testing, 140–141
Optimal hedging, 199
Ordinary least squares (OLS), 197–200, 
223
Orthogonality, 172–176
Orthonormal basis, 177–179
Over hedging, 47
P
Par, selling at, 13
Paradox, Zeno’s, 9–12
Parametric distributions, 61
Parsimony principle, 207
PCA. See Principal component analysis 
(PCA)
PDF. See Probability density function 
(PDF)
Pearson’s correlation, 106
Perpetuity, 11
Plateauing, in time series, 239
Platykurtotic distributions, 53
Poisson, Simeon Denis, 68
Poisson distribution, 68–69
Population and sample data, 29–31, 245
Population mean, 138
Portfolio variance and hedging, 44–47
Positive skew, 48
Posterior distribution, 124, 125–126, 
127
Principal component analysis (PCA):
factor analysis and, 208
global equity markets and, 191–193
interest rates and, 185–191
vector spaces and, 181–185
Prior distribution, 125–126, 127
Probabilities:
conditional, 24–26, 150
continuous random variables, 15–21
discrete random variables, 15
independent events, 22
mutually exclusive events, 21
networks and, 130–132
probability matrices, 22–24
problems, 26–27
Probability density function (PDF):
bivariate standard normal, 93
bivariate standard normal, with 
Clayton Copula, 98
continuous random variables, 32–34, 
40
definition, 16–18
joint uniform, 92
triangular, 144, 151
Probability matrices:
discrete multivariate distributions, 89
marginal distributions and, 96
two variables and, 22–24
Probability theory, 34–35
R
R2, 201–203, 206–207. See also 
Adjusted R2.
Rainfall example, 226–227
Random variables:
adding constant to, 41
continuous, 32–34
discrete, 31–32
mean of, 40

Index
315
Random walks, 215–216
Ratings transition matrices, 163–164
Rectangular window, 240
Regressand, use of term, 195
Regression analysis. See Linear 
regression analysis
Regressor:
multiple (see Multivariate regression)
one (see Univariate regression)
use of term, 195
Residual sum of squares (RSS), 201
Returns:
continuously compounded, 6–7
log, 2–3
simple, 3
Risk:
idiosyncratic, 47
systemic, 191
Risk factor analysis, 208–210
Risk-free asset, 41
Risk taxonomy, 208
Rolling mean, of time series, 239
Rotation:
basis, 178
change of, 180
vector, 177–180
R-squared. See R2
RSS. See Residual sum of squares  
(RSS)
S
Sample and population data, 29–31
Sample mean. See also Mean
estimator for, 30, 57
revisited, 135–137
Sample skewness, 49
Sample variance, 39, 137. See also 
Variance
Scalars:
orthogonality and, 172–175
scalar multiplication, 157, 159
use of term, 155
Scenarios, in stress testing, 211–212
Shifting, in yield curve, 185, 187
Shortfall, expected, 150–151
Simple returns, 3
Simulations, 41. See also Monte Carlo 
simulations
Skewness. See also Coskewness
continuous distributions, 50
negative skew, 48, 49
positive skew, 48
sample, 49
third central moment, 48
Spearman’s rho, 105, 110
Spherical errors, 198
Spikes, in time series, 238
Square root rule, uncorrelated 
variables and, 45, 136
Standard Brownian motion, 229
Standard deviation:
in practice, 37
variance and, 39–41
Standardized variables,  
41–42
Standard returns, 3
Standard uniform distributions, 63
Stationarity, 223–227
Statistics, basic. See Basic statistics
Step function, 229
Stock market index:
exponential growth and, 223
return of, 15–16
Stock versus bond matrix, 22–24
Stress testing, 211–212
Strong stationarity, 223
Student’s t distribution:
confidence intervals and, 137
critical values for, 141
definition, 78–79
Subadditivity, 148–149
Subtraction, matrix, 156–158
Symmetrical matrices, 163
Systemic risk, 191
T
Taylor expansions, 251–252
t-copula, 98
t-distribution, 138. See also Student’s t 
distribution
Testing:
back-, 145–148
F-tests, 207
Hypothesis (see Hypothesis testing)
stress, 211–212
t-tests, 141

316
Index
Theorems:
Bayes, 113–119
central limit, 73–76, 176
Gauss-Markov, 206
Three-dimensional vectors, 170
Tilting, in yield curve, 185, 188
Time series models:
applications, 230–234
autoregression, 217–221
continuous models, 228–230
drift-diffusion model, 216–217
GARCH application, 230–232
interest rate models, 232–234
jump-diffusion model, 232
moving averages, 227–228
problems, 234–236
random walks, 215–216
stationarity, 223–227
variance and autocorrelation, 
222–223
Titan space probe, 34
Total sum of squares (TSS), 201
Transition matrices, 163–164
Transposition, 156, 162–163
Triangular distribution, 81–82
Triangular matrix, 156
Triangular PDF, 144, 151
TSS. See Total sum of squares (TSS)
t-statistic, 138, 201
t-tests, 141
Twisting, in yield curve, 185, 188
Two-dimensional vectors, 169, 170
Two-tailed hypothesis testing,  
140–141
U
Uncorrelated variables, addition of, 45
Uniform distribution, 61–63
United Kingdom rainfall example, 
226–227
Univariate regression. See also Linear 
regression analysis
evaluating the regression, 201, 206, 
207
multivariate regression and, 203–204
ordinary least squares, 197
overview of, 195–196
parameters, estimating, 200
Upper diagonal matrix, 156
Upward-sloping yield curve, 186
V
Value at risk (VaR):
application, 142–145
back-testing, 8, 145–148
binary numbers and, 250
expected shortfall, 150–151
hybrid VaR, 245–247
problems, 152–154
subadditivity, 148–149
Var, See Variance
VaR. See Value at risk (VaR)
Variables:
continuous random, 15–21
discrete random, 15
independent and identically 
distributed (see Independent and 
identically distributed (i.i.d.) 
variables)
random (see Random variables)
standardized, 41–42
uncorrelated, addition of, 45
Variance. See also Covariance
autocorrelation and, 222–223
decay factors and, 243–244
of parameter estimators, 57
portfolio variance and hedging, 44–47
sample, 39, 137
as second central moment, 47
standard deviation and, 39–41
Vasicek model, 233
Vectors:
coordinate, 174, 179
matrix notation and, 155–156
revisited, 169–172
rotation, 177–180
Vector spaces:
applications, 185–193
definition of, 253
dynamic term structure of interest 
rates, 185–191
global equity markets, structure of, 
191–193
orthogonality, 172–176
principal component analysis, 
181–185

Index
317
problems, 193–194
rotation, 177–180
three-dimensional vector, 170
two-dimensional vector, 169, 170
vectors revisited, 169–172
Volatility, 39
W
Weak stationarity, 223
Website, ix, 307
Weighted least squares, 244–245
Weiner process, 229
Wilmott, Paul, 245
Wilmott and Hua approach, 
CrashMetrics, 245
Window length, decay factors and, 237, 
238, 239, 242
Y
Yield curve, 185–187, 189, 190
Z
Zeno’s paradox, 9–12
Zero matrix, 162

