
This page intentionally left blank

Bayesian Logical Data Analysis for the Physical
Sciences
A Comparative Approach with MathematicaTM Support
Increasingly, researchers in many branches of science are coming into contact with
Bayesian statistics or Bayesian probability theory. By encompassing both inductive
and deductive logic, Bayesian analysis can improve model parameter estimates by
many orders of magnitude. It provides a simple and unified approach to all data
analysis problems, allowing the experimenter to assign probabilities to competing
hypotheses of interest, on the basis of the current state of knowledge.
This book provides a clear exposition of the underlying concepts with large
numbers of worked examples and problem sets. The book also discusses numerical
techniques for implementing the Bayesian calculations, including an introduction
to Markov chain Monte Carlo integration and linear and nonlinear least-squares
analysis seen from a Bayesian perspective. In addition, background material is
provided in appendices and supporting Mathematica notebooks are available from
www.cambridge.org/052184150X, providing an easy learning route for upper-
undergraduate, graduate students, or any serious researcher in physical sciences
or engineering.
PHIL GREGORY is Professor Emeritus at the Department of Physics and
Astronomy at the University of British Columbia.


Bayesian Logical Data Analysis for the Physical
Sciences
A Comparative Approach with MathematicaTM Support
P. C. Gregory
Department of Physics and Astronomy, University of British Columbia


Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo
Cambridge University Press
The Edinburgh Building, Cambridge , UK
First published in print format
-
----
-
----
© Cambridge University Press 2005
Disclaimer of warranty
We make no warranties, express or implied, that the programs contained in this volume
are free of error, or are consistent with any particular standard of merchantability, or
that they will meet your requirements for any particular application. They should not
be relied on for solving a problem whose incorrect solution could result in injury to a
person or loss of property. If you do use the programs in such a manner, it is at your own
risk. The authors and publisher disclaim all liability for direct or consequential
damages resulting from your use of the programs.
2005
Information on this title: www.cambridg e.org /9780521841504
This book is in copyright. Subject to statutory exception and to the provision of
relevant collective licensing agreements, no reproduction of any part may take place
without the written permission of Cambridge University Press.
-
---
-
---
Cambridge University Press has no responsibility for the persistence or accuracy of
s for external or third-party internet websites referred to in this book, and does not
guarantee that any content on such websites is, or will remain, accurate or appropriate.
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
hardback
eBook (NetLibrary)
eBook (NetLibrary)
hardback

Contents
Preface
page xiii
Software support
xv
Acknowledgements
xvii
1
Role of probability theory in science
1
1.1
Scientific inference
1
1.2
Inference requires a probability theory
2
1.2.1
The two rules for manipulating probabilities
4
1.3
Usual form of Bayes’ theorem
5
1.3.1
Discrete hypothesis space
5
1.3.2
Continuous hypothesis space
6
1.3.3
Bayes’ theorem – model of the learning process
7
1.3.4
Example of the use of Bayes’ theorem
8
1.4
Probability and frequency
10
1.4.1
Example: incorporating frequency information
11
1.5
Marginalization
12
1.6
The two basic problems in statistical inference
15
1.7
Advantages of the Bayesian approach
16
1.8
Problems
17
2
Probability theory as extended logic
21
2.1
Overview
21
2.2
Fundamentals of logic
21
2.2.1
Logical propositions
21
2.2.2
Compound propositions
22
2.2.3
Truth tables and Boolean algebra
22
2.2.4
Deductive inference
24
2.2.5
Inductive or plausible inference
25
2.3
Brief history
25
2.4
An adequate set of operations
26
2.4.1
Examination of a logic function
27
2.5
Operations for plausible inference
29
v

2.5.1
The desiderata of Bayesian probability theory
30
2.5.2
Development of the product rule
30
2.5.3
Development of sum rule
34
2.5.4
Qualitative properties of product
and sum rules
36
2.6
Uniqueness of the product and sum rules
37
2.7
Summary
39
2.8
Problems
39
3
The how-to of Bayesian inference
41
3.1
Overview
41
3.2
Basics
41
3.3
Parameter estimation
43
3.4
Nuisance parameters
45
3.5
Model comparison and Occam’s razor
45
3.6
Sample spectral line problem
50
3.6.1
Background information
50
3.7
Odds ratio
52
3.7.1
Choice of prior pðTjM1; IÞ
53
3.7.2
Calculation of pðDjM1; T; IÞ
55
3.7.3
Calculation of pðDjM2; IÞ
58
3.7.4
Odds, uniform prior
58
3.7.5
Odds, Jeffreys prior
58
3.8
Parameter estimation problem
59
3.8.1
Sensitivity of odds to Tmax
59
3.9
Lessons
61
3.10 Ignorance priors
63
3.11 Systematic errors
65
3.11.1 Systematic error example
66
3.12 Problems
69
4
Assigning probabilities
72
4.1
Introduction
72
4.2
Binomial distribution
72
4.2.1
Bernoulli’s law of large numbers
75
4.2.2
The gambler’s coin problem
75
4.2.3
Bayesian analysis of an opinion poll
77
4.3
Multinomial distribution
79
4.4
Can you really answer that question?
80
4.5
Logical versus causal connections
82
4.6
Exchangeable distributions
83
4.7
Poisson distribution
85
vi
Contents

4.7.1
Bayesian and frequentist comparison
87
4.8
Constructing likelihood functions
89
4.8.1
Deterministic model
90
4.8.2
Probabilistic model
91
4.9
Summary
93
4.10 Problems
94
5
Frequentist statistical inference
96
5.1
Overview
96
5.2
The concept of a random variable
96
5.3
Sampling theory
97
5.4
Probability distributions
98
5.5
Descriptive properties of distributions
100
5.5.1
Relative line shape measures for distributions
101
5.5.2
Standard random variable
102
5.5.3
Other measures of central tendency and dispersion
103
5.5.4
Median baseline subtraction
104
5.6
Moment generating functions
105
5.7
Some discrete probability distributions
107
5.7.1
Binomial distribution
107
5.7.2
The Poisson distribution
109
5.7.3
Negative binomial distribution
112
5.8
Continuous probability distributions
113
5.8.1
Normal distribution
113
5.8.2
Uniform distribution
116
5.8.3
Gamma distribution
116
5.8.4
Beta distribution
117
5.8.5
Negative exponential distribution
118
5.9
Central Limit Theorem
119
5.10 Bayesian demonstration of the Central Limit Theorem
120
5.11 Distribution of the sample mean
124
5.11.1 Signal averaging example
125
5.12 Transformation of a random variable
125
5.13 Random and pseudo-random numbers
127
5.13.1 Pseudo-random number generators
131
5.13.2 Tests for randomness
132
5.14 Summary
136
5.15 Problems
137
6
What is a statistic?
139
6.1
Introduction
139
6.2
The 2 distribution
141
Contents
vii

6.3
Sample variance S2
143
6.4
The Student’s t distribution
147
6.5
F distribution (F-test)
150
6.6
Confidence intervals
152
6.6.1
Variance 2 known
152
6.6.2
Confidence intervals for , unknown variance
156
6.6.3
Confidence intervals: difference of two means
158
6.6.4
Confidence intervals for 2
159
6.6.5
Confidence intervals: ratio of two variances
159
6.7
Summary
160
6.8
Problems
161
7
Frequentist hypothesis testing
162
7.1
Overview
162
7.2
Basic idea
162
7.2.1
Hypothesis testing with the 2 statistic
163
7.2.2
Hypothesis test on the difference of two means
167
7.2.3
One-sided and two-sided hypothesis tests
170
7.3
Are two distributions the same?
172
7.3.1
Pearson 2 goodness-of-fit test
173
7.3.2
Comparison of two-binned data sets
177
7.4
Problem with frequentist hypothesis testing
177
7.4.1
Bayesian resolution to optional stopping problem
179
7.5
Problems
181
8
Maximum entropy probabilities
184
8.1
Overview
184
8.2
The maximum entropy principle
185
8.3
Shannon’s theorem
186
8.4
Alternative justification of MaxEnt
187
8.5
Generalizing MaxEnt
190
8.5.1
Incorporating a prior
190
8.5.2
Continuous probability distributions
191
8.6
How to apply the MaxEnt principle
191
8.6.1
Lagrange multipliers of variational
calculus
191
8.7
MaxEnt distributions
192
8.7.1
General properties
192
8.7.2
Uniform distribution
194
8.7.3
Exponential distribution
195
8.7.4
Normal and truncated Gaussian distributions
197
8.7.5
Multivariate Gaussian distribution
202
viii
Contents

8.8
MaxEnt image reconstruction
203
8.8.1
The kangaroo justification
203
8.8.2
MaxEnt for uncertain constraints
206
8.9
Pixon multiresolution image reconstruction
208
8.10 Problems
211
9
Bayesian inference with Gaussian errors
212
9.1
Overview
212
9.2
Bayesian estimate of a mean
212
9.2.1
Mean: known noise 
213
9.2.2
Mean: known noise, unequal 
217
9.2.3
Mean: unknown noise 
218
9.2.4
Bayesian estimate of 
224
9.3
Is the signal variable?
227
9.4
Comparison of two independent samples
228
9.4.1
Do the samples differ?
230
9.4.2
How do the samples differ?
233
9.4.3
Results
233
9.4.4
The difference in means
236
9.4.5
Ratio of the standard deviations
237
9.4.6
Effect of the prior ranges
239
9.5
Summary
240
9.6
Problems
241
10 Linear model fitting (Gaussian errors)
243
10.1
Overview
243
10.2
Parameter estimation
244
10.2.1
Most probable amplitudes
249
10.2.2
More powerful matrix formulation
253
10.3
Regression analysis
256
10.4
The posterior is a Gaussian
257
10.4.1
Joint credible regions
260
10.5
Model parameter errors
264
10.5.1
Marginalization and the covariance matrix
264
10.5.2
Correlation coefficient
268
10.5.3
More on model parameter errors
272
10.6
Correlated data errors
273
10.7
Model comparison with Gaussian posteriors
275
10.8
Frequentist testing and errors
279
10.8.1
Other model comparison methods
281
10.9
Summary
283
10.10 Problems
284
Contents
ix

11 Nonlinear model fitting
287
11.1
Introduction
287
11.2
Asymptotic normal approximation
288
11.3
Laplacian approximations
291
11.3.1
Bayes factor
291
11.3.2
Marginal parameter posteriors
293
11.4
Finding the most probable parameters
294
11.4.1
Simulated annealing
296
11.4.2
Genetic algorithm
297
11.5
Iterative linearization
298
11.5.1
Levenberg–Marquardt method
300
11.5.2
Marquardt’s recipe
301
11.6
Mathematica example
302
11.6.1
Model comparison
304
11.6.2
Marginal and projected
distributions
306
11.7
Errors in both coordinates
307
11.8
Summary
309
11.9
Problems
309
12 Markov chain Monte Carlo
312
12.1
Overview
312
12.2
Metropolis–Hastings algorithm
313
12.3
Why does Metropolis–Hastings work?
319
12.4
Simulated tempering
321
12.5
Parallel tempering
321
12.6
Example
322
12.7
Model comparison
326
12.8
Towards an automated MCMC
330
12.9
Extrasolar planet example
331
12.9.1
Model probabilities
335
12.9.2
Results
337
12.10 MCMC robust summary statistic
342
12.11 Summary
346
12.12 Problems
349
13 Bayesian revolution in spectral analysis
352
13.1
Overview
352
13.2
New insights on the periodogram
352
13.2.1
How to compute pðfjD; IÞ
356
13.3
Strong prior signal model
358
13.4
No specific prior signal model
360
x
Contents

13.4.1
X-ray astronomy example
362
13.4.2
Radio astronomy example
363
13.5
Generalized Lomb–Scargle periodogram
365
13.5.1
Relationship to Lomb–Scargle
periodogram
367
13.5.2
Example
367
13.6
Non-uniform sampling
370
13.7
Problems
373
14 Bayesian inference with Poisson sampling
376
14.1
Overview
376
14.2
Infer a Poisson rate
377
14.2.1
Summary of posterior
378
14.3
Signal þ known background
379
14.4
Analysis of ON/OFF measurements
380
14.4.1
Estimating the source rate
381
14.4.2
Source detection question
384
14.5
Time-varying Poisson rate
386
14.6
Problems
388
Appendix A Singular value decomposition
389
Appendix B Discrete Fourier Transforms
392
B.1
Overview
392
B.2
Orthogonal and orthonormal functions
392
B.3
Fourier series and integral transform
394
B.3.1
Fourier series
395
B.3.2
Fourier transform
396
B.4
Convolution and correlation
398
B.4.1
Convolution theorem
399
B.4.2
Correlation theorem
400
B.4.3
Importance of convolution in science
401
B.5
Waveform sampling
403
B.6
Nyquist sampling theorem
404
B.6.1
Astronomy example
406
B.7
Discrete Fourier Transform
407
B.7.1
Graphical development
407
B.7.2
Mathematical development of the DFT
409
B.7.3
Inverse DFT
410
B.8
Applying the DFT
411
B.8.1
DFT as an approximate Fourier transform
411
B.8.2
Inverse discrete Fourier transform
413
Contents
xi

B.9
The Fast Fourier Transform
415
B.10 Discrete convolution and correlation
417
B.10.1 Deconvolving a noisy signal
418
B.10.2 Deconvolution with an optimal Weiner filter
420
B.10.3 Treatment of end effects by zero padding
421
B.11 Accurate amplitudes by zero padding
422
B.12 Power-spectrum estimation
424
B.12.1 Parseval’s theorem and power spectral density
424
B.12.2 Periodogram power-spectrum estimation
425
B.12.3 Correlation spectrum estimation
426
B.13 Discrete power spectral density estimation
428
B.13.1 Discrete form of Parseval’s theorem
428
B.13.2 One-sided discrete power spectral density
429
B.13.3 Variance of periodogram estimate
429
B.13.4 Yule’s stochastic spectrum estimation model
431
B.13.5 Reduction of periodogram variance
431
B.14 Problems
432
Appendix C Difference in two samples
434
C.1
Outline
434
C.2
Probabilities of the four hypotheses
434
C.2.1
Evaluation of pðC; SjD1; D2; IÞ
434
C.2.2
Evaluation of pðC; SjD1; D2; IÞ
436
C.2.3
Evaluation of pðC; SjD1; D2; IÞ
438
C.2.4
Evaluation of pðC; SjD1; D2; IÞ
439
C.3
The difference in the means
439
C.3.1
The two-sample problem
440
C.3.2
The Behrens–Fisher problem
441
C.4
The ratio of the standard deviations
442
C.4.1
Estimating the ratio, given the means are the same
442
C.4.2
Estimating the ratio, given the means are different
443
Appendix D Poisson ON/OFF details
445
D.1
Derivation of pðsjNon; IÞ
445
D.1.1
Evaluation of Num
446
D.1.2
Evaluation of Den
447
D.2
Derivation of the Bayes factor Bfsþb;bg
448
Appendix E Multivariate Gaussian from maximum entropy
450
References
455
Index
461
xii
Contents

Preface
The goal of science is to unlock nature’s secrets. This involves the identification and
understanding of nature’s observable structures or patterns. Our understanding
comes through the development of theoretical models which are capable of explaining
the existing observations as well as making testable predictions. The focus of this book
is on what happens at the interface between the predictions of scientific models and the
data from the latest experiments. The data are always limited in accuracy and
incomplete (we always want more), so we are unable to employ deductive reasoning
to prove or disprove the theory. How do we proceed to extend our theoretical frame-
work of understanding in the face of this? Fortunately, a variety of sophisticated
mathematical and computational approaches have been developed to help us through
this interface, these go under the general heading of statistical inference. Statistical
inference provides a means for assessing the plausibility of one or more competing
models, and estimating the model parameters and their uncertainties. These topics are
commonly referred to as ‘‘data analysis’’ in the jargon of most physicists.
We are currently in the throes of a major paradigm shift in our understanding of
statistical inference based on a powerful theory of extended logic. For historical
reasons, it is referred to as Bayesian Inference or Bayesian Probability Theory. To
get a taste of how significant this development is, consider the following: probabilities
are commonly quantified by a real number between 0 and 1. The end-points, corre-
sponding to absolutely false and absolutely true, are simply the extreme limits of this
infinity of real numbers. Deductive logic, which is based on axiomatic knowledge,
corresponds to these two extremes of 0 and 1. Ask any mathematician or physicist how
important deductive logic is to their discipline! Now try to imagine what you might
achieve with a theory of extended logic that encompassed the whole range from 0 to 1.
This is exactly what is needed in science and real life where we never know anything is
absolutely true or false. Of course, the field of probability has been around for years,
but what is new is the appreciation that the rules of probability are not merely rules for
manipulating random variables. They are now recognized as uniquely valid principles
of logic, for conducting inference about any proposition or hypothesis of interest.
Ordinary deductive logic is just a special case in the idealized limit of complete
information. The reader should be warned that most books on Bayesian statistics
xiii

do not make the connection between probability theory and logic. This connection,
which is captured in the book by physicist E. T. Jaynes, Probability Theory – The Logic
of Science,1 is particularly appealing because of the unifying principles it provides for
scientific reasoning.
What are the important consequences of this development? We are only beginning
to see the tip of the iceberg. Already we have seen that for data with a high signal-to-
noise ratio, a Bayesian analysis can frequently yield many orders of magnitude
improvement in model parameter estimation, through the incorporation of relevant
prior information about the signal model. For several dramatic demonstrations of this
point, have a look at the first four sections of Chapter 13. It also provides a more
powerful way of assessing competing theories at the forefront of science by quantify-
ing Occam’s razor, and sheds a new light on systematic errors (e.g., Section 3.11). For
some problems, a Bayesian analysis may simply lead to a familiar statistic. Even in this
situation it often provides a powerful new insight concerning the interpretation of the
statistic. But most importantly, Bayesian analysis provides an elegantly simple and
rational approach for answering any scientific question for a given state of
information.
This textbook is based on a measurement theory course which is aimed at providing
first year graduate students in the physical sciences with the tools to help them design,
simulate and analyze experimental data. The material is presented at a mathematical
level that should make it accessible to physical science undergraduates in their final
two years. Each chapter begins with an overview and most end with a summary. The
book contains a large number of problems, worked examples and 132 illustrations.
The Bayesian paradigm is becoming very visible at international meetings of
physicists and astronomers (e.g., Statistical Challenges in Modern Astronomy III,
edited by E. D. Feigelson and G. J. Babu, 2002). However, the majority of scientists
are still not at home with the topic and much of the current scientific literature still
employs the conventional ‘‘frequentist’’ statistical paradigm. This book is an attempt
to help new students to make the transition while at the same time exposing them in
Chapters 5, 6, and 7 to some of the essential ideas of the frequentist statistical
paradigm that will allow them to comprehend much of the current and earlier
literature and interface with his or her research supervisor. This also provides an
opportunity to compare and contrast the two different approaches to statistical
inference. No previous background in statistics is required; in fact, Chapter 6 is
entitled ‘‘What is a statistic?’’ For the reader seeking an abridged version of
Bayesian inference, Chapter 3 provides a stand-alone introduction on the ‘‘How-to
of Bayesian inference.’’
1 Early versions of this much celebrated work by Jaynes have been in circulation since at least 1988. The book was finally
submitted for publication in 2002, four years after his death, through the efforts of his former student G. L. Bretthorst.
The book is published by Cambridge University Press (Jaynes, 2003, edited by G. L. Bretthorst).
xiv
Preface

The book begins with a look at the role of statistical inference in the scientific
method and the fundamental ideas behind Bayesian Probability Theory (BPT). We
next consider how to encode a given state of information into the form of a probability
distribution, for use as a prior or likelihood function in Bayes’ theorem. We demon-
strate why the Gaussian distribution arises in nature so frequently from a study of the
Central Limit Theorem and gain powerful new insight into the role of the Gaussian
distribution in data analysis from the Maximum Entropy Principle. We also learn how
a quantified Occam’s razor is automatically incorporated into any Bayesian model
comparison and come to understand it at a very fundamental level.
Starting from Bayes’ theorem, we learn how to obtain unique and optimal solutions
to any well-posed inference problem. With this as a foundation, many common
analysis techniques such as linear and nonlinear model fitting are developed and
their limitations appreciated. The Bayesian solution to a problem is often very simple
in principle, however, the calculations require integrals over the model parameter
space which can be very time consuming if there are a large number of parameters.
Fortunately, the last decade has seen remarkable developments in practical algorithms
for performing Bayesian calculations. Chapter 12 provides an introduction to the very
powerful Markov chain Monte Carlo (MCMC) algorithms, and demonstrates an
application of a new automated MCMC algorithm to the detection of extrasolar planets.
Although the primary emphasis is on the role of probability theory in inference,
there is also focus on an understanding of how to simulate the measurement process.
This includes learning how to generate pseudo-random numbers with an arbitrary
distribution (in Chapter 5). Any linear measurement process can be modeled as a
convolution of nature’s signal with the measurement point-spread-function, a process
most easily dealt with using the convolution theorem of Fourier analysis. Because of
the importance of this material, I have included Appendix B on the Discrete Fourier
Transform (DFT), the Fast Fourier Transform (FFT), convolution and Weiner
filtering. We consider the limitations of the DFT and learn about the need to zero
pad in convolution to avoid aliasing. From the Nyquist Sampling Theorem we learn
how to minimally sample the signal without losing information and what prefiltering
of the signal is required to prevent aliasing.
In Chapter 13, we apply probability theory to spectral analysis problems and gain a
new insight into the role of the DFT, and explore a Bayesian revolution in spectral
analysis. We also learn that with non-uniform data sampling, the effective bandwidth
(the largest spectral window free of aliases) can be made much wider than for uniform
sampling. The final chapter is devoted to Bayesian inference when our prior informa-
tion leads us to model the probability of the data with a Poisson distribution.
Software support
The material in this book is designed to empower the reader in his or her search to
unlock nature’s secrets. To do this efficiently, one needs both an understanding of the
principles of extended logic, and an efficient computing environment for visualizing
Preface
xv

and mathematically manipulating the data. All of the course assignments involve the
use of a computer. An increasing number of my students are exploiting the power of
integrated platforms for programming, symbolic mathematical computations, and
visualizing tools. Since the majority of my students opted to use Mathematica for their
assignments, I adopted Mathematica as a default computing environment for the
course. There are a number of examples in this book employing Mathematica com-
mands, although the book has been designed to be complete without reference to these
Mathematica examples. In addition, I have developed a Mathematica tutorial to
support this book, specifically intended to help students and professional scientists
with no previous experience with Mathematica to efficiently exploit it for data analysis
problems. This tutorial also contains many worked examples and is available for
download from http://www.cambridge.org/052184150X.
In any scientific endeavor, a great deal of effort is expended in graphically displaying
the results for presentation and publication. To simplify this aspect of the problem, the
Mathematica tutorial provides a large range of easy to use templates for publication-
quality plotting.
It used to be the case that interpretative languages were not as useful as compiled
languages such as C and Fortran for numerically intensive computations. The last few
years have seen dramatic improvements in the speed of Mathematica. Wolfram
Research now claims2 that for most of Mathematica’s numerical analysis function-
ality (e.g., data analysis, matrix operations, numerical differential equation solvers,
and graphics) Mathematica 5 operates on a par3 with Fortran or MATLAB code. In
the author’s experience, the time required to develop and test programs with
Mathematica is approximately 20 times shorter than the time required to write and
debug the same program in Fortran or C, so the efficiency gain is truly remarkable.
2 http://www.wolfram.com/products/mathematica/; newin5/performance/numericallinear.html.
3 Look up Mathematica gigaNumerics on the Web.
xvi
Preface

Acknowledgements
Most of the Bayesian material presented in this book I have learned from the works of
Ed Jaynes, Larry Bretthorst, Tom Loredo, Steve Gull, John Skilling, Myron Tribus,
Devinder Sivia, Jim Berger, and many others from the international community
devoted to the study of Bayesian inference. On a personal note, I encountered
Bayesian inference one day in 1989 when I found a monograph lying on the floor of
the men’s washroom entitled Bayesian Spectrum Analysis and Parameter Estimation,
by Larry Bretthorst. I was so enthralled with the book that I didn’t even try to find out
whose it was for several weeks. Larry’s book led me to the work of his Ph.D. super-
visor, Edwin T. Jaynes. I became hooked on this simple, elegant and powerful
approach to scientific inference. For me, it was a breath of fresh air providing a logical
framework for tackling any statistical inference question in an optimal way, in
contrast to the recipe or cookbook approach of conventional statistical analysis.
I would also like to acknowledge the proof reading and suggestions made by many
students who were exposed to early versions of this manuscript, in particular, Iva
Cheung for her very careful proof reading of the final draft. Finally, I am really
grateful to my partner, Jackie, and our children, Rene, Neil, Erin, Melanie, Ted, and
Laura, for their encouragement over the many years it took to complete this book.
xvii


1
Role of probability theory in science
1.1 Scientific inference
This book is primarily concerned with the philosophy and practice of inferring the
laws of nature from experimental data and prior information. The role of inference in
the larger framework of the scientific method is illustrated in Figure 1.1.
In this simple model, the scientific method is depicted as a loop which is entered
through initial observations of nature, followed by the construction of testable
hypotheses or theories as to the working of nature, which give rise to the prediction
of other properties to be tested by further experimentation or observation. The new
data lead to the refinement of our current theories, and/or development of new
theories, and the process continues.
The role of deductive inference1 in this process, especially with regard to deriving
the testable predictions of a theory, has long been recognized. Of course, any theory
makes certain assumptions about nature which are assumed to be true and these
assumptions form the axioms of the deductive inference process. The terms deductive
inference and deductive reasoning are considered equivalent in this book. For exam-
ple, Einstein’s Special Theory of Relativity rests on two important assumptions;
namely, that the vacuum speed of light is a constant in all inertial reference frames
and that the laws of nature have the same form in all inertial frames.
Unfortunately, experimental tests of theoretical predictions do not provide simple
yes or no answers. Our state of knowledge is always incomplete, there are always more
experiments that could be done and the measurements are limited in their accuracy.
Statistical inference is the process of inferring the truth of our theories of nature on the
basis of the incomplete information. In science we often make progress by starting
with simple models. Usually nature is more complicated and we learn in what direc-
tion to modify our theories from the differences between the model predictions and the
measurements. It is much like peeling off layers of an onion. At any stage in this
iterative process, the still hidden layers give rise to differences from the model predic-
tions which guide the next step.
1 Reasoning from one proposition to another using the strong syllogisms of logic (see Section 2.2.4).
1

1.2 Inference requires a probability theory
In science, the available information is always incomplete so our knowledge of nature is
necessarily probabilistic. Two different approaches based on different definitions of
probability will be considered. In conventional statistics, the probability of an event is
identified with the long-run relative frequency of occurrence of the event. This is
commonly referred to as the ‘‘frequentist’’ view. In this approach, probabilities are
restricted to a discussion of random variables, quantities that can meaningfully vary
throughout a series of repeated experiments. Two examples are:
1. A measured quantity which contains random errors.
2. Time intervals between successive radioactive decays.
The role of random variables in frequentist statistics is detailed in Section 5.2.
In recent years, a new perception of probability has arisen in recognition that the
mathematical rules of probability are not merely rules for calculating frequencies of
random variables. They are now recognized as uniquely valid principles of logic for
conducting inference about any proposition or hypothesis of interest. This more
powerful viewpoint, ‘‘Probability Theory as Logic,’’ or Bayesian probability theory,
is playing an increasingly important role in physics and astronomy. The Bayesian
approach allows us to directly compute the probability of any particular theory or
particular value of a model parameter, issues that the conventional statistical
approach can attack only indirectly through the use of a random variable statistic.
In this book, I adopt the approach which exposes probability theory as an extended
theory of logic following the lead of E. T. Jaynes in his book,2 Probability Theory –
Testable
Hypothesis
(theory)
Observations
Data
Predictions
Hypothesis testing
Parameter estimation
St
ati
sti
ca
l (
pla
us
ibl
e)
Inf
ere
nc
e
De
du
cti
ve
In
fe
re
nc
e
Figure 1.1 The scientific method.
2 The book was finally submitted for publication four years after his death, through the efforts of his former student
G. Larry Bretthorst.
2
Role of probability theory in science

The Logic of Science (Jaynes, 2003). The two approaches employ different definitions
of probability which must be carefully understood to avoid confusion.
The two different approaches to statistical inference are outlined in Table 1.1
together with their underlying definition of probability. In this book, we will be
primarily concerned with the Bayesian approach. However, since much of the current
scientific culture is based on ‘‘frequentist’’ statistical inference, some background in
this approach is useful.
The frequentist definition contains the term ‘‘identical repeats.’’ Of course the
repeated experiments can never be identical in all respects. The Bayesian definition
of probability involves the rather vague sounding term ‘‘plausibility,’’ which must be
given a precise meaning (see Chapter 2) for the theory to provide quantitative results.
In Bayesian inference, a probability distribution is an encoding of our uncertainty
about some model parameter or set of competing theories, based on our current state
of information. The approach taken to achieve an operational definition of prob-
ability, together with consistent rules for manipulating probabilities, is discussed in
the next section and details are given in Chapter 2.
In this book, we will adopt the plausibility definition3 of probability given in
Table 1.1 and follow the approach pioneered by E. T. Jaynes that provides for a
unified picture of both deductive and inductive logic. In addition, Jaynes brought
Table 1.1 Frequentist and Bayesian approaches to probability.
Approach
Probability definition
FREQUENTIST STATISTICAL
INFERENCE
pðAÞ ¼ long-run relative frequency with which
A occurs in identical repeats of an
experiment.
‘‘A’’ restricted to propositions about
random variables.
BAYESIAN INFERENCE
pðAjBÞ ¼ a real number measure of the
plausibility of a proposition/hypothesis A,
given (conditional on) the truth of the
information represented by proposition B.
‘‘A’’ can be any logical proposition, not
restricted to propositions about random
variables.
3 Even within the Bayesian statistical literature, other definitions of probability exist. An alternative definition commonly
employed is the following: ‘‘probability is a measure of the degree of belief that any well-defined proposition (an event)
will turn out to be true.’’ The events are still random variables, but the term is generalized so it can refer to the
distribution of results from repeated measurements, or, to possible values of a physical parameter, depending on the
circumstances. The concept of a coherent bet (e.g., D’Agostini, 1999) is often used to define the value of probability in
an operational way. In practice, the final conditional posteriors are the same as those obtained from the extended logic
approach adopted in this book.
1.2 Inference requires a probability theory
3

great clarity to the debate on objectivity and subjectivity with the statement, ‘‘the only
thing objectivity requires of a scientific approach is that experimenters with the same
state of knowledge reach the same conclusion.’’ More on this later.
1.2.1 The two rules for manipulating probabilities
It is now routine to build or program a computer to execute deductive logic. The goal
of Bayesian probability theory as employed in this book is to provide an extension of
logic to handle situations where we have incomplete information so we may arrive at
the relative probabilities of competing hypotheses for a given state of information.
Cox and Jaynes showed that the desired extension can be arrived at uniquely from
three ‘‘desiderata’’ which will be introduced in Section 2.5.1. They are called ‘‘desiderata’’
rather than axioms because they do not assert that anything is ‘‘true,’’ but only state
desirable goals of a theory of plausible inference.
The operations for manipulating probabilities that follow from the desiderata are
the sum and product rules. Together with the Bayesian definition of probability, they
provide the desired extension to logic to handle the common situation of incomplete
information. We will simply state these rules here and leave their derivation together
with a precise operational definition of probability to the next chapter.
Sum Rule: pðAjBÞ þ pðAjBÞ ¼ 1
(1:1)
Product Rule: pðA; BjCÞ ¼ pðAjCÞpðBjA; CÞ
¼ pðBjCÞpðAjB; CÞ;
(1:2)
where the symbol A stands for a proposition which asserts that something is true. The
symbol B is a proposition asserting that something else is true, and similarly, C stands
for another proposition. Two symbols separated by a comma represent a compound
proposition which asserts that both propositions are true. Thus A; B indicates that
both propositions A and B are true and pðA; BjCÞ is commonly referred to as the joint
probability. Any proposition to the right of the vertical bar j is assumed to be true.
Thus when we write pðAjBÞ, we mean the probability of the truth of proposition A,
given (conditional on) the truth of the information represented by proposition B.
Examples of propositions:
A  ‘‘The newly discovered radio astronomy object is a galaxy.’’
B  ‘‘The measured redshift of the object is 0:150  0:005.’’
A  ‘‘Theory X is correct.’’
A  ‘‘Theory X is not correct.’’
A  ‘‘The frequency of the signal is between f and f þ df.’’
We will have much more to say about propositions in the next chapter.
4
Role of probability theory in science

Bayes’ theorem follows directly from the product rule (a rearrangement of the two
right sides of the equation):
pðAjB; CÞ ¼ pðAjCÞpðBjA; CÞ
pðBjCÞ
:
(1:3)
Another version of the sum rule can be derived (see Equation (2.23)) from the product
and sum rules above:
Extended Sum Rule: pðA þ BjCÞ ¼ pðAjCÞ þ pðBjCÞ  pðA; BjCÞ;
(1:4)
where A þ B  proposition A is true or B is true or both are true. If propositions A and
B are mutually exclusive – only one can be true – then Equation (1.4) becomes
pðA þ BjCÞ ¼ pðAjCÞ þ pðBjCÞ:
(1:5)
1.3 Usual form of Bayes’ theorem
pðHijD; IÞ ¼ pðHijIÞpðDjHi; IÞ
pðDjIÞ
;
(1:6)
where Hi  proposition asserting the truth of a hypothesis of interest
I  proposition representing our prior information
D  proposition representing data
pðDjHi; IÞ ¼ probability of obtaining data D; if Hi and I are true
ðalso called the likelihood function LðHiÞÞ
pðHijIÞ ¼ prior probability of hypothesis
pðHijD; IÞ ¼ posterior probability of Hi
pðDjIÞ ¼
X
i pðHijIÞpðDjHi; IÞ
ðnormalization factor which ensures
X
i pðHijD; IÞ ¼ 1Þ:
1.3.1 Discrete hypothesis space
In Bayesian inference, we are interested in assigning probabilities to a set of competing
hypotheses perhaps concerning some aspect of nature that we are studying. This set
of competing hypotheses is called the hypothesis space. For example, a problem
of current interest to astronomers is whether the expansion of the universe is acceler-
ating or decelerating. In this case, we would be dealing with a discrete hypothesis
1.3 Usual form of Bayes’ theorem
5

space4 consisting of H1 ( accelerating) and H2 ( decelerating). For a discrete
hypothesis space, pðHijD; IÞ is called a probability distribution. Our posterior prob-
abilities for H1 and H2 satisfy the condition that
X
2
i ¼ 1
pðHijD; IÞ ¼ 1:
(1:7)
1.3.2 Continuous hypothesis space
In another type of problem we might be dealing with a hypothesis space that is
continuous. This can be considered as the limiting case of an arbitrarily large number
of discrete propositions.5 For example, we have strong evidence from the measured
velocities and distances of galaxies that we live in an expanding universe. Astronomers
are continually seeking to refine the value of Hubble’s constant, H0, which relates the
recession velocity of a galaxy to its distance. Estimating H0 is called a parameter
estimation problem and in this case, our hypothesis space of interest is continuous.
In this case, the proposition H0 asserts that the true value of Hubble’s constant is in the
interval h to h þ dh. The truth of the proposition can be represented by pðH0jD; IÞdH,
where pðH0jD; IÞ is a probability density function (PDF). The probability density
function is defined by
pðH0jD; IÞ ¼ lim
h!0
pðh  H0 < h þ hjD; IÞ
h
:
(1:8)
Box 1.1 Note about notation
The term ‘‘PDF’’ is also a common abbreviation for probability distribution
function, which can pertain to discrete or continuous sets of probabilities. This
term is particularly useful when dealing with a mixture of discrete and continuous
parameters.
We will use the same symbol, pð. . .Þ, for probabilities and PDFs; the nature of
the argument will identify which use is intended. To arrive at a final numerical
answer for the probability or PDF of interest, we eventually need to convert the
terms in Bayes’ theorem into algebraic expressions, but these expressions can
become very complicated in appearance. It is useful to delay this step until the last
possible moment.
4 Of course, nothing guarantees that future information will not indicate that the correct hypothesis is outside the current
working hypothesis space. With this new information, we might be interested in an expanded hypothesis space.
5 In Jaynes (2003), there is a clear warning that difficulties can arise if we are not careful in carrying out this limiting
procedure explicitly. This is often the underlying cause of so-called paradoxes of probability theory.
6
Role of probability theory in science

Let W be a proposition asserting that the numerical value of H0 lies in the range
a to b. Then
pðWjD; IÞ ¼
Z b
a
pðH0jD; IÞdH0:
(1:9)
In the continuum limit, the normalization condition of Equation (1.7) becomes
Z
H
pðHjD; IÞdH ¼ 1;
(1:10)
where H designates the range of integration corresponding to the hypothesis space
of interest.
We can also talk about a joint probability distribution, pðX; YjD; IÞ, in which both X
and Y are continuous, or, one is continuous and the other is discrete. If both are
continuous, then pðX; YjD; IÞ is interpreted to mean
pðX; YjD; IÞ ¼
lim
x;y!0
pðx  X < x þ x; y  Y < y þ yjD; IÞ
x y
:
(1:11)
In a well-posed problem, the prior information defines our hypothesis space, the
means for computing pðHijIÞ, and the likelihood function given some data D.
1.3.3 Bayes’ theorem – model of the learning process
Bayes’ theorem provides a model for inductive inference or the learning process. In the
parameter estimation problem of the previous section, H0 is a continuous hypothesis
space. Hubble’s constant has some definite value, but because of our limited state of
knowledge, we cannot be too precise about what that value is. In all Bayesian inference
problems, we proceed in the same way. We start by encoding our prior state of
knowledge into a prior probability distribution, pðH0jIÞ (in this case a density distribu-
tion). We will see a very simple example of how to do this in Section 1.4.1, and many
more examples in subsequent chapters. If our prior information is very vague then
pðH0jIÞ will be very broad, spanning a wide range of possible values of the parameter.
It is important to realize that a Bayesian PDF is a measure of our state of knowledge
(i.e., ignorance) of the value of the parameter. The actual value of the parameter is not
distributed over this range; it has some definite value. This can sometimes be a serious
point of confusion, because, in frequentist statistics, the argument of a probability is a
random variable, a quantity that can meaningfully take on different values, and these
values correspond to possible outcomes of experiments.
We then acquire some new data, D1. Bayes’ theorem provides a means for combining
what the data have to say about the parameter, through the likelihood function, with
our prior, to arrive at a posterior probability density, pðH0jD1; IÞ, for the parameter.
pðH0jD1; IÞ / pðH0jI0ÞpðD1jH0; IÞ:
(1:12)
1.3 Usual form of Bayes’ theorem
7

Two extreme cases are shown in Figure 1.2. In the first, panel (a), the prior is
much broader than the likelihood. In this case, the posterior PDF is determined
entirely by the new data. In the second extreme, panel (b), the new data are much
less selective than our prior information and hence the posterior is essentially the
prior.
Now suppose we acquire more data represented by proposition D2. We can again
apply Bayes’ theorem to compute a posterior that reflects our new state of knowledge
about the parameter. This time our new prior, I0, is the posterior derived from D1; I,
i.e., I0 ¼ D1; I. The new posterior is given by
pðH0jD2; I0Þ / pðH0jI0ÞpðD2jH0; I0Þ:
(1:13)
1.3.4 Example of the use of Bayes’ theorem
Here we analyze a simple model comparison problem using Bayes’ theorem. We start
by stating our prior information, I, and the new data, D.
I stands for:
a) Model M1 predicts a star’s distance, d1 ¼ 100 light years (ly).
b) Model M2 predicts a star’s distance, d2 ¼ 200 ly.
c) The uncertainty, e, in distance measurements is described by a Gaussian distribution of
the form
Parameter H0
(a)
Posterior
p(H0|D,M1,I )
Likelihood
p(D |H0,M1,I )
Prior
p(H0|M1,I )
Parameter H0
(b)
Posterior
p(H0|D,M1,I )
Prior
p(H0|M1,I )
Likelihood
p(D |H0,M1,I )
Figure 1.2 Bayes’ theorem provides a model of the inductive learning process. The posterior
PDF (lower graphs) is proportional to the product of the prior PDF and the likelihood function
(upper graphs). This figure illustrates two extreme cases: (a) the prior much broader than
likelihood, and (b) likelihood much broader than prior.
8
Role of probability theory in science

pðejIÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p

exp  e2
22


;
where  ¼ 40 ly.
d) There is no current basis for preferring M1 over M2 so we set pðM1jIÞ ¼ pðM2jIÞ ¼ 0:5.
D  ‘‘The measured distance d ¼ 120 ly.’’
The prior information tells us that the hypothesis space of interest consists of
models (hypotheses) M1 and M2. We proceed by writing down Bayes’ theorem for
each hypothesis, e.g.,
pðM1jD; IÞ ¼ pðM1jIÞpðDjM1; IÞ
pðDjIÞ
;
(1:14)
pðM2jD; IÞ ¼ pðM2jIÞpðDjM2; IÞ
pðDjIÞ
:
(1:15)
Since we are interested in comparing the two models, we will compute the odds ratio,
equal to the ratio of the posterior probabilities of the two models. We will abbreviate
the odds ratio of model M1 to model M2 by the symbol O12.
O12 ¼ pðM1jD; IÞ
pðM2jD; IÞ ¼ pðM1jIÞ
pðM2jIÞ
pðDjM1; IÞ
pðDjM2; IÞ ¼ pðDjM1; IÞ
pðDjM2; IÞ :
(1:16)
The two prior probabilities cancel because they are equal and so does pðDjIÞ since it is
common to both models. To evaluate the likelihood pðDjM1; IÞ, we note that in this
case, we are assuming M1 is true. That being the case, the only reason the measured d
can differ from the prediction d1 is because of measurement uncertainties, e. We can
thus write d ¼ d1 þ e or e ¼ d  d1. Since d1 is determined by the model, it is certain,
and so the probability,6 pðDjM1; IÞ, of obtaining the measured distance is equal to the
probability of the error. Thus we can write
pðDjM1; IÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p

exp  ðd  d1Þ2
22
 
!
¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p
40
exp  ð120  100Þ2
2ð40Þ2
 
!
¼ 0:00880:
(1:17)
Similarly we can write for model M2
6 See Section 4.8 for a more detailed treatment of this point.
1.3 Usual form of Bayes’ theorem
9

pðDjM2; IÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p

exp  ðd  d2Þ2
22
 
!
¼
1
ﬃﬃﬃﬃﬃﬃ
2 p
p
40
exp  ð120  200Þ2
2ð40Þ2
 
!
¼ 0:00135:
(1:18)
The evaluation of Equations (1.17) and (1.18) is depicted graphically in Figure 1.3.
The relative likelihood of the two models is proportional to the heights of the two
Gaussian probability distributions at the location of the measured distance.
Substituting into Equation (1.16), we obtain an odds ratio of 6.52 in favor of
model M1.
1.4 Probability and frequency
In Bayesian terminology, a probability is a representation of our state of knowledge
of the real world. A frequency is a factual property of the real world that we measure
or estimate.7 One of the great strengths of Bayesian inference is the ability to
incorporate relevant prior information in the analysis. As a consequence, some
critics have discounted the approach on the grounds that the conclusions are sub-
jective and there has been considerable confusion on that subject. We certainly
expect that when scientists from different laboratories come together at an inter-
national meeting, their state of knowledge about any particular topic will differ, and
as such, they may have arrived at different conclusions. It is important to recognize
0
50
100
150
200
250
300
350
Distance (ly)
0
Probability density
d1
dmeasured
d2
Figure 1.3 Graphical depiction of the evaluation of the likelihood functions, pðDjM1; IÞ and
pðDjM2; IÞ.
7 For example, consider a sample of 400 people attending a conference. Each person sampled has many characteristics or
attributes including sex and eye color. Suppose 56 are found to be female. Based on this sample, the frequency of
occurrence of the attribute female is 56=400  14%.
10
Role of probability theory in science

that the only thing objectivity requires of a scientific approach is that experimenters
with the same state of knowledge reach the same conclusion. Achieving consensus
amongst different experimenters is greatly aided by the requirement to specify how
relevant prior information has been encoded in the analysis. In Bayesian inference, we
can readily incorporate frequency information using Bayes’ theorem and by treating it
as data. In general, probabilities change when we change our state of knowledge;
frequencies do not.
1.4.1 Example: incorporating frequency information
A 1996 newspaper article reported that doctors in Toronto were concerned about
a company selling an unapproved mail-order HIV saliva test. According to labora-
tory tests, the false positive rate for this test was 2.3% and the false negative rate
was 1.4% (i.e., 98.6% reliable based on testing of people who actually have the
disease).
In this example, suppose a new deadly disease is discovered for which there is no
known cause but a saliva test is available with the above specifications. We will refer to
this disease by the abbreviation UD, for unknown disease. You have no reason to
suspect you have UD but decide to take the test anyway and test positive. What is the
probability that you really have the disease? Here is a Bayesian analysis of this
situation. For the purpose of this analysis, we will assume that the incidence of the
disease in a random sample of the region is 1:10 000.
Let H  ‘‘You have UD.’’
H  ‘‘You do not have UD.’’
D1  ‘‘You test positive for UD.’’
I1  ‘‘No known cause for the UD,
pðD1jH; I1Þ ¼ 0:986;
pðD1jH; I1Þ ¼ 0:023;
incidence of UD in the population is 1:104:’’
The starting point for any Bayesian analysis is to write down Bayes’ theorem.
pðHjD1; I1Þ ¼ pðHjI1ÞpðD1jH; I1Þ
pðD1jI1Þ
:
(1:19)
Since pðD1jI1Þ is a normalization factor, which ensures P
i pðHijD1; I1Þ ¼ 1, we
can write
pðD1jI1Þ ¼ pðHjI1ÞpðD1jH; I1Þ þ pðHjI1ÞpðD1jH; I1Þ:
(1:20)
1.4 Probability and frequency
11

In words, this latter equation stands for
prob. of a
þ test


¼
prob. you
have UD



prob. of a þ
test when you
have UD
0
B
@
1
C
A
þ
prob. you
don’t have UD



prob. of a þ
test when you
don’t have UD
0
B
@
1
C
A
¼
incidence of
UD in population


 ðreliability of testÞ
þ
1  incidence
of UD


 ðfalse positive rateÞ
pðHjD1; I1Þ ¼
104  0:986
104  0:986 þ 0:9999  0:023 ¼ 0:0042:
(1:21)
Thus, the probability you have the disease is 0.4% (not 98.6%).
Question: How would the conclusion change if the false positive rate of the test were
reduced to 0.5%?
Suppose you now have a doctor examine you and obtain new independent data D2,
perhaps from a blood test.
I2 ¼ New state of knowledge ¼ D1; I1 ) pðHjD2; I2Þ ¼ pðHjI2ÞpðD2jH; I2Þ
pðD2jI2Þ
;
where pðHjI2Þ ¼ pðHjD1; I1Þ.
1.5 Marginalization
In this section, we briefly introduce marginalization, but we will learn about important
subtleties to this operation in later chapters. Consider the following parameter
estimation problem. We have acquired some data, D, which our prior information,
I, indicates will contain a periodic signal. Our signal model has two continuous
parameters – an angular frequency, !, and an amplitude, A. We want to focus on
the implications of the data for the !, independent of the signal’s amplitude, A.
We can write the joint probability8 of ! and A given data D and prior information I
as pð!; AjD; IÞ. In this case !, A is a compound proposition asserting that the two
8 Since a parameter of a model is not a random variable, the frequentist approach is denied the concept of the probability
of a parameter.
12
Role of probability theory in science

propositions are true. How do we obtain an expression for the probability of the
proposition !? We eliminate the uninteresting parameter A by marginalization. How
do we do this?
For simplicity, we will start by assuming that the parameter A is discrete. In this
case, A can only take on the values A1 or A2 or A3, etc. Since we are assuming the
model to be true, the proposition represented by A1 þ A2 þ A3 þ   , where the þ
stands for the Boolean ‘or’, must be true for some value of Ai and hence,
pðA1 þ A2 þ A3 þ    jIÞ ¼ 1:
(1:22)
Now !; ½A1 þ A2 þ A3 þ    is a compound proposition which asserts that both !
and ½A1 þ A2 þ A3 þ    are true. The probability that this compound proposition is
true is represented by pð!; ½A1 þ A2 þ A3 þ   jD; IÞ. We use the product rule to
expand the probability of this compound proposition.
pð!; ½A1 þ A2 þ A3 þ   jD; IÞ ¼ pð½A1 þ A2 þ A3 þ   jD; IÞ
 pð!j½A1 þ A2 þ A3 þ   ; D; IÞ
¼ 1  pð!jD; IÞ:
(1:23)
The second line of the above equation has the quantity ½A1 þ A2 þ A3 þ   ; D; I to
the right of the vertical bar which should be read as assuming the truth of
½A1 þ A2 þ A3 þ   ; D; I. Now ½A1 þ A2 þ A3 þ   ; D; I is a compound proposition
asserting that all three propositions are true. Since proposition ½A1 þ A2 þ A3 þ   
is given as true by our prior information, I, knowledge of its truth is already
contained in proposition I. Thus, we can simplify the expression by replacing
pð!j½A1 þ A2 þ A3 þ   ; D; IÞ by pð!jD; IÞ.
Rearranging Equation (1.23), we get
pð!jD; IÞ ¼ pð!; ½A1 þ A2 þ A3 þ   jD; IÞ:
(1:24)
The left hand side of the equation is the probability we are seeking, but we are not
finished with the right hand side. Now we do a simple expansion of the right hand side
of Equation (1.24) by multiplying out the two propositions ! and ½A1 þ A2 þ A3 þ   
using a Boolean algebra relation which is discussed in more detail in Chapter 2.
pð!; ½A1 þ A2 þ A3 þ   jD; IÞ ¼ pðf!; A1g þ f!; A2g þ f!; A3g þ    jD; IÞ:
(1:25)
The term f!; A1g þ f!; A2g þ f!; A3g þ    is a proposition which asserts that !; A1
is true, or, !; A2 is true, or, !; A3 is true, etc. We have surrounded each of the !; Ai
terms by curly brackets to help with the interpretation, but normally they are not
required because the logical conjunction operation designated by a comma between
two propositions takes precedence over the logical ‘‘or’’ operation designated by
the þ sign.
1.5 Marginalization
13

The extended sum rule, given by Equation (1.5), says that the probability of the sum
of two mutually exclusive (only one can be true) propositions is the sum of their
individual probabilities. Since the compound propositions !; Ai for different i are
mutually exclusive, we can rewrite Equation (1.25) as
pð!; ½A1 þ A2 þ A3 þ   jD; IÞ ¼ pð!; A1jD; IÞ þ pð!; A2jD; IÞ
þpð!; A3jD; IÞ þ   
(1:26)
Substitution of Equation (1.26) into Equation (1.24) yields:
pð!jD; IÞ ¼
X
i
pð!; AijD; IÞ:
(1:27)
Extending this idea to the case where A is a continuously variable parameter instead
of a discrete parameter, we can write
pð!jD; IÞ ¼
Z
dA pð!; AjD; IÞ:
(1:28)
The quantity, pð!jD; IÞ, is the marginal posterior distribution for !, which, for a
continuous parameter like !, is a probability density function. It summarizes what D, I
(our knowledge state) says about the parameter(s) of interest. The probability that !
will lie in any specific range from !1 to !2 is given by
R !2
!1 pð!jD; IÞd!.
Another useful form of the marginalization operation can be obtained by expand-
ing Equation (1.28) using Bayes’ theorem:
pð!; AjD; IÞ ¼ pð!; AjIÞpðDj!; A; IÞ
pðDjIÞ
:
(1:29)
Now expand pð!; AjIÞ on the right hand side of Equation (1.29) using the product rule:
pð!; AjIÞ ¼ pð!jIÞpðAj!; IÞ:
(1:30)
Now we will assume the priors for ! and A are independent so we can write
pðAj!; IÞ ¼ pðAjIÞ. What this is saying is that any prior information we have about
the parameter ! tells us nothing about the parameter A. This assumption is fre-
quently valid and it usually simplifies the calculations. Equation (1.29) can now be
rewritten as
pð!; AjD; IÞ ¼ pð!jIÞpðAjIÞpðDj!; A; IÞ
pðDjIÞ
:
(1:31)
Finally, substitution of Equation (1.31) into Equation (1.28) yields:
pð!jD; IÞ / pð!jIÞ
Z
dA pðAjIÞpðDj!; A; IÞ:
(1:32)
14
Role of probability theory in science

This gives the marginal posterior distribution pð!jD; IÞ, in terms of the weighted
average of the likelihood function, pðDj!; A; IÞ, weighted by pðAjIÞ, the prior prob-
ability density function for A. This is another form of the operation of marginalizing
out the A parameter. The integral in Equation (1.32) can sometimes be evaluated
analytically which can greatly reduce the computational aspects of the problem
especially when many parameters are involved. A dramatic example of this is
given in Gregory and Loredo (1992) which demonstrates how to marginalize analy-
tically over a very large number of parameters in a model describing a waveform of
unknown shape.
1.6 The two basic problems in statistical inference
1. Model selection: Which of two or more competing models is most probable given our present
state of knowledge?
The competing models may have different numbers of parameters. For example, suppose
we have some experimental data consisting of a signal plus some additive noise and we want
to distinguish between two different models for the signal present. Model M1 predicts that the
signal is a constant equal to zero, i.e., has no unknown (free) parameters. Model M2
predicts that the signal consists of a single sine wave of known frequency f. Let us
further suppose that the amplitude, A, of the sine wave is a free parameter within some
specified prior range. In this problem, M1 has no free parameters and M2 has one free
parameter, A.
In model selection, we are interested in the most probable model, independent of the model
parameters (i.e., marginalize out all parameters). This is illustrated in the equation below for
model M2.
pðM2jD; IÞ ¼
Z
A
dA pðM2; AjD; IÞ;
(1:33)
where A designates the appropriate range of integration of A as specified by our prior
information, I.
We can rearrange Equation (1.33) into another useful form by application of Bayes’
theorem and the product rule, following the example given in the previous section
(Equations (1.28) to (1.32)). The result is
pðM2jD; IÞ ¼ pðM2jIÞ
R
A dA pðAjM2; IÞpðDjM2; A; IÞ
pðDjIÞ
:
(1:34)
In model selection, the hypothesis space of interest is discrete (although its parameters may be
continous) and M2 stands for the second member of this discrete space.
2. Parameter estimation: Assuming the truth of a model, find the probability density function
for each of its parameters.
Suppose the model M has two free parameters f and A. In this case, we want to solve for
pð fjD; M; IÞ and pðAjD; M; IÞ. The quantity pð fjD; M; IÞ is called the marginal posterior
1.6 The two basic problems in statistical inference
15

distribution for f, which, for a continuous parameter like f, is a probability density function as
defined by Equation (1.8). In Chapter 3, we will work through a detailed example of both
model selection and parameter estimation.
1.7 Advantages of the Bayesian approach
1. Provides an elegantly simple and rational approach for answering, in an optimal way, any
scientific question for a given state of information. This contrasts to the recipe or cookbook
approach of conventional statistical analysis. The procedure is well-defined:
(a) Clearly state your question and prior information.
(b) Apply the sum and product rules. The starting point is always Bayes’ theorem.
For some problems, a Bayesian analysis may simply lead to a familiar statistic. Even in this
situation it often provides a powerful new insight concerning the interpretation of the
statistic. One example of this is shown in Figure 1.4 and discussed in detail in Chapter 13.
2. Calculates probability of hypothesis directly: pðHijD; IÞ.
3. Incorporates relevant prior (e.g., known signal model) information through Bayes’ theorem.
This is one of the great strengths of Bayesian analysis. For data with a high signal-to-noise
ratio, a Bayesian analysis can frequently yield many orders of magnitude improvement in
model parameter estimation, through the incorporation of relevant prior information about
the signal model. This is illustrated in Figure 1.5 and discussed in more detail in Chapter 13.
4. Provides a way of eliminating nuisance parameters through marginalization. For some
problems, the marginalization can be performed analytically, permitting certain calculations
to become computationally tractable (see Section 13.4).
5. Provides a more powerful way of assessing competing theories at the forefront of science
by automatically quantifying Occam’s razor. Occam’s razor is a principle attributed to the
medieval philosopher William of Occam (or Ockham). The principle states that one
should not make more assumptions than the minimum needed. It underlies all scientific
modeling and theory building. It cautions us to choose from a set of otherwise equivalent
models of a given phenomenon the simplest one. In any given model, Occam’s razor
helps us to ‘‘shave off’’ those variables that are not really needed to explain the
phenomenon. It was previously thought to be only a qualitative principle. This topic is
introduced in Section 3.5.
The Bayesian quantitative Occam’s razor can also save a lot of time that might otherwise
be spent chasing noise artifacts that masquerade as possible detections of real phenomena.
One example of this is discussed in Section 12.9 on extrasolar planets.
6. Provides a way for incorporating the effects of systematic errors arising from both the
measurement operation and theoretical model predictions. Figure 1.6 illustrates the effect
of a systematic error in the scale of the cosmic ruler (Hubble’s constant) used to determine the
distance to galaxies. This topic is introduced in Section 3.11.
These advantages will be discussed in detail beginning in Chapter 3. We close with a
reminder that in Bayesian inference probabilities are a measure of our state of know-
ledge about nature, not a measure of nature itself.
16
Role of probability theory in science

1.8 Problems
1. For the example given in Section 1.3.4, compute pðDjM1; IÞ and pðDjM2; IÞ, for a
 ¼ 25 ly.
2. For the example given in Section 1.4.1, compute the probability that the person has
the disease, if the false positive rate for the test ¼ 0:5%, and everything else is
the same.
0
0.1
0.2
0.3
0.4
0.5
Frequency
50
100
150
200
250
Probability density
Bayesian Probability Density
0
0.1
0.2
0.3
0.4
0.5
Frequency
5
10
15
20
25
30
35
Power density
Fourier Power Spectral Density
10
20
30
40
50
60
Time axis
–4
–2
0
2
4
Signal strength
Simulated Time Series [sin 2π ft + noise (σ  =  1)]
Figure 1.4 The upper panel shows a simulated time series consisting of a single sinusoidal signal
with added independent Gaussian noise. A common conventional analysis (middle panel)
involves plotting the power spectrum, based on a Discrete Fourier Transform (DFT) statistic
of the data. The Bayesian analysis (lower panel) involves a nonlinear processing of the same
DFT statistic, which suppresses spurious peaks and the width of the spectral peak reflects the
accuracy of the frequency estimate.
1.8 Problems
17

Figure 1.5 Comparison of conventional analysis (middle panel) and Bayesian analysis (lower
panel) of the two-channel nuclear magnetic resonance free induction decay time series (upper
two panels). By incorporating prior information about the signal model, the Bayesian analysis
was able to determine the frequencies and exponential decay rates to an accuracy many orders of
magnitude greater than for a conventional analysis. (Figure credit G. L. Bretthorst, reproduced
by permission from the American Institute of Physics.)
18
Role of probability theory in science

1000
1500
2000
Distance (Mpc)
0
0.01
0.02
0.03
0.04
0.05
Probability density
case 2
case 1
Figure 1.6 The probability density function for the distance to a galaxy assuming: 1) a fixed value
for Hubble’s constant ðH0Þ, and 2) incorporating a Gaussian prior uncertainty for H0 of 14%.
3. In Section 1.4.1, based on the saliva test result and the prior information, the
probability that the person had the unknown disease (UD) was found to be 0.42%.
Subsequently, the same person received an independent blood test for UD and
again tested positive. If the false negative rate for this test is 1.4% and the false
positive rate is 0.5%, what is the new probability that the person has UD on the
basis of both tests?
4. Joint and marginal probability distributions
(Refer to the example on this topic in the Mathematica tutorial.)
(a) Suppose we are interested in estimating the parameters X and Y of a certain
model M, where both parameters are continuous as opposed to discrete. Make a
contour plot of the following posterior joint probability density function given by:
pðX; YjD; M; IÞ ¼ A1 exp  ðx  x1Þ2 þ ðy  y1Þ2
22
1
 
!
þ A2 exp  ðx  x2Þ2 þ ðy  y2Þ2
22
2
 
!
;
where A1 ¼ 4:82033; A2 ¼ 4:43181; x1 ¼ 0:5; y1 ¼ 0:5; x2 ¼ 0:65; y2 ¼ 0:75; 1 ¼
0:2; 2 ¼ 0:04, where 0  x  1 and 0  y  1. Your contour plot should
cover the interval x ¼ 0 ! 1; y ¼ 0 ! 1. In Mathematica, this can be accom-
plished with ContourPlot.
(b) Now make a 3-dimensional plot of pðX; YjD; M; IÞ. In Mathematica, this can
be accomplished with Plot3D.
(c) Now compute the marginal probability distributions pðXjD; M; IÞ and
pðYjD; M; IÞ. The prior information is
I  ‘‘X and Y are only non-zero in the interval 0 ! 1, and uniform within that
interval.’’
Check that the integral of pðXjD; M; IÞ in the interval 0 ! 1 is equal to 1.
1.8 Problems
19

(d) In your 3-dimensional plot of part (b), probability is represented by a height
along the z-axis. Now imagine a light source located a great distance away
along the y-axis illuminating the 3-dimensional probability density function.
The shadow cast by pðX; YjD; M; IÞ on the plane defined by y ¼ 0, we will call
the projected probability density function of X. Compute and compare the
projected probability density function of X with the marginal distribution on
the same plot. To accomplish this effectively, both density functions should be
normalized to have an integral ¼ 1 in the interval x ¼ 0 ! 1.
Note: the location of the peak of the marginal does not correspond to the
location of the projection peak although they would if the joint probability
density function were a single multi-dimensional Gaussian.
(e) Plot the normalized marginal and projected probability density functions for Y
on one graph.
20
Role of probability theory in science

2
Probability theory as extended logic
2.1 Overview
The goal of this chapter is to provide an extension of logic to handle situations where
we have incomplete information so we may arrive at the relative probabilities of
competing propositions (theories, hypotheses, or models) for a given state of informa-
tion. We start by reviewing the algebra of logical propositions and explore the
structure (syllogisms) of deductive and plausible inference. We then set off on a course
to come up with a quantitative theory of plausible inference (probability theory as
extended logic) based on the three desirable goals called desiderata. This amounts to
finding an adequate set of mathematical operations for plausible inference that
satisfies the desiderata. The two operations required turn out to be the product rule
and sum rule of probability theory. The process of arriving at these operations
uncovers a precise operational definition of plausibility, which is determined by the
data. The material presented in this chapter is an abridged version of the treatment
given by E. T. Jaynes in his book, Probability Theory – The Logic of Science (Jaynes,
2003), with permission from Cambridge University Press.
2.2 Fundamentals of logic
2.2.1 Logical propositions
In general, we will represent propositions by capital letters fA; B; C; etc:g. A proposi-
tion asserts that something is true.
e:g:; A  ‘‘The age of the specimen is  106 years:’’
The denial of a proposition is indicated by a bar:
A  ‘‘A is false.’’
We will only be concerned with two-valued logic; thus, any proposition has a truth
value of either
True
or
False
1
or
0

 Truth value:
21

2.2.2 Compound propositions
A; B  asserts both A and B are true
ðlogical product or conjunctionÞ
A; A  impossible statement, truth value ¼ F or zero
A þ B  asserts A is true or B is true or both are true
ðlogical sum or disjunctionÞ
A; B þ B; A  asserts either A is true or B is true but both are not true
ðexclusive form of logical sumÞ
2.2.3 Truth tables and Boolean algebra
Consider the two compound propositions A ¼ B; C and D ¼ B þ C. Are the proposi-
tions A and D equal? Two propositions are equal if they have the same truth value. We
can verify that A ¼ D by constructing a truth table which lays out the truth values for
A and D for all the possible combinations of the truth values of the propositions B and
C on which they are based (Table 2.1).
Since A and D have the same truth value for all possible truth values of propositions
B and C, then we can write
A ¼ D (which means they are logically equivalent):
We have thus established the relationship
B; C ¼ B þ C and 6¼ B; C:
(2:1)
In addition, the last two columns of the table establish the relationship
B; C ¼ B þ C:
(2:2)
Boole (1854) pointed out that the propositional statements in symbolic logic obey
the rules of algebra provided one interprets them as having values of 1 or 0 (Boolean
algebra). There are no operations equivalent to subtraction or division. The only
operations required are multiplications (‘and’) and additions (‘or’).
Table 2.1
B
C
B; C
A ¼ B; C
D ¼ B þ C
B þ C
B þ C
B; C
T
T
T
F
F
T
F
F
T
F
F
T
T
T
F
F
F
T
F
T
T
T
F
F
F
F
F
T
T
F
T
T
22
Probability theory as extended logic

Box 2.1
Worked exercise:
construct a truth table to show A; ðB þ CÞ ¼ A; B þ A; C.
Since A; ðB þ CÞ and A; B þ A; C have the same truth value for all possible truth
values of propositions A, B and C, then we can write
A; ðB þ CÞ ¼ A; B þ A; C. (This is a distributivity identity.)
One surprising result of Boolean algebra manipulations is that a given statement
may take several different forms which don’t resemble one another.
For example, show that D ¼ A þ B; C ¼ ðA þ BÞ; ðA þ CÞ.
In the proof below, we make use of the relationships X; Y ¼ X þ Y (on line 1), and
X; Y ¼ X þ Y (on line 3), from Equations (2.1) and (2.2).
D ¼ A þ B; C ¼ A þ B; C ¼ A; B; C
D ¼ A; ðB þ CÞ
D ¼ A; B þ A; C ¼ ðA þ BÞ þ ðA þ CÞ
D ¼ ðA þ BÞ; ðA þ CÞ
D ¼ ðA þ BÞ; ðA þ CÞ
or
A þ B; C ¼ ðA þ BÞ; ðA þ CÞ:
This can also be verified by constructing a truth table.
A
B
C
B þ C
A; ðB þ CÞ
A; B
A; C
A; B þ A; C
T
T
T
T
T
T
T
T
T
F
F
F
F
F
F
F
T
T
F
T
T
T
F
T
T
F
T
T
T
F
T
T
F
T
T
T
F
F
F
F
F
F
F
F
F
F
F
F
F
T
F
T
F
F
F
F
F
F
T
T
F
F
F
F
2.2 Fundamentals of logic
23

By the application of these identities, one can prove any number of further relations,
some highly non-trivial. For example, we shall presently have use for the rather
elementary ‘‘theorem’’:
If B ¼ A; D
A; B ¼ A; A; D ¼ A; D ¼ B
then A; B ¼ B:
(2:3)
Also, we can show that:
B; A ¼ A:
(2:4)
Proof of the latter follows from
B ¼ A; D ¼ A þ D
B; A ¼ A; A þ A; D ¼ A þ A; D ¼ A:
(2:5)
Clearly, Equation (2.5) is true if A is true and false if A is false, regardless of the
truth of D.
2.2.4 Deductive inference
Deductive inference is the process of reasoning from one proposition to another. It
was recognized by Aristotle (fourth century BC) that deductive inference can be
analyzed into repeated applications of the strong syllogisms:
1. If A is true, then B is true (major premise)
A is true
ðminor premiseÞ
Therefore B is true
ðconclusionÞ
2. If A is true, then B is true
B is false
Therefore A is false
Basic Boolean Identities
Idempotence:
A; A
¼
A
A þ A
¼
A
Commutativity:
A; B
¼
B; A
A þ B
¼
B þ A
Associativity:
A; ðB; CÞ
¼
ðA; BÞ; C
¼
A; B; C
A þ ðB þ CÞ
¼
ðA þ BÞ þ C
¼
A þ B þ C
Distributivity:
A; ðB þ CÞ
¼
A; B þ A; C
A þ ðB; CÞ
¼
ðA þ BÞ; ðA þ CÞ
Duality:
If
C ¼ A; B,
then
C ¼ A þ B
If
D ¼ A þ B,
then
D ¼ A; B
24
Probability theory as extended logic

In Boolean algebra, these strong syllogisms can be written as:
A ¼ A; B:
(2:6)
This equation says that the truth value of proposition A; B is equal to the truth value of
proposition A. It does not assert that either A or B is true. Clearly, if B is false, then the
right hand side of the equation equals 0, and so A must be false. On the other hand, if B
is known to be true, then according to Equation (2.6), proposition A can be true or
false. It is also written as the implication operation A ) B.
2.2.5 Inductive or plausible inference
In almost all situations confronting us, we do not have the information required to do
deductive inference. We have to fall back on weaker syllogisms:
If A is true, then B is true
B is true
Therefore A becomes more plausible
Example
A  ‘‘It will start to rain by 10 AM at the latest.’’
B  ‘‘The sky becomes cloudy before 10 AM.’’
Observing clouds at 9:45 AM does not give us logical certainty that rain will follow;
nevertheless, our common sense, obeying the weak syllogism, may induce us to change
our plans and behave as if we believed that it will rain, if the clouds are sufficiently dark.
This example also shows the major premise: ‘‘If A then B’’ expresses B only as a
logical consequence of A and not necessarily as a causal consequence (i.e., the rain is
not the cause of the clouds).
Another weak syllogism:
If A is true, then B is true
A is false
Therefore B becomes less plausible
2.3 Brief history
The early work on probability theory by James Bernoulli (1713), Rev. Thomas Bayes
(1763), and Pierre Simon Laplace (1774), viewed probability as an extension of logic to
the case where, because of incomplete information, Aristotelian deductive reasoning is
unavailable. Unfortunately, Laplace failed to give convincing arguments to show why
2.3 Brief history
25

the Bayesian definition of probability uniquely required the sum and product rules for
manipulating probabilities. The frequentist definition of probability was introduced
to satisfy this point, but in the process, eliminated the interpretation of probability as
extended logic. This caused a split in the subject into the Bayesian and frequentist
camps. The frequentist approach dominated statistical inference throughout most of
the twentieth century, but the Bayesian viewpoint was kept alive notably by Sir Harold
Jeffreys (1891–1989).
In the 1940s and 1950s, G. Polya, R. T. Cox and E. T. Jaynes provided the missing
rationale for Bayesian probability theory. In his book Mathematics and Plausible
Reasoning, George Polya dissected our ‘‘common sense’’ into a set of elementary
desiderata and showed that mathematicians had been using them all along to guide
the early stages of discovery, which necessarily precede the finding of a rigorous proof.
When one added (see Section 2.5.1) the consistency desiderata of Cox (1946) and
Jaynes, the result was a proof that, if degrees of plausibility are represented by real
numbers, then there is a unique set of rules for conducting inference according to
Polya’s desiderata which provides for an operationally defined scale of plausibility.
The final result was just the standard product and sum rules of probability theory,
given axiomatically by Bernoulli and Laplace! The important new feature is that
these rules are now seen as uniquely valid principles of logic in general, making no
reference to ‘‘random variables’’, so their range of application is vastly greater than
that supposed in the conventional probability theory that was developed in the early
twentieth century. With this came a revival of the notion of probability theory as
extended logic.
The work of Cox and Jaynes was little appreciated at first. Widespread application
of Bayesian methodology did not occur until the 1980s. By this time computers had
become sufficiently powerful to demonstrate that the methodology could outperform
standard techniques in many areas of science. We are now in the midst of a ‘‘Bayesian
Revolution’’ in statistical inference. In spite of this, many scientists are still unaware of
the significance of the revolution and the frequentist approach currently dominates
statistical inference. New graduate students often find themselves caught between the
two cultures. This book represents an attempt to provide a bridge.
2.4 An adequate set of operations
So far, we have discussed the following logical operations:
A; B logical product (conjunction)
A þ B logical sum (disjunction)
A ) B implication
A negation
26
Probability theory as extended logic

By combining these operations repeatedly in every possible way, we can generate
any number of new propositions, such as:
C  ðA þ BÞ; ðA þ A; BÞ þ A; B; ðA þ BÞ:
(2:7)
We now consider the following questions:
1. How large is the class of new propositions?
2. Is it infinite or finite?
3. Can every proposition defined from A and B be represented in terms of the above operations,
or are new operations required?
4. Are the four operations already over-complete?
Note: two propositions are not different from the standpoint of logic if they have the
same truth value. C, in the above equation, is logically the same statement as the
implication C ¼ ðB ) AÞ. Recall that the implication B ) A can also be written as
B ¼ A; B. This does not assert that either A or B is true; it only means that A; B is false,
or equivalently that ðA þ BÞ is true.
Box 2.2
Worked exercise:
expand the right hand side (RHS) of proposition C given by Equation (2.7), and
show that it can be reduced to ðA þ BÞ.
RHS ¼ A; A þ A; B þ A; A; B þ A; B; B þ A; A; B þ A; B; B
Drop all terms that are clearly impossible (false), e.g., A; A. Adding any number
of impossible propositions to a proposition in a logical sum does not alter the
truth value of the proposition. It is like adding a zero to a function; it doesn’t alter
the value of the function.
¼ A; B þ A; B þ A; B
¼ A; ðB þ BÞ þ A; B ¼ A þ A; B
¼ A þ A; B ¼ A; A; B ¼ A; ðA þ BÞ ¼ A; B
¼ A þ B:
2.4.1 Examination of a logic function
Any logic function C ¼ fðA; BÞ has only two possible values, and likewise for the
independent variables A and B. A logic function with n variables is defined on a
discrete space consisting of only m ¼ 2n points. For example, in the case of C ¼ fðA; BÞ,
m ¼ 4 points; namely those at which A and B take on the values fTT,TF,FT,FFg. The
number of independent logic functions ¼ 2m ¼ 16. Table 2.2 lists these 16 logical
functions.
2.4 An adequate set of operations
27

We can show that f5 ! f16 are logical sums of f1 ! f4.
Example 1:
f1 þ f3 þ f4 ¼ A; B þ A; B þ A; B
¼ B þ A; B ¼ ðB þ AÞ; ðB þ BÞ
last step is a distributivity identity
¼ B þ A
¼ f8:
(2:8)
Example 2:
f2 þ f4 ¼ A; B þ A; B
¼ ðA þ AÞ; B ¼ B
¼ f13 :
(2:9)
This method (called ‘‘reduction to disjunctive normal form’’ in logic textbooks) will
work for any n. Thus, one can verify that the three operations:
conjunction;
disjunction;
negation
logical product;
logical sum;
negation
AND
OR
NOT
8
<
:
9
=
;
Table 2.2 Logic functions of the two propositions A and B.
A; B
TT
TF
FT
FF
f1ðA; BÞ
T
F
F
F
¼ A; B
f2ðA; BÞ
F
T
F
F
¼ A; B
f3ðA; BÞ
F
F
T
F
¼ A; B
f4ðA; BÞ
F
F
F
T
¼ A; B
f5ðA; BÞ
T
T
T
T
f6ðA; BÞ
T
T
T
F
f7ðA; BÞ
T
T
F
T
f8ðA; BÞ
T
F
T
T
f9ðA; BÞ
F
T
T
T
f10ðA; BÞ
T
T
F
F
f11ðA; BÞ
T
F
T
F
f12ðA; BÞ
F
T
T
F
f13ðA; BÞ
F
T
F
T
f14ðA; BÞ
F
F
T
T
f15ðA; BÞ
T
F
F
T
f16ðA; BÞ
F
F
F
F
¼ A; A
28
Probability theory as extended logic

suffice to generate all logic functions, i.e., form an adequate set. But the logical sum
A þ B is the same as denying that they are both false: A þ B ¼ A; B. Therefore AND
and NOT are already an adequate set.
Is there a still smaller set? Answer: Yes.
NAND, defined as AND which is represented by A " B.
A " B  A; B ¼ A þ B
A ¼ A " A
A; B ¼ ðA " BÞ " ðA " BÞ
A þ B ¼ ðA " AÞ " ðB " BÞ:
Every logic function can be constructed from NAND alone.
The NOR operator is defined by:
A # B  A þ B ¼ A; B
and is also powerful enough to generate all logic functions.
A ¼ A # A
A þ B ¼ ðA # BÞ # ðA # BÞ
A; B ¼ ðA # AÞ # ðB # BÞ:
2.5 Operations for plausible inference
We now turn to the extension of logic for a common situation where we lack the
axiomatic information necessary for deductive logic. The goal according to Jaynes,
is to arrive at a useful mathematical theory of plausible inference which will enable
us to build a robot (write a computer program) to quantify the plausibility of any
hypothesis in our hypothesis space of interest based on incomplete information. For
example, given 107 observations, determine (in the light of these data and whatever
prior information is at hand) the relative plausibilities of many different hypotheses
about the causes at work.
We expect that any mathematical model we succeed in constructing will be replaced
by more complete ones in the future as part of the much grander goal of developing
a theory of common sense reasoning. Experience in physics has shown that as know-
ledge advances, we are able to invent better models, which reproduce more features of
the real world, with more accuracy. We are also accustomed to finding that these
advances lead to consequences of great practical value, like a computer program to
carry out useful plausible inference following clearly defined principles (rules or
operations) expressing an idealized common sense.
The rules of plausible inference are deduced from a set of three desiderata (see
Section 2.5.1) rather than axioms, because they do not assert anything is true, but only
state what appear to be desirable goals. We would definitely want to revise the
2.5 Operations for plausible inference
29

operation of our robot or computer program if they violated one of these elementary
desiderata. Whether these goals are attainable without contradiction and whether they
determine any unique extension of logic are a matter of mathematical analysis. We
also need to compare the inference of a robot built in this way to our own reasoning, to
decide whether we are prepared to trust the robot to help us with our inference
problems.
2.5.1 The desiderata of Bayesian probability theory
I. Degrees of plausibility are represented by real numbers.
II. The measure of plausibility must exhibit qualitative agreement with rationality. This means
that as new information supporting the truth of a proposition is supplied, the number which
represents the plausibility will increase continuously and monotonically. Also, to maintain
rationality, the deductive limit must be obtained where appropriate.
III. Consistency
(a) Structural consistency: If a conclusion can be reasoned out in more than one way, every
possible way must lead to the same result.
(b) Propriety: The theory must take account of all information, provided it is relevant to the
question.
(c) Jaynes consistency: Equivalent states of knowledge must be represented by equivalent
plausibility assignments. For example, if A; BjC ¼ BjC, then the plausibility of A; BjC
must equal the plausibility of BjC.
2.5.2 Development of the product rule
In Section 2.4 we established that the logical product and negation (AND, NOT) are
an adequate set of operations to generate any proposition derivable from
fA1; . . . ; ANg. For Bayesian inference, our goal is to find operations (rules) to deter-
mine the plausibility of logical conjunction and negation that satisfy the above
desiderata. Start with the plausibility of A; B:
Let ðA; BjCÞ  plausibility of A; B supposing the truth of C.
Remember, we are going to represent plausibility by real numbers (desideratum I). Now
ðA; BjCÞ must be a function of some combination of ðAjCÞ, ðBjCÞ, ðBjA; CÞ, ðAjB; CÞ.
There are 11 possibilities:
ðA; BjCÞ ¼ F1½ðAjCÞ; ðAjB; CÞ
ðA; BjCÞ ¼ F2½ðAjCÞ; ðBjCÞ
ðA; BjCÞ ¼ F3½ðAjCÞ; ðBjA; CÞ
ðA; BjCÞ ¼ F4½ðAjB; CÞ; ðBjCÞ
ðA; BjCÞ ¼ F5½ðAjB; CÞ; ðBjA; CÞ
30
Probability theory as extended logic

ðA; BjCÞ ¼ F6½ðBjCÞ; ðBjA; CÞ
ðA; BjCÞ ¼ F7½ðAjCÞ; ðAjB; CÞ; ðBjCÞ
ðA; BjCÞ ¼ F8½ðAjCÞ; ðAjB; CÞ; ðBjA; CÞ
ðA; BjCÞ ¼ F9½ðAjCÞ; ðBjCÞ; ðBjA; CÞ
ðA; BjCÞ ¼ F10½ðAjB; CÞ; ðBjCÞ; ðBjA; CÞ
ðA; BjCÞ ¼ F11½ðAjCÞ; ðAjB; CÞ; ðBjCÞ; ðBjA; CÞ
Box 2.3
Note on the use of the ‘‘ = ’’ sign
1. In Boolean algebra, the equals sign is used to denote equal truth value. By definition,
A ¼ B asserts that A is true if and only if B is true.
2. When
talking
about
plausibility,
which
is
represented
by
a
real
number,
ðA; BjCÞ ¼ ðÞðÞ . . . means equal numerically.
3.  means equal by definition.
Now let us examine these 11 different functions more closely. Since the order in which
the symbols A and B appear has no meaning (i.e., A; B ¼ B; A) it follows that
F1½ðAjCÞ; ðAjB; CÞ ¼ F6½ðBjCÞ; ðBjA; CÞ
F3½ðAjCÞ; ðBjA; CÞ ¼ F4½ðAjB; CÞ; ðBjCÞ
F7½ðAjCÞ; ðAjB; CÞ; ðBjCÞ ¼ F9½ðAjCÞ; ðBjCÞ; ðBjA; CÞ
F8½ðAjCÞ; ðAjB; CÞ; ðBjA; CÞ ¼ F10½ðAjB; CÞ; ðBjCÞ; ðBjA; CÞ
This reduces the number of equations dramatically from 11 to 7. The seven functions
remaining are F1; F2; F3; F5; F7; F8; F11.
If any function leads to an absurdity in even one example, it must be ruled out, even
if for other examples it would be satisfactory. Consider
ðA; BjCÞ ¼ F2½ðAjCÞ; ðBjCÞ:
Suppose A  next person will have blue left eye.
B  next person will have brown right eye.
C  prior information concerning our expectation that the left and right eye
colors of any individual will be very similar.
Now ðAjCÞ could be very plausible as could ðBjCÞ, but ðA; BjCÞ is extremely
implausible. We rule out functions of this form because they have no way of taking
such influence into account. Our robot could not reason the way humans do, even
qualitatively, with that functional form.
2.5 Operations for plausible inference
31

Similarly, we can rule out F1 for the extreme case where the conditional (given)
information represented by proposition C is that ‘‘A and B are independent.’’ In this
extreme case,
ðAjB; CÞ ¼ ðAjCÞ:
Therefore,
ðA; BjCÞ ¼ F1½ðAjCÞ; ðAjB; CÞ ¼ F1½ðAjCÞ; ðAjCÞ;
(2:10)
which is clearly absurd because F1 claims that the plausibility of A; BjC depends only
on the plausibility of AjC.
Other extreme conditions are A ¼ B; A ¼ C; C ¼ A, etc. Carrying out this type of
analysis, Tribus (1969) shows that all but one of the remaining possibilities can exhibit
qualitative violations with common sense in some extreme case. There is only one
survivor which can be written in two equivalent ways:
ðA; BjCÞ ¼ F ½ðBjCÞ; ðAjB; CÞ
¼ F ½ðAjCÞ; ðBjA; CÞ:
(2:11)
In addition, desideratum II, qualitative agreement with common sense, requires
that F½ðAjCÞ; ðBjA; CÞ must be a continuous monotonic function of ðAjCÞ and
ðBjA; CÞ. The continuity assumption requires that if ðAjCÞ changes only infinitesim-
ally, it can induce only an infinitesimal change in ðA; BjCÞ or ðAjCÞ.
Now use desideratum III: ‘‘Consistency’’
Suppose we want ðA; B; CjDÞ
1. Consider B; C to be a single proposition at first; then we can apply Equation (2.11):
ðA; B; CjDÞ ¼ F ½ðB; CjDÞ; ðAjB; C; DÞ
¼ FfF ½ðCjDÞ; ðBjC; DÞ; ðAjB; C; DÞg:
(2:12)
2. Consider A; B to be a single proposition at first:
ðA; B; CjDÞ ¼ F ½ðCjDÞ; ðA; BjC; DÞ
¼ FfðCjDÞ; F ½ðBjC; DÞ; ðAjB; C; DÞg:
(2:13)
For consistency, 1 and 2 must be equal.
Let x  ðAjB; C; DÞ; y  ðBjC; DÞ; z  ðCjDÞ, then:
Ffx; F ½y; zg ¼ FfF ½x; y; zg:
(2:14)
This equation has a long history in mathematics and is called the ‘‘the Associativity
Equation.’’ Acze´ l (1966) derives the general solution (Equation (2.15) below) without
assuming differentiability; unfortunately, the proof fills 11 pages of his book.
R. T. Cox (1961) provided a shorter proof, but assumed differentiability.
32
Probability theory as extended logic

The solution is
wfF ½x; yg ¼ wfxgwfyg;
(2:15)
where wfxg is any positive continuous monotonic function.
In the case of just two propositions, A, B given the truth of C, the solution to the
associativity equation becomes
wfðA; BjCÞg ¼ wfðAjB; CÞgwfðBjCÞg
¼ wfðBjA; CÞgwfðAjCÞg:
(2:16)
For simplicity, drop the fg brackets, but it should be remembered that the argument
of w is a plausibility.
wðA; BjCÞ ¼ wðAjB; CÞwðBjCÞ
¼ wðBjA; CÞwðAjCÞ:
(2:17)
Henceforth this will be called the product rule. Recall that at this moment, wðÞ is any
positive, continuous, monotonic function.
Desideratum II: Qualitative correspondence with common sense imposes further restric-
tions on wfxg
Suppose A is certain given C. Then A; BjC ¼ BjC (i.e., same truth value). By our
primitive axiom that propositions with the same truth value must have the same
plausibility,
ðA; BjCÞ ¼ ðBjCÞ
ðAjB; CÞ ¼ ðAjCÞ:
(2:18)
Therefore, Equation (2.17), the solution to the associativity equation, becomes
wðBjCÞ ¼ wðAjCÞwðBjCÞ:
(2:19)
This is only true when AjC is certain.
Thus we have arrived at a new constraint on wðÞ; it must equal 1 when the argument is
certain.
For the next constraint, suppose that A is impossible given C . This implies
A; BjC ¼ AjC
AjB; C ¼ AjC:
Then
wðA; BjCÞ ¼ wðAjB; CÞwðBjCÞ
(2:20)
becomes
wðAjCÞ ¼ wðAjCÞwðBjCÞ:
(2:21)
2.5 Operations for plausible inference
33

This must be true for any ðBjCÞ. There are only two choices: either wðAjCÞ ¼ 0 or þ1.
1. wðxÞ is a positive, increasing function ð0 ! 1Þ:
2. wðxÞ is a positive, decreasing function ð1 ! 1Þ:
They do not differ in content.
Suppose w1ðxÞ represents impossibility by þ1. We can define w2ðxÞ ¼ 1=w1ðxÞ
which represents impossibility by 0. Therefore, there is no loss of generality if we adopt:
0  wðxÞ  1:
Summary:
Using our desiderata, we have arrived at our present form of the product rule:
wðA; BjCÞ ¼ wðAjCÞwðBjA; CÞ ¼ wðBjCÞwðAjB; CÞ:
At this point we are still not referring to wðxÞ as the probability of x. wðxÞ is any
continuous, monotonic function satisfying:
0  wðxÞ  1;
where wðxÞ ¼ 0 when the argument x is impossible and 1 when x is certain.
2.5.3 Development of sum rule
We have succeeded in deriving an operation for determining the plausibility of the
logical product (conjunction). We now turn to the problem of finding an operation to
determine the plausibility of negation. Since the logical sum A þ A is always true, it
follows that the plausibility that A is false must depend on the plausibility that A is
true. Thus, there must exist some functional relation
wðAjBÞ ¼ SðwðAjBÞÞ:
(2:22)
Again, using our desiderata and functional analysis, one can show (Jaynes, 2003)
that the monotonic function wðAjBÞ obeys
wmðAjBÞ þ wmðAjBÞ ¼ 1
for positive m. This is known as the sum rule.
The product rule can equally well be written as
wmðA; BjCÞ ¼ wmðAjCÞwmðBjA; CÞ ¼ wmðBjCÞwmðAjB; CÞ:
But then we see that the value of m is actually irrelevant; for whatever value is chosen,
we can define a new function
pðxÞ  wmðxÞ
and our rules take the form
34
Probability theory as extended logic

pðA; BjCÞ ¼ pðAjCÞpðBjA; CÞ ¼ pðBjCÞpðAjB; CÞ
pðAjBÞ þ pðAjBÞ ¼ 1
This entails no loss of generality, for the only requirement we imposed on the
function wðxÞ is that wðxÞ is a continuous, monotonic, increasing function ranging
from w ¼ 0 for impossibility to w ¼ 1 for certainty. But if wðxÞ satisfies this, so does
wmðxÞ, 0 < m < 1.
Reminder: We are still not referring to pðxÞ as a probability.
We showed earlier that conjunction, A, B, and negation, A, are an adequate set of
operations, from which all logic functions can be constructed. Therefore, it ought to be
possible, by repeated applications of the product and sum rules, to arrive at the plausi-
bility of any proposition. To show this, we derive a formula for the logical sum A þ B.
pðA þ BjCÞ ¼ 1  pðA þ BjCÞ ¼ 1  pðA; BjCÞ
¼ 1  pðAjCÞpðBjA; CÞ
¼ 1  pðAjCÞ½1  pðBjA; CÞ
¼ 1  pðAjCÞ þ pðAjCÞpðBjA; CÞ
¼ pðAjCÞ þ pðA; BjCÞ
¼ pðAjCÞ þ pðBjCÞpðAjB; CÞ
¼ pðAjCÞ þ pðBjCÞ½1  pðAjB; CÞ
¼ pðAjCÞ þ pðBjCÞ  pðBjCÞpðAjB; CÞ
) pðA þ BjCÞ ¼ pðAjCÞ þ pðBjCÞ  pðA; BjCÞ:
:
(2:23)
This is a very useful relationship and is called the extended sum rule.
Starting with our three desiderata, we arrived at a set of rules for plausible inference:
product rule:
pðA; BjCÞ ¼ pðAjCÞpðBjA; CÞ ¼ pðBjCÞpðAjB; CÞ;
sum rule:
pðAjBÞ þ pðAjBÞ ¼ 1:
We have in the two rules formulae for the plausibility of the conjunction, A, B, and
negation, A, which are an adequate set of operations to generate any proposition
derivable from the set fA1; . . . ; ANg.
Using the product and sum rules, we also derived the extended sum rule
pðA þ BjCÞ ¼ pðAjCÞ þ pðBjCÞ  pðA; BjCÞ:
(2:24)
2.5 Operations for plausible inference
35

For mutually exclusive propositions pðA; BjCÞ ¼ 0, so Equation (2.24) becomes
pðA þ BjCÞ ¼ pðAjCÞ þ pðBjCÞ:
(2:25)
We will refer to Equation (2.25) as the generalized sum rule.
2.5.4 Qualitative properties of product and sum rules
Check to see if the product and sum rules predict the strong (deductive logic) and weak
(inductive logic) syllogisms.
Strong syllogisms:
(a)
(b)
A ) B
A ) B
major premise (prior information)
A true
B false
minor premise (data)
B true
A false
conclusion
Example:
* Let A  ‘‘Corn was harvested in Eastern Canada in AD 1000.’’
* Let B  ‘‘Corn seed was available in Eastern Canada in AD 1000.’’
* Let I  ‘‘Corn seed is required to grow corn, so if corn was harvested, the seed must have been
available.’’ This is our prior information or major premise.
In both cases, we start by writing down the product rule:
Syllogism (a)
Syllogism (b)
pðA; BjIÞ ¼ pðAjIÞpðBjA; IÞ
pðA; BjIÞ ¼ pðBjIÞpðAjB; IÞ
! pðBjA; IÞ ¼ pðA; BjIÞ
pðAjIÞ
pðAjB; IÞ ¼ pðA; BjIÞ
pðBjIÞ
Prior info. I  ‘‘A; B ¼ A’’
Prior info. I  ‘‘A; B ¼ A’’
! pðA; BjIÞ ¼ pðAjIÞ
! pðA; BjIÞ ¼ 0
! pðBjA; IÞ ¼ 1
i.e., B is true if A is true
since B could not be false if A is
true according to the information I.
Data: A ¼ 1 (true)
Data: B ¼ 1 ( B false)
! pðBjA; IÞ ¼ 1
! pðAjB; IÞ ¼ 0
Certainty
Impossibility
Weak syllogisms:
(a)
(b)
A ) B
A ) B
prior information
B true
A false
data
A more plausible
B less plausible
conclusion
36
Probability theory as extended logic

Start by writing down the product rule in the form of Bayes’ theorem:
Weak Syllogism (a)
Weak Syllogism (b)
pðAjB; IÞ ¼ pðAjIÞpðBjA; IÞ
pðBjIÞ
pðBjA; IÞ ¼ pðBjIÞpðAjB; IÞ
pðAjIÞ
Prior info. I  ‘‘A; B ¼ A’’
Syllogism (a) gives pðAjB; IÞ  pðAjIÞ
based on the same prior information.
! pðBjA; IÞ ¼ 1
! 1  pð AjB; IÞ  1  pð AjIÞ
and pðBjIÞ  1
since I says nothing about the truth of B.
! pðAjB; IÞ  pðAjIÞ or pðAjB; IÞ
pðAjIÞ
 1
Substituting into Bayes’ theorem
Substituting into Bayes’ theorem
! pðAjB; IÞ  pðAjIÞ
! pðBjA; IÞ  pðBjIÞ
A more plausible
B less plausible
2.6 Uniqueness of the product and sum rules
Corresponding to every different choice of continuous monotonic function pðxÞthere
seems to be a different set of rules. Nothing given so far tells us what numerical value
of plausibility should be assigned at the beginning of the problem. To answer both
issues, consider the following: suppose we have N mutually exclusive and exhaustive
propositions fA1; . . . ; ANg.
* Mutually exclusive  only one can be true, i.e., pðAi; AjjBÞ ¼ 0 for i 6¼ j
pðA1 þ    þ ANjBÞ ¼ PN
i ¼ 1 pðAijBÞ
* Exhaustive  the true proposition is contained in the set
PN
i ¼ 1 pðAijBÞ ¼ 1ðcertainÞ
This information is not enough to determine the individual pðAijBÞ since there is no
end to the variety of complicated information that might be contained in B.
Development of new methods for translating prior information to numerical values
of pðAijBÞ is an ongoing research problem. We will discuss several valuable
approaches to this problem in later chapters.
Suppose our information B is indifferent regarding the pðAijBÞ’s. Then the only
possibility that reflects this state of knowledge is:
pðAijBÞ ¼ 1
N ;
(2:26)
2.6 Uniqueness of the product and sum rules
37

where N is the number of mutually exclusive propositions. This is called the Principle
of Indifference.
In this one particular case, which can be generalized, we see that information B
leads to a definite numerical value for pðAijBÞ, but not the numerical value of the
plausibility ðAijBÞ.
Instead of saying pðAijBÞ is an arbitrary, monotonic function of the plausibility
ðAijBÞ, it is much more useful to turn this around and say: ‘‘the plausibility ðAijBÞ is an
arbitrary, monotonic function of pðÞ, defined in 0  pðÞ  1.’’
It is pðÞ that is rigidly fixed by the data, not ðAijBÞ.
The p’s define a particular scale on which degrees of plausibility can be measured. Out
of the possible monotonic functions we pick this particular one, not because it is
‘‘correct,’’ but because it is more convenient. p is the quantity that obeys the product
and sum rules and the numerical value of p is determined by the available information.
From now on we will refer to them as probabilities.
Jaynes (2003) writes, ‘‘This situation is analogous to that in thermodynamics, where
out of all possible empirical temperature scales T, which are monotonic functions of
each other, we finally decide to use the Kelvin scale T; not because it is more ‘correct’
than others, but because it is more convenient; i.e., the laws of thermodynamics take
their simplest form ½dU ¼ Tds  PdV; dG ¼  SdT þ VdP in terms of this particular
scale. Because of this, numerical values of Kelvin temperatures are directly measurable
in experiments.’’
With this operational definition of probability, we can readily derive another
intuitively pleasing result. In this problem, our prior information is:
I  ‘‘An urn is filled with 10 balls of identical size, weight and texture, labeled
1; 2; . . . ; 10. Three of the balls (numbers 3, 4, 7) are red and the others are
green. We are to shake the urn and draw one ball blindfolded.’’
Define the proposition:
Ei  ‘‘the ith ball is drawn’’; 1  i  10:
Since the prior information is indifferent to these ten possibilities, Equation (2.26)
applies.
pðEijIÞ ¼ 1
10 ; 1  i  10:
(2:27)
The proposition R  ‘‘that we draw a red ball’’ is equivalent to ‘‘we draw ball 3, 4,
or 7.’’ This can be written as the logical sum statement:
R ¼ E3 þ E4 þ E7:
(2:28)
It follows from the extended sum rule that
pðRjIÞ ¼ pðE3 þ E4 þ E7jIÞ ¼ 3
10 ;
(2:29)
38
Probability theory as extended logic

in accordance with our intuition.
More generally, if there are N such balls, and the proposition R is defined to be true
for any specified subset of M of them, and false on the rest, then we have
pðRjIÞ ¼ M
N :
(2:30)
2.7 Summary
Rather remarkably, the three desiderata of Section 2.5.1 have enabled us to arrive at a
theory of extended logic together with a particular scale for measuring the plausibility
of any hypothesis conditional on given information. We have shown that the rules for
manipulating plausibility are the product and sum rules. The particular scale of
plausibility we have adopted, now called probability, is determined by the data in a
way that agrees with our intuition. We also showed that in the limit of complete
information (certainty), the theory gives the same conclusions as the strong syllogisms
of deductive inference.
The main constructive requirement which determined the product and sum rules
was the desideratum of structural consistency, ‘‘If a conclusion can be reasoned out in
more than one way, every possible way must lead to the same result.’’ This does not
mean that our rules have been proved consistent,1 only that any other rules which
represent degrees of plausibility by real numbers, but which differ in content from the
product and sum rules, will lead to a violation of one of our desiderata.
Apart from the justification for probability as extended logic, the value of this
approach to solving inference problems is being demonstrated on a regular basis in a
wide variety of areas leading both to new scientific discoveries and a new level of
understanding. Modern computing power permits a simple comparison of the power
of different approaches in the analysis of well-understood simulated data sets. Some
examples of the power of Bayesian inference will be brought out in later chapters.
2.8 Problems
1. Construct a truth table to show
A; B ¼ A þ B:
2. Construct a truth table to show
A þ ðB; CÞ ¼ ðA þ BÞ; ðA þ CÞ:
1 According to Go¨ del’s theorem, no mathematical system can provide a proof of its own consistency.
2.8 Problems
39

3. With reference to Table 2.2, construct a truth table to show that
f8ðA; BÞ ¼ A þ B:
4. Based on the available evidence, the probability that Jones is guilty is equal to 0.7,
the probability that Susan is guilty is equal to 0.6, and the probability that both are
guilty is equal to 0.5. Compute the probability that Jones is guilty and/or Susan is
guilty.
5. The probability that Mr. Smith will make a donation is equal to 0.5, if his brother
Harry has made a donation. The probability that Harry will make a donation is
equal to 0.02. What is the probability that both men will make a donation?
40
Probability theory as extended logic

3
The how-to of Bayesian inference
3.1 Overview
The first part of this chapter is devoted to a brief description of the methods and
terminology employed in Bayesian inference and can be read as a stand-alone intro-
duction on how to do Bayesian analysis.1 Following a review of the basics in Section
3.2, we consider the two main inference problems: parameter estimation and model
selection. This includes how to specify credible regions for parameters and how to
eliminate nuisance parameters through marginalization. We also learn that Bayesian
model comparison has a built-in ‘‘Occam’s razor,’’ which automatically penalizes
complicated models, assigning them large probabilities only if the complexity of the
data justifies the additional complication of the model. We also learn how this penalty
arises through marginalization and depends both on the number of parameters and
the prior ranges of these parameters.
We illustrate these features with a detailed analysis of a toy spectral line problem
and in the process introduce the Jeffreys prior and learn how different choices of priors
affect our conclusions. We also have a look at a general argument for selecting priors
for location and scale parameters in the early phases of an investigation when our state
of ignorance is very high. The final section illustrates how Bayesian analysis provides
valuable new insights on systematic errors and how to deal with them.
I recommend that Sections 3.2 to 3.5 of this chapter be read twice; once quickly,
and again after seeing these ideas applied in the detailed example treated in Sections
3.6 to 3.11.
3.2 Basics
In Bayesian inference, the viability of each member of a set of rival hypotheses, fHig, is
assessed in the light of some observed data, D, by calculating the probability of each
hypothesis, given the data and any prior information, I, we may have regarding the
1 The treatment of this topic is a revised version of Section 2 of a paper by Gregory and Loredo (1992), which is
reproduced here with the permission of the Astrophysical Journal.
41

hypotheses and data. Following a notation introduced by Jeffreys (1961), we write
such a probability as pðHijD; IÞ, explicitly denoting the prior information by the
proposition, I, to the right of the bar. At the very least, the prior information must
specify the class of alternative hypotheses being considered (hypothesis space of inter-
est), and the relationship between the hypotheses and the data (the statistical model).
The basic rules for manipulating Bayesian probabilities are the sum rule,
pðHijIÞ þ pðHijIÞ ¼ 1;
(3:1)
and the product rule,
pðHi; DjIÞ ¼ pðHijIÞpðDjHi; IÞ
¼ pðDjIÞpðHijD; IÞ:
(3:2)
The various symbols appearing as arguments should be understood as propositions;
for example, D might be the proposition, ‘‘N photons were counted in a time T.’’ The
symbol Hi signifies the negation of Hi (a proposition that is true if one of the
alternatives to Hi is true), and ðHi; DÞ signifies the logical conjunction of Hi and D
(a proposition that is true only if Hi and D are both true). The rules hold for any
propositions, not just those indicated above.
Throughout this work, we will be concerned with exclusive hypotheses, so that if
one particular hypothesis is true, all others are false. For such hypotheses, we saw in
Section 2.5.3 that the sum and product rules imply the generalized sum rule,
pðHi þ HjjIÞ ¼ pðHijIÞ þ pðHjjIÞ:
(3:3)
To say that the hypothesis space of interest consists of n mutually exclusive hypotheses
means that for the purpose of the present analysis, we are assuming that one of them is
true and the objective is to assign a probability to each hypothesis in this space, based
on D; I. We will use normalized prior probability distributions, unless otherwise
stated, such that
X
i
pðHijIÞ ¼ 1:
(3:4)
Here a ‘‘þ’’ within a probability symbol stands for logical disjunction, so that
Hi þ Hj is a proposition that is true if either Hi or Hj is true.
One of the most important calculating rules in Bayesian inference is Bayes’ theorem,
found by equating the two right hand sides of Equation (3.2) and solving for pðHijD; IÞ:
pðHijD; IÞ ¼ pðHijIÞpðDjHi; IÞ
pðDjIÞ
:
(3:5)
42
The how-to of Bayesian inference

Bayes’ theorem describes a type of learning: how the probability for each member of
a class of hypotheses should be modified on obtaining new information, D. The
probabilities for the hypotheses in the absence of D are called their prior probabilities,
pðHijIÞ, and those including the information D are called their posterior probabilities,
pðHijD; IÞ. The quantity pðDjHi; IÞ is called the sampling probability for D, or the
likelihood of Hi, and the quantity pðDjIÞ is called the prior predictive probability for D,
or the global likelihood for the entire class of hypotheses.
All of the rules we have written down so far show how to manipulate known
probabilities to find the values of other probabilities. But to be useful in applications,
we additionally need rules that assign numerical values or functions to the initial direct
probabilities that will be manipulated. For example, to use Bayes’ theorem, we need to
know the values of the three probabilities on the right side of Equation (3.5). These
three probabilities are not independent. The quantity pðDjIÞ must satisfy the require-
ment that the sum of the posterior probabilities over the hypothesis space of interest is
equal to 1.
X
i
pðHijD; IÞ ¼
P
i pðHijIÞpðDjHi; IÞ
pðDjIÞ
¼ 1:
(3:6)
Therefore,
pðDjIÞ ¼
X
i
pðHijIÞpðDjHi; IÞ:
(3:7)
That is, the denominator of Bayes’ theorem, which does not depend on Hi, must be
equal to the sum of the numerator over Hi. It thus plays the role of a normalization
constant.
3.3 Parameter estimation
We frequently deal with problems in which a particular model is assumed to be
true and the hypothesis space of interest concerns the values of the model
parameters. For example, in a straight line model, the two parameters are the
intercept and slope. We can look at this problem as a hypothesis space that is
labeled, not by discrete numbers, but by the possible values of two continuous
parameters. In such cases, the quantity of interest (see also Section 1.3.2) is a
probability density function or PDF. More generally, ‘PDF’ is an abbreviation for
a probability distribution function which can apply to both discrete and contin-
uous parameters. For example, given some prior information, M, specifying a
parameterized model with one parameter, , pðjMÞ is the prior density for ,
which means that pðjMÞd is the prior probability that the true value of the
parameter is in the interval ½; þ d. We use the same symbol, pð. . .Þ, for prob-
abilities and PDFs; the nature of the argument will identify which use is intended.
3.3 Parameter estimation
43

Bayes’ theorem, and all the other rules just discussed, hold for PDFs, with all sums
replaced by integrals. For example, the global likelihood for model M can be calcu-
lated with the continuous counterpart of Equation (3.7),
pðDjMÞ ¼
Z
d pðjMÞpðDj; MÞ ¼ LðMÞ:
(3:8)
In words, the global likelihood of a model is equal to the weighted average likelihood
for its parameters. We will utilize the global likelihood of a model in Section 3.5 where
we deal with model comparison and Occam’s razor.
If there is more than one parameter, multiple integrals are used. If the prior density
and the likelihood are assigned directly, the global likelihood is an uninteresting
normalization constant. The posterior PDF for the parameters is simply proportional
to the product of the prior and the likelihood.
The use of Bayes’ theorem to determine what one can learn about the values of
parameters from data is called parameter estimation, though strictly speaking,
Bayesian inference does not provide estimates for parameters. Rather, the Bayesian
solution to the parameter estimation problem is the full posterior PDF, pðjD; MÞ, and
not just a single point in parameter space. Of course, it is useful to summarize this
distribution for textual, graphical, or tabular display in terms of a ‘‘best-fit’’ value and
‘‘error bars.’’ Possible summaries of the best-fit values are the posterior mode (most
probable value of ) or the posterior mean,
hi ¼
Z
d  pðjD; MÞ:
(3:9)
If the mode and mean are very different, the posterior PDF is too asymmetric to be
adequately summarized by a single estimate. An allowed range for a parameter with
probability content C (e.g., C ¼ 0:95 or 95%) is provided by a credible region, or
highest posterior density region, R, defined by
Z
R
d pðjD; MÞ ¼ C;
(3:10)
with the posterior density inside R everywhere greater than that outside it. We some-
times speak picturesquely of the region of parameter space that is assigned a large
density as the ‘‘posterior bubble.’’ In practice, the probability (density function)
pðjD; MÞ is represented by a finite list of values, pi, representing the probability in
discrete intervals of .
A simple way to compute the credible region is to sort these probability values in
descending order. Then starting with the largest value, add successively smaller pi
values until adding the next value would exceed the desired value of C. At each step
keep track of the corresponding i value. The credible region is the range of  that just
44
The how-to of Bayesian inference

includes all the i values corresponding to the pi values added. The boundaries of the
credible region are obtained by sorting these i values and taking the smallest and
largest values.
3.4 Nuisance parameters
Frequently, a parameterized model will have more than one parameter, but we will
want to focus attention on a subset of the parameters. For example, we may want to
focus on the implications of the data for the frequency of a periodic signal, independent
of the signal’s amplitude, shape, or phase. Or we may want to focus on the implications
of spectral data for the parameters of some line feature, independent of the shape of the
background continuum. In such problems, the uninteresting parameters are known as
nuisance parameters. As always, the full Bayesian inference is the full joint posterior
PDF for all of the parameters; but its implications for the parameters of interest can be
simply summarized by integrating out the nuisance parameters. Explicitly, if model M
has two parameters,  and , and we are interested only in , then it is a simple
consequence of the sum and product rules (see Section 1.5) that,
pðjD; MÞ ¼
Z
d pð; jD; MÞ:
(3:11)
For historical reasons, the procedure of integrating out nuisance parameters is
called marginalization, and pðjD; MÞ is called the marginal posterior PDF for .
Equation (3.8) for the global likelihood is a special case of marginalization in which
all of the model parameters are marginalized out of the joint prior distribution,
pðD; jMÞ.
The use of marginalization to eliminate nuisance parameters is one of the most
important technical advantages of Bayesian inference over standard frequentist sta-
tistics. Indeed, the name ‘‘nuisance parameters’’ originated in frequentist statistics
because there is no general frequentist method for dealing with such parameters; they
are indeed a ‘‘nuisance’’ in frequentist statistics. Marginalization plays a very import-
ant role in this work. We will see a detailed example of marginalization in action in
Section 3.6.
3.5 Model comparison and Occam’s razor
Often, more than one parameterized model will be available to explain a phenomenon,
and we will wish to compare them. The models may differ in form or in number of
parameters. Use of Bayes’ theorem to compare competing models by calculating the
probability of each model as a whole is called model comparison. Bayesian model
comparison has a built-in ‘‘Occam’s razor:’’ Bayes’ theorem automatically penalizes
complicated models, assigning them large probabilities only if the complexity of the
3.5 Model comparison and Occam’s razor
45

data justifies the additional complication of the model. See Jeffreys and Berger (1992)
for a historical account of the connection between Occam’s (Ockham’s) razor and
Bayesian analysis.
Model comparison calculations require the explicit specification of two or more
specific alternative models, Mi. We take as our prior information the proposition that
one of the models under consideration is true. Symbolically, we might write this as
I ¼ M1 þ M2 þ    þ MN, where the ‘‘þ’’ symbol here stands for disjunction (‘‘or’’).
Given this information, we can calculate the probability for each model with Bayes’
theorem:
pðMijD; IÞ ¼ pðMijIÞpðDjMi; IÞ
pðDjIÞ
:
(3:12)
We recognize pðDjMi; IÞ as the global likelihood for model Mi, which we can
calculate according to Equation (3.8). The term in the denominator is again a normal-
ization constant, obtained by summing the products of the priors and the global
likelihoods of all models being considered. Model comparison is thus completely
analogous to parameter estimation: just as the posterior PDF for a parameter is
proportional to its prior times its likelihood, so the posterior probability for a
model as a whole is proportional to its prior probability times its global likelihood.
It is often useful to consider the ratios of the probabilities of two models, rather than
the probabilities directly. The ratio,
Oij ¼ pðMijD; IÞ=pðMjjD; IÞ;
(3:13)
is called the odds ratio in favor of model Mi over model Mj. From Equation (3.12),
Oij ¼ pðMijIÞ
pðMjjIÞ
pðDjMi; IÞ
pðDjMj; IÞ
 pðMijIÞ
pðMjjIÞ Bij;
(3:14)
where the first factor is the prior odds ratio, and the second factor is called the Bayes
factor. Note: the normalization constant in Equation (3.12) drops out of the odds
ratio; this can make the odds ratio somewhat easier to work with. The odds ratio is
also conceptually useful when one particular model is of special interest. For example,
suppose we want to compare a constant rate model with a class of periodic alternatives,
and will thus calculate the odds in favor of each alternative over the constant
model.
If we have calculated the odds ratios, Oi1, in favor of each model over model M1, we
can find the probabilities for each model in terms of these odds ratios as follows:
X
Nmod
i¼1
pðMijD; IÞ ¼ 1;
(3:15)
46
The how-to of Bayesian inference

where Nmod is the total number of models considered. Dividing through by pðM1jD; IÞ,
we have
1
pðM1jD; IÞ ¼
X
Nmod
i¼1
Oi1:
(3:16)
Comparing Equation (3.16) to the expression for Oi1, given by
Oi1 ¼ pðMijD; IÞ=pðM1jD; IÞ;
(3:17)
we have the result that
pðMijD; IÞ ¼
Oi1
PNmod
i¼1 Oi1
;
(3:18)
where of course O11 ¼ 1. If there are only two models, the probability of M2 is given by
pðM2jD; IÞ ¼
O21
1 þ O21
¼
1
1 þ
1
O21
:
(3:19)
In this work, we will assume that we have no information leading to a prior
preference for one model over another, so the prior odds ratio will be unity, and the
odds ratio will equal the Bayes factor, the ratio of global likelihoods. A crucial
consequence of the marginalization procedure used to calculate global likelihoods is
that the Bayes factor automatically favors simpler models unless the data justify the
complexity of more complicated alternatives. This is illustrated by the following
simple example.
Imagine comparing two models: M1 with a single parameter, , and M0 with  fixed
at some default value 0 (so M0 has no free parameters). To calculate the Bayes factor
B10 in favor of model M1, we will need to perform the integral in Equation (3.8) to
compute pðDjM1; IÞ, the global likelihood of M1. To develop our intuition about the
Occam penalty, we will carry out a back-of-the-envelope calculation for the Bayes
factor. Often the data provide us with more information about parameters than we
had without the data, so that the likelihood function, LðÞ ¼ pðDj; M1; IÞ, will be
much more ‘‘peaked’’ than the prior, pðjM1; IÞ. In Figure 3.1 we show a Gaussian-
looking likelihood centered at ^, the maximum likelihood value of , together with
a flat prior for . Let  be the characteristic width of the prior. For a flat prior,
we have that
Z

d pðjM1; IÞ ¼ pðjM1; IÞ ¼ 1:
(3:20)
Therefore, pðjM1; IÞ ¼ 1=.
3.5 Model comparison and Occam’s razor
47

The likelihood has a characteristic width2 which we represent by . The character-
istic width is defined by
Z

d pðDj; M1; IÞ ¼ pðDj^; M1; IÞ  :
(3:21)
Then we can approximate the global likelihood (Equation (3.8)) for M1 in the
following way:
pðDjM1; IÞ ¼
Z
d pðjM1; IÞpðDj; M1; IÞ ¼ LðM1Þ
¼ 1

Z
d pðDj; M1; IÞ
 pðDj^; M1; IÞ 

or alternatively;
LðM1Þ  Lð^Þ 
 :
(3:22)
Since model M0 has no free parameters, no integral need be calculated to find its
global likelihood, which is simply equal to the likelihood for model M1 for  ¼ 0,
pðDjM0; IÞ ¼ pðDj0; M1; IÞ ¼ Lð0Þ:
(3:23)
Thus the Bayes factor in favor of the more complicated model is
B10  pðDj^; M1; IÞ
pðDj0; M1; IÞ

 ¼ Lð^Þ
Lð0Þ

 :
(3:24)
Parameter θ
p(D|θ, M1, I ) = L(θ)
L(θ) = p(D|θ, M1, I )
p(θ|M1,I ) = 1
∆θ
θ
δθ
∆θ
∧
∧
∧
Figure 3.1 The characteristic width  of the likelihood peak and  of the prior.
2 If the likelihood function is really a Gaussian and the prior is flat, it is simple to show that  ¼ 
ﬃﬃﬃﬃﬃﬃ
2p
p
, where  is the
standard deviation of the posterior PDF for .
48
The how-to of Bayesian inference

The likelihood ratio in the first factor can never favor the simpler model because M1
contains it as a special case. However, since the posterior width, , is narrower than
the prior width, , the second factor penalizes the complicated model for any
‘‘wasted’’ parameter space that gets ruled out by the data. The Bayes factor will thus
favor the more complicated model only if the likelihood ratio is large enough to
overcome this penalty.
Equation (3.22) has the form of the best-fit likelihood times the factor that penalizes
M1. In the above illustrative calculation we assumed a simple Gaussian likelihood
function for convenience. In general, the actual likelihood function can be very com-
plicated with several peaks. However, one can always write the global likelihood of a
model with parameter , as the maximum value of its likelihood times some factor, :
pðDjM; IÞ  Lmax:
(3:25)
The second factor, , is called the Occam factor associated with the parameters, .
It is so named because it corrects the likelihood ratio usually considered in statistical
tests in a manner that quantifies the qualitative notion behind ‘‘Occam’s razor:’’
simpler explanations are to be preferred unless there is sufficient evidence in favor
of more complicated explanations. Bayes’ theorem both quantifies such evidence and
determines how much additional evidence is ‘‘sufficient’’ through the calculation of
global likelihoods.
Suppose M1 has two parameters  and , then following Equation (3.22), we can
write
pðDjM1; IÞ ¼
ZZ
dd pðjM1; IÞpðjM1; IÞpðDj; ; M1; IÞ
 pðDj^; ^; M1; IÞ 


 ¼ Lmax:
(3:26)
The above equation assumes independent flat priors for the two parameters. It is clear
from Equation (3.26) that the total Occam penalty, total ¼ , can become very
large. For example, if = ¼ = ¼ 0:01 then total ¼ 104. Thus for the Bayes
factor in Equation (3.24) to favor M1, the ratio of the maximum likelihoods,
pðDj^; ^; M1; IÞ
pðDjM0; IÞ
¼ LmaxðM1Þ
LmaxðM0Þ
must be ‡104. Unless the data argue very strongly for the greater complexity of M1
through the likelihood ratio, the Occam factor will ensure we favor the simpler model.
We will explore the Occam factor further in a worked example in Section 3.6.
In the above calculations, we have specifically made a point of identifying the Occam
factors and how they arise. In many instances we are not interested in the value of the
Occam factor, but only in the final posterior probabilities of the competing models.
3.5 Model comparison and Occam’s razor
49

Because the Occam factor arises automatically in the marginalization process, its effect
will be present in any model selection calculation.
3.6 Sample spectral line problem
In this section, we will illustrate many of the above points in a detailed Bayesian
analysis of a toy spectral line problem. In a real problem, as opposed to the
hypothetical one discussed below, there could be all sorts of complicated prior
information. Although Bayesian analysis can readily handle these complexities,
our aim here is to bring out the main features of the Bayesian approach as simply
as possible. Be warned; even though it is a relatively simple problem, our detailed
solution, together with commentary and a summary of the lessons learned, will
occupy quite a few pages.
3.6.1 Background information
In this problem, we suppose that two competing grand unification theories have
been proposed. Each one is championed by a Nobel prize winner in physics. We want
to compute the relative probability of the truth of each theory based on our prior
(background) information and some new data. Both theories make definite predic-
tions in energy ranges beyond the reach of the present generation of particle accel-
erators. In addition, theory 1 uniquely predicts the existence of a new short-lived
baryon which is expected to form a short-lived atom and give rise to a spectral line at
an accurately calculable radio wavelength. Unfortunately, it is not feasible to detect
the line in the laboratory. The only possibility of obtaining a sufficient column
density of the short-lived atom is in interstellar space. Prior estimates of the
line strength expected from the Orion nebula according to theory 1 range from 0.1
to 100 mK.
Theory 1 also predicts the line will have a Gaussian line shape of the form
T exp
ði  oÞ2
22
L
(
)
ðabbreviated by TfiÞ;
(3:27)
where the signal strength is measured in temperature units of mK and T is the
amplitude of the line. The frequency, i, is in units of channel number and o ¼ 37.
The width of the line profile is characterized by L, and L ¼ 2 channel numbers. The
predicted line shape is shown in Figure 3.2.
Data:
To test this prediction, a new spectrometer was mounted on the James Clerk Maxwell
telescope on Mauna Kea and the spectrum shown in Figure 3.3 was obtained. The
spectrometer has 64 frequency channels with neighboring channels separated by
50
The how-to of Bayesian inference

0:5 L. All channels have Gaussian noise characterized by  ¼ 1 mK. The noise in
separate channels is independent. The data are given in Table 3.1.
Let D be a proposition representing the data from the spectrometer.
D  D1; D2; . . . ; DN;
N ¼ 64
(3:28)
where D1 is a proposition that asserts that ‘‘the data value recorded in the first channel
was d1.’’
0
10
20
30
40
50
60
Channel number
 –1
0
1
2
3
Signal strength (mK)
Spectral Line Data
Figure 3.3 Measured spectrum.
0
10
20
30
40
50
60
Channel number
0
0.2
0.4
0.6
0.8
1
Signal strength (mK)
Figure 3.2 Predicted spectral shape according to theory 1.
3.6 Sample spectral line problem
51

Question: Which theory is more probable?
Based on our current state of information, which includes just the above prior
information and the measured spectrum, what do we conclude about the relative
probabilities of the two competing theories and what is the posterior PDF for the line
strength?
Hypothesis space:
M1  ‘‘Theory 1 correct, line exists’’
M2  ‘‘Theory 2 correct, no line predicted’’
3.7 Odds ratio
To answer the above question, we compute the odds ratio (abbreviated simply by the
odds) of model M1 to model M2.
O12 ¼ pðM1jD; IÞ
pðM2jD; IÞ :
(3:29)
Table 3.1 Spectral line data consisting of 64 frequency channels (#) obtained with a radio
astronomy spectrometer. The output voltage from each channel has been calibrated in units
of effective black body temperature expressed in mK. The existence of negative values arises
from receiver channel noise which gives rise to both positive and negative fluctuations.
#
mK
#
mK
#
mK
#
mK
1
1.420
17
0.937
33
0.248
49
0.001
2
0.468
18
1.331
34
1.169
50
0.360
3
0.762
19
1.772
35
0.915
51
0.497
4
1.312
20
0.530
36
1.113
52
0.072
5
2.029
21
0.330
37
1.463
53
1.094
6
0.086
22
1.205
38
2.732
54
1.425
7
1.249
23
1.613
39
0.571
55
0.283
8
0.368
24
0.300
40
0.865
56
1.526
9
0.657
25
0.046
41
0.849
57
1.174
10
1.294
26
0.026
42
0.171
58
0.558
11
0.235
27
0.519
43
1.031
59
1.282
12
0.192
28
0.924
44
1.105
60
0.384
13
0.269
29
0.230
45
0.344
61
0.120
14
0.827
30
0.877
46
0.087
62
0.187
15
0.685
31
0.650
47
0.351
63
0.646
16
0.702
32
1.004
48
1.248
64
0.399
52
The how-to of Bayesian inference

From Equation (3.14) we can write
O12 ¼ pðM1jIÞ
pðM2jIÞ
pðDjM1; IÞ
pðDjM2; IÞ
 pðM1jIÞ
pðM2jIÞ B12
(3:30)
where pðM1jIÞ=pðM2jIÞ is the prior odds, and pðDjM1; IÞ=pðDjM2; IÞ is the global
likelihood ratio, which is also called the Bayes factor.
Based on the prior information given in the statement of the problem, we assign the
prior odds ¼ 1, so our final odds is given by,
O12 ¼ pðDjM1; IÞ
pðDjM2; IÞ
ðthe Bayes factorÞ:
(3:31)
To obtain pðDjM1; IÞ, the global likelihood of M1, we need to marginalize over its
unknown parameter, T. From Equation (3.8), we can write
pðDjM1; IÞ ¼
Z
dT pðTjM1; IÞpðDjM1; T; IÞ:
(3:32)
In the following section we will consider what form of prior to use for pðTjM1; IÞ. In
Section 3.7.2 we will show how to evaluate the likelihood, pðDjM1; T; IÞ.
3.7.1 Choice of prior p(T|M1, I )
We need to evaluate the global likelihood of model M1 for use in the Bayes factor. One
of the items we need in this calculation is pðTjM1; IÞ, the prior for T. Choosing a prior
is an important part of any Bayesian calculation and we will have a lot to say about
this topic in Section 3.10 and other chapters, e.g., Chapter 8, and Sections 9.2.3, 13.3
and 13.4. For this example, we will investigate two common choices: the uniform prior
and the Jeffreys prior.3
Uniform prior
Suppose we chose a uniform prior for pðTjM1; IÞ in the range Tmin  T  Tmax
pðTjM1; IÞ ¼
1
T ;
(3:33)
where T ¼ Tmax  Tmin.
There is a problem with this prior if the range of T is large. In the current example
Tmax ¼ 100 and Tmin ¼ 0:1. To illustrate the problem, we compare the probability that
3 If the lower limit on T extended all the way to zero, we would not be able to use a Jeffreys prior because of the infinity
at T ¼ 0. A modified version of the form, pðTjM1; IÞ ¼ 1=fðT þ aÞ ln½ða þ TmaxÞ=ag, where a is a constant, eliminates
this singularity. This modified Jeffreys behaves like a uniform prior for T < a and a Jeffreys for T > a.
3.7 Odds ratio
53

T lies in the upper decade of the prior range (10 to 100 mK) to the lowest decade (0.1 to
1 mK). This is given by
R 100
10 pðTjM1; IÞdT
R 1
0:1 pðTjM1; IÞdT
¼ 100:
(3:34)
We see that in this case, a uniform prior implies that the line strength is 100 times
more probable to be in the top decade of the predicted range than the bottom, i.e., it is
much more probable that T is strong than weak. Usually, expressing great uncertainty
in some quantity corresponds more closely to a statement of scale invariance or equal
probability per decade. In this situation, we recommend using a Jeffreys prior which is
scale invariant.
Jeffreys prior
The form of the prior which represents equal probability per decade (scale invariance)
is given by pðTjM1; IÞ ¼ k=T, where k ¼ constant.
Z 1
0:1
pðTjM1; IÞdT ¼ k
Z 1
0:1
dT
T ¼ k ln 10 ¼
Z 100
10
pðTjM1; IÞdT:
(3:35)
We can evaluate k from the requirement that
Z Tmax
Tmin
pðTjM1; IÞdT ¼ 1 ¼ k ln Tmax
Tmin


(3:36)
1
k ¼ ln Tmax
Tmin


:
(3:37)
Thus, the form of the Jeffreys prior is given by
pðTjM1; IÞ ¼
1
T ln Tmax=Tmin
ð
Þ :
(3:38)
A convenient way of summarizing the above comparison between the uniform and
Jeffreys prior is to plot the probability of each distribution per logarithmic interval or
pðln TjM1; IÞ. This can be obtained from the condition that the probability in the
interval T to T þ dT must equal the probability in the transformed interval ln T to
ln T þ d ln T.
pðTjM1; IÞdT ¼ pðln TjM1; IÞd ln T
pðTjM1; IÞ ¼ pðln TjM1; IÞ d ln T
dT
¼ 1
T pðln TjM1; IÞ
pðln TjM1; IÞ ¼ T  pðTjM1; IÞ:
(3:39)
54
The how-to of Bayesian inference

Figure 3.4 compares plots of the probability density function (PDF), pðTjM1; IÞ
(left panel), and the probability per logarithmic interval (PPLI), T  pðTjM1; IÞ (right
panel), for the uniform and Jeffreys priors.
3.7.2 Calculation of p(D|M1,T, I )
Let di represent the measured data value for the ith channel of the spectrometer.
According to model M1,
di ¼ Tfi þ ei;
(3:40)
where ei is an error term. Our prior information indicates that this error is caused by
receiver noise which has a Gaussian distribution with a standard deviation of . Also,
from Equation (3.27), we have
fi ¼ exp
ði  oÞ2
22
L
(
)
:
(3:41)
Assuming M1 is true, then if it were not for the error ei, di would equal Tfi. Let Ei  ‘‘a
proposition asserting that the ith error value is in the range ei to ei þ dei.’’ In this case,
we can show (see Section 4.8) that pðDijM1; T; IÞ ¼ pðEijM1; T; IÞ. If all the Ei are
independent4 then
pðDjM1; T; IÞ ¼ pðD1; D2; . . . ; DNjM1; T; IÞ
¼ pðE1; E2; . . . ; ENjM1; T; IÞ
¼ pðE1jM1; T; IÞpðE2jM1; T; IÞ . . . pðENjM1; T; IÞ
¼
Y
N
i¼1
pðEijM1; T; IÞ
(3:42)
0.1
1
10
100
T
0
0.2
0.4
0.6
0.8
1
1.2
1.4
PDF
Uniform
Jeffreys
0.1
1
10
100
T
0
0.2
0.4
0.6
0.8
1
PPLI = T × PDF
Uniform
Jeffreys
Figure 3.4 The left panel shows the probability density function (PDF), pðTjM1; IÞ, for the
uniform and Jeffreys priors. The right panel shows the probability per logarithmic interval
(PPLI), T  pðTjM1; IÞ.
4 We deal with the effect of correlated errors in Section 10.2.2.
3.7 Odds ratio
55

where QN
i¼1 stands for the product of N of these terms.From the prior information, we
can write
pðEijM1; T; IÞ ¼
1

ﬃﬃﬃﬃﬃﬃ
2p
p
exp  e2
i
22


¼
1

ﬃﬃﬃﬃﬃﬃ
2p
p
exp
 ðdi  TfiÞ2
22
(
)
:
(3:43)
It is apparent that pðEijM1; T; IÞ is a probability density function since ei, the value of
the error for channel i, is a continuous variable. The factor ð
ﬃﬃﬃﬃﬃﬃ
2p
p
Þ1 in the above
equation ensures that the integral over ei from 1 to þ1 is equal to 1. In Figure 3.5,
pðEijM1; T; IÞ is shown proportional to the height of the Gaussian error curve at the
position of the actual data value di.
Combining Equations (3.42) and (3.43), we obtain the probability of the entire data set
pðDjM1; T; IÞ ¼
Y
N
i ¼ 1
1

ﬃﬃﬃﬃﬃﬃ
2p
p
exp
 ðdi  TfiÞ2
22
(
)
¼ ð2pÞN=2N exp

P
iðdi  TfiÞ2
22
(
)
:
(3:44)
In Section 3.7.4, we will need the maximum value of the likelihood given by Equation
(3.44). Since we now know all the quantities in Equation (3.44) except T, we can
readily compute the likelihood as a function of T in the prior range 0:1  T  100. The
likelihood has a maximum ¼ 8:520  1037 (called the maximum likelihood) at
T ¼ 1:561 mK.
0
2
4
6
8
Signal strength (mK)
0
0.1
0.2
0.3
0.4
0.5
Probability density
p(Ei |M1, T, I ) 
proportional
to line height
ei
i th data value di
T f i predicted i th value
Figure 3.5 Probability of getting a data value di a distance ei away from the predicted value is
proportional to the height of the Gaussian error curve at that location.
56
The how-to of Bayesian inference

What we want is pðDjM1; IÞ, the global likelihood of M1, for use in Equation (3.31).
We now evaluate pðDjM1; IÞ, given by Equation (3.32), for the two different priors
discussed in Section 3.7.1, where we argued that the Jeffreys prior matches much more
closely the prior information given in this particular problem. Nevertheless, it is
interesting to explore what effect the choice of a uniform prior would have on our
conclusions. For this reason, we will do the calculations for both priors.
Uniform prior case:
pðDjM1; IÞ ¼ ð2pÞN=2N
T
exp T P difi
2

 Z Tmax
Tmin
dT exp T P difi
2


exp T P difi
2


¼ 1:131  1038:
(3:45)
According to Equation (3.25), we can always write the global likelihood of a model as
the maximum value of its likelihood times an Occam factor, T, which arises in this
case from marginalizing T.
pðDjM1; IÞ ¼ LmaxðM1Þ  T
¼ maximum value of ½pðDjM1; T; IÞ  Occam factor
¼ 8:520  1037 T:
(3:46)
Comparison of the results of Equations (3.45) and (3.46) leads directly to a value for
the Occam factor, associated with our prior uncertainty in the T parameter, of
T ¼ 0:0133.
Jeffreys prior case:
pðDjM1; IÞ ¼ ð2pÞN=2N
lnðTmax=TminÞ exp  P d2
i
22



Z Tmax
Tmin
dT
exp T P di fi
2


exp  T2 P f 2i
22


T
¼ 1:239  1037:
(3:47)
In this case the Occam factor associated with our prior uncertainty in the T
parameter, based on a Jeffreys prior, is 0.145. Note: the Occam factor based on the
Jeffreys prior is a factor of  10 less of a penalty than for the uniform prior for the
same parameter.
3.7 Odds ratio
57

3.7.3 Calculation of p(D|M2, I )
Model M2 assumes the spectrum is consistent with noise and has no free parameters so
in analogy to Equation (3.40), we can write
di ¼ 0 þ ei
(3:48)
where ei ¼ Gaussian noise with a standard deviation of . Assuming M2 is true, then if
it were not for the noise ei, di would equal 0.
pðDjM2; IÞ ¼ ð2pÞN=2 N exp 
P d 2
i
22


¼ 1:133  1038:
(3:49)
Since this model has no free parameters, there is no Occam factor, so the global
likelihood is also the maximum likelihood, LmaxðM2Þ, for M2.
3.7.4 Odds, uniform prior
Substitution of Equations (3.45) and (3.49) into Equation (3.31) leads to an odds ratio
for the uniform prior case given by
odds ¼
1
T
Z Tmax
Tmin
dT exp T P difi
2


exp  T 2 P f 2
i
22


:
(3:50)
For Tmin ¼ 0:1 mK and Tmax ¼ 100 mK, the odds ¼ 0:9986 and
pðM1jD; IÞ ¼
1
1 þ
1
odds
¼ 0:4996:
(3:51)
Although the ratio of the maximum likelihoods for the two models favors model M1,
by a factor of LmaxðM1Þ=LmaxðM2Þ ¼ 8:520  1037=1:131  1038  75, the ratio of
the global likelihoods marginally favors M2 because of the Occam factor which
penalizes M1 for its extra complexity.
3.7.5 Odds, Jeffreys prior
Substitution of Equations (3.47) and (3.49) into Equation (3.31) leads to an odds ratio
for the Jeffreys prior case, given by
odds ¼
1
lnðTmax=TminÞ
Z Tmax
Tmin
dT
exp T P difi
2


exp  T 2 P f 2
i
22


T
:
(3:52)
For Tmin ¼ 0:1 mK and Tmax ¼ 100 mK, the odds ¼ 10:94, and pðM1jD; IÞ ¼ 0:916.
58
The how-to of Bayesian inference

As noted earlier in this chapter, we consider the Jeffreys prior to be much more
consistent with the large uncertainty in signal strength which was part of the prior
information of the problem. On this basis, we conclude that for our current state of
information, pðM1jD; IÞ ¼ 0:916 and pðM2jD; IÞ ¼ 0:084.
3.8 Parameter estimation problem
Now that we have solved the model selection problem leading to a significant
preference for M1, which argues for the existence of the short-lived baryon, we
would like to compute pðTjD; M1; IÞ, the posterior PDF for the signal strength.
Again we will compute the result for both choices of prior for comparison, but
consider the Jeffreys result to be more reasonable for the current problem.
Again, start with Bayes’ theorem:
pðTjD; M1; IÞ ¼ pðTjM1; IÞpðDjM1; T; IÞ
pðDjM1; IÞ
/ pðTjM1; IÞpðDjM1; T; IÞ:
(3:53)
We have already evaluated pðDjM1; T; IÞ in Equation (3.44). All that remains is to plug
in our two different choices for the prior pðTjM1; IÞ.
Uniform prior case:
pðTjD; M1; IÞ / exp T P di fi
2


exp  T2 P f 2
i
22


(3:54)
Jeffreys prior case:
pðTjD; M1; IÞ / 1
T exp T P di fi
2


exp  T2 P f 2
i
22


:
(3:55)
Figure 3.6 shows the posterior PDF for the signal strength for both the uniform and
Jeffreys priors. As we saw earlier, the uniform prior favors stronger signals.
In our original spectrum, the line strength was comparable to the noise level. How
do the results change as we increase the line strength? Figure 3.7 shows a simulated
spectrum for a line strength equal to five times the noise  together with the estimated
posterior PDF for the line strength. The increase in line strength has a dramatic effect
on the odds which rise to 1:6  1012 for the uniform prior and 5:3  1012 for the
Jeffreys prior.
3.8.1 Sensitivity of odds to Tmax
Figure 3.8 is a plot of the dependence of the odds on the assumed value of Tmax for
both uniform and Jeffreys priors. We see that under the uniform prior, the odds are
3.8 Parameter estimation problem
59

much more strongly dependent on the prior range of T than for the Jeffreys case. In
both cases, the Occam’s razor penalizing M1 compared to M2 for its greater complex-
ity increases as the prior range for T increases. Model complexity depends not only on
the number of free parameters but also on their prior ranges.
In this problem, we assumed that both the center frequency and line width were
accurately predicted by M1; the only uncertain quantity was the line strength. Suppose
the center frequency and/or line width were uncertain as well. In this case, to compute
the odds ratio, we would have to marginalize over the prior ranges for these para-
meters as well, giving rise to additional Occam’s factors and a subsequent lowering of
the odds. This agrees with our intuition: the more uncertain our prior information
about the expected properties of the line, the less significance we attach to any bump in
the spectrum.
0
1
2
3
4
5
Line strength T
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
p(T \D, M1, I) 
Jeffreys
Uniform
Figure 3.6 Posterior PDF for the line strength, T, for uniform and Jeffreys priors.
0
10
20
30
40
50
60
Channel number
–1
0
1
2
3
4
5
6
Signal strength (mK)
Spectral Line Data
0
1
2
3
4
5
6
7
Line strength T
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Jeffreys
Uniform
p(T \D, M1, I) 
Figure 3.7 The left panel shows a spectrum with a stronger spectral line. The right panel shows
the computed posterior PDF for the line strength.
60
The how-to of Bayesian inference

3.9 Lessons
1. In the model selection problem, we are interested in the global probabilities of the two models
independent of the most probable model parameters. This was achieved using Bayes’
theorem and marginalizing over model M1’s parameter T, the signal strength (model M2
had no parameters pertaining to the spectral line data). An Occam’s razor automatically
arises each time a model parameter is marginalized, penalizing the model for prior parameter
space that gets ruled out by the data. The larger the prior range that is excluded by the
likelihood function, pðDjM1; T; IÞ, the greater the Occam penalty as can be seen from Figure
3.8. Recall that the global likelihood for a model is the weighted average likelihood for its
parameter(s). The weighting function is the prior for the parameter. Thus, the Occam penalty
can be very different for two different choices of prior (uniform and Jeffreys). The results are
always conditional on the truth of the prior which must be specified in the analysis, and there
is a need to seriously examine the consequences of the choice of prior.
2. When the prior range for a parameter spans many orders of magnitude, a uniform prior
implies that it is much more probable that the true value of the parameter is in the upper
decade. Often, a large prior parameter range can be taken to mean we are ignorant of the
scale, i.e., small values of the parameter are equally likely to large values. For these situations,
a useful choice is a Jeffreys prior, which corresponds to equal probability per decade (scale
invariance). Note: when the range of a prior is a small fraction of the central value, then the
conclusion will be the same whether a uniform or Jeffreys prior is used. In the spectrum
problem just analyzed, we started out with very crude prior information on the line strength
predicted by M1. Now that we have incorporated the new experimental information D, we
have arrived at a posterior probability for the line strength, pðTjD; M1; IÞ. Were we to obtain
more data, D2, we would set our new prior pðTjM1; I2Þ equal to our current posterior
pðTjD; M1; IÞ, i.e., I2 ¼ D; I. The question of whether to use a Jeffreys or uniform prior
would no longer be relevant.
1
1.5
2
2.5
3
3.5
4
Log10Tmax
0
2.5
5
7.5
10
12.5
15
17.5
Odds
Jeffreys
Uniform
Figure 3.8 The odds ratio versus upper limit on the predicted line strength ðTmaxÞ for the
uniform and Jeffreys priors.
3.9 Lessons
61

3. If the location and line width were also uncertain, we would have to marginalize over these
parameters as well, giving rise to other Occam factors which would decrease the odds still
further. For example, if the prior range for the expected channel number of the spectral line
were increased from less than 1 to 44 channels, the odds would decrease from  11 to 1,
assuming a uniform prior for the line location. We can also compute the marginal posterior
PDF for the line frequency for this case which is shown in Figure 3.9. This permits us to
update our knowledge of the line frequency given the data and assuming the theory is
correct. For further insights on this matter, see the discussion on systematic errors in
Section 3.11.
4. Once we established that model M1 was more probable, we were able to apply Bayes’
theorem again, to compute the posterior PDF for the line strength. Note: no Occam factors
arise in parameter estimation. Parameter estimation can be viewed as model selection
where the competing models all have exactly the same complexity so the Occam penalties
are identical and cancel out in the analysis. It can happen that the pðTjD; M1; IÞ can be very
small for values of T close to zero. One might be tempted to rule out M2 because it predicts
T ¼ 0, thus bypassing the model selection problem. This is not wise, however, because the
model selection analysis includes Occam factors that could rule out M1 compared to the
simpler M2. As we noted, these Occam factors do not appear in the parameter estimation
analysis.
5. In this toy problem, the spectral line data assume that any background continuum radiation
or instrumental DC level has been subtracted off, which can only be done to a certain
accuracy. It would be better to parameterize this DC level and marginalize over this para-
meter so that the effect of our uncertainty in this quantity (see Section 3.11) will be included in
our final odds ratio and spectral line parameter estimates. A still more complicated version of
this problem is if M1 simply predicts a certain prior range for the optical depth of the line but
10
20
30
40
Channel number
0.05
0.1
0.15
0.2
0.25
0.3
Probability density
Figure 3.9 Marginal posterior PDF for the line frequency, where the line frequency is expressed
as a spectrometer channel number.
62
The how-to of Bayesian inference

leaves unanswered whether the line will be seen in emission or absorption against the back-
ground continuum. In this problem, a Bayesian solution is still possible but will involve a
more complicated model of the spectral line data.
3.10 Ignorance priors
In the analysis of the spectral line problem of Section 3.7.1, we considered two
different forms of prior (uniform and Jeffreys) for the unknown line temperature
parameter. We learned that there was a strong reason for picking the Jeffreys prior in
this problem. What motivated a consideration of these particular priors in the first
place? In this section we will attempt to answer this question.
As we study any particular phenomenon, our state of knowledge changes. When we
are well into the study, our prior for the analysis of new data will be well defined by our
previous posterior. But in the earliest phase, our state of ‘‘ignorance’’ will be high. It is
therefore useful to have arguments to aid us in selecting an appropriate form of prior
to use in such situations. Of course, if we are completely ignorant we cannot even state
the problem of interest, and in that case we have no use for a prior. Let us suppose our
state of knowledge is sufficient to pose the problem but not much more. For example,
we might be interested in the location of the highest point on the equator of Pluto. Are
there any general arguments to help us select a suitable prior? In Section 2.6 we saw
how to use the Principle of Indifference to arrive at a probability distribution for a
discrete set of hypotheses.
In the discussion that follows, we will consider a general argument that suggests the
form of priors to use for two types of continuous parameters. We will make a
distinction between location parameters, and scale parameters. For example, consider
the location of an event in space. To describe this, we must locate the event with
respect to some origin and specify the size (scale) of our units of space (e.g., ft, m, light
years). The location of an event can be either a positive or negative quantity depending
on our choice of origin but the scale (size of our space units) is always a positive
quantity. We will first consider a prior for a location parameter.
Suppose we are interested in evaluating pðXjIÞ, where X  ‘‘a proposition asserting
that the location of the tallest tree along the shore of Lake Superior is between x and
x þ dx.’’ In this statement of the problem, x is measured with respect to a particular
survey stake. We will represent the probability density by the function fðxÞ.
What if we consider a different statement of the problem in which the only change is
that the origin of our distance measurement has been shifted by an amount c and we
are interested in pðX0jIÞ where x0 ¼ x þ c? If a shift of location (origin) can make the
problem appear in any way different, then it must be that we had some kind of prior
knowledge about location. In the limit of complete ignorance, the choice of prior
would be invariant to a shift in location. Although we are not completely ignorant it
still might be useful, in the earliest phase of an investigation, to adopt a prior which is
invariant to a shift in location. What form of prior does this imply? If we define our
3.10 Ignorance priors
63

state of ignorance to mean that the above two statements of the problem are equivalent,
then the desideratum of consistency demands that
pðXjIÞdX ¼ pðX0jIÞdX0 ¼ pðX0jIÞdðX þ cÞ ¼ pðX0jIÞdX:
(3:56)
From this it follows that
fðxÞ ¼ fðx0Þ ¼ fðx þ cÞ:
(3:57)
The solution of this equation is fðxÞ ¼ constant, so
pðXjIÞ ¼ constant:
(3:58)
In the Lake Superior problem, it is apparent that we have knowledge of the upper
ðxmaxÞ and lower ðxminÞ bounds of x, so the constant ¼ 1=ðxmax  xminÞ. If we are
ignorant of these limits then we refer to pðXjIÞ as an improper prior, meaning that it is
not normalized. An improper prior is useable in parameter estimation problems but is
not suitable for model selection problems, because the Occam factors depend on
knowing the prior range for each model parameter.
Now consider a problem where we are interested in the mean lifetime of a newly
discovered aquatic creature found in the ocean below the ice crust on the moon
Europa. We call the lifetime a scale parameter because it can only have positive values,
unlike a location parameter which can assume both positive and negative values. Let
T  ‘‘the mean lifetime is between  and  þ d.’’ What form of prior probability
density, pðT jIÞ, should we use in this case? We will represent the probability density by
the function gðÞ.
What if we consider a different statement of the problem in which the only change is
that the time is measured in units differing by a factor  ? Now we are interested in pðT 0jIÞ
where 0 ¼ . If we define our state of ignorance to mean that the two statements of the
problems are equivalent, then the desideratum of consistency demands that
pðT jIÞdT ¼ pðT 0jIÞdT 0 ¼ pðT 0jIÞdðT Þ ¼  pðT 0jIÞdT :
(3:59)
From this it follows that
gðÞ ¼ gð0Þ ¼ gðÞ:
(3:60)
The solution of this equation is gðÞ ¼ constant=, so
pðT jIÞ ¼ constant

:
(3:61)
This form of prior is called the Jeffreys prior after Sir Harold Jeffreys who first
suggested it. If we have knowledge of the upper (max) and lower (min) bounds of 
then we can evaluate the normalization constant. The result is
pðT jIÞ ¼
1
 ln ðmax=minÞ :
(3:62)
64
The how-to of Bayesian inference

Returning to the spectral line problem, we now see another reason for preferring the
choice of the Jeffreys prior for the temperature parameter, because it is a scale
parameter. In Section 9.2.3, we will discover yet another powerful argument for
selecting the Jeffreys prior for a scale parameter.
3.11 Systematic errors
In scientific inference, we encounter at least two general types of uncertainties which
are broadly classified as random and systematic. Random uncertainties can be
reduced by acquiring and averaging more data. This is the basis behind signal aver-
aging which is discussed in Section 5.11.1. Of course, what appears random for one
state of information might later be discovered to have a predictable pattern as our
state of information changes.
Some typical examples of systematic errors include errors of calibration of meters and
rulers,5 and stickiness and wear in the moving parts of meters. For example, over time
an old wooden meter stick may shrink by as much as a few mm. Some potential
systematic errors can be detected by careful analysis of the experiment before perform-
ing it and can then be eliminated either by applying suitable corrections or through
careful experimental design. The remaining systematic errors can be very subtle, and are
detected with certainty only when the same quantity is measured by two or more
completely different experimental methods. The systematic errors are then revealed
by discrepancies between the measurements made by the different methods.
Bayesian inference provides a powerful way of looking and dealing with some of
these subtle systematic errors. We almost always have some prior information about
the accuracy of our ‘‘ruler.’’ Clearly, if we had no information about its accuracy (in
contrast to its repeatability), we would have no logical grounds to use it at all except as
a means for ordering events. In this case, we would be expecting no more from our
ruler and we would have no concern about a systematic error. What this implies is that
we require at least some limited prior information about our ruler’s scale to be
concerned about a systematic error.
As we have seen, a unique feature of the Bayesian approach is the ability to incorporate
prior information and see how it affects our conclusions. In the case of the ruler accuracy,
the approach taken is to introduce the scale of the ruler into the calculation as a
parameter, i.e., we parameterize the systematic error. We can then treat this as a nuisance
parameter and marginalize (integrate over) this parameter to obtain our final inference
about the quantity of interest. If the uncertainty in the accuracy of our scale is very large,
this will be reflected quantitatively in a larger uncertainty in our final inference.
In a complex measurement, many different types of systematic errors can occur,
which in principle, can be parameterized and marginalized. For example, consider the
5 One important ruler in astronomy is the Hubble relation relating redshift or velocity to distance.
3.11 Systematic errors
65

following modification to the spectral line problem of Section 3.6. Even if we know the
predicted frequency of the spectral line accurately, the observed frequency depends on
the velocity of the source with respect to the observer through the Doppler effect. The
observed frequency of the line, fo, is related to the emitted frequency, fe by
fo ¼ fe 1 þ v
c


for v
c  1;
(3:63)
where v is the line of sight component of the velocity of the line emitting region and c
equals the velocity of light. In our search for a spectral line, we may be examining a
small portion of the Orion nebula and only know the distribution of velocities for the
integrated emission from the whole nebula, which may be dominated by turbulent and
rotational motion of its parts. The unknown factor v introduces a systematic error in
our frequency scale. In this case, we might choose to parameterize the systematic error
in v by a Gaussian with a mean and  equal to that of the Orion nebula as a whole.
From the Bayesian viewpoint, we can even consider uncertain scales that arise in a
theoretical model as introducing a systematic error on the same footing, for the
purposes of inference, as those associated with a measurement. In the above example,
we may know the velocity of the source accurately but the theory may be imprecise
with regard to its frequency scale.
Of course, the exact form by which we parameterize a systematic error is con-
strained by our available information, and just as our theories of nature are updated as
our state of knowledge changes, so in general will our understanding of these
systematic errors.
It is often the case that we can obtain useful information about a systematic error
from the interaction between measurements and theory in Bayesian inference. In
particular, we can compute the marginal posterior for the parameter characterizing
our systematic error as was done in Figure 3.9. This and other points raised in this
section are brought out by the problems at the end of this chapter.
The effect of marginalizing over any parameter, whether or not it is associated with a
systematic error, is to introduce an Occam factor which penalizes the model for any prior
parameter space that gets ruled out by the data through the likelihood function. The
larger the prior range that is excluded by the likelihood function, the greater the Occam
penalty. It is thus possible to rule out a valid model by employing an artificially large prior
for some systematic error or model parameter. Fortunately, Bayesian inference requires
one to specify one’s choice of prior so its effect on the conclusions can readily be assessed.
3.11.1 Systematic error example
In 1929, Edwin Hubble found a simple linear relationship between the distance of a
galaxy, x, and its recessional velocity, v, of the form v ¼ H0x, where H0 is known as
Hubble’s constant. Hubble’s constant provides the scale of our ruler for astronomical
distance determination. An error in H0 leads to a systematic error in distance
66
The how-to of Bayesian inference

determination. A modern value of H0 ¼ 70 	 10 km s1 Mpc1. Note: astronomical
distances are commonly measured in Mpc (a million parsecs). Suppose a particular
galaxy has a measured recessional velocity vm ¼ ð100 	 5Þ  103 km s1. Determine
the posterior PDF for the distance to the galaxy assuming:
1) A fixed value of H0 ¼ 70 km s1 Mpc1.
2) We allow for uncertainty in the value of Hubble’s constant. We assume a Gaussian prob-
ability density function for H0, of the form
pðH0jIÞ ¼ k exp
 ðH0  70Þ2
2  102
(
)
;
(3:64)
where k is a normalization constant.
3) We assume a uniform probability density function for H0, given by
pðH0jIÞ ¼
1=ð90  50Þ;
for 50  H0  90
0;
elsewhere.

(3:65)
4) We assume a Jeffreys probability density function for H0, given by
pðH0jIÞ ¼
½H0 lnð90=50Þ1;
for 50  H0  90
0;
elsewhere.

(3:66)
As usual, we can write
vm ¼ vtrue þ e
(3:67)
where vtrue is the true recessional velocity and e represents the noise component of the
measured velocity, vm. Assume that the probability density function for e can be
described by a Gaussian with mean 0 and  ¼ 5 km s1. To keep the problem simple,
we also assume the error in v is uncorrelated with the uncertainty in H0.
Through the application of Bayes’ theorem, as outlined in earlier sections of
this chapter, we can readily evaluate the posterior PDF, pðxjD; IÞ, for the
distance to the galaxy. The results for the four cases are given below and plotted
in Figure 3.10.
Case 1:
pðxjD; IÞ / pðxjIÞ pðDjx; IÞ ¼ pðxjIÞ
1ﬃﬃﬃﬃﬃﬃ
2p
p

exp  e2
22


¼ pðxjIÞ
1ﬃﬃﬃﬃﬃﬃ
2p
p

exp
 ðvm  vtrueÞ2
22
(
)
¼ pðxjIÞ
1ﬃﬃﬃﬃﬃﬃ
2p
p

exp
 ðvm  H0xÞ2
22
(
)
:
(3:68)
3.11 Systematic errors
67

Case 2:
In this case, I incorporates a Gaussian prior uncertainty in the value of H0.
pðxjD; IÞ ¼
Z 1
1
dH0 pðx; H0jD; IÞ
/ pðxjIÞ
Z 1
1
dH0 pðH0jx; IÞ pðDjx; H0; IÞ
¼ pðxjIÞ
Z 1
1
dH0 pðH0jIÞ pðDjx; H0; IÞ
¼ pðxjIÞ
Z 1
1
dH0 k exp
 ðH0  70Þ2
2  102
(
)

1ﬃﬃﬃﬃﬃﬃ
2p
p

exp
 ðvm  H0xÞ2
22
(
)
:
(3:69)
Case 3:
In this case, I incorporates a uniform prior uncertainty in the value of H0.
pðxjD; IÞ / pðxjIÞ
Z 90
50
dH0 pðH0jIÞ pðDjx; H0; IÞ
¼ pðxjIÞ
Z 90
50
dH0
1
ð90  50Þ
1ﬃﬃﬃﬃﬃﬃ
2p
p

exp
 ðvm  H0xÞ2
22
(
)
:
(3:70)
1000
1500
2000
Distance (Mpc)
0
0.005
0.01
0.015
0.02
0.025
p(x|D, I ) 
case 4
case 3
case 2
case 1
Figure 3.10 Posterior PDF for the galaxy distance, x: 1) assuming a fixed value of Hubble’s
constant (H0), 2) incorporating a Gaussian prior uncertainty for H0, 3) incorporating a uniform
prior uncertainty for H0, and 4) incorporating a Jeffreys prior uncertainty for H0.
68
The how-to of Bayesian inference

Case 4:
In this case, I incorporates a Jeffreys prior uncertainty in the value of H0.
pðxjD; IÞ / pðxjIÞ
Z 90
50
dH0 pðH0jIÞ pðDjx; H0; IÞ
¼ pðxjIÞ
Z 90
50
dH0
1
H0 lnð90=50Þ
1ﬃﬃﬃﬃﬃﬃ
2p
p

exp
 ðvm  H0xÞ2
22
(
)
:
(3:71)
Equations (3.68), (3.69), (3.70), and (3.71) have been evaluated assuming a uniform
prior for pðxjIÞ, and are plotted in Figure 3.10. Incorporating the uncertainty in the
scale of our astronomical ruler can lead to two effects. Firstly, the posterior PDF for
the galaxy distance is broader. Secondly the mean of the PDF is clearly shifted to a
larger value. The means of the PDFs for the four cases are 1429, 1486, 1512, and
1556 km s1, respectively.
It may surprise you that pðxjD; IÞ becomes asymmetric when we allow for the
uncertainty in H0. One way to appreciate this is to approximate the integral by a
weighted summation over a discrete set of choices for H0. For each choice of H0,
pðxjD; IÞ is a symmetric Gaussian offset by a distance x given by
x ¼
vm
H0 þ H0
 vm
H0
¼

H0
H0 þ H0

 vm
H0
:
(3:72)
For H0 ¼ þ 20 km s1 Mpc1, the bracketed term in Equation (3.72) is equal
to 0:22. For H0 ¼  20 km s1 Mpc1, this term is equal to þ0:4. Thus, the set of
discrete Gaussians is more spread out on one side than the other, which accounts for
the asymmetry.
3.12 Problems
1. Redo the calculation of the odds for the spectral line problem of Section 3.6 for the
case where there is a systematic uncertainty in the line center of 	5 channels.
2. The prior information is the same as that given for the spectral line problem in Section
3.6 of the text. The measured spectrum is given in Table 3.2. The spectrum consists of
64 frequency channels. Theory predicts the spectral line has a Gaussian shape with a
line width L ¼ 2 frequency channels. The noise in each channel is known to be
Gaussian with a  ¼ 1:0 mK and the spectrometer output is in units of mK.
(a) Plot a graph of the raw data.
(b) Compute the posterior probability of M1  ‘‘theory 1 is correct, the spectral
line exists,’’ for the two cases: (1) Jeffreys prior for the signal strength, and
(2) uniform prior. For this part of the problem, assume that the theory predicts
that the spectral line is in channel 24. The prior range for the signal strength is
0.1 to 100 mK. In Mathematica you can use the command NIntegrate to do the
numerical integration required in marginalizing over the line strength.
3.12 Problems
69

(c) Explain your reasons for preferring one or the other of the two priors.
(d) On the assumption that the model predicting the spectral line is correct,
compute and plot the posterior probability (density function) for the line
strength for both priors.
(e) Summarize the posterior probability for the line strength by quoting the most
probable value and the ðþÞ and ðÞ error bars that span the 95% credible region
(see the last part of Section 3.3 for a definition of credible region). The credible
region can be evaluated by computing the probability for a discrete grid of
closely spaced line temperature values. Sort these (probability, temperature)
pairs in descending order of probability and then sum the probabilities starting
from the highest until they equal 95%. As each term is added, keep track of the
upper and lower temperature bounds of the terms included in the sum.
Mathematica command Sort[yourdata, OrderedQ[{#2, #1] &];, will sort the
file ‘‘yourdata’’ in descending order according to the first item in each row of
the data list.
(f) Repeat the calculations in (b) and (d), only this time, assume that the prior
prediction on the location of the spectral line frequency is uncertain; it is
predicted to occur somewhere between channels 1 and 50. Assume a uniform
Table 3.2 Spectral line data consisting of 64 frequency channels obtained with a radio
astronomy spectrometer. The output voltage from each channel has been calibrated in
units of effective black body temperature expressed in mK. The existence of negative
values arises from receiver channel noise which gives rise to both positive and negative
fluctuations.
ch. #
mK
ch. #
mK
ch. #
mK
ch. #
mK
1
0.25
17
0.42
33
0.44
49
1.56
2
0.19
18
1.43
34
0.05
50
0.64
3
0.25
19
1.33
35
0.59
51
0.48
4
0.56
20
0.06
36
0.94
52
1.79
5
0.41
21
0.82
37
0.10
53
0.07
6
0.94
22
0.42
38
0.57
54
1.30
7
0.84
23
3.76
39
0.40
55
0.29
8
0.30
24
1.10
40
0.97
56
0.23
9
2.06
25
1.31
41
2.20
57
0.50
10
1.39
26
1.86
42
0.15
58
0.93
11
0.07
27
0.32
43
0.37
59
1.28
12
1.80
28
1.14
44
0.67
60
1.98
13
1.02
29
1.24
45
0.05
61
1.85
14
0.46
30
0.29
46
0.20
62
0.89
15
0.29
31
0.02
47
0.65
63
0.65
16
0.36
32
1.52
48
1.24
64
0.28
70
The how-to of Bayesian inference

prior for the unknown line center.6 This will involve computing a two-
dimensional likelihood distribution in the variables line frequency and line
strength for a discrete set of values of these parameters, and then using a
summation operation to approximate integration7 (you will probably find
NIntegrate too slow in two dimensions), for marginalizing over both para-
meters to obtain the global likelihood for computing the odds. For this
purpose, you can use a line frequency interval of 1 channel and a signal
strength interval of 0.1 mK for 100 intervals. Although this only spans the
prior range 0.1 to 10 mK the PDF will be so low beyond 10 mK that it will not
contribute significantly to the integral.
(g) Calculate and plot the marginal posterior probabilities for the line frequency.
(h) What additional Occam factor is associated with marginalizing over the prior
line frequency range?
3. Plot pðxjD; IÞ for case 4 (Jeffreys prior) in Section 3.11.1, assuming
pðH0jIÞ ¼
1
H0 lnð80=60Þ ;
for 60  H0  80
0;
elsewhere.

(3:73)
Box 3.1
Equation (3.69) can be evaluated using Mathematica.
The evaluation will be faster if you compute a Table of values for
pðx; H0jD; IÞ at equally spaced intervals in x, and use
NIntegrate to integrate over the given range for H0.
p(x|D; I)  Table [
x; NIntegrate
1
H0
ﬃﬃﬃﬃﬃﬃ
2p
p
s exp
- ðum - xH0Þ2
22
 
!
; {H0; 60; 80}
"
#
(
)
;
{x; 800; 2200; 50}]
6 Note: when the frequency range of the prior is a small fraction of center frequency, the conclusion will be the same
whether a uniform or Jeffreys prior is assumed for the unknown frequency.
7 A convenient way to sum elements in a list is to use the Mathematica command Plus@@list.
3.12 Problems
71

4
Assigning probabilities
4.1 Introduction
When we adopt the approach of probability theory as extended logic, the solution to
any inference problem begins with Bayes’ theorem:
pðHijD; IÞ ¼ pðHijIÞpðDjHi; IÞ
pðDjIÞ
:
(4:1)
In a well-posed problem, the prior information, I, defines the hypothesis space and
provides the information necessary to compute the terms in Bayes’ theorem.
In this chapter we will be concerned with how to encode our prior information, I,
into a probability distribution to use for pðDjHi; IÞ. Different states of knowledge
correspond to different probability distributions. These probability distributions are
frequently called sampling distributions, a carry-over from conventional statistics
literature. Recall that in inference problems, pðDjHi; IÞ gives the probability of obtain-
ing the data, D, that we actually got, under the assumption that Hi is true. Thus,
pðDjHi; IÞ yields how likely it is that Hi is true,1 and hence it is referred to as the
likelihood and frequently written as LðHiÞ.
For example, we might have two competing hypotheses H1 and H2 that each
predicts different values of some temperature, say 1 K and 4.5 K, respectively. If the
measured value is 1:2  0:4 K then it is clear that H1 is more likely to be true. In
precisely this type of situation we can use pðDjHi; IÞ to compute quantitatively the
relative likelihood of H1 and H2. We saw how to do that in one case (Section 3.6)
where the likelihood was the product of N independent Gaussian distributions.
4.2 Binomial distribution
In this section, we will see how a particular state of knowledge (prior information I) leads
us to the choice of likelihood, pðDjHi; IÞ, which is the well-known binomial distribution
(derivation due to M. Tribus, 1969). In this case, our prior information is as follows:
1 Conversely, if we know that Hi is true, then we can directly calculate the probability of observing any particular data
value. We will use pðDjHi; IÞ in this way to generate simulated data sets in Section 5.13.
72

I  ‘‘Proposition E represents an event that is repeated many times and has two
possible outcomes represented by propositions, Q and Q, e.g., tossing a coin. The
probability of outcome Q is constant from event to event, i.e., the probability of getting
an outcome Q in any individual event is independent of the outcome for any other event.’’
In the Boolean algebra of propositions we can write E as
E ¼ Q þ Q;
(4:2)
where Q þ Q is the logical sum. Then the possible outcomes of n events can be written as
E1; E2; . . . ; En ¼ ðQ1 þ Q1Þ; ðQ2 þ Q2Þ; . . . ; ðQn þ QnÞ;
(4:3)
where Qi  ‘‘outcome Q occurred for the ith event.’’ If the multiplication on the right is
carried out, the result will be a logical sum of 2n terms, each a product of n logical
statements, thereby enumerating all possible outcomes of the n events. For n ¼ 3 we find:
E1; E2; E3 ¼ Q1; Q2; Q3 þ Q1; Q2; Q3 þ Q1; Q2; Q3 þ Q1; Q2; Q3
þ Q1; Q2; Q3 þ Q1; Q2; Q3 þ Q1; Q2; Q3 þ Q1; Q2; Q3:
(4:4)
The probability of the particular sequence Q1; Q2; Q3 can be obtained from repeated
applications of the product rule.
pðQ1; Q2; Q3Þ ¼ pðQ1jIÞ pðQ2; Q3jQ1; IÞ
¼ pðQ1jIÞ pðQ2jQ1; IÞ pðQ3jQ1; Q2; IÞ:
(4:5)
Information I leads us to assign the same probability for outcome Q for each event
independent of what happened earlier or later, so Equation (4.5) becomes
pðQ1; Q2; Q3Þ ¼ pðQ1jIÞ pðQ2jIÞ pðQ3jIÞ
¼ pðQjIÞ pðQjIÞ pðQjIÞ
¼ pðQjIÞ pðQjIÞ2:
(4:6)
Thus, the probability of a particular outcome depends only on the number of Q’s and
Q’s in it and not on the order in which they occur. Returning to Equation (4.4), we
note that:
one outcome, the first, contains three Q’s,
three outcomes contain two Q’s,
three outcomes contain only one Q,
and one outcome contains no Q’s.
More generally, we are going to be interested in the number of ways of getting an
outcome with r Q’s in n events or trials. In each event, it is possible to obtain a Q, so the
question becomes in how many ways can we select r Q’s from n events where their
order is irrelevant, which is given by nCr.
4.2 Binomial distribution
73

nCr ¼
n!
r!ðn  rÞ! ¼
n
r


:
(4:7)
For example,
3
2


¼ 3!
2!1! ¼ 3;
Q; Q; Q
Q; Q; Q
Q; Q; Q.
Thus, the probability of getting r Q’s in n events is the probability of any one sequence
with r Q’s and ðn  rÞ Q’s, multiplied by nCr, the multiplicity of ways of obtaining r Q ’s
in n events or trials. Therefore, we conclude that in n trials, the probability of seeing the
outcome of r Q’s and ðn  rÞ Q’s is
pðrjn; IÞ ¼
n!
r!ðn  rÞ! pðQjIÞrpðQjIÞnr:
(4:8)
This distribution is called the binomial distribution.
Note the similarity to the binomial expansion
ðx þ yÞn ¼
X
n
r ¼ 0
n!
r!ðn  rÞ! xrynr:
(4:9)
Referring back to Equation (4.4), in the algebra of propositions, we can interpret En to
mean E carried out n times and write it in a form analogous to Equation (4.9):
En ¼ ðQ þ QÞn:
Example:
I  ‘‘You pick up one of two coins which appear identical. One, coin A, is known to be
a fair coin, while coin B is a weighted coin with pðheadÞ ¼ 0:2.’’ From this information
and from experimental information you will acquire from tossing the coin, compute
the probability that you picked up coin A.
D  ‘‘3 heads turn up in 5 tosses.’’
What is the probability you picked coin A?
Let odds ¼ pðAjD; IÞ
pðBjD; IÞ
¼ pðAjIÞpðDjA; IÞ
pðBjIÞpðDjB; IÞ ¼
1
2 pðDjA; IÞ
1
2 pðDjB; IÞ :
(4:10)
To evaluate the likelihoods pðDjA; IÞ and pðDjB; IÞ, we use the binomial distribution,
given by
pðrjn; IÞ ¼
n!
r!ðn  rÞ! pðheadjA; IÞrpðtailjA; IÞnr;
where pðrjn; IÞ is the probability of obtaining r heads in n tosses and pðheadjA; IÞ is
the probability of obtaining a head in any single toss assuming A is true. Now
74
Assigning probabilities

pðDjA; IÞ ¼
n
r


pðheadjA; IÞr pðtailjA; IÞnr ¼
5
3


ð0:5Þ3ð0:5Þ2
and pðDjB; IÞ ¼
5
3


ð0:2Þ3ð0:8Þ2 ! odds ¼ 6:1 ¼
pðAjD;IÞ
1pðAjD;IÞ and so pðAjD; IÞ ¼ 0:86.
Thus, the probability you picked up coin A ¼ 0:86, based on our current state of
knowledge.
4.2.1 Bernoulli’s law of large numbers
The binomial distribution allows us to compute pðrjn; IÞ, where r is, for example, the
number of heads occurring in n tosses of a coin. According to Bernoulli’s law of large
numbers, the long-run frequency of occurrence tends to the probability of the event
occurring in any single trial, i.e.,
lim
n!1
r
n ¼ pðheadjIÞ:
(4:11)
We can easily demonstrate this using the binomial distribution. If the probability of
a head in any single toss is pðheadjIÞ ¼ 0:4, Figure 4.1 shows a plot of pðr=njn; IÞ versus
the fraction r=n for a variety of different choices of n ranging from 20 to 1000.
Box 4.1 Mathematica evaluation of binomial distribution:
Needs[‘‘Statistics ‘DiscreteDistributions’’’]
The line above loads a package containing a wide range of discrete distributions of
importance to statistics, and the following line computes the probability of r heads
in n trials where the probability of a head in any one trial is p.
PDF[Binomial Distribution[n, p], r]
! answer ¼ 0:205 ðn ¼ 10; p ¼ 0:5; r ¼ 4Þ
Notice as n increases, the PDF for the frequency becomes progressively more sharply
peaked, converging on a value of 0.4, the probability of a head in any single toss.
Although Bernoulli was able to derive this result, his unfulfilled quest lay in the
inverse process: what could one say about the probability of obtaining a head, in a
single toss, given a finite number of observed outcomes? This turns out to be a
straightforward problem for Bayesian inference as we see in the next section.
4.2.2 The gambler’s coin problem
Let I  ‘‘You have acquired a coin from a gambling table. You want to determine
whether it is a biased coin from the results of tossing the coin many times. You specify
the bias of the coin by a proposition H, representing the probability of a head
4.2 Binomial distribution
75

occurring in any single toss. A priori, you assume that H can have any value in the
range 0 ! 1 with equal probability. You want to see how pðHjD; IÞ evolves as a
function of the number of tosses.’’
Let D  ‘‘You toss the coin 50 times and record the following results: (a) 2 heads in
the first 3 tosses, (b) 7 heads in the first 10 tosses, and (c) 33 heads in 50 tosses.’’
From the prior information, we determine that our hypothesis space H is contin-
uous in the range 0 ! 1. As usual, our starting point is Bayes’ theorem:
pðHjD; IÞ ¼ pðHjIÞpðDjH; IÞ
pðDjIÞ
:
(4:12)
Since we are assuming a uniform prior for pðHjIÞ, the action will all be in the
likelihood term pðDjH; IÞ, which, in this case, is given by the binomial distribution:
pðrjn; IÞ ¼
n!
r!ðn  rÞ! Hrð1  HÞnr:
(4:13)
Note: the symbol H is being employed in two different ways. In Equation (4.13), it is
acting as an ordinary algebraic variable standing for possible numerical values in the
range 0 to 1. When it appears as an argument of a probability or PDF, e.g., pðHjD; IÞ,
it acts as a proposition (obeying the rules of Boolean algebra) and asserts that the true
value lies in the numerical range H to H þ dH.
Figure 4.2 shows the results from Equation (4.13) as a function of H in the range
0 ! 1. From the figure, we can clearly see how the evolution of our state of knowledge
of the coin translates into a progressively more sharply peaked posterior PDF. From
this simple example, we can see how Bayes’ theorem solves the inverse problem: find
pðHjD; IÞ given a finite number of observed outcomes represented by D.
0
0.2
0.4
0.6
0.8
1
r /n
0
5
10
15
20
25
Probability density
n = 1000
n = 100
n = 20
Figure 4.1 A numerical illustration of Bernoulli’s law of large numbers. The PDF for the
frequency of heads, r=n, in n tosses of a coin is shown for three different choices of n. As n
increases, the distribution narrows about the probability of a head in any single toss ¼ 0:4.
76
Assigning probabilities

4.2.3 Bayesian analysis of an opinion poll
Let I  ‘‘A number of political parties are seeking election in British Columbia. The
questions to be addressed are: (a) what is the fraction of decided voters that support
the Liberals, and (b) what is the probability that the Liberals will achieve a majority of
at least 51% in the upcoming election, assuming the poll will be representative of the
population at the time of the election?’’
Let D  ‘‘In a poll of 800 decided voters, 18% supported the New Democratic Party
versus 55% for the Liberals, 19% for Reform BC and 8% for other parties.’’
Let the proposition H  ‘‘The fraction of the voters that will support the Liberals is
between H and H þ dH.’’ In this problem our hypothesis space of interest is contin-
uous in the range 0 to 1, so pðHjD; IÞ is a probability density function.
Based only on the prior information as stated, we adopt a flat prior pðHjIÞ ¼ 1.
Let r ¼ the number of respondents in the poll that support the Liberals. As far as
this problem is concerned, there are only two outcomes of interest; a voter either will
or will not vote for the Liberals. We can therefore use the binomial distribution to
evaluate the likelihood function pðDjH; IÞ. Given a particular value of H, the binomial
distribution gives the probability of obtaining D ¼ r successes in n samples, where in
this case, a success means support for the Liberals.
pðDjH; IÞ ¼
n!
r!ðn  rÞ! Hrð1  HÞnr:
(4:14)
In this problem n ¼ 800, and r ¼ 440. From Bayes’ theorem we can write
pðHjD; IÞ ¼ pðHjIÞpðDjH; IÞ
pðDjIÞ
¼ pðDjH; IÞ
pðDjIÞ
¼
pðDjH; IÞ
R 1
0 dH pðDjH; IÞ
:
(4:15)
0
0.2
0.4
0.6
0.8
1
H (probability of a head in one toss)
0
1
2
3
4
5
6
p(H |D,I )
Weighted Coin
n = 50
n = 10
n = 3
Figure 4.2 The posterior PDF for the bias of a coin determined from: (a) 3 tosses, (b) 10 tosses,
and (c) 50 tosses.
4.2 Binomial distribution
77

Figure 4.3 shows a graph of the posterior probability of H for a variety of poll sizes
including n ¼ 800. The 95% credible region2 for H is 55þ3:4
3:5%. A frequentist interpreta-
tion of the same poll would express the uncertainty in the fraction of decided voters
supporting the Liberals in the following way: ‘‘The poll of 800 people claims an
accuracy of 3:5%, 19 times out of 20.’’ We will see why when we deal with frequentist
confidence intervals in Section 6.6.
The second question, concerning the probability that the Liberals will achieve a
majority of at least 51% of the vote, is addressed as a model selection problem. The
two models are:
1. Model M1  ‘‘the Liberals will achieve a majority.’’ The parameter of the model is H, which is
assumed to have a uniform prior in the range 0:51  H  1:0.
2. Model M2  ‘‘the Liberals will not achieve a majority.’’ The parameter of the model is H,
which is assumed to have a uniform prior in the range 0  H 5 0:51.
From Equation (3.14) we can write
odds ¼ O12 ¼ pðM1jIÞ
pðM2jIÞ B12;
(4:16)
0
0.2
0.4
0.6
0.8
1
Fraction of voters supporting the Liberals
0
5
10
15
20
Probability density
n = 100
n = 200
n = 800
 
Figure 4.3 The posterior PDF for H, the fraction of voters in the province supporting the
Liberals based on polls of size n ¼ 100; 200; 800 decided voters.
2 Note: a Bayesian credible region is not the same as a frequentist confidence interval. For a uniform prior for H the 95%
confidence interval has essentially the same value as the 95% credible region, but the interpretation is very different.
The recipe for computing a credible region was given at the end of Section 3.3.
78
Assigning probabilities

where
B12 ¼ pðDjM1; IÞ
pðDjM2; IÞ
¼
R 1
H ¼ 0:51 dH pðHjM1; IÞ pðDjM1; H; IÞ
R 0:51
H ¼ 0 dH pðHjM2; IÞ pðDjM2; H; IÞ
¼
R 1
H ¼ 0:51 dHð1=0:49Þ pðDjM1; H; IÞ
R 0:51
H ¼ 0 dHð1=0:51Þ pðDjM2; H; IÞ
¼ 87:68:
(4:17)
Based on I, we have no prior reason to prefer M1 over M2, so O12 ¼ B12. The probability
that the Liberal party will win a majority is then given by (see Equation (3.18))
pðM1jD; IÞ ¼
1
ð1 þ 1=O12Þ ¼ 0:989:
(4:18)
Again, we emphasize that our conclusions are conditional on the assumed prior informa-
tion, which includes the assumption that the poll will be representative of the population
at the time of the election. Now that we have set up the equations to answer the questions
posed above, it is a simple exercise to recompute the answers assuming different prior
information, e.g., suppose the prior lower bound on H were 0.4 instead of 0.
4.3 Multinomial distribution
When we throw a six-sided die there are six possible outcomes. This motivates the
following question: Is there a generalization of the binomial distribution for the case
where we have more than two possible outcomes? Again we can use probability theory
as extended logic to derive the appropriate distribution starting from a statement of
our prior information.
I  ‘‘Proposition E represents an event that is repeated many times and has m
possible outcomes represented by propositions, O1; O2; . . . ; Om. The outcomes of
individual events are logically independent, i.e., the probability of getting an outcome
Oi in event j is independent of what outcome occurred in any other event.’’
E ¼ O1 þ O2 þ O3 þ    þ Om, then for the event E repeated n times:
En ¼ ðO1 þ O2 þ    þ OmÞn:
The probability of any particular En having
O1
occurring
n1
times
O2
occurring
n2
times
...
...
...
...
Om
occurring
nm
times
is pðEnjIÞ ¼ pðO1jIÞn1 pðO2jIÞn2 . . . pðOmjIÞnm.
4.3 Multinomial distribution
79

Next we need to find the number of sequences having the same number of
O1; O2; . . . ; Om (multiplicity) independent of the order. We can readily guess at
the form of multiplicity by rewriting Equation (4.7) setting the denominator
r!ðn  rÞ! ¼ n1!n2!.
multiplicity for the two-outcome case ¼
n!
r!ðn  rÞ! ¼
n!
n1!n2! ;
(4:19)
where n1 stands for the number of A’s and n2 for the number of A’s. Now in the current
problem, we have m possible outcomes for each event, so,
multiplicity for the m-outcome case ¼
n!
n1!n2! . . . nm! ;
(4:20)
where n ¼ Pm
i ¼ 1 ni.
Therefore, the probability of seeing the outcome defined by n1n2 . . . nm where ni 
‘‘Outcome Oi occurred ni times’’ is
pðn1; n2; . . . ; nmjEn; IÞ ¼
n!
n1!n2! . . . nm!
Y
m
i ¼ 1
pðOijIÞni:
(4:21)
This is called the multinomial distribution.
Compare this with the multinomial expansion:
ðx1 þ x2 þ    þ xmÞn ¼
X
n!
n1!n2! . . . nm! xni
1 xn2
2 . . . xnm
m ;
(4:22)
where the sum is taken over all possible values of ni, subject to the constraint that
Pm
i ¼ 1 ni ¼ n.
4.4 Can you really answer that question?
Let I  ‘‘A tin contains N buttons, identical in all respects except that M are black and
the remainder are white.’’
What is the probability that you will a pick a black button on the first draw
assuming you are blindfolded? The answer is clearly M/N. What is the probability
that you will a pick a black button on the second draw if you know that a black button
was picked on the first and not put back in the tin (sampling without replacement)?
Let Bi  ‘‘A black button was picked on the ith draw.’’
Let Wi  ‘‘A white button was picked on the ith draw.’’
Then
pðB2jB1; IÞ ¼ M  1
N  1 ;
because for the second draw there is one less black button and one less button
in total.
80
Assigning probabilities

Now, what is the probability of picking a black button on the second draw pðB2jIÞ
when we are not told what color was picked on the first draw? In this case the answer
might appear to be indeterminate, but as we shall show, questions of this kind can be
answered using probability theory as extended logic.
We know that either B1 or W1 is true, which can be expressed as the Boolean
equation B1 þ W1 ¼ 1. Thus we can write:
B2 ¼ ðB1 þ W1Þ; B2 ¼ B1; B2 þ W1; B2:
But according to Jaynes consistency (see Section 2.5.1), equivalent states of knowledge
must be represented by equivalent plausibility assignments. Therefore
pðB2jIÞ ¼ pðB1; B2jIÞ þ pðW1; B2jIÞ
¼ pðB1jIÞpðB2jB1; IÞ þ pðW1jIÞpðB2jW1; IÞ
¼
M
N

 M  1
N  1


þ
N  M
N


M
N  1


¼ M
N :
(4:23)
In like fashion, we can show
pðB3jIÞ ¼ M
N :
The probability of black at any draw, if we do not know the result of any other draw, is
always the same.
The method used to obtain this result is very useful.
1. Resolve the quantity whose probability is wanted into mutually exclusive sub-propositions:3
B3 ¼ ðB1 þ W1Þ; ðB2 þ W2Þ; B3
¼ B1; B2; B3 þ B1; W2; B3 þ W1; B2; B3 þ W1; W2; B3:
2. Apply the sum rule.
3. Apply the product rule.
If the sub-propositions are well chosen (i.e., they have a simple meaning in the
context of the problem), their probabilities are often calculable.
While we are on the topic of sampling without replacement, let’s introduce the
hypergeometric distribution (see Jaynes, 2003). This gives the probability of drawing r
3 In his book, Rational Descriptions, Decisions and Designs, M. Tribus refers to this technique as extending the
conversation. In many problems, there are many pieces of information which do not seem to fit together in any simple
mathematical formulation. The technique of extending the conversation provides a formal method for introducing this
information into the calculation of the desired probability.
4.4 Can you really answer that question?
81

black buttons (blindfolded) in n tries from a tin containing N buttons, identical in all
respects except that M are black and the remainder are white.
pðrjN; M; nÞ ¼
M
r


N  M
n  r


N
n


;
(4:24)
where
M
r


¼
M!
r!ðM  rÞ! etc:
(4:25)
Box 4.2
Mathematica evaluation of hypergeometric distribution:
Needs[‘‘Statistics ‘DiscreteDistributions’ ’’]
PDF[HypergeometricDistribution [n, nsucc, ntot], r]
gives the probability of r successes in n trials corresponding to sampling without
replacement from a population of size ntot with nsucc potential successes.
4.5 Logical versus causal connections
We now need to clear up an important distinction between a logical connection
between two propositions and a causal connection. In the previous problem with M
black buttons and N  M white buttons, it is clear that pðBjjBj1; IÞ < pðBjjIÞ since we
know there is one less black button in the tin when we take our next pick. Clearly, what
was drawn on earlier draws can affect what will happen in later draws. We can say
there is some kind of partial causal influence of Bj1 on Bj.
Now suppose we ask the question what is the probability pðBj1jBj; IÞ? Clearly in
this case what we get on a later draw can have no effect on what occurs on an earlier
draw, so it may be surprising to learn that pðBj1jBj; IÞ ¼ pðBjjBj1; IÞ. Consider the
following simple proof (Jaynes, 2003). From the product rule we write
pðBj1; BjjIÞ ¼ pðBj1jBj; IÞpðBjjIÞ ¼ pðBjjBj1; IÞpðBj1jIÞ:
But we have just seen that pðBjjIÞ ¼ pðBj1jIÞ ¼ M=N for all j, so
pðBj1jBj; IÞ ¼ pðBjjBj1; IÞ;
(4:26)
or more generally,
pðBkjBj; IÞ ¼ pðBjjBk; IÞ;
for all j; k:
(4:27)
82
Assigning probabilities

How can information about a later draw affect the probability of an earlier draw?
Recall that in Bayesian analysis, probabilities are an encoding of our state of know-
ledge about some question. Performing the later draw does not physically affect the
number Mj of black buttons in the tin at the jth draw. However, information about the
result of a later draw has the same effect on our state of knowledge about what could
have been taken on the jth draw, as does information about an earlier draw. Bayesian
probability theory is concerned with all logical connections between propositions
independent of whether there are causal connections.
Example 1:
I  ‘‘A shooting has occurred and the police arrest a suspect on the same day.’’
A  ‘‘Suspect is guilty of shooting.’’
B  ‘‘A gun is found seven days after the shooting with suspect’s fingerprints on it.’’
Clearly, B is not a partial cause of A but still we conclude that
pðAjB; IÞ5pðAjIÞ:
Example 2:
I  ‘‘A virulent virus invades Montreal. Anyone infected loses their hair a month
before dying.’’
A  ‘‘The mayor of Montreal lost his hair in September.’’
B  ‘‘The mayor of Montreal died in October.’’
Again, in this case, pðAjB; IÞ5pðAjIÞ.
Although a logical connection does not imply a causal connection, a causal con-
nection does imply a logical connection, so we can certainly use probability theory to
address possible causal connections.
4.6 Exchangeable distributions
In the previous section, we learned that information about the result of a later draw
has the same effect on our state of knowledge about what could have been taken on
the jth draw, as does information about an earlier one. Every draw has the same
relevance to every other draw regardless of their time order. For example,
pðBjjBj1; Bj2; IÞ ¼ pðBjjBjþ1; Bjþ2; IÞ, where again Bj is the proposition asserting a
black button on the jth draw. The only thing that is significant about the knowledge
of outcomes of other draws is the number of black or white buttons in these draws,
not their time order. Probability distributions of this kind are called exchangeable
distributions. It is clear that the hypergeometric distribution is exchangeable since for
pðrjN; M; nÞ we are not required to specify the exact sequence of the r black button
outcomes. The hypergeometric distribution takes into account the changing
4.6 Exchangeable distributions
83

contents of the tin. The result of any draw changes the probability of a black on any
other draw. If the number, N, of buttons in the tin is much larger than the number of
draws n, then this probability changes very little. In the limit as N ! 1, the
hypergeometric distribution simplifies to the binomial distribution, another
exchangeable distribution.
The multinomial distribution, discussed in Section 4.3, can be viewed as a general-
ization of the binomial distribution to the case where we have m possible outcomes,
not just two. From its form given in Equation (4.21), which we repeat here,
pðn1; n2; . . . ; nmjEn; IÞ ¼
n!
n1!n2! . . . nm!
Y
m
i ¼ 1
pðOijIÞni;
we can see that this is another exchangeable distribution because the probability
depends only on the numbers of different outcomes ðn1; n2; . . . ; nmÞ observed and
not on their order.
Worked example:
A spacecraft carrying two female and three male astronauts makes a trip to Mars.
The plan calls for three of the astronauts to board a detachable capsule to land on the
planet, while the other two remain behind in orbit. Which three will board the
capsule is decided by a lottery, consisting of picking names from a box. The first
person selected is to be the captain of the capsule. The second and third names
selected become capsule support crew. What is the probability that the captain is
female if we know that at least one of the support crew members is female? Let Fi
stand for the proposition that the ith name selected is female, and Mi if the person
is male.
Let Flater  ‘‘We learn that at least one of the crew members is female.’’
Flater ¼ F2 þ F3:
This information reduces the number of females available for the first draw by at
least one. To solve the problem we will make use of Bayes’ theorem and abbreviate
Flater by FL.
pðF1jFL; IÞ ¼ pðF1jIÞpðFLjF1; IÞ
pðFLjIÞ
:
(4:28)
To evaluate two of the terms on the right, it will be convenient to work with denials of
FL. From the sum rule, pðFLjF1; IÞ ¼ 1  pðFLjF1; IÞ. Since FL ¼ F2 þ F3, we have that
FL ¼ F2; F3 ¼ M2; M3, according to the duality identity of Boolean algebra (Section
84
Assigning probabilities

2.2.3). In words, the denial of at least one female in draws 2 and 3 is a male on both
draws. Therefore,
pðFLjF1; IÞ ¼ 1  pðM2; M3jF1; IÞ ¼ 1  pðM2jF1; IÞpðM3jM2; F1; IÞ
¼ 1 
3
4
  2
3
 
¼ 1
2 :
(4:29)
Similarly, we can write pðFLjIÞ ¼ 1  pðM2; M3jIÞ. By exchangeability, pðM2; M3jIÞ is
the same as the probability of a male on the first two draws given only the conditional
information I, i.e., not F1; I. Therefore,
pðFLjIÞ ¼ 1  pðM2; M3jIÞ ¼ 1  pðM1; M2jIÞ ¼ 1  pðM1jIÞpðM2jM1; IÞ
¼ 1 
3
5
  2
4
 
¼ 7
10 :
(4:30)
Substituting Equations (4.29) and (4.30) into Equation (4.28), we obtain
pðF1jFL; IÞ ¼
2
5
  1
2
 
7
10
  ¼ 2
7 :
(4:31)
The property of exchangeability has allowed us to evaluate the desired probability in a
circumstance where we were given less precise information, namely, a female will be
picked at least once on the second and third draws. Note: the result for pðF1jFL; IÞ is
different from these two cases:
pðF1jIÞ ¼ 2
5
and
pðF1jF2; IÞ ¼
2  1
5  1


¼ 1
4 :
4.7 Poisson distribution
In this section4 and we will see how a particular state of prior information, I, leads us
to choose the well-known Poisson distribution for the likelihood. Later, in Section
5.7.2, we will derive the Poisson distribution as a limiting ‘‘low count rate’’ approxi-
mation to the binomial distribution.
Prior information: I  ‘‘There is a positive real number r such that, given r, the
probability that an event, or count, will occur in the time interval ðt; t þ dtÞ is ¼ r dt.
Furthermore, knowledge of r makes any information about the occurrence or
4 Section 4.7 is based on a paper by E. T. Jaynes (1989).
4.7 Poisson distribution
85

non-occurrence of the event in any other time interval (that does not include ðt; t þ dtÞ)
irrelevant to this probability.’’
Let qðtÞ ¼ probability of no count in time interval (0,t).
Let E  ‘‘no count in ð0; t þ dtÞ’’.
E is the conjunction of two propositions A and B given by
E ¼ ½‘‘no count in ð0; tÞ’’; ½‘‘no count in ðt; t þ dtÞ’’ ¼ A; B:
From the product rule, pðEjIÞ ¼ pðA; BjIÞ ¼ pðAjIÞpðBjA; IÞ.
It follows that
pðEjIÞ ¼ qðt þ dtÞ ¼ qðtÞð1  r dtÞ
or
dq
dt ¼  r qðtÞ:
The solution for the evident initial condition qð0Þ ¼ 1 is qðtÞ ¼ expðr tÞ.
Now consider the probability of the proposition:
C  ‘‘In the interval ð0; tÞ, there are exactly n counts which happen at times
ðt1;t2;...;tnÞ with infinitesimal tolerances ðdt1;...;dtnÞ, where ð0 < t1 < t2 ... < tn < tÞ’’
This is the conjunction of 2n þ 1 propositions
C ¼ ½‘‘no count in ð0; t1Þ’’; ð‘‘count in dt1’’Þ;
½‘‘no count in ðt1; t2Þ’’; ð‘‘count in dt2’’Þ; . . . ;
½‘‘no count in ðtn1; tnÞ’’; ð‘‘count in dtn’’Þ; ½‘‘no count in ðtn; tÞ’’:
By the product rule and the independence of different time intervals,
pðCjr; IÞ ¼ expðr t1Þ: ðr dt1Þ: expðrðt2  t1ÞÞ: ðr dt2Þ . . .
 expðrðtn  tn1ÞÞ: ðr dtnÞ: ðexp rðt  tnÞÞ
¼ expðr tÞrn dt1 . . . dtn:
(4:32)
The probability (given r) that in the interval (0,t) there are exactly n counts,
whatever the times, is given by
pðnjr; t; IÞ ¼ expðrtÞrn
Z t
0
dtn . . .
Z t4
0
dt3
Z t3
0
dt2
Z t2
0
dt1
¼ expðrtÞrn
Z t
0
dtn . . .
Z t4
0
dt3
Z t3
0
t2
1! dt2
¼ expðrtÞrn
Z t
0
dtn . . .
Z t4
0
t2
3
2! dt3
¼ expðrtÞ ðrtÞn
n!
Poisson distribution:
(4:33)
86
Assigning probabilities

We will return to the Poisson distribution again in Chapter 5. Some sample Poisson
distributions are shown in Figure 5.6, and its relationship to the binomial and
Gaussian distributions is discussed in Section 5.7.2, together with some typical exam-
ples. Chapter 14 is devoted to Bayesian inference with Poisson sampling.
4.7.1 Bayesian and frequentist comparison
Let’s use the Poisson distribution to clarify a fundamental difference between the
Bayesian and frequentist approaches to inference. Consider how the probability
of n1 counts in a time interval ð0; t1Þ changes if we learn that n2 counts occurred
in the interval ð0; t2Þ where t2 > t1. According to I, the occurrence or non-
occurrence of counts in any other time intervals that do not include the interval
ð0; t1Þ is irrelevant to the probability of interest. Since ð0; t2Þ contains ð0; t1Þ it is
contributing information which we can incorporate through Bayes’ theorem
which we write now.
pðn1jn2; r; t1; t2; IÞ ¼ pðn1jr; t1; t2; IÞ pðn2jn1; r; t1; t2; IÞ
pðn2jr; t1; t2; IÞ
¼ pðn1jr; t1; IÞ pðn1; ðn2  n1Þjn1; r; t1; t2; IÞ
pðn2jr; t2; IÞ
:
(4:34)
Using the product rule, we can expand the second term in the numerator of
Equation (4.34):
pðn1; ðn2  n1Þjn1; r; t1; t2; IÞ ¼ pðn1jn1; r; t1; t2; IÞ  pðn2  n1jn1; r; t1; t2; IÞ
¼ 1  pðn2  n1jn1; r; t1; t2; IÞ
¼ exp½rðt2  t1Þ ½rðt2  t1Þn2n1
ðn2  n1Þ!
:
(4:35)
The other terms in Equation (4.34) can readily be evaluated by reference to
Equation (4.33). Substituting into Equation (4.34) and simplifying, we obtain
pðn1jn2; r; t1; t2; IÞ ¼
n2!
n1! ðn2  n1Þ!
exp½rt1 exp½rðt2  t1Þ
exp½rt2
 ½rt1n1 ½rðt2  t1Þn2n1
½rt2n2
¼
n2
n1

 t1
t2
 n1
1  t1
t2

n2n1
t1 < t2
n1 < n2


:
(4:36)
The result is rather surprising because the new posterior does not even depend on r.
The point is that r does not determine n1; it only gives probabilities for different values
of n1. If we know the actual value over the interval that includes ð0; t1Þ, then this takes
precedence over anything we could infer from r.
4.7 Poisson distribution
87

In frequentist random variable probability theory, one might think that r is the sole
relevant quantity, and thus arrive at a different conclusion, namely,
pðn1jn2; r; t1; t2; IÞ ¼ pðn1jr; t1; IÞ ¼ expðrt1Þ ðrt1Þn1
n1!


:
(4:37)
What if we used the measured n2 counts in the time interval t2 to compute a
new estimate of r0 ¼ n2=t2 and then used Equation (4.37) to compute pðn1jr0; t1; IÞ.
Would we get the same result as predicted by Equation (4.36)? The two distribu-
tions are compared in Figure 4.4 for n2 ¼ 10 counts, t2 ¼ 10 s and t1 ¼ 8 s. The two
curves are clearly very different. In addition, the probability distribution given by
Equation (4.37) predicts a tail extending well beyond 10 counts which makes no
physical sense given that we know only 10 counts will occur in the longer interval
t2 which contains t1. From the frequentist point of view, replacing r by r0 would
make little sense regarding long-run performance if the original r were estimated
on the basis of the counts in a much longer time span than t2. However, for any
non-zero value of r, Equation (4.37) predicts there is a finite probability that n1
can exceed the actual measured value n2 in the larger interval, which is clearly
impossible.
In frequentist theory, a probability represents the percentage of time that something
will happen in a very large number of identical repeats of an experiment, i.e., the long-
run relative frequency. As we will learn in Section 6.6 and Chapter 7, frequentist
theory says nothing directly about the probability of any estimate derived from a
single data set. The significance of any frequentist result can only be interpreted with
reference to a population of hypothetical data sets. From this point of view, the
2
4
6
8
10
n1
0.05
0.1
0.15
0.2
0.25
0.3
Probability
Exp [–r'   t1] (r'   t1)n1
  
 
n1!
with r' = n2
t2
n2
n1
t1
t1
t2
t2
1−
n2 = 10 counts
t2 = 10 s
 
t1 = 8 s
n1
n2–n1
Figure 4.4 A comparison of the predictions for pðn1jn2; r; t1; t2; IÞ based on Equations (4.36) and
(4.37) where we set r0 ¼ n2=t2. The assumed values are t1 ¼ 8 s, t2 ¼ 10 s and n2 ¼ 10 counts.
88
Assigning probabilities

frequentist procedure represented by Equation (4.37) is not intended to be optimum in
the individual case that we are considering here. In contrast, Bayesian probability
theory does apply to the individual case, where the goal is to reason as best we can on
the basis of our current state of information. In a Bayesian analysis, only the data that
were actually measured, combined with relevant prior information, are considered,
hypothetical data sets play no role.
4.8 Constructing likelihood functions
In this section, we amplify on the process of arriving at the likelihood function,
pðDjM; ; IÞ, for use in a Bayesian analysis, where
pðDjM; ; IÞ ¼ probability of obtaining data D; if model M
and background (prior) information I are true
(also called the likelihood function LðMÞÞ:
The parameters of model M are collectively designated by the symbol . We can
write D ¼ Y1; Y2; . . . ; YN ¼ fYig, where
* Yi  ‘‘A proposition asserting that the ith data value is in the infinitesimal range yi to
yi þ dyi.’’
* Zi  ‘‘A proposition asserting that the M model prediction for the ith data value is in the
range zi to zi þ dzi.’’
* Ei  ‘‘A proposition asserting that the ith error value is in the range ei to ei þ dei.’’
As usual, we can write
yi ¼ zi þ ei:
(4:38)
In the simplest case (see Section 4.8.1) the predicted value, zi, is given by a deterministic
model, mðxijÞ, which is a function of some independent variable(s) xi, like position or
time. More generally, the value of zi itself may be uncertain because of statistical
uncertainties in mðxijÞ, and/or uncertainties in the value of the independent variable(s)
xi. We will represent the probability distribution for proposition Zi by the function
pðZijM; ; IÞ ¼ fZðziÞ:
(4:39)
We can also represent the probability distribution for proposition Ei by another
function given by
pðEijM; ; IÞ ¼ fEðeiÞ:
(4:40)
Our next step is to compute pðYijM; ; IÞ. Now Yi depends on propositions Zi and
Ei. To evaluate pðYijM; ; IÞ, we first extend the conversation (Tribus, 1969) to
include these propositions by writing down the joint probability distribution
4.8 Constructing likelihood functions
89

pðYi; Zi; EijM; ; IÞ. We can then solve for pðYijM; ; IÞ by using the marginalizing
operation as follows:
pðYijM; ; IÞ ¼
ZZ
dZi dEi pðYi; Zi; EijM; ; IÞ
¼
ZZ
dZi dEi pðZijM; ; IÞ pðEijM; ; IÞ pðYijZi; Ei; M; ; IÞ;
(4:41)
where we assume Zi and Ei are independent.
Since yi ¼ zi þ ei,
pðYijZi; Ei; M; ; IÞ ¼ ðyi  zi  eiÞ
(4:42)
! pðYijM; ; IÞ ¼
Z
dzi fZðziÞ
Z
dei fEðeiÞðyi  zi  eiÞ:
(4:43)
The presence of the delta function in the second integral serves to pick out the value
of the integrand at ei ¼ yi  zi, so we have:
pðYijM; ; IÞ ¼
Z
dzi fZðziÞ fEðyi  ziÞ:
(4:44)
The right hand side of the equation is the convolution integral.5 We now evaluate our
equation for pðYijM; ; IÞ for two useful general cases.
4.8.1 Deterministic model
In this case, we assume that for any specific choice of the model parameters there is no
uncertainty in the predicted value, zi. We will refer to models of this kind as determin-
istic models. Given the model and the values of any of its parameters, then
fZðziÞ ¼ ðzi  mðxijÞÞ. In this case, Equation (4.44) becomes
pðYijM; ; IÞ ¼ fEðyi  mðxijÞÞ ¼ pðEijM; ; IÞ:
(4:45)
Thus, the probability of the ith data value is simply equal to the probability of the ith
error term. If the errors are all independent,6 then
pðDjM; ; IÞ ¼ pðY1; Y2; . . . ; YNjM; ; IÞ ¼ pðE1; E2; . . . ; ENjM; ; IÞ
¼
Y
N
i ¼ 1
pðEijM; ; IÞ;
(4:46)
where QN
i ¼ 1 stands for the product of N of these terms. We have already encountered
Equation (4.46) in the simple spectral line problem of Section 3.6 (see Equation (4.42)).
5 For more details on the convolution integral and how to evaluate it using the Fast Fourier Transform, see Sections B.4
and B.10.
6 We deal with the effect of correlated errors in Section 10.2.2.
90
Assigning probabilities

4.8.2 Probabilistic model
In the second case, our information about the model is uncertain. Here, we will
distinguish between three different situations.
1. The model prediction, zi, includes a statistical noise component i.
zi ¼ mðxijÞ þ i:
(4:47)
Equation (4.38) can be rewritten as
yi ¼ zi þ ei ¼ mðxijÞ þ i þ ei:
(4:48)
In this case, the data, yi, can differ from the model, mðxijÞ, because of a component ei
due to measurement errors, and a component i due to a statistical uncertainty in our
model. The two error terms are assumed to be uncorrelated. For example, suppose our
data consist of a radar return signal from an unidentified aircraft. We could compare
the signal to samples of measured radar return signals from a set of known aircraft for
different orientations to arrive at the most probable identification. In this case, these
sample measurements of known aircraft, which include a noise component, constitute
our model, mðxijÞ.
Suppose that the probability distribution of i is described by a Gaussian with
standard deviation mi. Then
pðZijM; ; IÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p
mi
exp
ðzi  mðxijÞÞ2
22
mi
(
)
¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p
mi
exp 2
i
22
i


¼ fZðziÞ:
(4:49)
Suppose also that the error term, ei, in Equation (4.38), has a Gaussian probability
distribution with a standard deviation, i, of the form
pðEijM; ; IÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p
i
exp e2
i
22
i


¼ fEðyi  ziÞ:
(4:50)
Then according to Equation (4.44), pðYijM; ; IÞ is the convolution of the two
Gaussian probability distributions. It is easy to show7 that the result is another
Gaussian given by
pðYijM; ; IÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
i þ 2
mi
p
exp
ðyi  mðxijÞÞ2
2ð2
i þ 2
miÞ
(
)
:
(4:51)
7 Simply evaluate Equation (4.44) using Mathematica with limits on the integral of 1 after substituting for fZðziÞ and
fEðyi  ziÞ using Equations (4.49) and (4.50), respectively.
4.8 Constructing likelihood functions
91

If the Yi terms are all independent, then
pðDjM; ; IÞ ¼ pðY1; Y2; . . . ; YNjM; ; IÞ
¼ ð2pÞN=2
Y
N
i ¼ 1
ð2
i þ 2
miÞ1=2
(
)
exp
X
N
i ¼ 1
ðyi  mðxijÞÞ2
2ð2
i þ 2
miÞ
 
!
(
)
:
(4:52)
2. In the second situation, our information about the model prediction, zi, is only
uncertain because of uncertainty in the value of the independent variable xi. For
example, we might be interested in fitting a straight line to some data with errors in
both coordinates. Let xi0 be the nominal value of the independent variable and xi the
true value. Then xi ¼ xi  xi0, is the uncertainty in xi. Now suppose the probability
distribution of xi is a Gaussian given by
pðXijIÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p
xi
exp
ðxi  xi0Þ2
22
xi
(
)
¼ fXðxiÞ;
(4:53)
where the scale of xi is set by xi.
Our goal here is to compute an expression for pðZijM; ; IÞ ¼ fZðziÞ, for use in
Equation (4.44). In Section 5.12, we will show how to compute the probability
distribution of a function of xi if we know the probability distribution of xi. In our
case, this function is zi ¼ mðxijÞ. The function mðxijÞ must be a monotonic and
differentiable function over the range of xi of interest. Then there exists an inverse
function xi ¼ m1ðzijÞ which is monotonic and differentiable. Thus, for every interval
dxi there is a corresponding interval dzi. The result is
fZðziÞ ¼ fXðxiÞ dxi
dzi








 ¼ fXðm1ðzijÞÞ dxi
dzi








;
(4:54)
which is valid provided the derivative does not change significantly over a scale of
order 2xi.
Let’s evaluate Equation (4.54) for the straight-line model, zi ¼ mðxijA; BÞ ¼
A þ Bxi. In that case,
xi ¼ m1ðzijA; BÞ ¼ 1
B zi  A
B ;
(4:55)
so
xi  xi0 ¼ 1
B ðzi  zi0Þ:
(4:56)
Also, it is apparent that
dxi
dzi








 ¼ 1
jBj :
(4:57)
92
Assigning probabilities

Combining Equations (4.53), (4.54), (4.56) and (4.57), we obtain
fZðziÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p
jBjxi
exp
ðzi  zi0Þ2
2B22
xi
(
)
:
(4:58)
We now have everything we need to evaluate Equation (4.44). Again, pðYijM; ; IÞ is
the convolution of the two Gaussian probability distributions. The result is
pðYijM; A; B; IÞ ¼
1
ﬃﬃﬃﬃﬃﬃ
2p
p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
i þ B22
xi
p
exp
ðyi  mðxi0jA; BÞÞ2
2ð2
i þ B22
xiÞ
(
)
:
(4:59)
If the Yi terms are all independent, then,
pðDjM; A; B; IÞ ¼ ð2pÞN=2
Y
N
i ¼ 1
ð2
i þ B22
xiÞ1=2
 
!
 exp
X
N
i ¼ 1
ðyi  mðxi0jA; BÞÞ2
2ð2
i þ B22
xiÞ
(
)
:
(4:60)
The reader is directed to Section 11.7 for a worked problem of this kind.
3. The model prediction, zi, is uncertain because of statistical uncertainties in both the
model and the value of the independent variable(s), xi. In this case, if we again assume
Gaussian distributions for the uncertain quantities, Equation (4.60) becomes
pðDjM; A; B; IÞ ¼ ð2pÞN=2
Y
N
i ¼ 1
ð2
i þ 2
mi þ B22
xiÞ1=2
 
!
 exp
X
N
i ¼ 1
ðyi  mðxi0jA; BÞÞ2
2ð2
i þ 2
mi þ B22
xiÞ
(
)
:
(4:61)
4.9 Summary
In any Bayesian analysis, the prior information defines the hypothesis space of
interest, prior probability distributions and the means for computing pðDjHi; IÞ, the
likelihood function. In this chapter, we have given examples of how to encode prior
information into a probability distribution (commonly referred to as the sampling
distribution) for use in computing the likelihood term. We saw how the well-known
binomial, multinomial, hypergeometric and Poisson distributions correspond to dif-
ferent prior information. In the process, we learned that Bayesian inference is con-
cerned with logical connections between propositions which may or may not
correspond to causal physical influences. We introduced the notion of exchangeable
distributions and learned how to compute probabilities for situations where the prior
4.9 Summary
93

information, at first sight, appears very imprecise. In Section 4.7.1, we gained import-
ant insight into the fundamental difference between Bayesian and frequentist
approaches to inference. Finally, in Section 4.8, we learned how to construct like-
lihood functions for both deterministic and probabilistic models.
4.10 Problems
1. A bottle contains 50 black balls and 30 red balls. The bottle is first shaken to mix
up the balls. What is the probability that blindfolded, you will pick two red balls in
three tries?
2. Let I  ‘‘A tin is purchased from a company that makes an equal number of two
types. Both contain 90 buttons which are identical except that 2/3 of the buttons in
one tin are black (the rest are white) and 2/3 of the buttons in the other tin are
white (the rest are black). You can’t distinguish the tins from their outside.’’
Let D  ‘‘In a sample of ten buttons drawn from the tin, seven are black.’’
Let B  ‘‘We are drawing from the black tin.’’
Let W  ‘‘We are drawing from the white tin.’’
Compute the odds ¼ pðBjD; IÞ
pðWjD; IÞ, assuming pðBjIÞ ¼ pðWjIÞ.
3. A tin contains 17 black buttons and 6 white buttons. The tin is first shaken to mix
up the buttons. What is the probability that blindfolded, you will pick a white
button on the third pick if you don’t know what was picked on the first two picks?
4. A bottle contains three green balls and three red balls. The bottle is first shaken to
mix up the balls. What is the probability that blindfolded, you will pick a red ball
on the third pick, if you learn that at least one red ball was picked on the first two
picks?
5. A spacecraft carrying two female and three male astronauts makes a trip to Mars.
The plan calls for a two-person detachable capsule to land at site A on the planet
and a second one-person capsule to land at site B. The other two astronauts
remain in orbit. Which three will board the two capsules is decided by a lottery,
consisting of picking names from a box. What is the probability that a female
occupies the one-person capsule if we know that at least one member of the other
capsule is female, but we are not told the order in which the astronauts were
picked?
6. In a particular water sample, ten bacteria are found, of which three are of type A.
Let Q  ‘‘the probability that any particular bacterium is of type A is between q
and q þ dq.’’ Plot the posterior pðQjD; IÞ. What prior probability distribution did
you assume and why?
7. In a particular water sample, ten bacteria are found, of which three are of type A.
What is the probability of obtaining six type A bacteria, in a second independent
water sample containing 12 bacteria in total?
94
Assigning probabilities

8. In a radio astronomy survey, 41 quasars were detected in a total sample of
90 sources. Let F  ‘‘the probability that any particular source is a quasar is
between f and f þ df.’’ Plot the posterior pðFjD; IÞ assuming a uniform prior for F.
9. In problem 7, what is the probability of obtaining at least three type A bacteria?
10. A certain solution contains three types of bacteria: A; B, and C. Given
pðAjIÞ ¼ 0:2; pðBjIÞ ¼ 0:3, and pðCjIÞ ¼ 0:5, what is the probability of obtaining
a sample of ten bacteria with three type A, three type B and four type C?
11. A total of five -ray photons were detected from a particular star in one hour.
What is the probability that three photons will be detected in the next hour of
observing?
12. On average, five -ray photons are detected from a particular star each hour.
What is the probability that three photons were detected in the first hour of a two-
hour observation that recorded eight photons in total?
13. In the opinion poll problem of Section 4.2.3, re-plot Figure 4.3 for n ¼ 55.
14. In the opinion poll problem of Section 4.2.3, compute the probability that the
Liberals will achieve a majority of at least 51%, for n ¼ 55 and everything else the
same.
15. We want to fit a straight line model of the form yi ¼ a þ bxi to the list of x; y
pairs given below. The data have Gaussian distributed errors in both the x
and y coordinates with x ¼ 1 and y ¼ 2. Assume uniform priors for a and b,
with boundaries that enclose the range of parameter space where there is a
significant contribution from the likelihood function. This means that we can
treat the prior as a constant, and write pða; bjD; M; IÞ / pðDjM; a; b; IÞ.
ff5; 1:22g; f4; 3:28g; f3; 2:52g; f2; 3:74g; f1; 3:01g; f0; 1:80g;
f1; 2:49g; f2; 5:48g; f3; 0:42g; f4; 4:80g; f5; 4:22gg
(a) Plot the data with error bars in both coordinates.
(b) Show a contour plot of the joint posterior PDF, pða; bjD; IÞ.
(c) For what choice of a; b is pða; bjD; IÞ a maximum? You can use the
Mathematica command
FindMaximum[ p(a, b|D, I),{a, 0:0},{b, 0:5}].
(d) Show the best fit line and data with error bars on the same plot.
(e) Compute and plot the marginal distributions pðajD; IÞ and pðbjD; IÞ. One
way to do this is to compute a table of the joint posterior values for a grid of
a; b values and approximate the integrals required for marginalization by a
summation over the rows or columns. Make sure to normalize your mar-
ginal distributions so
R
pðajD; IÞda ¼ 1  P
i pðaijD; IÞa.
4.10 Problems
95

5
Frequentist statistical inference
5.1 Overview
We now begin three chapters which are primarily aimed at a discussion of the main
concepts of frequentist statistical inference. This is currently the prevailing approach to
much of scientific inference, so a student should understand the main ideas to appre-
ciate current literature and understand the strengths and limitations of this approach.
In this chapter, we introduce the concept of a random variable and discuss some
general properties of probability distributions before focusing on a selection of
important sampling distributions and their relationships. We also introduce the very
important Central Limit Theorem in Section 5.9 and examine this from a Bayesian
viewpoint in Section 5.10. The chapter concludes with the topic of how to generate
pseudo-random numbers of any desired distribution, which plays an important role in
Monte Carlo simulations.
In Chapter 6, we address the question of what is a statistic and give some
common important examples. We also consider the meaning of a frequentist
confidence interval for expressing the uncertainty in parameter values. The reader
should be aware that study of different statistics is a very big field which we only
touch on in this book. Some other topics normally covered in a statistics course like
the fitting of models to data are treated from a Bayesian viewpoint in later chapters.
Finally, Chapter 7 concludes our brief summary of frequentist statistical inference
with the important topic of frequentist hypothesis testing and discusses an important
limitation known as the optional stopping problem.
5.2 The concept of a random variable
Recall from Section 1.1 that conventional ‘‘frequentist’’ statistical inference and Bayesian
inference employ fundamentally different definitions of probability. In frequentist
statistics, when we write the probability pðAÞ, the argument of the probability is called
a random variable. It is a quantity that can be considered to take on various values
throughout an ensemble or a series of repeated experiments. For example:
1. A measured quantity which contains random errors.
2. Time intervals between successive radioactive decays.
96

Before proceeding, we need an operational definition of a random variable. From
this, we discover that the random variable is not the particular number recorded in one
measurement, but rather, it is an abstraction of the measurement operation or
observation that gives rise to that number.
Definition: A random variable, X, transforms the possible outcomes of an experiment
(measurement operation) to real numbers.
Example: Suppose we are interested in measuring a pollutant’s concentration level for
each of n time intervals. The observations (procedure for producing a real number)
X1; X2; . . . ; Xn form a sample of the pollutant’s concentration. Before the instrument
actually records the concentration level during the ith trial, the observation, Xi, is a
random variable. The recorded value, xi, is not a random variable, but the actual
measured value of the observation, Xi.
Question: Why do we need to have n random variables Xi? Why not one random
variable X for which x1; x2; . . . ; xn are the realizations of the random variable during
the n observations?
Answer: Because we often want to determine the joint probability of getting x1 on trial
1, x2 on trial 2, etc. If we think of each observation as a random variable, then we
can distinguish between situations corresponding to:
1. Sampling with replacement so that no observation is affected by any other (i.e., independent
X1; X2; . . . ; Xn). In this case, all observations are random variables with identical probability
distributions.
2. Sampling without replacement. In this case, the observations are not independent and hence
are characterized by different probability distributions. Think of an urn filled with black and
white balls. When we don’t replace the drawn balls, the probability of say a black on each
draw is different.
5.3 Sampling theory
The most important aspect of frequentist statistics is the process of drawing conclu-
sions based on sample data drawn from the population (which is the collection of all
possible samples). The concept of the population assumes that in principle, an infinite
number of measurements (under identical conditions) are possible. The use of the term
random variable conveys the idea of an intrinsic uncertainty in the measurement
characterized by an underlying population.
Question: What does the term ‘‘random’’ really mean?
Answer: When we randomize a collection of balls in a bottle by shaking it, this is
equivalent to saying that the details of this operation are not understood or too
complicated to handle. It is sometimes necessary to assume that certain complicated
details, while undeniably relevant, might nevertheless have little numerical effect on
5.3 Sampling theory
97

the answers to certain questions, such as the probability of drawing r black balls
from a bottle in n trials when n is sufficiently small.
According to E. T. Jaynes (2003), the belief that ‘‘randomness’’ is some kind of
property existing in nature is a form of Mind Projection Fallacy which says, in effect,
‘‘I don’t know the detailed causes – therefore Nature is indeterminate.’’ For example,
later in this chapter we discuss how to write computer programs which generate
seemingly ‘‘random’’ numbers, yet all these programs are completely deterministic.
If you did not have a copy of the program, there is almost no chance that you could
discover it merely by examining more output from the program. Then the Mind
Projection Fallacy might lead to the claim that no rule exists. At scales where quantum
mechanics becomes important, the prevailing view is that nature is indeterminate. In
spite of the great successes of the theory of quantum mechanics, physicists readily admit
that they currently lack a satisfactory understanding of the subject. The Bayesian
viewpoint isthatthelimitationinscientificinferenceresultsfromincompleteinformation.
In both Bayesian and frequentist statistical inference, certain sampling distributions
(e.g., binomial, Poisson, Gaussian) play a central role. To the frequentist, the sampling
distribution is a model of the probability distribution of the underlying population
from which the sample was taken. From this point of view, it makes sense to interpret
probabilities as long-run relative frequencies.
In a Bayesian analysis, the sampling distribution is a mathematical description of
the uncertainty in predicting the data for any particular model because of incomplete
information. It enables us to compute the likelihood pðDjH; IÞ.
In Bayesian analysis, any sampling distribution corresponds to a particular state of
knowledge. But as soon as we start accumulating data, our state of knowledge
changes. The new information necessarily modifies our probabilities in a way that
can be incomprehensible to one who tries to interpret probabilities as physical caus-
ations or long-run relative frequencies.
5.4 Probability distributions
Now that we have a better understanding of what a random variable is let’s restate the
frequentist definition of probability more precisely. It is commonly referred to as the
relative frequency definition.
Relative frequency definition of probability: If an experiment is repeated n times under
identical conditions and nx outcomes yield a value of the random variable X ¼ x, the
limit of nx=n, as n becomes very large,1 is defined as pðxÞ, the probability that X ¼ x.
Experimental outcomes can be either discrete or continuous. Associated with each
random variable is a probability distribution. A probability distribution may be
1 See Bernoulli’s law of large numbers discussed in Section 4.2.1.
98
Frequentist statistical inference

quantitatively and conveniently described by two functions pðxÞ and FðxÞ which are
given below for the discrete and continuous cases.
1. Discrete random variables
Probability distribution function: (Also called the probability mass function). pðxiÞ
gives the probability of obtaining the particular value of the random variable X ¼ xi.
(a) pðxÞ ¼ pfX ¼ xg
(b) pðxÞ  0
for all x
(c) P
x pðxÞ ¼ 1
Cumulative probability function: this gives the probability that the random variable
will have a value  x.
(a) FðxÞ ¼ pfX  xg ¼
X
xi¼x
xi¼0
pðxiÞ
(b) 0  FðxÞ  1
(c) FðxjÞ > FðxiÞ if xj > xi
(d) FfX > xg ¼ 1  FðxÞ
Figure 5.1 shows the discrete probability distribution (binomial) describing the num-
ber of heads in ten throws of a fair coin. The right panel shows the corresponding
cumulative distribution function.
2. Continuous random variables2
Probability density function: fðxÞ
(a) pfa  X  bg ¼
R b
a fðxÞ dx
(b) fðxÞ  0ð1 < x < 1Þ
(c)
R þ1
1 fðxÞdx ¼ 1
2
4
6
8
10
x (number of heads)
0.1
0.2
p (x) 
2
4
6
8
10
x (number of heads)
0.2
0.4
0.6
0.8
1
F (x) 
Figure 5.1 The left panel shows the discrete probabilities for the number of heads in ten throws
of a fair coin. The right panel shows the corresponding cumulative distribution function.
2 Continuous density function defined by fðX ¼ xÞ ¼ lim
x!0½fðx < X < x þ xÞ=x.
5.4 Probability distributions
99

Cumulative probability density function:
(a) FðxÞ ¼ pfX  xg ¼
R x
1 fðxÞdx
(b) Fð1Þ ¼ 0; Fðþ1Þ ¼ 1
(c) pfa < X < bg ¼ FðbÞ  FðaÞ
(d) dFðxÞ
dx ¼ fðxÞ
Figure 5.2 shows an example of a continuous probability density function (left
panel) and the corresponding cumulative probability density function (right panel).
5.5 Descriptive properties of distributions
The expectation value for a function, gðXÞ, of a random variable, X, is the weighted
average of the function over all possible values of x. We will designate the expectation
value of gðXÞ by hgðXÞi, which is given by
hgðXÞi ¼
P
all x gðxÞ pðxÞ
(discrete),
R þ1
1 gðxÞ fðxÞdx
(continuous).

(5:1)
The result, if it exists, is a fixed number (not a function) and a property of the
probability distribution of X. The expectation defined above is referred to as the
first moment of the distribution gðXÞ. The shape of a probability distribution can be
rigorously described by the value of its moments:
The rth moment of the random variable X about the origin ðx ¼ 0Þ is defined by
0
r ¼ hXri ¼
P
x xrpðxÞ
(discrete),
R þ1
1 xrfðxÞdx
(continuous).
(
(5:2)
Mean ¼ 0
1 ¼ hXi ¼  ¼ first moment about the origin. This is the usual measure of
the location of a probability distribution.
The rth central moment ðorigin ¼ meanÞ of X is defined by
r ¼ hðX  Þri ¼
P
xðx  ÞrpðxÞ
(discrete),
R þ1
1 ðx  ÞrfðxÞdx
(continuous).
(
(5:3)
1
2
3
4
5
6
x
0.1
0.2
0.3
0.4
0.5
0.6
f (x) 
1
2
3
4
5
6
x
0.2
0.4
0.6
0.8
1
F (x)
Figure 5.2 The left panel shows a continuous probability density function and the right panel
shows the corresponding cumulative probability density function.
100
Frequentist statistical inference

The distinction between r and 0
r is simply that in the calculation of r the origin is
shifted to the mean value of x.
First central moment: hðX  Þi ¼ hXi   ¼ 0.
Second central moment: VarðXÞ ¼ 2
x ¼ hðX  Þ2i, where 2
x ¼ usual measure of
dispersion of a probability distribution.
hðX  Þ2i ¼ hðX2  2X þ 2Þi ¼ hX2i  2hXi þ 2
¼ hX2i  22 þ 2 ¼ hX2i  2 ¼ hX2i  hXi2
Therefore; 2 ¼ hX2i  hXi2:
(5:4)
The standard deviation, , equal to the square root of the variance, is a useful measure
of the width of a probability distribution.
It is frequently desirable to compute an estimate of 2 as the data are being acquired.
Equation (5.4) tells us how to accomplish this, by subtracting the square of the average
of the data from the average of the data values squared. Later, in Section 6.3, we will
introduce a more accurate estimate of 2 called the sample variance.
Box 5.1
Question: What is the variance of the random variable Y ¼ aX þ b?
Solution:
VarðYÞ ¼ hðY  yÞ2i ¼ hfðaX þ bÞ  ðaX þ bÞg2i
¼ hfaX  ag2i
¼ ha2X2  2a2X þ a22i ¼ a2ðhX2i  hXi2Þ
¼ a2VarðXÞ
Third central moment: 3 ¼ hðX  Þ3i:
This is a measurement of the asymmetry or skewness of the distribution. For a
symmetric distribution, 3 ¼ 0 and 2nþ1 ¼ 0 for any integer value of n.
Fourth central moment: 4 ¼ hðX  Þ4i:
4 is called kurtosis (another shape factor). It is a measure of how flat-topped a
distribution is near its peak. See Figure 5.3 and discussion in the next section for an
example.
5.5.1 Relative line shape measures for distributions
The shape of a distribution cannot be entirely judged by the values of 3 and 4
because they depend on the units of the random variable. It is better to use measures
relative to the distribution’s dispersion.
5.5 Descriptive properties of distributions
101

Coefficient of skewness: 3 ¼
3
ð2Þ3=2.
Coefficient of kurtosis: 4 ¼
4
ð2Þ2.
Figure 5.3 illustrates a single peaked distribution for different 3 and 4
coefficients. Note: 4 ¼ 3 for any Gaussian distribution so distributions with
4 > 3 are more sharply peaked than a Gaussian, while those with 4 < 3 are
more flat-topped.
5.5.2 Standard random variable
A random variable X can always be converted to a standard random variable Z using
the following definition:
Z ¼ X  
x
:
(5:5)
Z has a mean hZi ¼ 0, and variance hZ2i ¼ 2
z ¼ 1.
α3 > 0 ≡ positively skewed →
α3 > 0 ≡ negatively skewed →
α3 = 0 ≡ symmetric →
α3 > 3 leptokurtic ≡ highly-peaked →
α3 > 3 platykurtic ≡ flat-topped →
Figure 5.3 Single peak distributions with different coefficients of skewness and kurtosis.
102
Frequentist statistical inference

For any particular value x of X, the quantity z ¼ ðx  Þ=x indicates the deviation of
x from the expected value of X in terms of standard deviation units. At several points
in this chapter we will find it convenient to make use of the standard random variable.
5.5.3 Other measures of central tendency and dispersion
Median: The median is a measure of the central tendency in the sense that half the area
of the probability distribution lies to the left of the median and half to the right. For
any continuous random variable, the median is defined by
pðX  medianÞ ¼ pðX  medianÞ ¼ 1=2:
(5:6)
If a distribution has a strong central peak, so that most of its area is under a single
peak, then the median is an estimator of the central peak. It is a more robust estimator
than the mean: the median fails as an estimator only if the area in the tail region of the
probability distribution is large, while the mean fails if the first moment of the tail is
large. It is easy to construct examples where the first moment of the tail is large even
though the area is negligible.
Mode: Defined to be a value, xm of X, that maximizes the probability function (if X is
discrete) or probability density (if X is continuous). Note: this is only meaningful if
there is a single peak.
If X is continuous, the mode is the solution to
dfðxÞ
dx
¼ 0;
for
d2fðxÞ
dx2
< 0:
(5:7)
An example of the mode, median and mean for a particular PDF is shown in
Figure 5.4.
0
0.2
0.4
0.6
0.8
1
x
0.5
1
1.5
2
2.5
3
Probability density
mean
median
mode
Figure 5.4 The mode, median and mean are three different measures of this probability density
function.
5.5 Descriptive properties of distributions
103

5.5.4 Median baseline subtraction
Suppose you want to remove the baseline variations in some data without suppressing
the signal. Many automated signal detection schemes only work well if these baselines
variations are removed first. The upper panel of Figure 5.5 depicts the output from a
detector system with a signal profile represented by narrow Gaussian-like features
sitting on top of a slowly varying baseline with noise. How do we handle this problem?
Solution: Use running median subtraction.
One way to remove the slowly varying baseline is to subtract a running median. The
signal at sample location i is replaced by the original signal at i minus the median of all
values within ðN  1Þ=2 samples. N is chosen so it is large compared to the signal
profile width and short compared to baseline changes.
0
25
50
75
100
125
150
175
Sample number
0
0.5
1
1.5
2
2.5
Signal strength
0
25
50
75
100
125
150
175
Sample number
0
0.5
1
1.5
2
2.5
Signal strength
25
50
75
100
125
150
175
Sample number
0.5
1
1.5
2
2.5
3
3.5
Signal strength
(a)
(b)
(c)
Figure 5.5 (a) A signal profile sitting on top of a slowly varying baseline. (b) The same data with
the baseline variations removed by a running median subtraction. (c) The same data with the
baseline variations removed by a running mean subtraction; notice the negative bowl in the
vicinity of the source profile.
104
Frequentist statistical inference

Question: Why is median subtraction more robust than mean subtraction?
Answer: When the N samples include some of the signal points, both the mean value
and median will be elevated so that when the running subtraction occurs the signal
will sit in a negative bowl as is illustrated in Figure 5.5(c).
With mean subtraction, the size of the bowl will be proportional to the signal
strength. With median subtraction, the size of the bowl is smaller and essentially
independent of the signal strength for signals greater than noise. To understand
why, consider a running median subtraction with N ¼ 21 and a signal profile,
which for simplicity is assumed to have a width of only 1 sample. First, imagine
a histogram of the 21 sample values when no signal is present, i.e., just a
Gaussian noise histogram with some median, m0. Now suppose a signal of
strength S is added to sample 11, shifting it in the direction of increasing signal
strength. Let T11 be the value of sample 11 before the signal was added. There
are two cases of interest. (a) If T11 > m0 then T11 þ S > m0 and the addition of
the signal produces no change in the median value, i.e., the number of sample
values on either side of m0 is unchanged. (b) If T11 < m0, then the addition of S
can cause the sample to move to the other side of m0 thus increasing the median
by a small amount to m1. The size of S required to produce this small shift is S 
the RMS noise. Once sample 11 has been shifted to the other side, no further
increase in the value of S will change the median. Figure 5.5(b) shows the result
of a 21-point running median subtraction. The baseline curvature has been nicely
removed and there is no noticeable negative bowl in the vicinity of the source.
In the case of a running mean subtraction, the change in the mean of our 21 samples
is directly proportional to the signal strength S, which gives rise to the very noticeable
negative bowl that can be seen in Figure 5.5(c).
Mean deviation (alternative measure of dispersion)
hjX  ji ¼
P
all x jx  j pðxÞ
(discrete),
R þ1
1 jx  j fðxÞdx
(continuous).
(
(5:8)
For long-tailed distributions, the effect on the mean deviation of the values in the tail is
less than the effect on the standard deviation.
5.6 Moment generating functions
In Section 5.5 we looked at various useful moments of a random variable. It would be
convenient if we could describe all moments of a random variable in one function.
This function is called the moment generating function. We will use it directly to
compute moments for a variety of distributions. We will also employ the moment
generating function in the derivation of the Central Limit Theorem, in Section 5.9, and
5.6 Moment generating functions
105

in the proof of several theorems in Chapter 6. The moment generating function, mxðtÞ,
of the random variable X is defined by
mxðtÞ ¼ hetXi ¼
P
x etxpðxÞ
(discrete),
R þ1
1 etxfðxÞdx
(continuous),
(
(5:9)
where t is a dummy variable. The moment generating function exists if there is a
positive constant  such that mxðtÞ is finite for jtj  . The moments themselves are the
coefficients in a Taylor series expansion of the moment generating function (see
Equation ((5.12)) below) which converges for jtj  .
It can be shown that if a moment generating function exists, then it completely
determines the probability distribution of X, i.e., if two random variables
have the same moment generating function, they have the same probability
distribution.
The rth moment about the origin (see Equation (5.2)) is obtained by taking the rth
derivative of mxðtÞ with respect to t and then evaluating the derivative at t ¼ 0 as
shown in Equation (5.10).
drmxðtÞ
dtr

t ¼ 0
¼ dr
dtr hetXi

t ¼ 0
¼
dretX
dtr


t ¼ 0
¼ hXretXit ¼ 0 ¼ hXri
¼ 0
r:
(5:10)
For moments about the mean (central moments), we can use the central moment
generating function.
mxðtÞ ¼ hexpftðx  Þgi:
(5:11)
Now we use a Taylor series expansion of the exponential,
hexp½tðX  Þi ¼
1 þ tðX  Þ þ t2ðX  Þ2
2!
þ t3ðX  Þ3
3!
  
*
+
:
(5:12)
From the expansion, one can see clearly that each successive moment is obtained by
taking the next higher derivative with respect to t, each time evaluating the derivative
at t ¼ 0.
Example:
Let X be a random variable with probability density function
fðxÞ ¼
1
 expðx=Þ;
for x > 0;  > 0
0;
elsewhere.
(
(5:13)
106
Frequentist statistical inference

Determine the moment generating function and variance:
mxðtÞ ¼ 1

Z 1
0
expðtxÞ expðx=Þdx
¼ 1

Z 1
0
exp½ð1  tÞx=dx
¼

ð1  tÞ exp½ð1  tÞx=j1
0
¼ ð1  tÞ1
ðfor t < 1=Þ
(5:14)
dmxðtÞ
dt
t ¼ 0
j
¼ ð1  tÞ2
t ¼ 0
j
¼  ¼ hXi
(5:15)
d2mxðtÞ
dt2
t ¼ 0
j
¼ 22ð1  tÞ3
t ¼ 0
j
¼ 22 ¼ hX2i:
(5:16)
From Equation (5.4), the variance, 2, is given by
2 ¼ hX2i  hXi2 ¼ 22  2 ¼ 2:
(5:17)
5.7 Some discrete probability distributions
5.7.1 Binomial distribution
The binomial distribution3 is one of the most useful discrete probability distributions
and arises in any repetitive experiment whose result is either the occurrence or non-
occurrence of an event (only two possible outcomes, like tossing a coin). A large
number of experimental measurements contain random errors which can be repre-
sented by a limiting form of the binomial distribution called the normal or Gaussian
distribution (Section 5.8.1).
Let X be a random variable representing the number of successes (occurrences)
out of n independent trials such that the probability of success for any one trial
is p.4 Then X is said to have a binomial distribution with probability mass
function
pðxÞ ¼ pðxjn; pÞ ¼
n!
ðn  xÞ! x! pxð1  pÞnx;
for
x ¼ 0; 1; . . . ; n; 0  p  1;
(5:18)
which has two parameters n and p.
3 A Bayesian derivation of the binomial distribution is presented in Section 4.2.
4 Note: any time the symbol p appears without an argument, it will be taken to be a number representing the probability
of a success. pðxÞ is a probability distribution either discrete or continuous.
5.7 Some discrete probability distributions
107

Cumulative distribution function:
FðxÞ ¼
X
x
i ¼ 0
pðiÞ ¼
X
x
i ¼ 0
n
i
 
pið1  pÞðn  iÞ
n
i
 
¼ short-hand notation for number of combinations of
n items taken i at a time.
ð5:19Þ
Box 5.2 Mathematica cumulative binomial distribution:
Needs[‘‘Statistics ‘DiscreteDistributions’ ’’]
The probability of at least x successes in n binomial trials is given by
(1 – CDF[BinomialDistribution[n; p], x])
! answer ¼ 0:623 ðn ¼ 10; p ¼ 0:5; x ¼ 4Þ
Moment generating function of a binomial distribution:
We can apply Equation (5.9) to compute the moment generating function of the
binomial distribution.
mxðtÞ ¼ hetxi ¼
X
n
x ¼ 0
etx n
x
 
pxð1  pÞnx
(5:20)
mxðtÞ ¼
X
n
x¼0
n!
ðn  xÞ! x! ðetpÞxð1  pÞnx
¼ ð1  pÞn þ nð1  pÞn1ðetpÞ þ    þ
n!
ðn  kÞ! ð1  pÞnkðetpÞn
þ    þ ðetpÞn
¼ binomial expansion of ½ð1  pÞ þ etpn:
Therefore, mxðtÞ ¼ ½1  p þ etpn.
From the first derivative, we compute the mean, which is given by
mean ¼ 0
1 ¼ dmxðtÞ
dt

t¼0¼ n½1  p þ etpn1etp t¼0
j
¼ np.
The second derivative yields the second moment:
0
2 ¼ d2mxðtÞ
dt2
¼ nðn  1Þ½1  p þ etpn2ðetpÞ2 þ n½1  p þ etpn1etp t ¼ 0
j
¼ nðn  1Þp2 þ np:
108
Frequentist statistical inference

But 0
2 ¼ hX2i, and therefore, the variance 2 is given by
2 ¼ hðX  Þ2i ¼ hX2i  hXi2 ¼ hX2i  2
¼ nðn  1Þp2 þ np  ðnpÞ2
2 ¼ npð1  pÞ
(variance of binomial distribution):
(5:21)
Box 5.3 Mathematica binomial mean and variance
The same results could be obtained in Mathematica with the commands:
Mean[BinomialDistribution[n, p]]
Variance[BinomialDistribution[n, p]].
5.7.2 The Poisson distribution
The Poisson distribution was derived by the French mathematician Poisson in 1837,
and the first application was to the description of the number of deaths by horse
kicking in the Prussian army. The Poisson distribution resembles the binomial dis-
tribution if the probability of occurrence of a particular event is very small. Let X be a
random variable representing the number of independent random events that occur at
a constant average rate in time or space. Then X is said to have a Poisson distribution
with probability function
pðxjÞ ¼
ex
x!
;
for x ¼ 0; 1; 2; . . . and  > 0
0;
elsewhere.
8
<
:
(5:22)
The parameter of the Poisson distribution is , the average number of occurrences
of the random event in some time or space interval. pðxjÞ is the probability of x
occurrences of the event in a specified interval.5
The Poisson distribution is a limiting case of the binomial distribution in the limit of large
n and small p:
The following calculation illustrates the steps in deriving the Poisson distribution as
a limiting case of the binomial distribution.
Binomial distribution:
pðxjn; pÞ ¼
n!
ðn  xÞ!x! pxð1  pÞnx;
(5:24)
5 In Section 4.7, we derived the Poisson distribution by using probability theory as logic, directly from a statement of a
particular state of prior information. In that treatment, the Poisson distribution was written as
pðnjr; t; IÞ ¼ ertðrtÞn
n!
:
ð5:23Þ
From a comparison of Equations (5.23) and (5.22), it is clear that the symbol , the average number of occurrences in a
specified interval, is equal to rt where r is rate of occurrence and t is a specified time interval. Also, in the current chapter,
the symbol x will be used in place of n.
5.7 Some discrete probability distributions
109

where p is the probability of a single occurrence in a sample n in some time interval.
Multiply the numerator and denominator of Equation (5.24) by nx and substitute the
following expansion:
n!=ðn  xÞ! ¼ nðn  1Þðn  2Þ . . . ðn  x  1Þ:
(5:25)
With these changes, Equation (5.24) becomes
pðxjn; pÞ ¼ nðn  1Þðn  2Þ . . . ðn  x  1Þ
nxx!
ðnpÞxð1  pÞnx
¼ nðn  1Þ . . . ðn  x  1Þ
nx
x
x! ð1  pÞnx
¼ 1ð1  1
nÞð1  2
nÞ . . . ð1  ðx1Þ
n Þ
ð1  pÞx
x
x! ð1  pÞn;
(5:26)
where  has replaced the product np.
Now ð1  pÞn  ½ð1  pÞ1=pnp ¼ ½ð1  pÞ1=p and by definition lim
z!0ð1 þ zÞ1=z ¼ e.
Let z ¼ p, then lim
p!0½ð1  pÞ1=p ¼ e.
Moreover,
lim
n!1ð1  1=nÞð1  2=nÞ . . . ð1  ðx  1Þ=nÞ ¼ 1
(5:27)
and,
lim
p!0ð1  pÞx ¼ 1:
(5:28)
Therefore,
lim
n!1; p!0 pðxjn; pÞ ¼ ex
x!
;
x ¼ 0; 1; 2; . . .
(5:29)
Thus, the Poisson distribution is a limiting case of the binomial distribution in the
limit of large n and small p. To make use of the binomial distribution we need to
know both n and p. In some instances the only information we have is the their
product, i.e., the mean number of occurrences, . For example, traffic accidents are
rare events and the number of accidents per unit of time is well described by the
Poisson distribution. The number of traffic accidents that occur each day is usually
recorded by the police department, but not the number of cars that are not involved
in an accident.
Mean of a Poisson distribution:
 ¼ hXi ¼
X
1
x ¼ 0
x xe
x!
¼ e X
1
x ¼ 0
x1
ðx  1Þ! :
(5:30)
110
Frequentist statistical inference

Let y ¼ x  1
 ¼ e X
1
y ¼ 0
y
y! ¼ ee ¼ :
(5:31)
The mean of a Poisson distribution ¼ . (For a binomial distribution  ¼ np)
Cumulative distribution:
FðxjÞ ¼
X
x
xi ¼ 0
xie
xi!
:
(5:32)
Poisson variance:
2ðXÞ ¼ hX2i  hXi2
(5:33)
hX2i ¼ hXðX  1Þ þ Xi ¼ hXðX  1Þi þ hXi:
(5:34)
Then
hXðX  1Þi ¼
X
1
x¼0
xðx  1Þxe
x!
¼ e2 X
1
x ¼ 2
x2
ðx  2Þ!
¼ 2eeþ
¼ 2 ¼ 2:
(5:35)
Then
hX2i ¼ 2 þ 
2ðXÞ ¼ 2 þ   hXi2 ¼ 
! ðXÞ ¼
ﬃﬃﬃ
p :
Note: for a binomial distribution, 2 ¼ npð1  pÞ ! np ¼  as p ! 0.
Figure 5.6 illustrates how the shape of the Poisson distribution varies with . As 
increases, the shape of the Poisson distribution asymptotically approaches a Gaussian
distribution. The dashed curve in the  ¼ 40 panel is a Gaussian distribution with a
mean ¼  and a standard deviation ¼
ﬃﬃﬃ

p
.
Examples of situations described by a Poisson distribution:
* Number of telephone calls on a line in a given interval.
* Number of shoppers entering a store in a given interval.
* Number of failures of a product in a given interval.
* Number of photons detected from a distant quasar in a given time interval.
* Number of meteorites to fall per unit area of land.
5.7 Some discrete probability distributions
111

5.7.3 Negative binomial distribution
Imagine a binomial scenario involving a sequence of independent trials where the
probability of success of each trial is p. Instead of fixing the number of trials, n,
suppose we continue the trials until exactly k successes have occurred.6 Here, the
random variable is n, the number of trials necessary for exactly k successes. If
the independent trials continue until the kth success, then the last trial must have
been a success. Prior to the last trial, there must have been k  1 successes in n  1
trials. The number of distinct ways k  1 successes can be observed in n  1 trials is
n1
k1

	
. Therefore, the probability of k successes in the n trials with the last being
a success is
pðnjk; pÞ ¼
n  1
k  1


pk1ð1  pÞnk 	 p1 ¼
n  1
k  1


pkð1  pÞnk:
(5:36)
Equation (5.36) is called the negative binomial distribution.
Let the number of trials required to achieve k successes ¼ X þ k. Then random
variable X is the number of failures before k successes, which is given by
pðxjk; pÞ ¼
k þ x  1
k  1


pkð1  pÞx;
x ¼ 0; 1; 2; . . .
k ¼ 1; 2; . . .
0  p  1
0;
elsewhere.
8
>
>
>
>
<
>
>
>
>
:
For the special case of one success k ¼ 1, the above distribution is known as the
geometric distribution.
pðxjpÞ ¼ pð1  pÞx:
(5:37)
The geometric random variable represents the number of failures before the first
success.
0
1
2
3
4
5
6
x
0.1
0.2
0.3
0.4
p (x)
λ = 1
0
1
2
3
4
5
6
x
0.1
0.2
0.3
p (x)
λ = 2
20
30
40
50
60
x
0.01
0.02
0.03
0.04
0.05
0.06
p (x)
λ = 40
Figure 5.6 As  increases, the shape of the Poisson distribution becomes more symmetric.
6 For example, an astronomer could plan to continue taking spectra of candidate stars until exactly 50 white dwarfs have
been detected.
112
Frequentist statistical inference

5.8 Continuous probability distributions
5.8.1 Normal distribution
The normal (Gaussian) distribution is the most important and widely used probability
distribution. One of the reasons why the normal distribution is so useful is because of
the Central Limit Theorem. This theorem will be discussed in detail later, but briefly, it
says the following: suppose you have a radioactive source and you measure the
average number of decays in one hundred 10-second intervals. (We know that the
individual counts obey a Poisson distribution). If you repeated the experiment many
times and hence determined a large number of averages then, according to the Central
Limit Theorem, the averages will be normally distributed.
The distribution of the sample means (from populations with a finite mean and
variance) approaches a normal distribution as the number of terms in the mean
approaches infinity. It can be shown to be the limit of a binomial distribution as
n ! 1 and np 
 1.
Corollary: Whenever a random variable can be assumed to be the result of a large
number of small effects, the distribution is approximately normal.
Gaussian probability density function:
fXðxÞ ¼ fðxj; Þ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p

exp
 ðx  Þ2
22
(
)
(5:38)
for  1 < x < 1; 1 <  < 1; 0 < 2 < 1:
Box 5.4
Mathematica evaluation of a Gaussian or normal distribution:
Needs[‘‘Statistics‘ContinuousDistributions ’ ’’]
The line above loads a package containing a wide range of continuous distribu-
tions of importance to statistics, and the following line computes the probability
density function at x for a normal distribution with mean  and standard devia-
tion .
PDF[NormalDistribution[ m, s],x]
! answer ¼ 0:45662 ð ¼ 2:0;  ¼ 0:4; x ¼ 1:5Þ
The mean and standard deviation of the distribution are given by
Mean[NormalDistribution[ m, s]]
! answer ¼ 
StandardDeviation[NormalDistribution[m; s]]
! answer ¼ 
5.8 Continuous probability distributions
113

Central moment generating function:
mXðtÞ ¼ hexpftðX  Þgi
¼
1ﬃﬃﬃﬃﬃﬃ
2p
p

Z þ1
1
expftðx  Þg exp
 ðx  Þ2
22
(
)
dx
¼
1ﬃﬃﬃﬃﬃﬃ
2p
p

Z þ1
1
exp  1
22 fðx  Þ2  22tðx  Þg


dx:
Adding and subtracting 4t2 in the term in the curly braces:
fðx  Þ2  22ðx  Þt þ 4t2  4t2g ¼ f½x    2t2  4t2g
! mXðtÞ ¼ exp 2t2
2


1ﬃﬃﬃﬃﬃﬃ
2p
p

Z þ1
1
exp
 ðx    2t2Þ2
22
(
)
dx
¼ exp 2t2
2


¼ 1 þ 2t2
2
þ 4t4
4 	 2! þ 6t6
8 	 3! . . .
VarðXÞ ¼ d2mXðtÞ
dt2

t¼0
¼ 2
3 ¼ 0 and 4 ¼ 4!4
4 	 2! ¼ 34
4 ¼ coefficient of kurtosis ¼
4
ð2Þ2 ¼ 3.
Note: for a Poisson distribution, 4 ¼ 3 þ 1
 ! 3 as  ! 1.
Also, for a binomial distribution 4 ¼ 3 þ ½1  6pð1  pÞ
npð1  pÞ
! 3 as n ! 1.
Convention:
If the random variable X is known to follow a normal distribution with mean  and
variance 2, then it is common to abbreviate this by
X  Nð; 2Þ:
For convenience, the following transformation to the standard random variable is
often made:
Z ¼ X  

 Nð0; 1Þ:
In terms of Z the normal distribution becomes
fðZÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p
exp  z2
2 :
Cumulative distribution function:
FðxÞ  Fðxj; Þ ¼ pðX  xÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p

Z x
1
exp
 ðt  Þ2
22
(
)
dt:
114
Frequentist statistical inference

This integral cannot be integrated in closed form. Fðxj; Þ can be tabulated as a
function of  and , which requires a separate table for each pair of values. Since there
are an infinite number of values for  and , this task is not practical.
Instead, it is common to calculate the cumulative distribution function of the
standard random variable Z. Then:
pðX  xÞ ¼ p Z  x  

h
i
¼
1ﬃﬃﬃﬃﬃﬃ
2p
p
Z
z ¼ x

ð
Þ
1
exp  z
02
2


dz0 ¼ FðzÞ:
Usually, FðzÞ is expressed in terms of the error function, erf(z).
erfðzÞ ¼ 2ﬃﬃﬃp
p
Z z
0
exp ðu2Þdu
erfðzÞ ¼ erfðzÞ:
(5:39)
Then FðzÞ ¼ 1
2 þ 1
2 erfðz=
ﬃﬃﬃ
2
p
Þ. The error function is in many computer libraries.
Box 5.5
In Mathematica, it can be evaluated with the command Erf[z].
However, it is simpler to compute the cumulative probability with the
Mathematica command: CDF[NormalDistribution[ m, s], x].
For any normally distributed random variable:
pð    X   þ Þ ¼ 0:683
pð  2  X   þ 2Þ ¼ 0:954
pð  3  X   þ 3Þ ¼ 0:997
pð  4  X   þ 4Þ ¼ 0:999 937
pð  5  X   þ 5Þ ¼ 0:999 999 43:
Figure 5.7 shows graphs of the normal distribution (left) and the cumulative normal
distribution (right) for three different values of .
1
2
3
4
5
6
x
0.2
0.4
0.6
0.8
1
f (x)
σ = 1.0
σ =  0.7
σ = 0.35
1
2
3
4
5
6
x
0.2
0.4
0.6
0.8
1
F (x)
Figure 5.7 Graphs of the normal distribution (left) and the cumulative normal distribution (right).
5.8 Continuous probability distributions
115

5.8.2 Uniform distribution
Examples of a uniform distribution include round-off errors and quantization of noise
in linear analog-to-digital conversion.
A random variable is said to be uniformly distributed over the interval (a; b) if
fðxja; bÞ ¼
1=ðb  aÞ;
for a  x  b
0;
elsewhere

(5:40)
mean ¼ ða þ bÞ=2;
3 ¼ 0
variance ¼ ðb  aÞ2=12;
4 ¼ 9=5
no mode;
median ¼ mean:
Thespecialcaseofa ¼ 0 andb ¼ 1 playsakeyroleinthecomputersimulationof values
of a random variable with a specified distribution, which will be discussed in Section 5.13.
Cumulative distribution function:
Fðxja; bÞ ¼
0;
for x < a
ðx  aÞ=ðb  aÞ;
for a  x  b
1;
for x > b.
8
<
:
(5:41)
5.8.3 Gamma distribution
The gamma distribution is used extensively in several diverse areas. For example, it is
used to represent the random time until the occurrence of some event which occurs
only if exactly  independent sub-events occur where the sub-events occur at an
average rate  ¼ 1= per unit of time.
fðxÞ ¼ fðxj; Þ ¼
1
ðÞ x1 exp ðx=Þ;
for x > 0; ;  > 0
0;
elsewhere.
8
<
:
(5:42)
mean ¼ 
variance ¼ 2
3 ¼ 2=
ﬃﬃﬃﬃ
p
4 ¼ 3 1 þ 2


	
Note: ðnÞ, the gamma function ¼ R 1
0 u n1 exp ðuÞdu for n > 0. Some properties
of the gamma function are:
1. ðn þ 1Þ ¼ n! (for n an integer)
2. ðn þ 1Þ ¼ nðnÞ
3. ð1=2Þ ¼
ﬃﬃﬃp
p
Cumulative distribution function:
The cumulative distribution function can be expressed in closed form if the shape
parameter  is a positive integer.
116
Frequentist statistical inference

Fðxj; Þ ¼ 1  1 þ x
 þ 1
2!
x

 2
þ    þ
1
ð  1Þ!
x

 1


exp ðx=Þ:
(5:43)
Example:
Suppose a metal specimen will break after exactly two stress cycles. If stress occurs
independently and at an average rate of 2 per 100 hours, determine the probability that
the length of time until failure is within one standard deviation of the average time.
Solution: Let X be a random variable representing the length of time until the second
stress cycle. X is gamma-distributed with  ¼ 2 and  ¼ 50.
 ¼ mean ¼  ¼ 2 	 50 ¼ 100
standard deviation ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
2
p
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2 	 502
p
¼ 70:71
pð   < X <  þ Þ ¼ pð29:29 < X < 170:71Þ
¼ Fð170:71j2; 50Þ  Fð29:28j2; 50Þ:
Equation (5.43) for the cumulative distribution function reduces to:
Fðxj; Þ ¼ 1  ð1 þ x=50Þ exp ðx=50Þ;
x > 0
! pð   < X <  þ Þ ¼ 0:7376:
When  is an integer, the gamma distribution is known as the Erlang probability
model after the Danish scientist who used it to study telephone traffic problems.
5.8.4 Beta distribution
While we are on the subject of sampling distribution, here is one that plays a useful role
in Bayesian inference. The family of beta distributions allows for a wide variety of shapes.
fðxÞ  fðxj; Þ ¼
ð þ Þ
ðÞðÞ x1ð1  xÞ1;
0 < x < 1
;  > 0
0;
elsewhere.
8
>
<
>
:
(5:44)
mean ¼ =ð þ Þ; variance ¼

ð1 þ Þ2ð þ  þ 1Þ
.
Note: the  appearing in the beta distribution has no connection with the  used in the
previously mentioned gamma distribution.
Some examples of the beta distribution are illustrated in Figure 5.8. Any smooth
unimodal distribution in the interval x ¼ 0 to 1 is likely to be reasonably well
approximated by a beta distribution, so it is often possible to approximate a
Bayesian prior distribution in this way. If the likelihood function is a binomial
distribution, then the Bayesian posterior will have a simple analytic form; namely,
another beta distribution. More generally, when both the prior and posterior belong
to the same distribution family (in this case the beta distribution), then the prior and
5.8 Continuous probability distributions
117

likelihood are called conjugate distributions. This can greatly simplify any calculations
that involve the posterior distribution. The beta distribution is often referred to as a
conjugate prior for the binomial likelihood.7 Other well-known examples of conjugate
priors are the Gaussian (when dealing with a Gaussian likelihood) and the gamma
distribution (when dealing with a Poisson likelihood). In each case, the posterior and
prior are members of the same family of distributions.
5.8.5 Negative exponential distribution
The negative exponential distribution is a special case of the gamma distribution for
 ¼ 1.
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)  
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
α = 0.5, β = 1.5
α = 1.0, β = 1.0
α = 1.0, β = 2.0
α = 3.0, β = 3.0
α = 1.5, β = 3.0
α = 1.5, β = 1.5
α = 3.0, β = 1.5
α = 0.5, β = 0.5
α = 1.5, β = 0.5
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
0.2 0.4 0.6 0.8
1
x
0.5
1
1.5
2
f (x)
Figure 5.8 Graphs of beta density function for various values of , .
7 For example, if the prior is a beta distribution, Be(;  ), then we can write
pðxjI Þ / x1ð1  xÞ1
ð0  x  1Þ :
ð5:45Þ
Suppose the likelihood is a binomial, with pð yjn; xÞ ¼ the probability of obtaining y successes in n trials where the
probability of success in any trial is x. Then we can write the likelihood as
pðDjx; I Þ / xyð1  xÞny:
ð5:46Þ
The posterior is proportional to the product of Equations (5.45) and (5.46), and given by
pðxjD; I Þ / xþy1ð1  xÞþny1
ð5:47Þ
which is another beta distribution, Beð þ y;  þ n  yÞ.
118
Frequentist statistical inference

fðxÞ  fðxjÞ ¼
1
 exp ðx=Þ;
for x > 0;  > 0
0;
elsewhere.
8
<
:
(5:48)
The random variable X is the waiting time until the occurrence of the first Poisson
event. That is, the negative exponential distribution can model the length of time
between successive Poisson events. It has been used extensively as a time-to-failure
model in reliability problems and in waiting-line problems.  is the mean time between
Poisson events.
The cumulative negative exponential distribution function is given by
FðxjÞ ¼ 1  expðx=Þ:
5.9 Central Limit Theorem
Let X1; X2; X3; . . . ; Xn be n independent and identically distributed (IID) random
variables with unspecified probability distributions, and having a finite mean, , and
variance, 2. The sample average, X ¼ ðX1 þ X2 þ X3 þ    þ XnÞ=n has a distribution
with mean  and variance 2=n that tends to a normal (Gaussian) distribution as
n ! 1. In other words, the standard random variable,
ðX  Þ
= ﬃﬃﬃn
p
! standard normal distribution:
Proof:
As a proof, we will show that the moment generating function of ðX  Þ
ﬃﬃﬃn
p = tends
to that of a standard normal as n ! 1.
Let
zi ¼ ðXi  Þ=;
i ¼ 1; n
hzii ¼ 0
hz2
i i ¼ 1
9
=
;by definition:
Let Y ¼ ðX  Þ
=
ﬃﬃﬃn
p
.
Now P
n
i¼1
zi ¼ 1

PðXi  Þ ¼ n
 ðX  Þ ¼
ﬃﬃﬃn
p Y or Y ¼
1ﬃﬃn
p P
n
i¼1
zi.
Then the moment generating function mYðtÞ is given by
mYðtÞ ¼ hexpðtYÞi ¼
exp t
X
n
i¼1
ziﬃﬃﬃn
p
 
!
*
+
¼
exp t ziﬃﬃﬃn
p



n
since the zi’s are IID:
5.9 Central Limit Theorem
119

Now
exp t ziﬃﬃﬃn
p


¼ 1 þ tziﬃﬃﬃn
p þ t2z2
i
2!n þ t3z3
i
3!n3=2 þ   
and since hzii ¼ 0; hz2
i i ¼ 1 for all i.
exp
tziﬃﬃﬃn
p




¼ 1 þ t2
2n þ t3hz3
i i
3!n3=2 þ   
mYðtÞ ¼
1 þ t2
2n þ t3hz3
i i
3!n3=2 þ   

n
¼
1 þ 1
n
t2
2 þ t3hz3
i i
3!
ﬃﬃﬃn
p
þ   



n
¼ 1 þ u
n
h
in
;
where u ¼
t2
2 þ t3hz3
i i
3!
ﬃﬃﬃn
p
þ   


lim
n!1 1 þ u
n
h
in
¼ eu:
In the limit as n ! 1, all terms in u ! 0 except the first, t2=2, since all other terms
have an n in the denominator.
lim
n ! 1 mYðtÞ ¼ lim
n ! 1 eu ¼ exp t2
2
¼ moment generating function of a standard normal.
This completes the proof.
5.10 Bayesian demonstration of the Central Limit Theorem
The proof of the CLT given in Section 5.9 does little to develop the reader’s intuition
on how it works and what are its limitations. To help on both counts, we give the
following demonstration of the CLT which is adapted from the work of M. Tribus
(1969). In data analysis, it is common practice to compute the average of a repeated
measurement and perform subsequent analysis using the average value.
The probability density function (PDF) of the average is simply related to the
PDF of the sum which is evaluated below using probability theory as logic. In this
demonstration, we will be concerned with measurements of the length of a widget8
which is composed of many identical components that have all been manufactured
on the same assembly line. Because of variations in the manufacturing process, the
widgets do not all end up with exactly the same length. The components are
analogs of the data points and the widget is the analog of the sum of a set of
data points.
8 A widget is some unspecified gadget or device.
120
Frequentist statistical inference

I  ‘‘a widget is composed of two components. Length of widget ¼ sum of compo-
nent lengths.’’
Y  ‘‘Length of widget lies between y and y þ dy.’’
Note: Y is a logical proposition which appears in the probability function and y is an
ordinary algebraic variable.
X1  ‘‘Length of component 1 lies between x1 and x1 þ dx1.’’
X2  ‘‘Length of component 2 lies between x2 and x2 þ dx2.’’
We are given that
pðX1jIÞ ¼ f1ðx1Þ
pðX2jIÞ ¼ f2ðx2Þ:
Problem: Find pðYjIÞ.
Now Y depends on propositions X1 and X2. To evaluate pðYjIÞ, we first extend the
conversation (Tribus, 1969) to include these propositions by writing down the joint
probability distribution pðY; X1; X2jIÞ. We can then solve for pðYjIÞ by using the
marginalizing operation as follows:
pðYjIÞ ¼
Z Z
dX1dX2 pðY; X1; X2jIÞ
¼
Z Z
dX1dX2 pðX1jIÞpðX2jIÞpðYjX1; X2; IÞ;
where we assume X1 and X2 are independent.
Since y ¼ x1 þ x2,
pðYjX1; X2; IÞ ¼ ðy  x1  x2Þ
! pðYjIÞ ¼
Z
dx1 f1ðx1Þ
Z
dx2 f2ðx2Þðy  x1  x2Þ:
The presence of the delta function in the second integral serves to pick out the value
of the integrand at x2 ¼ y  x1, so we have
pðYjIÞ ¼
Z
dx1 f1ðx1Þf2ðy  x1Þ:
(5:49)
The right hand side of this equation is the convolution integral.9 The convolution
operation is demonstrated in Figure 5.9 for the case where both f1ðxÞ and f2ðxÞ are
uniform PDFs of the same width. The result is a triangular distribution.
9 For more details on the convolution integral and how to evaluate it using the Fast Fourier Transform, see Sections B.4
and B.10.
5.10 Bayesian demonstration of the Central Limit Theorem
121

What if the widget is composed of three components?
Let Z  ‘‘Length of widget is between z and z þ dz.’’
pðZjIÞ ¼
Z Z Z
dX1 dX2 dX3 pðZ; X1; X2; X3jIÞ
¼
Z Z
dY dX3 pðZ; X3; YjIÞ
¼
Z
dY pðYjIÞ
Z
dX3 pðX3jIÞ pðZjX3; Y; IÞ
where pðZjX3;Y;IÞ ¼ ðz yx3Þ and pðYjIÞ is the solution to the two-component case.
Convolution
−1
0
1
2
y
f1(x)
0
1
2
x
f2(y − x)
0
1
2
x
0
1
2
x
f2(x)
f2(−x)
0
1
2
x
−1
−1
−1
−1
Figure 5.9 The convolution operation.
122
Frequentist statistical inference

pðZjIÞ ¼
Z
dy pðYjIÞf3ðz  yÞ
¼
Z
dy fðyÞf3ðz  yÞ:
Another convolution!
Shown below, the probability density function (PDF) of the average is simply
related to the PDF of the sum (which we have just evaluated).
Let xA ¼ ðx1 þ x2 þ x3Þ=3 ¼ z=3 or z ¼ 3xA.
fðxAÞdxA ¼ fðzÞdz ¼ 3fðzÞdxA
! pðXAjIÞ ¼ 3pðZjIÞ:
Figure 5.10 compares the PDF of the average for the case of n ¼ 1, 2, 4 and 8
components. According to the Central Limit Theorem, pðXAjIÞ tends to a Gaussian
distribution as the number of data being averaged becomes larger. After averaging
only four components, the PDF has already taken on the appearance of a Gaussian. If
instead of a uniform distribution, our starting PDF had two peaks (bimodal), then a
larger number of components would have been required before the PDF of the average
was a reasonable approximation to a Gaussian. On the basis of this analysis, we come to
the following generalization of the Central Limit Theorem: ‘‘Any quantity that stems
from a large number of sub-processes is expected to have a Gaussian distribution.’’
The Central Limit Theorem (CLT) is both remarkable and of great practical value
in data analysis. In frequentist statistics, we are often uncertain of the form of the
sampling distribution the data are drawn from. The equivalent problem in a
Bayesian analysis is the choice of likelihood function to use. By working with
the averages of data points (frequently as few as five points), we can appeal to the
CLT and make use of a Gaussian distribution for the sampling distribution or
likelihood function. The CLT also provides a deep understanding for why meas-
urement uncertainties frequently have a Gaussian distribution. This is because the
0.2
0.4
0.6
0.8
1
X
0
1
2
3
PDF
n
1
n
2
n
4
n
6
n
8
0.2
0.4
0.6
0.8
1
X
0
1
2
3
4
PDF
Figure 5.10 The left panel shows a comparison of the probability density function of the average
for the case of n ¼ 1, 2, 4 and 8 components. The right panel compares the n ¼ 8 case to a
Gaussian (dashed curve) with the same mean and variance. The two curves are so similar it is
difficult to separate them.
5.10 Bayesian demonstration of the Central Limit Theorem
123

measured quantity is often the result of a large number of effects, i.e., is some kind
of averaged resultant of these effects (random variables in frequentist language).
Since the distribution of the average of a collection of random variables tends to a
Gaussian, this is often what we observe.
Two exceptions to the Central Limit Theorem exist. They are:
1. One of the pðXijIÞ is much broader than all of the others. It is apparent from the above
demonstration that convolving a very wide uniform distribution with a narrow uniform
distribution will give a result that is essentially the same as the original wide uniform
distribution.
2. The variances of one or more of the individual pðXijIÞ distributions are infinite. A Cauchy or
Lorentzian distribution is an example of such a distribution:
pðxj; ; IÞ ¼

p½ 2 þ ðx  Þ2
:
Its very wide wings lead to an infinite second moment, i.e., the variance of X is infinite and
the sample mean is not a useful quantity. One example of this is the natural line shape of a
spectral line.
5.11 Distribution of the sample mean
It is apparent from the previous section that the PDF of the sample mean (average)
rapidly approaches a Gaussian in shape and the width of this Gaussian becomes
narrower as the number of samples in the average increases. In this section, we want to
quantify this latter effect using the frequentist approach.
Let a random sample X1; X2; . . . ; Xn consist of n IID random variables such that
hXii ¼ 
and
VarðXiÞ ¼ 2:
Then
hXi ¼ h1
n
P Xii ¼ 1
n
PhXii ¼ 1
n
P 
! hXi ¼ ;
and
VarðXÞ ¼
ðX  Þ2
D
E
¼
1
n
X
Xi  1
n
X


2
*
+
¼ 1
n2
X
ðXi  Þ2
D
E
¼ 1
n2
X
ðXi  Þ2
D
E
¼ 1
n2
X
2 ¼ 1
n2 n2
VarðXÞ ¼ 2
n :
(5:50)
124
Frequentist statistical inference

The following is true for any distribution with a finite variance:
hXi ¼ 
VarðXÞ ¼ 2
n
Conclusion:
The distribution of a sample average X sharpens around  as the
sample size n increases.10 Signal averaging is based on this principle.
5.11.1 Signal averaging example
Every second a spectrometer output consisting of 64 voltage levels corresponding to
64 frequencies, is sampled by the computer. These voltages are added to a memory
buffer containing the results of all previous one-second spectrometer readings. The
accumulated spectra are shown in Figure 5.11 at different stages. Although no signal is
evident above the noise level in the first spectrum, the signal is clearly evident (near
channel 27) after eight spectra have been summed.
Let Si / nXi ¼ the signal in the ith channel of n summed spectra, and
Ni / n
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
VarðXiÞ
q
¼ the noise in the ith channel. Then
Si
Ni
¼
nXi
n=
ﬃﬃﬃn
p ¼
ﬃﬃﬃn
p Xi
 :
In radio astronomy, we are often trying to detect signals which are 103 of the noise.
For a S=N  5, n  2:5 	 107. However, in these cases, the time required for one
independent sample is often much less than one microsecond, and is determined by the
radio astronomy receiver bandwidth and detector time constant.
5.12 Transformation of a random variable
In Section 5.13, we will want to generate random variables having a variety of
probability distributions for use in simulating experimental data. To do that, we
must first learn about the probability distribution of a transformed random variable.
10 What happens to the average of samples drawn from a distribution which has an infinite variance? In this case, the
error bar for the sample mean does not decrease with increasing n. Even though the sample mean is not a good
estimator of the distribution mean , we can still employ Bayes’ theorem to compute the posterior PDF of  from the
available samples. The PDF continues to sharpen about  as the number of samples increases. For a good numerical
demonstration of this point, see the lighthouse problem discussed by Sivia (1996) and Gull (1988a).
5.12 Transformation of a random variable
125

Problem: How do we obtain the probability density function, fYðyÞ, of the transformed
random variable y, where y ¼ gðxÞ, from knowledge of the probability density
function, fXðxÞ, of the original random variable X?
The function y ¼ gðxÞ must be a monotonic (increasing or decreasing), differenti-
able function of x. Then there exists an inverse function x ¼ g1ðyÞ which is also
monotonic and differentiable and for every interval dx there is a corresponding
interval dy. Then the probability that y  Y  y þ dy must equal the probability
that x  X  x þ dx, or
j fYðyÞdyj ¼ j fXðxÞdxj:
(5:51)
Since probabilities are always positive, we can write
fYðyÞ ¼ fXðxÞ dx
dy

:
(5:52)
Sample
Spectrometer
Computer
memory
buffer
10
20
30
40
50
60
–1.5
–1
–0.5
0.5
1
10
20
30
40
50
60
–2
–1
1
2
3
10
20
30
40
50
60
–4
–2
2
4
6
8
10
20
30
40
50
60
–10
–5
5
10
15
1 spectrum
2 spectra
 
4 spectra
 
8 spectra
Figure 5.11 Signal averaging. Every second a spectrometer output consisting of 64 voltage levels,
corresponding to 64 frequencies, is added to a computer memory buffer. The summed spectra
are shown at different stages. Although no signal is evident above the noise level in the first
spectrum, the signal is clearly evident (near channel 27) after eight spectra have been summed.
126
Frequentist statistical inference

Example:
Find fZðzÞ, where Z is the standard random variable defined by Z ¼ ðX  Þ=, where
 ¼ mean and  ¼ standard deviation.
z ¼ gðxÞ ¼ x  

:
(5:53)
x ¼ g1ðzÞ ¼ z þ  and dx
dz ¼ :
(5:54)
Then from Equation (5.52), we can write fZðzÞ ¼ fXðxÞ.
Suppose fXðxÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p

exp  ðx  Þ2
22
(normal distribution).
Then from Equations (5.52) and (5.53), we obtain
fZðzÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p
exp  z2
2 :
(5:55)
5.13 Random and pseudo-random numbers
Computer simulations have become an extremely useful tool for testing data analysis
algorithms and analyzing complex systems, which are often comprised of many
interdependent components. Some examples of their use are given below.
* To simulate experimental data in the design of a complex detector system in many branches
of science.
* To test the effectiveness or completeness of some complex analysis program.
* To compute the uncertainties in the parameter estimates derived from nonlinear model fitting.
* To calculate the solution to a statistical mechanics problem which is not amenable to
analytical solution.
* To make unpredictable data for use in cryptography, to deal with a variety of authentication
and confidentiality problems.
What is usually done is to assume an appropriate probability distribution for each
distinct component and to generate a sequence of random or pseudo-random values
for each. There are many procedures, known by the generic name of Monte Carlo,11
that follow these lines and use the commodity called random numbers, which have to
be manufactured somehow. Typically, the sequences of random numbers are gener-
ated by numerical algorithms that can be repeated exactly; such sequences are not
truly random. However, they exhibit enough random properties to be sufficient for
most applications. We consider below, possible ways of generating random values
from some discrete and continuous probability distributions.
11 In Chapter 12, we discuss the important topic of Markov chain Monte Carlo (MCMC) methods, which are
dramatically increasing our ability to evaluate the integrals required in a Bayesian analysis of very complicated
problems.
5.13 Random and pseudo-random numbers
127

The uniform distribution on the interval (0, 1) plays a key role in the generation of
random values. From it, we can generate random numbers for any other distribution
using the following theorem:
Theorem:
For any continuous random variable X, the cumulative distribution function FðxjÞ
with parameter  may be represented by a random variable u, which is uniformly
distributed on the unit interval.
Proof:
By definition, FðxjÞ ¼
R x
1 fðtjÞdt. For each value of x, there is a corresponding
value of FðxjÞ which is necessarily in the interval (0,1). Also, FðxjÞ is a random
variable by virtue of the randomness of X. For each value u of the random variable u,
the function u ¼ FðxjÞ defines a one-to-one correspondence between U and X having
an inverse relationship x ¼ F1ðuÞ.
Recall that it was shown earlier how to obtain the PDF fðyÞ of the transformed
random variable Y ¼ gðXÞ from the knowledge of the PDF of X. The result was
fyðyÞ ¼ fXðxjÞ dx
dy

 ¼ fX½g1ðyÞj dg1ðyÞ
dy

:
(5:56)
In the present case, this means
fUðuÞ ¼ fX½F1ðuÞj dx
du

:
(5:57)
Since
u ¼ FðxjÞ ! du
dx ¼ dFðxjÞ
dx
¼ fXðxjÞ
! dx
du ¼ f fXðxjÞg1:
(5:58)
But x ¼ F1ðuÞ. Substituting for x in Equation (5.58), we obtain
dx
du ¼ f fX½F1ðuÞjg1:
(5:59)
Substituting Equation (5.59) into Equation (5.57) yields
fUðuÞ ¼ fX½F1ðuÞj
fX½F1ðuÞj
fUðuÞ ¼ 1;
0  u  1:
(5:60)
128
Frequentist statistical inference

The essence of the theorem is that in many instances, we are able to determine the
value of x corresponding to a value of u such that FðxjÞ ¼ u. For this reason,
practically all computer systems have a built-in capability of generating random
values for a uniform distribution on the unit interval.
Therefore, to generate random variables for any continuous distribution, we need
only generate a random number, u, from a uniform distribution and then solve
Z x
1
fXðxjÞdx ¼ u for x;
where fXðxjÞ is the PDF of distribution of interest.
The procedure is illustrated in Figure 5.12. Suppose we want to generate random
numbers with a PDF represented by panel (a). Construct the cumulative distribution
function, FðxÞ, as shown in panel (b). Generate a sequence of random numbers which
have a uniform distribution in the interval 0 to 1. Locate each of these on the y-axis of
panel (c) and draw a line parallel to the x-axis to intersect FðxÞ. Drop a perpendicular
to the horizontal axis and read off the x value. The distribution of random x values
1
2
3
4
5
x
0
0.2
0.4
0.6
0.8
1
CDF
(c)
2
3
4
5
x
0
10
20
30
40
50
60
Number
(d)
1
2
3
4
5
6
x
0.1
0.2
0.3
0.4
0.5
0.6
PDF
(a)
1
2
3
4
5
x
0
0.2
0.4
0.6
0.8
1
CDF
(b)
Figure 5.12 This figure illustrates the construction of random numbers which have a distribution
corresponding to that shown in panel (a). It makes use of the cumulative distribution function
(CDF) shown in panel (b), and a sequence of random numbers that have a uniform distribution in
the interval 0 to 1. The construction is illustrated in panel (c) for 20 random numbers. Panel
(d) shows a histogram of 500 random numbers generated by this process. See the text for details.
5.13 Random and pseudo-random numbers
129

derived in this way will have the desired probability distribution. Panel (c) illustrates
this construction for 20 random numbers. A histogram of 500 of these random x
values is shown in panel (d).
Examples:
1. Uniform distribution on the interval ða; bÞ:
fðxja; bÞ ¼
1
ðb  aÞ ; ða  x  bÞ:
First, generate a random value of u in the interval (0, 1), equate it to the cumulative
distribution function, integrate and solve:
ðb  aÞ1
Z x
a
dt ¼ u
x ¼ uðb  aÞ þ a; ða  x  bÞ:
2. Negative exponential distribution:
fðxjÞ ¼
expðx=Þ;
for x > 0;  > 0
0;
elsewhere.

(5:61)
1

Z x
0
exp  t



dt ¼ u
1


 
ðÞ exp  t



x
0¼ u
1  exp  x



¼ u
x ¼  ln
1
1  u


¼  lnð1  uÞ ¼  lnðuÞ:
(5:62)
3. Poisson distribution: recall the probability of exactly x occurrences in a time T is given by
pðxjTÞ ¼ ðrTÞx expðrTÞ
x!
;
x ¼ 0; 1; 2; . . .
where r ¼ average rate of occurrences and  ¼ rT is the average number of occurrences in
time T. Since the time difference between independent Poisson occurrences has a negative
exponential distribution, one can generate a random Poisson value by generating successive
negative exponential random values using t ¼  lnðuÞ. The process continues until the sum
130
Frequentist statistical inference

of x þ 1 values of t exceeds the prescribed length T. The Poisson random value, therefore,
is x. Recall  ¼ mean time between Poisson events ¼ 1=r.
5.13.1 Pseudo-random number generators
Considerable effort has been focused on finding methods for generating uniform
distributions of numbers in the range [0,1] (Knuth, 1981; Press et al., 1992). These
numbers can then be transformed into other ranges and other types of distributions
(e.g., Poisson, normal) as we have seen.
The procedure below illustrates one approach to pseudo-random number gener-
ation called Linear Congruent Generators (LCG) which generate a sequence of integers
I1; I2; I3; . . . each between 0 and ðm  1Þ=m, where m is a large number, by the
following operations:
Step 1: Ii þ 1 ¼ aIi þ c where a and c are integers. This generates an upward-going
sequence from a seed I0.
Step 2: Modulus½I; m ¼ I  IntegerPart½I=m 	 m
e.g., Modulus½5; 3 ¼ 5  Integer Part½5=3 	 3 ¼ 2
This reduces the above sequence to a random one with values in the range 0 to m  1
(actually a distribution of round-off errors).
Also written as Ii þ 1 ¼ aIi þ cðMod mÞ.
Step 3: U ¼ 1
m Modulus½I; m
This gives the desired sequence U between 0 and ðm  1Þ=m.
Notice the smallest difference between terms is 1=m, which means the numbers a LCG
produces comprise a set of m equally spaced rational fractions in the range
0  x  ðm  1Þ=m.
Problems:
1. The sequence repeats itself with some period which is  m.
2. For certain choices of parameters, some generators skip many of the possible numbers and
give an incomplete set. A series that generates all the m distinct integers ð0 < n < m  1Þ
during each period is called a full period.
3. Contains subtle serial correlations. See Numerical Recipes (Press et al., 1992) for more details.
Established rules for choosing parameters that give a long and full period are given
by Knuth (1981) and by Park and Miller (1988). One way to reduce all of the above
problems is to use a compound LCG or shuffling generator which works as follows:
1. Use two LCGs.
2. Use first LCG to generate N lists of random numbers.
3. Use second LCG to calculate a number l between 1 and N, then select top number from lth list
(return this number back to the bottom of that list).
4. Period of compound LCG  product of periods of individual LCGs.
5.13 Random and pseudo-random numbers
131

Box 5.6 Mathematica pseudo-random numbers:
We can use Mathematica to generate pseudo-random numbers with a wide range
of probability distributions. The following command will yield a list of 10 000
uniform random numbers in the interval 0 ! 1:
Table[Random[ ],{10000}]
Random uses the Wolfram rule 30 cellular automaton generator for integers
(Wolfram, 2002).
To obtain a table of pseudo-random numbers with a Gaussian distribution use the
following commands. The first line loads a package containing a wide range of
continuous distributions of interest for statistics.
Needs[‘‘Statistics ‘ContinuousDistributions’ ’’]
Table [Random[NormalDistribution[ m, s]], {10000}]
Mathematica uses the time of day as a seed for random number generation. To
ensure you always get the same sequence of pseudo-random numbers, you need to
provide a specific seed (e.g., 99) with the command:
SeedRandom[99]
5.13.2 Tests for randomness
Most computers have lurking in their library routines a random number generator
typically with the name RAN. X ¼ RAN(ISEED) is a typical calling sequence. ISEED
is some arbitrary initialization value. Any random number generator needs testing
before use as the example discussed below illustrates. Four common approaches to
testing are:
* Random walk.
* Compare the actual distribution of the pseudo-random numbers to a uniform distribution
using a statistical test. Two commonly used frequentist tests are the Kolmogorov–Smirnov
test and the 	2 goodness-of-fit test. The latter is discussed in Section 7.3.1.
* Examine the Fourier spectrum.
* Test for correlations between neighboring random numbers.
Examples of the latter two tests are given in this section.
Panel (a) of Figure 5.13 shows the power spectral density of 262 144 pseudo-random
numbers generated using Mathematica. The frequency axis is the number of cycles in
the 262 144 steps. There do not appear to be any significant peaks indicative of a
periodicity. Note: the uniformly distributed pseudo-random numbers in the interval
132
Frequentist statistical inference

0 ! 1 were transformed to be uniform in the interval 0:5 ! 0:5 by subtracting 0.5
from each, so there is no DC (zero frequency) component in the spectrum. Panel (b)
shows a histogram of the real part of the Fourier amplitudes which has a Gaussian
shape. From the Central Limit Theorem, we expect the histogram to be a Gaussian,
since each amplitude corresponds to a weighted sum (weighted by a sine wave) of a
very large number of random values.
Panels (c) and (d) demonstrate how sensitive the power spectral density (PSD) and
Fourier amplitude histogram are to a repeating sequence of random numbers. Panel
(c) shows the PSD for a sequence of 262 144 random numbers consisting of 5.24 cycles
of 50 000 random numbers generated with Mathematica. Again the frequency axis is
the number of cycles in the 262 144 steps. This time, one can clearly see peaks in the
PSD at multiples of 5.24, and the histogram has become much narrower. Note: when
the sequence is an exact multiple of the repeat period, the vast majority of Fourier
amplitudes are zero and the histogram takes on the appearance of a sharp spike or
delta function, sitting on a broad plateau. A program to carry out the above calcula-
tions can be found in the section of the Mathematica tutorial entitled, ‘‘Fourier test of
random numbers.’’
5
10
15
20
25
30
35
40
Frequency
0.2
0.4
0.6
0.8
1
1.2
1.4
PSD
(c)
 –0.5
0
0.5
1
Fourier amplitude (real)
 
 
0
1
2
3
4
PDF
(d)
5
10
15
20
25
30
35
40
Frequency
0.2
0.4
0.6
0.8
1
1.2
1.4
PSD
(a)
 –0.5
0
0.5
1
Fourier amplitude (real)
 
 
0
0.5
1
1.5
2
PDF
(b)
Figure 5.13 Panel (a) shows the power spectral density of 262 144 pseudo-random numbers
generated using Mathematica. The frequency axis is the number of cycles in the 262 144 steps.
Panel (b) shows a histogram of the real part of the Fourier amplitudes. For comparison, panels
(c) and (d) demonstrate how sensitive the PSD and Fourier amplitude histogram are to a
repeating sequence of random numbers (5.24 cycles of 50 000 random numbers).
5.13 Random and pseudo-random numbers
133

Since each pseudo-random number is derived from the previous value, it is important
to test whether successive values are independent or exhibit correlations. We can look
for evidence of correlations between adjacent random numbers by grouping them in
pairs and plotting the value of one against the other. Such a plot is shown in Figure 5.14,
for 3000 pairs of random numbers. If adjacent pairs were completely correlated, we
would expect the points to lie on a straight line. This is clearly not the case as the points
appear to be randomly scattered over the figure.
The right panel of Figure 5.14 shows a similar correlation test involving neighboring
points, taken three at a time, and plotted in three dimensions. If the sequence of
numbers is perfectly random, then we expect the points to have an approximately
uniform distribution, as they appear to do.
It is possible to extend and quantify these correlation tests. The most common
frequentist tool for quantifying correlation is called the autocorrelation function
(ACF). Here is how it works for our problem: let fxig be a list of uniformly distributed
pseudo-random numbers in the interval 0 to 1. Now subtract the mean value of the list,
x, to obtain a new list in the interval 0:5 to 0.5. Make a copy of the list fxi  xg and
place it below the first list. Then shift the copy to the left by j terms so the ith term in the
original list is above the ði þ jÞth term in the copy. This shift is referred to as a lag.
Next, multiply each term in the original list by the term in the shifted list immediately
below, and compute the average of these products (for all terms that overlap in the two
lists), which we designate 
ð jÞ. We can repeat this process and compute 
ðjÞ for a wide
range of lags, ranging from j ¼ 0 to some large value. If the numbers in the list are truly
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
0.25
0.5
0.75
1
0
0.25
0.5
0.75
1
0
0.25
0.5
0.75
1
Figure 5.14 The left panel shows a correlation test between successive pairs of random numbers,
obtained from the Mathematica pseudo-random number generator. The coordinates of each
point are given by the pair of random numbers. The right panel shows a three-dimensional
correlation test involving successive random numbers taken three at a time. The right panel was
plotted with the Mathematica command ScatterPlot3D.
134
Frequentist statistical inference

random then any term in the original list will be completely independent of any term in
the shifted copy. So each multiplication is equally likely to be a positive or negative
quantity. The average of a large number of random positive and negative quantities
tends to zero. Of course for j ¼ 0 (no shift), the two terms are identical so the products
are all positive quantities and there is no cancellation. Thus, for a list of completely
random numbers, a plot of the ACF, 
ð jÞ, will look like a spike at j ¼ 0 and be close to
zero for all j  1. If the terms are not completely independent, then we expect the plot
of 
ð jÞ to decay gradually towards zero over a range of j values.
The formula for 
ð jÞ given below differs slightly from the operation just described,
in that instead of computing the average, we sum the product terms for each j and then
normalize by dividing by
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X
overlap
ðxi  xÞ2
s
	
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X
overlap
ðxi þ j  xÞ2
s
:
With this normalization, the maximum value of the ACF is 1.0 and it allows the ACF
to handle a wider variety of correlation problems than the particular one we are
interested in here:

ð jÞ ¼
P
overlap½ðxi  xÞðxi þ j  xÞ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
overlapðxi  xÞ2
q
	
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
overlapðxi þ j  xÞ2
q
;
(5:63)
where the summation is carried out over the subset of samples that overlap.
Figure 5.15 shows a plot of the ACF for a sequence of 10 000 uniformly distributed
0
200
400
600
800
1000
Lag
0
0.2
0.4
0.6
0.8
1
ACF
2
4
6
8
10
Lag
0
0.05
0.1
0.15
 
0.2
ACF
Figure 5.15 The autocorrelation function (ACF) for a sequence of 10 000 uniformly distributed
pseudo-random numbers generated by the Mathematica Random command. The larger plot
spans a range of 1000 lags, while the blow-up in the corner shows the first ten lags. Clearly, for
lags  1, the ACF is essentially zero indicating no detectable correlation.
5.13 Random and pseudo-random numbers
135

pseudo-random numbers generated by the Mathematica Random command. The
larger plot spans a range of 1000 lags, while the blow-up in the corner shows the
first ten lags. Clearly, for lags  1, the ACF is essentially zero indicating no detectable
correlation. The noise-like fluctuations for j  1 arise because of incomplete cancella-
tion of the product terms for a finite list of random numbers.
For quite a few years, RAN3 in Numerical Recipes (not an LCG but based on a
subtractive method) was considered a reliable portable random number generator, but
even this has been called into question (see Barber et al., 1985; Vattulainen et al., 1994;
Maddox, 1994; and Fernandez and Rivero, 1996). However, what is random enough
for one application may not be random enough for another. In the near future,
random number generators based upon a physical process, like Johnson noise from
a resistor or a reverse-biased zener diode, will be incorporated into every computer.
Intel already supplies such devices on some chipsets for PC-type computers. One can
anticipate that users of these hardware-derived random numbers will again be con-
cerned with just how random these numbers are.
5.14 Summary
The most important aspect of frequentist statistics is the process of drawing conclu-
sions based on sample data drawn from the population (which is the collection of all
possible samples). The use of the term random variable conveys the idea of an intrinsic
uncertainty in the measurement characterized by an underlying population. A random
variable is not the particular number recorded in one measurement, but rather, it is an
abstraction of the measurement operation or observation that gives rise to that
number, e.g., X may represent the random variable and x the realization of the
random variable in one measurement.
To the frequentist, the sampling distribution is a model of the probability distribu-
tion of the underlying population from which the sample was taken. In a Bayesian
analysis, the sampling distribution is a mathematical description of the uncertainty in
predicting the data for any particular model because of incomplete information. It
enables us to compute the likelihood pðDjH; IÞ.
We considered various descriptive properties of probability distributions: moments,
moment generating functions (useful in proofs of important theorems) and measures
of the central tendency of a distribution (mode, median and mean). This was followed
by a discussion of some important discrete and continuous probability distributions.
The most important probability distribution is the Gaussian or normal distribution.
This is because a measured quantity is often the result of a large number of effects, i.e.,
is some kind of average of these effects. According to the Central Limit Theorem, the
distribution of the average of a collection of random variables tends to a Gaussian.
We also learned that in most circumstances, the distribution of the sample average
sharpens around the sample mean as the sample size increases, which is the basis of
signal averaging that plays such an important role in experimental work.
136
Frequentist statistical inference

Finally, we learned how to generate pseudo-random samples from an arbitrary
probability distribution, a topic that is of great importance in experimental simula-
tions and Monte Carlo techniques.
5.15 Problems
1. Write a small program to reproduce Figure 5.5 starting from the raw data ‘‘badbase.dat’’
(supplied with the Mathematica tutorial) and using 21 points for the running median
and mean. For the first and last ten points of the data, just subtract the average of the ten
from each point.
2. When sampling from a normal distribution with mean  ¼ 2 and  ¼ 1, compute
Pð  2:7  X   þ 2:7Þ.
3. As one test of your pseudo-random number generator, generate a sample of 50 000
random numbers in the interval 0 to 1 with a uniform distribution. Compare the
mean and variance of the sequence to that expected for a uniform distribution. Does
the sample mean agree with the expected mean to within one standard error of the
sample mean?
4. Generate 10 000 pseudo-random numbers with a beta distribution with  ¼ 2 and
 ¼ 4. See the Mathematica example in Section 5.13.1 of the book and use
BetaDistribution instead of NormalDistribution. Plot a histogram of your random
numbers, and on the same plot, overlay a beta distribution for comparison.
Compute the mean and median of your simulated data set. See the BinCounts,
Mean, and Median commands in Mathematica.
5. Let X1; X2; X3; . . . ; Xn be n independent and identically distributed (IID) random
variables with a beta PDF given by
fðxÞ  fðxj; Þ ¼
ð þ Þ
ðÞðÞ x1ð1  xÞ1;
for 0 < x < 1
;  > 0;
0;
elsewhere,
8
>
<
>
:
(5:64)
where  ¼ 2 and  ¼ 4.
What is the probability density function (PDF) of X, the average of n measurements?
As an alternative to averaging large numbers of samples (simplest approach) you
could make use of the convolution theorem and the Fast Fourier Transform (FFT)
(remember to zero pad). Note: if you are not familiar with using the FFT and zero
padding, you will find this approach much more challenging. Note: the Discrete
Fourier Transform, the FFT and zero padding are discussed in Appendix B.
a) By way of an answer, plot the PDFs for n ¼ 1; 3; 5; 8 and display all four
distributions on the same plot. Be careful to normalize each distribution for
unit area.
5.15 Problems
137

b) Compute the mean and variance of the four PDFs (do not simply quote an
expected theoretical value) for each value of n.
c) Compare your result for the n ¼ 5 case to a Gaussian with the same mean and
variance drawn on the same graph. Repeat for n ¼ 8. What conclusions do
you draw?
138
Frequentist statistical inference

6
What is a statistic?
6.1 Introduction
In this chapter, we address the question ‘‘What is a statistic’’? In particular, we look at
what role statistics play in scientific inference and give some common useful examples.
We will examine their role in the two basic inference problems: hypothesis testing (the
frequentist equivalent of model selection) and parameter estimation, with emphasis on
the latter. Hypothesis testing will be dealt with in Chapter 7.
Recall that an important aspect of frequentist statistical inference is the process of
drawing conclusions based on sample data drawn from the population (which is the
collection of all possible samples). The concept of the population assumes that in
principle, an infinite number of measurements (under identical conditions) are pos-
sible. Suppose X1; X2; . . . ; Xn are n independent and identically distributed (IID)
random variables that constitute a random sample from the population for which
x1; x2; . . . ; xn is one realization. The population is assumed to have an intrinsic
probability distribution (or density function) which, if known, would allow us to
predict the likelihood of the sample x1; x2; . . . ; xn.
For example, suppose the random variable we are measuring is the time interval
between successive decays of a radioactive sample. In this case, the population
probability density function is a negative exponential (see Section 5.8.5), given by
fðxjÞ ¼ ½expðx=Þ/. The likelihood is given by
Lðx1; x2; . . . ; xnjÞ ¼
Y
n
i ¼ 1
fðxijÞ:
(6:1)
This particular population probability density function is characterized by a single
parameter . Another population probability distribution that arises in many prob-
lems is the normal (Gaussian) distribution which has two parameters,  and 2.
In most problems, the parameters of the underlying population probability distribution
are not known. Without knowledge of their values, it is impossible to compute the desired
probabilities. However, a population parameter can be estimated from a statistic, which is
determined from the information contained in a random sample. It is for this reason that
the notion of a statistic and its sampling distribution is so important in statistical inference.
139

Definition: A statistic is any function of the observed random variables in a sample
such that the function does not contain any unknown quantities.
One important statistic is the sample mean X given by
X ¼ ðX1 þ X2 þ    þ XnÞ=n ¼ 1
n
X
n
i ¼ 1
Xi:
(6:2)
Note: we are using a capital X which implies we are talking about a random variable.
All statistics are random variables and to be useful, we need to be able to specify their
sampling distribution.
For example, we might be interested in the mean redshift1 of a population of cosmic
gamma-ray burst (GRB) sources. This would provide information about the distances
of these objects and their mean energy. GRBs are the most powerful type of explosion
known in the universe. The parameter of interest is the mean redshift which we
designate . A parameter of a population is always regarded as a fixed and usually
unknown constant. Let Z be a random variable representing GRB redshifts. Suppose
the redshifts, fz1; z2; . . . ; z7g, of a sample of seven GRB sources are obtained after a
great deal of effort. What can we conclude about the population mean redshift  from
our sample, i.e., how accurately can we determine  from our sample?
This can be a fairly difficult question to answer using the individual measurements,
zi, because we don’t know the form of the sampling distribution for GRB source
redshifts. Happily, in this case, we can proceed with our objective by exploiting the
Central Limit Theorem (CLT) which predicts the sampling distribution of the sample
mean statistic. The way to think about this is as follows: consider a thought experiment
in which we are able to obtain redshifts for a very large number of samples (hypothet-
ical reference set) of GRB redshifts. Each sample consists of seven redshift measure-
ments. The means of all these samples will have a distribution. According to the CLT,
the distribution of sample means tends to a Gaussian as the number n of observations
tends to infinity. In practice, a Gaussian sampling distribution is often employed when
n  5. Of course, we don’t have the results from this hypothetical reference set, only
the results from our one sample, but at least we know that the shape of the sampling
distribution characterizing our sample mean statistic is approximately a Gaussian.
This allows us to make a definite statement about the uncertainty in the population
mean redshift  which we derive from our one sample of seven redshift measurements.
Just how we do this is discussed in detail in Section 6.6.2. In the course of answering
that question, we will encounter the sample variance statistic, S2, and develop the
notion of a sampling distribution of a statistic.
1 Redshift is a measure of the wavelength shift produced by the Doppler effect. In 1929, Edwin Hubble showed that we
live in an expanding universe in which the velocity of recession of a galaxy is proportional to its distance. A recession
velocity shifts the observed wavelength of a spectral line to longer wavelengths, i.e., to the red end of the optical
spectrum.
140
What is a statistic?

6.2 The 2 distribution
The sampling distribution of any particular statistic is the probability distribution of
that statistic that would be determined from an infinite number of independent
samples, each of size n, from an underlying population. We start with a treatment
of the 2 sampling distribution.2 We will prove in Section 6.3 that the 2 distribution
describes the distribution of the variances of samples taken from a normal distribu-
tion. The 2 distribution is a special case of the gamma distribution:
fðxj; Þ ¼
1
ðÞ x1 exp x



(6:3)
with  ¼ 2 and  ¼ =2, where  is called the degree of freedom.
The 2 distribution has the following properties:
fðxjÞ ¼
1
 
2
 
2

2 x

21 exp  x
2


(6:4)
hxi ¼ ;
Var½x ¼ 2:
(6:5)
The coefficients of skewness (3) and kurtosis (4) are given by
3 ¼
4ﬃﬃﬃﬃﬃ
2
p
;
4 ¼ 3 1 þ 4



:
(6:6)
Finally, the moment generating function of 2
 with  degrees of freedom is given by
m2ðtÞ ¼ ð1  2tÞ
2:
(6:7)
We now prove two useful theorems pertaining to the 2 distribution.
Theorem 1:
Let fXig ¼ X1; X2; . . . ; Xn be an IID sample from a normal distribution Nð; Þ.
Let Y ¼ Pn
i ¼ 1ðXi  Þ2=2 ¼ Pn
i ¼ 1 Z2
i , where Zi are standard random variables.
Then Y has a chi-squared 2
n


distribution with n degrees of freedom.
Proof:
Let mYðtÞ ¼ the moment generating function (recall Section 5.6) of Y. From Equation
(5.9), we can write
mYðtÞ ¼ hetYi ¼ hetiZ2
i i
¼ hetZ2
1  etZ2
2      etZ2
ni:
(6:8)
2 The 2 statistic plays an important role in fitting models to data using the least-squares method, which is discussed in
great detail in Chapters 10 and 11.
6.2 The 2 distribution
141

Since the random variable Z is IID then,
mYðtÞ ¼ hetZ2
1i  hetZ2
2i      hetZ2
ni
¼ mZ2
1ðtÞ  mZ2
2ðtÞ      mZ2nðtÞ:
(6:9)
The moment generating function for each Zi is given by
mZ2ðtÞ ¼
Z þ1
1
fðzÞ expðtZ2ÞdZ
¼
1ﬃﬃﬃﬃﬃﬃ
2p
p
Z
expðtZ2Þ exp Z2
2


dZ
¼
1ﬃﬃﬃﬃﬃﬃ
2p
p
Z
exp Z2
2
ð1  2tÞ

	
dZ;
(6:10)
where we have made use of the fact that fðzÞ is also a normal distribution, i.e., a
Gaussian.
Multiplying and dividing Equation (6.10) by ð1  2tÞ1
2 we get
mZ2ðtÞ ¼ ð1  2tÞ1
2
Z þ1
1
1
ﬃﬃﬃﬃﬃﬃ
2p
p
ð1  2tÞ1
2 exp
Z2
2ð1  2tÞ1
"
#
dZ
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
Integral of normal distribution ¼ 1
) mZ2ðtÞ ¼ ð1  2tÞ1
2:
(6:11)
Therefore,
mYðtÞ ¼ ð1  2tÞn
2:
(6:12)
Comparison of Equations (6.12) and (6.7) shows that Y has a 2 distribution, with n
degrees of freedom, which we designate by 2
n. Figure 6.1 illustrates the 2 distribution
for three different choices of the number of degrees of freedom.
Example:
In Section 5.9, we showed that for any IID sampling distribution with a finite variance,
ðX  Þ
ﬃﬃﬃn
p = tends to Nð0; 1Þ as n ! 1, and therefore ½ðX  Þ
ﬃﬃﬃn
p =2 is approxi-
mately 2
1 with one degree of freedom.3
3 When sampling from a normal distribution, the distribution of ðX  Þ
ﬃﬃﬃn
p = is always N(0, 1) regardless of the value
of n.
142
What is a statistic?

Theorem 2:
If X1 and X2 are two independent 2-distributed random variables with 1 and 2
degrees of freedom, then Y ¼ X1 þ X2 is also 2-distributed with 1 þ 2 degrees of
freedom.
Proof:
Since X1 and X2 are independent, the moment generating function of Y is given by
myðtÞ ¼ mX1ðtÞ  mX2ðtÞ ¼ ð1  2tÞ
1
2  ð1  2tÞ
2
2
(6:13)
¼ ð1  2tÞ
ð1þ2Þ
2
;
(6:14)
which equals the moment generating function of a 2 random variable with 1 þ 2
degrees of freedom.
6.3 Sample variance S2
We often want to estimate the variance ð2Þ of a population from an IID sample taken
from a normal distribution. We usually don’t know the mean ðÞ of the population so
we use the sample mean ðXÞ as an estimate. To estimate 2 we use another random
variable called the sample variance ðS2Þ, defined as follows:
S2 ¼
X
n
i ¼ 1
ðXi  XÞ2
n  1
:
(6:15)
2.5
5
7.5
10
12.5
15
17.5
20
 
χ2 value
0.05
0.1
0.15
0.2
0.25
Probability density
  ν = 8
  ν = 3
  ν = 1
Figure 6.1 The 2 distribution for three different choices of the number of degrees of freedom.
6.3 Sample variance S2
143

Just why we define the sample variance random variable in this way will soon be made
clear. Of course, for any particular sample of n data values, the sample random
variable would take on a particular value designated by lower case s2.
Here is a useful theorem that enables us to estimate  from S:
Theorem 3:
The sampling distribution of ðn  1ÞS2=2 is 2 with ðn  1Þ degrees of freedom.
Proof:
ðn  1ÞS2 ¼
X
n
i ¼ 1
ðXi  XÞ2 ¼
X
½ðXi  Þ  ðX  Þ2
¼
X
½ðXi  Þ2  2ðXi  ÞðX  Þ þ ðX  Þ2
¼
X
ðXi  Þ2  2ðX  Þ
X
ðXi  Þ þ
X
ðX  Þ2
¼
X
ðXi  Þ2  2ðX  ÞnðX  Þ þ nðX  Þ2
¼
X
½ðXi  Þ2  nðX  Þ2:
(6:16)
Therefore,
ðn  1ÞS2
2
þ ðX  Þ2
2=n
|ﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄ}
2
1
¼
X
n
i ¼ 1
ðXi  Þ2
2
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
2
n
:
(6:17)
From Theorem 2, ðn  1ÞS2=2 is 2
n1 with ðn  1Þ degrees of freedom.
The expectation value of a quantity that has a 2 distribution with ðn  1Þ degrees
of freedom is equal to the number of degrees of freedom (see Equation (6.5)).
Therefore,
ðn  1ÞS2
2


¼ n  1:
(6:18)
But,
ðn  1ÞS2
2


¼ hS2i ðn  1Þ
2
¼ n  1:
(6:19)
Therefore,
hS2i ¼ 2:
(6:20)
This provides justification for our definition of S2 – its expectation value is the
population variance. Note: this does not mean that S2 will equal 2 for any particular
sample.
144
What is a statistic?

Note 1: We have just established Equation (6.20) when sampling for a normal
distribution. We now show that Equation (6.20) is valid for IID sampling from any
arbitrary distribution with finite variance. From Equation (6.16), we can write
hS2i ¼
PhðXi  Þ2i  nhðX  Þ2i
n  1
:
(6:21)
But hðXi  Þ2i ¼ VarðXiÞ ¼ 2 by definition, and hðX  Þ2i ¼ VarðXÞ ¼ 2=n from
Equation (5.50). It follows that
hS2i ¼ n2  2
n  1
¼ 2:
(6:22)
Thus, Equation (6.22) is valid for IID sampling from an arbitrary distribution with
finite variance. In the language of frequentist statistics, we say that S2, as defined in
Equation (6.15), is an unbiased estimator of 2.
Standard error of the sample mean: We often want to quote a typical error for the mean
of a population based on our sample. According to Equation (5.50), VarðXÞ ¼ 2=n
for any distribution with finite variance. Since we do not normally know 2, the
variance of the population, we use the sample variance as an estimate.
The standard error of the sample mean is defined as
Sﬃﬃﬃn
p :
(6:23)
In Section 6.6.2 we will use a Student’s t distribution to be more precise about
specifying the uncertainty in our estimate of the population mean from the sample
mean.
Note 2:
In a situation where we know population  but not 2, define S2:
S2 ¼
X
n
i ¼ 1
ðXi  Þ2
n
:
(6:24)
It is easily shown that with this definition, nS2=2 is 2
n with n degrees of freedom. We
lose one degree of freedom when we estimate  from X.
Example:
A random sample of size n ¼ 16 (IID sample) is drawn from a population with a
normal distribution of unknown mean () and variance (2). We compute the sample
variance, S2, and want to determine
pð2 < 0:49S2Þ:
(6:25)
Solution: Equation (6.25) is equivalent to
p S2
2 > 2:041


:
(6:26)
6.3 Sample variance S2
145

We know that the random variable X ¼ ðn  1ÞS2=2 has a 2 distribution with ðn  1Þ
degrees of freedom. In this case, ðn  1Þ ¼ 15 ¼  degrees of freedom. Therefore,
p S2
2 > 2:041


¼ p ðn  1Þ S2
2 > 30:61


:
(6:27)
Let
 ¼ pððn  1ÞS2=2 > 30:61Þ:
Then
1   ¼ pððn  1ÞS2=2  30:61Þ;
or more generally, 1   ¼ pðX  x1Þ where x1 is the particular value of the
random variable X for which the cumulative distribution pðX  x1Þ ¼ 1  . x1
is called the ð1  Þ quantile value of the distribution, and pðX  x1jÞ is given by
pðX  x1jÞ ¼
1
 
2
 
2

2
Z x1
0
t

21 exp  t
2


dt ¼ 1  :
(6:28)
For  ¼ 15 degrees of freedom, 30.61 corresponds to  ¼ 0:01 or x0:990. Thus, the
probability that the random variable 2 < 0:49S2 ¼ 1%. Figure 6.2 shows the 2
distribution for  ¼ 15 degrees of freedom and the 1   ¼ 0:99 quantile value.
0
10
20
30
40
0
0.02
0.04
0.06
Probability density
χ2
0.99
χ2 value
Figure 6.2 The 2 distribution for  ¼ 15 degrees of freedom. The vertical line marks the
1   ¼ 0:99 quantile value. The area to the left of this line corresponds to 1  .
146
What is a statistic?

We can evaluate Equation (6.28) with the following Mathematica command:
Box 6.1
Mathematica 2 significance
Needs [‘‘Statistics ‘ContinuousDistributions’’’]
The line above loads a package containing a wide range of continuous distribu-
tions of importance to statistics, and the following line computes , the area in the
tail of the 2 distribution to the right of 2 ¼ 30:61, for  ¼ 15 degrees of freedom.
GammaRegularized n
2 , c2
2

	
¼ GammaRegularized 15
2 , 30:61
2

	
¼ 0:01
In statistical hypothesis testing (to be discussed in the next chapter),  is referred to
as the significance or the one-sided P-value of a statistical test.
6.4 The Student’s t distribution
Recall, when sampling from a normal distribution with known standard deviation, ,
the distribution of the standard random variable Z ¼ ðX  Þ
ﬃﬃﬃn
p = is Nð0; 1Þ. In
practice,  is usually not known. The logical thing to do is to replace  by the sample
standard deviation S. The usual inference desired is that there is a specified probability
that X lies within S of the true mean .
Unfortunately, the distribution of ðX  Þ
ﬃﬃﬃn
p =S is not Nð0; 1Þ. However, it is
possible to determine the exact sampling distribution of ðX  Þ
ﬃﬃﬃn
p =S when sampling
from Nð; Þ with both  and 2 unknown. To this end, we examine the Student’s
t distribution.4 The following useful theorem pertaining to the Student’s t distribution
is given without proof.
Theorem 4:
Let Z be a standard normal random variable and let X be a 2 random variable with 
degrees of freedom. If Z and X are independent, then the random variable
T ¼
Zﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X=
p
(6:29)
has a Student’s t distribution with  degrees of freedom and a probability density given
by
fðtjÞ ¼ ½ðþ1Þ
2 
ﬃﬃﬃﬃﬃﬃ
p
p
ð
2Þ 1 þ
t2

 

	ðþ1Þ
2
; ð1 < t < þ1Þ;  > 0:
(6:30)
4 The t distribution is named for its discoverer, William Gosset, who wrote a number of statistical papers under the
pseudonym ‘‘Student.’’ He worked as a brewer for the Guinness brewery in Dublin in 1899. He developed the t
distribution in the course of analyzing the variability of various materials used in the brewing process.
6.4 The Student’s t distribution
147

The Student’s t distribution has the following properties:
hT i ¼ 0
and
VarðT Þ ¼

ð  2Þ
 > 2:
(6:31)
When sampling Nð; Þ we know that ðX  Þ
ﬃﬃﬃn
p = is Nð0; 1Þ. We also know that
ðn  1ÞS2=2 is 2 with ðn  1Þ degrees of freedom. Therefore, we can identify Z with
ðX  Þ
ﬃﬃﬃn
p = and X with ðn  1ÞS2=2. Therefore,
T ¼
ðXÞ
ð= ﬃﬃn
p Þ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ðn1ÞS2=2
n1
q
¼ ðX  Þ
ð=
ﬃﬃﬃn
p Þ

S ¼ ðX  Þ
ðS=
ﬃﬃﬃn
p Þ :
(6:32)
Therefore, ðX  Þ
ﬃﬃﬃn
p =S is a random variable with a Student’s t distribution with
n  1 degrees of freedom. Figure 6.3 shows a comparison of a Student’s t distribution
for three degrees of freedom, and a standard normal. The broader wings of the
Student’s t distribution are clearly evident.
The ð1  Þ quantile value for  degrees of freedom, t1;, is given by
pðT  t1;Þ ¼ ½ðþ1Þ
2 
ﬃﬃﬃﬃﬃﬃ
p
p
ð
2Þ
Z t1;
1
1 þ
t2

 

	ðþ1Þ
2
dt ¼ 1  :
(6:33)
Example:
Suppose a cigarette manufacturer claims that one of their brands has an average
nicotine content of 0.6 mg per cigarette. An independent testing organization
 –4
 –2
0
2
4
Student’s t value
0
0.1
0.2
0.3
0.4
Probability density
Normal
Student’s t
Figure 6.3 Comparison of a standard normal distribution and a Student’s t distribution for
3 degrees of freedom.
148
What is a statistic?

measures the nicotine content of 16 such cigarettes and has determined the sample
average and the sample standard deviation to be 0.75 and 0.197 mg, respectively. If we
assume the amount of nicotine is a normal random variable, how likely is the sample
result given the manufacturer’s claim?
T ¼ ðX  Þ
ﬃﬃﬃn
p =S has a Student’s t distribution.
x ¼ 0:75 mg; s ¼ 0:197 mg, and n ¼ 16;
so the number of degrees of freedom  ¼ 15.
Manufacturer claims  ¼ 0:6 mg corresponds to a
t ¼ ð0:75  0:6Þ
0:197=
ﬃﬃﬃﬃﬃ
16
p
¼ 3:045:
(6:34)
The Student’s t distribution is a continuous distribution, and thus we cannot calculate
the probability of any specific t value since there is no area under a point. The question
of how likely the t value is, given the manufacturer’s claim, is usually interpreted as
what is the probability by chance that T  3:045. The area of the distribution beyond
the sample t value gives us a measure of how far out in the tail of the distribution the
sample value resides.
Box 6.2
Mathematica solution:
We can solve the above problem with the following commands:
Needs[‘‘Statistics ‘ContinuousDistributions’’’]
The following line computes the area in the tail of the
T distribution beyond T ¼ 3:045.
(1 – CDF[StudentTDistribution[n], 3.045]) ! answer ¼ 0:004 ð ¼ 15Þ
where CDF[StudentTDistribution [n], 3.045] stands for the cumulative density
function of the T distribution from T ¼ 1 ! 3:045.
Therefore, pðT>3:045Þ ¼  ¼ 0:004 or 0.4%, i.e., the manufacturer’s claim is very
improbable. The way to think of this is to imagine we could repeatedly obtain samples
of 16 cigarettes and compute the value of t for each sample. The fraction of these t
values that we would expect to fall in the tail area beyond t > 3:045 is only 0.4%. If the
manufacturer’s claim were reasonable, we would expect that the t value of our actual
sample would not fall so far out in the tail of the distribution. If you are still puzzled by
this reasoning, we will have a lot more to say about it in Chapter 7. We will revisit this
example in Section 7.2.3.
Note: although ðx  Þ=s ¼ 0:15=0:197 < 1, s is not a meaningful uncertainty for x –
only for xi. The usual measure of the uncertainty in x is s=
ﬃﬃﬃn
p ¼ 0:049. The quantity
s=
ﬃﬃﬃn
p is called the standard error of the sample mean.
6.4 The Student’s t distribution
149

6.5 F distribution (F-test)
The F distribution is used to find out if two data sets have significantly different
variances. For example, we might be interested in the effect of a new catalyst in the
brewing of beer so we compare some measurable property of a sample brewed with the
catalyst to a sample from the control batch made without the catalyst. What effect has
the catalyst had on the variance of this property?
Here, we develop the appropriate random variable for use in making inferences
about the variances of two independent normal distributions based on a random
sample from each. Recall that inferences about 2, when sampling from a normal
distribution, are based on the random variable ðn  1ÞS2=2, which has a 2
n1
distribution.
Theorem 5:
Let X and Y be two independent 2 random variables with 1 and 2 degrees of
freedom. Then the random variable
F ¼ X=1
Y=2
(6:35)
has an F distribution with a probability density function
pð f j1; 2Þ ¼
½ð1þ2Þ=2
ð1=2Þð2=2Þ
1
2
 1
2
f
1
2ð12Þ
ð1þf1=2Þ
1
2ð1þ2Þ ;
ð f > 0Þ
0;
elsewhere.
8
<
:
(6:36)
An F distribution has the following properties:
hFi ¼
2
2  2 ; ð2 > 2Þ:
(6:37)
(Surprisingly, hFi depends only on 2 and not on 1.)
VarðFÞ ¼ 2
2ð22 þ 21  4Þ
1ð2  1Þ2ð2  4Þ
; ð2 > 4Þ
(6:38)
Mode ¼ 2ð1  2Þ
1ð2 þ 2Þ :
(6:39)
Let X ¼ ðn1  1ÞS2
1=2
1 and Y ¼ ðn2  1ÞS2
2=2
2. Then,
F12 ¼ X=1
Y=2
¼ X=ðn1  1Þ
Y=ðn2  1Þ ¼ S2
1=2
1
S2
2=2
2
:
(6:40)
150
What is a statistic?

Box 6.3
Mathematica example:
The sample variance is s2
1 ¼ 16:65 for n1 ¼ 6 IID samples from a normal distribu-
tion with a population variance 2
1, and s2
2 ¼ 5:0 for n2 ¼ 11 IID samples from a
second independent normal distribution with a population variance 2
2. If we
assume that 2
1 ¼ 2
2, then from Equation (6.40), we obtain f ¼ 3:33 for
1 ¼ n1  1 ¼ 5 and 2 ¼ n2  1 ¼ 10 degrees of freedom. What is the probability
of getting an f value  3:33 by chance if 2
1 ¼ 2
2?
Needs[‘‘Statistics ‘ContinuousDistributions’’’]
The following line computes the area in the tail of the F distribution beyond f ¼ 3:33.
ð1  CDF[FRatioDistribution[n1, n2], 3:33]Þ ! answer ¼ 0:05
where CDF[FRatioDistribution[n1, n2], 3:33] stands for the cumulative density
function of the F distribution from f ¼ 0 ! 3:33. Another way to compute this
tail area is with
FRatioPValue[fratio, n1, n2]
The F distribution for this example is shown in Figure 6.4.
What if we had labeled our two measurements of s the other way around so
1 ¼ 10; 2 ¼ 5 and s2
1=s2
2 ¼ 1=3:33? The equivalent question is: what is the probability
that f  1=3:33 which we can evaluate by
CDF[FRatioDistribution [n1, n2], 1=3:33]? Answer : 0:05
Not surprisingly, we obtain the same probability.
0
1
2
3
4
5
f value
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Probability density
f0.95,5,10
predicted distribution
measured
Figure 6.4 The F distribution for 1 ¼ 5; 2 ¼ 10 degrees of freedom. The measured value of
3.33, indicated by the line, corresponds to f0:95;5;10, the 0.95 quantile value.
6.5 F distribution (F-test)
151

6.6 Confidence intervals
In this section, we consider how to specify the uncertainty of our estimate of any
particular parameter of the population, based on the results of our sample. We start by
considering the uncertainty in the population mean  when it is known that we are
sampling from a population with a normal distribution. There are two cases of
interest. In the first, we will assume that we know the variance 2 of the underlying
population we are sampling from. More commonly, we don’t know the variance and
must estimate it from the sample. This is the second case.
6.6.1 Variance  2 known
Let fXig be an IID Nð; 2Þ random sample of n ¼ 10 measurements from a popula-
tion with unknown  but known  ¼ 1. Let X be the sample mean random variable
which will have a sample mean standard deviation, m ¼ =
ﬃﬃﬃn
p ¼ 1=
ﬃﬃﬃﬃﬃ
10
p
¼ 0:32, to two
decimal places. The probability that X will be within one m ¼ 0:32 of  is approxi-
mately 0.68 (from Section 5.8.1). We can write this as
pð  0:32 < X <  þ 0:32Þ ¼ 0:68:
(6:41)
Since we are interested in making inferences about  from our sample, we rearrange
Equation (6.41) as follows:
pð  0:32 < X <  þ 0:32Þ ¼ pð0:32 < X   < 0:32Þ
¼ pð0:32 >   X > 0:32Þ
¼ pðX þ 0:32 >  > X  0:32Þ ¼ 0:68;
or,
pðX  0:32 <  < X þ 0:32Þ ¼ 0:68:
(6:42)
Suppose the measured sample mean is x ¼ 5:40. Can we simply substitute this value
into Equation (6.42), which would yield
pð5:08 <  < 5:72Þ ¼ 0:68?
(6:43)
We need to be careful how we interpret Equations (6.42) and (6.43).
Equation (6.42) says that if we repeatedly draw samples of the same size from this
population, and each time compute specific values for the random interval
ðX  0:32; X þ 0:32Þ, then we would expect 68% of them to contain the unknown
mean . In frequentist theory, a probability represents the percentage of time that
something will happen. It says nothing directly about the probability that any one
realization of a random interval will contain . The specific interval (5.08, 5.72) is but
one realization of the random interval ðX  0:32; X þ 0:32Þ based on the data of a
152
What is a statistic?

single sample. Since the probability of 0.68 is with reference to the random interval
ðX  0:32; X þ 0:32Þ, it would be incorrect to say that the probability of  being
contained in the interval (5.08, 5.72) is 0.68.
However, the 0.68 probability of the random interval does suggest that our con-
fidence in the interval (5.08, 5.72) for containing the unknown mean  is high and we
refer to it as a confidence interval. It is only in this sense that we are willing to assign a
degree of confidence in the statement 5:02 <  < 5:72.
Meaning of a confidence interval: When we write pð5:08 <  < 5:72Þ, we are not
making a probability statement in a classical sense but rather are expressing a
degree of confidence. In general, we write pð5:08 <  < 5:72Þ ¼ 1   where 1  
is called the confidence coefficient. It is important to remember that the ‘‘68%
confidence’’ refers to the probability of the test, not to the parameter.
If you listen closely to the results of a political poll, you will hear something like the
following: ‘‘In a recent poll, 55% of a sample of 800 voters indicated they would vote
for the Liberals. These results are reliable within 3:5%, 19 times out of 20.’’ What this
means is that if you repeated the poll using the same methodology, then 95% (19 out of
20) of the time you would get the same result within 3.5%. In this case, the 95%
confidence interval is 51.5 to 58.5%. A Bayesian analysis of the same polling data was
given in Section 4.2.3.
Figure 6.5 shows 68% confidence intervals for the means of 20 samples of a random
normal distribution with a  ¼ 5:0 and  ¼ 1:0. Each sample consists of ten measure-
ments. Notice that 13 out of 20 intervals contain the true mean of 5. The number
expected for 68% confidence intervals is 13.6.
4.25
4.5
4.75
5
5.25
5.5
5.75
Confidence intervals
Figure 6.5 68% confidence intervals for the means of 20 samples of a random normal distribu-
tion with a  ¼ 5:0 and  ¼ 1:0. Each sample consists of ten measurements.
6.6 Confidence intervals
153

A general procedure for finding confidence intervals:
If we wish to find a general procedure for finding confidence intervals, we must first
return to Equation (6.42).
pð0:32 < X   < 0:32Þ ¼ 0:68:
(6:44)
More generally, we can write
pðL1 < X   < L2Þ ¼ 1  ;
(6:45)
where L1 and L2 stand for the lower and upper limits of our confidence interval. We
need to develop expressions for L1 and L2. The limits are obtained from our sampling
distribution, which in this particular case is the sampling distribution for the sample
mean random variable. Recall that X is Nð; 2=nÞ, so the distribution of the standard
random variable Z ¼ ðX  Þ
ﬃﬃﬃn
p = is Nð0; 1Þ. Figure 6.6 shows the distribution of Z.
In terms of Z, we can write Equation (6.45) as
p
L1
=
ﬃﬃﬃn
p < Z <
L2
=
ﬃﬃﬃn
p


¼ 1  :
(6:46)
The desired sampling distribution is
fðzÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p
exp
 z2
2


:
(6:47)
–3
–2
–1
0
1
2
3
4
Z = X – µ
0.1
0.2
0.3
0.4
Probability density
1 – α
α /2
α /2
L1
L2
σ/√n
Figure 6.6 The figure shows the expected distribution for the standard random variable
Z ¼ ðX  Þ
ﬃﬃﬃn
p = which is N(0,1). The lower ðL1Þ and upper ðL2Þ boundaries of the 1  
confidence interval are indicated by the vertical lines. The location of L1 is set by the require-
ment that the shaded area to the left of L1 is equal to =2. Similarly, the shaded area to the right
of L2 is equal to =2.
154
What is a statistic?

The limits L1 and L2 are evaluated from the following two equations:
Z
L1
= ﬃﬃn
p
1
fðzÞdz ¼ 
2 ;
(6:48)
and
Z þ1
L2
= ﬃﬃn
p
fðzÞdz ¼ 
2 :
(6:49)
Let Z
2 ¼ L1
ﬃﬃﬃn
p = and Z1
2 ¼ L2
ﬃﬃﬃn
p =. Then
pðZ
2 < Z < Z1
2Þ ¼ 1  :
(6:50)
It follows that
L1 ¼ Z
2
ﬃﬃﬃn
p
and
L2 ¼ Z1
2
ﬃﬃﬃn
p :
But for a standard normal, Z
2 ¼  Z1
2; therefore,
L1 ¼  L2 ¼  Z1
2
ﬃﬃﬃn
p :
(6:51)
We can now generalize Equations (6.41) and (6.42) and write
p   ﬃﬃﬃn
p Z1
2 < X <  þ ﬃﬃﬃn
p Z1
2


¼ 1  ;
(6:52)
and
p X  ﬃﬃﬃn
p Z1
2 <  < X þ ﬃﬃﬃn
p Z1
2


¼ 1  :
(6:53)
Therefore, the 100ð1  Þ% confidence interval for  is
x  ﬃﬃﬃn
p Z1
2:
(6:54)
Clearly, the larger the sample size, the smaller the width of the interval.
6.6 Confidence intervals
155

Box 6.4
Mathematica example:
We can compute the 68% confidence interval for the mean of a population, with
known variance ¼ 0:1, from a list of data values with the following commands:
Needs[‘‘Statistics ‘ConfidenceIntervals’’’]
The line above loads the confidence intervals package and the line below computes
the confidence interval for a normal distribution.
MeanCI[data, KnownVariance ﬁ0.1, ConfidenceLevel ﬁ0.68]
Where data is a list of the sample data values. If the variance is unknown, leave out
the KnownVariance ﬁ0.1 option and then the confidence interval will be based on
a Student’s t distribution.
6.6.2 Confidence intervals for , unknown variance
Again, we know that the distribution of X is Nð; 2=nÞ, but since we do not know  we
are unable to use this distribution to compute the desired confidence interval.
Fortunately, we can obtain the confidence interval using the Student’s t statistic
which makes use of the sample variance which we can compute. Recall, that the
random variable T ¼ ðX  Þ
ﬃﬃﬃn
p =S has a Student’s t distribution with ðn  1Þ degrees
of freedom. Figure 6.7 shows a Student’s t distribution for  ¼ n  1 ¼ 9 degrees of
 –3
 –2
 –1
0
1
2
3
4
0.1
0.2
0.3
0.4
Probability density
L1
L2
T = X – µ
1 – α
α /2
α /2
S/√n
Figure 6.7 The figure shows the Student’s t distribution for the T ¼ ðX  Þ
ﬃﬃﬃn
p =S statistic, for
 ¼ n  1 ¼ 9 degrees of freedom. The lower ðL1Þ and upper ðL2Þ boundaries of the 1   con-
fidence interval are indicated by the vertical lines. The location of L1 is set by the requirement that the
shadedareatotheleftofL1 isequalto=2.Similarly,theshadedareatotherightofL2 isequalto=2.
156
What is a statistic?

freedom. For a Student’s t distribution, the t1
2;n1 quantile value is defined by the
equation
pðt1
2; n1 < T < t1
2; n1Þ ¼ 1  ;
(6:55)
which we can rewrite as
p  sﬃﬃﬃn
p t1
2; n1 < X   < sﬃﬃﬃn
p t1
2; n1


¼ 1  :
(6:56)
We can obtain values for L1 and L2 by comparing Equation (6.56) to Equation (6.45).
This yields L1 ¼  L2 ¼  ðs=
ﬃﬃﬃn
p Þt1
2; n1. The final 1   confidence interval is
x  sﬃﬃﬃn
p t1
2; n1:
(6:57)
Box 6.5
Mathematica example:
In the introduction to this chapter, we posed a problem concerning the mean
redshift of a population of cosmic gamma-ray bursts (GRB), based on a sample of
seven measured GRB redshifts (the number known at the time of writing). The
redshifts are: 1.61, 0.0083, 1.619, 0.835, 3.420, 1.096, 0.966. We now want to
determine the 68% confidence interval for the mean redshift for the population
GRB sources. We neglect the uncertainties in the individual measured redshifts as
they are much smaller than the spread of the seven values. Although we do not
know the probability density function for the population, we know from the CLT
that the distribution of the sample mean random variable ðXÞ will be approxi-
mately normal for n ¼ 7. Furthermore, 5X4 ¼ , the mean of the population,
and VarðXÞ ¼ 2=n, where 2 ¼ the variance of the population. Since we do not
know 2, we use the measured sample variance,
s2 ¼
X
7
i ¼ 1
ðxi  xÞ2
n  1
:
We can thus evaluate the Student’s t value for our sample and use this to arrive at
our 68% confidence interval for the population mean redshift (recall Equation
(6.56)).
data ¼ {1:61, 0:0083, 1:619, 0:835, 3:420, 1:096, 0:966}
MeanCI[data, ConfidenceLevel ﬁ0:68] ¼ {0:93, 1:80}
In this case, we have left out the KnownVariance option to the confidence interval
command, MeanCI, because the population variance is unknown. MeanCI now
returns a confidence interval based on the Student’s t distribution.
6.6 Confidence intervals
157

6.6.3 Confidence intervals: difference of two means
One of the most fundamental problems that occurs in experimental science, is that of
analyzing two independent measurements of the same physical quantity, one ‘‘con-
trol’’ and one ‘‘trial,’’ taken under slightly different experimental conditions, e.g., drug
testing. Here, we are interested in computing confidence intervals for the difference in
the means of the control population and the trial population, when sampling from two
independent normal distributions.
1) If x and y are unknown and x and y are known, then the random variable
Z ¼ X  Y  ðx  yÞ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
x=nx þ 2
y=ny
q
(6:58)
has a normal distribution Nð0; 1Þ. The 100ð1  Þ% confidence interval for
ðx  yÞ is
x  y  Z1
2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
x
nx
þ
2
y
ny
s
;
(6:59)
where the quantile Z1
2 is such that
pðZ  Z1
2Þ ¼ 1  
2 :
(6:60)
At this point you may be asking yourself what value of  to use in presenting your
results. There are really two types of questions we might be interested in. First, do the
data indicate that the means are significantly different? This type of question is
addressed in Chapter 7, which deals with hypothesis testing. The other type of question,
which is being addressed here, concerns estimating the difference of the two means. For
this question, it is common practice to use an  ¼ 0:32, corresponding to a 68%
confidence interval. We will look at this issue again in more detail in Section 7.2.1.
2) If x and y are unknown but assumed equal, the random variable
T ¼ X  Y  ðx  yÞ
SD
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1=nx þ 1=ny
p
has a Student’s t distribution with ðnx þ ny  2Þ degrees of freedom, where
S2
D ¼
½ðnx  1ÞS2
x þ ðny  1ÞS2
y
ðnx þ ny  2Þ
:
(6:61)
The 100ð1  Þ% confidence interval is
x  y  spt1
2; ðnxþny2Þ:
(6:62)
158
What is a statistic?

3) If x and y are unknown and assumed to be unequal, the random variable
T ¼ X  Y  ðx  yÞ
SD
is distributed approximately as Student’s t with  degrees of freedom (Press et al.,
1992), where
S2
D ¼ S2
x
nx
þ
S2
y
ny
;
(6:63)
and,
 ¼
S2
x
nx þ
S2
y
ny
h
i2
½S2x=nx2
nx1 þ
½S2y=ny2
ny1 :
(6:64)
See Section 7.2.2 for a worked example of the use of the Student’s t test for these
conditions.
6.6.4 Confidence intervals for 2
Here, we are interested in computing confidence intervals for 2 when sampling from a
normal distribution with unknown mean. Recall that ðn  1ÞS2=2 is 2
n1. Then it
follows that the 100ð1  Þ% interval for 2 is
ðn  1Þs2
2
1
2; n1
; ðn  1Þs2
2
2; n1
"
#
:
(6:65)
Box 6.6
Mathematica example:
We can compute the 68% confidence interval for the variance of a population with
unknown mean, from a list of data values designated by data, with the following
command:
VarianceCI[data,ConfidenceLevel ﬁ0.68]
6.6.5 Confidence intervals: ratio of two variances
In this section, we want to determine confidence intervals for the ratio of two variances
when sampling from two independent normal distributions. In this case, the
100ð1  Þ% confidence interval for 2
y=2
x is
6.6 Confidence intervals
159

s2
y
s2
x
1
f1
2; ny1; nx1
;
s2
y
s2
x
f1
2; nx1; ny1
"
#
:
(6:66)
Box 6.7
Mathematica example:
We can compute the 68% confidence interval for the ratio of the population
variance of data1 to the population variance of data2 with the following command:
VarianceRatioCI[data1,data2,ConfidenceLevel ﬁ0.68]
6.7 Summary
In this chapter, we introduced the X, 2, S2, Student’s t and F statistics and showed
how they are useful in making inferences about the mean ðÞ and variance ð2Þ of an
underlying population from a random sample. In the frequentist camp, the usefulness
of any particular statistic stems from our ability to predict its distribution for a very
large number of hypothetical repeats of the experiment. In this chapter we have
assumed that each of the data sets, either real or hypothetical, is an IID sample
from a normal distribution, in some cases appealing to the Central Limit Theorem
to satisfy this requirement. For IID normal samples, we found that:
1.
S2 ¼
X
n
i ¼ 1
ðXi  XÞ2
n  1
is an unbiased estimator of the sample variance, 2.
2. The sampling distribution of
ðn  1Þ S2
2 ¼
X
n
i ¼ 1
ðXi  XÞ2
2
is 2 with ðn  1Þ degrees of freedom. This statistic has a wide range of uses that we will learn
in subsequent chapters (e.g., Method of Least Squares) and is clearly useful in specifying
confidence intervals for estimates of 2 based on the sample variance S2.
3. One familiar form of the Student’s t statistic is
T ¼ ðX  Þ
ðS=
ﬃﬃﬃn
p Þ :
The statistic is particularly useful for computing confidence intervals for the population mean,
, based on the sample X and S2. In Chapter 9, we will see the Student’s t distribution reappear
in a Bayesian context characterizing the posterior PDF for a particular state of information.
160
What is a statistic?

4. The F statistic is given by
F12 ¼ S2
1=2
1
S2
2=2
2
:
We saw how this can be used to compare the ratio of the variances of two populations from a
measurement of the sample variance of each population.
Once the distribution of the statistic is specified, it is possible to interpret the
significance of the particular value of the statistic corresponding to our one actual
measured sample. For example, we were able to test a cigarette manufacturer’s claim
about the mean nicotine content by comparing the value of the Student’s t statistic for
a measured sample to the distribution for a hypothetical reference set. In case you
didn’t fully comprehend this line of reasoning, we will go into it in more detail in the
next chapter, which deals with frequentist hypothesis testing.
Throughout this chapter, the expression ‘‘number of degrees of freedom’’ has
cropped up in connection with each choice of statistic. Its precise meaning is defined
in the definition of the 2, Student’s t, and F distributions. Roughly, what it translates
to in practice is the number of data points (or data bins if the data are binned) in the
sample used to compute the statistic, minus the number of additional parameters (like
S2 in the Student’s t statistic) that have to be estimated from the same sample.
A major part of inferring the values of the  and 2 of the population concerns their
estimated uncertainties. In the frequentist case, this amounts to estimating a con-
fidence interval, e.g., 68% confidence interval. Keep in mind that a frequentist con-
fidence interval says nothing directly about the probability that a single confidence
interval, derived from your one actual measured sample, will contain the true popula-
tion value. Then what does the 68% confidence mean? It means that if you repeated the
measurement a large number of times, each time computing a 68% confidence interval
from the new sample, then 68% of these intervals will contain the true value.
6.8 Problems
1. Suppose you are given the IID normal data sample f0:753; 3:795; 4:827; 2:025g.
Compute the sample variance and standard deviation. What is the standard error
of the sample mean?
2. What is the 95% confidence interval for the mean of the IID normal sample
f0:753; 3:795; 4:827; 2:025g?
3. Compute the area in the tail of a 2 distribution to the right of 2 ¼ 30:61, for  ¼ 10
degrees of freedom.
4. The sample variance is s2
1 ¼ 16:65 for n1 ¼ 6 IID samples from a normal distribution
with a population variance 2
1. Also, s2
2 ¼ 5:0 for n2 ¼ 11 IID samples from a second
independent normal distribution with a population variance 2
2. If we assume that
2
1 ¼ 22
2, then from Equation (6.40), we obtain f ¼ 1:665 for 1 ¼ n1  1 ¼ 5 and
2 ¼ n2  1 ¼ 10 degrees of freedom. What is the probability of getting an f value
 3:33 by chance if 2
1 ¼ 22
2?
6.8 Problems
161

7
Frequentist hypothesis testing
7.1 Overview
One of the main objectives in science is that of inferring the truth of one or more
hypotheses about how some aspect of nature works. Because we are always in a state
of incomplete information, we can never prove any hypothesis (theory) is true. In
Bayesian inference, we can compute the probabilities of two or more competing
hypotheses directly for our given state of knowledge.
In this chapter, we will explore the frequentist approach to hypothesis testing which
is considerably less direct. It involves considering each hypothesis individually and
deciding whether to (a) reject the hypothesis, or (b) fail to reject the hypothesis, on the
basis of the computed value of a suitable choice of statistic. This is a very big subject
and we will give only a limited selection of examples in an attempt to convey the main
ideas. The decision on whether to reject a hypothesis is commonly based on a quantity
called a P-value. At the end of the chapter we discuss a serious problem with
frequentist hypothesis testing, called the ‘‘optional stopping problem.’’
7.2 Basic idea
In hypothesis testing we are interested in making inferences about the truth of some
hypothesis. Two examples of hypotheses which we analyze below are:
* The radio emission from a particular galaxy is constant.
* The mean concentration of a particular toxin in river sediment is the same at two locations.
Recall that in frequentist statistics, the argument of a probability is restricted to
a random variable. Since a hypothesis is either true or false, it cannot be considered
a random variable and therefore we must indirectly infer the truth of the hypothesis
(in contrast to the direct Bayesian ).
In the river toxin example, we proceed by assuming that the mean concentration is
the same for both locations and call this the null hypothesis. We then choose a statistic,
such as the sample mean, that can be computed from our one actual data set. The
value of the statistic can also be computed in principle for a very large number of
162

hypothetical repeated measurements of the river sediment under identical conditions.
Our choice of statistic must be one whose distribution is predictable for this reference
set of hypothetical repeats, assuming the truth of our null hypothesis. We then
compare the actual value of the statistic, computed from our one actual data set, to
the predicted reference distribution. If it falls in a very unlikely spot (i.e., way out in the
tail of the predicted distribution) we choose to reject the null hypothesis at some
confidence level on the basis of the measured data set.
If the statistic falls in a reasonable part of the distribution, this does not mean that
we accept the hypothesis; only that we fail to reject it. At best, we can substantiate
a particular hypothesis by failing to reject it and rejecting every other competing
hypothesis that has been proposed. It is an argument by contradiction designed to
show that the null hypothesis will lead to an absurd conclusion and should therefore
be rejected on the basis of the measured data set. It is not even logically correct to say
we have disproved the hypothesis, because, for any one data set it is still possible by
chance that the statistic will fall in a very unlikely spot far out in the tail of the
predicted distribution. Instead, we choose to reject the hypothesis because we consider
it more fruitful to consider others.
7.2.1 Hypothesis testing with the 2 statistic
Figure 7.1 shows radio flux density measurements of a radio galaxy over a span of
6100 days made at irregular intervals of time. The observations were obtained as part
of a project to study the variability of galaxies at radio wavelengths. The individual
radio flux density measurements are given in Table 7.1.
0
1000
2000
3000
4000
5000
6000
Time (days)
0
5
10
15
20
Radio flux density
Figure 7.1 Radio astronomy measurements of a galaxy over time.
7.2 Basic idea
163

Below we outline the steps involved in the current hypothesis test:
1. Choose as our null hypothesis that the galaxy has an unknown but constant flux density.
If we can demonstrate that this hypothesis is absurd at say the 95% confidence level, then this
provides indirect evidence that the radio emission is variable. Previous experience with the
measurement apparatus indicates that the measurement errors are independently normal
with a  ¼ 2:7.
2. Select a suitable statistic that (a) can be computed from the measurements, and (b) has a
predictable distribution. More precisely, (b) means that we can predict the distribution of
values of the statistic that we would expect to obtain from an infinite number of repeats of the
above set of radio measurements under identical conditions. We will refer to these as our
hypothetical reference set. More specifically, we are predicting a probability distribution for
this reference set.
To refute the null hypothesis, we will need to show that scatter of the individual measure-
ments about the mean is larger than would be expected from measurement errors alone.
A useful measure of the scatter in the measurements is the sample variance. We know from
Section 6.3, that the random variable ðn  1ÞS2=2 (usually called the 2 statistic) has a 2
distribution with ðn  1Þ degrees of freedom when the measurement errors are known to be
independently normal. From Equation (6.4), it is clear that the distribution depends only on
the number of degrees of freedom.
3. Evaluate the 2 statistic from the measured data. Let’s start with the expression for the 2
statistic for our data set:
2 ¼
X
n
i¼1
ðxi  xÞ2
2
;
(7:1)
Table 7.1 Radio astronomy flux density measurements for a galaxy.
Day Number
Flux Density (mJy)
0.0
14.2
718.0
5.0
1097.0
3.3
1457.1
15.5
2524.1
4.2
3607.7
9.2
3630.1
8.2
4033.1
3.2
4161.3
5.6
5355.9
9.9
5469.1
7.4
6012.4
6.9
6038.3
10.0
6063.2
5.8
6089.3
11.4
164
Frequentist hypothesis testing

where xi represents the ith flux density value, x ¼ 7:98 mJy is the average of our sample values,
and  ¼ 2:7, as given above. The number of degrees of freedom  ¼ n  1 ¼ 15  1 ¼ 14,
where n is the number of flux density measurements.1 Equation (7.1) becomes
2 ¼
X
n
i¼1
ðxi  xÞ2
2
¼
X
n
i¼1
ðxi  7:98Þ2
2:72
¼ 26:76:
(7:3)
4. Plot the computed value of 2 ¼ 26:76 on the 2 distribution predicted for 14 degrees of
freedom. This is shown in Figure 7.2. The 2 computed from our one actual data set is shown
by the vertical line. The question of how unlikely is this value of 2 is usually interpreted in
terms of the area in the tail of the 2 distribution to the right of this line which is called the
P-value or significance. We can evaluate this from
P-value ¼ 1  Fð2Þ ¼ 1 
Z 2
0
1
ð
2Þ2

2 x

21 exp  x
2


dx;
(7:4)
where Fð2Þ is the cumulative 2 distribution. Alternatively, we can evaluate the P-value with
the following Mathematica command.
5
10
15
20
25
30
35
40
 χ2
0.02
0.04
0.06
0.08
Probability density
Measured χ2 = 26.76
Figure 7.2 The 2 distribution predicted on the basis of our null hypothesis with 14 degrees of
freedom. The value computed from the measurements, 2 ¼ 26:76, is indicated by the vertical
bar.
1 The null hypothesis did not specify the assumed value for , the constant flux density, so we estimated it from the mean
of the data. Whenever we estimate a model parameter from the data, we lose one degree of freedom. If the null
hypothesis had specified , then we would have used the following expression for the 2 statistic:
2 ¼
X
n
i¼1
ðxi  Þ2
2
;
ð7:2Þ
which has a 2 distribution with n degrees of freedom.
7.2 Basic idea
165

Box 7.1
Mathematica 2 P-value
Needs[‘‘Statistics ‘HypothesisTests’’’]
The line above loads a package containing a wide range of hypothesis tests, and
the following line computes the P-value for a 2 ¼ 26:76 and 14 degrees of
freedom:
ChiSquarePValue[26.76,14] ! 0:02
Note: the ChiSquarePValue has a maximum value of 0.5 and will measure the area
in the lower tail of the distribution if 2
measured falls in the lower half of the
distribution. In the current problem, we want to be sure we measure the area to
the right of 2
measured, so use the command:
GammaRegularized
h
NM
2
; c2
2
i
¼GammaRegularized
 14
2 ; 26:76
2

where N is the number of data points and M is the number of parameters
estimated from the data.
Note: in some problems, it is relevant to use a two-sided test (see Section 7.2.3)
using the 2 statistic, e.g., testing that the population variance is equal to a
particular value.
5. Finally, compute our confidence in rejecting the null hypothesis which is equal to the area
of the 2 distribution to the left of 2 ¼ 26:76. This area is equal to ð1  P-valueÞ ¼ 0:98
or 98%.
While the above recipe is easy to compute, it undoubtedly contains many perplexing
features. Most among them is the strangely convoluted definition of the key determi-
nant of falsification, the P-value, also known as the significance .
What precisely does the P-value mean? It means that if the flux density of this galaxy
is really constant, and we repeatedly obtained sets of 15 measurements under the same
conditions, then only 2% of the 2 values derived from these sets would be expected to
be greater than our one actual measured value of 26.76. At this point, you may be
asking yourself why we should care about a probability involving results never
actually obtained, or how we choose a P-value to reject the null hypothesis. In some
areas of science, a P-value threshold of 0.05 (confidence of 95%) is used; in other areas,
the accepted threshold for rejection is 0.01,2 i.e., it depends on the scientific culture you
are working in.
Unfortunately, P-values are often incorrectly viewed as the probability that the
hypothesis is true. There is no objective means for deciding the latter without specify-
ing an alternative hypothesis, H1, to the null hypothesis. The point is that any
2 Note: because experimental errors are frequently underestimated, and hence 2 values overestimated, it is not
uncommon to require a P-value < 0:001 before rejecting a hypothesis.
166
Frequentist hypothesis testing

particular P-value might arise even if the alternative hypothesis is true.3 The concept of
an alternative hypothesis is introduced in Section 7.2.3. In Section 9.3, we will consider
a Bayesian analysis of the galaxy variability problem.
There is another useful way of expressing a statistical conclusion like that of the
above hypothesis test. Instead of the P-value, we can measure how far out in the tail
the statistic falls in units of the  ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
variance
p
of the reference distribution. For
example, the variance of a 2 distribution ¼ 2 ¼ 28 and the expectation value of
2 ¼ h2i ¼  ¼ 14. Therefore:
2
obs  h2i

¼ 2
obs  h2i
ﬃﬃﬃﬃﬃ
2
p
¼ 26:76  14
ﬃﬃﬃﬃﬃ
28
p
¼ 2:4  2:4:
In many branches of science, a minimum of a 3 effect is required for a claim to be
taken with any degree of seriousness. More often, referees of scientific journals will
require a 5 result to recommend publication. It depends somewhat on how difficult
or expensive it is to get more data.
Now suppose we were studying a sample of 50 galaxies for evidence of variable
radio emission. If all 50 galaxies were actually constant, then for a confidence thresh-
old of 98%, we would expect to detect only one false variable in the sample by chance.
If we found that ten galaxies had 2 values that exceeded the 98% quantile value, then
we would expect nine of them were not constant. If, on the other hand, we were
studying a sample of 104 galaxies, we would expect to detect approximately 200 false
variables.
It is easy to see how to extend the use of the 2 test described above to other more
complex situations. Suppose we had reason to believe that the radio flux density was
decreasing linearly with time at a known rate, m, with respect to some reference time,
t0. In that case,
2 ¼
X
n
i ¼ 1
ðxi  ½mðti  t0ÞÞ2
2
;
(7:5)
where ti is the time of the ith sample. We will have much more use for the 2 statistic in
later chapters dealing with linear and nonlinear model fitting (see Section 10.8).
7.2.2 Hypothesis test on the difference of two means
Table 7.2 gives measurements of a certain toxic substance in the river sediment at two
locations in units of parts per million (ppm). In this example, we want to test the
hypothesis that the mean concentration of this toxin is the same at the two locations.
How do we proceed? Sample 1 consists of 12 measurements taken from location 1, and
3 The difficulty in interpreting P-values has been highlighted in many papers (e.g., Berger and Sellke, 1987; Delampady
and Berger, 1990; Sellke et al., 2001). The focus of these works is that P-values are commonly considered to imply
considerably greater evidence against the null hypothesis H0 than is actually warranted.
7.2 Basic idea
167

sample 2 consists of 8 measurements from location 2. For each location, we can
compute the sample mean. From the frequentist viewpoint, we can compare sample 1
to an infinite set of hypothetical data sets that could have been realized from location 1.
For each of the hypothetical data sets, we could compute the mean of the 12 values.
According to the Central Limit Theorem, we expect that the means for the hypo-
thetical data sets will have an approximately normal distribution. Let X1 and X2 be
random variables representing means for locations 1 and 2, respectively. It is con-
venient to work with the standard normal distributions given by
Z1 ¼ X1  1
1= ﬃﬃﬃﬃﬃ
n1
p
;
(7:6)
and
Z2 ¼ X2  2
2= ﬃﬃﬃﬃﬃ
n2
p
;
(7:7)
where 1 and 2 are the population means and 1 and 2 the population standard
deviations. Similarly, we expect
Z ¼ X1  X2  ð1  2Þ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
1=n1 þ 2
2=n2
q
(7:8)
to be approximately normal as well (see Section 6.6.3). In the present problem, the null
hypothesis represented by H0 corresponds to
H0  1 ¼ 0:
(7:9)
Table 7.2 River sediment toxin concentration measurements at two locations.
Location 1 (ppm)
Location 2 (ppm)
13.2
8.9
13.8
9.1
8.7
8.3
9.0
6.0
8.6
7.7
9.9
9.9
14.2
9.9
9.7
8.9
10.7
8.3
8.5
9.2
168
Frequentist hypothesis testing

Since we do not know the population standard deviation for Z, we need to estimate
it from our measured sample. Then according to Section 6.6.3, the random variable T
given by
T ¼ X1  X2  ð1  2Þ
Sp
(7:10)
has a Student’s t distribution. All that remains is to specify the value of Sp and the
number of degrees of freedom, , for the Student’s t distribution.
In the present problem, we cannot assume 1 ¼ 2 so we use Equations (6.63) and
(6.64):
S2
p ¼ S2
1
n1
þ S2
2
n2
;
(7:11)
and
 ¼
S2
1
n1 þ
S2
2
n2
h
i2
½S2
1=n12
n11 þ
½S2
2=n22
n21
:
(7:12)
Note: Equation (6.30) for the Student’s t probability density is valid even if  is not an
integer.
Of course, we could test the hypothesis that the standard deviations are the same but
we leave that for a problem at the end of the chapter. Inserting the data we find the t
statistic ¼ 2:23 and  ¼ 17:83 degrees of freedom. We are now ready to test the null
hypothesis by comparing the measured value of the t statistic to the distribution of t
values expected for a reference set of hypothetical data sets for 17.83 degrees of
freedom. Figure 7.3 shows the reference t distribution and the measured value
of 2.23. We can compute the area to the right of t ¼ 2:23 which is called the one-
sided P-value. We can evaluate this with the following Mathematica command:
Needs[‘‘Statistics ‘HypothesisTests’’’]
StudentTPValue[2.23,17.83,OneSided ->True] ﬁ0:0193
This P-value is the fraction of hypothetical repeats of the experiment that are expected
to have t values  2:23 if the null hypothesis is true. In this problem, we would expect
an equal number of hypothetical repeats to fall in the same area in the opposite tail
region by chance.
What we are really interested in is the fraction of hypothetical repeats that would be
extreme enough to fall in either of these tail regions (shaded regions of Figure 7.3) or
what is called the two-sided P-value. We can evaluate this with the following
Mathematica command:
7.2 Basic idea
169

Needs[‘‘Statistics ‘HypothesisTests’’’]
StudentTPValue[2.23,17.83,TwoSided ->True] ﬁ0:0386
Mathematica provides an easier way of computing this P-value (i.e., computes the
t value and degrees of freedom for you) with
MeanDifferenceTest[data1,data2,diff,TwoSided ->True, FullReport ->True]
where data1 and data2 are the two data lists.
If the variances of the two data sets are known to be the same then use
MeanDifferenceTest[data1,data2,diff,EqualVariances ->True,
TwoSided ->True,FullReport ->True]
Our confidence in rejecting the null hypothesis is equal to the area outside of these
extreme tail regions which equals 1  (two-sided P-value) ¼ 0:961 or 96.1%. If we use
a typical threshold for rejection of say 95%, then in this case, we just reject the null
hypothesis.
7.2.3 One-sided and two-sided hypothesis tests
In the galaxy example, where we used the 2 statistic, we computed the confidence in
rejecting the null hypothesis using a one-sided tail region. Why didn’t we use a two-
sided tail region as in the river toxin problem? Here, we introduce the concept of the
 –3
 –2
 –1
0
1
2
3
4
Student’s t statistic
0.1
0.2
0.3
0.4
Probability density
Student’s t = 2.23 value
Figure 7.3 Reference Student’s t distribution with 17.83 degrees of freedom. The measured t
statistic is indicated by a line and the shaded areas correspond to upper and lower tail areas in a
two-sided hypothesis test.
170
Frequentist hypothesis testing

alternative hypothesis, i.e., alternative to the null hypothesis. In the galaxy problem,
the alternative hypothesis is that the radio emission is variable. If the alternative
hypothesis were true, then examination of Equation (7.1) indicates that for a given
value of the measurement error, , we expect the value of 2 to be greater4 when the
source is variable than when it is constant. In this case, we would expect to measure 2
values in the upper tail but not the lower, which is why we used a one-sided test. In the
river toxin problem, the alternative hypothesis is that the mean toxin levels at the two
locations are different. In this case, if the alternative were true, we would expect t
values in either tail region, which is why we used the two-sided P-value test.
The rules of the game are that the null hypothesis is regarded as true unless sufficient
evidence to the contrary is presented. If this seems a strange way of proceeding, it might
prove useful to consider the following courtroom analogy. In the courtroom, the null
hypothesis stands for ‘‘the accused is presumed innocent until proven otherwise.’’ Table
7.3 illustrates the possible types of errors that can arise in a hypothesis test.
In hypothesis testing, a type I error is considered more serious (i.e., the possibility of
convicting an innocent party is considered worse than the possibility of acquitting a
guilty party). A type I error is only possible if we reject H0, the null hypothesis. It is not
possible to minimize both the type I and type II errors. The normal procedure is to
select the maximum size of the type I error we can tolerate and construct a test
procedure that minimizes the type II error.5 This means choosing a threshold value
for the statistic which if exceeded will lead us to reject H0. For example, suppose we are
dealing with a one-sided upper tail region test and we are willing to accept a maximum
type I error of 5%. This means a threshold value of the test statistic anywhere in the
upper 5% tail area satisfies our type I error requirement. The size of the type II error is
a minimum at the lower boundary of this region, i.e., the larger the value of the test
statistic, the more likely it is we will acquit a possibly guilty party.
Suppose we had used a two-tail test in the radio galaxy problem of Section 7.2.1
rather than the upper tail test. Recall that the alternative hypothesis is only expected to
Table 7.3 Type I and type II errors in hypothesis testing.
Possible decisions
Possible consequences
Errors
Reject
when in fact H0 true
 Type I error (conviction)
H0
when in fact H0 false
Fail to reject
when in fact H0 true
H0
when in fact H0 false
 Type II error (acquittal)
4 The only way for the variability to reduce 2 is if the fluctuations in the galaxies’ output canceled measurement errors.
5 The test that minimizes the type II error is often referred to as having maximum ‘‘power’’ in rejecting the null hypothesis
when it really is false.
7.2 Basic idea
171

give rise to larger values of 2 than those expected on the basis of the null hypothesis.
In a two-tail test we would divide the rejection area equally between the lower and
upper tails, i.e., for a 98% confidence threshold, that would mean the upper and lower
tail areas would each have an area of 1%. The 2 value required for rejecting the null
hypothesis in the upper tail region would be larger in a two-tail test than for a one-tail
test. Thus, for a given confidence level, the two-tail test would increase the chance of a
type II error, because we would have squandered rejection area in the lower tail region,
a region of 2 that would not be accessed under the assumption of our alternative
hypothesis.
In the river toxin example of Section 7.2.2, the alternative hypothesis can give rise to
values of the Student’s t statistic in either tail region. In this case, we will want to reject
H0 if the t value falls far enough out in either tail region. In this case, divide the area
corresponding to the maximum acceptable type I error equally between the two tail
regions. To minimize the type II area, choose threshold values for the test statistic that
are at the inner boundaries of these two tails.
In practice, the role of the alternative hypothesis is mainly to help decide whether to
use an upper tail region, a lower tail region or both tails in our statistical test. The
choice depends on what is physically meaningful and minimizes the size of the type II
error. In Section 6.4, we used the Student’s t statistic in an analysis of a cigarette
manufacturer’s claim regarding nicotine content. Since we would reject the claim if the t
valuefell sufficientlyfarout ineithertail region,weshoulduseatwo-sidedtest inthiscase.
Typically, in frequentist hypothesis testing involving the use of P-values, a specific
value for the type II error is not normally computed. Instead it is used as an argument
to decide where in the tail region to locate the decision value of the test statistic, as
outlined above.
7.3 Are two distributions the same?
We have previously considered tests to compare the means and variances of two
samples. Now generalize the questions and ask the simple question: ‘‘Can we reject the
null hypothesis that the two samples are drawn from the same population?’’ Rejecting
the null hypothesis in effect implies that the two data sets are from different distribu-
tions. Failing to reject the null hypothesis only shows that the data sets can be
consistent with a single distribution.
Deciding whether two distributions are different is a problem that occurs in many
research areas.
Example 1:
Are stars uniformly distributed in the sky? That is, is the distribution of stars as a
function of latitude the same as the distribution of the sky area with latitude? In this
case, the data set (location of stars) and comparison distribution (sky area) are
continuous.
172
Frequentist hypothesis testing

Example 2:
Are the educational patterns in Vancouver and Toronto the same? Is the distribution
of people as a function of ‘‘last grade attended’’ the same? Here, both data sets are
discrete or binned.
Example 3:
Are the distribution of grades in a particular physics course normally distributed?
Here, the grades are discrete or binned and the distribution we to is continuous. In this
latter case, we might be comparing with a normal distribution with a given  and 2 or
alternatively we might not know  and 2 and be interested only in whether the shape
is normal.
One can always turn continuous data into binned data by grouping the events into
specified ranges of the continuous variable(s). Binning involves a loss of information,
however, and there is considerable arbitrariness as to how the bins should be chosen.
The accepted test for differences between binned distributions is the Pearson 2 test.
For continuous data as a function of a simple variable, the most generally accepted
test is the Kolmogorov–Smirnov test.
7.3.1 Pearson 2 goodness-of-fit test
Let a random sample of size n from the distribution of a random variable X be divided
into k mutually exclusive and exhaustive classes (or bins) and let Ni ði ¼ 1; . . . ; kÞ be the
number of observations in each class (or bin). We want to test the simple null hypothesis
H0  pðxÞ ¼ p0ðxÞ
where the claimed probability model p0ðxÞ is completely specified with regard to all
parameters. Since p0ðxÞ is completely specified, we can determine the probability pi of
obtaining an observation in the ith class under H0, where by necessity Pk
i ¼ 1 pi ¼ 1.
Let ni ¼ npi ¼ expected number in each class according to the null hypothesis, H0.
Usually, H0 does not predict n, and this is obtained by setting
n ¼
X
k
i¼1
Ni:
This has the effect of reducing the number of degrees of freedom in the 2 test by
one.6 Note: Ni is an integer while the ni’s may not be.
6 Note on the number of degrees of freedom: If H0 does predict the ni’s and there is no a priori constraint on any of the
Ni’s, then  = number of bins, k.
More commonly, the ni’s are normalized after the fact so that their sum equals the sum of the Ni’s, the total number
of events measured. In this case,  ¼ k  1.
If the model that gives the ni’s had additional free parameters that were adjusted after the fact to agree with the data,
then each of these additional ‘‘fitted’’ parameters reduces the  by one. The number of these additional fitted parameters
(not including the normalization of the ni’s) is commonly called the ‘‘number of constraints’’ so the number of degrees
of freedom is  ¼ k  1 when there are ‘‘zero constraints.’’
7.3 Are two distributions the same?
173

Question: What is the form of p0ðxÞ?
Answer: Since there are k mutually exclusive categories with probabilities p1; p2; . . . ; pk,
then under the null hypothesis, the probability of the grouped sample is the same as the
probability of a multinomial distribution discussed in Section 4.3.
In what follows, we will deduce the appropriate test statistic for H0 which is known
as the Pearson chi-square goodness-of-fit test. Start with the simple case where k ¼ 2;
thus, p0ðxÞ is a binomial distribution.
pðxjn; pÞ ¼
n!
ðn  xÞ!x! pxð1  pÞnx;
x ¼ 0; 1; . . . ; n:
(7:13)
In this case, x ¼ n1, p ¼ p1, n  x ¼ n2 and ð1  pÞ ¼ p2. Recall that  ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
npð1  pÞ
p
for the binomial distribution. Consider the standardized random variable
Y ¼
N1  np1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
np1ð1  p1Þ
p
:
(7:14)
For np1  1, the distribution of Y is approximately the standard normal. Recall that
the square of a standard normal variable,
X
n
i¼1
ðxi  Þ2
2
;
is 2-distributed with n degrees of freedom. Thus we expect the statistic
ðN1  np1Þ2
np1ð1  p1Þ
(7:15)
to be approximately 2-distributed with one degree of freedom.
Note:
1
np1
þ 1
np2


¼ nðp1 þ p2Þ
n2p1p2
¼
1
np1ð1  p1Þ
ðN1  np1Þ2
np1ð1  p1Þ ¼ ðN1  np1Þ2
np1
þ ½ðn  N2Þ  nð1  p2Þ2
np2
¼ ðN1  np1Þ2
np1
þ ðN2  np2Þ2
np2
¼
X
2
i¼1
ðNi  npiÞ2
npi
:
(7:16)
Following this reasoning, it can be shown that for k  2 the statistic,
X
k
i¼1
ðNi  npiÞ2
npi
(7:17)
174
Frequentist hypothesis testing

is approximately 2-distributed with  ¼ k  1 degrees of freedom. Ni is the observed
frequency of the ith class and npi is the corresponding expected frequency under the
null hypothesis. Any term in Equation (7.17) with Ni ¼ npi ¼ 0 should be omitted
from the sum. A term with pi ¼ 0 and Ni 6¼ 0 gives an infinite 2, as it should, since in
this case, the Ni’s cannot possibly be drawn from the pi’s.
Strictly speaking, the 2 P-value is the probability that the sum of squares of 
standard normal random variables will be greater than 2. In general, the terms in the
sum of Equation (7.17) will not be individually normal. However, if either the number
of bins is large ð 1Þ, or the number of events in each bin is large ð 1Þ, then the 2
P-value is a good approximation for computing the significance of 2 values given by
Equation (7.17). Its use to estimate the significance of the Pearson 2 goodness-of-fit
test is standard.
Example 1:
In this first example, we apply the Pearson 2 goodness-of-fit test to a k ¼ 2 bin
problem and compare with the exact result expected using a test based on the binomial
distribution. Suppose a certain theory predicts that the fraction of radio sources that
are expected to be quasars at an observing wavelength of 20 cm is 70%. A sample of 90
radio sources is selected and each source is optically identified. Only 54 turn out to be
quasars. At what confidence level can we reject the above theory? Thus, our null
hypothesis is that the theory is true.
Quasars
Other
Predicted
63
27
Observed
54
36
Number of degrees of freedom ¼ number of bins  1 ¼ 1.
2
1 ¼
X
2
i¼1
ðNi  npiÞ2
npi
¼ ð54  63Þ2
63
þ ð36  27Þ2
27
¼ 4:29:
Our alternative hypothesis in this case is that the theory is not true. Based on the
alternative hypothesis, we would choose an upper tail test for the Pearson 2 statistic.
The observed 2 of 4.29 corresponds to a P-value of 3.8%.
What is the corresponding P-value predicted by the binomial distribution? Recall
that the binomial distribution (Equation (7.13)) predicts the probability of x successes
in n trials when the probability of a success in any one trial is p. In this case, a success
means the source is a quasar. According to the theory, p ¼ 0:7. First we calculate the
area in the tail region extending from n ¼ 0 to n ¼ 54 which equals 2.7%. The true
P-value is double this, or 5.4%, because we need to use a two-tailed test since we would
reject the null hypothesis if the observed number fell far enough out in either tail of the
binomial distribution. Examination of Equation (7.15) demonstrates that both of
these binomial tails contribute to a single 2 tail. Thus, using the 2 test, we would
reject the null hypothesis at the 95% confidence level but just fail to reject the
7.3 Are two distributions the same?
175

hypothesis using the more accurate test based on the binomial distribution.
Comparison of the results, P-values ¼ 3:8% ð2Þ and ¼ 5:4% (binomial) indicates
the approximate level of agreement to be expected from the Pearson 2 test in this
simple two-bin test and an n  100.
Now repeat the above test; only this time, we will use a sample of 2000 radio sources
of which 1360 prove to be quasars.
2
1 ¼
X
2
i¼1
ðNi  npiÞ2
npi
¼ ð1360  1400Þ2
1400
þ ð640  600Þ2
600
¼ 3:81:
In this case, the observed 2 of 3.81 corresponds to a P-value (significance ) of 5.1%.
The more accurate P-value based on the binomial distribution is equal to 5.4%. As
expected, as we increase the sample size, the agreement between the two tests becomes
much closer. In this case, both tests just fail to reject the null hypothesis at the 95% level.
Example 2:
Now we consider an example involving a large number of bins or classes. Table 7.4
compares the total number of goals scored per game in four seasons of World Cup
soccer matches (years 1990, 1994, 1998, and 2002), with the expected number if the
number of goals is Poisson distributed. Only the goals scored in the 90 minutes
regulation time are considered. This leaves out goals scored in extra time or in penalty
shoot-outs. Based on the information provided, is there reason to believe at the 95%
confidence level that the number of goals is not a Poisson random variable?
The Poisson distribution is given by
pðnÞ ¼ ðÞne
n!
;
where  ¼ average number of goals per game (a parameter that must be estimated
from the data). Each parameter estimated from the data decreases the number of
degrees of freedom by one. From the data of Table 7.4, we compute  ¼ 2:4785.
The probability of exactly zero goals under the null hypothesis of a Poisson
distribution is
pð0Þ ¼ ð2:4785Þ0e2:4785
0!
¼ 0:0839:
For n ¼ 232 games, the expected number of games with zero goals is
232  0:0839 ¼ 19:46. Even though the Poisson distribution makes non-zero predic-
tions for seven or more goals, the expected number rapidly falls below the resolution
of our data set. There is no requirement that the bins be of equal size so our last bin is
for  7 goals.
For k ¼ 8 classes, the number of degrees of freedom ¼ 6. We lose one degree of
freedom from the normalizing n ¼ Pk
i¼1 Ni, and another from estimating  from
the data. The value of 2 ¼ 2:66, which is derived from the data in Table 7.4,
176
Frequentist hypothesis testing

corresponds to a P-value (significance ) of 0.85. This corresponds to a confidence in
rejecting the null hypothesis of 15%, which is much less than the 95% usually
required. Thus, we fail to reject the null hypothesis that the number of goals scored
is Poisson distributed. For more statistical analysis of the World Cup soccer data,
see Chu (2003).
7.3.2 Comparison of two-binned data sets
In this case,
2 ¼
X
i
ðRi  SiÞ2
Ri þ Si
;
(7:18)
where Ri and Si are the number of events in bin i for the first and second data set,
respectively. It is instructive to compare Equation (7.18) with Equation (7.17). The
term in the denominator of Equation (7.17), the predicted number of counts in the ith
bin, is a measure of the expected variance in the counts. The variance of the difference
of two random variables is the sum of their variances, which explains why the
denominator in Equation (7.18) is Ri þ Si.
If the data were collected in such a way that P Ri ¼ P Si, then  ¼ k  1. If this
requirement were absent, the number of degrees of freedom would be k.
7.4 Problem with frequentist hypothesis testing
We now consider a serious problem with frequentist hypothesis testing referred to as
the optional stopping problem (e.g., Loredo, 1990; Berger and Berry, 1988). The
optional stopping problem is best illustrated by an example. Consider the following
Table 7.4 World Cup goal statistics.
Number of goals
Actual number of
games
Expected number of
games
½Ni  npiðÞ2
npiðÞ
0
19
19.46
0.0108
1
49
48.23
0.0124
2
60
59.76
0.0009
3
47
49.37
0.1142
4
32
30.59
0.0647
5
18
15.16
0.5302
6
3
6.26
1.7009
7
4
3.15
0.2267
Totals
232
232
2.6607
7.4 Problem with frequentist hypothesis testing
177

astronomical fable motivated by a tutorial given by Tom Loredo at a Maximum
Entropy and Bayesian Methods meeting:
An Astronomical Fable
Theorist: I predict the fraction of nearby stars that are like the sun (G spectral class) is
f ¼ 0:1.
Observer: I count five G stars out of N ¼ 102 total stars observed. This gives me a
P-value ¼ 4:3%. Your theory is rejected at the 95% level.
Theorist: Let me check that: I can use the binomial distribution to compute the
probability of observing five or fewer G stars out of a total of 102 stars observed
for a predicted probability f ¼ 0:1.
P-value ¼ 2 
X
5
n¼0
pðnjN; f Þ;
(7:19)
where,
pðnjN; f Þ ¼
N!
n!ðN  nÞ! f nð1  f ÞNn:
(7:20)
The factor of 2 in Equation (7.19) is because a two-tailed test is required here. My
hypothesis could be rejected if either too few or too many G stars were counted.
I get a P-value ¼ 10% so my theory is still alive. You have failed to reject my theory
at the 95% level.
Observer: Never trust a theorist with your data! I planned my observations by deciding
beforehand that I would observe until I saw nG ¼ 5 G stars, and then stop. The
random quantity your theory predicts is thus N, not nG. The correct reference
distribution is the negative binomial. Thus,
P-value ¼ 2 
X
1
N¼102
pðNjnG; f Þ;
(7:21)
where,
pðNjnG; f Þ ¼
N  1
nG  1


f nGð1  f ÞNnG:
(7:22)
I get a P-value ¼ 4:3% as I claimed.
Theorist: What if bad weather ended your observations before you saw five G stars?
Observer: I’d either throw out the data, or include the probability of bad weather.
178
Frequentist hypothesis testing

Theorist: But then you should include it in the analysis now, because the weather could
have been bad.
MORAL: Never trust a frequentist with your data!
The problem with the frequentist approach is that we need to specify a reference set
of hypothetical samples that could have been observed, but were not, in order to
compute the P-value of our observed sample. Thus, the decision on whether to reject
the null hypothesis based on the P-value depends on the thoughts of the investigator
about data that might have been observed but were not. Clearly, the theorist and
observer had different thoughts about what was the appropriate reference set and thus
arrived at quite different conclusions. To avoid this problem, experiments must
therefore be carefully planned beforehand (e.g., the stopping rule specified before
the experiment commences) to be amenable to frequentist analysis and if the plan is
altered during execution for any reason (for example, if the experimenter runs out of
funds), the data are worthless and cannot be analyzed.
The fact that P-value hypothesis testing depends on considerations like the inten-
tions of the investigator and unobserved data indicates a potentially serious flaw in the
logic behind the use of P-values. Surely if our plan for an experiment has to be altered
(e.g., astronomical observations cut short due to bad weather), we should still be able
to analyze the resulting data provided we are fully aware of the physical details of the
experiment. Clearly, our state of information has changed. Fortunately in Bayesian
inference, the stopping rule plays no role in the analysis. There is no ambiguity over
which quantity is to be considered a ‘‘random variable,’’ because the notion of a
random variable and consequent need for a reference set of hypothetical data is absent
from the theory. All that is required is a specification of the state of knowledge that
allows us to compute the likelihood function.
7.4.1 Bayesian resolution to optional stopping problem
In the Bayesian approach, where the probability assignments describe the state of
knowledge defined in the problem, such paradoxes disappear. Here, we are interested
in the posterior probability of f, the fraction of all nearby stars that are G stars.
pð f jD; IÞ ¼ pð f jIÞpðDj f; IÞ
pðDjIÞ
:
(7:23)
The Bayesian calculation focuses on the functional dependence of the likelihood on
the hypotheses corresponding to different choices of f. Both the binomial and
negative binomial distributions depend on f in the same way, so Bayesian calcul-
ations by the theorist and the observer lead to the same conclusion, as we now
demonstrate.
7.4 Problem with frequentist hypothesis testing
179

1. Binomial case:
pðDj f; IÞ ¼ pðnGjN; f Þ ¼
N!
ðN  nGÞ!ðnGÞ! f nGð1  f ÞNnG
pðDjIÞ ¼
Z
df pð f jIÞ pðDj f; IÞ
pð f jD; IÞ ¼
pð f jIÞf nGð1  f ÞNnG
R
df pð f jIÞf nGð1  f ÞNnG ;
(7:24)
where the factorial terms cancel out because they appear in both the numerator and
denominator.
2. Negative binomial case:
pðDj f; IÞ ¼ pðNjnG; f Þ ¼
N  1
nG  1


f nGð1  f ÞNnG
pð f jD; IÞ ¼
pð f jIÞ f nGð1  f ÞNnG
R
df pð f jIÞf nGð1  f ÞNnG :
(7:25)
Again the factorial terms cancel out because they appear in both the numerator and
denominator. Equations (7.24) and (7.25) are identical so the conclusions are the
same; theorist and observer agree. Figure 7.4 shows the Bayesian posterior PDF for
the fraction of G stars assuming a uniform prior for pð fjIÞ.
The frequentist calculations, on the other hand, focus on the dependence of the
sampling distribution on the data N and nG. Since the binomial and negative binomial
distributions depend on N and nG in different ways, one would be led to different
conclusions depending on the distribution chosen. Variations of weather and
0
0.05
0.1
0.15
0.2
f (fraction of G stars) 
0
2.5
5
7.5
10
12.5
15
17.5
Probability density
Figure 7.4 Bayesian posterior PDF for the fraction of G stars.
180
Frequentist hypothesis testing

equipment can affect N and nG but not f, and thus only the Bayesian conclusion is
consistently the same.
In the frequentist hypothesis test, we were attempting to reject the null hypothesis that
the theorist’s prediction ð f ¼ 0:1Þ is correct. Recall that in a Bayesian analysis, we
cannot compute the probability of a single hypothesis in isolation but only in compari-
son to one or more alternative hypotheses. The posterior PDF shown in Figure 7.4
allows us to compare the probability density at f ¼ 0:1 to the probability density at any
other value of f. Assuming a uniform prior, the PDF is a maximum close to f  0:05.
7.5 Problems
1. In Section 7.2.2, we tested the hypothesis that the river sediment toxin concentra-
tions at the two locations are the same. Using the same data, test whether the
variances of the data are the same for the two locations. Should you use a one-sided
or a two-sided hypothesis test in this case? Some choices of Mathematica commands
to use to answer this question are given in the following box:
Needs[‘‘Statistics ‘HypothesisTests’’’]
VarianceRatioTest[data1,data2,ratio,FullReport -< True]
or
VarianceRatioTest[data1,data2,ratio,TwoSided -> True, FullReport ->True]
Note: OneSided -> True, is the default.
Both are based on the FRatioPValue[fratio,numdef,dendef] calculation of Section 6.5.
2. Table 7.5 gives measurements of a certain river sediment toxic substance at two
locations in units of parts per million (ppm). The sampling is assumed to be from
two independent normal populations.
a) Determine the 95% confidence intervals for the means and variances of the two
data sets.
b) At what confidence level (express as a %) can you reject the hypothesis that the
two samples are from populations with the same variance? Explain why you
chose to use a one-sided or two-sided hypothesis test.
c) At what confidence level can you reject the hypothesis that the two samples are
from populations with the same mean? Assume the population variances are
unknown but equal and use a two-sided hypothesis test.
d) At what confidence level can you reject the hypothesis that the two samples are
from populations with the same mean? Assume the population variances are
unknown and unequal, and use a two-sided hypothesis test.
7.5 Problems
181

Tips: The following Mathematica commands may prove useful.
StudentTPValue FRatioPValue VarianceRatioTest MeanDifferenceTest MeanCI
VarianceCI
3. In Example 1 of Section 7.3.1, suppose 41 quasars were detected in a total sample of
90 radio sources. With what confidence could you reject the hypothesis that 70% of
radio sources are quasars?
4. Generate a list of 50 000 random numbers with a uniform distribution in the
interval 0 to 1. Divide this interval into 500 bins of equal size and count the number
Table 7.5 Measurements of the concentration of a river
sediment toxin in ppm at two locations.
Location 1
Location 2
17.1
7.0
11.1
12.0
12.6
6.8
12.1
9.3
5.9
8.9
7.7
9.4
10.5
9.6
15.3
7.6
10.5
10.5
Table 7.6 The distribution of a sample of 100 radiation measurements.
Count Obtained
Number of Occurrences
0
1
1
6
2
18
3
17
4
23
5
10
6
15
7
4
8
4
9
1
10
0
11
0
12
1
182
Frequentist hypothesis testing

of random numbers in each bin (see Mathematica command BinCounts). Use the
Pearson 2 goodness-of-fit test to see if you can reject the hypothesis that the counts
have a uniform distribution at a 95% confidence level.
5. A distribution of background radiation measurements in a radioactively contamin-
ated site are given in Table 7.6 based on a sample of 100 measurements. Use the
Pearson 2 goodness-of-fit test to see if you can reject the hypothesis that the counts
have a Poisson distribution at a 95% confidence level. Include a plot of the data.
7.5 Problems
183

8
Maximum entropy probabilities
8.1 Overview
This chapter can be thought of as an extension of the material covered in Chapter 4
which was concerned with how to encode a given state of knowledge into a probability
distribution suitable for use in Bayes’ theorem. However, sometimes the information
is of a form that does not simply enable us to evaluate a unique probability distribu-
tion pðYjI Þ. For example, suppose our prior information expresses the following
constraint:
I  ‘‘the mean value of cos y ¼ 0:6.’’
This information alone does not determine a unique pðYjI Þ, but we can use I to test
whether any proposed probability distribution is acceptable. For this reason, we call
this type of constraint information testable information. In contrast, consider the
following prior information:
I1  ‘‘the mean value of cos y is probably > 0:6.’’
This latter information, although clearly relevant to inference about Y, is too vague to
be testable because of the qualifier ‘‘probably.’’
Jaynes (1957) demonstrated how to combine testable information with Claude
Shannon’s entropy measure of the uncertainty of a probability distribution to arrive
at a unique probability distribution. This principle has become known as the max-
imum entropy principle or simply MaxEnt.
We will first investigate how to measure the uncertainty of a probability distribution
and then find how it is related to the entropy of the distribution. We will then examine
three simple constraint problems and derive their corresponding probability distribu-
tions. In the course of this examination, we gain further insight into the special
properties of a Gaussian distribution. We also explore the application of MaxEnt to
situations where the constraints are uncertain and consider an application to image
184

restoration/reconstruction.1 The last section deals with a promising Bayesian image
reconstruction/compression technique called the PixonTM method.
8.2 The maximum entropy principle
The major use of Bayes’ theorem is to update the probability of a hypothesis when new
data become available. However, for certain types of constraint information, it is not
always obvious how to use it directly in Bayes’ theorem. This is because the informa-
tion does not easily enable us to evaluate a prior probability distribution or evaluate
the likelihood function.
As an example, consider the following problem involving a six-sided die: each side
has a unique number of dots on it, ranging in number from one to six. Suppose the
die is thrown a very large number of times and on each throw, the number of dots
appearing on the top face is recorded. The book containing the results of the
individual throws is then unfortunately lost. The only information remaining is
the average number of dots on the repeated throws. Using only this prior informa-
tion, how can we arrive at a unique assignment for the probability that the top face
will have n dots on any one throw (i.e., we want to obtain a prior probability for each
side of the die)?
Principle: Out of all the possible probability distributions which agree with the given
constraint information, select the one that is maximally non-committal with regard
to missing information.
Question: How do we accomplish the goal of being maximally non-committal about
missing information?
Answer: The greater the missing information, the more uncertain the estimate.
Therefore, make estimates that maximize the uncertainty in the probability dis-
tribution, while still being maximally constrained by the given information.
What is uncertainty and how do we measure it?
Jaynes argued that the best measure of uncertainty to maximize is the entropy of the
probability distribution, an idea which was first introduced by Claude Shannon in his
pioneering work on information theory.
We start by developing our intuition about uncertainty:
Example 1:
Consider an experiment with only two possible outcomes. For which of the three
probability distributions listed below is the outcome most uncertain?
1 Image restoration, the recovery of images from image-like data, usually means removing the effects of
point-spread-function blurring and noise. Image reconstruction means the construction of images from more
complexly encoded data (e.g., magnetic resonance imaging data or from the Fourier data measured in radio
astronomy aperture synthesis). In the remainder of the chapter, we will use the term image reconstruction to refer to
both.
8.2 The maximum entropy principle
185

(1) p1 ¼ p2 ¼ 1
2
 The outcome here most uncertain
(2) p1 ¼ 1
4 ; p2 ¼ 3
4
(3) p1 ¼
1
100 ; p2 ¼ 99
100
Example 2:
Consider an experiment with different numbers of outcomes
(1) p1 ¼ p2 ¼ 1
2
(2) p1 ¼ p2 ¼ p3 ¼ p4 ¼ 1
4
(3) p1 ¼ p2 ¼    ¼ p8 ¼ 1
8
 Most uncertain
i.e., If there are n equally probable outcomes, the uncertainty / n.
8.3 Shannon’s theorem
In 1948, Claude Shannon published a landmark paper on information theory in which
he developed a measure of the uncertainty of a probability distribution which he
labeled ‘entropy.’ He demonstrated that the expression for entropy has a meaning
quite independent of thermodynamics. Shannon showed that the uncertainty,
Sðp1; p2; . . . ; pnÞ, of a discrete probability distribution pi is given by the entropy of
the distribution, which is
Sð p1; p2; . . . ; pnÞ ¼ 
X
n
i¼1
pi lnð piÞ ¼ entropy:
(8:1)
The theorem is based on the following assumptions:
(1) Some real numbered measure of the uncertainty of the probability distribution
ð p1; p2; . . . ; pnÞ exists, which we designate by
Sð p1; p2; . . . ; pnÞ:
(2) S is a continuous function of the pi. Otherwise an arbitrary small change in the probability
distribution could lead to the same big change in the amount of uncertainty as a big change
in the probability distribution.
(3) Sð p1; p2; . . . ; pnÞ should correspond to common sense in that when there are many possibil-
ities, we are more uncertain than when there are few. This condition implies that in the case
where the pi are all equal (i.e., pi ¼ 1=n),
S 1
n ; . . . ; 1
n


¼ nf 1
n
 
shall be a monotonic increasing function of n:
(4) Sð p1; p2; . . . ; pnÞ is a consistent measure. If there is more than one way of working out its
value, we must get the same answer for every possible way.
186
Maximum entropy probabilities

8.4 Alternative justification of MaxEnt
Here, we consider how we might go about assigning a probability distribution for the
sides of a weighted die given only constraint information about the die. Let pi ¼ the
probability of the ith side occurring in any toss where i ¼ number of dots on that side.
We now impose the constraint that
mean number of dots ¼
X
6
i¼1
i pðiÞ ¼ 4:
(8:2)
Note: the mean value for a fair die is 3.5. Our job is to come up with a unique set of pi
values consistent with this constraint.
As a start, let’s consider what we can infer about the probabilities of the six sides
from prior information consisting of the mean number of dots from ten throws of the
die. Suppose I  ‘‘in ten tosses of a die, the mean number of dots was four.’’ We will
solve this problem and then consider what happens as the number of tosses becomes
very large.
For a finite number of tosses, there are a finite number of possible outcomes. Let
h1 ! hn be the set of hypotheses representing these different outcomes. Some example
outcomes are given in Table 8.1. Which hypothesis is the most probable?
In the die problem just discussed, we can use our information to reject all hypoth-
eses which predict a mean 6¼ 4. This still leaves us a large number of possible
hypotheses.
Our intuition tells us that in the absence of any additional information, certain
hypotheses are more likely than others (e.g., h1 is less likely than h2 or h4). Let’s try and
refine our intuition.
If we knew the individual pi’s, we could calculate the probability of each hi. It is
given by the multinomial distribution
Table 8.1 Some hypotheses about the possible outcomes of tossing a die ten times.
# of dots
h1
h2
h3
h4
  
hn
1
0/10
1/10
1/10
1/10
2/10
2
0/10
1/10
2/10
1/10
1/10
3
0/10
1/10
2/10
1/10
3/10
4
10/10
1/10
2/10
2/10
2/10
5
0/10
6/10
2/10
4/10
1/10
6
0/10
0/10
1/10
1/10
1/10
mean
4.0
4.0
3.5
4.0
  
3.2
8.4 Alternative justification of MaxEnt
187

pðn1; n2; . . . ; n6jN; p1; p2; . . . ; p6Þ ¼
N!
n1!n2! . . . n6!
|ﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄ}
W
pn1
1  pn2
2      pn6
6
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
P
8
>
>
>
<
>
>
>
:
(8:3)
where N ¼ ini ¼ the total number of throws of the die. W is the number of different
ways that hi can occur in N trials, usually called the multiplicity. P is the probability of
any particular realization of hypothesis hi.
Without knowing the pi’s we have no way of computing the P term.2 In what
follows, we will ignore this term and investigate the consequences of the W term alone.
Let’s evaluate the multiplicity, W, for h1 and h4.
Wh1 ¼
10!
0!0!0!10!0!0! ¼ 1;
Wh4 ¼
10!
1!1!1!2!4!1! ¼ 75 600:
It is obvious that h1 can only occur in one way, but to our surprise we find that h4
can occur in 75 600 different ways. In the absence of additional information, if we were
to carry out a large number of repeats of ten tosses, we would expect h4 to occur 75 600
times more often than h1. Thus, amongst the hypotheses that satisfy our constraint,
the one with the largest multiplicity is the one we would consider most probable. Call
this outcome Wmax.
From Wmax we can derive the frequency of occurrence of any particular side of the
die and use this as an estimate of the probability of that side. A problem arises because
for a small number of throws like ten, the frequency determined for one or more sides
might be zero. To set the probability of these sides to zero would be unwarranted since
what it really means is that pi < 1=10.
The general concept of using the multiplicity to select from the hi satisfying the
constraint is good, but we need to refine it further. Suppose we were to use the average
of the ten throws as the best estimate of the average of a much larger number of throws
N  10. For a much larger N, there would be a correspondingly larger number of
hypotheses about probability distributions which could satisfy the average constraint.
In this case, the smallest increment in pi will be 1=N instead of 1/10. The one with the
largest multiplicity (Wmax) will be a smoother version of what we got earlier with only
ten throws, and if N is large enough, it will be very unlikely for any of the pi to be exactly
zero, unless of course the average was either one or six dots.
We like the smoother version of the probability distribution that comes about from
using a larger value of N; however, this gives rise to a new difficulty. We will see in
Equation (8.7) that as N increases, Wmax increases at such a rate that there are
2 Clearly, if the mean number of dots is significantly different from 3.5, the value for a fair die, then the constraint
information is telling us that some sides are more probable than others. A challenge for the future is to see how this
information can be used to constrain the P term.
188
Maximum entropy probabilities

(essentially) infinitely more ways Wmax can be realized than other not-too-different
probability distributions. Since we started with an average constraint pertaining to only
ten throws, this degree of discrimination against acceptable competing hi is unwar-
ranted. Happily, if we use Stirling’s approximation for ln N!, we can factor ln W into two
terms as we now show. Stirling’s approximation for large N is
ln N! ¼ N ln N  N:
(8:4)
Writing ni ¼ Npi, the multiplicity becomes
ln W ¼ N ln N  N 
X6
i ¼ 1 Npi ln Npi þ
X6
i¼1 Npi
¼ N ln N  N 
X
Npi lnðNpiÞ þ
X
Npi
¼ N ln N  N  N
X
pi ln pi þ ln N


þ N
¼ N
X6
i ¼ 1 pi ln pi
ln W ¼ N
X
6
i¼1
pi ln pi ¼ N  entropy ¼ NS;
(8:5)
where
S ¼ 
X
6
i¼1
pi ln pi:
(8:6)
Equation (8.5) factors ln W into two terms: the number of throws, N, and the
entropy term, which depends only on the desired pi’s. Maximizing entropy achieves
the desired smooth probability distribution.
Since the multiplicity W ¼ expðNSÞ, it follows that
Wmax
W
¼ exp½NðSmax  SÞ ¼ expðNSÞ;
(8:7)
where Wmax is the multiplicity of the probability distribution with maximum entropy,
Smax, and W is the multiplicity of a distribution with entropy S. The actual relative
probabilities of two different probability distributions is proportional to the ratio of
their multiplicities or / expðN  entropyÞ. Clearly, the degree of discrimination
depends strongly on N. For N large, Equation (8.7) tells us that there are (essentially)
infinitely more ways the outcome corresponding to maximum entropy (MaxEnt) can
be realized than any outcome having a lower entropy.
Jaynes (1982) showed that the quantity 2NS has a 2 distribution with M  k  1
degrees of freedom, where M is the number of possible outcomes and k is the number
of constraints. In our problem of the die, M ¼ 6 and k ¼ 1. This allows us to compute
explicitly the range of S about Smax corresponding to any confidence level.
8.4 Alternative justification of MaxEnt
189

8.5 Generalizing MaxEnt
8.5.1 Incorporating a prior
In Equation (8.3), we argued that without knowing the pi’s we have no way of comput-
ing term P. Using the principle of indifference, we assigned the same value for P for each
of the acceptable hypotheses and concluded that the relative probability of acceptable
hypotheses is proportional to the multiplicity term. In the present generalization, we
allow for the possibility of prior information about the fpig. For example, suppose that
the index i enumerates the individual pixels in an image of a very faint galaxy taken with
the Hubble Space Telescope. Our constraint information in this case is the set of
measured image pixel values. However, because of noise, these constraints are uncer-
tain. In Section 8.8.2 we will learn how to make use of MaxEnt with uncertain
constraints. In general, to find the MaxEnt image requires an iterative procedure
which starts from an assumed prior image which is often taken to be flat, i.e., all pi
equal. However, if we already have another lower resolution image of the same galaxy
taken with a ground-based telescope, then this would be a better prior image to start
from. In this way, we can have a prior estimate of the pi values in Equation (8.3).
For the moment we will return to the case where our constraints are certain and we
will let fmig be our prior estimate of fpig. For example, maybe we know that two sides
of the die have two dots and that the other four sides have 3, 4, 5, and 6 dots, respectively.
Substituting into Equation (8.3), and generalizing the discussion to a discrete probability
distribution where i varies from 1 to M (instead of i ¼ 1 to 6 for the die), we obtain
pðn1; n2; . . . ; nMjN; p1; p2; . . . ; pMÞ ¼
N!
n1! n2! . . . nM! mn1
1  mn2
2      mnM
M :
(8:8)
Taking the natural logarithm of both sides yields
ln½ pðn1; n2; . . . ; nMjN; p1; p2; . . . ; pMÞ ¼
X
M
i¼1
ni ln½mi þ ln½N! 
X
M
i¼1
ln½ni!
¼
X
M
i¼1
ni ln½mi  N
X
M
i¼1
pi ln½ pi
(8:9)
where we have used Stirling’s approximation (Equation (8.4)) in the last line.
Substituting for ni ¼ Npi, we obtain
1
N ln½ pðn1; n2; . . . ; nMjN; p1; p2; . . . ; pMÞ ¼
X
M
i¼1
pi ln½mi 
X
M
i¼1
pi ln½ pi
¼ 
X
M
i¼1
pi ln½ pi=mi ¼ S:
(8:10)
This generalized entropy is known by various names including the Shannon–Jaynes
entropy and the Kullback entropy. It is also sometimes written with the opposite sign
(so it has to be minimized) and referred to as the cross-entropy.
190
Maximum entropy probabilities

8.5.2 Continuous probability distributions
The correct measure of uncertainty in the continuous case (Jaynes, 1968; Shore and
Johnson, 1980) is:
Sc ¼ 
Z
pðyÞ ln pðyÞ
mðyÞ


dy:
(8:11)
The quantity mðyÞ, called the Lebesgue measure (Sivia, 1996), ensures that the entropy
expression is invariant under a change of variables, y ! y0 ¼ f ðyÞ, because both pðyÞ
and mðyÞ transform in the same way. Essentially, the measure takes into account how
the (uniform) bin-widths in y-space translate to a corresponding set of (variable) bin-
widths in the alternative y0-space. If mðyÞ is a constant, this equation reduces to
Sc ¼ 
Z
pðyÞ ln pðyÞdy þ ln mðyÞ
Z
pðyÞdy
¼ 
Z
pðyÞ ln pðyÞdy þ constant:
(8:12)
To find the maximum entropy solution, we are interested in derivatives of Equation
(8.12), and for this, a constant prior has no effect.
8.6 How to apply the MaxEnt principle
In this section, we will demonstrate how to use the MaxEnt principle to encode some
testable information into a probability distribution. We will need to use the Lagrange
multipliers of variational calculus in which MaxEnt plays the role of a variational
principle,3 so we first briefly review that topic.
8.6.1 Lagrange multipliers of variational calculus
Suppose there are M distinct possibilities fyig to be considered where i ¼ 1 to M.
We want to compute pðyijIÞ (abbreviated by pi) subject to a testable constraint.
If S represents the entropy of pðyijIÞ, then the condition for maximum entropy is
given by
dS ¼ @S
@p1
dp1 þ    þ @S
@pM
dpM ¼ 0:
Without employing a constraint, the dpi’s are independent and the only solution is if
all the coefficients are individually equal to 0. Suppose we are given the constraint
3 One desirable feature of a variational principle is that it does not introduce correlations between the pi values unless
information about these correlations is contained in the constraints. In Section 8.8.1, we show that the MaxEnt
variational principle satisfies this condition.
8.6 How to apply the MaxEnt principle
191

P p2
i ¼ R, where R is a constant. Rewrite the constraint4 as C ¼ P p2
i  R ¼ 0. With
this constraint, any permissible dpi’s must satisfy
dC ¼ 0 ¼ @C
@p1
dp1 þ    þ @C
@pM
dpM
¼ 2p1dp1 þ    þ 2pMdpM:
(8:13)
We can combine dS and dC in the form
dS  dC ¼ 0;
(8:14)
where  is an undetermined multiplier.
@S
@p1
 2p1


dp1 þ    þ
@S
@pM
 2pM


dpM ¼ 0:
Now if  is chosen so ð@S=@p1  2p1Þ ¼ 0, then the equation reduces to
@S
@p2
 2p2


dp2 þ    þ
@S
@pM
 2pM


dpM ¼ 0:
(8:15)
But the remaining M  1 variables dpi can be considered independent so their coeffi-
cients must also equal zero to satisfy Equation (8.15). This yields a set of M equations
which can be solved for the fpig. It can be shown that this procedure does lead to a
global maximum in S (e.g., Tribus, 1969).
8.7 MaxEnt distributions
Before deriving MaxEnt probability distributions for some common forms of testable
information, we first examine some general properties of MaxEnt distributions.
8.7.1 General properties
Suppose we are given the following constraints:
XM
i ¼ 1 pi ¼ 1
XM
i ¼ 1 f1ðyiÞpi ¼ h f1i ¼ f1
...
XM
i ¼ 1 frðyiÞpi ¼ h fri ¼ fr
where M is the number of discrete probabilities. For example, suppose we have the
constraint information hcosðyÞi ¼ f1. In this case, f1ðyiÞ ¼ cosðyiÞ. Equation (8.14)
can be written with the help of Equation (8.10) as
4 In principle, R might be a f ðp1; . . . ; pMÞ and thus lead to a term in the differential.
192
Maximum entropy probabilities

d 
X
M
i ¼ 1
pi ln pi þ
X
M
i ¼ 1
pi ln mi  
X
M
i ¼ 1
pi  1
 
!
 1
X
M
i ¼ 1
f1ðyiÞpi  f1
 
!

"
    r
X
M
i ¼ 1
frðyiÞpi  fr
 
!#
¼ 0:
(8:16)
Assuming mi is a constant, then PM
i ¼ 1 pi ln mi ¼ ln mi
PM
i ¼ 1 pi ¼ ln mi and d ln mi ¼ 0.
In this case, the above equation simplifies to
X
M
i¼1
 ln pi  pi
@ ln pi
@pi
   1 f1ðyiÞ      r frðyiÞ


dpi
¼
X
M
i¼1
 ln pi  ð1 þ Þ  1 f1ðyiÞ      r frðyiÞ
½
dpi ¼ 0:
(8:17)
For each i, we can solve for pi.
pi ¼ exp½ð1 þ Þ exp½1 f1ðyiÞ      rfrðyiÞ
¼ exp½0 exp 
X
r
j¼1
j fjðyiÞ
"
#
;
(8:18)
where 0 ¼ 1 þ . Using the first constraint, we obtain
X
M
i¼1
pi ¼ exp½0
X
M
i¼1
exp 
X
r
j¼1
j fjðyiÞ
"
#
¼ 1;
(8:19)
which can be rewritten as
exp½þ0 ¼
X
M
i ¼ 1
exp 
X
r
j¼1
j fjðyiÞ
"
#
:
(8:20)
Now differentiate Equation (8.20) with respect to k, and multiply through by
 exp½0 to obtain
 @0
@k
¼
X
M
i¼1
exp½0 exp 
X
r
j¼1
j fjðyiÞ
"
#
fkðyiÞ
¼
X
M
i¼1
pi fkðyiÞ ¼ h fki:
(8:21)
This leads to the following useful result, that we make use of in Section 8.7.4.
 @0
@k
¼ h fki ¼ fk:
(8:22)
8.7 MaxEnt distributions
193

From Equation (5.4), we can write the variance of fk as
Varð fkÞ¼h f 2
k iðh fkiÞ2:
(8:23)
We obtain h f 2
k i from a second derivative of Equation (8.21). Substituting that into
Equation (8.23) yields
Varð fkÞ ¼ @20
@2
k

@0
@k

2
:
(8:24)
8.7.2 Uniform distribution
Suppose the only known constraint is the minimal constraint possible for a probability
distribution PM
i ¼ 1 pi ¼ 1. Following Equation (8.14), we can write
d 
X
M
i ¼ 1
pi ln½ pi=mi
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
entropy

X
M
i ¼ 1
pi  1
 
!
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
constraint
2
66664
3
77775
¼ 0
d 
X
M
i ¼ 1
pi ln pi þ
X
M
i ¼ 1
pi ln mi  
X
M
i ¼ 1
pi  1
 
!
"
#
¼ 0
(8:25)
X
M
i ¼ 1
 ln pi  pi
@ ln pi
@pi
þ ln mi   @pi
@pi


dpi ¼ 0
X
M
i ¼ 1
ð ln½ pi=mi  1  Þdpi ¼ 0:
The addition of the Lagrange undetermined multiplier makes
ð ln½ pi=mi  1   ¼ 0Þ
for one pi and the remaining ðM  1Þ of the dpi’s independent. So for all pi, we require
 ln½ pi=mi  1   ¼ 0;
(8:26)
or,
pi ¼ mieð1þÞ:
(8:27)
Since P pi ¼ 1,
X
M
i¼1
mi eð1þÞ ¼ 1 ¼ eð1þÞ X
M
i¼1
mi:
(8:28)
Since PM
i ¼ 1 mi ¼ 1, then  ¼ 1 and thus
pi ¼ mi:
(8:29)
194
Maximum entropy probabilities

Suppose our prior information leads us to assume mi ¼ a constant ¼ 1=M. Then pi
describesauniformdistribution.Inthecontinuumlimit,wewouldwriteEquation(8.29)as
pðyjIÞ ¼ mðyÞ:
(8:30)
Thus, for mðyÞ ¼ a constant and the minimal constraint,
R
pðyÞ ¼ 1, the uniform
distribution has maximum entropy.
8.7.3 Exponential distribution
In this case, we assume an additional constraint that the average value of yi is known
and equal to , so we have two constraints.
(1) PM
i pi ¼ 1 (constraint 1)
(2) PM
i yipi ¼  (constraint 2: known mean)
For example, in the die problem of Section 8.4, we could be told the average number of
dots on a very large number of throws of the die but not be given the results of the
individual throws. In this case, we use two Lagrange multipliers,  and 1. Following
Equation (8.14), we can write
d 
X
M
i¼1
pi ln½pi=mi
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
entropy

X
M
i¼1
pi  1
 
!
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
constraint 1
1
X
M
i¼1
yipi  
 
!
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
constraint 2
2
66664
3
77775
¼ 0
(8:31)
X
M
i¼1
 ln½pi=mi  pi
@ ln pi
@pi
  @pi
@pi
 yi1
@pi
@pi


dpi ¼ 0
X
M
i¼1
ð ln½pi=mi  1    yi1Þdpi ¼ 0:
(8:32)
Again,
the
addition
of
the
Lagrange
undetermined
multipliers
makes
ð ln½ pi=mi  1    yi 1 ¼ 0Þ for one pi and the remaining ðM  1Þ of the dpi’s
independent. So for all pi, we require
 ln½ pi=mi  1    yi1 ¼ 0;
(8:33)
or,
pi ¼ mi eð1þÞe1yi:
(8:34)
We can now apply our two constraints to determine the Lagrange multipliers.
X
M
i¼1
pi ¼ 1 ¼ eð1þÞ X
M
i¼1
mi e1yi:
(8:35)
8.7 MaxEnt distributions
195

Therefore
eð1þÞ ¼
1
PM
i ¼ 1 mie1yi :
(8:36)
From the second constraint, we have
X
M
i ¼ 1
yipi ¼  ¼
PM
i ¼ 1 yimie1yi
PM
i ¼ 1 mie1yi ;
(8:37)
or
X
M
i ¼ 1
yimie1yi  
X
M
i ¼ 1
mie1yi ¼ 0:
(8:38)
For any particular value of , the above equation can be solved numerically for 1. If we
set mi ¼ 1=6 and yi ¼ i, then Equation (8.38) can be used to solve for the probability of
thesixsidesofthedieproblemdiscussedinSection8.4.Weillustratethiswiththefollowing
Mathematica commands assuming  ¼ 2:2 and the result is shown in Figure 8.1.
Box 8.1
Mathematica commands: MaxExt die problem
First, we define the function q[m] for an arbitrary value of m:
q[m]: =
X6
i¼1 i Exp[  i l1]  m
X6
i ¼ 1 Exp[  i l1];
The next line solves for l1 with m ¼ 2:2:
sol = Solve[q[2:2]==0; l1]
For each m; l1 has multiple complex solutions and one real solution l1real.
Pick out the real solution using Cases.
l1real=Cases[l1=:sol, Real][[1]]
Next, evaluate the expression for the probability of the ith side, probi
probi=
Exp[  i l1real]
P6
j ¼ 1 Exp[  j l1real]
Finally create a table of the probabilities of the 6 sides.
prob=Table[{i, probi}, {i, 6}]
ff1; 0:421273g; f2; 0:251917g; f3; 0:150644g;
f4; 0:0900838g; f5; 0:0538692g; f6; 0:0322133gg
196
Maximum entropy probabilities

We can simply generalize Equation (8.34) for pi to the continuous case pðyjIÞ:
pðyjIÞ ¼ mðyÞeð1þÞe1y:
(8:39)
If we assume mðyÞ is a constant, then we have
pðyjIÞ / e1y:
(8:40)
The normalization and 1 can easily be evaluated if the limits of integration extend
from 0 to 1. The result is
pðyjÞ ¼ 1
 ey=
for y  0:
(8:41)
8.7.4 Normal and truncated Gaussian distributions
In this section, we assume mðyÞ, the prior for pðyÞ, has the following form:
mðyÞ ¼
1=ðyH  yLÞ;
if yL  y  yH
0;
if yL > y or y > yH.

(8:42)
In this case, we assume an additional constraint that the variance of y is equal to 2.
The two constraints in this case are:
(1)
R yH
yL pðyÞdy ¼ 1
(2)
R yH
yL ðy  Þ2pðyÞdy ¼ 2
Because mðyÞ is a constant, we solve for pðyÞ which maximizes

Z
pðyÞ ln pðyÞdy
1
2
3
4
5
6
Number of dots
0.1
0.2
0.3
0.4
Probability
Mean number of dots = 2.2
Figure 8.1 The figure shows the probability of the six sides of a die given the constraint that the
average number of dots  ¼ 2:2.
8.7 MaxEnt distributions
197

subject to the constraints 1 and 2. This optimization is best done as the limiting case of
a discrete problem; explicitly, we need to find the solution to
d

X
M
i ¼ 1
pi ln pi  
X
M
i ¼ 1
pi  1
"
#
 1
X
M
i ¼ 1
ðyi  Þ2pi  2
"
#
(
)
¼ 0;
(8:43)
where M is the number of discrete probabilities. This leads to
X
M
i ¼ 1
½ ln pi  1    1ðyi  Þ2dpi ¼ 0:
(8:44)
For each value of i, we require
 ln pi  1    1ðyi  Þ2 ¼ 0;
(8:45)
or,
pi ¼ eð1þÞe1ðyiÞ2
¼ e0e1ðyiÞ2;
(8:46)
where 0 ¼ 1 þ . This generalizes to the continuum assignment
pðyÞ ¼ e0e1ðyÞ2:
(8:47)
We can solve for 1 and 0 from our two constraints. From the first constraint,
Z yH
yL
pðyÞdy ¼ 1 ¼ e0
Z yH
yL
e1ðyÞ2dy:
(8:48)
Compare this equation to the equation for the error function5 erfðzÞ (see Equation
(5.39)) given by
erfðzÞ ¼ 2ﬃﬃﬃp
p
Z z
0
expðu2Þ du:
(8:49)
The solution for 0 in Equation (8.48), in terms of the error function, is
0 ¼ ln
ﬃﬃﬃp
p
2
ﬃﬃﬃﬃﬃ
1
p


þ ln erf
ﬃﬃﬃﬃﬃ
1
p
ðyH  Þ
n
o
 erf
ﬃﬃﬃﬃﬃ
1
p
ðyL  Þ
n
o
h
i
:
(8:50)
We will consider two cases which depend on the limits of integration ðyL; yHÞ.
Case I (Normal Gaussian)
Suppose the limits of integration satisfy the condition6
ﬃﬃﬃﬃﬃ
1
p
ðyH  Þ  1 and
ﬃﬃﬃﬃﬃ
1
p
ðyL  Þ 	 1:
(8:51)
5 The error function has the following properties: erfð1Þ ¼ 1; erfð1Þ ¼ 1 and erfðzÞ ¼ erfðzÞ.
6 Note: erfð1Þ ¼ 0:843, erfð
ﬃﬃﬃ
2
p
Þ ¼ 0:955, erfð2Þ ¼ 0:995, and erfð3Þ ¼ 0:999978.
198
Maximum entropy probabilities

In this case,
erf
ﬃﬃﬃﬃﬃ
1
p
ðyH  Þ
n
o

 1 and erf
ﬃﬃﬃﬃﬃ
1
p
ðyL  Þ
n
o

 1;
and Equation (8.50) simplifies to
0 
 ln
ﬃﬃﬃp
p
2
ﬃﬃﬃﬃﬃ
1
p


þ ln½2 ¼ ln
ﬃﬃﬃﬃﬃp
1
r


:
(8:52)
We now make use of Equation (8.22) to obtain an equation for 1:
 @0
@1
¼ 
@ ln
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
p=1
p
h
i
@1
¼ 1
21
¼ 2:
(8:53)
Combining Equations (8.53) and (8.52), we obtain
1 ¼ 1
22 ;
e0 ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p

:
The result,
pðyÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2p
p

eðyÞ2=22;
(8:54)
is a Gaussian. Thus, for a given 2 and a uniform prior that satisfies Equation (8.51), a
Gaussian distribution has the greatest uncertainty (maximum entropy). Now that we
have evaluated 0 and 1, we can rewrite Equation (8.51) in the more useful form
ðyH  Þ
ﬃﬃﬃ
2
p

 1
and
ð  yLÞ
ﬃﬃﬃ
2
p

 1:
(8:55)
We frequently deal with problems where the qth data value, yq, is described by an
equation of the form
yq ¼ ypq þ eq
)
yq  ypq ¼ eq;
where ypq is the model prediction for the qth data value and eq is an error term. In
Section 4.8.1, we showed that for a deterministic model, Mj, the probability of the
data, pðYqjMj; IÞ, is equal to pðEqjMj; IÞ, the probability of the errors. If we interpret
the  in Equation (8.54) as ypq, the model prediction, then this equation becomes the
MaxEnt sampling distribution for the qth error term in the likelihood function.
This is a very important result. It says that unless we have some additional prior
information which justifies the use of some other sampling distribution, then use a
Gaussian sampling distribution. It makes the fewest assumptions about the informa-
tion you don’t have and will lead to the most conservative estimates (i.e., greater
uncertainty than you would get from choosing a more appropriate distribution based
on more information).
In a situation where we do not know the appropriate sampling distribution, we will
also, in general, not know the actual variance (2) of the distribution. In that case, we
8.7 MaxEnt distributions
199

can treat the  of the Gaussian sampling distribution as an unknown nuisance
parameter with a range specified by our prior information. The one restriction to
this argument is that the prior upper bound on  must satisfy Equation (8.55). If
possible data values, represented by the variable y, are unrestricted, then this condi-
tion simply requires that the upper bound on  be finite. In some experiments, the
range of possible data values is limited, e.g., positive values only. In that case, the
MaxEnt distribution may become a truncated Gaussian, as discussed in Case II below.
We now consider a simple example that exploits a MaxEnt Gaussian sampling
distribution with unknown . We will make considerable use of this approach in
later chapters starting with Section 9.2.3.
Example:
Suppose we want to estimate the location of the start of a stratum in a core sample
taken by a Martian rover. The rover transmits a low resolution scan, which allows the
experimenter to refine the region of interest for analysis by a higher resolution
instrument aboard the rover. Unfortunately, the rover made a rough landing and
ceases operation after only two high resolution measurements have been completed.
In this example, we simulate a sample of two measurements made with the high
resolution instrument for a stratum starting position of 20 units along the core sample.
For the simulation, we assume a bimodal distribution of measurement errors as shown
in panel (a) of Figure 8.2. We further suppose that the distribution of measurement
errors is unknown by the scientist, named Jean, who will perform the analysis.
Jean needs to choose a sampling distribution for use in evaluating the likelihood
function in a Bayesian analysis of the high resolution core sample. In the absence of
additional information, she picks a Gaussian sampling distribution, because from the
above argument, the Gaussian will lead to the most conservative estimates (i.e.,
greater uncertainty than you would get from choosing a more appropriate distribution
based on more information). Based on the low resolution core sample measurements, she
assumes a uniform prior for the mean location extending from 15 to 25 units. She assumes
a Jeffreys prior for  and estimates a conservative upper limit to  of 4 units. She
estimates the lower limit,  ¼ 0:4 units, by setting it equal to the digital read out accuracy.
To see how well the parameterized Gaussian sampling distribution performs, we
simulated five independent samples, each consisting of two measurements. Panels (b),
(c), (d), (e), and (f) of Figure 8.2 show a comparison of the posterior PDFs for the stratum
start location computed using: (1) the true sampling distribution (solid curve), and (2) a
Gaussian with an unknown  (dotted curve). The actual measurements are indicated by
the arrows in the top of each panel.
It is quite often the case that we don’t know the true likelihood function. In some
cases, we have a sufficient number of repeated measurements (say five or more) that we
can appeal to the CLT (see Section 5.11) and work with the average value, whose
distribution will be closely Gaussian with a  given by Equation (5.50). However, in
200
Maximum entropy probabilities

this example, we had only two measurements. Instead, we appealed to the MaxEnt
principle and used a Gaussian likelihood function, marginalizing over the unknown
variance. From Figure 8.2, it is apparent that the Gaussian likelihood function per-
formed quite well compared to the true bimodal likelihood function. The conservative
nature of the Gaussian assumption is apparent from the much broader tails. Further
details of this type of analysis are given in Section 9.2.3.
Case II (Truncated Gaussian)
When the condition specified by Equation (8.55) is not satisfied, it is still possible to
compute a MaxEnt sampling distribution that we refer to as a truncated Gaussian, but
there is no simple analytic solution for the Lagrange multipliers. The ’s need to be
solved for numerically.7
17
18
19
20
21
22
23
x
0.5
1
1.5
2
2.5
PDF
(e)
17
18
19
20
21
22
23
x
0.5
1
1.5
2
2.5
PDF
(f)
17
18
19
20
21
22
23
x
0.5
1
1.5
2
2.5
PDF
(c)
17
18
19
20
21
22
23
x
0.5
1
1.5
2
2.5
PDF
(d)
–3
–2
–1
0
1
2
3
x
0.1
0.2
0.3
0.4
0.5
0.6
PDF
(a)
17
18
19
20
21
22
23
x
0.5
1
1.5
2
2.5
PDF
(b)
Figure 8.2 Panel (a) shows the bimodal distribution of instrumental measurement errors. Panels
(b), (c), (d), (e), and (f) show a comparison of the posterior PDFs for the stratum start location
derived from five simulated data samples. Each sample consists of the two data points indicated
by the two arrows at the top of each panel. The solid curve shows the result obtained using the
true sampling distribution. The dotted curve shows the result using a Gaussian with unknown .
7 See Tribus (1969) for a more detailed discussion of this case.
8.7 MaxEnt distributions
201

8.7.5 Multivariate Gaussian distribution
The MaxEnt procedure is easily extended to multiple variables by defining the entropy
as a multi-dimensional integral:
S ¼ 
Z
pðYÞ ln½ pðYÞ=mðYÞdY;
(8:56)
where pðYÞ ¼ pðy1; y2; . . . ; yNjIÞ ¼ pðfyigjIÞ and
R
dY ¼
R
  
R
dNy. Suppose the tes-
table information only consists of knowledge of their individual variances,
hðyi  iÞ2i ¼
Z
ðyi  iÞ2pðy1; y2; . . . ; yNÞdNy ¼ ii ¼ 2
i
ði ¼ 1 to NÞ;
(8:57)
and covariances,
hðyi  iÞðyj  jÞi ¼
Z
ðyi  iÞðyj  jÞ pðy1; y2; . . . ; yNÞdNy ¼ ij:
(8:58)
In Appendix E, we show that provided the prior limits on the range of each variable
satisfy the condition given in Equation (8.55), maximizing Equation (8.56), with
uniform measure, yields the general form of a correlated multivariate Gaussian
distribution:
pðYjfi; ijgÞ ¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2
X
ij
ðyi  iÞ½E1ijðyj  jÞ
"
#
;
(8:59)
where
X
ij
¼
X
N
i¼1
X
N
j¼1
;
and
E ¼
11
12
13
  
1N
21
22
23
  
2N





N1
N2
N3
  
NN
0
B
B
@
1
C
C
A:
(8:60)
In most applications that we will encounter, the yi variable will represent possible
values of a datum and be labeled di. Equation (8.59) can then be rewritten as a
likelihood:
pðDjM; IÞ ¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2
X
ij
ðdi  fiÞ½E1ijðdj  fjÞ
"
#
;
(8:61)
where fi is the model prediction for the ith datum.
202
Maximum entropy probabilities

If the variables are all independent, i.e., the covariance terms are all zero, then
Equation (8.61) reduces to
pðDjM; IÞ ¼
Y
N
i ¼ 1
1ﬃﬃﬃﬃﬃﬃ
2p
p
i
exp
 ðdi  fiÞ2
22
i
(
)
¼
Y
N
i ¼ 1
1ﬃﬃﬃﬃﬃﬃ
2p
p
i
 
!
exp

X
R
r ¼ 1
ðdi  fiÞ2
22
i
(
)
:
(8:62)
In Chapter 10, we discuss the concepts of covariance and correlation in more detail
and make use of a multivariate Gaussian in least-squares analysis.
8.8 MaxEnt image reconstruction
It is convenient to think of a probability distribution as a special case of a PAD
(positive, additive distribution). Another example of a PAD is the intensity or power,
fðx; yÞ, of incoherent light as a function of position ðx; yÞ, in an optical image. This is
positive and additive because the integral
RR
fðx; yÞdxdy represents the signal energy
recorded by the image. By contrast, the amplitude of incoherent light, though positive,
is not additive. A probability distribution is a PAD which is normalized so
Z þ1
1
pðYÞdY ¼ 1:
Question: What form of entropy expression should we maximize in image reconstruc-
tion to best represent the PAD fðx; yÞ values?
Answer: Derived by Skilling (1989).
Sð f; mÞ ¼ 
Z
dy fðx; yÞ  mðx; yÞ  fðx; yÞ ln
fðx; yÞ
mðx; yÞ




;
where mðx; yÞ is the prior estimate of fðx; yÞ. If fðx; yÞ and mðx; yÞ are normalized, this
reduces to the simpler form:

Z Z
fðx; yÞ ln fðx; yÞ
mðx; yÞ


dxdy:
8.8.1 The kangaroo justification
The following simple argument (Gull and Skilling, 1984) gives additional insight into
the use of entropy for a PAD. Imagine that we are given the following information:
a) One third of kangaroos have blue eyes.
b) One third of kangaroos are left-handed.
8.8 MaxEnt image reconstruction
203

How can we estimate the proportion of kangaroos that are both blue-eyed (BE) and
left-handed (LH) using only the above information? The joint proportions of LH and
BE can be represented by a 2  2 probability table which is shown in Table 8.2(a). The
probabilities p1; p2; p3 and p4 must satisfy the given constraints:
a) p1 þ p2 ¼ 1
3 (1/3 of kangaroos have blue eyes)
b) p1 þ p3 ¼ 1
3 (1/3 of kangaroos are left-handed)
c) p1 þ p2 þ p3 þ p4 ¼ 1.
Feasible solutions have one remaining degree of freedom which we parameterize by
the variable z. Table 8.2(b) shows the parameterized joint probability table. The
parameter z is constrained by the above three constraints to 0  z  1
3. Below we
consider three feasible solutions:
1. The first corresponds to the independent case
pðBE; LHÞ ¼ pðBEÞpðLHÞ ¼
1
3
  1
3
 
¼ 1
9
z ¼ 1
9
which leads to the contingency table shown in Figure 8.3(a).
2. Case of maximum positive correlation.
pðBE; LHÞ ¼ pðBEÞpðLHjBEÞ ¼
1
3
 
ð1Þ ¼ 1
3
z ¼ 1
3 :
3. Case of maximum negative correlation.
pðBE; LHÞ ¼ pðBEÞpðLHjBEÞ ¼
1
3
 
ð0Þ ¼ 0
z ¼ 0:
Blue eyes
Left-Handed
True
False
True
False
p1
p3
p2
p4
(a)
Blue eyes
Left-Handed
True
False
0 ≤ z ≤
      – z
1
3
1
3
True
False
– z
+ z
1
3
1
3
(b)
Table 8.2 Panel (a) is the joint probability table for the kangaroo problem. In
panel (b), the table is parameterized in terms of the remaining one degree of
freedom represented by the variable z
204
Maximum entropy probabilities

Suppose we must choose one answer – which is the best?
The answer we select cannot be thought of as being any more likely than any other
choice, because there may be some degree of genetic correlation between eye color and
handedness. However, it is nonsensical to select either positive or negative correlations
without having any relevant prior information. Therefore, based on the available
information, the independent choice p1 ¼ pðBE; LHÞ ¼ 1=9 is preferred.
Question: Is there some function of the pi which, when maximized subject to the
known constraints, yields the same preferred solution? If so, then it would be a good
candidate for a general variational principle which could be used in situations that
were too complicated for our common sense. Skilling (1988) showed that the only
functions with the desired property, pðBE; LHÞ ¼ 1=9, are those related mono-
tonically to the entropy:
S ¼ 
X
4
i¼1
pi ln pi
¼ z ln z  2 1
3  z


ln 1
3  z



1
3 þ z


ln 1
3 þ z


:
Three proposed alternatives are listed in Table 8.3. Only one of the four ( P pi ln pi)
gives the preferred uncorrelated result.
Left-Handed
Left-Handed
Left-Handed
True
False
True
False
True
False
Blue
True
1
9
2
9
Blue
True
1
3
0
Blue
True
0
1
3
Eyes
False
2
9
4
9
Eyes
False
0 
2
3
Eyes
False
1
3
1
3
(a) Independent
(b) Positive correlation
(c) Negative correlation
Figure 8.3 The three panels give the joint probabilities for (a) the independent case,
(b) maximum positive correlation, and (c) maximum negative correlation.
Table 8.3 Solutions to the kangaroo problem obtained by maximizing four different
functions, subject to the constraints.
Variation Function
Optimal z
Implied Correlation
 P pi ln pi
1=9 ¼ 0:1111
uncorrelated
 P p2
i
1=12 ¼ 0:0833
negative
P ln pi
0:1303
positive
P p1=2
i
0:1218
positive
8.8 MaxEnt image reconstruction
205

But what have kangaroos got to do with image restoration/reconstruction?
Consider the following restatement of the problem.
a) One third of the flux comes from the top half of the image.
b) One third of the flux comes from the left half of the image.
What proportion of the flux comes from the top left quarter? All the advertised
functionals except ( P pi ln pi) imply either a positive or negative correlation in the
distribution of the flux in the four quadrants based on the given information. Thus,
these functionals fail to be consistent with our prior information on even the simplest
non-trivial image problem. Inconsistencies are not expected to disappear just because
practical data are more complicated.
8.8.2 MaxEnt for uncertain constraints
Example:
In image reconstruction, we want the most probable image when the data are incom-
plete and noisy. In this example,
B  ‘‘proposition representing prior information’’
Ii  ‘‘proposition representing a particular image.’’
Apply Bayes’ theorem:
pðIijD; BÞ / pðIijBÞpðDjIi; BÞ:
(8:63)
Suppose the image consists of M pixels ð j ¼ 1 ! MÞ
Let dj ¼ measured value for pixel j
Iij ¼ predicted value for pixel j based on image hypothesis Ii
ej ¼ dj  Iij ¼ error due to noise which is assumed to be IID Gaussian.
In this situation, the measured dj values are the constraints, which are uncertain
because of noise. Thus,
pðdjjIij; BÞ ¼ pðejjIij; BÞ / exp 
e2
j
22
j
"
#
¼ exp  dj  Iij
2j

2
"
#
(8:64)
and
pðDjIi; BÞ /
Y
m
j ¼ 1
exp  dj  Iij
2j

2
"
#
¼ exp  1
2
X
m
j ¼ 1
dj  Iij
j

2
"
#
¼ exp  2
2


:
(8:65)
206
Maximum entropy probabilities

Determination of p(Ii|B):
Suppose we made trial images, Ii, by taking N quanta and randomly throwing them
into the M image pixels. Then pðIijBÞ is given by a multinomial distribution,
pðIijBÞ ¼
N!
n1! . . . nM!
1
MN ¼ W
MN ;
(8:66)
where W is the multiplicity.
Recall for large N,
ln W ! N
X
j
pj ln pj ¼ N  entropy ¼ NS;
where as N ! 1, pj ! nj=N ¼ constant.
Therefore,
pðIijBÞ ¼
1
MN expðNSÞ:
(8:67)
In general, we don’t know the number of discrete quanta in the image, so we write
pðIijBÞ ¼ expðSÞ:
(8:68)
Substituting Equations (8.68) and (8.65) into Equation (8.63), we obtain
pðIijD; BÞ ¼ exp S  2
2


:
(8:69)
We want to maximize pðIi jD; BÞ or ðS  2=2Þ.
In ‘‘classic’’ MaxEnt, the  parameter is set so the misfit statistic 2 is equal to the
number of data points N. This in effect overestimates 2, since some effective number
1 parameters are being ‘‘fitted’’ in doing the image reconstruction.
The full Bayesian approach treats  as a parameter of the hypothesis space which
can be estimated by marginalizing over the image hypothesis space. Improved images
can also be obtained by introducing prior information about the correlations between
image pixels, enforcing smoothness. More details on MaxEnt image reconstruction
can be found in Buck (1991), Gull and Skilling (1984), Skilling (1989), Gull (1989a),
and Sivia (1996).
Two examples that illustrate some of the capabilities of MaxEnt image reconstruc-
tion are shown in Figures 8.4 and 8.5. Figure 8.4 illustrates how the maximum entropy
method is capable of increasing the contrast of an image, and can also increase its
sharpness if the measurements are sufficiently accurate. Figure 8.5 illustrates how the
maximum entropy method automatically allows for missing data (Skilling and Gull,
1985).
These
and
other
examples,
along
with
information
on
commercial
software products, are available from Maximum Entropy Data Consultants, Ltd.
(http://www.maxent.co.uk/).
8.8 MaxEnt image reconstruction
207

8.9 Pixon multiresolution image reconstruction
Pin˜ a and Puetter (1993) and Puetter (1995) describe another very promising Bayesian
approach to image reconstruction, which they refer to as the PixonTM method. Instead
of representing the image with pixels of a constant size, they introduce an image model
where the size of the pixel varies locally according to the structure in the image. Their
generalized pixels are called pixons. A map of the pixon sizes is called an image model.
The Pixon method seeks to find the best joint image and image model that is consistent
with the data based on a 2 goodness-of-fit criterion, and that can represent the
structure in the image by the smallest number of pixons. For example, suppose we
have a 1024 by 1024 image of the sky containing a galaxy which occupies the inner 100
(d)
(e)
(b)
(c)
(a)
Figure 8.4 The original high-resolution low-noise image is shown in panel (a). Panel (b) shows
the blurred original with high added noise. The MaxEnt reconstruction of the blurred noisy
image is shown in (c). This demonstrates how the maximum entropy method suppresses noise,
yielding a higher contrast image. Panel (d) shows the blurred original with low added noise. The
MaxEnt reconstructed image, shown in (e), demonstrates how well maximum entropy de-blurs
if the data are accurate enough. (Courtesy S. F. Gull, Maximum Entropy Data Consultants.)
208
Maximum entropy probabilities

by 100 pixels. In principle, we need many numbers to encode the significant structure
in the galaxy region, but only one number to encode information in the featureless
remainder of the image. Because the Pixon method constructs a model that represents
the significant structure by the smallest number of parameters (pixons), it has the
smallest Occam penalty.
Figure 8.6 shows an image reconstructions of a mock data set. The original image is
shown on the far left along with a surface plot (center row). The original image is
convolved (blurred) with the point-spread-function (PSF) shown at the bottom of the
first column. Then noise (see bottom of second column) is added to the smoothed
(PSF-convolved) data to produce the input (surface plot in middle panel) to the image
reconstruction algorithm. To the right are a Pixon method reconstruction and a
maximum entropy reconstruction. The algorithms used are the MEMSYS 5
(e)
(c)
(a)
(d)
(f)
(b)
Figure 8.5 This figure demonstrates how the maximum entropy method automatically allows
for missing data. Panel (a) shows the original image when 50% of the pixels, selected at random,
have been removed. Panel (b) shows the corresponding MaxEnt reconstructed image. Panel
(c) shows the original image when 95% of the pixels have been removed. Panel (d) shows the
corresponding MaxEnt reconstructed image. Panel (e) shows the original image when 99% of
the pixels have been removed. Panel (f) shows the corresponding MaxEnt reconstructed image.
(Courtesy S. F. Gull, Maximum Entropy Data Consultants.)
8.9 Pixon multiresolution image reconstruction
209

algorithms, a powerful set of commercial maximum entropy (ME) algorithms avail-
able from Maximum Entropy Data Consultants, Ltd. The ME reconstructions were
performed by Nick Weir, a recognized ME and MEMSYS expert. The reconstructions
were supplemented by Nick Weir’s multi-correlation channel approach.
The Pixon method reconstructions use the Fractal–Pixon Basis (FPB) approach
(Pin˜ a and Puetter, 1993; Puetter, 1995). The ‘‘Fractal’’ nomenclature has since been
dropped, so the term FPB simply refers to the ‘‘standard’’ Pixon method. It can be seen
that the FPB reconstruction has no signal correlated residuals and is effectively
artifact (false-source) free, whereas these problems are obvious in the MEMSYS
reconstruction. The absence of signal correlated residuals and artifacts can be under-
stood from the underlying theory of the Pixon method (Puetter, 1995).
Figure 8.7 shows the Pixon method applied to X-ray mammography, taken from
the PixonTM homepage located at http://www.pixon.com, or alternatively, http://
casswww.ucsd.edu/personal/puetter/pixonpage.html. The raw X-ray image appears
to the left. In this example, a breast phantom is used (material with X-ray absorption
properties similar to the human breast). A small fiber (400 micrometer diameter) is
present in the phantom. The signature of the fiber is rather faint in the direct X-ray
image. The Pixon method reconstruction is seen to the right. Here, the signature of the
fiber is obvious. Such image enhancement is of clear benefit to the discovery of weak
True
(a)
(b)
(c)
(d)
(h)
(g)
(f)
(e)
(i)
(j)
(k)
(l)
Noise
PSF
Residuals
Residuals
MEMSYS
FPB
Input
Figure 8.6 Reconstruction of a mock data set. The original image is shown on the far left
(a) along with a surface plot (e). This image is convolved (blurred) with the point-spread-
function (PSF) (i) shown at the bottom of the first column. Then noise (j) is added to the
smoothed (PSF-convolved) data to produce the input (b), (f) to the image reconstruction
algorithm. To the right are a Pixon method reconstruction (FPB) and a maximum entropy
reconstruction (MEMSYS). (Courtesy Pixon LLC.)
210
Maximum entropy probabilities

X-ray signatures. As can be seen, the X-ray signature of the fiber is very close to the
noise level. This is evidenced by the break-up of the continuous fiber into pieces in the
Pixon image. The Pixon method recognized that in certain locations, the X-ray signal
present is not statistically significant. In these locations, the fiber vanished in the
reconstructed image.
8.10 Problems
1. Use the maximum entropy method to compute and plot the probability of each side
of a six-sided loaded die given that exhaustive tests have determined that the
expectation value of the number of dots on the uppermost face ¼ 4:6.
2. Use the maximum entropy method to compute and plot the probability of each side
of a six-sided loaded die given that exhaustive tests have determined that the
expectation value of the number of dots on the uppermost face ¼ , for  ¼ 1:1
to 5.9 in steps of 0.1. Plot the probability of each side versus . Plot the probability
of all six sides on one plot versus .
3. Evaluate a unique probability distribution for pðYjIÞ (the question posed in Section
8.1) using the MaxEnt principle together with the constraint: ‘‘the mean value of
cos y ¼ 0:6.’’ Our prior information also tells us that mðYjIÞ, the prior estimate of
pðYjIÞ, is a constant in the range 0 to 2p. In working out the solution, you will
encounter the modified Bessel functions of the first kind, designated by BesselI[n; z]
in Mathematica. You may also find the command FindRoot[] useful.
Figure 8.7 An example of the Pixon method applied to X-ray mammography. The raw X-ray
image appears to the left. In this example, a breast phantom is used (material with X-ray
absorption properties similar to the human breast). In this case, a small fiber (400 micrometer
diameter) is present in the phantom. The Pixon method reconstruction is seen to the right.
(Courtesy Pixon LLC.)
8.10 Problems
211

9
Bayesian inference with Gaussian errors
9.1 Overview
In the next three chapters, we will be primarily concerned with estimating model
parameters when our state of knowledge leads us to assign a Gaussian sampling
distribution when calculating the likelihood function. In this chapter, we start with
a simple problem of computing the posterior probability of the mean of a data set.
Initially, we assume the variance of the sampling distribution is known and then
consider the case where the variance is unknown. We next look at the question of how
to determine whether the signal present in the data is constant or variable. In the final
section, we consider a Bayesian treatment of a fundamental problem that occurs in
experimental science – that of analyzing two independent measurements of the same
physical quantity, one ‘‘control’’ and one ‘‘trial.’’
9.2 Bayesian estimate of a mean
Here we suppose that we have collected a set of N data values fd1; . . . ; dNg and we are
assuming the following model is true:
di ¼  þ ei;
where ei represents the noise component of the ith data value. For this one data set,
and any prior information, we want to obtain the Bayesian estimate of . We will
investigate three interesting cases. In all three cases, our prior information about ei
leads us to adopt an independent Gaussian sampling distribution.1 In Section 9.2.1, we
analyze the case where the noise  is the same for all ei. In Section 9.2.2, we treat the
more general situation where the i are unequal. Section 9.2.3 considers the case where
the i are assumed equal but the value is unknown.
1 Note: if we had prior evidence of dependence, i.e., correlation, it is a simple computational detail to take this into
account as shown in Section 10.2.2.
212

9.2.1 Mean: known noise s
In this situation, we will assume that the variance of the noise is already known. We
might, for example, know this from earlier measurements with the same apparatus in
similar conditions. We also assume the prior information gives us lower and upper
limits on  but no preference for  in that range.
The problem is to solve for pðjD; IÞ. The first step is to write down Bayes’
theorem:
pðjD; IÞ ¼ pðjIÞ pðDj; IÞ
pðDjIÞ
;
(9:1)
where the likelihood pðDj; IÞ is sometimes written as LðÞ. Our assumed prior for  is
given by
pðjIÞ ¼ KðconstantÞ;
L    H
¼ 0;
otherwise:
Evaluate K from
Z H
L
pðjIÞd ¼
Z H
L
Kd ¼ 1:
Therefore,
K ¼
1
H  L
¼ 1
R
;
where R  range of . This gives the normalized prior,
pðjIÞ ¼ 1
R
:
(9:2)
The likelihood is given by
pðDj; IÞ ¼
Y
N
i¼1
1

ﬃﬃﬃﬃﬃﬃ
2p
p
exp
 ðdi  Þ2
22
(
)
¼ Nð2pÞN
2 exp

PN
i¼1ðdi  Þ2
22
(
)
¼ Nð2pÞN
2 exp  Q
22


;
(9:3)
where we have abbreviated PN
i¼1ðdi  Þ2 by Q.
9.2 Bayesian estimate of a mean
213

Expanding Q, we obtain
Q ¼
X
N
i¼1
ðdi  Þ2 ¼
X
d2
i þ
X
2  2
X
di
¼
X
d2
i þ N2  2Nd
fd  1
N
X
dig
¼ Nð2  2d þ d
2Þ þ
X
d2
i  Nd
2
¼ Nð  dÞ2 þ
X
d2
i  Nd
2
¼ Nð  dÞ2 þ
X
d2
i  2Nd
2 þ Nd
2
¼ Nð  dÞ2 þ
X
d2
i  2d
X
di þ
X
d
2
¼ Nð  dÞ2 þ
X
ðdi  dÞ2
¼ Nð  dÞ2 þ Nr2;
(9:4)
where r2 ¼ 1
N
Pðdi  dÞ2 is the mean square deviation from d. Now substitute
Equation (9.4) into Equation (9.3):
pðDj; IÞ ¼ Nð2pÞN
2 exp  Nr2
22


exp
 Nð  dÞ2
22
(
)
:
(9:5)
We can express pðDjIÞ as
pðDjIÞ ¼
Z H
L
d pðjIÞpðDj; IÞ:
(9:6)
Substitution of Equations (9.2), (9.5) and (9.6) into Equation (9.1) yields the desired
posterior:
pðjD; IÞ ¼
1
R Nð2pÞN
2 exp  Nr2
22
n
o
exp  NðdÞ2
22
n
o
1
R Nð2pÞN
2 exp  Nr2
22

 R H
L d exp  NðdÞ2
22
n
o :
(9:7)
Equation (9.7) simplifies to
pðjD; IÞ ¼
exp  ðdÞ2
22=N
n
o
R H
L exp  ðdÞ2
22=N
n
o
d
¼ NUM
DEN :
(9:8)
Therefore,
pðjD; IÞ ¼
1
DEN exp
 ð  dÞ2
22=N
(
)
:
(9:9)
214
Bayesian inference with Gaussian errors

Since the denominator (DEN) evaluates to a constant (see Equation (9.11), the
posterior, within the range L to H, is simply a Gaussian with variance equal to 2=N.
Thus, the uncertainty in the mean is inversely proportional to the square root of the
sample size, which is the basis of signal averaging as discussed in Section 5.11.1. Figure
9.1 shows the resulting posterior probability density function for pðjD; IÞ in the limit
of H ¼ þ1 and L ¼ 1.
It is interesting to compare this Bayesian result to the frequentist confidence
intervals for the mean when sampling from a normal distribution as discussed in
Section 6.6. In the frequentist approach, we were not able to make any probability
statement in connection with a single confidence interval derived from one data set
fdig. For example, the interpretation of the 68% confidence interval was: if we
repeatedly draw samples of the same size from a population, and each time compute
specific values for the 68% confidence interval, d  =
ﬃﬃﬃﬃ
N
p
, then we expect 68% of
these confidence intervals to contain the unknown mean . In the frequentist case, the
problem was to find the mean of a hypothetical population of possible measurements
for which our sample was but one realization.
In the Bayesian case, we are making a probability statement about the value of a
model parameter. From our posterior probability density function, we can always
compute the probability that the model parameter  lies within =
ﬃﬃﬃﬃ
N
p
of the sample
mean d. It turns out that when the prior bounds for  are so wide that they are far
outside the range indicated by the data, the value of this probability is 68%. In this
particular instance, the boundaries of the Bayesian 68% credible region are the same as
the frequentist 68% confidence interval. However, if we decrease the range of the prior
bounds for , the probability contained within the frequentist 68% confidence bound-
ary increases and reaches 100% when the prior boundaries coincide with =
ﬃﬃﬃﬃ
N
p
.
The differences in conclusions drawn between a Bayesian and a frequentist analysis
of the same data are a consequence of the different definitions of probability used in
the two approaches. Recall that in the frequentist case, the argument of a probability
must be a random variable. Because a parameter is not a random variable, the
frequentist approach does not permit the probability density of a parameter to be
calculated directly or allow for the inclusion of a prior probability for the parameter.
 µ
p(µ |D,I )
√N
σ
Figure 9.1 The posterior probability density function for pðjD; IÞ.
9.2 Bayesian estimate of a mean
215

The interpretation of any frequentist statistic, such as the sample mean, is always in
relation to a hypothetical population of possible samples that could have been
obtained under similar circumstances.
Detail: Calculation of DEN in Equation (9.8)
To evaluate DEN, compare with the error function erfðxÞ (the Mathematica command
is Erf[x]).
erfðxÞ ¼ 2ﬃﬃﬃp
p
Z x
0
expðu2Þdu;
note: erfðxÞ ¼ erfðxÞ
(9:10)
let
Nð  dÞ2
22
¼ u2 ) u ¼ ð  dÞð22
N Þ1
2;
therefore,
du ¼
22
N

1
2
d
or
d ¼
22
N

1
2
du;
and
DEN ¼
22
N

1
2
ﬃﬃﬃp
p
2
2ﬃﬃﬃp
p
Z uH
uL
expðu2Þdu

	
:
We can rewrite the integral limits in DEN as follows:
Z uH
uL
¼
Z uH
1

Z uL
1
¼
Z 0
1
þ
Z uH
0

Z 0
1

Z uL
0
¼
Z uH
0

Z uL
0
therefore,
DEN ¼
22
N

1
2
ﬃﬃﬃp
p
2 ½erfðuHÞ  erfðuLÞ
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ};
ð 2 if uH  1 and uL  1Þ
(9:11)
where
uH ¼
22
N

1
2
ðH  dÞ;
uL ¼
22
N

1
2
ðL  dÞ:
216
Bayesian inference with Gaussian errors

9.2.2 Mean: known noise, unequal s
In this situation, we again assume that the noise variance is known but that it can differ
for each data point. The likelihood is given by
pðDj; IÞ ¼
Y
N
i¼1
1
i
ﬃﬃﬃﬃﬃﬃ
2p
p
exp
 ðdi  Þ2
22
i
(
)
¼
Y
N
i¼1
1
i
"
#
ð2pÞN
2 exp

X
N
i¼1
ðdi  Þ2
22
i
(
)
¼
Y
N
i¼1
1
i
"
#
ð2pÞN
2 exp

X
N
i¼1
wiðdi  Þ2
2
(
)
¼
Y
N
i¼1
1
i
"
#
ð2pÞN
2 exp  Q
2


;
(9:12)
where wi ¼ 1=2
i is called the weight of data value di. In this case, Q is given by
Q ¼
X
N
i¼1
wiðdi  Þ2 ¼
X
wid2
i þ 2 X
wi  2
X
widi
¼
X
wi


2  2
P widi
P wi
þ
P wid2
i
P wi


¼
X
wi


2  2
P widi
P wi
þ ðP widiÞ2
ðP wiÞ2
 
!
 ðP widiÞ2
ðP wiÞ2 þ
P wid2
i
P wi
(
)
¼
X
wi


 
P widi
P wi

2
 ðP widiÞ2
ðP wiÞ2 þ
P wid2
i
P wi
(
)
¼
X
wi


 
P widi
P wi

2
 ðP widiÞ2
P wi
þ
X
wid2
i :
(9:13)
Only the first term, which contains the unknown mean , will appear in our final
equation for the posterior probability of the mean, as we see below. Although the
second and third terms do not appear in the final result, they can be shown to equal the
weighted mean square residual (r2
w) times the sum of the weights (P wi). The weighted
mean square residual, r2
w, is given by
r2
w ¼
1
P wi
X
wi di 
P widi
P wi

2
(
)
;
(9:14)
where P widi=ðP wiÞ ¼ dw is the weighted mean of the data values. Thus
r2
w ¼
1
P wi
X
wiðdi  dwÞ2
n
o
;
(9:15)
9.2 Bayesian estimate of a mean
217

and
Q ¼ ð  dwÞ2
1= P wi
þ r2
w
X
wi:
(9:16)
Now substitute Equation (9.16) into (9.12).
pðDj; IÞ ¼
Y
N
i¼1
1
i
"
#
ð2pÞN
2 exp  r2
w
P wi
2


exp  ð  dwÞ2
2=P wi
 
!
¼
Y
N
i¼1
1
i
"
#
ð2pÞN
2 exp  r2
w
P wi
2


exp  ð  dwÞ2
22
w
 
!
;
(9:17)
where 2
w ¼ 1=ðP wiÞ. Substitution of Equations (9.2), (9.17) and (9.6) into Equation
(9.1) yields the desired posterior:
pðjD; IÞ ¼
1
R ½Q
i 1
i ð2pÞN
2 expð
r2
w
P
wi
2
Þ exp  ðdwÞ2
22w


1
R ½Q
i 1
i ð2pÞN
2 expð
r2w
P
wi
2
Þ
R H
L d exp  ðdwÞ2
22w

 :
(9:18)
Therefore,
pðjD; IÞ ¼
exp  ðdwÞ2
22w
n
o
R H
L exp  ðdwÞ2
22w
n
o
d
:
(9:19)
Since the denominator evaluates to a constant, the posterior, within the range L to
H, is simply a Gaussian with variance 2
w ¼ 1=ðP wiÞ. The most probable value of  is
the weighted mean dw ¼ P widi=ðP wiÞ.
9.2.3 Mean: unknown noise s
In this section, we assume that the variance, 2, of the noise is unknown but is assumed
to be the same for each measurement,2 di. As in the previous case, we proceed by
writing down the assumed model:
di ¼  þ ei:
In general, ei consists of the random measurement errors plus any real signal in the
data that cannot be explained by the model. For example, suppose that unknown to us,
the data contained a periodic signal superposed on the mean. In this connection, the
periodic signal would act like an additional unknown noise term. It is often the case, that
nature is more complex than our current model. In the absence of a detailed knowledge
2 See Section 12.9 on extrasolar planets for a discussion of the case where the variance is not constant.
218
Bayesian inference with Gaussian errors

of the effective noise distribution, we could appeal to the Central Limit Theorem and
argue that if the effective noise stems from a large number of sub-processes then it is
expected to have a Gaussian distribution. Alternatively, the MaxEnt principle tells us
that a Gaussian distribution would be the most conservative choice (i.e., maximally
non-committal about the information we don’t have). For a justification of this argu-
ment, see Section 8.7.4. The only requirement is that the noise variance be finite. In what
follows, we will assume the effective noise has a Gaussian distribution with unknown .
Now we have two unknowns in our model,  and . The joint posterior probability
pð; jD; IÞ is given by Bayes’ theorem:
pð; jD; IÞ ¼ pð; jIÞpðDj; ; IÞ
pðDjIÞ
:
(9:20)
We are interested in pðjD; IÞ regardless of what the true value of  is. In this problem,
 is a nuisance parameter so we marginalize over :
pðjD; IÞ ¼
Z
pð; jD; IÞd:
(9:21)
From the product rule: pð; jIÞ ¼ pðjIÞpðj; IÞ.
Assuming the prior for  is independent of the prior for , then
pð; jIÞ ¼ pðjIÞpðjIÞ:
(9:22)
Combining Equations (9.20), (9.21), and (9.22),
pðjD; IÞ ¼ pðjIÞ
R
pðjIÞpðDj; ; IÞd
pðDjIÞ
;
(9:23)
where
pðDjIÞ ¼
Z
pðjIÞ
Z
pðjIÞpðDj; ; IÞdd:
(9:24)
As before we assume a flat prior for  in the range L to H. Therefore
pðjIÞ ¼ 1
R
;
ðR ¼ H  LÞ:
(9:25)
 is a scale parameter, so it can only take on positive values 0 ! 1. Realistic limits do
not go all the way to zero and infinity. For example, we always know that  cannot be
less than a value determined by the digitizing accuracy with which we record the data;
nor so great that the noise power would melt the apparatus. Let L and H be our prior
limits on .
We will assume a Jeffreys prior for the scale parameter :
pðjIÞ ¼
K=;
L    H
0;
otherwise.

9.2 Bayesian estimate of a mean
219

The constant K is determined from the condition
Z H
L
pðjIÞd ¼ 1
)
K ¼
1
lnðH=LÞ
pðjIÞ ¼
1
 ln H=L
:
(9:26)
Question: Why did we choose  instead of the variance v ¼ 2 as our second parameter
or does it matter? To the extent that both v and  are ‘‘equally natural’’ parameteriza-
tions of the width of a Gaussian, it is desirable that investigators using either para-
meter reach the same conclusions.
Answer: A feature of the Jeffreys prior is that it is invariant to such a reparameteriza-
tion as we now demonstrate. We start with the requirement that
pðvjIÞdv ¼ pðjIÞd:
(9:27)
The Jeffreys prior for  can be written as
pðjIÞd ¼ K
 d;
(9:28)
where K is a constant that depends on the prior upper and lower bounds on .
Since  ¼ v1=2, d ¼ ð1=2Þv1=2dv. Upon substitution into Equation (9.28), we
obtain
pðvjIÞdv ¼ K
2v dv ¼ K0
v dv:
(9:29)
Thus, choosing a Jeffreys prior for  is equivalent to assuming a Jeffreys prior for v. It
is easy to show that this would not be the case for a uniform prior.
Another example of ‘‘equally natural’’ parameters is the choice of whether to use the
frequency or period of an unknown periodic signal. Again, it is easy to show that the
choice of a Jeffreys prior for frequency is equivalent to assuming a Jeffreys prior for
the period.
Calculation of the likelihood function:
Lð; Þ ¼ pðDj; ; IÞ ¼
Y
N
i¼1
1

ﬃﬃﬃﬃﬃﬃ
2p
p
e½ðdiÞ2=22
¼ Nð2pÞN=2eQ=22;
(9:30)
where Q depends on  and is given by Equation (9.4).
Q ¼ Nð  dÞ2 þ Nr2:
(9:31)
220
Bayesian inference with Gaussian errors

Substituting Equations (9.25), (9.26), and (9.30) into Equation (9.23), we obtain
pðjD; IÞ ¼
ð2pÞN
2
1
R lnH
L
R H
L ðNþ1Þe Q
22d
ð2pÞN
2
1
R ln
H
L
R H
L
R H
L ðNþ1Þe Q
22dd
¼
R H
L ðNþ1Þe Q
22d
R H
L
R H
L ðNþ1Þe Q
22dd
:
(9:32)
Now we change variables. Let  ¼ Q=22; therefore,
 ¼
ﬃﬃﬃﬃﬃ
Q
2
r
and
d ¼  1
2 3
2
ﬃﬃﬃﬃ
Q
2
r
d
ðNþ1Þ ¼
2
Q

Nþ1
2
¼ 2
Nþ1
2 
Nþ1
2 QðNþ1
2 Þ
ðNþ1Þd ¼ 2
N
21
N
21QðN
2Þd
(9:33)
and therefore,
pðjD; IÞ ¼
R H
L QðN
2Þ
N
21ed
R H
L dQðN
2Þ R L
H 
N
21ed

QðN
2Þ
R H
L dQðN
2Þ ;
(9:34)
where L ¼ Q=ð22
HÞ and H ¼ Q=ð22
LÞ:
The integral with respect to  in equation (9.34) can be evaluated in terms of the
incomplete gamma function (see equation (C.15) of Appendix C). The  integral
clearly depends on , but provided L  r and H  r, where r ¼ the RMS residual
of the most probable model fit, the integral is effectively constant. As an example, for
N ¼ 10; L ¼ 0:5r and H ¼ 5r; the  integral deviates by  1% for values of
j  dj  2:3r. However, at jx  dj ¼ 2:3r, the term QN=2 in equation (9.34) has
reached a value of 10–4 of its value at j  dj ¼ 0. For larger values of j  dj, the 
integral decreases monotonically. At j  dj ¼ 3r the integral is only down by 5%, but
now QN=2 is down by a factor of 105.
Use Equation (9.31) to substitute for Q:
pðjD; IÞ 
½Nr2 þ Nð  dÞ2N
2
R H
L d½Nr2 þ Nð  dÞ2N
2
pðjD; IÞ 
1 þ ðdÞ2
r2
h
iN
2
R H
L d 1 þ ðdÞ2
r2
h
iN
2 ;
(9:35)
9.2 Bayesian estimate of a mean
221

where the quantity Nr2 ¼ Pðdi  dÞ2, which is independent of , has been factored
out of the numerator and denominator and canceled.Now compare
1 þ ð  dÞ2
r2
"
#N
2
(9:36)
with the Student’s t distribution which was discussed in Section 6.4.
fðtjÞ ¼ ½ðþ1Þ
2 
ﬃﬃﬃﬃﬃﬃ
p
p
 
2
  1 þ t2


	ðþ1Þ
2
:
(9:37)
If we set
t2
 ¼ ð  dÞ2
r2
;
(9:38)
and the number of degrees of freedom  ¼ N  1, then Equation (9.36) has the same
form as the Student’s t distribution.3
From this comparison, it is clear that the posterior probability for  when  is
unknown is a Student’s t distribution. If L ¼ 1 and H ¼ þ1, then
pðjD; IÞ 
ðN
2Þ
ﬃﬃﬃp
p ðN1
2 Þ
1
r 1 þ ð  dÞ2
r2
"
#N
2
:
(9:39)
If the limits on  do not extend to 1, then the constant outside the square brackets
will be different but computable from a Student’s t distribution and the known prior
limits on . In practice, if L and H are well outside some measure of the range of 
argued for by the likelihood function, then the result is the same as setting the prior
limits of  to 1.
We can easily generalize the results of this section to more complicated models than
one that predicts the mean. Suppose the data were described by the following model:
di ¼ miðÞ þ ei;
where  represents a set of model parameters with a prior pðjIÞ. Then from Equation
(9.34), we can write
pðjD; IÞ 
pðjIÞQðN
2Þ
R
d pðjIÞQðN
2Þ ;
(9:40)
where Q is given by
Q ¼
X
N
i¼1
ðdi  miðÞÞ2:
(9:41)
3 In Equation (9.36), r2 ¼ 1
N
Pðdi  dÞ2 ¼ N1
N S2, where S2 is the frequentist sample variance as defined in Equation
(6.15).
222
Bayesian inference with Gaussian errors

Example:
Often we encounter situations in which our model plus known instrumental errors fail
to adequately describe the full range of variability in the data. We illustrate this with
an example from radio astronomy. In this case, we are interested in inferring the mean
flux density of a celestial radio source from repeated measurements with a radio
telescope with well-known noise properties.
Figure 9.2 shows 56 measurements of the radio flux density of a galaxy. The
individual measurement errors are known to have a Gaussian distribution with a
1 ¼ 30 units of radio flux density. It is obvious from the scatter in the measurements
compared to the error bars that there is some additional source of uncertainty or the
signal strength is variable. For example, additional fluctuations might arise from
propagation effects in the interstellar medium between the source and observer. In
the absence of prior information about the distribution of the additional scatter, both
the Central Limit Theorem and the MaxEnt principle (Section 8.7.4) lead us to adopt a
Gaussian distribution because it is the most conservative choice. Let 2 ¼ the standard
deviation of this Gaussian.4 The resulting likelihood function is the convolution of the
Gaussian model of the additional scatter and the Gaussian measurement error dis-
tribution (see Section 4.8.2). The result is another Gaussian with a variance,
2 ¼ 2
1 þ 2
2.
0
2000
4000
6000
8000
Time (days) 
50
100
150
200
250
300
350
Radio flux density
Figure 9.2 Plot of the radio source measurements and 1 measurement errors.
4 Since 2 is an unknown nuisance parameter we will need to marginalize over some prior range. For values of 2 close to
the upper bounds of this range, the lower tail of the Gaussian distribution may extend into negative values of source
strength. If the scatter arises from variations in the source strength then this situation is non-physical. Thus, it would be
more exact to adopt a truncated Gaussian but the mathematics is greatly complicated. The current analysis must
therefore be viewed as approximate.
9.2 Bayesian estimate of a mean
223

We have computed the posterior probability of the mean flux density pðjD; IÞ in
two ways. First, assuming the known measurement errors and Equation (9.8), the
result is shown as the solid curve in Figure 9.3. Next we assumed  was unknown
and plotted the result after marginalizing over values of  in the range 30 to 400
units, using Equation (9.39). This results in the much broader dashed curve shown
in Figure 9.3. In the latter analysis, where we marginalize over , we are in effect
estimating  from the data and any variability which is not described by the model
is assumed to be noise (the following section provides a justification of this
statement). This approach leads to a broader posterior probability distribution
which reflects the larger effective noise when using a model that assumes the source
flux density is constant. Note: if the effective noise had been equal to the measure-
ment error ( ¼ 30) then the result for pðjD; IÞ would have been the same as if we
had used a fixed noise of 30. A justification of this claim is given in the following
section.
9.2.4 Bayesian estimate of s
In the previous section, we computed the Bayesian estimate of the mean of a data set
when the  of the Gaussian sampling distribution is unknown. It is also of interest to
see what the data have to say about . This can be answered by computing pðjD; IÞ,
the posterior marginal for . Following Equation (9.23), we write
pðjD; IÞ ¼ pðjIÞ
R
pðjIÞpðDj; ; IÞd
pðDjIÞ
:
(9:42)
140
160
180
200
220
Mean flux density µ
0
0.02
0.04
0.06
0.08
0.1
Probability density
Figure 9.3 Comparison of the computed results for the posterior PDF for the mean radio flux
density assuming  known (solid curve), and marginalizing over an unknown  (dashed curve).
224
Bayesian inference with Gaussian errors

Substituting Equations (9.30) and (9.31) into Equation (9.42), we obtain
pðjD; IÞ ¼
ð2pÞN
2
1
R lnH
L
ðNþ1ÞeNr2
22 R H
L eNðdÞ2
22 d
ð2pÞN
2
1
R ln
H
L
R H
L ðNþ1ÞeNr2
22 R H
L eNðdÞ2
22 dd
pðjD; IÞ ¼
ðNþ1ÞeNr2
22 R H
L eNðdÞ2
22 d
R H
L ðNþ1ÞeNr2
22 R H
L eNðdÞ2
22 dd
¼
ðNþ1ÞeNr2
22
ﬃﬃﬃﬃﬃﬃ
2p
p
ﬃﬃﬃ
N
p
R H
L ðNþ1ÞeNr2
22
ﬃﬃﬃﬃﬃﬃ
2p
p
ﬃﬃﬃ
N
p d
¼ CNeNr2
22 :
(9:43)
In the above equation, we have made use of the fact that the integral of a normalized
Gaussian is equal to 1, i.e.,
1
ﬃﬃﬃﬃﬃﬃ
2p
p
ﬃﬃﬃ
N
p
Z H
L
e
ðdÞ2
22=Nd ¼ 1;
(9:44)
therefore,
Z H
L
eNðdÞ2
22 d ¼
ﬃﬃﬃﬃﬃﬃ
2p
p
ﬃﬃﬃﬃ
N
p
:
(9:45)
The most probable value (mode) of Equation (9.43) is the solution of
@p
@ ¼ ½N^N1 þ Nr2^N3CeNr2=2^2 ¼ 0:
(9:46)
The solution is
^ ¼ r:
(9:47)
Thus, pðjD; IÞ has a maximum at  ¼ r, the RMS deviation from d.
Since pðjD; IÞ is not a simple Gaussian, it is of interest to compare the mode to hi
and h2i, the expectation values of  and 2, respectively. They are given by
hi ¼
Z 1
0
pðjD; IÞd;
(9:48)
h2i ¼
Z 1
0
2pðjD; IÞd:
(9:49)
9.2 Bayesian estimate of a mean
225

These equations can be evaluated using an inverse gamma integral and a change of
variables. The results are
hi ¼
ﬃﬃﬃﬃ
N
p
r
ﬃﬃﬃ
2
p
½ðN  2Þ=2
½ðN  1Þ=2 ;
(9:50)
and
h2i ¼ Nr2
N  1 ¼
1
N  1
X
N
i¼1
ðdi  dÞ2:
(9:51)
These three summaries ð^; hi;
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
h2i
p
Þ of pðjD; IÞ are all different; the distribution
is not symmetric like a Gaussian. Figure 9.4 illustrates the three summaries assuming a
value of r ¼ 2. For N ¼ 3, hi can differ from ^ by as much as a factor  2, but this
difference drops to 15 % by N ¼ 10. As N increases, the summaries asymptotically
approach r, the RMS residual. Of the three,
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
h2i
p
is the most representative, lying
between the other two.
The reader should recognize the expression for h2i is identical to the equation for
the frequentist sample variance, S2 ¼ Pðdi  dÞ2=ðN  1Þ, that is used to estimate the
population variance for an IID sample taken from a normal distribution (see Section
6.3). Of course in Bayesian analysis, the concept of a population of hypothetical
samples plays no role.
The main message of this section is that in problems where  is unknown, the effect
of marginalizing over  is roughly equivalent to setting  ¼ RMS residual of the most
probable model. Thus, anything in the data that can’t be explained by the model is
treated as noise, leading to the most conservative estimates of model parameters. It is a
very safe thing to do.
10
20
30
40
50
N
1
2
3
4
5
Summary value
≺σ ≻ 
σ∧
≺ σ 2 ≻
√
Figure 9.4 A comparison of the three summaries for the marginal probability density function
for pðjD; IÞ assuming an RMS residual r ¼ 2.
226
Bayesian inference with Gaussian errors

Returning to the radio source example (Figure 9.2) of the previous section, we now
use Equation (9.43) to estimate the posterior marginal pðjD; IÞ for these data, which
are shown in panel (a) of Figure 9.5. The three summaries in this case are
^ ¼ 73:8; hi ¼ 75:6;
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
h2i
p
¼ 74:5. Recall that in the absence of prior information
on the sampling distribution for the radio source measurements, we adopted a
Gaussian with unknown . Panel (b) compares the effective Gaussian sampling
distribution (based on
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
h2i
p
¼ 74:5)) employed in the analysis with a normalized
histogram of the actual data values. The Gaussian is centered at  ¼ 182, the posterior
maximum.
So far in this chapter, we have been concerned with fitting a simple linear model
with one parameter, the mean. In Chapter 10, we will be concerned with linear models
with M parameters. We will also have occasion to marginalize over an unknown noise
. Again, we can compute the posterior marginal pðjD; IÞ, after marginalizing over
the M model parameters. Assuming a Jeffreys prior for  with prior boundaries well
outside the region of the posterior peak, it can be shown that the value of h2i is given by
h2i ¼
1
ðN  MÞ
X
N
i¼1
ðdi  dÞ2:
(9:52)
9.3 Is the signal variable?
In Section 7.2.1, we used a frequentist hypothesis test to decide whether we could
reject, at the 95% confidence level, the null hypothesis that the radio signal from a
galaxy is constant. If we can reject this hypothesis, then it provides indirect evidence
that the signal is variable. A Bayesian analysis of the same data allows one to directly
compare the probabilities of two hypotheses: Hc  ‘‘the signal is constant,’’ and Hv 
‘‘the signal is variable.’’ To compute pðHvjD; IÞ, it is first necessary to specify a model
40
60
80
100
120
Standard deviation σ
0
0.01
0.02
0.03
0.04
0.05
Probability density
 (a) 
50
100 150 200 250 300 350
Flux density
0.001
0.002
0.003
0.004
0.005
0.006
Probability density
(b) 
Figure 9.5 Panel (a) shows the marginal probability density function for pðjD; IÞ for the radio
galaxy data of Figure 9.2. Panel (b) compares the effective Gaussian sampling distribution
employed in the analysis with a normalized histogram of the actual data values.
9.3 Is the signal variable?
227

for the signal variability. Some examples of different categories of variability models
are given below.
1. The signal varies according to some specific non-periodic function of time, fðtjÞ, where 
stands for a set of model parameters, e.g., slope and intercept in a linear model. The model
might make specific predictions concerning the parameters or they may be unknown nuis-
ance parameters. Of course, each nuisance parameter will introduce an Occam penalty in the
calculation of the Bayes factor. Model fitting is discussed in Chapters 10, 11, 12.
2. The signal varies according to some specific periodic function of time. Examples of this are
discussed in Section 12.9 and Chapter 13.
3. The signal varies according to some unknown periodic function of time (Gregory and
Loredo, 1992; Loredo, 1992; Gregory, 1999). In this case, it is possible to proceed if we
assume a model, or family of models, that is capable of describing an arbitrary shape of
periodic variability with the minimum number of parameters. An example of this will be
discussed in Section 13.4.
4. The signal varies according to some unknown non-periodic function of time. Again, it is
possible to proceed if we assume a model, or family of models, that is capable of describing an
arbitrary shape of variability with the minimum number of parameters. An example of this is
given by Gregory and Loredo (1993).
5. The model only provides information about the statistical properties of the signal variability,
i.e., specifies a probability distribution of the signal fluctuations. When combined with a
model of the measurement errors (see Section 4.8.2), it can be used as a sampling distribution
to compute the likelihood of the data set.
6. Finally, we may only have certain constraints on a model of the signal variability. We can
always exploit the MaxEnt principle to arrive at a form of the signal variability distribution
that reflects our current state of knowledge. Again, when combined with a model of the
measurement errors (see Section 4.8.2), it can be used as a sampling distribution to compute
the likelihood of the data set.
9.4 Comparison of two independent samples
The decisions on whether a particular drug is effective, or some human activity is
proving harmful to the environment, are important topics to which Bayesian analysis
can make a significant contribution. The issue typically boils down to comparing two
independent samples referred to as the trial sample and the control sample. In this
section, we will demonstrate a Bayesian approach to comparing two samples based on
the treatment given by Bretthorst (1993), which is an extension of earlier work by
Dayal (1972), and Dayal and Dickey (1976). His derivation is a generalization of the
Behrens–Fisher and two-sample problems,5 using the traditional F and Student’s t
distributions.
5 In the frequentist statistical literature, estimating the difference in means assuming the same but unknown standard
deviation is referred to as the two-sample problem. Estimating the difference in means assuming different unknown
standard deviations is known as the Behrens–Fisher problem.
228
Bayesian inference with Gaussian errors

To start, we need to specify the prior information, I, which includes a statement of
the problem, the hypothesis space of interest, and the sampling distribution to be used
in calculating the likelihood function. To illustrate the methodology, we will re-visit a
problem that was considered using frequentist statistical tools in Section 7.2.2, and in
problem 2 at the end of Chapter 7. The problem is to compare the concentrations of a
particular toxin in river sediment samples taken from two locations and tabulated in
Table 7.2. The location 1 sample was taken upriver (control sample) from a processing
plant and the location 2 sample taken downstream (trial sample) from the plant. In
Section 7.2.2 we considered whether we could reject the null hypothesis that the mean
toxin concentrations are the same at the two locations assuming the standard devia-
tions of the two samples were different. Using the frequentist approach, we were just
able to reject the null hypothesis at the 95% confidence level.
The current analysis assumes the two samples can differ in only two ways, the mean
toxin concentrations and/or the sample standard deviations. Let d1;i represent the ith
measurement in the first sample consisting of N1 measurements in total. The symbol
D1 will represent the set of measurements fd1;ig that constitute sample 1. We will
model d1;i by the equation
d1;i ¼ c1 þ e1;i;
(9:53)
where, as usual, e1;i represents an unknown error component in the measurement. We
assume that our knowledge of the source of the errors leads us to assume a Gaussian
distribution for e1;i, with a standard deviation of 1. To be more precise, 1 is a
continuous hypothesis asserting that the noise standard deviation in D1 is between 1
and 1 þ d1. In some cases, we assume a Gaussian distribution because, in the
absence of knowledge of the true sampling distribution, employing a Gaussian
distribution is the most conservative choice for the reasons given in Section 8.7.4.
We also assume that individual measurements that constitute the sample are indepen-
dent, i.e., the e1;i are independent.
In the absence of the error component, the model predicts d1;i ¼ c1. Although c1 will
be referred to as the mean of D1; c1 is more precisely, a continuous hypothesis asserting
that the constant signal component in D1 is between c1 and c1 þ dc1. We can write
a similar equation for the ith measurement of sample 2, which consists of N2
measurements.
d2;i ¼ c2 þ e2;i:
(9:54)
Again, we will let 2 represent the standard deviation of the Gaussian error term. The
hypothesis space of interest for our Bayesian analysis is given in Table 9.1.
We will be concerned with answering the following hierarchy of questions:
1. Do the samples differ, i.e., do the mean concentrations and/or the standard deviations
differ?
2. If so, how do they differ; in the mean, standard deviation or both?
9.4 Comparison of two independent samples
229

3. If the means differ, what is their difference ?
4. If the standard deviations differ, what is their ratio r?
To answer the above questions, we need to compute the probabilities of the hypoth-
eses listed in Table 9.1. The discrete hypotheses are represented by the capitalized
symbols and the continuous hypotheses by the lower case symbols,  and r. For
example, the symbol C stands for the hypothesis that the means are the same, and C
stands for the hypothesis that they differ.
9.4.1 Do the samples differ?
The answer to question (1) can be obtained by computing pðC þ SjD1; D2; IÞ,
the probability that the means and/or the standard deviations are different given the
sample data (D1 and D2) and the prior information I. Apart from the priors for the
parameters c1; c2; 1; 2, we have already specified the prior information I above. To
compute the probability that the means and/or the standard deviations differ, we note
that from Equation (2.1), we can write
pðC þ SjD1; D2; IÞ ¼ pðC; SjD1; D2; IÞ ¼ 1  pðC; SjD1; D2; IÞ:
(9:55)
Equation (9.55) demonstrates that it is sufficient to compute the probability that
the means and the standard deviations are the same. From that, one can compute the
probability that the means and/or the standard deviations differ. The hypothesis
C; S assumes the means and the standard deviations are the same, so only two
Table 9.1 The hypotheses addressed. The symbol in the right hand column is used as an
abbreviation for the hypothesis.
Hypothesis
In words
Symbol
c1 ¼ c2
Same means
C
c1 6¼ c2
Means differ
C
1 ¼ 2
Same standard deviations
S
1 6¼ 2
Standard deviations differ
S
c1 ¼ c2 and 1 ¼ 2
Same means and standard deviations
C; S
c1 ¼ c2 and 1 6¼ 2
Same means, standard deviations differ
C; S
c1 6¼ c2 and 1 ¼ 2
Means differ, same standard deviations
C; S
c1 6¼ c2 and 1 6¼ 2
Means and standard deviations differ
C; S
c1 6¼ c2 and/or 1 6¼ 2
Means and/or standard deviations differ
C þ S
c1  c2 ¼ 
Difference in means ¼ 

1=2 ¼ r
Ratio of standard deviations ¼ r
r
230
Bayesian inference with Gaussian errors

parameters (a constant c1, and a standard deviation 1) have to be removed by
marginalization:
pðC; SjD1; D2; IÞ ¼
Z
dc1d1pðC; S; c1; 1jD1; D2; IÞ;
(9:56)
where c2 ¼ c1 and 2 ¼ 1. The right hand side of this equation may be factored using
Bayes’ theorem to obtain
pðC; SjD1; D2; IÞ ¼ K
Z
dc1d1pðC; S; c1; 1jIÞpðD1; D2jC; S; c1; 1; IÞ;
(9:57)
where,
K ¼
1
pðD1; D2jIÞ :
(9:58)
We need to evaluate the probabilities of four basic alternative hypotheses. They are
ðC; SÞ; ðC; SÞ; ðC; SÞ and ðC; SÞ. Equation (9.57) gives the posterior for (C; S). We
could similarly write out the posterior for the other three. For hypothesis ðC; SÞ, which
assumes 1 6¼ 2, the result is
pðC; SjD1; D2; IÞ ¼ K
Z
dc1d1d2pðC; S; c1; 1; 2jIÞ
	 pðD1; D2jC; S; c1; 1; 2; IÞ:
(9:59)
Each of the four posteriors has a different numerator on the right hand side but a
common denominator, pðD1; D2jIÞ. Recall that the denominator in Bayes’ theorem,
pðD1; D2jIÞ, ensures that the posterior is normalized over this hypothesis space. In
terms of these basic hypotheses, pðD1; D2jIÞ is the sum of the four numerators and is
given by
pðD1; D2jIÞ ¼
Z
dc1d1pðC; S; c1; 1jIÞpðD1; D2jC; S; c1; 1; IÞ
þ
Z
dc1d1d2pðC; S; c1; 1; 2jIÞpðD1; D2jC; S; c1; 1; 2; IÞ
þ
Z
dc1dc2d1pðC; S; c1; c2; 1jIÞpðD1; D2jC; S; c1; c2; 1; IÞ
þ
Z
dc1dc2d1d2pðC; S; c1; c2; 1; 2jIÞ
	 pðD1; D2jC; S; c1; c2; 1; 2; IÞ:
(9:60)
9.4 Comparison of two independent samples
231

Assuming logical independence of the parameters and the data, Equation (9.57)
may be further simplified to obtain
pðC; SjD1; D2; IÞ ¼K
Z
dc1d1pðC; SjIÞpðc1jIÞpð1jIÞ
	 pðD1jC; S; c1; 1; IÞpðD2jC; S; c1; 1; IÞ;
(9:61)
where pðC; SjIÞ is the prior probability that the means and the standard deviations are
the same, pðc1jIÞ is the prior probability for the mean, pð1jIÞ is the prior probability
for the standard deviation, and pðD1jC; S; c1; 1; IÞ and pðD2jC; S; c1; 1; IÞ are the
likelihoods of the two data sets.
Assignment of priors
In this calculation we will adopt bounded uniform priors for the location parameters,
c1 and c2, and Jeffreys priors for the scale parameters, 1 and 2. Thus, for the mean,
c1, we write
pðc1jIÞ ¼
1=Rc;
if L  c1  H
0;
otherwise

(9:62)
where Rc  H  L, and H and L are the limits on the constant c1 and are assumed
known. The same prior will be used for the c2 constant.
The prior for the standard deviation, 1, of the noise component in D1, is given by
pð1jIÞ ¼
1=1 logðRÞ;
if L  1  H
0;
otherwise

(9:63)
where R is the ratio H=L, and H and L are the limits on the standard deviation 1
and are also assumed known. Again, the same prior will be assumed for 2.
We now come to the difficult issue of choosing prior ranges for the mean toxin
concentrations (the means c1 and c2 in Equations (9.53) and (9.54)), and the standard
deviations (1 and 2). Recall from Section 3.5 that in a Bayesian model selection
problem, marginalizing over parameters introduces Occam penalties, one for each
parameter. Here, the models all contain the same types of parameters, constants and
standard deviations, but they contain differing numbers of these parameters.
Consequently, the prior ranges are important and will affect model selection conclu-
sions. We also saw in Section 3.8.1 that for a uniform prior, the results are quite
sensitive to the prior boundaries.
In general, any scientific enquiry is motivated from a particular prior state of
knowledge on which we base our selection of prior boundaries. In the current instance,
the motivation is to illustrate some methodology so we will investigate the dependence
of the results on four different choices of prior boundaries as given in Table 9.2.
Finally, we need to assign a prior probability for each of the four fundamental
hypotheses: ðC; SÞ; ðC; SÞ; ðC; SÞ, and ðC; SÞ. Since the given information, I, indicates
no preference, we assign a probability of 1/4 to each.
232
Bayesian inference with Gaussian errors

There is a danger that the reader will get lost in the forest of calculations required to
evaluate the probabilities of the four fundamental hypotheses so we have moved them
to Appendix C. If you are planning on applying Bayesian analysis to a non-trivial
problem in your own research field, it often helps to see worked examples of other
non-trivial problems. Consider Appendix C as such a worked example. After we have
evaluated the four basic hypotheses, Equation (9.61) can be used to determine if the
data sets are the same. Equation (9.55) can be used to determine the probability that
the means and/or the standard deviations differ, and thus, answers the first question of
interest, ‘‘Do the samples differ?’’
9.4.2 How do the samples differ?
We now address the second question: assuming that the two samples differ, how do
they differ? There are only three possibilities: the means differ, the standard deviations
differ, or both differ. To determine if the means differ, one computes pðCjD1; D2; IÞ.
Similarly, to determine if the standard deviations differ, one computes pðSjD1; D2; IÞ.
Using the sum rule, these probabilities may be written
pðCjD1; D2; IÞ ¼ pðC; SjD1; D2; IÞ þ pðC; SjD1; D2; IÞ
(9:64)
and
pðSjD1; D2; IÞ ¼ pðC; SjD1; D2; IÞ þ pðC; SjD1; D2; IÞ
(9:65)
where pðCjD1; D2; IÞ is computed independent of whether or not the standard devia-
tions are the same, while pðSjD1; D2; IÞ is independent of whether or not the means are
the same.
9.4.3 Results
We now have expressions for computing the probability for the first nine hypotheses
appearing in Table 9.1. These calculations have been implemented in a special
Table 9.2 Different choices for lower and upper bounds on the priors for the mean and
standard deviation of the river sediment toxin concentrations.
Case
Mean lower (ppm)
Mean upper (ppm)
L lower (ppm)
H upper (ppm)
1
2
18
0.4
10
2
7
12
0.4
10
3
2
18
1
4
4
7
12
1
4
9.4 Comparison of two independent samples
233

section in the Mathematica tutorial entitled, ‘‘Bayesian analysis of two independent
samples.’’
This analysis program produces three different types of output: (1) the probability
for the four fundamental compound hypotheses; (2) the probability that the means are
different, the probability that the variances are different, and the probability that one
or both are different; and finally (3) the probability for the difference in means and the
ratio of the standard deviations. Table 9.3 illustrates the output for the prior bound-
aries corresponding to case 4 in Table 9.2, i.e., 7:0  c1; c2  12 ppm and for the
standard deviations 1  1; 2  4. The last line gives an odds ratio of 9.25 in favor
of the means and/or standard deviations being different.
Recall that the posterior probability is proportional to the product of the prior
probability and the likelihood. Following Bretthorst’s analysis, we assumed equal
Table 9.3 Output from Mathematica program: ‘‘Bayesian analysis of two independent
samples,’’ for the river sediment toxin measurements.
Data Summary
No.
Standard Deviation
Average
Data Set
12
2.1771
10.3167
river B.1
8
1.2800
8.5875
river B.2
20
2.0256
9.6251
Combined
Prior mean lower bound
7.0
Prior mean upper bound
12.0
Prior standard deviation lower bound
1.0
Prior standard deviation upper bound
4.0
Number of steps for plotting pðjD1; D2; IÞ
200
Number of steps for plotting pðrjD1; D2; IÞ
300
Hypothesis
Probability
C; S  same means, same standard deviations
0.0975
C; S  different means, same standard deviation
0.2892
C; S  same mean, different standard deviations
0.1443
C; S  different means, different standard deviations
0.4690
C  means are the same
0.2419
C  means are different
0.7581
The odds ratio in favor of different means
odds ¼ 3:13
S  standard deviations are the same
0.3867
S  standard deviations are different
0.6133
The odds ratio in favor of different standard deviations
odds ¼ 1:59
C; S  same means, same standard deviations
0.0975
C þ S  one or both are different
0.9025
The odds ratio in favor of a difference
odds ¼ 9:25
234
Bayesian inference with Gaussian errors

prior probabilities for the four compound hypotheses: pðC; SjIÞ, pðC; SjIÞ, pðC; SjIÞ,
and pðC; SjIÞ. With this assumption, the prior odds favoring different means and/or
different standard deviations ðC þ SÞ is 3.0 to 1. The data acting through the like-
lihood term are responsible for increasing this from 3 to 9.25 in this case. If instead we
had taken as our prior that pðC; SjIÞ ¼ pðC þ SjIÞ, then the posterior odds ratio
would be reduced to 3.08. It is important to remember that all Bayesian probabilities
are conditional probabilities, conditional on the truth of the data and prior informa-
tion. It is thus important in any Bayesian analysis to specify the prior used in the
analysis.
Table 9.4 illustrates the dependence of the probabilities of the different hypotheses
on different choices of prior boundaries. It is clear from the table that as we increase
our prior uncertainty, the hypotheses with more parameters to marginalize over suffer
larger Occam penalties and hence their probability is reduced compared to the simpler
hypothesis of no change. This might be a good time to review the material on the
Occam factor in Section 3.5. In all cases, the odds ratio, Oddsdiff, favoring different
means and/or standard deviations, exceeds 1. In this analysis, we have purposely
considered four choices of prior boundaries to see what effect the different boundaries
have on the final results. It often requires some careful thought to translate the
available background information into an appropriate choice of prior parameter
boundaries. Otherwise one might make these boundaries artificially large and as a
consequence, the probability of a possibly correct complex model will decrease in
relation to simpler models.
How do the present results compare to our earlier frequentist test of the null
hypothesis that the mean toxin concentrations are the same (see Section 7.2.2)? On
the basis of that analysis, we obtained a P-value ¼ 0:04 and thus rejected the null
hypothesis at the 96% confidence level. The frequentist P-value is often incorrectly
viewed as the probability that the null hypothesis is true. The Bayesian conclusion
regarding the question of whether the means are the same is given by
pðCÞ ¼ 1  pðCÞ. Although this depends on our prior uncertainty in the means
and standard deviations of two samples, the minimum value for pðCÞ according to
Table 9.4 is  1  0:76 ¼ 0:24. The difficulty in interpreting P-values and confidence
Table 9.4 Dependence of the probabilities of the hypotheses of interest on the different
prior boundaries given in Table 9.2. See Table 9.1 for the meaning of the different
hypotheses.
#
pðC; SÞ
pðC; SÞ
pðC; SÞ
pðC; SÞ
pðCÞ
pðSÞ
pðC þ SÞ
Oddsdiff
1
0.293
0.276
0.209
0.222
0.498
0.431
0.707
2.41
2
0.141
0.420
0.101
0.338
0.757
0.439
0.858
6.06
3
0.202
0.190
0.299
0.308
0.499
0.607
0.798
3.95
4
0.098
0.289
0.144
0.469
0.758
0.613
0.902
9.25
9.4 Comparison of two independent samples
235

levels has been highlighted in many papers (e.g., Berger and Sellke, 1987; Delampady
and Berger, 1990; Sellke et al., 2001). The focus of these works is that P-values are
commonly considered to imply considerably greater evidence against the null
hypothesis than is actually warranted.
Now that one knows that the means and/or standard deviations are not the same, or
at the very least are probably not the same, one would like to know what is different
between the control and the trial. Are the means different? Are the standard deviations
different? Examination of Table 9.4 indicates that the probability the means differ is
0.758, for the choice of prior boundaries corresponding to case 4. The probability that
the standard deviations differ is 0.613.
Using the calculations presented so far, one can determine if something is different,
and then determine what is different. But after determining what is different, again
one’s interest in the problem changes. The next step is to estimate the magnitude of the
changes.
9.4.4 The difference in means
To estimate the difference in means, one must first introduce this difference into the
problem. Defining  and  to be the difference and sum, respectively, of the constants
c1 and c2, one has
 ¼ c1  c2;
 ¼ c1 þ c2:
(9:66)
The two constants, c1 and c2, are then given by
c1 ¼  þ 
2
;
c2 ¼   
2
:
(9:67)
The probability for the difference, , is then given by
pðjD1; D2; IÞ ¼ pð; SjD1; D2; IÞ þ pð; SjD1; D2; IÞ
¼ pðSjD1; D2; IÞpðjS; D1; D2; IÞ
þ pðSjD1; D2; IÞpðjS; D1; D2; IÞ:
(9:68)
This is a weighted average of the probability for the difference in means given that
the standard deviations are the same (the two-sample problem) and the probability for
the difference in means given that the standard deviations are different (the
Behrens–Fisher problem). The weights are just the probabilities that the standard
deviations are the same or different. Two of these four probabilities, pðSjD1; D2; IÞ and
pðSjD1; D2; IÞ ¼ 1  pðSjD1; D2; IÞ, have already been computed in Equation (9.65).
The other two probabilities, pðjS; D1; D2; IÞ and pðjS; D1; D2; IÞ, are derived in
Appendix C.3. Figure 9.6 shows the probability density function for the difference
in means for the prior boundaries corresponding to case 4 of Table 9.2. Three curves
are shown: the probability for the difference in means given that the standard
236
Bayesian inference with Gaussian errors

deviations are the same (dotted line); the probability for the difference in means given
that the the standard deviations are different (dashed line); and the probability for the
difference in means independent of whether or not the standard deviation are the same
(solid line).
All three curves are very similar but it is possible to notice small differences
especially near the peak. The parameters listed along the top border of the figure
are the peak and mean of the distribution, and the lower and upper boundaries of
the 95% credible region. These apply to the weighted average distribution (solid
curve).
9.4.5 Ratio of the standard deviations
To estimate the ratio of the standard deviations, this ratio must first be introduced into
the problem. Defining r and  to be
r ¼ 1
2
;
 ¼ 2
(9:69)
and substituting these into the model, Equations (9.53) and (9.54), one obtains
d1i ¼ c1 þ noise of standard deviation r;
(9:70)
and
d2i ¼ c2 þ noise of standard deviation :
(9:71)
–1
0
1
2
3
4
δ Mean toxin level difference (ppm)
0
0.1
0.2
0.3
0.4
Probability density
Peak = 1.75; mean = 1.73; 95% lower = 0; 95% upper = 3.5
p (δ |S, D1, D2, I )
p (δ |S, D1, D2, I )
average
Figure 9.6 Three probability density functions are shown: the probability for the difference in
means given that the standard deviations are the same (dotted line); the probability for the
difference in means given that the the standard deviations are different (dashed line); and the
probability for the difference in means independent of whether or not the standard deviation are
the same (solid line).
9.4 Comparison of two independent samples
237

The probability for the ratio of the standard deviations, pðrjD1; D2; IÞ, is then
given by
pðrjD1; D2; IÞ ¼ pðr; CjD1; D2; IÞ þ pðr; CjD1; D2; IÞ
¼ pðCjD1; D2; IÞpðrjC; D1; D2; IÞ
þ pðCjD1; D2; IÞpðrjC; D1; D2; IÞ:
(9:72)
This is a weighted average of the probability for the ratio of the standard deviations
given that the means are the same plus the probability for the ratio of the standard
deviations given that the means are different. The weights are just the probabilities
that the means are the same or not. Two of the four probabilities, pðCjD1; D2; IÞ and
pðCjD1; D2; IÞ ¼ 1  pðCjD1; D2; IÞ, have already been computed in Equation (9.64).
The other two probabilities, pðrjC; D1; D2; IÞ and pðrjC; D1; D2; IÞ, are derived in
Appendix C.4.
In case 4 of Table 9.4, there is significant evidence in favor of the means being
different. Thus, we might expect that the probability for the ratio of the standard
deviations, assuming the same means, will differ from the probability for the ratio of
the standard deviations assuming that the means are different.
These two distributions, as well as the weighted average, are shown in Figure 9.7.
The probability for the ratio of the standard deviations, assuming that the means are
the same, is shown as the dotted line. This model does not fit the data as well (the
pooled data have a larger standard deviation than either data set separately).
Consequently, the uncertainty in this probability distribution is larger compared to
0
0.5
1
1.5
2
2.5
3
3.5
r  Standard deviation ratio
0
0.2
0.4
0.6
0.8
Probability density
Peak = 1.45; Mean = 1.61; 95% lower = 0.59; 95% upper = 2.7
p (r |C, D1, D2, I )
p (r |C, D1, D2, I )
average
Figure 9.7 Probability density for the ratio of the standard deviations. Three probability density
functions are shown: the probability for the ratio of standard deviations given that the means
are the same (dotted line); the probability for the ratio of standard deviations given that the
means are different (dashed line); the probability for the ratio of standard deviations indepen-
dent of whether or not the means are the same (solid line).
238
Bayesian inference with Gaussian errors

the other models and the distribution is more spread out. The probability for the ratio
of standard deviations assuming different means is shown as the dashed line. This
model fits the data better, and results in a more strongly peaked probability distribu-
tion. But probability theory tells one to take a weighted average of these two distribu-
tions, the solid line. The weights are just the probabilities that the means are the same
or different. Here those probabilities are 0.242 and 0.758, respectively. As expected,
the weighted average agrees more closely with pðrjC; D1; D2; IÞ. The parameters listed
along the top border of the figure apply to the weighted average distribution (solid
curve).
9.4.6 Effect of the prior ranges
We have already discussed the effect of different prior ranges on the model selection
conclusions (see Table 9.4). Here we look at their effect on the two-parameter
estimation problems. Figure 9.8 shows the weighted average estimate of the difference
in the means of the two data sets as given by Equation (9.68), for the four choices of
prior boundaries. The results for all four cases are essentially identical. Provided the
prior ranges are outside the parameter range selected by the likelihood function, we
don’t expect much of an effect. This is because in a parameter estimation problem we
are comparing a continuum of hypotheses all with the same number of parameters so
the Occam factors cancel. However, since we are plotting the weighted average of the
two-sample calculation and the Behrens–Fisher calculation, in principle, the prior
ranges can affect the weights differently and lead to a small effect. This is particularly
–1
0
1
2
3
4
δ Mean toxin level difference (ppm)
0
0.1
0.2
0.3
0.4
Probability density
Case 4
Case 3
Case 2
Case 1
Figure 9.8 Posterior probability of the differences in the mean river sediment toxin concentra-
tion for the four different choices of prior boundaries given in Table 9.2. The effects of different
choices of prior boundaries are barely discernible near the peak.
9.4 Comparison of two independent samples
239

noticeable in the case of the estimation of the standard deviation ratio shown in Figure
9.9, which is a weighted average (Equation (9.72)) of the result assuming no difference
in the means and the result which assumes the means are different.
9.5 Summary
This whole chapter has been concerned with Bayesian analysis of problems when our
prior information (state of knowledge) leads us to assign a Gaussian sampling
distribution when calculating the likelihood function. In some cases, we do this
because, in the absence of knowledge of the true sampling distribution, employing a
Gaussian distribution is the most conservative choice for the reasons given in Section
8.7.4. We examined a simple model parameter estimation problem – namely, estimat-
ing a mean. We started with data for which the  of the Gaussian sampling distribu-
tion was a known constant. This was extended to the case where  is known but is not
the same for all data. Often, nature is more complex than the assumed model and gives
rise to residuals which are larger than the instrumental measurement errors. We dealt
with this by treating  as a nuisance parameter which we marginalize over, leading to a
Student’s t PDF. This has the desirable effect of treating anything in the data that can’t
be explained by the model as noise, leading to the most conservative estimates of
model parameters.
The final section of this chapter dealt with a Bayesian analysis of two independent
samples of some physical quantity taken under slightly different conditions, and we
wanted to know if there has been a change. The numerical example deals with toxin
concentrations in river sediment which are taken at two different locations. One
location might be upriver from a power plant and the other just downstream. What
other examples can you think of where this type of analysis might be useful? The
0
1
2
3
4
r Standard deviation ratio
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Probability density
Case 4
Case 3
Case 2
Case 1
Figure 9.9 Posterior probability for the ratio of standard deviations of the river sediment toxin
concentration for the four different choices of prior boundaries given in Table 9.2.
240
Bayesian inference with Gaussian errors

Bayesian analysis allows the experimenter to investigate the problem in ways never
before possible. The details of this non-trivial problem are presented in Appendix C,
and Mathematica software to solve the problem is included in the accompanying
Mathematica tutorial.
9.6 Problems
1. Vi is a set of ten voltage measurements with known but unequal independent
Gaussian errors i.
Vi ¼ f4:36; 4:00; 4:87; 5:64; 6:14; 5:92; 3:93; 6:58; 3:78; 5:84g
i ¼ f2:24; 1:94; 1:39; 2:55; 1:69; 1:38; 1:00; 1:60; 1:00; 1:00g
a) Compute the weighted mean value of the voltages.
b) Compute and plot the Bayesian posterior probability density for the mean
voltage assuming a uniform prior for the mean in the range 3 to 7.
c) Find the 68.3 % credible region for the mean and compare the upper and lower
boundaries to
 þ mean
  mean
where
 ¼
PN
i widi
PN
i wi
;
(9:73)
and
2
mean ¼
1
PN
i wi
;
wi ¼ 1=2
i :
(9:74)
d) Compute and plot the Bayesian posterior probability density for the mean
voltage assuming a uniform prior for the mean in the range 4.6 to 5.4. Be sure
your probability density is normalized to an area of 1 in this prior range. Plot the
posterior over the mean range 3 to 7. (Hint: For plotting you may find it useful to
examine the item ‘‘Define a function which has a different meaning in different
ranges of x’’ in the section ‘‘Functions and Plotting’’ of the Mathematica tutorial.)
e) Find the new 68 % credible region for the mean based on (d) and compare with
that found in (c).
2. In Section 9.2.3, we derived the Bayesian estimate of the mean assuming the noise 
is unknown. The desired quantity, pðjD; IÞ, was obtained from the joint posterior
9.6 Problems
241

pð; jD; IÞ by marginalizing over the nuisance parameter , leading to Equation
(9.34). Would we have arrived at the same conclusion if we had started from the
joint posterior pð; 2jD; IÞ and marginalized over the variance, 2? To answer this
question, re-derive Equation (9.34) for this case.
3. Table 7.5 gives measurements of the concentration of a toxic substance at two
locations in units of parts per million (ppm). The sampling is assumed to be from
two independent normal populations. Assume a uniform prior for the unknown
mean concentrations, and a Jeffreys prior for the unknown s. Use the material
discussed in Section 9.4 to evaluate the items (a) to (f) listed below, for two different
choices of prior ranges for the means and standard deviations. These two choices are:
1) mean (1,18), ð0:1; 12Þ
2) mean (7,13), ð1:0; 4:0Þ
Note: the prior ranges for the mean and standard deviation are assumed to be the
same at both locations.
a) The probabilities of the four models:
i. two data sets have same mean and same standard deviation,
ii. have different means and same standard deviation,
iii. have same mean and different standard deviations,
iv. have different means and different standard deviations.
b) The odds ratio in favor of different means.
c) The odds ratio in favor of different standard deviations.
d) The odds ratio in favor of different means and/or different standard deviations.
e) Plot a graph of the probability of the difference in means assuming the standard
deviations are (i) the same, (ii) different, and (iii) regardless of whether or not
the standard deviations are the same. Plot the result for all three on the same
graph.
f) Plot a graph of the probability of the ratio of standard deviations assuming the
means are (i) the same, (ii) different, and (iii) regardless of whether or not the
means are the same. Plot all three on the same graph.
g) Explain the changes in the probabilities of the four models that occur as a result
of a change in the prior ranges of the parameters, in terms of the Occam’s
penalty.
These calculations have been implemented in a special section in the Mathematica
tutorial accompanying this book. The section is entitled, ‘‘Bayesian analysis of two
independent samples.’’
242
Bayesian inference with Gaussian errors

10
Linear model fitting (Gaussian errors)
10.1 Overview
An important part of the life of any physical scientist is comparing theoretical models
to data. We now begin three chapters devoted to the nuts and bolts of model fitting. In
this chapter, we focus on linear models.1 By a linear model, we mean a model that is
linear with respect to the model parameters, not (necessarily) with respect to the
indicator variables labeling the data. We will encounter the method of linear least-
squares, which is so familiar to most undergraduate science students, but we will see it
as a special case in a more general Bayesian treatment.
Examples of linear models:
1. fi ¼ A0 þ A1xi þ A2x2
i þ   
where A0, A1; . . . are the linear model parameters,
and xi is the independent (indicator) variable.
2. fi;j ¼ A0 þ A1xi þ A2yj þ A3xiyj
where A0, A1; . . . are the linear model parameters,
and xi; yj are a pair of independent variables.
3. fi ¼ A1 cos !ti þ A2 sin !ti
where A1, A2 are the linear model parameters,
and ! is a known constant.
4. Ti ¼ Tfi;
where T is the linear parameter,
and fi is a Gaussian line shape of the form fi ¼ exp
ðioÞ2
22
L
n
o
;
and o and L are known constants.
Such a model was considered previously in Section 3.6.
It is important to distinguish between linear and nonlinear models. In the fourth
example, Ti is called a linear model because Ti is linearly dependent on T. On the other
hand, if the center frequency o and/or line width L were unknown, then Ti would be
1 About 10 years ago, Tom Loredo circulated some very useful notes on this topic. Those notes formed the starting point
for my own treatment, which is presented in this chapter.
243

a nonlinear model. Nonlinear parameter estimation will be considered in the following
chapter.
In Section 10.2, we first derive the posterior distribution for the amplitudes
(i.e., parameters) of a linear model for a signal contaminated with Gaussian noise.
A remarkable feature of linear models is that the joint posterior probability distribu-
tion pðA1; . . . ; AnjD; IÞ of the parameters is a multivariate (multi-dimensional)
Gaussian if we assume a flat prior.2 That means that there is a single peak in the
joint posterior. We derive the most probable amplitudes (which are the same as those
found in linear least-squares) and their errors. The errors are given by an entity called
the covariance matrix of the parameters, which we will introduce in Section 10.5.1. We
also revisit the use of the 2 statistic to assess whether we can reject the model in a
frequentist hypothesis test. In Section 10.3, we briefly consider the relationship
between least-squares model fitting and regression analysis.
In most of this chapter, we assume that the data errors are independent and identi-
cally distributed (IID). In Section 10.2.2, we show how to generalize the results to allow
for data errors with standard deviations that are not equal and also not independent.
We will also show how to find the boundaries of the full joint credible regions using
the 2 distribution. We then consider how to calculate the marginal probability
distribution for individual model parameters, or for a subset of amplitudes of parti-
cular interest. A useful property of Gaussian joint posterior distributions allows us to
calculate any marginal distribution by maximizing with respect to the uninteresting
amplitudes, instead of integrating them in a marginalization operation which is in
general more difficult.
Finally, we derive some results for Bayesian model comparison with Gaussian pos-
teriors and consider some other schemes to decide on the optimum model complexity.
10.2 Parameter estimation
Our task is to infer the parameters of some model function, f, that we sample in the
presence of noise. We assume that we have N data values, di, that are related to N
values of the function fi, according to
di ¼ fi þ ei;
(10:1)
where ei represents an unknown ‘‘error’’ component in the measurement of fi. We
assume that our knowledge (or lack thereof !) of the source of the errors is described by
a Gaussian distribution for the ei.3 For now, we assume the distribution for each ei to
2 Though only a linear model leads to an exactly Gaussian posterior, nonlinear models may be approximately Gaussian
close to the peak of their posterior probability.
3 If the only knowledge we have about the noise is that it has a finite variance, then the MaxEnt principle of Chapter 8
tells us to assume a Gaussian. This is because it makes the fewest assumptions about the information we don’t have and
will lead to the most conservative estimates, i.e., greater uncertainty than we would get from choosing a more
appropriate distribution based on more information.
244
Linear model fitting (Gaussian errors)

be independent of the values of the other errors, and that all of the error distributions
have a common standard deviation, . We will later generalize the results to remove
the restriction of equal and independent data errors.
By a linear model, we mean that fi can be written as a linear superposition of M
functions, gi, where gi is the value of the th known function for the ith datum. The
M functions are each completely specified (they have no parameters); it is their relative
amplitudes that are unknown and to be inferred. Denoting the coefficients of the
known functions by A, we thus have
fiðAÞ ¼
X
M
¼1
Agi:
(10:2)
Our task is to infer fAg, which we will sometimes denote collectively with an
unadorned A, as we have here. For example, if
fi ¼ A1 þ A2xi þ A3x2
i þ A4x3
i þ    ¼
X
M
¼1
Agi;
(10:3)
then gi ¼ f1; xi; x2
i ; . . .g.
Note: to avoid confusing the various indices that will arise in this calculation, we
are using Roman indices to label data values and Greek indices to label model basis
functions. Thus, Roman indices can take on values from 1 to N, and Greek indices can
take on values from 1 to M. When limits in a sum are unspecified, the sum should be
taken over the full range appropriate to its index.
Our goal is to compute the joint posterior probability distribution of the parameters,
pðA1; . . . ; AMjD; IÞ. According to Bayes’ theorem, this will require us to specify priors
for the parameters and to evaluate the likelihood function. The likelihood function is
the joint probability for all the data values, which we denote collectively by D, given all
of the parameters specifying the model function, fi. This is just the probability that the
difference between the data and the specified function values is made up by the noise.
With identical, independent Gaussians for the errors, the likelihood function is simply
the product of N Gaussians, one for each of the ei ¼ di  fi. Figure 10.1 illustrates
graphically the basis for the calculation of the likelihood function pðDjfAgIÞ for a
model fi of the form fi ¼ A1 þ A2xi þ A3x2
i . The smooth curve is the model prediction
for a specific choice of the parameters, namely A1 ¼ 0:5; A2 ¼ 0:8; A3 ¼ 0:06. The
predicted values of fi for each choice of the independent variable xi are marked by a
dashed line. The actual measured value of di (represented by a cross) is located at the
same value of xi but above or below fi as a result of the uncertainty ei. Since the
distribution of ei values is assumed to be Gaussian, at the location of each fi value,
we have constructed a Gaussian probability density function (which we call a tent) for ei
along the line of fixed xi, with probability plotted in the z-coordinate.
10.2 Parameter estimation
245

We have assumed that the width of each Gaussian curve, determined by i, is the
same for all fi but in principle they can all be different. For the assumed choice of
model parameters, the probability of any di is proportional to the height of the
Gaussian curve directly above the data point which is shown by the solid line.
The probability of the data set D is proportional to the product of these Gaussian
heights. As we vary the choice of model parameters, the locations of the fi points and
Gaussian tents move up and down while the measured data points stay fixed. For
some choice of model parameters, the likelihood will be a maximum. It should be clear
that the particular choice of model parameters illustrated in the figure is far from
optimal, since the data values are systematically above the model. A better choice of
parameters would have the data values distributed about the model. Of course, if our
prior information indicated that the probability density function for ei had a different
non-Gaussian shape, then we only need to change the shape of the probability tents.
2
3
Probability
density
0
5
10
15
x-axis
–2
0
2
4
y-axis
0
1
Figure 10.1 This figure illustrates graphically the basis for the calculation of the likelihood
function pðDjfAgIÞ for a model fi of the form fi ¼ A1 þ A2xi þ A3x2
i . The smooth curve is the
model prediction for a specific choice of the parameters. The predicted values of fi for each
choice of the independent variable xi are marked by a dashed line. The actual measured value of
di (represented by a cross) is located at the same value of xi but above or below fi as a result of the
uncertainty ei. At the location of each fi value we have constructed a Gaussian probability
density function (tent) for ei along the line of fixed xi, with probability plotted in the
z-coordinate. For the assumed choice of model parameters, the probability of any di is propor-
tional to the height of the Gaussian curve directly above the data point which is shown by the
solid line.
246
Linear model fitting (Gaussian errors)

The product of these N IID Gaussians is given by
pðDjfAg; IÞ ¼
1
Nð2pÞN=2 exp  1
22
X
N
i¼1
ðdi  fiÞ2
"
#
¼
1
Nð2pÞN=2 eQ=22:
(10:4)
In Equation (10.4), the quadratic form QðfAgÞ is
QðfAgÞ ¼
X
N
i¼1
ðdi  fiÞ2
¼
X
N
i¼1
di 
X
M
¼1
Agi
 
!2
¼
X
N
i¼1
d2
i þ
X
N
i¼1
X

AAgigi  2
X
N
i¼1
di
X
M
¼1
Agi:
(10:5)
To get to our destination, we will take advantage of the quadratic nature of
Gaussians to simplify our notation. The new notation will not only make things
look simpler, it will actually simplify the calculations themselves, and their
interpretation.
The new notation will eliminate Roman (data) indices by denoting such quantities
as vectors. Thus, the N data are written as ~d, the N values of the total model are written
as~f, the N error values are written as~e, and the M model functions are written as ~g. In
terms of these N-dimensional vectors, the data equation is
~d ¼ ~f þ ~e;
(10:6)
with
~f ¼
X

A~g:
(10:7)
Note: ~f is the sum of M vectors, where usually M5N. Thus, the model spans an
M-dimensional subspace of the N-dimensional data space. Actually, if one or more of
the ~g ’s can be written as a linear superposition of the others, the model spans a
subspace of dimension less than M. Hereafter, we will refer to the ~g ’s as the basis
functions for the model.
10.2 Parameter estimation
247

The quadratic form is Q ¼ ð~d  ~fÞ2 ¼ ~e ~e ¼ e2, the squared magnitude of the error
vector extending from ~f to ~d. In terms of the basis functions, the quadratic form can be
written
QðfAgÞ ¼ ð~d  ~fÞ2
¼ d2 þ f2  2~d  ~f
¼ d2 þ
X

AA~g  ~g  2
X

A~d  ~g
¼ d2 þ
X

A2
~g  ~g þ 2
X
6¼
AA~g  ~g  2
X

A~d  ~g;
(10:8)
where we follow the usual notation, ~a  ~b ¼ P
i aibi, and a2 ¼ ~a  ~a. It follows that
X

AA~g  ~g ¼
X

AA
X
i
gigi;
(10:9)
where
X

¼
X
M
¼1
X
M
¼1
:
(10:10)
~g  ~g and ~d  ~g are easily computable from the data values di and the corresponding
values of the basis functions gi.
To estimate the amplitudes, we need to assign a prior density to them. We will
simply use a uniform prior that is constant over some range A for each parameter,
so that
pðfAgjIÞ ¼
1
Q
 A
:
(10:11)
Then as long as we are inside the prior range, the posterior density for the ampli-
tudes is just proportional to the likelihood function
pðfAgjD; IÞ ¼ CeQðfAgÞ=22:
(10:12)
Outside the prior range, the posterior vanishes. In this equation, C is a normal-
ization constant4
C ¼ pðfAgjIÞ
pðDjIÞ
;
(10:13)
4 This is only true for the choice of a uniform prior for pðfAgjIÞ appropriate for amplitudes which are location
parameters. For a scale parameter like a temperature, we should use a Jeffreys prior and then C is no longer a constant.
However, for many parameter estimation problems, the likelihood function selects out a very narrow range of the
parameter space over which a Jeffreys prior is effectively constant. Thus, the exact choice of prior used is only critical if
there are few data or we are dealing with a model selection problem. In the latter case, the choice of prior can have a big
effect as we saw in Section 3.8.1.
248
Linear model fitting (Gaussian errors)

where the global likelihood in the denominator is
pðDjIÞ ¼
Z
A
dMApðfAgjIÞpðDjA; IÞ
¼
1
Q
 A
1
Nð2pÞN=2
Z
A
dMAeQ=22:
(10:14)
We can calculate the value of C if needed – indeed, we will do so below when we
discuss model comparison – but since it is independent of the A, we don’t need to
know it to address many parameter estimation questions.
The full joint posterior distribution given by Equation (10.12) is the Bayesian
answer to the question, ‘‘What do the data tell us about the A parameters?’’ It is
usually useful to have simple summaries of the posterior, especially if it is of high
dimension, in which case it is often difficult to depict it (either mentally or graphically).
We will devote the next few subsections to finding point estimates for the amplitudes
(most probable and mean values) and credible regions. We’ll also discuss how to
summarize the implications of the data for a subset of the amplitudes by marginalizing
out the uninteresting amplitudes. In fact, since the mean amplitudes require integrat-
ing the posterior over the A, we’ll have to learn how to do such marginalization
integrals before we can calculate the mean amplitudes.
10.2.1 Most probable amplitudes
The most probable values for the amplitudes are the values that maximize the pos-
terior (Equation (10.12)), which (because of our uniform prior) are the values that
minimize Q and lead to the ‘‘normal equations’’ of the method of least-squares.
Denoting the most probable values by ^A, we can find them by solving the following
set of M equations (one for each value of ):
@Q
@A

A¼ ^A
¼ 2
X

^A~g  ~g  2~g  ~d ¼ 0;
(10:15)
or,
X

^A~g  ~g ¼ ~g  ~d:
(10:16)
For the M ¼ 2 case, Equation (10.16) corresponds to the two equations
^A1~g1  ~g1 þ ^A2~g2  ~g1 ¼ ~g1  ~d
(10:17)
and
^A1~g1  ~g2 þ ^A2~g2  ~g2 ¼ ~g2  ~d:
(10:18)
10.2 Parameter estimation
249

Define the most probable model vector, ^~f, by
^~f ¼
X

^A~g:
(10:19)
Using ^~f, Equation (10.16) can be written as
^~f  ~g ¼ ~g  ~d:
(10:20)
This doesn’t help us solve Equation (10.16), but it gives us a bit of insight: the most
probable total model function is the one whose projection on each basis function
equals the data’s projection on each basis function. Crudely, the most probable model
vector explains as much of the data as can be spanned by the M-dimensional model
basis.
Equations (10.17) and (10.18) can be written in the following matrix form:
~g1  ~g1
~g2  ~g1
~g1  ~g2
~g2  ~g2


^A1
^A2


¼
~g1  ~d
~g2  ~d


:
(10:21)
Problem: Evaluate Equation (10.21) for a straight line model.
Solution: When fitting a straight line, f ¼ A1 þ A2x, the two basis functions are gi1 ¼ 1
and gi2 ¼ xi. In this case, the matrix elements are given by:
~g1  ~g1 ¼
X
N
i
g2
i1 ¼
X
N
i
1 ¼ N;
(10:22)
~g1  ~g2 ¼ ~g2  ~g1 ¼
X
N
i
gi1gi2 ¼
X
N
i
xi;
(10:23)
~g2  ~g2 ¼
X
N
i
gi2gi2 ¼
X
N
i
x2
i ;
(10:24)
~g1  ~d ¼
X
N
i
gi1di ¼
X
N
i
di;
(10:25)
~g2  ~d ¼
X
N
i
dixi;
(10:26)
250
Linear model fitting (Gaussian errors)

and Equation (10.21) becomes
N
P
i xi
P
i xi
P
i x2
i


^A1
^A2


¼
P
i di
P
i dixi


:
(10:27)
It will prove useful to express Equation (10.16) in a more compact matrix form.
Let G be an N  M matrix where the th column contains N values of the th basis
function evaluated at each of the N data locations. As an example, consider the M ¼ 2
case again. The two basis functions for the ith data value are gi1 and gi2, and G is given by
G 
g11
g12
g21
g22






gN1
gN2
0
B
B
B
B
B
B
@
1
C
C
C
C
C
C
A
:
(10:28)
Now take the transpose of G which is given by
GT 
g11
g21



gN1
g12
g22



gN2


:
(10:29)
Define the matrix y ¼ GTG, which for M ¼ 2 is given by
y 
P
i g2
i1
P
i gi1gi2
P
i gi2gi1
P
i g2
i2
 
!
¼
g2
1
~g1  ~g2
~g2  ~g1
g2
2
 
!
¼
 11
 12
 21
 22
 
!
:
(10:30)
Thus, y is a symmetric matrix because ~g1  ~g2 ¼ ~g2  ~g1. More generally,
  ¼ ~g  ~g ¼  :
(10:31)
Finally, if D is a column matrix of data values di, then for M ¼ 2
GTD 
P
i gi1di
P
i gi2di


¼
~g1  ~d
~g2  ~d


:
(10:32)
Equation (10.21) can now be written as
GTG^A ¼ GTD:
(10:33)
The solution to this matrix equation is given by
^A ¼ ðGTGÞ1GTD ¼ y1GTD;
(10:34)
10.2 Parameter estimation
251

or in component form becomes
^A ¼
X

½y1~g  ~d:
(10:35)
In the method of least-squares, the set of equations represented by Equation (10.33)
are referred to as the normal equations.
Again, for the M ¼ 2 case, we can write Equation (10.33) in long form:
 11
 12
 21
 22


^A1
^A2


¼
~g1  ~d
~g2  ~d


;
(10:36)
where  12 ¼  21. The solution (Equation (10.34)) is given by
^A1
^A2


¼ 1

 22
 12
 21
 11


~g1  ~d
~g2  ~d


;
(10:37)
and where  12 ¼  21 and the denominator, , is the determinant of the y matrix
given by
 ¼ ð 11 22   2
12Þ:
(10:38)
^A1 ¼  22ð~g1  ~dÞ   12ð~g2  ~dÞ
 11 22   2
12
(10:39)
^A2 ¼  12ð~g1  ~dÞ þ  11ð~g2  ~dÞ
 11 22   2
12
:
(10:40)
Note: the matrix must be non-singular – the basis vectors must be linearly independent –
for a solution to exist. We henceforth assume that any redundant basis models have been
eliminated, so that y is non-singular.5
Problem: Evaluate Equation (10.34) for the straight line model.
Solution: Comparison of Equations (10.27) and (10.36) allows an evaluation of all the
terms needed for Equations (10.39) and (10.40).
^A1 ¼
P
i x2
i
P
i di  P
i xi
P
i xidi
N P
i x2
i  ðP
i xiÞ2
^A2 ¼  P
i xi
P
i di þ N P
i xidi
N P
i x2
i  ðP
i xiÞ2
:
5 Sometimes the data do not clearly distinguish between two or more of the basis functions provided, and y gets
sufficiently close to being singular that the answer becomes extremely sensitive to round-off errors. The solution in this
case is to use singular value decomposition which is discussed in Appendix A.
252
Linear model fitting (Gaussian errors)

10.2.2 More powerful matrix formulation
Everything we have done so far has assumed that the error associated with each datum
is independent of the errors for the others, and that the Gaussian describing our
knowledge of the magnitude of the error has the same variance for each datum. In
general, however, the errors can have different variances, and could be correlated. In
that case, we need to replace the likelihood function pðDjfAg; IÞ, given by Equation
(10.4), by the multivariate Gaussian (Equation (8.61)) which we derived using the
MaxEnt principle in Section 8.7.5 and Appendix E. The new likelihood is
pðDjfAg; IÞ ¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2
X
ij
ðdi  fiÞ½E1ijðdj  fjÞ
"
#
¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
e2=2;
(10:41)
where E is called the data covariance matrix6
E ¼
11
12
13
  
1N
21
22
23
  
2N





N1
N2
N3
  
NN
0
B
B
@
1
C
C
A;
(10:42)
and
X
ij
¼
X
N
i¼1
X
N
j¼1
:
How does this affect the ‘‘normal equations’’ of the method of least-squares? We
simply need to replace Q=2 appearing in the likelihood, Equation (10.4), by
2 ¼
X
i;j
ðdi  fiÞ½E1ijðdj  fjÞ:
(10:43)
If the errors are independent, E is diagonal, with entries equal to 2
i , and Equation
(10.43) takes the familiar form
2 ¼
X
i
ðdi  fiÞ2
2
i
¼
X
i
e2
i
2
i
:
(10:44)
The inverse data covariance matrix, E1, plays the role of a metric7 in the full
N-dimensional vector space of the data. Thus, if we set  ¼ 1, and understand ~a  ~b
6 If we designate each element in the covariance matrix by ij, then the diagonal elements are given by ii ¼ 2
i ¼ he2
i i,
where he2
i i is the expectation value of e2
i . The off-diagonal elements are ij ¼ heieji ði 6¼ jÞ.
7 The metric of a vector space is useful for answering questions having to do with the geometry of the vector space, such
as the distance between two points. In our work, we use it to compute the dot product in the vector space.
10.2 Parameter estimation
253

to stand for ~a½E1~b everywhere a dot product occurs in the above analysis, then we
already have the desired generalization! Thus, we have that
~d  ~d ¼
X
ij
di½E1ijdj
(10:45)
and
~g  ~g ¼
X
ij
gi½E1ijgj:
(10:46)
The new equivalents of Equations (10.33) and (10.34) are
GTE1G^A ¼ GTE1D
(10:47)
^A ¼ ðGTE1GÞ1GTE1D ¼ Y1GTE1D:
(10:48)
To bring out the changes more clearly, we repeat our earlier Equation (10.34) for the
model amplitudes.
^A ¼ ðGTGÞ1GTD ¼ y1GTD:
(10:49)
Notice that whenever we employ E, we need to replace y by its capitalized form Y.
Recall the matrix y did not incorporate information about the data errors while Y
does. In the case that the data errors all have the same  and are independent, then
Y ¼  =2. The following problem employs the Y matrix for the case of independent
errors. We consider a problem with correlated errors in Section 10.6 after we have
introduced the correlation coefficient.
Problem: Fit a straight line model to the data given in Table 10.1, where di is the average
of ni data values measured at xi. The probability of the individual di measurements is IID
normal with 2 ¼ 8:1, regardless of the xi value. Recall from the Central Limit Theorem,
Table 10.1 Data table.
xi
di
ni
10
0.5
14
20
4.67
3
30
6.25
25
40
10.0
2
50
13.5
3
60
13.7
22
70
17.5
5
80
23.0
2
254
Linear model fitting (Gaussian errors)

pðdijIÞ will tend to a Gaussian with variance ¼ 2=ni as ni increases even if pðdijIÞ is very
non-Gaussian.
Solution: The data covariance matrix E can be written as
E ¼ 2
1=n1
0
0
  
0
0
1=n2
0
  
0
0
0
1=n3
  
0





0
0
  
0
1=nN
0
B
B
B
B
@
1
C
C
C
C
A
:
(10:50)
The inverse data covariance matrix E1 is
E1 ¼ 1
2
n1
0
0
  
0
0
n2
0
  
0
0
0
n3
  
0





0
0
  
0
nN
0
B
B
B
B
B
B
@
1
C
C
C
C
C
C
A
¼ 1
2
14
0
0
  
0
0
3
0
  
0
0
0
25
  
0





0
0
  
0
2
0
B
B
B
B
B
B
@
1
C
C
C
C
C
C
A
:
(10:51)
Y ¼ GTE1G
¼
1
1
1
  
1
10
20
30
  
80

 1
2
14
0
0
  
0
0
3
0
  
0
0
0
25
  
0





0
0
  
0
2
0
B
B
B
B
B
B
@
1
C
C
C
C
C
C
A
1
10
1
20
1
30


1
80
0
B
B
B
B
B
B
@
1
C
C
C
C
C
C
A
¼ 1
2
76
3010
3010
152 300


:
(10:52)
Y1 ¼ 2
0:061
0:0012
0:0012
0:000030


:
(10:53)
Let R ¼ GTE1D
¼
1
1
1
  
1
10
20
30
  
80

 1
2
14
0
0
  
0
0
3
0
  
0
0
0
25
  
0





0
0
  
0
2
0
B
B
B
B
@
1
C
C
C
C
A
0:5
4:67
6:25

23:0
0
B
B
B
B
@
1
C
C
C
C
A
:
(10:54)
10.2 Parameter estimation
255

Then,
^A ¼ Y1R:
(10:55)
^
A1
^
A2


¼
2:054
0:275


:
(10:56)
Figure 10.2 shows the straight line model fit, y ¼ 0:275x  2:054, with the data plus
error bars overlaid.
Mathematica provides a variety of simple ways to enter the G, E, D matrices and
then we can evaluate the matrix of amplitudes, A, with the commands:
Y ¼ Transpose½G:Inverse½E:G
A ¼ Inverse½Y:Transpose½G:Inverse½E:D
10.3 Regression analysis
Least-squares fitting is often called regression analysis for historical reasons. For
example, Mathematica provides the package called Statistics ‘Linear Regression’ for
doing a linear least-squares fit. Regression analysis applies when we have, for example,
two quantities like height and weight, or income and education and we want to predict
one from information about the other. This is possible if there is a correlation between
the two quantities, even if we lack a model to account for the correlation. Typically in
these problems, there is little experimental error in the measurements compared to the
intrinsic spread in their values. Thus, we can talk about the regression line for income
10
20
30
40
50
60
70
80
x-axis
0
5
10
15
20
25
y-axis
Figure 10.2 Straight line model fit with data plus errors overlaid. Clearly, the best fitting line is
mostly determined by the data points with smallest error bars.
256
Linear model fitting (Gaussian errors)

on education. The regression line is often called the least-squares line because it makes
the sum of the squares of the residuals as small as possible.
In contrast, model fitting usually assumes that there is an underlying exact relation-
ship between some measured quantities, and we are interested in the best choice of
model parameters or in comparing competing models. In some areas, especially in the
life sciences, the phenomena under study are sufficiently complex that good models
are hard to come by and regression analysis is the name of the game.
The results from a regression analysis may make no physical sense but may point the
way to a physical model. Consider the following simple example which assumes the
experimenter is ignorant of an elementary geometrical relationship, that the area of a
rectangle is equal to the product of the width and height. The experimenter fabricates
many different shaped rectangles and determines the area of each rectangle by count-
ing the number of very small squares that fit into the rectangle. Our experimenter then
examines whether there is a correlation between rectangle area and perimeter. The
resulting regression line would look like a line with considerable scatter, because the
perimeter is not a good physical model for the area. In contrast, a plot of area versus
the product of the width times the height would be an almost perfect straight line,
limited only by the measurement accuracy of the width and height measurements.
10.4 The posterior is a Gaussian
We have succeeded in finding the most probable model parameters. Now we want to
determine the shape of their joint probability distribution with an eye to specifying
credible regions for each parameter. We will continue to work with the simple case
where all the data errors are assumed to be IID so that pðfAgjD; IÞ is given by
Equation (10.12),
pðfAgjD; IÞ ¼ CeQðfAgÞ=22:
(10:57)
Then maximizing pðfAgjD; IÞ, corresponds to minimizing Q. Since we’ve already
taken one derivative of Q (Equation (10.15)), let’s see what happens when we take
another. Define A ¼ A  ^A. Call the value of Q at the mode Qmin. Recall that the
mode is the value that maximizes the probability density. Consider a Taylor series
expansion of Q about the Qmin.
Q ¼ Qmin þ
X

@Q
@A

min
A þ 1=2
X

@2Q
@A@A

min
AA:
(10:58)
The first derivative is zero at the minimum and from Equation (10.8), it is clear there
are no higher derivatives than the second. We are now in the position to write Q in a
form that explicitly reveals the posterior distribution to be a multivariate Gaussian.
Q ¼ Qmin þ QðAÞ;
(10:59)
10.4 The posterior is a Gaussian
257

and
QðAÞ ¼ 1=2
X

@2Q
@A@A

min
AA:
(10:60)
Taking another derivative of Equation (10.15) and substituting from Equation
(10.31), we get the equation8
@2Q
@A@A

min
¼ 2~g  ~g ¼ 2  ¼ 2 :
(10:62)
Substituting this into Equation (10.60), we get the equation
QðAÞ ¼
X

A A;
(10:63)
where y is a symmetric matrix. Note: the differential dðAÞ ¼ dA, so densities for the
A are directly equal to densities for the A. Thus,
pðfAgjD; IÞ ¼ C0 exp  Q
22


;
(10:64)
where
C0 ¼ C exp  Qmin
22


;
(10:65)
is an adjusted normalization constant. If we let A be a column matrix of A values,
then Equation (10.64) can be written as
pðfAgjD; IÞ ¼ C0 exp  ATyA
22


:
(10:66)
8 For M=2, y is given by
y 
g2
1
~g1  ~g2
~g2  ~g1
g2
2
 
!
¼ 1
2
@2Q
@A2
1
@2Q
@A1@A2
@2Q
@A2@A1
@2Q
@A2
2
0
@
1
A:
ð10:61Þ
258
Linear model fitting (Gaussian errors)

Since y is symmetric there is a change of variable, A ¼ OX, that transforms9 the
quadratic form ATyA into the quadratic form XTLX (Principal Axis Theorem).
L is a diagonal matrix whose diagonal elements are the eigenvalues of the y matrix and
the columns of O are the orthonormal eigenvectors of y.
For the M ¼ 2 case, we have
Q ¼ ðX1 X2Þ
1
0
0
2


X1
X2


¼ 1X2
1 þ 2X2
2;
(10:67)
where 1 and 2 are the eigenvalues of y. They are all positive since y is positive
definite.10 Thus, Q ¼ k (a constant) defines the ellipse (see Figure 10.3),
X2
1
k=1
þ X2
2
k=2
¼ 1;
(10:68)
9.5
10
10.5
11
11.5
A1
0.24
0.26
0.28
0.3
0.32
A2
Q = k
k /λ 1
√
k /λ 2
√
e2 
e1   
Figure 10.3 The contour in A1A2 parameter space for Q ¼ a constant k. It is an ellipse,
centered at ð ^A1; ^A2Þ, whose major and minor axes are determined by the eigenvalues  and
eigenvectors~e of y. Note: dX1 and dX2 in Equation (10.67), are measured in the directions of the
eigenvectors ~e1 and ~e2, respectively.
9 In two dimensions the transformation O corresponds to a planar rotation followed by a reflection of the X2 axis.
Since  is symmetric this is equivalent to a rotation of the axes.
10 This would not be the case if the basis vectors were linearly dependent. In that case,  would be singular and  1
would not exist.
10.4 The posterior is a Gaussian
259

with major and minor axes given by
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
k=1
p
and
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
k=2
p
, respectively. From Equation
(10.64), we see that Q ¼ k corresponds to a contour of constant posterior prob-
ability in the space of our two parameters.
Clearly, Figure 10.3 provides information about the joint credible region for the
model parameters A1 and A2. We still need to compute what size of ellipse corresponds
to, say, a 95% credible region. In the next section, we discuss how to find various
summaries of a Gaussian posterior.
Problem: In Section 10.2.2, we fitted a straight line model to the data in Table 10.1.
Find the eigenvalues of the corresponding Y matrix given by Equation (10.52) and
which we repeat here.
Y ¼ 1
2
76
3010
3010
152 300


;
(10:69)
where 2 ¼ 8:1.
In that problem, the errors were not all the same, so we employed the data
covariance matrix E1. For that situation, Equation (10.66) becomes
pðfAgjD; IÞ ¼ C0 exp 
P
 A½YA
2


:
(10:70)
Since there are only two parameters ðA1; A2Þ, we can rewrite Equation (10.70) as
pðA1; A2jD; IÞ ¼ C0 exp

P2
¼1
P2
¼1 A½YA
2
(
)
:
(10:71)
Solution: We can readily determine the eigenvalues of Y with the following
Mathematica command:
Eigenvalues½Y
f18 809:8; 2:03766g
So the two eigenvalues are 1 ¼ 18 809:8 and 2 ¼ 2:03766.
10.4.1 Joint credible regions
A credible region is a locus of points of constant probability which surrounds a region
containing a specified probability in the joint probability distribution. Figure 10.3
illustrated that in the two-parameter case, this locus is an ellipse defined by Q ¼ k
where k is a constant. In this section, we will find out for what value of k the ellipse
contains say 68.3% of the posterior joint probability. The results will be presented in a
more general way so we can specify the credible region corresponding to Q ¼ k for
an arbitrary number of model parameters, not just the M ¼ 2 case.
260
Linear model fitting (Gaussian errors)

We slightly simplify the notation for this subsection to connect with more familiar
results, by writing the posterior density for the A as
pðfAgjD; IÞ ¼ Ce2=2;
(10:72)
where 2ðfAgÞ ¼ Q=2. Let 2
min ¼ Qmin=2, and 2 ¼ Q=2. Then from
Equation (10.64), we can write
pðfAgjD; IÞ ¼ C0e2=2:
(10:73)
By definition, the boundary of a joint credible region for all the amplitudes is
defined by 2ðfAgÞ ¼ 2
min þ 2
crit, where 2
crit is a constant chosen such that
the region contains some specified probability, P. Our task is to find 2
crit such that
P ¼
Z
2<2
crit
dMA pðfAgjD; IÞ:
(10:74)
The result, which is given without proof, is
P ¼ 1  ðM=2; 2
crit=2Þ
ðM=2Þ
:
(10:75)
This is the probability within the joint credible region for all the amplitudes
corresponding to 2 < 2
crit. The quantity ðM=2; 2
crit=2Þ is one form of the
incomplete gamma function,11 which is given by
ð=2; xÞ ¼
1
ð=2Þ
Z 1
x
ett

21 dt;
(10:76)
where  ¼ M is the number of degrees of freedom. Recall from Section 6.2 that
the 2 distribution is a special case of a gamma distribution. In Mathematica
ð=2; 2
crit=2Þ is given by the command
Gamma½n=2; Dc2
crit=2
Table 10.2 gives values for 2
crit as a function of P and  obtained from Equation
(10.75).
For example, the credible region containing probability P ¼ 68:3%, for M ¼ 2 free
model parameters, is bounded by a surface of constant 2 ¼ 2
min þ 2
crit ¼
2
min þ 2:3. Note: in Table 10.2, the degrees of freedom  ¼ M, the number of free
model parameters.
11 See Numerical Recipes by Press et al. (1992).
10.4 The posterior is a Gaussian
261

Question: Figure 10.3 shows an ellipse of constant probability for a two-parameter
model defined by Q ¼ k (a constant). For what value of k does the ellipse contain a
probability of 95.4%?
Answer: First we note that Q ¼ 22. From Table 10.2, we obtain 2 ¼ 6:17 for
 ¼ 2 degrees of freedom (for a two-parameter model) and a probability of 95.4%.
The desired value of k ¼ 6:172.
Question: Suppose we fit a model with six linear parameters. We are really only inter-
ested in two of these parameters so we remove the other four by marginalization. The
result is the posterior probability distribution for the two interesting parameters. Now
suppose we want to plot the 95.4% credible region (ellipse) for these two parameters.
How many degrees of freedom should be used when consulting Table 10.2?
Answer: 2!
Problem: In Section 10.2.2, we fitted a straight line model to the data in Table 10.1.
Compute and plot the 95.4% joint credible region for the slope and intercept.
Solution: FromTable10.2,weobtain2 ¼ 6:17 for ¼ 2 degreesoffreedom(foratwo-
parameter model) and a probability of 95.4%. Now 2 is related to the Y matrix by
2 ¼
X
2
¼1
X
2
¼1
A½YA;
(10:77)
where
Y ¼ 1
2
76
3010
3010
152 300


¼
9:383
371:6
371:6
18 802


;
(10:78)
Table 10.2 This table allows us to find the value of 2
crit in Equation (10.74) that
defines the boundary of the joint posterior probability in  model parameters that
contains a specified probability P. Thus, the P ¼ 68:3% joint probability boundary in two
parameters corresponds to a 2
crit ¼ 2:3, where 2
crit is measured from 2
min, the value
corresponding to the peak of the joint posterior probability.
P
Degrees of Freedom 
1
2
3
4
5
6
68.3%
1.00
2.30
3.53
4.72
5.89
7.04
90%
2.71
4.61
6.25
7.78
9.24
10.6
95.4%
4.00
6.17
8.02
9.70
11.3
12.8
99%
6.63
9.21
11.3
13.3
15.1
16.8
99.73%
9.00
11.8
14.2
16.3
18.2
20.1
99.99%
15.1
18.4
21.1
23.5
25.7
27.8
262
Linear model fitting (Gaussian errors)

since 2 ¼ 8:1. Combining Equations (10.77) and (10.78), we obtain
2 ¼ ðA1 A2Þ
9:383
371:6
371:6
18 802


A1
A2


¼ 6:17:
(10:79)
It is convenient to change from rectangular coordinates ðA1; A2Þ to polar coordinates
ðr; 	Þ. Equation (10.79) becomes
ðr cos 	 r sin 	Þ
9:383
371:6
371:6
18 802


r cos 	
r sin 	


¼ 6:17:
(10:80)
Next, solve this equation for r for a set of values of 	, and by so doing map out the
joint credible region. In Mathematica this can easily be accomplished by:
polarA [r, q] :={{r * Cos[q]}, {r * Sin[q]}};
tpolarA[r, q] := Transpose[polarA[r, q]];
locus = Table[
{NSolve[Flatten[tpolarA[r, q].Y.polarA[r, q]][[1]]==6:17, r]
[[2]][[1, 2]], q}, {q, 0, 2p, Dq}];
Finally, transform the r; 	 values back to A1, A2 and convert them to A1, A2,
where A1 ¼ A1 þ ^
A1 and A2 ¼ A2 þ ^
A2. Note: ^
A1 and ^
A2 are the most probable
values of the intercept and slope, respectively. Figure 10.4(a) shows a plot of the
resulting 95.4% joint credible region (dashed curve). The solid curve shows the 68.3%
joint credible region derived in the same way.
What if we are interested in summarizing what the data and our prior information
have to say about the slope, i.e., determining the marginal PDF, pðA2jD; IÞ? In this
–1
–2
–3
Intercept
0.24
0.26
0.28
0.3
0.32
Slope
 (a)
∆χ 2 = 6.17
∆χ2 = 4
∆χ2 = 1
∆χ 2 = 2.3
–1
–2
–3
Intercept
0.24
0.26
0.28
0.3
0.32
Slope
(b)
B
B′  
A
A′ 
Figure 10.4 Panel (a) is a plot of the 95.4% (dashed) and 68.3% (solid) joint credible regions for
the slope and intercept of the best-fit straight line to the data of Table 10.1. Panel (b) shows
ellipses corresponding to 2 ¼ 1:0 and 2 ¼ 4:0. The two lines labeled A and A0, which are
tangent to the inner ellipse, define the 68.3% credible region for the marginal PDF, pðA2jD; IÞ.
The two lines labeled B and B0, which are tangent to the outer ellipse, define the 95.4% credible
region for pðA2jD; IÞ.
10.4 The posterior is a Gaussian
263

case, we need to marginalize over all possible values of A1. We will look at this
question more fully in Section 10.5, but we can use the material of this section to
obtain the 68.3% credible region for A2 as follows. By good fortune it turns out that
for Gaussian posteriors, in any number of dimensions, the marginal PDF is also equal
to the projected distribution (projected PDF). What do we mean by the projected PDF
for A2? Imagine a light source located a great distance away along the A1 axis,
illuminating the 3-dimensional probability density function, thought of as an opaque
mountain sitting on the A1; A2 plane. The height of the mountain at any particular
A1; A2 is equal to pðA1; A2jD; IÞ. The shadow cast by this mountain on the plane
defined by A1 ¼ 0 is called the projected probability density function of A2.
To plot out the projected PDF, we can do the following. Each value of A2 in our
final plot corresponds to a line parallel to the A1 axis. Vary A1 along this line and find
the maximum value of pðA1; A2jD; IÞ along the line. If we raise the line to this height it
will be tangent to the surface of the probability mountain for this A2. This is the value
of the projected PDF for that particular value of A2.
Now consider the two lines shown in Figure 10.4(b), labeled A and A0, which define
the borders of the 68.3% credible region for A2. You might naively expect these two
lines to be tangent to the ellipse containing 68.3% of the joint probability,
pðA1; A2jD; IÞ, as illustrated in Figure 10.4(a) for 2 ¼ 2:3. The correct answer is
that they are tangent to the ellipse shown in Figure 10.4(b), corresponding to
2 ¼ 1:0, as indicated in Table 10.2 for one degree of freedom. The two lines, B
and B0, which define the 95.4% credible region, are tangent to the ellipse defined by
2 ¼ 4:0. In a like fashion we could locate the 68.3% and 95.4% credible region
boundaries for A1.
10.5 Model parameter errors
In Sections 10.2.1 and 10.2.2, we found the most probable values of linear model
parameters. To complete the discussion, we need to specify the uncertainties of these
parameters and introduce the parameter covariance matrix.
10.5.1 Marginalization and the covariance matrix
Now suppose that we are only interested in a subset of the model amplitudes (for
example, one amplitude may describe an uninteresting mean background level, or, we
may be interested in the probability density function of only one of the parameters).
We can summarize the implications of the data for the interesting amplitudes by
calculating the marginal distribution for those amplitudes, integrating the uninterest-
ing nuisance parameters out of the full joint posterior. In this subsection we start by
showing how to integrate out a single amplitude; the procedure can be repeated to
remove more parameters. We then consider the special case of a model with only two
264
Linear model fitting (Gaussian errors)

parameters (M ¼ 2) and see how this leads to an understanding of the parameter
errors.
Suppose that the amplitude we want to marginalize out is A1. Returning to the
Q notation and IID Gaussian errors, the marginal distribution for the remaining
amplitudes is then
pðA2; . . . ; AMjD; IÞ ¼
Z
A1
dA1 pðfAgjD; IÞ
¼ C0
Z
A1
dA1 eQ=22;
(10:81)
where
QðAÞ ¼
X

A A:
(10:82)
To perform the required integral, we first pull out the A1-dependent terms in Q,
writing
Q ¼ ðA1Þ2 11 þ 2A1
X
M
¼2
 1A þ
X
M
;¼2
A A;
(10:83)
where A1 appears only in the first two terms.
Now we complete the square for A1 by adding and subtracting a term as
follows:
Q ¼ ðA1Þ2 11 þ 2A1
X
M
¼2
 1A þ 1
 11
X
M
¼2
 1A
 
!2
 1
 11
X
M
¼2
 1A
 
!2
þ
X
M
;¼2
A A
¼  11 A1 þ  1
11
X
M
¼2
 1A
"
#2
þ Qr:
(10:84)
By construction, A1 appears only in the squared term, and the terms depending on
the remaining A’s make up the reduced quadratic form,
Qr ¼  1
 11
X
M
¼2
 1A
 
!2
þ
X
M
;¼2
A A:
(10:85)
10.5 Model parameter errors
265

Equation (10.81) can now be written
pðA2; . . . ; AMjD; IÞ ¼ C0eQr=22 Z
A1
dðA1Þ
 exp   11
22
A1 þ  1
11
X
M
¼2
 1A
 
!2
2
4
3
5:
(10:86)
The integrand is a Gaussian in A1, with variance 2= 11. If the range of integration,
A1, were infinite, the integral would merely be a constant (the normalization constant
for the Gaussian, 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2p= 11
p
). With a finite range, it can be written in terms of error
functions with arguments that depend on A2 through AM. But as long as the prior range
is large compared to =
ﬃﬃﬃﬃﬃﬃﬃ
 11
p
, this integral will be very nearly constant with respect to the
remaining amplitudes. Thus, to a good approximation, the marginal distribution is
pðA2; . . . ; AMjD; IÞ ¼ C00eQr=22;
(10:87)
where C00 ¼ C0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2p= 11
p
is a new normalization constant. In the limit where
A1 ! 1, this result is exact.
Again, it is useful to consider the special case of only two parameters, M ¼ 2. In this
case, after marginalizing out A1 we are left with pðA2jD; IÞ. Let’s evaluate this now.
We can rewrite Equation (10.85),
Qr ¼  1
 11
ð 12A2Þ2 þ A2 22A2
¼ A2
2
 11 22   2
12
 11


:
(10:88)
Thus, we can write
pðA2jD; IÞ ¼ C0
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2p= 11
p
eA2
2=22
2;
(10:89)
which is a Gaussian with variance 2
2 given by
2
2 ¼ 2
 11
 11 22   2
12


:
(10:90)
Similarly, if we had marginalized out A2 instead, we would have obtained a
Gaussian PDF for pðA1jD; IÞ with 2
1 given by
2
1 ¼ 2
 22
 11 22   2
12


:
(10:91)
266
Linear model fitting (Gaussian errors)

Notice that the variances for A1 and A2 can be written in terms of the elements of y1:
y1 ¼
1
 11 22   2
12
 22
 12
 12
 11


:
(10:92)
Comparing with Equations (10.91) and (10.90), we can write
2
1 ¼ 2½y111;
(10:93)
2
2 ¼ 2½y122:
(10:94)
Thus, we have shown for the M ¼ 2 case, that the matrix y1 that we needed to solve
for ^A (see Equation (10.34)), when multiplied by the data variances (2), also
contains information about the errors of the parameters. In Section 10.5.3, we will
generalize this result for the case of a linear model with an arbitrary number of
parameters M, and show that
2
 ¼ 2½y1:
(10:95)
The matrix V ¼ 2y1 is given the name parameter variance-covariance matrix or
simply the parameter covariance matrix.12 We shall shortly define what we mean by
covariance.
If we wish to summarize our posterior state of knowledge about the parameters with
a few numbers, then we can write
A1 ¼ ^A1  1
(10:96)
A2 ¼ ^A2  2:
(10:97)
Formally, the variance of A1 is defined as the expectation value of the square-of-the-
deviations from the mean 
1;
VarðA1Þ ¼ hðA1  
1Þ2i ¼
Z
A1
dA1ðA1  
1Þ2pðA1jD; IÞ:
(10:98)
The idea of variance can be broadened to consider the simultaneous deviations of
both A and A. The covariance is given by
 ¼
Z
A
Z
A
dAdAðA  
ÞðA  
ÞpðA; AjD; IÞ
(10:99)
and is a measure of the correlation between the inferred parameters. If, for example,
there is a high probability that overestimates of A are associated with overestimates
12 If we are employing the covariance matrix, E, for our knowledge of the measurement errors, then simply replace y1
by Y1,   by  and drop all the factors of 2 in Equations (10.93), (10.94), (10.101), and (10.100).
10.5 Model parameter errors
267

of A, and underestimates of A associated with underestimates of A, then the
covariance will be positive. Negative covariance (anti-correlation) implies that over-
estimates of A will be associated with underestimates of A. When the estimate of one
parameter has little or no influence on the inferred value of the other, then
the magnitude of the covariance will be negligible in comparison to the variance
terms, jj 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

p
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
2

q
.
By now you may have guessed that the covariance of the inferred parameters is
given by 2 times the off-diagonal elements of the y1 matrix.
 ¼ 2½y1:
(10:100)
Thus, for the M ¼ 2 case, we have
12 ¼ 2½y112
¼ 2
 12
 11 22   2
12


:
(10:101)
Referring to Figure 10.3, we see that the major axis of the elliptical credible region is
inclined to the A1 axis with a positive slope. This indicates a positive correlation
between the parameters A1 and A2. A value of 12 ¼ 0 would correspond to a major
axis which is aligned with the A1 axis if 1 > 2.
10.5.2 Correlation coefficient
It is useful to summarize the correlation between estimates of any two parameters by a
coefficient in the range from 1 to þ1, where 1 indicates complete negative correl-
ation, þ1 indicates complete positive correlation, and 0 indicates no correlation. The
correlation coefficient is defined by
 ¼

ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

p
¼

ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
2

q
:
(10:102)
In the extreme case of  ¼ 1, the elliptical contours will be infinitely wide in one
direction (with only information in the prior preventing this catastrophe) and oriented
at an angle  tan1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ð 22= 11Þ
p


. In this case, the parameter error bars 1 and 2 will
be huge, saying that our individual estimates of A1 and A2 are completely unreliable,
but we can still infer a linear combination of the parameters quite well. For  large
and positive, the probability contours will all bunch up close to the line
A2 ¼ intercept þ mA1, where m ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ð 22= 11Þ
p
. We can rewrite this as A2  mA1 ¼
intercept. Varying the intercept corresponds to motion perpendicular to this line. The
concentration of probability contours implies that the probability density of the
intercept is quite narrow. Since the intercept is equal to A2  mA1, this indicates
268
Linear model fitting (Gaussian errors)

that the data contain a lot of information about the difference A2  mA1. If  is large
and negative, then we can infer the sum A2 þ mA1.
Problem: In Section 10.2.2, we fitted a straight line model to the data in Table 10.1. We
are now in a position to evaluate the errors for the marginal posterior density functions
for the intercept, A1, and slope, A2, from the diagonal elements of V ¼ Y1 ¼
ðGTE1GÞ1 which is given by
Y1 ¼ 2
0:061
0:0012
0:0012
0:000030


;
(10:103)
where 2 ¼ 8:1.
Solution: Let 1 and 2 be the 1 errors of A1 and A2. Y1 is the variance-covariance
matrix of the parameter errors. In this case, it includes the data covariance matrix E1
so we need to use Equations (10.93) and (10.94) without the 2 term in front.
1 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
½Y111
q
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
0:0612
p
¼ 0:70;
(10:104)
2 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
½Y122
q
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
0:000030 2
p
¼ 0:016;
(10:105)
and,
^
A1
^
A2


¼
2:05  0:70
0:275  0:016


:
(10:106)
The correlation coefficient is
12 ¼
12
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1122
p
¼
½Y112
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
½Y111½Y122
q
¼
0:0012
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
0:061  0:00003
p
¼ 0:885:
(10:107)
When there are only two parameters, it is more informative to give a contour plot of
the joint posterior probability density function, which illustrates the correlation in the
parameter error estimates. In Section 10.4.1, we showed how to compute the joint
credible region for the slope and intercept and plotted two examples in Figure 10.4(a).
This figure is repeated in the left panel of Figure 10.5. The two contours shown enclose
95.4% and 68.3% of the probability.
In the previous analysis, the intercept and slope are referenced to the origin of our
data. It turns out that the size of the correlation coefficient depends on the origin we
choose for the x-coordinate, as we demonstrate in Figure 10.6. In fact, if we shift the
origin by just the right amount, call it xw, we can eliminate the correlation altogether.
10.5 Model parameter errors
269

From Equation (10.107) it is clear that 12 ¼ 0 if ½Y112 ¼ 0, and it is easy to show
that the off-diagonal elements of Y1 are zero if the off-diagonal elements of Y are
zero. These modified basis functions are referred to as orthogonal basis functions.
From Equations (10.47) and (10.46) we can write
½Y12 ¼
X
ij
gi1½E1ij gj2:
(10:108)
25
50
75
100
125
150
175
x-axis
0
10
20
30
40
50
60
y-axis
Figure 10.6 Two straight line fits to some data with an origin well outside the x range of the
data. Clearly, any variation in the slope parameter will have a strongly correlated effect on
the intercept and vice versa. If the x origin had been chosen closer to the middle of the data,
then variations in slope would have a much smaller effect on the intercept.
–1
–2
–3
Intercept
0.24
0.26
0.28
0.3
0.32
Slope
 (a) 
  
8
9
10
11
Intercept
0.24
0.26
0.28
0.3
0.32
Slope
 (b) 
  
∆χ2 = 2.3
∆χ2 = 2.3
∆χ2 = 6.17
∆χ2 = 6.17
Figure 10.5 Panel (a) shows a contour plot of the joint posterior PDF pðA1; A2jD; IÞ. The dashed
and solid contours enclose 95.4% and 68.3% of the probability, respectively. Panel (b) is the
same but using the weighted average x-coordinate as the origin of the fit.
270
Linear model fitting (Gaussian errors)

For the straight line model gi1 ¼ f1; 1; . . . ; 1g and gj2 ¼ fx1; x2; . . . ; xNg. Shifting the
origin to xw changes gj2 to g0
j2 ¼ fx1  xw; x2  xw; . . . ; xN  xwg. We can solve for xw
by setting
½Y0
12 ¼
X
ij
gi1 ½E1ij g0
j2 ¼ 0:
(10:109)
From Equation (10.52), we can rewrite Equation (10.109) as
½Y0
12 ¼ ð1; 1; 1; . . . ; 1Þ 1
2
14
0
0
  
0
0
3
0
  
0
0
0
25
  
0





0
0
  
0
2
0
B
B
B
B
B
B
B
B
@
1
C
C
C
C
C
C
C
C
A
x1  xw
x2  xw
x3  xw

xN  xw
0
B
B
B
B
B
B
B
B
@
1
C
C
C
C
C
C
C
C
A
¼ 1
2 ð14; 3; 25; . . . ; 2Þ
x1  xw
x2  xw
x3  xw

xN  xw
0
B
B
B
B
B
B
B
B
@
1
C
C
C
C
C
C
C
C
A
¼ ðw1; w2; w3; . . . ; wNÞ
x1  xw
x2  xw
x3  xw

xN  xw
0
B
B
B
B
B
B
B
B
@
1
C
C
C
C
C
C
C
C
A
¼ w1ðx1  xwÞ þ w2ðx2  xwÞ þ    þ wNðxn  xwÞ ¼ 0;
(10:110)
where the data weights, wi, are given by the diagonal elements of the inverse data
covariance matrix E1. The solution of Equation (10.110) is given by
xw ¼
P wixi
P wi
:
(10:111)
Panel (b) of Figure 10.5 shows the joint credible region for the parameters obtained
using the weighted average, xw, as the origin. The major and minor axes of the ellipse
are now parallel to the parameter axes. The sensitivity of the analysis to the choice of
origin arises from the model predictions’ dependence on the origin.
10.5 Model parameter errors
271

Suppose that instead of a straight line model, we had wanted to fit a higher order
polynomial to the data. The appropriate function to fit, to ensure the coefficients are
uncorrelated, can be shown to be of the form
yðxiÞ ¼ A1 þ A2ðxi  xwÞ þ A3ðxi  1Þðxi  2Þ
þ A4ðxi  1Þðxi  2Þðxi  3Þ þ    ;
(10:112)
In the case of a polynomial with just the first 3 terms, we can compute 1 and 2 from
the two equations
½Y0
13 ¼
X
ij
gi1 ½E1ij g0
j3 ¼ 0;
(10:113)
½Y0
23 ¼
X
jk
g0
j2 ½E1jk g0
k3 ¼ 0;
(10:114)
where g0
j2 ¼ fx1  xw; x2  xw; . . . ; xN  xwg
and g0
k3 ¼ fðx1  1Þðx1  2Þ; ðx2  1Þðx2  2Þ; . . . ; ðxN  1ÞðxN  2Þg: (10:115)
10.5.3 More on model parameter errors
In Sections 10.2.1 and 10.2.2, we found the most probable values of linear model para-
meters. To complete the discussion, we need to specify the uncertainties of these para-
meters. We made a start on this in Section 10.5.1 for the special case of a linear model with
only two parameters ðM ¼ 2Þ. We also introduced the concept of the covariance of two
parameters and the correlation coefficient. In this section, we will generalize these results
for an arbitrary value of M. In Section 10.4, we showed that the posterior probability
distribution of the parameters pðfAgjD; IÞ is a multivariate Gaussian given by
pðfAgjD; IÞ / exp  1
22
X

A A
"
#
:
(10:116)
If we use the more powerful matrix formulation which includes the data covariance
matrix E (see Section 10.2.2), then we need to replace
1
22
X

A A
by
1
2
X

AA:
Equation (10.116) becomes
pðfAgjD; IÞ / exp  1
2
X

AA
"
#
¼ exp  1
2
X

ðA  ^AÞ½YðA  ^AÞ
"
#
:
(10:117)
272
Linear model fitting (Gaussian errors)

Now compare Equation (10.117) with Equation (10.41) for pðDjfAg; IÞ which is
repeated here.
pðDjfAg; IÞ / exp  1
2
X
ij
ðdi  fiÞ½E1ijðdj  fjÞ
"
#
:
(10:118)
Both have the same form. In Equation (10.118), E is the data covariance matrix. By
analogy the inverse of Y; Y1 is the model parameter covariance matrix. Thus,
everything we need to know about the uncertainties with which the various parameters
have been determined, and their correlations, is given by Y1 ¼ ðGTE1GÞ1, a matrix
which we previously computed (Section 10.2.2) in the determination of the most
probable values of the parameters. The variance terms are given by the diagonal
elements of Y1 and the covariance terms by the off-diagonal elements. We see that
the parameter errors depend on the data errors through E1 but in a complicated way
which depends on our choice of model basis functions.
In Section 10.2.2, we also saw that E1 plays the role of a metric in the full
N-dimensional vector space of the data. In a similar fashion, Y plays the role of a
metric in the M-dimensional subspace spanned by the model functions.
10.6 Correlated data errors
In this section, we compute the mean of a data set for which the off-diagonal elements
of the data covariance matrix, E, are not all zero, i.e., the noise components are
correlated. These correlations can be introduced by the experimental apparatus prior
to the digitization of the data, or by subsequent software operations. Panel (a) of
Figure 10.7 shows 100 simulated data samples of a mean, 
 ¼ 0:5, with added IID
Gaussian noise ð ¼ 1Þ. Panel (b) shows the same data after a smoothing operation
that replaces each original sample ðdiÞ by a weighted average ðziÞ of the original sample
and its nearest neighbors according to Equation (10.119).
zi ¼
0:75di þ 0:25diþ1
for i ¼ 1
0:25di1 þ 0:5di þ 0:25diþ1
for 1 < i < 100
0:25di1 þ 0:75di
for i ¼ 100.
8
<
:
(10:119)
If the characteristic width of the signal component in the data is very broad13 (in this
example the signal is a DC offset), then the smoothing will have little effect on the
signal component. However, it will introduce correlations into the independent noise
components. These correlations need to be incorporated in the analysis. The dominant
correlation in the smoothed data is with the nearest neighbor on either side. There is
13 If the smoothing has a significant effect on the signal component then this can be accounted for in the signal model by
a convolution operation, as discussed in Appendix B.4.3.
10.6 Correlated data errors
273

also a weaker correlation with the next nearest neighbor14. A common tool for
calculating correlations is the autocorrelation function (ACF), which was introduced
in Section 5.13.2. To compute the ACF of the noise15 we need a sample of data
(without any signal present) which has been smoothed in the same way. Panel (c) of
Figure 10.7 compares the autocorrelation functions for the raw data and smoothed
data. For the smoothed data, the ACF yields a correlation coefficient 1 ¼ 0:68 for
nearest neighbors (lag of 1), and 2 ¼ 0:16 for next nearest neighbors (lag of 2).
Panel (d) shows the Bayesian marginal posterior of the mean, pð
jD; IÞ, computed
for three cases. In case 1, pð
jD; IÞ was computed from the independent samples of
panel (a) following the treatment of Section 9.2.1. In case 2, pð
jD; IÞ was computed
0
5
10
15
20
25
30
35
Lag
–0.2
0
0.2
0.4
0.6
0.8
1
ACF
Smoothed
Raw data
(c)
0
0.2
0.4
0.6
0.8
1
Mean µ
0
1
2
3
4
5
6
Probability density
Case 3
Case 2
Case 1
(d)
20
40
60
80
100
Sample number
 –1
0
1
2
Signal strength
(a)
20
40
60
80
100
Sample number
 –1
0
1
2
Signal strength
(b)
Figure 10.7 Panel (a) shows 100 independent samples of a mean value 
. In panel (b), the data
have been smoothed using a running average that introduces correlations. Panel (c) compares
the autocorrelation functions (ACF) for the raw data and smoothed data. Panel (d) compares
the posterior density for 
 for three cases. Case 1 is based on an analysis of the independent
samples. The smoothed data results correspond to case 2 (assuming no correlations) and case 3
(including correlations).
14 According to equation (5.63), we first subtract the mean of the noise data which can introduce a correlation between
all the noise terms. If N is large this correlation is very weak and has been neglected in the current analysis.
15 We can write
12 ¼ he1e2i ¼ he2e3i ¼ heieiþ1i ¼ 2ðj ¼ 1Þ;
where ðj ¼ 1Þ is the value of the ACF for lag j ¼ 1.
274
Linear model fitting (Gaussian errors)

from the smoothed data and assuming no correlation. This second case results in
a narrower posterior which is unwarranted because our state of information
is unchanged from case 1, we have simply transformed the original data via
a smoothing operation. In case 3, we incorporated information about the correlations
introduced by the smoothing. This yielded essentially the same result as we obtained
in case 1, as we would expect. In all three cases, we assumed the noise  was
an unknown nuisance parameter. We assumed a Jeffreys prior for  and a uniform
prior for 
.
For case 3, the likelihood was computed from Equation (10.41), which for the
current problem can be written as
pðDj
; ; IÞ ¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2
X
ij
ðdi  fiÞ½E1ijðdj  fjÞ
"
#
¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2 YTE1Y
	

;
(10:120)
where YT ¼ fðd1  f1Þ; ðd2  f2Þ; . . . ; ðdN  fNÞg is a vector of the differences between
the measured and predicted data values. From the results of the ACF, the data
covariance matrix, E, is given by
E ¼ 2
1
1
2
0
  
0
0
0
1
1
1
2
  
0
0
0
2
1
1
1
  
0
0
0








0
0
0
0
  
2
1
1
0
B
B
B
B
B
B
@
1
C
C
C
C
C
C
A
¼ 2
1
0:68
0:16
0
  
0
0
0
0:68
1
0:68
0:16
  
0
0
0
0:16
0:68
1
0:68
  
0
0
0








0
0
0
0
  
0:16
0:68
1
0
B
B
B
B
B
B
@
1
C
C
C
C
C
C
A
:
(10:121)
10.7 Model comparison with Gaussian posteriors
In this section, we are interested in comparing the probabilities of two linear models
with different numbers of amplitude parameters. From our treatment of model
comparison in Section 3.5, it is clear that the key quantity in model comparison is
the evaluation of the global likelihood of a model. Calculation of the global likelihood
requires integrating away all of the model parameters from the product of the prior
10.7 Model comparison with Gaussian posteriors
275

and the likelihood. The integral required to calculate the global likelihood was given
earlier as Equation (10.14), which we repeat here:
pðDjMi; IÞ ¼
1
Q
 A
1
Nð2pÞN=2
Z
A
dMAeðQ=22Þ
¼
1
Q
 A
1
Nð2pÞN=2 eðQmin=22Þ
Z
A
dMAeðQ=22Þ;
(10:122)
where we have used Equation (10.59) to expand Q.
We could do the remaining integral by repeating the process of the preceding
Section 10.5.1 for each amplitude: complete the square and integrate, one amplitude
at a time. This gets to be very tedious if there are a large number of parameters. A
mathematically more elegant approach involves transforming to an orthonormal set
of model basis functions. The result is given by
pðDjMi; IÞ ¼
ð2pÞM=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det V
p
Q
 A
"
#
1
Nð2pÞN=2 eð2
min=2Þ
¼ M Lmax;
(10:123)
where V is the parameter covariance matrix. The quantity Lmax is the likelihood for the
model at the mode, which is given by
Lmax ¼ pðDj ^A; MiÞ ¼
1
Nð2pÞN=2 eð2
min=2Þ
(10:124)
and the Occam factor for the model is
M ¼ ð2pÞM=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det V
p
Q
 A
:
(10:125)
Assigning competing models equal prior probabilities, the posterior probability for
a model will be proportional to Equation (10.123). The odds ratio in favor of one
model over a competitor is simply given by the ratio of Equation (10.123) for the two
models. Suppose model 1 has M1 parameters, denoted A, and has a minimum 2
equal to 2
1;min. Suppose model 2 has M2 parameters, denoted A0
, and has a minimum
2 equal to 2
2;min. Then the odds ratio in favor of model 1 over model 2 is
O12 ¼ pðM1jIÞ
pðM2jIÞ  pðDjM1; IÞ
pðDjM2; IÞ ¼ 1  pðDjM1; IÞ
pðDjM2; IÞ
¼ e2
min=2 ð2pÞðM1M2Þ=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det V1
det V2
s
QM2
¼1 A
QM1
¼1 A0

;
(10:126)
276
Linear model fitting (Gaussian errors)

where V1 and V2 are the covariance matrices for the estimated parameters and
2
min ¼ 2
2;min  2
1;min. If the two models have some parameters in common, then
the ratio of the prior ranges A and A0 for these parameters will cancel.
Problem: In Section 3.6, we considered two competing theories. One theory ðM1Þ
predicted the existence of a spectral line with known Gaussian shape and location,
and a line amplitude in the range 0.1 to 100 units. The other theory ðM2Þ predicted
no spectral line (i.e., an amplitude ¼ 0). We now re-analyze the 64 channel spectral
line data given in Table 3.1 using the linear least-squares method discussed in this
chapter. We will assume a uniform prior for the line amplitude predictions of M1.16
Solution: First we calculate the most probable amplitude using Equation (10.34),
^A ¼ ðGTE1GÞ1GTE1D ¼ Y1GTE1D:
(10:127)
For M1, the model prediction, fi, is given by
fi ¼ A1gi ¼ A1 exp  ði  oÞ2
22
L
 
!
;
(10:128)
and so there is only one basis function, gi. Thus, GT is given by
GT ¼ ðg1; g2; . . . ; g64Þ:
(10:129)
Also, for this problem, the inverse data covariance matrix is a 64  64 matrix given by
E1 ¼ 1
2 ¼
1
0
0
  
0
0
1
0
  
0
0
0
1
  
0





0
0
  
0
1
0
B
B
B
B
@
1
C
C
C
C
A
¼
1
0
0
  
0
0
1
0
  
0
0
0
1
  
0





0
0
  
0
1
0
B
B
B
B
@
1
C
C
C
C
A
;
(10:130)
since the errors are independent and identically distributed with a 2 ¼ 1.
The D matrix is a column matrix containing the 64 channel spectrometer measure-
ments given in Table 3.1 of Section 3.6. Now that we have specified all the matrices, we
can evaluate ^A from Equation (10.127) using Mathematica.
Since M1 has only one parameter, the parameter covariance matrix V¼Y1 ¼
ðGTE1GÞ1 is a single number equal to the variance of ^A. The final answer for ^A is
^A ¼ 1:54  0:53:
(10:131)
Now we want to compute the odds ratio, O12, in favor of M1 over the competing
model M2. Since the two models were assigned equal prior probability, the odds is
16 The diligent reader might object at this point that in Section 3.6, we gave a strong argument for using a Jeffreys prior
for the line amplitude. Linear least-squares analysis is widely used in data analysis and we wanted to highlight its
strengths and weaknesses which are discussed in the conclusions given at the end of the problem.
10.7 Model comparison with Gaussian posteriors
277

given by
O12 ¼ pðM1jIÞ
pðM2jIÞ  pðDjM1; IÞ
pðDjM2; IÞ ¼ 1  pðDjM1; IÞ
pðDjM2; IÞ :
(10:132)
Model M2 has no undetermined parameter and predicts the spectrum equals zero
apart from noise. The quantity pðDjM2; IÞ is given by
pðDjM2; IÞ ¼
1
Nð2pÞN=2 e2
2;min=2;
(10:133)
where
2
2;min ¼
X
N¼64
i
d2
i
2 ¼ 57:13:
(10:134)
For model M1 we can use Equation (10.123) with M ¼ 1 parameter, yielding
pðDjM1; IÞ ¼
ð2pÞ1=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det V
p
A1
"
#
1
Nð2pÞN=2 e2
1;min =2
¼ 1Lmax;
(10:135)
where
2
1;min ¼
X
N¼64
i
ðdi  ^AgiÞ2
2
¼ 48:49:
(10:136)
Equation (10.135) contains an Occam penalty, 1, which penalizes M1 for prior
parameter space that gets ruled out by the data through the likelihood function. The
penalty arises automatically from marginalizing over the prior range A. In this case,
1 ¼
ð2pÞ1=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det V
p
A1
"
#
¼ 0:0133:
(10:137)
Substituting Equations (10.133) and (10.135) into Equation (10.132), we get
O12 ¼ 1eð2
2;min2
1;minÞ=2 ¼ 1:0:
(10:138)
Conclusions:
a)
Not surprisingly, the results obtained here for ^A and O12 are the same as we got from the
brute force analysis used in Section 3.6 for the uniform prior assumption for A. In the
current problem, we were dealing with only one parameter (for M1). Some problems involve
278
Linear model fitting (Gaussian errors)

a very large number of linear parameters and in these cases, the linear least-squares
approach is very efficient because no integrals need to be performed.
b)
In principle, linear least-squares analysis is only applicable for linear parameters with uniform
priors. In Section 3.10, we learned that there are good reasons for distinguishing between
location parameters, i.e., both positive and negative values are allowed, and scale parameters,
which are always positive. We also learned that there are strong reasons for preferring a
Jeffreys prior over a uniform prior when dealing with a scale parameter. Of course, in some
problems, we are fortunate to have much more selective prior information about parameter
values, e.g., based on the results of previous experiments.
The reader may well ask why we chose the spectral line example where the amplitude is a
scale parameter. Linear least-squares analysis is widely used in data analysis and we wanted
to highlight its strengths and weaknesses. For many parameter estimation problems, the
choice of prior is not too important because the posterior probability density is usually
dominated by the likelihood function which is generally rather strongly peaked except when
there are very little data.
c)
In model selection problems, the choice of prior is much more critical. In Section 3.6, we
addressed this question in considerable detail. We showed that using a more appropriate
Jeffreys prior led to an odds ratio favoring M1 which was a factor of 11 larger than for the
uniform prior assumption. The main message here is to only use the material on model
comparison in Section 10.7 when dealing with parameters for which the choice of a uniform
prior is appropriate.
10.8 Frequentist testing and errors
The results in this chapter have been developed from a Bayesian perspective. For
comparison purposes, we now introduce a section on model testing and parameter
errors from a frequentist perspective. My apologies to those of you who have your
Bayesian hat on at this point and can’t face the transition again. You can always skip
over this section now and return to it if you want to answer question 3(e) in the problems
at the end of this chapter. In Section 7.2.1, we discussed the use of the 2 statistic in
hypothesis testing. Once we have determined the best set of model parameters, we can
use the 2 statistic to test if the model is acceptable by attempting to reject the model at
some confidence level. From Equation (10.41) we see that 2 for the fit17 is given by
2 ¼
X
ij
ðdi  fiÞ½E1ijðdj  fjÞ:
(10:139)
If the errors are independent, this reduces to the more familiar form:
2 ¼
X
i
ðdi  fiÞ2
2
i
:
(10:140)
17 In the frequentist context, if the data errors are IID normal, then treated as a random variable, this quantity will have a
2 distribution with the number of degrees of freedom equal to N  M. If the data covariance matrix E1 has non-zero
off-diagonal elements, indicating correlations, then the number of degrees of freedom will be less than N  M.
10.8 Frequentist testing and errors
279

If the model contains M parameters and there are N data points, then our con-
fidence in rejecting the model is given by the Mathematica command:
1 - GammaRegularized NM
2
; c2
2
h
i
Some words of caution are in order on the use of the above for rejecting a hypothesis.
First GammaRegularized [(N  M)=2; 2=2] measures the significance of the test, which
equals the area of the 2 distribution to the right of our measured value. Again, if the
model is correct and the data errors are known to be IID normal, this area represents the
fraction of hypothetical repeats of the experiment that are expected to fall in this tail area
by chance. If this area is very small, then there are at least three possibilities: (1) we have
underestimated the size of the data errors, (2) the model does a poor job of explaining
the systematic structure in the data, or (3) the model is correct; the result is just a very
unlikely statistical fluctuation. Because experimental errors are frequently underestimated,
it is not uncommon to require a significance < 0:001 before rejecting a hypothesis.
Note: if the significance is very large, e.g., 	 0:5, this is an indication that the data errors
may have been overestimated.
Note: Mathematica provides a command called
ChiSquarePValue½c2; N  M
which has a maximum value of 0.5. This command can sometimes lead to confusion
because it measures the area in either tail region. Thus, if the measured value of 2 is
less than the number of degrees of freedom (the expectation value for the hypothetical
reference distribution), we would not want to refer to our confidence in rejecting the
model as 1-ChiSquarePValue.
The above model test assumes we know the errors accurately. What if the scatter in
the data from the best fitting model is considerably larger than the data errors used in
the analysis but we are convinced that the model is correct? The other option is that we
have underestimated the errors. Perhaps the model correctly describes some aspect of
the data but in addition something else is going on. Frequently this is how we discover
the presence of some new phenomenon: by looking for systematic effects in the
residuals after subtracting off the best-fit model from the data.
In Section 10.5.1, we saw that information about the model parameter errors is
contained in the covariance matrix, one form of which is given by
V ¼ 2y1 ¼ 2ðGTGÞ1:
(10:141)
If we have underestimated the data errors () then this will lead to our underestimating the
parameter errors. We saw in Section 9.2.3 that in a Bayesian analysis, we can marginalize
over any unknown data error and ensure that our parameter uncertainties properly
reflect the size of the residuals between the best fitting model and data (see Figure 9.3).
280
Linear model fitting (Gaussian errors)

A useful frequentist method for obtaining more robust parameter errors is based on
assuming the model is correct and then adjusting all the assumed measurement errors
by a factor k. The new value of 2 is then given by
2 ¼
X
N
i¼1
ðdi  fiÞ2
k22
i
¼ 2
meas
k2
;
(10:142)
where 2
meas is the value of 2 computed using the initial i error estimates. The factor k
is computed in the following way. When the model is valid, and the data errors are
known, the expected value of 2 for the best choice of model parameters, 2
expect, is
equal to the number of degrees of freedom ¼ N  M, where N ¼ the number of data
points, and M ¼ the number of fit parameters. The procedure then is to adjust the
value of k so that 2 in Equation (10.142) is equal to N  M.
2 ¼ 2
meas
k2
¼ 2
expect ¼ N  M:
(10:143)
The solution is
k ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2
meas
N  M
r
:
(10:144)
Including a factor k is a good thing to do since often nature is more complicated than
either the model or known measurement errors can account for. Increasing all the
measurement errors from  to k corresponds to increasing the terms in the parameter
covariance matrix (see Equation (10.141)) by k2 or the parameter standard errors by k.
The equivalent operation in Bayesian analysis would be to introduce k as a nuisance
parameter and marginalize over our prior uncertainty in this parameter.
The method just described for obtaining more accurate error estimates assumed
that the model was true. We cannot turn around and use these errors in a 2 hypothesis
test to see if we can reject the model. In contrast, in a Bayesian analysis, we can allow
for uncertainty in the value of k and also carry out a model selection operation after
marginalizing over the unknown k. Recall that whenever we marginalize over a model
parameter, this introduces an Occam penalty which penalizes the model for our prior
uncertainty in the parameter in a quantitative fashion. If all the models that we are
comparing in the model selection operation depend on this parameter in the same way,
then these Occam penalties cancel out. If they depend on the parameter in different
ways (e.g., models pðC; SjD; IÞ and pðC; SjD; IÞ in Section 9.4), then the Occam
penalties do not cancel.
10.8.1 Other model comparison methods
It is often useful to plot the variance of the residuals versus the number of model fitting
parameters, M. For example, in the case of a polynomial model we can vary the
10.8 Frequentist testing and errors
281

number of parameters. Of course, for M ¼ 0, the residual variance is just the data
variance. We can characterize a model by how quickly the curve of residual variance
versus M drops. Any variance curve which drops below another indicates a model
which is better, in the sense that it achieves a better quality fit to the data with a given
number of model functions. What one would expect to find is a very rapid drop as the
systematic signal is taken up by the model, followed by a slow drop as additional
model functions expand the noise. The total number of useful model parameters is
determined by the break in this curve. In constructing the residual variance curves, we
need to be aware that if we were to rearrange the order in which the best model terms
are incorporated, we can always produce a curve that is above that of the same model
but with a different order. We want to order the model parameters to produce the
lowest residual variance curve before selecting the break point.
The F statistic can also be used to decide which basis functions are significant.
Suppose our null hypothesis is that a model with M unknown parameters is the correct
model. If the model’s prediction for the ith data point is designated fl, then
2
v ¼
X
N
i¼1
ðdi  fiÞ2
2
(10:145)
has a 2
v distribution with  ¼ N  M degrees of freedom. Consider the effect on 2
when an extra term is added to the model fitting function so the number of degrees of
freedom is decreased by 1. If the simpler model is true then the effect of the extra term
is to remove some of the noise variation. The expected decrease in 2 is the same as if
we had not added the extra term but simply reduced N by one. Thus
2 ¼ 2
  2
1
(10:146)
has a 2 distribution with 1 degree of freedom.
According to equation (6.35)
F ¼
2
2
1=ð  1Þ
(10:147)
follows an F distribution18 with 1 and   1 degrees of freedom. If the simpler model is
correct you expect to get an f ratio near 1.0. If the ratio is much greater than 1.0, there
are two possibilities:
1. The more complicated model is correct.
2. The simpler model is correct, but random scatter led the more complicated model to fit better.
The P-value tells you how rare this coincidence would be.
18 Since 2 is a common factor in the calculation of both 2 and 2
v1 we can rewrite equation (10.147) as
F ¼ N
i¼1ðdi  fiÞ2  N
i¼1ðdi  fþiÞ2
N
i¼1ðdi  fþiÞ2
ð10:148Þ
where f+i ¼ the predicted value for the model with the extra term. Thus it is not necessary to know 2 to carry out this
F-test.
282
Linear model fitting (Gaussian errors)

If the P-value is small enough (e.g., 
 5%), reject the simpler model. Otherwise,
conclude that there is no compelling evidence to reject the simpler model.
As an example, we use the F-test to compare models M1 (line exists) and M2 (no
line exists) in the spectral line problem of Section 3.6. The best fit for M1 (63 degrees
of freedom) yielded a 2
v ¼ 63 ¼ 48:49. For M2, with 64 degrees of freedom,
2
v ¼ 64 ¼ 57:13. Substituting these values into equation (10.147) yields f ¼ 10.5. This
corresponds to a P-value ¼ 0.2%. On the basis of this F-test, we can reject the simpler
model M2 at a 99.8% confidence level.
10.9 Summary
Here we briefly summarize the main results of this chapter:
1. We saw how the Bayesian treatment leads to the familiar method of least-squares when we
are interested in the question of the most probable set of model parameters (see Equation
(10.34)), assuming an IID normal distribution for our knowledge of the measurement errors
and a flat prior for each parameter.
2. We then relaxed the IID requirement for our knowledge of the measurement errors by
introducing E, the covariance matrix for the errors. Equation (10.48) gives the revised
solution for the most probable set of parameters. Weighted linear least-squares can be seen
as a special case of this equation.
3. A full description of our knowledge of the model parameters is given by the joint posterior
distribution for the parameters. For a linear model, and a flat prior for each parameter, this
distribution is particularly simple, namely a multivariate Gaussian. Equation (10.75) or
Table 10.2 defines the boundary, 2
crit, of a (joint) credible region for one or more of the
parameters that contains a specified probability. Also, it turns out that for Gaussian poster-
iors, in any number of dimensions, the marginal PDF is also equal to the projected distribu-
tion (projected PDF).
4. A useful summary of the parameter errors is given by the model parameter covariance
matrix, V ¼ 2y1. If we are employing the covariance matrix, E, for our knowledge of the
measurement errors, then simply replace y1 by Y1 ¼ ðGTE1GÞ1,   by  and drop all
the factors of 2 in Equations (10.93), (10.94), (10.100), and (10.101).
5. The parameter covariance matrix also provides information about the correlation between
the estimates of any pair of model parameters, which is conveniently expressed by the
correlation coefficient (see Equation (10.102)), , ranging between 1. If  is close to 1
then it will not be possible to estimate reliably the two parameters separately, but we can still
infer a linear combination of the parameters quite well. This comes about because the model
basis functions are not orthogonal. At the end of Section 10.5.2, we show how to construct an
orthogonal polynomial model.
6. The key quantity in Bayesian model comparison is the global likelihood of a model.
Calculation of the global likelihood requires integrating away all of the model parameters.
The final result regarding Bayesian model selection is usually expressed as an odds ratio,
which is given by Equation (10.126). It is important to remember that this equation assumes
uniform parameter priors and prior boundaries well removed from the peak of the posterior.
Where these assumptions do not hold, the necessary marginalizations must in general be
10.9 Summary
283

carried out numerically and the resulting odds ratio can be very different. See Section 3.6 for a
detailed example of this latter point.
7. Common frequentist methods for model testing and estimating robust parameter errors are
discussed in Section 10.8.
10.10 Problems
1. Fit a straight line model to the data given in Table 10.3, where di is the average of ni
data values measured at xi. The probability of the individual di measurements is
normal with  ¼ 4:0, regardless of the xi value.
a) Give the slope and intercept of the best-fit line together with their errors.
b) Plot the best-fit straight line together with the data values and their errors.
c) Give the parameter covariance matrix.
d) Repeat (a) and (c) but this time use the average x-coordinate as the origin.
Comment on the differences between the covariance matrices in (c) and (d).
2. Compute and plot the ellipse that defines the 68.3% and 95.4% joint credible region
for the slope and intercept, for the data given in Table 10.3. The shape of this ellipse
depends on the x-coordinate origin used in the fit (see Figure 10.5). Use the average
x-coordinate as the origin. See the section of the Mathematica tutorial entitled
‘‘Joint Credible Region Contouring.’’
3. Table 10.4 gives measurements of ozone partial pressure, y, in millibars in each of
15 atmospheric layers where each layer, x, is approximately 2 km in height. The
layers have been scaled for convenience from 7 to þ7.
Use the least-squares method to fit the data with
(i) a quadratic model: yðxÞ ¼ A1 þ A2x þ A3x2
(ii) a cubic model: yðxÞ ¼ A1 þ A2x þ A3x2 þ A4x3
Table 10.3 Data table
xi
di
ni
10
0.387
14
20
5.045
3
30
7.299
25
40
6.870
2
50
16.659
3
60
13.951
22
70
16.781
5
80
20.323
2
284
Linear model fitting (Gaussian errors)

Please include the following items as part of your solution:
a) In this problem, you don’t know that the raw data errors are normally
distributed, or even if the variance is the same from one layer to the next.
Explain how you can take advantage of the Central Limit Theorem (CLT) in
this problem.
Note: real data are seldom as nice as we would like. For some ozone layers
there are fewer than five data values (the approximate number recommended
for applying the CLT), so you may want to combine data for some of the layers
where this is a problem. Of course, combining layers results in lower structural
resolution.
Note: you must provide a table of the ozone values and computed errors you
actually used in your model fitting. Explain how you computed the errors.
b) Determine the parameters for each model and the variance-covariance matrix.
Quote an error for each parameter and explain what your errors mean.
c) Compare the models with the data by plotting the model fits on the same graph as
your data. Include error bars (as you have determined them to be) on the data
points used for fitting.
d) Compute the Bayesian odds ratio of the cubic model to the quadratic model.
For the purpose of this calculation, assume the prior information warrants a
Table 10.4 Measurements of ozone partial pressure, y, in millibars in each of
15 atmospheric layers where each layer, x, is approximately 2 km in height. The layers
have been scaled for convenience from 7 to þ7.
Layer
Pressure
Layer
Pressure
Layer
Pressure
Layer
Pressure
7
53.8
5
73.2
2
97.4
3
93.6
7
53.3
5
75.6
2
98.3
3
86.2
7
54.8
5
76.2
1
102.8
3
87.9
7
54.6
5
72.7
1
96.9
3
89.5
7
53.7
4
79.4
1
98.2
4
74.8
7
55.2
4
81.1
0
98.9
4
82.3
7
55.7
4
85.2
0
96.1
4
76.9
7
54.1
4
83
0
99.6
4
81.2
6
63.8
4
84.1
0
91.4
5
73.6
6
64.2
4
82.8
1
101.1
5
65.4
6
66.9
3
90.3
1
94.6
5
67.1
6
67.2
3
84.2
1
95.9
6
60.2
6
65.4
3
88.3
2
92.3
6
54.9
6
67.3
3
86
2
96.6
6
50.8
5
71.8
2
93.2
2
98.5
7
44.7
7
38.5
10.10 Problems
285

flat prior probability for each parameter with ranges A given by:
A1 ¼ 100, A2 ¼ A3 ¼ 10, and A4 ¼ 1.
Explain in words what you conclude from this.
e) Calculate the frequentist 2 goodness-of-fit statistic and the P-value (signifi-
cance) for each model. The confidence in rejecting the model ¼ 1P-value.
Explain what you conclude from these goodness-of-fit results.
4. Repeat the analysis of the ozone data as described in the previous problem, but this
time adopt the following different strategy: instead of rebinning the data to take
advantage of the CLT, use the original binning as given in Table 10.4. According to
the MaxEnt principle (see Section 8.7.4), unless we have prior information that
justifies the use of some other sampling distribution, then use a Gaussian sampling
distribution. It makes the least assumptions about the information we don’t have
and will lead to the most conservative estimates. Use Equation (9.51) to estimate 
of each layer. In contrast to the approach proposed in the previous problem, we do
not have to sacrifice the resolution of the original data through rebinning.
286
Linear model fitting (Gaussian errors)

11
Nonlinear model fitting
11.1 Introduction
In the last chapter, we learned that the posterior distribution for the parameters in a
linear model with Gaussian errors and flat priors is itself a multivariate Gaussian. The
topology for this distribution in the multi-dimensional parameter space is very simple.
In contrast, even for flat priors, the topology of the posterior for a nonlinear model
can be very complex with many hills and valleys.
Examples of nonlinear models:
1. fi ¼ A1 cos !ti þ A2 sin !ti
where A1, A2 are linear parameters,
and ! is a nonlinear parameter.
2. fi ¼ A1 þ A2 exp
 ðxi  C1Þ2
22
1
(
)
þ A3 exp
 ðxi  C2Þ2
22
2
(
)
where A1; A2; A3 are linear parameters,
and C1; C2; 2
1; 2
2 are nonlinear parameters.
In this chapter, we will let  represent the set of all parameters both linear and
nonlinear and ^ the most probable set of the parameters. Again, the problem is to
find the most probable set of parameters together with an estimate of their errors.
(Of course, if the posterior has several maxima of comparable magnitude then it
doesn’t make sense to talk about a single best set of parameters.) The Bayesian
solution to the problem is very simple in principle but can be very difficult in
practice. The calculations require integrals over the parameter space which can be
difficult to evaluate.
The brute force approach is as follows: for a one-parameter model, the most robust
way is to plot the posterior or 2. This entails division of the parameter range into a
finite number of grid points. As long as there are enough grid points to cover the prior
range (a few hundred is usually adequate), this will usually work. It doesn’t matter
whether the posterior PDF is asymmetric, multi-modal or differentiable.
287

This approach can easily be extended to two parameters. It is also easy to compute
marginal distributions. One need only add up the probabilities in the 1 or 2 direction,
as appropriate.
After the two-parameter case, however, this approach rapidly becomes impractical.
In fact, the number of calculations is  ð100ÞM, where M is the number of parameters.
For example:
2 parameters might take 100 milliseconds to compute
5 parameters might take one day to compute
11 parameters might take the age of the universe to compute.
Fortunately, the last fifteen years have seen remarkable developments in practical
algorithms for performing Bayesian calculations (Loredo, 1999). They can be grouped
into three families: asymptotic approximations; methods for moderate dimensional
models; and methods for high dimensional models. In this chapter, we will mainly
be concerned with solutions that assume the posterior distribution for the parameters
can be approximated by a multivariate Gaussian. We will first illustrate this in a
simulation and then focus on methods for efficiently finding the most probable set of
parameters and their covariance matrix.
In the following chapter, we will give an introduction to Markov chain Monte Carlo
algorithms which facilitate full Bayesian calulations for nonlinear models involving
very large numbers of parameters.
11.2 Asymptotic normal approximation
Expressed in frequentist language, asymptotic theory tells us that the maximium
likelihood estimator becomes more unbiased, more normally distributed and of
smaller variance as the sample size becomes larger (see Lindley, 1965). In other
words, as the sample size increases, the nonlinear problem asymptotically approaches
a linear problem. From a Bayesian perspective, the posterior distribution for the
parameters asymptotically approaches a multivariate normal (Gaussian) distribution.
We will illustrate this with a simulation.
We simulated data sets with different numbers of data points by randomly sampling
a nonlinear model, represented by fðxjÞ, which has one nonlinear parameter . We
also added independent Gaussian noise to each data point with a mean of zero and a
 ¼ 2. The data values are described by the equation
yi ¼ fðxij ¼ 2=3Þ þ ei:
(11:1)
Figure 11.1 illustrates a set of N ¼ 12 simulated data points together with a plot of
the known model prediction. Of course, the data points differ from this model because
of the added noise. We then carry out a Bayesian analysis of the simulated data,
assuming we know the mathematical form of the model but not the value of the model
parameter, . Our goal is to infer the posterior PDF for  assuming a flat prior. The
288
Nonlinear model fitting

steps involved in calulating the posterior should now be fairly familiar to the reader
(e.g., Section 10.2). The resulting PDFs are graphed in Figure 11.2 for four data sets of
different size, N. It is apparent from this simulation that for small data sets, the
posterior exhibits multiple peaks, but as N increases, the posterior approaches a
Gaussian shape with a decreasing variance. The conclusion is not affected by the
choice of prior; in large samples, the data totally dominate the priors and the result
converges on a value of  ¼ 2=3, the value used to simulate the data. For a nonlinear
model with M parameters, the joint posterior for the parameters asymptotically
approaches an M-dimensional multivariate Gaussian as the number of data points
becomes much greater than the number of unknown parameters.
0.2
0.4
0.6
0.8
1
x
0
2
4
6
y
Figure 11.1 A simulated set of 12 data points for a nonlinear model with the one parameter
 ¼ 2=3 (solid line) plus added Gaussian noise.
0
0.2
0.4
0.6
0.8
1
α Parameter value
0
2
4
6
8
10
12
14
Probability density
N = 80
N = 40
N = 10
N = 5
Figure 11.2 The Bayesian posterior density function for the nonlinear model parameter for four
simulated data sets of different size ranging from N ¼ 5 to N ¼ 80. The N ¼ 5 case has the
broadest distribution and exhibits four maxima.
11.2 Asymptotic normal approximation
289

In what follows, we will assume that in the vicinity of the mode of the joint posterior,
the product of the prior and likelihood can be approximated by a multivariate
Gaussian. We want to develop a convenient mathematical formulation to describe
an approximate multivariate Gaussian. We start with one form of the posterior for a
true multivariate Gaussian we developed for linear models in Section 10.4 which we
repeat here (see Equation (10.66)), only this time we let A stand for the set of linear
model parameters that we previously wrote as fAg.
pðAjD; M; IÞ ¼ C0 exp  ATyA
22


:
(11:2)
This equation describes the joint posterior for a set of linear model parameters
assuming flat priors for the parameters. When we use the more powerful matrix
formulation which includes the data covariance matrix E (see Section 10.5.3), then
we replace y by Y and rewrite Equation (11.2) as
pðAjD; M; IÞ ¼ C0e1
2ðATYAÞ:
(11:3)
The term C0 is the value of the posterior at the mode, which can be written as the
product of the prior times the maximum value of the likelihood. The exponential term
in Equation (11.3) describes the variation of the likelihood about the mode which has
the form of a multivariate Gaussian. Thus, we can rewrite Equation (11.2) as
pðAjD; M; IÞ / pðAjM; IÞpðDjA; M; IÞ ¼ pðAjM; IÞLðAÞ
¼ pð ^AjM; IÞLð ^AÞ exp  1
2
X

ðA  ^AÞ½YðA  ^AÞ
"
#
:
(11:4)
Now take the natural logarithm of both sides.
ln½ pðAjM; IÞLðAÞ ¼ ln pð ^AjM; IÞLð ^AÞ


þ  1
2
X

ðA  ^AÞ½YðA  ^AÞ
"
#
:
(11:5)
We can show that Y is a matrix of second derivatives of ln½ pðAjM; IÞLðAÞ at A ¼ ^A.
 ¼ 
@2
@A@A
ln½ pðAjM; IÞLðAÞ
ðat A ¼ ^AÞ:
(11:6)
For the nonlinear model case, we will represent the set of model parameters by  and
write an equation analogous to (11.4).
pðjD; M; IÞ  pð^jM; IÞLð^Þ exp  1
2
X

ð  ^Þ½Ið  ^Þ
"
#
;
(11:7)
290
Nonlinear model fitting

where I is called the Fisher information matrix and is the nonlinear problem analog of
Y in the linear case. The approximate sign in the above equation is there because the
posterior is only approximately a multivariate Gaussian at the mode. We can rewrite
Equation (11.7) as
ln½pðjM; IÞLðÞ ¼ ln pð^jM; IÞLð^Þ
h
i
þ  1
2
X

ð  ^Þ½Ið  ^Þ
"
#
:
(11:8)
I is a matrix of second derivatives of ln½pðjM; IÞLðÞ at  ¼ ^.
I ¼ 
@2
@@
ln½pðjM; IÞLðÞ
ðat  ¼ ^Þ:
(11:9)
Recall that Y1 is the covariance matrix of the parameters in the linear problem. Y1
provides a measure of how wide or spread out the Gaussian is. If the posterior in the
nonlinear problem is not Gaussian, but is unimodal (single peak), then I1 does not
give the variances and covariances of the posterior distribution. However, it may give
a good estimate of them, and is probably easier to calculate than the integrals required
to get the variances and covariances.
A difficulty arising in these computations is that it has not been possible to present
guidelines for how large the sample size must be for asymptotic properties to be closely
approximated. In Section 11.4, we will assume the approximation is good enough, and
focus on useful schemes for finding the most probable parameters, ^. But first we will
investigate another useful type of approximation that allows us to obtain a better
estimate of the desired Bayesian quantities without having to perform complicated
integrals. These kinds of approximation originated with Laplace, so they are called
Laplacian approximations.
11.3 Laplacian approximations
11.3.1 Bayes factor
Suppose we want to compute the Bayes factor for model comparison (Section 3.5). In
this case, we need to compute the global likelihood, pðDjM; IÞ, by integrating over all
the model parameters (also required for the normalization constant in parameter
estimation). We can evaluate this from Equation (11.7).
pðDjM; IÞ ¼
Z
d pðjM; IÞLðÞ
 pð^jM; IÞLð^Þ
Z
d exp  1
2 ðqTIqÞ


;
(11:10)
where ½ ¼ ð  ^Þ. We can use the principal axis theorem to make a change
of variables according to q ¼ OX, that transforms qTIq to XTLX, where L is
11.3 Laplacian approximations
291

a diagonal matrix of eigenvalues of the I matrix. The columns of O are the
orthonormal eigenvectors of I. Let 1; 2; . . . ; M be the eigenvalues of I. Then
we can write
I ¼
Z
d exp  1
2 ðqTIqÞ


¼ J
Z
dX exp  1
2 ðXTLXÞ


;
(11:11)
where J ¼ det O, is the Jacobian of the transformation,
R
d ¼ J
R
dX. Since the
columns of O are orthonormal J ¼ 1.
For the M ¼ 2 case,
I ¼
Z
dX exp  X2

2

 Z
dX exp 
X2

2
"
#
¼ ð
ﬃﬃﬃﬃﬃﬃ
2p
p
Þ2
1ﬃﬃﬃﬃﬃﬃ

p
1ﬃﬃﬃﬃﬃ

p
Z
dX
1
ﬃﬃﬃﬃﬃﬃ
2p
p
1=
ﬃﬃﬃﬃﬃﬃ

p
exp  X2

2=



Z
dX
1
ﬃﬃﬃﬃﬃﬃ
2p
p
1=
ﬃﬃﬃﬃﬃ

p
exp 
X2

2=
"
#
¼ ð
ﬃﬃﬃﬃﬃﬃ
2p
p
Þ2
1ﬃﬃﬃﬃﬃﬃ

p
1ﬃﬃﬃﬃﬃ

p
:
(11:12)
For the general case of arbitrary M, we have,
I ¼ ð2pÞM=2
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Q
 
q
:
(11:13)
We can express our result for I in terms of the det I by writing I ¼ OLOT. Then
det I ¼ det OT  det L  det O
¼ 1 
Y

  1 ¼
Y

:
(11:14)
Substituting Equation (11.14) into Equation (11.13), we obtain
I ¼ ð2pÞM=2ðdet IÞ1=2:
(11:15)
Even if the multivariate Gaussian approximation is not exact, but the posterior
distribution has a single dominant peak located away from the prior boundary of the
parameter space, then the use of Equation (11.15) provides a useful Laplacian
approximation. Thus, the global likelihood can be written as
pðDjM; IÞ  pð^jM; IÞLð^Þð2pÞM=2ðdet IÞ1=2:
(11:16)
292
Nonlinear model fitting

In the case of a perfect Gaussian approximation and a uniform parameter prior,
Equation (11.16) reduces to Equation (10.123). In Section 11.4, we will discuss how to
locate the best set of parameters, ^.
11.3.2 Marginal parameter posteriors
We can also use the Laplacian approximation in Equation (11.15) to do the integral
needed to eliminate nuisance parameters. Suppose we want to obtain the marginal
probability distribution for one of the parameters which we will label .1 We need to
remove the remaining parameters which we label collectively as 	. Instead of integrat-
ing over the 	 parameters, we construct a ‘‘profile’’ function for , found by maximizing2
the prior  the likelihood over 	 for each choice of : fðÞ ¼ max	 pð;	jM; IÞ
Lð; 	Þ. The profile function is a projection of the posterior onto the  axis. Finding a
maximum is generally much faster than computing the integrals. An efficient method
of finding the maximum, starting from a good guess, is discussed in Section 11.5. We
can construct an approximate marginal distribution for  by multiplying fðÞ by
a factor that accounts for the volume of 	 space:
pðjD; M; IÞ / fðÞ½det IðÞ1=2;
(11:17)
where IðÞ is the information matrix of the nuisance parameters, with  held fixed.
To illustrate how different the marginal and projected distributions can be, consider
a hypothetical joint probability distribution for the parameters  and 	 as shown in
panel (a) of Figure 11.3. The projected and marginal distributions for  are shown in
0
0.2
0.4
0.6
0.8
1
θ axis 
0
0.2
0.4
0.6
0.8
1
φ axis
(a) Joint Probability 
0
0.2
0.4
0.6
0.8
1
θ axis
0
0.5
1
1.5
2
2.5
3
Probability Density
(b) Marginal and Projected
marginal
projected
Figure11.3Comparisonof the projected andmarginal probability distributionfor the  parameter.
1 More generally,  can represent a subset of one or more parameters of interest, with the remainder considered as
nuisance parameters.
2 This process is easy to visualize if there are only two parameters A1 and A2. The joint probability distribution,
pð ~A1; A2jD; IÞ, is a three-dimensional space with A1 and A2 as the x; y-axes and probability as the z-axis. Each choice of
A2 (i.e., A2 ¼ constant) corresponds to a vertical slice through the probability mountain. We then vary A1 until we find
the maximum value of the probability in that slice. Repeat this process for all possible choices of parameter A2 and
record the probability pð ~A1; A2jD; IÞ. The resulting PDF is a function of A2 and can be seen to be the projection of the
joint probability mountain onto the A2 axis.
11.3 Laplacian approximations
293

panel (b). Although the peak probability occurs near  ¼ 0:65, more probability
resides in the broad plateau to the left of the peak and this is indicated by the marginal
distribution. The value of the marginal, pðjD; IÞ, for any particular choice of , is
proportional to the integral over 	, i.e., the area under a slice of the joint probability
distribution for  fixed. Clearly, this area can be approximated by the peak height of
the slice times a characteristic width of the probability distribution in the slice. In this
two-parameter problem, the projected distribution is converted to an approximation
of the true marginal by multiplying by the factor ½det IðÞ1=2 in Equation (11.17),
which gives the scale of the width of the distribution in the 	 direction for the
particular value of . Recall from Equation (11.14) the det IðÞ is equal to the product
of the eigenvalues of IðÞ. At this point, it might be useful to refer back to Figure 10.3,
which shows how the eigenvalues of the corresponding y matrix in the linear model
problem give information on the scale of the width of the posterior.
We explore the Laplacian marginal distribution further in the following example:
consider a nonlinear model of the form fðxj; Þ ¼ x1ð1  xÞ1 for 0 < x and
;  > 1. We constructed a simulated data set for 12 values of the independent
variable, x, using this nonlinear model with  ¼ 6;  ¼ 3, and added independent
Gaussian noise with a mean of zero and a  ¼ 0:005. The data values are described by
the equation
yi ¼ fðxij ¼ 6;  ¼ 3Þ þ ei:
(11:18)
The results of this simulation are shown in the four panels of Figure 11.4. Panel (a)
shows the simulated data (diamonds) and model (solid curve). Panel (b) shows a
contour plot of the Bayesian joint posterior probability of  and , which differs
significantly from a multivariate Gaussian. Panel (c) compares the projected or profile
function (dots) and Bayesian marginal probability density for  (dashed). Panel (d) is
the same as (c) but with the Laplacian approximation of the marginal overlaid,
illustrating the close agreement with the true marginal density. You will have to look
very closely to see any difference. The difference between the derived most probable
values of  ¼ 3:2 and the true value of  ¼ 3 is simply a consequence of the added noise.
The Laplacian marginal distribution can perform remarkably well even for modest
amounts of data, despite the fact that one might expect the underlying Gaussian
approximation to be good only to order 1=
ﬃﬃﬃﬃ
N
p
, the usual rate of asymptotic conver-
gence to a Gaussian. The Laplacian approximations are good to order 1=N or higher.
For more details on this point, see Tierney and Kadane (1986).
11.4 Finding the most probable parameters
In this section, we will assume flat priors for the model parameters and focus on
methods for finding the peak of the likelihood. Again, we assume the data are given by
di ¼ fi þ ei;
294
Nonlinear model fitting

where fi represents the model function and assume our knowledge of noise ei leads us
to assume Gaussian errors.
Then the likelihood is given by
LðÞ ¼ pðDj; M; IÞ ¼ C exp  1
2
X
N
i; j¼1
ðdi  fiÞ½E1ijðdj  fjÞ
"
#
;
(11:19)
where E ¼ covariance matrix of measurement errors. If the errors are independent,
E is diagonal with entries equal to 2
i . In this case
pðDj; M; IÞ ¼ ð2pÞN=2 Y
N
i¼1
1
i
exp  1
2
X
N
i¼1
ðdi  fiÞ2
2
i
"
#
¼ C exp  2ðÞ
2


:
(11:20)
2.8
3
3.2 3.4 3.6 3.8
4
β axis 
0.25
0.5
0.75
1
1.25
1.5
Probability density
(c)
2.8
3
3.2 3.4 3.6 3.8
4
β axis
0.25
0.5
0.75
1
1.25
1.5
Probability density
(d)
0.2
0.4
0.6
0.8
1
x
– 0.005 
0
0.005
0.01
0.015
0.02
y
(a) Model + Data
4
5
6
7
8
α axis 
2.6
2.8
3
3.2
3.4
3.6
3.8
4
β axis 
(b) Probability Contours
Figure 11.4 The figure provides a demonstration of the Laplacian approximation to the
marginal posterior for a model parameter. Panel (a) shows the simulated data (diamonds)
and model (solid curve), which has two nonlinear parameters  and . (b) shows a contour plot
of the Bayesian joint posterior probability of  and , which differs significantly from a
multivariate Gaussian. (c) compares the projected or profile function (dots) and Bayesian
marginal probability density for  (dashed). (d) is the same as (c) but with the Laplacian
approximation of the marginal overlaid, illustrating the close agreement with the true marginal
density.
11.4 Finding the most probable parameters
295

In general, 2ðÞ may have many local minima but only one global minimum. For a
nonlinear model, there is no general solution to the global minimization problem.
Some of the approaches to finding the global minimum are as follows:
1. Random search techniques
a) Monte Carlo exploration of parameter space
b) Simulated annealing
c) Genetic algorithm
2. Home in on minimum from initial guess
a) Levenberg Marquardt (iterative linearization)
b) Downhill simplex
3. Combination of above. MINUIT is a very powerful Fortran-based function minimization and
error analysis tool developed at CERN. It is designed to find the minimum value of a multi-
parameter function and analyze the shape of the function around the minimum. The principal
application is for statistical analysis, working on 2 or log-likelihood functions, to compute the
best-fit parameter values and uncertainties, including correlations between the parameters.
MINUIT contains code for carrying out a combination of the above items 1(a), 1(b), 2(a)
and 2(b). For more information on MINUIT see: http://wwwinfo.cern.ch/asdoc/minuit.
11.4.1 Simulated annealing
The idea of using a temperature parameter in optimization problems started to
become popular with the introduction of the simulated annealing (SA) method by
Kirkpatrick et al. (1983). It is based on a thermodynamic analogy to growing a crystal
starting with the material in a liquid state called a melt. When a melt is slowly cooled,
the atoms will achieve the lowest energy crystal state (i.e., global minimum), whereas if
it is rapidly cooled, it will reach a higher energy amorphous state.
Kirkpatrick et al. (1983) proposed a computer imitation of thermal annealing for
use in optimization problems. In one version of simulated annealing, we construct a
modified posterior probability distribution pTðjD; IÞ which is given by
pTðjD; IÞ ¼ exp ln½ pðjD; IÞ
T


;
(11:21)
which contains a temperature parameter T. For T ¼ 1, pTðjD; IÞ is equal to the true
posterior distribution for . For higher temperatures, pTðjD; IÞ is a flatter version of
pðjD; IÞ. The basic scheme involves an exploration of the parameter space by a series
of random changes in the current c estimate of the solution
next ¼ c þ ;
(11:22)
where  is chosen by a random number generator. The proposed update is always
considered advantageous if it yields a higher pTðjD; IÞ, but bad moves are sometimes
296
Nonlinear model fitting

accepted. This occasional allowance of retrograde steps provides a mechanism for
escaping entrapment in local maxima. The process starts off with T large so the
acceptance rate for unrewarding changes is high. The value of T is gradually decreased
towards T ¼ 1 as the number of iterations gets larger and the acceptance rate of
unrewarding changes drops. This general scheme, of always accepting an uphill step
while sometimes accepting a downhill step, has become known as the Metropolis
algorithm (Metropolis et al., 1953). At each value of T the Metropolis algorithm is
used to explore the parameter space. The Metropolis algorithm and the related
Metropolis–Hasting algorithms are described in more detail in Section 12.2.
Assuming a flat prior for , it is frequently the case that pðjD; IÞ / expf2=2g.
Simulated annealing works well for a 2 topology like that shown in Figure 11.5,
where there is an underlying trend towards a global minimum.
11.4.2 Genetic algorithm
Genetic algorithms are a class of search techniques inspired from the biological
process of evolution by means of natural selection (Holland, 1992). They can be
used to construct numerical optimization techniques that perform robustly in para-
meter search spaces with complex topology.
Consider the following generic modeling task: a model that depends on a set of
adjustable parameters is used to fit a given dataset; the task consists in finding the
single parameter set that minimizes the difference between the model’s predictions and
the data. The genetic algorithm consists of the following steps.
1. Start by generating a set (‘‘population’’) of trial solutions, usually by choosing random values
for all model parameters.
2. Evaluate the goodness-of-fit (‘‘fitness’’) of each member of the current population (through a
2 measure with the data, for example).
3. Select pairs of solutions (‘‘parents’’) from the current population, with the probability of a
given solution being selected made proportional to that solution’s fitness. Breed the two
solutions selected in (2) and produce two new solutions (‘‘offspring’’).
a
χ2(a)
Global and local minima
Figure 11.5 Sample topology of 2 for a nonlinear model with one parameter labeled a.
11.4 Finding the most probable parameters
297

4. Repeat steps (2)–(3) until the number of offspring produced equals the number of individuals
in the current population.
5. Use the new population of offspring to replace the old population.
6. Repeat steps (1) through (5) until some termination criterion is satisfied (e.g., the
best solution of the current population reaches a goodness-of-fit exceeding some
preset value).
Superficially, this may look like some peculiar variation of a Monte Carlo theme.
There are two crucial differences: first, the probability of a given solution being
selected to participate in a breeding event is made proportional to that solution’s
fitness (step 2); better trial solutions breed more often, the computational equivalent
of natural selection. Second, the production of new trial solutions from existing ones
occurs through breeding. This involves encoding the parameters defining each solu-
tion as a string-like structure (‘‘chromosome’’), and performing genetically inspired
operations of crossover and mutation to the pair of chromosomes encoding the two
parents, the end result of these operations being two new chromosomes defining the
two offspring. Applying the reverse process of decoding those strings into solution
parameters completes the breeding process and yields two new offspring solutions that
incorporate information from both parents.
If you want to try out the genetic algorithm and watch a demonstration, check out the
following web site: http://www.hao.ucar.edu/public/research/si/pikaia/pikaia.html#sec2.
PIKAIA (pronounced ‘‘pee-kah-yah’’) is a general purpose function optimization
Fortran-77 subroutine based on a genetic algorithm. PIKAIA was written by Paul
Charbonneau and Barry Knapp (Charbonneau, 1995; Charbonneau and Knapp,
1995) both at the High Altitude Observatory, a scientific division of the National
Center for Atmospheric Research in Boulder, Colorado. The above web site lists other
useful references.
11.5 Iterative linearization
In this section, we will develop the equations needed for understanding the
Levenberg–Marquardt method which is discussed in Section 11.5.1. This is a widely
used and efficient scheme for homing in on the best set of nonlinear model parameters,
^, starting from an initial guess of their values. Start with a Taylor series expansion of
2 about some point in  parameter space represented by c (standing for current) and
keep only the first three terms:
2ðÞ  2ðcÞ þ
X
k
@2ðcÞ
@k
k þ 1
2
X
kl
@22ðcÞ
@k @l
kl;
(11:23)
where
 ¼   c:
(11:24)
298
Nonlinear model fitting

For a linear model, 2 is quadratic so there are no higher derivatives. Let

kl ¼ 1
2
@22ðcÞ
@k @l
be called the curvature matrix. On the topic of nomenclature, in nonlinear analysis
literature, the Hessian (H) matrix is frequently mentioned and is related to our
curvature matrix by H ¼ 2k. In matrix form, Equation (11.23) becomes
2ðÞ  2ðcÞ þ r2ðcÞq þ qTkq:
(11:25)
Take the gradient of both sides of Equation (11.25)
r2ðÞ  r2ðcÞ þ k q:
(11:26)
The left hand side is the gradient at location  away from c.
Now consider the special case where  takes us from c to ^, the best set of
parameter values. At  ¼ ^  c; 2 ¼ 2
min. In this case,
r2ð^Þ ¼ r2
min ¼ 0
(11:27)
k q ¼ r2ðcÞ
(11:28)
or
^ ¼ c  k1r2ðcÞ
(11:29)
where k1 ¼ inverse of the curvature matrix. For a linear model, 2 is exactly a
quadratic and thus k is constant independent of c.
For a nonlinear model, we expect that sufficiently close to 2
min; 2 will be approxi-
mately quadratic so we should be able to ignore higher order terms in the Taylor
expansion. Equation (11.29) should provide a reasonable approximation if c is close to ^.
This suggests an iterative algorithm:
1. Start with a good guess 1 of ^.
2. Evaluate gradient r2ð1Þ and curvature matrix kð1Þ.
3. Calculate improved estimate using Equation (11.29).
4. Repeat process until gradient ¼ 0.
When r2ðcÞ ¼ 0 then k1 ¼ information matrix. Thus, the covariances of the
parameters are to a good approximation given by
kl ¼ ½k1kl:
(11:30)
If Equation (11.29) provides a poor approximation to the shape of the model function
at c, then all we can do is to step down the gradient.
next ¼ c  constantr2ðcÞ;
(11:31)
11.5 Iterative linearization
299

where the constant is small enough not to exhaust the downhill direction (more on the
constant later). Note: if you are planning on writing your own program for iterative
linearization, see the useful tips on computing the gradient and curvature (Hessian)
matrices given in Press (1992).
11.5.1 Levenberg–Marquardt method
We can rewrite Equation (11.28) as a set of M simultaneous equations for
k ¼ 1; . . . ; M
X
M
l¼1

kll ¼ k;
(11:32)
where k ¼ @ 2ðcÞ=@k; and for M ¼ 2,

111 þ 
122 ¼ 1,

211 þ 
222 ¼ 2:
We can also rewrite Equation (11.31) as
l ¼ constant  l:
(11:33)
Equations (11.32) and (11.33) are central to the discussion of the Levenberg–Marquardt
method which follows.
Far from 2
min, use Equation (11.33) which corresponds to stepping down the
direction of steepest descent on a scale set by the constant. Close to 2
min, use
Equation (11.32) which allows us to jump directly to the minimum.
What sets the scale of the constant in Equation (11.33)? Note: l ¼ @2=@l
has dimensions of 1=l which may have dimensions (e.g., m). Each component l
may have different dimensions. The constant of proportionality between l and l
must therefore have dimensions of 2
l . Looking at 
, there is only one obvious
quantity with the above dimension and that is 1=
ll, the reciprocal of the diagonal
element. But the scale might be too big, so divide it by an adjustable non-dimensional
fudge factor .
l ¼ 1

ll
l
(11:34)
or

lll ¼ l:
(11:35)
The next step is to combine Equations (11.32) and (11.35) by defining a new
curvature matrix k0

0
kk ¼ 
kkð1 þ Þ
(11:36)
300
Nonlinear model fitting

and

0
kl ¼ 
kl
ðk 6¼ lÞ:
(11:37)
The new equation is
X
M
l¼1

0
kll ¼ k:
(11:38)
If  is large, k0 is forced into being dominated by the diagonal elements and becomes
Equation (11.33). If  ! 0, Equation (11.38) ! Equation (11.32). The basis of the
method is that when c is far from ^, then Equation (11.33) representing the steepest
descent is best. When c is close to ^, then Equation (11.32) is best.
The Levenberg–Marquardt method employs Equation (11.38) which can switch
between these two desirable states (Equations (11.32) and (11.33)) by varying . Recall
Equation (11.32) can jump to the 2
min in one step if the approximation is valid.
11.5.2 Marquardt’s recipe
1. Compute 2ð1Þ for guess of ^.
2. Pick a small value of   0:001.
3. Solve Equation (11.38) for  and evaluate 2ð1 þ Þ.
4. If 2ð1 þ Þ  2ð1Þ increase  by factor of 10 and go to (3).
5. If 2ð1 þ Þ < 2ð1Þ, decrease  by a factor of 10, update trial solution. 2  1 þ .
6. Repeat steps (3) to (5) until the solution converges.
Since k plays the role of a metric on the M-dimensional subspace spanned by the
model functions, the Levenberg–Marquardt method is referred to as a variable metric
approach. The matrix k is the same as the y matrix in the linear model case.
All that is necessary is a condition for stopping the iteration. Iterating to conver-
gence or machine accuracy is generally wasteful and unnecessary since the minimum at
best is only a statistical estimate of the parameter . Recall from our earlier discussion
of joint credible regions in Section 10.4.1, that changes in 2 by an amount  1 are
never statistically meaningful. For M ¼ 2 parameters, the probability ellipse defined
by 2 ¼ 2:3 away from 2
min encompasses 68.3% of the joint PDF. For M ¼ 1 the
corresponding 2 ¼ 1. These considerations suggest that, in practice, stop iterating
on the 1st or 2nd iteration that 2 decreases by an amount  1.
Once the minimum is found, set  ¼ 0 and compute the variance-covariance matrix
V ¼ k1
to obtain the estimated standard errors of the fitted parameters. Mathematica uses the
Levenberg–Marquardt method in NonlinearRegress analysis. Subroutines are also
available in Press (1992). If the posterior has several maxima of comparable magni-
tude, then in this case it doesn’t make sense to talk about a single best ^.
11.5 Iterative linearization
301

11.6 Mathematica example
In this example, we illustrate the solution of a simple nonlinear model fitting problem
using Mathematica’s NonlinearRegress which implements the Levenberg–Marquardt
method. The data consist of one or possibly two spectral lines sitting on an unknown
constant background. The measurement errors are assumed to be IID normal with a
 ¼ 0:3. Model 1 assumes the spectrum contains a single spectral line while model 2
assumes two spectral lines. The raw data and measurement errors are shown in panel
(a) of Figure 11.6, together with the best fitting model 1 shown by the solid curve. The
parameter values for the best fitting model 1 were obtained with the NonlinearRegress
command as illustrated in Figure 11.7. The arguments to the command are as follows:
1. data is a list of ðx; yÞ pairs of data values where the x value is a frequency and the y value a
signal strength.
2. model[ f ] is the mathematical form of the model for the spectrum signal strength as a function
of frequency, f. This is given by
model[ f ] :¼ a0 þ a1 line[ f, f 1]
where,
line[ f ; f1 ] :¼ Sin[2pð f  f 1Þ=Df ]
2pð f  f1Þ=Df
;
0
1
2
3
4
5
6
Frequency axis
1
2
3
4
Signal
(c) Model 2 + Raw Data
0
1
2
3
4
5
6
Frequency axis
–0.75
–0.5
–0.25
0
0.25
0.5
0.75
1
Signal
(d) Residuals
0
1
2
3
4
5
6
Frequency axis
1
2
3
4
Signal
(a) Model 1 + Raw Data 
0
1
2
3
4
5
6
Frequency axis
–0.5
0
0.5
1
1.5
Signal
(b) Residuals
Figure 11.6 Two nonlinear models fitted to simulated spectral line data. Panel (a) shows the raw
data and the best fit (solid curve) for model 1 which assumes a single line. Panel (b) illustrates the
model 1 fit residuals. Panel (c) shows the best-fit model 2 compared to the data. Panel (d) shows
the model 2 residuals.
302
Nonlinear model fitting

where D f ¼ 1:5. Note: line [ f, f 1] becomes indeterminate for ð f  f 1Þ ¼ 0. To avoid the
likelihood of this condition occurring in NonlinearRegress, set the initial estimate of f 1 to a
non-integer number.
3. f is the independent variable frequency.
4. The third item is a list of the unknown model parameters and initial estimates. Since
NonlinearRegress uses the Levenberg–Marquardt method, it is important that the initial
estimates land you somewhere in the neighborhood of the global minimum of 2, where
2 ¼
X
N
i¼1
ðdi  model[ fi]Þ2
2
i
¼
X
N
i¼1
wtiðdi  model[ fi]Þ2:
5. wt is an optional list of weights to be assigned to the data points, where wti ¼ 1=2
i .
6. RegressionReport is a list of options for the output of NonlinearRegress.
7. ShowProgress ﬁTrue shows the value of 2 achieved after each iteration of the
Levenberg–Marquardt method and the parameter values at that step.
result = Nonlinear [Regressdata,
model[f], {f}, {{a0, 1.2), {a1,4}, {f1, 2.6}}, Weights->wt,
RegressionReport->
{BestFitParameters, ParameterCITable,
AsymptoticCovarianceMatrix, FitResiduals, BestFit},
ShowProgress-> True]
Iteration:1 ChiSquared:128.05290737029276` Parameters:{1.2, 4., 2.6}
Iteration:2 ChiSquared:67.07120991521835` Parameters:{1.04667, 3.1995, 2.58491}
Iteration:3 ChiSquared:66.77321228639481` Parameters:{1.04602, 3.20506, 2.57661}
Iteration:4 ChiSquared:66.74836021101748` Parameters:{1.04588, 3.20626, 2.5742}
Iteration:5 ChiSquared:66.74632730538346` Parameters:{1.04587, 3.20636, 2.57351}
Iteration:6 ChiSquared:66.7461616482541` Parameters:{1.04587, 3.20636, 2.57332}
{BestFitParameters→ {a0→1.04587, a1→3.20637, f1→2.57326},
ParameterCITable→
Estimate
Asymptotic SE
CI
a0
1.04587
0.0545299
{0.936233, 1.15551}
a1
3.20637
0.190783
{2.82277, 3.58996}
f1
2.57326
0.0204051
{2.53224, 2.61429}
AsymptoticCovarianceMatrix→
0.00297351
–0.00434888
–1.20476 × 10–6
–0.00434888
0.036398
1.68676 × 10–6
1.20476 × 10–6
1.68676 × 10–6
0.000416367
,
,
FitResiduals→  {–0.209178, 0.0139153, –0.351702, 0.108264, –0.081711, 0.232977,
–0.0502895, 0.0859089, –0.0988917, –0.181999, 0.0500372, –0.33713, –0.329429,
–0.218716, –0.151456, 0.0154221, –0.264555, 0.496109, 0.256117, 0.616037, –0.194287,
–0.0907203, –0.448441, 0.12935, –0.0518219, 1.02491, 0.559758, 0.660035, 0.980723,
0.291933, –0.133344, –0.389732, –0.0151427, –0.186632, –0.166834, –0.388142,
0.297471, –0.477721, –0.287358, –0.331853, –0.401507, –0.263538, 0.20304, 0.102339,
0.166333, 0.178261, –0.337149, –0.339727, –0.258125, 0.100323, 0.062864},
BestFit→ 1.04587 + 0.182741 Sin[4.18879 (–2.57326 + f)]2
(–2.57326 + f)2
}
Figure 11.7 Example of the use of the Mathematica command NonlinearRegress to fit model 1 to
the spectral data.
11.6 Mathematica example
303

The full NonlinearRegress command together with its arguments is shown in
bold face type in Figure 11.7. The output, shown in normal type face, indicates
that the minimum 2 achieved for model 1 was 66.7.3 Below that is a list of the
various RegressionReport items. The second item lists the parameter values, the
asymptotic standard error for each parameter and the frequentist confidence
interval (95% by default) for each parameter. The asymptotic error for each
parameter is equal to the square root of the corresponding diagonal element in
the AsymptoticCovarianceMatrix. The use of these errors is based on the assump-
tion that in the vicinity of the mode, the joint posterior probability density
function for the parameters is a good approximation to a multivariate Gaussian
(see Section 11.2). The AsymptoticCovarianceMatrix ¼ I1, the inverse of the
observed information matrix. Note: the AsymptoticCovarianceMatrix elements, as
given by NonlinearRegress, have been scaled by a factor k2 ¼ 1:39 where k is given
by Equation (10.144). This leads to more robust parameter errors but we must
correct for this later on when we compute the Bayesian odds ratio for comparing
models 1 and 2. The values of 2 quoted in the output of Figure 11.7 have not
been modified by the k factor and thus 2
min ¼ 66:7 is the minimum value calcul-
ated on the basis of the input measurement error  ¼ 0:3.
Panel (b) of Figure 11.6 shows the residuals after subtracting model 1 from the data.
There is clear evidence for another spectral line at about 3.6 on the frequency axis. On
the basis of these residuals, a second model was constructed, consisting of two spectral
lines sitting on a constant background. Model 2 has the mathematical form:
model[ f; f]: = a0 + a1 line[ f1] + a2 line[ f; f2]:
Panel (c) shows the best fitting model 2. The residuals shown in Panel (d) appear to
be consistent with the measurement errors and show no evidence for any further
systematic signal component. The output from Mathematica’s NonlinearRegress
command for model 2 is shown in Figure 11.8.
11.6.1 Model comparison
Here, we compute the Bayesian odds ratio given by
O21 ¼ pðM2jD; IÞ
pðM1jD; IÞ ¼ pðM2jIÞ
pðM1jIÞ  pðDjM2; IÞ
pðDjM1; IÞ
¼ pðM2jIÞ
pðM1jIÞ  Bayes factor:
(11:39)
3 Here, we evaluate the frequentist theory confidence in rejecting model 1. Model 1 has three fit parameters
so the number of degrees of freedom ¼ N  M ¼ 51 data points 3 ¼ 48; thus the confidence is
¼
1  GammaRegularized NM
2
; 2
2
h
i
¼ 0:96.
304
Nonlinear model fitting

We will use the Laplace approximation for the Bayes factor described in Section 11.3.1
which expresses the global likelihood, given by Equation (11.16), in terms of the
determinant of the information matrix, I.
pðDjMi; IÞ  pð^jMi; IÞLð^Þð2pÞM=2ðdet IÞ1=2
¼
1
Q
 
1
Nð2pÞN=2 e2
min=2ð2pÞM=2ðdet IÞ1=2:
(11:40)
Let V stand for the parameter asymptotic covariance matrix in thenonlinear problem,so
ðdet IÞ1=2 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det V
p
:
(11:41)
Equation (11.40) assumes uniform priors for the model parameters, where  is the
prior range for parameter . In the current problem, we assume the prior ranges for
the parameters are known to within a factor of three of the initial estimates used in
NonlinearRegress, i.e., 3  =3 ¼ 2:667.
Let V be the asymptotic covariance matrix elements returned by Mathematica’s
NonlinearRegress command. Recall that Mathematica scales the asymptotic covariance
matrix elements by a factor k2, to allow for more robust parameter errors, where k is
given by Equation (10.144). We need to remove this factor for use in Equation (11.40),
result = NonlinearRegress[data,
model2[f], {f}, {{a0, 1.2}, {a1, 3}, {f1, 2.6}, {a2, 1}, {f2, 3.5}},Weights-> wt,
RegressionReport ->
{BestFitParameters, ParameterCITable, BestFit},
ShowProgress -> True]
Iteration:1 ChiSquared:113.44567855780089` Parameters:{1.2, 3., 2.6, 1., 3.5}
Iteration:2 ChiSquared:44.87058091255775`
Parameters:{0.996707, 3.16903, 2.55205, 0.447086, 3.22451}
Iteration:3 ChiSquared:39.478968989091` Parameters:{0.958289, 3.08133, 2.51609, 0.866957, 2.98474}
Iteration:4 ChiSquared:31.202371941916066`
Parameters:{0.934233, 2.99456, 2.48976, 1.14837, 3.12047}
Iteration:5 ChiSquared:30.26136004999436`
Parameters:{0.933864, 2.94356, 2.48483, 1.20244, 3.06137}
Iteration:6 ChiSquared:30.236264668012137`
Parameters:{0.932706, 2.93206, 2.48383, 1.22363, 3.06401}
{BestFitParameters → {a0→0.932717, a1→2.93172, f1→2.48379, a2→1.22387, f2→3.0638},
ParameterCITable →
Estimate
Asymptotic SE
CI
a0
0.932717
0.0406876
{0.850817,1.01462}
a1
2.93172
0.182306
{2.56476,3.29869}
f1
2.48379
0.0253238
{2.43281,2.53476}
a2
1.22387
0.182139
{0.857242,1.5905}
f2
3.0638
0.0606851
{2.94164,3.18595}
,
BestFit →
0.932717 + 0.0697522 Sin[4.18879(–3.0638 + f)]2
(–3.0638+f)2
0.167088 Sin[4.18879(–2.48379 + f)]2
(–2.48379 + f)2
+
Figure 11.8 The output from Mathematica’s NonlinearRegress command for model 2.
11.6 Mathematica example
305

by multiplying the asymptotic covariance matrix provided by Mathematica by 1=k2,
before computing its determinant, i.e.,
V ¼ 1
k2 V:
(11:42)
We can extract V from result, the name given to the result of the NonlinearRegress
command. For model 1 (see Figure 11.7) the covariance matrix was the third item in
the RegressionReport. Thus, V ¼ result½½3; 2½½1 is the desired matrix.4 The value of
O21 derived from Equations (11.39), (11.40), (11.41), and (11.42), assuming equal
prior probabilities for the two models, is 1:4  105.
11.6.2 Marginal and projected distributions
Finally, we will compute the Laplacian approximation to the Bayesian marginal
probability density function pðjD; M; IÞ and compare it to the frequentist projected
probability, which we refer to as the profile function, fðÞ, according to Equation
(11.17). We illustrate this calculation for the a2 parameter. The Laplacian marginal is
the profile function fða2Þ times the factor
½det Iða2Þ1=2 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det Vða2Þ
p
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det 1
k2 Vða2Þ
r
:
(11:43)
The
quantity
Vða2Þ
is
the
asymptotic
covariance
matrix
evaluated
by
NonlinearRegress obtained by fixing a2 and minimizing 2, with all the other para-
meters free to vary. This can be done using a simple Do loop to repeatedly run
NonlinearRegress for different values of a2. For an example of this, see the nonlinear
fitting section of the Mathematica tutorial. The profile function is given by
fða2Þ / exp 2
minða2Þ
2

	
:
(11:44)
Let ^k be the value of k in Equation (11.43) for the fit corresponding to the most
probable set of parameters. If ^k > 1, this indicates that the data errors may have been
underestimated. An approximate way5 to take account of this, when computing the
marginal parameter PDF, is to modify Equations (11.43) and (11.44) as follows:
½det Iða2Þ1=2 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det Vða2Þ
p
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det
^k2
k2 Vða2Þ
s
(11:45)
fða2Þ / exp 2
minða2Þ
2 ^k2

	
:
(11:46)
4 The quantity result[[3,2]] is V expressed in Mathematica’s MatrixForm. To compute the determinant of this matrix we
need to extract the argument of MatrixForm which is given by result[[3,2]][[1]].
5 A fully Bayesian way of handling this would be to treat k as a parameter and marginalize over a prior range for k.
306
Nonlinear model fitting

The resulting projected and marginal PDF for a2 are shown in Figure 11.9 and are
clearly quite different. It is a common frequentist practice to improve on the asymptotic
standard errors of a parameter by finding the two values of the parameter for which the
projected2 ¼ 2
min þ 1,inanalogytothelinearmodelcase(seeTable10.2).Forexample,
see the command MINOS in the MINUIT software (James, 1998). As we have discussed
earlier, the Bayesian marginal distribution should be strongly preferred over the projected,
and the Laplacian approximation provides a quick way of estimating the marginal.
Finally we can readily compute the Bayesian 95% credible region for a2 from the
marginal distribution and compare with the 95% confidence interval returned by
NonlinearRegress. They are:
Bayesian 95% credible region ¼ ð0:74; 1:68Þ
frequentist 95% confidence interval ¼ ð0:86; 1:60Þ:
11.7 Errors in both coordinates
In Section 4.8.2, we derived the likelihood function applicable to the general problem
of fitting an arbitrary model when there are independent errors in both coordinates.
For the special case of a straight line model (see also Gull, 1989b) the likelihood
function, pðDjM; A; B; IÞ, is given by Equation (4.60), which we repeat here after
replacing yi by di.
pðDjM; A; B; IÞ ¼ð2pÞN=2
Y
N
i¼1
2
i þ B22
xi

1=2
 
!
 exp
X
N
i¼1
ðdi  mðxi0jA; BÞÞ2
2 2
i þ B22
xi
ð
Þ
(
)
:
(11:47)
0.5
0.75
1
1.25
1.5
1.75
2
a2
0
0.01
0.02
0.03
0.04
0.05
PDF
marginal
projected
Figure 11.9 Comparison of the projected and Laplacian marginal PDF for the a2 parameter.
11.7 Errors in both coordinates
307

Here, A and B are model parameters representing the intercept and slope. It is
apparent that when there are errors in both coordinates, the problem has become
nonlinear in the parameters.
Problem: In Section 10.2.2, we fitted a straight line model to the data given in Table
10.1 using the method of least-squares. This time assume that the xi coordinates are
uncertain with an uncertainty descibed by a Gaussian PDF with a xi ¼ 3. Using the
likelihood given in Equation (11.47), compute the marginal PDF for the intercept
(A) and the marginal for the slope (B), and compare the results to the case where
xi ¼ 0. Assume uniform priors with boundaries well outside the region with
significant likelihood.
Solution: Since we are assuming flat priors, the joint posterior pðA; BjD; M; IÞ is directly
proportional to the likelihood. The marginal PDF for the intercept is given by
pðAjD; M; IÞ ¼
Z
dB pðA; BjD; M; IÞ
/ pðAjM; IÞ
Z
dB pðBjM; IÞ pðDjM; A; B; IÞ:
(11:48)
We can write a similar equation for the marginal PDF for the slope. The upper two
panels of Figure 11.10 show plots of the two marginals for two cases. The solid
curves correspond to xi ¼ 0 (no uncertainty in xi values), and the dashed curves to
xi ¼ 3. The uncertainty in the xi values results in broader and shifted marginals.
–40
–20
0
20
40
x
0
5
10
15
20
25
y
9
10
11
12
13
Intercept
0.2
0.4
0.6
0.8
1
1.2
PDF
0.25
0.3
0.35
Slope
5
10
15
20
25
PDF
Figure 11.10 The top two panels show the marginal PDFs for the intercept and slope. The solid
curves show the result when there is no error in the x-coordinate. The dashed curves are the
result when there are errors in both coordinates. The lower panel shows the corresponding
best-fit straight lines.
308
Nonlinear model fitting

The lower panel of Figure 11.10 shows the most probable straight line fits for the
two cases. The likelihood function given by Equation (11.47) contains xi in two
terms. In both terms, it is multiplied by the slope parameter B. The effect of the first
term is to favor smaller values of B. The effect of the second term is to decrease the
relative weight given to measurements with a smaller i, i.e., this causes the points to
be given more equal weight. In this particular case, the best fitting line has a slope
and intercept which are slightly larger when xi ¼ 3:0.
11.8 Summary
The problem of finding the best set of parameters for a nonlinear model can be very
challenging, because the posterior distribution for the parameters can be complex with
many hills and valleys. As the sample size increases, the posterior asymptotically
approaches a multivariate normal distribution (Section 11.2). Unfortunately, there are
no clear guidelines for how large the sample size must be. The goal is to find the global
maximum in the posterior, or equivalently, the minimum in 2. A variety of methods are
discussed, including random search techniques like simulated annealing and the genetic
algorithm. The other main approach is to home in on the minimum in 2 from a good
initialguessusinganiterativelinearizationtechniquelikeLevenberg–Marquardt(Sections
11.5 and 11.5.1), the method used in Mathematica’s Non-linearRegress command.
Once the minimum is located, the parameter errors can be approximately estimated
from I1, the inverse of the information matrix (Section 11.2). I1 is analogous to the
parameter covariance matrix in linear model fitting. Improved error estimates can be
obtained from the Laplacian approximation to the marginal posterior distribution for
any particular parameter (see Section 11.3.2). For model comparison problems, Section
11.3.1 describes a useful Laplacian approximation for the global likelihood, pðDjM; IÞ,
that is needed in calculating the Bayes factor. Section 11.6 and the section entitled,
‘‘Nonlinear Least-Squares Fitting’’ in the accompanying Mathematica tutorial, provide
useful templates for the analysis of typical nonlinear model fitting problems.
The data from some experiments have errors in both coordinates which can turn a
linear model fitting problem into a nonlinear problem. This issue was discussed earlier
in Section 4.8.2, and a particular example of fitting a straight line model was treated in
Section 11.7.
11.9 Problems
Nonlinear Model Fitting
(See ‘‘Nonlinear Least-Squares Fitting’’ in the Mathematica tutorial.)
Table 11.1 gives a frequency spectrum consisting of 100 pairs of frequency and
voltage (x, y). From measurements when the signal was absent, the noise is known to
be IID normal with a standard deviation  ¼ 0:3 voltage units. The spectrum is
11.9 Problems
309

thought to consist of two or more narrow lines which are broadened by the instru-
mental response of the detector which is well described by a Gaussian with a L ¼ 1:0
frequency unit. In addition, there is an unknown constant offset. Use a model for the
signal consisting of a sum of Gaussians plus a constant offset of the form
yðxiÞ ¼ A0 þ A1 exp  ðxi  C1Þ2
22
L
 
!
þ A2 exp  ðxi  C2Þ2
22
L
 
!
þ 	 	 	
In this problem, refer to the model with two lines as model 2, that with three lines as
model 3, etc.
The objective of this assignment is to determine the most probable model and the
best estimates of the model parameters and their errors. Find the most likely number
Table 11.1 The table contains a frequency spectrum consisting of 100 pairs of frequency
and voltage.
f (Hz)
V
f (Hz)
V
f (Hz)
V
f (Hz)
V
1.00
1.391
5.25
5.537
9.50
3.113
13.75
2.038
1.17
1.000
5.42
6.091
9.67
3.293
13.92
2.585
1.34
0.552
5.59
6.163
9.84
3.139
14.09
2.492
1.51
1.249
5.76
5.365
10.01
2.840
14.26
2.193
1.68
0.534
5.93
5.916
10.18
3.119
14.43
1.866
1.85
1.386
6.10
5.530
10.35
3.311
14.60
1.571
2.02
0.971
6.27
4.552
10.52
4.347
14.77
1.779
2.19
0.901
6.44
3.833
10.69
4.819
14.94
1.542
2.36
0.851
6.61
3.756
10.86
4.378
15.11
1.562
2.53
1.334
6.78
3.055
11.03
4.544
15.28
1.666
2.70
0.549
6.95
3.009
11.20
4.562
15.45
0.904
2.87
1.373
7.12
2.855
11.37
5.662
15.62
1.074
3.04
0.997
7.29
2.357
11.54
4.479
15.79
1.530
3.21
1.231
7.46
2.732
11.71
5.373
15.96
0.747
3.38
1.586
7.63
1.836
11.88
4.883
16.13
0.945
3.55
2.244
7.80
1.918
12.05
4.678
16.30
1.301
3.72
1.914
7.97
1.534
12.22
5.100
16.47
1.323
3.89
2.467
8.14
2.238
12.39
3.868
16.64
0.919
4.06
2.609
8.31
2.623
12.56
4.132
16.81
1.320
4.23
3.036
8.48
2.275
12.73
3.702
16.98
0.915
4.40
3.581
8.65
2.408
12.90
3.267
17.15
0.814
4.57
4.073
8.82
2.701
13.07
3.323
17.32
0.983
4.74
5.010
8.99
2.659
13.24
3.413
17.49
1.158
4.91
4.989
9.16
3.224
13.41
2.762
17.66
0.917
5.08
4.940
9.33
2.237
13.58
2.418
17.83
1.355
310
Nonlinear model fitting

of lines by fitting progressively more Gaussians, examining the residuals after each
trial. The following items are required as part of your solution:
1. Plot the raw data together with error bars. NonlinearRegress in Mathematica uses the
Levenberg–Marquardt method which requires good initial guesses of the parameter
values. For each model, provide a table of your initial guess of each parameter
value.
2. For each choice of model, give a table of the best-fit parameters and their errors as
derived from the asymptotic covariance matrix. Also list the covariance matrix.
Note: If you are using Mathematica’s NonlinearRegress, remember that it computes
an asymptotic covariance matrix that is scaled by a factor k2. This is an attempt to
obtain more robust parameter errors based on assuming the model is correct and
then adjusting all the assumed measurement errors by a factor k (explained in
Section 11.6; see also Equation (10.142) and discussion). For each choice of model,
compute the factor k.
3. Plot each model on top of the data with error bars.
4. For each model, plot the residuals and decide whether there is evidence for another
line to be fitted. Estimate the parameters of the line from the residuals and then
generate a new model to fit to the data that includes the new line together with the
earlier lines. Note: the residuals may suggest the presence of multiple lines. It is best
to add only the strongest one to your next model. Some of the minor features in the
residuals will disappear as the earlier model lines re-adjust their best locations in
response to the addition of the one new line.
5. For each model, calculate the 2 goodness-of-fit and the frequentist P-value
(significance), which represents the fraction of hypothetical repeats of the experi-
ment that are expected to fall in the tail area by chance if the model is correct. The
confidence in rejecting the model ¼ 1  P-value. Explain what you conclude from
these goodness-of-fit results.
6. For each model, compute the Laplacian estimate of the global likelihood for use
in the model selection problem. Compute the odds ratio for model ðiÞ compared
to model ði  1Þ. Assume a uniform prior for each model amplitude parameter, with
a range of 
 a factor of 3 of your initial guess, Ag, for the parameter, i.e.,
3Ag  Ag=3 ¼ 2:667Ag. Assume a uniform prior for each model line center
frequency parameter within the range 1 to 17 frequency units.
7. For your best model, compute and plot (on the same graph) the projected probability
and the Laplacian approximation to the marginal probability for A3, the amplitude
of the third strongest line. Again, see the Mathematica tutorial for an example.
11.9 Problems
311

12
Markov chain Monte Carlo
12.1 Overview
In the last chapter, we discussed a variety of approaches to estimate the most probable
set of parameters for nonlinear models. The primary rationale for these approaches is
that they circumvent the need to carry out the multi-dimensional integrals required in
a full Bayesian computation of the desired marginal posteriors. This chapter provides
an introduction to a very efficient mathematical tool to estimate the desired posterior
distributions for high-dimensional models that has been receiving a lot of attention
recently. The method is known as Markov Chain Monte Carlo (MCMC). MCMC was
first introduced in the early 1950s by statistical physicists (N. Metropolis,
A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller) as a method for the simulation
of simple fluids. Monte Carlo methods are now widely employed in all areas of science
and economics to simulate complex systems and to evaluate integrals in many dimen-
sions. Among all Monte Carlo methods, MCMC provides an enormous scope for
dealing with very complicated systems. In this chapter we will focus on its use in
evaluating the multi-dimensional integrals required in a Bayesian analysis of models
with many parameters.
The chapter starts with an introduction to Monte Carlo integration and exam-
ines how a Markov chain, implemented by the Metropolis–Hastings algorithm, can
be employed to concentrate samples to regions with significant probability. Next,
tempering improvements are investigated that prevent the MCMC from getting
stuck in the region of a local peak in the probability distribution. One such method
called parallel tempering is used to re-analyze the spectral line problem of Section 3.6.
We also demonstrate how to use the results of parallel tempering MCMC for model
comparison. Although MCMC methods are relatively simple to implement, in
practice, a great deal of time is expended in optimizing some of the MCMC
parameters. Section 12.8 describes one attempt at automating the selection of
these parameters. The capabilities of this automated MCMC algorithm are demon-
strated in a re-analysis of an astronomical data set used to discover an extrasolar
planet.
312

12.2 Metropolis–Hastings algorithm
Suppose we can write down the joint posterior density,1 pðXjD; IÞ, of a set of model
parameters represented by X. We now want to calculate the expectation value of some
function fðXÞ of the parameters. The expectation value is obtained by integrating the
function weighted by pðXjD; IÞ.
h fðXÞi ¼
Z
fðXÞpðXjD; IÞdX ¼
Z
gðXÞdX:
(12:1)
For example, if there is only one parameter and we want to compute its mean value, then
fðXÞ ¼ X. Also, we frequently want to compute the marginal probability of a subset XA
of the parameters and need to integrate over the remaining parameters designated XB.
Unfortunately, in many cases, we are unable to perform the integrals required in a
reasonable length of time. In this section, we develop an efficient method to approxi-
mate the desired integrals, starting with a discussion of Monte Carlo integration. Given
a value of X, the discussion below assumes we can compute the value of gðXÞ.
In straight Monte Carlo integration, the procedure is to pick n points, uniformly
randomly distributed in a multi-dimensional volume (V) of our parameter space X.
The volume must be large enough to contain all regions where gðXÞ contributes
significantly to the integral. Then the basic theorem of Monte Carlo integration
estimates the integral of gðXÞ over the volume V by
h fðXÞi ¼
Z
V
gðXÞdX  V  hgðXÞi  V 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
hg2ðXÞi  hgðXÞi2
n
s
;
(12:2)
where
hgðXÞi ¼ 1
n
X
n
i ¼ 1
gðXiÞ; hg2ðXÞi ¼ 1
n
X
n
i ¼ 1
g2ðXiÞ:
(12:3)
There is no guarantee that the error is distributed as a Gaussian, so the error term is
only a rough indicator of the probable error. When the random samples Xi are
independent, the law of large numbers ensures that the approximation can be made
as accurate as desired by increasing n. Note: n is the number of random samples of
gðXÞ, not the size of the fixed data sample. The problem with Monte Carlo integration
is that too much time is wasted sampling regions where pðXjD; IÞ is very small.
Suppose in a one-parameter problem the fraction of the time spent sampling regions
of high probability is 101. Then in an M-parameter problem, this fraction could
easily fall to 10M. A variation of the simple Monte Carlo described above, which
involves reweighting the integrand and adjusting the sample rules (known as ‘‘import-
ance sampling’’), helps considerably but it is difficult to design the reweighting for
large numbers of parameters.
1 In the literature dealing with MCMC, it is common practice to write pðXÞ instead of pðXjD; IÞ.
12.2 Metropolis–Hastings algorithm
313

In general, drawing samples independently from pðXjD; IÞ is not currently computa-
tionally feasible for problems where there are large numbers of parameters. However, the
samples need not necessarily be independent. They can be generated by any process that
generates samples from the target distribution, pðXjD; IÞ, in the correct proportions. All
MCMC algorithms generate the desired samples by constructing a kind of random walk
in the model parameter space such that the probability for being in a region of this space
is proportional to the posterior density for that region. The random walk is accomplished
using a Markov chain, whereby the new sample, Xtþ1, depends on the previous sample
Xt according to an entity called the transition probability or transition kernel, pðXtþ1jXtÞ.
The transition kernel is assumed to be time independent. The remarkable property of
pðXtþ1jXtÞ is that after an initial burn-in period (which is discarded) it generates samples
of X with a probability density equal to the desired posterior pðXjD; IÞ.
How does it work? There are two steps. In the first step, we pick a proposed value for
Xtþ1 which we call Y, from a proposal distribution, qðYjXtÞ, which is easy to evaluate. As
we show below, qðYjXtÞ can have almost any form. To help in developing your intuition,
it is perhaps convenient to contemplate a multivariate normal (Gaussian) distribution for
qðYjXtÞ, with a mean equal to the current sample Xt. With such a proposal distribution,
the probability density decreases with distance away from the current sample.
The second step is to decide on whether to accept the candidate Y for Xtþ1 on the
basis of the value of a ratio r given by
r ¼ pðYjD; IÞ
pðXtjD; IÞ
qðXtjYÞ
qðYjXtÞ ;
(12:4)
where r is called the Metropolis ratio. If the proposal distribution is symmetric, then the
second factor is ¼ 1. If r  1, then we set Xtþ1 ¼ Y. If r < 1, then we accept it with a
probability ¼ r. This is done by sampling a random variable U from Uniform(0, 1), a
uniform distribution in the interval 0 to 1. If U  r we set Xtþ1 ¼ Y, otherwise we set
Xtþ1 ¼ Xt. This second step can be summarized by a term called the acceptance prob-
ability ðXt; YÞ given by
ðXt; YÞ ¼ minð1; rÞ ¼ min 1; pðYjD; IÞ qðXtjYÞ
pðXtjD; IÞ qðYjXtÞ


:
(12:5)
The MCMC method as initially proposed by Metropolis et al. in 1953, considered
only symmetric proposal distributions, having the form qðYjXtÞ ¼ qðXtjYÞ. Hastings
(1970) generalized the algorithm to include asymmetric proposal distributions and the
generalization is commonly referred to as the Metropolis–Hastings algorithm. There
are now many different versions of the algorithm.
The Metropolis–Hastings algorithm is extremely simple:
1. Initialize X0; set t ¼ 0:
2. Repeat fObtain a new sample Y from qðYjXtÞ
Sample a Uniform(0,1) random variable U
If U  r set Xtþ1 ¼ Y otherwise set Xtþ1 ¼ Xt Increment tg
314
Markov chain Monte Carlo

Example 1:
Suppose the posterior is a Poisson distribution, pðXjD; IÞ ¼ Xe=X!. For our pro-
posal distribution qðYjXtÞ, we will use a simple random walk such that:
1. Given Xt, pick a random number U1  Uð0; 1Þ
2. If U1 > 0:5, propose Y ¼ Xt þ 1 otherwise Y ¼ Xt  1
3. Compute the Metropolis ratio r ¼ pðYjD; IÞ=pðXtjD; IÞ ¼ YXtXt!=Y!
4. Acceptance/rejection: U2  Uð0; 1Þ
Accept Xtþ1 ¼ Y if U2  r otherwise set Xtþ1 ¼ Xt
Figure 12.1 illustrates the results for the above simple MCMC simulation using a
value of  ¼ 3 and starting from an initial X0 ¼ 10 which is far out in the tail of the
posterior. Panel (a) shows a sequence of 1000 samples from the MCMC. It is clear that
the samples quickly move from our starting point far out in the tail to the vicinity of
the posterior mean. Panel (b) compares a histogram of the last 900 samples from the
MCMC with the true Poisson posterior which is indicated by the solid line. The
2
4
6
8
10
X
50
100
150
200
Number
(b)
0
200
400
600
800
1000
t
2
4
6
8
10
12
X
(a)
Figure 12.1 The results from a simple one-dimensional Markov chain Monte Carlo simulation
for a Poisson posterior for X. Panel (a) shows a sequence of 1000 samples from the MCMC.
Panel (b) shows a comparison of the last 900 MCMC samples with the true posterior indicated
by the solid curve.
12.2 Metropolis–Hastings algorithm
315

agreement is very good. We treated the first 100 samples as an estimate of the burn-in
period and did not use them.
Example 2:
Now consider a MCMC simulation of samples from a joint posterior pðX1; X2jD; IÞ in
two parameters X1 and X2, which has a double peak structure. Note: if we want to refer
to the tth time sample of the ith parameter from a Markov chain, we will do so with the
designation Xt;i. We define the posterior in Mathematica with the following commands.
Needs[‘‘Statistics ‘MultinormalDistribution’ ’’]
dist1=MultinormalDistribution [{0; 0}, {{1; 0}, {0; 1}}]
The first argument f0; 0g indicates the multinormal distribution is centered at 0,0.
The second argument ff1; 0g; f0; 1gg gives the covariance of the distribution.
dist2=MultinormalDistribution[{{4; 0}; {{2; 0:8}; {0:8; 2}}]
Posterior=0.5 (PDF[dist1, {X1; X2}]þ PDF[dist2, {X1; X2}])
The factor of 0.5 ensures the posterior is normalized to an area of one.
In this example, we used a proposal density function qðY1; Y2jX1; X2Þ which is a
two-dimensional Gaussian (normal) distribution.
[MultinormalDistribution[{X1,X2}, {{2
1,0},{0,2
2}}]]
The results for 8000 samples of the posterior generated with this MCMC are shown
in Figure 12.2. Note that the first 50 samples were treated as the burn-in period and are
not included in this plot. Panel (a) shows a sequence of 7950 samples from the MCMC
with 1 ¼ 2 ¼ 1. The two model parameters represented by X1 and X2 could be very
different physical quantities each characterized by a different scale. In that case, 1
and 2 could be very different. Panel (b) shows the same points with contours of the
posterior overlaid. The distribution of sample points matches the contours of the true
posterior very well. Panel (c) shows a comparison of the true marginal posterior (solid
curve) for X1 and the MCMC marginal (dots). The MCMC marginal is simply a
normalized histogram of the X1 sample values. Panel (d) shows a comparison of the
true marginal posterior (solid curve) for X2 and the MCMC marginal (dots). In both
cases, the agreement is very good.
We also investigated the evolution of the MCMC samples for proposal distributions
with different values of . Panel (a) in Figure 12.3 shows the case for a   1=10 the
scale of the smallest features in the true posterior. The starting point for each simula-
tion was at X1 ¼ 4:5; X2 ¼ 4:5. In this case, the burn-in period is considerably longer
and it appears that a larger number of samples would be needed to do justice to the
posterior which is indicated by the contours. Panel (b) illustrates the case for  ¼ 1, the
value used for Figure 12.2. Panel (c) uses a   10 times the scale of the smallest
features in the posterior. From the density of the points it appears that we have used a
316
Markov chain Monte Carlo

 –2
0
2
4
6
X1
 –2
 –1
0
1
2
3 (b)
 –3
 –2  –1
0
1
2
3
4
X2
0.1
0.2
0.3
0.4
Prob. density
(d)
 –2
0
2
4
6
X1
 –2
 –1
0
1
2
3
X2
X2
(a)
–2
0
2
4
6
8
X1
0.05
0.1
0.15
0.2
Prob. density
(c)
Figure 12.2 The results from a two-dimensional Markov chain Monte Carlo simulation of a
double peaked posterior. Panel (a) shows a sequence of 7950 samples from the MCMC. Panel
(b) shows the same points with contours of the posterior overlaid. Panel (c) shows a comparison
of the marginal posterior (solid curve) for X1 and the MCMC marginal (dots). Panel (d) shows a
comparison of the marginal posterior (solid curve) for X2 and the MCMC marginal (dots).
0
2
4
6
8
10
X1
–4
–2
0
2
4
X2
(c)
 –4  –2
–4  –2
–4
–2
0
2
4
6
8
10
X1
–4
–2
0
2
4
X2
σ = 0.1
σ = 1
σ = 10
(a)
0
2
4
6
8
10
X1
 –4
 –2
0
2
4
X2
(b)
Figure 12.3 A comparison of the samples from three Markov chain Monte Carlo runs using
Gaussian proposal distributions with differing values of the standard deviation: (a)  ¼ 0:1,
(b)  ¼ 1, (c)  ¼ 10. The starting point for each run was at X1 ¼ 4:5 and X2 ¼ 4:5.
12.2 Metropolis–Hastings algorithm
317

much smaller number of MCMC samples. In fact we used the same number of
samples. Recall that in MCMC we carry out a test to decide whether to accept the
new proposal (see discussion following Equation (12.4)). If we fail to accept the
proposal, then we set Xtþ1 ¼ Xt. Thus, many of the points in panel (c) are repeats of
the same sample as the proposed sample was rejected on many occasions.
It is commonly agreed that finding an ideal proposal distribution is an art. If we
restrict the conversation to Gaussian proposal distributions then the question
becomes what is the optimum choice of ? As mentioned earlier, the samples from a
MCMC are not independent, but exhibit correlations. In Figure 12.4, we illustrate the
correlations of samples corresponding to the three choices of  used in Figure 12.3 by
plotting the autocorrelation functions (ACFs) for X2. The ACF, ðhÞ, which was
introduced in Section 5.13.2, is given by
ðhÞ ¼
P
overlap½ðXt  XÞðXtþh  XÞ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
overlapðXt  XÞ2
q

ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
overlapðXtþh  XÞ2
q
;
(12:6)
where Xtþh is a shifted version of Xt and the summation is carried out over the subset
of samples that overlap. The shift h is referred to as the lag. It is often observed that
ðhÞ is roughly exponential in shape so we can model the ACF
ðhÞ  expf h
exp
g:
(12:7)
The autocorrelation time constant, exp, reflects the convergence speed of the MCMC
sampler and is approximately equal to the interval between independent samples. In
general, the smaller the value of exp the better, i.e., the more efficient, the MCMC
50
100
150
200
250
300
Lag
0
0.2
0.4
0.6
0.8
1
X2 ACF
10
σ = 1
σ = 0.1
Figure 12.4 A comparison of the autocorrelation functions for three Markov chain Monte Carlo
runs using Gaussian proposal distributions with differing values of the standard deviation:
 ¼ 0:1;  ¼ 1;  ¼ 10.
318
Markov chain Monte Carlo

sampler is. Examination of Figure 12.4 indicates that of the three choices of  chosen
above,  ¼ 1:0 leads to the smallest values of exp for X2. Of course, in this example just
considered, we have set X1 ¼ X2. In general, they will not be equal. Related to the
optimum choice of  is the average rate at which proposed state changes are accepted,
called the acceptance rate. Based on empirical studies, Roberts, Gelman, and Gilks
(1997) recommend calibrating the acceptance rate to about 25% for a high-dimensional
model and to about 50% for models of one or two dimensions. The acceptance rates
corresponding to our three choices of  in Figure 12.3 are 95%, 63%, and 5%,
respectively.
A number of issues arise from a consideration of these two simple examples. How
do we decide: (a) the length of the burn-in period, (b) when to stop the Markov chain,
and (c) what is a suitable proposal distribution? For a discussion of these points, the
reader is referred to a collection of review and application papers (Gilks, Richardson,
and Spiegelhalter 1996). For an unpublished 1996 roundtable discussion of informal
advice for novice practitioners, moderated by R. E. Kass, see www.amstat.org/
publications/tas/kass.pdf. The treatment of MCMC given in this text is intended
only as an introduction to this topic.
Loredo (1999) gives an interesting perspective on the relationship between the devel-
opment of MCMC in statistics and certain computational physics techniques. Define a
function ðXÞ ¼  ln½ pðXjIÞ pðDjX; IÞ. Then the posterior distribution can be written
as pðXjD; IÞ ¼ eðXÞ=Z, where Z ¼
R
dX eðXÞ. Evaluation of the posterior resembles
two classes of problems familiar to physicists: evaluating Boltzmann factors and parti-
tion functions in statistical mechanics, and evaluating Feynman path weights and path
integrals in Euclidean quantum field theory. For a discussion of some useful modern
extensions of the Metropolis algorithm that are particularly accessible to physical
scientists, see Liu (2001) and the first section of Toussaint (1989). A readable tutorial
for statistics students is available in Chib and Greenberg (1995).
12.3 Why does Metropolis–Hastings work?
Remarkably,
for
a
wide
range
of
proposal
distributions
qðYjXÞ,
the
Metropolis–Hastings algorithm generates samples of X with a probability density
which converges on the desired target posterior pðXjD; IÞ, called the stationary dis-
tribution of the Markov chain. For the distribution of Xt to converge to a stationary
distribution, the Markov chain must have three properties (Roberts, 1996). First, it
must be irreducible. That is, from all starting points, the Markov chain must be able
(eventually) to jump to all states in the target distribution with positive probability.
Second it must be aperiodic. This stops the chain from oscillating between different
states in a regular periodic movement. Finally the chain must be positive recurrent.
This can be expressed in terms of the existence of a stationary distribution pðXÞ, say,
such that if an initial value X0 is sampled from pðXÞ, then all subsequent iterates will
also be distributed according to pðXÞ.
12.3 Why does Metropolis–Hastings work?
319

To see that the target distribution is the stationary distribution of the Markov chain
generated by the Metropolis–Hastings algorithm, consider the following: suppose we
start with a sample Xt from the target distribution. The probability of drawing Xt from
the posterior is pðXtjD; IÞ. The probability that we will draw and accept a sample Xtþ1 is
given by the transition kernel, pðXtþ1jXtÞ ¼ qðXtþ1jXtÞ ðXt; Xtþ1Þ, where ðXt; Xtþ1Þ
is given by Equation (12.5). The joint probability of Xt and Xtþ1 is then given by
Joint probabilityðXt; Xtþ1Þ ¼ pðXtjD; IÞ pðXtþ1jXtÞ
¼ pðXtjD; IÞ qðXtþ1jXtÞðXt; Xtþ1Þ
¼ pðXtjD; IÞ qðXtþ1jXtÞ min 1; pðXtþ1jD; IÞ qðXtjXtþ1Þ
pðXtjD; IÞ qðXtþ1jXtÞ


¼ minðpðXtjD; IÞ qðXtþ1jXtÞ; pðXtþ1jD; IÞqðXtjXtþ1ÞÞ
¼ pðXtþ1jD; IÞ qðXtjXtþ1ÞðXtþ1; XtÞ
¼ pðXtþ1jD; IÞ pðXtjXtþ1Þ:
(12:8)
Thus, we have shown
pðXtjD; IÞ pðXtþ1jXtÞ ¼ pðXtþ1jD; IÞ pðXtjXtþ1Þ;
(12:9)
which is called the detailed balance equation.
In statistical mechanics, detailed balance occurs for systems in thermodynamic
equilibrium.2 In the present case, the condition of detailed balance means that
the Markov chain generated by the Metropolis–Hastings algorithm converges to a
stationary distribution.
Recall from Equation (12.8) that pðXtjD; IÞpðXtþ1jXtÞ is the joint probability of Xt
and Xtþ1. We will now integrate this joint probability with respect to Xt, making use of
Equation (12.9), and demonstrate that the result is simply the marginal probability
distribution of Xtþ1.
Z
pðXtjD; IÞ pðXtþ1jXtÞdXt ¼
Z
pðXtþ1jD; IÞpðXtjXtþ1Þ dXt
¼ pðXtþ1jD; IÞ
Z
pðXtjXtþ1Þ dXt
¼ pðXtþ1jD; IÞ:
(12:10)
Thus, we have shown that once a sample from the stationary target distribution has
been obtained, all subsequent samples will be from that distribution.
2 It may help to consider the following analogy: suppose we have a collection of hydrogen atoms. The number of atoms
making a transition from excited state t to state t þ 1 in 1 s is given by N  pðtÞ  pðt þ 1jtÞ, where N equals the total
number of atoms, p(t) is the probability of an atom being in state t, and pðt þ 1jtÞ is the probability that an atom in state
t will make a transition to state t þ 1 in 1 s. Similarly the number making transitions from t þ 1 to t in 1 s is given by
N  pðt þ 1Þ  pðtjt þ 1Þ. In thermodynamic equilibrium, the rate of transition from t to t þ 1 is equal to the rate from
t þ 1 to t, so
pðtÞ  pðt þ 1jtÞ ¼ pðt þ 1Þ  pðtjt þ 1Þ:
320
Markov chain Monte Carlo

12.4 Simulated tempering
The simple Metropolis–Hastings algorithm outlined in Section 12.2 can run into
difficulties if the target probability distribution is multi-modal. The MCMC can become
stuck in a local mode and fail to fully explore other modes which contain significant
probability. This problem is very similar to the one encountered in finding a global
minimum in a nonlinear model fitting problem. One solution to that problem was to use
simulated annealing (see Section 11.4.1) by introducing a temperature parameter T . The
analogous process applied to drawing samples from a target probability distribution
(e.g., Geyer and Thompson, 1995) is often referred to as simulated tempering (ST). In
annealing, the temperature parameter is gradually decreased. In ST, we create a discrete
set of progressively flatter versions of the target distribution using a temperature
parameter. For T ¼ 1, the distribution is the desired target distribution which is referred
to as the cold sampler. For T 	 1, the distribution is much flatter. The basic idea is that
by repeatedly heating up the distribution (making it flatter), the new sampler can escape
from local modes and increase its chance of reaching all regions of the target distribution
that contain significant probability. Typical inference is based on samples drawn from
the cold sampler and the remaining observations discarded. Actually, in Section 12.7 we
will see how to use the samples from the hotter distributions to evaluate Bayes factors in
model selection problems.
Again, let pðXjD; IÞ be the target posterior distribution we want to sample.
Applying Bayes’ theorem, we can write this as
pðXjD; IÞ ¼ C pðXjIÞ  pðDjX; IÞ;
where C ¼ 1=pðDjIÞ is the usual normalization constant which is not important at this
stage and will be dropped. We can construct other flatter distributions as follows:
pðXjD; ; IÞ ¼ pðXjIÞpðDjX; IÞ
¼ pðXjIÞ expð ln½ pðDjX; IÞÞ;
for 0 <  < 1:
(12:11)
Rather than use a temperature which varies from 1 to infinity, we prefer to use its
reciprocal which we label  and refer to as the tempering parameter. Thus  varies
from 1 to zero. We will use a discrete set of  values labeled f1; 2; 
 
 
 ; mg, where
 ¼ 1 corresponds to the cold sampler (target distribution) and m corresponds to our
hottest sampler which is generally much flatter. This particular formulation is also
convenient for our later discussion on determining the Bayes factor in model selection
problems. Rather than describe ST in detail, we will describe a more efficient related
algorithm called parallel tempering in the next section.
12.5 Parallel tempering
Parallel tempering (PT) is an attractive alternative to simulated tempering (Liu, 2001).
Again, multiple copies of the simulation are run in parallel, each at a different
12.5 Parallel tempering
321

temperature (i.e., a different  ¼ 1=T ). One of the simulations, corresponding to
 ¼ 1=T ¼ 1, is the desired target probability distribution. The other simulations
correspond to a ladder of higher temperature distributions indexed by i. Let n
equal the number of parallel MCMC simulations. At intervals, a pair of adjacent
simulations on this ladder are chosen at random and a proposal made to swap their
parameter states. Suppose simulations i and iþ1 are chosen. At time t, simulation i
is in state Xt;i and simulation iþ1 is in state Xt;iþ1. If the swap is accepted by the test
given below then these states are interchanged. In the example discussed in Section
12.6, we specify that on average, a swap is proposed after every ns iterations (ns ¼ 30
was used) of the parallel simulations in the ladder. This is done by choosing a random
number, U1  Uniform[0,1], at each time iteration and proposing a swap only if
U1  1=ns. If a swap is to be proposed, we use a second random number to pick one of
the ladder simulations i in the range i ¼ 1 to ðnb  1Þ, and propose swapping the
parameter states of i and i þ 1. A Monte Carlo acceptance rule determines the
probability for the proposed swap to occur. Accept the swap with probability
r ¼ min 1; pðXt;iþ1jD; i; IÞ pðXt;ijD; iþ1; IÞ
pðXt;ijD; i; IÞ pðXt;iþ1jD; iþ1; IÞ


;
(12:12)
where pðXjD; ; IÞ is given by Equation (12.11). We accept the swap if U2 
Uniform[0,1]  r.
This swap allows for an exchange of information across the population of parallel
simulations. In the higher temperature simulations, radically different configurations
can arise, whereas in lower temperature states, a configuration is given the chance to
refine itself. By making exchanges, we can capture and improve the higher probability
configurations generated by the population by putting them into lower temperature
simulations. Some experimentation is needed to refine suitable choices of i values.
Adjacent simulations need to have some overlap to achieve a sufficient acceptance
probability for an exchange operation.
12.6 Example
Although MCMC really comes into its own when the number of model parameters is
very large, we will apply it to the toy spectral line problem we analyzed in Section 3.6,
because we can compare with our earlier results. The objective of that problem was to
test two competing models, represented by M1 and M2, on the basis of some spectral line
data. Only M1 predicts the existence of a particular spectral line. In the simplest version
of the problem, the line frequency and shape is exactly predicted by M1; the only
quantity which is uncertain is the line strength T expressed in temperature units. The
odds ratio in favor of M1 was found to be 11:1 assuming a Jeffreys prior for the line
strength. We also computed the most probable line strength. In Section 3.9, we inves-
tigated how our conclusions would be altered if the line frequency were uncertain, i.e., it
322
Markov chain Monte Carlo

could occur anywhere between channels 1 to 44. In that case, the odds ratio favoring M1
dropped from 11:1 to  1:1, assuming a uniform prior for the line center frequency.
Below, we apply both the Metropolis–Hastings and parallel tempering versions of
MCMC to the problem of estimating the marginal posteriors of the line strength and
center frequency to compare with our previous results. In Section 12.7, we will employ
parallel tempering to compute the Bayes factor needed for model comparison.
Metropolis–Hastings results
In this section, we will draw samples from pðXjD; M1; IÞ, where X is a vector repre-
senting the two parameters of model M1, namely the line strength T and the line center
frequency  expressed as channel number. We use a Jeffreys prior for T in the range
Tmin ¼ 0:1 mK to Tmax ¼ 100 mK. We assume a uniform prior for  in the range
channel 1 to 44. The steps in the calculation are as follows:
1. Initialize X0; set t ¼ 0:
In this example we set X0 ¼ fT0 ¼ 5; 0 ¼ 30g
2. Repeat f
a) Obtain a new sample Y from qðYjXtÞ
Y ¼ fT0; 0g
we set q(T0|Tt)=Random[NormalDistribution[Tt,T=1:0]]
and q(n0jntÞ=Random[NormalDistribution[nt; sf=1:0]]
b) Compute the Metropolis ratio
r ¼ pðY|D; M1; IÞ
pðXtjD; M1; IÞ ¼ pðT 0; 0jM1; IÞ pðDjM1; T 0; 0; IÞ
pðTt; tjM1; IÞ pðDjM1; Tt; t; IÞ
where pðDjM1; T; ; IÞ is given by Equations (3.44) and (3.41).
The priors pðT; jM1; IÞ ¼ pðTjM1; IÞ pðjM1; IÞ are given by Equations (3.38)
and (3.33).
Note: if T 0 or 0 lie outside the prior boundaries set r ¼ 0.
c) Acceptance/rejection: U  U(0; 1)
d) Accept Xtþ1 ¼ Y if U  r, otherwise set Xtþ1 ¼ Xt
e) Increment tg
Figure 12.5 shows results for 105 iterations of a Metropolis–Hastings Markov chain
Monte Carlo. Panel (a) shows every 50th value of parameter , expressed as a channel
number, and panel (c) the same for parameter T. It is clear that the  values move
quickly to a region centered on channel 37 with occasional jumps to a region centered
on channel 24 and only one jump to small channel numbers. The T parameter can be
seen to fluctuate between 0.1 and 3:5 mK. Panels (b) and (d) show a blow-up of the
first 500 iterations. It is apparent from these panels that the burn-in period is very
short, < 50 iterations for a starting state of T ¼ 5 and  ¼ 30.
Figure 12.6 shows distributions of the two parameters. In panel (a), the joint
distribution of T and  is apparent from the scatter plot of every 20th iteration obtained
12.6 Example
323

after dropping the burn-in period consisting of the first 50 iterations. To obtain the
marginal posterior density for the  parameter, we simply plot a histogram of all the 
values (post burn-in) normalized by dividing by the sum of the  values multiplied by
the width of each bin. This is shown plotted in panel (b) together with our earlier
marginal distribution (solid curve) computed by numerical integration. It is clear that
0
100
200
300
400
500
Iteration
0
1
2
3
4
5
T
(d)
0
50000
100000
Iteration
0
1
2
3
4
5
T
(c)
0
100
200
300
400
500
Iteration
30
32
34
36
38
40
42
Channel number
(b)
0
50000
100000
Iteration
10
20
30
40
Channel number
(a)
Figure 12.5 Results for 105 iterations of a Metropolis–Hastings Markov chain Monte Carlo.
Panel (a) shows every 50th value of parameter  and panel (c) the same for parameter T. Panels
(b) and (d) show a blow-up of the first 500 iterations.
324
Markov chain Monte Carlo

105 iterations of Metropolis–Hastings does a good job of defining the dominant peak of
the probability distribution for  but does a poor job of capturing two other widely
separated islands containing significant probability. On the other hand, it is clear from
panel (c) that it has done a great job of defining the distribution of T.
Parallel tempering results
We also analyzed the spectral line data with a parallel tempering (PT) version of
MCMC described in Section 12.5. We used five values for the tempering parameter, ,
0.5
1
1.5
2
2.5
3
3.5
T (mK)
 
 
0.2
0.4
0.6
0.8
1
1.2
Probability density
(c)
10
20
30
40
Channel number
0.05
0.1
0.15
0.2
0.25
0.3
Probability density
(b)
10
20
30
40
Channel number
0.5
1
1.5
2
2.5
3
3.5
4
T
(a)
Figure 12.6 Results for the spectral line problem using a Metropolis–Hastings Markov chain
Monte Carlo analysis. Panel (a) is a scatter plot of the result for every 20th iteration in the two
model parameters, channel number and line strength T. Panel (b) shows the marginal prob-
ability density for channel number (points) compared to our earlier numerical integration result
indicated by the solid curve. Panel (c) shows the marginal probability density for line strength T
(points) compared to our earlier numerical integration result indicated by the solid curve.
12.6 Example
325

uniformly spaced between 0.01 and 1.0, and ran all five chains in parallel. At intervals
(on average every 50 iterations) a pair of adjacent simulations on this ladder are
chosen at random and a proposal made to swap their parameter states. We used the
same starting state of T ¼ 5;  ¼ 30 and executed 105 iterations. The final results for
the  ¼ 1, corresponding to the target distribution, are shown in Figures 12.7 and
12.8. The acceptance rate for this simulation was 37%.
Comparing panel (a) of Figures 12.7 and 12.5, we see that the PT version visits
the two low-lying regions of  probability much more frequently than the
Metropolis–Hastings version. Comparing the marginal densities of Figures 12.8 and
12.6 we see that the PT marginal density for  is in better agreement with the expected
results indicated by the solid curves. For both versions, the marginal densities for T are
in excellent agreement with the expected result. In more complicated problems, we often
cannot conveniently compute the marginal densities by another method. In this case, it
is useful to compare the results from a number of PT simulations with different starting
parameter states.
12.7 Model comparison
So far we have demonstrated how to use MCMC to compute the marginal posteriors
for model parameters. In this section, we will show how to use the results of parallel
tempering to compute the Bayes factor used in model comparison (Skilling, 1998;
Goggans and Chi, 2004). In the toy spectral line problem of Section 3.6, we were
interested in computing the odds ratio of two models M1 and M2 which from
Equation (3.30) is equal to the prior odds times the Bayes factor given by
B12 ¼ pðDjM1; IÞ
pðDjM2; IÞ ;
(12:13)
where pðDjM1; IÞ and pðDjM2; IÞ are the global likelihoods for the two models. In the
version of this problem analyzed in Section 12.6, M1 has two parameters  and T. For
independent priors,
pðDjM1; IÞ ¼
Z
d pðjM1; IÞ
Z
dT pðTjM1; IÞpðDjM1; ; T; IÞ:
(12:14)
In what follows, we will generalize the model parameter set to an arbitrary number of
parameters which we represent by the vector X.
To evaluate pðDjM1; IÞ, using parallel tempering MCMC, we first define a partition
function
ZðÞ ¼
Z
dX pðXjM1; IÞ pðDjM1; X; IÞ
¼
Z
dX expfln½ pðXjM1; IÞ þ  ln½ pðDjM1; X; IÞg;
(12:15)
326
Markov chain Monte Carlo

where  is the tempering parameter introduced in Section 12.4. Now take the deriva-
tive of ln½ZðÞ.
d
d ln½ZðÞ ¼
1
ZðÞ
d
d ZðÞ
(12:16)
0
100
200
300
400
500
Iteration
0
1
2
3
4
5
T
(d)
0
50000
100000
Iteration
0
1
2
3
4
5
T
(c)
0
100
200
300
400
500
Iteration
28
30
32
34
36
38
40
Channel number
(b)
0
50000
100000
Iteration
0
10
20
30
40
Channel number
(a)
Figure 12.7 Results for 105 iterations of a parallel tempering Markov chain Monte Carlo. Panel
(a) shows every 50th value of parameter  and panel (c) the same for parameter T. Panels (b) and
(d) show a blow-up of the first 500 iterations.
12.7 Model comparison
327

d
d ZðÞ ¼
Z
dX ln½ pðDjM1; X; IÞ
 expfln½ pðXjM1; IÞ þ  ln½ pðDjM1; X; IÞg
¼
Z
dX ln½ pðDjM1; X; IÞ pðXjM1; IÞ pðDjM1; X; IÞ:
(12:17)
0.5
1
1.5
2
2.5
3
3.5
T (mK)
0.2
0.4
0.6
0.8
1
1.2
Probability density
(c)
10
20
30
40
Channel number
0.05
0.1
0.15
0.2
0.25
0.3
Probability density
(b)
10
20
30
40
Channel number
0.5
1
1.5
2
2.5
3
3.5
4
T
(a)
Figure 12.8 Results for the spectral line problem using a Markov chain Monte Carlo analysis
with parallel tempering. Panel (a) is a scatter plot of the result for every 20th iteration in the two
model parameters, channel number and line strength T. Panel (b) shows the marginal prob-
ability density for channel number (points) compared to our earlier numerical integration result
indicated by the solid line. Panel (c) shows the marginal probability density for line strength T
(points) compared to our earlier numerical integration result indicated by the solid line.
328
Markov chain Monte Carlo

Substituting Equation (12.17) into Equation (12.16), we obtain
d
d ln½ZðÞ ¼
R dX ln½ pðDjM1; X; IÞ pðXjM1; IÞ pðDjM1; X; IÞ
R
dX pðXjM1; IÞ pðDjM1; X; IÞ
¼ hln½ pðDjM1; X; IÞi;
(12:18)
where hln½ pðDjM1; X; IÞi is the expectation value of the ln½ pðDjM1; X; IÞ. This
quantity is easily evaluated from the MCMC results which consist of sets of Xt
samples, one set for each value of the tempering parameter . Let fXt;g represent
the samples for tempering parameter .
hln½ pðDjM1; X; IÞi ¼ 1
n
X
t
ln½ pðDjM1; Xt;; IÞ;
(12:19)
where n is the number of samples in each set after the burn-in period. From Equation
(12.18) we can write
Z 1
0
d ln½ZðÞ ¼ ln½Zð1Þ  ln½Zð0Þ
¼
Z
d hln½ pðDjM1; X; IÞi:
(12:20)
Now from Equation (12.15)
Zð1Þ ¼
Z
dX pðXjM1; IÞ pðDjM1; X; IÞ ¼ pðDjM1; IÞ;
(12:21)
and
Zð0Þ ¼
Z
dX pðXjM1; IÞ:
(12:22)
From Equations (12.20) and (12.21) we can write
ln½ pðDjM1; IÞ ¼ ln½Zð0Þ þ
Z
dhln½ pðDjM1; X; IÞi:
(12:23)
For a normalized prior, Zð0Þ ¼ 1 and Equation (12.23) becomes
ln½ pðDjM1; IÞ ¼
Z
dhln½ pðDjM1; X; IÞi:
(12:24)
Armed with Equation (12.24) we are now in a position to evaluate the Bayes factor
given by Equation (12.13), which is at the heart of model comparison.
Returning to the spectral line problem,
hln½ pðDjM1; ; T; IÞi ¼ 1
n
X
t
ln½ pðDjM1; t;; Tt;; IÞ:
(12:25)
12.7 Model comparison
329

We evaluated Equation (12.25) for the five values of  ¼ 0:01, 0.2575, 0.505, 0.7525,
1.0
used
in
the
PT
MCMC
analysis
of
Section
12.6.
The
results
were
97:51; 87:1937; 86:4973; 85:9128; 85:1565, respectively. We then evaluated
the integral in Equation (12.24) by generating an interpolating function and integrating
the interpolating function in the interval 0 to 1. This yielded ln½pðDjM1; IÞ ¼ 87:4462.
A more sophisticated interpolation of the results yielded ln½pðDjM1; IÞ ¼ 87:3369.
Model M2 had no free parameters and pðDjM2; IÞ ¼ 1:133  1038 from Equation
(3.49). The resulting Bayes factors for the two interpolations were B1;2 ¼ 0:93 and
1.04, respectively. This should be compared to B1;2 ¼ 1:06 obtained from our earlier
solution to this problem.
12.8 Towards an automated MCMC
As the number of model parameters increases, so does the time required to choose a
suitable  value for each of the parameter proposal distributions. Suitable means that
MCMC solutions, starting from different locations in the prior parameter space, yield
equilibrium distributions of model parameter values that are not significantly different,
in an acceptable number of iterations. Generally this involves running a series of
chains, each time varying  for one or more of the parameter proposal distributions,
until the chain appears to converge on an equilibrium distribution with a proposal
acceptance rate, , that is reasonable for the number of parameters involved, e.g.,
approximately 25% for a large number of parameters (Roberts, Gelman, and Gilks,
1997). This is especially time consuming if each parameter corresponds to a different
physical quantity, so that the  values can be very different. In this section, we describe
one attempt at automating this process, which we apply to the detection of an
extrasolar planet using some real astronomical data.
Suppose we are dealing with M parameters that are represented collectively by
fXg. Let  represent the characteristic width of a symmetric proposal distribution
for X. We will assume Gaussian proposal distributions but the general approach
should also be applicable to other forms of proposal distributions. To automate the
MCMC, we need to incorporate a control system that makes use of some form of error
signal to steer the selection of the fg.
For a manually controlled MCMC, a useful approach is to start with a large value
of , approximately one tenth of the prior uncertainty of that parameter. In a PT
MCMC, this will normally be sufficient to provide access to all areas with significant
probability within the prior range, but may result in a very small acceptance rate for
the  ¼ 1 member of the PT MCMC chain. By running a number of smaller iteration
chains, each time perturbing one or more of the fg, it soon becomes clear which
parameters are restraining the acceptance rate from a more desirable level. Larger
fg values yield larger jumps in parameter proposal values. The general approach of
refining the fg towards smaller values is analogous to an annealing operation. The
refinement is terminated when the target proposal acceptance rate is reached.
330
Markov chain Monte Carlo

In the automated version of this process described below, the error signal used for the
control system is the difference between the current acceptance rate and a target
acceptance rate. The control system steers the proposal ’s to desirable values during
the burn-in stage of a single parallel tempering MCMC run. Although inclusion of the
control system may result in a somewhat longer burn-in period, there is a huge saving in
time because it eliminates many trial runs to manually establish a suitable set of fg. In
addition the control system error monitor provides another indication of the length of
the burn-in period. In practice, it is important to repeat the operation for a few different
choices of initial parameter values, to ensure that the MCMC results converge.
The automatic parallel tempering MCMC (APT MCMC) algorithm contains major
and minor cycles. During the major cycles the current set of fg are used for n1
iterations. The acceptance rate achieved during this major cycle is compared to the
target acceptance rate. If the difference (control system error signal), , is greater than
a chosen threshold, tol1, then a set of minor cycles, one cycle of n2 iterations for each
, are employed to explore the sensitivity of the acceptance rate to each . The fg
are updated and another major cycle run. If tol1 is set ¼ 0, then the minor cycles are
always performed after each major cycle. At this point, the reader might find it useful
to examine the evolution of the error signal, and the {}, for the examples shown in
Figures 12.12 and 12.13. One can clearly see the expected Poisson fluctuations in the
error signal after the {} stabilize. For these examples we set tol1=1.5
ﬃﬃﬃﬃﬃﬃﬃﬃ
n1
p
to reduce
the number of minor cycles. Normally the control system is turned off after  is less
than some threshold, tol2. Typically tol2 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
n1
p
.
Full details of the control system are not included here as it is considered experi-
mental and in a process of evolution. The latest version is included in the Mathematica
tutorial in the section entitled ‘‘Automatic parallel tempering MCMC,’’ along with
useful default values for the algorithm parameters and input data format. Figure 12.9
provides a summary of the inputs and outputs for the APT MCMC algorithm. In the
following section we demonstrate the behavior of the algorithm with a set of astro-
nomical data used to detect an extrasolar planet.
12.9 Extrasolar planet example
In this section, we will apply the automated parallel tempering MCMC described
in Section 12.8 to some real astronomical data, which were used to discover (Tinney
et al., 2003) an extrasolar planet orbiting a star with a catalog number HD 2039.
Although light from the planet is too faint to be detected, the gravitational tug of the
planet on the star is sufficient to produce a measurable Doppler shift in the velocity of
absorption lines in the star’s spectrum. By fitting a Keplerian orbit to the measured
radial velocity data, vi, it is possible to obtain information about the orbit and a lower
limit on the mass of the unseen planet. The predicted model radial velocity, fi, for a
particular orbit is given below, and involves six unknowns. The geometry of a stellar
orbit with respect to the observer is shown in Figure 12.10. The points labeled F, P,
12.9 Extrasolar planet example
331

and S, are the location of the focus of the elliptical orbit, periastron, and the star’s
position at time ti, respectively.
fi ¼ V þ K½cosf	ðti þ t0Þ þ !g þ e cos !;
(12:26)
where
V ¼ the systematic velocity of the system.
K ¼ velocity amplitude ¼ 2pP1ð1  e2Þ1=2a sin i.
P ¼ the orbital period.
a ¼ the semi-major axis of the orbit.
e ¼ the eccentricity of the elliptical orbit.
i ¼ the inclination of the orbit as defined in Figure 12.10.
! ¼ the longitude of periastron, angle LFA in Figure 12.10.

 ¼ the fraction of an orbit prior to the start of data-taking that periastron occurred
at. Thus, t0 ¼ 
P ¼ the number of days prior to ti ¼ 0 that the star was at periastron,
for an orbital period of P days. At ti ¼ 0, the star is at an angle AFB from periastron.
	ðti þ t0Þ ¼ the angle (AFS) of the star in its orbit relative to periastron at time ti.
The dependence of 	 on ti, which follows from the conservation of angular momen-
tum, is given by the solution of
d	
dt  2p½1 þ e cos 	ðti þ t0Þ2
Pð1  e2Þ3=2
¼ 0:
(12:27)
APT
MCMC
Target Posterior 
p({Xα}|D,M,I)
Control system 
parameters
___ ___ ___ ___ ___ ___ ___
n1 = major cycle iterations 
n2 = minor cycle iterations
λ = acceptance ratio
γ  = damping constant
Data
n = no. of iterations
{Xα}init = start parameters
{σα}init = start proposal σ's
Tempering levels
- Control system diagnostics
- {Xa} iterations
- Summary statistics
Best fit model & residuals
-
-
{Xα}marginals
- {Xα} 68.3% credible regions
- p(D|M,I) global likelihood 
 for model comparison
Figure 12.9 An overview schematic of the inputs and outputs for the automated parallel
tempering MCMC.
332
Markov chain Monte Carlo

To fit Equation (12.26) to the data, we need to specify the six model parameters,
P; K; V; e; !; 
.
The measured radial velocities and their errors are shown Figure 12.11. As we have
discussed before, it is good idea not to assume that the quoted measurement errors are
the only error component in the data.
0
200
400
600
800
1000
1200
1400
Julian day number (–2,451,118.0578)
 –50
0
50
100
150
Velocity (ms–1)
Figure 12.11 HD 2039 radial velocity measurements plotted from the data given in Tinney et al.,
(2003).
To
observer
Sky plane
Orbital
plane
F
S
B
C
P
L
A
inclination
Figure 12.10 The geometry of a stellar orbit with respect to the observer. The sky plane is
perpendicular to the dashed line connecting the star and the observer.
12.9 Extrasolar planet example
333

We can represent the measured velocities by the equation
vi ¼ fi þ ei;
(12:28)
where ei is the component of vi which arises from measurement errors plus any real signal
in the data that cannot be explained by the model prediction fi. For example, suppose
that the star actually has two planets, and the model assumes only one is present. In
regard to the single planet model, the velocity variations induced by the second planet act
like an additional unknown noise term. In the absence of detailed knowledge of the
effective noise distribution, other than that it has a finite variance, the maximum entropy
principle tells us that a Gaussian distribution would be the most conservative choice (i.e.,
maximally non-committal about the information we don’t have). We will assume the
noise variance is finite and adopt a Gaussian distribution for ei with a variance 2
i .
In a Bayesian analysis where the variance of ei is unknown, but assumed to be the
same for all data points, we can treat  as an unknown nuisance parameter.
Marginalizing over  has the desirable effect of treating anything in the data that
can’t be explained by the model as noise and this leads to the most conservative
estimates of model parameters.
In the current problem, the quoted measurement errors are not all the same. We let
si ¼ the experimenter’s estimate of i, prior to fitting the model and examining the
model residuals. The i values are not known, but the si values are our best initial
estimates. They also contain information on the relative weight we want to associate
with each point. Since we do not know the absolute values of the i, we introduce a
parameter called the noise scale parameter, b, to allow for this.3 It could also be called
a noise weight parameter. Several different definitions of b are possible including
2
i ¼ bs2
i and i ¼ bsi. The definition we use here is given by
1
2
i
¼ b
s2
i
:
(12:29)
Again marginalizing over b has the desirable effect of treating anything in the data
that can’t be explained by the model as noise, leading to the most conservative
estimates of orbital parameters. Since b is a scale parameter, we assume a Jeffreys
prior (see Section 3.10).
3 Note added in proof:
A better choice for parameterizing any additional unknown noise term is to rewrite equation (12.28) as
vi ¼ fi þ ei þ e0
where ei is the noise component arising from known but unequal measurement errors, and e0 is the additional unknown
noise term. From the arguments given above, we can characterize the combination of ei þ e0 by a Gaussian distribution
with variance = 2
i þ 2
0. With this form of parameterization we would marginalize over 0 instead of b. The one
advantage of using b is that it can allow for the possibility that the measurement errors have been overestimated.
334
Markov chain Monte Carlo

pðbjIÞ ¼
1
b ln bmax
bmin
;
(12:30)
with bmax ¼ 2 and bmin ¼ 0:1. We also compute pðbjD; Model; IÞ. If the most probable
estimate of b  1, then the one-planet model is doing a good job accounting for everything
that is not noise based on the si estimates. If b < 1, then either the model is not accounting
for significant real features in the data or the initial noise estimates, si, were low.
12.9.1 Model probabilities
In this section, we set up the equations needed to (a) specify the joint posterior probability
of the model parameters (parameter estimation problem) for use in the MCMC analysis,
and (b) decide if a planet has been detected (model selection problem). To decide if a
planet has been detected, we will compare the probability of M1  ‘‘the star’s radial
velocity variations are caused by one planet’’ to the probability of M0  ‘‘the radial
velocity variations are consistent with noise.’’ From Bayes’ theorem, we can write
pðM1jD; IÞ ¼ pðM1jIÞ pðDjM1; IÞ
pðDjIÞ
¼ C pðM1jIÞ pðDjM1; IÞ;
(12:31)
where
pðDjM1;IÞ¼
Z
dP
Z
dK
Z
dV
Z
de
Z
d
Z
d!
Z
dbpðP;K;V;e;
;!;bjM1;IÞ
pðDjM1;P;K;V;e;
;!;b;IÞ:
(12:32)
The joint prior for the model parameters, assuming independence, is given by
pðP; K; V; e; 
; !; bjM1; IÞ ¼
1
P ln
Pmax
Pmin


1
K ln
Kmax
Kmin


1
ðVmax  VminÞ

1
ðemax  eminÞ
1
2p
1
b ln
bmax
bmin

 :
(12:33)
Note: we have assumed a uniform prior for 
 in the range 0 to 1, so pð
|M1; IÞ ¼ 1.
pðDjM1; P; K; V; e; 
; !; b; IÞ ¼ AbN=2  exp  b
2
X
N
i ¼ 1
ðvi  fiÞ2
s2
i
"
#
;
(12:34)
where
A ¼ ð2pÞN=2 Y
N
i ¼ 1
s1
i
"
#
:
(12:35)
12.9 Extrasolar planet example
335

For the purposes of estimating the model parameters, we will assume a prior uncer-
tainty in b in the range bmin ¼ 0:1 and bmax ¼ 2.
When it comes to comparing the probability of M1 to M0, or to a model which
assumes there are two planets present, we will set b ¼ 1 and perform the model
comparison based on the errors quoted in Tinney et al., (2003). The probability of
M0 is given by
pðM0jD; IÞ ¼ C pðM0jIÞpðDjM0; IÞ;
(12:36)
where
pðDjM0; IÞ ¼
Z
db
Z
dV pðV; bjD; M0; IÞ
¼
Z
db
Z
dV pðV; bjM0; IÞ pðDjM0; V; b; IÞ;
(12:37)
pðVjM0; IÞ ¼
1
ðVmax  VminÞ
1
b ln
bmax
bmin

 ;
(12:38)
and
pðDjM0; V; b; IÞ ¼ ð2pÞN=2 Y
N
i ¼ 1
s1
i
"
#
b
N
2 exp  b
2
X
N
i ¼ 1
ðvi  VÞ2
s2
i
"
#
:
(12:39)
The integral over V in Equation (12.37) can be performed analytically yielding
pðDjM0; IÞ ¼ A
ﬃﬃﬃp
2
r
W1=2
Z
db b
N  3
2 exp  bW
2
X
N
i ¼ 1
ðv2
w  ðvwÞ2Þ2
"
#
 erfðumaxÞ  erfðuminÞ
½
;
(12:40)
where
vw ¼
X
N
i ¼ 1
wi vi;
(12:41)
v2
w ¼
X
N
i ¼ 1
wi v2
i ;
(12:42)
wi ¼ 1=s2
i ;
(12:43)
W ¼
X
N
i ¼ 1
wi;
(12:44)
336
Markov chain Monte Carlo

umax ¼
bW
2

1=2
ðVmax  vwÞ;
(12:45)
umin ¼
bW
2

1=2
ðVmin  vwÞ:
(12:46)
In conclusion, Equations (12.31) and (12.34) are required for the parameter estima-
tion part of the problem, and Equations (12.32) and (12.40) answer the model selection
part of the problem. Equation (12.32) is evaluated from the results of the parallel
tempering chains according to the method discussed in Section 12.7.
12.9.2 Results
The APT MCMC algorithm described in Section 12.8 was used to re-analyze the
measurements of Tinney et al. (2003). Figures 12.12 and 12.13 show the diagnostic
information output by the MCMC control system for two runs of the APT MCMC
algorithm that use different starting values for the parameters and different starting
values for the proposal ’s. The top left panel shows the evolution of the control
system error for 100 000 iterations. Even for the best set of fg, the control system
error will exhibit statistical fluctuations of order
ﬃﬃﬃﬃﬃﬃﬃﬃ
n1
p
which will result in fluctuations
of fg throughout the run. Recall,  ¼ the target acceptance fraction and n1 ¼ the
number of iterations in major cycles (see Section 12.8). These fluctuations are of no
consequence since the equilibrium distribution of parameter values is insensitive to
small fluctuations in fg. To reduce the time spent in perturbing fg values, we set a
threshold on the control system error of 1:5
ﬃﬃﬃﬃﬃﬃﬃﬃ
n1
p
. When the error is less than this value
no minor cycles are executed. Normally, the control system is disabled the first time
the error is <1:5
ﬃﬃﬃﬃﬃﬃﬃﬃ
n1
p
. This was not done in the two examples shown in order to
illustrate the behavior of the control system and evolution of the fg. For the two
runs, the error drops to a level consistent with the minimum threshold set for initiating
a change in fg in 8000 and 9600 iterations, respectively. The other six panels exhibit
the evolution of the fg to relatively stable values. Table 12.1 compares the starting
and final values for two APT MCMC runs with a set of fg values arrived at manually.
The starting parameter values for the two APT MCMC runs are shown in Table 12.2.
Control system parameters were: scmax ¼ 0:1, n1 ¼ 1000, n2 ¼ 100,  ¼ 0:25, and a
damping factor,  ¼ 1:6. scmax specifies the maximum scaling of fg to be used in a
minor cycle. Tempering  values used were f0:01; 0:2575; 0:505; 0:7525; 1g.  values are
chosen to give ’50% swap acceptance between adjacent levels.
Figure 12.14 shows the iterations of the six model parameters, P; K; V; e; 
; !, for
the 100 000 iterations of APT MCMC 1. Only every 100th value is plotted. The plot for
K shows clear evidence that parallel tempering is doing its job, enabling regions of
significant probability to be explored apart from the biggest peak region. A conser-
vative burn-in period of 8000 samples was arrived at from an examination of the
12.9 Extrasolar planet example
337

control system error, shown in the upper left panel of Figure 12.12, and the parameter
iterations of Figure 12.14.
The level of agreement between two different MCMC runs can be judged from a
comparison of the marginal distributions of the parameters. Figures 12.15 and 12.16
show the posterior marginals for the six model parameters, P; K; V; e; 
; !, and the noise
scale parameter b for APT MCMC 1 and APT MCMC 2, respectively. The final model
0
20000
40000
60000
80000
Iteration
0.05
0.1
0.15
0.2
0.25
0.3
0.35
  
0
20000
40000
60000
80000
Iteration
0.025
0.05
0.075
0.1
0.125
0.15
0.175
σ e
σ ω
σ χ
0
20000
40000
60000
80000
Iteration
0.025
0.05
0.075
0.1
0.125
0.15
0.175
0
20000
40000
60000
80000
Iteration
20
40
60
80
σ K
0
20000
40000
60000
80000
Iteration
5
10
15
20
 σ V
0
20000
40000
60000
80000
Iteration
 –250
 –200
 –150
 –100
 –50
0
50
Error
0
20000
40000
60000
80000
Iteration
20
40
60
80
σ P
Figure 12.12 The upper left panel shows the evolution of the APT MCMC control system error
versus iteration number for the first run. The other six panels exhibit the evolution of the
Gaussian parameter proposal distribution ’s.
338
Markov chain Monte Carlo

parameter values are given in Table 12.3, along with values of a sin i, M sin i, and the
Julian date of periastron passage, that were derived from the parameter values.
a sin iðkmÞ ¼ 1:38  105KP
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  e2
p
;
(12:47)
where K is in units of m s1 and P is in days.
M sin i ¼ 4:91  103ðMÞ2=3KP1=3
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  e2
p
;
(12:48)
0
20000
40000
60000
80000
100000
Iteration
0.02
0.04
0.06
0.08
0.1
0.12
σ e
0
20000
40000
60000
80000
100000
Iteration
0.05
0.1
0.15
0.2
σ ω
0
20000
40000
60000
80000
100000
Iteration
0.02
0.04
0.06
0.08
0.1
0.12
σ χ
0
20000
40000
60000
80000
100000
Iteration
10
20
30
40
50
60
70
σ K
0
20000
40000
60000
80000
100000
Iteration
2
4
6
8
10
12
σ V
0
20000
40000
60000
80000
100000
Iteration
–250
–200
–150
–100
–50
0
50
Error
0
20000
40000
60000
80000
100000
Iteration
10
20
30
40
50
60
σ P
Figure 12.13 The upper left panel shows the evolution of the APT MCMC control system error
versus iteration number for the second run. The other six panels exhibit the evolution of the
Gaussian parameter proposal distribution ’s.
12.9 Extrasolar planet example
339

where M is the mass of the planet measured in Jupiter masses, and M is the mass of
the star in units of solar masses.
One important issue concerns what summary statistic to use to represent the best
estimate of the parameter values. We explore the question of a suitable robust summary
statistic further in Section 12.10. In Table 12.3, the final quoted parameter values
correspond to the MAP values. The median values are shown in brackets below. The
error bars correspond to the boundaries of the 68.3% credible region of the marginal
distribution. The MAP parameter values for APT MCMC 1 were used to construct the
model plotted in panel (a) of Figure 12.17. The residuals are shown in panel (b).
Figure 12.18 shows the posterior probability distributions for a sin i, M sin i, and the
Julian date of periastron passage, that are derived from the MCMC samples of the
orbital parameters.
The Bayes factors, pðDjM1; IÞ=pðDjM0; IÞ, determined from the two APT MCMC
runs were 1:4  1014 and 1:6  1014. Clearly, both trials overwhelmingly favor M1
over M0.
The upper panel of Figure 12.19 shows a comparison of the marginal and projected
probability density functions for the velocity amplitude, K, derived from the APT
MCMC parameter samples. To understand the difference, it is useful to examine the
strong correlation that is evident between K and orbital eccentricity in the lower panel.
Table 12.1 Comparison of the starting and final values of proposal distribution ’s for
two automatic parallel tempering MCMC runs, to manually derived values.
Proposal

APT MCMC 1
APT MCMC 2
Manual
Start
Final
Start
Final
Final
P (days)
70
6.2
50
7.8
10
Kðm s1Þ
70
5.7
60
6.0
5
Vðm s1Þ
20
1.5
10
1.2
2
e
0.15
0.012
0.1
0.012
0.005

0.15
0.013
0.1
0.009
0.007
!
0.3
0.023
0.2
0.019
0.05
Table 12.2 Starting parameter values for the two automatic parallel tempering MCMC
runs.
Trial
P
K
V
e

!
b
1
950
80
2
0.4
0.0
0.0
1.0
2
1300
250
5
0.2
0.0
0.0
1.0
340
Markov chain Monte Carlo

Not only is the density of samples much higher at low K values, but the characteristic
width of the K sample distribution is also much broader, giving rise to an enhancement
in the marginal beyond that seen in the projected.
Finally, even though the 68.3% credible region contains b ¼ 1, we decided to
analyze the best-fit residuals, shown in the lower panel of Figure 12.17, to see what
probability theory had to say about the evidence for another planet.4 The APT
MCMC program was re-run on the residuals to look for evidence of a second planet
in the period range 2 to 500 days, K ¼ 1 to 40 m s1, V ¼ 10 to 10 m s1, e ¼ 0 to
0.95, 
 ¼ 0 to 1, and ! ¼ p to p. The most probable orbital solution had a period of
11:90  0:02 days, K ¼ 18þ9
15 m s1, V ¼ 2:7þ2:4
1:6 m s1, eccentricity ¼ 0:626þ0:16
0:18,
! ¼ 156þ2
4 deg,
periastron
passage
¼ 1121  1 days ðJD 2;450;000Þ,
and
an
M sin i ¼ 0:14þ0:07
0:04. Figure 12.20 shows this orbital solution overlaid on the residuals
for two cycles of phase. Note: the second cycle is just a repeat of the first. The
computed Bayes factor pðDjM2; IÞ=pðDjM1; IÞ ¼ 0:7. Assuming a priori that
0
20000
40000
60000
80000
100000
Iteration
 –0.1
0
0.1
0.2
0.3
 
0
20000
40000
60000
80000
100000
Iteration
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Eccentricity
0
20000
40000
60000
80000
100000
Iteration
1000
1100
1200
1300
Period/days
0
20000
40000
60000
80000
100000
Iteration
 –20
 –10
0
10
20
V (ms–1)
0
20000
40000
60000
80000
100000
Iteration
100
200
300
400
K (ms–1)
0
20000
40000
60000
80000
100000
Iteration
 –0.8
 –0.6
 –0.4
 –0.2
0
 ω
χ
Figure 12.14 The figure shows every 100th APT MCMC iteration of the six model parameters,
P; K; V; e; 
; !.
4 Note: a better approach would be to fit a two-planet model to the original radial velocity data.
12.9 Extrasolar planet example
341

pðM2jIÞ ¼ pðM1jIÞ, this result indicates that it is more probable that the orbital
solution for the residuals arises from fitting a noise feature than from the existence
of a second planet. Thus, there is insufficient evidence at this time to claim the presence
of a second planet.
12.10 MCMC robust summary statistic
In the previous section, the best estimate of each model parameter is based on the
maximum a posteriori (MAP) value. It has been argued, e.g., Fox and Nicholls (2001),
0.4
0.6
0.8
1
1.2
1.4
1.6
Noise scale parameter b
0.5
1
1.5
2
Probability density
0.15
0.2
0.25
0.3
2
4
6
8
10
12
14
Probability density
–0.7
–0.6
–0.5
–0.4
–0.3
–0.2
Longitude of periastron ω
1
2
3
4
Probability density
 –10
0
10
20
30
40
0.01
0.02
0.03
0.04
0.05
0.06
0.07
Probability density
0.5
0.6
0.7
0.8
0.9
Eccentricity
1
2
3
4
5
Probability density
1150
1200
1250
1300
Period (d) 
0.002
0.004
0.006
0.008
0.01
0.012
0.014
Probability density
100
200
300
400
500
K (ms–1)
V (ms–1)
0.0025
0.005
0.0075
0.01
0.0125
0.015
0.0175
Probability density
χ
Figure 12.15 The marginal probabilities for the six model parameters, P; K; V; e; 
; !, and the
noise scale parameter b for the run APT MCMC 1.
342
Markov chain Monte Carlo

that MAP values are sometimes unrepresentative of the bulk of the posterior prob-
ability. Fox and Nicholls were considering the reconstruction of degraded binary
images. The current problem is very different but the issue remains the same: what
choice of summary statistic to use? Two desirable properties are: a) that it be repre-
sentative of the marginal probability distribution, and b) the set of summary parameter
values provides a good fit to the data. Here, we consider three other possible choices of
summary statistic. They are the mean, the median, and the marginal posterior mode
(MPM), all of which satisfy point (a). In repeated APT MCMC runs, it was found that
0.4
0.6
0.8
1
1.2
1.4
1.6
0.5
1
1.5
2
0.15
0.2
0.25
0.3
 
2.5
5
7.5
10
12.5
15
 –0.7  –0.6  –0.5  –0.4  –0.3  –0.2
1
2
3
4
 –10
0
10
20
30
40
0.01
0.02
0.03
0.04
0.05
0.06
0.5
0.6
0.7
0.8
0.9
1
2
3
4
5
1150
1200
1250
1300
0.0025
0.005
0.0075
0.01
0.0125
0.015
100
200
300
400
500
0.002
0.004
0.006
0.008
0.01
0.012
0.014
Noise scale parameter b
Probability density
Probability density
Longitude of periastron ω
Probability density
Probability density
Eccentricity
Probability density
Period (days) 
Probability density
K (ms–1)
V (ms–1)
Probability density
χ
Figure 12.16 The marginal probabilities for the six model parameters, P; K; V; e; 
; !, and the
noise scale parameter b for the run APT MCMC 2.
12.10 MCMC robust summary statistic
343

the MPM solution provided a relatively poor fit to the data, while the mean was
somewhat better, and in all cases, the median provided a good fit – almost as good as
the MAP fits. One example of the fits is shown in Figure 12.21. The residuals were as
follows: (a) 14:0 m s1 (MAP), (b) 16.1 (mean), (c) 18.7 (MPM), and (d) 14.0 (median).
In the previous example the Bayes factor favored the one-planet model, M1,
compared to the no-planet model, M0, by a factor of approximately 1014. It is also
Table 12.3 Comparison of the results from two parallel tempering MCMC Bayesian runs
with the analysis of Tinney et al. (2003). The values quoted for the two APT MCMC runs
are MAP (maximum a posterior) values. The error bars correspond to the boundaries of
the 68.3% credible region of the marginal distribution. The median values are given in
brackets on the line below. Note: the periastron time and error quoted by Tinney et al. is
identical with their P value and is assumed to be a typographical error.
Parameter
Tinney et al.
(2003)
APT MCMC
1
APT MCMC
2
Orbital period
1183  150
1188þ28
35
1177þ36
21
P (days)
(1188)
(1188)
Velocity amplitude
130  20
106þ46
29
116þ56
39
K ðm s1Þ
(115)
(125)
Eccentricity e
0:67  0:1
0:63þ0:12
0:06
0:65þ0:15
0:06
(0.67)
(0.68)
Longitude of periastron
333  15
333þ6
5
332þ8
3
! (deg)
(334)
(334)
a sin i
1:56  0:3
1:35þ0:4
0:3
1:4þ0:4
0:4
(units of 106 km)
(1.42)
(1.66)
Periastron time
1183  150
864þ18
58
856þ52
28
ðJD 2;450;000Þ
(845)
(844)
Systematic velocity
0:7þ8
6
1:4þ7
7
V ðm s1Þ
(0.8)
(2.1)
M sin i ðMJÞ
4:9  1:0
4:2þ1:2
1:0
4:5þ1:3
1:3
(4.5)
(4.7)
RMS about fit
15
13.8
14.0
(14.1)
(14.0)
344
Markov chain Monte Carlo

interesting to compare the four different summary statistics in the case where the
Bayes factor is close to 1, as we found for the toy spectral line problem in Section 12.7,
i.e., neither model is preferred. Figure 12.22 shows a comparison of the fits obtained
using (a) the MAP, (b) the mean, (c) the MPM, and (d) the median. Both the MAP and
median summary statistic placed the model line at the actual location of the simulated
spectral line (channel 37). The MAP achieved a slightly lower RMS residual
ðRMS ¼ 0:87Þ compared to the median ðRMS ¼ 0:89Þ. The mean statistic performed
rather poorly and the MPM not much better.
The conclusion, based on the current studies, is that the median statistic provides a
robust alternative to the common MAP statistic for summarizing the posterior dis-
tribution. Unfortunately, the median was not one of the statistics considered in Fox
and Nicholls (2001).
0
200
400
600
800
1000
1200
1400
Julian day number (–2,451,118.0578) 
Julian day number (–2,451,118.0578) 
 –40
 –20
0
20
Velocity residual (ms–1) 
Velocity (ms–1) 
(b)
0
200
400
600
800
1000
1200
1400
 –50
0
50
100
150
(a)
Figure 12.17 Panel (a) shows the raw data with error bars plotted together with the model radial
velocity curve using the MAP (maximum a posteriori) summary statistic. Panel (b) shows the
radial velocity residuals.
12.10 MCMC robust summary statistic
345

12.11 Summary
This chapter provides a brief introduction to the powerful role MCMC methods can
play in a full Bayesian analysis of a complex inference problem involving models with
large numbers of parameters. We have only demonstrated their use for models with a
small to a moderate number of parameters, where they can easily be compared with
results from other methods. These comparisons will provide a useful introduction and
calibration of these methods for readers wishing to handle more complex problems.
For the examples considered, the median statistic proved to be a robust alternative to
the common MAP statistic for summarizing the MCMC posterior distribution.
The most ambitious topic treated in this chapter dealt with an experimental new
algorithm for automatically annealing the  values for the parameter proposal dis-
tributions in a parallel tempering Markov chain Monte Carlo (APT MCMC) calcula-
tion. This was applied to the analysis of a set of astronomical data used in the detection
of an extrasolar planet. Existing analyses are based on the use of nonlinear least-
squares methods which typically require a good initial guess of the parameter values
(see Section 11.5). Frequently, the first indication of a periodic signal comes from a
periodogram analysis of the data. As we show in the next chapter, a Bayesian analysis
based on prior information of the shape of the periodic signal can frequently do a
better job of detection than the ordinary Fourier power spectrum, otherwise known as
the Schuster periodogram. In the extrasolar planet Kepler problem, the mathematical
form of the signal is well known and is built into the Bayesian analysis. The APT
700
750
800
850
900
950
Periastron passage (JD – 2,450,000)
0.002
0.004
0.006
0.008
0.01
0.012
PDF
1
2
3
4
5
a sin i (106 km)
0.2
0.4
0.6
0.8
1
1.2
PDF
4
6
8
10
12
14
M sin i (MJ )
0.05
0.1
0.15
0.2
0.25
0.3
0.35
PDF
Figure 12.18 The figure shows the distribution of three useful astronomical quantities; a sin i,
M sin i and epoch of periastron passage, that are derived from the MCMC samples of the orbital
parameters.
346
Markov chain Monte Carlo

100
200
300
400
K (ms–1)
K (ms–1)
0.5
0.6
0.7
0.8
0.9
Eccentricity e
100
200
300
400
500
0
0.0025
0.005
0.0075
0.01
0.0125
0.015
Probability density
Projected
Marginal
Figure 12.19 The upper panel shows a comparison of the marginal and projected probability
density functions for the velocity amplitude, K. The lower panel illustrates the strong correlation
between K and orbital eccentricity.
0
0.5
1
1.5
2
Phase
 –40
 –20
0
20
Velocity (ms–1)
Figure 12.20 The figure shows the most probable orbital solution to the data residuals (for two
cycles of phase), after removing the best fitting model of the first planet.
12.11 Summary
347

0
200
400
600
800
1000 1200 1400
Julian day number (–2,451,118.0578)
Julian day number (–2,451,118.0578)
Julian day number (–2,451,118.0578)
Julian day number (–2,451,118.0578)
–50
0
50
100
150
Velocity (ms–1)
Velocity (ms–1)
Velocity (ms–1)
Velocity (ms–1)
(c)
0
200
400
600
800
1000 1200 1400
–50
0
50
100
150
200
(d)
0
200
400
600
800
1000 1200 1400
–50
0
50
100
150
(a)
0
200
400
600
800
1000 1200 1400
–50
0
50
100
150
200
250
(b)
Figure 12.21 The four panels illustrate typical fits obtained in the extrasolar planet problem
using different choices of summary statistic to represent the MCMC parameter distributions.
They correspond to: (a) the MAP (maximum a posteriori), (b) the mean, (c) the MPM (marginal
posterior mode), and (d) the median.
0
10
20
30
40
50
60
Channel
–2
–1
0
1
2
3
4
Signal Strength (mK)
(c)
0
10
20
30
40
50
60
Channel
 –2
 –1
0
1
2
3
4
Signal Strength (mK)
(d)
0
10
20
30
40
50
60
Channel
 –2
 –1
0
1
2
3
4
Signal Strength (mK)  
Spectral Line Data
Spectral Line Data
Spectral Line Data
Spectral Line Data
(a)
0
10
20
30
40
50
60
Channel
 –2
 –1
0
1
2
3
4
Signal Strength (mK)
(b)
Figure 12.22 The four panels illustrate the fits obtained in the toy spectral line problem using
different choices of summary statistic to represent the MCMC parameter distributions. They
correspond to: (a) the MAP (maximum a posteriori), (b) the mean, (c) the MPM (marginal
posterior mode), and (d) the median.
348
Markov chain Monte Carlo

MCMC algorithm implemented in Section 12.9 is thus effective for both detecting and
characterizing the orbits of extrasolar planets. Another advantage is that a good initial
guess of the orbital parameter values is not required, which allows for the earliest
possible detection of a new planet. Moreover, the built-in Occam’s razor in the
Bayesian analysis can save a great deal of time in deciding whether a detection is
believable.
Finally, it is important to remember that the MCMC techniques described in this
chapter are basically tools to allow us to evaluate the integrals needed for a full
Bayesian analysis of some problem of interest. The APT MCMC algorithm discussed
in the context of the extrasolar planet problem can readily be modified to tackle other
very different problems.
12.12 Problems
1. In Section 12.6, we used both the Metropolis–Hastings and parallel tempering (PT) versions
of MCMC to re-analyze the toy spectral line problem of Section 3.6. A program to perform
the PT calculations is given in the Markov chain Monte Carlo section of the Mathematica
tutorial. Use this program to analyze the spectrum given in Table 12.4, for n ¼ 10 000 to
50 000 iterations, depending on the speed of your computer. As part of your solution,
recompute Figures 12.7, 12.8, and the Bayes factor used to compare the two competing
models. Explain how you arrived at your choice for the number of burn-in samples.
The prior information is the same as that assumed in Section 12.6. Theory predicts the
spectral line has a Gaussian shape with a line width L ¼ 2 frequency channels. The noise in
each channel is known to be Gaussian with a  ¼ 1:0 mK and the spectrometer output is in
units of mK.
2. Repeat the analysis of problem 1 with the following changes. In addition to the unknown line
strength and center frequency, the line width is also uncertain. Assume a uniform prior for
the line width, with upper and lower bounds of 0.5 and 4 frequency channels, respectively.
You will need to modify the parallel tempering MCMC program to allow for the addition of
the line width parameter. Experiment with your choice of , for the line width in the Gaussian
proposal distribution, to obtain a reasonable value for the acceptance rate somewhere in the
range 0.25 to 0.5. Your solution should include a plot of the marginal probability distribution
for each of the three parameters and a calculation of the Bayes factor for comparing the two
models. Justify your choice for the number of burn-in samples.
3. Carry out the analysis described in problem 2 by modifying the experimental APT MCMC
software provided in the Mathematica tutorial, and discussed in Section 12.8.
4. In Section 11.6, we illustrated the solution of a simple nonlinear model fitting problem using
Mathematica’s NonlinearRegress, which implements the Levenberg–Marquardt method. In
this problem we want to analyze the same spectral line data (Table 12.5) using the experi-
mental APT MCMC software given in the Mathematica tutorial and discussed in Section
12.8. It will yield a fully Bayesian solution to the problem without the need to assume the
asymptotic normal approximation, or to assume the Laplacian approximations for comput-
ing the Bayes factor and marginals. In general, MCMC solutions come into their own for
12.12 Problems
349

Table 12.5 Spectral line data consisting of 51 pairs of frequency and signal strength
(mK) measurements.
f
mK
f
mK
f
mK
f
mK
0.00
0.86
1.56
0.97
3.12
1.95
4.68
1.39
0.12
1.08
1.68
0.97
3.24
1.75
4.80
0.64
0.24
0.70
1.80
1.06
3.36
2.03
4.92
0.79
0.36
1.16
1.92
0.85
3.48
1.42
5.04
1.27
0.48
0.98
2.04
1.94
3.60
1.06
5.16
1.17
0.60
1.32
2.16
2.34
3.72
0.79
5.28
1.23
0.72
1.05
2.28
3.55
3.84
1.11
5.40
1.23
0.84
1.17
2.40
3.53
3.96
0.88
5.52
0.71
0.96
0.96
2.52
4.11
4.08
0.88
5.64
0.71
1.08
0.86
2.64
3.72
4.20
0.68
5.76
0.80
1.20
1.12
2.76
3.52
4.32
1.39
5.88
1.16
1.32
0.79
2.88
2.78
4.44
0.62
6.00
1.12
1.44
0.86
3.00
3.03
4.56
0.80
Table 12.4 Spectral line data consisting of 64 frequency channels obtained with a radio
astronomy spectrometer. The output voltage from each channel has been calibrated in
units of effective black body temperature expressed in mK. The existence of negative
values arises from receiver channel noise which gives rise to both positive and negative
fluctuations.
ch. #
mK
ch. #
mK
ch. #
mK
ch. #
mK
1
0.82
17
0.90
33
0.03
49
0.72
2
2.07
18
0.33
34
1.47
50
0.38
3
0.38
19
0.80
35
1.70
51
0.02
4
0.99
20
1.42
36
1.89
52
1.26
5
0.12
21
0.28
37
4.55
53
1.35
6
1.35
22
0.42
38
3.59
54
0.04
7
0.20
23
0.12
39
2.02
55
1.45
8
0.36
24
0.14
40
0.21
56
1.48
9
0.78
25
0.63
41
0.05
57
1.16
10
1.01
26
1.77
42
0.54
58
0.40
11
0.44
27
0.67
43
0.09
59
0.01
12
0.34
28
0.55
44
0.61
60
0.29
13
1.58
29
1.98
45
2.49
61
1.35
14
0.08
30
0.08
46
0.07
62
0.21
15
0.38
31
1.16
47
1.45
63
1.67
16
0.71
32
0.48
48
0.56
64
0.70
350
Markov chain Monte Carlo

higher dimensional problems but it is desirable to gain experience working with simpler
problems.
Modify the APT MCMC software to analyze these data for the two models described in
Section 11.6.
In Mathematica, model 1 has the form:
model[a0_; a1_; f1_]:=a0 þ a1 line[ f1]
where
line[ f 1] :¼ sin[2p(ff1)=Df]
2p( ff1)=Df
and  f ¼ 1:5.
Model 2 has the form:
model[a0; a1; a2; f1; f2] :¼ a0 þ a1 line[ f1] þ a2 line[ f2];
where f 2 is assumed to be the higher frequency line.
Adopt uniform priors for all parameters and assume a lower bound of 0 and an upper bound
of 10 for a0, a1 and a2. For the two spectral line model, we need to carefully consider the
prior boundaries for f1 and f2 to prevent the occurrence of two degenerate peaks in the joint
posterior. Adopt a range for f2 = 1.0 to 5.0. Since by definition, f1 is the lower frequency
line, at any iteration the current value of f1 must be less than current value of f2. Thus
pðf1jf2; M2; IÞ ¼
1
f2  1:0 :
12.12 Problems
351

13
Bayesian revolution in spectral analysis1
13.1 Overview
Science is all about identifying and understanding organized structures or patterns in
nature. In this regard, periodic patterns have proven especially important. Nowhere is
this more evident than in the field of astronomy. Periodic phenomena allow us to
determine fundamental properties like mass and distance, enable us to probe the
interior of stars through the new techniques of stellar seismology, detect new planets,
and discover exotic states of matter like neutron stars and black holes. Clearly, any
fundamental advance in our ability to detect periodic phenomena will have profound
consequences in our ability to unlock nature’s secrets. The purpose of this chapter is to
describe advances that have come about through the application of Bayesian prob-
ability theory,2 and provide illustrations of its power through several examples in
physics and astronomy. We also examine how non-uniform sampling can greatly
reduce some signal aliasing problems.
13.2 New insights on the periodogram
Arthur Schuster introduced the periodogram in 1905, as a means for detecting a
periodicity and estimating its frequency. If the data are evenly spaced, the period-
ogram is determined by the Discrete Fourier Transform (DFT), thus justifying the use
of the DFT for such detection and measurement problems. In 1965, Cooley and Tukey
introduced the Fast Discrete Fourier Transform (FFT), a very efficient method of
implementing the DFT that removes certain redundancies in the computation and
greatly speeds up the calculation of the DFT. A detailed treatment of the DFT and
FFT is given in Appendix B.
The Schuster periodogram was introduced largely for intuitive reasons, but in 1987,
Jaynes provided a formal justification by applying the principles of Bayesian inference
1 The term ‘‘spectral analysis’’ has been used in the past to denote a wider class of problems than will be considered in this
chapter. For a brief introduction to stochastic spectrum estimation, see Appendix B.13.4.
2 The first three sections of this chapter are a revised version of an earlier paper by the author (Gregory, 2001), which is
reproduced here with the permission of the American Institute of Physics.
352

as follows: suppose we are analyzing data consisting of samples of a continuous
function contaminated with additive independent Gaussian noise with a variance of
2. Jaynes showed that, presuming the possible periodic signal is sinusoidal (but with
unknown amplitude, frequency, and phase), the Schuster periodogram exhausts all
the information in the data relevant to assessing the possibility that a signal is present,
and to estimating the frequency and amplitude of such a signal. The periodogram is
essentially the squared magnitude of the FFT and can be defined as
periodogram ¼ Cð fnÞ ¼ 1
N
X
N1
k¼0
dk ei2pnfkT


2
¼ 1
N FFT
j
j2:
(13:1)
In an FFT, the frequency interval, f ¼ 1=T , where T is the duration of the data
set. The quantity Cð fnÞ is indeed fundamental to spectral analysis but not because it is
itself a satisfactory spectrum estimator. Jaynes showed that the probability for the
frequency of a periodic sinusoidal signal is given approximately by3
pð fnjD; IÞ / exp Cð fnÞ
2


:
(13:2)
Thus, the proper algorithm to convert Cð fnÞ to pð fnjD; IÞ involves first dividing Cð fnÞ
by the noise variance and then exponentiating. This naturally suppresses spurious
ripples at the base of the periodogram, usually accomplished with linear smoothing;
but does it by attenuation rather than smearing, and therefore does not sacrifice any
precision. The Bayesian nonlinear processing of Cð fnÞ also yields, when the data give
evidence for them, arbitrarily sharp spectral peaks. Since the peak in pð fn j D; IÞ can be
much sharper than the peak in Cð fnÞ, it is necessary to zero pad the FFT to obtain a
sufficient density of points in Cð fnÞ for use in Equation (13.2) to accurately define a
peak in pð fnjD; IÞ.
Figure 13.1 provides a demonstration of these properties for a simulated data set
consisting of a single sine wave plus additive Gaussian noise given by Equation (13.3).
y ¼ A cos 2pft þ Gaussian noise ðmean ¼ 0;  ¼ 1Þ;
(13:3)
where A ¼ 1, f ¼ 0:1 Hz. The upper panel shows 64 simulated data points computed
from Equation (13.3), with one- error bars. The middle panel is the Fourier
power spectral density or periodogram, computed for this data according to
Equation (13.1).4 The sinusoidal signal is clearly indicated by the prominent peak.
3 Bretthorst (2000) derives the exact result for non-uniformly sampled data which involves an analogous nonlinear
transformation of the Lomb–Scargle periodogram (Lomb, 1976; Scargle, 1982, 1989). Bretthorst (2001) also shows how
to generalize the Lomb–Scargle periodogram for the case of a non-stationary sinusoid. This is discussed further in
Section 13.5.
4 The 64 points were zero padded to provide a total of 512 points for the FFT. See Appendix B.11 for more details on
zero padding.
13.2 New insights on the periodogram
353

The signal-to-noise ratio (S/N), defined as the ratio of the RMS signal amplitude to
the noise , was 0.7 in the above simulation. If we repeated the simulation with a larger
S/N ratio, the main peak would increase in relation to the noise peaks and we would
start to notice side lobes emerging associated with the finite duration of the data set
(rectangular window function, see Appendix B.7.1). However, a well-known property
of the periodogram is that the width of any spectral peak depends only on the duration
of the data set and not on the signal-to-noise level. Various methods have been used to
determine the accuracy to which the peak frequency can be determined, but, as we see
below, the Bayesian posterior probability for the signal frequency provides this
information directly.
0
0.1
0.2
0.3
0.4
0.5
Frequency
50
100
150
200
250
Probability density
Bayesian Probability Density
0
0.1
0.2
0.3
0.4
0.5
Frequency
5
10
15
20
25
30
35
Power density
Fourier Power Spectral Density
10
20
30
40
50
60
Time axis
– 4
 – 2
0
2
4
Signal strength
Simulated Time Series [sin 2πft + noise (σ = 1)]
Figure 13.1 Comparison of conventional (middle panel) and Bayesian analysis (lower panel) of a
simulated time series (upper panel).
354
Bayesian revolution in spectral analysis

The lower panel of Figure 13.1 shows the Bayesian probability density for the
period of the signal, derived from Equation (13.2). As the figure demonstrates, the
spurious noise features are suppressed and the width of the spectral peak is much
narrower than the peak in the periodogram. In a Bayesian analysis, the width of
spectral peak, which reflects the accuracy of the frequency estimate, is determined by
the duration of the data, the S/N, and the number of data points. More precisely, the
standard deviation of the spectral peak, f, for a S/N > 1, is given by
f 
1:6 S
N T
ﬃﬃﬃﬃ
N
p

1
Hz;
(13:4)
where T ¼ the data duration in s, and N ¼ the number of data points in T . To improve
the accuracy of the estimate, the two most important factors are how long we sample
(the T dependence) and the signal-to-noise ratio.
Equation (13.2) assumes that the noise variance is a known quantity. In some
situations, the noise is not well understood, i.e., our state of knowledge is less certain.
Even if the measurement apparatus noise is well understood, the data may contain a
greater complexity of phenomena than the current signal model incorporates. In such
cases, Equation (13.2) is no longer relevant, but again, Bayesian inference can readily
handle this situation by treating the noise variance as a nuisance parameter with a
prior distribution reflecting our uncertainty in this parameter. We saw how to do that
when estimating the mean of a data set in Section 9.2.3. The resulting posterior can be
expressed in the form of a Student’s t distribution. The corresponding result for
estimating the frequency of a single sinusoidal signal (Bretthorst, 1988) is given
approximately5 by
pð fnjD; IÞ / 1  2Cð fnÞ
Nd2

2N
2
;
(13:5)
where N is the number of data values and d2 ¼ ð1=NÞ P
j d2
i is the mean square average
of the data values. The analysis assumes any DC component in the data has been
removed. If  is not well known, then it is much safer to use Equation (13.5) than
Equation (13.2) because Equation (13.5) will treat anything that cannot be fitted by
the model as noise. This leads to more conservative estimates.
A corollary of Jaynes’ analysis is that for any other problem (e.g., non-sinusoidal
light curve, non-Gaussian noise, or non-uniform sampling) use of the FFT is not
optimal; more information can be extracted from the data if we use more sophisticated
statistics. Jaynes made this point himself, and it has been amply demonstrated in the
work of Bretthorst (1988), who has applied similar methods to signal detection and
estimation problems with non-sinusoidal models with Gaussian noise probabilities.
5 Note: Equations (13.2) and (13.5) do not require the data to be uniformily sampled provided that: 1) the number of
data values N is large, 2) there is no constant (DC) component in the data, and 3) there is no evidence of a low
frequency.
13.2 New insights on the periodogram
355

In the following sections, we will consider two general classes of spectral problems:
(a) those for which we have strong prior information of the signal model, and (b) those
for which we have no specific prior information about the signal.
13.2.1 How to compute p( f |D,I )
In Section 13.2, we saw that the periodogram, Cð fnÞ, follows naturally from Bayesian
probability theory6 when our prior information indicates there is a single sine wave
present in the data and we want to compute the pð fnjD; IÞ. Equation (13.2) gives the
relationship between pð fnjD; IÞ and Cð fnÞ if the noise  is known, and Equation (13.5)
applies when the noise  is unknown. The value of the periodogram at a set of discrete
frequencies, indexed by n, is given by
Cð fnÞ ¼ 1
N
X
N
j ¼ 1
djei2pfntj


2
¼ 1
N FFT
j
j2
or CðnÞ ¼ 1
N
X
N
j ¼ 1
djei2pnj
N


2
¼ jHnj2
N
;
(13:6)
where Hn is the FFT or DFT transform defined by Equations (B.49) and (B.55) in
Appendix B.
We illustrate the calculations in more detail by comparing the Bayesian pðnjD; IÞ to
the one-sided PSD (given in Appendix B.13.2) for two simulated time series shown in
Figure 13.2. The time series consist of 64 samples at one-second intervals of
dj ¼ A cos 2pftj þ Gaussian noise ð ¼ 1Þ:
(13:7)
The simulated data for two different choices of signal amplitude (A ¼ 0:8 and
A ¼ 10), corresponding to low and high signal-to-noise ratios, are shown in the two
top panels of Figure 13.2. In the computation of the FFT, we take N time samples at
intervals of T seconds and compute N transform points Hn. The value, n ¼ 0, corre-
sponds to the FFT at zero frequency, and n ¼ N=2 to the value at the Nyquist
frequency ¼ 1=ð2TÞ. Values of n between N=2 þ 1 to N  1 correspond to values of
the FFT for negative frequencies. In Appendix B.13.1 we show that jHnj2T=N is the
two-sided PSD (two-sided periodogram) with units of power Hz1.
6 In general, for a different signal model or noise model, Bayesian inference will lead to an equation involving a different
function or statistic of the data for computing the probability of the signal frequency.
356
Bayesian revolution in spectral analysis

In the computation of the Bayesian pðnjD; IÞ; CðnÞ is just the positive frequency part
of jHnj2=N.
CðnÞ ¼ jHnj2
N
for n ¼ 0; 1; . . . ; N
2 :
(13:8)
Both CðnÞ and 2 have units of power and thus their ratio is dimensionless.
In general, pðnjD; IÞ will be very narrow when CðnÞ=2 > 1 because of the expo-
nentiation occurring in Equations (13.2) or (13.5). Thus, to accurately define pðnjD; IÞ
we need to zero pad the FFT to obtain a sufficient density of Hn points to accurately
define the pðnjD; IÞ peak. Zero padding is used to obtain higher frequency resolution
in the transform and is discussed in detail in Appendix B.11. In the zero padding case,
Equation (13.8) becomes
CðnÞ ¼ jHnj2
Norig
for n ¼ 0; 1; . . . ; Nzp
2 ;
(13:9)
0
0.1
0.2
0.3
0.4
0.5
Frequency
25
50
75
100
125
150
175
Probability density
Bayesian Probability
0
0.1
0.2
0.3
0.4
0.5
Frequency
200
400
600
800
1000
Probability density
Bayesian Probability
0
0.1
0.2
0.3
0.4
0.5
Frequency
2.5
5
7.5
10
12.5
15
17.5
Power density
Fourier Power Spectral Density
0.1
0.2
0.3
0.4
0.5
Frequency
500
1000
1500
2000
2500
3000
Power density
Fourier Power Spectral Density
10
20
30
40
50
60
Time axis
–4
–2
0
2
4
Signal strength
Simulation [0.8 sin 2πft + noise (σ = 1)]
Simulation [10 sin 2πft + noise (σ = 1)]
10
20
30
40
50
60
Time axis
 –10
–5
0
5
10
Signal strength
Figure 13.2 Comparison of conventional (middle panels) and Bayesian analysis (bottom panels)
of two simulated time series (top panels).
13.2 New insights on the periodogram
357

where Norig is the number of original time series samples and Nzp is the total number of
points including the added zeros. For analysis of the time series in Figure 13.2, we zero
padded to produce Nzp ¼ 512 points.
Box 13.1
Note: Mathematica uses a slightly different definition of Hn to that given in
Equation (13.6), which we designate by ½HnMath.
½HnMath ¼
1ﬃﬃﬃﬃ
N
p
X
N
j ¼ 1
djei2pnj
N
The modified version of Equation (13.9) is
CðnÞ ¼ Nzp
Norig
j½HnMathj2
for n ¼ 0; 1; . . . ; Nzp
2 ;
where ½HnMath ¼ Fourier[data], and data is a list of dj values.
The bottom two panels of Figure 13.2 show the Bayesian posterior pðnjD; IÞ
computed from Equation (13.2) for the two simulations. The middle panels show
the one-sided PSD for comparison. For the weak signal-to-noise simulation shown on
the left, the PSD display exhibits many spurious noise peaks. The Bayesian pðnjD; IÞ
shows a single strong narrow peak while the spurious noise features have been strongly
suppressed. Keep in mind that both quantities were computed from the same FFT of
the time series. The comparison serves to show how much of an improvement can be
obtained by a Bayesian estimation of the period over the intuitive PSD spectrum
estimator even for a RMS signal-to-noise ratio of  0:6.
The three panels on the right hand side of Figure 13.2 illustrate the corresponding
situation for a RMS signal-to-noise ratio of  7. In this case, we can clearly see the side
lobes adjacent to the main peak which arise from using a rectangular data windowing
function. In a conventional analysis, these side lobes are reduced by employing a data
windowing function which reduces the relative importance of data at either end and
results in a broadening of the spectral peak. The Bayesian analysis suppresses both the
side lobes and spurious ripples by attenuation, and results in a very much narrower
spectral peak. Also, because we have computed pðnjD; IÞ directly, we can readily
compute the accuracy of our spectral peak frequency estimate.
13.3 Strong prior signal model
Larry Bretthorst (1988, 1990a, b, c, 1991) extended Jaynes’ work to more complex
signal models with additive Gaussian noise and revolutionized the analysis of Nuclear
Magnetic Resonance (NMR) signals. In NMR free-induction decay, the signal
358
Bayesian revolution in spectral analysis

consists of a sum of exponentially decaying sinusoids of different frequency and decay
rate. The top two panels of Figure 13.3 illustrate the quadrature channel measure-
ments in an NMR free-induction decay experiment. In this example, the S/N is very
high. The middle panel illustrates the conventional absorption spectrum based on an
Figure 13.3 Comparison of conventional analysis (middle panel) and Bayesian analysis (bottom
panel) of the two-channel NMR time series (top two panels). (Figure credit G. L. Bretthorst,
reproduced by permission from the American Institute of Physics.)
13.3 Strong prior signal model
359

FFT of the data, which shows three obvious spectral peaks with an indication of
further structure in the peaks. The bottom panel illustrates Bretthorst’s Bayesian
analysis of this NMR data, which clearly isolates six separate peaks. The resolution
is so good that the six peaks appear as delta functions in this figure. A similar
improvement was obtained in the estimation of the decay rates. The Bayesian analysis
provides much more reliable and informative results when prior knowledge of the
shape of the signal and noise statistics are incorporated.
The question of how many frequencies are present, and what are the marginal
PDFs for the frequencies and decay rates, can readily be addressed in the Bayesian
framework using a Markov chain Monte Carlo computation. We saw how to do
this in Sections 12.5 to 12.9. Frequently, the physics of the problem provides
additional information about the relationships between pairs of frequencies, which
can be incorporated as useful prior information. Varian Corporation now offers
an expert analysis package with their new NMR machines based on Bretthorst’s
Bayesian algorithm. The manual for this software is available online at http://
bayesiananalysis.wustl.edu/.
13.4 No specific prior signal model
In this case, we are addressing the detection and measurement of a periodic signal in a
time series when we have no specific prior knowledge of the existence of such a signal
or of its characteristics, including its shape. For example, an extraterrestrial civiliza-
tion might be transmitting a repeating pattern of information either intentionally or
unintentionally. What scheme could we use to optimally detect such a signal after we
have made our best guess at a suitable wavelength of observation? Bayesian inference
provides a well-defined procedure for solving any inference problem including ques-
tions of this kind. However, to proceed with the calculation, it is necessary to assume a
model or family of models which is capable of approximating a periodic signal of
arbitrary shape. A very useful Bayesian solution to the problem of detecting a signal of
unknown shape was worked out by the author in collaboration with Tom Loredo
(Gregory and Loredo, 1992, 1993, 1996), for the case of event arrival time data.
The Gregory–Loredo (GL) algorithm was initially motivated by the problem of
detecting periodic signals (pulsars) in X-ray astronomy data. In this case, the time
series consisted of individual photon arrival times where the appropriate sampling
distribution is the Poisson distribution. To address the periodic signal detection
problem, we compute the ratio of the probabilities (odds) of two models MPer and
M1. Model MPer is a family of periodic models capable of describing a background
plus a periodic signal of arbitrary shape. Each member of the family is a histogram
with m bins, with m ranging from 2 to some upper limit, typically 12. Three examples
are shown in Figure 13.4. The prior probability that MPer is true is divided equally
among the members of this family. Model M1 assumes the data are consistent with a
360
Bayesian revolution in spectral analysis

constant event rate. M1 is a special case of MPer, with m ¼ 1 bin. Model M1 is
illustrated in the bottom right panel of Figure 13.4.
The Bayesian calculation automatically incorporates a quantified Occam’s penalty,
penalizing models with a larger number of bins for their greater complexity.7 The
calculation thus balances model simplicity with goodness-of-fit, allowing us to deter-
mine both whether there is evidence for a periodic signal, and the optimum number of
bins for describing the structure in the data. The parameter space for the m-bin
periodic model consists of the unknown period, an unknown phase (position of the
first bin relative to the start of the data), and m histogram amplitudes describing the
signal shape. A remarkable feature of this particular signal model is that the search in
the m shape parameters can be carried out analytically, permitting the method to be
computationally tractable. Further research is underway to investigate computation-
ally tractable ways of incorporating additional desirable features into the signal
model, such as variable bin widths to allow for a reduction in the number of bins
needed to describe certain types of signal.
The solution in the Poisson case yields a result that is intuitively very satisfying. The
probability for the family of periodic models can be shown to be approximately
inversely proportional to the entropy (Gregory and Loredo, 1992) of any significant
organized periodic structure found in the search parameter space. What structure is
significant is determined through built-in quantified Occam’s penalties in the calcula-
tion. Of course, structure with a high degree of organization corresponds to a state of
low entropy. In the absence of knowledge about the shape of the signal, the method
identifies the most organized significant periodic structure in the model parameter
space.
12–bin periodic model
Constant model
2–bin periodic model
6–bin periodic model
 
Figure 13.4 Three of the four panels show members of MPer, a family of histogram (piecewise
constant) periodic signal models, with m ¼ 2; 6, and 12 bins, respectively. The constant rate
model, M1, is a special case of MPer, with m ¼ 1 bin, and is illustrated in the bottom right panel.
7 The Occam penalty becomes so large for m  12, that the data are generally not good enough to make it worthwhile
including periodic models with larger values of m.
13.4 No specific prior signal model
361

Some of the capabilities of the GL method are illustrated in the following two
examples, one taken from X-ray astronomy and the other from radio astronomy.
13.4.1 X-ray astronomy example
In 1984, Seward et al. discovered a 50 ms X-ray pulsar at the center of a previously
known radio supernova remnant, SNR 0540-693, located in the Large Magellanic
Cloud. The initial detection of X-ray pulsations was from an FFT periodogram
analysis of the data obtained from the Einstein Observatory. The true pulsar signal
turned out to be the second highest peak in the initial FFT. Confidence in the reality
of the signal was established from FFT runs on other data sets. The pulsar was
re-observed with the ROSAT Observatory by Seward and colleagues, but this time,
an FFT search failed to detect the pulsar. In Gregory and Loredo (1996), we used the
GL method on a sample ROSAT data set of 3305 photons provided by F. Seward. The
data spanned an interval of 116 341 s and contained many gaps.
In the first instance, we incorporated the prior information on the period, period
derivative and their uncertainties, obtained from the earlier detection with the Einstein
Observatory data. The Gregory–Loredo method provides a calculation of the global
odds ratio defined as the ratio of the probability for the family of periodic models to
the probability of a constant rate model, regardless of the exact shape, period and
phase of the signal. The resulting odds ratio of 2:6  1011 indicates near certainty in
the presence of a periodic signal.
It is interesting to consider whether we would still claim the detection of a periodic
signal if we did not have the prior information derived from the earlier detection.
Thus, in the second instance, we assume a prior period search range extending from
the rotational breakup period of a neutron star ð 1:5 msÞ, to half the duration of the
data. This gives an odds ratio of 4:5  105. This is greatly reduced due to the much
larger Occam penalty associated with not knowing the period. But this still provides
overwhelming evidence for the presence of a periodic signal, despite the fact that it was
undetected by FFT techniques.
In their paper, Seward et al. (1984) used another method commonly employed in
X-ray astronomy, called period folding (also known as epoch folding), to obtain the
pulsar light curve and a best period. Period folding involves dividing the trial period
into m bins (typically five) and binning the data modulo the trial period for a given
trial phase. The 2 statistic is used to decide at some significance level, whether a
constant model can be rejected, and thus indirectly infer the presence of a periodic
signal. In Seward et al. (1984), their period uncertainty was estimated from the half-
width of the 2 peak, which is sometimes used as a naive estimate of the accuracy of the
frequency estimate. Figure 13.5 shows a comparison of the largest frequency peak
comparing the GL marginal probability density for f to the period folding h2i
statistic. The width of the GL marginal probability density for f is more than an
order of magnitude smaller.
362
Bayesian revolution in spectral analysis

13.4.2 Radio astronomy example
In 1999, the author generalized the GL algorithm to the Gaussian noise case.
Application of the method to a radio astronomy data set has resulted in the discovery
of a new periodic phenomenon (Gregory, 1999, 2002; Gregory et al., 1999; Gregory
and Neish, 2002) in the X-ray and radio emitting binary, LS I þ61303. LS I þ61303
is a remarkable tenth magnitude binary star (Gregory and Taylor, 1978; Hutchings
and Crampton, 1981) that exhibits periodic radio outbursts every 26.5 days (Taylor
and Gregory, 1982), which is the binary orbital period. The radio, infrared, optical,
X-ray and -ray data indicate that the binary consists of a rapidly rotating massive
young star, called a Be star, together with a neutron star in an eccentric orbit.
The Be star exhibits a dense equatorial wind and the periodic radio outbursts are
thought to arise from variations in wind accretion by the neutron star in its eccentric
orbit. Some of the energy associated with the accretion process is liberated in the form
of outbursts of radio emission. One puzzling feature of the outbursts has been the
variablity of the orbital phase of the outburst maxima, which can range over 180
degrees of phase. In addition, the strength of the outburst peaks was known to vary on
time scales of approximately 4 years (Gregory et al., 1989; Paredes et al., 1990).
Armed with over twenty years of data, we (Gregory, 1999; Gregory et al., 1999)
applied Bayesian inference to assess a variety of hypotheses to explain the outburst
timing residuals and peak flux density variations. The results for both the outburst
peak flux density and timing residuals demonstrated a clear 1667-day periodic modu-
lation in both quantities. The periodic modulation model was found to be  3  103
80
60
40
20
0
70
75
80
85
90
(frequency – 19852800) micro Hz
{CHI-square} and {Bayesian p(f)}
Figure 13.5 Close-up of largest frequency peak comparing the Gregory–Loredo probability
density for f to the period folding h2i statistic (diamonds). The h2i statistic versus trial
frequency results from epoch folding analysis using m ¼ 5 bins (Gregory and Loredo, 1996).
13.4 No specific prior signal model
363

times more probable than the sum of the probabilities of three competing non-periodic
models.
Figure 13.6 shows the data and results from the timing residual analysis. Panel (a)
shows the radio outburst peak timing residuals.8 The abscissa is the time interval in
days from the peak of the first outburst in 1977. Very sparsely sampled measurements
1000
1500
2000
2500
Modulation period (days)
 
0
0.01
0.02
0.03
0.04
Probability density
(c)
0
2000
4000
6000
8000
10000
Time (days)
 
 
 –10
–5
0
5
10
Residuals (days)
 
 
(b)
0
2000
4000
6000
8000
10000
Time (days)
 
 
 –10
–5
0
5
10
Residuals (days) 
(a)
Figure 13.6 Panel (a) shows the outburst timing residuals. A comparison of the predicted
outburst timing residuals with the data versus time is shown in panel (b). The solid curves
show the estimated mean light curve, 1 standard deviation. The new data are indicated
by a filled box symbol. Panel (c) shows the probability for the modulation period of
LS I þ61303.
8 The timing residuals depend on the assumed orbital period which is not accurately known independent of the radio
data. The GL algorithm was modified to compute the joint probability distribution of the orbital and modulation
periods. Only the marginal distribution for the modulation period is shown.
364
Bayesian revolution in spectral analysis

were obtained from the initial discovery in 1977 until 1992. However, beginning in
January 1994, Ray et al. (1997) performed detailed monitoring (several times a day)
with the National Radio Astronomy Observatory Green Bank Interferometer. With
such sparsely sampled data, the eye is unable to pick out any obvious periodicity.
Panel (c) shows the Bayesian marginal probability density for the modulation period.
The single well-defined peak provides clear evidence for a periodicity of approxi-
mately 1667 days.
Subsequent monitoring of the binary star system has confirmed and refined the
orbital and modulation period. Panel (b) shows a comparison of the predicted out-
burst timing residuals with the data versus time. The solid curves show the estimated
mean light curve, 1 standard deviation. The new data, indicated by a shaded box,
nicely confirm the periodic modulation model. This discovery has contributed sig-
nificantly to our understanding of Be star winds.
The Mathematica tutorial includes a Markov chain Monte Carlo version of the GL
algorithm, for the Gaussian noise case, in the section entitled, ‘‘MCMC version of the
Gregory–Loredo algorithm.’’
13.5 Generalized Lomb–Scargle periodogram
In Section 13.2, we introduced Jaynes’ insights on the periodogram from probability
theory and discussed how to compute pð fjD; IÞ in more detail in Section 13.2.1.
Bretthorst (2000, 2001) generalized Jaynes’ insights to a broader range of single-
frequency estimation problems and sampling conditions and removed the need for
the approximations made in the derivation of Equations (13.2) and (13.5). In the
course of this development, Bretthorst established a connection between the Bayesian
results and an existing frequentist statistic known as the Lomb–Scargle periodigram
(Lomb, 1976; Scargle, 1982, 1989), which is a widely used replacement for the Schuster
periodogram in the case of non-uniform sampling. We will summarize Bretthorst’s
Bayesian results in this section. In particular, his analysis allows for the following
complications:
1. Either real or quadrature data sampling. Quadrature data involve measurements of the real
and imaginary components of a complex signal. The top two panels of Figure 13.3 show an
example of quadrature signals occurring in NMR.
Let dRðtiÞ denote the real data at time ti and dIðt0
iÞ denote the imaginary data at time t0
i. There
are NR real samples and NI imaginary samples for a total of N ¼ NR þ NI samples.
2. Uniform or non-uniform sampling and for quadrature data with non-simultaneous sam-
pling.
The analysis does not require the ti and t0
i to be simultaneous and successive samples can be
unequally spaced in time.
3. Allows for a non-stationary single sinusoid model of the form
dRðtiÞ ¼ A cosð2pfti  ÞZðtiÞ þ B sinð2pfti  ÞZðtiÞ þ nRðtiÞ;
(13:10)
13.5 Generalized Lomb–Scargle periodogram
365

where A and B are the cosine and sine amplitudes, and nRðtiÞ denotes the noise at ti. The
function ZðtiÞ describes an arbitrary modulation of the amplitude, e.g., exponential decay as
exhibited in NMR signals. If Z(t) is a function of any parameters, those parameters are
assumed known, e.g., the exponential decay rate. Z(t) is sometimes called a weighting function
or apodizing function.
The corresponding signal model for the imaginary channel is given by
dIðt0
jÞ ¼ A cosð2pft0
j  ÞZðt0
jÞ þ B sinð2pft0
j  ÞZðt0
jÞ þ nIðt0
jÞ:
(13:11)
The angle  is defined in such a way as to make the cosine and sine functions orthogonal on
the discretely sampled times. This corresponds to the condition
0 ¼
X
NR
i ¼ 1
cosð2pfti  Þ sinð2pfti  ÞZðtiÞ2

X
NI
j ¼ 1
sinð2pft0
j  Þ cosð2pft0
j  ÞZðt0
jÞ2:
(13:12)
The solution of Equation (13.12) is given by
 ¼ 1
2 tan1
PNR
i ¼ 1 sinð4pfti  ÞZðtiÞ2  PNI
j ¼ 1 sinð4pft0
j  ÞZðt0
jÞ2
PNR
i ¼ 1 cosð4pfti  ÞZðtiÞ2  PNI
j ¼ 1 cosð4pft0
j  ÞZðt0
jÞ2
"
#
:
(13:13)
Note: if the data are simultaneously sampled, ti ¼ t0
j, then the orthogonal condition is
automatically satisfied so  ¼ 0.
4. The noise terms nRðtiÞ and nIðtiÞ are assumed to be IID Gaussian with an unknown . Thus, 
is a nuisance parameter, which is assumed to have a Jeffreys prior. By marginalizing over ,
any variability in the data that is not described by the model is assumed to be noise.
The final Bayesian expression for pð fjD; IÞ, after marginalizing over the amplitudes A and B
(assuming independent uniform priors), is given by
pð f jD; IÞ /
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Cð fÞSð fÞ
p
½Nd2  h2
2N
2 ;
(13:14)
where the mean-square data value, d2, is defined as
d2 ¼ 1
N
X
NR
i ¼ 1
dRðtiÞ2 þ
X
NI
j ¼ 1
dIðt0
jÞ2
"
#
:
(13:15)
The term h2 is given by
h2 ¼ Rð f Þ2
Cð f Þ þ Ið f Þ2
Sð f Þ ;
(13:16)
366
Bayesian revolution in spectral analysis

where
Rð f Þ 	
X
NR
i ¼ 1
dRðtiÞ cosð2pfti  ÞZðtiÞ 
X
NI
j ¼ 1
dIðt0
jÞ sinð2pft0
j  ÞZðt0
jÞ;
(13:17)
Ið f Þ 	
X
NR
i ¼ 1
dRðtiÞ sinð2pfti  ÞZðtiÞ þ
X
NI
j ¼ 1
dIðt0
jÞ cosð2pft0
j  ÞZðt0
jÞ;
(13:18)
Cð f Þ 	
X
NR
i ¼ 1
cos2ð2pfti  ÞZðtiÞ2 þ
X
NI
j ¼ 1
sin2ð2pft0
j  ÞZðt0
jÞ2
(13:19)
and
Sð fÞ 	
X
NR
i ¼ 1
sin2ð2pfti  ÞZðtiÞ2 þ
X
NI
j ¼ 1
cos2ð2pft0
j  ÞZðt0
jÞ2:
(13:20)
13.5.1 Relationship to Lomb–Scargle periodogram
If the sinusoidal signal is known to be stationary (ZðtiÞ is a constant) and the data are
entirely real, then Equations (13.17) to (13.20) greatly simplify. In this case, the
quantity h2 given by Equation (13.16) corresponds to the Lomb–Scargle periodogram;
however, we now see this statistic in a new light. The Bayesian expression for pð fjD; IÞ
(Equation (13.14)) involves a nonlinear processing of the Lomb–Scargle periodogram,
analogous to the nonlinear processing of the Schuster periodogram in Equation
(13.5). In fact, Bretthorst showed that for uniformly sampled quadrature data and a
stationary sinusoid, the Lomb–Scargle periodogram reduces to a Schuster period-
ogram, the power spectrum of the data. For real data, Equations (13.2) and (13.5) are
only approximately true. As we will demonstrate in Figure 13.7, Equation (13.5) can
provide an excellent approximation to pð fjD; IÞ for uniformly sampled real data and a
stationary sinusoid, and the Schuster periodogram is much faster to compute than the
Lomb–Scargle periodogram.
Equations (13.14) to (13.20) provide the exact answer for pð fjD; IÞ for a much wider
range problems and involve a generalized version of the Lomb–Scargle statistic.
13.5.2 Example
In this example, we compare the Schuster periodogram to the Lomb–Scargle period-
ogram, for the time series simulation involving a stationary sinusoid model and
13.5 Generalized Lomb–Scargle periodogram
367

uniformily sampled real data that we used in Section 13.2.1. In the first, which is
illustrated in Figure 13.7, the data are uniformly sampled. The top panel shows the
time series and the two middle panels show the Fourier power spectral density
(Schuster periodogram) and Lomb–Scargle periodogram of this time series. The
corresponding Bayesian pð fjD; IÞ probability densities are shown in the bottom two
panels. Clearly, for this example, the Schuster periodogram provides an excellent
approximation to the Lomb–Scargle periodogram, and is much faster to compute.
Recall that the width of the spectral peak in the Bayesian pð fjD; IÞ depends on the
signal-to-noise ratio (SNR). Even for a moderate SNR, the spectral peak can become
very narrow, requiring a large number of evaluations of the Lomb–Scargle statistic at
very closely spaced frequencies.
0
0.1
0.2
0.3
0.4
0.5
Frequency
25
50
75
100
125
150
175
Probability density
Bayesian Probability
0
0.1
0.2
0.3
0.4
0.5
Frequency
25
50
75
100
125
150
175
Probability density
Bayesian Lomb–Scargle Probability
0
0.1
0.2
0.3
0.4
0.5
Frequency
2.5
5
7.5
10
12.5
15
17.5
Power density
Fourier Power Spectral Density
0
0.1
0.2
0.3
0.4
0.5
Frequency
2.5
5
7.5
10
12.5
15
17.5
Power density
Lomb–Scargle Periodogram
10
20
30
40
50
60
Time axis
 –4
 –2
0
2
4
Signal strength
Simulation [0.8 sin 2πft + noise (σ = 1)]
Figure 13.7 The middle two panels compare the Fourier power spectral density (Schuster
periodogram) and Lomb–Scargle periodogram for the uniformly sampled time series simulation
shown in the top panel. The bottom two panels compare the Bayesian counterparts for the same
time series.
368
Bayesian revolution in spectral analysis

The second example, which is illustrated in Figure 13.8, makes use of the same time
series, but has 14 samples removed creating gaps in the otherwise uniform sampling.
These gaps can clearly be seen in the top right panel. To compute the Schuster
periodogram, some assumption must be made regarding the data in the gaps, to
achieve the uniform sampling required for the calculation of the FFT. In the top
left panel, the missing data have been filled in with values equal to the time series
average. In the calculation of the Lomb–Scargle periodogram, only the actual data are
used. The two bottom panels again illustrate the corresponding Bayesian pð f jD; IÞ
probability densities. In this case, it is clear that the Bayesian generalization of the
Lomb–Scargle periodogram does a better job.
In the latter example, the data are uniformly sampled apart from the gaps. In the
next section we will explore the issue of non-uniform sampling in greater detail.
0
0.1
0.2
0.3
0.4
0.5
Frequency
20
40
60
80
100
120
Probability density
Bayesian Probability
0
0.1
0.2
0.3
0.4
0.5
Frequency
20
40
60
80
100
120
Probability density
Bayesian Lomb–ScargleProbability
0
0.1
0.2
0.3
0.4
0.5
Frequency
2
4
6
8
10
12
Power density
Fourier Power Spectral Density
0
0.1
0.2
0.3
0.4
0.5
Frequency
2
4
6
8
10
12
Power density
Lomb–Scargle Periodogram
10
20
30
40
50
60
Time axis
 –4
–2
0
2
4
Signal strength
10
20
30
40
50
60
Time axis
–4
–2
0
2
4
 Signal strength
Simulation [0.8 sin 2πft + noise (σ = 1)]
Simulation [0.8 sin 2πft + noise (σ = 1)]
Figure 13.8 The middle two panels compare the Fourier power spectral density (Schuster
periodogram) and Lomb–Scargle periodogram for a time series with significant data gaps, as
shown in the top right panel. The bottom two panels compare the Bayesian counterparts for the
same time series.
13.5 Generalized Lomb–Scargle periodogram
369

13.6 Non-uniform sampling
In many cases, the data available are not uniformly sampled in the coordinate of
interest, e.g., time. In some cases this introduces complications, but on the flip side,
there is a distinct advantage. Non-uniform sampling can eliminate the common
problem of aliasing (Bretthorst 1988, 2000a). In this section, we explore this effect
with a demonstration.
We start with a uniform time series of 32 points containing a sinusoidal signal plus
additive independent Gaussian noise. The data are described by the following
equation:
dk ¼ 2 cosð2pfkTÞ þ noise ð ¼ 1Þ
with f ¼ 1:23Hz;
(13:21)
where T is the sample interval and k is an index running for 32 points. In this
demonstration, T ¼ 1 s. At 1.23 Hz, the signal frequency is well above the Nyquist
frequency ¼ 1=ð2TÞ ¼ 0:5 Hz.
In Figure 13.9 we demonstrate how the aliasing arises. The top panel shows the
Fourier Transform (FT) of the sampling. It is convenient to show both positive and
negative frequencies which arise in the mathematics of the FT. The middle panel
shows the FT of the signal together with the Nyquist frequency. The bottom panel
shows the resulting convolution. There are three aliased signals at f ¼ 0:23, f ¼ 0:77,
and f ¼ 1:77, only one of which, at f ¼ 0:23, is below the Nyquist frequency. For
deeper understanding of this figure, the reader is referred to Appendix B.5 and B.6.
We start by computing the Fourier transform and Bayesian posterior probability
density for the signal frequency of the initial uniformly sampled data. We will replace
some of the samples by samples taken at times that are not an integer multiple of T,
and explore how the spectrum is altered. Since we will be considering non-uniform
samples, we make use of the Lomb–Scargle periodogram, discussed in Section 13.5, to
compute the power spectrum. We also display the Bayesian posterior probability
density for the signal frequency using Bretthorst’s Bayesian generalization of the
Lomb–Scargle algorithm, also discussed in Section 13.5. Figure 13.10 shows the
evolution of both quantities as the number of non-uniform samples is increased. In
the top two panels (a), the original signal frequency at 1.23 Hz is clearly seen together
with three aliased signals. In the second row (b), one uniformly sampled data point has
been replaced by one non-uniform sample. The Lomb–Scargle periodogram shows
only a slight change, but remarkably, the Bayesian probability density has clearly
distinguished the real signal at 1.23 Hz. As more and more uniformly sampled points
are replaced, the amplitudes of the aliases in the Lomb–Scargle periodogram decrease.
Notice that for the non-uniform sampling used in this demonstration, no alias
occurs up to frequencies 
 4 times the effective Nyquist frequency. Of course, it
must be true that the aliasing phenomenon returns at sufficiently high frequencies.
If the sampling times tk, although non-uniform, are all integer multiples of some small
interval t, then signals at frequencies > 1=ð2tÞ will still be aliased.
370
Bayesian revolution in spectral analysis

Consideration of Figure 13.11 shows why aliasing does not occur for the non-
uniform sampling. In this example, we first generated four data points (filled boxes) by
sampling a 1.23 Hz sinusoidal signal, with no noise, at one-second intervals. The figure
shows four sinusoids corresponding to the 1.23 Hz signal and the 3 aliases at 0.23, 0.77
and 1.77 Hz, which all pass through these uniformly sampled data points. Next, we
replaced the first uniform sample by one which is non-uniformly sampled in time
(star). In this case, only the 1.23 Hz sinusoid passes through all four points.
There is clearly an advantage to employing non-uniform sampling which needs to
be considered as part of the experimental design. As Figure 13.11 clearly demon-
strates, even the addition of a small number of non-uniform samples (only one
required in this 32-point time series) to an otherwise uniformly sampled data set is
sufficient to strongly suppress aliasing in the Bayesian posterior probability density
for signal frequency.
– 
f
1.23
–1.23
–1.23
1.23
0.77
1.77
–0.77 
–1.77 
0.23
–0.23 
(CONVOLVE)
–fN 
fN
– 
f
1/ T
1/ T
1/ T
1/ T
 +
 +
 +
– 
f
Figure 13.9 How aliasing arises. Uniform sampling at an interval T in the time domain
corresponds to convolution in the frequency domain. The top panel shows the Fourier
Transform (FT) of the sampling. The middle panel shows the FT of the signal together with
the Nyquist frequency. The bottom panel shows the resulting convolution. There are 3 aliased
signals at f ¼ 0:23, f ¼ 0:77, and f ¼ 1:77, only one of which, at f ¼ 0:23, is below the Nyquist
frequency.
13.6 Non-uniform sampling
371

0
0.5
1
1.5
2
Frequency
10
20
30
40
50
60
70
Power density
(d) 16 non-uniform samples out of 32
0
0.5
1
1.5
2
Frequency
50
100
150
200
Probability density
0
0.5
1
1.5
2
Frequency
10
20
30
40
50
60
70
80
Power density
Lomb–Scargle Periodogram
Lomb–Scargle Periodogram
Lomb–Scargle Periodogram
Lomb–Scargle Periodogram
(c) 5 non-uniform samples out of 32
0
0.5
1
1.5
2
Frequency
50
100
150
200
Probability density
0
0.5
1
1.5
2
Frequency
10
20
30
40
50
60
70
Power density
(b) 1 non-uniform sample out of 32
0
0.5
1
1.5
2
Frequency
50
100
150
200
Probability density
0
0.5
1
1.5
2
Frequency
10
20
30
40
50
60
70
Power density
(a) Uniform sampling
0
0.5
1
1.5
2
Frequency
10
20
30
40
50
Probability density
Bayesian Lomb–Scargle
Bayesian Lomb–Scargle
Bayesian Lomb–Scargle
Bayesian Lomb–Scargle
Figure 13.10 Evolution of the Lomb–Scargle periodogram (left) and Bretthorst’s Bayesian
generalization of the Lomb–Scargle periodogram (right), with increasing number of non-
uniform samples in the time series. Notice how sensitive the Bayesian result is to a change of
only one sample from a uniform interval to a non-uniform interval.
372
Bayesian revolution in spectral analysis

13.7 Problems
Table 13.1 is a simulated times series consisting of a single sinusoidal signal with
additive IID Gaussian noise. In this problem, you will compare the usual one-sided
power spectral density discussed in Appendix B to the Bayesian posterior probability
density for the frequency of the model sinusoid.
0
1
2
3
4
Time
–2
 –1
0
1
2
Signal amplitude
Figure 13.11 An illustration of how four different frequencies can all pass through the same set
of four uniformly sampled data points (boxes) but only one passes through all the points when
one sample is relaced by a non-uniform sample (star).
Table 13.1 The table contains 64 samples of a simulated times series consisting of a single
sinusoidal signal with additive IID Gaussian noise.
#
mK
#
mK
#
mK
#
mK
1
0.474
17
0.865
33
0.225
49
0.369
2
0.281
18
0.206
34
1.017
50
0.695
3
1.227
19
0.926
35
0.817
51
1.291
4
1.523
20
2.294
36
2.064
52
0.978
5
0.831
21
0.786
37
0.103
53
0.592
6
0.978
22
0.522
38
1.878
54
0.986
7
0.169
23
1.04
39
0.625
55
1.005
8
0.04
24
0.181
40
1.418
56
1.268
9
0.76
25
1.47
41
0.464
57
0.571
10
0.847
26
1.837
42
1.182
58
1.128
11
0.106
27
0.523
43
1.319
59
0.64
12
1.814
28
0.605
44
1.354
60
0.144
13
1.16
29
1.595
45
1.784
61
1.468
14
0.249
30
0.413
46
0.989
62
0.71
15
1.054
31
1.275
47
1.52
63
1.486
16
0.359
32
1.644
48
1.239
64
0.129
13.7 Problems
373

Part 1: Fast Fourier Transform and PSD
a) Use an FFT to determine the one-sided power spectral density (PSD), as defined by
Equation (B.102) in Appendix B. Plot both the raw data and your spectrum and
determine the period of the strongest peak.
b) ToobtainamoreaccuratedeterminationofthepeakinthePSD, addzerostotheendof
the input data so that the total data set (data þ appended zeros) is 1024 points and
recomputethePSD.Note:althoughthenumberofspectralpointswillincrease,the1=N
normalizationterminEquation(B.102)stillreferstotheoriginalnumberofdatapoints.
Plot the new PSD.Do you expect the width of the peak to be affected by zero padding?
Part 2: Bayesian posterior probability of signal frequency
The Bayesian posterior probability of the signal frequency, assuming a model of a
single harmonic signal plus independent Gaussian noise, is given by Equation (13.2). If
the noise is not well understood, then it is safer to use the Student’s t form of Equation
(13.5) which treats anything that cannot be fitted by the model as noise and leads to
more conservative parameter estimates. Since we are evaluating pðnjD; IÞ at n discrete
frequencies, we rewrite Equation (13.5) as
pðnjD; IÞ ¼
1  2CðnÞ
Norigd2

2Norig
2
PNzp=2
0
1  2CðnÞ
Norigd2

2Norig
2
;
(13:22)
where d2 ¼
1
Norig
P
i d2
i .
In Equation (13.22), the frequency associated with any particular value of n is given
by fn ¼ n=NT. T equals the sample interval in time and N is the total number of
samples. The value n ¼ 0 corresponds to zero frequency. The quantity CðnÞ is the
positive frequency part of the two-sided periodogram (two-sided PSD) given by
Equation (13.6), which we rewrite as
CðnÞ ¼ jHnj2
N
;
for
n ¼ 0; 1; . . . ; N
2 :
(13:23)
In general, pðnjD; IÞ will be very narrow when CðnÞ=2 > 1 because of the expo-
nentiation occurring in Equation (13.2). Thus, to accurately define pðnjD; IÞ, we need
to zero pad the FFT to obtain a sufficient density of Hn points to accurately define the
pðnjD; IÞ peak. Zero padding is discussed in detail in Appendix B. In the zero padding
case, Equation (13.23) becomes
CðnÞ ¼ jHnj2
Norig
;
for
n ¼ 0; 1; . . . ; Nzp
2 ;
(13:24)
374
Bayesian revolution in spectral analysis

where Norig is the number of original time series samples and Nzp is the total number of
points including the added zeros.
(a) Compute and plot pðnjD; ; IÞ from a zero padded FFT of the time series given
above. Assume the variance of the data set ¼ 1.
(b) Measure the width of the peak at half height of pðnjD; ; IÞ and compare the width
of the PSD peak at half height.
(c) Plot the natural logarithm of the Bayesian pðnjD; IÞ and compare its shape to the PSD.
Note: Mathematica uses a slightly different definition of Hn to that given in
Equation (B.51), which we designate by ½HnMath. The modified version of Equation
(13.24) is given by:
CðnÞ ¼ Nzp
Norig
j½HnMathj2;
for
n ¼ 0; 1; . . . ; Nzp
2 :
(13:25)
13.7 Problems
375

14
Bayesian inference with Poisson sampling
14.1 Overview
In many experiments, the basic data consist of a set of discrete events distributed in
space, time, energy, angle or some other coordinate. They include macroscopic events
like a traffic accident or the location of a star. They also include microscopic events
such as the detection of individual particles or photons in time or position. In
experiments of this kind, our prior information often leads us to model the probability
of the data (likelihood function) with a Poisson distribution. See Section 4.7 for
a derivation of the Poisson distribution, and Section 5.7.2 for the relationship between
the binomial and Poisson distributions.
For temporally distributed events, the Poisson distribution is given by
pðnjr; IÞ ¼ ðrTÞnerT
n!
:
(14:1)
It relates the probability that n discrete events will occur in some time interval T to a
positive real-valued Poisson process event rate r. When n and rT are large, the Poisson
distribution can be accurately approximated by a Gaussian distribution. Here, we will
be concerned with situations where the Gaussian approximation is not good enough
and we must work directly with the Poisson distribution.
In this chapter, we employ Bayes’ theorem to solve the following inverse problem:
compute the posterior PDF for r given the data D and prior information I. We divide
this into three common problems:
1. How to infer a Poisson rate r.
2. How to infer a signal in a known background.
3. Analysis of ON/OFF data, where ON is the signal þ background and OFF is a just the
background. The background is only known imprecisely from the OFF measurement.
The treatment is similar to that given by Loredo (1992), but also includes a
treatment of the source detection question in the ON/OFF measurement problem.
In the above three problems, the Poisson rate is assumed to be constant in the ON or
OFF source position. In Section 14.5, we consider a simple radioactive decay problem
in which r varies significantly over the duration of the data.
376

14.2 Infer a Poisson rate
The simplest problem is to infer the rate r from a single measurement of n events. From
Bayes’ theorem:
pðrjn; IÞ ¼ pðrjIÞpðnjr; IÞ
pðnjIÞ
:
(14:2)
The prior information I must specify both pðrjIÞ and the likelihood function pðnjr; IÞ.
In this case, the latter is just the Poisson distribution.
I
likelihood:
pðnjr; IÞ ¼ ½ðrTÞnerT=n!
prior:
pðrjIÞ ¼ ?
(
Our first guess at pðrjIÞ is a Jeffreys prior since r is a scale parameter. However, the
scale invariance argument is not valid if r may vanish. Instead, we adopt a uniform
prior for r based on the following argument: intuition suggests ignorance of r corres-
ponds to not having any prior preference for seeing any particular number of counts,
n. In situations where it is desirable to use the Poisson distribution, the prior range for
n is frequently small, so it is reasonable to use a uniform prior:
pðnjIÞ ¼ constant:
But pðnjIÞ is also the denominator in Equation (14.2), so we can write
pðnjIÞ ¼
Z 1
0
dr pðrjIÞ pðnjr; IÞ
¼ 1
n!T
Z 1
0
dðrTÞ pðrjIÞðrTÞnerT:
(14:3)
For pðnjIÞ to be constant, it is necessary that
Z 1
0
dðrTÞ pðrjIÞðrTÞnerT / n!
but
Z 1
0
dx xn ex ¼ ðn þ 1Þ ¼ n!
(14:4)
which implies that pðrjIÞ ¼ constant. Use
pðrjIÞ ¼
1
rmax
;
0  r  rmax:
(14:5)
Then
pðnjIÞ ¼
1
Trmax
Z rmax
0
dðrTÞðrTÞnerT
¼
1
Trmax
ðn þ 1; rmaxTÞ
n!
;
(14:6)
14.2 Infer a Poisson rate
377

where ðn; xÞ ¼
R x
0 dy yn1ey is one form of the incomplete gamma function.1 Now
substitute Equations (14.1), (14.5), and (14.6) into Equation (14.2) to obtain the
posterior pðrjn; IÞ.
pðrjn; IÞ ¼ TðrTÞnerT
n!

n!
ðn þ 1; rmaxTÞ ;
0  r  rmax:
(14:7)
For rmaxT  n, then ðn þ 1; rmaxTÞ ’ ðn þ 1Þ ¼ n! and Equation (14.7) simplifies to
pðrjn; IÞ ¼ TðrTÞnerT
n!
;
r  0:
(14:8)
14.2.1 Summary of posterior
pðrjn; IÞ ¼ TðrTÞnerT
n!
;
r  0
mode:
r ¼ n=T;
mean:
<r> ¼ ðn þ 1Þ=T;
sigma:
r ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
n þ 1
p
=T:
Figure 14.1 illustrates the shape of the posterior pðrjn; IÞ, divided by the time
interval T, for four different choices of n ranging from n ¼ 0 to 100. In each case,
the count interval T ¼ 1 s. As n increases, the pðrjn; IÞ becomes more symmetrical and
gradually approaches a Gaussian (shown by the dotted line) with the same mode and
standard deviation. For n ¼ 10, the Gaussian approximation is still a poor fit. By
n ¼ 100, the Gaussian approximation provides a good fit near the mode but still
departs noticeably in the wings.
The 95% credible region can be found by solving for the two values rhigh and rlow
which satisfy the two conditions:
pðrhighjn; IÞ ¼ pðrlowjn; IÞ;
and
Z rhigh
rlow
pðrjn; IÞdr ¼ 0:95:
For n ¼ 1 the credible region is
p 0:042
T
 r  4:78
T


¼ 0:95:
(14:9)
1 See Press et al. (1992).
378
Bayesian inference (Poisson sampling)

14.3 Signal + known background
In this case, the measured rate consists of two components, one due to a signal of
interest, s, and the other a known background rate, b.
r ¼ s þ b
s ¼ signal rate
b ¼ known background rate:
(
Since we are assuming the background rate is known,
pðsjn; b; IÞ ¼ pðrjn; b; IÞ:
We can now use Equation (14.8) of the previous section for pðrjn; b; IÞ, and replace r by
s þ b. The result is
pðsjn; b; IÞ ¼ C T½ðs þ bÞTneðsþbÞT
n!
(14:10)
C1 ¼ ebT
n!
Z 1
0
dðsTÞðs þ bÞn TnesT:
(14:11)
5
10
15
20
Rate r
0.02
0.04
0.06
0.08
0.1
0.12
0.14
p(rn, I )/T
p(rn, I )/T
p(rn, I )/T
p(rn, I )/T
n = 10
80
100
120
140
Rate r
0.01
0.02
0.03
0.04
n = 100
1
2
3
4
5
Rate r
0.2
0.4
0.6
0.8
1
n = 0
1
2
3
4
5
6
7
8
Rate r
0.1
0.2
0.3
0.4
n = 1
Figure 14.1 The posterior PDF, pðrjn; IÞ, divided by the time interval T, plotted for four different
values of n. For comparison, a Gaussian with the same mode and standard deviation is shown
by the dotted curve for the n ¼ 10 and n ¼ 100 cases.
14.3 Signal + known background
379

The constant C ensures that the area under the probability density function ¼ 1. Using
a binomial expansion of ðs þ bÞn (see Equation (D.7) in Appendix D), we can arrive at
the following simple expression for C1:
C1 ¼
X
n
i¼0
ðbTÞiebT
i!
:
(14:12)
Equation (14.10) was proposed by Helene (1983, 1984) as a Bayesian solution for
analyzing multichannel spectra in nuclear physics.
14.4 Analysis of ON/OFF measurements
In this section, we want to infer the source rate, s, when the background rate, b, is
imprecisely measured. This is called an ON/OFF measurement.
OFF ! detector pointed off source to measure b
ON ! detector pointed on source to measure s þ b:
The usual approach is to assume
OFF ! ^b  b
ON ! ^r  r;
where ^b ¼ Noff=T and b ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Noff
p
=T and ^r ¼ Non=T and r ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
Non
p
=T. Then
^s ¼ ^r  ^b and the variance 2
s ¼ 2
r þ 2
b. This procedure works well for the Poisson
case provided both s and b are large enough that the Poisson is well approximated by
a Gaussian. But when either or both of the rates are small, the procedure fails. This can
lead to negative estimates of s and/or error bars extending into non-physical negative
values. This is a big problem in -ray and ultra-high energy astrophysics, where data
are very sparse. First consider the OFF measurement:
pðbjNoff; IbÞ ¼ ToffðbToffÞNoffebToff
Noff!
:
(14:13)
For the ON measurement, we can write the joint probability of the source and
background rate:
pðs; bjNon; IÞ ¼ pðs; bjIÞpðNonjs; b; IÞ
pðNonjIÞ
¼ pðsjb; IÞpðbjIÞpðNonjs; b; IÞ
pðNonjIÞ
:
(14:14)
380
Bayesian inference (Poisson sampling)

Note: the prior information, I, includes information about the background OFF
measurement in addition to the model Msþb, which asserts that the Poisson rate in
the ON measurement is equal to s þ b. We can express this symbolically by I ¼ Noff,
Ib, Msþb. In the parameter estimation part of the problem, we will estimate the value of
the source rate s in the model Msþb. Following this, we will evaluate a model selection
problem to compare the probability of model Msþb, which assumes a source is present,
to the simpler model Mb, which asserts that the Poisson rate in the ON source
measurement is equal to b, i.e., no source is present.
14.4.1 Estimating the source rate
The likelihood for the ON measurement is the Poisson distribution for a source with
strength s þ b:
pðNonjs; b; IÞ ¼ ½ðs þ bÞTonNoneðsþbÞTon
Non!
:
(14:15)
We will again assume a constant prior for s, so we write pðsjb; IÞ ¼ 1=smax. The prior
for b is simply the posterior from the background measurement, given by Equation
(14.13). Combining Equations (14.13), (14.14) and (14.15), we can compute the joint
posterior for s and b. To find the posterior for s alone, independent of the background,
we just marginalize with respect to b.
pðsjNon; IÞ ¼
Z bmax
0
db pðs; bjNon; IÞ:
(14:16)
The exact integral can be calculated after expanding the binomial, ðs þ bÞNon and
making use of the incomplete gamma function to evaluate the integrals, as we did in
Section 14.2. The details of this calculation are given in Appendix D. The result is
pðsjNon; IÞ ¼
X
Non
i¼0
Ci
TonðsTonÞiesTon
i!
;
(14:17)
where
Ci 
1 þ Toff
Ton

i ðNonþNoffiÞ!
ðNoniÞ!
PNon
j¼0 1 þ Toff
Ton

j ðNonþNoffjÞ!
ðNonjÞ!
:
(14:18)
Note:
X
Non
i¼0
Ci ¼ 1:
14.4 Analysis of ON/OFF measurements
381

Figure 14.2 shows plots of the posterior probability density of the source rate
pðsjNon; IÞ for four different combinations of Non; Noff; Ton; and Toff. Notice that
even in the case that Non < Noff, the value of pðsjNon; IÞ is always zero for non-physical
negative values of s. It is also clear that increasing the ON measurement time and/or
the OFF measurement time sharpens the definition of pðsjNon; IÞ.
We can gain a better understanding for the meaning of the complicated Ci term in
Equation (14.17) by evaluating pðsjNon; IÞ for a restatement of the problem. The
background information I includes Noff, the number of background events measured
in the off-source measurement as well as Ton and Toff. For the state of information
corresponding to Non; I, we can use Bayes’ theorem to compute pðijNon; IÞ, the prob-
ability that i of the on-source events are due to the source and Non  i are due to the
background. Clearly, i is an integer that can take on values from 0 to Non. We can then
obtain the posterior probability for s, from the joint probability pðs; ijNon; IÞ, by
marginalizing over i as follows:
pðsjNon; IÞ ¼
X
Non
i¼0
pðs; ijNon; IÞ ¼
X
Non
i¼0
pðijNon; IÞpðsji; Non; IÞ
¼
X
Non
i¼0
pðijNon; IÞ TonðsTonÞiesTon
i!
;
(14:19)
where we have used Equation (14.8) to evaluate pðsji; Non; IÞ. Comparing Equation
(14.17) with (14.19), we can write Ci ¼ pðijNon; IÞ, the probability that i of the ON
measurement events are due to the source.
We are now able to interpret Equation (14.17) in the following useful way: Bayes’
theorem estimates s by taking a weighted average of the posteriors one would obtain
2
4
6
8
10
12
14
16
Signal rate (s–1)
0.1
0.2
0.3
0.4
p(s |Noh, I )
Non = 2, Noff = 3, Ton = 1, Toff = 1
Non = 24, Noff = 9, Ton = 3, Toff = 3
Non = 8, Noff = 36, Ton = 1, Toff = 12
Non = 8, Noff = 3, Ton = 1, Toff = 1
Figure 14.2 The posterior probability density of the source rate, pðsjNon; IÞ, plotted for four
different combinations of Non, Noff, Ton, and Toff.
382
Bayesian inference (Poisson sampling)

attributing i ¼ 0; 1; 2; . . . ; Non events to the source. The weight Ci is equal to the
probability of attributing i of the on-source events to the source, or equivalently,
attributing Non  i events to the background, assuming Msþb is true.
Now suppose our question changes from estimating the source rate, s, to the
question of how confidently we can claim to have detected the source in the ON
measurement. We might be tempted to reason as follows: for the source to have been
detected in the ON measurement, then at least one of the Non photons must have been
from the source. The probability of attributing at least one of the Non photons to the
source is just the sum of Ci terms for i ¼ 1 to Non, which is given by
pði  1jNon; IÞ 
PNon
i¼1 1 þ Toff
Ton

iðNonþNoffiÞ!
ðNoniÞ!
PNon
j¼0 1 þ Toff
Ton

jðNonþNoffjÞ!
ðNonjÞ!
:
(14:20)
In Figure 14.3, we have plotted pði  1jNon; IÞ versus Non for two different back-
ground OFF measurements. In the first case, Noff ¼ 3 counts in a Toff ¼ 1 s. In the
second case, Noff ¼ 36 counts in a Toff ¼ 12 s. In many experiments, the cost and/or
effort required to obtain ON measurements (e.g., particle accelerator beam ON) is
much greater than for OFF measurements. As our knowledge of the background rate
improves, we see that pði  1jNon; IÞ decreases for Non  3, the expected number of
background photons, and increases above this. For Non ¼ 8 and Noff ¼ 3 counts in
Toff ¼ 1 s, the probability is 95.6%. This rises to 98.9% for Noff ¼ 36 counts in
Toff ¼ 12 s.
What is wrong with setting the probability of source detection equal to
pði  1jNon; IÞ? The answer is that the Ci probabilities are based on assuming that
0
2
4
6
8
10
12
14
0.2
0.4
0.6
0.8
1
p(i ≥ 1|Non, I )
Noff = 36,Ton = 1,Toff = 12
Noff = 3,Ton = 1,Toff = 1
Non   (counts)
Figure 14.3 The probability of attributing at least one of the Non photons to the source,
pði  1jNon; IÞ, assuming model Msþb is true, versus the number of counts in the ON measure-
ment, for two different durations of the background OFF measurement.
14.4 Analysis of ON/OFF measurements
383

the model Msþb is true. They do not account for the extra complexity of Msþb when
compared to an intrinsically simpler model, Mb, which asserts that the Poisson rate in
the ON source measurement is equal to b, i.e., no source is present. To answer the
source detection question, we need to compare the probabilities of these two models,
which we do next. This approach automatically introduces an Occam penalty which
penalizes Msþb for its greater complexity.
14.4.2 Source detection question
In the parameter estimation problem above, we assumed the truth of model Msþb and
estimated the value of s. Here, we will address the source detection (model selection)
problem: ‘‘Have we detected a source in the ON measurement?’’ To answer this, we
will compute the odds ratio, Ofsþb;bg, of two models Msþb and Mb, which have the
following meaning:
Mb 	 ‘‘the ON measurement is solely due to the Poisson background rate, b.’’ The
prior probability for b is derived from the OFF measurement.
Msþb 	 ‘‘the Poisson rate in the ON source measurement is equal to s þ b.’’ The prior
for s is a constant in the range 0 to smax. Again, the prior probability for b is derived
from the OFF measurement.
In
our
earlier
work,
our
background
information
was
represented
by
I ¼ Noff; Ib; Msþb. In the current model selection problem, we will use the abbreviation
Ioff ¼ Noff; Ib:
(14:21)
According to Section 3.14, we can write the odds as
Ofsþb;bg ¼ pðMsþbjNon; IoffÞ
pðMbjNon; IoffÞ ¼ pðMsþbjIoffÞ
pðMbjIoffÞ
pðNonjMsþb; IoffÞ
pðNonjMb; IoffÞ
¼ prior odds  Bfsþb;bg;
(14:22)
where Bfsþb;bg is the Bayes factor, the ratio of the global likelihoods for the two
models. The calculation of the global likelihood for Msþb introduces an Occam factor
that penalizes this model for its greater complexity when compared to Mb. The Occam
factor depends directly on the prior uncertainty in the additional parameter s (see
Section 3.5). The details behind the calculation of the Bayes factor are again given in
Appendix D.2. The result is
Bfsþb;bg 
Non!
smaxTonðNon þ NoffÞ!
X
Non
i¼0
ðNon þ Noff  iÞ!
ðNon  iÞ!
1 þ Toff
Ton

i
:
(14:23)
384
Bayesian inference (Poisson sampling)

In what follows, we will assume a prior odds ratio of 1, so Ofsþb;bg ¼ Bfsþb; bg. Since
pðMsþbjNon; IoffÞ þ pðMbjNon; IoffÞ ¼ 1, we can express pðMsþbjNon; IoffÞ in terms of
the odds ratio:
pðMsþbjNon; IoffÞ ¼
1
ð1 þ 1=Ofsþb; bgÞ :
(14:24)
In Figure 14.4, we have plotted PðMsþbjNon; IoffÞ versus Non for two different back-
ground OFF measurements, assuming an smax ¼ 30. In the first case, Noff ¼ 3 counts
in a Toff ¼ 1 s. In the second case, Noff ¼ 36 counts in a Toff ¼ 12 s. For a given value
of Non, the probability that a source is detected decreases for Non  3, the expected
number of background photons, and increases above this. For Non ¼ 8 and Noff ¼ 3
counts in Toff ¼ 1 s, the probability is 61.0%. This rises to 74.6% for Noff ¼ 36 counts
in Toff ¼ 12 s. These are significantly lower than the corresponding probabilities for
pði  1jNon; IÞ as shown in Figure 14.3.
Sensitivity to prior information
We close by reminding the reader that the conclusions of any Bayesian analysis are
always conditional on the truth of our prior information. It is clear that in the source
detection (model selection) problem, the Bayes factor (Equation (14.23)) is very
sensitive to the choice of the prior upper boundary,2 smax. Halving the value of smax
causes the Bayes factor to increase by a factor of two. It is useful to consider the
uncertainty in smax as introducing a systematic error into our conclusion. As discussed
in Section 3.6, we can readily allow for the effect of systematic error in a Bayesian
0
2
4
6
8
10
12
14
Non (counts)
0.2
0.4
0.6
0.8
1
p(Ms + b|Non, Ioff)
Noff = 36, Ton = 1, Toff = 12
Noff = 3, Ton = 1, Toff = 1
Figure 14.4 The probability that model Msþb is true, pðMsþbjNon; IoffÞ, versus the number of
counts in the ON measurement, for two different durations of the background OFF
measurement.
2 We met this issue before in Section 3.8.1, for a completely different spectral line problem.
14.4 Analysis of ON/OFF measurements
385

analysis. The solution is to treat smax as an additional parameter in the problem,
choose a prior for this parameter and marginalize over the parameter. This will
introduce an additional Occam penalty reducing the odds ratio in a way that quanti-
tatively reflects our uncertainties in smax. Depending on the importance of the result,
it may be useful to examine the dependence of the conclusion on the choice of prior
for s, by considering an alternative but reasonable form of prior. One alternative
choice worth considering in this case is a modified Jeffreys of the form
pðsjIÞ ¼ 1=fðs þ aÞ ln½ða þ smaxÞ=ag, where a is a constant. This modified Jeffreys
looks like a uniform prior for s < a and a Jeffreys for s > a.
14.5 Time-varying Poisson rate
So far, we have assumed the Poisson rate, r, is a constant. We now analyze a simple
problem in which r is a function of time.
I 	 ‘‘We want to estimate the half-life, , of a radioactive sample. The sample count
rate is given by
rðtjr0; Þ ¼ r02t=;
(14:25)
where r0 is the count rate at t ¼ 0. Assume a uniform prior for r0, and an independent
Jeffreys prior for .’’
The data, D, are a simulated list of times,3 ftig, for N ¼ 60 measured Geiger counter
clicks, for a radioactive sample with a half-life of 30 s. To make use of the full
resolution of the data, we will work with the individual event times.
D ¼ f1:44; 1:64; 2:55; 2:88; 2:9; 3:27; 4:39; 5:01; 5:08; 5:11; 5:33; 5:4; 5:45;
5:58; 5:79; 6:17; 7:84; 7:86; 8:8; 8:9; 11:71; 11:73; 11:78; 14:88; 14:96;
15:61; 18:95; 19:42; 20:11; 20:28; 21:46; 21:52; 23:62; 24:21; 24:38;
24:39; 25:76; 27:92; 28:92; 29:28; 29:74; 30:04; 31:34; 32:08; 34:62;
35:04; 35:38; 36:43; 36:94; 38:97; 40:66; 41:62; 42:69; 43:02; 43:36;
45:11; 47:38; 49:65; 50:52; 51:22g
From Bayes’ theorem we can write
pðr0; jD; IÞ / pðr0jIÞ pðjIÞpðDjr0; ; IÞ:
(14:26)
The prior ranges’ upper and lower boundaries for r0 and  are assumed to lie well
outside the region of interest defined by the likelihood function. Thus, for our current
parameter estimation problem, we can write
pðjD; IÞ /
Z
r0
dr0
1
 pðDjr0; ; IÞ:
(14:27)
3 See Problem 6 for hints on how to simulate your own data set.
386
Bayesian inference (Poisson sampling)

The likelihood can be calculated as follows: divide the observation period, T, into
small time intervals, t, each containing either one event (counter click) or no event.
We assume that t is sufficiently small that the average rate in the interval t is
approximately equal to the rate at any time within the interval.
From the Poisson distribution, p0ðtÞ, the probability of no event in t is given by
p0ðtÞ ¼ erðtÞt;
(14:28)
and the probability of one event is given by
p1ðtÞ ¼ rðtÞterðtÞt:
(14:29)
If N and M are the number of time intervals in which one event and no events are
detected, respectively, then the likelihood function is given by
pðDjrðtÞ; IÞ ¼
Y
N
i¼1
p1ðtiÞ
Y
M
j¼1
p0ðtjÞ
¼ tN Y
N
i¼1
rðtiÞ
"
#
exp 
X
NþM
j¼1
rðtjÞt
"
#
¼ tN Y
N
i¼1
rðtiÞ
"
#
exp 
Z
T
dt rðtÞ


:
(14:30)
Note: we have replaced the sum of rðtÞt over all the observed intervals by the integral
of the rate over the intervals, with the range of integration T ¼ ðN þ MÞt. The tN
factor in the likelihood cancels with the same factor which appears in the denominator
of Bayes’ theorem, so the result does not depend on the size of t, and is well-behaved
even in the limit where t become infinitesimal.
Now use Equation (14.25) to substitute for rðtÞ in Equation (14.30):
pðDjr0; ; IÞ ¼ tN Y
N
i¼1
r02ti=
"
#
exp 
Z
T
dt r02t=


¼ tNrN
0 2 1

PN
i¼1 ti

	
exp  r0
ln 2 1  2T=


h
i
;
(14:31)
where T is the duration of the time series data.
The marginal posterior probability density for the half-life can be obtained by
substituting Equation (14.31) into Equation (14.27), and then evaluated numerically.4
14.5.
4 Since there are only two parameters, the joint probability distribution can be quickly evaluated at a finite number of
two-dimensional grid points. Each marginal distribution can be obtained by summing the results for grid points along
the other parameter.
14.5 Time-varying Poisson rate
387

What if the rate were to vary with time in some unknown fashion, perhaps
periodically? For an interesting treatment of this class of problem, see Gregory and
Loredo (1992, 1993, and 1996) and Loredo (1992).
14.6 Problems
1. The results of an ON/OFF measurement are Non ¼ 5 counts, Noff ¼ 90 counts,
Ton ¼ 1 s, Toff ¼ 100 s. Plot pðsÞ, the posterior probability of the source rate.
2. Using the data given in Problem 1, compute the probability of attributing i of the
on-source events to the source. Plot a graph of this probability for the range i ¼ 0 to 5.
3. Repeat Problem 2, only this time, compute the probability of attributing j of the
on-source events to the background. Plot a graph of this probability for the range
j ¼ 0 to 5.
4. For the radioactive counter times given in Section 14.5, compute and plot the
marginal posterior PDF for the initial count rate r0.
5. Compute and plot the marginal posterior PDF for the radioactive sample half-life,
based on the first 30 counter times given in Section 14.5.
6. Simulate your own radioactive decay time series (N ¼ 100 count times) for an
initial decay rate of one count per second and a half-life of 40 s. Divide the decay
into 20 bins. For each bin, use Equation (5.62) to generate a list of Poisson time
intervals for a Poisson rate corresponding to the time of the middle of the bin.
Convert the time intervals to a sequence of count times and add the start time of the
corresponding bin. You can use Mathematica’s Select[list,# 1 < bin boundary time &]
command to select out the times from any particular list that are less than the end
time of the corresponding bin. Use ListPlot[] to plot a graph of your time series.
20
40
60
80
100
120
140
Half-life (s )
0
0.005
0.01
0.015
0.02
Probability
Figure 14.5 The marginal posterior for the half-life of a radioactive sample.
388
Bayesian inference (Poisson sampling)

Appendix A
Singular value decomposition
Frequently, the solution of a linear least-squares problem using the normal equations
of Section 10.2.2,
^A ¼ ðGTE1GÞ1GTE1D ¼ Y1GTE1D;
(A:1)
fails because a zero pivot occurs in the matrix calculation because C is singular. If the
matrix is sufficiently close to singular, the answer becomes extremely sensitive to
round-off errors, in which case you typically get fitted A’s with very large amplitudes
that are delicately balanced to almost precisely cancel out. Here is an example of a
nearly singular matrix:
1:0
1:0
1:0
1:0001


:
(A:2)
This arises when the data do not clearly distinguish between two or more of the basis
functions provided.
The solution is to use singular value decomposition (SVD). When some combina-
tion of basis functions is irrelevant to the fit, SVD will drive the amplitudes of these
basis functions down to small values rather than pushing them up to delicately
canceling infinities.
How does SVD work?
First, we need to restate the least-squares problem slightly differently. In least-squares,
we want to minimize
2 ¼
X
i
ðdi  fiÞ2
2
i
¼
X
i
di
i
 fi
i

2
;
(A:3)
where
fiðAÞ ¼
X
M
¼1
Agi:
(A:4)
389

In matrix form, we can write
2 ¼ jX A  bj2;
(A:5)
where X is the design matrix given by
X ¼
g1ðx1Þ
1

gMðx1Þ
1



g1ðxNÞ
N

gMðxNÞ
N
0
@
1
A;
(A:6)
and
b ¼
d1
1
dN
N
0
@
1
A:
(A:7)
The problem is to find A which minimizes Equation (A.5).
Any rectangular matrix can be written in reduced SVD form as follows1 (see any
good linear algebra text for a proof):
X
¼
UT
D
V;
(A:9)
ðN  MÞ
ðN  MÞðM  MÞðM  MÞ
where the columns of U are orthonormal and are the eigenvectors of X XT. The
columns
of
V
are
orthonormal
and
are
the
eigenvectors
of
XTX
and
XTX ¼ GTE1G. The elements of the diagonal matrix, D, are called the singular values
of X. These singular values, !1; !1; . . . ; !M, are the square roots of the non-zero
eigenvalues of both XTX and X XT.
D ¼
!1
0

0
0
!2

0








0
0

!M
0
B
B
B
B
@
1
C
C
C
C
A
(A:10)
The number of singular values is equal to the rank of X.
The three matrices U; D; V can be obtained in Mathematica with the command
fU; D; Vg ¼ SingularValues½X
1 In some texts, Equation (A.9) is written in the form
X ¼ U D VT:
ðA:8Þ
390
Appendix A

In a least-squares problem, the design matrix, X, does not have an inverse because it
is not a square matrix, but we can use SVD to construct a pseudo-inverse, Xþ, which
provides the best solution in a least-squares sense to Equation (A.5) in terms of the
basis functions that the data can distinguish between. We will designate that solution
Aþ, which is given by
Aþ ¼ Xþb:
(A:11)
The pseudo-inverse, in the Mathematica convention, is given by
Xþ ¼ VTD1U ¼ VT diag
1
!




U:
(A:12)
Before using Equation (A.11), it is desirable to investigate the singular values of the
design matrix X. If any singular values ! are close to zero, set 1=! ¼ 0 for that .
This corresponds to throwing away one or more basis functions that the data can not
decide on. The condition number of a matrix is defined by
condition number ¼ maximum eigenvalue
minimum eigenvalue
¼ maximum singular value
minimum singular value

2
:
(A:13)
The matrix becomes ill-conditioned if the reciprocal of its condition number
approaches the floating point accuracy.
The PseudoInverse command in Mathematica allows one to specify a Tolerance
option for throwing away basis functions whose singular values are < Tolerance
multiplied by the maximum singular value. Equation (A.11) becomes
Aþ ¼ PseudoInverse½X; Tolerance > t:b
Note: use of the Tolerance option can lead to strange results when fitting poly-
nomials. This is because the range (scale of changes) of the different basis functions
can be very different, e.g., the x3 will have a much larger range than say the x term. The
different scales of the basis functions make a simple comparison of singular values
difficult. In this case, it is better to rescale x so it lies in the range 0 to 1 or 1 to þ1
before computing the singular values.
Singular value decomposition
391

Appendix B
Discrete Fourier Transforms
B.1 Overview
The operations of convolution, correlation and Fourier analysis play an important role
in data analysis and experiment simulations. These operations on digitally sampled data
are efficiently carried out with the Discrete Fourier Transform (DFT), and in particular
with a fast version of the DFT called the Fast Fourier Transform (FFT). In this section,
we introduce the DFT and FFT and explore their relationship to the analytic Fourier
transform and Fourier series. We investigate Fourier deconvolution of a noisy signal
with an optimal Weiner filter. We also learn how to minimally sample data without
losing any information (Nyquist theorem) and about the aliasing that occurs when a
waveform is sampled at an insufficient rate. Since the DFT is an approximation to the
analytic Fourier transform, we learn how to zero pad a time series to obtain accurate
Fourier amplitudes, and to remove spurious end effects in discrete convolution. Finally,
we explore two commonly used approaches to spectral analysis and how to reduce the
variance of spectral density estimators.
B.2 Orthogonal and orthonormal functions
Before we consider the problem of representing a function in terms of a sum of orthogonal
basis functions, we review the more familiar problem of representing a vector in terms of a
set of orthogonal unit vectors. The vector F can be represented as the vector sum
F ¼ Fx^ix þ Fy^iy þ Fz^iz;
(B:1)
where the ^i’s are unit vectors along 3 mutually perpendicular axes. Because the unit
vectors satisfy the relation ^ix  ^iy ¼ ^iy  ^iz ¼ ^iz  ^ix ¼ 0, they are said to be an orthogonal
set. In addition,
^ix  ^ix ¼ ^iy  ^iy ¼ ^iz  ^iz ¼ 1;
(B:2)
so they are called an orthonormal set. They are not the only orthonormal set which can
be used to represent F. Any orthonormal coordinate system can be used. For example,
in spherical coordinates,
392

F ¼ Fr^ir þ F^i þ F^i:
(B:3)
In summary, we can represent the vector F by
F ¼
X
N
n¼1
Fn^in;
(B:4)
where the orthonormal set of basis vectors satisfies the condition
^im  ^in ¼ m;n ¼ 1
m ¼ n
¼ 0
m 6¼ n:
(B:5)
To find the scalar component along ^im, take the scalar product of ^im with F.
Fm ¼ F  ^im:
(B:6)
In an analogous fashion, we would like to represent a function yðtÞ in terms of an
orthonormal set of basis functions,
yðtÞ ¼
X
N
n¼1
YnnðtÞ:
(B:7)
We need to define the equivalent of the scalar product for use with functions, which
is called the inner product for two functions. It is easy to show that
1
p
Z þp
p
sin mt sin nt dt ¼ m;n:
(B:8)
If this relationship is to be satisfied, then the inner product between two functions
should be defined as
R p
p xðtÞ yðtÞ dt. Thus, if
yðtÞ ¼
X
N
n¼1
Yn nðtÞ ¼
X
N
n¼1
Yn
sin nt
ﬃﬃﬃp
p
;
(B:9)
then the inner product of yðtÞ and mðtÞ is
Z
yðtÞmðtÞdt ¼
X
N
n¼1
Yn
Z þp
p
sin nt
ﬃﬃﬃp
p
sin mt
ﬃﬃﬃp
p
dt
¼
X
N
n¼1
Ynm;n ¼ Ym:
(B:10)
The next question is whether any function can be represented by an orthonormal
series like Equation (B.9). Since all terms on the right side of Equation (B.9) are periodic
in t, with period 2p, their sum will also be periodic. If the original function yðtÞ is periodic
as well, over the same period, then this series representation will be valid for all values
of t. Otherwise, the series will only represent the function yðtÞ in the range p < t < p.
Discrete Fourier Transforms
393

What about the question of completeness? Returning to the vector analogy: in
general, a set of unit vectors is not complete if it is possible to find a vector belonging to
the space which is orthogonal to every vector in the set, i.e., 3 basis vectors required for
3-dimensional space. How many dimensions does our function space have? It is clear
from Equation (B.9) that for values n > N, it is possible to find a function sin nt which
is orthogonal to all members. Furthermore, even if N is infinite, cos nt is orthogonal to
every member of the set for any value of n. A complete set must contain at least an
infinite number of functions of the form sin nt and cos nt. We will say more about
completeness later when we discuss the Nyquist sampling theorem.
Many well-known sets of functions exhibit relationships similar to Equation (B.9).
Such function sets, not sinusoidal and usually not periodic, can be used to form
orthogonal series. In general, the inner product can be defined in the interval
a < t < b as follows:
Z b
a
xðtÞ yðtÞ !ðtÞdt;
(B:11)
where yðtÞ is the complex conjugate of yðtÞ and !ðtÞ is a weighting function. A set of
functions nðtÞ is an orthogonal set over the range a < t < b if
n  m ¼
Z b
a
nðtÞ
mðtÞ!ðtÞdt ¼ kn m;n:
(B:12)
The set is orthonormal if kn = 1 for all n.
Examples of useful orthogonal functions are:
1. 1; cos x; sin x; cos 2x; sin 2x; . . . used in a Fourier series
2. Legendre polynomials
3. Spherical harmonics
4. Bessel functions
5. Chebyshev or Tschebyscheff polynomials
6. Laguerre polynomials
7. Hermite polynomials
B.3 Fourier series and integral transform
In the case of the Fourier series, the limits p to þp correspond to the period of the
function. The limits can be made arbitrary by setting t ¼ 2pt0=T. Then
1
p
Z þp
p
sin nt sin mt dt ¼ 2
T
Z þT=2
T=2
sin ð2pn f0t0Þ sin ð2pm f0t0Þdt0;
(B:13)
where f0 ¼ 1=T.
394
Appendix B

B.3.1 Fourier series
The Fourier series representation of yðtÞ is given by
yðtÞ ¼
X
1
n¼0
½an cos 2pn f0t þ bn sin 2pn f0t:
(B:14)
To find the coefficients an and bn of yðtÞ, compute the inner product of yðtÞ with the
cosine and sine basis functions. This is analogous to finding the component of a vector
in Equation (B.6).
an ¼ 2
T
Z T=2
T=2
yðtÞ cos 2pn f0tdt;
(B:15)
and,
bn ¼ 2
T
Z T=2
T=2
yðtÞ sin 2pn f0tdt;
(B:16)
for n ¼ 0; 1; . . .
Exponential notation
We will rewrite Equation (B.14) using the common exponential notation, where
cos 2pn f0t ¼ 1
2 ðei2pnf0t þ ei2pnf0tÞ
sin 2pn f0t ¼ 1
2i ðei2pnf0t  ei2pnf0tÞ:
Equation (B.14) becomes
yðtÞ ¼ a0 þ 1
2
X
1
n¼1
ðan  ibnÞei2pnf0t þ
X
1
n¼1
ðan þ ibnÞei2pnf0t
"
#
:
(B:17)
To simplify the expression, negative values of n are introduced. Thus, we can rewrite
Equation (B.17) as
yðtÞ ¼ a0 þ 1
2
X
1
n¼1
ðan  ibnÞei2pðnÞf0t þ
X
1
n¼1
ðan þ ibnÞei2pnf0t
"
#
¼ a0 þ 1
2
X
1
n¼1
ðajnj  ibjnjÞei2pnf0t þ
X
1
n¼1
ðan þ ibnÞei2pnf0t
"
#
¼
X
1
n¼1
Ynei2pnf0t;
(B:18)
Discrete Fourier Transforms
395

where
Yn ¼
1
2 ðan þ ibnÞ;
n > 0
a0;
n = 0
1
2 ðajnj  ibjnjÞ;
n < 0.
8
<
:
(B:19)
In Equation (B.18), we expanded yðtÞ in terms of the ei2 pnf0t basis set. Alternatively
we could have expanded it in terms of the ei2pnf0t basis set, in which case we would write
yðtÞ ¼
X
1
n¼1
Y0
nei2pnf0t;
(B:20)
where
Y0
n ¼
1
2 ðan  ibnÞ;
n > 0
a0;
n ¼ 0
1
2 ðajnj þ ibjnjÞ;
n < 0.
8
<
:
(B:21)
Both conventions exist in the literature, but we will use the convention specified by
Equations (B.18) and (B.19) to be consistent with the default definitions for the
Discrete Fourier Transform (discussed in Section B.7) used in Mathematica.
B.3.2 Fourier transform
In the Fourier series, the Fourier frequency components are separated by f0 ¼ 1=T. In
the limit as T ! 1, the Fourier components, Yn, become a continuous function Yð f Þ
where Yð f Þ is called the Fourier transform of yðtÞ.
yðtÞ ¼
Z 1
0
½gð fÞ cos 2pft þ kð fÞ sin 2pftdf:
(B:22)
If we define Yð fÞ by
YðfÞ ¼
1
2 fgð fÞ þ ikð fÞg;
f > 0
gð0Þ;
f = 0
1
2 fgðjfjÞ  ikðjfjÞg;
f < 0,
8
<
:
(B:23)
then Equation (B.22) can be rewritten as
yðtÞ ¼
Z þ1
1
YðfÞei2pftdf
where Yð f Þ ¼
Z þ1
1
yðtÞ ei2pftdt:
(B:24)
Designate Fourier transform pairs by
yðtÞ()Yð f Þ:
(B:25)
Units: If t is measured in seconds, then f is in units of cycles s1 ¼ hertz. If t is
measured in minutes, then f is in cycles per minute. Some common Fourier transform
pairs are illustrated in Figure B.1.
396
Appendix B

Note: we normally associate the analysis of periodic functions such as a square wave
with Fourier series rather than Fourier transforms. We can show that a Fourier
transform reduces to a Fourier series whenever the function being transformed is
periodic.
Example:
Consider the FT of a pulse time waveform
hðtÞ ¼
A;
jtj < T0
A=2;
t ¼ T0
0;
jtj > T0.
8
<
:
(B:26)
T
h (t ) =Σ δ (t–nT )
t
f
1
– T
1
T
1
T
h (t ) = K
t
.....
.....
.....
.....
H (f ) = K δ (f )
f
K
h (t ) = 2 A fo
Sin [2foπt ]
2foπt
t
1
2fo
2fo
fo
1
3
H(f ) = A, | f | < fo
A
2 , | f | = fo
=
=  0, | f | > fo
A
f
–fo
fo
h (t ) = A, | t | < To
A
2 , | t | = To
= 0, | t | > To
A
t
To
–To
H (f ) = 2ATo
2 f πTo
Sin [2f πTo]
f
1
2To
2To
To
1
3
TIME DOMAIN
FREQUENCY DOMAIN
=
∞
n=–∞
1
T
n
T
H (f ) =     Σ δ (f –    )
∞
n=–∞
Figure B.1 Some common Fourier transform pairs.
Discrete Fourier Transforms
397

The value of the function at a discontinuity must be defined to be the mid-value if the
inverse Fourier transform is to hold (Brigham, 1988).
Hð fÞ ¼
Z T0
T0
Aei2pftdt ¼ A
Z T0
T0
cos 2p ftdt þ iA
Z T0
T0
sin 2p ftdt:
(B:27)
The final integral ¼ 0 since the integral is odd:
) Hð fÞ ¼
A
2pf sin 2p ft

T0
T0
¼ 2AT0
sin 2pT0 f
2pT0 f
:
(B:28)
Table B.1 gives the correspondence between important symmetry properties in time
and frequency domains.
B.4 Convolution and correlation
We previously considered some fundamental properties of the FT. However, there
exists a class of FT relationships whose importance outranks those previously con-
sidered. These properties are the convolution and correlation theorems. The import-
ance of the convolution operation in science is discussed in Section B.4.3.
Convolution integral
yðtÞ ¼
Z þ1
1
sðÞhðt  Þd ¼ sðtÞ  hðtÞ
(B:29)
or alternatively,
yðtÞ ¼
Z þ1
1
hðÞ sðt  Þd;
(B:30)
where the symbol  in Equation (B.29) stands for convolution. The convolution
procedure is illustrated graphically in Figure B.2.
Table B.1 Correspondence of symmetry properties in the two domains.
If hðtÞ is . . .
then Hð f Þ is . . .
real
real part even imaginary part odd
imaginary
real part odd imaginary part even
real even and imaginary odd
real
real odd and imaginary even
imaginary
real and even
real and even
real and odd
imaginary and odd
imaginary and even
imaginary and even
imaginary and odd
real and odd
complex and even
complex and even
complex and odd
complex and odd
398
Appendix B

B.4.1 Convolution theorem
The convolution theorem is one of the most powerful tools in modern scientific
analysis. According to the convolution theorem, the FT of the convolution of two
functions is equal to the product of the FT of each function separately.
hðtÞ  sðtÞ()Hð fÞ Sð fÞ:
(B:31)
INTEGRATE
0
0.5
1
1.5
2
t
y (t )
MULTIPLY
SHIFT
FOLD
h (τ)
s (τ)
0
0.5
1
1.5
2
0
0.5
1
1.5
2
τ
τ
0
0.5
1
1.5
2
h (t – τ)
τ
0
0.5
1
1.5
2
τ
0
0.5
1
1.5
2
h (– τ)
τ
Figure B.2 Graphical illustration of convolution.
Discrete Fourier Transforms
399

Proof :
Z þ1
1
yðtÞei2pftdt ¼
Z þ1
1
Z þ1
1
sðÞhðt  Þd


ei2pftdt:
(B:32)
Now interchange the order of integration:
YðfÞ ¼
Z þ1
1
sðÞ
Z þ1
1
hðt  Þei2pftdt


d:
(B:33)
Let r ¼ ðt  Þ. Then,
Z þ1
1
hðt  Þei2pftdt


¼
Z 1
1
hðrÞei2pfðrþÞdr
(B:34)
¼ ei2pfHðfÞ:
(B:35)
Therefore,
YðfÞ ¼ HðfÞ
Z 1
1
sðÞei2pfd ¼ Hð fÞ Sð fÞ:
(B:36)
This relationship allows one the complete freedom to convolve mathematically (or
visually) in the time domain by simple multiplication in the frequency domain. Among
other things, it provides a convenient tool for developing additional FT pairs.
Figure B.3 illustrates the theorem applied to the convolution of a rectangular pulse
of width 2T0 with a bed of nails (an array of uniformly-spaced delta functions).
We can equivalently go from convolution in the frequency domain to multiplication
in the time domain.
hðtÞsðtÞ  ! HðfÞ  SðfÞ:
(B:37)
B.4.2 Correlation theorem
The correlation of two functions sðtÞ and hðtÞ is defined by
Corr ðs; hÞ ¼ zðtÞ ¼
Z 1
1
sðÞhð þ tÞd:
(B:38)
It is useful to compare Equation (B.38) with Equation (B.29) for convolution.
Convolution involves a folding of hðÞ before shifting, while correlation does not.
According to the correlation theorem,
zðtÞ()Hð fÞSð fÞ ¼ Zð fÞ:
(B:39)
Thus, Corr ðs; hÞ()Hð fÞSð fÞ are an FT pair.
Compare with the convolution: sðtÞ  hðtÞ()Sð fÞHð fÞ.
400
Appendix B

Note: if sðtÞ is a real and even function, Sð f Þ is real and Sð f Þ ¼ Sð f Þ. Thus, in this
case, Corr ðs; hÞ ¼ sðtÞ  hðtÞ = convolution.
B.4.3 Importance of convolution in science
The goal of science is to infer how nature works based on measurements or
observations.
Nature )
Apparatus
Measurements
) Observation:
Unfortunately, all measurement apparatus introduces distortions which need to be
understood. Often, the most exciting questions of the day require pushing the meas-
urement equipment to its very limits where the distortions are most extreme. Of
course, some of these distortions can be approximately calculated from theory, like
the diffraction effects of a telescope or microscope, but others need to be measured.
Are there any general principles that help us to understand these distortions that we
can apply to any measurement process? The answer is yes for any linear measurement
h (t ) ∗ s (t )
(e)
t
H (f ) S (f )
(f)
2ATo
T
f
s (t )
t
T
1
(c)
....
....
(CONVOLVE)
S (f  )
(d)
f
....
....
(MULTIPLY)
h (t )
t
A
(a)
CONVOLVE IN TIME DOMAIN
H (f  )
2ATo
(b)
f
MULTIPLY IN FREQUENCY DOMAIN
1
T
1
T

 
Figure B.3 Example of the convolution theorem.
Discrete Fourier Transforms
401

process where the output is linearly related to the input signal, even if the apparatus is
a very complex piece of equipment consisting of many separate parts, e.g., a
radio telescope consisting of one or more parabolic antennas and a room full of
sophisticated electronics. Any linear measurement process corresponds mathemat-
ically to a convolution of the measurement apparatus point spread function with the
signal from nature. The point spread function is the response of the apparatus to an
input signal that is unresolved in the measurement dimension, e.g., a short pulse in
the time dimension. From an understanding of the equipment, it is often possible to
partially correct for these distortions to better approximate the original signal.
Radio astronomy example
The simplest radio telescope consists of a parabolic collecting antenna which focuses,
amplifies, and detects the radiation arriving within a narrow cone of solid angle (two
angular dimensions). Because of diffraction, the sensitivity within the cone may have
several peaks often referred to as the main beam and side lobes. The angular size of the
main beam in radians is  wavelength=telescope diameter. For example, a 100 m
diameter telescope operating at a wavelength of 3 cm has about the same resolving
power as the human eye at optical wavelengths.
The detailed shape of the main beam and side lobes may be very difficult to
calculate, especially when the telescope is operated at very short wavelengths where
irregularities in the telescope surface and gravitational distortions are most important.
Any image of the intensity distribution of the sky (incident radiation), made with this
instrument, will be blurred by this diffraction pattern or point spread function.
Fortunately, the point spread function can be measured provided it is stable. This
can be achieved by observing a strong ‘‘point’’ source of very small angular extent,
much smaller than the main beam of the telescope.
The use of an unresolved ‘‘point’’ source to measure the telescope point spread
function, and the blurring effect the point spread function has on a model extended
source, are illustrated in Figure B.4 for one angular coordinate, . The dashed curve in
the upper left panel shows the response of the telescope as a function of  that we wish
to measure. In this example, it consists of a main beam and a strong secondary side
lobe. The solid curve represents the radio intensity distribution of an unresolved point
source. The source is fixed in position but the telescope response, defined by the
location of the center of the main beam and represented by 0, can be steered. By
scanning the telescope (varying 0) across the point source, we can map out the
telescope point spread function as shown in the lower left panel. One can see that
the response of the telescope to the point source (point spread function) in 0 is the
mirror image of the telescope response in .
Thus, to simulate an observation of an extended source, the model galaxy, we need
to obtain the telescope response in  by folding the measured point spread function in
0 about the main beam axis. Then for each pointing position of the telescope, we
multiply the telescope response in  times the galaxy intensity distribution and
402
Appendix B

integrate. The lower right panel shows the results of such a convolution with our
model galaxy intensity distribution.
The convolution theorem provides what is often a simpler way of computing the
measured galaxy intensity distribution. Just Fourier transform the telescope sensitiv-
ity in  and the galaxy intensity distribution, multiply the two transforms, and then
take the inverse Fourier transform. The inverse of convolution, called deconvolution,
is demonstrated in Section B.10.1.
B.5 Waveform sampling
In many practical situations, we only obtain samples of some continuous function.
How could we go about sampling the continuous voltage function, vðtÞ to obtain a
sample at t ¼ ? One way would be to convert vðtÞ to a frequency fðtÞ ¼ kvðtÞ and
count the number of cycles (N) in some short time interval  to  þ 4T.
–0.25 0
0.25 0.5 0.75
1
1.25 1.5
Telescope pointing position θ0
0.2
0.4
0.6
0.8
1
Intensity
(b) Point Source Response
–0.25 0
0.25 0.5 0.75
1
1.25 1.5
Telescope position θ0
0.2
0.4
0.6
0.8
1
Intensity
(d) Galaxy Convolved with Beam
–0.25 0
0.25 0.5 0.75
1
1.25 1.5
Angular position θ
Angular position θ
0.2
0.4
0.6
0.8
1
Intensity
(a) Telescope Beam + Point Source
–0.25 0
0.25 0.5 0.75
1
1.25 1.5
0.2
0.4
0.6
0.8
1
Intensity
(c) Galaxy and Telescope Beam
Figure B.4 A simulation of the response of a radio telescope to an unresolved ‘‘point’’ source and
an extended source in one angular sky coordinate, . The dashed curve in the upper panels is the
telescope sensitivity as a function of . The solid curve in the upper left represents the intensity
distribution of a point source, and in the right panel, a model galaxy intensity distribution. The
lower panels are the measured telescope output versus 0, the telescope pointing position.
Discrete Fourier Transforms
403

N ¼
Z þ4T

fðtÞdt ¼
Z þ4T

k vðtÞdt:
(B:40)
If sðÞ, the time averaged value of vðtÞ around t ¼ , is the desired sample, then
sðÞ ¼
N
k 4 T ¼
R þ4T

k vðtÞdt
R þ4T

k dt
:
(B:41)
We can generalize this to
sðÞ ¼
R þ1
1 kðt  Þ vðtÞdt
R þ1
1 kðt  Þdt
;
(B:42)
where kðtÞ is some suitable weighting function. One choice of kðtÞ is a square pulse of
width T and height 1=T. In this case,
R þ1
1 kðt  Þdt ¼ 1.
The ideal choice which we can only approach in practice is ! kðtÞ ¼ ðtÞ (the
impulse or Dirac delta function)
ðt  Þ ¼ 0 for
t 6¼ 
and
Z þ1
1
ðt  Þdt ¼ 1:
(B:43)
In most texts, sampling at uniform intervals separated by T is represented by
multiplying the waveform by a set of impulse functions with separation T (often
referred as a bed of nails).
Note: the FT of a bed of nails is another bed of nails such that
4ðtÞ ¼
X
1
n¼1
ðt  nTÞ() 4ðfÞ ¼ 1
T
X
1
n¼1
 f  n
T


;
(B:44)
where the area integral of one nail in the frequency domain ¼ 1=T.
We can use the convolution theorem to illustrate (see Figure B.5) how to determine
the FT of a sampled waveform. The FT of the sampled waveform is then a periodic
function where one period is equal to, within the constant ð1=TÞ, the FT of the
continuous function hðtÞ. Notice that in this situation, we have not lost any informa-
tion about the original continuous hðtÞ. By picking out one period of the transform, we
can reconstruct identically the continuous waveform by the inverse FT.
B.6 Nyquist sampling theorem
Consider what would happen in Figure B.5 if the sampling interval were made larger.
In the frequency domain, the separation ð¼ 1=TÞ between impulse functions of Sð f Þ
would decrease. Because of this decreased spacing of the frequency impulses, their
convolution with the frequency function Hð f Þ results in overlapping waveforms as
illustrated in panel (f) of Figure B.6.
404
Appendix B

In this case, we can no longer recover an undistorted simple period which is
identical with the FT of the continuous function hðtÞ. This distortion of a
sampled waveform is known as aliasing. It arises because the original waveform
was not sampled at a sufficiently high rate. For a given sampling interval, T, the
Nyquist frequency is defined as 1=ð2TÞ. If the waveform that is being sampled
contains frequency components above the Nyquist frequency, they will give rise
to aliasing.
Examination of Figure B.6(b) and (d) indicates that convolution overlap will occur
until the separation of the impulses of SðfÞ is increased to 1=T ¼ 2fc, where fc is the
highest frequency. Therefore, the sampling interval T must be  1=ð2fcÞ.
The Nyquist sampling theorem states that if the Fourier transform of a function hðtÞ
is zero for all jfj  fc, then the continuous function hðtÞ can be uniquely determined
from a knowledge of its sampled values at intervals of T  1=ð2fcÞ. If HðfÞ ¼ 0 for
jfj  fc then we say that HðfÞ is band-limited. In practice, it is a good idea to use a
smaller sample interval T  1=ð4fcÞ.
Conversely, if hðtÞ is time-limited, that is hðtÞ ¼ 0 for jtj  Tc then hðtÞ can be
uniquely reconstructed from samples of HðfÞ at intervals 4f ¼ 1=ð2TcÞ.
(e)
t
H (f ) ∗ S (f )
(f)
f
1
(c)
t
T
....
....
(MULTIPLY)
f
(d)
....
....
(CONVOLVE)
MULTIPLY IN TIME DOMAIN
(a)
t
1
(b)
f
fc
fc
CONVOLVE IN FREQUENCY DOMAIN
1
T—
–
1
T—
1
T—
1
T—
h (t ) s (t )
s (t )
 S (f )
h (t )
H (f )
Figure B.5 The Fourier transform of a sampled waveform illustrated using multiplication in the
time domain and convolution in the frequency domain.
Discrete Fourier Transforms
405

B.6.1 Astronomy example
In this example, taken from radio astronomy, we are interested in determining the
intensity distribution, bð; Þ of a galaxy with the Very Large Array (VLA). The
position of any point in the sky is specified by the two spherical coordinates ; .
The VLA is an aperture synthesis radio telescope consisting of twenty-seven 25 m
diameter dish antennas which can be moved along railway tracks to achieve a variety
of relative spacings up to a maximum of 21 km. By this means, it can make images with
an angular resolution equivalent to that of a telescope with a 21 km diameter aperture
(0.08 arcseconds at  ¼ 1 cm). The signal from each antenna is cross-correlated
separately with the signals from all other antennas while all antennas track the same
source. It can be shown that each cross-correlation is directly proportional to a two-
dimensional Fourier component of bð; Þ. If there are N antennas, there are
NðN  1Þ=2 correlation pairs. The VLA records 27ð271Þ=2 ¼ 351 Fourier compon-
ents simultaneously.
The FT of bð; Þ is equal to Bðu; vÞ. The quantities u and v are called spatial
frequencies and have units ¼ 1= where  is in radians (dimensionless). Let u ¼ x=
and v ¼ y= be the components of the projected separation of any pair of antennas on
(e)
t
1
T
(f) 
f
s (t )
1
 (c) 
t
T
....
....
(MULTIPLY)
S (f )
f
1    
T
(d)
....
....
(CONVOLVE)
h (t )
(a)
t
MULTIPLY IN TIME DOMAIN
H (f )
1
(b)
f
fc
fc
CONVOLVE IN FREQUENCY DOMAIN
—
1
T
1
T—
—
–
—
H (f ) ∗ S (f )
h (t ) s (t )
Figure B.6 When the waveform is sampled at an insufficient rate, overlapping (referred to as
aliasing) occurs in the transform domain.
406
Appendix B

a plane perpendicular to the line of sight to the distant radio source in units of the
observing wavelength.
In practice, one wants to measure the minimum number of Fourier components
necessary to reconstruct bð; Þ, i.e., move the dish antennas along the railway tracks
as little as possible. This is where the sampling theorem comes in handy.
If the galaxy is known to have a finite angular width 4 ¼ 4 ¼ 4 , then from the
sampling theorem, this means we only need to sample in u and v at intervals of
4 u ¼ 4v 
1
4 :
(B:45)
Note: in this problem, 4 is the equivalent to 2fc in Figure B.6 in the time frequency
problem.
Thus, if 4 	 10 arcseconds ¼ 4:8 
 105 radians,
4 u ¼ 4x
 ¼ 20 833 ¼ 4v ¼ 4y
 :
(B:46)
If the wavelength of observation,  ¼ 6 cm, then 4x ¼ 1:25 km, which means that
the increment in antenna spacing required for complete reconstruction of bð; Þ is
1.25 km.
Since the antennas are 25 m in diameter, they could in principle be spaced at intervals
of  25 m and at that increment in spacing, we could obtain all the Fourier components
(coefficients) necessary to reconstruct (synthesize) the image of a source of angular extent
 8:3 arcmin. Because each antenna will shadow its neighbor at very close spacings, the
limiting angular size that can be completely reconstructed is smaller than this.
B.7 Discrete Fourier Transform
B.7.1 Graphical development
The approach here is to develop the Discrete FT (abbreviated DFT) from a graphical
derivation based on the waveform sampling and the convolution theorem, following
the treatment given by Brigham (1988). The steps in this derivation are illustrated in
Figure B.7.
Panel (a) of Figure B.7 shows the continuous FT pair hðtÞ and HðfÞ. To obtain
discrete samples, we multiply hðtÞ by the bed of nails shown in the time domain which
corresponds to convolving in the f domain, with the result shown in (c). Note: the
effect of sampling is to create a periodic version of HðfÞ. To represent the fact that we
only want a finite number of samples, we multiply in the time domain by the
rectangular window function of width T0 of panel (d), which corresponds to convolv-
ing with its frequency transform. This has side lobes, which produce an undesirable
ripple in our transform as seen in panel (e). One way to reduce the ripple is to use a
tapered window function instead of a rectangle.
Discrete Fourier Transforms
407

Finally, to manipulate a finite number of samples in the frequency domain, we
multiply in the frequency domain by a bed of nails at a frequency interval
f ¼ 1=T0 as shown in panels (f) and (g). After taking the DFT of our N samples
of hðtÞ, we obtain an N-sample approximation of the HðfÞ as shown in panel (g).
Note 1: sampling in the frequency domain results in a periodic version of hðtÞ in the
time domain. It is very important to be aware of this periodic property when executing
convolution operations using the DFT.
h (t )
(g)
t
N
N
H (f )
f
s2(t )
S2(t )
(f)
t
– To 
To
f
...
...
(e) 
t
f
w (t )
(d)
t
f
 
 
 
(c)
t
H(f ) ∗ S1 (f )
H (f ) ∗ S1(f ) ∗ W (f )
 
f
T
 
(b)
 
t
....
....
 
f
(a) 
t
f
1
T
–−
1
T−
1
2T
– —
1
2T
—
1
2T
– —
1
2T
—
1
To
– —
—
1
To
1
To
—
W (f )
h (t ) s (t ) w (t )
To
2
—
To
2
– —
To
2
—
To
2
—
s1(t )
S1f )
h (t )
H (f )
h(t ) s(t )
~
~
Figure B.7 Graphical development of the Discrete Fourier Transform. See discussion in Section
B.7.1.
408
Appendix B

Note 2: the location of the rectangular window function wðtÞ is very important. Its
width T0 equals NT, where T is the sample interval. If wðtÞ had been located so that a
sample value coincided with each end-point, the rectangular function would be
N þ 1 sample values, and the convolution of hðtÞsðtÞwðtÞ with the impulses spaced
at intervals of T0 as shown in panels (f) and (g) would result in time domain aliasing.
B.7.2 Mathematical development of the DFT
We now estimate the FT of a function from a finite number of samples. Suppose we
have N equally spaced samples hk 	 hðkTÞ at an interval of T seconds, where
k ¼ 0; 1; 2; . . . ; N  1. From the discussion of the Nyquist sampling theorem, for a
sample interval T, we can only obtain useful frequency information for jfj < fc. We
seek estimates at the discrete values
fn 	 n
NT ;
n ¼  N
2 ; . . . ; N
2 ;
(B:47)
where the upper and lower limits are fc. Counting n ¼ 0, this range corresponds to
N þ 1 values of frequency, but only N values will be unique.
HðfnÞ ¼
Z þ1
1
hðtÞ ei2pfntdt

X
N1
k¼0
hðkTÞ ei2pfnkTT
¼ T
X
N1
k¼0
hk ei2pnfkT
¼ T
X
N1
k¼0
hk ei2pnk=N
¼ THðnfÞ ¼ TH
n
NT


¼ THn;
(B:48)
where T ¼ the sample interval and hk for k ¼ 0; . . . ; N  1, are the sample values of
the truncated hðtÞ waveform.
Hn is defined as the DFT of hk and given by
Hn ¼
X
N1
k¼0
hk ei2pnk=N:
(B:49)
Defined in this way, Hn does not depend on the sample interval T.
The relationship between the DFT of a set of samples of a continuous function hðtÞ
at interval T, and the continuous FT of hðtÞ can be written as
HðfnÞ ¼ THn:
(B:50)
Discrete Fourier Transforms
409

We can show that since Equation (B.49) for Hn is periodic, there are only N distinct
complex values computable. To show this, let n ¼ r þ N, where r is an arbitrary
integer from 0 to N  1.
Hn ¼ H
n
NT


¼
X
N1
k¼0
hk ei2pkðrþNÞ=N
¼
X
N1
k¼0
hk ei2pkr=N ei2pk
¼
X
N1
k¼0
hk ei2pkr=N
¼ H
r
NT


¼ Hr;
(B:51)
since ei2pk ¼ cosð2pkÞ þ i sinð2pkÞ ¼ 1 for k an integer.
Until now, we have assumed that the index n varies from N=2 to N=2. Since Hn
is periodic, it follows that Hn ¼ HNn so HN=2 ¼ HN=2 and thus we only need N
values of n. It is customary to let n vary from 0 to N  1. Then n ¼ 0 corresponds to the
DFT at zero frequency and n ¼ N=2 to the value at fc. Values of n between N=2 þ 1
and N  1 correspond to values of the DFT for negative frequencies from
–ðN=2  1Þ; ðN=2  2Þ; . . . ; 1. Thus, to display the DFT in the same way as an
analytic transform is displayed (f on the left and þf on the right), it is necessary to
reorganize the DFT frequency values.
B.7.3 Inverse DFT
Again, our starting point is the integral FT:
hðkTÞ ¼ hk ¼
Z þ1
1
HðfÞ ei2pfkTdf
hðkTÞ 
X
N1
n¼0
HðfnÞ ei2pfnkTf:
(B:52)
Now substitute HðfnÞ ¼ THn and f ¼ ð1=NTÞ:
hk ¼
X
N1
n¼0
THn ei2pfnkTf
hk ¼ 1
N
X
N1
n¼0
Hn ei2pfnkT:
(B:53)
Note: the definition of DFT pair given in Mathematica is the more symmetrical
form
410
Appendix B

Hn ¼
1ﬃﬃﬃﬃ
N
p
X
N1
k¼0
hk ei2pnk=N
(B:54)
hk ¼
1ﬃﬃﬃﬃ
N
p
X
N1
n¼0
Hn ei2pfnkT:
(B:55)
Box B.1
The Fourier transform of a list of real or complex numbers,
represented by ui, is given by the Mathematica command
(Fourier [{u1; u2;    ; un}].)
The inverse Fourier transform is given by
InverseFourier [{u1; u2;    ; un}].
Mathematica can find Fourier transforms for data in any number of dimensions.
In n dimensions, the data is specified by a list nested n levels deep. For two
dimensions, often used in image processing, the command is
Fourier [{{u11; u12;    ; u1n}; {u21; u22;    ; u2n};    }].
An example of the use of the FFT in the convolution and deconvolution of an
image is given in the accompanying Mathematica tutorial.
B.8 Applying the DFT
We have already developed the relationship between the discrete and continuous
Fourier transforms. Here, we explore the mechanics of applying the DFT to the
computation of Fourier transforms and Fourier series. The primary concern is one
of correctly interpreting these results.
B.8.1 DFT as an approximate Fourier transform
To illustrate the application of the DFT to the computation of Fourier transforms,
consider Figure B.8. Figure B.8(a) shows the real function fðtÞ, given by
fðtÞ ¼
0;
t < 0
et;
t  0.

(B:56)
We wish to compute by means of the DFT an approximation to the Fourier transform
of this function.
The first step in applying the discrete transform is to choose the number of samples
N and the sample interval T. For T ¼ 0:25, we show the samples of fðtÞ within the
dashed rectangular window function in Figure B.8(b). Note: the start of the window
Discrete Fourier Transforms
411

function occurs T=2 ahead of the first sample so that there are only N samples within
the window, as discussed in Section B.7.1. Also, the value of the function at a
discontinuity must be defined to be the mid-value if the inverse Fourier transform is
to hold. Since the DFT assumes the function is periodic, we set this value equal to the
average of the function value at both ends to avoid the discontinuity at t ¼ 0.
We next compute the Fourier transform using the DFT approximation
HðfnÞ  THn ¼ TH
n
NT


;
(B:57)
5
10
15
20
25
30
Frequency sample n
–0.4
–0.2
0
0.2
0.4
DFT (Imaginary)
(d)
Nyquist f
Positive f
Negative f
10
20
30
40
50
60
Frequency sample n
–0.4
–0.2
0
0.2
0.4
DFT (Imaginary)
(e)
T  = 0.125
N  = 64
Nyquist f
Positive f
Negative f
0
10
20
30
Sample number k
0.2
0.4
0.6
0.8
1
Amplitude
(b)
5
10
15
20
25
30
Frequency sample n
0.2
0.4
0.6
0.8
1
DFT (Real)
(c)
T  = 0.25
N  = 32
Nyquist f
Positive f
Negative f
–5
0
5
10
15
20
t
0.2
0.4
0.6
0.8
1
Amplitude
f (t ) 
(a)
T  = 0.25
N  = 32
T  = 0.25
N  = 32
Figure B.8 A 32-point DFT of the function fðtÞ. The function itself is plotted in panel (a). Panel
(b) illustrates the location of the 32 time samples within the rectangular window function
(dashed box). Panel (c) compares the real part of the DFT to the continuous Fourier transform
shown by the solid curve. The imaginary part of the DFT is compared to the continuous case
(solid curve) in panel (d). Panel (e) illustrates the improved agreement obtained by halving the
sample interval in time and doubling the number of samples.
412
Appendix B

where
H
n
NT


¼
X
N1
k¼0
ekT


ei2 pnk=N; n ¼ 0; 1; . . . ; N  1:
(B:58)
Note: the scale factor T in Equation (B.57), is required to produce equivalence
between the continuous and discrete transforms. These results are shown in panels (c)
and (d) of Figure B.8 In Figure B.8(c), we show the real part of the Fourier transform
as computed by Equation (B.58). The index n ¼ 0 corresponds to zero frequency or
the DC term, which is proportional to the data average. Note: the real part of the
discrete transform is symmetrical about n ¼ N=2, the Nyquist frequency sample. The
real part of a Fourier transform of a real function is even and the imaginary part of the
transform is odd. In Figure B.8(b), the results for the real part for n > N=2 are simply
negative frequency results. For T ¼ 0:25 s, the physical frequency associated with
frequency sample n ¼ N=2 is 1=ð2TÞ ¼ 2 Hz. Sample ðN=2Þ þ 1 ¼ 17 corresponds to
a negative frequency ¼ ðN=2  1Þ=ðNTÞ ¼ 1:875 Hz, and sample n ¼ 31 corres-
ponds to the frequency ¼ 1=ðNTÞ ¼ 0:125 Hz.
The conventional method of displaying results of the discrete Fourier transform is
to graph the results of Equation (B.58) as a function of the parameter n. As long as we
remember that those results for n > N=2 actually relate to negative frequency results,
then we should encounter no interpretation problems.
In panel (d) of Figure B.8, we illustrate the imaginary part of the Fourier transform
and the discrete transform. As shown, the discrete transform approximates rather
poorly the continuous transform for the higher frequencies. To reduce this error, it is
necessary to decrease the sample interval T and increase N. Panel (e) shows the
improved agreement obtained by halving T and doubling N to 64 samples. We note
that the imaginary function is odd with respect to n ¼ N=2. Again, those results for
n > N=2 are to be interpreted as negative frequency results.
In summary, applying the discrete Fourier transform to the computation of the
Fourier transform only requires that we exercise care in the choice of T and N and
interpret the results correctly. For a worked example of the DFT using Mathematica,
see the section entitled ‘‘Exercise on DFT, Zero Padding and Nyquist Sampling,’’ in
the accompanying Mathematica tutorial.
B.8.2 Inverse discrete Fourier transform
Assume that we are given the continuous real and imaginary frequency functions
considered in the previous discussion and that we wish to determine the corresponding
time function by means of the inverse discrete Fourier transform
hðkTÞ ¼ 4f
X
N1
n¼0
½Rðn4fÞ þ iIðn4fÞei2pnk=N
for k ¼ 0; 1; . . . ; N  1;
(B:59)
Discrete Fourier Transforms
413

where 4f is the sample interval in frequency. Assume N ¼ 32 and 4f ¼ 1=8.
Since we know that RðfÞ, the real part of the complex frequency function, must be
an even function, then we fold Rð fÞ about the frequency f ¼ 2:0 Hz, which corres-
ponds to the sample point n ¼ N=2. As shown in Figure B.9(a), we simply sample the
frequency function up to the point n ¼ N=2 and then fold these values about n ¼ N=2
to obtain the remaining samples.
In Figure B.9(b), we illustrate the method of determining the N samples of the
imaginary part of the frequency function. Because the imaginary frequency function is
odd, we must not only fold about the sample value N=2 but also flip the results. To
preserve symmetry, we set the sample at n ¼ N=2 to zero.
Computation of Equation (B.59) with the sampled function illustrated in Figures
B.9(a) and (b) yields the inverse discrete Fourier transform. The result is a complex
function whose imaginary part is approximately zero and whose real part is as shown
in panel (c). We note that at k ¼ 0, the result is approximately equal to the correct mid-
value and reasonable agreement is obtained for all but the results for k large.
Improvement can be obtained by reducing 4f and increasing N.
The key to using the discrete inverse Fourier transform for obtaining an approxi-
mation to continuous results is to specify the sampled frequency functions correctly.
5
10
15
20
25
30
Sample number k
0
0.2
0.4
0.6
0.8
1
Amplitude
(c)
T = 0.25
N = 32
5
10
15
20
25
30
Frequency sample n
0.2
0.4
0.6
0.8
1
DFT (Real)
(a)
Fold about
Positive f
Negative f
5
10
15
20
25
30
Frequency sample n
–0.4
–0.2
0
0.2
0.4
DFT (Imaginary)
(b)
Fold about
n = N/ 2
n = N /  2
Nyquist f
Positive f
Negative f
T = 0.25
N = 32
Figure B.9 Panels (a) and (b) illustrate the sampling of the real and imaginary parts of the
continuous Fourier transform in readiness for computing the inverse DFT which is shown in
panel (c).
414
Appendix B

Figures B.9(a) and (b) illustrate this correct method. One should observe the scale
factor 4f which was required to give a correct approximation to continuous inverse
Fourier transform results.
B.9 The Fast Fourier Transform
The FFT (Cooley and Tukey, 1965) is a very efficient method of implementing the
DFT that removes certain redundancies in the computation and greatly speeds up the
calculation of the DFT. Consider the DFT
AðnÞ ¼
X
N1
k¼0
xðkÞei2pnk=N
ðn ¼ 0; 1; . . . ; N  1Þ;
(B:60)
where we have replaced kT by k and n=NT by n for convenience of notation.
Let w ¼ ei2p=N. Equation (B.60) can be written in matrix form:
Að0Þ
Að1Þ
Að2Þ
Að3Þ
2
6664
3
7775
¼
¼
¼
¼
w0
w0
w0
w0
w0
w1
w2
w3
w0
w2
w4
w6
w0
w3
w6
w9
2
66664
3
77775
xð1Þ
xð2Þ
xð3Þ
xð4Þ
2
6664
3
7775
(B:61)
or AðnÞ ¼ wnk xðkÞ:
(B:62)
It is clear from the matrix representation that since w and possibly xðkÞ are complex,
then N2 complex multiplications and ðNÞðN  1Þ complex additions are necessary to
perform the required matrix computation. The FFT owes its success to the fact that
the algorithm reduces the number of multiplications from N2 to N log2 N.
For example, if N ¼ 1024 ¼ 210
N2 ¼ 220 operations in DFT
N log2 N ¼ 210
10 operations in FFT.
This amounts to a factor of 100 reduction in computer time and round-off errors are
also reduced.
How does it work?
The FFT takes an N-point transform and splits it into two N=2-point transforms. This
is already a saving, since 2ðN=2Þ2 < N2. The N=2-point transforms are not computed,
but each split into two N=4-point transforms. It takes log2 N of these splittings, so that
generating the N-point transform takes a total of approximately N log2 N operations
rather than N2.
The mathematics involves a splitting of the data set xðkÞ into odd and even labeled
points, yðkÞ and zðkÞ.
Discrete Fourier Transforms
415

Let yðkÞ ¼ xð2kÞ
for
k ¼ 0; 1; . . . ; N=2  1
zðkÞ ¼ xð2k þ 1Þ:
(B:63)
Equation (B.60) can be rewritten as:
AðnÞ ¼
X
N=21
k¼0
yðkÞei4pnk=N þ zðkÞei2pnð2kþ1Þ=N
n
o
¼
X
N=21
k¼0
yðkÞei4pnk=N þ ei2pn=N X
N=21
k¼0
zðkÞei4pnk=N:
(B:64)
This will still generate the whole set AðnÞ if n is allowed to vary over the full range
(0  n  N  1). First, let n vary over (0  n  N=2  1). Then
AðnÞ ¼ BðnÞ þ CðnÞwn ðvalid for 0  n  N=2  1Þ;
(B:65)
where
BðnÞ ¼
X
N=21
k¼0
yðkÞw2nk
and
CðnÞ ¼
X
N=21
k¼0
zðkÞw2nk
for n ¼ 0; . . . ; N
2  1:
(B:66)
But since BðnÞ and CðnÞ are periodic in the half-interval, generating AðnÞ for
the second half may be done without further computing using the same BðnÞ and
CðnÞ:
A n þ N
2
	

¼ BðnÞ þ CðnÞwnwN=2
¼ BðnÞ  CðnÞwn
ð0  n  N=2  1Þ;
(B:67)
where
wN=2 ¼ eip ¼ cos p ¼ 1:
(B:68)
The work of computing an N-point transform AðnÞ has been reduced to computing
two N=2 point transforms BðnÞ and CðnÞ and appropriate multiplicative phase factors
wn. Each of these sub-sequences yðkÞ and zðkÞ can be further subdivided with each step
involving a further reduction in operations. These reductions can be carried out as
long as the original sequence is a power of 2.
Consider n ¼ 8 ¼ 23. In 3 divisions we go from 1 
 8, to 2 
 4, to 4 
 2, to 8 
 1.
Note: the DFT of one term is simply the term itself,
i:e: Að0Þ ¼
X
k¼0
xðkÞei2pkn=N ¼ xð0Þ;
for
n ¼ 0:
(B:69)
In the above we have assumed N ¼ power of 2. (2 is called the radix ¼ r). One can
use other values for the radix, e.g., N ¼ 42
416
Appendix B

Speed enhancement: ’ N logr N
N2
:
In addition to the splitting into sub-sequences, the FFT also makes use of period-
icities in the exponential term wnk to eliminate redundant operations.1
wnk ¼ wnk mod N
(B:70)
e.g., if N ¼ 4; n ¼ 2 and k ¼ 3, then
wnk ¼ w6 ¼ exp
i2p
4
	

ð6Þ


¼ expði3pÞ
¼ expðipÞ¼exp
i2p
4
	

ð2Þ


¼ w2
w2 ¼  w0:
(B:71)
Note: the FFT is not an approximation but a method of computing which reduces
the work by recognizing symmetries and by not repeating redundant operations.
B.10 Discrete convolution and correlation
One of the most common uses of the FFT is for computing convolutions and
correlations of two time functions. Discrete convolution can be written as
sðkTÞ ¼
X
N1
i¼0
hðiTÞr½ðk  iÞT ¼ hðkTÞ  rðkTÞ:
(B:72)
According to the Discrete Convolution Theorem,
X
N1
i¼0
hðiTÞr½ðk  iÞT () H
n
NT


R
n
NT


:
(B:73)
Note: the discrete convolution theorem assumes that hðkTÞ and rðkTÞ are periodic
since the DFT is only defined for periodic functions of time. Usually, one is interested
in convolving non-periodic functions. This can be accomplished with the DFT by the
use of zero padding which is discussed in the next section. Reiterating, discrete
convolution is only a special case of continuous convolution; discrete convolution
assumes both functions repeat outside the sampling window.
1 For example,
I mod m ¼ I  Int
I
m
	 

 m
6 mod 4 ¼ 6  Int 6
4
	 

 4 ¼ 2
Discrete Fourier Transforms
417

To efficiently compute the discrete convolution:
1. Use an FFT algorithm to compute RðnÞ and HðnÞ.
2. Multiply the two transforms together, remembering that the transforms consist of complex
numbers.
3. Then use the FFT to inverse transform the product.
4. The answer is the desired convolution hðkÞ  rðkÞ.
If both time functions are real (generally so) both of their transforms can be taken
simultaneously. For details see Press (1992).
What about deconvolution? One is usually more interested in the signal hðkTÞ before
it is smeared by the instrumental response. Deconvolution is the process of undoing
the smearing of the data, due to the effect of a known response function.
Deconvolution in the frequency domain consists of dividing the transform of the
convolution by RðnÞ, e.g.,
HðnÞ ¼ SðnÞ
RðnÞ ;
(B:74)
and then transforming back to obtain hðkÞ.
This procedure can go wrong mathematically if RðnÞ is zero for some value of n, so
that we can’t divide by it. This indicates that the original convolution has truly lost all
information at that one frequency so that reconstruction of that component is not
possible. Apart from this mathematical problem, the process is generally very sensitive
to noise in the input data and to the accuracy to which rðkÞ is known. This is the
subject of the next section.
B.10.1 Deconvolving a noisy signal
We already know how to deconvolve the effects of the response function, rðkÞ (short
for rðkTÞ), of the measurement device, in the absence of noise. We transform the
measured output, sðkÞ, and the response, rðkÞ, to the frequency domain yielding SðnÞ
(short for SðnfÞ) and RðnÞ. The transform, HðnÞ, of the desired signal, hðkÞ, is given
by Equation (B.74).
Even without additive noise, this can fail because for some n, RðnÞ may equal 0. The
solution in this case is
HðnÞ ¼
SðnÞ
ðRðnÞ þ Þ ;
(B:75)
where  is very small compared to the maximum value of RðnÞ and =RðnÞ > the
machine precision.
Panel (a) in Figure B.10 shows our earlier result (see Figure B.4) of convolving the
image of a galaxy with the response (beam pattern) of a radio telescope. Panel (b)
418
Appendix B

shows the deconvolved version assuming perfect knowledge of RðnÞ and a value of
 ¼ 108. In practice, we will only be able to determine RðnÞ to a certain accuracy
which will limit the accuracy of the deconvolution. In panel (c), we have added
independent Gaussian noise to (a), and panel (d) shows the best reconstruction
obtained by varying the size of , which occurs for an   0:15. We now investigate
–0.25 0 0.25 0.5 0.75 1 1.25 1.5
0.2
0.4
0.6
0.8
1
Intensity
(e) Deconvolved (Weiner filter)
–0.25 0 0.25 0.5 0.75 1 1.25 1.5
Telescope position θ0
Telescope position θ0
Telescope position θ0
Telescope position θ0
Telescope position θ0
0.2
0.4
0.6
0.8
1
Intensity
(c) Convolved Galaxy + Noise
–0.25 0 0.25 0.5 0.75 1 1.25 1.5
0.2
0.4
0.6
0.8
1
Intensity
(d) Deconvolved Galaxy
–0.25 0 0.25 0.5 0.75 1 1.25 1.5
0.2
0.4
0.6
0.8
1
Intensity
(a) Galaxy Convolved with Beam
–0.25 0 0.25 0.5 0.75 1 1.25 1.5
0.2
0.4
0.6
0.8
1
Intensity
(b) Deconvolved Galaxy
Figure B.10 Panel (a) shows the earlier result (see Figure (B.4)) of convolving a model galaxy
with the point spread function of a radio telescope. Panel (b) shows the deconvolved galaxy
image. Panel (c) is the same as (a) but with added Gaussian noise. Panel (d) is the best
deconvolved image without any filtering of noise. Panel (e) shows the result of deconvolution
using an optimal Weiner filter.
Discrete Fourier Transforms
419

the use of an optimal Weiner filter to improve upon the reconstruction when noise is
present.
B.10.2 Deconvolution with an optimal Weiner filter
If additive noise is present, the output from the measurement system is now cðkÞ, where
cðkÞ ¼ sðkÞ þ nðkÞ:
(B:76)
The task is to find the optimum filter ðkÞ or ðnÞ, which, when applied to the CðnÞ, the
transform of the measured signal cðkÞ, and then divided by RðnÞ, produces an output
~HðnÞ, that is closest to HðnÞ in a least-squares sense. This translates to the equation
X
n
½SðnÞ þ NðnÞ ðnÞ
RðnÞ
 SðnÞ
RðnÞ


2
¼
X
n
RðnÞ
j
j2 SðnÞ
j
j2 1  ðnÞ
j
j2þ NðnÞ
j
j2 ðnÞ
j
j2
h
i
¼ minimum:
(B:77)
If the signal SðnÞ and noise NðnÞ are uncorrelated, their cross product when summed
over n can be ignored. Equation (B.77) will be a minimum if and only if the sum is
minimized with respect to ðnÞ at every value of n. Differentiating with respect to ,
and setting the result equal to zero gives
ðnÞ ¼
SðnÞ
j
j2
SðnÞ
j
j2 þ NðnÞ
j
j2 :
(B:78)
The solution contains SðnÞ and NðnÞ but not the CðnÞ, the transform of the measured
quantity cðkÞ. We happen to know SðnÞ and NðnÞ because we are working with a
simulation. In general, we only know CðnÞ, so we estimate SðnÞ and NðnÞ in the
following way: Figure B.11 shows the log of CðnÞ
j
j2; SðnÞ
j
j2 and NðnÞ
j
j2 in panels
(a), (b), (c), respectively. For small n, CðnÞ
j
j2 has the same shape as SðnÞ
j
j2, while at
large n, it looks like the noise spectrum. If we only had CðnÞ
j
j2, we could estimate
SðnÞ
j
j2 by extrapolating the spectrum at high values of n to zero. Similarly, we can
estimate the NðnÞ
j
j2 by extrapolating back into the signal region. Panel (d) shows the
resulting optimal filter  given by Equation (B.78). Where SðnÞ
j
j2  NðnÞ
j
j2, ðnÞ ¼ 1
and when the noise spectrum dominates, ðnÞ  0.
Panel (e) of Figure (B.10) shows the reconstruction ~HðnÞ obtained using Equation
(B.79):
~HðnÞ ¼ CðnÞðnÞ
RðnÞ
:
(B:79)
We investigate other approaches to image reconstruction in Chapter 8.
420
Appendix B

B.10.3 Treatment of end effects by zero padding
Since the discrete convolution theorem assumes that the response function is periodic,
it falsely pollutes some of the initial channels with data from the far end because of the
wrapped-around response arising from the assumed periodic nature of the response
function, hðÞ. Although the convolution is carried out by multiplying the Fast
Fourier Transforms of hðÞ and xðÞ and then inverse transforming back to the
time domain, the polluting effect of the wrap-around is best illustrated by analyzing
the situation completely in the time domain. Figure B.12 illustrates the convolution of
xðÞ, shown in panel (b), by an exponential decaying response function shown in panel
(a). First, the response function is folded about  ¼ 0, causing it to disappear from the
left of panel (c). Since the DFT assumes that hðÞ is periodic, a wrap-around copy of
hðÞ appears at the right of the panel. To compute the convolution at t, we shift the
folded response to the right by t, multiply hðt  Þ and xðÞ and integrate. Panel (e)
shows the resulting polluted convolution.
To avoid polluting the initial samples, we add a buffer zone of zeros at the far end of
the data stream. The width of this zero padding is equal to the maximum wrap-around
of the response function (see Figure B.13). Note: if we increase N for the data stream,
we must also add zeros to the response to make up the same number of samples. The
wrap-around response shown in panels (c) and (d) is multiplied by zeros and so does
not pollute the convolution as shown in panel (e).
50
100
150
200
250
Frequency channel
0.0001
0.001
0.01
0.1
1
(c)
50
100
150
200
250
Frequency channel
0.0001
0.001
0.01
0.1
1
Log Φ (n) 
(d)
50
100
150
200
250
Frequency channel
0.0001
0.001
0.01
0.1
1
Log C (n)
2
Log S (n)
2
Log N (n)
2
(a)
50
100
150
200
250
Frequency channel
0.0001
0.001
0.01
0.1
1
(b)
Figure B.11 The figure shows the log of CðnÞ
j
j2, SðnÞ
j
j2 and NðnÞ
j
j2 in panels (a), (b), (c),
respectively. Panel (d) shows the optimal Weiner filter.
Discrete Fourier Transforms
421

A Mathematica example of zero padding in the convolution of a two-dimensional
image is given in the accompanying Mathematica tutorial.
B.11 Accurate amplitudes by zero padding
The FFT of hðkÞ produces a spectrum HðnÞ in which any intrinsically narrow
spectral feature is broadened by convolution with the Fourier transform of the
window function. For a rectangular window, this usually results in only two
samples to define a spectral peak in HðnÞ and deductions about the true amplitude
of the peak are usually underestimated unless by chance one of these samples lies
at the center of the peak. This situation is illustrated in Figure B.14. Panel (a)
shows 12 samples of a sine wave taken within a rectangular window function
indicated by the dashed lines. The actual samples are represented by the vertical
solid lines. In panel (b), the DFT (vertical lines) is compared to the analytic
Fourier transform of the windowed continuous sine wave. In this particular
0.2
0.4
0.6
0.8
1
τ
τ
τ
Wrap around
response
0.2
0.4
0.6
0.8
1
τ
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
t
h (− τ)
h (t − τ)
h (τ)
x (τ)
y (t )
(a)
(c)
(e)
(b)
(d)
Figure B.12 Wrap-around effects in FFT convolution.
422
Appendix B

example, only two DFT components are visible; the others fall on the zeros of the
analytic transform.
Doubling the length of the window function to 2 
 T0 causes the samples to be more
closely spaced in the frequency domain 4f ¼ 1=ð2T0Þ, but at the same time, the
transform of the window function becomes narrower by the same factor. The net
effect is to not increase the number of samples within the spectral peak. Demonstrate
this for yourself by executing the section entitled ‘‘Exercise on the DFT, Zero Padding
and Nyquist Sampling,’’ in the accompanying Mathematica tutorial.
Consider what happens when we append 3N zeros to hðkÞ which has been windowed
by a rectangular function N samples long. This situation is illustrated in panels (c) and
(d) of Figure B.14. There are now four times as many frequency components to define
the spectrum. Even in this situation, noticeable differences between the DFT and
analytic transform start to appear at larger values of f.
In the top panel, we see 12 samples of the data and to the right, the magnitude of
the discrete transform. In the bottom panel, we have four times the number of points
to be transformed by adding 36 zeros to the 12 original data points. Now the spectral
peak remains the same in size but we have four times as many points defining
the peak.
0.2 0.4 0.6 0.8
1
1.2 1.4
τ
 h (− τ)
Wrap around
response
0.2 0.4 0.6 0.8
1
1.2 1.4
τ
h (t − τ)
0.2 0.4 0.6 0.8
1
1.2 1.4
τ
h (τ)
Zero
pad
0.2 0.4 0.6 0.8
1
1.2 1.4
τ
x (τ)
Zero
pad
0
0.2
0.4
0.6
0.8
1
1.2
1.4
t
y (t)
(a)
(c)
(e)
(d)
(b)
Figure B.13 Removal of wrap-around effects in FFT convolution by zero padding.
Discrete Fourier Transforms
423

B.12 Power-spectrum estimation
The measurement of power spectra is a difficult and often misunderstood topic.
Because the FFT yields frequency and amplitude information, many investigators
proceed to estimate the power spectrum from the magnitude of the FFT. If the
waveform is periodic or deterministic, then the correct interpretation of the FFT
result is likely. However, when the waveforms are random processes, it is necessary
to develop a statistical approach to amplitude estimation. We will consider two
approaches to the subject in this section, and Chapter 13 provides a powerful
Bayesian viewpoint of spectral analysis. We start by introducing Parseval’s
theorem.
B.12.1 Parseval’s theorem and power spectral density
Parseval’s theorem states that the energy in a waveform hðtÞ computed in the time
domain must equal the energy as computed in the frequency domain.
0
2
4
6
8
10
12
t
–1
–0.5
0
0.5
1
y
 12 Data Sample + 48 Zeros
Zero padding
–0.4 
–0.2
0
0.2
0.4
Fraction of sampling frequency
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Magnitude
 Fourier Transform
0
0.5
1
1.5
2
2.5
3
3.5
t
–1
–0.5
0
0.5
1
y
 12 Data Sample
–0.4
 –0.2
0
0.2
0.4
Fraction of sampling frequency
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Magnitude
 Fourier Transform
(a)
(b)
(c)
(d)
Figure B.14 How to obtain more accurate DFT amplitudes by zero padding. The frequency axis
in the two right hand panels is in units of 1=T, the sampling frequency. On this scale the Nyquist
frequency ¼ 0:5.
424
Appendix B

Energy ¼
Z 1
1
h2ðtÞdt ¼
Z 1
1
Hð fÞ
j
j2df:
(B:80)
From this equation, it is clear that Hð fÞ
j
j2 is an energy spectral density. Frequently,
one wants to know ‘‘how much energy’’ is contained in the frequency interval between
f and f þ df. In such circumstances, one does not usually distinguish between þf
and f, but rather regards f as varying from 0 to þ1. In such cases, we define the
one-sided energy spectral density (ESD) of the function hðtÞ as
Ehð fÞ 	 Hð fÞ
j
j2 þ HðfÞ
j
j2; 0  f < 1:
(B:81)
When hðtÞ is real, then the two terms are equal, so
Ehð fÞ ¼ 2 Hð fÞ
j
j2:
(B:82)
If hðtÞ goes endlessly from 1 < t < 1, then its ESD will, in general, be infinite. Of
interest then is the one-sided ESD per unit time or power spectral density (PSD). This
is computed from a long but finite stretch of hðtÞ. The PSD is computed for a
function ¼ hðtÞ in the finite stretch which is zero elsewhere, divided by the length of
the stretch used. Parseval’s theorem in this case states that the integral of the one-sided
PSD over positive frequency is equal to the mean-square amplitude of the signal hðtÞ.
Proof of Parseval’s theorem using the convolution theorem:
FT of hðtÞ  hðtÞ ¼ Hð fÞ  Hð fÞ.
That is,
R 1
1h2ðtÞei2ptdt ¼
R 1
1HðfÞHð  fÞdf.
Setting  ¼ 0 yields
Z 1
1
h2ðtÞdt ¼
Z 1
1
Hð fÞHðfÞdf ¼
Z 1
1
Hð fÞ
j
j2df: QED
(B:83)
The last equality follows since
Hð fÞ ¼ Rð fÞ þ iIð fÞ and thus HðfÞ ¼ RðfÞ þ iIðfÞ:
(B:84)
For hðtÞ real, Rð fÞ is even and Ið fÞ is odd, and
HðfÞ ¼ RðfÞ  iIðfÞ ¼ H ðfÞ:
(B:85)
B.12.2 Periodogram power-spectrum estimation
A common approach used to estimate the spectrum of hðtÞ is by means of the period-
ogram also referred to as the Schuster periodogram after Schuster who first introduced
the method in 1898.
Let ^Ppð fÞ ¼
1
L
	 
 Z L=2
L=2
hðtÞei2pftdt


2
;
(B:86)
Discrete Fourier Transforms
425

where the subscript p denotes periodogram estimate and L is the length of the data set.
An FFT is normally used to compute this.
We define the power spectral density, Pð f Þ, as follows:
Pð fÞ ¼ lim
L!1
1
L
	 
 Z L=2
L=2
hðtÞei2pftdt


2
:
(B:87)
We now develop another power-spectrum estimator which is in common use.
B.12.3 Correlation spectrum estimation
Let hðtÞ be a random function of time (could be the sum of a deterministic function
and noise). In contrast to a pure deterministic function, future values of a random
function cannot be predicted exactly. However, it is possible that the value of the
random function at time t influences the value at a later time t þ . One way to express
this statistical characteristic is by means of the autocorrelation function, which for this
purpose is given by
ðÞ ¼ lim
L!1 1=L
Z þL=2
L=2
hðtÞ½hðt þ Þdt;
(B:88)
where hðtÞ extends from L=2 to þL=2.
In the limit of L ¼ 1, the power spectral density function Pð fÞ and the autocorrel-
ation function ðÞ are a Fourier transform pair:
ðÞ ¼
Z þ1
1
Pð fÞei2pfdf()Pð fÞ ¼
Z þ1
1
ðÞei2pfd:
(B:89)
Proof:
From Equation (B.87) and the correlation theorem, we have
Pð fÞ /
Z 1
1
hðtÞei2pftdt


2
¼ FT ½hðtÞ 
 FT ½hðtÞ
¼ FT
Z 1
1
hðtÞhðt þ Þdt


¼ FT ðÞ
½
:
(B:90)
In the literature, Pð fÞ is called by many terms including: power spectrum, spectral
density function, and power spectral density function (PSD). If the autocorrelation
function is known, then the calculation of the power spectrum is determined directly
from the Fourier transform.
426
Appendix B

Since hðtÞ is known only over a finite interval, we estimate ðÞ based on this finite
duration of data. The estimator generally used is
^ðÞ ¼
1
L  jj
Z Ljj
0
hðtÞh½t þ jjdt; jj < L;
(B:91)
where hðtÞ is known only over length L.
Notice that Pð fÞ cannot be calculated since ^ðÞ is undefined for jj > L. However,
consider the quantity wðÞ ^ðÞ, where wðÞ is a window function which is non-zero for
jj  L and zero elsewhere. The modified autocorrelation function wðÞ ^ðÞ exists for
all  and hence its FT exists.
^Pcð fÞ ¼
Z 1
1
wðÞ ^ðÞe2pfd;
(B:92)
where wðÞ ¼ 1 for jj5L and is zero elsewhere. ^Pcð fÞ is called the correlation or
lagged-product estimator of the PSD. This approach to spectral analysis is commonly
referred to as the Blackman–Tukey procedure (Blackman and Tukey, 1958). An instru-
ment for estimating the PSD in this way is called an autocorrelation spectrometer. They
are very common in the field of radio astronomy and especially in aperture synthesis
telescopes where it is already necessary to cross-correlate the signals from different pairs
of telescopes. It is quite convenient to add additional multipliers to calculate the
correlation as a function of delay to obtain the spectral information as well.
Although the periodogram and correlation spectrum estimation procedures appear
quite different, they are equivalent under certain conditions. It can be shown (Jenkins
and Watts, 1968) that
^Ppð fÞ ¼
Z þL=2
L=2
1  jj
L
	

^ðÞei2pfd:
(B:93)
The inverse FT yields
^pðÞ¼
1  jj
L
	

^ðÞ; jj < L:
(B:94)
Hence, if we modify the lagged-product spectrum estimation technique by simply
using a triangular (Bartlett) window function in Equation (B.92), then the two
procedures are equivalent.
In spectrum estimation problems, one strives to achieve an estimator whose mean
value (the average of multiple estimates) is the parameter being estimated. It can be
shown (Jenkins and Watts, 1968) that the mean value of both the correlation and
periodogram estimation procedures is the true spectrum Pð fÞ convolved with the
frequency-domain window function:
E ^Pcð fÞ


¼ E ^Ppð fÞ


¼ Wð fÞ  Pð fÞ:
(B:95)
Discrete Fourier Transforms
427

Hence, the mean (expectation) value equals the true spectrum only if the frequency-
domain window function is an impulse function (i.e., the data record length is infinite
in duration). If the mean of the estimate is not equal to the true value, then we say that
the estimate is biased.
B.13 Discrete power spectral density estimation
We will develop the discrete form of the PSD from the discrete form of Parseval’s
theorem. We start with a continuous waveform hðtÞ and its transform HðfÞ, which are
related by
hðtÞ ¼
Z þ1
1
Hð fÞei2pftdf
where
Hð fÞ ¼
Z þ1
1
hðtÞei2pftdt:
(B:96)
We refer to Hð fÞ as two-sided because from the mathematics, it has non-zero values at
both ðþÞ and ðÞ frequencies.
According to Parseval’s theorem,
Energy ¼
Z 1
1
h2ðtÞdt ¼
Z 1
1
Hð fÞ
j
j2df:
(B:97)
Thus, Hð fÞ
j
j2 ¼ two-sided energy spectral density.
B.13.1 Discrete form of Parseval’s theorem
Suppose our function hðtÞ is sampled at N uniformly spaced points to produce the
values hk for k ¼ 0 to N  1 spanning a length of time L ¼ NT with T ¼ the sample
interval.
Energy ¼
X
N1
k¼0
h2
kT ¼
X
N1
n¼0
Hð fnÞ
j
j2f
¼
X
N1
n¼0
THn
j
j2f:
(B:98)
Note: the substitution THn ¼ HðfnÞ comes from Equation (B.50). Thus, jTHnj2 ¼
two-sided discrete energy spectral density.
We note in passing that the usual discrete form of Parseval’s theorem is obtained
from Equation (B.98) by rewriting f ¼ 1=ðNTÞ and then simplifying to give
X
N1
k¼0
h2
k ¼ 1
N
X
N1
n¼0
Hn
j
j2:
(B:99)
428
Appendix B

We will find Equation (B.98) a more useful version of the discrete form of Parseval’s
theorem because it makes clear that jTHnj2 is a discrete energy spectral density.
Average waveform power ¼ waveform energy
waveform duration
¼ 1
NT
X
N1
k¼0
h2
kT
¼
X
N1
n¼0
jHnj2T
N
f
(B:100)
¼ 1
N
X
N1
k¼0
h2
k
¼ mean squared amplitude:
ðB:101Þ
We can identify the two-sided discrete PSD with jHnj2T/N from the RHS of the above
equation, which has units of power per cycle.
B.13.2 One-sided discrete power spectral density
Let Pð fnÞ ¼ the one-sided power spectral density.
Pðf0Þ ¼ T
N jH0j2
PðfnÞ ¼ T
N
Hn
j
j2 þ HNn
j
j2
h
i
; n ¼ 1; 2; . . . ; ðN=2  1Þ
P fN=2


¼ T
N HN=2

2;
(B:102)
where fN=2 corresponds to the Nyquist frequency and Pð fnÞ is only defined for zero
and positive frequencies. From Equation (B.102), it is clear that Pð fnÞ is normalized so
that PN1
n¼0 Pð fnÞf ¼ the mean squared amplitude. Note: our expression for the one-
sided discrete PSD which has units of power per unit of bandwidth differs from the one
given in Press et al., (1992). In particular, the definition used there, PNRð fnÞ, is related
to our Pð fnÞ by PNRð fnÞ ¼ Pð fnÞf ¼ Pð fnÞ=ðNTÞ.
B.13.3 Variance of periodogram estimate
What is the variance of Pð fnÞ as N ! 1? In other words, as we take more sampled
points from the original function (either sampling a longer stretch of data, or else by
resampling the same stretch of data with a faster sampling rate), how much more
accurate do the estimates Pð fnÞ become?
Discrete Fourier Transforms
429

The unpleasant answer is that periodogram estimates do not become more accurate
at all! It can be shown that in the case of white Gaussian noise2 the standard deviation
at frequency fn is equal to the expectation value of the spectrum of fn (Marple, 1987).
How can this be? Where did this information go as we added more points? It all
went into producing estimates at a greater number of discrete frequencies fn. If we
sample a longer run of data using the same sampling rate, then the Nyquist critical
frequency fc is unchanged, but we now have finer frequency resolution (more fn’s). If
we sample the same length with a finer sampling interval, then our frequency resolu-
tion is unchanged, but the Nyquist range extends to higher frequencies. In neither case
do the additional samples reduce the variance of any one particular frequency’s
estimated PSD. Figure B.15 shows examples for increasing N.
As you will see below, there are ways to reduce the variance of the estimate.
However, this behavior caused many researchers to consider periodograms of noisy
0.1
0.2
0.3
0.4
0.5
Fraction of sampling frequency
2
4
6
8
10
12
14
PSD
64 – points
0.1
0.2
0.3
0.4
0.5
Fraction of sampling frequency
2
4
6
8
10
12
14
PSD
128 – points
0.1
0.2
0.3
0.4
0.5
Fraction of sampling frequency
2
4
6
8
10
12
14
PSD
16 – points
0.1
0.2
0.3
0.4
0.5
Fraction of sampling frequency
2
4
6
8
10
12
14
PSD
32 – points
(a)
(b)
(c)
(d)
Figure B.15 Power spectral density (PSD) for white (IID) Gaussian noise for different record
lengths. The frequency axis is in units of 1=T, the sampling frequency. On this scale the Nyquist
frequency ¼ 0:5.
2 The term white noise
means that the spectral density of the noise is constant from zero frequency through the
frequencies of interest, i.e., up to the Nyquist frequency. It is really another way of saying the noise is independent. An
independent ensemble of noise values has an autocorrelation function (Equation (B.88)) which is a delta function.
According to equation (B.90), the power spectral density is just the FT of the autocorrelation function, which in this
case would be a constant.
430
Appendix B

data to be erratic and this resulted in a certain amount of disenchantment with
periodograms for several decades. However, even Schuster was aware of the solu-
tion. This disenchantment led G. Yule to introduce a notable alternative analysis
method in 1927. Yule’s idea was to model a time series with linear regression analysis
data. This led to the parametric methods which assume a time-series model and solve
for the parameters of the random process. These include autoregressive (AR), moving
average (MA) and autoregressive-moving average (ARMA) process models (see
Priestley, 1981; Marple, 1987 for more details). In contrast, the correlation and
periodogram spectral estimations are referred to as non-parametric statistics of a
random process.
B.13.4 Yule’s stochastic spectrum estimation model
The Schuster periodogram is appropriate to a model of a sinusoid with additive noise.
Suppose the situation were more akin to a pendulum which was being hit by boys
throwing peas randomly from both sides.
The result is simple harmonic motion powered by a random driving force. The
motion is now affected, not by superposed noise, but by a random driving force. As a
result, the graph will be of an entirely different kind to a graph in the case of a sinusoid
with superposed errors. The pendulum graph will remain surprisingly smooth, but the
amplitude and phase will vary continuously as governed by the inhomogeneous
difference equation:
xðnÞ þ a1xðn  1Þ þ a2xðn  2Þ ¼ ðnÞ;
(B:103)
where ðnÞ is the white noise input.
Given an empirical time series, xðnÞ, Yule used the method of regression analysis
to find these coefficients. Because he regressed xðnÞ on its own past instead of some
other variable, he called it autoregression. The least-squares normal equations
involve the empirical autocorrelation coefficients of the time series, and today
these equations are called the Yule–Walker equations. A good example of such a
time series is electronic shot noise passing through some band pass filter which rings
every shot. A detailed discussion of these methods goes beyond the scope of
this book and the interested reader is referred to the works of Priestley (1981) and
Marple (1987).
B.13.5 Reduction of periodogram variance
There are two simple techniques for reducing the variance of a periodogram that are
very nearly identical mathematically, though different in implementation. The first is
to compute a periodogram estimate with finer discrete frequency spacing than you
really need, and then to sum the periodogram estimates at K consecutive discrete
Discrete Fourier Transforms
431

frequencies to get one ‘‘smoother’’ estimate at the mid frequency of those K.3 The
variance of that summed estimate will be smaller than the estimate itself by a factor of
exactly 1=K, i.e., the standard deviation will be smaller than 100 percent by a factor
1=
ﬃﬃﬃﬃ
K
p
. Thus, to estimate the power spectrum at M þ 1 discrete frequencies between 0
and fc inclusive, you begin by taking the FFT of 2MK points (which number had better
be an integer power of two!). You then take the modulus squared of the resulting
coefficients, add positive and negative frequency pairs and divide by ð2MKÞ2. Finally,
you ‘‘bin’’ the results into summed (not averaged) groups of K. The reason that you
sum rather than average K consecutive points is so that your final PSD estimate will
preserve the normalization property that the sum of its M þ 1 values equals the mean
square value of the function.
A second technique for estimating the PSD at M þ 1 discrete frequencies in the
range of 0 to fc is to partition the original sampled data into K segments each of 2M
consecutive sampled points. Each segment is separately FFT’d to produce a period-
ogram estimate. Finally, the K periodogram estimates are averaged at each frequency.
It is this final averaging that reduces the variance of the estimate by a factor of K
(standard deviation by
ﬃﬃﬃﬃ
K
p
). The principal advantage of the second technique, how-
ever, is that only 2M data points are manipulated at a single time, not 2KM as in the
first technique. This means that the second technique is the natural choice for pro-
cessing long runs of data, as from a magnetic tape or other data record.
B.14 Problems
1. Exercise on the DFT, zero padding and Nyquist sampling
a) In the accompanying Mathematica tutorial, you will find a section entitled,
‘‘Exercise on the DFT, Zero Padding and Nyquist Sampling.’’ Execute the
notebook and make sure you understand each step. Do not include a copy of
this part in your submission.
b) Repeat the exercise items, but this time with
fn ¼ Cos½2pf1t+Sin½2pf2t.
Let f1 ¼ 1 Hz; f2 ¼ 0:7 Hz; T ¼ 0:25 s and the data window length L ¼ 3 s.
c) Explain why one of the two frequencies only appeared in the real part of the
analytic FT and the other only appeared in the imaginary part.
d) What was the effect of zero padding on the DFT?
e) Comment on the degree of agreement between the FT and the DFT in the
Mathematica tutorial.
f) Repeat item (b), only this time increase the window size L ¼ 8 s. What effect did
this have on the spectrum? Explain why this occurred (see Figure B.7).
3 Of course, if your goal is to detect a very narrow band signal, then smoothing may actually reduce the signal-to-noise
ratio for detecting such a signal.
432
Appendix B

g) What is the value of the Nyquist frequency for the sampling interval used?
h) Do the two signals appear at their correct frequencies in the FT and DFT?
Explain why there are low level bumps in the spectrum at other frequencies.
i) Recompute the DFT with a sample interval, T ¼ 0:65 s, and a data window
length L ¼ 65 s. Do the two signals appear at their correct frequencies? If not,
explain why.
2. Exercise on Fourier image convolution and deconvolution
a) In the accompanying Mathematica tutorial, you will find a section entitled
‘‘Exercise on Fourier Image Convolution and Deconvolution.’’ Execute the
notebook and make sure you understand each step.
b) Repeat (a) using a point spread function which is the sum of the following two
multinormal distributions:
Multinormal½f0; 0g; ff1; 0g; f0; 1gg
Multinormal½f4; 0g; ff2; 0:8g; f0:8; 2gg
Discrete Fourier Transforms
433

Appendix C
Difference in two samples
C.1 Outline
In Section 9.4, we explored a Bayesian treatment of the analysis of two independent
measurements of the same physical quantity, the control and the trial, taken under
slightly different experimental conditions. In the next four subsections, we give the
details behind the calculations of the probabilities of the four fundamental hypotheses
ðC; SÞ, ðC; SÞ, ðC; SÞ and ðC; SÞ which arose in Section 9.4.
After determining what is different, the next problem is to estimate the magnitude of
the changes. Section 9.4.4 introduced the calculation for the probability of the difference
in the two means pðjD1; D2; IÞ. The details of this calculation are given in Section C.3.
Finally, Section 9.4.5 introduced the calculation for the probability for the ratio of
the standard deviations, pðrjD1; D2; IÞ. The details of this calculation are given in
Section C.4.
C.2 Probabilities of the four hypotheses
C.2.1 Evaluation of pðC; SjD1; D2; IÞ
The only quantities that remain to be assigned are the two likelihood functions. The
prior probability for the noise will be taken to be Gaussian.
pðD1jC; S; c1; 1; IÞ and pðD2jC; S; c1; 1; IÞ
D1  fd11; d12; d13; . . . ; d1N1g
where D1i ¼ c1 þ e1i; therefore,
pðD1jC; S; c1; 1; IÞ ¼ pðe11; e12; . . . ; e1N1jc11IÞ
¼
Y
N1
i¼1
1ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2p2
1
q
exp  e2
i
22
1


2
64
3
75
pðD1jC; S; c1; 1; IÞ ¼ ð2p2
1Þ
N1
2 exp

X
N1
i¼1
ðd1i  c1Þ2
22
1
(
)
(C:1)
434

pðD2jC; S; c1; 1; IÞ ¼ð2p2
1Þ
N2
2 exp

X
N2
i¼1
ðd2i  c1Þ2
22
1
(
)
:
(C:2)
Let
 1 ¼
X
N1
i¼1
ðd1i  c1Þ2
¼
X
d2
1i þ N1c2
1  2c1
X
d1i
and
 2 ¼
X
N2
i¼1
d2
2i þ N2c2
1  2c1
X
d2i
and
 1 þ  2 ¼
X
N¼N1þN2
i¼1
d2
i þ Nc2
1  2c1
X
N¼N1þN2
i¼1
di
¼ Nd2 þ Nc2
1  2c1Nd
¼ Nc2
1  2c1Nd þ NðdÞ2  NðdÞ2 þ Nd2
¼ Nðc1  dÞ2 þ Nðd2  ðdÞ2Þ;
(C:3)
where d and d2 are the mean and mean square of the pooled data, N ¼ N1 þ N2.
Therefore,
pðD1jC; S; c1; 1; IÞ pðD2jC; S; c1; 1; IÞ ¼ð2p2
1ÞN
2 exp
Nðd2  ðdÞ2Þ
22
1
(
)
 exp
Nðc1  dÞ2
22
1
(
)
:
(C:4)
Now combine the likelihoods with the priors to obtain the posterior probability
pðC; SjD1; D2; IÞ:
pðC; SjD1; D2; IÞ ¼K
Z H
L
d1
ð2p2
1ÞN
2
4Rc1 lnðRÞ exp
Nðd2  ðdÞ2Þ
22
1
(
)

Z cH
cL
dc1 exp
 Nðc1  dÞ2
22
1
(
)
:
(C:5)
If the limits on the c1 integral extend from minus infinity to plus infinity, and the
limits on the 1 integral extend from zero to infinity, then both integrals can be
Difference in two samples
435

evaluated in closed form. However, with finite limits, either of the two indicated
integrals may be evaluated, but the other must be evaluated numerically. The integral
over amplitude will be evaluated in terms of erf(x), the error function
erfðxÞ ¼ 2ﬃﬃﬃp
p
Z x
0
eu2du
(C:6)
by setting
u2 ¼ Nðc1  dÞ2
22
1
:
(C:7)
Z cH
cL
dc1 exp
 Nðc1  dÞ2
22
1
(
)
¼
ﬃﬃﬃﬃ
2
N
r
1
Z XH
XL
eu2du
¼
ﬃﬃﬃﬃ
2
N
r
1
ﬃﬃﬃp
p
2
2ﬃﬃﬃp
p
Z XH
XL
eu2du


¼
ﬃﬃﬃﬃﬃﬃﬃ
p
2N
r
1 ½erfðXHÞ  erfðXLÞ:
(C:8)
Evaluating the integral over the amplitude, we obtain:
pðC; SjD1; D2; IÞ ¼ Kð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
p=2N
p
4Rc logðRÞ
Z H
L
d1 N
1
 exp  z
22
1


erfðXHÞ  erfðXLÞ
½
;
(C:9)
where
XH ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N
22
r
ðc1H  dÞ;
XL ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N
22
r
ðc1L  dÞ;
z ¼ N½d2  ðdÞ2:
(C:10)
C.2.2 Evaluation of pðC; SjD1; D2; IÞ
Notice that pðC; SjD1; D2; IÞ assumes the constants are the same in both data sets, but
the standard deviations are different. Thus, pðC; SjD1; D2; IÞ is a marginal probability
436
Appendix C

density, where the constant and the two standard deviations were removed as nuisance
parameters.
pðC; SjD1; D2; IÞ ¼
Z
dc1d1d2 pðC; S; c1; 1; 2jD1; D2; IÞ
¼K
Z
dc1d1d2 pðC; S; c1; 1; 2jIÞ
 pðD1; D2jC; S; c1; 1; 2; IÞ
¼K
Z
dc1d1d2 pðC; SjIÞ pðc1jIÞ pð1jIÞ pð2jIÞ
 pðD1jC; S; c1; 1; IÞ pðD2jC; S; c1; 2; IÞ:
(C:11)
By analogy with Equations (C.1) to (C.3), we can evaluate
pðD1jC; S; c1; 1; 2; IÞ pðD2jC; S; c1; 1; 2; IÞ
¼ ð2pÞN
2N1
1
exp  U1
2
1


N2
2
exp  U2
2
2


;
(C:12)
where
U1 ¼ N1
2 ðd2
1  2c1d1 þ c2
1Þ;
U2 ¼ N2
2 ðd2
2  2c1d2 þ c2
1Þ
(C:13)
and d1, d2
1, d2, d2
2 are the means and mean squares of D1 and D2 respectively.
Substituting Equation (C.12) into (C.11) and adding the priors, we have
pðC; SjD1; D2; IÞ ¼
Kð2pÞN=2
16Rc½logðRÞ2
Z H
L
dc1
Z H
L
d1ðN1þ1Þ
1
exp  U1
2
1



Z H
L
d2ðN2þ1Þ
2
exp  U2
2
2


:
(C:14)
The integrals over 1 and 2 will be evaluated in terms of Qðr; xÞ, one form of the
incomplete gamma function of index r and argument x:
Qðr; xÞ ¼
1
ðrÞ
Z 1
x
ettr1 dt:
(C:15)
If we let
t ¼ U1
2
1
;
r ¼ N1
2 ;
(C:16)
Difference in two samples
437

then we can show that
Z H
L
d1ðN1þ1Þ
1
exp  U1
2
1


¼ 1
2 U

N1
2
1
ðN1=2Þ

1
ðN1=2Þ
Z 1
XL
ett
N1
2 1dt



1
ðN1=2Þ
Z 1
XH
ett
N1
2 1dt




¼ 1
2 U

N1
2
1
ðN1=2Þ Q N1
2 ; U1
2
H


 Q N1
2 ; U1
2
L




:
(C:17)
Evaluating the integral over 1 and 2, one obtains
pðC; SjD1; D2; IÞ ¼ Kð2pÞN=2ðN1=2ÞðN2=2Þ
16Rc½logðRÞ2
Z H
L
dc1U

N1
2
1
U

N2
2
2
 Q N1
2 ; U1
2
H


 Q N1
2 ; U1
2
L




 Q N2
2 ; U2
2
H


 Q N2
2 ; U2
2
L




:
(C:18)
C.2.3 Evaluation of pðC; SjD1; D2; IÞ
pðC; SjD1; D2; IÞ ¼
Z
dc1 dc2 d1 pðC; S; c1; c2; 1jD1; D2; IÞ
¼K
Z
dc1 dc2 d1 pðC; S; c1; c2; 1jIÞ
 pðD1; D2jC; S; c1; c2; 1; IÞ
¼K
Z
dc1 dc2 d1 pðC; S; jIÞ pðc1jIÞ pðc2jIÞ pð1jIÞ
 pðD1jC; S; c1; 1; IÞ pðD2jC; S; c2; 1; IÞ:
(C:19)
Evaluating the integrals over c1 and c2, one obtains
pðC; SjD1; D2; IÞ ¼
Kð2pÞN=2p
8R2
c logðRÞ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
N1N2
p
Z H
L
d1Nþ1
1
exp  z1 þ z2
22
1


 ½erfðX1HÞ  erfðX1LÞ½erfðX2HÞ  erfðX2LÞ;
(C:20)
where
z1 ¼ N1½d2
1  ðd1Þ2;
z2 ¼ N2½d2
2  ðd2Þ2;
(C:21)
X1H ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N1
22
1
s
ðH  d1Þ;
X1L ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N1
22
1
s
ðL  d1Þ;
(C:22)
438
Appendix C

X2H ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N2
22
1
s
ðH  d2Þ;
X2L ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N2
22
1
s
ðL  d2Þ:
(C:23)
C.2.4 Evaluation of pðC; SjD1; D2; IÞ
pðC; SjD1; D2; IÞ ¼
Z
dc1 dc2 d1 d2 pðC; S; c1; c2; 1; 2jD1; D2; IÞ
¼K
Z
dc1 dc2 d1 d2 pðC; S; c1; c2; 1; 2jIÞ
 pðD1; D2jC; S; c1; c2; 1; 2; IÞ
¼K
Z
dc1 dc2 d1 d2 pðC; SjIÞ pðc1jIÞpðc2jIÞ pð1jIÞ pð2jIÞ
 pðD1jC; S; c1; 1; IÞ pðD2jC; S; c2; 2; IÞ:
(C:24)
Evaluating the integrals over c1 and c2, one obtains
pðC; SjD1; D2; IÞ ¼
Kð2pÞN=2p
8R2
c½logðRÞ2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
N1N2
p

Z H
L
d1N1
1
exp  z1
22
1


½erfðX1HÞ  erfðX1LÞ

Z H
L
d2N2
2
exp  z2
22
2


½erfðX2HÞ  erfðX2LÞ;
(C:25)
where
X1H ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N1
22
1
s
ðc1H  d1Þ;
X1L ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N1
22
1
s
ðc1L  d1Þ;
ðC:26Þ
X2H ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N2
22
2
s
ðc1H  d2Þ;
X2L ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N2
22
2
s
ðc1L  d2Þ;
ðC:27Þ
z1 ¼ N1½d2
1  ðd1Þ2;
z2 ¼ N2½d2
2  ðd2Þ2:
ðC:28Þ
C.3 The difference in the means
Section 9.4.4 introduced the calculation for the probability of the difference in the two
means pðjD1; D2; IÞ, which was expressed in Equation (9.68) as a weighted sum of
pðjS; D1; D2; IÞ and pðjS; D1; D2; IÞ, the probability for the difference in means given
that the standard deviations are the same (the two-sample problem) and the
Difference in two samples
439

probability for the difference in means given that the standard deviations are different
(the Behrens–Fisher problem). The details of the calculation of these two probabilities
are given below.
C.3.1 The two-sample problem
pðjS; D1; D2; IÞ is essentially the two-sample problem. This probability is a marginal
probability where the standard deviation and  have been removed as nuisance
parameters:
pðjS; D1; D2; IÞ ¼
Z
d d1 pð; ; 1jS; D1; D2; IÞ
/
Z
d d1 pð; ; 1jS; IÞ pðD1; D2jS; ; ; 1; IÞ
¼
Z
d d1 pðjIÞ pðjIÞ pð1jIÞ
 pðD1jS; ; ; 1; IÞ pðD2jS; ; ; 1; IÞ;
(C:29)
where pðjIÞ and pðjIÞ are assigned bounded uniform priors:
pðjIÞ ¼
1
2Rc ;
if L  H    H  L
0;
otherwise

(C:30)
and
pðjIÞ ¼
1
2Rc ;
if 2L    2H
0;
otherwise.

(C:31)
We can evaluate pðD1jS; ; ; 1; IÞ by comparison with Equation (C.1), after substi-
tuting for c1 according to Equation (9.67).
pðD1jS; ; ; 1; IÞ ¼ ð2p2
1Þ
N1
2 exp  Q1
2
1


;
(C:32)
where Q1 is given by:
Q1 ¼
X
N1
i¼1
d1i  ð þ Þ
2

2
¼ N1
2
d2
1  ð þ Þd1 þ 2
4 þ 
2 þ 2
4


:
(C:33)
Similarly, pðD2jS; ; ; 1; IÞ is given by
pðD2jS; ; ; 1; IÞ ¼ ð2p2
1Þ
N2
2 exp  Q2
2
1


;
(C:34)
440
Appendix C

where
Q2 ¼
X
N2
i¼1
d2i  ð  Þ
2

2
¼ N2
2
d2
2  ð  Þd2 þ 2
4  
2 þ 2
4


:
(C:35)
The product of Equations (C.32) and (C.34) can be simplified to
pðD1jS; ; ; 1; IÞ pðD2jS; ; ; 1; IÞ ¼ ð2pÞN
2N
1
exp  V
2
1


;
(C:36)
where
V ¼ N
2
d2  2b  d þ 2
4 þ 2
4 þ 
2


;
(C:37)
 ¼ N1  N2
N
;
and
b ¼ N1d1  N2d2
2N
:
(C:38)
After substituting Equations (C.30) and (C.31) and (C.36) into Equation (C.29), the
integral over 1 is evaluated in terms of incomplete gamma functions.
pðjS; D1; D2; IÞ /
ðN=2Þ
8R2
c logðRÞ
Z 2H
2L
dVN
2
 Q N
2 ; V
2
H


 Q N
2 ; V
2
L




:
(C:39)
The final integral over  is computed numerically.
C.3.2 The Behrens–Fisher problem
The Behrens–Fisher problem is essentially given by pðjS; D1; D2; IÞ, the probability
for the difference in means given that the standard deviations are not the same. This
probability is a marginal probability where both the standard deviations and the sum
of the means, , have been removed as nuisance parameters:
pðjS;D1;D2;IÞ ¼
Z
d d1 d2 pð;;1; 2jS;D1; D2;IÞ
/
Z
d d1 d2 pð;;1; 2jS;IÞ pðD1;D2jS;;;1;2;IÞ
¼
Z
d d1 d2 pðjIÞ pðjIÞ pð1jIÞ pð2jIÞ
 pðD1jS;;;1; IÞ pðD2jS;;;2;IÞ;
(C:40)
Difference in two samples
441

where all of the terms appearing in this probability density function have been
previously assigned.
To evaluate the integrals over 1 and 2, one substitutes Equations (9.63), (C.30)
and (C.31), and a Gaussian noise prior is used in the two likelihoods. Evaluating the
integrals, one obtains
pðjS; D1; D2; IÞ / ðN1=2ÞðN2=2Þ
16R2
c½logðRÞ2
Z 2H
2L
d W

N1
2
1
W

N2
2
2
 Q N1
2 ; W1
2
H


 Q N1
2 ; W1
2
L




 Q N2
2 ; W2
2
H


 Q N2
2 ; W2
2
L




;
(C:41)
where
W1 ¼ N1
2
d2
1  d1ð þ Þ þ ð þ Þ2
4
"
#
;
(C:42)
and
W2 ¼ N2
2
d2
2  d2ð  Þ þ ð  Þ2
4
"
#
:
(C:43)
With the completion of this calculation, the probability for the difference in means,
Equation (9.68), is now complete. We now turn our attention to calculation of the
probability for the ratio of the standard deviations.
C.4 The ratio of the standard deviations
Section 9.4.5 introduced the calculation for the probability for the ratio of the
standard deviations, pðrjD1; D2; IÞ, independent of whether the means are the same
or different. This is a weighted average of the probability for the ratio of the standard
deviations given the means are the same, pðrjC; D1; D2; IÞ, and the probability for the
ratio of the standard deviations given that the means are different, pðrjC; D1; D2; IÞ.
These two probabilities are given below.
C.4.1 Estimating the ratio, given the means are the same
The first term to be addressed is pðrjC; D1; D2; IÞ. This probability is a marginal
probability where both  and c1 have been removed as nuisance parameters:
442
Appendix C

pðrjC; D1; D2; IÞ ¼
Z
dc1d pðr; c1; jC; D1; D2; IÞ
/
Z
dc1d pðr; c1; jC; IÞ pðD1; D2jC; r; c1; ; IÞ
¼
Z
dc1d pðrjIÞpðc1jIÞ pðjIÞ
 pðD1jC; r; c1; ; IÞ pðD2jC; r; c1; ; IÞ;
(C:44)
where the prior probability for the ratio of the standard deviations is taken to be a
bounded Jeffreys prior:
pðrjIÞ ¼
1=½2r logðRÞ;
if L=H  r  H=L
0;
otherwise.

(C:45)
To evaluate the integral over c1, one substitutes Equations (9.63) and (C.45), and a
Gaussian noise prior probability is used to assign the two likelihoods. Evaluating the
integral, one obtains
pðrjC; D1; D2; IÞ ¼ ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
p=8w
p
rN11
Rc½logðRÞ2

Z H
L
d N exp  z
22
n
o
½erfðXHÞ  erfðXHÞ;
(C:46)
where
XH ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
w
22
r
½c1H  v=w;
XL ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
w
22
r
½c1L  v=w;
ðC:47Þ
u ¼ N1d2
1
r2
þ N2d2
2;
v ¼ N1d1
r2
þ N2d2;
ðC:48Þ
w ¼ N1
r2 þ N2;
z ¼ u  v2
w :
ðC:49Þ
C.4.2 Estimating the ratio, given the means are different
The second term that must be computed is pðrjC; D1; D2; IÞ, the probability for the
ratio of standard deviations given that the means are not the same. This is a marginal
probability where , c1, and c2 have been removed as nuisance parameters:
Difference in two samples
443

pðrjC; D1; D2; IÞ ¼
Z
dc1dc2d pðr; c1; c2; jC; D1; D2; IÞ
/
Z
dc1dc2d pðr; c1; c2; jC; IÞ pðD1; D2jC; r; c1; c2; ; IÞ
¼
Z
dc1dc2d pðrjIÞ pðc1jIÞ pðc2jIÞ pðjIÞ
 pðD1jr; C; c1; ; IÞ pðD2jr; C; c2; ; IÞ;
(C:50)
where all of the terms appearing in this probability density function have been
previously assigned.
To evaluate the integral over c1 and c2, one substitutes Equations (9.62), (9.63) and
(C.45) and a Gaussian noise prior is used in assigning the two likelihoods. Evaluating
the indicated integrals, one obtains
pðrjC; D1; D2; IÞ /
ð2pÞN=2p
4R2
c½logðRÞ2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
N1N2
p
Z H
L
d rN1Nþ1
 exp 
z1
2r22  z2
22
n
o
½erfðX1HÞ  erfðX1LÞ
 ½erfðX2HÞ  erfðX2LÞ;
(C:51)
where
X1H ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
N1
2r22
r
½c1H  d1;
X1L ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
N1
2r22
r
½c1L  d1;
ðC:52Þ
X2H ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N2
22
r
½c2H  d2;
X2L ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
N2
22
r
½c2L  d2;
ðC:53Þ
z1 ¼ N1½d2
1  ðd1Þ2;
z2 ¼ N2½d2
2  ðd2Þ2:
ðC:54Þ
444
Appendix C

Appendix D
Poisson ON/OFF details
D.1 Derivation of pðsjNon; IÞ
In Section 14.4, we explored a Bayesian analysis of ON/OFF measurements, where
ON is signal þ background and OFF is a just the background. The background is only
known imprecisely from OFF measurement. In this appendix, we derive Equation
(14.17) for pðsjNon; IÞ, the posterior probability of the signal event rate.
Our starting point is Equation (14.16), which we repeat here together with some of
the other relevant equations:
pðsjNon; IÞ ¼
Z bmax
0
db pðs; bjNon; IÞ
(D:1)
pðs; bjNon; IÞ ¼ pðs; bjIÞpðNonjs; b; IÞ
pðNonjIÞ
¼ pðsjb; IÞpðbjIÞpðNjs; b; IÞ
pðNonjIÞ
(D:2)
pðbjNoff; IbÞ ¼ pðbjIÞ ¼ ToffðbToffÞNoffebToff
Noff!
(D:3)
pðsjb; IÞ ¼ 1=smax:
(D:4)
The denominator of pðs; bjNon; IÞ in Equation (D.2) is given by
pðNonjIÞ ¼
Z smax
s¼0
ds
Z bmax
b¼0
db pðNon; s; bjIÞ
¼
Z smax
s¼0
ds
Z bmax
b¼0
db pðsjb; IÞpðbjIÞpðNonjs; b; IÞ:
(D:5)
445

Substituting Equations (D.5), (D.4), (D.3) and (D.2) into Equation (D.1), we
obtain
pðsjNon; IÞ ¼
R bmax
b¼0 db
1
smax
T
ð1þNoffÞ
off
bNoffebToff
Noff!
ðsþbÞNonTNon
on eðsþbÞTon
Non!
R smax
s¼0 ds
R bmax
b¼0 db
1
smax
T
ð1þNoffÞ
off
bNoffebToff
Noff!
ðsþbÞNonTNon
on eðsþbÞTon
Non!
¼
R bmax
b¼0 db bNoffebToffðs þ bÞNoneðsþbÞTon
R smax
s¼0 ds
R bmax
b¼0 db bNoffebToffðs þ bÞNoneðsþbÞTon
¼ Num
Den :
(D:6)
D.1.1 Evaluation of Num
We start with a binomial expansion of ðs þ bÞNon.
ðs þ bÞNon ¼
X
Non
i¼0
Non!
i!ðNon  iÞ! sibðNoniÞ:
(D:7)
The numerator of Equation (D.6) becomes
Num ¼
Z bmax
b¼0
db bNoffebðTonþToffÞ X
Non
i¼0
Non!
i!ðNon  iÞ! sibðNoniÞesTon
¼
X
Non
i¼0
Non!
i!ðNon  iÞ! siesTon
Z bmax
b¼0
db bðNonþNoffiÞeb½TonþToff
¼
X
Non
i¼0
Non!
i!ðNon  iÞ! siesTon  integral:
(D:8)
We now want to evaluate the integral in Equation (D.8), which we first rewrite in the
form of an incomplete gamma function:
Integral ¼ ðTon þ ToffÞðNonþNoffiþ1Þ

Z bmax½TonþToff
b¼0
dðb½Ton þ ToffÞ ðb½Ton þ ToffÞðNonþNoffiÞ
 eb½TonþToff:
(D:9)
Compare this to one form of the incomplete gamma function:
ðn þ 1; xÞ ¼
Z x
0
dy yney:
(D:10)
446
Appendix D

Thus, Equation (D.9) can be rewritten as
Integral ¼ ðTon þ ToffÞðNonþNoffiþ1Þ
 ð½Non þ Noff  i þ 1; bmax½Ton þ ToffÞ:
(D:11)
Provided bmax½Ton þ Toff  ½Non þ Noff  i, we have that
ð½Non þ Noff  i þ 1; bmax½Ton þ ToffÞ  ð½Non þ Noff  i þ 1Þ
¼ ðNon þ Noff  iÞ!
(D:12)
Substituting Equation (D.12) into Equation (D.11), we obtain
Integral  ðTon þ ToffÞðNonþNoffiþ1ÞðNon þ Noff  iÞ!
(D:13)
Now substitute Equation (D.13) into Equation (D.8) to obtain
Num 
Non!
ðTon þ ToffÞðNonþNoffþ1Þ
X
Non
i¼0
ðNon þ Noff  iÞ!
i!ðNon  iÞ!
siesTon
ðTon þ ToffÞi
¼
Non!
TonðTon þ ToffÞðNonþNoffþ1Þ

X
Non
i¼0
ðNon þ Noff  iÞ!
i!ðNon  iÞ!
TonðsTonÞiesTon
1 þ Toff
Ton

i
:
(D:14)
D.1.2 Evaluation of Den
The equation for denominator (Den) in Equation (D.6) is the same as Equation (D.14)
for the numerator (Num) except for the additional integral over s.
Den ¼
Z smax
s¼0
ds
Non!
TonðTon þ ToffÞðNonþNoffþ1Þ

X
Non
i¼0
ðNon þ Noff  iÞ!
i!ðNon  iÞ!
TonðsTonÞiesTon
1 þ Toff
Ton

i
¼
Non!
TonðTon þ ToffÞðNonþNoffþ1Þ
X
Non
i¼0
ðNon þ Noff  iÞ!
i!ðNon  iÞ!
1 þ Toff
Ton

i

Z smax
s¼0
dðsTonÞðsTonÞiesTon:
(D:15)
Poisson ON/OFF details
447

The integral can be recognized as the incomplete gamma function ði þ 1; smaxTonÞ.
Provided smaxTon  i þ 1, we can write ði þ 1; smaxTonÞ  i!, and Equation (D.15)
simplifies to
Den 
Non!
TonðTon þ ToffÞðNonþNoffþ1Þ
X
Non
i¼0
ðNon þ Noff  iÞ!
ðNon  iÞ!
1 þ Toff
Ton

i
:
(D:16)
Substitution of Equation (D.14) and (D.16) into Equation (D.17) yields
pðsjNon; IÞ ¼
X
Non
i¼0
Ci
TonðsTonÞiesTon
i!
;
(D:17)
where
Ci 
1 þ Toff
Ton

iðNonþNoffiÞ!
ðNoniÞ!
PNon
j¼0 1 þ Toff
Ton

jðNonþNoffjÞ!
ðNonjÞ!
:
(D:18)
D.2 Derivation of the Bayes factor Bfsþb;bg
Here, we will derive the Bayes factor, Bfsþb;bg, given in Equation (14.23), for the two
models Msþb and Mb, which have the following meaning:
Mb  ‘‘the ON measurement is solely due to the Poisson background rate, b, where the
prior probability for b is derived from the OFF measurement.’’
Msþb  ‘‘the ON measurement is due to a source with unknown Poisson rate, s, plus a
Poisson background rate b. Again, the prior probability for b is derived from the OFF
measurement.’’
Bfsþb;bg ¼ pðNonjMsþb; IoffÞ
pðNonjMb; IoffÞ
¼
R smax
0
ds
R bmax
0
db pðNon; s; bjMsþb; IoffÞ
R bmax
0
db pðNon; bjMb; IoffÞ
¼
R smax
0
ds
R bmax
0
db pðsjb; Msþb; IoffÞpðbjMsþb; IoffÞpðNonjs; b; Msþb; IoffÞ
R bmax
0
db pðbjMb; IoffÞpðNonjb; Mb; IoffÞ
¼
R smax
s¼0 ds
R bmax
b¼0 db
1
smax
T
ð1þNoffÞ
off
bNoffebToff
Noff!
ðsþbÞNonTNon
on eðsþbÞTon
Non!
R bmax
b¼0 db
T
ð1þNoffÞ
off
bNoffebToff
Noff!
bNonTNon
on ebTon
Non!
¼
R smax
s¼0 ds
1
smax
R bmax
b¼0 db bNoffebToffðs þ bÞNoneðsþbÞTon
R bmax
b¼0 db bðNonþNoffÞebðTonþToffÞ
¼ Num1
Den1 ;
(D:19)
448
Appendix D

where Ioff ¼ Noff; Ib, as defined in Equation (14.21). Comparing Equation (D.19) to
Equation (D.6), we see that Num1 ¼ 1=smax Den, which we have already evaluated in
Equation (D.16). All that remains is to evaluate Den1, which we do here:
Den1 ¼
Z bmax
b¼0
db bðNonþNoffÞebðTonþToffÞ
¼ðTon þ ToffÞðNonþNoffþ1Þ
Z bmax½TonþToff
b¼0
dðb½Ton þ ToffÞ
 ðb½Ton þ ToffÞðNonþNoffÞ ebðTonþToffÞ:
(D:20)
The integral in the above equation is the incomplete gamma function
ð½Non þ Noff þ 1; bmax½Ton þ ToffÞ;
which can be approximated as
ð½Non þ Noff þ 1; bmax½Ton þ ToffÞ  ½Non þ Noff!;
(D:21)
provided bmax½Ton þ Toff  ½Non þ Noff.
Equation (D.20) can be rewritten as
Den1  ðTon þ ToffÞðNonþNoffþ1Þ½Non þ Noff!
(D:22)
Substituting Num1 and Den1 into Equation (D.19), and canceling quantities in
common, yields
Bfsþb;bg 
Non!
smaxTonðNon þ NoffÞ!
X
Non
i¼0
ðNon þ Noff  iÞ!
ðNon  iÞ!
1 þ Toff
Ton

i
:
(D:23)
Poisson ON/OFF details
449

Appendix E
Multivariate Gaussian from maximum entropy
In this appendix, we will derive the multivariate Gaussian distribution of Equation
(8.59) from the MaxEnt principle, given constraint information on the variances
and covariances of the multiple variables. We will start with the simpler case of
only two variables, y1 and y2, and then generalize the result to an arbitrary
number of variables. We assume that the priors for y1 and y2 have the following
form:
mðyiÞ ¼
1
yiHyiL ;
if yiL  yi  yiH
0;
if yiL > yi or yi > yiH.
(
(E:1)
The constraints in this case are:
1. R y1H
y1L
R y2H
y2L pðy1; y2Þdy1dy2 ¼ 1
2.
R y1H
y1L
R y2H
y2L ðy1  1Þ2 pðy1; y2Þ dy1dy2 ¼ 11 ¼ 2
1
3.
R y1H
y1L
R y2H
y2L ðy2  2Þ2 pðy1; y2Þ dy1dy2 ¼ 22 ¼ 2
2
4. R y1H
y1L
R y2H
y2L ðy1  1Þðy2  2Þ pðy1; y2Þ dy1dy2 ¼ 12 ¼ 21
Because mðyiÞ is a constant, we solve for pðy1; y2Þ which maximizes
S ¼ 
Z
pðy1; y2Þ ln ½pðy1; y2ÞdNy;
(E:2)
where N ¼ 2 in this case. The problem then is to maximize pðfyigÞ subject to the
constraints 1 to 4. This optimization is best done as the limiting case of a discrete
problem. Let yi and yj (Roman typeface) represent the discrete versions of y1 and y2,
respectively. Explicitly, we need to find the solution to
d 
X
ij
pij ln pi  
X
ij
pij  1
(
)
 1
2 A1  2
2 A2  3
2 A3
"
#
¼ 0;
(E:3)
450

where
A1 ¼
X
ij
ðyi  iÞ2pij  ii
(
)
A2 ¼
X
ij
ðyj  jÞ2pij  jj
(
)
A3 ¼
X
ij
ðyi  iÞðyj  jÞpij  ij
(
)
;
and
X
ij
¼
X
N
i¼1
X
N
j¼1
:
This leads to
X
ij
 ln pij  1    1
2
1ðyi  iÞ2
n
o

þ 1
2
2ðyj  jÞ2 þ 3ðyi  iÞðyj  jÞ
n
o


dpij ¼ 0:
(E:4)
For each ij, we require
 ln pij  1    1
2
1ðyi  iÞ2 þ 2ðyj  jÞ2 þ 3ðyi  iÞðyj  jÞ
n
o
¼ 0;
(E:5)
or,
pij ¼ e0  exp  1
2
1ðyi  iÞ2 þ 2ðyj  jÞ2 þ 3ðyi  iÞðyj  jÞ
n
o


;
(E:6)
where 0 ¼ 1 þ .
This generalizes to the continuum assignment
pðy1; y2Þ ¼ expf0g
 exp  1
2
1ðy1  1Þ2 þ 2ðy2  2Þ2 þ 3ðy1  1Þðy2  2Þ
n
o


:
(E:7)
To simplify the notation, we will use the abbreviation y1 ¼ ðy1  1Þ and
y2 ¼ ðy2  2Þ. Then Equation (E.7) becomes
pðy1; y2Þ ¼ expf0g exp  1
2 1y2
1 þ 2y2
2 þ 3y1y2




¼ expf0g exp
 Q
2




;
(E:8)
Multivariate Gaussian from maximum entropy
451

where
Q ¼ 1y2
1 þ 2y2
2 þ 3y1y2
¼ 1 y2
1 þ 2
3
21


y1y2 þ 2
3
42
1
y2
2


þ 2y2
2  2
3
41
y2
2
¼ 1 y1 þ 3
21
y2

2
þ 2  2
3
41


y2
2:
(E:9)
In Equation (E.9), we have carried out an operation called completing the squares,
which will help us in our next step, evaluating 0 from constraint number 1.
Z y1H
y1L
Z y2H
y2L
pðy1; y2Þdy1dy2 ¼
Z y1H
y1L
Z y2H
y2L
e0 exp  Q
2


¼e0
Z y2H
y2L
dy2 exp  1
2
2  2
3
41


y2
2



Z y1H
y1L
dy1 exp  1
2
y1 þ 3
21
y2

2
"
#
¼ 1:
(E:10)
The second integrand in Equation (E.10) is a Gaussian in dy1, with variance 1=1. If
the range of integration were infinite, the integral would merely be a constant (the
normalization constant for the Gaussian,
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2p=1
p
). With a finite range, it can be
written in terms of error functions with arguments that depend on y2. But, as we
showed in Section 8.7.4, as long as the limits y1H and y1L lie well outside the region
where there is a significant contribution to the integral, then the limits can effectively
be replaced by þ1 and 1, which is what we assume here.
The first integrand in Equation (E.10) is another Gaussian in dy2. We will also
assume that range of integration is effectively infinite, so the integrand evaluates to the
normalization constant,
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2p=ð2  2
3=41Þ
q
. Equation (E.10) thus simplifies to
e0
2p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
12 
2
3
4
q
¼ 1:
(E:11)
The solution is
e0 ¼ 1
2p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
12  2
3
4
r
:
(E:12)
We now make use of Equation (8.22) to evaluate the remaining Lagrange multi-
pliers, 1, 2 and 3.
 @0
@1
¼ 1
2 hðy1  1Þ2i ¼ 11
2 ;
(E:13)
452
Appendix E

 @0
@2
¼ 1
2 hðy2  2Þ2i ¼ 22
2 ;
(E:14)
 @0
@3
¼ 1
2 hðy1  1Þðy2  2Þi ¼ 12
2 :
(E:15)
Note: the extra factor of 2 appearing in the denominator on the right hand side of
Equations (E.13), (E.14), (E.15), when compared to Equation (8.22), arises from the
factor of 1/2 introduced in front of 1, 2 and 3 in Equation (E.4), which defines the
meaning of these Lagrange multipliers.
The solutions to Equations (E.13), (E.14), and (E.15) are as follows:
1 ¼
22
1122  2
12
;
(E:16)
2 ¼
11
1122  2
12
;
(E:17)
3 ¼
212
1122  2
12
:
(E:18)
Equation (E.12) for the term e0 can now be expressed in terms of 11, 22 and 12
as follows:
e0 ¼
1
2p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1122  2
12
q
:
(E:19)
At this point, it is convenient to rewrite Q, which first appeared in Equation (E.8), in
the following matrix form:
Q ¼ ðy1y2Þ
1
3=2
3=2
2
 
!
y1
y2
 
!
¼ YTE1Y:
(E:20)
The E1 matrix, which stands for the inverse of the E matrix, can be expressed in terms
of 11, 22 and 12 as follows:
E1 ¼
1
1122  2
12
22
12
12
11


:
(E:21)
Although E1 is rather messy, the E matrix itself is a very simple and useful matrix.
E ¼
11
12
12
22


:
(E:22)
Multivariate Gaussian from maximum entropy
453

Now substitute Equations (E.20) and (E.19) into Equation (E.8) to obtain a final
equation for pðy1; y2Þ.
pðy1; y2Þ ¼
1
2p
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1122  2
12
q
exp  1
2 YTE1Y




¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2 YTE1Y




;
(E:23)
where N ¼ 2 for two variables. Equation (E.23) is also valid for an arbitrary number
of variables,1 which we write as
pðfyigjfi; ijgÞ ¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2 YTE1Y




¼
1
ð2pÞN=2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
det E
p
exp  1
2
X
ij
ðyi  iÞ½E1ijðyj  jÞ
"
#
;
(E:24)
where
E ¼
11
12
13
  
1N
21
22
23
  
2N





N1
N2
N3
  
NN
0
B
B
@
1
C
C
A:
(E:25)
The E matrix is called the data covariance matrix when each y variable describes
possible values of a datum, di.
1 ?In Equation (E.24), fyig refers to a set of continuous variables.
454
Appendix E

References
Acze´ l, J. (1966). Lectures on Functional Equations and their Applications. New York:
Academic Press. See also Aczel, J. (1987), A Short Course on Functional
Equations, Dordrecht–Holland: D. Reidel.
Barber, M. N., Pearson, R. B., Toussaint, D., and Richardson, J. L. (1985). Finite-size
scaling in the three-dimensional Ising model. Physics Review B, 32, 1720–1730.
Bayes, T. (1763). An essay toward solving a problem in the doctrine of chances.
Philosophical Transactions of the Royal Society, pp. 370–418.
Berger, J. O. and Berry, D. A. (1988). Statistical analysis and the illusion of objectivity.
American Scientist, 76, 159–165.
Berger, J. O. and Sellke, T. (1987). Testing a point null hypothesis: The
irreconcilability of p-values and evidence. Journal of the American Statistical
Association, 82, 112–122.
Bernoulli, J. (1713). Ars conjectandi, Basel: Thurnisiorum. Reprinted in Die Werke von
Jakob Bernoulli, Vol. 3, Basel: Birkhaeuser, (1975), pp. 107–286.
Blackman, R. B. and Tukey, J. W. (1958). The Measurement of Power Spectra. New
York: Dover Publications, Inc.
Boole, G. (1854). An Investigation of the laws of Thought. London: Macmillan;
reprinted by Dover Publications, New York (1958).
Bretthorst, G. L. (1988). Bayesian Spectrum Analysis and Parameter Estimation.
New York: Springer-Verlag.
Bretthorst, G. L. (1990a). Bayesian analysis. I. Parameter estimation using quadrature
NMR models. Journal of Magnetic Resonance, 88, 533–551.
Bretthorst, G. L. (1990b). Bayesian analysis. II. Signal detection and model selection.
Journal of Magnetic Resonance, 88, 552–570.
Bretthorst, G. L. (1990c). Bayesian analysis. III. Applications to NMR signal
detection, model selection, and parameter estimation. Journal of Magnetic
Resonance, 88, 571–595.
Bretthorst, G. L. (1991). Bayesian analysis. IV. Noise and computing time
considerations. Journal of Magnetic Resonance, 93, 369–394.
Bretthorst, G. L. (1993). On the difference in means. In Physics & Probability Essays in
honor of Edwin T. Jaynes, W. T. Grandy and P. W. Milonni (eds.). England:
Cambridge University Press.
Bretthorst, G. L. (2000a). Nonuniform sampling: Bandwidth and aliasing. In Maximum
Entropy and Bayesian Methods in Science and Engineering, J. Rychert,
G. Erickson, and C. R. Smith (eds.). USA: American Institute of Physics,
pp. 1–28.
455

Bretthorst, G. L. (2001). Generalizing the Lomb–Scargle periodogram. In Bayesian
Inference and Maximum Entropy Methods in Science and Engineering, Paris
Ali Mohammad-Djafari (ed.). New York: American Institute of Physics
Proceedings, 568, 241–245.
Brigham, E. O. (1988). The Fast Fourier Transform and Its Applications, New Jersey:
Prentice Hall.
Buck, B. and MaCaulay V. A. (eds.) (1991). Maximum Entropy in Action. Oxford
Science Publication, Oxford: Clarendon Press.
Charbonneau, P. (1995). Genetic algorithms in astronomy and astrophysics.
Astrophysical Journal (Supplements), 101, 309–334.
Charbonneau, P. and Knapp, B. (1995). A User’s guide to PIKAIA 1.0, NCAR
Technical Note 418+IA. Boulder: National Center for Atmospheric Research.
Chib, S. and Greenberg, E. (1995). Understanding the Metropolis algorithm.
American Statistician, 49, 327–335.
Chu, S. (2003). Using soccer goals to motivate the Poisson process. INFORMS
ransactions onEducation, 3(2) http://ite.pubs.informs.org/Vol3No2/Chu/index.php.
Cooley, J. W. and Tukey, J. W. (1965). An algorithm for the machine calculation of
complex fourier series. Mathematics of Computing, 19, 297–301.
Cox, R. T. (1946). Probability, frequency, and reasonable expectation. American
Journal of Physics, 17, 1–13.
Cox, R. T. (1961). The Algebra of Probable Inference, Baltimore, MD: Johns Hopkins
University Press.
D’Agostini, G. (1999). Bayesian Reasoning in High-Energy Physics: Principles and
Applications. CERN Yellow Reports.
Dayal, Hari H. (1972). Bayesian statistical inference in Behrens–Fisher Problems,
Ph.D. dissertation, State University of New York at Buffalo, September 1972.
Dayal., Hari H. and James M. Dickey, (1976), Bayes factors for Behrens–Fisher
problems. The Indian Journal of Statistics, 38, 315–328.
Delampady, M. and Berger, J. O. (1990). Lower bounds on Bayes factors for
multinomial distributions, with applications to chi-squared tests of fit. Annals
of Statistics, 18, 1295–1316.
Feigelson E. D. and Babu, G. J. (eds.) (2002). Statistical Challenges in Modern
Astronomy III. New York: Springer-Verlag.
Fernandez, J. F. and Rivero, J. (1996). Fast algorithms for random numbers with
exponential and normal distributions. Computers in Physics, 10, 83–88.
Fox, C. and Nicholls, G. K. (2001). Exact MAP states and expectations from perfect
sampling: Greig, Porteous and Seheult revisited. In Bayesian Inference and
Maximum Entropy Methods in Science and Engineeering, Paris. Ali Mohammad-
Djafari (ed). New York: American Institute of Physics Proceedings, 568, 252–263.
Geyer, C. and Thompson, E. (1995). Annealing Markov chain Monte Carlo with
applications to ancestral inference. Journal of the American Statistical
Association, 90, 909–920.
Gilks, W. R., Richardson, S. and Spiegelhalter, D. J. (1996). Markov Chain Monte
Carlo in Practice. London: Chapman and Hall.
Goggans, P. M. and Chi, Y. (2004). Using thermodynamic integration to calculate the
posterior probability in Bayesian model selection problems. In Bayesian Inference
and Maximum Entropy Methods in Science and Engineering, Proceedings, 23rd
International Workshop, G. Erickson and Y. X. Zhai (eds.). USA: American
Institute of Physics, pp. 59–66.
456
References

Gregory, P. C. (1999). Bayesian periodic signal detection: Analysis of 20 years of radio
flux measurements of LS I+618 303. Astrophysical Journal, 520, 361–375.
Gregory, P. C. (2001). A Bayesian revolution in spectral analysis. In Bayesian
Inference and Maximum Entropy Methods in Science and Engineeering, Paris. Ali
Mohammad-Djafari, (ed.) New York: American Institute of Physics
Proceedings, 568, 557–568.
Gregory, P. C.(2002). Bayesian analysis of radio observations of the Be X-ray binary
LS I+618 303. Astrophysical Journal, 575, 427–434.
Gregory, P. C. and Loredo, T. J. (1992). A new method for the detection of a periodic
signal of unknown shape and period. Astrophysical Journal, 398, 146–168.
Gregory, P. C. and Loredo, T. J. (1993). A Bayesian method for the detection of
unknown periodic and non-periodic signals in binned time series. In Maximum
Entropy and Bayesian Methods, Paris. Ali Mohammad-Djafari and G. Demoment,
(eds.). Dordrecht: Kluwer Academic Press, pp. 225–232.
Gregory, P. C. and Loredo, T. J. (1996). Bayesian periodic signal detection: Analysis
of ROSAT observations of PSR 0540-693. Astrophysical Journal, 473, 1059–1066.
Gregory, P. C. and Neish, C. (2002). Density and velocity structure of the Be star
equatorial disk in the binary, LS I+618 303, a probable microquasar.
Astrophysical Journal, 580, 1133–1148.
Gregory, P. C. and Taylor, A. R. (1978). New highly variable radio source, possible
counterpart of gamma-ray source CG 135+1. Nature, 272, 704–706.
Gregory, P. C., Xu, H. J., Backhouse, C. J. and Reid, A. (1989). Four-year modulation
of periodicradiooutburstsfromLSI+618303.AstrophysicalJournal, 339,1054–1058.
Gregory, P. C., Peracaula, M. and Taylor, A. R. (1999). Bayesian periodic signal
detection: Discovery of periodic phase modulation in LS I+618 303 radio
outbursts. Astrophysical Journal, 520, 376–390.
Gull, S. F. (1988). Bayesian inductive inference and maximum entropy. In Maximum
Entropy & Bayesian Methods in Science and Engineering, G. J. Erickson and C. R.
Smith (eds.). Dordrecht: Kluwer Academic Press, pp. 53–74.
Gull, S. F. (1989a). Developments in maximum entropy data analysis. in Maximum
Entropy & Bayesian Methods, J. Skilling (ed.), Dordrecht: Kluwer Academic
Press. pp. 53–71.
Gull, S. F. (1989b). Bayesian data analysis – straight line fitting. In Maximum Entropy
& Bayesian Methods, J. Skilling (ed.). Dordrecht: Kluwer Academic Press,
pp. 511–518.
Gull, S. F., and Skilling, J. (1984). Maximum entropy method in image processing.
IEEE Proceedings, 131, Part F, (6) 646–659.
Hastings, W. K. (1970). Monte Carlo Sampling methods using Markov chains and
their applications. Biometrika, 57, 97–109.
Helene, O. (1983). Upper limit of peak area. Nuclear Instruments and Methods, 212,
319–322.
Helene, O. (1984). Errors in experiments with small numbers of events. Nuclear
Instruments and Methods, 228, 120–128.
Holland, J. (1992). Genetic algorithms. Scientific American, July, 66–72.
Hutchings, J. B. and Crampton, D. (1981). Spectroscopy of the unique degenerate
binary star LS I+618 303. PASP, 93, 486–489.
James, F. (1998). MINUIT, Function Minimization and Error Analysis Reference
Manual, Version 94.1. Computing and Network Division, CERN Geneva,
Switzerland.
References
457

Jaynes, E. T. (1957). How does the brain do plausible reasoning? Stanford University
Microwave Laboratory Report 421. Reprinted in Maximum Entropy and
Bayesian Methods in Science and Engineeering, G. J. Erickson and C. R. Smith
(eds.) (1988). Dordrecht: Kluwer Academic Press.
Jaynes, E. T. (1968). Prior probabilities. IEEE Transactions on System Science &
Cybernetics, 4(3), 227–241.
Jaynes, E. T. (1976). Confidence intervals vs Bayesian intervals. In Foundations
of Probability Theory, Statistical Inference, and Statistical Theories of
Science, 2, pp. 175–257, W. L. Harper and C. A. Hooker (eds.). Dordrecht:
D. Reidel.
Jaynes, E. T. (1982). On the Rationale of Maximum Entropy Methods. Proceedings of
the IEEE, 70(9), 939–952.
Jaynes, E. T. (1983). Papers on Probability, Statistics and Statistical Physics, a reprint
collection. Dordrecht: D. Reidel. Second edition, Dordrecht: Kluwer Academic
Press, (1989).
Jaynes, E. T. (1987). Bayesian spectrum and chirp analysis. In Maximum Entropy and
Bayesian Spectral Analysis and Estimation Problems, C. R. Smith and G. L.
Erickson (eds.). Dordrecht: D. Reidel, pp. 1–37.
Jaynes, E. T. (1990). Probability theory as logic. In Maximum-Entropy and Bayesian
Methods, P. F. Fougre (ed.). Dordrecht: Kluwer, pp. 1–16.
Jaynes, E. T. (2003). Probability Theory – The Logic of Science, G. L. Bretthorst (ed.).
Cambridge: Cambridge University Press.
Jeffreys, H. (1931). Scientific Inference. Cambridge: Cambridge University Press.
Later editions, 1937, 1957, 1973.
Jeffreys, H. (1932). On the theory of errors and least squares. Proceedings of the Royal
Society, 138, 48–55.
Jeffreys, H. (1939). Theory of Probability. Oxford: Clarendon Press. Later editions,
1948, 1961, 1967, 1988.
Jeffreys, W. H. and Berger, J. O. (1992). Ockham’s razor and Bayesian analysis.
American Scientist, 80, 64–72.
Jenkins, G. M. and Watts, D. G. (1968). Spectral Analysis and its Applications, San
Francisco: Holden Day.
Kirkpatrick, S., Gelatt, C. D., and Vecchi, M. P. (1983). Optimisation by simulated
annealing. Science, 220, 671–680.
Knuth, D. (1981). Seminumerical algorithms, 2nd edn, vol. 2 of The Art of Computer
Programming. Reading, MA: Addison-Wesley.
Laplace, P. S. (1774). Me´moire sur la probabilite´ des causes par les e´ve´nements.
Me´ moires de l’Acade´ mie royale des sciences, 6, 621–656. Reprinted in Laplace
(1878–1912), vol. 8, pp. 27–65, Paris: Gauthier–Villars, English translation by
S. M. Stigler (1986).
Lindley, D. V. (1965). Introduction to Probability and Statistics, (Part 1 – Probability
and Part 2 – Inference). Cambridge: Cambridge University Press.
Liu, J. S. (2001). Monte Carlo Strategies in Scientific Computing. Springer Series in
Statistics. New York: Springer-Verlag.
Lomb, N. R. (1976). Least squares frequency analysis of unevenly spaced data.
Astrophysical and Space Sciences, 39, 447–462.
Loredo, T. J. (1990). From Laplace to Supernova SN 1987A: Bayesian inference in
astrophysics. Maximum Entropy and Bayesian Methods, Dartsmouth. P. Fouge` re
(ed.). Dordrecht: Kluwer Academic Press, pp. 81–142.
458
References

Loredo, T. J. (1992). The promise of Bayesian inference for astrophysics. In Statistical
Challenges in Modern Astronomy, E. D. Feigelson and G. J. Babu (eds.). New
York: Springer-Verlag, pp. 275–297.
Loredo, T. J. (1999). Computational technology for Bayesian inference. In ASP
Conference Series, Vol. 172, Astronomical Data Analysis Software and Systems
VIII, D. M. Mehringer, R. L. Plante, and D. A. Roberts (eds.). San Fransisco:
Astronomical Society of the Pacific, pp. 297–306.
Maddox, J. (1994). The poor quality of random numbers. Nature, 372, 403.
Marple, S. L. (1987). Digital Spectral Analysis (Appendix 4a). Englewood Cliffs,
NJ: Prentice Hall.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., and Teller, E. (1953).
Equation of state calculation by fast computing machines. Journal of Chemical
Physics, 21, 1087–1092.
Nedler, J. A. and Mead, R. (1965). A simple method for function minimizations.
Computing Journal, 7, 308–313.
Paredes, J. M., Estelle, R. and Ruis, A. (1990). Observation at 3.6 cm wavelength of
the radio light curve of LS I+618 303. Astronomy and Astrophysics, 232, 377–380.
Park, S. K. and Miller, K. W. (1988). Random number generators: good ones are hard
to find. Communications of the Association for Computing Machinery, 31 (10),
1192–1201.
Pin˜ a, R. K. and Puetter, R. C. (1993). Bayesian image reconstruction: the Pixon and
optimal image modeling. Proceedings of the Astronomical Society of the Pacific.
105, 630–637.
Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P. (1992).
Numerical Recipes (second edition). Cambridge: Cambridge University Press.
Priestley, M. B. (1981). Spectral Analysis and Time Series. London: Academic Press.
Puetter, R. C. (1995). Pixon-based multiresolution image reconstruction and the
quantification of picture information content. International Journal of Image
Systems & Technology, 6, 314–331.
Ray, P. S., Foster, R. S., Waltman, E. B. et al. (1997). Long term monitoring of LS
I+618 303 at 2.25 and 8.3 GHz. Astrophysical Journal, 491, 381–387.
Roberts, G. O. (1996). Markov chain concepts related to sampling algorithms. In
Markov Chain Monte Carlo in Practice, W. R. Gilks, S. Richardson, and D. J.
Spiegelhalter (eds.). London: Chapman and Hall. pp. 45–57.
Roberts, G. O., Gelman, A. and Gilks, W. R. (1997). Weak convergence and optimal
scaling of random walk Metropolis algorithms. Annals of Applied Probability, 7,
110–120.
Scargle, J. D. (1982). Studies in astronomical time series analysis II. Statistical aspects of
spectral analysis of unevenly sampled data. Astrophysical Journal, 263, 835–853.
Scargle, J. D. (1989). Studies in astronomical time series analysis III. Autocorrelation
and cross-correlation functions of unevenly sampled data. Astrophysical Journal,
343, 874–887.
Schuster, A. (1905). The periodogram and its optical analogy. Proceedings of the
Royal Society of London, 77, 136–140.
Sellke, T., Bayarri, M. J. and Berger, J. O. (2001). Calibration of P-values for testing
precise null hypotheses. The American Statistician, 55, 62–71.
Seward, F. D., Harnden, F. R., and Helfand, D. J. (1984). Discovery of a 50
millisecond pulsar in the Large Magellanic Cloud. Astrophysical Journal Letters,
287, L19–22.
References
459

Shannon, C. E. (1948). Bell Systems Tech. J., 27, 379, 623; these papers were reprinted
in C. E. Shannon and W. Weaver, The Mathematical Theory of Communication,
Urbana: University of Illinois Press, (1949).
Shore, J. and Johnson, R. (1980). Axiomatic derivation of the principle of maximum
entropy and the principle of minimum cross-entropy. IEEE Transactions on
Information Theory, 26, 26–37.
Sivia, D. S. (1996). Data Analysis: A Bayesian Tutorial. Oxford: Clarendon Press.
Skilling, J. (1988). The axioms of maximum entropy. In Maximum Entropy & Bayesian
Methods on Science and Engineering, Vol. 1, G. J. Erickson and C. R. Smith
(eds.). Dordrecht: Kluwer Academic Press, p. 173.
Skilling, J. (1989). Classical maximum entropy. In Maximum Entropy & Bayesian
Methods, J. Skilling (ed.). Dordrecht: Kluwer Academic Press, pp. 45–52.
Skilling, J. (1998). Probabilistic data analysis: an introductory guide. Journal of
Microscopy, 190, 297–302.
Skilling, J. and Gull, S. F. (1985). Algorithms and applications. In Maximum Entropy
& Bayesian Methods in Inverse Problems, C. R. Smith and W. T. Grandy, Jr.
(eds.), pp. 83–132.
Stigler, S. M. (1986). Laplace’s 1774 memoir on inverse probability. Translation of
Laplace’s 1774 Memoir on ‘‘Probability of Causes.’’ Statistical Science, 1,
359–378.
Taylor, A. R. and Gregory, P. C. (1982). Periodic radio emission from LS I+618 303.
Astrophysical Journal, 255, 210–216.
Tierney, L. and Kadane, J. B. (1986), Accurate approximations for posterior moments
and densities. J. American Statistical Association, 81, 82–86.
Tinney, C. G., Butler, R. P., Marcy, G. W., Jones, H. R. A., Penny, A. J., McCarthy,
C., Carter, B. D., and Bond, J. (2003). Four new planets orbiting metal-enriched
stars. Astrophysical Journal, 587, 423–428.
Toussaint, D. (1989). Introduction to algorithms for Monte Carlo simulations and
their application to QCD. Computational Physics Communications, 56, 69–92.
Tribus, M. (1969). Rational Descriptions, Decisions and Designs. Oxford: Pergamon
Press.
Vattulainen, I., Ala-Nissila, T., and Kankaala, K. (1994). Physical tests for random
numbers in simulations. Physical Review Letters, 73, 2513–2516.
Wolfram, S. (1999). The Mathematica Book (fourth edition). Cambridge: Cambridge
University Press.
Wolfram, S. (2002). A New Kind of Science. Champaign, IL: Wolfram Media, Inc.
460
References

Index
Terms followed by [ ] are Mathematica commands.
2 cumulative distribution, 165
2 distribution, 141
moment generating function, 142
properties, 141
2 statistic, 163, 164, 279
absorption lines, 331
acceptance probability, 314
acceptance rate, 319, 331
ACF, 134, 318
adequate set of operations, 26
aliasing, 392, 405
alternative hypothesis, 170
amplitudes, most probable, 249
AND, 28
anti-correlation,
see negative covariance
apodizing function, 366
APT MCMC
automated MCMC, 331, 341
AR, 431
ARMA, 431
asymptotic covariance matrix, 305
asymptotic normal approximation, 288
autocorrelation, 318
autocorrelation function, 134, 274, 318
autocorrelation spectrometer, 427
automated MCMC, 330
autoregressive, see AR
autoregressive-moving average, see ARMA
basis function, 245, 247
Bayes factor, 46, 53, 326
Bayes’ theorem, 42, 45, 61, 72, 76, 77, 84,
125, 184, 206, 213, 219, 231, 245,
321, 377, 382
model of inductive inference, 7
usual form, 5
Bayesian, 87
advantages, 16
frequentist comparison, 87
Bayesian analysis
detailed example, 50
Bayesian inference
basics, 41
how-to, 41
Poisson distribution, 376
Bayesian mean estimate, 212
unknown noise, 218
Bayesian noise estimate, 224
Bayesian probability theory, 2
Bayesian revolution, 26
Bayesian versus frequentist, 87
Be star, 363
bed of nails, 400, 404, 407
Behrens–Fisher problem, 228, 441
Bernoulli’s law of large numbers, 75
illustration, 76
beta distribution, 117
bimodal, 123
binomial distribution, 74
Bayesian, 72
binomial expansion, 74
BinomialDistribution[ ], 75
Blackman–Tukey
procedure, 427
Boolean algebra, 22
Boolean identities, 24
associativity, 24
commutativity, 24
distributivity, 24
duality, 24
idempotence, 24
Bretthorst, G. L., 228
burn-in period, 314, 316, 319,
323, 329, 331
461

Cauchy, 124
causal consequence, 25
CDF[ ], 149, 151
CDF[BinomialDistribution½n; p; x, 108
CDF[NormalDistribution½; ; x, 113, 115
Central Limit Theorem, 105, 113, 119, 219
Bayesian demonstration, 120
exceptions, 124
central tendency, 103
ChiSquarePValue[ ], 166
coefficient of
kurtosis, 102
skewness, 102
column density, 50
column matrix, 258
common sense, 25, 29
completeness, 394
compound LCG, 131
compound propositions, 22, 42
condition number, 391
confidence coefficient, 153
confidence interval, 78, 153, 215
for 
variance known, 152
variance unknown, 156
for 2, 159
for difference of means, 158
ratio of two variances, 159
conjugate distribution, 118
conjugate prior distributions, 118
constraint
minimal, 194
continuous distributions, 113
continuous hypothesis space, 6
continuous random variable, 99
ContourPlot[ ], 19
control, 158, 434
control system, 331
convention, 114
convolution, 392, 398
importance in science, 401
radio astronomy example, 402
using an FFT, 417
convolution integral, 90, 121, 398
convolution theorem, 399
discrete, 407, 417
core sample, 200
correlation, 318, 392
using an FFT, 417
correlation coefficient, 268, 274
correlation spectrum estimation, 426
correlation theorem, 400
courtroom analogy, 171
covariance matrix, 280, 291
data errors, 253
inverse data, 253
parameters, 264
Cox, R.T., 4, 26
credible region, 44, 78, 215, 260, 378
cross-entropy, 190
cumulative density function, 149
cumulative distribution function, 99, 100, 108
gamma, 116
Gaussian, 114
normal, 114
curvature matrix, 299, 300
data covariance matrix, 253, 454
inverse, 253
deconvolution, 418
deductive inference, 1, 24
degree of confidence, 153
degree of freedom, 141
desiderata, 4, 26, 29, 30
consistency, 30
Jaynes, 30
propriety, 30
structural, 30
rationality, 30
design matrix, 390
detailed balance, 320
DFT, 392, 407
approximation, 411
approximation of inverse, 413
discontinuity treatment, 412
graphical development, 407
interesting results, 411
inverse, 410
mathematical development, 409
diagonal matrix, 259
difference in means and/or variances
hypotheses, 434
difference in two samples, 434
differentiable, 126
Dirac delta function, 404
Discrete Fourier Transform, see DFT
discrete random variables, 99
disjunctive normal form, 28
dispersion, 101, 105
dispersion measure, 103
distribution function
cumulative, see cumulative distribution function
distributions, 98
2, 141
beta, 117
binomial, 72, 74, 107
continuous, 113
descriptive properties of, 100
462
Index

discrete probability, 107
Erlang, 117
exchangeable, 83
F, 150
F statistic, 282
gamma, 116
Gaussian, 113
geometric, 112
hypergeometric, 83
multinomial, 79, 80, 174
negative binomial, 112
negative exponential, 118
normal, 113
Poisson, 85, 109, 376
Student’s t, 147, 222
uniform, 116
Doppler shift, 331
downhill simplex method, 296
eigenvalues, 259
Eigenvalues[ ], 260, 263
eigenvectors, 259, 390
encoding, 72
end effects, 421
energy spectral density, 425
entropy generalization incorporating prior, 190
epoch folding, 362, 363
equally natural parameterization, 220
erf½z; see error function
Erlang distribution, 117
error function, 115, 198, 436
errors in both coordinates, 92, 307
ESD, see energy spectral density
exchangeable distributions, 83
exclusive hypothesis, 42
exercises
spectral line problem, 69
expectation value, 100, 144
experimental design
non-uniform sampling, 371
exponential notation, 395
extended sum rule, 5, 35
extrasolar planets, 331
F distribution, 150
mode, 150
properties, 150
variance, 150
F-test, 150
Fast Fourier Transform, 392, 415
accurate amplitudes, 422
how it works, 415
zero padding, 422
FFT, see Fast Fourier Transform
first moment, see expectation value
Fisher information matrix, 291
Flatten[ ], 263
Fourier analysis, 392
Fourier series, 394
Fourier spectrum, 132
Fourier transform, 396
Fourier[ ], 358, 411
FRatioPValue[ ], 182
frequency, 10, 11
frequentist, 2, 78, 96, 162
full period, 131
gambler’s coin problem, 75
gamma function, 116
Gamma[=2; 2
crit=2], 261
GammaRegularized[ ], 147, 166, 280
Gaussian, 48
line shape, 50
noise, 55, 91
Gaussian distributions, 123
Gaussian moment generating function, 114
Gaussian posterior, 257
Geiger counter, 386
generalized sum rule, 36, 42
genetic algorithm, 296, 297
geometric distribution, 112
GL method, 360
global likelihood, 44, 46, 275, 326
global minimization, 296
Gregory–Loredo method, see GL method
half-life, 386
Hessian matrix, 299
historical perspective recent, 25
HIV, 11
Hubble’s constant, 16, 66
hypergeometric distribution, 81
HypergeometricDistribution[ ], 82
hypothesis, 4, 21
exclusive, 42
of interest, 5
hypothesis space, 5, 52
continuous, 6
discrete, 5, 6
hypothesis testing, 162
2 statistic, 163
difference of two means, 167
one- and two-sided, 170
sameness, 172
ignorance priors, 63
IID, 119
ill-conditioned, 391
Index
463

image model, 208
image reconstruction, 203
pixon, 208
implication, 26
implication operation, 25
impulse function, 404
incomplete gamma function, 261, 437, 446
incomplete information, 1, 4, 29, 206
incomplete set, 131
independent errors, 90
independent random events, 55, 109
inductive inference, 25
inference
Bayesian, 5
deductive, 1, 24
inductive, 25
plausible, 25
statistical, 3
inner product, 393
inverse DFT, 410
Inverse[ ], 256
InverseFourier[ ], 411
iterative linearization, 296, 298
Jaynes, E. T., 2, 26
Jeffreys prior, 54, 220
modified, 386
joint posterior, 219
joint prior distribution, 45
joint probability, 7, 19
Keplerian orbit, 331
Kolmogorov–Smirnov test, 173
Kullback entropy, 190
kurtosis, 101
lag, 318
Lagrange multipliers, 191
Laplacian approximations, 291
Bayes factor, 291
marginal parameter posteriors, 293
LCG, 131
least-squares model fitting, 244
least-squares problem, 389
Lebesgue measure, 191
leptokurtic distribution, 102
Levenberg–Marquardt method, 296, 298,
300
lighthouse problem, 125
likelihood
characteristic width of, 47
global, 326
likelihood function, 5, 89
likelihood ratio, 49, 53
line strength
posterior, 60
linear congruential generators, 131
linear least-squares, 243
linear models, 243
linearly independent, 252
logic function, 27
logical disjunction, 42
logical product, 26
logical proposition, 21
logical sum, 26
exclusive form, 22
logical versus causal connections, 82
logically equivalent, 22
Lomb–Scargle periodogram, 367
long-run frequency, 75
long-run relative frequency, 2
Lorentzian, 124
MA, 431
MAP
maximum a posteriori, 343
marginal distribution, 263
marginal PDF, 263
marginal posterior, 45
marginal probability, 19
marginalization, 12, 16, 45
marginalization integral, 249
Markov chain, 314
Markov chain Monte Carlo, 312
Martian rover, 200
matrix formulation, 251, 253
MaxEnt, 184
alternative derivation, 187
classic, 207
computing pi values, 191
continuous probability distribution, 191
exponential distribution, 195
Gaussian distribution, 197
generalization, 190
global maximum, 192
image reconstruction, 203
kangaroo justification, 203
multivariate Gaussian, 450
noisy constraints, 206
uniform distribution, 194
maximally non-committal, 185
maximum entropy principle,
see MaxEnt
maximum likelihood, 56
MCMC, 312
acceptance rate, 319, 330
annealing parameter, 325, 327
aperiodic, 319
464
Index

automated, 330
Bayes factor, 326
burn-in period, 331
control system, 330, 331
convergence speed, 318
detailed balance, 320
model comparison, 326
parallel simulations, 322
parallel tempering, 321
partition function, 326
robust summary statistic, 342
sample correlations, 318
simulated tempering, 321
stationary distribution, 319
temperature parameter, 321
when to stop, 319
mean, 44, 100, 343
Poisson, 110
mean deviation, 105
mean square deviation, 214
Mean[BinomialDistribution[n, p]], 109
MeanCI[ ], 182
MeanCI[data, KnownVariance], 156
MeanDifferenceTest[ ], 170, 182
median, 103, 343
baseline subtraction, 104
running subtraction, 104
metric, 253
Metropolis algorithm, 297, 314
Metropolis ratio, 314
Metropolis–Hastings
why it works, 319
Metropolis–Hastings algorithm, 313
mind projection fallacy, 98
mode, 44
model, 21
deterministic, 90
probabilistic, 91
model comparison, 45, 275, 326
other methods, 281
model fitting, 257
model function, 245
model parameter errors, 264
model selection, 15, 335
model testing
frequentist, 279
models
high dimensional, 288
moderate dimensional, 288
modified Jeffreys prior, 53, 386
moment
about the mean, 106
about the origin, 106, 269
first central, 101
fourth central, 101
second central, 101
third central, 101
moment generating function, 105
2
, 141
binomial distribution, 99, 108
central, 106
Monte Carlo, 127, 296
Monte Carlo integration, 313
most probable model vector, 250
moving average, see MA
MPM
marginal posterior mode, 343
multinomial distribution, 79, 174, 187
multinomial expansion, 80
Multinormal[ ], 433
MultinormalDistribution[ ], 316
multiplicity, 74, 80, 188
multivariate Gaussian, 202, 244
NAND, 29
negation, 26
negative binomial distribution, 112
negative covariance, 268
negative exponential distribution, 118, 119
negatively skewed distribution, 102
NIntegrate [ ], 71
noise
Bayesian estimate, 224
noise scale parameter, 334
non-uniform sampling, 370
nonlinear models
examples, 243, 287
NonlinearRegress [ ], 302
NOR, 29
normal distribution,
see distributions, normal, 103
normal equations, 252
normal Gaussian, 198
NormalDistribution[ ], 132
NOT, 28
notation, 6
NSolve[ ], 263
nuisance parameters, 16, 45, 264
null hypothesis, 162, 164
Nyquist frequency, 370, 405, 413, 429,
430, 432
Nyquist sampling theorem, 392, 404
astronomy example, 406
objectivity, 11
Occam factor, 49, 239, 276
Occam’s razor, 16, 45, 60
odds, see odds ratio
Index
465

odds ratio, 9, 46, 52, 277
Jeffreys prior, 58
prior, 46, 53
sensitivity, 59
uniform prior, 58
versus prior boundary, 61
ON/OFF measurements, 380
operations
implication, 26
logical disjunction, 42
logical product, 26
logical sum, 26
negation, 26
optional stopping problem, 177
Bayesian resolution, 179
OR, 28
orthogonal basis functions, 270
orthogonal functions, 392
orthonormal, 390
orthonormal functions, 276, 392
orthonormal set, 392
P-value, 147, 165, 166
one-sided, 147, 169
PAD, see positive, additive distribution
parallel tempering, 312, 321, 323, 325, 326, 330
parameter
location, 63
scale, 63, 219
parameter covariance matrix, 267, 273, 276, 283
parameter estimation, 12, 15, 43, 59, 244
Parseval’s theorem, 424, 428
discrete form, 428
partition function, 326
PDF, see probability distribution function
Pearson 2
goodness-of-fit test, 173, 175
comparison of two binned data sets, 177
period folding, 362
periodogram, 352
reductive of variance, 431
variance, 429
periodogram power spectrum estimation, 425
Pixon method, 208
planet, 331
platykurtic distribution, 102
plausibility, 3
scale of, 26
plausible inference, 4
Plot3D[ ], 19
point spread function, 402
Poisson
cumulative distribution, 111
mean, 110
time-varying rate, 386
variance, 111
Poisson distribution, 85, 109, 376
Bayesian, 85
examples, 111
infer rate, 377
limiting form of a binomial, 109
ON/OFF measurements, 380
signal and known background,
379
Poisson ON/OFF
details, 445
poll, 153
polling, 77
population, 97
positive definite, 259
positive, additive distribution, 203
positively skewed distribution, 102
posterior
bubble, 44
density, 44
mean, 44
mode, 44
posterior PDF, 44
posterior probability, 5
power spectral density, 425
discrete, 428
one-sided, 429
variance, 429
power spectrum, 426
power-spectrum estimation, 424
power spectral density function, 426
Principal Axis Theorem, 259
Principle of Indifference, 38
prior, 232
choice of, 53
exponential, 195
ignorance, 63
Jeffreys, 54, 57, 220
location parameter, 63
modified Jeffreys, 53
odds ratio, 46
scale parameter, 63
uniform, 53, 57, 377
prior information, 65, 72
prior probability, 5
probability, 10
definition of, 3
distribution, 6
of data value, 56
per logarithmic interval, 54
posterior, 59
relative, 52
relative frequency definition, 98
466
Index

rules for manipulating, 4
weighted average, 236
probability and frequency, 10
probability density, 43
probability density function, 6, 99
Gaussian, 113
probability distribution, 72
probability distribution function, 6, 43
definition, 99
probability mass function, 99
probability theory, 21
as logic, 2
requirements of, 2
role of, 1
product rule, 4, 35, 42
development of, 30
qualitative properties, 36
uniqueness, 37
profile function, 293
projected distribution, 264
projected probability density function, 20, 264
proposal distribution, 314
proposition, 21
examples of, 4
logical, 21
PSD, see power spectral density
correlation estimator, 427
lagged-product estimator, 427
pseudo-random, 127
pseudo-random number generation, 131
PseudoInverse[ ], 391
quantile value, 146, 148
Student’s t, 157
radial velocity, 333
radioactivity, 386
radix, 416
RAN3, 136
random number generation, 127
random variable, 2, 96, 113
continuous, 99
generation, 129
random walk, 132
Random[ ], 132
randomness
tests for, 132
ratio of standard deviations, 442
rectangular matrix, 390
regression analysis, 244, 256
relative frequency definition, 98
relative line shape measures, 101
ripple, 407
RMS deviation, 225
sample mean distribution, 124
sample variance, 143, 164
sampling
non-uniform, 370
sampling distribution, 72, 98
sampling probability, 43
sampling theory, 97
scale invariance, 54
scale parameter, 219
Schuster periodogram, 425
scientific inference, 1
scientific method
model of, 1
SeedRandom[99], 132
serial correlations, 131, 191, 205, 207
Shannon, C., 185, 186
Shannon–Jaynes entropy, 190
Shannon’s theorem, 186
shuffling generator
see compound LCG,, 131
signal averaging, 65, 125
signal variability, 227
signal-to-noise ratio, 354
significance, 147, 165
simulated annealing, 296
simulated tempering, 321
singular basis vectors, 252
singular value decomposition, 252, 389, 389
singular values, 390
SingularValues[ ], 390
skewness, 101
Sort[ ], 70
spatial frequency, 406
spectral analysis, 352
spectral line problem, 50, 322, 329
spectral density function, 426
standard deviation, 55, 101
ratio, 237
standard error of the sample mean, 145, 149
standard random variable, 102, 115, 119,
127, 154
state of knowledge, 72
stationary distribution, 319
statistic, 140
statistical inference, 3
statistics
conventional, 2
frequentist, 2, 96
stellar orbit, 331
Stirling’s approximation, 189
stochastic spectrum estimation, 431
straight line fitting, 92, 307
Student’s t distribution, 147, 222
StudentTPValue[ ], 169, 170, 182
Index
467

sum rule, 4, 35, 42
development of, 34
generalized, 42
qualitative properties, 36
uniqueness, 37
SVD, see singular value decomposition
syllogisms
strong, 24, 28, 36
weak, 25, 28, 36
symmetric matrix, 251
systematic errors, 16, 65, 66, 385
systematic uncertainty
examples of, 65
parameterization of, 65, 386
tapered window function, 407
target distribution, 314
Taylor series expansion, 257, 298
tempering, 312, 321, 323, 326, 328
testable information, 184
time series, 356
time-to-failure, 119
transformation of random variable, 125
transition
kernel, 314
probability, 314
Transpose[ ], 256
trial, 73, 158, 434
truncated Gaussian, 201
truth tables, 22, 27, 132
truth value, 21, 27
two-sample problem, 228, 440
two-sided test, 166
two-valued logic, 21
uncertainty
random, 65
systematic, 65
undetermined multiplier, 192
uniform distribution, 116
uniform prior, 53, 279
unimodal, 291
variable metric approach, 301
variance, 101, 124, 141, 194
Bayesian estimate, 224
variance curve, 282
Variance[BinomialDistribution[n; p]], 109
VarianceCI[ ], 182
VarianceRatioCI[ ], 160
VarianceRatioTest[ ], 182
vector notation, 247
waveform sampling, 403
weighted average, 100
weighting function, 366
Weiner filter, 420
well-posed problem, 7
white noise, 430
Yule, G., 431
Yule–Walker equations, 431
zero pad, 357, 392, 421
zero padding, 421
468
Index

