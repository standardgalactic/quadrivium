Relevant and Substructural Logics
GREG RESTALL∗
PHILOSOPHY DEPARTMENT, MACQUARIE UNIVERSITY
Greg.Restall@mq.edu.au
June 23, 2001
http://www.phil.mq.edu.au/staff/grestall/
Abstract: This is a history of relevant and substructural logics, written for the Hand-
book of the History and Philosophy of Logic, edited by Dov Gabbay and John Woods.1
1
Introduction
Logics tend to be viewed of in one of two ways — with an eye to proofs, or
with an eye to models.2 Relevant and substructural logics are no different:
you can focus on notions of proof, inference rules and structural features of
deduction in these logics, or you can focus on interpretations of the language
in other structures.
This essay is structured around the bifurcation between proofs and mod-
els: The ﬁrst section discusses Proof Theory of relevant and substructural log-
ics, and the second covers the Model Theory of these logics. This order is a
natural one for a history of relevant and substructural logics, because much
of the initial work — especially in the Anderson–Belnap tradition of relevant
logics — started by developing proof theory. The model theory of relevant
logic came some time later. As we will see, Dunn’s algebraic models [76, 77]
Urquhart’s operational semantics [267, 268] and Routley and Meyer’s rela-
tional semantics [239, 240, 241] arrived decades after the initial burst of ac-
tivity from Alan Anderson and Nuel Belnap. The same goes for work on the
Lambek calculus: although inspired by a very particular application in lin-
guistic typing, it was developed ﬁrst proof-theoretically, and only later did
model theory come to the fore. Girard’s linear logic is a different story: it
was discovered though considerations of the categorical models of coherence
∗This research is supported by the Australian Research Council, through its Large Grant pro-
gram. Thanks, too, go to Nuel Belnap, Mike Dunn, Bob Meyer, Graham Priest, Stephen Read and
John Slaney for many enjoyable conversations on these topics.
⟨⟨This is a draft and it is not for citation without permission. Some features are due for severe
revision before publication. Please contact me if you wish to quote this version. I expect to have
a revised version completed before the end of 2001. Please check my website for an updated copy
before emailing me with a list of errors. But once you’ve done that, by all means, ﬁre away!⟩⟩
1The title, Relevant and Substructural Logics is not to be read in the same vein as “apples and
oranges” or “Australia and New Zealand.” It is more in the vein of “apples and fruit” or “Australia
and the Paciﬁc Rim.” It is a history of substructural logics with a particular attention to relevant
logics, or dually, a history of relevant logics, playing particular attention to their presence in the
larger class of substructural logics.
2Sometimes you see this described as the distinction between an emphasis on syntax or se-
mantics. But this is to cut against the grain. On the face of it, rules of proof have as much to
do with the meaning of connectives as do model-theoretic conditions. The rules interpreting a
formal language in a model pay just as much attention to syntax as does any proof theory.
1

http://www.phil.mq.edu.au/staff/grestall/
2
spaces. However, as linear logic appears on the scene much later than rele-
vant logic or the Lambek calculus, starting with proof theory does not result
in too much temporal reversal.
I will end with one smaller section Loose Ends, sketching avenues for fur-
ther work. The major sections, then, are structured thematically, and inside
these sections I will endeavour to sketch the core historical lines of develop-
ment in substructural logics. This, then, will be a conceptual history, indicat-
ing the linkages, dependencies and development of the content itself. I will
be less concerned with identifying who did what and when.3
I take it that logic is best learned by doing it, and so, I have taken the lib-
erty to sketch the proofs of major results when the techniques used in the
proofs us something distinctive about the ﬁeld. The proofs can be skipped or
skimmed without any threat to the continuity of the story. However, to get the
full ﬂavour of the history, you should attempt to savour the proofs at leisure.
Let me end this introduction by situating this essay in its larger context
and explaining how it differs from other similar introductory books and es-
says. Other comprehensive introductions such as Dunn’s “Relevance Logic
and Entailment” [81] and its descendant “Relevance Logic” [94], Read’s Rel-
evant Logic [224] and Troelstra’s Lectures on Linear Logic [264] are more nar-
rowly focussed than this essay, concentrating on one or other of the many
relevant and substructural logics. The Anderson–Belnap two-volume Entail-
ment [10, 11] is a goldmine of historical detail in the tradition of relevance
logic, but it contains little about other important traditions in substructural
logics.
My Introduction to Substructural Logics [234] has a similar scope to this
chapter, in that it covers the broad sweep of substructural logics: however,
that book is more technical than this essay, as it features many formal re-
sults stated and proved in generality. It is also written to introduce the subject
purely thematically instead of historically.
2
Proofs
The discipline of relevant logic grew out of an attempt to understand notions
of consequence and conditionality where the conclusion of a valid argument
is relevant to the premises, and where the consequent of a true conditional is
relevant to the antecedent.
“Substructural” is a newer term, due to Schr¨oder-Heister and Doˇsen. They
write:
Our proposal is to call logics that can be obtained ... by restricting
structural rules, substructural logics. [250, page 6]
The structural rules mentioned here dictate admissible forms of transforma-
tions of premises in proofs. Later in this section, we will see how relevant
logics are naturally counted as substructural logics, as certain commonly ad-
mitted structural rules are to blame for introducing irrelevant consequences
into proofs.
3In particular, I will say little about the intellectual ancestry of different results. I will not trace
the degree to which researchers in one tradition were inﬂuenced by those in another.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
3
Historical priority in the ﬁeld belongs to the tradition of relevant logic, and
it is to the early stirrings of considerations of relevance that we will turn.
2.1
Relevant Implication: Orlov, Moh and Church
Doˇsen has shown us [71] that substructural logic dates back at least to 1928
with I. E. Orlov’s axiomatisation of a propositional logic weaker than classi-
cal logic [207].4 Orlov axiomatised this logic in order to “represent relevance
between propositions in symbolic form” [71, page 341]. Orlov’s propositional
logic has this axiomatisation.5
⋄
A →∼∼A
double negation introduction
⋄
∼∼A →A
double negation elimination
⋄
A →∼(A →∼A)
contraposed reductio
⋄
(A →B) →(∼B →∼A)
contraposition
⋄
(A →(B →C)) →(B →(A →C))
permutation
⋄
(A →B) →((C →A) →(C →B))
preﬁxing
⋄
A, A →B ⇒B
modus ponens
The axioms and rule here form a traditional Hilbert system. The rule modus
ponens is written in the form using a turnstile to echo the general deﬁnition
of logical consequence in a Hilbert system. Given a set X of formulas, and a
single formula A, we say that A can be proved from X (which I write “X ⇒A”)
if and only if there is a proof in the Hilbert system with A as the conclusion,
and with hypotheses from among the set X. A proof from hypotheses is sim-
ply a list of formulas, each of which is either an hypothesis, an axiom, or one
which follows from earlier formulas in the list by means of a rule. In Orlov’s
system, the only rule is modus ponens. We will see later that this is not nec-
essarily the most useful notion of logical consequence applicable to relevant
and substructural logics. In particular, more interesting results can be proven
with consequence relations which do not merely relate sets of formulas as
premises to a conclusion, but rather relate lists, or other forms of structured
collections as premises, to a conclusion. This is because lists or other struc-
tures can distinguish the order or quantity of individual premises, while sets
cannot. However, this is all that can simply be done to deﬁne consequence re-
lations within the conﬁnes of a Hilbert system, so here is where our deﬁnition
of consequence will start.
These axioms and the rule do not explicitly represent any notion of rele-
vance. Instead, we have an axiomatic system governing the behaviour of im-
plication and negation. The system tells us about relevance in virtue of what
4Allen Hazen has shown that in Russell’s 1906 paper “The Theory of Implication” his propo-
sitional logic (without negation) is free of the structural rule of contraction [133, 243]. Only after
negation is introduced can contraction can be proved. However, there seems to be no real sense
in which Russell could be pressed in to favour as a proponent of substructural logics, as his aim
was not to do without contraction, but to give an axiomatic account of material implication.
5The names are mine, and not Orlov’s. I have attempted to give each axiom or rule its com-
mon name (see for example Anderson and Belnap’s Entailment [10] for a list of axioms and their
names). In this case, “contraposed reductio” is my name, as the axiom
 
 
  is a
rarely seen axiom, but it is a contraposed form of
 
	 

 , which is commonly known
as reductio.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
4
it leaves out, rather than what it includes. Neither of the following formulas
are provable in Orlov’s system:
A →(B →B)
∼(B →B) →A
This distinguishes his logic from both classical and intuitionistic proposi-
tional logic.6 If the “→” is read as either the material conditional or the con-
ditional of intuitionistic logic, those formulas are provable. However, both of
these formulas commit an obvious failure of relevance. The consequent of the
main conditional need not have anything to do with the antecedent. If when
we say “if A then B” we mean that B follows from A, then it seems that we
have lied when we say that “if A then B →B”, for B →B (though true enough)
need not follow from A, if A has nothing to do with B →B. Similarly, A need
not follow from ∼(B →B) (though ∼(B →B) is false enough) for again, A need
not have anything to do with ∼(B →B). If “following from” is to respect these
intuitions, we need look further aﬁeld than classical or intuitionistic propo-
sitional logic, for these logics contain those formulas as tautologies. Excising
these fallacies of relevance is no straightforward job, for once they go, so must
other tautologies, such as these
⋄
A →(B →A)
weakening
⋄
B →(∼B →A)
ex contradictione quodlibet
from which they can be derived.7 To do without obvious fallacies of relevance,
we must do without these formulas too. And this is exactly what Orlov’s sys-
tem manages to do. His system contains none of these “fallacies of relevance”,
and this makes his system a relevant logic. In Orlov’s system, a formula A →B
is provable only when A and B share a propositional atom. There is no way to
prove a conditional in which the antecedent and the consequent have noth-
ing to do with one another. Orlov did not prove this result in his paper. It only
came to light more than 30 years later, with more recent work in relevant logic.
This more recent work is applicable to Orlov’s system, because Orlov has ax-
iomatised the implication and negation fragment of the now well-known rel-
evant logic R.
Orlov’s work didn’t end with the implication and negation fragment of a
relevant propositional logic. He looked at the behaviour of other connectives
deﬁnable in terms of conjunction and negation. In particular, he showed that
deﬁning a conjunction connective
A ◦B =df ∼(A →∼B)
6Heyting’s original text is still a classic introduction to intuitionistic logic, dating from this
era [134].
7Using substitution and modus ponens, and identity. If weakening is an axiom then
 
 


 
 
 
 is an instance, and hence, by modus ponens, with
 
 , we get
 
 
  .
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
5
gives you a connective you can prove to be associative and symmetric and
square increasing8
(A ◦B) ◦C
→
A ◦(B ◦C)
A ◦(B ◦C)
→
(A ◦B) ◦C
A ◦B
→
B ◦A
A
→
A ◦A
However, the converse of the “square increasing” postulate
A ◦A →A
is not provable, and neither are the stronger versions A◦B →A or B◦A →A.
However, for all of that, the connective Orlov deﬁned is quite like a conjunc-
tion, because it satisﬁes the following condition:
⇒A →(B →C) if and only if ⇒A ◦B →C
You can prove a nested conditional if and only if you can prove the corre-
sponding conditional with the two antecedents combined together as one.
This is a residuation property.9 It renders the connective ◦with properties
of conjunction, for it stands with the implication ◦in the same way that ex-
tensional conjunction and the conditional of intuitionistic or classical logic
stand together.10 Residuation properties such as these will feature a great deal
in what follows.
It follows from this residuation property that ◦cannot have all of the prop-
erties of extensional conjunction. A◦B →A is not provable because if it were,
then weakening axiom A →(B →A) would also be provable. B ◦A →A is
not provable, because if it were, B →(A →A) would be.
In the same vein, Orlov deﬁned a disjunction connective
A + B =df ∼A →B
which can be proved to be associative, symmetric and square decreasing (A+
A →A) but not square increasing. It follows that these deﬁned connectives
do not have the full force of the lattice disjunction and conjunction present
in classical and intuitionistic logic. At the very ﬁrst example of the study of
substructural logics we are that the doorstep of one of the profound insights
made clear in this area: the splitting of notions identiﬁed in stronger logi-
cal systems. Had Orlov noticed that one could deﬁne conjunction explicitly
following the lattice deﬁnitions (as is done in intuitionistic logic, where the
deﬁnitions in terms of negation and implication also fail) then he would have
noticed the split between the intensional notions of conjunction and disjunc-
tion, which he deﬁned so clearly, and the extensional notions which are dis-
tinct. We will see this distinction in more detail and in different contexts as
8Here, and elsewhere, brackets are minimised by use of binding conventions. The general
rules are simple: conditional-like connectives such as

bind less tightly than other two-place
operators such as conjunction and disjunction (and fusion ◦and ﬁssion
  ) which in turn bind
less tightly than one place operators. So,
 
 


is the conditional whose antecedent
is the disjunction of
	 with
 and whose consequent is the conjunction of

with

.
9It ought to remind you of simple arithmetic results:
	

if and only if
 ×

 ;
	

if and only if

 
 .
10Namely, that
 
 ⊃

is provable if and only if
 ⊃

 ⊃

 .
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
6
we continue our story through the decades. In what follows, we will refer to ◦
and + so much that we need to give them names. I will follow the literature of
relevant logic and call them fusion and ﬁssion.
Good ideas have a feature of being independently discovered and redis-
covered. The logic R is no different. Moh [253] and Church [56], indepen-
dently formulated the implication fragment of R in the early 1950’s. Moh for-
mulated an axiom system
⋄
A →A
identity
⋄
(A →(A →B)) →(A →B)
contraction
⋄
A →((A →B) →B)
assertion
⋄
(A →B) →((B →C) →(A →C))
suﬃxing
Whereas Church’s replaces the assertion and sufﬁxing with permutation and
preﬁxing
⋄
(A →(B →C)) →(B →(A →C))
permutation
⋄
(A →B) →((C →A) →(C →B))
preﬁxing
Showing that these two axiomatisations are equivalent is an enjoyable (but
lengthy) exercise in axiom chopping. It is a well-known result that in the
presence either preﬁxing and sufﬁxing, permutation is equivalent to asser-
tion. Similarly, in the presence of either permutation or assertion, preﬁxing is
equivalent to sufﬁxing. (These facts will be more perspicuous when we show
how the presence of these axioms correspond to particular structural rules.
But this is to get ahead of the story by a number of decades.)
Note that each of the axioms in either Church’s or Moh’s presentation of
R are tautologies of intuitionistic logic. Orlov’s logic of relevant implication
extends intuitionistic logic when it comes to negation (as double negation
elimination is present) but when it comes to implication alone, the logic R is
weaker than intuitionistic logic. As a corollary, Peirce’s law
⋄
((A →B) →A) →A
Peirce’s law
is not provable in R, despite being a classical tautology. The fallacies of rele-
vance are examples of intuitionistic tautologies which are not present in rel-
evant logic. Nothing so far has shown us that adding negation conservatively
extends the implication fragment of R (in the sense that there is no impli-
cational formula which can be proved with negation which cannot also be
proved without it). However, as we will see later, this is, indeed the case.
Adding negation does not lead to new implicational theorems.
Church’s work on his weak implication system closely paralleled his work
on the lambda calculus. (As we will see later, the tautologies of this system
are exactly the types of the terms in his λI calculus.11) Church’s work extends
that of Orlov by proving a deduction theorem. Church showed that if there is
a proof with hypotheses A1 to An with conclusion B, then there is either a
proof of B from hypotheses A1 to An−1 (in which case An was irrelevant as
an hypothesis) or there is a proof of An →B from A1, . . . , An−1.
11In which
  can abstract a variable from only those terms in which the variable
 occurs. As a
result, the
  -term
 
 
 , of type
 

 
  , is a term of the traditional
  -calculus, but not
of the
  calculus.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
7
FACT 1 (CHURCH’S DEDUCTION THEOREM) In the implicational fragment of
the relevant logic R, if A1, . . . , An ⇒B can be proved in the Hilbert system then
either of the following two consequences can also be proved in that system.
⋄A1, . . . , An−1 ⇒B,
⋄A1, . . . , An−1 ⇒An →B.
PROOF The proof follows the traditional proof of the Deduction Theorem for
the implicational fragment of either classical or intuitionistic logic. A proof
for A1, . . . , An ⇒B is transformed into a proof for A1, . . . , An−1 ⇒An →B
by preﬁxing each step of the proof by “An →”. The weakening axiom A →
(B →A) is needed in the traditional result for the step showing that if an hy-
pothesis is not used in the proof, it can be introduced as an antecedent any-
way. Weakening is not present in R, and this step is not needed in the proof of
Church’s result, because he allows a special clause, exempting us from prov-
ing An →B when An is not actually used in the proof.
□
We will see others later on in our story. This deduction theorem lays some
claim to helping explain the way in which the logic R can be said to be rele-
vant. The conditional of R respects use in proof. To say that A →B is true is to
say not only that B is true whenever A is true (keeping open the option that A
might have nothing to do with B). To say that A →B is true is to say that B fol-
lows from A. This is not the only kind of deduction theorem applicable to rel-
evant logics. In fact, it is probably not the most satisfactory one, as it fails once
the logic is extended to include extensional conjunction. After all, we would
like A, B ⇒A ∧B but we can have neither A ⇒B →A ∧B (since that would
give the fallacy of relevance A ⇒B →A, in the presence of A ∧B →A) nor
A ⇒A∧B (which is classically invalid, and so, relevantly invalid). So, another
characterisation of relevance must be found in the presence of conjunction.
In just the same way, combining conjunction-like pairing operations in the λI
calculus has proved quite difﬁcult [212]. Avron has argued that this difﬁculty
should make us conclude that relevance and extensional connectives cannot
live together [13, 14].
Meredith and Prior were also aware of the possibility of looking for log-
ics weaker than classical propositional logic, and that different axioms corre-
sponded to different principles of the λ-calculus (or in Meredith and Prior’s
case, combinatory logic). Following on from work of Curry and Feys [62, 63],
they formalised subsystems of classical logic including what they called BCK
(logic without contraction) and BCI (logic without contraction or weakening:
which is know known as linear logic) [169]. They, with Curry, are the ﬁrst to ex-
plicitly chart the correspondence of propositional axioms with the behaviour
of combinators which allow the rearrangement of premises or antecedents.12
For a number of years following this pioneering work, the work of Ander-
son and Belnap continued in this vein, using techniques from other branches
of proof theory to explain how the logic R and its cousins respected condi-
tions of relevance and necessity. We will shift our attention now to another of
the precursors of Anderson and Belnap’s work, one which pays attention to
conditions of necessity as well as relevance.
12It is in their honour that I use Curry’s original terminology for the structural rules we will see
later: W for contraction, K for weakening, C for commutativity, etc.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
8
2.2
Entailment: Ackermann
Ackermann formulated a logic of entailment in the late 1950s [2]. He ex-
tended C. I. Lewis’ work on systems of entailment to respect relevance and
to avoid the paradoxes of strict implication. His favoured system of entail-
ment is a weakening of the system S4 of strict implication designed to avoid
the paradoxes. Unlike earlier work on relevant implication, Ackermann’s sys-
tem includes the full complement of sentential connectives.
To motivate the departures that Ackermann’s system takes from R, note
that the arrow of R is no good at all to model entailment. If we want to say
that A entails that B, the arrow of R is signiﬁcantly too strong. Speciﬁcally,
axioms such as permutation and assertion must be rejected for the arrow of
entailment. To take an example, suppose that A is contingently true. It is an
instance of assertion that
A →((A →A) →A)
However, even if A is true, it ought not be true that A →A entails A. For
A →A is presumably necessarily true. We cannot not have this necessity
transferring to the contingent claim A.13 Permutation must go too, as asser-
tion is follows from permuting the identity (A →B) →(A →B). So, a logic of
entailment must be weaker than R. However, it need not be too much weaker.
It is clear that preﬁxing, sufﬁxing and contraction are not prone to any sort of
counterexample along these lines: they can survive into a logic of entailment.
Ackermann’s original paper features two different presentations of the sys-
tem of entailment. The ﬁrst, Σ′, is an ingenious consecution calculus, which
is unlike any proof theory which has survived into common use, so unfor-
tunately, I must skim over it here in one paragraph.14 The system manipu-
lates consecutions of the form A, B ⊢C (to be understood as A ∧B →C)
and A∗, B ⊢C (to be understood as as A →(B →C)). If you note that the
comma in the antecedent place has no uniform interpretation, and that what
you have, in effect, is two different premise combining operations. This is,
in embryonic form at least, the ﬁrst explicit case of a dual treatment of both
intensional and extensional conjunction in a proof theory that I have found.
Ackermann’s other presentation of the logic of entailment is a Hilbert sys-
tem. The axioms and rules are presented in Figure 1. You can see that many of
the axioms considered have already occurred in the study of relevant implica-
tion. The innovations appear in both what is omitted (assertion and permu-
tation, as we have seen) and in the full complement of rules for conjunction
and disjunction.15
To make up for the absence of assertion and permutation, Ackermann
adds restricted permutation. This rule is not a permutation rule (it doesn’t
permute anything) but it is a restriction of the permutation rule to infer B →
(A →C) from A →(B →C). For the restricted rule we conclude A →C from
13If something is entailed by a necessity, it too is necessary. If
 entails
 then if we cannot
have
 false, we cannot have
 false either.
14The interested reader is referred to Ackermann’s paper (in German) [2] or to Anderson, Bel-
nap and Dunn’s sympathetic summary [11, §44–46] (in English).
15The choice of counterexample as a thesis connecting implication and negation in place of
reductio (as in Orlov) is of no matter. The two are equivalent in the presence of contraposition
and double negation rules. Showing this is a gentle exercise in axiom-chopping.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
9
Axioms
⋄
A →A
identity
⋄
(A →B) →((C →B) →(C →A))
preﬁxing
⋄
(A →B) →((B →C) →(A →C))
suﬃxing
⋄
(A →(A →B)) →(A →B)
contraction
⋄
A ∧B →A, A ∧B →B
conjunction elimination
⋄
(A →B) ∧(A →C) →(A →B ∧C)
conjunction introduction
⋄
A →A ∨B, B →A ∨B
disjunction introduction
⋄
(A →C) ∧(B →C) →(A ∨B →C)
disjunction elimination
⋄
A ∧(B ∨C) →B ∨(A ∧C)
distribution
⋄
(A →B) →(∼B →∼A)
contraposition
⋄
A ∧∼B →∼(A →B)
counterexample
⋄
A →∼∼A
double negation introduction
⋄
∼∼A →A
double negation elimination
Rules
(α)
A, A →B ⇒B
modus ponens
(β)
A, B ⇒A ∧B
adjunction
(γ)
A, ∼A ∨B ⇒B
disjunctive syllogism
(δ)
A →(B →C), B ⇒A →C
restricted permutation rule
Figure 1: Ackermann’s axiomatisation Π ′
A →(B →C) and B. Clearly this follows from permutation. This restriction
allows a restricted form of assertion too.
⋄
(A →A′) →(((A →A′) →B) →B)
restricted assertion
This is an instance of the assertion where the ﬁrst position A is replaced by
the entailment A →A′. While assertion might not be valid for the logic of
entailment, it is valid when the proposition in the ﬁrst position is itself an
entailment.
As Anderson and Belnap point out [11, §8.2], (δ) is not a particularly satis-
factory rule. Its status is akin to that of the rule of necessitation in modal logic
(from ⇒A to infer ⇒□A). It does not extend to an entailment (A →□A). If it
is possible to do without a rule like this, it seems preferable, as it licences tran-
sitions in proofs which do not correspond to valid entailments. Anderson and
Belnap showed that you can indeed do without (δ) to no ill effect. The system
is unchanged when you replace restricted permutation by restricted assertion.
This is not the only rule of Ackermann’s entailment which provokes com-
ment. The rule (γ) (called disjunctive syllogism) has had more than its fair
share of ink spilled. It suffers the same failing in this system of entailment
as does (δ): it does not correspond to a valid entailment. The corresponding
entailment A∧(∼A∨B) →B is not provable. I will defer its discussion to Sec-
tion 2.4, by which time we will have sufﬁcient technology available to prove
theorems about disjunctive syllogism as well as arguing about its signiﬁcance.
Ackermann’s remaining innovations with this system are at least twofold.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
10
First, we have an thorough treatment of extensional disjunction and con-
junction. Ackermann noticed that you need to add distribution of conjunc-
tion over disjunction as a separate axiom.16 The conjunction and disjunction
elimination and introduction rules are sufﬁcient to show that conjunction
and disjunction are lattice join and meet on propositions ordered by provable
entailment. (It is a useful exercise to show that in this system of entailment,
you can prove A ∨∼A, ∼(A ∧∼A), and that all de Morgan laws connecting
negation, conjunction and disjunction hold.)
The ﬁnal innovation is the treatment of modality. Ackermann notes that
as in other systems of modal logic which take entailment as primary, it is pos-
sible to deﬁne the one-place modal operators of necessity, possibility and
others in terms of entailment. A traditional choice is to take impossibility
“U”17 deﬁned by setting UA to be A →B ∧∼B for some choice of a contradic-
tion. Clearly this will not do in the case of a relevant logic as even though it
makes sense to say that if A entails the contradictory B∧∼B then A is impossi-
ble, we might have A entailing some contradiction (and so, being impossible)
without entailing that contradiction. It is a fallacy of relevance to take all con-
tradictions to be provably equivalent. No, Ackermann takes another tack, by
introducing a new constant f, with some special properties.18 The intent is
to take f to mean “some contradiction is true”. Ackermann then posits the
following axioms and rules.
⋄
A ∧∼A →f
⋄
(A →f) →∼A
(ϵ)
A →B, (A →B) ∧C →f ⇒C →f
Clearly the ﬁrst two are true, if we interpret f as the disjunction of all contra-
dictions. The last we will not tarry with. It is an idiosyncratic rule, distinctive
to Ackermann. More important for our concern is the deﬁnition of f. It is
a new constant, with new properties which open up once we enter the sub-
structural context. Classically (or intuitionistically) f would behave as ⊥, a
proposition which entails all others. In a substructural logic like R or Acker-
mann’s entailment, f does no such thing. It is true that f is provably false (we
can prove ∼f, from the axiom (f →f) →∼f) but it does not follow that f en-
tails everything. Again, a classical notion splits: there are two different kinds
of falsehood. There is the Ackermann false constant f, which is the weakest
provably false proposition, and there is the Church false constant ⊥, which is
the strongest false proposition, which entails every proposition whatsoever.
Classically and intuitionistically, both are equivalent. Here, they come apart.
The two false constants are mirrored by their negations: two true con-
stants. The Ackermann true constant t (which is ∼f) is the conjunction of all
tautologies. The Church true constant ⊤(which is ∼⊥) is the weakest propo-
sition of all, such that A →⊤is true for each A. If we are to deﬁne necessity
by means of a propositional constant, then t →A is the appropriate choice.
For t →A will hold for all provable A. Choosing ⊤→A would be much too
16If we have the residuation of conjunction by ⊃(intuitionistic or classical material implica-
tion) then distribution follows. The algebraic analogue of this result is the thesis that a residuated
lattice is distributive.
17For unm¨oglich.
18Actually, Ackermann uses the symbol “
 ”, but it now appears in the literature as “
 ”.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
11
restrictive, as we would only allow as “necessary” propositions which were
entailed by all others. Since we do not have A ∨∼A →B ∨∼B, if we want
both to be necessary, we must be happy with the weaker condition, of being
entailed by t.
This choice of true constant to deﬁne necessity motivates the choice that
Anderson and Belnap used. t must entail each proposition of the form A →A
(as each is a tautology). Anderson and Belnap showed that t →A in Acker-
mann’s system is equivalent to (A →A) →A, and so they use (A →A) →A
as a deﬁnition of □A, and in this way, they showed that it was possible to
deﬁne the one-place modal operators in the original language alone, with-
out the use of propositional constants at all.19 It is instructive to work out
the details of the behaviour of □as we have deﬁned it. Necessity here has
properties roughly of S4. In particular, you can prove □A →□□A but not
♦A →□♦A in Ackermann’s system.20 (You will note that using this deﬁni-
tion of necessity and without (δ) you need to add an axiom to the effect that
□A ∧□B →□(A ∧B),21 as it cannot be proved from the system as it stands.
Deﬁning □A as t →A does not have this problem.)
2.3
Anderson and Belnap
We have well-and-truly reached beyond Ackermann’s work on entailment to
that of Alan Anderson and Nuel Belnap. Anderson and Belnap started their
exploration of relevance and entailment with Ackermann’s work [6, 8], but
very soon it became an independent enterprise with a wealth of innovations
and techniques from their own hands, and from their students and colleagues
(chieﬂy J. Michael Dunn, Robert K. Meyer, Alasdair Urquhart, Richard Rout-
ley (later known as Richard Sylvan) and Kit Fine). Much of this research is re-
ported in the two-volume Entailment [10, 11], and in the papers cited therein.
There is no way that I can adequately summarise this work in a few pages.
However, I can sketch what I take to be some of the most important enduring
themes of this tradition.
2.3.1
Fitch Systems
Hilbert systems are not the most only way to present proofs. Other proof the-
ories give us us different insights into a logical system by isolating rules rele-
vant to each different connective. Hilbert systems, with many axioms and few
rules, are not so suited to a project of understanding the internal structure of a
family of logical systems. It is no surprise that in the relevant logic tradition,
a great deal of work was invested toward providing different proof theories
which model directly the relationship between premises and conclusions.
The ﬁrst natural deduction system for R and E (Anderson and Belnap’s sys-
tem of entailment) was inspired by Fitch’s natural deduction system, in com-
mon use in undergraduate and postgraduate logic instruction in the 1950s in
the United States [100].22 A Fitch system is a linear presentation of a natural
19Impossibility
  is then
 

 
  .
20Deﬁning

 as

	 , i. e., as


 
 

  .
21The axiom is ungainly when it is written out in full:

 
 

 



 
 

 


 
 
 
 

 
  .
22That Fitch systems would be used by Anderson and Belnap is to be expected. It is also to
be expected that Read [224] and Slaney [256] (from the U. K.) use Lemmon-style natural deduc-
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
12
deduction proof, with introduction and elimination rules for each connec-
tive, and the use of vertical lines to present subproofs — parts of proofs un-
der hypotheses. Here, for example, is a proof of the relevantly unacceptable
weakening axiom in a Fitch system for classical (or intuitionistic) logic:
1
A
hyp
2
B
hyp
3
A
1 reit
4
B →A
2–3 →I
5
A →(B →A)
1–4 →I
Each line is numbered to the left, and the annotation to the right indicates
the provenance of each formula. A line marked with “hyp” is an hypothesis,
and its introduction increases the level of nesting of the proof. In line 4 we
have the application of conditional proof, or as it is indicated here, implica-
tion introduction (→I). Since A has been proved under the hypothesis of B,
we deduce B →A, discharging that hypothesis. The other distinctive feature
of Fitch proofs is the necessity to reiterate formulas. If a formula appears out-
side a nested subproof, it is possible to reiterate it under the assumption, for
use inside the subproof.
Now, this proof is defective, if we take →to indicate relevant implication.
There are two possible points of disagreement. One is to question the proof
at the point of line 3: perhaps something has gone wrong at the point of re-
iterating A in the subproof. This is not where Anderson and Belnap modify
Fitch’s system in order to model R.23 As you can see in the proof of (relevantly
acceptable) assertion axiom, reiteration of a formula from outside a subproof
is unproblematic.
1
A
hyp
2
A →B
hyp
3
A
1 reit
4
B
2–3 →E
5
(A →B) →B
2–4 →I
6
A →((A →B) →B)
1–5 →I
The difference between the two proofs indicates what has gone wrong in the
proof of the weakening axiom. In this proof, we have indeed used A →B
in the proof of B from lines 1 to 4. In the earlier “proof”, we indeed proved
A under the assumption of B but we did not use B in that proof. The impli-
cation introduction in line 4 is fallacious. If I am to pay attention to use in
proof, I must keep track of it in some way. Anderson and Belnap’s innovation
is to add labels to formulas in proofs. The label is a set of indices, indicating
the hypotheses upon which the formula depends. If I introduce an hypoth-
esis A in a proof, I add a new label, a singleton of a new index standing for
tion [153], modelled after Lemmon’s textbook, used in the U. K. for many years. Logicians on
continental Europe are much more likely to use Prawitz [214] or Gentzen-style [111, 112] natu-
ral deduction systems. This geographic distribution of pedagogical techniques (and its result-
ing inﬂuence on the way research is directed, as well as teaching) is remarkably resilient across
the decades. The recent publication of Barwise and Etchemendy’s popular textbook introducing
logic still uses a Fitch system [19]. As far as I am aware, instruction in logic in none of the major
centres in Europe or Australia centres on Fitch-style presentation of natural deduction.
23Restricting reiteration is the way to give hypothesis generation and conditional introduction
modal force, as we shall see soon.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
13
that hypothesis. The implication introduction and elimination rules must be
amended to take account of labels. For implication elimination, given Aa and
A →Bb, I conclude Ba∪b, for this instance of B in the proof depends upon ev-
erything we needed for A and for A →B. For implication elimination, given
a proof of Ba under the hypothesis A{i}, I can conclude A →Ba−{i}, provided
that i ∈a. With these amended rules, we can annotate the original proof of
assertion with labels, as follows.
1
A{1}
hyp
2
A →B{2}
hyp
3
A{1}
1 reit
4
B{1,2}
2–3 →E
5
(A →B) →B{1}
2– 4 →I
6
A →((A →B) →B)
1–5 →I
The proof of weakening, on the other hand, cannot be annotated with labels
satisfying the rules for implication.
1
A{1}
hyp
2
B{2}
hyp
3
A{1}
1 reit
4
B →A???
2–3 →I
5
A →(B →A)???
1–4 →I
Modifying the system to model entailment is straightforward. As I hinted ear-
lier, if the arrow has a modal force, we do not want unrestricted reiteration.
Instead of allowing an arbitrary formula to be reiterated into a subproof, since
entertaining an hypothesis now has the force of considering an alternate pos-
sibility, we must only allow for reiteration formulas which might indeed hold
in those alternate possibilities. Here, the requisite formulas are entailments.
Entailments are not only true, but true of necessity, and so, we can reiterate
an entailment under the context of an hypothesis, but we cannot reiterate
atomic formulas. So, the proof above of assertion breaks down at the point
at which we wished to reiterate A into the second subproof. The proof of re-
stricted assertion will succeed.
1
A →A′{1}
hyp
2
(A →A′) →B{2}
hyp
3
A →A′
{1}
1 reit
4
B{1,2}
2–3 →E
5
((A →A′) →B) →B{1}
2–4 →I
6
(A →A′) →(((A →A′) →B) →B)
1–5 →I
This is a permissible proof because we are entitled to reiterate A →A ′ at line
3. Even given the assumption that (A →A ′) →B, the prior assumption of
A →A′ holds in the new context.
Here is a slightly more complex proof in this Fitch system for entailment.
(Recall that □A is shorthand for (A →A) →A, for Anderson and Belnap’s
system of entailment.) This proof shows that in E, the truth of an entailment
(here B →C) entails that anything entailed by that entailment (here A) is
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
14
itself necessary too. The reiterations on lines 4 and 5 are permissible, because
B →C and (B →C) →A are both entailments.
1
B →C{1}
hyp
2
(B →C) →A{2}
hyp
3
A →A{3}
hyp
4
B →C{1}
1 reit
5
(B →C) →A{2}
2 reit
6
A{1,2}
4, 5 →E
7
A{1,2,3}
3, 6 →E
8
(A →A) →A{1,2}
3–7 →I
9
((B →C) →A) →□A{1}
2–8 →I
10
(B →C) →(((B →C) →A) →□A)
1–9 →I
We say that A follows relevantly from B when a proof of with hypothesis A{i}
concludes in B{i}. This is written “A ⊢B.” We say that A is provable by itself
when there is a proof of A with no label at all. Then the Hilbert system and
the natural deduction system match in the following two senses.
FACT 2 (HILBERT AND FITCH EQUIVALENCE) ⇒A →B if and only if A ⊢B.
⇒A if and only if ⊢A.
PROOF
The proof is by an induction on the complexity of proofs in both
directions. To convert a Fitch proof to a Hilbert proof, we replace the hy-
potheses A{i} by the identity A →A, and the arbitrary formula B{i1,i2,...,in}
by A1 →(A2 →· · · →(An →B) · · ·) (where Aj is the formula introduced
with label Aj). Then you show that the the steps between these formulas can
be justiﬁed in the Hilbert system. Conversely, you simply need to show that
each Hilbert axiom is provable in the Fitch system, and that modus ponens
preserves provability. Neither proof is difﬁcult.
□
Other restrictions on reiteration can be given to this Fitch system in order to
model even weaker logics. In particular, Anderson and Belnap examine a sys-
tem T of ticket entailment, whose rationale is the idea that statements of the
form A →B are rules but not facts. They are to be used as major premises of
implication eliminations, but not as minor premises. The restriction on reit-
eration to get this effect allows you to conclude Ba∪b from Aa and A →Bb,
provided that max(b) ≤max(a). The effect of this is to render restricted as-
sertion unprovable, while identity, preﬁxing, sufﬁxing and contraction remain
provable (and these axiomatise the calculus T of ticket entailment).24 (It is an
open problem to this day whether the implicational fragment of T is decid-
able.)
Before considering the extension of this proof theory to deal with the ex-
tensional connectives, let me note one curious result in the vicinity of T. The
logic TW you get by removing contraction from T has a surprising property.
Errol Martin has shown that if A →B and B →A are provable in TW, then A
and B must be the same formula [166].25
24This is as good a place as any to note that the axiom of self distribution
 

 





 
 

 


 will do instead of contraction in any of these axiomatisations.
25Martin’s proof proceeds via a result showing that the logic given by preﬁxing and sufﬁxing
(without identity) has no instances of identity provable at all. This is required, for
 
 



 
 

 
 
 is an instance of sufﬁxing. The system S (for syllogism) has interesting
properties in its own right, modelling noncircular (non “question begging”?) logic [165].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
15
2.3.2
First Degree Entailment
It is one thing to provide a proof theory for implication or entailment. It is
another to combine it with a theory of the other propositional connectives:
conjunction, disjunction and negation. Anderson and Belnap’s strategy was
to ﬁrst decide the behaviour of conjunction, disjunction and negation, and
then combine this theory with the theory of entailment or implication. This
is gives the structure of the ﬁrst volume of Entailment [10]. The ﬁrst 100 pages
deals with implication alone, the next 50 with implication and negation, the
next 80 with the ﬁrst degree fragment (entailments between formulas not in-
cluding implication) and only at page 231 do we ﬁnd the formulation of the
full system E of entailment.
Anderson and Belnap’s work on entailments between truth functions (or
what they call ﬁrst degree entailment) dates back to a paper in 1962 [9]. There
are many different ways to carve out ﬁrst degree entailments which are rel-
evant from those which are not. For example, ﬁlter techniques due to von
Wright [288], Lewy [155], Geach [109] and Smiley [257] tell us that statements
like
A →B ∨∼B
A ∧∼A →B
fail as entailments because there is no atom shared between antecedent and
consequent. So far, so good, and their account follows Anderson and Bel-
nap’s. However, if this is the only criterion to add to classical entailment, we
allow through as entailments their analogues:
A →A ∧(B ∨∼B)
(A ∧∼A) ∨B →B
for the propositional atom A is shared in the ﬁrst case, and B in the second.
Since both of the following classical entailments
A ∧(B ∨∼B) →B ∨∼B
A ∧∼A →(A ∧∼A) ∨B
also satisfy the atom-sharing requirement, using variable sharing as the only
criterion makes us reject the transitivity of entailment. After all, given A →
A ∧(B ∨∼B) and given A ∧(B ∨∼B) →B ∨∼B, if →is transitive, we get
A →B ∨∼B.26
Anderson and Belnap respond by noting that if A →B∨∼B is problematic
because of relevance, then A →A ∧(B ∨∼B) is at least 50% problematic [10,
page 155]. Putting things another way, if to say that A entails B ∧C is at least
to say that A entails B and that A entails C, then we cannot just add a blanket
atom-sharing criterion to ﬁlter out failures of relevance, for it might apply to
one conjunct and not the other. Filter techniques do not work.
Anderson and Belnap characterise valid ﬁrst degree entailments in a num-
ber of ways. The simplest way which does not use any model theory is a nor-
mal form theorem for ﬁrst degree entailments. We will use a process of re-
duction to transform arbitrary entailments into primitive entailments, which
26Nontransitive accounts of entailment have survived to this day, with more sophistication.
Neil Tennant has an idiosyncratic approach to normalisation in logics, arguing for a “relevant
logic” which differs from our substructural logics by allowing the validity of
 
  	 ⊢
 and
 ⊢
 
  , while rejecting
  	 ⊢
 [261, 262]. Tennant’s system rejects the unrestricted
transitivity of proofs: the ‘Cut’ which would allow
  	 ⊢
 from the proofs of
 
  	 ⊢
 and
 ⊢
 
 is not admissible. Tennant uses normalisation to motivate this system.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
16
we can determine on sight. The ﬁrst part of the process is to drive negations
inside other operators, leaving them only on atoms. We use the de Morgan
equivalences and the double negation equivalence to do this.27
∼(A ∨B) ↔∼A ∧∼B
∼(A ∧B) ↔∼A ∨∼B
∼∼A ↔A
(I write “A ↔B” here a shorthand for “both A →B and B →A”.)
The next process involves pushing conjunctions and disjunctions around.
The aim is to make the antecedent of our putative entailment a disjunction
of conjunctions, and the consequent a conjunction of disjunctions. We use
these distribution facts to this effect.28
(A ∨B) ∧C ↔(A ∧C) ∨(B ∧C)
(A ∧B) ∨C ↔(A ∨C) ∧(B ∨C)
With that transformation done, we break the entailment up into primitive en-
tailments in these two kinds of steps:
A ∨B →C if and only if A →C and B →C
A →B ∧C if and only if A →B and A →C
Each of these transformation rules is intended to be unproblematically valid
when it comes to relevant entailment. The ﬁrst batch (the negation condi-
tions) seem unproblematic if negation is truth functional. The second batch
(the distribution conditions, together with the associativity, commutativity
and idempotence of both disjunction and conjunction) are sometimes ques-
tioned29 but we have been given no reason yet to quibble with these as rel-
evant entailments. Finally, the steps to break down entailments from dis-
junctions and entailments to disjunction are fundamental to the behaviour of
conjunction and disjunction as lattice connectives. They are also fundamen-
tal to inferential properties of these connectives. A ∨B licences an inference
to C (and a relevant one, presumably!) if and only if A and B both licence that
inference. B ∧C follows from A (and relevantly presumably!) if and only if B
and C both follow from A.
The result of the completed transformation will then be a collection of
primitive entailments: each of which is a conjunction of atoms and negated
atoms in the antecedent, and a disjunction of atoms and negated atoms in
the consequent. Here are some examples of primitive entailments:
p ∧∼p →q ∨∼q
p →p ∨∼p
p ∧∼p ∧∼q ∧r →s ∨∼s ∨q ∨∼r
Anderson and Belnap’s criterion for deciding a primitive entailment is simple.
A primitive entailment A →B is valid if and only if one of the conjuncts in the
antecedent also features as a disjunct in the consequent. If there is such an
atom, clearly the consequent follows from the antecedent. If there is no such
27We also lean on the fact that we can replace provable equivalents ad libitum in formulas.
Formally, if we can prove
 
 and
 
 then we can prove



′ and

′

 , where

′ results from

by changing as many instances of
 to
 in

as you please. All substructural
logics satisfy this condition.
28Together with the associativity, commutativity and idempotence of both disjunction and
conjunction, which I will not bother to write out formally.
29We will see later that linear logic rejects the distribution of conjunction over disjunction.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
17
atom, the consequent may well be true (and perhaps even necessarily so, if an
atom and its negation both appear as disjuncts) but its truth does not follow
from the truth of the antecedent. This makes some kind of sense: what is it
for the consequent to be true? It’s for B1 or B2 or B3 ... to be true. (And that’s
all, as that’s all that the consequent says.) If none of these things are given
by the antecedent, then the consequent as a whole doesn’t follow from the
antecedent either.30
We can then decide an arbitrary ﬁrst degree entailment by this reduction
process. Given an entailment, reduce it to a collection of primitive entail-
ments, and then the original entailment is valid if and only if each of the prim-
itive entailments is valid. Let’s apply this to the inference of disjunctive syllo-
gism: (A ∨B) ∧∼A →B. Distributing the disjunction over the conjunction in
the antecedent, we get (A ∧∼A) ∨(B ∧∼A) →B. This is a valid entailment if
and only if A ∧∼A →B and B ∧∼A →B both are. The second is, but the ﬁrst
is not. Disjunctive syllogism is therefore rejected by Anderson and Belnap. To
accept it as a valid entailment is to accept A ∧∼A →B as valid. Since this is a
fallacy of relevance, so is disjunctive syllogism.
This is one simple characterisation of ﬁrst degree entailments. Once we
start looking at models we will see some different models for ﬁrst degree en-
tailment which give us other straightforward characterisations of the ﬁrst-
degree fragment of R and E. Now, however, we must consider how to graft
this account together with the account of implicational logics we have already
seen.
2.3.3
Putting them together
To add the truth functional connectives to a Hilbert system for R or E, An-
derson and Belnap used the axioms due to Ackermann for his system Π ′. The
conjunction introduction and elimination, disjunction introduction and elim-
ination axioms, together with distribution and the rule of adjunction is sufﬁ-
cient to add the distributive lattice connectives. To add negation, you add the
double negation axioms and contraposition, and counterexample (or equiva-
lently, reductio). Adding the truth functions to a Hilbert system is straightfor-
ward.
It is more interesting to see how to add the connectives to the natural de-
duction system, because these systems usually afford a degree of separation
between different connectives, and they provide a context in which you can
see the distinctive behaviour of those connectives. Let’s start with negation.
Here are the negation rules proposed by Anderson and Belnap:
⋄(∼I) From ∼Aa proved under the hypothesis A{k}, deduce ∼Aa−{k} (if k ∈
a). (This discharges the hypothesis.)
30I am not here applying the fallacious condition that
  
  follows from
 if and only if
  follows from
 or
  follows from
 , which is invalid in general. Let
 be
  
  , for example.
But in that case we note that
   follows from some disjunct of
 and
  also follows from other
disjunct of
 . In the atomic case,
 can no longer be split up.
Classically the idea to show the entailment





the idea would be to import the
tautologous



into the antecedent, to get









 , distribute to get














	 , and split to get both







(which is valid, by means
of
 ) and


	



	
(which is valid, by means of
	 ). With eyes of relevance there’s no
reason to see the appeal for importing


 in the ﬁrst place.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
18
⋄(Contraposition) From Ba and ∼Bb proved under the hypothesis A{k}, de-
duce ∼Aa∪b−{k} (if k ∈b). (This discharges the hypothesis.)
⋄(∼∼E) From ∼∼Aa to deduce Aa.
These rules follow directly the axioms of reductio, contraposition and double
negation elimination. They are sufﬁcient to derive all of the desired negation
properties of E and R. Here, for example, is a proof of the reductio axiom.
1
A →∼A{1}
hyp
2
A{2}
hyp
3
A →∼A{1}
1 reit
4
∼A{1,2}
2–3 →E
5
∼A{1}
2–4 ∼I
6
(A →∼A) →∼A
1–5 →I
The rules for conjunction are also straightforward.
⋄(∧E1) From A ∧Ba to deduce Aa.
⋄(∧E2) From A ∧Ba to deduce Ba.
⋄(∧I) From Aa and Ba to deduce A ∧Ba.
These rules mirror the Hilbert axiom conditions (which make ∧a lattice join).
The conjunction entails both conjuncts, and the conjunction is the strongest
thing which entails both conjuncts.
We do not have a rule which says that if A depends on something and
B depends on something else then A ∧B depends on those things together,
because that would allow us to do too much. If we did have a connective (use
“&” for this connective for the moment) which satisﬁed the same elimination
clause as conjunction, and which satisﬁed that liberal introduction rule, it
would allow us to prove the positive paradox in the following way.
1
A{1}
hyp
2
B{2}
hyp
3
A{1}
1 reit
4
A&B{1,2}
2, 3 &E
5
A{1,2}
4 &E reit
6
B →A{1}
2–5 ∼I
7
A →(B →A)
1–6 →I
If we have a connective with the elimination rules of conjunction (which we
surely require, if that connective is to be “and” in the traditional sense) then
the liberal rules are too strong. They would allow us to take vacuous excur-
sions through conjunction introductions and elimination, picking up irrele-
vant indices along the way.
No, the appropriate introduction rule for a conjunction is the restricted
one which requires that both conjuncts already have the same relevance la-
bel. This, somewhat surprisingly, sufﬁces to prove everything we can prove
in the Hilbert system. Here, for an example, is the proof of the conjunction
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
19
introduction Hilbert axiom
1
(A →B) ∧(A →C){1}
hyp
2
A →B{1}
1 ∧E
3
A →C{1}
1 ∧E
4
A{2}
hyp
5
A →B{1}
2 reit
6
B{1,2}
4, 5 →E
7
A →C{1}
3 reit
8
C{1,2}
4, 7 →E
9
B ∧C{1,2}
6, 8 ∧I
10
A →B ∧C{1}
4–9 ∼I
11
(A →B) ∧(A →C) →(A →B ∧C)
1–10 →I
From these rules, using from the de Morgan equivalence between A ∨B and
∼(∼A ∧∼B) it is possible to derive the following two rules for disjunction.31
Unfortunately, these rules essentially involve the conditional. There seems to
be no way to isolate rules which involve disjunction alone.
⋄(∨I1) From Aa to deduce A ∨Ba.
⋄(∨I2) From Ba to deduce A ∨Ba.
⋄(∨E) From A →Ca and B →Ca and from A ∨Bb to deduce Ca∪b.
The most disheartening thing about these rules for disjunction (and about
the natural deduction system itself) is that they do not sufﬁce. They do not
prove the distribution of conjunction over disjunction. Anderson and Belnap
had to posit an extra rule.
⋄(Dist) From A ∧(B ∨C)a to deduce (A ∧B) ∨Ca
It follows that this Fitch-style proof theory, while useful for proving things
in R or E, and while giving some separation of the distinct behaviours of the
logical connectives, does not provide pure introduction and elimination rules
for each connective. For a proof theory which does that, the world would have
to wait until the 1970s, and for some independent work of Grigori Minc [195,
197]32 and J. Michael Dunn [78].33
The fusion connective ◦plays a minor role in early work in the Anderson–
Belnap tradition.34 They noted that it has some interesting properties in R,
but that the residuation connection fails in E if we take A ◦B to be deﬁned
as ∼(A →∼B). Residuation fails because ∼(A →∼B) →C does not A →
(B →C) if we cannot permute antecedents of arbitrary conditionals. Since E
was their focus, fusion played little role in their early work. Later, with Dunn’s
development of natural algebraic semantics, and with the shift of focus to R,
fusion began to play a more central role.
The topic of ﬁnding a natural proof theory for relevant implication — and
in particular, the place of distribution in such a proof theory — was a re-
curring theme in logical research in this tradition. The problem is not re-
31See Anderson and Belnap’s Entailment [10, §23.2] for the details.
32Then in Russia, and now at Stanford. He publishes now under the name “Grigori Mints”
33A graduate student of Nuel Belnap’s.
34They call ◦“fusion” after trying out names such as “cotenability” or “compossibility”, con-
nected with the deﬁnition as

 

  .
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
20
stricted to Fitch-style systems. Dag Prawitz’s 1965 monograph Natural De-
duction [214], launched Gentzen-style natural deduction systems on to cen-
tre stage. At the end of the book, Prawitz remarked that modifying the rules of
his system would give you a system of relevant implication. Indeed they do.
Almost.
Rules in Prawitz’s system are simple. Proofs take the form of a tree. Some
rules simply extend trees downward, from one conclusion to another. Others,
take two trees and join them into a new tree with a single conclusion.
A ∧B
A
A ∧B
B
A
B
A ∧B
A →B
A
B
These rules have as assumptions any undischarged premises at the top of the
tree. To prove things on the basis of no assumptions, you need to use rules
which discharge them. For example, the implication introduction rule is of
this form:
[A]
...
B
A →B
This indicates that at the node for B there is a collection of open assumptions
A, and we can derive A →B, closing those assumptions. Prawitz hypoth-
esised that if you modiﬁed his rules to only allow the discharge of assump-
tions which were actually used in a proof, as opposed to allowing vacuous
discharge (which is required in the proof of A →(B →A), for example),
you would get a system of relevant logic in the style of Anderson and Belnap.
Keeping our attention to implication alone, the answer is correct. His rule
modiﬁcation gives us a simple natural deduction system for R.
However, Prawitz’s rules for relevant logic are less straightforward once we
attempt to add conjunction. If we keep the rules as stated, then the conjunc-
tion rules allow us to prove the positive paradox in exactly the same way as in
the case with & in the Fitch system.35
A2
B1


I

A ∧B


E

A

  
I

B →A

 
I

A →(B →A)
We must do something to the rule for conjunction introduction to ban this
proof. The required emendation is to only allow conjunction introduction
when the two subproofs have exactly the same open assumptions. A simi-
lar emendation is required for disjunction elimination. And then, once those
patches are applied, it turns out that distribution is no longer provable in the
system. (The intuitionistic or classical proof of distribution in Prawitz’s sys-
tem requires either a weakening in of an irrelevant assumption or a banned
35The superscripts and the line numbers pair together assumptions and the points in the proof
at which they were discharged.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
21
conjunction or disjunction move.) Prawitz’s system is no friendlier to distri-
bution than is Fitch’s.
Logics without distribution, such as linear logic are popular, in part, be-
cause of the difﬁculty of presenting straightforward proof systems for logics
with distribution. In general, proof theories seem more natural or straightfor-
ward doing without it. The absence of distribution has also sparked debate.
The naturalness or otherwise of a proof theory is no argument in and of itself
for the failure of distribution. See Belnap’s “Life in the Undistributed Mid-
dle” [32] for more on this point.
2.3.4
Embeddings
One of the most beautiful results of early work on relevant logic is the embed-
ding results showing how intuitionistic logic, classical logic and S4 ﬁnd their
home inside R and E [7, 176, 180]. The idea is that we can move to an irrele-
vant conditional by recognising that they might be enthymemes. When I say
that A ⊃B holds (⊃is the intuitionistic conditional), I am not saying that
B follows from A, I am saying that B follows from A together perhaps with
some truth or other. One simple way to say this is to lean on the addition of
the Ackermann constant t. We can easily add t to R by way of the following
equivalences
A →(t →A)
(t →A) →A
These state that a claim is true just in case it follows from t.36 Given t we can
deﬁne the enthymematic conditional A ⊃B as follows. A ⊃B is
A ∧t →B
which states that B follows from A together with some truth or other. Now,
A ⊃(B ⊃A) is provable: in fact, the stronger claim A →(B ⊃A) is provable,
since it follows directly from the axiom A ⊃(t ⊃A). But this is no longer
paradoxical, since B ⊃A does not state that A follows from B. (The proof that
you get precisely intuitionistic logic through this embedding is a little trickier
than it might seem. You need to revisit the deﬁnition of intuitionistic negation
(write it “¬” for the moment) in order to show that A ∧¬A ⊃B holds.37 The
subtleties are to be found in a paper by Meyer [180].)
The same kind of process will help us embed the strict conditional of S4
into E. In E, t is not only true but necessary (as the necessary propositions
are those entailed by t) so the effect of the enthymematic deﬁnition in E is to
get a strict conditional. The result is the strict conditional of E. If we deﬁne
A ⇒B as A∧t →B in E, then the ∧, ∨, ⇒fragment of E is exactly the ∧, ∨, ⇒
fragment of S4 [11, §35].
We can extend the modelling of intuitionistic logic into E if we step further
aﬁeld. We require not only the propositional atom t, but some more machin-
ery: the machinery of propositional quantiﬁcation. If we add propositional
36The ﬁrst axiom here is too strong to govern
  in the logic E, in which case we replace it by
the permuted form
 
 
  . The claim
  doesn’t entail all truths. (If it did, then all truths
would be provable, since
  is provable.) Instead,
  entails all identities.
37You can’t just use the negation of relevant logic, because of course we get
 ⊃
 

  , since
 
 

  .
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
22
quantiﬁers ∀p and ∃p to E38 then intuitionistic and strict implication are de-
ﬁned as follows:
A ⊃B
=df
∃p(p ∧(p ∧A →B))
A ⇒B
=df
∃p(□p ∧(p ∧A →B))
An intuitionistic conditional asserts that there is some truth, such that it con-
joined with A entails B. A strict conditional asserts that there is some neces-
sary truth, such that it conjoined with A entails B.
Embedding the classical conditional into relevant logic is also possible.
The emendation is that not only do we need to show that weakening is pos-
sible, but contradictions must entail everything: and we want to attempt this
without introducing a new negation. The innovation comes from noticing
that we can dualise the enthymematic construction. Instead of just requiring
an extra truth as a conjunct in the antecedent, we can admit an extra false-
hood as a disjunct in the consequent. The classical conditional (also written
“A ⊃B”) can be deﬁned like this
A ∧t →B ∨f
where f = ∼t. Now we will get A ∧∼A ⊃B since A ∧∼A →f.39 Anderson and
Belnap make some sport of material “implication” on the basis of this deﬁni-
tion. Note that constructive implication is still genuinely an implication with
the consequent being what we expect to conclude. A “material” implication
is genuinely an implication, but you cannot conclude with the consequent of
the original “conditional.” No, you can only conclude the consequent with a
disjoined ∨f.40
Arguments about disjoined fs lead quite well into arguments over the law
of disjunctive syllogism, and these are the focus of our next section.
2.4
Disjunctive Syllogism
We have already seen that Ackermann’s system Π ′ differs from Anderson and
Belnap’s system E by the presence of the rule (γ). In Ackermann’s Π ′, we can
directly infer B from the premises A ∨B and ∼A. In E, this is not possible: for
E a rule of inference from X to B is admitted only when there is some corre-
sponding entailment from X (or the conjunction of formulas in X) to A. As
disjunctive syllogism in an entailment
(A ∨B) ∧∼A →B
is not present, Anderson and Belnap decided to do without the rule too. This
motivates a question. Does dropping the rule (γ) change the set of theorems?
38And the proof theory for propositional quantiﬁers is not difﬁcult [11, §30–32].
39The result can be extended to the embed the whole of S4 into E (rather than only its positive
fragment of S4) by setting
   
df ∃








 
 



 .
40I suspect that the situation is not quite so bad for material implication. If one treats accep-
tance and rejection, assertion and denial with equal priority, and if you take the role of implica-
tion as not only warranting the acceptance of the consequent, given the acceptance of the an-
tecedent but also the rejection of the antecedent on the basis of the rejection of the consequent,
then the enthymematic deﬁnition of the material conditional seems not so bad [236].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
23
Is there anything you can prove with (γ) that you cannot prove without it? Of
course there are things you can prove from from hypotheses, using (γ) which
cannot be proved without it. In Ackermann’s system Π ′ there is a straightfor-
ward proof for A, ∼A ⇒B. In Anderson and Belnap’s E there is no such proof.
However, this leaves the special case of proofs from no hypotheses. Is it the
case that in E, if ⊢A ∨B and ⊢∼A that ⊢B too? This is the question of the
admissibility of disjunctive syllogism. If disjunctive syllogism is admissible in
E then its theorems do not differ from the theorems of Ackermann’s Π ′.
2.4.1
A Proof of the Admissibility of Disjunctive Syllogism
There are four different proofs of the admissibility of disjunctive syllogism for
logics such as E and R. The ﬁrst three proofs [184, 241, 170] are due to Meyer
(with help from Dunn on the ﬁrst, and help from Routley on the second).
They all depend on the same ﬁrst step, which we will describe here as the way
up lemma. The last proof was obtained by Kripke in 1978 [92]. In this section I
will sketch the third of Meyer’s proofs, because it will illustrate two techniques
which have proved fruitful in the study of relevant and substructural logics. It
is worth examining this result in some detail because it shows some of the
distinctive techniques in the metatheory of relevant logics.
FACT 3 (DISJUNCTIVE SYLLOGISM IS ADMISSIBLE IN E AND R) In both E and R,
if ⊢A ∨B and ⊢∼A then ⊢B.
To present the bare bones of the proof of this result, we need some deﬁnitions.
DEFINITION 4 (THEORIES) A set T of formulas is a theory if whenever A, B ∈T
then A ∧B ∈T, and if A ⊢B then if A ∈T we also have B ∈T. Theories are
closed under conjunction and provable consequence.
Note that theories in relevant logics are rather special. Nonempty theories in
irrelevant logics contain all theorems, since if A ∈T and if B is a theorem then
so is A →B in an irrelevant logic. In relevant logics this is not the case, so
theories need not contain all theorems.
Furthermore, since A ∧∼A →B is not a theorem of relevant logics, the-
ories may be inconsistent without being trivial. A theory might contain an
inconsistent pair A and ∼A, and contain its logical consequences, without
the theory containing every formula whatsoever.
Finally, consistent and complete theories in classical propositional logic
respect all logical connectives. In particular, if A ∨B is a member of a consis-
tent and complete theory, then one of A and B is a member of that theory. For
if neither are, then ∼A and ∼B are members of the theory, and so is ∼(A ∨B)
(by logical consequence) contradicting A ∨B’s membership of the theory. In
a logic like R or E it is quite possible for A ∨B and ∼(A ∨B) to be members
of our theory without the theory becoming trivial. A theory can be complete
without respecting disjunction. It turns out that theories which respect dis-
junction play a very important role, not only in our proof of the admissibility
of disjunctive syllogism, but also in the theory of models for substructural
logics. So, they deserve their own deﬁnition.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
24
DEFINITION 5 (SPECIAL THEORIES) A theory T is said to be prime if whenever
A ∨B ∈T then either A ∈T or B ∈T. A theory T is said to be regular (with
respect to a particular logic) whenever it contains all of the theorems of that
logic.
Now we can sketch the proof of the admissibility of (γ).
PROOF We will argue by reductio, showing that there cannot be a case where
A ∨B and ∼A are provable but B is not. Focus on B ﬁrst. If B is not provable,
we will show ﬁrst that there is a prime theory containing all of the theorems
of the logic but which still avoids B. This stage is the Way Up. We may have
overshot our mark on the Way Up, as a prime theory containing all theorems
will certainly be complete (as C ∨∼C is a theorem in E or R so one of C and
∼C will be present in our theory) but it may not be consistent. If we can have
a consistent complete prime theory containing all theorems but still missing
out B we will have found our contradiction, for since this new theory contains
all theorems, it contains A ∨B and ∼A. By primeness it contains either A
or it contains B. Containing A is ruled out since it already contains ∼A, so
containing B is the remaining option.41 So, the Way Down cuts down our
original theory into a consistent and complete one. Given the way up and the
way down, we will have our result. Disjunctive syllogism is admissible.
□
All that remains is to prove both Way Up and Way Down lemmas.
FACT 6 (WAY UP LEMMA) If ̸⊢A, then there is a regular prime theory T such
that A ̸∈T.
This is a special case of the general pair extension theorem, which is so useful
in relevant and substructural logics that it deserves a separate statement and
a sketch of its proof. To introduce this proof, we need a new deﬁnition to keep
track of formulas which are to appear in our theory, and those which are to
be kept out.
DEFINITION 7 (⊢-PAIRS) An ordered pair ⟨L, R⟩of sets of formulae is said to be
a ⊢-pair if and only if there are no formulas A1, . . . , An ∈L and B1, . . . , Bm ∈R
where A1 ∧· · · ∧An ⊢B1 ∨· · · ∨Bm.
A helpful shorthand will be to write ‘V Ai ⊢W Bj’ for the extended conjunc-
tions and disjunctions. A ⊢-pair is represents a set of formulas we wish to take
to be true (those in the left) and those we wish to take to be false (those in the
right). The process of constructing a prime theory will involve enumerating
the entire language and building up a pair, taking as many formulas as possi-
ble to be true, but adding some as false whenever we need to. So, we say that
a ⊢-pair ⟨L′, R′⟩extends ⟨L, R⟩if and only if L ⊇L ′ and R ⊇R′. We write this as
“⟨L, R⟩⊆⟨L′, R′⟩.” The end point of this process will be a full pair.
DEFINITION 8 (FULL ⊢-PAIRS) A ⊢-pair ⟨L, R⟩is a full ⊢-pair if and only if L∪R
is the entire language.
Full ⊢-pairs are important, as they give us prime theories.
41Note here that disjunctive syllogism was used in the language used to present the proof.
Much has been made of this in the literature on the signiﬁcance of disjunctive syllogism [33, 182].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
25
FACT 9 (PRIME THEORIES FROM FULL ⊢-PAIRS) If ⟨L, R⟩is a full ⊢-pair, L is a
prime theory.
PROOF
We need to verify that L is closed under consequence and conjunc-
tion, and that it is prime. First, consequence. Suppose A ∈L and that A ⊢B.
If B ̸∈L, then since ⟨L, R⟩is full, B ∈R. But then A ⊢B contradicts the condi-
tion that ⟨L, R⟩is a ⊢-pair.
Second, conjunction. If A1, A2 ∈x, then since A1 ∧A2 ⊢A1 ∧A2, and
⟨L, R⟩is a ⊢-pair, we must have A1∧A2 ̸∈y, and since ⟨L, R⟩is full, A1∧A2 ∈L
as desired.
Third, primeness. If A1 ∨A2 ∈L, then if A1 and A2 are both not in L, by
fullness, they are both in R, and since A1 ∨A2 ⊢A1 ∨A2, we have another
contradiction to the claim that ⟨x, y⟩is a ⊢-pair. Hence, one of A1 and A2 is in
R, as we wished.
□
FACT 10 (PAIR EXTENSION THEOREM) If ⊢is the logical consequence relation
of a logic including all distributive lattice properties, then any ⊢-pair ⟨L, R⟩is
extended by some full ⊢-pair ⟨L′, R′⟩.
To prove this theorem, we will assume that we have enumerated the language
so that every formula in the language is in the list C1, C2, . . . , Cn, . . . We will to
consider each formula one by one, to check to see whether we should throw it
in L or in R instead. We assume, in doing this, that our language is countable.42
PROOF
First we show that if ⟨L, R⟩is a ⊢-pair, then so is at least one of ⟨L ∪
{C}, R⟩and ⟨L, R ∪{C}⟩, for any formula C. Equivalently, we show that if ⟨L ∪
{C}, R⟩is not a ⊢-pair, then the alternative, ⟨L, R ∪{C}⟩, is. If this were not a
⊢-pair either, then there would be some A ∈V L (the set of all conjunctions
of formulae from L) and B ∈W R where A ⊢B ∨C. Since ⟨L ∪{C}, R⟩is not a
⊢-pair, there are also A′ ∈V L and B′ ∈W R such that A′ ∧C ⊢B′. But then,
A∧A′ ⊢B∨C. But this means that A∧A′ ⊢(B∨C)∧A′. Now by distributive
lattice properties, we then get A ∧A′ ⊢B ∨(A′ ∧C). But A′ ∧C ⊢B′, so cut,
and disjunction properties give us A ∧A ′ ⊢B ∨B′, contrary to the fact that
⟨L, R⟩is a ⊢-pair.
With that fact in hand, we can create our full pair. Deﬁne the series of
⊢-pairs ⟨Ln, Rn⟩as follows. Let ⟨L0, R0⟩= ⟨L, R⟩, and given ⟨Ln, Rn⟩deﬁne
⟨Ln+1, Rn+1⟩in this way.
⟨Ln+1, Rn+1⟩=
 ⟨Ln ∪{Cn}, Rn⟩
if ⟨Ln ∪{Cn}, Rn⟩is a ⊢-pair,
⟨Ln, Rn ∪{Cn}⟩
otherwise.
Each ⟨Ln+1, Rn+1⟩is a ⊢-pair if its predecessor ⟨Ln, Rn⟩is, for there is always
a choice for placing Cn while keeping the result a ⊢-pair. So, by induction
on n, each ⟨Ln, Rn⟩is a ⊢-pair. It follows then then ⟨S
n∈ω Ln, S
n∈ω Rn⟩, the
limit of this process, is also a ⊢-pair, and it covers the whole language. (If
⟨S
n∈ω Ln, S
n∈ω Rn⟩is not a ⊢-pair, then we have some Ai ∈S Ln and some
Bj ∈S Rn such that A1 ∧· · · ∧Al ⊢B1 ∨· · · ∨Bm, but if this is the case, then
there is some number n where each Ai is in Ln and each Bj is in Rn. It would
follow that ⟨Ln, Rn⟩is not a ⊢-pair. So, we are done.
□
42The general kind of proof works for well-ordered languages as well as countable languages.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
26
Belnap proved the Pair Extension Theorem in the early 1970s. Dunn cir-
culated a write-up of it in about 1975, and cited it in some detail in 1976 [80].
Gabbay independently used the result for ﬁrst-order intuitionistic logic, also
in 1976 [106]. The theorem gives us the Way Up Lemma, because if ̸⊢B, then
⟨Th, {B}⟩is a ⊢-pair, where Th is the set of theorems. Then this pair is extended
by a full pair, the left part of which is a regular prime theory, avoiding B.
Now we can complete our story with the proof of the Way Down Lemma.
PROOF
We must move from our regular prime theory T to a consistent reg-
ular prime theory T ∗⊆T. We need the concept of a “metavaluation.” The
concept and its use in proving the admissibility (γ) is ﬁrst found in Meyer’s
paper from 1976 [170]. A metavaluation is a set of formulas T ∗on formulas
deﬁned inductively on the construction of formulas as follows:
⋄For a propositional atom p, p ∈T ∗if and only if p ∈T;
⋄∼A ∈T ∗iff (a) A ̸∈T ∗, and (b) ∼A ∈T;
⋄A ∧B ∈T ∗iff both A ∈T ∗and B ∈T ∗;
⋄A ∨B ∈T ∗iff either A ∈T ∗or B ∈T ∗;
⋄A →B ∈T ∗iff (a) if A ∈T ∗then B ∈T ∗and (b) A →B ∈T.
Note the difference between the clauses for the extensional connectives ∧
and ∨and the intensional connectives →and ∼. The extensional connectives
have one-punch rules which match their evaluation with respect to truth ta-
bles. The intensional connectives are more complicated. They require both
that the formula is in the original theory and that the extensional condition
holds in the new set T ∗.
We will prove that T ∗is a regular theory. Its primeness and consistency are
already delivered by ﬁat, from the clauses for ∨and ∼. The ﬁrst step on the
way is a simple lemma.
FACT 11 (COMPLETENESS LEMMA) If A ∈T ∗then A ∈T, and if A ̸∈T ∗then
¬A ∈T.
It is simplest to prove both parts together by induction on the construction
of A. As an example, consider the case for implication. The positive part
is straightforward: if A →B ∈T ∗then A →B ∈T by ﬁat. Now suppose
A →B ̸∈T ∗. Then it follows that either A →B ̸∈T or A ∈T ∗and B ∈T ∗. In
the ﬁrst case, by the completeness of T, ∼(A →B) ∈T follows immediately. In
the second case, A ∈T ∗(so by the induction hypothesis, A ∈T) and B ̸∈T ∗
(so by the induction hypothesis, ∼B ∈T). Since A, ∼B ⊢∼(A →B) in both R
and E, we have ∼(A →B) ∈T, as desired.
It is also not too difﬁcult to check that T ∗is a regular theory. First, T ∗
is closed under conjunction (by the conjunction clause) and it is detached
(closed under modus ponens, by the implication clause). To show that it is a
regular theory, then, it sufﬁces to show that every axiom of the Hilbert system
for R is a member. To give you an idea of how it goes, I shall consider two
typical cases.
First we check sufﬁxing: (A →B) →((B →C) →(A →C)). Suppose it
isn’t in T ∗. Since it is a theorem of the logic and thus a member of T, it satisﬁes
the intensional condition and so must fail to satisfy the extensional condition.
So A →B ∈T ∗and (B →C) →(A →C) ̸∈T ∗. By the Completeness Lemma,
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
27
then A →B ∈T, and so by modus ponens from the sufﬁxing axiom itself, we
have that (B →C) →(A →C) ∈T. So (B →C) →(A →C) satisﬁes the
intensional condition, and so must fail to satisfy the extensional condition:
B →C ∈T ∗and A →C ̸∈T ∗. By similar reasoning we derive that A →C
must ﬁnally fail to satisfy the extensional condition, i.e. A ∈T ∗and C ̸∈T ∗.
But since of A →B ∈T ∗, B →C ∈T ∗, A ∈T ∗, by the extensional condition,
C ∈T ∗, and we have a contradiction.
Second, check double negation elimination: ∼∼A →A. Suppose it isn’t in
T ∗. Again, since it’s a theorem of the logic and thus a member of T, if it fails it
must fail the extensional condition. So, ∼∼A ∈T ∗but A ̸∈T ∗. Since ∼∼A ∈T ∗,
by the negation clause, we have both ∼A ̸∈T ∗and ∼∼A ∈T. From ∼∼A ∈T,
using double negation elimination, we get A ∈T. Using the negation clause
again, unpacking ∼A ̸∈T ∗, we have either A ∈T ∗or ∼A ̸∈T. The ﬁrst possibil-
ity clashes with our assumption that A ̸∈T ∗. The second possibility, ∼A ̸∈T
clashes again with A ̸∈T ∗, using the Completeness Lemma.
The same techniques show that each of the other axioms are also present
in T ∗. Finally T ∗is closed under modus ponens, and as a result, T ∗is a com-
plete, consistent regular theory, and a subset of T. This completes our proof
of the Way Down Lemma.
□
Meyer pioneered the use of metavaluations in relevant logic [178, 181].
Metavaluations were also used be Kleene in his study of intuitionistic theo-
ries [143, 144], who was in turn inspired by Harrop, who used the technique
in the 1950s to prove primeness for intuitionistic logic [128].
There are many different proofs of the admissibility of disjunctive syllo-
gism. Meyer pioneered the technique using metavaluations, and Meyer and
Dunn have used other techniques [183, 184]. Friedman and Meyer showed
that disjunctive syllogism fails in ﬁrst-order relevant Peano arithmetic [103],
but that it holds when you add an inﬁnitary “omega” rule. Meyer and I have
used a different style of metavaluation argument to construct a complete
“true” relevant arithmetic [189]. This metavaluation argument treats nega-
tion with “one punch” clause: ∼A ∈T ∗if and only if A ̸∈T ∗. In this arithmetic,
0 = 1 →0 = 2 is a theorem, as you can deduce 0 = 2 from 0 = 1 by arithmetic
means, while ∼(0 = 2 →0 = 1) is a theorem, as there is no way, by using
multiplication, addition and identity, to deduce 0 = 1 from 0 = 2.
2.4.2
Interpretation
A great deal of the literature interpreting relevant logics has focussed on the
status of disjunctive syllogism. The relevantist of Belnap and Dunn’s essay
“Entailment and Disjunctive Syllogism” [33] is a stout hearted person who
rejects all use of disjunctive syllogism. Belnap and Dunn explain how difﬁcult
it is to maintain this line. Once you learn A ∨B and you learn ∼A, it is indeed
difﬁcult to admit that you have no reason at all to conclude B. Stephen Read
is perhaps the most prominent relevantist active today [223, 224]. Read’s way
of resisting disjunctive syllogism is to argue that in any circumstance in which
there is pressure to conclude B from A∨B and ∼A, we have pressure to admit
more than A ∨B: we have reason to admit ∼A →B, which will licence the
conclusion to B.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
28
Some proponents of relevantists reject disjunctive syllogism not merely
because it leads to fallacies of relevance, but because it renders non-trivial
but inconsistent theories impossible [186, 238]. The strong version of this
view is that inconsistencies are not only items of non-trivial theories, they are
genuine possibilities [217]. Such a view is dialetheism, the thesis that contra-
dictions are possible. Not all proponents of relevant logics are dialetheists,
but dialetheism has provided a strong motivation for research into relevant
logics, especially in Australia.43
My view on this issue differs from both the relevantist, the dialetheist and
the classicalist (who accepts disjunctive syllogism, and hence rejects relevant
logic) pluralistic [22, 233]. Disjunctive syllogism is indeed inappropriate to
apply to the content of inconsistent theories. However it is impossible that
the premises of a disjunctive syllogism be true while if the very same time
the conclusion is false. Relevant entailment is not the only constraint under
which truth may be regulated. Relevant entailment is one useful criterion
for evaluating reasoning, but it is not the only one. If we are given reason to
believe A ∨B and reason to believe ∼A, then (provided that these reasons to
do not conﬂict with one another) we have reason to believe B. This reason is
not one licensed by relevant consequence, but relevant consequence is not
the only sort of licence to which a good inference might aspire.
Debate over disjunctive syllogism has motivated interesting formal work
in relevant logics. If you take the lack of disjunctive syllogism to be a fault
in relevant logics, you can always add a new negation (say, Boolean negation,
written ‘−’) which satisﬁes the axioms A∧−A →B and A →B∨−B. Then rel-
evant logics are truly systems of modal logic extending classical propositional
logic with two modal or intensional operators, ∼(a one-place operator) and
→(a two-place operator). Meyer and Routley have presented alternative ax-
iomatisations of relevant logics which contain Boolean negation ‘−’, and the
material conditional A ⊃B =df −A∨B, as the primary connective [191, 192].
2.5
Lambek Calculus
Lambek worked on his calculus to model the behaviour of syntactic and se-
mantic types in natural languages. He used technique from proof theory [149,
150] (as well as techniques from category theory which we will see later [151]).
His techniques built on work of Bar-Hillel [15] and Ajdukiewicz [4] who in
turn formalised some insights of Husserl.
The logical systems Lambek studied contain implication connectives and
a fusion connective. Fusion in this language is not commutative, so it nat-
urally motivates two implication connectives →and ←.44 We get two arrow
connectives because we may residuate A ◦B ⊢C by isolating A on the an-
43See the Australian entries in the volume “Paraconsistent Logic: Essays on the Inconsis-
tent” [221], for example [46, 49, 173, 219, 254].
44Lambek wrote the two implication connectives as “
 ” for

and “
  ” for

, and fusion as
concatenation, but to keep continuity with other sections I will use the notation of arrows and
the circle for fusion.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
29
tecedent, or equally, by isolating B.
A ⊢B →C
=========
A ◦B ⊢C
=========
B ⊢C ←A
If A ◦B has the same effect as B ◦A, then B →C will have the same effect as
C ←A. If B ◦A differs from A ◦B then so will →and ←.
One way to view Lambek’s innovation is to see him as to motivating and
develop a substructural logic in which two implications have a natural home.
To introduce this system, consider the problem of assigning types to strings
in some language. We might assign types to primitive expressions in the lan-
guage, and explain how these cold be combined to form complex expressions.
The result of such a task is a typing judgement of the form x ⊩A, indicating
that the string x has the type A. Here are some example typing judgements.
John
⊩
n
poor
⊩
n →n
John works
⊩
s
works
⊩
s ←n
must work
⊩
s ←n
work
⊩
i
must
⊩
i →(s ←n)
John work
⊩
n ◦i
Types can be atomic or complex: they form an algebra of formulas just like
those in a propositional logic. Here, the judgement “John ⊩n” says that the
string John has the type n (for name, or noun). The next judgement says that
poor has a special compound type n →n: it converts names to names. It does
this by composition. The string poor has the property that when you preﬁx it
to a string of type n you get another (compound) string of type n. So, poor
John has type n. So does poor Jean, and poor Joan of Arc (if Jean and Joan
of Arc have the requisite types).45 Strings can, of course, be concatenated
at the end of other strings too. The string works has type s ←n because
whenever you sufﬁx a string of type n with works you get a string of type s (a
sentence). John works, poor Joan works and poor poor Joan of Arc works
are all sentences, according to this grammar.
Typing can be nested arbitrarily. We see that must work has type s ←n
(it acts like works). The word work has type i (intransitive inﬁnitive) so must
has type i →(s ←n). When you concatenate it in front of any string of type
i you get a string of type s ←n. So must play and must subscribe to New
Scientist also have type s ←n, as play and subscribe to New Scientist
have type i.
Finally, compositions have types even if the results do not have a pred-
iﬁned simple type. John work at least has the type n◦i, as it is a concatenation
of a string of type n with a string of type i. The string must work also has type
(i →(s ←n)) ◦i, because it is a composition of a string of type i →(s ←n)
45According to this deﬁnition, poor poor John and poor poor poor poor Joan of Arc are
also strings of type
  .
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
30
with a string of type i. Clearly here fusion is not commutative. John work has
type n ◦i, but work John does not. As a corollary, →and ←differ. Given the
associativity of concatenation of strings, fusion is associative too. Any string
of type A◦(B◦C) is of type (A◦B)◦C. We can associate freely in any direction.46
Once we have a simple type system like this, typing inferences are then
possible, on the basis of the interactions of the type-constructors →, ←and
◦. One of Lambek’s innovations was to notice that this type system can be
manipulated using a simple Gentzen-style consecution calculus. This calcu-
lus manipulates consecutions of the form A1, A2, . . . , An ⊢B. We read this
consecution as asserting that any string which is a concatenation of strings of
type A1, A2, ..., An also has type B.47 A list of types will be treated as a type
in my explanations below.48
The system is made up of one axiom and a collection of rules. The ele-
mentary type axiom is the identity.
A ⊢A
Any string of type A is of type A. The rules introduce type constructors on the
left and the right of the turnstile. Here are the rules for the left-to-right arrow.
X, A ⊢B
 

X ⊢A →B
X ⊢A
Y, B, Z ⊢C
 

Y, A →B, X, Z ⊢C
If you have any string of type X concatenated with a string of type A is a string
of type B, then this means that X is of type A →B. Conversely, if any string
of type X is also of type A, and strings of type Y, B, Z are also of type C, then
strings of type Y, A →B, X, Z are also of type C. Why is this? It is because
strings of type A →B, X are also of type B, because they are concatenations
of a string of type A →B to the left of a string of type X (which also has type
A). The mirror image of this reasoning motivates the right-to-left conditional
rules:
A, X ⊢B
 

X ⊢B ←A
X ⊢A
Y, B, Z ⊢C
 

Y, X, B ←A, Z ⊢C
The next rules make fusion the direct object language correlate of the comma
in the metalanguage.
X ⊢A
Y ⊢B
  ◦

X, Y ⊢A ◦B
X, A, B, Y ⊢C
  ◦

X, A ◦B, Y ⊢C
Proofs in this system are trees with consecutions at the nodes, and whose
leaves are axioms of identity. Each step in the tree is an instance of one or
other of the rules. Here is a proof, showing that the preﬁxing axiom holds in
46We can associate fusion freely, not the conditionals.
 

 

 is not the same type as
 
 

 , as you can check.
47Lambek used the same notation (an arrow) to stand ambiguously for the two relations we
mark with

and ⊢respectively.
48The list constructor is the metalinguistic analogue of the fusion connective. Note too that
“metalinguistic” here means the metalanguage of the type language, which itself is a kind of met-
alanguage of the language of strings which it types.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
31
rule form.49
C ⊢C
A ⊢A
B ⊢B




A →B, A ⊢B




A →B, C →A, C ⊢B




A →B, C →A ⊢C →B




A →B ⊢(C →A) →(C →B)
Here is another proof, which combines both implication connectives.
C ⊢C
A ⊢A
B ⊢B




A →B, A ⊢B




C, (A →B) ←C, A ⊢B




(A →B) ←C, A ⊢B ←C




(A →B) ←C ⊢A →(B ←C)
A proof system like this has a number of admirable properties. Most obvious
is the clean division of labour in the rules for each connective. Each rule fea-
tures only the connective being introduced, whether in antecedent (left) or
consequent (right) position. Another admirable property is the way that for-
mulas appearing in the premises also appear in the conclusion of a rule (ei-
ther as entire formulas or as subformulas of other formulas). In proof search,
there is no need to go looking for other intermediate formulas in the proof of
a consecution. These two facts prove simple conservative extension results.
Adding ◦to the logic of ←and →would result in no more provable consecu-
tions in the original language, because a proof of a consecution involving no
fusions could not involve any fusions at all.
All of this would be for naught if the deduction system were incomplete. If
it didn’t match its intended interpretation, these beautiful properties would
be useless. One important step toward proving that the deduction system is
complete is proving that the cut rule is admissible. (Recall that a rule is admis-
sible if whenever you can prove the premises you can prove the conclusion:
adding it as an extra rule does not increase the stock of provable things.)
X ⊢A
Y, A, Z ⊢B
 
  

Y, X, Z ⊢B
This is not a primitive rule in our calculus, because adding it would destroy
the subformula property, and make proof search intolerably unbounded. It
ought to be admissible because of the intended interpretation of ⊢. If X ⊢A,
every string of type X is also of type A. If Y, A, Z ⊢B, then every string which is
a concatenation of a Y an A and a Z has type B. So, given a concatenation of
a Y and an X and a Z, this is also a type B since the string of type X is a string
of type A. The cut rule expresses the transitivity of the “every string of type x
is of type y” relation.
49There is no sense at this point in which some type is a theorem of the calculus, so we focus
on the consecution forms of axioms, in which the main arrow is converted into a turnstile.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
32
FACT 12 (CUT IS ADMISSIBLE IN THE LAMBEK CALCULUS) If X ⊢A is provable
in the Lambek calculus with the aid of the cut rule, it can also be proved with-
out it.
PROOF
Lambek’s proof of the cut admissibility theorem parallels Gentzen’s
own [111, 112]. You take a proof featuring a cut and you push that cut up-
wards to the top of the tree, where it evaporates. So, given an instance of the
cut rule, if the formula featured in the cut is not introduced in the rules above
the cut, you permute the cut with the other rules. (You show that you could
have done the cut before applying the other rule, instead of after.) Once that
is done as much as possible, you have a cut where the cut formula was in-
troduced in both premises of the cut. If the formula is atomic, then the only
way it was introduced was in an axiom, and the instance of cut is irrelevant
(it has evaporated: cutting Y, A, Z ⊢B with A ⊢A gives us just Y, A, Z ⊢B). If
the formula is not atomic, you show that you could trade in the cut on that
formula with cuts on smaller formulas. Here is an example cut on the impli-
cation formula A →B introduced in both left and right branches.
W, A ⊢B
 

W ⊢A →B
X ⊢A
Y, B, Z ⊢C
 

Y, A →B, X, Z ⊢C
 
  
 

Y, W, X, Z ⊢C
We can transform it so that cuts occur on the subformulas of A →B.
X ⊢A
W, A ⊢B
 
  

W, X ⊢B
Y, B, Z ⊢C
 
  

Y, W, X, Z ⊢C
The cases for the other formulas are just as straightforward. As formulas have
only ﬁnite complexity, and trees have only ﬁnite height, this process termi-
nates.
□
The result that cut is admissible gives us a decision procedure for the calculus.
FACT 13 (DECIDABILITY OF THE LAMBEK CALCULUS) The issue of whether or
not a consecution X ⊢A has a proof is decidable.
PROOF
To check if X ⊢A is provable, consider its possible ancestors in the
Gentzen proof system. There are only ﬁnitely many ancestors, each corre-
sponding to the decomposition of one of the formulas inside the consecution.
(The complex cases are the implication left rules, which give you the option
of many different possible places to split the Y in the antecedent X, A →B, Y
or Y, B ←A, X, and the fusion right rule, which gives you the choice of loca-
tions to split X in X ⊢A ◦B.) The possible ancestors themselves are simpler
consecutions, with fewer connectives. Decision of consecutions with no con-
nectives is trivial (X ⊢p is provable if and only if X is p) so we have our algo-
rithm by a recursion.
□
This decision procedure for the calculus is exceedingly simple. Gentzen’s pro-
cedure for classical and intuitionistic logic has to deal with the structural rule
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
33
of contraction:50
X(Y, Y) ⊢A
  WI

X(Y) ⊢A
which states that if a formula is used twice in a proof, it may as well have been
used once. This makes proof search chronically more difﬁcult, as some kind
of limit must be found on how many consecutions might have appeared as
the premises of the consecution we are trying to prove.
Sometimes people refer to the Lambek calculus as a logic without struc-
tural rules, but this is not the case. The Lambek calculus presumes the as-
sociativity of concatenation. A proper generalisation of the calculus treats
antecedent structures not as lists of formulas but as more general bunches for
which the comma is a genuine ordered-pairing operation. In this case, the
antecedent structure A, (B, C) is not the same structure as (A, B), C.51 Lam-
bek’s original calculus is properly called Lambek’s associative calculus. The
non-associative calculus can no longer prove the preﬁxing consecution. (Try
to follow through the proof in the absence of associativity. It doesn’t work.)
Of course, given a non-associative calculus, you must modify the rules for the
connectives. Instead of the rules with antecedent X, A, Y ⊢B we can have
X(A) ⊢B, where “X(A)” indicates a structure with a designated instance of A.
The rule for implication on the left becomes, for example
X ⊢A
Y(B) ⊢C
 

Y(A →B, X) ⊢C
Absence of structural rules also makes other things fail. The structural rule of
contraction (W) is required for the contraction consecution.52
X((Y, Z), Z)) ⊢A
  W

X(Y, Z) ⊢C
A ⊢A
A ⊢A
B ⊢B




A →B, A ⊢B




((A →(A →B), A), A) ⊢B
 W

A →(A →B), A ⊢B




A →(A →B) ⊢A →B
50You’ll see that the structural rule is stated in generality: contraction operates on arbitrary
structures, in arbitrary contexts. This is needed for the cut elimination process. If we could
contract only whole formulas, then if we wanted to push a cut past the move from
     ⊢
 to
   ⊢
  , where we are cutting with

 
⊢
 , the result would require us to somehow get
from
 


 

 

 

 ⊢
 to
 

 
 ⊢
  . We cannot do this if cut operates only on formulas,
and if associativity or commutativity is absent.
51Non-associative combination plays an important role in general grammars, according to
Lambek [150]. The role of some conversions such as wh- constructions (replacing names by
“who”, to construct questions, etc.) seem to require a ﬁner analysis of the phrase structure of
sentences, and seem to motivate a rejection of associativity.
Commutative composition may also have a place in linguistic analysis. Composition of differ-
ent gestures in sign language may run in parallel, with no natural ordering. This kind of com-
position might be best modelled as distinct from the temporal ordered composition of different
sign units. In this case, we have reason to admit two forms of composition, a situation we will see
more of later.
52Sometimes you see it claimed that (WI) is required for the contraction consecution, this is
true in the presence of associativity, but can fail outside that context. The rule (WI) corresponds
to the validity of
 
 
  ⊢
  . It does not correspond to the validity of any consecution in
the

only fragment of the language.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
34
The structural rule of weakening (K) is required for the weakening axiom,
X(Y) ⊢C
  K

X(Y, Z) ⊢C
A ⊢A
 K

A, B ⊢A




A ⊢B →A
and the structural rule of permutation (C) gives the permutation axiom.
X(Y1, (Y2, Z)) ⊢D
  C

X(Y2, (Y1, Z)) ⊢D
A ⊢A
B ⊢B
C ⊢C




B →C, B ⊢C




(A →(B →C), A), B ⊢C
 C

(A →(B →C), B), A ⊢C




A →(B →C), B ⊢A →C




A →(B →C) ⊢B →(A →C)
Finally (for this brief excursus into the effect of structural rules) the mingle
rule (M) has been of interest to the relevant logic community. It is the con-
verse of WI contraction, and a special instance of weakening (K). It corre-
sponds to the mingle consecution A ⊢A →A, whose addition to R results
in the well-behaved system RM. We will consider models of RM in the next
section.
X(Y) ⊢C
  M

X(Y, Y) ⊢C
A ⊢A
 M

A, A ⊢A




A ⊢A →A
There are many different structural rules which feature in different logics for
different purposes. Table 1 contains some prominent structural rules. I use
the notation X ⇐Y to stand for the structural rule
Z(X) ⊢A
Z(Y) ⊢A
You can replace Y by X (reading the proof upwards) in any context in an an-
tecedent.
This proliferation of options concerning structural rules leaves us with the
issue of how to choose between them. In some cases, such as Lambek’s anal-
ysis of typing regimes on languages, the domain is explicit enough for the
appropriate structural rules to be “read off” the objects being modelled. In
the case of ﬁnding an appropriate logic of entailment, the question is more
fraught. Anderson and Belnap’s considerations in favour of the logic E are
by no means the only choices available for a relevantist. Richard Sylvan’s
depth relevant program [139, 242] and Brady’s constraints of concept contain-
ment [45, 48] motivate logics much weaker than E. They motivate logics with-
out weakening, commutativity, associativity and contraction.
Let’s return to Lambek, after that excursus on structural rules. In one of
his early papers, Lambek considered adding conjunction to his calculus with
these rules [150].
X ⊢A
X ⊢B
 

X ⊢A ∧B
X(A) ⊢C
 

 
X(A ∧B) ⊢C
X(B) ⊢C
 



X(A ∧B) ⊢C
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
35
Name
Label
Rule
Associativity
B
X, (Y, Z)
⇐
(X, Y), Z
Twisted Associativity
B′
X, (Y, Z)
⇐
(Y, X), Z
Converse Associativity
Bc
(X, Y), Z
⇐
X, (Y, Z)
Strong Commutativity
C
(X, Y), Z
⇐
(X, Z), Y
Weak Commutativity
CI
X, Y
⇐
Y, X
Strong Contraction
W
(X, Y), Y
⇐
X, Y
Weak Contraction
WI
X, X
⇐
X
Mingle
M
X
⇐
X, X
Weakening
K
X
⇐
X, Y
Commuted Weakening
K′
X
⇐
Y, X
Table 1: Structural Rules
Adding disjunction with dual rules is also straightforward.
X ⊢A
 

 
X ⊢A ∨B
X ⊢B
 



X ⊢A ∨B
X(A) ⊢C
X(B) ⊢C
 

X(A ∨B) ⊢C
Conjunctive and disjunctive types have clear interpretations in the calculus of
syntactic types. In English, and is promiscuous. It conjoins sentences, names,
verbs, and other things. It makes sense to say that it has a conjunctive type
and ⊩((a1 →a1) ←a1) ∧· · · ∧((an →an) ←an)
for n types ai.53 Similarly, disjunctive types have a simple interpretation.
⋄x ⊩A ∧B if and only if x ⊩A and x ⊩B.
⋄x ⊩A ∨B if and only if x ⊩A or x ⊩B.
Lambek’s rules for conjunction and disjunction are satisﬁed under this inter-
pretation of their behaviour. Lambek’s rules are sound for this interpretation.
Cut is still admissible with the addition of these rules. It is straightforward
to permute cuts past these rules, and to eliminate conjunctions introduced
simultaneously by both. However, the addition results in the failure of distri-
bution. The traditional proof of distribution (in Figure 2) requires both con-
traction and weakening. This means that the simple rules for conjunction
and disjunction (in the context of this proof theory, including its structural
rules) are incomplete for the intended interpretation.
2.6
Kripke’s Decidability Technique for R[→, ∧]
Lambek’s proof theory for the calculus of syntactic types has a close cousin,
for the relevant logic R. Within a year of Lambek’s publication of his calculus
53Actually it makes sense to think of and as having type ∀









 . However, proposi-
tionally quantiﬁed Lambek calculus is a wide-open ﬁeld. No-one that I know of has explored this
topic, at the time of writing.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
36
A ⊢A
(K)
A, B ⊢B
B ⊢B
(K)
A, B ⊢B




A, B ⊢A ∧B




A, B ⊢(A ∧B) ∨(A ∧C)
A ⊢A
(K)
A, C ⊢C
C ⊢C
(K)
A, C ⊢C




A, C ⊢A ∧C




A, C ⊢(A ∧B) ∨(A ∧C)




A, B ∨C ⊢(A ∧B) ∨(A ∧C)




A, A ∧(B ∨C) ⊢(A ∧B) ∨(A ∧C)




A ∧(B ∨C), A ∧(B ∨C) ⊢(A ∧B) ∨(A ∧C)
(WI)
A ∧(B ∨C) ⊢(A ∧B) ∨(A ∧C)
Figure 2: Proof of Distribution of ∧over ∨
of types, Saul Kripke published a decidability result using a similar Gentzen
system for the implication fragments of the relevant logics R and E [147].
Kripke’s results extend without much modiﬁcation to the implication and
conjunction fragments of these logics, and less straightforwardly to the im-
plication, negation fragment [35, 27, 10] or to the whole logic without dis-
tribution [174] (Meyer christened the resulting logic LR for lattice R). I will
sketch the decidability argument for the implication and conjunction frag-
ment R[→, ∧], and then show how LR can be embedded within R[→, ∧], ren-
dering it decidable as well.
The technique uses the Gentzen proof system for R[→, ∧], which is a ver-
sion of the Gentzen systems seen in the previous section. It uses the the same
rules for →and ∧, and it is modiﬁed to make it model the logic R. We have
the structural rules of associativity and commutativity (which we henceforth
ignore, taking antecedents of consecutions to be multisets of formulas). We
add also the structural rule WI of contraction. Cut is eliminable from this sys-
tem, using standard techniques. However, the decidability of the system is
not straightforward, given the presence of the rule WI. WI makes proof-search
ﬁendishly difﬁcult. The main strategy of the decision procedure for R[→, ∧]
is to limit applications WI in order to prevent a proof search from running
on forever in the following way: “Is p ⊢q derivable? Well it is if p, p ⊢q is
derivable. Is p, p ⊢q derivable? Well it is if p, p, p ⊢q is ...”
We need one simple notion before this strategy can be explained. We will
say that the consecution X′ ⊢A is a contraction of X ⊢A just in case X′ ⊢A
can be derived from X ⊢A by (repeated) applications of the the structural
rules. (This means contraction, in effect, if you take the structures X and X ′ to
be multisets, identifying different permutations and associations of the for-
mulas therein.) Kripke’s plan is to drop the WI, replacing it by building into
the connective rules a limited amount of contraction.
More precisely, the idea is to allow a contraction of the conclusion of an
connective rule only in so far as the same result could not be obtained by ﬁrst
contracting the premises. A little thought shows that this means no change
for the rules (→R), (∧L) and (∧R), and that the following is what is needed
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
37
sufﬁce to modify (→L).
X ⊢A
Y, B ⊢C
 

′

[X, Y, A →B] ⊢C
where [X, Y, A →B] is any contraction of X, Y, A →B such that
⋄A →B occurs only 0, 1, or 2 times fewer than in X, Y, A →B;
⋄Any formula other than A →B occurs only 0 or 1 time fewer.
It is clear that after modifying the system R[→, ∧] by building some limited
contraction into (→L′) in the manner just discussed, the following lemma is
provable by an induction on length of derivations:
LEMMA 14 (CURRY’S LEMMA) If a consecution X ′ ⊢A is a contraction of a con-
secution X ⊢A and X ⊢A has a derivation of length n, then X ′ ⊢A has a
derivation of length no greater than n.54
This shows that the modiﬁcation of the system leaves the same consecutions
derivable (since the lemma shows that the effect of contraction is retained).
For the rest of this section we will work in the modiﬁed proof system.
Curry’s Lemma also has the corollary that every derivable consecution has
an irredundant derivation: that is, a proof containing no branch with a con-
secution X′ ⊢A below a sequent X ⊢A of which it is a contraction.
Now we can describe the decision procedure. Given a consecution X ⊢A,
you test for provability by building a proof search tree: you place above X ⊢A
all possible premises or pairs of premises from which X ⊢A follows by one
of the rules. Even though we have built some contraction into one rule, this
will be only a ﬁnite number of consecutions. This gives a tree. If a proof of
the consecution exists, it will be formed as a subtree of this proof search tree.
By Curry’s Lemma, the proof search tree can be made irredundant. The tree
is also ﬁnite, by the following lemma.
LEMMA 15 (K ¨ONIG’S LEMMA) A tree with ﬁnitely branching tree with branches
of ﬁnite length is itself ﬁnite.
We have already proved that the tree is ﬁnitely branching (each consecution
can have only ﬁnitely many possible ancestors). The question of the length of
the branches remains open, and this is where an Kripke proved an important
lemma. To state it we need an idea from Kleene. Two consecutions X ⊢A and
X′ ⊢A are cognate just when exactly the same formulas X as in X ′. The class
of all consecutions cognate to a given consecution is called a cognation class.
Now we can state and prove Kripke’s lemma.
LEMMA 16 (KRIPKE’S LEMMA) There is no inﬁnite sequence of cognate conse-
cutions such that no earlier consecution is a contraction of a later consecution
in the sequence.
54The name comes from Anderson and Belnap [10], who note that it is a modiﬁcation of a
lemma due to Curry [61], applicable to classical and intuitionistic Gentzen systems.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
38
This means that the number of cognation classes occurring in any derivation
(and hence in each branch) is ﬁnite. But Kripke’s Lemma also shows that only
a ﬁnite number of members of each cognation class occur in a branch (this
is because we have constructed the complete proof search tree to be irredun-
dant). So every branch is ﬁnite, and so both conditions of K¨onig’s Lemma
hold. It follows that the complete proof search tree is ﬁnite and so there is a
decision procedure. So, a proof of Kripke’s Lemma concludes our search for a
decision procedure for R[∧, →].
PROOF This is not a complete proof of Kripke’s Lemma. (The literature con-
tains some clear expositions [10, 35].) The kernel idea can be seen in a picture.
As a special case, consider consecutions cognate to X, Y ⊢A. Each such con-
secution can be depicted as a point in the upper right-hand quadrant of the
plane, marked with the origin at (1, 1) rather than (0, 0) since X, Y ⊢A is the
minimal consecution in the cognation class. So, X, X, Y, Y, Y, Y ⊢A is repre-
sented as (2, 4): ‘2 X units’ and ‘4 Y units’. Now given any initial consecution,
for example
(Γ0)
X, X, X, Y, Y ⊢A
you might try to build an irredundant sequence by ﬁrst inﬂating the number
of Ys (for purposes of keeping on the page we let this be to 5 rather than 3088).
But then, you have to decrement number of Xs at least by one. The result is
depicted in Figure 3 for the ﬁrst two members of the sequence Γ0, Γ1.
Γ0
Γ1
1
2
3
4
5
6
7
2
3
4
5
6
7
Figure 3: Descending Regions
The purpose of the intersecting lines at each point is to mark off areas
(shaded in the diagram) into which no further points of the sequence may be
placed. If Γ2 were placed as indicated at the point (6, 5), it would reduce to
Γ0. This this means that each new point must proceed either one unit closer
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
39
to the X axis or one unit closer to the Y axis. After a ﬁnite number of choices
the consecutions will arrive at one or other of the two axes, and then after
a time, you will arrive at the other. At that time, no more additions can be
made, keeping the sequence irredundant.
This proof sketch generalises to n-dimensional space, corresponding to
an initial consecution with n different antecedent parts. The only difﬁculty is
in drawing the pictures.55
□
Extending this result to the whole of R (without distribution) is not difﬁ-
cult. You can amend the proof system to manipulate consecutions with struc-
ture on the right as well as on the left. (I won’t present the modiﬁcation of the
rules here because they are the same as the rules for those connectives in lin-
ear logic which we will see in a few sections time.) The system will not prove
the distribution of conjunction over disjunction, but an explicit decision pro-
cedure for the whole logic can be found. This result is due to Meyer, and can
be ﬁrst found in his dissertation [174] from 1966. Meyer also showed how
LR can be embedded in R[→, ∧] by translation. Meyer’s translation is fairly
straightforward, but I will not go through the details here.56 I will sketch a
simpler translation which comes from the Vincent Danos’ more recent work
on linear logic [64, 65], and which is a simple consequence of the soundness
and completeness of phase space models. We translate formulas in the lan-
guage of LR into the language of implication and negation by picking a par-
ticular distinguished proposition in the target language and designating that
as f. Then we deﬁne ∼in the language of R[→, ∧] by setting ∼A to be A →f.
Then the rest of the translation goes as follows:
pt
=
∼∼p
(A ∧B)t
=
∼∼(At ∧Bt)
(A ∨B)t
=
∼(∼At ∧∼Bt)
(A ◦B)t
=
∼(At →∼Bt)
(A →B)t
=
At →Bt
(∼A)t
=
∼At
I will not go through the proof of the adequacy of this translation, as we will
see it when we come to look at phase spaces. However, a direct demonstra-
tion of its adequacy (without an argument taking a detour through models) is
possible.57 Given this translation, any decision procedure for R[→, ∧] trans-
forms into a decision procedure for the whole of LR.
McRobbie and Belnap [168] have translated the implication negation frag-
ment of the proof theory in an analytic tableau style, and Meyer has extended
this to give analytic tableau for linear logic and other systems in the vicinity of
55Meyer discovered that Kripke’s Lemma is equivalent to Dickson’s Theorem about primes:
Given any set of natural numbers all of which are composed out of the ﬁrst
 primes (that is,
every member has the form


1
 

2






k

) if no member of this set has a proper divisor in the
set, then the set is ﬁnite.
56The details of the translation can be found elsewhere [81, 94]. The point which makes the
translation a little more complex than the translation I use here is the treatment of
 and its
negation
  .
57The nicest is due to Danos. Take a proof of
 ⊢

in the calculus for LR and translate it step
by step into a proof of
 
 

 ⊢
 . (Here


 is the collection of the negations of the translations
of each of the elements of
 .) The translation here is exactly what you need to make the rules
correspond (modulo a few applications of Cut).
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
40
R [187]. Neither time nor space allows me to consider tableaux for substruc-
tural logics, save for this reference.
Some recent work of Alasdair Urquhart has shown that although R[→, ∧]
is decidable, it has great complexity [272, 275]: Given any particular formula,
there is no primitive recursive bound on either the time or the space taken by
a computation deciding that formula. Urquhart follows some work in linear
logic [156] by using the logic to encode the behaviour of a branching counter
machines. A counter machine has a ﬁnite number of registers (say, ri for suit-
able i) which each hold one non-negative integer, and some ﬁnite set of possi-
ble states (say, qj for suitable j). Machines are coded with a list of instructions,
which enable you to increment or decrement registers, and test for registers’
being zero. A branching counter machine dispenses with the test instructions
and allows instead for machines to take multiple execution paths, by way of
forking instructions. The instruction qi + rjqk means “when in qi, add 1 to
register rj and enter stage qk,” and qi −rjqk means “when in qi, subtract 1 to
register rj (if it is non-empty) and enter stage qk,” and qifqjqk is “when in qi,
fork into two paths, one taking state qj and the other taking qk.”
A machine conﬁguration is a state, together with the values of each regis-
ter. Urquhart uses the logic LR to simulate the behaviour of a machine. For
each register ri, choose a distinct variable Ri, for each state qj choose a dis-
tinct variable Qj. The conﬁguration ⟨qi; n1, . . . , nl⟩, where ni is the value of
ri is the formula
Qi ◦Rn1
1
◦· · · ◦Rnl
l
and the instructions are modelled by sequents in the Gentzen system, as fol-
lows:
Instruction
Sequent
qi + rjqk
Qi ⊢Qk ◦Rj
qi −rjqk
Qi, Rj ⊢Qk
qifqjqk
Qi ⊢Qj ∨Qk
Given a machine program (a set of instructions) we can consider what is prov-
able from the sequents which code up those instructions. This set of sequents
we can call the theory of the machine. Qi◦Rn1
1 ◦· · ·◦Rnl
l
⊢Qj◦Rm1
1
◦· · ·◦Rml
l
is
intended to mean that from state conﬁguration ⟨qi; n1, . . . , nl⟩all paths will
go through conﬁguration ⟨qj; m1, . . . , ml⟩after some number of steps.
A branching counter machine accepts an initial conﬁguration if when run
on that conﬁguration, all branches terminate at the ﬁnal state qf, with all reg-
isters taking the value zero. The corresponding condition in LR will be the
provability of
Qi ◦Rn1
1
◦· · · ◦Rnl
l
⊢Qm
This will nearly do to simulate branching counter machines, except for the
fact that in LR we have A ⊢A ◦A. This means that each of our registers
can be incremented as much as you like, provided that they are non-zero to
start with. This means that each of our machines need to be equipped with
every instruction of the form qi>0 + rjqi, meaning “if in state qi, add 1 to rj,
provided that it is already nonzero, and remain in state qi.”
Urquhart is able to prove that a conﬁguration is accepted in branching
counter machine, if and only if the corresponding sequent is provable from
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
41
the theory of that machine. But this is equivalent to a formula
^
Theory(M) ∧t →(Q1 →Qm)
in the language of LR. It is then a short step to our complexity result, given the
fact that there is no primitive recursive bound on determining acceptability
for these machines. Once this is done, the translation of LR into R
 ∧gives us
our complexity result.
Despite this complexity result, Kripke’s algorithm has been implemented
with quite some success. The theorem prover Kripke, written by McRobbie,
Thistlewaite and Meyer, implements Kripke’s decision procedure, together
with some quite intelligent proof-search pruning, by means of ﬁnite mod-
els. This implementation works in many cases [263]. Clearly, work must be
done to see whether the horriﬁc complexity of this problem in general can be
transferred to results about average case complexity.
2.7
Richer Structures Gentzen systems for distribution
Grigori Minc [195, 197] and J. Michael Dunn [78] independently developed
a Gentzen-style consecution calculus for relevant logics in the vicinity of R.
As we have seen in the Gentzen calculus for R[→], the distinctive behaviour
of implication arises out of the presence or absence of structural rules gov-
erning the combination of premises. To ﬁnd a logic without the paradoxes of
implication, we are lead to reject the structural rule of weakening. However,
the structural rule of weakening is required to prove distribution.58 Dunn
and Minc’s innovations were to see a way around this apparent impasse. One
way to think of the problem is this: consider the proof of distribution in Fig-
ure 2 on page 36. Focus on the point at which (∨L) is applied. The proof
moves from A, B ⊢· · · and A, C ⊢· · · to A, B ∨C ⊢· · ·. It is this point
at which some form of distribution has just been used: we have used the
disjunction rule inside a comma context. This makes disjunction distribute
over whatever the comma represents. In the case where comma is the met-
alinguistic analogue of fusion (as it is in these proof systems) we can prove
A ◦(B ∨C) ⊢(A ◦B) ∨(A ◦C). We cannot prove the distribution of ex-
tensional conjunction over disjunction simply because there is no structure
able to represent conjunction in this proof system.59 The solution to provide
distribution is then to allow a structure to represent extensional conjunction,
just as there is a structural analogue for intensional conjunction.
In a proof system like this, we deﬁne structures recursively, allowing both
intensional and extensional conjunction.
⋄A formula is a structure.
⋄If X and Y are structures, so is (X; Y). This is the intensional combination
of X and Y.
58At least, it is required if the proof is going to be anything like the proof of distribution in
standard Gentzen systems.
59That is a simpliﬁcation. The proof could be dualised, and work in a proof system with single
antecedent and multiple consequents, for a dual intuitionistic logic. In this case it is the structure
for extensional disjunction which would distribute over the conjunction rule. The relevant part
of a proof would be the move from · · · ⊢
   and · · · ⊢
  
to · · · ⊢
   
 , distributing a
conjunction over a disjunction again.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
42
⋄If X and Y are structures, so is (X, Y). This is the extensional combination
of X and Y.
Then all of the traditional structural rules (B, C, K, W) are admitted for ex-
tensional combination, and only a weaker complement (say, omitting K, for
relevant logic, or all but associativity, for the Lambek calculus, or some other
menu of choices for some other substructural logic) are admitted for inten-
sional combination.
The rules for the connectives may remain unchanged (apart from the no-
tational variation “;” for intensional combination, instead of “,” which was
used up until this point). However, the rules for conjunction may be varied
to match those for fusion: we can instead take extensional conjunction to be
explicitly paired with extensional combination.
X(A, B) ⊢C
[

L′]
X(A ∧B) ⊢C
X ⊢A
Y ⊢B
[

R′]
X, Y ⊢A ∧B
These rules are admissible, given the original structure-free rules, as these
demonstrations show.60
X(A, B) ⊢C
(

L)
X(A ∧B, B) ⊢C
(

L)
X(A ∧B, A ∧B) ⊢C
(WI)
X(A ∧B) ⊢C
X ⊢A
(K)
X, Y ⊢A
Y ⊢B
(K)
Y, X ⊢B
(C)
X, Y ⊢B
(

R)
X, Y ⊢A ∧B
The modiﬁed proof theory is sound and complete for the relevant logic R and
its neighbours. The cut elimination proof works as before — even with richer
structures, the conditions of the cut elimination proof (permutability of cut
with other rules, eliminability of matching principal formulas) are still satis-
ﬁed. The subformula property is also satisﬁed, and the proof theory
However, the beneﬁcial consequences of a cut-free Gentzen system for a
logic — its decidability — is not always available. The difﬁculty is the pres-
ence of contraction for extensional combination. This is not surprising, be-
cause as we will see later, R is undecidable. You cannot extract a decision pro-
cedure from its Gentzen calculus. However, in the absence of expansive rules
such as W and WI, a decision procedure can be found, as Steve Giambrone
found in the early 1980s [114]. Giambrone’s decidability argument for the
negation-free fragment of R without contraction (which, we will see, is equiv-
alent to linear logic with distribution added) and also for positive TW. Ross
Brady extended this argument in the early 1990s to show that RW and TW
are decidable [47]. Brady’s technique involved extending the Gentzen system
with signed formulas, to give straightforward rules for negation without re-
sorting to a multiple consequent calculus.
Other extensions to this proof theory are possible for different applica-
tions. Belnap, Dunn and Gupta extended Dunn’s original work to model R
with an S4-style necessity [34]. I have shown how a system like this one can
be used to motivate an extension of the Lambek calculus which is sound and
60The converse proofs, to the effect that (

L) and (

R) are admissible in the presence of (

L ′)
and (

R′) are just as simple.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
43
complete for its intended interpretation on conjunction and disjunction on
frame models [228] (unlike the structure-free rules which Lambek originally
proposed).
The natural deduction analogue of the Gentzen system has been the focus
of much attention, too. Read uses the natural deduction system as the basis
of his presentation of R in his Relevant Logic [224]. Slaney, in an inﬂuential
article from 1990 [256] gives a philosophical defence of the two different sorts
of bunching operators, characterising extensional combination of bodies of
information as a monotonic lumping of information together, while taking
intensional combination of X with Y (that’s X; Y) as the application of X to Y.
This distinction motivates the rules for implication (X ⊢A →B iff X; A ⊢B:
A →B follows from X just when whenever you apply X to A, the resulting
information gives B).
O’Hearn and Pym call this kind of proof theory the logic of bunched im-
plications [204], and they use it to model computation.
2.8
Display Logic
Nuel Belnap’s Display Logic [30] is a neat, uniform method for providing a
cut-free consecution calculus for a wide range of formal systems. The cen-
tral ideas of Belnap’s Display Logic are simple and elegant. Like other con-
secution proof theories, the calculus deals with structured collections of for-
mulas, consecutions. In display logic, consecutions are of the form X ⊢Y,
where X and Y are structures, made up from formulas. Structures are made
up of structure-connectives operating on structures, building up structures
from smaller structures, in much the same way as formulas are built up by
formula-connectives. The base level of structures are the formulas. So far,
display logic is of a piece with standard Gentzen systems — in traditional
systems structures are simply lists, and in the more avant garde systems of
Dunn and Minc, structures can be made up of two bunching operators —
but in Belnap’s work, structures can be even richer. This richness is present
so that consecutions can support the display property: any substructure of a
consecution can be displayed to be the entire antecedent or consequent of
an equivalent consecution. In general, what is wanted is a way to “unravel” a
context like so that we can perform equivalences such as this:
X(Y) ⊢Z is equivalent to Y ⊢X−1(Z)
where the Y inside the structure X(Y) is exposed to view, and the surrounding
X(—) context is unravelled. Once you can do this, connective rules are sim-
ple, because you can assume that each formula is displayed to be the entire
antecedent or consequent of a consecution.
Belnap’s original work on display logic was motivated by the problem for
ﬁnding a natural proof theory for relevant logics and their neighbours. As
a result, it is illustrative to see the choices he made in constructing rules to
allow the display of substructures. Here are some equivalences present in R
and weaker relevant logics.
A ◦B ⊢C
=========
A ⊢∼B + C
A ⊢B + C
=========
A ◦∼B ⊢C
=========
A ⊢C + B
A ⊢B
=======
∼B ⊢∼A
=======
∼∼A ⊢B
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
44
These equivalences allow us to “get under” the connectives in formulas. Here,
the equivalences govern fusion, ﬁssion and negation. In traditional Gentzen
systems, the “comma” is an overloaded operator, signifying conjunction in
antecedent position and disjunction in consequent position. That is, a conse-
cution of the form X ⊢Y is interpreted as saying something like: “if everything
in X is true, something in Y must be true.” In substructural logics, this comma
(the one which also governs the behaviour of implication) is interpreted as fu-
sion on the left, and if it appears on the right at all, as ﬁssion. Belnap noted
that we could get the display property if you add a structural connective for
negation. If you write this connective with an asterisk, you get the following
display postulates to parallel the facts we have already seen, governing fusion
and ﬁssion.
X ◦Y ⊢Z
========
X ⊢∗Y ◦Z
X ⊢Y ◦Z
========
X ◦∗Y ⊢Z
========
X ⊢Z ◦Y
X ⊢Y
======
∗Y ⊢∗X
=======
∗∗X ⊢Y
(Belnap uses “◦” for the structure connective which is fusion- and ﬁssion-like,
and I will follow him in this notation.) As before, structures can be interpreted
in “antecedent” position or in “consequent” position. However, now we can
have “◦” representing fusion on the right of the turnstile, or ﬁssion on the left,
because the negation operator ﬂips structures from one position to another.
Consider the equivalence of X◦Y ⊢Z with X ⊢∗Y ◦Z. In the ﬁrst consecution,
the structure Y is on the left of the turnstile, but on the second it is on the right.
It must have the same content in both cases61 which means that the structure
connectives inside Y must be interpreted in the same way. With this caveat,
the display calculus is a straightforward Gentzen-system with structure con-
nectives allowing both positive and negative information. The rules govern-
ing the connectives are straightforward analogs of the traditional rules, with
the simpliﬁcation that we can now assume that principal formulas are the
entire antecedent or consequent of the consecutions which introduce them.
Here are the conditional rules:
X ◦A ⊢B
X ⊢A →B
X ⊢A
B ⊢Y
A →B ⊢∗X ◦Y
The display postulates mean that the cut rule appropriate for a display calcu-
lus can be stated exceedingly simply:
X ⊢A
A ⊢Y
 
  
X ⊢Y
There is no need for a stronger rule placing the cut-formula in a context, be-
cause we can always assume that the cut formula has been displayed. This
is an advance in the proof theories of substructural logics because some the
various strengthenings of the cut rule, required to prove the cut-elimination
theorem, are not valid in some substructural systems.62 In his original paper,
61It is justiﬁed by the equivalence of
 ◦
 ⊢

with
 ⊢

   , and in this case
 “means the
same thing” in both cases.
62The most generous case of Mix — from
 ⊢

  and
 ′
 
⊢

′ to some conclusion,
where both

  and
 ′
  involve multiple occurrences of
 to ve eliminated — seems to have
no appropriate valid conclusion in general substructural logics.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
45
Belnap provides a list of eight easily checked conditions. If a display proof
theory satisﬁes these conditions, then Cut is admissible in the system. We
need not go in to the detail of these conditions here.63
Belnap shows that different logical systems can be given by adding dif-
ferent structural rules governing the display connectives — and that further-
more, the one proof system can have more than one family of display con-
nectives. This is the parallel with the Dunn-Minc Gentzen system for logics
with distribution. Belnap shows how you can construct proof theories for
relevant logics, modal logics, intuitionistic logic, and logics which combine
connectives from different families.
The idea of using display postulates to provide proof theories for different
connectives is not restricted to Belnap’s original family featuring a binary op-
erator ◦and a unary ∗. Wansing [285] extended Belnap’s original work show-
ing that a unary structure • with display rules
•X ⊢Y
=====
X ⊢•Y
would sufﬁce to model normal modal logics. The corresponding connective
rules for □are
X ⊢•A
 

X ⊢□A
A ⊢X
 

□A ⊢•X
This shows that □is the object-language correlate of • in consequent posi-
tion.64 As a result, display logic has been used outside its original substruc-
tural setting. Wansing has shown that display logic is a natural home for
proof theory for classical modal logics [285, 286], Belnap has extended his
calculus to model Girard’s linear logic [31],65 Gor´e and I have used the dis-
play calculus to model substructural logics other than those considered by
Belnap [124, 229], and I have extracted some decidability results in the vein
of Giambrone and Brady [232].66
2.9
Linear Logic
Girard, in 1987, introduced linear logic, a particular substructural system that
allows commuting and reassociating of premises, but no contraction or weak-
ening [117]. Perhaps Girard’s major innovation in linear logic is the introduc-
tion of the modalities — the exponentials67 which allow the recovery of these
63I have generalised Belnap’s conditions for the admissibility of cut in such a way as to include
traditional consecution systems as well as display logics. It remains unclear if this generalisation
will prove useful in practice, but it does seem to be an advantage to not have to prove the cut
elimination theorem again and again for each proof system you construct [234, Chapter 6].
64Its partner in antecedent position is a possibility operator, but the dual possibility operator
which looks backwards down the accessibility relation for necessity. It is tied together to

by the
display postulates
 ⊢

 if and only if
  ⊢
  .
65The issue is the treatment of the exponentials.
66However, Kracht has shown that in general, decidability results from a display calculus are
not to be expected. He has shown that in general, it is undecidable whether a given displayed
modal logic is decidable [145].
67So called because of the equivalence between

 
  and

 ◦

  , and dually, between

 
  and

  
  . This also explains why

and

are the additives and ◦and
 are the
multiplicatives in the parlance of linear logic.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
46
structural rules in a limited, controlled fashion. Linear logic has a straight-
forward resource interpretation: when premises and conclusions are taken to
be resources to be used in proof, then the absence of contraction indicates
that resources cannot be duplicated, and the absence of weakening indicates
that resources cannot be simply thrown away. Only particular kinds of re-
sources — those marked off by the exponentials — can be treated in this
manner. Linear logic has received a great deal of attention in the literature
in theoretical computer science.
2.9.1
Gentzen Systems
The most straightforward proof theory for linear logic is a consecution system
where consecutions feature structure in the antecedent and the consequent:
A ⊢A
X ⊢Y, A
X′, A ⊢Y ′
[Cut]
X′, X ⊢Y, Y ′
X ⊢A, Y
[
 L]
X, ∼A ⊢Y
X, A ⊢Y
[
 R]
X ⊢∼A, Y
X, A ⊢Y
[

L
  ]
X, A ∧B ⊢Y
X, B ⊢Y
[

L
 ]
X, A ∧B ⊢Y
X ⊢Y, A
X ⊢Y, B
[

R]
X ⊢Y, A ∧B
X, A, B ⊢Y
[◦L]
X, A ◦B ⊢Y
X ⊢Y, A
X′ ⊢B, Y ′
[◦R]
X, X′ ⊢Y, A ◦B, Y ′
X, A ⊢Y
X, B ⊢Y
[

L]
X, A ∨B ⊢Y
X ⊢Y, A
[

R
  ]
X ⊢Y, A ∨B
X ⊢Y, B
[

R
 ]
X ⊢Y, A ∨B
X, A ⊢Y
B, X′ ⊢Y ′
[
  L]
X, A + B, X′ ⊢Y, Y ′
X ⊢Y, A, B
[
  R]
X ⊢Y, A + B
X ⊢Y, A
X′, B ⊢Y ′
[

L]
X′, X, A →B ⊢Y, Y ′
X, A ⊢B, Y
[

R]
X ⊢A →B, Y
X ⊢Y
[
  L]
X, t ⊢Y
⊢t [tR]
f ⊢[fL]
X ⊢Y
[
 R]
X ⊢Y, f
X(⊥) ⊢Y
X ⊢Y(⊤)
X ⊢Y
[K
 ]
X, !A ⊢Y
X, A ⊢Y
[L
 ]
X, !A ⊢Y
!X ⊢A, ?Y
[R
 ]
!X ⊢!A, ?Y
X, !A, !A ⊢Y
[WI
 ]
X, !A ⊢Y
X ⊢Y
[K
 ]
X ⊢?A, Y
X ⊢Y, A
[R
 ]
X ⊢Y, ?A
!X, A ⊢?Y
[L
 ]
!X, ?A ⊢?Y
X ⊢Y, ?A, ?A
[WI
 ]
X ⊢Y, ?A
Girard’s notation for the connectives differs from the one we have chosen
here. Figure 4 contains a translation manual between the three traditions we
have seen so far.
Linear logic has two distinctive features. First, the exponentials, which al-
low the recovery of structural rules. Girard in fact discovered linear logic as
a decomposition of the intuitionistic conditional A ⊃B into !A →B in the
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
47
Connective
Here
Lambek
Girard
Implication
A →B
A / B
A
◦
−B
Converse Implication
B ←A
B \ A
Fusion
A ◦B
A • B
A ⊗B
Fission
A + B
A
&
B
Conjunction
A ∧B
A & B
Disjunction
A ∨B
A ⊕B
Negation
∼A
A⊥
Church Truth
t
1
Church Falsehood
f
⊥
Ackermann Truth
⊤
⊤
Ackermann Falsehood
⊥
0
Of course
!
!
Why not
?
?
Figure 4: Translation between notations
models of coherence spaces, which we shall see in the next part of this essay.
For now, it is enough to get a taste of this decomposition. The linear implica-
tion A →B indicates that one use of A is sufﬁcient to get one instance of B.
The exponential is the operator which licences arbitrary re-use of resources.
So, an intuitionistic conditional says that the consequent B can be found, us-
ing as many instances of A as we need. Here are the proofs of the equivalence
between !(A ∧B) and !A ◦!B.
A ⊢A




A ∧B ⊢A




!(A ∧B) ⊢A

 !

!(A ∧B) ⊢!A
B ⊢B




A ∧B ⊢A




!(A ∧B) ⊢B




!(A ∧B) ⊢!B
 ◦


!(A ∧B), !(A ∧B) ⊢!A ◦!B
 WI


!(A ∧B) ⊢!A ◦!B
A ⊢A




!A ⊢A
 K


!A, !B ⊢A
B ⊢B




!B ⊢B
 K


!A, !B ⊢B




!A, !B ⊢A ∧B
 ◦


!A, !B ⊢!(A ∧B)

 ◦

!A ◦!B ⊢!(A ∧B)
Vincent Danos has shown that this modelling of intuitionistic logic can be
made very intimate [64, 65]. It is possible to translate intuitionistic logic into
linear logic in such a way that all intuitionistic Gentzen proofs have step-by-
step equivalent linear logic proofs of their translations.
Another distinctive feature of linear logic is the pervasive presence of du-
ality in the system. The presence of negation means that other connectives
can be easily deﬁned in terms of their duals. On the other hand, it is also pos-
sible to take negation as the deﬁned connective in the following way: for each
atomic formula p pick out a distinguished atomic formula to be ∼p. Then de-
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
48
ﬁne ∼A for complex formulas as follows:
∼∼A
is
A
∼(A ∧B)
is
∼A ∨∼B
∼(A ∨B)
is
∼A ∧∼B
∼⊤
is
⊥
∼⊥
is
⊤
∼(A ◦B)
is
∼A + ∼B
∼(A + B)
is
∼A ◦∼B
∼t
is
f
∼f
is
t
∼!A
is
?∼A
∼?A
is
!∼A
We also take A →B to be deﬁned as ∼A + B (or if you like, ∼(A ◦∼B), which is
literally the same formula under this new regime). Together with this aspect
of duality, we can also transpose consecutions from the multiple left-right
variety, to a conclusion only system. We replace the consecution X ⊢Y with
the consecution ⊢∼X, Y, where ∼X is the structure containing the negations
of all of the formulas in X. Then formulas are introduced only in the right, and
we get a much simpler system, with one rule for every connective, as opposed
to two.
⊢A, ∼A
⊢X, A
⊢∼A, Y
[Cut]
⊢X, Y
⊢X, A
⊢X, B
[

]
⊢X, A ∧B
⊢X, A
[

  ]
⊢X, A ∨B
⊢X, B
[

 ]
⊢X, A ∨B
⊢X, A
⊢B, Y
[◦]
⊢X, A ◦B, Y
⊢X, A, B
[
  ]
⊢X, A + B
⊢t [t]
⊢X
[
 ]
⊢X, f
⊢X, ⊤[⊤]
⊢?X, A
[
 ]
⊢?X, !A
⊢X, A
[
 ]
⊢X, ?A
⊢X
[K
 ]
⊢X, ?A
⊢X, ?A, ?A
[WI
 ]
⊢X, ?A
2.9.2
Proof Nets
[[This section must be added. Relevant citations will be from among [26, 43,
57, 66, 107, 117, 119]]]
2.10
Curry-Howard
Some logicians have found that it is possible to analyse proofs more closely
by giving them names. After all, if proofs are ﬁrst-class entities, we will be
better-off if we can distinguish different proofs. I can illustrate this by looking
at an example from intuitionistic logic. The language for describing proofs
in the intuitionistic logic of the conditional and implication is given by the λ-
calculus with pairing. A term of this calculus is built up from variables x, y, . . .
using the constructors ⟨−, −⟩, fst (−), snd (−), λx.M and application (which we
write as juxtaposition). A judgement is a pair M:A of a term M and a formula
A. Then in proofs in this system we keep tabs on what is going on by building
terms up to represent the ongoing proof. We start with the identity rule x:A ⊢
x:A. Then for conjunction, we reason as follows:
Γ ⊢M:A
Γ ⊢N:B
Γ ⊢⟨M, N⟩:A ∧B
Γ ⊢M:A ∧B
Γ ⊢fst (M):A
Γ ⊢M:A ∧B
Γ ⊢snd (M):B
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
49
If M is the proof of A from Γ, and N is the proof of B from Γ, then the pair
⟨M, N⟩is the proof of A ∧B from Γ. Similarly, if M is a proof of A ∧B (from Γ)
then fst (M) (the “ﬁrst part” of M) is the proof of A from Γ. Similarly, snd (M)
is the proof of B from Γ. For implication, we have these rules:
Γ ⊢M:A →B
∆⊢N:A
Γ, ∆⊢(MN):B
Γ, x:A ⊢M:B
Γ ⊢λx.M:A →B
If M is a proof of A →B, and N is a proof of A, then you get a proof of B by
applying M to N. So, this proof is (MN). Similarly, if M is a proof of B from
Γ, x:A, then a proof of A →B is a function from proofs of A to the proof of B. It
is of type λx.M. We put these together to get names for more complex proofs
x:A →B ⊢x:A →B
y:A ⊢y:A
x:A →B, y:A ⊢(xy):B
y:A ⊢λx.(xy):(A →B) →B
0 ⊢λy.λx.(xy):A →((A →B) →B)
The term λy.λx.(xy) encodes the shape of the proof. The ﬁrst step was an
application of one assumption on another (the term (xy)). The second was
the abstraction of the ﬁrst assumption (λx), and the last step was the abstrac-
tion of the second assumption (λy). The term encodes the proof. There are a
number of important features of these terms.
⋄Terms encoding proofs with no premises are closed. They have no free
variables.
⋄More generally, if Γ ⊢M:A is provable and x is free in M then x appears
free in Γ too.
⋄Proofs encode connective steps, not structural rules. For example, the
rule CI or C was used in the proof of A →((A →B) →B. It is not encoded
in the term explicitly. Its presence can be seen implicitly by noting that
the variables x and y are bound in the opposite order to their appearance.
Once we have a term system, we have contracting rules, which give us the
behaviour of proof reduction.
fst ⟨M, N⟩
⇝
M
snd ⟨M, N⟩
⇝
N
(λx.M)N
⇝
M[x := N]
These correspond to cutting the detours out of proofs. For example, consider
the reduction
Γ ⊢M:A
Γ ⊢N:B
Γ ⊢⟨M, N⟩:A ∧B
Γ ⊢fst ⟨M, N⟩:A
⇝
Γ ⊢M:A
Or a slightly more complex case:
Γ, x:A ⊢M:B
Γ ⊢λx.M:A →B
∆⊢N:A
Γ, ∆⊢(λx.M)N:B
⇝
Γ, ∆⊢M[x := N]:B
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
50
The term M[x := N] indicates that the assumption(s) marked x in M are re-
placed by N. This matches the assumption(s) A marked x in Γ, x:A which are
replaced by the ∆in the transformation.
An explanation of the Curry–Howard isomorphism between intuitionistic
logic and the types of terms in the λ-calculus is found in Howard’s original pa-
per [137]. As we’ve already heard, Church’s original calculus, the λI-calculus,
was actually a model for the implicational fragment of R and not intuitionistic
logic, as Church’s calculus did not allow the binding of variables which were
not free in the term in question [54]. You eliminate contraction if you do not
allow a λ term to bind more than one instance of a variable at once. Similarly,
you eliminate C if you allow variables to be bound only in the order in which
they are introduced. Structural rules correspond to restrictions on binding.
A helpful account of more recent general work in types and logic is found in
Girard, Lafont and Taylor’s Proofs and Types [121], and Girard’s monograph
Proof Theory and Logical Complexity [118].
Work on the application of the term calculus to substructural logics, which
focuses on three aspects. First, on encoding the normalisation results (that
cutting detours out of proofs ends, and ends in a canonical “normal” proof).
Second, on the appropriate term encoding of the exponentials of linear logic.
Work in this area has not yet reached stability. The work of Benton, Bier-
man, Hyland and de Paiva [38, 39, 40] shows the difﬁculty present in the area.
Thirdly, on showing that the restrictions on λ-abstraction in substructural
logics has useful parallels in computation where resources may be consumed
by computation. Wadler and colleagues show that this kind of term system
has connections with functional programming [160, 278, 279, 281, 280, 282,
283].
2.11
Structurally Free Logic
A very recent innovation in the proof theory of substructural logics is the ad-
vent of structurally free logic. The idea is not new — it comes from a 1976
essay by Bob Meyer [171]. However, the detailed exposition is new, dating
from 1997 [42, 41, 93]. The motivating idea is simple. Just as free logic is free
from existential commitments and any existence claims can be explicitly ex-
amined and questioned, so in a structurally free logic, no structural rules are
present in and of themselves, but structural rules, if applied, are marked in a
proof as explicit premises. So, structural rules are tagged with a combinator,
such as these examples:
W(X, (Y, Z)) ⊢A
  B

W(((B, X), Y), Z) ⊢A
W((X, Z), Y)) ⊢A
  C

W(((C, X), Y), Z) ⊢A
W((X, Y), Y)) ⊢A
  W

W((W, X), Y) ⊢A
These are the combinator versions of the structural rules B (association) C
(commutativity) and W (contraction). Now the conclusions not only feature
the structures as rearranged: they also feature a combinator marking the ac-
tion of the structural rule. Proofs in this kind of system then come with “tick-
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
51
ets” indicating which kinds of structural rules licence the conclusion:
B ⊢B
A ⊢A




(A →B), A ⊢B
C ⊢C




(A →B), (C →A, C) ⊢B
 B

((B, A →B), C →A), C ⊢B




(B, A →B), C →A ⊢C →B




B, A →B ⊢(C →A) →(C →B)




B ⊢(A →B) →((C →A) →(C →B))
Any further explanation the workings of this proof system for structurally free
logic brings us perilously close to looking at models for combinatory logic
and the λ-calculus [16, 172]. I will defer this discussion to the next section,
where we broach the question in a broader setting. What on earth counts as
a model of a substructural logic?
3
Models
Our focus so far has been syntax and proof. Now we turn our gaze to inter-
pretation. Clearly we have not been unconcerned with matters of interpreta-
tion thus far. We have paid some attention to the meanings of the connec-
tives when we have examined the kinds of inferential steps appropriate for
sentences formed out of these connectives. According to some views, in giv-
ing these rules for a connective we have thereby explicated their meanings.
According to other views, we have merely cashed out a consequence of the
meanings of the connectives, meanings which are to be found in some other
way.68 Thankfully, we have no need to adjudicate such a debate here. It is not
our place to clarify the ultimate source of meaning. It is, however, our place
to consider some of the different kinds of interpretations open to logical sys-
tems, and particular, substructural logics.
An interpretation of a language maps the sentences in the language onto
some kind of structure. There are many possible kinds of interpretations.
Some propositions are true and others are not true. We can interpret a lan-
guage in the structure {t, f} of truth values by setting the interpretation [[A]]
of A to be t if A is true, and f otherwise. This interpretation is helpful in the
study of logical consequence because of the way it interacts with the tradi-
tional propositional connectives. A conjunction is true if and only if both of
the conjuncts are true. A disjunction is true if and only if one of the disjuncts
is true. A negation is true if and only if the negand is not true. It follows that
[[A ∧B]], [[A ∨B]] are functions of [[A]] and [[B]], in the sense that once the val-
ues [[A]] and [[B]] are ﬁxed, the values [[A ∧B]], [[A ∨B]] are also ﬁxed. The be-
haviour of the operations of conjunction, disjunction and negation on the set
{t, f} of truth values goes some way towards telling us the meanings of those
connectives. More than that, it gives us an account of the behaviour of logical
68This debate is between truth conditional [260] versus inferentialist [50] accounts of meaning
in philosophy of language, proof theorists [118, 73] and model theorists [25, 136] in mathematical
logic, and operational and denotational semantics in computer science [198].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
52
consequence, as the set of truth values has a natural order. We can order the
set by saying that f < t, in the sense that t is “more true” than f. An argument
is {t, f}-valid if no matter how you interpret the propositions in the argument,
the conclusion is never any less true than the premises. Or in this case, you
never can interpret the premises as true and the conclusion as false. This is
the traditional truth-table conception of validity.
The simple set {t, f} of truth values is not the only domain in which a lan-
guage can be interpreted. For example, we might think that not all proposi-
tions or sentences in the language are truth-valued. We might interpret the
language in the structure {t, n, f}, where the true claims are interpreted as t,
the false ones as f, and the non-truth-valued sentences are interpreted as n.
This path leads one to many valued logics [91, 271].
However, one need not interpret the domain of values as truth values. For
one early example of an alternative sort of domain in which sentences can be
interpreted, consider Frege’s later philosophy of language. For the Frege of
the Grundgesetze [102] declarative sentences had a reference (Bedeutung) and
a sense (Sinn). We can interpret sentences by mapping them onto a domain
of senses and by interpreting the connectives as functions on senses. This is
another “denotational” semantics for declarative sentences.69
Different applications will motivate different sorts of models and domains
of semantic values. In the Lambek calculus for syntactic types, the formulas
can be mapped onto sets of syntactic strings. In this interpretation, a sen-
tence will be modelled by the set of strings (in the analysed language) which
have the type denoted by the sentence.
These last two examples — of possible worlds and of syntactic strings —
have similar structures. Formulas are interpreted as sets of objects of one kind
or other. These are especially interesting models, which we will discuss in
detail soon. For now, however, I will focus on the general idea of interpreting
logics in structures, for simple algebras are the ﬁrst port of call when it comes
to models of substructural logics.
3.1
Algebras
The most direct way to interpret a logic is by a map from the language of the
logic into some structure. Such structures are usually equipped with opera-
tions to match the connectives in the language. The interpretation of a com-
plex formula is then deﬁned recursively in terms of the operations on the in-
terpretations of the atomic subformulas. All of this is standard. In this sec-
tion, I will examine just a few structures which have proved to be useful in
the study of substructural logics. Then in the next section, I will explain just a
few of the theorems which can be proved about substructural logics by using
these structures.
69For a modern interpretation of Frege’s ideas, one could consider a sense of a claim to be
the set of possible worlds in which it is true. Now for each sentence you have its interpretation
as some set of possible worlds. For an account of how this approach might be philosophically
productive, see Robert Stalnaker’s Inquiry [258], David Lewis’ On the Plurality of Worlds [154].
For recent work which takes Frege’s talk of senses at face value (and which motivates a weak
substructural logic, to boot) consider the paper “Sense, Entailment and Modus Ponens” by Gra-
ham Priest [215].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
53
3.1.1
Example Algebras
EXAMPLE 17 (BN4) Perhaps the most simple, yet rich, ﬁnite structure used
to interpret substructural logics is the four-valued lattice BN4 [79, 28, 29]. It
ﬁrst came to fame as a simple lattice sufﬁcient to interpret ﬁrst degree entail-
ments. Any valid ﬁrst degree entailment is valid in this structure (in a sense
to be explained soon) and any invalid ﬁrst degree entailment is invalid in this
structure. It is also the source of intuitions in its own right. The behaviour
of BN4 is presented in the diagram and tables in Figure 5. The diagram can
present the behaviour of conjunction, disjunction, ⊤and ⊥. The conjunction
of two elements is their greatest lower bound, their disjunction, the least up-
per bound, ⊤is the top element and ⊥is the bottom element. The operations
of negation and implication and fusion are read off the tables.
f
b
t
n
∼
t
f
b
b
n
n
f
t
→
t
b
n
f
t
t
f
n
f
b
t
b
n
f
n
t
n
t
n
f
t
t
t
t
◦
t
b
n
f
t
t
t
n
f
b
t
b
n
f
n
n
n
f
f
f
f
f
f
f
Figure 5: The Algebra BN4
If you think of the values t, b, n, f as the values “true only”, “both true and
false”, “neither true nor false” and “false only” then the negation of a set values
is simply the set of the negations of values in that set. Implication is similarly
deﬁned. The value “true” is in the set a →b just when if a is at least “true”
then b is at least “true”, and if b is at least “false” then so is a. On the other
hand, a conditional a →b is at least “false” if a is at least “true” and b is at
least “false.” This gives the implication table. The values for fusion table are
given by setting a ◦b to be ∼(a →∼b).
Given this deﬁnition, fusion is commutative and associative, with an iden-
tity b. Negation is deﬁnable in terms of implication by setting ∼a to be a →b.
So in this algebra, the false constant f is modelled by b, as is the true constant
t. Fusion is residuated by →, and the lattice is distributive.
In this algebra, the order in the diagram (read from bottom to top, and
written “≤”) models entailment. You can see that a ∧b always entails a, as
the greatest lower bound of a and b (whatever a and b might be) is always
lower than, or equal to, a. In just the same way, you can show that all of the
entailments of a distributive lattice hold for ∧and ∨, that a = ∼∼a (and so,
double negation elimination and introduction hold) and that the de Morgan
laws, such as ∼(a ∨b) = ∼a ∧∼b also hold in this structure.
In this lattice, some structural rules fail: WI is not satisﬁed, as n ̸≤n ◦n.
The K rule also fails, as t ◦b ≤b, and hence we do not have b ≤t →b.
However, fusion is symmetric and associative. So BN4 is a model for linear
logic (with the addition of distribution), in the sense that if A ⊢B holds in
linear logic plus distribution, then for any interpretation [[·]] into BN4, we must
have [[A]] ≤[[B]].
However, BN4 is not a model of R, for some contraction related principles
fail in BN4. For example, there is an interpretation in which [[A ∧(A →B)]] ̸≤
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
54
⊥
∼b
a
∼c
b
∼a
c
⊤
◦
⊥
∼c
∼b
∼a
a
b
c
⊤
⊥
⊥
⊥
⊥
⊥
⊥
⊥
⊥
⊥
∼c
⊥
∼c
⊤
⊤
∼c
⊤
∼c
⊤
∼b
⊥
⊤
∼b
⊤
∼b
∼b
⊤
⊤
∼a
⊥
⊤
⊤
⊤
∼a
⊤
⊤
⊤
a
⊥
∼c
∼b
∼a
a
b
c
⊤
b
⊥
⊤
∼b
⊤
b
b
⊤
⊤
c
⊥
∼c
⊤
⊤
c
⊤
c
⊤
⊤
⊥
⊤
⊤
⊤
⊤
⊤
⊤
⊤
Figure 6: An Eight-Point Lattice for R
[[B]].70
This lattice has also been used in the semantics of programming [101].
Interpreting the four values as epistemic states of no information, positive
and negative information, and conﬂicting information, may be of some help
in modelling states of information-bearing devices.
EXAMPLE 18 (AN EIGHT POINT MODEL) Consider the structure with the or-
der and fusion table shown in Figure 6. This is a model of R: Fusion is com-
mutative (the table is symmetric about the diagonal), and associative. We
have x ≤x ◦x, so WI holds. The element a is an identity for fusion. Negation
is deﬁned by the names of the elements and the fact that ∼is a de Morgan
negation. Setting x →y = ∼(x ◦∼y) makes →residuate fusion.
We can use this structure to show that R has the relevance property. Sup-
pose we have two propositions A and B, in the language ∧, ∨, ∼, ◦and →,
such that there is no atom shared between A and B. Construct an evaluation
[[◦]], such that [[p]] is either b or ∼b for any atom p in A, and it is either c or ∼c
for any atom p in B.
By induction, we can verify that the value [[A]] is one of b and ∼b, and sim-
ilarly, the value [[B]] is one of c or ∼c. Therefore, [[A]] ̸≤[[B]], and since this is a
model of R, we have A ̸⊢B in R, and hence, A ̸⊢B in any sublogic of R.
EXAMPLE 19 (SUGIHARA MODELS) One can modify BN4 in a number of ways.
You can leave out the value b, and get Łukasiewicz’s three-valued logic. Ex-
tensions to Łukasiewicz’s n-valued, and inﬁnitary logics are straightforward
too. These systems all invalidate contraction, but validate weakening and the
other common contraction-free structural rules. Another way of modifying
BN4 is to leave out the value n.This gives us the structure known as RM3, a
three-valued algebra useful in the study of relevant logics, because this is a
model of R. This simple three-valued model can be generalised to RM2n+1
for any n as follows by setting the domain of propositions to be the numbers
{−n, −(n −1), . . . , −1, 0, 1, . . . , n −1, n}
70Hint: set
   


n and
   


f. Check for yourself that this is a counterexample.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
55
where we set ∼a to be −a, and →and fusion are deﬁned as follows:
a →b =
 −a ∨b
if a ≤b
−a ∧b
if a > b
a · b =
 a ∧b
if a ≤−b
a ∨b
if a > −b
Fusion is commutative (verify by eye) and associative (verify by checking case
by case), with identity 0. Note that a · a = a, so the logic satisﬁes both W and
M — this is a model for the logic RM discussed earlier.
This model can also be extended by not stopping at −n or n but by includ-
ing all of Z, the positive and negative integers. This inﬁnite model captures
exactly the logic RM in the language ∧, ∨, →, ◦, ∼, t. The inﬁnite model has no
members ﬁt for either ⊤or ⊥, but they can be added as ∞and −∞without
disturbing the logic of the model.
EXAMPLE 20 (THE INTEGERS) The integers feature in the RM algebra above.
The choice of the interpretation of implication in that model is only one of
many different ways you could go in this structure. Another is to consider
addition as a model for fusion. The residual for addition is obvious: it is sub-
traction. X →Y is Y −X. This structure is unlike the RM algebra in a number
of ways. First, W fails, as a ̸≤a + a whenever a is negative. Second, M fails
(and so, K and K′ do too) as a + a ̸≤a whenever a is positive. However, C and
B are satisﬁed in this structure, so we have a structure ﬁt for linear logic. In
particular, since the structure is totally ordered, we have the distribution of
conjunction over disjunction, so we have a model for distributive linear logic.
More interestingly, (x →y) →y = x for each x and y. This does not hold
in any boolean algebra or in any other non-trivial structure with ⊤. If ⊤were
present, then (a →⊤) →⊤= a but ⊤≤b →⊤for each b (including a →⊤)
so ⊤≤a.
It is possible to deﬁne the negation ∼a as a →0 = −a. However, other
choices are possible. Taking b an arbitrary proposition, we can deﬁne ∼ba as
a →b, and the condition (x →y) →y = x states, in effect, that ∼b∼ba = a.
Double negation introduction and elimination holds for any negation ∼b we
choose.
This model is a way to invalidate simple consecutions in distributive linear
logic. For example, can we prove A →(B →C) ⊢(A →B) →(A →C)? If
this holds in our structure we must have (z −y) −x ≤(z −x) −(y −x), but
this simpliﬁes to z ≤(z −x) + 2x = z + x (add x + y to both sides). And
when x ≥0 we have z ≤z + x, but if x < 0 this fails. Similar manipulations
can be used to invalidate other consecutions. However, some consecutions
invalid in distributive linear logic do hold in the integers. We have seen that
(A →B) →B ⊢A already. Another case is t ⊢(A →B) ∨(B →A). So the
integers do not give an exact ﬁt for distributive linear logic.
(Others have been aware that simple “counting” mechanisms can provide
a useful ﬁlter for issues of validity in substructural logics [37, 148, 237, 210].)
The logic here is known as abelian logic: It was introduced by Meyer and
Slaney, who show that it is the logic of ordered abelian groups [173].
EXAMPLE 21 (ω UNDER DIVISION) Using number systems as structures gives
us rich mathematical tradition upon which we can build. However, the struc-
tures we have seen so far are all totally ordered: for any x and y either x ≤y or
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
56
y ≤x. This is not always desirable — it leads to the truth of (A →B) ∨(B →
A). Now some “natural” orderings of numbers are total orders, but others
are not. For example, take the positive integers, ordered by divisibility. This
is a partial ordering — indeed, a lattice ordering — in which join is the low-
est common multiple and meet is the greatest common divisor. Fusion has a
natural model in multiplication.
The lattice is distributive, as gcd(a, lcm(b, c)) | lcm(gcd(a, b), gcd(b, c)).
With fusion modelled as multiplication, 1 is the identity of fusion and we have
a distributive lattice-ordered commutative monoid with a unit. Furthermore,
the monoid is square-increasing (as a | a2), so it models the structural rules
of R[∧, ∨, ◦, t].
How can you model a conditional residuating fusion? We want
xy | z if and only if x | y →z
If y divides z, then we can set y →z to be z/y. For any x you choose, xy | z if
and only if x | z/y. However, if y does not divide z, we do not have anything
to choose, as 1 is the bottom of the order we have thus far. To get a residual
in every instance, we need to add another element to the ordering. It will be
the lowest element in the ordering, so we will call it 0 (for reasons which will
become more obvious later). We can by ﬁat determine that 0 | x for every x
in the structure, and that x | 0 only when x = 0. Conjunction and disjunction
are as before, with the addition that 0 ∧x = 0 and 0 ∨x = x for each x. The
rule for implication is then:
x →y =

y/x
if x | y,
0
otherwise.
Given 0 we need to extend the interpretation of fusion. But this is simple
0x = x0 = 0
for every x. So deﬁned, the operation is still order-preserving, commuta-
tive, square-increasing and with 1 as the identity. This structure is a model
for R[∧, ∨, ◦, t, →]. To model the whole of R we need to model a de Morgan
negation. That requires an order-inverting involution on the structure. To do
this, we need to introduce many more elements in the structure, as no order-
inverting involution can be found on what we have here before us: consider
the inﬁnite ascending chain
0 | 1 | 2 | 4 | · · · | 2n | · · ·
To negate each element in the series you must get an inﬁnite descending
chain. Why? Because we need an involution: x | y if and only if −y | −x,
and in particular, if −x = −y, then we must have x = y. Each element in the
inverted chain must be distinct. Alas, there are no such chains in our struc-
ture, as every number has only ﬁnitely many divisors. So, we need to add
more elements to do the job. As our notation has suggested, we will add the
negative integers and ∞. The order is given by setting
0 | x | −y | ∞
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
57
for every positive x and y, and in particular, −x | −y if and only if y | x. So
you can read ‘|’ as divides only when it holds between positive integers. Oth-
erwise, it is deﬁned by these clauses. The inﬁnite ascending chain is then
mapped onto the inﬁnite descending chain above it as follows:
0 | 1 | 2 | 4 | · · · | 2n | · · · | −2n | · · · | −4 | −2 | −1 | ∞
The result is still a distributive lattice order, and conjunction and disjunction
are obviously deﬁnable as greatest lower bound and least upper bound, re-
spectively. Implication between all pairs of elements is deﬁned as follows:
⋄If x is negative and y is positive, x →y = 0.
⋄If x is positive and y is negative, then x →y = (−x)y
⋄If x and y are both negative, then x →y = −y →−x
Fusion is then deﬁned by setting xy = −(x →−y), and you can show that this
is commutative, square-increasing and with 1 as the identity.
The lattice is not complete, in that not every subset has a least upper or a
greatest lower bound: The chain 0 | 1 | 2 | · · · | 2n | · · · has an upper bound
(any negative number will do) but no least upper bound.
This structure was ﬁrst constructed by Meyer [177] in 1970 who used it to
establish some formal properties of R. The technique of expanding an algebra
to model negation is one we shall see again as an important technique in the
metatheory of these logics.
EXAMPLE 22 (ALGEBRAS OF RELATIONS) A generalisation of Boolean algebras
due to de Morgan [201] and Peirce [209] and later developed, for example,
by Schr¨oder [249], was to consider algebras of binary relations. A concrete re-
lation algebra is the set of all subsets of some set D × D of pairs of elements
from a set D under not only the Boolean operations of intersection, union and
complementation but also under new operations which exploit the relational
structure.
For any two relations R and S their composition is also a relation: R · S is
deﬁned by setting x(R · S)y if and only if (∃z ∈D)(xRz ∧zRy). This is a model
for fusion. Fusion has a left and right identity, 1, the identity relation on D.
Furthermore, for any relation R we have its converse, given by setting x˘Ry if
and only if yRx. Note that (R · S)˘= ˘S · ˘R.
We can deﬁne left and right residuals for composition directly by the resid-
uation conditions, or we can note that they are deﬁnable in terms of the
Boolean connectives, fusion and converse. R →S = −(−S · ˘R) and S ←R =
−(˘R · −S).
It is possible to modify the behaviour of these algebras by considering re-
stricted classes of relations. For example, we could look at algebras of reﬂex-
ive relations. These are odd, in that 1 ≤R for each R, so the bottom element
of the algebra is also the identity for fusion. These algebras are closed under
some of the operations at issue, but not all. The Boolean complement of a
reﬂexive relation is not reﬂexive, but the conjunction or disjunction of two
reﬂexive relations is.
Another possibility is to consider, for example, equivalence relations [96].
When is the composition of two equivalence relations an equivalence rela-
tion? It turns out that R · S is also commutative when R · S = S · R. And if this
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
58
obtains, then their composition is the least upper bound of the two relations
(in the set of equivalence relations). Therefore, a class of commuting equiva-
lence relations forms a lattice, in which fusion is least upper bound. And it is
not too hard to show that this lattice generally fails to be distributive, but it is
modular. It satisﬁes the modular law
a ∧(b ∨(a ∧c)) ≤(a ∧b) ∨(a ∧c)
but not the more general distributive law.
Tarski [259] helped bring relation algebras back to prominence in modern
logic, and there is much contemporary research in the area, particularly in
Hungary [12]. Vaughan Pratt has also considered them (and dynamic alge-
bras, a tractable fragment of relation algebras) as a useful model of computa-
tion [213].
3.1.2
General Structures
The algebraic study of models of substructural logics was ﬁrst explicitly and
comprehensively tackled by J. Michael Dunn in his doctoral dissertation from
the middle 1960s [75]. The techniques he used are mostly standard ones,
adapted to the new context of relevant logics. There had been a long tra-
dition of using ﬁnite algebras (also called ‘matrices’ for obvious reasons) to
prove syntactic results about logics, such as the relevance property for R, as
we have seen. Section 22 of Entailment Volume 1 [10] contains a good dis-
cussion of results of this sort. However, it was Dunn’s work that ﬁrst took such
structures as a ﬁt object of study in their own right.
For a helpful guide to the state of the art in the 1970s, Helena Rasiowa’s An
Algebraic Approach to Non-classical Logics [222] is a compendium of results in
the ﬁeld. Meyer and Routley’s groundbreaking paper “An Algebraic Analysis of
Entailment” [190] did a great deal of work showing how a whole host of logics
ﬁt together, all with the theme of residuation or the connection of fusion with
implication. They showed that not only in R but also in other relevant logics,
fusion is connected together with implication by the residuation postulate
a ◦b ≤c iff a ≤b →c
and that the natural way to ring the changes in the logic is to vary the postu-
lates governing fusion. Here a summary of Dunn’s and Meyer and Routley’s
work on the general theory of algebras for substructural logics.
DEFINITION 23 (POSETS) A poset (a partially ordered set) is a set equipped
with a binary relation ≤which is reﬂexive, transitive, and asymmetric. That
is, a ≤a for each a, if a ≤b and b ≤c then a ≤c, and if both a ≤b and
b ≤a, then a = b.
Posets are the basic structure of an algebra for a logic. The order is entailment
between propositions in structure. Entailment is asymmetric as we assume
that co-entailing propositions are identical. This is what makes propositions
in this kind of structure differ from sentences in a formal language.
Extensional conjunction and disjunction enrich the poset into a familiar
algebraic structure:
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
59
DEFINITION 24 (LATTICES) A lattice is a partially ordered set equipped with
least upper bound ∨and a greatest lower bound ∧.
A lattice is distributive if and only if a ∧(b ∨c) = (a ∧b) ∨(a ∧c) holds for
each a, b and c.
A lattice is bounded if it has greatest and least elements, ⊤and ⊥respectively.
For traditional substructural logics, two more additions are required to this
kind of structure. First, negation, and second, fusion and implication. Let’s
tackle negation ﬁrst.
DEFINITION 25 (NEGATIONS) A negation on a poset is an order inverting op-
eration ∼: that is, if a ≤b then ∼b ≤∼a.
A negation on a lattice is de Morgan ∼∼a = a and it satisﬁes the de Morgan
identities ∼(a ∧b) = ∼a ∨∼b and ∼(a ∨b) = ∼a ∧∼b.
A de Morgan negation in a bounded lattice is an ortho-negation if a ∧∼a = ⊥
and a ∨∼a = ⊤.
Note that a de Morgan negation need not be an ortho-negation. (The nega-
tions in each of the structures in the previous section are de Morgan but not
ortho-negation.) An ortho-negation operation in a distributive lattice is the
Boolean negation in that structure.71
Some very recent work of Dunn has charted even more possibilities for the
behaviour of negation. In particular, he has shown that a basic structure in a
substructural logic is a split negation satisfying the following residuation-like
clauses
a ≤¬b iff b ≤−a
Given this equivalence, both ¬ and −are negations, and both satisfy some of
the de Morgan inequalities but not others [87].72
The most interesting operations in algebras for substructural logics are
fusion and implication. The simplest way to deﬁne them is by residuation.
DEFINITION 26 (RESIDUATED PAIRS AND TRIPLES) ⟨◦, →⟩is a residuated pair
in a poset if and only if a ◦b ≤c if and only if a ≤b →c.
⟨◦, →, ←⟩is a residuated triple in a poset if and only if a ◦b ≤c if and only if
a ≤b →c if and only if b ≤c ←a.
If ⟨◦, →⟩is a residuated pair then it immediately follows that ◦is isotonic in
both places with respect to the entailment ordering. That is
if a ≤a′ and b ≤b′ then a ◦b ≤a′ ◦b′
71There may be more than one ortho-negation in a lattice, but there is only one ortho-negation
in a distributive lattice.
72In particular,
 

 

 



 and
 

 
≤
 



 (this latter inequality is satisﬁed
by any negation) but the converse can fail:
 



 ̸≤
 

  . The negation
 differs from
intuitionistic or minimal negation, however, by not necessarily satisfying

≤
   . We do have,
however,

≤
 

and

≤

  . For an example of a split negation, let

 be
 
 and let
 be


 in the Lambek calculus extended with a false constant
 .
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
60
Implication, on the other hand, is not isotonic in both places. It is isotonic in
the consequent place and antitonic in the antecedent place. That is we have
if a′ ≤a and b ≤b′ then a →b ≤a′ →b′
All of this was noticed by Meyer and Routley in the 1970s and made rigor-
ous (and generalised to arbitrary n-place operations and residuated families)
by Dunn in the 1980s and 1990s in his work on gaggle theory (from “ggl” for
“Generalised Galois Logic”: a Galois connection is the general phenomenon
of which a residuated pair or triple is a special case) [85, 86].73
Tonicity is not the only behaviour of fusion and implication present in
these models. If the poset is a lattice ordering, then tonicity generalises to
distribution. It is also an elementary consequence of the residuation clause
that fusion distributes over disjunction in both places
(a ∨a′) ◦b = (a ◦b) ∨(a′ ◦b) and a ◦(b ∨b′) = (a ◦b) ∨(a ◦b′)
and implication distributes over the extensional connectives in a more com-
plicated fashion.
(a ∨a′) →b = (a →b) ∧(a′ →b) and a →(b ∧b′) = (a →b) ∧(a →b′)
These sorts of structures are well known, and they appear independently in
different disciplines. Quantales [203] are but one example. These are lattice-
ordered semigroups (so, ◦is associative) with arbitrary disjunctions but only
ﬁnite conjunctions. They appear in both pure mathematics and theoreti-
cal computer science. They are discussed a little in Vickers’ Topology via
Logic [277], which is a useful source book of other algebraic constructions
and their use in modelling processes and observation. The existence of ar-
bitrary disjunctions means that in a quantale, implication is deﬁnable from
fusion. If you set a →b as follows
a →b =
_
{x : x ◦a ≤b}
then →satisﬁes the residuating condition for fusion.74 The same deﬁnition
is possible in the other direction too. If you have a lattice with arbitrary con-
junctions (and implication distributes over conjunction in the right way) then
you can deﬁne fusion from implication
a ◦b =
^
{x : a ≤b →x}
This deﬁnition is key to one of the important techniques in understanding
the behaviour of fusion and the connections between fusion and implication.
For fusion plays no part in the Hilbert systems introducing some substruc-
tural logics. Yet it is present in the Gentzen systems (at least as the comma,
73And I have begun to sketch the obvious parallels between gaggle theory and display logic.
Residuation is displaying, and isotonicity and antitonicity have connections to antecedent and
consequent position in the proof rules for a connective. When you process a fusion, the subfor-
mulas remain on the same side of the turnstile as the original formula. On the other hand, when
you process an implication, the antecedent swaps sides and the consequent stays put.
74The distribution of ◦over the inﬁnitary disjunction is essential here.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
61
if not explicitly) and in these algebras. Does the addition of fusion add any-
thing new to the system in the language of implication? Or is the addition
of fusion conservative? In the next section I will sketch Meyer’s techniques
for proving conservative extensions for many substructural logics, by way of
algebraic models.
Before that, I must say a little about truth in these algebras. In Boolean
algebras (for classical logic) and Heyting lattices (for intuitionistic logic) the
truths in a structure are the formulas which are interpreted as the top ele-
ment. There is no need for this to be the case in our structures. In the ab-
sence of K′, we might have b ̸≤a →a. That means that a true conditional (as
every identity a →a is true) need not be the top element of the ordering. So,
instead of picking out true propositions as those at the top of the ordering,
substructural logics need be more subtle.
DEFINITION 27 (A TRUTH SET) Given an algebra with →, the truth set T is the
set of all x where a →b ≤x for some a, b where a ≤b.75
The truth set is the set of all conditionals true on the basis of logic alone, and
anything entailed by those conditionals. A truth set has some nice properties.
FACT 28 (A TRUTH SET IN A LATTICE IS A FILTER) Any truth set T in a lattice is
a ﬁlter. (A ﬁlter is a set which is closed under ≤, and closed under conjunc-
tion.76) If x, y ∈T then x ∧y ∈T. If x ≤x′ then x′ ∈T too.
PROOF
That T is closed upwards is immediate. That T is closed under con-
junction, note that if x, y ∈T then a →b ≤x and a ′ →b′ ≤y where a ≤b
and a′ ≤b′. Then a∧a′ ≤b∨b′, and (a →b)∧(a′ →b′) = a∧a′ →b∨b′,
so since (a →b) ∧(a′ →b′) ≤x ∧y, we have x ∧y ∈T too.
□
If the logic contains t, then the truth set the ﬁlter generated by t: T = {x : t ≤
x}. The presence of truth sets in models shows that a logic without t can be
conservatively extended by it. Both conservative extension constructions —
due to Meyer in the 1970s, are the topic of the next section.
3.1.3
Conservative Extension Theorems
Meyer’s conservative extension results follow the one technique [179]. Sup-
pose we have consecution invalid in a logic with a restricted language A ̸⊢B.
Then (by the soundness and completeness results for propositional struc-
tures) there is an algebra A and an interpretation [[·]] into A where [[A]] ̸≤[[B]].
Then, we manipulate A into a new structure A ′, appropriate for the larger
language, and in which we have a new interpretation which is still a coun-
terexample to [[A]] ̸≤[[B]]. There are two separate techniques Meyer pioneered.
One, injecting a structure A into it’s completion A∗(giving us a way to inter-
pret t, ◦, and conjunction and disjunction if those are not present), and then,
taking a structure A and pasting on an inverted duplicate Aop, in order to
model negation.
75Equivalently, it is the set generated by all identities


 , since



≤



if

≤
 .
76It is the algebraic analogue of a theory, which we have already seen.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
62
EXAMPLE 29 (MAPPING A INTO A∗) The map from a propositional structure
into its completion is given in the following way. A∗is deﬁned in a number of
alternative ways.
⋄If A is only a poset or a semilattice (with ∧but not ∨), then A∗is the set of
all downwardly closed sets of A. That is, I is an element of A∗if and only
if whenever a ∈I and b ≤a then b ∈I.
⋄If A contains disjunction, then A∗is the set of all ideals in A. (Ideals are
dual to ﬁlters. They are closed downward, and closed under disjunction:
if a, b ∈I then a ∨b ∈I.)
⋄If A contains disjunction and ⊥, then A∗is the set of nonempty ideals in
A — every ideal must contain ⊥, the least element of A.
A∗is a complete lattice — order is subsethood, the conjunction of a class
of elements is their intersection, and the disjunction of a class of elements
is the intersection of all elements above each element in that class. It is not
difﬁcult to show that it completely distributive if the original lattice contains
no counterexample to distributivity. If fusion is present in A then it is present
in A∗too.
I ◦J = {z : ∃x ∈I, y ∈J(z ≤x ◦y)}
and other connectives lift in a similar way. The structural rules of A are pre-
served in A∗.77 This shows that A∗has the nice logical properties of A.
However, since A∗is a complete lattice, we can do interesting things with
it. If A doesn’t contain a truth element t as a left identity for fusion, A∗still
does. Since A∗is complete, you can set t to be V{I →J : I ≤J}. Then t ◦I ≤J
if and only if t ≤I →J if and only if I ≤J, and so, t is a left identity for fusion.
Furthermore, the map from A to A∗which sends a to ↓a = {x : x ≤a}
injects one structure into the other, preserving all of the operations in A. Any
consecution with a counterexample in A will have a counterexample in A∗
too. It shows that linear logic without the additives is conservatively extended
by additives which distribute, for example.
EXAMPLE 30 (PASTING A AND Aop TOGETHER) Modifying a structure in such
a way as to add negation is more difﬁcult. To add a de Morgan negation to
a structure, we need an upside down copy Aop of A so that for negation can
be an order inverting map of period two. Following the details of this con-
struction will be a great deal easier if we take A to include top and bottom
elements, so from now I will do so.
Conjunction and disjunction in Aop can be deﬁned as the de Morgan dual
of that in A. So, if a, b ∈Aop then a ∧b = −(−a ∨−b), where −is the map
from A to Aop and back. Deﬁning conjunctions and disjunctions of elements
between A and Aop depends on another decision we need take. If a ∈A
and b ∈Aop, then we need decide on what we take a ∧b and a ∨b to be.
There are three options for this, each depending on the relevant positioning
of A and Aop. Meyer’s original choice [179] was to put Aop above A. Then the
disjunction of an element form A with an element from Aop will be the ele-
ment from Aop and the conjunction will be the element from A. This choice
(rather than putting Aop under A) is the one to take if you wish to end up with
a model for the relevant logic R, for we wish to end up with t ⊢A ∨−A. The
77The proof is tedious but straightforward [234, Chapter 9].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
63
element t is in A, and we wish it to be under each a ∨−a. But a ∨−a can
be any element in the top half of the model, so t must be under each element
in the top half, so it is either the bottom element of the top half of the model
(not likely, if any conditional is untrue at all in the original model) or it is in
the bottom half.
The other choice for ordering the two components — putting Aop below
A — is required if you wish the original model to satisfy K. Then, t must be ⊤,
and since t is in the original model, it must be at the top of the new model, so
Aop can go underneath.
There is one other natural choice for the ordering of A and Aop, and that is
to take them in parallel. You can paste together the top elements both mod-
els and the bottom elements of both models (or add new top and bottom el-
ements if you prefer) and then take the disjunction of a pair, one from A and
Aop, to be the ⊤element of the whole structure, and the conjunction of that
pair to be the ⊥element. This in another natural option, but the resulting
lattice is not distributive if A is not trivial.
To make the resulting structure a model for a logic, you must deﬁne ◦and
→in the whole structure. Most choices are ﬁxed in advance, if fusion is com-
mutative in A. Since we want a ◦b to be −(a →−b), and a →b to be
−b →−a, we take a ◦b when a ∈A and b ∈Aop to be −(a →−b) (and
the dual choice when a ∈Aop and b ∈A). The remaining choice is for a ◦b
where a, b ∈Aop. Here, it depends on the relative position of A and Aop. If
we add the new structure on top, take a◦b to be ⊤. If we add the new structure
below, or alongside, take a◦b to be ⊥. The new structure satisﬁes many of the
structural rules of the old structure, and as a result, a conservative extension
result for logics in the vicinity of R follows [177, 179, 234].
There is one substructural logic for which a conservative extension by
negation fails: RM. RM is given by extending R with the mingle rule A◦A →A
(or equivalently, A ⊢A →A). If you add mingle to positive R then the re-
sult is still a sublogic of intuitionistic logic, and as a result, total ordering
t ⊢(A →B) ∨(B →A) is not provable. This logic is called RM0. In the
presence of negation, however, the addition of mingle brings along with it-
self the total ordering principle. (This result is due to Meyer and Parks, from
1972 [188].)
3.2
Categories
In propositional structures, we abstract away from the particulars of the lan-
guages in which our propositions are expressed to focus on the propositions
themselves, ordered under entailment. In propositional structures, propo-
sitions are ﬁrst-class citizens, and proofs between propositions fade into the
background. If there is a proof from A to B, then [[A]] ≤[[B]]. The differences
between proofs from A to B are not registered in this algebraic semantics.
Models do not have to be like this. We can consider not only propositions
as objects but also proofs as “arrows” between objects. If we have one proof
from A to B, we might indicate this as ‘f : A
- B,’ where f is the proof. We
might have another proof g : B
- C, and then we could compose them to
construct another proof gf : A
- C, which runs though f and then g.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
64
Logicians did not have to go to the trouble of inventing structures like this.
It turns out that mathematical objects with just these properties have been
widely studied for many decades. Categories are important mathematical
structures. Category theory is a helpful language for describing constructions
which appear in disparate parts of mathematics. This means that category
theory is, by its nature, very abstract. This also means that category theory
is rich in examples, interesting categories are models of substructural logics.
In particular, I will look at one example categorical model of a logic, Girard’s
model of coherence spaces, for linear logic.78
To understand the role of categories as models of logic, you need to focus
on one particular part of categorical technology: the adjoint pair. An adjoint
pair is a relationship between two functors, and functors are structure pre-
serving maps between categories. Thinking of a category as a model of a logic
generalising an algebra, the operators such as fusion, implication and so on
are all functors from the category to itself (or perhaps, from the category to
its opposite, which is found by swapping arrows from a to b to go from b to a
instead). Operators like fusion, which are isotonic, are really two-place maps
from a category to itself, not only sending a pair of category objects to another
object (their fusion) but also sending arrows f : a
- a′ and g : b
- b′ to
an arrow f ◦g : a ◦b - a ◦b′.
DEFINITION 31 (ADJOINT PAIRS) If F : C
- D and G : D
- D, and there is
a bijection φ : HomC(X, F(Y)) ∼= HomD(G(X), Y), natural in both X and Y,79
then we say that ⟨F, G, φ⟩is an adjunction. F is the left adjoint and G is the
right adjoint.
EXAMPLE 32 (ADJUNCTION BETWEEN FUSION AND IMPLICATION) In cartesian
closed categories,80 product: — × B is a functor C
- C. Similarly [B ⇒—]
is a functor C
- C. These functors form an adjunction. If f : A × B
- C,
then λf : A
- [B ⇒C]. Conversely, if g : A
- [B →C], then ev(g × idB) :
A × B - C. This is a bijection Hom(A × B, C) ∼= Hom(A, [B ⇒C]).
This is the categorical equivalent of the residuation between extensional con-
junction and intuitionistic implication. Cartesian closed categories are mod-
els of intuitionistic logic [152].
3.2.1
Coherence Spaces
Coherence spaces arise as a model of the λ-calculus, and intuitionistic logic.
They provided the ﬁrst model which gave Girard an insight into the decom-
position of intuitionistic implication in terms of linear implication and the
exponential ! [117, 121].
78In a history like this I can only assume some category theory, and not introduce it myself.
Here are some standard references: Mac Lane’s Categories for the Working Mathematician is a
very good introduction to the area [158], very readable, even by those who are not working math-
ematicians. Barr and Wells’ Category Theory for Computing Science is also clear, from a perspec-
tive of the theory of computation [17]. Chapter 10 of An Introduction to Substructural Logics [234]
contains just the category theory you need to go through the detail of this model. Doˇsen’s paper
“Deductive Completeness” is a clear introduction focussing on the use of categories in logic [72].
79I can’t tell you what it is for a bijection to be natural, unfortunately. However, Hom
 
  
 is
the class of all arrows from
 to

in the category.
80I can’t tell you what these are, for lack of space.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
65
DEFINITION 33 (COHERENCE SPACES) A coherence space is a set A of sets, sat-
isfying the following two conditions.
⋄If a ∈A and b ⊆a then b ∈A, and
⋄If for each x, y ∈a, {x, y} ∈A, then a ∈A.
But coherence spaces are much better thought of as undirected graphs. We
say a coheres with b (in A) if {x, y} ∈A. We write this: ‘x⌣
⌢y (mod A).’ The co-
herence relation determines the coherence space completely. Coherent sets
(a ∈A) are cliques in the graph. The coherence relation is reﬂexive and sym-
metric, but not, in general, transitive.81
Given a coherence space A, we deﬁne coherence relations as follows:
⋄x⌢y (mod A) iff x⌣
⌢y (mod A) and x ̸= y.
⋄x⌣y (mod A) iff {x, y} ̸∈A.
⋄x⌢
⌣y (mod A) iff it is not the case that x⌢y (mod A).
DEFINITION 34 (PRODUCT, SUM AND NEGATION SPACES) Given spaces A and
B, the coherence spaces A ∧B and A ∨B are deﬁned on the disjoint union of
the points x of the graph of A and y of the graph of B, as follows:
(0, x)⌣
⌢(0, x′) (mod A ∧B)
iff x⌣
⌢x′ (mod A)
(1, y)⌣
⌢(1, y′) (mod A ∧B)
iff y⌣
⌢y′ (mod B)
(0, x)⌣
⌢(1, y) (mod A ∧B)
always
(0, x)⌣
⌢(0, x′) (mod A ∨B)
iff x⌣
⌢x′ (mod A)
(1, y)⌣
⌢(1, y′) (mod A ∨B)
iff y⌣
⌢y′ (mod B)
(0, x)⌣
⌢(1, y) (mod A ∨B)
never
Given a coherence space A, the coherence space ∼A is deﬁned by setting x⌣
⌢y
(mod ∼A) if and only if x⌢
⌣y (mod A). Note that ∼∼A = A. Sgl = {∅, {∗}}, the
one-point coherence space. Emp = {∅}, the empty coherence space. Note that
∼Sgl = Sgl and ∼Emp = Emp.
Note that here ∼(A ∧B) = ∼A ∨∼B, and ∼(A ∨B) = ∼A ∧∼B. Furthermore,
A ∧Emp = Emp ∧A = A = A ∨Emp = Emp ∨A. Emp does the job of both ⊤
and ⊥in the category of coherence spaces.82
The class of all coherence spaces can be made into a cartesian closed cat-
egory, if we take the arrows to be continuous functions.
DEFINITION 35 (CONTINUOUS FUNCTIONS) F : A
- B is continuous if and
only if
⋄If a ⊆b then F(a) ⊆F(b).
⋄If S ⊆A is directed (that is, if a, b ∈S, then a ∪b ∈S too) then F(S S) =
S{F(a) : a ∈S}.
81Erhard’s hypercoherences are a generalisation of coherence spaces which are richer than a
graph represents [95]. In hypercoherences,
 might be a coherent set without

′ ⊆
 also being
coherent. The category of hypercoherences is also a model of linear logic.
82This shows how categories have a kind of ﬂexibility unavailable to posets. In a poset, ⊤

⊥
only if the poset is trivial. In a category, ⊤and ⊥might be identical or isomorphic, without the
category structure being trivial. Yes, there will be arrows from every object to every other object,
but it is not the case that all objects are isomorphic.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
66
FACT 36 (MINIMAL REPRESENTATIVES) If F : A
- B is continuous, and if a ∈
A and y ∈F(a), then there is a minimal ﬁnite a ′ ∈A where y ∈F(a′).
PROOF
If y ∈F(a) then y ∈F(a∗) for some ﬁnite a∗. Pick some smallest
subset a′ of a∗with this property. (This is possible, as a∗is ﬁnite.)
□
We want to construct a coherence space representing F : A - B. We start by
deﬁning the trace of a function.
Trace(F) = {(a, y) ∈Aﬁn × |B| : y ∈F(a) and a is minimal}
Note that Trace(F) ⊆Aﬁn × |B| has the following properties.
⋄If (a, y), (a, y′) ∈Trace(F) then y⌣
⌢y′ (mod B).
⋄If a′ ⊆a, (a, y), (a′, y) ∈Trace(F), then a = a′.
Conversely, if F is any set with these two properties, then deﬁne FF by setting
FF(a) = {y ∈|B| : ∃a′ ⊆a where (a′, y) ∈F}
We can represent continuous functions by their traces. In fact, if F is con-
tinuous, then F = FTrace(F). Can we deﬁne a coherence relation on traces?
Consider the special case where there are two minimal representatives, that
is, (a, y), (a′, y) ∈Trace(F). Under what circumstances are they coherent?
Unfortunately, we need more information in order to deﬁne a coherence re-
lation — we need a relationship between a and a ′. We can show that in a
particular class of continuous functions, there is always a unique minimal a.
DEFINITION 37 (STABLE FUNCTIONS) F : A
- B is stable if it is continuous,
and in addition, whenever a, a′, a ∪a′ ∈A, then F(a ∩a′) = F(a) ∩F(a′).
With stable functions, we can choose a unique minimal representative a.
FACT 38 (UNIQUE MINIMAL REPRESENTATIVES) F : A
- B is stable if and
only if for each a ∈A, where y ∈F(a), there is a unique minimal a ′ ∈Aﬁn
such that y ∈F(a′).
PROOF
For left to right, it is straightforward to check that a ′ = T{a∗∈A :
a∗⊆a, where y ∈F(a∗)} is the required a′. For right to left, monotonicity
tells us that F(a ∩a′) ⊆F(a) and F(a ∩a′) ⊆F(a′), so F(a ∩a′) ⊆F(a) ∩F(a′).
Conversely, if a, a′, a ∪a′ ∈A, then if y ∈F(a) and y ∈F(a ′), then y is in
F(a′′) for a unique minimal a′′. Therefore a′′ ⊆a and a′′ ⊆a′, so a′′ ⊆a∩a′,
and hence y ∈F(a′′) ⊆F(a ∩a′), as desired.
□
The next result is simple to verify.
FACT 39 (CHARACTERISING STABLE FUNCTIONS) If F is stable, then whenever
(a, y), (a′, y′) ∈Trace(F)
⋄If a ∪a′ ∈A then y⌣
⌢y′ (mod B).
⋄If a ∪a′ ̸∈A then y = y′ (mod B).
Conversely, if the set F satisﬁes these conditions, then FF is stable.
□
Given this, we can deﬁne A ⊃B. |A ⊃B| = Aﬁn×|B| as follows: (a, y)⌣
⌢(a′, y′)
(mod A ⊃B) if and only if
⋄If a ∪a′ ∈A then y⌣
⌢y′ (mod B).
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
67
⋄If a ∪a′ ∈A then y = y′ (mod B).
That is, A ⊃B = {Trace(F) | F : A
- B is stable}. The category of coherent
spaces and stable functions between them is cartesian closed. This construc-
tion is obviously a two-stage process. It begs to be decomposed. We should
deﬁne a coherence space !A on the set of ﬁnite coherent sets of Aﬁn as follows:
a⌣
⌢a′ (mod !A) iff a ∪a′ ∈A
and deﬁne linear implication A →B by setting (x, y)⌣
⌢(x′, y′) (mod A →B)
if and only if
⋄If x⌣
⌢x′ (mod A) then y⌣
⌢y′ (mod B).
⋄If x⌣
⌢x′ (mod A) and y = y′ then x = x′.
Note that A →B is (isomorphic to) ∼B →∼A. Furthermore, Sgl →A is
(isomorphic to) A and A →Sgl is (isomorphic to) ∼A. The operation ⊃stands
to stable functions as →stands to a new kind of function: the linear functions.
DEFINITION 40 (LINEAR MAPS) F is a linear map if and only if whenever A ⊆
A is linked (that is, if a, b ∈A then a ∪b ∈A) then F(S A) = S{F(a) : a ∈A}.
If F is linear then F is stable (this is straightforward) and in addition, if x ∈F(a)
then the minimal b where x ∈F(b) is a singleton. It follows that the trace of F
can be simpliﬁed. The linear trace of a linear map F is deﬁned as follows:
Trlin(F) = {(x, y) : y ∈F({x})}
Therefore, A →B = {Trlin(F) | F : A
- B is linear}.
Given →, we can see that it is connected by an adjunction to a natural
fusion operation. We can deﬁne A ◦B as follows: |A ◦B| = |A| × |B|, and
(x, y)⌣
⌢(x′, y′) if and only if x⌣
⌢x′ (mod A) and y⌣
⌢y′ (mod B).
FACT 41 (THE ADJUNCTION BETWEEN FUSION AND IMPLICATION) In the cate-
gory of coherence spaces with linear maps
Hom(A ◦B, C) ∼= Hom(A, B →C)
is an adjunction for all A, B and C.
This, with the associativity and commutativity of ◦, together with the be-
haviour of !, shows that the category of coherence spaces and linear maps
is a model of linear logic.
Some very recent work (2001) of Schalk and de Paiva’s on poset-valued
sets [248] generalises coherence spaces in an interesting direction. They show
that coherence spaces and hypercoherences can be seen as maps from Set ×
Set to the algebra RM3.83 If x⌢y then f(x, y) = t, if x⌣y then f(x, y) = f, if
x = y then f(x, y) = b. The logical operators of negation, fusion and impli-
cation then lift from the algebra to the coherence spaces. (In other words, if
A : Set × Set →RM3 is a coherence space, then ∼A is the map composing A
83They do not recognise that the algebra is already quite studied in the relevant logic literature.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
68
with ∼: RM3 →RM3. The same goes for the other operations.) Different cat-
egorical models in the style of coherence spaces can then be given by varying
the target algebra. I suspect that using some of the algebras known in the sub-
structural literature will lead to interesting categorical models of linear logic
and related systems.
Girard has shown that Banach spaces can be used in place of coherent
spaces to model linear logic [120]. The norm in a Banach space takes the
place of the coherence relation. As we shall see later, it is not the only point at
which geometric intuitions have come to play a role in substructural logic.
3.3
Frames
The study of modal logic found new depth and vigour with the advent of pos-
sible worlds semantics. As we have seen, algebras are useful models of sub-
structural logics. However, they are so close to the proof theory of these logics
that they do not provide a great deal of new information, either about the in-
trinsic properties of the logic in question, or about how it is to be applied.
Models in terms of frames are one way to extract more information. Perhaps
this is because frames are a further step removed from the logic in an im-
portant sense. In algebras, each formula in the language is interpreted as an
element in the algebra. In frames, each formula is not interpreted as an ele-
ment in the frame — the elements in the frame lie underneath the interpre-
tation of formulas. Formulas are interpreted as collections of frame elements.
Therefore the interpretations of connectives on a frame are themselves de-
composed. They are no longer simply functions on algebras satisfying spec-
iﬁed conditions. Their action on sets of frame elements is factored through
their action on individual frame elements. As a result, frame interpretations
of logics can be thought to carry more information than algebras. In addi-
tion, frame semantics is suggestive of applications of logics. Just as the idea
of the interpretation of a proposition as a set of possible worlds, or a set of
times or a set of locations has driven the application of different models of
modal or temporal logics, so the interpretation of frame semantics for sub-
structural logics has led to their use in diverse applications. But enough of
scene-setting. Let’s start with a the ﬁrst attempts to give precise frame se-
mantics for substructural logics. As before, our story starts with the relevant
logic R.
3.3.1
Operational Frames
The idea of frame semantics for relevant logics occurred independently to
Routley and to Urquhart in the late 1960s and early 1970s. Routley’s tech-
niques are more general than Urquhart’s, but Urquhart’s were published ﬁrst,
and are the simplest to introduce, so we will start with them.
Consider the constraints for developing a frame semantics for a relevant
logic. The bare bones of any frame semantics are as follows. A frame is a set
of objects (call them points, though “worlds”, “situations”, “set-ups” and other
names have all been used), and a model on that frame is a relation ⊩which
indicates what formulas are true at what points. We read “x ⊩A” as “A is
true at x.” Typically, the relation ⊩is constrained by inductive clauses that
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
69
indicate how the truth (or otherwise) of a complex formula at each point is
determined by the truth (or otherwise) of its subformulas. Given a particular
model, then, we say that A entails B on that model if and only if for every
point x, if x ⊩A then x ⊩B. Entailment is preservation of truth at all points
in a model.
This is the bare bones of a frame semantics for a logic. Consider how this
determines what we can do to interpret relevant implication. It is axiomatic
for a relevant logic that the entailment from A to B →B can fail. In frame
terms this means that we must have points in our models in which B →B
can fail. This means that the interpretation of implication must differ from
any kind of frame interpretation of conditionals seen. For a strict conditional
A ⇒B to be true at a world, we need to check all accessible worlds, to see if
B is true whenever A is true. As a result, B ⇒B is true at every world. Sim-
ilarly, for counterfactual conditionals A □→B, we check the nearby worlds
where A is true, to see if B is true there too. Again, B □→B is true, because
we check the consequent at the very same points in the model where we have
taken the antecedent to be true. Something different must be done for a rel-
evant conditional. At the very least we need to check the value of the con-
sequent somewhere at places other than simply where we have checked the
antecedent.
Urquhart’s innovation was a natural way to do just this [265, 266, 267, 268].
Consider again what an implication A →B says. To be committed to A →B
is to be committed to B whenever we gain the information that A. To put it
another way, a body of information warrants A →B if and only if whenever
you update that information with new information which warrants A, the re-
sulting (perhaps new) body of information warrants B. Putting this idea in
technical garb, we get a familiar-looking inductive clause from a frame se-
mantics:
⋄x ⊩A →B if and only if for each y, if y ⊩A then x ⊔y ⊩B.
But this inductive clause has a new twist. Unlike the clauses for strict or
counterfactual conditionals, in this clause we check the consequent and an-
tecedent at different points in the model structure. The way is open for B →B
to fail.
Let’s take some time to examine the detail of this clause. We have a class
of points (over which “x” and “y” vary), and a function ⊔which gives us new
points from old. The point x ⊔y is supposed, on Urquhart’s interpretation,
to be the body of information given by combining x with y. The properties
we take combination to have will inﬂuence the properties of the conditional.
First up, let’s consider our old enemy, A ⊢B →B. For this to fail, we need
have a point x where x ̸⊩B →B, and for this, we need just some y where
y ⊩B and x ∪y ̸⊩B. This means that combination of bodies of information
cannot satisfy this hereditary condition:
⋄
If x ⊩A then x ⊔y ⊩A
left hereditary condition
Similarly, if we are to have A ⊢B →A to fail, then combination cannot satisfy
the dual hereditary condition.
⋄
If x ⊩A then y ⊔x ⊩A
right hereditary condition
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
70
This means that combination is sometimes nonmonotonic in a natural sense.
Sometimes when a body of information is combined with another body of
information, some of the original body of information might be lost. This is
simplest to see in the case motivating the failure of A ⊢B →A. A body of
information might tell us that A. However, when we combine it with some-
thing which tells us B, we the resulting body of information might no longer
warrant A (as A might conﬂict with B). Combination might not simply result
in the addition of information. It may well warrant its revision.
To model the logic R, combination must satisfy a number of properties:
⋄
x ⊔y = y ⊔x
commutativity
⋄
(x ⊔y) ⊔z = x ⊔(y ⊔z)
associativity
⋄
x ⊔x = x
idempotence
Commutativity gives us assertion, associativity gives us preﬁxing and sufﬁx-
ing, and idempotence gives us contraction, as is easily veriﬁed. For example,
consider assertion: to verify that A ⊢(A →B) →B, suppose that x ⊩A. To
show that x ⊩(A →B) →B, take a y where y ⊩A →B. We wish to show that
x ⊔y ⊩B. By commutativity, x ⊔y = y ⊔x, and since y ⊩A →B and x ⊩A,
we can apply the conditional clause at y to give y ⊔x ⊩B. So, x ⊔y ⊩B as
desired.
These frame properties, governing the behaviour of ⊔are very similar in
scope to the structural rules governing fusion and intensional combination
in different proof theories. This is no surprise, as ⊔is the frame analogue of
fusion. It comes as no surprise, then, that as you vary conditions on ⊔you
can model different substructural logics.
Keeping the analogy aﬂoat, then, we can see how these models might in-
terpret theoremhood in our logics. In analogy with the proof theory and alge-
braic models of our logics, we can see that there are two different grades of
truth. It is one thing for a formula to be true everywhere in a model — this
corresponds to being entailed by the Church true constant ⊤. It is another
thing for it to be a tautology, for it to be entailed by the Ackermann true con-
stant t. Identities are entailed by t. What corresponds to being a tautology
in this sense in our models? Clearly being true at every point is ruled out, as
identities can fail at different points in a model. Continuing the interpreta-
tion of points as bodies of information, if we can have bodies of information
which do not warrant all of the tautologies of logic, then we need some way
of talking about which bodies of information do. The simplest approach (and
the one which Urquhart took) is to take a special body of information 0 to
stand for “logic.” A natural condition to take on 0 is that it is a left identity for
composition
⋄
0 ⊔x = x
left identity
In this way, 0 ⊩A →B if and only if for each x, if x ⊩A then x ⊩B — so the
conditionals warranted by logic correspond to exactly the entailments valid
in the frame. The identity point 0 does a good job of modelling logic.
The interpretation of points as bodies of information warrants a simple
interpretation of conjunction as well. The usual clause
⋄x ⊩A ∧B if and only if x ⊩A and x ⊩B
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
71
is uncontroversial. If a body of information warrants A ∧B it warrants A and
it warrants B, and conversely. Adding this clause to the semantics gives us the
conjunction and implication fragment of R (and its neighbours, varying the
behaviour of of ⊔).
Intensional conjunction is also straightforward. We can add fusion as the
object-language witness of composition:
⋄x ⊩A ◦B if and only if for some y, z where x = y ⊔z, y ⊩A and z ⊩B.
It is instructive to verify that in these models, that A ◦B ⊢C if and only if
A ⊢B →C. Residuation between →and ◦corresponds to the universal
clause modelling →interacting with the existential clause modelling ◦.
Let’s now turn to soundness and completeness with respect to these mod-
els. To prove soundness of a proof theory with respect to these models, it is re-
quired only to show that everything provable in the proof theory holds in the
model (either holds at 0 for a Hilbert system, or holds over the entire frame for
a proof theory which delivers consecutions). As usual, verifying soundness is
a straightforward matter of checking axioms and rules.
There are two different ways to prove the completeness of a proof the-
ory with Urquhart’s operational models. Again, as usual, the common tech-
nique is to provide a counterexample for an unprovable formula (or conse-
cution). Both techniques use a canonical model construction, familiar from
the worlds semantics for modal logics. Where these constructions differ is in
the stuff out of which the points in the model are made. The ﬁrst, and most
general kind of canonical model we can provide for an operational semantics
is the theory model, in which the points are all of the theories of the logic in
question.
DEFINITION 42 (THE Theory CANONICAL MODEL) The set of points is the set
T of theories. The identity theory is the set L of all of the tautologies of the
logic. The composition relation ⊔is deﬁned as follows:
S ⊔T = {B : (∃A)(A →B ∈S and A ∈T)}
and S ⊩A if and only if A ∈S.
To verify that the theory canonical model is indeed a canonical model we
must show that ⊔so deﬁned satisﬁes all of the conditions of a composition
relation, and that ⊩satisﬁes the recursive conditions of an evaluation rela-
tion.
To show that ⊔satisﬁes the conditions of composition, you need ﬁrst show
that ⊔is indeed a function on the class of theories: that if S and T are theories,
so is S⊔T. The veriﬁcation of this fact is elementary. The frame conditions on
⊔correspond quite neatly to axioms or structural rules.
To show that ⊩satisﬁes the recursive conditions, you need show that A ∧
B ∈T if and only if A, B ∈T (which is an immediate consequence of the
deﬁnition of a theory) and that A →B ∈S if and only if for each T where A ∈
T, B ∈S ⊔T. The veriﬁcation from left to right is an immediate consequence
of the deﬁnition of ⊔. The veriﬁcation from right to left is simplest to prove
in the contrapositive: that if A →B ̸∈S then there is a T where A ∈T and
B ̸∈S ⊔T. Finding such a T is easy here: let T = {C : A ⊢C}. If B ∈S ⊔T
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
72
then there is some C ∈T where C →B ∈S. Since A ⊢C, it follows that
C →B ⊢A →B (by monotonicity of →) and A →B ∈S contrary to what we
have assumed.
It is possible to extend this kind of completeness proof to show that the
condition for fusion models this connective correctly too.
DEFINITION 43 (THE Finite Set CANONICAL MODEL) The points are the ﬁnite
sets of formulas. Composition ⊔is set union. {A1, . . . , An} ⊩B if and only if
⊢A1 →(· · · →(An →B))
(The permutation axiom shows that the order of presentation in the set is
irrelevant in this deﬁnition.)
It is not difﬁcult to show that this is indeed a model — that the recursive
clause deﬁning →is satisﬁed.
This is a simple model which gives a straightforward counterexample to
any invalid argument. If A ̸⊢B then {A} is the point in the model invalidating
the argument: {A} ⊩A and {A} ̸⊩B.
Operational frames are important models of other substructural logics too.
EXAMPLE 44 (LANGUAGE FRAMES) A language frame on alphabet A is the col-
lection of all strings on that alphabet, with ⊔deﬁned as concatenation.
Language frames are a model of the Lambek calculus. The composition op-
eration ⊔is associative but not commutative (except in the case where A is a
singleton). It was an open question for many years whether or not the Lam-
bek calculus is complete for Language frames. Mati Pentus showed that it
is, using an ingenious (and difﬁcult!) model construction argument pasting
chains of partial models together to form a string model [210, 211]. Different
frames for the Lambek calculus feature prominently in some recent work on
the system and its linguistic applications [200, 202].
EXAMPLE 45 (DOMAIN SPACES) Models of the λ-calculus [1, 126, 251, 252] are
models for substructural logics too. Scott’s famous model construction in-
volves a topological space D such that D is isomorphic to the space [D →D]
of continuous functions from D to itself. Each element of D is paired with
a function in [D →D], so can think of the objects equally well as functions.
Therefore, there is a two-place operation of application on the domain. Con-
sider x(y) — the application of x to y. We can assign types to functions in this
model by “reading” the model as a frame for a logic. If we set x ⊔y to be x(y),
then this is an operational frame:
x ⊩A →B if and only if for each y, where y ⊩A, x(y) ⊩B.
In other words, x is of type A →B if and only if whenever given an input of
type x, the output is of type B. This gives us a plausible notion of function
typing. For example, λx.(x + 1) will have type Even →Odd and Odd →Even.
The function λx.λy.(2x + y) has type N →(Odd →Odd) (whatever number x
is, if y is odd, so is 2x + y) but it does not have type Odd →(N →Odd) (if y
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
73
is even, the output will be even, not odd). This is an example demonstrating
the failure of the permutation-related rule: A →(B →C) ⊢B →(A →B).84
This is an important model because it motivates the failure of not only
commutativity of ⊔but also associativity. There is no sense in which x(y(z))
ought be equal to (x(y))(z). Function typing models a very weak substruc-
tural logic.
Urquhart considered adding disjunction to operational frames, with the nat-
ural clause:
⋄x ⊩A ∨B if and only if x ⊩A or x ⊩B
However, this is not as satisfactory as its cousin for conjunction. For one
thing, R models extended with this clause validate the following formula
(A →B ∨C) ∧(B →C) →(A →C)
(1)
which is not valid in R.85 Secondly, and more importantly, the interpretation
in terms of pieces of information simply doesn’t motivate the straightforward
clause for disjunction. Pieces of information may well warrant disjunctions
without warranting either disjunct. To interpret disjunction in operational
models (and to get a logic in the vicinity of R or any of the other logics we
are interested in) you can do one of two things. One approach is, taken by
Ono [205, 206], Doˇsen [68, 69] and Wansing [284], is to admit some kind of
closure operator on the frame: A ∨B is true not only at points where A is true
and where B is true, but also at some more points, found by closing the orig-
inal set under some operation. Doing this will almost invariably invalidate
distribution, and we will look at one example of this kind of semantics in the
a couple of section’s time, when we come to phase space models for linear
logic.
A related method, and one which validates distribution, was discovered
by Kit Fine [97, 99] in the mid 1970s. He showed that if you have a two tiered
collection of points, the whole class S with a special subset P of prime points
(in analogy with prime theories) which respect disjunction. For points in P, a
disjunction is true if and only if a disjunct is. For arbitrary points in S this may
fail. For an arbitrary point in S, however, you have a guarantee that there it
can be covered by a point in P. For each s ∈S there is at least one s ′ ∈P where
s ⊑s′. This means that disjunctions are at least promissory notes: although
a disjunct may not be true given this body of information, it is possible for
the information to be ﬁlled out so that you get one or other disjunct. Then, a
disjunction, in a Fine model, is evaluated like this:
⋄x ⊩A ∨B if and only if for each y ∈T where x ⊑y, y ⊩A or y ⊩B.
Fine’s models will satisfy distribution, and model the positive fragment of R
nicely. They do so at the cost of requiring special bodies of information, those
84We can use other connectives to expand the type analysis of terms. Conjunction clearly
makes sense in this interpretation:


 
 if and only if


 and


  . In this way,
we have models not only for typing functions with

but also with intersection. These are mod-
els for the Torino type system
  ∩[16, 60, 135, 276].
85This is not to say that the operational semantics with this disjunction clause hasn’t been
investigated. See some interesting papers of Charlewood: [52, 53], following on from a result of
Fine [98].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
74
which are prime. They also have the cost of requiring a new notion ⊑, of infor-
mational inclusion. This requires a new condition on frames, the hereditary
condition, familiar from models for intuitionistic logic:
DEFINITION 46 (HEREDITARY CONDITION) If x ⊩p and x ⊑y then y ⊩p too.
To show that the hereditary condition extends from atomic propositions to all
propositions, a further model condition is required to validate the inductive
step for the conditional. You need to assume that
If x ⊑x′ and y ⊑y′ then x ⊔y ⊑x′ ⊔y′.
Given this clause, we indeed have a model for positive R. The cost has been
a complication of the clause for disjunction, the requirement that we have a
two-tiered universe of points, and a hereditary condition on points. This is
not the only way to model the whole of R. Routley and Meyer, independently
of Fine, came to an equally powerful semantics, with a slightly smaller set of
primitive notions. Before looking at the Routley–Meyer semantics in the next
section, I must say a little about negation in the operational semantics.
How one interprets negation depends to a great extent on the intended
interpretation. The Boolean clause for negation
⋄x ⊩−A if and only if x ̸⊩A
is marvellously appropriate in string models of the Lambek calculus (a string
is of type “not a noun” just when it is not of type “noun”) and in function typ-
ing (a function like λx.x2 has type −Even →−Even: it sends inputs which are
not even to outputs which are also not even) but it is terrible when it comes
to taking points as bodies of information. There is little reason to think that
a body of information x warrants the negation of A just when it fails to war-
rant A. Bodies of information can be incomplete (warranting neither a claim
nor its negation) and they can be inconsistent (warranting — you might think
misleadingly — a claim and its negation). Something else too must be done
to model negation. Fine had a treatment of negation in his models, but it too
appeals essentially to the two-tiered nature of a model, and it is simpler in the
Routley–Meyer incarnation.
3.3.2
Routley–Meyer Frames
Routley and Meyer [239, 240, 241, 242] chose to keep the interpretation for
disjunction simple, and to generalise the interpretation for implication. The
central feature of a Routley–Meyer frame is the ternary relation R. The clause
for implication then is:
⋄x ⊩A →B if and only if for each y, z where Rxyz, if y ⊩A then z ⊩B.
This is a generalisation of the operational semantics. An operational frame is
a Routley–Meyer frame where Rxyz holds if and only if x ⊔y = z. The inter-
pretation of R is similarly a generalisation of that for ⊔. Reading the implica-
tion clause “in reverse” (as assigning meaning to R and not to →)86 we have
that Rxyz if and only if the laws (or conditionals) in x, applied to the facts
86Which, frankly, is exactly what is done in cases of interpreting the accessibility relation in a
modal logic as “relative possibility”.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
75
(antecedents) in y give outcomes (consequents) true in z. Or more shortly,
applying x to y gives an outcome included in z. That this is a genuine rela-
tion means that applying x to y might give no outcome at all. On the other
hand, it we might have Rxyz and Rxyz ′ for different z and z′. The result of
applying x and y is no doubt a body of information, but it might not be a
prime body of information. For example we might have x ⊩A →B ∨C and
y ⊩A. Applying the information in x to that in y will give B ∨C, without
giving us any guidance on which of B or C it is to be. And this is possible
even if x is prime — for in R we don’t have the counterintuitive entailment
A →B ∨C ⊢(A →B) ∨(A →C), so we have no reason to think that x might
contain either A →B or A →C. So, in this case, we’d have two points z and
z′ where Rxyz and Rxyz′. At z we can have B and at z′ we can have C. In this
way, we verify A →B ∨C at x, all the time using prime points. We only have
a semantics for the positive part of R when endow the ternary relation R with
some properties. Routley and Meyer’s original properties are best stated with
the use of some shorthand.
⋄“R2abcd” is shorthand for (∃x)(Rabx ∧Rxcd).
⋄Given the distinguished point 0, we let “a ⊑b” be shorthand for R0ab.
These abbreviations make sense, given the interpretations of the concepts at
hand. R2abcd conjoins application. You apply a to b and get a result in x (for
some x) which we then apply to c to get a result in d. One way of thinking of
this is applying a to b and applying all of this to c. The inclusion relation is
deﬁned by looking at what happens when you apply logic to a state. Applying
logic to a ought result in nothing more than a. So, if R0ab if and only if a is
included in b.
Fine has suggested [97] writing Rabc as “b ⊑a c”, and reading it as: ac-
cording to a, b is contained in c.87 In this case, ⊑is ⊑0, containment from the
point of view of logic.
Here are the postulates Routley and Meyer gave to make their semantics
model the logic R.
⋄(Identity) R0aa for each a.
⋄(Commutativity) If Rabc then Rbac.
⋄(Pasch’s Postulate) If R2abcd then R2acbd.
⋄(Idempotence) Raaa for each a.
⋄(Heredity) If Rabc and a′ ⊑a then Ra′bc.
These postulates parallel the postulates for ⊔. Identity and heredity govern
the behaviour of 0, making it ﬁt to do the job of t, and to be a place to witness
logical truths. Commutativity corresponds to the commutativity of fusion,
Pasch’s postulate corresponds to B ′: an equivalent postulate, given commu-
tativity, would be
⋄(Associativity) If R2abcd then R2a(bc)d.
Where “R2a(bc)d” is read as (∃x)(Rbcx ∧Raxd).
87This is a plausible proposal, provided that you are aware that in models for R, ⊑
  may fail to
be reﬂexive, as is needed to forma counterexample to
 ⊢
 
  .
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
76
Idempotence does the job of WI. So, we have a match with the postulates
for an operational frame. And as with operational frames, ringing the changes
with regard to the behaviour of R will result in different logical systems.
Soundness of Routley–Meyer models is a straightforward matter of show-
ing that each provable consecution is valid on each model. (A valid consecu-
tion is, as usual, one which is preserved at every point.) To interpret conse-
cutions, you must have an interpretation of fusion, but that is as you would
expect.
⋄x ⊩A ◦B iff there are y, z where Ryzx, y ⊩A and z ⊩B.
A fusion is true at a point in a model when it is the composition of two points,
at which the “fusejuncts” are, respectively, true. Logically true formulas are
then always true at 0 in a Routley–Meyer model.
Demonstrating completeness, as always for a semantics like this, is much
more involved. As usual, it is a canonical model construction. To construct
a canonical model for a logic like R, instead of dealing with all theories, as
we could with operational models, we must deal in prime theories88 But here,
not just any prime theories will do. In these models, each point is closed un-
der consequence as deﬁned at the point 0. This is a fundamental fact about
Routley–Meyer models:
FACT 47 (SEMANTIC ENTAILMENT) A entails B in a Routley–Meyer model (that
is, for all x, if x ⊩A then x ⊩B) if and only if 0 ⊩A →B.
This means that these points are not only prime theories, they are prime 0-
theories. They are closed under the “logic of 0.” And here, what is going on at
0 may be more than just genuinely “logic” according to the logic in question.
In particular, this is the case at R, at least if negation is around. (Bear with
the fact that I haven’t told you how to interpret negation yet.) For R proves
A ∨∼A, and so, by the primeness of the point 0, we will have either 0 ⊩A or
0 ⊩∼A. In any particular model, 0 will validate more than “logic alone”. So, to
construct a model, we will ﬁrst construct a prime theory T for the base point
0, and then the other points in the model will be prime T-theories: theories
closed under the inferences licensed by T.
DEFINITION 48 (THE Prime Theory CANONICAL MODEL ON T) Given a prime,
regular theory T, prime theory canonical model on T is populated by prime T-
theories. The identity point is T itself. The ternary relation R is deﬁned as
follows:
RUVWif and only if{B : (∃A)(A →B ∈U and A ∈V)} ⊆W
and U ⊩A if and only if A ∈U.
Note the similarity of the deﬁnition of R here to the deﬁnition of ⊔on the
canonical theory model on page 71. Here, R is deﬁned by composition of the-
ories, but the composition of two prime T-theories may not itself be a prime
theory, so we resort to the ternary relation.
88Deﬁned at Deﬁnition 5 on page 24.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
77
Proving that this is indeed a model is a matter of checking all of the clauses.
The difﬁcult conditions are the existential ones, according to which there is
a point in the model with certain properties. An example is one half of the
implication clause: if A →B ̸∈U, we need to ﬁnd V, W where RUVW, A ∈V
and B ̸∈W. This is a matter of using Belnap’s Pair Extension Theorem89 twice.
First, to construct V you use the pair ⟨{A}, {C : C →B ∈U}⟩, and extend it to
get a prime V. Then, for W you use the pair ⟨U ⊔V, {B}⟩. The result will be
the two prime theories you wish. The same techniques work for the other
difﬁcult clauses. The canonical prime theory model is indeed a model.
This shows the ubiquity of the pair extension theorem in the metatheory
of distributive substructural logics. Prime theories play the part here of con-
sistent and complete theories in the metatheory of classical intensional log-
ics.
I have said nothing about the treatment of negation. Routley’s innovation
is to understand that negation can be modelled by another operator which
takes us away from the current point of evaluation. The Boolean clause will
not do. The alternative is this:
⋄x ⊩∼A if and only if x∗̸⊩A
where ∗is a map of period two on the set of points in a model. That is, x∗∗= x.
This indeed sufﬁces to make ∼a de Morgan negation on the model. Adding
the following condition
⋄(Contraposition) If Rxyz then Rxz∗y∗
results in the model validating the contraposition axiom.
There has been a great deal of debate centred around the interpretation
of the ∗operator [58, 59, 186].90 There is no doubt that the ∗operation is
not particularly perspicuous in and of itself. (Being told that it turns set-ups
“inside out” is not particularly enlightening.) Instead of pursuing that debate
here (which largely burned out), I will merely quote an insight from Belnap
and Dunn:
... we are convinced of the high probability that a mathemati-
cal apparatus of such proven formal power will eventually ﬁnd its
concrete applications and its resting place in intuition (think of
tensors). [11, page 164]
This, I think, has been borne out in the later development of the Routley–
Meyer semantics, and its applications. But to ﬁnd a plausible interpretation
of ∗, and to understand the semantics more fully, we need to work with it
some more. As it stands so far, the Routley–Meyer construction might seem
ad hoc and ﬁt simply for R and its neighbours. For although you can ring
the changes with some of the rules (commutativity, associativity, contraction)
others seem hopelessly ﬁxed. The models, as they stand, do not seem natural
in the way that Kripke models for modal logic do.
This is merely an appearance. Recent work (dating from the 1990s, and
chieﬂy due to Dunn, on gaggle theory) has shown that ternary frames are
89Fact 10 on 25.
90Not to be confused with the ∗of display logic, which simply means “not” in the metatheory
of structures.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
78
completely natural models for substructural logics in just the same way as
Kripke models interpret normal modal logics [85, 86, 87, 88, 234].
DEFINITION 49 (TERNARY FRAMES) A ternary frame is a set with a ternary re-
lation R on that set. The connectives ∧, ∨, ⊤, ⊥, →, ◦, ←can be deﬁned on a
ternary frame as follows:
⋄x ⊩A ∧B if and only if x ⊩A and x ⊩B
⋄x ⊩A ∨B if and only if x ⊩A or x ⊩B
⋄x ⊩⊥never
⋄x ⊩⊤always
⋄x ⊩A →B if and only if for each y, z where Rxyz, if y ⊩A then z ⊩B.
⋄x ⊩A ←B if and only if for each y, z where Ryxz, if y ⊩A then z ⊩B.
⋄x ⊩A ◦B iff there are y, z where Ryzx, y ⊩A and z ⊩B.
Many structural rules come with a corresponding conditions on R.91
There are no restrictions on R in such an interpretation. It models distributive
lattice operations, together with the triple ⟨→, ◦, ←⟩. A soundness and com-
pleteness result, using standard techniques, works for this frame semantics.
Interpreting R is a tricky business, as we have seen. Probably no non-
circular deﬁnition (one which doesn’t appeal to conditionality) will be pos-
sible. However, some interesting explications of R have been tried in the ap-
plied semantics of relevant logics. One answer which has some cach´et at
present explains R in terms of situation theory. If the points in a model are cir-
cumstances or situations of some kind, then R indicates the degree to which
situations can carry information about other situations. In particular, Rabc
holds just when circumstance a acts as a information channel from b to c.
There is a signiﬁcant growing recent literature on the connections between
traditional situation theory and the semantics of relevant logics [21, 18, 161,
228, 231].
Some conditions (such as the condition for double negation elimination,
which is too complex to discuss here [235]) require talk of a relation of in-
clusion between points in models. This is not surprising, if in the intended
interpretation, points are possibly incomplete (think of models for intuition-
istic logic) then sometimes the relation of extension or inclusion might play a
role.
DEFINITION 50 (INCLUSION) ⊑is an inclusion relation on a ternary frame if
and only if it is reﬂexive, transitive and asymmetric, and in addition
⋄For all x, y, z if Rxyz and x′ ⊑x, y′ ⊑y and z ⊑z′ then Rx′y′z′.92
A model on a ternary frame with an inclusion relation must satisfy the hered-
itary condition on atomic formulas
⋄If x ⊩p and x ⊑x′ then x′ ⊩p
The clause linking ⊑and R sufﬁces to prove the hereditary lemma: complex
formulas involving →, ◦, ←satisfy the hereditary lemma if their constituents
do.
91Some, however, require an inclusion relation ⊑, to be deﬁned below.
92This is quite a defensible condition as it stands, but it’s more general than it needs to be to
prove the hereditary lemma for all formulas [234, Chapter 11].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
79
Inclusion as a relation between points in a model, is usually simple to ex-
plain given an interpretation of these points. If points are situations, then
a ⊑b just when a is a substitution of b. The situation of my bedroom is a
substitution of the situation of my house. An inconsistent circumstance de-
scribed by the ﬁrst chapter of some ﬁction may well be a substitution of an
inconsistent circumstance described by the whole book. Given these explica-
tions of inclusion, the connection between it and R is plausible. As x shrinks
to x′, it connects more pairs of circumstances, as for a given antecedent cir-
cumstance there are more possible consequent circumstances. Given x, as y
shrinks to y′, again, there are more possible consequent circumstances, as
y′ gives us less information to constrain possible consequents. These expli-
cations are probably not reductions of the notion, but they go some way to
explain their appeal and their use.
Another signiﬁcant role in models is played by the distinguished point 0
in Routley–Meyer models. This point plays the part of modelling t,
DEFINITION 51 (TRUTH SET) T is a truth set in a ternary model with inclusion
if and only if.
⋄RTab if and only if a ⊑b.
where “RTab” stands for (∃x)(x ∈T ∧Rxab). A truth set is reduced if it has the
form {x : 0 ⊑x} for some point 0.
A truth set does the job of recording frame consequence. The →formulas true
at every point in T are exactly the entailments witnessed by the entire model.
For some applications (in particular, using frames to prove the admissibility
of disjunctive syllogism [239]) reduced truth sets are desirable. A great deal of
work has gone in to showing the circumstances in which a logic has a seman-
tics with a reduced truth set [255, 220, 227, 230]. On the other hand, in our
intended interpretation, it is by no means obvious.
Most contentious is the interpretation of negation. Some of Dunn’s recent
work, however, has served to take the sting out of ∗[87, 233]. Dunn notes that
∗is a particular case of a more understandable clause for negation:93
DEFINITION 52 (COMPATIBILITY) A compatibility relation C on a frame is an
arbitrary two-place relation. Negation is interpreted using C as follows:
⋄x ⊩∼A if and only if for all y, if xCy then y ̸⊩A.
If the frame uses an inclusion relation, compatibility is related to inclusion as
follows:
⋄If xCy, x′ ⊑x and y′ ⊑y then x′Cy′.
If you think of x and y as compatible just when there are no clashes between
them, then these clauses are defensible. A circumstance warrants ∼A just
when there’s no compatible circumstance in which A holds. So, ∼A’s hold-
ing in a circumstance just when A is ruled out by that circumstance: there
is no compatible circumstance in which A. If circumstances are possibly in-
complete (they might be compatible with more than just themselves) and if
they are possibly inconsistent (not compatible with themselves: it contains
93The expression in terms of compatibility is mine. Dunn uses a relation of incompatibility,
expressed the symbol “⊥”, which is already overloaded here.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
80
an internal contradiction) then we have counterexamples to the paradoxes of
implication from before. We may have x ⊩A ∧∼A (when it is not the case
that xCx) or we may have x ̸⊩A ∨∼A (when x ̸⊩A, but xCy where y ⊩A).
But what of the dreaded ∗? It can be seen to be a special case of C. The
behaviour of C is wrapped up by ∗just if a∗is the unique ⊑-maximum of
the set {x : aCx} of all points compatible with a. If this set has a unique ⊑-
maximum, a∗, then indeed a ⊩∼A just when a∗̸⊩A [233].
So, the ternary frame semantics can be “deconstructed” into individual
components, each of which may be explained and applied in different cir-
cumstances. Here are some other examples of ternary frames which have
been useful in the study of substructural logics.
EXAMPLE 53 (TWO-DIMENSIONAL FRAMES) Given a set D, we can deﬁne a
frame on the set D × D of pairs of D elements, by deﬁning the ternary re-
lation R on D × D, setting R⟨a, b⟩⟨c, d⟩⟨e, f⟩if and only if b = c, e = a and
b = f. In other words, ⟨a, b⟩composes with ⟨b, c⟩to result in ⟨a, c⟩, and no
other relations hold between pairs. So, the evaluation conditions on these
two-dimensional frames reduce as follows:
⋄⟨a, b⟩⊩A ◦B if and only if for some c ∈D, ⟨a, c⟩⊩A and ⟨c, b⟩⊩B.
⋄⟨a, b⟩⊩A →B if and only if for each c ∈D if ⟨b, c⟩⊩A then ⟨a, c⟩⊩B.
⋄⟨a, b⟩⊩B ←A if and only if for each c ∈D if ⟨c, a⟩⊩A then ⟨c, b⟩⊩B.
In this frame, the ternary R reduces to a partial function on pairs. This func-
tion is associative but not symmetric, where deﬁned. The point set is ﬂat —
there is no natural notion of inclusion to be imposed. This frame has a truth
set, but in this case it is not reduced: it is the set {⟨a, a⟩: a ∈D}.
These models are studied by van Benthem, Doˇsen and Orłowska [37, 70,
208] in the context of substructural logics, and they have blossomed into their
own industry, under the suggestive name ‘arrow logics’ [167]. In these logics,
we think of the points ⟨a, b⟩as transitions, or arrows, from a to b.
These are important frames for they are closely related to language frames
in a number of respects — the relation R is functional: if Rxyz and Rxyz ′ then
z = z′. However, in this case the relation is partial. For some x, y there is no z
such that Rxyz.
EXAMPLE 54 (MITCHELL’S IE models) Mitchell’s IE models, are models of lin-
ear logic with distribution of ∧over ∨[199]. In these models, points are
pairs ⟨m, n⟩whose elements are taken from a commutative monoid R of re-
sources. As R is a commutative monoid, there is an operation + on R, such
that m + n = n + m, with an identity 0, such that m + 0 = m = 0 + m. We
evaluate propositions at points as follows: ⟨m, n⟩⊩A ◦B if and only if for
some n1, n2 where n = n1 + n2, ⟨m + n1, n2⟩⊩A and ⟨m + n2, n1⟩⊩B.
⟨m, n⟩⊩∼A if and only if ⟨n, m⟩̸⊩A. ⟨m, n⟩⊩A →B if and only if for each
m1, m2 where m = m1 + m2, if ⟨n + m2, m1⟩⊩A then ⟨m2, n + m1⟩⊩B.
Conjunction, disjunction, ⊤and ⊥are deﬁned in the usual way.
Early antecedents of the frame semantics for substructural logics can be
found in J´onnson and Tarski’s work on the representation of Boolean alge-
bras with operators [141, 142]. This work presents what amounts to a sound-
ness and completeness result for frames of substructural logics (with Boolean
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
81
negation), though it takes a certain amount of hindsight to see it as such. The
papers are written very much from the perspective of algebra and represen-
tation theory.
An extensive study of the properties of ternary frames is given in Routley,
Meyer, Brady and Plumwood’s Relevant Logics and their Rivals [242]. Gab-
bay [105] also gave a ternary relational semantics for implication, indepen-
dently of the tradition of Routley and Meyer. Frames can be viewed from an
algebraic point of view. The class of propositions of the frame is a completely
distributive lattice under intersection and union, and it is equipped with the
appropriate operators, deﬁned by the clauses in the evaluation conditions.
For example, the implication clause gives us
α →β = {x : (∀y, z ∈F)(Rxyz →(y ∈α →z ∈β))}
Similarly, ∼α = {x : (∀y ∈F)(xCy →y ̸∈α)}, and so on. We will call the result-
ing propositional structure ‘Alg(F)’ the algebra of the frame F. Furthermore,
any interpretation ⊩on a frame gives you an evaluation v⊩given by setting
v⊩(A) to be [[A]]. The connections with algebra run even deeper. Our canon-
ical model is constructed out of prime theories in a language. A similar con-
struction can work with the prime ﬁlters of a propositional structure. Dunn’s
work on gaggles [85, 86, 87, 88] generalises the results here to operators with
arbitrary arity. An n-ary operator is modelled with an n + 1-place relation.
Duality theory is the study of the relationship between algebras and their
representations in terms of frames. There is an important strand of recent
work in the semantics of substructural logic exploring duality theory in this
context [129, 130, 132, 247, 274].
Meyer and Mares have important work on the particular case of adding an
S4-type necessity for R [164], and they have shown that disjunctive syllogism
is admissible in this case, using the frame semantics to prove it. Meyer and
Mares have also studied the extensions of these logics with Boolean nega-
tion [163, 185].
Study of the frame conditions corresponding to rules brings forward ques-
tions of canonicity and correspondence. When is the canonical frame for a
logic itself a model of the logic? This is not always the case in modal logics,
and also, not always the case in substructural logics. There has been some
work in attempting to pin down the class of substructural logics for which
canonicity holds [113, 148, 234].
Not all logics have connectives which are amenable to the treatment of
accessibility relations. We will see this when we consider ! from linear logic.
Another case is the counterfactual conditional. These are more aptly mod-
elled by neighbourhood frames. There has been a little work considering how
neighbourhood frames can be used in a substructural setting [5, 104, 162].
3.3.3
Projective Frames, and Undecidability
R is undecidable. Alasdair Urquhart proved this in his ground breaking pa-
pers [269, 270]. The general idea is a straightforward one: encode a known
undecidable problem into the language of R. Meyer showed how to do this
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
82
in the 1960s, by constructing a simple substructural logic, such that deciding
what was a theorem in a that logic would enable you to solve the word prob-
lem for free semigroups [175, 193]. That logic was not particularly natural.
(It was the Lambek calculus together with just enough contraction to enable
you to represent the deducibility problem as a conditional.) The logic was
not particularly like R. The insights that helped decide the issue for R came
from an unexpected quarter — projective geometry. To see why projective
geometry gave the necessary insights, we will ﬁrst consider a simple case, the
undecidability of the system KR. KR is given by adding A ∧∼A →B to R. A KR
frame is one satisfying the following conditions (given by adding the clause
that a = a∗to the conditions for an R frame).94
R0ab iff a = b
Rabc iff Rbac iff Racb (total permutation)
Raaa for each a
R2abcd only if R2acbd
The clauses for the connectives are standard, with the proviso that a ⊩∼A iff
a ̸⊩A, since a = a∗.
Urquhart’s ﬁrst important insight was that KR frames are surprisingly sim-
ilar to projective spaces. A projective space P is a set P of points, and a collec-
tion L of subsets of P called lines, such that any two distinct points are on ex-
actly one line, and any two distinct lines intersect in exactly one point. But we
can deﬁne projective spaces instead through the ternary relation of collinear-
ity. Given a projective space P, its collinearity relation C is a ternary relation
satisfying the condition:
Cabc iff a = b = c, or a, b and c are distinct and they lie on a
common line.
If P is a projective space, then its collinearity relation C satisﬁes the following
conditions,
Caaa for each a. Cabc iff Cbac iff Cacb. C2abcd only if C2acbd.
provided that every line has at least four points (this last requirement is nec-
essary to verify the last condition). Conversely, if we have a set with a ternary
relation C satisfying these conditions, then the space deﬁned with the origi-
nal set as points and the sets lab = {c : Cabc} ∪{a, b} where a ̸= b as lines is a
projective space.
Now the similarity with KR frames becomes obvious. If P is a projective
space, the frame F(P) generated by P is given by adjoining a new point 0,
adding the conditions C0aa, Ca0a, and Caa0, and by taking the extended
relation C to be the accessibility relation of the frame.
Projective spaces have a naturally associated undecidable problem. The
problem arises when considering the linear subspaces of projective spaces.
A subspace of a projective space is a subset which is also a projective space
under its inherited collinearity relation. Given any two linear subspaces X
and Y, the subspace X + Y is the set of all points on lines through points in X
and points in Y.
In KR frames there are propositions which play the role of linear subspaces
in projective spaces. We need a convention to deal with the extra point 0, and
we simply decree that 0 should be in every “subspace.” Then linear subspaces
94My presentation of these results is indebted to many discussions with Pragati Jain [140].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
83
are equivalent to the positive idempotents in a frame. That is, they are the
propositions X which are positive (so 0 ∈X) and idempotent (so X = X ◦X).
Clearly for any formula A and any KR model M, the extension of A, ||A|| in M
is a positive idempotent iff 0 ⊩A ∧(A ↔A ◦A). It is then not too difﬁcult
to show that if A and B are positive idempotents, so are A ◦B and A ∧B, and
that t and ⊤are positive idempotents.
Given a projective space P, the lattice algebra ⟨L, ∩, +⟩of all linear sub-
spaces of the projective space, under intersection and + is a modular geo-
metric lattice. That is, it is a complete lattice, satisfying these conditions:
Modularity a ≥c ⇒(∀b)
 a ∩(b + c) ≤(a ∩b) + c

Geometricity Every lattice element is a join of atoms, and if a is an atom and
X is a set where a ≤ΣX then there’s some ﬁnite Y ⊆X, where a ≤ΣY.
The lattice of linear subspaces of a projective space satisﬁes these conditions,
and that in fact, any modular geometric lattice is isomorphic to the lattice of
linear subspaces of some projective space. Furthermore the lattice of positive
idempotents of any KR frame is also a modular geometric lattice.
The undecidable problem which Urquhart uses to prove the undecidabil-
ity of KR is now simple to state. Hutchinson [138] and Lipshitz [157] proved
that
FACT 55 (MODULAR LATTICE WORD PROBLEM) The word problem for a class
of modular lattices which includes the subspace lattice of an inﬁnite dimen-
sional projective space is undecidable.
Given an inﬁnite dimensional projective space in which every line includes at
least four points P, the logic of the frame (P) is said to be a strong logic. Our
undecidability theorem then goes like this:
FACT 56 (UNDECIDABILITY FOR KR) Any logic between KR and a strong logic
is undecidable.
PROOF Consider a modular lattice problem
If v1 = w1 ... vn = wn then v = w
stated in a language with variables xi (i = 1, 2, . . .) constants 1 and 0, and
the lattice connectives ∩and +. Fix a map into the language of KR by setting
xt
i = pi for variables, 0t = t, 1t = ⊤, (v ∩w)t = vt ∧wt and (v + w)t = vt ◦wt.
The translation of our modular lattice problem is then the KR formula
 B ∧(vt
1 ↔wt
1) ∧· · · ∧(vt
n ↔wt
n) ∧t

→(vt ↔wt)
where the formula B is the conjunction of all formulas pi ∧(pi ↔pi ◦pi) for
each pi appearing in the formulae vt
j or wt
j.
We will show that given a particular inﬁnite dimensional projective space
(with every line containing at least four points) P, then the word problem
is valid in the lattice of linear subspaces of P if and only if its translation is
provable in L, for any logic L intermediate between KR and the logic of the
frame F(P).
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
84
If the translation of the word problem is valid in L, then it holds in the
frame F(P). Consider the word problem. If it were invalid, then there would
be linear subspaces x1, x2, . . . in the space P such that each vi = wi would be
true while v ̸= w. Construct a model on the frame F(P) as follows. Let the
extension of pi be the space xi together with the point 0. It is then simple to
show that 0 ⊩B, as each pi is a positive idempotent. In addition, 0 ⊩t, and
0 ⊩vt
i ↔wt
i, for the extension of each vt
i and wt
i will be the spaces picked
out by vi and wi (both with the obligatory 0 added). However, we would have
0 ̸⊩vt ↔wt, since the extensions of vt and wt were picked out to differ. This
would amount to a counterexample to the translation of the word problem,
which we said was valid. As a result, the word problem is valid in the space P.
The converse reasoning is straightforward. Deciding the logic would give us
a decision for the word problem.
□
Unfortunately, these techniques do not work for systems weaker than KR.
The proof that positive idempotents are modular uses essentially the special
properties of KR. Not every positive idempotent in R is modular. Nonethe-
less, the techniques of the proof can be extended to apply to a much wider
range of systems. You do not need to restrict your attention to modular lat-
tices to construct an undecidable word problem. But to do that, you need to
examine Lipshitz and Hutchinson’s proof more carefully. In the rest of this
section, I will hint at the structure of Urquhart’s undecidability proof for R
and other logics. For detail, the reader is urged to consult Urquhart’s original
paper [270] or my retelling of the proof [234, Chapter 15]
Lipshitz and Hutchinson proved that the word problem for modular lat-
tices was undecidable by embedding into that problem the already known
undecidable word problem for semigroups. It is enough to show that a struc-
ture can deﬁne a free associative binary operation, for then you will have the
tools for representing arbitrary semigroup problems. Urquhart showed that
this could be done without resorting to the full power of a modular lattice.
It sufﬁces to have an 0-structure, and a modular 4-frame deﬁned within
that 0-structure. An 0-structure is a set equipped with the following struc-
ture
⋄It has a semilattice join operator ⊓, deﬁning an order ≤;
⋄It has a commutative and associative binary operator +;
⋄x ≤y ⇒x + z ≤y + z;
⋄0 + x = x;
⋄y ≥0 ⇒x ⊓(x + y) = x;
A 4-frame in a 0-structure is a set {a1, a2, a3, a4} ∪{cij : i ̸= j, i, j = 1, . . . , 4}
such that
⋄The ais are independent. If G, H ⊆{a1, . . . , a4} then (ΣG) ⊓(ΣH) = Σ(G ∩
H) (where Σ∅= 0)
⋄If G ⊆{a1, . . . , a4} then ΣG is modular
⋄ai + ai = ai
⋄cij = cji
⋄ai + aj = ai + cik; cij ⊓aj = 0, if i ̸= j
⋄(ai + ak) ⊓(cij + cjk) = cik for distinct i, j, k
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
85
Given the 4-frame, we can deﬁne a semigroup structure. For each distinct i, j,
we deﬁne the set Lij to be {x : x + aj = ai + aj and x ⊓aj = 0}. Then if b ∈Lij
and d ∈Ljk where i, j, k are distinct, we set b ⊗d = (b + d) ⊓(ai + ak). It
follows (through some manipulation) that b ⊗d ∈Lik. Then, we can deﬁne
a semigroup operation ‘.’ on L12 by:
x.y = (x ⊗c23) ⊗(c31 ⊗y)
It is quite an involved operation to show that this is associative. Further-
more, in certain circumstances, the operation is freely associative. Given a
countably inﬁnite-dimensional vector space V, its lattice of subspaces is a 0-
structure, and it is possible to deﬁne a modular 4-frame in this lattice of sub-
spaces, such that any countable semigroup is isomorphic to a subsemigroup
of L12 under the deﬁned associative operation.
The rest of the work of the undecidability proof involves showing that
this construction can be modelled in a logic. Perhaps surprisingly, it can
all be done in a weak logic like TW[∧, ∨, →, ⊤, ⊥]. We can do without nega-
tion by deﬁning it implicationally as usual: Pick a distinguished propositional
atom f, and by deﬁning −A to be A →f, t to be −f, and A : B to be −(A →
−B). A is a regular proposition iff −−A ↔A is provable. The regular
propositions form an 0-structure, under the assumption of the formula Θ =
{R(t, f, ⊤, ⊥), N(t, f, ⊤, ⊥), −⊤↔⊥}. where R(A) is −−A ↔A, N(A) is (t →
A) →A, and R(A, B, . . .) is R(A) ∧R(B) ∧· · · and similarly for N. So, we can
show that the conditions for an 0-structure hold in the regular propositions,
assuming Θ as a premise. To interpret the 0-structure conditions we model ⊓
by ∧, + by : and 0 by t. To model a 4-frame in the 0-structure, Deﬁne K(A) to
be R(A) ∧(A ∧−A ↔⊥) ∧(A ∨−A ↔⊤) ∧(A : −A ↔−A) ∧(A ↔A : A).
Then we can show the following
K(A), R(B, C), C →A ⇒A ∧(B : C) ↔(A ∧B) : C
Then the conditions for a 4-frame go as follows: Choose distinct atomic for-
mulas A1, . . . , A4 and C12, . . . , C34 to match a1, . . . , a4 and c12, . . . , c34. One
independence axiom is then
(A1 : A2 : A3) ∧(A2 : A3 : A4) ↔(A2 : A3)
and one modularity condition is
K(A1 : A3 : A4)
Let Π be the conjunction of the statements expressing that the propositions
Ai and Cij form a 4-frame in the 0-structure of regular propositions. In any al-
gebra in which Θ∪Π is true, the lattice of regular propositions is a 0-structure,
and the denotations of the propositions Ai and Cij form a 4-frame. Finally,
when coding up a semigroup problem with variables x1, x2, . . . , xm, we will
need formulas doing duty for these variables: We need a condition to pick
out the fact that pi (standing for xi) is in L12. We deﬁne L(p) to be (p : A2 ↔
A1 : A2) ∧(p ∧A2 ↔t). Then the semigroup operation on elements of L12
can be deﬁned in terms of ∧and : and the formulas Ai and Cij. We assume
that done, and we will take it that there is an operation · on formulas which
picks out the operation on L12. Then we have the following:
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
86
FACT 57 (DEDUCIBILITY FROM TW TO KR IS UNDECIDABLE) For any logic be-
tween TW[∧, ∨, →, ⊤, ⊥] and KR, the Hilbert deducibility problem is undecid-
able.
PROOF Take a semigroup problem which is known to be undecidable. It may
be presented in the following way
If v1 = w1 ... vn = wn then v = w
where each term vi, wi is a term in the language of semigroups, constructed
out of the variables x1, x2, . . . , xm for some m. The translation of that problem
into the language of TW[∧, ∨, →, ⊤, ⊥] is the deducibility problem
Θ, Π, L(p1, . . . , pm), vt
1 ↔wt
1, . . . , vt
n ↔wt
n ⇒vt ↔wt
where each the translation ut of each term u is deﬁned recursively by setting
xt
i to be pi, and (u1.u2)t to be ut
1 · ut
2.
For any logic between TW and KR the word problem in semigroups is valid
if and only if its translation is valid in that logic. If the word problem is valid in
the theory of semigroups, its translation must be valid, for given the truth of
Θ and Π and L(p1, . . . , pm), the operator · is provably a semigroup operation
on the propositions in L12 in the algebra of the logic, and the terms vi and
wi satisfy the semigroup conditions. As a result, vt and wt pick out the same
propositions, and we have a proof of vt ↔wt.
Conversely, if the word problem is invalid, then it has an interpretation in
the semigroup S deﬁned on L12 in the lattice of subspaces of an inﬁnite di-
mensional vector space. The lattice of subspaces of this vector space is the
0-structure in our countermodel. Consider the argument for KR. There, the
subspaces were the positive idempotents in the frame. The other proposi-
tions in the frame were arbitrary subsets of points. Something similar can
work here. On the vector space, consider the subsets of points which are
closed under multiplication (that is, if x ∈α, so is kx, where k is taken from
the ﬁeld of the vector space). This is a De Morgan algebra, deﬁning conjunc-
tion and disjunction by means of intersection and union as is usual. Negation
is modelled by set difference. The fusion α ◦β of two sets of points is the set
{x + y : x ∈α and y ∈β}. It is not too difﬁcult to show that this is commu-
tative and associative, and square increasing, when the vector space is in a
ﬁeld of characteristic other than 2, since if x ∈α then x = 1
2x + 1
2x ∈α ◦α.
Then α →β is simply −(α ◦−β). This is an algebraic model for KR, and that
the regular propositions in this model are exactly the subspaces of the vector
space. It follows that our counterexample in the 0-structure is a counterex-
ample in a model of KR to the translation of the word problem. As a result,
the translation is not provable in KR or in any weaker logic.
□
This result applies to systems between TW and KR, and it shows that the de-
ducibility problem is undecidable for any of these systems. In the presence of
the modus ponens axiom A ∧(A →B) ∧t →B, this immediately yields the
undecidability of the theoremhood problem, as the deducibility problem can
be rewritten as a single formula.
 Θ ∧Π ∧L(p1, . . . , pm) ∧(vt
1 ↔wt
1) ∧· · · ∧(vt
n ↔wt
n) ∧t

→(vt ↔wt)
As a result, the theoremhood problem for logics between T and KR is unde-
cidable. In particular, R, E and T are all undecidable.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
87
The restriction to TW is necessary in the theorem. Without the preﬁxing
and sufﬁxing axioms, you cannot show that the lattice of regular propositions
is closed under the ‘fusion-like’ connective ‘ : ’.
Before moving on to our next section, let us mention that these geometric
methods have been useful not only in proving the undecidability of logics,
but also in showing that interpolation fails in R and related logics [273].
3.3.4
Phase Spaces
Not all substructural logics are distributive, and not all point models validate
distribution. In this section, we will look at phase spaces for linear logic as
an example of a frame invalidating distribution. Before launching into the
deﬁnition (due to Girard [117]) I will set the scene with some historical prece-
dents.
An important idea germane to the representation of non-distributive lat-
tices is that of a Dedekind–MacNeille closure [67, 125, 130, 159, 264].
EXAMPLE 58 (DEDEKIND–MACNEILLE FRAMES) Consider a poset with order
⊑. Deﬁne ‘y ⊑α’ for a set α to mean y ⊑x for each x ∈α. Then the closure
Γα of a set α of points can be given as follows:
Γα = {z : ∀y(y ⊑α →y ⊑z)}
Consider the closure operation on the class of all theories of some logic. If α
is a set of theories, then suppose y ⊑α — that is, y ⊑x for each x ∈α. This is
equivalent to saying that y ⊑T α: y is no bigger than the intersection of the
set of the theories in α, which is itself a theory. So, if y ⊑z, then we must have
T α ⊑z too. If x ∈Γα, then anything true in all of α must also be true in x.
So in these frames, to model disjunction we require x ⊩A ∨B if and only if
x ∈Γ([[A]] ∪[[B]]).
Sambin and others have used the notion of a “pretopology” (in our language,
a set with a closure operator) not only as a model of substructural logics but
also as a constructive generalisation of a topological space [131, 244, 245,
246]. Doˇsen [68, 69], Ono and Komori [205], and Ono [206] have also used
given semantics involving a closure operation
This is not the only way to avoid distribution. In a model without a notion
of inclusion, we can get by with a negation to deﬁne a closure operator:
EXAMPLE 59 (GOLDBLATT FRAMES) Consider orthologic: an ortho-negation
combined lattice logic. Here a frame will most likely appeal to a two-place
compatibility relation C to deal with negation. The compatibility relation is
reﬂexive (so A∧∼A ⊢⊥) and symmetric (so A ⊢∼∼A). Robert Goldblatt [122]
showed (in 1974) how to deal with disjunction by considering a simple com-
patibility frame ⟨P, C⟩, where P is a set of points (unordered by any inclusion
relation) and C is a symmetric, reﬂexive compatibility relation on P.95 Con-
junction and negation are modelled in the standard way:
⋄x ⊩A ∧B iff x ⊩A and x ⊩B
95J. L. Bell presents an interesting philosophical analysis of Goldblatt’s semantics, in which

is understood as proximity [24].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
88
⋄x ⊩∼A iff for each y where xCy, y ̸⊩A
However, as it stands, this semantics does not validate ∼∼A ⊢A. To add an ex-
tra condition on C to validate double negation elimination would result in C
being the identity relation and the logic would collapse into classical proposi-
tional logic. Goldblatt’s insight was to instead restrict the evaluation of propo-
sitions on the frame to those propositions for which ∼∼A ⊢A is valid. In the
process, you reject distribution.
Given a set α ⊆P, let α∼= {y : ∀x(x ∈α →∼yCx)}, or equivalently,
{y : ∀x(yCx →x ̸∈α)}. Therefore, for any evaluation, [[A]]∼= [[∼A]]. A set
α ⊆P is said to be C-closed if and only if α = α∼∼. The C-closed sets will
model our propositions. Since C is symmetric, α ⊆α∼∼.
A disjunction is true not only at the points at which either disjunct is true
but also at the closure of that set of points. Here, however, it is C-closure at
work.
⋄x ⊩A ∨B iff x ∈([[A]] ∪[[B]])∼∼
Girard’s phase spaces (1987) are a generalisation of Goldblatt’s compatibility
frames (discovered independently of Goldblatt’s work, despite being 10 years
later).
EXAMPLE 60 (PHASE SPACES) A phase space is a quadruple ⟨P, ·, 1, 0⟩in which
⟨P, ·, 1⟩is a commutative monoid, and in which 0 is a distinguished subset
of P. The elements of P are phases, and 0 is the set of orthogonal phases of
P.96 In a phase space, the binary operator · is used for the ternary relation for
implication. Here, Rxyz if and only if x · y = z. For any subset G ⊆P, the dual
G∼of G is deﬁned as follows:
G∼= {x ∈P : for all y ∈G(x · y ∈0)}
In other words, G∼is the set of all objects which send each element of G (by
the monoid operation) to 0. For any set G of phases, G∼∼is the closure of G.
It is not too hard to verify that this is indeed a closure operation, by showing
the following:
⋄G ⊆G∼∼.
⋄G∼∼∼= G∼.
⋄If G ⊆H then H∼⊆G∼.
⋄G = G∼∼iff G = H∼for some H ⊆P.
The closed sets are called facts. The set of facts can be equipped with a natural
monoid operation, (G · H)∼∼, where G · H is deﬁned in the obvious way as
{x · y : x ∈G and y ∈H}. This operation is residuated by the operation →
deﬁned by setting G →H = {x : ∀y ∈G(xy ∈H)}, which can be shown to
equal (GH∼)∼.
For negation, we deﬁne xCy to hold if and only if x · y ̸∈0. C is symmetric,
given the commutativity composition, and the negation of a fact G is G∼. The
negation of a fact is itself a fact.
It follows that this is a model for linear logic without exponentials. R satis-
ﬁes the conditions for C and B, as composition is associative and commuta-
tive. The set 1 = {1}∼∼is the identity (both left and right) for fusion.
96In the linear logic literature, ‘⊥’ is used instead of ‘0’ for the set of orthogonal phases. We use
⊥for the bottom element of a lattice, so we will use 0 for the set of orthogonal phases.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
89
Phase spaces are a particular kind of closure frame. They are special in a num-
ber of ways. Not only is the closure operation deﬁned by negation, and not
only are the structural rules B and C satisﬁed, but the accessibility relation un-
derlying the frame is functional. Nevertheless, phase spaces are still a faithful
model for linear logic. We have the following theorem.
FACT 61 (SOUNDNESS AND COMPLETENESS IN PHASE SPACES) X ⊢A is prov-
able in linear logic if and only if X ⊢A holds in all phase spaces.
PROOF The soundness result is straightforward as usual. For completeness,
we construct the canonical phase space out of formulas. The operator · on
this frame is fusion. If you wish to think of a ternary relation, think of RABC
iff A = B ◦C. Then for 0, we have {A : 0 ⊢∼A}. The false elements are the
set of all formulae whose negations are provable, as you would expect. This
is the correct choice, as G∼= {A : ∀B ∈G(B ⊢∼A)}, and so, G∼∼= {A : ∀B ∈
G∼(B ⊢∼A)} = {A : ∀B(∀C ∈G where C ⊢∼B)B ⊢∼A}. Verifying the details
is no more difﬁcult in this case than in Urquhart’s operational models for the
conjunction/implication fragment of R.
□
The deﬁnition of a phase space gives us a nice result. It motivates an em-
bedding of the whole of multiplicative additive linear logic into its (→, ∧, t)
fragment. You choose f to be some arbitrary proposition, a translation as fol-
lows (where we set ∼A = A →f).
pt
=
∼∼p
(A ∧B)t
=
∼∼(At ∧Bt)
(A ∨B)t
=
∼(∼At ∧∼Bt)
(A ◦B)t
=
∼(At →∼Bt)
(A →B)t
=
At →Bt
tt
=
∼∼t
FACT 62 (EMBEDDING USING ∧, →AND t) A ⊢B holds in multiplicative, ad-
ditive linear logic in if and only if At ⊢Bt in the (→, ∧, t) fragment.
PROOF
First, if At ⊢Bt is provable then At ⊢Bt is provable in linear logic,
and in particular, it is provable when we choose ∼t for f. In this case, At is
equivalent to A in linear logic, and therefore, A ⊢B is provable.
Conversely, if At ⊢Bt does not hold in the (→, ∧, t) fragment then in the
canonical model (constructed simply out of theories) we have a counterex-
ample to At ⊢Bt. Construct a phase space out of this model. The phases are
the theories in the canonical model. The monoid operation is theory fusion,
and the set 0 is {x : f ∈x}. It is straightforward to check that any set of the
form [[∼∼A]] in the original canonical model is a fact in the phase space we
are constructing. Construct an interpretation of the language of linear logic
by setting [[A]] in the phase space to be [[At]] in the canonical model. As the
deﬁnition of the translation t mimics the evaluation clauses in a phase space,
this is an acceptable phase space evaluation, and it is one which invalidates
A ⊢B, so this consecution fails in linear logic.
□
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
90
Note that this construction works in logics other than linear logic. For exam-
ple, it will work to embed the whole of R without distribution into R[→, ∧, t],
for if the original model satisﬁes W, so will the phase model for R without
distribution.
We will end this section by sketching how to cope with non-normal modal
operators, such as ! and ? of linear logic. The difﬁculty with operators like
these is the way the distribution properties of normal operators fail. We do
not have !A∧!B ⊢!(A∧B). So, we cannot use standard accessibility relations.
However, something is possible.
DEFINITION 63 (TOPOLINEAR SPACES) A phase space with a set F of facts sat-
isfying the following conditions:
⋄If X ⊆F then T X ∈F.
⋄If F, G ∈F then F + G ∈F.
⋄If F ∈F then F + F = F.
⋄T F = 0.
is called a topolinear space. G is a closed fact iff G ∈F, and G is a open fact iff
G∼∈F.
Now, given any fact G, the consideration of G, ?G, is
?G =
\
{F : G ⊆F and F ∈F}
It is simply the smallest element of F containing G. Its dual, the afﬁrmation
of G, !G is
!G = (
[
{H : H ⊆G and H∼∈F})∼∼
These are duals, as you can readily check.
LEMMA 64 (DUALITY OF ! AND ?) For any fact G, !(G∼) = (?G)∼, and dually,
?(G∼) = (!G)∼.
□
This deﬁnition gives us a semantics for the exponentials. The semantics does
as we would expect: by construction G ⊆?G, for any fact G, so by duality,
!G ⊆G. Furthermore, ?G is itself a closed fact, so ?G = ??G, and dually, !G =
!!G. Similarly, all of the closed facts are ﬁxed points for ﬁssion, ?G + ?G = ?G,
and by duality, !G ◦!G = !G. Finally, 0 ⊆?G by construction, so by duality
!G ⊆t, and by the behaviour of t, G ◦t = t gives F ◦!G ⊆F.
Each of these simple veriﬁcations shows that the construction of ! and ?
satisﬁes the rules for the exponentials in linear logic. This gives us the ﬁrst
part of the following fact.
FACT 65 (SOUNDNESS AND COMPLETENESS IN TOPOLINEAR SPACES) X ⊢A is
provable in LL if and only if X ⊢A holds in all topolinear spaces.
PROOF
As we have seen, the rules for the exponentials hold in topolinear
spaces. For the converse, we must verify that the canonical topolinear space
satisﬁes the conditions required for a topolinear space. So how should we
construct the canonical topolinear space?
We will use the canonical phase space we have seen to construct a set of
closed facts. Obviously, each {A : ?B ⊢A} ought to be a closed fact for any
choice of B. This cannot be the whole thing, as the intersection of a class
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
91
of closed facts is not necessarily a set of the form {A : ?B ⊢A}. So we add
these intersections. For any class of formulae Bi, we will let T
i{A : ?Bi ⊢A}
be a closed fact. Once we do this, it is straightforward to check that ?[[A]] =
T{F : [[A]] ⊆F and F ∈F} for any formula A in the canonical model structure.
The duality of ? and !, together with the duality of their deﬁning conditions,
ensures that the result for ! holds too.
□
This kind of closure operation works well to model the exponentials in phase
spaces.
4
Loose Ends
Let me end this whirlwind tour through the history of substructural logic by
indicating what I take to be some interesting directions for further research.
4.1
Paradox
Untutored intuitions about collections might lead you to believe that for any
property, there is a collection of all and only those things which have that
property. Formally, you might try this:
a ∈{x : φ(x)} ⊣⊢φ(a)
A object a is in the collection {x : φ(x)} of all of the φs if and only if a has
property φ. This is the na¨ıve membership scheme. Russell has shown that
from na¨ıve membership scheme, paradox follows. Consider the Russell set
{x : x ̸∈x}. As an instance of the general scheme of membership, we have
Russell’s paradox:
{x : x ̸∈x} ∈{x : x ̸∈x} ↔{x : x ̸∈x} ̸∈{x : x ̸∈x}
The Russell set is a member of itself if and only if it is not a member of itself.
In many traditional logics (classical or intuitionistic propositional logic, for
example) from p ↔∼p ⊢p ∧∼p, and from this, anything at all.
The mainstream response to Russell’s paradox is to calm our enthusiasm
for the na¨ive membership scheme and to hunt around for weaker theories of
set membership which are not so extravagant.97
However, this is not the only possibility. There is a motivation to consider
logics in which we can retain the na¨ıve membership scheme. Clearly, some-
thing must be done with the logic of negation, as we wish to retain propo-
sitions p such that p ↔∼p, without everything following from this. There
are generally two options, logics with “gaps” or “gluts,” corresponding to the
point in the inference from p ↔∼p to p∧∼p to ⊥which is taken to fail. A logic
allows “gaps” if it the ﬁrst inference fails, for p would then be “neither true nor
false.” A logic allows “gluts” if the second inference fails. Plenty of work has
been done on both options for a number of years [115, 116, 216, 226]
However, it is not just the logic of negation which must be non-classical
in order to retain the na¨ıve membership scheme. Curry’s paradox [108, 194].
97There is some interesting work in this area, attempting to admit sets which are self-
membered, without paradox [3, 20].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
92
Curry’s paradox shows that more must be done, if the logic is to contain im-
plication. Consider {x : x ∈x →F}, for some false proposition F.
{x : x ∈x →F} ∈{x : x ∈x →F} ↔({x : x ∈x →F} ∈{x : x ∈x →F} →F)
This paradox reveals that there is a proposition p such that p ↔(p →F), and
as the following deduction shows, it is hard to avoid the inference to F:
p ⊢p →F
p ⊢p


 
p; p ⊢F
[WI]
p ⊢F




0 ⊢p →F
p →F ⊢p
[Cut]
⊢p
p ⊢p →F
p ⊢p


 
p; p ⊢F
[WI]
p ⊢F
[Cut]
⊢F
As the choice of F is arbitrary, we must attempt to stop this somewhere. A
number of people have taken the step of contraction as the one to blame [44,
49, 46, 51, 287]. However, contraction is a useful inferential move. It is re-
quired in mathematical induction. The step to, say, F5 from F0 ∧(∀x)(Fx →
Fx + 1) requires the use of the premise no less than six times. Doing without
contraction seems a little like cutting off one’s nose to spite one’s face. Can
better be done here?
4.2
Relevant Predication
Dunn’s Relevant Predication program is an interesting application of relevant
logic to the clariﬁcation of philosophical issues [82, 83, 84, 90, 89, 146]. A
theory of relevant implication is used to attempt to mark out the distinction
between genuine properties — say, my height, which is a genuine property of
me — and fake properties — say, my height, as a fake property of you. I am
indeed such that I am under 1.8 metres tall, and you are such that I am under
1.8 metres tall. But in the ﬁrst case I have described how I am, and in the
second, I haven’t described any genuine property of you.
Classical logic is not good at marking out such a distinction, for if Hx
stands for ‘x is under 1.8 metres tall’, and g stands for Greg, and h stands for
you, then Hx is true of x iff it is under 1.8 metres tall, and (Hg ∧x = x) ∨Hg
is true of something iff I am under 1.8 metres tall. Why is one a ‘real’ property
and the other not? If we can reason using relevant implication, we can make
the following distinction: It is true that if x is Greg then x is under 1.8 metres.
However, it is not true that if x is you then Greg is under 1.8 metres. At least,
it is plausible that this conditional fail, when read as a relevant conditional.
This can be cashed out as follows.
DEFINITION 66 (RELEVANT PREDICATION) F is a relevant property of a (writ-
ten (ρxFx)a) if and only if (∀x)(x = a →Fx).
If F is a relevant property of a then Fa holds (quite clearly) and if F and G are
relevant properties of a then so is their conjunction, and the disjunction of
any relevant property with anything at all is still a relevant property.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
93
Relevant logics excel at telling you what follows from what as a matter of
logic — this gives us an interesting picture of the logical structure of relevant
predication. However, that is only half the story. Applying the semantics of
relevant logics ought to give us insight into what it is to that a relevant impli-
cation is true. That task is as yet, undone.
4.2.1
Monism and Pluralism
One debate in philosophical logic has been inspired by work in relevance
and substructural logic, and we have already seen a hint of it in the discus-
sion of disjunctive syllogism in Section 2.4. This is a debate between plural-
ists [22, 23] and monists [218, 225] with respect to logical consequence. Is
there one relation of deductive logical consequence (relative, say, to a partic-
ular choice of language, if this is a concern), or are there more than one? To
make the discussion particular, given a particular instance of the inference of
disjunctive syllogism
A ∨B, ∼A ⊢? B
should the reasoner accept the inference as valid, reject it as invalid, or is
there more to be said? In an interpretation which gives a counterexample to
this inference, we may have a “point” x such that x ⊩A, x ⊩∼A and x ̸⊩B.
What are we to say about this?
Monists will say that if the choice of interpretations is correct, then this
provides a counterexample to the inference. If the choice of interpretations is
not a good one (if the interpretations are a model of a logic but not of the One
True Logic) then the argument may well still be valid. For example, Priest [218]
argues that for an argument to be valid, it must be that in every circumstance
in which the premises are true so is the conclusion, and the One True Logic
is one which is sound and complete for the intended interpretation on the
actual class of circumstances. Any logical consequence relation other than
this either undergenerates by adding extra circumstances (which are alleged
counterexamples to really valid arguments) or overgenerates by missing some
out (which are counterexamples to invalid arguments missed out by the logic
which is too strong).
Pluralists about logical consequence, on the other hand will say that a
logic (and its attendant interpretations) may give us some information about
the inference, but that this may not be the whole story about its validity or
otherwise. For example, a pluralist may agree that there are indeed circum-
stances in which the premises of a disjunctive syllogism are true and the con-
clusion untrue. However, this choice of circumstances may include special
circumstances not always considered: it includes impossible circumstances,
as one would expect, if we are taking relevance seriously. It is natural too, to
only consider possible circumstances, and if these are the only circumstances
to consider, then disjunctive syllogism ought be considered valid in this new,
restricted sense. It is a lesson of relevant logic and its semantics that these are
choices which can be made. For a monist, there is one deﬁnitive best answer
to this choice. For a pluralist, both sides may have competing merits.
Pluralism extends beyond our interpretation of the semantics into our
interpretation of proof theory too. Substructural logics have shown us that
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
94
there is remarkable robustness in the interpretation of a conditional by means
of the residuation clause:
X, A ⊢B
=========
X ⊢A →B
However, the introduction and elimination rules for a conditional laid down
by this clause, does not determine the meaning of the conditional.98 These
rules only pick out a ﬁxed interpretation in combination with some account
of the behaviour of the structural feature of the comma.
At the very least, relevant and substructural logics have provided so many
new tools for understanding logical consequence that they have put the issue
of pluralism on the agenda. Clarifying these options will deepen our under-
standing of logical consequence.
References
[1] SAMSON ABRAMSKY AND ACHIM JUNG. “Domain Theory”. In SAMSON ABRAMSKY, DOV M.
GABBAY, AND T. S. E. MAIBAUM, editors, Handbook of Logic in Computer Science,
volume 3, pages 1–168. Clarendon Press, Oxford, 1994.
[2] WILHELM ACKERMANN. “Begr¨undung Einer Strengen implikation”. Journal of Symbolic
Logic, 21:113–128, 1956.
[3] PETER ACZEL. Non-Well-Founded Sets. Number 14 in CSLI Lecture Notes. CSLI
Publications, Stanford, 1988.
[4] K. AJDUKIEWICZ. “Die Syntaktische Konnexit¨at”. Studia Philosophica, 1:1–27, 1935.
[5] SEIKI AKAMA. “Relevant Counterfactuals and Paraconsistency”. In Proceedings of the First
World Conference on Paraconsistency, Gent, Belgium., 1997.
[6] A. R. ANDERSON AND N. D. BELNAP JR. “Modalities in Ackermann’s ‘Rigorous
Implication”’. Journal of Symbolic Logic, 24:107–111, 1959.
[7] A. R. ANDERSON AND N. D. BELNAP JR. “Enthymemes”. Journal of Philosophy,
58:713–723, 1961.
[8] A. R. ANDERSON AND N. D. BELNAP JR. “The Pure Calculus of Entailment”. Journal of
Symbolic Logic, 27:19–52, 1962.
[9] A. R. ANDERSON AND N. D. BELNAP JR. “Tautological Entailments”. Philosophical Studies,
13:9–24, 1962.
[10] ALAN ROSS ANDERSON AND NUEL D. BELNAP. Entailment: The Logic of Relevance and
Necessity, volume 1. Princeton University Press, Princeton, 1975.
[11] ALAN ROSS ANDERSON, NUEL D. BELNAP, AND J. MICHAEL DUNN. Entailment: The Logic
of Relevance and Necessity, volume 2. Princeton University Press, Princeton, 1992.
[12] HAJNAL ANDR´EKA, STEVEN GIVANT, AND ISTV´AN N´EMETI. “Decision Problems for
Equational Theories of Relation Algebras”. Memoirs of the American Mathematical
Society, 126(604), 1997.
[13] ARNON AVRON. “On Purely Relevant Logics”. Notre Dame Journal of Formal Logic,
27:180–194, 1986.
[14] ARNON AVRON. “Whither Relevance Logic?”. Journal of Philosophical Logic, 21:243–281,
1992.
[15] Y. BAR-HILLEL. “A Quasiarithmetical Notation for Syntactic Description”. Language,
28:47–58, 1953.
[16] H. P. BARENDREGT, M. COPPO, AND M. DEZANI-CIANCAGLINI. “A Filter Lambda Model
and the Completeness of Type Assignment”. Journal of Symbolic Logic, 48:931–940, 1983.
[17] MICHAEL BARR AND CHARLES WELLS. Category Theory for Computing Science.
Prentice-Hall, 1990.
[18] J. BARWISE, D. GABBAY, AND C. HARTONAS. “Information Flow and the Lambek Calculus”.
In J. SELIGMAN AND D. WESTERSTAHL, editors, Logic, Language and Computation, Proc.
98Despite the overwhelming literature on introduction and elimination rules determining the
meanings of logical connectives [50, 74, 127].
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
95
Information-Oriented Approaches to Logic, Language and Computation, volume 58, pages
47–62. CSLI Lecture Notes, 1996.
[19] JON BARWISE AND JOHN ETCHEMENDY. Language, Proof and Logic. Seven Bridges Press,
2000.
[20] JON BARWISE AND LARRY MOSS. Vicious Circles. CSLI Publications, 1997.
[21] JON BARWISE AND JERRY SELIGMAN. “Imperfect Information Flow”. Proceedings of the 8th
Annual IEEE Symposium on Logic in Computer Science, 1993.
[22] JC BEALL AND GREG RESTALL. “Logical Pluralism”. Australasian Journal of Philosophy,
78:475–493, 2000.
[23] JC BEALL AND GREG RESTALL. “Defending Logical Pluralism”. In B. BROWN AND
J. WOODS, editors, Logical Consequences. Kluwer Academic Publishers, to appear.
[24] J. L. BELL. “A New Approach to Quantum Logic”. British Journal for the Philosophy of
Science, 37:83–99, 1986.
[25] J. L. BELL AND A. B. SLOMSON. Models and Ultraproducts: An Introduction. North
Holland, 1969.
[26] G. BELLIN. “Proof Nets for Multiplicative and Additive Linear Logic”. Technical Report,
Department of Computer Science, Edinburgh University, 1991. ECS-LFCS 91-161.
[27] NUEL D. BELNAP. “Special Cases of the Decision Problem of Relevant Implication”.
Journal of Symbolic Logic, 32:431–432, 1967. (Abstract.).
[28] NUEL D. BELNAP. “How a Computer Should Think”. In G. RYLE, editor, Contemporary
Aspects of Philosophy. Oriel Press, 1977.
[29] NUEL D. BELNAP. “A Useful Four-Valued Logic”. In J. MICHAEL DUNN AND GEORGE
EPSTEIN, editors, Modern Uses of Multiple-Valued Logics, pages 8–37. Reidel, Dordrecht,
1977.
[30] NUEL D. BELNAP. “Display Logic”. Journal of Philosophical Logic, 11:357–417, 1982.
[31] NUEL D. BELNAP. “Linear Logic Displayed”. Notre Dame Journal of Formal Logic,
31:15–25, 1990.
[32] NUEL D. BELNAP. “Life in the Undistributed Middle”. In PETER SCHROEDER-HEISTER AND
KOSTA DOˇSEN, editors, Substructural Logics, pages 31–41. Oxford University Press, 1993.
[33] NUEL D. BELNAP AND J. MICHAEL DUNN. “Entailment and the Disjunctive Syllogism”. In
F. FLØISTAD AND G. H. VON WRIGHT, editors, Philosophy of Language / Philosophical
Logic, pages 337–366. Martinus Nijhoff, The Hague, 1981. Reprinted as Section 80 in
Entailment Volume 2, [11].
[34] N. D. BELNAP JR., A. GUPTA, AND J. MICHAEL DUNN. “A consecution calculus for positive
relevant implication with necessity”. Journal of Philosophical Logic, 9:343–362, 1980.
[35] N. D. BELNAP JR. AND J. R. WALLACE. “A Decision Procedure for the System
   of
Entailment With Negation”. Technical Report 11, Contract No. SAR/609 (16), Ofﬁce of
Naval Research, New Haven, 1961. Also published as [36].
[36] N. D. BELNAP JR. AND J. R. WALLACE. “A Decision Procedure for the System
   of
Entailment With Negation”. Zeitschrift f¨ur Mathematische Logik und Grundlagen der
Mathematik, 11:261–277, 1965.
[37] JOHAN VAN BENTHEM. Language in Action: Categories, Lambdas and Dynamic Logic.
North Holland, 1991.
[38] NICK BENTON, G. M. BIERMAN, J. MARTIN E. HYLAND, AND VALERIA DE PAIVA. “Linear
  -Calculus and Categorical Models Revisited”. In E. B ¨ORGER, editor, Proceedings of the
Sixth Workshop on Computer Science Logic, volume 702 of Lecture Notes in Computer
Science, pages 61–84. Springer-Verlag, 1992.
[39] NICK BENTON, G. M. BIERMAN, J. MARTIN E. HYLAND, AND VALERIA DE PAIVA. “Term
Assignment for Intuitionistic Linear Logic”. Technical Report 262, Computer Laboratory,
University of Cambridge, August 1992.
[40] NICK BENTON, G. M. BIERMAN, J. MARTIN E. HYLAND, AND VALERIA DE PAIVA. “A Term
Calculus for Intuitionistic Linear Logic”. In M. BEZEM AND J. F. GROOTE, editors,
Proceedings of the International Conference on Typed Lambda Calculi and Applications,
volume 664 of Lecture Notes in Computer Science, pages 75–90. Springer-Verlag, 1993.
[41] KATALIN BIMB ´O. “Semantics for Structurally Free Logics


  ”. Logic Journal of the IGPL,
9(4):557–571, 2001.
[42] KATALIN BIMB ´O AND J. MICHAEL DUNN. “Two Extensions of the Structurally Free Logic
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
96

 ”. Logic Journal of the IGPL, 6(3):493–424, 1998.
[43] RICHARD BLUTE, J. R. B. COCKETT, R. A. G. SEELY, AND T. H. TRIMBLE. “Natural
Deduction and Coherence for Weakly Distributive Categories”. Journal of Pure and
Applied Algebra, 13(3):229–296, 1996. Available from
ftp://triples.math.mcgill.ca/pub/rags/nets/nets.ps.gz.
[44] ROSS T. BRADY. “The Simple Consistency of a Set Theory Based on the Logic CSQ”. Notre
Dame Journal of Formal Logic, 24:431–449, 1983.
[45] ROSS T. BRADY. “A Content Semantics for Quantiﬁed Relevant Logics I”. Studia Logica,
47:111–127, 1988.
[46] ROSS T. BRADY. “The Non-Triviality of Dialectical Set Theory”. In GRAHAM PRIEST,
RICHARD ROUTLEY, AND JEAN NORMAN, editors, Paraconsistent Logic: Essays on the
Inconsistent, pages 437–470. Philosophia Verlag, 1989.
[47] ROSS T. BRADY. “Gentzenization and Decidability of some Contraction-Less Relevant
Logics”. Journal of Philosophical Logic, 20:97–117, 1991.
[48] ROSS T. BRADY. “Relevant Implication and the Case for a Weaker Logic”. Journal of
Philosophical Logic, 25:151–183, 1996.
[49] ROSS T. BRADY AND RICHARD ROUTLEY. “The Non-Triviality of Extensional Dialectical Set
Theory”. In GRAHAM PRIEST, RICHARD ROUTLEY, AND JEAN NORMAN, editors,
Paraconsistent Logic: Essays on the Inconsistent, pages 415–436. Philosophia Verlag, 1989.
[50] ROBERT B. BRANDOM. Making It Explicit. Harvard University Press, 1994.
[51] MARTIN BUNDER. “BCK-Predicate Logic as a Foundation of Multiset Theory”. Technical
Report, Mathematics Department, University of Wollongong, 1985.
[52] G. W. CHARLEWOOD. Representations of Semilattice Relevance Logic. PhD thesis,
University of Toronto, 1978.
[53] G. W. CHARLEWOOD. “An axiomatic version of positive semi-lattice relevance logic”.
Journal of Symbolic Logic, 46:233–239, 1981.
[54] ALONZO CHURCH. The Calculi of Lambda-Conversion. Number 6 in Annals of
Mathematical Studies. Princeton University Press, 1941.
[55] ALONZO CHURCH. “The Weak Positive Implication Calculus”. Journal of Symbolic Logic,
16:238, 1951. Abstract of “The Weak Theory of Implication” [56].
[56] ALONZO CHURCH. “The Weak Theory of Implication”. In A. MENNE, A. WILHELMY, AND
H. ANGSIL, editors, Kontroliertes Denken: Untersuchungen zum Logikkalk¨ul und zur
Logik der Einzelwissenschaften, pages 22–37. Kommissions-Verlag Karl Alber, Munich,
1951. Abstracted in “The Weak Positive Implication Calculus” [55].
[57] J. R. B. COCKETT AND R. A. G. SEELY. “Proof Theory for full intuitionistic linear logic,
bilinear logic, and MIX categories”. Theory and Applications of categories, 3(5):85–131,
1997. Available from ftp://triples.math.mcgill.ca/pub/rags/nets/fill.ps.gz.
[58] B. J. COPELAND. “On When a Semantics is not a Semantics: some reasons for disliking the
Routley-Meyer semantics for relevance logic”. Journal of Philosophical Logic, 8:399–413,
1979.
[59] B. J. COPELAND. “What is a Semantics for Classical Negation?”. Mind, 95:478–480, 1986.
[60] M. COPPO, M. DEZANI-CIANCAGLINI, AND B. VENNERI. “Functional Characters of
Solvable Terms”. Zeitschrift f¨ur Mathematische Logik und Grundlagen der Mathematik,
27:45–58, 1981.
[61] HASKELL B. CURRY. A Theory of Formal Deducibility, volume 6 of Notre Dame
Mathematical Lectures. Notre Dame University Press, 1950.
[62] HASKELL B. CURRY AND R. FEYS. Combinatory Logic, volume 1. North Holland, 1958.
[63] HASKELL B. CURRY, J. ROGER HINDLEY, AND JONATHAN P. SELDIN. Combinatory Logic,
volume 2. North Holland, 1972.
[64] VINCENT DANOS. La Logique Lin´eaire Appliqu´ee `a l’´etude de divers processus de
normalisation (et principalement du
  -calcul). PhD thesis, Universit´e de Paris VII, 1990.
[65] VINCENT DANOS, JEAN-BAPTISTE JOINET, AND HAROLD SCHELLINX. “On the Linear
Decoration of Intuitionistic Derivations”. Archive of Mathematical Logic, 33:387–412,
1995.
[66] VINCENT DANOS AND LAURENT REGINER. “The Structures of Multiplicatives”. AoML,
28:181–203, 1986.
[67] B. A. DAVEY AND H. A. PRIESTLEY. Introduction to Lattices and Order. Cambridge
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
97
University Press, Cambridge, 1990.
[68] KOSTA DOˇSEN. “Sequent Systems and Groupoid Models, Part 1”. Studia Logica,
47:353–386, 1988.
[69] KOSTA DOˇSEN. “Sequent Systems and Groupoid Models, Part 2”. Studia Logica, 48:41–65,
1989.
[70] KOSTA DOˇSEN. “A Brief Survey of Frames for the Lambek Calculus”. Zeitschrift f¨ur
Mathematische Logik und Grundlagen der Mathematik, 38:179–187, 1992.
[71] KOSTA DOˇSEN. “The First Axiomatisation of Relevant Logic”. Journal of Philosophical
Logic, 21:339–356, 1992.
[72] KOSTA DOˇSEN. “Deductive Completeness”. Bulletin of Symbolic Logic, 2:243–283, 1996.
[73] ALBERT GRIGOREVICH DRAGALIN. Mathematical Intuitionism: Introduction to Proof
Theory, volume 67 of Translations of Mathematical Monographs. American Mathematical
Society, 1987.
[74] MICHAEL DUMMETT. The Logical Basis of Metaphysics. Harvard University Press, 1991.
[75] J. MICHAEL DUNN. The Algebra of Intensional Logics. PhD thesis, University of Pittsburgh,
1966.
[76] J. MICHAEL DUNN. “Algebraic Completeness for
 -mingle and its Extensions”. Journal of
Symbolic Logic, 35:1–13, 1970.
[77] J. MICHAEL DUNN. “An Intuitive Semantics for First Degree Relevant Implications
(abstract)”. Journal of Symbolic Logic, 36:363–363, 1971.
[78] J. MICHAEL DUNN. “A ‘Gentzen’ System for Positive Relevant Implication”. Journal of
Symbolic Logic, 38:356–357, 1974. (Abstract).
[79] J. MICHAEL DUNN. “Intuitive Semantics for First-Degree Entailments and “Coupled
Trees””. Philosophical Studies, 29:149–168, 1976.
[80] J. MICHAEL DUNN. “A Variation on the Binary Semantics for RM”. Relevance Logic
Newsletter, 1:56–67, 1976.
[81] J. MICHAEL DUNN. “Relevance Logic and Entailment”. In DOV M. GABBAY AND FRANZ
G ¨UNTHNER, editors, Handbook of Philosophical Logic, volume 3, pages 117–229. Reidel,
Dordrecht, 1986.
[82] J. MICHAEL DUNN. “Relevant Predication 1: The Formal Theory”. Journal of Philosophical
Logic, 16:347–381, 1987.
[83] J. MICHAEL DUNN. “Relevant Predication 2: Intrinsic Properties and Internal Relations”.
Philosophical Studies, 60:177–206, 1990.
[84] J. MICHAEL DUNN. “Relevant Predication 3: Essential Properties”. In J. MICHAEL DUNN
AND ANIL GUPTA, editors, Truth or Consequences, pages 77–95. Kluwer, 1990.
[85] J. MICHAEL DUNN. “Gaggle Theory: An Abstraction of Galois Connections and
Residuation with Applications to Negation and Various Logical Operations”. In Logics in
AI, Proceedings European Workshop JELIA 1990, volume 478 of Lecture Notes in Computer
Science. Springer-Verlag, 1991.
[86] J. MICHAEL DUNN. “Partial-Gaggles Applied to Logics with Restricted Structural Rules”. In
PETER SCHROEDER-HEISTER AND KOSTA DOˇSEN, editors, Substructural Logics. Oxford
University Press, 1993.
[87] J. MICHAEL DUNN. “Star and Perp: Two Treatments of Negation”. In JAMES E. TOMBERLIN,
editor, Philosophical Perspectives, volume 7, pages 331–357. Ridgeview Publishing
Company, Atascadero, California, 1994.
[88] J. MICHAEL DUNN. “Positive Modal Logic”. Studia Logica, 55:301–317, 1995.
[89] J. MICHAEL DUNN. “Is Existence a (Relevant) Predicate?”. Philosophical Topics, 24:1–34,
1996.
[90] J. MICHAEL DUNN. “Relevant Predication: A Logical Framework for Natural Properties”.
In J. EARMAN AND J. D. NORTON, editors, The Cosmos of Science, Pittsburgh–Konstanz
Series in the Philosophy and History of Science. University of Pittsburgh Press and
Universitaets Verlug Konstanz, 1996.
[91] J. MICHAEL DUNN AND G. EPSTEIN. Modern Uses of Multiple-Valued Logic. Reidel,
Dordrecht, 1977.
[92] J. MICHAEL DUNN AND ROBERT K. MEYER. “Gentzen’s Cut and Ackermann’s
  ”. In
RICHARD SYLVAN AND JEAN NORMAN, editors, Directions in Relevant Logic. Kluwer,
Dordrecht, 1989.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
98
[93] J. MICHAEL DUNN AND ROBERT K. MEYER. “Combinators and Structurally Free Logic”.
Logic Journal of the IGPL, 5:505–357, 1997.
[94] J. MICHAEL DUNN AND GREG RESTALL. “Relevance Logic”. In DOV M. GABBAY, editor,
Handbook of Philosophical Logic, volume ??, page ?? Kluwer Academic Publishers, second
edition, 200? to appear.
[95] THOMAS EHRHARD. “Hypercoherences: a strongly stable model of linear logic”.
Mathematical Structures in Computer Science, 3:365–385, 1993.
[96] DAVID FINBERG, MATTEO MAINETTI, AND GIAN-CARLO ROTA. “The Logic of Commuting
Equivalence Relations”. In Logic and Algebra (Pontignan, 1994), volume 180 of Lecture
Notes in Pure and Applied Mathematics, pages 69–96. Dekker, 1996.
[97] KIT FINE. “Models for Entailment”. Journal of Philosophical Logic, 3:347–372, 1974.
[98] KIT FINE. “Completeness for the Semilattice Semantics with Disjunction and
Conjunction”. Journal of Symbolic Logic, 41:560, 1976.
[99] KIT FINE. “Semantics for Quantiﬁed Relevance Logic”. Journal of Philosophical Logic,
17:27–59, 1988.
[100] F. B. FITCH. Symbolic Logic. Roland Press, New York, 1952.
[101] MELVIN C. FITTING. “Bilattices and the Semantics of Logic Programming”. Journal of
Logic Programming, 11(2):91–116, 1989.
[102] GOTTLOB FREGE. Grundgesetze der Arithmetik, Begriffsschriftlich abgeleitet. Verlag
Hermann Pohle, Jena, 1893–1903. Parts translated in Gottlob Frege: Logical
Investigations [110].
[103] HARVEY FRIEDMAN AND ROBERT K. MEYER. “Whither Relevant Arithmetic?”. Journal of
Symbolic Logic, 57:824–831, 1992.
[104] ANDR´E FUHRMANN AND EDWIN D. MARES. “On S”. Studia Logica, 53:75–91, 1994.
[105] D. M. GABBAY. “A General Theory of the Conditional in Terms of a Ternary Operator”.
Theoria, 38:39–50, 1972.
[106] D. M. GABBAY. Investigations in Modal and Tense Logics with Applications to Problems in
Philosophy and Linguistics. Reidel, Dordrecht, 1976.
[107] D. GALMICHE. “Connection methods in Linear Logic and Proof Nets Construction”.
Theoretical Computer Science, 232:231–272, 2000.
[108] P. T. GEACH. “On Insolubilia”. Analysis, 15:71–72, 1955.
[109] P. T. GEACH. “Entailment”. Aristotelian Society supplementary volume, 32:157–172, 1958.
[110] PETER GEACH AND MAX BLACK. Translations from the Philosophical Writings of Gottlob
Frege. Oxford University Press, 1952.
[111] GERHARD GENTZEN. “Untersuchungen ¨uber das logische Schliessen”. Math. Zeitschrift,
39:176–210 and 405–431, 1934. Translated in The Collected Papers of Gerhard
Gentzen [112].
[112] GERHARD GENTZEN. The Collected Papers of Gerhard Gentzen. North Holland, 1969.
Edited by M. E. Szabo.
[113] SILVIO GHILARDI AND GIANCARLO MELONI. “Constructive Canonicity in Non-Classical
Logic”. Annals of Pure and Applied Logic, 86:1–32, 1997.
[114] STEVE GIAMBRONE. “
 

and



are Decidable”. Journal of Philosophical Logic,
14:235–254, 1985.
[115] PAUL C. GILMORE. “The Consistency of partial Set Theory without Extensionality”. In
Axiomatic Set Theory, volume 13 of Proceedings of Symposia in Pure Mathematics, pages
147–153, Providence, Rhode Island, 1974. American Mathematical Society.
[116] PAUL C. GILMORE. “Natural Deduction Based Set Theories: A New Resolution of the Old
Paradoxes”. Journal of Symbolic Logic, 51:393–411, 1986.
[117] JEAN-YVES GIRARD. “Linear Logic”. Theoretical Computer Science, 50:1–101, 1987.
[118] JEAN-YVES GIRARD. Proof Theory and Logical Complexity. Bibliopolis, Naples, 1987.
[119] JEAN-YVES GIRARD. “Geometry of Interaction III: accomodating the additives”. In J. Y.
GIRARD, Y. LAFONT, AND L. REGINER, editors, Advances in Linear Logic, pages 1–42.
Cambridge University Press, Cambridge, 1995.
[120] JEAN-YVES GIRARD. “Coherent Banach Spaces: a continuous denotational semantics”.
Electronic Notes in Theoretical Computer Science, 3, 1996. Extended abstract, available
from http://www.elsevier.nl/locate/entcs/volume3.html.
[121] JEAN-YVES GIRARD, YVES LAFONT, AND PAUL TAYLOR. Proofs and Types, volume 7 of
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
99
Cambridge Tracts in Theoretical Computer Science. Cambridge University Press, 1989.
[122] ROBERT GOLDBLATT. “Semantic Analysis of Orthologic”. Journal of Philosophical Logic,
3:19–35, 1974. Reprinted as Chapter 3 of Mathematics of Modality [123].
[123] ROBERT GOLDBLATT. Mathematics of Modality. CSLI Publications, 1993.
[124] RAJEEV GOR´E. “Substructural Logics on Display”. Logic Journal of the IGPL, 6(3):451–604,
1998.
[125] GEORGE GR¨ATZER. General Lattice Theory. Academic Press, 1978.
[126] C. A. GUNTER AND D. S. SCOTT. “Semantic Domains”. In J. VAN LEEUWEN, editor,
Handbook of Theoretical Computer Science, pages 633–674. Elsevier Science Publishers
B.V., 1990.
[127] GILBERT HARMAN. “The meanings of logical constants”. In ERNEST LE PORE, editor, Truth
and Interpretation: Perspectives on the Philosophy of Donald Davidson, pages 125–134.
Blackwell, Oxford, 1986.
[128] R. HARROP. “On Disjunctions and Existential Statements in Intuitionistic Systems of
Logic”. Mathematische Annalen, 132:347–361, 1956.
[129] C. HARTONAS. “Order-Duality, Negation and Lattice Representation”. In H. WANSING,
editor, Negation: Notion in Focus, pages 27–37. De Gruyter Publication, New York–Berlin,
1996. Paper presented at the conference ANALYOMEN 2, Leipzig, 1994, Workshop on
Negation.
[130] C. HARTONAS. “Duality for Lattice-Ordered Algebras and Normal Algebraizable Logics”.
Studia Logica, 58(3):403–450, 1997.
[131] C. HARTONAS. “Pretopology Semantics for Bimodal Intuitionistic Linear Logic”. Journal of
the Interest Group in Pure and Applied Logics, 5(1):65–78, 1997.
[132] C. HARTONAS AND J. MICHAEL DUNN. “Stone Duality for Lattices”. Algebra Universalis,
37:391–401, 1997.
[133] ALLEN HAZEN. “Aspects of Russell’s Logic in 1906”. Letter, dated October 21, 1997.
[134] AREND HEYTING. Intuitionism: An Introduction. North Holland, Amsterdam, 1956.
[135] J. R. HINDLEY. “The Simple Semantics for Coppo-Dezani-Sall´e Types”. In
M. DEZANI-CIANCAGLINI AND H. MONTANARI, editors, International Symposium on
Programming, volume 137 of Lecture Notes in Computer Science, pages 212–226.
Springer-Verlag, 1983.
[136] WILFRID HODGES. Model Theory. Cambridge University Press, 1993.
[137] W. A. HOWARD. “The Formulae-as-types Notion of Construction”. In J. P. SELDIN AND
J. R. HINDLEY, editors, To H. B. Curry: Essays on Combinatory Logic, Lambda Calculus and
Formalism, pages 479–490. Academic Press, London, 1980.
[138] G. HUTCHINSON. “Recursively Unsolvable Word Problems of Modular Lattices and
Diagram Chasing”. Journal of Algebra, pages 385–399, 1973.
[139] DOMINIC HYDE AND GRAHAM PRIEST, editors. Sociative Logics and their Applications:
Essays by the Late Richard Sylvan. Ashgate, 2000.
[140] PRAGATI JAIN. “Undecidability of Relevant Logics”. Technical Report, Automated
Reasoning Project, 1997. TR-ARP-06-97, available from
ftp://arp.anu.edu.au/pub/techreports/.
[141] BJARNI J ´ONSSON AND ALFRED TARSKI. “Boolean Algebras with Operators: Part I”.
American Journal of Mathematics, 73:891–939, 1951.
[142] BJARNI J ´ONSSON AND ALFRED TARSKI. “Boolean Algebras with Operators: Part II”.
American Journal of Mathematics, 75:127–162, 1952.
[143] S. C. KLEENE. “Disjunction and Existence under Implication in Elementary Intuitionistic
Formalisms”. Journal of Symbolic Logic, 27:11–18, 1962. (This paper has an
addendum [144]).
[144] S. C. KLEENE. “An Addendum”. Journal of Symbolic Logic, 28:154–156, 1963. (Addendum
to “Disjunction and Existence under Implication in Elementary Intuitionistic
Formalisms” [143]).
[145] MARKUS KRACHT. “Power and Weakness of the Modal Display Calculus”. In Proof Theory
of Modal Logic, pages 93–121. Kluwer Academic Publishers, Dordrecht, 1996.
[146] PHILIP KREMER. “Dunns Relevant Prediction, Real Properties and Identity”. Erkenntnis,
47:37–65, 1997.
[147] SAUL A. KRIPKE. “The Problem of Entailment”. Journal of Symbolic Logic, 24:324, 1959.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
100
Abstract.
[148] NATASHA KURTONINA. Frames and Labels: A Modal Analysis of Categorial Inference. PhD
thesis, Institute for Logic, Language and Computation, University of Utrecht, 1995.
[149] JOACHIM LAMBEK. “The Mathematics of Sentence Structure”. American Mathematical
Monthly, 65:154–170, 1958.
[150] JOACHIM LAMBEK. “On the Calculus of Syntactic Types”. In R. JACOBSEN, editor, Structure
of Language and its Mathematical Aspects, Proceedings of Symposia in Applied
Mathematics, XII. American Mathematical Society, 1961.
[151] JOACHIM LAMBEK. “Deductive Systems and Categories II”. In PETER HILTON, editor,
Category Theory, Homology Theory and their Applications II, volume 86 of Lecture Notes in
Mathematics. Springer-Verlag, 1969.
[152] JOACHIM LAMBEK AND PHILIP J. SCOTT. Introduction to Higher Order Categorical Logic.
Cambridge University Press, 1986.
[153] E. J. LEMMON. Beginning Logic. Nelson, 1965.
[154] DAVID K. LEWIS. On the Plurality of Worlds. Blackwell, Oxford, 1986.
[155] CASIMIR LEWY. “Entailment”. Aristotelian Society supplementary volume, 32:123–142,
1958.
[156] P. LINCOLN, J. MITCHELL, A. SCENROV, AND N. SHANKAR. “Decision Problems for
Propositional Linear Logic”. Annals of Pure and Applied Logic, 56:239–311, 1992.
[157] L. LIPSHITZ. “The Undecidability of the Word Problems for Projective Geometries and
Modular Lattices”. Transactions of the American Mathematical Society, pages 171–180,
1974.
[158] SAUNDERS MAC LANE. Categories for the Working Mathematician. Number 5 in Graduate
Texts in Mathematics. Springer-Verlag, 1971.
[159] H. M. MACNEILLE. “Partially Ordered Sets”. Transactions of the American Mathematical
Society, 42:416–460, 1937.
[160] JOHN MARAIST, MARTIN ODERSKY, DAVID N. TURNER, AND PHILIP WADLER.
“Call-by-name, call-by-value, call-by-need, and the linear lambda calculus”. In 11th
International Conference on the Mathematical Foundations of Programming Semantics,
New Orleans, Lousiana, March–April 1995.
[161] EDWIN MARES. “Relevant Logic and the Theory of Information”. Synthese, 109:345–360,
1997.
[162] EDWIN D. MARES AND ANDR´E FUHRMANN. “A Relevant Theory of Conditionals”. Journal
of Philosophical Logic, 24:645–665, 1995.
[163] EDWIN D. MARES AND ROBERT K. MEYER. “The Admissibility of
 in R4”. Notre Dame
Journal of Formal Logic, 33:197–206, 1992.
[164] EDWIN D. MARES AND ROBERT K. MEYER. “The Semantics of R4”. Journal of Philosophical
Logic, 22:95–110, 1993.
[165] E. P. MARTIN. “Noncircular Logic”. Journal of Symbolic Logic, 49:1427, 1984. abstract.
[166] E. P. MARTIN AND R. K. MEYER. “Solution to the P-W problem”. Journal of Symbolic Logic,
47:869–886, 1982.
[167] MAARTEN MARX, L´ASZL ´O P ´OLOS, AND MICHAEL MAUSCH, editors. Arrow Logic and
Multi-Modal Logic. CSLI Publications, 1996.
[168] M. A. MCROBBIE AND N. D. BELNAP JR. “Relevant Analytic Tableaux”. Studia Logica,
38:187–200, 1979.
[169] C. A. MEREDITH AND A. N. PRIOR. “Notes on the Axiomatics of the Propositional
Calculus”. Notre Dame Journal of Formal Logic, 4:171–187, 1963.
[170] R. K. MEYER. “Ackermann, Takeuti and Schnitt;
 for higher-order relevant logics”.
Bulletin of the Section of Logic, 5:138–144, 1976.
[171] R. K. MEYER. “A General Gentzen System for Implicational Calculi”. Relevance Logic
Newsletter, 1:189–201, 1976.
[172] R. K. MEYER, M. BUNDER, AND L. POWERS. “Implementing the ‘Fool’s Model’ for
Combinatory Logic”. Journal of Automated Reasoning, 7:597–630, 1991.
[173] R. K. MEYER AND J. K. SLANEY. “Abelian Logic from A to Z”. In GRAHAM PRIEST, RICHARD
SYLVAN, AND JEAN NORMAN, editors, Paraconsistent Logic: Essays on the Inconsistent,
pages 245–288. Philosophia Verlag, 1989.
[174] ROBERT K. MEYER. Topics in Modal and Many-valued Logic. PhD thesis, University of
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
101
Pittsburgh, 1966.
[175] ROBERT K. MEYER. “An undecidability result in the theory of relevant implication”.
Zeitschrift f¨ur Mathematische Logik und Grundlagen der Mathematik, 14:255–262, 1968.
[176] ROBERT K. MEYER. “E and S4”. Notre Dame Journal of Formal Logic, 11:181–199, 1970.
[177] ROBERT K. MEYER. “

  —the Bounds of Finitude”. Zeitschrift f¨ur Mathematische Logik
und Grundlagen der Mathematik, 16:385–387, 1970.
[178] ROBERT K. MEYER. “On Coherence in Modal Logics”. Logique et Analyse, 14:658–668, 1971.
[179] ROBERT K. MEYER. “Conserving Positive Logics”. Notre Dame Journal of Formal Logic,
14:224–236, 1973.
[180] ROBERT K. MEYER. “Intuitionism, Entailment, Negation”. In H. LEBLANC, editor, Truth,
Syntax and Modality, pages 168–198. North Holland, 1973.
[181] ROBERT K. MEYER. “Metacompleteness”. Notre Dame Journal of Formal Logic,
17:501–517, 1976.
[182] ROBERT K. MEYER. “Why I am not a Relevantist”. Technical Report 1, Logic Group, RSSS,
Australian National University, 1978.
[183] ROBERT K. MEYER. “⊃E is Admissible in ‘True’ Relevant Arithmetic”. Journal of
Philosophical Logic, 27:327–351, 1998.
[184] ROBERT K. MEYER AND J. MICHAEL DUNN. “
  ,

and
  ”. Journal of Symbolic Logic,
34:460–474, 1969.
[185] ROBERT K. MEYER AND EDWIN MARES. “Semantics of Entailment 0”. In PETER
SCHROEDER-HEISTER AND KOSTA DOˇSEN, editors, Substructural Logics. Oxford University
Press, 1993.
[186] ROBERT K. MEYER AND ERROL P. MARTIN. “Logic on the Australian Plan”. Journal of
Philosophical Logic, 15:305–332, 1986.
[187] ROBERT K. MEYER, MICHAEL A. MCROBBIE, AND NUEL D. BELNAP. “Linear Analytic
Tableaux”. In Proceedings of the Fourth Workshop on Theorem Proving with Analytic
Tableaux and Related Methods, volume 918 of Lecture Notes in Computer Science, 1995.
[188] ROBERT K. MEYER AND ZANE PARKS. “Independent Axioms of Soboci´nski’s three-valued
logic”. Zeitschrift f¨ur Mathematische Logik und Grundlagen der Mathematik, 18:291–295,
1972.
[189] ROBERT K. MEYER AND GREG RESTALL. “‘Strenge’ Arithmetic”. Automated Reasoning
Project, Australian National University. Submitted for publication, 1996.
[190] ROBERT K. MEYER AND RICHARD ROUTLEY. “Algebraic Analysis of Entailment”. Logique et
Analyse, 15:407–428, 1972.
[191] ROBERT K. MEYER AND RICHARD ROUTLEY. “Classical Relevant Logics I”. Studia Logica,
32:51–66, 1973.
[192] ROBERT K. MEYER AND RICHARD ROUTLEY. “Classical Relevant Logics II”. Studia Logica,
33:183–194, 1973.
[193] ROBERT K. MEYER AND RICHARD ROUTLEY. “An Undecidable Relevant Logic”. Zeitschrift
f¨ur Mathematische Logik und Grundlagen der Mathematik, 19:289–397, 1973.
[194] ROBERT K. MEYER, RICHARD ROUTLEY, AND J. MICHAEL DUNN. “Curry’s Paradox”.
Analysis, 39:124–128, 1979.
[195] G. MINC. “Cut-Elimination Theorem in Relevant Logics”. In J. V. MATIJASEVIC AND O. A.
SILENKO, editors, Issl´edovani´a po konstructivnoj mathematik´e i matematiˇceskoj logike V,
pages 90–97. Izdat´el’stvo “Nauka”, 1972. (English translation in “Cut-Elimination
Theorem in Relevant Logics” [196]).
[196] G. MINC. “Cut-Elimination Theorem in Relevant Logics”. The Journal of Soviet
Mathematics, 6:422–428, 1976. (English translation of the original article [195]).
[197] G. MINC. “Closed Categories and the Theory of Proofs”. Zapiski Nauchnykh Seminarov
Leningradskogo Otdeleniya Matematischeskogo Instituta im. V. A. Steklova AN SSSR,
68:83–114, 1977. (Russian, English summary).
[198] JOHN C. MITCHELL. Foundations for Programming Languages. MIT Press, 1996.
[199] WILLIAM P. R. MITCHELL. “The Carcinogenic Example”. Logic Journal of the IGPL,
5(6):795–810, 1997.
[200] MICHIEL MOORTGAT. Categorial Investigations: Logical Aspects of the Lambek Calculus.
Foris, Dordrecht, 1988.
[201] A. DE MORGAN. “On the Syllogism: IV, and on the Logic of Relations”. Transactions of the
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
102
Cambridge Philosophical Society, 10:331–358, 1864. Read before the Cambridge
Philosophical Society on April 23, 1860.
[202] GLYN MORRILL. Type Logical Grammar: Categorial Logic of Signs. Kluwer, Dordrecht,
1994.
[203] C. J. MULVEY. “&”. In Second Topology Conference, Rendiconti del Circolo Matematico di
Palermo, ser.2, supplement no. 12, pages 99–104, 1986.
[204] P. O’HEARN AND D. PYM. “The Logic of Bunched Implications”. Bulletin of Symbolic
Logic, 5:215–244, 1999.
[205] H. ONO AND Y. KOMORI. “Logic without the Contraction Rule”. Journal of Symbolic Logic,
50:169–201, 1985.
[206] HIROAKIRA ONO. “Semantics for Substructural Logics”. In PETER SCHROEDER-HEISTER
AND KOSTA DOˇSEN, editors, Substructural Logics, pages 259–291. Oxford University Press,
1993.
[207] I. E. ORLOV. “The Calculus of Compatibility of Propositions (in Russian)”.
Matematicheskiˇı Sbornik, 35:263–286, 1928.
[208] E. ORŁOWSKA. “Relational Interpretation of Modal Logics”. Bulletin of the Section of Logic,
17:2–14, 1988.
[209] CHARLES S. PEIRCE. “Description of a notation for the logic of relatives, resulting from an
ampliﬁcation of the conceptions of Boole’s calculus of logic”. Memoirs of the American
Academy of Science, 9:317–378, 1870.
[210] MATI PENTUS. “Models for the Lambek Calculus”. Annals of Pure and Applied Logic,
75(1–2):179–213, 1995.
[211] MATI PENTUS. “Free monoid completeness of the Lambek calculus allowing empty
premises”. In J. M. LARRAZABAL, LASCAR D., AND MINTS G., editors, Logic Colloquium ’96:
proceedings of the colloquium held in San Sebastian, Spain, July 9–15, 1996, pages
171–209. Springer, 1998. Lecture Notes in Logic, 12.
[212] G. POTTINGER. “On analysing relevance constructively”. Studia Logica, 38:171–185, 1979.
[213] V. R. PRATT. “Dynamic Algebras as a Well-Behaved Fragment of Relation Algebras”. In
Algebraic Logic and Universal Algebra in Computer Science, number 425 in Lecture Notes
in Computer Science. Springer-Verlag, 1990.
[214] DAG PRAWITZ. Natural Deduction: A Proof Theoretical Study. Almqvist and Wiksell,
Stockholm, 1965.
[215] GRAHAM PRIEST. “Sense, Entailment and Modus Ponens”. Journal of Philosophical Logic,
9:415–435, 1980.
[216] GRAHAM PRIEST. In Contradiction: A Study of the Transconsistent. Martinus Nijhoff, The
Hague, 1987.
[217] GRAHAM PRIEST. “Motivations for Paraconsistency: The Slippery Slope from Classical
Logic to Dialetheism”. In GRAHAM PRIEST DIDERIK BATENS, CHRIS MORTENSEN AND
JEAN-PAUL VAN BENDEGEM, editors, Frontiers of Paraconsistency, pages 223–232. Kluwer
Academic Publishers, 2000.
[218] GRAHAM PRIEST. “Logic: One or Many?”. In B. BROWN AND J. WOODS, editors, Logical
Consequences. Kluwer Academic Publishers, forthcoming.
[219] GRAHAM PRIEST AND RICHARD SYLVAN. “Reductio ad absurdum et Modus Tollendo
Ponens”. In GRAHAM PRIEST, RICHARD SYLVAN, AND JEAN NORMAN, editors,
Paraconsistent Logic: Essays on the Inconsistent, pages 613–626. Philosophia Verlag, 1989.
[220] GRAHAM PRIEST AND RICHARD SYLVAN. “Simpliﬁed Semantics for Basic Relevant Logics”.
Journal of Philosophical Logic, 21:217–232, 1992.
[221] GRAHAM PRIEST, RICHARD SYLVAN, AND JEAN NORMAN, editors. Paraconsistent Logic:
Essays on the Inconsistent. Philosophia Verlag, 1989.
[222] H. RASIOWA. An Algebraic Approach to Non-classical Logics. North Holland, 1974.
[223] STEPHEN READ. “What is Wrong with Disjunctive Syllogism?”. Analysis, 41:66–70, 1981.
[224] STEPHEN READ. Relevant Logic. Basil Blackwell, Oxford, 1988.
[225] STEPHEN READ. Thinking about Logic. Oxford University Press, 1995.
[226] GREG RESTALL. “A Note on Na¨ıve Set Theory in LP”. Notre Dame Journal of Formal Logic,
33:422–432, 1992.
[227] GREG RESTALL. “Simpliﬁed Semantics for Relevant Logics (and some of their rivals)”.
Journal of Philosophical Logic, 22:481–511, 1993.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
103
[228] GREG RESTALL. “A Useful Substructural Logic”. Bulletin of the Interest Group in Pure and
Applied Logic, 2(2):135–146, 1994.
[229] GREG RESTALL. “Display Logic and Gaggle Theory”. Reports in Mathematical Logic,
29:133–146, 1995.
[230] GREG RESTALL. “Four Valued Semantics for Relevant Logics (and some of their rivals)”.
Journal of Philosophical Logic, 24:139–160, 1995.
[231] GREG RESTALL. “Information Flow and Relevant Logics”. In JERRY SELIGMAN AND DAG
WESTERSTAHL, editors, Logic, Language and Computation: The 1994 Moraga Proceedings,
pages 463–477. CSLI Publications, 1995.
[232] GREG RESTALL. “Displaying and Deciding Substructural Logics 1: Logics with
contraposition”. Journal of Philosophical Logic, 27:179–216, 1998.
[233] GREG RESTALL. “Negation in Relevant Logics: How I Stopped Worrying and Learned to
Love the Routley Star”. In DOV GABBAY AND HEINRICH WANSING, editors, What is
Negation?, volume 13 of Applied Logic Series, pages 53–76. Kluwer Academic Publishers,
1999.
[234] GREG RESTALL. An Introduction to Substructural Logics. Routledge, 2000.
[235] GREG RESTALL. “Deﬁning Double Negation Elimination”. Logic Journal of the IGPL,
9(3):??–???, 2001.
[236] GREG RESTALL. “Laws of Non-Contradiction, Laws of the Excluded Middle and Logics”. In
The Law of Non-Contradiction. ???, to appear. A collection edited by Graham Priest and JC
Beall.
[237] D. ROORDA. Resource Logics: Proof-theoretical Investigations. PhD thesis, Amsterdam,
1991.
[238] RICHARD ROUTLEY. “Relevantism, Material Detachment, and the Disjunctive Syllogism
Argument”. Canadian Journal of Philosophy, 14:167–188, 1984.
[239] RICHARD ROUTLEY AND ROBERT K. MEYER. “Semantics of Entailment — II”. Journal of
Philosophical Logic, 1:53–73, 1972.
[240] RICHARD ROUTLEY AND ROBERT K. MEYER. “Semantics of Entailment — III”. Journal of
Philosophical Logic, 1:192–208, 1972.
[241] RICHARD ROUTLEY AND ROBERT K. MEYER. “Semantics of Entailment”. In HUGUES
LEBLANC, editor, Truth Syntax and Modality, pages 194–243. North Holland, 1973.
Proceedings of the Temple University Conference on Alternative Semantics.
[242] RICHARD ROUTLEY, VAL PLUMWOOD, ROBERT K. MEYER, AND ROSS T. BRADY. Relevant
Logics and their Rivals. Ridgeview, 1982.
[243] BERTRAND RUSSELL. “The Theory of Implication”. American Journal of Mathematics,
28:159–202, 1906.
[244] GIOVANNI SAMBIN. “Intuitionistic Formal Spaces and their Neighbourhood”. In
C. BONOTTO, R. FERRO, S. VALENTINI, AND A. ZANARDO, editors, Logic Colloquium ’88,
pages 261–286. North Holland, 1989.
[245] GIOVANNI SAMBIN. “The Semantics of Pretopologies”. In PETER SCHROEDER-HEISTER AND
KOSTA DOˇSEN, editors, Substructural Logics, pages 293–307. Oxford University Press, 1993.
[246] GIOVANNI SAMBIN. “Pretopologies and Completeness Proofs”. Journal of Symbolic Logic,
60(3):861–878, 1995.
[247] GIOVANNI SAMBIN AND V. VACCARO. “Topology and duality in modal logic”. Annals of Pure
and Applied Logic, 37:249–296, 1988.
[248] ANDREA SCHALK AND VALERIA DE PAIVA. “Poset-valued sets or How to build models for
Linear Logics”. ???, 2001.
[249] E. SCHR ¨ODER. Vorlesungen ¨uber die Algebra der Logik (exacte Logik), Volume 3, “Algebra
und Logik der Relative”. Leipzig, 1895. Part I.
[250] PETER SCHROEDER-HEISTER AND KOSTA DOˇSEN, editors. Substructural Logics. Oxford
University Press, 1993.
[251] DANA SCOTT. “Models for Various Type-Free Calculi”. In PATRICK SUPPES, LEON HENKIN,
ATHANASE JOJA, AND GR. C. MOISIL, editors, Logic, Methodology and Philosophy of
Science IV, pages 157–187. North Holland, Amsterdam, 1973.
[252] DANA SCOTT. “Lambda Calculus: Some Models, Some Philosophy”. In J. BARWISE, H. J.
KEISLER, AND K. KUNEN, editors, The Kleene Symposium, pages 223–265. North Holland,
Amsterdam, 1980.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
104
[253] MOH SHAW-KWEI. “The Deduction Theorems and Two New Logical Systems”. Methodos,
2:56–75, 1950.
[254] J. K. SLANEY. “RWX is not Curry-paraconsistent”. In GRAHAM PRIEST, RICHARD SYLVAN,
AND JEAN NORMAN, editors, Paraconsistent Logic: Essays on the Inconsistent, pages
472–480. Philosophia Verlag, 1989.
[255] JOHN K. SLANEY. “Reduced Models for Relevant Logics without WI”. Notre Dame Journal
of Formal Logic, 28:395–407, 1987.
[256] JOHN K. SLANEY. “A General Logic”. Australasian Journal of Philosophy, 68:74–88, 1990.
[257] T. J. SMILEY. “Entailment and Deducibility”. Proceedings of the Aristotelian Society (new
series), 59:233–254, 1959.
[258] ROBERT STALNAKER. Inquiry. Bradford Books. MIT Press, 1984.
[259] ALFRED TARSKI. “On The Calculus of Relations”. Journal of Symbolic Logic, 6:73–89, 1941.
[260] ALFRED TARSKI. Logic, Semantics, Metamathematics: papers from 1923 to 1938.
Clarendon Press, Oxford, 1956. Translated by J. H. Woodger.
[261] NEIL TENNANT. Autologic. Edinburgh University Press, 1992.
[262] NEIL TENNANT. “The Transmission of Truth and the Transitivity of Deduction”. In DOV
GABBAY, editor, What is a Logical System?, volume 4 of Studies in Logic and Computation,
pages 161–177. Oxford University Press, Oxford, 1994.
[263] PAUL THISTLEWAITE, MICHAEL MCROBBIE, AND ROBERT K. MEYER. Automated Theorem
Proving in Non-Classical Logics. Wiley, New York, 1988.
[264] A. S. TROELSTRA. Lectures on Linear Logic. CSLI Publications, 1992.
[265] ALASDAIR URQUHART. “The Completeness of Weak Implication”. Theoria, 37:274–282,
1972.
[266] ALASDAIR URQUHART. “A General Theory of Implication”. Journal of Symbolic Logic,
37:443, 1972.
[267] ALASDAIR URQUHART. “Semantics for Relevant Logics”. Journal of Symbolic Logic,
37:159–169, 1972.
[268] ALASDAIR URQUHART. The Semantics of Entailment. PhD thesis, University of Pittsburgh,
1972.
[269] ALASDAIR URQUHART. “Relevant Implication and Projective Geometry”. Logique et
Analyse, 26:345–357, 1983.
[270] ALASDAIR URQUHART. “The Undecidability of Entailment and Relevant Implication”.
Journal of Symbolic Logic, 49:1059–1073, 1984.
[271] ALASDAIR URQUHART. “Many-Valued Logics”. In DOV M. GABBAY AND FRANZ G ¨UNTHNER,
editors, Handbook of Philosophical Logic, volume 3, pages 71–116. Reidel, Dordrecht,
1986.
[272] ALASDAIR URQUHART. “The Complexity of Decision Procedures in Relevance Logic”. In
J. MICHAEL DUNN AND ANIL GUPTA, editors, Truth or Consequences, pages 77–95. Kluwer,
1990.
[273] ALASDAIR URQUHART. “Failure of Interpolation in Relevant Logics”. Journal of
Philosophical Logic, 22:449–479, 1993.
[274] ALASDAIR URQUHART. “Duality for Algebras of Relevant Logics”. Studia Logica,
56:263–276, 1996.
[275] ALASDAIR URQUHART. “The Complexity of Decision Procedures in Relevance Logic II”.
Available from the author, University of Toronto, 1997.
[276] BETTI VENNERI. “Intersection Types as Logical Formulae”. Journal of Logic and
Computation, 4:109–124, 1994.
[277] STEVEN VICKERS. Topology via Logic, volume 5 of Cambridge Tracts in Theoretical
Computer Science. Cambridge University Press, 1990. Revised edition.
[278] PHILIP WADLER. “Linear Types can Change the World!”. In M. BROY AND C. JONES,
editors, Programming Concepts and Methods, Sea of Galilee, Israel, April 1990. North
Holland. IFIP TC 2 Working Conference.
[279] PHILIP WADLER. “Is there a Use for Linear Logic?”. In ACM Conference on Partial
Evaluation and Semantics-Based Program Manipulation, New Haven, Connecticut, June
1991.
[280] PHILIP WADLER. “Comprehending monads”. Mathematical Structures in Computer
Science, 2:461–493, 1992. (Special issue of selected papers from 6th Conference on Lisp
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

http://www.phil.mq.edu.au/staff/grestall/
105
and Functional Programming.).
[281] PHILIP WADLER. “There’s No Substitute for Linear Logic”. In Workshop on Mathematical
Foundations of Programming Semantics, Oxford, UK, April 1992. (No proceedings
published. Available from
http://www.cs.bell-labs.com/who/wadler/topics/linear-logic.html).
[282] PHILIP WADLER. “A Syntax for Linear Logic”. In 9th International Conference on the
Mathematical Foundations of Programming Semantics, New Orleans, Lousiana, April
1993.
[283] PHILIP WADLER. “A Taste of Linear Logic”. In Mathematical Foundations of Computer
Science, volume 711 of Lecture Notes in Computer Science, Gdansk, Poland, August 1993.
Springer-Verlag.
[284] HEINRICH WANSING. The Logic of Information Structures. Number 681 in Lecture Notes in
Artiﬁcial Intelligence. Springer-Verlag, 1993.
[285] HEINRICH WANSING. “Sequent Calculi for Normal Propositional Modal Logics”. Journal of
Logic and Computation, 4:125–142, 1994.
[286] HEINRICH WANSING. Displaying Modal Logic. Kluwer Academic Publishers, Dordrecht,
1998.
[287] RICHARD WHITE. “The Consistency of the Axiom of Comprehension in the Inﬁnite Valued
Predicate Logic of Łukasiewicz”. Journal of Philosophical Logic, 8:503–534, 1979.
[288] G. H. VON WRIGHT. Logical Studies. Routledge & Kegan Paul, 1957.
Greg Restall, Greg.Restall@mq.edu.au
June 23, 2001

