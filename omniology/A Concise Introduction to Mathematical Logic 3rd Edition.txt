
Universitext
For further volumes:
http://www.springer.com/series/223


Wolfgang Rautenberg
A Concise Introduction
to Mathematical Logic
Third Edition
123

Prof. Dr. Wolfgang Rautenberg
Fachbereich Mathematik und Informatik
14195 Berlin
Germany
raut@math.fu-berlin.de
Editorial board:
Sheldon Axler, San Francisco State University, San Francisco, CA, USA
Vincenzo Capasso, University of Milan, Milan, Italy
Carles Casacuberta, Universitat de Barcelona, Barcelona, Spain
Angus MacIntyre, Queen Mary, University of London, London, UK
Kenneth Ribet, University of California, Berkeley, CA, USA
Claude Sabbah, Ecole Polytechnique, Palaiseau, France
Endre Süli, Oxford University, Oxford, UK
Wojbor Woyczynski, Case Western Reserve University, Cleveland, OH, USA
Cover illustration: Photographer unknown. Courtesy of The Shelby White and Leon Levy
Archives Center, Institute for Advanced Study, Princeton, NJ, USA.
ISBN 978-1-4419-1220-6
e-ISBN 978-1-4419-1221-3
DOI 10.1007/978-1-4419-1221-3
Springer New York Dordrecht Heidelberg London
Library of Congress Control Number: 2009932782
Mathematics Subject Classiﬁcation (2000): 03-XX, 68N 17
c⃝Springer Science+Business Media, LLC 2010
All rights reserved. This work may not be translated or copied in whole or in part without the written
permission of the publisher (Springer Science+Business Media, LLC, 233 Spring Street, New York, NY
10013, USA), except for brief excerpts in connection with reviews or scholarly analysis. Use in connection
with any form of information storage and retrieval, electronic adaptation, computer software, or by similar or
dissimilar methodology now known or hereafter developed is forbidden.
The use in this publication of trade names, trademarks, service marks, and similar terms, even if they are
not identiﬁed as such, is not to be taken as an expression of opinion as to whether or not they are subject to
proprietary rights.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

Foreword
by Lev Beklemishev, Moscow
The ﬁeld of mathematical logic—evolving around the notions of logical
validity, provability, and computation—was created in the ﬁrst half of the
previous century by a cohort of brilliant mathematicians and philosophers
such as Frege, Hilbert, Gödel, Turing, Tarski, Malcev, Gentzen, and some
others. The development of this discipline is arguably among the highest
achievements of science in the twentieth century: it expanded mathe-
matics into a novel area of applications, subjected logical reasoning and
computability to rigorous analysis, and eventually led to the creation of
computers.
The textbook by Professor Wolfgang Rautenberg is a well-written in-
troduction to this beautiful and coherent subject. It contains classical
material such as logical calculi, beginnings of model theory, and Gödel’s
incompleteness theorems, as well as some topics motivated by applica-
tions, such as a chapter on logic programming. The author has taken
great care to make the exposition readable and concise; each section is
accompanied by a good selection of exercises.
A special word of praise is due for the author’s presentation of Gödel’s
second incompleteness theorem, in which the author has succeeded in
giving an accurate and simple proof of the derivability conditions and
the provable Σ1-completeness, a technically diﬃcult point that is usually
omitted in textbooks of comparable level. This work can be recommended
to all students who want to learn the foundations of mathematical logic.
v


Preface
The third edition diﬀers from the second mainly in that parts of the
text have been elaborated upon in more detail.
Moreover, some new
sections have been added, for instance a separate section on Horn formulas
in Chapter 4, particularly interesting for logic programming. The book
is aimed at students of mathematics, computer science, and linguistics.
It may also be of interest to students of philosophy (with an adequate
mathematical background) because of the epistemological applications of
Gödel’s incompleteness theorems, which are discussed in detail.
Although the book is primarily designed to accompany lectures on a
graduate level, most of the ﬁrst three chapters are also readable by under-
graduates. The ﬁrst hundred twenty pages cover suﬃcient material for an
undergraduate course on mathematical logic, combined with a due por-
tion of set theory. Only that part of set theory is included that is closely
related to mathematical logic.
Some sections of Chapter 3 are partly
descriptive, providing a perspective on decision problems, on automated
theorem proving, and on nonstandard models.
Using this book for independent and individual study depends less on
the reader’s mathematical background than on his (or her) ambition to
master the technical details. Suitable examples accompany the theorems
and new notions throughout.
We always try to portray simple things
simply and concisely and to avoid excessive notation, which could divert
the reader’s mind from the essentials. Line breaks in formulas have been
avoided. To aid the student, the indexes have been prepared very carefully.
Solution hints to most exercises are provided in an extra ﬁle ready for
download from Springer’s or the author’s website.
Starting from Chapter 4, the demands on the reader begin to grow. The
challenge can best be met by attempting to solve the exercises without
recourse to the hints. The density of information in the text is rather high;
a newcomer may need one hour for one page. Make sure to have paper and
pencil at hand when reading the text. Apart from suﬃcient training in
logical (or mathematical) deduction, additional prerequisites are assumed
only for parts of Chapter 5, namely some knowledge of classical algebra,
and at the very end of the last chapter some acquaintance with models of
axiomatic set theory.
vii

viii
Preface
On top of the material for a one-semester lecture course on mathemat-
ical logic, basic material for a course in logic for computer scientists is
included in Chapter 4 on logic programming. An eﬀort has been made to
capture some of the interesting aspects of this discipline’s logical founda-
tions. The resolution theorem is proved constructively. Since all recursive
functions are computable in PROLOG, it is not hard to deduce the un-
decidability of the existence problem for successful resolutions.
Chapter 5 concerns applications of mathematical logic in mathematics
itself. It presents various methods of model construction and contains the
basic material for an introductory course on model theory. It contains in
particular a model-theoretic proof of quantiﬁer eliminability in the theory
of real closed ﬁelds, which has a broad range of applications.
A special aspect of the book is the thorough treatment of Gödel’s incom-
pleteness theorems in Chapters 6 and 7. Chapters 4 and 5 are not needed
here. 6.11 starts with basic recursion theory needed for the arithmeti-
zation of syntax in 6.2 as well as in solving questions about decidability
and undecidability in 6.5. Deﬁning formulas for arithmetical predicates
are classiﬁed early, to elucidate the close relationship between logic and
recursion theory. Along these lines, in 6.5 we obtain in one sweep Gödel’s
ﬁrst incompleteness theorem, the undecidability of the tautology problem
by Church, and Tarski’s result on the nondeﬁnability of truth, all of which
are based on certain diagonalization arguments. 6.6 includes among other
things a sketch of the solution to Hilbert’s tenth problem.
Chapter 7 is devoted mainly to Gödel’s second incompleteness theo-
rem and some of its generalizations. Of particular interest thereby is the
fact that questions about self-referential arithmetical statements are al-
gorithmically decidable due to Solovay’s completeness theorem. Here and
elsewhere, Peano arithmetic (PA) plays a key role, a basic theory for the
foundations of mathematics and computer science, introduced already in
3.3. The chapter includes some of the latest results in the area of self-
reference not yet covered by other textbooks.
Remarks in small print refer occasionally to notions that are undeﬁned
and direct the reader to the bibliography, or will be introduced later.
The bibliography can represent an incomplete selection only. It lists most
1 This is to mean Section 6.1, more precisely, Section 1 in Chapter 6. All other boldface
labels are to be read accordingly throughout the book.

Preface
ix
English textbooks on mathematical logic and, in addition, some original
papers mainly for historical reasons. It also contains some titles treating
biographical, historical, and philosophical aspects of mathematical logic
in more detail than this can be done in the limited size of our book. Some
brief historical remarks are also made in the Introduction. Bibliographical
entries are sorted alphabetically by author names. This order may slightly
diverge from the alphabetic order of their citation labels.
The material contained in this book will remain with high probability
the subject of lectures on mathematical logic in the future. Its streamlined
presentation has allowed us to cover many diﬀerent topics. Nonetheless,
the book provides only a selection of results and can at most accentuate
certain topics. This concerns above all Chapters 4, 5, 6, and 7, which go
a step beyond the elementary. Philosophical and foundational problems
of mathematics are not systematically discussed within the constraints of
this book, but are to some extent considered when appropriate.
The seven chapters of the book consist of numbered sections. A ref-
erence like Theorem 5.4 is to mean Theorem 4 in Section 5 of a given
chapter. In cross-referencing from another chapter, the chapter number
will be adjoined.
For instance, Theorem 6.5.4 means Theorem 5.4 in
Chapter 6. You may ﬁnd additional information about the book or con-
tact me on my website www.math.fu-berlin.de/~raut. Please contact me
if you propose improved solutions to the exercises, which may afterward
be included in the separate ﬁle Solution Hints to the Exercises.
I would like to thank the colleagues who oﬀered me helpful criticism
along the way. Useful for Chapter 7 were hints from Lev Beklemishev
and Wilfried Buchholz.
Thanks also to Peter Agricola for his help in
parts of the contents and in technical matters, and to Michael Knoop and
David Kramer for their thorough reading of the manuscript and ﬁnding a
number of mistakes.
Wolfgang Rautenberg, June 2009


Contents
Introduction
xv
Notation
xix
1
Propositional Logic
1
1.1
Boolean Functions and Formulas
. . . . . . . . . . . . . .
2
1.2
Semantic Equivalence and Normal Forms . . . . . . . . . .
11
1.3
Tautologies and Logical Consequence . . . . . . . . . . . .
17
1.4
A Calculus of Natural Deduction . . . . . . . . . . . . . .
22
1.5
Applications of the Compactness Theorem . . . . . . . . .
30
1.6
Hilbert Calculi
. . . . . . . . . . . . . . . . . . . . . . . .
35
2
First-Order Logic
41
2.1
Mathematical Structures . . . . . . . . . . . . . . . . . . .
42
2.2
Syntax of First-Order Languages . . . . . . . . . . . . . .
53
2.3
Semantics of First-Order Languages
. . . . . . . . . . . .
61
2.4
General Validity and Logical Equivalence
. . . . . . . . .
73
2.5
Logical Consequence and Theories
. . . . . . . . . . . . .
78
2.6
Explicit Deﬁnitions—Language Expansions
. . . . . . . .
85
3
Complete Logical Calculi
91
3.1
A Calculus of Natural Deduction . . . . . . . . . . . . . .
92
3.2
The Completeness Proof . . . . . . . . . . . . . . . . . . .
97
3.3
First Applications: Nonstandard Models . . . . . . . . . .
103
xi

xii
Contents
3.4
ZFC and Skolem’s Paradox . . . . . . . . . . . . . . . . . .
111
3.5
Enumerability and Decidability . . . . . . . . . . . . . . .
117
3.6
Complete Hilbert Calculi . . . . . . . . . . . . . . . . . . .
121
3.7
First-Order Fragments . . . . . . . . . . . . . . . . . . . .
126
3.8
Extensions of First-Order Languages . . . . . . . . . . . .
129
4
Foundations of Logic Programming
135
4.1
Term Models and Herbrand’s Theorem . . . . . . . . . . .
136
4.2
Horn Formulas
. . . . . . . . . . . . . . . . . . . . . . . .
140
4.3
Propositional Resolution . . . . . . . . . . . . . . . . . . .
143
4.4
Horn Resolution
. . . . . . . . . . . . . . . . . . . . . . .
149
4.5
Uniﬁcation
. . . . . . . . . . . . . . . . . . . . . . . . . .
152
4.6
Logic Programming . . . . . . . . . . . . . . . . . . . . . .
156
4.7
A Proof of the Main Theorem . . . . . . . . . . . . . . . .
166
5
Elements of Model Theory
169
5.1
Elementary Extensions . . . . . . . . . . . . . . . . . . . .
170
5.2
Complete and κ-Categorical Theories . . . . . . . . . . . .
176
5.3
The Ehrenfeucht Game . . . . . . . . . . . . . . . . . . . .
183
5.4
Embedding and Characterization Theorems . . . . . . . .
186
5.5
Model Completeness . . . . . . . . . . . . . . . . . . . . .
194
5.6
Quantiﬁer Elimination . . . . . . . . . . . . . . . . . . . .
202
5.7
Reduced Products and Ultraproducts . . . . . . . . . . . .
209
6
Incompleteness and Undecidability
215
6.1
Recursive and Primitive Recursive Functions
. . . . . . .
217
6.2
Arithmetization . . . . . . . . . . . . . . . . . . . . . . . .
226
6.3
Representability of Arithmetical Predicates
. . . . . . . .
234
6.4
The Representability Theorem
. . . . . . . . . . . . . . .
243
6.5
The Theorems of Gödel, Tarski, Church . . . . . . . . . .
250
6.6
Transfer by Interpretation . . . . . . . . . . . . . . . . . .
258
6.7
The Arithmetical Hierarchy . . . . . . . . . . . . . . . . .
264

Contents
xiii
7
On the Theory of Self-Reference
269
7.1
The Derivability Conditions . . . . . . . . . . . . . . . . .
270
7.2
The Provable Σ1-Completeness . . . . . . . . . . . . . . .
277
7.3
The Theorems of Gödel and Löb
. . . . . . . . . . . . . .
279
7.4
The Provability Logic G . . . . . . . . . . . . . . . . . . .
284
7.5
The Modal Treatment of Self-Reference
. . . . . . . . . .
287
7.6
A Bimodal Provability Logic for PA . . . . . . . . . . . . .
291
7.7
Modal Operators in ZFC . . . . . . . . . . . . . . . . . . .
294
Bibliography
299
Index of Terms and Names
307
Index of Symbols
317


Introduction
Traditional logic as a part of philosophy is one of the oldest scientiﬁc
disciplines. It can be traced back to the Stoics and to Aristotle2 and
is the root of what is nowadays called philosophical logic. Mathematical
logic, however, is a relatively young discipline, having arisen from the en-
deavors of Peano, Frege, and Russell to reduce mathematics entirely to
logic. It steadily developed during the twentieth century into a broad dis-
cipline with several subareas and numerous applications in mathematics,
computer science, linguistics, and philosophy.
One feature of modern logic is a clear distinction between object lan-
guage and metalanguage. The ﬁrst is formalized or at least formalizable.
The latter is, like the language of this book, a kind of a colloquial language
that diﬀers from author to author and depends also on the audience the
author has in mind. It is mixed up with semiformal elements, most of
which have their origin in set theory. The amount of set theory involved
depends on one’s objectives.
Traditional semantics and model theory
as essential parts of mathematical logic use stronger set-theoretic tools
than does proof theory. In some model-theoretic investigations these are
often the strongest possible ones. But on average, little more is assumed
than knowledge of the most common set-theoretic terminology, presented
in almost every mathematical course or textbook for beginners. Much of
it is used only as a façon de parler.
The language of this book is similar to that common to almost all math-
ematical disciplines. There is one essential diﬀerence though. In math-
ematics, metalanguage and object language strongly interact with each
other, and the latter is semiformalized in the best of cases. This method
has proved successful. Separating object language and metalanguage is
relevant only in special context, for example in axiomatic set theory, where
formalization is needed to specify what certain axioms look like. Strictly
formal languages are met more often in computer science. In analyzing
complex software or a programming language, as in logic, formal linguistic
entities are the central objects of consideration.
2 The Aristotelian syllogisms are easy but useful examples for inferences in a ﬁrst-order
language with unary predicate symbols. One of these syllogisms serves as an example
in Section 4.6 on logic programming.
xv

xvi
Introduction
The way of arguing about formal languages and theories is traditionally
called the metatheory. An important task of a metatheoretic analysis is
to specify procedures of logical inference by so-called logical calculi, which
operate purely syntactically. There are many diﬀerent logical calculi. The
choice may depend on the formalized language, on the logical basis, and
on certain aims of the formalization. Basic metatheoretic tools are in any
case the naive natural numbers and inductive proof procedures. We will
sometimes call them proofs by metainduction, in particular when talking
about formalized object theories that speak about natural numbers. In-
duction can likewise be carried out on certain sets of strings over a ﬁxed
alphabet, or on the system of rules of a logical calculus.
The logical means of the metatheory are sometimes allowed or even ex-
plicitly required to be diﬀerent from those of the object language. But in
this book the logic of object languages, as well as that of the metalang-
uage, are classical, two-valued logic. There are good reasons to argue that
classical logic is the logic of common sense. Mathematicians, computer
scientists, linguists, philosophers, physicists, and others are using it as a
common platform for communication.
It should be noticed that logic used in the sciences diﬀers essentially
from logic used in everyday language, where logic is more an art than a se-
rious task of saying what follows from what. In everyday life, nearly every
utterance depends on the context. In most cases logical relations are only
alluded to and rarely explicitly expressed. Some basic assumptions of two-
valued logic mostly fail, in particular, a context-free use of the logical con-
nectives. Problems of this type are not dealt with here. To some extent,
many-valued logic or Kripke semantics can help to clarify the situation,
and sometimes intrinsic mathematical methods must be used in order to
solve such problems. We shall use Kripke semantics here for a diﬀerent
goal, though, the analysis of self-referential sentences in Chapter 7.
Let us add some historical remarks, which, of course, a newcomer may
ﬁnd easier to understand after and not before reading at least parts of this
book. In the relatively short period of development of modern mathemat-
ical logic in the twentieth century, some highlights may be distinguished,
of which we mention just a few. Many details on this development can be
found in the excellent biographies [Daw] and [FF] on Gödel and Tarski,
the leading logicians in the last century.

Introduction
xvii
The ﬁrst was the axiomatization of set theory in various ways. The most
important approaches are those of Zermelo (improved by Fraenkel and von
Neumann) and the theory of types by Whitehead and Russell. The latter
was to become the sole remnant of Frege’s attempt to reduce mathematics
to logic. Instead it turned out that mathematics can be based entirely on
set theory as a ﬁrst-order theory. Actually, this became more salient after
the rest of the hidden assumptions by Russell and others were removed
from axiomatic set theory around 1915; see [Hei]. For instance, the notion
of an ordered pair, crucial for reducing the notion of a function to set
theory, is indeed a set-theoretic and not a logical one.
Right after these axiomatizations were completed, Skolem discovered
that there are countable models of the set-theoretic axioms, a drawback
to the hope for an axiomatic characterization of a set. Just then, two
distinguished mathematicians, Hilbert and Brouwer, entered the scene
and started their famous quarrel on the foundations of mathematics. It
is described in a comprehensive manner for instance in [Kl2, Chapter IV]
and need therefore not be repeated here.
As a next highlight, Gödel proved the completeness of Hilbert’s rules for
predicate logic, presented in the ﬁrst modern textbook on mathematical
logic, [HA]. Thus, to some extent, a dream of Leibniz became real, namely
to create an ars inveniendi for mathematical truth. Meanwhile, Hilbert
had developed his view on a foundation of mathematics into a program. It
aimed at proving the consistency of arithmetic and perhaps the whole of
mathematics including its nonﬁnitistic set-theoretic methods by ﬁnitary
means. But Gödel showed by his incompleteness theorems in 1931 that
Hilbert’s original program fails or at least needs thorough revision.
Many logicians consider these theorems to be the top highlights of math-
ematical logic in the twentieth century. A consequence of these theorems
is the existence of consistent extensions of Peano arithmetic in which true
and false sentences live in peaceful coexistence with each other, called
“dream theories” in 7.3. It is an intellectual adventure of holistic beauty
to see wisdom from number theory known for ages, such as the Chinese re-
mainder theorem, simple properties of prime numbers, and Euclid’s char-
acterization of coprimeness (page 249), unexpectedly assuming pivotal
positions within the architecture of Gödel’s proofs. Gödel’s methods were
also basic for the creation of recursion theory around 1936.

xviii
Introduction
Church’s proof of the undecidability of the tautology problem marks an-
other distinctive achievement. After having collected suﬃcient evidence
by his own investigations and by those of Turing, Kleene, and some oth-
ers, Church formulated his famous thesis (see 6.1), although in 1936 no
computers in the modern sense existed nor was it foreseeable that com-
putability would ever play the basic role it does today.
Another highlight of mathematical logic has its roots in the work of
Tarski, who proved ﬁrst the undeﬁnability of truth in formalized languages
as explained in 6.5, and soon thereafter started his fundamental work on
decision problems in algebra and geometry and on model theory, which
ties logic and mathematics closely together. See Chapter 5.
As already mentioned, Hilbert’s program had to be revised. A decisive
step was undertaken by Gentzen, considered to be another groundbreaking
achievement of mathematical logic and the starting point of contemporary
proof theory. The logical calculi in 1.4 and 3.1 are akin to Gentzen’s
calculi of natural deduction.
We further mention Gödel’s discovery that it is not the axiom of choice
(AC) that creates the consistency problem in set theory. Set theory with
AC and the continuum hypothesis (CH) is consistent, provided set theory
without AC and CH is. This is a basic result of mathematical logic that
would not have been obtained without the use of strictly formal methods.
The same applies to the independence proof of AC and CH from the axioms
of set theory by Cohen in 1963.
The above indicates that mathematical logic is closely connected with
the aim of giving mathematics a solid foundation. Nonetheless, we conﬁne
ourself to logic and its fascinating interaction with mathematics, which
characterizes mathematical logic. History shows that it is impossible to
establish a programmatic view on the foundations of mathematics that
pleases everybody in the mathematical community. Mathematical logic
is the right tool for treating the technical problems of the foundations of
mathematics, but it cannot solve its epistemological problems.

Notation
We assume that the reader is familiar with the most basic mathematical
terminology and notation, in particular with the union, intersection, and
complementation of sets, denoted by ∪, ∩, and \, respectively. Here we
summarize only some notation that may diﬀer slightly from author to
author or is speciﬁc for this book. N, Z, Q, R denote the sets of natural
numbers including 0, integers, rational, and real numbers, respectively,
and N+, Q+, R+ the sets of positive members of the corresponding sets.
n, m, i, j, k always denote natural numbers unless stated otherwise. Hence,
extended notation like n ∈N is mostly omitted.
In the following, M, N denote sets, M ⊆N denotes inclusion, while
M ⊂N means proper inclusion (i.e., M ⊆N and M ̸= N). As a rule, we
write M ⊂N only if the circumstance M ̸= N has to be emphasized. If
M is ﬁxed in a consideration and N varies over subsets of M, then M \N
may also be symbolized by \N or ¬N.
∅denotes the empty set, and PM the power set (= set of all subsets)
of M. If one wants to emphasize that all elements of a set S are sets, S is
also called a system or family of sets.  S denotes the union of S, that is,
the set of elements belonging to at least one M ∈S, and  S stands for
the intersection of a nonempty system S, the set of elements belonging to
all M ∈S. If S = {Mi | i ∈I} then  S and  S are mostly denoted by

i∈I Mi and 
i∈I Mi, respectively.
A relation between M and N is a subset of M × N, the set of ordered
pairs (a, b) with a ∈M and b ∈N. A precise deﬁnition of (a, b) is given
on page 114. Such a relation, f say, is said to be a function or mapping
from M to N if for each a ∈M there is precisely one b ∈N with (a, b) ∈f.
This b is denoted by f(a) or fa or af and called the value of f at a. We
denote a function f from M to N also by f : M →N, or by f : x 
→t(x),
provided f(x) = t(x) for some term t (see 2.2). ran f = {fx | x ∈M}
is called the range of f, and dom f = M its domain. idM denotes the
identical function on M, that is, idM(x) = x for all x ∈M.
f : M →N is injective if fx = fy ⇒x = y, for all x, y ∈M, surjective
if ran f = N, and bijective if f is both injective and surjective. The reader
should basically be familiar with this terminology. The phrase “let f be
a function from M to N” is sometimes shortened to “let f : M →N.”
xix

xx
Notation
The set of all functions from a set I to a set M is denoted by M I. If
f, g are functions with ran g ⊆dom f then h: x 
→f(g(x)) is called their
composition (or product). It will preferably be written as h = f ◦g.
Let I and M be sets, f : I →M, and call I the index set. Then f will
often be denoted by (ai)i∈I and is named, depending on the context, an
(indexed) family, an I-tuple, or a sequence. If 0 is identiﬁed with ∅and
n > 0 with {0, 1, . . . , n −1}, as is common in set theory, then M n can
be understood as the set of n-tuples (ai)i<n = (a0, . . . , an−1) of length n
whose members belong to M. In particular, M 0 = {∅}. Also the set of
sequences (a1, . . . , an) with ai ∈M will frequently be denoted by M n. In
concatenating ﬁnite sequences, which has an obvious meaning, the empty
sequence (i.e., ∅), plays the role of a neutral element. (a1, . . . , an) will
mostly be denoted by ⃗a. Note that this is the empty sequence for n = 0,
similar to {a1, . . . , an} for n = 0 always being the empty set. f⃗a means
f(a1, . . . , an) throughout.
If A is an alphabet, i.e., if the elements s ∈A are symbols or at least
named symbols, then the sequence (s1, . . . , sn) ∈An is written as s1 · · · sn
and called a string or a word over A. The empty sequence is called in
this context the empty string. A string consisting of a single symbol s is
termed an atomic string. It will likewise be denoted by s, since it will be
clear from the context whether s means a symbol or an atomic string.
Let ξη denote the concatenation of the strings ξ and η. If ξ = ξ1ηξ2 for
some strings ξ1, ξ2 and η ̸= ∅then η is called a segment (or substring) of
ξ, termed a proper segment in case η ̸= ξ. If ξ1 = ∅then η is called an
initial, if ξ2 = ∅, a terminal segment of ξ.
Subsets P, Q, R, . . . ⊆Mn are called n-ary predicates of M or n-ary re-
lations. A unary predicate will be identiﬁed with the corresponding subset
of M. We may write P⃗a for ⃗a ∈P, and ¬P⃗a for ⃗a /∈P. Metatheoretical
predicates (or properties) cast in words will often be distinguished from
the surrounding text by single quotes, for instance, if we speak of the
syntactic predicate ‘The variable x occurs in the formula α’. We can do
so since quotes inside quotes will not occur in this book. Single-quoted
properties are often used in induction principles or reﬂected in a theory,
while ordinary (“double”) quotes have a stylistic function only.
An n-ary operation of M is a function f : M n →M. Since M 0 = {∅}, a
0-ary operation of M is of the form {(∅, c)}, with c ∈M; it is denoted by

Notation
xxi
c for short and called a constant. Each operation f : Mn →M is uniquely
described by the graph of f, deﬁned as
graph f := {(a1, . . . , an+1) ∈M n+1 | f(a1, . . . , an) = an+1}.1
Both f and graph f are essentially the same, but in most situations it is
more convenient to distinguish between them.
The most important operations are binary ones.
The corresponding
symbols are mostly written between the arguments, as in the following
listing of properties of a binary operation ◦on a set A.
◦: A2 →A is
commutative
if
a ◦b = b ◦a for all a, b ∈A,
associative
if
a ◦(b ◦c) = (a ◦b) ◦c for all a, b, c ∈A,
idempotent
if
a ◦a = a for all a ∈A,
invertible
if
for all a, b ∈A there are x, y ∈A
with a ◦x = b and y ◦a = b.
If H, Θ (read eta, theta) are expressions of our metalanguage, H ⇔Θ
stands for ‘H iﬀΘ’ which abbreviates ‘H if and only if Θ’. Similarly,
H ⇒Θ and H & Θ mean ‘if H then Θ’ and ‘H and Θ’, respectively, and
H∨∨∨Θ is to mean ‘H or Θ.’ This notation does not aim at formalizing the
metalanguage but serves improved organization of metatheoretic state-
ments. We agree that ⇒, ⇔, . . . separate stronger than linguistic binding
particles such as “there is” or “for all.” Therefore, in the statement
‘X ⊢α ⇔X ⊨α, for all X and all α’
(Theorem 1.4.6)
the comma should not be dropped; otherwise, some serious misunder-
standing may arise: ‘X ⊨α for all X and all α ’ is simply false.
H :⇔Θ means that the expression H is deﬁned by Θ. When integrating
formulas in the colloquial metalanguage, one may use certain abbreviating
notation.
For instance, ‘α ≡β and β ≡γ’ is occasionally shortened
to α ≡β ≡γ. (‘the formulas α, β, and β, γ are equivalent’). This is
allowed, since in this book the symbol ≡will never belong to the formal
language from which the formulas α, β, γ are taken. W.l.o.g. or w.l.o.g. is
a colloquial shorthand of “without loss of generality” used in mathematics.
1 This means that the left-hand term graph f is deﬁned by the right-hand term. A
corresponding meaning has := throughout, except in programs and ﬂow diagrams,
where x := t means the allocation of the value of the term t to the variable x.


Chapter 1
Propositional Logic
Propositional logic, by which we here mean two-valued propositional logic,
arises from analyzing connections of given sentences A, B, such as
A and B,
A or B,
not A,
if A then B.
These connection operations can be approximately described by two-
valued logic.
There are other connections that have temporal or local
features, for instance, ﬁrst A then B or here A there B, as well as unary
modal operators like it is necessarily true that, whose analysis goes beyond
the scope of two-valued logic. These operators are the subject of tempo-
ral, modal, or other subdisciplines of many-valued or nonclassical logic.
Furthermore, the connections that we began with may have a meaning in
other versions of logic that two-valued logic only incompletely captures.
This pertains in particular to their meaning in natural or everyday lan-
guage, where meaning may strongly depend on context.
In two-valued propositional logic such phenomena are set aside. This
approach not only considerably simpliﬁes matters, but has the advantage
of presenting many concepts, for instance those of consequence, rule in-
duction, or resolution, on a simpler and more perspicuous level. This will
in turn save a lot of writing in Chapter 2 when we consider the corre-
sponding concepts in the framework of predicate logic.
We will not consider everything that would make sense in two-valued
propositional logic, such as two-valued fragments and problems of deﬁn-
ability and interpolation. The reader is referred instead to [KK] or [Ra1].
We will concentrate our attention more on propositional calculi. While
there exists a multitude of applications of propositional logic, we will not
consider technical applications such as the designing of Boolean circuits
W. Rautenberg, A Concise Introduction to Mathematical Logic,
1
Universitext, DOI 10.1007/978-1-4419-1221-3_1,
c⃝Springer Science+Business Media, LLC 2010

2
1 Propositional Logic
and problems of optimization. These topics have meanwhile been inte-
grated into computer science.
Rather, some useful applications of the
propositional compactness theorem are described comprehensively.
1.1
Boolean Functions and Formulas
Two-valued logic is based on two foundational principles: the principle of
bivalence, which allows only two truth values, namely true and false, and
the principle of extensionality, according to which the truth value of a
connected sentence depends only on the truth values of its parts, not on
their meaning. Clearly, these principles form only an idealization of the
actual relationships.
Questions regarding degrees of truth or the sense-content of sentences
are ignored in two-valued logic.
Despite this simpliﬁcation, or indeed
because of it, such a method is scientiﬁcally successful. One does not even
have to know exactly what the truth values true and false actually are.
Indeed, in what follows we will identify them with the two symbols 1 and
0. Of course, one could have chosen any other apt symbols such as ⊤and
⊥or t and f. The advantage here is that all conceivable interpretations of
true and false remain open, including those of a purely technical nature,
for instance the two states of a gate in a Boolean circuit.
According to the meaning of the word and, the conjunction A and B of
sentences A, B, in formalized languages written as A ∧B or A & B, is true
if and only if A, B are both true and is false otherwise. So conjunction
corresponds to a binary function or operation over the set {0, 1} of truth
values, named the ∧-function and denoted by ∧. It is given by its value
matrix
1
0
0
0

, where, in general,
1◦1 1◦0
0◦1 0◦0

represents the value matrix or
truth table of a binary function
◦with arguments and values in {0, 1}.
The delimiters of these small matrices will usually be omitted.
A function f : {0, 1}n →{0, 1} is called an n-ary Boolean function or
truth function. Since there are 2n n-tuples of 0, 1, it is easy to see that
the number of n-ary Boolean functions is 22n. We denote their totality by
Bn. While B2 has 24 = 16 members, there are only four unary Boolean
functions. One of these is negation, denoted by ¬ and deﬁned by ¬1 = 0
and ¬0 = 1. B0 consists just of the constants 0 and 1.

1.1 Boolean Functions and Formulas
3
The ﬁrst column of the table below contains the common binary connec-
tions with examples of their instantiation in English. The second column
lists some of its traditional symbols, which also denote the corresponding
truth function, and the third its truth table. Disjunction is the inclusive
or and is to be distinguished from the exclusive disjunction. The latter
corresponds to addition modulo 2 and is therefore given the symbol +.
In Boolean circuits the functions +, ↓, ↑are often denoted by xor, nor,
and nand; the latter is also known as the Sheﬀer function. Recall our
agreement in the section Notation that the symbols &, ∨, ⇒, and ⇔
will be used only on the metatheoretic level.
A connected sentence and its corresponding truth function need not be
denoted by the same symbol; for example, one might take ∧for conjunc-
tion and et as the corresponding truth function. But in doing so one would
only be creating extra notation, but no new insights. The meaning of a
symbol will always be clear from the context: if α, β are sentences of a for-
mal language, then α ∧β denotes their conjunction; if a, b are truth values,
then a ∧b just denotes a truth value. Occasionally, we may want to refer
to the symbols ∧, ∨, ¬, . . . themselves, setting their meaning temporarily
aside. Then we talk of the connectives or truth functors ∧, ∨, ¬, . . .
compound sentence
symbol
truth table
conjunction
A and B; A as well as B
∧, &
1
0
0
0
disjunction
A or B
∨, ∨
1
1
1
0
implication
if A then B; B provided A
→, ⇒
1
0
1
1
equivalence
A if and only if B; A iﬀB
↔, ⇔
1
0
0
1
exclusive disjunction
either A or B but not both
+
0
1
1
0
nihilation
neither A nor B
↓
0
0
0
1
incompatibility
not at once A and B
↑
0
1
1
1

4
1 Propositional Logic
Sentences formed using connectives given in the table are said to be
logically equivalent if their corresponding truth tables are identical. This
is the case, for example, for the sentences A provided B and A or not B,
which represent the converse implication, denoted by A ←B.1 It does
not appear in the table, since it arises by swapping A, B in the implication.
This and similar reasons explain why only a few of the sixteen binary
Boolean functions require notation. Another example of logical equivalent
sentences are if A and B then C, and if B then C provided A.
In order to recognize and describe logical equivalence of compound sen-
tences it is useful to create a suitable formalism or a formal language. The
idea is basically the same as in arithmetic, where general statements are
more clearly expressed by means of certain formulas. As with arithmetical
terms, we consider propositional formulas as strings of signs built in given
ways from basic symbols. Among these basic symbols are variables, for
our purposes called propositional variables, the set of which is denoted by
PV. Traditionally, these are symbolized by p0, p1, . . . However, our num-
bering of the variables below begins with p1 rather than with p0, enabling
us later on to represent Boolean functions more conveniently. Further, we
use certain logical signs such as ∧, ∨, ¬, . . . , similar to the signs +, ·, . . . of
arithmetic. Finally, parentheses ( , ) will serve as technical aids, although
these are dispensable, as will be seen later on.
Each time a propositional language is in question, the set of its logi-
cal symbols, called the logical signature, and the set of its variables must
be given in advance. For instance, it is crucial in some applications of
propositional logic in Section 1.5 for PV to be an arbitrary set, and not
a countably inﬁnite one as indicated previously. Put concretely, we de-
ﬁne a propositional language F of formulas built up from the symbols
( , ) , ∧, ∨, ¬ , p1, p2, . . . inductively as follows:
(F1) The atomic strings p1, p2, . . . are formulas, called prime formulas,
also called atomic formulas, or simply prime.
(F2) If the strings α, β are formulas, then so too are the strings (α ∧β),
(α ∨β), and ¬α.
This is a recursive (somewhat sloppily also called inductive) deﬁnition
in the set of strings on the alphabet of the mentioned symbols, that is,
1 Converse implication is used in the programming language PROLOG, see 4.6.

1.1 Boolean Functions and Formulas
5
only those strings gained using (F1) or (F2) are in this context formulas.
Stated set-theoretically, F is the smallest (i.e., the intersection) of all sets
of strings S built from the aforementioned symbols with the properties
(f1) p1, p2, . . . ∈S,
(f2) α, β ∈S ⇒(α ∧β), (α ∨β), ¬α ∈S.
Example. (p1 ∧(p2 ∨¬p1)) is a formula. On the other hand, its initial
segment (p1 ∧(p2 ∨¬p1) is not, because a closing parenthesis is missing.
It is intuitively clear and will rigorously be proved on the next page that
the number of left parentheses occurring in a formula coincides with the
number of its right parentheses.
Remark 1. (f1) and (f2) are set-theoretic translations of (F1) and (F2). Some
authors like to add a third condition to (F1), (F2), namely (F3): No other strings
than those obtained by (F1) and (F2) are formulas in this context. But this at
most underlines that (F1), (F2) are the only formula-building rules; (F3) follows
from our deﬁnition, as its set-theoretic translation by (f1), (f2) indicates. Note
that we do not strictly distinguish between the symbol pi and the prime formula
or atomic string pi. Note also that in the formula deﬁnition parentheses are
needed only for binary connectives, not if a formula starts with ¬. By a slightly
more involved deﬁnition at least the outermost parentheses in formulas of the
form (α◦β) with a binary connective ◦could be saved. Howsoever propositional
formulas are deﬁned, what counts is their unique readability, see page 7.
The formulas deﬁned by (F1), (F2) are called Boolean formulas, because
they are obtained using the Boolean signature { ∧, ∨, ¬}. Should further
connectives belong to the logical signature, for example →or ↔, (F2) of
the above deﬁnition must be augmented accordingly. But unless stated
otherwise, (α →β) and (α ↔β) are here just abbreviations; the ﬁrst is
¬(α ∧¬β), the second is ((α →β) ∧(β →α)).
Occasionally, it is useful to have symbols in the logical signature for
always false and always true, ⊥and ⊤respectively, say, called falsum
and verum and sometimes also denoted by 0 and 1.
These are to be
regarded as supplementary prime formulas, and clause (F1) should be
altered accordingly. However, we prefer to treat ⊥and ⊤as abbreviations:
⊥:= (p1 ∧¬p1) and ⊤:= ¬⊥.
For the time being we let F be the set of all Boolean formulas, although
everything said about F holds correspondingly for any propositional lan-
guage.
Propositional variables will henceforth be denoted by p, q, . . . ,
formulas by α, β, γ, δ, ϕ, . . . , prime formulas also by π, and sets of propo-
sitional formulas by X, Y, Z, where these letters may also be indexed.

6
1 Propositional Logic
For the reason of parenthesis economy in formulas, we set some conven-
tions similar to those used in writing arithmetical terms.
1. The outermost parentheses in a formula may be omitted (if there
are any).
For example, (p ∨q) ∧¬p may be written in place of
((p ∨q) ∧¬p). Note that (p ∨q) ∧¬p is not itself a formula but
denotes the formula ((p ∨q) ∧¬p).
2. In the order ¬, ∧, ∨, →, ↔, each connective binds more strongly
than those following it. Thus, one may write p ∨q ∧¬p instead of
p ∨(q ∧¬p), which means (p ∨(q ∧¬p)) by convention 1.
3. By the multiple use of
→we associate to the right. So p →q →p
is to mean p →(q →p). Multiple occurrences of other binary con-
nectives are associated to the left, for instance, p ∧q ∧¬p means
(p ∧q) ∧¬p. In place of α0 ∧· · · ∧αn and α0∨· · · ∨αn we may write

i⩽n αi and 
i⩽n αi, respectively.
Also, in arithmetic, one normally associates to the left. An exception is
the term xyz, where traditionally association to the right is used, that is,
xyz equals x(yz). Association to the right has some advantages in writing
tautologies in which →occurs several times; for instance in the examples
of tautologies listed in 1.3 on page 18.
The above conventions are based on a reliable syntax in the framework
of which intuitively clear facts, such as the identical number of left and
right parentheses in a formula, are rigorously provable. These proofs are
generally carried out using induction on the construction of a formula. To
make this clear we denote by Eϕ that a property E holds for a string ϕ.
For example, let E mean the property ‘ϕ is a formula that has equally
many right- and left-hand parentheses’.
E is trivially valid for prime
formulas, and if Eα, Eβ then clearly also E(α ∧β), E(α ∨β), and E¬α.
From this we may conclude that E applies to all formulas, our reasoning
being a particularly simple instance of the following
Principle of formula induction. Let E be a property of strings that
satisﬁes the conditions
(o) Eπ for all prime formulas π,
(s) Eα, Eβ ⇒E(α ∧β), E(α ∨β), E¬α, for all α, β ∈F.
Then Eϕ holds for all formulas ϕ.

1.1 Boolean Functions and Formulas
7
The justiﬁcation of this principle is straightforward. The set S of all
strings with property E has, thanks to (o) and (s), the properties (f1)
and (f2) on page 5. But F is the smallest such set. Therefore, F ⊆S.
In words, E applies to all formulas ϕ. Clearly, if other connectives are
involved, condition (s) must accordingly be modiﬁed.
It is intuitively clear and easily conﬁrmed inductively on ϕ that a com-
pound Boolean formula ϕ (i.e., ϕ is not prime) is of the form ϕ = ¬α
or ϕ = (α ∧β) or ϕ = (α ∨β) for suitable α, β ∈F. Moreover, this de-
composition is unique. For instance, (α ∧β) cannot at the same time be
written (α′ ∨β′) with perhaps diﬀerent formulas α′, β′. Thus, compound
formulas have the unique readability property, more precisely, the
Unique formula reconstruction property. Each compound formula
ϕ ∈F is either of the form ¬α or (α ◦β) for some uniquely determined
formulas α, β ∈F, where ◦is either ∧or ∨.
This property is less obvious than it might seem. Nonetheless, the proof
is left as an exercise (Exercise 4) in order to maintain the ﬂow of things. It
may be a surprise to the novice that for the unique formula reconstruction,
parentheses are dispensable throughout. Indeed, propositional formulas,
like arithmetical terms, can be written without any parentheses; this is
realized in Polish notation (= PN), also called preﬁx notation, once widely
used in the logic literature. The idea consists in altering (F2) as follows:
if α, β are formulas then so too are ∧αβ,
∨αβ, and ¬α. Similar to PN is
RPN (reverse Polish notation), still used in some programming languages
like PostScript. RPN diﬀers from PN only in that a connective is placed
after the arguments. For instance, (p ∧(q ∨¬p)) is written in RPN as
pqp¬∨∧. Reading PN or RPN requires more eﬀort due to the high density
of information; but by the same token it can be processed very fast by a
computer or a high-tech printer getting its job as a PostScript program.
The only advantage of the parenthesized version is that its decoding is
somewhat easier for our eye through the dilution of information.
Intuitively it is clear what a subformula of a formula ϕ is; for example,
(q ∧¬p) is a subformula of (p ∨(q ∧¬p)). All the same, for some pur-
poses it is convenient to characterize the set Sf ϕ of all subformulas of ϕ
inductively:
Sf π = {π} for prime formulas π;
Sf ¬α = Sf α ∪{¬α},
Sf(α ◦β) = Sf α ∪Sf β ∪{(α ◦β)} for a binary connective ◦.

8
1 Propositional Logic
Thus, a formula is always regarded as a subformula of itself. The above is
a typical example of a recursive deﬁnition on the construction of formulas.
Another example of such a deﬁnition is the rank rk ϕ of a formula ϕ, which
provides a sometimes more convenient measure of the complexity of ϕ
than its length as a string and occasionally simpliﬁes inductive arguments.
Intuitively, rk ϕ is the highest number of nested connectives in ϕ. Let
rk π = 0 for prime formulas π, and if rk α and rk β are already deﬁned,
then rk ¬α = rk α+1 and rk(α◦β) = max{rk α, rk β}+1. Here ◦denotes
any binary connective. We will not give here a general formulation of
this deﬁnition procedure because it is very intuitive and similar to the
well-known procedure of recursive deﬁnitions on N.
It has been made
suﬃciently clear by the preceding examples.
Its justiﬁcation is based
on the unique reconstruction property and insofar not quite trivial, in
contrast to the proof procedure by induction on formulas that immediately
follows from the deﬁnition of propositional formulas.
If a property is to be proved by induction on the construction of formulas
ϕ, we will say that it is a proof by induction on ϕ. Similarly, the recursive
construction of a function f on F will generally be referred to as deﬁning
f by recursion on ϕ, often somewhat sloppily paraphrased as deﬁning f
by induction on ϕ. Examples are Sf and rk. Others will follow.
Since the truth value of a connected sentence depends only on the truth
values of its constituent parts, we may assign to every propositional vari-
able of α a truth value rather than a sentence, thereby evaluating α,
i.e., calculating a truth value.
Similarly, terms are evaluated in, say,
the arithmetic of real numbers, whose value is then a real (= real num-
ber).
An arithmetical term t in the variables x1, . . . , xn describes an
n-ary function whose arguments and values are reals, while a formula ϕ
in p1, . . . , pn describes an n-ary Boolean function. To be precise, a propo-
sitional valuation, or alternatively, a (propositional) model, is a mapping
w: PV →{0, 1} that can also be understood as a mapping from the set
of prime formulas to {0, 1}. We can extend this to a mapping from the
whole of F to {0, 1} (likewise denoted by w) according to the stipulations
(∗)
w(α ∧β) = wα ∧wβ;
w(α ∨β) = wα ∨wβ;
w¬α = ¬wα.2
By the value wϕ of a formula ϕ under a valuation w: PV →{0, 1}
2 We often use (∗) or (⋆) as a temporary label for a condition (or property) that we
refer back to in the text following the labeled condition.

1.1 Boolean Functions and Formulas
9
we mean the value given by this extension.
We could denote the ex-
tended mapping by ˆw, say, but it is in fact not necessary to distinguish
it symbolically from w: PV →{0, 1} because the latter determines the
extension uniquely. Similarly, we keep the same symbol if an operation
in N extends to a larger domain. If the logical signature contains further
connectives, for example →, then (∗) must be supplemented accordingly,
with w(α →β) = wα →wβ in the example. However, if →is deﬁned as
in the Boolean case, then this equation must be provable. Indeed, it is
provable, because from our deﬁnition of α →β it follows that
w(α →β) = w¬(α ∧¬β) = ¬w(α ∧¬β) = ¬(wα ∧¬wβ) = wα →wβ,
for any w. A corresponding remark could be made with respect to ↔
and to ⊤and ⊥. Always w⊤= 1 and w⊥= 0 by our deﬁnition of ⊤, ⊥,
in accordance with the meaning of these symbols. However, if these or
similar symbols belong to the logical signature, then suitable equations
must be added to the deﬁnition of w.
Let Fn denote the set of all formulas of F in which at most the variables
p1, . . . , pn occur (n > 0).
Then it can easily be seen that wα for the
formula α ∈Fn depends only on the truth values of p1, . . . , pn. In other
words, α ∈Fn satisﬁes for all valuations w, w′,
(⋆)
wα = w′α whenever wpi = w′pi for i = 1, . . . , n.
The simple proof of (⋆) follows from induction on the construction of for-
mulas in Fn, observing that these are closed under the operations ¬, ∧, ∨.
Clearly, (⋆) holds for p ∈Fn, and if (⋆) is valid for α, β ∈Fn, then also
for ¬α, α ∧β, and α ∨β. It is then clear that each α ∈Fn deﬁnes or
represents an n-ary Boolean function according to the following
Deﬁnition. α ∈Fn represents the function f ∈Bn (or f is represented
by α) whenever wα = fw⃗p (:= f(wp1, . . . , wpn)) for all valuations w.
Because wα for α ∈Fn is uniquely determined by wp1, . . . , wpn, α
represents precisely one function f ∈Bn, sometimes written as α(n). For
instance, both p1 ∧p2 and ¬(¬p1 ∨¬p2) represent the ∧-function, as can
easily be illustrated using a table. Similarly, ¬p1 ∨p2 and ¬(p1 ∧¬p2)
represent the
→-function, and p1 ∨p2, ¬(¬p1 ∧¬p2), (p1 →p2) →p2 all
represent the ∨-function. Incidentally, the last formula shows that the
∨-connective can be expressed using implication alone.

10
1 Propositional Logic
There is a caveat though: since α = p1 ∨p2, for instance, belongs
not only to F2 but to F3 as well, α also represents the Boolean function
f : (x1, x2, x3) 
→x1∨x2. However, the third argument is only “ﬁctional,”
or put another way, the function f is not essentially ternary.
In general we say that an operation f : M n →M is essentially n-ary if f
has no ﬁctional arguments, where the ith argument of f is called ﬁctional
whenever for all x1, . . . , xi, . . . xn ∈M and all x′
i ∈M,
f(x1, . . . , xi, . . . , xn) = f(x1, . . . , x′
i, . . . , xn).
Identity and the ¬-function are the essentially unary Boolean functions,
and out of the sixteen binary functions, only ten are essentially binary, as
is seen in scrutinizing the possible truth tables.
Remark 2. If an denotes temporarily the number of all n-ary Boolean func-
tions and en the number of all essentially n-ary Boolean functions, it is not
particularly diﬃcult to prove that an = 
i⩽n
	n
i

ei. Solving for en results in
en = 
i⩽n(−1)n−i	n
i

ai. However, we will not make use of these equations.
These become important only in a more specialized study of Boolean functions.
Exercises
1. f ∈Bn is called linear if f(x1, . . . , xn) = a0 + a1x1 + · · · + anxn for
suitable coeﬃcients a0, . . . , an ∈{0, 1}. Here + denotes exclusive
disjunction (addition modulo 2) and the not written multiplication
is conjunction (i.e., aixi = xi for ai = 1 and aixi = 0 for ai = 0).
(a) Show that the above representation of a linear function f is
unique. (b) Determine the number of n-ary linear Boolean functions.
(c) Prove that each formula α in ¬, + (i.e., α is a formula of the
logical signature {¬, +}) represents a linear Boolean function.
2. Verify that a compound Boolean formula ϕ is either of the form
ϕ = ¬α or else ϕ = (α ∧β) or ϕ = (α ∨β) for suitable formulas α, β
(this is the easy part of the unique reconstruction property).
3. Prove that a proper initial segment of a formula ϕ is never a formula.
Equivalently: If αξ = βη with α, β ∈F and arbitrary strings ξ, η,
then α = β. The same holds for formulas in PN, but not in RPN.
4. Prove (with Exercise 3) the second more diﬃcult part of the unique
reconstruction property, the claim of uniqueness.

1.2 Semantic Equivalence and Normal Forms
11
1.2
Semantic Equivalence and Normal Forms
Throughout this chapter w will always denote a propositional valuation.
Formulas α, β are called (logically or semantically) equivalent, and we
write α ≡β, when wα = wβ for all valuations w. For example α ≡¬¬α.
Obviously, α ≡β iﬀfor any n such that α, β ∈Fn, both formulas represent
the same n-ary Boolean function. It follows that at most 22n formulas in
Fn can be pairwise inequivalent, since there are no more than 22n n-ary
Boolean functions.
In arithmetic one writes simply s = t to express that the terms s, t rep-
resent the same function. For example, (x+y)2 = x2 +2xy +y2 expresses
the equality of values of the left- and right-hand terms for all x, y ∈R.
This way of writing is permissible because formal syntax plays a minor role
in arithmetic. In formal logic, however, as is always the case when syntac-
tic considerations are to the fore, one uses the equality sign in messages
like α = β only for the syntactic identity of the strings α and β. There-
fore, the equivalence of formulas must be denoted diﬀerently. Clearly, for
all formulas α, β, γ the following equivalences hold:
α ∧(β ∧γ) ≡α ∧β ∧γ,
α ∨(β ∨γ) ≡α ∨β ∨γ
(associativity);
α ∧β ≡β ∧α,
α ∨β ≡β ∨α
(commutativity);
α ∧α ≡α,
α ∨α ≡α
(idempotency);
α ∧(α ∨β) ≡α,
α ∨α ∧β ≡α
(absorption);
α ∧(β ∨γ) ≡α ∧β ∨α ∧γ,
( ∧-distributivity);
α ∨β ∧γ ≡(α∨β) ∧(α∨γ)
(∨-distributivity);
¬(α ∧β) ≡¬α ∨¬β,
¬(α ∨β) ≡¬α ∧¬β
(de Morgan rules).
Furthermore, α ∨¬α ≡⊤, α ∧¬α ≡⊥, and α ∧⊤≡α ∨⊥≡α. It is also
useful to list certain equivalences for formulas containing →, for example
the frequently used α →β ≡¬α ∨β (≡¬(α ∧¬β), and the important
α →β →γ ≡α ∧β →γ ≡β →α →γ.
To generalize: α1 →· · · →αn ≡α1 ∧· · · ∧αn−1 →αn. Further, we men-
tion the “left distributivity” of implication with respect to ∧and ∨, namely
α →β ∧γ ≡(α →β) ∧(α →γ);
α →β ∨γ ≡(α →β) ∨(α →γ).
Should the symbol
→lie to the right then the following are valid:
α ∧β →γ ≡(α →γ) ∨(β →γ);
α ∨β →γ ≡(α →γ) ∧(β →γ).

12
1 Propositional Logic
Remark 1. These last two logical equivalences are responsible for a curious
phenomenon in everyday language. For example, the two sentences
A: Students and pensioners pay half price,
B: Students or pensioners pay half price
evidently have the same meaning. How to explain this? Let student and pen-
sioner be abbreviated by S, P, and pay half price by H. Then
α :
(S →H) ∧(P →H),
β :
(S ∨P) →H
express somewhat more precisely the factual content of A and B, respectively.
Now, according to our truth tables, the formulas α and β are simply logically
equivalent. The everyday-language statements A and B of α and β obscure the
structural diﬀerence of α and β through an apparently synonymous use of the
words and and or.
Obviously, ≡is an equivalence relation, that is,
α ≡α
(reﬂexivity),
α ≡β ⇒β ≡α
(symmetry),
α ≡β, β ≡γ ⇒α ≡γ
(transitivity).
Moreover, ≡is a congruence relation on F,3 i.e., for all α, α′, β, β′,
α ≡α′, β ≡β′ ⇒α ◦β ≡α′ ◦β′, ¬α ≡¬α′
(◦∈{ ∧, ∨}).
For this reason the replacement theorem holds: α ≡α′
⇒
ϕ ≡ϕ′,
where ϕ′ is obtained from ϕ by replacing one or several of the possi-
ble occurrences of the subformula α in ϕ by α′.
For instance, by re-
placing the subformula ¬p ∨¬q by the equivalent formula ¬(p ∧q) in
ϕ = (¬p ∨¬q) ∧(p ∨q) we obtain ϕ′ = ¬(p ∧q) ∧(p ∨q), which is equiva-
lent to ϕ. A similar replacement theorem also holds for arithmetical terms
and is constantly used in their manipulation. This mostly goes unnoticed,
because = is written instead of ≡, and the replacement for = is usually
correctly applied. The simple inductive proof of the replacement theorem
will be given in a somewhat broader context in 2.4.
Furnished with the equivalences ¬¬α ≡α, ¬(α ∧β) ≡¬α ∨¬β, and
¬(α ∨β) ≡¬α ∧¬β, and using replacement it is easy to construct for each
formula an equivalent formula in which ¬ stands only in front of variables.
For example, ¬(p ∧q ∨r) ≡¬(p ∧q) ∧¬r ≡(¬p ∨¬q) ∧¬r is obtained in
this way. This observation follows also from Theorem 2.1.
3 This concept, stemming originally from geometry, is meaningfully deﬁned in every
algebraic structure and is one of the most important and most general mathematical
concepts; see 2.1. The deﬁnition is equivalent to the condition
α ≡α′ ⇒α ◦β ≡α′ ◦β, β ◦α ≡β ◦α′, ¬α ≡¬α′, for all α, α′, β.

1.2 Semantic Equivalence and Normal Forms
13
It is always something of a surprise to the newcomer that independent of
its arity, every Boolean function can be represented by a Boolean formula.
While this can be proved in various ways, we take the opportunity to
introduce certain normal forms and therefore begin with the following
Deﬁnition. Prime formulas and negations of prime formulas are called
literals. A disjunction α1∨· · · ∨αn, where each αi is a conjunction of liter-
als, is called a disjunctive normal form, a DNF for short. A conjunction
β1 ∧· · · ∧βn, where every βi is a disjunction of literals, is called a con-
junctive normal form, a CNF for short.
Example 1. The formula p ∨(q ∧¬p) is a DNF; p ∨q is at once a DNF
and a CNF; p ∨¬(q ∧¬p) is neither a DNF nor a CNF.
Theorem 2.1 states that every Boolean function is represented by a
Boolean formula, indeed by a DNF, and also by a CNF. It would suﬃce
to show that for given n there are at least 22n pairwise inequivalent DNFs
(resp. CNFs). However, we present instead a constructive proof whereby
for a Boolean function given in tabular form a representing DNF (resp.
CNF) can explicitly be written down. In Theorem 2.1 we temporarily
use the following notation: p1 := p and p0 := ¬p. With this stipulation,
w(p x1
1
∧p x2
2 ) = 1 iﬀwp1 = x1 and wp2 = x2. More generally, induction
on n ⩾1 easily shows that for all x1, . . . , xn ∈{0, 1},
(∗) w(p x1
1
∧· · · ∧p xn
n ) = 1 ⇔w⃗p = ⃗x (i.e., wp1 = x1, . . . , wpn = xn).
Theorem 2.1. Every Boolean function f with f ∈Bn (n > 0) is repre-
sentable by a DNF, namely by
αf :=

f⃗x=1
p x1
1
∧· · · ∧p xn
n .4
At the same time, f is representable by the CNF
βf :=

f⃗x=0
p¬x1
1
∨· · · ∨p¬xn
n
.
Proof. By the deﬁnition of αf, the following equivalences hold for an
arbitrary valuation w:
4 The disjuncts of αf can be arranged, for instance, according to the lexicographical
order of the n-tuples (x1, . . . , xn) ∈{0, 1}n. If the disjunction is empty (that is, if f
does not take the value 1) let αf be ⊥(= p1 ∧¬p1). Thus, the empty disjunction is
⊥. Similarly, the empty conjunction equals ⊤(= ¬⊥). These conventions correspond
to those in arithmetic, where the empty sum is 0 and the empty product is 1.

14
1 Propositional Logic
wαf = 1
⇔
there is an ⃗x with f⃗x = 1 and w(p x1
1
∧· · · ∧p xn
n ) = 1
⇔
there is an ⃗x with f⃗x = 1 and w⃗p = ⃗x
	
by (∗)

⇔
fw⃗p = 1
(replace ⃗x by w⃗p).
Thus, wαf = 1 ⇔fw⃗p = 1. From this equivalence, and because there
are only two truth values, wαf = fw⃗p follows immediately. The repre-
sentability proof of f by βf runs analogously; alternatively, Theorem 2.4
below may be used.
Example 2. For the exclusive-or function +, the construction of αf
in Theorem 2.1 gives the representing DNF p1 ∧¬p2 ∨¬p1 ∧p2, because
(1, 0), (0, 1) are the only pairs for which + has the value 1. The CNF given
by the theorem, on the other hand, is (p1 ∨p2) ∧(¬p1 ∨¬p2); the equiv-
alent formula (p1 ∨p2) ∧¬(p1 ∧p2) makes the meaning of the exclusive-or
compound particularly intuitive.
p1 ∧p2 ∨¬p1 ∧p2 ∨¬p1 ∧¬p2 is the DNF given by Theorem 2.1 for the
Boolean function
→. It is longer than the formula ¬p1 ∨p2, which is
also a representing DNF. But the former is distinctive in that each of its
disjuncts contains each variable occurring in the formula exactly once.
A DNF of n variables with the analogous property is called canonical.
The notion of canonical CNF is correspondingly explained. For instance,
the function ↔is represented by the canonical CNF (¬p1∨p2) ∧(p1∨¬p2)
according to Theorem 2.1, which always provides canonical normal forms
as representing formulas.
Since each formula represents a certain Boolean function, Theorem 2.1
immediately implies the following fact, which has also a (more lengthy)
syntactical proof with the replacement theorem mentioned on page 12.
Corollary 2.2. Each ϕ ∈F is equivalent to a DNF and to a CNF.
Functional completeness.
A logical signature is called functional
complete if every Boolean function is representable by a formula in this
signature.
Theorem 2.1 shows that {¬, ∧, ∨} is functional complete.
Because of p ∨q ≡¬(¬p ∧¬q) and p ∧q ≡¬(¬p ∨¬q), one can further
leave aside ∨, or alternatively ∧. This observation is the content of
Corollary 2.3. Both {¬, ∧} and {¬, ∨} are functional complete.
Therefore, to show that a logical signature L is functional complete, it
is enough to represent ¬, ∧or else ¬, ∨by formulas in L. For example,

1.2 Semantic Equivalence and Normal Forms
15
because ¬p ≡p →0 and p ∧q ≡¬(p →¬q), the signature { →, 0} is func-
tional complete. On the other hand, { →, ∧, ∨}, and a fortiori { →}, are
not. Indeed, wϕ = 1 for any formula ϕ in
→, ∧, ∨and any valuation w
such that wp = 1 for all p. This can readily be conﬁrmed by induction on
ϕ. Thus, never ¬p ≡ϕ for any such formula ϕ.
It is noteworthy that the signature containing only ↓is functional com-
plete: from the truth table for ↓we get ¬p ≡p ↓p as well as p ∧q ≡¬p ↓¬q.
Likewise for { ↑}, because ¬p ≡p ↑p and p ∨q ≡¬p ↑¬q. That { ↑} must
necessarily be functional complete once we know that { ↓} is will become
obvious in the discussion of the duality theorem below. Even up to term
equivalence, there still exist inﬁnitely many signatures. Here signatures
are called term equivalent if the formulas of these signatures represent the
same Boolean functions as in Exercise 2, for instance.
Deﬁne inductively on the formulas from F a mapping δ : F →F by
pδ = p,
(¬α)δ = ¬αδ,
(α ∧β)δ = αδ ∨βδ,
(α ∨β)δ = αδ ∧βδ.
αδ is called the dual formula of α and is obtained from α simply by inter-
changing ∧and ∨. Obviously, for a DNF α, αδ is a CNF, and vice versa.
Deﬁne the dual of f ∈Bn by fδ⃗x := ¬f¬⃗x with ¬⃗x := (¬x1, . . . , ¬xn).
Clearly fδ2 := (fδ)δ = f since (fδ)δ⃗x = ¬¬f¬¬⃗x = f⃗x.
Note that
∧δ = ∨, ∨δ = ∧, ↔δ= +, ↓δ = ↑, but ¬δ = ¬. In other words, ¬ is self-
dual. One may check by going through all truth tables that essentially
binary self-dual Boolean functions do not exist. But it was Dedekind who
discovered the interesting ternary self-dual function
d3 : (x1, x2, x3) 
→x1 ∧x2 ∨x1 ∧x3 ∨x2 ∧x3.
The above notions of duality are combined in the following
Theorem 2.4 (The duality principle for two-valued logic). If α
represents the function f then αδ represents the dual function f δ.
Proof by induction on α. Trivial for α = p. Let α, β represent f1, f2,
respectively. Then α ∧β represents f : ⃗x 
→f1⃗x ∧f2⃗x, and in view of the
induction hypothesis, (α ∧β)δ = αδ ∨βδ represents g : ⃗x 
→f δ
1⃗x ∨fδ
2⃗x.
This function is just the dual of f because
fδ⃗x = ¬f¬⃗x = ¬(f1¬⃗x ∧f2¬⃗x) = ¬f1¬⃗x ∨¬f2¬⃗x = fδ
1⃗x ∨fδ
2⃗x = g⃗x.
The induction step for ∨is similar. Now let α represent f. Then ¬α
represents ¬f : ⃗x 
→¬f⃗x. By the induction hypothesis, αδ represents fδ.

16
1 Propositional Logic
Thus (¬α)δ = ¬αδ represents ¬fδ, which coincides with (¬f)δ because of
(¬f)δ⃗x = (¬¬f⃗x)¬⃗x = ¬(¬f¬⃗x) = ¬(fδ⃗x).
For example, we know that ↔is represented by p ∧q ∨¬p ∧¬q. Hence,
by Theorem 2.4, + (= ↔δ) is represented by (p∨q) ∧(¬p∨¬q). More gener-
ally, if a canonical DNF α represents f ∈Bn, then the canonical CNF αδ
represents fδ. Thus, if every f ∈Bn is representable by a DNF then ev-
ery f must necessarily be representable by a CNF, since f 
→fδ maps Bn
bijectively onto itself as follows from fδ2 = f. Note also that Dedekind’s
just deﬁned ternary self-dual function d3 shows in view of Theorem 2.4
that p ∧q ∨p ∧r ∨q ∧r ≡(p ∨q) ∧(p ∨r) ∧(q ∨r).
Remark 2. { ∧, ∨, 0, 1} is maximally functional incomplete, that is, if f is any
Boolean function not representable by a formula in ∧, ∨, 0, 1, then { ∧, ∨, 0, 1, f}
is functional complete (Exercise 4). As was shown by E. Post (1920), there are up
to term equivalence only ﬁve maximally functional incomplete logical signatures:
besides { ∧, ∨, 0, 1} only { →, ∧}, the dual of this, {↔, ¬}, and {d3, ¬}. The
formulas of the last one represent just the self-dual Boolean functions. Since
¬p ≡1 + p, the signature {0, 1, +, ·} is functional complete, where · is written
in place of
∧. The deeper reason is that {0, 1, +, ·} is at the same time the
extralogical signature of ﬁelds (see 2.1). Functional completeness in the two-
valued case just derives from the fact that for a ﬁnite ﬁeld, each operation on
its domain is represented by a suitable polynomial. We mention also that for
any ﬁnite set M of truth values considered in many-valued logics there is a
generalized two-argument Sheﬀer function, by which every operation on M can
be obtained, similarly to ↑in the two-valued case.
Exercises
1. Verify the logical equivalences
(p →q1) ∧(¬p →q2) ≡p ∧q1 ∨¬p ∧q2,
p1 ∧q1 →p2 ∨q2 ≡(p1 →p2) ∨(q1 →q2).
2. Show that the signatures {+, 1}, {+, ¬}, {↔, 0}, and {↔, ¬} are all
term equivalent. The formulas of each of these signatures represent
precisely the linear Boolean functions.
3. Show that the formulas in ∧, ∨, 0, 1 represent exactly the monotonic
Boolean functions. These are the constants from B0, and for n > 0
the f ∈Bn such that for all i with 1 ⩽i ⩽n,
f(x1, . . . , xi−1, 0, xi+1, . . . , xn) ⩽f(x1, . . . , xi−1, 1, xi+1, . . . , xn).

1.3 Tautologies and Logical Consequence
17
4. Show that the logical signature { ∧, ∨, 0, 1} is maximally functional
incomplete.
5. If one wants to prove Corollary 2.2 syntactically with the properties
of ≡(page 11) one needs generalizations of the distributivity, e.g.,

i⩽n αi ∧
j⩽m βj ≡
i⩽n, j⩽m(αi ∧βj). Verify the latter.
1.3
Tautologies and Logical Consequence
Instead of wα = 1 we prefer from now on to write w ⊨α and read this w
satisﬁes α. Further, if X is a set of formulas, we write w ⊨X if w ⊨α
for all α ∈X and say that w is a (propositional) model for X. A given α
(resp. X) is called satisﬁable if there is some w with w ⊨α (resp. w ⊨X).
⊨, called the satisﬁability relation, evidently has the following properties:
w ⊨p
⇔
wp = 1
(p ∈PV );
w ⊨¬α
⇔
w ⊭α;
w ⊨α ∧β
⇔
w ⊨α and w ⊨β;
w ⊨α ∨β
⇔
w ⊨α or w ⊨β.
One can deﬁne the satisﬁability relation w ⊨α for a given w: PV →{0, 1}
also inductively on α, according to the clauses just given. This approach
is particularly useful for extending the satisﬁability conditions in 2.3.
It is obvious that w: PV →{0, 1} will be uniquely determined by setting
down in advance for which variables w ⊨p should be valid. Likewise the
notation w ⊨α for α ∈Fn is already meaningful when w is deﬁned only
for p1, . . . , pn. One could extend such a w to a global valuation by setting,
for instance, wp = 0 for all unmentioned variables p.
For formulas containing other connectives the satisfaction conditions
are to be formulated accordingly. For example, we expect
(∗)
w ⊨α →β
⇔
if w ⊨α then w ⊨β.
If
→is taken to be a primitive connective, (∗) is required. However, we
deﬁned
→in such a way that (∗) is provable.
Deﬁnition. α is called logically valid or a (two-valued) tautology, in short
⊨α, whenever w ⊨α for all valuations w. A formula not satisﬁable at all,
i.e. w ⊭α for all w, is called a contradiction.
Examples. p ∨¬p is a tautology and so is α ∨¬α for every formula α,
the so-called law of the excluded middle or the tertium non datur. On the

18
1 Propositional Logic
other hand, α ∧¬α and α ↔¬α are always contradictions. The following
tautologies in
→are mentioned in many textbooks on logic. Remember
our agreement about association to the right in formulas in which
→
repeatedly occurs.
p →p
(self-implication),
(p →q) →(q →r) →(p →r)
(chain rule),
(p →q →r) →(q →p →r)
(exchange of premises),
p →q →p
(premise charge),
(p →q →r) →(p →q) →(p →r)
(Frege’s formula),
((p →q) →p) →p
(Peirce’s formula).
It will later turn out that all tautologies in
→alone are derivable (in a
sense still to be explained) from the last three formulas.
Clearly, it is decidable whether a formula α is a tautology, in that one
tries out the valuations of the variables of α. Unfortunately, no essentially
more eﬃcient method is known; such a method exists only for formulas
of a certain form. We will have a somewhat closer look at this problem
in 4.3. Various questions such as checking the equivalence of formulas
can be reduced to a decision about whether a formula is a tautology. For
notice the obvious equivalence of α ≡β and ⊨α ↔β.
Basic in propositional logic is the following
Deﬁnition. α is a logical consequence of X, written X ⊨α, if w ⊨α for
every model w of X. In short, w ⊨X ⇒w ⊨α, for all valuations w.
While we use ⊨both as the symbol for logical consequence (which is a
relation between sets of formulas X and formulas α) and the satisﬁability
property, it will always be clear from the context what ⊨actually means.
Evidently, α is a tautology iﬀ∅⊨α, so that ⊨α can be regarded as an
abbreviation for ∅⊨α.
In this book, X ⊨α, β will always mean ‘X ⊨α and X ⊨β’. More
generally, X ⊨Y is always to mean ‘X ⊨β for all β ∈Y ’. We also write
throughout α1, . . . , αn ⊨β in place of {α1, . . . , αn} ⊨β, and more brieﬂy,
X, α ⊨β in place of X ∪{α} ⊨β.
Examples of logical consequence. (a) α, β ⊨α ∧β and α ∧β ⊨α, β.
This is evident from the truth table of
∧.
(b) α, α →β ⊨β, because
1 →x = 1 ⇒x = 1 according to the truth table of
→.

1.3 Tautologies and Logical Consequence
19
(c) X ⊨⊥⇒X ⊨α for each α. Indeed, X ⊨⊥= p1 ∧¬p1 obviously
means that X is unsatisﬁable (has no model), as e.g. X = {p2, ¬p2}.
(d) X, α ⊨β & X, ¬α ⊨β ⇒X ⊨β. In order to see this let w ⊨X.
If w ⊨α then X, α ⊨β and hence w ⊨β, and if w ⊭α (i.e., w ⊨¬α)
then w ⊨β clearly follows from X, ¬α ⊨β. Note that (d) reﬂects our case
distinction made in the naive metatheory while proving (d).
Example (a) could also be stated as X ⊨α, β ⇔X ⊨α ∧β.
The
property exempliﬁed by (b) is called the modus ponens when formulated
as a rule of inference, as will be done in 1.6. Example (d) is another
formulation of the often-used procedure of proof by cases: In order to
conclude a sentence β from a set of premises X it suﬃces to show it to be
a logical consequence both under an additional supposition and under its
negation. This is generalized in Exercise 3.
Important are the following general and obvious properties of ⊨:
(R)
α ∈X ⇒X ⊨α
(reﬂexivity),
(M)
X ⊨α & X ⊆X′ ⇒X′ ⊨α
(monotonicity),
(T)
X ⊨Y & Y ⊨α ⇒X ⊨α
(transitivity).
Useful for many purposes is also the closure of the logical consequence
relation under substitution, which generalizes the fact that from p ∨¬p
all tautologies of the form α ∨¬α arise from substituting α for p.
Deﬁnition.
A (propositional) substitution is a mapping σ : PV →F
that is extended in a natural way to a mapping σ : F →F as follows:
(α ∧β)σ = ασ ∧βσ,
(α ∨β)σ = ασ ∨βσ,
(¬α)σ = ¬ασ.
Thus, like valuations, substitutions are considered as operations on the
whole of F. For example, if pσ = α for some ﬁxed p and qσ = q otherwise,
then ϕσ arises from ϕ by substituting α for p at all occurrences of p in
ϕ. From p ∨¬p arises in this way the schema α ∨¬α. For X ⊆F let
Xσ := {ϕσ | ϕ ∈X}. The observation ⊨ϕ ⇒⊨ϕσ turns out to be the
special instance X = ∅of the useful property
(S)
X ⊨α ⇒Xσ ⊨ασ
(substitution invariance).
In order to verify (S), deﬁne wσ for a given valuation w in such a way
that wσp = wpσ. We ﬁrst prove by induction on α that
(∗)
w ⊨ασ ⇔wσ ⊨α.
If α is prime, (∗) certainly holds. As regards the induction step, note that

20
1 Propositional Logic
w ⊨(α ∧β)σ ⇔w ⊨ασ ∧βσ ⇔w ⊨ασ, βσ
⇔wσ ⊨α, β
(induction hypothesis)
⇔wσ ⊨α ∧β.
The reasoning for ∨and ¬ is analogous and so (∗) holds. Now let X ⊨α
and w ⊨Xσ. By (∗), we get wσ ⊨X. Thus wσ ⊨α, and again by (∗),
w ⊨ασ. This conﬁrms (S). Another important property of ⊨that is not
so easily obtained will be proved in 1.4, namely
(F)
X ⊨α ⇒X0 ⊨α for some ﬁnite subset X0 ⊆X.
⊨shares the properties (R), (M), (T), and (S) with almost all classical
and nonclassical (many-valued) propositional consequence relations. This
is to mean a relation ⊢between sets of formulas and formulas of an ar-
bitrary propositional language F that has the properties corresponding
to (R), (M), (T), and (S). These properties are the starting point for a
general and strong theory of logical systems created by Tarski, which un-
derpins nearly all logical systems considered in the literature. Should ⊢
satisfy the property corresponding to (F) then ⊢is called ﬁnitary.
Remark 1. Sometimes (S) is not demanded in deﬁning a consequence relation,
and if (S) holds, one speaks of a structural consequence relation. We omit this
reﬁnement. Notions such as tautology, consistency, maximal consistency, and
so on can be used with reference to any consequence relation ⊢in an arbitrary
propositional language F. For instance, a set of formulas X is called consistent
in ⊢whenever X ⊬α for some α, and maximally consistent if X is consistent but
has no proper consistent extension. ⊢itself is called consistent if X ⊬α for some
X and α (this is equivalent to not ⊢α for all α). Here as always, ⊢α stands for
∅⊢α. If F contains ¬ then the consistency of X is often deﬁned by X ⊢α, ¬α for
no α. But the aforementioned deﬁnition has the advantage of being completely
independent of any assumption concerning the occurring connectives. Another
example of a general deﬁnition is this: A formula set X is called deductively
closed in ⊢provided X ⊢α ⇒α ∈X, for all α ∈F. Because of (R), this
condition can be replaced by X ⊢α ⇔α ∈X. Examples in ⊨are the set of
all tautologies and the whole of F. The intersection of a family of deductively
closed sets is again deductively closed. Hence, each X ⊆F is contained in a
smallest deductively closed set, called the deductive closure of X in ⊢. It equals
{α ∈F | X ⊢α}, as is easily seen. The notion of a consequence relation can
also be deﬁned in terms of properties of the deductive closure. We mention that
(F) holds not just for our relation ⊨that is given by a two-valued matrix, but
for the consequence relation of any ﬁnite logical matrix in any propositional
language. This is stated and at once essentially generalized in Exercise 3 in 5.7
as an application of the ultraproduct theorem.

1.3 Tautologies and Logical Consequence
21
A special property of the consequence relation ⊨, easily provable, is
(D)
X, α ⊨β ⇒X ⊨α →β,
called the (semantic) deduction theorem for propositional logic. To see
this suppose X, α ⊨β and let w be a model for X. If w ⊨α then by the
supposition, w ⊨β, hence w ⊨α →β. If w ⊭α then w ⊨α →β as well.
Hence X ⊨α →β in any case. This proves (D). As is immediately seen,
the converse of (D) holds as well, that is, one may replace ⇒in (D) by
⇔. Iterated application of this simple observation yields
α1, . . . , αn ⊨β ⇔⊨α1 →α2 →· · · →αn →β ⇔⊨α1 ∧α2 ∧· · · ∧αn →β.
In this way, β’s being a logical consequence of a ﬁnite set of premises is
transformed into a tautology. Using (D) it is easy to obtain tautologies.
For instance, to prove ⊨p →q →p, it is enough to verify p ⊨q →p, for
which it in turn suﬃces to show that p, q ⊨p, and this is trivial.
Remark 2. By some simple applications of (D) each of the tautologies in the
examples on page 18 can be obtained, except the formula of Peirce. As we shall
see in Chapter 2, all properties of ⊨derived above and in the exercises will carry
over to the consequence relation of a ﬁrst-order language.
Exercises
1. Use the deduction theorem as in the text in order to prove
(a)
⊨(p →q →r) →(p →q) →(p →r),
(b)
⊨(p →q) →(q →r) →(p →r).
2. Suppose that X ⊨α →β. Prove that X ⊨(γ →α) →(γ →β).
3. Verify the (rule of) disjunctive case distinction: if X, α ⊨γ and
X, β ⊨γ then X, α ∨β ⊨γ. This implication is traditionally written
more suggestively as
X, α ⊨γ X, β ⊨γ
X, α ∨β ⊨γ
.
4. Verify the rules of contraposition (notation as in Exercise 3):
X, α ⊨β
X, ¬β ⊨¬α
;
X, ¬β ⊨¬α
X, α ⊨β
.
5. Let ⊢be a consequence relation and let X be maximally consistent
in ⊢(see Remark 1). Show that X is deductively closed in ⊢.

22
1 Propositional Logic
1.4
A Calculus of Natural Deduction
We will now deﬁne a derivability relation ⊢by means of a calculus op-
erating solely with some structural rules. ⊢turns out to be identical to
the consequence relation ⊨. The calculus ⊢is of the so-called Gentzen
type and its rules are given with respect to pairs (X, α) of formulas X
and formulas α. Another calculus for ⊨, of the Hilbert type, will be con-
sidered in 1.6. In distinction to [Ge], we do not require that X be ﬁnite;
our particular goals here make such a restriction dispensable. If ⊢applies
to the pair (X, α) then we write X ⊢α and say that α is derivable or
provable from X (made precise below); otherwise we write X ⊬α.
Following [Kl1], Gentzen’s name for (X, α), Sequenz, is translated as
sequent. The calculus is formulated in terms of ∧, ¬ and encompasses the
six rules below, called the basic rules. How to operate with these rules will
be explained afterwards. The choice of { ∧, ¬} as the logical signature is
a matter of convenience and justiﬁed by its functional completeness. The
other standard connectives are introduced by the deﬁnitions
α ∨β := ¬(¬α ∧¬β), α →β := ¬(α ∧¬β), α ↔β := (α →β) ∧(β →α).
⊤, ⊥are deﬁned as on page 5.
Of course, one could choose any other
functional complete signature and adapt the basic rules correspondingly.
But it should be observed that a complete calculus in ¬, ∧, ∨, →, say,
must also include basic rules concerning ∨and →, which makes induction
arguments on the basic rules of the calculus more lengthy.
Each of the basic rules below has certain premises and a conclusion.
Only (IS) has no premises. It allows the derivation of all sequents α ⊢α.
These are called the initial sequents, because each derivation must start
with these. (MR), the monotonicity rule, could be weakened. It becomes
even provable if all pairs (X, α) with α ∈X are called initial sequents.
(IS) α ⊢α (initial sequent)
(MR)
X ⊢α
X′ ⊢α (X′ ⊇X),
( ∧1) X ⊢α, β
X ⊢α ∧β
( ∧2) X ⊢α ∧β
X ⊢α, β
(¬1) X ⊢α, ¬α
X ⊢β
(¬2) X, α ⊢β
X, ¬α ⊢β
X ⊢β

1.4 A Calculus of Natural Deduction
23
Here and in the following X ⊢α, β is to mean X ⊢α and X ⊢β. This
convention is important, since X ⊢α, β has another meaning in Gentzen
calculi that operate with pairs of sets of formulas. The rules ( ∧1) and
(¬1) actually have two premises, just like (¬2). Note further that ( ∧2)
really consists of two subrules corresponding to the conclusions X ⊢α
and X ⊢β. In (¬2), X, α means X ∪{α}, and this abbreviated form will
always be used when there is no risk of misunderstanding.
α1, . . . , αn ⊢β stands for {α1, . . . , αn} ⊢β; in particular, α ⊢β for
{α} ⊢β, and ⊢α for ∅⊢α, just as with ⊨.
X ⊢α (read from “X is provable or derivable α”) is to mean that the
sequent (X, α) can be obtained after a stepwise application of the basic
rules. We can make this idea of “stepwise application” of the basic rules
rigorous and formally precise (intelligible to a computer, so to speak) in
the following way: a derivation is to mean a ﬁnite sequence (S0; . . . ; Sn)
of sequents such that every Si is either an initial sequent or is obtained
through the application of some basic rule to preceding elements in the
sequence. Thus, from X is derivable α if there is a derivation (S0; . . . ; Sn)
with Sn = (X, α). A simple example with the end sequent α, β ⊢α ∧β,
or minutely ({α, β}, α ∧β), is the derivation
(α ⊢α ; α, β ⊢α ; β ⊢β ; α, β ⊢β ; α, β ⊢α ∧β).
Here (MR) was applied twice, followed by an application of ( ∧1). Not
shorter would be complete derivation of the sequent (∅, ⊤), i.e., a proof of
⊢⊤. In this example both (¬1) and (¬2) are essentially involved.
Useful for shortening lengthy derivations is the derivation of additional
rules, which will be illustrated with the examples to follow. The second
example, a generalization of the ﬁrst, is the often-used proof method re-
ductio ad absurdum: α is proved from X by showing that the assumption
¬α leads to a contradiction. The other examples are given with respect
to the deﬁned
→-connective. Hence, for instance, the
→-elimination
mentioned below runs in the original language X ⊢¬(α ∧¬β)
X, α ⊢β
.
Examples of derivable rules
X, ¬α ⊢α
X ⊢α
proof
applied
(¬-elimination)
1
X, α ⊢α
(IS), (MR)
2
X, ¬α ⊢α
supposition
3
X ⊢α
(¬2)

24
1 Propositional Logic
X, ¬α ⊢β, ¬β
X ⊢α
proof
applied
(reductio ad absurdum)
1
X, ¬α ⊢β, ¬β
supposition
2
X, ¬α ⊢α
(¬1)
3
X ⊢α
¬-elimination
X ⊢α →β
X, α ⊢β
( →-elimination)
1
X, α, ¬β ⊢α, ¬β
(IS), (MR)
2
X, α, ¬β ⊢α ∧¬β
( ∧1)
3
X ⊢¬(α ∧¬β)
supposition
4
X, α, ¬β ⊢¬(α ∧¬β)
(MR)
5
X, α, ¬β ⊢β
(¬1) on 2 and 4
6
X, α ⊢β
¬-elimination
X ⊢α
X, α ⊢β
X ⊢β
(cut rule)
1
X, ¬α ⊢α
supposition, (MR)
2
X, ¬α ⊢¬α
(IS), (MR)
3
X, ¬α ⊢β
(¬1)
4
X, α ⊢β
supposition
5
X ⊢β
(¬2) on 4 and 3
X, α ⊢β
X ⊢α →β
( →-introduction)
1
X, α ∧¬β, α ⊢β
supposition, (MR)
2
X, α ∧¬β ⊢α
(IS), (MR), ( ∧2)
3
X, α ∧¬β ⊢β
cut rule
4
X, α ∧¬β ⊢¬β
(IS), (MR), ( ∧2)
5
X, α ∧¬β ⊢α →β
(¬1)
6
X, ¬(α ∧¬β) ⊢α →β
(IS), (MR)
7
X ⊢α →β
(¬2) on 5 and 6
Remark 1. The example of
→-introduction is nothing other than the syntactic
form of the deduction theorem that was semantically formulated in the previous
section. The deduction theorem also holds for intuitionistic logic. However, it is
not in general true for all logical systems dealing with implication, thus indicating
that the deduction theorem is not an inherent property of every meaningful
conception of implication. For instance, the deduction theorem does not hold
for certain formal systems of relevance logic that attempt to model implication
as a cause-and-eﬀect relation.

1.4 A Calculus of Natural Deduction
25
A simple application of the
→-elimination and the cut rule is a proof
of the detachment rule
X ⊢α, α →β
X ⊢β
.
Indeed, the premise X ⊢α →β yields X, α ⊢β by
→-elimination, and
since X ⊢α, it follows X ⊢β by the cut rule. Applying detachment on
X = {α, α →β}, we obtain α, α →β ⊢β. This collection of sequents is
known as modus ponens. It will be more closely considered in 1.6.
Many properties of ⊢are proved through rule induction, which we de-
scribe after introducing some convenient terminology. We identify a prop-
erty E of sequents with the set of all pairs (X, α) to which E applies. In
this sense the logical consequence relation ⊨is the property that applies
to all pairs (X, α) with X ⊨α.
All the rules considered here are of the form
R :
X1 ⊢α1
· · ·
Xn ⊢αn
X ⊢α
and are referred to as Gentzen-style rules. We say that E is closed under
R when E(X1, α1), . . . , E(Xn, αn) implies E(X, α).
For a rule without
premises, i.e., n = 0, this is just to mean E(X, α). For instance, consider
the above already mentioned property E : X ⊨α. This property is closed
under each basic rule of ⊢. In detail this means
α ⊨α,
X ⊨α ⇒X′ ⊨α for X′ ⊇X, X ⊨α, β ⇒X ⊨α ∧β, etc.
From the latter we may conclude that E applies to all provable sequents;
in other words, ⊢is (semantically) sound. What we need here to verify
this conclusion is the following easily justiﬁable
Principle of rule induction. Let E (⊆PF × F) be a property closed
under all basic rules of ⊢. Then X ⊢α implies E(X, α).
Proof by induction on the length of a derivation of S = (X, α). If
the length is 1, ES holds since S must be an initial sequent. Now let
(S0; . . . ; Sn) be a derivation of the sequent S := Sn. By the induction
hypothesis we have ESi for all i < n. If S is an initial sequent then ES
holds by assumption. Otherwise S has been obtained by the application
of a basic rule on some of the Si for i < n. But then ES holds, because E
is closed under all basic rules.

26
1 Propositional Logic
As already remarked, the property X ⊨α is closed under all basic
rules. Therefore, the principle of rule induction immediately yields the
soundness of the calculus, that is, ⊢⊆⊨. More explicitly,
X ⊢α ⇒X ⊨α, for all X, α.
There are several equivalent deﬁnitions of ⊢.
A purely set-theoretic
one is the following: ⊢is the smallest of all relations ⊆PF × F that are
closed under all basic rules. ⊢is equally the smallest consequence relation
closed under the rules ( ∧1) through (¬2). The equivalence proofs of such
deﬁnitions are wordy but not particularly contentful. We therefore do not
elaborate further, because we henceforth use only rule induction. Using
rule induction one can also prove X ⊢α ⇒Xσ ⊢ασ, and in particular
the following theorem, for which the soundness of ⊢is irrelevant.
Theorem 4.1 (Finiteness theorem for ⊢). If X ⊢α then there is a
ﬁnite subset X0 ⊆X with X0 ⊢α.
Proof. Let E(X, α) be the property ‘X0 ⊢α for some ﬁnite X0 ⊆X’.
We will show that E is closed under all basic rules. Certainly, E(X, α)
holds for X = {α}, with X0 = X so that E is closed under (MI). If X has
a ﬁnite subset X0 such that X0 ⊢α, then so too does every set X′ such
that X′ ⊇X. Hence E is closed under (MR). Let E(X, α), E(X, β), with,
say, X1 ⊢α, X2 ⊢β for ﬁnite X1, X2 ⊆X. Then we also have X0 ⊢α, β
for X0 = X1 ∪X2 by (MR). Hence X0 ⊢α ∧β by ( ∧1). Thus E(X, α ∧β)
holds, and E is closed under ( ∧1). Analogously one shows the same for
all remaining basic rules of ⊢so that rule induction can be applied.
Of great signiﬁcance is the notion of formal consistency. It fully de-
termines the derivability relation, as the lemma to come shows. It will
turn out that consistent formalizes adequately the notion satisﬁable. The
proof of this adequacy is the clue to the completeness problem.
Deﬁnition. X ⊆F is called inconsistent (in our calculus ⊢) if X ⊢α for
all α ∈F, and otherwise consistent. X is called maximally consistent if
X is consistent but each Y ⊃X is inconsistent.
The inconsistency of X can be identiﬁed by the derivability of a single
formula, namely ⊥(= p1 ∧¬p1), because X ⊢⊥implies X ⊢p1, ¬p1 by
( ∧2), hence X ⊢α for all α by (¬1). Conversely, when X is inconsistent

1.4 A Calculus of Natural Deduction
27
then in particular X ⊢⊥. Thus, X ⊢⊥may be read as ‘X is inconsistent’,
and X ⊬⊥as ‘X is consistent’. From this it easily follows that X is
maximally consistent iﬀeither α ∈X or ¬α ∈X for each α. The latter
is necessary, for if α, ¬α /∈X then both X, α ⊢⊥and X, ¬α ⊢⊥, hence
X ⊢⊥by (¬2). This contradicts the consistency of X. Suﬃciency is
obvious. Most important is the following lemma, in which the properties
C+ and C−can also be understood each as a pair of provable rules.
Lemma 4.2. The derivability relation ⊢has the properties
C+ :
X ⊢α ⇔X, ¬α ⊢⊥,
C−:
X ⊢¬α ⇔X, α ⊢⊥.
Proof. Suppose that X ⊢α. Then clearly X, ¬α ⊢α and since certainly
X, ¬α ⊢¬α, we have X, ¬α ⊢β for all β by (¬1), in particular X, ¬α ⊢⊥.
Conversely, let X, ¬α ⊢⊥be the case, so that in particular X, ¬α ⊢α,
and thus X ⊢α by ¬-elimination on page 23.
Property C−is proved
completely analogously.
The claim ⊨⊆⊢, not yet proved, is equivalent to X ⊬α ⇒X ⊭α,
for all X and α. But so formulated it becomes apparent what needs to
be done to obtain the proof. Since X ⊬α is by C+ equivalent to the
consistency of X′ := X ∪{¬α}, and likewise X ⊭α to the satisﬁability
of X′, we need only show that consistent sets are satisﬁable. To this end
we state the following lemma, whose proof, exceptionally, jumps ahead of
matters in that it uses Zorn’s lemma from 2.1 (page 46).
Lemma 4.3 (Lindenbaum’s theorem). Every consistent set X ⊆F
can be extended to a maximally consistent set X′ ⊇X.
Proof. Let H be the set of all consistent Y ⊇X, partially ordered with
respect to ⊆. H ̸= ∅, because X ∈H. Let K ⊆H be a chain, i.e.,
Y ⊆Z or Z ⊆Y , for all Y, Z ∈K. Claim: U :=  K is an upper bound
for K. Since Y ∈K ⇒Y ⊆U, we have to show that U is consistent.
Assume that U ⊢⊥. Then U0 ⊢⊥for some ﬁnite U0 = {α0, . . . , αn} ⊆U.
If, say, αi ∈Yi ∈K, and Y is the biggest of the sets Y0, . . . , Yn, then
αi ∈Y for all i ⩽n, hence also Y ⊢⊥by (MR). This contradicts Y ∈H
and conﬁrms the claim. By Zorn’s lemma, H has a maximal element X′,
which is necessarily a maximally consistent extension of X.
Remark 2. The advantage of this proof is that it is free of assumptions regarding
the cardinality of the language, while Lindenbaum’s original construction was

28
1 Propositional Logic
based on countable languages F and runs as follows: Let X0 := X ⊆F be
consistent and let α0, α1, . . . be an enumeration of F. Put Xn+1 = Xn ∪{αn}
if this set is consistent and Xn+1 = Xn otherwise. Then Y = 
n∈ω Xn is a
maximally consistent extension of X, as can be easily veriﬁed. In this proof,
Zorn’s lemma, which is equivalent to the axiom of choice, is not required.
Lemma 4.4. A maximally consistent set X ⊆F has the property
[¬]
X ⊢¬α ⇔X ⊬α, for arbitrary α.
Proof. If X ⊢¬α, then X ⊢α cannot hold due to the consistency of X.
If, on the other hand, X ⊬α, then X, ¬α is a consistent extension of X
according by C+. But then ¬α ∈X, because X is maximally consistent.
Consequently X ⊢¬α.
Lemma 4.5. A maximally consistent set X is satisﬁable.
Proof. Deﬁne w by w ⊨p ⇔X ⊢p. We will show that for all α,
(∗)
X ⊢α ⇔w ⊨α.
For prime formulas this is trivial. Further,
X ⊢α ∧β
⇔
X ⊢α, β
(rules ( ∧1), ( ∧2) )
⇔
w ⊨α, β
(induction hypothesis)
⇔
w ⊨α ∧β
(deﬁnition)
X ⊢¬α
⇔
X ⊬α
(Lemma 4.4)
⇔
w ⊭α
(induction hypothesis)
⇔
w ⊨¬α
(deﬁnition).
By (∗), w is a model for X, thereby completing the proof.
Only the properties [ ∧] X ⊢α ∧β ⇔X ⊢α, β and [¬] from Lemma 4.4
are used in the simple model construction in Lemma 4.5, which reveals
the requirements for propositional model construction in the base { ∧, ¬}.
Since maximally consistent sets X are deductively closed (Exercise 5
in 1.3), these requirements may also be stated as
( ∧) α ∧β ∈X ⇔α, β ∈X
;
(¬) ¬α ∈X ⇔α /∈X.
Lemma 4.3 and Lemma 4.5 conﬁrm the equivalence of the consistency
and the satisﬁability of a set of formulas. From this fact we easily obtain
the main result of the present section.
Theorem 4.6 (Completeness theorem). X ⊢α ⇔X ⊨α, for all
formula sets X and formulas α.

1.4 A Calculus of Natural Deduction
29
Proof. The direction ⇒is the soundness of ⊢. Conversely, X ⊬α implies
that X, ¬α is consistent. Let Y be a maximally consistent extension of
X, ¬α according to Lemma 4.3. By Lemma 4.5, Y is satisﬁable, hence
also X, ¬α. Therefore X ⊭α.
An immediate consequence of Theorem 4.6 is the ﬁniteness property
(F) mentioned in 1.3, which is almost trivial for ⊢but not for ⊨:
Theorem 4.7 (Finiteness theorem for ⊨). If X ⊨α, then so too
X0 ⊨α for some ﬁnite subset X0 of X.
This is clear because the ﬁniteness theorem holds for ⊢(Theorem 4.1),
hence also for ⊨. A further highly interesting consequence of the com-
pleteness theorem is
Theorem 4.8 (Propositional compactness theorem). A set X of
propositional formulas is satisﬁable if each ﬁnite subset of X is satisﬁable.
This theorem holds because if X is unsatisﬁable, i.e., if X ⊨⊥, then, by
Theorem 4.7, we also know that X0 ⊨⊥for some ﬁnite X0 ⊆X, thus
proving the claim indirectly. Conversely, one easily obtains Theorem 4.7
from Theorem 4.8; both theorems are directly derivable from one another.
Because Theorem 4.6 makes no assumptions regarding the cardinality of
the set of variables, the compactness theorem following from it is likewise
valid without the respective restrictions. This means that Theorem 4.8
has many useful applications, as the next section will illustrate.
Let us notice that there are direct proofs of Theorem 4.8 or appropri-
ate reformulations that have nothing to do with a logical calculus. For
example, the theorem is equivalent to

α∈X Md α = ∅⇒
α∈X0 Md α = ∅for some ﬁnite X0 ⊆X,
where Md α denotes the set of all models of α. In this formulation the
compactness of a certain naturally arising topological space is claimed.
The points of this space are the valuations of the variables, hence the
name “compactness theorem.” More on this can be found in [RS].
Another approach to completeness (probably the simplest one) is pro-
vided by Exercises 3 and 4. This approach makes some elegant use of
substitutions, hence is called the completeness proof by the substitution
method. This method is explained in the Solution Hints (and in more
detail in [Ra3]). It yields the maximality of the derivability relation ⊢

30
1 Propositional Logic
(see Exercise 3), a much stronger result than its semantic completeness.
This result yields not only the Theorems 4.6, 4.7, and 4.8 in one go, but
also some further remarkable properties: Neither new tautologies nor new
Hilbert style rules can consistently be adjoined to the calculus ⊢. These
properties (discussed in detail, e.g., in [Ra1]) are known under the names
Post completeness and structural completeness of ⊢, respectively.
Exercises
1. Prove using Theorem 4.7: if X ∪{¬α | α ∈Y } is inconsistent and
Y is nonempty, then there exist formulas α0, . . . , αn ∈Y such that
X ⊢α0 ∨· · · ∨αn.
2. Augment the signature {¬, ∧} by ∨and prove the completeness of
the calculus obtained by supplementing the basic rules used so far
with the rules
(∨1)
X ⊢α
X ⊢α ∨β, β ∨α
;
(∨2) X, α ⊢γ X, β ⊢γ
X, α ∨β ⊢γ
.
3. Let ⊢be a ﬁnitary consistent consequence relation in F{ ∧, ¬} with
the properties ( ∧1) through (¬2).
Show that ⊢is maximal (or
maximally consistent). This means that each consequence relation
⊢′ ⊃⊢in F{ ∧, ¬} is inconsistent, i.e., ⊢′ α for all α.
4. Show by referring to Exercise 3: there is exactly one (consistent)
consequence relation in F{ ∧, ¬} satisfying ( ∧1)–(¬2). This clearly
entails the completeness of ⊢.
1.5
Applications of the Compactness Theorem
Theorem 4.8 is very useful in carrying over certain properties of ﬁnite
structures to inﬁnite ones. This section presents some typical examples.
While these could also be treated with the compactness theorem of ﬁrst-
order logic in 3.3, the examples demonstrate how the consistency of cer-
tain sets of ﬁrst-order sentences can also be obtained in propositional logic.
This approach to consistency is also useful also for Herbrand’s theorem
and related results concerning logic programming.

1.5 Applications of the Compactness Theorem
31
1. Every set M can be (totally) ordered.5
This means that there is an irreﬂexive, transitive, and connex relation <
on M. For ﬁnite M this follows easily by induction on the number of
elements of M. The claim is obvious when M = ∅or is a singleton. Let
now M = N ∪{a} with an n-element set N and a /∈N, so that M has
n + 1 elements. Then we clearly get an order on M from that for N by
“setting a to the end,” that is, deﬁning x < a for all x ∈N.
Now let M be any set. We consider for every pair (a, b) ∈M × M a
propositional variable pab. Let X be the set consisting of the formulas
¬paa
(a ∈M),
pab ∧pbc →pac
(a, b, c ∈M),
pab ∨pba
(a ̸= b).
From w ⊨X we obtain an order <, simply by putting a < b ⇔w ⊨pab.
w ⊨¬paa says the same thing as a ≮a.
Analogously, the remaining
formulas of X reﬂect transitivity and connexity. Thus, according to The-
orem 4.8, it suﬃces to show that every ﬁnite subset X0 ⊆X has a model.
In X0 only ﬁnitely many variables occur.
Hence, there are ﬁnite sets
M1 ⊆M and X1 ⊇X0, where X1 is given exactly as X except that a, b, c
now run through the ﬁnite set M1 instead of M. But X1 is satisﬁable,
because if < orders the ﬁnite set M1 and w is deﬁned by w ⊨pab iﬀa < b,
then w is clearly a model for X1, hence also for X0.
2. The four-color theorem for inﬁnite planar graphs.
A simple graph is a pair (V, E) with an irreﬂexive symmetrical relation
E ⊆V 2. The elements of V are called points or vertices. It is convenient
to identify E with the set of all unordered pairs {a, b} such that aEb and
to call these pairs the edges of (V, E). If {a, b} ∈E then we say that a, b
are neighbors. (V, E) is said to be k-colorable if V can be decomposed
into k color classes C1, . . . , Ck ̸= ∅, V = C1 ∪· · · ∪Ck, with Ci ∩Cj = ∅
for i ̸= j, such that neighboring points do not carry the same color; in
other words, if a, b ∈Ci then {a, b} /∈E for i = 1, . . . , k.
5 Unexplained notions are deﬁned in 2.1. Our ﬁrst application is interesting because in
set theory the compactness theorem is weaker than the axiom of choice (AC) which
is equivalent to the statement that every set can be well-ordered. Thus, the ordering
principle is weaker than AC since it follows from the compactness theorem.

32
1 Propositional Logic
t
t





t
T
T
T
T
T
T

Q
Q
Q
Q
t
The ﬁgure shows the smallest four-colorable graph
that is not three-colorable; all its points neighbor
each other.
We will show that a graph (V, E) is
k-colorable if every ﬁnite subgraph (V0, E0) is k-
colorable. E0 consists of the edges {a, b} ∈E with
a, b ∈V0. To prove our claim consider the following set X of formulas
built from the variables pa,i for a ∈V and 1 ⩽i ⩽k:
pa,1 ∨· · · ∨pa,k,
¬(pa,i ∧pa,j)
(a ∈V, 1 ⩽i < j ⩽k),
¬(pa,i ∧pb,i)
({a, b} ∈E, i = 1, . . . , k).
The ﬁrst formula states that every point belongs to at least one color class;
the second ensures their disjointedness, and the third that no neighboring
points have the same color. Once again it is enough to construct some
w ⊨X. Deﬁning then the Ci by a ∈Ci ⇔w ⊨pa,i proves that (V, E) is
k-colorable. We must therefore satisfy each ﬁnite X0 ⊆X. Let (V0, E0)
be the ﬁnite subgraph of (V, E) of all the points that occur as indices in
the variables of X0. The assumption on (V0, E0) obviously ensures the
satisﬁability of X0 for reasons analogous to those given in Example 1, and
this is all we need to show. The four-color theorem says that every ﬁnite
planar graph is four-colorable. Hence, the same holds for all graphs whose
ﬁnite subgraphs are planar. These cover in particular all planar graphs
embeddable in the real plane.
3. König’s tree lemma. There are several versions of this lemma. For
simplicity, ours refers to a directed tree. This is a pair (V, ◁) with an
irreﬂexive relation ◁⊆V 2 such that for a certain point c, the root of the
tree, and any other point a there is precisely one path connecting c with
a. This is a sequence (ai)i⩽n with a0 = c, an = a, and ai ◁ai+1 for all
i < n. From the uniqueness of a path connecting c with any other point
it follows that each b ̸= c has exactly one predecessor in (V, ◁), that is,
there is precisely one a with a ◁b. Hence the name tree.
König’s lemma then reads as follows: If every a ∈V has only ﬁnitely
many successors and V contains arbitrarily long ﬁnite paths, then there
is an inﬁnite path through V starting at c. By such a path we mean a
sequence (ci)i∈N such that c0 = c and ck ◁ck+1 for each k. In order
to prove the lemma we deﬁne the “layer” Sk inductively by S0 = {c}
and Sk+1 = {b ∈V | there is some a ∈Sk with a ◁b}. Since every point

1.5 Applications of the Compactness Theorem
33
has only ﬁnitely many successors, each Sk is ﬁnite, and since there are
arbitrarily long paths c ◁a1 ◁· · · ◁ak and ak ∈Sk, no Sk is empty.
Now let pa for each a ∈V be a propositional variable, and let X consist
of the formulas
(A)

a∈Sk pa,
¬(pa ∧pb)
	
a, b ∈Sk, a ̸= b, k ∈N

,
(B)
pb →pa
	
a, b ∈V, a ◁b

.
Suppose that w ⊨X. Then by the formulas under (A), for every k there
is precisely one a ∈Sk with w ⊨pa, denoted by ck. In particular, c0 = c.
Moreover, ck ◁ck+1 for all k. Indeed, if a is the predecessor of b = ck+1,
then w ⊨pa in view of (B), hence necessarily a = ck. Thus, (ci)i∈N is a
path of the type sought. Again, every ﬁnite subset X0 ⊆X is satisﬁable;
for if X0 contains variables with indices up to at most the layer Sn, then
X0 is a subset of a ﬁnite set of formulas X1 that is deﬁned as X, except
that k runs only up to n, and for this case the claim is obvious.
4. The marriage problem (in linguistic guise).
Let N ̸= ∅be a set of words or names (in speech) with meanings in a set
M. A name ν ∈N can be a synonym (i.e., it shares its meaning with other
names in N), or a homonym (i.e., it can have several meanings), or even
both. We proceed from the plausible assumption that each name ν has
ﬁnitely many meanings only and that k names have at least k meanings.
It is claimed that a pairing-oﬀexists; that is, an injection f : N →M
that associates to each ν one of its original meanings.
For ﬁnite N, the claim will be proved by induction on the number n of
elements of N. It is trivial for n = 1. Now let n > 1 and assume that the
claim holds for all k-element sets of names whenever 0 < k < n.
Case 1: For each k (0 < k < n): k names in N have at least k + 1
distinct meanings. Then to an arbitrarily chosen ν from N, assign one of
its meanings a to it so that from the names out of N \{ν} any k names
still have at least k meanings ̸= a. By the induction hypothesis there is a
pairing-oﬀfor N \{ν} that together with the ordered pair (ν, a) yields a
pairing-oﬀfor the whole of N.
Case 2: There is some k-element K ⊆N (0 < k < n) such that the
set MK of meanings of the ν ∈K has only k members. Every ν ∈K
can be assigned its meaning from MK by the induction hypothesis. From
the names in N \K any i names (i ⩽n −k) still have i meanings not in
MK, as is not hard to see. By the induction hypothesis there is also a

34
1 Propositional Logic
pairing-oﬀfor N \K with a set of values from M \MK. Joining the two
obviously results in a pairing-oﬀfor the whole of N.
We will now prove the claim for arbitrary sets of names N: assign to
each pair (ν, a) ∈N × M a variable pν,a and consider the set of formulas
X :
 pν,a ∨· · · ∨pν,e
(ν ∈N, a, . . . , e the meanings of ν),
¬(pν,x ∧pν,y)
(ν ∈N, x, y ∈M, x ̸= y).
Assume that w ⊨X. Then to each ν there is exactly one aν with w ⊨pν,aν,
so that {(ν, αn) | ν ∈N} is a pairing-oﬀfor N. Such a model w exists by
Theorem 4.8, for in a ﬁnite set X0 ⊆X occur only ﬁnitely many names
as indices and the case of ﬁnitely many names has just been treated.
5. The ultraﬁlter theorem.
This theorem is of fundamental signiﬁcance in topology (from which it
originally stems), model theory, set theory, and elsewhere. Let I be any
nonempty set. A nonempty collection of sets F ⊆PI is called a ﬁlter on
I if for all M, N ⊆I hold the conditions
(a) M, N ∈F ⇒M ∩N ∈F,
(b) M ∈F & M ⊆N ⇒N ∈F.
Since F ̸= ∅, (b) shows that always I ∈F. As is easily veriﬁed, (a) and
(b) together are equivalent to just a single condition, namely to
(∩)
M ∩N ∈F ⇔M ∈F and N ∈F.
For ﬁxed K ⊆I, {J ⊆I | J ⊇K} is a ﬁlter, the principal ﬁlter generated
by K. This is a proper ﬁlter provided K ̸= ∅, which in general is to mean
a ﬁlter with ∅/∈F. Another example on an inﬁnite I is the set of all
coﬁnite subsets M ⊆I, i.e., ¬M (= I \M) is ﬁnite. This holds because
M1 ∩M2 is coﬁnite iﬀM1, M2 are both coﬁnite, so that (∩) is satisﬁed.
A ﬁlter F is said to be an ultraﬁlter on I provided it satisﬁes, in addition,
(¬)
¬M ∈F ⇔M /∈F.
Ultraﬁlters on an inﬁnite set I containing all coﬁnite subsets are called
nontrivial. That such ultraﬁlters exist will be shown below. It is nearly
impossible to describe them more closely. Roughly speaking, “we know
they exist but we cannot see them.” A trivial ultraﬁlter on I contains at
least one ﬁnite subset. {J ⊆I | i0 ∈J} is an example for each i0 ∈I.
This is a principal ultraﬁlter.
All trivial ultraﬁlters are of this form,
Exercise 3. Thus, trivial and principal ultraﬁlters coincide. In particular,
each ultraﬁlter on a ﬁnite set I is trivial in this sense.

1.6 Hilbert Calculi
35
Each proper ﬁlter F obviously satisﬁes the assumption of the following
theorem and can thereby be extended to an ultraﬁlter.
Theorem 5.1 (Ultraﬁlter theorem). Every subset F ⊆PI can be
extended to an ultraﬁlter U on a set I, provided M0 ∩· · · ∩Mn ̸= ∅for all
n and all M0, . . . , Mn ∈F.
Proof. Consider along with the propositional variables pJ for J ⊆I
X :
pM∩N ↔pM ∧pN,
p¬M ↔¬pM ,
pJ
(M, N ⊆I, J ∈F).
Let w ⊨X. Then (∩), (¬) are valid for U := {J ⊆I | w ⊨pJ}; hence U
is an ultraﬁlter such that F ⊆U. It therefore suﬃces to show that every
ﬁnite subset of X has a model, for which it is in turn enough to prove the
ultraﬁlter theorem for ﬁnite F. But this is easy: Let F = {M0, . . . , Mn},
D := M0 ∩· · · ∩Mn, and i0 ∈D. Then U = {J ⊆I | i0 ∈J} is an
ultraﬁlter containing F.
Exercises
1. Prove (using the compactness theorem) that every partial order ⩽0
on a set M can be extended to a total order ⩽on M.
2. Let F be a proper ﬁlter on I (̸= ∅). Show that F is an ultraﬁlter iﬀ
it satisﬁes (∪): M ∪N ∈F ⇔M ∈F or N ∈F.
3. Let I be an inﬁnite set. Show that an ultraﬁlter U on I is trivial iﬀ
there is an i0 ∈I such that U = {J ⊆I | i0 ∈J}.
1.6
Hilbert Calculi
In a certain sense the simplest logical calculi are so-called Hilbert calculi.
They are based on tautologies selected to play the role of logical axioms;
this selection is, however, rather arbitrary and depends considerably on
the logical signature. They use rules of inference such as, for example,
modus ponens MP: α, α →β/β.6 An advantage of these calculi consists
6 Putting it crudely, this notation should express the fact that β is held to be proved
from a formula set X when α and α →β are provable from X. Modus ponens is an
example of a binary Hilbert-style rule; for a general deﬁnition of this type of rule see,
for instance, [Ra1].

36
1 Propositional Logic
in the fact that formal proofs, deﬁned below as certain ﬁnite sequences,
are immediately rendered intuitive. This advantage will pay oﬀabove all
in the arithmetization of proofs in 6.2.
In the following we consider such a calculus with MP as the only rule
of inference; we denote this calculus for the time being by |∼, in order to
distinguish it from the calculus ⊢of 1.4. The logical signature contains
just ¬ and ∧, the same as for ⊢. In the axioms of |∼, however, we will
also use implication deﬁned by α →β := ¬(α ∧¬β), thus considerably
shortening the writing down of the axioms.
The logical axiom scheme of our calculus consists of the set Λ of all
formulas of the following form (not forgetting the right association of
parentheses in Λ1, Λ2, and Λ4):
Λ1
(α →β →γ) →(α →β) →α →γ,
Λ2
α →β →α ∧β,
Λ3
α ∧β →α,
α ∧β →β,
Λ4
(α →¬β) →β →¬α.
Λ consists only of tautologies. Moreover, all formulas derivable from Λ
using MP are tautologies as well, because ⊨α, α →β implies ⊨β. We will
show that all 2-valued tautologies are provable from Λ by means of MP.
To this aim we ﬁrst deﬁne the notion of a proof from X ⊆F in |∼.
Deﬁnition. A proof from X (in |∼) is a sequence Φ = (ϕ0, . . . , ϕn) such
that for every k ⩽n either ϕk ∈X ∪Λ or there exist indices i, j < k
such that ϕj = ϕi →ϕk (i.e., ϕk results from applying MP to terms of Φ
preceding ϕk). A proof (ϕ0, . . . , ϕn) with ϕn = α is called a proof of α
from X of length n+1. Whenever such a proof exists we write X |∼α and
say that α is provable or derivable from X.
Example. (p, q, p →q →p ∧q, q →p ∧q, p ∧q) is a proof of p ∧q from the
set X = {p, q}. The last two terms in the proof sequence derive with MP
from the previous ones, which are members of X ∪Λ.
Since a proof contains only ﬁnitely many formulas, the preceding def-
inition leads immediately to the ﬁniteness theorem for
|∼, formulated
correspondingly to Theorem 4.1. Every proper initial segment of a proof
is obviously a proof itself. Moreover, concatenating proofs of α and α →β
and tacking on β to the resulting sequence will produce a proof for β, as
is plain to see. This observation implies
(∗)
X |∼α, α →β ⇒X |∼β.

1.6 Hilbert Calculi
37
In short, the set of all formulas derivable from X is closed under MP. In
applying the property (∗) we will often say “MP yields . . . ” It is easily seen
that X |∼α iﬀα belongs to the smallest set containing X ∪Λ and closed
under MP. For the arithmetization of proofs and for automated theorem
proving, however, it is more appropriate to base derivability on the ﬁni-
tary notion of a proof that was given in the last deﬁnition. Fortunately,
the following theorem relieves us of the necessity to verify a property of
formulas α derivable from a given formula set X each time by induction
on the length of a proof of α from X.
Theorem 6.1 (Induction principle for |∼). Let X be given and let E
be a property of formulas. Then E holds for all α with X |∼α, provided
(o) E holds for all α ∈X ∪Λ,
(s) Eα and E(α →β) imply Eβ, for all α, β.
Proof by induction on the length n of a proof Φ of α from X. If α ∈X∪Λ
then Eα holds by (o), which applies in particular if n = 1. If α /∈X ∪Λ
then n > 1 and Φ contains members αi and αj = αi →α both having
proofs of length < n.
Hence, it holds Eαi and Eαj by the induction
hypothesis, and so Eα according to (s).
An application of Theorem 6.1 is the proof of |∼⊆⊨, or more explicitly,
X |∼α ⇒X ⊨α
(soundness).
To see this let Eα be the property ‘X ⊨α’ for ﬁxed X. Certainly, X ⊨α
holds for α ∈X. The same is true for α ∈Λ. Thus, Eα for all α ∈X ∪Λ,
and (o) is conﬁrmed. Now let X ⊨α, α →β; then so too X ⊨β, thus
conﬁrming the inductive step (s) in Theorem 6.1. Consequently, Eα (that
is, X ⊨α) holds for all α with X |∼α.
Unlike the proof of completeness for ⊢, the one for |∼requires a whole
series of derivations to be undertaken. This is in accordance with the
nature of things. To get Hilbert calculi up and running one must often
begin with drawn-out derivations. In the derivations below we shall use
without further comment the monotonicity (M) (page 19, with |∼for ⊨).
(M) is obvious, for a proof in |∼from X is also a proof from X′ ⊇X.
Moreover, |∼is a consequence relation (as is every Hilbert calculus, based
on Hilbert style rules). For example, if X |∼Y |∼α, we construct a proof of
α from X by replacing each ϕ ∈Y occurring in a proof of α from Y by a
proof of ϕ from X. This conﬁrms the transitivity (T).

38
1 Propositional Logic
Lemma 6.2. (a) X |∼α →¬β ⇒X |∼β →¬α,
(b) |∼α →β →α,
(c) |∼α →α,
(d) |∼α →¬¬α,
(e) |∼β →¬β →α.
Proof. (a): Clearly X |∼(α →¬β) →β →¬α by Axiom Λ4. From this and
from X |∼α →¬β the claim is derived by MP. (b): By Λ3, |∼β ∧¬α →¬α,
and so with (a), |∼α →¬(β ∧¬α) = α →β →α.
(c): From γ := α, β := α →α in Λ1 we obtain
|∼(α →(α →α) →α) →(α →α →α) →α →α,
which yields the claim by applying (b) and MP twice; (d) then follows
from (a) using |∼¬α →¬α. (e): Due to |∼¬β ∧¬α →¬β and (a), we get
|∼β →¬(¬β ∧¬α) = β →¬β →α.
Clearly, |∼satisﬁes the rules ( ∧1) and ( ∧2) of 1.4, in view of Λ2, Λ3.
Part (e) of Lemma 6.2 yields X |∼β, ¬β ⇒X |∼α, so that |∼satisﬁes also
rule (¬1). After some preparation we will show that rule (¬2) holds for
|∼as well, thereby obtaining the desired completeness result. A crucial
step in this direction is
Lemma 6.3 (Deduction theorem). X, α |∼γ implies X |∼α →γ.
Proof by induction in |∼with a given set X, α. Let X, α |∼γ, and let Eγ
now mean ‘X |∼α →γ’. To prove (o) in Theorem 6.1, let γ ∈Λ∪X ∪{α}.
If γ = α then clearly X |∼α →γ by Lemma 6.2(c). If γ ∈X ∪Λ then cer-
tainly X |∼γ. Because also X |∼γ →α →γ by Lemma 6.2(b), MP yields
X |∼α →γ, thus proving (o). To show (s) let X, α |∼β and X, α |∼β →γ,
so that X |∼α →β, α →β →γ by the induction hypothesis. Applying MP
to Λ1 twice yields X |∼α →γ, thus conﬁrming (s). Therefore, by Theo-
rem 6.1, Eγ for all γ, which completes the proof.
Lemma 6.4. |∼¬¬α →α.
Proof. By Λ3 and MP, ¬¬α ∧¬α |∼¬α, ¬¬α. Choose any τ with |∼τ.
The already veriﬁed rule (¬1) clearly yields ¬¬α ∧¬α |∼¬τ, and in view
of Lemma 6.3,
|∼¬¬α ∧¬α →¬τ.
From Lemma 6.2(a) it follows that
|∼τ →¬(¬¬α ∧¬α). But |∼τ, hence using MP we obtain |∼¬(¬¬α ∧¬α)
and the latter formula is just ¬¬α →α.
Lemma 6.3 and Lemma 6.4 are preparations for the next lemma, which
is decisive in proving the completeness of |∼.

1.6 Hilbert Calculi
39
Lemma 6.5. |∼satisﬁes also rule (¬2) of the calculus ⊢.
Proof. Let X, β |∼α and X, ¬β |∼α; then X, β |∼¬¬α and X, ¬β |∼¬¬α
by Lemma 6.2(d).
Hence, X |∼β →¬¬α, ¬β →¬¬α (Lemma 6.3), and
so X |∼¬α →¬β and X |∼¬α →¬¬β by Lemma 6.2(a). Thus, MP yields
X, ¬α |∼¬β, ¬¬β, whence X, ¬α |∼¬τ by (¬1), with τ as in Lemma 6.4.
Therefore X |∼¬α →¬τ, due to Lemma 6.3, and hence X |∼τ →¬¬α by
Lemma 6.2(a). Since X |∼τ it follows that X |∼¬¬α and so eventually
X |∼α by Lemma 6.4.
Theorem 6.6 (Completeness theorem). |∼= ⊨.
Proof. Clearly, |∼⊆⊨. Now, by what was said already on page 38 and
by the lemma above, |∼satisﬁes all basic rules of ⊢. Therefore, ⊢⊆
|∼.
Since ⊢= ⊨(Theorem 4.6), we obtain also ⊨⊆|∼.
This theorem implies in particular |∼ϕ ⇔⊨ϕ. In short, using MP one
obtains from the axiom system Λ exactly the two-valued tautologies.
Remark 1. It may be something of a surprise that Λ1–Λ4 are suﬃcient to obtain
all propositional tautologies, because these axioms and all formulas derivable
from them using MP are collectively valid in intuitionistic and minimal logic.
That Λ permits the derivation of all two-valued tautologies is based on the fact
that
→was deﬁned. Had
→been considered as a primitive connective, this
would no longer have been the case. To see this, alter the interpretation of ¬
by setting ¬0 = ¬1 = 1. While one here indeed obtains the value 1 for every
valuation of the axioms of Λ and formulas derived from them using MP, one does
not do so for ¬¬p →p, which therefore cannot be derived. Modifying the two-
valued matrix or using many-valued logical matrices is a widely applied method
to obtain independence results for logical axioms.
Thus, we have seen that there are very diﬀerent calculi for deriving
tautologies or to recover other properties of the semantic relation ⊨. We
have studied here to some extend Gentzen-style and Hilbert-style calculi
and this will be done also for ﬁrst-order logic in Chapter 2. In any case,
logical calculi and their completeness proofs depend essentially on the
logical signature, as can be seen, for example, from Exercise 1.
Besides Gentzen- and Hilbert-style calculi there are still other types
of logical calculi, for example various tableau calculi, which are above all
signiﬁcant for their generalizations to nonclassical logical systems. Related
to tableau calculi is the resolution calculus dealt with in 4.3.

40
1 Propositional Logic
Using Hilbert-style calculi one can axiomatize 2-valued logic in other
logical signatures and functional incomplete fragments. For instance, the
fragment in
∧,∨, which, while having no tautologies, contains a lot of
interesting Hilbert-style rules. Proving that this fragment is axiomatizable
by ﬁnitely many such rules is less easy as might be expected. At least nine
Hilbert rules are required. Easier is the axiomatization of the well-known
→-fragment in Exercise 3, less easy that of the ∨-fragment in Exercise 4.
Each of the inﬁnitely many fragments of two-valued logic with or without
tautologies is axiomatizable by a calculus using only ﬁnitely many Hilbert-
style rules of its respective language, as was shown in [HeR].
Remark 2. The calculus in Exercise 4 that treats the fragment in ∨alone, is
based solely on unary rules. This fact considerably simpliﬁes the matter, but
the completeness proof is nevertheless nontrivial. For instance, the indispensable
rule (αβ)γ/α(βγ) is derivable in this calculus, since a tricky application of the
rules (3) and (4) yields (αβ)γ ⊢γ(αβ) ⊢(γα)β ⊢β(γα) ⊢(βγ)α ⊢α(βγ).
Much easier would be a completeness proof of this fragment with respect to the
Gentzen-style rules (∨1) and (∨2) from Exercise 2 in 1.4.
Exercises
1. Prove the completeness of the Hilbert calculus ⊢in F{→, ⊥} with
MP as the sole rule of inference, the deﬁnition ¬α := α →⊥, and
the axioms A1: α →β →α, A2: (α →β →γ) →(α →β) →α →γ,
and A3: ¬¬α →α.
2. Let ⊢be a ﬁnitary consequence relation and let X ⊬ϕ. Use Zorn’s
lemma to prove that there is a ϕ-maximal Y ⊇X, that is, Y ⊬ϕ
but Y, α ⊢ϕ whenever α /∈Y . Such a Y is deductively closed but
need not be maximally consistent.
3. Let ⊢denote the calculus in F{→} with the rule of inference MP, the
axioms A1, A2 from Exercise 1, and ((α →β) →α) →α (the Peirce
axiom). Verify that (a) a ϕ-maximal set X is maximally consistent,
(b) ⊢is a complete calculus in the propositional language F{→}.
4. Show the completeness of the calculus ⊢in F{∨} with the four unary
Hilbert-style rules below. The writing of ∨has been omitted:
(1) α/αβ,
(2) αα/α,
(3) αβ/βα,
(4) α(βγ)/(αβ)γ.

Chapter 2
First-Order Logic
Mathematics and some other disciplines such as computer science often
consider domains of individuals in which certain relations and operations
are singled out. When using the language of propositional logic, our abil-
ity to talk about the properties of such relations and operations is very
limited. Thus, it is necessary to reﬁne our linguistic means of expres-
sion, in order to procure new possibilities of description. To this end, one
needs not only logical symbols but also variables for the individuals of the
domain being considered, as well as a symbol for equality and symbols
for the relations and operations in question. First-order logic, sometimes
called also predicate logic, is the part of logic that subjects properties of
such relations and operations to logical analysis.
Linguistic particles such as “for all” and “there exists” (called quantiﬁers)
play a central role here, whose analysis should be based on a well prepared
semantic background. Hence, we ﬁrst consider mathematical structures
and classes of structures. Some of these are relevant both to logic (in
particular model theory) and to computer science. Neither the newcomer
nor the advanced student needs to read all of 2.1, with its mathemati-
cal ﬂavor, at once. The ﬁrst ﬁve pages should suﬃce. The reader may
continue with 2.2 and later return to what is needed.
Next we home in on the most important class of formal languages,
the ﬁrst-order languages, also called elementary languages. Their main
characteristic is a restriction of the quantiﬁcation possibilities. We discuss
in detail the semantics of these languages and arrive at a notion of logical
consequence from arbitrary premises.
In this context, the notion of a
formalized theory is made more precise.
W. Rautenberg, A Concise Introduction to Mathematical Logic,
41
Universitext, DOI 10.1007/978-1-4419-1221-3_2,
c⃝Springer Science+Business Media, LLC 2010

42
2 First-Order Logic
Finally, we treat the introduction of new notions by explicit deﬁnitions
and other expansions of a language, for instance by Skolem functions.
Not until Chapter 3 do we talk about methods of formal logical deduc-
tion. While a multitude of technical details have to be considered in this
chapter, nothing is especially profound. Anyway, most of it is important
for the undertakings of the subsequent chapters.
2.1
Mathematical Structures
By a structure A we understand a nonempty set A together with certain
distinguished relations and operations of A, as well as certain constants
distinguished therein. The set A is also termed the domain of A, or its
universe. The distinguished relations, operations, and constants are called
the (basic) relations, operations, and constants of A. A ﬁnite structure
is one with a ﬁnite domain. An easy example is ({0, 1}, ∧, ∨, ¬). Here
∧, ∨, ¬ have their usual meanings on the domain {0, 1}, and no distin-
guished relations or constants occur. An inﬁnite structure has an inﬁnite
domain.
A = (N, <, +, ·, 0, 1) is an example with the domain N; here
<, +, ·, 0, 1 have again their ordinary meaning.
Without having to say so every time, for a structure A the correspond-
ing letter A will always denote the domain of A; similarly B denotes the
domain of B, etc. If A contains no operations or constants, then A is also
called a relational structure. If A has no relations it is termed an algebraic
structure, or simply an algebra. For example, (Z, <) is a relational struc-
ture, whereas (Z, +, 0) is an algebraic structure, the additive group Z (it is
customary to use here the symbol Z as well). Also the set of propositional
formulas from 1.1 can be understood as an algebra, equipped with the
operations (α, β) 
→(α ∧β), (α, β) 
→(α ∨β), and α 
→¬α. Thus, one
may speak of the formula algebra F whenever it is useful to do so.
Despite our interest in speciﬁc structures, whole classes of structures
are also often considered, for instance the classes of groups, rings, ﬁelds,
vector spaces, Boolean algebras, and so on. Even when initially just a
single structure is viewed, call it the paradigm structure, one often needs
to talk about similar structures in the same breath, in one language, so to
speak. This can be achieved by setting aside the concrete meaning of the
relation and operation symbols in the paradigm structure and considering

2.1 Mathematical Structures
43
the symbols in themselves, creating thereby a formal language that en-
ables one to talk at once about all structures relevant to a topic. Thus,
one distinguishes in this context clearly between denotation and what is
denoted. To emphasize this distinction, for instance for A = (A, +, <, 0),
it is better to write A = (A, +A, <A, 0A), where +A, <A, and 0A mean
the relation, operation, and constant denoted by +, <, and 0 in A. Only
if it is clear from the context what these symbols denote may the super-
scripts be omitted. In this way we are free to talk on the one hand about
the structure A, and on the other hand about the symbols +, <, 0.
A ﬁnite or inﬁnite set L resulting in this way, consisting of relation,
operation, and constant symbols of a given arity, is called an extralogical
signature. For the class of all groups (see page 47), L = {◦, e} exempliﬁes
a favored signature; that is, one often considers groups as structures of
the form (G, ◦, e), where ◦denotes the group operation and e the unit
element. But one can also deﬁne groups as structures of the signature
{◦}, because e is deﬁnable in terms of ◦, as we shall see later. Of course,
instead of ◦, another operation symbol could be chosen such as ·, ∗, or +.
The latter is mainly used in connection with commutative groups. In this
sense, the actual appearance of a symbol is less important; what matters
is its arity. r ∈L always means that r is a relation symbol, and f ∈L
that f is an operation symbol, each time of some arity n > 0, which of
course depends on the symbols r and f, respectively.1
An L-structure is a pair A = (A, LA), where LA contains for every r ∈L
a relation rA on A of the same arity as r, for every f ∈L an operation
fA on A of the arity of f, and for every c ∈L a constant cA ∈A. We
may omit the superscripts, provided it is clear from the context which
operation or relation on A is meant. We occasionally shorten also the
notation of structures. For instance, we sometimes speak of the ring Z or
the ﬁeld R provided there is no danger of misunderstanding.
Every structure is an L-structure for a certain signature, namely that
consisting of the symbols for its relations, functions, and constants. But
this does not make the name L-structure superﬂuous. Basic concepts,
1 Here r and f represent the general case and look diﬀerent in a concrete situation.
Relation symbols are also called predicate symbols, in particular in the unary case,
and operation symbols are sometimes called function symbols. In special contexts,
we also admit n = 0, regarding constants as 0-ary operations.

44
2 First-Order Logic
such as isomorphism and substructure, each refer to structures of the
same signature. From 2.2 on, once the ﬁrst-order language L belonging
to L has been deﬁned, L-structures will mostly be called L-structures.
We then also often say that r, f, or c belongs to L instead of L.
If A ⊆B and f is an n-ary operation on B then A is closed under f,
brieﬂy f-closed, if f⃗a ∈A for all ⃗a ∈An. If n = 0, i.e., if f is a constant
c, this simply means c ∈A. The intersection of any nonempty family of
f-closed subsets of B is itself f-closed. Accordingly, we can talk of the
smallest (the intersection) of all f-closed subsets of B that contain a given
subset E ⊆B. All of this extends in a natural way if f is here replaced
by an arbitrary family of operations of B.
Example. For a given positive m, the set mZ := {m · n | n ∈Z} of
integers divisible by m is closed in Z under +, −, and ·, and is in fact the
smallest such subset of Z containing m.
The restriction of an n-ary relation rB ⊆Bn to a subset A ⊆B is
rA = rB ∩An.
For instance, the restriction of the standard order of
R to N is the standard order of N. Only because of this fact can the
same symbol be used to denote these relations. The restriction fA of an
operation f B on B to a set A ⊆B is deﬁned analogously whenever A is
f-closed. Simply let fA⃗a = fB⃗a for ⃗a ∈An. For instance, addition in N
is the restriction of addition in Z to N, or addition in Z is an extension of
this operation in N. Again, only this state of aﬀairs allows us to denote
the two operations by the same symbol.
Let B be an L-structure and let A ⊆B be nonempty and closed under
all operations of B; this will be taken to include cB ∈A for constant
symbols c ∈L. To such a subset A corresponds in a natural way an L-
structure A = (A, LA), where rA and fA for r, f ∈L are the restrictions
of rB respectively fB to A. Finally, let cA = cB for c ∈L. The structure A
so deﬁned is then called a substructure of B, and B is called an extension
of A, in symbols A ⊆B. This is a certain abuse of ⊆but it does not
cause confusion, since the arguments indicate what is meant.
A ⊆B implies A ⊆B but not conversely, in general. For example,
A = (N, <, +, 0) is a substructure of B = (Z, <, +, 0) since N is closed
under addition in Z and 0 has the same meaning in A and B.
Here
we dropped the superscripts for <, +, and 0 because there is no risk of
misunderstanding.

2.1 Mathematical Structures
45
A nonempty subset G of the domain B of a given L-structure B deﬁnes
a smallest substructure A of B containing G. The domain of A is the
smallest subset of B containing G and closed under all operations of B.
A is called the substructure generated from G in B. For instance, 3N
(= {3n | n ∈N}) is the domain of the substructure generated from {3} in
(N, +, 0), since 3N contains 0 and 3, is closed under +, and is clearly the
smallest such subset of N. A structure A is called ﬁnitely generated if for
some ﬁnite G ⊆A the substructure generated from G in A coincides with
A. For instance, (Z, +, −, 0) is ﬁnitely generated by G = {1}.
If A is an L-structure and L0 ⊆L then the L0-structure A0 with domain
A and where sA0 = sA for all symbols s ∈L0 is termed the L0-reduct of
A, and A is called an L-expansion of A0. For instance, the group (Z, +, 0)
is the {+, 0}-reduct of the ordered ring (Z, <, +, ·, 0). The notions reduct
and substructure must clearly be distinguished. A reduct of A has always
the same domain as A, while the domain of a substructure of A is as a
rule a proper subset of A.
Below we list some frequently cited properties of a binary relation ◁
in a set A. It is convenient to write a ◁b instead of (a, b) ∈◁, and a ⋪b
for (a, b) /∈◁. Just as a < b < c often stands for a < b & b < c, we
write a ◁b ◁c for a ◁b & b ◁c. In the listing below, ‘for all a’ and
‘there exists an a’ respectively mean ‘for all a ∈A’ and ‘there exists some
a ∈A’. The relation ◁⊆A2 is called
reﬂexive
if
a ◁a for all a,
irreﬂexive
if
a ⋪a for all a,
symmetric
if
a ◁b ⇒b ◁a, for all a, b,
antisymmetric
if
a ◁b ◁a ⇒a = b, for all a, b,
transitive
if
a ◁b ◁c ⇒a ◁c, for all a, b, c,
connex
if
a = b or a ◁b or b ◁a, for all a, b.
Reﬂexive, transitive, and symmetric relations are also called equivalence
relations. These are often denoted by ∼, ≈, ≡, ≃, or similar symbols.
Such a relation generates a partition of its domain whose parts, consisting
of mutually equivalent elements, are called equivalence classes.
We now present an overview of classes of structures to which we will
later refer, mainly in Chapter 5. Hence, for the time being, the beginner
may skip the following and jump to 2.2.

46
2 First-Order Logic
1. Graphs, partial orders, and orders. A relational structure (A, ◁)
with some relation ◁⊆A2 is often termed a (directed) graph. If ◁is
irreﬂexive and transitive we usually write < for ◁and speak of a (strict)
partial order or a partially ordered set, also called a poset for short. If
we deﬁne x ⩽y by x < y or x = y, then ⩽is reﬂexive, transitive, and
antisymmetric, called a reﬂexive partial order, the one that belongs to <.
If one starts with a reﬂexive partial order on A and deﬁnes x < y by
x ⩽y & x ̸= y, then (A, <) is clearly a poset.
A connex partial order A = (A, <) is called a total or linear order, also
termed an ordered or a strictly ordered set. N, Z, Q, R are examples with
respect to their standard orders. Here we follow the traditional habit of
referring to ordered sets by their domains only.
Let U be a nonempty subset of some ordered set A such that for all
a, b ∈A, a < b ∈U ⇒a ∈U. Such a U is called an initial segment of A.
In addition, let V := A \U ̸= ∅. Then the pair (U, V ) is called a cut. The
cut is said to be a gap if U has no largest and V no smallest element.
However, if U has a largest element a, and V a smallest element b, then
(U, V ) is called a jump. b is in this case called the immediate successor of
a, and a the immediate predecessor of b, because then there is no element
from A between a and b. An inﬁnite ordered set without gaps and jumps,
like R, is said to be continuously ordered. Such a set is easily seen to be
densely ordered, i.e., between any two elements lies another one.
A totally ordered subset K of a partially ordered set H is called a chain
in H. Such a K is said to be bounded (to the above) if there is some b ∈H
with a ⩽b for all a ∈K. Call c ∈H maximal in H if no a ∈H exists
with a > c. An inﬁnite partial order need not have a maximal element,
nor need all chains be bounded, as is seen by the example (N, <). With
these notions, a basic mathematical tool can now be stated:
Zorn’s lemma. If every chain in a nonempty poset H is bounded then
H has a maximal element.
A (totally) ordered set A is well-ordered if every nonempty subset of
A has a smallest element; equivalently, there are no inﬁnite decreasing
sequences a0 > a1 > · · · of elements from A. Clearly, every ﬁnite ordered
set is well-ordered. The simplest example of an inﬁnite well-ordered set is
N together with its standard order.

2.1 Mathematical Structures
47
2. Groupoids, semigroups, and groups. Algebras A = (A, ◦) with
an operation ◦: A2 →A are termed groupoids. If ◦is associative then A
is called a semigroup, and if ◦is additionally invertible, then A is said
to be a group. It is provable that a group (G, ◦) in this sense contains
exactly one unit element, that is, an element e such that x ◦e = e ◦x = x
for all x ∈G, also called a neutral element. A well-known example is the
group of bijections of a set M. If the group operation ◦is commutative,
we speak of a commutative or abelian group.
Here are some examples of semigroups that are not groups: (a) the
set of strings on some alphabet A with respect to concatenation, the
word-semigroup or free semigroup generated from A.
(b) the set MM
of mappings from M to itself with respect to composition.
(c) (N, +)
and (N, ·); these two are commutative semigroups. With the exception of
(MM, ◦), all mentioned examples of semigroups are regular, which is to
mean x ◦y = x ◦z ⇒y = z, and x ◦z = y ◦z ⇒x = y, for all x, y, z.
Substructures of semigroups are again semigroups.
Substructures of
groups are in general only semigroups, as seen from (N, +) ⊆(Z, +). Not
so in the signature {◦, e, −1}, where e denotes the unit element and x−1
the inverse of x. Here all substructures are indeed subgroups. The reason
is that in {◦, e, −1}, the group axioms can be written as universally quan-
tiﬁed equations, where for brevity, we omit the writing of “for all x, y, z,”
namely as x ◦(y ◦z) = (x ◦y) ◦z, x ◦e = x, x ◦x−1 = e. These equations
certainly retain their validity in the transition to substructures. We men-
tion that from the last three equations, e ◦x = x and x−1 ◦x = e are
derivable, although ◦is not supposed to be commutative.
Ordered semigroups and groups possess along with ◦some order, with
respect to which ◦is monotonic in both arguments, like (N, +, 0, ⩽). A
commutative ordered semigroup (A, +, 0, ⩽) with zero element 0, which
at the same time is the smallest element in A, and where a ⩽b iﬀthere
is some c with a + c = b, is called a domain of magnitude. Everyday
examples are the domains of length, mass, money, etc.
3. Rings and ﬁelds. These belong to the most commonly known struc-
tures. Below we list the axioms for the theory TF of ﬁelds in +, ·, 0, 1. A
ﬁeld is a model of TF . A ring is a model of the axiom system TR for rings
that derives from TF by dropping the constant 1 from the signature and
the axioms N×, C×, and I× from TF . Here are the axioms of TF :

48
2 First-Order Logic
N+ :
x + 0==== x
N× :
x · 1==== x
C+ :
x + y ==== y + x
C× :
x · y ==== y · x
A+ :
(x + y) + z ==== x + (y + z)
A× :
(x · y) · z ==== x · (y · z)
D :
x · (y + z)==== x · y + x · z
D′ :
(y + z) · x==== y · x + z · x
I+ :
∀x∃y x + y ==== 0
I× :
0̸====1 ∧(∀x̸====0)∃y x · y ==== 1
In view of C×, axiom D′ is dispensable for TF but not for TR. When
removing I+ from TR, we obtain the theory of semirings. A well-known
example is (N, +, ·, 0).
A commutative ring that has a unit element 1
but no zero-divisor (i.e., ¬∃x∃y(x, y ̸==== 0 ∧x · y ==== 0) is called an integral
domain. A typical example is (Z, +, ·, 0, 1).
Let K, K′ be any ﬁelds with K ⊂K′. We call a ∈K′ \K algebraic or
transcendental on K, depending on whether a is a zero of a polynomial
with coeﬃcients in K or not. If every polynomial of degree ⩾1 with
coeﬃcients in K breaks down into linear factors, as is the case for the
ﬁeld of complex numbers, then K is called algebraically closed, in short, K
is a.c. These ﬁelds will be more closely inspected in 3.3 and Chapter 5.
Each ﬁeld K has a smallest subﬁeld P, called a prime ﬁeld. One says that
K has characteristic 0 or p (a prime number), depending on whether P is
isomorphic to the ﬁeld Q or the ﬁnite ﬁeld of p elements. No other prime
ﬁelds exist. It is not hard to show that K has the characteristic p iﬀthe
sentence charp : 1 + · · · + 1



p
==== 0 holds in K.
Rings, ﬁelds, etc. may also be ordered, whereby the usual monotonicity
laws are required.
For example, (Z, <, +, ·, 0, 1) is the ordered ring of
integers and (N, <, +, ·, 0, 1) the ordered semiring of natural numbers.
4. Semilattices and lattices. A = (A, ◦) is called a semilattice if ◦is
associative, commutative, and idempotent. An example is ({0, 1}, ◦) with
◦= ∧. If we deﬁne a ⩽b :⇔a ◦b = a then ⩽is a reﬂexive partial order
on A. Reﬂexivity holds, since a ◦a = a. As can be easily veriﬁed, a ◦b
is in fact the inﬁmum of a, b with respect to ⩽, a ◦b = inf{a, b}, that is,
a ◦b ⩽a, b, and c ⩽a, b ⇒c ⩽a ◦b, for all a, b, c ∈A.
A = (A, ∩, ∪) is called a lattice if (A, ∩) and (A, ∪) are both semi-
lattices and the following so-called absorption laws hold: a ∩(a ∪b) = a
and a ∪(a ∩b) = a.
These imply a ∩b = a ⇔a ∪b = b.
As above,
a ⩽b :⇔a ∩b = a deﬁnes a partial order such that a ∩b = inf{a, b}.

2.1 Mathematical Structures
49
In addition, one has a ∪b = sup{a, b} (the supremum of a, b), which is
to mean a, b ⩽a ∪b, and a, b ⩽c
⇒
a ∪b ⩽c, for all c ∈A. If A
satisﬁes, moreover, the distributive laws x ∩(y ∪c) = (x ∩y) ∪(x ∩c) and
x ∪(y ∩c) = (x ∪y) ∩(x ∪c), then A is termed a distributive lattice. For
instance, the power set PM with the operations ∩and ∪for ∩and ∪re-
spectively is a distributive lattice, as is every nonempty family of subsets
of M closed under ∩and ∪, a so-called lattice of sets. Another important
example is (N, gcd, lcm). Here gcd(a, b) and lcm(a, b) denote the greatest
common divisor and the least common multiple of a, b ∈N.
5. Boolean algebras. An algebra A = (A, ∩, ∪, ¬) where (A, ∩, ∪) is
a distributive lattice and in which at least the equations
¬¬x = x,
¬(x ∩y) = ¬x ∪¬y,
x ∩¬x = y ∩¬y
are valid is called a Boolean algebra. The paradigm structure is the two-
element Boolean algebra 2 := ({0, 1}, ∧, ∨, ¬), with ∩, ∪interpreted as
∧, ∨, respectively. One deﬁnes the constants 0 and 1 by 0 := a ∩¬a for
any a ∈A and 1 := ¬0. There are many ways to characterize Boolean
algebras A, for instance, by saying that A satisﬁes all equations valid in 2.
The signature can also be variously selected. For example, the signature
∧, ∨, ¬ is well suited to deal algebraically with two-valued propositional
logic.
Terms of this signature are, up to the denotation of variables,
precisely the Boolean formulas from 1.1, and a valid logical equivalence
α ≡β corresponds to the equation α = β, valid in 2. Further examples
of Boolean algebras are the algebras of sets A = (A, ∩, ∪, ¬). Here A
consists of a nonempty system of subsets of a set I, closed under ∩, ∪,
and ¬ (complementation in I). These are the most general examples; a
famous theorem, Stone’s representation theorem, says that each Boolean
algebra is isomorphic to an algebra of sets.
6. Logical L-matrices. These are structures A = (A, LA, DA), where
L contains only operation symbols (the “logical” symbols) and D denotes
a unary predicate, the set of distinguished values of A. Best known is the
two-valued Boolean matrix B = (2, DB) with DB = {1}. The consequence
relation ⊨A in the propositional language F of signature L is deﬁned as
in the two-valued case: Let X ⊆F and ϕ ∈F. Then X ⊨A ϕ if wϕ ∈DA
for every w: PV →A with wX ⊆DA (wX := {wα | α ∈X}). In words,
if the values of all α ∈X are distinguished, then so too is the value of ϕ.

50
2 First-Order Logic
Homomorphisms and isomorphisms. The following notions are im-
portant for both mathematical and logical investigations. Much of the
material presented here will be needed in Chapter 5. In the following
deﬁnition, n (>0) denotes as always the arity of f or r.
Deﬁnition. Let A, B be L-structures and h: A →B (strictly speaking
h: A →B) a mapping such that for all f, c, r ∈L and ⃗a ∈An,
(H): hf A⃗a = fBh⃗a, hcA = cB, rA⃗a ⇒rBh⃗a
	
h⃗a = (ha1, . . . , han)

.
Then h is called a homomorphism. If the third condition in (H) is replaced
by the stronger condition (S): (∃⃗b∈An)(h⃗a=h⃗b & rA⃗b ) ⇔rBh⃗a 2 then h
is said to be a strong homomorphism (for algebras, the word “strong” is
dispensable). An injective strong homomorphism h: A →B is called an
embedding of A into B. If, in addition, h is bijective then h is called an
isomorphism, and in case A = B, an automorphism.
An embedding or isomorphism h: A →B satisﬁes rA⃗a ⇔rBh⃗a. Indeed,
since h⃗a=h⃗b ⇔⃗a=⃗b, (S) yields rBh⃗a ⇒(∃⃗b∈An)(⃗a=⃗b & rA⃗b) ⇒rA⃗a.
A, B are said to be isomorphic, in symbols A ≃B, if there is an isomor-
phism from A to B. It is readily veriﬁed that ≃is reﬂexive, symmetric, and
transitive, hence an equivalence relation on the class of all L-structures.
Examples 1. (a) A valuation w considered in 1.1 can be regarded as
a homomorphism of the propositional formula algebra F into the two-
element Boolean algebra 2. Such a w: F →2 is necessarily onto.
(b) Let A = (A, ∗) be a word semigroup with the concatenation operation
∗and B the additive semigroup of natural numbers, considered as L-
structures for L = {◦} with ◦A = ∗and ◦B = +. Let lh(ξ) denote the
length of a word or string ξ ∈A. Then ξ 
→lh(ξ) is a homomorphism
since lh(ξ ∗η) = lh(ξ) + lh(η), for all ξ, η ∈A. If A is generated from a
single letter, lh is evidently bijective, hence an isomorphism.
(c) The mapping a 
→(a, 0) from R to C (= set of complex numbers,
understood as ordered pairs of real numbers) is a good example of an
embedding of the ﬁeld R into the ﬁeld C. Nonetheless, in this case, we
are used to saying that R is a subﬁeld of C, and that R is a subset of C.
2 (∃⃗b∈An)(h⃗a=h⃗b & rA⃗b ) abbreviates ‘there is some ⃗b ∈An with h⃗a = h⃗b and rA⃗b’.
If h: A →B is onto (and only this case will occur in our applications) then (S) is
equivalent to the more suggestive condition rB = {h⃗a | rA⃗a}.

2.1 Mathematical Structures
51
(d) Let A = (R, +, <) be the ordered additive group of real numbers
and B = (R+, ·, <) the multiplicative group of positive reals. Then for
any b ∈R+ \{1} there is precisely one isomorphism η: A →B such that
η1 = b, namely η: x 
→bx, the exponential function expb to the base b.
It is even possible to deﬁne expb as this isomorphism, by ﬁrst proving
that—up to isomorphism—there is only one continuously ordered abelian
group (ﬁrst noticed in [Ta2] though not explicitly put into words).
(e) The algebras A = ({0, 1}, +) and B = ({0, 1}, ↔) are only apparently
diﬀerent, but are in fact isomorphic, with the isomorphism δ where δ0 = 1,
δ1 = 0. Thus, since A is a group, B is a group as well, which is not
obvious at ﬁrst glance. By adjoining the unary predicate D = {1}, A and
B become (nonisomorphic) logical matrices. These actually deﬁne the two
“dual” fragmentary two-valued logics for the connectives either . . . or . . . ,
and . . . if and only if . . . , which have many properties in common.
Congruences. A congruence relation (or simply a congruence) in a struc-
ture A of signature L is an equivalence relation ≈in A such that for all
n > 0, all f ∈L of arity n, and all ⃗a,⃗b ∈An,
⃗a ≈⃗b ⇒f A⃗a ≈fA⃗b.
Here ⃗a ≈⃗b means ai ≈bi for i = 1, . . . , n.
A trivial example is the
identity in A. If h: A →B is a homomorphism then ≈h ⊆A2, deﬁned
by a ≈h b ⇔ha = hb, is a congruence in A, called the kernel of h. Let
A′ be the set of equivalence classes a/≈:= {x ∈A | a ≈x} for a ∈A,
also called the congruence classes of ≈, and set ⃗a/≈:= (a1/≈, . . . , an/≈)
for ⃗a ∈An. Deﬁne fA′(⃗a/≈) := (fA⃗a)/≈and let rA′⃗a/≈:⇔(∃⃗b≈⃗a)rA⃗b.
These deﬁnitions are sound, that is, independent of the choice of the n-
tuple ⃗a of representatives. Then A′ becomes an L-structure A′, the factor
structure of A modulo ≈, denoted by A/≈. Interesting, in particular for
Chapter 5, is the following very general and easily provable
Homomorphism theorem. Let A be L-structure and ≈a congruence
in A. Then k: a 
→a/≈is a strong homomorphism from A onto A/≈,
the canonical homomorphism. Conversely, if h: A →B is a strong homo-
morphism from A onto an L-structure B with kernel ≈then ı : a/≈
→ha
is an isomorphism from A/≈to B, and h = ı ◦k.
Proof. We omit here the superscripts for f and r just for the sake of
legibility. Clearly, kf⃗a = (f⃗a)/≈= f(⃗a/≈) = fk⃗a
	
=f(ka1, . . . , kan)

,

52
2 First-Order Logic
and (∃⃗b∈An)(k⃗a = k⃗b & r⃗b) ⇔(∃⃗b≈⃗a)r⃗b ⇔r⃗a/≈⇔r k⃗a by deﬁnition.
Hence k is what we claimed. The deﬁnition of ı is sound, and ı is bijective
since ha = hb ⇒a/≈= b/≈. Furthermore, ı is an isomorphism because
ıf(⃗a/≈) = hf⃗a = fh⃗a = fı(⃗a/≈) and r⃗a/≈⇔r h⃗a ⇔r ı(⃗a/≈).
Finally, h is the composition ı ◦k by the deﬁnitions of ı and k.
Remark. For algebras A, this theorem is the usual homomorphism theorem of
universal algebra. A/≈is then named the factor algebra. The theorem covers
groups, rings, etc. In groups, the kernel of a homomorphism is already deter-
mined by the congruence class of the unit element, called a normal subgroup,
in rings by the congruence class of 0, called an ideal. Hence, in textbooks on
basic algebra the homomorphism theorem is separately formulated for groups
and rings, but is easily derivable from the general theorem present here.
Direct products. These provide the basis for many constructions of new
structures, especially in 5.7. A well-known example is the n-dimensional
vector group (Rn, 0, +). This is the n-fold direct product of the group
(R, 0, +) with itself. The addition in Rn is deﬁned componentwise, as is
also the case in the following
Deﬁnition.
Let (Ai)i∈I be a nonempty family of L-structures.
The
direct product B = 
i∈I Ai is the structure deﬁned as follows: Its domain
is B = 
i∈I Ai, called the direct product of the sets Ai. The elements
a = (ai)i∈I of B are functions deﬁned on I with ai ∈Ai for each i ∈I.
Relations and operations in B are deﬁned componentwise, that is,
rB⃗a ⇔rAi⃗ai for all i ∈I,
fB⃗a = (fAi⃗ai)i∈I,
cB = (cAi)i∈I,
where ⃗a = (a1, . . . , an) ∈Bn (here the superscripts count the components)
with aν := (aν
i )i∈I for ν = 1, . . . , n, and ⃗ai := (a1
i , . . . , an
i ) ∈A n
i .
Whenever Ai = A for all i ∈I, then 
i∈I Ai is denoted by AI and
called a direct power of the structure A. Note that A is embedded in AI
by the mapping a 
→(a)i∈I, where (a)i∈I denotes the I-tuple with the
constant value a, that is, (a)i∈I = (a, a, . . . ). For I = {1, . . . , m}, the
product 
i∈I Ai is also written as A1 × · · · × Am. If I = {0, . . . , n−1}
one mostly writes An for AI.
Examples 2. (a) Let I = {1, 2}, Ai = (Ai, <i), and B = 
i∈I Ai.
Then a <B b ⇔a1 <1 b1 & a2 <2 b2, for all a, b ∈B = A1 × A2. Note
that if A1, A2 are ordered sets then B is only a partial order. The deeper
reason for this observation will become clear in Chapter 5.

2.2 Syntax of First-Order Languages
53
(b) Let B = 2 I be a direct power of the two-element Boolean algebra 2.
The elements a ∈B are I-tuples of 0 and 1. These uniquely correspond
to the subsets of I via the mapping ı: a 
→Ia := {i ∈I | ai = 1}. As a
matter of fact, ı is an isomorphism from B to (PI, ∩, ∪, ¬), as can readily
be veriﬁed; Exercise 4.
Exercises
1. Show that there are (up to isomorphism) exactly ﬁve two-element
proper groupoids. Here a groupoid (H, ·) is termed proper if the
operation · is essentially binary.
2. ≈(⊆A2) is termed Euclidean if a ≈b & a ≈c ⇒b ≈c, for all
a, b, c ∈A. Show that ≈is an equivalence relation in A if and only
if ≈is reﬂexive and Euclidean.
3. Prove that an equivalence relation ≈on an algebraic L-structure A
is a congruence iﬀfor all f ∈L of arity n, all i = 1, . . . , n, and all
a1, . . . , ai−1, a, a′, ai+1, . . . , an ∈A with a ≈a′,
f(a1, . . . , ai−1, a, ai+1, . . . , an) ≈f(a1, . . . , ai−1, a′, ai+1, . . . , an).
4. Prove in detail that 2 I ≃(PI, ∩, ∪, ¬) for a nonempty index set I.
Prove the corresponding statement for any subalgebra of 2 I.
5. Show that h: 
i∈I Ai →Aj with ha = aj is a homomorphism for
each j ∈I.
2.2
Syntax of First-Order Languages
Standard mathematical language enables us to talk precisely about struc-
tures, such as the ﬁeld of real numbers. However, for logical (and meta-
mathematical) issues it is important to delimit the theoretical framework
to be considered; this is achieved most simply by means of a formalization.
In this way one obtains an object language; that is, the formalized elements
of the language, such as the components of a structure, are objects of our
consideration. To formalize interesting properties of a structure in this
language, one requires at least variables for the elements of its domain,
called individual variables. Further are required suﬃciently many logical

54
2 First-Order Logic
symbols, along with symbols for the distinguished relations, functions,
and constants of the structure. These extralogical symbols constitute the
signature L of the formal language that we are going to deﬁne.
In this manner one arrives at the ﬁrst-order languages, also termed
elementary languages. Nothing is lost in terms of generality if the set
of variables is the same for all elementary languages; we denote this set
by Var and take it to consist of the countably many symbols v0, v1, . . .
Two such languages therefore diﬀer only in the choice of their extralogical
symbols. Variables for subsets of the domain are consciously excluded,
since languages containing variables both for individuals and sets of these
individuals—second-order languages, discussed in 3.8—have diﬀerent se-
mantic properties from those investigated here.
We ﬁrst determine the alphabet, the set of basic symbols of a ﬁrst-order
language determined by a signature L. It includes, of course, the already
speciﬁed variables v0, v1, . . . In what follows, these will mostly be denoted
by x, y, z, u, v, though sometimes other letters with or without indices may
serve the same purpose. The boldface printed original variables are useful
in writing down a formula in the variables vi1, . . . , vin, for these can then
be denoted, for instance, by v1, . . . , vn, or by x1, . . . , xn.
Further, the logical symbols ∧(and), ¬ (not), ∀(for all), the equality
sign ====, and, of course, all extralogical symbols from L should belong to
the alphabet. Note that the boldface symbol ==== is taken as a basic symbol;
simply taking = could lead to unintended mix-ups with the metamath-
ematical use of the equality symbol = (in Chapter 4 also identity-free
languages without ==== will be considered). Finally, the parentheses ( , )
are included in the alphabet. Other symbols are introduced by deﬁnition,
e.g., ∨, →, ↔are deﬁned as in 1.4 and the symbols ∃(there exists) and
∃! (there exists exactly one) will be deﬁned later. Let SL denote the set
of all strings made up of symbols that belong to the alphabet of L.
From the set SL of all strings we pick out the meaningful ones, namely
terms and formulas, according to certain rules. A term, under an inter-
pretation of the language, will always denote an element of a domain,
provided an assignment of the occurring variables to elements of that do-
main has been given. In order to keep the syntax as simple as possible,
terms will be understood as certain parenthesis-free strings, although this
kind of writing may look rather unusual at the ﬁrst glance.

2.2 Syntax of First-Order Languages
55
Terms in L:
(T1) Variables and constants, considered as atomic strings, are terms,
also called prime terms.
(T2) If f ∈L is n-ary and t1, . . . , tn are terms, then ft1 · · · tn is a term.
This is a recursive deﬁnition of the set of terms as a subset of SL. Any
string that is not generated by (T1) and (T2) is not a term in this context
(cf. the related deﬁnition of F in 1.1).
Parenthesis-free term notation
simpliﬁes the syntax, but for binary operations we proceed diﬀerently in
practice and write, for example, the term ·+xyz as (x+y)·z. The reason
is that a high density of information in the notation complicates read-
ing. Our brain does not process information sequentially like a computer.
Oﬃcially, terms are parenthesis-free, and the parenthesized notation is
just an alternative way of rewriting terms. Similarly to the unique recon-
struction property of propositional formulas in 1.1, here the unique term
reconstruction property holds, that is,
ft1 · · · tn = fs1 · · · sn implies si = ti for i = 1, . . . , n
(ti, si terms),
which immediately follows from the unique term concatenation property
t1 · · · tn = s1 · · · sm implies n = m and ti = si for i = 1, . . . , n.
The latter is shown in Exercise 2. T (= TL) denotes the set of all terms
of a given signature L. Variable-free terms, which can exist only with
the availability of constant symbols, are called constant terms or ground
terms, mainly in logic programming. With the operations given in T by
setting fT (t1, . . . , tn) = ft1 · · · tn, T forms an algebra, the term algebra.
From the deﬁnition of terms immediately follows the useful
Principle of proof by term induction. Let E be a property of strings
such that E holds for all prime terms, and for each n > 0 and each n-ary
function symbol f, the assumptions Et1, . . . , Etn imply Eft1 · · · tn. Then
all terms have the property E.
Indeed, T is by deﬁnition the smallest set of strings satisfying the condi-
tions of this principle, and hence a subset of the set of all strings with the
property E. A simple application of term induction is the proof that each
compound term t is a function term in the sense that t = ft1 · · · tn for
some n-ary function symbol f and some terms t1, . . . , tn. Simply consider
the property ‘t is either prime or a function term’. Term induction can
also be executed on certain subsets of T , for instance on ground terms.

56
2 First-Order Logic
We also have at our disposal a deﬁnition principle by term recursion
which, rather than deﬁning it generally, we present through examples.
The set var t of variables occurring in a term t is recursively deﬁned by
var c = ∅; var x = {x} ; var ft1 · · · tn = var t1 ∪· · · ∪var tn.
var t, and even var ξ for any ξ ∈SL, can also be deﬁned explicitly using
concatenation. var ξ is the set of all x ∈Var for which there are strings
η, ϑ with ξ = ηxϑ. The notion of a subterm of a term can also be deﬁned
recursively. Again, we can also do it more brieﬂy using concatenation.
Deﬁnition by term induction should more precisely be called deﬁnition by
term recursion. But most authors are sloppy in this respect.
We now deﬁne recursively those strings of the alphabet of L to be called
formulas, also termed (ﬁrst-order) expressions or well-formed formulas.
Formulas in L:
(F1) If s, t are terms, then the string s==== t is a formula.
(F2) If t1, . . . , tn are terms and r ∈L is n-ary, then rt1 · · · tn is a formula.
(F3) If α, β are formulas and x is a variable, then (α ∧β), ¬α, and ∀xα
are formulas.
Any string not generated according to (F1), (F2), (F3) is in this context
not a formula. Other logical symbols serve throughout merely as abbre-
viations, namely ∃xα := ¬∀x¬α, (α ∨β) := ¬(¬α ∧¬β), and as in 1.1,
(α →β) := ¬(α ∧¬β), and (α ↔β) := ((α →β) ∧(β →α)). In addition,
s ̸==== t will throughout be written for ¬ s==== t. The formulas ∀xα and ∃xα
are said to arise from α by quantiﬁcation.
Examples. (a) ∀x∃y x + y ==== 0 (more explicitly, ∀x¬∀y¬ x + y ==== 0) is a
formula, expressing ‘for all x there exists a y such that x+y = 0’. Here we
assume tacitly that x, y denote distinct variables. The same is assumed
in all of the following whenever this can be made out from the context.
(b) ∀x∀x x==== y is a formula, since repeated quantiﬁcation of the same
variable is not forbidden. ∀z x==== y is a formula also if z ̸= x, y, although
z does then not appear in the formula x==== y.
Example (b) indicates that the grammar of our formal language is more
liberal than one might expect. This will spare us a lot of writing. The for-
mulas ∀x∀x x==== y and ∃x∀x x==== y both have the same meaning as ∀x x==== y.

2.2 Syntax of First-Order Languages
57
These three formulas are logically equivalent (in a sense still to be deﬁned),
as are ∀z x==== y and x==== y. It would be to our disadvantage to require any
restriction here. In spite of this liberality, the formula syntax corresponds
roughly to the syntax of natural language.
The formulas procured by (F1) and (F2) are said to be prime or atomic
formulas, or simply called prime. As in propositional logic, prime formulas
and their negations are called literals.
Prime formulas of the form s==== t are called equations. These are the
only prime formulas if L contains no relation symbols, in which case L
is called an algebraic signature. Prime formulas that are not equations
begin with a relation symbol, although in practice a binary symbol tends
to separate the two arguments as, for example, in x ⩽y. The oﬃcial
notation is, however, that of clause (F2). The unique term concatenation
property clearly implies the unique prime formula reconstruction property
rt1 · · · tn = rs1 · · · sn implies ti = si for i = 1, . . . , n.
The set of all formulas in L is denoted by L. If L = {∈} or L = {◦}
then L is also denoted by L∈or L◦, respectively. If L is more complex,
e.g. L = {◦, e}, we write L = L{◦, e}. The case L = ∅is also permitted;
it deﬁnes the language of pure identity, denoted by L=
==
=.
Instead of terms, formulas, and structures of signature L, we will talk
of L-terms (writing TL for TL), L-formulas, and L-structures respectively.
We also omit the preﬁx if L has been given earlier and use the same
conventions of parenthesis economy as in 1.1. We will also allow ourselves
other informal aids in order to increase readability. For instance, variously
shaped brackets may be used as in ∀x∃y∀z[z ∈y ↔∃u(z ∈u ∧u ∈x)]. Even
verbal descriptions (partial or complete) are permitted, as long as the
intended formula is uniquely recognizable.
The strings ∀x and ∃x (read “for all x” respectively “there is an x”) are
called preﬁxes. Also concatenations of these such as ∀x∃y are preﬁxes. No
other preﬁxes are considered here. Formulas in which ∀, ∃do not occur
are termed quantiﬁer-free or open. These are the Boolean combinations
of prime formulas. Generally, the Boolean combinations of formulas from
a set X ⊆L are the ones generated by ¬, ∧(and ∨) from those of X.
X, Y, Z always denote sets of formulas, α, β, γ, δ, π, ϕ, . . . denote formu-
las, and s, t terms, while Φ, Ψ are reserved to denote ﬁnite sequences of

58
2 First-Order Logic
formulas and formal proofs. Substitutions (to be deﬁned below) will be
denoted by σ, τ, ω, ρ, and ι.
Principles of proof by formula induction and of deﬁnition by formula
induction (more precisely formula recursion) also exist for ﬁrst-order and
other formal languages.
After the explanation of these principles for
propositional languages in 1.1, it suﬃces to present here some examples,
adhering to the maxim verba docent, exempla trahunt. Formula recursion is
based on the unique formula reconstruction, which is similar to the corre-
sponding property in 1.1: Each composed ϕ ∈L can uniquely be written
as ϕ = ¬α, ϕ = (α ∧β), or ∀xα for some α, β ∈L and x ∈Var. A simple
example of a recursive deﬁnition is rk ϕ, the rank of a formula ϕ. Starting
with rk π = 0 for prime formulas π it is deﬁned as on page 8, with the
additional clause rk ∀xα = rk α+1. Functions on L are sometimes deﬁned
by recursion on rk ϕ, not on ϕ, as for instance on page 60.
Useful for some purposes is also the quantiﬁer rank, qr ϕ. It represents
a measure of nested quantiﬁers in ϕ. For prime π let qr π = 0, and let
qr ¬α = qr α, qr(α ∧β) = max{qr α, qr β}, qr ∀xα = qr α + 1.
Note that qr ∃xϕ = qr ¬∀x¬ϕ = qr ∀xϕ. A subformula of a formula is
deﬁned analogously to the deﬁnition in 1.1. Hence, we need say no more
on this. We write x ∈bnd ϕ (or x occurs bound in ϕ) if ϕ contains the
preﬁx ∀x. In subformulas of ϕ of the form ∀xα, the formula α is called
the scope of ∀x. The same preﬁx can occur repeatedly and with nested
scopes in ϕ, as for instance in ∀x(∀x x==== 0 ∧x<y). In practice we avoid
this way of writing, though for a computer this would pose no problem.
Intuitively, the formulas (a) ∀x∃y x+y ==== 0 and (b) ∃y x+y ==== 0 are diﬀer-
ent in that in every context with a given meaning for + and 0, the former
is either true or false, whereas in (b) the variable x is waiting to be as-
signed a value. One also says that all variables in (a) are bound, while
(b) contains the “free” variable x. The syntactic predicate ‘x occurs free
in ϕ’, or ‘x ∈free ϕ’ is deﬁned inductively: Let free α = var α for prime
formulas α (var α was deﬁned on page 56), and
free (α ∧β) = free α ∪free β, free ¬α = free α, free ∀xα = free α\{x}.
For instance, free (∀x∃y x+y ==== 0) = ∅, while free (x ⩽y ∧∀x∃y x+y ==== 0)
equals {x, y}. As the last formula shows, x can occur both free and bound
in a formula. This too will be avoided in practice whenever possible. In
some proof-theoretically oriented presentations, even diﬀerent symbols are

2.2 Syntax of First-Order Languages
59
chosen for free and bound variables. Each of these approaches has its
advantages and its disadvantages.
Formulas without free variables are called sentences, or closed formulas.
1+1==== 0 and ∀x∃y x+y ==== 0 (= ∀x¬∀y¬x+y ==== 0) are examples. Through-
out take L0 to denote the set of all sentences of L. More generally, let Lk
be the set of all formulas ϕ such that free ϕ ⊆Vark := {v0, . . . , vk−1}.
Clearly, L0 ⊆L1 ⊆· · · and L = 
k∈N Lk.
At this point we meet a for the remainder of the book valid
Convention. As long as not otherwise stated, the notation ϕ = ϕ(x)
means that the formula ϕ contains at most x as a free variable; more
generally, ϕ = ϕ(x1, . . . , xn) or ϕ = ϕ(⃗x) is to mean free ϕ ⊆{x1, . . . , xn},
where x1, . . . , xn stand for arbitrary but distinct variables. Not all of these
variables need actually occur in ϕ. Further, t = t(⃗x) for terms t is to be
read completely analogously.
The term ft1 · · · tn is often denoted by f⃗t , the prime formula rt1 · · · tn
by r⃗t . Here ⃗t denotes the string concatenation t1 · · · tn. Fortunately, ⃗t
behaves exactly like the sequence (t1, . . . , tn) as was pointed out already;
it has the unique term concatenation property, see page 55.
Substitutions. We begin with the substitution tx of some term t for a
single variable x, called a simple substitution. Put intuitively, ϕ tx (also
denoted by ϕx(t) and read “ϕ t for x”) is the formula that results from
replacing all free occurrences of x in ϕ by the term t.
This intuitive
characterization is made precise recursively, ﬁrst for terms by
x tx = t,
y tx = y
(x ̸= y),
c tx = c,
(ft1 · · · tn) tx = ft′
1 · · · t′
n,
where, for brevity, t′
i stands for ti tx , and next for formulas as follows:
(t1 ==== t2) tx = t′
1 ==== t′
2, (r⃗t ) tx = rt′
1 · · · t′
n,
(α ∧β) tx = α tx ∧β tx , (¬α) tx = ¬(α tx),
(∀yα)tx =

∀yα if x = y,
∀y(α tx) otherwise.
Then also (α →β) tx = α tx →β tx , and the corresponding holds for ∨,
while (∃yα) tx = ∃yα for y = x, and ∃y(α tx ) otherwise. Simple substitu-
tions are special cases of so-called simultaneous substitutions
ϕ t1··· tn
x1··· xn
(x1, . . . , xn distinct).
For brevity, this will be written ϕ⃗t
⃗x or ϕ⃗x(⃗t ) or just ϕ(⃗t ), provided there is
no danger of misunderstanding. Here the variables xi are simultaneously
replaced by the terms ti at free occurrences. Simultaneous substitutions

60
2 First-Order Logic
easily generalize to global substitutions σ.
Such a σ assigns to every
variable x a term xσ ∈T . It extends to the whole of T by the clauses
cσ = c and (f⃗t )σ = ftσ
1 · · · tσ
n, and subsequently to L by recursion on
rk ϕ, so that σ is deﬁned for the whole of T ∪L: (t1 ==== t2)σ = tσ
1 ==== tσ
2,
(r⃗t )σ = rtσ
1 · · · tσ
n, (α ∧β)σ = ασ ∧βσ, (¬α)σ = ¬ασ, and (∀xϕ)σ = ∀xϕτ,
where τ is deﬁned by xτ = x and yτ = yσ for y ̸= x.3
These clauses cover also the case of a simultaneous substitution, because
⃗t
⃗x can be identiﬁed with the global substitution σ such that x σ
i
= ti
for i = 1, . . . , n and xσ = x otherwise. In other words, a simultaneous
substitution can be understood as a global substitution σ such that xσ = x
for almost all variables x, i.e., with the exception of ﬁnitely many. The
identical substitution, always denoted by ι, is deﬁned by xι = x for all x;
hence tι = t and ϕι = ϕ for all terms t and formulas ϕ.
Clearly, a global substitution yields locally, i.e. with respect to individual
formulas, the same as a suitable simultaneous substitution. Moreover, it
will turn out below that simultaneous substitutions are products of simple
ones. Nonetheless, a separate study of simultaneous substitutions is useful
mainly for Chapter 4.
It always holds that
t1t2
x1x2 =
t2t1
x2x1 , whereas the compositions t1
x1
t2
x2 and
t2
x2
t1
x1 are distinct, in general. Let us elaborate by explaining the diﬀerence
between ϕ t1t2
x1x2 and ϕ t1
x1
t2
x2
	
= (ϕ t1
x1 ) t2
x2

. For example, if one wants
to swap x1, x2 at their free occurrences in ϕ then the desired formula
is ϕ x2x1
x1x2 , but not, in general, ϕ x2
x1
x1
x2 (choose for instance ϕ = x1<x2).
Rather ϕ x2x1
x1x2 = ϕ y
x2
x2
x1
x1y for any y /∈var ϕ∪{x1, x2}, as is readily shown
by induction on ϕ after ﬁrst treating terms. We recommend to carry out
this induction in detail. In the same way we obtain
(1)
ϕ⃗t
⃗x = ϕ y
xn
t1··· tn-1
x1··· xn-1
tny
(y /∈var ϕ ∪var ⃗x ∪var⃗t , n ⩾2).
This formula shows that a simultaneous substitution is a suitable product
(composition) of simple substitutions. Conversely, it can be shown that
each such product can be written as a single simultaneous substitution.
In some cases (1) can be simpliﬁed. Useful, for example, is the following
equation which holds in particular when all terms ti are variable-free:
(2)
ϕ⃗t
⃗x = ϕ t1
x1 · · · tn
xn
(xi /∈var tj for i ̸= j).
3 Since rk ϕ < rk ∀xϕ, we may assume according to the recursive construction of σ that
ϕτ is already deﬁned for all global substitutions τ.

2.3 Semantics of First-Order Languages
61
Getting on correctly with substitutions is not altogether simple; it
requires practice, because our ability to regard complex strings is not
especially trustworthy. A computer is not only much faster but also more
reliable in this respect.
Exercises
1. Show by term induction that a terminal segment of a term t is a
concatenation s1 · · · sm of terms si for some m ⩾1. Thus, a symbol
in t is at each position in t the initial symbol of a unique subterm s
of t. The uniqueness of s is an easy consequence of Exercise 2(a).
2. Let L be a ﬁrst-order language, T = TL, and Et the property ‘No
proper initial segment of t (∈T ) is a term, nor is t a proper initial
segment of a term from T ’.
Prove (a) Et for all t ∈T , hence
tξ = t′ξ′ ⇒t = t′ for all t, t′ ∈T and arbitrary ξ, ξ′ ∈SL, and
(b) the unique term concatenation property (page 55).
3. Prove (a) No proper initial segment of a formula ϕ is a formula.
(b) The unique formula reconstruction property stated on page 58.
(c) ¬ξ ∈L ⇒ξ ∈L and α, (α ∧ξ) ∈L ⇒ξ ∈L. (c) easily yields
(d) α, (α →ξ) ∈L ⇒ξ ∈L, for all ξ ∈SL.
4. Prove ϕ tx = ϕ for x /∈free ϕ, and ϕ y
x ty = ϕ tx for y /∈var ϕ. It can
be shown that these restrictions are indispensable, provided t ̸= x.
5. Let X ⊆L be a nonempty formula set and X∗= X ∪{¬ϕ | ϕ ∈X}.
Show that a Boolean combination of formulas from X is equivalent
to a disjunction of conjunctions of formulas from X∗.
2.3
Semantics of First-Order Languages
Intuitively it is clear that the formula ∃y y+y ==== x can be allocated a truth
value in the domain (N, +) only if to the free variable x there corresponds a
value in N. Thus, along with an interpretation of the extralogical symbols,
a truth value allocation for a formula ϕ requires a valuation of at least the
variables occurring free in ϕ. However, it is technically more convenient

62
2 First-Order Logic
to work with a global assignment of values to all variables, even if in a
concrete case only the values of ﬁnitely many variables are needed. We
therefore begin with the following
Deﬁnition. A model M is a pair (A, w) consisting of an L-structure A
and a valuation w: Var →A, w: x 
→xw. We denote rA, f A, cA, and xw
also by rM, fM, cM, and xM, respectively. The domain of A will also
called the domain of M.
Models are sometimes called interpretations, occasionally also L-models
if the connection to L is to be highlighted. Some authors identify models
with structures from the outset.
This also happens in 2.5, where we
are talking about models of theories.
The notion of a model is to be
maintained suﬃciently ﬂexible in logic and mathematics.
A model M allocates in a natural way to every term t a value in A,
denoted by tM or tA,w or just by tw. Clearly, for prime terms the value is
already given by M. This evaluation extends to compound terms by term
induction as follows: (f⃗t )M = fM⃗t M, where ⃗t M abbreviates here the
sequence (tM
1 , . . . , tM
n ). If the context allows we neglect the superscripts
and retain just an imaginary distinction between symbols and their inter-
pretation. For instance, if A = (N, +, ·, 0, 1) and xw = 2, say, we write
somewhat sloppily (0 · x + 1)A,w = 0 · 2 + 1 = 1.
The value of t under M depends only on the meaning of the symbols
that eﬀectively occur in t; using induction on t, the following slightly more
general claim is obtained: if var t ⊆V ⊆Var and M, M′ are models with
the same domain such that xM = xM′ for all x ∈V and sM = sM′ for
all remaining symbols s occurring in t, then tM = tM′. Clearly, tA,w may
simply be denoted by tA, provided the term t contains no variables.
We now are going to deﬁne a satisﬁability relation ⊨between models
M = (A, w) and formulas ϕ, using induction on ϕ as in 1.3. We read
M ⊨ϕ as M satisﬁes ϕ, or M is a model for ϕ.
Sometimes A ⊨ϕ [w] is written instead of M ⊨ϕ. A similar notation,
just as frequently encountered, is introduced later. Each of these notations
has its advantages, depending on the context. If M ⊨ϕ for all ϕ ∈X
we write M ⊨X and call M a model for X.
For the formulation of
the satisfaction clauses below (taken from [Ta1]) we consider for given
M = (A, w), x ∈Var, and a ∈A also the model Ma
x (generalized to M⃗a
⃗x

2.3 Semantics of First-Order Languages
63
below). Ma
x diﬀers from M only in that the variable x receives the value
a ∈A instead of xM. Thus, Ma
x = (A, w′) with xw′ = a and yw′ = yw
otherwise. The satisfaction clauses then look as follows:
M ⊨s==== t
⇔
sM = tM,
M ⊨r⃗t
⇔
rM⃗t M,
M ⊨(α ∧β) ⇔
M ⊨α and M ⊨β,
M ⊨¬α
⇔
M ⊭α,
M ⊨∀xα
⇔
Ma
x ⊨α for all a ∈A.
Remark 1. The last satisfaction clause can be stated diﬀerently if a name for
each a ∈A, say a, is available in the signature: M ⊨∀xα ⇔M ⊨α ax for all
a ∈A. This assumption permits the deﬁnition of the satisfaction relation for
sentences using induction on sentences while bypassing arbitrary formulas. If
not every a ∈A has a name in L, one could “ﬁll up” L in advance by adjoining
to L a name a for each a. But expanding the language is not always wanted and
does not really simplify the matter.
Ma
x is slightly generalized to M⃗a
⃗x := Ma1···an
x1···xn (= (Ma1
x1)a2
x2 . . . ), which
diﬀers from M in the values of a sequence x1, . . . , xn of distinct variables.
This and writing ∀⃗xϕ for ∀x1 · · · ∀xnϕ permits a short notation of a useful
generalization of the last clause above, namely
M ⊨∀⃗xϕ ⇔M⃗a
⃗x ⊨ϕ for all ⃗a ∈An.
The deﬁnitions of α ∨β, α →β, and α ↔β from page 56 readily imply
the additional clauses M ⊨α ∨β iﬀM ⊨α or M ⊨β, M ⊨α →β
iﬀM ⊨α ⇒M ⊨β, and analogously for ↔. Clearly, if ∨, →, ↔were
treated as independent connectives, these equivalences would have to be
added to the above ones. Further, the deﬁnition of ∃xϕ in 2.2 corresponds
to its intended meaning, because M ⊨∃xϕ ⇔Ma
x ⊨ϕ for some a ∈A.
Indeed, whenever M ⊨¬∀x¬ϕ (= ∃xϕ) then Ma
x ⊨¬ϕ does not hold
for all a; hence there is some a ∈A such that Ma
x ⊭¬ϕ, or equivalently,
Ma
x ⊨ϕ. And this chain of reasoning is obviously reversible.
Example 1. M ⊨∃x x==== t for arbitrary M, provided x /∈var t. Indeed,
Ma
x ⊨x==== t with a := tM, since xMa
x = a = tM = tMa
x in view of x /∈var t.
The assumption x /∈var t is essential. For instance, M ⊨∃x x==== fx holds
only if the function fM has a ﬁxed point.
We now introduce several fundamental notions that will be treated more
systematically in 2.4 and 2.5, once certain necessary preparations have
been completed.

64
2 First-Order Logic
Deﬁnition. A formula or set of formulas in L is termed satisﬁable if it
has a model. ϕ ∈L is called generally valid, logically valid, or a tautology,
in short, ⊨ϕ, if M ⊨ϕ for every model M. Formulas α, β are called
(logically or semantically) equivalent, in symbols, α ≡β, if
M ⊨α ⇔M ⊨β, for each L-model M.
Further, let A ⊨ϕ (read ϕ holds in A or A satisﬁes ϕ) if (A, w) ⊨ϕ for
all w: Var →A. One writes A ⊨X in case A ⊨ϕ for all ϕ ∈X. Finally,
let X ⊨ϕ (read from X follows ϕ, or ϕ is a consequence of X) if every
model M of X also satisﬁes the formula ϕ, i.e., M ⊨X ⇒M ⊨ϕ.
As in Chapter 1, ⊨denotes both the satisfaction and the consequence
relation. Here, as there, we write ϕ1, . . . , ϕn ⊨ϕ for {ϕ1, . . . , ϕn} ⊨ϕ.
Note that in addition, ⊨denotes the validity relation in structures, which
is illustrated by the following
Example 2. We show that A ⊨∀x∃y x ̸==== y, where the domain of A
contains at least two elements. Indeed, let M = (A, w) and let a ∈A
be given arbitrarily. Then there exists some b ∈A with a ̸= b. Hence,
(Ma
x)b
y = Ma b
xy ⊨x ̸==== y, and so Ma
x ⊨∃y x ̸==== y. Since a was arbitrary,
M ⊨∀x∃y x ̸==== y. Clearly the actual values of w are irrelevant in this
argument. Hence (A, w) ⊨∀x∃y x̸====y for all w, that is, A ⊨∀x∃y x̸====y.
Here some care is needed. While M ⊨ϕ or M ⊨¬ϕ for all formulas,
A ⊨ϕ or A ⊨¬ϕ (the law of the excluded middle for validity in structures)
is in general correct only for sentences ϕ, as Theorem 3.1 will show. If
A contains more than one element, then, for example, neither A ⊨x==== y
nor A ⊨x̸====y. Indeed, x==== y is falsiﬁed by any w such that xw ̸= yw, and
x̸====y by any w with xw = yw. This is one of the reasons why models were
not simply identiﬁed with structures.
For ϕ ∈L let ϕg be the sentence ∀x1 · · · ∀xmϕ, where x1, . . . , xm is
an enumeration of free ϕ according to index size, say. ϕg is called the
generalized of ϕ, also called its universal closure.
For ϕ ∈L0 clearly
ϕg = ϕ. From the deﬁnitions immediately results
(1)
A ⊨ϕ ⇔A ⊨ϕg,
and more generally, A ⊨X ⇔A ⊨X g (:= {ϕg | ϕ ∈X}). (1) explains
why ϕ and ϕg are often notionally identiﬁed, and the information that
formally runs ϕg is often shortened to ϕ. It must always be clear from

2.3 Semantics of First-Order Languages
65
the context whether our eye is on validity in a structure, or on validity in
a model with its ﬁxed valuation. Only in the ﬁrst case can a generaliza-
tion (or globalization) of the free variables be thought of as carried out.
However, independent of this discussion, ⊨ϕ ⇔⊨ϕg always holds.
Even after just these incomplete considerations it is already clear that
numerous properties of structures and whole systems of axioms can ad-
equately be described by ﬁrst-order formulas and sentences. Thus, for
example, an axiom system for groups in ◦, e, −1, mentioned already in
2.1, can be formulated as follows:
∀x∀y∀z x ◦(y ◦z)==== (x ◦y) ◦z;
∀x x ◦e==== x;
∀x x ◦x−1 ==== e.
Precisely, the sentences that follow from these axioms form the elementary
group theory in ◦, e, −1. It will be denoted by T =
==
=
G . In the sense elaborated
in Exercise 3 in 2.6 an equivalent formulation of the theory of groups in
◦, e, denoted by TG, is obtained if the third T =
==
=
G -axiom is replaced by
∀x∃y x ◦y ==== e.
Let us mention that ∀x e ◦x==== x and ∀x∃y y ◦x==== e are
provable in TG and also in T =
==
=
G .
An axiom system for ordered sets can also easily be provided, in that
one formalizes the properties of being irreﬂexive, transitive, and connex.
Here and elsewhere, ∀x1 · · · xnϕ stands for ∀x1 · · · ∀xnϕ:
∀x x ≮x; ∀xyz(x < y ∧y < z →x < z); ∀xy(x̸====y →x < y ∨y < x).
In writing down these and other axioms the outer ∀-preﬁxes are very
often omitted so as to save on writing, and we think implicitly of the
generalization of variables as having been carried out. This kind of eco-
nomical writing is employed also in the formulation of (1) above, which
strictly speaking runs ‘for all A, ϕ : A ⊨ϕ ⇔A ⊨ϕg ’.
For sentences α of a given language it is intuitively clear that the values
of the variables of w for the relation (A, w) ⊨α are irrelevant.
The
precise proof is extracted from the following theorem for V = ∅. Thus,
either (A, w) ⊨α for all w and hence A ⊨α, or else (A, w) ⊨α for no w,
i.e., (A, w) ⊨¬α for all w, and hence A ⊨¬α. Sentences therefore obey
the already-cited tertium non datur.
Theorem 3.1 (Coincidence theorem). Let V ⊆Var, free ϕ ⊆V , and
M, M′ be models on the same domain A such that xM = xM′ for all
x ∈V , and sM = sM′ for all extralogical symbols s occurring in ϕ. Then
M ⊨ϕ ⇔M′ ⊨ϕ.

66
2 First-Order Logic
Proof by induction on ϕ. Let ϕ = r⃗t be prime, so that var⃗t ⊆V . As was
mentioned earlier, the value of a term t depends only on the meaning of the
symbols occurring in t. But in view of the suppositions, these meanings
are the same in M and M′. Therefore, ⃗t M = ⃗t M′ (i.e., t M
i
= t M′
i
for
i = 1, . . . , n), and so M ⊨r⃗t ⇔rM⃗t M ⇔rM′⃗t M′ ⇔M′ ⊨r⃗t . For
equations t1 ==== t2 one reasons analogously. Further, the induction hypoth-
esis for α, β yields M ⊨α ∧β ⇔M ⊨α, β ⇔M′ ⊨α, β ⇔M′ ⊨α ∧β.
In the same way one obtains M ⊨¬α ⇔M′ ⊨¬α. By the induction step
on ∀it becomes clear that the induction hypothesis needs to be skillfully
formulated. It must be given with respect to any pair M, M′ of models
and any subset V of Var.
Therefore let a ∈A and Ma
x ⊨ϕ. Since for V ′ := V ∪{x} certainly
free ϕ ⊆V ′ and the models Ma
x, M′ a
x coincide for all y ∈V ′ (although
in general xM ̸= xM′), by the induction hypothesis Ma
x ⊨ϕ ⇔M′ a
x ⊨ϕ,
for each a ∈A. This clearly implies
M ⊨∀xϕ ⇔Ma
x ⊨ϕ for all a ⇔M′ a
x ⊨ϕ for all a ⇔M′ ⊨∀xϕ.
It follows from this theorem that an L-model M = (A, w) of ϕ for
the case that ϕ ∈L ⊆L′ can be completely arbitrarily expanded to an
L′-model M′ = (A′, w) of ϕ, i.e., arbitrarily ﬁxing sM′ for s ∈L′ \L
gives M ⊨ϕ ⇔M′ ⊨ϕ by the above theorem with V = Var. This
readily implies that the consequence relation ⊨L′ with respect to L′ is a
conservative extension of ⊨L in that X ⊨L ϕ ⇔X ⊨L′ ϕ, for all sets
X ⊆L and all ϕ ∈L. Hence, there is no need here for using indices. In
particular, the satisﬁability or general validity of ϕ depends only on the
symbols eﬀectively occurring in ϕ.
Another application of Theorem 3.1 is the following fact, which justiﬁes
the already mentioned “omission of superﬂuous quantiﬁers.”
(2)
∀xϕ ≡ϕ ≡∃xϕ whenever x /∈free ϕ.
Indeed, x /∈free ϕ implies M ⊨ϕ ⇔Ma
x ⊨ϕ (here a ∈A is arbitrary)
according to Theorem 3.1; choose M′ = Ma
x and V = free ϕ. Therefore,
M ⊨∀xϕ ⇔Ma
x ⊨ϕ for all a ⇔M ⊨ϕ
⇔Ma
x ⊨ϕ for some a ⇔M ⊨∃xϕ.
Very important for the next theorem and elsewhere is
(3)
If A ⊆B, M = (A, w), M′ = (B, w) and w: Var →A then
tM = tM′.

2.3 Semantics of First-Order Languages
67
This is clear for prime terms, and the induction hypothesis tM
i
= tM′
i
for
i = 1, . . . , n together with fM = fM′ imply
(f⃗t )M = fM(tM
1 , . . . , tM
n ) = fM′(tM′
1
, . . . , tM′
n ) = (f⃗t )M′.
For M = (A, w) and xw
i = ai let tA,⃗a, or more suggestively tA(⃗a) denote
the value of t = t(⃗x). Then (3) can somewhat more simply be written as
(4)
A ⊆B and t = t(⃗x) imply tA(⃗a) = tB(⃗a) for all ⃗a ∈An.
Thus, along with the basic functions, also the so-called term functions
⃗a 
→tA(⃗a) are the restrictions to their counterparts in B. Clearly, if n = 0
or t is variable-free, one may write tA for tA(⃗a). Note that in these cases
tA = tB whenever A ⊆B, according to (4).
By Theorem 3.1 the satisfaction of ϕ in (A, w) depends only on the
values of the x ∈free ϕ. Let ϕ = ϕ(⃗x)4 and ⃗a = (a1, . . . , an) ∈An. Then
the statement
(A, w) ⊨ϕ for a valuation w with x w
1 = a1, . . . , x w
n = an
can more suggestively be expressed by writing
(A,⃗a) ⊨ϕ or A ⊨ϕ [a1, . . . , an] or A ⊨ϕ [⃗a]
without mentioning w as a global valuation. Such notation also makes
sense if w is restricted to a valuation on {x1, . . . , xn}. One may accord-
ingly extend the concept of a model and call a pair (A,⃗a) a model for a
formula ϕ(⃗x) whenever (A,⃗a) ⊨ϕ(⃗x), in particular if ϕ ∈Ln. We return
to this extended concept in 4.1. Until then we use it only for n = 0. That
is, besides M = (A, w) also the structure A itself is occasionally called a
model for a set S ⊆L0 of sentences, provided A ⊨S.
As above let ϕ = ϕ(⃗x). Then ϕA := {⃗a ∈An | A ⊨ϕ [⃗a]} is called the
predicate deﬁned by the formula ϕ in the structure A. For instance, the
⩽-predicate in (N, +) is deﬁned by ϕ(x, y) = ∃z z + x==== y, but also by
several other formulas.
More generally, a predicate P ⊆An is termed (explicitly or elementarily
or ﬁrst-order) deﬁnable in A if there is some ϕ = ϕ(⃗x) with P = ϕA, and
ϕ is called a deﬁning formula for P. Analogously, f : An →A is called
deﬁnable in A if ϕA = graph f for some ϕ(⃗x, y). One often talks in this
4 Since this equation is to mean free ϕ ⊆{x1, . . . , xn}, ⃗x is not uniquely determined
by ϕ. Hence, the phrase “Let ϕ = ϕ(⃗x) . . . ” implicitly includes along with a given ϕ
also a tuple ⃗x given in advance. The notation ϕ = ϕ(⃗x) does not even state that ϕ
contains free variables at all.

68
2 First-Order Logic
case of explicit deﬁnability of f in A, to distinguish it from other kinds
of deﬁnability. Much information is gained from the knowledge of which
sets, predicates, or functions are deﬁnable in a structure. For instance,
the sets deﬁnable in (N, 0, 1, +) are the eventually periodic ones (periodic
from some number on). Thus, · cannot explicitly be deﬁned by +, 0, 1
because the set of square numbers is not eventually periodic.
A ⊆B and ϕ = ϕ(⃗x) do not imply ϕA = ϕB ∩An, in general. For
instance, let A = (N, +), B = (Z, +), and ϕ = ∃z z + x==== y.
Then
ϕA = ⩽A, while ϕB contains all pairs (a, b) ∈Z2. As the next theorem
will show, ϕA = ϕB ∩An holds in general only for open formulas ϕ, and
is even characteristic for A ⊆B provided A ⊆B. Clearly, A ⊆B is much
weaker a condition than A ⊆B:
Theorem 3.2 (Substructure theorem). For structures A, B such that
A ⊆B the following conditions are equivalent:
(i)
A ⊆B,
(ii)
A ⊨ϕ [⃗a] ⇔B ⊨ϕ [⃗a], for all open ϕ = ϕ(⃗x) and all ⃗a ∈An,
(iii)
A ⊨ϕ [⃗a] ⇔B ⊨ϕ [⃗a], for all prime formulas ϕ(⃗x) and ⃗a ∈An.
Proof. (i)⇒(ii): It suﬃces to prove that M ⊨ϕ ⇔M′ ⊨ϕ, with
M = (A, w) and M′ = (B, w), where w: Var →A. In view of (3) the
claim is obvious for prime formulas, and the induction steps for ∧, ¬ are
carried out just as in Theorem 3.1. (ii)⇒(iii): Trivial. (iii)⇒(i): By (iii),
rA⃗a ⇔A ⊨r⃗x [⃗a] ⇔B ⊨r⃗x [⃗a] ⇔rB⃗a. Analogously,
f A⃗a = b ⇔A ⊨f⃗x==== y [⃗a, b] ⇔B ⊨f⃗x==== y [⃗a, b] ⇔fB⃗a = b,
for all ⃗a ∈An, b ∈A. These conclusions state precisely that A ⊆B.
Let α be of the form ∀⃗xβ with open β, where ∀⃗x may also be the empty
preﬁx. Then α is a universal or ∀-formula (spoken “A-formula”), and for
α ∈L0 also a universal or ∀-sentence. A simple example is ∀x∀y x==== y,
which holds in A iﬀA contains precisely one element. Dually, ∃⃗xβ with
β open is termed an ∃-formula, and an ∃-sentence whenever ∃⃗xβ ∈L0.
Examples are the “how-many sentences”
∃1 := ∃v0 v0 ==== v0;
∃n := ∃v0 · · · ∃vn−1

i<j<n vi̸====vj
(n > 1).
∃n states ‘there exist at least n elements’, ¬∃n+1 thus that ‘there exist
at most n elements’, and ∃=n := ∃n ∧¬∃n+1 says ‘there exist exactly

2.3 Semantics of First-Order Languages
69
n elements’.
Since ∃1 is a tautology, it is convenient to set ⊤:= ∃1,
and ∃0 := ⊥:= ¬⊤in all ﬁrst-order languages with equality. Clearly,
equivalent deﬁnitions of ⊤, ⊥may be used as well.
Corollary 3.3. Let A ⊆B. Then every ∀-sentence ∀⃗xα valid in B is also
satisﬁed in A. Dually, every ∃-sentence ∃⃗xβ valid in A is also valid in B.
Proof. Let B ⊨∀⃗xβ and ⃗a ∈An. Then B ⊨β [⃗a], hence A ⊨β [⃗a] by
Theorem 3.2. ⃗a was arbitrary and therefore A ⊨∀⃗xβ. Now let A ⊨∃⃗xβ.
Then A ⊨β [⃗a] for some ⃗a ∈An, hence B ⊨β [⃗a] by Theorem 3.2, and
consequently B ⊨∃⃗xβ.
We now formulate a generalization of certain individual often-used ar-
guments about the invariance of properties under isomorphisms:
Theorem 3.4 (Invariance theorem). Let A, B be isomorphic structures
of signature L and let ı: A →B be an isomorphism. Then for all ϕ = ϕ(⃗x)
A ⊨ϕ [⃗a] ⇔B ⊨ϕ [ı⃗a]
	
⃗a ∈An, ı⃗a = (ıa1, . . . , ıan)

.
In particular A ⊨ϕ ⇔B ⊨ϕ, for all sentences ϕ of L.
Proof. It is convenient to reformulate the claim as
M ⊨ϕ ⇔M′ ⊨ϕ
	
M = (A, w), M′ = (B, w′), w′ : x 
→ıxw
.
This is easily conﬁrmed by induction on ϕ after ﬁrst proving ı(tM) = tM′
inductively on t. This proof clearly includes the case ϕ ∈L0.
Thus, for example, it is once and for all clear that the isomorphic image
of a group is a group even if we know at ﬁrst only that it is a groupoid.
Simply let α in the theorem run through all axioms of group theory.
Another application: Let ı be an isomorphism of the group A = (A, ◦)
onto the group A′ = (A′, ◦) and let e and e′ denote their unit elements,
not named in the signature. We claim that nonetheless ıe = e′, using
the fact that the unit element of a group is the only solution of x ◦x==== x
(Example 2, page 83). Thus, since A ⊨e ◦e==== e, we get A′ ⊨ıe ◦ıe==== ıe by
Theorem 3.4, hence ıe = e′. Theorem 3.4, incidentally, holds for formulas
of higher order as well. For instance, the property of being a continuously
ordered set (formalizable in a second-order language, see 3.8) is likewise
invariant under isomorphism.
L-structures A, B are termed elementarily equivalent if A ⊨α ⇔B ⊨α,
for all α ∈L0. One then writes A ≡B. We consider this important notion

70
2 First-Order Logic
in 3.3 and more closely in 5.1. Theorem 3.4 states in particular that
A ≃B ⇒A ≡B. The question immediately arises whether the converse
of this also holds. For inﬁnite structures the answer is negative (see 3.3),
for ﬁnite structures aﬃrmative; a ﬁnite structure of a ﬁnite signature can,
up to isomorphism, even be described by a single sentence. For example,
the 2-element group ({0, 1}, +) is up to isomorphism well determined by
the following sentence, which tells us precisely how + operates:
∃v0∃v1[v0̸====v1 ∧∀x(x==== v0 ∨x==== v1)
∧v0 + v0 ==== v1 + v1 ==== v0 ∧v0 + v1 ==== v1 + v0 ==== v1].
We now investigate the behavior of the satisfaction relation under sub-
stitution. The deﬁnition of ϕ tx in 2.2 pays no attention to collision of
variables, which is taken to mean that some variables of the substitution
term t fall into the scope of quantiﬁers after the substitution has been
performed. In this case M ⊨∀xϕ does not necessarily imply M ⊨ϕ tx ,
although this might have been expected. In other words, ∀xϕ ⊨ϕ tx is
not unrestrictedly correct. For instance, if ϕ = ∃y x ̸==== y then certainly
M ⊨∀xϕ (= ∀x∃y x ̸==== y) whenever M has at least two elements, but
M ⊨ϕ y
x (= ∃y y ̸==== y) is certainly false. Analogously ϕ tx ⊨∃xϕ is not
correct, in general. For example, choose ∀y x==== y for ϕ and y for t.
One could forcibly obtain ∀xϕ ⊨ϕ tx without any limitation by renam-
ing bound variables by a suitable modiﬁcation of the inductive deﬁnition
of ϕ tx in the quantiﬁer step. However, such measures are rather unwieldy
for the arithmetization of proof method in 6.2. It is therefore preferable
to put up with minor restrictions when we are formulating rules of deduc-
tion later. The restrictions we will use are somewhat stronger than they
need to be but can be handled more easily; they look as follows:
Call ϕ, tx collision-free if y /∈bnd ϕ for all y ∈var t distinct from x.
We need not require x /∈bnd ϕ because t is substituted only at free oc-
currences of x in ϕ, that is, x cannot fall after substitution within the
scope of a preﬁx ∀x, even if x ∈var t. For collision-free ϕ, tx we always
get ∀xϕ ⊨ϕ tx by Corollary 3.6 below.
If σ is a global substitution (see 2.2) then ϕ, σ are termed collision-free
if ϕ, xσ
x are collision-free for every x ∈Var. If σ = ⃗t
⃗x, this condition clearly
need be checked only for the pairs ϕ, xσ
x with x ∈var ⃗x and x ∈free ϕ.

2.3 Semantics of First-Order Languages
71
For M = (A, w) put Mσ := (A, wσ) with xwσ := (xσ)M for x ∈Var,
so that xMσ = xσM (= (xσ)M). This equation reproduces itself to
(5)
tMσ = tσM for all terms t.
Indeed, tMσ = fM(t Mσ
1
, . . . , t Mσ
n
) = fM(t σ
1
M, . . . , t σ
n
M) = tσM for
t = f⃗t in view of the induction hypothesis tMσ
i
= t σ
i
M (i = 1, . . . , n).
Notice that Mσ coincides with M⃗t M
⃗x
for the case σ = ⃗t
⃗x.
Theorem 3.5 (Substitution theorem). Let M be a model and σ a
global substitution. Then holds for all ϕ such that ϕ, σ are collision-free,
(6) M ⊨ϕσ ⇔Mσ ⊨ϕ.
In particular, M ⊨ϕ ⃗t
⃗x ⇔M⃗t M
⃗x
⊨ϕ, provided ϕ, ⃗t
⃗x are collision-free.
Proof by induction on ϕ. In view of (5), we obtain
M ⊨(t1 ==== t2)σ ⇔tσ
1
M = tσ
2
M ⇔tMσ
1
= tMσ
2
⇔Mσ ⊨t1 ==== t2.
Prime formulas r⃗t are treated analogously. The induction steps for ∧, ¬
in the proof of (6) are harmless.
Only the ∀-step is interesting.
The
reader should recall the deﬁnition of (∀xα)σ page 60 and realize that the
induction hypothesis refers to an arbitrary global substitution τ.
M ⊨(∀xα)σ ⇔M ⊨∀x ατ
(xτ = x and yτ = yσ else)
⇔Ma
x ⊨ατ for all a
(deﬁnition)
⇔(Ma
x)τ ⊨α for all a
(induction hypothesis)
⇔(Mσ)a
x ⊨α for all a
	
(Ma
x)τ = (Mσ)a
x, see below

⇔Mσ ⊨∀xα.
We show that (Ma
x)τ = (Mσ)a
x. Since ∀xα, σ (hence ∀xα, yσ
y for every y)
are collision-free, we have x /∈var yσ if y ̸= x, and since yτ = yσ we get
in this case y(Ma
x)τ = yτ Ma
x = yσMa
x = yσM = yMσ = y(Mσ)a
x. But also
in the case y = x we have x(Ma
x)τ = xτ Ma
x = xMa
x = a = x(Mσ)a
x.
Corollary 3.6. For all ϕ and
⃗t
⃗x such that ϕ, ⃗t
⃗x are collision-free, the
following properties hold:
(a) ∀⃗xϕ ⊨ϕ ⃗t
⃗x, in particular ∀xϕ ⊨ϕ tx ,
(b) ϕ ⃗t
⃗x ⊨∃⃗xϕ,
(c) ϕ sx, s==== t ⊨ϕ tx , provided ϕ, sx, tx are collision-free.
Proof. Let M ⊨∀⃗xϕ, so that M⃗a
⃗x ⊨ϕ for all ⃗a ∈An. In particular,
M⃗t M
⃗x
⊨ϕ. Therefore, M ⊨ϕ ⃗t
⃗x by Theorem 3.5. (b) follows easily from
¬∃⃗xϕ ⊨¬ϕ ⃗t
⃗x. This holds by (a), for ¬∃⃗xϕ ≡∀⃗x¬ϕ and ¬(ϕ ⃗t
⃗x) ≡(¬ϕ) ⃗t
⃗x.

72
2 First-Order Logic
(c): Let M ⊨ϕ sx, s==== t, so that sM = tM and MsM
x
⊨ϕ by the theorem.
Clearly, then also MtM
x
⊨ϕ. Hence M ⊨ϕ tx .
Remark 2. The identical substitution ι is obviously collision-free with every
formula. Thus, ∀xϕ ⊨ϕ (= ϕι) is always the case, while ∀xϕ ⊨ϕ tx is correct
in general only if t contains at most the variable x, since ϕ, tx are then collision-
free. Theorem 3.5 and Corollary 3.6 are easily strengthened. Deﬁne inductively
a ternary predicate ‘t is free for x in ϕ’, which intuitively is to mean that no free
occurrence in ϕ of the variable x lies within the scope of a preﬁx ∀y whenever
y ∈var t. In this case Theorem 3.5 holds for σ =
tx as well, so that nothing
needs to be changed in the proofs based on this theorem if one works with
‘t is free for x in ϕ’, or simply reads “ϕ, tx are collision-free” as “t is free for x in
ϕ.” Though collision-freeness is somewhat cruder and slightly more restrictive,
it is for all that more easily manageable, which will pay oﬀ, for example, in 6.2,
where proofs will be arithmetized.
Once one has become accustomed to the
required caution, it is allowable not always to state explicitly the restrictions
caused by collisions of variables, but rather to assume them tacitly.
Theorem 3.5 also shows that the quantiﬁer “there exists exactly one,” de-
noted by ∃!, is correctly deﬁned by ∃!xϕ := ∃xϕ ∧∀x∀y(ϕ ∧ϕ y
x →x==== y)
with y /∈var ϕ. Indeed, it is easily seen that M ⊨∀x∀y(ϕ ∧ϕ y
x →x==== y)
means just Ma
x ⊨ϕ & Mb
y ⊨ϕ y
x ⇒a = b. In short, Ma
x ⊨ϕ for at most
one a. Putting everything together, M ⊨∃!xϕ iﬀthere is precisely one
a ∈A with Ma
x ⊨ϕ. An example is M ⊨∃!x x==== t for arbitrary M and
x /∈var t. In other words, ∃!x x==== t is a tautology. Half of this, namely
⊨∃x x==== t, was shown in Example 1, and ⊨∀x∀y(x==== t ∧y ==== t →x==== y) is
obvious. There are various equivalent deﬁnitions of ∃!xϕ. For example,
a short and catchy formula is ∃x∀y(ϕ y
x ↔x==== y), where y /∈var ϕ. The
equivalence proof is left to the reader.
Exercises
1. Let X ⊨ϕ and x /∈free X. Show that X ⊨∀xϕ.
2. Prove that ∀x(α →β) ⊨∀xα →∀xβ, which is obviously equivalent
to ⊨∀x(α →β) →∀xα →∀xβ.
3. Suppose A′ results from A by adjoining a constant symbol a for
some a ∈A. Prove A ⊨α [a] ⇔A′ ⊨α(a) (= α ax) for α = α(x),
by ﬁrst verifying t(x) A,a = t(a) A′. This is easily generalized to the
case of more than one free variable in α.

2.4 General Validity and Logical Equivalence
73
4. Show that (a) A conjunction of the ∃i and their negations is equiva-
lent to ∃n ∧¬∃m for suitable n, m (∃n ∧¬∃0 ≡∃n, ∃1 ∧¬∃m ≡¬∃m).
(b) A Boolean combination of the ∃i is equivalent to 
ν⩽n ∃=kν or
to ∃k ∨
ν⩽n ∃=kν, with k0 < · · · < kn < k. Note that 
ν⩽n ∃=kν
equals ∃=0 (≡⊥) for n=k0=0 and ¬∃n ≡
ν<n ∃=ν for n>0.
2.4
General Validity and Logical Equivalence
From the perspective of predicate logic α ∨¬α (α ∈L) is a trivial example
of a tautology, because it results by inserting α for p from the propositional
tautology p ∨¬p. Every propositional tautology provides generally valid
L-formulas by the insertion of L-formulas for the propositional variables.
But there are tautologies not arising in this way. ∀x(x < x ∨x ≮x) is
an example, though it has still a root in propositional logic. Tautologies
without a such a root are ∃x x==== x and ∃x x==== t for x /∈var t. The former
arises from the convention that structures are always nonempty, the latter
from the restriction to totally deﬁned basic operations. A particularly
interesting tautology is given by the following
Example 1 (Russell’s antinomy). We will show that the “Russellian
set” u, consisting of all sets not containing themselves as a member, does
not exist which clearly follows from ⊨¬∃u∀x(x ∈u ↔x /∈x). We start with
∀x(x ∈u ↔x /∈x) ⊨u ∈u ↔u /∈u. This holds by Corollary 3.6(a). Clearly,
u ∈u ↔u /∈u is unsatisﬁable. Hence, the same holds for ∀x(x ∈u ↔x /∈x),
and thus for ∃u∀x(x ∈u ↔x /∈x). Consequently, ⊨¬∃u∀x(x ∈u ↔x /∈x).
Note that we need not assume in the above argument that ∈means
membership. The proof of ⊨¬∃u∀x(x ∈u ↔x /∈x) need not be related to
set theory at all. Hence, our example represents rather a logical paradox
than a set-theoretic antinomy. What looks like an antinomy here is the
expectation that ∃u∀x(x ∈u ↔x /∈x) should hold in set theory if ∈is to
mean membership and Cantor’s deﬁnition of a set is taken literally.
The satisfaction clause for α →β easily yields α ⊨β
⇔
⊨α →β,
a special case of X, α ⊨β
⇔
X ⊨α →β.
This can be very useful
in checking whether formulas given in implicative form are tautologies, as
was mentioned already in 1.3. For instance, from ∀xα ⊨α tx (which holds
for collision-free α, tx ) we immediately get ⊨∀xα →α tx .

74
2 First-Order Logic
As in propositional logic, α ≡β is again equivalent to ⊨α ↔β.
By inserting L-formulas for the variables of a propositional equivalence
one automatically procures one of predicate logic.
Thus, for instance,
α →β ≡¬α ∨β, because certainly p →q ≡¬p ∨q. Since every L-formula
results from the insertion of propositionally irreducible L-formulas in a
formula of propositional logic, one also sees that every L-formula can be
converted into a conjunctive normal form. But there are also numerous
other equivalences, for example ¬∀xα ≡∃x¬α and ¬∃xα ≡∀x¬α. The
ﬁrst of these means just ¬∀xα ≡¬∀x¬¬α (= ∃x¬α), obtained by replac-
ing α by the equivalent formula ¬¬α under the preﬁx ∀x. This is a simple
application of Theorem 4.1 below with ≡for ≈.
As in propositional logic, semantic equivalence is an equivalence relation
in L and, moreover, a congruence in L.
Speaking more generally, an
equivalence relation ≈in L satisfying the congruence property
CP:
α ≈α′, β ≈β′ ⇒α ∧β ≈α′ ∧β′, ¬α ≈¬α′, ∀xα ≈∀xα′
is termed a congruence in L. Its most important property is expressed by
Theorem 4.1 (Replacement theorem). Let ≈be a congruence in L
and α ≈α′. If ϕ′ results from ϕ by replacing the formula α at one or
more of its occurrences in ϕ by the formula α′, then ϕ ≈ϕ′.
Proof by induction on ϕ. Suppose ϕ is a prime formula. Both for ϕ = α
and ϕ ̸= α, ϕ ≈ϕ′ clearly holds. Now let ϕ = ϕ1 ∧ϕ2. In case ϕ = α
holds trivially ϕ ≈ϕ′. Otherwise ϕ′ = ϕ′
1 ∧ϕ′
2, where ϕ′
1, ϕ′
2 result from
ϕ1, ϕ1 by possible replacements. By the induction hypothesis ϕ1 ≈ϕ′
1
and ϕ2 ≈ϕ′
2. Hence, ϕ = ϕ1 ∧ϕ2 ≈ϕ′
1 ∧ϕ′
2 = ϕ′ according to CP above.
The induction steps for ¬, ∀follow analogously.
This theorem will constantly be used, mainly with ≡for ≈, without
actually speciﬁcally being cited, just as in the arithmetical rearrangement
of terms, where the laws of arithmetic used are hardly ever named ex-
plicitly. The theorem readily implies that CP is provable for all deﬁned
connectives such as
→and ∃. For example, α ≈α′ ⇒∃xα ≈∃xα′,
because α ≈α′ ⇒∃xα = ¬∀x¬α ≈¬∀x¬α′ = ∃xα′.
First-order languages have a ﬁner structure than those of propositional
logic. There are consequently further interesting congruences in L. In
particular, formulas α, β are equivalent in an L-structure A, in symbols

2.4 General Validity and Logical Equivalence
75
α ≡A β, if A ⊨α [w] ⇔A ⊨β [w], for all w. Hence, in A = (N, <, +, 0)
the formulas x < y and ∃z (z ̸==== 0 ∧x + z ==== y) are equivalent. The proof
of CP for ≡A is very simple and is therefore left to the reader.
Clearly, α ≡A β is equivalent to A ⊨α ↔β. Because of ≡⊆≡A,
properties such as ¬∀xα ≡∃x¬α carry over from ≡to ≡A. But there
are often new interesting equivalences in certain structures. For instance,
there are structures in which every formula is equivalent to a formula
without quantiﬁers, as we will see in 5.6.
A very important fact with an almost trivial proof is that the intersec-
tion of a family of congruences is itself a congruence. Consequently, for
any class K ̸= ∅of L-structures, ≡K := {≡A| A ∈K} is necessarily a
congruence. For the class K of all L-structures, ≡K equals the logical
equivalence ≡, which in this section we deal with exclusively. Below we
list its most important features; these should be committed to memory,
since they will continually be applied.
(1)
∀x(α ∧β) ≡∀xα ∧∀xβ,
(2)
∃x(α ∨β) ≡∃xα ∨∃xβ,
(3)
∀x∀yα ≡∀y∀xα,
(4)
∃x∃yα ≡∃y∃xα.
If x does not occur free in the formula β, then also
(5)
∀x(α ∨β) ≡∀xα ∨β,
(6)
∃x(α ∧β) ≡∃xα ∧β,
(7)
∀xβ ≡β,
(8)
∃xβ ≡β,
(9)
∀x(α →β) ≡∃xα →β,
(10)
∃x(α →β) ≡∀xα →β.
The simple proofs are left to the reader. (7) and (8) were stated in (2)
in 2.3. Only (9) and (10) look at ﬁrst sight surprising. But in practice
these equivalences are very frequently used. For instance, consider for a
ﬁxed set of formulas X the evidently true metalogical assertion ‘for all α:
if X ⊨α, ¬α then X ⊨∀x x̸====x’. This clearly states the same as ‘If there
is some α such that X ⊨α, ¬α then X ⊨∀x x̸====x’.
Remark. In everyday speech variables tend to remain unquantiﬁed, partly be-
cause in some cases the same meaning results from quantifying with “there exists
a” as with “for all.” For instance, consider the following three sentences, which
obviously tell us the same thing, and of which the last two correspond to the
logical equivalence (9):
• If a lawyer ﬁnds a loophole in the law it must be changed.
• If there is a lawyer who ﬁnds a loophole in the law it must be changed.
• For all lawyers: if one of them ﬁnds a loophole in the law then it must be
changed.

76
2 First-Order Logic
Often, the type of quantiﬁcation in linguistic bits of information can be made
out only from the context, and this leads not all too seldom to unintentional (or
intentional) misunderstandings. “Logical relations in language are almost always
just alluded to, left to guesswork, and not actually expressed” (G. Frege).
Let x, y be distinct variables and α ∈L. One of the most important
logical equivalences is renaming of bound variables (in short, bound re-
naming), stated in
(11)
(a) ∀xα ≡∀y(α y
x),
(b) ∃xα ≡∃y(α y
x)
(y /∈var α).
(b) follows from (a) by rearranging equivalently. Note that y /∈var α is
equivalent to y /∈free α and α, y
x collision-free. Writing My
x for MyM
x
, (a)
derives as follows:
M ⊨∀xα ⇔Ma
x ⊨α
for all a
(deﬁnition)
⇔(Ma
y)a
x ⊨α for all a
(Theorem 3.1)
⇔(Ma
y)y
x ⊨α for all a
	
(Ma
y)y
x = (Ma
y)a
x

⇔Ma
y ⊨α y
x
for all a
(Theorem 3.5)
⇔M ⊨∀y(α y
x).
(12) and (13) below are also noteworthy. According to (13), substitu-
tions are completely described up to logical equivalence by so-called free
renamings (substitutions of the form
y
x).
(13) also embraces the case
x ∈var t. In (12) and (13) we tacitly assume that α, tx are collision-free.
(12) ∀x(x==== t →α) ≡α tx ≡∃x(x==== t ∧α)
(x /∈var t).
(13) ∀y(y ==== t →α y
x) ≡α tx ≡∃y(y ==== t ∧α y
x)
(y /∈var α, t).
Proof of (12): ∀x(x==== t →α) ⊨(x==== t →α) tx = t==== t →α tx ⊨α tx by
Corollary 3.6.
Conversely, let M ⊨α tx .
If Ma
x ⊨x==== t then clearly
a = tM. Hence also Ma
x ⊨α, since MtM
x
⊨α. Thus, Ma
x ⊨x==== t →α for
any a ∈A, i.e., M ⊨∀x(x==== t →α). This proves the left equivalence in
(12). The right equivalence reduces to the left one because
∃x(x==== t ∧α) = ¬∀x¬(x==== t ∧α) ≡¬∀x(x==== t →¬α) ≡¬¬α tx ≡α tx .
Item (13) is proved similarly. Note that ∀y(y ==== t →α y
x) ⊨α y
x ty = α tx
by Corollary 3.6 and Exercise 4 in 2.2.
With the above equivalences we can now regain an equivalent formula
starting with any formula in which all quantiﬁers are standing at the be-
ginning. But this result requires both quantiﬁers ∀and ∃, in the following
denoted by Q, Q1, Q2, . . .

2.4 General Validity and Logical Equivalence
77
A formula of the form α = Q1x1 · · · Qnxnβ with an open formula β
is termed a prenex formula or a prenex normal form, in short, a PNF.
β is called the kernel of α. W.l.o.g. x1, . . . , xn are distinct and xi occurs
free in β since we may drop “superﬂuous quantiﬁers,” see (2) page 66.
Prenex normal forms are very important for classifying deﬁnable number-
theoretic predicates in 6.3, and for other purposes. The already mentioned
∀- and ∃-formulas are the simplest examples.
Theorem 4.2 (on the prenex normal form). Every formula ϕ is
equivalent to a formula in prenex normal form that can eﬀectively be con-
structed from ϕ.
Proof. Without loss of generality let ϕ contain only the logical symbols
¬, ∧, ∀, ∃(besides ====). For each preﬁx Qx in ϕ consider the number of
symbols ¬ or ∧occurring to the left of Qx. Let sϕ be the sum of these
numbers, summed over all preﬁxes occurring in ϕ. Clearly, ϕ is a PNF iﬀ
sϕ = 0. Let sϕ ̸= 0. Then ϕ contains some preﬁx Qx and ¬ or ∧stands
immediately in front of Qx. A successive application of either
¬∀xα ≡∃x¬α, ¬∃xα ≡∀x¬α, or β ∧Qxα ≡Qy( b ∧α y
x) (y /∈var α, β),
inside ϕ obviously reduces sϕ stepwise.
Example 2. ∀x∃y(x̸====0 →x·y ==== 1) is a PNF for ∀x(x̸====0 →∃y x·y ==== 1).
And ∃x∀y∀z(ϕ ∧(ϕ y
x ∧ϕ zx →y ==== z)) for ∃xϕ ∧∀y∀z(ϕ y
x ∧ϕ zx →y ==== z),
provided y, z /∈free ϕ; if not, a bound renaming will help. An equivalent
PNF for this formula with minimal quantiﬁer rank is ∃x∀y(ϕ y
x ↔x==== y).
The formula ∀x(x̸====0 →∃y x·y ==== 1) from Example 2 may be abbreviated
by (∀x̸====0)∃y x · y ==== 1. More generally, we shall often write (∀x̸====t)α for
∀x(x̸====t →α) and (∃x̸====t)α for ∃x(x̸====t ∧α). A similar notation is used
for ⩽, <, ∈and their negations.
For instance, (∀x⩽t)α and (∃x⩽t)α
are to mean ∀x(x⩽t →α) and ∃x(x⩽t ∧α), respectively. For any binary
relation symbol ◁, the “preﬁxes” (∀y◁x) and (∃y◁x) are related to each
other, as are ∀and ∃, see Exercise 2.
Exercises
1. Let α ≡β. Prove that α ⃗t
⃗x ≡β ⃗t
⃗x
(α, ⃗t
⃗x and β, ⃗t
⃗x collision-free).
2. Prove that ¬(∀x◁y)α ≡(∃x◁y)¬α and ¬(∃x◁y)α ≡(∀x◁y)¬α.
Here ◁represents any binary relation symbol.

78
2 First-Order Logic
3. Show by means of bound renaming that both the conjunction and
the disjunction of ∀-formulas α, β is equivalent to some ∀-formula.
Prove the same for ∃-formulas.
4. Show that every formula ϕ ∈L is equivalent to some ϕ′ ∈L built
up from literals by means of ∧, ∨, and ∃.
5. Let P be a unary predicate symbol. Prove that ∃x(Px →∀yPy) is
a tautology.
6. Call α, β ∈L tautologically equivalent if ⊨α ⇔⊨β. Conﬁrm that
the following (in general not logically equivalent) formulas are tau-
tologically equivalent: α, ∀xα, and α cx, where the constant symbol
c does not occur in α.
2.5
Logical Consequence and Theories
Whenever L′ ⊇L, the language L′ is called an expansion or extension
of L and L a reduct or restriction of L′. Recall the insensitivity of the
consequence relation to extensions of a ﬁrst-order language, mentioned in
2.3. Theorem 3.1 yields that establishing X ⊨α does not depend on the
language to which the set of formulas X and the formula α belong. For
this reason, indices for ⊨, such as ⊨L, are dispensable.
Because of the unaltered satisfaction conditions for ∧and ¬, all prop-
erties of the propositional consequence gained in 1.3 carry over to the
ﬁrst-order logical consequence relation. These include general properties
such as, for example, the reﬂexivity and transitivity of ⊨, and the seman-
tic counterparts of the rules ( ∧1), ( ∧2), (¬1), (¬2) from 1.4, for instance
the counterpart of ( ∧1), X ⊨α, β
X ⊨α ∧β .5
In addition, Gentzen-style properties such as the deduction theorem
automatically carry over. But there are also completely new properties.
Some of these will be elevated to basic rules of a logical calculus for ﬁrst-
order languages in 3.1, to be found among the following ones:
5 A suggestive way of writing “X ⊨α, β implies X ⊨α ∧β,” a notation that was
introduced already in Exercise 3 in 1.3. A corresponding notation will also be used
in stating the properties of ⊨on the next page.

2.5 Logical Consequence and Theories
79
Some properties of the predicate logical consequence relation.
(a) X ⊨∀xα
X ⊨α tx
(α, tx collision-free),
(b) X ⊨α sx, s==== t
X ⊨α tx
(α, sx and α, tx collision-free),
(c)
X, β ⊨α
X, ∀xβ ⊨α
(anterior generalization),
(d)
X ⊨α
X ⊨∀xα
(x /∈free X, posterior generalization),
(e)
X, β ⊨α
X, ∃xβ ⊨α
(x /∈free X, α, anterior particularization),
(f) X ⊨α tx
X ⊨∃xα
(α, tx collision-free, posterior particularization)
(a) follows from X ⊨∀xα ⊨α tx , for ⊨is transitive. Similarly, (b) follows
from α sx, s==== t ⊨α tx , stated in Corollary 3.6. Analogously (c) results from
∀xβ ⊨β. To prove (d), suppose that X ⊨α, M ⊨X, and x /∈free X.
Then Ma
x ⊨X for any a ∈A by Theorem 3.1, which just means M ⊨∀xα.
As regards (e), let X, β ⊨α. Observe that by contraposition and by (d),
X, β ⊨α ⇒X, ¬α ⊨¬β ⇒X, ¬α ⊨∀x¬β,
whence X, ¬∀x¬β ⊨α. (e) captures deduction from an existence claim,
while (f) conﬁrms an existence claim. (f) holds since α tx ⊨∃xα according
to Corollary 3.6. Both (e) and (f) are permanently applied in mathemati-
cal reasoning and will brieﬂy be discussed in Example 1 on the next page.
All above properties have certain variants; for example, a variant of (d) is
(g)
X ⊨α y
x
X ⊨∀xα
(y /∈free X ∪var α).
This results from (d) with α y
x for α and y for x, since ∀yα y
x ≡∀xα.
From the above properties, complicated chains of deduction can, where
necessary, be justiﬁed step by step. But in practice this makes sense only
in particular circumstances, because formalized proofs are readable only
at the expense of a lot of time, just as with lengthy computer programs,
even with well-prepared documentation. What is most important is that a
proof, when written down, can be understood and reproduced. This is why
mathematical deduction tends to proceed informally, i.e., both claims and

80
2 First-Order Logic
their proofs are formulated in a mathematical “everyday” language with
the aid of fragmentary and ﬂexible formalization. To what degree a proof
is to be formalized depends on the situation and need not be determined
in advance. In this way the strict syntactic structure of formal proofs is
slackened, compensating for the imperfection of our brains in regard to
processing syntactic information.
Further, certain informal proof methods will often be described by a
more or less clear reference to so-called background knowledge, and not
actually carried out.
This method has proven itself to be suﬃciently
reliable. As a matter of fact, apart from speciﬁc cases it has not yet been
bettered by any of the existing automatic proof machines. Let us present
a very simple example of an informal proof in a language L for natural
numbers that along with 0, 1, +, · contains the symbol
for divisibility,
deﬁned by m n ⇔∃k m · k = n. In addition, let L contain a symbol f for
some given function from N to N. We need no closer information on this
function, but we shall write fi for f(i) in Example 1.
Example 1. We want to prove ∀n∃x(∀i⩽n)fi x. That is, for every n,
f0, . . . , fn have a common multiple. A careful proof proceeds by induction
on n. Here we focus solely on X, ∃x(∀i⩽n)fi x ⊨∃x(∀i⩽n+1)fi x, the
induction step. X represents our prior knowledge about familiar proper-
ties of divisibility. Informally we reason as follows: Suppose ∃x(∀i⩽n)fi x
and let x denote any common multiple of f0, . . . , fn.
Then x · fn+1 is
clearly a common multiple of f0, . . . , fn+1, hence ∃x(∀i⩽n+1)fi x. That’s
all. To argue here formally like a proof machine, let us start from the
obvious (∀i⩽n)fi x ⊨(∀i⩽n+1)fi (x·fn+1). Posterior particularization of
x yields X, (∀i⩽n)fi x ⊨∃x(∀i⩽n+1)fi x. From this follows the desired
X, ∃x(∀i⩽n)fi x ⊨∃x(∀i⩽n+1)fi x by anterior particularization. Thus,
formalizing a nearly trivial informal argument may need a lot of writing
and turns out to be nontrivial in some sense.
Some textbooks deal with a somewhat stricter consequence relation,
which we denote here by ⊨
g. The reason is that in mathematics one largely
considers derivations in theories. For X ⊆L and ϕ ∈L deﬁne X ⊨
g ϕ if
A ⊨X ⇒A ⊨ϕ, for all L-structures A. In contrast to ⊨, which may
be called the local consequence relation, ⊨
g can be considered as the global
consequence relation since it cares only about A, not about a concrete
valuation w in A as does ⊨.

2.5 Logical Consequence and Theories
81
Let us collect a few properties of ⊨
g. Obviously, X ⊨ϕ implies X ⊨
g ϕ, but
the converse does not hold in general. For example, x==== y ⊨
g ∀xy x==== y,
but x==== y ⊭∀xy x==== y. By (d) from page 79, X ⊨ϕ ⇒X ⊨ϕg holds
in general only if the free variables of ϕ do not occur free in X, while
X ⊨
g ϕ ⇒X ⊨
g ϕg (hence ϕ ⊨
g ϕg) holds unrestrictedly. A reduction of ⊨
g
to ⊨is provided by the following equivalence, which easily follows from
M ⊨X g ⇔A ⊨X g, for each model M = (A, w):
(1)
X ⊨
g ϕ ⇔X g ⊨ϕ.
Because of S g = S for sets of sentences S, we clearly obtain from (1)
(2)
S ⊨
g ϕ ⇔S ⊨ϕ
(S ⊆L0).
In particular, ⊨
g ϕ ⇔⊨ϕ. Thus, a distinction between ⊨and ⊨
g is apparent
only when premises are involved that are not sentences. In this case the
relation ⊨
g must be treated with the utmost care. Neither the rule of case
distinction X, α ⊨
g β X, ¬α ⊨
g β
X ⊨g β
nor the deduction theorem
X, α ⊨
g β
X ⊨g α →β is
unrestrictedly correct. For example x==== y ⊨
g ∀xy x==== y, but it is false that
⊨
g x==== y →∀xy x==== y. This means that the deduction theorem fails to hold
for the relation ⊨
g. It holds only under certain restrictions.
One of the reasons for our preference of ⊨over ⊨
g is that ⊨extends the
propositional consequence relation conservatively, so that features such as
the deduction theorem carry over unrestrictedly, while this is not the case
for ⊨
g. It should also be said that ⊨
g does not reﬂect the actual procedures of
natural deduction in which formulas with free variables are frequently used
also in deductions of sentences from sentences, for instance in Example 1.
We now make more precise the notion of a formalized theory in L, where
it is useful to think of the examples in 2.3, such as group theory. Again,
the deﬁnitions by diﬀerent authors may look somewhat diﬀerently.
Deﬁnition. An elementary theory or ﬁrst-order theory in L, also termed
an L-theory, is a set of sentences T ⊆L0 deductively closed in L0, i.e.,
T ⊨α ⇔α ∈T, for all α ∈L0. If α ∈T then we say that α is valid
or true or holds in T, or α is a theorem of T. The extralogical symbols
of L are called the symbols of T. If T ⊆T ′ then T is called a subtheory
of T ′, and T ′ an extension of T. An L-structure A such that A ⊨T is
also termed a model of T, brieﬂy a T-model. Md T denotes the class of
all models of T in this sense; Md T consist of L-structures only.

82
2 First-Order Logic
For instance, {α ∈L0 | X ⊨α} is a theory for any set X ⊆L, since ⊨
is transitive. A theory T in L satisﬁes T ⊨ϕ ⇔A ⊨ϕ for all A ⊨T,
where ϕ ∈L is any formula. Important is also T ⊨ϕ ⇔T ⊨ϕg. These
readily conﬁrmed facts should be taken in and remembered, since they
are constantly used. Diﬀerent authors may use diﬀerent deﬁnitions for a
theory. For example, they may not demand that theories contain sentences
only, as we do. Conventions of this type each have their advantages and
disadvantages. Proofs regarding theories are always adaptable enough to
accommodate small modiﬁcations of the deﬁnition. Using the deﬁnition
given above we set the following
Convention. In talking of the theory S, where S is a set of sentences, we
always mean the theory determined by S, that is, {α ∈L0 | S ⊨α}. A set
X ⊆L is called an axiom system for T whenever T = {α ∈L0 | X g ⊨α},
i.e., we tacitly generalize all possibly open formulas in X. We have always
to think of free variables occurring in axioms as being generalized.
Thus, axioms of a theory are always sentences. But we conform to stan-
dard practice of writing long axioms as formulas. We will later consider
extensive axiom systems (in particular, for arithmetic and set theory)
whose axioms are partly written as open formulas just for economy.
There exists a smallest theory in L, namely the set Taut (= TautL) of all
generally valid sentences in L, also called the “logical” theory. An axiom
system for Taut is the empty set of axioms. There is also a largest the-
ory: the set L0 of all sentences, the inconsistent theory, which possesses
no models. All remaining theories are called satisﬁable or consistent.6
Moreover, the intersection T = 
i∈I Ti of a nonempty family of theories
Ti is in turn a theory: if T ⊨α ∈L0 then clearly Ti ⊨α and so α ∈Ti for
each i ∈I, hence α ∈T as well. In this book T and T ′, with or without
indices, exclusively denote theories.
For T ⊆L0 and α ∈L0 let T + α denote the smallest theory that
extends T and contains α. Similarly let T + S for S ⊆L0 be the smallest
theory containing T ∪S. If S is ﬁnite then T ′ = T +S = T + S is called
a ﬁnite extension of T. Here  S denotes the conjunction of all sentences
in S. A sentence α is termed compatible or consistent with T if T + α is
6 Consistent mostly refers to a logic calculus, e.g., the calculus in 3.1. However, it will
be shown in 3.2 that consistency and satisﬁability of a theory coincide, thus justifying
the word’s ambiguous use.

2.5 Logical Consequence and Theories
83
satisﬁable, and refutable in T if T +¬α is satisﬁable. Thus, the theory TF
of ﬁelds is compatible with the sentence 1 + 1==== 0. Equivalently, 1 + 1̸====0
is refutable in TF , since the 2-element ﬁeld satisﬁes 1 + 1==== 0.
If both α and ¬α are compatible with T then the sentence α is termed
independent of T. The classic example is the independence of the parallel
axiom from the remaining axioms of Euclidean plane geometry, which
deﬁne absolute geometry. Much more diﬃcult is the independence proof
of the continuum hypothesis from the axioms for set theory. These axioms
are presented and discussed in 3.4.
At this point we introduce another important concept; α, β ∈L are
said to be equivalent in or modulo T, α ≡T β, if α ≡A β for all A ⊨T.
Being an intersection of congruences, ≡T is itself a congruence and hence
satisﬁes the replacement theorem. This will henceforth be used without
mention, as will the obvious equivalence of α ≡T β, T ⊨α ↔β, and of
T ⊨(α ↔β)g. A suggestive writing of α ≡T β would also be α====T β.
Example 2. Let TG be as on p. 65. Claim: x ◦x==== x ≡TG x==== e. The only
tricky proof step is TG ⊨x ◦x==== x →x==== e. Let x ◦x==== x and choose some
y with x ◦y ==== e. The claim then follows from x==== x ◦e==== x ◦x ◦y ==== x ◦y ==== e.
A strict formal proof of the latter uses anterior particularization.
Another important congruence is term equivalence.
Call terms s, t
equivalent modulo (or in) T, in symbols s ≈T t, if T ⊨s==== t, that is,
A ⊨s==== t [w] for all A ⊨T and w: Var →A. For instance, in T = T =
==
=
G ,
(x ◦y)−1 ==== y−1 ◦x−1 is easily provable, so that (x ◦y)−1 ≈T y−1 ◦x−1.
Another example: in the theory of ﬁelds, each term is equivalent to a
polynomial in several variables with integer coeﬃcients.
If all axioms of a theory T are ∀-sentences then T is called a univer-
sal or ∀-theory. Examples are partial orders, orders, rings, lattices, and
Boolean algebras. For such a theory, Md T is closed with respect to sub-
structures, which means A ⊆B ⊨T ⇒A ⊨T. This follows at once
from Corollary 3.3. Conversely, a theory closed with respect to substruc-
tures is necessarily a universal one, as will turn out in 5.4. ∀-theories are
further classiﬁed. The most important subclasses are equational, quasi-
equational, and universal Horn theories, all of which will be considered to
some extent in later chapters. Besides ∀-theories, the ∀∃-theories (those
having ∀∃-sentences as axioms) are of particular interest for mathematics.
More about all these theories will be said in 5.4.

84
2 First-Order Logic
Theories are frequently given by structures or classes of structures. The
elementary theory Th A and the theory Th K of a nonempty class K of
structures are deﬁned respectively by
Th A := {α ∈L0 | A ⊨α},
Th K := {Th A | A ∈K}.
It is easily seen that Th A and Th K are theories in the precise sense
deﬁned above. Instead of α ∈Th K one often writes K ⊨α. In general,
Md Th K is larger than K, as we shall see.
One easily conﬁrms that the set of formulas breaks up modulo T (more
precisely, modulo ≡T ) into equivalence classes; their totality is denoted
by BωT. Based on these we can deﬁne in a natural manner operations
∧, ∨, ¬.
For instance, ¯α ∧¯β = α ∧β, where ¯ϕ denotes the equivalence
class to which ϕ belongs. One shows easily that BωT forms a Boolean
algebra with respect to
∧, ∨, ¬.
For every n, the set BnT of all ¯ϕ in
BωT such that the free variables of ϕ belong to Varn (= {v0, . . . , vn−1})
is a subalgebra of BωT.
Note that B0T is isomorphic to the Boolean
algebra of all sentences modulo ≡T , also called the Tarski–Lindenbaum
algebra of T. The signiﬁcance of the Boolean algebras BnT is revealed only
in the somewhat higher reaches of model theory, and they are therefore
mentioned only incidentally.
Exercises
1. Suppose x /∈free X and c is not in X, α. Prove the equivalence of
(i) X ⊨α,
(ii) X ⊨∀xα,
(iii) X ⊨α cx.
This holds then in particular if X is the axiom system of a theory
or itself a theory. Then x /∈free X is trivially satisﬁed.
2. Let S be a set of sentences, α and β formulas, x /∈free β, and let c
be a constant not occurring in S, α, β. Show that
S ⊨α cx →β ⇔S ⊨∃xα →β.
3. Verify for all α, β ∈L0 that β ∈T + α ⇔α →β ∈T.
4. Let T ⊆L be a theory, L0 ⊆L, and T0 := T ∩L0. Prove that T0 is
also a theory (the so-called reduct theory in the language L0).

2.6 Explicit Deﬁnitions—Language Expansions
85
2.6
Explicit Deﬁnitions—Language Expansions
The deductive development of a theory, be it given by an axiom system
or a single structure or classes of those, nearly always goes hand in hand
with expansions of the language carried out step by step. For example,
in developing elementary number theory in the language L(0, 1, +, ·), the
introduction of the divisibility relation by means of the (explicit) deﬁnition
x y ↔∃z x · z ==== y has certainly advantages not only for purely technical
reasons. This and similar examples motivate the following
Deﬁnition I. Let r be an n-ary relation symbol not occurring in L. An
explicit deﬁnition of r in L is to mean a formula of the form
ηr :
r⃗x ↔δ(⃗x)
with δ(⃗x) ∈L and distinct variables in ⃗x, called the deﬁning formula.
For a theory T, the extension Tr := T + η g
r is then called a deﬁnitorial
extension (or expansion) of T by r, more precisely, by ηr.
Tr is a theory in L[r], the language resulting from L by adjoining the
symbol r. It will turn out that Tr is a conservative extension of T, which,
in the general case, means a theory T ′ ⊇T in L′ ⊇L such that T ′∩L = T.
Thus, Tr contains exactly the same L-sentences as does T. In this sense, Tr
is a harmless extension of T. Our claim constitutes part of Theorem 6.1.
For ϕ ∈L[r] deﬁne the reduced formula ϕrd ∈L as follows: Starting from
the left, replace every prime formula r⃗t occurring in ϕ by δ⃗x(⃗t ). Clearly,
ϕrd = ϕ, provided r does not appear in ϕ.
Theorem 6.1 (Elimination theorem). Let Tr ⊆L[r] be a deﬁnitorial
extension of the theory T ⊆L0 by the explicit deﬁnition ηr. Then for all
formulas ϕ ∈L[r] holds the equivalence
(∗)
Tr ⊨ϕ ⇔T ⊨ϕrd.
For ϕ ∈L we get in particular Tr ⊨ϕ ⇔T ⊨ϕ (since ϕrd = ϕ). Hence,
Tr is a conservative extension of T, i.e., α ∈Tr ⇔α ∈T, for all α ∈L0.
Proof. Each A ⊨T is expandable to a model A′ ⊨Tr with the same
domain, setting rA′⃗a :⇔A ⊨δ [⃗a] (⃗a ∈An). Since r⃗t ≡Tr δ(⃗t ) for any ⃗t ,
we obtain ϕ ≡Tr ϕrd for all ϕ ∈L[r] by the replacement theorem. Thus,
(∗) follows from

86
2 First-Order Logic
Tr ⊨ϕ ⇔A′ ⊨ϕ for all A ⊨T
(Md Tr = {A′ | A ⊨T})
⇔A′ ⊨ϕrd for all A ⊨T
(because ϕ ≡Tr ϕrd)
⇔A ⊨ϕrd for all A ⊨T
(Theorem 3.1)
⇔T ⊨ϕrd.
Operation symbols and constants can be similarly introduced, though
in this case there are certain conditions to observe. For instance, in TG
(see page 65) the operation −1 is deﬁned by η : y ==== x−1 ↔x ◦y ==== e. This
deﬁnition is legitimate, since TG ⊨∀x∃!y x ◦y ==== e; Exercise 3. Only this
requirement (which by the way is a logical consequence of η) ensures that
TG+η g is a conservative extension of TG. We therefore extend Deﬁnition I
as follows, keeping in mind that to the end of this section constant symbols
are to be counted among the operation symbols.
Deﬁnition II. An explicit deﬁnition of an n-ary operation symbol f not
occurring in L is a formula of the form
ηf :
y ==== f⃗x ↔δ(⃗x, y)
(δ ∈L and y, x1, . . . , xn distinct).
ηf is called legitimate in T ⊆L if T ⊨∀⃗x ∃!yδ, and Tf := T + η g
f is
then called a deﬁnitorial extension by f, more precisely by ηf. In the case
n = 0 we write c for f and speak of an explicit deﬁnition of the constant
symbol c. Written more suggestively y ==== c ↔δ(y).
Some of the free variables of δ are often not explicitly named, and thus
downgraded to parameter variables.
More on this will be said in the
discussion of the axioms for set theory in 3.4. The elimination theorem is
proved in almost exactly the same way as above, provided ηf is legitimate
in T. The reduced formula ϕrd is deﬁned correspondingly. For a constant
c (n = 0 in Deﬁnition II), let ϕrd := ∃z(ϕ zc ∧δ zy), where ϕ zc denotes the
result of replacing c in ϕ by z (/∈var ϕ). Now let n > 0. If f does not
appear in ϕ, set ϕrd = ϕ. Otherwise, looking at the ﬁrst occurrence of
f in ϕ from the left, we certainly may write ϕ = ϕ0
f⃗t
y for appropriate
ϕ0, ⃗t , and y /∈var ϕ.
Clearly, ϕ ≡Tf ∃y(ϕ0 ∧y ==== f⃗t ) ≡Tf ϕ1, with
ϕ1 := ∃y(ϕ0 ∧δf(⃗t , y)). If f still occurs in ϕ1 then repeat this procedure,
which ends in, say, m steps in a formula ϕm that no longer contains f.
Then put ϕrd := ϕm.
Frequently, operation symbols f are introduced in more or less strictly
formalized theories by deﬁnitions of the form
(∗)
f⃗x := t(⃗x),

2.6 Explicit Deﬁnitions—Language Expansions
87
where of course f does not occur in the term t(⃗x). This procedure is in
fact subsumed by Deﬁnition II, because the former is nothing more than
a deﬁnitorial extension of T with the explicit deﬁnition
ηf : y ==== f⃗x ↔y ==== t(⃗x).
This deﬁnition is legitimate, since ∀⃗x ∃!y y ==== t(⃗x) is a tautology. It can
readily be shown that η g
f is logically equivalent to ∀⃗x f⃗x==== t(⃗x). Hence,
(∗) can indeed be regarded as a kind of an informative abbreviation of a
legitimate explicit deﬁnition with the deﬁning formula y ==== t(⃗x).
Remark 1. Instead of introducing new operation symbols, so-called iota-terms
from [HB] could be used. For any formula ϕ = ϕ(⃗x, y) in a given language,
let ιyϕ be a term in which y appears as a variable bound by ι.
Whenever
T ⊨∀⃗x∃!yϕ, then T is extended by the axiom ∀⃗x∀y[y ==== ιyϕ(⃗x, y) ↔ϕ(⃗x, y)], so
that ιyϕ(⃗x, y) so to speak stands for the function term f⃗x, which could have been
introduced by an explicit deﬁnition. We mention that a deﬁnitorial language
expansion is not a necessity. In principle, formulas of the expanded language can
always be understood as abbreviations in the original language. This is in some
presentations the actual procedure, though our imagination prefers additional
notions over long sentences that would arise if we were to stick to a minimal set
of basic notions.
Deﬁnitions I and II can be uniﬁed in a more general declaration. Let
T, T ′ be theories in the languages L, L′, respectively. Then T ′ is called a
deﬁnitorial extension (or expansion) of T whenever T ′ = T + Δ for some
list Δ of explicit deﬁnitions of new symbols legitimate in T, given in terms
of those of T (here legitimate refers to operation symbols and constants
only). Δ need not be ﬁnite, but in most cases it is ﬁnite. A reduced
formula ϕrd ∈L is stepwise constructed as above, for every ϕ ∈L′.
In this way the somewhat long-winded proof of the following theorem is
reduced each time to the case of an extension by a single symbol:
Theorem 6.2 (General elimination theorem). Let T ′ be a deﬁnitorial
extension of T. Then α ∈T ′ ⇔αrd ∈T. In particular, α ∈T ′ ⇔α ∈T
whenever α ∈L, i.e., T ′ is a conservative extension of T.
A relation or operation symbol s occurring in T ⊆L is termed explicitly
deﬁnable in T if T contains an explicit deﬁnition of s whose deﬁning
formula belongs to L0, the language of symbols of T without s.
For
example, in the theory TG of groups the constant e is explicitly deﬁned
by x==== e ↔x ◦x==== x; Example 2 page 83. Another example is presented

88
2 First-Order Logic
in Exercise 3. In such a case each model of T0 := T ∩L0 can be expanded
in only one way to a T-model. If this special condition is fulﬁlled then s is
said to be implicitly deﬁnable in T. This could also be stated as follows: if
T ′ is distinct from T only in that the symbol s is everywhere replaced by a
new symbol s′, then either T ∪T ′ ⊨∀⃗x(s⃗x ↔s′⃗x) or T ∪T ′ ⊨∀⃗x(s⃗x==== s′⃗x),
depending on whether s, s′ are relation or operation symbols. It is highly
interesting that this kind of deﬁnability is already suﬃcient for the explicit
deﬁnability of s in T. But we will go without the proof and only quote
the following theorem.
Beth’s deﬁnability theorem. A relation or operation symbol implicitly
deﬁnable in a theory T is also explicitly deﬁnable in T.
Deﬁnitorial expansions of a language should be conscientiously distin-
guished from expansions of languages that arise from the introduction of
so-called Skolem functions. These are useful for many purposes and are
therefore brieﬂy described.
Skolem normal forms. According to Theorem 4.2, every formula α can
be converted into an equivalent PNF, α ≡Q1x1 · · · Qkxkα′, where α′ is
open. Obviously then ¬α ≡Q1x1 · · · Qkxk¬α′, where ∀= ∃and ∃= ∀.
Because ⊨α if and only if ¬α is unsatisﬁable, the decision problem for
general validity can ﬁrst of all be reduced to the satisﬁability problem
for formulas in PNF. Using Theorem 6.3 below, the latter—at the cost
of introducing new operation symbols—is then completely reduced to the
satisﬁability problem for ∀-formulas.
Call formulas α and β satisﬁably equivalent if both are satisﬁable (not
necessarily in the same model), or both are unsatisﬁable. We construct
for every formula, which w.l.o.g. is assumed to be given in prenex form
α = Q1x1 · · · Qkxkβ, a satisﬁably equivalent ∀-formula ˆα with additional
operation symbols such that free ˆα = free α. The construction of ˆα will be
completed after m steps, where m is the number of ∃-quantiﬁers among the
Q1, . . . , Qk. Take α = α0 and αi to be already constructed. If αi is already
an ∀-formula let ˆα = αi. Otherwise αi has the form ∀x1 · · · ∀xn∃yβi for
some n ⩾0. With an n-ary operation symbol f (which is a constant
in case n=0) not yet used let αi+1 = ∀⃗xβi
f⃗x
y . Thus, after m steps an
∀-formula ˆα is obtained such that free ˆα = free α; this formula ˆα is called
a Skolem normal form (SNF) of α.

2.6 Explicit Deﬁnitions—Language Expansions
89
Example 1. If α is the formula ∀x∃y x < y then ˆα is just ∀x x < fx.
For α = ∃x∀y x · y ==== y we have ˆα = ∀y c · y ==== y.
If α = ∀x∀y∃z(x < z ∧y < z) then ˆα = ∀x∀y(x < fxy ∧y < fxy).
Theorem 6.3. Let ˆα be a Skolem normal form for the formula α. Then
(a) ˆα ⊨α,
(b) α is satisﬁably equivalent to ˆα.
Proof. (a): It suﬃces to show that αi+1 ⊨αi for each of the described
construction steps. βi
f⃗x
y ⊨∃yβi implies αi+1 = ∀⃗xβi
f⃗x
y ⊨∀⃗x ∃yβi = αi,
by (c) and (d) in 2.5. (b): If ˆα is satisﬁable then by (a) so too is α.
Conversely, suppose A ⊨∀⃗x ∃yβi(⃗x, y, ⃗z) [⃗c ]. For each ⃗a ∈An we choose
some b ∈A such that A ⊨β [⃗a, b,⃗c ] (which is possible in view of the
axiom of choice AC) and expand A to A′ by setting fA′⃗a = b for the new
operation symbol. Then evidently A′ ⊨αi+1 [⃗c ]. Thus, we ﬁnally obtain
a model for ˆα that expands the initial model.
Now, for each α, a tautologically equivalent ∃-formula ˇα is gained as
well (that is, ⊨α ⇔⊨ˇα). By the above theorem, we ﬁrst produce for
β = ¬α a satisﬁably equivalent SNF ˆβ and put ˇα := ¬ˆβ. Then indeed
⊨α ⇔⊨ˇα, because
⊨α ⇔β unsatisﬁable ⇔ˆβ unsatisﬁable ⇔⊨ˇα.
Example 2. For α := ∃x∀y(ry →rx) we have ¬α ≡β := ∀x∃y(ry ∧¬rx)
and ˆβ = ∀x(rfx ∧¬rx). Thus, ˇα = ¬ˆβ ≡∃x(rfx →rx). The last formula
is a tautology. Indeed, if rA ̸= ∅then clearly A ⊨∃x(rfx →rx). But the
same holds if rA = ∅, for then never A ⊨rfx. Thus, ˇα and hence also α
is a tautology, which is not at all obvious after a ﬁrst glance at α. This
shows how useful Skolem normal forms can be for discovering tautologies.
Remark 2. There are many applications of Skolem normal forms, mainly in
model theory and in logic programming. For instance, Exercise 5 permits one to
reduce the satisﬁability problem of an arbitrary ﬁrst-order formula set to a set
of ∀-formulas (at the cost of adjoining new function symbols). Moreover, a set
X of ∀-formulas is satisﬁably equivalent to a set X′ of open formulas as will be
shown in 4.1, and this problem can be reduced completely to the satisﬁability of
a suitable set of propositional formulas, see also Remark 1 in 4.1. The examples
of applications of the propositional compactness theorem in 1.5 give a certain
feeling for how to proceed in this way.

90
2 First-Order Logic
Exercises
1. Suppose that Tf results from T by adjoining an explicit deﬁnition η
for f and let αrd be constructed as explained in the text. Show that
Tf is a conservative extension of T if and only if η is a legitimate
explicit deﬁnition.
2. Let S: n 
→n+1 denote the successor function in N = (N, 0, S, +, ·).
Show that Th N is a deﬁnitorial extension of Th (N, S, ·); in other
words, 0 and + are explicitly deﬁnable by S and · in N.
3. Prove that η : y ==== x−1 ↔x ◦y ==== e is a legitimate explicit deﬁnition
in TG (it suﬃces to prove TG ⊨x ◦y ==== x ◦z →y ==== z). Show in ad-
dition that T =
==
=
G
= TG + η. Thus, T =
==
=
G
is a deﬁnitorial and hence a
conservative extension of TG. In this sense, the theories T =
==
=
G
and TG
are equivalent formulations of the theory of groups.
4. As is well known, the natural <-relation of N is explicitly deﬁnable
in (N, 0, +), for instance, by x < y ↔(∃z̸====0)z + x==== y. Prove that
the <-relation of Z is not explicitly deﬁnable in (Z, 0, +).
5. Construct to each α ∈X (⊆L) an SNF ˆα such that X is satisﬁably
equivalent to ˆX = {ˆα | α ∈X} and ˆX ⊨X, called a Skolemization
of X. Since we do not suppose that X is countable, the function
symbols introduced in ˆX must properly be indexed.

Chapter 3
Complete logical Calculi
Our ﬁrst goal is to characterize the consequence relation in a ﬁrst-order
language by means of a calculus similar to that of propositional logic. That
this goal is attainable at all was shown for the ﬁrst time by Gödel in [Gö1].
The original version of Gödel’s theorem refers to the axiomatization of
tautologies only and does not immediately imply the compactness theorem
of ﬁrst-order logic; but a more general formulation of completeness in
3.2 does. The importance of the compactness theorem for mathematical
applications was ﬁrst revealed in 1936 by A. Malcev, see [Ma].
The characterizability of logical consequence by means of a calculus
(the content of the completeness theorem) is a crucial result in mathe-
matical logic with far-reaching applications. In spite of its metalogical
origin, the completeness theorem is essentially a mathematical theorem.
It satisfactorily explains the phenomenon of the well-deﬁnedness of logical
deductive methods in mathematics. To seek any additional, possibly un-
known methods or rules of inference would be like looking for perpetual
motion in physics. Of course, this insight does not aﬀect the development
of new ideas in solving open questions. We will say somewhat more re-
garding the metamathematical aspect of the theorem and its applications,
as well as the use of the model construction connected with its proof in a
partly descriptive manner, in 3.3, 3.4, and 3.5.
Without beating around the bush, we deal from the outset with the case
of an arbitrary, not necessarily countable ﬁrst-order language. Nonethe-
less, the proof given, based on Henkin’s idea of a constant expansion [He],
is kept relatively short, mainly thanks to an astute choice of its logical ba-
sis. Although mathematical theories are countable as a rule, a successful
W. Rautenberg, A Concise Introduction to Mathematical Logic,
91
Universitext, DOI 10.1007/978-1-4419-1221-3_3,
c⃝Springer Science+Business Media, LLC 2010

92
3 Complete Logical Calculi
application of methods of mathematical logic in algebra and analysis relies
essentially on the unrestricted version of the completeness theorem. Only
with such generality does the proof display the inherent unity that tends
to distinguish the proofs of magniﬁcent mathematical theorems.
3.1
A Calculus of Natural Deduction
As in Chapter 2, let L be an arbitrary but ﬁxed ﬁrst-order language in
the logical signature ¬, ∧, ∀, ==== . We deﬁne a calculus ⊢by the system
of deductive rules enclosed in the box below. The calculus operates with
sequents as in 1.4. It supplements the basic rules given there with three
predicate-logical rules. We also use the same modes of speaking, for in-
stance, ‘X ⊢α’ is read as ‘X derivable α’. Note that the initial rule (IR)
is subject to a minor extension. Using (MR), it could be pared down to
α ⊢α and ⊢t==== t, which are rules without premises like (IR).
(IR) X ⊢α (α ∈X ∪{t==== t})
(MR) X ⊢α
X′ ⊢α (X ⊆X′)
( ∧1) X ⊢α, β
X ⊢α ∧β
( ∧2) X ⊢α ∧β
X ⊢α, β
(¬1) X ⊢β, ¬β
X ⊢α
(¬2) X, β ⊢α
X, ¬β ⊢α
X ⊢α
(∀1) X ⊢∀xα
X ⊢α tx
(α, tx collision-free)
(∀2) X ⊢α y
x
X ⊢∀xα (y ̸∈free X ∪var α)
(=) X ⊢s==== t, α sx
X ⊢α tx
(α prime)
By (IR), X ⊢t==== t for arbitrary X and t, in particular ⊢t==== t. Here as
everywhere, ⊢ϕ stands for ∅⊢ϕ (read ‘ϕ is derivable’). The remaining
notation from 1.4 is also used here; thus, α ⊢β abbreviates {α} ⊢β, etc.
Note also that α ⊢β ⊢γ can have only the meaning α ⊢β and β ⊢γ.

3.1 A Calculus of Natural Deduction
93
⊢is called a calculus of natural deduction because it models logical
inference in mathematics and other deductive sciences suﬃciently well.1
Our aim is to show that ⊨is completely characterized by ⊢. The calculus
is developed in the sequel only insofar as the completeness proof requires.
While undertaking further derivations can be instructive (see the examples
and exercises), this is not the principal point of formalizing proofs unless
one is after speciﬁc proof-theoretic goals. It should also be said that an
acute study of formalized proofs does not really promote our ability to
draw correct conclusions in everyday life.
All basic rules are sound in the sense of 1.4. The restrictions in the rules
(∀1), (∀2), and (=) ensure their soundness as shown by the properties (a),
(g), and (b) on page 79. Rule (=) could have been strengthened from the
outset to allow α to be any formula such that α, sx, tx are collision-free,
but we get along with the weak version. Also (∀1) could be strengthened
by weakening its restriction that α, tx are collision-free in various ways.
As already stated in 2.3, we could in fact avoid any kind of restriction
by means of a more involved deﬁnition for substitution. However, such
measures would unnecessarily strengthen the calculus. Weakly formulated
logical calculi like the one given here often alleviate certain induction
procedures, for example in verifying these rules in other logical calculi, as
will be done in 3.6 for a certain Hilbert calculus.
Because ⊢can be understood as an extension of the corresponding cal-
culus from 1.4, all the examples of provable rules given there carry over
automatically, the cut rule included. All further sound rules, such as the
formal versions of generalization and particularization in 2.5, are provable
thanks to the completeness of the calculus. This is also true of the rule
X ⊢α
X ⊢∀xα (x /∈free X), which is sound by (d) in 2.5, though it does not
result directly from (∀2). However, we do not want to spend too much
time on the proofs of other rules; they are irrelevant for the completeness
proof, which can then be used to justify these rules retrospectively.
Just as in the propositional case the following proof method referring to
the base rules above will often be applied; it is legitimate because the proof
1 We deal here with a version of the calculus NK from [Ge] adapted to our purpose;
more involved descriptions of this and related sequent calculi are given in various
textbooks on proof theory; see e.g. [Po].

94
3 Complete Logical Calculi
of the corresponding principle in 1.4 depends on neither the language nor
the concrete rules.
Principle of rule induction. Let E be a property of sequents (X, α)
such that
(o)
E(X, α) provided α ∈X or α is of the form t==== t,
(s)
E(X, α) ⇒E(X′, α) for (MR), and similarly for ( ∧1)–(=).
Then X ⊢α implies E(X, α), for all X, α.
Since the basic rules are clearly sound, the soundness of the calculus,
that is to say ⊢⊆⊨, follows immediately by rule induction. Similarly one
obtains the following monotonicity property:
(mon)
L ⊆L′ ⇒⊢L ⊆⊢L′.
Here the derivability relation is indexed; note that every elementary lan-
guage deﬁnes its own derivability relation, and for the time being we are
concerned with the comparison of these relations in various languages.
Only with the completeness theorem will we see that the indices are su-
perﬂuous, just as for the consequence relation ⊨.
To prove (mon) let
E(X, α) be the property ‘X ⊢L′ α’, for which the conditions (o) and (s) of
rule induction are easily veriﬁed. To conﬁrm at least one of the induction
steps (i.e. the veriﬁcation of (s) for each single rule), let X ⊢L α, β and
suppose X ⊢L′ α, β. Then ( ∧1), applied in L′, yields X ⊢L′ α ∧β as well.
As in propositional logic we have here the easily provable
Finiteness theorem. If X ⊢α then X0 ⊢α for some ﬁnite X0 ⊆X.
The only diﬀerence to the proof from 1.4 is that a few more rules have
to be considered. Remember that L denotes the signature of L, L0 that
of L0, etc. For the moment we require a somewhat stronger version of the
ﬁniteness theorem, namely
(ﬁn) If X ⊢L α then there exist a ﬁnite signature L0 ⊆L and a ﬁnite
subset X0 ⊆X such that X0 ⊢L0 α.
Herein the claim X0 ⊢L0 α, of course, includes X0 ∪{α} ⊆L0. For the
proof, consider the property ‘there exist some ﬁnite X0 ⊆X and L0 ⊆L
such that X0 ⊢L0 α ’. It suﬃces to conﬁrm the conditions (o) and (s)
of the principle of rule induction. For α ∈X ∪{t==== t} we clearly have
X0 ⊢L0 α, where X0 = {α} or X0 = ∅. Thus, L0 may be chosen to contain
all the extralogical symbols occurring in α or in t==== t, and their number

3.1 A Calculus of Natural Deduction
95
is surely ﬁnite. This conﬁrms (o). The induction step on (MR) is trivial.
For ( ∧1) suppose X1 ⊢L1 α1 and X2 ⊢L2 α2 for some ﬁnite Xi ⊆X and
Li ⊆L, i = 1, 2. Then (mon) gives X0 ⊢L0 αi, where X0 = X1 ∪X2 and
L0 = L1 ∪L2. Applying ( ∧1) in L0, we obtain X0 ⊢L0 α1 ∧α2, which
is what we want.
The induction steps for all remaining rules proceed
similarly and are even somewhat simpler. This conﬁrms condition (s),
which in turn proves (ﬁn).
In the foregoing proof, L0 contains at least the extralogical symbols
of X0 and α but perhaps also some others. Only with the completeness
theorem can we know that the symbols occurring in X0, α in fact suf-
ﬁce. This insensitivity of derivation with respect to language extensions
can be derived purely proof-theoretically, albeit with considerable eﬀort,
but purely combinatorially and without recourse to the inﬁnitistic means
of semantics. A modest demonstration of such methods is the constant
elimination by Lemmas 2.1 and 2.2 from the next section.
Now for some more examples of provable rules required later.
Example 1. (a) X ⊢s==== t, s==== t′
X ⊢t==== t′
,
(b) X ⊢s==== t
X ⊢t==== s,
(c) X ⊢t==== s, s==== t′
X ⊢t==== t′
.
To show (a) let x /∈var t′ and let α be the formula x==== t′. Then the premise
of (a) is written X ⊢s==== t, α sx. Rule (=) yields X ⊢α tx. Now, α tx equals
t==== t′, since x /∈var t′; hence X ⊢t==== t′. (b) is obtained immediately from
(a), choosing there t′ = s because X ⊢s==== s. And with this follows (c),
for thanks to (b), the premise of (c) now yields X ⊢s==== t, s==== t′ and hence,
by (a), the conclusion of (c).
Example 2. In (a)–(d), n is as usual the arity of the symbols f and r.
(a) and (c) are provable for i = 1, . . . , n. In order to ease the writing,
X ⊢⃗t ==== ⃗t′ abbreviates X ⊢t1 ==== t′
1, . . . , tn ==== t′
n, so that, for instance, rule
(b) below has actually n premises:
(a)
X ⊢ti ==== t
X ⊢f⃗t ==== ft1 · · · ti−1tti+1 · · · tn
,
(b)
X ⊢⃗t ==== ⃗t′
X ⊢f⃗t ==== f⃗t′ ,
(c)
X ⊢ti ==== t, r⃗t
X ⊢rt1 · · · ti−1tti+1 · · · tn
,
(d) X ⊢⃗t ==== ⃗t′, r⃗t
X ⊢r⃗t′
.
Proof of (a): Let X ⊢ti ==== t and α := f⃗t ==== ft1 · · · ti−1xti+1 · · · tn, where
x is not to occur in any of the tj. Since X ⊢α tix (= f⃗t ==== f⃗t ), it follows

96
3 Complete Logical Calculi
that X ⊢α tx using (=). This is the conclusion of (a). (b) is then obtained
by considering Example 1(c) and the n-fold iteration of (a), as can best
be seen by ﬁrst working through the case n = 2. Rule (c) is just another
application of (=) by taking the formula rt1 · · · ti−1xti+1 · · · tn for α, where
again, x is supposed not to occur in any of the tj. Applying (c) n times
then yields (d).
The next example indicates that sometimes considerable eﬀort is needed
in formally deriving what is nearly obvious from the semantic point of
view. Of course, diﬃculties in formal proofs strongly depend on the cal-
culus in which these proofs are carried out.
Example 3. (a) ⊢∃x t==== x, for all x, t with x /∈var t,
(b) ⊢∃x x==== x.
(a) holds because (∀1) gives ∀x t̸====x ⊢t̸====t, for t̸====t equals (t̸====x) tx ; here
x /∈var t is required. Clearly, ∀x t̸====x ⊢t==== t as well. Thus, by (¬1),
∀x t̸====x ⊢∃x t==== x.
Trivially, also ¬∀x t ̸==== x ⊢∃x t==== x (= ¬∀x t ̸==== x). Therefore, by (¬2),
⊢∃x t==== x. The assumption x /∈var t is in fact essential in order to derive
∃x t==== x; cf. Example 1 in 2.3 page 63. (b) is veriﬁed similarly, starting
with ∀x x̸====x ⊢x̸====x, x==== x.
A set X (⊆L) is called inconsistent if X ⊢α for all α ∈L, and
otherwise consistent, exactly as in propositional logic. A satisﬁable set X
is evidently consistent. By (¬1), the inconsistency of X is equivalent to
X ⊢α, ¬α for any α, hence also to X ⊢⊥, since ⊥= ¬⊤and certainly
X ⊢⊤(= ∃v0 v0 ==== v0) by Example 3.
The relation ⊢is completely characterized by some inconsistency con-
dition, as in 1.4. Indeed, the proofs of the two properties
C+ :
X ⊢α ⇔X, ¬α ⊢⊥,
C−:
X ⊢¬α ⇔X, α ⊢⊥
from Lemma 1.4.2 remain correct for any meaningful deﬁnition of ⊥. The
properties C+ and C−will permanently be used in the sequel without our
explicitly referring to them.
As in propositional logic, X ⊆L is called maximally consistent if X
is consistent but each proper extension of X in L is inconsistent. There
are various characterizations of this property, e.g. the one in Exercise 4,
known already from 1.4. Examples of maximally consistent sets are the
{ϕ ∈L | M ⊨ϕ} for L-models M, the typical ones as will turn out.

3.2 The Completeness Proof
97
Exercises
1. Derive the rule
X ⊢α tx
X ⊢∃xα
(α, tx collision-free).
2. Prove ∀xα ⊢∀y(α y
x) and ∀y(α y
x) ⊢∀xα provided y /∈var α.
3. Using Exercise 2 and the cut rule prove X ⊢∀y(α y
x)
X ⊢∀z(α zx) (y, z /∈var α).
4. Show that X ⊆L is maximal consistent iﬀeither ϕ ∈X or ¬ϕ ∈X
for each ϕ ∈L. This easily implies that a maximally consistent set
X is deductively closed, i.e. X ⊢ϕ ⇒ϕ ∈X, for each ϕ ∈L.
3.2
The Completeness Proof
Let L be a language and c a constant symbol. Lc is the result of adjoining
c to L. We have Lc = L if c occurs already in L. Similarly LC denotes the
language resulting from L by adjoining a set C of constants, a constant
expansion of L. We shall also come across such expansions in Chapter 5.
Let α zc (read “α z for c”) denote the formula arising from α by replacing
c with the variable z, and put X zc := {α zc | α ∈X}. c then no longer
occurs in X zc. We actually require the following assertion only for a single
variable z, but as is often the case, we are able too prove by induction
only a stronger version unproblematically.
Lemma 2.1 (on constant elimination). Suppose X ⊢Lc α.
Then
X zc ⊢L α zc for almost all variables z.
Proof by rule induction in ⊢Lc . If α ∈X then α zc ∈X zc is clear; if α is
of the form t==== t, so too is α zc. Thus, X zc ⊢L α zc in either case, even for
all z. Only the induction steps on (∀1), (∀2), and (=) are not immediately
apparent. We restrict ourselves to (∀1), because the induction steps for
(∀2) and (=) proceed analogously. Let α, tx be collision-free, X ⊢Lc ∀xα,
and assume that X zc ⊢L (∀xα) zc for almost all z. In addition, we may
suppose that z /∈var {∀xα, t} for almost all z. A separate induction on α
readily conﬁrms α tx zc = α′ t′
x with α′ := α zc and t′ := t zc. Clearly α′, t′
x
are collision-free as well. By our assumption, X zc ⊢L (∀x α) zc = ∀xα′.
Rule (∀1) then clearly yields X zc ⊢L α′ t′
x = α tx zc, and this holds still for
almost all z which completes the proof of the induction step on (∀1).

98
3 Complete Logical Calculi
This lemma leads to the following rule of “constant quantiﬁcation,” the
semantic counterpart of which plays an essential role in Chapter 5:
(∀3)
X ⊢α cx
X ⊢∀xα
(c not in X, α).
Indeed, suppose that X ⊢α cx. Because of the ﬁniteness theorem we may
assume that X is ﬁnite. By Lemma 2.1, where in the case at hand Lc = L,
some y not occurring in X∪{α} can be found such that X y
c ⊢α cx
y
c = α y
x
(the latter holds because c does not occur in α). Since X y
c = X, we thus
obtain X ⊢α y
x. Hence X ⊢∀xα by (∀2). This conﬁrms (∀3). A likewise
useful consequence of constant elimination is
Lemma 2.2. Let C be any set of constant symbols and L′ = LC. Then
X ⊢L α ⇔X ⊢L′ α, for all X ⊆L and α ∈L. Thus, ⊢L′ is a conservative
expansion of ⊢L.
Proof. (mon) states that X ⊢L α ⇒X ⊢L′ α. Suppose conversely that
X ⊢L′ α. To prove X ⊢L α we may assume, thanks to (ﬁn) and (MR),
that C is ﬁnite. Since the adjunction of ﬁnitely many constants can be
undertaken stepwise, we may suppose for the purpose of the proof that
L′ = Lc for a single constant c not occurring in L. Lemma 2.1 then yields
X zc ⊢L α zc for at least one variable z. Now, X zc ⊢L α zc means the same
as X ⊢L α because c occurs neither in X nor in α.
In the following, we represent the derivability relation in L and in every
constant expansion L′ of L with the same symbol ⊢. By Lemma 2.2 no
misunderstandings can arise from this notation. Since the consistency of
X is equivalent to X ⊬⊥, there is also no need to distinguish between the
consistency of X ⊆L with respect to L or L′. This is highly signiﬁcant
for the proofs of the next two lemmas.
The proof of the completeness theorem essentially proceeds with a model
construction from the syntactic material of a certain constant expansion
of L. We ﬁrst choose for each variable x and each α ∈L a constant cx,α
not occurring in L; more precisely, we choose exactly one such constant
for each pair x, α. Deﬁne
(1)
αx := ¬∀xα ∧α cx
(c := cx,α).
Here it is insigniﬁcant how many free variables α contains, and whether
x occurs at all in α. Note that ¬αx ≡∃x¬α →¬α cx. The formula on
the right side tells us that under the hypothesis ∃x¬α the constant c

3.2 The Completeness Proof
99
represents a counterexample to the validity of α, that is, an example for
the validity of ¬α. Note also that ¬αx ≡⊤whenever x /∈free α.
Lemma 2.3. Let ΓL := {¬αx | α ∈L, x ∈Var}, where αx is deﬁned as
in (1), and let X ⊆L be consistent. Then X ∪ΓL is consistent as well.
Proof. Assume that X ∪ΓL ⊢⊥. There exist some n ⩾0 and formulas
¬αx0
0 , . . . , ¬αxn
n ∈ΓL such that (a) X ∪{¬αxi
i | i ⩽n} ⊢⊥. Since X ⊬⊥,
there is some minimal n with (b) X′ := X ∪{¬αxi
i
| i < n} ⊬⊥. Let
x := xn, α := αn, and c := cx,α. By (a), X′ ∪{¬αx} ⊢⊥. Hence, X′ ⊢αx,
and so X′ ⊢¬∀xα, α cx, by ( ∧2). But X′ ⊢α cx yields X′ ⊢∀xα using
(∀3), since c does not occur in X′ and α. Thus, X′ ⊢∀xα, ¬∀xα, whence
X′ ⊢⊥, contradicting (b) and hence our assumption.
Call X ⊆L a Henkin set if X satisﬁes the following two conditions:
(H1)
X ⊢¬α
⇔
X ⊬α,
(equivalently, X ⊢α ⇔X ⊬¬α),
(H2)
X ⊢∀xα
⇔
X ⊢α cx for all constants c in L.
(H1) and (H2) imply another useful property of a Henkin set X, namely
(H3)
For each term t there is a constant c such that X ⊢t==== c.
Indeed, X ⊢¬∀x t ̸==== x (= ∃xt==== x) for x /∈var t by Example 3 in 3.1.
Hence, X ⊬∀x t̸====x in view of (H1). Thus, X ⊬t̸====c for some c by (H2),
and so X ⊢t==== c by (H1).
Lemma 2.4. Let X ⊆L be consistent. Then there exists a Henkin set
Y ⊇X in a suitable constant expansion LC of L.
Proof. Put L0 := L, X0 := X and assume that Ln and Xn have been
given. Let Ln+1 result from Ln by adopting new constants cx,α,n for all
x ∈Var, α ∈Ln; more precisely, Ln+1 = LnCn, with the set Cn of
constants cx,α,n. Further, let Xn+1 = Xn ∪ΓLn. Here ΓLn is deﬁned as
in Lemma 2.3 so that Xn+1 ⊆Ln+1. Using Lemma 2.3 we have Xn ⊬⊥
for each n.
Let X′ := 
n∈N Xn; hence X′ ⊆L′ := 
n∈N Ln = LC,
where C := 
n∈N Cn. Then X′ ⊬⊥, since X′, as the union of a chain
of consistent sets, is surely consistent (in L′). Let α ∈L′, x ∈Var, and,
say, α ∈Ln with minimal n, and let αx be the formula deﬁned as in (1)
but with respect to Ln. Then ¬αx belongs to Xn+1. Hence ¬αx ∈X′.
Now let (H, ⊆) be the partial order of all consistent extensions of X′ in
L′. Every chain K ⊆H has the upper bound  K in H, because if all

100
3 Complete Logical Calculi
members of K are consistent then so is  K. Also H ̸= ∅, e.g. X′ ∈H.
By Zorn’s lemma, H therefore contains a maximal element Y . In short,
Y is a maximal consistent extension of X′. Since ¬αx ∈X′ ⊆Y it holds
(2)
Y ⊢¬αx for all α ∈L′.
Further, Y is at the same time a Henkin set. Here is the proof:
(H1) ⇒: Y ⊢¬α implies Y ⊬α due to the consistency of Y . ⇐: If Y ⊬α
then surely α ̸∈Y . As a result Y, α ⊢⊥, for Y is maximally consistent.
Thus Y ⊢¬α by C−. You may also use Exercise 4 in 3.1
(H2) ⇒: Clear by (∀1). ⇐: Let Y ⊢α cx for all c in L′, so also Y ⊢α cx for
c := cx,α,n, where n is minimal with α ∈Ln. Assume that Y ⊬∀xα. Then
Y ⊢¬∀xα by (H1). But Y ⊢¬∀xα, α cx implies Y ⊢¬∀xα ∧α cx = αx
using (∧1). Now, since Y is consistent, Y ⊢αx which contradicts (2).
Thus, our assumption was wrong and indeed Y ⊢∀xα.
Remark 1. In the original language L, consistent sets are not generally embed-
dable in Henkin sets. For instance, let the signature of L consist of the constants
ci, i ∈I with any inﬁnite set I. Then the consistent set X = {v0 ̸====ci | i ∈I}
represents a counterexample in L=
=
=
=.
In no consistent extension of X can be
derived v0 ==== ci for some i ∈I. In other words, (H3) is violated.
Lemma 2.5. Every Henkin set Y ⊆L possesses a model.
Proof. The model constructed in the following is called a term model.
Let t ≈t′ whenever Y ⊢t==== t′. The relation ≈is a congruence in the term
algebra T of L. This means (repeating the deﬁnition on page 51) that
(a)
≈is an equivalence relation,
(b)
t1 ≈t′
1, . . . , tn ≈t′
n
⇒
f⃗t ≈f⃗t′, for operation symbols f.
The claim (a) follows immediately from Y ⊢t==== t and Example 1 in 3.1;
(b) is just another way of formulating 2(b). Let A := {t | t ∈T }. Here t
denotes the equivalence class of ≈containing the term t, so that
(c)
¯t = ¯s ⇔t ≈s ⇔Y ⊢t==== s.
This set A is the domain of the sought model M = (A, w) for Y . The
factorization of T will ensure that ==== means identity in the model. Let C
be the set of constants in L. By (H3) there is for each term t in T some
c ∈C such that c ≈t. Therefore even A = {¯c | c ∈C}. Now put xM := x
and cM := c for variables and constants in L. An operation symbol f
occurring in L of arity n > 0 is interpreted by fM, deﬁned by
fM(t1, . . . , tn) := ft1 · · · tn.

3.2 The Completeness Proof
101
This deﬁnition is sound because ≈is a congruence in the term algebra T .
Finally, deﬁne rM for an n-ary relation symbol r by
rMt1 · · · tn ⇔Y ⊢r⃗t .
This deﬁnition is also sound, since Y ⊢r⃗t implies Y ⊢r⃗t′ whenever
t1 ≈t′
1, . . . , tn ≈t′
n. Here we use Example 2(d) in 3.1. We shall prove
(d) tM = t;
(e) M ⊨α ⇔Y ⊢α,
of which (e) may be regarded as the goal of the constructions. (d) fol-
lows by term induction. It is evident for prime terms, and the induction
hypothesis tM
i
= ti for i = 1, . . . , n leads with t = f⃗t to
tM = fM(tM
1 , . . . , tM
n ) = fM(t1, . . . , tn) = ft1 · · · tn = t.
(e) follows by induction on rk α.
We begin with formulas of rank 0
(prime formulas). Induction proceeds under consideration of rk α < rk ¬α,
rk α, rk β < rk(α ∧β), and rk α tx < rk ∀xα, as in formula induction:
M ⊨t==== s ⇔tM = sM
⇔t = s
(by (d) )
⇔Y ⊢t==== s
(by (c) ).
M ⊨r⃗t
⇔rMtM
1 · · · tM
n
⇔rMt1 · · · tn
⇔Y ⊢r⃗t .
M ⊨α ∧β ⇔M ⊨α, β
⇔Y ⊢α, β
(induction hypothesis)
⇔Y ⊢α ∧β
(using ( ∧1), ( ∧2) ).
M ⊨¬α
⇔M ⊭α
⇔Y ⊬α
(induction hypothesis)
⇔Y ⊢¬α
(using (H1) ).
M ⊨∀xα
⇔
Mc
x ⊨α for all c ∈C
(because A = {c | c ∈C})
⇔
McM
x
⊨α for all c ∈C
(because cM = c)
⇔
M ⊨α cx for all c ∈C
(substitution theorem)
⇔
Y ⊢α cx for all c ∈C
(induction hypothesis)
⇔
Y ⊢∀xα
(using (H2) ).
Because of Y ⊢α for all α ∈Y , (e) immediately implies M ⊨Y .
Just as for propositional logic, the equivalence of consistency and sat-
isﬁability, and the completeness of ⊢, result from the above. Information
about the size of the model constructed in the next theorem will be given
in Theorem 4.1.

102
3 Complete Logical Calculi
Theorem 2.6 (Model existence theorem). Each consistent X ⊆L
(in particular, each consistent theory T in L) has a model.
Proof. Let Y ⊇X be a Henkin expansion of X, i.e., a Henkin set in a
suitable constant expansion LC according to Lemma 2.4. By Lemma 2.5,
Y and hence also X has a model M′ in LC. Let M denote the L-reduct
of M′. In other words, “forget” the interpretation of the constants not in
L. Then, by Theorem 2.3.1, M ⊨X holds as well.
Theorem 2.7 (Completeness theorem). Let L denote any ﬁrst-order
language. Then X ⊢α ⇔X ⊨α, for all X ⊆L and α ∈L.
Proof. The soundness of ⊢states that X ⊢α ⇒X ⊨α. The converse
follows indirectly. Let X ⊬α, so that X, ¬α is consistent. Theorem 2.6
then provides a model for X ∪{¬α}, whence X ⊭α.
Thus, ⊨and ⊢can henceforth be freely interchanged. We will often
conﬁrm X ⊢α by proving X ⊨α in a semi-formal manner as is common
in mathematics. In particular, for theories T, T ⊨α is equivalent to T ⊢α,
for which in the following we mostly write ⊢T α. Clearly, ⊢T α means
the same as α ∈T for sentences α. More generally, let X ⊢T α stand for
X ∪T ⊢α and α ⊢T β for {α} ⊢T β. We will also occasionally abbreviate
α ⊢T β & β ⊢T γ to α ⊢T β ⊢T γ. In subsequent chapters, equivalences
such as α ⊢T β ⇔⊢T α →β ⇔⊢T+α β and ⊢T α ⇔⊢T αg will be used
without further mentioning and should be committed to memory. Several
other useful equivalences are listed in Exercise 4.
Remark 2. The methods in this section easily provide also completeness of
a logical calculus for identity-free (or ==== -free) languages in which ==== does not
appear, considered in the exercises and Chapter 4. Simply discard from the
calculus in 3.1 everything that refers to ====. Most things run as before. The
domain of M is now the set T of all terms of LC without a factorization of
T , so that tM = t. Note that (H3) is not to our disposal anymore so that the
proof of Lemma 2.5 must be modiﬁed. We will not go into details, since we need
in 4.1 only a slight generalization of Exercise 1. In any case, consistency of a
==== -free set X means the same, no matter whether X is regarded as belonging to
a language with or without ==== , because X has a model in either case. Moreover,
if X consists of ∀-formulas only, we come along without a Henkin expansion in
constructing a model as will be shown in Theorem 4.1.1. The set of terms of the
original language is suﬃcient for model construction in this case.

3.3 First Applications: Nonstandard Models
103
Exercises
1. Let L be ==== -free, T0 ̸= ∅the set of its ground terms, and U ⊆L
a consistent set of ∀-sentences. Construct a model T ⊨U on the
domain T0 by setting cT = c, fT⃗t := f⃗t (hence tT = t for all t ∈T0,
shown by induction on t), and rT⃗t :⇔X ⊢r⃗t (⃗t ∈T n
0 ; X ⊇U
maximally consistent, so that X ⊢¬ϕ ⇔X ⊬α, for all α ∈L, cf.
e.g. Lemma 1.4.4). T is called a Herbrand model; see also 4.1.
2. Let K ̸= ∅be a chain of theories in L, i.e., T ⊆T ′ or T ′ ⊆T, for
all T, T ′ ∈K. Show that  K is a theory that is consistent iﬀall
T ∈K are consistent.
3. Suppose T is consistent and Y ⊆L. Prove the equivalence of
(i) Y ⊢T ⊥,
(ii) ⊢T ¬α for some conjunction α of formulas in Y .
4. Let x /∈var t and α, tx collision-free. Verify the equivalence of
(i) ⊢T α tx,
(ii) x==== t ⊢T α,
(iii) ⊢T x==== t →α,
(iv) ⊢T ∀x(x==== t →α),
(v) ⊢T ∃x(x==== t ∧α).
3.3
First Applications: Nonstandard Models
In this section we draw important conclusions from Theorem 2.7 and the
model-construction for proving it. Since the ﬁniteness theorem holds for
the provability relation ⊢, Theorem 2.7 immediately yields
Theorem 3.1 (Finiteness theorem for the consequence relation).
X ⊨α implies X0 ⊨α for some ﬁnite subset X0 ⊆X.
Let us consider a ﬁrst application. The ﬁrst-order theory of ﬁelds of
characteristic 0 is axiomatized by the set X containing the axioms for
ﬁelds and the formulas ¬charp (page 48). We claim that
(1) A sentence α valid in all ﬁelds of characteristic 0 is also valid in all
ﬁelds of suﬃciently high prime characteristic p that depends on α.
Indeed, since X ⊨α, for some ﬁnite subset X0 ⊆X we have X0 ⊨α. If
p is a prime number larger than all prime numbers q with ¬charq ∈X0,
then α holds in all ﬁelds of characteristic p, since these satisfy X0. Thus

104
3 Complete Logical Calculi
(1) holds. From (1) we obtain, for instance, the information that two given
polynomials coprime over all ﬁelds of characteristic 0 are also coprime over
ﬁelds of suﬃciently high prime characteristic. The statement that given
polynomials are coprime is readily formalized in L{0, 1, +, ·}.
A noteworthy consequence of Theorem 3.1 is also the nonﬁnite axiom-
atizability of many elementary theories. Before presenting examples, we
explain ﬁnite axiomatizability in a somewhat broader context.
A set Z of strings of a given alphabet A is called decidable if there is an
algorithm (a mechanical decision procedure) that after ﬁnitely many cal-
culation steps provides us with an answer to the question whether a string
ξ of symbols of A belongs to Z; otherwise Z is called undecidable. Thus it
is certainly decidable whether ξ is a formula. While this is all intuitively
plausible, it nonetheless requires more precision (undertaken in 6.2). A
theory T is called recursively axiomatizable, or just axiomatizable, if it
possesses a decidable axiom system. This is the case, for instance, if T is
ﬁnitely axiomatizable, that is, if it has a ﬁnite axiom system.
From (1) it follows straight away that the theory of ﬁelds of characteris-
tic 0 is not ﬁnitely axiomatizable. For were F a ﬁnite set of axioms, their
conjunction α =  F would, by (1), also have a ﬁeld of ﬁnite character-
istic as a model. Here is another instructive example. An abelian group
G is called n-divisible if G ⊨ϑn with ϑn := ∀x∃y x==== ny, where ny is the
n-fold sum y + · · · + y, and G is called divisible if G ⊨ϑn for all n ⩾1.
Thus, the theory of divisible abelian groups, DAG, is axiomatized by the
set X consisting of the axioms for abelian groups plus all sentences ϑn.
Also DAG is not ﬁnitely axiomatizable. This follows as above from
(2) A sentence α ∈L{+, 0} valid in all divisible abelian groups is also
valid in at least one nondivisible abelian group.
To prove (2), let α ∈DAG, or equivalently X ⊨α. According to The-
orem 3.1, X0 ⊨α for some ﬁnite X0 ⊆X. Let Zp be the cyclic group
of order p, where p is a prime > n for all n with ϑn ∈X0. The map-
ping x 
→nx from Zp to itself is surjective for 0 < n < p; otherwise
{na | a ∈Zp} would be a nontrivial subgroup of Zp which cannot be.
Hence, Zp ⊨ϑn for 0 < n < p. Thus, Zp ⊨X0 and so Zp ⊨α. On the
other hand, Zp is not p-divisible because px = 0 for all x ∈Zp. In exactly
the same way, we can show that the theory of torsion-free abelian groups
is not ﬁnitely axiomatizable. In these groups is na ̸= 0 whenever n, a ̸= 0.

3.3 First Applications: Nonstandard Models
105
In a similar manner, it is possible to prove for many theories that they
are not ﬁnitely axiomatizable. However, this often demands more involved
methods. For instance, consider the theory ACF of a.c. ﬁelds (see p. 48).
It results from adjoining to the (ﬁnitely axiomatizable) theory of ﬁelds the
schema of all sentences ∀⃗a ∃x p(⃗a, x)==== 0, where p(⃗a, x) denotes the term
xn+1 + anxn + · · · + a1x + a0 (n = 0, 1, . . . ), called a monic polynomial of
degree n + 1. Here let a0, . . . , an, x denote distinct variables. Thus, in an
a.c. ﬁeld every monic polynomial has a zero, and so does every polynomial
of positive degree. Nonﬁnite axiomatizability of ACF follows from the by
no means trivial existence proof of ﬁelds in which all polynomials up to a
certain degree do factorize but irreducible polynomials still exist.
As in propositional logic, the ﬁniteness theorem for the consequence
relation leads immediately to the corresponding compactness result:
Theorem 3.2 (Compactness theorem). Any set X of ﬁrst-order for-
mulas is satisﬁable, provided every ﬁnite subset of X is satisﬁable.
Because of the ﬁner structure of ﬁrst-order languages, this theorem is
somewhat more amenable to certain applications than its propositional
counterpart. It can be proved in various ways, even quite independent
of a logical calculus; for instance, by means of ultraproducts, as will be
carried out in 5.7. It can also be reduced to the propositional compactness
theorem, see Remark 1 in 4.1. For applications of Theorem 3.2 we will
concentrate on the construction of nonstandard models.
A theory T (⊆L0) is called complete if it is consistent and has no
consistent proper extension in L0. It is easily seen that the completeness
of T is equivalent to either ⊢T α or ⊢T ¬α but not both, for each α ∈L0.
Hence, Th A is complete for each L-structure A. Other equivalences of
completeness are given by Theorem 5.2.1. Note that completeness of a
theory is not related to the completeness theorem in 3.2.
We will frequently come across the theory Th N with N = (N, 0, S, +, ·).
Here S: n 
→n + 1 is the successor function. N is the standard structure
for the arithmetical language Lar := L{0, S, +, ·}. The choice of signature
is a matter of convenience and has a long tradition. Of relations deﬁnable
in N, we name just ⩽and <, deﬁned by x ⩽y ↔∃z z + x==== y, and
x < y ↔x ⩽y ∧x ̸==== y.
This will be our standard deﬁnitions of the
symbols ⩽and < in Lar.

106
3 Complete Logical Calculi
Certain axiomatic subtheories of the complete theory Th N are even
more frequently dealt with, in particular the so-called Peano arithmetic
PA, a ﬁrst-order theory in Lar that is important both for mathematical
foundations as well as for investigations in computer science; see e.g. [Kra].
The axioms of PA are as follows:
∀x Sx̸====0,
∀x x + 0==== x,
∀x x · 0==== 0,
∀xy(Sx==== Sy →x==== y),
∀xy x + Sy ==== S(x + y),
∀xy x · Sy ==== x · y + x,
IS: ϕ 0x ∧∀x(ϕ →ϕ Sx
x ) →∀xϕ.
IS is called the induction schema and should not be mixed up with the
induction axiom IA discussed on page 108. In IS, ϕ runs over all formulas
from Lar, i.e., IS reads more precisely [ϕ 0x ∧∀x(ϕ →ϕ Sx
x ) →∀xϕ]g; see
our convention in 2.5. With IS one can prove ⊢PA ∀xϕ by induction on x:
First conﬁrm ⊢PA ϕ 0x (induction initiation), and then ⊢PA ∀x(ϕ →ϕ Sx
x ),
or equivalently, ϕ ⊢PA ϕ Sx
x (induction step). The latter means the deriva-
tion of the induction claim ϕ Sx
x from the induction hypothesis ϕ.
Example. Let ϕ be the formula x==== 0 ∨∃v Sv ==== x. We prove ⊢PA ∀xϕ.
In other words, each x̸====0 has a predecessor, not something seen at once
from the axioms. Clearly, ⊢PA ϕ 0x. Since Sv ==== x ⊢PA SSv ==== Sx, we get
∃vSv ==== x ⊢PA ∃vSv ==== Sx (particularization). Since x==== 0 ⊢PA ∃vSv ==== Sx
as well, we obtain ϕ ⊢PA ∃vSv ==== Sx ⊢PA Sx==== 0 ∨∃vSv ==== Sx = ϕ Sx
x . This
conﬁrms the induction step ϕ ⊢PA ϕ Sx
x . Hence, ⊢PA ∀xϕ by IS. The above
is easily supplemented by an inductive proof of ⊢PA ∀x Sx̸====x.
Remark 1. Only a few arithmetical facts (for instance, ∀x 0 ⩽x) are derivable in
PA without IS. Already the derivation of such simple statements as ∀x x ⩽Sx and
∀x Sx̸====x needs IS. The schema IS is extremely strong. In 7.2 it will then become
clear that PA fully embraces elementary number theory and practically the whole
of discrete mathematics. More about PA in the exercises; these are exclusively
devoted to PA, in order to give the reader familiarity with this important theory
as early as possible. Despite its strength, PA is incomplete, as will be shown
in 6.5. It is not of any import that subtraction is only partially deﬁned in PA.
A theory of integers, formulated similarly to PA, may be more convenient for
number theory, but is actually not stronger than PA; it is interpretable in PA in
the sense of 6.6. We mention that PA is not ﬁnitely axiomatizable, shown for
the ﬁrst time in [Ry]. For this and other historical remarks see, e.g., [HP].
We will now prove that not only PA but also the complete theory Th N
has alongside the standard model N other models not isomorphic to N,

3.3 First Applications: Nonstandard Models
107
called nonstandard models. In these models, exactly the same theorems
hold as in N. The existence proof of a nonstandard model N ′ of Th N is
strikingly simple. Let x ∈Var and X := Th N ∪{n < x | n ∈N}. Here
and throughout the text we use n to denote the term Sn0 := S · · · S
  
n
0.
Therefore, 1 = S0, 2 = S1, . . . , and generally Sn = Sn. The term 0
(that is, S00) is mostly denoted by 0. Note that n < x is the formula
n ⩽x ∧n ̸==== x. One may replace x here by a constant symbol c, thus
expanding the language. But both approaches lead to the same result.
Every ﬁnite subset X0 ⊆X possesses a model. Indeed, there is evidently
some m such that X0 ⊆X1 := Th N ∪{n < x | n < m}, and X1 certainly
has a model: one need only assign to x in N the number m. Thus, by
Theorem 3.2, X has a model (N ′, c) with the domain N′, where c ∈N′
denotes the interpretation of x. We know that N ′ satisﬁes all sentences
valid in N, including in particular the sentences Sn==== Sn, n + m==== n + m
and n · m==== n · m. Therefore, n 
→nN ′ constitutes an embedding from N
into N ′ whose image can be thought of as coinciding with N.2 In other
words, it is legitimate to assume that nN ′ = n so that N ⊆N ′.
Because N ′ ⊨X, on the one hand N ′ is elementarily equivalent to N,
and on the other n < a for all n and any a ∈N′ \N, since in N and
hence in N ′ we have (∀x⩽n) 
i⩽n x==== i. In short, N is a (proper) initial
segment of N′, or N ′ is an end extension of N. The elements of N′ \N
are called nonstandard numbers. Alongside c, other examples are c + c
and c + n for n ∈N. Clearly, c has both an immediate successor and an
immediate predecessor in the order, because N ′ ⊨(∀x̸====0)∃!y x==== Sy. The
ﬁgure gives a rough picture of a nonstandard model N ′:
N′ :
· · ·
s
s
s
s
s
s
r
r
r
r
r
r
r
r
r
q
q
q
q
q
q
p
p
p
p
p
q
q
q
q
r
r
r
r
r
r
s
s
0 1
c
c+c



N
N ′ has the same number-theoretic features as N, at least all those that
can be formulated in Lar. These include nearly all the interesting ones, as
will turn out to be the case in 7.1. For example, ∀x∃y(x==== 2y ∨x==== 2y+1)
holds in every model of Th N, that is, every nonstandard number is either
2 Whenever A is embeddable into B there is a structure B′ isomorphic to B such that
A ⊆B′. The domain B′ arises from B by interchanging the images of the elements
of A with their originals.

108
3 Complete Logical Calculi
even or odd. Clearly, the model N′ contains gaps in the sense of 2.1.
The most obvious example is (N, N′ \N).
Remark 2. Theorem 4.1 will show that Th N has also countable nonstandard
models. The order of such a model N ′ is easy to make intuitive: it arises from
the half-open interval [0, 1) of rational numbers by replacing 0 with N and every
other r ∈[0, 1) by a specimen from Z. On the other hand, neither +N ′ nor ·N ′
is eﬀectively describable; see for instance [HP].
Replacing the induction schema IS in the axiom system for PA by the
so-called induction axiom
IA:
∀P(P0 ∧∀x(Px →PSx) →∀xPx)
(P a predicate variable)
results in a categorical axiom system that, up to isomorphism, has just
a single model (see e.g. [Ra5]).
How is it possible that N is uniquely
determined up to isomorphism by a few axioms, but at the same time
nonstandard models exist for Th N? The answer is simple: IA cannot be
adequately formulated in Lar. That is, IA is not an axiom or perhaps
an axiom schema of the ﬁrst-order language of N. It is a sentence of a
second-order language, about which we shall say more in 3.8. However,
this intimated limitation regarding the possibilities of formulation in ﬁrst-
order languages is merely an apparent one, as the undertakings of the rest
of the book will show, especially the considerations about axiomatic set
theory in 3.4.
In no nonstandard model N ′ is the initial segment N deﬁnable, indeed
not even parameter deﬁnable, which means that there is no α = α(x, ⃗y)
and no b1, . . . , bn ∈N′ such that N = {a ∈N′ | N ′ ⊨α [a,⃗b]}. Otherwise
we would have N ′ ⊨α 0x
∧∀x(α →α Sx
x ) [⃗b]. This yields N ′ ⊨∀xα [⃗b]
by IS, in contradiction to N′ \N ̸= ∅. The same reasoning shows that no
proper initial segment A ⊂N′ without a largest element is deﬁnable in
N′; such an A would clearly deﬁne a gap in the order of N′. The situation
can also be described as gaps in N′ are not recognizable from within.
Introductory courses in real analysis tend to give the impression that
a meaningful study of the subject requires the axiom of continuity: Ev-
ery nonempty bounded set of real numbers has a supremum.
On this
basis, Cauchy and Weierstrass reformed analysis, thus banishing from
mathematics the somewhat mysterious inﬁnitesimal arguments of Leibniz,
Newton, and Euler. But mathematical logic has developed methods that,
to a large extent, justify the original arguments. This is undertaken in the

3.3 First Applications: Nonstandard Models
109
framework of nonstandard analysis, developed above all by A. Robinson
around 1950. In the sequel, we provide an indication of its basic idea.
The same construction as for N also provides a nonstandard model for
the theory of R = (R, +, ·, <, {a | a ∈R}), where for each real number a, a
name a was added to the signature. Consider X = Th R∪{a < x | a ∈R}.
Every ﬁnite subset of X has a model on the domain R.
Thus, X is
consistent, and as above, a model of X represents a proper extension R∗
of R, a nonstandard model of analysis.
In each such model the same
theorems hold as in R. For instance, in R∗every polynomial of positive
degree can be decomposed into linear and quadratic factors. In Chapter 5
it will be shown that the nonstandard models of Th R are precisely the
real closed extensions of R. All these are elementarily equivalent to R.
For analysis, it is now decisive that the language can be enriched from
the very beginning, say by the adoption of the symbols exp, ln, sin, cos
for the exponential, logarithmic, and trigonometric functions, and further
symbols for further functions. We denote a thus expanded standard model
once again by R and a corresponding nonstandard model by R∗. The
mentioned real functions available in R carry over to R∗and maintain
all properties that can be elementarily formulated. That means in fact
almost all properties with interesting applications, for example
∀xy exp(x+y)==== exp x·exp y,
(∀x>0) exp ln x==== x,
∀x sin2 x+cos2 x==== 1,
as well as the addition theorems for the trigonometric functions and so
on. All these functions remain continuous and repeatedly diﬀerentiable.
However, the Bolzano–Weierstrass theorem and other topological prop-
erties cannot be salvaged in full generality.
They are replaced by the
aforementioned inﬁnitesimal arguments.
In a nonstandard model R∗of Th R with R ⊆R∗there exist not only
inﬁnitely large numbers c (i.e., r < c for all r ∈R), but also inﬁnitely
many small positive numbers. Let c be inﬁnite. Since 1r < c ⇔1c < r for
all r > 0, 1c is smaller than each positive real r, and yet positive. That
is, 1c is fairly precisely what Leibniz once named an inﬁnitesimal. Taking
a somewhat closer look reveals the following picture: Every real number
a is sitting in a nest of nonstandard numbers a∗∈R∗that are only
inﬁnitesimally distinct from a. In other words, |a∗−a| is an inﬁnitesimal.
Hence, quantities such as dx, dy exist in mathematical reality, and may

110
3 Complete Logical Calculi
once again be considered as inﬁnitesimals in the sense of their inventor
Leibniz. These quantities are exactly the elements of R∗inﬁnitesimally
distinct from 0.
From the existence of nonstandard models for Th R, it can be concluded
that the continuity axiom, just like IA, cannot be elementarily formulated.
For by adjoining this axiom to those for ordered ﬁelds, R is characterized,
up to isomorphism, as the only continuously ordered ﬁeld; see e.g. [Ta4].
Hence, the order of a nonstandard model R∗of Th R possesses gaps. Here,
too, the gaps are “not recognizable from within,” since every nonempty,
bounded parameter-deﬁnable subset of R∗has a supremum in R∗. That
is the case because in R and thus also in R∗, the following continuity
schema holds, which ensures the existence of a supremum for those sets;
here ϕ = ϕ(x, ⃗y) runs over all formulas such that y, z /∈free ϕ:
∃xϕ ∧∃y∀x(ϕ →x ⩽y) →∃z∀x[(ϕ →x ⩽z) ∧∀y((ϕ →x ⩽y) →z ⩽y)].
Analogous remarks can be made on complex numbers.
There is an
algebraically closed ﬁeld R∗[i] ⊇R∗in which familiar facts such as Euler’s
formula eix ==== cos x + i · sin x continue to hold, in particular eiπ ==== −1.
Exercises
1. Prove in PA the associativity, commutativity, and distributivity of
+, ·. Before proving x+y = y+x derive Sx+y ==== x+Sy and 0+y = y
by induction on y. The basic arithmetical laws provable in PA are
collected in the axiom system N on page 235.
2. ⩽was deﬁned in Lar on page 105. Reﬂexivity and transitivity of ⩽
easily derive in PA. Prove in PA the antisymmetry of ⩽.
3. Prove x < y ≡PA Sx ⩽y (or equivalently, x < Sy ≡PA x ⩽y). Use
this to prove ⊢PA x ⩽y ∨y ⩽x by induction on x.
4. Verify (a),(b), and (c) for arbitrary formulas α, β, γ ∈Lar such that
y /∈var {α, β} and z /∈var γ.
(a) ⊢PA ∀x((∀y<x)α y
x →α) →∀xα, the schema of <-induction,
(b) ⊢PA ∃xβ →∃x(β ∧(∀y<x)¬β y
x), the minimum schema,
(c) ⊢PA (∀x<v)∃yγ →∃z(∀x<v)(∃y<z)γ, the schema of collection.

3.4 ZFC and Skolem’s Paradox
111
3.4
ZFC and Skolem’s Paradox
Before turning to further consequences of the results from 3.2, we collect
a few basic facts about countable sets. The proofs are simple and can be
found in any textbook on basic set theory. A set M is called countable if
there is a surjection f : N →M (i.e. M = {an | n ∈N} provided fn = an)
or M = ∅, and otherwise uncountable. Every subset of a countable set
is itself countable. If f : M →N is surjective and M is countable then
clearly so too is N. Sets M, N are termed equipotent, brieﬂy M ∼N, if a
bijection from M to N exists. If M ∼N, then M is said to be countably
inﬁnite. A countable set can only be countably inﬁnite or ﬁnite, which is
to mean equipotent to {1, . . . , n} for some n ∈N.
The best-known uncountable set is R. It is equipotent to PN. The
uncountability of PN is a particular case of an important theorem from
Cantor: The power set PM of a set M has a higher cardinality than M,
i.e., no injection from M to PM is surjective. The cardinality of sets will
be explained to some extent in 5.1. Here it suﬃces to know that two sets
M, N are of the same cardinality iﬀM ∼N, and that there are countable
and uncountable inﬁnite sets.
If M, N are countable so too are M ∪N and M × N, as is easy
to see. Moreover, as was shown already by Cantor, a countable union
U = 
i∈N Mi of countable sets Mi is again countable. Cantor’s proof
a00
a01
a02
a03
a20
a10
a11
-
-



?







ppp
r
r
r
consists in writing down U as an inﬁnite
matrix where the nth line enumerates of
Mn = {anm | m ∈N}.
Then enumer-
ate the matrix in the zigzag manner indi-
cated by the ﬁgure on the right, beginning
with a00. Accordingly, for countable M,
in particular U = 
n∈N M n, the set of all
ﬁnite sequences of elements in M is again countable, because every M n is
countable. Hence, every ﬁrst-order language with a countable signature
is itself countable, more precisely countably inﬁnite.3
By a countable theory we always mean a theory formalized in a countable
language. We now formulate a theorem signiﬁcant for many reasons.
3 Here we use the axiom of choice, since for every Mi some enumeration is chosen. It
can be shown that without the axiom of choice the proof cannot be carried out.

112
3 Complete Logical Calculi
Theorem 4.1 (Löwenheim–Skolem). A countable consistent theory T
always has a countable model.
Proof. By Theorem 2.6, T (⊆L) has a model M with domain A, con-
sisting of the equivalence classes ¯c for c ∈C in the set of all terms of
L′ = LC, where C = 
n∈N Cn is a set of new constants. By construction,
C0 is equipotent to Var×L and thus countable. The same holds for every
Cn, and so C is also countable. The map c 
→¯c from C to A is trivially
surjective, so that M has a countable (possibly ﬁnite) domain, and this
was the very claim.
In 5.1 we will signiﬁcantly generalize the theorem, but even in the above
formulation it leads to noteworthy consequences. For example, there are
also countable ordered ﬁelds as nonstandard models of the ﬁrst-order the-
ory Th (R, 0, 1, +, <, ·, exp, sin, . . . ) in which the usual theorems about
real functions retain their validity. Thus, one need not really overstep the
countable to obtain a rich theory of analysis.
Especially surprising is the existence, ensured by Theorem 4.1, of count-
able models of formalized set theory. Although set theory can be regarded
as the basis for the whole of presently existing mathematics, it embraces
only a few set-building principles. The most important system of formal-
ized set theory is ZFC, created at the beginning of the twentieth century.
Remark 1. Z stands for E. Zermelo, F for A. Fraenkel, and C for AC, the axiom
of choice. ZF denotes the theory resulting from the removal of AC. ZFC sets out
from the principle that every element of a set is again a set, so that a distinction
between sets and systems of sets vanishes. Thus, ZFC speaks exclusively about
sets, unlike Russell’s type-theoretic system, in which, along with sets, so-called
urelements (objects that are members of sets but aren’t sets themselves) are
considered. Set theory without urelements is fully suﬃcient as a foundation of
mathematics and for nearly all practical purposes. Even from the epistemological
point of view there is no evidence that urelements occur in reality: each object
can be identiﬁed with the set of all properties that distinguish it from other
objects. Nonetheless, urelements are still in use as a technical tool in certain
set-theoretic investigations.
We mention in passing that neither ZF nor ZFC
is ﬁnitely axiomatizable. This seems plausible if we look at the axioms given
below, but the proof is not quite easy.
To make clear that ZFC is a countable ﬁrst-order theory and hence
belongs to the scope of applications of Theorem 4.1, we present in the
following its axioms. Each of the axioms will be brieﬂy discussed. This

3.4 ZFC and Skolem’s Paradox
113
will be at the same time an excellent exercise in advanced formalization
technique. The set-theoretic language already denoted in 2.2 by L∈is
one of the most conceivably simple languages and is certainly countable.
Alongside ==== it contains only the membership symbol ∈. This symbol
should be distinguished from the somewhat larger ∈that is used through-
out in our metatheory. The variables are now called set variables. These
will as a rule be denoted by lowercase letters as in other ﬁrst-order lan-
guages. In order to make the axioms and its consequences easily legible,
we employ the widely used abbreviations
(∀y∈x)ϕ := ∀y(y ∈x →ϕ),
(∃y∈x)ϕ := ∃y(y ∈x ∧ϕ).
Besides, we deﬁne the relation of inclusion by x ⊆y ↔∀z(z ∈x →z ∈y).
Note also that all free variables occurring in the axioms below (e.g., x, y in
AE) have to be thought of as being generalized according to our convention
in 2.5. The ZFC axioms are then the following:
AE :
∀z(z ∈x ↔z ∈y) →x==== y
(axiom of extensionality).
AS :
∃y∀z(z ∈y ↔ϕ ∧z ∈x)
(axiom of separation).
Here ϕ runs over all L∈-formulas with y /∈free ϕ. AS is in fact a schema of
axioms. Let ϕ = ϕ(x, z,⃗a). From AS and AE , ∀x ∃!y∀z(z ∈y ↔ϕ ∧z ∈x)
is derivable. Indeed, observe for y, y′ /∈free ϕ the obvious derivability of
(z ∈y ↔ϕ ∧z ∈x) ∧(z ∈y′ ↔ϕ ∧z ∈x) →(z ∈y ↔z ∈y′).
This implies ∀z(z ∈y ↔ϕ ∧z ∈x) ∧∀z(z ∈y′ ↔ϕ ∧z ∈x) →y ==== y′ and
hence the claim. Thus, y ==== {z ∈x | ϕ} ↔∀z(z ∈y ↔ϕ ∧z ∈x) is a legiti-
mate deﬁnition in the sense of 2.6. {z ∈x | ϕ} is called a set term and is
just a suggestive writing of a function term f⃗ax. This term still depends
on the “parameter” vector ⃗a. It collects the free variables of ϕ distinct from
x, z. Thus, instead of introducing each time a new operation symbol, one
uses the more economical “curled bracket notation.”
The empty set can explicitly be deﬁned by y ==== ∅↔∀z z /∈y. Indeed,
thanks to AS, ∃y∀z(z ∈y ↔z /∈x ∧z ∈x) is provable.
This formula is
equivalent to ∃y∀z z /∈y, since z ∈y ↔z /∈x ∧z ∈x ≡z /∈y. Clearly, using
AE, ∀z z /∈y ∧∀z z /∈y′ →y ==== y′ is provable. This, together with ∃y∀z z /∈y,
yields ∃!y∀z z /∈y, which legitimates the explicit deﬁnition y ==== ∅↔∀z z /∈y,
as was explained in detail in 2.6. The next axiom is
AU :
∀x∃y∀z(z ∈y ↔(∃u ∈x) z ∈u)
(axiom of union).

114
3 Complete Logical Calculi
Here again, because of AE, ∃y can be replaced by ∃!y. As in 2.6, we
may therefore deﬁne an operator on the universe,4 denoted by x 
→ x.
We avoid the word “function,” since functions are understood as special
objects of the universe. AU is equivalent to ∀x∃y∀z((∃u ∈x)z ∈u →z ∈y),
because  x can be separated from such a set y by means of AS. The
following axiom could analogously be weakened.
AP :
∀x∃y∀z(z ∈y ↔z ⊆x)
(power set axiom).
Let Px denote the y that in view of AE is uniquely determined by x
in AP.
What ﬁrst can easily be proved is ∀x(x ∈P∅↔x==== ∅) as well
as ∀x(x ∈PP∅↔x==== ∅∨x==== P∅). Since ∅̸==== P∅, the set PP∅contains
precisely two elements. This is decisive for deﬁning {a, b} below.
The following axiom was added to those of Zermelo by Fraenkel.
AR : ∀x∃!yϕ →∀u∃v∀y(y ∈v ↔(∃x∈u) ϕ) (axiom of replacement).
Here ϕ = ϕ(x, y,⃗a) and u, v /∈free ϕ. If ∀x∃!yϕ is provable, then we know
from 2.6 that an operator x 
→Fx can be introduced. By AR, the image of
a set u under F is again a set which, as a rule, is denoted by {Fx | x ∈u}.
F may depend on further parameters a1, . . . , an, so we had better write
F⃗a for F. AR is very strong; even AS is derivable from it, Exercise 4. An
instructive example of an application of AR, for which ∀x∃!yϕ is certainly
provable, is provided by ϕ = ϕ(x, y, a, b) := x==== ∅∧y ==== a ∨x̸====∅∧y ==== b.
The operator F = Fa,b deﬁned by ϕ clearly satisﬁes F∅==== a and Fx==== b
if x ̸= ∅. Accordingly, the image of the two-element set PP∅under Fa,b
contains the (not necessarily distinct) members a, b. We then deﬁne
{a, b} := {Fa,b(x) | x ∈PP∅}
and call this set the pair set of a, b. We next put a ∪b := {a, b} (while
a ∩b := {z ∈a | z ∈b} already exists from AS). Further, let {a} := {a, a}
and {a1, . . . , an+1} = {a1, . . . , an} ∪{an+1} for n ⩾2. Now we can prove
that P∅==== {∅}, PP∅==== {∅, {∅}}, . . . The ordered pair of a, b is deﬁned as
(a, b) := {{a}, {a, b}}. This deﬁnition may look artiﬁcial but it implies
the basic property (a, b)==== (c, d) ↔a==== c ∧b==== c. Only this is needed.
We now have at our disposal the tools necessary to develop elementary
set theory. Beginning with sets of ordered pairs it is possible to model
relations and functions and all concepts building upon them, even though
4 A frequently used synonym for the domain of a ZFC-model, mostly denoted by V ,
and ‘for all sets a’ is then often expressed as ‘for all a ∈V ’.

3.4 ZFC and Skolem’s Paradox
115
the existence of inﬁnite sets is still unprovable. Mathematical require-
ments demand their existence, though then the borders of our experience
with ﬁnite sets are transgressed. The easiest way to get inﬁnite sets is
using the set operator x 
→Sx, with Sx := x ∪{x}.
AI :
∃u[∅∈u ∧∀x(x ∈u →Sx ∈u)]
(axiom of inﬁnity).
Such a set u contains ∅, S∅= ∅∪{∅} = {∅}, SS∅= {∅, {∅}}, . . . and
is therefore inﬁnite in the naive sense. This holds in particular for the
smallest set u of this type, denoted by ω. In formalized set theory ω plays
the role of the set of natural numbers. ω contains 0 := ∅, 1 := S0 = {0},
2 := S1 = {∅, {∅}} = {0, 1}, . . . Generally, Sn = {0, 1, . . . , n}. Thus, the
n ∈N are represented in ZF by certain variable-free terms, called ω-terms.
In everyday mathematics the following axiom is basically dispensable:
AF :
(∀x̸====∅)(∃y∈x) x ∩y ==== ∅(axiom of foundation).
Put intuitively: Every set x ̸==== ∅contains an ∈-minimal element y. AF
precludes the possibility of “∈-circularity” x0 ∈· · · ∈xn ∈x0. In particular,
there is no set x with x ∈x.
Remark 2. In axiomatic set theory, AF plays a highly important role. The most
important consequence of AF is the existence of the von Neumann hierarchy
V = 
α∈On Vα. Here On denotes the class of all ordinal numbers. These are
generalizations of natural numbers, deﬁned in each textbook on set theory. Vα
is a set for each α ∈On and deﬁned by recursion: V0 = ∅, Vα+1 = PVα, and
Vλ = 
α<λ Vα for limit ordinals λ. All this is more important for the foundations
of mathematics than for applications of set theory.
ZF is the theory with the above axioms. ZFC results from ZF by ad-
joining the axiom of choice AC:
∀u[∅/∈u ∧(∀x∈u)(∀y∈u)(x̸====y →x ∩y ==== ∅) →∃z(∀x∈u)∃!y(y ∈x ∩z)].
AC states that for every set u of disjoint nonempty sets x there is a set z,
a choice set, that picks up precisely one element from each x in u. One of
the many equivalences to AC is 
i∈I Ai ̸= ∅, for any index set I.
The above expositions clearly show that ZFC can be understood as a
ﬁrst-order theory.
In some sense, ZFC is even the purest such theory,
because all sophisticated proof methods that occur in mathematics, for
instance transﬁnite induction and recursion and every other type of in-
duction and recursion, can be made explicit and derived in the ﬁrst-order
language L∈of ZFC without particular diﬃculty.

116
3 Complete Logical Calculi
Whereas mathematicians regularly transgress the framework of a theory,
even one that is unambiguously deﬁned by ﬁrst-order axioms, in that
they make use of combinatorial, number- or set-theoretic tools wherever
it suits them, set theory, as it stands now, imposes upon itself an upper
limit. Within ZFC, all sophisticated proof and deﬁnition techniques gain
an elementary character, so to speak.
As a matter of fact, there are
no pertinent arguments against the claim that the whole of mathematics
can be treated within the frame of ZFC as a single ﬁrst-order theory, a
claim based on general mathematical experience that is highly interesting
for the philosophy of mathematics.
However, one should not make a
religion out of this insight, because for mathematical practice it is of
limited signiﬁcance only.
If ZFC is consistent—and no one really doubts this assumption although
there is no way of proving it—then by Theorem 4.1, ZFC must have a
countable model V = (V, ∈V). The existence of such a model V is at
ﬁrst glance paradoxical because the existence of uncountable sets is easily
provable within ZFC. An example is Pω. On the other hand, because of
(Pω)V ⊆V , it must be true (judged from the outside) that also (Pω)V
is countable. Thus, the notion countable has a diﬀerent meaning “inside
and outside the world V,” which comes rather unexpectedly. This is the
so-called Skolem’s paradox.
The explanation of Skolem’s paradox is that the countable model V, to
put it ﬁguratively, is “thinned out” and contains fewer sets and functions
than expected. Indeed, roughly put, it contains just enough to satisfy the
axioms, yet not, for instance, some bijection from ωV to (Pω)V, which,
seen from the outside, certainly exists. Therefore, the countable set (Pω)V
is uncountable from the perspective of the world V. In other words, count-
ability is not an absolute concept.
Moreover, the universe V of a ZFC-model is by deﬁnition a set, whereas
⊢ZFC ¬∃v∀z z ∈v, i.e., there is no “universal set.” Thus, seen from within,
V is too big to be a set. ¬∃v∀z z ∈v is derived as follows: the hypothesis
∃v∀z z ∈v entails with AE and AS the existence of the “Russellian set”
u = {x ∈v | x /∈x}. That is, ∃v∀z z ∈v ⊢ZFC ∃u∀x(x ∈u ↔x /∈x).
On the other hand, by Example 1 page 73, ⊢ZFC ¬∃u∀x(x ∈u ↔x /∈x).
Thus, indeed ⊢ZFC ¬∃v∀z z ∈v.
Accordingly, even the notion of a set
depends on the model. There is no absolute deﬁnition of a set.

3.5 Enumerability and Decidability
117
None of the above has anything to do with ZFC’s incompleteness.5
Mathematics has no problem with the fact that its basic theory is in-
complete and cannot be rendered complete, at least not in an axiomatic
manner. More of a problem is the lack of undisputed criteria for extending
ZFC in a way coinciding with truth or at least with our intuition.
Exercises
1. Let T be an elementary theory with arbitrarily large ﬁnite models.
Prove that T also has an inﬁnite model.
2. Suppose A = (A, <) is an inﬁnite well-ordered set (see 2.1). Show
that there is a not well-ordered set elementarily equivalent to A.
Thus, being well-ordered is not a ﬁrst-order property.
3. Prove that a consistent theory T coincides with the intersection of
all its complete extensions, i.e., T = {T ′ ⊇T | T ′ complete}.
4. Derive the axiom AS of separation from the replacement axiom AR.
5. ﬁn(a) := ∀s[∅∈s ∧(∀u ∈s)(a\u ̸==== ∅→(∃e ∈a\u)u ∪{e} ∈s) →a ∈s]
is one of several deﬁnitions of ‘a is ﬁnite’. Prove for each ϕ ∈L∈:
ﬁn(a) ⊢ZF ϕx(∅) ∧∀u∀e(ϕx(u) →ϕx(u ∪{e})) →ϕx(a).
3.5
Enumerability and Decidability
Of all the far-reaching consequences of the completeness theorem, perhaps
the most signiﬁcant is the eﬀective enumerability of all tautologies of a
countable ﬁrst-order language.
Once Gödel had proved this, the hope
grew that the decidability problem for tautologies might soon be resolved.
Indeed, the wait was not long, and a few years after Gödel’s result Church
proved the problem to be unsolvable for suﬃciently expressive languages.
This section is intended to provide only a brief glimpse of enumeration
and decision problems as they appear in logic, computer science, and
elsewhere. We consider them more rigorously in Chapters 5 and 6.
The term eﬀectively enumerable will be made more precise in 6.1 by the
notion of recursive enumerability. At this stage, our explanation of this
5 In 6.6 the incompleteness of ZFC and all its axiomatic extensions will be proved.

118
3 Complete Logical Calculi
notion must be somewhat superﬁcial, though like that for a decidable set
it is highly visualizable. Put roughly, a set M of natural numbers, say, or
syntactic objects, ﬁnite structures, or similar objects is called eﬀectively
(or recursively) enumerable if there exists an algorithm that delivers the
elements of M stepwise.
Thus, in the case of an inﬁnite set M, the
algorithm does not stop its execution by itself.
The calculus of natural deduction enables ﬁrst of all an eﬀective enu-
meration of all provable ﬁnite sequences of a ﬁrst-order language with
at most countably many logical symbols, i.e., all pairs (X, α) such that
X ⊢α and X is ﬁnite, at least in principle. First of all, we imagine all ini-
tial sequents as enumerated in an ongoing, explicitly producible sequence
S0, S1, . . . Then it is systematically checked whether one of the sequent
rules is applicable; the resulting sequents are then enumerated in a second
sequence and so on. Leaving aside problems concerning the storage ca-
pacity of such a deduction machine, as well as the diﬃculties involved in
evaluating the ﬂood of information that would pour from such a device, it
is simply a question of organization to create a program that enumerates
all provable ﬁnite sequents.
Moreover, it can be seen without diﬃculty that the tautologies of a
countable language L are eﬀectively enumerable; one need only pick out
from an enumeration procedure of provable sequents (X, α) those such
that X = ∅. In short, the aforementioned deduction machine delivers
stepwise a sequence α0, α1, . . . (without repetitions if so desired) that
consists of exactly the tautologies of L. This would be somewhat easier
with the calculus in 3.6. However, we cannot in this way obtain a decision
procedure as to whether any given formula α ∈L is a tautology, for we do
not know whether α ever appears in the produced sequence. We will prove
rigorously in 6.5 that in fact such an algorithm does not exist, provided
L contains at least a binary predicate or operation symbol.
Decision
procedures exist only for L=
==
= as will be shown in 5.2, and expansions of
L=
==
= containing only unary predicate and constant symbols, and at most
one unary operation symbol; see also [BGG].
The deduction machine can also be applied to enumerate the theorems
of a given axiomatizable theory T, in that parallel to the enumeration
process for all provable sequents of the language, a process is also set
going that enumerates all axioms of T. It must then continually be checked

3.5 Enumerability and Decidability
119
for the enumerated sequents whether all their premises occur as already-
enumerated assertions; if so, then the conclusion of the sequent in question
is provable in T.
The preceding considerations constitute an informal
proof of the following theorem. A rigorous proof free of merely intuitive
arguments is provided by Theorem 6.2.4.
Theorem 5.1. The theorems of an axiomatizable theory are eﬀectively
enumerable.
Almost all theories considered in mathematics are axiomatizable, in-
cluding formalized set theory ZFC and Peano arithmetic PA. While the
axiom systems of these two theories are inﬁnite and cannot be replaced
by ﬁnite ones, these sets of axioms are evidently decidable.
Our experience hitherto shows us that all theorems of mathematics held
to be proved are also provable in ZFC. Hence, according to Theorem 5.1,
all mathematical theorems can in principle be stepwise generated by a
computer. This fact is theoretically highly important, even if it has little
far-reaching practical signiﬁcance at present.
Recall the notion of a complete theory. Among the most important
examples is the theory of the real closed ﬁelds (Theorem 5.5.5). A note-
worthy feature of complete and axiomatizable theories is their decidability.
We call a theory decidable if the set of its theorems is a decidable set of
formulas, and otherwise undecidable. We shall prove the next theorem in
an intuitive manner. A strict proof, based on the rigorous deﬁnition of
decidability based on the theory of recursive functions in 6.1, will later
be provided by Theorem 6.4.4 on page 247.
Theorem 5.2. A complete axiomatizable theory T is decidable.
Proof. By Theorem 5.1 let α0, α1, . . . be an eﬀective enumeration of all
sentences provable in T. A decision procedure consists simply in com-
paring for given α ∈L0 the sentences α and ¬α in the nth construction
step of α0, α1, . . . with αn. If α = αn then ⊢T α; if α = ¬αn then ⊬T α.
This process certainly terminates, because due to the completeness of T,
either α or ¬α will appear in the enumeration sequence α0, α1, . . . of the
theorems of T.
Conversely, a complete decidable theory is trivially axiomatizable (by
T itself). Thus, for complete theories, “decidable” and “axiomatizable”

120
3 Complete Logical Calculi
mean one and the same thing. A consistent theory has a model and hence
at least one completion, i.e., a complete extension in the same language.
The only completion of a complete theory T is T itself. A remarkable
generalization of Theorem 5.2 is Exercise 3.
A (countable) decidable theory has always a decidable completion, see
Exercise 4. Hence, a theory all completions of which are undecidable is
itself undecidable. We will meet such theories in 6.5. On the other hand,
if T has only ﬁnitely many completions, T0, . . . , Tn say, all of which are
decidable, then so is T. Indeed, according to Exercise 3 in 3.4, α ∈T iﬀ
α ∈Ti for all i ⩽n.6 See also Exercise 3 below.
In the early stages in the development of fast computing machines,
high hopes were held concerning the practical carrying out of mechanized
decision procedures. For various reasons, this optimism has since been
muted, though skillfully employed computers can be helpful not only in
verifying proofs but also in ﬁnding them. This area of applied logic is
called automated theorem proving (ATP). Convincing examples include
computer-supported proofs of the four-color theorem, the Robbins prob-
lem about a particular axiomatization of Boolean algebras, Bieberbach’s
conjecture in function theory, and the nonexistence of a projective plane
of order 10. ATP is used today both in hardware and software veriﬁcation,
for instance in integrated circuit (chip) design and veriﬁcation. A quick
source of information about ATP is the Internet.
Despite these applications, even a developed artiﬁcial-intelligence sys-
tem has presently no chance of simulating the heuristic approach in math-
ematics, where a precise proof from certain hypotheses is frequently only
the culmination of a series of considerations ﬂowing from the imagination.
Creativity in mathematics of today is still a domain of human beings, not
of automata. However, that is not to say that an automatic system may
not be creative in a new way, for it is not necessarily the case that the
human procedural method, inﬂuenced by all kinds of pictorial thoughts,
is the sole means of gaining mathematical knowledge.
6 The elementary absolute (plane) geometry T has precisely two completions, Euclidean
and non-Euclidean (or hyperbolic) geometry. Both are axiomatizable, hence decid-
able. Completeness follows in either case from the completeness of the elementary
theory of real numbers, Theorem 5.5.5. Thus, absolute geometry is decidable as well.
Further applications can be found in 5.2.

3.6 Complete Hilbert Calculi
121
Exercises
1. Let T ′ = T + α (α ∈L0) be a ﬁnite extension of T. Show that if T
is decidable so too is T ′ (cf. Lemma 6.5.3).
2. Assume that T is consistent and has ﬁnitely many completions only.
Prove that each completion of T is a ﬁnite extension of T.
3. Show that an axiomatizable theory with ﬁnitely many completions is
decidable (observe Exercise 2, Exercise 3 in 3.4, and Theorem 5.2).
4. Using the Lindenbaum construction in 1.4, show that a decidable
countable theory T has a decidable completion, [TMR, p. 15].
5. Show that a consistent theory T that has ﬁnitely many completions
has also only ﬁnitely many extensions. More precisely, if T has n
completions then T has 2n −1 consistent extensions. Clearly, n = 1
if T itself is complete.
3.6
Complete Hilbert Calculi
The sequent calculus of 3.1 models natural deduction suﬃciently well.
But it is nonetheless advantageous to use a Hilbert calculus for some pur-
poses, for instance the arithmetization of formal proofs. Such calculi are
based on logical axioms and rules of inference such as modus ponens MP:
α, α →β/β, also called Hilbert-style rules. These rules can be understood
as sequent rules without premises. In a Hilbert calculus, deductions are
drawn from a ﬁxed set of formulas X, e.g., the axioms of a theory, with
the inclusion of the logical axioms. The situation is basically the same as
in 1.6. In the case X = ∅one deduces from the logical axioms alone, and
only tautologies are derivable.
In the following we prove the completeness of a Hilbert calculus in the
logical symbols ¬, ∧, ∀, ==== . It will be denoted here by |∼. MP is its only
rule of inference. |∼refers to any ﬁrst-order language L and is essentially
an extension of the corresponding propositional Hilbert calculus treated
in 1.6. Once again, implication, deﬁned by α →β := ¬(α ∧¬β), will play
a useful part in presenting the calculus.

122
3 Complete Logical Calculi
The logical axiom system Λ of our calculus is taken to consist of all
formulas ∀x1 · · · ∀xnϕ, where ϕ is a formula of the form Λ1–Λ10 below,
and n ⩾0. For example, due to Λ9, x==== x, ∀x x==== x, ∀y x==== x, ∀x∀y x==== x
are logical axioms, even though ∀y is meaningless in the last two formulas.
One may also say that Λ is the set of all formulas that can be derived from
Λ1–Λ10 by means of the rule MQ: α/∀xα. Attention: MQ is not a rule
of inference of the calculus
|∼, nor is it provable, although the set of
tautologies is closed under MQ. We will later take a closer look at MQ.
Λ1: (α →β →γ) →(α →β) →α →γ, Λ2: α →β →α ∧β,
Λ3: α ∧β →α,
α ∧β →β,
Λ4: (α →¬β) →β →¬α,
Λ5: ∀xα →α tx
(α, tx collision-free), Λ6: α →∀xα
(x /∈free α)
Λ7: ∀x(α →β) →∀xα →∀xβ,
Λ8: ∀yα y
x →∀xα
(y ̸∈var α),
Λ9: t==== t,
Λ10: x==== y →α →α y
x
(α prime).
It is easy to recognize Λ1–Λ10 as tautologies. For Λ1–Λ4 this is clear by
1.6. For Λ5–Λ8 the reasoning proceeds straightforwardly by accounting
for Corollary 2.3.6 on page 71 and the logical equivalences in 2.4. For Λ9
the claim is trivial, and Λ10 is equivalent to x==== y, α ⊨y
x, and the latter
is obviously the case.
Axiom Λ5 corresponds to the rule (∀1) of the calculus in 3.1, while
Λ6 serves to deal with superﬂuous preﬁxes. The role of Λ7 will become
clear in the completeness proof for |∼, and Λ8 is part of bound renaming.
Λ9 and Λ10 control the formal treatment of identity. If ϕ is a tautology,
then for any preﬁx block ∀⃗x, so too is ∀⃗xϕ. Thus, Λ consists solely of
tautologies.
The same holds for formulas derivable from Λ using MP,
simply because ⊨α, α →β implies ⊨β.
Let X |∼α if there exists a proof Φ = (ϕ0, . . . , ϕn) of α from X, that is,
α = ϕn, and for all k ⩽n either ϕk ∈X ∪Λ or there exists some ϕ such
that ϕ and ϕ →ϕk appear as members of Φ before ϕk. This deﬁnition
and its consequences are the same as in 1.6. As is the case there and
proved in the same way, it holds that X |∼α, α →β ⇒X |∼β. Moreover,
Theorem 1.6.1 also carries over unaltered, whose application will often be
announced by the heading “proof by induction on X |∼α.” For instance,
the soundness of |∼is proved by induction on X |∼α, where soundness is
as usual to mean X |∼α ⇒X ⊨α, for all X and α. In short, |∼⊆⊨.
The proof runs exactly as on page 37.

3.6 Complete Hilbert Calculi
123
The completeness of |∼can now be relatively easily be traced back to
that of the rule calculus ⊢of 3.1. Indeed, much of the work was already
undertaken in 1.6, and we can immediately formulate the completeness
of the calculus |∼.
Theorem 6.1 (Completeness theorem for |∼).
|∼= ⊨.
Proof. |∼⊆⊨has already been veriﬁed. ⊨⊆|∼follows from the claim
that |∼satisﬁes all nine basic rules of ⊢. This implies ⊢⊆|∼, and since
⊢= ⊨we have also ⊨⊆|∼. For the rules ( ∧1) through (¬2) the claim holds
according to their proof for the Hilbert calculus in 1.6. Lemmas 1.6.2
through 1.6.5 carry over word for word, because we have kept the four
axioms on which the proofs are based and have taken no new rules into
account. (∀1) follows immediately from Λ5 using MP, and (IR) is dealt
with by Λ9. Only (∀2) and (=) provide us with a little work, which, by
the way, will clear up the role of axioms Λ6, Λ7, and Λ8.
(∀2): Suppose x ̸∈free X. We ﬁrst prove X |∼α ⇒X |∼∀xα by induc-
tion on X |∼α. Initial step: If α ∈X then x is not free in α. Hence,
X |∼α →∀xα using Λ6, and MP yields X |∼∀xα.
If α ∈Λ then also
∀xα ∈Λ, and likewise X |∼∀xα. Induction step: Let X |∼α, α →β and
X |∼∀xα, ∀x(α →β) according to the induction hypothesis. This yields
X |∼∀xα, ∀xα →∀xβ by Axiom Λ7 and MP and, by another application
of MP, the induction claim X |∼∀xβ.
Now, to verify (∀2), let X |∼α y
x
and y ̸∈free X ∪var α. By what we have just proved, we get X |∼∀yα y
x.
This, MP, and X |∼∀yα y
x →∀xα (Axiom Λ8) yield the conclusion of (∀2),
X |∼∀xα. Thus, |∼indeed satisﬁes the rule (∀2).
(=): Let α be a prime formula and X |∼s==== t, α sx.
Further, let y be a
variable ̸= x not in s and α. Then certainly X |∼∀x∀y(x==== y →α →α y
x),
because the latter is a logical axiom in view of Λ10. By the choice of y,
rule (∀1) shows that
X |∼[∀y(x==== y →α →α y
x)] sx
= ∀y(s==== y →α sx →α y
x).
Because of y /∈var α, s and α y
x ty = α tx, another application of (∀1) yields
X |∼[s==== y →α sx →α y
x] ty
= s==== t →α sx →α y
x ty
= s==== t →α sx →α tx.
Since X |∼s==== t, α sx by assumption, two applications of MP then leads to
the desired conclusion X |∼α tx .
A special case of the above completeness theorem is the following

124
3 Complete Logical Calculi
Corollary 6.2. For any α ∈L, the following properties are equivalent:
(i)
|∼α, that is, α is derivable from Λ by means of MP only,
(ii)
α is derivable from Λ1–Λ10 by means of MP and MQ,
(iii) ⊨α, i.e., α is a tautology.
The equivalence of (i) and (iii) renders especially intuitive the possi-
bility to construct a “deduction machine” that eﬀectively enumerates the
set of all tautologies of L. Here, we are dealing with just one rule of in-
ference, modus ponens; hence we need the help of a machine to list the
logical axioms, a “deducer” to check whether MP is applicable, and, if so,
to apply it, and an output unit that emits the results and feeds them back
into the deducer for further processing. However, similar to the case of a
sequent calculus, such a procedure is not actually practicable; the distinc-
tion between signiﬁcant and insigniﬁcant derivations is too involved to be
taken into account. Who would be interested to ﬁnd in the listing such a
weird-looking tautology as for instance ∃x(rx →∀y ry)?
Next we want to show that the global consequence relation ⊨
g deﬁned
in 2.5 can also be completely characterized by a Hilbert calculus. It is
necessary only to adjoin the generalization rule MQ to the calculus |∼.
The resulting Hilbert calculus, denoted by ⊢
g, has two rules of inference,
MP and MQ. Proofs in ⊢
g have to be correspondingly redeﬁned.
Like every Hilbert calculus, ⊢
g is transitive: X ⊢
g Y & Y ⊢
g α ⇒X ⊢
g α.
This was veriﬁed in 1.6 for propositional Hilbert calculi, but the same
argument applies also to Hilbert calculi in ﬁrst-order languages. With
this remark, the completeness of ⊢
g follows easily from that of |∼:
Theorem 6.3 (Completeness theorem for ⊢
g ). ⊢
g = ⊨
g.
Proof. Certainly ⊢
g ⊆⊨
g, since both MP and MQ are sound for ⊨
g. Now let
X ⊨
g α, so that X g ⊨α by (1) of 2.5. This yields X g |∼α by Theorem 6.1,
and so X g ⊢
g α, since |∼⊆⊢
g by deﬁnition of ⊢
g. Clearly, X ⊢
g X g in virtue
of MQ; hence transitivity provides the desired X ⊢
g α.
We now are going to discuss a notion of equal interest for both logic and
computer science. α ∈L0 is called generally valid in the ﬁnite if A ⊨α for
all ﬁnite structures A. Examples of such sentences α not being tautolo-
gies can be constructed in every ﬁrst-order language L that contains at
least a unary function or a binary relation symbol. For instance, consider

3.6 Complete Hilbert Calculi
125
∀x∀y(fx==== fy →x==== y) →∀y∃x y ==== fx from a language L containing the
function symbol f. This sentence can be refuted only in an inﬁnite L-
structure since an injection in a ﬁnite L-structure is surjective. It holds
in all ﬁnite L-structures A, but is not in TautL. Thus, TautL is properly
extended by the set of L-sentences valid in the ﬁnite, TautﬁnL.
Tautﬁn (= TautﬁnL) is for each L a theory T with the ﬁnite model
property, i.e., every α ∈L0 compatible with T has a ﬁnite T-model. More
generally, the theory T = Th K has for any class K of ﬁnite L-structures
the ﬁnite model property. Indeed, if T +α is consistent, i.e., ¬α /∈T, then
A ⊭¬α for some A ∈K; hence A ⊨α. Examples are the theories FSG
and FG of all ﬁnite semigroups and ﬁnite groups in L◦, respectively. Both
theories are undecidable. As regards FSG, the proof is not particularly
diﬃcult; see 6.6. Unlike Taut, the set Tautﬁn is not axiomatizable for
most languages L. This is the claim of
Theorem 6.4 (Trachtenbrot). TautﬁnL is not (recursively) axiomatiz-
able for any ﬁrst-order language L containing at least one binary operation
or a binary relation symbol.
Proof. We restrict ourselves to the ﬁrst case; for a binary relation symbol,
the same follows easily by means of interpretation (Theorem 6.6.3). If
TautﬁnL were axiomatizable it would also be decidable because of the
ﬁnite model property; Exercise 2. The same is true also for TautﬁnL◦,
and by Exercise 1 in 3.5, so too for FSG, because FSG is the extension
of TautﬁnL◦by a single sentence, the law of associativity. But as already
mentioned, FSG is undecidable.
The theorem is in fact a corollary of much stronger results that have
been established in the meantime. For the newer literature on decision
problems of this type consult [Id]. Unlike FG, the theory of ﬁnite abelian
groups, as well as of all abelian groups, is decidable, [Sz]. The former is a
proper extension of the latter; for instance (as stated in Exercise 4),
∀x∃y y + y ==== x →∀x(x + x==== 0 →x==== 0)
does not hold in all abelian groups, though it does in all ﬁnite ones.
As early as 1922 Behmann discovered by quantiﬁer elimination that
Taut possesses the ﬁnite model property provided the signature contains
only unary predicate symbols; one can also prove this without diﬃculty by

126
3 Complete Logical Calculi
the Ehrenfeucht game of 5.3. In this case, then, Tautﬁn = Taut, because
α /∈Taut implies ¬α is satisﬁable and therefore has a ﬁnite model. Thus,
α /∈Tautﬁn. This proves Tautﬁn ⊆Taut and hence Tautﬁn = Taut. With
the Ehrenfeucht game also a quite natural axiomatization of the theory
FO of all ﬁnite ordered sets is obtained. See Exercise 3 in 5.3.
Exercises
1. Show that MQ is unprovable in |∼(that is, X |∼α ⇒X |∼∀xα does
not hold, in general).
2. Suppose (i) a theory T has the ﬁnite model property, (ii) the ﬁ-
nite T-models are eﬀectively enumerable (more precisely, a system
of representatives thereof up to isomorphism). Show that (a) the
sentences α refutable in T are eﬀectively enumerable, (b) if T is
axiomatizable then it is also decidable.
3. Let T be a ﬁnitely axiomatizable theory with the ﬁnite model prop-
erty. Show by working back to Exercise 2 that T is decidable.
4. Show that ∀x∃y y + y ==== x →∀x(x + x==== 0 →x==== 0) holds in all ﬁnite
abelian groups. Moreover, provide an example of an inﬁnite abelian
group for which the above proposition fails.
3.7
First-Order Fragments
Subsequent to Gödel’s completeness theorem it makes sense to investigate
some fragments of ﬁrst-order languages aiming at a formal characteriza-
tion of deduction inside the fragment. In this section we present some
results in this regard; in the next section we shall do the same for some
extensions. First-order fragments are formalisms that come along without
the full means of expression in a ﬁrst-order language, for instance by the
omission of some or all logical connectives, or restricted quantiﬁcation.
These formalisms are interesting for various reasons, partly because of
the growing interest in automatic information processing with its more or
less restricted user interface. The poorer a linguistic fragment, the more
modest the possibilities for the formulation of sound rules. Therefore, the
completeness problem for fragments is in general nontrivial.

3.7 First-Order Fragments
127
A useful example dealt with more closely is the language of equations,
whose only formulas are equations of a ﬁxed algebraic signature. We think
of the variables in the equations as being tacitly generalized and call these
generalizations identities, though we often speak somewhat sloppily of
equations. Theories with axiom systems of identities are called equational
theories and their model classes equational-deﬁned classes or varieties.
Let Γ denote a set of identities deﬁning an equational theory, γ a single
equation, and assume Γg ⊨γ. By Theorem 2.7 there is a formal proof
for γ from Γ. But because of the special form of the equations, it can be
expected that one does not need the whole formalism to verify Γg ⊢γ.
Indeed, Theorem 7.2 states that the Birkhoﬀrules (B0)–(B4) below, taken
from [Bi], suﬃce. This result is so pleasing because when operating with
(B0)–(B4), we remain completely inside the language of equations. The
rules deﬁne a Hilbert-style calculus denoted by ⊢
B and look as follows:
(B0) /t==== t,
(B1) s==== t/t==== s,
(B2) t==== s, s==== t′/t==== t′,
(B3) t1 ==== t′
1, . . . , tn ==== t′
n/ft1 · · · tn ==== ft′
1 · · · t′
n, (B4) s==== t/sσ ==== tσ.
Here σ is a global substitution, though as explained in 2.2 it would suf-
ﬁce to consider just simple σ. (B0) has no premise, which means that
t==== t is derivable from any set of identities (or t==== t is added as an ax-
iom to Γ). These rules are formally stated with respect to unquantiﬁed
equations. However, we think of all variables as being generalized in a
formal derivation sequence. We are forced to do this by the soundness
requirement of (B4), because in general only (s==== t)g ⊨sσ ==== tσ. To verify
Γ ⊢
B γ ⇒Γg ⊨γ, we need only to show that the property Γg ⊨γ is closed
under (B0)–(B4), i.e., A ⊨t==== t (which is trivial), A ⊨s==== t ⇒A ⊨t==== s,
etc. We have already come across the rules of ⊢
B in 3.1, stated there as
Gentzen-style rules; they ensure that by s ≈t :⇔Γ ⊢
B s==== t, a congru-
ence in the term algebra T is deﬁned as in Lemma 2.5. (B4) states the
substitution invariance of ≈, which is to mean s ≈t ⇒sσ ≈tσ.
Let F denote the factor structure of T with respect to ≈(no distinction
is made between the algebra T and its domain), and let t denote the
congruence class modulo ≈to which the term t belongs, so that
(1)
t1 = t2 ⇔Γ ⊢
B t1 ==== t2.
Further, let w: Var →F, say xw = tx, with arbitrary tx ∈xw. Any such
choice determines a global substitution σw : x 
→tx. Induction on t yields
(2)
tF,w = tσ
(σ := σw).

128
3 Complete Logical Calculi
Lemma 7.1. Γ ⊢
B t1 ==== t2 ⇔F ⊨t1 ==== t2.
Proof. Let Γ ⊢
B t1 ==== t2, w: Var →F, and σ = σw. By (B4) then also
Γ ⊢
B tσ
1 ==== tσ
2, so that tσ
1 = tσ
2 by (1). Thus, tF,w
1
= tF,w
2
using (2). Since
w was arbitrary, F ⊨t1 ==== t2. Now suppose the latter and let κ be the
so-called canonical valuation x 
→x. Here we choose σκ = ι (the identical
substitution), hence tF,κ
i
= ti by (2). F ⊨t1 ==== t2 implies tF,κ
1
= tF,κ
2
, and
in view of tF,κ
i
= ti, we get t1 = t2 and so Γ ⊢
B t1 ==== t2 by (1).
Theorem 7.2 (Birkhoﬀ’s completeness theorem). Let Γ be a set of
identities and t1====t2 an equation. Then Γ ⊢
B t1====t2 ⇔Γg ⊨t1====t2.
Proof. The direction ⇒is the soundness of ⊢
B. Now let Γg ⊨t1 ==== t2.
Then certainly F ⊨Γ according to Lemma 7.1, or equivalently F ⊨Γg.
Thus, F ⊨t1 ==== t2. Using Lemma 7.1 once again yields Γ ⊢
B t1 ==== t2.
This proof is distinguished on the one hand by its simplicity and on
the other by its highly abstract character. It has manifold variations and
is valid in a corresponding sense, for example, for sentences of the form
∀⃗xπ with arbitrary prime formulas π of any given ﬁrst-order language. It
is rather obvious how to strengthen the Birkhoﬀrules to cover this more
general case: Keep (B0), (B1), and (B3) and replace the conclusions of
(B3) and (B4) by arbitrary prime formulas of the language.
There is also a special calculus for sentences of the form
(3)
∀⃗x (γ1 ∧· · · ∧γn →γ0)
(n ⩾0, all γi equations),
called quasi-identities.
Theories whose axioms are of the form (3) are
called quasi-equational theories and their model classes quasi-varieties.
The latter are important both for algebra and logic. (B0) is retained and
(B1)–(B3) are replaced by the rules without premises (axioms)
/x==== y →y ==== x,
/x==== y ∧y ==== z →x==== z,
/ n
i=1 xi ==== yi →f⃗x==== f⃗y.
Besides an adaptation of (B4), some rules are required for the formal
handling of the premises γ1, . . . , γn in (3), for instance their permutability
(for details see e.g. [Se]). A highly important additional rule is here a
variant of the cut rule, namely the binary Hilbert-style rule
α ∧δ →γ, α →δ/α →γ
(α a conjunction of equations).
The most interesting case for automated information processing, where
Hilbert rules remaining inside the fragment still provide completeness, is
that of universal Horn theories. Here, roughly speaking, the equations γi

3.8 Extensions of First-Order Languages
129
in (3) may be any prime formulas. Horn theories are treated in Chapter 4.
But for enabling a real machine implementation, the calculus considered
there, the resolution calculus, is diﬀerent from a Hilbert- or a Gentzen-
style calculus.
Exercises
1. Show that a variety K is closed with respect to homomorphic im-
ages, taking subalgebras, and forming arbitrary direct products of
members of K; in short, K has the properties H, S, and P.7
2. Develop a calculus for quasi-varieties as indicated in the text and
prove its completeness. This exercise is a comprehensive task; we
recommend to start with a study of [Se].
3.8
Extensions of First-Order Languages
Now we consider a few of the numerous possibilities for extending ﬁrst-
order languages to increase the power of expression: We say that a lan-
guage L′ ⊇L of the same signature as L is more expressive than L if for
at least one sentence α ∈L′, Md α is distinct from all Md β for β ∈L.
In L′, some of the properties of ﬁrst-order languages are lost. Indeed,
the claim of the next theorem is that ﬁrst-order languages are optimal in
regard to the richness of their applications.
Lindström’s Theorem (see [EFT] or [CK]). There is no language of
a given signature that is more expressive than the ﬁrst-order language
and for which both the compactness theorem and the Löwenheim–Skolem
theorem hold.
Many-sorted languages. In describing geometric facts it is convenient
to use several variables, for points, lines, and, depending on dimension,
also for geometrical objects of higher dimension.
For every argument
of a predicate or operation symbol of such a language, it is useful to
ﬁx its sort. For instance, the incidence relation of plane geometry has
arguments for points and lines. For function symbols, the sort of their
7 Conversely, if a class K has these three properties then K is a variety.
This is
Birkhoﬀ’s HSP theorem, a basic theorem of universal algebra; see e.g. [Mo].

130
3 Complete Logical Calculi
values must additionally be given. If L is of sort k and vs
0, vs
1, . . . are
variables of sort s (1 ⩽s ⩽k) then every relation symbol r is assigned
a sequence (s1, . . . , sn); in a language without function symbols, prime
formulas beginning with r have the form rxs1
1 · · · xsn
n , where xsi
i denotes a
variable of the sort si.
Many-sorted languages represent only an inessential extension of the
concept hitherto expounded, provided the sorts are given equal rights.
Instead of a language L with k sorts of variables, we can consider a one-
sorted language L′ with additional unary predicate symbols P1, . . . , Pk
and the adoption of certain new axioms: ∃xPix for i = 1, . . . , k (no sort
is empty, for otherwise it is dispensable) and ¬∃x(Pix ∧Pjx) for i ̸= j
(sort disjunction). For example, plane geometry could also be described
in a one-sorted language with the additional predicates pt (to be a point)
and li (to be a line). Apart from a few diﬀerences in dealing with term
insertion, many-sorted ﬁrst-order languages behave almost exactly like
one-sorted languages.
Second-order languages. Some frequently quoted axioms, e.g., the in-
duction axiom IA, may be looked upon as second-order sentences. The sim-
plest extension of a ﬁrst-order language to one of higher order is the
monadic second-order language, a two-sorted language. Let us consider
such a language L with variables x, y, z, . . . for individuals and variables
X, Y, Z, . . . for sets of these individuals, along with at least one binary re-
lation symbol ∈but without function symbols. Prime formulas are x==== y,
X ==== Y, and x ∈X. An L-structure is generally of the form (A, B, ∈), where
∈⊆A × B. The goal is that by formulating additional axioms such as
∀XY [∀x(x ∈X ↔x ∈Y ) →X ==== Y ] (which corresponds to the axiom of
extensionality AE in 3.4), the relation symbol ∈should be interpretable
as the membership relation ∈; hence B should consist of the subsets of A.
This goal is not fully attainable, but nearly so. Axioms on A, B can be
found such that B is interpretable as a subset of PA, with ∈interpreted
as ∈. The same works by adding sort variables for members of PPA,
PPPA, etc. This “completeness of the theory of types” plays a basic role,
for instance, in the higher nonstandard analysis.
A more enveloping second-order language, LII, is won by adopting
quantiﬁable variables for relations of each ﬁnite arity on the domains
of individuals. But LII then fails to satisfy both the ﬁniteness and the

3.8 Extensions of First-Order Languages
131
Löwenheim–Skolem theorem (Theorem 4.1), even for L = L=
==
=. The former
fails because a sentence αﬁn can be given in LII such that A ⊨αﬁn iﬀA
is ﬁnite. For note that A is ﬁnite iﬀevery injective f : A →A is bijective.
This can eﬀortlessly be formalized using a single universally quantiﬁed
binary predicate variable characterizing the graph of f.
The Löwenheim–Skolem theorem is also easily refutable for LII; one
need only write down in LII the sentence ‘there exists a continuous order
on A without smallest or largest element’. This sentence has no countable
model. For if there were such a model, it would be isomorphic to the
ordered set of rationals according to a theorem of Cantor (Example 2 in
5.2) and therefore has gaps, contradicting our assumption.
There is still a more serious problem as regards LII: The ZFC-axioms,
seen as axioms of the underlying set theory, do not suﬃce to establish
what a tautology in LII should actually be. For instance, the continuum
hypothesis CH (see page 174) can be easily formulated as an LII-sentence,
αCH.
But CH is independent of ZFC.
Thus, if CH is true, αCH is an
LII-tautology, otherwise not. It does not look as though mathematical
intuition suﬃces to decide this question unambiguously.
New quantiﬁers.
A simple syntactic extension L∼O of a ﬁrst-order
language L is obtained by taking on a new quantiﬁer denoted by ∼O,
which formally is to be handled as the ∀-quantiﬁer. However, in a model
M = (A, w), a new interpretation of ∼O is provided by means of the
satisfaction clause
(0)
M ⊨∼Oxα ⇔there are inﬁnitely many a ∈A with Ma
x ⊨α.
With this interpretation, we write L 0
∼O instead of L∼O, since yet another
interpretation of ∼O will be discussed.
L 0
∼O is more expressive than L,
as seen by the fact, for example, that the ﬁniteness theorem for L0
∼O no
longer holds: Let X be the collection of all sentences ∃n (there exist at
least n elements) plus αﬁn := ¬∼Ox x==== x (there exist only ﬁnitely many
elements). Every ﬁnite subset of X has a model, but X itself does not. All
the same, L 0
∼O still satisﬁes the Löwenheim–Skolem theorem. This can be
proved straightforwardly with the methods of 5.1. Once again, because
of the missing ﬁniteness theorem there cannot be a complete rule calculus
for L 0
∼O . Otherwise, just as in 3.1, one could prove the ﬁniteness theorem
after all. However, there are several nontrivial, correct Hilbert-style rules
for L 0
∼O , for instance the four rules

132
3 Complete Logical Calculi
(Q1) /¬∼Ox(x==== y ∨x==== z),
(Q2) ∼Oxα/∼Oyα y
x (y /∈free α),
(Q3) ∀x(α →β)/∼Oxα →∼Oxβ,
(Q4) ∼Ox∃yα, ¬∼Oy∃xα/∃y∼Ox α.
In rule (Q1), which has no premises, clearly x ̸= y, z. Intuitively, this
rule tells us that the pair set {y, z} is ﬁnite. (Q2) is bound renaming.
(Q3) says that a set containing an inﬁnite subset is itself inﬁnite. (Q4) is
rendered intuitive with α = α(x, y) as follows:
Suppose that A ⊨∼Ox∃yα, ¬∼Oy∃xα and let Ab = {a ∈A | A ⊨α(a, b)}.
Then A ⊨∼Ox∃y α states ‘
b∈A Ab is inﬁnite’, and A ⊨¬∼Oy∃x α says
‘there exist only ﬁnitely many b such that Ab ̸= ∅’. The conclusion ∃y∼Oxα
tells us therefore ‘Ab is inﬁnite for at least one index b’. Hence, (Q4)
expresses altogether that the union of a ﬁnite system of ﬁnite sets is ﬁnite.
Now let us replace the satisfaction clause (0) by
(1) M ⊨∼Oxα ⇔there are uncountably many a ∈A with Ma
x ⊨α.
Also with this interpretation, (Q1)–(Q4) are sound for L 1
∼O (= L∼O with
the interpretation (1) ). Rule (Q4) now evidently expresses that a count-
able union of countable sets is again countable.
Moreover, the logical
calculus ⊢
1 resulting from the basic rules of 3.1 by adjoining (Q1)–(Q4)
is, surprisingly, complete for these semantics when restricted to countable
sets X.
Thus, X ⊢
1 α ⇔X ⊨α, for any countable X ⊆L 1
∼O , [CK].
This implies the following compactness theorem for L 1
∼O : If every ﬁnite
subset of a countable set X ⊆L 1
∼O has a model then so too does X. For
uncountable sets of formulas this is false in general; Exercise 1.
The above is a fairly incomplete listing of languages with modiﬁed quan-
tiﬁers. There are also several other extensions of ﬁrst-order languages, for
instance languages with inﬁnite formulas (containing inﬁnitely long con-
junctions and disjunctions). In this respect we refer to the literature on
model theory.
Programming languages.
All languages hitherto discussed are of
static character inasmuch as there are spatially and temporally indepen-
dent truth values for given valuations w in a structure A. But one can
also connect a ﬁrst-order language L in various ways with a programming
language having dynamic character and aiming at the description of cer-
tain types of information processing. The choice of L depends on what
the programming language is aiming at. L can as a rule be reconstructed
from the description of the programming language’s syntax.

3.8 Extensions of First-Order Languages
133
The theory of programming languages, both syntax and semantics, has
its roots in mathematical logic. Nonetheless, it has assumed an indepen-
dent status and belongs rather to computer science than to logic. Hence
our considerations will be rather brief.
We describe here a simple example of such a language, PL, where L
is a ﬁxed ﬁrst-order language. Only the open formulas of L will be used
in PL, not the quantiﬁers. The elements of PL are certain strings, called
programs, denoted by P, Q, . . . , and deﬁned below.
The dynamic character of PL arises by modifying traditional semantics
as follows: A program P starts with a valuation w: Var →A where A
is the domain of a given L-structure A. The program P alters stepwise
the values of the variables as a run of the program proceeds in time. If P
terminates upon feeding in w, i.e., the calculation ends after ﬁnitely many
steps of calculation, then the result is a new valuation wP. Otherwise we
take wP to be undeﬁned. The precise description of this in general only
partially deﬁned operation w 
→wP is called the procedural semantics of
PL. A closer description will be given below.
It is possible to meaningfully consider issues of completeness, say, for
procedural semantics as well.
For instance, if L speaks about natural
numbers one may ask what conditions have to be posed on L such that
each computable function is programmable in PL.
The syntax of PL is speciﬁed as follows: The logical signature of L
is extended by the symbols WHILE , DO , END , :==== , and ; (the semicolon
serves only as a separator for concatenated programs and could be omitted
if programs are arranged 2-dimensionally). Programs on L are deﬁned
inductively as strings of symbols in the following manner:
• For any x ∈Var and term t ∈TL, the string x :==== t is a program.
• If α is an open formula in L and P, Q are programs, so too are the
strings P ; Q and WHILE α DO P END.
No other strings are programs in this context. P ; Q is to mean that
ﬁrst P and then Q are executed.
Let Pn denote the n-times repeated
execution of P, more precisely, P0 is the empty program (wP0 = w) and
Pn+1 = Pn ; P.
The procedural semantics for the programming language PL is made
precise by the following stipulations:

134
3 Complete Logical Calculi
(a) wx :==== t = w tw
x (i.e., w alters at most the value of the variable x).
(b) If wP and (wP)Q are deﬁned, so too is wP;Q, and wP;Q = (wP)Q.
(c) For Q := WHILE α DO P END let wQ = wPk with k speciﬁed below.
According to our intuition regarding the “WHILE loop,” k is the smallest
number such that A ⊨α [wPi] for all i < k and A ⊭α [wPk], provided
such a k exists and all wPi for i ⩽k are well deﬁned. Otherwise wQ is
considered to be undeﬁned. If k = 0, that is, A ⊭α [w], then wQ = w,
which amounts to saying that P is not executed at all, in accordance with
the meaning of WHILE in standard programming languages.
Example. Let L = L{0, S, Pd} and consider A = (N, 0, S, Pd), where S
denotes the successor function and Pd the predecessor function, deﬁned
by y ==== Pd x ↔y ==== 0 ∨x==== Sy (so that Pd 0==== 0). Let P be the program
z :==== x ; v :==== y ; WHILE v̸====0 DO z :==== Sz ; v :==== Pd v END.
If x and y initially have the values xw = m and yw = n, the program ends
with zwP = m + n. In other words, P terminates for every input m, n
for x, y and computes the output m + n in the variable z, while x, y keep
their initial values.
In PL, the self-explanatory program schema IF α THEN P ELSE Q END is
deﬁnable by the following composed program:
x :==== 0 ; WHILE α ∧x==== 0 DO P ; x :==== S0 END ; WHILE x==== 0 DO Q ; x :==== S0 END,
where x is a variable not appearing in P, Q, and α.
Exercises
1. Show (a) both LII and L 1
∼O violate the Löwenheim–Skolem theorem,
(b) the ﬁniteness theorem is false for uncountable sets of formulas
in L 1
∼O , in general (although it holds for countable sets of formulas).
2. Express the continuum hypothesis as a (possibly false) theorem of
LII.
3. Verify the correctness of the deﬁnition of IF α THEN P ELSE Q END
given at the end of the above text.
4. Deﬁne the D0 P UNTIL α END loop in the programming language PL.
In this loop, P is executed before the test α is started. That is, P is
executed at least once.

Chapter 4
Foundations of Logic Programming
Logic programming aims not so much at solving numerical problems in
science and technology, as at treating information processing in general,
in particular at the creation of expert systems of artiﬁcial intelligence.
A distinction has to be made between logic programming as theoretical
subject matter and the widely used programming language for practical
tasks of this kind, PROLOG. In regard to the latter, we conﬁne ourselves
to a presentation of a somewhat simpliﬁed version, which nonetheless
preserves the typical features.
The notions dealt with in 4.1 are of fairly general nature. Their origin
lies in certain theoretical questions posed by mathematical logic, and they
took shape before the invention of the computer.
For certain sets of
formulas, in particular for sets of universal Horn formulas, which are very
important for logic programming, term models are obtained canonically.
The newcomer need not understand all details of 4.1 at once, but should
learn about Horn formulas in 4.2 and after a glance at the theorems may
then continue with 4.3.
The resolution method and its combination with uniﬁcation applied
in PROLOG were directly inspired by mechanical information processing.
This method is also of signiﬁcance for tasks of automated theorem proving,
which extends beyond logic programming.
We treat resolution ﬁrst in
the framework of propositional logic in 4.3. Its highlight, the resolution
theorem, is proved constructively, without recourse to the propositional
compactness theorem. In 4.5, uniﬁcation is dealt with, and 4.6 presents
the combination of resolution with uniﬁcation and its application to logic
programming. An introduction to this area is also oﬀered by [Ll].
W. Rautenberg, A Concise Introduction to Mathematical Logic,
135
Universitext, DOI 10.1007/978-1-4419-1221-3_4,
c⃝Springer Science+Business Media, LLC 2010

136
4 Foundations of Logic Programming
4.1
Term Models and Herbrand’s Theorem
In the proof of Lemma 3.2.5 as well as in Lemma 3.7.1 we have come
across models whose domains are equivalence classes of terms of a ﬁrst-
order language L. In general, a term model is to mean an L-model F
whose domain F is the set of congruence classes t = t/≈of a congruence
≈(= ≈F) on the algebra T = TL. If ≈is the identity in T , one identiﬁes
F with T so that then t = t. Function symbols and constants are always
interpreted canonically: fF(t1, . . . , tn) := ft1 · · · tn and cF := c, while no
particular condition is imposed on realizing the relation symbols in F.
Further, let κ: x 
→x (x ∈Var). This is called the canonical valuation.
In the terminology of 2.3, F = (F, κ), where F = T/≈T denotes the L-
structure belonging to the model F with the domain F = {t | t ∈T }. We
claim that independent of a speciﬁcation of ≈F and of the rF,
(1)
tF = t for all t ∈T,
(2)
F ⊨∀⃗xα ⇔F ⊨α ⃗t
⃗x for all ⃗t ∈T n
(α open).
(1) is veriﬁed by an easy term induction (cf. the proof of (d) page 101). (2)
follows from left to right by Corollary 2.3.6. The converse runs as follows:
F ⊨α ⃗t
⃗x for all ⃗t ∈T n implies Ft1···tn
x1···xn = F⃗t F
⃗x
⊨α for all t1, . . . , tn ∈T in
view of (1) and of Theorem 2.3.5. But this means that F ⊨∀⃗xα, because
the t for t ∈T exhaust the domain of F.
Interesting for both theoretical logic and automated theorem proving
including logic programming, is the question, for which consistent X ⊆L
can a term model be constructed in L. An answer to this question is
given by Theorems 1.1 and 2.1 below. First, we associate with each given
X ⊆L a special term model as follows.
Deﬁnition. The term model F = FX (associated with a set X ⊆L) is
the term model for which ≈FX and rFX are deﬁned by
s ≈FX t :⇔X ⊢s==== t;
rFXt1 · · · tn :⇔X ⊢rt1 · · · tn .
It is easily veriﬁed that ≈FX is a congruence in T and that the deﬁnition
of rFX does not depend on the representatives. If X is the axiom system
of some theory T, then we write also FT for FX, and s ≈T t for s ≈FX t.
By (1), FX ⊨s==== t ⇔s = t ⇔X ⊢s==== t. Similarly FX ⊨r⃗t ⇔X ⊢r⃗t .
In general, FX is not a model for X. Our deﬁnition merely implies
(3)
FX ⊨π ⇔X ⊢π
(π prime).

4.1 Term Models and Herbrand’s Theorem
137
Here is a simple example in which the associated term model FT is a
model for T. It will turn out to be a special case of Theorem 2.1.
Example 1. Let T be the theory of semigroups and F the algebra belong-
ing to the term model FT. Every term t is equivalent in T to a term in left
association, denoted by x1 · · · xn (the operation symbol is not written and
x1, . . . , xn is an enumeration of the variables of t in order of appearance
in t from left to right, possibly with repetitions). Thus, t ≈T x1 · · · xn.
For instance, v0((v1v0)v1) ≈T v0v1v0v1. It is easy to see that ı: S →F
with ı(x1, . . . , xn) = x1 . . . xn is an isomorphism, where S is the semigroup
of strings over the alphabet Var, and (x1, . . . , xn) denotes here the string
with the letters x1, . . . , xn. Thus, with S also F is a semigroup, hence
F ⊨T. This amounts to the same as saying F ⊨T.
As already announced earlier, we slightly extend the concept of a model.
Let Lk and Vark be deﬁned as in 2.2. Pairs (A, w) with dom w ⊇Vark
are called Lk-models. Here w need not be deﬁned for vk, vk+1, . . . One
may also say that an allocation to these variables has deliberately been
“forgotten.”
In the case k = 0 Choose is w = ∅, so that an L0-model
coincides with an L-structure. Put Tk := {t ∈T | var t ⊆Vark}. To
ensure that the set T0 of ground terms is nonempty, we tacitly assume in
this chapter that L contains at least one constant when considering T0.
Clearly, Tk is a subalgebra of T , since t1, . . . , tn ∈Tk ⇒f⃗t ∈Tk.
The concept of a term model can equally be related to Lk: Let ≈be
a congruence in Tk and Fk the factor structure Tk/≈whose domain is
Fk = {t | t ∈Tk} with t = t/≈, together with some interpretation of the
relation symbols in Tk. We extend Fk canonically to an Lk-model Fk by
the (partial) valuation x 
→x for x ∈Vark, which is empty for k = 0
so that F0 and F0 can be identiﬁed. For each k, the following conditions
are veriﬁed similarly as with (1), (2), (3). The Lk-model FkX in (3k) is
deﬁned analogously to FX on the domain Tk/≈with s ≈t ⇔X ⊢s==== t
for s, t ∈Tk; in particular, F0X arises by factorizing T0.
(1k)
tFk = t for all t ∈Tk,
(2k)
Fk ⊨∀⃗xα ⇔Fk ⊨α ⃗t
⃗x for all ⃗t ∈T n
k
(α open),
(3k)
FkX ⊨π ⇔X ⊢π
(π a prime formula from Lk).
Let ϕ = ∀⃗xα a universal formula (∀-formula). Then α ⃗t
⃗x is called an
instance of ϕ. And if ⃗t ∈T n
k then α ⃗t
⃗x is called a Tk-instance, for k = 0

138
4 Foundations of Logic Programming
also called a ground instance of ϕ. If U is a set of universal formulas,
let GI(U) denote the set of ground instances of all ϕ ∈U. Note that
GI(U) ̸= ∅for U ̸= ∅, provided L contains constants.
Theorem 1.1. Let U (⊆L) be a set of ∀-formulas and ˜U the set of all
instances of the formulas in U. Then the following are equivalent:
(i) U is consistent, (ii) ˜U is consistent, (iii) U has a term model in L.
The same holds if U ⊆Lk (in particular for sets U ⊆L0 of ∀-sentences),
where ˜U now denotes the set of all Tk-instances of the formulas in U.
Proof. (i)⇒(ii): Clear since U ⊢˜U. (ii)⇒(iii): Choose some maximally
consistent X ⊇˜U. Then FX ⊨π ⇔X ⊢π for prime formulas π, by (3).
Induction on ∧, ¬ easily yields FX ⊨α ⇔X ⊢α, for all open α. Since
X ⊇˜U we obtain FX ⊨˜U. But this yields FX ⊨U for the term model
F = FX according to (2). (iii)⇒(i): Trivial. For the case U ⊆Lk the
proof runs similarly using (3k), (2k), and Fk = FkX.
By Theorem 1.1, a consistent set U of universal sentences has a term
model F0. For our purposes, the important case is that U is ==== -free. Then
U has a model T on the set T0 of all ground terms, since F0X (that replaces
FX in the proof of Theorem 1.1 for k = 0) is then constructed without
a factorization of T0. Such a model T ⊨U is called a Herbrand model
(cf. also Exercise 1 in 3.2). Its domain T0 is called the Herbrand universe
of T. In general, U has many Herbrand models on the same domain T0
with the same canonical interpretation of constants and functions: cT = c
and fT(t1, . . . , tn) = f⃗t for all ⃗t ∈T n
0 . Only the relations may vary.
If U is a universal Horn theory (to be explained in 4.2), then U has a
distinguished Herbrand model, the minimal Herbrand model. It will be
deﬁned on page 142.
Example 2. Let U ⊆L{0, S, <} consist of the ==== -free universal sentences
(a) ∀x x < Sx,
(b) ∀x∀y∀z(x < y ∧y < z →x < z).
Here the Herbrand universe T0 consists of all ground terms n (= Sn0).
Obviously, N := (N, 0, S, <) ⊨˜U. Since SN t = St for each t ∈T0 (canon-
ical interpretation), N itself is then a Herbrand model. There are sever
other Herbrand models for U, since < may be interpreted in various ways
as will be seen in Example 3 in 4.2.
Remark 1. With Theorem 1.1 the problem of satisﬁability for X ⊆L can
basically be reduced to a propositional satisﬁability problem.
By Exercise 5

4.1 Term Models and Herbrand’s Theorem
139
in 2.6, X is—after adding new operation symbols—satisﬁably equivalent to a
set U of ∀-formulas which, by Theorem 1.1, is in turn satisﬁably equivalent to
the set of open formulas ˜U.
Now replace the prime formulas π occurring in
the formulas of ˜U with propositional variables pπ, distinct variables for distinct
prime formulas, as in 1.5. In this way one obtains a satisﬁably equivalent set of
propositional formulas. This works immediately on ==== -free sets of ∀-formulas.
By dealing with the congruence conditions for ==== (page 141), this method can
be generalized for sets of arbitrary ∀-formulas but is slightly more involved.
Although we will focus on a certain variant of the next theorem, its basic
concern (the construction of explicit solutions of existential assertions) is
the same in logic programming and related areas.
Theorem 1.2 (Herbrand’s theorem). Let U ⊆L be a set of univer-
sal formulas, ∃⃗xα ∈L, α open, and let ˜U be the set of all instances of
members from U. Then the following properties are equivalent:
(i)
U ⊢∃⃗xα,
(ii)
U ⊢
i⩽m α⃗t i
⃗x for some m and some ⃗t0, . . . , ⃗tm ∈T n,
(iii)
˜U ⊢
i⩽m α⃗t i
⃗x for some m and some ⃗t0, . . . , ⃗tm ∈T n.
The same holds if L is replaced here by Lk, T by Tk, and T n by T n
k , for
each k ⩾0, where ˜U is now the set of all Tk-instances.
Proof. Because U ⊢˜U, certainly (iii)⇒(ii)⇒(i). It remains to be shown
that (i)⇒(iii): According to (i), X = U ∪{∀⃗x¬α} is inconsistent; hence
also ˜U ∪{¬α ⃗t
⃗x | ⃗t ∈T n} by Theorem 1.1. Replacing here the prime
formulas with propositional variables as indicated in Remark 1 above,
(iii) follows already propositionally according to Exercise 1 in 1.4 (with
Y = {α tx | t ∈T }). The proof for Lk, Tk, and T n
k runs analogously.
Remark 2. Herbrand’s theorem was originally a proof-theoretic statement. It
has several versions. The theorem’s assumption that α is open is essential, as
can be seen from the example ⊢∃xα with α := ∀y(ry →rx) and U = ∅. Indeed,
⊢∃xα holds, for ∃xα is a tautology, Example 2 in 2.6. But there are no terms
t0, . . . , tm (variables in this case) such that ⊢
i⩽m α tix . The last formula can
be falsiﬁed in a model with n + 2 elements in its domain as is readily seen.
Exercises
1. Verify the conditions (1k), (2k), (3k) in detail.
2. Prove Herbrands theorem also for Lk instead of L.

140
4 Foundations of Logic Programming
4.2
Horn Formulas
We will deﬁne Horn formulas (after [Hor]) for a given language L recur-
sively. The following deﬁnition covers also the propositional case; simply
omit everything that refers to quantiﬁcation.
Deﬁnition. (a) Literals (i.e. prim formulas and their negations) are basic
Horn formulas. If α is prime and β a basic Horn formula, then α →β is a
basic Horn formula. (b) Basic Horn formulas are Horn formulas. If α, β
are Horn formulas then so too are (α ∧β), ∀xα, and ∃xα.
For instance, ∀y(ry →rx) and ∀x(y ∈x →x /∈y) are Horn formulas. Ac-
cording to our deﬁnition, α1 →· · · →αn →β (n ⩾0) is the general form
of a basic Horn formula, where α1, . . . , αn are prime and β is a literal.
Note that in the propositional case, the αi are propositional variables and
β is a propositional literal. We also call a formula a (basic) Horn formula
if it is equivalent to an original (basic) Horn formula. Thus, since
α1 →· · · →αn →β ≡β ∨¬α1 ∨· · · ∨¬αn
and by writing α0 for β in case β is prime, and β = ¬α0 if β is negated,
basic Horn formulas are up to logical equivalence of the type
I: α0 ∨¬α1 ∨· · · ∨¬αn
or
II: ¬α0 ∨¬α1 ∨· · · ∨¬αn
for prime formulas α0, . . . , αn. I and II are disjunctions of literals of which
at most one is a prime formula. Basic Horn formulas are often deﬁned in
this way. But our deﬁnition above has pleasant advantages in inductive
proofs as we shall see, for instance, in the proof of Theorem 2.1. Basic
Horn formulas of type I are called positive and those of type II negative.
A propositional Horn formula, i.e., a conjunction of propositional basic
Horn formulas, can always be conceived of as a CNF whose disjunctions
contain at most one nonnegated element. It is possible to think of an open
Horn formula of L as resulting from replacing the propositional variables
of some suitable propositional Horn formula by prime formulas of L.
Each Horn formula is equivalent to a prenex Horn formula. If its preﬁx
contains only ∀-quantiﬁers, then the formula is called a universal Horn
formula. If the kernel of a Horn formula ϕ in prenex form is a conjunction
of positive basic Horn formulas, ϕ is termed a positive Horn formula. Horn
formulas without free variables are called Horn sentences. The universal
Horn sentences in the following example are all positive.

4.2 Horn Formulas
141
Example 1. Identities and quasi-identities are universal Horn sentences,
as are transitivity (x ⩽y ∧y ⩽z →x ⩽z)g, reﬂexivity, and irreﬂexivity,
but not connexity (x ⩽y ∨y ⩽x)g. Also the congruence conditions for ====
are Horn sentences. Therein ⃗x==== ⃗y is to mean n
i=1 xi ==== yi:
(x==== x)g,
(x==== y ∧x==== z →y ==== z)g,
(⃗x==== ⃗y →r⃗x →r⃗y)g,
(⃗x==== ⃗y →f⃗x==== f⃗y )g.
∀x∃y x ◦y ==== e is a Horn sentence, while ∀x∃y(x ̸==== 0 →x · y ==== 0) is not,
and is even not equivalent to a Horn sentence in the theory TF of ﬁelds.
Otherwise Md TF would be closed under direct products; see Exercise 1.
This is not the case: Q × Q is a ring that has zero-divisors, for example
(1, 0) · (0, 1) = 0. Thus, Q × Q cannot be a ﬁeld.
A Horn theory is to mean a theory T with an axiom system of Horn
sentences. If these axioms are universal Horn sentences, then T is called
a universal Horn theory. Examples are the theories of groups in various
languages, of rings, and all equational and quasi-equational theories.
Theorem 2.1. Let U be a consistent set of universal Horn formulas in
a language L with term set T . Then F := FU is a model for U. In the
case U ⊆Lk, Fk := FkU is a model for U as well.
Proof. F ⊨U follows from (∗) : U ⊢α ⇒F ⊨α, for Horn formulas α.
(∗) is proved inductively on the construction of α in the deﬁnition of
Horn formulas. For prime formulas π, (∗) is clear, for then (3) reads as
	∗∗

: U ⊢π ⇔F ⊨π. Now suppose that U ⊢¬π. Then U ⊬π, for U is
consistent. Hence F ⊭π by
	∗∗

, and so F ⊨¬π. This conﬁrms (∗) for
all literals. Now let α be prime, β a basic Horn formula, U ⊢α →β, and
assume F ⊨α. Then U ⊢α; hence U ⊢β, and so F ⊨β by the induction
hypothesis. This proves F ⊨α →β. Induction on ∧is clear. Finally, let
U ⊢∀⃗xα for some open Horn formula α, and ⃗t ∈T n. Since then certainly
U ⊢α⃗t
⃗x, we get F ⊨α⃗t
⃗x by the induction hypothesis. ⃗t was arbitrary
and hence F ⊨∀⃗xα by (2) from 4.1. This proves (∗). The case U ⊆Lk
is treated analogously. Consider (2k), (3k) and take Fk for F.
Incidentally, U’s consistency in the theorem is always secured if U con-
sists of positive Horn formulas; Exercise 2. The most interesting case in
Theorem 2.1 is that U is the axiom system of a universal Horn theory.
Then FU ⊨T, and since U ⊆Lk for each k, also FkU ⊨T.

142
4 Foundations of Logic Programming
Example 2. Let T be the simple universal Horn theory from Example 1
in 4.1. That F ⊨T for the algebra F underlying FT was shown there
by proving that F is isomorphic to the word-semigroup on the alphabet
Var, while Theorem 2.1 yields F ⊨T directly. It is easily seen that F
is generated by v0, v1, . . . F is called the free semigroup with the free
generators v0, v1, . . . Also T =
==
=
G
is a universal Horn theory so that the free
group generated from v0, v1, . . . is deﬁned as well.
Remark 1. A universal Horn theory T is said to be nontrivial if ⊬T ∀xy x==== y.
The generators v0, v1, . . . of F are then distinct and FT is called the free model
of T with the free generators vi. The word “free” comes from the fact that if
M = (A, w) is any T-model, then the mapping x 
→xM (x ∈Var) generates
a homomorphism h: F 
→A; moreover, we can make “free use” of the values
hx of the free generators x, keeping A ﬁxed and choosing suitable valuations
in M = (A, w).
h is given by ht = tM.
Note that h is well deﬁned, for
t1 ==== t2 ⇒T ⊢t1 ==== t2 ⇒M ⊨t1 ==== t2 ⇒tM
1 ==== tM
2
⇒ht1 ==== ht2, and it is a
matter of routine to check the homomorphism conditions p. 50. E.g., if f is
n-ary then hf(t1, . . . , tn) = hft1 . . . tn = (f⃗t )M = f(⃗t M) = f(ht1, . . . , htn).
Similarly, FkT is the free model of T with the free generators v0, . . . , vk−1. We
will not make use of these remarks, made for the more advanced reader.
Let U ⊆L0 be as in Theorem 2.1 but ==== -free, and T be axiomatized by
U. Let F0U be well deﬁned, i.e. L contains constant symbols. Then F0U
is a Herbrand model for T, called the free or minimal Herbrand model
for T, and henceforth denoted by CU or CT . The domain of CU is the
set of ground terms. A not too simple example of describing the minimal
Herbrand model for a set U of =-free universal Horn sentences is
Example 3. Let U and N be as in Example 2 in 4.1. Both (a) and (b)
are universal Horn sentences. We determine the minimal Herbrand model
CU (whose domain consists of the terms n) by proving N ≃CU, with the
isomorphism n 
→n. Since CU ⊨m < k ⇔U ⊢m < k by the deﬁnition
page 136, it suﬃces to prove (∗): m < k ⇔U ⊢m < k. The direction ⇒
is shown by induction on k, beginning with k = Sm. The initial step is
clear since U ⊢m < Sm by (a). Let m < Sk. By the induction hypothesis
we then get U ⊢m < k, or m = k. In both cases, U ⊢m < Sk by (a) and
(b). The direction ⇐in (∗) is obvious because N is a model of U.
Remark 2. The set U in Example 2 in 4.1 has many models on the Herbrand
universe N. One may interpret < by any transitive relation on N that extends
<N, e.g., by ⩽N. This interpretation will be excluded by adding ∀x x ̸< x to U,
but the minimal Herbrand model remains the same if enlarging U this way.

4.3 Propositional Resolution
143
Most useful for logic programming is the following variant of Herbrand’s
theorem. The main diﬀerence is that for sets U of universal Horn formulas
we get a single solution γ ⃗t
⃗x whenever U ⊢∃⃗xγ. The theorem does also
hold with the same proof if k is dropped throughout.
Theorem 2.2. Let U ⊆Lk (k ⩾0) be a consistent set of universal Horn
formulas, γ = γ0 ∧· · · ∧γm, where all γi are prime, and ∃⃗xγ ∈Lk. Then
the following are equivalent:
(i) FkU ⊨∃⃗xγ,
(ii) U ⊢γ ⃗t
⃗x for some ⃗t ∈T n
k ,
(iii) U ⊢∃⃗xγ.
In particular, for a consistent universal Horn theory T of any ==== -free
language with constants, CT ⊨∃⃗xγ is always equivalent to ⊢T ∃⃗xγ.
Proof. (i)⇒(ii): Let FkU ⊨∃⃗xγ. Then FkU ⊨γ ⃗t
⃗x for some ⃗t , because
FkU ⊨¬γ ⃗t
⃗x for all ⃗t implies FkU ⊨∀⃗x¬γ by (2k), contradicting (i). Thus,
for all i ⩽m, FkU ⊨γi
⃗t
⃗x . Therefore U ⊢γi
⃗t
⃗x by (3k), and so U ⊢γ ⃗t
⃗x.
(ii)⇒(iii): Trivial. (iii)⇒(i): Theorem 2.1 states that FkU ⊨U. Hence
(iii) implies FkU ⊨∃⃗xγ. The particular case follows from (i)⇔(iii) when
we choose k = 0 and observe that CT = F0T by deﬁnition.
Exercises
1. Show that Md T for a Horn theory T is closed under direct products
(i.e. (∀i∈I)Ai ⊨T
⇒
i∈I Ai ⊨T), and if T is a universal Horn
theory, then also under substructures (A′ ⊆A ⊨T ⇒A′ ⊨T).
2. Prove that a set of positive Horn formulas is always consistent.
3. Prove CU ≃(N, 0, S, ⩽), where U consists of the universal Horn
sentences ∀x x ⩽x, ∀x x ⩽Sx, ∀x∀y∀z(x ⩽y ∧y ⩽z →x ⩽z).
4.3
Propositional Resolution
We recall the problem of quickly deciding the satisﬁability of propositional
formulas. This problem is of eminent practical importance, for many non-
numerical (sometimes called “logical”) problems can be reduced to this.
The truth table method, practical for formulas with few variables, grows
in terms of calculation eﬀort exponentially with the number of variables;
even the most powerful computers of the forseeable future will not be able

144
4 Foundations of Logic Programming
to carry out the table method for propositional formulas with just 100
variables. As a matter of fact, no essentially better procedure is known,
unless one is dealing with formulas of a particular shape, for instance with
certain normal forms. The general case represents an unsolved problem
of theoretic computer science, not discussed here, the so-called P=NP
problem; see for instance [GJ] or look for progress on the Internet.
For conjunctive normal forms, the optimal procedure for contempo-
rary computers is the resolution procedure introduced in the following.
For the sake of a sparing presentation one switches from a disjunction
λ1 ∨· · · ∨λn of literals λi to the set {λ1, . . . , λn}. In so doing, the order
of the disjuncts and their possible repetition, inessential factors for the
question of satisﬁability, are eliminated. For instance, λ1 ∨λ2 ∨λ1 is
equally represented by {λ1, λ2}.
A ﬁnite, possibly empty set of literals is called a (propositional) clause.
By a clause in p1, . . . , pn is meant a clause K with var K ⊆{p1, . . . , pn}.
In the following, K, H, G, L, P, N denote clauses and K, H, P, N sets of
clauses. K = {λ1, . . . , λn} corresponds to the formula λ1 ∨· · · ∨λn. The
empty clause (i.e., n = 0) is denoted by
. It corresponds to the empty
disjunction (which is ⊥, see the footnote page 13).
K = {q1, . . . , qm, ¬r1, . . . , ¬rk} (qi, rj ∈PV) is called a positive clause if
m > 0, for m = 1 also a deﬁnite, and for m = 0 a negative clause. These
conventions will also be adopted when the qi and ri later denote prime
formulas of a ﬁrst-order language.
Write w ⊨K (a propositional valuation w satisﬁes the clause K) if K
contains some λ with w ⊨λ. K is termed satisﬁable if there is some w
with w ⊨K. Note that the empty clause
, as the deﬁnition’s wording
suggests, is not satisﬁable. w is a model for a set K of clauses if w ⊨K for
all K ∈K. If K has a model then K is called satisﬁable. In contrast to
the empty clause
, the empty set of clauses is clearly satisﬁed by every
valuation, again by the deﬁnition’s wording.
w satisﬁes a CNF α iﬀw satisﬁes all its conjuncts, and hence all
of the clauses corresponding to these conjuncts.
Since every proposi-
tional formula can be transformed into a CNF, α is satisﬁably equiv-
alent to a corresponding ﬁnite set of clauses.
For instance, the CNF
(p ∨q) ∧(¬p ∨q ∨r) ∧(q ∨¬r) ∧(¬q ∨s) ∧¬s is satisﬁably equivalent to
the corresponding set of clauses {{p, q}, {¬p, q, r}, {q, ¬r}, {¬q, s}, {¬s}}.

4.3 Propositional Resolution
145
It will turn out later that this set is not satisﬁable. We write K ⊨H
if every model of K also satisﬁes the clause H.
A set of clauses K is
accordingly unsatisﬁable if and only if K ⊨
.
For λ /∈K we frequently denote the clause K ∪{λ} by K, λ. Moreover,
let ¯λ = ¬p for λ = p, ¯λ = p for λ = ¬p (hence ¯¯λ = λ in any case), and set
¯K = {¯λ | λ ∈K}. The resolution calculus operates with sets of clauses
and individual clauses, and has a single rule working with these objects,
the so-called resolution rule
RR:
K, λ L, ¯λ
K ∪L
(λ, ¯λ /∈K ∪L).
RR may be read as follows: If the clauses K, λ and L, ¯λ are derivable,
then also the clause K ∪L, called a resolvent of the clauses K, λ and L, ¯λ.
A clause H is said to be derivable from a set of clauses K, in symbols
K ⊢
RRH, if H can be obtained from K by the stepwise application of RR;
equivalently, if H belongs to the resolution closure RcK of K, which is
the smallest set of clauses H ⊇K closed with respect to applications of
RR. The deﬁnition of the resolution closure corresponds completely to the
deﬁnition of an MP-closed set of formulas in 1.6.
Example 1. Let K = {{p, ¬q}, {q, ¬p}}. Application of RR leads to the
resolvents {p, ¬p} and {q, ¬q}, from which we see that a pair of clauses
has several resolvents, in general. Every subsequent application of RR
yields already available clauses, so that RcK contains only the clauses
{p, ¬q}, {q, ¬p}, {p, ¬p}, and {q, ¬q}.
Applying RR to {p}, {¬p} yields the empty clause
. Hence K ⊢
RR
,
with the unsatiﬁable set of clauses K = {{p}, {¬p}}. By the resolution
theorem below, the derivability of the empty clause from a set of clauses
K is characteristic of the nonsatisﬁability of K. To test this one needs
only to check whether K ⊢
RR , i.e.,
∈RcK. This question is eﬀectively
decidable for ﬁnite sets K because then RcK is ﬁnite as well. Indeed, a
resolvent that results from applying RR to clauses in p1, . . . , pn contains
at most these very same variables. Further, there are only ﬁnitely many
clauses in p1, . . . , pn, exactly 22n. But that is still an exponential increase
as n increases. Aside from this, the mechanical implementation of the
resolution calculus mostly involves potentially inﬁnite sets of clauses. We
consider this problem more closely at the end of 4.6.

146
4 Foundations of Logic Programming
The derivation of a clause H from a set of clauses K, especially the
derivation of the empty clause, can best be graphically represented by a
resolution tree as in Example 2. This is a tree that branches “upward”
with an endpoint H without edge exits, called the root of the tree. Points
without entering edges are called leaves. A point that is not a leaf has
two entrances, and the points leading to them are called their predecessors.
The points of a resolution tree bear sets of clauses in the sense that a point
not being a leaf is a resolvent of the two clauses above it.
Example 2. The following ﬁgure shows one of the many resolution trees
for the already-mentioned collection of clauses
K0 = {{p, q}, {¬p, q, r}, {q, ¬r}, {¬q, s}, {¬s}}.
{¬q}
{¬q, s}
""""
"
{¬s}
{q}
T
T
T
{p, q}
{¬p, q}


T
T
TT
{¬p, q, r}




e
e
e



{q, ¬r}
The leaves of this tree are all
occupied by clauses in K0. It
should be clear that an ar-
bitrary clause H belongs to
the resolution closure of a set
of clauses K just when there
exists a resolution tree with
leaves in K and root H.
A
resolution tree with leaves in
K and the root
as shown
in the ﬁgure on the left for
K = K0 is called a resolution
for K, or more precisely, a successful resolution for K. Thus, because of
∈RcK0, the set of clauses K0 is unsatisﬁable, and hence so is the con-
junctive normal form that corresponds to the set K0, namely the formula
(p ∨q) ∧(¬p ∨q ∨r) ∧(q ∨¬r) ∧(¬q ∨s) ∧¬s.
Remark 1. If a resolution tree ends with a point ̸=
, either to which RR
cannot be applied or where upon application the points are simply reproduced,
then one talks of an unsuccessful resolution. In this case, most interpreters of the
resolution calculus will “backtrack,” which means the program searches backward
along the tree for the ﬁrst point where one of several resolution alternatives was
chosen, and picks up another alternative. Some kind of selection strategy must
in any case be implemented, since just as with any logical calculus, the resolution
calculus is nondeterministic, that is, no natural preferences exist regarding the
order of the derivations leading to a successful resolution, even if the existence
of such a resolution is known for other reasons.

4.3 Propositional Resolution
147
We remark that despite the derivability of the empty clause, for inﬁnite
unsatisﬁable sets of clauses K there also may exist inﬁnite resolution trees
with nonrepeating points, where
never appears. Such a tree has no root.
For example, the set of clauses
K = {{p1}, {¬p1}, {p1, ¬p2}, {p2, ¬p3}, . . . }
q
q
q
{¬p3}
p
{¬p2}
{p2, ¬p3}
J
J
J






J
J
J
{¬p1}
{p1, ¬p2}
is not satisﬁable. Here we obtain the inﬁnite re-
solution tree in the ﬁgure on the right, occupied
by leaves from K, which has no root and does
not reﬂect that
is derivable by just a single
application of RR to the ﬁrst two clauses of K.
In the diagram, the resolution calculus is run-
ning on K with a rather stupid strategy. This
and similar examples indicate that the resolu-
tion calculus is incapable in general of deciding
the satisﬁability of inﬁnite sets K of clauses. In-
deed, this will be conﬁrmed in 4.6. Nonetheless, by Theorem 3.2 below
there does exist—if K is in actual fact unsatisﬁable—a successful resolu-
tion for K that can in principle be found in ﬁnitely many steps.
We commence the more detailed study of the resolution calculus with
Lemma 3.1 (Soundness lemma). Let K be a set of clauses and K a
single clause. Then K ⊢
RRH ⇒K ⊨H.
Proof. As in the case of a Hilbert calculus, it suﬃces to conﬁrm the
soundness of the rule RR, that is, to prove that a model for K, λ and L, λ
is also one for K ∪L. Thus let w ⊨K, λ and w ⊨L, ¯λ. Case 1: w ⊭λ.
Then there must be a literal λ′ ∈K with w ⊨λ′. Hence w ⊨K and
therefore w ⊨K ∪L. Case 2: w ⊨λ. Then w ⊭¯λ. Similar to the above
we get w ⊨L. Hence w ⊨K ∪L as well.
For the case K ⊢
RR
the lemma shows K ⊨
, that is, the unsatisﬁability
of K. The converse of Lemma 3.1 is in general not valid; for instance
{{p}} ⊨{p, q}, but {{p}} ⊬
RR {p, q}. It does hold, though, for H =
.
This follows from Theorem 3.2 below, often stated as “K is unsatisﬁable
iﬀK ⊢
RR
.” In its proof we recursively construct a global valuation w
from partial valuations, deﬁned only for p1, . . . , pn.

148
4 Foundations of Logic Programming
Theorem 3.2 (Resolution theorem). K is satisﬁable iﬀK ⊬
RR .
Proof. Clearly K ⊭
if K is satisﬁable, so K ⊬
RR
by Lemma 3.1. Now let
K ⊬
RR , or equivalently,
/∈H with H := RcK. Let Λ(n) denote the set
of all literals in p1, . . . , pn, and H(n) be the set of all K ∈H with K ⊆Λ(n)
such that pn or ¬pn or both belong to K. Note that Λ(0) = H(0) = ∅,
var H(n) ⊆{p1, . . . , pn}, and H = 
n∈N H(n). We will construct a model
for H (hence for K) stepwise. vn := wpn will be deﬁned recursively on n
(more precisely, by naive course-of-value recursion, discussed e.g. in 6.1)
such that wn := (v1, . . . , vn) has the property (∗) : wn ⊨
i⩽n H(i).
We agree to say that the “empty valuation” satisﬁes H(0) = ∅, hence (∗)
holds trivially for n = 0. Let v1, . . . , vn be deﬁned so that (∗) is true.
We will deﬁne vn+1 = wpn+1 such that (+) : wn+1 ⊨H(n+1) is satisﬁed.
This clearly implies wn+1 ⊨
i⩽n+1 H(i), hence wn ⊨H(n) for all n, so
that w = (v1, v2, . . . ) is a model for the whole of H. In order to verify (+)
we need to consider only those K ∈H(n+1) containing no λ ∈Λ(n) with
wn ⊨λ and not both pn+1 and ¬pn+1. These K will be called sensitive
clauses during this proof, since every other K ∈H(n+1) either contains
some λ ∈Λ(n) with wn ⊨λ or else both pn+1 and ¬pn+1, and hence is
satisﬁed by any expansion of wn to wn+1.1 We may assume that there is
a sensitive K ∈H(n+1) (otherwise put vn+1 = 0) and prove the following
claim: Either pn+1 ∈K for all sensitive K—then put vn+1 = 1—or else
¬pn+1 ∈K for all sensitive K, in which case put vn+1 = 0, so that (+)
holds in either case. To prove this claim assume that there are sensitive
K, H ∈H(n+1) with pn+1 ∈K and ¬pn+1 ∈H, hence ¬pn+1 /∈K and
pn+1 /∈H. Applying RR to H, K, we then obtain either
(a contradiction
to
/∈H), or else a clause from H(i) for some i ⩽n whose literals are
not satisﬁed by wn, a contradiction to (∗), i.e. to wn ⊨H(i) for all i ⩽n.
This conﬁrms the claim and completes the proof.
Remark 2. The foregoing proof is constructive, that is, if K ⊬
RR
and the H(n)
in the proof above are computable, then a valuation satisfying K is computable
as well. Moreover, we incidentally proved the propositional compactness theorem
for countable sets of formulas X once again. Here is the argument: Every formula
is equivalent to some KNF, and hence X is satisﬁably equivalent to a set of
clauses KX. So if X is not satisﬁable, the same is true of KX. Consequently,
1 The newcomer should write down all eight candidates for the subset H(1) of
Λ(n) = {{p1}, {¬p1}, {p1, ¬p1}}. Only {p1} and {¬p1} are sensitive to v1 = wp1.

4.4 Horn Resolution
149
KX ⊢
RR
by Theorem 3.2. Therefore K0 ⊢
RR
for some ﬁnite subset K0 ⊆KX,
for there must be some successful resolution tree whose leaves are collected in
K0. Having this, it is obvious that just a ﬁnite subset of X is not satisﬁable,
namely the one that corresponds to the set of clauses K0.
4.4
Horn Resolution
A clause belonging to a propositional basic Horn formula is called a
(propositional) Horn clause. It is called positive or negative if the cor-
responding Horn formula is positive or negative. Positive Horn clauses
are of the form {¬q1, . . . , ¬qn, p} with n ⩾0, negative ones of the form
{¬q1, . . . , ¬qk}. The empty clause (k = 0) is counted among the negative
ones. It is important in practice that the resolution calculus can be for-
mulated more speciﬁcally for Horn clauses. The empty clause, if it can
be obtained from a set of Horn clauses at all, can also be obtained using
a restricted resolution rule, which is applied only to pairs of Horn clauses
in which one premise is positive (the left one in HR below) and the other
one is negative. This is the rule of Horn resolution
HR :
K, p | L, ¬p
K ∪L
(K, L negative, p, ¬p /∈K ∪L).
Nℓ+1
%
%%
Nℓ
e
e
e
Pℓ
q q qN2
%
%%
N1
e
e
e
P1
%
%%
N0
e
e
e
P0
The calculus operating with Horn
clauses and rule HR is denoted by ⊢
HR.
A positive Horn clause is clearly def-
inite.
Hence, the resolvent of an ap-
plication of HR is unique and always
negative. An H-resolution tree is there-
fore of the simple form illustrated by the
ﬁgure on the right. Therein P0, . . . , Pℓ
denote positive and N0, . . . , Nℓ+1 neg-
ative Horn clauses. Such a tree is also
called an H-resolution for P, N—where
P here and elsewhere is taken to mean a
set of positive Horn clauses and N is a negative clause ̸=
—if it satisﬁes
(1) Pi ∈P for all i ⩽ℓ, and (2) N0 = N & Nℓ+1 =
. It is evidently pos-
sible to regard an H-resolution for P, N simply as a sequence (Pi, Ni)i⩽ℓ
with the properties (0) Ni+1 = HR(Pi, Ni) for all i ⩽ℓ, (1), and (2).
Here HR(P, N) denotes the uniquely determined resolvent resulting from
applying HR to the positive clause P and the negative clause N.

150
4 Foundations of Logic Programming
Before proving the completeness of ⊢
HR we require a little preparation.
Let P be a set of positive Horn clauses. In order to gain an overview of
all models w of P, consider the natural correspondence
w ←→Vw := {p ∈PV | w ⊨p}
between valuations w and subsets of PV. Put w ⩽w′ : ⇔
Vw ⊆Vw′.
Clearly, P is always satisﬁed by the “maximal” valuation w with Vw = PV,
for w satisﬁes every positive clause and P contains only such clauses. It
is obvious that w ⊨P iﬀV = Vw satisﬁes the following two conditions:
(a) p ∈V provided {p} ∈P,
(b) q1, . . . , qn ∈V ⇒p ∈V , provided {¬q1, . . . , ¬qn, p} ∈P (n > 0).
Of all subsets V ⊆PV satisfying (a) and (b) there is clearly a smallest
one, namely VP := {Vw | w ⊨P}. Let wP be the P-model corresponding
to VP and call it the minimal P-model. We may deﬁne VP for the minimal
model wP of P also as follows: Put V0 = {p ∈PV | {p} ∈P} and
Vk+1 = Vk ∪

p ∈PV | {¬q1, . . . , ¬qn, p} ∈P for some q1, . . . , qn ∈Vk

.
Then VP = 
k∈N Vk. Indeed, Vk ⊆Vw for all k and all w ⊨P. Hence,

k∈N Vk ⊆VP. Also VP ⊆
k∈N Vk, since w ⊨P with Vw = 
k∈N Vk.
The minimal m with p ∈Vm is termed the P-rank of p, denoted by ρPp.
Those p with {p} ∈P are of P-rank 0. The variables arising from these
by applying (b) have P-rank 1 if not already in V0, and so on.
Lemma 4.1. Let P be a set of positive Horn clauses and q0, . . . , qk ∈VP.
Then P, N ⊢
HR
, where N = {¬q0, . . . , ¬qk}.
Proof. For r0, . . . , rn ∈VP set ρP(r0, . . . , rn) := max{ρPr0, . . . , ρPrn}. Let
μ(r0, . . . , rn) be the number of i ⩽n such that ρPri = ρP(r0, . . . , rn). The
claim is proved inductively on ρ := ρP(q0, . . . , qk) and μ := μ(q0, . . . , qk).
First suppose ρ = 0, i.e., {q0}, . . . , {qk} ∈P.
Then there is certainly
an H-resolution for P, N, namely the tree ({qi}, {¬qi, . . . , ¬qk})i⩽k. Now
take ρ > 0 and w.l.o.g. ρ = ρPq0.
Then there are qk+1, . . . , qm ∈VP
such that P := {¬qk+1, . . . , ¬qm, q0} ∈P and ρP(qk+1, . . . , qm) < ρ.
Thus, ρP(q1, . . . , qk, qk+1, . . . , qm) is either <ρ, or it is =ρ, in which case
μ(q1, . . . , qm) < μ. By the induction hypothesis, in both cases P, N1 ⊢
HR
for N1 := {¬q1, . . . , ¬qm}. Hence, an H-resolution (Pi, Ni)1⩽i⩽ℓfor P, N1
exists.
But then (Pi, Ni)i⩽ℓ, with P0 := P and N0 := N, is just an
H-resolution for P, N.

4.4 Horn Resolution
151
Theorem 4.2 (the H-Resolution theorem). A set K of Horn clauses
is satisﬁable iﬀK ⊬
HR
.
Proof. The condition K ⊬
HR
is certainly necessary if K is satisﬁable.
For the converse assume that K is unsatisﬁable, K = P ∪N, all P ∈P
are positive and all N ∈N negative. Since wP ⊨P but wP ⊭P ∪N
there is some N = {¬q0, . . . , ¬qk} ∈N such that wP ⊭N. Consequently,
wP ⊨q0, . . . , qk and therefore q0, . . . , qk ∈VP. By Lemma 4.1 we then
obtain P, N ⊢
HR
, and a fortiori K ⊢
HR
.
Corollary 4.3. Let K = P∪N be a set of Horn clauses, all P ∈P positive
and all N ∈N negative. Then the following conditions are equivalent:
(i) K is unsatisﬁable,
(ii) P, N is unsatisﬁable for some N ∈N.
Proof. (i) implies K ⊢
HR
by Theorem 4.2. Hence, there is some N ∈N
and some H-Resolution for P, N, whence P, N is unsatisﬁable. (ii)⇒(i) is
trivial because P, N is a subset of K.
Thus, the investigation of sets of Horn clauses as regards satisﬁability
can completely be reduced to the case of just a single negative clause.
The hitherto illustrated techniques can without further ado be carried
over to quantiﬁer-free formulas of a ﬁrst-order language L, in that one
thinks of the propositional variables to be replaced by prime formulas of
L. Clauses are then ﬁnite sets of literals in L. By Remark 1 in 4.1 a set of
L-formulas is satisﬁably equivalent to a set of open formulas, which w.l.o.g.
are given in conjunctive normal form. Splitting these into their conjuncts
provides a satisﬁably equivalent set of disjunctions of literals. Converting
these disjunctions into clauses, one obtains a set of clauses for which, by
the remark just cited, a consistency condition can be stated proposition-
ally. Now, because predicate-logical proofs are always reducible to the
demonstration of certain inconsistencies by virtue of the equivalence of
X ⊢α with the inconsistency of X, ¬α, these proofs can basically also be
carried out by resolution.
To sum up, resolution by Theorem 3.2 and 4.2 is not at all restricted
to propositional logic but includes application to sets of literals of ﬁrst-
order languages. Theorem 7.3, the predicate logic version of Theorem 3.2,
will essentially be reduced to the latter. Moreover, questions concerning
resolution in ﬁrst-order languages can basically be treated propositionally,
as indicated by the exercises below.

152
4 Foundations of Logic Programming
Before elaborating on this, we consider an additional aid to automated
proof procedures, namely uniﬁcation. This will later be combined with
resolution, and it is this combination that makes automated proof pro-
cedures fast enough for modern computers equipped with eﬃcient inter-
preters of PROLOG.
Exercises
1. Prove that the satisﬁable set of clauses P = {{p3}, {¬p3, p1, p2}}
does not have a smallest model. The 2nd clause in P is not a Horn
clause. Thus, in general only Horn clauses have a smallest model.
2. Let pm,n,k for m, n, k ∈N be propositional variables, S the successor
function, and P the set of all clauses belonging to the Horn formulas
pm,0,m ;
pm,n,k →pm,Sn,Sk
(m, n, k ∈N).2
Let the standard model ws be deﬁned by ws ⊨pm,n,k ⇔m+n = k.
Show that the minimal model wP coincides with ws.
3. Let P be the set of Horn clauses of Exercise 2. Prove that
(a) P, ¬pn,m,n+m ⊢
HR
,
(b) P, ¬pn,m,k ⊢
HR
⇒k = n + m.
(a) and (b) together are equivalent to the the single condition
(c) P, ¬pn,m,k ⊢
HR
⇔k = n + m.
4.5
Uniﬁcation
A decisive aid in logic programming is uniﬁcation. This notion is mean-
ingful for any set of formulas, but we conﬁne ourself to ¬-free clauses
K ̸=
of an identity-free language. K contains only unnegated prime
formulas, each starting with a relation symbol. Such a clause K is called
uniﬁable if a substitution σ exists, a so-called uniﬁer of K, such that
Kσ := {λσ | λ ∈K} contains exactly one element; in other words, Kσ is a
singleton. Here σ can most easily be understood as a simultaneous substi-
tution, that is, σ is globally deﬁned and xσ = x for almost all variables x.
2 In 4.6 these formulas will be interpreted as the ground instances of a logic program
for computing the sum of two natural numbers.

4.5 Uniﬁcation
153
Simultaneous substitutions form a semigroup with respect to composition,
with the neutral element ι, a fact we will heavily make use of.
Example 1. Consider K = {rxfxz, rfyzu}, r and f binary.
Here
ω = fyz
x
ffyzz
u
is a uniﬁer: Kω = {rfyzffyzz}, as is readily conﬁrmed.
Clearly, ω as a composition of simple substitutions can be understood as
a simultaneous substitution, see page 60.
Obviously, a clause containing prime formulas that start with distinct
relation symbols is not uniﬁable. A further obstacle to uniﬁcation is high-
lighted by
Example 2. Let K = {rx, rfx} (r, f unary). Assume (rx)σ = (rfx)σ.
This clearly implies rxσ = rfxσ and hence xσ = fxσ. This is impossible,
for xσ and fxσ are clearly of diﬀerent lengths. Hence, K is not uniﬁable.
If σ is a uniﬁer then so too is στ for any substitution τ.
Call ω a
generic or a most general uniﬁer of K if any other uniﬁer τ of K has a
representation τ = ωσ for some substitution σ. By Theorem 5.1 below,
each uniﬁable clause has a generic uniﬁer. For instance, it will turn out
below that ω in Example 1 is generic.
A renaming of variables, a renaming for short, is for the sake of simplic-
ity a substitution ρ such that ρ2 = ι. This deﬁnition could be rendered
more generally, but it suﬃces for our purposes. ρ is necessarily bijective
and maps variables to variables. Let x ρ
i = yi (̸= xi) for i = 1, . . . , n and
zρ = z otherwise. Then clearly y ρ
i = xi, that is, ρ swaps the variables xi
and yi. In this case we shall write ρ =
	x1···xn
y1···yn

.
If ω is a generic uniﬁer of K then so too is ω′ = ωρ, for any renaming
ρ. Indeed, for any given uniﬁer τ of K there is some σ such that τ = ωσ.
For σ′ := ρσ then τ = ωρ2σ = (ωρ)(ρσ) = ω′σ′. Choosing in Example 1
for instance ρ :=
	y z
u v

, we obtain the generic uniﬁer ω′ = ωρ for K, with
Kω′ = {rfuvffuvv}.
We now consider a procedure in the form of a ﬂow diagram, the uniﬁca-
tion algorithm, denoted by U. It checks each nonempty clause K of prime
formulas of an identity-free language for uniﬁability, and in the positive
case it produces a generic uniﬁer. U uses a variable σ for substitutions
with initial value ι, and a variable L for clauses with initial value K. Later
on, L contains Kσ for the actual value of σ that depends on the actual
state of the procedure. Here the diagram of U:

154
4 Foundations of Logic Programming
Input L := K. Do all α∈K
start with same symbol ?
no
no
yes
OUTPUT: K cannot be
uniﬁed
?yes
yes
no
yes
OUTPUT: K is uniﬁable
with generic uniﬁer σ
Choose α1 ̸= α2 from L and
determine the ﬁrst distinction
letters s1 in α1 and s2 in α2.
Is s1 or s2 a variable?
Let s1 = x ∈Var and t be
the subterm of α2 starting
with s2. Is x /∈var t ?

σ := σ tx
L := Kσ








#
"
 
!

-
Is L a singleton?




-
?

-
-
?
no
The ﬁrst distinction letters of two strings are the ﬁrst symbols from the
left that distinguish the strings. The ﬁrst letter of α ∈L is a relation
symbol.
By Exercise 1 in 2.2, any further symbol s in α determines
uniquely at each position of its occurrence a subterm of α whose initial
symbol is s. The diagram has just one (thick-lined) loop that starts and
ends in the test ‘Is L a singleton?’. The loop runs through the operation
σ := σ tx, L := Kσ, which assigns a new value to σ and then the new
value Kσ to L. This reduces the number of variables in L, since x /∈var L.
Hence, U necessarily leaves the loop after ﬁnitely many steps, and must
stop and halt in one of the two OUTPUT boxes of U. But we do not yet
know whether U always ends up in the “right” box, i.e., whether U answers
correctly. The ﬁnal value σ is printed in the lower OUTPUT box.
Example 3. Let U be executed on K from Example 1. The ﬁrst distinc-
tion letters of the two members α1, α2 ∈K are s1 = x and s2 = f at
the second position. The subterm beginning with s2 in α2 is t = fyz.
Hence, after the ﬁrst run through the loop with σ := ι fyz
x
= fyz
x
we get
Kσ = {rfyzffyzz, rfyzu}. Here the ﬁrst distinction letters are f and u
at position 5. The term beginning with f at this position is t = ffyzz.
Since u /∈var ffyzz, the loop is run through once again and we obtain
σ := σ ffyzz
u
= fyz
x
ffyzz
u
. This is a uniﬁer, and U comes to a halt with
OUTPUT ‘K is uniﬁable with the generic uniﬁer σ = fyz
x
ffyzz
u
’.
We recommend a thorough study of this example. That the σ at the
end of the example is indeed generic follows from

4.5 Uniﬁcation
155
Theorem 5.1. The uniﬁcation algorithm U is sound, i.e., upon input of
a negation-free clause K it always answers correctly.3
U uniﬁes with a
generic uniﬁer.
Proof. This is obvious if two elements of K are already distinguished
by the ﬁrst letter. Assume therefore that all α ∈K begin with the same
letter. If U stops with the output ‘K is uniﬁable . . . ’, K is in fact uniﬁable,
since it must have been previously veriﬁed that L = Kσ is a singleton.
Conversely, we claim that U also halts with the correct output, provided
K is uniﬁable. The latter will be our assumption till the end of the proof,
along with the choice of an arbitrary but ﬁxed uniﬁer τ of K.
It has to be conﬁrmed that both tests on the right side of the diagram
do not end with the upper OUTPUT, i.e., the test questions are answered
Yes.
For the upper test this is clear, since substitutions preserve the
symbols s1, s2 so that uniﬁcation would be impossible; this contradicts
our assumption. For the lower test (‘Is x /∈var t?’) the correctness of the
answer will be veriﬁed below. Let i (= 0, . . . , m) denote the moment after
the ith run through the loop has been ﬁnished. i = 0 before the ﬁrst run.
Put σ0 := ι and let σi for i > 0 be the value of σ after the ith run through
the loop. Below we shall prove that
(∗) there exists a substitution τi with σiτi = τ
(i = 0, . . . , m).
Assume that x ∈var t in the (i + 1)th run, with α1, α2 ∈Kσi chosen as
in the diagram. Choose τi according to (∗). Since σiτi = τ is a uniﬁer,
ατi
1 = ατi
2 . Hence
	∗∗

: xτi = tτi (the terms xτi and tτi start at the same
position and must be identical; see Exercise 1 in 2.2). But then x ∈var t
is impossible, since otherwise xτi and tτi were of diﬀerent length as in
Example 2. This conﬁrms the correctness of the diagram in the uniﬁable
case as claimed above. (∗) says in particular that σmτm = τ. Since τ
was arbitrary, and the σi do not depend on the choice of τ, it follows that
σ := σm is indeed a generic uniﬁer of K.
It remains to prove (∗) by induction on i ⩽m.
This is trivial for
i = 0: choose simply τ0 = τ, so that σ0τ0 = ιτ = τ. Suppose (∗) holds for
i < m. As was shown,
	∗∗

holds while running through the test ‘x /∈var t?’
3 The proof will be a paradigm for a so-called correctness proof of an algorithm. Such
a proof is often fairly lengthy and has almost always to be carried out inductively on
the number of runs through a loop occurring in the algorithm.

156
4 Foundations of Logic Programming
We set τi+1 :=
tx τi and claim that
tx τi+1 = τi. Indeed, for y ̸= x we
obtain y
tx τi+1 = yτi+1 = y
tx τi = yτi, but in view of xτi = tτi we have also
x
tx τi+1 = tτi+1 = t
tx τi
= tτi
(since x /∈var t)
= xτi.
tx τi+1 = τi and σi+1 = σi tx yield the induction claim
σi+1τi+1 = σi tx τi+1 = σiτi = τ.
This completes the proof.
Exercises
1. Let α, β be prime formulas without shared variables. Show that the
properties (i) and (ii) are equivalent:
(i) {α, β} is uniﬁable, (ii) there are substitutions σ, τ with ασ = βτ.
2. Show: σ = ⃗t
⃗x is idempotent (which is to mean σ2 = σ) if and only if
xi /∈var tj, for all i, j with 1 ⩽i, j ⩽n.
3. A renaming ρ is termed a separator of a pair of clauses K0, K1 if
var Kρ
0 ∩var K1 = ∅. Show that if K0 ∪K1 is uniﬁable then so is
Kρ
0 ∪K1, but not conversely, in general.
4. Assume s1, s2 /∈Var for the ﬁrst distinction letters s1, s2 of the
clauses K1 ̸= K2. Show rigorously that {K1, K2} is not uniﬁable.
4.6
Logic Programming
A rather general starting point in dealing with systems of artiﬁcial intel-
ligence consists in using computers to draw consequences ϕ from certain
data and facts given in the form of a set of formulas X, that is, proving
X ⊢ϕ mechanically. That this is possible in theory was the subject of
3.5. In practice, however, such a project is in general realizable only under
certain limitations regarding the pattern of the formulas in X, ϕ. These
limitations refer to any ﬁrst-order language L adapted to the needs of a
particular investigation. For logic programming the following restrictions
on the set X and the formula ϕ are characteristic:

4.6 Logic Programming
157
• L is identity-free and contains at least one constant symbol,
• each α ∈X is a positive universal Horn sentence,
• ϕ is a sentence of the form ∃⃗x(γ0 ∧· · · ∧γk) with prime formulas γi.
Note that ¬ϕ is equivalent to ∀⃗x(¬γ0 ∨· · · ∨¬γk) and hence a negative
universal Horn sentence. Because ∀-quantiﬁers can be distributed among
conjunctions, we may assume that each α ∈X is of the form
(∗)
(β1 ∧· · · ∧βm →β)g
(β, β1, . . . , βm prime formulas, m ⩾0).
A ﬁnite set of sentences of this type is called a logic program and will
henceforth be denoted by P. The availability of a constant symbol just
ensures the existence of a Herbrand model for P. In the programming
language PROLOG, (∗) is formally written without quantiﬁers as follows
and called a program clause:
β :−β1, . . . , βm
(or just β :−in case m = 0).
:−symbolizes converse implication mentioned in 1.1. For m = 0 such
program clauses are called facts, and for m > 0 rules. In the sequel we
make no distinction between a logic program P as a set of formulas and
its transcript in PROLOG. The sentence ϕ = ∃⃗x(γ0 ∧· · · ∧γk) in the last
bulleted item above is also called a query to P. In PROLOG, ¬ϕ is mostly
denoted by :−γ0, . . . , γk.4 ∃⃗x may be empty. This notation comes from
the logical equivalence of the kernel of ¬ϕ (≡∀⃗x(¬γ0 ∨· · · ∨¬γk)) to
the converse implication ⊥←γ0 ∧· · · ∧γk, omitting the writing of ⊥.
Using rules one not only proceeds from given facts to new facts but may
also arrive at answers to queries. The restriction as regards the abstinence
from ==== is not really essential. This will become clear in Examples 1 and
4 and in the considerations of this section. Whenever required, ==== can
be treated as an additional binary relation symbol by adjoining the Horn
sentences from Example 1 in 4.2.
Program clauses and negated queries can equally well be written as
Horn clauses: β :−β0, . . . , βm as {¬β1, . . . , ¬βn, β}, and :−γ0, . . . , γk as
{¬γ0, . . . , ¬γk}. For a logic program P, let P denote the corresponding
4 Sometimes also ?−γ0, . . . , γk. Like many programming languages, PROLOG also has
numerous “dialects.” We shall therefore not consistently stick to a particular syntax.
We also disregard many details, for instance that variables always begin with capital
letters and that PROLOG recognizes certain unchanging predicates like read, . . . , to
provide a convenient user interface.

158
4 Foundations of Logic Programming
set of positive Horn clauses. P and P can almost always be identiﬁed.
To justify this semantically, let A ⊨K for a given L-structure A and
K = {λ0, . . . , λk} simply mean A ⊨
i⩽k λi, which is clearly equivalent
to A ⊨(
i⩽k λi)g. Note that A ⊭
, since
corresponds to the formula
⊥. For L-models M, let M ⊨K have its ordinary meaning M ⊨
i⩽k λi.
If A ⊨K for all K ∈K, then A is called a model for a given set K of
clauses, and K is called satisﬁable or consistent if such an A exists. This is
clearly equivalent to the consistency of the set of sentences corresponding
to K. Further, let K ⊨H if every model for K also satisﬁes H. Evidently
K ⊨Kσ for K ∈K and arbitrary substitutions σ, since A ⊨K ⇒A ⊨Kσ.
The clause Kσ is also termed an instance of K, in particular a ground
instance whenever Kσ contains no variables.
A logic program P, considered as a set of positive Horn formulas, is
always consistent. All facts and rules of P are valid in the minimal Her-
brand model CP.
This model should be thought of as the model of a
domain of objects about which one wishes to express properties by means
of P. A logic program P is always written such that a real situation is
modeled as precisely as possible by the minimal Herbrand model CP.
Suppose that P ⊢∃⃗xγ, where γ is a conjunction of prime formulas as
at the beginning, i.e., ∃⃗xγ is a query. Then a central goal of logic pro-
gramming is to gain “solutions” of P ⊢∃⃗xγ in CP, which by Theorem 2.2
always exist. Here γ ⃗t
⃗x is called a solution of P ⊢∃⃗xγ whenever P ⊢γ ⃗t
⃗x.
One also speaks of the solution ⃗x := ⃗t , or an answer to the query :−γ.
Logic programming follows the strategy of proving P ⊢ϕ for a query
ϕ by establishing the inconsistency of P, ¬ϕ.
To verify this we know
from Theorem 1.1 that an inconsistency proof of GI(P, ¬ϕ) suﬃces. The
resolution theorem shows that for this proof in turn, it suﬃces to derive the
empty clause from the set of clauses GI(P, N) corresponding to GI(P, ¬ϕ).
Here GI(K) generally denotes the set of all ground instances of members
of a set K of clauses, and N = {¬γ1, . . . , ¬γn} is the negative clause
corresponding to the query ϕ, the so-called goal clause.
As a matter of fact, we proceed somewhat more artfully and work not
only with ground instances but also with arbitrary instances. Nor does the
search for resolutions take place coincidentally or arbitrarily, but rather
with the most sparing use of substitutions possible for the purpose of
uniﬁcation. Before the general formulation of Theorem 6.2, we exhibit

4.6 Logic Programming
159
this method of “uniﬁed resolution” by means of two easy examples. In the
ﬁrst of these, sum denotes the ternary relation graph+ in N.
Example 1. Consider the following program P = P+ in L{0, S, sum}:
∀xsum x0x
;
∀x∀y∀z(sum xyz →sum xSySz).
In PROLOG one may write this program somewhat more brieﬂy as
sum x0x :−
;
sum xSySz :−sum xyz.
The ﬁrst program clause is a “fact,” the second one is a “rule.” The set of
Horn clauses that belongs to P is
P = {{sum x0x}, {¬sum xyz, sum xSySz}}.
P describes sum = graph+ in N together with 0, S; more precisely,
CP ≃N := (N, 0, S, sum ),
that is, CP ⊨sum m n k ⇔N ⊨sum m n k (⇔m + n = k).
This is
deduced in Example 3 on page 164, but more directly from Exercise 2
in 4.3. By replacing therein pm,n,k with sum m n k, the formulas of this
exercise correspond precisely to the ground instances of P+.
Examples of queries to P are ∃u∃vsum u1v and ∃usum uu6. Another
example is sum n 2 n + 2 (here the ∃-preﬁx is empty). For each of these
three queries ϕ, clearly CP ⊨ϕ holds. Hence, P ⊢ϕ by the last part of
Theorem 2.2. But how can this be conﬁrmed by a computer?
As an illustration, let ϕ := ∃u∃vsum u1v. Since P ⊢sum n, Sn we know
that (u, v) := (n, Sn) is a solution of
(∗)
P ⊢∃u∃vsum u1v.
We will show that P ⊢sum x1Sx, where x occurs free in the last for-
mula, is the general solution of (∗). The inconsistency proof of P, ¬ϕ
results by deriving
from suitable instances of P, N that will be con-
structed by certain substitutions. N := {¬sum u1v} is the goal clause
corresponding to ϕ.
The resolution rule is not directly applicable to
P, N. But with ω0 := ux 0y Sz
v it is applicable to P ω0, Nω0, with the Horn
clause P := {¬sum xyz, sum xSySz} ∈P. Indeed, one easily conﬁrms that
P ω0 = {¬sum u0z, sum u1Sz} and N ω0 = {¬sum u1Sz}. The resolvent of
the pair of Horn clauses P ω0, Nω0 is N1 := {¬sum u0z}. This can be
stated as follows: Resolution is becoming possible thanks to the uniﬁa-
bility of the clause {sum xSySz, sum u1v}, where sum xSySz belongs to P

160
4 Foundations of Logic Programming
and ¬sum u1v to N. But we have still to continue to try to get the empty
clause. Let P1 := {sum x0x} ∈P. Then P1, N1 can be brought to reso-
lution by uniﬁcation with ω1 := xu xz . For notice that P ω1
1
= {sum x0x}
and N ω1
1
= {¬sum x0x}. Now simply apply RR to this pair of clauses
""""
¬sum u0z
b
b
b
b
sum x0x
ω1 = xu xz
""""
¬sum u1v
b
b
b
b
¬sum xyz, sum xSySz
ω0 = ux 0y Sz
v
to obtain
. The diagram
on the left makes this kind
of a description more in-
tuitive. Note that the set
braces of the clauses have
been omitted in the dia-
gram. This resolution can
certainly be produced by
a computer; what the computer has to do is just to look for appropriate
uniﬁers for pairs of clauses. In this way, (∗) is proved by Theorem 6.2(a)
below. At the same time, by Theorem 6.2(b), applied to the resolution
represented by the above diagram, we obtain a solution of (∗), namely
(sum u1v)ω0 ω1 = sum x1Sx. This solution is an example of a most gen-
eral solution of (∗), because by substitution we obtain from sum x1Sx all
individual solutions, namely the sentences sum n 1 Sn.
Example 2. The logic program P = {∀x(hu x →mt x), hu Socr}, written
hu Socr ; mt x :−hu x in PROLOG, formalizes the two premises of the old
classical Aristotelian syllogism
All humans are mortal; Socrates is a human. Hence, Socrates is mortal.
""""
¬hu x
b
b
b
b
hu Socr
σ= Socr
x
""""
¬mt x
b
b
b
b
¬hu x, mt x
Here CP is just the single-
point model {Socr}, since
Socr is the only constant
and no functions occur.
The ﬁgure on the right
shows a resolution of the
query : −mt x (in words,
“Is there a mortal x in the Herbrand model CP?”), with the solution
x := Socr. The familiar logic argument runs as follows: ∀x(hu x →mt x)
implies hu Socr →mt Socr by speciﬁcation of x. Thus, since hu Socr, MP
yields mt Socr. We learn from this example among other things that proofs
using MP can also be gained by resolution.

4.6 Logic Programming
161
Of course, the above examples are far too simple to display the eﬃciency
of logic programming in practice. Here we are interested only in illustrat-
ing the methods, which are essentially a combination of resolution and
uniﬁcation. Clearly, these methods concern basically the implementation
of PROLOG and may be less interesting to the programmer who cares
in the ﬁrst line about successful programming, whereas the logician cares
about the theory behind logical programming.
Following these preliminary considerations we will now generalize our
examples and start with the following deﬁnition of the rules UR and UHR
of uniﬁed resolution and uniﬁed Horn resolution, respectively. Therein,
K0, K1 denote clauses and ω a substitution.
Deﬁnition Let UωR(K0, K1) be the set of all clauses K such that there
are clauses H0, H1 and negation-free clauses G0, G1 ̸=
such that after a
possible swapping of the indices 0, 1,
(a) K0 = H0 ∪G0 and K1 = H1 ∪G1
(G1 = {λ | λ ∈G1}),
(b) ω is a (w.l.o.g. generic) uniﬁer of G0 ∪G1 and K = H ω
0 ∪H ω
1 .
K is called a U-resolvent of K0, K1 or an application of the rule UR to
K0, K1 if K ∈UωR(Kρ
0, K1) for some ω and some separator ρ of K0, K1.
The restriction of UR to Horn clauses K0, K1 (K0 positive, K1 negative)
is denoted by UHR and UωR(K0, K1) by UωHR(K0, K1). The resolvent
K is then termed a UH-resolvent of K0, K1.
This deﬁnition becomes more lucid by some additional explanations.
According to (b), Gω
0 = {π} = Gω
1 for some prime formula π. Hence K
results from applying standard resolution on suitable premises. Applying
UR or UHR to K0, K1 always includes a choice of ω and ρ (ρ may enlarge
the set of resolvents, see Exercise 3 in 4.5). In the examples we used UHR.
In the ﬁrst resolution step of Example 1 is ¬sum u0z ∈Uω0HR(P ρ, N)
(with ρ = ι).
The splitting of K0 and K1 according (a) above reads
H0 = {¬sum xyz}, G0 = {sum xSySz}, and H1 = ∅, G1 = {sum u1v}.
UHR was used again in the second resolution step, as well as in Example 2,
strictly following the instruction of the above deﬁnition.
We write K ⊢
URH if H is derivable from the set of clauses K using UR.
Accordingly, let K ⊢
UHR H be deﬁned for sets of Horn clauses K, where
only UHR is used. As in 4.3, derivations in ⊢
UR or ⊢
UHR can be visualized
by means of trees. A (successful) U-Resolution for K is just a U-resolution

162
4 Foundations of Logic Programming
tree with leaves in K and the root
, where the applied substitutions are
tied to the resolution nodes as in the diagram below.
A UH-resolution is deﬁned similarly; it may as well be regarded as
a sequence (P ρi
i , Ni, ωi)i⩽ℓwith Ni+1 ∈UωiHR(P ρi
i , Ni) for i < ℓand
∈UωℓHR(P ρℓ
ℓ, Nℓ). If P is a set of positive clauses and N a negative
clause, and if further Pi ∈P holds for all i ⩽ℓand N0 = N, one speaks of
a UH-resolution for P, N. In general, P consists of the clauses of some logic
%
%%
Nℓ
e
e
e
P ρℓ
ℓ
ωℓ
q q qN2
%
%%
ω1
N1
e
e
e
P ρ1
1
%
%%
N0
ω0
e
e
e
P ρ0
0
program and N is any given
goal clause. In place of UH-
resolution one may also speak
of SLD-resolution (Linear re-
solution with Selection func-
tion for Deﬁnite clauses).
This name has nothing to
do with some special strat-
egy for searching a success-
ful resolution, implemented
in PROLOG. For details on
this matter see for instance
[Ll].
The diagram illustrates a UH-resolution (P ρi
i , Ni, ωi)i⩽ℓfor P, N.
It generalizes the diagrams in Examples 1 and 2, which represent partic-
ularly simple examples of UH-resolutions.
First of all we prove the soundness of the calculus ⊢
UR in Lemma 6.1.
This clearly covers also the calculus ⊢
UHR of uniﬁed Horn resolution, where
one has to do with special clauses only.
Lemma 6.1 (Soundness lemma). K ⊢
UR H implies K ⊨H.
Proof. It suﬃces to show that K0, K1 ⊨H if H is a U-resolvent of K0, K1.
Let H ∈UωR(Kρ
0, K1), Kρ
0 = H0 ∪G0, K1 = H1 ∪G1, Gω
0 = {π} = Gω
1 ,
H = Hρω
0 ∪Hω
1 , and A ⊨K0, K1. Then A ⊨Kρω
0 , Kω
1 as well. Further, let
w: Var →A, with M := (A, w) ⊨Kρω
0
= Hρω
0
∪{π}, M ⊨Hω
1 ∪{¬π}.
If M ⊭π then evidently M ⊨Hρω
0 . Otherwise M ⊭¬π, hence M ⊨Hω
1 .
So M ⊨Hω
0 ∪Hω
1 = H in any case. This states that A ⊨H, because w
was arbitrary.
With respect to the calculus ⊢
UHR this lemma serves the proof of (a) in

4.6 Logic Programming
163
Theorem 6.2 (Main theorem of logic programming). Let P be a
logic program, ∃⃗xγ a query, γ = γ0 ∧· · · ∧γk, and N = {¬γ0, . . . , ¬γk}.
Then the following hold:
(a) P ⊢∃⃗xγ iﬀP, N ⊢
UHR
(Adequacy).
(b) If (P ρi
i , Ni, ωi)i⩽ℓis a UH-resolution for P, N and ω := ω0 · · · ωℓ,
then P ⊢γω
(Solution soundness).
(c) Suppose that P ⊢γ ⃗t
⃗x (⃗t ∈T n
0 ). Then there is some UH-resolution
(Kρi
i , Ni, ωi)i⩽ℓand some σ such that x ωσ
i
= ti for i = 1, . . . , n,
where ω = ω0 · · · ωℓ
(Solution completeness).
The proof of this theorem is undertaken in 4.7. It has a highly technical
character and uses a substantial amount of substitutions. Here are just a
few comments. In view of ¬∃⃗xγ ≡∀⃗x¬γ it is clear that
(∗)
P ⊢∃⃗xγ
is equivalent to the inconsistency of P, ∀⃗x¬γ, hence also to that of the
corresponding set of Horn clauses P, N. Theorem 6.2(a) states that this
is equivalent to P, N ⊢
UHR
, which is not obvious. (b) tells us how to
achieve a solution of (∗) by a successful resolution. Since γω in (b) may
still contain free variables (like (sum u1v)ω for ω = ω1ω2 in Example 1)
and since P ⊢γω ⇒P ⊢γωτ for any τ, we often obtain whole families of
solutions of (∗) in the Herbrand model CP by substituting ground terms.
By (c), all solutions in CP are gained in this way, though not always with
a single generic resolution as in Example 1. However, the theorem makes
no claim as to whether and under what circumstances (∗) is solvable.
Logic programming is also expedient for purely theoretical purposes.
For instance, it can be used to make the notion of computable functions
on N entirely precise. The deﬁnition below provides just one of several
similarly styled, intuitively illuminating possibilities. We will construct
an undecidable problem in Theorem 6.3 below that explains the principal
diﬃculties surrounding a general answer to the question P ⊢∃⃗xγ. Because
in 6.1 computable functions are equated with recursive functions, we keep
things fairly brief here.
Deﬁnition. f : Nn →N is called computable if there is a logic program Pf
in a language that, in addition to 0 and S, contains only relation symbols,
including an (n+1)-ary relation symbol denoted by rf (to mean graph f),
such that for all ⃗k = (k1, . . . , kn) and m the following is satisﬁed:

164
4 Foundations of Logic Programming
(1)
Pf ⊢rf⃗k m ⇔f⃗k = m
	⃗k = (k1, . . . , kn)

.5
A function f : Nn →N satisfying (1) is certainly computable in the
intuitive sense: a deduction machine is set to list all formulas provable
from Pf, and one simply has to wait until a sentence r⃗k m appears. Then
the value m = f⃗k is computed. By Theorem 6.2(a), the left-hand side
of (1) is for P = Pf equivalent to P, {¬r⃗k m} ⊢
UHR
. Therefore, f is
basically also computable with the Horn resolution calculus.
The domain of the Herbrand model CPf is N, and by Theorem 2.2,
Pf ⊢rf⃗k m ⇔CPf ⊨rf⃗k m,
so that (1) holds when just the following claim has been proved:
(2)
CPf ⊨rf⃗k m ⇔f⃗k = m, for all ⃗k, m.
Example 3. P+ in Example 1 computes +, more precisely graph+, since
CP+ ⊨sum k n m ⇔k +n = m was shown there. So (2) holds and hence
also (1). A logic program P× for computing prd := graph · arises from
P+ by expanding the language to L{0, S, sum, prd } and adding to P+ the
program clauses prd x00 :−and prd xSyu :−prd xyz, sum zxu. Here we
see that besides the graph of the target function some additional relations
may be involved in the function’s computation.
Example 4. The program PS in L{0, S, rS }, containing only rS xSx :−,
computes the graph rS of the successor function. Clearly, PS ⊢rS nSn,
since PS, {¬rS nSn} ⊢
UHR
(
is a resolvent of {rS xSx}σ and {¬rS nSn}σ,
where σ equals Sn0
x ). Let m ̸= Sn. Then (N, 0, S, graph S) ⊨PS, ¬rS n m.
Hence, PS ⊬rS n m. This conﬁrms (1).
It is not diﬃcult to recognize that each recursive function f can be
computed by a logic program Pf in the above sense in a language that
in addition to some relation symbols contains only the operation symbols
0, S. Exercises 1, 2, and 3 provide the main steps in the proof, which
proceeds by induction on the generating operations Oc, Op, and Oμ of
recursive functions from 6.1. Example 4 conﬁrms the induction initiation
for the initial primitive recursive function S. The interested reader should
study 6.1 to some extent in order to understand what is going on.
5 By grounding computability in diﬀerent terms one could f provisionally call LP-
computable. Our deﬁnition is related to the Herbrand–Gödel deﬁnition of computable
functions but we will not step into further details in this respect.

4.6 Logic Programming
165
Thus, the concept of logic programming is very comprehensive.
On
the other hand, this has the consequence that the question P ⊢∃⃗xγ is,
in general, not eﬀectively decidable.
Indeed, this undecidability is the
assertion of our next theorem.
Theorem 6.3. A logic program P exists whose signature contains at least
a binary relation symbol r, but no operation symbols other than 0, S, such
that no algorithm answers the question P ⊢∃x rxk for each k.
Proof. Let f : N →N be recursive, but ran f = {m ∈N | ∃kfk = m} not
recursive. Such a function f exists; see Exercise 5 in 6.5. Then we get
for P := Pf from the deﬁnition page 163,
P ⊢∃x rxm ⇔CP ⊨∃x rxm
(Theorem 2.2, r means rf)
⇔CP ⊨rk m for some k
(CP has the domain N)
⇔fk = m for some k
	
by (2)

⇔m ∈ran f.
Thus, if the question P ⊢∃x rxm were decidable then so too would be the
question m ∈ran f, and this is a contradiction to the choice of f.
Exercises
1. Let g: Nn →N and h: Nn+2 →N be computable by means of the
logic programs Pg and Ph, and let f : Nn+1 →N arise from g, h by
primitive recursion. This is to mean that
f(⃗a, 0) = g⃗a and f(⃗a, k + 1) = h(⃗a, k, f(⃗a, k)) for all ⃗a ∈Nn.
Provide a logic program for computing (the graph of) f.
2. Let Ph and Pgi be logic programs for computing h: Nm →N and
gi : Nn →N (i = 1, . . . , m). Further, let the function f be deﬁned
by f⃗a = h(g1⃗a, . . . , gm⃗a) for all ⃗a ∈Nn. Give a logic program for
computing f.
3. Let g: Nn+1 →N and Pgi be logic program for computing g. Further
assume that to each ⃗a ∈Nn there is some b ∈N with g(⃗a, b) = 0 and
let h⃗a for ⃗a ∈Nn be the smallest m such that g(⃗a, m) = 0. Give a
logic program for computing h: Nn →N.
These exercises and the examples show that the LP-computable
functions coincide with the general recursive functions.

166
4 Foundations of Logic Programming
4.7
A Proof of the Main Theorem
While we actually require the following lemmas and Theorem 7.3 below
only for the uniﬁed Horn resolution, the proofs are carried out here for the
more general U-resolution. These proofs are not essentially more diﬃcult.
As a matter of fact, the only diﬃculty in the proofs is the handling of
substitutions. The calculi ⊢
RRand ⊢
HR from 4.3 now operate with variable-
free clauses of a ﬁxed identity-free ﬁrst-order language with at least one
constant. The presence of constants assures that variable-free clauses are
available. ρ, σ, τ denote simultaneous substitutions throughout.
Lemma 7.1. Let K0, K1 be clauses with separator ρ and let Kσ0
0 , Kσ1
1
be
variable-free. Suppose that K is a resolvent of Kσ0
0 , Kσ1
1 . Then there are
substitutions ω, τ and some H ∈UωR(Kρ
0, K1) such that Hτ = K, i.e., K
is a ground instance of some U-resolvent of K0, K1. Further, for a given
ﬁnite set V of variables, ω, τ can be selected in such a way that xωτ = xσ1
for all x ∈V . The same holds for Horn resolution.
Proof. Suppose w.l.o.g. that Kσ0
0
= L0, π and Kσ1
1
= L1, ¬π for some
prime formula π, and K = L0 ∪L1. Put Hi := {α ∈Ki | ασi ∈Li},
G0 := {α ∈K0 | ασ0 = π}, and G1 := {β ∈K1 | βσ1 = π}, i = 0, 1.
Then K0 = H0 ∪G0, K1 = H1 ∪G1, Hσi
i
= Li, Gσi
i
= {π}. Let ρ be a
separator of K0, K1 and deﬁne σ by xσ = xρσ0 in case x ∈var Kρ
0, and
xσ = xσ1 else, so that e.g. Kσ
1 = Kσ1
1 . Note that also ρσ = ρρσ0 = σ0,
hence Kρσ
0
= Kσ0
0 . Therefore (Gρ
0 ∪G1)σ = Gρσ
0 ∪Gσ
1 = Gσ0
0 ∪Gσ1
1 = {π},
that is, σ uniﬁes Gρ
0 ∪G1. Let ω be a generic uniﬁer of this clause, so
that σ = ωτ for suitable τ. Then H := Hρω
0
∪Hω
1 ∈UωR(Kρ
0, K1) by
deﬁnition of the rule UR, and Hρσ
0
= Hσ0
0 , Hσ
1 = Hσ1
1
yield the desired
Hτ = Hρωτ
0
∪Hωτ
1
= Hρσ
0
∪Hσ
1 = Hσ0
0 ∪Hσ1
1
= L0 ∪L1 = K.
The second part of our lemma is easily conﬁrmed. Since V is ﬁnite, ρ can
clearly be chosen such that V ∩var Kρ
0 = ∅, hence xσ = xσ1 for all x ∈V .
By deﬁnition of σ and in view of ωτ = σ it then obviously follows that
xωτ = xσ1 whenever x ∈V .
The next lemma claims that if the
is derivable from GI(K) with
resolution only (i.e., without uniﬁcation and separation), then
is also
directly derivable from K in the calculi ⊢
UR and ⊢
UHR, respectively.

4.7 A Proof of the Main Theorem
167
Lemma 7.2 (Lifting lemma). Suppose that GI(K) ⊢
RR
for some set of
clauses K. Then K ⊢
UR
. And if K consists of Horn clauses only, then
also K ⊢
UHR
.
Proof. We shall verify the more general claim
(∗) If GI(K) ⊢
RRK then K ⊢
UR H and K = Hτ for some H and τ.
For K =
, (∗) is our claim since
τ =
. (∗) follows straightforwardly
by induction on GI(K) ⊢
RRK. It is trivial for K ∈GI(K), by deﬁnition of
GI(K). For the inductive step let GI(K) ⊢
RRKσ0
0 , Kσ1
1 , with K0, K1 ∈K
for suitable σ0, σ1 according to the induction hypotheses, and let K be
a resolvent of Kσ0
0 , Kσ1
1 . That then H ∈UωR(Kρ
0, K1) and K = Hτ for
suitable H, ω, τ is exactly the ﬁrst claim of Lemma 7.1. This proves (∗).
The case for Horn clauses is completely similar.
Theorem 7.3 (U-Resolution theorem). A set of clauses K is incon-
sistent iﬀK ⊢
UR
; a set of Horn clauses K is inconsistent iﬀK ⊢
UHR
.
Proof. If K ⊢
UR
then K ⊨
by Lemma 6.1; hence K is inconsistent.
Suppose now the latter, so that the set U of ∀-sentences corresponding
to K is inconsistent as well.
Then GI(U) is inconsistent according to
Theorem 1.1; hence GI(K) as well. Thus, GI(K) ⊢
RR
by Theorem 3.2
and so K ⊢
UR
by the Lifting lemma. For sets of Horn clauses the proof
runs analogously, using Theorem 4.2 instead of Theorem 3.2.
Proof of Theorem 6.2. (a): P ⊢∃⃗xγ is equivalent to the inconsis-
tency of P, ∀⃗x¬γ or of P, N. But the inconsistency of P, N is, by the
U-Resolution theorem, precisely the same as saying P, N ⊢
UHR .
(b): Proof by induction on the length ℓof a (successful) UH-resolution
(P ρi
i , Ni, ωi)i⩽ℓfor P, N. Let ℓ= 0, so that
∈UωHR(P ρ
0 , N) for suitable
ρ, ω (= ω0), and P0 ∈P. Then ω uniﬁes P ρ
0 ∪N, i.e., P ρω
0
= {π} = γω
i
for some prime formula π and all i ⩽k. Hence trivially Pρω
0
⊢γω
i (=
π) for each i ⩽k, and so P ⊢γω
0 ∧· · · ∧γω
k = γω as claimed in Theo-
rem 6.2(b) for the case ℓ= 0. Now let ℓ> 0. Then (P ρi
i , Ni, ωi)1⩽i⩽ℓis a
UH-resolution for P, N1 as well. By the induction hypothesis,
(1)
P ⊢αω1···ωℓwhenever ¬α ∈N1 .
It suﬃces to verify P ⊢γω
i for all i ⩽k with ω = ω0 . . . ωn in agreement
with the notation in Theorem 6.2. To this end we distinguish two cases
for given i: if ¬γω0
i
∈N1 then P ⊢(γω0
i )ω1···ωℓby (1), hence P ⊢γω
i . Now

168
4 Foundations of Logic Programming
suppose ¬γω0
i
/∈N1.
Then γω0
i
disappears in the resolution step from
P ρ0
0 , N0 (= N) to N1. So P0 takes the form P0 = {¬β1, . . . , ¬βm, β},
where βρ0ω0 = γω0
i
and ¬βρ0ω0
j
∈N1 for j = 1, . . . , m. Thus (1) evidently
yields P ⊢(βρ0ω0
j
)ω1···ωℓand therefore P ⊢m
j=1 βρ0ω
j
. At the same time, it
holds P ⊢m
j=1 βρ0ω
j
→βρ0ω because of P ⊢¬βρ0ω
1
∨. . . ∨¬βρ0ω
m
∨βρ0ω (the
latter holds since P0 = {¬β1, . . . , ¬βm, β}). Using MP we then obtain
P ⊢βρ0ω. From βρ0ω0 = γω0
i , applying ω1 · · · ωℓon both sides, we obtain
βρ0ω = γω
i . Hence P ⊢γω
i also in the second case. Thus, βρ0ω = γω
i for
all i ⩽n, independent on our case distinction. This proves (b).
(c): Let P ⊢γτ with τ := ⃗t
⃗x, and P′ = GI(P). Then P, ¬γτ is inconsis-
tent, and so too is P′, ¬γτ by Theorem 1.1 (consider GI(¬γτ) = {¬γτ}).
According to the H-resolution theorem 4.2, there is some H-resolution
B = (P ′
i, Qi)i⩽ℓfor P′, Nτ with Q0 = Nτ. Here let, say, P ′
i = P σi
i
for
appropriate clauses Pi ∈P and σi. From this facts we will derive
(2) for ﬁnite V ⊆Var there exist ρi, Ni, ωi, τ such that (P ρi
i , Ni, ωi)i⩽ℓ
is a UH-resolution for P, N. Moreover, xωτ = xσ for ω := ω0 · · · ωℓ
and all x ∈V .
This completes our reasoning, because (2) yields (for V = {x1, . . . , xn})
x ω τ
i
= x σ
i = ti for i = 1, . . . , n, whence (c). For the inductive proof of (2)
look at the ﬁrst resolution step Q1 = HR(P ′
0, Q0) in B, with P ′
0 = P σ0
0 ,
Q0 = N σ1, σ1 := τ. By Lemma 7.1 with K0 := P0, K1 := N0 := N,
we choose ω0, ρ0, τ0, H such that H ∈UωHR(P ρ0
0 , N0) and Hτ0 = Q1,
as well as xω0τ0 = xσ for all x ∈V . If ℓ= 0, that is, if Q1 =
, then
also H =
and (2) is proved with τ = τ0. Now suppose ℓ> 0. For the
H-resolution (P ′
i, Qi)1⩽i⩽ℓfor P′, Q1 and for V ′ := var {xω0 | x ∈V } there
exist by the induction hypothesis ρi, Ni, ωi for i = 1, . . . , ℓand some τ,
such that (P ρi
i , Ni, ωi)1⩽i⩽ℓis a UH-resolution for P, H and simultaneously
yω1···ωℓτ = yτ0 for all y ∈V ′ (instead of Q0 = N σ we have now to consider
Q1 = Hτ0). Because of var xω0 ⊆V ′ and xω0τ0 = xσ for x ∈V we get
(3)
xωτ = (xω0)ω1···ωℓτ = xω0τ0 = xσ, for all x ∈V .
(P ρi
i , Ni, ωi)i⩽ℓis certainly a UH-resolution. Moreover, by virtue of (3),
and by choosing V = {x1, . . . , xn}, it holds xωτ
i
= xσ
i = ti for i = 1, . . . , n.
This proves (2), hence (c), and completes the proof of Theorem 6.2.

Chapter 5
Elements of Model Theory
Model theory is a main branch of applied mathematical logic. Here the
techniques developed in mathematical logic are combined with construc-
tion methods of other areas (such as algebra and analysis) to their mutual
beneﬁt. The following demonstrations can provide only a ﬁrst glimpse in
this respect, a deeper understanding being gained, for instance, from [CK]
or [Ho]. For further-ranging topics, such as saturated models, stability
theory, and the model theory of languages other than ﬁrst-order, we refer
to the special literature, [Bue], [Mar], [Pz], [Rot], [Sa], [She].
The theorems of Löwenheim and Skolem were ﬁrst formulated in the
generality given in 5.1 by Tarski. These and the compactness theorem
form the basis of model theory, a now wide-ranging discipline that arose
around 1950. Key concepts of model theory are elementary equivalence
and elementary extension. These not only are interesting in themselves
but also have multiple applications to model constructions in set theory,
nonstandard analysis, algebra, geometry and elsewhere.
Complete axiomatizable theories are decidable; see 3.5. The question of
decidability and completeness of mathematical theories and the develop-
ment of well-honed methods that solve these questions have always been
a driving force for the further development of mathematical logic.
Of
the numerous methods, we introduce here the most important: Vaught’s
test, Ehrenfeucht’s game, Robinson’s method of model completeness, and
quantiﬁer elimination. For more involved cases, such as the theories of
algebraically closed and real closed ﬁelds, model-theoretic criteria are de-
veloped and applied. For a complete understanding of the material in 5.5
the reader should to some extent be familiar with some basic algebraic
constructions, mainly concerning the theory of ﬁelds.
W. Rautenberg, A Concise Introduction to Mathematical Logic,
169
Universitext, DOI 10.1007/978-1-4419-1221-3_5,
c⃝Springer Science+Business Media, LLC 2010

170
5 Elements of Model Theory
5.1
Elementary Extensions
In 3.3 nonstandard models were obtained using a method that we now
generalize. For given L and a set A let LA denote the language resulting
from L by adjoining new constant symbols a for all a ∈A. The symbol a
should depend only on a, not on A, so that LA ⊆LB whenever A ⊆B.
To simplify notation we shall write from Theorem 1.3 onward just a rather
than a; there will be no risk of misunderstanding.
Let B be an L-structure and A ⊆B (the domain of B).
Then the
LA-expansion in which a is interpreted by a ∈A will be denoted by BA.
According to Exercise 3 in 2.3 we have for arbitrary α = α(⃗x) ∈L and
arbitrary ⃗a ∈An,
(1)
B ⊨α [⃗a] ⇔BA ⊨α(⃗a)
(α(⃗a) := α a1
x1 · · · an
xn ).
It is important to notice that every sentence from LA is of the form
α(⃗a) for suitable α(⃗x) ∈L and ⃗a ∈An. Instead of BA ⊨α(⃗a) (which is
equivalent to B ⊨α [⃗a]) we later will write just BA ⊨α(⃗a) or even B ⊨α(⃗a),
as in Theorem 1.3. Thus, B may also denote a constant expansion of B if it
is not the distinction that is to be emphasized. This notation is somewhat
sloppy but points up the ideas behind the constructions.
Note that for an L-structure A, the LA-expansion AA receives a new
constant symbol for every a ∈A, even if some elements of A already
possess names in L.
The set of all variable-free literals λ ∈LA such
that AA ⊨λ is called the diagram of A, denoted by DA. For instance,
D(R, <) contains for all a, b ∈R the literals a==== b, a̸====b, a < b, or a ≮b,
depending on whether indeed a=b, a̸=b, a<b, or a≮b for the reals a, b.
Diagrams are important for various constructions in model theory.
The notion of an embedding ı: A →B as deﬁned in 2.1 (that is, the
image of A under ı is an isomorphic copy of A) embraces the notion of a
substructure. Indeed, A ⊆B iﬀı = idA, i.e. if ı is the identical or trivial
embedding of A into B.
Let L0 ⊆L. In this chapter, the embeddability of an L0-structure A
into a given L-structure B often means the embeddability of A into the
L0-reduct B0 of B, and we shall write A ⊆B also in such a situation. In
this sense the group Z, for example, is embeddable into the ﬁeld Q.

5.1 Elementary Extensions
171
Theorem 1.1. Let L0 ⊆L, A be an L0-structure, and B an LA-structure.
Then B ⊨DA iﬀı: a 
→aB is an embedding of A in B.
Proof. ⇒: Let B ⊨DA and a, b ∈A, a ̸= b. Then a̸====b ∈DA. Hence
B ⊨a ̸==== b, or equivalently, aB ̸= bB. Thus ı is injective. For a relation
symbol r from L0 and ⃗a ∈An we have in view of B ⊨DA,
rA⃗a ⇔r⃗a ∈DA ⇔B ⊨r⃗a ⇔rBı⃗a
	
ı⃗a := (ıa1, . . . , ıan)

.
Similarly ıfA⃗a = fBı⃗a is obtained, for note that whenever ⃗a ∈An and
b ∈A then f A⃗a = b ⇔f⃗a==== b ∈DA ⇔B ⊨f⃗a==== b ⇔fBı⃗a = ıb. Thus,
ı is indeed an embedding. ⇐: For variable-free terms t in L0A one easily
veriﬁes ıtA = tB, where here and elsewhere tA means more precisely tAA.
Since ı is injective, it follows for variable-free equations t1 ==== t2 in L0A,
t1 ==== t2 ∈DA ⇔t A
1 = t A
2 ⇔ıt A
1 = ıt A
2 ⇔t B
1 = t B
2 ⇔B ⊨t1 ==== t2.
In the same way we get t1̸====t2 ∈DA ⇔B ⊨t1̸====t2. Sentences of the form
r⃗t and their negations are dealt with analogously. Thus, B ⊨DA.
Corollary 1.2. Let A, B be L-structures and B′ an LA-expansion of B.
Then B′ ⊨DA iﬀA is embeddable into B. Moreover, if A ⊆B then
BA ⊨DA ⇔A ⊆B.
Indeed, by the theorem with L0 = L, the mapping ı: a 
→aB′ realizes the
embedding, and also the converse of the ﬁrst claim is obvious. ı is the
identical mapping in case A ⊆B, which veriﬁes the “Moreover” part with
B′ = BA. Frequent use will be made of this corollary, without mentioning
it explicitly.
Taking a prime model for a theory T to mean a model
embeddable into every T-model, the corollary states that AA is a prime
model for DA, understood as a theory. We are using the concept of a
prime model only in this sense. It must be distinguished from the concept
of an elementary prime model for T as deﬁned in Exercise 2.
Probably the most important concept in model theory, for which a ﬁrst
example appears on the next page, is given by the following
Deﬁnition. Let L be a ﬁrst-order language and let A, B be L-structures.
A is called an elementary substructure of B, and B an elementary extension
of A, in symbols A ≼B, if A ⊆B and
(2)
A ⊨α [⃗a] ⇔B ⊨α [⃗a], for all α = α(⃗x) ∈L and ⃗a ∈An.

172
5 Elements of Model Theory
Clearly, A ≼B ⇒A ⊆B. Terming Del A := {α ∈LA0 | AA ⊨α} the
elementary diagram of A, A ≼B is obviously equivalent to A ⊆B and
BA ⊨Del A. Indeed, (2) already holds given only A ⊨α [⃗a] ⇒B ⊨α [⃗a],
for all α = α(⃗x) ∈L and ⃗a ∈An.
(2) is equivalent to AA ⊨α(⃗a) ⇔BA ⊨α(⃗a), by (1). And since every
α ∈LA is of the form α(⃗a) for appropriate α(⃗x) ∈L, ⃗a ∈An, and
n ⩾0, the property A ≼B is also characterized by A ⊆B and AA ≡BA
(elementary equivalence in LA).
In general, A ≼B means much more than A ⊆B and A ≡B. For
instance, let A = (N+, <) and B = (N, <). Then certainly A ⊆B, and
since A ≃B, we have also A ≡B. But A ≼B is false. For example,
∃x x < 1 is true in BA, but obviously not in AA. The following theorem
will prove to be very useful for, among other things, the provision of
nontrivial examples for A ≼B:
Theorem 1.3 (Tarski’s criterion). For arbitrary L-structures A, B with
A ⊆B the following conditions are equivalent:
(i) A ≼B,
(ii) For all ϕ(⃗x, y) ∈L and ⃗a ∈An holds the implication
B ⊨∃yϕ(⃗a, y) ⇒B ⊨ϕ(⃗a, a) for some a ∈A.
Proof. (i)⇒(ii): Let A ≼B and B ⊨∃yϕ(⃗a, y), so that also A ⊨∃yϕ(⃗a, y).
Then A ⊨ϕ(⃗a, a) for some a ∈A. But A ≼B; hence B ⊨ϕ(⃗a, a). (ii)⇒(i):
Since A ⊆B, (2) certainly holds for prime formulas. The induction steps
for ∧, ¬ are obvious. Only the quantiﬁer step needs a closer look:
A ⊨∀yϕ(⃗a, y) ⇔A ⊨ϕ(⃗a, a) for all a ∈A
⇔B ⊨ϕ(⃗a, a) for all a ∈A
(induction hypothesis)
⇔B ⊨∀yϕ(⃗a, y)
(see below).
We prove the direction ⇒in the last equivalence indirectly: Assume that
B ⊭∀yϕ(⃗a, y). Then B ⊨∃y¬ϕ(⃗a, y). Hence B ⊨¬ϕ(⃗a, a) for some a ∈A
according to (ii). Thus, B ⊨ϕ(⃗a, a) cannot hold for all a ∈A.
Interesting examples for A ≼B are provided in a surprisingly simple
way by the following theorem, which, unfortunately, is applicable only if
B has “many automorphisms,” as is the case in the example below, and in
geometry, for instance.

5.1 Elementary Extensions
173
Theorem 1.4. Let A ⊆B. Suppose that for all n, all ⃗a ∈An, and all
b ∈B there is an automorphism ı: B →B such that ı⃗a = ⃗a, and ıb ∈A.
Then A ≼B.
Proof. It suﬃces to verify (ii) in Theorem 1.3. Let B ⊨∃yϕ(⃗a, y), or
equivalently B ⊨ϕ(⃗a, b) for some b ∈B. Then B ⊨ϕ(ı⃗a, ıb) according to
Theorem 2.3.4, and since ı⃗a = ⃗a, we obtain B ⊨ϕ(⃗a, a) with a := ıb ∈A.
This proves (ii).
Example. It is readily shown that for given a1, . . . , an ∈Q and b ∈R
there exists an automorphism of (R, <) that maps b to a rational num-
ber and leaves a1, . . . , an ﬁxed (Exercise 3). Thus, (Q, <) ≼(R, <). In
particular (Q, <) ≡(R, <).
Here is a look at some less simple examples of elementary extensions,
considered more closely in 5.5. Let A = (A, 0, 1, +, ·) denote the ﬁeld
of algebraic numbers and C the ﬁeld of complex numbers. The domain A
consists of all complex numbers that are zeros of (monic) polynomials with
rational coeﬃcients. Then A ≼C. Similarly, Ar ≼R where Ar denotes
the ﬁeld of all real algebraic numbers and R is the ﬁeld of all reals. The
claim A ≼C follows from the model completeness of the theory ACF
proved on page 198. Similarly Ar ≼R will be shown.
Before continuing we will acquaint ourselves somewhat with transﬁnite
cardinal numbers. It is possible to assign a set-theoretic object denoted
by |M| not only to ﬁnite sets but to arbitrary sets M such that
(3) M ∼N ⇔|M| = |N|
(∼means equipotency; see page 111).
|M| is called the cardinal number or cardinality of M. This is just the
number of elements in M for a ﬁnite M; for an inﬁnite set M, |M| is
called a transﬁnite cardinal number, or brieﬂy a transﬁnite cardinal.
At this stage it is unimportant just how |M| is deﬁned in detail. The
interested reader will ﬁnd some deﬁnition in every textbook on set theory.
Signiﬁcant are (4) and (5), taken as granted, from which (6) and (7)
straightforwardly follow.
(4) The cardinal numbers are well-ordered according to size, i.e., each
nonempty collection of them possesses a smallest element.
Here
let |N| ⩽|M| if there is an injection from N to M. The smallest
transﬁnite cardinality is |N|, i.e., |N| ⩽|M| for all inﬁnite sets M.

174
5 Elements of Model Theory
(5) |M ∪N| = |M × N| = max{|M|, |N|} for arbitrary sets M and N of
which at least one is inﬁnite.
Remark. With this deﬁnition of ⩽it follows that |M| ⩽|N| & |N| ⩽|M| implies
|M| = |N| (without AC). This is called the Cantor–Bernstein theorem. Actually,
the ﬁrst proof of this theorem without AC (even more elegant than Bernstein’s)
is due to Dedekind, who left it unpublished in his diary from 1887. This theorem
holds under surprisingly weak assumptions; see [De].
We ﬁrst derive from (4) and (5) that M ∗:= 
n>0 M n has the same
cardinality as M for inﬁnite M, where M ∗denotes the set of all nonempty
ﬁnite sequences of elements of M. In short,
(6) |M ∗| = |M|
(M inﬁnite).
Indeed, |M 1| = |M|, and the hypothesis |M n| = |M| obviously yields
|Mn+1| = |Mn × M| = |M| by (5). Thus |M n| = |M| for all n. Therefore
|M∗| = |
n>0 M n| = |M × N| = |M|. One similarly obtains from (4), (5)
for every transﬁnite cardinal κ the property
(7) If A0, A1 . . . are sets and |An| ⩽κ for all n ∈N then |
n∈N An| ⩽κ.
The smallest transﬁnite cardinal number (i.e., |N|) is that of the count-
ably inﬁnite sets, denoted by ℵ0. The next one is ℵ1. Then follows ℵ2,
ℵ3, . . . There is a smallest cardinal larger than all ℵn, denoted by ℵω, etc.
The Cantor–Bernstein theorem shows that the power set PN and the set
R have the same cardinality, denoted by 2ℵ0. Certainly ℵ0 < 2ℵ0, hence
ℵ1 ⩽2ℵ0. Cantor’s continuum hypothesis (CH) states that ℵ1 = 2ℵ0.
CH is independent in ZFC; see e.g. [Ku]. While there are axioms ex-
tending beyond ZFC that decide CH one way or another, none of these is
suﬃciently plausible to be regarded as “true.” In the last decades some ev-
idence has been collected that suggests that 2ℵ0 = ℵ2, but this seemingly
does not yet convince the majority of mathematicians.
The cardinality of a structure A is always that of its domain, that
is, |A| := |A|. Theorem 1.5 below, essentially due to Tarski and there-
fore sometimes called the Löwenheim–Skolem–Tarski theorem, generalizes
Theorem 3.4.1 (page 112) essentially. The additive “downward” prevents
a mix-up of these theorems. For |B| ⩾|L|, Theorem 1.5 ensures the exis-
tence of some A ≼B (in particular A ≡B) such that |A| ⩽|L|.

5.1 Elementary Extensions
175
Theorem 1.5 (Löwenheim–Skolem theorem downward). Suppose
that B is an L-structure such that |L| ⩽|B| and let A0 ⊆B be arbitrary.
Then B has an elementary substructure A of cardinality ⩽max{|A0|, |L|}
such that A0 ⊆A.
Proof. We construct a sequence A0 ⊆A1 ⊆· · · ⊆B as follows. Let Ak
be given. For every α = α(⃗x, y) and ⃗a ∈A n
k such that B ⊨∃yα(⃗a, y)
we select some b ∈B with B ⊨α(⃗a, b) and adjoin b to Ak, thus getting
Ak+1. In particular, if α is f⃗x==== y then certainly B ⊨∃y f⃗a==== y. Since
B ⊨∃!y f⃗a==== y, there is no alternative selection; hence f B⃗a ∈Ak+1. Thus,
A := 
k∈N Ak is closed under the operations of B, and therefore deﬁnes
a substructure A ⊆B. We shall prove A ≼B by Tarski’s criterion. Let
B ⊨∃yα(⃗a, y) for α = α(⃗x, y) and let ⃗a ∈An. Then ⃗a ∈A n
k for some k.
Therefore, there is some a ∈Ak+1 (hence a ∈A) such that B ⊨α(⃗a, a).
This proves (ii) in Theorem 1.3 and so A ≼B. It remains to show that
|A| ⩽κ := max{|A0|, |L|}. There are at most κ formulas and κ ﬁnite
sequences of elements in A0. Thus, by deﬁnition of A1, at most κ new
elements are adjoined to A0.
Hence |A1| ⩽κ.
Similarly, |An| ⩽κ is
veriﬁed for each n > 0. By (7) we thus get |
n∈N An| ⩽κ.
Combined with the compactness theorem, the above theorem yields
Theorem 1.6 (Löwenheim–Skolem theorem upward). Let C be any
inﬁnite L-structure and κ ⩾max{|C|, |L|}. Then there exists an A ≽C
with |A| = κ.
Proof. Choose some D ⊇C with |D| = κ.
From (6) it follows that
|LD| = κ, because the alphabet of LD has cardinality κ. Since |C| ⩾ℵ0,
by the compactness theorem, Del C ∪{c̸====d | c, d ∈D, c ̸= d} has a model
B. Since d 
→d B (d ∈D) is injective, we may assume d B = d for all
d ∈D, i.e., D ⊆B. By Theorem 1.5 with LD for L and D for A0, there
is some A ≼B with D ⊆A and κ ⩽|D| ⩽|A| ⩽max{|LD|, |D|} = κ.
Hence |A| = κ.
From C ⊆D and A ≡LD B ⊨Del C it follows that
A ⊨Del C.
Since C ⊆D ⊆A in addition, the L-reduct of A is an
elementary extension of the given structure C.
These theorems show in particular that a countable theory T with at
least one inﬁnite model also has models in every inﬁnite cardinality. Fur-
ther, ⊢T α already holds when merely A ⊨α for all T-models A of a

176
5 Elements of Model Theory
single inﬁnite cardinal number κ, as long as T has only inﬁnite models,
because under this assumption every T-model is elementarily equivalent
to a T-model of cardinality κ.
Exercises
1. Let A ≼C and B ≼C, where A ⊆B. Prove that A ≼B.
2. An embedding ı: A →B is termed elementary if ıA ≼B, where
ıA denotes the image of A under ı. Show similarly to Theorem 1.1
that an LA-structure B is a model of Del A iﬀA is elementarily
embeddable into B.
3. Let a1, . . . , an ∈Q and b ∈R. Show that there is an automorphism
of (R, <) that maps b to a rational number and leaves all ai ﬁxed.
4. Let A ≡B. Construct a structure C in which A, B are both elemen-
tarily embeddable.
5. Let A be an L-structure generated from G ⊆A and TG the set of
ground terms in LG. Prove that (a) for every a ∈A there is some
t ∈TG such that a = tA, (b) if A ⊨T and DA ⊢T α (∈LG) then
DGA ⊢T α. Here DGA := DA ∩LG.
5.2
Complete and κ-Categorical Theories
According to the deﬁnition on page 105, a theory T ⊆L0 is complete if
it is consistent and each extended theory T ′ ⊃T in L0 is inconsistent. A
complete theory need not be maximally consistent in the whole of L. For
instance, in general neither ⊢T x==== y nor ⊢T x̸====y, even if T is complete.
Some equivalent formulations of completeness, whose usefulness depends
on the situation at hand, are presented by the following
Theorem 2.1. For a consistent theory T the following conditions are
equivalent:1
1 All these conditions are also equivalent (they all hold) if the inconsistent theory is
taken to be complete, which is not the case here, as we agreed upon in 3.3.

5.2 Complete and κ-Categorical Theories
177
(i)
T is complete,
(ii)
T = Th A for every A ⊨T,
(iii)
A ≡B for all A, B ⊨T,
(iv)
⊢T α ∨β implies ⊢T α or ⊢T β
(α, β ∈L0),
(v)
⊢T α or ⊢T ¬α (α ∈L0).
Proof. (i) ⇒(ii): Since T ⊆Th A for each model A ⊨T, it must be that
T = Th A. (ii) ⇒(iii): For A, B ⊨T we have by (ii) Th A = T = Th B,
and therefore A ≡B. (iii) ⇒(iv): Let ⊢T α ∨β, A ⊨T, and A ⊨α,
say. Then B ⊨α for all B ⊨T by (iii), hence ⊢T α. (v) is a special case
of (iv) because ⊢T α ∨¬α, for arbitrary α ∈L0. (v) ⇒(i): Let T ′ ⊃T
and α ∈T ′ \T. Then ⊢T ¬α by (v); hence also ⊢T ′ ¬α. But then T ′ is
inconsistent. Hence, by the above deﬁnition, T is complete.
We now present various methods by which conjectured completeness can
be conﬁrmed. The completeness question is important for many reasons.
For example, according to Theorem 3.5.2, a complete axiomatizable theory
is decidable whatever the means of proving completeness might have been.
An elementary theory with at least one inﬁnite model, even if it is
complete, has many diﬀerent inﬁnite models. For instance, according to
Theorem 1.6, the theory possesses models of arbitrarily high cardinality.
However, sometimes it happens that all of its models of a given ﬁnite or
inﬁnite cardinal number κ are isomorphic. The following deﬁnition bears
this circumstance in mind.
Deﬁnition. A theory T is κ-categorical if there exists up to isomorphism
precisely one T-model of cardinality κ.
Example 1.
The theory Taut =
==
= of tautological sentences in L=
==
= is κ-
categorical for every cardinal κ. Indeed, here models A, B of cardinality κ
are naked sets and these are trivially isomorphic under any bijection from
A onto B.
The theory DO of densely ordered sets results from the theory of ordered
sets (formalized in 2.3; see also 2.1) by adjoining the axioms
∃x∃y x̸====y ;
∀x∀y∃z(x < y →x < z ∧z < y).
It is obvious that a densely ordered set is inﬁnite. DO can be extended
by the axioms L := ∃x∀y x ⩽y and R := ∃x∀y y ⩽x to the theory DO11
of densely ordered sets with edge elements. Replacing R by ¬R results in

178
5 Elements of Model Theory
the theory DO10 of densely ordered sets with left but without right edge
elements. Accordingly DO01 denotes the theory with right but without
left, and DO00 that of dense orders without edge elements. The paradigm
of a model for DO00 is (Q, <). Another model is (Q+, <).
Example 2. DO00 is ℵ0-categorical (Exercise 1 treats the other DOij).
The following proof is due to Cantor. A function f with dom f ⊆M
and ran f ⊆N is said to be a partial function from M to N.
Now
let A = {a0, a1, . . . } and B = {b0, b1, . . . } be countable DO00-models.
Deﬁne f0 by f0a0 = b0 so that dom f0 = {a0}, ran f0 = {b0} (step 0).
Assume that in the nth step a partial function fn from A to B with ﬁnite
domain was constructed with a < a′ ⇔fna < fna′, for all a, a′ ∈dom fn
(a so-called partial isomorphism), and that {a0, . . . , an} ⊆dom fn and
{b0, . . . , bn} ⊆ran fn. These conditions are trivially satisﬁed for f0. Let
m be minimal with am ∈A \dom fn. Choose b ∈B \ran fn such that
gn := fn ∪{(am, b)} is also a partial isomorphism. This is possible thanks
to the denseness of B.
Now let m be minimal with bm ∈B \ran gn.
Choose a suitable a ∈A \dom gn such that fn+1 := gn ∪{(a, bm)} is a
partial isomorphism too. This “to and fro” construction clearly provides
for both an+1 ∈dom fn+1 and bn+1 ∈ran fn+1. Claim: f = 
n∈N fn
is an isomorphism from A onto B. Indeed, f is a function. Moreover,
dom f = A and ran f = B. The isomorphism condition x < y ⇔fx < fy
is clear, since any x, y ∈A belong already to dom fn for suitable n.
Example 3. The successor theory Tsuc in L{0, S} has the axioms
∀x 0̸====Sx,
∀xy(Sx==== Sy →x==== y),
(∀x̸====0)∃y x==== Sy,
∀x0 · · · xn(
i<n Sxi ==== xi+1 →x0̸====xn)
(n = 1, 2, . . . ).
The last axiom says there are no “circles.” Tsuc is not ℵ0-categorical, but
it is ℵ1-categorical. Indeed, each model A ⊨Tsuc with |A| = ℵ1 consists up
to isomorphism of the (countable) standard model (N, 0, S) and ℵ1 many
“threads” of isomorphism type (Z, S), where S: z 
→z + 1. For if there
were only countably many such threads then the entire model would be
countable. Hence any two Tsuc-models of cardinality ℵ1 are isomorphic.
Example 4. The theory ACFp of a.c. ﬁelds of given characteristic p (page
105) is ℵ1-categorical. We sketch here a proof very brieﬂy because ACFp
is analyzed in 5.5 in a diﬀerent way. The claim follows from the facts
that each ﬁeld is embeddable into an a.c. ﬁeld (cf. Example 1 in 5.5) and

5.2 Complete and κ-Categorical Theories
179
that a transcendental extension K′ of a ﬁeld K (that is, every a ∈K′ \K
is transcendental over K) has a transcendence basis B. This is a maximal
system of algebraically independent elements in K′ \K. The isomorphism
type of K′ is completely determined by the cardinality of B.
It is fairly plausible that in Examples 3 and 4 κ-categoricity holds for
every cardinal κ > ℵ0. This observation is no coincidence. It is explained
by the following theorem.
Morley’s theorem. If a countable theory T is κ-categorical for some
κ > ℵ0 then it is κ-categorial for all κ > ℵ0.
The proof makes use of extensive methods and must be passed over
here. On the other hand, the proof of the following theorem requires but
little eﬀort.
Theorem 2.2 (Vaught’s test). A countable consistent theory T without
ﬁnite models is complete provided T is κ-categorical for some κ.
Proof. Note ﬁrst that κ ⩾ℵ0 because T possesses no ﬁnite models.
Assume that T is incomplete. Choose some α ∈L0 with ⊬T α and ⊬T ¬α.
Then T, α and T, ¬α are consistent. These sets have countable inﬁnite
models by Theorem 1.5, and according to Theorem 1.6 there are also
models A and B of cardinal κ. Since A, B ⊨T, by hypothesis A ≃B;
hence A ≡B, which contradicts A ⊨α and B ⊨¬α.
Example 5. (a) DO00 has only inﬁnite models and is ℵ0-categorical by
Example 2. Hence DO00 is complete by Vaught’s test. This fact conﬁrms
(Q, <) ≡(R, <) once again. In fact, each DOij is complete (Exercise 1).
Thus, A ≡B for A, B ⊨DO iﬀA, B have “the same edge conﬁguration,”
which tells us that the DOij are the only completions of DO. Since DO is
axiomatizable, it follows by Exercise 3 in 3.5 that DO is decidable. The
same applies to each of its ﬁnite extensions DOij.
(b) The successor theory Tsuc is ℵ1-categorical (Example 3) and has only
inﬁnite models. Hence it is complete by Vaught’s test and as an axioma-
tizable theory thus decidable (Theorem 3.5.2).
(c) ACFp is ℵ1-categorical by Example 4. Each a.c. ﬁeld A is inﬁnite.
For assume the converse, A = {a0, . . . , an}, say. Then the polynomial
1 + 
i⩽n(x −ai) would have no root, a contradiction. Thus, by Vaught’s
test, ACFp is complete and decidable (since it is axiomatizable).
This
result will be derived by quite diﬀerent methods in 5.5.

180
5 Elements of Model Theory
The model classes of ﬁrst-order sentences are called elementary classes.
These clearly include the model classes of ﬁnitely axiomatizable theories.
For each such theory T, Md T = 
α∈T Md α is an intersection of ele-
mentary classes, also termed a Δ-elementary class. Thus, the class of
all ﬁelds is elementary, and that of all a.c. ﬁelds is Δ-elementary. On
the other hand, the class of all ﬁnite ﬁelds is not Δ-elementary because
its theory evidently has inﬁnite models. An algebraic characterization of
elementary and Δ-elementary classes will be provided in 5.7.
The model classes of complete ﬁrst-order theories are called elementary
types. Md T is the union of the elementary types belonging to the comple-
tions of a theory T. For instance, DO has just the four completions DOij
determined by the edge conﬁguration, that is, by those of the sentences
L, R, ¬L, ¬R, valid in the respective completion. For this case, the next
theorem provides more information on T, in particular on ≡T .
Let X ⊆L be nonempty and T a theory.
Take ⟨X⟩to denote the
set (still dependent on T) of all formulas equivalent in T to Boolean
combinations of formulas in X. Clearly, ⊤∈⟨X⟩since ⊤≡T α ∨¬α
for α ∈X.
Therefore, T ⊆⟨X⟩, because α ≡T
⊤whenever α ∈T.
Call X ⊆L0 a Boolean basis for L0 in T if every α ∈L0 belongs to
⟨X⟩, i.e., every sentence in L is a Boolean combination of sentences from
X. Example 6(b) below indicates how useful a Boolean base for decision
problems can be. A ≡X B is to mean A ⊨α ⇔B ⊨α, for all α ∈X.
Theorem 2.3 (Basis theorem for sentences). Let T be a theory and
X ⊆L0 a set of sentences with A ≡X B ⇒A ≡B, for all A, B ⊨T.2
Then X is a Boolean basis for L0 in T.
Proof. Let α ∈L0 and Yα := {β ∈⟨X⟩| α ⊢T β}. We claim (∗): Yα ⊢T α.
Otherwise let A ⊨T, Yα, ¬α. Then TXA := {γ ∈⟨X⟩| A ⊨γ} ⊢¬α;
indeed, for any B ⊨TXA we have B ≡X A and hence B ≡A. Therefore
γ ⊢T ¬α for some γ ∈TXA, because ⟨X⟩is closed under conjunctions.
This yields α ⊢T ¬γ, i.e., ¬γ ∈Yα.
Thus A ⊨¬γ, in contradiction
to A ⊨γ.
So (∗) holds.
Hence there are β0, . . . , βm ∈Yα such that
β := 
i⩽m βi ⊢T α. We know that α ⊢T βi and so that α ⊢T β as well.
This and β ⊢T α conﬁrms α ≡T β, and since β ∈⟨X⟩, also α ∈⟨X⟩.
2 This assumption is equivalent to the assertion that {γ ∈⟨X⟩| A ⊨γ} is complete;
see the subsequent proof. For reﬁnements of the theorem we refer to [HR].

5.2 Complete and κ-Categorical Theories
181
Example 6. (a) Let T = DO and X = {L, R}. Then A ≡X B ⇒A ≡B,
for all A, B ⊨T. Indeed, A ≡X B states that A, B possess the same edge
conﬁguration. But then A ≡B, because the DOij are all complete; see
Example 5(a). Therefore, L and R form a Boolean basis for L0
< in DO.
This theory has four completions, and so by Exercise 5 in 3.5, exactly
15 (= 24 −1) consistent extensions.
(b) Let T = ACF and X = {charp | p prime}. Again, A ≡X B ⇒A ≡B,
for all A, B ⊨T, because by Example 5(c), ACFp is complete for each p
(including p = 0). Hence, by Theorem 2.3, the charp constitute a Boolean
basis for sentences modulo ACF. This implies the decidability of ACF: let
α ∈L0 be given; just wait in an enumeration process of the theorems of
ACF until a sentence of the form α ↔β appears, where β is a Boolean
combination of the charp. Such a sentence deﬁnitely appears. Then test
whether β ≡ACF ⊤, for example by converting β into a CNF.
Corollary 2.4. Let T ⊆L0 be a theory with arbitrarily large ﬁnite models,
such that all ﬁnite T-models with the same number of elements and all
inﬁnite T-models are elementarily equivalent. Then
(a) the sentences ∃n form a Boolean basis for L0 in T,
(b) T is decidable provided T is ﬁnitely axiomatizable.
Proof. Let X := {∃k | k ∈N}. Then by hypothesis, A ≡X B ⇒A ≡B,
for all A, B ⊨T. Thus, (a) follows by Theorem 2.3. By (a) and Exercise 4
in 2.3 each α ∈L0 is equivalent in T to 
ν⩽n ∃=kν with k0 < · · · < kn or
to ∃k ∨
ν⩽n ∃=kν for some k. Hence a sentence α that has a T-model
has also a ﬁnite T-model by the ﬁrst assumption on T, i.e., T has the
ﬁnite model property. Thus, (b) holds by Exercise 3 in 3.6.
An easy example of application is the theory Taut =
==
= of tautologies in
L=
==
=. The formulas constructed from the Boolean base {∃n | n ∈ω} in the
proof also permit a simple description of the elementary classes of L=
==
=.
These are ﬁnite unions of classes determined by sentences ∃k and ∃=m.
Another example is the theory FO of ﬁnite ordered sets. We prove in the
next section that FO satisﬁes the assumptions of Corollary 2.4. Hence,
the elementary classes of FO have the same simple description.
These examples illustrate the following: If we know the elementary
types of a theory T—these correspond to the completions of T—then we

182
5 Elements of Model Theory
also know their elementary classes. As a rule, the type classiﬁcation, that
is, ﬁnding an appropriate set X satisfying the hypothesis of Theorem 2.3,
is successful only in particular cases.
The required work tends to be
extensive. We mention in this regard the theories of abelian groups, of
Boolean algebras, and of other locally ﬁnite varieties; see for instance
[MV]. The above examples are just the simplest ones.
Easy to deal with is the case of an incomplete theory T that has ﬁnitely
many completions.
Example 6(a) is just a special case.
According to
Exercise 5 in 3.5, T then has ﬁnitely many extensions. Moreover, all these
are ﬁnite extensions. Indeed, if T + {αi | i ∈N} is a nonﬁnite extension
then w.l.o.g. 
i<n αi ⊬T αn, which obviously implies that T has inﬁnitely
many completions, contradicting our hypothesis. Thus, we may assume
that T1, . . . , Tm are the completions of T and that Ti = T + αi for some
αi ∈L0. Then {α1, . . . , αm} is a Boolean basis for L0 in T. Exercise 4
provides a canonical axiomatization of all consistent extensions of T.
Exercises
1. Prove that also DO10, DO11, and DO01 are ℵ0-categorical and hence
complete. In addition, verify that these theories and DO00 are the
only completions of DO.
2. Prove that Tsuc (page 178) is also completely axiomatized by the ﬁrst
two given axioms plus IS: ϕ 0x ∧∀x(ϕ →ϕ Sx
x ) →∀xϕ; here ϕ runs
over all formulas of L{0, S} (the “induction schema” for L{0, S}).
3. Show that the theory T of torsion-free divisible abelian groups is ℵ1-
categorical and complete (hence decidable). This shows, e.g., that
the groups (R, 0, +) and (Q, 0, +) are elementarily equivalent.
4. Let T be incomplete and let T +α0, . . . , T +αm be all the completions
of T. Prove that T + 
ν⩽n αiν are all consistent extensions of T.
Here n ⩽m and i0 < · · · < in ⩽m. (Note that T = T + 
i⩽m αi.)
5. Show that an ℵ0-categorical theory T with no ﬁnite models has an
elementary prime model. Example: (Q, <) is an elementary prime
model for DO00.

5.3 The Ehrenfeucht Game
183
5.3
The Ehrenfeucht Game
Unfortunately, Vaught’s criterion has only limited applications because
many complete theories are not categorical in any transﬁnite cardinality.
Let SO denote the theory of discretely ordered sets, i.e., of all (M, <) such
that every a ∈M has an immediate successor provided a is not the right
edge element, and likewise an immediate predecessor provided a is not
a left edge element. “SO” is intended to recall “step order,” because the
word “discrete” in connection with orders often has the stronger sense
“each cut is a jump.” SOij (i.j ∈{0, 1}) is deﬁned analogously to DOij
(see page 177). For instance, SO10 is the theory of discretely ordered sets
with left and without right edge element. Clearly, (N, <) is a prime model
for SO10. The models of SO10 arise from arbitrary orders (M, <) with a
left edge element by replacing the latter by (N, <) and every other element
of M by a specimen of (Z, <). From this it follows that SO10 cannot be κ-
categorical for any κ ⩾ℵ0. Yet this theory is complete, as will be shown,
and the same applies to SO00 and SO01. Only SO11 is incomplete and is
the only one of the four theories that has ﬁnite models. It coincides with
the elementary theory of all ﬁnite ordered sets; Exercise 3.
We prove the completeness of SO10 game-theoretically using a two-
person game with players I and II, Ehrenfeucht’s game Γk(A, B), which is
played in k rounds, k ⩾0. Here A, B are given L-structures and L is a re-
lational language, i.e., L does not contain constants or operation symbols.
With regard to our goal this presents no real loss of generality because
each structure can be converted into a relational one by replacing its op-
erations by the corresponding graphs. Another advantage of relational
structures used in the sequel is that there is a bijective correspondence
between subsets and substructures.
We now describe the game Γk(A, B). Player I chooses in each of the
k rounds one of the two structures A and B.
If this is A, he selects
some a ∈A. Then player II has to answer with some element b ∈B.
If player I chooses B and some b from B then player II must answer
with some element a ∈A. This is the entire game. Clearly, it has still
to be explained who wins. After k rounds, elements a1, . . . , ak ∈A and
b1, . . . , bk ∈B have been selected, where ai, bi denote the elements selected
in round i. Player II wins if the mapping ai 
→bi (i = 1, . . . , k) is a partial

184
5 Elements of Model Theory
isomorphism from A to B; in other words, if the substructure of A with
the domain {a1, . . . , ak} is isomorphic to the substructure of B with the
domain {b1, . . . , bk}. Otherwise, player I is the winner.
We write A ∼k B if player II has a winning strategy in the game
Γk(A, B), that is, in every round player II can answer any move from
player I such that at the end player II is the winner. For the “zero-round
game” let A ∼0 B by deﬁnition.
Example. Let A = (N, <) be a proper initial segment of B ⊨SO10. We
show that A ∼k B for arbitrary k > 0. Player II plays as follows: If player
I chooses some b1 in B in the ﬁrst round then player II answers with
a1 = 2k−1−1 if d(0, b1) ⩾2k−1−1, otherwise with a1 = d(0, b1).3
The
procedure is similar if player I begins with A. If player I now selects some
b2 ∈B such that d(0, b2), d(b1, b2) ⩾2k−2−1, then player II answers with
a2 = a1 ± 2k−2 depending on whether b2 > b1 or b2 < b1, and otherwise
u
u
t
t
t
t
s
s
s
s
r
r
q
q
q
q
q q r s s t
t
u
t
t s s
b1
b3
b2
a3
a2
a1
r q qA
B
a1 = 22−1 = 3, a2 = a1−21 = 1
with the element of
the same distance
from 0 or a1 as that
of b2 from 0 or b1 in
B. Similarly in the
third round, etc. The ﬁgure shows the course of a 3-round game played in
the described way. Player I has chosen from B only for simplicity. With
this strategy player II wins every game, as can be shown by induction on
k. The reader should play a few rounds before proving this rigorously.
In contrast to the example, for A = (N, <) and B = (Z, <) player II’s
chances have already dropped in Γ2(A, B) if player I selects 0 ∈A in the
ﬁrst round. Player II will lose already in the second round. This has to
do with the fact that the existence of an edge element is expressible by a
sentence of quantiﬁer rank 2. We write A ≡k B for L-structures A, B if
A ⊨α ⇔B ⊨α, for all α ∈L0 with qr α ⩽k. It is always the case that
A ≡0 B for all A, B, because in relational languages there are no sentences
of quantiﬁer rank 0. Below we will prove the following remarkable
Theorem 3.1. A ∼k B implies A ≡k B. Hence, A ≡B provided A ∼k B
for all k.
3 The “distance” d(a, b) between elements a, b of some SO-model is 0 for a = b, 1 + the
number of elements between a and b if it is ﬁnite, and d(a, b) = ∞otherwise.

5.3 The Ehrenfeucht Game
185
For ﬁnite signatures a somewhat weaker version of the converse of the
theorem is valid as well, though we do not discuss this here.
Before
proving Theorem 3.1 we demonstrate its applicability. The theorem and
the above example yield (N, <) ≡k B for all k and hence (N, <) ≡B
for every B ⊨SO10, because (N, <) is a prime model for SO10 and hence
can always be regarded as an initial segment of B.
Therefore SO10 is
complete. For reasons of symmetry the same holds for SO01, and likewise
for SO00. On the other hand, SO11 has the ﬁnite model property according
to Exercise 3 and coincides with the theory FO of all ﬁnite ordered sets.
For the proof of Theorem 3.1 we ﬁrst consider a minor generalization
of Γk(A, B), the game Γk(A, B,⃗a,⃗b) with prior moves ⃗a ∈An,⃗b ∈Bn. In
the ﬁrst round player I selects some an+1 ∈A or bn+1 ∈B and player II
answers with bn+1 or an+1, etc. The game protocol consists of sequences
(a1, . . . , an+k) and (b1, . . . , bn+k) at the end. Player II has won if ai 
→bi
(i = 1, . . . , n + k) is a partial isomorphism. Clearly, for n = 0 we obtain
precisely the original game Γk(A, B).
This adjustment brings about an inductive characterization of a winning
strategy for player II independent of more general concepts as follows:
Deﬁnition. Player II has a winning strategy in Γ0(A, B,⃗a,⃗b) provided
ai 
→bi for i = 1, . . . , n is a partial isomorphism. Player II has a winning
strategy in Γk+1(A, B,⃗a,⃗b) if for every a ∈A there is some b ∈B, and
for every b ∈B some a ∈A, such that player II has a winning strategy
in Γk(A, B,⃗a⌣a,⃗b⌣b). Here ⃗c⌣c denotes the operation of appending the
element c to the sequence ⃗c.
We shall write (A,⃗a) ∼k (B,⃗b) if player II has a winning strategy in
Γk(A, B,⃗a,⃗b). In particular, A ∼k B (this represents the choice ⃗a = ⃗b = ∅)
is now precisely deﬁned.
Lemma 3.2. Let (A,⃗a) ∼k (B,⃗b), where ⃗a ∈An and ⃗b ∈Bn. Then
(∗) : A ⊨ϕ(⃗a) ⇔B ⊨ϕ(⃗b), for all ϕ = ϕ(⃗x) such that qr ϕ ⩽k.
Proof by induction on k. Let k = 0. Since ai 
→bi (i = 1, . . . , n) is a par-
tial isomorphism, (∗) is valid for prime formulas, and since the induction
steps in the proof of (∗) for ¬, ∧are obvious, it is valid also for all formulas
ϕ with qr ϕ = 0. Now let (A,⃗a) ∼k+1 (B,⃗b). The only interesting case is
ϕ = ∀yα(⃗x, y) such that qr ϕ = k + 1, because it is easily seen that every

186
5 Elements of Model Theory
other formula of quantiﬁer rank k + 1 is a Boolean combination of such
formulas and of formulas of quantiﬁer rank ⩽k. Induction over ¬ and ∧
in proving (∗) is harmless. Let A ⊨∀yα(⃗a, y) and b ∈B. Then Player
II chooses some a ∈A with (A,⃗a⌣a) ∼k (B,⃗b⌣b), so that according to
the induction hypothesis, A ⊨α(⃗a, a) ⇔B ⊨α(⃗b, b). Clearly, the latter
is supposed to hold for sequences ⃗a,⃗b of elements of arbitrary length. Be-
cause of A ⊨α(⃗a, a), also B ⊨α(⃗b, b). Since b was arbitrary, we obtain
B ⊨∀yα(⃗b, y). For reasons of symmetry, B ⊨∀yα(⃗b, y) ⇒A ⊨∀yβ(⃗a, y)
holds as well.
Theorem 3.1 is just the application of this lemma for the case n = 0
and has therefore been proved. The method illustrated is wide-ranging
and has many generalizations.
Exercises
1. Let A, B be two inﬁnite discretely ordered sets with the same edge
conﬁguration. Prove that A ∼k B for all k. Hence A, B are elemen-
tarily equivalent.
2. Let A, B ⊨SO11, k > 0, and |A|, |B| ⩾2k −1. Prove that A ∼k B,
so that A ≡k B according to Theorem 3.1.
3. Infer from Exercise 2 that SO11 has the ﬁnite model property and
coincides with the elementary theory FO of all ﬁnite ordered sets.
4. Show that L, R, ∃1, ∃2, . . . constitute a Boolean basis modulo SO
and use this to prove the decidability of SO.4
5.4
Embedding and Characterization Theorems
Many of the foregoing theories, for instance those of orders, of groups in
·, e, −1, and of rings, are universal or ∀-theories, considered already on
page 83. We also know that for every theory T of this kind A ⊆B ⊨T
implies A ⊨T; in short, T is S-invariant. DO obviously does not have
4 Moreover, the theory of all linear orders is decidable (Ehrenfeucht), and thus each of
its ﬁnite extensions; but the proof is incomparably more diﬃcult than for DO or SO.

5.4 Embedding and Characterization Theorems
187
this property, and so there cannot exist an axiom system of ∀-sentences for
it. According to Theorem 4.3 the ∀-theories are completely characterized
by the property of S-invariance. This fact presents a particularly simple
example of the model-theoretic characterization of certain syntactic forms
of axiom systems.
T ∀:= {α ∈T | α is an ∀-sentence} is called the universal part of a
theory T. Note the distinction between the set T ∀and the ∀-theory T ∀,
which of course contains more than just ∀-sentences. For L0 ⊆L put
T ∀
0 := L0 ∩T ∀. If A is an L0-structure and B an L-structure then A ⊆B
or ‘A is a substructure of B ’ will often mean in this section that A is a
substructure of the L0-reduct of B. The phrase ‘A is embeddable into B ’
introduced in 5.1 is to be understood correspondingly. Examples will be
found below. First we state the following
Lemma 4.1. Every T ∀
0 -model A is embeddable into some T-model.
Proof. It is enough to prove (∗) : T + DA is consistent, because A is
embeddable into each B ⊨T + DA by Theorem 1.1. Assume that (∗)
is false. Then there is a conjunction κ(⃗a) of sentences in DA such that
κ(⃗a) ⊢T ⊥, or equivalently, ⊢T ¬κ(⃗a). Here let ⃗a embrace all the constants
of LA that appear in the members of κ but not in T. By the rule (∀3)
of constant quantiﬁcation from 3.2, ⊢T ∀⃗x¬κ(⃗x). Hence ∀⃗x¬κ(⃗x) ∈T ∀
0
and thus A ⊨∀⃗x¬κ(⃗x), a contradiction to A ⊨κ(⃗a).
Lemma 4.2. Md T ∀consists of just the substructures of all T-models.
Proof. Every substructure of a T-model is of course a T ∀-model. Fur-
thermore, each A ⊨T ∀is (by Lemma 4.1 for L0 = L) embeddable into
some B ⊨T, and this is surely equivalent to B′ ≃B and A ⊆B′ for some
B′ ⊨T, because Md T is always closed under isomorphic images.
Example. (a) Let AG be the theory of abelian groups in L{◦}. A sub-
structure of A ⊨AG is obviously a commutative regular semigroup. Con-
versely, it is not hard to prove that every such semigroup is embeddable
into an abelian group. Therefore, the theory AG∀coincides with the the-
ory of the commutative regular semigroups. Warning: noncommutative
regular semigroups need not be embeddable into groups.
(b) Substructures of ﬁelds in L{0, 1, +, −, ·} are integral domains. Con-
versely, according to a basic algebraic construction, every integral domain

188
5 Elements of Model Theory
(not every ring) is embeddable into a ﬁeld, its quotient ﬁeld. It is con-
structed similarly to the ﬁeld Q from the integral domain Z. Hence, by
Lemma 4.2, the theory TJ of integral domains, axiomatized by the axioms
for commutative rings with 1 and without zero-divisors, has the same uni-
versal part as the theory TF of ﬁelds. Also, ACF has the same universal
part, because every ﬁeld is embeddable into some algebraically closed ﬁeld,
its algebraic closure; see [Wae] and Example 1 in 5.5.
Theorem 4.3. T is a universal theory iﬀT is S-invariant.
Proof. This follows immediately from Lemma 4.2, since for an S-invariant
theory T, clearly Md T = Md T ∀. In other words, T is axiomatized by its
universal part T ∀.
This theorem is reminiscent of the HSP theorem cited on page 129.
However, the latter concerns identities only. It has a proof that is akin to
the proof of the following remarkable theorem, which presents an elegant
model-theoretic characterization of universal Horn theories introduced in
4.2. Call a theory T SP-invariant if Md T is closed under direct products
and substructures. Always remember that a statement like A ⊨ϕ(⃗a) with
⃗a ∈An is to mean either A ⊨ϕ(⃗x) [⃗a] or AA ⊨ϕ(⃗a).
Theorem 4.4. T is a universal Horn theory iﬀT is SP-invariant.
Proof. ⇒: Exercise 1 in 4.2. ⇐: Trivial if ⊢T ∀xy x==== y, for then T
is axiomatized by ∀xy x==== y. Otherwise let U be the set of all universal
Horn sentences of T. We prove Md T = Md U. Only Md U ⊆Md T is not
obvious. Let A ⊨U. To verify A ⊨T it suﬃces to show (∗): T ∪DA ⊬⊥,
since for B ⊨T, DA w.l.o.g. A ⊆B, so A ⊨T thanks to S-invariance. Let
P := {π ∈DA | π prime}, so that DA = P ∪{¬πi | i ∈I} for some I ̸= ∅,
all πi prime. We ﬁrst show
	∗∗

: P ⊬T πi for all i ∈I. Indeed, otherwise
⊢T κ(⃗a) →πi(⃗a) for some conjunction κ(⃗a) of sentences in P, with the
tuple ⃗a of constants not in T.
Therefore ⊢T α := ∀⃗x(κ(⃗x) →πi(⃗x)).
Hence α ∈U, for α is a universal Horn sentence in the language of T,
whence A ⊨α. But this contradicts A ⊨κ(⃗a) ∧¬πi(⃗a) and conﬁrms
	∗∗

.
Choose Ai ⊨T, P, ¬πi. Then B := 
i∈I Ai ⊨T ∪P ∪{¬πi | i ∈I} =
T ∪DA (note that B ⊨πi is impossible since Ai ⊨¬πi). This veriﬁes (∗).
The following application of Lemma 4.1 aims in a somewhat diﬀerent
direction.

5.4 Embedding and Characterization Theorems
189
Theorem 4.5. Let L0 ⊆L and let A be an L0-structure. For T ⊆L0 the
following are equivalent:
(i)
A is embeddable into some T-model,
(ii)
every ﬁnitely generated B ⊆A is embeddable into a T-model,
(iii)
A ⊨T ∀
0 (= L0 ∩T ∀).
Proof. (i)⇒(ii): Trivial. (ii)⇒(iii): Let ∀⃗xα ∈T ∀
0 with α = α(⃗x) open,
w.l.o.g. ⃗x = (x1, . . . , xn) ̸= ∅. Let A0 for ⃗a = (a1, . . . , an) ∈An be the
substructure in A generated from a1, . . . , an. By (ii), A0 ⊆B for some
model B ⊨T. Since B ⊨∀⃗xα, it holds that A0 ⊨∀⃗xα; therefore A0 ⊨α(⃗a),
so that A ⊨α(⃗a) by Theorem 2.3.2. Since ⃗a ∈An was chosen arbitrarily,
A ⊨∀⃗xα, and since ∀⃗xα was arbitrarily taken from T ∀
0 , it follows that
A ⊨T ∀
0 . (iii)⇒(i): This is exactly the claim of Lemma 4.1.
Examples of applications. (a) Let T be the theory of ordered abelian
groups in L = L{0, +, −, <}. Such a group is clearly torsion-free, which
is expressed by a schema of ∀-sentences in L0 = L{0, +, −}. Conversely,
Theorem 4.5 implies that a torsion-free abelian group (the A in the theo-
rem) is orderable, or what amounts to the same thing, is embeddable into
an ordered abelian group. One needs to show only that every ﬁnitely gen-
erated torsion-free abelian group G is orderable. By a well-known result
from group theory, G ≃Zn for some n > 0. But Zn can be ordered lexico-
graphically, as is easily seen by induction on n. For nonabelian groups, the
conditions corresponding to torsion-freeness are somewhat more involved.
(b) Without needing algebraic methods we know that there exists a set of
universal sentences in 0, 1, +, −, ·, whose adoption to the theory of ﬁelds
characterizes the orderable ﬁelds.
Suﬃcient for this, by Theorem 4.5,
is the set of all ∀-sentences in 0, 1, +, −, · provable from the axioms for
ordered ﬁelds. Indeed, even the schema of sentences ‘−1 is not a sum of
squares’ is enough to characterize the orderable ﬁelds (see [Wae]).
Not just ∀-theories but also ∀-formulas can be characterized model-
theoretically. Call α(⃗x) S-persistent or simply persistent in T provided
all A, B ⊨T have the property
(sp)
A ⊆B ⊨α(⃗a) ⇒A ⊨α(⃗a), for all ⃗a ∈An.
According to the next theorem this property is characteristic for the ∀-
formulas up to equivalence in T.

190
5 Elements of Model Theory
Theorem 4.6. If α = α(⃗x) is persistent in T then α is equivalent to some
∀-formula α′ in T, which can be chosen such that free α′ ⊆free α.
Proof. Let Y be the set of all formulas ∀⃗yβ(⃗x, ⃗y) with α ⊢T ∀⃗yβ(⃗x, ⃗y),
where β is open and ⃗x and ⃗y are of length n ⩾0 and m ⩾0, respectively.
We shall prove (a): Y ⊢T α(⃗x). This would complete the proof because
then, thanks to free Y ⊆{x1, . . . , xn}, there is a conjunction κ = κ(⃗x)
of formulas from Y with κ ⊢T α. Since also α ⊢T κ, we have α ≡T κ.
Moreover, α′ := κ ∈Y , since Y is closed under conjunction according
to Exercise 3 in 2.4. This proves the claim. For proving (a) we assume
(b) (A,⃗a) ⊨T, Y with ⃗a ∈An. We need to show that (A,⃗a) ⊨α. This
follows from (c): T, α(⃗a), DA is consistent, for if B ⊨T, α(⃗a), DA, then
w.l.o.g. A ⊆B; and also A ⊨α(⃗a) since α is persistent. If (c) were false
then α(⃗a) ⊢T ¬κ(⃗a,⃗b) for some conjunction κ(⃗a,⃗b) of sentences from
DA with the m-tuple ⃗b of constants of κ from A\{a1, . . . , an}.
Thus
α(⃗a) ⊢T ∀⃗y¬κ(⃗a, ⃗y).
Since the a1, . . . , an do not appear in T, we get
α(⃗x) ⊢T ∀⃗y¬κ(⃗x, ⃗y) ∈Y . Therefore, and by (b), (A,⃗a) ⊨∀⃗y¬κ(⃗x, ⃗y), or
equivalently A ⊨∀⃗y¬κ(⃗a, ⃗y), in contradiction to A ⊨κ(⃗a,⃗b).
Remark. Let T be countable and all T-models inﬁnite.
Then α is already
equivalent in T to an ∀-formula, provided α is κ-persistent; this means that
(sp) holds for all T-models A, B of some ﬁxed cardinal κ ⩾ℵ0.
For in this
case each T-model is elementarily equivalent to a model of cardinality κ by the
Löwenheim–Skolem theorems. Hence, it suﬃces to verify (a) in the above proof
by considering only models A, B of cardinality κ.
Sentences of the form ∀⃗x ∃⃗yα with kernel α are called ∀∃-sentences.
Many theories, for instance of real or of algebraically closed ﬁelds and
of divisible groups, are ∀∃-theories, i.e., they possess axiom systems of
∀∃-sentences. We shall characterize the ∀∃-theories semantically.
A chain K of structures is a set K of L-structures such that A ⊆B
or B ⊆A for all A, B ∈K. Chains are very often given as sequences
A0 ⊆A1 ⊆A2 ⊆· · · . No matter how K is given, a structure C :=  K
can be deﬁned in a natural way: Let C := {A | A ∈K} be its domain.
Further, let rC⃗a ⇔rA⃗a for ⃗a ∈Cn, where A ∈K is chosen such that
⃗a ∈An. Such an A ∈K exists: Let A simply be the maximum of the
chain members containing a1, . . . , an, respectively. The deﬁnition of rC is
independent of the choice of A. Indeed, let A′ ∈K and a1, . . . , an ∈A′.
Since A ⊆A′ or A′ ⊆A, it holds that rA⃗a ⇔rA′⃗a in either case. Finally,

5.4 Embedding and Characterization Theorems
191
for function symbols f, let fC⃗a = fA⃗a, where A ∈K is chosen such that
⃗a ∈An. Here too the choice of A ∈K is irrelevant. C was just deﬁned in
such a way that each A ∈K is a substructure of C.
Example 1. Let Dn be the additive group of n-place decimal numbers
(with at most n decimals after the decimal point). Since Dn ⊆Dn+1, the
Dn form a chain. Here D = 
n∈N Dn is just the additive group of ﬁnite
decimal numbers. The corresponding holds if the Dn are understood as
ordered sets. Because then D ⊨DO, while Dn ⊨SO for all n, Md SO is not
closed under union of chains. Therefore SO is not an ∀∃-theory (in contrast
to DO), as follows from a simple observation in the next paragraph.
It is easy to see that an ∀∃-sentence α = ∀x1 · · · xn∃y1 · · · ymβ(⃗x, ⃗y) valid
in all members A of a chain K of structures is also valid in C =  K. For
let ⃗a ∈Cn. Then clearly ⃗a ∈An for some A ∈K, hence A ⊨∃⃗y(⃗a, ⃗y).
Since A ⊆C, it follows that C ⊨∃⃗y(⃗a, ⃗y) according to Corollary 2.3.3.
Now, ⃗a was arbitrarily be chosen, hence indeed C ⊨∀⃗x∃⃗yβ(⃗x, ⃗y). Thus, if
T is an ∀∃-theory then Md T is always closed under union of chains, or as
is said, T is inductive.
This property is characteristic of ∀∃-theories, Theorem 4.9. However,
the proof is no longer simple.
It requires the notion of an elementary
chain. This is a set K of L-structures such that A ≼B or B ≼A, for all
A, B ∈K. Clearly, K is then also a chain with respect to ⊆.
Lemma 4.7 (Tarski’s chain lemma). Let K be an elementary chain
and put C =  K. Then A ≼C for every A ∈K.
Proof. We have to show that A ⊨α(⃗a) ⇔C ⊨α(⃗a), with ⃗a ∈An. This
follows by induction on α = α(⃗x) and is clear for prime formulas. The
induction steps over ∧, ¬ are also straightforward. Let A ⊨∀yα(y,⃗a) and
a0 ∈C arbitrary. There is certainly some B ∈K such that a0, . . . , an ∈B
and A ≼B.
Thus, B ⊨∀yα(y,⃗a) and hence B ⊨α(a0,⃗a).
By the
induction hypothesis (which is supposed to hold for any chain member)
so too C ⊨α(a0,⃗a). Since a0 ∈C was arbitrary, C ⊨∀yα(y,⃗a). The
converse C ⊨∀yα(y,⃗a) ⇒A ⊨∀yα(y,⃗a) follows similarly.
We require yet another useful concept, found in many of the examples
in 5.5. Let A ⊆B. Then A is termed existentially closed in B, in symbols
A ⊆ec B, provided

192
5 Elements of Model Theory
(∗) B ⊨∃⃗xϕ(⃗x,⃗a) ⇒A ⊨∃⃗xϕ(⃗x,⃗a)
(⃗a ∈An),
where ϕ = ϕ(⃗x,⃗a) runs through all conjunctions of literals from LA. (∗)
then holds automatically for all open ϕ ∈LA.
One sees this straight
away by converting ϕ into a disjunctive normal form and distributing ∃⃗x
over the disjuncts. Clearly A ≼B ⇒A ⊆ec B ⇒A ⊆B. Moreover, ⊆ec
satisﬁes a readily proved chain lemma as well: If K is a chain of structures
such that A ⊆ec B or B ⊆ec A for all A, B ∈K, then A ⊆ec
 K for every
A ∈K. This is an easy exercise.
The next lemma presents various characterizations of A ⊆ec B. Let D∀A
denote the universal diagram of A, which is the set of all ∀-sentences of
LA valid in A. Clearly D∀A ⊆Del A. In (iii) the indexing of B with A is
omitted to ease legibility.
Lemma 4.8. Let A, B be L-structures and A ⊆B. Then are equivalent
(i) A ⊆ec B,
(ii) there is an A′ ⊇B such that A ≼A′,
(iii) B ⊨D∀A.
Proof. (i)⇒(ii): Let A ⊆ec B. We obtain some A′ ⊇B such that A ≼A′
as a model of Del A∪DB (more precisely, as the L-reduct of such a model),
so that it remains only to show the consistency. Suppose the opposite, so
that Del A ⊢¬κ(⃗b) for some conjunction κ(⃗b) of members from DB with
the n-tuple ⃗b of all constants of B \A in κ. Since b1, . . . , bn do not occur in
Del A, we get Del A ⊢∀⃗x¬κ(⃗x). Thus A ⊨∀⃗x¬κ(⃗x). On the other hand,
B ⊨κ(⃗b); hence B ⊨∃⃗xκ(⃗x). With (i) and κ(⃗x) ∈LA also A ⊨∃⃗xκ(⃗x),
in contradiction to A ⊨∀⃗x¬κ(⃗x).
(ii)⇒(iii): Since A ≼A′, we have
A′ ⊨Del A ⊇D∀A. Because of B ⊆A′ ⊨D∀A, evidently B ⊨D∀A.
(iii)⇒(i): By (iii), A ⊨α ⇒B ⊨α, for all ∀-sentences α of LA. The
latter is equivalent to B ⊨α ⇒A ⊨α, for all ∃-sentences α ∈LA, and
hence to property (i).
Theorem 4.9. A theory T is an ∀∃-theory if and only if T is inductive.
Proof. As already shown, an ∀∃-theory T is inductive. Conversely let T
be inductive. We show that Md T = Md T ∀∃, where T ∀∃denotes the set
of all ∀∃-theorems provable in T. The nontrivial part is the veriﬁcation
of Md T ∀∃⊆Md T. So let A ⊨T ∀∃. Claim: T ∪D∀A is consistent.
Otherwise ⊢T ¬κ for some conjunction κ = κ(⃗a) of sentences of D∀A
with the tuple ⃗a of constants in A appearing in κ but not in T. Hence
⊢T ∀⃗x¬κ(⃗x). Now, κ(⃗x) is equivalent to an ∀-formula, and so ¬κ(⃗x) to an

5.4 Embedding and Characterization Theorems
193
∃-formula. Thus, ∀⃗x¬κ(⃗x) belongs up to equivalence to T ∀∃. Therefore
A ⊨∀⃗x¬κ(⃗x), which contradicts A ⊨κ(⃗a). This proves the claim.
Now let A1 ⊨T ∪D∀A and w.l.o.g. A1 ⊇A. Then also A ⊆ec A1
in view of Lemma 4.8.
By the same lemma there exists an A2 ⊇A1
with A0 := A ≼A2, so that A2 ⊨T ∀∃as well.
We now repeat this
construction with A2 in place of A0 and obtain structures A3, A4 such that
A2 ⊆ec A3 ⊨T, A3 ⊆A4, and A2 ≼A4. Continuing this construction
produces a sequence A0 ⊆A1 ⊆A2 ⊆· · · of structures with the inclusion
relation illustrated in the following ﬁgure:
A = A0
⊆
A1
⊆
A2
⊆
A3
⊆
A4 ⊆
q
q
q ⊆C




≼
≼
Let C := 
i∈N Ai. Clearly, also C = 
i∈N A2i, and since by construction
A = A0 ≼A2 ≼· · · , we get A ≼C from the chain lemma. At the same
time we also have C = 
i∈N A2i+1, and since by construction A2i+1 ⊨T
for all i, it holds that C ⊨T, for T is inductive. But then too A ⊨T
because A ≼C. This is what we had to prove.
A decent application of the theorem is that SO10 cannot be axiomatized
by ∀∃-axioms, for SO10 is not inductive according to Example 1. SO10 is
an ∀∃∀-theory, and we see now that at least one ∀∃∀-axiom is needed in
its axiomatization.
The “sandwich” construction in the proof of Theorem 4.9 can still be
generalized. We will not elaborate on this but rather add some words
about so-called model compatibility. Let T0 + T1 be the smallest theory
containing T0 and T1. From the consistency of T0 and T1 we cannot in-
fer that T0, T1 are compatible, i.e., T0 + T1 is consistent, even if T0 and
T1 are model compatible in the following sense: every T0-model is em-
beddable into some T1-model and vice versa. This property is equivalent
to T ∀
0 = T ∀
1 by Theorem 4.5, hence it is an equivalence relation. Thus,
the class of consistent L-theories splits into disjoint classes of pairwise
model compatible theories. That model compatible theories need not be
compatible in the ordinary sense is shown by the following
Example 2. DO and SO are model compatible (Exercise 2) but DO + SO
is clearly inconsistent. Since DO is inductive, we get another argument

194
5 Elements of Model Theory
that SO is not inductive: if it were inductive, DO+SO would be consistent
according to Exercise 3.
Exercises
1. Let X be a set of positive sentences, i.e., the α ∈X are constructed
from prime formulas by means of ∧,
∨, ∀, ∃only. Prove that if
A ⊨X then also B ⊨X, whenever B is a homomorphic image of A,
that is, Md X is closed under homomorphic images. Once again the
converse holds (Lyndon’s theorem; see [CK]).
2. Show that the theories DO and SO are model compatible.
3. Suppose T0 and T1 are model compatible and inductive. Show that
T0 + T1 is an inductive theory that, in addition is model compatible
with T0 and T1.
4. For inductive T show that of all inductive extensions model com-
patible with T there exists a largest one, the inductive completion
of T. For instance, this is ACF for the theory TF of ﬁelds.
5.5
Model Completeness
A theory T is called model complete if for every model A ⊨T the theory
T + DA is complete in LA. This notion was introduced in [Ro1]. For
A, B ⊨T where A ⊆B (hence BA ⊨DA), the completeness of T + DA
obviously means the same as AA ≡BA, or equivalently, A ≼B. In short,
a model complete theory T has the property
(∗)
A ⊆B ⇒A ≼B, for all A, B ⊨T.
Conversely, if (∗) is satisﬁed then T + DA is also complete. Indeed, let
B ⊨T, DA so that w.l.o.g. A ⊆B and hence A ≼B. But then all these B
are elementarily equivalent in LA to AA and therefore to each other, which
tells us that T + DA is complete. (∗) is therefore an equivalent deﬁnition
of model completeness, and this deﬁnition, which is easy to remember,
will be preferred in the sequel.
It is clear that if T ⊆L is model complete then so too is every theory
that extends it in L. Furthermore, T is then inductive. Indeed, a chain

5.5 Model Completeness
195
K of T-models is always elementary, by (∗). By Lemma 4.7, we obtain
that A ≼ K for any A ∈K, and therefore  K ⊨T thanks to A ⊨T,
which conﬁrms the claim. Hence, by Theorem 4.9, only an ∀∃-theory can
be model complete.
An example of an ∀∃-theory that is not model complete is DO. Let Qa be
{x ∈Q | a ⩽x} for a ∈Q. Then (Q1, <) ⊆(Q0, <) but (Q1, <) ̸≼(Q0, <)
so that (∗) does not hold. These two models also show that the complete
theory DO10 is not model complete. Another example of a complete but
not model complete theory is SO10, since as was noticed on page 193,
SO10 is not an ∀∃-theory.
Conversely, a model complete theory need
not be complete: A prominent example is ACF, which will be treated in
Theorem 5.4. Nonetheless, with the following theorem the completeness
of a theory can often be obtained more easily than with other methods.
Theorem 5.1. If a theory T is model complete and has a prime model
then T is complete.
Proof.
Suppose that A ⊨T and let P ⊨T be a prime model. Then
P ⊆A up to isomorphism, and so P ≼A by (∗), in particular P ≡A.
Hence, all T-models are elementarily equivalent to each other so that T
is in fact complete.
The following theorem states additional characterizations of model com-
pleteness, of which (ii) is as a rule more easily veriﬁable than the deﬁni-
tion. The implication (ii)⇒(i) carries the name Robinson’s test for model
completeness.
Theorem 5.2. For any theory T the following items are equivalent:
(i) T is model complete,
(ii) A ⊆B ⇒A ⊆ec B, for all A, B ⊨T,
(iii) each ∃-formula α is equivalent in T to an ∀-formula β such that
free β ⊆free α,
(iv) each formula α is equivalent in T to an ∀-formula β such that
free β ⊆free α.
Proof. (i)⇒(ii): evident, since A ⊆B ⇒A ≼B ⇒A ⊆ec B. (ii)⇒(iii):
According to Theorem 4.6 it is enough to verify that every ∃-formula
α = α(⃗x) ∈L is persistent in T. Let A, B ⊨T, A ⊆B, ⃗a ∈An, and

196
5 Elements of Model Theory
B ⊨α(⃗a). Then A ⊨α(⃗a), because A ⊆ec B thanks to (ii). (iii)⇒(iv):
induction on α.
(iii) is used only in the ¬-step: Let α ≡β, β some
∀-formula (induction hypothesis). Then ¬β ≡γ for some ∀-formula γ,
hence ¬α ≡γ. (iv)⇒(i): let A, B ⊨T, A ⊆B, and B ⊨α(⃗a) with ⃗a ∈An.
Then A ⊨α(⃗a), since by (iv), α(⃗x) ≡T β for some ∀-formula β. This
shows that A ≼B, hence (i).
Remark 1. If T is countable and has inﬁnite models only, then it is possible to
restrict the criterion (ii) to models A, B of any chosen inﬁnite cardinal number κ.
Then we can prove that an ∃-formula is κ-persistent as deﬁned in the remark on
page 190, which by the same remark suﬃces to prove the claim of Theorem 5.2
and hence (iii). Once we have obtained (iii) we have also (i). This remark is
signiﬁcant for Lindström’s criterion, Theorem 5.7.
A relatively simple example of a model complete theory is TVQ, the
theory of (nontrivial) Q-vector spaces V = (V, +, 0, Q), where 0 denotes
the zero vector and each r ∈Q is taken to be a unary operation on
the set of vectors V . TVQ formulates the familiar vector axioms, where,
for example, the axiom r(a + b)==== ra + rb is reproduced as a schema of
sentences, namely ∀a∀b r(a + b)==== ra + rb for all r ∈Q. Let V, V′ ⊨TVQ
with V ⊆V′. We claim that V ⊆ec V′. By Theorem 5.2(iii), TVQ is then
model complete. For the claim let V′ ⊨∃⃗xα, with a conjunction α of
literals in x1, . . . , xn and constants a1, . . . , am, b1, . . . , bk ∈V . Then α is
essentially a system of the form
(s)
⎧
⎪
⎪
⎨
⎪
⎪
⎩
r11x1 + · · · + r1nxn ==== a1
s11x1 + · · · + s1nxn̸====b1
...
...
rm1x1 + · · · + rmnxn ==== am
sk1x1 + · · · + sknxn̸====bk
Indeed, the only prime formulas are term equations, and every term in
x1, . . . , xn is equivalent in TVQ to some term of the form r1x1 +· · ·+rnxn.
Without going into detail, it is plausible by the properties of linear systems
that the system (s) has already a solution in V, provided it is solvable at
all; see for instance [Zi].
For the rest of this section we assume some knowledge of classical alge-
bra, where closure constructions are frequently undertaken. For instance,
a torsion-free abelian group has a divisible closure, a ﬁeld A has an alge-
braic closure (a minimal a.c. extension of A), and an ordered ﬁeld has a
real closure; see Example 2 below. Generally speaking, we start from a

5.5 Model Completeness
197
theory T and A ⊨T ∀. By a closure of A in T we mean a T-model ¯
A ⊇A
such that A ⊆B ⇒¯
A ⊆B, for every B ⊨T. More precisely, if A ⊆B
then there is an embedding of ¯
A into B leaving A pointwise ﬁxed. In this
case we say that T permits a closure operation.
Supposing this, let A, B ⊨T, A ⊂B, and b ∈B \A. Then there is a
smallest submodel of B containing A ∪{b}, the T ∀-model generated in B
by A ∪{b}, denoted by A(b). Its closure in T is denoted by Ab. In view
of A ⊂Ab ⊆B, it is called an immediate extension of A in T.
Example 1. Let T := ACF. A T ∀-model A is here an integral domain.
T permits a closure operation:
¯
A is the so-called algebraic closure of
the quotient ﬁeld of A. That there exists an a.c. ﬁeld ¯
A ⊇A that in
addition is embeddable into every a.c. ﬁeld B ⊇A, is Steinitz’s theorem
regarding a.c. ﬁelds, [Wae, p. 201]. Let now A, B ⊨T with A ⊂B and
b ∈B \A.
Then b is transcendental over A, because A is a.c.
Thus,
a0 + a1b + · · · + anbn ̸= 0, for all a0, . . . , an ∈A with an ̸= 0. For this
reason A(b) is isomorphic to the ring A(x) of polynomials 
i⩽n aixi with
the “unknown” x (the image of b). Hence, A(b) ≃A(x) ≃A(c) provided
A, B, C ⊨T, with A ⊂B, C and b ∈B \A, c ∈C \A. The isomorphism of
A(b), A(c) extends in a natural way to their quotient ﬁelds (represented
by the ﬁeld of rational functions over A) and hence to their closures Ab
and Ac. Thus, a T-model has up to isomorphism only one immediate
extension in T. Not so in the next, more involved, example.
Example 2. A real closed ﬁeld is an ordered ﬁeld A (such as R) in which
every polynomial of odd degree has a zero and every a ⩾0 is a square
in A. These properties will turn out to be equivalent to the continuity
scheme CS (p. 110). Let RCF denote the theory of these ﬁelds. Although
⩽is deﬁnable in RCF by x ⩽y ↔∃z y −x==== z2, order should here be
a basic relation. Let T := RCF. A T ∀-model A is an ordered integral
domain that determines the order of its quotient ﬁeld Q. According to
Artin’s theorem for real closed ﬁelds [Wae, p. 244], some ¯
A = ¯Q ⊨T can
be constructed, called the real closure of A or of its quotient ﬁeld Q in T.
Let A, B ⊨RCF, A ⊂B, and b ∈B \A.
Then b is transcendental
over A, because no algebraic extension of A is orderable—this is another
characterization of real closed ﬁelds. Here A(b) is isomorphic to the or-
dered ring A(x) of polynomials over A and determines the isomorphism

198
5 Elements of Model Theory
type of its quotient ﬁeld Q(b) and of its real closure Ab = Q(b). Actu-
ally, <Ab is determined by its restriction to A ∪{b}, or by the partition
A = {a ∈A | a <Ab b} ∪{a ∈A | b <Ab a}. To see this, note that it
is provable in RCF that a polynomial p(x) with the zeros a1, . . . , an ∈A
decomposes in A ⊨RCF as c · q(x) · n
i=1(x −ai) with c ∈A, n ⩾0, and
q(x) a product of irreducible polynomials of degree 2 or q(x) = 1. In Q(b)
(and Ab) one has q(b) > 0. Indeed, each irreducible factor b2 + db + e of
q(b) is > 0 since b2 + db + e = (b + d
2)2 + e −d2
4 > 0 (d, e ∈A). Thus
we know whether p(b) > 0 if we know the signs of b −ai for all zeros ai
of p(x) in A. This suﬃces to ﬁx the order in Q(b) as is easily seen, and
hence in Ab by Artin’s theorem.
For inductive theories T that permit a closure operation, Robinson’s
test for model completeness can still be simpliﬁed as follows:
Lemma 5.3. Let T be inductive, and suppose T permits a closure opera-
tion. Assume further that A ⊆ec A′ for all A, A′ ⊨T in the case that A′
is an immediate extension of A in T. Then T is model complete.
Proof. Let A, B ⊨T, A ⊆B. By Theorem 5.2(ii) it suﬃces to show that
A ⊆ec B. Let H be the set of all C ⊆B such that A ⊆ec C ⊨T. Trivially
A ∈H. Since T is inductive, a chain K ⊆H satisﬁes  K ⊨T. One easily
veriﬁes A ⊆ec
 K as well, so that  K ∈H. By Zorn’s lemma there is
a maximal element Am ∈H. Claim: Am = B. Assume Am ⊂B. Then
there is an immediate extension A′
m ⊨T of Am such that Am ⊂A′
m ⊆B.
Since A ⊆ec Am, and by hypothesis Am ⊆ec A′
m, we get A ⊆ec A′
m. This,
however, contradicts the maximality of Am in H. Therefore, it must be
the case that Am = B. Consequently, A ⊆ec B.
Theorem 5.4. ACF is model complete and thus so too ACFp, the theory
of a.c. ﬁelds of given characteristic p (= 0 or a prime). Moreover, ACFp
is complete.
Proof. Let A, B ⊨ACF, A ⊂B, and b ∈B \A. By Lemma 5.3 it suﬃces
to show that A ⊆ec Ab. Here Ab is an immediate extension of A in ACF.
Let α := ∃⃗xβ(⃗x,⃗a) ∈LA, β quantiﬁer-free, and Ab ⊨α. We shall prove
A ⊨α and for this we consider
X := ACF ∪DA ∪{p(x)̸====0 | p(x) a monic polynomial on A}.

5.5 Model Completeness
199
With b for x one sees that (Ab, b) ⊨X (for b is trancendental over A). Let
(C, c) ⊨X, with c for x. Since C ⊨DA, w.l.o.g. A ⊆C. By Example 1
Ab ≃Ac, and so Ac ⊨α. Ac ⊆C implies C ⊨α, for α is an ∃-sentence.
Since (C, c) has been chosen arbitrarily we obtain X ⊢α, and from this
by the ﬁniteness theorem evidently
DA, 
i⩽k pi(x)̸====0 ⊢ACF α,
for some k and monic polynomials p0, . . . , pk. Particularization and the
deduction theorem show that DA ⊢ACF ∃x 
i⩽k pi(x) ̸==== 0 →α.
Every
a.c. ﬁeld is inﬁnite (Example 5(c) in 5.2), and a polynomial has only
ﬁnitely many zeros in a ﬁeld. Thus, DA ⊢ACF ∃x 
i⩽k pi(x)̸====0. Hence,
DA ⊢ACF α and so A ⊨α. This proves A ⊆ec Ab and in view of Lemma 5.3
the ﬁrst part of the theorem. The algebraic closure of the prime ﬁeld
of characteristic p is obviously a prime model for ACFp. Therefore, by
Theorem 5.1, ACFp is complete.
The following signiﬁcant theorem is won similarly.
It was originally
proved in [Ta3] by means of quantiﬁer elimination. Incidentally, the claim
of completeness is not obtainable by means of Vaught’s criterion, in con-
trast to the case of ACF.
Theorem 5.5. The theory RCF of real closed ﬁelds is model complete
and complete. It is thus identical to the theory of the ordered ﬁeld of real
numbers, and as a complete axiomatizable theory it is also decidable.
Proof. Let A ⊨RCF. It once again suﬃces to show that A ⊆ec Ab for
an immediate extension Ab of A in RCF. Let U := {a ∈A | a <B b},
V := {a ∈A | b <B a}, with B := Ab. Then U ∪V = A. Now let
Ab ⊨∃⃗xβ(⃗x,⃗a), β quantiﬁer-free, ⃗a ∈Am. The model (B, b) with b for x
then clearly satisﬁes the set of formulas
X := RCF ∪DA ∪{a < x | a ∈U} ∪{x < a | a ∈V }.
Suppose (C, c) ⊨X, interpreting x as c. We may assume A ⊆C because
C ⊨DA. Since c /∈U ∪V = A, c is transcendental over A (see Example 2).
Hence, the quotient ﬁeld Q(c) of A(c) is isomorphic to the ﬁeld of rational
functions over A with the unknown x. The order of Q(c) is ﬁxed by the
partition A = U ∪V coming from Q(b). Thus, Q(b) ≃Q(x) ≃Q(c).
The isomorphism Q(b) ≃Q(c) extends to one between the real closures
Ab and Ac. As in Theorem 5.4 we thus obtain X ⊢α, and so for some

200
5 Elements of Model Theory
a1, . . . , ak, b1, . . . , bl ∈A (where k, l ⩾0 but k + l > 0),
DA ⊢RCF ∃x(k
i=1 ai < x ∧l
i=1 x < bi) →α
(ai ∈U, bi ∈V ).
Now, an ordered ﬁeld is densely ordered without edge elements, hence is
inﬁnite. Therefore, ⊢RCF ∃x(k
i=1 ai < x ∧l
i=1 x < bi) which results in
DA ⊢RCF α. Thus, A ⊨α, and A ⊆ec Ab is proved. To verify completeness
observe that RCF has a prime model, namely the real closure of Q, the
ordered ﬁeld of all real algebraic numbers. Applying Theorem 5.1 once
again conﬁrms the completeness of RCF.
A theory T is called the model completion of a theory T0 of the same
language if T0 ⊆T and T +DA is complete for every A ⊨T0. Clearly, T is
then model complete; moreover, T is model compatible with T0 (A ⊨T0
implies (∃C∈Md T)A ⊆C, since T + DA is consistent). The existence
of a model complete extension is necessary for the existence of a model
completion of T0, but not suﬃcient. See Exercise 1.
Remark 2. A somewhat surprising fact is that a model completion of T is
uniquely determined provided it exists. Indeed, let T, T ′ be model completions
of T0. Both theories are model compatible with T0, and hence with each other.
T, T ′ are model complete and therefore inductive, so that T + T ′ is model com-
patible with T (Exercise 3 in 5.4).
Thus, if A ⊨T then there exist some
B ⊨T + T ′ with A ⊆B, and since T is model complete we obtain A ≼B.
This implies A ≡B ⊨T ′, and consequently A ⊨T ′. For reasons of symmetry,
A ⊨T ′ ⇒A ⊨T as well. Therefore T = T ′.
Example 3. ACF is the model completion of the theory TJ of integral
domains, hence also of the theory TF of ﬁelds. Indeed, let A ⊨TJ. By
Theorem 5.4, ACF is model complete, hence also T := ACF+DA (in LA).
Moreover, T is complete, since by Example 1, T has a prime model, the
closure ¯
A of A in ACF. Using Theorem 5.5, one shows analogously that
RCF is the model completion of the theory of ordered commutative rings
with unit element. Each such ring is embeddable into an ordered ﬁeld (an
algebraic standard construction) and hence into a real closed ﬁeld.
A ⊨T is called existentially closed in T, or ∃-closed in T for short, if
A ⊆ec B for each B ⊨T with A ⊆B. For instance, every a.c. ﬁeld A is
∃-closed in the theory of ﬁelds. For let B ⊇A be any ﬁeld and C be any
a.c. extension of B. Then A ≼C thanks to the model completeness of
ACF. Hence A ⊆ec B by Lemma 4.8(ii). The following lemma generalizes
in some sense the fact that every ﬁeld is embeddable into an a.c. ﬁeld.

5.5 Model Completeness
201
Similarly, a group, for instance, is embeddable into a group that is ∃-
closed in the theory of groups.
Lemma 5.6. Let T be an ∀∃-theory of some countable language L. Then
every inﬁnite model A of T can be extended to a model A∗of T such that
|A∗| = |A|, which is ∃-closed in T.
Proof. For the proof we assume, for simplicity, that A is countable. Then
LA is also countable. Let α0, α1, . . . be an enumeration of the ∃-sentences
of LA and A0 = AA.5 Let An+1 be an extension of An in LA such that
An+1 ⊨T + αn, as long as such an extension exists; otherwise simply put
An+1 = An. Since T is inductive, B0 = 
n∈N An ⊨T. If α = αn is
an ∃-sentence in LA valid in some extension B ⊨T of B0, then already
An+1 ⊨α and thus also B0 ⊨α. Now we repeat this construction with B0
in place of A0 with respect to an enumeration of all ∃-sentences in LB0
and obtain an LB0-structure B1 ⊨T. Subsequent reiterations produce a
sequence B1 ⊆B2 ⊆· · · of LBn-structures Bn+1 ⊨T. Let A∗(⊨T) be
the L-reduct of 
n∈N Bn ⊨T and A∗⊆B ⊨T. Assume B ⊨∃⃗xβ(⃗a, ⃗x),
⃗a ∈(A∗)n. Then Bm ⊨β(⃗a,⃗b) for suitable m. Hence 
n∈N Bn ⊨β(⃗a,⃗b),
and so A∗⊨∃⃗xβ(⃗a, ⃗x).
With this lemma one readily obtains the following highly applicable
criterion for proving the model completeness of countable κ-categorial
theories, which, by Vaught’s criterion, are always complete.
Theorem 5.7 (Lindström’s criterion). A countable κ-categorical ∀∃-
theory T without ﬁnite models is model complete.
Proof. Since all T-models are inﬁnite, T has a model of cardinality κ,
and by Lemma 5.6 also one that is ∃-closed in T. But then all T-models
of cardinality κ are ∃-closed in T, because all these are isomorphic. Thus
A ⊆B ⇒A ⊆ec B, for all A, B ⊨T of cardinality κ. Therefore, T is
model complete according to Remark 1 on page 196.
Examples of applications.
(a) The ℵ0-categorical theory of atomless Boolean algebras.
(b) The ℵ1-categorical theory of nontrivial Q-vector spaces.
(c) The ℵ1-categorical theory of a.c. ﬁelds of given characteristic.
5 For uncountable A we have |LA| = |A|. In this case one proceeds with an ordinal
enumeration of LA rather than an ordinary one. But the proof is almost the same.

202
5 Elements of Model Theory
A few comments: A Boolean algebra B is called atomless if for each
a ̸= 0 in B there is some b ̸= 0 in B with b < a (< is the partial lattice
order of B). The proof of (a) is similar to that for densely ordered sets.
Also (b) is easily veriﬁed. Observe that a Q-vector space of cardinality
ℵ1 has a base of cardinality ℵ1. From (c) the model completeness of ACF
follows in a new way: If A, B ⊨ACF and A ⊆B then both ﬁelds have the
same characteristic p ⩾0. Since ACFp is model complete by (c), A ≼B
follows. This obviously implies that ACF itself is model complete.
Exercises
1. Prove that of the four theories DOij only DO00 is model complete.
Moreover, show that DO00 is the model completion of both DO and
the theory Tord of all orders, but not of the theory of all irreﬂexive
relations which is not model-compatible with Tord.
2. Let T be the theory of divisible torsion-free abelian groups. Show
that T is the model completion of the theory T0 of torsion-free
abelian groups.
3. T ∗is called the model companion of T provided T, T ∗are model
compatible and T ∗is model complete. Show that if T ∗exists then
T ∗is uniquely determined provided it exists. Moreover, show that
each A ∈Md T ∗is ∃-closed in T.
4. Prove that an ∀∃-sentence valid in all ﬁnite ﬁelds is valid also in all
a.c. ﬁelds. This fact is highly useful in algebraic geometry.
5.6
Quantiﬁer Elimination
Because ∃x(y < x ∧x < z) ≡DO y < z, in the theory of densely or-
dered sets the quantiﬁer in the left-hand formula can be eliminated. In
fact, in some theories, including the theory DO00 (see 5.2), the quantiﬁers
can be eliminated from every formula. One says that T (⊆L0) allows
quantiﬁer elimination if for every ϕ ∈L there exists some open formula
ϕ′ ∈L such that ϕ ≡T ϕ′. Quantiﬁer elimination is the oldest method

5.6 Quantiﬁer Elimination
203
of showing that certain theories are decidable and occasionally also com-
plete. Some presentations demand additionally free ϕ′ = free ϕ, but one
is not obliged to to do so. A theory T that allows quantiﬁer elimina-
tion is model complete by Theorem 5.2(iv), because open formulas are
∀-formulas. Hence, T is an ∀∃-theory, which is a remarkable necessary
condition for quantiﬁer eliminability.
In order to conﬁrm quantiﬁer elimination for a theory T it suﬃces to
eliminate the preﬁx ∃x from every formula of the form ∃xα, where α is
open. Indeed, think of all subformulas of the form ∀xα in a formula ϕ
as being equivalently replaced by ¬∃x¬α, so that only the ∃-quantiﬁer
appears in ϕ. Looking at the farthest-right preﬁx ∃x in ϕ one can write
ϕ = · · · ∃xα · · · with some quantiﬁer-free α. Now, if ∃xα is replaceable
by an open formula α′ then this process can be iterated no matter how
long it takes for all ∃-quantiﬁers in ϕ to disappear.
Thanks to the ∨-distributivity of ∃-quantiﬁers we may moreover assume
that the quantiﬁer-free part α of ∃xα from which ∃x has to be eliminated
is a conjunction of literals, and that x explicitly occurs in each of these
literals: simply convert α into a DNF and distribute ∃x over the disjuncts
such that ∃x stands in front of a conjunction of literals only. If x does
not appear in any of these literals, ∃x can simply be discarded. Otherwise
remove the literals not containing x beyond the scope of ∃x, observing
that ∃x(α ∧β) ≡∃xα ∧β if x /∈var β.
Furthermore, it can be supposed that none of the conjuncts is of the form
x==== t with x /∈var t. Indeed, since ∃x(x==== t ∧α) ≡α tx , the quantiﬁer has
then already been eliminated. We may also assume x ̸= v0 (using bound
renaming) and that neither x==== x nor x̸====x is among the conjuncts. For
x==== x can equivalently be replaced by ⊤, as can x̸====x by ⊥. Here one may
deﬁne ⊤and ⊥as v0 ==== v0 and v0 ̸==== v0, respectively. Replacement will
then introduce v0 as a possible new free variable, but that is harmless. If
the language contains a constant c one may replace v0 by c in the above
consideration. If not, one may add a constant or even ⊥as a new prime
formula to the language, similar to what is proposed below for DO00.
Call an ∃-formula simple if it is of the form ∃x 
i αi, where every αi
is a literal with x ∈var αi. Then the above considerations result in the
following theorem.

204
5 Elements of Model Theory
Theorem 6.1. T allows quantiﬁer elimination if every simple ∃-formula
∃x 
i αi is equivalent in T to some open formula. Here w.l.o.g., none of
the literals αi is x==== x, x̸====x, or of the form x==== t with x /∈var t.
Example 1. T = DO00 allows quantiﬁer elimination. Because of
y ≮z ≡T z < y ∨z ==== y and z̸====y ≡T z < y ∨y < z
and since in general (α ∨β) ∧γ ≡(α ∧γ) ∨(β ∧γ), we may suppose that
the conjunction of the αi in Theorem 6.1 does not contain the negation
symbol. We are therefore dealing with a formula of the form
∃x(y1 < x ∧· · · ∧ym < x ∧x < z1 ∧· · · ∧x < zk),
which is equivalent to ⊥(≡v0̸====v0) if x is one of the variables yi, zj, or to
⊤whenever m = 0 or k = 0, and in the remaining case to n
i,j=1 yi < zj.
Who wants to avoid the use of v0 as an extra variable may also regard at
⊥as an additional 0-ary relation symbol.
DO itself does not allow quantiﬁer elimination, since in α(y) := ∃x x < y
the quantiﬁer is not eliminable. Indeed, if α(y) were equivalent in DO to an
open formula then A, B ⊨DO, A ⊆B, a ∈A, and B ⊨α(a) would imply
A ⊨α(a). But this is not so for the densely ordered sets A, B with A =
{x ∈Q | 1 ⩽x} and B = Q. Choose a = 1. Quantiﬁer elimination does
however become possible if the signature {<} is expanded by considering
L, R as 0-ary predicate symbols. The fact that {L, R} forms a Boolean
basis for sentences in DO is not yet suﬃcient for quantiﬁer eliminability
if looking at L and R as formulas, for these contain quantiﬁers.
Also the theory SO does not allow quantiﬁer elimination in the original
language, simply because it is not an ∀∃-theory as was noticed earlier.
The same is true for the expansions SOij of SO.
Example 2. A classical and nontrivial result of quantiﬁer elimination
by Presburger [Pr] refers to Th (N, 0, 1, +, <), with the additional unary
predicate symbols m (m = 2, 3, . . . ), deﬁned by m x ↔∃y my ==== x, where
my denotes the m-fold sum y+· · ·+y of y. We shall prove a related result
with respect to the group Z in L{0, 1, +, −, <, 2 , 3 , . . . }. Denote the k-
fold sum 1 + · · · + 1 by k, and set (−k)x := −kx.
Let ZGE be the elementary theory in L{0, 1, +, −, <, 2 , 3 , . . . } whose
axioms subsume those for ordered abelian groups plus the axioms
∀x(0 < x ↔1 ⩽x), ∀x(m x ↔∃y my ==== x), and ϑm := ∀x 
k<m m x + k

5.6 Quantiﬁer Elimination
205
for m = 2, 3, . . . The reducts of ZGE-models to L := L{0, 1, +, −, <} are
called Z-groups. These are ordered with the smallest positive element 1.
The ϑm state for a Z-group G that the factor groups G/mG are cyclic of
order m. Here mG := {mx | x ∈G}. Let ZG denote the reduct theory
of ZGE in L. Its models are precisely the Z-groups. ZGE is a deﬁnitorial,
hence conservative extension of ZG (cf. 2.6).
It will turn out that Z-
groups are just the ordered abelian groups elementarily equivalent to the
paradigm of a Z-group, (Z, 0, 1, +, −, <). Let us notice that ⊢ZG ∀xηn for
each n, where ηn is the formula 0 ⩽x < n →
k<n x==== k.
We are now going to prove that ZGE allows quantiﬁer elimination. Ob-
serve ﬁrst that since t ̸==== s ≡ZGE s < t ∨t < s, m̸
t ≡ZGE
m−1
i=1 m t + i,
and m t ≡ZGE m −t, we may assume that the kernel of a simple ∃-formula
is a conjunction of formulas of the form nix==== t0
i , n′
ix < t1
i , t2
i < n′′
i x, and
mi n′′′
i x+t3
i , where x /∈var tj
i. By multiplying these formulas by a suitable
integer and using t < s ≡ZGE nt < ns and m t ≡ZGE nm nt for n ̸= 0, one
sees that all the ni, n′
i, n′′
i , n′′′
i can be made equal to some number n > 1.
Clearly, in doing so, tj
i and the “modules” mi all change. But the problem
of elimination is thus reduced to formulas of the following form, where the
jth conjunct disappears whenever kj = 0 (j ⩽3):
(1) ∃x
	 k0
i=1 nx==== t0
i ∧k1
i=1 t1
i < nx ∧k2
i=1 nx < t2
i ∧k3
i=1 mi nx + t3
i

.
With y for nx and m0 = n, (1) is certainly equivalent in ZGE to
(2) ∃y
	 k0
i=1 y ==== t0
i ∧k1
i=1 t1
i < y ∧k2
i=1 y < t2
i ∧k3
i=1 mi y + t3
i ∧m0 y

.
According to Theorem 6.1 we can at once assume that k0 = 0, so that the
elimination problem, after renaming y back to x, reduces to formulas of
the following form, where x /∈var tj
i:
(3) ∃x
	 k1
i=1 t1
i < x ∧k2
i=1 x < t2
i ∧k3
i=0 mi x + t3
i

.
Let m be the least common multiple of m0, . . . , mk3.
Case 1: k1, k2 = 0. Then (3) is equivalent in ZGE to m
j=1
k3
i=0 mi j + t3
i .
Indeed, if an x such that k3
i=0 mi x + t3
i exists at all, then so does some
x = j ∈{1, . . . , m}. For let j with m x + (m −j) be given by axiom ϑm.
Then also m x −j and consequently mi x −j for all i ⩽k3. Therefore
mi x + t3
i −(x −j) = j + t3
i also holds for i = 0, . . . , k3 as was claimed.
Case 2: k1 ̸= 0 and j as above. Then (3) is equivalent to
(4) k1
μ=1[k1
i=1 t1
i ⩽t1
μ ∧m
j=1(k2
i=1 t1
μ + j < t2
i ∧k3
i=0 mi t1
μ + j + t3
i )].
This is a case distinction according to the maximum among the values of

206
5 Elements of Model Theory
the t1
i . From each disjunct in (4) certainly (3) follows in ZGE (consider
t1
i < t1
μ + j). Now suppose conversely that x is a solution of (3). Then in
the case k1
i=1 t1
i ⩽t1
μ the μth disjunct of (4) is also valid. To prove this
we need only conﬁrm t1
μ + j < t2
i , which comes down to t1
μ + j ⩽x. Were
x < t1
μ + j, i.e., 0 < x −t1
μ < j, then x −t1
μ = k follows for some k < j by
ηj, that is, x = t1
μ + k. Thus, mi t1
μ + j −x = j −k for all i ⩽k3. But
this yields the contradiction m j −k < m.
Case 3: k1 = 0 and k2 ̸= 0. The argument is analogous to Case 2 but
with a distinction according to the smallest term among the t2
i .
From this remarkable example we obtain the following
Corollary 6.2. ZGE is model complete. Moreover, ZGE and ZG are both
complete and decidable.
Proof. Since Z determines a prime model for ZGE, completeness follows
from model completeness, which in turn follows from quantiﬁer eliminabil-
ity. Clearly, along with ZGE also its reduct theory ZG is complete. Hence,
as complete axiomatizable theories, both these theories are decidable.
Remark 1. Also ZG is model complete; Exercise 1. Actually, ZG is the model
completion of the theory of discretely ordered abelian groups because every such
group is embeddable into some Z-group (which is not quite easy to prove). This
is a main reason for the interest in ZG. Although model complete, ZG does not
allow quantiﬁer elimination.
We now intend to show that theories ACF and RCF of algebraically and
real closed ﬁelds respectively allow quantiﬁer elimination, even without
any expansion of their signatures. Attacking the elimination problem in a
direct manner as above would ﬁll a separate chapter. We therefore under-
take a model-theoretic proof in Theorem 6.4, applying thereby a variant
of Theorem 2.3. Call X ⊆L a Boolean basis for L in T if every ϕ ∈L
belongs to ⟨X⟩, the set of Boolean combinations of formulas from X. Let
M, M′ be L-models. Write M ≡X M′ whenever M ⊨ϕ ⇔M′ ⊨ϕ, for
all ϕ ∈X, and M ≡M′ whenever M ⊨ϕ ⇔M′ ⊨ϕ, for all ϕ ∈L.
Theorem 6.3 (Basis theorem for formulas). Let T ⊆L0 be a theory,
X ⊆L, and suppose that M ≡X M′ ⇒M ≡M′, for all M, M′ ⊨T.
Then X is a Boolean basis for L in T.
Proof. Let α ∈L and Yα := {γ ∈⟨X⟩| α ⊢T γ}, where ⟨X⟩is deﬁned as
on page 180. One then shows that Yα ⊢T α as in the proof of Theorem 2.3

5.6 Quantiﬁer Elimination
207
by arguing with a model M rather than a structure A. The remainder of
the proof proceeds along the lines of the proof of the mentioned theorem
and is therefore left to the reader.
A theory T is called substructure complete if for all A, B with A ⊆B ⊨T
the theory T + DA is complete. This generalizes model completeness and
is basically only a reformulation of ‘T is the model completion of T ∀’.
Indeed, let T be substructure complete and A ⊨T ∀. Then by Lemma 4.1,
A ⊆B for some B ⊨T, hence T + DA is complete.
Thus, T is the
model completion of T ∀. Conversely, let T be the model completion of
T ∀and A ⊆B ⊨T. Then A ⊨T ∀, so that T + DA is complete. Thus,
T is substructure complete. The criterion (ii) in the next theorem may
therefore also be reformulated. There exist yet other criteria, in particular
the amalgamability of models of T ∀; see e.g. [CK].
Theorem 6.4. For every theory T in L the following are equivalent:
(i) T allows quantiﬁer elimination,
(ii) T is substructure complete.
Proof. (i)⇒(ii): Let A be a substructure of a T-model, ϕ(⃗x) ∈L, and
⃗a ∈An such that A ⊨ϕ [⃗a].
Further, let B ⊨T, DA so that w.l.o.g.
B ⊇A. Then also B ⊨ϕ(⃗a), because in view of (i) we may suppose that ϕ
is open. Since B was arbitrary, DA ⊢T ϕ(⃗a). Hence T + DA is complete.
(ii)⇒(i): Let X denote the set all of literals of L. It suﬃces to prove
(∗)
M ≡X M′ ⇒M ≡M′, for all M, M′ ⊨T,
for then X is a Boolean basis for L in T according to Theorem 6.3. This
obviously amounts to saying that T allows quantiﬁer elimination.
Let
M, M′ ⊨T, M = (A, w), M ⊨ϕ(⃗x), ⃗x ̸= ∅, and a1 = xw
1 , . . . , an = xw
n .
Let AE be the substructure generated in A from E := {a1, . . . , an}. By
(ii), T + DAE is complete and consistent with ϕ(⃗a), since AA satisﬁes
T + DAE + ϕ(⃗a). Hence DAE ⊢T ϕ(⃗a). Moreover, DAE ∩LE ⊢T ϕ(⃗a)
by Exercise 5 in 5.1. Thus, by the ﬁniteness theorem, there are literals
λ0(⃗x), . . . , λk(⃗x) ∈L with λi(⃗a) ∈DAE and 
i⩽k λi(⃗a) ⊢T ϕ(⃗a). There-
fore 
i⩽k λi(⃗x) ⊢T ϕ(⃗x), because a1, . . . , an do not appear in T. Since
M ⊨
i⩽k λi(⃗x) and M ≡X M′, also M′ ⊨
i⩽k λi(⃗x) and so M′ ⊨ϕ(⃗x).
The above holds for arbitrary formulas ϕ(⃗x) ∈L provided ⃗x ̸= ∅. These
include sentences as well which completes the proof of (∗).

208
5 Elements of Model Theory
Corollary 6.5. An ∀-theory T permits quantiﬁer elimination if and only
if T is model complete.
Proof. Due to A ⊆B ⊨T ⇒A ⊨T, (ii) in Theorem 6.4 is satisﬁed
provided only that T + DA is complete for all A ⊨T. But this is granted
if T is model complete.
Example 3. Let T be the ∀-theory with two unary function symbols f, g
whose axioms state that f and g are injective, f and g are mutually inverse
(∀x fgx==== x and ∀x gfx==== x), and there are no circles, i.e., no sequences
x0, . . . , xn (n > 0) such that xi+1 = fxi and x0 = xn. This implies in
particular ∀x x̸====fx. Note that ∀y∃xfx==== y is provable (choose x = gy).
Hence, f and g are bijective. The T-models consist of disjoint countable
inﬁnite “threads,” which occurred also in Example 3 in 5.2. Hence, T is
ℵ1-categorical and thus model complete by Lindström’s criterion. By the
corollary, T permits the elimination of quantiﬁers.
Theorem 6.6. ACF and RCF allow quantiﬁer elimination.
Proof. By Theorem 6.4 it is enough to show that ACF and RCF are
substructure complete, or put another way, ACF and RCF are the model
completions of ACF∀and RCF∀, respectively. Both claims are clear from
Example 3 in 5.5 according to which ACF∀coincides with the theory of
integral domains, and RCF∀with the theory of ordered commutative rings
with a unit element.
Theorem 6.6 was originally proved by Tarski in [Ta3]. While thanks to
a host of model-theoretic methods the above proof is signiﬁcantly shorter
than Tarski’s original, the latter is still of import in many algorithmic
questions. Decidability and eliminability of quantiﬁers in RCF have great
impact also on other ﬁelds of research, in particular on the foundations of
geometry, which are not treated in this book. Let us mention that both
Euclidean and non-Euclidean geometry can entirely be based on RCF and
hence are decidable as well.
Remark 2. Due to the completeness of RCF, one may also say that the ﬁrst-
order theory of the ordered ﬁeld R allows quantiﬁer elimination. Incidentally,
the quantiﬁers in RCF are not eliminable if the order, which is deﬁnable in RCF,
is not considered as a basic relation. Also T := Th (R, <, 0, 1, +, −, ·, exp), a
(complete) theory with the exponential function exp in the language, does not
allow quantiﬁer elimination. Nonetheless, T is model complete, as was shown

5.7 Reduced Products and Ultraproducts
209
in [Wi]. Because of its completeness, the decision problem for T reduces to the
still unsolved axiomatization problem, whose solution hinges on the unanswered
problem concerning transcendental numbers, Schanuel’s conjecture, which lies
outside the scope of logic (consult the Internet). A particular question related
to the conjecture is whether ee is transcendental.
Exercises
1. Show that the theory ZG is model complete in its language, and even
in the language L{0, 1, +, −}.
2. A structure elementarily equivalent to (N, 0, 1, +, <) is called an
N-semigroup.
Axiomatize the theory of N-semigroups and show
(by tracing back to ZG) that it allows quantiﬁer elimination in
L{0, 1, +, <, 1 , 2 , . . . }.
3. Let RCF◦be the theory of real closed ﬁelds without order as a basic
notion. Prove that ∃y is not eliminable in α(x) = ∃y y · y ==== x in the
frame of RCF◦.
4. Show that RCF is axiomatized alternatively by the axioms for or-
dered ﬁelds and the continuity scheme in 3.3 page 110.
5. Show that the theory T of divisible ordered abelian groups allows
quantiﬁer elimination.
5.7
Reduced Products and Ultraproducts
In order to merely indicate the usefulness of the following constructions
consider for instance Zn, a direct power of the additive group Z.
By
componentwise veriﬁcation of the axioms it can be shown that Zn is itself
an abelian group (n ⩾2). But in this and similar examples we can save
ourselves the bother, because by Theorem 7.5 below a Horn sentence valid
in all Ai is also valid in the direct product 
i∈I Ai, and the group axioms
are Horn sentences in each reasonable signature for groups.
Let (Ai)i∈I be a family of L-structures and F a proper ﬁlter on a
nonempty index set I (see page 34).
We deﬁne a relation ≈F on the
domain B of the product B := 
i∈I Ai by
a ≈F b ⇔{i ∈I | ai = bi} ∈F.

210
5 Elements of Model Theory
This is an equivalence relation on B. Indeed, let Ia=b := {i ∈I | ai = bi}.
≈F is reﬂexive (since Ia=a = I ∈F) and trivially symmetric, but also
transitive, because Ia=b, Ib=c ∈F ⇒Ia=c ∈F, thanks to the obvious fact
Ia=b ∩Ib=c ⊆Ia=c.
Furthermore, ≈F is a congruence in the algebraic reduct of B.
To
see this let f be an n-ary function symbol and ⃗a ≈F ⃗b (which for ⃗a =
(a1, . . . , an), ⃗b = (b1, . . . , bn) in Bn abbreviates a1 ≈F b1, . . . , an ≈F bn).
Then clearly I⃗a=⃗b := n
ν=1 Iaν=bν belongs to F. Since certainly I⃗a=⃗b ⊆
If⃗a=f⃗b, we get If⃗a=f⃗b ∈F and hence fB⃗a ≈F fB⃗b.
Let C := {a/F | a ∈B}, where a/F denotes the congruence class of
≈F to which a ∈B belongs. Thus, a/F = b/F
⇔Ia=b ∈F. This C
becomes the domain of some L-structure C in which ﬁrst the operations
f C are deﬁned in a canonical way. With ⃗a/F := (a1/F, . . . , an/F) we set
f C(⃗a/F) := (f B⃗a)/F. This deﬁnition is sound because ≈F is a congruence.
For constant symbols c let cC of course be cB/F.
Similar to the identity, the relation symbols are interpreted in C in a
completely natural way as follows:
rC⃗a/F :⇔Ir⃗a ∈F
	
Ir⃗a := {i ∈I | rAi⃗ai}, ⃗ai := (a1
i , . . . , an
i )

.
Also this deﬁnition is sound, since Ir⃗a ∈F and ⃗a ≈F ⃗b imply Ir⃗b ∈F.
Indeed, ⃗a ≈F ⃗b is equivalent to I⃗a=⃗b ∈F and it is readily veriﬁed that
Ir⃗a ∩I⃗a=⃗b ⊆Ir⃗b.
The L-structure C so deﬁned is called a reduced product of the Ai by the
ﬁlter F and is denoted by F
i∈I Ai (some authors denote it by 
i∈I Ai/F).
Imagining a ﬁlter F as a system of subsets of I each of which contains
“almost all indices,” one may think of F
i∈I Ai as arising from B = 
i∈I Ai
by identiﬁcation of those a, b ∈B for which the ith projections are the
same for almost all indices i.
Let C = F
i∈I Ai. For w: Var →B (= 
i∈I Ai) the valuation x 
→(xw)i
to Ai is denoted by wi, so that xw = (xwi)i∈I.
Induction on t yields
tw = (twi)i∈I. Deﬁne the valuation w/F : Var →C by xw/F = xw/F. This
setting generalizes inductively to
(1) tw/F = tw/F, for all terms t and valuations w: Var →B.
(1) follows from (f⃗t )w/F = f C(⃗t w/F ) = fC(⃗t w/F) = fB(⃗t w)/F = (f⃗t )w/F.
It is easily seen that each w′ : Var →C is of the form w/F for a suitable
valuation w: Var →B.

5.7 Reduced Products and Ultraproducts
211
Let w: Var →B and α ∈L. Deﬁne Iw
α := {i ∈I | Ai ⊨α [wi]}. Then
(2) Iw
∃xβ ⊆Iw′
β
for some a ∈B and w′ = wa
x.
Indeed, let i ∈Iw
∃xβ, i.e., Ai ⊨∃xβ [wi].
Choose some ai ∈Ai with
Ai ⊨β [wi ai
x ]. For i /∈Iw
∃xβ pick up any ai ∈Ai. Then clearly (2) holds
with a = (ai)i∈I and w′ = wa
x.
The case that F is an ultraﬁlter on I is of particular interest.
By
Theorem 7.1, all elementary properties valid in almost all factors carry
over to the reduced product, which in this case is called an ultraproduct.
If Ai = A for all i ∈I then F
i∈I Ai is termed an ultrapower of A, usually
denoted by AI/F.
The importance of ultrapowers is underlined by Shelah’s theorem (not
proved here) that A ≡B iﬀA and B have isomorphic ultrapowers. The
proof of Theorem 7.1 uses mainly ﬁlter properties; the speciﬁc ultraﬁlter
property is applied only for conﬁrming Iw
¬α ∈F ⇔Iw
α /∈F.
Theorem 7.1 (Łoś’s ultraproduct theorem). Let C = F
i∈I Ai be an
ultraproduct of the L-structures Ai. Then for all formulas α ∈L and all
w: Var →
i∈I Ai,
(∗) C ⊨α[w/F] ⇔Iw
α ∈F.
Proof by induction on α. (∗) is obtained for equations t1 ==== t2 as follows:
C ⊨t1 ==== t2 [w/F]
⇔tw/F
1
= tw/F
2
⇔tw
1/F = tw
2 /F
	
by (1)

⇔{i ∈I | twi
1 = twi
2 } ∈F
	
tw = (twi)i∈I

⇔{i ∈I | Ai ⊨t1 ==== t2 [wi]} ∈F ⇔Iw
t1 =
==
= t2 ∈F.
One similarly proves (∗) for prime formulas r⃗t . Induction steps:
C ⊨α ∧β [w/F] ⇔C ⊨α, β [w/F]
⇔Iw
α , Iw
β ∈F
(induction hypothesis)
⇔Iw
α ∩Iw
β ∈F
(ﬁlter property)
⇔Iw
α ∧β ∈F
(since Iw
α ∧β = Iw
α ∩Iw
β ).
Further, C ⊨¬α [w/F] ⇔C ⊭α [w/F] ⇔Iw
α /∈F ⇔I \Iw
α ∈F ⇔Iw
¬α ∈F.
Now let Iw
∀xα ∈F, a ∈
i∈I Ai, and w′ := wa
x. Since Iw
∀xα ⊆Iw′
α , also
Iw′
α ∈F. Hence, C ⊨α [w′/F] by the induction hypothesis. a was arbitrary,
therefore C ⊨∀xα [w/F]. The converse is, with β := ¬α, equivalent to
Iw
∃xβ ∈F ⇒C ⊨∃xβ [w/F]. This follows from (2), since (∗) holds by the
induction hypothesis for α, hence also for ¬α.

212
5 Elements of Model Theory
Corollary 7.2. A sentence α is valid in the ultraproduct F
i∈I Ai iﬀα
is valid in “almost all” Ai, that is, {i ∈I | Ai ⊨α} ∈F. In particular,
AI/F ⊨α ⇔A ⊨α, for all α ∈L0. In words, an ultrapower of A is
elementarily equivalent to A.
The last claim is clear, since the validity of α in a structure does not
depend on the valuation chosen.
The ultrapower case can be further
strengthened to A ≼AI/F (Exercise 2), useful for the construction of
special nonstandard models, for instance.
From countless applications
of ultraproducts, we present here a very short proof of the compactness
theorem for arbitrary ﬁrst-order languages. The proof is tricky, but it is
undoubtedly the most elegant proof of the compactness theorem.
Theorem 7.3. Let X ⊆L and let I be the set of all ﬁnite subsets of
X. Assume that every i ∈I has a model (Ai, wi). Then there exists an
ultraﬁlter F on I such that F
i∈I Ai ⊨X [w/F], where xw = (xwi)i∈I for
x ∈Var. In short, if every ﬁnite subset of X ⊆L has a model then the
same applies to the whole of X.
Proof. Let Jα := {i ∈I | α ∈i} for α ∈X. The intersection of ﬁnitely
many members of E := {Jα | α ∈X} is ̸= ∅; for instance {α0, . . . , αn}
belongs to Jα0∩· · ·∩Jαn. By the ultraﬁlter theorem (page 35), there exists
an ultraﬁlter F ⊇E. If α ∈X and i ∈Jα (that is, α ∈i) then Ai ⊨α [wi].
Consequently, Jα ⊆Iw
α ; hence Iw
α ∈F. Therefore, F
i∈I Ai ⊨α [w/F] by
Theorem 7.1, as claimed.
A noteworthy consequence of these results is the following theorem in
which KL denotes the class of all L-structures; by Shelah’s theorem men-
tioned above, condition (a) can be converted into a purely algebraic one.
Theorem 7.4. Let K ⊆KL. Then
(a) K is Δ-elementary iﬀK is closed under elementary equivalence and
under ultraproducts,
(b) K is elementary iﬀK is closed under elementary equivalence and
both K and \K (= KL \K) are closed under ultraproducts.
Proof. (a): A Δ-elementary class is trivially closed under elementary
equivalence. The rest of the direction ⇒holds by Theorem 7.1. ⇐: Let
T := Th K and A ⊨T, and let I be the set of all ﬁnite subsets of Th A.

5.7 Reduced Products and Ultraproducts
213
For each i = {α1, . . . , αn} ∈I there exists some Ai ∈K such that Ai ⊨i,
for otherwise n
ν=1 ¬αν ∈T which contradicts i ⊆Th A. According to
Theorem 7.3 (with X = Th A) there is a C := F
i∈I Ai ⊨Th A, and
if Ai ∈K then so too C ∈K.
Because of C ⊨Th A we know that
C ≡A, and therefore A ∈K. This shows that A ⊨T ⇒A ∈K. Hence
A ⊨T ⇔A ∈K, i.e., K is Δ-elementary. (b): ⇒is obvious by (a),
because for K = Md α we have \K = Md ¬α. ⇐: By (a), K = Md S
for some S ⊆L0. Let I be the set of all ﬁnite nonempty subsets of S.
Claim: There is some i = {α0, . . . , αn} ∈I with Md i ⊆K. Otherwise let
Ai ⊨i such that Ai ∈\K for all i ∈I. Then there exists an ultraproduct
C of the Ai such that C ∈\K and C ⊨i for all i ∈I; hence C ⊨S.
This is a contradiction to Md S ⊆K. Thus, the claim holds. Since also
K = Md S ⊆Md i, we obtain K = Md i = Md 
ν⩽n αν.
Application. Let K be the (Δ-elementary) class of all ﬁelds of char-
acteristic 0. We show that K is not elementary, and thus in a new way
that Th K is not ﬁnitely axiomatizable. Let Pi denote the prime ﬁeld
of characteristic pi (p0=2, p1=3, . . . ) and let F be a nontrivial ultraﬁl-
ter on N. We claim that the ﬁeld F
i∈N Pi has characteristic 0. Indeed,
{i ∈I | Pi ⊨¬charp} is for a given prime p certainly coﬁnite and belongs
to F, so that F
i∈N Pi ⊨¬charp for all p. Hence \K is not closed under
ultraproducts, and so by Theorem 7.4(b), K cannot be elementary.
We now turn to reduced products. Everything said below on reduced
products remains valid for direct products; these are the special case with
the minimal ﬁlter F = {I}. More precisely, {I}
i∈I Ai ≃
i∈I Ai. Filters
are always supposed to be proper in the sequel.
Theorem 7.5. Let C = F
i∈I Ai be a reduced product, w: Var →
i∈I Ai,
and α a Horn formula from the corresponding ﬁrst-order language. Then
(⋆) Iw
α ∈F ⇒C ⊨α [w/F].
In particular, a Horn sentence valid in almost all Ai is also valid in C.
Proof by induction on the construction of Horn formulas. For prime for-
mulas the converse of (⋆) is also valid, because in the proof of (∗) from
Theorem 7.1 for prime formulas no speciﬁc ultraﬁlter property was used.
Moreover, Iw
¬α ∈F ⇒Iw
α /∈F ⇒C ⊭α [w/F] ⇒C ⊨¬α [w/F], provided
α is prime. Hence, (⋆) is correct for all literals. Now suppose (⋆) for a
prime formula α and a basic Horn formula β, and let Iw
α →β ∈F. We

214
5 Elements of Model Theory
show that C ⊨α →β [w/F]. Let C ⊨α [w/F]. Then Iw
α ∈F since α is
prime. Iw
α ∩Iw
α →β ⊆Iw
β leads to Iw
β ∈F; hence C ⊨β [w/F] by the
induction hypothesis. This shows that C ⊨α →β [w/F] and proves (⋆) for
all basic Horn formulas. Induction on ∧and ∀proceeds as in Theorem 7.1
and the ∃-step easily follows with the help of (2) above.
According to this theorem the model classes of Horn theories are al-
ways closed under reduced products, in particular under direct products.
This result strengthens Exercise 1 in 4.2 signiﬁcantly. We mention ﬁ-
nally that also the converse holds: every theory with a model class closed
with respect to reduced products is a Horn theory. But the proof of this
claim, presented in [CK], is essentially more diﬃcult than that for the
similar-sounding Theorem 4.4.
Exercises
1. Show that F
i∈I Ai is isomorphic to Ai0 for some i0 ∈I if F is a triv-
ial ultraﬁlter. This applies, for instance, to ultraproducts on a ﬁnite
index set (Exercise 3 in 1.5). Thus, ultraproducts are interesting
only if the index set I is inﬁnite.
2. Prove that A is elementarily embeddable into an ultrapower AI/F.
3. (Basic in nonclassical logics). Let ⊨K:= {⊨A| A ∈K} be the
consequence relation deﬁned by a class K of L-matrices (page 49).
Show that ⊨K is ﬁnitary provided K is closed under ultraproducts
(which is the case, for instance, if K = {A} with ﬁnite A). Thus,
⊨A is ﬁnitary for each ﬁnite logical matrix.
4. Let A, B be Boolean algebras.
Prove that A ⊨α ⇔B ⊨α for
all universal Horn sentences α. This holds in particular for identi-
ties and quasi-identities. Every sentence of this kind valid in 2 is
therefore valid in all Boolean algebras.
5. Let A′
i for each i ∈I (̸= ∅) be an expansion of the L-structure Ai to
L′ ⊇L. Prove that the reduced product F
i∈I A′
i is an L′-expansion
of the reduced product F
i∈I Ai (the “expansion theorem”).

Chapter 6
Incompleteness and Undecidability
Gödel’s fundamental results concerning the incompleteness of formal
systems suﬃciently rich in content, along with Tarski’s on the nonde-
ﬁnability of the notion of truth and Church’s on the undecidability of
logic, as well as other undecidability results, are all based on essentially
the same arguments. A widely known popularization of Gödel’s ﬁrst in-
completeness theorem runs as follows:
Consider a formalized axiomatic theory T that describes a given domain
of objects A in a manner that we hope is complete. Moreover, suppose
that T is capable of talking in its language L about its own syntax and
proofs from its axioms.
This is often possible if T has actually been
devised to investigate other things (numbers or sets, say), namely by
means of an internal encoding of the syntax of L. Then the sentence γ:
“I am unprovable in T” belongs to L, where “I” refers precisely to the
sentence γ (clearly, this possibility of self-reference has to be laid down
in detail, which was the main work in [Gö2]). Then γ is true in A but
unprovable in T.
Indeed, if we assume that γ is provable, then, like any other provable
sentence in T, γ would be true in A and so unprovable, since this is just
what γ claims. Thus, our assumption leads to a contradiction. Hence, γ
is indeed unprovable, that is, γ’s assertion conforms with truth; moreover,
γ belongs to the sentences from L true in A, as it will turn out.
Put together, our goal of exhaustively capturing all theorems valid in
A by means of the axioms of T has not been achieved and is in fact not
achievable, as we will see. No matter how strong our axiomatic theory T
is, there are always sentences true in A but unprovable in T.
W. Rautenberg, A Concise Introduction to Mathematical Logic,
215
Universitext, DOI 10.1007/978-1-4419-1221-3_6,
c⃝Springer Science+Business Media, LLC 2010

216
6 Incompleteness and Undecidability
Clearly, the above is just a rough simpliﬁcation of Gödel’s theorem that
does not speak at all about a domain of objects, but is rather a proof-
theoretic assertion the proof of which can be carried out in the framework
of Hilbert’s ﬁnitistic metamathematics. This in turn means about the
same as being formalizable and provable in Peano arithmetic PA, intro-
duced in 3.3.
This result was a decisive point for a wellfounded criticism of Hilbert’s
program, which aimed to justify inﬁnitistic methods by means of a ﬁnitis-
tic understanding of metamathematics. For a detailed description of what
Hilbert was aiming at, see [Kl2] or consult [HB, Vol. 1]. The paradigm
of a domain of objects in the above sense is, for a variety of reasons, the
structure N = (N, 0, S, +, ·). Gödel’s theorem states that even for N a
complete axiomatic characterization in its language is impossible, a result
with far-reaching consequences. In particular, PA, which aims at telling
us as much as possible about N, is shown to be incomplete. PA is the
center point of Chapter 7. It is of special importance because most of
classical number theory and of discrete mathematics can be developed in
it. In addition, known methods for investigating mathematical founda-
tions can be formalized and proved in PA. These methods have stood ﬁrm
against all kinds of criticism, leaving aside some objections concerning the
unrestricted use of two-valued logic, not to be discussed here.
Some steps in Gödel’s proof require only modest suppositions regarding
T, namely the numeralwise representability of relevant syntactic predi-
cates and functions in T in the sense of 6.3. It was one of Gödel’s deci-
sive discoveries that all the predicates required in γ’s construction above
are primitive recursive 1 and that all predicates and functions of this type
are indeed representable in T. As remarked by Tarski and Mostowski,
the latter works even in certain ﬁnitely axiomatizable, highly incomplete
theories T and, in addition, covers all recursive functions. This yields
not only the recursive undecidability of T and all its subtheories in L (in
particular the theory TautL), but also of all consistent extensions of T.
1 All these predicates are also elementary in the recursion-theoretic sense, see e.g. [Mo],
although it requires much more eﬀort to verify this. Roughly speaking, the elemen-
tary functions are the “not too rapidly growing” primitive recursive functions. The
exponential function (m, n) →mn is still elementary; however, the hyperexponential
function deﬁned on page 239 is not.

6.1 Recursive and Primitive Recursive Functions
217
From this it follows that the ﬁrst incompleteness theorem as well as
Church’s and Tarski’s results can all be obtained in one go, making es-
sential use of the ﬁxed point lemma in 6.5, also called the diagonalization
lemma because it is shown by some kind of diagonalization on the primi-
tive recursive substitution function. Its basic idea can even be recognized
in the ancient liar paradox, and is also used in the foregoing popularization
of the ﬁrst incompleteness theorem.
In 6.1 we develop the theory of recursive and primitive recursive func-
tions to the required extent. 6.2 deals with the arithmetization of syntax
and of formal proofs.
6.3 and 6.4 treat the representability of recur-
sive functions in axiomatic theories. In 6.5 all the aforementioned re-
sults are proved, while the deeper-lying second incompleteness theorem
is dealt with in Chapter 7. Section 6.6 concerns the transferability of
decidability and undecidability by interpretation, and 6.7 describes the
ﬁrst-order arithmetical hierarchy, which vividly illustrates the close re-
lationship between logic and recursion theory. At the end we consider
special Σ1-formulas, important for Chapter 7.
6.1
Recursive and Primitive Recursive Functions
From now on, along with i, . . . , n we take a, . . . , e to denote natural num-
bers, unless stated otherwise. Let Fn denote the set of all n-ary functions
with arguments and values in N, and put F := 
n∈N Fn. For f ∈Fm
and g1, . . . , gm ∈Fn, we call h : ⃗a 
→f(g1⃗a, . . . , gm⃗a) the (canonical)
composition of f and the gi and write h = f[g1, . . . , gm]. The arity of h is
n. Analogously, let P[g1, . . . , gm] for a given predicate P ⊆Nm (m > 0)
denote the n-ary predicate {⃗a ∈Nn | P(g1⃗a, . . . , gm⃗a)}.
In an intuitive sense f ∈Fn is computable if there is an algorithm
for computing f⃗a for every ⃗a in ﬁnitely many steps. Sum and product
are simple examples. There are uncountably many unary functions on
N, and because of the ﬁniteness of every set of computation instructions,
only countably many of these can be computable. Thus, there must be
noncomputable functions. This existence proof brings to mind the one
for transcendental real numbers, based on the countability of the set of
algebraic numbers. Coming up with concrete examples is, in both cases,
much less simple.

218
6 Incompleteness and Undecidability
The computable functions in the intuitive sense obviously have the fol-
lowing properties:
Oc: If h ∈Fm and g1, . . . , gm ∈Fn are computable, so too is the com-
position f = h[g1, . . . , gm].
Op: If g ∈Fn and h ∈Fn+2 are computable then so is f ∈Fn+1,
uniquely determined by the equations
f(⃗a, 0) = g⃗a;
f(⃗a, Sb) = h(⃗a, b, f(⃗a, b)).
These are called the recursion equations for f, and f is said to result
from g, h by primitive recursion, or f = Op(g, h) for short.
Oμ: Let g ∈Fn+1 be such that ∀⃗a ∃b g(⃗a, b) = 0. If g is computable then
so is f, given by f⃗a = μb[g(⃗a, b) = 0]. Here the right-hand term
denotes the smallest b with g(⃗a, b) = 0. f is said to result from g by
the so-called μ-operation.
Considering Oc, Op, and Oμ as generating operations for obtaining new
functions from already-constructed ones, we state the following deﬁnition
due to Kleene:
Deﬁnition. The set of p.r. (primitive recursive) functions consists of all
functions on N that can be obtained by ﬁnitely many applications of Oc
and Op starting with the following initial functions: the constant 0, the
successor function S, and the projection functions In
ν :⃗a 
→aν (1 ⩽ν ⩽n,
n = 1, 2, . . . ). With the additional generating schema Oμ one obtains the
set of all recursive or μ-recursive functions. A predicate P ⊆Nn is called
p.r. or recursive (also decidable) provided the characteristic function χP
of P has the respective property, deﬁned by
χP⃗a =

1 in case P⃗a,
0 in case ¬P⃗a.
Remark 1. It should at least be noticed that it was Dedekind who ﬁrst proved
that Op deﬁnes exactly one function f ∈Fn in the sense of set theory. Note also
that for n = 0 the recursion equations reduce to f0 = c and fSb = h(b, fb), where
c ∈F0 and h ∈F2. If the condition ∀⃗a ∃b g(⃗a, b) = 0 in Oμ is omitted, then f
is regarded as undeﬁned for those ⃗a for which there is no b with g(⃗a, b) = 0. In
this way the so-called partially recursive functions are deﬁned. These are very
important for recursion theory. However, we will not require them.

6.1 Recursive and Primitive Recursive Functions
219
The following examples make it clear that by means of the functions In
ν
our stipulations concerning arity in Oc and Op can be extensively relaxed.
In the examples, however, we will still adjoin the normalized notation each
time in parentheses.
Examples. Let S0 = I1
1 and Sk+1 = S[Sk], so that clearly Sk : a 
→a + k.
By Oc these functions are all p.r. The n-ary constant functions Kn
c :⃗a 
→c
can be seen to be p.r. as follows: K0
c = Sc[0] for arbitrary c ∈N, while
K1
c0 = c
	
= K0
c

and K1
cSb = c
	
= I2
2(b, K1
cb)

. Thus, K1
c = Op(K0
c, I2
1).
For n > 1 we have Kn
c = K1
c[In
1]. Further, the recursion equations
a + 0 = a
	
= I1
1(a)

;
a + Sb = S(a + b)
	
= SI3
3(a, b, a + b)

show addition to be a p.r. function. Since
a · 0 = 0
	
= K1
0a

and a · Sb = a · b + a
	
= I3
3(a, b, a · b) + I3
1(a, b, a · b)

,
it follows that · is p.r. and entirely analogously so is (a, b) 
→ab. Also the
predecessor function Pd is p.r. since Pd 0 = 0 and Pd(Sb) = b
	
= I2
1(b, Pd b)

.
“Cut-oﬀsubtraction”
·−, deﬁned by a ·−b = a −b for a ⩾b, and
a ·−b = 0 otherwise, is p.r. because
a ·−0 = a
	
= I1
1(a)

and a ·−Sb = Pd(a ·−b)
	
= Pd I3
3(a, b, a ·−b)

.
The absolute diﬀerence |a −b| is p.r., for |a −b| = (a ·−b) + (b ·−a).
One sees easily that if f is p.r. (resp. recursive) then so too is every
function that results from f by swapping, equating, or adjoining ﬁctional
arguments. For example, let f ∈F2 and f1 := f[I2
2, I2
1]. Then clearly
f1(a, b) = f(b, a).
For f2 := f[I1
1, I1
1] we have f2a = f(a, a), and for
f3 := f[I3
1, I3
2] we get f3(a, b, c) = f(a, b), for all a, b, c.
From now on we will be more relaxed in writing down applications of
Oc or Op; the In
ν will no longer explicitly appear. If f ∈Fn+1 is p.r.
then so is the function (⃗a, b) 
→
k<b f(⃗a, k), since 
k<0 f(⃗a, k) = 1, and

k<Sb f(⃗a, k) = 
k<b f(⃗a, k)·f(⃗a, b). Also (⃗a, b) 
→
k<b f(⃗a, k), deﬁned
by 
k<0 f(⃗a, k) = 0 and 
k<Sb f(⃗a, k) = 
k<b f(⃗a, k) + f(⃗a, b) is p.r.
The δ-function is deﬁned by δ0 = 1, δSn = 0 and hence is p.r. With δ we
easily obtain the characteristic function of the identity relation: χ=(a, b)
equals δ|a −b|. This in turn implies that every ﬁnite subset E of N is p.r.
because χ∅= K1
0 and for E = {a1, . . . , an} ̸= ∅we have
χE(a) = χ=(a, a1) + · · · + χ=(a, an).

220
6 Incompleteness and Undecidability
The inequality relation ̸= is p.r. because χ̸=(a, b) = σ|a−b| with the
signum function σ, deﬁned by σ0 = 0, σSn = 1. Also ⩽is p.r. because
χ⩽(a, b) = σ(Sb ·−a), as is easily veriﬁed.
Almost all functions considered in number theory are p.r., in particular
the prime enumeration n 
→pn (with p0 = 2, p1 = 3, . . . ). The same
is true for standard predicates like
(divides) and prim (to be a prime
number). This will all be veriﬁed after some additional remarks.
Important is the closure of the set of p.r. functions with respect to
deﬁnition by p.r. (resp. recursive) case distinction: If P, g, h are p.r. (resp.
recursive) then so is f, given by f⃗a = g⃗a · χP⃗a + h⃗a · δχP⃗a, or
f⃗a =

g⃗a in case P⃗a,
h⃗a in case ¬P⃗a.
A simple example is (a, b) 
→max(a, b), deﬁned by max(a, b) = b if a ⩽b
and max(a, b) = a otherwise. Case distinction easily generalizes to more
than two cases. Sometimes equations in Op are given by p.r. case distinc-
tion as in a deﬁning equation for rem(a, b), the remainder of dividing a by
b (̸= 0): rem(Sa, b) = 0 if b Sa, and rem(Sa, b) = S rem(a, b) otherwise.
Case distinction yields also that a 
→bia is p.r., where bia denotes the
ith digit of the binary representation of a ∈N, a = 
i⩾0 bia · 2i. Indeed,
bia = 0 if rem(a, 2i+1) < 2i and bia = 1 otherwise.
Of fundamental importance is the hypothesis that recursive functions
exhaust all the computable functions over N. This hypothesis is called
Church’s thesis; all undecidability results are based on it. Though it is
not at all obvious from looking at the deﬁnition of recursive functions
that these functions exhaust all computable functions no matter what the
computation procedures look like, all the variously deﬁned computabil-
ity concepts turned out to be equivalent, providing evidence in favor of
the thesis. One of these concepts is computability by means of a Turing
machine [Tu], a particularly simple model of automated information pro-
cessing. Also, programming languages may be used to deﬁne the concept
of computability, for instance PROLOG, as was seen in 4.6.
Below we compile a list of the easily provable basic facts about p.r. and
recursive predicates needed in the following. Further insights, above all
concerning the form of their deﬁning formulas, will emerge in 6.3 and
thereafter. P, Q, R now denote exclusively predicates of N. In order to

6.1 Recursive and Primitive Recursive Functions
221
simplify the notation of properties of such predicates, we use as abbrevia-
tions in our metatheory the preﬁxes (∃a<b), (∃a⩽b), (∀a<b), and (∀a⩽b)
as in (B) below. Their meaning is self-explanatory.
(A) The set of p.r. (resp. recursive) predicates is closed under forming
the complement, union, and intersection of predicates of the same arity,
as well as under insertion of p.r. (resp. recursive) functions, and ﬁnally
under swapping, equating, and adjoining ﬁctional arguments.
This is
proved as follows: for P ⊆Nn, δ[χP ] is exactly the characteristic function
of ¬P := Nn \P; furthermore, χP∩Q = χP · χQ and χP∪Q = sg[χP + χQ]
as well as χP[g1,...,gm] = χP [g1, . . . , gm]. Since χgraph f (⃗a, b) is the same
as χ=(f⃗a, b), graph f is p.r. provided f is (though the converse need not
hold, see the end of this section). All the other above-mentioned closure
properties are simply obtained from the corresponding properties of the
characteristic functions.
(B) Let P, Q, R ⊆Nn+1. Suppose that Q(⃗a, b) ⇔(∀k<b)P(⃗a, k) and
R(⃗a, b) ⇔(∃k<b)P(⃗a, k).
Then we say that Q, R result from P by
bounded quantiﬁcation. The same will be said if < in these deﬁnitions
is replaced by ⩽.
If P is p.r. so too are all these predicates, because
χQ(⃗a, b) = 
k<b χP (⃗a, k), χR(⃗a, b) = sg(
k<b χP (⃗a, k)), and similarly
if < is replaced by ⩽.
The proofs of these equations are so simple
that we may pass over them.
Brieﬂy, the set of p.r. (resp. recursive)
predicates is closed under bounded quantiﬁcation.
For instance, since
a b ⇔(∃k⩽b)[a·k = b], also
is p.r. So too is the predicate prim, because
prim p ⇔p ̸= 0, 1 & (∀a<p)[a p ⇒a=1]. Note that a p ⇒a = 1 is
equivalent (at the metatheoretical level) to a̸
p ∨∨∨a = 1 and is therefore
the union of p.r. predicates. Hence, this predicate is indeed p.r.
(C) Suppose P ⊆Nn+1 satisﬁes ∀⃗a ∃b P(⃗a, b) and let f⃗a = μk[P(⃗a, k)]
be the smallest k such that P(⃗a, k). Then by Oμ, if P is recursive so
too is the function f, because f⃗a = μk[δχP (⃗a, k) = 0]. This important
generalization of Oμ will henceforth likewise be denoted by Oμ. On the
other hand, f need no longer be p.r., provided P is.
This does hold,
though, for the bounded μ-operation: if P ⊆Nn+1 is p.r. so too is f
deﬁned by f(⃗a, m) = μk⩽m[P(⃗a, k)]. Here let
μk⩽m[P(⃗a, k)] =

the smallest k ⩽m with P(⃗a, k), if such k exists,
m otherwise.

222
6 Incompleteness and Undecidability
Clearly f(⃗a, 0) = 0, and f(⃗a, Sm) = f(⃗a, m) if (∃k⩽m)P(⃗a, k), and
f(⃗a, Sm) = Sm otherwise.
To convert this into a p.r. case distinction
we deﬁne a p.r. function g by
g(⃗a, m, b) =

b if (∃k⩽m)P(⃗a, k),
Sm otherwise.
Then f(⃗a, Sm) = g(⃗a, m, f(⃗a, m)) is readily conﬁrmed. Therefore, f is
indeed a p.r. function.
Let h and P be p.r. and μk⩽h⃗a[P(⃗a, k)] := μk⩽m[P(⃗a, k) & m=h⃗a].
0,0
0,1
0,2
0,3
1,0
1,1
1,2
2,0
2,1
3,0
r r r
QQ
s
QQ
s
QQ
s
QQ
s
QQ
s
QQ
s
6
@
@
@
@
I
@
@
@
@
@
@
@
I
Then also ⃗a 
→μk⩽h⃗a[P(⃗a, k)] is p.r. A ﬁrst
application is the pairing function ℘, a bi-
jective mapping from N2 to N, deﬁned by
℘(a, b) = 
i⩽a+b i + a. It enumerates the
pairs (a, b) as in the ﬁgure (cf. Exercise 2).
Using the formula (∗) : 
i⩽n i = 1
2n(n + 1)
we obtain ℘(a, b) = 1
2(a + b)(a + b + 1) + a.
From this equation one easily obtains a def-
inition of ℘by means of the bounded μ-operation, for instance
℘(a, b) = μk⩽(a + b)(a + b + 1) + 2a [2k = (a + b)(a + b + 1) + 2a].
The famous formula (∗) was probably ﬁrst considered by Pythagoras,
s
s
s
s
s
s
s
s
s
s
1+2+3+4
who counted the number tn of points of a triangle with
n base points as in the right-hand ﬁgure in two ways. tn
equals 1+2+· · ·+n if one counts vertically. But two such
triangles, put together appropriately, form a rectangle
with n · (n + 1) points. Thus, in fact tn = 1
2n(n+1).
Clearly, the bounded μ-operation is not really needed in order to see
that ℘is p.r. A more convincing application of this operation is a rigorous
proof that the prime number enumeration is p.r. If p is prime then p! + 1
is certainly not divisible by a prime q ⩽p. Indeed, if q p! + 1 and q p!,
we obtain q p! + 1 −p! = 1 and hence the contradiction q 1. Thus, a
prime divisor of p! + 1 is necessarily a new prime. Therefore, the function
n 
→pn is uniquely characterized by the equations
(⋆)
p0 = 2 ;
pn+1 = μq⩽pn!+1[prim q & q > pn].
(⋆) is an application of Op, because with f : (a, b) 
→μq⩽b[prim q & q > a],
g : a 
→f(a, a! + 1) is p.r. as well, and the second equation in (⋆) can be
written pn+1 = g(pn), as is easily veriﬁed. Hence, n 
→pn is indeed p.r.

6.1 Recursive and Primitive Recursive Functions
223
Remark 2. Unlike the set of p.r. functions, the set of μ-recursive functions can
no longer be eﬀectively enumerated, indeed, not even all unary ones: if (fn)n∈N
were such an eﬀective enumeration then f : n 
→fn(n) + 1 would be computable
and hence recursive by Church’s thesis.
Thus, f = fm for some m, so that
fm(m) = f(m) = fm(m) + 1, a contradiction.
While this seemingly speaks
against the thesis, it can in fact be eliminated from the argument using some
basic recursion theory. (C) clariﬁes the distinction between p.r. and recursive
functions to some extent. The former can be computed with an eﬀort that can
in principle be estimated in advance, whereas the existence condition in the
unbounded μ-operation may be nonconstructive, so that even crude estimates
of the eﬀort required for computation are impossible. It is not very hard to
construct a computable unary function that each p.r. unary function eventually
overtakes. Nonetheless, also a p.r. function may grow extremely fast. For in-
stance, it is physically impossible to compute the digits of f6 for the p.r. function
f : n 
→22··· 2

n
. While f5 has “only” 19 729 digits, the number of digits of f6 is
already astronomical.
The following considerations are required in 6.2.
They concern the
encoding of ﬁnite sequences of numbers of arbitrary length. There are ba-
sically several possibilities for doing this. One of these is to use the pairing
function ℘(or a similar one, cf. [Shoe]) repeatedly. Here we choose the
particularly intuitive encoding from [Gö2], based on the prime enumera-
tion n 
→pn and the unique prime factorization.
Deﬁnition. ⟨a0, . . . , an⟩:= pa0+1
0
· · · pan+1
n
(= 
i⩽n pai+1
i
) is called the
Gödel number of (a0, . . . , an). The empty sequence has the Gödel number
1, also denoted by ⟨⟩. Let GN denote the set of all Gödel numbers.
Clearly, ⟨a0, . . . , an⟩= ⟨b0, . . . , bm⟩implies m = n and ai = bi for
i = 1, . . . , n. Also, (a0, . . . , an) 
→⟨a0, . . . , an⟩is certainly p.r. and by
(A), (B) above, so is GN, since
a ∈GN ⇔a ̸= 0 & (∀p⩽a)(∀q⩽p)[prim p, q & p a ⇒q a].
We now create a small provision of p.r. functions useful for the encoding
of syntax in 6.2. Using (C) we deﬁne a p.r. function a 
→ℓa as follows:
ℓa = μk⩽a[pk̸
a].
We call ℓa for a Gödel number a the “length” of a, since clearly ℓ1 = 0,
and for a = ⟨a0, . . . , an⟩= 
i⩽n pai+1
i
is ℓa = n + 1, because k = n + 1
is the smallest index such that pk̸
a. Note that always ℓa ⩽a and for

224
6 Incompleteness and Undecidability
a ̸= 0 even ℓa < a, because pa−1̸
a in view of pa−1 > a. Also the binary
operation (a, i) 
→(((a)))i is p.r., where the term (((a)))i is deﬁned by
(((a)))i = μk⩽a[pk+2
i
̸
a pd].
This is the “component-recognition function.” pk+1
i
a and pk+2
i
̸
a imply
k = (((a)))i, hence (((⟨a0, . . . , an⟩)))i = ai for all i ⩽n. This function, printed
bold in order to catch the eye, always begins counting the components
of a Gödel number with i = 0. Therefore, (((a)))last := (((a)))ℓa ·−1 is the last
component of a Gödel number a ̸= 1, while (((1)))last = 0. Which values (((a)))i
and ℓhave for arguments outside GN is irrelevant.
From the above deﬁnitions it follows that a = 
i<ℓa p(((a)))i+1
i
for Gödel
numbers a including a = 1 (because the empty product equals 1). Next
we deﬁne the arithmetical concatenation ∗∈F2 by
a ∗b = a · 
i<ℓb p(((b)))i+1
ℓa+i
for a, b ∈GN and a ∗b = 0 otherwise.
Obviously, ⟨a1, . . . , an⟩∗⟨b1, . . . , bm⟩= ⟨a1, . . . , an, b1, . . . , bm⟩, so that GN
is closed under ∗. Moreover, a, b ∈GN ⇒a, b ⩽a ∗b, as immediately
follows from the deﬁnition. Note also that a ∗b ∈GN ⇒a, b ∈GN, for all
a, b. Clearly, ∗is p.r., for its deﬁnition is based on p.r. case distinction.
The arithmetical function ∗is useful for, among other things, a powerful
generalization of Op, the course-of-values recursion explained now. To
every f ∈Fn+1 corresponds a function ¯f ∈Fn+1 given by
¯f(⃗a, 0) = ⟨⟩
	
= 1

;
¯f(⃗a, b) = ⟨f(⃗a, 0), . . . , , f(⃗a, b −1)⟩for b > 0.
¯f encodes the course of values of f in the last argument. Let F ∈Fn+2.
Then just as for Op there is one and only one f ∈Fn+1 that satisﬁes
Oq :
f(⃗a, b) = F(⃗a, b, ¯f(⃗a, b)).
Namely, f(⃗a, 0) = F(⃗a, 0, ⟨⟩) = F(⃗a, 0, 1), f(⃗a, 1) = F(⃗a, 1, ⟨f(⃗a, 0)⟩),
f(⃗a, 2) = F(⃗a, 2, ⟨f(⃗a, 0), f(⃗a, 1)⟩), etc. In Oq, f(⃗a, b) in general depends
for b > 0 on all values f(⃗a, 0), . . . , f(⃗a, b −1), not just on f(⃗a, b −1) as in
Op. Hence Oq is called the schema of course-of-values recursion. A simple
example is the Fibonacci sequence (fn)n∈N, deﬁned by f0 = 0, f1 = 1,
and fn = f(n −1) + f(n −2) for n ⩾2. The F in “normal form” Oq is
given here by F(b, c) = b for b ⩽1 and F(b, c) = (((c)))b−1+(((c)))b−2 otherwise.
Indeed, f0 = 0 = F(0, ¯f0), f1 = 1 = F(1, ¯f1), and for n ⩾2, we have
fn = f(n −1) + f(n −2) = ((( ¯fn)))n−1 + ((( ¯fn)))n−2 = F(n, ¯fn).

6.1 Recursive and Primitive Recursive Functions
225
Op is a special case of Oq. If f = Op(g, h) and F is deﬁned by the
equations F(⃗a, 0, c) = g(⃗a) and F(⃗a, Sb, c) = h(⃗a, b,(((c)))b), then f satisﬁes
Oq with this F, as may straightforwardly be checked while observing that
f(⃗a, b) equals ((( ¯f(⃗a, Sb))))b .
Theorem 1.1. Let f satisfy Oq. If F is p.r. then so too is f.
Proof. Since ⟨c0, . . . , cb⟩= ⟨c0, . . . , cb−1⟩∗⟨cb⟩for b > 0, our ¯f satisﬁes
¯f(⃗a, 0) = 1;
¯f(⃗a, Sb) = ¯f(⃗a, b) ∗⟨f(⃗a, b)⟩= ¯f(⃗a, b) ∗⟨F(⃗a, b, ¯f(⃗a, b))⟩.
The second equation can be written ¯f(⃗a, Sb) = h(⃗a, b, ¯f(⃗a, b)), where h is
deﬁned by h(⃗a, b, c) = c ∗⟨F(⃗a, b, c)⟩. With F also the function h is p.r.
Hence, by Op, ¯f is p.r. But then so is f, because in view of Oq, f is a
composition of p.r. functions.
We now make precise the intuitive notion of recursive (or eﬀective)
enumerability. M ⊆N is called r.e. (recursively enumerable) if there is
some recursive R ⊆N2 such that M = {b ∈N | (∃a∈N)Rab}. In short,
M is the range of some recursive relation. Since a ∈M ⇔(∃b∈N)R′ab,
where R′ab ⇔Rba, M is at the same time the domain of some recursive
relation. More generally, P ⊆Nn is called r.e. if P⃗a ⇔(∃x∈N)Q(x,⃗a) for
some (n + 1)-ary recursive predicate Q. Note that a recursive predicate
P is r.e. Indeed, P⃗a ⇔(∃b∈N)P ′(b,⃗a); here P ′(b,⃗a) :⇔P⃗a (adjoining a
ﬁctional variable). It is not quite easy to present an ad hoc example of an
r.e. predicate that is not recursive. But such examples arise naturally in
6.5, where we prove the undecidability of several axiomatic theories.
It is readily shown that M ̸= ∅is r.e. if and only if M = ran f for some
recursive f ∈F1; Exercise 5. This characterization corresponds perfectly
to our intuition: stepwise computation of f0, f1, . . . provides an eﬀective
enumeration of M in the intuitive sense. This enumeration can be carried
out by a computer that puts out f0, f1, . . . successively and does not stop
its execution by itself.
The empty set is r.e. because it is the domain of the empty binary
relation, which is recursive, and even p.r., since its characteristic function
is the constant function K2
0. In view of the above characterization of r.e.
sets M ̸= ∅, one could have deﬁned these from the outset as the ranges
of unary recursive functions. But the ﬁrst deﬁnition has the advantage of
immediately expanding to the n-dimensional case.

226
6 Incompleteness and Undecidability
It is easily seen that a function f ∈Fn is recursive provided graph f
is, simply because f⃗a = μb[graph f(⃗a, b)] (or in strict terms of property
Oμ, f⃗a = μb[δχgraph f(⃗a, b) = 0]), that is, f can immediately be isolated
from graph f with the μ-operator. Conversely, if f is recursive then so is
graph f, because χgraph f(⃗a, b) = χ=(f⃗a, b). This equation also shows that
graph f is p.r. whenever f is p.r. The converse need not be true. There
are functions f whose graph is p.r. although f itself is not. A famous
example is the (modiﬁed) Ackermann function ◦∈F2, deﬁned by
0 ◦b = Sb
;
Sa ◦0 = a ◦1
;
Sa ◦Sb = a ◦(Sa ◦b)
(see e.g. [Fel1, pp. 76–84]). Thus, not every recursion is primitive recursive.
Exercises
1. Let a ⩽fa for all a. Prove that if f is p.r. (resp. recursive) then so
is ran f. The same holds for f ∈Fn if a1, . . . , an ⩽f⃗a for ⃗a ∈Nn.
2. Prove in detail that the pairing function ℘: N2 →N is bijective and
that its diagram in the ﬁgure on page 222 is correct.
3. Since ℘: N2 →N is bijective, there are functions κ1, κ2 ∈F1 with
℘(κ1n, κ2n) = n, for all n. Prove that κ1, κ2 are p.r. (One need
not exhibit explicit terms for κ1, κ2, although this is not diﬃcult.)
4. Let lcm{fν| ν⩽n} be the least common multiple of f0, . . . , fn with
f∈F1. Show that n 
→lcm{fν| ν⩽n} is p.r. provided f is.
5. Let M ⊆N be nonempty. Show that M is r.e. iﬀM = ran f for
some recursive f ∈F1.
6.2
Arithmetization
Roughly put, arithmetization (or Gödelization) is the description of the
syntax of a formal language L and of formal proofs from an axiom system
by means of arithmetical operations and relations on natural numbers. It
presupposes the encoding of strings from the alphabet of L by natural

6.2 Arithmetization
227
numbers. Syntactic functions and predicates correspond in this way to
welldeﬁned functions and predicates on N.
Thus many goals at once become attainable. First of all, the intuitive
idea of a computable word function can be made more precise using the
notion of recursive functions. Second, syntactic predicates such as, for
instance ‘x ∈var α’, can be replaced by corresponding predicates of N.
Third, using encoding, statements about syntactic functions, predicates,
and formal proofs can be formulated in theories T ⊆L able to speak
about arithmetic, and perhaps be proved in T.
We demonstrate the arithmetization of syntax using as an example the
language L = Lar, whose extralogical symbols are 0, S, +, · . This is the
language of Peano arithmetic PA. However, the same procedure can be
carried out analogously for other formal languages, as will be apparent in
the course of our considerations.
The ﬁrst step is to assign uniquely to every basic symbol s of L a number
♯s, its symbol code. The following table provides an example for L = Lar:
s
====
¬
∧
∀
(
)
0
S
+
·
v0
v1
♯s
1
3
5
7
9
11
13
15
17
19
21
23 · · ·
Next we encode the string ξ = s0 · · · sn by its Gödel number, which is the
number ⟨♯s0, . . . , ♯sn⟩= p1+♯s0
0
· . . . · p1+♯sn
n
. The empty string gets Gödel
number 1. This is Gödel’s original encoding, but there are several other
possibilities to encode syntax by natural numbers.
Example. The term 0 and the prime formula 0==== 0 have the still compar-
atively small Gödel numbers 21+♯0 = 214 and 214 · 32 · 514, respectively.
The term 1 has Gödel number 216 · 314. This encoding is not particularly
economical, but that need not concern us here. Nor is it a problem that
the symbol code of ==== is just the Gödel number of the empty string. For
note that ==== , considered as an atomic string or a string of length 1, has
Gödel number 21+1 = 4.
Let ˙ξ be the Gödel number of ξ ∈SL, and ˙t and ˙α therefore those
of the term t and the formula α, respectively.
If we write ξη for the
concatenation of ξ, η ∈SL, then obviously (ξη)· = ˙ξ ∗˙η, where ∗is the
arithmetical concatenation from 6.1. ˙SL = { ˙ξ | ξ ∈SL} is a p.r. subset
of the set of all Gödel numbers. Indeed, since L-symbols are encoded by
odd numbers, n ∈˙SL ⇔n ∈GN & (∀k<ℓn) 2̸
(((n)))k.

228
6 Incompleteness and Undecidability
When arithmetizing the syntax one has to carefully distinguish a sym-
bol s from its corresponding atomic string, although these are normally
denoted identically (see also the Notation). ♯s is the symbol code of the
symbol s, while ˙s = 21+♯s is the Gödel number of the atomic string s. For
example, the symbol 0 has the symbol code 13, while the prime term 0
has Gödel number ˙0 = 21+♯0 = 214. We must also distinguish between the
symbol vi and the prime term vi. Thus, the set of prime terms v1, v2, . . . ,
denoted by V, cannot simply be identiﬁed with Var.
Remark 1. Nonetheless, one could, right from the beginning, identify symbols
with their codes and strings with their Gödel numbers, so that ˙ϕ = ϕ and ˙t = t
for formulas ϕ and terms t. Then syntactic predicates are arithmetical from the
outset. This would even alleviate some of the following considerations in tech-
nical respect. However, we postpone this until we have convinced ourselves that
syntax can indeed adequately be encoded in arithmetic. Further, the alphabet
of Lar could easily be replaced by a ﬁnite one, consisting, say, of the symbols
==== , ¬, . . . , ·, v, in that v0 is replaced by the string v0, v1 by vS0, etc. Other
encodings found in the literature arise from the identiﬁcation of the letters in
such alphabets with the digits of a suitable number base.
In the following, let
˙W = { ˙ξ | ξ ∈W} for sets W ⊆SL of words. A
corresponding notation will be used for many-place word predicates P. We
call P p.r. or recursive whenever ˙P is p.r. or recursive, respectively. So, for
example, if we talk about a recursive axiom system X ⊆L, it is always
understood that
˙X is recursive.
Other properties, such as recursively
enumerable or representable, can be transferred to word predicates by
means of the above or a similar arithmetization.
All these remarks refer not just to L = Lar, but to an arbitrary arith-
metizable (or Gödelizable) language L, by which we simply mean that L
possesses ﬁnitely or countably many speciﬁed basic symbols, so that each
string can be assigned a number code in a computable way. In this way,
the concepts of an axiomatizable or decidable theory, already used in 3.3,
obtain a precise meaning. Of course, one must clearly distinguish between
the axioms and theorems of an axiomatic theory; the axiom systems of
familiar theories like PA and ZFC are readily seen to be p.r., while these
theories considered as sets of theorems are shown in 6.5 to be undecidable
and cannot even be extended in any way to decidable theories.
The main goal now is the arithmetization of the formal proof method.
We use ⊢from now on to denote the Hilbert calculus of 3.6 consisting of

6.2 Arithmetization
229
the axiom system Λ with the axiom schemata Λ1–Λ10 given there and the
Modus Ponens MP as the only rule of inference. Here everything refers to
a ﬁxed arithmetizable language L, which, as a rule, will be the arithmetical
language Lar. Just as for strings, for a ﬁnite sequence Φ = (ϕ0, . . . , ϕn)
of L-formulas we call ˙Φ := ⟨˙ϕ0, . . . , ˙ϕn⟩its Gödel number. This includes
in particular the case that Φ is a proof from X (⊆L) in the sense of
3.6, which in the general case also contains formulas from Λ. Note that
˙Φ ̸= ˙ξ for all ξ ∈SL, because 2 ((( ˙Φ)))0 (a proof is not empty), whereas
2̸
((( ˙ξ)))0 because the symbol codes are odd. This is the case in our example
language Lar and may actually be presupposed throughout. Thus, we can
comfortably distinguish the Gödel numbers of formulas and terms from
the Gödel numbers of ﬁnite sequences of formulas.
Now let T (⊆L0) be a theory axiomatized by some ﬁxed axiom system
X ⊆T. Examples are PA and ZFC.2 A proof Φ = (ϕ0, . . . , ϕn) from X is
also called a proof in T. Here and elsewhere the axiom system X is tacitly
understood to be an essential part of T, which is originally understood
as a set of sentences. First deﬁne the p.r. functions ˜¬, ˜∧, ˜
→as follows:
˜¬a := ˙¬ ∗a, a˜∧b := ˙( ∗a ∗˙∧∗b ∗˙) and a ˜
→b := ˜¬(a ˜∧˜¬b) (argument
parentheses in the last expression should not be mixed up with parentheses
belonging to the alphabet of L). Clearly, both ˙SL and ˙L are closed under
these operations.
Let proofT denote the unary arithmetical predicate that corresponds to
the syntactic predicate ‘Φ is a proof in T ’. We denote the arithmetical
predicates corresponding to ‘Φ is a proof in T for ϕ’ (the last component
of Φ) and to ‘there is a proof for ϕ in T’ by bewT and bwbT , respectively
(coming from beweis = proof and beweisbar = provable). Precise deﬁni-
tions of these predicates look as follows:
(1) proofT (b) :⇔b ∈GN & b ̸= 1
& (∀k<ℓb)[(((b)))k ∈˙X ∪˙Λ ∨∨∨(∃i, j < k)(((b)))i = (((b)))j ˜
→(((b)))k],
(2) bewT (b, a) :⇔proofT (b) & a = (((b)))last ,
(3) bwbT a :⇔∃b bewT (b, a).
Since bwbT is a unary predicate that will be met several times in the
sequel, we dropped the argument parentheses in writing bwbT a. Easily
2 The language L∈of ZFC is obviously simpler than Lar. It contains no composed terms
and hence only the simplest possible equations, which of course simpliﬁes encoding.

230
6 Incompleteness and Undecidability
obtained from (1), (2), and (3) are
(4) ⊢T α ⇔bwbT ˙α (⇔∃b bewT (b, ˙α)),
(5) bewT (c, a) & bewT (d, a ˜
→b) ⇒bewT (c ∗d ∗⟨b⟩, b), for all a, b, c, d,
(6) bwbT a & bwbT (a ˜
→b) ⇒bwbT b, for all a, b,
(7) bwbT ˙α & bwbT (α →β)· ⇒bwbT ˙β, for all α, β ∈L.
The equivalence (4) is clear, for if ⊢T α then there is a proof Φ for α,
hence ∃n bewT (n, ˙α) with n = ˙Φ, and conversely. (5) tells us in arith-
metical terms the familiar story that concatenating proofs for α, α →β
and tacking on β yields a proof for β.
(5) immediately yields (6) by
particularization, and (6) implies (7) since (α →β)· = ˙α ˜
→˙β.
Remark 2. We will not need (5)–(7) until 7.1. But it is very instructive for
our later transfer of proofs to PA to verify (5) ﬁrst naively. This is simple when
we refer to the following facts: ℓ(a ∗b) = ℓa + ℓb, (∀i<ℓa)(((a ∗b)))i = (((a)))i and
(∀i<ℓb)(((a ∗b)))ℓa+i = (((b)))i, for all a, b ∈GN. Note also that (((⟨c⟩)))0 = c for all c.
Since it would impede the proof of (5), (∀k<b)(((b)))k ∈˙L was not added to the
right-hand side of (1). This is in fact dispensable, for induction on the length
ℓb of the Gödel number b readily shows that proofT (b) implies (∀k<ℓb)(((b)))k ∈˙L.
Here we need a, a ˜
→b ∈˙L ⇒b ∈˙L, for all a, b ∈N (Exercise 3 in 2.3).
Now we really get down to work and show that the syntactic basic
notions up to the predicate bewT are p.r. In 6.5 only their recursiveness
is important; not until Chapter 7 do we make essential use of their p.r.
character, which ensures that all involved functions are deﬁnable in PA.
We shall return to our example L = Lar only at the end of 6.3, because
the proofs of the following lemmas are not entirely independent of the
language’s syntax and the selected encoding, though they can be proved
for other arithmetizable languages in nearly the same way.
In addition to the already-deﬁned functions ˜¬, ˜∧, and
˜
→, we deﬁne
a ˜==== b := a∗˙==== ∗b (= a∗22 ∗b) and ˜∀(i, a) := ˙∀∗i∗a. ˜∃is deﬁned similarly.
Finally, for the operations S, +, · deﬁne ˜Sa := ˙S ∗a, a˜+b := ˙( ∗a ∗˙+ ∗b ∗˙),
and similarly for ·. Then, for example, (s==== t)· = ˙s ˜==== ˙t and (St)· = ˜S˙t for
terms s, t, as well as (∀xα)· = ˜∀˙x ˙α (= ˜∀( ˙x, ˙α)). All these functions are
obviously primitive recursive.
For arbitrary strings ξ, η let ξ ⩽η mean ˙ξ ⩽˙η (correspondingly for <).
For example, ξ ⩽η holds if ξ is a substring of η, in particular if ξ is a
subformula of the formula η. This follows immediately from the property
a, b ⩽a ∗b for Gödel numbers a, b, mentioned already on page 224.

6.2 Arithmetization
231
Lemma 2.1. The set T of all terms is primitive recursive.
Proof. The set V of terms vi is p.r. since n ∈˙V ⇔(∃k⩽n) n = 222+2k.
Thus Tprim := V ∪{0}, the set of all prime terms, is p.r. as well. By the
recursive deﬁnition of T , t ∈T if and only if
t ∈Tprim∨∨∨(∃t1, t2 < t)[t1, t2 ∈T & (t = St1∨∨∨t = (t1 +t2)∨∨∨t = (t1 ·t2))].
Therefore the corresponding arithmetical equivalence holds as well:
(∗)
n ∈˙T
⇔n ∈˙Tprim ∨∨∨(∃i, k < n)[i, k ∈˙T & Q(n, i, k)],
where Q(n, i, k) ⇔(n = ˜Si ∨∨∨n = i˜+k ∨∨∨n = i˜·k). We now show how
to convert this “informal deﬁnition” of ˙T , which on the right-hand side
makes use of elements of ˙T smaller than n only, into a course-of-values
recursion for the characteristic function χ ˙T , whence χ ˙T , and so T would
turn out to be p.r. Consider the p.r. predicate P deﬁned by
P(a, n) ⇔n ∈˙Tprim ∨∨∨(∃i, k < n)[(((a)))i = (((a)))k = 1 & Q(n, i, k)].
We claim that f := χ ˙T satisﬁes Oq : fn = χP ( ¯fn, n), where ¯fn equals
⟨f(0), . . . , f(n −1)⟩, and hence f is p.r. by Theorem 1.1. Indeed, since
fi = fk = 1 ⇔i, k ∈˙T , we obtain in view of (∗)
n ∈˙T
⇔
n ∈˙Tprim ∨∨∨(∃i, k < n)[fi = fk = 1 & Q(n, i, k)]
⇔
P( ¯fn, n)
	
because ((( ¯fn)))i = fi and ((( ¯fn)))k = fk

.
From this it clearly follows that fn = 1 ⇔χP ( ¯fn, n) = 1, which in turn
implies Oq, since both f and χP take values from {0, 1} only.
Lemma 2.2. The set L (= Lar) of all formulas is primitive recursive.
Proof. Lprim is p.r. simply because
n ∈˙Lprim ⇔(∃i, k < n)[i, k ∈˙T & n = i ˜==== k].
If we consider ˙x < ˙ξ for every ξ ∈SL with x ∈var ξ (because then ξ = ηxθ
for some strings η, θ ∈SL), then the predicate ‘ϕ ∈L’ clearly satisﬁes
ϕ ∈Lprim ∨∨∨(∃α, β, x < ϕ)[α, β ∈L & x ∈V
& (ϕ = ¬α ∨∨∨ϕ = (α ∧β) ∨∨∨ϕ = ∀xα)].
This “informal deﬁnition” can then be transformed just as in Lemma 2.1
into a course-of-values recursion of the characteristic function of ˙L using
the characteristic function of the certainly p.r. predicate P given by

232
6 Incompleteness and Undecidability
P(a, n) ⇔n ∈˙Lprim ∨∨∨(∃i, k, j < n)[(((a)))i = (((a)))k = 1 & j ∈˙V
& (n = ˜¬i ∨∨∨n = i ˜∧k ∨∨∨n = ˜∀jk)].
We now deﬁne a ternary p.r. function (m, i, k) 
→[m]k
i such that
(∗)
[ ˙ξ]˙t
˙x = (ξ tx)· for all ξ ∈L ∪T , x ∈V, and t ∈T .
[m]k
i will be constructed essentially by course-of-value recursion on m in
two steps, ﬁrst for m ∈˙T and then for m ∈˙L. Step 1: Put [m]k
i = 0,
if m /∈˙T or i /∈˙V or k /∈˙T . Otherwise let ﬁrst m ∈˙Tprim. In case
m = i set [m]k
i = k (remember that x tx = t), and if m ̸= i set [m]k
i = m.
Now let m ∈˙T \ ˙Tprim. According to the case distinction in Exercise 2, let
ﬁrst (∃m0<m)(m = ˜Sm0 & m0 ∈˙T ). Put [m]k
i = ˜S[m0]k
i (m0 is unique).
If (∃m1, m2<m)(m = m1 ˜+m2 & m1, m2 ∈˙T ), set [m]k
i = [m1]k
i ˜+[m2]k
i ,
and similarly for ˜·. Thus, [m]k
i is now well deﬁned and p.r., but (∗) holds
currently only for ξ ∈T , since [m]k
i = 0 for m ∈˙L. Step 2: We modify
the step 1 deﬁnition of [m]k
i for the case m ∈˙L, i ∈˙V, and k ∈˙T in
a p.r. way. For m = (t1 ==== t2)· put [m]k
i = [˙t1]k
i ˜==== [˙t2]k
i (t1, t2 ∈T , prime
formula case). Otherwise, m = ˜¬m0 or m = m0 ˜∧m1 or m = ˜∀(m2, m0)
for suitable m0, m1 < a from ˙L and m2 ∈˙V according to Exercise 3. We
then explain [m]k
i for all m ∈˙L by course-of-value recursion similarly to
what we did in Step 1 and according to the deﬁnition of a substitution on
formulas. This results in a p.r. function that satisﬁes (∗).
As was already noticed, the predicate ‘x occurs in ξ’, or ‘x ∈var ξ’
for short, is p.r., since x ∈var ξ
⇔
x ∈V & (∃η, ϑ ⩽ξ)(ξ = ηxϑ).
Replacing here ηxϑ by η∀xϑ makes it clear that ‘x ∈bnd α’ is p.r. as well.
The binary predicate ‘x ∈free α’ is also p.r. because x ∈free α if and only
if x ∈V & α 0x ̸= α (⇔x ∈V & [ ˙α]˙0
˙x ̸= ˙α). Consequently L0 is p.r. With
these preparations we now prove
Lemma 2.3. The set Λ of logical axioms is primitive recursive.
Proof. Λ1 is p.r. because ϕ ∈Λ1 if and only if
(∃α, β, γ < ϕ)[α, β, γ ∈L & ϕ = (α →β →γ) →(α →β) →(α →γ)].
To characterize the corresponding arithmetical predicate we use the p.r.
function ˜
→. One reasons similarly for Λ2–Λ4. For a p.r. characterization
of Λ5 use the fact that the ternary predicate ‘α, tx collision-free’ is p.r.

6.2 Arithmetization
233
For ‘α, tx collision-free’ holds iﬀ(∀y<α)(y ∈bnd α & y ∈var t ⇒y = x).
Further, the predicate ‘ϕ = ∀xα →α tx ’, which depends on ϕ, α, x, t, is
p.r., as can be seen by applying (m, i, k) 
→[m]k
i . Hence, Λ5 is p.r. as
well, because ϕ ∈Λ5 if and only if
(∃α, x, t < ϕ)(α ∈L & x ∈V & t ∈T
& ϕ = ∀xα →α tx
& α, tx collision-free).
Similarly it is shown that Λ6–Λ10 are p.r. Thus, each of the schemata Λi
is p.r. and therefore so is Λ0 := Λ1 ∪· · · ∪Λ10. But then the same holds
for Λ itself, because k 
→♯vk is surely p.r. and every α ∈Λ can be written
α = ∀⃗xα0 with some (possibly empty) preﬁx ∀⃗x and for some α0 ∈Λ0,
and then it must hold that
n ∈˙Λ ⇔n ∈˙L & (∃m, k < n)(n = m ∗k & 2 ℓm & k ∈˙Λ0
& (∀i<ℓm)[2 i & (((m)))i = ♯∀
∨∨∨
2̸
i & (∃k⩽n)(((m)))i = ♯vk].
The second line of this formula tells us that m is the Gödel number of a
preﬁx ∀x1 · · · ∀xl. This is a string of length m = 2l.
All of the above holds completely analogously for every arithmetizable
language. Hence, given a p.r. or recursive axiom system X, X ∪Λ is p.r.
(resp. recursive) as well. This applies in particular to the axiom systems
of PA and ZFC. These are p.r. like every other common axiom system,
despite the diﬀerence in their strengths. The proof is carried out in a
manner fairly similar to that of Lemma 2.3.
The main result of this section, which now follows, is completely in-
dependent of the strength of an axiomatic theory T. The strength of a
theory T ﬁrst comes into the picture when we want to prove something
about bewT and bwbT within T itself.
Theorem 2.4. Let X be a p.r. axiom system for a theory T of an arith-
metizable language. Then the predicate bewT is p.r. The same holds if we
substitute here “recursive” for “primitive recursive.” T is in either case
recursively enumerable.
Proof. Deﬁnition (2) on page 229 shows that bewT is p.r. Because of (3)
on the same page, ˙T = {a ∈
˙L0 | bwbT a} is the range of a (primitive)
recursive relation and thus is r.e. Clearly, the last part of the theorem is
proved in the same manner.

234
6 Incompleteness and Undecidability
Theorem 2.4 can be strengthened only under particular circumstances,
for example if T is complete. Although bewT is a (primitive) recursive
predicate for each axiomatic arithmetizable theory T, bwbT need not be
recursive, as, for example, in the case T = Q. This is a famous ﬁnitely
axiomatizable theory presented in the next section, whose particular role
for applied recursion theory was revealed in [TMR].
Exercises
1. Prove that if a theory T has a recursively enumerable axiom system
X, then T also possesses a recursive axiom system (W. Craig).
2. Let a ∈˙T \ ˙Tprim. Show that there are b, c ∈˙T with a = ˜Sb or
a = b˜+c or a = b˜· c. Moreover, b, c are unique and < a in each case.
3. Let a ∈˙L \ ˙Lprim. Show that there are b, c ∈˙L, d ∈˙V with a = ˜¬b
or a = b˜∧c or a = ˜∀(d, b, c). b, c, d are unique and < a in each case.
4. Let T be axiomatizable and α ∈L0
ar. (a) Deﬁne a binary p.r. f such
that bewT+α( ˙Φ, ˙ϕ) ⇒bewT (f( ˙Φ, ˙α), (α →ϕ)·) (the arithmetized de-
duction theorem). (b) Show that bwbT+α ˙ϕ ⇔bwbT (α →ϕ)·.
6.3
Representability of Arithmetical Predicates
First of all we consider the ﬁnitely axiomatized theory Q with the axioms
Q1: ∀x Sx̸====0,
Q2: ∀xy(Sx==== Sy →x==== y),
Q3: (∀x̸====0)∃y x==== Sy,
Q4: ∀x x + 0==== x,
Q5: ∀xy x + Sy ==== S(x + y),
Q6: ∀x x · 0==== 0,
Q7: ∀xy x · Sy ==== x · y + x.
The axioms characterize Q, also called Robinson’s arithmetic, as a modest
subtheory of PA. Both theories are formalized in Lar and are subtheories
of Th N, where N as always denotes the standard model (N, 0, S, +, ·). In
Q, PA and related theories in Lar, ⩽, and < are deﬁned by the formulas
x ⩽y ↔∃z z + x==== y and x < y ↔x ⩽y ∧x ̸==== y according to our
convention on page 105. The term Sn0 is denoted by n.
From the results of this and the next section, not only will the recursive
undecidability of Q be derived, but also that of every subtheory and every
consistent extension of Q; see 6.5. If we were interested only in undecid-
ability results, we could simplify the proof of Theorem 4.2 by noting that

6.3 Representability of Arithmetical Predicates
235
all recursive functions can already be obtained with Oc and Oμ from the
somewhat larger set of initial functions 0, S, In
ν , +, ·, ·−. But even ignoring
the considerable eﬀort required to prove the eliminability of the schema
Op at the price of additional initial functions, such an approach would
blur the distinction between primitive recursive and μ-recursive functions,
relevant for some details in Chapter 7.
∀x x ̸==== Sx is easily provable in PA by induction, but Q is too weak to
allow a proof of this sentence. Its unprovability follows from the fact that
(N ∪{∞}, 0, S, +, ·) satisﬁes all axioms of Q, but not ∀x x̸====Sx. Here ∞
is a new object and the operations S, +, · are extended to N ∪{∞} by
putting S∞= ∞, ∞· 0 = 0, and for all n and all m ̸= 0,
∞+ n = n + ∞= ∞+ ∞= n · ∞= ∞· m = ∞.
This model shows the unprovability in Q of many familiar laws of arith-
metic, which tell us that N is the nonnegative part of a discretely ordered
commutative ring with unit element 1 := S0. These laws are collected in
the following axiom system of a ﬁnitely axiomatizable theory N ⊆Lar,
with the order deﬁned as in Q above:
N0:
x + 0==== x
N1:
x + y ==== y + x
N2:
(x + y) + z ==== x + (y + z)
N3:
x·1==== x
N4:
x·y ==== y·x
N5:
(x·y)·z ==== x·(y·z)
N6:
x·(y + z)==== x·y + x·z
N7:
Sx==== x + 1
N8:
x + z ==== y + z →x==== y
N9:
x ⩽y ∨y ⩽x
N10: x ⩽0 →x==== 0
N11: x < y ↔Sx ⩽y
∀-quantiﬁers in the axioms are omitted.
N is also denoted by PA−in
the literature, and like Q, a subtheory of PA. All Q-axioms are derivable
in N (a recommendable exercise), so that Q ⊆N ⊆PA.
Reﬂexivity,
transitivity, and antisymmetry of ⩽are provable in N, as are the strong
and weak monotonicity laws for + and ·.
In this section we mostly write ⊢α for ⊢Q α and α ⊢β for α ⊢Q β etc.
We also write occasionally α ⊢β ⊢γ for α ⊢β & β ⊢γ, and apply further
self-explanatory abbreviations such as ⊢t1 ==== t2 ==== t3 for ⊢t1 ==== t2 ∧t2 ==== t3,
and ⊢α ≡β for ‘ ⊢Q α and α is equivalent to β ’. The use of ⊢in the subtle
derivations carried out below helps one see what is going on and makes
the metainduction used there more vivid. Some of the proofs can be seen

236
6 Incompleteness and Undecidability
as “transplanting inductions from PA into the metatheory.” For instance,
∀x x̸====Sx is provable in PA, but not in Q, as was just shown. Nonetheless,
we still can prove ⊢n ̸==== Sn for all n, as is seen by metainduction on n.
Indeed, ⊢0̸====S0 is clear by Q1. The induction step ⊢n̸====Sn ⇒⊢Sn̸====SSn
derives from n̸====Sn ⊢Sn̸====SSn. This in turn easily follows with MP from
Sn==== SSn ⊢n==== Sn, an application of Q2. We now prove
C0: ⊢Sx + n==== x + Sn,
C1: ⊢m + n==== m + n, m · n==== m · n,
C2: ⊢n̸====m
for n ̸= m,
C3: ⊢m ⩽n
for m ⩽n,
C4: ⊢m  n
for m  n,
C5: x ⩽n ⊢x==== 0 ∨· · · ∨x==== n,
C6: ⊢x ⩽n ∨n ⩽x.
From C5 follows x < n ⊢x==== 0 ∨· · · ∨x==== n −1 (= 
i<n x==== i), which
is ⊥for n = 0. The proofs of C0–C6 will be carried out by induction
(more precisely, metainduction) on n.
C0: Clear for n = 0, because ⊢Sx + 0==== Sx==== S(x + 0)==== x + S0 by Q4
and Q5. Our induction hypothesis is ⊢Sx + n==== x + Sn. It yields, again
by Q5, the induction claim ⊢Sx + Sn==== S(Sx + n)==== S(x + Sn)==== x + SSn.
C1: Clear for n = 0, because ⊢m+0==== m==== m + 0 by Q4. The induction
hypothesis ⊢m + n==== m + n yields ⊢m + Sn==== S(m + n)==== S m + n, by
Q5, and the last term is the same as m + Sn. This proves the induction
step. Analogously we derive ⊢m · n==== m · n with Q6, Q7, and what was
shown already.
C2: Clear for n = 0, since then m = Sk for some k, and so ⊢0̸====m by
Q1. Let Sn ̸= m. By Q1, ⊢Sn̸====m in case m = 0. Otherwise, m = Sk for
some k, so that n ̸= k; hence ⊢n̸====k by the induction hypothesis. Thus,
⊢Sn̸====Sk ==== m by Q2.
C3: m ⩽n implies k + m = n for some k, hence k + m = n. Thus,
⊢k + m==== n by C1. Therefore ⊢∃z z + m==== n, i.e., ⊢m ⩽n.
C4: m  n ⇒m ̸= 0, hence m = Sk for some k. Let m  0. Then
⊢m  0 because m ⩽0 ⊢Sk ⩽0 ⊢∃v S(v+k)==== 0 ⊢⊥by Q5, Q1. Let
m  Sn. Then k  n, and so ⊢k  n by the induction hypothesis. Hence
⊢m  Sn, for x ⩽y ≡Q Sx ⩽Sy (the latter needs only Q5 and Q2).
C5: Clear for n = 0, because x ̸==== 0, x ⩽0 ⊢∃vSv ==== 0 ⊢⊥by Q3, Q5,
Q1. The induction claim is equivalent to x̸====0, x ⩽Sn ⊢n+1
i=1 x==== i. It is
derived as follows:

6.3 Representability of Arithmetical Predicates
237
x̸====0, x ⩽Sn
⊢∃y(x==== Sy ∧y ⩽n)
(Q3, Q5, and Q2)
⊢∃y(x==== Sy ∧
i⩽n y ==== i)
(induction hypothesis)
⊢∃y(x==== Sy ∧n+1
i=1 Sy ==== i) ⊢n+1
i=1 x==== i.
C6: Clear for n = 0. Further, n < x ⊢∃ySy + n==== x ⊢∃yy + Sn==== x, by
Q3, C0, and ⊢0 + n==== n by C1. Thus, n < x ⊢Sn ⩽x. Now, C5 and C3
easily lead to x ⩽n ⊢x ⩽Sn. This and the former yield the inductive
step, because x ⩽n ∨n ⩽x ⊢x ⩽n ∨n < x ⊢x ⩽Sn ∨Sn ⩽x.
With these preparations we now give the following crucial deﬁnition, in
which T ⊇Q is supposed. This will cover all our applications.
Deﬁnition. Call a predicate P ⊆Nn numeralwise representable or simply
representable in T (⊇Q)3 if there is some α = α(⃗x), called a representing
formula, such that
R+: P⃗a ⇒⊢T α(⃗a) ;
R−: ¬P⃗a ⇒⊢T ¬α(⃗a).
Examples. The identity relation {(a, a) | a ∈N} is represented by x==== y,
because ⊢Q a==== b is trivial if a = b, and ⊢Q a̸====b is derivable for a ̸= b by
C2. By C3 and C4 the formula x ⩽y represents the ⩽-predicate. x ̸====x
represents the empty set, represented as well by any α with ¬α ∈Q.
For consistent T ⊇Q, whenever R+, R−are valid then so too are their
converses, so that in fact P⃗a ⇔⊢T α(⃗a) and ¬P⃗a ⇔⊢T ¬α(⃗a). Note
also that a representable P ⊆Nn is recursive by Church’s thesis. For let
P be represented by α(⃗x). Simply turn on the enumeration machine for
Q and wait until α(⃗a) or ¬α(⃗a) appears. The set of n-ary representable
predicates is closed under union, intersection, and complement, as well as
swapping, equating, and adjoining ﬁctional arguments. If P, Q are repre-
sented respectively by α(⃗x), β(⃗x), then so too are P ∩Q by α(⃗x) ∧β(⃗x)
and ¬P by ¬α(⃗x). Consequently, P ∪Q by α(⃗x) ∨β(⃗x), etc.
A predicate P represented in Q by α is clearly representable by the
same α in any consistent extension of Q, in particular in Th N.
But
this just means deﬁnability of P in N by α in the sense of 2.3, because
N ⊨α [⃗a] is equivalent to N ⊨α(⃗a). In short, deﬁnability of P in N and
representability of P in Th N coincide. In the main, however, we consider
3 ‘in T’ will often be omitted; we then always mean ‘in T = Q’. Representable pred-
icates are called entscheidungsdeﬁnit in [Gö2] (translated as decidable in [Hei]), in
[HB] vertretbar, in [Kl1] numeralwise expressible, and in [TMR] deﬁnable.

238
6 Incompleteness and Undecidability
representability in Q to obtain some strong results needed in 6.5. We
always have to look carefully at the representing formulas.
One could deﬁne f ∈Fn to be representable if graph f is representable.
However, it turns out that this deﬁnition is equivalent to a stronger no-
tion of representability for functions that will be introduced after some
additional preparation.
Predicates and functions deﬁnable in N, that is, by 0, S.+, ·, are called
arithmetical after [Gö2]. From now on this word will always have this
meaning. The arithmetical predicates encompass the representable ones.
In order to discover more about these objects we consider their deﬁning
formulas more closely. Prime formulas in Lar are equations, also called
Diophantine equations for traditional reasons. If δ(⃗x, ⃗y) is such an equa-
tion and P⃗a ⇔N ⊨∃⃗yδ(⃗a, ⃗y), then P is called Diophantine. A simple
example is ⩽, because a ⩽b ⇔∃y y + a = b.4 In fact, all predicates de-
ﬁnable in N by ∃-formulas ∃⃗yϕ from Lar with kernel ϕ are Diophantine.
The proof is not diﬃcult: Think of ϕ as being constructed from literals by
means of ∧, ∨(cf. Exercise 4 in 2.4), and use the following easily provable
equivalences in an inductive proof on ϕ of what has been claimed:
s̸====t
≡N
∃z(Sz + s==== t ∨Sz + t==== s),
s1 ==== t1 ∨s2 ==== t2
≡N
s1s2 + t1t2 ==== s1t2 + s2t1,
s1 ==== t1 ∧s2 ==== t2
≡N
s 2
1 + t 2
1 + s 2
2 + t 2
2 ==== 2(s1t1 + s2t2).
A classiﬁcation of arithmetical formulas and predicates helpful not only
for the sake of representability is given by the following deﬁnition, to be
generalized in 6.7:
Deﬁnition. A formula is called Δ0 or a Δ0-formula if it is generated
from prime formulas of Lar by ∧, ¬, and bounded quantiﬁcation, i.e., if
α is Δ0 then so is (∀x⩽t)α; here t is any Lar-term with x /∈var t. (It
is not important that x⩽t is not a prime formula of Lar). Let ϕ be Δ0
and ⃗x arbitrary. Then ∃⃗xϕ is called a Σ1-formula, and ∀⃗xϕ a Π1-formula.
Further, P ⊆Nn is said to be Δ0, Σ1, or Π1 whenever P is deﬁned in
N by a Δ0-, Σ1-, or Π1-formula, respectively. Δ0, Σ1, and Π1 denote
the sets of Δ0-, Σ1-, and Π1-predicates.
In addition, Δ1 := Σ1 ∩Π1.
There are no Δ1-formulas, for there is no meaningful deﬁnition of such
4 The right side of this equivalence is an informal and more easily readable substitute
for the somewhat lengthy notation N ⊨∃y y + a ==== b.

6.3 Representability of Arithmetical Predicates
239
formulas. ϕ is called Δ0, Σ1, or Π1 also if it is equivalent to an original
Δ0-, Σ1-, or Π1-formula, respectively. In this sense, if α is Δ0 then so too
are (∃x⩽t) α
	
≡¬(∀x⩽t)¬α

and (∀x<t)α
	
≡(∀x⩽t)(x==== t ∨α)

.
Clearly, Π1 consists of the complements of the P ∈Σ1. The P ∈Δ1 are
both Σ1- and Π1-deﬁnable, with possibly distinct formulas. By Exercise 3
in 2.4, Σ1 and Π1 are closed under union and intersection of predicates of
the same arity, and Δ1 like Δ0 moreover under complements. If P ∈Nm
and g1, . . . , gm ∈Fn are Σ1, so too is Q = P[g1, . . . , gm], simply because
Q⃗a ⇔∃⃗y(n
i=1 yi=gi⃗a & P⃗y). Note also that if graph f is Σ1 then it is
automatically Δ1, for f⃗a̸=b ⇔∃y(f⃗a=y & y̸=b), so that the complement
of graph f is again Σ1. Here some examples of Δ0- and Σ1-formulas and
sentences. Interesting Π1-sentences are found at the end of 6.5.
Examples. Diophantine equations are the simplest Δ0-formulas. To these
belong the formulas y ==== t(⃗x) with y /∈var t, which deﬁne the term func-
tions ⃗a 
→tN (⃗a). Since a b ⇔(∃c⩽b)(a · c = b), divisibility and thus also
the predicate prim are Δ0. Because ℘(a, b) = c ⇔2c = (a + b)2 + 3a + b,
graph℘is Δ0. The same holds for the relation of being coprime, denoted
by ⊥and deﬁned by a⊥b :⇔(∀c ⩽a + b)(c a, b ⇒c = 1). Diophantine
predicates are trivially Σ1.
Surprisingly, by Theorem 5.6 the converse
holds as well, although it had originally been conjectured that, for in-
stance, the set {a ∈N | (∀p⩽a)(prim p & p a ⇒p = 2)} of all powers of 2
was not Diophantine. This set is Δ0. Even the graph of n 
→2n is Δ0.
Remark 1. More generally, the predicate ‘ab = c’ is Δ0, though it is diﬃcult to
prove this fact. Indeed, even the proof in 6.4 that this predicate is arithmetical
requires eﬀort. Earlier results from Bennet, Paris, Pudlak, among others, are
generalized in [BA] as follows: if f ∈Fn+1 (more precisely, graph f) is Δ0 then so
is g: (⃗a, n) 
→
i⩽n f(⃗a, i), and the recursion equation g(⃗x, Sy)==== g(⃗x, y) · f(⃗x, y)
is provable in IΔ0. This theory is an important weakening of PA. It results from
Q by adjoining the induction schema restricted to Δ0-formulas. IΔ0 plays a role
in various questions, e.g., in complexity theory ([Kra] or [HP]). Induction on the
Δ0-formulas readily shows that all Δ0-predicates are p.r. The converse does not
hold; an example is the graph of the very rapidly growing hyperexponentiation,
recursively deﬁned by hex(a, 0) = 1 and hex(a, Sb) = ahex(a,b). Stated more
suggestively, hex(a, n) = aa··· a
  
n
.
According to Theorem 3.1 below, already the weak theory Q is Σ1-
complete, i.e., each Σ1-sentence true in N is provable in Q. This can be

240
6 Incompleteness and Undecidability
conﬁrmed in various ways. For instance, one may use that by C1 and C2,
N is a prime model of Q in the sense of 5.1; in addition, each A ⊨Q is an
end extension of N as deﬁned in 3.3. But we choose here a constructive
approach, which provides some additional information.
Theorem 3.1 (on the Σ1-completeness of Q). Every Σ1-sentence true
in N is already provable in Q and hence in each extension T ⊇Q.
Proof. We claim that it suﬃces to prove
(∗)
Either ⊢Q α or ⊢Q ¬α, for each Δ0-sentence α.
Indeed, let N ⊨∃⃗xϕ(⃗x) with the Δ0-formula ϕ(⃗x), say N ⊨α := ϕ(⃗a).
Then ⊢Q α by (∗), for ⊢Q ¬α is impossible. Hence ⊢Q ∃⃗xϕ(⃗x). We verify
(∗) ﬁrst for prime sentences. If t is a variable-free term then C1 readily
yields ⊢Q t==== tN . For example, ⊢Q (3 + 4)·5==== 35. Thus, if α is the prime
sentence t1 ==== t2, then ⊢Q tN
1 ==== tN
2 or ⊢Q tN
1 ̸==== tN
2 by C2, which conﬁrms
(∗) for α. The induction steps over ∧, ¬ are simple. For instance, ⊢Q α ∧β
if ⊢Q α, β, and ⊢Q ¬α ∨¬β ≡¬(α ∧β) otherwise, i.e. if ⊢Q ¬α or ⊢Q ¬β.
These steps suﬃce already to prove (∗), because bounded quantiﬁers are
eliminable from a Δ0-sentence α modulo Q. Indeed, let (∀x⩽t) be the ﬁrst
bounded quantiﬁer in α from the left, with the scope β. Then var t = ∅,
because x /∈var t and any y ∈var t must have been bounded further
to the left. Moreover, (∀x⩽t)β(x) ≡Q (∀x⩽n)β(x) with n := tN , since
⊢Q t==== n. We then easily get (∀x⩽n)β(x) ≡Q β(0) ∧· · · ∧β(n) with C3
and C5. Thus, (∀x⩽t) can be eliminated from α and this process can be
repeated if necessary.
If ϕ(⃗x) is Δ0 then N ⊨ϕ(⃗a) ⇒⊢Q ϕ(⃗a) and N ⊨¬ϕ(⃗a) ⇒⊢Q ¬ϕ(⃗a)
by the theorem, because both ϕ(⃗a) and ¬ϕ(⃗a) are trivially Σ1. Thus, we
obtain a ﬁrst important result on representing formulas:
Corollary 3.2. A Δ0-formula represents in Q the predicate that it deﬁnes
in N.
Lemma 3.3. Let α(⃗x, y) represent P ⊆Nn+1. Then (∃z<y)α(⃗x, z) and
(∀z<y)α(⃗x, z) represent the predicates Q and R, respectively, where
Q(⃗a, b) :⇔(∃c<b)P(⃗a, c) and R(⃗a, b) :⇔(∀c<b)P(⃗a, c).
The same is true if < is replaced by ⩽in this lemma.

6.3 Representability of Arithmetical Predicates
241
Proof. R+: Suppose Q(⃗a, b), that is, P(⃗a, c) for some c < b.
Then
⊢c < b ∧α(⃗a, c). Consequently, ⊢(∃z<b)α(⃗a, z). To prove R−suppose
¬Q(⃗a, b), hence ¬P(⃗a, i), i.e., ⊢¬ϕ(⃗a, i) for all i < b. We thus obtain

i<b z ==== i ⊢¬α(⃗a, z). By C5, z < b ⊢
i<b z ==== i and so z < b ⊢¬α(a, z).
Therefore, ⊢(∀z<b)¬α(⃗a, z) ≡¬(∃z<b)α(⃗a, z).
This proves R−.
For
handling the predicate R simply notice that R(⃗a, b) ⇔¬(∃c<b)¬P(⃗a, c).
This proof is literally the same if < is replaced by ⩽in the lemma.
Following [Gö2] and [TMR], we now deﬁne the notion of a representable
function. Although representability of f is much stronger a notion than
representability of graph f, Lemma 3.4(b) will show that both properties
coincide, provided the axioms of Q are available.
Deﬁnition. f ∈Fn is representable in T if there is a formula ϕ(⃗x, y) ∈Lar
such that for all ⃗a ∈Nn,
R+ :
⊢T ϕ(⃗a, f⃗a),
R= :
ϕ(⃗a, y) ⊢T y ==== f⃗a.
If ϕ is Δ0 (respectively Σ1 or Π1) then f is said to be Δ0-representable
(respectively Σ1- or Π1-representable).
For some purposes it is useful to reﬁne this deﬁnition: f ⊆Fn is said to
be Δ1-representable if f is both Σ1- and Π1-representable, with usually
distinct formulas. Corresponding phrases will be used for predicates P
instead of functions f.
Since R+ is equivalent to y ==== f⃗a ⊢T ϕ(⃗a, y), it is obvious that R+ and
R= together are replaceable by the single condition y ==== f⃗a ≡T ϕ(⃗a, y) for
all ⃗a. If f is represented by ϕ(⃗x, y) then graph f is represented by the same
formula, because if b ̸= f⃗a and hence ⊢b̸====f⃗a by C2, then ⊢¬ϕ(⃗a, b) by
R=, so that the condition R−holds. The following lemma will show in
particular that f is representable provided graph f is representable.
Lemma 3.4. (a) Let P ⊆Nn+1 be represented by α(⃗x, y) and suppose
that ∀⃗a ∃bP(⃗a, b).
Then ϕ(⃗x, y) := α(⃗x, y) ∧(∀z<y)¬α(⃗x, z) represents
the function f :⃗a 
→μb[P(⃗a, b)]. If P is Δ0-representable then so too is f.
If P is Δ1-representable then so is f.
(b) f is representable provided graph f is representable.
(c) If f is Σ1-representable then f is Π1-representable as well.
(d) If χP is Σ1-representable then P is Δ1-representable.

242
6 Incompleteness and Undecidability
Proof. By Lemma 3.3, ϕ(⃗x, y) represents the predicate deﬁned by ϕ(⃗x, y)
and this is clearly graph f. Hence, R+ holds. We verify R= by proving
(∗)
α(⃗a, y) ∧(∀z<y)¬α(⃗a, z) ⊢y ==== f⃗a.
Suppose b := f⃗a. Then b < y ⊢(∃z<y)α(⃗a, z), because ⊢α(⃗a, b). Con-
traposition yields (∀z<y)¬α(⃗a, z) ⊢b ≮y.
By C5 and R−we have
y < b ⊢
i<b y ==== i ⊢¬α(⃗a, y). Hence α(⃗a, y) ⊢y ≮b and so, by C6,
α(⃗a, y) ∧(∀z<y)¬α(⃗a, z) ⊢y ≮b ∧b ≮y ⊢y ==== b.
This conﬁrms (∗).
Clearly, ϕ in (a) is Δ0 if α is Δ0.
Let P be rep-
resented at the same time by the Π1-formula β.
Repeating the above
with α(⃗x, y) ∧(∀v<y)¬β(⃗x, v) (a Σ1-formula by Exercise 2) in place of
ϕ shows that f is Σ1-representable. It is then also Δ1-representable by
item (c).
(b) follows from applying (a) to P = graph f while noting
that f⃗a = μb[P(⃗a, b)]. (c): Let the Σ1-formula ϕ(⃗x, y) represent f and
z /∈var ϕ. Then ϕ′(⃗x, y) := ∀z(ϕ(⃗x, z) →z ==== y) is a Π1-formula that rep-
resents f as well: Application of R= results in ⊢ϕ′(⃗a, f⃗a), which conﬁrms
R+ for ϕ′, and because of ⊢ϕ(⃗a, f⃗a), we obtain R= for ϕ′ from
ϕ′(⃗a, y) = ∀z(ϕ(⃗a, z) →y ==== z) ⊢ϕ(⃗a, f⃗a) →y ==== f⃗a ⊢y ==== f⃗a.
(d): Let χP be Σ1-represented by ϕ(⃗x, y). Then P is Σ1-represented by
ϕ(⃗x, 1) and Π1-represented by ¬ϕ(⃗x, 0), as is easily conﬁrmed.
Remark 2.
α(x, y, z) := z · 2 ==== (x + y) · S(x + y) + x · 2 represents graph ℘in
Q. Thus, the Δ0-formula α(x, y, z) ∧(∀u<z)¬α(x, y, u) represents ℘according
to Lemma 3.4(a).
We mention that in PA (but not in Q) the function ℘is
represented even by the open formula α.
Lemma 3.5. Let P ⊆Nk be represented by α(⃗y), and gi ∈Fn represented
by γi for i = 1, . . . , k. Then β(⃗x) := ∃⃗y [
i γi(⃗x, yi) ∧α(⃗y)] represents the
predicate Q := P[g1, . . . , gk]. If the γi are Σ1 and P is Σ1-representable
or Δ1-representable, then the corresponding holds for Q.
Proof. Let bi := gi⃗a, so that ⊢γi(⃗a, bi), and ⃗b = (b1, . . . , bk).
If Q⃗a
holds, hence P⃗b, then ⊢α(⃗b), whence ⊢
i γi(⃗a, bi)
∧α(⃗b), and so
⊢β(⃗a).
But if ¬Q⃗a and thus ¬P⃗b, then clearly ⊢¬α(⃗b).
Using R=
for the γi, this then yields 
i γi(⃗a, yi) ⊢
i yi ==== bi ⊢¬α(⃗y).
Hence
⊢∀⃗y [
i γi(⃗a, yi) →¬α(⃗y)] ≡¬β(⃗a). If the γi and also α are Σ1, then so
too is β. If P is represented by the Π1-formula α′(⃗x) at the same time,
then the Π1-formula ∀⃗y [
i γi(⃗x, yi) →α′(⃗y)] represents Q as well.

6.4 The Representability Theorem
243
From this lemma, applied to graph h, follows without diﬃculty
Corollary 3.6. If h ∈Fm is representable by β and the gi ∈Fn by γi,
then ϕ(⃗x, z) := ∃⃗y [
i γi(⃗x, yi) ∧β(⃗y, z)] represents f = h[g1, . . . , gm].
Exercises
1. Let ∃⃗xα be Σ1 and ∀⃗xα be Π1. Construct Δ0-formulas β and γ
such that ∃⃗xα ≡N ∃xβ and ∀⃗xα ≡N ∀xγ (quantiﬁer compression).
Since a Δ0-predicate is p.r. (Remark 1), each Σ1-predicate is r.e.
and w.l.o.g. of the form (∃b∈N)Q(⃗a, b) with Q ∈Δ0.
2. Show using (c) from Exercise 4 in 3.3 that Σ1 is closed under
bounded quantiﬁcation, that is, if α = α(⃗x, ⃗y, y) and ∃⃗xα is Σ1
(deﬁnes an (m + 1)-ary Σ1-predicate), then also (∀z<y)∃⃗xα zy and
(∃z<y)∃⃗xα zy are Σ1. Derive the corresponding for Π1 and Δ1.
3. Prove that α(⃗x) ∧y ==== 1 ∨¬α(⃗x) ∧y ==== 0 represents χP provided α
represents P.
4. Show that every Δ0-formula is equivalent to a Δ0-formula built up
from literals by means of ∧, ∨, and the bounded quantiﬁers (∀x⩽t)
and (∃x⩽t), a correspondence to Exercise 4 in 2.4.
6.4
The Representability Theorem
For the representability of all recursive or just all p.r. functions, it is
helpful to have a representable g ∈F2 that satisﬁes the following: for
every n and every sequence c0, . . . , cn there exists a number c such that
g(c, i) = ci for all i ⩽n. In short, c can be chosen such that the val-
ues g(c, 0), g(c, 1), . . . , g(c, n) are the given ones. Now, there are many
p.r. functions g that can do this, for example g: (c, i) 
→(((c)))i for choosing
c = p1+c0
0
· · · p1+cn
n
. Initially there is no obvious way to show the repre-
sentability of such a function g in Q or in some extension of Q within the
language Lar. Therefore, K. Gödel, who around 1930 was working on this
and related problems, in the words of A. Mostowski “phoned with God.”
Although nowadays several possibilities are known, we follow the original,
which has not lost any of its attraction.

244
6 Incompleteness and Undecidability
Let α(a, b, i) := rem(a, (1 + (1 + i)b)), where rem(a, d) denotes the
remainder of a divided by d (̸= 0). In addition, rem(a, 0) := 0. Note that
r = rem(a, d) is well deﬁned, since for any a and d ̸= 0 there are unique
q, r ∈N with a = qd + r and r < d (readily shown by induction on a).
Clearly, graph α has the Δ0-deﬁnition
α(a, b, i) = k ⇔(∃q⩽a)[a = q(1 + (1 + i)b) + k & k < 1 + (1 + i)b].
Hence, the function α is Δ0-representable by Lemma 3.4(b). The same
holds for the pairing function ℘. Because ℘is bijective there are unary
functions κ1, κ2 such that ℘(κ1k, κ2k) = k for all k. Their explicit form
is insigniﬁcant; we just require the obvious property κ1k, κ2k ⩽k. The
function β: (c, i) 
→α(κ1c, κ2c, i) is called the β-function. Since
β(c, i) = k ⇔(∃a⩽c)(∃b⩽c)[℘(a, b) = c & α(a, b, i) = k],
graph β is Δ0. Hence, according to Lemma 3.4, β is represented by a Δ0-
formula, which will be denoted by beta. Omitting the argument paren-
theses in beta, this means that
(1)
⊢Q beta c i y ↔y ==== β(c, i), for all c, i ∈N.
Clearly, beta also deﬁnes the β-function in N. The following simple
number-theoretic facts known for ages will be applied in proving the main
property of the β-function stated in Lemma 4.1 below.
Euclid’s lemma. Let a, b be positive and coprime (a⊥b). Then there
exist x, y ∈N such that xa + 1 = yb.
(The converse of this claim is
obvious: c a, b implies c yb−xa = 1 and hence c = 1.)
Proof by <-induction on s = a + b. Trivial for s ⩽2, i.e., a = b = 1.
Let s > 2. Then a ̸= b, say a > b, and clearly a −b⊥b as well. Since
(a −b) + b < s, there are x, y ∈N with x(a −b) + 1 = yb by the induction
hypothesis. Hence, xa + 1 = y′b with y′ = x + y. In the case a < b
consider a⊥b−a, so that xa+1 = y(b−a) for some x, y by the induction
hypothesis. Hence (x + y)a + 1 = yb.
Chinese remainder theorem.
Let ci < di for i = 0, . . . , k and let
d0, . . . , dk be pairwise coprime. Then there exists some a ∈N such that
rem(a, di) = ci for i = 0, . . . , k.
Proof by induction on k. For k = 0 this is clear with a = c0. Let the
assumptions hold for k > 0. By the induction hypothesis, rem(a, di) = ci

6.4 The Representability Theorem
245
for some a and all i < k. Since d0, . . . , dk are coprime, m := lcm{dκ | ν<k}
and dk are coprime (Exercise 1c). Thus, by Euclid’s lemma, there are
x, y ∈N such that xm+1 = ydk. Multiplying both sides by ck(m−1)+a,
we obtain x′m + ck(m −1) + a = y′dk with new values x′, y′ ∈N. Put
a′ := (x′ + ck)m + a = y′dk + ck. Then rem(a′, di) = rem(a, di) = ci for
all i < k, since di m. But also rem(a′, dk) = ck, because ck < dk.
Unlike those in most textbooks of number theory, the proof above is
constructive and easily transferable to PA, as will be shown in 7.1. In
logic it is occasionally not just important what you prove, but how you
prove it. The claim of Euclid’s lemma can also be shown by means of the
Euclidean algorithm for determining lcm(a, b).
Lemma 4.1 (on the β-function). For every n and every sequence
c0, . . . , cn there exists some c such that β(c, i) = ci for i = 0, . . . , n.
Proof. It suﬃces to provide numbers a and b such that α(a, b, i) = ci for
all i ⩽n. Because of β(℘(a, b), i) = α(a, b, i) the claim is then satisﬁed
with c = ℘(a, b). Let m := max{n, c0, . . . , cn} and b := lcm{1, . . . , m}.
We claim that the numbers di := 1 + (1 + i) · b > ci (i ⩽n) are pairwise
coprime. For otherwise let p be a common prime factor of di, dj with
i < j ⩽n. Then p dj −di = (j −i)b; hence p j −i or p b. But since
j −i b in view of j −i ⩽n ⩽m, it follows that p b in any case. Since
b di −1 this yields p di −1, contradicting p di. Hence, d0, . . . , dn are
indeed pairwise coprime. By the Chinese remainder theorem there is an
a such that rem(a, di) = ci, that is, α(a, b, i) = ci for i = 0, . . . , n.
Remark 1. Already at this stage we gain the interesting insight that the expo-
nential function (a, b) 
→ab is explicitly deﬁnable in N, namely by
δexp(x, y, z) := ∃u[β(u, 0)==== S0 ∧(∀v<y) β(u, Sv)==== β(u, v) · x ∧β(u, y)==== z].
This is a Σ1-formula, more precisely, the description of a Σ1-formula arising after
the elimination of the occurring β-terms by means of (1), using some further
∃-quantiﬁers instead. By induction on b one sees that N ⊨δexp(a, b, c) implies
ab = c. Suppose conversely that ab = c. Then Lemma 4.1 guarantees a suitable
u such that N ⊨δexp(a, b, c): choose u such that β(u, i) = ai for all i ⩽b. This
argument is generalized in Theorem 4.2 below. It tells us in particular that each
recursive function is explicitly deﬁnable in N.
For simplicity, we assume T ⊇Q in Theorem 4.2 below, though it
holds as well if Q is merely interpretable in T in the sense of 6.6. For

246
6 Incompleteness and Undecidability
the derivation of undecidability results or a simpliﬁed version of the ﬁrst
incompleteness theorem, the theorem’s “Moreover” part is not needed.
Theorem 4.2 (Representability theorem). Each recursive function
f—and hence every recursive predicate—is representable in an arbitrary
consistent axiomatic extension T ⊇Q. Moreover, f is Σ1-representable.
Proof. It suﬃces to construct a Σ1-formula that represents f in Q. For
the initial functions 0, S, In
ν we may choose the formulas v0 ==== 0, v1 ==== Sv0,
and vn ==== vν. As regards Oc, let f = h[g1, . . . , gm] and suppose β(⃗y, z) and
γi(⃗x, yi) are Σ1-formulas representing h and the gi. Then by Corollary 3.6,
ϕ(⃗x, z) := ∃⃗y [
i γi(⃗x, yi) ∧β(⃗y, z)] is such a formula for f.
Next let
f = Op(g, h), with g, h both being Σ1-representable. Deﬁne
P(⃗a, b, c) :⇔β(c, 0) = g⃗a & (∀v<b)β(c, Sv) = h(⃗a, v, β(c, v)).
According to Lemmas 3.5 and 3.3, P is Δ1-representable (use composi-
tion, instantiation of Σ1-representable functions, bounded quantiﬁcation,
and conjunction). Clearly P(⃗a, b, c) is equivalent to (∗): β(c, i) = f(⃗a, i)
for all i ⩽b.
By Lemma 4.1, for given ⃗a, b there is some c satisfying
(∗); hence we know that ∀⃗a, b ∃cP(⃗a, b, c). Thus, ˜f : (⃗a, b) 
→μc[P(⃗a, b, c)]
is Σ1-representable; Lemma 3.4(a). Since P(⃗a, b, ˜f(⃗a, b)), (∗) holds with
c = ˜f(⃗a, b), which yields f(⃗a, b) = β( ˜f(⃗a, b), b) for i = b. Thus, as a com-
position of Σ1-representable functions, f is Σ1-representable. Finally, let
f result from g by Oμ, f⃗a = μb[P(⃗a, b)], where P(⃗a, b) ⇔g(⃗a, b) = 0 and
g is Σ1-representable. By Lemma 3.4(c), g is Π1-representable, too. This
clearly implies that P is Δ1-representable. Hence, f is Σ1-representable
by Lemma 3.4(a).
Let T ⊇Q be a theory in Lar. To ϕ ∈Lar corresponds within T the
term n with n := ˙ϕ, which will be denoted by ⌜ϕ⌝(or ˙ϕ) and called the
Gödel term of ϕ. For example, ⌜v0 ==== 0⌝is ˙v0 ˜==== ˙0 (= 222 · 32 · 514). Anal-
ogously ⌜t⌝is deﬁned for terms t. For instance, ⌜1⌝= ⌜S0⌝= 216 · 314.
If T is axiomatized, also ⌜Φ⌝= ˙Φ for proofs Φ in T is well deﬁned. For
instance, (v0 ==== v0) is for such a T a trivial proof of length 1 by axiom
Λ9 in 3.6.
Its Gödel term is 2 ˙v0 ˜=
==
= ˙v0 + 1 .
The predicate bewT is p.r.
(Theorem 2.4), hence Σ1-representable (Theorem 4.2), by the formula
bewT (y, x), say. Deﬁne bwbT (x) := ∃y bewT (y, x). Then Theorem 4.2 and
(4) from page 230 obviously yield the following important

6.4 The Representability Theorem
247
Corollary 4.3. If T ⊇Q is axiomatizable then ⊢T ϕ ⇒⊢T bewT (n, ⌜ϕ⌝)
for some n, and ⊬T ϕ ⇒⊢T ¬ bewT (n, ⌜ϕ⌝) for all n.
Hence, ⊢T ϕ
implies ⊢T bwbT (⌜ϕ⌝) in any case.
The converse ⊢T bwbT (⌜ϕ⌝)
⇒⊢T ϕ need not hold; see 7.1. The-
orem 4.2 has several important consequences, for example Theorem 4.5
below.
Before stating it we will acquaint ourselves with a method of
eliminating Church’s thesis from certain intuitively clear arguments that
demand justiﬁcation when ‘decidable’ is identiﬁed with ‘recursive’.
Of
course, such an elimination must in principle always be possible if the
thesis is to retain its legitimacy. For instance, Church’s thesis was essen-
tially used in the proof of Theorem 3.5.2. We reformulate the theorem
and will give a rigorous proof.
Theorem 4.4. A complete axiomatizable theory T is recursive.
Proof. Because of completeness, the function
f : a 
→μb[a ∈˙L0 ⇒bewT (b, a) ∨∨∨bewT (b, ˜¬a)]
is well deﬁned. Indeed, let P(a, b) denote the recursive predicate in square
brackets. Then ∀a∃bP(a, b) (note that P(a, 0) if a /∈˙L0). By Oμ, then, f
is recursive. We claim (∗): a ∈˙T ⇔a ∈˙L0 & bewT (fa, a). This clearly
implies the recursiveness of T. In order to prove (∗) let a ∈˙T, so certainly
a ∈˙L0. Then for b = fa, the smallest b such that bewT (b, a)∨∨∨bewT (b, ˜¬a),
the ﬁrst disjunct must hold, because due to the consistency of T, no c ∈N
with bewT (c, ˜¬a) can exist at all. Hence, bewT (fa, a). The ⇐-direction in
(∗) is obvious.
This proof illustrates suﬃciently well the distinction between a primitive
recursive and a recursive decision procedure.
Even when X and thus
the predicate P in the proof above are primitive recursive, the deﬁned
recursive function f need not be so, because the completeness of T may
have been established in a nonconstructive way.
The use of Church’s
thesis in the proofs of (i)⇒(ii) and (iii)⇒(ii) of the following theorem can
be eliminated in almost exactly the same manner as above, although then
the proof would lose much of its transparency.
Theorem 4.5. For a predicate P ⊆Nn and any consistent axiomatizable
theory T ⊇Q the following are equivalent:
(i) P is representable in T,
(ii) P is recursive,
(iii) P is Δ1.

248
6 Incompleteness and Undecidability
Proof. (i)⇒(ii): Suppose P is represented in T by α(⃗x). Given ⃗a we set
going the enumeration machine of T and wait until α(⃗a) or ¬α(⃗a) appears.
Thus, P is decidable and hence recursive by Church’s thesis. (ii)⇒(i),(iii):
By Theorem 4.2, χP is representable in T by a Σ1-formula; hence P is
Δ1-representable by Lemma 3.4(d) and of course by the corresponding
formulas also deﬁned in N. Thus, P ∈Δ1. (iii)⇒(ii): Let P be deﬁned
by the Σ1-formula α(⃗x) and the Π1-formula β(⃗x). Given ⃗a we start the
enumeration machine for Q and wait until the Σ1-sentence α(⃗a) or ¬β(⃗a)
appears.
In the ﬁrst case P⃗a holds; in the second it does not.
This
procedure terminates because Q is Σ1-complete by Theorem 3.1.
This theorem tells us that in all consistent axiomatic extensions of Q
exactly the same predicates are representable, namely the recursive ones.
Moreover, Δ1 contains precisely the recursive predicates, from which it
easily follows that Σ1 consists just of all r.e. predicates. Theorem 4.5 clar-
iﬁes fairly well the close relationship between logic and recursion theory.
It is independent of Church’s thesis. Even if the thesis for certain theo-
retical or practical reasons had to be revised, the distinguished role of the
μ-recursive functions would not be aﬀected.
Remark 2. The above results allow us to deﬁne recursive or decidable predicates
directly as follows: P ⊆N n is recursive iﬀthere is some ﬁnitely axiomatizable
theory in which P is representable. We need only to notice that a predicate rep-
resentable in any ﬁnitely axiomatizable theory in which representability makes
sense is recursive by Church’s thesis. In this and the previous section we met
several formulas or classes of those that represent predicates in Q and hence
are recursive. It would of course be nice to provide a somewhat more uniform
system of formulas that represent the recursive predicates, or at least that deﬁne
them in N. Unfortunately, such a system of formulas cannot be recursively enu-
merated. Indeed, suppose there is such an enumeration. Let α0, α1, . . . be the
resulting subenumeration of its members in L1
ar. These deﬁne in N the recursive
sets. Then also {n ∈N | n /∈αN
n } is recursive, hence is deﬁned in N by αm,
say, so that n ∈αN
m ⇔n /∈αN
n . However, this equivalence yields for n = m the
contradiction m ∈αN
m ⇔m /∈αN
m.
In 6.5 we need a p.r. “substitution” function and in 7.1 a generalization.
Let cf n := ˙n (= (n)·) denote the Gödel number of the “cipher term”
n (= Sn0). Then n 
→cf n is p.r., since cf 0 = ˙0 and cf Sn = ˙S ∗cf n.
Let sbx(m, n) = [m]cfn
˙x
and deﬁne sb⃗x ∈Fn+1 inductively on the length n
of ⃗x ∈Varn by sb∅(m) = m and sb⃗xx(m,⃗a, a) = sbx(sb⃗x(m,⃗a), a). Here
x1, . . . , xn, x denote distinct variables. Clearly, the sb⃗x are all p.r.

6.4 The Representability Theorem
249
Let ˙ϕ⃗x(⃗a) denote the Gödel number of the formula ϕ⃗x(⃗a) that arises
from ϕ by stepwise substituting ai at the free occurrences of xi in ϕ
for i = 1, . . . , n (cf. also page 60). Then the main property of the p.r.
functions sb⃗x is expressed by
Theorem 4.6. sb⃗x( ˙ϕ,⃗a) = ˙ϕ⃗x(⃗a), for arbitrary ϕ ∈L and all ⃗a ∈Nn.
Proof. Since ϕ⃗x(⃗a) results from applying simple substitutions stepwise,
we need only show that sbx( ˙ϕ, a) = ˙ϕx(a) for all ϕ ∈L, x ∈Var, and
a ∈N. This holds, since sbx( ˙α, a) = [ ˙α]cf a
˙x
= [ ˙α]˙a
˙x = (αx(a))· = ˙αx(a) in
view of (∗) from page 232.
Example. Let α be Sx==== y. Then sbxy( ˙α, a, b) = (Sa==== Sb)· for a, b ∈N.
Further, sbxy( ˙α, a, Sa) = (Sa==== Sa)· = (Sa==== Sa)· = sbx( ˙α Sx
y , a).
This
equation will be generalized in Exercise 3c.
Exercises
1. Let a, b, a0, . . . , an (n > 0) be positive natural numbers and p a
prime. Prove (a) p ab ⇒p a ∨∨∨p b, (b) p lcm{aν| ν⩽n} ⇒p aν
for some ν ⩽n, and (c) lcm{aν|ν<n} and an are coprime provided
a0, . . . , an are pairwise coprime.
2. Provide a deﬁning Σ1-formula for the prime enumeration n 
→pn.
3. Expand the Lar-structure N by the functions ˜∧, ˜¬, ˜
→, ˜∀, and all
sb⃗x, and if necessary, further p.r. base functions to a structure N ∗.
Then the terms sb⃗x(⌜ϕ⌝, ⃗x) for ϕ ∈Lar are well deﬁned in the theory
of N ∗.5 Verify for arbitrary α, β, ϕ ∈Lar the following equations
in N ∗:
(a) sb⃗x((α˜∧β)·, ⃗x) = sb⃗x( ˙α, ⃗x)˜∧sb⃗x( ˙β, ⃗x), and analogously for ¬,
→, and ∀.
(b) sb⃗x( ˙ϕ, ⃗x) = sb⃗x ′( ˙ϕ, ⃗x ′), where ⃗x ′ covers all x ∈free ϕ such
that x ∈var ⃗x.
(c) Let y /∈bnd ϕ.
Then sb⃗x,x( ˙ϕ, ⃗x, t) = sb⃗x,y((ϕ tx )·, ⃗x, y) for
t ∈{0, y, Sy} in case x ∈free ϕ and y /∈var ⃗x; otherwise
sb⃗x,x( ˙ϕ, ⃗x, t) = sb⃗x((ϕ tx )·, ⃗x).
5 The expansion of N alleviates the later transfer of this exercise to PA. In 7.1 it will
be shown that the additional functions of N ∗are explicitly deﬁnable already in PA.

250
6 Incompleteness and Undecidability
6.5
The Theorems of Gödel, Tarski, Church
Call a theory T ⊆L arithmetizable if L is arithmetizable and a sequence
(n)n∈N of constant terms is available such that ⊢T n̸====m for n ̸= m and
cf : n 
→(n)· is p.r. These are minimal requirements that representability
of arithmetical predicates in T make sense. They are trivially satisﬁed for
T ⊇Q, but also for ZFC with respect to ω-terms (page 115). Terms and
formulas are coded within T, similarly to what is done in theories in Lar.
In particular, ⌜α⌝(= ( ˙α)) denotes the already deﬁned Gödel term of a
formula α. In order to evoke a concrete picture of the following two fairly
general lemmas, take L = Lar and T = PA as standard examples.
A sentence γ is called a ﬁxed point of α = α(x) in T if γ ≡T α(⌜γ⌝);
equivalently, ⊢T γ ↔α(⌜γ⌝). In intuitive terms, γ then says “α applies to
me.” The p.r. function sbx from 6.4 is representable in T under relatively
weak assumptions by Theorem 4.2. Hence, the lemmas below have a large
spectrum of application.
Fixed point lemma. Let T be an arithmetizable theory and suppose
that sbx is representable in T. Then for each α = α(x) ∈L there is some
γ ∈L0 such that
(1)
γ ≡T α(⌜γ⌝).
Proof. Let x1, x2, y ̸= x and sb(x1, x2, y) be a formula representing sbx
in T. Then sb(⌜ϕ⌝, n, y) ≡T y ==== ⌜ϕ(n)⌝for all ϕ = ϕ(x) and all n. With
n = ⌜ϕ⌝we then get
(2)
sb(⌜ϕ⌝, ⌜ϕ⌝, y) ≡T y ==== ⌜ϕ(⌜ϕ⌝)⌝.
Let β(x) := ∀y(sb(x, x, y) →α y
x).
Then γ := β(⌜β⌝) yields what we
require. Indeed,
γ
=
∀y(sb(⌜β⌝, ⌜β⌝, y) →α y
x)
≡T
∀y(y ==== ⌜β(⌜β⌝)⌝→α y
x)
	
(2) with ϕ := β(x)

=
∀y(y ==== ⌜γ⌝→α y
x)
	
because γ = β(⌜β⌝)

≡
α(⌜γ⌝).
A ﬁxed point can in the most interesting cases of α be constructed
fairly easily; see 7.5. The following lemma also formulates a frequently
appearing argument.

6.5 The Theorems of Gödel, Tarski, Church
251
Nonrepresentability lemma. Let T be a theory as in the ﬁxed point
lemma. Then T (more precisely ˙T) is not representable in T itself.
Proof. Let T be represented by the formula τ(x). We show that even
the weaker assumption (a): (∀α∈L0) ⊬T α ⇔⊢T ¬τ(⌜α⌝) leads to a
contradiction. Indeed, let γ be a ﬁxed point of ¬τ(x) according to (1), so
that (b): ⊢T γ ⇔⊢T ¬τ(⌜γ⌝). Choosing α = γ in (a) clearly yields with
(b) the contradiction ⊬T γ ⇔⊢T γ.
We now formulate Gödel’s ﬁrst incompleteness theorem, giving three
versions, of which the second corresponds essentially to the original. For
simplicity, let henceforth L ⊇Lar and T ⊇Q, ensuring the applicability
of the two lemmas above. However, all of the following holds for theories
T, such as ZFC, in which Q is just interpretable in the sense of 6.6.
Theorem 5.1 (the popular version). Every consistent (recursively)
axiomatizable theory T ⊇Q is incomplete.
Proof. If T is complete then it is recursive by Theorem 4.4, hence rep-
resentable in T by Theorem 4.2, which is impossible by the nonrepre-
sentability lemma.
Unlike the proofs of Theorems 5.1′ and 5.1′′, the above proof is noncon-
structive, for it does not explicitly provide a sentence α such that ⊬T α
and ⊬T ¬α.
Stronger than the consistency of T is the so-called ω-consistency of
T (⊆Lar), i.e., for all ϕ = ϕ(x) such that ⊢T ∃xϕ(x) we have ⊬T ¬ϕ(n)
for at least one n, or equivalently, if ⊢T ¬ϕ(n) for all n, then ⊬T ∃xϕ(x).
Clearly, if N ⊨T then T is surely ω-consistent, because the supposition
⊢T ∃xα and ⊢T ¬α(n) for all n implies the contradiction N ⊨∃xα, ∀x¬α.
Thus, from a semantic perspective the theories Q and PA are certainly
ω-consistent, hence also consistent.6
Theorem 5.1′ (the original version). For every ω-consistent theory
T ⊇Q axiomatized by a p.r. axiom system X, there is a Π1-sentence α
such that neither ⊢T α nor ⊢T ¬α, i.e., α is independent in T. There is
a p.r. function that assigns such an α to a formula representing X.
6 There are famous (relative) consistency proofs for PA that presuppose considerably
less than the full semantic approach; cf. e.g. [Tak].

252
6 Incompleteness and Undecidability
Proof. Let bewT be represented in T by the Σ1-formula bew(y, x), see
page 247. For bwb(x) = ∃ybew(y, x) from Corollary 4.3 we obtain (a):
⊢T ϕ ⇒⊢T bwb(⌜ϕ⌝), for all ϕ.
Let γ be a ﬁxed point of ¬ bwb(x)
according to the ﬁxed point lemma, so that (b): γ ≡T ¬ bwb(⌜γ⌝). The
assumption ⊢T γ yields ⊢T bwb(⌜γ⌝) by (a), but ⊢T ¬ bwb(⌜γ⌝) by (b),
contradicting the consistency of T. Thus, ⊬T γ. Now assume ⊢T ¬γ,
so that ⊢T bwb(⌜γ⌝) by (b); hence (c): ⊢T ∃y bew(y, ⌜γ⌝)). Obviously
⊬T γ, because T is consistent. Applying Corollary 4.3 once again, we
infer that ⊢T ¬ bew(n, ⌜γ⌝) for all n. However, this and (c) contradict the
ω-consistency of T. Consequently ⊢T ¬γ is impossible as well. Thus, γ
is independent in T. But then too is the Π1-sentence α := ¬ bwb(⌜γ⌝),
which is equivalent to γ in T. The claim of the p.r. assignment follows
evidently from the construction of γ in the proof of (1).
This theorem remains valid without restriction if the axiom system X
is just r.e. In this case X can be replaced by some recursive X′ (Exercise 1
in 6.2), so that bewT is still recursive according to Theorem 2.4.
Theorem 5.1′′ (Rosser’s strengthening of Theorem 5.1′ ).
The
assumption of ω-consistency in Theorem 5.1′ can be weakened to the con-
sistency of T.
Proof. Instead of bew(y, x) we consider the arithmetical predicate
prov(x) := ∃y[bew(y, x) ∧(∀z<y)¬ bew(z, ˜¬x)],
where bew is bewT and T is consistent. We think here of the p.r. function
˜¬ as having been eliminated in the usual way by a formula representing
it. Because of the consistency of T, prov(x) says essentially the same as
bwb(x) and has the following fundamental properties:
(a) ⊢T α ⇒⊢T prov(⌜α⌝),
(b) ⊢T ¬α ⇒⊢T ¬ prov(⌜α⌝).7
Indeed, suppose ⊢T α, so that ⊢T bew(n, ⌜α⌝) for some n (Corollary 4.3).
Since ⊬T ¬α, it follows that ⊢T ¬ bew(k, ⌜¬α⌝) for all k. Therefore, C5
in 6.3 gives ⊢T (∀z<n)¬ bew(z, ⌜¬α⌝), and so
⊢T bew(n, ⌜α⌝) ∧(∀z<n)¬ bew(z, ⌜¬α⌝),
7 In particular ⊢T ¬ prov(⌜⊥⌝). That the latter is not the case if we write bwb instead of
prov is the import of Gödel’s second incompleteness theorem, Theorem 7.3.2. Thus,
bwb and prov behave within T very diﬀerently, although bew(y, x) ≡N prov(y, x).

6.5 The Theorems of Gödel, Tarski, Church
253
whence particularization yields the claim ⊢T prov(⌜α⌝).
Proof of (b):
Suppose ⊢T ¬α, say ⊢T bew(m, ⌜¬α⌝). Then ⊢T (∀y⩽m)¬ bew(y, ⌜α⌝)
by C5, since ⊬T α. This gives bew(y, ⌜α⌝) ⊢T y > m by C6. Because of
y > m ⊢T (∃z<y) bew(z, ⌜¬α⌝) (choose m for z) we clearly obtain that
⊢T ∀y[bew(y, ⌜α⌝) →(∃z<y) bew(z, ⌜¬α⌝)] ≡¬ prov(⌜α⌝). This conﬁrms
(b). Now let (c): γ ≡T ¬ prov(⌜γ⌝) by (1). The assumption ⊢T γ yields
with (a) and (c) the contradiction ⊢T prov(⌜γ⌝), ¬ prov(⌜γ⌝), and the
assumption ⊢T ¬γ yields with (b) and (c) the same contradiction. Thus,
neither ⊢T γ nor ⊢T ¬γ.
T ⊆L0
ar is called ω-incomplete if there is some ϕ = ϕ(x) such that
⊢T ϕ(n) for all n and yet ⊬T ∀xϕ. We claim that PA is not only incomplete
but ω-incomplete. Let γ ≡PA ¬ bwbPA(⌜γ⌝) and ϕ(x) := ¬ bewPA(x, ⌜γ⌝).
By Theorem 5.1′, ⊬PA γ ≡PA ¬ bwbPA(⌜γ⌝) ≡∀xϕ, that is, ⊬PA ∀xϕ. On
the other hand, since ⊬PA γ, we know that ⊢PA ϕ(n) (= ¬ bewPA(n, ⌜γ⌝))
for all n (Corollary 4.3) which conﬁrms our claim. Note that ϕ(x) is even
a Π1-formula, which is particularly interesting.
α ∈L0 is said to be true in A if A ⊨α. In particular, α ∈L0
ar is
called true (more precisely, true in N or true in reality, as some people
like to say) if N ⊨α. If there is some τ(x) ∈L with a single free variable
such that A ⊨α ⇔A ⊨τ(⌜α⌝), for all α ∈L0, it is said that truth of
A is deﬁnable in A. Clearly, this is equivalent to the representability of
Th A in Th A. For A = N, however, such a possibility is excluded by the
nonrepresentability lemma. We therefore obtain
Theorem 5.2 (Tarski’s nondeﬁnability theorem). The notion of
truth in N is not deﬁnable in N; in other words, Th N is not arithmetical.
In this theorem lies the origin of a highly developed theory of deﬁnability
in N (see also 6.7). The theorem holds correspondingly for every domain
of objects A whose language is arithmetizable and in which the function
sbx is representable for some variable x.
We now turn to undecidability results. First of all we prove the claim
in Exercise 1 in 3.5 in a somewhat stronger framework: ‘decidable’ will
now have the precise meaning of ‘recursive’.
Lemma 5.3. Every ﬁnite extension T ′ of a decidable theory T of one and
the same (arithmetizable) language L is decidable.

254
6 Incompleteness and Undecidability
Proof. Suppose T ′ extends T by α0, . . . , αn. Put α := 
i⩽n αi, so that
T ′ = T + α. Since β ∈T ′ ⇔α →β ∈T, we obtain
n ∈˙T ′ ⇔n ∈˙L0 & ˙α ˜
→n ∈˙T.
Now, ˙T, ˙L0, and ˜
→are recursive. Hence the same applies to ˙T ′.
That T ′ belongs to the same language as T is important. A decidable
theory T axiomatized by X ⊆L0 but considered as a theory in L′ ⊃L
with the same axiom system X may well be undecidable, due to a higher
complexity of the additional tautologies of L′.
T0 ⊆L0 is called strongly undecidable if T0 is consistent and each theory
T ⊆L0 compatible with T0 (i.e., T +T0 is consistent) is undecidable. Then
each T compatible with T0 in a language L ⊇L0 is also undecidable, for
otherwise T ∩L0 would clearly be decidable. If T0 is strongly undecidable
then so is every consistent T1 ⊇T0, for if T is compatible with T1 then
it is also compatible with T0. Moreover, each subtheory of T0 in L0 is
then undecidable, or T0 is hereditarily undecidable in the terminology of
[TMR]. The weaker a strongly undecidable theory, the wider the scope
of applications. This will become plain by means of examples in the next
section. The following theorem is the main result from [TMR].
Theorem 5.4. Q is strongly undecidable.
Proof. Let T ∪Q be consistent. Assume T is decidable. Then the same
does hold for the ﬁnite extension T ′ = T + Q of T; Lemma 5.3. Thus,
by Theorem 4.2, T ′ is representable in itself, which is impossible by the
nonrepresentability lemma.
Theorem 5.5 (Church’s undecidability theorem). The set TautL of
all tautological sentences is undecidable for L ⊇Lar.
Proof. TautL is surely compatible with Q and hence is undecidable by
Theorem 5.4.
This result readily carries over to the language with a single binary
relation, as will be shown in the next section, and hence to all expansions
of this language. Indeed, it carries over to all languages with the exception
of those containing unary predicate symbols only and at most one unary
function symbol. For the tautologies of these languages there exist various
decision procedures; see [ML, vol. I].

6.5 The Theorems of Gödel, Tarski, Church
255
By Theorem 5.4, in particular Th N is undecidable; likewise is every
subtheory of Th N, for instance Peano arithmetic PA and each of its sub-
theories, as well as all consistent extensions of PA, because these are all
compatible with Q. Th N is not even axiomatizable, since an axiomatiz-
able complete theory is decidable. Further conclusions concerning unde-
cidable theories will be drawn in 6.6.
Alongside undecidability results concerning formalized theories, numer-
ous special results can also be obtained in a similar manner; for instance
negative solutions to word problems of all kinds, and halting problems
(see e.g. [Rog] or [Bar, C2]). Of these perhaps the most spectacular was
the solution to Hilbert’s tenth problem: Does an algorithm exist that for
every polynomial p(⃗x) with integer coeﬃcients decides whether the Dio-
phantine equation p(⃗x)==== 0 has a solution in Z?
The answer is no, as
Matiyasevich proved in 1970.
We brieﬂy sketch the proof.
Note ﬁrst that it suﬃces to show that
no algorithm exists for the solvability of all Diophantine equations in N.
Indeed, by a famous theorem from Lagrange, every natural number is the
sum of four squares of integers. Consequently, p(⃗x)==== 0 is solvable in N iﬀ
p(u 2
1 + v 2
1 + w 2
1 + z 2
1 , . . . , u 2
n + v 2
n + w 2
n + z 2
n)==== 0 is solvable in Z. Thus,
if we could decide the solvability of Diophantine equations in Z, then we
could solve as well the corresponding problem in N. For the latter notice
ﬁrst of all that the question of solvability of p(⃗x)==== 0 in natural numbers
is equivalent to the solvability of a Diophantine equation of Lar (i.e., an
equation s(⃗x)==== t(⃗x)), by simply bringing all terms of p(⃗x) preceded by a
minus sign “to the other side.” Thus, Hilbert’s problem is reduced to the
question of a decision procedure for the problem N ⊨∃⃗xδ(⃗x), where δ(⃗x)
runs through all Diophantine equations s(⃗x)==== t(⃗x)) in Lar.
The negative solution to the last question follows easily from the much
further-reaching Theorem 5.6, which establishes a surprising connection
between number theory and recursion theory, proved in detail for instance
in [Mat]. This theorem is a paradigm of the experience that the solution of
certain mathematical questions lead to results whose signiﬁcance extends
way beyond that of an answer to the original question.
Theorem 5.6. An arithmetical predicate P is Diophantine if and only if
P is recursively enumerable.

256
6 Incompleteness and Undecidability
To give at least an indication of the proof, let the Diophantine predicate
P ⊆Nm be deﬁned by P⃗a ⇔N ⊨∃⃗xδN (⃗x,⃗a), with the equation δ(⃗x, ⃗y),
⃗y = (y1, . . . , ym). The deﬁning formula for P is Σ1, and since δN (⃗x,⃗a)
is recursive by Theorem 4.5, P is r.e. This is the trivial direction of the
claim.
The converse—every r.e. predicate is Diophantine—is too large
in scope to be given here. Much tricky inventiveness is used in order to
show that certain arithmetical predicates and functions are Diophantine,
among them the ternary predicate ‘ab = c ’, which for a long time resisted
the proof of being Diophantine. Theorem 5.6 yields
Corollary 5.7. (a) Hilbert’s tenth problem has a negative answer.
(b) For every axiomatizable theory T ⊇Q, in particular T = PA, there is
an unsolvable Diophantine equation whose unsolvability is provable in T.
Proof. bwbQ is r.e. by 6.2. Hence, by Theorem 5.6, there is a Diophantine
equation δ(⃗x, y) such that bwbQ(n) ⇔N ⊨∃⃗x δ(⃗x, n). We claim that
even for the set {δ(⃗x, n) | n ∈N} of equations it is undecidable whether
N ⊨∃⃗x δ(⃗x, n). Otherwise, {n ∈N | N ⊨∃⃗x δ(⃗x, n)} and hence also bwbQ
would be recursive. This is a contradiction to Theorem 5.4 and proves (a).
(b): If the unsolvability of every unsolvable Diophantine equation δ(⃗x)
were provable in T, then either ⊢T ¬∃⃗xδ(⃗x) (provided δ(⃗x) is unsolvable)
or else ⊢T ∃⃗xδ(⃗x), for T is Σ1-complete. Since the theorems of T are r.e.,
one would then have a decision procedure for the solvability of Diophantine
equations, which contradicts part (a).
Theorem 5.6 can be yet further strengthened; namely, it can be proved
within PA. Thus, one obtains the following theorem, whose name stems
from Matiyasevich, Robinson, Davis, and Putnam, all of whom made
signiﬁcant contributions to the solution of Hilbert’s tenth problem. Be-
cause of its lengthy proof, we shall not use this theorem, though in fact
many things would thereby be simpliﬁed.
MRDP theorem. For every Σ1-formula α there exists an ∃-formula ϕ
in Lar such that α ≡PA ϕ. Here ϕ is without loss of generality of the form
∃⃗x s==== t with certain Lar-terms s, t.
Π1-formulas and -sentences have a corresponding simple representation.
A famous example of a Π1-sentence is Goldbach’s conjecture
(∗)
∀x(2 < x ∧2 x →(∃p, q < x)(prim p, q ∧x = p + q)).

6.5 The Theorems of Gödel, Tarski, Church
257
(each even number >2 is a sum of two primes). (∗) represents an example
of a Π1-sentence in L1
ar whose truth in N is still unknown, hence may be
independent in PA. Clearly, if (∗) is false then its negation is provable,
even in Q. But (∗) may be true and nevertheless unprovable.
Fermat’s conjecture, which has a still longer history and was ﬁnally
proved at the end of the twentieth century, is the statement
(†)
(∀x, y, z ∈N+)(∀n>2) xn + yn ̸= zn.
This is equivalent to a Π1-sentence, because (a, b) 
→ab is not only Σ1-
but even Δ0-deﬁnable in N, as was noticed in Remark 1 in 6.3. Hence,
(†) is a candidate for a sentence that may be independent in PA.
Remark. It would be interesting to discover whether the proof of Fermat’s
conjecture or a suitable modiﬁcation of this proof can be carried out in PA. A
demonstration that this is not the case would hardly be less spectacular than the
solution of the problem itself. However, it seems that the proof can be carried
out in a suitable conservative extension of PA (communicated by G. Kreisel).
Note also the following: Since PA is ω-incomplete already for Π1-formulas (see
page 253), it may even be the case that ⊢PA (∀x∀y∀z̸====0) xn + yn̸====zn for every
single n > 2, although (∗) is not provable in PA. Similarly, it may well be that
∃p, q (prim p, q ∧2n = p + q) is true for each n > 1 but (†) is still unprovable.
This would be no less sensational than a proof of Goldbach’s conjecture itself.
Exercises
1. Show that an ω-incomplete theory in Lar has a consistent but ω-
inconsistent extension.
2. Suppose T is complete; prove the equivalence of
(i) T is strongly undecidable,
(ii) T is hereditarily undecidable.
3. A consistent theory T0 ⊆L0 is called essentially undecidable if each
consistent T ⊇T0 is undecidable. Show that a ﬁnitely axiomatizable
theory T is essentially decidable iﬀT is strongly undecidable.
4. Let Δ be a ﬁnite list containing explicit deﬁnitions of new symbols
in terms of those occurring in L. Show that if T is decidable then so
is T + Δ (independent of whether all deﬁnitions in Δ are legitimate
in T; in the worst case T + Δ is inconsistent).
5. Construct a primitive recursive function f : N →N such that ran f
is not recursive (although it is surely recursively enumerable).

258
6 Incompleteness and Undecidability
6.6
Transfer by Interpretation
Interpretability is a powerful method to transfer model-theoretic and other
properties, such as undecidability, from one theory to another. Roughly
speaking, interpreting a theory T0 ⊆L0 into a theory T1 ⊆L1 means
to make the basic notions of T0 understandable in T1 via explicit deﬁ-
nitions. ‘for all x’ from T0 is replaced in T1 by ‘for all x ∈P ’, where
P is a new unary predicate symbol for the domains of T0-models, i.e.,
the T0-quantiﬁers run over the subdomains PA of the domains of the T1-
models A.
We consider the most important concepts, interpretability
from Tarski (also called relative interpretability) and interpretability from
Rabin, called model interpretability. All theories considered in this section
are supposed to be consistent.
Let P be a unary predicate symbol not occurring in T1. The formula ϕP,
the P-relativized of a formula ϕ, results from ϕ by replacing all subformulas
of the form ∀xα by ∀x(P x →α). A precise deﬁnition of ϕP runs by induc-
tion: ϕP = ϕ if ϕ is a prime formula, (¬ϕ)P = ¬ϕP, (ϕ ∧ψ)P = ϕP ∧ψP,
and (∀xϕ)P = ∀x(P x →ϕP), so that ϕP = ϕ for open ϕ. One readily con-
ﬁrms (∃xϕ)P ≡∃x(P x ∧ϕP). The right-side formula shows clearly what
relativation is intending to mean. Set XP := {αP | α ∈X} for X ⊆L0.
Example. (∀x∃y y ==== Sx)P ≡∀x(P x→∃y(P y ∧y ==== Sx)) ≡∀x(P x→P Sx).
The last equivalence results from ∃y(P y ∧y ==== Sx) ≡P Sx, cf. (12) in 2.4.
Deﬁnition. T0 ⊆L0 is called interpretable in T1 ⊆L1 (where for simplic-
ity we assume that T0 has ﬁnite signature) if there is a list Δ of explicit
deﬁnitions legitimate in T1 of the symbols of T0 not occurring in T1 and
of a new unary predicate symbol P such that T P
0 ⊆T1 +Δ, the deﬁnitorial
extension of T1 by Δ.
This deﬁnition expresses only that all notions of T0 “are understood” in
T1, and what is provable in T0 is also provable in T1. Examples will be
given later. The theory T + Δ (T ⊆L1) will henceforth be denoted by
T Δ, and its language by LΔ
1 . Interpretability generalizes the notion of a
subtheory: If T0 ⊆T1 then T0 is trivially interpretable in T1, i.e., only the
trivial relativation P x ↔x==== x belongs to Δ. In this case αP ≡α.
Let CA denote the set of the so-called closure axioms
∃x P x, P c, ∀⃗x (n
i=i P xi →P f⃗x)
(c, f ∈L0).

6.6 Transfer by Interpretation
259
These are equivalent to (∃x x==== x)P, (∃x x==== c)P, and (∀⃗x ∃y y ==== f⃗x)P, re-
spectively. Thus, CA is up to equivalence a set of the form F P for some
ﬁnite set F of L0-tautologies, so that CA ⊆T P
0 for each theory T0 ⊆L0.
The sentences of CA guarantee that for a given LΔ
0 -structure B ⊨Δ there
is a well-deﬁned L0-structure A whose domain is A = PB. The relations
and operations of A are the ones deﬁned by Δ but restricted to A. This
structure A will be denoted by BΔ. It is a substructure of the L0-reduct
of B, whose role will become clear in the next lemma.
Lemma 6.1. Let B ⊨CA. Then BΔ ⊨α ⇔B ⊨αP, for all sentences α
of the language L0.
Proof. A := BΔ is an L0-structure. Claim: (A, w) ⊨ϕ ⇔(B, w) ⊨ϕP,
for any w: Var →A. This proves the lemma, since α is a sentence. We
prove the claim by induction on ϕ ∈L0. It is clear for prime formulas
π since αP = π. The induction steps for ∧, ¬ proceed without diﬃculty,
and the one for ∀is obtained as follows:
(A, w) ⊨∀xϕ ⇔(A, wa
x) ⊨ϕ for all a ∈A
⇔(B, wa
x) ⊨ϕP for all a ∈A
(induction hypothesis)
⇔(B, wa
x) ⊨P x →ϕP, for all a ∈B
(because PB = A)
⇔(B, w) ⊨∀x(P x →ϕP) = (∀xϕ)P.
Remark 1. If T0 is axiomatized by X0 then in the deﬁnition of interpretability
it suﬃces to require just XP
0 ∪CA ⊆T Δ
1 instead of T P
0 ⊆T Δ
1 . That is, we have
only to check αP ∈T Δ
1
for the axioms α of T0, and CA ⊆T Δ
1
(cf. the example
below). This fact is highly important. It follows immediately from
(∗)
S ⊢α ⇒SP ∪CA ⊢αP
(S ∪{α} ⊆L0
0).
For proving (∗) let S ⊢α and B ⊨SP ∪CA. Then BΔ ⊨S by the lemma. Thus,
BΔ ⊨α because S ⊢α, and so B ⊨αP. Since B ⊨SP ∪CA was arbitrary, we get
SP ∪CA ⊢αP.
Theorem 6.2. Let T0 be interpretable in T1. If T0 is strongly undecidable
so is T1.
Proof. Let T ⊆L1 be compatible with T1. Then T + T1 is consistent
and so is (T + T1)Δ. Now, S := {α ∈L0
0 | αP ∈T Δ + CA} is a theory,
for SP ⊆T Δ + CA and (∗) yield S ⊢α ⇒T Δ ∪CA ⊢αP ⇒α ∈S. Let
B ⊨(T + T1)Δ ⊇T P
0 ∪CA ∪SP. Thus, BΔ ⊨T0, S by Lemma 6.1; hence
S is compatible with T0 and so undecidable. If T were decidable, then so
would be T Δ (Exercise 3 in 6.5). Hence also T Δ + CA (Lemma 5.3), and
so clearly S. This is a contradiction.

260
6 Incompleteness and Undecidability
Example. Q is interpretable in the theory Td of discretely ordered rings
R = (R, 0, +, ×, <). These have a smallest positive element e, deﬁned by
x==== e ↔0 < x ∧∀y(0 < y →x ⩽y), that need not be a unit element of R.
Ring multiplication is denoted by ×, to distinguish it from multiplication
in Q. Here are the deﬁnitions for P, S, · (0, + remain unaltered):
P x ↔x ⩾0 ∧x × e==== e × x ∧∀y∃z z × e==== y × x,
y ==== Sx ↔y ==== x+e,
z ==== x·y ↔z×e==== x×y
∨∀u(u×e̸====x×y ∧z ==== x).
With some patience, all P-relativized Q-axioms can be proved in T Δ
d , with
the list Δ of the above deﬁnitions. Thus, by Remark 1, Q is interpretable
in Td, and Td is strongly undecidable according to Theorem 6.2.
While Q is not directly interpretable in the theory TF of ﬁelds, it is in
a certain ﬁnite extension of TF , whereby TF is shown to be undecidable
(Julia Robinson). The same also holds for the theory of groups TG [TMR].
However, none of these theories is strongly undecidable.
Q and also PA are interpretable in ZFC, as is nearly every other theory.
Let P x ↔x ∈ω, and deﬁne S, +, · within ZFC such that their restrictions
to ω coincide with the usual operations. In particular, S is deﬁned by
y ==== Sx ↔y ==== x ∪{x}. This immediately yields the incompleteness and
the undecidability of ZFC, assuming of course its consistency. Q is also
interpretable in weak subtheories of ZFC, e.g., in the Tarski fragment TF,
by which we mean the theory in L∈with the following three axioms.8
Hence, like Q, the theory TF is strongly undecidable.
∃x∀y y /∈x
(∅exists),
∀x∀y(∀z(z ∈x ↔z ∈y) →x==== y)
(extensionality),
∀x∀y∃z∀u(u ∈z ↔u ∈x ∨u==== y)
(x ∪{y} exists).
In particular, the set of tautologies in a binary relation is undecidable, even
without identity in the language; for ==== can conservatively be eliminated
from T∈by means of x==== y ↔∀z(z ∈x ↔z ∈y). Q is surely interpretable
in Th N, and Th N in turn in Th Z with Z = (Z, 0, 1, +, ·). This is a
consequence of Lagrange’s theorem. Hence, Th Z is strongly undecidable,
and thus every subtheory is undecidable, e.g., the theory of commutative
rings. Th N and Th Z have the same degree of complexity, because Th Z
is (in various ways) interpretable in Th N; Exercise 3.
8 Claimed in [TMR, p. 34]. The lengthy proof is presented in [Mo, pp. 283–290].

6.6 Transfer by Interpretation
261
Remark 2. Remarkable is the mutual interpretability of PA and ZFCﬁn, the
theory of (hereditarily) ﬁnite sets. It arises from ZFC by replacing AI by the
schema Sﬁn: ϕ(∅) ∧∀xy(ϕ(x) →ϕ(x ∪{y}) →∀xϕ(x)) and AF by the schema of
foundation Sfnd : ∃xϕ →∃(ϕ ∧(∀y ∈x)¬ϕ y
x); see [De] or [Ra4]. A surprisingly
simple interpretation of ZFCﬁn in PA was given by Ackermann in [Ac]: Each
natural number represents a ﬁnite set in PA (relativation is trivial), and the
∈-relation is deﬁned by i ∈a :⇔bia = 1.9 For instance, 0 represents ∅, since
bi0 = 0 for all i. 1, 2, and 3 (more precisely, 1, 2, and 3) represent {∅}, {1},
and {0, 1} (= {∅, {∅}}), respectively. To see that 3 represents {0, 1}, notice that
b03 = b13 = 1 and bi3 = 0 for i > 1. See also [Fi] for more details.
We now describe a related notion of interpretability.
For simplicity,
we omit some details. Let K0 and K be nonempty classes of L0- and
L-structures, respectively. Further, let Δ be a list of deﬁnitions of the L0-
symbols and a predicate symbol P, and let LΔ, CA, and BΔ for B ⊨CA be
deﬁned as above. AΔ denotes the expansion of A ∈K in LΔ according
to Δ (the Δ-expansion of A). If γ ∈LΔ is a sentence, let Kγ denote the
class of all AΔ for A ∈K such that AΔ ⊨γ.
Deﬁnition. K0 (or Th K0) is called model interpretable in K (or in Th K
respectively) if for suitable Δ and a suitable sentence γ ∈LΔ,
(1) Kγ ⊨CA and BΔ ∈K0 for each B ∈Kγ,
(2) For every A ∈K0 there is some B ∈Kγ such that A ≃BΔ.
Clearly, we can construct as in 2.6 for each sentence α ∈LΔ a reduced
sentence αrd ∈L such that
(3) AΔ ⊨α ⇔A ⊨αrd, for all A ∈K.
Theorem 6.3. Let K0 be model interpretable in K. If Th K0 is unde-
cidable then so too is Th K.
Proof. Put ˆα := (γ →αP)rd = γrd →(αP)rd for α ∈L0
0. It suﬃces to
prove (∗) : K0 ⊨α ⇔K ⊨ˆα, because a decision procedure for Th K
then clearly extends to Th K0. ⇒: Let K0 ⊨α, A ∈K, AΔ ⊨γ so that
A ⊨γrd by (3), and B := AΔ ∈Kγ. By (1), BΔ ∈K0. Thus, BΔ ⊨α.
Hence B ⊨αP by Lemma 6.1, and so A ⊨(αP)rd. This conﬁrms A ⊨ˆα
for all A ∈K, in other words, K ⊨ˆα. ⇐: Assume that K0 ⊭α, say
A ⊭α. Choose some B ∈Kγ according to (2), so that BΔ ⊭α. Then
B ⊭γ →αP; hence K ⊭ˆα. This conﬁrms (∗).
9 a →bia (the ith binary digit of a; see 6.1) is a p.r. function and hence explicitly
deﬁnable in PA, as is every p.r. function according to Theorem 7.1.1.

262
6 Incompleteness and Undecidability
Example. The class K0 of all graphs (A, R) is model interpretable in
the class K of simple graphs (B, S), i.e. S is irreﬂexive and symmetric.
The ﬁgure below shows some A ∈K0 with aRa, aRb, bRa, bRc, and
on the right some B ∈K, called the encoding structure of A because it
completely describes A in order to satisfy (2). Roughly put, a set N of
new points is adjoined to A so that B = A ∪N. Since the edges in B are
undirected, we need new points for coding the edge directions of A.
A:
u
u
u
-
a
b
c


W
*

B:
TT


@
@
 DD
DD



u
s
u
s
u
s
s s s
s s
s
s
The “old” points in B, the larger dots in the ﬁgure, are the ones from
A = PB. Such a point neighbors three or two endpoints (i.e., points in
which only one S-edge ends), depending on whether the point is reﬂexive
in A or not (only a is reﬂexive). Informally, the deﬁnition for R in B
reads as follows: “xRy iﬀx, y ∈PB and either x==== y and x neighbors three
endpoints, or there exists exactly one new point z such that xSzSy, or
there are exactly two new points u, v such that xSuSvSy and uSy.” γ is
rendered informally into “∃x P x and all new points are either endpoints
or neighbor precisely two old points or one old and one new point.”
In the example, Th K0 is the logical theory of a binary relation, al-
ready established as undecidable. Accordingly the theory of all simple
graphs is undecidable. The latter can be used to show, for instance, that
the theory SL of semilattices is undecidable. By Theorem 5.4 the same
then follows for the theory SG of semigroups, for SL is a ﬁnite exten-
sion of SG. In order to show that Th K0 is model interpretable in SG,
u
u
u
u
s
s
s
@
@
@
@
L
L
L
@
@
@
@











e
e
a
b
c
d
0
it suﬃces to provide, similarly to the last ex-
ample, for a simple graph (A, S) the encoding
semilattice (B, ◦). The ﬁgure on the left shows
the ordering diagram of B for A = {a, b, c, d}
and S = {{a, b}, {a, c}}; here S is understood as
a set of edges. The old points are precisely the
maximal points of B. By construction, B has
a smallest element 0 and is of depth 3, that is, there are at most three
consecutive points in B with respect to <. This must now be expressed
by the sentence γ required in the deﬁnition of model interpretability.

6.6 Transfer by Interpretation
263
The theory of ﬁnite simple graphs with or without some additional
feature (for instance planarity) is undecidable; see e.g. [RZ]. The above
construction shows that the undecidable theory of ﬁnite simple graphs
is model interpretable in the theory of ﬁnite semilattices, which hence is
undecidable. This clearly implies the undecidability of the theory FSG
of ﬁnite semigroups. Setting an element on top of the maximal elements
in the last ﬁgure results in the order diagram of a ﬁnite lattice, so that
the theory of ﬁnite lattices turns out to be undecidable. The same holds
for the theory FPO of ﬁnite partial orders because for the description of
(A, S) only the partial order of B is relevant.
Remark 3. Somewhat more mathematics is required to prove the undecidability
of the theory FDL of all ﬁnite distributive lattices. The previous ﬁgure illustrates
that also FPO is undecidable. But FPO is model interpretable in FDL, in that
one identiﬁes the elements of g with the
∩-irreducible elements of the lattice,
A say. Here we need to know that A’s structure is completely determined by
the partial order of its irreducible elements and that this order can be given
completely arbitrarily.
Positive results are also transferable. For instance, the (logical) theory
of a unary function is interpretable in the ﬁrst-order theory of (undirected)
trees [KR], and with the latter the former is also decidable. The decidabil-
ity of the theory of a single unary function was ﬁrst proved by Ehrenfeucht
with a diﬀerent method. We mention that the theory of two or more unary
functions is undecidable. Decidability of the theory of simple trees also
follows from the decidability of the second-order monadic theory of binary
trees [Bar, C3], a very strong result with an immense scope of applica-
tions. One of these applications is a simple proof of decidability of all
modal systems considered in Chapter 7 (see e.g. [Ga]).
Exercises
1. Show that if a theory T0 is essentially undecidable and interpretable
in T1 ⊆L1 then T1 is essentially undecidable as well.
2. Show (informally) that PA is interpretable not only in ZFC but also
in ZFCﬁn. (Attention: ω is no longer a set in ZFCﬁn.)
3. Show in detail that Th (Z, 0, 1, +, ·, ⩽) is interpretable in Th N.
4. Prove that all axioms of ZFCﬁn derive from TF + Sﬁn + Sfnd. This
makes interpretability of ZFCﬁn in PA an easy task.

264
6 Incompleteness and Undecidability
6.7
The Arithmetical Hierarchy
We now add a little more on the complexity of predicates of N including
subsets of N. The set of the Gödel numbers of all sentences valid in N
is an example of a rather simply deﬁned nonarithmetical subset of N; by
Theorem 5.2 it has no deﬁnition in Lar.10
However, relatively simply
deﬁned arithmetical sets and predicates may be recursion-theoretically
highly complicated. It is useful to classify these according to the com-
plexity of the deﬁning formulas. The result is the arithmetical hierarchy,
also called the ﬁrst-order Kleene–Mostowski hierarchy. The following def-
inition builds upon the one in 6.3 of the Σ1- and Π1-formulas and the
Σ1-, Π1-, and Δ1-predicates deﬁned by these.
Deﬁnition. A Σn+1-formula is a formula of the form ∃⃗xα(⃗x, ⃗y), where α
is a Πn-formula from Lar; analogously, we call ∀⃗xβ(⃗x, ⃗y) a Πn+1-formula
if β is a Σn-formula. Here ⃗x, ⃗y are arbitrary tuples of variables. A Σn-
predicate (resp. Πn-predicate) is an arithmetical predicate P deﬁned in
N by a Σn-formula (resp. Πn-formula). If P is both Σn and Πn (i.e., a
Σn- and Πn-predicate) then we say that P is a Δn-predicate, or P is Δn
for short. We denote by Σn, Πn, and Δn the sets of the Σn-, Πn- and
Δn-predicates, respectively. In addition, Σ0 := Π0 := Δ0.
According to this deﬁnition, a Σn-formula is a prenex formula ϕ with
n alternating blocks of quantiﬁers, the ﬁrst of which is an ∃-block, which
may also be empty. ϕ’s kernel is Δ0. Clearly, each ϕ ∈Lar is equivalent
to a Σn- or Πn-formula for a suitable n, for ϕ can be brought into prenex
normal form and the quantiﬁers can be grouped into blocks of the same
quantiﬁers. Obviously, Δn ⊆Σn, Πn. When considering the hierarchy it
is convenient to have Σn- and Πn-formulas closed under equivalence in N.
Hence, we say that α is Σn or Πn to indicate that α is equivalent to an
original Σn- or Πn-formula, respectively. Note that since ∃⃗xϕ ≡∀⃗xϕ ≡ϕ
in case var ⃗x ∩var ϕ = ∅, every Σn- or Πn-formula is also both Σn+1
and Πn+1. Therefore Σn, Πn ⊆Δn+1. This yields the following inclusion
diagram, where all the inclusions, indicated by lines, are proper:
10 Th N is deﬁnable only in second-order arithmetic, which along with variables for
numbers has variables for sets of natural numbers. However, the set of sentences α
from Th N with bounded quantiﬁer rank, i.e. qr α ⩽n, is deﬁnable for each n. In
this sense, Th N has an “approximate” elementary deﬁnition.

6.7 The Arithmetical Hierarchy
265
Σ1
Σ2
Σ3


@
@


@
@


Δ0
Δ1
Δ2
Δ3
· · ·
@
@


@
@


@
@
Π1
Π2
Π3
We have already come across Σ1-, Π1-, and Δ1-predicates; for instance,
the solvability claims of Diophantine equations are Σ1, and the unsolv-
ability claims are Π1. Below we provide an example of a Π2-predicate.
It is also convenient to say that Σn- and Πn-sentences deﬁne 0-ary Σn-
and Πn-predicates, respectively. In this sense the consistency of PA (in
arithmetical terms ¬ bwb(⌜∅̸====∅⌝)) is Π1, the incompleteness of PA is Σ2,
and the ω-consistency is Π3 (Exercise 3). The hierarchy serves various
purposes. More recent investigations have considered also Δ0- or Σn- or
Πn-induction. Here the schema IS is restricted to the corresponding class
of formulas. An example is IΔ0 mentioned on page 239.
As already shown in 6.4, the Σ1-predicates are the recursively enumer-
able ones, the Π1-predicates their complements, and the Δ1-predicates are
exactly the recursive predicates, which are the ones whose complements
are r.e. as well. Thus, we are provided with a purely recursion-theoretic
way of regarding Σ1, Π1, and Δ1. This underscores the importance of
the arithmetical hierarchy, which is fairly stable with respect to minor
changes in the deﬁnition of Δ0.
In view of Theorem 5.6 one could begin, for instance, with a Δ0 consist-
ing of all polynomially (or equivalently, quantiﬁer-free) deﬁnable relations.
In some presentations, a system of formulas is eﬀectively enumerated (and
denoted by Δ0) that deﬁne exactly the p.r. predicates in N. Section 7.1
will indicate how such a system can be deﬁned. Between these and the
Δ0-formulas (which themselves may still be classiﬁed) lie many r.e. sets of
formulas that deﬁne computable functions signiﬁcant in both the theory
and practice of computability, e.g., the elementary functions mentioned
in the introduction to this chapter.
However, by Remark 2 in 6.4 we know that there exists no eﬀectively
enumerable system of formulas in Lar through which all recursive, or equi-
valently all Δ1-predicates, are deﬁned, so that the deﬁnition of the arith-
metical hierarchy cannot start in a feasible manner with a representative
“set of Δ1-formulas.”

266
6 Incompleteness and Undecidability
Remark. We mention that the ﬁrst-order arithmetical hierarchy considered so
far extends in a natural way to the second-order arithmetic. Also this extended
hierarchy is closely related to recursion theory (see e.g. [Shoe]). A treatment lies
outside the scope of this book.
Similarly to the case n = 1, one readily shows that a conjunction or dis-
junction of Σn-formulas is equivalent to some other Σn-formula; likewise
for Πn-formulas. The negation of a Σn-formula is equivalent to a Πn-
formula, and vice versa; this is certainly correct for n = 1, which initiates
an easy induction on n. The complement of a Σn-predicate is therefore a
Πn-predicate, and vice versa. From this it easily follows that Δn is closed
under all the mentioned operations, including complementation.
By “compression of quantiﬁers,” the idea of which was illustrated in
Exercise 1 in 6.3, one obtains a somewhat simpler presentation of the
quantiﬁer blocks. The ∃- and ∀-blocks can each be collapsed into one
quantiﬁer. This procedure is fairly easy, provided we are dealing with
equivalence in N as is the case here, and not in a possibly too weakly
axiomatized theory over N (in fact, PA would suﬃce for the proof):
Theorem 7.1. A (proper) Σn-predicate is deﬁnable by a prenex formula
∃x1∀x2 · · · Qnxnα with a Δ0-formula α, where Qn is either the ∀- or ∃-
quantiﬁer, depending on whether n is even or odd.
Similarly, a Πn-
predicate is deﬁnable by a formula ∀x1∃x2 · · · Qnxnα.
Proof by (simultaneous) induction on n. Exercise 1 in 6.3 formulates the
case for Σ1- and for Π1-predicates. Assume that this is the case for n and
let ∃⃗xα be the deﬁning formula of a Σn+1-predicate, where α deﬁnes a
Πn-predicate and ∃⃗x is a block of length m ⩾1. By using the (deﬁning
Δ0-formula of the) pairing function, ∃⃗x can be compressed stepwise to
a single ∃-quantiﬁer ∃x. The arising bounded quantiﬁers commute with
the following ∀-block (Exercise 1). The case m = 0 can also be included
in the argument, using a “vacuous quantiﬁer” ∃x (i.e., x /∈var α). The
Πn+1-formulas are treated completely analogously.
It is quite often a nontrivial task to determine a well-deﬁned predi-
cate’s exact position in the arithmetical hierarchy, or better, like every
fastidious game, it requires suﬃcient training. In the example below, we
consider a set that is neither recursive nor r.e. For the sake of simplicity,
we apply Church’s thesis in one place, although it can be eliminated using

6.7 The Arithmetical Hierarchy
267
a little recursion theory, as was demonstrated previously in the proof of
Theorem 4.4. The example is also a good preparation for 7.6.
Example. Let Lr denote the set of the α ∈L1
ar that represent in Q
recursive subsets of N. Thus, the α ∈Lr have at most one free variable,
namely the ﬁrst one. For instance, all Δ0-formulas in L1
ar belong to this
Lr. Since N and ∅are recursive and L0
ar ⊆L1
ar, all members of the set
Q∗:= Q ∪{α | ¬α ∈Q} also belong to Lr, because each α ∈Q trivially
represents N, and each α with ¬α ∈Q represents ∅. Conversely, each
closed formula of Lr belongs to Q∗. Obviously then, Q∗= Lr ∩L0
ar.
We now show that Lr is arithmetical; more precisely, it is Π2, and indeed
properly Π2, that is, neither Σ1 nor Π1. By deﬁnition,
α ∈Lr ⇔α ∈L1
ar & ∀n∃Φ[Φ is a proof for α(n) or for ¬α(n)].
This equivalence readily yields a deﬁnition of Lr (more exactly, of ˙Lr)
by a Π2-formula ϕ(x) (that is, a ∀-formula ∀xα such that α is Σ1). Let
the p.r. predicate ‘a ∈L1
ar’ be Σ1-deﬁned by the formula λ1(x). With
sb = sbv0, we then set
ϕ(x) := λ1(x) ∧∀y∃u[bewQ(u, sb(x, y)) ∨bewQ(u, ˜¬ sb(u, y))].
More precisely, ϕ should be the reduced in Lar after eliminating the oc-
curring p.r. function terms using more ∃-quantiﬁers inside the brackets.
Thus, ϕ describes a Π2-formula, that is, Lr is Π2. It is not Σ1, because
Lr is not r.e. by Remark 2 in 6.4, nor is it Π1. Indeed, assume this were
the case; then Q∗= Lr ∩L0
ar would also be Π1, for L0
ar is Δ1. Now Q∗is
certainly r.e. and thus Σ1, and so by Theorem 4.5, Q∗would be recursive.
But then we obtain a decision procedure for Q (hence a contradiction) as
follows: Let α ∈L0
ar be given. If α /∈Q∗then also α /∈Q; if α ∈Q∗,
we turn on the enumeration machine for Q and wait until either α or ¬α
appears. This obviously is a decision procedure for Q.
Special Σ1-formulas. We end this chapter with a result useful for prov-
ing the Σ1-completeness of PA inside PA in 7.2, the so-called provable
Σ1-completeness. It will be shown that the Σ1-predicates are deﬁnable
without reference to Δ0, using special Σ1-formulas. To this end some-
what stronger axioms are considered than those of Q, namely the axioms
of the theory N presented in 6.3. All axioms of N are derivable in PA, as
was pointed out already on page 235.

268
6 Incompleteness and Undecidability
Deﬁnition. Special Σ1-formulas are deﬁned as follows:
(a) Sx==== y, x+y ==== z, and x·y ==== z are special Σ1-formulas, where x, y, z
denote distinct variables (the special prime formula condition);
(b) if α, β are special Σ1-formulas then so too are α ∧β, α ∨β, α 0x, and
α y
x, where x, y are distinct and not in bnd α (prime-term substitu-
tion), as well as ∃xα and (∀x<y)α for y /∈var α.
Theorem 7.2. Every original Σ1-formula is equivalent to a special Σ1-
formula in the theory N, thus in PA and a fortiori in N.
Proof. It suﬃces to verify the claim for all Δ0-formulas, since the set of
special Σ1-formulas is closed under ∃-quantiﬁcation. Since
s==== t ≡∃x(x==== s ∧x==== t) with x /∈var s, t,
it is enough to consider prime formulas of the form x==== t. For prime terms
t this clearly follows from x==== 0 ≡(x==== y) 0y and x==== y ≡N (x + z ==== y) 0z.
The induction steps on the operations S, + are obtained as follows:
x==== St ≡∃y(x==== Sy ∧y ==== t), x==== s + t ≡∃y∃z(x==== y + z ∧y ==== s ∧z ==== t),
and similarly for ·. The claim holds for all literals because
s̸====t ≡∃y∃z(x̸====y ∧x==== s ∧y ==== t),
x̸====y ≡N ∃u∃z(Su==== z ∧(x + z ==== y ∨y + z ==== x)).
By Exercise 4 in 6.3 we need only carry out induction on ∧, ∨, (∀x⩽t)
and (∃x⩽t). For ∧, ∨this is clear. For the remainder note that (∀x⩽t)α
and (∃x⩽t)α are N-equivalent respectively to ∃y(y ==== t ∧(∀x<y)α ∧α y
x)
and ∃x∃y∃z(x + y ==== z ∧z ==== t ∧α).
Exercises
1. Show that Σn and Πn and hence Δn are closed under bounded
quantiﬁcation (bounded quantiﬁers “commute” with the next ∃- or
∀-block, Exercise 2 in 6.3).
2. Conﬁrm that Δ0 ⊂Δ1 ⊂Σ1, Π1, which therefore shows that these
four classes of arithmetical predicates are distinct.
3. Prove that ω-inconsistency is (at most) Σ3. Theorem 7.6.2 will show
that ω-inconsistency is properly Σ3. Hence, ω-consistency is Π3.

Chapter 7
On the Theory of Self-Reference
By self-reference we basically mean the possibility of talking inside a
theory T about T itself or related theories.
Here we can give merely
a glimpse into this recently much advanced area of research; see e.g. [Bu].
We will prove Gödel’s second incompleteness theorem, Löb’s theorem, and
many other results related to self-reference, while further results are dis-
cussed only brieﬂy and elucidated by means of applications. All this is of
great interest both for epistemology and the foundations of mathematics.
The mountain we ﬁrst have to climb is the proof of the derivability condi-
tions for PA and related theories in 7.1, and the derivable Σ1-completeness
in 7.2. But anyone contented with leaﬁng through these sections can be-
gin straight away in 7.3; from then on we will just be reaping the fruits of
our labor. However, one would forgo a real adventure in doing so, namely
the fusion of logic and number theory in the analysis of PA. For a com-
prehensive understanding of self-reference, the material of 7.1 and 7.2
(partly prepared in Chapter 6) should be studied anyway.
Gödel himself tried to interpret the notion “provable” using a modal
operator in the framework of the modal system S4. This attempt reﬂects
some of his own results, though not adequately. Only after 1970, when
modal logic was suﬃciently advanced, could such a program be success-
fully carried out. A suitable instrument turned out to be the modal logic
denoted by G (or GL).
The Kripke semantics for G introduced in 7.4
is an excellent tool for conﬁrming or refuting self-referential statements.
Solovay’s completeness theorem and the completeness theorem of Kripke
semantics for G in 7.5 are fortunately of the kind that allows application
without knowing the completeness proof itself, which in both cases are
not quite easy and use several technical tricks.
W. Rautenberg, A Concise Introduction to Mathematical Logic,
269
Universitext, DOI 10.1007/978-1-4419-1221-3_7,
c⃝Springer Science+Business Media, LLC 2010

270
7 On the Theory of Self-Reference
There are several extensions of G, for example, the bimodal logic GD
in 7.6. This logic is related to Hilbert’s famous ω-rule. A weakening of it
can expressed by the modal operator □
1 of GD. A comprehensive survey
can be found in [Bu, Chapter VII]; see also [Vi2]. In 7.7 we discuss some
questions regarding self-reference in axiomatic set theory.
7.1
The Derivability Conditions
Put somewhat simply, Gödel’s second incompleteness theorem states that
⊢T ConT cannot hold for a suﬃciently strong and consistent axiomatizable
theory T. Here ConT is a sentence reﬂecting the metatheoretic statement
of consistency of T inside T, more precisely, inside the (ﬁrst-order) lan-
guage L of T.
In a popular formulation: If T is consistent, then this
consistency is unprovable in T. As was outlined by Gödel and will be
veriﬁed in this chapter, the italicized sentence is not only true but also
formalizable in L and even provable in the framework of T.
The easiest way to obtain Gödel’s theorem is ﬁrst to prove the deriv-
ability conditions stated below. Their formulation supposes the arithme-
tizability of T, which includes the distinguishing of a sequence 0, 1, . . . of
ground terms; see page 250. Let bewT (y, x) be a formula that represents
the recursive predicate bewT in T as in 6.4. For bwbT (x) = ∃y bewT (y, x)
we write □(x), and □α is to mean bwbT ⌜α⌝
x . We may read □α as “box α”
or more suggestively “α is provable in T,” because □α reﬂects the metathe-
oretic property ⊢T α in T. If □refers to some theory T ′ ̸= T then □has
to be indexed correspondingly. For instance, □ZFCα for α ∈L∈can eas-
ily expressed also in Lar. Note that □α is always a sentence, even if α
contains free variables.
Further, set 3α := ¬□¬α for α ∈L. If α is a sentence, 3α may be
read as α is compatible with T, because it formalizes ‘⊬T ¬α’, which is,
as we know, equivalent to the consistency of T + α. First of all, we deﬁne
ConT in a natural way by
ConT := ¬□⊥
	
= ¬ bwbT (⌜⊥⌝)

,
where ⊥is a contradiction, 0̸====0, for instance. We shall see in a moment
that ConT is independent modulo T of the choice of ⊥. The mentioned
derivability conditions then read as follows:

7.1 The Derivability Conditions
271
D1: ⊢T α ⇒⊢T □α,
D2: □α ∧□(α →β) ⊢T □β,
D3: ⊢T □α →□□α.
Here α, β run through all sentences of L. These conditions are due to Löb,
but they were considered in a slightly diﬀerent setting already in [HB].
Sometimes D2 is written in the equivalent form □(α →β) ⊢T □α →□β,
and D3 as □α ⊢T □□α.
A consequence of D1 and D2 is D0: α ⊢T β
⇒
□α ⊢T □β. This
results from the following chain of implications:
α ⊢T β ⇒⊢T α →β ⇒⊢T □(α →β) ⇒⊢T □α →□β ⇒□α ⊢T □β.
From D0 it clearly follows that α ≡T β ⇒□α ≡T □β. In particular,
the choice of ⊥in ConT is arbitrary as long as ⊥≡T 0̸====0.
Remark 1. Any operator ∂: L →L satisfying the conditions d1: ⊢T α ⇒⊢T ∂α
and d2: ∂(α →β) ⊢T ∂α →∂β thus satisﬁes also d0: α ⊢T β ⇒∂α ⊢T ∂β,
and hence d00: α ≡T β ⇒∂α ≡T ∂β, for all α, β ∈L. It likewise satisﬁes
d∧: ∂(α ∧β) ≡T ∂α ∧∂β, for α ∧β ⊢T α, β, hence ∂(α ∧β) ⊢T ∂α, ∂β ⊢T ∂α ∧∂β
in view of d0. The converse direction ∂α ∧∂β ⊢T ∂(α ∧β) readily follows from
α ⊢T β →α ∧β by ﬁrst applying d0 and then d2.
Whereas D2 and D3 represent sentence schemata in T, condition D1
is of metatheoretic nature and follows obviously from the representability
of bewT in T. Thus, D1 holds even for weak theories such as T = Q. On
the other hand, the converse of D1,
D1∗:
⊢T □α ⇒⊢T α, for all α ∈L0,
may fail. Fortunately, it holds for all ω-consistent axiomatic extensions
T ⊇Q such as T = PA. Indeed, ⊬T α implies ⊢T ¬ bewT (n, ⌜α⌝) for all n
(Corollary 6.4.3). Hence, ⊬T ∃y bewT (y, ⌜α⌝) in view of the ω-consistency
of T, that is, ⊬T □α.
Unlike D1, the properties D2 and D3 are not so easily obtained. The
theory T must be able not only to speak about provability in T (perhaps
via arithmetization), but also to prove basic properties about provability.
D3 is nothing else than condition D1 formalized within T, while D2 for-
malizes (7) from page 230, the closure under MP in arithmetical terms.
Let us ﬁrst realize that D2 holds, provided it has been shown that
D2∗:
bewT (u, x) ∧bewT (v, x ˜
→y) ⊢T bewT (u ∗v ∗⟨y⟩, y),

272
7 On the Theory of Self-Reference
where the p.r. functions ˜
→, ∗, and y 
→⟨y⟩appearing in D2∗must either
be present or deﬁnable in T. Generally speaking, f ∈Fn is called deﬁnable
in an arithmetizable theory T ⊆L (with respect to the sequence of terms
(n)n∈N in T) if there is a formula δ(⃗x, y) ∈L such that
(1)
(a) ⊢T δ(⃗a, f⃗a) for all ⃗a,
(b) ⊢T ∀⃗x ∃!yδ(⃗x, y).
Clearly, f is then also represented by δ(⃗x, y). For T = PA and related
theories, (1) means that f is explicitly deﬁnable in T in the sense of 2.6
and may be introduced in T (using a corresponding symbol). From now
on we will no longer distinguish between T and its deﬁnitorial extensions
and apply ⊢T y ==== f⃗x ↔δ(⃗x, y) without comment. This and (1) easily
imply ⊢T f⃗a==== f⃗a, e.g. ⊢T a ˜
→b==== a ˜
→b. With ⌜α⌝, ⌜β⌝for x, y, we thus
obtain from D2∗in view of ⌜α →β⌝= ˙α ˜
→˙β = ˙α ˜
→˙β = ⌜α⌝˜
→⌜β⌝,
bewT (u, ⌜α⌝) ∧bewT (v, ⌜α →β⌝) ⊢T bewT (u ∗v ∗⟨⌜β⌝⟩, ⌜β⌝).
Particularization yields D2.
But the real work, the deﬁnability of the
functions appearing in D2∗in theories like T = PA, still lies ahead.
In order to better keep track of things, we restrict our considerations
to the theories ZFC and PA, which are of central interest in nearly all
foundational questions. ZFC is only brieﬂy discussed. Here the proofs of
D2 and D3 (with □= □ZFC) are much easier than in PA and need only a
few lines as follows: D2∗and hence D2 are clear, because the naive proof
of D2∗above with bewT = bewZFC can easily be formalized inside ZFC.
This includes the deﬁnability of all functions occurring in D2∗, for we did
deﬁne them; for instance, the operation ∗on page 224 may be deﬁned
by setting a ∗b = ∅if a /∈ω or b /∈ω. We arithmetize L∈according
to the pattern in 6.2, encoding formulas with Gödel numbers,1 so that
L∈-formulas are encoded within ZFC by certain ω-terms, deﬁned in 3.4.
Formulas from Lar are identiﬁed with their ω-relativized in L∈, called the
arithmetical formulas of L∈. Moreover, the arithmetical predicate bewZFC
is certainly representable in ZFC by Theorem 6.4.2, since this theorem can
be viewed, just like every theorem in this book, as a theorem within ZFC.
Thus, the naive proof of D1 based on this theorem (up to Corollary 6.4.3)
can as a whole be carried out in ZFC, and so D3 is proved.
1 This is not actually necessary, since in ZFC one can talk directly about ﬁnite sequences
and hence about L∈-formulas (Remark 2 in 6.6), but we do so in order to maintain
coherence with the exposition in 6.2.

7.1 The Derivability Conditions
273
Roughly speaking, D2 and D3 hold for ZFC because ordinary mathe-
matics, in particular the material in Chapter 6, is formalizable in ZFC. In
all of the above, no special set-theoretic constructions such as transﬁnite
recursion are needed. Only relatively simple combinatorial facts are re-
quired. Hence there is some hope that the proofs of D2 and D3 can also
be carried out in suﬃciently strong arithmetical theories like PA. This
is indeed so. The proof of D3 for PA will need the most eﬀort and will
be completed only in 7.2. Our ﬁrst goal will be to show that the p.r.
functions occurring in D2∗, and in fact all p.r. functions, are explicitly
deﬁnable in PA.2 They turn out to be deﬁnable even in a sense stronger
than required by (1) from the previous page.
Deﬁnition. An n-ary recursive function f is called provably recursive or
Σ1-deﬁnable in PA if there is a Σ1-formula δf(⃗x, y) in Lar such that
(2)
(a) ⊢PA δf(⃗a, f⃗a) for all ⃗a ∈Nn;
(b) ⊢PA ∀⃗x ∃!yδf(⃗x, y).
Since PA is Σ1-complete, 2(a) is equivalent to N ⊨δf(⃗a, f⃗a) for all ⃗a,
which is often more easily veriﬁed than 2(a) and could replace 2(a). We
will show that all p.r. functions are Σ1-deﬁnable in PA, which strengthens
their explicit deﬁnability in PA. Thereafter we may treat all occurring p.r.
functions in PA as if they had been available in the language right from the
outset. Essentially this fundamental fact allows a treatment of elementary
number theory and combinatorics within the boundaries of PA and hence
is particularly interesting for a critical foundation of mathematics.
If δf(⃗x, y) in (2) is Δ0 then f is called Δ0-deﬁnable. An example is
the β-function (Exercise 1), which from now on may be supposed to be
present in PA. Basic for the Σ1-deﬁnability of all p.r. functions is β’s main
property, Lemma 6.4.1, of which we need, of course, some provable version
in PA.
Since Euclid’s lemma and the Chinese remainder theorem are
involved here, these should be derived ﬁrst. Clearly, the basic arithmetical
laws applied in their proofs in 6.3 should be at our disposal, including
those on the order relation and on a −b for a ⩾b, all provable in N.
The proof of Euclid’s lemma is straightforward, Exercise 2.
As for
the Chinese remainder theorem, we avoid the quantiﬁcation over ﬁnite
2 In [Gö2], Gödel presented a list of 45 deﬁnable p.r. functions; the last was χbew.
Following [WR], Gödel considered a higher-order arithmetical theory. That Gödel’s
theorems also hold in ﬁrst-order arithmetic was probably ﬁrst noticed in [HB].

274
7 On the Theory of Self-Reference
sequences for the time being, by stating the theorem as a scheme. Let c, d
denote unary provably recursive functions, which may depend on further
parameters. Each such c determines for given n the sequence c0, . . . , cn,
with cν = c(ν) for ν ⩽n. For suggestive reasons from now on also letters
such as n, ν, . . . may denote variables in Lar. With the Δ0-deﬁnable re-
lation ⊥of coprimeness, the Chinese remainder theorem can provisionally
be stated as follows: for arbitrary c, d as arranged above, we get
(3) ⊢PA ∀n[(∀i, j⩽n)(ci<di ∧(i̸====j →di⊥dj))
→∃a(∀ν⩽n) rem(a, dν)==== cν].
To convert the original proof of the remainder theorem to one for (3) we
require, for given provably recursive d, the term lcm{dν| ν⩽n}, the least
common multiple of d0, . . . , dn. Claim: f : n 
→lcm{dν|ν⩽n} is deﬁned
in PA by the Σ1-formula
δf(x, y) := (∀ν⩽x)dν y ∧(∀z<y)(∃ν⩽x) dν̸
z.
More precisely, δf(x, y) describes a Σ1-formula in Lar that is even Δ0,
provided d is Δ0-deﬁnable.
Clearly N ⊨δ(n, lcm{dν|ν⩽n}) for all n.
Thus, 2(a) holds. With the minimum schema (Exercise 4 in 3.3) applied
to β(x, y) := (∀ν⩽x)dν y, we obtain ⊢PA ∃!yδf(x, y), provided it has been
shown that ⊢PA ∃yβ(x, y) (‘c0, . . . , cx have a common multiple’), which is
easily derived by induction on x; see Example 1 in 2.5. This proves the
claim. After having derived Euclid’s lemma in PA (Exercise 2) we conﬁrm
(3) by following the proof of the remainder theorem in 6.2, and, writing
βst for β(s, t), a suitable version of Lemma 6.4.1 as follows:
(4)
⊢PA ∀n∃u(∀ν⩽n) cν ==== βuν, for any given provably recursive c.
Theorem 1.1. Each p.r. function f is provably recursive. Moreover, the
recursion equations for f are provable in PA whenever f = Op(g, h).
Proof. For the initial functions and +, · the formulas v0 ==== 0, v1 ==== Sv0,
vn ==== vν along with v2 ==== v0 + v1 and v2 ==== v0 · v1 are obviously deﬁning
Σ1-formulas. For the composition f = h[g1, . . . , gm], let δf(⃗x, y) be the
formula y ==== h(g1⃗x, . . . , gm⃗x). In this case (2) is clear, because we might
think of h, g1, . . . , gm as being already introduced in PA, so that δf(⃗x, y)
belongs to the expanded language. Only the construction of δf for the
case f = Op(g, h) requires some skill. We may assume that besides β also
g, h have already been introduced in the language. Consider

7.1 The Derivability Conditions
275
(5) δf(⃗x, y, z) := ∃u[ βu0==== g⃗x ∧(∀v<y)βuSv ==== h(⃗x, v, βuv) ∧βuy ==== z



γ(u,⃗x,y,z)
].
δf is similar to δexp from Remark 1 in 6.4. It is Σ1, because β, g, h are
Σ1-deﬁnable. Lemma 6.4.1 applied with ci = f(⃗a, i) for i ⩽b shows that
N ⊨δf(⃗a, b, f⃗a), equivalently 2(a). Uniqueness in 2(b), that is,
δf(⃗x, y, z) ∧δf(⃗x, y, z′) ⊢PA z ==== z′,
derives easily from γ(u, ⃗x, y, z) ∧γ(u′, ⃗x, y, z′) ⊢PA z ==== z′, which clearly
follows from γ(u, ⃗x, y, z) ∧γ(u′, ⃗x, y, z′) ⊢PA (∀v⩽y)βuv ==== βu′v. This is
easily shown by induction on y. Also, ⊢PA ∃zδf(⃗x, y, z) will be shown
inductively on y. We get ⊢PA ∃uβu0==== g⃗x (hence ⊢PA ∃zδf(⃗x, 0, z)) from
(4), choosing c therein such that c0 = g⃗x and cν = 0 for ν ̸= 0. c is
provably recursive, for the term g⃗x is Σ1-deﬁnable. The inductive step
will be veriﬁed informally, that is, we shall prove
(∗)
∃zδf(⃗x, y, z) ⊢PA ∃z′δf(⃗x, Sy, z′).
Suppose γ(u, ⃗x, y, z). Consider the provably recursive c: ν 
→cν deﬁned by
cν = βuν for ν ⩽Sy and cSy = h(⃗x, y, βuy). Here u, ⃗x, y are parameters in
the deﬁning Σ1-formula for c. So by (4) (taking Sy for n) there is some u′
with βu′ν = cν = βuν for all ν ⩽y and βu′Sy = cSy = h(⃗x, y, βuy). With
this u′ and z′ = βu′Sy we obtain γ(u′, ⃗x, Sy, z′), and so ∃z′δf(⃗x, Sy, z′).
This conﬁrms (∗) and hence 2(b).
Thus, f is provably recursive and
may now be introduced in PA. We ﬁnally sketch a proof of the recursion
equations for f in PA, which also in PA may be written as usual, i.e.,
(A) ⊢PA f(⃗x, 0)==== g⃗x,
(B) ⊢PA f(⃗x, Sy)==== h(⃗x, y, f(⃗x, y)).
(A) holds because ⊢PA δf(⃗x, 0, f(⃗x, 0)) ≡PA ∃u(βu0==== g⃗x ∧βu0==== f(⃗x, 0))
and clearly ∃u(βu0==== g⃗x ∧βu0==== f(⃗x, 0)) ⊢f(⃗x, 0)==== g⃗x. (B) follows by
<-induction on y applied to α = α(⃗x, y) := f(⃗x, Sy)==== h(⃗x, y, f(⃗x, y)).
Assume that (∀v<y)α vy. Choosing u in (5) such that γ(u, ⃗x, Sy, f(⃗x,Sy)),
we readily obtain (∀v⩽y)f(⃗x, v)==== βuv, so that
f(⃗x, Sy)==== βuSy ==== h(⃗x, y, βuy)==== h(⃗x, y, f(⃗x, y)).
This conﬁrms ∀y((∀v<y)α vy →α), hence ⊢PA ∀yα by <-induction.
We thus have achieved our ﬁrst goal. Next observe that the properties
of ∗, ℓ, . . . from the remark on page 230 along with the basic property (5)
stated there are also readily proved within PA. This is a little extra pro-
gram that includes the proof of unique prime factorization, see Exercise 4.

276
7 On the Theory of Self-Reference
Thus, D2∗and hence D2 are indeed provable for T = PA. In particular,
the property (6) from page 230 carries over to PA, so that
(6)
□(x ˜
→y) ⊢PA □(x) →□(y).
We mention that □in (3) may even denote the formula bwbT for any
axiomatizable (and arithmetizable) theory T. D3 will be proved in the
next section in a somewhat broader context.
Remark 2. The formalized equations of Exercise 3 in 6.4 are now also provable
in PA. For instance, item (b) reads ⊢PA sb⃗x(⌜ϕ⌝, ⃗x)==== sb⃗x ′(⌜ϕ⌝, ⃗x ′) for ϕ = ϕ(⃗x),
where ⃗x ′(⊆⃗x) enumerates the free variables of ϕ. As regards (c), consider ﬁrst a
special case. Let ϕ be Sx==== y. Then sbxy( ˙ϕ, x, Sx) = sbx((ϕ Sx
y )·, x), formalized
sbxy(⌜ϕ⌝, x, y) Sx
y ==== sbx(⌜ϕ Sx
y ⌝, x). For the proof of this equation in PA, just
⊢PA cf Sx==== ˜S cf x is required, which holds by Theorem 1.1. Whoever wants to
write down a detailed proof should follow the example on page 249.
Exercises
1. Prove in PA the Δ0-deﬁnability of the remainder function rem, the
pairing function, and the β-function; see 6.4. In particular, rem is
deﬁned by δrem(a, b, r) := (∃q⩽a)(a==== b · q + r ∧r < b) ∨b==== r ==== 0.
The laws of arithmetic as given by N (page 235) may be used.
2. Prove in PA (a) (∀a, b>0)∃x∃y(a⊥b →ax+1==== by), that is, Euclid’s
lemma. (b) (∀a>1)∃p(prim p ∧p a) (‘each number ⩾2 has a prime
divisor’), (c) ⊢PA (∀a, b>0)∀p(prim p ∧p ab →p a ∨p b).
3. Show that ⊢PA prim p ∧p lcm{dν| ν⩽n} →(∃i⩽n)p di, required for
carrying out the proof of the Chinese remainder theorem in PA.
4. One of several possibilities of formalizing the prime factorization in
PA is (∀n⩾2)(∃m⩾2)n==== 
i⩽ℓm p(((m)))i
i
, where m serves as a variable
for the sequence of prime exponents.3
Prove this in PA, as well as
its uniqueness, which is essentially based on Exercise 2.
5. Let T ′ = T + α and T satisfy D1–D3. Show that
(a) ⊢T □T ′ϕ ↔□T(α →ϕ) (the formalized deduction theorem),
(b) D1–D3 hold also for T ′.
3 An equivalent formalization of the prime factorization in PA using the β-function is
(∀k⩾2)∃u∃n(k ==== 
i⩽n pβui
i
∧βun̸====0).

7.2 The Provable Σ1-Completeness
277
7.2
The Provable Σ1-Completeness
D3 is a special case of the provable Σ1-completeness. This is essentially
the statement ⊢PA α →□α for Σ1-sentences α. The proof demands still
additional preparation, and even good textbooks do not carry out all
proof steps. All steps described in this section and not handled in detail
can easily be completed in full by the suﬃciently assiduous reader. Life
could be made easier through the mutual interpretability of PA and ZFCﬁn
mentioned in 6.6. Let □= □(x) denote the formula bwbPA(x) till the end
of this section. We ﬁrst introduce an additional notation. Let ϕ = ϕ(⃗x).
Deﬁnition. □[ϕ] := □(sb⃗x(⌜ϕ⌝, ⃗x)) (= bwbPA
sb⃗x(⌜ϕ⌝,⃗x)
x
).
By Remark 2 in 7.1, ⊢PA sb⃗x(⌜ϕ⌝, ⃗x)==== sb⃗x ′(⌜ϕ⌝, ⃗x ′), where ⃗x ′ enu-
merates free ϕ. Hence, we may assume w.l.o.g. that free □[ϕ] = free ϕ.
Moreover, for α ∈L0
ar we have ⊢PA sb⃗x(⌜α⌝, ⃗x)==== sb∅(⌜α⌝)==== ⌜α⌝, hence
□[α] and □α may be identiﬁed. ‘⊢PA ϕ(⃗a) for all ⃗a ∈Nn’ is reﬂected
in PA by ‘⊢PA ∀⃗x □[ϕ]’. The latter thus reﬂects in PA the existence of a
collection of proofs which, due to the ω-incompleteness of PA, may be less
than ⊢PA □∀⃗xϕ, or what amounts to the same, ⊢PA □ϕ.
Example. Let ϕ = ϕ(x, y) be Sx==== y. We prove ϕ ⊢PA □[ϕ], or equiva-
lently, ⊢PA □[ϕ] Sx
y , where w.l.o.g. x, y do not occur bound in □(x). In
order to prove ⊢PA □[ϕ] Sx
y observe that in view of Remark 2 in 7.1,
□[ϕ] Sx
y = □(sbxy(⌜ϕ⌝, x, Sy)) ≡PA □(sbx(⌜ϕ Sx
y ⌝, x)) = □[α(x)]
with α(x) := Sx==== Sx. Thus, it suﬃces to verify ⊢PA □[α(x)] (equivalently,
⊢PA ∀x□[α(x)]). This reﬂects in PA ‘for arbitrary n, ⊢PA Sn==== Sn ’. We
verify ⊢PA □[α(x)] in detail. Consider the p.r. function ˜α: n 
→sbx( ˙α, n)
(the Gödel number of α(n)). By axiom Λ9, ⟨˜α(n)⟩is for each n a trivial
arithmetized proof of length 1. Stated within PA, ⊢PA bewPA(⟨˜α(x)⟩, ˜α(x)).
This clearly yields ⊢PA ∃y bewPA(y, ˜α(x)) = □(˜α(x)) = □[α].
Next we prove some modiﬁcations D1, D2 for α = α(⃗x) and β = β(⃗x):
(1)
(a) ⊢PA α ⇒⊢PA □[α];
(b) □[α →β] ⊢PA □[α] →□[β].
To see (a) let ⊢PA α, hence also ⊢PA ∀⃗xα and so ⊢PA □∀⃗xα. Just as in
the above example, a proof for ∀⃗xα provides one for α⃗x(⃗a) in a p.r. way,
or stated within PA: □∀⃗x ⊢PA □(sb⃗x(⌜α⌝, ⃗x)) (= □[α]; thus, ⊢PA □[α]).

278
7 On the Theory of Self-Reference
(b) follows from (6) in 7.1 with sb⃗x(⌜α⌝, ⃗x), sb⃗x(⌜β⌝, ⃗x) for x, y, observ-
ing that ⊢PA sb⃗x(⌜α →β⌝, ⃗x)==== sb⃗x(⌜α⌝, ⃗x) ˜
→sb⃗x(⌜β⌝, ⃗x), see Exercise 3
in 6.4. (c) of this exercise yields for all not necessarily distinct x, y
(2)
□[α] tx ≡PA □[α tx ]
(t ∈{0, y, Sy} and y /∈bnd α).
Now, D3 is only a special case of the provable Σ1-completeness of PA,
stated not only for sentences, but for arbitrary formulas as follows:
(3)
ϕ ⊢PA □[ϕ] (equivalently, ⊢PA ϕ →□[ϕ]), for all Σ1-formulas ϕ.
Indeed, choose in (3) for ϕ the Σ1-sentence □α for any α ∈L0
ar. Then
□α ⊢PA □[□α] ≡□□α, and D3 is proved. We obtain (3) from Theo-
rem 2.1 below, since by (1), (2), and since w.l.o.g. free α = free □[α], the
operator ∂: α 
→□[α] satisﬁes the conditions of the theorem.
Theorem 2.1. Let ∂: Lar →Lar be any operator with free ∂α ⊆free α
satisfying
d1:
⊢PA α ⇒⊢PA ∂α,
d2:
∂(α →β) ⊢PA ∂α →∂β,
ds:
∂α tx ≡PA ∂(α tx )
(t ∈{0, y, Sy}, y /∈bnd α).
Then ⊢PA ϕ →∂ϕ holds for all Σ1-formulas ϕ ∈Lar.
Proof. ∂satisﬁes also d0, d00, and d ∧(see Remark 1 in 7.1). Hence,
by Theorem 6.7.2 and d00 we need to carry out the proof only for special
Σ1-formulas. First let ϕ be Sx==== y. Clearly, ⊢PA ϕ →∂ϕ is equivalent
to ⊢PA ∂ϕ Sx
y , and this to ⊢PA ∂Sx==== Sx by ds, which is obvious from
d1. Now let ϕ be x + y ==== z. We shall prove ⊢PA ∀yz(ϕ →∂ϕ) by induc-
tion on x. Observing that y ==== z ⊢PA ∂y ==== z (equivalently ⊢PA ∂z ==== z),
we obtain ϕ 0x ⊢PA y ==== z ⊢PA ∂y ==== z ≡PA ∂(ϕ 0x) ≡PA ∂ϕ 0x.
Thus,
⊢PA ∀yz(ϕ →∂ϕ) 0x. Now ϕ Sy
y ≡PA ϕSx
x ; hence ∂ϕ Sy
y ≡PA ∂ϕ Sx
x , by d00,
ds. The induction step ∀yz(ϕ→∂ϕ) ⊢PA ∀yz(ϕ→∂ϕ)Sx
x follows then from
∀yz(ϕ →∂ϕ) ⊢ϕ Sy
y
→∂ϕ Sy
y ⊢PA ϕ Sx
x
→∂ϕ Sx
x = (ϕ →∂ϕ) Sx
x .
The formula x·y ==== z is left to the reader, who should observe d ∧, d2, the
induction steps for ∧and ∃, and Sx·y ==== z ≡PA ∃u(x·y ==== u ∧u + y ==== z).
We now treat the logical connectives. The induction steps for ∧, ∨, ∃
are simple. Indeed, from d ∧we obtain
α ∧β ⊢α, β ⊢PA ∂α ∧∂β ⊢PA ∂(α ∧β).
For ∨note that α ⊢PA ∂α ⊢PA ∂(α∨β), and similarly for β. Further, since
ϕ ⊢∃xϕ we get ϕ ⊢PA ∂ϕ ⊢PA ∂∃xϕ by d0, and from x /∈free ∂∃xϕ

7.3 The Theorems of Gödel and Löb
279
follows ∃xϕ ⊢PA ∂∃xϕ. The prime-term substitution step (t is prime in
tx ) also runs smoothly: ϕ ⊢PA ∂ϕ yields ϕ tx ⊢PA ∂ϕ tx ⊢PA ∂(ϕ tx ) by ds.
It remains to verify the step for bounded quantiﬁcation. Suppose that
α ⊢PA ∂α and y /∈var α. We prove ϕ := (∀x<y) α ⊢PA ∂ϕ by induction
on y. The initial step is obvious: ⊢PA ϕ 0y, and therefore
⊢PA ∂(ϕ 0y) ⊢PA ∂ϕ 0y ⊢PA ϕ 0y →∂ϕ 0y .
Clearly, ϕ Sy
y ≡PA ϕ ∧α y
x. Hence α y
x ⊢PA ∂α y
x ⊢PA ∂(α y
x) because of
α ⊢PA ∂α. That leads to
ϕ Sy
y
∧(ϕ →∂ϕ) ⊢PA ϕ ∧α y
x ∧(ϕ →∂ϕ) ⊢PA ∂ϕ ∧∂(α y
x)
⊢PA ∂(ϕ ∧α y
x) ⊢PA ∂(ϕ Sy
y ).
Thus, ϕ →∂ϕ ⊢PA ϕSy
y
→∂(ϕSy
y ), which is obviously equivalent to the
inductive step.
Remark 3. D1–D3 are also provable for much weaker theories than PA, e.g.,
for the so-called elementary arithmetic EA = IΔ0 +∀xy∃zδexp(x, y, z). Here IΔ0
is deﬁned in Remark 1 in 6.3 and δexp is a deﬁning Δ0-formula for exp, see also
[FS]. Also Theorem 1.1 can essentially be strengthened and has many variants.
For instance, the provably recursive functions of IΣ1 (like PA but IS restricted
to Σ1-formulas) are precisely the p.r. ones, [Tak]. The same provably recursive
functions has EA augmented by the Π2-induction schema without parameters,
[Be4]. It is noteworthy that the provable recursive functions of EA itself are
precisely the elementary ones, [Si]. For more material on the metatheory of PA
and related theories see [Bar, Part D], and in particular [HP].
7.3
The Theorems of Gödel and Löb
We are now in a position to harvest the yields of our eﬀorts. As long as
not stated otherwise, let T denote any arithmetizable axiomatic theory
in L, that satisﬁes the derivability conditions D1–D3 of 7.1 along with
the ﬁxed point lemma of 6.5. We direct attention straight away to the
uniqueness statement of Lemma 3.1(b) below. According to this claim,
up to equivalence in T at most □α →α can be the ﬁxed point of the
formula □(x) →α. The proof of Theorem 3.2 will show that ¬□(x) too
has only one ﬁxed point modulo T. Beneath all this lies, as we shall see
from Corollary 5.6, a completely general result.

280
7 On the Theory of Self-Reference
Lemma 3.1. Let T be as arranged above, and let α, γ ∈L0 be such that
γ ≡T □γ →α. Then (a) □γ ≡T □α and (b) γ ≡T □α →α.
Proof. The supposition yields □γ ⊢T □(□γ →α) ⊢T □□γ →□α, by D0
and D2. Now by D3, we clearly obtain □γ ⊢T □□γ, hence □γ ⊢T □α.
Since α ⊢T □γ →α ≡T γ and so α ⊢T γ, it follows that □α ⊢T □γ by
D0. Together with the already veriﬁed □γ ⊢T □α we get (a). Using (a)
we may replace □γ with □α in γ ≡T □γ →α, which results in (b).
Theorem 3.2 (Second incompleteness theorem). PA satisﬁes along-
side the ﬁxed point lemma also D1–D3. Every theory T with these prop-
erties satisﬁes the conditions
(1) ⊬T ConT provided T is consistent,
(2) ⊢T ConT
→¬□ConT .
Proof. D1–D3 were proved for PA in 7.1. (1) follows from (2). Assume
⊢T ConT . Then ⊢T □ConT by D1, as well as ⊢T ¬□ConT by (2). Thus,
T is inconsistent. To verify (2), let γ be a ﬁxed point of ¬□(x), i.e.,
(∗)
γ ≡T ¬□γ (≡□γ →⊥).
By Lemma 3.1(b) with α = ⊥, we obtain γ ≡T □⊥→⊥≡¬□⊥= ConT .
Replacing γ in (∗) with ConT gives ConT ≡T ¬□ConT . Half of this is the
claim (2).
Thus, by (1), no suﬃciently strong consistent theory can prove its own
consistency. In particular, ⊬PA ConPA as long as PA is consistent which
is assumed throughout this book and is a minimal assumption for a far-
reaching metamathematics. The above proof shows that ConT is the only
ﬁxed point of ¬ bwbT modulo T. Actually, it shows a bit more, namely
(3)
ConT ≡T ¬□ConT .
This strengthens (2), but only by a little: ¬□ConT ⊢T ConT is just a
special case of
(4)
¬□α ⊢T ConT (equivalently, ¬ ConT ⊢T □α), for every α ∈L.
This follows from ⊥⊢T α, since ¬ ConT ≡□⊥⊢T □α by D0. (4) reﬂects
in T ‘If T is inconsistent then every formula is provable’. From (1) and
(3) we get in particular ⊬PA ¬□PA ConPA, although ‘ConPA is unprovable in
PA’ is true according to (1) (again we tacitly use the consistence of PA).
¬□PA ConPA reﬂects ‘ConPA is unprovable in PA’; hence ⊬PA ¬□PA ConPA
is just another formulation of the second incompleteness theorem.

7.3 The Theorems of Gödel and Löb
281
The above claims hold independently of the “truth content” of the sen-
tences provable in T. Namely, a consequence of the second incompleteness
theorem is the existence of consistent theories T ⊇PA in which along
with claims true in N also false ones are provable, i.e., in which truth and
untruth live in peaceful coexistence with each other. Such “dream theo-
ries” are highly rich in content, for all of them include ordinary number
theory.
An example is PA⊥:= PA + ¬ ConPA.
This theory is consis-
tent because the consistency of PA⊥is equivalent to the unprovability of
ConPA in PA. The italicized sentence is even provable in PA, as (5) be-
low will show. By the formalized deduction theorem (Exercise 5 in 7.1),
□T+α⊥≡T □(α →⊥) ≡□¬α; hence ¬□T+α⊥≡T ¬□¬α (≡3α), and
consequently,
(5)
ConT+α ≡T ¬□¬α
(in particular, ConPA⊥≡PA ¬□PA ConPA).
The special cases under (5) and (3) for T = PA now clearly yield
(6)
ConPA ≡PA ConPA⊥
(hence also ConPA ≡PA⊥ConPA⊥).
Put together, PA⊥contains ordinary number theory as known to us, but
also proves the indubitably false sentence bwbPA(⌜0 ̸==== 0⌝).
Moreover,
because of ⊢PA⊥¬ ConPA and hence ⊢PA⊥¬ ConPA⊥by (6), PA⊥proves
(the reﬂection of) its own inconsistency, although along with PA also PA⊥
is consistent. It claims to have a mysterious proof of ⊥. Thus, consistency
of T can have a diﬀerent meaning within T and seen from outside, just as
the meanings of countable diverge, depending on whether one is situated
in ZFC or is looking at it from outside. One may even say that PA⊥is
lying to us with the claim ¬ ConPA⊥.
We learn from the preceding that the extension T +ConT of a consistent
theory T need not be consistent. T = PA⊥is a concrete example, and in
fact only one of arbitrarily many others. More on the meaning of ¬ ConT
will be said in Theorem 3.4.
We now discuss what is, along with (3), the most famous example of a
self-referential sentence. Clearly, a ﬁxed point α of □(x) claims just its
own provability, that is, α ≡T □α. A trivial example is α = ⊤, because
⊢T □⊤→⊤, and since ⊢T
⊤, clearly ⊢T □⊤, so that ⊤≡T □⊤. What
is surprising here is that ⊤turns out to be the only ﬁxed point of □(x)
modulo T. By D4◦below, ⊢T □α →α implies ⊢T α and so α ≡T ⊤(which
conﬁrms the uniqueness), although one might perhaps expect ⊢T □α →α
for all α ∈L0 because □α →α is intuitively true.

282
7 On the Theory of Self-Reference
Theorem 3.3 (Löb’s theorem). Take T to satisfy D1–D3 and the ﬁxed
point lemma. Then T has the properties
D4: ⊢T □(□α →α) →□α,
D4◦: ⊢T □α →α ⇒⊢T α
(α ∈L0).
Proof. Let γ be a ﬁxed point of □(x) →α, i.e., γ ≡T □γ →α. Then
γ ≡T □α →α by Lemma 3.1(b). This and D0 imply □γ ≡T □(□α →α).
Lemma 3.1(a) states □γ ≡T □α, hence □α ≡T □(□α →α). Half of this
is D4. Now suppose ⊢T □α →α. Then by D1, ⊢T □(□α →α). Using D4
results in ⊢T □α, and ⊢T □α →α yields ⊢T α, thus proving D4◦.
D4 reﬂects just D4◦in T.
One application of Löb’s theorem is an
extremely easy proof of ⊬PA ConPA. Indeed, ⊢PA ConPA (≡□⊥→⊥) im-
plies ⊢PA ⊥by D4◦.
That’s all.
Similarly, D4 implies (2) for α = ⊥
by contraposition. Thus, Löb’s theorem is stronger than Gödel’s second
incompleteness theorem, which is not obvious at ﬁrst glance.
Unlike PA⊥, PA + ConPA conforms to truth (in N). Unfortunately it
is not quite clear what ConPA means in number-theoretic terms.
This
is clear, however, for an arithmetical statement discovered by Paris and
Harrington (see [Bar]) that implies ConPA; this statement is provable in
ZFC but not in PA. Since then, many such sentences have been found,
mostly of a combinatorial nature. A popular example is
Goodstein’s theorem. Every Goodstein sequence ends in 0.
A Goodstein sequence is a number sequence (an)n∈N, with arbitrary a0
given in advance, such that an+1 is obtained from an as follows: Let
bn = n + 2, so that b0 = 2, b1 = 3, etc. Expand an in b-adic base for
b := bn, so that for suitable k,
(∗)
an = 
i⩽k bk−ici, with 0 ⩽ci < b.
Also the powers k −i are represented in b-adic form, so too the powers
of powers, and so on. Now replace b everywhere with b + 1 (= bn+1) and
subtract 1 from the output. The result is an+1. The table below gives an
example beginning with a0 = 11; already a6 has the value 134 217 727.
a0 = 11 = 22+1 + 2 + 1
2 ⇝3
33+1 + 3 + 1 = 85
a1 = 84 = 33+1 + 3
3 ⇝4
44+1 + 4 = 1028
a2 = 1027 = 44+1 + 3
4 ⇝5
55+1 + 3 = 15 628
a3 = 15 627 = 55+1 + 2
5 ⇝6
66+1 + 2 = 279 938
a4 = 279 937 = 66+1 + 1
6 ⇝7
77+1 + 1 = 5 764 802

7.3 The Theorems of Gödel and Löb
283
As one sees from this example, an initially increases enormously, and it
is hardly believable that the sequence ever starts to decrease and ends in
0. But the proof of the theorem is not particularly diﬃcult; one estimates
an from above by the ordinal number λn, which, crudely put, results from
an on replacing the basis b in (∗) by ω. With some ordinal arithmetic
it can readily be shown that λn+1 < λn as long as λn ̸= 0. Since there
is no properly decreasing inﬁnite sequence of ordinal numbers (these are
well-ordered), the sequence (an)n∈N must eventually end in 0. For more
detailed information see for instance [HP].
Many metatheoretic properties can be expressed using the provability
operator □in T, often using sentence schemata. The following ones turn
out to be equivalent and facilitate a better understanding of the meaning
of ¬ ConT within T. None of these properties hold for a consistent T from
the outside (Theorem 6.5.1′), but all of them are provable in T = PA⊥.
(i)
¬ ConT :
□⊥
(provable inconsistency),
(ii)
SyComp :
□α ∨□¬α
(syntactic completeness),
(iii)
SeComp :
α →□α
(semantic completeness),
(iv)
ω-Comp :
∀x□[ϕ(x)] →□∀xϕ(x)
(ω-completeness).
Theorem 3.4. The properties (i)–(iv) are all equivalent in a theory T
satisfying the properties named at the beginning of this section.
Proof. By (4) (i)⇒(ii),(iii),(iv) are clear. (ii)⇒(i): By Rosser’s theorem
formulated in T (see 7.5), ConT ⊢T ¬□α ∧¬□¬α for some α.
Thus,
□α ∨□¬α ⊢T ¬ ConT .
(iii)⇒(i): For α := ConT , SeComp and (2)
yield α ⊢T □α, ¬□α and so ⊢T ¬α. (iv)⇒(i): By (3) in 7.2, we obtain
¬ bewT (x, ⌜⊥⌝) ⊢T □[¬ bewT (x, ⌜⊥⌝)], for ¬ bewT (x, ⌜⊥⌝) is Σ1. Hence,
ConT = ∀x¬ bewT (x, ⌜⊥⌝) ⊢T ∀x□[¬ bewT (x, ⌜⊥⌝)].
ω-Comp and (2) yield ConT ⊢T □∀x¬ bew(x, ⌜⊥⌝) = □ConT ⊢T ¬ ConT .
Therefore, ⊢T ¬ ConT .
Remark. ConT is also equivalent in T to other properties, for example to the
schema □α →α for Π1-formulas α (the local Π1-reﬂection principle) as well
as the uniform Π1-reﬂection principle ∀x□[α(x)] →∀xα(x) for Π1-formulas α.
Both the theorems of Paris–Harrington and of Goodstein are equivalent in PA
to the uniform Σ1-reﬂection, or equivalently, to the consistency of PA plus all
true Π1-sentences; see e.g. [Bar, D8].

284
7 On the Theory of Self-Reference
Deﬁne inductively T 0 = T and T n+1 = T n + ConT n. This n-times-
iterated consistency extension T n can be written as T n = T + ¬□n⊥
with □= bwbT , □0α = α and □n+1α = □□nα (Exercise 3). Thus, the
consistency of T n can be expressed by an iterated consistency statement
on T. Let T ω := 
n∈ω T n. Since T n ⊆T n+1 and T n = T + ¬□n⊥(hence
T ω = T ∪{¬□n⊥| n ∈ω}), the following three items are equivalent:
(i) T ω is consistent, (ii) T n is consistent for all n, (iii) ⊬T □n⊥for all n.
Like PA1 = PA + ConPA, also PAω conforms to truth looking at PA
from outside. When considered more closely, this means only that PAω is
relatively consistent with respect to ZFC. In other terms, ⊢ZFC ConPAω.
The argument (to be formalized in ZFC) runs as follows: ⊢PAω ⊥implies
⊢PAn ⊥for some n, as was noticed above, hence ⊢PA □n⊥. But this is
impossible, as is seen by a repeated application of D1∗(p. 271) on PA.
Exercises
1. Prove D4◦for T by applying Theorem 3.2 to T ′ = T + ¬α.
2. Show by means of Löb’s theorem that ConPA →¬□¬ ConPA is un-
provable in PA, although this formula is true if seen from outside.
3. Let T n recursively be deﬁned as in the text above.
Prove that
T n = T + ¬□n⊥and ConT n ≡T ¬□n+1⊥, where □is bwbT .
4. Show that ⊢ZFC □PAα →α for all arithmetical sentences α from L∈
(the L∈-sentences relativized to ω).
7.4
The Provability Logic G
In 7.3 ﬁrst-order logic was hardly required. It comes then as no surprise
that many of the results there can be obtained propositionally, more pre-
cisely, in a certain modal propositional calculus. This calculus contains
alongside ∧, ¬ the falsum symbol ⊥, and a further unary connective □to
be interpreted as the proof operator in Lar, denoted by □as well. First
we deﬁne a propositional language F□, whose formulas are denoted by
H, G, F: (a) the variables p1, p2, . . . from PV (page 4) and ⊥belong to F□;
(b) if H, G belong to F□then so too (H ∧G), ¬H, and □H.

7.4 The Provability Logic G
285
No other strings belong to F□in this context. H ∨G, H →G, and
H ↔G are deﬁned as in 1.4, ⊤:= ¬⊥. Further, set 3H := ¬□¬H and
deﬁne recursively □0H = H, □n+1H = □□nH. Let G be the set of those
formulas in F□derivable using substitution in F□, modus ponens MP,
and the rule MN: H/□H from the tautologies of two-valued propositional
logic, augmented by the axioms (called also the G-axioms)
□(p →q) →□p →□q, □p →□□p,4 □(□p →p) →□p.
For H ∈G we mostly write ⊢G H (read “H is derivable in G”). Rule MN
corresponds to D1. The ﬁrst G-axiom reﬂects D2, the middle D3, and
the last (called Löb’s formula) D4, hence the name provability logic. The
connection between G and PA is described in 7.5. Here we are concerned
with the modal logic G and its Kripke semantics.
For simplicity, we
restrict ourselves to ﬁnite Kripke frames, which are just ﬁnite directed
graphs. We can do so, since all modal logics considered here have the
ﬁnite model property. We begin without further ado with the following
Deﬁnition. A G-frame or Kripke frame for G is a ﬁnite poset (g, <). A
valuation is a mapping w that assigns to every variable p a subset wp of g.
The relation P ⊩H, dependent on w, between points P ∈g and formulas
H ∈F□(read “P accepts H”) is deﬁned inductively by
P ⊩p iﬀP ∈wp,
P ⊮⊥,
P ⊩H ∧G iﬀP ⊩H & P ⊩G,
P ⊩¬H iﬀP ⊮H,
P ⊩□H iﬀP ′ ⊩H for all P ′ > P.
These conditions easily imply P ⊩3H iﬀP ′ ⊩H for some P ′ > P,
and P ⊩H →G iﬀP ⊩H ⇒P ⊩G. If P ⊩H for all w and all P ∈g,
we write g ⊨H and say H holds in g. If g ⊨H for all G-frames g, we write
s
s
-
P
P ′
⊨G H and say H is G-valid. The G-frame on the right, consist-
ing of two points P, P ′ with P < P ′, shows that ⊭G p →□p.
Indeed, let wp = {P}. Then P ⊩p, but P ⊮□p because P ′ ⊮p. Note
also ⊭G □p →p, for P ′ ⊮p but P ′ ⊩□p because there is no P ′′ > P ′.
We may tacitly assume that G-frames are initial (have a smallest point),
for g ⊨H is veriﬁed pointwise. We write H ≡G H′ for ⊨G H ↔H′. It is
readily seen that ≡G is a congruence in F□that extends the usual logical
equivalence conservatively. For instance, ¬□H ≡G ¬□¬¬H ≡G 3¬H.
Many more equivalences are presented in the following examples. These
will later be translated into statements about self-reference.
4 This axiom is dispensable; it is provable from the remaining, see e.g. [Boo] or [Ra1].

286
7 On the Theory of Self-Reference
Examples. (a) Let g be an arbitrary G-frame. Although always P ⊮⊥,
we have P ⊩□⊥, provided P is maximal in g, that is, no Q > P exists.
Likewise, □¬□⊥is accepted precisely at the maximal points of g. Thus,
□⊥≡G □¬□⊥, or equivalently, ¬□⊥≡G 3□⊥(= ¬□¬□⊥). This reﬂects
in G the second incompleteness theorem, as will be seen in 7.5.
(b) Let {P0, . . . , Pn} be the ordered G-frame with Pn < · · · < P0. Clearly,
P0 ⊩□m⊥for each m > 0. Induction on n shows that Pn ⊩□m⊥for
all m > n, but Pn ⊮□n⊥, and therefore Pn ⊮□n+1⊥→□n⊥. Hence,
⊭G □n+1⊥→□n⊥, and a fortiori ⊭G □n⊥and ⊭G ¬□n+1⊥, for all n.
(c) ⊨G □(□p →p) →□p. For take an arbitrary g and P ∈g. If P ⊮□p
then there is, since g is ﬁnite, some Q > P with Q ⊩¬p and Q′ ⊩p for
all Q′ > Q. Thus Q ⊩□p; hence Q ⊮□p →p and so P ⊮□(□p →p).
Consequently, P ⊩□(□p →p) →□p, which proves our claim. Note also
that ⊨G □p →□□p. Only the transitivity of < is relevant for the proof.
(d) ⊨G ¬□n+1⊥→3Rn, where Rn := n
i=1(□pi →pi). For let P ∈g,
P ⊩¬□n+1⊥. Then there must be a chain P = P0 < P1 < · · · < Pn+1
in g. Now, it is a nice separate exercise to verify that each conjunct of
Rn fails to be accepted by at most one of the n + 1 points P1, . . . , Pn+1.
Thus, at least one of these accepts all conjuncts. In other words, Pi ⊩Rn
for some i > 0; hence P ⊩3Rn. This nontrivial example will essentially
be employed in the proof of Theorem 7.1.
By induction on ⊢G H one easily proves ⊢G H ⇒⊨G H (soundness of
Kripke semantics for ⊢G). Example (c) is a part of the initial step. The
induction steps over the rules are easy. For instance, g ⊨H clearly implies
g ⊨□H. The converse, ⊨G H ⇒⊢G H, holds as well. Thus, ⊢G H can be
conﬁrmed by proving ⊨G H, and vice versa. This is the content of
Theorem 4.1 (Completeness of Kripke semantics for G). For each
formula H from F□it holds that ⊢G H ⇔⊨G H.
The nontrivial direction ⇐follows directly from the ﬁnite model property
of G, i.e., each H /∈G is falsiﬁed or refuted by some ﬁnite G-frame, proved,
for example, in [Boo], [Ra1], and [CZ]. For the relatively simple formulas
considered here, ⊨G H is in general more easily checked than ⊢G H.
Both the formulas provable in G and those refutable are clearly recur-
sively enumerable, thanks to the ﬁnite model property of G. Thus, in
analogy to Exercise 2 in 3.6, we obtain

7.5 The Modal Treatment of Self-Reference
287
Theorem 4.2. G is decidable.
Remark. The ﬁnite model property, decidability, and some other properties
such as interpolation can all be proved in one move, see e.g. [Ra2]. An important
fragment of G is G0 := G∩F0
□, where F0
□denotes the set of variable-free formulas
of F□. The formulas ¬□n⊥(≡G 3n⊤) form a Boolean base in G0. One proves this
most easily by showing that G0 is complete with respect to all (totally) ordered
G-frames, including the inﬁnite ones, and applying Theorem 5.2.3 accordingly.
Exercises
1. Let g be any ﬁnite Kripke frame (a graph) that satisﬁes the axioms
of G. Show that g is necessarily a poset. Only this fact justiﬁes the
identiﬁcation of G-frames with posets.
2. Prove ⊢G □p →□(□p →p), the inverse of Löb’s formula. (Only the
ﬁrst of the three G-axioms is needed in the proof.)
7.5
The Modal Treatment of Self-Reference
Let T be a theory as in 7.3. A mapping ı from PV to L0 with p ı
i = αi
is called an insertion.
ı can be extended to the whole of F□by the
clauses ⊥ı = ⊥, (¬H)ı = ¬Hı, (H ∧G)ı = Hı ∧Gı, and (□H)ı = □Hı
(= bwbT (⌜Hı⌝)). Brieﬂy speaking, Hı results from H(p1, . . . , pn) by re-
placing the pν by the sentences αν from L. For instance, if pı = α then
(□p ∧¬□⊥)ı = □α ∧¬□⊥, and (¬□⊥)ı = ¬□⊥= ConT . The following
lemma shows that ⊢G is “sound” for ⊢T . Already this simple fact consid-
erably simpliﬁes proofs about self-referential statements.
Lemma 5.1. For each H with ⊢G H and each insertion ı, ⊢T Hı.
Proof by induction on ⊢G H. If H is a propositional tautology then
Hı ∈TautL ⊆T. If H is one of the modal axioms of G, then ⊢T Hı by D2,
D3, or D4. If ⊢G H and σ: F□→F□is a substitution, then ⊢T Hσı, since
Hσı = Hı′ with ı′ : p 
→pσı, and ⊢T Hı′ holds by the induction hypothesis.
As regards the induction step over MP, consider (F →G)ı = F ı →Gı.
Finally, if MN is applied, and ⊢T Hı by the induction hypothesis, then
⊢T □Hı = (□H)ı, due to D1.
Example 1. We prove (3) of Theorem 3.2 with the calculus ⊢G. By
Lemma 5.1 and Theorem 4.1 it suﬃces to show that ⊨G ¬□⊥↔¬□¬□⊥.

288
7 On the Theory of Self-Reference
This holds by Example (a) in 7.4. Next example: ⊨G □(p ↔3p) →¬3p
is easily conﬁrmed. Thus, ⊢T □(α ↔3α) →¬3α. This tells us (if every-
thing is related to T = PA) that a sentence claiming its own consistency
with PA is incompatible with PA, which hardly seems plausible. Even the
converse is provable in PA since ⊨G ¬3p →□(p ↔3p).
We now explain certain facts that expand upon the reasoning of above.
For PA and related theories, the converse of Lemma 5.1 holds as well.
That is to say, the derivability conditions and Löb’s theorem already con-
tain everything worth knowing about self-referential formulas or schemes.
This is essentially the content of Theorem 5.2. For the subtle proofs of
Theorems 5.2, 5.4, and 5.5, the reader is referred to [Boo].
Theorem 5.2 (Solovay’s completeness theorem). For all H ∈F□:
⊢G H (equivalently ⊨G H) if and only if ⊢PA Hı for all insertions ı.
Example 2 (applications). (a) ⊬PA □n+1⊥→□n⊥because by Exam-
ple (b) in 7.4, ⊭G □n+1⊥→□n⊥. In particular, ⊬PA ConPA (≡□⊥→⊥).
(b) ⊬PA ¬□n+1⊥, since ⊭G ¬□n+1⊥. (c) It is easily veriﬁed with the 2-point
frame on page 285 that ⊭G ¬□p →□¬□p, in particular ⊭G ¬□⊥→□¬□⊥.
Therefore, ⊬PA ConPA →□ConPA.
(d) PAn := PA + □n⊥is consistent
for n > 0 by (b), but is ω-inconsistent. Otherwise, by D1∗(page 271),
⊢PAn □n⊥⇒⊢PAn □n−1⊥⇒· · · ⇒⊢PAn ⊥, contradicting ⊬PAn ⊥. Since
⊢PA □n⊥→□n+1⊥by D3, we get PAn ⊇PAn+1, and since PAn ̸= PAn+1
by (a), we have PA0 ⊃PA1 ⊃· · · ⊃PA. Observe that PA1 is just PA⊥.
Note also the following: Since ⊭G □p →p, there must be some α ∈L0
ar
such that ⊬PA □α →α. Indeed, choose α = ⊥. The above examples point
out that Theorem 5.2 and the decidability of G are very eﬃcient tools in
deciding the provability of self-referential statements.
Many other theories have the same provability logic as PA, where in
general a modal propositional logic H is the provability logic for T when the
analogue of Theorem 5.2 holds with respect to T and H. For some theories,
the provability logic may be a proper extension of G. For example, the
ω-inconsistent theory PAn from Example 2(d) has the provability logic
Gn := G + □n⊥, the smallest extension of G closed under all rules of G
with the additional axiom □n⊥(Exercise 1; note that G0 is inconsistent).
By the following theorem, which will be proved in 7.7, other extensions
of G to be considered as provability logics are out of the question.

7.5 The Modal Treatment of Self-Reference
289
Theorem 5.3 ([Vi1]). Let T be at least as strong as PA. Then
(a) If T ω (page 284) is consistent, then G is the provability logic of T;
(b) if ⊢T ω ⊥and n is minimal such that ⊢T n ⊥, then T’s provability
logic is Gn.
The formulas H ∈F□such that N ⊨Hı for all insertions ı in Lar
can also be surprisingly easily characterized. All H ∈G are obviously
included; but in addition also □p →p belongs to this sort of formula,
because N ⊨□α →α for α ∈L0
ar. Indeed, if N ⊨□α then there is some
n that codes a proof of α in PA, hence N ⊨α.
Let GS (⊇G) be the set of all formulas in F□that can be obtained
from those in G ∪{□p →p} using substitution and modus ponens only.
Induction in GS readily yields H ∈GS ⇒N ⊨Hı for all ı. Again, the
converse holds as well:
Theorem 5.4 ([So]). H ∈GS if and only if N ⊨Hı for all insertions ı.
GS is decidable as well, because it can be shown that H ∈GS ⇔H∗∈G,
where H∗:= [ 
□G∈Sf□H(□G →G)] →H. Here Sf□H is the set of sub-
formulas of H of the form □G. Thus, Theorem 5.4 reduces the decidability
of GS to that of G. Using this theorem, many questions concerning the
relations between provable and true are eﬀectively decidable. For instance,
H(p) := ¬□(¬□⊥→¬□p ∧¬□¬p) ̸∈GS
is readily veriﬁed. Hence N ⊨¬H(α) ≡□(¬□⊥→¬□α ∧¬□¬α) for some
α ∈L0
ar by Theorem 5.4. Translated into English: It is provable in PA that
the consistency of PA implies the independence of α for some sentence α.
This is exactly Rosser’s theorem, which in this way turns out to be prov-
able in PA. As was shown in [Be1], the box in the formulas H ∈GS in
Theorem 5.4 may denote bwbT for any axiomatizable T ⊇PA, provided
T ⊆Th N. However, if T proves false sentences (as does e.g. PA⊥) then
GS has to be redeﬁned in a feasible manner and is always decidable.
A variable p in H is called modalized in H if every occurrence of p
is contained within the scope of a □, as is the case in ¬□p, ¬□¬p, and
□(p →q). By contrast, p is not modalized in □p →p. Another particularly
interesting theorem is

290
7 On the Theory of Self-Reference
Theorem 5.5 (DeJongh–Sambin ﬁxed point theorem). Let p be
modalized in H(p, q1, . . . , qn), n ⩾0. Then a formula F = F(⃗q) from F□
can eﬀectively be constructed such that
(a) F ≡G H(F, ⃗q),
(b) ⊢G
2
i=1[(pi ↔H(pi, ⃗q )) ∧□(pi ↔H(pi, ⃗q ))] →(p1 ↔p2).
This theorem easily yields a corresponding result for theories T:
Corollary 5.6. Let p be modalized in H = H(p, ⃗q ) and suppose T satisﬁes
D1–D4. Then there is an F = F(⃗q) ∈F□with F(⃗α) ≡T H(F(⃗α), ⃗α) for
all ⃗α = (α1, . . . , αn), αi ∈L0. For each ⃗α there is only one β ∈L0 modulo
T such that β ≡T H(β, ⃗α).
Proof. Choose F as in (a) of the theorem. Then F(⃗α) ≡T H(F(⃗α), ⃗α) by
Lemma 5.1 (⃗q ı = ⃗α). To prove uniqueness let βi ≡T H(βi, ⃗α) for i = 1, 2.
By D1, ⊢T (βi ↔H(βi, ⃗α)) ∧□(βi ↔H(βi, ⃗α)). Inserting βi for pi and αi
for qi in the formula under (b) in the theorem then yields ⊢T β1 ↔β2 by
Lemma 5.1.
Example 3. For H = ¬□p (n = 0), F = ¬□⊥is a “solution” of (a)
in Theorem 5.5 because ¬□⊥≡G ¬□(¬□⊥). According to Corollary 5.6,
ConT (= ¬□⊥) is modulo T the only ﬁxed point of ¬ bwbT . This is just
the claim of (3) from 7.3.
Many special cases of the corollary represent older self-reference results
from Gödel, Löb, Rogers, Jeroslow, and Kreisel, which, stated in terms of
modal logic, concern ﬁxed points of ¬□p, □p, ¬□¬p, □¬p, and □(p →q)
in PA. Incidentally, one gets the ﬁxed points of these formulas—namely
¬□⊥, ⊤, ⊥, □⊥, and □q—according to a simple recipe. All ﬁrst listed
formulas are of the form H = G □H′
p , where p is not modalized in G(p, ⃗q)
and H′(p, ⃗q) is chosen appropriately. In this case, F = H G(⊤,⃗q )
p
is the
ﬁxed point of H, as is seen after some calculation. For H = ¬□p from
Example 3 is G = ¬p. Thus, according to the recipe the ﬁxed point is
F = ¬□p ¬⊤
p = ¬□¬⊤≡G ¬□⊥.
For Kreisel’s formula □(p →q) is G = p. Hence, it has the ﬁxed point
F = □(p →q) ⊤p = □(⊤→q) ≡G □q.
The recipe also works for H = □p →q, by choosing G = p →q. Hence
F = (□p →q)
⊤→q
p
= □(⊤→q) →q ≡G □q →q is the only ﬁxed point of

7.6 A Bimodal Provability Logic for PA
291
H modulo T. Exactly this is the claim of Lemma 3.1(b), used in Gödel’s
second incompleteness theorem.
Exercises
1. Prove that the theory PAn from Example 2(d) has the provability
logic Gn.
2. Show that PAn
⊥:= PAn + ¬ ConPAn equals PA + □n+1⊥∧¬□n⊥and
that it has the provability logic G1 = G + □⊥. Here □means □PA.
3. Prove that ⊤, ⊥, and □⊥are the ﬁxed points of □p, ¬□¬p, and □¬p.
4. (Mostowski). Let T ⊇PA be axiomatizable and suppose N ⊨T.
Show that there are two mutually independent Σ1-sentences α, β in
T, that is, α →β, α →¬β, β →α, β →¬α (hence also α, β, ¬α, and
¬β) are unprovable in T.
7.6
A Bimodal Provability Logic for PA
Hilbert remarked jokingly that the incompleteness phenomenon can be
forcefully removed from the world by use of the so-called ω-rule
ρω : X ⊢ϕ(n) for all n
X ⊢∀xϕ
.
ρω has inﬁnitely many premises. It is an easy exercise to derive with the
aid of ρω every sentence α valid in N from the axioms of PA, even from
those of Q. Indeed, all sentences can (up to equivalence) be obtained from
variable-free literals with ∧, ∨, ∀, ∃, bypassing formulas with free variables.
Due to the Σ1-completeness of Q, all valid variable-free literals are deriv-
able. The inductive steps for ∧, ∨, ∃are simple, applying Σ1-completeness
in the ∃-step once again. Only in the ∀-step is ρω used.
Clearly, an unrestricted use of the inﬁnitistic rule ρω (in spite of its rel-
evance for higher order arithmetic) contradicts Hilbert’s own intention of
giving mathematics a ﬁnitistic foundation. However, things look diﬀerent
if we restrict ρω each time to a single application. In view of Remark 1
in 6.2, we no longer distinguish between ϕ and ˙ϕ, so that ϕ itself is a
number and ⌜ϕ⌝= ϕ is the corresponding Gödel term. Let us deﬁne

292
7 On the Theory of Self-Reference
1bwbPA(α) := (∃ϕ∈L1
ar)[bwbPA(∀xϕ →α) & ∀n bwbPA(ϕ(n))].
1bwbPA is arithmetical, in fact it is Σ3, for bwbPA is Σ1 and ∀n bwbPA(ϕ(n))
is Π1. We read 1bwbPA(α) as “α is 1-provable.” Let 1bwb(x) be the Σ3-
formula in Lar deﬁning 1bwbPA. Here let x be v0. Write □
1 α for 1bwb(⌜α⌝)
and 3
1 α for ¬ □
1 ¬α. Clearly, □α for α ∈L0
ar (□= □PA) can be read
‘PA + ¬α is inconsistent’, while □
1 α, by Lemma 6.1, formalizes ‘PA + ¬α
is ω-inconsistent’.
Thus, 3
1 ⊤(≡¬ □
1 ⊥) means ‘PA (= PA + ¬⊥) is ω-
consistent’. This explains the interest in the operator □
1 .
If bwbPA(α) then certainly 1bwbPA(α) (choose α for ϕ). The italicized
statement is reﬂected in PA as ‘⊢PA □α →□
1 α for every α ∈L0
ar’. The
converse fails, since ⊬PA ConPA, while ConPA is easily 1-provable: ⊢PA ϕ(n)
for all n, with ϕ(x) := ¬ bewPA(x, ⊥), and trivially ⊢PA ∀xϕ(x) →ConPA.
In what follows, some claims will not be proved in detail.
Deﬁne Ω := {ϕ∈L1
ar | ⊢PA ϕ(n) for all n}.
By its deﬁnition, Ω and
hence also PAΩ := PA + Ω are formally Σ3. As Theorem 6.2 will show,
PAΩ is properly Σ3 and hence is no longer recursively axiomatizable.
Lemma 6.1. The following properties are equivalent for α ∈L0
ar:
(i) 1bwbPA(α),
(ii) ⊢PAΩ α,
(iii) PA + ¬α is ω-inconsistent.
Proof. (i)⇒(ii) follows with a glance at the deﬁnitions (read (i) naively).
(ii)⇒(iii): Let ⊢PAΩ α. Since Ω is closed under conjunctions, there is some
∀xϕ(x) ∈Ω with ∀xϕ ⊢PA α, hence ⊢PA ¬α →∃x¬ϕ and so ⊢PA+¬α ∃x¬ϕ.
Now, ∀xϕ ∈Ω, therefore ⊢PA ϕ(n) and a fortiori ⊢PA+¬α ϕ(n), for all n.
Thus, PA + ¬α is ω-inconsistent. (iii)⇒(i): Let ⊢PA+¬α β(n) for all n,
but ⊢PA+¬α ∃x¬β. Then ⊢PA ∀xβ →α. With ϕ(x) := ¬α →β(x) clearly
⊢PA ϕ(n) for all n. Now, ∀xϕ ≡α ∨∀xβ ⊢PA α. Hence ⊢PA ∀xϕ →α.
Thus, altogether 1bwbPA(α).
Theorem 6.2 (the 1-provable Σ3-completeness of PA). All true Σ3-
sentences are 1-provable. Moreover, for every β of this kind, ⊢PA β →□
1 β.
Proof. Let N ⊨β := ∃y∀xγ(y, x) where γ(y, x) is Σ1. Then there is
some m such that N ⊨γ(m, n) for all n. Therefore, ⊢PA γ(m, n) for all
n, because PA is Σ1-complete. Hence, ∀xγ(m, x) ∈Ω and so ⊢PAΩ ∃z∀xγ,
or equivalently, 1bwbPA(β) by Lemma 6.1. Because of the provable Σ1-
completeness of PA, this argumentation is comprehensible in PA, so that
also ⊢PA β →□
1 β.

7.6 A Bimodal Provability Logic for PA
293
D1–D4 are also valid for the operator □
1 : L0
ar →L0
ar. Indeed, D1 holds
because ⊢PA α ⇒⊢PA □α ⇒⊢PA □
1 α, and D2 formalizes (or reﬂects)
‘⊢PAΩ α, α →β ⇒⊢PAΩ β’ in PA (observe Lemma 6.1). D3 follows from
Theorem 6.2 with β = □
1 α. The proof of D4 in 7.3 uses, along with the
ﬁxed point lemma, only D1–D3; so D4 holds as well. Therefore, nearly
everything said in 7.3 on □applies also to □
1 , including Theorem 3.2,
which now reads ⊬PA ¬ □
1 ⊥(≡3
1 ⊤). To put it more concisely, although
the consistency of PA is provable with the extended means, ω-consistency
is not. Hence, this property, which is Π3-deﬁnable according to Exercise 3
in 6.7, cannot be Σ3 by Theorem 6.2, and must therefore be properly Π3.
Equivalently, ω-inconsistency is properly Σ3.
Alongside □α →□
1 α, there are other noteworthy interactions between
□and □
1 , in particular ⊢PA ¬□α →□
1 ¬□α. This formalizes ‘If ⊬PA α then
¬□α is 1-provable’. To verify the latter notice that ⊬PA α implies ⊢PA ϕ(n)
for all n, where ϕ(x) is ¬ bewPA(x, ⌜α⌝), and since ⊢PA ∀xϕ →¬□α, we
get ⊢PA □
1 ¬□α. On the other hand, ⊢PA ¬□α →□¬□α fails in general;
Example 2(c) in 7.5 yields a counterexample.
The language of the bimodal propositional logic GD now to be deﬁned
results from F□by adding a further connective □
1 to F□, which is treated
syntactically just as □. The axioms of GD are those of G stated both for
□and □
1 , augmented by the axioms
□p →□
1 p
and
¬□p →□
1 ¬□p.
The rules of GD are the same as those for G.
Insertions ı to L0
ar are
deﬁned as in 7.5, but with the additional clause (□
1 H)ı = □
1 Hı, that is,
(□
1 H)ı = 1bwb(⌜Hı⌝). By the reasoning above, all axioms and rules of
GD are sound. This proves (the easier) half of the following remarkable
theorem from Dzhaparidze (1985):
Theorem 6.3. ⊢GD H ⇔⊢PA Hı for all insertions ı as deﬁned above.
Furthermore, GD is decidable.
Thus, the modal system GD completely captures the interaction be-
tween bwbPA and 1bwbPA; also Theorem 5.5 carries over. However, GD no
longer has an adequate Kripke semantics, which complicates the decision
procedure. For further references see [Boo] or [Be3] .
As an exercise, the reader should derive □
1 (□p →p) from the axioms of
GD. Thus, ⊢PA □
1 (□α →α) for every α ∈L0
ar, while ⊢PA □(□α →α) is the

294
7 On the Theory of Self-Reference
case only provided ⊢PA α. In other words, the local reﬂection principle
{□α →α | α ∈L0
ar} is 1-provable in PA. Be careful: GD expands G
conservatively, so that ⊬GD □p →p.
7.7
Modal Operators in ZFC
Considerations regarding self-reference in ZFC are technically sometimes
easier, but from the foundational point of view more involved because
there is no superordinate theory. If ZFC is consistent, as we assume it
is, then ConZFC is a true arithmetical statement that is unprovable in
ZFC. Thus, true arithmetical statements may even be unprovable in ZFC,
not only in PA or similarly strong arithmetical theories. It makes sense,
therefore, to consider ZFC+ := ZFC + ConZFC, because after all, we want
set theory to embrace as many facts about numbers and sets as possible
from which interesting consequences may result.
As 7.3 shows, the consistency of ZFC alone does not guarantee that
ZFC+ is consistent. The second incompleteness theorem clearly excludes
⊢ZFC ConZFC but does not preclude ⊢ZFC ConZFC →ConZFC+. In this case
⊢ZFC+ ConZFC+, and so ⊢ZFC+
⊥by the same theorem.
On the other
hand, from certain assumptions about the existence of large cardinals, the
consistency of ZFC+ readily follows. These assumptions would have to be
jettisoned in case ⊢ZFC+ ⊥, i.e. ⊢ZFC ¬ ConZFC. Moreover, the consistency
of ZFC would then not correctly be reﬂected in ZFC, and ZFC proves along
with true arithmetical facts also false ones. This sounds strange, but there
is hardly a convincing argument that this cannot be so.
Even if ZFC+ is consistent, i.e. ⊬ZFC ¬ ConZFC, it may still be that one of
the sentences from the sequence □¬ ConZFC, □□¬ ConZFC, . . . is provable
in ZFC (where □denotes □ZFC as long as it is not redeﬁned). The latter
is excluded only if we assume that the ω-iterated consistency extension
ZFCω is consistent, hence ⊬ZFC □n⊥, for all n (see page 284), so that by
Theorem 5.3, G would be the provability logic of ZFC.
In fact, the assumption (∀n∈N) ⊬ZFC □n⊥is equivalent to G’s being
the provability logic of ZFC, by the general Theorem 7.1 below. Therein
Rf T := {□α →α | α ∈L0} denotes the already encountered reﬂection
principle. Also Theorem 5.3 is a corollary of the theorem, simply because
(∀n∈N) ⊬T □n+1⊥is equivalent to the consistency of T ω.

7.7 Modal Operators in ZFC
295
Theorem 7.1. For a suﬃciently expressive theory T 5 the following con-
ditions are equivalent:
(i)
T ω is consistent,
(ii)
T + Rf T is consistent,
(iii) G is the provability logic of T.
Proof. (i)⇒(ii) indirect: Suppose that T + Rf T is inconsistent. Then
there are formulas α0, . . . , αn such that ⊢T ¬ϕ, ϕ := n
i=1(□αi →αi).
Hence ⊢T □¬ϕ ≡T ¬3ϕ. Now, because ⊢T ω ¬□n+1⊥, by Example (d) in
7.4 and Lemma 5.1, we get ⊢T ω 3Rı
n (pı
i = αi). Clearly, Rı
n = ϕ and so
⊢T ω 3ϕ. Since also ⊢T ω ¬3ϕ, T ω is inconsistent. (ii)⇒(iii): The proof of
Theorem 5.2 for PA, as presented in [Boo], runs nearly in the same way
for T, because PA is transgressed in one place only: one uses the fact that
N ⊨Rf PA. However, the existence of a corresponding T-model is ensured
by (ii). (iii)⇒(i): ⊭G □n+1⊥, hence ⊬T □n+1⊥≡T ¬ ConT n for all n, and
so T ω is consistent.
The equivalence (i)⇔(ii) is a purely proof-theoretic one. It is called
Goryachev’s theorem; see [Gor] or [Be2]. We obtained it using essentially
some elementary modal logic. For T = ZFC, perhaps a bit more interesting
than (i) or (ii) is the assumption of the ω-consistency of ZFC, that is,
(∗) ⊢ZFC (∃x∈ω)ϕ(x) ⇒⊬ZFC ¬ϕ(n) for some n
(ϕ(x) ∈L∈).
This assumption implies D1∗, which in turn ensures ⊬ZFC □n+1⊥for all
n, that is, (i), and hence all other conditions in Theorem 7.1 hold for
T = ZFC. It is worthwhile to observe that the consistency of ZFC+Rf ZFC
and thereby the proof of Solovay’s completeness theorem for ZFC follow
directly from (∗), without appealing to Goryachev’s theorem. What is
needed to see that the latter is the case is the following
Lemma. Suppose that ZFC is ω-consistent. Then there exists a model
V ⊨ZFC such that V ⊨Rf ZFC.
Proof. Let Ω := {(∀x ∈ω)α | α=α(x) ∈L∈, ⊢ZFC α(n) for all n}. Then
ZFC+Ω is consistent. Indeed, otherwise ⊢ZFC ¬(∀x ∈ω)α ≡(∃x ∈ω)¬α for
some (∀x ∈ω)α ∈Ω (since Ω is closed under conjunction), in contradiction
to (∗). Any V ⊨ZFC + Ω satisﬁes the reﬂection principle Rf ZFC, for if
5 By such a T we mean that the proof steps of Solovay’s Theorem 5.2 not transgressing
PA can be carried out in T. This does not yet imply the provability of the theorem
itself. Which steps are transgressing PA is described in the following proof.

296
7 On the Theory of Self-Reference
V ⊭α then ⊬ZFC α and therefore ⊢ZFC ¬ bewZFC(n, ⌜α⌝) for all n. Hence
(∀y ∈ω)¬ bewZFC(y, ⌜α⌝) ∈Ω, which clearly implies V ⊭□α.
Now we interpret the modal operator □no longer as provable in ZFC,
which is equivalent to valid in all ZFC-models, but rather as valid in
particular classes of ZFC-models. For undeﬁned notions used in the sequel
we refer to [Ku]. A ‘model’ is to mean throughout a ZFC-model.
Particularly interesting are transitive models, i.e. models V = (V, ∈V),
where the set V is transitive. This is to mean a ∈b ∈V ⇒a ∈V . In
these models, ∈V coincides with the ordinary ∈-relation restricted to V (a
set in our metatheory that itself is ZFC). We write V for V. Let ρa denote
the ordinal rank of the set a, i.e., the smallest ordinal ρ with a ∈Vρ+1. To
prove the soundness half of Theorem 7.3 we will need
Lemma 7.2. ([JK]) Let V, W be transitive models such that ρV < ρW
and let V ⊨α. Then W ⊨‘there is a transitive model U with U ⊨α’.6
Let the modal logic Gi result from augmenting G by the axiom
(i)
□(□p →□q) ∨□(□q →p).
Gi is complete with respect to all preference orders g, i.e., g is a ﬁnite
poset together with some function π: g →n (= {0, . . . , n−1}) such that
P < Q ⇔πP < πQ, for all P, Q ∈g. This implies the ﬁnite model
property of Gi, which, as for G, ensures the decidability of Gi.
More
suitable for our aims is the characterization of preference orders g by the
property
(p)
P < P ′ implies P < Q or Q < P ′, for all P, P ′, Q ∈g,
which at once follows from the deﬁnition: Let P < P ′, hence πP < πP ′.
If P ̸< Q, i.e. πP ̸< πQ, then πQ ⩽πP < πP ′, so that Q < P ′. The

3

3P ′
P
Q
O
XX
z
s
s
s
s
proof of the converse is Exercise 1. The ﬁgure shows a poset g
that is not a preference order (for neither P < Q nor Q < P ′).
Axiom (i) is easily refuted in g choosing wp = {P ′}, wq = ∅,
and verifying that O ⊩3(□p ∧¬□q) and O ⊩3(□q ∧¬p) (for notice that
P ⊩□p ∧¬3q and Q ⊩□q ∧¬p). Hence, (i) does not belong to G, so
that Gi is a proper extension of G. We mention that in [So] and in [Boo]
a somewhat more complex axiomatization of Gi has been considered.
6 In transitive models W the sentence in ‘ ’ (which with some encoding can be for-
mulated in L∈) is absolute, and therefore equivalent to the existence of a transitive
model U ∈W with U ⊨α.

7.7 Modal Operators in ZFC
297
Remark on splittings in modal logic. The completeness of Gi with respect
to all preference orders follows also from the fact that Gi is the split logic arising
from splitting the lattice of all extensions of G (see e.g. [Kra]) by the subdirect
irreducible G-algebra belonging to the frame from the previous page.
We deﬁne insertions ı: F□→L0
∈as in 7.5 as usual by (□H)ı = □Hı,
where □α for the set-theoretic sentence α = Hı ∈L0
∈is now to mean ‘α is
valid in all transitive models’. Accordingly, 3α = ¬□¬α states ‘α holds
in at least one transitive model’.
Theorem 7.3. ⊢Gi H iﬀ⊢ZFC Hı for all insertions ı as deﬁned above.
We prove only the direction ⇒, that is, soundness. The converse is much
more diﬃcult, see [Boo]. As regards the axioms of Gi, since □p →□□p is
provable from the other axioms of G (see 7.4), it suﬃces to prove
(A) □(α →β) ∧□α ⊢ZFC □β,
(B) □(□α →α) ⊢ZFC □α,
(C) ⊢ZFC □(□α →□β) ∨□(□β →α), for all α, β ∈L0
∈.
(A) is trivial, because the sentences valid in any class of models are closed
under MP. (B) is equivalent to (B′): 3¬α ⊢ZFC 3(□α ∧¬α). Here is the
proof: Suppose 3¬α, i.e. there is a transitive model in which ¬α holds.
Then there is also one with minimal rank, V say. We claim V ⊨□α.
Otherwise V ⊨3¬α, and hence there would be a transitive model U ∈V
with U ⊨¬α and ρU < ρV , contradicting our choice of V . Therefore,
V ⊨□α ∧¬α. Thus, there is a transitive model in which □α ∧¬α holds,
which conﬁrms (B′). Finally, (C) is veriﬁed by contraposition: suppose
there are transitive models V, W and sentences α, β such that
(a) V ⊨‘α holds in all transitive models and there is a transitive model
in which ¬β holds’,
(b) W ⊨‘β holds in all transitive models’,
(c) W ⊨¬α.
From these assumptions it follows ﬁrst of all that ρW < ρV . Indeed,
suppose by (a) that U ∈V is a transitive model for ¬β. If ρV ⩽ρW then
ρU < ρW. Hence, by Lemma 7.2, W ⊨‘there is a transitive model for ¬β’,
contradicting (b). Now, since W ⊨¬α by (c) and because of ρW < ρV ,
in V holds ‘there is some transitive model for ¬α’ by Lemma 7.2, in
contradiction to (a). This proves (C). Soundness of the substitution rule
follows as for G in 7.5. MN is trivially sound, because if α is provable
in ZFC then, of course, α is valid in all transitive models. Also MP is
obvious: If α and α →β hold in any class of models, then also β.

298
7 On the Theory of Self-Reference
Another interesting model-theoretic interpretation of □α is ‘α is valid in
all Vκ’. Here κ runs through all inaccessible cardinal numbers. According
to [So], the adequate modal logic for this interpretation of □is
Gj := G + □(□p ∧p →q) ∨□(□q →p).
More precisely, if there are inﬁnitely many inaccessibles then we have
Theorem 7.4. ⊢Gj H iﬀ
⊢ZFC Hı for all insertions ı, where □α is to
mean ‘α is valid in all Vκ’, κ running through all inaccessible cardinals.
Gj is also denoted by G.3. This logic is complete with respect to all
ﬁnite strict linear orders. These, of course, are also frames for Gi, so that

3P
OXX
z
s
s
s
Gi ⊆Gj. The ﬁgure shows a Gi-frame, also called “the fork,”
on which the additional axiom is easily refuted at its initial
point O with wp = {P} and wq = ∅. Hence the fork is not
a Gj-frame, and so Gi ⊂Gj. The completeness of Gj with respect to ﬁnite
orders entails the ﬁnite model property of Gj and hence its decidability.
We recommend that the reader carry out the proof of the soundness part
of Theorem 7.4, without consulting the hints to the solutions (Exercise 4).
It is easier than the soundness part of Theorem 7.3 proved above. All one
needs to know besides Lemma 7.2 is that each Vκ is a transitive ZFC-
model and that Vκ ∈Vλ or Vλ ∈Vκ, for arbitrary inaccessible cardinals
κ ̸= λ. Maybe the reader can also ﬁnd a new and lucid proof of the hard
direction of Theorem 7.4: If ⊢ZFC Hı for all ı then H holds in all ﬁnite
strict linear orders, or equivalently, Gj ⊢H.
Exercises
1. Let g be a G-frame with property (p), page 296. Show by induction
on the length of a maximal path in g that g is a preference order.
2. Show (using Exercise 1) that axiom (i) for Gi holds in a G-frame g
iﬀg is a preference order. This is an essential step in proving the
completeness of Gi with respect to all preference orders.
3. This exercise is a crucial step in the completeness proof of Gj. Show
that a G-frame g is a frame for Gj, i.e., □(□p ∧p →q) ∨□(□q →p))
holds in g if and only if g is (totally) ordered.
4. Verify the soundness part of Theorem 7.4, i.e., ⊢Gj ⇒⊢ZFC Hı for
all insertions ı.

Bibliography
[AGM] S. Abramsky, D. M. Gabbay, T. S. E. Maibaum (editors), Handbook
of Computer Science, I–IV, Oxford Univ. Press, Vol. I, II 1992, Vol. III
1994, Vol. IV 1995.
[Ac]
W. Ackermann, Die Widerspruchsfreiheit der Allgemeinen Mengen-
lehre, Mathematische Annalen 114 (1937), 305–315.
[Bar]
J. Barwise (editor), Handbook of Mathematical Logic, North-Holland
1977.
[BF]
J. Barwise, S. Feferman (editors), Model-Theoretic Logics, Springer
1985.
[Be1]
L. D. Beklemishev, On the classiﬁcation of propositional provability
logics, Math. USSR – Izvestiya 35 (1990), 247–275.
[Be2]
, Iterated local reﬂection versus iterated consistency, Ann. Pure
Appl. Logic 75 (1995), 25–48.
[Be3]
, Bimodal logics for extensions of arithmetical theories, J. Symb.
Logic 61 (1996), 91–124.
[Be4]
, Parameter free induction and reﬂection, in Computational Logic
and Proof Theory, Lecture Notes in Computer Science 1289, Springer
1997, 103–113.
[BM]
J. Bell, M. Machover,
A Course in Mathematical Logic,
North-
Holland 1977.
[Ben]
M. Ben-Ari,
Mathematical Logic for Computer Science,
New York
1993, 2nd ed. Springer 2001.
[BP]
P. Benacerraf, H. Putnam (editors), Philosophy of Mathematics,
Selected Readings, Englewood Cliﬀs NJ 1964, 2nd ed. Cambridge Univ.
Press 1983, reprint 1997.
[BA]
A. Berarducci,
P. D’Aquino,
Δ0-complexity of the relation
y = 
i⩽n F(i), Ann. Pure Appl. Logic 75 (1995), 49–56.
299

300
Bibliography
[Bi]
G. Birkhoff, On the structure of abstract algebras, Proceedings of the
Cambridge Philosophical Society 31 (1935), 433–454.
[Boo]
G. Boolos, The Logic of Provability, Cambridge Univ. Press 1993.
[BJ]
G. Boolos, R. Jeffrey, Computability and Logic, 3rd ed. Cambridge
Univ. Press 1989.
[BGG] E. Börger, E. Grädel, Y. Gurevich, The Classical Decision Prob-
lem, Springer 1997.
[Bue]
S. Buechler, Essential Stability Theory, Springer 1996.
[Bu]
S. R. Buss (editor), Handbook of Proof Theory, Elsevier 1998.
[Ca]
G. Cantor, Gesammelte Abhandlungen (editor E. Zermelo), Berlin
1932, Springer 1980.
[CZ]
A. Chagrov, M. Zakharyashev, Modal Logic, Clarendon Press 1997.
[CK]
C. C. Chang, H. J. Keisler, Model Theory, Amsterdam 1973, 3rd ed.
North-Holland 1990.
[Ch]
A. Church, A note on the Entscheidungsproblem, J. Symb. Logic 1
(1936), 40–41, also in [Dav, 108–109].
[CM]
W. Clocksin, C. Mellish, Programming in PROLOG, 3rd ed. Sprin-
ger 1987.
[Da]
D. van Dalen, Logic and Structure, Berlin 1980, 4th ed. Springer 2004.
[Dav]
M. Davis (editor), The Undecidable, Raven Press 1965.
[Daw]
J. W. Dawson, Logical Dilemmas, The Life and Work of Kurt Gödel,
A. K. Peters 1997.
[De]
O. Deiser, Axiomatische Mengenlehre, Springer, to appear 2010.
[Do]
K. Doets, From Logic to Logic Programming, MIT Press 1994.
[EFT]
H.-D. Ebbinghaus, J. Flum, W. Thomas, Mathematical Logic, New
York 1984, 2nd ed. Springer 1994.
[FF]
A. B. Feferman, S. Feferman, Alfred Tarski, Live and Logic, Cam-
bridge Univ. Press 2004.
[Fe1]
S. Feferman, Arithmetization of metamathematics in a general setting,
Fund. Math. 49 (1960), 35–92.
[Fe2]
, In the Light of Logic, Oxford Univ. Press 1998.
[Fel1]
W. Felscher, Berechenbarkeit, Springer 1993.

Bibliography
301
[Fel2]
, Lectures on Mathematical Logic, Vol. 1–3, Gordon & Breach
2000.
[Fi]
M. Fitting, Incompleteness in the Land of Sets, College Publ. 2007.
[Fr]
T. Franzén, Gödel’s Theorem: An Incomplete Guide to Its Use and
Abuse, A. K. Peters 2005.
[Fre]
G. Frege, Begriﬀsschrift, eine der arithmetischen nachgebildete For-
melsprache des reinen Denkens, Halle 1879, G. Olms Verlag 1971, also
in [Hei, 1–82].
[FS]
H. Friedman, M. Sheard, Elementary descent recursion and proof
theory, Ann. Pure Appl. Logic 71 (1995), 1–47.
[Ga]
D. Gabbay, Decidability results in non-classical logic III, Israel Journal
of Mathematics 10 (1971), 135–146.
[GJ]
M. Garey, D. Johnson, Computers and Intractability, A Guide to the
Theory of NP-Completeness, Freeman 1979.
[Ge]
G. Gentzen, The Collected Papers of Gerhard Gentzen (editor M. E.
Szabo), North-Holland 1969.
[Gö1]
K. Gödel, Die Vollständigkeit der Axiome des logischen Funktionen-
kalküls, Monatshefte f. Math. u. Physik 37 (1930), 349–360, also in [Gö3,
Vol. I, 102–123], [Hei, 582–591].
[Gö2]
, Über formal unentscheidbare Sätze der Principia Mathematica
und verwandter Systeme I, Monatshefte f. Math. u. Physik 38 (1931),
173–198, also in [Gö3, Vol. I, 144–195], [Hei, 592–617], [Dav, 4–38].
[Gö3]
,
Collected Works (editor S. Feferman),
Vol. I–V,
Oxford
Univ. Press, Vol. I 1986, Vol. II 1990, Vol. III 1995, Vol. IV, V 2003.
[Gor]
S. N. Goryachev, On the interpretability of some extensions of arith-
metic, Mathematical Notes 40 (1986), 561–572.
[Gr]
G. Grätzer, Universal Algebra, New York 1968, 2nd ed. Springer 1979.
[HP]
P. Hájek, P. Pudlák, Metamathematics of First-Order Arithmetic,
Springer 1993.
[Hei]
J. van Heijenoort (editor), From Frege to Gödel, Harvard Univ. Press
1967.
[He]
L. Henkin, The completeness of the ﬁrst-order functional calculus, J.
Symb. Logic 14 (1949), 159–166.
[Her]
J. Herbrand, Recherches sur la théorie de la démonstration, C. R.
Soc. Sci. Lett. Varsovie, Cl. III (1930), also in [Hei, 525–581].

302
Bibliography
[HR]
H. Herre, W. Rautenberg, Das Basistheorem und einige Anwen-
dungen in der Modelltheorie, Wiss. Z. Humboldt-Univ., Math. Nat. R.
19 (1970), 579–583.
[HeR]
B. Herrmann, W. Rautenberg,
Finite replacement and ﬁnite
Hilbert-style axiomatizability, Zeitsch. Math. Logik Grundlagen Math.
38 (1982), 327–344.
[HA]
D. Hilbert, W. Ackermann,
Grundzüge der theoretischen Logik,
Berlin 1928, 6th ed. Springer 1972.
[HB]
D. Hilbert, P. Bernays, Grundlagen der Mathematik, I, II, Berlin
1934, 1939, 2nd ed. Springer, Vol. I 1968, Vol. II 1970.
[Hi]
P. Hinman, Fundamentals of Mathematical Logic, A. K. Peters 2005.
[Ho]
W. Hodges, Model Theory, Cambridge Univ. Press 1993.
[Hor]
A. Horn, On sentences which are true of direct unions of algebras, J.
Symb. Logic 16 (1951), 14–21.
[Hu]
T. W. Hungerford, Algebra, Springer 1980.
[Id]
P. Idziak, A characterization of ﬁnitely decidable congruence modular
varieties, Trans. Amer. Math. Soc. 349 (1997), 903–934.
[Ig]
K. Ignatiev, On strong provability predicates and the associated modal
logics, J. Symb. Logic 58 (1993), 249–290.
[JK]
R. Jensen, C. Karp, Primitive recursive set functions, in Axiomatic
Set Theory, Vol. I (editor D. Scott), Proc. Symp. Pure Math. 13, I
AMS 1971, 143–167.
[Ka]
R. Kaye, Models of Peano Arithmetic, Clarendon Press 1991.
[Ke]
H. J. Keisler, Logic with the quantiﬁer “there exist uncountably many”,
Annals of Mathematical Logic 1 (1970), 1–93.
[Kl1]
S. Kleene, Introduction to Metamathematics, Amsterdam 1952, 2nd ed.
Wolters-Noordhoﬀ1988.
[Kl2]
, Mathematical Logic, Wiley & Sons 1967.
[KR]
I. Korec, W. Rautenberg, Model interpretability into trees and ap-
plications, Arch. math. Logik 17 (1976), 97–104.
[Kr]
M. Kracht, Tools and Techniques in Modal Logic, Elsevier 1999.
[Kra]
J. Krajíček, Bounded Arithmetic, Propositional Logic, and Complexity
Theory, Cambridge Univ. Press 1995.

Bibliography
303
[KK]
G. Kreisel, J.-L. Krivine, Elements of Mathematical Logic, North-
Holland 1971.
[Ku]
K. Kunen, Set Theory, An Introduction to Independence Proofs, North-
Holland 1980.
[Le]
A. Levy, Basic Set Theory, Springer 1979.
[Li]
P. Lindström, On extensions of elementary logic, Theoria 35 (1969),
1–11.
[Ll]
J. W. Lloyd, Foundations of Logic Programming, Berlin 1984, 2nd ed.
Springer 1987.
[Lö]
M. Löb,
Solution of a problem of Leon Henkin,
J. Symb. Logic 20
(1955), 115–118.
[MS]
A. Macintyre, H. Simmons, Gödel’s diagonalization technique and
related properties of theories,
Colloquium Mathematicum 28 (1973),
165–180.
[Ma]
A. I. Mal’cev, The Metamathematics of Algebraic Systems, North-
Holland 1971.
[Mal]
J. Malitz, Introduction to Mathematical Logic, Springer 1979.
[Mar]
D. Marker, Model Theory, An Introduction, Springer 2002.
[Mat]
Y. Matiyasevich, Hilbert’s Tenth Problem, MIT Press 1993.
[MV]
R. McKenzie, M. Valeriote,
The Structure of Decidable Locally
Finite Varieties, Progress in Mathematics 79, Birkhäuser 1989.
[Me]
E. Mendelson, Introduction to Mathematical Logic, Princeton 1964,
4th ed. Chapman & Hall 1997.
[Mo]
D. Monk, Mathematical Logic, Springer 1976.
[Moo]
G. H. Moore, The emergence of ﬁrst-order logic, in History and Phi-
losophy of Modern Mathematics (editors W. Aspray, P. Kitcher),
University of Minnesota Press 1988, 95–135.
[ML]
G. Müller, W. Lenski (editors), The Ω-Bibliography of Mathematical
Logic, Springer 1987.
[Po]
W. Pohlers, Proof Theory, An Introduction, Lecture Notes in Mathe-
matics 1407, Springer 1989.
[Pz]
B. Poizat, A Course in Model Theory, Springer 2000.

304
Bibliography
[Pr]
M. Presburger, Über die Vollständigkeit eines gewissen Systems der
Arithmetik ganzer Zahlen, in welchem die Addition als einzige Opera-
tion hervortritt, Congrès des Mathématiciens des Pays Slaves 1 (1930),
92–101.
[RS]
H. Rasiowa, R. Sikorski,
The Mathematics of Metamathematics,
Warschau 1963, 3rd ed. Polish Scientiﬁc Publ. 1970.
[Ra1]
W. Rautenberg, Klassische und Nichtklassische Aussagenlogik, Vie-
weg 1979.
[Ra2]
, Modal tableau calculi and interpolation, Journ. Phil. Logic 12
(1983), 403–423.
[Ra3]
, A note on completeness and maximality in propositional logic,
Reports on Mathematical Logic 21 (1987), 3–8.
[Ra4]
,
Einführung in die mathematische Logik,
Wiesbaden 1996,
3rd ed. Vieweg+Teubner 2008.
[Ra5]
,
Messen und Zählen, Eine einfache Konstruktion der reellen
Zahlen, Heldermann 2007.
[RZ]
W. Rautenberg, M. Ziegler, Recursive inseparability in graph the-
ory, Notices Amer. Math. Soc. 22 (1975), A–523.
[Ro1]
A. Robinson, Introduction to Model Theory and to the Metamathemat-
ics of Algebra, Amsterdam 1963, 2nd ed. North-Holland 1974.
[Ro2]
,
Non-Standard Analysis,
Amsterdam 1966, 3rd ed. North-
Holland 1974.
[Rob]
J. Robinson, A machine-oriented logic based on the resolution princi-
ple, Journal of the ACM 12 (1965), 23–41.
[Rog]
H. Rogers, Theory of Recursive Functions and Eﬀective Computability,
New York 1967, 2nd ed. MIT Press 1988.
[Ros]
J. B. Rosser, Extensions of some theorems of Gödel and Church, J.
Symb. Logic 1 (1936), 87–91, also in [Dav, 230–235].
[Rot]
P. Rothmaler, Introduction to Model Theory, Gordon & Breach 2000.
[Ry]
C. Ryll-Nardzewki, The role of the axiom of induction in elemenary
arithmetic, Fund. Math. 39 (1952), 239–263.
[Sa]
G. Sacks, Saturated Model Theory, W. A. Benjamin 1972.
[Sam]
G. Sambin, An eﬀective ﬁxed point theorem in intuitionistic diagonal-
izable algebras, Studia Logica 35 (1976), 345–361.
[Sc]
U. Schöning, Logic for Computer Scientist, Birkhäuser 1989.

Bibliography
305
[Se]
A. Selman, Completeness of calculi for axiomatically deﬁned classes of
algebras, Algebra Universalis 2 (1972), 20–32.
[Sh]
S. Shapiro (editor), The Oxford Handbook of Philosophy of Mathemat-
ics and Logic, Oxford Univ. Press 2005.
[She]
S. Shelah, Classiﬁcation Theory and the Number of Nonisomorphic
Models, Amsterdam 1978, 2nd ed. North-Holland 1990.
[Shoe]
J. R. Shoenfield, Mathematical Logic, Reading Mass. 1967, A. K.
Peters 2001.
[Si]
W. Sieg, Herbrand analyses, Arch. Math. Logic 30 (1991), 409–441.
[Sm]
P. Smith,
An Introduction to Gödel’s Theorems,
Cambridge Univ.
Press 2007.
[Smo]
C. Smoryński, Self-reference and Modal Logic, Springer 1984.
[Smu]
R. Smullyan, Theory of Formal Systems, Princeton Univ. Press 1961.
[So]
R. Solovay, Provability interpretation of modal logic, Israel Journal of
Mathematics 25 (1976), 287–304.
[Sz]
W. Szmielew, Elementary properties of abelian groups, Fund. Math.
41 (1954), 203–271.
[Tak]
G. Takeuti, Proof Theory, Amsterdam 1975, 2nd ed. Elsevier 1987.
[Ta1]
A. Tarski, Der Wahrheitsbegriﬀin den formalisierten Sprachen, Studia
Philosophica 1 (1936), 261–405 (ﬁrst edition in Polish, 1933), also in
[Ta4, 152-278].
[Ta2]
, Introduction to Logic and to the Methodology of Deductive Sci-
ences, Oxford 1941, 3rd ed. Oxford Univ. Press 1965 (ﬁrst edition in
Polish, 1936).
[Ta3]
,
A Decision Method for Elementary Algebra and Geometry,
Santa Monica 1948, Berkeley 1951, Paris 1967.
[Ta4]
, Logic, Semantics, Metamathematics (editor J. Corcoran),
Oxford 1956, 2nd ed. Hackett 1983.
[TMR] A. Tarski, A. Mostowski, R. M. Robinson, Undecidable Theories,
North-Holland 1953.
[TV]
A. Tarski, R. Vaught, Arithmetical extensions and relational systems,
Compositio Mathematica 13 (1957), 81–102.
[Tu]
A. Turing, On computable numbers, with an application to the Ent-
scheidungsproblem,
Proc. London Math. Soc., 2nd Ser. 42 (1937),
230–265, also in [Dav, 115–154].

306
Bibliography
[Vi1]
A. Visser, Aspects of Diagonalization and Provability, Dissertation,
University of Utrecht 1981.
[Vi2]
,
An overview of interpretability logic,
in Advances in Modal
Logic, Vol. 1 (editors M. Kracht et al.), CSLI Lecture Notes 87 (1998),
307–359.
[Wae]
B. L. van der Waerden, Algebra I, Berlin 1930, 4th ed. Springer
1955.
[Wag]
F. Wagner, Simple Theories, Kluwer Academic Publ. 2000.
[Wa1]
H. Wang, From Mathematics to Philosophy, Routlegde & Kegan Paul
1974.
[Wa2]
, Computer, Logic, Philosophy, Kluwer Academic Publ. 1990.
[Wa3]
, A Logical Journey, From Gödel to Philosophy, MIT Press 1997.
[WR]
A. Whitehead, B. Russell, Principia Mathematica, I–III, Cambridge
1910, 1912, 1913, 2nd ed. Cambridge Univ. Press, Vol. I 1925, Vol. II,
III 1927.
[Wi]
A. Wilkie, Model completeness results for expansions of the ordered
ﬁeld of real numbers by restricted Pfaﬃan functions and the exponential
function, Journal Amer. Math. Soc. 9 (1996), 1051–1094.
[WP]
A. Wilkie, J. Paris, On the scheme of induction for bounded arith-
metic formulas, Ann. Pure Appl. Logic 35 (1987), 261–302.
[Zi]
M. Ziegler, Model theory of modules, Ann. Pure Appl. Logic 26 (1984),
149–213.

Index of Terms and Names
A
a.c. (algebraically closed), 48
∀-formula, ∀-sentence, 68
∀-theory, 83
∀∃-sentence, ∀∃-theory, 190
abelian group, 47
divisible, torsion-free, 104
absorption laws, 48
Ackermann function, 226
Ackermann interpretation, 261
algebra, 42
algebraic, 48
almost all, 60, 210
alphabet, xx, 54
antisymmetric, 45
arithmetical, 238
arithmetical hierarchy, 264
arithmetization (of syntax), 226
associative, xxi
automated theorem proving, 120
automorphism, 50
axiom
of choice, 115
of continuity, 108
of extensionality, 113
of foundation, 115
of inﬁnity, 115
of power set, 114
of replacement, 114
of union, 113
axiom system
logical, 36, 121
of a theory, 82
axiomatizable, 104
ﬁnitely, recursively, 104
B
β-function, 244
basis theorem
for formulas, 206
for sentences, 180
Behmann, 125
Birkhoﬀrules, 127
Boolean algebra, 49
atomless, 202
of sets, 49
Boolean basis
for L in T, 206
for L0 in T, 180
Boolean combination, 57
Boolean function, 2
dual, self-dual, 15
linear, 10
monotonic, 16
Boolean matrix, 49
Boolean signature, 5
bounded, 46
Brouwer, xvii
307

308
Index of Terms and Names
C
Cantor, 111
cardinal number, 173
cardinality, 173
of a structure, 174
chain, 46
of structures, 190
elementary, 191
of theories, 103
characteristic, 48
Chinese remainder theorem, 244
Church, xviii, 117
Church’s thesis, 220
clause, 144, 151
deﬁnite, 144
positive, negative, 144
closed under MP, 37
closure
deductive, 20
of a formula, 64
of a model in T, 197
closure axioms, 258
coﬁnite, 34
Cohen, xviii
coincidence theorem, 66
collision of variables, 70
collision-free, 70
commutative, xxi
compactness theorem
ﬁrst-order, 105
propositional, 29
compatible, 82, 254
complementation, xix
completeness theorem
Birkhoﬀ’s, 128
ﬁrst-order (Gödel’s), 102
for |∼, 123
for G, 286
for ⊢
g, 124
propositional, 29
Solovay’s, 288
completion, 120
inductive, 194
composition, xx, 217
computable, 217
concatenation, xx
arithmetical, 224
congruence, 12, 51
in L, 74
congruence class, 51
conjunction, 2
connective, 3
connex, 45
consequence relation, 20, 21
ﬁnitary, 20
local, global, 80
predicate logical, 64
propositional, 18
consistency extension, 284
consistent, 20, 26, 82, 96, 158
constant, xxi
constant expansion, 97
constant quantiﬁcation, 98
continuity schema, 110
continuum hypothesis, 174
contradiction, 17
contraposition, 21
converse implication, 4
coprime, 239
course-of-values recursion, 224
cut, 46
cut rule, 24

Index of Terms and Names
309
D
Δ-elementary class, 180
δ-function, 219
Δ0-formula, 238
Δ0-induction, 265
Davis, 256
decidable, 104, 218
deduction theorem, 21, 38
deductively closed, 20, 82
deﬁnable
Δ0-deﬁnable, 273
explicitly, 67, 87
implicitly, 88
in a structure, 67
in a theory, 272
Σ1-deﬁnable, 273
with parameters, 108
DeJongh, 290
derivability conditions, 270
derivable, 22, 23, 36, 92
derivation, 23
diagram, 170
elementary, 172
universal, 192
direct power, 52
disjunction, 3
exclusive, 3
distributive laws, 49
divisibility, 239
domain, xix, 42
E
∃-formula, 68
simple, 203
Ehrenfeucht game, 183
elementary class, 180
elementary equivalent, 69
elementary type, 180
embedding, 50
elementary, 176
end extension, 107
enumerable
eﬀectively, 117
recursively, 225
equation, 57
Diophantine, 238, 255
equipotent, 111
equivalence, 3
equivalence class, 45
equivalence relation, 45
equivalent, 11, 64
in (or modulo) T, 83
in a structure, 74
logically or semantically, 11, 64
Euclid’s lemma, 244
existentially closed, 191, 200
expansion, 45, 78, 87
explicit deﬁnition, 85, 86
extension, 44, 78, 81
conservative, 66, 85
deﬁnitorial, 87
elementary, 171
ﬁnite, 82
immediate, 197
of a language, 78
of a theory, 81
transcendental, 179
F
f-closed, 44
factor structure, 51
falsum, 5
family (of sets), xix
Fermat’s conjecture, 257

310
Index of Terms and Names
Fibonacci sequence, 224
ﬁctional argument, 10
ﬁeld, 47
algebraically closed, 48
of algebraic numbers, 173
of characteristic 0 or p, 48
ordered, 48
real closed, 197
ﬁlter, 34
ﬁnitary, 20
ﬁnite model property, 125
ﬁnitely generated, 45
ﬁniteness theorem, 26, 29, 94, 103
ﬁxed point lemma, 250
formula, 56
arithmetical, 238, 272
Boolean, 5
closed, 59
deﬁning, 85
dual, 15
ﬁrst-order, 56
open (quantiﬁer-free), 57
prenex, 77
representing, 9, 237
universal, 68
formula algebra, 42
formula induction, 6, 58
formula recursion, 8, 58
four-color theorem, 32
Frege, 76
Frege’s formula, 18
function, xix
bijective, xix
characteristic, 218
identical, xix
injective, surjective, xix
partial, 178
primitive recursive, 218
recursive (= μ-recursive), 218
function term, 55
functional complete, 14
G
gap, 46
generalization, 79
anterior, posterior, 79
generalized of a formula, 64
generally valid, 64
Gentzen calculus, 22
goal clause, 158
Gödel, xvii, 91, 243, 290
Gödel number, 223
of a proof, 229
of a string, 227
Gödel term, 246
Gödelizable, 228
Goldbach’s conjecture, 256
graph, 46
k-colorable, 31
of an operation, xxi
planar, simple, 31
ground instance, 138, 158
ground (or constant) term, 55
group, groupoid, 47
ordered, 47
H
H-resolution, 149
Harrington, 282
Henkin set, 99
Herbrand model, 103, 138
minimal, 142
Herbrand universe, 138

Index of Terms and Names
311
Hilbert, xvii
Hilbert calculus, 35, 121
Hilbert’s program, xvii, 216
homomorphism, 50
canonical, 51
strong, 50
homomorphism theorem, 51
Horn clause, 149
Horn formula, 140
basic, 140
positive, negative, 140
universal, 140
Horn sentence, 140
Horn theory, 141
universal, nontrivial, 141
hyperexponentiation, 239
I
ι-term, 87
I-tuple, xx
idempotent, xxi
identity, 127
identity-free (==== -free), 102
immediate predecessor, 46
immediate successor, 46
implication, 4
incompleteness theorem
ﬁrst, 251
second, 280
inconsistent, 26, 96
independent (of T), 83
individual variable, 53
induction
on ϕ, 8, 58
on t, 55
<-induction, 110
induction axiom, 108
induction hypothesis, 106
induction schema, 106
induction step, 106
inﬁmum, 48
inﬁnitesimal, 109
instance, 137, 158
integral domain, 48
(relatively) interpretable, 258
interpretation, 62
intersection, xix
invariance theorem, 69
invertible, xxi
irreﬂexive, 45
isomorphism, 50
partial, 178
J
Jeroslow, 290
jump, 46
K
kernel, 51
kernel (of a prenex formula), 77
Kleene, 218, 264
König’s lemma, 32
Kreisel, 257, 290
Kripke frame, 285
for G, 285
Kripke semantics, 285
L
L-formula, 57
L-model, 62
L-structure (= L-structure), 43
language
arithmetizable, 228
ﬁrst-order (or elementary), 54
of equations, 127

312
Index of Terms and Names
second-order, 130
lattice, 48
distributive, 49
of sets, 49
legitimate, 86
Lindenbaum, 27
Lindström’s criterion, 201
literal, 13, 57
Löb, 290
Löb’s formula, 285
logic program, 157
logical matrix, 49
logically valid, 17, 64
M
μ-operation, 218
bounded, 221
mapping (see function), xix
Matiyasevich, 255
ϕ-maximal, 40
maximal element, 46
maximally consistent, 20, 26, 30, 96
metainduction, xvi, 236
metatheory, xvi
model
free, 142
minimal, 150
of a theory, 81
predicate logical, 62
propositional, 8
transitive, 296
model companion, 202
model compatible, 193
model complete, 194
model completion, 200
model interpretable, 261
modus ponens, 19, 35
monotonicity rule, 22
Mostowski, 216, 243, 291
N
n-tuple, xx
negation, 2
neighbor, 31
nonrepresentability lemma, 251
nonstandard analysis, 109
nonstandard model, 107
nonstandard number, 107
normal form
canonical, 14
disjunctive, conjunctive, 13
prenex, 77
Skolem, 88
O
ω-consistent, 251
ω-incomplete, 253
ω-rule, 291
ω-term, 115
object language, xv
operation, xx
essentially n-ary, 10
order, 46
continuous, 46
dense, 46, 177
discrete, 183
linear, partial, 46
ordered pair, 114
ordinal rank, 296
P
p.r. (primitive recursive), 218
Π1-formula, 238
pair set, 114
pairing function, 222

Index of Terms and Names
313
parameter deﬁnable, 108
parenthesis economy, 6, 57
Paris, 282
partial order, 46
irreﬂexive, reﬂexive, 46
particularization, 79
anterior, posterior, 79
Peano arithmetic, 106
Peirce’s formula, 18
persistent, 189
Polish (preﬁx) notation, 7
(monic) polynomial, 105
poset, 46
power set, xix
predecessor function, 134
predicate, xx
arithmetical, 238
Diophantine, 238
primitive recursive, 218
recursive, 218
recursively enumerable, 225
preference order, 296
preﬁx, 57
premise, 22
Presburger, 204
prime ﬁeld, 48
prime formula, 4, 57
prime model, 171
elementary, 171
prime term, 55
primitive recursion, 218
principle of bivalence, 2
principle of extensionality, 2
product
direct, 52
reduced, 210
programming language, 132
projection, 52
projection function, 218
PROLOG, 157
(formal) proof, 36, 122
propositional variable, 4
modalized, 289
provability logic, 285
for T, 288
provable, 22, 23, 36
provably recursive, 273
Putnam, 256
Q
quantiﬁcation, 56
bounded, 221, 238
quantiﬁer, 41
quantiﬁer compression, 243
quantiﬁer elimination, 202
quantiﬁer rank, 58
quasi-identity, quasi-variety, 128
query, 157
quotient ﬁeld, 188
R
r.e. (recursively enumerable), 225
Rabin, 258
range, xix
rank (of a formula), 8, 58
recursion equations, 218
recursive deﬁnition, 8
reduced formula, 85, 86
reduct, 45, 78
reduct theory, 84
reductio ad absurdum, 23
reﬂection principle, 283, 294
reﬂexive, 45

314
Index of Terms and Names
refutable, 83
relation, xix
relativised of a formula, 258
renaming, 76, 153
bound, free, 76
replacement theorem, 12, 74
representability
of Boolean functions, 9
of functions, 241
of predicates, 237
representability theorem, 246
(successful) resolution, 146
resolution calculus, 145
resolution closure, 145
resolution rule, 145
resolution theorem, 148, 151, 167
resolution tree, 146
resolvent, 145
restriction, 44
ring, 47
commutative, 48
ordered, 48
Abraham Robinson, 109
Julia Robinson, 256
Robinson’s arithmetic, 234
Rogers, 290
rule, 22, 23, 92
basic, 22, 92
derivable (provable), 23
Gentzen-style, 25
Hilbert-style, 121
of Horn resolution, 149
sound, 25, 93
rule induction, 25, 94
Russell, xvii
Russell’s antinomy, 73
S
S-invariant, 186
Σ1-completeness, 239
provable, 278
Σ1-formula, 238
special, 267
Sambin, 290
satisﬁability relation, 17, 62
satisﬁable, 17, 64, 82, 144
satisﬁably equivalent, 88
scope (of a preﬁx), 58
segment, xx
initial, xx, 46
terminal, xx
semigroup, 47
free, 47
ordered, 47
regular, 47
semilattice, 48
semiring, 48
ordered, 48
sentence, 59
separator, 156
sequence, xx
sequent, 22
initial, 22
set
countable, uncountable, 111
densely ordered, 46
discretely ordered, 183
ﬁnite, 111
ordered, 46
transitive, 296
well-ordered, 46
Sheﬀer function, 3
signature

Index of Terms and Names
315
algebraic, 57
extralogical, 43
logical, 4
signum function, 220
singleton, 152
Skolem, xvii
Skolem function, 88
Skolem’s paradox, 116
Skolemization, 90
SLD-resolution, 162
solution, 158
soundness, 26, 94
SP-invariant, 188
Stone’s representation theorem, 49
string, xx
atomic, xx
structure, 42
algebraic, relational, 42
subformula, 7, 58
substitution, 59
global, 60
identical, 60
propositional, 19
simple, 59
simultaneous, 59
substitution function, 248
substitution invariance, 127
substitution theorem, 71
substring, xx
substructure, 44
(ﬁnitely) generated, 45
elementary, 171
substructure complete, 207
subterm, 56
subtheory, 81
successor function, 105
supremum, 49
symbol, xx
extralogical, logical, 54
of T, 81
symmetric, 45
system (of sets), xix
T
T-model, 82
Tarski, 20, 169, 216
Tarski fragment, 260
Tarski–Lindenbaum algebra, 84
tautologically equivalent, 78
tautology, 17, 64
term, 55
term algebra, 55, 136
term equivalent, 15
term function, 67
term induction, 55
term model, 100, 136
tertium non datur, 17
theorem
Artin’s, 197
Cantor’s, 111
Cantor–Bernstein, 174
Dzhaparidze’s, 293
Goodstein’s, 282
Goryachev’s, 295
Herbrand’s, 139
Lagrange’s, 255
Lindenbaum’s, 27
Lindström’s, 129
Löb’s, 282
Łoś’s, 211
Löwenheim–Skolem, 112, 175
Morley’s, 179
Rosser’s, 252

316
Index of Terms and Names
Shelah’s, 211
Steinitz’s, 197
Trachtenbrot’s, 125
Visser’s, 289
theory, 81
(ﬁnitely) axiomatizable, 104
arithmetizable, 250
complete, 105
consistent (satisﬁable), 82
countable, 111
decidable, 119, 228
elementary or ﬁrst-order, 81
equational, 127
essentially undecidable, 257
hereditarily undecidable, 254
inconsistent, 82
inductive, 191
κ-categorical, 176
quasi-equational, 128
strongly undecidable, 254
undecidable, 119
universal, 83
transcendental, 48
transitive, 45
(directed) tree, 32
true, 253
truth function, 2
truth functor, 3
truth table, 2
truth value, 2
Turing machine, 220
U
U-resolution, 162
U-resolvent, 161
UH -resolution, 162
ultraﬁlter, 34
nontrivial, 34
ultraﬁlter theorem, 35
ultrapower, 211
ultraproduct, 211
undecidable, 104, 119
uniﬁable, 152
uniﬁcation algorithm, 153
uniﬁer, 152
generic, 153
union, xix
unique formula reconstruction, 7, 58
unique term concatenation, 55
unique term reconstruction, 55
unit element, 47
universal closure, 64
universal part, 187
universe, 114
urelement, 112
V
valuation, 8, 62, 285
value matrix, 2
variable, 54
free, bound, 58
variety, 127
Vaught, 179
verum, 5
W
w.l.o.g., xxi
word (over A), xx
word semigroup, 47
Z
Z-group, 205
zero-divisor, 48
Zorn’s lemma, 46

Index of Symbols
N, Z, Q, R
xix
N+, Q+, R+
xix
∪, ∩, \
xix
⊆, ⊂
xix
∅, PM
xix
 S,  S
xix
M × N
xix
f(a), fa, af
xix
f : M →N
xix
x 
→t(x)
xix
dom f, ran f
xix
idM
xix
MI
xx
(ai)i∈I
xx
(a1, . . . , an)
xx
⃗a, f⃗a
xx
P⃗a, ¬P⃗a
xx
graph f
xxi
⇔, ⇒, &,∨∨∨
xxi
:=, :⇔
xxi
Bn
2
∧, ∨, ¬
3
F, PV
4
→, ↔, ⊤, ⊥
5
PN, RPN
7
Sf α
7
wϕ
8
Fn, α(n)
9
α ≡β
11
DNF, CNF
13
w ⊨α, ⊨α
17
X ⊨α, X ⊨Y
18
⊢
20
C+, C−
27
MP
35
|∼
36
rA, fA, cA
43
A ⊆B
44
TF , TR
47
charp
48
2
49
A ≃B
50
lh(ξ)
50
a/≈, A/≈
51

i∈I Ai
52
AI
52
Var
54
∀, ====
54
SL
54
T (= TL)
55
var ξ, var t
56
∃,
∨
56
̸====
56
L
57
L◦, L∈
57
L=
=
=
=
57
TL
57
rk ϕ, qr ϕ
58
bnd ϕ
58
free ϕ
58
L0, Lk, Vark
59
ϕ(x1, . . . , xn)
59
ϕ(⃗x), t(⃗x)
59
⃗t , f⃗t , r⃗t
59
ϕ t
x, ϕx(t)
59
ϕ⃗t
⃗x, ϕ⃗x(⃗t )
59
ι (iota)
60
M = (A, w)
62
rM, f M, cM
62
tA,w, tM
62
⃗t M, tA
62
M ⊨ϕ
62
A ⊨ϕ[w]
62
Ma
x, M⃗a
⃗x
62
⊨ϕ
64
α ≡β
64
A ⊨ϕ, A ⊨X
64
X ⊨ϕ
64
ϕg, X g
64
TG, T =
=
=
=
G
65
tA(⃗a), tA
67
317

318
Index of Symbols
(A,⃗a) ⊨ϕ
67
A ⊨ϕ [⃗a]
67
ϕA
67
∃n, ∃=n
68
⊤, ⊥
69
A ≡B
69
Mσ
71
∃!
72
≡A, ≡K
75
Q (∀or ∃)
76
PNF
77
(∀x◁t),(∃x◁t)
77
(divides)
80
X ⊨
g ϕ
80
T, Md T
82
Taut
82
T + α, T + S
82
≡T , ≈T
83
Th A, Th K
84
K ⊨α
84
L[r], ϕrd
85
SNF
88
⊢
92
mon, ﬁn
94
Lc, LC, α zc
97
⊢T α
102
X ⊢T α
102
ACF, ACFp
105
N, S
105
Lar
105
⩽, <
105
PA
106
IS
106
n (= Sn0)
107
IA
108
M ∼N
111
ZFC, ZF
112
AE, AS, AU
113
{z ∈x | ϕ}
113
AP, AR
114
{a, b}, {c}
114
(a, b)
114
AI, AF, AC
115
ω
115
Vα, Vω
115
|∼
121
Λ, Λ1–Λ10
122
MQ
122
Tautﬁn
125
Γ ⊢
B γ
127
LII
130
∼O, L∼O
131
Pd
134
F, FX, FT
136
Tk
137
Fk, FkX
137
GI(X)
138
CU, CT
142
144
K ⊨H
145
λ; ¯λ, ¯K
145
RR, ⊢
RR
145
Rc
145
HR, ⊢
HR
149
P, N
149
HR(P, N)
149
VP, wP, ρP
150
Kσ
152
P, :−
157
GI(K)
158
sum
159
UR, ⊢
UR
161
UHR, ⊢
UHR
161
UωR, UωHR
161
AA, BA
170
DA
170
A ≼B
171
Del A
172
|M|
173
ℵ0, ℵ1, 2ℵ0
174
CH
174
DO
177
L, R
177
DO00, . . .
178
⟨X⟩, ≡X
180
SO, SO00, . . .
183
Γk(A, B)
183
A ∼k B
184
A ≡k B
184
T ∀
187
TJ
188
A ⊆ec B
191
D∀A
192

Index of Symbols
319
RCF
197
ZGE, ZG
204
≈F
209
a/F, w/F
210
F
i∈I Ai
210
Iw
α
211
Fn, F
217
h[g1, . . . , gm]
217
P[g1, . . . , gm]
217
Oc, Op, Oμ
218
f = Op(g, h)
218
In
ν
218
χP
218
Kn
c , ·−, δ
219
σ, max
220
prim, pn
220
rem(a, d)
220
bia
220
μk[P(⃗a, k)]
221
μk⩽m[P(⃗a, k)] 222
℘(a, b), tn
222
⟨a1, . . . , an⟩
223
GN, ℓ
223
(((a)))k, (((a)))last
224
∗, ¯f, Oq
224
lcm{fν| ν⩽n}
226
♯s
227
˙ξ, ˙ϕ, ˙t
227
V
228
˙s, ˙W
228
˜¬, ˜∧,
˜
→
229
bewT, bwbT
229
˜====, ˜∀
230
˜S, ˜+, ˜·
230
Tprim, Lprim
231
[m]k
i
232
Q
234
N
235
Δ0, Σ1, Π1
238
Δ1
238
⊥(coprime)
239
IΔ0
239
β, beta
244
⌜ϕ⌝, ⌜t⌝, ⌜Φ⌝
246
bewT, bwbT
246
cf, ˙n
248
sbx, sb⃗x
248
˙ϕ⃗x(⃗a)
249
prov
252
αP, XP
258
T Δ, BΔ
258
CA
258
TF
260
ZFCﬁn (FST)
261
Sﬁn, Sfnd
261
Σn, Πn, Δn
264
□(x)
270
□α, 3α
270
ConT
270
D0–D3
271
∂, d0, . . .
271
D1∗, D2∗
271
□[ϕ]
277
PA
⊥
281
D4, D4◦
281
T n, T ω
284
□nα
284
F□
284
3, □n
285
MN
285
G, ⊢G
285
P ⊩H
285
⊨G H
285
G ≡G H
285
Gn
288
GS
289
1bwbPA
292
□
1 , 3
1
292
GD
293
Rf T
294
ρa
296
Gi
296
Gj
298

