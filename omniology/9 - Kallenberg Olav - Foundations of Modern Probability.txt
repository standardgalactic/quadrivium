Foundations of
Modern Probability
Olav Kallenberg
Springer





Preface
Some thirty years ago it was still possible, as Lo`eve so ably demonstrated,
to write a single book in probability theory containing practically everything
worth knowing in the subject. The subsequent development has been ex-
plosive, and today a corresponding comprehensive coverage would require a
whole library. Researchers and graduate students alike seem compelled to a
rather extreme degree of specialization. As a result, the subject is threatened
by disintegration into dozens or hundreds of subﬁelds.
At the same time the interaction between the areas is livelier than ever,
and there is a steadily growing core of key results and techniques that every
probabilist needs to know, if only to read the literature in his or her own
ﬁeld. Thus, it seems essential that we all have at least a general overview of
the whole area, and we should do what we can to keep the subject together.
The present volume is an earnest attempt in that direction.
My original aim was to write a book about “everything.” Various space
and time constraints forced me to accept more modest and realistic goals
for the project. Thus, “foundations” had to be understood in the narrower
sense of the early 1970s, and there was no room for some of the more recent
developments. I especially regret the omission of topics such as large de-
viations, Gibbs and Palm measures, interacting particle systems, stochastic
diﬀerential geometry, Malliavin calculus, SPDEs, measure-valued diﬀusions,
and branching and superprocesses. Clearly plenty of fundamental and in-
triguing material remains for a possible second volume.
Even with my more limited, revised ambitions, I had to be extremely
selective in the choice of material. More importantly, it was necessary to look
for the most economical approach to every result I did decide to include. In
the latter respect, I was surprised to see how much could actually be done
to simplify and streamline proofs, often handed down through generations of
textbook writers. My general preference has been for results conveying some
new idea or relationship, whereas many propositions of a more technical
nature have been omitted. In the same vein, I have avoided technical or
computational proofs that give little insight into the proven results. This
conforms with my conviction that the logical structure is what matters most
in mathematics, even when applications is the ultimate goal.
Though the book is primarily intended as a general reference, it should
also be useful for graduate and seminar courses on diﬀerent levels, ranging
from elementary to advanced. Thus, a ﬁrst-year graduate course in measure-
theoretic probability could be based on the ﬁrst ten or so chapters, while
the rest of the book will readily provide material for more advanced courses
on various topics. Though the treatment is formally self-contained, as far
as measure theory and probability are concerned, the text is intended for
a rather sophisticated reader with at least some rudimentary knowledge of
subjects like topology, functional analysis, and complex variables.

vi
Preface
My exposition is based on experiences from the numerous graduate and
seminar courses I have been privileged to teach in Sweden and in the United
States, ever since I was a graduate student myself. Over the years I have
developed a personal approach to almost every topic, and even experts might
ﬁnd something of interest. Thus, many proofs may be new, and every chapter
contains results that are not available in the standard textbook literature. It
is my sincere hope that the book will convey some of the excitement I still
feel for the subject, which is without a doubt (even apart from its utter use-
fulness) one of the richest and most beautiful areas of modern mathematics.
Notes and Acknowledgments: My ﬁrst thanks are due to my numerous
Swedish teachers, and especially to Peter Jagers, whose 1971 seminar opened
my eyes to modern probability. The idea of this book was raised a few years
later when the analysts at Gothenburg asked me to give a short lecture course
on “probability for mathematicians.” Although I objected to the title, the
lectures were promptly delivered, and I became convinced of the project’s fea-
sibility. For many years afterward I had a faithful and enthusiastic audience
in numerous courses on stochastic calculus, SDEs, and Markov processes. I
am grateful for that learning opportunity and for the feedback and encour-
agement I received from colleagues and graduate students.
Inevitably I have beneﬁted immensely from the heritage of countless au-
thors, many of whom are not even listed in the bibliography. I have further
been fortunate to know many prominent probabilists of our time, who have
often inspired me through their scholarship and personal example. Two peo-
ple, Klaus Matthes and Gopi Kallianpur, stand out as particularly important
inﬂuences in connection with my numerous visits to Berlin and Chapel Hill,
respectively.
The great Kai Lai Chung, my mentor and friend from recent years, oﬀered
penetrating comments on all aspects of the work: linguistic, historical, and
mathematical. My colleague Ming Liao, always a stimulating partner for
discussions, was kind enough to check my material on potential theory. Early
versions of the manuscript were tested on several groups of graduate students,
and Kamesh Casukhela, Davorin Dujmovic, and Hussain Talibi in particular
were helpful in spotting misprints. Ulrich Albrecht and Ed Slaminka oﬀered
generous help with software problems. I am further grateful to John Kimmel,
Karina Mikhli, and the Springer production team for their patience with my
last-minute revisions and their truly professional handling of the project.
My greatest thanks go to my family, who is my constant source of happi-
ness and inspiration. Without their love, encouragement, and understanding,
this work would not have been possible.
Olav Kallenberg
May 1997

Contents
1. Elements of Measure Theory
1
σ-ﬁelds and monotone classes
measurable functions
measures and integration
monotone and dominated convergence
transformation of integrals
product measures and Fubini’s theorem
Lp-spaces and projection
measure spaces and kernels
2. Processes, Distributions, and Independence
22
random elements and processes
distributions and expectation
independence
zero–one laws
Borel–Cantelli lemma
Bernoulli sequences and existence
moments and continuity of paths
3. Random Sequences, Series, and Averages
39
convergence in probability and in Lp
uniform integrability and tightness
convergence in distribution
convergence of random series
strong laws of large numbers
Portmanteau theorem
continuous mapping and approximation
coupling and measurability
4. Characteristic Functions and Classical Limit Theorems
60
uniqueness and continuity theorem
Poisson convergence
positive and symmetric terms
Lindeberg’s condition
general Gaussian convergence
weak laws of large numbers
domain of Gaussian attraction
vague and weak compactness
5. Conditioning and Disintegration
80
conditional expectations and probabilities
regular conditional distributions
vii

viii
Foundations of Modern Probability
disintegration theorem
conditional independence
transfer and coupling
Daniell–Kolmogorov theorem
extension by conditioning
6. Martingales and Optional Times
96
ﬁltrations and optional times
random time-change
martingale property
optional stopping and sampling
maximum and upcrossing inequalities
martingale convergence, regularity, and closure
limits of conditional expectations
regularization of submartingales
7. Markov Processes and Discrete-Time Chains
117
Markov property and transition kernels
ﬁnite-dimensional distributions and existence
space homogeneity and independence of increments
strong Markov property and excursions
invariant distributions and stationarity
recurrence and transience
ergodic behavior of irreducible chains
mean recurrence times
8. Random Walks and Renewal Theory
136
recurrence and transience
dependence on dimension
general recurrence criteria
symmetry and duality
Wiener–Hopf factorization
ladder time and height distribution
stationary renewal process
renewal theorem
9. Stationary Processes and Ergodic Theory
156
stationarity, invariance, and ergodicity
mean and a.s. ergodic theorem
continuous time and higher dimensions
ergodic decomposition
subadditive ergodic theorem
products of random matrices
exchangeable sequences and processes
predictable sampling

Contents
ix
10. Poisson and Pure Jump-Type Markov Processes
176
existence and characterizations of Poisson processes
Cox processes, randomization and thinning
one-dimensional uniqueness criteria
Markov transition and rate kernels
embedded Markov chains and explosion
compound and pseudo-Poisson processes
Kolmogorov’s backward equation
ergodic behavior of irreducible chains
11. Gaussian Processes and Brownian Motion
199
symmetries of Gaussian distribution
existence and path properties of Brownian motion
strong Markov and reﬂection properties
arcsine and uniform laws
law of the iterated logarithm
Wiener integrals and isonormal Gaussian processes
multiple Wiener–Itˆo integrals
chaos expansion of Brownian functionals
12. Skorohod Embedding and Invariance Principles
220
embedding of random variables
approximation of random walks
functional central limit theorem
law of the iterated logarithm
arcsine laws
approximation of renewal processes
empirical distribution functions
embedding and approximation of martingales
13. Independent Increments and Inﬁnite Divisibility
234
regularity and jump structure
L´evy representation
independent increments and inﬁnite divisibility
stable processes
characteristics and convergence criteria
approximation of L´evy processes and random walks
limit theorems for null arrays
convergence of extremes
14. Convergence of Random Processes, Measures, and Sets
255
relative compactness and tightness
uniform topology on C(K, S)
Skorohod’s J1-topology

x
Foundations of Modern Probability
equicontinuity and tightness
convergence of random measures
superposition and thinning
exchangeable sequences and processes
simple point processes and random closed sets
15. Stochastic Integrals and Quadratic Variation
275
continuous local martingales and semimartingales
quadratic variation and covariation
existence and basic properties of the integral
integration by parts and Itˆo’s formula
Fisk–Stratonovich integral
approximation and uniqueness
random time-change
dependence on parameter
16. Continuous Martingales and Brownian Motion
296
martingale characterization of Brownian motion
random time-change of martingales
isotropic local martingales
integral representations of martingales
iterated and multiple integrals
change of measure and Girsanov’s theorem
Cameron–Martin theorem
Wald’s identity and Novikov’s condition
17. Feller Processes and Semigroups
313
semigroups, resolvents, and generators
closure and core
Hille–Yosida theorem
existence and regularization
strong Markov property
characteristic operator
diﬀusions and elliptic operators
convergence and approximation
18. Stochastic Diﬀerential Equations and Martingale Problems
335
linear equations and Ornstein–Uhlenbeck processes
strong existence, uniqueness, and nonexplosion criteria
weak solutions and local martingale problems
well-posedness and measurability
pathwise uniqueness and functional solution
weak existence and continuity

Contents
xi
transformations of SDEs
strong Markov and Feller properties
19. Local Time, Excursions, and Additive Functionals
350
Tanaka’s formula and semimartingale local time
occupation density, continuity and approximation
regenerative sets and processes
excursion local time and Poisson process
Ray–Knight theorem
excessive functions and additive functionals
local time at regular point
additive functionals of Brownian motion
20. One-Dimensional SDEs and Diﬀusions
371
weak existence and uniqueness
pathwise uniqueness and comparison
scale function and speed measure
time-change representation
boundary classiﬁcation
entrance boundaries and Feller properties
ratio ergodic theorem
recurrence and ergodicity
21. PDE-Connections and Potential Theory
390
backward equation and Feynman–Kac formula
uniqueness for SDEs from existence for PDEs
harmonic functions and Dirichlet’s problem
Green functions as occupation densities
sweeping and equilibrium problems
dependence on conductor and domain
time reversal
capacities and random sets
22. Predictability, Compensation, and Excessive Functions
409
accessible and predictable times
natural and predictable processes
Doob–Meyer decomposition
quasi–left-continuity
compensation of random measures
excessive and superharmonic functions
additive functionals as compensators
Riesz decomposition

xii
Foundations of Modern Probability
23. Semimartingales and General Stochastic Integration
433
predictable covariation and L2-integral
semimartingale integral and covariation
general substitution rule
Dol´eans’ exponential and change of measure
norm and exponential inequalities
martingale integral
decomposition of semimartingales
quasi-martingales and stochastic integrators
Appendices
455
A1. Hard Results in Measure Theory
A2. Some Special Spaces
Historical and Bibliographical Notes
464
Bibliography
486
Indices
509
Authors
Terms and Topics
Symbols

Chapter 1
Elements of Measure Theory
σ-ﬁelds and monotone classes; measurable functions; measures
and integration; monotone and dominated convergence; transfor-
mation of integrals; product measures and Fubini’s theorem; Lp-
spaces and projection; measure spaces and kernels
Modern probability theory is technically a branch of measure theory, and any
systematic exposition of the subject must begin with some basic measure-
theoretic facts.
In this chapter we have collected some elementary ideas
and results from measure theory that will be needed throughout this book.
Though most of the quoted propositions may be found in any textbook in
real analysis, our emphasis is often somewhat diﬀerent and has been chosen
to suit our special needs. Many readers may prefer to omit this chapter on
their ﬁrst encounter and return for reference when the need arises.
To ﬁx our notation, we begin with some elementary notions from set the-
ory. For subsets A, Ak, B, . . . of some abstract space Ω, recall the deﬁnitions
of union A ∪B or 
k Ak, intersection A ∩B or

k Ak, complement Ac, and
diﬀerence A \ B = A ∩Bc. The latter is said to be proper if A ⊃B. The
symmetric diﬀerence of A and B is given by A∆B = (A \ B) ∪(B \ A).
Among basic set relations, we note in particular the distributive laws
A ∩

kBk =

k(A ∩Bk),
A ∪

kBk =

k(A ∪Bk),
and de Morgan’s laws

kAk
c =

kAc
k,

kAk
c =

kAc
k,
valid for arbitrary (not necessarily countable) unions and intersections. The
latter formulas allow us to convert any relation involving unions (intersec-
tions) into the dual formula for intersections (unions).
A σ-algebra or σ-ﬁeld in Ωis deﬁned as a nonempty collection A of subsets
of Ωsuch that A is closed under countable unions and intersections as well
as under complementation. Thus, if A, A1, A2, . . . ∈A, then also Ac,

k Ak,
and 
k Ak lie in A. In particular, the whole space Ωand the empty set ∅
belong to every σ-ﬁeld. In any space Ωthere is a smallest σ-ﬁeld {∅, Ω} and a
largest one 2Ω, the class of all subsets of Ω. Note that any σ-ﬁeld A is closed
under monotone limits. Thus, if A1, A2, . . . ∈A with An ↑A or An ↓A, then
also A ∈A. A measurable space is a pair (Ω, A), where Ωis a space and A
is a σ-ﬁeld in Ω.
1

2
Foundations of Modern Probability
For any class of σ-ﬁelds in Ω, the intersection (but usually not the union)
is again a σ-ﬁeld. If C is an arbitrary class of subsets of Ω, there is a smallest
σ-ﬁeld in Ωcontaining C, denoted by σ(C) and called the σ-ﬁeld generated
or induced by C. Note that σ(C) can be obtained as the intersection of all
σ-ﬁelds in Ωthat contain C. A metric or topological space S will always be
endowed with its Borel σ-ﬁeld B(S) generated by the topology (class of open
subsets) in S unless a σ-ﬁeld is otherwise speciﬁed. The elements of B(S)
are called Borel sets. In the case of the real line R, we shall often write B
instead of B(R).
More primitive classes than σ-ﬁelds often arise in applications. A class
C of subsets of some space Ωis called a π-system if it is closed under ﬁnite
intersections, so that A, B ∈C implies A ∩B ∈C. Furthermore, a class
D is a λ-system if it contains Ωand is closed under proper diﬀerences and
increasing limits. Thus, we require that Ω∈D, that A, B ∈D with A ⊃B
implies A \ B ∈D, and that A1, A2, . . . ∈D with An ↑A implies A ∈D.
The following monotone class theorem is often useful to extend an estab-
lished property or relation from a class C to the generated σ-ﬁeld σ(C). An
application of this result is referred to as a monotone class argument.
Theorem 1.1 (monotone class theorem, Sierpi´nski) Let C be a π-system
and D a λ-system in some space Ωsuch that C ⊂D. Then σ(C) ⊂D.
Proof: We may clearly assume that D = λ(C), the smallest λ-system
containing C. It suﬃces to show that D is a π-system, since it is then a σ-
ﬁeld containing C and therefore must contain the smallest σ-ﬁeld σ(C) with
this property. Thus, we need to show that A ∩B ∈D whenever A, B ∈D.
The relation A ∩B ∈D is certainly true when A, B ∈C, since C is a π-
system contained in D. The result may now be extended in two steps. First
we ﬁx an arbitrary set B ∈C and deﬁne AB = {A ⊂Ω; A ∩B ∈D}. Then
AB is a λ-system containing C, and so it contains the smallest λ-system D
with this property. This shows that A ∩B ∈D for any A ∈D and B ∈C.
Next ﬁx an arbitrary set A ∈D, and deﬁne BA = {B ⊂Ω; A ∩B ∈D}. As
before, we note that even BA contains D, which yields the desired property. ✷
For any family of spaces Ωt, t ∈T, we deﬁne the Cartesian product Xt∈TΩt
as the class of all collections (ωt; t ∈T), where ωt ∈Ωt for all t. When
T = {1, . . . , n} or T = N = {1, 2, . . .}, we shall often write the product space
as Ω1 ×· · ·×Ωn or Ω1 ×Ω2 ×· · ·, respectively, and if Ωt = Ωfor all t, we shall
use the notation ΩT, Ωn, or Ω∞. In case of topological spaces Ωt, we endow
XtΩt with the product topology unless a topology is otherwise speciﬁed.
Now assume that each space Ωt is equipped with a σ-ﬁeld At. In XtΩt
we may then introduce the product σ-ﬁeld

t At, generated by all one-
dimensional cylinder sets At × Xs̸=tΩs, where t ∈T and At ∈At. (Note
the analogy with the deﬁnition of product topologies.) As before, we shall
write A1 ⊗· · ·⊗An, A1 ⊗A2 ⊗· · ·, AT, An, or A∞in the appropriate special
cases.

1. Elements of Measure Theory
3
Lemma 1.2 (product and Borel σ-ﬁelds) Let S1, S2, . . . be separable metric
spaces. Then
B(S1 × S2 × · · ·) = B(S1) ⊗B(S2) ⊗· · · .
Thus, for countable products of separable metric spaces, the product and
Borel σ-ﬁelds agree. In particular, B(Rd) = (B(R))d = Bd, the σ-ﬁeld gener-
ated by all rectangular boxes I1 × · · · × Id, where I1, . . . , Id are arbitrary real
intervals.
Proof: The assertion may be written as σ(C1) = σ(C2), and it suﬃces to
show that C1 ⊂σ(C2) and C2 ⊂σ(C1). For C2 we may choose the class of
all cylinder sets Gk × Xn̸=kSn with k ∈N and Gk open in Sk. Those sets
generate the product topology in S = XnSn, and so they belong to B(S).
Conversely, we note that S = XnSn is again separable. Thus, for any
topological base C in S, the open subsets of S are countable unions of sets
in C. In particular, we may choose C to consist of all ﬁnite intersections of
cylinder sets Gk × Xn̸=kSn as above. It remains to note that the latter sets
lie in 
n B(Sn).
✷
Every point mapping f between two spaces S and T induces a set mapping
f −1 in the opposite direction, that is, from 2T to 2S, given by
f −1B = {s ∈S; f(s) ∈B},
B ⊂T.
Note that f −1 preserves the basic set operations in the sense that for any
subsets B and Bk of T,
f −1Bc = (f −1B)c,
f −1 
k
Bk =

k
f −1Bk,
f −1 
k
Bk =

k
f −1Bk.
(1)
The next result shows that f −1 also preserves σ-ﬁelds, in both directions.
For convenience we write
f −1C = {f −1B; B ∈C},
C ⊂2T.
Lemma 1.3 (induced σ-ﬁelds) Let f be a mapping between two measurable
spaces (S, S) and (T, T ). Then f −1T is a σ-ﬁeld in S, whereas {B ⊂T;
f −1B ∈S} is a σ-ﬁeld in T.
Proof: Use (1).
✷
Given two measurable spaces (S, S) and (T, T ), a mapping f : S →T
is said to be S/T -measurable or simply measurable if f −1T ⊂S, that is,
if f −1B ∈S for every B ∈T . (Note the analogy with the deﬁnition of
continuity in terms of topologies on S and T.)
By the next result, it is
enough to verify the deﬁning condition for a generating subclass.

4
Foundations of Modern Probability
Lemma 1.4 (measurable functions) Consider two measurable spaces (S, S)
and (T, T ), a class C ⊂2T with σ(C) = T , and a mapping f : S →T. Then
f is S/T -measurable iﬀf −1C ⊂S.
Proof: Use the second assertion in Lemma 1.3.
✷
Lemma 1.5 (continuity and measurability)
Any continuous mapping be-
tween two topological spaces S and T is measurable with respect to the Borel
σ-ﬁelds B(S) and B(T).
Proof: Use Lemma 1.4, with C equal to the topology in T.
✷
Here we insert a result about subspace topologies and σ-ﬁelds, which will
be needed in Chapter 14. Given a class C of subsets of S and a set A ⊂S,
we deﬁne A ∩C = {A ∩C; C ∈C}.
Lemma 1.6 (subspaces) Fix a metric space (S, ρ) with topology T and Borel
σ-ﬁeld S, and let A ⊂S. Then (A, ρ) has topology TA = A ∩T and Borel
σ-ﬁeld SA = A ∩S.
Proof: The natural embedding IA : A →S is continuous and hence
measurable, and so A∩T = I−1
A T ⊂TA and A∩S = I−1
A S ⊂SA. Conversely,
given any B ∈TA, we may deﬁne G = (B ∪Ac)◦, where the complement and
interior are with respect to S, and it is easy to verify that B = A∩G. Hence,
TA ⊂A ∩T , and therefore
SA = σ(TA) ⊂σ(A ∩T ) ⊂σ(A ∩S) = A ∩S,
where the operation σ(·) refers to the subspace A.
✷
Next we note that measurability (like continuity) is preserved by compo-
sition. The proof is immediate from the deﬁnitions.
Lemma 1.7 (composition) For any measurable spaces (S, S), (T, T ), and
(U, U), and measurable mappings f : S →T and g : T →U, the composition
g ◦f : S →U is again measurable.
To state the next result, we note that any collection of functions ft : Ω→
St, t ∈T, deﬁnes a mapping f = (ft) from Ωto XtSt given by
f(ω) = (ft(ω); t ∈T),
ω ∈Ω.
(2)
It is often useful to relate the measurability of f to that of the coordinate
mappings ft.
Lemma 1.8 (families of functions) For any measurable spaces (Ω, A) and
(St, St), t ∈T, and for arbitrary mappings ft : Ω→St, t ∈T, the function
f = (ft) : Ω→XtSt is measurable with respect to the product σ-ﬁeld

t St
iﬀft is St-measurable for every t.

1. Elements of Measure Theory
5
Proof: Use Lemma 1.4, with C equal to the class of cylinder sets At ×
Xs̸=tSt with t ∈T and At ∈St.
✷
Changing our perspective, assume the ft in (2) to be mappings into some
measurable spaces (St, St). In Ωwe may then introduce the generated or
induced σ-ﬁeld σ(f) = σ{ft; t ∈T}, deﬁned as the smallest σ-ﬁeld in Ωthat
makes all the ft measurable. In other words, σ(f) is the intersection of all
σ-ﬁelds A in Ωsuch that ft is A/St-measurable for every t ∈T. In this
notation, the functions ft are clearly measurable with respect to a σ-ﬁeld
A in Ωiﬀσ(f) ⊂A. It is further useful to note that σ(f) agrees with the
σ-ﬁeld in Ωgenerated by the collection {f −1
t St; t ∈T}.
For real-valued functions, measurability is always understood to be with
respect to the Borel σ-ﬁeld B = B(R). Thus, a function f from a measurable
space (Ω, A) into a real interval I is measurable iﬀ{ω; f(ω) ≤x} ∈A
for all x ∈I. The same convention applies to functions into the extended
real line R = [−∞, ∞] or the extended half-line R+ = [0, ∞], regarded as
compactiﬁcations of R and R+ = [0, ∞), respectively. Note that B(R) =
σ{B, ±∞} and B(R+) = σ{B(R+), ∞}.
For any set A ⊂Ω, we deﬁne the associated indicator function 1A : Ω→R
to be equal to 1 on A and to 0 on Ac. (The term characteristic function has
a diﬀerent meaning in probability theory.) For sets A = {ω; f(ω) ∈B}, it is
often convenient to write 1{·} instead of 1{·}. Assuming A to be a σ-ﬁeld in
Ω, we note that 1A is A-measurable iﬀA ∈A.
Linear combinations of indicator functions are called simple functions.
Thus, a general simple function f : Ω→R is of the form
f = c11A1 + · · · + cn1An,
where n ∈Z+ = {0, 1, . . .}, c1, . . . , cn ∈R, and A1, . . . , An ⊂Ω. Here we
may clearly take c1, . . . , cn to be the distinct nonzero values attained by f
and deﬁne Ak = f −1{ck}, k = 1, . . . , n. With this choice of representation,
we note that f is measurable with respect to a given σ-ﬁeld A in Ωiﬀ
A1, . . . , An ∈A.
We proceed to show that the class of measurable functions is closed under
the basic ﬁnite or countable operations occurring in analysis.
Lemma 1.9 (bounds and limits) Let f1, f2, . . . be measurable functions from
some measurable space (Ω, A) into R. Then supn fn, infn fn, lim supn fn, and
lim infn fn are again measurable.
Proof: To see that supn fn is measurable, write
{ω; supnfn(ω) ≤t} =

n{ω; fn(ω) ≤t} =

nf −1
n [−∞, t] ∈A,
and use Lemma 1.4. The measurability of the other three functions follows
easily if we write infn fn = −supn(−fn) and note that
lim sup
n→∞fn = inf
n sup
k≥n fk,
lim inf
n→∞fn = sup
n
inf
k≥n fk.
✷

6
Foundations of Modern Probability
From the last lemma we may easily deduce the measurability of limits
and sets of convergence.
Lemma 1.10 (convergence and limits) Let f1, f2, . . . be measurable func-
tions from a measurable space (Ω, A) into some metric space (S, ρ). Then
(i) {ω; fn(ω) converges} ∈A if S is complete;
(ii) fn →f on Ωimplies that f is measurable.
Proof: (i) Since S is complete, the convergence of fn is equivalent to the
Cauchy convergence
lim
n→∞sup
m≥n ρ(fm, fn) = 0.
Here the left-hand side is measurable by Lemmas 1.5 and 1.9.
(ii) If fn →f, we have g◦fn →g◦f for any continuous function g: S →R,
and so g◦f is measurable by Lemmas 1.5 and 1.9. Fixing any open set G ⊂S,
we may choose some continuous functions g1, g2, . . . : S →R+ with gn ↑1G
and conclude from Lemma 1.9 that 1G ◦f is measurable. Thus, f −1G ∈A
for all G, and so f is measurable by Lemma 1.4.
✷
Many results in measure theory are proved by a simple approximation,
based on the following observation.
Lemma 1.11 (approximation) For any measurable function f : (Ω, A) →
R+, there exist some simple measurable functions f1, f2, . . . : Ω→R+ with
0 ≤fn ↑f.
Proof: We may deﬁne
fn(ω) = 2−n[2nf(ω)] ∧n,
ω ∈Ω, n ∈N.
✷
To illustrate the method, we may use the last lemma to prove the mea-
surability of the basic arithmetic operations.
Lemma 1.12 (elementary operations) Fix any measurable functions f, g :
(Ω, A) →R and constants a, b ∈R. Then af + bg and fg are again measur-
able, and so is f/g when g ̸= 0 on Ω.
Proof: By Lemma 1.11 applied to f± = (±f) ∨0 and g± = (±g) ∨0, we
may approximate by simple measurable functions fn →f and gn →g. Here
afn+bgn and fngn are again simple measurable functions; since they converge
to af + bg and fg, respectively, even the latter functions are measurable by
Lemma 1.9. The same argument applies to the ratio f/g, provided we choose
gn ̸= 0.
An alternative argument is to write af + bg, fg, or f/g as a composition
ψ ◦ϕ, where ϕ = (f, g) : Ω→R2, and ψ(x, y) is deﬁned as ax + by, xy,
or x/y, repectively. The desired measurability then follows by Lemmas 1.2,

1. Elements of Measure Theory
7
1.5, and 1.8. In case of ratios, we are using the continuity of the mapping
(x, y) →x/y on R × (R \ {0}).
✷
For statements in measure theory and probability, it is often convenient
ﬁrst to give a proof for the real line and then to extend the result to more
general spaces. In this context, it is useful to identify pairs of measurable
spaces S and T that are Borel isomorphic, in the sense that there exists a
bijection f : S →T such that both f and f −1 are measurable. A space S
that is Borel isomorphic to a Borel subset of [0, 1] is called a Borel space. In
particular, any Polish space endowed with its Borel σ-ﬁeld is known to be a
Borel space (cf. Theorem A1.6). (A topological space is said to be Polish if
it admits a separable and complete metrization.)
The next result gives a useful functional representation of measurable
functions. Given any two functions f and g on the same space Ω, we say
that f is g-measurable if the induced σ-ﬁelds are related by σ(f) ⊂σ(g).
Lemma 1.13 (functional representation, Doob) Fix two measurable func-
tions f and g from a space Ωinto some measurable spaces (S, S) and (T, T ),
where the former is Borel. Then f is g-measurable iﬀthere exists some mea-
surable mapping h: T →S with f = h ◦g.
Proof: Since S is Borel, we may assume that S ∈B([0, 1]). By a suitable
modiﬁcation of h, we may further reduce to the case when S = [0, 1]. If
f = 1A with a g-measurable A ⊂Ω, then by Lemma 1.3 there exists some
set B ∈T with A = g−1B. In this case f = 1A = 1B ◦g, and we may choose
h = 1B. The result extends by linearity to any simple g-measurable function
f. In the general case, there exist by Lemma 1.11 some simple g-measurable
functions f1, f2, . . . with 0 ≤fn ↑f, and we may choose associated T -
measurable functions h1, h2, . . . : T →[0, 1] with fn = hn ◦g. Then h =
supn hn is again T -measurable by Lemma 1.9, and we note that
h ◦g = (supnhn) ◦g = supn(hn ◦g) = supnfn = f.
✷
Given any measurable space (Ω, A), a function µ: A →R+ is said to be
countably additive if
µ

k≥1Ak =

k≥1µAk,
A1, A2, . . . ∈A disjoint.
(3)
A measure on (Ω, A) is deﬁned as a function µ : A →R+ with µ∅= 0 and
satisfying (3). A triple (Ω, A, µ) as above, where µ is a measure, is called a
measure space. From (3) we note that any measure is ﬁnitely additive and
nondecreasing. This implies in turn the countable subadditivity
µ

k≥1Ak ≤

k≥1µAk,
A1, A2, . . . ∈A.
We note the following basic continuity properties.

8
Foundations of Modern Probability
Lemma 1.14 (continuity) Let µ be a measure on (Ω, A), and assume that
A1, A2, . . . ∈A. Then
(i) An ↑A implies µAn ↑µA;
(ii) An ↓A with µA1 < ∞implies µAn ↓µA.
Proof: For (i) we may apply (3) to the diﬀerences Dn = An \ An−1 with
A0 = ∅. To get (ii), apply (i) to the sets Bn = A1 \ An.
✷
The class of measures on (Ω, A) is clearly closed under positive linear
combinations. More generally, we note that for any measures µ1, µ2, . . . on
(Ω, A) and constants c1, c2, . . . ≥0, the sum µ =
	
n cnµn is again a measure.
(For the proof, recall that we may change the order of summation in any
double series with positive terms. An abstract version of this fact will appear
as Theorem 1.27.) The quoted result may be restated in terms of monotone
sequences.
Lemma 1.15 (monotone limits) Let µ1, µ2, . . . be measures on some mea-
surable space (Ω, A) such that either µn ↑µ or else µn ↓µ with µ1 bounded.
Then µ is again a measure on (Ω, A).
Proof: In the increasing case, we may use the elementary fact that, for
series with positive terms, the summation commutes with increasing limits.
(A general version of this result appears as Theorem 1.19.)
For decreas-
ing sequences, the previous case may be applied to the increasing measures
µ1 −µn.
✷
For any measure µ on (Ω, A) and set B ∈A, the function ν : A →µ(A∩B)
is again a measure on (Ω, A), called the restriction of µ to B. Given any
countable partition of Ωinto disjoint sets A1, A2, . . . ∈A, we note that
µ = 	
n µn, where µn denotes the restriction of µ to An. The measure µ is
said to be σ-ﬁnite if the partition can be chosen such that µAn < ∞for all
n. In that case the restrictions µn are clearly bounded.
We proceed to establish a simple approximation property.
Lemma 1.16 (regularity) Let µ be a σ-ﬁnite measure on some metric space
S with Borel σ-ﬁeld S. Then
µB = sup
F⊂B µF = inf
G⊃B µG,
B ∈S,
with F and G restricted to the classes of closed and open subsets of S, re-
spectively.
Proof: We may clearly assume that µ is bounded. For any open set G
there exist some closed sets Fn ↑G, and by Lemma 1.14 we get µFn ↑µG.
This proves the statement for B belonging to the π-system G of all open sets.

1. Elements of Measure Theory
9
Letting D denote the class of all sets B with the stated property, we further
note that D is a λ-system. Hence, Theorem 1.1 shows that D ⊃σ(G) = S. ✷
A measure µ on some topological space S with Borel σ-ﬁeld S is said to
be locally ﬁnite if every point s ∈S has a neighborhood where µ is ﬁnite.
A locally ﬁnite measure on a σ-compact space is clearly σ-ﬁnite. It is often
useful to identify simple measure-determining classes C ⊂S such that a
locally ﬁnite measure on S is uniquely determined by its values on C. For
measures on a Euclidean space Rd, we may take C = Id, the class of all
bounded rectangles.
Lemma 1.17 (uniqueness) A locally ﬁnite measure on Rd is determined by
its values on Id.
Proof: Let µ and ν be two measures on Rd with µI = νI < ∞for all
I ∈Id. To see that µ = ν, we may ﬁx any J ∈Id, put C = Id ∩J, and let D
denote the class of Borel sets B ⊂J with µB = νB. Then C is a π-system,
D is a λ-system, and C ⊂D by hypothesis. By Theorem 1.1 and Lemma
1.2, we get B(J) = σ(C) ⊂D, which means that µB = νB for all B ∈B(J).
The last equality extends by the countable additivity of µ and ν to arbitrary
Borel sets B.
✷
The simplest measures that can be deﬁned on a measurable space (S, S)
are the Dirac measures δs, s ∈S, given by δsA = 1A(s), A ∈S. More
generally, for any subset M ⊂S we may introduce the associated counting
measure µM =
	
s∈M δs with values µMA = |M ∩A|, A ∈S, where |A|
denotes the cardinality of the set A.
For any measure µ on a topological space S, the support supp µ is deﬁned
as the smallest closed set F ⊂S with µF c = 0. If |supp µ| ≤1, then µ is
said to be degenerate, and we note that µ = cδs for some s ∈S and c ≥0.
More generally, a measure µ is said to have an atom at s ∈S if {s} ∈S and
µ{s} > 0. For any locally ﬁnite measure µ on some σ-compact metric space
S, the set A = {s ∈S; µ{s} > 0} is clearly measurable, and we may deﬁne
the atomic and diﬀuse components µa and µd of µ as the restrictions of µ to
A and its complement. We further say that µ is diﬀuse if µa = 0 and purely
atomic if µd = 0.
In the important special case when µ is locally ﬁnite and integer valued,
the set A above is clearly locally ﬁnite and hence closed. By Lemma 1.14
we further have supp µ ⊂A, and so µ must be purely atomic. Hence, in
this case µ = 	
s∈A csδs for some integers cs. In particular, µ is said to be
simple if cs = 1 for all s ∈A. In that case clearly µ agrees with the counting
measure on its support A.
Any measurable mapping f between two measurable spaces (S, S) and
(T, T ) induces a mapping of measures on S into measures on T. More pre-
cisely, given any measure µ on (S, S), we may deﬁne a measure µ ◦f −1 on

10
Foundations of Modern Probability
(T, T ) by
(µ ◦f −1)B = µ(f −1B) = µ{s ∈S; f(s) ∈B},
B ∈T .
Here the countable additivity of µ◦f −1 follows from that for µ together with
the fact that f −1 preserves unions and intersections.
Our next aim is to deﬁne the integral
µf =

fdµ =

f(ω)µ(dω)
of a real-valued, measurable function f on some measure space (Ω, A, µ).
First assume that f is simple and nonnegative, hence of the form c11A1 +
· · ·+cn1An for some n ∈Z+, A1, . . . , An ∈A, and c1, . . . , cn ∈R+, and deﬁne
µf = c1µA1 + · · · + cnµAn.
(Throughout measure theory we are following the convention 0 · ∞= 0.)
Using the ﬁnite additivity of µ, it is easy to verify that µf is independent of
the choice of representation of f. It is further clear that the mapping f →µf
is linear and nondecreasing, in the sense that
µ(af + bg)
=
aµf + bµg,
a, b ≥0,
f ≤g
⇒
µf ≤µg.
To extend the integral to any nonnegative measurable function f, we may
choose as in Lemma 1.11 some simple measurable functions f1, f2, . . . with
0 ≤fn ↑f, and deﬁne µf = limn µfn. The following result shows that the
limit is independent of the choice of approximating sequence (fn).
Lemma 1.18 (consistency) Fix any measurable function f ≥0 on some
measure space (Ω, A, µ), and let f1, f2, . . . and g be simple measurable func-
tions satisfying 0 ≤fn ↑f and 0 ≤g ≤f. Then limn µfn ≥µg.
Proof: By the linearity of µ, it is enough to consider the case when g = 1A
for some A ∈A. Fix any ε > 0, and deﬁne
An = {ω ∈A; fn(ω) ≥1 −ε},
n ∈N.
Then An ↑A, and so
µfn ≥(1 −ε)µAn ↑(1 −ε)µA = (1 −ε)µg.
It remains to let ε →0.
✷
The linearity and monotonicity properties extend immediately to arbi-
trary f ≥0, since if fn ↑f and gn ↑g, then afn +bgn ↑af +bg, and if f ≤g,
then fn ≤(fn ∨gn) ↑g. We are now ready to prove the basic continuity
property of the integral.

1. Elements of Measure Theory
11
Theorem 1.19 (monotone convergence, Levi) Let f, f1, f2 . . . be measurable
functions on (Ω, A, µ) with 0 ≤fn ↑f. Then µfn ↑µf.
Proof: For each n we may choose some simple measurable functions gnk,
with 0 ≤gnk ↑fn as k →∞. The functions hnk = g1k ∨· · · ∨gnk have the
same properties and are further nondecreasing in both indices. Hence,
f ≥lim
k→∞hkk ≥lim
k→∞hnk = fn ↑f,
and so 0 ≤hkk ↑f. Using the deﬁnition and monotonicity of the integral,
we obtain
µf = lim
k→∞µhkk ≤lim
k→∞µfk ≤µf.
✷
The last result leads to the following key inequality.
Lemma 1.20 (Fatou) For any measurable functions f1, f2, . . . ≥0 on (Ω,
A, µ), we have
lim inf
n→∞µfn ≥µ lim inf
n→∞fn.
Proof: Since fm ≥infk≥n fk for all m ≥n, we have
inf
k≥n µfk ≥µ inf
k≥n fk,
n ∈N.
Letting n →∞, we get by Theorem 1.19
lim inf
k→∞µfk ≥lim
n→∞µ inf
k≥n fk = µ lim inf
k→∞fk.
✷
A measurable function f on (Ω, A, µ) is said to be integrable if µ|f| < ∞.
In that case f may be written as the diﬀerence of two nonnegative, integrable
functions g and h (e.g., as f+ −f−, where f± = (±f)∨0), and we may deﬁne
µf as µg−µh. It is easy to check that the extended integral is independent of
the choice of representation f = g−h and that µf satisﬁes the basic linearity
and monotonicity properties (the former with arbitrary real coeﬃcients).
We are now ready to state the basic condition that allows us to take
limits under the integral sign. For gn ≡g the result reduces to Lebesgue’s
dominated convergence theorem, a key result in analysis.
Theorem 1.21 (dominated convergence, Lebesgue) Let f, f1, f2, . . . and g,
g1, g2, . . . be measurable functions on (Ω, A, µ) with |fn| ≤gn for all n, and
such that fn →f, gn →g, and µgn →µg < ∞. Then µfn →µf.
Proof: Applying Fatou’s lemma to the functions gn ± fn ≥0, we get
µg + lim inf
n→∞(±µfn) = lim inf
n→∞µ(gn ± fn) ≥µ(g ± f) = µg ± µf.
Subtracting µg < ∞from each side, we obtain

12
Foundations of Modern Probability
µf ≤lim inf
n→∞µfn ≤lim sup
n→∞µfn ≤µf.
✷
The next result shows how integrals are transformed by measurable map-
pings.
Lemma 1.22 (substitution) Fix a measure space (Ω, A, µ), a measurable
space (S, S), and two measurable mappings f : Ω→S and g: S →R. Then
µ(g ◦f) = (µ ◦f −1)g
(4)
whenever either side exists. (Thus, if one side exists, then so does the other
and the two are equal.)
Proof: If g is an indicator function, then (4) reduces to the deﬁnition
of µ ◦f −1. From here on we may extend by linearity and monotone con-
vergence to any measurable function g ≥0. For general g it follows that
µ|g ◦f| = (µ ◦f −1)|g|, and so the integrals in (4) exist at the same time.
When they do, we get (4) by taking diﬀerences on both sides.
✷
Turning to the other basic transformation of measures and integrals, ﬁx
any measurable function f ≥0 on some measure space (Ω, A, µ), and deﬁne
a function f · µ on A by
(f · µ)A = µ(1Af) =

A fdµ,
A ∈A,
where the last relation deﬁnes the integral over a set A. It is easy to check
that ν = f · µ is again a measure on (Ω, A). Here f is referred to as the
µ-density of ν. The corresponding transformation rule is as follows.
Lemma 1.23 (chain rule) Fix a measure space (Ω, A, µ) and some mea-
surable functions f : Ω→R+ and g: Ω→R. Then
µ(fg) = (f · µ)g
whenever either side exists.
Proof: As in the last proof, we may begin with the case when g is an
indicator function and then extend in steps to the general case.
✷
Given a measure space (Ω, A, µ), a set A ∈A is said to be µ-null or
simply null if µA = 0. A relation between functions on Ωis said to hold
almost everywhere with respect to µ (abbreviated as a.e. µ or µ-a.e.) if it
holds for all ω ∈Ωoutside some µ-null set. The following frequently used
result explains the relevance of null sets.
Lemma 1.24 (null functions) For any measurable function f ≥0 on some
measure space (Ω, A, µ), we have µf = 0 iﬀf = 0 a.e. µ.

1. Elements of Measure Theory
13
Proof: The statement is obvious when f is simple. In the general case, we
may choose some simple measurable functions fn with 0 ≤fn ↑f, and note
that f = 0 a.e. iﬀfn = 0 a.e. for every n, that is, iﬀµfn = 0 for all n. Here
the latter integrals converge to µf, and so the last condition is equivalent to
µf = 0.
✷
The last result shows that two integrals agree when the integrands are
a.e. equal. We may then allow integrands that are undeﬁned on some µ-null
set. It is also clear that the basic convergence Theorems 1.19 and 1.21 remain
valid if the hypotheses are only fulﬁlled outside some null set.
In the other direction, we note that if two σ-ﬁnite measures µ and ν are
related by ν = f ·µ for some density f, then the latter is µ-a.e. unique, which
justiﬁes the notation f = dν/dµ. It is further clear that any µ-null set is
also a null set for ν. For measures µ and ν with the latter property, we say
that ν is absolutely continuous with respect to µ and write ν ≪µ. The other
extreme case is when µ and ν are mutually singular or orthogonal (written
as µ ⊥ν), in the sense that µA = 0 and νAc = 0 for some set A ∈A.
Given any measure space (Ω, A, µ), we deﬁne the µ-completion of A as
the σ-ﬁeld Aµ = σ(A, Nµ), where Nµ denotes the class of all subsets of µ-null
sets in A. The description of Aµ can be made more explicit, as follows.
Lemma 1.25 (completion) Consider a measure space (Ω, A, µ) and a Borel
space (S, S). Then a function f : Ω→S is Aµ-measurable iﬀthere exists
some A-measurable function g satisfying f = g a.e. µ.
Proof: With Nµ as before, let A′ denote the class of all sets A ∪N with
A ∈A and N ∈Nµ. It is easily veriﬁed that A′ is a σ-ﬁeld contained in
Aµ. Since moreover A ∪Nµ ⊂A′, we conclude that A′ = Aµ. Thus, for
any A ∈Aµ there exists some B ∈A with A∆B ∈Nµ, which proves the
statement for indicator functions f.
In the general case, we may clearly assume that S = [0, 1].
For any
Aµ-measurable function f, we may then choose some simple Aµ-measurable
functions fn such that 0 ≤fn ↑f. By the result for indicator functions, we
may next choose some simple A-measurable functions gn such that fn = gn
a.e. for each n. Since a countable union of null sets is again a null set, the
function g = lim supn gn has the desired property.
✷
Any measure µ on (Ω, A) has a unique extension to the σ-ﬁeld Aµ. Indeed,
for any A ∈Aµ there exist by Lemma 1.25 some sets A± ∈A with A−⊂
A ⊂A+ and µ(A+ \ A−) = 0, and any extension must satisfy µA = µA±.
With this choice, it is easy to check that µ remains a measure on Aµ.
Our next aims are to construct product measures and to establish the
basic condition for changing the order of integration. This requires a prelim-
inary technical lemma.

14
Foundations of Modern Probability
Lemma 1.26 (sections)
Fix two measurable spaces (S, S) and (T, T ), a
measurable function f : S × T →R+, and a σ-ﬁnite measure µ on S. Then
f(s, t) is S-measurable in s ∈S for each t ∈T, and the function t →µf(·, t)
is T -measurable.
Proof: We may assume that µ is bounded. Both statements are obvious
when f = 1A with A = B × C for some B ∈S and C ∈T , and they extend
by a monotone class argument to any indicator functions of sets in S ⊗T .
The general case follows by linearity and monotone convergence.
✷
We are now ready to state the main result involving product measures,
commonly referred to as Fubini’s theorem.
Theorem 1.27 (product measures and iterated integrals, Lebesgue, Fubini,
Tonelli) For any σ-ﬁnite measure spaces (S, S, µ) and (T, T , ν), there exists
a unique measure µ ⊗ν on (S × T, S ⊗T ) satisfying
(µ ⊗ν)(B × C) = µB · νC,
B ∈S, C ∈T .
(5)
Furthermore, for any measurable function f : S × T →R+,
(µ ⊗ν)f =

µ(ds)

f(s, t)ν(dt) =

ν(dt)

f(s, t)µ(ds).
(6)
The last relation remains valid for any measurable function f : S × T →R
with (µ ⊗ν)|f| < ∞.
Note that the iterated integrals in (6) are well deﬁned by Lemma 1.26,
although the inner integrals νf(s, ·) and µf(·, t) may fail to exist on some
null sets in S and T, respectively.
Proof: By Lemma 1.26 we may deﬁne
(µ ⊗ν)A =

µ(ds)

1A(s, t)ν(dt),
A ∈S ⊗T ,
(7)
which is clearly a measure on S × T satisfying (5). By a monotone class
argument there can be at most one such measure. In particular, (7) remains
true with the order of integration reversed, which proves (6) for indicator
functions f. The formula extends by linearity and monotone convergence to
arbitrary measurable functions f ≥0.
In the general case, we note that (6) holds with f replaced by |f|. If
(µ ⊗ν)|f| < ∞, it follows that NS = {s ∈S; ν|f(s, ·)| = ∞} is a µ-null set
in S whereas NT = {t ∈T; µ|f(·, t)| = ∞} is a ν-null set in T. By Lemma
1.24 we may redeﬁne f(s, t) to be zero when s ∈NS or t ∈NT. Then (6)
follows for f by subtraction of the formulas for f+ and f−.
✷

1. Elements of Measure Theory
15
The measure µ ⊗ν in Theorem 1.27 is called the product measure of µ
and ν. Iterating the construction in ﬁnitely many steps, we obtain product
measures µ1 ⊗. . .⊗µn =

k µk satisfying higher-dimensional versions of (6).
If µk = µ for all k, we shall often write the product as µ⊗n or µn.
By a measurable group we mean a group G endowed with a σ-ﬁeld G
such that the group operations in G are G-measurable.
If µ1, . . . , µn are
σ-ﬁnite measures on G, we may deﬁne the convolution µ1 ∗· · · ∗µn as the
image of the product measure µ1 ⊗· · · ⊗µn on Gn under the iterated group
operation (x1, . . . , xn) →x1 · · · xn. The convolution is said to be associative
if (µ1 ∗µ2) ∗µ3 = µ1 ∗(µ2 ∗µ3) whenever both µ1 ∗µ2 and µ2 ∗µ3 are σ-ﬁnite
and commutative if µ1 ∗µ2 = µ2 ∗µ1.
A measure µ on G is said to be right or left invariant if µ ◦T −1
g
= µ for
all g ∈G, where Tg denotes the right or left shift x →xg or x →gx. When
G is Abelian, the shift is called a translation. We may also consider spaces
of the form G × S, in which case translations are deﬁned to be mappings of
the form Tg : (x, s) →(x + g, s).
Lemma 1.28 (convolution) The convolution of measures on a measurable
group (G, G) is associative, and it is also commutative when G is Abelian. In
the latter case,
(µ ∗ν)B =

µ(B −s)ν(ds) =

ν(B −s)µ(ds),
B ∈G.
If µ = f · λ and ν = g · λ for some invariant measure λ, then µ ∗ν has the
λ-density
(f ∗g)(s) =

f(s −t)g(t)λ(dt) =

f(t)g(s −t)λ(dt),
s ∈G.
Proof: Use Fubini’s theorem.
✷
On the real line there exists a unique measure λ, called the Lebesgue
measure, such that λ[a, b] = b−a for any numbers a < b (cf. Corollary A1.2).
The d-dimensional Lebesgue measure is deﬁned as the product measure λd
on Rd. The following result characterizes λd up to a normalization by the
property of translation invariance.
Lemma 1.29 (invariance and Lebesgue measure) Fix any measurable space
(S, S), and let µ be a measure on Rd×S such that ν = µ([0, 1]d×·) is σ-ﬁnite.
Then µ is translation invariant iﬀµ = λd ⊗ν.
Proof: The invariance of λd is obvious from Lemma 1.17, and it extends to
λd ⊗ν by Theorem 1.27. Conversely, assume that µ is translation invariant.
The stated relation then holds for all product sets I1 × · · · × Id × B, where
I1, . . . , Id are dyadic intervals and B ∈S, and it extends to the general case
by a monotone class argument.
✷

16
Foundations of Modern Probability
Given a measure space (Ω, A, µ) and some p > 0, we write Lp = Lp(Ω, A, µ)
for the class of all measurable functions f : Ω→R with
∥f∥p ≡(µ|f|p)1/p < ∞.
Lemma 1.30 (norm inequalities, H¨older, Minkowski) For any measurable
functions f and g on Ω,
∥fg∥r ≤∥f∥p∥g∥q,
p, q, r > 0 with p−1 + q−1 = r−1,
(8)
and
∥f + g∥p∧1
p
≤∥f∥p∧1
p
+ ∥g∥p∧1
p
,
p > 0.
(9)
Proof: To prove (8) it is clearly enough to take r = 1 and ∥f∥p = ∥g∥q = 1.
The relation p−1 + q−1 = 1 implies (p −1)(q −1) = 1, and so the equations
y = xp−1 and x = yq−1 are equivalent for x, y ≥0. By calculus,
|fg| ≤

 |f|
0
xp−1dx +

 |g|
0
yq−1dy = p−1|f|p + q−1|g|q,
and so
∥fg∥1 ≤p−1

|f|pdµ + q−1

|g|qdµ = p−1 + q−1 = 1.
Relation (9) holds for p ≤1 by the concavity of xp on R+. For p > 1, we
get by (8) with q = p/(1 −p) and r = 1
∥f + g∥p
p
≤

|f| |f + g|p−1dµ +

|g| |f + g|p−1dµ
≤
∥f∥p∥f + g∥p−1
p
+ ∥g∥p∥f + g∥p−1
p
.
✷
In particular, ∥·∥p becomes a norm for p ≥1 if we identify functions that
agree a.e. For any p > 0 and f, f1, f2, . . . ∈Lp, we say that fn →f in Lp if
∥fn −f∥p →0 and that (fn) is Cauchy in Lp if ∥fm −fn∥p →0 as m, n →∞.
Lemma 1.31 (completeness) Let (fn) be a Cauchy sequence in Lp, where
p > 0. Then ∥fn −f∥p →0 for some f ∈Lp.
Proof: First choose a subsequence (nk) ⊂N with
	
k ∥fnk+1 −fnk∥p∧1
p
<
∞. By Lemma 1.30 and monotone convergence we get ∥	
k |fnk+1 −fnk| ∥p∧1
p
< ∞, and so
	
k |fnk+1 −fnk| < ∞a.e. Hence, (fnk) is a.e. Cauchy in R, so
Lemma 1.10 yields fnk →f a.e. for some measurable function f. By Fatou’s
lemma,
∥f −fn∥p ≤lim inf
k→∞∥fnk −fn∥p ≤sup
m≥n ∥fm −fn∥p →0,
n →∞,
which shows that fn →f in Lp.
✷
The next result gives a useful criterion for convergence in Lp.

1. Elements of Measure Theory
17
Lemma 1.32 (Lp-convergence) For any p > 0, let f, f1, f2, . . . ∈Lp with
fn →f a.e. Then fn →f in Lp iﬀ∥fn∥p →∥f∥p.
Proof: If fn →f in Lp, we get by Lemma 1.30
|∥fn∥p∧1
p
−∥f∥p∧1
p
| ≤∥fn −f∥p∧1
p
→0,
and so ∥fn∥p →∥f∥p. Now assume instead the latter condition, and deﬁne
gn = 2p(|fn|p + |f|p),
g = 2p+1|f|p,
Then gn →g a.e. and µgn →µg < ∞by hypotheses. Since also |gn| ≥
|fn −f|p →0 a.e., Theorem 1.21 yields ∥fn −f∥p
p = µ|fn −f|p →0.
✷
We proceed with a simple approximation property.
Lemma 1.33 (approximation) Given a metric space S with Borel σ-ﬁeld
S, a bounded measure µ on (S, S), and a constant p > 0, the set of bounded,
continuous functions on S is dense in Lp(S, S, µ). Thus, for any f ∈Lp there
exist some bounded, continuous functions f1, f2, . . . : S →R with ∥fn −f∥p
→0.
Proof: If f = 1A with A ⊂S open, we may choose some continuous func-
tions fn with 0 ≤fn ↑f, and then ∥fn −f∥p →0 by dominated convergence.
By Lemma 1.16 the result remains true for arbitrary A ∈S. The further
extension to simple measurable functions is immediate. For general f ∈Lp
we may choose some simple measurable functions fn →f with |fn| ≤|f|.
Since |fn−f|p ≤2p+1|f|p, we get ∥fn−f∥p →0 by dominated convergence. ✷
Taking p=q =2 and r =1 in H¨older’s inequality (8), we get the Cauchy-
Buniakovsky inequality (often called Schwarz’s inequality)
∥fg∥1 ≤∥f∥2∥g∥2.
In particular, we note that, for any f, g ∈L2, the inner product ⟨f, g⟩= µ(fg)
exists and satisﬁes |⟨f, g⟩| ≤∥f∥2∥g∥2. From the obvious bilinearity of the
inner product, we get the parallelogram identity
∥f + g∥2 + ∥f −g∥2 = 2∥f∥2 + 2∥g∥2,
f, g ∈L2.
(10)
Two functions f, g ∈L2 are said to be orthogonal (written as f ⊥g)
if ⟨f, g⟩= 0. Orthogonality between two subsets A, B ⊂L2 means that
f ⊥g for all f ∈A and g ∈B. A subspace M ⊂L2 is said to be linear if
af + bg ∈M for any f, g ∈M and a, b ∈R, and closed if f ∈M whenever f
is the L2-limit of a sequence in M.
Theorem 1.34 (orthogonal projection) Let M be a closed linear subspace
of L2. Then any function f ∈L2 has an a.e. unique decomposition f = g +h
with g ∈M and h ⊥M.

18
Foundations of Modern Probability
Proof: Fix any f ∈L2, and deﬁne d = inf{∥f −g∥; g ∈M}. Choose
g1, g2, . . . ∈M with ∥f −gn∥→d. Using the linearity of M, the deﬁnition of
d, and (10), we get as m, n →∞,
4d2 + ∥gm −gn∥2
≤
∥2f −gm −gn∥2 + ∥gm −gn∥2
=
2∥f −gm∥2 + 2∥f −gn∥2 →4d2.
Thus, ∥gm −gn∥→0, and so the sequence (gn) is Cauchy in L2. By Lemma
1.31 it converges toward some g ∈L2, and since M is closed we have g ∈M.
Noting that h = f −g has norm d, we get for any l ∈M,
d2 ≤∥h + tl∥2 = d2 + 2t⟨h, l⟩+ t2∥l∥2,
t ∈R,
which implies ⟨h, l⟩= 0. Hence, h ⊥M, as required.
To prove the uniqueness, let g′ + h′ be another decomposition with the
stated properties. Then g −g′ ∈M and also g −g′ = h′ −h ⊥M, so
g −g′ ⊥g −g′, which implies ∥g −g′∥2 = ⟨g −g′, g −g′⟩= 0, and hence
g = g′ a.e.
✷
For any measurable space (S, S), we may introduce the class M(S) of σ-
ﬁnite measures on S. The set M(S) becomes a measurable space in its own
right when endowed with the σ-ﬁeld induced by the mappings πB : µ →µB,
B ∈S. Note in particular that the class P(S) of probability measures on
S is a measurable subset of M(S). In the next two lemmas we state some
less obvious measurability properties, which will be needed in subsequent
chapters.
Lemma 1.35 (measurability of products) For any measurable spaces (S, S)
and (T, T ), the mapping (µ, ν) →µ ⊗ν is measurable from P(S) × P(T) to
P(S × T).
Proof: Note that (µ⊗ν)A is measurable whenever A = B×C with B ∈S
and C ∈T , and extend by a monotone class argument.
✷
In the context of separable metric spaces S, we shall assume the measures
µ ∈M(S) to be locally ﬁnite, in the sense that µB < ∞for any bounded
Borel set B.
Lemma 1.36 (diﬀuse and atomic parts) For any separable metric space S,
(i) the set D ⊂M(S) of degenerate measures on S is measurable;
(ii) the diﬀuse and purely atomic components µd and µa are measurable
functions of µ ∈M(S).
Proof: (i) Choose a countable topological base B1, B2, . . . in S, and deﬁne
J = {(i, j); Bi ∩Bj = ∅}. Then, clearly,
D =

µ ∈M(S);

(i,j)∈J(µBi)(µBj) = 0

.

1. Elements of Measure Theory
19
(ii) Choose a nested sequence of countable partitions Bn of S into Borel
sets of diameter less than n−1. Introduce for ε > 0 and n ∈N the sets U ε
n =
{B ∈Bn; µB ≥ε}, U ε = {s ∈S; µ{s} ≥ε}, and U = {s ∈S; µ{s} > 0}.
It is easily seen that U ε
n ↓U ε as n →∞and further that U ε ↑U as ε →0.
By dominated convergence, the restrictions µε
n = µ(U ε
n∩·) and µε = µ(U ε∩·)
satisfy locally µε
n ↓µε and µε ↑µa. Since µε
n is clearly a measurable function
of µ, the asserted measurability of µa and µd now follows by Lemma 1.10. ✷
Given two measurable spaces (S, S) and (T, T ), a mapping µ: S×T →R+
is called a (probability) kernel from S to T if the function µsB = µ(s, B) is
S-measurable in s ∈S for ﬁxed B ∈T and a (probability) measure in B ∈T
for ﬁxed s ∈S. Any kernel µ determines an associated operator that maps
suitable functions f : T →R into their integrals µf(s) =
 µ(s, dt)f(t). Ker-
nels play an important role in probability theory, where they may appear in
the guises of random measures, conditional distributions, Markov transition
functions, and potentials.
The following characterizations of the kernel property are often useful.
For simplicity we are restricting our attention to probability kernels.
Lemma 1.37 (kernels) Fix two measurable spaces (S, S) and (T, T ), a π-
system C with σ(C) = T , and a family µ = {µs; s ∈S} of probability mea-
sures on T. Then these conditions are equivalent:
(i) µ is a probability kernel from S to T;
(ii) µ is a measurable mapping from S to P(T);
(iii) s →µsB is a measurable mapping from S to [0, 1] for every B ∈C.
Proof: Since πB : µ →µB is measurable on P(T) for every B ∈T ,
condition (ii) implies (iii) by Lemma 1.7. Furthermore, (iii) implies (i) by
a straightforward application of Theorem 1.1.
Finally, under (i) we have
µ−1π−1
B [0, x] ∈S for all B ∈T and x ≥0, and (ii) follows by Lemma 1.4. ✷
Let us now introduce a third measurable space (U, U), and consider two
kernels µ and ν, one from S to T and the other from S × T to U. Imitating
the construction of product measures, we may attempt to combine µ and ν
into a kernel µ ⊗ν from S to T × U given by
(µ ⊗ν)(s, B) =

µ(s, dt)

ν(s, t, du)1B(t, u),
B ∈T ⊗U.
The following lemma justiﬁes the formula and provides some further useful
information.
Lemma 1.38 (kernels and functions) Fix three measurable spaces (S, S),
(T, T ), and (U, U). Let µ and ν be probability kernels from S to T and from
S × T to U, respectively, and consider two measurable functions f : S × T →
R+ and g: S × T →U. Then

20
Foundations of Modern Probability
(i) µsf(s, ·) is a measurable function of s ∈S;
(ii) µs ◦(g(s, ·))−1 is a kernel from S to U;
(iii) µ ⊗ν is a kernel from S to T × U.
Proof: Assertion (i) is obvious when f is the indicator function of a set
A = B × C with B ∈S and C ∈T . From here on, we may extend to
general A ∈S ⊗T by a monotone class argument and then to arbitrary f
by linearity and monotone convergence. The statements in (ii) and (iii) are
easy consequences.
✷
For any measurable function f ≥0 on T × U, we get as in Theorem 1.27
(µ ⊗ν)sf =

µ(s, dt)

ν(s, t, du)f(t, u),
s ∈S,
or simply (µ ⊗ν)f = µ(νf). By iteration we may combine any kernels µk
from S0 × · · · × Sk−1 to Sk, k = 1, . . . , n, into a kernel µ1 ⊗· · · ⊗µn from S0
to S1 × · · · × Sn, given by
(µ1 ⊗· · · ⊗µn)f = µ1(µ2(· · · (µnf) · · ·))
for any measurable function f ≥0 on S1 × · · · × Sn.
In applications we may often encounter kernels µk from Sk−1 to Sk, k =
1, . . . , n, in which case the composition µ1 · · · µn is deﬁned as a kernel from
S0 to Sn given for measurable B ⊂Sn by
(µ1 · · · µn)sB
=
(µ1 ⊗· · · ⊗µn)s(S1 × · · · × Sn−1 × B)
=

µ1(s, ds1)

µ2(s1, ds2) · · ·
· · ·

µn−1(sn−2, dsn−1)µn(sn−1, B).
Exercises
1. Prove the triangle inequality µ(A∆C) ≤µ(A∆B) + µ(B∆C). (Hint:
Note that 1A∆B = |1A −1B|.)
2. Show that Lemma 1.9 is false for uncountable index sets. (Hint: Show
that every measurable set depends on countably many coordinates.)
3. For any space S, let µA denote the cardinality of the set A ⊂S. Show
that µ is a measure on (S, 2S).
4. Let K be the class of compact subsets of some metric space S, and let
µ be a bounded measure such that infK∈K µKc = 0. Show for any B ∈B(S)
that µB = supK∈K∩B µK.

1. Elements of Measure Theory
21
5. Show that any absolutely convergent series can be written as an inte-
gral with respect to counting measure on N. State series versions of Fatou’s
lemma and the dominated convergence theorem, and give direct elementary
proofs.
6. Give an example of integrable functions f, f1, f2, . . . on some proba-
bility space (Ω, A, µ) such that fn →f but µfn ̸→µf.
7. Fix two σ-ﬁnite measures µ and ν on some measurable space (Ω, F)
with sub-σ-ﬁeld G. Show that if µ ≪ν holds on F, it is also true on G.
Further show by an example that the converse may fail.
8. Fix two measurable spaces (S, S) and (T, T ), a measurable function
f : S →T, and a measure µ on S with image ν = µ ◦f −1. Show that f
remains measurable w.r.t. the completions Sµ and T ν.
9. Fix a measure space (S, S, µ) and a σ-ﬁeld T ⊂S, let Sµ denote the
µ-completion of S, and let T µ be the σ-ﬁeld generated by T and the µ-null
sets of Sµ. Show that A ∈T µ iﬀthere exist some B ∈T and N ∈Sµ with
A∆B ⊂N and µN = 0. Also, show by an example that T µ may be strictly
greater than the µ-completion of T .
10. State Fubini’s theorem for the case where µ is any σ-ﬁnite measure
and ν is the counting measure on N. Give a direct proof of this result.
11. Let f1, f2, . . . be µ-integrable functions on some measurable space S
such that g = 	
k fk exists a.e., and put gn =
	
k≤n fk. Restate the dominated
convergence theorem for the integrals µgn in terms of the functions fk, and
compare with the result of the preceding exercise.
12. Extend Theorem 1.27 to the product of n measures.
13. Show that Lebesgue measure on Rd is invariant under rotations. (Hint:
Apply Lemma 1.29 in both directions.)
14. Fix a measurable Abelian group G such that every σ-ﬁnite, invariant
measure on G is proportional to some measure λ. Extend Lemma 1.29 to
this case.
15. Let λ denote Lebesgue measure on R+, and ﬁx any p > 0. Show that
the class of step functions with bounded support and ﬁnitely many jumps is
dense in Lp(λ). Generalize to Rd
+.
16. Let M ⊃N be closed linear subspaces of L2. Show that if f ∈L2 has
projections g onto M and h onto N, then g has projection h onto N.
17.
Let M be a closed linear subspace of L2, and let f, g ∈L2 with
M-projections ˆf and ˆg. Show that ⟨ˆf, g⟩= ⟨f, ˆg⟩= ⟨ˆf, ˆg⟩.
18. Let µ1, µ2, . . . be kernels between two measurable spaces S and T.
Show that the function µ = 	
n µn is again a kernel.
19. Fix a function f between two measurable spaces S and T, and deﬁne
µ(s, B) = 1B ◦f(s). Show that µ is a kernel iﬀf is measurable.

Chapter 2
Processes, Distributions,
and Independence
Random elements and processes; distributions and expectation;
independence; zero–one laws; Borel–Cantelli lemma; Bernoulli
sequences and existence; moments and continuity of paths
Armed with the basic notions and results of measure theory from the previ-
ous chapter, we may now embark on our study of probability theory itself.
The dual purpose of this chapter is to introduce the basic terminology and
notation and to prove some fundamental results, many of which are used
throughout the remainder of this book.
In modern probability theory it is customary to relate all objects of study
to a basic probability space (Ω, A, P), which is nothing more than a normal-
ized measure space. Random variables may then be deﬁned as measurable
functions ξ on Ω, and their expected values as the integrals Eξ =
 ξdP.
Furthermore, independence between random quantities reduces to a kind of
orthogonality between the induced sub-σ-ﬁelds. It should be noted, how-
ever, that the reference space Ωis introduced only for technical convenience,
to provide a consistent mathematical framework. Indeed, the actual choice
of Ωplays no role, and the interest focuses instead on the various induced
distributions P ◦ξ−1.
The notion of independence is fundamental for all areas of probability
theory. Despite its simplicity, it has some truly remarkable consequences. A
particularly striking result is Kolmogorov’s zero–one law, which states that
every tail event associated with a sequence of independent random elements
has probability zero or one. As a consequence, any random variable that
depends only on the “tail” of the sequence must be a.s. constant. This result
and the related Hewitt–Savage zero–one law convey much of the ﬂavor of
modern probability: Although the individual elements of a random sequence
are erratic and unpredictable, the long-term behavior may often conform to
deterministic laws and patterns. Our main objective is to uncover the latter.
Here the classical Borel–Cantelli lemma is a useful tool, among others.
To justify our study, we need to ensure the existence of the random ob-
jects under discussion. For most purposes, it suﬃces to use the Lebesgue unit
interval ([0, 1], B, λ) as the basic probability space. In this chapter the exis-
tence will be proved only for independent random variables with prescribed
22

2. Processes, Distributions, and Independence
23
distributions; we postpone the more general discussion until Chapter 5. As
a key step, we use the binary expansion of real numbers to construct a so-
called Bernoulli sequence, consisting of independent random digits 0 or 1
with probabilities 1−p and p, respectively. Such sequences may be regarded
as discrete-time counterparts of the fundamental Poisson process, to be in-
troduced and studied in Chapter 10.
The distribution of a random process X is determined by the ﬁnite-
dimensional distributions, and those are not aﬀected if we change each value
Xt on a null set. It is then natural to look for versions of X with suitable
regularity properties. As another striking result, we shall provide a moment
condition that ensures the existence of a continuous modiﬁcation of the pro-
cess.
Regularizations of various kinds are important throughout modern
probability theory, as they may enable us to deal with events depending on
the values of a process at uncountably many times.
To begin our systematic exposition of the theory, we may ﬁx an arbi-
trary probability space (Ω, A, P), where P, the probability measure, has total
mass 1. In the probabilistic context the sets A ∈A are called events, and
PA = P(A) is called the probability of A. In addition to results valid for all
measures, there are properties that depend on the boundedness or normal-
ization of P, such as the relation PAc = 1 −PA and the fact that An ↓A
implies PAn →PA.
Some inﬁnite set operations have special probabilistic signiﬁcance. Thus,
given any sequence of events A1, A2, . . . ∈A, we may be interested in the
sets {An i.o.}, where An happens inﬁnitely often, and {An ult.}, where An
happens ultimately (i.e., for all but ﬁnitely many n). Those occurrences are
events in their own right, expressible in terms of the An as
{An i.o.}
=

n1An = ∞

=

n

k≥nAk,
(1)
{An ult.}
=

n1Acn < ∞

=

n

k≥nAk.
(2)
From here on, we are omitting the argument ω from our notation when there
is no risk for confusion. For example, the expression {	
n 1An = ∞} is used
as a convenient shorthand form of the unwieldy {ω ∈Ω; 	
n 1An(ω) = ∞}.
The indicator functions of the events in (1) and (2) may be expressed as
1{An i.o.} = lim sup
n→∞1An,
1{An ult.} = lim inf
n→∞1An,
where, for typographical convenience, we write 1{·} instead of 1{·}. Applying
Fatou’s lemma to the functions 1An and 1Acn, we get
P{An i.o.} ≥lim sup
n→∞PAn,
P{An ult.} ≤lim inf
n→∞PAn.
Using the continuity and subadditivity of P, we further see from (1) that
P{An i.o.} = lim
n→∞P

k≥nAk ≤lim
n→∞

k≥nPAk.

24
Foundations of Modern Probability
If 	
n PAn < ∞, we get zero on the right, and it follows that P{An i.o.} =
0. The resulting implication constitutes the easy part of the Borel–Cantelli
lemma, to be reconsidered in Theorem 2.18.
Any measurable mapping ξ of Ωinto some measurable space (S, S) is
called a random element in S. If B ∈S, then {ξ ∈B} = ξ−1B ∈A, and we
may consider the associated probabilities
P{ξ ∈B} = P(ξ−1B) = (P ◦ξ−1)B,
B ∈S.
The set function P ◦ξ−1 is again a probability measure, deﬁned on the range
space S and called the (probability) distribution of ξ.
We shall also use
the term distribution as synonomous to probability measure, even when no
generating random element has been introduced.
Random elements are of interest in a wide variety of spaces. A random
element in S is called a random variable when S = R, a random vector
when S = Rd, a random sequence when S = R∞, a random or stochastic
process when S is a function space, and a random measure or set when S
is a class of measures or sets, respectively. A metric or topological space
S will be endowed with its Borel σ-ﬁeld B(S) unless a σ-ﬁeld is otherwise
speciﬁed. For any separable metric space S, it is clear from Lemma 1.2 that
ξ = (ξ1, ξ2, . . .) is a random element in S∞iﬀξ1, ξ2, . . . are random elements
in S.
If (S, S) is a measurable space, then any subset A ⊂S becomes a mea-
surable space in its own right when endowed with the σ-ﬁeld A∩S = {A∩B;
B ∈ˆS}. By Lemma 1.6 we note in particular that if S is a metric space with
Borel σ-ﬁeld S, then A ∩S is the Borel σ-ﬁeld in A. Any random element in
(A, A ∩S) may clearly be regarded, alternatively, as a random element in S.
Conversely, if ξ is a random element in S such that ξ ∈A a.s. (almost surely
or with probability 1) for some A ∈S, then ξ = η a.s. for some random
element η in A.
Fixing a measurable space (S, S) and an abstract index set T, we shall
write ST for the class of functions f : T →S, and let ST denote the σ-ﬁeld in
ST generated by all evaluation maps πt : ST →S, t ∈T, given by πtf = f(t).
If X : Ω→U ⊂ST, then clearly Xt = πt ◦X maps Ωinto S. Thus, X may
also be regarded as a function X(t, ω) = Xt(ω) from T × Ωto S.
Lemma 2.1 (measurability) Fix a measurable space (S, S), an index set T,
and a subset U ⊂ST. Then a function X : Ω→U is U ∩ST-measurable iﬀ
Xt : Ω→S is S-measurable for every t ∈T.
Proof: Since X is U-valued, the U ∩ST-measurability is equivalent to
measurability with respect to ST.
The result now follows by Lemma 1.4
from the fact that ST is generated by the mappings πt.
✷
A mapping X with the properties in Lemma 2.1 is called an S-valued
(random) process on T with paths in U. By the lemma it is equivalent to
regard X as a collection of random elements Xt in the state space S.

2. Processes, Distributions, and Independence
25
For any random elements ξ and η in a common measurable space, the
equality ξ d= η means that ξ and η have the same distribution, or P ◦ξ−1 =
P ◦η−1.
If X is a random process on some index set T, the associated
ﬁnite-dimensional distributions are given by
µt1,...,tn = P ◦(Xt1, . . . , Xtn)−1,
t1, . . . , tn ∈T, n ∈N.
The following result shows that the distribution of a process is determined
by the set of ﬁnite-dimensional distributions.
Proposition 2.2 (ﬁnite-dimensional distributions) Fix any S, T, and U as
in Lemma 2.1, and let X and Y be processes on T with paths in U. Then
X
d= Y iﬀ
(Xt1, . . . , Xtn) d= (Yt1, . . . , Ytn),
t1, . . . , tn ∈T, n ∈N.
(3)
Proof: Assume (3). Let D denote the class of sets A ∈ST with P{X ∈A}
= P{Y ∈A}, and let C consist of all sets
A = {f ∈ST; (ft1, . . . , ftn) ∈B},
t1, . . . , tn ∈T, B ∈Sn, n ∈N.
Then C is a π-system and D a λ-system, and furthermore C ⊂D by hypoth-
esis. Hence, ST = σ(C) ⊂D by Theorem 1.1, which means that X
d= Y .
✷
For any random vector ξ = (ξ1, . . . , ξd) in Rd, we deﬁne the associated
distribution function F by
F(x1, . . . , xd) = P

k≤d{ξk ≤xk},
x1, . . . , xd ∈R.
The next result shows that F determines the distribution of ξ.
Lemma 2.3 (distribution functions) Let ξ and η be random vectors in Rd
with distribution functions F and G. Then ξ d= η iﬀF = G.
Proof: Use Theorem 1.1.
✷
The expected value, expectation, or mean of a random variable ξ is deﬁned
as
Eξ =

Ωξ dP =

R x(P ◦ξ−1)(dx)
(4)
whenever either integral exists.
The last equality then holds by Lemma
1.22. By the same result we note that, for any random element ξ in some
measurable space S and for an arbitrary measurable function f : S →R,
Ef(ξ)
=

Ωf(ξ) dP =

S f(s)(P ◦ξ−1)(ds)
=

R x(P ◦(f ◦ξ)−1)(dx),
(5)

26
Foundations of Modern Probability
provided that at least one of the three integrals exists.
Integrals over a
measurable subset A ⊂Ωare often denoted by
E[ξ; A] = E(ξ 1A) =

A ξ dP,
A ∈A.
For any random variable ξ and constant p > 0, the integral E|ξ|p = ∥ξ∥p
p
is called the pth absolute moment of ξ. By H¨older’s inequality (or by Jensen’s
inequality in Lemma 2.5) we have ∥ξ∥p ≤∥ξ∥q for p ≤q, so the corresponding
Lp-spaces are nonincreasing in p. If ξ ∈Lp and either p ∈N or ξ ≥0, we
may further deﬁne the pth moment of ξ as Eξp.
The following result gives a useful relationship between moments and tail
probabilities.
Lemma 2.4 (moments and tails) For any random variable ξ ≥0,
Eξp = p

 ∞
0
P{ξ > t}tp−1dt = p

 ∞
0
P{ξ ≥t}tp−1dt,
p > 0.
Proof: By elementary calculus and Fubini’s theorem,
Eξp
=
E

 ∞
0
1{ξp > s}ds = E

 ∞
0
1{ξ > s1/p}ds
=
pE

 ∞
0
1{ξ > t}tp−1dt = p

 ∞
0
P{ξ > t}tp−1dt.
The proof of the second expression is similar.
✷
A random vector ξ = (ξ1, . . . , ξd) or process X = (Xt) is said to be
integrable if integrability holds for every component ξk or value Xt, in which
case we may write Eξ = (Eξ1, . . . , Eξd) or EX = (EXt).
Recall that a
function f : Rd →R is said to be convex if
f(px + (1 −p)y) ≤pf(x) + (1 −p)f(y),
x, y ∈Rd, p ∈[0, 1].
(6)
The relation may be written as f(Eξ) ≤Ef(ξ), where ξ is a random vector
in Rd with P{ξ = x} = 1 −P{ξ = y} = p. The following extension to
arbitrary integrable random vectors is known as Jensen’s inequality.
Lemma 2.5 (convex maps, H¨older, Jensen) Let ξ be an integrable random
vector in Rd, and ﬁx any convex function f : Rd →R. Then
Ef(ξ) ≥f(Eξ).
Proof: By a version of the Hahn–Banach theorem, the convexity condition
(6) is equivalent to the existence for every s ∈Rd of a supporting aﬃne
function hs(x) = ax + b with f ≥hs and f(s) = hs(s). In particular, we get
for s = Eξ,
Ef(ξ) ≥Ehs(ξ) = hs(Eξ) = f(Eξ).
✷

2. Processes, Distributions, and Independence
27
The covariance of two random variables ξ, η ∈L2 is given by
cov(ξ, η) = E(ξ −Eξ)(η −Eη) = Eξη −Eξ · Eη.
It is clearly bilinear, in the sense that
cov

j≤majξj,

k≤nbkηk

=

j≤m

k≤najbkcov(ξj, ηk).
We may further deﬁne the variance of a random variable ξ ∈L2 by
var(ξ) = cov(ξ, ξ) = E(ξ −Eξ)2 = Eξ2 −(Eξ)2,
and we note that, by the Cauchy–Buniakovsky inequality,
|cov(ξ, η)| ≤{var(ξ) var(η)}1/2.
Two random variables ξ and η are said to be uncorrelated if cov(ξ, η) = 0.
For any collection of random variables ξt ∈L2, t ∈T, we note that
the associated covariance function ρs,t = cov(ξs, ξt), s, t ∈T, is nonnegative
deﬁnite, in the sense that 	
ij aiajρti,tj ≥0 for any n ∈N, t1, . . . tn ∈T, and
a1, . . . , an ∈R. This is clear if we write

i,jaiajρti,tj =

i,jaiajcov(ξti, ξtj) = var

iaiξti

≥0.
The events At ∈A, t ∈T, are said to be (mutually) independent if, for
any distinct indices t1, . . . , tn ∈T,
P

k≤nAtk =

k≤nPAtk.
(7)
The families Ct ⊂A, t ∈T, are said to be independent if independence holds
between the events At for arbitrary At ∈Ct, t ∈T. Finally, the random
elements ξt, t ∈T, are said to be independent if independence holds between
the generated σ-ﬁelds σ(ξt), t ∈T.
Pairwise independence between two
objects A and B, ξ and η, or B and C is often denoted by A⊥⊥B, ξ⊥⊥η, or
B⊥⊥C, respectively.
The following result is often useful to prove extensions of the indepen-
dence property.
Lemma 2.6 (extension) If the π-systems Ct, t ∈T, are independent, then
so are the σ-ﬁelds Ft = σ(Ct), t ∈T.
Proof: We may clearly assume that Ct ̸= ∅for all t. Fix any distinct
indices t1, . . . , tn ∈T, and note that (7) holds for arbitrary Atk ∈Ctk, k =
1, . . . , n. Keeping At2, . . . , Atn ﬁxed, we deﬁne D as the class of sets At1 ∈A
satisfying (7). Then D is a λ-system containing Ct1, and so D ⊃σ(Ct1) = Ft1
by Theorem 1.1. Thus, (7) holds for arbitrary At1 ∈Ft1 and Atk ∈Ctk, k =
2, . . . , n. Proceeding recursively in n steps, we obtain the desired extension
to arbitrary Atk ∈Ftk, k = 1, . . . , n.
✷

28
Foundations of Modern Probability
As an immediate consequence, we obtain the following basic grouping
property. Here and in the sequel we shall often write F ∨G = σ{F, G} and
FS =

t∈S Ft = σ{Ft; t ∈S}.
Corollary 2.7 (grouping) Let Ft, t ∈T, be independent σ-ﬁelds, and con-
sider a disjoint partition T of T. Then the σ-ﬁelds FS =

t∈S Ft, S ∈T ,
are again independent.
Proof: For each S ∈T , let CS denote the class of all ﬁnite intersections
of sets in 
t∈S Ft. Then the classes CS are independent π-systems, and by
Lemma 2.6 the independence extends to the generated σ-ﬁelds FS.
✷
Though independence between more than two σ-ﬁelds is clearly stronger
than pairwise independence, we shall see how the full independence may be
reduced to the pairwise notion in various ways. Given any set T, a class
T ⊂2T is said to be separating if, for any s ̸= t in T, there exists some
S ∈T such that exactly one of the elements s and t lies in S.
Lemma 2.8 (pairwise independence)
(i) The σ-ﬁelds F1, F2, . . . are independent iﬀ

k≤n Fk ⊥⊥Fn+1 for all n.
(ii) The σ-ﬁelds Ft, t ∈T, are independent iﬀFS⊥⊥FSc for all sets S in
some separating class T ⊂2T.
Proof: The necessity of the two conditions follows from Corollary 2.7. As
for the suﬃciency, we shall consider only part (ii), the proof for (i) being
similar. Under the stated condition, we need to show for any ﬁnite subset
S ⊂T that the σ-ﬁelds Fs, s ∈S, are independent. Let |S| denote the
cardinality of S, and assume the statement to be true for |S| ≤n. Proceeding
to the case when |S| = n + 1, we may choose U ∈T such that S′ = S ∩U
and S′′ = S \ U are nonempty. Since FS′⊥⊥FS′′, we get for any sets As ∈Fs,
s ∈S,
P

s∈SAs =

P

s∈S′As
 
P

s∈S′′As

=

s∈SPAs,
where the last relation follows from the induction hypothesis.
✷
A σ-ﬁeld F is said to be P-trivial if PA = 0 or 1 for every A ∈F. We
further say that a random element is a.s. degenerate if its distribution is a
degenerate probability measure.
Lemma 2.9 (triviality and degeneracy) A σ-ﬁeld F is P-trivial iﬀF⊥⊥F.
In that case, any F-measurable random element ξ taking values in a separable
metric space is a.s. degenerate.
Proof: If F⊥⊥F, then for any A ∈F we have PA = P(A ∩A) = (PA)2,
and so PA = 0 or 1. Conversely, assume that F is P-trivial. Then for any

2. Processes, Distributions, and Independence
29
two sets A, B ∈F we have P(A ∩B) = PA ∧PB = PA · PB, which means
that F⊥⊥F.
Now assume that F is P-trivial, and let ξ be as stated. For each n we may
partition S into countably many disjoint Borel sets Bnj of diameter < n−1.
Since P{ξ ∈Bnj} = 0 or 1, we have ξ ∈Bnj a.s. for exactly one j, say for
j = jn. Hence, ξ ∈

n Bn,jn a.s. The latter set has diameter 0, so it consists
of exactly one point s, and we get ξ = s a.s.
✷
The next result gives the basic relation between independence and prod-
uct measures.
Lemma 2.10 (product measures) Let ξ1, . . . , ξn be random elements with
distributions µ1, . . . , µn in some measurable spaces S1, . . . , Sn. Then the ξk
are independent iﬀξ = (ξ1, . . . , ξn) has distribution µ1 ⊗· · · ⊗µn.
Proof: Assuming the independence, we get for any measurable product
set B = B1 × · · · × Bn,
P{ξ ∈B} =

k≤n
P{ξk ∈Bk} =

k≤n
µkBk =

k≤n
µk B.
This extends by Theorem 1.1 to arbitrary sets in the product σ-ﬁeld.
✷
In conjunction with Fubini’s theorem, the last result leads to a useful
method of computing expected values.
Lemma 2.11 (conditioning) Let ξ and η be independent random elements
in some measurable spaces S and T, and let the function f : S × T →R be
measurable with E(E|f(s, η)|)s=ξ < ∞. Then Ef(ξ, η) = E(Ef(s, η))s=ξ.
Proof: Let µ and ν denote the distributions of ξ and η, respectively.
Assuming that f ≥0 and writing g(s) = Ef(s, η), we get, by Lemma 1.22
and Fubini’s theorem,
Ef(ξ, η)
=

f(s, t)(µ ⊗ν)(dsdt)
=

µ(ds)

f(s, t)ν(dt) =

g(s)µ(ds) = Eg(ξ).
For general f, this applies to the function |f|, and so E|f(ξ, η)| < ∞. The
desired relation then follows as before.
✷
In particular, for any independent random variables ξ1, . . . , ξn,
E

kξk =

kEξk,
var

kξk =

kvar ξk,
whenever the expressions on the right exist.
If ξ and η are random elements in a measurable group G, then the product
ξη is again a random element in G. The following result gives the connection
between independence and the convolutions in Lemma 1.28.

30
Foundations of Modern Probability
Corollary 2.12 (convolution) Let ξ and η be independent random elements
with distributions µ and ν, respectively, in some measurable group G. Then
the product ξη has distribution µ ∗ν.
Proof: For any measurable set B ⊂G, we get by Lemma 2.10 and the
deﬁnition of convolution,
P{ξη ∈B} = (µ ⊗ν){(x, y) ∈G2; xy ∈B} = (µ ∗ν)B.
✷
Given any sequence of σ-ﬁelds F1, F2, . . . , we may introduce the associ-
ated tail σ-ﬁeld
T =

n

k>nFk =

nσ{Fk; k > n}.
The following remarkable result shows that T is trivial whenever the Fn are
independent. An extension appears in Corollary 6.25.
Theorem 2.13 (zero–one law, Kolmogorov) Let F1, F2, . . . be independent
σ-ﬁelds. Then the tail σ-ﬁeld T = 
n

k>n Fk is P-trivial.
Proof: For each n ∈N, deﬁne Tn =

k>n Fk, and note that F1, . . . , Fn, Tn
are independent by Corollary 2.7. Hence, so are the σ-ﬁelds F1, . . . , Fn, T ,
and then also F1, F2, . . . , T . By the same theorem we obtain T0⊥⊥T , and so
T ⊥⊥T . Thus, T is P-trivial by Lemma 2.9.
✷
We shall consider some simple illustrations of the last theorem.
Corollary 2.14 (sums and averages) Let ξ1, ξ2, . . . be independent random
variables, and put Sn = ξ1 + · · · + ξn. Then each of the sequences (Sn) and
(Sn/n) is either a.s. convergent or a.s. divergent. For the latter sequence,
the possible limit is a.s. degenerate.
Proof: Deﬁne Fn = σ{ξn}, n ∈N, and note that the associated tail σ-
ﬁeld T is P-trivial by Theorem 2.13. Since the sets of convergence of (Sn)
and (Sn/n) are T -measurable by Lemma 1.9, the ﬁrst assertion follows. The
second assertion is obtained from Lemma 2.9.
✷
By a ﬁnite permutation of N we mean a bijective map p : N →N such
that pn = n for all but ﬁnitely many n. For any space S, a ﬁnite permutation
p of N induces a permutation Tp on S∞given by
Tp(s) = s ◦p = (sp1, sp2, . . .),
s = (s1, s2, . . .) ∈S∞.
A set I ⊂S∞is said to be symmetric (under ﬁnite permutations) if
T −1
p I ≡{s ∈S∞; s ◦p ∈I} = I

2. Processes, Distributions, and Independence
31
for every ﬁnite permutation p of N. If (S, S) is a measurable space, then the
symmetric sets I ∈S∞form a sub-σ-ﬁeld I ⊂S∞, called the permutation
invariant σ-ﬁeld in S∞.
We may now state the other basic zero–one law, which refers to sequences
of random elements that are independent and identically distributed (abbre-
viated as i.i.d.).
Theorem 2.15 (zero–one law, Hewitt and Savage) Let ξ be an inﬁnite se-
quence of i.i.d. random elements in some measurable space (S, S), and let
I denote the permutation invariant σ-ﬁeld in S∞. Then the σ-ﬁeld ξ−1I is
P-trivial.
Our proof is based on a simple approximation. Write
A△B = (A \ B) ∪(B \ A),
and note that
P(A△B) = P(Ac△Bc) = E|1A −1B|,
A, B ∈A.
(8)
Lemma 2.16 (approximation) Given any σ-ﬁelds F1 ⊂F2 ⊂· · · and a set
A ∈
n Fn, there exist some A1, A2, . . . ∈

n Fn with P(A△An) →0.
Proof: Deﬁne C =

n Fn, and let D denote the class of sets A ∈

n Fn
with the stated property. Then C is a π-system and D a λ-system containing
C. By Theorem 1.1 we get 
n Fn = σ(C) ⊂D.
✷
Proof of Theorem 2.15: Deﬁne µ = P ◦ξ−1, put Fn = Sn × S∞, and
note that I ⊂S∞=

n Fn. For any I ∈I there exist by Lemma 2.16
some sets Bn ∈Sn such that the corresponding sets In = Bn × S∞satisfy
µ(I△In) →0. Writing ˜In = Sn × Bn × S∞, it is clear from the symmetry of
µ and I that µ˜In = µIn →µI and µ(I△˜In) = µ(I△In) →0. Hence, by (8),
µ(I△(In ∩˜In)) ≤µ(I△In) + µ(I△˜In) →0.
Since moreover In⊥⊥˜In under µ, we get
µI ←µ(In ∩˜In) = (µIn)(µ˜In) →(µI)2.
Thus, µI = (µI)2, and so P ◦ξ−1I = µI = 0 or 1.
✷
The next result lists some typical applications. Say that a random vari-
able ξ is symmetric if ξ d= −ξ.
Corollary 2.17 (random walk) Let ξ1, ξ2, . . . be i.i.d., nondegenerate ran-
dom variables, and put Sn = ξ1 + . . . + ξn. Then
(i) P{Sn ∈B i.o.} = 0 or 1 for any B ∈B;
(ii) lim supn Sn = ∞a.s. or −∞a.s.;
(iii) lim supn(±Sn) = ∞a.s. if the ξn are symmetric.

32
Foundations of Modern Probability
Proof: Statement (i) is immediate from Theorem 2.15, since for any ﬁnite
permutation p of N we have xp1 + · · · + xpn = x1 + · · · + xn for all but ﬁnitely
many n. To prove (ii), conclude from Theorem 2.15 and Lemma 2.9 that
lim supn Sn = c a.s. for some constant c ∈R = [−∞, ∞]. Hence, a.s.,
c = lim supnSn+1 = lim supn(Sn+1 −ξ1) + ξ1 = c + ξ1.
If |c| < ∞, we get ξ1 = 0 a.s., which contradicts the nondegeneracy of ξ1.
Thus, |c| = ∞. In case (iii), we have
c = lim supnSn ≥lim infnSn = −lim supn(−Sn) = −c,
and so −c ≤c ∈{±∞}, which implies c = ∞.
✷
Using a suitable zero–one law, one can often rather easily see that a
given event has probability zero or one. Determining which alternative ac-
tually occurs is often harder. The following classical result, known as the
Borel–Cantelli lemma, may then be helpful, especially when the events are
independent. An extension to the general case appears in Corollary 6.20.
Theorem 2.18 (Borel, Cantelli) Let A1, A2, . . . ∈A. Then
	
n PAn < ∞
implies P{An i.o.} = 0, and the two conditions are equivalent when the An
are independent.
Here the ﬁrst assertion was proved earlier as an application of Fatou’s
lemma. The use of expected values allows a more transparent argument.
Proof: If 	
n PAn < ∞, we get by monotone convergence
E

n1An =

nE1An =

nPAn < ∞.
Thus, 	
n 1An < ∞a.s., which means that P{An i.o.} = 0.
Next assume that the An are independent and satisfy
	
n PAn = ∞.
Noting that 1 −x ≤e−x for all x, we get
P

k≥nAk
=
1 −P

k≥nAc
k = 1 −

k≥nPAc
k
=
1 −

k≥n(1 −PAk) ≥1 −

k≥n exp(−PAk)
=
1 −exp

−

k≥nPAk

= 1.
Hence, as n →∞,
1 = P

k≥nAk ↓P

n

k≥nAk = P{An i.o.},
and so the probability on the right equals 1.
✷

2. Processes, Distributions, and Independence
33
For many purposes it is suﬃcient to use the Lebesgue unit interval ([0, 1],
B[0, 1], λ) as the basic probability space.
In particular, the following re-
sult ensures the existence on [0, 1] of some independent random variables
ξ1, ξ2, . . . with arbitrarily prescribed distributions. The present statement is
only preliminary. Thus, we shall remove the independence assumption in
Theorem 5.14, prove an extension to arbitrary index sets in Theorem 5.16,
and eliminate the restriction on the spaces in Theorem 5.17.
Theorem 2.19 (existence, Borel) For any probability measures µ1, µ2, . . .
on some Borel spaces S1, S2, . . . , there exist some independent random ele-
ments ξ1, ξ2, . . . on ([0, 1], λ) with distributions µ1, µ2, . . . .
In particular, there exists some probability measure µ on S1 × S2 × · · ·
with
µ ◦(π1, . . . , πn)−1 = µ1 ⊗· · · ⊗µn,
n ∈N.
For the proof we shall ﬁrst consider two special cases of independent interest.
The random variables ξ1, ξ2, . . . are said to form a Bernoulli sequence
with rate p if they are i.i.d. with P{ξn = 1} = 1 −P{ξn = 0} = p. We
shall further say that a random variable ϑ is uniformly distributed on [0, 1]
(written as U(0, 1)) if P ◦ϑ−1 equals Lebesgue measure λ on [0, 1].
By
the binary expansion of a number x ∈[0, 1], we mean the unique sequence
r1, r2, . . . ∈{0, 1} with sum 0 or ∞such that x =
	
n rn2−n. The following
result provides a simple construction of a Bernoulli sequence on the Lebesgue
unit interval.
Lemma 2.20 (Bernoulli sequence) Let ϑ be a random variable in [0, 1] with
binary expansion ξ1, ξ2, . . . . Then ϑ is U(0, 1) iﬀthe ξn form a Bernoulli
sequence with rate 1
2.
Proof: If ϑ is U(0, 1), then P 
j≤n{ξj = kj} = 2−n for all k1, . . . , kn ∈
{0, 1}. Summing over k1, . . . , kn−1, we get P{ξn = k} = 1
2 for k = 0 and 1.
A similar calculation yields the asserted independence.
Now assume instead that the ξn form a Bernoulli sequence with rate
1
2.
Letting ˜ϑ be U(0, 1) with binary expansion ˜ξ1, ˜ξ2, . . . , we get (ξn)
d= (˜ξn).
Thus,
ϑ =

nξn2−n d=

n˜ξn2−n = ˜ϑ.
✷
The next result shows how a single U(0, 1) random variable can be used
to generate a whole sequence.
Lemma 2.21 (duplication) There exist some measurable functions f1, f2,
. . . on [0, 1] such that whenever ϑ is U(0, 1), the random variables ϑn = fn(ϑ)
are i.i.d. U(0, 1).

34
Foundations of Modern Probability
Proof: Introduce for every x ∈[0, 1] the associated binary expansion
g1(x), g2(x), . . . , and note that the gk are measurable. Rearrange the gk into
a two-dimensional array hnj, n, j ∈N, and deﬁne
fn(x) =

j2−jhnj(x),
x ∈[0, 1], n ∈N.
By Lemma 2.20 the random variables gk(ϑ) form a Bernoulli sequence with
rate 1
2, and the same result shows that the variables ϑn = fn(ϑ) are U(0, 1).
The latter are further independent by Corollary 2.7.
✷
Finally, we need to construct a random element with arbitrary distribu-
tion from a given randomization variable. The required lemma will be stated
in a version for kernels, in view of our needs in Chapters 5, 7, and 12.
Lemma 2.22 (kernels and randomization)
Let µ be a probability kernel
from a measurable space S to a Borel space T. Then there exists some mea-
surable function f : S × [0, 1] →T such that if ϑ is U(0, 1), then f(s, ϑ) has
distribution µ(s, ·) for every s ∈S.
Proof: We may assume that T is a Borel subset of [0, 1], in which case we
may easily reduce to the case when T = [0, 1]. Deﬁne
f(s, t) = sup{x ∈[0, 1]; µ(s, [0, x]) < t},
s ∈S, t ∈[0, 1],
(9)
and note that f is product measurable on S × [0, 1], since the set {(s, t);
µ(s, [0, x]) < t} is measurable for each x by Lemma 1.12, and the supremum
in (9) can be restricted to rational x. If ϑ is U(0, 1), we get
P{f(s, ϑ) ≤x} = P{ϑ ≤µ(s, [0, x])} = µ(s, [0, x]),
x ∈[0, 1],
and so f(s, ϑ) has distribution µ(s, ·) by Lemma 2.3.
✷
Proof of Theorem 2.19: By Lemma 2.22 there exist some measurable
functions fn : [0, 1] →Sn such that λ ◦f −1
n
= µn. Letting ϑ be the identity
mapping on [0, 1] and choosing ϑ1, ϑ2, . . . as in Lemma 2.21, we note that the
functions ξn = fn(ϑn), n ∈N, have the desired joint distribution.
✷
Next we shall discuss the regularization and sample path properties of
random processes. Two processes X and Y on a common index set T are
said to be versions of each other if Xt = Yt a.s. for each t ∈T. In the special
case when T = Rd or R+, we note that two continuous or right-continuous
versions X and Y of the same process are indistinguishable, in the sense that
X ≡Y a.s. In general, the latter notion is clearly stronger.
For any function f between two metric spaces (S, ρ) and (S′, ρ′), the
associated modulus of continuity wf = w(f, ·) is given by
wf(r) = sup{ρ′(fs, ft); s, t ∈S, ρ(s, t) ≤r},
r > 0.

2. Processes, Distributions, and Independence
35
Note that f is uniformly continuous iﬀwf(r) →0 as r →0. Say that f is
H¨older continuous with exponent c if wf(r) <
⌢rc as r →0. The property
is said to hold locally if it is true on every bounded set. Here and in the
sequel, we are using the relation f <
⌢g between positive functions to mean
that f ≤cg for some constant c < ∞.
A simple moment condition ensures the existence of a H¨older-continuous
version of a given process on Rd. Important applications are given in Theo-
rems 11.5, 18.3, and 19.4, and a related tightness criterion appears in Corol-
lary 14.9.
Theorem 2.23 (moments and continuity, Kolmogorov, Lo`eve, Chentsov)
Let X be a process on Rd with values in a complete metric space (S, ρ),
and assume for some a, b > 0 that
E{ρ(Xs, Xt)}a <
⌢|s −t|d+b,
s, t ∈Rd.
(10)
Then X has a continuous version, and for any c ∈(0, b/a) the latter is a.s.
locally H¨older continuous with exponent c.
Proof: It is clearly enough to consider the restriction of X to [0, 1]d.
Deﬁne
Dn = {(k1, . . . , kd)2−n; k1, . . . , kn ∈{1, . . . , 2n}},
n ∈N,
and let
ξn = max{ρ(Xs, Xt); s, t ∈Dn, |s −t| = 2−n},
n ∈N.
Since
|{(s, t) ∈D2
n; |s −t| = 2−n}| ≤d2dn,
n ∈N,
we get by (10), for any c ∈(0, b/a),
E

n
(2cnξn)a =

n
2acnEξa
n <
⌢

n
2acn2dn(2−n)d+b =

n
2(ac−b)n < ∞.
The sum on the left is then a.s. convergent, and therefore ξn <
⌢2−cn a.s.
Now any two points s, t ∈
n Dn with |s −t| ≤2−m can be connected by a
piecewise linear path involving, for each n ≥m, at most 2d steps between
nearest neighbors in Dn. Thus, for r ∈[2−m−1, 2−m],
sup

ρ(Xs, Xt); s, t ∈

nDn, |s −t| ≤r

<
⌢

n≥mξn <
⌢

n≥m2−cn <
⌢2−cm <
⌢rc,
which shows that X is a.s. H¨older continuous on 
n Dn with exponent c.
In particular, there exists a continuous process Y on [0, 1]d that agrees
with X a.s. on 
n Dn, and it is easily seen that the H¨older continuity of Y on

n Dn extends with the same exponent c to the entire cube [0, 1]d. To show
that Y is a version of X, ﬁx any t ∈[0, 1]d, and choose t1, t2, . . . ∈

n Dn

36
Foundations of Modern Probability
with tn →t. Then Xtn = Ytn a.s. for each n. Furthermore, Xtn
P→Xt by
(10) and Ytn →Yt a.s. by continuity, so Xt = Yt a.s.
✷
The next result shows how regularity of the paths may sometimes be
established by comparison with a regular process.
Lemma 2.24 (transfer of regularity) Let X
d= Y be random processes on
some index set T, taking values in a separable metric space S, and assume
that Y has paths in some set U ⊂ST that is Borel for the σ-ﬁeld U =
(B(S))T ∩U. Then even X has a version with paths in U.
Proof: For clarity we may write ˜Y for the path of Y , regarded as a random
element in U. Then ˜Y is Y -measurable, and by Lemma 1.13 there exists a
measurable mapping f : ST →U such that ˜Y = f(Y ) a.s. Deﬁne ˜X = f(X),
and note that ( ˜X, X) d= (˜Y , Y ). Since the diagonal in S2 is measurable, we
get in particular
P{ ˜Xt = Xt} = P{˜Yt = Yt} = 1,
t ∈T.
✷
We conclude this chapter with a characterization of distribution functions
in Rd, required in Chapter 4. For any vectors x = (x1, . . . , xd) and y =
(y1, . . . , yd), write x ≤y for the componentwise inequality xk ≤yk, k =
1, . . . , d, and similarly for x < y. In particular, the distribution function F
of a probability measure µ on Rd is given by F(x) = µ{y; y ≤x}. Similarly,
let x ∨y denote the componentwise maximum.
Put 1 = (1, . . . , 1) and
∞= (∞, . . . , ∞).
For any rectangular box (x, y] = {u; x < u ≤y} = (x1, y1] × · · · ×
(xd, yd] we note that µ(x, y] =
	
u s(u)F(u), where s(u) = (−1)p with p =
	
k 1{uk = yk}, and the summation extends over all corners u of (x, y]. Let
F(x, y] denote the stated sum and say that F has nonnegative increments if
F(x, y] ≥0 for all pairs x < y. Let us further say that F is right-continuous
if F(xn) →F(x) as xn ↓x and proper if F(x) →1 or 0 as mink xk →±∞,
respectively.
The following result characterizes distribution functions in terms of the
mentioned properties.
Theorem 2.25 (distribution functions) A function F : Rd →[0, 1] is the
distribution function of some probability measure µ on Rd iﬀit is right con-
tinuous and proper with nonnegative increments.
Proof: The set function F(x, y] is clearly ﬁnitely additive. Since F is
proper, we further have F(x, y] →1 as x →−∞and y →∞, that is, as
(x, y] ↑(−∞, ∞) = Rd. Hence, for every n ∈N there exists a probability
measure µn on (2−nZ)d with Z = {. . . , −1, 0, 1, . . .} such that
µn{2−nk} = F(2−n(k −1), 2−nk],
k ∈Zd, n ∈N.

2. Processes, Distributions, and Independence
37
From the ﬁnite additivity of F(x, y] we obtain
µm(2−m(k −1, k]) = µn(2−m(k −1, k]),
k ∈Zd, m < n in N.
(11)
By successive division of the Lebesgue unit interval ([0, 1], B[0, 1], λ), we
may construct some random vectors ξ1, ξ2, . . . with distributions µ1, µ2, . . .
such that ξm −2−m < ξn ≤ξm for all m < n, which is possible because of
(11). In particular, ξ1 ≥ξ2 ≥· · · ≥ξ1 −1, and so ξn converges pointwise to
some random vector ξ. Deﬁne µ = λ ◦ξ−1.
To see that µ has distribution function F, we note that since F is proper
λ{ξn ≤2−nk} = µn(−∞, 2−nk] = F(2−nk),
k ∈Zd, n ∈N.
Since, moreover, ξn ↓ξ a.s., Fatou’s lemma yields for dyadic x ∈Rd
λ{ξ < x}
=
λ{ξn < x ult.} ≤lim infnλ{ξn < x}
≤
F(x) = lim supnλ{ξn ≤x}
≤
λ{ξn ≤x i.o.} ≤λ{ξ ≤x},
and so
F(x) ≤λ{ξ ≤x} ≤F(x + 2−n1),
n ∈N.
Letting n →∞and using the right-continuity of F, we get λ{ξ ≤x} = F(x),
which extends to any x ∈Rd by the right-continuity of both sides.
✷
The last result has the following version for unbounded measures.
Corollary 2.26 (unbounded measures) Let the function F on Rd be right-
continuous with nonnegative increments. Then there exists some measure µ
on Rd such that µ(x, y] = F(x, y] for all x ≤y in Rd.
Proof: For each a ∈Rd we may apply Theorem 2.25 to suitably normal-
ized versions of the function Fa(x) = F(a, a ∨x], to obtain a measure µa
on [a, ∞) with µa(a, x] = F(a, x] for all x > a. In particular, µa = µb on
(a ∨b, ∞) for all a and b, and we note that µ = supa µa is a measure with
the desired property.
✷
Exercises
1. Give an example of two processes X and Y with diﬀerent distributions
such that Xt
d= Yt for all t.
2. Let X and Y be {0, 1}-valued processes on some index set T. Show
that X
d= Y iﬀP{Xt1 +· · ·+Xtn > 0} = P{Yt1 +· · ·+Ytn > 0} for all n ∈N
and t1, . . . , tn ∈T.

38
Foundations of Modern Probability
3. Let F be a right-continuous function of bounded variation and with
F(−∞) = 0. Show for any random variable ξ that EF(ξ) =
 P{ξ ≥t}
F(dt). (Hint: First take F to be the distribution function of some random
variable η⊥⊥ξ, and use Lemma 2.11.)
4. Consider a random variable ξ ∈L1 and a strictly convex function f
on R. Show that Ef(ξ) = f(Eξ) iﬀξ = Eξ a.s.
5. Assume that ξ = 	
j ajξj and η =
	
j bjηj, where the sums converge
in L2. Show that cov(ξ, η) =
	
i,j aibjcov(ξi, ηj), where the double series on
the right is absolutely convergent.
6. Let the σ-ﬁelds Ft,n, t ∈T, n ∈N, be nondecreasing in n for each t
and independent in t for each n. Show that the independence extends to the
σ-ﬁelds Ft =

n Ft,n.
7. For each t ∈T, let ξt, ξt
1, ξt
2, . . . be random elements in some metric
space St with ξt
n →ξt a.s., and assume for each n ∈N that the random ele-
ments ξt
n are independent. Show that the independence extends to the limits
ξt. (Hint: First show that E

t∈S ft(ξt) =

t∈S Eft(ξt) for any bounded,
continuous functions ft on St and for ﬁnite subsets S ⊂T.)
8. Give an example of three events that are pairwise independent but
not independent.
9. Give an example of two random variables that are uncorrelated but
not independent.
10. Let ξ1, ξ2, . . . be i.i.d. random elements with distribution µ in some
measurable space (S, S).
Fix a set A ∈S with µA > 0, and put τ =
inf{k; ξk ∈A}. Show that ξτ has distribution µ[ · |A] = µ(· ∩A)/µA.
11. Let ξ1, ξ2, . . . be independent random variables taking values in [0, 1].
Show that E 
n ξn =

n Eξn. In particular, show that P

n An =

n PAn
for any independent events A1, A2, . . . .
12. Let ξ1, ξ2, . . . be arbitrary random variables. Show that there exist
some constants c1, c2, . . . > 0 such that the series
	
n cnξn converges a.s.
13. Let ξ1, ξ2, . . . be random variables with ξn →0 a.s. Show that there
exists some measurable function f > 0 with 	
n f(ξn) < ∞a.s. Also show
that the conclusion fails if we only assume L1-convergence.
14. Give an example of events A1, A2, . . . such that P{An i.o.} = 0 but
	
n PAn = ∞.
15. Extend Lemma 2.20 to a correspondence between U(0, 1) random
variables ϑ and Bernoulli sequences ξ1, ξ2, . . . with rate p ∈(0, 1).
16. Give an elementary proof of Theorem 2.25 for d = 1. (Hint: Deﬁne
ξ = F −1(ϑ), where ϑ is U(0, 1), and note that ξ has distribution function F.)

Chapter 3
Random Sequences, Series,
and Averages
Convergence in probability and in Lp; uniform integrability and
tightness; convergence in distribution; convergence of random se-
ries; strong laws of large numbers; Portmanteau theorem; contin-
uous mapping and approximation; coupling and measurability
The ﬁrst goal of this chapter is to introduce and compare the basic modes of
convergence of random quantities. For random elements ξ and ξ1, ξ2, . . . in a
metric or topological space S, the most commonly used notions are those of
almost sure convergence, ξn →ξ a.s., and convergence in probability, ξn
P→ξ,
corresponding to the general notions of convergence a.e. and in measure,
respectively. When S = R, we have the additional concept of Lp-convergence,
familiar from Chapter 1. Those three notions are used throughout this book.
For a special purpose in Chapter 22, we shall also need the notion of weak
L1-convergence.
For our second main topic, we shall study the very diﬀerent concept
of convergence in distribution, ξn
d→ξ, deﬁned by the condition Ef(ξn) →
Ef(ξ) for all bounded, continuous functions f on S. This is clearly equivalent
to weak convergence of the associated distributions µn = P ◦ξ−1
n
and µ =
P ◦ξ−1, written as µn
w→µ and deﬁned by the condition µnf →µf for every
f as above. In this chapter we shall only establish the most basic results of
weak convergence theory, such as the “Portmanteau” theorem, the continuous
mapping and approximation theorems, and the Skorohod coupling.
Our
development of the general theory continues in Chapters 4 and 14, and further
distributional limit theorems appear in Chapters 7, 8, 10, 12, 13, 17, and 20.
Our third main theme is to characterize the convergence of series 	
k ξk
and averages n−c 	
k≤n ξk, where ξ1, ξ2, . . . are independent random variables
and c is a positive constant. The two problems are related by the elementary
Kronecker lemma, and the main results are the basic three-series criterion
and the strong law of large numbers. The former result is extended in Chap-
ter 6 to the powerful martingale convergence theorem, whereas extensions
and reﬁnements of the latter result are proved in Chapters 9 and 12. The
mentioned theorems are further related to certain weak convergence results
presented in Chapters 4 and 13.
Before beginning our systematic study of the various notions of conver-
gence, we shall establish a couple of elementary but useful inequalities.
39

40
Foundations of Modern Probability
Lemma 3.1 (moments and tails, Bienaym´e, Chebyshev, Paley and Zyg-
mund) Let ξ be an R+-valued random variable with 0 < Eξ < ∞. Then
(1 −r)2
+
(Eξ)2
Eξ2
≤P{ξ > rEξ} ≤1
r,
r > 0.
(1)
The second relation in (1) is often referred to as Chebyshev’s or Markov’s
inequality. Assuming that Eξ2 < ∞, we get in particular the well-known
estimate
P{|ξ −Eξ| > ε} ≤ε−2var(ξ),
ε > 0.
Proof of Lemma 3.1: We may clearly assume that Eξ = 1. The upper
bound then follows as we take expectations in the inequality r1{ξ > r} ≤ξ.
To get the lower bound, we note that for any r, t > 0
t21{ξ > r} ≥(ξ −r)(2t + r −ξ) = 2ξ(r + t) −r(2t + r) −ξ2.
Taking expected values, we get for r ∈(0, 1)
t2P{ξ > r} ≥2(r + t) −r(2t + r) −Eξ2 ≥2t(1 −r) −Eξ2.
Now choose t = Eξ2/(1 −r).
✷
For random elements ξ and ξ1, ξ2, . . . in a metric space (S, ρ), we say that
ξn converges in probability to ξ (written as ξn
P→ξ) if
lim
n→∞P{ρ(ξn, ξ) > ε} = 0,
ε > 0.
By Chebyshev’s inequality it is equivalent that E[ρ(ξn, ξ) ∧1] →0. This
notion of convergence is related to the a.s. version as follows.
Lemma 3.2 (subsequence criterion) Let ξ, ξ1, ξ2, . . . be random elements in
a metric space (S, ρ). Then ξn
P→ξ iﬀevery subsequence N ′ ⊂N has a
further subsequence N ′′ ⊂N ′ such that ξn →ξ a.s. along N ′′. In particular,
ξn →ξ a.s. implies ξn
P→ξ.
In particular, the notion of convergence in probability depends only on
the topology and is independent of the choice of metric ρ.
Proof: Assume that ξn
P→ξ, and ﬁx an arbitrary subsequence N ′ ⊂N.
We may then choose a further subsequence N ′′ ⊂N ′ such that
E

n∈N′′
{ρ(ξn, ξ) ∧1} =

n∈N′′
E[ρ(ξn, ξ) ∧1] < ∞,
where the equality holds by monotone convergence. The series on the left
then converges a.s., which implies ξn →ξ a.s. along N ′′.

3. Random Sequences, Series, and Averages
41
Now assume instead the stated condition. If ξn ̸
P→ξ, there exists some
ε > 0 such that E[ρ(ξn, ξ) ∧1] > ε along a subsequence N ′ ⊂N. By hypoth-
esis, ξn →ξ a.s. along a further subsequence N ′′ ⊂N ′, and by dominated
convergence we get E[ρ(ξn, ξ) ∧1] →0 along N ′′, a contradiction.
✷
For a ﬁrst application, we shall see how convergence in probability is
preserved by continuous mappings.
Lemma 3.3 (continuous mappings) Fix two metric spaces S and T. Let
ξ, ξ1, ξ2, . . . be random elements in S with ξn
P→ξ, and consider a measurable
mapping f : S →T such that f is a.s. continuous at ξ. Then f(ξn)
P→f(ξ).
Proof: Fix any subsequence N ′ ⊂N. By Lemma 3.2 we have ξn →ξ
a.s. along some further subsequence N ′′ ⊂N ′, and by continuity we get
f(ξn) →f(ξ) a.s. along N ′′. Hence, f(ξn)
P→f(ξ) by Lemma 3.2.
✷
Now consider for each k ∈N a metric space (Sk, ρk), and introduce the
product space S = XkSk = S1 ×S2 ×· · · endowed with the product topology,
a convenient metrization of which is given by
ρ(x, y) =

k2−k{ρk(xk, yk) ∧1},
x, y ∈XkSk.
(2)
If each Sk is separable, then B(S) =

k B(Sk) by Lemma 1.2, and so a
random element in S is simply a sequence of random elements in Sk, k ∈N.
Lemma 3.4 (random sequences) Fix any separable metric spaces S1, S2, . . . ,
and let ξ = (ξ1, ξ2, . . .) and ξn = (ξn
1 , ξn
2 , . . .), n ∈N, be random elements in
XkSk. Then ξn
P→ξ iﬀξn
k
P→ξk in Sk for each k.
Proof: With ρ as in (2), we get for each n ∈N
E[ρ(ξn, ξ) ∧1] = Eρ(ξn, ξ) =

k2−kE[ρk(ξn
k , ξk) ∧1].
Thus, by dominated convergence E[ρ(ξn, ξ) ∧1] →0 iﬀE[ρk(ξn
k , ξk) ∧1] →0
for all k.
✷
Combining the last two lemmas, it is easily seen how convergence in
probability is preserved by the basic arithmetic operations.
Corollary 3.5 (elementary operations) Let ξ, ξ1, ξ2, . . . and η, η1, η2, . . . be
random variables with ξn
P→ξ and ηn
P→η. Then aξn + bηn
P→aξ + bη for
all a, b ∈R, and ξnηn
P→ξη. Furthermore, ξn/ηn
P→ξ/η whenever a.s. η ̸= 0
and ηn ̸= 0 for all n.

42
Foundations of Modern Probability
Proof: By Lemma 3.4 we have (ξn, ηn)
P→(ξ, η) in R2, so the results for
linear combinations and products follow by Lemma 3.3. To prove the last as-
sertion, we may apply Lemma 3.3 to the function f : (x, y) →(x/y)1{y ̸= 0},
which is clearly a.s. continuous at (ξ, η).
✷
Let us next examine the associated completeness properties.
For any
random elements ξ1, ξ2, . . . in a metric space (S, ρ), we say that (ξn) is Cauchy
(convergent) in probability if ρ(ξm, ξn)
P→0 as m, n →∞, in the sense that
E[ρ(ξm, ξn) ∧1] →0.
Lemma 3.6 (completeness) Let ξ1, ξ2, . . . be random elements in some com-
plete metric space (S, ρ). Then (ξn) is Cauchy in probability or a.s. iﬀξn
P→ξ
or ξn →ξ a.s., respectively, for some random element ξ in S.
Proof: The a.s. case is immediate from Lemma 1.10. Assuming ξn
P→ξ,
we get
E[ρ(ξm, ξn) ∧1] ≤E[ρ(ξm, ξ) ∧1] + E[ρ(ξn, ξ) ∧1] →0,
which means that (ξn) is Cauchy in probability.
Now assume instead the latter condition. Deﬁne
nk = inf

n ≥k; supm≥nE[ρ(ξm, ξn) ∧1] ≤2−k
,
k ∈N.
The nk are ﬁnite and satisfy
E

k{ρ(ξnk, ξnk+1) ∧1} ≤

k2−k < ∞,
and so 	
k ρ(ξnk, ξnk+1) < ∞a.s. The sequence(ξnk) is then a.s. Cauchy and
converges a.s. toward some measurable limit ξ. To see that ξn
P→ξ, write
E[ρ(ξm, ξ) ∧1] ≤E[ρ(ξm, ξnk) ∧1] + E[ρ(ξnk, ξ) ∧1],
and note that the right-hand side tends to zero as m, k →∞, by the Cauchy
convergence of (ξn) and dominated convergence.
✷
Next consider any probability measures µ and µ1, µ2, . . . on some metric
space (S, ρ) with Borel σ-ﬁeld S, and say that µn converges weakly to µ
(written as µn
w→µ) if µnf →µf for every f ∈Cb(S), the class of bounded,
continuous functions f : S →R. If ξ and ξ1, ξ2, . . . are random elements in
S, we further say that ξn converges in distribution to ξ (written as ξn
d→ξ) if
P ◦ξ−1
n
w→P ◦ξ−1, that is, if Ef(ξn) →Ef(ξ) for all f ∈Cb(S). Note that the
latter mode of convergence depends only on the distributions and that ξ and
the ξn need not even be deﬁned on the same probability space. To motivate
the deﬁnition, note that xn →x in a metric space S iﬀf(xn) →f(x) for all
continuous functions f : S →R, and also that P ◦ξ−1 is determined by the
integrals Ef(ξ) for all f ∈Cb(S).
The following result gives a connection between convergence in probability
and in distribution.

3. Random Sequences, Series, and Averages
43
Lemma 3.7 (convergence in probability and in distribution) Let ξ, ξ1, ξ2, . . .
be random elements in some metric space (S, ρ). Then ξn
P→ξ implies ξn
d→
ξ, and the two conditions are equivalent when ξ is a.s. constant.
Proof: Assume ξn
P→ξ.
For any f ∈Cb(S) we need to show that
Ef(ξn) →Ef(ξ). If the convergence fails, we may choose some subsequence
N ′ ⊂N such that infn∈N′ |Ef(ξn) −Ef(ξ)| > 0. By Lemma 3.2 there ex-
ists a further subsequence N ′′ ⊂N ′ such that ξn →ξ a.s. along N ′′. By
continuity and dominated convergence we get Ef(ξn) →Ef(ξ) along N ′′, a
contradiction.
Conversely, assume that ξn
d→s ∈S. Since ρ(x, s) ∧1 is a bounded and
continuous function of x, we get E[ρ(ξn, s) ∧1] →E[ρ(s, s) ∧1] = 0, and so
ξn
P→s.
✷
A family of random vectors ξt, t ∈T, in Rd is said to be tight if
lim
r→∞sup
t∈T P{|ξt| > r} = 0.
For sequences (ξn) the condition is clearly equivalent to
lim
r→∞lim sup
n→∞P{|ξn| > r} = 0,
(3)
which is often easier to verify. Tightness plays an important role for the
compactness methods developed in Chapters 4 and 14. For the moment we
shall note only the following simple connection with weak convergence.
Lemma 3.8 (weak convergence and tightness) Let ξ, ξ1, ξ2, . . . be random
vectors in Rd satisfying ξn
d→ξ. Then (ξn) is tight.
Proof: Fix any r > 0, and deﬁne f(x) = (1 −(r −|x|)+)+. Then
lim sup
n→∞P{|ξn| > r} ≤lim
n→∞Ef(ξn) = Ef(ξ) ≤P{|ξ| > r −1}.
Here the right-hand side tends to 0 as r →∞, and (3) follows.
✷
We may further note the following simple relationship between tightness
and convergence in probability.
Lemma 3.9 (tightness and convergence in probability) Let ξ1, ξ2, . . . be ran-
dom vectors in Rd.
Then (ξn) is tight iﬀcnξn
P→0 for any constants
c1, c2, . . . ≥0 with cn →0.
Proof: Assume (ξn) to be tight, and let cn →0. Fixing any r, ε > 0, and
noting that cnr ≤ε for all but ﬁnitely many n ∈N, we get
lim sup
n→∞P{|cnξn| > ε} ≤lim sup
n→∞P{|ξn| > r}.

44
Foundations of Modern Probability
Here the right-hand side tends to 0 as r →∞, so P{|cnξn| > ε} →0.
Since ε was arbitrary, we get cnξn
P→0. If instead (ξn) is not tight, we may
choose a subsequence (nk) ⊂N such that infk P{|ξnk| > k} > 0. Letting
cn = sup{k−1; nk ≥n}, we note that cn →0 and yet P{|cnkξnk| > 1} ̸→0.
Thus, the stated condition fails.
✷
We turn to a related notion for expected values. A family of random
variables ξt, t ∈T, is said to be uniformly integrable if
lim
r→∞sup
t∈T E[|ξt|; |ξt| > r] = 0.
(4)
For sequences (ξn) in L1, this is clearly equivalent to
lim
r→∞lim sup
n→∞E[|ξn|; |ξn| > r] = 0.
(5)
Condition (4) holds in particular if the ξt are Lp-bounded for some p > 1, in
the sense that supt E|ξt|p < ∞. To see this, it suﬃces to write
E[|ξt|; |ξt| > r] ≤r−p+1E|ξt|p,
r, p > 0.
The next result gives a useful characterization of uniform integrability.
For motivation we note that if ξ is an integrable random variable, then
E[|ξ|; A] →0 as PA →0, by Lemma 3.2 and dominated convergence. The
latter condition means that supA∈A,PA<ε E[|ξ|; A] →0 as ε →0.
Lemma 3.10 (uniform integrability) The random variables ξt, t ∈T, are
uniformly integrable iﬀsupt E|ξt| < ∞and
lim
PA→0 sup
t∈T E[|ξt|; A] = 0.
(6)
Proof: Assume the ξt to be uniformly integrable, and write
E[|ξt|; A] ≤rPA + E[|ξt|; |ξt| > r],
r > 0.
Here (6) follows as we let PA →0 and then r →∞. To get the boundedness
in L1, it suﬃces to take A = Ωand choose r > 0 large enough.
Conversely, let the ξt be L1-bounded and satisfy (6). By Chebyshev’s
inequality we get as r →∞
suptP{|ξt| > r} ≤r−1suptE|ξt| →0,
and so (4) follows from (6) with A = {|ξt| > r}.
✷
The relevance of uniform integrability for the convergence of moments
is clear from the following result, which also contains a weak convergence
version of Fatou’s lemma.

3. Random Sequences, Series, and Averages
45
Lemma 3.11 (convergence of means) Let ξ, ξ1, ξ2, . . . be R+-valued random
variables with ξn
d→ξ. Then Eξ ≤lim infn Eξn, and furthermore Eξn →
Eξ < ∞iﬀ(5) holds.
Proof: For any r > 0 the function x →x ∧r is bounded and continuous
on R+. Thus,
lim inf
n→∞Eξn ≥lim
n→∞E(ξn ∧r) = E(ξ ∧r),
and the ﬁrst assertion follows as we let r →∞. Next assume (5), and note
in particular that Eξ ≤lim infn Eξn < ∞. For any r > 0 we get
|Eξn −Eξ|
≤
|Eξn −E(ξn ∧r)| + |E(ξn ∧r) −E(ξ ∧r)|
+ |E(ξ ∧r) −Eξ|.
Letting n →∞and then r →∞, we obtain Eξn →Eξ. Now assume instead
that Eξn →Eξ < ∞. Keeping r > 0 ﬁxed, we get as n →∞
E[ξn; ξn > r] ≤E[ξn −ξn ∧(r −ξn)+] →E[ξ −ξ ∧(r −ξ)+].
Since x ∧(r −x)+ ↑x as r →∞, the right-hand side tends to zero by domi-
nated convergence, and (5) follows.
✷
We may now examine the relationship between convergence in Lp and in
probability.
Proposition 3.12 (Lp-convergence) Fix any p > 0, and let ξ, ξ1, ξ2, . . . ∈
Lp with ξn
P→ξ. Then these conditions are equivalent:
(i) ξn →ξ in Lp;
(ii) ∥ξn∥p →∥ξ∥p;
(iii) the variables |ξn|p, n ∈N, are uniformly integrable.
Conversely, (i) implies ξn
P→ξ.
Proof: First assume that ξn →ξ in Lp. Then ∥ξn∥p →∥ξ∥p by Lemma
1.30, and by Lemma 3.1 we have, for any ε > 0,
P{|ξn −ξ| > ε} = P{|ξn −ξ|p > εp} ≤ε−p∥ξn −ξ∥p
p →0.
Thus, ξn
P→ξ. For the remainder of the proof we may assume that ξn
P→ξ. In
particular, |ξn|p
d→|ξ|p by Lemmas 3.3 and 3.7, so (ii) and (iii) are equivalent
by Lemma 3.11. Next assume (ii). If (i) fails, there exists some subsequence
N ′ ⊂N with infn∈N′ ∥ξn −ξ∥p > 0. By Lemma 3.2 we may choose a further
subsequence N ′′ ⊂N ′ such that ξn →ξ a.s. along N ′′. But then Lemma 1.32
yields ∥ξn −ξ∥p →0 along N ′′, a contradiction. Thus, (ii) implies (i), so all
three conditions are equivalent.
✷

46
Foundations of Modern Probability
We shall brieﬂy consider yet another notion of convergence of random
variables. Assuming ξ, ξ1, . . . ∈Lp for some p ∈[1, ∞), we say that ξn →ξ
weakly in Lp if Eξnη →Eξη for every η ∈Lq, where p−1 + q−1 = 1. Taking
η = |ξ|p−1sgn ξ, we get ∥η∥q = ∥ξ∥p−1
p
, so by H¨older’s inequality
∥ξ∥p
p = Eξη = lim
n→∞Eξnη ≤∥ξ∥p−1
p
lim inf
n→∞∥ξn∥p,
which shows that ∥ξ∥p ≤lim infn ∥ξn∥p.
Now recall the well-known fact that any L2-bounded sequence has a sub-
sequence that converges weakly in L2. The following related criterion for
weak compactness in L1 will be needed in Chapter 22.
Lemma 3.13 (weak L1-compactness, Dunford) Every uniformly integrable
sequence of random variables has a subsequence that converges weakly in L1.
Proof: Let (ξn) be uniformly integrable. Deﬁne ξk
n = ξn1{|ξn| ≤k}, and
note that (ξk
n) is L2-bounded in n for each k. By the compactness in L2 and
a diagonal argument, there exist a subsequence N ′ ⊂N and some random
variables η1, η2, . . . such that ξk
n →ηk holds weakly in L2 and then also in
L1, as n →∞along N ′ for ﬁxed k.
Now ∥ηk −ηl∥1 ≤lim infn ∥ξk
n −ξl
n∥1, and by uniform integrability the
right-hand side tends to zero as k, l →∞. Thus, the sequence (ηk) is Cauchy
in L1, so it converges in L1 toward some ξ. By approximation it follows easily
that ξn →ξ weakly in L1 along N ′.
✷
We shall now derive criteria for the convergence of random series, begin-
ning with an important special case.
Proposition 3.14 (series with positive terms) Let ξ1, ξ2, . . . be independent
R+-valued random variables. Then
	
n ξn < ∞a.s. iﬀ
	
n E[ξn ∧1] < ∞.
Proof: Assuming the stated condition, we get E
	
n(ξn ∧1) < ∞by
Fubini’s theorem, so 	
n(ξn ∧1) < ∞a.s. In particular,
	
n 1{ξn > 1} < ∞
a.s., so the series 	
n(ξn ∧1) and
	
n ξn diﬀer by at most ﬁnitely many terms,
and we get 	
n ξn < ∞a.s.
Conversely, assume that 	
n ξn < ∞a.s. Then also
	
n(ξn ∧1) < ∞a.s.,
so we may assume that ξn ≤1 for all n. Noting that 1 −x ≤e−x ≤1 −ax
for x ∈[0, 1] where a = 1 −e−1, we get
0
<
E exp

−

nξn

=

nEe−ξn
≤

n(1 −aEξn) ≤

ne−aEξn = exp

−a

nEξn

,
and so
	
n Eξn < ∞.
✷
To handle more general series, we need the following strengthened ver-
sion of the Bienaym´e–Chebyshev inequality. A further extension appears as
Proposition 6.15.

3. Random Sequences, Series, and Averages
47
Lemma 3.15 (maximum inequality, Kolmogorov) Let ξ1, ξ2, . . . be indepen-
dent random variables with mean zero, and put Sn = ξ1 + · · · + ξn. Then
P{supn|Sn| > r} ≤r−2
nEξ2
n,
r > 0.
Proof: We may assume that
	
n Eξ2
n < ∞. Writing τ = inf{n; |Sn| > r}
and noting that Sk1{τ = k}⊥⊥(Sn −Sk) for k ≤n, we get

k≤nEξ2
k
=
ES2
n ≥

k≤nE[S2
n; τ = k]
≥

k≤n{E[S2
k; τ = k] + 2E[Sk(Sn −Sk); τ = k]}
=

k≤nE[S2
k; τ = k] ≥r2P{τ ≤n}.
As n →∞, we obtain

kEξ2
k ≥r2P{τ < ∞} = r2P{supk|Sk| > r}.
✷
The last result leads easily to the following suﬃcient condition for the
a.s. convergence of random series with independent terms. Conditions that
are both necessary and suﬃcient are given in Theorem 3.18.
Lemma 3.16 (variance criterion for series, Khinchin and Kolmogorov) Let
ξ1, ξ2, . . . be independent random variables with mean 0 and
	
n Eξ2
n < ∞.
Then 	
n ξn converges a.s.
Proof: Write Sn = ξ1 + · · · + ξn. By Lemma 3.15 we get for any ε > 0,
P

supk≥n|Sn −Sk| > ε

≤ε−2
k≥nEξ2
k.
Hence, supk≥n |Sn−Sk|
P→0 as n →∞, and by Lemma 3.2 we get supk≥n |Sn−
Sk| →0 a.s. along a subsequence. Since the last supremum is nonincreasing
in n, the a.s. convergence extends to the entire sequence, which means that
(Sn) is a.s. Cauchy convergent. Thus, Sn converges a.s. by Lemma 3.6.
✷
The next result gives the basic connection between series with positive
and symmetric terms. By ξn
P→∞we mean that P{ξn > r} →1 for every
r > 0.
Theorem 3.17 (positive and symmetric terms) Let ξ1, ξ2, . . . be indepen-
dent, symmetric random variables. Then these conditions are equivalent:
(i)
	
n ξn converges a.s.;
(ii)
	
n ξ2
n < ∞a.s.;
(iii) 	
n E(ξ2
n ∧1) < ∞.
If the conditions fail, then |
	
k≤n ξk|
P→∞.

48
Foundations of Modern Probability
Proof: Conditions (ii) and (iii) are equivalent by Proposition 3.14. Next
assume (iii), and conclude from Lemma 3.16 that 	
n ξn1{|ξn| ≤1} converges
a.s. From (iii) and Fubini’s theorem we further note that 	
n 1{|ξn| > 1} < ∞
a.s., so the series 	
n ξn1{|ξn| ≤1} and
	
n ξn diﬀer by at most ﬁnitely many
terms, and even the latter series must converge a.s. Thus, (iii) implies (i).
We shall complete the proof by showing that if (ii) fails, so that 	
n ξ2
n =
∞a.s. by Kolmogorov’s zero–one law, then |Sn|
P→∞, where Sn =
	
k≤n ξk.
Since the latter condition implies |Sn| →∞a.s. along some subsequence,
even (i) will fail, and so conditions (i) to (iii) are equivalent.
For this part of the proof, it is convenient to introduce an independent
sequence of i.i.d. random variables ϑn with P{ϑn = ±1} = 1
2, and note that
the sequences (ξn) and (ϑn|ξn|) have the same distribution. Letting µ denote
the distribution of the sequence (|ξn|), we get by Lemma 2.11
P{|Sn| > r} =

P


k≤nϑkxk
 > r

µ(dx),
r > 0,
and by dominated convergence it is enough to show that the integrand on
the right tends to 0 for µ-almost every x = (x1, x2, . . .). Since
	
n x2
n = ∞
a.e., this reduces the argument to the case of nonrandom |ξn| = cn, n ∈N.
First assume that (cn) is unbounded. For any r > 0 we may recursively
construct a subsequence (nk) ⊂N such that cn1 > r and cnk > 4
	
j<k cnj for
each k. Then clearly P{	
j≤k ξnj ∈I} ≤2−k for every interval I of length
2r. By convolution we get P{|Sn| ≤r} ≤2−k for all n ≥nk, which shows
that P{|Sn| ≤r} →0.
Next assume that cn ≤c < ∞for all n. Choosing a > 0 so small that
cos x ≤e−ax2 for |x| ≤1, we get for 0 < |t| ≤c−1
0 ≤EeitSn =

k≤n
cos(tck) ≤

k≤n
exp(−at2c2
k) = exp

−at2
k≤nc2
k

→0.
Anticipating the elementary Lemma 4.1 of the next chapter, we again get
P{|Sn| ≤r} →0 for each r > 0.
✷
The problem of characterizing the convergence, a.s. or in distribution, of a
series of independent random variables is solved completely by the following
result. Here we write var[ξ; A] = var(ξ1A).
Theorem 3.18 (three-series criterion, Kolmogorov, L´evy) Let ξ1, ξ2, . . . be
independent random variables. Then 	
n ξn converges a.s. iﬀit converges in
distribution and also iﬀthese conditions are fulﬁlled:
(i) 	
n P{|ξn| > 1} < ∞;
(ii)
	
n E[ξn; |ξn| ≤1] converges;
(iii)
	
n var[ξn; |ξn| ≤1] < ∞.

3. Random Sequences, Series, and Averages
49
For the proof we need the following simple symmetrization inequalities.
Say that m is a median of the random variable ξ if P{ξ > m} ∨P{ξ < m}
≤
1
2. A symmetrization of ξ is deﬁned as a random variable of the form
˜ξ = ξ −ξ′ with ξ′⊥⊥ξ and ξ′
d= ξ. For symmetrized versions of the random
variables ξ1, ξ2, . . . , we require the same properties for the whole sequences
(ξn) and (ξ′
n).
Lemma 3.19 (symmetrization)
Let ˜ξ be a symmetrization of a random
variable ξ with median m. Then
1
2P{|ξ −m| > r} ≤P{|˜ξ| > r} ≤2P{|ξ| > r/2},
r ≥0.
Proof: Assume ˜ξ = ξ −ξ′ as above, and write
{ξ −m > r, ξ′ ≤m} ∪{ξ −m < −r, ξ′ ≥m}
⊂{|˜ξ| > r} ⊂{|ξ| > r/2} ∪{|ξ′| > r/2}.
✷
We also need a simple centering lemma.
Lemma 3.20 (centering) Let the random variables ξ1, ξ2, . . . and constants
c1, c2, . . . be such that both ξn and ξn +cn converge in distribution. Then even
cn converges.
Proof: Assume that ξn
d→ξ.
If cn →±∞along some subsequence
N ′ ⊂N, then clearly ξn + cn
P→±∞along N ′, which contradicts the tight-
ness of ξn + cn. Thus, (cn) must be bounded. Now assume that cn →a and
cn →b along two subsequences N1, N2 ⊂N. Then ξn + cn
d→ξ + a along N1
and ξn + cn
d→ξ + b along N2, so ξ + a d= ξ + b. Iterating this relation, we
get ξ + n(b −a)
d= ξ for arbitrary n ∈Z, which is impossible unless a = b.
Thus, all limit points of (cn) agree, and cn converges.
✷
Proof of Theorem 3.18: Assume conditions (i) through (iii), and deﬁne
ξ′
n = ξn1{|ξn| ≤1}. By (iii) and Lemma 3.16 the series
	
n(ξ′
n −Eξ′
n) con-
verges a.s., so by (ii) the same thing is true for 	
n ξ′
n. Finally, P{ξn ̸= ξ′
n i.o.}
= 0 by (i) and the Borel–Cantelli lemma, so 	
n(ξn−ξ′
n) has a.s. ﬁnitely many
nonzero terms. Hence, even 	
n ξn converges a.s.
Conversely, assume that 	
n ξn converges in distribution. Then Lemma
3.19 shows that the sequence of symmetrized partial sums 	
k≤n ˜ξk is tight,
and so
	
n ˜ξn converges a.s. by Theorem 3.17. In particular, ˜ξn →0 a.s. For
any ε > 0 we obtain 	
n P{|˜ξn| > ε} < ∞by the Borel–Cantelli lemma.
Hence, 	
n P{|ξn −mn| > ε} < ∞by Lemma 3.19, where m1, m2, . . . are
medians of ξ1, ξ2, . . . . Using the Borel–Cantelli lemma again, we get ξn −
mn →0 a.s.
Now let c1, c2, . . . be arbitrary with mn −cn →0. Then even ξn −cn →0
a.s. Putting ηn = ξn1{|ξn −cn| ≤1}, we get a.s. ξn = ηn for all but ﬁnitely

50
Foundations of Modern Probability
many n, and similarly for the symmetrized variables ˜ξn and ˜ηn. Thus, even
	
n ˜ηn converges a.s. Since the ˜ηn are bounded and symmetric, Theorem 3.17
yields 	
n var(ηn) = 1
2
	
n var(˜ηn) < ∞. Thus,
	
n(ηn −Eηn) converges a.s.
by Lemma 3.16, as does the series 	
n(ξn −Eηn). Comparing with the distri-
butional convergence of 	
n ξn, we conclude from Lemma 3.20 that
	
n Eηn
converges. In particular, Eηn →0 and ηn −Eηn →0 a.s., so ηn →0 a.s.,
and then also ξn →0 a.s. Hence, mn →0, so we may take cn = 0 in the
previous argument, and conditions (i) to (iii) follow.
✷
A sequence of random variables ξ1, ξ2, . . . with partial sums Sn is said to
obey the strong law of large numbers if Sn/n converges a.s. to a constant.
If a similar convergence holds in probability, one says that the weak law is
fulﬁlled. The following elementary proposition enables us to convert conver-
gence results for random series into laws of large numbers.
Lemma 3.21 (series and averages, Kronecker) If 	
n n−can converges for
some a1, a2, . . . ∈R and c > 0, then n−c 	
k≤n ak →0.
Proof: Put bn = n−can, and assume that
	
n bn = b.
By dominated
convergence as n →∞,

k≤n
bk −n−c 
k≤n
ak
=

k≤n
(1 −(k/n)c)bk = c

k≤n
bk

 1
k/n xc−1dx
=
c

 1
0 xc−1dx

k≤nx
bk →bc

 1
0 xc−1dx = b,
and the assertion follows since the ﬁrst term on the left tends to b.
✷
The following simple result illustrates the method.
Corollary 3.22 (variance criterion for averages, Kolmogorov) Let ξ1, ξ2, . . .
be independent random variables with mean 0, such that 	
n n−2cEξ2
n < ∞
for some c > 0. Then n−c 	
k≤n ξk →0 a.s.
Proof: The series
	
n n−cξn converges a.s. by Lemma 3.16, and the asser-
tion follows by Lemma 3.21.
✷
In particular, we note that if ξ, ξ1, ξ2, . . . are i.i.d. with Eξ = 0 and Eξ2 <
∞, then n−c 	
k≤n ξk →0 a.s. for any c > 1
2. The statement fails for c = 1
2,
as may be seen by taking ξ to be N(0, 1). The best possible normalization is
given in Corollary 12.8. The next result characterizes the stated convergence
for arbitrary c > 1
2. For c = 1 we recognize the strong law of large numbers.
Corresponding criteria for the weak law are given in Theorem 4.16.

3. Random Sequences, Series, and Averages
51
Theorem 3.23 (strong laws of large numbers, Kolmogorov, Marcinkiewicz
and Zygmund) Let ξ, ξ1, ξ2, . . . be i.i.d. random variables, and ﬁx any p ∈
(0, 2). Then n−1/p 	
k≤n ξk converges a.s. iﬀE|ξ|p < ∞and either p ≤1 or
Eξ = 0. In that case the limit equals Eξ for p = 1 and is otherwise 0.
Proof: Assume that E|ξ|p < ∞and for p ≥1 that even Eξ = 0. Deﬁne
ξ′
n = ξn1{|ξn| ≤n1/p}, and note that by Lemma 2.4

n
P{ξ′
n ̸= ξn} =

n
P{|ξ|p > n} ≤

 ∞
0
P{|ξ|p > t}dt = E|ξ|p < ∞.
By the Borel–Cantelli lemma we get P{ξ′
n ̸= ξn i.o.} = 0, and so ξ′
n = ξn
for all but ﬁnitely many n ∈N a.s.
It is then equivalent to show that
n−1/p 	
k≤n ξ′
k →0 a.s.
By Lemma 3.21 it suﬃces to prove instead that
	
n n−1/pξ′
n converges a.s.
For p < 1, this is clear if we write
E

nn−1/p|ξ′
n|
=

nn−1/pE[|ξ|; |ξ| ≤n1/p]
<
⌢

 ∞
0
t−1/pE[|ξ|; |ξ| ≤t1/p]dt
=
E[|ξ|

 ∞
|ξ|p t−1/pdt] <
⌢E|ξ|p < ∞.
If instead p > 1, it suﬃces by Theorem 3.18 to prove that
	
n n−1/pEξ′
n
converges and
	
n n−2/pvar(ξ′
n) < ∞. Since Eξ′
n = −E[ξ; |ξ| > n1/p], we have
for the former series

nn−1/p|Eξ′
n|
≤

nn−1/pE[|ξ|; |ξ| > n1/p]
≤

 ∞
0
t−1/pE[|ξ|; |ξ| > t1/p]dt
=
E[|ξ|

 |ξ|p
0
t−1/pdt] <
⌢E|ξ|p < ∞.
As for the latter series, we get

nn−2/pvar(ξ′
n)
≤

nn−2/pE(ξ′
n)2
=

nn−2/pE[ξ2; |ξ| ≤n1/p]
<
⌢

 ∞
0
t−2/pE[ξ2; |ξ| ≤t1/p]dt
=
E[ξ2

 ∞
|ξ|p t−2/pdt] <
⌢E|ξ|p < ∞.
If p = 1, then Eξ′
n = E[ξ; |ξ| ≤n] →0 by dominated convergence. Thus,
n−1 	
k≤n Eξ′
k →0, and we may prove instead that n−1 	
k≤n ξ′′
k →0 a.s.,
where ξ′′
n = ξ′
n −Eξ′
n. By Lemma 3.21 and Theorem 3.18 it is then enough
to show that 	
n n−2var(ξ′
n) < ∞, which may be seen as before.

52
Foundations of Modern Probability
Conversely, assume that n−1/pSn = n−1/p 	
k≤n ξk converges a.s. Then
ξn
n1/p = Sn
n1/p −(n −1
n )
1/p
Sn−1
(n −1)1/p →0 a.s.,
and in particular P{|ξn|p > n i.o.} = 0.
Hence, by Lemma 2.4 and the
Borel–Cantelli lemma,
E|ξ|p =

 ∞
0
P{|ξ|p > t}dt ≤1 +

n≥1
P{|ξ|p > n} < ∞.
For p > 1, the direct assertion yields n−1/p(Sn −nEξ) →0 a.s., and so
n1−1/pEξ converges, which implies Eξ = 0.
✷
For a simple application of the law of large numbers, consider an arbitrary
sequence of random variables ξ1, ξ2, . . . , and deﬁne the associated empirical
distributions as the random probability measures ˆµn = n−1 	
k≤n δξk. The
corresponding empirical distribution functions ˆFn are given by
ˆFn(x) = ˆµn(−∞, x] = n−1
k≤n1{ξk ≤x},
x ∈R, n ∈N.
Proposition 3.24 (empirical distribution functions, Glivenko, Cantelli) Let
ξ1, ξ2, . . . be i.i.d. random variables with distribution function F and empirical
distribution functions ˆF1, ˆF2, . . . . Then
lim
n→∞sup
x | ˆFn(x) −F(x)| = 0 a.s.
(7)
Proof: By the law of large numbers we have ˆFn(x) →F(x) a.s. for every
x ∈R. Now ﬁx a ﬁnite partition −∞= x1 < x2 < · · · < xm = ∞. By the
monotonicity of F and ˆFn
sup
x | ˆFn(x) −F(x)| ≤max
k
| ˆFn(xk) −F(xk)| + max
k
|F(xk+1) −F(xk)|.
Letting n →∞and reﬁning the partition indeﬁnitely, we get in the limit
lim sup
n→∞
sup
x | ˆFn(x) −F(x)| ≤sup
x ∆F(x) a.s.,
which proves (7) when F is continuous.
For general F, let ϑ1, ϑ2, . . . be i.i.d. U(0, 1), and deﬁne ηn = g(ϑn) for
each n, where g(t) = sup{x; F(x) < t}. Then ηn ≤x iﬀϑn ≤F(x), and
so (ηn)
d= (ξn).
We may then assume that ξn ≡ηn.
Writing ˆG1, ˆG2, . . .
for the empirical distribution functions of ϑ1, ϑ2, . . ., it is further seen that
ˆFn = ˆGn ◦F. Writing A = F(R), we get a.s. from the result for continuous
F,
sup
x | ˆFn(x) −F(x)| = sup
t∈A | ˆGn(t) −t| ≤sup
t∈[0,1]
| ˆGn(t) −t| →0.
✷

3. Random Sequences, Series, and Averages
53
We turn to a systematic study of convergence in distribution. Although
we are currently mostly interested in distributions on Euclidean spaces, it is
crucial for future applications that we consider the more general setting of
an abstract metric space. In particular, the theory is applied in Chapter 14
to random elements in various function spaces.
Theorem 3.25 (Portmanteau theorem, Alexandrov) For any random ele-
ments ξ, ξ1, ξ2, . . . in a metric space S, these conditions are equivalent:
(i) ξn
d→ξ;
(ii) lim infn P{ξn ∈G} ≥P{ξ ∈G} for any open set G ⊂S;
(iii) lim supn P{ξn ∈F} ≤P{ξ ∈F} for any closed set F ⊂S;
(iv) P{ξn ∈B} →P{ξ ∈B} for any B ∈B(S) with ξ /∈∂B a.s.
A set B ∈B(S) with ξ ̸∈∂B a.s. is often called a ξ-continuity set.
Proof: Assume (i), and ﬁx any open set G ⊂S. Letting f be continuous
with 0 ≤f ≤1G, we get Ef(ξn) ≤P{ξn ∈G}, and (ii) follows as we let
n →∞and then f ↑1G. The equivalence between (ii) and (iii) is clear from
taking complements. Now assume (ii) and (iii). For any B ∈B(S),
P{ξ ∈B◦} ≤lim inf
n→∞P{ξn ∈B} ≤lim sup
n→∞P{ξn ∈B} ≤P{ξ ∈B}.
Here the extreme members agree when ξ /∈∂B a.s., and (iv) follows.
Conversely, assume (iv) and ﬁx any closed set F ⊂S. Write F ε = {s ∈S;
ρ(s, F) ≤ε}. Then the sets ∂F ε ⊂{s; ρ(s, F) = ε} are disjoint, and so
ξ /∈∂F ε for almost every ε > 0. For such an ε we may write P{ξn ∈F} ≤
P{ξ ∈F ε}, and (iii) follows as we let n →∞and then ε →0. Finally,
assume (ii) and let f ≥0 be continuous. By Lemma 2.4 and Fatou’s lemma,
Ef(ξ)
=

 ∞
0
P{f(ξ) > t}dt ≤

 ∞
0
lim inf
n→∞P{f(ξn) > t}dt
≤
lim inf
n→∞

 ∞
0
P{f(ξn) > t}dt = lim inf
n→∞Ef(ξn).
(8)
Now let f be continuous with |f| ≤c < ∞. Applying (8) to c ± f yields
Ef(ξn) →Ef(ξ), which proves (i).
✷
For an easy application, we insert a simple lemma that is needed in Chap-
ter 14.
Lemma 3.26 (subspaces) Fix a metric space (S, ρ) with subspace A ⊂S,
and let ξ, ξ1, ξ2, . . . be random elements in (A, ρ). Then ξn
d→ξ in (A, ρ) iﬀ
the same convergence holds in (S, ρ).

54
Foundations of Modern Probability
Proof: Since ξ, ξ1, ξ2, . . . ∈A, condition (ii) of Theorem 3.25 is equivalent
to
lim inf
n→∞P{ξn ∈A ∩G} ≥P{ξ ∈A ∩G},
G ⊂S open.
By Lemma 1.6, this is precisely condition (ii) of Theorem 3.25 for the sub-
space A.
✷
It is clear directly from the deﬁnitions that convergence in distribution is
preserved by continuous mappings. The following more general statement is
a key result of weak convergence theory.
Theorem 3.27 (continuous mappings, Mann and Wald, Prohorov, Rubin)
Fix two metric spaces S and T, and let ξ, ξ1, ξ2, . . . be random elements in
S with ξn
d→ξ. Consider some measurable mappings f, f1, f2, . . . : S →T
and a measurable set C ⊂S with ξ ∈C a.s. such that fn(sn) →f(s) as
sn →s ∈C. Then fn(ξn)
d→f(ξ).
In particular, we note that if ξn
d→ξ in S and if f : S →T is a.s. contin-
uous at ξ, then f(ξn)
d→f(ξ). The latter frequently used result is commonly
referred to as the continuous mapping theorem.
Proof: Fix any open set G ⊂T, and let s ∈f −1G∩C. By hypothesis there
exist an integer m ∈N and some neighborhood N of s such that fk(s′) ∈G
for all k ≥m and s′ ∈N. Thus, N ⊂

k≥m f −1
k G, and so
f −1G ∩C ⊂

m

k≥mf −1
k G
◦.
Now let µ, µ1, µ2, . . . denote the distributions of ξ, ξ2, ξ2, . . . . By Theorem
3.25 we get
µ(f −1G)
≤
µ

m

k≥mf −1
k G
◦= sup
m µ

k≥mf −1
k G
◦
≤
sup
m lim inf
n→∞µn

k≥m
f −1
k G ≤lim inf
n→∞µn(f −1
n G).
Using the same theorem again gives µn ◦f −1
n
w→µ ◦f −1, which means that
fn(ξn)
d→f(ξ).
✷
We will now prove an equally useful approximation theorem. Here the
idea is to prove ξn
d→ξ by choosing approximations ηn of ξn and η of ξ such
that ηn
d→η. The desired convergence will follow if we can ensure that the
approximation errors are uniformly small.
Theorem 3.28 (approximation) Let ξ, ξn, ηk, and ηk
n be random elements in
a metric space (S, ρ) such that ηk
n
d→ηk as n →∞for ﬁxed k, and moreover
ηk
d→ξ. Then ξn
d→ξ holds under the further condition
lim
k→∞lim sup
n→∞E[ρ(ηk
n, ξn) ∧1] = 0.
(9)

3. Random Sequences, Series, and Averages
55
Proof: For any closed set F ⊂S and constant ε > 0 we have
P{ξn ∈F} ≤P{ηk
n ∈F ε} + P{ρ(ηk
n, ξn) > ε},
where F ε = {s ∈S; ρ(s, F) ≤ε}. By Theorem 3.25 we get as n →∞
lim sup
n→∞P{ξn ∈F} ≤P{ηk ∈F ε} + lim sup
n→∞P{ρ(ηk
n, ξn) > ε}.
Now let k →∞, and conclude from Theorem 3.25 together with (9) that
lim sup
n→∞P{ξn ∈F} ≤P{ξ ∈F ε}.
As ε →0, the right-hand side tends to P{ξ ∈F}. Since F was arbitrary, we
get ξn
d→ξ by Theorem 3.25.
✷
Next we consider convergence in distribution on product spaces.
Theorem 3.29 (random sequences) Fix any separable metric spaces S1, S2,
. . . , and let ξ = (ξ1, ξ2, . . .) and ξn = (ξ1
n, ξ2
n, . . .), n ∈N, be random elements
in XkSk. Then ξn
d→ξ iﬀ
(ξ1
n, . . . , ξk
n)
d→(ξ1, . . . , ξk) in S1 × · · · × Sk,
k ∈N.
(10)
If ξ and the ξn have independent components, it is further equivalent that
ξk
n
d→ξk in Sk for each k.
Proof: The necessity of the conditions is clear from the continuity of the
projections s →(s1, . . . , sk) and s →sk.
Now assume instead that (10)
holds. Fix any ak ∈Sk, k ∈N, and conclude from the continuity of the
mappings (s1, . . . , sk) →(s1, . . . , sk, ak+1, . . .) that
(ξ1
n, . . . , ξk
n, ak+1, . . .)
d→(ξ1, . . . , ξk, ak+1, . . .),
k ∈N.
(11)
Writing ηk
n and ηk for the sequences in (11), and letting ρ be the metric in
(2), we further note that ρ(ξ, ηk) ≤2−k and ρ(ξn, ηk
n) ≤2−k for all n and k.
Hence, ξn
d→ξ by Theorem 3.28.
To prove the last assertion, it is clearly enough to consider the product of
two separable metric spaces S and T. We need to show that if ξn
d→ξ in S
and ηn
d→η in T with ξn⊥⊥ηn and ξ⊥⊥η, then (ξn, ηn)
d→(ξ, η) in S × T. To
see this, we note that ξ∂Bs,ε = 0 a.s. for each s ∈S and almost every ε > 0,
where Bs,ε denotes the ε-ball around s. Thus, S has a topological basis BS
consisting of ξ-continuity sets, and similarly T has a basis BT consisting of
η-continuity sets. Since ∂(B ∪C) ⊂∂B ∪∂C, even the generated ﬁelds AS
and AT consist of continuity sets.
Now ﬁx any open set G in S × T. Since S × T is separable with basis
BS × BT, we have G =

j(Bj × Cj) for suitable Bj ∈BS and Cj ∈BT.

56
Foundations of Modern Probability
Here each set Uk =

j≤k(Bj × Cj) may be written as a ﬁnite disjoint union
of product sets A ∈AS × AT. By the assumed independence and Theorem
3.25, we obtain
lim inf
n→∞P{(ξn, ηn) ∈G} ≥lim
n→∞P{(ξn, ηn) ∈Uk} = P{(ξ, η) ∈Uk}.
As k →∞, the right-hand side tends to P{(ξ, η) ∈G}, and the desired
convergence follows by Theorem 3.25.
✷
In connection with convergence in distribution of a random sequence
ξ1, ξ2, . . . , it is often irrelevant how the elements ξn are related. The next
result may enable us to change to a more convenient representation, which
sometimes leads to very simple and transparent proofs.
Theorem 3.30 (coupling, Skorohod, Dudley) Let ξ, ξ1, ξ2, . . . be random el-
ements in a separable metric space (S, ρ) such that ξn
d→ξ. Then, on a suit-
able probability space, there exist some random elements η d= ξ and ηn
d= ξn,
n ∈N, with ηn →η a.s.
In the course of the proof, we shall need to introduce families of inde-
pendent random elements with given distributions. The existence of such
families is ensured, in general, by Corollary 5.18. When S is complete, we
may instead rely on the more elementary Theorem 2.19.
Proof: First assume that S = {1, . . . , m}, and put pk = P{ξ = k} and
pn
k = P{ξn = k}. Assuming ϑ to be U(0, 1) and independent of ξ, we may
easily construct some random elements ˜ξn
d= ξn such that ˜ξn = k whenever
ξ = k and ϑ ≤pn
k/pk. Since pn
k →pk for each k, we get ˜ξn →ξ a.s.
For general S, ﬁx any p ∈N, and choose a partition of S into ξ-continuity
sets B1, B2, . . . ∈B(S) of diameter < 2−p.
Next choose m so large that
P{ξ ̸∈
k≤m Bk} < 2−p, and put B0 =

k≤m Bc
k. For k = 0, . . . , m, deﬁne
κ = k when ξ ∈Bk and κn = k when ξn ∈Bk, n ∈N. Then κn
d→κ, and
by the result for ﬁnite S we may choose some ˜κn
d= κn with ˜κn →κ a.s.
Let us further introduce some independent random elements ζk
n in S with
distributions P[ξn ∈· |ξn ∈Bk] and deﬁne ˜ξp
n =
	
k ζk
n1{˜κn = k}, so that
˜ξp
n
d= ξn for each n.
From the construction it is clear that

ρ(˜ξp
n, ξ) > 2−p
⊂{˜κn ̸= κ} ∪{ξ ∈B0},
n, p ∈N.
Since ˜κn →κ a.s. and P{ξ ∈B0} < 2−p, there exists for every p some np ∈N
with
P

n≥np

ρ(˜ξp
n, ξ) > 2−p
< 2−p,
p ∈N,
and we may further assume that n1 < n2 < · · · .
By the Borel–Cantelli
lemma we get a.s. supn≥np ρ(˜ξp
n, ξ) ≤2−p for all but ﬁnitely many p. Now
deﬁne ηn = ˜ξp
n for np ≤n < np+1, and note that ξn
d= ηn →ξ a.s.
✷

3. Random Sequences, Series, and Averages
57
We conclude this chapter with a result on functional representations of
limits, needed in Chapters 15 and 18. To motivate the problem, recall from
Lemma 3.6 that if ξn
P→η for some random elements in a complete metric
space S, then η = f(ξ) a.s. for some measurable function f : S∞→S,
where ξ = (ξn). Here f depends on the distribution µ of ξ, so a universal
representation must be of the form η = f(ξ, µ). For certain purposes, it is
crucial to choose a measurable version even of the latter function. To allow
constructions by repeated approximation in probability, we need to consider
the more general case when ηn
P→η for some random elements ηn = fn(ξ, µ).
For a precise statement of the result, let P(S) denote the space of prob-
ability measures µ on S, endowed with the σ-ﬁeld induced by all evaluation
maps µ →µB, B ∈B(S).
Proposition 3.31 (representation of limits) Fix a complete metric space
(S, ρ), a measurable space U, and some measurable functions f1, f2, . . . :
U × P(U) →S. Then there exist a measurable set A ⊂P(U) and some
measurable function f : U × A →S such that for any random element ξ in
U with distribution µ, the sequence ηn = fn(ξ, µ) converges in probability iﬀ
µ ∈A, in which case ηn
P→f(ξ, µ).
Proof: For sequences s = (s1, s2, . . .) in S, deﬁne l(s) = limk sk when
the limit exists and otherwise put l(s) = s∞, where s∞∈S is arbitrary.
By Lemma 1.10 we note that l is a measurable mapping from S∞to S.
Next consider a sequence η = (η1, η2, . . .) of random elements in S, and put
ν = P ◦η−1. Deﬁne n1, n2, . . . as in the proof of Lemma 3.6, and note that
each nk = nk(ν) is a measurable function of ν. Let C be the set of measures
ν such that nk(ν) < ∞for all k, and note that ηn converges in probability
iﬀν ∈C. Introduce the measurable function
g(s, ν) = l(sn1(ν), sn2(ν), . . .),
s = (s1, s2, . . .) ∈S∞, ν ∈P(S∞).
If ν ∈C, it is seen from the proof of Lemma 3.6 that ηnk(ν) converges a.s.,
and so ηn
P→g(η, ν).
Now assume that ηn = fn(ξ, µ) for some random element ξ in U with
distribution µ and some measurable functions fn. It remains to show that ν
is a measurable function of µ. But this is clear from Lemma 1.38 (ii) applied
to the kernel K(µ, ·) = µ from P(U) to U and the function F = (f1, f2, . . .):
U × P(U) →S∞.
✷
As a simple consequence, we may consider limits in probability of mea-
surable processes. The resulting statement will be useful in Chapter 15.
Corollary 3.32 (measurability of limits, Stricker and Yor) For any mea-
surable space T and complete metric space S, let X1, X2, . . . be S-valued
measurable processes on T. Then there exist a measurable set A ⊂T and
some measurable process X on A such that Xn
t converges in probability iﬀ
t ∈A, in which case Xn
t
P→Xt.

58
Foundations of Modern Probability
Proof: Deﬁne ξt = (X1
t , X2
t , . . .) and µt = P ◦ξ−1
t . By Proposition 3.31
there exist a measurable set C ⊂P(S∞) and some measurable function
f : S∞× C →S such that Xn
t converges in probability iﬀµt ∈C, in which
case Xn
t
P→f(ξt, µt). It remains to note that the mapping t →µt is measur-
able, which is clear by Lemmas 1.4 and 1.26.
✷
Exercises
1. Let ξ1, . . . , ξn be independent symmetric random variables. Show that
P{(	
k ξk)2 ≥r
	
k ξ2
k} ≥(1 −r)2/3 for any r ∈(0, 1). (Hint: Reduce by
means of Lemma 2.11 to the case of nonrandom |ξk|, and use Lemma 3.1.)
2.
Let ξ1, . . . , ξn be independent symmetric random variables.
Show
that P{maxk |ξk| > r} ≤2P{|S| > r} for all r > 0, where S =
	
k ξk.
(Hint: Let η be the ﬁrst term ξk where maxk |ξk| is attained, and check that
(η, S −η) d= (η, η −S).)
3. Let ξ1, ξ2, . . . be i.i.d. random variables with P{|ξn| > t} > 0 for all
t > 0. Show that there exist some constants c1, c2, . . . such that cnξn →0 in
probability but not a.s.
4. Show that a family of random variables ξt is tight iﬀsupt Ef(|ξt|) < ∞
for some increasing function f : R+ →R+ with f(∞) = ∞.
5. Consider some random variables ξn and ηn such that (ξn) is tight and
ηn
P→0. Show that even ξnηn
P→0.
6. Show that the random variables ξt are uniformly integrable iﬀsupt
Ef(|ξt|) < ∞for some increasing function f : R+ →R+ with f(x)/x →∞
as x →∞.
7. Show that the condition supt E|ξt| < ∞in Lemma 3.10 can be omitted
if A is nonatomic.
8. Let ξ1, ξ2, . . . ∈L1. Show that the ξn are uniformly integrable iﬀthe
condition in Lemma 3.10 holds with supn replaced by lim supn.
9. Deduce the dominated convergence theorem from Lemma 3.11.
10. Show that if {|ξt|p} and {|ηt|p} are uniformly integrable for some p > 0,
then so is {|aξt + bηt|p} for any a, b ∈R. (Hint: Use Lemma 3.10.) Use this
fact to deduce Proposition 3.12 from Lemma 3.11.
11. Give examples of random variables ξ, ξ1, ξ2, . . . ∈L2 such that ξn →ξ
holds a.s. but not in L2, in L2 but not a.s., or in L1 but not in L2.
12. Let ξ1, ξ2, . . . be independent random variables in L2. Show that
	
n ξn
converges in L2 iﬀ
	
n Eξn and
	
n var(ξn) both converge.
13. Give an example of independent symmetric random variables ξ1, ξ2,
. . . such that 	
n ξn is a.s. conditionally (nonabsolutely) convergent.
14. Let ξn and ηn be symmetric random variables with |ξn| ≤|ηn| such
that the pairs (ξn, ηn) are independent. Show that
	
n ξn converges whenever
	
n ηn does.

3. Random Sequences, Series, and Averages
59
15. Let ξ1, ξ2, . . . be independent symmetric random variables. Show that
E[(	
n ξn)2 ∧1] ≤
	
n E[ξ2
n ∧1] whenever the latter series converges. (Hint:
Integrate over the sets where supn |ξn| ≤1 or > 1, respectively.)
16. Consider some independent sequences of symmetric random variables
ξk, η1
k, η2
k, . . . with |ηn
k| ≤|ξk| such that
	
k ξk converges, and assume ηn
k
P→ηk
for each k. Show that
	
k ηn
k
P→
	
k ηk. (Hint: Use a truncation based on the
preceding exercise.)
17. Let 	
n ξn be a convergent series of independent random variables.
Show that the sum is a.s. independent of the order of terms iﬀ	
n |E[ξn; |ξn|
≤1]| < ∞.
18. Let the random variables ξnj be symmetric and independent for each
n. Show that
	
j ξnj
P→0 iﬀ
	
j E[ξ2
nj ∧1] →0.
19. Let ξn
d→ξ and anξn
d→ξ for some nondegenerate random variable
ξ and some constants an > 0.
Show that an →1.
(Hint: Turning to
subsequences, we may assume that an →a.)
20. Let ξn
d→ξ and anξn+bn
d→ξ for some nondegenerate random variable
ξ, where an > 0. Show that an →1 and bn →0. (Hint: Symmetrize.)
21. Let ξ1, ξ2, . . . be independent random variables such that an
	
k≤n ξk
converges in probability for some constants an →0. Show that the limit is
degenerate.
22. Show that Theorem 3.23 is false for p = 2 by taking the ξk to be
independent and N(0, 1).
23. Let ξ1, ξ2, . . . be i.i.d. and such that n−1/p 	
k≤n ξk is a.s. bounded for
some p ∈(0, 2). Show that E|ξ1|p < ∞. (Hint: Argue as in the proof of
Theorem 3.23.)
24. Show for p ≤1 that the a.s. convergence in Theorem 3.23 remains
valid in Lp. (Hint: Truncate the ξk.)
25. Give an elementary proof of the strong law of large numbers when
E|ξ|4 < ∞. (Hint: Assuming Eξ = 0, show that E
	
n(Sn/n)4 < ∞.)
26.
Show by examples that Theorem 3.25 is false without the stated
restrictions on the sets G, F, and B.
27. Use Theorem 3.30 to give a simple proof of Theorem 3.27 when S
is separable. Generalize to random elements ξ and ξn in Borel sets C and
Cn, respectively, assuming only fn(xn) →f(x) for xn ∈Cn and x ∈C with
xn →x. Extend the original proof to that case.
28. Give a short proof of Theorem 3.30 when S = R. (Hint: Note that
the distribution functions Fn and F satisfy F −1
n
→F −1 a.e. on [0, 1].)

Chapter 4
Characteristic Functions
and Classical Limit Theorems
Uniqueness and continuity theorem; Poisson convergence; posi-
tive and symmetric terms; Lindeberg’s condition; general Gaus-
sian convergence; weak laws of large numbers; domain of Gaus-
sian attraction; vague and weak compactness
In this chapter we continue the treatment of weak convergence from Chapter
3 with a detailed discussion of probability measures on Euclidean spaces.
Our ﬁrst aim is to develop the theory of characteristic functions and Laplace
transforms. In particular, the basic uniqueness and continuity theorem will
be established by simple equicontinuity and approximation arguments. The
traditional compactness approach—in higher dimensions a highly nontrivial
route—is required only for the case when the limiting function is not known in
advance to be a characteristic function. The compactness theory also serves
as a crucial bridge to the general theory of weak convergence presented in
Chapter 14.
Our second aim is to establish the basic distributional limit theorems in
the case of Poisson or Gaussian limits. We shall then consider triangular
arrays of random variables ξnj, assumed to be independent for each n and
such that ξnj
P→0 as n →∞uniformly in j. In this setting, general criteria
will be obtained for the convergence of 	
j ξnj toward a Poisson or Gaussian
distribution. Specializing to the case of suitably centered and normalized
partial sums from a single i.i.d. sequence ξ1, ξ2, . . . , we may deduce the ulti-
mate versions of the weak law of large numbers and the central limit theorem,
including a complete description of the domain of attraction of the Gaussian
law.
The mentioned limit theorems lead in Chapters 10 and 11 to some basic
characterizations of Poisson and Gaussian processes, which in turn are needed
to describe the general independent increment processes in Chapter 13. Even
the limit theorems themselves are generalized in various ways in subsequent
chapters.
Thus, the Gaussian convergence is extended in Chapter 12 to
suitable martingales, and the result is strengthened to uniform approximation
of the summation process by the path of a Brownian motion. Similarly, the
Poisson convergence is extended in Chapter 14 to a general limit theorem
for point processes. A complete solution to the general limit problem for
60

4. Characteristic Functions and Classical Limit Theorems
61
triangular arrays is given in Chapter 13, in connection with our treatment of
L´evy processes.
In view of the crucial role of the independence assumption for the meth-
ods in this chapter, it may come as a surprise that the scope of the method
of characteristic functions and Laplace transforms extends far beyond the
present context. Thus, exponential martingales based on characteristic func-
tions play a crucial role in Chapters 13 and 16, whereas Laplace functionals
of random measures are used extensively in Chapters 10 and 14. Even more
importantly, Laplace transforms play a key role in Chapters 17 and 19, in
the guises of resolvents and potentials for general Markov processes and their
additive functionals.
To begin with the basic deﬁnitions, consider a random vector ξ in Rd with
distribution µ. The associated characteristic function ˆµ is given by
ˆµ(t) =

eitxµ(dx) = Eeitξ,
t ∈Rd,
where tx denotes the inner product t1x1 + · · · + tdxd. For distributions µ on
Rd
+, it is often more convenient to consider the Laplace transform ˜µ, given
by
˜µ(u) =

e−uxµ(dx) = Ee−uξ,
u ∈Rd
+.
Finally, for distributions µ on Z+, it is often preferable to use the (probability)
generating function ψ, given by
ψ(s) =

n≥0
snP{ξ = n} = Esξ,
s ∈[0, 1].
Formally, ˜µ(u) = ˆµ(iu) and ˆµ(t) = ˜µ(−it), and so the functions ˆµ and ˜µ
are essentially the same, apart from domain. Furthermore, the generating
function ψ is related to the Laplace transform ˜µ by ˜µ(u) = ψ(e−u) or ψ(s) =
˜µ(−log s). Though the characteristic function always exists, it may not be
extendable to an analytic function in the complex plane.
For any distribution µ on Rd, we note that the characteristic function
ϕ = ˆµ is uniformly continuous with |ϕ(t)| ≤ϕ(0) = 1. It is further seen to
be Hermitian in the sense that ϕ(−t) = ¯ϕ(t), where the bar denotes complex
conjugation. If ξ has characteristic function ϕ, then the linear combination
aξ = a1ξ1 +· · ·+adξd has characteristic function t →ϕ(ta). Also note that if
ξ and η are independent random vectors with characteristic functions ϕ and
ψ, then the characteristic function of the pair (ξ, η) is given by the tensor
product ϕ ⊗ψ : (s, t) →ϕ(s)ψ(t). Thus, ξ + η has characteristic function
ϕψ. In particular, the characteristic function of the symmetrization ξ −ξ′
equals |ϕ|2.
Whenever applicable, the mentioned results carry over to Laplace trans-
forms and generating functions. The latter functions have the further ad-
vantage of being positive, monotone, convex, and analytic—properties that
simplify many arguments.

62
Foundations of Modern Probability
The following result contains some elementary but useful estimates in-
volving characteristic functions. The second inequality was used in the proof
of Theorem 3.17, and the remaining relations will be useful in the sequel to
establish tightness.
Lemma 4.1 (tail estimates) For any probability measure µ on R, we have
µ{x; |x| ≥r}
≤
r
2

 2/r
−2/r(1 −ˆµt)dt,
r > 0,
(1)
µ[−r, r]
≤
2r

 1/r
−1/r |ˆµt|dt,
r > 0.
(2)
If µ is supported by R+, then also
µ[r, ∞) ≤2(1 −˜µ(1/r)),
r > 0.
(3)
Proof: Using Fubini’s theorem and noting that sin x ≤x/2 for x ≥2, we
get for any c > 0

 c
−c(1 −ˆµt)dt
=

µ(dx)

 c
−c(1 −eitx)dt
=
2c

 
1 −sin cx
cx

µ(dx) ≥cµ{x; |cx| ≥2},
and (1) follows as we take c = 2/r. To prove (2), we may write
1
2µ[−r, r]
≤
2

 1 −cos(x/r)
(x/r)2
µ(dx)
=
r

µ(dx)

(1 −r|t|)+eixtdt
=
r

(1 −r|t|)+ˆµtdt ≤r

 1/r
−1/r |ˆµt|dt.
To obtain (3), we note that e−x < 1
2 for x ≥1. Thus, for t > 0,
1 −˜µt =

(1 −e−tx)µ(dx) ≥1
2µ{x; tx ≥1}.
✷
Recall that a family of probability measures µα on Rd is said to be tight
if
lim
r→∞sup
α µα{x; |x| > r} = 0.
The following lemma describes tightness in terms of characteristic functions.
Lemma 4.2 (equicontinuity and tightness)
A family {µα} of probability
measures on Rd is tight iﬀ{ˆµα} is equicontinuous at 0, and then {ˆµα} is
uniformly equicontinuous on Rd. A similar statement holds for the Laplace
transforms of distributions on Rd
+.

4. Characteristic Functions and Classical Limit Theorems
63
Proof: The suﬃciency is immediate from Lemma 4.1, applied separately
in each coordinate. To prove the necessity, let ξα denote a random vector
with distribution µα, and write for any s, t ∈Rd
|ˆµα(s) −ˆµα(t)|
≤
E|eisξα −eitξα| = E|1 −ei(t−s)ξα|
≤
2E[|(t −s)ξα| ∧1].
If {ξα} is tight, then by Lemma 3.9 the right-hand side tends to 0 as t−s →0,
uniformly in α, and the asserted uniform equicontinuity follows. The proof
for Laplace transforms is similar.
✷
For any probability measures µ, µ1, µ2, . . . on Rd, we recall that the weak
convergence µn
w→µ holds by deﬁnition iﬀµnf →µf for any bounded,
continuous function f on Rd, where µf denotes the integral
 fdµ.
The
usefulness of characteristic functions is mainly due to the following basic
result.
Theorem 4.3 (uniqueness and continuity, L´evy) For any probability mea-
sures µ, µ1, µ2, . . . on Rd we have µn
w→µ iﬀˆµn(t) →ˆµ(t) for every t ∈Rd,
and then ˆµn →ˆµ uniformly on every bounded set. A corresponding statement
holds for the Laplace transforms of distributions on Rd
+.
In particular, we may take µn ≡ν and conclude that a probability mea-
sure µ on Rd is uniquely determined by its characteristic function ˆµ. Simi-
larly, a probability measure µ on Rd
+ is seen to be determined by its Laplace
transform ˜µ.
For the proof of Theorem 4.3, we need the following simple cases or con-
sequences of the Stone–Weierstrass approximation theorem. Here [0, ∞] de-
notes the compactiﬁcation of R+.
Lemma 4.4 (approximation) Every continuous function f : Rd →R with
period 2π in each coordinate admits a uniform approximation by linear com-
binations of cos kx and sin kx, k ∈Zd
+. Similarly, every continuous function
g : [0, ∞]d →R+ can be approximated uniformly by linear combinations of
the functions e−kx, k ∈Zd
+.
Proof of Theorem 4.3: We shall consider only the case of characteristic
functions, the proof for Laplace transforms being similar. If µn
w→µ, then
ˆµn(t) →ˆµ(t) for every t, by the deﬁnition of weak convergence. By Lemmas
3.8 and 4.2, the latter convergence is uniform on every bounded set.
Conversely, assume that ˆµn(t) →ˆµ(t) for every t. By Lemma 4.1 and
dominated convergence we get, for any a ∈Rd and r > 0,
lim sup
n→∞µn{x; |ax| > r}
≤
lim
n→∞
r
2

 2/r
−2/r(1 −ˆµn(ta))dt
=
r
2

 2/r
−2/r(1 −ˆµ(ta))dt.

64
Foundations of Modern Probability
Since ˆµ is continuous at 0, the right-hand side tends to 0 as r →∞, which
shows that the sequence (µn) is tight. Given any ε > 0, we may then choose
r > 0 so large that µn{|x| > r} ≤ε for all n, and µ{|x| > r} ≤ε.
Now ﬁx any bounded, continuous function f : Rd →R, say with |f| ≤
m < ∞. Let fr denote the restriction of f to the ball {|x| ≤r}, and extend
fr to a continuous function ˜f on Rd with | ˜f| ≤m and period 2πr in each
coordinate. By Lemma 4.4 there exists some linear combination g of the
functions cos(kx/r) and sin(kx/r), k ∈Zd
+, such that | ˜f −g| ≤ε. Writing
∥· ∥for the supremum norm, we get for any n ∈N
|µnf −µng| ≤µn{|x| > r}∥f −˜f∥+ ∥˜f −g∥≤(2m + 1)ε,
and similarly for µ. Thus,
|µnf −µf| ≤|µng −µg| + 2(2m + 1)ε,
n ∈N.
Letting n →∞and then ε →0, we obtain µnf →µf. Since f was arbitrary,
this proves that µn
w→µ.
✷
The next result provides a way of reducing the d-dimensional case to that
of one dimension.
Corollary 4.5 (one-dimensional projections, Cram´er and Wold) Let ξ and
ξ1, ξ2, . . . be random vectors in Rd. Then ξn
d→ξ iﬀtξn
d→tξ for all t ∈Rd.
For random vectors in Rd
+, it suﬃces that uξn
d→uξ for all u ∈Rd
+.
Proof: If tξn
d→tξ, then Eeitξn →Eeitξ by the deﬁnition of weak conver-
gence, so ξn
d→ξ by Theorem 4.3. The proof for random vectors in Rd
+ is
similar.
✷
The last result contains in particular a basic uniqueness result, the fact
that ξ
d= η iﬀtξ
d= tη for all t ∈Rd or Rd
+, respectively. In other words,
a probability measure on Rd is uniquely determined by its one-dimensional
projections.
We shall now apply the continuity theorem to prove some classical limit
theorems, and we begin with the case of Poisson convergence. For an in-
troduction, consider for each n ∈N some i.i.d. random variables ξn1, . . . , ξnn
with distribution
P{ξnj =1} = 1 −P{ξnj =0} = cn,
n ∈N,
and assume that ncn →c < ∞. Then the sums Sn = ξn1 + . . . + ξnn have
generating functions
ψn(s) = (1 −(1 −s)cn)n →e−c(1−s) = e−c 
n≥0
cnsn
n! ,
s ∈[0, 1].

4. Characteristic Functions and Classical Limit Theorems
65
The limit ψ(s) = e−c(1−s) is the generating function of the Poisson distribu-
tion with parameter c, possessing the probabilities pn = e−ccn/n!, n ∈Z+.
Note that the corresponding expected value equals ψ′(1) = c. Since ψn →ψ,
it is clear from Theorem 4.3 that Sn
d→η, where P{η = n} = pn for all n.
Before turning to more general cases of Poisson convergence, we need to
introduce the notion of a null array. By this we mean a triangular array of
random variables or vectors ξnj, 1 ≤j ≤mn, n ∈N, such that the ξnj are
independent for each n and satisfy
supjE[|ξnj| ∧1] →0.
(4)
The latter condition may be thought of as the convergence ξnj
P→0 as n →∞,
uniformly in j. When ξnj ≥0 for all n and j, we may allow the mn to be
inﬁnite.
The following lemma characterizes null arrays in terms of the associated
characteristic functions or Laplace transforms.
Lemma 4.6 (null arrays) Consider a triangular array of random vectors
ξnj with characteristic functions ϕnj or Laplace transforms ψnj. Then (4)
holds iﬀ
supj|1 −ϕnj(t)| →0,
t ∈Rd,
(5)
respectively,
infjψnj(u) →1,
u ∈Rd
+.
Proof: Relation (4) holds iﬀξn,jn
P→0 for all sequences (jn). By Theo-
rem 4.3 this is equivalent to ϕn,jn(t) →1 for all t and (jn), which in turn is
equivalent to (5). The proof for Laplace transforms is similar.
✷
We shall now give a general criterion for Poisson convergence of the row-
sums in a null array of integer-valued random variables. The result will be
extended in Lemmas 13.15 and 13.24 to more general limiting distributions
and in Theorem 14.18 to the context of point processes.
Theorem 4.7 (Poisson convergence) Let (ξnj) be a null array of Z+-valued
random variables, and let ξ be Poisson distributed with mean c. Then 	
j ξnj
d→ξ iﬀthese conditions hold:
(i) 	
j P{ξnj > 1} →0;
(ii) 	
j P{ξnj = 1} →c.
Moreover, (i) is equivalent to supj ξnj ∨1
P→1. If
	
j ξnj converges in distri-
bution, then (i) holds iﬀthe limit is Poisson.
We need the following frequently used lemma.
Lemma 4.8 (sums and products) Consider a null array of constants cnj ≥0,
and ﬁx any c ∈[0, ∞]. Then 
j(1 −cnj) →e−c iﬀ
	
j cnj →c.

66
Foundations of Modern Probability
Proof: Since supj cnj < 1 for large n, the ﬁrst relation is equivalent to
	
j log(1−cnj) →−c, and the assertion follows from the fact that log(1−x) =
−x + o(x) as x →0.
✷
Proof of Theorem 4.7: Denote the generating function of ξnj by ψnj. By
Theorem 4.3 the convergence
	
j ξnj
d→ξ is equivalent to

j ψnj(s) →e−c(1−s)
for arbitrary s ∈[0, 1], which holds by Lemmas 4.6 and 4.8 iﬀ

j(1 −ψnj(s)) →c(1 −s),
s ∈[0, 1].
(6)
By an easy computation, the sum on the left equals
(1 −s)

j
P{ξnj > 0} +

k>1
(s −sk)

j
P{ξnj = k} = T1 + T2,
(7)
and we further note that
s(1 −s)

jP{ξnj > 1} ≤T2 ≤s

jP{ξnj > 1}.
(8)
Assuming (i) and (ii), it is clear from (7) and (8) that (6) is fulﬁlled. Now
assume instead that (6) holds. For s = 0 we get 	
j P{ξnj > 0} →c, so in
general T1 →c(1 −s). But then T2 →0 because of (6), and (i) follows by
(8). Finally, (ii) is obtained by subtraction.
To prove that (i) is equivalent to supj ξnj ∨1
P→1, we note that
P{supjξnj ≤1} =

jP{ξnj ≤1} =

j(1 −P{ξnj > 1}).
By Lemma 4.8 the right-hand side tends to 1 iﬀ
	
j P{ξnj > 1} →0, which
is the stated equivalence.
To prove the last assertion, put cnj = P{ξnj > 0} and write
E exp

−

jξnj

−P{supjξnj > 1} ≤E exp

−

j(ξnj ∧1)

=

jE exp{−(ξnj ∧1)} =

j{1 −(1 −e−1)cnj}
≤

j exp{−(1 −e−1)cnj} = exp

−(1 −e−1)

jcnj

.
If (i) holds and
	
j ξnj
d→η, then the left-hand side tends to Ee−η > 0, so
the sums cn =
	
j cnj are bounded. Hence, cn converges along a subsequence
N ′ ⊂N toward some constant c. But then (i) and (ii) hold along N ′, and
the ﬁrst assertion shows that η is Poisson with mean c.
✷
Next consider some i.i.d. random variables ξ1, ξ2, . . . with P{ξk = ±1} =
1
2, and write Sn = ξ1 + · · · + ξn. Then n−1/2Sn has characteristic function
ϕn(t) = cosn(n−1/2t) =

1 −t2
2n + O(n−2)
n
→e−t2/2 = ϕ(t).

4. Characteristic Functions and Classical Limit Theorems
67
By a classical computation, the function e−x2/2 has Fourier transform

 ∞
−∞eitxe−x2/2dx = (2π)1/2e−t2/2,
t ∈R.
Hence, ϕ is the characteristic function of a probability measure on R with
density (2π)−1/2e−x2/2. This is the standard normal or Gaussian distribution
N(0, 1), and Theorem 4.3 shows that n−1/2Sn
d→ζ, where ζ is N(0, 1). The
general Gaussian law N(m, σ2) is deﬁned as the distribution of the random
variable η = m + σζ, and we note that η has mean m and variance σ2.
From the form of the characteristic functions together with the uniqueness
property, it is clear that any linear combination of independent Gaussian
random variables is again Gaussian.
The convergence to a Gaussian limit generalizes easily to a more general
setting, as in the following classical result. The present statement is only
preliminary, and a more general version is obtained by diﬀerent methods in
Theorem 4.17.
Proposition 4.9 (central limit theorem, Lindeberg, L´evy) Let ξ, ξ1, ξ2, . . .
be i.i.d. random variables with Eξ = 0 and Eξ2 = 1, and let ζ be N(0, 1).
Then n−1/2 	
k≤n ξk
d→ζ.
The proof may be based on a simple Taylor expansion.
Lemma 4.10 (Taylor expansion) Let ϕ be the characteristic function of a
random variable ξ with E|ξ|n < ∞. Then
ϕ(t) =
n

k=0
(it)kEξk
k!
+ o(tn),
t →0.
Proof: Noting that |eit −1| ≤t for all t ∈R, we get recursively by
dominated convergence
ϕ(k)(t) = E(iξ)keitξ,
t ∈R, 0 ≤k ≤n.
In particular, ϕ(k)(0) = E(iξ)k for k ≤n, and the result follows from Taylor’s
formula.
✷
Proof of Proposition 4.9: Let the ξk have characteristic function ϕ. By
Lemma 4.10, the characteristic function of n−1/2Sn equals
ϕn(t) =

ϕ(n−1/2t)
n =

1 −t2
2n + o(n−1)
n
→e−t2/2,
where the convergence holds as n →∞for ﬁxed t.
✷
Our next aim is to examine the relationship between null arrays of sym-
metric and positive random variables. In this context, we may further obtain
criteria for convergence toward Gaussian and degenerate limits, respectively.

68
Foundations of Modern Probability
Theorem 4.11 (positive and symmetric terms) Let (ξnj) be a null array
of symmetric random variables, and let ξ be N(0, c) for some c ≥0. Then
	
j ξnj
d→ξ iﬀ
	
j ξ2
nj
P→c, and also iﬀthese conditions hold:
(i) 	
j P{|ξnj| > ε} →0 for all ε > 0;
(ii) 	
j E(ξ2
nj ∧1) →c.
Moreover, (i) is equivalent to supj |ξnj|
P→0. If
	
j ξnj or
	
j ξ2
nj converges in
distribution, then (i) holds iﬀthe limit is Gaussian or degenerate, respectively.
Here the necessity of condition (i) is a remarkable fact that plays a crucial
role in our proof of the more general Theorem 4.15. It is instructive to com-
pare the present statement with the corresponding result for random series
in Theorem 3.17. Note also the extended version appearing in Proposition
13.23.
Proof: First assume that 	
j ξnj
d→ξ. By Theorem 4.3 and Lemmas 4.6
and 4.8 it is equivalent that

jE(1 −cos tξnj) →1
2ct2,
t ∈R,
(9)
where the convergence is uniform on every bounded interval. Comparing the
integrals of (9) over [0, 1] and [0, 2], we get 	
j Ef(ξnj) →0, where f(0) = 0
and
f(x) = 3 −4 sin x
x
+ sin 2x
2x ,
x ∈R \ {0}.
Now f is continuous with f(x) →3 as |x| →∞, and furthermore f(x) > 0
for x ̸= 0. Indeed, the last relation is equivalent to 8 sin x −sin 2x < 6x for
x > 0, which is obvious when x ≥π/2 and follows by diﬀerentiation twice
when x ∈(0, π/2). Writing g(x) = infy>x f(y) and letting ε > 0 be arbitrary,
we get

jP{|ξnj| > ε} ≤

jP{f(ξnj) > g(ε)} ≤

jEf(ξnj)/g(ε) →0,
which proves (i).
If instead
	
j ξ2
nj
P→c, the corresponding symmetrized variables ηnj satisfy
	
j ηnj
P→0, and we get
	
j P{|ηnj| > ε} →0 as before. By Lemma 3.19 it
follows that 	
j P{|ξ2
nj −mnj| > ε} →0, where the mnj are medians of ξ2
nj,
and since supj mnj →0, condition (i) follows again. Using Lemma 4.8, we
further note that (i) is equivalent to supj |ξnj|
P→0. Thus, we may henceforth
assume that (i) is fulﬁlled.
Next we note that, for any t ∈R and ε > 0,

jE[1 −cos tξnj; |ξnj| ≤ε] = 1
2t2 
1 −O(t2ε2)
 
jE[ξ2
nj; |ξnj| ≤ε].

4. Characteristic Functions and Classical Limit Theorems
69
Assuming (i), the equivalence between (9) and (ii) now follows as we let
n →∞and then ε →0. To get the corresponding result for the variables
ξ2
nj, we may instead write

jE[1 −e−tξ2
nj; ξ2
nj ≤ε] = t(1 −O(tε))

jE[ξ2
nj; ξ2
nj ≤ε],
t, ε > 0,
and proceed as before. This completes the proof of the ﬁrst assertion.
Finally, assume that (i) holds and 	
j ξnj
d→η. Then the same relation
holds for the truncated variables ξnj1{|ξnj| ≤1}, and so we may assume that
|ξnj| ≤1 for all j and k. Deﬁne cn =
	
j Eξ2
nj. If cn →∞along some sub-
sequence, then the distribution of c−1/2
n
	
j ξnj tends to N(0, 1) by the ﬁrst
assertion, which is impossible by Lemmas 3.8 and 3.9. Thus, (cn) is bounded
and converges along some subsequence. By the ﬁrst assertion, 	
j ξnj then
tends to some Gaussian limit, so even η is Gaussian.
✷
The following result gives the basic criterion for Gaussian convergence,
under a normalization by second moments.
Theorem 4.12 (Gaussian convergence under classical normalization, Lin-
deberg, Feller) Let (ξnj) be a triangular array of rowwise independent random
variables with mean 0 and 	
j Eξ2
nj →1, and let ξ be N(0, 1). Then these
conditions are equivalent:
(i)
	
j ξnj
d→ξ and supj Eξ2
nj →0;
(ii)
	
j E[ξ2
nj; |ξnj| > ε] →0 for all ε > 0.
Here (ii) is the celebrated Lindeberg condition. Our proof is based on two
elementary lemmas.
Lemma 4.13 (comparison of products) For any complex numbers z1, . . . , zn
and z′
1, . . . , z′
n of modulus ≤1, we have


k
zk −

k
z′
k
 ≤

k
|zk −z′
k|.
Proof: For n = 2 we get
|z1z2 −z′
1z′
2| ≤|z1z2 −z′
1z2| + |z′
1z2 −z′
1z′
2| ≤|z1 −z′
1| + |z2 −z′
2|,
and the general result follows by induction.
✷
Lemma 4.14 (Taylor expansion) For any t ∈R and n ∈Z+, we have
eit −
n

k=0
(it)k
k!
 ≤2|t|n
n!
∧
|t|n+1
(n + 1)!.

70
Foundations of Modern Probability
Proof: Letting hn(t) denote the diﬀerence on the left, we get
hn(t) = i

 t
0 hn−1(s)ds,
t > 0, n ∈Z+.
Starting from the obvious relations |h−1| ≡1 and |h0| ≤2, it follows by
induction that |hn−1(t)| ≤|t|n/n! and |hn(t)| ≤2|t|n/n!.
✷
We return to the proof of Theorem 4.12. At this point we shall prove
only the suﬃciency of the Lindeberg condition (ii), which is needed for the
proof of the main Theorem 4.15. To avoid repetition, we postpone the proof
of the necessity part until after the proof of that theorem.
Proof of Theorem 4.12, (ii) ⇒(i): Write cnj = Eξ2
nj and cn =
	
j cnj.
First we note that for any ε > 0
supjcnj ≤ε2 + supjE[ξ2
nj; |ξnj| > ε] ≤ε2 +

jE[ξ2
nj; |ξnj| > ε],
which tends to 0 under (ii), as n →∞and then ε →0.
Now introduce some independent random variables ζnj with distributions
N(0, cnj), and note that ζn =
	
j ζnj is N(0, cn). Hence, ζn
d→ξ. Letting
ϕnj and ψnj denote the characteristic functions of ξnj and ζnj, respectively, it
remains by Theorem 4.3 to show that 
j ϕnj −

j ψnj →0. Then conclude
from Lemmas 4.13 and 4.14 that, for ﬁxed t ∈R,


jϕnj(t) −

jψnj(t)
 ≤

j|ϕnj(t) −ψnj(t)|
≤

j|ϕnj(t) −1 + 1
2t2cnj| +

j|ψnj(t) −1 + 1
2t2cnj|
<
⌢

jEξ2
nj(1 ∧|ξnj|) +

jEζ2
nj(1 ∧|ζnj|).
For any ε > 0, we have

jEξ2
nj(1 ∧|ξnj|) ≤ε

jcnj +

jE[ξ2
nj; |ξnj| > ε],
which tends to 0 by (ii), as n →∞and then ε →0. Further note that

jEζ2
nj(1 ∧|ζnj|) ≤

jE|ζnj|3 =

jc3/2
nj E|ξ|3 <
⌢cnsupjc1/2
nj →0
by the ﬁrst part of the proof.
✷
The problem of characterizing the convergence to a Gaussian limit is
solved completely by the following result. The reader should notice the strik-
ing resemblance between the present conditions and those of the three-series
criterion in Theorem 3.18. A far-reaching extension of the present result is
obtained by diﬀerent methods in Chapter 13. As before var[ξ; A] = var(ξ1A).

4. Characteristic Functions and Classical Limit Theorems
71
Theorem 4.15 (Gaussian convergence, Feller, L´evy)
Let (ξnj) be a null
array of random variables, and let ξ be N(b, c) for some constants b and c.
Then 	
j ξnj
d→ξ iﬀthese conditions hold:
(i)
	
j P{|ξnj| > ε} →0 for all ε > 0;
(ii)
	
j E[ξnj; |ξnj| ≤1] →b;
(iii)
	
j var[ξnj; |ξnj| ≤1] →c.
Moreover, (i) is equivalent to supj |ξnj|
P→0. If
	
j ξnj converges in distribu-
tion, then (i) holds iﬀthe limit is Gaussian.
Proof: To see that (i) is equivalent to supj |ξnj|
P→0, we note that
P{supj|ξnj| > ε} = 1 −

j(1 −P{|ξnj| > ε}),
ε > 0.
Since supj P{|ξnj| > ε} →0 under both conditions, the assertion follows by
Lemma 4.8.
Now assume
	
nj ξnj
d→ξ. Introduce medians mnj and symmetrizations
˜ξnj of the variables ξnj, and note that mn ≡supj |mnj| →0 and
	
j ˜ξnj
d→˜ξ,
where ˜ξ is N(0, 2c). By Lemma 3.19 and Theorem 4.11, we get for any ε > 0

jP{|ξnj| > ε}
≤

jP{|ξnj −mnj| > ε −mn}
≤
2

jP{|˜ξnj| > ε −mn} →0.
Thus, we may henceforth assume condition (i) and hence that supj |ξnj|
P→0.
But then 	
j ξnj
d→η is equivalent to
	
j ξ′
nj
d→η, where ξ′
nj = ξnj1{|ξnj| ≤1},
and so we may further assume that |ξnj| ≤1 a.s. for all n and j. In this
case (ii) and (iii) reduce to bn ≡
	
j Eξnj →b and cn ≡
	
j var(ξnj) →c,
respectively.
Write bnj = Eξnj, and note that supj |bnj| →0 because of (i). Assuming
(ii) and (iii), we get 	
j ξnj −bn
d→ξ −b by Theorem 4.12, and so
	
j ξnj
d→ξ.
Conversely, 	
j ξnj
d→ξ implies
	
j ˜ξnj
d→˜ξ, and (iii) follows by Theorem
4.11. But then 	
j ξnj −bn
d→ξ −b, so Lemma 3.20 shows that bn converges
toward some b′. Hence,
	
j ξnj
d→ξ + b′ −b, so b′ = b, which means that even
(ii) is fulﬁlled.
It remains to prove that, under condition (i), any limiting distribution
is Gaussian. Then assume
	
j ξnj
d→η, and note that
	
j ˜ξnj
d→˜η, where ˜η
denotes a symmetrization of η. If cn →∞along some subsequence, then
c−1/2
n
	
j ˜ξnj tends to N(0, 2) by the ﬁrst assertion, which is impossible by
Lemma 3.9. Thus, (cn) is bounded, and we have convergence cn →c along
some subsequence.
But then 	
nj ξnj −bn tends to N(0, c), again by the
ﬁrst assertion, and Lemma 3.20 shows that even bn converges toward some
limit b. Hence, 	
nj ξnj tends to N(b, c), which is then the distribution of η. ✷

72
Foundations of Modern Probability
Proof of Theorem 4.12, (i) ⇒(ii): The second condition in (i) implies
that (ξnj) is a null array. Furthermore, we have for any ε > 0

jvar[ξnj; |ξnj| ≤ε] ≤

jE[ξ2
nj; |ξnj| ≤ε] ≤

jEξ2
nj →1.
By Theorem 4.15 even the left-hand side tends to 1, and (ii) follows.
✷
As a ﬁrst application of Theorem 4.15, we shall prove the following ulti-
mate version of the weak law of large numbers. The result should be com-
pared with the corresponding strong law established in Theorem 3.23.
Theorem 4.16 (weak laws of large numbers) Let ξ, ξ1, ξ2, . . . be i.i.d. ran-
dom variables, and ﬁx any p ∈(0, 2) and c ∈R. Then n−1/p 	
k≤n ξk
P→c iﬀ
the following conditions hold as r →∞, depending on the value of p:
p < 1 :
rpP{|ξ| > r} →0 and c = 0;
p = 1 :
rP{|ξ| > r} →0 and E[ξ; |ξ| ≤r] →c;
p > 1 :
rpP{|ξ| > r} →0 and Eξ = c = 0.
Proof: Applying Theorem 4.15 to the null array of random variables
ξnj = n−1/pξj, j ≤n, we note that the stated convergence is equivalent to
the three conditions
(i) nP{|ξ| > n1/pε} →0 for all ε > 0,
(ii) n1−1/pE[ξ; |ξ| ≤n1/p] →c,
(iii) n1−2/pvar[ξ; |ξ| ≤n1/p] →0.
By the monotonicity of P{|ξ| > r1/p}, condition (i) is equivalent to rpP{|ξ| >
r} →0. Furthermore, Lemma 2.4 yields for any r > 0
rp−2var[ξ; |ξ| ≤r]
≤
rpE[(ξ/r)2 ∧1] = rp

 1
0 P{|ξ| ≥r
√
t}dt,
rp−1|E[ξ; |ξ| ≤r]|
≤
rpE(|ξ/r| ∧1) = rp

 1
0 P{|ξ| ≥rt}dt.
Since t−a is integrable on [0, 1] for any a < 1, it follows by dominated con-
vergence that (i) implies (iii) and also that (i) implies (ii) with c = 0 when
p < 1.
If instead p > 1, it is seen from (i) and Lemma 2.4 that
E|ξ| =

 ∞
0
P{|ξ| > r}dr <
⌢

 ∞
0 (1 ∧r−p)dr < ∞.
Thus, E[ξ; |ξ| ≤r] →Eξ, and (ii) implies Eξ = 0. Moreover, we get from (i)
rp−1E[|ξ|; |ξ| > r] = rpP{|ξ| > r} + rp−1

 ∞
r
P{|ξ| > t}dt →0.
Under the further assumption that Eξ = 0, we obtain (ii) with c = 0.

4. Characteristic Functions and Classical Limit Theorems
73
Finally, let p = 1, and conclude from (i) that
E[|ξ|; n < |ξ| ≤n + 1] <
⌢nP{|ξ| > n} →0.
Hence, under (i), condition (ii) is equivalent to E[ξ; |ξ| ≤r] →c.
✷
We shall next extend the central limit theorem in Proposition 4.9 by
characterizing convergence of suitably normalized partial sums from a single
i.i.d. sequence toward a Gaussian limit. Here a nondecreasing function L ≥0
is said to vary slowly at ∞if supx L(x) > 0 and moreover L(cx) ∼L(x) as
x →∞for each c > 0. This holds in particular when L is bounded, but it is
also true for many unbounded functions, such as log(x ∨1).
Theorem 4.17 (domain of Gaussian attraction, L´evy, Feller, Khinchin)
Let ξ, ξ1, ξ2, . . . be i.i.d. nondegenerate random variables, and let ζ be N(0, 1).
Then an
	
k≤n(ξk −mn)
d→ζ for some constants an and mn iﬀthe function
L(x) = E[ξ2; |ξ| ≤x] varies slowly at ∞, in which case we may take mn ≡
Eξ. In particular, the stated convergence holds with an ≡n−1/2 and mn ≡0
iﬀEξ = 0 and Eξ2 = 1.
Even other so-called stable distributions may occur as limits, but the
conditions for convergence are too restrictive to be of much interest for ap-
plications. Our proof of Theorem 4.17 is based on the following result.
Lemma 4.18 (slow variation, Karamata) Let ξ be a nondegenerate random
variable such that L(x) = E[ξ2; |ξ| ≤x] varies slowly at ∞. Then so does the
function Lm(x) = E[(ξ −m)2; |ξ −m| ≤x] for every m ∈R, and moreover
lim
x→∞x2−pE[|ξ|p; |ξ| > x]/L(x) = 0,
p ∈[0, 2).
(10)
Proof: Fix any constant r ∈(1, 22−p), and choose x0 > 0 so large that
L(2x) ≤rL(x) for all x ≥x0. For such an x, we get
x2−pE[|ξ|p; |ξ| > x]
=
x2−p
n≥0E

|ξ|p; |ξ|/x ∈(2n, 2n+1]

≤

n≥02(p−2)nE

ξ2; |ξ|/x ∈(2n, 2n+1]

≤

n≥02(p−2)n(r −1)rnL(x)
=
(r −1)L(x)/(1 −2p−2r).
Now (10) follows, as we divide by L(x) and let x →∞and then r →1.
In particular, we note that E|ξ|p < ∞for all p < 2. If even Eξ2 < ∞,
then E(ξ −m)2 < ∞, and the ﬁrst assertion is obvious. If instead Eξ2 = ∞,
we may write
Lm(x) = E[ξ2; |ξ −m| ≤x] + mE[m −2ξ; |ξ −m| ≤x].

74
Foundations of Modern Probability
Here the last term is bounded, and the ﬁrst term lies between the bounds
L(x ±m) ∼L(x). Thus, Lm(x) ∼L(x), and the slow variation of Lm follows
from that of L.
✷
Proof of Theorem 4.17: Assume that L varies slowly at ∞. By Lemma
4.18 this is also true for the function Lm(x) = E[(ξ −m)2; |ξ −m| > x],
where m = Eξ, and so we may assume that Eξ = 0. Now deﬁne
cn = 1 ∨sup{x > 0; nL(x) ≥x2},
n ∈N,
and note that cn ↑∞. From the slow variation of L it is further clear that
cn < ∞for all n and that, moreover, nL(cn) ∼c2
n. In particular, cn ∼n1/2
iﬀL(cn) ∼1, that is, iﬀvar(ξ) = 1.
We shall verify the conditions of Theorem 4.15 with b = 0, c = 1, and
ξnj = ξj/cn, j ≤n. Beginning with (i), let ε > 0 be arbitrary, and conclude
from Lemma 4.18 that
nP{|ξ/cn| > ε} ∼c2
nP{|ξ| > cnε}
L(cn)
∼c2
nP{|ξ| > cnε}
L(cnε)
→0.
Recalling that Eξ = 0, we get by the same lemma
n|E[ξ/cn; |ξ/cn| ≤1]| ≤n
cn
E[|ξ|; |ξ| > cn] ∼cnE[|ξ|; |ξ| > cn]
L(cn)
→0,
(11)
which proves (ii). To obtain (iii), we note that in view of (11)
n var[ξ/cn; |ξ/cn| ≤1] = n
c2
n
L(cn) −n(E[ξ/cn; |ξ| ≤cn])2 →1.
By Theorem 4.15 the required convergence follows with an = c−1
n and mn ≡0.
Now assume instead that the stated convergence holds for suitable con-
stants an and mn. Then a corresponding result holds for the symmetrized
variables ˜ξ, ˜ξ1, ˜ξ2, . . . with constants an/
√
2 and 0, so we may assume that
c−1
n
	
k≤n ˜ξk
d→ζ. Here, clearly, cn →∞and, moreover, cn+1 ∼cn, since even
c−1
n+1
	
k≤n ˜ξk
d→ζ by Theorem 3.28. Now deﬁne for x > 0
˜T(x) = P{|˜ξ| > x},
˜L(x) = E[˜ξ2; |˜ξ| ≤x],
˜U(x) = E(˜ξ2 ∧x2).
By Theorem 4.15 we have n ˜T(cnε) →0 for all ε > 0, and also nc−2
n ˜L(cn)
→1. Thus, c2
n ˜T(cnε)/˜L(cn) →0, which extends by monotonicity to
x2 ˜T(x)
˜U(x)
≤x2 ˜T(x)
˜L(x)
→0,
x →∞.
Next deﬁne for any x > 0
T(x) = P{|ξ| > x},
U(x) = E(ξ2 ∧x2).

4. Characteristic Functions and Classical Limit Theorems
75
By Lemma 3.19 we have T(x + |m|) ≤2 ˜T(x) for any median m of ξ. Fur-
thermore, by Lemmas 2.4 and 3.19 we get
˜U(x) =

 x2
0
P{˜ξ2 > t}dt ≤2

 x2
0
P{4ξ2 > t}dt = 8U(x/2).
Hence, as x →∞,
L(2x) −L(x)
L(x)
≤
4x2T(x)
U(x) −x2T(x) ≤
8x2 ˜T(x −|m|)
8−1 ˜U(2x) −2x2 ˜T(x −|m|) →0,
which shows that L is slowly varying.
Finally, assume that n−1/2 	
k≤n ξk
d→ζ. By the previous argument with
cn = n1/2, we get ˜L(n1/2) →2, which implies E ˜ξ2 = 2 and hence var(ξ) = 1.
But then n−1/2 	
k≤n(ξk −Eξ)
d→ζ, and by comparison Eξ = 0.
✷
We return to the general problem of characterizing the weak convergence
of a sequence of probability measures µn on Rd in terms of the associated
characteristic functions ˆµn or Laplace transforms ˜µn. Suppose that ˆµn or
˜µn converges toward some continuous limit ϕ, which is not recognized as a
characteristic function or Laplace transform. To conclude that µn converges
weakly toward some measure µ, we need an extended version of Theorem
4.3, which in turn requires a compactness argument for its proof.
As a preparation, consider the space M = M(Rd) of locally ﬁnite mea-
sures on Rd. On M we may introduce the vague topology, generated by the
mappings µ →µf =
 fdµ for all f ∈C+
K, the class of continuous functions
f : Rd →R+ with compact support. In particular, µn converges vaguely to
µ (written as µn
v→µ) iﬀµnf →µf for all f ∈C+
K. If the µn are probability
measures, then clearly µRd ≤1. The following version of Helly’s selection
theorem shows that the set of probability measures on Rd is vaguely relatively
sequentially compact.
Theorem 4.19 (vague sequential compactness, Helly) Any sequence of prob-
ability measures on Rd has a vaguely convergent subsequence.
Proof: Fix any probability measures µ1, µ2, . . . on Rd, and let F1, F2, . . .
denote the corresponding distribution functions. Write Q for the set of ra-
tional numbers. By a diagonal argument, the functions Fn converge on Qd
toward some limit G, along a suitable subsequence N ′ ⊂N, and we may
deﬁne
F(x) = inf{G(r); r ∈Qd, r > x},
x ∈Rd.
(12)
Since each Fn has nonnegative increments, the same thing is true for G and
hence also for F. From (12) and the monotonicity of G, it is further clear that
F is right-continuous. Hence, by Corollary 2.26 there exists some measure µ
on Rd with µ(x, y] = F(x, y] for any bounded rectangular box (x, y] ⊂Rd,
and it remains to show that µn
v→µ along N ′.

76
Foundations of Modern Probability
Then note that Fn(x) →F(x) at every continuity point x of F. By the
monotonicity of F there exist some countable sets D1, . . . , Dd ⊂R such that
F is continuous on C = Dc
1×· · ·×Dc
d. Then µnU →µU for every ﬁnite union
U of rectangular boxes with corners in C, and by a simple approximation we
get for any bounded Borel set B ⊂Rd
µB◦≤lim inf
n→∞µnB ≤lim sup
n→∞µnB ≤µB.
(13)
For any bounded µ-continuity set B, we may consider functions f ∈C+
K
supported by B, and proceed as in the proof of Theorem 3.25 to show that
µnf →µf. Thus, µn
v→µ.
✷
If µn
v→µ for some probability measures µn on Rd, we may still have
µRd < 1, due to an escape of mass to inﬁnity. To exclude this possibility, we
need to assume that (µn) be tight.
Lemma 4.20 (vague and weak convergence) For any probability measures
µ1, µ2, . . . on Rd with µn
v→µ for some measure µ, we have µRd = 1 iﬀ(µn)
is tight, and then µn
w→µ.
Proof: By a simple approximation, the vague convergence implies (13)
for every bounded Borel set B, and in particular for the balls Br = {x ∈Rd;
|x| ≤r}, r > 0. If µRd = 1, then µB◦
r →1 as r →∞, and the ﬁrst inequality
shows that (µn) is tight. Conversely, if (µn) is tight, then lim supn µnBr →1,
and the last inequality yields µRd = 1.
Now assume that (µn) is tight, and ﬁx any bounded continuous function
f : Rd →R. For any r > 0, we may choose some gr ∈C+
K with 1Br ≤gr ≤1
and note that
|µnf −µf|
≤
|µnf −µnfgr| + |µnfgr −µfgr| + |µfgr −µf|
≤
|µnfgr −µfgr| + ∥f∥(µn + µ)Bc
r.
Here the right-hand side tends to zero as n →∞and then r →∞, so
µnf →µf. Hence, in this case µn
w→µ.
✷
Combining the last two results, we may easily show that the notions
of tightness and weak sequential compactness are equivalent. The result is
extended in Theorem 14.3, which forms a starting point for the theory of
weak convergence on function spaces.
Proposition 4.21 (tightness and weak sequential compactness) A sequence
of probability measures on Rd is tight iﬀevery subsequence has a weakly
convergent further subsequence.
Proof: Fix any probability measures µ1, µ2, . . . on Rd. By Theorem 4.19
every subsequence has a vaguely convergent further subsequence. If (µn) is
tight, then by Lemma 4.20 the convergence holds even in the weak sense.

4. Characteristic Functions and Classical Limit Theorems
77
Now assume instead that (µn) has the stated property. If it fails to be
tight, we may choose a sequence nk →∞and some constant ε > 0 such that
µnkBc
k > ε for all k ∈N. By hypothesis there exists some probability mea-
sure µ on Rd such that µnk
w→µ along a subsequence N ′ ⊂N. The sequence
(µnk; k ∈N ′) is then tight by Lemma 3.8, and in particular there exists some
r > 0 with µnkBc
r ≤ε for all k ∈N ′. For k > r this is a contradiction, and
the asserted tightness follows.
✷
We may now prove the desired extension of Theorem 4.3.
Theorem 4.22 (extended continuity theorem, L´evy, Bochner) Let µ1, µ2,
. . . be probability measures on Rd with ˆµn(t) →ϕ(t) for every t ∈Rd, where
the limit ϕ is continuous at 0.
Then µn
w→µ for some probability mea-
sure µ on Rd with ˆµ = ϕ. A corresponding statement holds for the Laplace
transforms of measures on Rd
+.
Proof: Assume that ˆµn →ϕ, where the limit is continuous at 0. As in
the proof of Theorem 4.3, we may conclude that (µn) is tight. Hence, by
Proposition 4.21 there exists some probability measure µ on Rd such that
µn
w→µ along a subsequence N ′ ⊂N. By continuity we get ˆµn →ˆµ along
N ′, so ϕ = ˆµ, and by Theorem 4.3 the convergence µn
w→µ extends to N.
The proof for Laplace transforms is similar.
✷
Exercises
1. Show that if ξ and η are independent Poisson random variables, then
ξ + η is again Poisson. Also show that the Poisson property is preserved
under convergence in distribution.
2. Show that any linear combination of independent Gaussian random
variables is again Gaussian. Also show that the class of Gaussian distribu-
tions is preserved under weak convergence.
3. Show that ϕr(t) = (1 −t/r)+ is a characteristic functions for every
r > 0. (Hint: Compute the Fourier transform ˆψr of the function ψr(t) =
1{|t| ≤r}, and note that the Fourier transform ˆψ2
r of ψ∗2
r is integrable. Now
use Fourier inversion.)
4. Let ϕ be a real, even function that is convex on R+ and satisﬁes ϕ(0) =
1 and ϕ(∞) ∈[0, 1].
Show that ϕ is the characteristic function of some
symmetric distribution on R. In particular, ϕ(t) = e−|t|c is a characteristic
function for every c ∈[0, 1]. (Hint: Approximate by convex combinations of
functions ϕr as above, and use Theorem 4.22.)
5. Show that if ˆµ is integrable, then µ has a bounded and continuous
density. (Hint: Let ϕr be the triangular density above. Then ( ˆϕr)ˆ= 2πϕr,
and so
 e−ituˆµt ˆϕr(t)dt = 2π
 ϕr(x −u)µ(dx). Now let r →0.)

78
Foundations of Modern Probability
6. Show that a distribution µ is supported by some set aZ + b iﬀ|ˆµt| = 1
for some t ̸= 0.
7. Give an elementary proof of the continuity theorem for generating
functions of distributions on Z+.
(Hint: Note that if µn
v→µ for some
distributions on R+, then ˜µn →˜µ on (0, ∞).)
8. The moment-generating function of a distribution µ on R is given by
˜µt =
 etxµ(dx). Assuming ˜µt < ∞for all t in some nondegenerate interval
I, show that ˜µ is analytic in the strip {z ∈C; ℜz ∈I◦}. (Hint: Approximate
by measures with bounded support.)
9. Let µ, µ1, µ2, . . . be distributions on R with moment-generating func-
tions ˜µ, ˜µ1, ˜µ2, . . . such that ˜µn →˜µ < ∞on some nondegenerate interval
I. Show that µn
w→µ. (Hint: If µn
v→ν along some subsequence N ′, then
˜µn →˜ν on I◦along N ′, and so ˜ν = ˜µ on I. By the preceding exercise we get
νR = 1 and ˆν = ˆµ. Thus, ν = µ.)
10. Let µ and ν be distributions on R with ﬁnite moments
 xnµ(dx) =
 xnν(dx) = mn, where
	
n tn|mn|/n! < ∞for some t > 0. Show that µ = ν.
(Hint: The absolute moments satisfy the same relation for any smaller value
of t, so the moment-generating functions exist and agree on (−t, t).)
11. For each n ∈N, let µn be a distribution on R with ﬁnite moments mk
n,
k ∈N, such that limn mk
n = ak for some constants ak with
	
k tk|ak|/k! < ∞
for some t > 0. Show that µn
w→µ for some distribution µ with moments ak.
(Hint: Each function xk is uniformly integrable with respect to the measures
µn. In particular, (µn) is tight. If µn
w→ν along some subsequence, then ν
has moments ak.)
12. Given a distribution µ on R × R+, introduce the mixed transform
ϕ(s, t) =
 eisx−tyµ(dx dy), where s ∈R and t ≥0. Prove versions for ϕ of
the continuity Theorems 4.3 and 4.22.
13. Consider a null array of random vectors ξnj = (ξ1
nj, . . . , ξd
nj) in Zd
+, let
ξ1, . . . , ξd be independent Poisson variables with means c1, . . . , cd, and put
ξ = (ξ1, . . . , ξd). Show that
	
j ξnj
d→ξ iﬀ
	
j P{ξk
nj = 1} →ck for all k
and 	
j P{
	
k ξk
nj > 1} →0. (Hint: Introduce independent random variables
ηk
nj
d= ξk
nj, and note that
	
j ξnj
d→ξ iﬀ
	
j ηnj
d→ξ.)
14. Consider some random variables ξ⊥⊥η with ﬁnite variance such that
the distribution of (ξ, η) is rotationally invariant. Show that ξ is centered
Gaussian. (Hint: Let ξ1, ξ2, . . . be i.i.d. and distributed as ξ, and note that
n−1/2 	
k≤n ξk has the same distribution for all n. Now use Proposition 4.9.)
15. Prove a multivariate version of the Taylor expansion in Lemma 4.10.
16. Let µ have a ﬁnite nth moment mn. Show that ˆµ is n times contin-
uously diﬀerentiable and satisﬁes ˆµ(n)
0
= inmn. (Hint: Diﬀerentiate n times
under the integral sign.)

4. Characteristic Functions and Classical Limit Theorems
79
17. For µ and mn as above, show that ˆµ(2n)
0
exists iﬀm2n < ∞. Also,
characterize the distributions such that ˆµ(2n−1)
0
exists. (Hint: For ˆµ′′
0 proceed
as in the proof of Proposition 4.9, and use Theorem 4.17. For ˆµ′
0 use Theorem
4.16. Extend by induction to n > 1.)
18. Let µ be a distribution on R+ with moments mn. Show that ˜µ(n)
0
=
(−1)nmn whenever either side exists and is ﬁnite. (Hint: Prove the statement
for n = 1, and extend by induction.)
19. Deduce Proposition 4.9 from Theorem 4.12.
20. Let the random variables ξ and ξnj be such as in Theorem 4.12, and
assume that 	
j E|ξnj|c →0 for some c > 2. Show that
	
j ξnj
d→ξ.
21. Extend Theorem 4.12 to random vectors in Rd, with the condition
	
j Eξ2
nj →1 replaced by
	
j cov(ξnj) →a, with ξ as N(0, a), and with ξ2
nj
replaced by |ξnj|2. (Hint: Use Corollary 4.5 to reduce to one dimension.)
22. Show that Theorem 4.15 remains true for random vectors in Rd, with
var[ξnj; |ξnj| ≤1] replaced by the corresponding covariance matrix. (Hint:
If a, a1, a2, . . . are symmetric, nonnegative deﬁnite matrices, then an →a iﬀ
u′anu →u′au for all u ∈Rd. To see this, use a compactness argument.)
23. Show that Theorems 4.7 and 4.15 remain valid for possibly inﬁnite
row-sums 	
j ξnj. (Hint: Use Theorem 3.17 or 3.18 together with Theorem
3.28.)
24. Let ξ, ξ1, ξ2, . . . be i.i.d. random variables. Show that n−1/2 	
k≤n ξk
converges in probability iﬀξ = 0 a.s. (Hint: Use condition (iii) in Theorem
4.15.)
25. Let ξ1, ξ2, . . . be i.i.d. µ, and ﬁx any p ∈(0, 2). Find a µ such that
n−1/p 	
k≤n ξk →0 in probability but not a.s.
26. Let ξ1, ξ2, . . . be i.i.d., and let p > 0 be such that n−1/p 	
k≤n ξk →0 in
probability but not a.s. Show that lim supn n−1/p|
	
k≤n ξk| = ∞a.s. (Hint:
Note that E|ξ1|p = ∞.)
27. Give an example of a distribution with inﬁnite second moment in
the domain of attraction of the Gaussian law, and ﬁnd the corresponding
normalization.

Chapter 5
Conditioning and Disintegration
Conditional expectations and probabilities; regular conditional dis-
tributions;
disintegration theorem;
conditional independence;
transfer and coupling; Daniell–Kolmogorov theorem; extension by
conditioning
Modern probability theory can be said to begin with the notions of condi-
tioning and disintegration. In particular, conditional expectations and dis-
tributions are needed already for the deﬁnitions of martingales and Markov
processes, the two basic dependence structures beyond independence and
stationarity. Even in other areas and throughout probability theory, condi-
tioning is constantly used as a basic tool to describe and analyze systems
involving randomness. The notion may be thought of in terms of averaging,
projection, and disintegration—viewpoints that are all essential for a proper
understanding.
In all but the most elementary contexts, one deﬁnes conditioning with
respect to a σ-ﬁeld rather than a single event. In general, the result of the
operation is not a constant but a random variable, measurable with respect
to the given σ-ﬁeld. The idea is familiar from elementary constructions of
the conditional expectation E[ξ|η], in cases where (ξ, η) is a random vector
with a nice density, and the result is obtained as a suitable function of η.
This corresponds to conditioning on the σ-ﬁeld F = σ(η).
The simplest and most intuitive general approach to conditioning is via
projection. Here E[ξ|F] is deﬁned for any ξ ∈L2 as the orthogonal Hilbert
space projection of ξ onto the linear subspace of F-measurable random
variables. The L2-version extends immediately, by continuity, to arbitrary
ξ ∈L1.
From the orthogonality of the projection one gets the relation
E(ξ −E[ξ|F])ζ = 0 for any bounded, F-measurable random variable ζ.
This leads in particular to the familiar averaging characterization of E[ξ|F]
as a version of the density d(ξ · P)/dP on the σ-ﬁeld F, the existence of
which can also be inferred from the Radon–Nikod´ym theorem.
The conditional expectation is deﬁned only up to a null set, in the sense
that any two versions agree a.s. It is then natural to look for versions of
the conditional probabilities P[A|F] = E[1A|F] that combine into a random
probability measure on Ω. In general, such regular versions exist only for
A restricted to suitable sub-σ-ﬁelds. The basic case is when ξ is a random
element in some Borel space S, and the conditional distribution P[ξ ∈·|F]
80

5. Conditioning and Disintegration
81
may be constructed as an F-measurable random measure on S. If we further
assume that F = σ(η) for a random element η in some space T, we may write
P[ξ ∈B|η] = µ(η, B) for some probability kernel µ from T to S. This leads
to a decomposition of the distribution of (ξ, η) according to the values of η.
The result is formalized in the disintegration theorem—a powerful extension
of Fubini’s theorem that is often used in subsequent chapters, especially in
combination with the (strong) Markov property.
Using conditional distributions, we shall further establish the basic trans-
fer theorem, which may be used to convert any distributional equivalence
ξ
d= f(η) into a corresponding a.s. representation ξ = f(˜η) with a suitable
˜η
d= η. From the latter result, one easily obtains the fundamental Daniell–
Kolmogorov theorem, which ensures the existence of random sequences and
processes with speciﬁed ﬁnite-dimensional distributions.
A diﬀerent ap-
proach is required for the more general Ionescu Tulcea extension, where the
measure is speciﬁed by a sequence of conditional distributions.
Further topics treated in this chapter include the notion of conditional in-
dependence, which is fundamental for both Markov processes and exchange-
ability and also plays an important role in Chapter 18, in connection with
SDEs. Especially useful in those contexts is the elementary but powerful
chain rule. Let us ﬁnally call attention to the local property of conditional
expectations, which in particular leads to simple and transparent proofs of
the strong Markov and optional sampling theorems.
Returning to our construction of conditional expectations, let us ﬁx a
probability space (Ω, A, P) and consider an arbitrary sub-σ-ﬁeld F ⊂A. In
L2 = L2(A) we may introduce the closed linear subspace M, consisting of all
random variables η ∈L2 that agree a.s. with some element of L2(F). By the
Hilbert space projection Theorem 1.34, there exists for every ξ ∈L2 an a.s.
unique random variable η ∈M with ξ−η ⊥M, and we deﬁne EFξ = E[ξ|F]
as an arbitrary F-measurable version of η.
The L2-projection EF is easily extended to L1, as follows.
Theorem 5.1 (conditional expectation, Kolmogorov) For any σ-ﬁeld F ⊂
A there exists an a.s. unique linear operator EF : L1 →L1(F) such that
(i) E[EFξ; A] = E[ξ; A], ξ ∈L1, A ∈F.
The following additional properties hold whenever the corresponding expres-
sions exist for the absolute values:
(ii) ξ ≥0 implies EFξ ≥0 a.s.;
(iii) E|EFξ| ≤E|ξ|;
(iv) 0 ≤ξn ↑ξ implies EFξn ↑EFξ a.s.;
(v) EFξη = ξEFη a.s. when ξ is F-measurable;
(vi) E(ξEFη) = E(ηEFξ) = E(EFξ · EFη);
(vii) EFEGξ = EFξ a.s. for all F ⊂G.

82
Foundations of Modern Probability
In particular, we note that EFξ = ξ a.s. iﬀξ has an F-measurable version
and that EFξ = Eξ a.s. when ξ⊥⊥F.
We shall often refer to (i) as the
averaging property, to (ii) as the positivity, to (iii) as the L1-contractivity, to
(iv) as the monotone convergence property, to (v) as the pull-out property, to
(vi) as the self-adjointness, and to (vii) as the chain rule. Since the operator
EF is both self-adjoint by (vi) and idempotent by (vii), it may be thought
of as a generalized projection on L1.
The existence of EF is an immediate consequence of the Radon–Nikod´ym
Theorem A1.3. However, we prefer the following elementary construction
from the L2-version.
Proof of Theorem 5.1: First assume that ξ ∈L2, and deﬁne EFξ by
projection as above. For any A ∈F we get ξ −EFξ ⊥1A, and (i) follows.
Taking A = {EFξ ≥0}, we get in particular
E|EFξ| = E[EFξ; A] −E[EFξ; Ac] = E[ξ; A] −E[ξ; Ac] ≤E|ξ|,
which proves (iii). Thus, the mapping EF is uniformly L1-continuous on L2.
Also note that L2 is dense in L1 by Lemma 1.11 and that L1 is complete
by Lemma 1.31. Hence, EF extends a.s. uniquely to a linear and continuous
mapping on L1.
Properties (i) and (iii) extend by continuity to L1, and from Lemma 1.24
we note that EFξ is a.s. determined by (i). If ξ ≥0, it is clear from (i) with
A = {EFξ ≤0} together with Lemma 1.24 that EFξ ≥0, which proves (ii).
If 0 ≤ξn ↑ξ, then ξn →ξ in L1 by dominated convergence, so by (iii) we get
EFξn →EFξ in L1. Now the sequence (EFξn) is a.s. nondecreasing by (ii),
so by Lemma 3.2 the convergence remains true in the a.s. sense. This proves
(iv).
Property (vi) is obvious when ξ, η ∈L2, and it extends to the general
case by means of (iv). To prove (v), we note from the characterization in (i)
that EFξ = ξ a.s. when ξ is F-measurable. In the general case we need to
show that
E[ξη; A] = E[ξEFη; A],
A ∈F,
which follows immediately from (vi). Finally, property (vii) is obvious for
ξ ∈L2 since L2(F) ⊂L2(G), and it extends to the general case by means of
(iv).
✷
The next result shows that the conditional expectation EFξ is local in
both ξ and F, an observation that simpliﬁes many proofs. Given two σ-
ﬁelds F and G, we say that F = G on A if A ∈F ∩G and A ∩F = A ∩G.
Lemma 5.2 (local property) Let the σ-ﬁelds F, G ⊂A and functions ξ, η ∈
L1 be such that F = G and ξ = η a.s. on some set A ∈F ∩G.
Then
EFξ = EGη a.s. on A.

5. Conditioning and Disintegration
83
Proof: Since 1AEFξ and 1AEGη are F ∩G-measurable, we get B ≡A ∩
{EFξ > EGη} ∈F ∩G, and the averaging property yields
E[EFξ; B] = E[ξ; B] = E[η; B] = E[EGη; B].
Hence, EFξ ≤EGη a.s. on A by Lemma 1.24. Similarly, EGη ≤EFξ a.s.
on A.
✷
The conditional probability of an event A ∈A, given a σ-ﬁeld F, is deﬁned
as
P FA = EF1A
or
P[A|F] = E[1A|F],
A ∈A.
Thus, P FA is the a.s. unique random variable in L1(F) satisfying
E[P FA; B] = P(A ∩B),
B ∈F.
Note that P FA = PA a.s. iﬀA⊥⊥F and that P FA = 1A a.s. iﬀA agrees a.s.
with a set in F. From the positivity of EF we get 0 ≤P FA ≤1 a.s., and by
the monotone convergence property it is further seen that
P F
nAn =

nP FAn a.s.,
A1, A2, . . . ∈A disjoint.
(1)
Here the exceptional null set may depend on the sequence (An), so P F is not
a measure in general.
If η is a random element in some measurable space (S, S), then condi-
tioning on η is deﬁned as conditioning with respect to the induced σ-ﬁeld
σ(η). Thus,
Eηξ = Eσ(η)ξ,
P ηA = P σ(η)A,
or
E[ξ|η] = E[ξ|σ(η)],
P[A|η] = P[A|σ(η)].
By Lemma 1.13, the η-measurable function Eηξ may be represented in the
form f(η), where f is a measurable function on S, determined P ◦η−1-a.e.
by the averaging property
E[f(η); η ∈B] = E[ξ; η ∈B],
B ∈S.
In particular, we note that f depends only on the distribution of (ξ, η).
The situation for P ηA is similar. Conditioning with respect to a σ-ﬁeld F is
clearly the special case when η is the identity mapping from (Ω, A) to (Ω, F).
Motivated by (1), we proceed to examine the existence of measure-valued
versions of the functions P F and P η. Then recall from Chapter 1 that a kernel
between two measurable spaces (T, T ) and (S, S) is a function µ: T ×S →R+
such that µ(t, B) is T -measurable in t ∈T for each B ∈S and a measure in
B ∈S for each t ∈T. Say that µ is a probability kernel if µ(t, S) = 1 for all
t. Kernels on the basic probability space Ωare called random measures.
Now ﬁx a σ-ﬁeld F ⊂A and a random element ξ in some measurable
space (S, S). By a regular conditional distribution of ξ, given F, we mean

84
Foundations of Modern Probability
a version of the function P[ξ ∈· |F] on Ω× S which is a probability kernel
from (Ω, F) to (S, S), hence an F-measurable random probability measure
on S. More generally, if η is another random element in some measurable
space (T, T ), a regular conditional distribution of ξ, given η, is deﬁned as a
random measure of the form
µ(η, B) = P[ξ ∈B|η] a.s.,
B ∈S,
(2)
where µ is a probability kernel from T to S. In the extreme cases when ξ is
F-measurable or independent of F, we note that P[ξ ∈B|F] has the regular
version 1{ξ ∈B} or P{ξ ∈B}, respectively. The general case requires some
regularity conditions on the space S.
Theorem 5.3 (conditional distribution) Fix a Borel space S and a measur-
able space T, and let ξ and η be random elements in S and T, respectively.
Then there exists a probability kernel µ from T to S satisfying P[ξ ∈· |η] =
µ(η, ·) a.s., and µ is unique a.e. P ◦η−1.
Proof: We may assume that S ∈B(R). For every r ∈Q we may choose
some measurable function fr = f(·, r): T →[0, 1] such that
f(η, r) = P[ξ ≤r|η] a.s.,
r ∈Q.
(3)
Let A be the set of elements t ∈T such that f(t, r) is nondecreasing in
r ∈Q with limits 1 and 0 at ±∞. Since A is speciﬁed by countably many
measurable conditions, each of which holds a.s. at η, we have A ∈T and
η ∈A a.s. Now deﬁne
F(t, x) = 1A(t) infr>xf(t, r) + 1Ac(t)1{x ≥0},
x ∈R, t ∈T,
and note that F(t, ·) is a distribution function on R for every t ∈T. Hence,
there exists some probability measures m(t, ·) on R with
m(t, (−∞, x]) = F(t, x),
x ∈R, t ∈T.
The function F(t, x) is clearly measurable in t for each x, and by a monotone
class argument it follows that m is a kernel from T to R.
By (3) and the monotone convergence property of Eη, we have
m(η, (−∞, x]) = F(η, x) = P[ξ ≤x|η] a.s.,
x ∈R.
Using a monotone class argument based on the a.s. monotone convergence
property, we may extend the last relation to
m(η, B) = P[ξ ∈B|η] a.s.,
B ∈B(R).
(4)
In particular, we get m(η, Sc) = 0 a.s., and so (4) remains true on S = B ∩S
with m replaced by the kernel
µ(t, ·) = m(t, ·)1{m(t, S) = 1} + δs1{m(t, S) < 1},
t ∈T,

5. Conditioning and Disintegration
85
where s ∈S is arbitrary. If µ′ is another kernel with the stated property,
then
µ(η, (−∞, r]) = P[ξ ≤r|η] = µ′(η, (−∞, r]) a.s.,
r ∈Q,
and a monotone class argument yields µ(η, ·) = µ′(η, ·) a.s.
✷
We shall next extend Fubini’s theorem, by showing how ordinary and con-
ditional expectations can be computed by integration with respect to suitable
conditional distributions. The result may be regarded as a disintegration of
measures on a product space into their one-dimensional components.
Theorem 5.4 (disintegration) Fix two measurable spaces S and T, a σ-ﬁeld
F ⊂A, and a random element ξ in S such that P[ξ ∈· |F] has a regular
version ν. Further consider an F-measurable random element η in T and a
measurable function f on S × T with E|f(ξ, η)| < ∞. Then
E[f(ξ, η)|F] =

ν(ds)f(s, η) a.s.
(5)
The a.s. existence and F-measurability of the integral on the right should
be regarded as part of the assertion. In the special case when F = σ(η) and
P[ξ ∈· |η] = µ(η, ·) for some probability kernel µ from T to S, (5) becomes
E[f(ξ, η)|η] =

µ(η, ds)f(s, η) a.s.
(6)
Integrating (5) and (6), we get the commonly used formulas
Ef(ξ, η) = E

ν(ds)f(s, η) = E

µ(η, ds)f(s, η).
(7)
If ξ⊥⊥η, we may take µ(η, ·) ≡P ◦ξ−1, and (7) reduces to the relation in
Lemma 2.11.
Proof of Theorem 5.4: If B ∈S and C ∈T , we may use the averaging
property of conditional expectations to get
P{ξ ∈B, η ∈C}
=
E[P[ξ ∈B|F]; η ∈C] = E[νB; η ∈C]
=
E

ν(ds)1{s ∈B, η ∈C},
which proves the ﬁrst relation in (7) for f = 1B×C. The formula extends,
along with the measurability of the inner integral on the right, ﬁrst by a
monotone class argument to all measurable indicator functions, and then by
linearity and monotone convergence to any measurable function f ≥0.
Now ﬁx a measurable function f : S × T →R+ with Ef(ξ, η) < ∞,
and let A ∈F be arbitrary. Regarding (η, 1A) as an F-measurable random
element in T × {0, 1}, we may conclude from (7) that
E[f(ξ, η); A] = E

ν(ds)f(s, η)1A,
A ∈F.

86
Foundations of Modern Probability
This proves (5) for f ≥0, and the general result follows by taking diﬀer-
ences.
✷
Applying (7) to functions of the form f(ξ), we may extend many prop-
erties of ordinary expectations to a conditional setting. In particular, such
extensions hold for the inequalities of Jensen, H¨older, and Minkowski. The
ﬁrst of those implies the Lp-contractivity
∥EFξ∥p ≤∥ξ∥p,
ξ ∈Lp, p ≥1.
Considering conditional distributions of entire sequences (ξ, ξ1, ξ2, . . .), we
may further derive conditional versions of the basic continuity properties of
ordinary integrals.
The following result plays an important role in Chapter 6.
Lemma 5.5 (uniform integrability, Doob) For any ξ ∈L1, the conditional
expectations E[ξ|F], F ⊂A, are uniformly integrable.
Proof: By Jensen’s inequality and the self-adjointness property,
E[|EFξ|; A] ≤E[EF|ξ|; A] = E[|ξ|P FA],
A ∈A,
and by Lemma 3.10 we need to show that this tends to zero as PA →0,
uniformly in F. By dominated convergence along subsequences, it is then
enough to show that P FnAn
P→0 for any σ-ﬁelds Fn ⊂A and sets An ∈A
with PAn →0. But this is clear, since EP FnAn = PAn →0.
✷
Turning to the topic of conditional independence, consider any sub-σ-
ﬁelds F1, . . . , Fn, G ⊂A. Imitating the deﬁnition of ordinary independence,
we say that F1, . . . , Fn are conditionally independent, given G, if
P G 
k≤nBk =

k≤nP GBk a.s.,
Bk ∈Fk, k = 1, . . . , n.
For inﬁnite collections of σ-ﬁelds Ft, t ∈T, the same property is required
for every ﬁnite subcollection Ft1, . . . , Ftn with distinct indices t1, . . . , tn ∈T.
The relation ⊥⊥G will be used to denote pairwise conditional independence,
given some σ-ﬁeld G. Conditional independence involving events At or ran-
dom elements ξt, t ∈T, is deﬁned as before in terms of the induced σ-ﬁelds
σ(At) or σ(ξt), respectively, and the notation involving ⊥⊥carries over to this
case.
In particular, we note that any F-measurable random elements ξt are
conditionally independent, given F. If the ξt are instead independent of F,
then their conditional independence, given F, is equivalent to the ordinary
independence between the ξt. The regularization theorem shows that any
general statement or formula involving conditional independencies between
countably many random elements in some Borel space remains true in a

5. Conditioning and Disintegration
87
conditional setting. For example, as in Lemma 2.8, the σ-ﬁelds F1, F2, . . .
are conditionally independent, given G, iﬀ
(F1, . . . , Fn)⊥⊥
G Fn+1,
n ∈N.
Much more can be said in the conditional case, and we begin with a fun-
damental characterization. If nothing else is said, F, G, . . . with or without
subscripts denote sub-σ-ﬁelds of A.
Proposition 5.6 (conditional independence, Doob) For any σ-ﬁelds F, G,
and H, we have F⊥⊥GH iﬀ
P[H|F, G] = P[H|G] a.s.,
H ∈H.
(8)
Proof: Assuming (8) and using the chain and pull-out properties of con-
ditional expectations, we get for any F ∈F and H ∈H
P G(F ∩H)
=
EGP F∨G(F ∩H) = EG[P F∨GH; F]
=
EG[P GH; F] = (P GF) (P GH),
which shows that F⊥⊥GH. Conversely, assuming F⊥⊥GH and using the chain
and pull-out properties, we get for any F ∈F, G ∈G, and H ∈H
E[P GH; F ∩G]
=
E[(P GF) (P GH); G]
=
E[P G(F ∩H); G] = P(F ∩G ∩H).
By a monotone class argument, this extends to
E[P GH; A] = P(H ∩A),
A ∈F ∨G,
and (8) follows by the averaging characterization of P F∨GH.
✷
From the last result we may easily deduce some further useful proper-
ties. Let G denote the completion of G with respect to the basic σ-ﬁeld A,
generated by G and the family N = {N ⊂A; A ∈A, PA = 0}.
Corollary 5.7 For any σ-ﬁelds F, G, and H, we have
(i) F⊥⊥GH iﬀF⊥⊥G(G, H);
(ii) F⊥⊥GF iﬀF ⊂G.
Proof: (i) By Proposition 5.6, both relations are equivalent to
P[F|G, H] = P[F|G] a.s.,
F ∈F.
(ii) If F⊥⊥GF, then by Proposition 5.6
1F = P[F|F, G] = P[F|G] a.s.,
F ∈F,
which implies F ⊂G. Conversely, the latter relation yields
P[F|G] = P[F|G] = 1F = P[F|F, G] a.s.,
F ∈F,
and so F⊥⊥GF by Proposition 5.6.
✷
The following result is often applied in both directions.

88
Foundations of Modern Probability
Proposition 5.8 (chain rule) For any σ-ﬁelds G, H, and F1, F2, . . . , these
conditions are equivalent:
(i) H⊥⊥
G (F1, F2, . . .);
(ii) H ⊥⊥
G, F1, . . . , Fn
Fn+1,
n ≥0.
Proof: Assuming (i), we get by Proposition 5.6 for any H ∈H and n ≥0
P[H|G, F1, . . . , Fn] = P[H|G] = P[H|G, F1, . . . , Fn+1],
and (ii) follows by another application of Proposition 5.6.
Now assume (ii) instead, and conclude by Proposition 5.6 that for any
H ∈H
P[H|G, F1, . . . , Fn] = P[H|G, F1, . . . , Fn+1],
n ≥0.
Summing over n < m gives
P[H|G] = P[H|G, F1, . . . , Fm],
m ≥1,
so by Proposition 5.6
H⊥⊥
G (F1, . . . , Fm),
m ≥1,
which extends to (i) by a monotone class argument.
✷
The last result is even useful for establishing ordinary independence. In
fact, taking G = {∅, Ω} in Proposition 5.8, we note that H⊥⊥(F1, F2, . . .) iﬀ
H ⊥⊥
F1, . . . , Fn
Fn+1,
n ≥0.
Our next aim is to show how regular conditional distributions can be used
to construct random elements with desired properties.
This may require
an extension of the basic probability space. By an extension of (Ω, A, P)
we mean a product space (ˆΩ, ˆ
A) = (Ω× S, A ⊗S), equipped with some
probability measure ˆP satisfying ˆP(· × S) = P. Any random element ξ on
Ωmay be regarded as deﬁned on ˆΩ. Thus, we may formally replace ξ by the
random element ˆξ(ω, s) = ξ(ω), which clearly has the same distribution. For
extensions of this type, we may retain our original notation and write P and
ξ instead of ˆP and ˆξ.
We begin with an elementary extension suggested by Theorem 5.4. The
result is needed for various constructions in Chapter 10.
Lemma 5.9 (extension) Fix a probability kernel µ between two measurable
spaces S and T, and let ξ be a random element in S. Then there exists a
random element η in T, deﬁned on some extension of the original probability
space Ω, such that P[η ∈·|ξ] = µ(ξ, ·) a.s. and, moreover, η⊥⊥ξζ for any
random element ζ on Ω.

5. Conditioning and Disintegration
89
Proof: Letting T be the σ-ﬁeld in T, we may put (ˆΩ, ˆ
A) = (Ω×T, A⊗T ),
and deﬁne a probability measure ˆP on ˆΩby
ˆPA = E

1A(·, t)µ(ξ, dt),
A ∈ˆ
A.
Then clearly ˆP(·×T) = P, and the random element η(ω, t) ≡t on ˆΩsatisﬁes
ˆP[η ∈·|A] = µ(ξ, ·) a.s. In particular, we get η⊥⊥ξA by Proposition 5.6, and
so η⊥⊥ξζ.
✷
For most constructions we need only a single randomization variable.
By this we mean a U(0, 1) random variable ϑ that is independent of all
previously introduced random elements and σ-ﬁelds. The basic probability
space is henceforth assumed to be rich enough to support any randomization
variables we may need. This involves no serious loss of generality, since we
can always get the condition fulﬁlled by a simple extension of the space. In
fact, it suﬃces to take
ˆΩ= Ω× [0, 1],
ˆ
A = A ⊗B[0, 1],
ˆP = P ⊗λ,
where λ denotes Lebesgue measure on [0, 1]. Then ϑ(ω, t) ≡t is U(0, 1) on
ˆΩand ϑ⊥⊥A. By Lemma 2.21 we may use ϑ to produce a whole sequence of
independent randomization variables ϑ1, ϑ2, . . . if required.
The following basic result shows how a probabilistic structure can be car-
ried over from one context to another by means of a suitable randomization.
Constructions of this type are frequently employed in the sequel.
Theorem 5.10 (transfer) Fix any measurable space S and Borel space T,
and let ξ
d= ˜ξ and η be random elements in S and T, respectively. Then
there exists a random element ˜η in T with (˜ξ, ˜η)
d= (ξ, η). More precisely,
there exists a measurable function f : S × [0, 1] →T such that we may take
˜η = f(˜ξ, ϑ) whenever ϑ⊥⊥˜ξ is U(0, 1).
Proof: By Theorem 5.3 there exists a probability kernel µ from S to T
satisfying
µ(ξ, B) = P[η ∈B|ξ],
B ∈B[0, 1],
and by Lemma 2.22 we may further choose a measurable function f : S ×
[0, 1] →T such that f(s, ϑ) has distribution µ(s, ·) for every s ∈S. Deﬁne
˜η = f(˜ξ, ϑ). Using Lemmas 1.22 and 2.11 together with Theorem 5.4, we get
for any measurable function g: S × [0, 1] →R+
Eg(˜ξ, ˜η)
=
Eg(˜ξ, f(˜ξ, ϑ)) = E

g(ξ, f(ξ, u))du
=
E

g(ξ, t)µ(ξ, dt) = Eg(ξ, η),
which shows that (˜ξ, ˜η) d= (ξ, η).
✷

90
Foundations of Modern Probability
The following version of the last result is often useful to transfer repre-
sentations of random objects.
Corollary 5.11 (stochastic equations)
Fix two Borel spaces S and T, a
measurable mapping f : T →S, and some random elements ξ in S and η
in T with ξ
d= f(η). Then there exists a random element ˜η
d= η in T with
ξ = f(˜η) a.s.
Proof: By Theorem 5.10 there exists some random element ˜η in T with
(ξ, ˜η) d= (f(η), η). In particular, ˜η d= η and, moreover, (ξ, f(˜η)) d= (f(η), f(η)).
Since the diagonal in S2 is measurable, we get P{ξ = f(˜η)} = P{f(η) =
f(η)} = 1, and so ξ = f(˜η) a.s.
✷
The last result leads in particular to a useful extension of Theorem 3.30.
Corollary 5.12 (extended Skorohod coupling) Let f, f1, f2, . . . be measur-
able functions from a Borel space S to a Polish space T, and let ξ, ξ1, ξ2, . . .
be random elements in S with fn(ξn)
d→f(ξ). Then there exist some random
elements ˜ξ d= ξ and ˜ξn
d= ξn with fn(˜ξn) →f(˜ξ) a.s.
Proof: By Theorem 3.30 there exist some η d= f(ξ) and ηn
d= fn(ξn) with
ηn →η a.s. By Corollary 5.11 we may further choose some ˜ξ d= ξ and ˜ξn
d= ξn
such that a.s. f(˜ξ) = η and fn(˜ξn) = ηn for all n. But then fn(˜ξn) →f(˜ξ)
a.s.
✷
The next result clariﬁes the relationship between randomizations and
conditional independence. Important applications appear in Chapters 7, 10,
and 18.
Proposition 5.13 (conditional independence and randomization) Let ξ, η,
and ζ be random elements in some measurable spaces S, T, and U, respec-
tively, where S is Borel. Then ξ⊥⊥ηζ iﬀξ = f(η, ϑ) a.s. for some measurable
function f : T × [0, 1] →S and some U(0, 1) random variable ϑ⊥⊥(η, ζ).
Proof: First assume that ξ = f(η, ϑ) a.s., where f is measurable and
ϑ⊥⊥(η, ζ). Then Proposition 5.8 yields ϑ⊥⊥ηζ, and so (η, ϑ)⊥⊥ηζ by Corollary
5.7, which implies ξ⊥⊥ηζ.
Conversely, assume that ξ⊥⊥ηζ, and let ϑ⊥⊥(η, ζ) be U(0, 1). By Theorem
5.10 there exists some measurable function f : T × [0, 1] →S such that the
random element ˜ξ = f(η, ϑ) satisﬁes ˜ξ
d= ξ and (˜ξ, η)
d= (ξ, η).
By the
suﬃciency part, we further note that ˜ξ⊥⊥ηζ. Hence, by Proposition 5.6,
P[˜ξ ∈· |η, ζ] = P[˜ξ ∈· |η] = P[ξ ∈· |η] = P[ξ ∈· |η, ζ],
and so (˜ξ, η, ζ)
d= (ξ, η, ζ). By Theorem 5.10 we may choose some ˜ϑ
d= ϑ
with (ξ, η, ζ, ˜ϑ)
d= (˜ξ, η, ζ, ϑ).
In particular, ˜ϑ⊥⊥(η, ζ) and (ξ, f(η, ˜ϑ))
d=

5. Conditioning and Disintegration
91
(˜ξ, f(η, ϑ)).
Since ˜ξ = f(η, ϑ) and the diagonal in S2 is measurable, we
get ξ = f(η, ˜ϑ) a.s., and so the stated condition holds with ˜ϑ in place of ϑ. ✷
We shall now use the transfer theorem to construct random sequences or
processes with given ﬁnite-dimensional distributions. Given any measurable
spaces S1, S2, . . . , a sequence of probability measures µn on S1 × · · · × Sn,
n ∈N, is said to be projective if
µn+1(· × Sn+1) = µn,
n ∈N.
(9)
Theorem 5.14 (existence of random sequences, Daniell) Given any Borel
spaces S1, S2, . . . and a projective sequence of probability measures µn on S1×
· · · × Sn, n ∈N, there exist some random elements ξn in Sn, n ∈N, such
that (ξ1, . . . , ξn) has distribution µn for each n.
Proof: By Lemma 2.21 there exist on the Lebesgue unit interval some
i.i.d. U(0, 1) random variables ϑ1, ϑ2, . . . , and we may construct ξ1, ξ2, . . .
recursively from the ϑn. Then assume for some n ≥0 that ξ1, . . . , ξn have
already been constructed as measurable functions of ϑ1, . . . , ϑn with joint
distribution µn. Let η1, . . . , ηn+1 be arbitrary with joint distribution µn+1.
The projective property yields (ξ1, . . . , ξn)
d= (η1, . . . , ηn), so by Theorem
5.10 we may form ξn+1 as a measurable function of ξ1, . . . , ξn, ϑn+1 such that
(ξ1, . . . , ξn+1) d= (η1, . . . , ηn+1). This completes the recursion.
✷
The last theorem may be used to extend a process from bounded to
unbounded domains. We state the result in an abstract form, designed to
fulﬁll our needs in Chapters 16 and 21. Let I denote the identity mapping
on any space.
Corollary 5.15 (extension of domain) Fix any Borel spaces S, S1, S2, . . .
and some measurable mappings πn : S →Sn and πn
k : Sn →Sk, k ≤n, such
that
πn
k = πm
k ◦πn
m,
k ≤m ≤n.
(10)
Let S denote the set of sequences (s1, s2, . . .) ∈S1×S2×· · · with πn
ksn = sk for
all k ≤n, and assume that there exists some measurable mapping h: S →S
with (π1, π2, . . .) ◦h = I on S. Then for any probability measures µn on Sn
with µn ◦(πn
k)−1 = µk for all k ≤n, there exists some probability measure µ
on S with µ ◦π−1
n
= µn for all n.
Proof: Introduce the measures
¯µn = µn ◦(πn
1 , . . . , πn
n)−1,
n ∈N,
(11)
and conclude from (10) and the relation between the µn that
¯µn+1(· × Sn+1)
=
µn+1 ◦(πn+1
1
, . . . , πn+1
n
)−1
=
µn+1 ◦(πn+1
n
)−1 ◦(πn
1 , . . . , πn
n)−1
=
µn ◦(πn
1 , . . . , πn
n)−1 = ¯µn.

92
Foundations of Modern Probability
By Theorem 5.14 there exists some measure ¯µ on S1 × S2 × · · · with
¯µ ◦(¯π1, . . . , ¯πn)−1 = ¯µn,
n ∈N,
(12)
where ¯π1, ¯π2, . . . denote the coordinate projections in S1 × S2 × · · · . From
(10) through (12) it is clear that ¯µ is restricted to S, which allows us to deﬁne
µ = ¯µ ◦h−1. It remains to note that
µ ◦π−1
n
= ¯µ ◦(πnh)−1 = ¯µ ◦¯π−1
n
= ¯µn ◦¯π−1
n
= µn ◦(πn
n)−1 = µn.
✷
We shall often need an extension of Theorem 5.14 to processes on arbi-
trary index sets T. For any collection of spaces St, t ∈T, deﬁne SI = Xt∈ISt,
I ⊂T. Similarly, if each St is endowed with a σ-ﬁeld St, let SI denote the
product σ-ﬁeld 
t∈I St. Finally, if each ξt is a random element in St, write
ξI for the restriction of the process (ξt) to the index set I.
Now let ˆT and T denote the classes of ﬁnite and countable subsets of T,
respectively. A family of probability measures µI, I ∈ˆT or T, is said to be
projective if
µJ(· × SJ\I) = µI,
I ⊂J in ˆT or T.
(13)
Theorem 5.16 (existence of processes, Kolmogorov) For any collection of
Borel spaces St, t ∈T, consider a projective family of probability measures
µI on SI, I ∈ˆT. Then there exist some random elements ξt in St, t ∈T,
such that ξI has distribution µI for every I ∈ˆT.
Proof: Recall that the product σ-ﬁeld ST in ST is generated by all coor-
dinate projections πt, t ∈T, and hence consists of all countable cylinder sets
B × ST\U, B ∈SU, U ∈T. For each U ∈T, there exists by Theorem 5.14
some probability measure µU on SU satisfying
µU(· × SU\I) = µI,
I ∈ˆU,
and by Proposition 2.2 the family µU, U ∈T, is again projective. We may
then deﬁne a function µ: ST →[0, 1] by
µ(· × ST\U) = µU,
U ∈T.
To check the countable additivity of µ, consider any disjoint sets A1, A2, . . . ∈
ST. For each n we have An = Bn × ST\Un for some Un ∈T and Bn ∈SUn.
Writing U = 
n Un and Cn = Bn × SU\Un, we get
µ

nAn = µU

nCn =

nµUCn =

nµAn.
The process ξ = (ξt) may now be deﬁned as identity mapping on the proba-
bility space (ST, ST, µ).
✷
If the projective sequence in Theorem 5.14 is deﬁned recursively in terms
of a sequence of conditional distributions, then no regularity condition is
needed on the state spaces. For a precise statement, deﬁne the product µ⊗ν
of two kernels µ and ν as in Chapter 1.

5. Conditioning and Disintegration
93
Theorem 5.17 (extension by conditioning, Ionescu Tulcea) For any mea-
surable spaces (Sn, Sn) and probability kernels µn from S1 × · · · × Sn−1 to
Sn, n ∈N, there exist some random elements ξn in Sn, n ∈N, such that
(ξ1, . . . , ξn) has distribution µ1 ⊗· · · ⊗µn for each n.
Proof: Put Fn = S1 ⊗· · ·⊗Sn and Tn = Sn+1 ×Sn+2 ×· · · , and note that
the class C = 
n(Fn ×Tn) is a ﬁeld in T0 generating the σ-ﬁeld F∞. We may
deﬁne an additive function µ on C by
µ(A × Tn) = (µ1 ⊗· · · ⊗µn)A,
A ∈Fn, n ∈N,
(14)
which is clearly independent of the representation C = A × Tn. We need
to extend µ to a probability measure on F∞. By Carath´eodory’s extension
Theorem A1.1, it is then enough to show that µ is continuous at ∅.
For any sequence C1, C2, . . . ∈C with Cn ↓∅, we need to show that
µCn →0. Renumbering if necessary, we may assume for each n that Cn =
An × Tn with An ∈Fn. Now deﬁne
f n
k = (µk+1 ⊗· · · ⊗µn)1An,
k ≤n,
(15)
with the understanding that f n
n = 1An for k = n. By Lemma 1.38 (i) and
(iii), each f n
k is an Fk-measurable function on S1 × · · · × Sk, and from (15)
we note that
f n
k = µk+1f n
k+1,
0 ≤k < n.
(16)
Since Cn ↓∅, the functions f n
k are nonincreasing in n for ﬁxed k, say with
limits gk. By (16) and dominated convergence,
gk = µk+1gk+1,
k ≥0.
(17)
Combining (14) and (15), we get µCn = f n
0 ↓g0. If g0 > 0, then by (17)
there exists some s1 ∈S1 with g1(s1) > 0. Continuing recursively, we may
construct a sequence ¯s = (s1, s2, . . .) ∈T0 such that gn(s1, . . . , sn) > 0 for
each n. Then
1Cn(¯s) = 1An(s1, . . . , sn) = f n
n(s1, . . . , sn) ≥gn(s1, . . . , sn) > 0,
and so ¯s ∈

n Cn, which contradicts the hypothesis Cn ↓∅. Thus, g0 = 0,
which means that µCn →0.
✷
As a simple application, we may deduce the existence of independent ran-
dom elements with arbitrary distributions. The result extends the elementary
Theorem 2.19.
Corollary 5.18 (inﬁnite product measures, FLomnicki and Ulam) For any
collection of probability spaces (St, St, µt), t ∈T, there exist some independent
random elements ξt in St with distributions µt, t ∈T.

94
Foundations of Modern Probability
Proof: For any countable subset I ⊂T, the associated product measure
µI =

t∈I µt exists by Theorem 5.17. Now proceed as in the proof of Theo-
rem 5.16.
✷
Exercises
1. Show that (ξ, η)
d= (ξ′, η) iﬀP[ξ ∈B|η] = P[ξ′ ∈B|η] a.s. for any
measurable set B.
2. Show that EFξ = EGξ a.s. for all ξ ∈L1 iﬀF = G.
3. Show that the averaging property implies the other properties of con-
ditional expectations listed in Theorem 5.1.
4. Let 0 ≤ξn ↑ξ and 0 ≤η ≤ξ, where ξ1, ξ2, . . . , η ∈L1, and ﬁx a σ-ﬁeld
F. Show that EFη ≤supn EFξn. (Hint: Apply the monotone convergence
property to EF(ξn ∧η).)
5. For any [0, ∞]-valued random variable ξ, deﬁne EFξ = supn EF(ξ∧n).
Show that this extension of EF satisﬁes the monotone convergence property.
(Hint: Use the preceding result.)
6. Show that the above extension of EF remains characterized by the
averaging property and that EFξ < ∞a.s. iﬀthe measure ξ · P = E[ξ; ·] is
σ-ﬁnite on F. Extend EFξ to any random variable ξ such that the measure
|ξ| · P is σ-ﬁnite on F.
7. Let ξ1, ξ2, . . . be [0, ∞]-valued random variables, and ﬁx any σ-ﬁeld F.
Show that lim infn EFξn ≥EF lim infn ξn a.s.
8. Fix any σ-ﬁeld F, and let ξ, ξ1, ξ2, . . . be random variables with ξn →ξ
and EF supn |ξn| < ∞a.s. Show that EFξn →EFξ a.s.
9. Let F be the σ-ﬁeld generated by some partition A1, A2, . . . ∈A of Ω.
Show for any ξ ∈L1 that E[ξ|F] = E[ξ|Ak] = E[ξ; Ak]/PAk on Ak whenever
PAk > 0.
10. For any σ-ﬁeld F, event A, and random variable ξ ∈L1, show that
E[ξ|F, 1A] = E[ξ; A|F]/P[A|F] a.s. on A.
11. Let the random variables ξ1, ξ2, . . . ≥0 and σ-ﬁelds F1, F2, . . . be
such that E[ξn|Fn]
P→0. Show that ξn
P→0. (Hint: Consider the random
variables ξn ∧1.)
12. Let (ξ, η) d= (˜ξ, ˜η), where ξ ∈L1. Show that E[ξ|η] d= E[˜ξ|˜η]. (Hint:
If E[ξ|η] = f(η), then E[˜ξ|˜η] = f(˜η) a.s.)
13. Let (ξ, η) be a random vector in R2 with probability density f, put
F(y) =
 f(x, y)dx, and let g(x, y) = f(x, y)/F(y). Show that P[ξ ∈B|η] =

B g(x, η)dx a.s.
14. Use conditional distributions to deduce the monotone and dominated
convergence theorems for conditional expectations from the corresponding
unconditional results.

5. Conditioning and Disintegration
95
15.
Assume that EFξ
d= ξ for some ξ ∈L1.
Show that ξ is a.s. F-
measurable. (Hint: Choose a strictly convex function f with Ef(ξ) < ∞,
and apply the strict Jensen inequality to the conditional distributions.)
16. Assume that (ξ, η)
d= (ξ, ζ), where η is ζ-measurable. Show that
ξ⊥⊥ηζ. (Hint: Show as above that P[ξ ∈B|η] d= P[ξ ∈B|ζ], and deduce the
corresponding a.s. equality.)
17. Let ξ be a random element in some separable metric space S. Show
that P[ξ ∈·|F] is a.s. degenerate iﬀξ is a.s. F-measurable. (Hint: Reduce
to the case when P[ξ ∈·|F] is degenerate everywhere and hence equal to δη
for some F-measurable random element η in S. Then show that ξ = η a.s.)
18. Assuming ξ⊥⊥ηζ and γ⊥⊥(ξ, η, ζ), show that ξ⊥⊥η,γζ and ξ⊥⊥η(ζ, γ).
19. Extend Lemma 2.6 to the context of conditional independence. Also
show that Corollary 2.7 and Lemma 2.8 remain valid for the conditional
independence, given some σ-ﬁeld H.
20. Fix any σ-ﬁeld F and random element ξ in some Borel space, and
deﬁne η = P[ξ ∈·|F]. Show that ξ⊥⊥ηF.
21.
Let ξ and η be random elements in some Borel space S.
Prove
the existence of a measurable function f : S × [0, 1] →S and some U(0, 1)
random variable γ⊥⊥η such that ξ = f(η, γ) a.s.
(Hint: Choose f with
(f(η, ϑ), η)
d= (ξ, η) for any U(0, 1) random variable ϑ⊥⊥(ξ, η), and then let
(γ, ˜η) d= (ϑ, η) with (ξ, η) = (f(γ, ˜η), ˜η) a.s.)
22. Let ξ and η be random elements in some Borel space S. Show that
we may choose a random element ˜η in S with (ξ, η) d= (ξ, ˜η) and η⊥⊥ξ˜η.

Chapter 6
Martingales and Optional Times
Filtrations and optional times; random time-change; martingale
property; optional stopping and sampling; maximum and upcross-
ing inequalities; martingale convergence, regularity, and closure;
limits of conditional expectations; regularization of submartin-
gales
The importance of martingale methods can hardly be exaggerated. Indeed,
martingales and the associated notions of ﬁltrations and optional times are
constantly used in all areas of modern probability and appear frequently
throughout the remainder of this book.
In discrete time a martingale is simply a sequence of integrable random
variables centered at the successive conditional means, a centering that can
always be achieved by the elementary Doob decomposition. More precisely,
given any discrete ﬁltration F = (Fn), that is, an increasing sequence of
σ-ﬁelds in Ω, one says that a sequence M = (Mn) forms a martingale with
respect to F if E[Mn|Fn−1] = Mn−1 a.s. for all n. A special role is played
by the class of uniformly integrable martingales, which can be represented in
the form Mn = E[ξ|Fn] for some integrable random variables ξ.
Martingale theory owes its usefulness to a number of powerful general
results, such as the optional sampling theorem, the submartingale conver-
gence theorem, and a variety of maximum inequalities.
The applications
discussed in this chapter include extensions of the Borel–Cantelli lemma and
Kolmogorov’s zero–one law. Martingales are also used to establish the ex-
istence of measurable densities and to give a short proof of the law of large
numbers.
Much of the discrete-time theory extends immediately to continuous time
thanks to the fundamental regularization theorem, which ensures that every
continuous-time martingale with respect to a right-continuous ﬁltration has a
right-continuous version with left-hand limits. The implications of this result
extend far beyond martingale theory. In particular, it enables us in Chapters
13 and 17 to obtain right-continuous versions of independent-increment and
Feller processes.
The theory of continuous-time martingales is continued in Chapters 15,
16, 22, and 23 with studies of quadratic variation, random time-change, inte-
gral representations, removal of drift, additional maximum inequalities, and
various decomposition theorems. Martingales further play a basic role for es-
pecially the Skorohod embedding in Chapter 12, the stochastic integration in
96

6. Martingales and Optional Times
97
Chapters 15 and 23, and the theories of Feller processes, SDEs, and diﬀusions
in Chapters 17, 18, and 20.
As for the closely related notion of optional times, our present treatment
is continued with a more detailed study in Chapter 22. Optional times are
fundamental not only for martingale theory but also for a variety of models
involving Markov processes. In the latter context they appear frequently in
the sequel, especially in Chapters 7, 8, 10, 11, 12, 17, and 19 through 22.
To begin our systematic exposition of the theory, we may ﬁx an arbitrary
index set T ⊂R. A ﬁltration on T is deﬁned as a nondecreasing family
of σ-ﬁelds Ft ⊂A, t ∈T. One says that a process X on T is adapted to
F = (Ft) if Xt is Ft-measurable for every t ∈T. The smallest ﬁltration with
this property is the induced or generated ﬁltration Ft = σ{Xs; s ≤t}, t ∈T.
Here “smallest” should be understood in the sense of set inclusion for every
ﬁxed t.
By a random time we shall mean a random element in T = T ∪{sup T}.
Such a time is said to be F-optional or an F-stopping time if {τ ≤t} ∈Ft
for every t ∈T, that is, if the process Xt = 1{τ ≤t} is adapted. (Here
and in similar cases, the preﬁx F is often omitted when there is no risk for
confusion.) If T is countable, it is clearly equivalent that {τ = t} ∈Ft for
every t ∈T. For any optional times σ and τ we note that even σ ∨τ and
σ ∧τ are optional.
With any optional time τ we may associate the σ-ﬁeld
Fτ = {A ∈A; A ∩{τ ≤t} ∈Ft, t ∈T}.
Some basic properties of optional times and the associated σ-ﬁelds are listed
below.
Lemma 6.1 (optional times) For any optional times σ and τ, we have
(i) τ is Fτ-measurable;
(ii) Fτ = Ft on {τ = t} for all t ∈T;
(iii) Fσ ∩{σ ≤τ} ⊂Fσ∧τ = Fσ ∩Fτ.
In particular, it is seen from (iii) that {σ ≤τ} ∈Fσ ∩Fτ, that Fσ = Fτ
on {σ = τ}, and that Fσ ⊂Fτ whenever σ ≤τ.
Proof: (iii) For any A ∈Fσ and t ∈T we have
A ∩{σ ≤τ} ∩{τ ≤t} = (A ∩{σ ≤t}) ∩{τ ≤t} ∩{σ ∧t ≤τ ∧t},
which belongs to Ft since σ ∧t and τ ∧t are both Ft-measurable. Hence
Fσ ∩{σ ≤τ} ⊂Fτ.
The ﬁrst relation now follows as we replace τ by σ ∧τ. Replacing σ and τ
by the pairs (σ ∧τ, σ) and (σ ∧τ, τ), it is further seen that Fσ∧τ ⊂Fσ ∩Fτ.
To prove the reverse relation, we note that for any A ∈Fσ ∩Fτ and t ∈T
A ∩{σ ∧τ ≤t} = (A ∩{σ ≤t}) ∪(A ∩{τ ≤t}) ∈Ft,

98
Foundations of Modern Probability
whence A ∈Fσ∧τ.
(i) Applying (iii) to the pair (τ, t) gives {τ ≤t} ∈Fτ for all t ∈T, which
extends immediately to any t ∈R. Now use Lemma 1.4.
(ii) First assume that τ ≡t. Then Fτ = Fτ ∩{τ ≤t} ⊂Ft. Conversely,
assume that A ∈Ft and s ∈T. If s ≥t we get A ∩{τ ≤s} = A ∈Ft ⊂Fs,
and if s < t then A ∩{τ ≤s} = ∅∈Fs. Thus, A ∈Fτ. This shows that
Fτ = Ft when τ ≡t. The general case now follows by part (iii).
✷
Given an arbitrary ﬁltration F on R+, we may deﬁne a new ﬁltration F+
by F+
t =

u>t Fu, t ≥0, and we say that F is right-continuous if F+ = F.
In particular, F+ is right-continuous for any ﬁltration F. We say that a
random time τ is weakly F-optional if {τ < t} ∈Ft for every t > 0. In
that case τ + h is clearly F-optional for every h > 0, and we may deﬁne
Fτ+ =

h>0 Fτ+h. When the index set is Z+, we write F+ = F and make
no diﬀerence between strictly and weakly optional times.
The following result shows that the notions of optional and weakly op-
tional times agree when F is right-continuous.
Lemma 6.2 (weakly optional times) A random time τ is weakly F-optional
iﬀit is F+-optional, in which case
Fτ+ = F+
τ = {A ∈A; A ∩{τ < t} ∈Ft, t > 0}.
(1)
Proof: For any t ≥0, we note that
{τ ≤t} =

r>t{τ < r},
{τ < t} =

r<t{τ ≤r},
(2)
where r may be restricted to the rationals. If A ∩{τ ≤t} ∈Ft+ for all t, we
get by (2) for any t > 0
A ∩{τ < t} =

r<t(A ∩{τ ≤r}) ∈Ft.
Conversely, if A ∩{τ < t} ∈Ft for all t, then (2) yields for any t ≥0 and
h > 0
A ∩{τ ≤t} =

r∈(t,t+h)
(A ∩{τ < r}) ∈Ft+h,
and so A ∩{τ ≤t} ∈Ft+. For A = Ωthis proves the ﬁrst assertion, and for
general A ∈A it proves the second relation in (1).
To prove the ﬁrst relation, we note that A ∈Fτ+ iﬀA ∈Fτ+h for each
h > 0, that is, iﬀA ∩{τ + h ≤t} ∈Ft for all t ≥0 and h > 0. But
this is equivalent to A ∩{τ ≤t} ∈Ft+h for all t ≥0 and h > 0, hence to
A ∩{τ ≤t} ∈Ft+ for every t ≥0, which means that A ∈F+
τ .
✷
We have already seen that the maximum and minimum of two optional
times are again optional.
The result extends to countable collections as
follows.

6. Martingales and Optional Times
99
Lemma 6.3 (closure properties) For any random times τ1, τ2, . . . and ﬁl-
tration F on R+ or Z+, we have the following:
(i) if the τn are F-optional, then so is σ = supn τn;
(ii) if the τn are weakly F-optional, then so is τ = infn τn, and moreover
F+
τ =

n F+
τn.
Proof: To prove (i) and the ﬁrst assertion in (ii), we note that
{σ ≤t} =

n{τn ≤t},
{τ < t} =

n{τn < t},
(3)
where the strict inequalities may be replaced by ≤for the index set T = Z+.
To prove the second assertion in (ii), we note that F+
τ ⊂

n F+
τn by Lemma
6.1. Conversely, assuming A ∈
n F+
τn, we get by (3) for any t ≥0
A ∩{τ < t} = A ∩

n{τn < t} =

n(A ∩{τn < t}) ∈Ft,
with the indicated modiﬁcation for T = Z+. Thus, A ∈F+
τ .
✷
Part (ii) of the last result is often useful in connection with the following
approximation of optional times from the right.
Lemma 6.4 (discrete approximation) For any weakly optional time τ in
R+, there exist some countably valued optional times τn ↓τ.
Proof: We may deﬁne
τn = 2−n[2nτ + 1],
n ∈N.
Then τn ∈2−nN for each n, and τn ↓τ. Also note that each τn is optional,
since {τn ≤k2−n} = {τ < k2−n} ∈Fk2−n.
✷
We shall now relate the optional times to random processes. Say that
a process X on R+ is progressively measurable or simply progressive if its
restriction to Ω× [0, t] is Ft ⊗B[0, t]-measurable for every t ≥0. Note that
any progressive process is adapted by Lemma 1.26.
Conversely, a simple
approximation from the left or right shows that any adapted and left- or
right-continuous process is progressive. A set A ⊂Ω× R+ is said to be
progressive if the corresponding indicator function 1A has this property, and
we note that the progressive sets form a σ-ﬁeld.
Lemma 6.5 (optional evaluation) Fix a ﬁltration F on some index set T,
let X be a process on T with values in some measurable space (S, S), and
let τ be a T-valued optional time. Then Xτ is Fτ-measurable under each of
these conditions:
(i) T is countable and X is adapted;
(ii) T = R+ and X is progressive.

100
Foundations of Modern Probability
Proof: In both cases, we need to show that
{Xτ ∈B, τ ≤t} ∈Ft,
t ≥0, B ∈S.
This is clear in case (i) if we write
{Xτ ∈B} =

s≤t{Xs ∈B, τ = s} ∈Ft,
B ∈S.
In case (ii) it is enough to show that Xτ∧t is Ft-measurable for every t ≥0.
We may then assume τ ≤t and prove instead that Xτ is Ft-measurable.
Then write Xτ = X ◦ψ where ψ(ω) = (ω, τ(ω)), and note that ψ is mea-
surable from Ft to Ft ⊗B[0, t] whereas X is measurable on Ω× [0, t] from
Ft ⊗B[0, t] to S. The required measurability of Xτ now follows by Lemma
1.7.
✷
Given a process X on R+ or Z+ and a set B in the range space of X, we
may introduce the hitting time
τB = inf{t > 0; Xt ∈B}.
It is often important to decide whether the time τB is optional. The following
elementary result covers most cases arising in applications.
Lemma 6.6 (hitting times) Fix a ﬁltration F on T = R+ or Z+, let X be
an F-adapted process on T with values in some measurable space (S, S), and
let B ∈S. Then τB is weakly optional under each of these conditions:
(i) T = Z+;
(ii) T = R+, S is a metric space, B is closed, and X is continuous;
(iii) T = R+, S is a topological space, B is open, and X is right-continuous.
Proof: In case (i) it is enough to write
{τB ≤n} =

k∈[1,n]
{Xk ∈B} ∈Fn,
n ∈N.
In case (ii) we get for t > 0
{τB ≤t} =

h>0

n∈N

r∈Q∩[h,t]
{ρ(Xr, B) ≤n−1} ∈Ft,
where ρ denotes the metric in S. Finally, in case (iii) we get
{τB < t} =

r∈Q∩(0,t)
{Xr ∈B} ∈Ft,
t > 0,
which suﬃces by Lemma 6.2.
✷
For special purposes we may need the following more general but much
deeper result, known as the debut theorem. Here and below a ﬁltration F is
said to be complete if the basic σ-ﬁeld A is complete and each Ft contains
all P-null sets in A.

6. Martingales and Optional Times
101
Theorem 6.7 (ﬁrst entry, Doob, Hunt) Let the set A ⊂R+ ×Ωbe progres-
sive with respect to some right-continuous and complete ﬁltration F. Then
the time τ(ω) = inf{t ≥0; (t, ω) ∈A} is F-optional.
Proof: Since A is progressive, we have A ∩[0, t) ∈Ft ⊗B([0, t]) for every
t > 0. Noting that {τ < t} is the projection of A ∩[0, t) onto Ω, we get
{τ < t} ∈Ft by Theorem A1.8, and so τ is optional by Lemma 6.2.
✷
In applications of the last result and for other purposes, we may need
to extend a given ﬁltration F on R+ to make it both right-continuous and
complete. Then let A be the completion of A, put N = {A ∈A; PA = 0},
and deﬁne Ft = σ{Ft, N}. Then F = (Ft) is the smallest complete extension
of F. Similarly, F+ = (Ft+) is the smallest right-continuous extension of
F. The following result shows that the two extensions commute and can be
combined into a smallest right-continuous and complete extension, commonly
referred to as the (usual) augmentation of F.
Lemma 6.8 (augmented ﬁltration) Any ﬁltration F on R+ has a smallest
right-continuous and complete extension G, given by
Gt = Ft+ = Ft+,
t ≥0.
(4)
Proof: First we note that
Ft+ ⊂Ft+ ⊂Ft+,
t ≥0.
Conversely, assume that A ∈Ft+. Then A ∈Ft+h for every h > 0, and
so, as in Lemma 1.25, there exist some sets Ah ∈Ft+h with P(A∆Ah) = 0.
Now choose hn →0, and deﬁne A′ = {Ahn i.o.}.
Then A′ = Ft+ and
P(A∆A′) = 0, so A ∈Ft+. Thus, Ft+ ⊂Ft+, which proves the second
relation in (4).
In particular, the ﬁltration G in (4) contains F and is both right-contin-
uous and complete. For any ﬁltration H with those properties, we have
Gt = Ft+ ⊂Ht+ = Ht+ = Ht,
t ≥0,
which proves the required minimality of G.
✷
The next result shows how the σ-ﬁelds Fτ arise naturally in the context
of a random time-change.
Proposition 6.9 (random time-change)
Let X ≥0 be a nondecreasing,
right-continuous process adapted to some right-continuous ﬁltration F. Then
τs = inf{t > 0; Xt > s},
s ≥0,
is a right-continuous process of optional times, generating a right-continuous
ﬁltration Gs = Fτs, s ≥0. If X is continuous and the time τ is F-optional,
then Xτ is G-optional and Fτ ⊂GXτ. If X is further strictly increasing, then
Fτ = GXτ.

102
Foundations of Modern Probability
In the latter case, we have in particular Ft = GXt for all t, so the processes
(τs) and (Xt) play symmetric roles.
Proof: The times τs are optional by Lemmas 6.2 and 6.6, and since (τs)
is right-continuous, so is (Gs) by Lemma 6.3. If X is continuous, then by
Lemma 6.1 we get for any F-optional time τ > 0 and set A ∈Fτ
A ∩{Xτ ≤s} = A ∩{τ ≤τs} ∈Fτs = Gs,
s ≥0.
For A = Ωit follows that Xτ is G-optional, and for general A we get A ∈GXτ.
Thus, Fτ ⊂GXτ. Both statements extend by Lemma 6.3 to arbitrary τ.
Now assume that X is also strictly increasing. For any A ∈GXt with
t > 0 we have
A ∩{t ≤τs} = A ∩{Xt ≤s} ∈Gs = Fτs,
s ≥0,
so
A ∩{t ≤τs ≤u} ∈Fu,
s ≥0, u > t.
Taking the union over all s ∈Q+—the set of nonnegative rationals—gives
A ∈Fu, and as u ↓t we get A ∈Ft+ = Ft. Hence, Ft = GXt, which extends
as before to t = 0. By Lemma 6.1 we now obtain for any A ∈GXτ
A ∩{τ ≤t} = A ∩{Xτ ≤Xt} ∈GXt = Ft,
t ≥0,
and so A ∈Fτ. Thus, GXτ ⊂Fτ, so the two σ-ﬁelds agree.
✷
To motivate the introduction of martingales, we may ﬁx a random variable
ξ ∈L1 and a ﬁltration F on some index set T, and put
Mt = E[ξ|Ft],
t ∈T.
The process M is clearly integrable (for each t) and adapted, and by the
chain rule for conditional expectations we note that
Ms = E[Mt|Fs] a.s.,
s ≤t.
(5)
Any integrable and adapted process M satisfying (5) is called a martingale
with respect to F, or an F-martingale. When T = Z+, it suﬃces to require
(5) for t = s + 1, so in that case the condition becomes
E[∆Mn|Fn−1] = 0 a.s.,
n ∈N,
(6)
where ∆Mn = Mn −Mn−1. A process M = (M 1, . . . , M d) in Rd is said to be
a martingale if M 1, . . . , M d are one-dimensional martingales.
Replacing the equality in (5) or (6) by an inequality, we arrive at the
notions of sub- and supermartingales. Thus, a submartingale is deﬁned as an
integrable and adapted process X with
Xs ≤E[Xt|Fs] a.s.,
s ≤t;
(7)

6. Martingales and Optional Times
103
reversing the inequality sign yields the notion of a supermartingale. In par-
ticular, the mean is nondecreasing for submartingales and nonincreasing for
supermartingales. (The sign convention is suggested by analogy with sub-
and superharmonic functions.)
Given a ﬁltration F on Z+, we say that a random sequence A = (An)
with A0 = 0 is predictable with respect to F, or F-predictable, if An is Fn−1-
measurable for every n ∈N, that is, if the shifted sequence θA = (An+1) is
adapted. The following elementary result, often called the Doob decomposi-
tion, is useful to deduce results for submartingales from the corresponding
martingale versions. An extension to continuous time is proved in Chap-
ter 22.
Lemma 6.10 (centering) Given a ﬁltration F on Z+, any integrable and
adapted process X on Z+ has an a.s. unique decomposition M + A, where M
is a martingale and A is a predictable process with A0 = 0. In particular, X
is a submartingale iﬀA is a.s. nondecreasing.
Proof: If X = M + A for some processes M and A as stated, then clearly
∆An = E[∆Xn|Fn−1] a.s. for all n ∈N, and so
An =

k≤nE[∆Xk|Fk−1] a.s.,
n ∈Z+,
(8)
which proves the required uniqueness. In general, we may deﬁne a predictable
process A by (8). Then M = X −A is a martingale, since
E[∆Mn|Fn−1] = E[∆Xn|Fn−1] −∆An = 0 a.s.,
n ∈N.
✷
We proceed to show how the martingale and submartingale properties
are preserved under various transformations.
Lemma 6.11 (convex maps) Let M be a martingale in Rd, and consider
a convex function f : Rd →R such that X = f(M) is integrable. Then X
is a submartingale. The statement remains true for real submartingales M,
provided that f is also nondecreasing.
Proof: In the martingale case, the conditional version of Jensen’s inequal-
ity yields
f(Ms) = f(E[Mt|Fs]) ≤E[f(Mt)|Fs] a.s.,
s ≤t,
(9)
which shows that f(M) is a submartingale. If instead M is a submartin-
gale and f is nondecreasing, the ﬁrst relation in (9) becomes f(Ms) ≤
f(E[Mt|Fs]), and the conclusion remains valid.
✷
The last result is often applied with f(x) = |x|p for some p ≥1 or, for
d = 1, with f(x) = x+ = x ∨0.

104
Foundations of Modern Probability
Say that an optional time τ is bounded if τ ≤u a.s. for some u ∈T.
This is always true when T has a last element. The following result is an
elementary version of the basic optional sampling theorem. An extension to
continuous-time submartingales appears as Theorem 6.29.
Theorem 6.12 (optional sampling, Doob) Let M be a martingale on some
countable index set T with ﬁltration F, and consider two optional times σ
and τ, where τ is bounded. Then Mτ is integrable, and
Mσ∧τ = E[Mτ|Fσ] a.s.
Proof: By Lemmas 5.2 and 6.1 we get for any t ≤u in T
E[Mu|Fτ] = E[Mu|Ft] = Mt = Mτ a.s. on {τ = t},
and so E[Mu|Fτ] = Mτ a.s. whenever τ ≤u a.s. If σ ≤τ ≤u, then Fσ ⊂Fτ
by Lemma 6.1, and we get
E[Mτ|Fσ] = E[E[Mu|Fτ]|Fσ] = E[Mu|Fσ] = Mσ a.s.
On the other hand, clearly E[Mτ|Fσ] = Mτ a.s. when τ ≤σ ∧u. In the
general case, the previous results combine by means of Lemmas 5.2 and 6.1
into
E[Mτ|Fσ] = E[Mτ|Fσ∧τ] = Mσ∧τ
a.s. on {σ ≤τ},
E[Mτ|Fσ] = E[Mσ∧τ|Fσ] = Mσ∧τ
a.s. on {σ > τ}.
✷
In particular, we note that if M is a martingale on an arbitrary time scale
T with ﬁltration F and (τs) is a nondecreasing family of bounded, optional
times that take countably many values, then the process (Mτs) is a martingale
with respect to the ﬁltration (Fτs). In this sense, the martingale property is
preserved by a random time-change.
From the last theorem we note that every martingale M satisﬁes EMσ =
EMτ, for any bounded optional times σ and τ that take only countably many
values. An even weaker property characterizes the class of martingales.
Lemma 6.13 (martingale criterion) Let M be an integrable, adapted pro-
cess on some index set T. Then M is a martingale iﬀEMσ = EMτ for any
T-valued optional times σ and τ that take at most two values.
Proof: If s < t in T and A ∈Fs, then τ = s1A + t1Ac is optional, and so
0 = EMt −EMτ = EMt −E[Ms; A] −E[Mt; Ac] = E[Mt −Ms; A].
Since A is arbitrary, it follows that E[Mt −Ms|Fs] = 0 a.s.
✷
The following predictable transformations of martingales are basic for
stochastic integration theory.

6. Martingales and Optional Times
105
Corollary 6.14 (martingale transforms) Let M be a martingale on some
index set T with ﬁltration F, ﬁx an optional time τ that takes countably
many values, and let η be a bounded, Fτ-measurable random variable. Then
the process Nt = η(Mt −Mt∧τ) is again a martingale.
Proof: The integrability follows from Theorem 6.12, and the adaptedness
is clear if we replace η by η1{τ ≤t} in the expression for Nt. Now ﬁx any
bounded, optional time σ taking countably many values. By Theorem 6.12
and the pull-out property of conditional expectations, we get a.s.
E[Nσ|Fτ] = ηE[Mσ −Mσ∧τ|Fτ] = η(Mσ∧τ −Mσ∧τ) = 0,
and so ENσ = 0. Thus, N is a martingale by Lemma 6.13.
✷
In particular, we note that optional stopping preserves the martingale
property, in the sense that the stopped process M τ
t = Mτ∧t is a martingale
whenever M is a martingale and τ is an optional time that takes countably
many values.
More generally, we may consider predictable step processes of the form
Vt =

k≤nηk1{t > τk},
t ∈T,
where τ1 ≤· · · ≤τn are optional times, and each ηk is a bounded, Fτk-
measurable random variable.
For any process X, we may introduce the
associated elementary stochastic integral
(V · X)t ≡

 t
0 VsdXs =

k≤nηk(Xt −Xt∧τk),
t ∈T.
From Corollary 6.14 we note that V · X is a martingale whenever X is a
martingale and each τk takes countably many values. In discrete time we
may clearly allow V to be any bounded, predictable sequence, in which case
(V · X)n =

k≤nVk∆Xk,
n ∈Z+.
The result for martingales extends in an obvious way to submartingales X
and nonnegative, predictable sequences V .
Our next aim is to derive some basic martingale inequalities. We begin
with an extension of Kolmogorov’s maximum inequality in Lemma 3.15.
Proposition 6.15 (maximum inequalities, Bernstein, L´evy)
Let X be a
submartingale on some countable index set T.
Then for any r ≥0 and
u ∈T,
rP{supt≤uXt ≥r}
≤
E[Xu; supt≤uXt ≥r] ≤EX+
u ,
(10)
rP{supt|Xt| ≥r}
≤
3 suptE|Xt|.
(11)

106
Foundations of Modern Probability
Proof: By dominated convergence it is enough to consider ﬁnite index
sets, so we may assume that T = Z+. Deﬁne τ = u ∧inf{t; Xt ≥r} and
B = {maxt≤u Xt ≥r}. Then τ is an optional time bounded by u, and we
note that B ∈Fτ and Xτ ≥r on B. Hence, by Lemma 6.10 and Theorem
6.12,
rPB ≤E[Xτ; B] ≤E[Xu; B] ≤EX+
u ,
which proves (10). Letting M + A be the Doob decomposition of X and
applying (10) to −M, we further get
rP{mint≤uXt ≤−r}
≤
rP{mint≤uMt ≤−r} ≤EM −
u
=
EM +
u −EMu ≤EX+
u −EX0
≤
2 maxt≤uE|Xt|.
Combining this with (10) yields (11).
✷
We proceed to derive a basic norm inequality. For processes X on some
index set T, we deﬁne
X∗
t = sups≤t|Xs|,
X∗= supt∈T|Xt|.
Proposition 6.16 (norm inequality, Doob) Let M be a martingale on some
countable index set T, and ﬁx any p, q > 1 with p−1 + q−1 = 1. Then
∥M ∗
t ∥p ≤q∥Mt∥p,
t ∈T.
Proof:
By monotone convergence we may assume that T = Z+.
If
∥Mt∥p < ∞, then ∥Ms∥p < ∞for all s ≤t by Jensen’s inequality, and
so we may assume that 0 < ∥M ∗
t ∥p < ∞. Applying Proposition 6.15 to the
submartingale |M|, we get
rP{M ∗
t > r} ≤E[|Mt|; M ∗
t > r],
r > 0.
Hence, by Lemma 2.4, Fubini’s theorem, and H¨older’s inequality,
∥M ∗
t ∥p
p
=
p

 ∞
0
P{M ∗
t > r}rp−1dr
≤
p

 ∞
0
E[|Mt|; M ∗
t > r] rp−2dr
=
p E |Mt|

 M∗
t
0
rp−2dr = q E |Mt| M ∗(p−1)
t
≤
q ∥Mt∥p
M ∗(p−1)
t

q = q ∥Mt∥p ∥M ∗
t ∥p−1
p
.
It remains to divide by the last factor on the right.
✷
The next inequality is needed to prove the basic Theorem 6.18. For any
function f on T and constants a < b, the number of [a, b]-crossings of f up to
time t is deﬁned as the supremum of all n ∈Z+ such that there exist times
s1 < t1 < s2 < t2 < · · · < sn < tn ≤t in T with f(sk) ≤a and f(tk) ≥b for
all k. The supremum may clearly be inﬁnite.

6. Martingales and Optional Times
107
Lemma 6.17 (upcrossing inequality, Doob, Snell) Let X be a submartingale
on a countable index set T, and let N b
a(t) denote the number of [a, b]-crossings
of X up to time t. Then
EN b
a(t) ≤E(Xt −a)+
b −a
,
t ∈T, a < b in R.
Proof: As before, we may assume that T = Z+. Since Y = (X −a)+ is
again a submartingale by Lemma 6.11 and the [a, b]-crossings of X correspond
to [0, b−a]-crossings of Y , we may assume that X ≥0 and a = 0. Now deﬁne
recursively the optional times 0 = τ0 ≤σ1 < τ1 < σ2 < · · · by
σk = inf{n ≥τk−1; Xn = 0},
τk = inf{n ≥σk; Xn ≥b},
k ∈N,
and introduce the predictable process
Vn =

k≥11{σk < n ≤τk},
n ∈N.
Then (1 −V ) · X is again a submartingale by Corollary 6.14, and so E((1 −
V ) · X)t ≥E((1 −V ) · X)0 = 0. Also note that (V · X)t ≥bN b
0(t). Hence,
bEN b
0(t) ≤E(V · X)t ≤E(1 · X)t = EXt −EX0 ≤EXt.
✷
We may now state the fundamental regularity and convergence theorem
for submartingales.
Theorem 6.18 (regularity and convergence, Doob) Let X be an L1-bounded
submartingale on some countable index set T. Then Xt converges along every
increasing or decreasing sequence in T, outside some ﬁxed P-null set A.
Proof: By Proposition 6.15 we have X∗< ∞a.s., and Lemma 6.17 shows
that X has a.s. ﬁnitely many upcrossings of every interval [a, b] with rational
a < b. Outside the null set A where any of these conditions fails, it is clear
that X has the stated property.
✷
The following is an interesting and useful application.
Proposition 6.19 (one-sided bounds) Let M be a martingale on Z+ with
∆M ≤c a.s. for some constant c < ∞. Then a.s.
{Mn converges} = {supnMn < ∞}.
Proof: Since M −M0 is again a martingale, we may assume that M0 = 0.
Introduce the optional times
τm = inf{n; Mn ≥m},
m ∈N.

108
Foundations of Modern Probability
The processes M τm are again martingales by Corollary 6.14. Since M τm ≤
m + c a.s., we have E|M τm| ≤2(m + c) < ∞, and so M τm converges a.s. by
Theorem 6.18. Hence, M converges a.s. on
{supnMn < ∞} =

m{M ≡M τm}.
The reverse implication is obvious, since every convergent sequence in R is
bounded.
✷
From the last result we may easily derive the following useful extension
of the Borel–Cantelli lemma in Theorem 2.18.
Corollary 6.20 (extended Borel–Cantelli lemma, L´evy) Fix any ﬁltration
F on Z+, and let An ∈Fn, n ∈N. Then a.s.
{An i.o.} =

nP[An|Fn−1] = ∞

.
Proof: The sequence
Mn =

k≤n (1Ak −P[Ak|Fk−1]) ,
n ∈Z+,
is a martingale with |∆Mn| ≤1, and so by Proposition 6.19
P{Mn →∞} = P{Mn →−∞} = 0.
Hence, a.s.
{An i.o.} =

n1An = ∞

=

nP[An|Fn−1] = ∞

.
✷
A martingale M or submartingale X is said to be closed if u = sup T
belongs to T. In the former case, clearly Mt = E[Mu|Ft] a.s. for all t ∈T. If
instead u ̸∈T, we say that M is closable if it can be extended to a martingale
on T = T ∪{u}. If Mt = E[ξ|Ft] for some ξ ∈L1, we may clearly choose
Mu = ξ. The next result gives general criteria for closability. An extension
to continuous-time submartingales appears as part of Theorem 6.29.
Theorem 6.21 (uniform integrability and closure, Doob) For martingales
M on an unbounded index set T, these conditions are equivalent:
(i) M is uniformly integrable;
(ii) M is closable at sup T;
(iii) M is L1-convergent at sup T.
Under those conditions, M is closable by the limit in (iii).
Proof: First note that (ii) implies (i) by Lemma 5.5. Next (i) implies (iii)
by Theorem 6.18 and Proposition 3.12. Finally, assume that Mt →ξ in L1

6. Martingales and Optional Times
109
as t →u ≡sup T. Using the L1-contractivity of conditional expectations,
we get, as t →u for ﬁxed s
Ms = E[Mt|Fs] →E[ξ|Fs] in L1.
Thus, Ms = E[ξ|Fs] a.s., and we may take Mu = ξ. This shows that (iii)
implies (ii).
✷
For comparison, we may examine the case of Lp-convergence for p > 1.
Corollary 6.22 (Lp-convergence) Let M be a martingale on some unboun-
ded index set T, and ﬁx any p > 1. Then M converges in Lp iﬀit is Lp-
bounded.
Proof: We may clearly assume that T is countable. If M is Lp-bounded, it
converges in L1 by Theorem 6.18. Since |M|p is also uniformly integrable by
Proposition 6.16, the convergence extends to Lp by Proposition 3.12. Con-
versely, if M converges in Lp, it is Lp-bounded by Lemma 6.11.
✷
We shall now consider the convergence of martingales of the special form
Mt = E[ξ|Ft] as t increases or decreases along some sequence. Without loss
of generality, we may assume that the index set T is unbounded above or
below, and deﬁne respectively
F∞=

t∈T Ft,
F−∞=

t∈T Ft.
Theorem 6.23 (limits in conditioning, Jessen, L´evy) Fix a ﬁltration F on
some countable index set T ⊂R that is unbounded above or below. Then for
any ξ ∈L1,
E[ξ|Ft] →E[ξ|F±∞] as t →±∞, a.s. and in L1.
Proof: By Theorems 6.18 and 6.21, the martingale Mt = E[ξ|Ft] con-
verges a.s. and in L1 as t →±∞, and the limit M±∞may clearly be taken
to be F±∞-measurable. To see that M±∞= E[ξ|F±∞] a.s., we need to verify
the relations
E[M±∞; A] = E[ξ; A],
A ∈F±∞.
(12)
Then note that, by the deﬁnition of M,
E[Mt; A] = E[ξ; A],
A ∈Fs, s ≤t.
(13)
This clearly remains true for s = −∞, and as t →−∞we get the “minus”
version of (12). To get the “plus” version, let t →∞in (13) for ﬁxed s, and
extend by a monotone class argument to arbitrary A ∈F∞.
✷
In particular, we note the following useful special case.

110
Foundations of Modern Probability
Corollary 6.24 (L´evy) For any ﬁltration F on Z+, we have
P[A|Fn] →1A a.s.,
A ∈F∞.
For a simple application, we shall consider an extension of Kolmogorov’s
zero–one law in Theorem 2.13. Say that two σ-ﬁelds agree a.s. if they have
the same completion with respect to the basic σ-ﬁeld.
Corollary 6.25 (tail σ-ﬁeld) If F1, F2, . . . and G are independent σ-ﬁelds,
then

nσ{Fn, Fn+1, . . . ; G} = G a.s.
Proof: Let T denote the σ-ﬁeld on the left, and note that T ⊥⊥G(F1∨· · ·∨
Fn) by Proposition 5.8. Using Proposition 5.6 and Corollary 6.24, we get for
any A ∈T
P[A|G] = P[A|G, F1, . . . , Fn] →1A a.s.,
which shows that T ⊂G a.s. The converse relation is obvious.
✷
The last theorem can be used to give a short proof of the law of large
numbers.
Then let ξ1, ξ2, . . . be i.i.d. random variables in L1, put Sn =
ξ1 + . . . + ξn, and deﬁne F−n = σ{Sn, Sn+1, . . .}. Here F−∞is trivial by
Theorem 2.15, and for any k ≤n we have E[ξk|F−n] = E[ξ1|F−n] a.s., since
(ξk, Sn, Sn+1, . . .) d= (ξ1, Sn, Sn+1, . . .). Hence, by Theorem 6.23,
n−1Sn
=
E[n−1Sn|F−n] = n−1
k≤nE[ξk|F−n]
=
E[ξ1|F−n] →E[ξ1|F−∞] = Eξ1.
As a further application of Theorem 6.23, we shall prove a kernel version
of the regularization Theorem 5.3. The result is needed in Chapter 18.
Proposition 6.26 (kernel densities) Fix a measurable space (S, S) and two
Borel spaces (T, T ) and (U, U), and let µ be a probability kernel from S to
T × U. Then the densities
ν(s, t, B) = µ(s, dt × B)
µ(s, dt × U),
s ∈S, t ∈T, B ∈U,
(14)
have versions that form a probability kernel from S × T to U.
Proof: We may assume T and U to be Borel subsets of R, in which case
µ can be regarded as a probability kernel from S to R2. Letting Dn denote
the σ-ﬁeld in R generated by the intervals Ink = [(k −1)2−n, k2−n), k ∈Z,
we deﬁne
Mn(s, t, B) =

k
µ(s, Ink × B)
µ(s, Ink × U)1{t ∈Ink},
s ∈S, t ∈T, B ∈B,

6. Martingales and Optional Times
111
under the convention 0/0 = 0. Then Mn(s, ·, B) is a version of the density
in (14) with respect to Dn, and for ﬁxed s and B it is also a martingale with
respect to µ(s, · × U). By Theorem 6.23 we get Mn(s, ·, B) →ν(s, ·, B) a.e.
µ(s, · × U). Thus, a product-measurable version of ν is given by
ν(s, t, B) = lim sup
n→∞Mn(s, t, B),
s ∈S, t ∈T, B ∈U.
It remains to ﬁnd a version of ν that is a probability measure on U for
each s and t. Then proceed as in the proof of Theorem 5.3, noting that
in each step the exceptional (s, t)-set A lies in S ⊗T and is such that the
sections As = {t ∈T; (s, t) ∈A} satisfy µ(s, As × U) = 0 for all s ∈S.
✷
In order to extend the previous theory to martingales on R+, we need
to choose suitably regular versions of the studied processes. The next result
provides two closely related regularizations of a given submartingale. Say
that a process X on R+ is right-continuous with left-hand limits (abbreviated
as rcll) if Xt = Xt+ for all t ≥0 and the left-hand limits Xt−exist and are
ﬁnite for all t > 0. For any process Y on Q+, we write Y + for the process of
right-hand limits Yt+, t ≥0, provided that the latter exist.
Theorem 6.27 (regularization, Doob) For any F-submartingale X on R+
with restriction Y to Q+, we have the following:
(i) Y + exists and is rcll outside some ﬁxed P-null set A, and Z = 1AcY +
is a submartingale with respect to the augmented ﬁltration F+;
(ii) if F is right-continuous, then X has an rcll version iﬀEX is right-
continuous; this holds in particular when X is a martingale.
The proof requires an extension of Theorem 6.21 to suitable submartin-
gales.
Lemma 6.28 (uniform integrability)
A submartingale X on Z−is uni-
formly integrable iﬀEX is bounded.
Proof: Let EX be bounded. Introduce the predictable sequence
αn = E[∆Xn|Fn−1] ≥0,
n ≤0,
and note that
E

n≤0αn = EX0 −infn≤0EXn < ∞.
Hence, 	
n αn < ∞a.s., so for n ∈Z−we may deﬁne
An =

k≤nαk,
Mn = Xn −An.
Here EA∗< ∞and M is a martingale closed at 0, so both A and M are
uniformly integrable.
✷

112
Foundations of Modern Probability
Proof of Theorem 6.27: (i) By Lemma 6.11 the process Y ∨0 is L1-bounded
on bounded intervals, so the same thing is true for Y . Thus, by Theorem
6.18, the right- and left-hand limits Yt± exist outside some ﬁxed P-null set
A, so Z = 1AcY + is rcll. Also note that Z is adapted to F+.
To prove that Z is an F+-submartingale, ﬁx any times s < t, and choose
sn ↓s and tn ↓t in Q+ with sn < t. Then Ysm ≤E[Ytn|Fsm] a.s. for all m
and n, and as m →∞we get Zs ≤E[Ytn|Fs+] a.s. by Theorem 6.23. Since
Ytn →Zt in L1 by Lemma 6.28, it follows that Zs ≤E[Zt|Fs+] = E[Zt|Fs+]
a.s.
(ii) For any t < tn ∈Q+,
(EX)tn = E(Ytn),
Xt ≤E[Ytn|Ft] a.s.,
and as tn ↓t we get, by Lemma 6.28 and the right-continuity of F,
(EX)t+ = EZt,
Xt ≤E[Zt|Ft] = Zt a.s.
(15)
If X has a right-continuous version, then clearly Zt = Xt a.s., so (15) yields
(EX)t+ = EXt, which shows that EX is right-continuous. If instead EX
is right-continuous, then (15) gives E|Zt −Xt| = EZt −EXt = 0, and so
Zt = Xt a.s., which means that Z is a version of X.
✷
Justiﬁed by the last theorem, we shall henceforth assume that all sub-
martingales are rcll unless otherwise speciﬁed and also that the underlying
ﬁltration is right-continuous and complete. Most of the previously quoted
results for submartingales on a countable index set extend immediately to
such a context. In particular, this is true for the convergence Theorem 6.18
and the inequalities in Proposition 6.15 and Lemma 6.17. We proceed to
show how Theorems 6.12 and 6.21 extend to submartingales in continuous
time.
Theorem 6.29 (optional sampling and closure, Doob)
Let X be an F-
submartingale on R+, where X and F are right-continuous, and consider
two optional times σ and τ, where τ is bounded. Then Xτ is integrable, and
Xσ∧τ ≤E[Xτ|Fσ] a.s.
(16)
The statement extends to unbounded τ iﬀX+ is uniformly integrable.
Proof: Introduce the optional times σn = 2−n[2nσ+1] and τn = 2−n[2nτ +
1], and conclude from Lemma 6.10 and Theorem 6.12 that
Xσm∧τn ≤E[Xτn|Fσm] a.s.,
m, n ∈N.
As m →∞, we get by Lemma 6.3 and Theorem 6.23
Xσ∧τn ≤E[Xτn|Fσ] a.s.,
n ∈N.
(17)

6. Martingales and Optional Times
113
By the result for the index sets 2−nZ+, the random variables X0; . . . , Xτ2, Xτ1
form a submartingale with bounded mean and are therefore uniformly inte-
grable by Lemma 6.28. Thus, (16) follows as we let n →∞in (17).
If X+ is uniformly integrable, then X is L1-bounded and hence converges
a.s. toward some X∞∈L1. By Proposition 3.12 we get X+
t →X+
∞in L1,
and so E[X+
t |Fs] →E[X+
∞|Fs] in L1 for each s. Letting t →∞along a
sequence, we get by Fatou’s lemma
Xs
≤
limtE[X+
t |Fs] −lim inftE[X−
t |Fs]
≤
E[X+
∞|Fs] −E[X−
∞|Fs] = E[X∞|Fs].
We may now approximate as before to obtain (16) for arbitrary σ and τ.
Conversely, the stated condition implies that there exists some X∞∈L1
with Xs ≤E[X∞|Fs] a.s. for all s > 0, and so X+
s
≤E[X+
∞|Fs] a.s. by
Lemma 6.11. Hence, X+ is uniformly integrable by Lemma 5.5.
✷
For a simple application, we shall consider the hitting probabilities of a
continuous martingale. The result is useful in Chapters 12 and 20.
Corollary 6.30 (ﬁrst hit) Let M be a continuous martingale with M0 = 0,
and deﬁne τx = inf{t > 0; Mt = x}. Then for any a < 0 < b
P{τa < τb} ≤
b
b −a ≤P{τa ≤τb}.
Proof: Since τ = τa ∧τb is optional by Lemma 6.6, Theorem 6.29 yields
EMτ∧t = 0 for all t > 0, so by dominated convergence EMτ = 0. Hence,
0
=
aP{τa < τb} + bP{τb < τa} + E[M∞; τ = ∞]
≤
aP{τa < τb} + bP{τb ≤τa}
=
b −(b −a)P{τa < τb},
which proves the ﬁrst inequality. The proof of the second relation is simi-
lar.
✷
The next result plays a crucial role in Chapter 17.
Lemma 6.31 (absorption) Let X ≥0 be a right-continuous supermartin-
gale, and put τ = inf{t ≥0; Xt ∧Xt−= 0}. Then X = 0 a.s. on [τ, ∞).
Proof: By Theorem 6.27 the process X remains a supermartingale with
respect to the right-continuous ﬁltration F+. The times τn = inf{t ≥0; Xt <
n−1} are F+-optional by Lemma 6.6, and by the right-continuity of X we
have Xτn ≤n−1 on {τn < ∞}. Hence, by Theorem 6.29
E[Xt; τn ≤t] ≤E[Xτn; τn ≤t] ≤n−1,
t ≥0, n ∈N.

114
Foundations of Modern Probability
Noting that τn ↑τ, we get by dominated convergence E[Xt; τ ≤t] = 0, so
Xt = 0 a.s. on {τ ≤t}. The assertion now follows, as we apply this result to
all t ∈Q+ and use the right-continuity of X.
✷
We proceed to show how the right-continuity of an increasing sequence of
supermartingales extends to the limit. The result is needed in Chapter 22.
Theorem 6.32 (increasing limits of supermartingales, Meyer) Let X1 ≤
X2 ≤· · · be right-continuous supermartingales with supn EXn
0 < ∞. Then
Xt = supn Xn
t , t ≥0, is again an a.s. right-continuous supermartingale.
Proof (Doob): By Theorem 6.27 we may assume the ﬁltration to be right-
continuous. The supermartingale property carries over to X by monotone
convergence. To prove the asserted right-continuity, we may assume that X1
is bounded below by an integrable random variable; otherwise consider the
processes obtained by optional stopping at the times m ∧inf{t; X1
t < −m}
for arbitrary m > 0.
Now ﬁx any ε > 0, let T denote the class of optional times τ with
lim supu↓t|Xu −Xt| ≤2ε,
t < τ,
and put p = infτ∈T Ee−τ. Choose σ1, σ2, . . . ∈T with Ee−σn →p, and note
that σ ≡supn σn ∈T with Ee−σ = p. We need to show that σ = ∞a.s.
Then introduce the optional times
τn = inf{t > σ; |Xn
t −Xσ| > ε},
n ∈N,
and put τ = lim supn τn. Noting that
|Xt −Xσ| = lim inf
n→∞|Xn
t −Xσ| ≤ε,
t ∈[σ, τ),
we obtain τ ∈T .
By the right-continuity of Xn, we note that |Xn
τn −Xσ| ≥ε on {τn < ∞}
for every n. Furthermore, we have on the set A = {σ = τ < ∞}
lim inf
n→∞Xn
τn ≥sup
k
lim
n→∞Xk
τn = sup
k Xk
σ = Xσ,
and so lim infn Xn
τn ≥Xσ + ε on A. Since A ∈Fσ by Lemma 6.1, we get by
Fatou’s lemma, optional sampling, and monotone convergence,
E[Xσ + ε; A]
≤
E[lim infnXn
τn; A] ≤lim infnE[Xn
τn; A]
≤
limnE[Xn
σ; A] = E[Xσ; A].
Thus, PA = 0, and so τ > σ a.s. on {σ < ∞}.
If p > 0, we get the
contradiction Ee−τ < p, so p = 0. Hence, σ = ∞a.s.
✷

6. Martingales and Optional Times
115
Exercises
1. Show for any optional times σ and τ that {σ = τ} ∈Fσ ∩Fτ and
Fσ = Fτ on {σ = τ}. However, Fτ and F∞may diﬀer on {τ = ∞}.
2. Show that if σ and τ are optional times on the time scale R+ or Z+,
then so is σ + τ.
3. Give an example of a random time that is weakly optional but not
optional. (Hint: Let F be the ﬁltration induced by the process Xt = ϑt with
P{ϑ = ±1} = 1
2, and take τ = inf{t; Xt > 0}.)
4.
Fix a random time τ and a random variable ξ in R \ {0}.
Show
that the process Xt = ξ 1{τ ≤t} is adapted to a given ﬁltration F iﬀτ is
F-optional and ξ is Fτ-measurable. Give corresponding conditions for the
process Yt = ξ 1{τ < t}.
5. Let P denote the class of sets A ∈R+ × Ωsuch that the process 1A is
progressive. Show that P is a σ-ﬁeld and that a process X is progressive iﬀ
it is P-measurable.
6. Let X be a progressive process with induced ﬁltration F, and ﬁx any
optional time τ < ∞. Show that σ{τ, Xτ} ⊂Fτ ⊂F+
τ ⊂σ{τ, Xτ+h} for
every h > 0. (Hint: The ﬁrst relation becomes an equality when τ takes only
countably many values.) Note that the result may fail when P{τ = ∞} > 0.
7. Let M be an F-martingale on some countable index set, and ﬁx an
optional time τ.
Show that M −M τ remains a martingale conditionally
on Fτ. (Hint: Use Theorem 6.12 and Lemma 6.13.) Extend the result to
continuous time.
8. Show that any submartingale remains a submartingale with respect
to the induced ﬁltration.
9. Let X1, X2, . . . be submartingales such that the process X = supn Xn
is integrable.
Show that X is again a submartingale.
Also show that
lim supn Xn is a submartingale when even supn |Xn| is integrable.
10. Show that the Doob decomposition of an integrable random sequence
X = (Xn) depends on the ﬁltration unless X is a.s. X0-measurable. (Hint:
Compare the ﬁltrations induced by X and by the sequence Yn = (X0, Xn+1).)
11.
Fix a random time τ and a random variable ξ ∈L1, and deﬁne
Mt = ξ 1{τ ≤t}. Show that M is a martingale with respect to the induced
ﬁltration F iﬀE[ξ; τ ≤t|τ > s] = 0 for any s < t. (Hint: The set {τ > s}
is an atom of Fs.)
12. Let F and G be ﬁltrations on a common probability space. Show that
every F-martingale is a G-martingale iﬀFt ⊂Gt⊥⊥FtF∞for every t ≥0.
(Hint: For the necessity, consider F-martingales of the form Ms = E[ξ|Fs]
with ξ ∈L1(Ft).)
13. Show for any rcll supermartingale X ≥0 and constant r ≥0 that
rP{supt Xt ≥r} ≤EX0.

116
Foundations of Modern Probability
14. Let M be an L2-bounded martingale on Z+. Imitate the proof of
Lemma 3.16 to show that Mn converges a.s. and in L2.
15. Give an example of a martingale that is L1-bounded but not uniformly
integrable. (Hint: Every positive martingale is L1-bounded.)
16. Show that if G⊥⊥FnH for some increasing σ-ﬁelds Fn, then G⊥⊥F∞H.
17. Let ξn →ξ in L1. Show for any increasing σ-ﬁelds Fn that E[ξn|Fn]
→E[ξ|F∞] in L1.
18. Let ξ, ξ1, ξ2, . . . ∈L1 with ξn ↑ξ a.s. Show for any increasing σ-
ﬁelds Fn that E[ξn|Fn] →E[ξ|F∞] a.s. (Hint: By Proposition 6.15 we have
supm E[ξ −ξn|Fm]
P→0. Now use the monotonicity.)
19. Show that any right-continuous submartingale is a.s. rcll.
20. Let σ and τ be optional times with respect to some right-continuous
ﬁltration F. Show that the operators EFσ and EFτ commute on L1 with
product EFσ∧τ. (Hint: For any ξ ∈L1, apply the optional sampling theorem
to a right-continuous version of the martingale Mt = E[ξ|Ft].)
21. Let X ≥0 be a supermartingale on Z+, and let τ0 ≤τ1 ≤· · · be
optional times. Show that the sequence (Xτn) is again a supermartingale.
(Hint: Truncate the times τn, and use the conditional Fatou lemma.) Show
by an example that the result fails for submartingales.

Chapter 7
Markov Processes
and Discrete-Time Chains
Markov property and transition kernels; ﬁnite-dimensional dis-
tributions and existence; space homogeneity and independence of
increments; strong Markov property and excursions; invariant
distributions and stationarity; recurrence and transience; ergodic
behavior of irreducible chains; mean recurrence times
A Markov process may be described informally as a randomized dynamical
system, a description that explains the fundamental role that Markov pro-
cesses play both in theory and in a wide range of applications. Processes
of this type appear more or less explicitly throughout the remainder of this
book.
To make the above description precise, let us ﬁx any Borel space S and
ﬁltration F. An adapted process X in S is said to be Markov if for any times
s < t we have Xt = fs,t(Xs, ϑs,t) a.s. for some measurable function fs,t and
some U(0, 1) random variable ϑs,t⊥⊥Fs. The stated condition is equivalent to
the less transparent conditional independence Xt⊥⊥XsFs. The process is said
to be time-homogeneous if we can take fs,t ≡f0,t−s and space-homogeneous
(when S = Rd) if fs,t(x, ·) ≡fs,t(0, ·) + x. A more convenient description of
the evolution is in terms of the transition kernels µs,t(x, ·) = P{fs,t(x, ϑ) ∈·},
which are easily seen to satisfy an a.s. version of the Chapman–Kolmogorov
relation µs,tµt,u = µs,u. In the usual axiomatic treatment, the latter equation
is assumed to hold identically.
This chapter is devoted to some of the most basic and elementary por-
tions of Markov process theory. Thus, the space homogeneity will be shown
to be equivalent to the independence of the increments, which motivates our
discussion of random walks and L´evy processes in Chapters 8 and 13. In
the time-homogeneous case we shall establish a primitive form of the strong
Markov property and see how the result simpliﬁes when the process is also
space-homogeneous. Next we shall see how invariance of the initial distri-
bution implies stationarity of the process, which motivates our treatment of
stationary processes in Chapter 9. Finally, we shall discuss the classiﬁcation
of states and examine the ergodic behavior of discrete-time Markov chains
on a countable state space. The analogous but less elementary theory for
continuous-time chains is postponed until Chapter 10.
117

118
Foundations of Modern Probability
The general theory of Markov processes is more advanced and is not con-
tinued until Chapter 17, which develops the basic theory of Feller processes.
In the meantime we shall consider several important subclasses, such as the
pure jump-type processes in Chapter 10, Brownian motion and related pro-
cesses in Chapters 11 and 16, and the above-mentioned random walks and
L´evy processes in Chapters 8 and 13. A detailed discussion of diﬀusion pro-
cesses appears in Chapters 18 and 20, and additional aspects of Brownian
motion are considered in Chapters 19, 21, and 22.
To begin our systematic study of Markov processes, consider an arbitrary
time scale T ⊂R, equipped with a ﬁltration F = (Ft), and ﬁx a measurable
space (S, S). An S-valued process X on T is said to be a Markov process if
it is adapted to F and such that
Ft⊥⊥
Xt
Xu,
t ≤u in T.
(1)
Just as for the martingale property, we note that even the Markov property
depends on the choice of ﬁltration, with the weakest version obtained for the
ﬁltration induced by X. The simple property in (1) may be strengthened as
follows.
Lemma 7.1 (extended Markov property) If X satisﬁes (1), then
Ft⊥⊥
Xt
{Xu; u ≥t},
t ∈T.
(2)
Proof: Fix any t = t0 ≤t1 ≤· · · in T. By (1) we have Ftn⊥⊥XtnXtn+1 for
every n ≥0, and so by Proposition 5.8
Ft ⊥⊥
Xt0, . . . , Xtn
Xtn+1,
n ≥0.
By the same proposition, this is equivalent to
Ft⊥⊥
Xt
(Xt1, Xt2, . . .),
and (2) follows by a monotone class argument.
✷
For any times s ≤t in T, we assume the existence of some regular condi-
tional distributions
µs,t(Xs, B) = P[Xt ∈B|Xs] = P[Xt ∈B|Fs] a.s.,
B ∈S.
(3)
In particular, we note that the transition kernels µs,t exist by Theorem 5.3
when S is Borel. We may further introduce the one-dimensional distributions
νt = P ◦X−1
t , t ∈T. When T begins at 0, we shall prove that the distribution
of X is uniquely determined by the kernels µs,t together with the initial
distribution ν0.

7. Markov Processes and Discrete-Time Chains
119
For a precise statement, it is convenient to use the kernel operations
introduced in Chapter 1. Note in particular that if µ and ν are kernels on
S, then µ ⊗ν and µν are kernels from S to S2 and S, respectively, given for
s ∈S by
(µ ⊗ν)(s, B)
=

µ(s, dt)

ν(t, du)1B(t, u),
B ∈S2,
(µν)(s, B)
=
(µ ⊗ν)(s, S × B) =

µ(s, dt)ν(t, B),
B ∈S.
Proposition 7.2 (ﬁnite-dimensional distributions) Let X be a Markov pro-
cess on T with one-dimensional distributions νt and transition kernels µs,t.
Then for any t0 ≤· · · ≤tn in T,
P ◦(Xt0, . . . , Xtn)−1
=
νt0 ⊗µt0,t1 ⊗· · · ⊗µtn−1,tn,
(4)
P[(Xt1, . . . , Xtn) ∈· |Ft0]
=
(µt0,t1 ⊗· · · ⊗µtn−1,tn)(Xt0, ·).
(5)
Proof: Formula (4) is clearly true for n = 0. Proceeding by induction,
assume (4) to be true with n replaced by n−1, and ﬁx any bounded measur-
able function f on Sn+1. Noting that Xt0, . . . , Xtn−1 are Ftn−1-measurable,
we get by Theorem 5.4 and the induction hypothesis
Ef(Xt0, . . . , Xtn)
=
E E[f(Xt0, . . . , Xtn)|Ftn−1]
=
E

f(Xt0, . . . , Xtn−1, xn)µtn−1,tn(Xtn−1, dxn)
=
(νt0 ⊗µt0,t1 ⊗· · · ⊗µtn−1,tn)f,
as desired. This completes the proof of (4).
In particular, for any B ∈S and C ∈Sn we get
P{(Xt0, . . . , Xtn) ∈B × C}
=

B νt0(dx)(µt0,t1 ⊗· · · ⊗µtn−1,tn)(x, C)
=
E[(µt0,t1 ⊗· · · ⊗µtn−1,tn)(Xt0, C); Xt0 ∈B],
and (5) follows by Theorem 5.1 and Lemma 7.1.
✷
An obvious consistency requirement leads to the following basic so-called
Chapman–Kolmogorov relation between the transition kernels. Here we say
that two kernels µ and µ′ agree a.s. if µ(x, ·) = µ′(x, ·) for almost every x.
Corollary 7.3 (Chapman, Smoluchovsky)
For any Markov process in a
Borel space S, we have
µs,u = µs,tµt,u a.s. νs,
s ≤t ≤u.
Proof: By Proposition 7.2 we have a.s. for any B ∈S
µs,u(Xs, B)
=
P[Xu ∈B|Fs] = P[(Xt, Xu) ∈S × B|Fs]
=
(µs,t ⊗µt,u)(Xs, S × B) = (µs,tµt,u)(Xs, B).
Since S is Borel, we may choose a common null set for all B.
✷

120
Foundations of Modern Probability
We shall henceforth assume the Chapman–Kolmogorov relation to hold
identically, so that
µs,u = µs,tµt,u,
s ≤t ≤u.
(6)
Thus, we deﬁne a Markov process by condition (3), in terms of some tran-
sition kernels µs,t satisfying (6). In discrete time, when T = Z+, the latter
relation is no restriction, since we may then start from any versions of the
kernels µn = µn−1,n and deﬁne µm,n = µm+1 · · · µn for arbitrary m < n.
Given such a family of transition kernels µs,t and an arbitrary initial
distribution ν, we need to show that an associated Markov process exists.
This is ensured, under weak restrictions, by the following result.
Theorem 7.4 (existence, Kolmogorov) Fix a time scale T starting at 0, a
Borel space (S, S), a probability measure ν on S, and a family of probability
kernels µs,t on S, s ≤t in T, satisfying (6). Then there exists an S-valued
Markov process X on T with initial distribution ν and transition kernels µs,t.
Proof: Introduce the probability measures
νt1,...,tn = νµt0,t1 ⊗· · · ⊗µtn−1,tn,
0 = t0 ≤t1 ≤· · · ≤tn, n ∈N.
To see that the family (νt0,...,tn) is projective, let B ∈Sn−1 be arbitrary, and
deﬁne for any k ∈{1, . . . , n} the set
Bk = {(x1, . . . , xn) ∈Sn; (x1, . . . , xk−1, xk+1, . . . , xn) ∈B}.
Then by (6)
νt1,...,tnBk
=
(νµt0,t1 ⊗· · · ⊗µtk−1,tk+1 ⊗· · · ⊗µtn−1,tn)B
=
νt1,...,tk−1,tk+1,...,tnB,
as desired. By Theorem 5.16 there exists an S-valued process X on T with
P ◦(Xt1, . . . , Xtn)−1 = νt1,...,tn,
t1 ≤· · · ≤tn, n ∈N,
(7)
and, in particular, P ◦X−1
0
= ν0 = ν.
To see that X is Markov with transition kernels µs,t, ﬁx any times s1 ≤
· · · ≤sn = s ≤t and sets B ∈Sn and C ∈S, and conclude from (7) that
P{(Xs1, . . . , Xsn, Xt) ∈B × C}
=
νs1,...,sn,t(B × C)
=
E[µs,t(Xs, C); (Xs1, . . . , Xsn) ∈B].
Writing F for the ﬁltration induced by X, we get by a monotone class argu-
ment
P[Xt ∈C; A] = E[µs,t(Xs, C); A],
A ∈Fs,
and so P[Xt ∈C|Fs] = µs,t(Xs, C) a.s.
✷

7. Markov Processes and Discrete-Time Chains
121
Now assume that S is a measurable Abelian group. A kernel µ on S is
then said to be homogeneous if
µ(x, B) = µ(0, B −x),
x ∈S, B ∈S.
An S-valued Markov process with homogeneous transition kernels µs,t is said
to be space-homogeneous. Furthermore, we say that a process X in S has
independent increments if, for any times t0 ≤· · · ≤tn, the increments Xtk −
Xtk−1 are mutually independent and independent of X0.
More generally,
given any ﬁltration F on T, we say that X has F-independent increments
if X is adapted to F and such that Xt −Xs⊥⊥Fs for all s ≤t in T. Note
that the elementary notion of independence corresponds to the case when F
is induced by X.
Proposition 7.5 (independent increments and homogeneity)
Consider a
measurable Abelian group S, a ﬁltration F on some time scale T, and an
S-valued and F-adapted process X on T.
Then X is space-homogeneous
F-Markov iﬀit has F-independent increments, in which case the transition
kernels are given by
µs,t(x, B) = P{Xt −Xs ∈B −x},
x ∈S, B ∈S, s ≤t in T.
(8)
Proof: First assume that X is Markov with transition kernels
µs,t(x, B) = µs,t(B −x),
x ∈S, B ∈S, s ≤t in T.
(9)
By Theorem 5.4, for any s ≤t in T and B ∈S we get
P[Xt −Xs ∈B|Fs] = P[Xt ∈B + Xs|Fs] = µs,t(Xs, B + Xs) = µs,tB,
so Xt −Xs is independent of Fs with distribution µs,t, and (8) follows by
means of (9).
Conversely, assume that Xt −Xs is independent of Fs with distribution
µs,t. Deﬁning the associated kernel µs,t by (9), we get by Theorem 5.4 for
any s, t, and B as before
P[Xt ∈B|Fs] = P[Xt −Xs ∈B −Xs|Fs] = µs,t(B −Xs) = µs,t(Xs, B).
Thus, X is Markov with the homogeneous transition kernels in (9).
✷
We may now specialize to the time-homogeneous case—when T = R+ or
Z+ and the transition kernels are of the form µs,t = µt−s, so that
P[Xt ∈B|Fs] = µt−s(Xs, B) a.s.,
B ∈S, s ≤t in T.
Introducing the initial distribution ν = P ◦X−1
0 , we may write the formulas
of Proposition 7.2 as
P ◦(Xt0, . . . , Xtn)−1
=
νµt0 ⊗µt1−t0 ⊗· · · ⊗µtn−tn−1,
P[(Xt1, . . . , Xtn) ∈· |Ft0]
=
(µt1−t0 ⊗· · · ⊗µtn−tn−1)(Xt0, ·),

122
Foundations of Modern Probability
and the Chapman–Kolmogorov relation becomes
µs+t = µsµt,
s, t ∈T,
which is again assumed to hold identically. We often refer to the family (µt)
as a semigroup of transition kernels.
The following result justiﬁes the interpretation of a discrete-time Markov
process as a randomized dynamical system.
Proposition 7.6 (recursion) Let X be a process on Z+ with values in a
Borel space S. Then X is Markov iﬀthere exist some measurable functions
f1, f2, . . .: S × [0, 1] →S and i.i.d. U(0, 1) random variables ϑ1, ϑ2, . . . ⊥⊥X0
such that Xn = fn(Xn−1, ϑn) a.s. for all n ∈N. Here we may choose f1 =
f2 = · · · = f iﬀX is time-homogeneous.
Proof: Let X have the stated representation and introduce the kernels
µn(x, ·) = P{fn(x, ϑ) ∈·}, where ϑ is U(0, 1). Writing F for the ﬁltration
induced by X, we get by Theorem 5.4 for any B ∈S
P[Xn ∈B|Fn−1]
=
P[fn(Xn−1, ϑn) ∈B|Fn−1]
=
λ{t; fn(Xn−1, t) ∈B} = µn(Xn−1, B),
which shows that X is Markov with transition kernels µn.
Now assume instead the latter condition. By Lemma 2.22 we may choose
some associated functions fn as above. Let ˜ϑ1, ˜ϑ2, . . . be i.i.d. U(0, 1) and in-
dependent of ˜X0
d= X0, and deﬁne recursively ˜Xn = fn( ˜Xn−1, ˜ϑn) for n ∈N.
As before, ˜X is Markov with transition kernels µn. Hence, ˜X
d= X by Propo-
sition 7.2, so by Theorem 5.10 there exist some random variables ϑn with
(X, (ϑn))
d= ( ˜X, (˜ϑn)). Since the diagonal in S2 is measurable, the desired
representation follows. The last assertion is obvious from the construction. ✷
Now ﬁx a transition semigroup (µt) on some Borel space S. For any proba-
bility measure ν on S, there exists by Theorem 7.4 an associated Markov pro-
cess Xν, and by Proposition 2.2 the corresponding distribution Pν is uniquely
determined by ν. Note that Pν is a probability measure on the path space
(ST, ST). For degenerate initial distributions δx, we may write Px instead of
Pδx. Integration with respect to Pν or Px is denoted by Eν or Ex, respectively.
Lemma 7.7 (mixtures) The measures Px form a probability kernel from S
to ST, and for any initial distribution ν we have
PνA =

S(PxA)ν(dx),
A ∈ST.
(10)
Proof: Both the measurability of PxA and formula (10) are obvious for
cylinder sets of the form A = (πt1, . . . , πtn)−1B. The general case follows

7. Markov Processes and Discrete-Time Chains
123
easily by a monotone class argument.
✷
Rather than considering one Markov process Xν for each initial distribu-
tion ν, it is more convenient to introduce the canonical process X, deﬁned
as the identity mapping on the path space (ST, ST), and equip the latter
space with the diﬀerent probability measures Pν. Note that Xt agrees with
the evaluation map πt : ω →ωt on ST, which is measurable by the deﬁnition
of ST. For our present purposes, it is suﬃcient to endow the path space ST
with the canonical ﬁltration induced by X.
On ST we may further introduce the shift operators θt : ST →ST, t ∈T,
given by
(θtω)s = ωs+t,
s, t ∈T, ω ∈ST,
and we note that the θt are measurable with respect to ST. In the canonical
case it is further clear that θtX = θt = X ◦θt.
Optional times with respect to a Markov process are often constructed
recursively in terms of shifts on the underlying path space. Thus, for any
pair of optional times σ and τ on the canonical space, we may introduce
the random time γ = σ + τ ◦θσ, with the understanding that γ = ∞when
σ = ∞. Under weak restrictions on space and ﬁltration, we may show that
γ is again optional. Here C(S) and D(S) denote the spaces of continuous or
rcll functions, respectively, from R+ to S.
Proposition 7.8 (shifted optional times) For any metric space S, let σ and
τ be optional times on the canonical space S∞, C(S), or D(S), endowed with
the right-continuous, induced ﬁltration. Then even γ = σ +τ ◦θσ is optional.
Proof: Since σ ∧n + τ ◦θσ∧n ↑γ, we may assume by Lemma 6.3 that σ
is bounded. Let X denote the canonical process with induced ﬁltration F.
Since X is F+-progressive, Xσ+s = Xs◦θσ is F+
σ+s-measurable for every s ≥0
by Lemma 6.5. Fixing any t ≥0, it follows that all sets A = {Xs ∈B} with
s ≤t and B ∈S satisfy θ−1
σ A ∈F+
σ+t. The sets A with the latter property
form a σ-ﬁeld, and therefore
θ−1
σ Ft ⊂F+
σ+t,
t ≥0.
(11)
Now ﬁx any t ≥0, and note that
{γ < t} =

r∈Q∩(0,t)
{σ < r, τ ◦θσ < t −r}.
(12)
For every r ∈(0, t) we have {τ < t −r} ∈Ft−r, so θ−1
σ {τ < t −r} ∈F+
σ+t−r
by (11), and Lemma 6.2 yields
{σ < r, τ ◦θσ < t −r} = {σ + t −r < t} ∩θ−1
σ {τ < t −r} ∈Ft.
Thus, {γ < t} ∈Ft by (12), and so γ is F+-optional by Lemma 6.2.
✷

124
Foundations of Modern Probability
We proceed to show how the elementary Markov property may be ex-
tended to suitable optional times. The present statement is only preliminary,
and stronger versions are obtained under further conditions in Theorems
10.16, 11.11, and 17.17.
Proposition 7.9 (strong Markov property) Fix a time-homogeneous Mar-
kov process X on T = R+ or Z+, and let τ be an optional time taking
countably many values. Then
P[θτX ∈A|Fτ] = PXτA a.s. on {τ < ∞},
A ∈ST.
(13)
If X is canonical, it is equivalent that
Eν[ξ ◦θτ|Fτ] = EXτξ, Pν-a.s. on {τ < ∞},
(14)
for any distribution ν on S and bounded or nonnegative random variable ξ.
Since {τ < ∞} ∈Fτ, we note that (13) and (14) make sense by Lemma
5.2, although θτX and PXτ are deﬁned only for τ < ∞.
Proof: By Lemmas 5.2 and 6.1 we may assume that τ = t is ﬁnite and
nonrandom. For sets A of the form
A = (πt1, . . . , πtn)−1B,
t1 ≤· · · ≤tn, B ∈Sn, n ∈N,
(15)
Proposition 7.2 yields
P[θtX ∈A|Ft]
=
P[(Xt+t1, . . . , Xt+tn) ∈B|Ft]
=
(µt1 ⊗µt2−t1 ⊗· · · ⊗µtn−tn−1)(Xt, B) = PXtA,
which extends by a monotone class argument to arbitrary A ∈ST.
In the canonical case we note that (13) is equivalent to (14) with ξ = 1A,
since in that case ξ ◦θτ = 1{θτX ∈A}. The result extends by linearity and
monotone convergence to general ξ.
✷
When X is both space- and time-homogeneous, the strong Markov prop-
erty can be stated without reference to the family (Px).
Theorem 7.10 (space and time homogeneity) Let X be a space- and time-
homogeneous Markov process in some measurable Abelian group S. Then
PxA = P0(A −x),
x ∈S, A ∈ST.
(16)
Furthermore, (13) holds for a given optional time τ < ∞iﬀXτ is a.s. Fτ-
measurable and
X −X0
d= θτX −Xτ ⊥⊥Fτ.
(17)

7. Markov Processes and Discrete-Time Chains
125
Proof: By Proposition 7.2 we get for any set A as in (15)
PxA
=
Px ◦(πt1, . . . , πtn)−1B
=
(µt1 ⊗µt2−t1 ⊗· · · ⊗µtn−tn−1)(x, B)
=
(µt1 ⊗µt2−t1 ⊗· · · ⊗µtn−tn−1)(0, B −x)
=
P0 ◦(πt1, . . . , πtn)−1(B −x) = P0(A −x).
This extends to (16) by a monotone class argument.
Next assume (13). Letting A = π−1
0 B with B ∈S, we get
1B(Xτ) = PXτ{π0 ∈B} = P[Xτ ∈B|Fτ] a.s.,
so Xτ is a.s. Fτ-measurable. By (16) and Theorem 5.4, we further note that
P[θτX −Xτ ∈A|Fτ] = PXτ(A + Xτ) = P0A,
A ∈ST,
(18)
and so θτX −Xτ is independent of Fτ with distribution P0. In particular,
this holds for τ = 0, so X −X0 has distribution P0, and (17) follows.
Next assume (17). To deduce (13), ﬁx any A ∈ST, and conclude from
(16) and Theorem 5.4 that
P[θτX ∈A|Fτ]
=
P[θτX −Xτ ∈A −Xτ|Fτ]
=
P0(A −Xτ) = PXτA.
✷
If a time-homogeneous Markov process X has initial distribution ν, then
the distribution at time t ∈T equals νt = νµt, or
νtB =

ν(dx)µt(x, B),
B ∈S, t ∈T.
A distribution ν is said to be invariant for the semigroup (µt) if νt is inde-
pendent of t, that is, if νµt = ν for all t ∈T. We further say that a process
X on T is stationary if θtX
d= X for all t ∈T. The two notions are related
as follows.
Lemma 7.11 (stationarity and invariance) Let X be a time-homogeneous
Markov process on T with transition kernels µt and initial distribution ν.
Then X is stationary iﬀν is invariant for (µt).
Proof: Assuming ν to be invariant, we get by Proposition 7.2
(Xt+t1, . . . , Xt+tn) d= (Xt1, . . . , Xtn),
t, t1 ≤· · · ≤tn in T,
and the stationarity of X follows by Proposition 2.2.
✷
For processes X in discrete time, we may consider the sequence of suc-
cessive visits to a ﬁxed state y ∈S. Assuming the process to be canonical,

126
Foundations of Modern Probability
we may introduce the hitting time τy = inf{n ∈N; Xn = y} and then deﬁne
recursively
τ k+1
y
= τ k
y + τy ◦θτ k
y ,
k ∈Z+,
starting from τ 0
y = 0. Let us further introduce the occupation times
κy = sup{k; τ k
y < ∞} =

n≥11{Xn = y},
y ∈S.
The next result expresses the distribution of κy in terms of the hitting prob-
abilities
rxy = Px{τy < ∞} = Px{κy > 0},
x, y ∈S.
Proposition 7.12 (occupation times) For any x, y ∈S and k ∈N,
Px{κy ≥k}
=
Px{τ k
y < ∞} = rxyrk−1
yy ,
(19)
Exκy
=
rxy
1 −ryy
.
(20)
Proof: By the strong Markov property, we get for any k ∈N
Px{τ k+1
y
< ∞}
=
Px

τ k
y < ∞, τy ◦θτ k
y < ∞

=
Px{τ k
y < ∞}Py{τy < ∞} = ryyPx{τ k
y < ∞},
and the second relation in (19) follows by induction on k. The ﬁrst relation
is clear from the fact that κy ≥k iﬀτ k
y < ∞. To deduce (20), conclude from
(19) and Lemma 2.4 that
Exκy =

k≥1
Px{κy ≥k} =

k≥1
rxyrk−1
yy
=
rxy
1 −ryy
.
✷
For x = y the last result yields
Px{κx ≥k} = Px{τ k
x < ∞} = rk
xx,
k ∈N.
Thus, under Px, the number of visits to x is either a.s. inﬁnite or geometri-
cally distributed with mean Exκx + 1 = (1 −rxx)−1 < ∞. This leads to a
corresponding classiﬁcation of the states into recurrent and transient ones.
Recurrence can often be deduced from the existence of an invariant dis-
tribution. Here and below we write pn
xy = µn(x, {y}).
Proposition 7.13 (invariant distributions and recurrence) If an invariant
distribution ν exists, then any state x with ν{x} > 0 is recurrent.
Proof: By the invariance of ν,
0 < ν{x} =

ν(dy)pn
yx,
n ∈N.
(21)

7. Markov Processes and Discrete-Time Chains
127
Thus, by Proposition 7.12 and Fubini’s theorem,
∞=

n≥1

ν(dy)pn
yx =

ν(dy)

n≥1
pn
yx =

ν(dy)
ryx
1 −rxx
≤
1
1 −rxx
.
Hence, rxx = 1, and so x is recurrent.
✷
The period dx of a state x is deﬁned as the greatest common divisor of
the set {n ∈N; pn
xx > 0}, and we say that x is aperiodic if dx = 1.
Proposition 7.14 (positivity) If x ∈S has period d < ∞, then pnd
xx > 0 for
all but ﬁnitely many n.
Proof: Deﬁne S = {n ∈N; pnd
xx > 0}, and conclude from the Chapman–
Kolmogorov relation that S is closed under addition. Since S has greatest
common divisor 1, the generated additive group equals Z.
In particular,
there exist some n1, . . . , nk ∈S and z1, . . . , zk ∈Z with
	
j zjnj = 1. Writing
m = n1
	
j |zj|nj, we note that any number n ≥m can be represented, for
suitable h ∈Z+ and r ∈{0, . . . , n1 −1}, as
n = m + hn1 + r = hn1 +

j≤k(n1|zj| + rzj)nj ∈S.
✷
For each x ∈S, the successive excursions of X from x are given by
Yn = Xτx ◦θτ n
x ,
n ∈Z+,
as long as τ n
x < ∞.
To allow for inﬁnite excursions, we may introduce
an extraneous element ∂/∈SZ+, and deﬁne Yn = ∂whenever τ n
x = ∞.
Conversely, X may be recovered from the Yn through the formulas
τn
=

k<n inf{t > 0; Yk(t) = x},
(22)
Xt
=
Yn(t −τn),
τn ≤t < τn+1, n ∈Z+,
(23)
where ∂t is arbitrary.
The distribution νx = Px ◦Y −1
0
is called the excursion law at x. When
x is recurrent and ryx = 1, Proposition 7.9 shows that Y1, Y2, . . . are i.i.d. νx
under Py. The result extends to the general case, as follows.
Proposition 7.15 (excursions)
Consider a discrete-time Markov process
X in a Borel space S, and ﬁx any x ∈S. Then there exist some independent
processes Y0, Y1, . . . in S, all but Y0 with distribution νx, such that X is a.s.
given by (22) and (23).
Proof: Put ˜Y0
d= Y0, and let ˜Y1, ˜Y2, . . . be independent of ˜Y0 and i.i.d. νx.
Construct associated random times ˜τ0, ˜τ1, . . . as in (22), and deﬁne a process
˜X as in (23). By Corollary 5.11, it is enough to show that X
d= ˜X. Writing
κ = sup{n ≥0; τn < ∞},
˜κ = sup{n ≥0; ˜τn < ∞},

128
Foundations of Modern Probability
it is equivalent to show that
(Y0, . . . , Yκ, ∂, ∂, . . .) d= (˜Y0, . . . , ˜Y˜κ, ∂, ∂, . . .).
(24)
Using the strong Markov property on the left and the independence of the
˜Yn on the right, it is easy to check that both sides are Markov processes in
SZ+ ∪{∂} with the same initial distribution and transition kernel. Hence,
(24) holds by Proposition 7.2.
✷
By a discrete-time Markov chain we mean a Markov process on the time
scale Z+, taking values in a countable state space I. In this case the transition
kernels of X are determined by the n-step transition probabilities pn
ij =
µn(i, {j}), i, j ∈I, and the Chapman–Kolmogorov relation becomes
pm+n
ik
=

jpm
ijpn
jk,
i, k ∈I, m, n ∈N,
(25)
or in matrix notation, pm+n = pmpn. Thus, pn is the nth power of the matrix
p = p1, which justiﬁes our notation. Regarding the initial distribution ν as
a row vector (νi), we may write the distribution at time n as νpn.
As before, we deﬁne rij = Pi{τj < ∞}, where τj = inf{n > 0; Xn = j}.
A Markov chain in I is said to be irreducible if rij > 0 for all i, j ∈I, so that
every state can be reached from any other state. For irreducible chains, all
states have the same recurrence and periodicity properties.
Proposition 7.16 (irreducible chains) For an irreducible Markov chain,
(i) the states are either all recurrent or all transient;
(ii) all states have the same period;
(iii) if ν is invariant, then νi > 0 for all i.
For the proof of (i) we need the following lemma.
Lemma 7.17 (recurrence classes) Let i ∈I be recurrent, and deﬁne Ci =
{j ∈I; rij > 0}. Then rjk = 1 for all j, k ∈Ci, and all states in Ci are
recurrent.
Proof: By the recurrence of i and the strong Markov property, we get for
any j ∈Ci
0
=
Pi{τj < ∞, τi ◦θτj = ∞}
=
Pi{τj < ∞}Pj{τi = ∞} = rij(1 −rji).
Since rij > 0 by hypothesis, we obtain rji = 1. Fixing any m, n ∈N with
pm
ij, pn
ji > 0, we get by (25)
Ejκj ≥

s>0pm+n+s
jj
≥

s>0pn
jips
iipm
ij = pn
jipm
ijEiκi = ∞,

7. Markov Processes and Discrete-Time Chains
129
and so j is recurrent by Proposition 7.12. Reversing the roles of i and j gives
rij = 1. Finally, we get for any j, k ∈Ci
rjk ≥Pj{τi < ∞, τk ◦θτi < ∞} = rjirik = 1.
✷
Proof of Proposition 7.16: (i) This is clear from Lemma 7.17.
(ii) Fix any i, j ∈I, and choose m, n ∈N with pm
ij, pn
ji > 0. By (25),
pm+h+n
jj
≥pn
jiph
iipm
ij,
h ≥0.
For h = 0 we get pm+n
jj
> 0, and so dj|(m+n) (dj divides m+n). In general,
ph
ii > 0 then implies dj|h, so dj ≤di. Reversing the roles of i and j yields
di ≤dj, so di = dj.
(iii) Fix any i ∈I. Choosing j ∈I with νj > 0 and then n ∈N with
pn
ji > 0, we may conclude from (21) that even νi > 0.
✷
We may now state the basic ergodic theorem for irreducible Markov
chains. For any signed measure µ we deﬁne ∥µ∥= supA |µA|.
Theorem 7.18 (ergodic behavior, Markov, Kolmogorov) For an irreducible,
aperiodic Markov chain, exactly one of these conditions holds:
(i) There exists a unique invariant distribution ν; furthermore, νi > 0 for
all i ∈I, and for any distribution µ on I,
lim
n→∞∥Pµ ◦θ−1
n −Pν∥= 0.
(26)
(ii) No invariant distribution exists, and
lim
n→∞pn
ij = 0,
i, j ∈I.
(27)
A Markov chain satisfying (i) is clearly recurrent, whereas one that sat-
isﬁes (ii) may be either recurrent or transient.
This leads to the further
classiﬁcation of the irreducible, aperiodic, and recurrent Markov chains into
positive recurrent and null recurrent ones, depending on whether (i) or (ii)
applies.
We shall prove Theorem 7.18 by the method of coupling. Here the general
idea is to compare the distributions of two processes X and Y , by construct-
ing copies ˜X
d= X and ˜Y
d= Y on a common probability space. By a suitable
choice of joint distribution, it is sometimes possible to reduce the original
problem to a pathwise comparison. Coupling often leads to simple intuitive
proofs, and we shall see further applications of the method in Chapters 8,
12, 13, 14, and 20. For our present needs, an elementary coupling by inde-
pendence is suﬃcient.

130
Foundations of Modern Probability
Lemma 7.19 (coupling) Let X and Y be independent Markov chains on
some countable state spaces I and J, with transition matrices (pii′) and (qjj′),
respectively. Then the pair (X, Y ) is again Markov with transition matrix
rij,i′j′ = pii′qjj′. If X and Y are irreducible and aperiodic, then so is (X, Y ),
and in that case (X, Y ) is recurrent whenever invariant distributions exist
for both X and Y .
Proof: The ﬁrst assertion is easily proved by computation of the ﬁnite-
dimensional distributions of (X, Y ) for an arbitrary initial distribution µ ⊗ν
on I × J, using Proposition 7.2. Now assume that X and Y are irreducible
and aperiodic. Fixing any i, i′ ∈I and j, j′ ∈J, it is seen from Proposition
7.14 that rn
ij,i′j′ = pn
ii′qn
jj′ > 0 for all but ﬁnitely many n ∈N, and so even
(X, Y ) has the stated properties. Finally, if µ and ν are invariant distribu-
tions for X and Y , respectively, then µ ⊗ν is invariant for (X, Y ), and the
last assertion follows by Proposition 7.13.
✷
The point of the construction is that if the coupled processes eventually
meet, their distributions must agree asymptotically.
Lemma 7.20 (strong ergodicity) Let the Markov chain in I2 with transition
matrix pii′pjj′ be irreducible and recurrent. Then for any distributions µ and
ν on I,
lim
n→∞∥Pµ ◦θ−1
n −Pν ◦θ−1
n ∥= 0.
(28)
Proof (Doeblin): Let X and Y be independent with distributions Pµ and
Pν. By Lemma 7.19 the pair (X, Y ) is again Markov with respect to the
induced ﬁltration F, and by Proposition 7.9 the strong Markov property
holds for (X, Y ) at every ﬁnite optional time τ. Taking τ = inf{n ≥0; Xn =
Yn}, we get for any measurable set A ⊂I∞
P[θτX ∈A|Fτ] = PXτA = PYτA = P[θτY ∈A|Fτ].
In particular, (τ, Xτ, θτX) d= (τ, Xτ, θτY ). Deﬁning ˜Xn = Xn for n ≤τ and
˜Xn = Yn otherwise, we obtain ˜X
d= X, so for any A as above
|P{θnX ∈A} −P{θnY ∈A}|
=
|P{θn ˜X ∈A} −P{θnY ∈A}|
=
|P{θn ˜X ∈A, τ > n} −P{θnY ∈A, τ > n}|
≤
P{τ > n} →0.
✷
The next result ensures the existence of an invariant distribution. Here a
coupling argument is again useful.
Lemma 7.21 (existence) If (27) fails, then an invariant distribution exists.

7. Markov Processes and Discrete-Time Chains
131
Proof: Assume that (27) fails, so that lim supn pn
i0,j0 > 0 for some i0, j0 ∈
I. By a diagonal argument we may choose a subsequence N ′ ⊂N and some
constants cj with cj0 > 0 such that pn
i0,j →cj along N ′ for every j ∈I. Note
that 0 < 	
j cj ≤1 by Fatou’s lemma.
To extend the convergence to arbitrary i, let X and Y be independent
processes with the given transition matrix (pij), and conclude from Lemma
7.19 that (X, Y ) is an irreducible Markov chain on I2 with transition prob-
abilities qij,i′j′ = pii′pjj′. If (X, Y ) is transient, then by Proposition 7.12

n(pn
ij)2 =

nqn
ii,jj < ∞,
i, j ∈I,
and (27) follows. The pair (X, Y ) is then recurrent and Lemma 7.20 yields
pn
ij −pn
i0,j →0 for all i, j ∈I. Hence, pn
ij →cj along N ′ for all i and j.
Next conclude from the Chapman–Kolmogorov relation that
pn+1
ik
=

jpn
ijpjk =

jpijpn
jk,
i, k ∈I.
Using Fatou’s lemma on the left and dominated convergence on the right, we
get as n →∞along N ′

jcjpjk ≤

jpijck = ck,
k ∈I.
(29)
Summing over k gives 	
j cj ≤1 on both sides, and so (29) holds with equal-
ity. Thus, (ci) is invariant and we get an invariant distribution ν by taking
νi = ci/
	
j cj.
✷
Proof of Theorem 7.18: If no invariant distribution exists, then (27) holds
by Lemma 7.21. Now let ν be an invariant distribution, and note that νi > 0
for all i by Proposition 7.16. By Lemma 7.19, the coupled chain in Lemma
7.20 is irreducible and recurrent, so (28) holds for any initial distribution µ,
and (26) follows since Pν ◦θ−1
n
= Pν by Lemma 7.11. If even ν′ is invariant,
then (26) yields Pν′ = Pν, and so ν′ = ν.
✷
The limits in Theorem 7.18 may be expressed in terms of the mean re-
currence times Ejτj, as follows.
Theorem 7.22 (mean recurrence times, Kolmogorov) For a Markov chain
in I and for states i, j ∈I with j aperiodic, we have
lim
n→∞pn
ij = Pi{τj < ∞}
Ejτj
.
(30)
Proof: First take i = j. If j is transient, then pn
jj →0 and Ejτj = ∞,
and so (30) is trivially true. If instead j is recurrent, then the restriction of
X to the set Cj = {i; rji > 0} is irreducible recurrent by Lemma 7.17 and
aperiodic by Proposition 7.16. Hence, pn
jj converges by Theorem 7.18.

132
Foundations of Modern Probability
To identify the limit, deﬁne
Ln = sup{k ∈Z+; τ k
j ≤n} =
n

k=1
1{Xk = j},
n ∈N.
The τ n
j form a random walk under Pj, so by the law of large numbers
L(τ n
j )
τ n
j
= n
τ n
j
→
1
Ejτj
Pj-a.s.
By the monotonicity of Lk and τ n
j it follows that Ln/n →(Ejτj)−1 a.s. Pj.
Noting that Ln ≤n, we get by dominated convergence
1
n
n

k=1
pk
jj = EjLn
n
→
1
Ejτj
,
and (30) follows.
Now let i ̸= j.
Using the strong Markov property, the disintegration
theorem, and dominated convergence, we get
pn
ij
=
Pi{Xn = j} = Pi{τj ≤n, (θτjX)n−τj = j}
=
Ei[p
n−τj
jj
; τj ≤n] →Pi{τj < ∞}/Ejτj.
✷
We return to continuous time and a general state space, to clarify the
nature of the strong Markov property of a process X at ﬁnite optional times
τ. The condition is clearly a combination of the conditional independence
θτX⊥⊥XτFτ and the strong homogeneity
P[θτX ∈·|Xτ] = PXτ a.s.
(31)
Though (31) appears to be weaker than (13), the two properties are in fact
equivalent, under suitable regularity conditions on X and F.
Theorem 7.23 (strong homogeneity) Fix a separable metric space (S, ρ),
a probability kernel (Px) from S to D(S), and a right-continuous ﬁltration
F on R+. Let X be an F-adapted rcll process in S satisfying (31) for all
bounded optional times τ. Then the strong Markov property holds at any
such time τ.
Our proof is based on a zero–one law for absorption probabilities, involv-
ing the sets
I = {w ∈D; wt ≡w0},
A = {x ∈S; PxI = 1}.
(32)
Lemma 7.24 (absorption) For X as in Theorem 7.23 and for any optional
time τ < ∞, we have
PXτI = 1I(θτX) = 1A(Xτ) a.s.
(33)

7. Markov Processes and Discrete-Time Chains
133
Proof: We may clearly assume that τ is bounded, say by n ∈N. Fix any
h > 0, and divide S into disjoint Borel sets B1, B2, . . . of diameter < h. For
each k ∈N, deﬁne
τk = n ∧inf{t > τ; ρ(Xτ, Xt) > h} on {Xτ ∈Bk},
(34)
and put τk = τ otherwise. The times τk are again bounded and optional, and
we note that
{Xτk ∈Bk} ⊂{Xτ ∈Bk, supt∈[τ,n]ρ(Xτ, Xt) ≤h}.
(35)
Using (31) and (35), we get as n →∞and h →0
E[PXτIc; θτX ∈I] =

kE[PXτIc; θτX ∈I, Xτ ∈Bk]
≤

kE[PXτkIc; Xτk ∈Bk]
=

kP{θτkX /∈I, Xτk ∈Bk}
≤

kP{θτX /∈I, Xτ ∈Bk, supt∈[τ,n]ρ(Xτ, Xt) ≤h}
→
P{θτX /∈I, supt≥τρ(Xτ, Xt) = 0} = 0,
and so PXτI = 1 a.s. on {θτX ∈I}. Since also EPXτI = P{θτX ∈I} by
(31), we obtain the ﬁrst relation in (33). The second relation follows by the
deﬁnition of A.
✷
Proof of Theorem 7.23: Deﬁne I and A as in (32). To prove (13) on
{Xτ ∈A}, ﬁx any times t1 < · · · < tn and Borel sets B1, . . . , Bn, write
B = 
k Bk, and conclude from (31) and Lemma 7.24 that
P

k{Xτ+tk ∈Bk}
 Fτ

=
P[Xτ ∈B|Fτ] = 1{Xτ ∈B}
=
P[Xτ ∈B|Xτ] = PXτ{w0 ∈B}
=
PXτ

k{wtk ∈Bk}.
This extends to (13) by a monotone class argument.
To prove (13) on {Xτ /∈A}, we may assume that τ ≤n a.s., and divide
Ac into disjoint Borel sets Bk of diameter < h. Fix any F ∈Fτ with F ⊂
{Xτ /∈A}. For each k ∈N, deﬁne τk as in (34) on the set F c ∩{Xτ ∈Bk},
and let τk = τ otherwise. Note that (35) remains true on F c. Using (31),
(35), and Lemma 7.24, we get as n →∞and h →0
|P[θτX ∈· ; F] −E[PXτ; F]|
=


kE[1{θτX ∈·} −PXτ; Xτ ∈Bk, F]

=


kE[1{θτkX ∈·} −PXτk; Xτk ∈Bk, F]

=


kE[1{θτkX ∈·} −PXτk; Xτk ∈Bk, F c]

≤

kP[Xτk ∈Bk; F c]

134
Foundations of Modern Probability
≤

kP{Xτ ∈Bk, supt∈[τ,n]ρ(Xτ, Xt) ≤h}
→
P{Xτ /∈A, supt≥τρ(Xτ, Xt) = 0} = 0.
Hence, the left-hand side is zero.
✷
Exercises
1. Let X be a process with Xs⊥⊥Xt{Xu, u ≥t} for all s < t. Show that
X is Markov with respect to the induced ﬁltration.
2. Let X be a Markov process in some space S, and ﬁx a measurable
function f on S. Show by an example that the process Yt = f(Xt) need not
be Markov. (Hint: Let X be a simple symmetric random walk on Z, and
take f(x) = [x/2].)
3. Let X be a Markov process in R with transition functions µt satisfying
µt(x, B) = µt(−x, −B). Show that the process Yt = |Xt| is again Markov.
4. Fix any process X on R+, and deﬁne Yt = Xt = {Xs∧t; s ≥0}. Show
that Y is Markov with respect to the induced ﬁltration.
5. Consider a random element ξ in some Borel space and a ﬁltration F
with F∞⊂σ{ξ}. Show that the measure-valued process Xt = P[ξ ∈·|Ft] is
Markov. (Hint: Note that ξ⊥⊥XtFt for all t.)
6. For any Markov process X on R+ and time u > 0, show that the
reversed process Yt = Xu−t, t ∈[0, u], is Markov with respect to the induced
ﬁltration. Also show by an example that a possible time homogeneity of X
need not carry over to Y .
7. Let X be a time-homogeneous Markov process in some Borel space
S. Show that there exist some measurable functions fh : S × [0, 1] →S,
h ≥0, and U(0, 1) random variables ϑt,h⊥⊥Xt, t, h ≥0, such that Xt+h =
fh(Xt, ϑt,h) a.s. for all t, h ≥0.
8. Let X be a time-homogeneous and rcll Markov process in some Pol-
ish space S. Show that there exist a measurable function f : S × [0, 1] →
D(R+, S) and some U(0, 1) random variables ϑt⊥⊥Xt such that θtX =
f(Xt, ϑt) a.s. Extend the result to optional times taking countably many
values.
9. Let X be a process on R+ with state space S, and deﬁne Yt = (Xt, t),
t ≥0. Show that X and Y are simultanously Markov, and that Y is then
time-homogeneous. Give a relation between the transition kernels for X and
Y . Express the strong Markov property of Y at a random time τ in terms
of the process X.
10. Let X be a discrete-time Markov process in S with invariant distri-
bution ν. Show for any measurable set B ⊂S that Pν{Xn ∈B i.o.} ≥νB.
Use the result to give an alternative proof of Proposition 7.13. (Hint: Use
Fatou’s lemma.)

7. Markov Processes and Discrete-Time Chains
135
11. Fix an irreducible Markov chain in S with period d. Show that S has
a unique partition into subsets S1, . . . , Sd such that pij = 0 unless i ∈Sk and
j ∈Sk+1 for some k ∈{1, . . . , d}, where the addition is deﬁned modulo d.
12.
Let X be an irreducible Markov chain with period d, and deﬁne
S1, . . . , Sd as above. Show that the restrictions of (Xnd) to S1, . . . , Sd are
irreducible, aperiodic and either all positive recurrent or all null recurrent.
In the former case, show that the original chain has a unique invariant dis-
tribution ν. Further show that (26) holds iﬀµSk = 1/d for all k. (Hint: If
(Xnd) has an invariant distribution νk in Sk, then νk+1
j
=
	
i νk
i pij form an
invariant distribution in Sk+1.)
13. Given a Markov chain X on S, deﬁne the classes Ci as in Lemma 7.17.
Show that if j ∈Ci but i ̸∈Cj for some i, j ∈S, then i is transient. If instead
i ∈Cj for every j ∈Ci, show that Ci is irreducible (i.e., the restriction of X
to Ci is an irreducible Markov chain). Further show that the irreducible sets
are disjoint and that every state outside all irreducible sets is transient.
14. For an arbitrary Markov chain, show that (26) holds iﬀ	
j |pn
ij −νj| →
0 for all i.
15. Let X be an irreducible, aperiodic Markov chain in N. Show that X is
transient iﬀXn →∞a.s. under any initial distribution and is null recurrent
iﬀthe same divergence holds in probability but not a.s.
16. For every irreducible, positive recurrent subset Sk ⊂S, there ex-
ists a unique invariant distribution νk restricted to Sk, and every invariant
distribution is a convex combination 	
k ckνk.
17.
Show that a Markov chain on a ﬁnite state space S has at least
one irreducible set and one invariant distribution. (Hint: Starting from any
i0 ∈S, choose i1 ∈Ci0, i2 ∈Ci1, etc. Then

n Cin is irreducible.)
18. Let X and Y be independent Markov processes with transition ker-
nels µs,t and νs,t. Show that (X, Y ) is again Markov with transition kernels
µs,t(x, ·)⊗νs,t(y, ·). (Hint: Compute the ﬁnite-dimensional distributions from
Proposition 7.2, or use Proposition 5.8 with no computations.)
19. Let X and Y be independent, irreducible Markov chains with periods
d1 and d2. Show that Z = (X, Y ) is irreducible iﬀd1 and d2 have greatest
common divisor 1 and that Z then has period d1d2.
20. State and prove a discrete-time version of Theorem 7.23. Further
simplify the continuous-time proof when S is countable.

Chapter 8
Random Walks and Renewal Theory
Recurrence and transience; dependence on dimension; general re-
currence criteria; symmetry and duality; Wiener–Hopf factoriza-
tion; ladder time and height distribution; stationary renewal pro-
cess; renewal theorem
A random walk in Rd is deﬁned as a discrete-time random process (Sn) evolv-
ing by i.i.d. steps ξn = ∆Sn = Sn −Sn−1. For most purposes we may take
S0 = 0, so that Sn = ξ1 + . . . + ξn for all n. Random walks may be regarded
as the simplest of all Markov processes. Indeed, we recall from Chapter 7
that random walks are precisely the discrete-time Markov processes in Rd
that are both space- and time-homogeneous. (In continuous time, a similar
role is played by the so-called L´evy processes, to be studied in Chapter 13.)
Despite their simplicity, random walks exhibit many basic features of Markov
processes in discrete time and hence may serve as a good introduction to the
general subject. We shall further see how random walks enter naturally into
the discussion of certain continuous-time phenomena.
Some basic facts about random walks were obtained in previous chapters.
Thus, some simple zero–one laws were established in Chapter 2, and in Chap-
ters 3 and 4 we proved the ultimate versions of the laws of large numbers and
the central limit theorem, both of which deal with the asymptotic behavior
of n−cSn for suitable constants c > 0. More sophisticated limit theorems of
this type are derived in Chapters 12, 13, and 14 through approximation by
Brownian motion and other L´evy processes.
Random walks in Rd are either recurrent or transient, and our ﬁrst major
task in this chapter is to derive a recurrence criterion in terms of the tran-
sition distribution µ. Next we consider some striking connections between
maximum and return times, anticipating the arcsine laws of Chapters 11,
12, and 13. This is followed by a detailed study of ladder times and heights
for one-dimensional random walks, culminating with the Wiener–Hopf fac-
torization and Baxter’s formula. Finally, we prove a two-sided version of the
renewal theorem, which describes the asymptotic behavior of the occupation
measure and associated intensity for a transient random walk.
In addition to the already mentioned connections to other chapters, we
note the relevance of renewal theory for the study of continuous-time Markov
chains, as considered in Chapter 10. Renewal processes may further be re-
garded as constituting an elementary subclass of the regenerative sets, to be
136

8. Random Walks and Renewal Theory
137
studied in full generality in Chapter 19 in connection with local time and
excursion theory.
To begin our systematic discussion of random walks, assume as before
that Sn = ξ1 + · · · + ξn for all n ∈Z+, where the ξn are i.i.d. random
vectors in Rd. The distribution of (Sn) is then determined by the common
distribution µ = P ◦ξ−1
n
of the increments. By the eﬀective dimension of
(Sn) we mean the dimension of the linear subspace spanned by the support
of µ. For most purposes, we may assume that the eﬀective dimension agrees
with the dimension of the underlying space, since we may otherwise restrict
our attention to a suitable subspace.
The occupation measure of (Sn) is deﬁned as the random measure
ηB =

n≥01{Sn ∈B},
B ∈Bd.
We also need to consider the corresponding intensity measure
(Eη)B = E(ηB) =

n≥0P{Sn ∈B},
B ∈Bd.
Writing Bε
x = {y; |x −y| < ε}, we may introduce the accessible set A, the
mean recurrence set M, and the recurrence set R, respectively given by
A
=

ε>0{x ∈Rd; EηBε
x > 0},
M
=

ε>0{x ∈Rd; EηBε
x = ∞},
R
=

ε>0{x ∈Rd; ηBε
x = ∞a.s.}.
The following result gives the basic dichotomy for random walks in Rd.
Theorem 8.1 (recurrence dichotomy) Let (Sn) be a random walk in Rd,
and deﬁne A, M, and R as above. Then exactly one of these conditions
holds:
(i) R = M = A, which is then a closed additive subgroup of Rd;
(ii) R = M = ∅, and |Sn| →∞a.s.
A random walk is said to be recurrent if (i) holds and to be transient
otherwise.
Proof: Since trivially R ⊂M ⊂A, the relations in (i) and (ii) are
equivalent to A ⊂R and M = ∅, respectively. Further note that A is a
closed additive semigroup.
First assume P{|Sn| →∞} < 1, so that P{|Sn| < r i.o.} > 0 for some
r > 0. Fix any ε > 0, cover the r-ball around 0 by ﬁnitely many open balls
B1, . . . , Bn of radius ε/2, and note that P{Sn ∈Bk i.o.} > 0 for at least one
k. By the Hewitt–Savage 0–1 law, the latter probability equals 1. Thus, the
optional time τ = inf{n ≥0; Sn ∈Bk} is a.s. ﬁnite, and the strong Markov
property at τ yields
1 = P{Sn ∈Bk i.o.} ≤P{|Sτ+n −Sτ| < ε i.o.} = P{|Sn| < ε i.o.}.

138
Foundations of Modern Pobability
Hence, 0 ∈R in this case
To extend the latter relation to A ⊂R, ﬁx any x ∈A and ε > 0. By the
strong Markov property at σ = inf{n ≥0; |Sn −x| < ε/2},
P{|Sn −x| < ε i.o.}
≥
P{σ < ∞, |Sσ+n −Sσ| < ε/2 i.o.}
=
P{σ < ∞}P{|Sn| < ε/2 i.o.} > 0,
and by the Hewitt–Savage 0–1 law the probability on the left equals 1. Thus,
x ∈R. The asserted group property will follow if we can prove that even
−x ∈A. This is clear if we write
P{|Sn + x| < ε i.o.}
=
P{|Sσ+n −Sσ + x| < ε i.o.}
≥
P{|Sn| < ε/2 i.o.} = 1.
Next assume that |Sn| →∞a.s. Fix any m, k ∈N, and conclude from
the Markov property at m that
P{|Sm| < r, infn≥k|Sm+n| ≥r}
≥
P{|Sm| < r, infn≥k|Sm+n −Sm| ≥2r}
=
P{|Sm| < r} P{infn≥k|Sn| ≥2r}.
Here the event on the left can occur for at most k diﬀerent values of m, and
therefore
P{infn≥k|Sn| ≥2r}

mP{|Sm| < r} < ∞,
k ∈N.
As k →∞the probability on the left tends to one. Hence, the sum converges,
and we get EηB < ∞for any bounded set B. This shows that M = ∅.
✷
The next result gives some easily veriﬁed recurrence criteria.
Theorem 8.2 (recurrence for d = 1, 2) A random walk (Sn) in Rd is re-
current under each of these conditions:
(i) d = 1 and n−1Sn
P→0;
(ii) d = 2, Eξ1 = 0, and E|ξ1|2 < ∞.
In (i) we recognize the weak law of large numbers, which is characterized
in Theorem 4.16.
In particular, the condition is fulﬁlled when Eξ1 = 0.
By contrast, Eξ1 ∈(0, ∞] implies Sn →∞a.s. by the strong law of large
numbers, so in that case (Sn) is transient.
Our proof of Theorem 8.2 is based on the following scaling relation. As
before, a <
⌢b means that a ≤cb for some constant c > 0.
Lemma 8.3 (scaling) For any random walk (Sn) in Rd,

n≥0P{|Sn| ≤rε} <
⌢rd 
n≥0P{|Sn| ≤ε},
r ≥1, ε > 0.

8. Random Walks and Renewal Theory
139
Proof: Cover the ball {x; |x| ≤rε} by balls B1, . . . , Bm of radius ε/2, and
note that we can make m <
⌢rd. Introduce the optional times τk = inf{n; Sn ∈
Bk}, k = 1, . . . , m, and conclude from the strong Markov property that

nP{|Sn| ≤rε}
≤

k

nP{Sn ∈Bk}
≤

k

nP{|Sτk+n −Sτk| ≤ε; τk < ∞}
=

kP{τk < ∞}

nP{|Sn| ≤ε}
<
⌢
rd 
nP{|Sn| ≤ε}.
✷
Proof of Theorem 8.2 (Chung and Ornstein): (i) Fix any ε > 0 and r ≥1,
and conclude from Lemma 8.3 that

n
P{|Sn| ≤ε} >
⌢r−1 
n
P{|Sn| ≤rε} =

 ∞
0
P{|S[rt]| ≤rε}dt.
Here the integrand on the right tends to 1 as r →∞, so the integral tends
to ∞by Fatou’s lemma, and the recurrence of (Sn) follows by Theorem 8.1.
(ii) We may assume that (Sn) is two-dimensional, since the one-dimen-
sional case is already covered by part (i). By the central limit theorem we
have n−1/2Sn
d→ζ, where the random vector ζ has a nondegenerate normal
distribution. In particular, P{|ζ| ≤c} >
⌢c2 for bounded c > 0. Now ﬁx any
ε > 0 and r ≥1, and conclude from Lemma 8.3 that

n
P{|Sn| ≤ε} >
⌢r−2 
n
P{|Sn| ≤rε} =

 ∞
0
P{|S[r2t]| ≤rε}dt.
As r →∞, we get by Fatou’s lemma

n
P{|Sn| ≤ε} >
⌢

 ∞
0
P{|ζ| ≤εt−1/2}dt >
⌢ε2

 ∞
1
t−1dt = ∞,
and the recurrence follows again by Theorem 8.1.
✷
We shall next derive a general recurrence criterion, stated in terms of the
characteristic function ˆµ of µ. Write Bε = {x ∈Rd; |x| < ε}.
Theorem 8.4 (recurrence criterion, Chung and Fuchs) Let (Sn) be a ran-
dom walk in Rd based on some distribution µ, and ﬁx any ε > 0. Then (Sn)
is recurrent iﬀ
sup
0<r<1

Bε
ℜ
1
1 −rˆµt
dt = ∞.
(1)
The proof is based on an elementary identity.
Lemma 8.5 (Parseval)
Let µ and ν be probability measures on Rd with
characteristic functions ˆµ and ˆν. Then
 ˆµdν =
 ˆνdµ.

140
Foundations of Modern Pobability
Proof: Use Fubini’s theorem.
✷
Proof of Theorem 8.4: The function f(s) = (1 −|s|)+ has Fourier trans-
form ˆf(t) = 2t−2(1−cos t), so the tensor product f ⊗d(s) =

k≤d f(sk) on Rd
has Fourier transform ˆf ⊗d(t) =

k≤d ˆf(tk). Writing µ∗n = P ◦S−1
n , we get
by Lemma 8.5 for any a > 0 and n ∈Z+

ˆf ⊗d(x/a)µ∗n(dx) = ad

f ⊗d(at)ˆµn
t dt.
By Fubini’s theorem, it follows that, for any r ∈(0, 1),

ˆf ⊗d(x/a)

n≥0
rnµ∗n(dx) = ad

 f ⊗d(at)
1 −rˆµt
dt.
(2)
Now assume that (1) is false. Taking δ = ε−1d1/2, we get by (2)

nP{|Sn| < δ}
=

nµ∗n(Bδ) <
⌢

ˆf ⊗d(x/δ)

nµ∗n(dx)
=
δd sup
r<1

 f ⊗d(δt)
1 −rˆµt
dt <
⌢ε−d sup
r<1

Bε
dt
1 −rˆµt
< ∞,
and so (Sn) is transient by Theorem 8.1.
To prove the converse, we note that ˆf ⊗d has Fourier transform (2π)df ⊗d.
Hence, (2) remains true with f and ˆf interchanged, apart from a factor (2π)d
on the left. If (Sn) is transient, then for any ε > 0 with δ = ε−1d1/2 we get
sup
r<1

Bε
dt
1 −rˆµt
<
⌢
sup
r<1

ˆf ⊗d(t/ε)
1 −rˆµt
dt
<
⌢
εd

f ⊗d(εx)

nµ∗n(dx)
≤
εd 
nµ∗n(Bδ) < ∞.
✷
In particular, we note that if µ is symmetric in the sense that ξ1
d= −ξ1,
then ˆµ is real valued and the last criterion reduces to

Bε
dt
1 −ˆµt
= ∞.
By a symmetrization of (Sn) we mean a random walk ˜Sn = Sn −S′
n, n ≥0,
where (S′
n) is an independent copy of (Sn). The following result relates the
recurrence behavior of (Sn) and ( ˜Sn).
Corollary 8.6 (symmetrization) If a random walk (Sn) is recurrent, then
so is the symmetrized version ( ˜Sn).

8. Random Walks and Renewal Theory
141
Proof: Noting that (ℜz)(ℜz−1) ≤1 for any complex number z ̸= 0, we
get
ℜ
1
1 −rˆµ2 ≤
1
1 −rℜˆµ2 ≤
1
1 −r|ˆµ|2.
Thus, if ( ˜Sn) is transient, then so is the random walk (S2n) by Theorem 8.4.
But then |S2n| →∞a.s. by Theorem 8.1, and so |S2n+1| →∞a.s. By com-
bination, |Sn| →∞a.s., which means that (Sn) is transient.
✷
The following suﬃcient conditions for recurrence or transience are often
more convenient for applications.
Corollary 8.7 (suﬃcient conditions) Fix any ε > 0. Then (Sn) is recurrent
if

Bε
ℜ
1
1 −ˆµt
dt = ∞
(3)
and transient if

Bε
dt
1 −ℜˆµt
< ∞.
(4)
Proof: First assume (3). By Fatou’s lemma, we get for any sequence
rn ↑1
lim inf
n→∞

Bε
ℜ
1
1 −rnˆµ ≥

Bε
lim
n→∞ℜ
1
1 −rnˆµ =

Bε
ℜ
1
1 −ˆµ = ∞.
Thus, (1) holds, and (Sn) is recurrent.
Now assume (4) instead. Decreasing ε if necessary, we may further assume
that ℜˆµ ≥0 on Bε. As before, we get

Bε
ℜ
1
1 −rˆµ ≤

Bε
1
1 −rℜˆµ ≤

Bε
1
1 −ℜˆµ < ∞,
and so (1) fails. Thus, (Sn) is transient.
✷
The last result enables us to supplement Theorem 8.2 with some conclu-
sive information for d ≥3.
Theorem 8.8 (transience for d ≥3) Any random walk of eﬀective dimen-
sion d ≥3 is transient.
Proof: We may assume that the symmetrized distribution is again d-
dimensional, since µ is otherwise supported by some hyperplane outside the
origin, and the transience follows by the strong law of large numbers. By
Corollary 8.6, it is enough to prove that the symmetrized random walk ( ˜Sn)
is transient, and so we may assume that µ is symmetric. Considering the
conditional distributions on Br and Bc
r for large enough r > 0, we may
write µ as a convex combination cµ1 + (1 −c)µ2, where µ1 is symmetric and

142
Foundations of Modern Pobability
d-dimensional with bounded support.
Letting (rij) denote the covariance
matrix of µ1, we get as in Lemma 4.10
ˆµ1(t) = 1 −1
2

i,jrijtitj + o(|t|2),
t →0.
Since the matrix (rij) is positive deﬁnite, it follows that 1 −ˆµ1(t) >
⌢|t|2 for
small enough |t|, say for t ∈Bε. A similar relation then holds for ˆµ, so

Bε
dt
1 −ˆµt
<
⌢

Bε
dt
|t|2 <
⌢

 ε
0 rd−3dr < ∞.
Thus, (Sn) is transient by Theorem 8.4.
✷
We turn to a more detailed study of the one-dimensional random walk
Sn = ξ1 + · · · + ξn, n ∈Z+. Say that (Sn) is simple if |ξ1| = 1 a.s. For a
simple, symmetric random walk (Sn) we note that
un ≡P{S2n = 0} = 2−2n

2n
n

,
n ∈Z+.
(5)
The following result gives a surprising connection between the probabilities
un and the distribution of last return to the origin.
Proposition 8.9 (last return, Feller) Let (Sn) be a simple, symmetric ran-
dom walk in Z, put σn = max{k ≤n; S2k = 0}, and deﬁne un by (5). Then
P{σn = k} = ukun−k,
0 ≤k ≤n.
Our proof will be based on a simple symmetry property, which will also
appear in a continuous-time version as Lemma 11.14.
Lemma 8.10 (reﬂection principle, Andr´e) For any symmetric random walk
(Sn) and optional time τ, we have ( ˜Sn) d= (Sn), where
˜Sn = Sn∧τ −(Sn −Sn∧τ),
n ≥0.
Proof: We may clearly assume that τ < ∞a.s. Writing S′
n = Sτ+n −Sτ,
n ∈Z+, we get by the strong Markov property S
d= S′⊥⊥(Sτ, τ), and by
symmetry −S
d= S. Hence, by combination (−S′, Sτ, τ)
d= (S′, Sτ, τ), and
the assertion follows by suitable assembly.
✷
Proof of Proposition 8.9: By the Markov property at time 2k, we get
P{σn = k} = P{S2k = 0}P{σn−k = 0},
0 ≤k ≤n,
which reduces the proof to the case when k = 0. Thus, it remains to show
that
P{S2 ̸= 0, . . . , S2n ̸= 0} = P{S2n = 0},
n ∈N.

8. Random Walks and Renewal Theory
143
By the Markov property at time 1, the left-hand side equals
1
2P{mink<2nSk = 0} + 1
2P{maxk<2nSk = 0} = P{M2n−1 = 0},
where Mn = maxk≤n Sk. Using Lemma 8.10 with τ = inf{k; Sk = 1}, we get
1 −P{M2n−1 = 0} = P{M2n−1 ≥1}
=
P{M2n−1 ≥1, S2n−1 ≥1} + P{M2n−1 ≥1, S2n−1 ≤0}
=
P{S2n−1 ≥1} + P{S2n−1 ≥2}
=
1 −P{S2n−1 = 1} = 1 −P{S2n = 0}.
✷
We shall now prove an even more striking connection between the maxi-
mum of a symmetric random walk and the last return probabilities in Propo-
sition 8.9. Related results for Brownian motion and more general random
walks will appear in Theorems 11.16 and 12.11.
Theorem 8.11 (ﬁrst maximum, Sparre-Andersen) Let (Sn) be a random
walk based on a symmetric, diﬀuse distribution, put Mn = maxk≤n Sk, and
write τn = min{k ≥0; Sk = Mn}. Deﬁne σn as in Proposition 8.9 in terms
of a simple, symmetric random walk. Then τn
d= σn for every n ≥0.
Here and below, we shall use the relation
(S1, . . . , Sn) d= (Sn −Sn−1, . . . , Sn −S0),
n ∈N,
(6)
valid for any random walk (Sn). The formula is obvious from the fact that
(ξ1, . . . , ξn) d= (ξn, . . . , ξ1).
Proof of Theorem 8.11: By the symmetry of (Sn) together with (6), we
have
vk ≡P{τk = 0} = P{τk = k},
k ≥0.
(7)
Using the Markov property at time k, we hence obtain
P{τn = k} = P{τk = k}P{τn−k = 0} = vkvn−k,
0 ≤k ≤n.
(8)
Clearly σ0 = τ0 = 0. Proceeding by induction, assume that σk
d= τk and
hence uk = vk for all k < n. Comparing (8) with Proposition 8.9, we obtain
P{σn = k} = P{τn = k} for 0 < k < n, and by (7) the equality extends to
k = 0 and n. Thus, σn
d= τn.
✷
For a general one-dimensional random walk (Sn), we may introduce the
ascending ladder times τ1, τ2, . . . , given recursively by
τn = inf{k > τn−1; Sk > Sτn−1},
n ∈N,
(9)

144
Foundations of Modern Pobability
starting with τ0 = 0. The associated ascending ladder heights are deﬁned as
the random variables Sτn, n ∈N, where S∞may be interpreted as ∞. In a
similar way, we may deﬁne the descending ladder times τ −
n and heights Sτ −
n ,
n ∈N. The times τn and τ −
n are clearly optional, so the strong Markov prop-
erty implies that the pairs (τn, Sτn) and (τ −
n , Sτ −
n ) form possibly terminating
random walks in R
2.
Replacing the relation Sk > Sτn−1 in (9) by Sk ≥Sτn−1, we obtain the weak
ascending ladder times σn and heights Sσn. Similarly, we may introduce the
weak descending ladder times σ−
n and heights Sσ−
n . The mentioned sequences
are connected by a pair of simple but powerful duality relations.
Lemma 8.12 (duality) Let η, η′, ζ, and ζ′ denote the occupation measures
of the sequences (Sτn), (Sσn), (Sn; n < τ −
1 ), and (Sn; n < σ−
1 ), respectively.
Then Eη = Eζ′ and Eη′ = Eζ.
Proof: By (6) we have for any B ∈B(0, ∞) and n ∈N
P{S1 ∧· · · ∧Sn−1 > 0, Sn ∈B}
=
P{S1 ∨· · · ∨Sn−1 < Sn ∈B}
=

kP{τk = n, Sτk ∈B}.
(10)
Summing over n ≥1 gives Eζ′B = EηB, and the ﬁrst assertion follows. The
proof of the second assertion is similar.
✷
The last lemma yields some interesting information. For example, in a
simple symmetric random walk, the expected number of visits to an arbitrary
state k ̸= 0 before the ﬁrst return to 0 is constant and equal to 1.
In
particular, the mean recurrence time is inﬁnite, and so (Sn) is a null recurrent
Markov chain.
The following result shows how the asymptotic behavior of a random walk
is related to the expected values of the ladder times.
Proposition 8.13 (ﬂuctuations and mean ladder times) For any nonde-
generate random walk (Sn) in R, exactly one of these cases occurs:
(i) Sn →∞a.s. and Eτ1 < ∞;
(ii) Sn →−∞a.s. and Eτ −
1 < ∞;
(iii) lim supn(±Sn) = ∞a.s. and Eσ1 = Eσ−
1 = ∞.
Proof: By Corollary 2.17 there are only three possibilities: Sn →∞a.s.,
Sn →−∞a.s., and lim supn(±Sn) = ∞a.s. In the ﬁrst case σ−
n < ∞for
ﬁnitely many n, say for n < κ < ∞. Here κ is geometrically distributed,
and so Eτ1 = Eκ < ∞by Lemma 8.12. The proof in case (ii) is similar.
In case (iii) the variables τn and τ −
n are all ﬁnite, and Lemma 8.12 yields
Eσ1 = Eσ−
1 = ∞.
✷
Next we shall see how the asymptotic behavior of a random walk is related
to the expected values of ξ1 and Sτ1.
Here we deﬁne Eξ = Eξ+ −Eξ−
whenever Eξ+ ∧Eξ−< ∞.

8. Random Walks and Renewal Theory
145
Proposition 8.14 (ﬂuctuations and mean ladder heights) If (Sn) is a non-
degenerate random walk in R, then
(i) Eξ1 = 0 implies lim supn(±Sn) = ∞a.s.;
(ii) Eξ1 ∈(0, ∞] implies Sn →∞a.s. and ESτ1 = Eτ1Eξ1;
(iii) Eξ+
1 = Eξ−
1 = ∞implies ESτ1 = −ESτ −
1 = ∞.
The ﬁrst assertion is an immediate consequence of Theorem 8.2 (i). It
can also be obtained more directly, as follows.
Proof: (i) By symmetry, we may assume that lim supn Sn = ∞a.s. If
Eτ1 < ∞, then the law of large numbers applies to each of the three ratios
in the equation
Sτn
τn
τn
n = Sτn
n ,
n ∈N,
and we get 0 = Eξ1Eτ1 = ESτ1 > 0. The contradiction shows that Eτ1 = ∞,
and so lim infn Sn = −∞by Proposition 8.13.
(ii) In this case Sn →∞a.s. by the law of large numbers, and the formula
ESτ1 = Eτ1 Eξ1 follows as before.
(iii) This is clear from the relations Sτ1 ≥ξ+
1 and Sτ −
1 ≤−ξ−
1 .
✷
We shall now derive a celebrated factorization, which can be used to ob-
tain more detailed information about the distributions of ladder times and
heights. Here we shall write χ± for the possibly defective distributions of
the pairs (τ1, Sτ1) and (τ −
1 , Sτ −
1 ), respectively, and let ψ± denote the corre-
sponding distributions of (σ1, Sσ1) and (σ−
1 , Sσ−
1 ). Put χ±
n = χ±({n} × ·) and
ψ±
n = ψ±({n} × ·). Let us further introduce the measure χ0 on N, given by
χ0
n
=
P{S1 ∧· · · ∧Sn−1 > 0 = Sn}
=
P{S1 ∨· · · ∨Sn−1 < 0 = Sn},
n ∈N,
where the second equality holds by (6).
Theorem 8.15 (Wiener–Hopf factorization) For random walks in R based
on a distribution µ, we have
δ0 −δ1 ⊗µ
=
(δ0 −χ+) ∗(δ0 −ψ−) = (δ0 −ψ+) ∗(δ0 −χ−),
(11)
δ0 −ψ±
=
(δ0 −χ±) ∗(δ0 −χ0).
(12)
Note that the convolutions in (11) are deﬁned on the space Z+ × R,
whereas those in (12) can be regarded as deﬁned on Z+. Alternatively, we
may consider χ0 as a measure on N × {0}, and interpret all convolutions as
deﬁned on Z+ × R.

146
Foundations of Modern Pobability
Proof: Deﬁne the measures ρ1, ρ2, . . . on (0, ∞) by
ρnB
=
P{S1 ∧· · · ∧Sn−1 > 0, Sn ∈B}
=
E

k1{τk = n, Sτk ∈B},
n ∈N, B ∈B(0, ∞),
(13)
where the second equality holds by (10). Put ρ0 = δ0, and regard the sequence
ρ = (ρn) as a measure on Z+ × (0, ∞).
Noting that the corresponding
measures on R equal ρn + ψ−
n and using the Markov property at time n −1,
we get
ρn + ψ−
n = ρn−1 ∗µ = (ρ ∗(δ1 ⊗µ))n,
n ∈N.
(14)
Applying the strong Markov property at τ1 to the second expression in (13),
it is further seen that
ρn =
n

k=1
χ+
k ∗ρn−k = (χ+ ∗ρ)n,
n ∈N.
(15)
Recalling the values at zero, we get from (14) and (15)
ρ + ψ−= δ0 + ρ ∗(δ1 ⊗µ),
ρ = δ0 + χ+ ∗ρ.
Eliminating ρ between the two equations, we obtain the ﬁrst relation in (11),
and the second one follows by symmetry.
To prove (12), we note that the restriction of ψ+ to (0, ∞) equals ψ+
n −χ0
n.
Thus, for B ∈B(0, ∞),
(χ+
n −ψ+
n + χ0
n)B = P{maxk<nSk = 0, Sn ∈B}.
Decomposing the event on the right according to the time of ﬁrst return to
0, we get
χ+
n −ψ+
n + χ0
n =
n−1

k=1
χ0
kχ+
n−k = (χ0 ∗χ+)n,
n ∈N,
and so χ+ −ψ+ + χ0 = χ0 ∗χ+, which is equivalent to the “plus” version of
(12). The “minus” version follows by symmetry.
✷
The preceding factorization yields in particular an explicit formula for
the joint distribution of the ﬁrst ladder time and height.
Theorem 8.16 (ladder distributions, Sparre-Andersen, Baxter) If (Sn) is
a random walk in R, then for |s| < 1 and u ≥0,
E sτ1 exp(−uSτ1) = 1 −exp

−
∞

n=1
sn
n E[e−uSn; Sn > 0]

.
(16)
For (σ1, Sσ1) a similar relation holds with Sn > 0 replaced by Sn ≥0.

8. Random Walks and Renewal Theory
147
Proof: Introduce the mixed generating and characteristic functions
ˆχ+
s,t = E sτ1 exp(itSτ1),
ˆψ−
s,t = E sσ−
1 exp(itSσ−
1 ),
and note that the ﬁrst relation in (11) is equivalent to
1 −sˆµt = (1 −ˆχ+
s,t)(1 −ˆψ−
s,t),
|s| < 1, t ∈R.
Taking logarithms and expanding in Taylor series, we obtain

nn−1(sˆµt)n =

nn−1(ˆχ+
s,t)n +

nn−1( ˆψ−
s,t)n.
For ﬁxed s ∈(−1, 1), this equation is of the form ˆν = ˆν+ + ˆν−, where ν and
ν± are bounded signed measures on R, (0, ∞), and (−∞, 0], respectively. By
the uniqueness theorem for characteristic functions we get ν = ν+ + ν−. In
particular, ν+ equals the restriction of ν to (0, ∞). Thus, the corresponding
Laplace transforms agree, and (16) follows by summation of a Taylor series
for the logarithm. A similar argument yields the formula for (σ1, Sσ1).
✷
From the last result we may easily obtain expressions for the probability
that a random walk stays negative or nonpositive and deduce criteria for its
divergence to −∞.
Corollary 8.17 (negativity and divergence to −∞) For any random walk
(Sn) in R, we have
P{τ1 = ∞} = (Eσ−
1 )−1 = exp

−

n≥1n−1P{Sn > 0}

,
(17)
P{σ1 = ∞} = (Eτ −
1 )−1 = exp

−

n≥1n−1P{Sn ≥0}

.
(18)
Furthermore, the following conditions are both equivalent to Sn →−∞a.s.:

n≥1n−1P{Sn > 0} < ∞,

n≥1n−1P{Sn ≥0} < ∞.
Proof: The last expression for P{τ1 = ∞} follows from (16) with u = 0
as we let s →1. Similarly, the formula for P{σ1 = ∞} is obtained from the
version of (16) for the pair (σ1, Sσ1). In particular, P{τ1 = ∞} > 0 iﬀthe
series in (17) converges, and similarly for the condition P{σ1 = ∞} > 0 in
terms of the series in (18). Since both conditions are equivalent to Sn →−∞
a.s., the last assertion follows. Finally, the ﬁrst equalities in (17) and (18) are
obtained most easily from Lemma 8.12 if we note that the number of strict
or weak ladder times τn < ∞or σn < ∞is geometrically distributed.
✷
We turn to a detailed study of the occupation measure η =
	
n≥0 δSn of
a transient random walk on R, based on transition and initial distributions
µ and ν. Recall from Theorem 8.1 that the associated intensity measure
Eη = ν∗	
n µ∗n is locally ﬁnite. By the strong Markov property, the sequence

148
Foundations of Modern Pobability
(Sτ+n −Sτ) has the same distribution for every ﬁnite optional time τ. Thus,
a similar invariance holds for the occupation measure, and the associated
intensities must agree. A renewal is then said to occur at time τ, and the
whole subject is known as renewal theory. In the special case when µ and ν
are supported by R+, we shall refer to η as a renewal process based on µ and
ν, and to Eη as the associated renewal measure. One usually assumes that
ν = δ0; if not, we say that η is delayed.
The occupation measure η is clearly a random measure on R, in the sense
that ηB is a random variable for every bounded Borel set B. From Lemma
10.1 we anticipate the simple fact that the distribution of a random measure
on R+ is determined by the distributions of the integrals ηf =
 fdη for all
f ∈C+
K(R+), the space of continuous functions f : R+ →R+ with bounded
support. For any measure µ on R and constant t ≥0, we may introduce
the shifted measure θtµ on R+, given by (θtµ)B = µ(B + t) for arbitrary
B ∈B(R+). A random measure η on R is said to be stationary on R+ if
θtη d= θ0η.
Given a renewal process η based on some distribution µ, the delayed
process ˜η = δα ∗η is said to be a stationary version of η if ν = P ◦α−1
is chosen such that the random measure ˜η becomes stationary on R+. The
following result shows that such a version exists iﬀµ has ﬁnite mean, in
which case ν is uniquely determined by µ. Write λ for Lebesgue measure on
R+, and recall that δx denotes a unit mass at x.
Proposition 8.18 (stationary renewal process) Let η be a renewal process
based on some distribution µ on R+ with mean c. Then η has a stationary
version ˜η iﬀc ∈(0, ∞). In that case E˜η = c−1λ, and the initial distribution
of ˜η is uniquely given by ν = c−1(δ0 −µ) ∗λ, or
ν[0, t] = c−1

 t
0 µ(s, ∞)ds,
t ≥0.
(19)
Proof: By Fubini’s theorem,
Eη
=
E

nδSn =

nP ◦S−1
n
=

nν ∗µ∗n
=
ν + µ ∗

nν ∗µ∗n = ν + µ ∗Eη,
and so ν = (δ0 −µ) ∗Eη. If η is stationary, then Eη is shift invariant, and
Lemma 1.29 yields Eη = aλ for some constant a > 0. Thus, ν = a(δ0−µ)∗λ,
and (19) holds with c−1 replaced by a. As t →∞, we get 1 = ac by Lemma
2.4. Hence, c ∈(0, ∞) and a = c−1.
Conversely, assume that c ∈(0, ∞), and let ν be given by (19). Then
Eη
=
ν ∗

nµ∗n = c−1(δ0 −µ) ∗λ ∗

nµ∗n
=
c−1λ ∗

n≥0µ∗n −

n≥1µ∗n
= c−1λ.

8. Random Walks and Renewal Theory
149
By the strong Markov property, the shifted random measure θtη is again a
renewal process based on µ, say with initial distribution νt. As before,
νt = (δ0 −µ) ∗(θtEη) = (δ0 −µ) ∗Eη = ν,
which implies the asserted stationarity of η.
✷
From the last result we may deduce a corresponding statement for the
occupation measure of a general random walk.
Proposition 8.19 (stationary occupation measure) Let η be the occupation
measure of a random walk in R based on distributions µ and ν, where µ has
mean c ∈(0, ∞), and ν is deﬁned as in (19) in terms of the ladder height
distribution ˜µ and its mean ˜c. Then η is stationary on R+ with intensity c−1.
Proof: Since Sn →∞a.s., Propositions 8.13 and 8.14 show that the
ladder times τn and heights Hn = Sτn have ﬁnite mean, and by Proposition
8.18 the renewal process ζ = 	
n δHn is stationary for the prescribed choice
of ν.
Fixing t ≥0 and putting σt = inf{n ∈Z+; Sn ≥t}, we note in
particular that Sσt −t has distribution ν. By the strong Markov property at
σt, the sequence Sσt+n −t, n ∈Z+, has then the same distribution as (Sn).
Since Sk < t for k < σt, we get θtη
d= η on R+, which proves the asserted
stationarity.
To identify the intensity, let ηn denote the occupation measure of the
sequence Sk −Hn, τn ≤k < τn+1, and note that Hn⊥⊥ηn
d= η0 for each n, by
the strong Markov property. Hence, by Fubini’s theorem,
Eη = E

n
ηn ∗δHn =

n
E(δHn ∗Eηn) = Eη0 ∗E

n
δHn = Eη0 ∗Eζ.
Noting that Eζ = ˜c−1λ by Proposition 8.18, that Eη0(0, ∞) = 0, and that
˜c = cEτ1 by Proposition 8.14, we get on R+
Eη = Eη0R−
˜c
λ = Eτ1
˜c
λ = c−1λ.
✷
The next result describes the asymptotic behavior of the occupation mea-
sure η and its intensity Eη. Under weak restrictions on µ, we shall see how
θtη approaches the corresponding stationary version ˜η, whereas Eη is asymp-
totically proportional to Lebesgue measure. For simplicity, we assume that
the mean of µ exists in R. Thus, if ξ is a random variable with distribution
µ, we assume that E(ξ+ ∧ξ−) < ∞and deﬁne Eξ = Eξ+ −Eξ−.
It is natural to state the result in terms of vague convergence for measures
on R+, and the corresponding notion of distributional convergence for ran-
dom measures. Recall that, for locally ﬁnite measures ν, ν1, ν2, . . . on R+, the
vague convergence νn
v→ν means that νnf →νf for all f ∈C+
K(R+). Simi-
larly, if η, η1, η2, . . . are random measures on R+, we deﬁne the distributional

150
Foundations of Modern Pobability
convergence ηn
d→η by the condition ηnf
d→ηf for every f ∈C+
K(R+). (The
latter notion of convergence will be studied in detail in Chapter 14.) A mea-
sure µ on R is said to be nonarithmetic if the additive subgroup generated
by supp µ is dense in R.
Theorem 8.20 (two-sided renewal theorem, Blackwell, Feller and Orey)
Let η be the occupation measure of a random walk in R based on distributions
µ and ν, where µ is nonarithmetic with mean c ∈R \ {0}. If c ∈(0, ∞),
let ˜η be the stationary version in Proposition 8.19, and otherwise put ˜η = 0.
Then as t →∞,
(i) θtη
d→˜η,
(ii) θtEη
v→E˜η = (c−1 ∨0)λ.
Our proof is based on two lemmas. First we consider the distribution
νt of the ﬁrst nonnegative ladder height for the shifted process (Sn −t).
The key step for c ∈(0, ∞) is to show that νt converges weakly toward
the corresponding distribution ˜ν for the stationary version.
This will be
accomplished by a coupling argument.
Lemma 8.21 (asymptotic delay) If c ∈(0, ∞), then νt
w→˜ν as t →∞.
Proof: Let α and α′ be independent random variables with distributions
ν and ˜ν. Choose some i.i.d. sequences (ξk)⊥⊥(ϑk) independent of α and α′
such that P ◦ξ−1
k
= µ and P{ϑk = ±1} = 1
2. Then
˜Sn = α′ −α −

k≤nϑkξk,
n ∈Z+,
is a random walk based on a nonarithmetic distribution with mean 0, and so
by Theorems 8.1 and 8.2 the set { ˜Sn} is a.s. dense in R. For any ε > 0, the
optional time σ = inf{n ≥0; ˜Sn ∈[0, ε]} is then a.s. ﬁnite.
Now deﬁne ϑ′
k = (−1)1{k≤σ}ϑk, k ∈N, and note as in Lemma 8.10 that
{α′, (ξk, ϑ′
k)}
d= {α′, (ξk, ϑk)}. Let κ1 < κ2 < · · · be the values of k with
ϑk = 1, and deﬁne κ′
1 < κ′
2 < · · · similarly in terms of (ϑ′
k). By a simple
conditioning argument, the sequences
Sn = α +

j≤nξκj,
S′
n = α′ +

j≤nξκ′
j,
n ∈Z+,
are random walks based on µ and the initial distributions ν and ˜ν, respec-
tively. Writing σ± =
	
k≤σ 1{ϑk = ±1}, we note that
S′
σ−+n −Sσ++n = ˜Sσ ∈[0, ε],
n ∈Z+.
Putting γ = S∗
σ+ ∨S′∗
σ−, and considering the ﬁrst entry of (Sn) and (S′
n) into
the interval [t, ∞), we obtain
˜ν[ε, x] −P{γ ≥t} ≤νt[0, x] ≤˜ν[0, x + ε] + P{γ ≥t}.

8. Random Walks and Renewal Theory
151
Letting t →∞and then ε →0, and noting that ˜ν{0} = 0 by stationarity,
we get νt[0, x] →˜ν[0, x].
✷
The following simple statement will be needed to deduce (ii) from (i) in
the main theorem.
Lemma 8.22 (uniform integrability) Let η be the occupation measure of a
transient random walk (Sn) in Rd with arbitrary initial distribution, and ﬁx
any bounded set B ∈Bd. Then the random variables η(B + x), x ∈Rd, are
uniformly integrable.
Proof: Fix any x ∈Rd, and put τ = inf{t ≥0; Sn ∈B + x}. Letting η0
denote the occupation measure of an independent random walk starting at
0, we get by the strong Markov property
η(B + x) d= η0(B + x −Sτ)1{τ < ∞} ≤η0(B −B).
In remains to note that Eη0(B −B) < ∞by Theorem 8.1, since (Sn) is
transient.
✷
Proof of Theorem 8.20 (c < ∞): By Lemma 8.22 it is enough to prove
(i). If c < 0, then Sn →−∞a.s. by the law of large numbers, so θtη = 0
for suﬃciently large t, and (i) follows. If instead c ∈(0, ∞), then νt
w→˜ν
by Lemma 8.21, and we may choose some random variables αt and α with
distributions νt and ν, respectively, such that αt →α a.s. We may further
introduce the occupation measure η0 of an independent random walk starting
at 0.
Now ﬁx any f ∈C+
K(R+), and extend f to R by putting f(x) = 0 for
x < 0. Since ˜ν ≪λ we have η0{−α} = 0 a.s., and so by the strong Markov
property and dominated convergence
(θtη)f
d=

f(αt + x)η0(dx) →

f(α + x)η0(dx) d= ˜ηf.
(c = ∞): In this case it is clearly enough to prove (ii). Then note that
Eη = ν ∗Eχ ∗Eζ, where χ is the occupation measure of the ladder height
sequence of (Sn −S0), and ζ is the occupation measure of the same process
prior to the ﬁrst ladder time. Here EζR−< ∞by Proposition 8.13, so by
dominated convergence it suﬃces to show that θtEχ
v→0. Since the mean of
the ladder height distribution is again inﬁnite by Proposition 8.14, we may
henceforth take ν = δ0 and let µ be an arbitrary distribution on R+ with
inﬁnite mean.
Put I = [0, 1], and note that Eη(I + t) is bounded by Lemma 8.22.
Deﬁne b = lim supt Eη(I + t), and choose a sequence tk →∞with Eη(I +
tk) →b. Here we may subtract the ﬁnite measures µ∗j for j < m to get
(µ∗m ∗Eη)(I + tk) →b for all m ∈Z+. By the reverse Fatou lemma, we

152
Foundations of Modern Pobability
obtain for any B ∈B(R+)
lim inf
k→∞Eη(I −B + tk)µ∗mB
≥
lim inf
k→∞

B Eη(I −x + tk)µ∗m(dx)
=
b −lim sup
k→∞

Bc Eη(I −x + tk)µ∗m(dx)
≥
b −

Bc lim sup
k→∞Eη(I −x + tk)µ∗m(dx) ≥bµ∗mB.
(20)
Now ﬁx any h > 0 with µ(0, h] > 0. Noting that Eη[r, r+h] > 0 for all r ≥0
and writing J = [0, a] with a = h + 1, we get by (20)
lim inf
k→∞Eη(J + tk −r) ≥b,
r ≥a.
(21)
Next conclude from the identity δ0 = (δ0 −µ) ∗Eη that
1 =

 tk
0
µ(tk −x, ∞)Eη(dx) ≥

n≥1
µ(na, ∞)Eη(J + tk −na).
As k →∞we get by (21) and Fatou’s lemma 1 ≥b
	
k≥1 µ(na, ∞), and since
the sum diverges by Lemma 2.4, it follows that b = 0.
✷
We shall use the preceding theory to study the renewal equation F =
f + F ∗µ, which often arises in applications. Here the convolution F ∗µ is
deﬁned by
(F ∗µ)t =

 t
0 F(t −s)µ(ds),
t ≥0,
whenever the integrals on the right exist. Under suitable regularity condi-
tions, the renewal equation has the unique solution F = f∗¯µ, where ¯µ denotes
the renewal measure 	
n≥0 µ∗n. Additional conditions ensure the solution F
to converge at ∞.
A precise statement requires some further terminology. By a regular step
function we shall mean a function on R+ of the form
ft =

j≥1aj1[j−1,j)(t/h),
t ≥0,
(22)
where h > 0 and a1, a2, . . . ∈R. A measurable function f on R+ is said to
be directly Riemann integrable if λ|f| < ∞and there exist some regular step
functions f ±
n with f −
n ≤f ≤f +
n and λ(f +
n −f −
n ) →0.
Corollary 8.23 (renewal equation) Fix a distribution µ ̸= δ0 on R+ with
associated renewal measure ¯µ, and let f be a locally bounded and measurable
function on R+. Then the equation F = f + F ∗µ has the unique, locally
bounded solution F = f ∗¯µ. If f is also directly Riemann integrable and if µ
is nonarithmetic with mean c, then Ft →c−1λf as t →∞.

8. Random Walks and Renewal Theory
153
Proof: Iterating the renewal equation, we get
F =

k<nf ∗µ∗k + F ∗µn,
n ∈N.
(23)
The law of large numbers yields µ∗n[0, t] →0 as n →∞for ﬁxed t ≥0, so
for locally bounded F we get F ∗µ∗n →0. If even f is locally bounded, then
by (23) and Fubini’s theorem
F =

k≥0f ∗µ∗k = f ∗

k≥0µ∗k = f ∗¯µ.
Conversely, f +f ∗¯µ∗µ = f ∗¯µ, which shows that F = f ∗¯µ solves the given
equation.
Now let µ be nonarithmetic. If f is a regular step function as in (22),
then by Theorem 8.20 and dominated convergence we get as t →∞
Ft
=

 t
0 f(t −s)¯µ(ds) =

j≥1aj ¯µ((0, h] + t −jh)
→
c−1h

j≥1aj = c−1λf.
In the general case, we may introduce some regular step functions f ±
n with
f −
n ≤f ≤f +
n and λ(f +
n −f −
n ) →0, and note that
(f −
n ∗¯µ)t ≤Ft ≤(f +
n ∗¯µ)t,
t ≥0, n ∈N.
Letting t →∞and then n →∞, we obtain Ft →c−1λf.
✷
Exercises
1. Show that if (Sn) is recurrent, then so is the random walk (Snk) for
each k ∈N. (Hint: If (Snk) is transient, then so is (Snk+j) for any j > 0.)
2. For any nondegenerate random walk (Sn) in Rd, show that |Sn|
P→∞.
(Hint: Use Lemma 4.1.)
3. Let (Sn) be a random walk in R based on a symmetric, nondegenerate
distribution with bounded support. Show that (Sn) is recurrent, using the
fact that lim supn(±Sn) = ∞a.s.
4. Show that the accessible set A equals the closed semigroup generated
by supp µ. Also show by examples that A may or may not be a group.
5. Let ν be an invariant measure on the accessible set of a recurrent
random walk in Rd. Show by examples that Eη may or may not be of the
form ∞· ν.
6. Show that a nondegenerate random walk in Rd has no invariant dis-
tribution. (Hint: If ν is invariant, then µ ∗ν = ν.)
7. Show by examples that the conditions in Theorem 8.2 are not neces-
sary. (Hint: For d = 2, consider mixtures of N(0, σ2) and use Lemma 4.18.)

154
Foundations of Modern Pobability
8. Consider a random walk (Sn) based on the symmetric p-stable distri-
bution on R with characteristic function e−|t|p. Show that (Sn) is recurrent
for p ≥1 and transient for p < 1.
9. Let (Sn) be a random walk in R2 based on the distribution µ2, where
µ is symmetric p-stable. Show that (Sn) is recurrent for p = 2 and transient
for p < 2.
10. Let µ = cµ1 + (1 −c)µ2, where µ1 and µ2 are symmetric distributions
on Rd and c is a constant in (0, 1). Show that a random walk based on µ is
recurrent iﬀrecurrence holds for the random walks based on µ1 and µ2.
11. Let µ = µ1 ∗µ2, where µ1 and µ2 are symmetric distributions on Rd.
Show that if a random walk based on µ is recurrent, then so are the random
walks based on µ1 and µ2. Also show by an example that the converse is
false. (Hint: For the latter part, let µ1 and µ2 be supported by orthogonal
subspaces.)
12.
For any symmetric, recurrent random walk on Zd, show that the
expected number of visits to an accessible state k ̸= 0 before return to the
origin equals 1. (Hint: Compute the distribution, assuming probability p for
return before visit to k.)
13. Use Proposition 8.13 to show that any nondegenerate random walk in
Zd has inﬁnite mean recurrence time. Compare with the preceding problem.
14. Show how part (i) of Proposition 8.14 can be strengthened by means
of Theorems 4.16 and 8.2.
15. For a nondegenerate random walk in R, show that lim supn Sn = ∞
a.s. iﬀσ1 < ∞a.s. and that Sn →∞a.s. iﬀEσ1 < ∞. In both conditions,
note that σ1 can be replaced by τ1.
16. Let η be a renewal process based on some nonarithmetic distribution
on R+. Show for any ε > 0 that sup{t > 0; Eη[t, t + ε] = 0} < ∞. (Hint:
Imitate the proof of Proposition 7.14.)
17. Let µ be a distribution on Z+ such that the group generated by supp µ
equals Z. Show that Proposition 8.18 remains true with ν{n} = c−1µ(n, ∞),
n ≥0, and prove a corresponding version of Proposition 8.19.
18. Let η be the occupation measure of a random walk on Z based on
some distribution µ with mean c ∈R \ {0} such that the group generated by
supp µ equals Z. Show as in Theorem 8.20 that Eη{n} →c−1 ∨0.
19. Derive the renewal theorem for random walks on Z+ from the ergodic
theorem for discrete-time Markov chains, and conversely. (Hint: Given a
distribution µ on N, construct a Markov chain X on Z+ with Xn+1 = Xn +1
or 0, and such that the recurrence times at 0 are i.i.d. µ. Note that X is
aperiodic iﬀZ is the smallest group containing supp µ.)
20. Fix a distribution µ on R with symmetrization ˜µ. Note that if ˜µ is
nonarithmetic, then so is µ. Show by an example that the converse is false.

8. Random Walks and Renewal Theory
155
21. Simplify the proof of Lemma 8.21, in the case when even the sym-
metrization ˜µ is nonarithmetic. (Hint: Let ξ1, ξ2, . . . and ξ′
1, ξ′
2, . . . be i.i.d.
µ, and deﬁne ˜Sn = α′ −α +
	
k≤n(ξ′
k −ξk).)
22. Show that any monotone and Lebesgue integrable function on R+ is
directly Riemann integrable.
23.
State and prove the counterpart of Corollary 8.23 for arithmetic
distributions.
24. Let (ξn) and (ηn) be independent i.i.d. sequences with distributions µ
and ν, put Sn =
	
k≤n(ξk + ηk), and deﬁne U =

n≥0[Sn, Sn + ξn+1). Show
that Ft = P{t ∈U} satisﬁes the renewal equation F = f + F ∗µ ∗ν with
ft = µ(t, ∞). Assuming µ and ν to have ﬁnite means, show also that Ft
converges as t →∞, and identify the limit.
25. Consider a renewal process η based on some nonarithmetic distribution
µ with mean c < ∞, ﬁx an h > 0, and deﬁne Ft = P{η[t, t + h] = 0}. Show
that F = f + F ∗µ, where ft = µ(t + h, ∞). Also show that Ft converges as
t →∞, and identify the limit. (Hint: Consider the ﬁrst point of η in (0, t),
if any.)
26. For η as above, let τ = inf{t ≥0; η[t, t + h] = 0}, and put Ft =
P{τ ≤t}. Show that Ft = µ(h, ∞) +
 h∧t
0
µ(ds)Ft−s, or F = f + F ∗µh,
where µh = 1[0,h] · µ and f ≡µ(h, ∞).

Chapter 9
Stationary Processes and
Ergodic Theory
Stationarity, invariance, and ergodicity; mean and a.s. ergodic
theorem; continuous time and higher dimensions; ergodic decom-
position; subadditive ergodic theorem; products of random matri-
ces; exchangeable sequences and processes; predictable sampling
A random process in discrete or continuous time is said to be stationary if its
distribution is invariant under shifts. Stationary processes are important in
their own right; they may also arise under broad conditions as steady-state
limits of various Markov and renewal-type processes, as we already saw in
Chapters 7 and 8 and will see again in Chapters 10 and 20. The aim of this
chapter is to present some of the most useful general results for stationary
and related processes.
The most fundamental result for stationary random sequences is the mean
and a.s. ergodic theorem, a powerful extension of the law of large numbers.
Here the limit is generally a random variable, measurable with respect to the
so-called invariant σ-ﬁeld. Of special interest is the ergodic case, when the
invariant σ-ﬁeld is trivial and the time average reduces to a constant. For
more general sequences, the distribution admits a decomposition into ergodic
components, obtainable through conditioning with respect to the invariant
σ-ﬁeld.
We will consider several extensions of the basic ergodic theorem, including
versions in continuous time and in higher dimensions. Additionally, we shall
prove a version of the powerful subadditive ergodic theorem and discuss an
important application to random matrices.
Just as the elementary Markov property may be extended to a strong
version, it is useful to strengthen the condition of stationarity by requiring
invariance in distribution under arbitrary optional shifts. This leads to the
notions of exchangeable sequences and to processes with exchangeable incre-
ments. The fairly elementary mean ergodic theorem yields an easy proof of
de Finetti’s theorem, the fact that exchangeable sequences are conditionally
i.i.d. In the other direction, we shall establish the striking and useful pre-
dictable sampling theorem, which in turn will lead to simple proofs of the
arcsine laws in Chapters 11, 12, and 13.
The material in this chapter is related in many ways to other parts of
the book.
Apart from the already mentioned connections, there are also
156

9. Stationary Processes and Ergodic Theory
157
links to the ratio ergodic theorem for diﬀusions in Chapter 20 as well as
to various applications and extensions in Chapters 10, 11, and 14 of results
for exchangeable sequences and processes. Furthermore, there is a relation
between the predictable sampling theorem here and some results on random
time-change appearing in Chapters 16 and 22.
We now return to the basic notions of stationarity and invariance. A
measurable transformation T on some measure space (S, S, µ) is said to be
measure-preserving or µ-preserving if µ ◦T −1 = µ. Thus, if ξ is a random
element of S with distribution µ, then T is measure-preserving iﬀTξ ≡
T ◦ξ d= ξ. In particular, consider a random sequence ξ = (ξ0, ξ1, . . .) in some
measurable space (S′, S′), and let θ denote the shift on S = (S′)∞given by
θ(x0, x1, . . .) = (x1, x2, . . .). Then ξ is said to be stationary if θξ
d= ξ. The
following result shows that the general situation is equivalent to this special
case.
Lemma 9.1 (stationarity and invariance) Let ξ be a random element in
some measurable space S, and let T be a measurable transformation on
S. Then Tξ
d= ξ iﬀthe sequence (T nξ) is stationary, in which case even
(f ◦T nξ) is stationary for any measurable function f. Conversely, any sta-
tionary sequence of random elements admits such a representation.
Proof: Assuming Tξ d= ξ, we get
θ(f ◦T nξ) = (f ◦T n+1ξ) = (f ◦T nTξ) d= (f ◦T nξ),
and so (f ◦T nξ) is stationary. Conversely, assume that η = (η0, η1, . . .) is
stationary. Then ηn = π0(θnη), where π0(x0, x1, . . .) = x0, and we note that
θη d= η by the stationarity of η.
✷
In particular, we note that if ξ0, ξ1, . . . is a stationary sequence of random
elements in some measurable space S, and if f is a measurable mapping of
S∞into some measurable space S′, then the random sequence
ηn = f(ξn, ξn+1, . . .),
n ∈Z+,
is again stationary.
The deﬁnition of stationarity extends in the obvious way to random se-
quences indexed by Z. The two-sided case is often more convenient because
of the group structure of the associated family of shifts. The next result
shows that the two cases are essentially equivalent. Recall our convention
from Chapter 5 about the existence of randomization variables.
Lemma 9.2 (two-sided extension)
Let ξ0, ξ1, . . . be a stationary sequence
of random elements in some Borel space S. Then there exist some random
elements ξ−1, ξ−2, . . . in S such that the extended sequence . . . , ξ−1, ξ0, ξ1, . . .
is stationary.

158
Foundations of Modern Probability
Proof:
Using some i.i.d. U(0, 1) random variables ϑ1, ϑ2, . . . indepen-
dent of ξ = (ξ0, ξ1, . . .), we may construct the ξ−n recursively such that
(ξ−n, ξ−n+1, . . .)
d= ξ for all n. In fact, assume that the required elements
ξ−1, . . . , ξ−n have already been constructed as functions of ξ, ϑ1, . . . , ϑn. Then
(ξ−n, ξ−n+1, . . .)
d= θξ, so even ξ−n−1 exists by Theorem 5.10. Finally, note
that the extended sequence is stationary by Proposition 2.2.
✷
Now ﬁx a measurable transformation T on some measure space (S, S, µ),
and let Sµ denote the µ-completion of S. A set I ⊂S is said to be invariant
if T −1I = I and almost invariant if T −1I = I a.e. µ, in the sense that
µ(T −1I∆I) = 0. Since inverse mappings preserve the basic set operations, it
is clear that the classes I and I′ of invariant sets in S and almost invariant
sets in the completion Sµ form σ-ﬁelds in S, the so-called invariant and
almost invariant σ-ﬁelds, respectively.
A measurable function f on S is said to be invariant if f ◦T ≡f and
almost invariant if f ◦T = f a.e. µ. The following result gives the basic
relationship between invariant or almost invariant sets and functions.
Lemma 9.3 (invariant sets and functions) Fix a measurable transforma-
tion T on some measure space (S, S, µ), and let f be a measurable mapping
of S into some Borel space S′. Then f is invariant or almost invariant iﬀit
is I-measurable or I′-measurable, respectively.
Proof: First apply a Borel isomorphism to reduce to the case when S′ = R.
If f is invariant or almost invariant, then so is the set Ix = f −1(−∞, x) for
any x ∈R, and so Ix ∈I or I′, respectively. Conversely, if f is measurable
w.r.t. I or I′, then Ix ∈I or I′, respectively, for every x ∈R. Hence, the
function fn(s) = 2−n[2nf(s)], s ∈S, is invariant or almost invariant for ev-
ery n ∈N, and the invariance or almost invariance clearly carries over to the
limit f.
✷
The next result shows how the invariant and almost invariant σ-ﬁelds
are related. Here we write Iµ for the µ-completion of I in Sµ, the σ-ﬁeld
generated by I and the µ-null sets in Sµ.
Lemma 9.4 (almost invariance) Let I and I′ be the invariant and almost
invariant σ-ﬁelds associated with a measure-preserving mapping T on some
probability space (S, S, µ). Then I′ = Iµ.
Proof: If J ∈Iµ, there exists some I ∈I with µ(I∆J) = 0. Since T is
µ-preserving, we get
µ(T −1J∆J)
≤
µ(T −1J∆T −1I) + µ(T −1I∆I) + µ(I∆J)
=
µ ◦T −1(J∆I) = µ(J∆I) = 0,
which shows that J ∈I′. Conversely, given any J ∈I′, we may choose some
J′ ∈S with µ(J∆J′) = 0 and put I =

n

k≥n T −nJ′. Then, clearly, I ∈I
and µ(I∆J) = 0, and so J ∈Iµ.
✷

9. Stationary Processes and Ergodic Theory
159
A measure-preserving mapping T on some probability space (S, S, µ) is
said to be ergodic w.r.t. µ, or µ-ergodic if the invariant σ-ﬁeld I is µ-trivial, in
the sense that µI = 0 or 1 for every I ∈I. Depending on our viewpoint, we
may prefer to say that µ is ergodic w.r.t. T, or T-ergodic. The terminology
carries over to any random element ξ with distribution µ, which is said to be
ergodic whenever this is true for T or µ. Thus, ξ is ergodic iﬀP{ξ ∈I} = 0
or 1 for any I ∈I, that is, if the σ-ﬁeld Iξ = ξ−1I in Ωis P-trivial. In
particular, a stationary sequence ξ = (ξn) is ergodic if the shift-invariant
σ-ﬁeld is trivial w.r.t. the distribution of ξ.
The next result shows how the ergodicity of a random element ξ is related
to the ergodicity of the generated stationary sequence.
Lemma 9.5 (ergodicity) Consider a random element ξ in S and a mea-
surable transformation T on S with Tξ
d= ξ. Then ξ is T-ergodic iﬀthe
sequence (T nξ) is θ-ergodic, in which case even η = (f ◦T nξ) is θ-ergodic for
any measurable mapping f on S.
Proof: Fix any measurable mapping f : S →S′, and deﬁne F = (f ◦T n;
n ≥0). Then F ◦T = θ ◦F, so if the set I ⊂(S′)∞is θ-invariant, we have
T −1F −1I = F −1θ−1I = F −1I. Thus, F −1I is T-invariant in S. Assuming ξ
to be ergodic, we hence obtain P{η ∈I} = P{ξ ∈F −1I} = 0 or 1, which
shows that even η is ergodic.
Conversely, let the sequence (T nξ) be ergodic, and ﬁx any T-invariant set
I in S. Put F = (T n; n ≥0), and deﬁne A = {s ∈S∞; sn ∈I i.o.}. Then
I = F −1A and A is θ-invariant, so we get P{ξ ∈I} = P{(T nξ) ∈A} = 0 or
1, which shows that even ξ is ergodic.
✷
We proceed to state the fundamental a.s. and mean ergodic theorem for
stationary sequences of random variables. The result may be regarded as an
extension of the law of large numbers.
Theorem 9.6 (ergodic theorem, von Neumann, Birkhoﬀ) Fix a measurable
space S, a measurable transformation T on S with associated invariant σ-
ﬁeld I, and a random element ξ in S with Tξ
d= ξ. Consider a measurable
function f : S →R with f(ξ) ∈Lp for some p ≥1. Then
n−1 
k<n
f(T kξ) →E[f(ξ)|ξ−1I] a.s. and in Lp.
The proof is based on a simple, but clever, estimate.
Lemma 9.7 (maximal ergodic lemma, Hopf) Consider a stationary sequence
of integrable random variables ξ1, ξ2, . . . , and deﬁne Sn = ξ1 +· · ·+ξn. Then
E[ξ1; supn Sn > 0] ≥0.

160
Foundations of Modern Probability
Proof (Garsia): Write S′
n = ξ2 + · · · + ξn+1, and deﬁne
Mn = S0 ∨· · · ∨Sn,
M ′
n = S′
0 ∨· · · ∨S′
n,
n ∈N.
Fixing n ∈N, we get on the set {Mn > 0}
Mn = S1 ∨· · · ∨Sn = ξ1 + M ′
n−1 ≤ξ1 + M ′
n.
On the other hand, Mn ≤M ′
n on {Mn = 0}. Noting that Mn
d= M ′
n by the
assumed stationarity, we obtain
E[ξ1; Mn > 0] ≥E[Mn −M ′
n; Mn > 0] ≥E[Mn −M ′
n] = 0.
Since Mn ↑supn Sn as n ∈N, the assertion now follows by dominated con-
vergence.
✷
Proof of Theorem 9.6 (Yosida and Kakutani): Write η = f(ξ), ηk =
f(T k−1ξ), Sn = η1 + · · · + ηn, and Iξ = ξ−1I. First assume that E[η|Iξ] = 0
a.s. Fix any ε > 0, and deﬁne
A = {lim supn(Sn/n) > ε},
η′
n = (ηn −ε)1A.
Writing S′
n = η′
1 + · · · + η′
n, we note that
{supnS′
n > 0} = {supn(S′
n/n) > 0} = {supn(Sn/n) > ε} ∩A = A.
Now A ∈Iξ, so the sequence (η′
n) is stationary, and Lemma 9.7 yields
0 ≤E[η′
1; supnS′
n > 0] = E[η −ε; A] = E[E[η|Iξ]; A] −εPA = −εPA,
which implies PA = 0.
Thus, lim supn(Sn/n) ≤ε a.s.
Since ε is arbi-
trary, we get lim supn(Sn/n) ≤0 a.s. Applying this result to (−Sn) yields
lim infn(Sn/n) ≥0 a.s., and by combination Sn/n →0 a.s.
If E[η|Iξ] ̸= 0, we may apply the previous result to the sequence ζn =
ηn −E[η|Iξ], which is again stationary, since the second term is an invariant
function of ξ, because of Lemma 9.3.
To prove the Lp-convergence, introduce for ﬁxed r > 0 the random vari-
ables η′ = η1{|η| ≤r} and η′′ = η −η′, and deﬁne η′
n and η′′
n similarly in
terms of ηn. Let S′
n and S′′
n denote the corresponding partial sums. Then
|S′
n/n| ≤r, and so the convergence S′
n/n →E[η′|Iξ] remains valid in Lp.
From Minkowski’s and Jensen’s inequalities it is further seen that
∥n−1S′′
n −E[η′′|Iξ]∥p ≤n−1 
k≤n
∥η′′
k∥p + ∥E[η′′|Iξ]∥p ≤2∥η′′∥p.
Thus,
lim sup
n→∞∥n−1Sn −E[η|Iξ]∥p ≤2∥η′′∥p.
Here the right-hand side tends to zero as r →∞, and the desired conver-
gence follows.
✷

9. Stationary Processes and Ergodic Theory
161
Writing I and T for the shift-invariant and tail σ-ﬁelds, respectively,
in R∞, we note that I ⊂T . Thus, for any sequence of random variables
ξ = (ξ1, ξ2, . . .) we have Iξ = ξ−1I ⊂ξ−1T . By Kolmogorov’s 0–1 law the
latter σ-ﬁeld is trivial when the ξn are independent. If they are even i.i.d.
and integrable, then Theorem 9.6 yields n−1(ξ1 + · · · + ξn) →Eξ1 a.s. and in
L1, in agreement with Theorem 3.23. Hence, the last theorem contains the
strong law of large numbers.
Our next aim is to extend the ergodic theorem to continuous time. We
may then consider a family of transformations Tt on S, t ≥0, satisfying
the semigroup or ﬂow property Ts+t = TsTt. A ﬂow (Tt) on S is said to be
measurable if the mapping (x, t) →Ttx is product measurable from S×R+ to
S. The invariant σ-ﬁeld I now consists of all sets I ∈S such that T −1
t
I = I
for all t. A random element ξ in S is said to be (Tt)-stationary if Ttξ d= ξ for
all t ≥0.
Theorem 9.8 (continuous-time ergodic theorem) Fix a measurable space S,
let (Tt) be a measurable ﬂow on S with invariant σ-ﬁeld I, and let ξ be a (Tt)-
stationary random element in S. Consider a measurable function f : S →R
with f(ξ) ∈Lp for some p ≥1. Then as t →∞,
t−1

 t
0 f(Tsξ)ds →E[f(ξ)|ξ−1I] a.s. and in Lp.
(1)
Proof: We may clearly assume that f ≥0. Writing Xs = f(Tsξ), we get
by Jensen’s inequality and Fubini’s theorem
E
t−1

 t
0 Xsds

p
≤E t−1

 t
0 Xp
sds = t−1

 t
0 EXp
sds = EXp
0 < ∞.
Thus, to see that the time averages in (1) converge a.s. and in Lp, it suﬃces to
apply Theorem 9.6 to the function g(x) =
 1
0 f(Tsx)ds and the shift T = T1.
To identify the limit η, ﬁx any I ∈I, and conclude from the invariance
of I and the stationarity of ξ that
E[f(Tsξ); ξ ∈I] = E[f(Tsξ); Tsξ ∈I] = E[f(ξ); ξ ∈I].
By Fubini’s theorem and the established L1-convergence,
E[X0; ξ ∈I] = E

t−1

 t
0 Xsds; ξ ∈I

→E[η; ξ ∈I].
Thus, E[η|ξ−1I] = E[X0|ξ−1I] a.s., and it remains to show that η is a.s.
ξ−1I-measurable. This is clear since
η = lim
r→∞lim sup
n→∞
n−1

 r+n
r
Xsds a.s.
✷

162
Foundations of Modern Probability
Next we shall see how the Lp-convergence in Theorem 9.6 can be extended
to higher dimensions. As in Lemma 9.1 for d = 1, any stationary array X
indexed by Zd
+ can be written as
Xk1,...,kd = f(T k1
1 · · · T kd
d ξ),
(k1, . . . , kd) ∈Zd
+,
(2)
where ξ is a random element in some measurable space (S, S), and T1, . . . , Td
are commuting measurable transformations on S that preserve the distribu-
tion µ = P ◦ξ−1. The invariant σ-ﬁeld I now consists of all sets in S that
are invariant under T1, . . . , Td.
Theorem 9.9 (multivariate mean ergodic theorem) Let (Xk) be given by (2)
in terms of some random element ξ in S, some commuting, P ◦ξ−1-preserving
transformations T1, . . . , Td on S, and some measurable function f : S →R
with f(ξ) ∈Lp for some p ≥1. Write I for the (T1, . . . , Td)-invariant σ-ﬁeld
in S. Then as n1, . . . , nd →∞,
(n1 · · · nd)−1 
k1<n1
· · ·

kd<nd
Xk1,...,kd →E[f(ξ)|ξ−1I] in Lp.
(3)
Proof: For convenience we may write (3) in the form [n]−1 	
k<n Xk →
E[f(ξ)|ξ−1I], where k = (k1, . . . , kd), n = (n1, . . . , nd), and [n] = n1 · · · nd.
The result will be proved by induction on d. If it holds in dimensions ≤d−1,
then in the d-dimensional case there exist some η0, η1, . . . ∈Lp with
[n′]−1
k′<n′Xj,k′ →ηj in Lp,
j ∈Z+,
(4)
where k′ = (k2, . . . , kd) and n′ = (n2, . . . , nd), and the convergence holds
as n2, . . . , nd →∞. The sequence (ηj) is again stationary, and so the one-
dimensional result yields m−1 	
j<m ηj →η in Lp for some η ∈Lp. Noting
that the rate of convergence in (4) is independent of j, we get by Minkowski’s
inequality, as n1, . . . , nd →∞,
[n]−1
k<nXk −η

p
≤
[n′]−1
k′<n′X0,k′ −η0

p +
n−1
1

j<n1ηj −η

p →0,
We may ﬁnally deduce the a.s. relation η = E[f(ξ)|ξ−1I] in the same way as
for Theorem 9.8.
✷
We turn to another main topic of this chapter, the decomposition of an
invariant distribution into ergodic components. For motivation, consider the
setting of Theorem 9.6 or 9.9, and assume that S is Borel, to ensure the
existence of regular conditional distributions. Writing η = P[ξ ∈·|ξ−1I], we
get
P ◦ξ−1 = E P[ξ ∈·|ξ−1I] = Eη =

m P ◦η−1(dm).
(5)

9. Stationary Processes and Ergodic Theory
163
Furthermore, for any I ∈I we note that ηI = P[ξ ∈I|ξ−1I] = 1{ξ ∈I}
a.s., and so ηI = 0 or 1 a.s. If the exceptional null set can be chosen to be
independent of I, we may conclude that η is a.s. ergodic, and (5) gives the
desired ergodic decomposition of µ = P ◦ξ−1. Though the suggested result
is indeed true, a rigorous proof is surprisingly hard.
Theorem 9.10 (ergodicity via conditioning, Farrell, Varadarajan) Let S,
T1, . . . , Td, ξ, and I be such as in Theorem 9.9, and let S be Borel. Then
the random measure η = P[ξ ∈·|ξ−1I] is a.s. invariant and ergodic under
T1, . . . , Td.
Our proof is based on a lemma involving the empirical distributions ηn =
µn(ξ, ·), where
µn(s, B) = n−d 
k1<n
· · ·

kd<n
1B(T k1
1 · · · T kd
d s),
B ∈S, n ∈N.
Note that ηnB
P→ηB for every B ∈S by Theorem 9.9. A class C ⊂S is
said to be (measure) determining if a probability measure on S is uniquely
determined by its values on C.
Lemma 9.11 (ergodicity via sample means)
Assume for some countable
determining class C ⊂S and subsequence N ′ ⊂N that ηnB →P{ξ ∈B}
a.s. along N ′ for all B ∈C. Then ξ is ergodic.
Proof: By Theorem 9.9 we have P{ξ ∈B} = ηB a.s. for all B ∈C. Since
C is countable and determining, it follows that P ◦ξ−1 = η a.s. Letting I ∈I,
we get a.s.
P{ξ ∈I} = ηI = P[ξ ∈I|ξ−1I] = 1I(ξ) ∈{0, 1}.
Hence, the left-hand side is either 0 or 1, which shows that ξ is ergodic.
✷
Proof of Theorem 9.10: Since S is Borel, we may choose a countable
determining class C ⊂S. For any B ∈C and i ∈{1, . . . , d}, we have a.s.
ηT −1
i
B = P[Tiξ ∈B|Iξ] = P[ξ ∈B|Iξ] = ηB,
where Iξ = ξ−1I. Thus, η is a.s. invariant.
By Theorem 9.9 and Lemma 3.2 together with a diagonal argument, we
may next choose a subsequence N ′ ⊂N such that ηnB →ηB a.s. along N ′
for every B ∈C. Using Theorem 5.4, we get along N ′
1 = P[ηnB →ηB|Iξ] = η{s ∈S; µn(s, B) →ηB} a.s.,
B ∈C.
The asserted a.s. ergodicity of η now follows by Lemma 9.11.
✷

164
Foundations of Modern Probability
As we have seen, (5) gives a decomposition of the invariant distribution
µ = P ◦ξ−1 into ergodic components. The next result shows that the decom-
position is unique; it further characterizes the ergodic measures as extreme
elements in the convex set of invariant measures.
To explain the terminology, recall that a subset M of a linear space is
said to be convex if cm1 + (1 −c)m2 ∈M for all m1, m2 ∈M and c ∈(0, 1).
In that case, we say that an element m ∈M is extreme if any relation
m = cm1+(1−c)m2 with m1, m2, and c as above implies m1 = m2 = m. For
sets of measures µ on some measurable space (S, S), we deﬁne measurability
with respect to the σ-ﬁeld induced by all evaluation maps πB : µ →µB,
B ∈S.
Theorem 9.12 (ergodic decomposition, Krylov and Bogolioubov)
Let T1,
. . . , Td be commuting measurable transformations on some Borel space S.
Then the (T1, . . . , Td)-invariant probability measures on S form a convex set
M whose extreme elements are precisely the ergodic measures in M. More-
over, every measure µ ∈M has a unique representation µ =
 m ν(dm) with
ν restricted to the class of ergodic measures.
Proof: The set M is clearly convex, and Theorem 9.10 shows that every
measure µ ∈M has a representation
 m ν(dm), where ν is restricted to the
class of ergodic measures. To see that ν is unique, introduce a regular version
η = µ[ · |I], and ﬁx a determining class C ⊂S. By Theorem 9.9, there exists
a subsequence N ′ ⊂N such that µnB →ηB a.s. µ along N ′ for all B ∈C.
Thus,
m{s ∈S; µn(s, B) →η(s, B), B ∈C} = 1 a.e. ν,
(6)
again with convergence along N ′. Since ν is restricted to ergodic measures,
(6) remains true with η(s, B) replaced by mB, and since C is determining we
obtain m{s; η(s, ·) = m} = 1 a.e. ν. Hence, for any measurable set A ⊂M,
µ{η ∈A} =

m{η ∈A}ν(dm) =

1A(m)ν(dm) = νA,
which shows that ν = µ ◦η−1.
To prove the equivalence of ergodicity and extremality, ﬁx any measure
µ ∈M with ergodic decomposition
 m ν(dm). First assume that µ is ex-
treme.
If it is not ergodic, then ν is nondegenerate, and we may write
ν = cν1 + (1 −c)ν2 for some ν1⊥ν2 and c ∈(0, 1).
Since µ is extreme,
we get
 m ν1(dm) =
 m ν2(dm), and so ν1 = ν2 by the uniqueness of the
decomposition. The contradiction shows that µ is ergodic.
Next let µ be ergodic, so that ν = δµ, and assume µ = cµ1 + (1 −c)µ2
with µ1, µ2 ∈M and c ∈(0, 1). If µi =
 m νi(dm) for i = 1, 2, then δµ =
cν1 + (1 −c)ν2 by the uniqueness of the decomposition. Hence, ν1 = ν2 = δµ,
and so µ1 = µ2, which shows that µ is extreme.
✷

9. Stationary Processes and Ergodic Theory
165
Our next aim is to prove a subadditive version of Theorem 9.6.
For
motivation and later needs, we begin with a simple result for nonrandom
sequences. A sequence c1, c2, . . . ∈R is said to be subadditive if cm+n ≤cm+cn
for all m, n ∈N.
Lemma 9.13 (subadditive sequences) For any subadditive sequence c1, c2,
. . . ∈R, we have
lim
n→∞
cn
n = inf
n
cn
n ∈[−∞, ∞).
Proof: Iterating the subadditivity relation, we get for any k, n ∈N
cn ≤[n/k]ck + cn−k[n/k] ≤[n/k]ck + c1 ∨· · · ∨ck−1.
Noting that [n/k] ∼n/k as n →∞, we get lim supn→∞(cn/n) ≤ck/k for all
k, and so
inf
n
cn
n ≤lim inf
n→∞
cn
n ≤lim sup
n→∞
cn
n ≤inf
n
cn
n .
✷
We turn to the more general case of two-dimensional arrays cj,k, 0 ≤
j < k, which are said to be subadditive if c0,n ≤c0,m + cm,n for all m < n.
For arrays of the form cj,k = ck−j, the present deﬁnition reduces to the
previous one. Also note that subadditivity holds trivially for arrays of the
form cj,k = aj+1 + · · · + ak.
We shall extend the ergodic theorem to subadditive arrays of random
variables Xj,k, 0 ≤j < k. Recall from Theorem 9.6 that, when Xm,n =
ηj+1+· · ·+ηk for some stationary and integrable sequence of random variables
ηk, then X0,n/n converges a.s. and in L1. A similar result holds for general
subadditive arrays (Xj,k) whenever they are jointly stationary, in the sense
that (Xj+1,k+1)
d= (Xj,k). To allow a wider range of applications, we shall
prove the result under the slightly weaker assumptions
(Xk,2k, X2k,3k, . . .)
d=
(X0,k, Xk,2k, . . .),
k ∈N,
(7)
(Xk,k+1, Xk,k+2, . . .)
d=
(X0,1, X0,2, . . .),
k ∈N.
(8)
For reference, we may restate the subadditivity condition
X0,n ≤X0,m + Xm,n,
0 < m < n.
(9)
Theorem 9.14 (subadditive ergodic theorem, Kingman)
Let (Xm,n) be a
subadditive array of random variables satisfying (7) and (8), put ξn = X0,n,
and assume that Eξ+
1 < ∞. Then ξn/n converges a.s. toward some random
variable ¯ξ in [−∞, ∞) with E ¯ξ = infn(Eξn/n) ≡c. The convergence holds
even in L1 when c > −∞. If the sequences in (7) are ergodic, then ¯ξ is a.s.
a constant.

166
Foundations of Modern Probability
Proof (Liggett): By (8) and (9) we have Eξ+
n ≤nEξ+
1 < ∞. Let us ﬁrst
assume c > −∞, so that the Xm,n are all integrable. Iterating (9) yields
ξn
n ≤n−1
[n/k]

j=1
X(j−1)k,jk + n−1
n

j=k[n/k]+1
Xj−1,j,
n, k ∈N.
(10)
For ﬁxed k the sequence X(j−1)k,jk, j ∈N, is stationary by (7), and so
Theorem 9.6 yields n−1 	
j≤n X(j−1)k,jk →¯ξk a.s. and in L1, where E ¯ξk = Eξk.
Hence, the ﬁrst term in (10) tends a.s. and in L1 toward ¯ξk/k. Similarly,
n−1 	
j≤n Xj−1,j →¯ξ1 a.s. and in L1, so the second term in (10) tends in the
same sense to 0. Thus, the right-hand side tends a.s. and in L1 toward ¯ξk/k,
and since k is arbitrary we get
lim sup
n→∞(ξn/n) ≤inf
n (¯ξn/n) ≡¯ξ < ∞a.s..
(11)
The variables ξ+
n /n are clearly uniformly integrable by Proposition 3.12, and
moreover
E lim sup
n→∞(ξn/n) ≤E ¯ξ ≤inf
n (E ¯ξn/n) = inf
n (Eξn/n) = c.
(12)
To get a lower bound, introduce for each n ∈N a random variable
κn⊥⊥(Xm,n), uniformly distributed over the set {1, . . . , n}, and deﬁne
ξn
k = Xκn,κn+k,
ηn
k = ξκn+k −ξκn+k−1,
k ∈N.
By (8) we have
(ξn
1 , ξn
2 , . . .) d= (ξ1, ξ2, . . .),
n ∈N.
(13)
Moreover, ηn
k ≤Xκn+k−1,κn+k
d= ξ1 by (9) and (8), and so the random
variables (ηn
k)+ are uniformly integrable. On the other hand, the sequence
Eξ1, Eξ2, . . . is subadditive, and so Lemma 9.13 yields as n →∞
Eηn
k = n−1(Eξn+k −Eξk−1) →inf
n (Eξn/n) = c,
k ∈N.
(14)
In particular, supn E|ηn
k| < ∞, and so the sequence η1
k, η2
k, . . . is tight for each
k. By Theorems 3.29, 4.19, and 5.14 there exist some random variables ξ′
k
and ηk such that
(ξn
1 , ξn
2 , . . . ; ηn
1 , ηn
2 , . . .)
d→(ξ′
1, ξ′
2, . . . ; η1, η2, . . .)
(15)
along a subsequence. Here (ξ′
k) d= (ξk) by (13), and by Theorem 5.10 we may
then assume that ξ′
k = ξk for each k.
The sequence η1, η2, . . . is clearly stationary, and by Lemma 3.11 it is also
integrable. Using (9) we get
ηn
1 + · · · + ηn
k = ξκn+k −ξκn ≤Xϑn,ϑn+k = ξn
k ,

9. Stationary Processes and Ergodic Theory
167
and in the limit η1 + · · · + ηk ≤ξk a.s. Hence, Theorem 9.6 yields
ξn/n ≥n−1
k≤nηn →¯η a.s. and in L1
for some ¯η ∈L1. In particular, even the variables ξ−
n /n are uniformly inte-
grable, and hence so are ξn/n. Using Lemma 3.11 and the uniform integra-
bility of the variables (ηn
k)+ together with (12) and (14), we get
c = lim sup
n→∞Eηn
1 ≤Eη1 = E¯η ≤E lim inf
n→∞
ξn
n ≤E lim sup
n→∞
ξn
n ≤E ¯ξ ≤c.
Thus, ξn/n converges a.s., and by (11) the limit equals ¯ξ. By Lemma 3.11
the convergence holds even in L1 and E ¯ξ = c. If the sequences in (7) are
ergodic, then ¯ξn = Eξn a.s. for each n, and so ¯ξ = c a.s.
Now assume instead that c = −∞. Then for each r ∈Z the truncated
array Xm,n ∨r(n −m), 0 ≤m < n, satisﬁes the hypotheses of the theo-
rem with c replaced by cr = infn(Eξr
n/n) ≥r, where ξr
n = ξn ∨rn. Thus,
ξr
n/n = (ξn/n) ∨r converges a.s. toward some random variable ¯ξr with mean
cr, and so ξn/n →infr ¯ξr ≡¯ξ. Finally, E ¯ξ = infr cr = c = −∞by monotone
convergence.
✷
As an application of the last theorem, we may derive a celebrated ergodic
theorem for products of random matrices.
Theorem 9.15 (random matrices, Furstenberg and Kesten) Consider a sta-
tionary sequence of random d × d matrices Xn whose elements are strictly
positive with integrable logarithms. Then there exists some random variable
ξ such that n−1 log(X1 · · · Xn)ij →ξ a.s. and in L1 for all i and j.
Proof: First let i = j = 1, and deﬁne
ξm,n = log(Xm+1 · · · Xn)11,
0 ≤m < n.
The array (−ξm,n) is clearly subadditive and jointly stationary, and moreover
E|ξ0,1| < ∞by hypothesis. Further note that
(X1 · · · Xn)11 ≤dn−1
k≤nmaxi,jXk
ij.
Hence,
ξ0,n −(n −1) log d ≤

k≤n
log max
i,j Xk
ij ≤

k≤n

i,j
log Xk
ij
 ,
and so
n−1Eξ0,n ≤log d +

i,jE
log X1
i,j
 < ∞.
Thus, by Theorem 9.14 and its proof, there exists some invariant random
variable ξ with ξ0,n/n →ξ a.s. and in L1.

168
Foundations of Modern Probability
To extend the convergence to arbitrary i, j ∈{1, . . . , d}, we may write
for any n ∈N
X2
i1(X3 · · · Xn)11Xn+1
1j
≤
(X2 · · · Xn+1)ij
≤
(X1
1iXn+2
j1 )−1(X1 · · · Xn+2)11.
Noting that n−1 log Xn
ij →0 a.s. and in L1 by Theorem 9.6 and using the sta-
tionarity of (Xn) and invariance of ξ, we obtain n−1 log(X2 · · · Xn+1)ij →ξ
a.s. and in L1, and the desired convergence follows by stationarity.
✷
We shall now consider invariance under transformations other than shifts.
A ﬁnite or inﬁnite random sequence ξ = (ξ1, ξ2, . . .) in some measurable space
(S, S) is said to be exchangeable if
(ξk1, ξk2, . . .) d= (ξ1, ξ2, . . .)
(16)
for all ﬁnite permutations k1, k2, . . . of the index set I. For inﬁnite I, we
further say that ξ is spreadable if (16) holds for all subsequences k1 < k2 < · · ·
of N. Finally, given any random probability measure η on S, we say that
ξ is conditionally η-i.i.d. if P[ξ ∈·|η] = η⊗I a.s., where the conditioning is
with respect to the σ-ﬁeld generated by all random variables ηB, B ∈S.
The latter property clearly implies that ξ is exchangeable. Also note that
any inﬁnite exchangeable sequence is trivially spreadable. We shall prove the
remarkable fact that, for inﬁnite sequences, all three properties are in fact
equivalent.
Theorem 9.16 (inﬁnite exchangeable sequences, de Finetti, Ryll-Nardzew-
ski) Let ξ = (ξk) be an inﬁnite random sequence in some Borel space S.
Then ξ is spreadable iﬀP[ξ ∈·|η] = η∞a.s. for some random probability
measure η on S, in which case η is a.s. unique.
Proof: Assume that ξ is spreadable, and let η be a regular version of
P[ξ1 ∈·|ξ−1I]. Fix any bounded measurable functions f1, f2, . . . on S and a
bounded I-measurable function g on S∞. Using the spreadability of ξ, we
get by Lemma 9.3, Theorem 9.6, and dominated convergence
E

k≤nfk(ξk) · g(ξ)
=
E

k<nfk(ξk) · m−1
j≤mfn(ξn+j) · g(ξ)
=
E

k<nfk(ξk) · ηfn · g(ξ).
Since η is ξ−1I-measurable, Lemma 1.13 shows that ηfn = gn(ξ) for some
I-measurable functions gn. We may then proceed by induction to obtain
E

k≤nfk(ξk) · g(ξ) = E

k≤nηfn · g(ξ).
Thus, P[ξ ∈A|ξ−1I] = η∞A a.s. for any measurable cylinder set A = B1 ×
· · ·×Bn×S∞, and the general relation follows by a monotone class argument.
Finally, P[ξ ∈·|η] = η∞a.s., since η is ξ−1I-measurable.

9. Stationary Processes and Ergodic Theory
169
To prove the uniqueness of η, conclude from the law of large numbers and
Theorem 5.4 that
n−1
k≤n1B(ξk) →ηB a.s.,
B ∈S.
✷
The last result shows that any inﬁnite, exchangeable sequence in a Borel
space is mixed i.i.d., in the sense that P ◦ξ−1 = Eη∞for some random prob-
ability measure η. For ﬁnite sequences the statement fails, and we need to
replace the i.i.d. sequences by so-called urn sequences, generated by succes-
sive drawing without replacement from a ﬁnite set.
To make this precise, ﬁx any measurable space S, and consider a measure
of the form µ = 	
k≤n δsk, where s1, . . . , sn ∈S. The associated factorial
measure µ(n) on Sn is deﬁned by
µ(n) =

pδs◦p,
where the summation extends over all permutations p = (p1, . . . , pn) of
1, . . . , n, and we are writing s ◦p = (sp1, . . . , spn).
Note that µ(n) is in-
dependent of the order of s1, . . . , sn and is measurable as a function of µ.
Proposition 9.17 (ﬁnite exchangeable sequences) Let ξ1, . . . , ξn be random
elements in some measurable space, and put ξ = (ξk) and η =
	
k δξk. Then
ξ is exchangeable iﬀP[ξ ∈·|η] = η(n)/n! a.s.
Proof: Since η is invariant under permutations of ξ1, . . . , ξn, we note that
(ξ ◦p, η)
d= (ξ, η) for any permutation p of 1, . . . , n.
Now introduce an
exchangeable random permutation π⊥⊥ξ of 1, . . . , n. Using Fubini’s theorem
twice, we get for any measurable sets A and B in appropriate spaces
P{ξ ∈B, η ∈A}
=
P{ξ ◦π ∈B, η ∈A}
=
E[P[ξ ◦π ∈B|ξ]; η ∈A]
=
E[(n!)−1η(n)B; η ∈A].
✷
Just as for the martingale and Markov properties, even the notions of
exchangeability and spreadability may be related to a ﬁltration F = (Fn).
Thus, a ﬁnite or inﬁnite sequence of random elements ξ = (ξ1, ξ2, . . .) is said
to be F-exchangeable if ξ is F-adapted and such that, for every n ≥0, the
shifted sequence θnξ = (ξn+1, ξn+2, . . .) is conditionally exchangeable, given
Fn. For inﬁnite sequences ξ, the notion of F-spreadability is deﬁned in a
similar way.
(Since those deﬁnitions may be stated without reference to
regular conditional distributions, no restrictions need to be imposed on S.)
When F is the ﬁltration induced by ξ, the stated properties reduce to the
unqualiﬁed versions considered earlier.
An inﬁnite sequence ξ is said to be strongly stationary or F-stationary if
θτξ d= ξ for every ﬁnite optional time τ ≥0. By the prediction sequence of ξ
we mean the set of conditional distributions
πn = P[θnξ ∈·|Fn],
n ∈Z+.
(17)

170
Foundations of Modern Probability
The random probability measures π0, π1, . . . on S are said to form a measure-
valued martingale if (πnB) is a real-valued martingale for every measurable
set B ⊂S.
The next result shows that strong stationarity is equivalent to exchange-
ability and exhibits an interesting connection with martingale theory.
Proposition 9.18 (strong stationarity) Fix a Borel space S, a ﬁltration F
on Z+, and an inﬁnite, F-adapted random sequence ξ in S with prediction
sequence π. Then these conditions are equivalent:
(i) ξ is F-exchangeable;
(ii) ξ is F-spreadable;
(iii) ξ is F-stationary;
(iv) π is a measure-valued F-martingale.
Proof: Conditions (i) and (ii) are equivalent by Theorem 9.16. Assuming
(ii), we get a.s. for any B ∈S∞and n ∈Z+
E[πn+1B|Fn] = P[θn+1ξ ∈B|Fn] = P[θnξ ∈B|Fn] = πnB,
(18)
which proves (iv). Conversely, (ii) is easily obtained by iteration from the
second equality in (18), and so (ii) and (iv) are equivalent.
Next we note that (17) extends by Lemma 5.2 to
πτB = P[θτξ ∈B|Fτ] a.s.,
B ∈S∞,
for any ﬁnite optional time τ. By Lemma 6.13 it follows that (iv) is equivalent
to
P{θτξ ∈B} = EπτB = Eπ0B = P{ξ ∈B},
B ∈S∞,
which in turn is equivalent to (iii).
✷
We shall now see how the property of exchangeability extends to a wide
class of random transformations. For a precise statement, we say that an
integer-valued random variable τ is predictable with respect to a given ﬁltra-
tion F, if the time τ −1 is F-optional.
Theorem 9.19 (predictable sampling)
Let ξ = (ξ1, ξ2, . . .) be a ﬁnite or
inﬁnite F-exchangeable sequence of random elements in some measurable
space S, and let τ1, . . . , τn be a.s. distinct F-predictable times in the index
set of ξ. Then
(ξτ1, . . . , ξτn) d= (ξ1, . . . , ξn).
(19)
Of special interest is the case of optional skipping, when τ1 < τ2 < · · · . If
τk ≡τ + k for some optional time τ < ∞, then (19) reduces to the strong
stationarity in Proposition 9.18. In general, we are requiring neither ξ to be
inﬁnite nor the τk to be increasing.

9. Stationary Processes and Ergodic Theory
171
For both applications and proof, it is useful to introduce the associated
allocation sequence
αj = inf{k; τk = j},
j ∈I,
where I is the index set of ξ. Note that a ﬁnite value of αj gives the po-
sition of j in the permuted sequence (τk). The random times τk are clearly
predictable iﬀthe αj form a predictable sequence in the sense of Chapter 6.
Proof of Theorem 9.19: First let ξ be indexed by I = {1, . . . , n}, so that
(τ1, . . . , τn) and (α1, . . . , αn) are inverse random permutations of I. For each
m ∈{0, . . . , n}, put αm
j = αj for all j ≤m, and deﬁne recursively
αm
j+1 = min(I \ {αm
1 , . . . , αm
j }),
m ≤j ≤n.
Then (αm
1 , . . . , αm
n ) is a predictable and Fm−1-measurable permutation of
1, . . . , n. Since, moreover, αm
j = αm−1
j
= αj whenever j < m, Theorem 5.4
yields for any bounded measurable functions f1, . . . , fn on S
E

jfαm
j (ξj)
=
E E

jfαm
j (ξj)
 Fm−1

=
E

j<mfαm
j (ξj) E

j≥mfαm
j (ξj)
 Fm−1

=
E

j<mfαm−1
j
(ξj) E

j≥mfαm−1
j
(ξj)
 Fm−1

=
E

jfαm−1
j
(ξj).
Summing over m ∈{1, . . . , n} and noting that αn
j = αj and α0
j = j for all j,
we get
E

kfk(ξτk) = E

jfαj(ξj) = E

kfk(ξk),
which extends to (19) by a monotone class argument.
Next assume that I = {1, . . . , m} with m > n. We may then extend the
sequence (τk) to I by recursively deﬁning
τk+1 = min(I \ {τ1, . . . , τk}),
k ≥n,
(20)
so that τ1, . . . , τm form a random permutation of I. Using (20), it is seen by
induction that the times τn+1, . . . , τm are again predictable, so the previous
case applies, and (19) follows.
Finally, assume that I = N.
For each m ∈N we may introduce the
predictable times
τ m
k = τk1{τk ≤m} + (m + k)1{τk > m},
k = 1, . . . , n,
and conclude from (19) in the ﬁnite case that
(ξτ m
1 , . . . , ξτ m
n ) d= (ξ1, . . . , ξn).
(21)

172
Foundations of Modern Probability
As m →∞, we have τ m
k
→τk, and (19) follows from (21) by dominated
convergence.
✷
The last result yields a simple proof of yet another basic property of
random walks in R, a striking relation between the ﬁrst maximum and the
number of positive values. The latter result will in turn lead to simple proofs
of the arcsine laws in Theorems 11.16 and 12.11.
Corollary 9.20 (positivity and ﬁrst maximum, Sparre-Andersen) Let ξ1,
. . . , ξn be exchangeable random variables, and put Sk = ξ1 + · · · + ξk. Then

k≤n1{Sk > 0} d= min{k ≥0; Sk = maxj≤nSj}.
Proof: Put ˜ξk = ξn−k+1 for k = 1, . . . , n, and note that the ˜ξk remain
exchangeable for the ﬁltration Fk = σ{Sn, ˜ξ1, . . . , ˜ξk}, k = 0, . . . , n. Write
˜Sk = ˜ξ1 + · · · + ˜ξk, and introduce the predictable permutation
αk =
k−1

j=0
1{ ˜Sj < Sn} + (n −k + 1)1{ ˜Sk−1 ≥Sn},
k = 1, . . . , n.
Deﬁne ξ′
k =
	
j ˜ξj1{αj = k} for k = 1, . . . , n, and conclude from Theorem
9.19 that (ξ′
k) d= (ξk). Writing S′
k = ξ′
1 + · · · + ξ′
k, we further note that
min{k ≥0; S′
k = maxjS′
j} =
n−1

j=0
1{ ˜Sj < Sn} =
n

k=1
1{Sk > 0}.
✷
Turning to continuous time, we say that a process X on some real interval
has exchangeable or spreadable increments if, for any disjoint subintervals
(s, t] of equal length, the associated increments Xt −Xs are exchangeable
or spreadable, respectively. Let us further say that the increments of X are
conditionally stationary and independent, given some σ-ﬁeld I, if the stated
property holds conditionally for any ﬁnite set of intervals. Finally, say that
X is continuous in probability if Xs
P→Xt as s →t.
The following continuous-time version of Theorem 9.16 characterizes the
exchangeable-increment processes on R+. The much harder ﬁnite-interval
case is not considered until Theorem 14.25.
Theorem 9.21 (exchangeable-increment processes, B¨uhlmann) Let the pro-
cess X on R+ be continuous in probability. Then X has spreadable increments
iﬀthe increments are conditionally stationary and independent, given some
σ-ﬁeld I.
Proof: The suﬃciency is obvious, so it is enough to prove that the stated
condition is necessary.
Thus, assume that X has spreadable increments.
Then the increments ξnk over the dyadic intervals Ink = 2−n(k −1, k] are

9. Stationary Processes and Ergodic Theory
173
spreadable for ﬁxed n, so by Theorem 9.16 they are conditionally ηn-i.i.d.
for some random probability measure ηn on R. Using Corollary 2.12 and the
uniqueness in Theorem 9.16, we obtain
η∗2n−m
n
= ηm a.s.,
m < n.
(22)
Thus, for any m < n, the increments ξmk are conditionally ηm-i.i.d. given ηn.
Since the σ-ﬁelds σ(ηn) are a.s. nondecreasing by (22), Theorem 6.23 shows
that the ξmk remain conditionally ηm-i.i.d. given I ≡σ{η0, η1, . . .}.
Now ﬁx any disjoint intervals I1, . . . , In of equal length with associated
increments ξ1, . . . , ξn. Here we may approximate by disjoint intervals Im
1 , . . . ,
Im
n of equal length with dyadic endpoints. For each m, the associated incre-
ments ξm
k are conditionally i.i.d., given I. Thus, for any bounded, continuous
functions f1, . . . , fn,
E

k≤nfk(ξm
k )
 I

=

k≤nE[fk(ξm
k )|I] =

k≤nE[fk(ξm
1 )|I].
(23)
Since X is continuous in probability, we have ξm
k
P→ξk for each k, so (23)
extends by dominated convergence to the original variables ξk. By suitable
approximation and monotone class arguments, we may ﬁnally extend the re-
lations to any measurable indicator functions fk = 1Bk.
✷
Exercises
1. State and prove continuous-time, two-sided, and higher-dimensional
versions of Lemma 9.1.
2. Consider a stationary random sequence ξ = (ξ1, ξ2, . . .). Show that
the ξn are i.i.d. iﬀξ1⊥⊥(ξ2, ξ2, . . .).
3. Fix a Borel space S, and let X be a stationary array of S-valued
random elements in S, indexed by Nd. Show that there exists a stationary
array Y indexed by Zd such that X = Y a.s. on Nd.
4. Let X be a stationary process on R+ with values in some Borel space
S. Show that there exists a stationary process Y on R with X
d= Y on R+.
Strengthen this to a.s. equality when S is a complete metric space and X is
right-continuous.
5. Consider a two-sided, stationary random sequence ξ with restriction
η to N.
Show that ξ and η are simultaneously ergodic.
(Hint: For any
measurable, invariant set I ∈SZ, there exists some measurable, invariant set
I′ ∈SN with I = SZ−× I′ a.s. P ◦ξ−1.)
6. Establish two-sided and higher-dimensional versions of Lemmas 9.4
and 9.5 as well as of Theorem 9.8.

174
Foundations of Modern Probability
7.
A measure-preserving transformation T on some probability space
(S, S, µ) is said to be mixing if µ(A ∩T −nB) →µA · µB for all A, B ∈S.
Prove the counterpart of Lemma 9.5 for mixing. Also, show that any mixing
transformation is ergodic. (Hint: For the latter assertion, take A = B to be
invariant.)
8. Show that it is enough to verify the mixing property for sets in a
generating π-system. Use this fact to prove that any i.i.d. sequence is mixing
under shifts.
9. Fix any a ∈R, and deﬁne Ts = s + a (mod 1) on [0, 1]. Show that T
fails to be mixing but is ergodic iﬀa ̸∈Q. (Hint: To prove the ergodicity, let
I ⊂[0, 1] be T-invariant. Then so is the measure 1I · λ, and since the points
ka are dense in [0, 1], it follows that 1I ·λ is invariant. Now use Lemma 1.29.)
10. (Bohl, Sierpi´nski, Weyl) For any a ̸∈Q, let µn = n−1 	
k≤n δka, where
ka is deﬁned modulo 1 as a number in [0, 1]. Show that µn
w→λ. (Hint:
Apply Theorem 9.6 to the mapping of the previous exercise.)
11. Prove that the transformation Ts = 2s (mod 1) on [0, 1] is mixing.
Also show how the mapping of Lemma 2.20 can be generated as in Lemma
9.1 by means of T.
12.
Note that Theorem 9.6 remains true for invertible shifts T, with
averages taken over increasing index sets [an, bn] with bn −an →∞. Show
by an example that the a.s. convergence may fail without the assumption of
monotonicity. (Hint: Consider an i.i.d. sequence (ξn) and disjoint intervals
[an, bn], and use the Borel–Cantelli lemma.)
13. Consider a one- or two-sided stationary random sequence (ξn) in some
measurable space (S, S), and ﬁx any B ∈S. Show that a.s. either ξn ∈Bc
for all n or ξn ∈B i.o. (Hint: Use Theorem 9.6.)
14. (von Neumann) Give a direct proof of the L2-version of Theorem 9.6.
(Hint: Deﬁne a unitary operator U on L2(S) by Uf = f ◦T. Let M denote
the U-invariant subspace of L2 and put A = I −U. Check that M ⊥= RA,
the closed range of A. By Theorem 1.34 it is enough to take f ∈M or
f ∈RA.) Deduce the general Lp-version, and extend the argument to higher
dimensions.
15. In the context of Theorem 9.12, show that the ergodic measures form
a measurable subset of M. (Hint: Use Lemma 1.38, Proposition 3.31, and
Theorem 9.9.)
16. Prove a continuous-time version of Theorem 9.12.
17. Deduce Theorem 3.23 for p ≤1 from Theorem 9.14. (Hint: Take
Xm,n = |Sn −Sm|p, and note that E|Sn|p = o(n) when p < 1.)
18. Let ξ = (ξ1, ξ2, . . .) be a stationary sequence of random variables, ﬁx
any B ∈B(Rd), and let κn be the number of indices k ∈{1, . . . , n −d} with
(ξk, . . . , ξd) ∈B. Prove from Theorem 9.14 that κn/n converges a.s. Deduce
the same result from Theorem 9.6, by considering suitable subsequences.

9. Stationary Processes and Ergodic Theory
175
19. Show by an example that a ﬁnite, exchangeable sequence need not be
mixed i.i.d.
20. Let the random sequence ξ be conditionally η-i.i.d. Show that ξ is
ergodic iﬀη is a.s. nonrandom.
21. Let ξ and η be random probability measures on some Borel space such
that Eξ∞= Eη∞. Show that ξ d= η. (Hint: Use the law of large numbers.)
22. Let ξ1, ξ2, . . . be spreadable random elements in some Borel space S.
Prove the existence of a measurable function f : [0, 1]2 →S and some i.i.d.
U(0, 1) random variables ϑ0, ϑ1, . . . such that ξn = f(ϑ0, ϑn) a.s. for all n.
(Hint: Use Lemma 2.22, Proposition 5.13, and Theorems 5.10 and 9.16.)
23. Let ξ = (ξ1, ξ2, . . .) be an F-spreadable random sequence in some
Borel space S. Prove the existence of some random measure η such that, for
each n ∈Z+, the sequence θnξ is conditionally η-i.i.d. given Fn and η.
24. Let ξ1, . . . , ξn be exchangeable random variables, ﬁx a Borel set B, and
let τ1 < · · · < τν be the indices k ∈{1, . . . , n} with
	
j<k ξj ∈B. Construct a
random vector (η1, . . . , ηn) d= (ξ1, . . . , ξn) such that ξτk = ηk a.s. for all k ≤ν.
(Hint: Extend the sequence (τk) to k ∈(ν, n], and apply Theorem 9.19.)
25. Prove a version of Corollary 9.20 for the last maximum.

Chapter 10
Poisson and Pure Jump-Type
Markov Processes
Existence and characterizations of Poisson processes; Cox pro-
cesses, randomization and thinning; one-dimensional uniqueness
criteria; Markov transition and rate kernels; embedded Markov
chains and explosion; compound and pseudo-Poisson processes;
Kolmogorov’s backward equation; ergodic behavior of irreducible
chains
Poisson processes and Brownian motion constitute the basic building blocks
of modern probability theory. Our ﬁrst goal in this chapter is to introduce the
family of Poisson and related processes. In particular, we construct Poisson
processes on bounded sets as mixed sample processes and derive a variety of
Poisson characterizations in terms of independence, symmetry, and renewal
properties. A randomization of the underlying intensity measure leads to the
richer class of Cox processes. We also consider the related randomizations
of general point processes, obtainable through independent motions of the
individual point masses. In particular, we will see how the latter type of
transformations preserve the Poisson property.
It is usually most convenient to regard Poisson and other point processes
on an abstract space as integer-valued random measures. The relevant parts
of this chapter may then serve at the same time as an introduction to random
measure theory.
In particular, Cox processes and randomizations will be
used to derive some general uniqueness criteria for simple point processes
and diﬀuse random measures. The notions and results of this chapter form
a basis for the corresponding weak convergence theory developed in Chapter
14, where Poisson and Cox processes appear as limits in important special
cases.
Our second goal is to continue the theory of Markov processes from Chap-
ter 7 with a detailed study of pure jump-type processes. The evolution of
such a process is governed by a rate kernel α, which determines both the rate
at which transitions occur and the associated transition probabilities. For
bounded α one gets a pseudo-Poisson process, which may be described as a
discrete-time Markov chain with transition times given by an independent,
homogeneous Poisson process. Of special interest is the case of compound
Poisson processes, where the underlying Markov chain is a random walk. In
176

10. Poisson and Pure Jump-Type Markov Processes
177
Chapter 17 we shall see how every Feller process can be approximated in a
natural way by pseudo-Poisson processes, recognized in that context by the
boundedness of their generators. A similar compound Poisson approximation
of general L´evy processes is utilized in Chapter 13.
In addition to the already mentioned connections to other topics, we note
the fundamental role of Poisson processes for the theory of L´evy processes
in Chapter 13 and for excursion theory in Chapter 19. In Chapter 22 the
independent-increment characterization of Poisson processes is extended to a
criterion in terms of compensators, and we derive some related time-change
results. Finally, the ergodic theory for continuous-time Markov chains devel-
oped at the end of this chapter is analogous to the theory for discrete-time
chains in Chapter 7, and also to the relevant results for one-dimensional
diﬀusions obtained in Chapter 20.
To introduce the basic notions of random measure theory, we may ﬁx
a topological space S, which we assume to be locally compact, second-
countable, and Hausdorﬀ(abbreviated as lcscH). We denote the Borel σ-ﬁeld
in S by S. In applications, S is typically an open subset of a Euclidean space
Rd, and on a ﬁrst reading one may assume that S = Rd. Write ˆS for the
ring of relatively compact sets in S. By a random measure on S we mean
a locally ﬁnite kernel ξ from the basic probability space (Ω, A) into (S, S).
Thus, ξ is a mapping from Ω×S to [0, ∞] such that ξ(ω, B) is a locally ﬁnite
measure in B for ﬁxed ω and an [0, ∞]-valued random variable in ω for ﬁxed
B. Here the term locally ﬁnite means that ξ(·, B) < ∞a.s. for all B ∈ˆS.
By Lemma 1.37 it is equivalent to think of ξ as a random element in the
space M(S) of locally ﬁnite measures on S, equipped with the σ-ﬁeld induced
by all evaluation maps πB : µ →µB. For convenience we write ξB = ξ(·, B)
and ξf =
 fdξ =
 f(s)ξ(·, ds). The integral ξf is measurable, hence an
[0, ∞]-valued random variable, for every measurable function f : S →R+. In
particular, we note that ξf < ∞for all f ∈C+
K(S), the space of continuous
functions f : S →R+ with compact support. By monotone convergence, the
intensity Eξ, given by (Eξ)B = E(ξB), is again a measure on S, although
it may not be σ-ﬁnite in general.
The following result provides the basic uniqueness criteria for random
measures. Stronger results are given for simple point processes and diﬀuse
random measures in Theorem 10.9, and related convergence criteria appear
in Theorem 14.16.
Lemma 10.1 (uniqueness of random measures)
Let ξ and η be random
measures on S. Then ξ
d= η iﬀEe−ξf = Ee−ηf for all f ∈C+
K(S) and also
iﬀ
(ξB1, . . . , ξBn) d= (ηB1, . . . , ηBn),
B1, . . . , Bn ∈ˆS, n ∈N.
(1)
Proof: The suﬃciency of (1) is clear from Proposition 2.2. Now assume
that Ee−ξf = Ee−ηf for every f ∈C+
K. Since C+
K is closed under positive

178
Foundations of Modern Probability
linear combinations, Theorem 4.3 yields
(ξf1, . . . , ξfn) d= (ηf1, . . . , ηfn),
f1, . . . , fn ∈C+
K, n ∈N.
By Theorem 1.1 we get P ◦ξ−1 = P ◦η−1 on F ≡σ{πf; f ∈C+
K}, where
πf : µ →µf, and it remains to show that F contains G ≡σ{πB; B ∈ˆS}.
Then ﬁx any compact set B ⊂S, and choose some functions fn ∈C+
K
with fn ↓1B. Then µfn ↓µB for every µ ∈M(S), and so the mapping πB is
F-measurable by Lemma 1.10. Next apply Theorem 1.1 to the Borel subsets
of an arbitrary compact set, to see that πB is F-measurable for any B ∈ˆS.
Hence, G ⊂F.
✷
By a point process on S we mean an integer-valued random measure ξ.
In this case ξB is clearly a Z+-valued random variable for every B ∈ˆS. The
support of ξ is a locally ﬁnite random subset Ξ ⊂S. We say that ξ is simple
if each point of Ξ has mass 1, so that ξB = |Ξ ∩B| for all B ∈S, where |B|
denotes the cardinality of the set B. In general, ξB ≥|Ξ ∩B|, and a simple
approximation shows that ξ∗B = |Ξ ∩B| is measurable and hence a simple
point process on S. Point processes may be regarded as random elements in
the space N(S) ⊂M(S) of locally ﬁnite, integer-valued measures on S.
We shall often use partitions of the sample space S. By a dissecting system
we mean an array of Borel sets Dnj ⊂S that form a nested sequence of ﬁnite
partitions of S, one for each n, and have the following further property. For
any compact set K ⊂S with open cover {Gi}, we assume the existence of
some n such that every set K ∩Dnj is contained in some Gi. To construct a
dissecting system, we may start from any countable base B1, B2, . . . , and let
Dn1, Dn2, . . . be the partition of S induced by the sets B1, . . . , Bn. It is then
easy to verify the dissecting property. For a simple application, note that if
(Dnj) is dissecting and µ ∈N(S), then
	
j{µ(B ∩Dnj)∧1} →µ∗B for every
B ∈S. In particular, this shows that the mapping µ →µ∗is measurable.
A random measure ξ on S is said to have independent increments if
ξB1, . . . , ξBn are independent for any disjoint sets B1, . . . , Bn ∈ˆS, n ∈N.
By a Poisson process on S with intensity measure µ ∈M(S) we mean a
point process ξ on S with independent increments such that ξB is Poisson
distributed with mean µB for every B ∈ˆS. By Lemma 10.1 the stated condi-
tions specify the distribution of ξ, which is then determined by the intensity
measure µ.
Results for Poisson and related processes may often be derived by easy
computations involving Laplace functionals. For this purpose we need the
real version of the following formula; the complex version is not required until
Chapter 13.
Lemma 10.2 (characteristic functional) Let ξ be a Poisson process on S
with intensity µ. Then for any measurable function f : S →R+,
Ee−ξf = exp{−µ(1 −e−f)}.
(2)

10. Poisson and Pure Jump-Type Markov Processes
179
If instead f : S →R is measurable with µ(|f| ∧1) < ∞, then (2) holds with
f replaced by −if.
Proof: If η is a Poisson random variable with mean c, then
Eeaη = e−c
n≥0
(ca)n
n!
= e−c(1−a),
a ∈C.
Thus, for f =
	
k≤m ak1Bk with a1, . . . , am ∈C and disjoint B1, . . . , Bm ∈ˆS,
Ee−ξf
=
E exp

−

kakξBk

=

kEe−akξBk
=

k exp{−µBk(1 −e−ak)}
=
exp

−

kµBk(1 −e−ak)

= e−µ(1−e−f).
For general f ≥0 we may choose some simple functions fn ≥0 with fn ↑f
and conclude by monotone convergence that ξfn →ξf and µ(1 −e−fn) →
µ(1 −e−f). Formula (2) then follows by dominated convergence from the
version for fn.
Next assume that µ(|f|∧1) < ∞. Writing (2) with f replaced by c|f| and
letting c ↓0, we get by dominated convergence P{ξ|f| < ∞} = e0 = 1, and
so ξ|f| < ∞a.s. Next choose some simple functions fn →f with |fn| ≤|f|,
and note that |1 −e−ifn| ≤(|f| ∧2) by Lemma 4.14. By dominated conver-
gence we obtain ξfn →ξf and µ(1 −e−ifn) →µ(1 −e−if). Thus, (2) follows
with f replaced by −if from the version for −ifn.
✷
To prepare for the construction of a general Poisson process, ﬁx an ar-
bitrary probability measure µ on S, and let γ1, γ2, . . . be i.i.d. random ele-
ments in S with distribution µ. A point process with the same distribution
as ξ = 	
k≤n δγk is called a sample process based on µ and n. Note that
ξ = nˆµn, where ˆµn denotes the empirical distribution based on the random
sample γ1, . . . , γn. Next consider a Z+-valued random variable κ⊥⊥(γn) with
distribution ν. A point process distributed as ξ = 	
k≤κ δγk is called a mixed
sample process based on µ and ν.
The following result gives the basic connection between Poisson and mixed
sample processes. Write µ[ · |B] = µ(· ∩B)/µB for µB > 0.
Proposition 10.3 (Poisson and mixed sample processes) Let ξ be a point
process on some σ-ﬁnite measure space (S, S, µ). Then ξ is Poisson with
intensity µ, iﬀfor every B ∈S with µB ∈(0, ∞), the restriction 1B · ξ is a
mixed sample process based on the measure µ[ · |B] and the Poisson distribu-
tion with mean µB.
Proof: Fix any B ∈S with 0 < µB < ∞, and deﬁne η = 	
k≤κ δγk,
where γ1, γ2, . . . are i.i.d. µ[ · |B] and κ is an independent Poisson variable
with mean µB. Then Esκ = e−µB(1−s), and so by Fubini’s theorem
Ee−ηf
=
E exp

−

k≤κf(γk)

= E(Ee−f(γ1))κ = E(µ[e−f|B])κ
=
exp{−µB(1 −µ[e−f|B])} = exp{−µ[1 −e−f; B]}.

180
Foundations of Modern Probability
By Lemmas 10.1 and 10.2 we may conclude that η is Poisson with Eη = 1B·µ,
and the asserted equivalence follows since B is arbitrary.
✷
We may now state the basic existence theorem for Poisson processes. For
this result alone, no regularity conditions are imposed on the space S. Recall
that a measure µ on S is said to be diﬀuse if µ{s} = 0 for all s ∈S.
Proposition 10.4 (Poisson existence and simplicity, Kingman, Mecke) For
any σ-ﬁnite measure space (S, S, µ) there exists a Poisson process ξ on S with
Eξ = µ. When S is Borel, ξ is a.s. simple iﬀµ is diﬀuse.
Proof: We may decompose S into disjoint subsets B1, B2, . . . ∈S with
measures µBn ∈(0, ∞). By Corollary 5.18 there exist some independent
mixed sample processes ξ1, ξ2, . . . on S such that each ξn is based on the
measure µ[ · |Bn] and the Poisson distribution with mean µBn. Then Propo-
sition 10.3 shows that each process ξn is Poisson with Eξn = 1Bn · µ, and so
ξ = 	
n ξn is Poisson with intensity Eξ =
	
n(1Bn · µ) = µ.
To prove the last assertion, it is enough to establish the corresponding
property for mixed sample processes. Then let γ1, γ2, . . . be i.i.d. with distri-
bution µ. By Fubini’s theorem
P{γi = γj} =

µ{s}µ(ds) =

s(µ{s})2,
i ̸= j,
and so the γj are a.s. distinct iﬀµ is diﬀuse.
✷
Now return to the setting of an arbitrary lcscH space S. We shall intro-
duce two basic constructions of point processes from a given random measure
or point process on S. First consider an arbitrary random measure ξ on S.
By a Cox process directed by ξ we mean a point process η on S such that η
is conditionally Poisson, given ξ, with E[η|ξ] = ξ a.s.
We next deﬁne a ν-randomization ζ of an arbitrary point process ξ on
S, where ν is a probability kernel from S to some lcscH space T.
As-
suming ﬁrst that ξ is nonrandom and equal to m = 	
k δsk, we may take
ζ = 	
k δsk,γk, where the γk are independent random elements in T with dis-
tributions ν(sk, ·). Note that the distribution ρm of ζ depends only on m. In
general, we deﬁne a ν-randomization ζ of ξ by the condition P[ζ ∈·|ξ] = ρξ
a.s. In the special case when T = {0, 1} and ν(s, {0}) ≡p ∈[0, 1], we refer
to the point process ξp = ζ(· × {0}) on S as a p-thinning of ξ.
The following result ensures the existence of Cox processes, randomiza-
tions, and thinnings.
Proposition 10.5 (Cox processes and randomizations)
For any random
measure ξ on some lcscH space S, there exists a Cox process η directed by ξ,
deﬁned on a suitable extension of the basic probability space. Similarly, given
any point process ξ on S and probability kernel ν from S to some lcscH space
T, there exists in the same sense some ν-randomization ζ of ξ.

10. Poisson and Pure Jump-Type Markov Processes
181
Proof: Let ρm denote the distribution of a Poisson process with intensity
m ∈M(S). For disjoint sets B1, . . . , Bn ∈ˆS we have
ρm

j≤n
{µBj = kj} =

j≤n
(mBj)kj
kj!
e−mBj,
and so the left-hand side is a measurable function of m. In general, the prob-
ability on the left is a ﬁnite sum of such products, and so the measurability
remains valid. Since the sets on the left form a π-system generating the σ-
ﬁeld in N(S), Lemma 1.37 shows that ρ is a probability kernel from M(S)
to N(S). The existence of η now follows by Lemma 5.9.
In case of randomizations, we may ﬁrst assume that T = [0, 1] and
ν(s, ·) ≡λ.
For each m ∈N(S), let ρm denote the distribution of a λ-
randomization of m. By Lemma 5.9 we need to verify that ρ is a kernel
from N(S) to N(S × T). It is then enough to show that ρm

j≤n{µAj = kj}
is measurable for any measurable rectangles Ak = Bk × Ck ⊂S × [0, 1],
and we may further reduce to the case when B1 = · · · = Bn and the sets
C1, . . . , Cn are disjoint. The stated probability is then given by a multinomial
distribution, and the desired measurability follows.
For general T and ν, Lemma 2.22 provides a measurable function f :
S × [0, 1] →T such that f(s, ϑ) has distribution ν(s, ·) when ϑ is U(0, 1).
Letting η be a λ-randomization of ξ and writing g(s, t) = (s, f(s, t)), we may
deﬁne ζ = η ◦g−1, which is clearly a ν-randomization of ξ.
✷
The following result shows in particular that the Poisson and Cox prop-
erties are preserved under randomizations and thinnings.
Proposition 10.6 (iterated transforms) For any lcscH spaces S, T, and U
and probability kernels µ and ν from S to T and from S×T to U, respectively,
we have the following:
(i) If η is a Cox process directed by some random measure ξ on S and ζ
is a µ-randomization of η with ζ⊥⊥ηξ, then ζ is again Cox and directed
by ξ ⊗µ;
(ii) if η is a µ-randomization of some point process ξ on S and ζ is a
ν-randomization of η, then ζ is a µ ⊗ν-randomization of ξ.
Note that the conditional independence in (i) holds automatically when ζ
is constructed by randomization, as in Lemma 5.9. The result will be proved
by means of Laplace functionals, which requires a simple lemma. Here a
kernel µ is regarded as an operator, given by µf(s) =
 µ(s, dt)f(t). We
shall further write ˆµ(s, ·) = δs ⊗µ(s, ·), so that ν ⊗µ = νˆµ.
Lemma 10.7 (Laplace functionals) Consider a Cox process η directed by
ξ, a µ-randomization ζ of ξ, and a p-thinning ξp of ξ. The corresponding

182
Foundations of Modern Probability
Laplace functionals are related by
ψξ,η(f, g)
=
ψξ(f + 1 −e−g),
(3)
ψζ(f)
=
ψξ(−log ˆµe−f),
(4)
ψξ,ξp(f, g)
=
ψξ(f −log{1 −p(1 −e−g)}).
(5)
A comparison of (3) and (5) suggests that, for small p > 0, a p-thinning
should be nearly Cox. The statement will be made precise in Theorem 14.19.
Proof: To prove (3), we note that by Lemma 10.2
ψξ,η(f, g)
=
Ee−ξf−ηg = Ee−ξfE[e−ηg|ξ]
=
Ee−ξf exp{−ξ(1 −e−g)} = ψξ(f + 1 −e−g).
To prove (4) we may ﬁrst assume that ξ = 	
k δsk is nonrandom. Introducing
random elements τk in T with distributions µ(sk, ·), we get
ψζ(f)
=
Ee−ζf = E exp

−

kf(sk, τk)

=

kEe−f(sk,τk) =

kˆµe−f(sk)
=
exp

k log ˆµe−f(sk) = exp ξ log ˆµe−f.
Hence, in general,
ψζ(f) = E exp ξ log ˆµe−f = ψξ(−log ˆµe−f).
Relation (5) may be either deduced from (4) or derived directly by the same
method.
✷
Proof of Proposition 10.6: To prove (i), we may conclude from Lemma
10.7 and the conditional independence that
ψξˆµ,ζ(f, g)
=
Ee−ξˆµfE[e−ζg|ξ, η] = Ee−ξˆµfeη log ˆµe−g
=
ψξ(ˆµf + 1 −ˆµe−g) = ψξˆµ(f + 1 −e−g).
The result now follows by Lemmas 10.1 and 10.7.
To prove (ii), we may use Lemma 10.7 to obtain
ψζ(f) = ψη(−log ˆνe−f) = ψξ(−log ˆµˆνe−f) = ψξ(−log(µ ⊗ν)ˆe−f).
✷
We now proceed to establish a simple uniqueness property of Cox pro-
cesses and thinnings, which is needed in a subsequent proof.
Lemma 10.8 (uniqueness for Cox processes and thinnings) If η and η′ are
Cox processes directed by ξ and ξ′, respectively, then ξ
d= ξ′ iﬀη
d= η′.
Similarly, if ξp and ξ′
p are p-thinnings of ξ and ξ′, respectively, for some
p ∈(0, 1), then ξ d= ξ′ iﬀξp
d= ξ′
p.

10. Poisson and Pure Jump-Type Markov Processes
183
Proof: Inverting the ﬁrst relation in Lemma 10.7, we get for any bounded
measurable function f : S →R+
ψξ(tf) = ψη(−log(1 −tf)),
t ∈[0, ∥f∥−1),
where ∥f∥= sups fs. Here the left-hand side is analytic in t ∈(0, ∞), and
so ψξ(f) is uniquely determined by ψη. The ﬁrst assertion now follows by
Lemma 10.1. The proof of the second assertion is similar.
✷
We shall use the Cox transformations and thinnings to establish some
general uniqueness criteria for simple point processes and diﬀuse random
measures, improving the elementary statements in Lemma 10.1.
Related
convergence criteria are given in Proposition 14.17 and Theorems 14.27 and
14.28.
Theorem 10.9 (one-dimensional uniqueness criteria)
(i) Let ξ and η be simple point processes on S. Then ξ d= η iﬀP{ξB = 0}
= P{ηB = 0} for all B ∈ˆS.
(ii) Let ξ and η be simple point processes or diﬀuse random measures on
S, and ﬁx any c > 0. Then ξ d= η iﬀEe−cξB = Ee−cηB for all B ∈ˆS.
(iii) Let ξ be a simple point process or diﬀuse random measure on S, and
let η be an arbitrary random measure on S. Then ξ
d= η iﬀξB
d= ηB
for all B ∈ˆS.
Proof: (i) Assume the stated condition. The class C of sets {µ; µB = 0}
with B ∈ˆS is clearly a π-system, and so Theorem 1.1 yields P ◦ξ−1 = P ◦η−1
on σ(C). From the construction of µ∗via dissecting systems, it is further seen
that the mapping µ →µ∗is σ(C)-measurable. Hence, ξ = ξ∗d= η∗= η.
(ii) In the diﬀuse case, let ˜ξ and ˜η be Cox processes directed by cξ and cη,
respectively. By dominated convergence, Lemma 10.7 applies with g = ∞·1B,
and we get
P{˜ξB = 0} = Ee−cξB = Ee−cηB = P{˜ηB = 0},
B ∈ˆS.
Since ˜ξ and ˜η are a.s. simple by Proposition 10.4, part (i) yields ˜ξ
d= ˜η, and
hence ξ d= η by Lemma 10.8. For simple point processes we may use a similar
argument, based on thinnings instead of Cox processes.
(iii) Fix a dissecting system (Dnj). Under the stated condition, we get
in the point process case ηDnj ∈Z+ outside a ﬁxed null set, and it follows
easily that even η is a point process. Then (i) yields ξ d= η∗, so for any B ∈ˆS
we get Ee−ηB = Ee−ξB = Ee−η∗B and therefore ηB = η∗B a.s. Hence, η is
a.s. simple, and so ξ d= η∗= η.
Next assume that ξ is a.s. diﬀuse. Introduce Cox processes ˜ξ and ˜η as
before, and note that ˜ξB
d= ˜ηB for each B ∈ˆS. Since ˜ξ is also a.s. simple

184
Foundations of Modern Probability
by Proposition 10.4, we may conclude as before that ˜ξ d= ˜η. Hence, ξ d= η by
Lemma 10.8.
✷
As a simple consequence, we get the following characterization of Poisson
processes.
Corollary 10.10 (one-dimensional Poisson criterion, R´enyi)
Let ξ be a
random measure on S with ξ{s} = 0 a.s. for all s ∈S. Then ξ is Poisson iﬀ
ξB is Poisson distributed for every B ∈ˆS, in which case µ = Eξ is locally
ﬁnite and diﬀuse.
Proof: The measure µ is locally ﬁnite and diﬀuse, since µB = EξB < ∞
for all B ∈ˆS and µ{s} = Eξ{s} = 0 for all s ∈S. By Proposition 10.4 there
exists some a.s. simple Poisson process η on S with Eη = µ. Since ξB d= ηB
for every B ∈ˆS, we get ξ d= η by Theorem 10.9.
✷
We proceed to extend the basic deﬁnitions to the case of marks. Let us
then ﬁx two lcscH spaces S and K, equipped with their Borel σ-ﬁelds S and
K, respectively. By a K-marked point process on S we mean a point process
ξ on S × K such that ξ({s} × K) ≤1 holds identically for all s ∈S. Note
that the projection ξ(· × K) is not required to be locally ﬁnite.
We say that ξ has independent increments if the point processes ξ(B1 × ·),
. . . , ξ(Bn ×·) on K are independent for any disjoint sets B1, . . . , Bn ∈ˆS. We
further say that ξ is a Poisson process if it is Poisson in the usual sense on the
product space S × K. The following result characterizes Poisson processes
in terms of the independence property. The result plays a crucial role in
Chapters 13 and 19. A related characterization in terms of compensators is
given in Corollary 22.25.
Theorem 10.11 (independence and Poisson property, Erlang, L´evy) Let ξ
be a K-marked point process on S such that ξ({s} × K) = 0 a.s. for all
s ∈S. Then ξ is Poisson iﬀit has independent increments, in which case
Eξ is locally ﬁnite with diﬀuse projections onto S.
The proof will be based on a simple lemma.
Lemma 10.12 (dissection properties) Let ξ be a simple point process on S
with ξ{s} = 0 a.s. for all s ∈S. Fix a set B ∈ˆS and a dissecting system
(Dnj), and deﬁne Bnj = B ∩Dnj. Then
(i) maxj ξBnj ∨1 →1 a.s.;
(ii) maxj P{ξBnj > 0} →0.
Proof: (i) Fix any µ ∈N(S). For each s ∈B we may choose an open set
Gs ∋s with µ∗Gs ≤1. By the dissecting property we may next choose n so
large that each set Bnj lies in some Gs. Then maxj µ∗Bnj ≤1.

10. Poisson and Pure Jump-Type Markov Processes
185
(ii) Fix any ε > 0. For each s ∈B we have P{ξ{s} > 0} = 0, and
by dominated convergence we may then choose an open set Gs ∋s with
P{ξGs > 0} < ε. By the dissecting property we may next choose n so large
that each set Bnj lies in some Gs. Then maxj P{ξBnj > 0} < ε.
✷
Proof of Theorem 10.11: Fix any bounded Borel set B ⊂S ×K, and note
that the projection η = (1B · ξ)(· × K) is a simple point process on S with
independent increments such that η{s} = 0 a.s. for all s ∈S. Now introduce
a dissecting system (Dnj) of S. By Lemma 10.12 the random variables ηDnj
form a null array with maxj ηDnj ∨1 →1 a.s., and so ξB = ηS =
	
j ηDnj
is Poisson by Theorem 4.7. Since B was arbitrary, the whole process ξ is
Poisson by Corollary 10.10.
✷
The last theorem yields in particular a representation of random measures
with independent increments. A version for general processes on R+ will be
proved in Theorem 13.4.
Corollary 10.13 (independent-increment random measures)
A random
measure ξ on S has independent increments and satisﬁes ξ{s} = 0 a.s. for
all s iﬀ
ξB = αB +

 ∞
0
x η(B × dx),
B ∈ˆS,
(6)
for some nonrandom, diﬀuse measure α on S and some Poisson process η
on S × (0, ∞) with η({s} × (0, ∞)) = 0 a.s. for all s ∈S and

 ∞
0 (x ∧1) Eη(B × dx) < ∞,
B ∈ˆS.
(7)
Proof: Deﬁne η = 	
s δs,ξ{s} and note that η may be regarded as a ξ-
measurable point process on S with marks in (0, ∞). Subtracting the atomic
part, we get a diﬀuse random measure α satisfying (6). If ξ has independent
increments and ξ{s} = 0 a.s. for all s, then the corresponding properties hold
for α and η, and so α is nonrandom by Theorem 4.11 whereas η is Poisson by
Theorem 10.11. Furthermore, Lemma 10.2 shows that (7) is necessary and
suﬃcient for the local ﬁniteness of the integral in (6).
✷
The next result gives a related characterization by symmetry. Given a
random measure ξ and a diﬀuse measure µ on S, we say that ξ is µ-symmetric
if ξ ◦f −1 d= ξ for every µ-preserving mapping f on S.
Theorem 10.14 (symmetric and mixed Poisson processes) Fix a diﬀuse,
locally ﬁnite, and unbounded measure µ on S, and let ξ be a simple point
process on S.
Then ξ is µ-symmetric iﬀit is conditionally Poisson with
intensity measure αµ, given some random variable α ≥0.
Proof: First assume that µB = 0 for some B ∈S. Fix any a ∈Bc, and
deﬁne f(x) = x on Bc and f(x) = a on B. Then f is µ-preserving, so we get
ξB d= ξ ◦f −1B = 0, and therefore ξB = 0 a.s.

186
Foundations of Modern Probability
By Theorem A1.6 we may assume that S is a Borel subset of R+. Let
f be µ-preserving on R+, and deﬁne ˜f = f on f −1S and ˜f = a ∈S on
f −1Sc. Since µ ◦f −1Sc = 0, we note that ˜f is µ-preserving on S and that
ξ ◦f −1Sc = 0 a.s. Thus, ξ ◦f −1 = ξ ◦˜f −1 d= ξ, which reduces the discussion
to the case when S = R+.
Next assume that A ∈S with µAc = 0, and let f be µ-preserving on A.
Deﬁne ˜f = f on A and ˜f(x) ≡x on Ac. Then ˜f is µ-preserving on R+, and
so ξ ◦˜f −1 d= ξ, which implies ξ ◦f −1 d= ξ on A. Since, moreover, ξAc = 0 a.s.,
it is equivalent to take S = A. Now deﬁne g(x) = inf{t ≥0; µ[0, t] > x},
and note that g maps bijectively onto the right support A = 
h>0{t ≥0;
µ[t, t + h) > 0} with λ ◦g−1 = µ. Since µAc = 0, we may henceforth assume
that µ = λ.
By Theorem 9.21, the increments of ξ over dyadic intervals are condi-
tionally stationary and independent, given some σ-ﬁeld I. By Theorem 4.7
applied to the conditional distribution of all dyadic increments, the latter
are seen to be conditionally Poisson, and so ξ is conditionally a homoge-
neous Poisson process.
The associated rate α may be constructed as an
I-measurable random variable, using the law of large numbers, and so it is
equivalent to condition on α.
✷
Integrals with respect to Poisson processes occur frequently in applica-
tions. The next result gives criteria for the existence of the integrals ξf,
(ξ −ξ′)f, and (ξ −µ)f, where ξ and ξ′ are independent Poisson processes
with a common intensity measure µ. In each case the integral may be deﬁned
as a limit in probability of elementary integrals ξfn, (ξ −ξ′)fn, or (ξ −µ)fn,
respectively, where the fn are bounded with compact support and such that
|fn| ≤|f| and fn →f. The integral of f is said to exist if the appropriate
limit exists and is independent of the choice of approximating functions fn.
Theorem 10.15 (Poisson integrals) Let ξ and ξ′ be independent Poisson
processes on S with a common σ-ﬁnite intensity measure µ, and ﬁx any
measurable function f on S. Then
(i) ξf exists iﬀµ(|f| ∧1) < ∞;
(ii) (ξ −ξ′)f exists iﬀµ(f 2 ∧1) < ∞;
(iii) (ξ −µ)f exists iﬀµ(f 2 ∧|f|) < ∞.
If one of the conditions fails, then the corresponding set of approximating
elementary integrals is not tight.
Proof: (i) If ξ|f| < ∞a.s., then µ(|f| ∧1) < ∞by Lemma 10.2. The
converse implication was established in the proof of the same lemma.
(ii) First consider a deterministic counting measure ν = 	
k δsk, and deﬁne
˜ν = 	
k ϑkδsk where ϑ1, ϑ2, . . . are i.i.d. random variables with P{ϑk = ±1}
= 1
2. By Theorem 3.17 the series ˜νf converges a.s. iﬀνf 2 < ∞, and otherwise

10. Poisson and Pure Jump-Type Markov Processes
187
|˜νfn|
P→∞for any bounded approximations fn = 1Bnf with Bn ∈ˆS. The re-
sult extends by conditioning to arbitrary point processes ν and their symmet-
ric randomizations ˜ν. Now Proposition 10.6 exhibits ξ −ξ′ as such a random-
ization of the Poisson process ξ + ξ′, and by part (i) we have (ξ + ξ′)f 2 < ∞
a.s. iﬀµ(f 2 ∧1) < ∞.
(iii) Write f = g + h, where g = f1{|f| ≤1} and h = f1{|f| > 1}. First
assume that µg2 +µ|h| = µ(f 2 ∧|f|) < ∞. Since clearly E(ξf −µf)2 = µf 2,
the integral (ξ −µ)g exists. Furthermore, ξh exists by part (i). Hence, even
(ξ −µ)f = (ξ −µ)g + ξh −µh exists.
Conversely, assume that (ξ −µ)f exists. Then so does (ξ −ξ′)f, and by
part (ii) we get µg2 + µ{h ̸= 0} = µ(f 2 ∧1) < ∞. The existence of (ξ −µ)g
now follows by the direct assertion, and trivially even ξh exists. Thus, the
existence of µh = (ξ −µ)g + ξh −(ξ −µ)f follows, and so µ|h| < ∞.
✷
A Poisson process ξ on R+ is said to be time-homogeneous with rate c ≥0
if Eξ = cλ. In that case Proposition 7.5 shows that Nt = ξ[0, t], t ≥0, is
a space- and time-homogeneous Markov process. We shall introduce a more
general class of Markov processes.
A process X in some measurable space (S, S) is said to be of pure jump
type if its paths are a.s. right-continuous and constant apart from isolated
jumps. We denote the jump times of X by τ1, τ2, . . . , with the understanding
that τn = ∞if there are fewer than n jumps. By Lemma 6.3 and a simple
approximation, the times τn are seen to be optional with respect to the right-
continuous ﬁltration F = (Ft) induced by X. For convenience we may choose
X to be the identity mapping on the canonical path space Ω. When X is
Markov, the distribution with initial state x is denoted by Px, and we note
that the mapping x →Px is a kernel from (S, S) to (Ω, F∞).
We begin our study of pure jump-type Markov processes by proving an
extension of the elementary strong Markov property in Proposition 7.9. A
further extension appears as Theorem 17.17.
Theorem 10.16 (strong Markov property, Doob) A pure jump-type Markov
process satisﬁes the strong Markov property at every optional time.
Proof: For any optional time τ, we may choose some optional times σn ≥
τ + 2−n taking countably many values such that σn →τ a.s. By Proposition
7.9 we get, for any A ∈Fτ ∩{τ < ∞} and B ∈F∞,
P[θσnX ∈B; A] = E[PXσnB; A].
(8)
By the right-continuity of X, we have P{Xσn ̸= Xτ} →0. If B depends on
ﬁnitely many coordinates, it is further clear that
P({θσnX ∈B}△{θτX ∈B}) →0,
n →∞.
Hence, (8) remains true for such sets B with σn replaced by τ, and the rela-
tion extends to the general case by a monotone class argument.
✷

188
Foundations of Modern Probability
We shall now see how the homogeneous Poisson processes may be char-
acterized as special renewal processes. Recall that a random variable γ is
said to be exponentially distributed with rate c > 0 if P{γ > t} = e−ct for all
t ≥0. In this case, clearly Eγ = c−1.
Proposition 10.17 (Poisson and renewal processes) Let ξ be a simple point
process on R+ with atoms at τ1 < τ2 < · · · , and put τ0 = 0. Then ξ is
homogeneous Poisson with rate c > 0 iﬀthe diﬀerences τn −τn−1 are i.i.d.
and exponentially distributed with mean c−1.
Proof: First assume that ξ is Poisson with rate c. Then Nt = ξ[0, t] is a
space- and time-homogeneous pure jump-type Markov process. By Lemma
6.6 and Theorem 10.16, the strong Markov property holds at each τn, and
by Theorem 7.10 we get
τ1
d= τn+1 −τn ⊥⊥(τ1, . . . , τn),
n ∈N.
Thus, the variables τn −τn−1 are i.i.d., and it remains to note that
P{τ1 > t} = P{ξ[0, t] = 0} = e−c.
Conversely, assume that τ1, τ2, . . . have the stated properties. Consider a
homogeneous Poisson process η with rate c and with atoms at σ1 < σ2 < · · · ,
and conclude from the necessity part that (σn) d= (τn). Hence,
ξ =

nδτn
d=

nδσn = η.
✷
We proceed to examine the structure of a general pure jump-type Markov
process.
The ﬁrst and crucial step is then to describe the distributions
associated with the ﬁrst jump.
Say that a state x ∈S is absorbing if
Px{X ≡x} = 1, that is, if Px{τ1 = ∞} = 1.
Lemma 10.18 (ﬁrst jump) If x is nonabsorbing, then under Px the time τ1
until the ﬁrst jump is exponentially distributed and independent of θτ1X.
Proof: Put τ1 = τ. Using the Markov property at ﬁxed times, we get for
any s, t ≥0
Px{τ > s + t} = Px{τ > s, τ ◦θs > t} = Px{τ > s}Px{τ > t}.
The only nonincreasing solutions to this Cauchy equation are of the form
Px{τ > t} = e−ct with c ∈[0, ∞]. Since x is nonabsorbing and τ > 0 a.s., we
have c ∈(0, ∞), and so τ is exponentially distributed with parameter c.
By the Markov property at ﬁxed times, we further get for any B ∈F∞
Px{τ > t, θτX ∈B}
=
Px{τ > t, (θτX) ◦θt ∈B}
=
Px{τ > t}Px{θτX ∈B},
which shows that τ⊥⊥θτX.
✷

10. Poisson and Pure Jump-Type Markov Processes
189
Writing X∞= x when X is eventually absorbed at x, we may deﬁne the
rate function c and jump transition kernel µ by
c(x) = (Exτ1)−1,
µ(x, B) = Px{Xτ1 ∈B},
x ∈S, B ∈S.
For convenience we may combine c and µ into a rate kernel α(x, B) =
c(x)µ(x, B) or α = cµ, where the required measurability is clear from that
for the kernel (Px). Conversely, µ may be reconstructed from α if we add
the requirement that µ(x, ·) = δx when α(x, ·) = 0, conforming with our con-
vention for absorbing states. This ensures that µ is a measurable function
of α.
The following theorem gives an explicit representation of the process in
terms of a discrete-time Markov chain and a sequence of exponentially dis-
tributed random variables. The result shows in particular that the distribu-
tions Px are uniquely determined by the rate kernel α. As usual, we assume
the existence of required randomization variables.
Theorem 10.19 (embedded Markov chain) Let X be a pure jump-type Mar-
kov process with rate kernel α = cµ.
Then there exist a Markov process
Y on Z+ with transition kernel µ and an independent sequence of i.i.d.,
exponentially distributed random variables γ1, γ2, . . . with mean 1 such that
a.s.
Xt = Yn for t ∈[τn, τn+1),
n ∈Z+,
(9)
where
τn =
n

k=1
γk
c(Yk−1),
n ∈Z+.
(10)
Proof: To satisfy (9), put τ0 = 0, and deﬁne Yn = Xτn for n ∈Z+. In-
troduce some i.i.d. exponentially distributed random variables γ′
1, γ′
2, . . . ⊥⊥X
with mean 1, and deﬁne for n ∈N
γn = (τn −τn−1)c(Yn)1{τn−1 < ∞} + γ′
n1{c(Yn) = 0}.
By Lemma 10.18, we get for any t ≥0, B ∈S, and x ∈S with c(x) > 0
Px{γ1 > t, Y1 ∈B} = Px{τ1c(x) > t, Y1 ∈B} = e−tµ(x, B),
a result that clearly remains true when c(x) = 0. By the strong Markov
property we obtain for every n, a.s. on {τn < ∞},
Px[γn+1 > t, Yn+1 ∈B|Fτn] = PYn{γ1 > t, Y1 ∈B} = e−tµ(Yn, B).
(11)
The strong Markov property also gives τn+1 < ∞a.s. on the set {τn < ∞,
c(Yn) > 0}. Arguing recursively, we get {c(Yn) = 0} = {τn+1 = ∞} a.s., and
(10) follows. Using the same relation, it is also easy to check that (11) re-
mains a.s. true on {τn = ∞}, and in both cases we may clearly replace Fτn
by Gn = Fτn ∨σ{γ′
1, . . . , γ′
n}. Thus, the pairs (γn, Yn) form a discrete-time

190
Foundations of Modern Probability
Markov process with the desired transition kernel. By Proposition 7.2, the
latter property together with the initial distribution determine uniquely the
joint distribution of Y and (γn).
✷
In applications the rate kernel α is normally given, and it is important to
decide whether a corresponding Markov process X exists. As before we may
write α(x, B) = c(x)µ(x, B) for a suitable choice of rate function c: S →R+
and transition kernel µ on S, where µ(x, ·) = δx when c(x) = 0 and otherwise
µ(x, {x}) = 0. If X does exist, it clearly may be constructed as in Theorem
10.19.
The construction fails when ζ ≡supn τn < ∞, in which case an
explosion is said to occur at time ζ.
Theorem 10.20 (synthesis) Fix a kernel α = cµ on S with α(x, {x}) ≡0,
and consider a Markov chain Y with transition kernel µ and some indepen-
dent, i.i.d., exponentially distributed random variables γ1, γ2, . . . with mean 1.
Assume that 	
n γn/c(Yn−1) = ∞a.s. under every initial distribution for Y .
Then (9) and (10) deﬁne a pure jump-type Markov process with rate kernel α.
Proof: Let Px be the distribution of the sequences Y = (Yn) and Γ = (γn)
when Y0 = x. For convenience, we may regard (Y, Γ) as the identity mapping
on the canonical space Ω= S∞×R∞
+ . Construct X from (Y, Γ) as in (9) and
(10), with Xt = s0 arbitrary for t ≥supn τn, and introduce the ﬁltrations
G = (Gn) induced by (Y, γ) and F = (Ft) induced by X. It suﬃces to prove
the Markov property Px[θtX ∈·|Ft] = PXt{X ∈·}, since the rate kernel may
then be identiﬁed via Theorem 10.19.
Then ﬁx any t ≥0 and n ∈Z+, and deﬁne
κ = sup{k; τk ≤t},
β = (t −τn)c(Yn).
Put T m(Y, Γ) = {(Yk, γk+1); k ≥m}, (Y ′, Γ′) = T n+1(Y, Γ), and γ′ = γn+1.
Since clearly
Ft = Gn ∨σ{γ′ > β} on {κ = n},
it is enough by Lemma 5.2 to prove that
Px[(Y ′, Γ′) ∈·, γ′ −β > r| Gn, γ′ > β] = PYn{T(Y, Γ) ∈·, γ1 > r}.
Now (Y ′, Γ′)⊥⊥Gn(γ′, β) because γ′⊥⊥(Gn, Y ′, Γ′), and so the left-hand side
equals
Px[(Y ′, Γ′) ∈·, γ′ −β > r|Gn]
Px[γ′ > β|Gn]
= Px[(Y ′, Γ′) ∈·|Gn] Px[γ′ −β > r|Gn]
Px[γ′ > β|Gn]
= (PYn ◦T −1)e−r,
as required.
✷
To complete the picture, we need a convenient criterion for nonexplosion.

10. Poisson and Pure Jump-Type Markov Processes
191
Proposition 10.21 (explosion) Fix a rate kernel α and an initial state x,
and let (Yn) and (τn) be such as in Theorem 10.19. Then a.s.
τn →∞
iﬀ

n{c(Yn)}−1 = ∞.
(12)
In particular, τn →∞a.s. when x is recurrent for (Yn).
Proof: Write βn = {c(Yn−1)}−1. Noting that Ee−uγn = (1 + u)−1 for all
u ≥0, we get by (10) and Fubini’s theorem
E[e−uζ|Y ] =

n(1 + uβn)−1 = exp

−

n log(1 + uβn)

a.s.
(13)
Since 1
2(r ∧1) ≤log(1 + r) ≤r for all r > 0, the series on the right converges
for every u > 0 iﬀ	
n βn < ∞. Letting u →0 in (13), we get by dominated
convergence
P[ζ < ∞| Y ] = 1

nβn < ∞

a.s.,
which implies (12). If x is visited inﬁnitely often, then the series 	
n βn has
inﬁnitely many terms c−1
x
> 0, and the last assertion follows.
✷
By a pseudo-Poisson process in some measurable space S we mean a
process of the form X = Y ◦N a.s., where Y is a discrete-time Markov
process in S and N is an independent homogeneous Poisson process. Letting
µ be the transition kernel of Y and writing c for the constant rate of N, we
may construct a kernel
α(x, B) = cµ(x, B \ {x}),
x ∈S, B ∈B(S),
(14)
which is measurable since µ(x, {x}) is a measurable function of x. The next
result characterizes pseudo-Poisson processes in terms of the rate kernel.
Proposition 10.22 (pseudo-Poisson processes) A process X in some Borel
space S is pseudo-Poisson iﬀit is pure jump-type Markov with a bounded
rate function. Speciﬁcally, if X = Y ◦N a.s. for some Markov chain Y with
transition kernel µ and an independent Poisson process N with constant rate
c, then X has the rate kernel in (14).
Proof: Assume that X = Y ◦N with Y and N as stated. Letting τ1, τ2, . . .
be the jump times of N and writing F for the ﬁltration induced by the pair
(X, N), it may be seen as in Theorem 10.20 that X is F-Markov. To identify
the rate kernel α, ﬁx any initial state x, and note that the ﬁrst jump of X
occurs at the ﬁrst time τn when Yn leaves x. For each transition of Y , this
happens with probability px = µ(x, {x}c). By Proposition 10.6 the time until
ﬁrst jump is then exponentially distributed with parameter cpx. If px > 0,
we further note that the location of X after the ﬁrst jump has distribution
µ(x, · \ {x})/px. Thus, α is given by (14).

192
Foundations of Modern Probability
Conversely, let X be a pure jump-type Markov process with uniformly
bounded rate kernel α ̸= 0. Put rx = α(x, S) and c = supx rx, and note that
the kernel
µ(x, ·) = c−1{α(x, ·) + (c −rx)δx},
x ∈S,
satisﬁes (14). Thus, if X′ = Y ′ ◦N ′ is a pseudo-Poisson process based on
µ and c, then X′ is again Markov with rate kernel α, so X
d= X′. Hence,
Corollary 5.11 yields X = Y ◦N a.s. for some pair (Y, N) d= (Y ′, N ′).
✷
If the underlying Markov chain Y is a random walk in some measurable
Abelian group S, then X = Y ◦N is called a compound Poisson process. In
this case X −X0 ⊥⊥X0, the jump sizes are i.i.d., and the jump times are given
by an independent homogeneous Poisson process. Thus, the distribution of
X −X0 is determined by the characteristic measure ν = cµ, where c is the
rate of the jump time process and µ is the common distribution of the jumps.
A kernel α on S is said to be homogeneous if α(x, B) = α(0, B −x) for all x
and B. Furthermore, a process X in S is said to have independent increments
if Xt −Xs ⊥⊥{Xr; r ≤s} for any s < t.
The next result characterizes compound Poisson processes in two ways,
analytically in terms of the rate kernel and probabilistically in terms of the
increments of the process.
Corollary 10.23 (compound Poisson processes) For a pure jump-type pro-
cess X in some measurable Abelian group, these conditions are equivalent:
(i) X is Markov with homogeneous rate kernel;
(ii) X has independent increments;
(iii) X is compound Poisson.
Proof: If a pure jump-type Markov process is space-homogeneous, then
its rate kernel is clearly homogeneous; the converse follows from the repre-
sentation in Theorem 10.19. Thus, (i) and (ii) are equivalent by Proposition
7.5. Next Theorem 10.19 shows that (i) implies (iii), and the converse follows
by Theorem 10.20.
✷
We shall now derive a combined diﬀerential and integral equation for the
transition kernels µt. An abstract version of this result appears in Theorem
17.6. For any measurable and suitably integrable function f : S →R, we
deﬁne
Ttf(x) =

f(y)µt(x, dy) = Exf(Xt),
x ∈S, t ≥0.
Theorem 10.24 (backward equation, Kolmogorov) Let α be the rate kernel
of a pure jump-type Markov process on S, and ﬁx any bounded, measurable
function f : S →R. Then Ttf(x) is continuously diﬀerentiable in t for ﬁxed
x, and we have
∂
∂tTtf(x) =

α(x, dy){Ttf(y) −Ttf(x)},
t ≥0, x ∈S.
(15)

10. Poisson and Pure Jump-Type Markov Processes
193
Proof: Put τ = τ1 and let x ∈S and t ≥0. By the strong Markov
property at σ = τ ∧t and Theorem 5.4,
Ttf(x)
=
Exf(Xt) = Exf((θσX)t−σ) = ExTt−σf(Xσ)
=
f(x)Px{τ > t} + Ex[Tt−τf(Xτ); τ ≤t]
=
f(x)e−tcx +

 t
0 e−scxds

α(x, dy)Tt−sf(y),
and so
etcxTtf(x) = f(x) +

 t
0 escxds

α(x, dy)Tsf(y).
(16)
Here the use of the disintegration theorem is justiﬁed by the fact that X(ω, t)
is product measurable on Ω×R+ because of the right-continuity of the paths.
From (16) we note that Ttf(x) is continuous in t for each x, and so by
dominated convergence the inner integral on the right is continuous in s.
Hence, Ttf(x) is continuously diﬀerentiable in t, and (15) follows by an easy
computation.
✷
The next result relates the invariant distributions of a pure jump-type
Markov process to those of the embedded Markov chain.
Proposition 10.25 (invariance) Let the processes X and Y be related as
in Theorem 10.19, and ﬁx a probability measure ν on S with
 c dν < ∞.
Then ν is invariant for X iﬀc · ν is invariant for Y .
Proof: By Theorem 10.24 and Fubini’s theorem we have for any bounded
measurable function f : S →R
Eνf(Xt) =

f(x)ν(dx) +

 t
0 ds

ν(dx)

α(x, dy){Tsf(y) −Tsf(x)}.
Thus, ν is invariant for X iﬀthe second term on the right is identically zero.
Now (15) shows that Ttf(x) is continuous in t, and by dominated convergence
this is also true for the integral
It =

ν(dx)

α(x, dy){Ttf(y) −Ttf(x)},
t ≥0.
Thus, the condition becomes It ≡0. Since f is arbitrary, it is enough to take
t = 0. The condition then reduces to (να)f ≡ν(cf) or (c · ν)µ = c · ν, which
means that c · ν is invariant for Y .
✷
By a continuous-time Markov chain we mean a pure jump-type Markov
process on a countable state space I. Here the kernels µt may be speciﬁed
by the set of transition functions pt
ij = µt(i, {j}). The connectivity proper-
ties are simpler than in discrete time, and the notion of periodicity has no
counterpart in the continuous-time theory.

194
Foundations of Modern Probability
Lemma 10.26 (positivity) For any i, j ∈I we have either pt
ij > 0 for all
t > 0 or pt
ij = 0 for all t ≥0. In particular, pt
ii > 0 for all t and i.
Proof: Let q = (qij) be the transition matrix of the embedded Markov
chain Y in Theorem 10.19. If qn
ij = Pi{Yn = j} = 0 for all n ≥0, then clearly
1{Xt ̸= j} ≡1 a.s. Pi, and so pt
ij = 0 for all t ≥0. If instead qn
ij > 0 for
some n ≥0, there exist some states i = i0, i1, . . . , in = j with qik−1,ik > 0
for k = 1, . . . , n. Noting that the distribution of (γ1, . . . , γn+1) has positive
density 
k≤n+1 e−xk > 0 on Rn+1
+
, we obtain for any t > 0
pt
ij ≥P
 n

k=1
γk
cik−1
≤t <
n+1

k=1
γk
cik−1

n

k=1
qik−1,ik > 0.
Since p0
ii = q0
ii = 1, we get in particular pt
ii > 0 for all t ≥0.
✷
A continuous-time Markov chain is said to be irreducible if pt
ij > 0 for
all i, j ∈I and t > 0. Note that this holds iﬀthe associated discrete-time
process Y in Theorem 10.19 is irreducible. In that case clearly sup{t > 0;
Xt = j} < ∞iﬀsup{n > 0; Yn = j} < ∞. Thus, when Y is recurrent, the
sets {t; Xt = j} are a.s. unbounded under Pi for all i ∈I; otherwise, they
are a.s. bounded. The two possibilities are again referred to as recurrence
and transience, respectively.
The basic ergodic Theorem 7.18 for discrete-time Markov chains has an
analogous version in continuous time.
Theorem 10.27 (ergodic behavior)
For an irreducible, continuous-time
Markov chain, exactly one of these cases occurs:
(i) There exists a unique invariant distribution ν; furthermore, νi > 0 for
all i ∈I, and for any distribution µ on I,
lim
t→∞∥Pµ ◦θ−1
t
−Pν∥= 0.
(17)
(ii) No invariant distribution exists, and pt
ij →0 for all i, j ∈I.
Proof: By Lemma 10.26 the discrete-time chain Xnh, n ∈Z+, is ir-
reducible and aperiodic. Assume that (Xnh) is positive recurrent for some
h > 0, say with invariant distribution ν. Then the chain (Xnh′) is positive re-
current for every h′ of the form 2−mh, and by the uniqueness in Theorem 7.18
it has the same invariant distribution. Since the paths are right-continuous,
we may conclude by a simple approximation that ν is invariant even for the
original process X.
For any distribution µ on I we have
∥Pµ ◦θ−1
t
−Pν∥=


iµi

j(pt
ij −νj)Pj
 ≤

iµi

j|pt
ij −νj|.

10. Poisson and Pure Jump-Type Markov Processes
195
Thus, (17) follows by dominated convergence if we can show that the inner
sum on the right tends to zero. This is clear if we put n = [t/h] and r = t−nh
and note that by Theorem 7.18

k|pt
ik −νk| ≤

j

k|pnh
ij −νj|pr
jk =

j|pnh
ij −νj| →0.
It remains to consider the case when (Xnh) is null recurrent or transient
for every h > 0. Fixing any i, k ∈I and writing n = [t/h] and r = t −nh as
before, we get
pt
ik =

jpr
ijpnh
jk ≤pnh
ik +

j̸=ipr
ij = pnh
ik + (1 −pr
ii),
which tends to zero as t →∞and then h →0, by Theorem 7.18 and the
continuity of pt
ii.
✷
As in discrete time, we note that condition (ii) of the last theorem holds
for any transient Markov chain, whereas a recurrent chain may satisfy either
condition. Recurrent chains satisfying (i) and (ii) are again referred to as
positive recurrent and null recurrent, respectively. It is interesting to note
that X may be positive recurrent even when the embedded, discrete-time
chain Y is null recurrent, and vice versa. On the other hand, X clearly has
the same ergodic properties as the discrete-time processes (Xnh), h > 0.
Let us next introduce the ﬁrst exit and recurrence times
γj = inf{t > 0; Xt ̸= j},
τj = inf{t > γj; Xt = j}.
As in Theorem 7.22 for the discrete-time case, we may express the asymptotic
transition probabilities in terms of the mean recurrence times Ejτj. To avoid
trivial exceptions, we may conﬁne our attention to nonabsorbing states.
Theorem 10.28 (mean recurrence times) For any continuous-time Markov
chain in I and states i, j ∈I with j nonabsorbing, we have
lim
t→∞pt
ij = Pi{τj < ∞}
cjEjτj
.
(18)
Proof: It is enough to take i = j, since the general statement will then
follow as in the proof of Theorem 7.22. If j is transient, then 1{Xt = j} →0
a.s. Pj, and so by dominated convergence pt
jj = Pj{Xt = j} →0. This agrees
with (18), since in this case Pj{τj = ∞} > 0. Turning to the recurrent case,
let Cj be the class of states i accessible from j. Then Cj is clearly irreducible,
and so pt
jj converges by Theorem 10.27.
To identify the limit, deﬁne
Lj
t = λ{s ≤t; Xs = j} =

 t
0 1{Xs = j}ds,
t ≥0,

196
Foundations of Modern Probability
and let τ n
j denote the instant of nth return to j. Letting m, n →∞with
|m −n| ≤1 and using the strong Markov property and the law of large
numbers, we get Pj-a.s.
Lj(τ m
j )
τ n
j
= Lj(τ m
j )
m
· n
τ n
j
· m
n →Ejγj
Ejτj
=
1
cjEjτj
.
By the monotonicity of Lj, it follows that t−1Lj
t →(cjEjτj)−1 a.s. Hence, by
Fubini’s theorem and dominated convergence,
1
t

 t
0 ps
jjds = EjLj
t
t
→
1
cjEjτj
,
and (18) follows.
✷
Exercises
1. Show that two random measures ξ and η are independent iﬀEe−ξf−ηg
= Ee−ξfEe−ηg for all f, g ∈C+
K. In the case of simple point processes, prove
also the equivalence of P{ξB + ηC = 0} = P{ξB = 0}P{ηC = 0} for any
B, C ∈ˆS. (Hint: Regard the pair (ξ, η) as a random measure on 2S.)
2. Let ξ1, ξ2, . . . be independent Poisson processes with intensity measures
µ1, µ2, . . . such that the measure µ =
	
k µk is σ-ﬁnite. Show that ξ =
	
k ξk
is again Poisson with intensity measure µ.
3.
Show that the class of mixed sample processes is preserved under
randomization.
4. Let ξ be a Cox process on S directed by some random measure η, and
let f be a measurable mapping into some space T such that η ◦f −1 is a.s.
locally ﬁnite. Prove directly from deﬁnitions that ξ ◦f −1 is a Cox process on
T directed by η ◦f −1. Derive a corresponding result for p-thinnings.
5. Consider a p-thinning η of ξ and a p′-thinning ζ of η with ζ⊥⊥ηξ. Show
that ζ is a pp′-thinning of ξ.
6. Let ξ be a Cox process directed by η or a p-thinning of η with p ∈(0, 1),
and ﬁx two disjoint sets B, C ∈ˆS. Show that ξB⊥⊥ξC iﬀηB⊥⊥ηC. (Hint:
Compute the Laplace transforms. The if assertions can also be obtained from
Proposition 5.8.)
7. Use Lemma 10.7 to derive expressions for P{ξB = 0} when ξ is a Cox
process directed by η, a µ-randomization of η, or a p-thinning of η. (Hint:
Note that Ee−tξB →P{ξB = 0} as t →0.)
8. Let ξ be a p-thinning of η, where p ∈(0, 1). Show that ξ and η are
simultaneously Cox. (Hint: Use Lemma 10.8.)

10. Poisson and Pure Jump-Type Markov Processes
197
9. Let the simple point process ξ be symmetric with respect to Lebesgue
measure λ on [0, 1]. Show that ξ is a mixed sample process based on λ. (Hint:
Reduce to the case when ξ[0, 1] is a constant, and estimate P{ξU = 0} for
ﬁnite unions U of dyadic intervals.)
10. Show that the distribution of a simple point process ξ on R is not
determined, in general, by the distributions of ξI for all intervals I. (Hint: If
ξ is restricted to {1, . . . , n}, then the distributions of all ξI give 	
k≤n k(n −
k + 1) ≤n3 linear relations between the 2n −1 parameters.)
11. Show that the distribution of a point process is not determined, in
general, by the one-dimensional distributions. (Hint: If ξ is restricted to
{0, 1} with ξ{0} ∨ξ{1} ≤n, then the one-dimensional distributions give 4n
linear relations between the n(n + 2) parameters.)
12. Show that Lemma 10.1 remains valid with B1, . . . , Bn restricted to an
arbitrary preseparating class C, as deﬁned in Chapter 14 or Appendix A2.
Also show that Theorem 10.9 holds with B restricted to a separating class.
(Hint: Extend to the case when C = {B ∈ˆS; (ξ + η)∂B = 0 a.s.}. Then use
monotone class arguments for sets in S and in M(S).)
13. Show that Theorem 10.11 remains true for any measurable space K
that admits a partition into measurable sets A1, A2, . . . , where ξ(· × An) is
a.s. locally ﬁnite for each n. (Hint: Reduce to the case when ξ(· × K) is
a.s. locally ﬁnite, ﬁx any disjoint measurable sets B1, . . . , Bn ⊂S × K, and
deﬁne ηk = (1Bk · ξ)(· × K), k ≤n. Then η1, . . . , ηn are independent Poisson,
by Theorem 12.3 applied to the space nS.)
14. Extend Corollary 10.13 to the case when ps = P{ξ{s} > 0} may be
positive. (Hint: By Fatou’s lemma, ps > 0 for at most countably many s.)
15. Prove Theorem 10.15 (i) and (iii) by means of characteristic functions.
16. Let ξ and ξ′ be independent Poisson processes on S with Eξ = Eξ′ =
µ, and let f1, f2, . . .: S →R be measurable with ∞> µ(f 2
n ∧1) →∞. Show
that |(ξ −ξ′)fn|
P→∞. (Hint: Consider the symmetrization ˜ν of a ﬁxed
measure ν ∈N(S) with νf 2
n →∞, and argue along subsequences as in the
proof of Theorem 3.17.)
17. For any pure jump-type Markov process on S, show that Px{τ2 ≤t}
= o(t) for all x ∈S. Also note that the bound can be sharpened to O(t2) if
the rate function is bounded, but not in general. (Hint: Use Lemma 10.18
and dominated convergence.)
18. Show that any transient, discrete-time Markov chain Y can be embed-
ded into an exploding (resp., nonexploding) continuous-time chain X. (Hint:
Use Propositions 7.12 and 10.21.)
19. In Corollary 10.23, use the measurability of the mapping X = Y ◦N
to deduce the implication (iii) ⇒(i) from its converse. (Hint: Proceed as in
the proof of Proposition 10.17.) Also use Proposition 10.6 to show that (iii)
implies (ii), and prove the converse by means of Theorem 10.11.

198
Foundations of Modern Probability
20. Consider a pure jump-type Markov process on (S, S) with transition
kernels µt and rate kernel α. Show for any x ∈S and B ∈S that α(x, B) =
˙µ0(x, B \{x}). (Hint: Take f = 1B\{x} in Theorem 10.24, and use dominated
convergence.)
21. Use Theorem 10.24 to derive a system of diﬀerential equations for the
transition functions pij(t) of a continuous-time Markov chain. (Hint: Take
f(i) = δij for ﬁxed j.)
22.
Give an example of a positive recurrent, continuous-time Markov
chain such that the embedded discrete-time chain is null recurrent, and vice
versa. (Hint: Use Proposition 10.25.)
23. Establish Theorem 10.27 directly, imitating the proof of Theorem
7.18.

Chapter 11
Gaussian Processes
and Brownian Motion
Symmetries of Gaussian distribution; existence and path proper-
ties of Brownian motion; strong Markov and reﬂection properties;
arcsine and uniform laws; law of the iterated logarithm; Wiener
integrals and isonormal Gaussian processes; multiple Wiener–Itˆo
integrals; chaos expansion of Brownian functionals
The main purpose of this chapter is to initiate the study of Brownian motion,
arguably the single most important object in modern probability theory.
Indeed, we shall see in Chapters 12 and 14 how the Gaussian limit theorems
of Chapter 4 can be extended to approximations of broad classes of random
walks and discrete-time martingales by a Brownian motion. In Chapter 16
we show how every continuous local martingale may be represented in terms
of Brownian motion through a suitable random time-change. Similarly, the
results of Chapters 18 and 20 demonstrate how large classes of diﬀusion
processes may be constructed from Brownian motion by various pathwise
transformations. Finally, a close relationship between Brownian motion and
classical potential theory is uncovered in Chapters 21 and 22.
The easiest construction of Brownian motion is via a so-called isonor-
mal Gaussian process on L2(R+), whose existence is a consequence of the
characteristic spherical symmetry of the multivariate Gaussian distributions.
Among the many important properties of Brownian motion, this chapter
covers the H¨older continuity and existence of quadratic variation, the strong
Markov and reﬂection properties, the three arcsine laws, and the law of the
iterated logarithm.
The values of an isonormal Gaussian process on L2(R+) may be identi-
ﬁed with integrals of L2-functions with respect to the associated Brownian
motion. Many processes of interest have representations in terms of such
integrals, and in particular we shall consider spectral and moving average
representations of stationary Gaussian processes. More generally, we shall
introduce the multiple Wiener–Itˆo integrals Inf of functions f ∈L2(Rn
+) and
establish the fundamental chaos expansion of Brownian L2-functionals.
The present material is related to practically every other chapter in the
book. Thus, we refer to Chapter 4 for the deﬁnition of Gaussian distributions
and the basic Gaussian limit theorem, to Chapter 5 for the transfer theorem,
199

200
Foundations of Modern Probability
to Chapter 6 for properties of martingales and optional times, to Chapter
7 for basic facts about Markov processes, to Chapter 8 for some similarities
with random walks, to Chapter 9 for some basic symmetry results, and to
Chapter 10 for analogies with the Poisson process.
Our study of Brownian motion per se is continued in Chapter 16 with the
basic recurrence or transience dichotomy, some further invariance properties,
and a representation of Brownian martingales.
Brownian local time and
additive functionals are studied in Chapter 19. In Chapter 21 we consider
some basic properties of Brownian hitting distributions, and in Chapter 22 we
examine the relationship between excessive functions and additive functionals
of Brownian motion. A further discussion of multiple integrals and chaos
expansions appears in Chapter 16.
To begin with some basic deﬁnitions, we shall say that a process X on
some parameter space T is Gaussian if the random variable c1Xt1+· · ·+cnXtn
is Gaussian for any choice of n ∈N, t1, . . . , tn ∈T, and c1, . . . , cn ∈R. This
holds in particular if the Xt are independent Gaussian random variables. A
Gaussian process X is said to be centered if EXt = 0 for all t ∈T. We shall
further say that the processes Xi on Ti, i ∈I, are jointly Gaussian if the
combined process X = {Xi
t; t ∈Ti, i ∈I} is Gaussian. The latter condition
is certainly fulﬁlled if the processes Xi are independent and Gaussian.
The following simple facts clarify the fundamental role of the covariance
function. As usual, we assume all distributions to be deﬁned on the σ-ﬁelds
generated by the evaluation maps.
Lemma 11.1 (covariance function)
(i) The distribution of a Gaussian process X on T is determined by the
functions EXt and cov(Xs, Xt), s, t ∈T.
(ii) The jointly Gaussian processes Xi on Ti, i ∈I, are independent iﬀ
cov(Xi
s, Xj
t ) = 0 for all s ∈Ti and t ∈Tj, i ̸= j in I.
Proof: (i) Let X and Y be Gaussian processes on T with the same
means and covariances. Then the random variables c1Xt1 + · · · + cnXtn and
c1Yt1 + · · · + cnYtn have the same mean and variance for any c1, . . . , cn ∈R
and t1, . . . , tn ∈T, n ∈N, and since both variables are Gaussian, their
distributions must agree.
By the Cram´er–Wold theorem it follows that
(Xt1, . . . , Xtn) d= (Yt1, . . . , Ytn) for any t1, . . . , tn ∈T, n ∈N, and so X
d= Y
by Proposition 2.2.
(ii) Assume the stated condition. To prove the asserted independence, we
may assume I to be ﬁnite. Introduce some independent processes Y i, i ∈I,
with the same distributions as the Xi, and note that the combined processes
X = (Xi) and Y = (Y i) have the same means and covariances. Hence, the
joint distributions agree by part (i). In particular, the independence between
the processes Y i implies the corresponding property for the processes Xi. ✷
The following result characterizes the Gaussian distributions by a simple
symmetry property.

11. Gaussian Processes and Brownian Motion
201
Proposition 11.2 (spherical symmetry, Maxwell)
Let ξ1, . . . , ξd be i.i.d.
random variables, where d ≥2. Then the distribution of (ξ1, . . . , ξd) is spher-
ically symmetric iﬀthe ξi are centered Gaussian.
Proof: Let ϕ denote the common characteristic function of ξ1, . . . , ξd, and
assume the stated condition. In particular, −ξ1
d= ξ1, and so ϕ is real valued
and symmetric. Noting that sξ1 +tξ2
d= ξ1
√
s2 + t2, we obtain the functional
equation ϕ(s)ϕ(t) = ϕ(
√
s2 + t2), and by iteration we get ϕn(t) = ϕ(t√n)
for all n. Thus, for rational t2 we have ϕ(t) = eat2 for some constant a, and
by continuity the solution extends to all real t. Finally, a ≤0 since |ϕ| ≤1.
Conversely, assume ξ1, . . . , ξd to be centered Gaussian, and let (η1, . . . ,
ηd) be obtained from (ξ1, . . . , ξd) by an arbitrary orthogonal transforma-
tion. Then both random vectors are Gaussian, and we note that cov(ηi, ηj)
= cov(ξi, ξj) for all i and j. Hence, the two distributions agree by Lemma
11.1.
✷
In inﬁnite dimensions, the Gaussian distribution can be deduced from the
rotational symmetry alone, without any assumption of independence.
Theorem 11.3 (unitary invariance, Schoenberg, Freedman) For any inﬁ-
nite sequence of random variables ξ1, ξ2, . . . , the distribution of (ξ1, . . . , ξn)
is spherically symmetric for every n ≥1 iﬀthe ξk are conditionally i.i.d.
N(0, σ2), given some random variable σ2 ≥0.
Proof: The ξn are clearly exchangeable, and so there exists by Theorem
9.16 some random probability measure µ such that the ξn are conditionally
µ-i.i.d. given µ. By the law of large numbers, we get
µB = lim
n→∞n−1
k≤n1{ξk ∈B} a.s.,
B ∈B,
which shows that µ is a.s. {ξ3, ξ4, . . .}-measurable. Now conclude from the
spherical symmetry that, for any orthogonal transformation T on R2,
P[(ξ1, ξ2) ∈B|ξ3, . . . , ξn] = P[T(ξ1, ξ2) ∈B|ξ3, . . . , ξn],
B ∈B(R2).
As n →∞, we get µ2 = µ2 ◦T −1 a.s. Considering a countable dense set
of mappings T, it is clear that the exceptional null set can be chosen to
be independent of T. Thus, µ2 is a.s. spherically symmetric, and so µ is a.s.
centered Gaussian by Proposition 11.2. It remains to take σ2 =
 x2µ(dx). ✷
Now ﬁx a separable Hilbert space H. By an isonormal Gaussian process
on H we mean a centered Gaussian process ηh, h ∈H, such that E(ηh ηk) =
⟨h, k⟩, the inner product of h and k.
To construct such a process η, we
may introduce an orthonormal basis (ONB) e1, e2, . . . ∈H, and let ξ1, ξ2, . . .
be independent N(0, 1) random variables. For any element h = 	
i biei, we
deﬁne ηh = 	
i biξi, where the series converges a.s. and in L2 since
	
i b2
i < ∞.

202
Foundations of Modern Probability
The process η is clearly centered Gaussian. Furthermore, it is linear, in the
sense that η(ah+bk) = aηh+bηk a.s. for all h, k ∈H and a, b ∈R. Assuming
that k = 	
i ciei, we may compute
E(ηh ηk) =

i,jbicjE(ξiξj) =

ibici = ⟨h, k⟩.
By Lemma 11.1 the stated conditions uniquely determine the distribution
of η. In particular, the symmetry property in Proposition 11.2 extends to a
distributional invariance of η under any unitary transformation on H.
The following result shows how the Gaussian distribution arises naturally
in the context of processes with independent increments. It is interesting to
compare with the similar Poisson characterization in Theorem 10.11.
Theorem 11.4 (independence and Gaussian property, L´evy) Let X be a
continuous process in Rd with independent increments.
Then X −X0 is
Gaussian, and there exist some continuous functions b in Rd and a in Rd2,
the latter with nonnegative deﬁnite increments such that Xt −Xs is N(bt −
bs, at −as) for any s < t.
Proof: Fix any s < t in R+ and u ∈Rd.
For every n ∈N we may
divide the interval [s, t] into n subintervals of equal length, and we denote the
corresponding increments of uX by ξn1, . . . , ξnn. By the continuity of X we
have maxj |ξnj| →0 a.s., and so Theorem 4.15 shows that u(Xt−Xs) =
	
j ξnj
is a Gaussian random variable.
Since X has independent increments, it
follows that the process X −X0 is Gaussian. Writing bt = EXt −EX0 and
at = cov(Xt −X0), we get E(Xt −Xs) = EXt −EXs = bt −bs, and by the
independence,
0 ≤cov(Xt −Xs) = cov(Xt) −cov(Xs) = at −as,
s < t.
The continuity of X yields Xs
d→Xt as s →t, so bs →bt and as →at. Thus,
both functions are continuous.
✷
If the process X in Theorem 11.4 has stationary, independent increments
and starts at 0, then the mean and covariance functions are clearly linear.
The simplest choice in one dimension is to take b = 0 and at = t, so that Xt−
Xs is N(0, t −s) for all s < t. The next result shows that the corresponding
process exists, and it also gives an estimate of the local modulus of continuity.
More precise rates of continuity are obtained in Theorem 11.18 and Lemma
12.7.
Theorem 11.5 (existence of Brownian motion, Wiener)
There exists a
continuous Gaussian process B in R with stationary independent increments
and B0 = 0 such that Bt is N(0, t) for every t ≥0. For any c ∈(0, 1
2), B is
further a.s. locally H¨older continuous with exponent c.

11. Gaussian Processes and Brownian Motion
203
Proof: Let η be an isonormal Gaussian process on L2(R+, λ), and de-
ﬁne Bt = η1[0,t], t ≥0. Since indicator functions of disjoint intervals are
orthogonal, the increments of the process B are uncorrelated and hence in-
dependent. Furthermore, we have ∥1(s,t]∥2 = t −s for any s ≤t, and so
Bt −Bs is N(0, t −s). For any s ≤t we get
Bt −Bs
d= Bt−s
d= (t −s)1/2B1,
(1)
whence,
E|Bt −Bs|c = (t −s)c/2E|B1|c < ∞,
c > 0,
and the asserted H¨older continuity follows by Theorem 2.23.
✷
A process B as in Theorem 11.5 is called a (standard) Brownian mo-
tion or a Wiener process.
By a Brownian motion in Rd we mean a pro-
cess Bt = (B1
t , . . . , Bd
t ), where B1, . . . , Bd are independent, one-dimensional
Brownian motions. From Proposition 11.2 we note that the distribution of
B is invariant under orthogonal transformations of Rd. It is also clear that
any continuous process X in Rd with stationary independent increments and
X0 = 0 can be written as Xt = bt + σBt for some vector b and matrix σ.
From Brownian motion we may construct other important Gaussian pro-
cesses. For example, a Brownian bridge may be deﬁned as a process on [0, 1]
with the same distribution as Xt = Bt −tB1, t ∈[0, 1]. An easy computation
shows that X has covariance function rs,t = s(1 −t), 0 ≤s ≤t ≤1.
The Brownian motion and bridge have many nice symmetry properties.
For example, if B is a Brownian motion, then so is −B as well as the process
c−1B(c2t) for any c > 0. The latter transformation is frequently employed
and will often be referred to as a Brownian scaling. We may also note that, for
each u > 0, the processes Bu±t −Bu are Brownian motions on R+ and [0, u],
respectively. If B is instead a Brownian bridge, then so are the processes
−Bt and B1−t.
The following result gives some less obvious invariance properties. Fur-
ther, possibly random mappings that preserve the distribution of a Brownian
motion or bridge are exhibited in Theorem 11.11, Lemma 11.14, and Propo-
sition 16.9.
Lemma 11.6 (scaling and inversion) If B is a Brownian motion, then so is
the process tB1/t, whereas (1 −t)Bt/(1−t) and tB(1−t)/t are Brownian bridges.
If B is instead a Brownian bridge, then the processes (1 + t)Bt/(1+t) and
(1 + t)B1/(1+t) are Brownian motions.
Proof: Since all processes are centered Gaussian, it suﬃces by Lemma
11.1 to verify that they have the desired covariance functions. This is clear
from the expressions s ∧t and (s ∧t)(1 −s ∨t) for the covariance functions
of the Brownian motion and bridge.
✷

204
Foundations of Modern Probability
From Proposition 7.5 together with Theorem 11.4 we note that any space-
and time-homogeneous, continuous Markov process in Rd has the form σBt+
tb+c, where B is a Brownian motion in Rd, σ is a d×d matrix, and b and c are
vectors in Rd. The next result gives a general characterization of Gaussian
Markov processes.
Proposition 11.7 (Gaussian Markov processes) Let X be a Gaussian pro-
cess on some index set T ⊂R, and deﬁne rs,t = cov(Xs, Xt). Then X is
Markov iﬀ
rs,u = rs,trt,u/rt,t,
s ≤t ≤u in T,
(2)
where 0/0 = 0. If X is further stationary and deﬁned on R, then rs,t =
ae−b|s−t| for some constants a ≥0 and b ∈[0, ∞].
Proof: Subtracting the means if necessary, we may assume that EXt ≡0.
Now ﬁx any times t ≤u in T, and choose a ∈R such that X′
u ≡Xu −
aXt ⊥Xt. Thus, a = rt,u/rt,t when rt,t ̸= 0, and if rt,t = 0, we may take
a = 0. By Lemma 11.1 we get X′
u⊥⊥Xt.
First assume that X is Markov, and let s ≤t be arbitrary.
Then
Xs⊥⊥XtXu, and so Xs⊥⊥XtX′
u. Since also Xt⊥⊥X′
u by the choice of a, Propo-
sition 5.8 yields Xs⊥⊥X′
u. Hence, rs,u = ars,t, and (2) follows as we insert
the expression for a. Conversely, (2) implies Xs ⊥X′
u for all s ≤t, and so
Ft⊥⊥X′
u by Lemma 11.1, where Ft = σ{Xs; s ≤t}. By Proposition 5.8 it
follows that Ft⊥⊥XtXu, which is the required Markov property of X at t.
If X is stationary, then rs,t = r|s−t|,0 = r|s−t|, and (2) reduces to the
Cauchy equation r0rs+t = rsrt, s, t ≥0, which admits the only bounded so-
lutions rt = ae−bt.
✷
A continuous, centered Gaussian process on R with covariance function
rt = 1
2e−|t| is called a stationary Ornstein–Uhlenbeck process. Such a process
Y can be expressed in terms of a Brownian motion B as Yt = e−tB( 1
2e2t),
t ∈R. The last result shows that the Ornstein–Uhlenbeck process is essen-
tially the only stationary Gaussian process that is also a Markov process.
We will now study some basic sample path properties of Brownian motion.
Lemma 11.8 (level sets) If B is a Brownian motion or bridge, then
λ{t; Bt = u} = 0 a.s.,
u ∈R.
Proof: Introduce the processes Xn
t = B[nt]/n, t ∈R+ or [0, 1], n ∈N, and
note that Xn
t →Bt for every t. Since each process Xn is product measurable
on Ω× R+ or Ω× [0, 1], the same thing is true for B. Now use Fubini’s
theorem to conclude that
Eλ{t; Bt = u} =

P{Bt = u}dt = 0,
u ∈R.
✷
The next result shows that Brownian motion has locally ﬁnite quadratic
variation. An extension to general continuous semimartingales is obtained in
Proposition 15.18.

11. Gaussian Processes and Brownian Motion
205
Theorem 11.9 (quadratic variation, L´evy) Let B be a Brownian motion,
and ﬁx any t > 0 and a sequence of partitions 0 = tn,0 < tn,1 < · · · < tn,kn = t,
n ∈N, such that hn ≡maxk(tn,k −tn,k−1) →0. Then
ζn ≡

k(Btn,k −Btn,k−1)2 →t in L2.
(3)
If the partitions are nested, then also ζn →t a.s.
Proof (Doob): To prove (3), we may use the scaling property Bt −Bs
d=
|t −s|1/2B1 to obtain
Eζn
=

kE(Btn,k −Btn,k−1)2
=

k(tn,k −tn,k−1)EB2
1 = t,
var(ζn)
=

kvar(Btn,k −Btn,k−1)2
=

k(tn,k −tn,k−1)2var(B2
1) ≤hntEB4
1 →0.
For nested partitions we may prove the a.s. convergence by showing that
the sequence (ζn) is a reverse martingale, that is,
E[ζn−1 −ζn|ζn, ζn+1, . . .] = 0 a.s.,
n ∈N.
(4)
Inserting intermediate partitions if necessary, we may assume that kn = n for
all n. In that case there exist some numbers t1, t2, . . . ∈[0, t] such that the
nth partition has division points t1, . . . , tn. To verify (4) for a ﬁxed n, we may
further introduce an auxiliary random variable ϑ⊥⊥B with P{ϑ = ±1} = 1
2,
and replace B by the Brownian motion
B′
s = Bs∧tn + ϑ(Bs −Bs∧tn),
s ≥0.
Since B′ has the same sums ζn, ζn+1, . . . as B whereas ζn−1 −ζn is replaced
by ϑ(ζn −ζn−1), it is enough to show that E[ϑ(ζn −ζn−1)|ζn, ζn+1, . . .] = 0
a.s. This is clear from the choice of ϑ if we ﬁrst condition on ζn−1, ζn, . . . . ✷
The last result implies that B has locally unbounded variation.
This
explains why the stochastic integral
 V dB cannot be deﬁned as an ordinary
Stieltjes integral and a more sophisticated approach is required in Chapter 15.
Corollary 11.10 (linear variation) Brownian motion has a.s. unbounded
variation on every interval [s, t] with s < t.
Proof: The quadratic variation vanishes for any continuous function of
bounded variation on [s, t].
✷
From Proposition 7.5 we note that Brownian motion B is a space-homo-
geneous Markov process with respect to its induced ﬁltration. If the Markov
property holds for some more general ﬁltration F = (Ft) —that is, if B is

206
Foundations of Modern Probability
adapted to F and such that the process B′
t = Bs+t −Bs is independent of
Fs for each s ≥0 —we say that B is a Brownian motion with respect to F,
or an F-Brownian motion. In particular, we may take Ft = Gt ∨N, t ≥0,
where G is the ﬁltration induced by B and N = σ{N ⊂A; A ∈A, PA = 0}.
With this construction, F becomes right-continuous by Corollary 6.25.
The Markov property of B will now be extended to suitable optional
times. A more general version of this result appears in Theorem 17.17. As
in Chapter 6, we shall write F+
t = Ft+.
Theorem 11.11 (strong Markov property, Hunt) For any F-Brownian mo-
tion B in Rd and a.s. ﬁnite F+-optional time τ, the process B′
t = Bτ+t −Bτ,
t ≥0, is again a Brownian motion independent of F+
τ .
Proof: As in Lemma 6.4, we may approximate τ by optional times τn →τ
that take countably many values and satisfy τn ≥τ+2−n. Then F+
τ ⊂

n Fτn
by Lemmas 6.1 and 6.3, and so by Proposition 7.9 and Theorem 7.10 each
process Bn
t = Bτn+t −Bτn, t ≥0, is a Brownian motion independent of
F+
τ . The continuity of B yields Bn
t →B′
t a.s. for every t. By dominated
convergence we then obtain, for any A ∈F+
τ and t1, . . . , tk ∈R+, k ∈N, and
for bounded continuous functions f : Rk →R,
E[f(B′
t1, . . . , B′
tk); A] = Ef(Bt1, . . . , Btk) · PA.
The general relation P[B′ ∈·, A] = P{B ∈·}·PA now follows by a straight-
forward extension argument.
✷
If B is a Brownian motion in Rd, then a process with the same distribution
as |B| is called a Bessel process of order d. More general Bessel processes
may be obtained as solutions to suitable SDEs. The next result shows that
|B| inherits the strong Markov property from B.
Corollary 11.12 (Bessel processes) If B is an F-Brownian motion in Rd,
then |B| is a strong F+-Markov process.
Proof: By Theorem 11.11 it is enough to show that |B + x|
d= |B + y|
whenever |x| = |y|. We may then choose an orthogonal transformation T on
Rd with Tx = y, and note that
|B + x| = |T(B + x)| = |TB + y| d= |B + y|.
✷
We shall use the strong Markov property to derive the distribution of
the maximum of Brownian motion up to a ﬁxed time. A stronger result is
obtained in Corollary 19.3.
Proposition 11.13 (maximum process, Bachelier) Let B be a Brownian
motion in R, and deﬁne Mt = sups≤t Bs, t ≥0. Then
Mt
d= Mt −Bt
d= |Bt|,
t ≥0.

11. Gaussian Processes and Brownian Motion
207
For the proof we shall need the following continuous-time counterpart to
Lemma 8.10.
Lemma 11.14 (reﬂection principle) For any optional time τ, a Brownian
motion B has the same distribution as the reﬂected process
˜Bt = Bt∧τ −(Bt −Bt∧τ),
t ≥0.
Proof: It is enough to compare the distributions up to a ﬁxed time t, and
so we may assume that τ < ∞. Deﬁne Bτ
t = Bτ∧t and B′
t = Bτ+t −Bτ. By
Theorem 11.11 the process B′ is a Brownian motion independent of (τ, Bτ).
Since, moreover, −B′
d= B′, we get (τ, Bτ, B′) d= (τ, Bτ, −B′). It remains to
note that
Bt = Bτ
t + B′
(t−τ)+,
˜Bt = Bτ
t −B′
(t−τ)+,
t ≥0.
✷
Proof of Proposition 11.13: By scaling it is suﬃcient to take t = 1. Ap-
plying Lemma 11.14 with τ = inf{t; Bt = x}, we get
P{M1 ≥x, B1 ≤y} = P{ ˜B1 ≥2x −y},
x ≥y ∨0.
By diﬀerentiation it follows that the pair (M1, B1) has probability density
−2ϕ′(2x −y), where ϕ denotes the standard normal density. Changing vari-
ables, we may conclude that (M1, M1−B1) has density −2ϕ′(x+y), x, y ≥0.
Thus, both M1 and M1 −B1 have density 2ϕ(x), x ≥0.
✷
To prepare for the next main result, we shall derive another elementary
sample path property.
Lemma 11.15 (local extremes) The local maxima and minima of a Brow-
nian motion or bridge are a.s. distinct.
Proof: Let B be a Brownian motion, and ﬁx any intervals I = [a, b] and
J = [c, d] with b < c. Write
sup
t∈J Bt −sup
t∈I Bt = sup
t∈J (Bt −Bc) + (Bc −Bb) −sup
t∈I (Bt −Bb).
Here the second term on the right has a diﬀuse distribution, and by inde-
pendence the same thing is true for the whole expression. In particular, the
diﬀerence on the left is a.s. nonzero. Since I and J are arbitrary, this proves
the result for local maxima. The case of local minima and the mixed case
are similar.
The result for the Brownian bridge B◦follows from that for Brownian
motion, since the distributions of the two processes are equivalent (mutually
absolutely continuous) on any interval [0, t] with t < 1. To see this, construct
from B and B◦the corresponding “bridges”
Xs = Bs −s
t Bt,
Ys = B◦
s −s
t B◦
t ,
s ∈[0, t],

208
Foundations of Modern Probability
and check that Bt⊥⊥X
d= Y ⊥⊥B◦
t . The stated equivalence now follows from
the fact that N(0, t) ∼N(0, t(1 −t)) when t ∈[0, 1).
✷
The next result involves the arcsine law, which may be deﬁned as the
distribution of ξ = sin2 α when α is U(0, 2π). The name comes from the fact
that
P{ξ ≤t} = P

| sin α| ≤
√
t

= 2
π arcsin
√
t,
t ∈[0, 1].
Note that the arcsine distribution is symmetric around 1
2, since
ξ = sin2 α d= cos2 α = 1 −sin2 α = 1 −ξ.
The following celebrated result exhibits three interesting functionals of Brow-
nian motion, all of which are arcsine distributed.
Theorem 11.16 (arcsine laws, L´evy) For a Brownian motion B on [0, 1]
with maximum M1, these random variables are all arcsine distributed:
τ1 = λ{t; Bt > 0};
τ2 = inf{t; Bt = M1};
τ3 = sup{t; Bt = 0}.
It is interesting to compare the relations τ1
d= τ2
d= τ3 with the discrete-
time versions obtained in Theorem 8.11 and Corollary 9.20. In Theorems
12.11 and 13.21, the arcsine laws are extended by approximation to appro-
priate random walks and L´evy processes.
Proof: To see that τ1
d= τ2, let n ∈N, and note that by Corollary 9.20
n−1
k≤n1{Bk/n > 0} d= n−1 min{k ≥0; Bk/n = maxj≤nBj/n}.
By Lemma 11.15 the right-hand side tends a.s. to τ2 as n →∞. To see that
the left-hand side converges to τ1, we may conclude from Lemma 11.8 that
λ{t ∈[0, 1]; Bt > 0} + λ{t ∈[0, 1]; Bt < 0} = 1 a.s.
It remains to note that, for any open set G ⊂[0, 1],
lim inf
n→∞n−1 
k≤n1G(k/n) ≥λG.
For i = 2, ﬁx any t ∈[0, 1], let ξ and η be independent N(0, 1), and let
α be U(0, 2π). Using Proposition 11.13 and the circular symmetry of the
distribution of (ξ, η), we get
P{τ2 ≤t}
=
P{sups≤t(Bs −Bt) ≥sups≥t(Bs −Bt)}
=
P{|Bt| ≥|B1 −Bt|} = P{tξ2 ≥(1 −t)η2}
=
P

η2
ξ2 + η2 ≤t

= P{sin2 α ≤t}.

11. Gaussian Processes and Brownian Motion
209
For i = 3, we may write
P{τ3 < t}
=
P{sups≥tBs < 0} + P{infs≥tBs > 0}
=
2P{sups≥t(Bs −Bt) < −Bt} = 2P{|B1 −Bt| < Bt}
=
P{|B1 −Bt| < |Bt|} = P{τ2 ≤t}.
✷
The ﬁrst two arcsine laws have the following counterparts for the Brow-
nian bridge.
Theorem 11.17 (uniform laws) For a Brownian bridge B with maximum
M1, these random variables are both U(0, 1):
τ1 = λ{t; Bt > 0};
τ2 = inf{t; Bt = M1}.
Proof: The relation τ1
d= τ2 may be proved in the same way as for Brow-
nian motion. To see that τ2 is U(0, 1), write (x) = x −[x], and consider for
each u ∈[0, 1] the process Bu
t = B(u+t) −Bu, t ∈[0, 1]. It is easy to check
that Bu
d= B for each u, and further that the maximum of Bu occurs at
(τ2 −u). By Fubini’s theorem we hence obtain for any t ∈[0, 1]
P{τ2 ≤t} =

 1
0 P{(τ2 −u) ≤t}du = E λ{u; (τ2 −u) ≤t} = t.
✷
From Theorem 11.5 we note that t−cBt →0 a.s. as t →0 for any c ∈[0, 1
2).
The following classical result gives the exact growth rate of Brownian motion
at 0 and ∞. Extensions to random walks and renewal processes are obtained
in Corollaries 12.8 and 12.14.
Theorem 11.18 (laws of the iterated logarithm, Khinchin) For a Brownian
motion B in R, we have a.s.
lim sup
t→0
Bt

2t log log(1/t)
= lim sup
t→∞
Bt
√2t log log t = 1.
Proof: The Brownian inversion ˜Bt = tB1/t of Lemma 11.6 converts the
two formulas into one another, so it is enough to prove the result for t →∞.
Then we note that as u →∞

 ∞
u
e−x2/2dx ∼u−1

 ∞
u
xe−x2/2dx = u−1e−u2/2.
By Proposition 11.13 we hence obtain, uniformly in t > 0,
P{Mt > ut1/2} = 2P{Bt > ut1/2} ∼(2/π)1/2u−1e−u2/2,
where Mt = sups≤t Bs. Writing ht = (2t log log t)1/2, we get for any r > 1
and c > 0
P{M(rn) > ch(rn−1)} <
⌢n−c2/r(log n)−1/2,
n ∈N.

210
Foundations of Modern Probability
Fixing c > 1 and choosing r < c2, it follows by the Borel–Cantelli lemma
that
P{lim supt→∞(Bt/ht) > c} ≤P{M(rn) > ch(rn−1) i.o.} = 0,
which shows that lim supt→∞(Bt/ht) ≤1 a.s.
To prove the reverse inequality, we may write
P{B(rn) −B(rn−1) > ch(rn)} >
⌢n−c2r/(r−1)(log n)−1/2,
n ∈N.
Taking c = {(r −1)/r}1/2, we get by the Borel–Cantelli lemma
lim sup
t→∞
Bt −Bt/r
ht
≥lim sup
n→∞
B(rn) −B(rn−1)
h(rn)
≥(r −1
r
)
1/2 a.s.
The upper bound obtained earlier yields lim supt→∞(−Bt/r/ht) ≤r−1/2, and
combining the two estimates gives
lim sup
t→∞
Bt
ht
≥(1 −r−1)1/2 −r−1/2 a.s.
Here we may ﬁnally let r →∞to obtain lim supt→∞(Bt/ht) ≥1 a.s.
✷
In the proof of Theorem 11.5 we constructed a Brownian motion B from
an isonormal Gaussian process η on L2(R+, λ) such that Bt = η1[0,t] a.s. for
all t ≥0. If instead we are starting from a Brownian motion B on R+, the
existence of an associated isonormal Gaussian process η may be inferred from
Theorem 5.10. Since every function h ∈L2(R+, λ) can be approximated by
simple step functions, as in the proof of Lemma 1.33, we note that the random
variables ηh are a.s. unique. We shall see how they can also be constructed
directly from B as suitable Wiener integrals
 hdB. As already noted, the
latter fail to exist in the pathwise Stieltjes sense, and so a diﬀerent approach
is needed.
As a ﬁrst step, we may consider the class S of simple step functions of
the form
ht =

j≤naj1(tj−1,tj](t),
t ≥0,
where n ∈Z+, 0 = t0 < · · · < tn, and a1, . . . , an ∈R. For such integrands h,
we may deﬁne the integral in the obvious way as
ηh =

 ∞
0
htdBt = Bh =

j≤naj(Btj −Btj−1).
Here ηh is clearly centered Gaussian with variance
E(ηh)2 =

j≤na2
j(tj −tj−1) =

 ∞
0
h2
tdt = ∥h∥2,
where ∥h∥denotes the norm in L2(R+, λ). Thus, the integration h →ηh =
 hdB deﬁnes a linear isometry from S ⊂L2(R+, λ) into L2(Ω, P).

11. Gaussian Processes and Brownian Motion
211
Since S is dense in L2(R+, λ), we may extend the integral by continuity
to a linear isometry h →ηh =
 hdB from L2(λ) to L2(P). Here ηh is again
centered Gaussian for every h ∈L2(λ), and by linearity the whole process
h →ηh is then Gaussian. By a polarization argument it is also clear that
the integration preserves inner products, in the sense that
E(ηh ηk) =

 ∞
0
htktdt = ⟨h, k⟩,
h, k ∈L2(λ).
We shall consider two general ways of representing stationary Gaussian
processes in terms of Wiener integrals ηh. Here a complex notation is conve-
nient. By a complex-valued, isonormal Gaussian process on a (real) Hilbert
space H we mean a process ζ = ξ + iη on H such that ξ and η are indepen-
dent, real-valued, isonormal Gaussian processes on H. For any f = g + ih
with g, h ∈H, we deﬁne ζf = ξg −ηh + i(ξh + ηg).
Now let X be a stationary, centered Gaussian process on R with co-
variance function rt = E XsXs+t, s, t ∈R. We know that r is nonnegative
deﬁnite, and it is further continuous whenever X is continuous in probability.
In that case Bochner’s theorem yields a unique spectral representation
rt =

 ∞
−∞eitxµ(dx),
t ∈R,
where the spectral measure µ is a bounded, symmetric measure on R.
The following result gives a similar spectral representation of the process
X itself. By a diﬀerent argument, the result extends to suitable non-Gaussian
processes. As usual, we assume that the basic probability space is rich enough
to support the required randomization variables.
Proposition 11.19 (spectral representation, Stone, Cram´er) Let X be an
L2-continuous, stationary, centered Gaussian process on R with spectral mea-
sure µ. Then there exists a complex, isonormal Gaussian process ζ on L2(µ)
such that
Xt = ℜ

 ∞
−∞eitxdζx a.s.,
t ∈R.
(5)
Proof: Denoting the right-hand side of (5) by Y , we may compute
E YsYt
=
E

(cos sx dξx −sin sx dηx)

(cos tx dξx −sin tx dηx)
=

(cos sx cos tx −sin sx sin tx)µ(dx)
=

cos(s −t)x µ(dx) =

ei(s−t)xµ(dx) = rs−t.
Since both X and Y are centered Gaussian, Lemma 11.1 shows that Y
d= X.
Now both X and ζ are continuous and deﬁned on the separable spaces L2(X)
and L2(µ), and so they may be regarded as random elements in suitable Pol-
ish spaces. The a.s. representation in (5) then follows by Theorem 5.10.
✷

212
Foundations of Modern Probability
Another useful representation may be obtained under suitable regularity
conditions on the spectral measure µ.
Proposition 11.20 (moving average representation) Let X be an L2-con-
tinuous, stationary, centered Gaussian process on R with absolutely contin-
uous spectral measure µ. Then there exist an isonormal Gaussian process η
on L2(R, λ) and some function f ∈L2(λ) such that
Xt =

 ∞
−∞ft−sdηs a.s.,
t ∈R.
(6)
Proof: Fix a symmetric density g ≥0 of µ, and deﬁne h = g1/2. Then
h ∈L2(λ), and we may introduce the Fourier transform in the sense of
Plancherel,
fs = ˆhs = (2π)−1/2 lim
a→∞

 a
−a eisxhxdx,
s ∈R,
(7)
which is again real valued and square integrable. For each t ∈R the function
kx = e−itxhx has Fourier transform ˆks = fs−t, and so by Parseval’s relation
rt =

 ∞
−∞eitxh2
xdx =

 ∞
−∞hx¯kxdx =

 ∞
−∞fsfs−tds.
(8)
Now consider any isonormal Gaussian process η on L2(λ). For f as in (7), we
may deﬁne a process Y on R by the right-hand side of (6). Using (8), we get
E YsYs+t = rt for arbitrary s, t ∈R, and so Y
d= X by Lemma 11.1. Again
an appeal to Theorem 5.10 yields the desired a.s. representation of X.
✷
For an example, we may consider a moving average representation of
the stationary Ornstein–Uhlenbeck process. Then introduce an isonormal
Gaussian process η on L2(R, λ) and deﬁne
Xt =

 t
−∞es−tdηs,
t ≥0.
The process X is clearly centered Gaussian, and we get
rs,t = E XsXt =

 s∧t
−∞eu−seu−tdu = 1
2e−|s−t|,
s, t ∈R,
as desired. The Markov property of X follows most easily from the fact that
Xt = es−tXs +

 t
s eu−tdηu,
s ≤t.
We proceed to introduce multiple integrals In = η⊗n with respect to an
isonormal Gaussian process η on a separable Hilbert space H. Without loss of
generality, we may then take H to be of the form L2(S, µ). In that case H⊗n
can be identiﬁed with L2(Sn, µ⊗n), where µ⊗n denotes the n-fold product

11. Gaussian Processes and Brownian Motion
213
measure µ ⊗· · · ⊗µ, and the tensor product 
k≤n hk = h1 ⊗· · · ⊗hn of the
functions h1, . . . , hn ∈H is equivalent to the function h1(t1) · · · hn(tn) on Sn.
Recall that for any ONB e1, e2, . . . in H, the tensor products

j≤n ekj with
arbitrary k1, . . . , kn ∈N form an ONB in H⊗n.
We may now state the basic existence and uniqueness result for the inte-
grals In.
Theorem 11.21 (multiple stochastic integrals, Wiener, Itˆo)
Let η be an
isonormal Gaussian process on some separable Hilbert space H. Then for
every n ∈N there exists a unique continuous linear mapping In : H⊗n →
L2(P) such that a.s.
In

k≤n
hk =

k≤n
ηhk,
h1, . . . , hn ∈H orthogonal.
Here the uniqueness means that Inh is a.s. unique for every h, and the
linearity means that In(af + bg) = aInf + bIng a.s. for any a, b ∈R and
f, g ∈H⊗n. Note in particular that I1h = ηh a.s. For consistency, we deﬁne
I0 as the identity mapping on R.
For the proof we may clearly assume that H = L2([0, 1], λ). Let En denote
the class of elementary functions of the form
f =

j≤m
cj

k≤n
1Ak
j ,
(9)
where the sets A1
j, . . . , An
j ∈B[0, 1] are disjoint for each j ∈{1, . . . , m}. The
indicator functions 1Ak
j are then orthogonal for ﬁxed j, and we need to take
Inf =

j≤m
cj

k≤n
ηAk
j,
(10)
where ηA = η1A. From the linearity in each factor it is clear that the value
of Inf is independent of the choice of representation (9) for f.
To extend the deﬁnition of In to the entire space L2(Rn
+, λ⊗n), we need
two lemmas. For any function f on Rn
+, we may introduce the symmetrization
˜f(t1, . . . , tn) = (n!)−1
pf(tp1, . . . , tpn),
t1, . . . , tn ∈R+,
where the summation extends over all permutations p of {1, . . . , n}. The
following result gives the basic L2-structure, which later carries over to the
general integrals.
Lemma 11.22 (isometry) The elementary integrals Inf deﬁned by (10) are
orthogonal for diﬀerent n and satisfy
E(Inf)2 = n!∥˜f∥2 ≤n!∥f∥2,
f ∈En.
(11)

214
Foundations of Modern Probability
Proof: The second relation in (11) follows from Minkowski’s inequality.
To prove the remaining assertions, we may ﬁrst reduce to the case when all
sets Ak
j are chosen from some ﬁxed collection of disjoint sets B1, B2, . . . . For
any ﬁnite index sets J ̸= K in N, we note that
E

j∈J
ηBj

k∈K
ηBk =

j∈J∩K
E(ηBj)2

j∈J∆K
EηBj = 0.
This proves the asserted orthogonality. Since clearly ⟨f, g⟩= 0 when f and
g involve diﬀerent index sets, it further reduces the proof of the isometry in
(11) to the case when all terms in f involve the same sets B1, . . . , Bn, though
in possibly diﬀerent order. Since Inf = In ˜f, we may further assume that
f = 
k 1Bk. But then
E(Inf)2 =

kE(ηBk)2 =

kλBk = ∥f∥2 = n!∥˜f∥2,
where the last relation holds since, in the present case, the permutations of
f are orthogonal.
✷
To extend the integral, we need to show that the elementary functions
are dense in L2(λ⊗n).
Lemma 11.23 (approximation) The set En is dense in L2(λ⊗n).
Proof: By a standard argument based on monotone convergence and a
monotone class argument, any function f ∈L2(λ⊗n) can be approximated by
linear combinations of products 
k≤n 1Ak, and so it is enough to approximate
functions f of the latter type. Then divide [0, 1] for each m into 2m intervals
Bmj of length 2−m, and deﬁne
fm = f

j1,...,jn

k≤n
1Bm,jk,
(12)
where the summation extends over all collections of distinct indices j1, . . . , jn
∈{1, . . . , 2m}. Here fm ∈En for each m, and the sum in (12) tends to 1 a.e.
λ⊗n. Thus, by dominated convergence fm →f in L2(λ⊗n).
✷
By the last two lemmas, In is deﬁned as a uniformly continuous map-
ping on a dense subset of L2(λ⊗n), and so it extends by continuity to all
of L2(λ⊗n), with preservation of both the linearity and the norm relations
in (11). To complete the proof of Theorem 11.21, it remains to show that
In

k≤n hk =

k ηhk for any orthogonal functions h1, . . . , hn ∈L2(λ). This is
an immediate consequence of the following lemma, where for any f ∈L2(λ⊗n)
and g ∈L2(λ) we are writing
(f ⊗1 g)(t1, . . . , tn−1) =

f(t1, . . . , tn)g(tn)dtn.

11. Gaussian Processes and Brownian Motion
215
Lemma 11.24 (recursion) For any f ∈L2(λ⊗n) and g ∈L2(λ) with n ∈N,
we have
In+1(f ⊗g) = Inf · ηg −nIn−1( ˜f ⊗1 g).
(13)
Proof: By Fubini’s theorem and the Cauchy–Buniakowski inequality,
∥f ⊗g∥= ∥f∥∥g∥,
∥˜f ⊗1 g∥≤∥˜f∥∥g∥≤∥f∥∥g∥.
Hence, the two sides of (13) are continuous in probability in both f and g,
and it is enough to prove the formula for f ∈En and g ∈E1. By the linearity
of each side we may next reduce to the case when f = 
k≤n 1Ak and g = 1A,
where A1, . . . , An are disjoint and either A ∩

k Ak = ∅or A = A1. In the
former case we have ˜f ⊗1 g = 0, so (13) is immediate from the deﬁnitions.
In the latter case, (13) becomes
In+1(A2 × A2 × · · · × An) = {(ηA)2 −λA}ηA2 · · · ηAn.
(14)
Approximating 1A2 as in Lemma 11.23 by functions fm ∈E2 with support in
A2, it is clear that the left-hand side equals I2A2 ηA2 · · · ηAn. This reduces
the proof of (14) to the two-dimensional version I2A2 = (ηA)2 −λA. To
prove the latter, we may divide A for each m into 2m subsets Bmj of measure
≤2−m, and note as in Theorem 11.9 and Lemma 11.23 that
(ηA)2 =

i(ηBmi)2 +

i̸=jηBmi ηBmj →λA + I2A2 in L2.
✷
The last lemma will be used to derive an explicit representation of the
integrals In in terms of the Hermite polynomials p0, p1, . . . . The latter are
deﬁned as orthogonal polynomials of degrees 0, 1, . . . with respect to the
standard Gaussian distribution on R.
This condition determines each pn
up to a normalization, which may be chosen for convenience such that the
leading coeﬃcient equals one. The ﬁrst few polynomials are then
p0(x) = 1;
p1(x) = x;
p2(x) = x2 −1;
p3(x) = x3 −3x;
. . . .
Theorem 11.25 (orthogonal representation, Itˆo)
On a separable Hilbert
space H, let η be an isonormal Gaussian process with associated multiple Wie-
ner–Itˆo integrals I1, I2, . . . . Then for any orthonormal elements e1, . . . , em ∈
H and integers n1, . . . , nm ≥1 with sum n, we have
In

j≤m
e
⊗nj
j
=

j≤m
pnj(ηej).
Using the linearity of In and writing ˆh = h/∥h∥, it is seen that the stated
formula is equivalent to the factorization
In

j≤m
h
⊗nj
j
=

j≤m
Injh
⊗nj
j
,
h1, . . . , hk ∈H orthogonal,
(15)

216
Foundations of Modern Probability
together with the representation of the individual factors
Inh⊗n = ∥h∥npn(ηˆh),
h ∈H \ {0}.
(16)
Proof: We shall prove (15) by induction on n. Then assume the rela-
tion to hold for all integrals up to order n, ﬁx any orthonormal elements
h, h1, . . . , hm ∈H and integers k, n1, . . . , nm ∈N with sum n + 1, and write
f = 
j≤m h
⊗nj
j
. By Lemma 11.24 and the induction hypothesis,
In+1(f ⊗h⊗k)
=
In(f ⊗h⊗(k−1)) · ηh −(k −1)In−1(f ⊗h⊗(k−2))
=
(In−k+1f)

Ik−1h⊗(k−1) · ηh −(k −1)Ik−2h⊗(k−2)
=
In−k+1f · Ikh⊗k.
Using the induction hypothesis again, we obtain the desired extension to
In+1.
It remains to prove (16) for an arbitrary element h ∈H with ∥h∥= 1.
Then conclude from Lemma 11.24 that
In+1h⊗(n+1) = Inh⊗n · ηh −nIn−1h⊗(n−1),
n ∈N.
Since I01 = 1 and I1h = ηh, it is seen by induction that Inh⊗n is a polynomial
in ηh of degree n and with leading coeﬃcient 1. By the deﬁnition of Hermite
polynomials, it remains to show that the integrals Inh⊗n for diﬀerent n are
orthogonal, which holds by Lemma 11.22.
✷
Given an isonormal Gaussian process η on some separable Hilbert space
H, we may introduce the space L2(η) = L2(Ω, σ{η}, P) of η-measurable
random variables ξ with Eξ2 < ∞. The nth polynomial chaos Pn is deﬁned
as the closed linear subspace generated by all polynomials of degree ≤n in
the random variables ηh, h ∈H. For each n ∈Z+ we may further introduce
the nth homogeneous chaos Hn, consisting of all integrals Inf, f ∈H⊗n.
The relationship between the mentioned spaces is clariﬁed by the following
result. As usual, we are writing ⊕and ⊖for direct sums and orthogonal
complements, respectively.
Theorem 11.26 (chaos expansion, Wiener) On a separable Hilbert space
H, let η be an isonormal Gaussian process with associated polynomial and
homogeneous chaoses Pn and Hn, respectively. Then the Hn are orthogonal,
closed, linear subspaces of L2(η), satisfying
Pn =
n
 
k=0
Hk, n ∈Z+;
L2(η) =
∞
 
n=0
Hn.
(17)
Furthermore, every ξ ∈L2(η) has a unique a.s. representation ξ =
	
n Infn
with symmetric elements fn ∈H⊗n, n ≥0.

11. Gaussian Processes and Brownian Motion
217
In particular, we note that H0 = P0 = R and
Hn = Pn ⊖Pn−1,
n ∈N.
Proof: The properties in Lemma 11.22 extend to arbitrary integrands,
and so the spaces Hn are mutually orthogonal, closed, linear subspaces of
L2(η). From Lemma 11.23 or Theorem 11.25 it is further seen that Hn ⊂Pn.
Conversely, let ξ be an nth-degree polynomial in the variables ηh. We may
then choose some orthonormal elements e1, . . . , em ∈H such that ξ is an
nth-degree polynomial in ηe1, . . . , ηem. Since any power (ηej)k is a linear
combination of the variables p0(ηej), . . . , pk(ηej), Theorem 11.25 shows that
ξ is a linear combination of multiple integrals Ikf with k ≤n, which means
that ξ ∈!
k≤n Hk. This proves the ﬁrst relation in (17).
To prove the second relation, let ξ ∈L2(η) ⊖
!
n Hn.
In particular,
ξ⊥(ηh)n for every h ∈H and n ∈Z+. Since
	
n |ηh|n/n! = e|ηh| ∈L2, the
series eiηh =
	
n(iηh)n/n! converges in L2, and we get ξ⊥eiηh for every h ∈H.
By the linearity of the integral ηh, we hence obtain for any h1, . . . , hn ∈H,
n ∈N,
E

ξ exp

k≤niukηhk

= 0,
u1, . . . , un ∈R.
Applying the uniqueness theorem for characteristic functions to the distribu-
tions of (ηh1, . . . , ηhn) under the bounded measures µ± = E[ξ±; ·], we may
conclude that
E[ξ; (ηh1, . . . , ηhn) ∈B] = 0,
B ∈B(Rn).
By a monotone class argument, this extends to E[ξ; A] = 0 for arbitrary
A ∈σ{η}, and since ξ is η-measurable, it follows that ξ = E[ξ|η] = 0 a.s.
The proof of (17) is then complete.
In particular, any element ξ ∈L2(η) has an orthogonal expansion
ξ =

n≥0Infn =

n≥0In ˜fn,
for some elements fn ∈H⊗n with symmetric versions ˜fn, n ∈Z+. Now as-
sume that also ξ = 	
n Ingn. Projecting onto Hn and using the linearity of In,
we get In(gn −fn) = 0. By the isometry in (11) it follows that ∥˜gn −˜fn∥= 0,
and so ˜gn = ˜fn.
✷
Exercises
1.
Let ξ1, . . . , ξn be i.i.d. N(m, σ2).
Show that the random variables
¯ξ = n−1 	
k ξk and s2 = (n −1)−1 	
k(ξk −¯ξ)2 are independent and that
(n −1)s2
d=
	
k<n(ξk −m)2. (Hint: Use the symmetry in Proposition 11.2,
and no calculations.)

218
Foundations of Modern Probability
2. For a Brownian motion B, put tnk = k2−n, and deﬁne ξ0,k = Bk−Bk−1
and ξnk = Btn,2k−1 −1
2(Btn−1,k−1 + Btn−1,k), k, n ≥1. Show that the ξnk are
independent Gaussian. Use this fact to construct a Brownian motion from a
sequence of i.i.d. N(0, 1) random variables.
3. Let B be a Brownian motion on [0, 1], and deﬁne Xt = Bt−tB1. Show
that X⊥⊥B1. Use this fact to express the conditional distribution of B, given
B1, in terms of a Brownian bridge.
4. Combine the transformations in Lemma 11.6 with the Brownian scal-
ing c−1B(c2t) to construct a family of transformations preserving the distri-
bution of a Brownian bridge.
5. Show that the Brownian bridge is an inhomogeneous Markov process.
(Hint: Use the transformations in Lemma 11.6 or verify the condition in
Proposition 11.7.)
6. Let B = (B1, B2) be a Brownian motion in R2, and consider some
times tnk as in Theorem 11.9. Show that
	
k(B1
tn,k −B1
tn,k−1)(B2
tn,k −B2
tn,k−1)
→0 in L2 or a.s., respectively. (Hint: Reduce to the case of the quadratic
variation.)
7. Use Theorem 6.27 to construct an rcll version B of Brownian motion.
Then show as in Theorem 11.9 that B has quadratic variation [B]t ≡t, and
conclude that B is a.s. continuous.
8. For a Brownian motion B, show that inf{t > 0; Bt > 0} = 0 a.s. (Hint:
Conclude from Kolmogorov’s 0–1 law that the stated event has probability
0 or 1. Alternatively, use Theorem 11.18.)
9. For a Brownian motion B, deﬁne τa = inf{t > 0; Bt = a}. Compute
the density of the distribution of τa for a ̸= 0, and show that Eτa = ∞.
(Hint: Use Proposition 11.13.)
10. For a Brownian motion B, show that Zt = exp(cBt −1
2c2t) is a mar-
tingale for every c. Use optional sampling to compute the Laplace transform
of τa above, and compare with the preceding result.
11. (Paley, Wiener, and Zygmund) Show that Brownian motion B is a.s.
nowhere Lipschitz continuous, and hence nowhere diﬀerentiable. (Hint: If B
is Lipschitz at t < 1, there exist some K, δ > 0 such that |Br −Bs| ≤2hK for
all r, s ∈(t −h, t + h) with h < δ. Apply this to three consecutive n-dyadic
intervals (r, s) around t.)
12. Reﬁne the preceding argument to show that B is a.s. nowhere H¨older
continuous with exponent c > 1
2.
13. Show that the local maxima of a Brownian motion are a.s. dense in
R and that the corresponding times are a.s. dense in R+. (Hint: Use the
preceding result.)
14. Show by a direct argument that lim supt t−1/2Bt = ∞a.s. as t →0
and ∞, where B is a Brownian motion. (Hint: Use Kolmogorov’s 0–1 law.)

11. Gaussian Processes and Brownian Motion
219
15. Show that the law of the iterated logarithm for Brownian motion at
0 remains valid for the Brownian bridge.
16. Show for a Brownian motion B in Rd that the process |B| satisﬁes
the law of the iterated logarithm at 0 and ∞.
17. Let ξ1, ξ2, . . . be i.i.d. N(0, 1). Show that lim supn(2 log n)−1/2ξn = 1
a.s.
18. For a Brownian motion B, show that Mt = t−1Bt is a reverse martin-
gale, and conclude that t−1Bt →0 a.s. and in Lp, p > 0, as t →∞. (Hint:
The limit is degenerate by Kolmogorov’s 0–1 law.) Deduce the same result
from Theorem 9.8.
19. For a Brownian bridge B, show that Mt = (1 −t)−1Bt is a martingale
on [0, 1). Check that M is not L1-bounded.
20. Let In be the n-fold Wiener–Itˆo integral w.r.t. Brownian motion B
on R+. Show that the process Mt = In(1[0,t]n) is a martingale. Express M in
terms of B, and compute the expression for n = 1, 2, 3. (Hint: Use Theorem
11.25.)
21.
Let η1, . . . , ηn be independent, isonormal Gaussian processes on a
separable Hilbert space H. Show that there exists a unique continuous linear
mapping 
k ηk from H⊗n to L2(P) such that

k ηk

k hk =

k ηkhk a.s. for
all h1, . . . , hn ∈H. Also show that

k ηk is an isometry.

Chapter 12
Skorohod Embedding
and Invariance Principles
Embedding of random variables; approximation of random walks;
functional central limit theorem; law of the iterated logarithm;
arcsine laws; approximation of renewal processes; empirical dis-
tribution functions; embedding and approximation of martingales
In Chapter 4 we used analytic methods to derive criteria for a sum of inde-
pendent random variables to be approximately Gaussian. Though this may
remain the easiest approach to the classical limit theorems, the results are
best understood when viewed as consequences of some general approximation
theorems for random processes. The aim of this chapter is to develop a purely
probabilistic technique, the so-called Skorohod embedding, for deriving such
functional limit theorems.
In the simplest setting, we may consider a random walk (Sn) based on
some i.i.d. random variables ξk with mean 0 and variance 1. In this case there
exist a Brownian motion B and some optional times τ1 ≤τ2 ≤· · · such that
Sn = Bτn a.s. for every n. For applications it is essential to choose the τn such
that the diﬀerences ∆τn are again i.i.d. with mean one. The step process S[t]
will then be close to the path of B, and many results for Brownian motion
carry over, at least approximately, to the random walk. In particular, the
procedure yields versions for random walks of the arcsine laws and the law
of the iterated logarithm.
From the statements for random walks, similar results may be deduced
rather easily for various related processes. In particular, we shall derive a
functional central limit theorem and a law of the iterated logarithm for re-
newal processes, and we shall also see how suitably normalized versions of
the empirical distribution functions from an i.i.d. sample can be approxi-
mated by a Brownian bridge. For an extension in another direction, we shall
obtain a version of the Skorohod embedding for general L2-martingales and
show how any suitably time-changed martingale with small jumps can be
approximated by a Brownian motion.
The present exposition depends in many ways on material from previous
chapters. Thus, we shall rely on the basic theory of Brownian motion as set
forth in Chapter 11. We shall also make frequent use of ideas and results from
Chapter 6 on martingales and optional times. Finally, occasional references
220

12. Skorohod Embedding and Invariance Principles
221
will be made to Chapter 3 for empirical distributions, to Chapter 5 for the
transfer theorem, to Chapter 8 for random walks and renewal processes, and
to Chapter 10 for the Poisson process.
More general approximations and functional limit theorems are obtained
by diﬀerent methods in Chapters 13, 14, and 17. We also note the close
relationship between the present approximation result for martingales with
small jumps and the time-change results for continuous local martingales in
Chapter 16.
To clarify the basic ideas, we begin with a detailed discussion of the
classical Skorohod embedding for random walks. The main result in this
context is the following.
Theorem 12.1 (embedding of random walk, Skorohod) Let ξ1, ξ2, . . . be i.i.d.
random variables with mean 0, and put Sn = ξ1+· · ·+ξn. Then there exists a
ﬁltered probability space with a Brownian motion B and some optional times
0 = τ0 ≤τ1 ≤. . . such that (Bτn) d= (Sn) and the diﬀerences ∆τn = τn −τn−1
are i.i.d. with E∆τn = Eξ2
1 and E(∆τn)2 ≤4Eξ4
1.
Here the moment requirements on the diﬀerences ∆τn are crucial for
applications. Without those conditions the statement would be trivially true,
since we could then choose B⊥⊥(ξn) and deﬁne the τn recursively by τn =
inf{t ≥τn−1; Bt = Sn}. In that case Eτn = ∞unless ξ1 = 0 a.s.
The proof of Theorem 12.1 is based on a sequence of lemmas. First we
exhibit some martingales associated with Brownian motion.
Lemma 12.2 (Brownian martingales) For a Brownian motion B, the pro-
cesses Bt, B2
t −t, and B4
t −6tB2
t + 3t2 are all martingales.
Proof: Note that EBt = EB3
t = 0, EB2
t = t, and EB4
t = 3t2. Write F
for the ﬁltration induced by B, let 0 ≤s ≤t, and recall that the process
˜Bt = Bs+t −Bs is again a Brownian motion independent of Fs. Hence,
E[B2
t |Fs] = E[B2
s + 2Bs ˜Bt−s + ˜B2
t−s|Fs] = B2
s + t −s.
Moreover,
E[B4
t |Fs]
=
E[B4
s + 4B3
s ˜Bt−s + 6B2
s ˜B2
t−s + 4Bs ˜B3
t−s + ˜B4
t−s|Fs]
=
B4
s + 6(t −s)B2
s + 3(t −s)2,
and so
E[B4
t −6tB2
t |Fs] = B4
s −6sB2
s + 3(s2 −t2).
✷
By optional sampling, we may derive some useful formulas.
Lemma 12.3 (moment relations) Consider a Brownian motion B and an
optional time τ such that Bτ is bounded. Then
EBτ = 0,
Eτ = EB2
τ,
Eτ 2 ≤4EB4
τ.
(1)

222
Foundations of Modern Probability
Proof: By optional stopping and Lemma 12.2, we get for any t ≥0
EBτ∧t = 0,
E(τ ∧t) = EB2
τ∧t,
(2)
3E(τ ∧t)2 + EB4
τ∧t = 6E(τ ∧t)B2
τ∧t.
(3)
The ﬁrst two relations in (1) follow from (2) by dominated and monotone
convergence as t →∞. In particular, Eτ < ∞, so we may take limits even
in (3) and conclude by dominated and monotone convergence together with
the Cauchy–Buniakovsky inequality that
3Eτ 2 + EB4
τ = 6EτB2
τ ≤6(Eτ 2EB4
τ)1/2.
Writing r = (Eτ 2/EB4
τ)1/2, we get 3r2 + 1 ≤6r. Thus, 3(r −1)2 ≤2, and
ﬁnally, r ≤1 + (2/3)1/2 < 2.
✷
The next result shows how an arbitrary distribution with mean zero can
be expressed as a mixture of centered two-point distributions. For any a ≤
0 ≤b, let νa,b denote the unique probability measure on {a, b} with mean
zero. Clearly, νa,b = δ0 when ab = 0; otherwise,
νa,b = bδa −aδb
b −a
,
a < 0 < b.
It is easy to verify that ν is a probability kernel from R−× R+ to R. For
mappings between two measure spaces, measurability is deﬁned in terms of
the σ-ﬁelds generated by all evaluation maps πB : µ →µB, where B is an
arbitrary set in the underlying σ-ﬁeld.
Lemma 12.4 (randomization) For any distribution µ on R with mean zero,
there exists a distribution µ∗on R−× R+ with µ =
 µ∗(dx dy)νx,y. Here we
may choose µ∗to be a measurable function of µ.
Proof (Chung): Let µ± denote the restrictions of µ to R± \ {0}, deﬁne
l(x) ≡x, and put c =
 ldµ+ = −
 ldµ−. For any measurable function
f : R →R+ with f(0) = 0, we get
c

fdµ
=

ldµ+

fdµ−−

ldµ−

fdµ+
=

 
(y −x)µ−(dx)µ+(dy)

fdνx,y,
and so we may take
µ∗(dx dy) = µ{0}δ0,0(dx dy) + c−1(y −x)µ−(dx)µ+(dy).
The measurability of the mapping µ →µ∗is clear by a monotone class ar-
gument if we note that µ∗(A × B) is a measurable function of µ for arbitrary
A, B ∈B(R).
✷
The embedding in Theorem 12.1 will now be constructed recursively, be-
ginning with the ﬁrst random variable ξ1.

12. Skorohod Embedding and Invariance Principles
223
Lemma 12.5 (embedding of random variable) Fix a probability measure µ
on R with mean 0, let the pair (α, β) have distribution µ∗as in Lemma 12.4,
and let B be an independent Brownian motion. Then τ = inf{t ≥0; Bt ∈
{α, β}} is an optional time for the ﬁltration Ft = σ{α, β; Bs, s ≤t}, and
moreover
P ◦B−1
τ
= µ,
Eτ =

x2µ(dx),
Eτ 2 ≤4

x4µ(dx).
Proof: The process B is clearly an F-Brownian motion, and it is further
seen as in Lemma 6.6 (ii) that the time τ is F-optional. Using Lemma 12.3
and Fubini’s theorem, we get
P ◦B−1
τ
= E P[Bτ ∈· | α, β] = Eνα,β = µ,
Eτ = E E[τ | α, β] = E

x2να,β(dx) =

x2µ(dx),
Eτ 2 = E E[τ 2 | α, β] ≤4E

x4να,β(dx) = 4

x4µ(dx).
✷
Proof of Theorem 12.1: Let µ be the common distribution of the ξn.
Introduce a Brownian motion B and some independent i.i.d. pairs (αn, βn),
n ∈N, with the distribution µ∗of Lemma 12.4.
Deﬁne recursively the
random times 0 = τ0 ≤τ1 ≤· · · by
τn = inf{t ≥τn−1; Bt −Bτn−1 ∈{αn, βn}},
n ∈N.
Here each τn is clearly optional for the ﬁltration Ft = σ{αk, βk, k ≥1; Bt},
t ≥0, and B is an F-Brownian motion. By the strong Markov property at
τn, the process B(n)
t
= Bτn+t −Bτn is then a Brownian motion independent of
Gn = σ{τk, Bτk; k ≤n}. Since moreover (αn+1, βn+1)⊥⊥(B(n), Gn), we obtain
(αn+1, βn+1, B(n))⊥⊥Gn, and so the pairs (∆τn, ∆Bτn) are i.i.d. The remaining
assertions now follow by Lemma 12.5.
✷
The last theorem enables us to approximate the entire random walk by a
Brownian motion. As before, we assume the underlying probability space to
be rich enough to support any randomization variables we may need.
Theorem 12.6 (approximation of random walk, Skorohod, Strassen)
Let
ξ1, ξ2, . . . be i.i.d. random variables with mean 0 and variance 1, and write
Sn = ξ1 + · · · + ξn. Then there exists a Brownian motion B with
t−1/2sups≤t|S[s] −Bs|
P→0,
t →∞,
(4)
and
lim
t→∞
S[t] −Bt
√2t log log t = 0 a.s.
(5)
The proof of (5) requires the following estimate.

224
Foundations of Modern Probability
Lemma 12.7 (rate of continuity) For a Brownian motion B in R, we have
lim
r↓1 lim sup
t→∞
sup
t≤u≤rt
|Bu −Bt|
√2t log log t = 0 a.s.
Proof: Write h(t) = (2t log log t)1/2. It is enough to show that
lim
r↓1 lim sup
n→∞
sup
rn≤t≤rn+1
|Bt −Brn|
h(rn)
= 0 a.s.
(6)
Proceeding as in the proof of Theorem 11.18, we get as n →∞for ﬁxed
r > 1 and c > 0
P

supt∈[rn,rn+1]|Bt −Brn| > ch(rn)

<
⌢
P{B(rn(r −1)) > ch(rn)}
<
⌢
n−c2/(r−1)(log n)−1/2,
where as before a <
⌢b means that a ≤cb for some constant c > 0.
If
c2 > r −1, it is clear from the Borel–Cantelli lemma that the lim sup in (6)
is a.s. bounded by c, and the relation follows as we let r →1.
✷
For the main proof, we need to introduce the modulus of continuity
w(f, t, h) =
sup
r,s≤t, |r−s|≤h
|fr −fs|,
t, h > 0.
Proof of Theorem 12.6: By Theorems 5.10 and 12.1 we may choose a
Brownian motion B and some optional times 0 ≡τ0 ≤τ1 ≤· · · such that
Sn = Bτn a.s. for all n, and the diﬀerences τn −τn−1 are i.i.d. with mean 1.
Then τn/n →1 a.s. by the law of large numbers, so τ[t]/t →1 a.s., and (5)
follows by Lemma 12.7.
Next deﬁne
δt = sup
s≤t |τ[s] −s|,
t ≥0,
and note that the a.s. convergence τn/n →1 implies δt/t →0 a.s. Fix any
t, h, ε > 0, and conclude by the scaling property of B that
P

t−1/2sups≤t|Bτ[s] −Bs| > ε

≤
P{w(B, t + th, th) > εt1/2} + P{δt > th}
=
P{w(B, 1 + h, h) > ε} + P{t−1δt > h}.
Here the right-hand side tends to zero as t →∞and then h →0, and (4)
follows.
✷
As an immediate application of the last theorem, we may extend the law
of the iterated logarithm to suitable random walks.

12. Skorohod Embedding and Invariance Principles
225
Corollary 12.8 (law of the iterated logarithm, Hartman and Wintner) Let
ξ1, ξ2, . . . be i.i.d. random variables with mean 0 and variance 1, and deﬁne
Sn = ξ1 + · · · + ξn. Then
lim sup
n→∞
Sn
√2n log log n = 1 a.s.
Proof: Combine Theorems 11.18 and 12.6.
✷
To derive a weak convergence result, let D[0, 1] denote the space of all
functions on [0, 1] that are right-continuous with left-hand limits (rcll). For
our present needs it is convenient to equip D[0, 1] with the norm ∥x∥=
supt |xt| and the σ-ﬁeld D generated by all evaluation maps πt : x →xt. The
norm is clearly D-measurable, and so the same thing is true for the open
balls Bx,r = {y; ∥x −y∥< r}, x ∈D[0, 1], r > 0. (However, D is strictly
smaller than the Borel σ-ﬁeld induced by the norm.)
Given a process X with paths in D[0, 1] and a mapping f : D[0, 1] →R,
we shall say that f is a.s. continuous at X if X ̸∈Df a.s., where Df is the
set of functions x ∈D[0, 1] where f is discontinuous. (The measurability of
Df is irrelevant here, provided that we interpret the condition in the sense
of inner measure.)
We may now state a functional version of the classical central limit the-
orem.
Theorem 12.9 (functional central limit theorem, Donsker) Let ξ1, ξ2, . . . be
i.i.d. random variables with mean 0 and variance 1, and deﬁne
Xn
t = n−1/2 
k≤nt
ξk,
t ∈[0, 1], n ∈N.
Consider a Brownian motion B on [0, 1], and let f : D[0, 1] →R be measur-
able and a.s. continuous at B. Then f(Xn)
d→f(B).
The result follows immediately from Theorem 12.6 together with the fol-
lowing lemma.
Lemma 12.10 (approximation and convergence) Let X1, X2, . . . and Y1, Y2,
. . . be rcll processes on [0, 1] with Yn
d= Y1 ≡Y for all n and ∥Xn −Yn∥
P→0,
and let f : D[0, 1] →R be measurable and a.s. continuous at Y .
Then
f(Xn)
d→f(Y ).
Proof: Put T = Q ∩[0, 1]. By Theorem 5.10 there exist some processes
X′
n on T such that (X′
n, Y ) d= (Xn, Yn) on T for all n. Then each X′
n is a.s.
bounded and has ﬁnitely many upcrossings of any nondegenerate interval,
and so the process ˜Xn(t) = X′
n(t+) exists a.s. with paths in D[0, 1]. From
the right continuity of paths, it is also clear that ( ˜Xn, Y ) d= (Xn, Yn) on [0, 1]
for every n.

226
Foundations of Modern Probability
To obtain the desired convergence, we note that ∥˜Xn−Y ∥d= ∥Xn−Yn∥
P→
0, and hence f(Xn) d= f( ˜Xn)
P→f(Y ) as in Lemma 3.3.
✷
In particular, we may recover the central limit theorem in Proposition 4.9
by taking f(x) = x1 in Theorem 12.9. We may also obtain results that go
beyond the classical theory, such as for the choice f(x) = supt |xt|. As a less
obvious application, we shall see how the arcsine laws of Theorem 11.16 can
be extended to suitable random walks. Recall that a random variable ξ is
said to be arcsine distributed if ξ d= sin2 α, where α is U(0, 2π).
Theorem 12.11 (arcsine laws, Erd¨os and Kac, Sparre-Andersen) Let (Sn)
be a random walk based on some distribution µ with mean 0 and variance 1,
and deﬁne for n ∈N
τ 1
n
=
n−1	
k≤n1{Sk > 0},
τ 2
n
=
n−1 min{k ≥0; Sk = maxj≤nSj},
τ 3
n
=
n−1 max{k ≤n; SkSn ≤0}.
Then τ i
n
d→τ for i = 1, 2, 3, where τ is arcsine distributed. The results for
i = 1, 2 remain valid for any nondegenerate, symmetric distribution µ.
For the proof, we consider on D[0, 1] the functionals
f1(x)
=
λ{t ∈[0, 1]; xt > 0},
f2(x)
=
inf{t ∈[0, 1]; xt ∨xt−= sups≤1xs},
f3(x)
=
sup{t ∈[0, 1]; xtx1 ≤0}.
The following result is elementary.
Lemma 12.12 (continuity of functionals) The functionals fi are measur-
able. Furthermore, f1 is continuous at x iﬀλ{t; xt = 0} = 0, f2 is continuous
at x iﬀxt ∨xt−has a unique maximum, and f3 is continuous at x if 0 is not
a local extreme of xt or xt−on (0, 1].
Proof of Theorem 12.11: Clearly, τ i
n = fi(Xn) for n ∈N and i = 1, 2, 3,
where
Xn
t = n−1/2S[nt],
t ∈[0, 1], n ∈N.
To prove the ﬁrst assertion, it suﬃces by Theorems 11.16 and 12.9 to show
that each fi is a.s. continuous at B. Thus, we need to verify that B a.s.
satisﬁes the conditions in Lemma 12.12.
For f1 this is obvious, since by
Fubini’s theorem
Eλ{t ≤1; Bt = 0} =

 1
0 P{Bt = 0}dt = 0.
The conditions for f2 and f3 follow easily from Lemma 11.15.

12. Skorohod Embedding and Invariance Principles
227
To prove the last assertion, it is enough to consider τ 1
n since τ 2
n has the
same distribution by Corollary 9.20.
Then we introduce an independent
Brownian motion B and deﬁne
σε
n = n−1
k≤n1{εBk + (1 −ε)Sk > 0},
n ∈N, ε ∈(0, 1].
By the ﬁrst assertion, together with Theorem 8.11 and Corollary 9.20, we
have σε
n
d= σ1
n
d→τ. Since P{Sn = 0} →0, e.g. by Theorem 3.17, we further
note that
lim sup
ε→0
|σε
n −τ 1
n| ≤n−1 
k≤n
1{Sk = 0}
P→0.
Hence, we may choose some constants εn →0 with σεn
n −τ 1
n
P→0, and by
Theorem 3.28 we get τ 1
n
d→τ.
✷
Theorem 12.9 is often referred to as an invariance principle, because the
limiting distribution of f(Xn) is the same for all i.i.d. sequences (ξk) with
mean 0 and variance 1. This fact is often useful for applications, since a
direct computation may be possible for some special choice of distribution,
such as for P{ξk = ±1} = 1
2.
The approximation Theorem 12.6 yields a corresponding result for re-
newal processes, regarded here as nondecreasing step processes.
Theorem 12.13 (approximation of renewal processes) Let N be a renewal
process based on some distribution µ with mean 1 and variance σ2 ∈(0, ∞).
Then there exists a Brownian motion B such that
t−1/2 sup
s≤t |Ns −s −σBs|
P→0,
t →∞,
(7)
and
lim
t→∞
Nt −t −σBt
√2t log log t = 0 a.s.
(8)
Proof: Let τ0, τ1, . . . be the renewal times of N, and introduce the random
walk Sn = n−τn+τ0, n ∈Z+. Choosing a Brownian motion B as in Theorem
12.6, we get
lim
n→∞
Nτn −τn −σBn
√2n log log n
= lim
n→∞
Sn −σBn
√2n log log n = 0 a.s.
Since τn ∼n a.s. by the law of large numbers, we may replace n in the
denominator by τn, and by Lemma 12.7 we may further replace Bn by Bτn.
Hence,
Nt −t −σBt
√2t log log t →0 a.s. along (τn).
To obtain (8), it remains by Lemma 12.7 to show that
τn+1 −τn
√2τn log log τn
→0 a.s.,
which may be seen most easily from Theorem 12.6.

228
Foundations of Modern Probability
From Theorem 12.6 it is further seen that
n−1/2 sup
k≤n |Nτk −τk −σBk| = n−1/2 sup
k≤n |Sk −τ0 −σBk|
P→0,
and by Brownian scaling,
n−1/2w(B, n, 1) d= w(B, 1, n−1) →0.
To get (7), it is then enough to show that
n−1/2supk≤n|τk −τk−1 −1| = n−1/2supk≤n|Sk −Sk−1|
P→0,
which is again clear from Theorem 12.6.
✷
We may now proceed as in Corollary 12.8 and Theorem 12.9 to deduce
an associated law of the iterated logarithm and a weak convergence result.
Corollary 12.14 (limits of renewal processes) Let N be a renewal process
based on some distribution µ with mean 1 and variance σ2 < ∞. Then
lim sup
t→∞
±(Nt −t)
√2t log log t = σ a.s.
If B is a Brownian motion and
Xr
t = Nrt −rt
σr1/2 ,
t ∈[0, 1], r > 0,
then also f(Xr)
d→f(B) as r →∞, for any measurable function f : D[0, 1] →
R that is a.s. continuous at B.
The weak convergence part of the last corollary yields a similar result
for the empirical distribution functions associated with a sequence of i.i.d.
random variables. In this case the asymptotic behavior can be expressed in
terms of a Brownian bridge.
Theorem 12.15 (approximation of empirical distribution functions)
Let
ξ1, ξ2, . . . be i.i.d. random variables with distribution function F and em-
pirical distribution functions ˆF1, ˆF2, . . . . Then there exist some Brownian
bridges B1, B2, . . . with
supx
n1/2{ ˆFn(x) −F(x)} −Bn ◦F(x)

P→0,
n →∞.
(9)
Proof: As in the proof of Proposition 3.24, we may easily reduce the
discussion to the case when the ξn are U(0, 1), and F(t) ≡t on [0, 1]. Then,
clearly,
n1/2( ˆFn(t) −F(t)) = n−1/2
k≤n(1{ξk ≤t} −t),
t ∈[0, 1].

12. Skorohod Embedding and Invariance Principles
229
Now introduce for each n some independent Poisson random variable κn with
mean n, and conclude from Proposition 10.3 that N n
t =
	
k≤κn 1{ξk ≤t} is a
homogeneous Poisson process on [0, 1] with rate n. By Theorem 12.13 there
exist some Brownian motions W n on [0, 1] with
supt≤1
n−1/2(N n
t −nt) −W n
t

P→0.
For the associated Brownian bridges Bn
t = W n
t −tW n
1 we get
supt≤1
n−1/2(N n
t −tN n
1 ) −Bn
t

P→0.
To deduce (9), it is enough to show that
n−1/2supt≤1


k≤|κn−n|(1{ξk ≤t} −t)

P→0.
(10)
Here |κn −n|
P→∞, e.g. by Proposition 4.9, and so (10) holds by Proposition
3.24 with n1/2 replaced by |κn −n|. It remains to note that n−1/2|κn −n| is
tight, since E(κn −n)2 = n.
✷
Our next aim is to establish martingale versions of the Skorohod embed-
ding Theorem 12.1 and the associated approximation Theorem 12.6.
Theorem 12.16 (embedding of martingales) Let (Mn) be a martingale with
M0 = 0 and induced ﬁltration (Gn). Then there exist a Brownian motion B
and associated optional times 0 = τ0 ≤τ1 ≤· · · such that Mn = Bτn a.s. for
all n and, moreover,
E[∆τn|Fn−1]
=
E[(∆Mn)2|Gn−1],
(11)
E[(∆τn)2|Fn−1]
≤
4E[(∆Mn)4|Gn−1],
(12)
where (Fn) denotes the ﬁltration induced by the pairs (Mn, τn).
Proof: Let µ1, µ2, . . . be probability kernels satisfying
P[∆Mn ∈· | Gn−1] = µn(M1, . . . , Mn−1; ·) a.s.,
n ∈N.
(13)
Since the Mn form a martingale, we may assume that µn(x; ·) has mean 0
for all x ∈Rn−1. Deﬁne the associated measures µ∗
n(x; ·) on R2 as in Lemma
12.4, and conclude from the measurability part of the lemma that µ∗
n is a
probability kernel from Rn−1 to R2. Next choose some measurable functions
fn : Rn →R2 as in Lemma 2.22 such that fn(x, ϑ) has distribution µ∗
n(x, ·)
when ϑ is U(0, 1).
Now ﬁx any Brownian motion B′ and some independent i.i.d. U(0, 1)
random variables ϑ1, ϑ2, . . . . Take τ ′
0 = 0, and recursively deﬁne the random
variables αn, βn, and τ ′
n, n ∈N, through the relations
(αn, βn)
=
fn(B′
τ ′
1, . . . , B′
τ ′
n−1, ϑn),
(14)
τ ′
n
=
inf

t ≥τ ′
n−1; B′
t −B′
τ ′
n−1 ∈{αn, βn}

.
(15)

230
Foundations of Modern Probability
Since B′ is a Brownian motion for the ﬁltration Bt = σ{(B′)t, (ϑn)}, t ≥0,
and each τ ′
n is B-optional, the strong Markov property shows that B(n)
t
=
B′
τ ′n+t −B′
τ ′n is again a Brownian motion independent of F′
n = σ{τ ′
k, B′
τ ′
k;
k ≤n}. Since also ϑn+1⊥⊥(B(n), F′
n), we have (B(n), ϑn+1)⊥⊥F′
n. Writing
G′
n = σ{B′
τ ′
k; k ≤n}, it follows easily that
(∆τ ′
n+1, ∆B′
τ ′
n+1)⊥⊥G′nF′
n.
(16)
By (14) and Theorem 5.4 we have
P[(αn, βn) ∈·|G′
n−1] = µ∗
n(B′
τ ′
1, . . . , B′
τ ′
n−1; ·).
(17)
Moreover, B(n−1)⊥⊥(αn, βn, G′
n−1), so B(n−1)⊥⊥G′
n−1(αn, βn) and B(n−1) is con-
ditionally a Brownian motion.
Applying Lemma 12.5 to the conditional
distributions given G′
n−1, we get by (15), (16), and (17)
P[∆B′
τ ′n ∈·|G′
n−1] = µn(B′
τ ′
1, . . . , B′
τ ′
n−1; ·),
(18)
E[∆τ ′
n|F′
n−1] = E[∆τ ′
n|G′
n−1] = E[(∆B′
τ ′n)2|G′
n−1],
(19)
E[(∆τ ′
n)2|F′
n−1] = E[(∆τ ′
n)2|G′
n−1] ≤4E[(∆B′
τ ′n)4|G′
n−1].
(20)
Comparing (13) and (18), it is clear that (B′
τ ′n)
d= (Mn). By Theorem
5.10 we may then choose a Brownian motion B with associated optional
times τ1, τ2, . . . such that
{B, (Mn), (τn)} d= {B′, (B′
τ ′n), (τ ′
n)}.
All a.s. relations between the objects on the right, involving also their con-
ditional expectations given any induced σ-ﬁelds, remain valid for the objects
on the left. In particular, Mn = Bτn a.s. for all n, and relations (19) and (20)
imply the corresponding formulas (11) and (12).
✷
We shall use the last theorem to show how martingales with small jumps
can be approximated by a Brownian motion. For martingales M on Z+, we
may introduce the quadratic variation [M] and predictable quadratic variation
⟨M⟩, given by
[M]n =

k≤n(∆Mk)2,
⟨M⟩n =

k≤nE[(∆Mk)2|Fk−1].
Continuous-time versions of those processes are considered in Chapters 15
and 23.
Theorem 12.17 (approximation of martingales with small jumps) For each
n ∈N, let M n be an Fn-martingale on Z+ with M n
0 = 0 and |∆M n
k | ≤1,
and assume that supk |∆M n
k |
P→0. Deﬁne
Xn
t =

k∆M n
k 1{[M n]k ≤t},
t ∈[0, 1], n ∈N,

12. Skorohod Embedding and Invariance Principles
231
and put ζn = [M n]∞. Then (Xn −Bn)∗
ζn∧1
P→0 for some Brownian motions
Bn. This remains true with [M n] replaced by ⟨M n⟩, and we may further
replace the condition supk |∆M n
k |
P→0 by

kP[|∆M n
k | > ε|Fn
k−1]
P→0,
ε > 0.
(21)
For the proof we need to show that the time scales given by the sequences
(τ n
k ), [M n], and ⟨M n⟩are asymptotically equivalent.
Lemma 12.18 (time-scale comparison)
Let the martingales in Theorem
12.17 be given by M n
k = Bn◦τ n
k a.s., for some Brownian motions Bn with as-
sociated optional times τ n
k as in Theorem 12.16. Put κn
t = inf{k; [M n]k > t}.
Then, as n →∞for ﬁxed t > 0,
sup
k≤κn
t
(|τ n
k −[M n]k| ∨|[M n]k −⟨M n⟩k|)
P→0.
(22)
Proof: By optional stopping, we may assume that [M n] is uniformly
bounded and take the supremum in (22) over all k.
To handle the sec-
ond diﬀerence in (22), we note that Dn = [M n] −⟨M n⟩is a martingale for
each n.
Using the martingale property, Proposition 6.16, and dominated
convergence, we get
E(Dn)∗2
<
⌢
supkE(Dn
k)2 =

kE(∆Dn
k)2
=

kE E[(∆Dn
k)2|Fn
k−1]
≤

kE E[(∆[M n]k)2|Fn
k−1]
=
E

k(∆M n
k )4 <
⌢Esupk(∆M n
k )2 →0,
and so (Dn)∗
P→0. This clearly remains true if each sequence ⟨M n⟩is deﬁned
in terms of the ﬁltration Gn induced by M n.
To complete the proof of (22), it is enough to show, for the latter versions
of ⟨M n⟩, that (τ n −⟨M n⟩)∗
P→0. Then let T n denote the ﬁltration induced
by the pairs (M n
k , τ n
k ), k ∈N, and conclude from (11) that
⟨M n⟩m =

k≤mE[∆τ n
k |T n
k−1],
m, n ∈N.
Hence, ˜Dn = τ n −⟨M n⟩is a T n-martingale. Using (11) and (12), we then
get as before
E( ˜Dn)∗2
<
⌢
supkE( ˜Dn
k)2 =

kE E[(∆˜Dn
k)2|T n
k−1]
≤

kE E[(∆τ n
k )2|T n
k−1]
<
⌢

kE E[(∆M n
k )4|Gn
k−1]
=
E

k(∆M n
k )4 <
⌢Esupk(∆M n
k )2 →0.
✷
The suﬃciency of (21) is a consequence of the following simple estimate.

232
Foundations of Modern Probability
Lemma 12.19 (Dvoretzky) For any ﬁltration F on Z+ and sets An ∈Fn,
n ∈N, we have
P

nAn ≤P

nP[An|Fn−1] > ε

+ ε,
ε > 0.
Proof: Write ξn = 1An and ˆξn = P[An|Fn−1], ﬁx any ε > 0, and deﬁne
τ = inf{n; ˆξ1 + · · · + ˆξn > ε}. Then {τ ≤n} ∈Fn−1 for each n, and so
E

n<τ
ξn =

n
E[ξn; τ > n] =

n
E[ˆξn; τ > n] = E

n<τ
ˆξn ≤ε.
Hence,
P

n
An ≤P{τ < ∞} + E

n<τ
ξn ≤P

nˆξn > ε

+ ε.
✷
Proof of Theorem 12.17: To prove the result for the time-scales [M n], we
may reduce by optional stopping to the case when [M n] ≤2 for all n. For
each n we may choose some Brownian motion Bn and associated optional
times τ n
k as in Theorem 12.16. Then
(Xn −Bn)∗
ζn∧1 ≤w(Bn, 1 + δn, δn),
n ∈N,
where
δn = supk{|τ n
k −[M n]k| + (∆M n
k )2},
and so
E[(Xn −Bn)∗
ζn∧1 ∧1] ≤E[w(Bn, 1 + h, h) ∧1] + P{δn > h}.
Since δn
P→0 by Lemma 12.18, the right-hand side tends to zero as n →∞
and then h →0, and the assertion follows.
In the case of the time-scales ⟨M n⟩, deﬁne κn = inf{k; [M n] > 2}. Then
[M n]κn −⟨M n⟩κn
P→0 by Lemma 12.18, so P{⟨M n⟩κn < 1, κn < ∞} →0,
and we may reduce by optional stopping to the case when [M n] ≤3. The
proof may now be completed as before.
✷
Though the Skorohod embedding has no natural extension to higher di-
mensions, one can still obtain useful multidimensional approximations by
applying the previous results to each component separately. To illustrate the
method, we shall see how suitable random walks in Rd can be approximated
by continuous processes with stationary, independent increments. Extensions
to more general limits are obtained by diﬀerent methods in Corollary 13.20
and Theorem 14.14.
Theorem 12.20 (approximation of random walks in Rd) Consider in Rd a
Brownian motion B and some random walks S1, S2, . . . such that Sn
mn
d→σB1
for some d × d-matrix σ and some integers mn →∞. Then there exist some
processes Xn d= (Sn
[mnt]) with (Xn −σB)∗
t
P→0 for all t ≥0.

12. Skorohod Embedding and Invariance Principles
233
Proof: By Theorem 4.15 we have
max
k≤mnt |∆Sn
k |
P→0,
t ≥0,
and so we may assume that |∆Sn
k | ≤1 for all n and k. Subtracting the means,
we may further assume that ESn
k ≡0. Writing Y n
t
= Sn
[mnt] and applying
Theorem 12.17 in each coordinate, we get w(Y n, t, h)
P→0 as n →∞and
then h →0. Furthermore, w(σB, t, h) →0 a.s. as h →0.
Using Theorem 4.15 in both directions gives Y n
tn
d→σBt as tn →t. By
independence, it follows that (Y n
t1, . . . , Y n
tm)
d→σ(Bt1, . . . , Btm) for all n ∈N
and t1, . . . , tn ∈Q+, and so Y n
d→σB on Q+ by Theorem 3.29. By Theorem
3.30, or more conveniently by Corollary 5.12 and Theorem A2.2, there exist
some rcll processes Xn d= Y n with Xn
t →σBt a.s. for all Q+. For any t, h > 0
we have
E[(Xn −σB)∗
t ∧1]
≤
E

maxj≤t/h|Xn
jh −σBjh| ∧1

+E[w(Xn, t, h) ∧1] + E[w(σB, t, h) ∧1].
Multiplying by e−t, integrating over t > 0, and letting n →∞and then
h →0 along Q+, we get by dominated convergence

 ∞
0
e−tE[(Xn −σB)∗
t ∧1]dt →0.
Hence, by monotonicity, the last integrand tends to zero as n →∞, and so
(Xn −σB)∗
t
P→0 for each t > 0.
✷
Exercise
1. Proceed as in Lemma 12.2 to construct Brownian martingales with
leading terms B3
t and B5
t .
Use multiple Wiener–Itˆo integrals to give an
alternative proof of the lemma, and ﬁnd for each n a martingale with leading
term Bn
t . (Hint: Use Theorem 11.25.)

Chapter 13
Independent Increments
and Inﬁnite Divisibility
Regularity and jump structure; L´evy representation; independent
increments and inﬁnite divisibility; stable processes; character-
istics and convergence criteria; approximation of L´evy processes
and random walks; limit theorems for null arrays; convergence of
extremes
In Chapters 10 and 11 we saw how Poisson processes and Brownian motion
arise as special processes with independent increments. Our present aim is
to study more general processes of this type. Under a mild regularity as-
sumption, we shall derive a general representation of independent-increment
processes in terms of a Gaussian component and a jump component, where
the latter is expressible as a suitably compensated Poisson integral. Of spe-
cial importance is the time-homogeneous case of so-called L´evy processes,
which admit a description in terms of a characteristic triple (a, b, ν), where a
is the diﬀusion rate, b is the drift coeﬃcient, and ν is the L´evy measure that
determines the rates for jumps of diﬀerent sizes.
In the same way that Brownian motion is the basic example of both a
a diﬀusion process and a continuous martingale, the general L´evy processes
constitute the fundamental cases of both Markov processes and general semi-
martingales. As a motivation for the general weak convergence theory of
Chapter 14, we shall further see how L´evy processes serve as the natural
approximations to random walks. In particular, such approximations may
be used to extend two of the arcsine laws for Brownian motion to general
symmetric L´evy processes. Increasing L´evy processes, even called subordi-
nators, play a basic role in Chapter 19, where they appear in representations
of local time and regenerative sets.
The distributions of L´evy processes at ﬁxed times coincide with the in-
ﬁnitely divisible laws, which also arise as the most general limit laws in the
classical limit theorems for null arrays. The special cases of convergence to-
ward Poisson and Gaussian limits were considered in Chapter 4, and now we
shall be able to characterize the convergence toward an arbitrary inﬁnitely
divisible law. Though characteristic functions will still be needed occasion-
ally as a technical tool, the present treatment is more probabilistic in ﬂavor
and involves as crucial steps a centering at truncated means followed by a
compound Poisson approximation.
234

13. Independent Increments and Inﬁnite Divisibility
235
To resume our discussion of general independent-increment processes, say
that a process X in Rd is continuous in probability if Xs
P→Xt whenever
s →t. Let us further say that a function f on R+ or [0, 1] is right-continuous
with left-hand limits (abbreviated as rcll) if the right- and left-hand limits
ft± exist and are ﬁnite and if, moreover, ft+ ≡ft. A process X is said to
be rcll if its paths have this property. In that case only jump discontinuities
may occur, and we say that X has a ﬁxed jump at some time t > 0 if
P{Xt ̸= Xt−} > 0.
The following result gives the basic regularity properties of independent-
increment processes.
A similar result for Feller processes is obtained by
diﬀerent methods in Theorem 17.15.
Theorem 13.1 (regularization, L´evy) Let the process X in Rd be continu-
ous in probability with independent increments. Then X has an rcll version
without ﬁxed jumps.
For the proof we shall use a martingale argument based on the charac-
teristic functions
ϕs,t(u) = E exp{iu(Xt −Xs)},
u ∈Rd, 0 ≤s ≤t.
Note that ϕr,sϕs,t = ϕr,t for any r ≤s ≤t, and put ϕ0,t = ϕt. In order to
construct associated martingales, we need to know that ϕs,t ̸= 0.
Lemma 13.2 (zeros) For any u ∈Rd and s ≤t we have ϕs,t(u) ̸= 0.
Proof: Fix any u ∈Rd and s ≤t. Since X is continuous in probabil-
ity, there exists for any r ≥0 some h > 0 such that ϕr,r′(u) ̸= 0 whenever
|r −r′| < h. By compactness we may then choose ﬁnitely many division
point s = t0 < t1 < · · · < tn = t such that ϕtk−1,tk(u) ̸= 0 for all k, and by
the independence of the increments we get ϕs,t(u) =

k ϕtk−1,tk(u) ̸= 0.
✷
We also need the following deterministic convergence criterion.
Lemma 13.3 (convergence in Rd) Fix any a1, a2, . . . ∈Rd. Then an con-
verges iﬀeiuan converges for almost every u ∈Rd.
Proof: Assume the stated condition. Fix a nondegenerate Gaussian ran-
dom vector η in Rd, and note that exp{itη(am −an)} →1 a.s. as m, n →∞
for ﬁxed t ∈R. By dominated convergence the characteristic function of
η(am −an) tends to 1, and so η(am −an)
P→0 by Theorem 4.3, which implies
am −an →0. Thus, (an) is Cauchy and therefore convergent.
✷
Proof of Theorem 13.1: We may clearly assume that X0 = 0. By Lemma
13.2 we may deﬁne
M u
t = eiuXt
ϕt(u),
t ≥0, u ∈Rd,

236
Foundations of Modern Probability
which is clearly a martingale in t for each u. Letting Ωu ⊂Ωdenote the set
where eiuXt has limits from the left and right along Q+ at every t ≥0, it is
seen from Theorem 6.18 that PΩu = 1.
Restating the deﬁnition of Ωu in terms of upcrossings, we note that
the set A = {(u, ω); ω ∈Ωu} is product measurable in Rd × Ω.
Writ-
ing Aω = {u ∈Rd; ω ∈Ωu}, it follows by Fubini’s theorem that the set
Ω′ = {ω; λdAc
ω = 0} has probability 1. If ω ∈Ω′ we have u ∈Aω for almost
every u ∈Rd, and so Lemma 13.3 shows that X itself has ﬁnite right- and
left-hand limits along Q+. Now deﬁne ˜Xt = Xt+ on Ω′ and ˜X = 0 on Ω′c,
and note that ˜X is rcll everywhere. Further note that ˜X is a version of X
since Xt+h
P→Xt as h →0 for ﬁxed t by hypothesis. For the same reason ˜X
has no ﬁxed jumps.
✷
We proceed to state the general representation theorem. Given any Pois-
son process η with intensity measure ν = Eη, we recall from Theorem 10.15
that the integral (η −ν)f =
 f(x)(η −ν)(dx) exists in the sense of approx-
imation in probability iﬀν(f 2 ∧|f|) < ∞.
Theorem 13.4 (independent-increment processes, L´evy, Itˆo) Let X be an
rcll process in Rd with X0 = 0. Then X has independent increments and no
ﬁxed jumps iﬀ, a.s. for each t ≥0,
Xt = mt + Gt +

 t
0

|x|≤1 x (η −Eη)(ds dx) +

 t
0

|x|>1 x η(ds dx),
(1)
for some continuous function m with m0 = 0, some continuous centered
Gaussian process G with independent increments and G0 = 0, and some
independent Poisson process η on (0, ∞) × (Rd \ {0}) with

 t
0

(|x|2 ∧1)Eη(ds dx) < ∞,
t > 0.
(2)
In the special case when X is real and nondecreasing, (1) simpliﬁes to
Xt = at +

 t
0

 ∞
0
x η(ds dx),
t ≥0,
(3)
for some nondecreasing continuous function a with a0 = 0 and some Poisson
process η on (0, ∞)2 with

 t
0

 ∞
0 (x ∧1)Eη(ds dx) < ∞,
t > 0.
(4)
Both representations are a.s. unique, and all functions m, a and processes
G, η with the stated properties may occur.
We begin the proof by analyzing the jump structure of X. Let us then
introduce the random measure
η =

tδt,∆Xt =

t1{(t, ∆Xt) ∈·},
(5)

13. Independent Increments and Inﬁnite Divisibility
237
where the summation extends over all times t > 0 with ∆Xt ≡Xt−Xt−̸= 0.
We say that η is locally X-measurable if for any s < t the measure η((s, t]×·)
is a measurable function of the process Xr −Xs, r ∈[s, t].
Lemma 13.5 (Poisson process of jumps) Let X be an rcll process in Rd
with independent increments and no ﬁxed jumps. Then η in (5) is a locally
X-measurable Poisson process on (0, ∞) × (Rd \ {0}) satisfying (2). If X
is further real valued and nondecreasing, then η is supported by (0, ∞)2 and
satisﬁes (4).
Proof (beginning): Fix any times s < t, and consider a sequence of parti-
tions s = tn,0 < · · · < tn,n with maxk(tn,k −tn,k−1) →0. For any continuous
function f on Rd that vanishes in a neighborhood of 0, we have

kf(Xtn,k −Xtn,k−1) →

f(x)η((s, t] × dx),
which implies the measurability of the integrals on the right. By a simple
approximation we may conclude that η((s, t] × B) is measurable for every
compact set B ⊂Rd \ {0}. The measurability extends by a monotone class
argument to all random variables ηA, where A is included in some ﬁxed
bounded rectangle [0, t] × B, and the further extension to arbitrary Borel
sets is immediate.
Since X has independent increments and no ﬁxed jumps, the same prop-
erties hold for η, which is then Poisson by Theorem 10.11. If X is real valued
and nondecreasing, then (4) holds by Theorem 10.15.
✷
The proof of (2) requires a further lemma, which is also needed for the
main proof.
Lemma 13.6 (orthogonality and independence) Let X and Y be rcll pro-
cesses in Rd with X0 = Y0 = 0 such that (X, Y ) has independent increments
and no ﬁxed jumps.
Also assume that Y is a.s. a step process and that
∆X · ∆Y = 0 a.s. Then X⊥⊥Y .
Proof: Deﬁne η as in (5) in terms of Y , and note as before that η is locally
Y -measurable whereas Y is locally η-measurable. By a simple transformation
of η we may reduce to the case when Y has bounded jumps. Since η is Poisson,
Y then has integrable variation on every ﬁnite interval. By Corollary 2.7 we
need to show that (Xt1, . . . , Xtn)⊥⊥(Yt1, . . . , Ytn) for any t1 < · · · < tn, and
by Lemma 2.8 it suﬃces to show for all s < t that Xt−Xs⊥⊥Yt−Ys. Without
loss of generality, we may take s = 0 and t = 1.
Then ﬁx any u, v ∈Rd, and introduce the locally bounded martingales
Mt = eiuXt
EeiuXt ,
Nt = eivYt
EeivYt ,
t ≥0.

238
Foundations of Modern Probability
Note that N again has integrable variation on [0, 1]. For n ∈N we get by
the martingale property and dominated convergence
E M1N1 −1
=
E

k≤n(Mk/n −M(k−1)/n)(Nk/n −N(k−1)/n)
=
E

 1
0 (M[sn+1−]/n −M[sn−]/n)dNs
→
E

 1
0 ∆MsdNs = E

s≤1∆Ms∆Ns = 0.
Thus, E M1N1 = 1, and so
EeiuX1+ivY1 = EeiuX1EeivY1,
u, v ∈Rd.
The asserted independence X1⊥⊥Y1 now follows by the uniqueness theorem
for characteristic functions.
✷
End of proof of Lemma 13.5: It remains to prove (2). Then deﬁne ηt =
η([0, t] × ·), and note that ηt{x; |x| > ε} < ∞a.s. for all t, ε > 0 because X
is rcll. Since η is Poisson, the same relations hold for the measures Eηt, and
so it suﬃces to prove that

|x|≤1 |x|2Eηt(dx) < ∞,
t > 0.
(6)
Then introduce for each ε > 0 the process
Xε
t =

s≤t∆Xs1{|∆Xs| > ε} =

|x|>ε xηt(dx),
t ≥0,
and note that Xε⊥⊥X −Xε by Lemma 13.6. By Lemmas 10.2 and 13.2 we
get for any ε, t > 0 and u ∈Rd \ {0}
0
<
|EeiuXt| ≤|EeiuXε
t | =
E exp

|x|>ε iux ηt(dx)

=
exp

|x|>ε(eiux −1)Eηt(dx)
 = exp

|x|>ε(cos ux −1)Eηt(dx).
Letting ε →0 gives

|ux|≤1 |ux|2Eηt(dx) <
⌢

(1 −cos ux)Eηt(dx) < ∞,
and (6) follows since u is arbitrary.
✷
Proof of Theorem 13.4: In the nondecreasing case, we may subtract the
jump component to obtain a continuous, nondecreasing process Y with in-
dependent increments, and from Theorem 4.11 it is clear that Y is a.s. non-
random. Thus, in this case we get a representation as in (3).

13. Independent Increments and Inﬁnite Divisibility
239
In the general case, introduce for each ε ∈[0, 1] the martingale
M ε
t =

 t
0

|x|∈(ε,1] x (η −Eη)(ds dx),
t ≥0.
Put Mt = M 0
t , and let Jt denote the last term in (1). By Proposition 6.16
we have E(M ε −M 0)∗2
t
→0 for each t. Thus, M + J has a.s. the same
jumps as X, and so the process Y = X −M −J is a.s. continuous. Since
η is locally X-measurable, the same thing is true for Y . Theorem 11.4 then
shows that Y is Gaussian with continuous mean and covariance functions.
Subtracting the means mt yields a continuous, centered Gaussian process G,
and by Lemma 13.6 we get G⊥⊥(M ε + J) for every ε > 0. The independence
extends to M by Lemma 2.6, and so G⊥⊥η.
The uniqueness of η is clear from (5), and G is then determined by sub-
traction. From Theorem 10.15 it is further seen that the integrals in (1) and
(3) exist for any Poisson process η with the stated properties, and we note
that the resulting process has independent increments.
✷
We may now specialize to the time-homogeneous case, when the distribu-
tion of Xt+h−Xt depends only on h. An rcll process X in Rd with stationary
independent increments and X0 = 0 is called a L´evy process. If X is also real
and nonnegative, it is often called a subordinator.
Corollary 13.7 (L´evy processes and subordinators) An rcll process X in Rd
is L´evy iﬀ(1) holds with mt ≡bt, Gt ≡σBt, and Eη = λ⊗ν for some b ∈Rd,
some d×d-matrix σ, some measure ν on Rd \{0} with
 (|x|2 ∧1)ν(dx) < ∞,
and some Brownian motion B⊥⊥η in Rd. Furthermore, X is a subordinator
iﬀ(3) holds with at ≡at and Eη = λ ⊗ν for some a ≥0 and some measure
ν on (0, ∞) with
 (x ∧1)ν(dx) < ∞. The triple (σσ′, b, ν) or pair (a, ν) is
determined by P ◦X−1, and any a, b, σ, and ν with the stated properties may
occur.
The measure ν above is called the L´evy measure of X, and the quantities
σσ′, b, and ν or a and ν are referred to collectively as the characteristics of X.
Proof: The stationarity of the increments excludes the possibility of ﬁxed
jumps, and so X has a representation as in Theorem 13.4. The stationarity
also implies that Eη is time invariant. Thus, Lemma 1.29 yields Eη = λ ⊗ν
for some measure ν on Rd \ {0} or (0, ∞). The stated conditions on ν are
immediate from (2) and (4). Finally, Theorem 11.4 gives the form of the
continuous component. Formula (5) shows that η is a measurable function
of X, and so ν is uniquely determined by P ◦X−1. The uniqueness of the
remaining characteristics then follows by subtraction.
✷
From the representations in Theorem 13.4 we may easily deduce the fol-
lowing so-called L´evy–Khinchin formulas for the associated characteristic

240
Foundations of Modern Probability
functions or Laplace transforms. Here we shall write u′ for the transpose
of u.
Corollary 13.8 (characteristic exponents, Kolmogorov, L´evy) Let X be a
L´evy process in Rd with characteristics (a, b, ν). Then EeiuXt = etψu for all
t ≥0 and u ∈Rd, where
ψu = iu′b −1
2u′au +

(eiu′x −1 −iu′x1{|x| ≤1})ν(dx),
u ∈Rd.
(7)
If X is a subordinator with characteristics (a, ν), then also Ee−uXt = e−tχu
for all t, u ≥0, where
χu = ua +

(1 −e−ux)ν(dx),
u ≥0.
(8)
In both cases the characteristics are determined by the distribution of X1.
Proof: Formula (8) follows immediately from (3) and Lemma 10.2. Sim-
ilarly, (7) is obtained from (1) by the same lemma when ν is bounded, and
the general case then follows by dominated convergence.
To prove the last assertion, we note that ψ is the unique continuous func-
tion with ψ0 = 0 satisfying eψu = EeiuX1. By the uniqueness theorem for
characteristic functions and the independence of the increments, ψ deter-
mines all ﬁnite-dimensional distributions of X, and so the uniqueness of the
characteristics follows from the uniqueness in Corollary 13.7.
✷
From Proposition 7.5 we note that a L´evy process X is Markov for
the induced ﬁltration G = (Gt) with translation-invariant transition kernels
µt(x, B) = µt(B −x) = P{Xt ∈B −x}. More generally, given any ﬁltra-
tion F, we say that X is L´evy with respect to F, or simply F-L´evy, if X is
adapted to F and such that (Xt −Xs)⊥⊥Fs for all s < t. In particular, we
may take Ft = Gt ∨N, t ≥0, where N = σ{N ⊂A; A ∈A, PA = 0}. Note
that the latter ﬁltration is right-continuous by Corollary 6.25. Just as for
Brownian motion in Theorem 11.11, it is further seen that a process X which
is F-L´evy for some right-continuous, complete ﬁltration F is a strong Markov
process, in the sense that the process X′ = θτX −Xτ satisﬁes X
d= X′⊥⊥Fτ
for any ﬁnite optional time τ.
We turn to a brief discussion of some basic symmetry properties.
A
process X on R+ is said to be self-similar if for any r > 0 there exists some
s = h(r) > 0 such that the process Xrt, t ≥0, has the same distribution as
sX. Excluding the trivial case when Xt = 0 a.s. for all t > 0, it is clear that
h satisﬁes the Cauchy equation h(xy) = h(x)h(y). If X is right-continuous,
then h is continuous, and the only solutions are of the form h(x) = xα for
some α ∈R.
Let us now return to the context of L´evy processes. Such a process X
is said to be strictly stable if it is self-similar and weakly stable if it is self-
similar apart from a centering, so that for each r > 0 the process (Xrt) has

13. Independent Increments and Inﬁnite Divisibility
241
the same distribution as (sXt + bt) for suitable s and b. In the latter case,
the corresponding symmetrized process is strictly stable, so s is again of the
form rα. In both cases it is clear that α > 0. We may then introduce the
index p = α−1 and say that X is strictly or weakly p-stable. The terminology
carries over to random variables or vectors with the same distribution as X1.
Proposition 13.9 (stable L´evy processes) Let X be a nondegenerate L´evy
process in R with characteristics (a, b, ν). Then X is weakly p-stable for some
p > 0 iﬀexactly one of these conditions holds:
(i) p = 2 and ν = 0;
(ii) p ∈(0, 2), a = 0, and ν(dx) = c±|x|−p−1dx on R± for some c± ≥0.
For subordinators, weak p-stability is equivalent to the condition
(iii) p ∈(0, 1) and ν(dx) = cx−p−1dx on (0, ∞) for some c > 0.
Proof: Writing Sr : x →rx for any r > 0, we note that the processes
X(rpt) and rX have characteristics rp(a, b, ν) and (r2a, rb, ν ◦S−1
r ), respec-
tively. Since the latter are determined by the distributions, it follows that
X is weakly p-stable iﬀrpa = r2a and rpν = ν ◦S−1
r
for all r > 0. In par-
ticular, a = 0 when p ̸= 2. Writing F(x) = ν[x, ∞) or ν(−∞, −x], we also
note that rpF(rx) = F(x) for all r, x > 0, and so F(x) = x−pF(1), which
yields the stated form of the density. The condition
 (x2 ∧1)ν(dx) < ∞
implies p ∈(0, 2) when ν ̸= 0. If X ≥0, we have the stronger condition
 (x ∧1)ν(dx) < ∞, so in this case p < 1.
✷
If X is weakly p-stable for some p ̸= 1, it can be made strictly p-stable by
a suitable centering. In particular, a weakly p-stable subordinator is strictly
stable iﬀthe drift component vanishes. In the latter case we simply say that
X is stable.
The next result shows how stable subordinators may arise naturally even
in the study of continuous processes. Given a Brownian motion B in R,
introduce the maximum process Mt = sups≤t Bs and its right-continuous
inverse
Tr = inf{t ≥0; Mt > r} = inf{t ≥0; Bt > r},
r ≥0.
(9)
Theorem 13.10 (inverse maximum process, L´evy) Deﬁne T as in (9) in
terms of a Brownian motion B. Then T is a 1
2-stable subordinator with L´evy
measure ν(dx) = (2π)−1/2x−3/2dx, x > 0.
Proof: By Lemma 6.6, the random times Tr are optional with respect
to the right-continuous ﬁltration F induced by B. By the strong Markov
property of B, the process θrT −Tr is then independent of FTr with the same
distribution as T. Since T is further adapted to the ﬁltration (FTr), it follows
that T has stationary independent increments and hence is a subordinator.

242
Foundations of Modern Probability
To see that T is 1
2-stable, ﬁx any c > 0, put ˜Bt = c−1B(c2t), and deﬁne
˜Tr = inf{t ≥0; ˜Bt > r}. Then
Tcr = inf{t ≥0; Bt > cr} = c2 inf{t ≥0; ˜Bt > r} = c2 ˜Tr.
By Proposition 13.9 the L´evy measure has a density of the form ax−3/2,
x > 0, and it remains to identify a. Then note that the process
Xt = exp(uBt −u2t/2),
t ≥0,
is a martingale for any u ∈R. In particular, E Xτr∧t = 1 for any r, t ≥0,
and since clearly Bτr = r, we get by dominated convergence
E exp(−u2Tr/2) = e−ur,
u, r ≥0.
Taking u =
√
2 and comparing with Corollary 13.8, we obtain
√
2
a =

 ∞
0 (1 −e−x)x−3/2dx = 2

 ∞
0
e−xx−1/2dx = 2√π,
which shows that a = (2π)−1/2.
✷
If we add a negative drift to a Brownian motion, the associated maximum
process M becomes bounded, and so T = M −1 terminates by a jump to in-
ﬁnity. For such occasions, it is useful to consider subordinators with possibly
inﬁnite jumps. By a generalized subordinator we mean a process of the form
Xt ≡Yt + ∞· 1{t ≥ζ} a.s., where Y is an ordinary subordinator and ζ is
an independent, exponentially distributed random variable. In this case we
say that X is obtained from Y by exponential killing. The representation
in Theorem 13.4 remains valid in the generalized case, except that ν is now
allowed to have positive mass at ∞.
The following characterization is needed in Chapter 19.
Lemma 13.11 (generalized subordinators) Let X be a nondecreasing and
right-continuous process in [0, ∞] with X0 = 0, and let F denote the ﬁltration
induced by X. Then X is a generalized subordinator iﬀ
P[Xs+t −Xs ∈·|Fs] = P{Xt ∈·} a.s. on {Xs < ∞},
s, t > 0.
(10)
Proof: Writing ζ = inf{t; Xt = ∞}, we get from (10) the Cauchy equation
P{ζ > s + t} = P{ζ > s}P{ζ > t},
s, t ≥0,
(11)
which shows that ζ is exponentially distributed with mean m ∈(0, ∞]. Next
deﬁne µt = P[Xt ∈·|Xt < ∞], t ≥0, and conclude from (10) and (11) that
the µt form a semigroup under convolution. By Theorem 7.4 there exists a
corresponding process Y with stationary, independent increments. From the
right-continuity of X, it follows that Y is continuous in probability. Hence, Y

13. Independent Increments and Inﬁnite Divisibility
243
has a version that is a subordinator. Now choose ˜ζ
d= ζ with ˜ζ⊥⊥Y , and let ˜X
denote the process Y killed at ˜ζ. Comparing with (10), we note that ˜X
d= X.
By Theorem 5.10 we may assume that even X = ˜X a.s., which means that
X is a generalized subordinator. The converse assertion is obvious.
✷
The next result provides the basic link between L´evy processes and tri-
angular arrays. A random vector ξ or its distribution is said to be inﬁnitely
divisible if for every n ∈N there exist some i.i.d. random vectors ξn1, . . . , ξnn
with
	
k ξnk
d= ξ. By an i.i.d. array we mean a triangular array of random
vectors ξnj, j ≤mn, where the ξnj are i.i.d. for each n and mn →∞.
Theorem 13.12 (L´evy processes and inﬁnite divisibility) For any random
vector ξ in Rd, these conditions are equivalent:
(i) ξ is inﬁnitely divisible;
(ii) 	
j ξnj
d→ξ for some i.i.d. array (ξnj);
(iii) ξ d= X1 for some L´evy process X in Rd.
Under those conditions, the distribution of X is determined by that of ξ.
A simple lemma is needed for the proof.
Lemma 13.13 If the ξnj are such as in (ii), then ξn1
P→0.
Proof: Let µ and µn denote the distributions of ξ and ξnj, respectively.
Choose r > 0 so small that ˆµ ̸= 0 on [−r, r], and write ˆµ = eψ on this interval,
where ψ : [−r, r] →C is continuous with ψ(0) = 0. Since the convergence
ˆµmn
n
→ˆµ is uniform on bounded intervals, it follows that ˆµn ̸= 0 on [−r, r]
for suﬃciently large n. Thus, we may write ˆµn(u) = eψn(u) for |u| ≤r, where
mnψn →ψ on [−r, r]. Then ψn →0 on the same interval, and therefore
ˆµn →1. Now let ε ≤r−1, and note as in Lemma 4.1 that

 r
−r(1 −ˆµn(u))du
=
2r

(1 −sin rx
rx )µn(dx)
≥
2r(1 −sin rε
rε )µn{|x| ≥ε}.
As n →∞, the left-hand side tends to 0 by dominated convergence, and we
get µn
w→δ0.
✷
Proof of Theorem 13.12: Trivially (iii) ⇒(i) ⇒(ii). Now let ξnj, j ≤mn,
be an i.i.d. array satisfying (ii), put µn = P ◦ξ−1
nj , and ﬁx any k ∈N. By
Lemma 13.13 we may assume that k divides each mn and write
	
j ξnj =
ηn1 + · · · + ηnk, where the ηnj are i.i.d. with distribution µ∗(mn/k)
n
. For any
u ∈Rd and r > 0 we have
(P{uηn1 > r})k = P {minj≤kuηnj > r} ≤P

j≤kuηnj > kr

,

244
Foundations of Modern Probability
and so the tightness of 	
j ηnj carries over to the sequence ηn1. By Proposition
4.21 we may extract a weakly convergent subsequence, say with limiting
distribution νk.
Since
	
j ηnj
d→ξ, it follows by Theorem 4.3 that ξ has
distribution ν∗k
k . Thus, (ii) ⇒(i).
Next assume (i), so that P ◦ξ−1 ≡µ = µ∗n
n
for each n.
By Lemma
13.13 we get ˆµn →1 uniformly on bounded intervals, so ˆµ ̸= 0, and we may
write ˆµ = eψ and ˆµn = eψn for some continuous functions ψ and ψn with
ψ(0) = ψn(0) = 0. Then ψ = nψn for each n, so etψ is a characteristic func-
tion for every t ∈Q+ and then also for t ∈R+ by Theorem 4.22. By Theorem
5.16 there exists a process X with stationary independent increments such
that Xt has characteristic function etψ for every t. Here X is continuous in
probability, and so by Theorem 13.1 it has an rcll version, which is the desired
L´evy process. Thus, (i) ⇒(iii). The last assertion is clear from Corollary
13.8.
✷
Justiﬁed by the one-to-one correspondence between inﬁnitely divisible
distributions µ and their characteristics (a, b, ν) or (a, ν), we shall use the
notation µ = id(a, b, ν) or µ = id(a, ν), respectively. The last result shows
that the class of inﬁnitely divisible laws is closed under weak convergence,
and we proceed to derive explicit convergence criteria. Then deﬁne for each
h > 0
ah = a +

|x|≤h xx′ν(dx),
bh = b −

h<|x|≤1 xν(dx),
where

h<|x|≤1 = −

1<|x|≤h when h > 1. In the positive case we may instead
deﬁne ah = a +

x≤h xν(dx). Let Rd denote the one-point compactiﬁcation
of Rd.
Theorem 13.14 (convergence of inﬁnitely divisible distributions)
(i) Let µ = id(a, b, ν) and µn = id(an, bn, νn) on Rd, and ﬁx any h > 0
with ν{|x| = h} = 0. Then µn
w→µ iﬀah
n →ah, bh
n →bh, and νn
v→ν
on Rd \ {0},
(ii) Let µ = id(a, ν) and µn = id(a, ν) on R+, and ﬁx any h > 0 with
ν{h} = 0. Then µn
w→µ iﬀah
n →ah and νn
v→ν on (0, ∞].
For the proof we shall ﬁrst consider the one-dimensional case, which allows
some important simpliﬁcations. Thus, (7) may then be written as
ψu = icu +

(eiux −1 −
iux
1 + x2)1 + x2
x2
˜ν(dx),
(12)
where
˜ν(dx)
=
σ2δ0(dx) +
x2
1 + x2ν(dx),
(13)
c
=
b +

(
x
1 + x2 −x1{|x| ≤1})ν(dx),
(14)

13. Independent Increments and Inﬁnite Divisibility
245
and the integrand in (12) is deﬁned by continuity as −u2/2 when x = 0.
For inﬁnitely divisible distributions on R+, we may instead introduce the
measure
˜ν(dx) = aδ0 + (1 −e−x)ν(dx).
(15)
The associated distributions µ will be denoted by Id(c, ˜ν) and Id(˜ν), respec-
tively.
Lemma 13.15 (one-dimensional criteria)
(i) Let µ = Id(c, ˜ν) and µn = Id(cn, ˜νn) on R. Then µn
w→µ iﬀcn →c
and ˜νn
w→˜ν.
(ii) Let µ = Id(˜ν) and µn = Id(˜νn) on R+. Then µn
w→µ iﬀ˜νn
w→˜ν.
Proof: (i) Deﬁning ψ and ψn as in (12), we may write ˆµ = eψ and
ˆµn = eψn. If cn →c and ˜νn
w→˜ν, then ψn →ψ because of the boundedness
and continuity of the integrand in (12), and so ˆµn →ˆµ, which implies µn
w→µ
by Theorem 4.3. Conversely, µn
w→µ implies ˆµn →ˆµ uniformly on bounded
intervals, and we get ψn →ψ in the same sense. Now deﬁne
χ(u) =

 1
−1(ψ(u) −ψ(u + s))ds = 2

eiux(1 −sin x
x )1 + x2
x2
˜ν(dx)
and similarly for χn, where the interchange of integrations is justiﬁed by
Fubini’s theorem. Then χn →χ, and so by Theorem 4.3
(1 −sin x
x )1 + x2
x2
˜νn(dx)
w→(1 −sin x
x )1 + x2
x2
˜ν(dx).
Since the integrand is continuous and bounded away from 0, it follows that
˜νn
w→˜ν. This implies convergence of the integral in (12), and by subtraction
cn →c.
(ii) This may be proved directly by the same method, where we note that
the functions in (8) satisfy χ(u + 1) −χ(u) =
 e−ux˜ν(dx).
✷
Proof of Theorem 13.14: For any ﬁnite measures mn and m on R we note
that mn
w→m iﬀmn
v→m on R \ {0} and mn(−h, h) →m(−h, h) for some
h > 0 with m{±h} = 0. Thus, for distributions µ and µn on R we have
˜νn
w→˜ν iﬀνn
v→ν on R \ {0} and ah
n →ah for any h > 0 with ν{±h} = 0.
Similarly, ˜νn
w→˜ν holds for distributions µ and µn on R+ iﬀνn
v→ν on (0, ∞]
and ah
n →ah for all h > 0 with ν{h} = 0. Thus, (ii) follows immediately from
Lemma 13.15. To obtain (i) from the same lemma when d = 1, it remains to
notice that the conditions bh
n →bh and cn →c are equivalent when ˜νn
w→˜ν
and ν{±h} = 0, since |x −x(1 + x2)−1| ≤|x|3.
Turning to the proof of (i) when d > 1, let us ﬁrst assume that νn
v→ν
on Rd \ {0} and that ah
n →ah and bh
n →bh for some h > 0 with ν{|x| = h}
= 0. To prove µn
w→µ, it is enough by Corollary 4.5 to show for any one-
dimensional projection πu : x →u′x with u ̸= 0 that µn ◦π−1
u
w→µ ◦π−1
u .

246
Foundations of Modern Probability
Then ﬁx any k > 0 with ν{|u′x| = k} = 0, and note that µ ◦π−1
u
has the
associated characteristics νu = ν ◦π−1
u
and
au,k
=
u′ahu +

(u′x)2{1(0,k](|u′x|) −1(0,h](|x|)}ν(dx),
bu,k
=
u′bh +

u′x{1(1,k](|u′x|) −1(1,h](|x|)}ν(dx).
Let au,k
n , bu,k
n , and νu
n denote the corresponding characteristics of µn ◦π−1
u .
Then νu
n
v→νu on R \ {0}, and furthermore au,k
n
→au,k and bu,k
n
→bu,k. The
desired convergence now follows from the one-dimensional result.
Conversely, assume that µn
w→µ. Then µn◦π−1
u
w→µ◦π−1
u
for every u ̸= 0,
and the one-dimensional result yields νu
n
v→νu on R\{0} as well as au,k
n
→au,k
and bu,k
n
→bu,k for any k > 0 with ν{|u′x| = k} = 0. In particular, the
sequence (νnK) is bounded for every compact set K ⊂Rd \ {0}, and so the
sequences (u′ah
nu) and (u′bh
n) are bounded for any u ̸= 0 and h > 0. In follows
easily that (ah
n) and (bh
n) are bounded for every h > 0, and therefore all three
sequences are relatively compact.
Given any subsequence N ′ ⊂N, we have νn
v→ν′ along a further subse-
quence N ′′ ⊂N ′ for some measure ν′ satisfying
 (|x|2∧1)ν′(dx) < ∞. Fixing
any h > 0 with ν′{|x| = h} = 0, we may choose a still further subsequence
N ′′′ such that even ah
n and bh
n converge toward some limits a′ and b′. The
direct assertion then yields µn
w→µ′ along N ′′′, where µ′ is inﬁnitely divisible
with characteristics determined by (a′, b′, ν′). Since µ′ = µ, we get ν′ = ν,
a′ = ah, and b′ = bh. Thus, the convergence remains valid along the original
sequence.
✷
By a simple approximation, we may now derive explicit criteria for the
convergence 	
j ξnj
d→ξ in Theorem 13.12. Note that the compound Poisson
distribution with characteristic measure µ = P◦ξ−1 is given by ˜µ = id(0, b, µ),
where b = E[ξ; |ξ| ≤1]. For any array of random vectors ξnj, we may in-
troduce an associated compound Poisson array, consisting of row-wise inde-
pendent compound Poisson random vectors ˜ξnj with characteristic measures
P ◦ξ−1
nj .
Corollary 13.16 (i.i.d. arrays) Consider in Rd an i.i.d. array (ξnj) and
an associated compound Poisson array (˜ξnj), and let ξ be id(a, b, ν). Then
	
j ξnj
d→ξ iﬀ
	
j ˜ξnj
d→ξ. For any h > 0 with ν{|x| = h} = 0, it is further
equivalent that
(i) mnP ◦ξ−1
n1
v→ν on Rd \ {0};
(ii) mnE[ξn1ξ′
n1; |ξn1| ≤h] →ah;
(iii) mnE[ξn1; |ξn1| ≤h] →bh.
Proof: Let µ = P ◦ξ−1 and write ˆµ = eψ, where ψ is continuous with
ψ(0) = 0. If µ∗mn
n
w→µ, then ˆµmn
n
→ˆµ uniformly on compacts. Thus, on

13. Independent Increments and Inﬁnite Divisibility
247
any bounded set B we may write ˆµn = eψn for large enough n, where the ψn
are continuous with mnψn →ψ uniformly on B. Hence, mn(eψn −1) →ψ,
and so ˜µ∗mn
n
w→µ. The proof in the other direction is similar. Since ˜µ∗mn
n
is id(0, bn, mnµn) with bn = mn

|x|≤1 xµn(dx), the last assertion follows by
Theorem 13.14.
✷
The weak convergence of inﬁnitely divisible laws extends to a pathwise
approximation property for the corresponding L´evy processes.
Theorem 13.17 (approximation of L´evy processes, Skorohod) Let X, X1,
X2, . . . be L´evy processes in Rd with Xn
1
d→X1.
Then there exist some
processes ˜Xn d= Xn with ( ˜Xn −X)∗
t
P→0 for all t ≥0.
Before proving the general result, we shall consider two special cases.
Lemma 13.18 (compound Poisson case) The conclusion of Theorem 13.17
holds when X, X1, X2, . . . are compound Poisson with characteristic measures
ν, ν1, ν2, . . . satisfying νn
w→ν.
Proof: Allowing positive mass at the origin, we may assume that ν and
the νn have the same total mass, which may then be reduced to 1 through
a suitable scaling. If ξ1, ξ2, . . . and ξn
1 , ξn
2 , . . . are associated i.i.d. sequences,
then (ξn
1 , ξn
2 , . . .)
d→(ξ1, ξ2, . . .) by Theorem 3.29, and by Theorem 3.30 we
may assume that the convergence holds a.s. Letting N be an independent
unit-rate Poisson process, and deﬁning Xt =
	
j≤Nt ξj and Xn
t =
	
j≤Nt ξn
j ,
it follows that (Xn −X)∗
t →0 a.s. for each t ≥0.
✷
Lemma 13.19 (case of small jumps)
The conclusion of Theorem 13.17
holds when EXn ≡0 and 1 ≥(∆Xn)∗
1
P→0.
Proof: Since (∆Xn)∗
1
P→0, we may choose some constants hn →0 with
mn = h−1
n
∈N such that w(Xn, 1, hn)
P→0.
By the stationarity of the
increments, it follows that w(Xn, t, hn)
P→0 for all t ≥0. Next, Theorem
13.14 shows that X is centered Gaussian. Thus, there exist as in Theorem
12.20 some processes Y n
d= (Xn
[mnt]hn) with (Y n −X)∗
t
P→0 for all t ≥0.
By Corollary 5.11 we may further choose some processes ˜Xn
d= Xn with
Y n ≡˜Xn
[mnt]hn a.s. Then, as n →∞for ﬁxed t ≥0,
E[( ˜Xn −X)∗
t ∧1] ≤E[(Y n −X)∗
t ∧1] + E[w(Xn, t, hn) ∧1] →0.
✷
Proof of Theorem 13.17: The asserted convergence is clearly equivalent
to ρ( ˜Xn, X) →0, where ρ denotes the metric
ρ(X, Y ) =

 ∞
0
e−tE[(X −Y )∗
t ∧1]dt.

248
Foundations of Modern Probability
For any h > 0 we may write X = Lh + M h + Jh and Xn = Ln,h + M n,h +
Jn,h with Lh
t ≡bht and Ln,h
t
≡bh
nt, where M h and M n,h are martingales
containing the Gaussian components and all centered jumps of size ≤h, and
the processes Jh and Jn,h are formed by all remaining jumps. Write B for
the Gaussian component of X, and note that ρ(M h, B) →0 as h →0 by
Proposition 6.16.
For any h > 0 with ν{|x| = h} = 0, it is clear from Theorem 13.14 that
bh
n →bh and νh
n
w→νh, where νh and νh
n denote the restrictions of ν and
νn, respectively, to the set {|x| > h}. The same theorem yields ah
n →a as
n →∞and then h →0, and so under those conditions M n,h
1
d→B1.
Now ﬁx any ε > 0. By Lemma 13.19 there exist some constants h, r > 0
and processes ˜
M n,h
d= M n,h such that ρ(M h, B) ≤ε and ρ( ˜
M n,h, B) ≤ε for
all n > r. Furthermore, if ν{|x| = h} = 0, there exist by Lemma 13.18 some
number r′ ≥r and processes ˜Jn,h
d= Jn,h independent of
˜
M n,h such that
ρ( ˜Jh, ˜Jn,h) ≤ε for all n > r′. We may ﬁnally choose r′′ ≥r′ so large that
ρ(Lh, Ln,h) ≤ε for all n > r′′. The processes ˜Xn ≡Ln,h + ˜
M n,h + ˜Jn,h d= Xn
then satisfy ρ(X, ˜Xn) ≤4ε for all n > r′′.
✷
Combining Theorem 13.17 with Corollary 13.16, we get a similar approx-
imation theorem for random walks, which extends the result for Gaussian
limits in Theorem 12.20. A slightly weaker result is obtained by diﬀerent
methods in Theorem 14.14.
Corollary 13.20 (approximation of random walks) Consider in Rd a L´evy
process X and some random walks S1, S2, . . . such that Sn
mn
d→X1 for some
integers mn →∞, and let N be an independent unit-rate Poisson process.
Then there exist some processes Xn
d= (Sn ◦Nmnt) with (Xn −X)∗
t
P→0 for
all t ≥0.
In particular, we may use this result to extend the ﬁrst two arcsine laws
in Theorem 11.16 to symmetric L´evy processes.
Theorem 13.21 (arcsine laws) Let X be a symmetric L´evy process in R
with X1 ̸= 0 a.s. Then these random variables are arcsine distributed:
τ1 = λ{t ≤1; Xt > 0};
τ2 = inf{t ≥0; Xt ∨Xt−= sups≤1Xs}.
(16)
The role of the condition X1 ̸= 0 a.s. is to exclude the case of pure jump
type processes.
Lemma 13.22 (diﬀuseness, Doeblin) A measure µ = id(a, b, ν) in Rd is
diﬀuse iﬀa ̸= 0 or νRd = ∞.
Proof: If a = 0 and νRd < ∞, then µ is compound Poisson apart from a
shift, so it is clearly not diﬀuse. When either condition fails, then it does so

13. Independent Increments and Inﬁnite Divisibility
249
for at least one coordinate projection, and so we may take d = 1. If a > 0,
the diﬀuseness is obvious by Lemma 1.28. Next assume that ν is unbounded,
say with ν(0, ∞) = ∞. For each n ∈N we may then write ν = νn + ν′
n,
where ν′
n is supported by (0, n−1) and has total mass log 2. For µ we get a
corresponding decomposition µn ∗µ′
n, where µ′
n is compound Poisson with
L´evy measure ν′
n and µ′
n{0} = 1
2. For any x ∈R and ε > 0 we get
µ{x}
≤
µn{x}µ′
n{0} + µn[x −ε, x)µ′
n(0, ε] + µ′
n(ε, ∞)
≤
1
2µn[x −ε, x] + µ′
n(ε, ∞).
Letting n →∞and then ε →0, and noting that µ′
n
w→δ0 and µn
w→µ, we
get µ{x} ≤1
2µ{x} by Theorem 3.25, and so µ{x} = 0.
✷
Proof of Theorem 13.21: Introduce the random walk Sn
k = Xk/n, let N
be an independent unit-rate Poisson process, and deﬁne Xn
t = Sn ◦Nnt. By
Corollary 13.20 there exist some processes ˜Xn
d= Xn with ( ˜Xn −X)∗
1
P→0.
Deﬁne τ n
1 and τ n
2 as in (16) in terms of Xn, and conclude from Lemmas 12.12
and 13.22 that τ n
i
d→τi for i = 1 and 2.
Now deﬁne
σn
1 = N −1
n

k≤Nn
1{Sn
k > 0};
σn
2 = N −1
n min

k; Sn
k = maxj≤NnSn
j

.
Since t−1Nt →1 a.s. by the law of large numbers, we have supt≤1 |n−1Nnt −t|
→0 a.s., and so σn
2 −τ n
2 →0 a.s. Applying the same law to the sequence
of holding times in N, we further note that σn
1 −τ n
1
P→0. Hence, σn
i
d→τi
for i = 1, 2. Now σn
1
d= σn
2 by Corollary 9.20, and by Theorem 12.11 we have
σn
2
d→sin2 α where α is U(0, 2π). Hence, τ1
d= τ2
d= sin2 α.
✷
The preceding results will now be used to complete the classical limit
theory for sums of independent random variables begun in Chapter 4. Recall
that a null array in Rd is deﬁned as a family of random vectors ξnj, j =
1, . . . , mn, n ∈N, such that the ξnj are independent for each n and satisfy
supj E[|ξnj|∧1] →0. Our ﬁrst goal is to extend Theorem 4.11, by giving the
basic connection between sums with positive and symmetric terms. Here we
write p2 for the mapping x →x2.
Proposition 13.23 (positive and symmetric terms) Let (ξnj) be a null ar-
ray of symmetric random variables, and let ξ and η be inﬁnitely divisible with
characteristics (a, 0, ν) and (a, ν◦p−1
2 ), respectively, where ν is symmetric and
a ≥0. Then
	
j ξnj
d→ξ iﬀ
	
j ξ2
nj
d→η.
Again the proof may be based on a simple compound Poisson approxi-
mation.

250
Foundations of Modern Probability
Lemma 13.24 (approximation) Let (ξnj) be a null array of positive or sym-
metric random variables, and let (˜ξnj) be an associated compound Poisson
array. Then for any random variable ξ we have 	
j ξnj
d→ξ iﬀ
	
j ˜ξnj
d→ξ.
Proof: Write µ = P ◦ξ−1 and µnj = P ◦ξ−1
nj . In the symmetric case we
need to show that

j ˆµnj →ˆµ
⇔

j exp(ˆµnj −1) →ˆµ,
which is immediate from Lemmas 4.6 and 4.8. In the nonnegative case, a
similar argument applies to the Laplace transforms.
✷
Proof of Proposition 13.23: Let µnj denote the distribution of ξnj, and ﬁx
any h > 0 with ν{|x| = h} = 0. By Theorem 13.14 (i) and Lemma 13.24 we
have 	
j ξnj
d→ξ iﬀ

jµnj
v→ν on R \ {0},

jE[ξ2
nj; |ξnj| ≤h] →a +

|x|≤h x2ν(dx),
whereas 	
j ξ2
nj
d→η iﬀ

jµnj ◦p−1
2
v→ν ◦p−1
2
on (0, ∞],

jE[ξ2
nj; ξ2
nj ≤h2] →a +

y≤h2 y(ν ◦p−1
2 )(dy).
The two sets of conditions are equivalent by Lemma 1.22.
✷
The limit problem for general null arrays is more delicate, since a com-
pound Poisson approximation as in Corollary 13.16 or Lemma 13.24 applies
only after a careful centering, as prescribed by the following key result.
Theorem 13.25 (compound Poisson approximation) Let (ξnj) be a null ar-
ray of random vectors in Rd, and ﬁx any h > 0. Deﬁne ηnj = ξnj −bnj, where
bnj = E[ξnj; |ξnj| ≤h], and let (˜ηnj) be an associated compound Poisson ar-
ray. Then for any random vector ξ,

jξnj
d→ξ
iﬀ

j(˜ηnj + bnj)
d→ξ.
(17)
A technical estimate is needed for the proof.
Lemma 13.26 (uniform summability) Let ϕnj be the characteristic func-
tions of the random vectors ηnj = ξnj −bnj in Theorem 13.25. Then either
condition in (17) implies that
lim sup
n→∞

j|1 −ϕnj(u)| < ∞,
u ∈Rd.

13. Independent Increments and Inﬁnite Divisibility
251
Proof: By the deﬁnitions of bnj, ηnj, and ϕnj, we have
1 −ϕnj(u) = E

1 −eiu′ηnj + iu′ηnj1{|ξnj| ≤h}

−iu′bnjP{|ξnj| > h}.
Putting
an =

jE[ηnjη′
nj; |ξnj| ≤h],
pn =

jP{|ξnj| > h},
and using Lemma 4.14, we get

j|1 −ϕnj(u)| <
⌢
1
2u′anu + (2 + |u|)pn.
Hence, it is enough to show that (u′anu) and (pn) are bounded.
Assuming the second condition in (17), the desired boundedness follows
easily from Theorem 13.14, together with the fact that maxj |bnj| →0. If
instead
	
j ξnj
d→ξ, we may introduce an independent copy (ξ′
nj) of the array
(ξnj) and apply Theorem 13.14 and Lemma 13.24 to the symmetric random
variables ζu
nj = u′ξnj −u′ξ′
nj. For any h′ > 0, this gives
lim sup
n→∞

jP{|ζu
nj| > h′} < ∞,
(18)
lim sup
n→∞

jE[(ζu
nj)2; |ζu
nj| ≤h′] < ∞.
(19)
The boundedness of pn follows from (18) and Lemma 3.19. Next we note that
(19) remains true with the condition |ζu
nj| ≤h′ replaced by |ξnj| ∨|ξ′
nj| ≤h.
Furthermore, by the independence of ξnj and ξ′
nj,
1
2

jE[(ζu
nj)2; |ξnj| ∨|ξ′
nj| ≤h]
=

jE[(u′ηnj)2; |ξnj| ≤h]P{|ξnj| ≤h} −

j(E[u′ηnj; |ξnj| ≤h])2
≥
u′anu minjP{|ξnj| ≤h} −

j(u′bnjP{|ξnj| > h})2.
Here the last sum is bounded by pn maxj(u′bnj)2 →0, and the minimum on
the right tends to 1. Thus, the boundedness of (u′anu) follows by (19).
✷
Proof of Theorem 13.25:
By Lemma 4.13 it is enough to show that
	
j |ϕnj(u) −exp{ϕnj(u) −1}| →0, where ϕnj denotes the characteristic
function of ηnj. This is clear from Taylor’s formula, together with Lemmas
4.6 and 13.26.
✷
In particular, we may now identify the possible limits.
Corollary 13.27 (limit laws, Feller, Khinchin) Let (ξnj) be a null array of
random vectors in Rd such that
	
j ξnj
d→ξ for some random vector ξ. Then
ξ is inﬁnitely divisible.

252
Foundations of Modern Probability
Proof: The random vectors ˜ηnj in Theorem 13.25 are inﬁnitely divisible,
so the same thing is true for the sums 	
j(˜ηnj −bnj). The inﬁnite divisibility
of ξ then follows by Theorem 13.12.
✷
We may further combine Theorems 13.14 and 13.25 to obtain explicit
convergence criteria for general null arrays. The present result generalizes
Theorem 4.15 for Gaussian limits and Corollary 13.16 for i.i.d. arrays. For
convenience we write cov[ξ; A] for the covariance matrix of the random vec-
tor 1Aξ.
Theorem 13.28 (general convergence criteria, Doeblin, Gnedenko)
Let
(ξnj) be a null array of random vectors in Rd, let ξ be id(a, b, ν), and ﬁx
any h > 0 with ν{|x| = h} = 0. Then 	
j ξnj
d→ξ iﬀthese conditions hold:
(i) 	
j P ◦ξ−1
nj
v→ν on Rd \ {0};
(ii)
	
j cov[ξnj; |ξnj| ≤h] →ah;
(iii)
	
j E[ξnj; |ξnj| ≤h] →bh.
Proof: Deﬁne anj = cov[ξnj; |ξnj| ≤h] and bnj = E[ξnj; |ξnj| ≤h]. By
Theorems 13.14 and 13.25 the convergence 	
j ξnj
d→ξ is equivalent to the
conditions
(i′)
	
j P ◦η−1
nj
v→ν on Rd \ {0},
(ii′)
	
j E[ηnjη′
nj; |ηnj| ≤h] →ah,
(iii′)
	
j(bnj + E[ηnj; |ηnj| ≤h]) →bh.
Here (i) and (i′) are equivalent, since maxj |bnj| →0. Using (i) and the facts
that maxj |bnj| →0 and ν{|x| = h} = 0, it is further clear that the sets
{|ηnj| ≤h} in (ii′) and (iii′) can be replaced by {|ξnj| ≤h}. To prove the
equivalence of (ii) and (ii′), it is then enough to note that, in view of (i),


j

anj −E[ηnjη′
nj; |ξnj| ≤h]
 ≤


jbnjb′
njP{|ξnj| > h}

<
⌢
maxj|bnj|2 
jP{|ξnj| > h} →0.
Similarly, (iii) and (iii′) are equivalent, because


jE[ηnj; |ξnj| ≤h]
 =


jbnjP{|ξnj| > h}

≤maxj|bnj|

jP{|ξnj| > h} →0.
✷
In the one-dimensional case we shall give two probabilistic interpretations
of the ﬁrst condition in Theorem 13.28, one of which involves the rowwise
extremes. For random measures η and ηn on R\{0}, the convergence ηn
d→η
on R \ {0} is deﬁned by the condition ηnf
d→ηf for all f ∈C+
K(R \ {0}).

13. Independent Increments and Inﬁnite Divisibility
253
Theorem 13.29 (sums and extremes)
Let (ξnj) be a null array of ran-
dom variables with distributions µnj, and deﬁne ηn =
	
j δξnj and α±
n =
maxj(±ξnj), n ∈N. Fix a L´evy measure ν on R \ {0}, let η be a Poisson
process on R \ {0} with Eη = ν, and put α± = sup{x ≥0; η{±x} > 0}.
Then these conditions are equivalent:
(i)
	
j µnj
v→ν on R \ {0};
(ii) ηn
d→η on R \ {0};
(iii) α±
n
d→α±.
The equivalence of (i) and (ii) is an immediate consequence of Theorem
14.18 in the next chapter. Here we shall give a direct elementary proof.
Proof: Condition (i) holds iﬀ

jµnj(x, ∞) →ν(x, ∞),

jµnj(−∞, −x) →ν(−∞, −x),
(20)
for all x > 0 with ν{±x} = 0. By Lemma 4.8, the ﬁrst condition in (20) is
equivalent to
P{α+
n ≤x} =

j(1 −P{ξnj > x}) →e−ν(x,∞) = P{α+ ≤x},
which holds for all continuity points x > 0 iﬀα+
n
d→α+. Similarly, the second
condition in (20) holds iﬀα−
n
d→α−. Thus, (i) and (iii) are equivalent.
To show that (i) implies (ii), we may write the latter condition in the
form

jf(ξnj)
d→ηf,
f ∈C+
K(R \ {0}).
(21)
Here the variables f(ξnj) form a null array with distributions µnj ◦f −1, and
ηf is compound Poisson with characteristic measure ν ◦f −1. Thus, Theorem
13.14 (ii) shows that (21) is equivalent to the conditions

jµnj ◦f −1
v→ν ◦f −1 on (0, ∞],
(22)
lim
ε→0 lim sup
n→∞

j

f(x)≤ε f(x)µnj(dx) = 0.
(23)
Now (22) follows immediately from (i), and to deduce (23) it suﬃces to note
that the sum on the left is bounded by 	
j µnj(f ∧ε) →ν(f ∧ε).
Finally, assume (ii). By a simple approximation, ηn(x, ∞)
d→η(x, ∞) for
any x > 0 with ν{x} = 0. In particular, for such an x,
P{α+
n ≤x} = P{ηn(x, ∞) = 0} →P{η(x, ∞) = 0} = P{α+ ≤x},
so α+
n
d→α+. Similarly, α−
n
d→α−, which proves (iii).
✷

254
Foundations of Modern Probability
Exercises
1. Show that a L´evy process X in R is a subordinator iﬀX1 ≥0 a.s.
2. Let X be a weakly p-stable L´evy process. If p ̸= 1, show that the
process Xt −ct is strictly p-stable for a suitable constant c. Note that the
centering fails for p = 1.
3. Extend Proposition 13.23 to null arrays of spherically symmetric ran-
dom vectors in Rd.
4. Show by an example that Theorem 13.25 fails without the centering
at truncated means. (Hint: Without the centering, condition (ii) of Theorem
13.28 becomes 	
j E[ξnjξ′
nj; |ξnj| ≤h] →ah.)
5. Deduce Theorems 4.7 and 4.11 from Theorem 13.14 and Lemma 13.24.
6. For a L´evy process X of eﬀective dimension d ≥3, show that |Xt| →∞
a.s. as t →∞. (Hint: Deﬁne τ = inf{t; |Xt| > 1}, and iterate to form a
random walk (Sn). Show that the latter has the same eﬀective dimension as
X, and use Theorem 8.8.)
7. Let X be a L´evy process in R, and ﬁx any p ∈(0, 2). Show that
t−1/pXt converges a.s. iﬀE|X1|p < ∞and either p ≤1 or EX1 = 0. (Hint:
Deﬁne a random walk (Sn) as before, show that S1 satisﬁes the same moment
condition as X1, and apply Theorem 3.23.)

Chapter 14
Convergence of Random Processes,
Measures, and Sets
Relative compactness and tightness; uniform topology on C(K, S);
Skorohod’s J1-topology; equicontinuity and tightness; convergence
of random measures; superposition and thinning; exchangeable se-
quences and processes; simple point processes and random closed
sets
The basic notions of weak or distributional convergence were introduced in
Chapter 3, and in Chapter 4 we studied the special case of distributions on
Euclidean spaces. The purpose of this chapter is to develop the general weak
convergence theory into a powerful tool that applies to a wide range of set,
measure, and function spaces. In particular, some functional limit theorems
derived in the last two chapters by cumbersome embedding and approxi-
mation techniques will then be accessible by straightforward compactness
arguments.
The key result is Prohorov’s theorem, which gives the basic connection
between tightness and relative distributional compactness. This result will
enable us to convert some classical compactness criteria into convenient prob-
abilistic versions. In particular, we shall see how the Arzel`a–Ascoli theo-
rem yields a corresponding criterion for distributional compactness of con-
tinuous processes.
Similarly, an optional equicontinuity condition will be
shown to guarantee the appropriate compactness for processes that are right-
continuous with left-hand limits (rcll). We shall also derive some general
criteria for convergence in distribution of random measures and sets, with
special attention to the point process case.
The general criteria will be applied to some interesting concrete situations.
In addition to some already familiar results from Chapters 12 and 13, we shall
obtain a general functional limit theorem for sampling from ﬁnite populations
and derive convergence criteria for superpositions and thinnings of point
processes.
Further applications appear in subsequent chapters, such as a
general approximation result for Markov chains in Chapter 17 and a method
for constructing weak solutions to SDEs in Chapter 18.
Beginning with the case of continuous processes, let us ﬁx two metric
spaces (K, d) and (S, ρ), where K is compact and S is separable and com-
plete, and consider the space C(K, S) of continuous functions from K to S,
255

256
Foundations of Modern Probability
endowed with the uniform metric ˆρ(x, y) = supt∈K ρ(xt, yt). For each t ∈K
we may introduce the evaluation map πt : x →xt from C(K, S) to S. The
following result shows that the random elements in C(K, S) are precisely the
continuous S-valued processes on K.
Lemma 14.1 (evaluations and Borel sets) B(C(K, S)) = σ{πt; t ∈K}.
Proof: The maps πt are continuous and hence Borel measurable, so the
generated σ-ﬁeld C is contained in B(C(K, S)). To prove the reverse rela-
tion, we need to show that any open subset G ⊂C(K, S) lies in C. From
the Arzel`a–Ascoli Theorem A2.1 we note that C(K, S) is σ-compact and
hence separable. Thus, G is a countable union of open balls Bx,r = {y ∈
C(K, S); ˆρ(x, y) < r}, and it suﬃces to prove that the latter lie in C. But
this is clear, since for any countable dense set D ⊂K,
Bx,r =

t∈D
{y ∈C(K, S); ρ(xt, yt) ≤r}.
✷
If X and Xn are random processes on K, we shall write Xn
fd
−→X for
convergence of the ﬁnite-dimensional distributions, in the sense that
(Xn
t1, . . . , Xn
tk)
d→(Xt1, . . . , Xtk),
t1, . . . , tk ∈K, k ∈N.
(1)
Though by Proposition 2.2 the distribution of a random process is determined
by the family of ﬁnite-dimensional distributions, condition (1) is insuﬃcient
in general for the convergence Xn
d→X in C(K, S). This is already clear
when the processes are nonrandom, since pointwise convergence of a sequence
of functions need not be uniform. To overcome this diﬃculty, we may add a
compactness condition. Recall that a sequence of random elements ξ1, ξ2, . . .
is said to be relatively compact in distribution if every subsequence has a
further subsequence that converges in distribution.
Lemma 14.2 (weak convergence via compactness) Let X, X1, X2, . . . be ran-
dom elements in C(K, S). Then Xn
d→X iﬀXn
fd
−→X and (Xn) is relatively
compact in distribution.
Proof: If Xn
d→X, then Xn
fd
−→X follows by Theorem 3.27, and (Xn) is
trivially relatively compact in distribution. Now assume instead that (Xn)
satisﬁes the two conditions. If Xn ̸
d→X, we may choose a bounded continuous
function f : C(K, S) →R and some ε > 0 such that |Ef(Xn) −Ef(X)| > ε
along some subsequence N ′ ⊂N. By the relative compactness we may choose
a further subsequence N ′′ and a process Y such that Xn
d→Y along N ′′. But
then Xn
fd
−→Y along N ′′, and since also Xn
fd
−→X, Proposition 2.2 yields
X
d= Y . Thus, Xn
d→X along N ′′, and so Ef(Xn) →Ef(X) along the same
sequence, a contradiction. We conclude that Xn
d→X.
✷

14. Convergence of Random Processes, Measures, and Sets
257
The last result shows the importance of ﬁnding tractable conditions for
a random sequence ξ1, ξ2, . . . in a metric space S to be relatively compact.
Generalizing a notion from Chapter 3, we say that (ξn) is tight if
supK lim inf
n→∞P{ξn ∈K} = 1,
(2)
where the supremum extends over all compact subsets K ⊂S.
We may now state the key result of weak convergence theory, the equiv-
alence between tightness and relative compactness for random elements in
suﬃciently regular metric spaces. A version for Euclidean spaces was ob-
tained in Proposition 4.21.
Theorem 14.3 (tightness and relative compactness, Prohorov) For any se-
quence of random elements ξ1, ξ2, . . . in a metric space S, tightness implies
relative compactness in distribution, and the two conditions are equivalent
when S is separable and complete.
In particular, we note that when S is separable and complete, a single
random element ξ in S is tight, in the sense that supK P{ξ ∈K} = 1. In
that case we may clearly replace the “lim inf” in (2) by “inf.”
For the proof of Theorem 14.3 we need a simple lemma. Recall from
Lemma 1.6 that a random element in a subspace of a metric space S may
also be regarded as a random element in S.
Lemma 14.4 (preservation of tightness) Tightness is preserved by continu-
ous mappings. In particular, if (ξn) is a tight sequence of random elements in
a subspace A of some metric space S, then (ξn) remains tight when regarded
as a sequence in S.
Proof: Compactness is preserved by continuous mappings. This applies
in particular to the natural embedding I : A →S.
✷
Proof of Theorem 14.3 (Varadarajan): For S = Rd the result was proved
in Proposition 4.21. Turning to the case when S = R∞, consider a tight
sequence of random elements ξn = (ξn
1 , ξn
2 , . . .) in R∞. Writing ηn
k = (ξn
1 , . . . ,
ξn
k ), we conclude from Lemma 14.4 that the sequence (ηn
k; n ∈N) is tight
in Rk for each k ∈N. Given any subsequence N ′ ⊂N, we may then use a
diagonal argument to extract a further subsequence N ′′ such that ηn
k
d→some
ηk as n →∞along N ′′ for ﬁxed k ∈N. The sequence (P ◦η−1
k ) is projective
by the continuity of the coordinate projections, and so by Theorem 5.14 there
exists some random sequence ξ = (ξ1, ξ2, . . .) with (ξ1, . . . , ξk) d= ηk for each
k. But then ξn
fd
−→ξ along N ′′, so Theorem 3.29 yields ξn
d→ξ along the
same sequence.
Next assume that S ⊂R∞. If (ξn) is tight in S, then by Lemma 14.4
it remains tight as a sequence in R∞.
Hence, for any sequence N ′ ⊂N

258
Foundations of Modern Probability
there exists a further subsequence N ′′ and some random element ξ such that
ξn
d→ξ in R∞along N ′′. To show that the convergence remains valid in S, it
suﬃces by Lemma 3.26 to verify that ξ ∈S a.s. Then choose some compact
sets Km ⊂S with lim infn P{ξn ∈Km} ≥1−2−m for each m ∈N. Since the
Km remain closed in R∞, Theorem 3.25 yields
P{ξ ∈Km} ≥lim sup
n∈N′′ P{ξn ∈Km} ≥lim inf
n→∞P{ξn ∈Km} ≥1 −2−m,
and so ξ ∈
m Km ⊂S a.s.
Now assume that S is σ-compact. In particular, it is then separable and
therefore homeomorphic to a subset A ⊂R∞. By Lemma 14.4 the tightness
of (ξn) carries over to the image sequence (˜ξn) in A, and by Lemma 3.26 the
possible relative compactness of (˜ξn) implies the same property for (ξn). This
reduces the discussion to the previous case.
Now turn to the general case. If (ξn) is tight, there exist some compact
sets Km ⊂S with lim infn P{ξn ∈Km} ≥1 −2−m. In particular, P{ξn ∈
A} →1, where A = 
m Km, and so we may choose some random elements
ηn in A with P{ξn = ηn} →1. Here (ηn) is again tight, even as a sequence
in A, and since A is σ-compact, the previous argument shows that (ηn) is
relatively compact as a sequence in A. By Lemma 3.26 it remains relatively
compact in S, and by Theorem 3.28 the relative compactness carries over to
(ξn).
To prove the converse assertion, let S be separable and complete, and
assume that (ξn) is relatively compact. For any r > 0 we may cover S by
some open balls B1, B2, . . . of radius r. Writing Gk = B1 ∪· · · ∪Bk, we claim
that
lim
k→∞inf
n P{ξn ∈Gk} = 1.
(3)
Indeed, we may otherwise choose some integers nk ↑∞with supk P{ξnk ∈Gk}
= c < 1. By the relative compactness we have ξnk
d→ξ along a subsequence
N ′ ⊂N for a suitable ξ, and so
P{ξ ∈Gm} ≤lim inf
k∈N′ P{ξnk ∈Gm} ≤c < 1,
m ∈N,
which leads as m →∞to the absurdity 1 < 1. Thus, (3) must be true.
Now take r = m−1 and write Gm
k for the corresponding sets Gk. For any
ε > 0 there exist by (3) some k1, k1, . . . ∈N with
inf
n P{ξn ∈Gm
km} ≥1 −ε2−m,
m ∈N.
Writing A =

m Gm
km, we get infn P{ξn ∈A} ≥1 −ε. Also, note that ¯A is
complete and totally bounded, hence compact. Thus, (ξn) is tight.
✷
In order to apply the last theorem, we need convenient criteria for tight-
ness. Beginning with the space C(K, S), we may convert the classical Arzel`a–
Ascoli compactness criterion into a condition for tightness. Then introduce

14. Convergence of Random Processes, Measures, and Sets
259
the modulus of continuity
w(x, h) = sup{ρ(xs, xt); d(s, t) ≤h},
x ∈C(K, S), h > 0.
The function w(x, h) is clearly continuous for ﬁxed h > 0 and hence a mea-
surable function of x.
Theorem 14.5 (tightness in C(K, S), Prohorov)
Fix two metric spaces
K and S, where K is compact and S is separable and complete, and let
X, X1, X2, . . . be random elements in C(K, S). Then Xn
d→X iﬀXn
fd
−→X
and
lim
h→0 lim sup
n→∞E[w(Xn, h) ∧1] = 0.
(4)
Proof: Since C(K, S) is separable and complete, Theorem 14.3 shows that
tightness and relative compactness are equivalent for (Xn). By Lemma 14.2
it is then enough to show that, under the condition Xn
fd
−→X, the tightness
of (Xn) is equivalent to (4).
First let (Xn) be tight. For any ε > 0 we may then choose a compact
set B ⊂C(K, S) such that lim supn P{Xn ∈Bc} < ε. By the Arzel`a–Ascoli
Theorem A2.1 we may next choose h > 0 so small that w(x, h) ≤ε for all
x ∈B. But then lim supn P{w(Xn, h) > ε} < ε, and (4) follows since ε was
arbitrary.
Next assume that (4) holds and Xn
fd
−→X. Since each Xn is continuous,
w(Xn, h) →0 a.s. as h →0 for ﬁxed n, so the “lim sup” in (4) may be
replaced by “sup.” For any ε > 0 we may then choose h1, h2, . . . > 0 so small
that
sup
n P{w(Xn, hk) > 2−k} ≤2−k−1ε,
k ∈N.
(5)
Letting t1, t2, . . . be dense in K, we may further choose some compact sets
C1, C2, . . . ⊂S such that
sup
n P{Xn(tk) ∈Cc
k} ≤2−k−1ε,
k ∈N.
(6)
Now deﬁne
B =

k{x ∈C(K, S); x(tk) ∈Ck, w(x, hk) ≤2−k}.
Then B is compact by the Arzel`a–Ascoli Theorem A2.1, and from (5) and
(6) we get supn P{Xn ∈Bc} ≤ε. Thus, (Xn) is tight.
✷
One often needs to replace the compact parameter space K by some
more general index set T. Here we may assume that T is locally compact,
second-countable, and Hausdorﬀ(abbreviated as lcscH) and endow the space
C(T, S) of continuous functions from T to S with the topology of uniform
convergence on compacts. As before, the Borel σ-ﬁeld in C(T, S) is gener-
ated by the evaluation maps πt, and so the random elements in C(T, S) are
precisely the continuous processes on T taking values in S. The following
result characterizes convergence in distribution of such processes.

260
Foundations of Modern Probability
Proposition 14.6 (locally compact parameter space) Let X, X1, X2, . . . be
random elements in C(T, S), where S is a metric space and T is lcscH. Then
Xn
d→X iﬀthe convergence holds for the restrictions to arbitrary compact
subsets K ⊂T.
Proof: The necessity is obvious from Theorem 3.27, since the restriction
map πK : C(T, S) →C(K, S) is continuous for any compact set K ⊂T. To
prove the suﬃciency, we may choose some compact sets K1 ⊂K2 ⊂· · · ⊂T
with K◦
j ↑T, and let Xi, X1
i , X2
i , . . . denote the restrictions of the processes
X, X1, X2, . . . to Ki. By hypothesis we have Xn
i
d→Xi for every i, and so
Theorem 3.29 yields (Xn
1 , Xn
2 , . . .)
d→(X1, X2, . . .). Now π = (πK1, πK2, . . .)
is a homeomorphism from C(T, S) onto its range in XjC(Kj, S), so Xn
d→X
by Lemma 3.26 and Theorem 3.27.
✷
For a simple illustration, we may prove a version of Donsker’s Theorem
12.9. Since Theorem 14.5 applies only to processes with continuous paths,
we need to replace the original step processes by their linearly interpolated
versions
Xn
t = n−1/2 
k≤ntξk + (nt −[nt])ξ[nt]+1

,
t ≥0, n ∈N.
(7)
Corollary 14.7 (functional central limit theorem, Donsker) Let ξ1, ξ2, . . .
be i.i.d. random variables with mean 0 and variance 1, deﬁne X1, X2, . . . by
(7), and let B denote a Brownian motion on R+. Then Xn
d→B in C(R+).
The following simple estimate may be used to verify the tightness.
Lemma 14.8 (maximum inequality, Ottaviani) Let ξ1, ξ2, . . . be i.i.d. ran-
dom variables with mean 0 and variance 1, and put Sn =
	
j≤n ξj. Then
P{S∗
n ≥2r√n} ≤P{|Sn| ≥r√n}
1 −r−2
,
r > 1, n ∈N.
Proof: Put c = r√n, and deﬁne τ = inf{k∈N; |Sk| ≥2c}. By the strong
Markov property at τ and Theorem 5.4,
P{|Sn| ≥c}
≥
P{|Sn| ≥c, S∗
n ≥2c}
≥
P{τ ≤n, |Sn −Sτ| ≤c}
≥
P{S∗
n ≥2c} min
k≤n P{|Sk| ≤c},
and by Chebyshev’s inequality,
min
k≤n P{|Sk| ≤c} ≥min
k≤n(1 −kc−2) ≥(1 −nc−2) = 1 −r−2.
✷

14. Convergence of Random Processes, Measures, and Sets
261
Proof of Corollary 14.7: By Proposition 14.6 it is enough to prove the
convergence on [0, 1]. Clearly, Xn
fd
−→X by Proposition 4.9 and Corollary
4.5. Combining the former result with Lemma 14.8, we further get the rough
estimate
lim
r→∞r2 lim sup
n→∞P{S∗
n ≥r√n} = 0,
which implies
lim
h→0 h−1 lim sup
n→∞
sup
t P

sup0≤r≤h|Xn
t+r −Xn
t | > ε

= 0.
Now (4) follows easily, as we divide [0, 1] into subintervals of length ≤h. ✷
Next we shall see how the Kolmogorov–Chentsov criterion in Theorem
2.23 may be converted into a suﬃcient condition for tightness in C(Rd, S).
An important application appears in Theorem 18.9.
Corollary 14.9 (moments and tightness) Let X1, X2, . . . be continuous pro-
cesses on Rd with values in a separable, complete metric space (S, ρ). Assume
that (Xn
0 ) is tight in S and that for some constants a, b > 0
E{ρ(Xn
s , Xn
t )}a <
⌢|s −t|d+b,
s, t ∈Rd, n ∈N,
(8)
uniformly in n. Then (Xn) is tight in C(Rd, S), and for every c ∈(0, b/a)
the limiting processes are a.s. locally H¨older continuous with exponent c.
Proof: For each process Xn we may deﬁne the associated quantities ξnk,
as in the proof of Theorem 2.23, and we get Eξa
nk <
⌢2−kb. Hence, Lemma
1.30 yields for m, n ∈N
∥w(Xn, 2−m)∥a∧1
a
<
⌢

k≥m∥ξnk∥a∧1
a
<
⌢

k≥m2−kb/(a∨1) <
⌢2−mb/(a∨1),
which implies (4). Condition (8) extends by Lemma 3.11 to any limiting
process X, and the last assertion then follows by Theorem 2.23.
✷
Let us now ﬁx a separable, complete metric space S, and consider random
processes with paths in D(R+, S), the space of rcll functions f : R+ →S. We
shall endow D(R+, S) with the Skorohod J1-topology, whose basic properties
are summarized in Appendix A2. Note in particular that the path space
is again Polish and that compactness may be characterized in terms of a
modiﬁed modulus of continuity ˜w, as deﬁned in Theorem A2.2.
The following result gives a criterion for weak convergence in D(R+, S),
similar to Theorem 14.5 for C(K, S).
Theorem 14.10 (tightness in D(R+, S), Skorohod, Prohorov) Fix a sepa-
rable, complete metric space S, and let X, X1, X2, . . . be random elements in
D(R+, S). Then Xn
d→X iﬀXn
fd
−→X on some dense set contained in
T = {t ≥0; ∆Xt = 0 a.s.} and, moreover,
lim
h→0 lim sup
n→∞E[ ˜w(Xn, t, h) ∧1] = 0,
t > 0.
(9)

262
Foundations of Modern Probability
Proof: Since πt is continuous at every path x ∈D(R+, S) with ∆xt = 0,
Xn
d→X implies Xn
fd
−→X on T by Theorem 3.27. Now use Theorem A2.2
and proceed as in the proof of Theorem 14.5.
✷
Tightness in D(R+, S) is often veriﬁed most easily by means of the fol-
lowing suﬃcient condition. Given a process X, we say that a random time
is X-optional if it is optional with respect to the ﬁltration induced by X.
Theorem 14.11 (optional equicontinuity and tightness, Aldous)
Fix any
metric space (S, ρ), and let X1, X2, . . . be random elements in D(R+, S).
Then (9) holds if, for any bounded sequence of Xn-optional times τn and any
positive constants hn →0,
ρ(Xn
τn, Xn
τn+hn)
P→0,
n →∞.
(10)
The proof will be based on two lemmas, where the ﬁrst one is a restate-
ment of condition (10).
Lemma 14.12 The condition in Theorem 14.11 is equivalent to
lim
h→0 lim sup
n→∞
sup
σ,τ E[ρ(Xn
σ, Xn
τ ) ∧1] = 0,
t > 0,
(11)
where the supremum extends over all Xn-optional times σ, τ ≤t with σ ≤
τ ≤σ + h.
Proof: Replacing ρ by ρ ∧1 if necessary, we may assume that ρ ≤1. The
condition in Theorem 14.11 is then equivalent to
lim
δ→0 lim sup
n→∞
sup
τ≤t
sup
h∈[0,δ]
Eρ(Xn
τ , Xn
τ+h) = 0,
t > 0,
where the ﬁrst supremum extends over all Xn-optional times τ ≤t.
To
deduce (11), assume that 0 ≤τ −σ ≤δ. Then [τ, τ + δ] ⊂[σ, σ + 2δ], and
so by the triangle inequality and a simple substitution,
δρ(Xσ, Xτ)
≤

 δ
0 {ρ(Xσ, Xτ+h) + ρ(Xτ, Xτ+h)}dh
≤

 2δ
0
ρ(Xσ, Xσ+h)dh +

 δ
0 ρ(Xτ, Xτ+h)dh.
Thus,
sup
σ,τ Eρ(Xσ, Xτ) ≤3 sup
τ
sup
h∈[0,2δ]
Eρ(Xτ, Xτ+h),
where the suprema extend over all optional times τ ≤t and σ ∈[τ −δ, τ]. ✷
We also need the following elementary estimate.

14. Convergence of Random Processes, Measures, and Sets
263
Lemma 14.13 Let ξ1, . . . , ξn ≥0 be random variables with sum Sn. Then
Ee−Sn ≤e−nc + max
k≤n P{ξk < c},
c > 0.
Proof: Let p denote the maximum on the right.
By the H¨older and
Chebyshev inequalities we get
Ee−Sn = E

k
e−ξk ≤

k
(Ee−nξk)1/n ≤

(e−nc + p)1/nn = e−nc + p.
✷
Proof of Theorem 14.11: Again we may assume that ρ ≤1, and by suitable
approximation we may extend condition (11) to weakly optional times σ and
τ. For each n ∈N and ε > 0 we recursively deﬁne the weakly Xn-optional
times
σn
k+1 = inf{s > σn
k; ρ(Xn
σn
k , Xn
s ) > ε},
k ∈Z+,
starting with σn
0 = 0. Note that for m ∈N and t, h > 0
˜w(Xn, t, h) ≤2ε +

k<m
1{σn
k+1 −σn
k < h, σn
k < t} + 1{σn
m < t}.
(12)
Now let νn(t, h) denote the supremum in (11). By Chebyshev’s inequality
and a simple truncation,
P{σn
k+1 −σn
k < h, σn
k < t} ≤ε−1νn(t + h, h),
k ∈N, t, h > 0,
(13)
and so by (11) and (12),
lim
h→0 lim sup
n→∞E ˜w(Xn, t, h) ≤2ε + lim sup
n→∞P{σn
m < t}.
(14)
Next we conclude from (13) and Lemma 14.13 that, for any c > 0,
P{σn
m < t} ≤etE[e−σn
m; σn
m < t] ≤et{e−mc + ε−1νn(t + c, c)}.
By (11) the right-hand side tends to 0 as m, n →∞and then c →0. Hence,
the last term in (14) tends to 0 as m →∞, and (9) follows since ε is arbi-
trary.
✷
We shall illustrate the use of Theorem 14.11 by proving an extension of
Corollary 14.7. A more precise result is obtained by diﬀerent methods in
Corollary 13.20. An extension to Markov chains appears in Theorem 17.28.
Theorem 14.14 (approximation of random walks, Skorohod) Let S1, S2, . . .
be random walks in Rd such that Sn
mn
d→X1 for some L´evy process X and
some integers mn →∞. Then the processes Xn
t = Sn
[mnt] satisfy Xn
d→X in
D(R+, Rd).

264
Foundations of Modern Probability
Proof: By Corollary 13.16 we have Xn fd
→X, and by Theorem 14.11 it is
then enough to show that |Xn
τn+hn −Xn
τn|
P→0 for any ﬁnite optional times τn
and constants hn →0. By the strong Markov property of Sn (or by Theorem
9.19) we may reduce to the case when τn = 0 for all n, and so it suﬃces to
show that Xn
hn
P→0 as hn →0. This again may be seen from Corollary
13.16.
✷
For the remainder of this chapter we assume that S is lcscH with Borel
σ-ﬁeld S. Write ˆS for the class of relatively compact sets in S. Let M(S)
denote the space of locally ﬁnite measures on S, endowed with the vague
topology induced by the mappings πf : µ →µf =
 fdµ, f ∈C+
K. Some
basic properties of this topology are summarized in Theorem A2.3. Note in
particular that M(S) is Polish and that the random elements in M(S) are
precisely the random measures on S. Similarly, the point processes on S
are random elements in the vaguely closed subspace N(S), consisting of all
integer-valued measures in M(S).
The following result gives the basic tightness criterion.
Lemma 14.15 (tightness of random measures, Prohorov) Let ξ1, ξ2, . . . be
random measures on some lcscH space S. Then the sequence (ξn) is relatively
compact in distribution iﬀ(ξnB) is tight in R+ for every B ∈ˆS.
Proof: By Theorems 14.3 and A2.3 the notions of relative compactness
and tightness are equivalent for (ξn). If (ξn) is tight, then so is (ξnf) for every
f ∈C+
K by Lemma 14.4, and hence (ξnB) is tight for all B ∈ˆS. Conversely,
assume the latter condition. Choose an open cover G1, G2, . . . ∈ˆS of S, ﬁx
any ε > 0, and let r1, r2, . . . > 0 be large enough that
sup
n P{ξnGk > rk} < ε2−k,
k ∈N.
(15)
Then the set A = 
k{µ; µGk ≤rk} is relatively compact by Theorem A2.3
(ii), and (15) yields infn P{ξn ∈A} > 1 −ε. Thus, (ξn) is tight.
✷
We may now derive some general convergence criteria for random mea-
sures, corresponding to the uniqueness results in Lemma 10.1 and Theorem
10.9. Deﬁne ˆSξ = {B ∈ˆS; ξ∂B = 0 a.s.}.
Theorem 14.16 (convergence of random measures) Let ξ, ξ1, ξ2, . . . be ran-
dom measures on some lcscH space S. Then these conditions are equivalent:
(i) ξn
d→ξ;
(ii) ξnf
d→ξf for all f ∈C+
K;
(iii) (ξnB1, . . . , ξnBk)
d→(ξB1, . . . , ξBk) for all B1, . . . , Bk ∈ˆSξ, k ∈N.
If ξ is a simple point process or a diﬀuse random measure, it is also equivalent
that
(iv) ξnB
d→ξB for all B ∈ˆSξ.

14. Convergence of Random Processes, Measures, and Sets
265
Proof: By Theorems 3.27 and A2.3 (iii), condition (i) implies both (ii)
and (iii). Conversely, Lemma 14.15 shows that (ξn) is relatively compact
in distribution under both (ii) and (iii). Arguing as in the proof of Lemma
14.2, it remains to show for any random measures ξ and η on S that ξ
d= η
if ξf
d= ηf for all f ∈C+
K, or if
(ξB1, . . . , ξBk) d= (ηB1, . . . , ηBk),
B1, . . . , Bk ∈ˆSξ+η, k ∈N.
(16)
In the former case this holds by Lemma 10.1, and in the latter case it follows
by a monotone class argument from Theorem A2.3 (iv). The last assertion
is obtained in a similar way from a suitable version of Theorem 10.9 (iii). ✷
Much weaker conditions are required for convergence to a simple point
process, as suggested by Theorem 10.9. The following conditions are only
suﬃcient; a precise criterion is given in Theorem 14.28.
Here a class U ⊂ˆS is said to be separating if, for any compact and open
sets K and G with K ⊂G, there exists some U ∈U with K ⊂U ⊂G.
Furthermore, we say that I ⊂ˆS is preseparating if all ﬁnite unions of sets
in I form a separating class. Applying Lemma A2.6 to the function h(B) =
Ee−ξB, we note that the class ˆSξ is separating for any random measure ξ. For
Euclidean spaces S, a preseparating class will typically consist of rectangular
boxes, whereas the corresponding ﬁnite unions form a separating class.
Proposition 14.17 (convergence of point processes) Let ξ, ξ1, ξ2, . . . be point
processes on some lcscH space S, where ξ is simple, and ﬁx a separating class
U ⊂ˆS. Then ξn
d→ξ under these conditions:
(i) P{ξnU = 0} →P{ξU = 0} for all U ∈ˆU;
(ii) lim supn EξnK ≤EξK < ∞for all compact sets K ⊂S.
Proof: First note that both (i) and (ii) extend by suitable approximation
to sets in ˆSξ. By the usual compactness argument together with Lemma
3.11, it is enough to prove that a point process η is distributed as ξ whenever
P{ηB = 0} = P{ξB = 0},
EηB ≤EξB,
B ∈ˆSξ+η.
Here the ﬁrst relation yields η∗
d= ξ as in Theorem 10.9 (i), and from the
second one we then obtain EηB ≤Eη∗B for all B ∈ˆSξ, which shows that η
is a.s. simple.
✷
We shall illustrate the use of Theorem 14.16 by showing how Poisson and
Cox processes may arise as limits under superposition or thinning. Say that
the random measures ξnj, n, j ∈N, form a null array if they are independent
for each n and such that, for each B ∈ˆS, the random variables ξnjB form a
null array in the sense of Chapter 4. The following result is a point process
version of Theorem 4.7.

266
Foundations of Modern Probability
Theorem 14.18 (convergence of superpositions, Grigelionis) Let (ξnj) be a
null array of point processes on some lcscH space S, and consider a Poisson
process ξ on S with Eξ = µ. Then 	
j ξnj
d→ξ iﬀthese conditions hold:
(i) 	
j P{ξnjB > 0} →µB for all B ∈ˆSµ;
(ii) 	
j P{ξnjB > 1} →0 for all B ∈ˆS.
Proof: If
	
j ξnj
d→ξ, then
	
j ξnjB
d→ξB for all B ∈ˆSµ by Theorem
14.16, so (i) and (ii) hold by Theorem 4.7. Conversely, assume (i) and (ii).
To prove that 	
j ξnj
d→ξ, we may restrict our attention to an arbitrary
compact set C ∈ˆSµ, and to simplify the notation we may assume that S
itself is compact. Deﬁne ηnj = ξnj1{ξnjS ≤1}, and note that (i) and (ii)
remain true for the array (ηnj). Note also that
	
j ηnj
d→ξ implies
	
j ξnj
d→ξ
by Theorem 3.28. This reduces the discussion to the case when ξnjS ≤1 for
all n and j.
Now deﬁne µnj = Eξnj. By (i) we get

jµnjB =

jEξnjB =

jP{ξnjB > 0} →µB,
B ∈ˆSµ,
so 	
j µnj
w→µ by Theorem 3.25. Noting that m(1 −e−f) = 1 −e−mf when
m = δx or 0 and writing ξn =
	
j ξnj, we get by Lemmas 4.8 and 10.2
Ee−ξnf
=

jEe−ξnjf =

jE{1 −ξnj(1 −e−f)}
=

j{1 −µnj(1 −e−f)} ∼exp

−

jµnj(1 −e−f)

→
exp(−µ(1 −e−f)) = Ee−ξf.
✷
We shall next establish a basic limit theorem for independent thinnings
of point processes.
Theorem 14.19 (convergence of thinnings) Let η1, η2, . . . be point processes
on some lcscH space S, and for each n let ξn be a pn-thinning of ηn, where
pn →0. Then ξn
d→some ξ iﬀpnηn
d→some η, in which case ξ is distributed
as a Cox process directed by η.
Proof: For any f ∈C+
K we get by Lemma 10.7
E−ξnf = E exp(ηn log{1 −pn(1 −e−f)}).
Noting that px ≤−log(1 −px) ≤−x log(1 −p) for p, x ∈[0, 1) and writing
p′
n = −log(1 −pn), we obtain
E exp{−p′
nηn(1 −e−f)} ≤Ee−ξnf ≤E exp{−pnηn(1 −e−f)}.
(17)

14. Convergence of Random Processes, Measures, and Sets
267
If pnηn
d→η, then even p′
nηn
d→η, and by Lemma 10.7
Ee−ξnf →E exp{−η(1 −e−f)} = Ee−ξf,
where ξ is a Cox process directed by η. Hence, ξn
d→ξ.
Conversely, assume that ξn
d→ξ. Fix any g ∈C+
K and let 0 ≤t < ∥g∥−1.
Applying (17) with f = −log(1 −tg), we get
lim inf
n→∞E exp{−tpnηng} ≥E exp{ξ log(1 −tg)}.
Here the right-hand side tends to 1 as t →0, and so by Lemmas 4.2 and
14.15 the sequence (pnηn) is tight. For any subsequence N ′ ⊂N we may
then choose a further subsequence N ′′ such that pnηn
d→some η along N ′′.
By the direct assertion, ξ is then distributed as a Cox process directed by
η, which by Lemma 10.8 determines the distribution of η. Hence, ηn
d→η
remains true along the original sequence.
✷
The last result leads in particular to an interesting characterization of
Cox processes.
Corollary 14.20 (Cox processes and thinnings, Mecke) Let ξ be a point
process on S. Then ξ is Cox iﬀfor every p ∈(0, 1) there exists some point
process ξp such that ξ is distributed as a p-thinning of ξp.
Proof: If ξ and ξp are Cox processes directed by η and η/p, respectively,
then Proposition 10.6 shows that ξ is distributed as a p-thinning of ξp. Con-
versely, assuming the stated condition for every p ∈(0, 1), we note that ξ is
Cox by Theorem 14.19.
✷
The previous theory will now be used to derive a general limit theorem
for sums of exchangeable random variables. The result applies in particular
to sequences obtained by sampling without replacement from a ﬁnite popu-
lation. It is also general enough to contain a version of Donsker’s theorem.
The appropriate function space in this case is D([0, 1], R) = D[0, 1], to which
the results for D(R+) apply with obvious modiﬁcations.
Consider for each n ∈N some exchangeable random variables ξnj, j ≤mn,
where mn →∞, and introduce the processes
Xn
t =

j≤mnt
ξnj,
t ∈[0, 1], n ∈N.
(18)
The potential limiting processes are of the form
Xt = αt + σBt +

jβj(1{τj ≤t} −t),
t ∈[0, 1],
(19)
for some Brownian bridge B, some independent i.i.d. U(0, 1) random vari-
ables τj, and some independent set of coeﬃcients α, σ, and βj. To ensure

268
Foundations of Modern Probability
convergence of the series on the right for each t, we need to assume that
	
j β2
j < ∞a.s. In that case we may divide by 1 −t and conclude by a
martingale argument that the sum converges in probability with respect to
the uniform metric on [0, 1]. In particular, X has a version in D[0, 1].
The convergence criteria will be stated in terms of the random variables
and measures
αn =

jξnj,
κn =

jξ2
njδξnj,
n ∈N,
(20)
κ = σ2δ0 +

jβ2
j δβj.
(21)
Theorem 14.21 (approximation of exchangeable sums) For each n ∈N let
ξnj, j ≤mn, be exchangeable random variables, and deﬁne Xn, αn, and κn
as in (18) and (20). Assume mn →∞. Then Xn
d→some X in D[0, 1] iﬀ
(αn, κn)
d→some (α, κ) in R × M(R), in which case X can be represented as
in (19) with coeﬃcients satisfying (21).
For the proof we need three auxiliary results. We begin with a simple
randomization lemma, which will enable us to reduce the proof to the case
of non-random coeﬃcients. Recall that if ν is a measure on S and µ is a
kernel from S to T, then νµ denotes the measure
 µ(s, ·)ν(ds) on T. For
any measurable function f : T →R+, we deﬁne the measurable function µf
on S by µf(s) =
 µ(s, dt)f(t).
Lemma 14.22 (randomization) For any metric spaces S and T, let ν, ν1,
ν2, . . . be probability measures on S with νn
w→ν, and let µ, µ1, µ2, . . . be
probability kernels from S to T such that sn →s in S implies µn(sn, ·)
w→
µ(s, ·). Then νnµn
w→νµ.
Proof: Fix any bounded, continuous function f on T. Then µnf(sn) →
µf(s) as sn →s, and so by Theorem 3.27
(νnµn)f = νn(µnf) →ν(µf) = (νµ)f.
✷
To establish tightness of the random measures κn, we shall need the
following conditional hyper-contractivity criterion.
Lemma 14.23 (hyper-contractivity and tightness) Let the random variables
ξ1, ξ2, . . . ≥0 and σ-ﬁelds F1, F2, . . . be such that, for some a > 0,
E[ξ2
n|Fn] ≤a(E[ξn|Fn])2 < ∞a.s.,
n ∈N.
Then if (ξn) is tight, so is the sequence ηn = E[ξn|Fn], n ∈N.

14. Convergence of Random Processes, Measures, and Sets
269
Proof: By Lemma 3.9 we need to show that cnηn
P→0 whenever 0 ≤cn →
0. Then conclude from Lemma 3.1 that, for any r ∈(0, 1) and ε > 0,
0 < (1 −r)2a−1 ≤P[ξn ≥rηn|Fn] ≤P[cnξn ≥rε|Fn] + 1{cnηn < ε}.
Here the ﬁrst term on the right
P→0 since cnξn
P→0 by Lemma 3.9. Hence,
1{cnηn < ε}
P→1, which means that P{cnηn ≥ε} →0. Since ε is arbitrary,
we get cnηn
P→0.
✷
Since we are going to approximate the summation processes in (18) by
processes of type (19), we shall ﬁnally need a convergence criterion for the
latter. In view of Theorem 14.25, the result has considerable independent
interest.
Proposition 14.24 (convergence of exchangeable processes)
Let X1, X2,
. . . be processes as in (19) with associated random pairs (αn, κn), n ∈N,
where the κn are deﬁned as in (21).
Then Xn
d→some X in D[0, 1] iﬀ
(αn, κn)
d→some (α, κ) in R × M(R), in which case even X can be repre-
sented as in (19) with coeﬃcients satisfying (21).
Proof: First let (αn, κn)
d→(α, κ). To prove Xn
d→X for the correspond-
ing processes in (19), it suﬃces by Lemma 14.22 to assume that all the αn
and κn are nonrandom. Thus, we may restrict our attention to processes Xn
with constant coeﬃcients αn, σn, and βnj, j ∈N.
To prove that Xn
fd
−→X, we begin with four special cases. First we
note that if αn →α, then trivially αnt →αt uniformly on [0, 1]. Similarly,
σn →σ implies σnB →σB in the same sense. Next we consider the case
when αn = σn = 0 and βn,m+1 = βn,m+2 = · · · = 0 for some ﬁxed m ∈N.
Here we may assume that even α = σ = 0 and βm+1 = βm+2 = · · · = 0, and
that moreover βnj →βj for all j. The convergence Xn →X is then obvious.
Finally, we may assume that αn = σn = 0 and α = β1 = β2 = · · · = 0. Then
maxj |βnj| →0, and for any s ≤t we have
E(Xn
s Xn
t ) = s(1 −t)

jβ2
nj →s(1 −t)σ2 = E(XsXt).
(22)
In this case, Xn
fd
−→X by Theorem 4.12 and Corollary 4.5. By independence
we may combine the four special cases to obtain Xn
fd
−→X whenever βj = 0
for all but ﬁnitely many j. From here on, it is easy to extend to the general
case by means of Theorem 3.28, where the required uniform error estimate
may be obtained as in (22).
To strengthen the convergence to Xn
d→X in D[0, 1], it is enough to
verify the tightness criterion in Theorem 14.11. Thus, for any Xn-optional
times τn and positive constants hn →0 with τn + hn ≤1 we need to show

270
Foundations of Modern Probability
that Xn
τn+hn −Xn
τn
P→0. By Theorem 9.19 and a simple approximation, it is
equivalent that Xn
hn
P→0, which is clear since
E(Xn
hn)2 = h2
nα2
n + hn(1 −hn)κnR →0.
To obtain the reverse implication, we assume that Xn
d→X in D[0, 1] for
some process X. Since αn = Xn
1
d→X1, the sequence (αn) is tight. Next
deﬁne for n ∈N
ηn = 2Xn
1/2 −Xn
1 = 2σnB1/2 + 2

jβnj(1{τj ≤1
2} −1
2).
Then
E[η2
n|κn]
=
σ2
n +

jβ2
nj = κnR,
E[η4
n|κn]
=
3

σ2
n +

jβ4
nj
2
−2

jβ4
nj ≤3(κnR)2.
Since (ηn) is tight, it follows by Lemmas 14.15 and 14.23 that even (κn) is
tight, and so the same thing is true for the sequence of pairs (αn, κn).
The tightness implies relative compactness in distribution, and so every
subsequence contains a further subsequence that converges in R × M(R) to-
ward some random pair (α, κ). Since the measures in (21) form a vaguely
closed subset of M(R), the limit κ has the same form for suitable σ and
β1, β2, . . . . By the direct assertion it follows that Xn
d→Y with Y as in
(19), and therefore X
d= Y . Now the coeﬃcients in (19) can be constructed
as measurable functions of Y , and so the distribution of (α, κ) is uniquely
determined by that of X. Thus, the limiting distribution is independent of
subsequence, and the convergence (αn, κn)
d→(α, κ) remains true along N.
We may ﬁnally transfer the representation (19) to the original process X by
means of Corollary 5.11.
✷
Proof of Theorem 14.21: Let τ1, τ2, . . . be i.i.d. U(0, 1) and independent
of all ξnj, and deﬁne
Y n
t =

jξnj1{τj ≤t} = αnt +

jξnj(1{τj ≤t} −t),
t ∈[0, 1].
Writing ˜ξnk for the kth jump from the left of Y n (including possible 0
jumps when ξnj = 0), we note that (˜ξnj)
d= (ξnj) by exchangeability. Thus,
˜Xn
d= Xn, where ˜Xn
t =
	
j≤mnt ˜ξnj. Furthermore, d( ˜Xn, Y n) →0 a.s. by
Proposition 3.24, where d is the metric in Theorem A2.2. Hence, by Theo-
rem 3.28 it is equivalent to replace Xn by Y n. But then the assertion follows
by Proposition 14.24.
✷
By similar compactness arguments, we may show that the most general
exchangeable-increment processes on [0, 1] are given by (19).
The result
supplements the one for processes on R+ in Theorem 9.21.

14. Convergence of Random Processes, Measures, and Sets
271
Theorem 14.25 (exchangeable-increment processes on [0, 1]) Let X be a
process on [0, 1] with X0 = 0. Then X is continuous in probability and has
exchangeable increments iﬀit can be represented as in (19). In that case X
has an rcll version.
In particular, we may combine with Theorem 10.14 to see that a simple
point process is symmetric with respect to some diﬀuse measure iﬀit is a
mixed Poisson or sample process.
Proof: The suﬃciency part is obvious, so it is enough to prove the neces-
sity. Thus, assume that X has exchangeable increments. Introduce the step
processes
Xn
t = X(2−n[2nt]),
t ∈[0, 1], n ∈N,
deﬁne κn as in (20) in terms of the jump sizes of Xn, and put αn ≡X1. If the
sequence (κn) is tight, then (αn, κn)
d→(α, κ) along some subsequence, and
by Theorem 14.21 we get Xn
d→Y along the same subsequence, where Y can
be represented as in (19). In particular, Xn
fd
−→Y , so the ﬁnite-dimensional
distributions of X and Y agree for dyadic times. The agreement extends
to arbitrary times, since both processes are continuous in probability. By
Lemma 2.24 it follows that X has a version in D[0, 1], and by Corollary 5.11
we obtain the desired representation.
To prove the required tightness of (κn), denote the increments in Xn by
ξnj, put ζnj = ξnj −2−nαn, and note that
κnR =

jξ2
nj =

jζ2
nj + 2−nα2
n.
(23)
Writing ηn = 2Xn
1/2 −Xn
1 = 2X1/2 −X1 and noting that
	
j ζnj = 0, we get
the elementary estimates
E[η4
n|κn] <
⌢

jζ4
nj +

i̸=jζ2
njζ2
nj =

jζ2
nj
2
<
⌢(E[η2
n|κn])2.
Since ηn is independent of n, the sequence of sums
	
j ζ2
nj is tight by Lemma
14.23, and so even (κn) is tight by (23).
✷
For measure-valued processes Xn with rcll paths, we may express the
tightness in terms of the real-valued projections Xn
t f =
 f(s)Xn
t (ds), f ∈
C+
K.
Theorem 14.26 (measure-valued processes) Let X1, X2, . . . be random el-
ements in D(R+, M(S)), where S is lcscH. Then (Xn) is tight iﬀ(Xnf) is
tight in D(R+, R+) for every f ∈C+
K(S).
Proof: Assume that (Xnf) is tight for every f ∈C+
K, and ﬁx any ε > 0.
Let f1, f2, . . . be such as in Theorem A2.4, and choose some compact sets
B1, B2, . . . ⊂D(R+, R+) with
P{Xnfk ∈Bk} ≥1 −ε2−k,
k, n ∈N.
(24)

272
Foundations of Modern Probability
Then A = 
k{µ; µfk ∈Bk} is relatively compact in D(R+, M(S)), and (24)
yields P{Xn ∈A} ≥1 −ε.
✷
We turn to a discussion of random sets. Then ﬁx an lcscH space S, and
let F, G, and K denote the classes of closed, open, and compact subsets,
respectively. We shall endow F with the Fell topology, generated by the sets
{F; F ∩G ̸= ∅} and {F; F ∩K = ∅} for arbitrary G ∈G and K ∈K.
Some basic properties of this topology are summarized in Theorem A2.5. In
particular, F is compact and metrizable, and {F; F ∩B = ∅} is universally
measurable for every B ∈ˆS.
By a random closed set in S we mean a random element ϕ in F. In this
context we shall often write ϕ ∩B = ϕB, and we note that the probabilities
P{ϕB = ∅} are well deﬁned. For any random closed set ϕ we may introduce
the class
ˆSϕ =

B ∈ˆS; P{ϕB◦= ∅} = P{ϕB = ∅}

,
which is separating by Lemma A2.6. We may now state the basic convergence
criterion for random sets. It is interesting to note the formal agreement with
the ﬁrst condition in Proposition 14.17.
Theorem 14.27 (convergence of random sets, Norberg) Let ϕ, ϕ1, ϕ2, . . . be
random closed sets in some lcscH space S. Then ϕn
d→ϕ iﬀ
P{ϕnU = ∅} →P{ϕU = ∅},
U ∈U,
(25)
for some separating class U ⊂ˆS, in which case we may take U = ˆSϕ.
Proof: Write h(B) = P{ϕB ̸= ∅} and hn(B) = P{ϕnB ̸= ∅}. If ϕn
d→ϕ,
then by Theorem 3.25
h(B◦) ≤lim inf
n→∞hn(B) ≤lim sup
n→∞hn(B) ≤h(B),
B ∈ˆS,
and so for B ∈ˆSϕ we get hn(B) →h(B).
Next assume that (25) holds for some separating class U. Fix any B ∈ˆSϕ,
and conclude from (25) that, for any U, V ∈U with U ⊂B ⊂V ,
h(U) ≤lim inf
n→∞hn(B) ≤lim sup
n→∞hn(B) ≤h(V ).
Since U is separating, we may let U ↑B◦to get {ϕU ̸= ∅} ↑{ϕB◦̸= ∅}
and hence h(U) ↑h(B◦) = h(B). Next choose some sets V ∈U with V ↓B,
and conclude by the ﬁnite intersection property that {ϕV ̸= ∅} ↓{ϕB ̸= ∅},
which gives h(V ) ↓h(B) = h(B). Thus, hn(B) →h(B), and so (25) remains
true for U = ˆSϕ.
Now F is compact, so {ϕn} is relatively compact by Theorem 14.3. Thus,
for any subsequence N ′ ⊂N we have ϕn
d→ψ along a further subsequence

14. Convergence of Random Processes, Measures, and Sets
273
for some random closed set ψ. By the direct statement together with (25)
we get
P{ϕB = ∅} = P{ψB = ∅},
B ∈ˆSϕ ∩ˆSψ.
(26)
Since ˆSϕ ∩ˆSψ is separating by Lemma A2.6, we may approximate as before
to extend (26) to arbitrary compact sets B. The class of sets {F; F ∩K = ∅}
with K compact is clearly a π-system, and so a monotone class argument
gives ϕ d= ψ. Since N ′ is arbitrary, we obtain ϕn
d→ϕ along N.
✷
Simple point processes allow the dual descriptions as integer-valued ran-
dom measures or locally ﬁnite random sets. The corresponding notions of
convergence are diﬀerent, and we proceed to examine how they are related.
Since the mapping µ →supp µ is continuous on N(S), we note that ξn
d→ξ
implies supp ξn
d→supp ξ. Conversely, assuming the intensity measures Eξ
and Eξn to be locally ﬁnite, it is seen from Proposition 14.17 and Theorem
14.27 that ξn
d→ξ whenever supp ξn
d→supp ξ and Eξn
v→Eξ. The next
result gives a general criterion.
Theorem 14.28 (supports of point processes) Let ξ, ξ1, ξ2, . . . be point pro-
cesses on some lcscH space S, where ξ is simple, and ﬁx any preseparating
class I ⊂ˆSξ. Then ξn
d→ξ iﬀsupp ξn
d→supp ξ and
lim sup
n→∞P{ξnI > 1} ≤P{ξI > 1},
I ∈I.
(27)
Proof: By Corollary 5.12 we may assume that supp ξn
f→supp ξ a.s., and
since ξ is simple we get by Proposition A2.8
lim sup
n→∞(ξnB ∧1) ≤ξB ≤lim inf
n→∞ξnB a.s.,
B ∈Bξ.
(28)
Next we have for any a, b ∈Z+
{b ≤a ≤1}c
=
{a > 1} ∪{a < b ∧2}
=
{b > 1} ∪{a = 0, b = 1} ∪{a > 1 ≥b},
where all unions are disjoint. Substituting a = ξI and b = ξnI, we get by
(27) and (28)
lim
n→∞P{ξI < ξnI ∧2} = 0,
I ∈I.
(29)
Next let B ⊂I ∈I and B′ = I \ B, and note that
{ξnB > ξB}
⊂
{ξnI > ξI} ∪{ξnB′ < ξB′}
⊂
{ξnI ∧2 > ξI} ∪{ξI > 1} ∪{ξnB′ < ξB′}.
(30)
More generally, assume that B ∈Bξ is covered by I1, . . . , Im ∈I. It may
then be partitioned into sets Bk ∈Bξ ∩Ik, k = 1, . . . , m, and by (28), (29),
and (30) we get
lim sup
n→∞P{ξnB > ξB} ≤P

k{ξIk > 1}.
(31)

274
Foundations of Modern Probability
Now let B ∈Bξ and K ∈K with B ⊂K◦. Fix a metric d in S and let
ε > 0. Since I is preseparating, we may choose some I1, . . . , Im ∈I with
d-diameters < ε such that B ⊂
k Ik ⊂K. Letting ρK denote the minimum
d-distance between points in (supp ξ)∩K, it follows that the right-hand side
of (31) is bounded by P{ρK < ε}. Since ρK > 0 a.s. and ε > 0 is arbitrary,
we get P{ξnB > ξB} →0. In view of the second relation in (28), we obtain
ξnB
P→ξB. Thus, ξn
d→ξ by Theorem 14.16.
✷
Exercises
1.
Show by an example that the condition in Theorem 14.11 is not
necessary for tightness. (Hint: Consider nonrandom processes Xn.)
2. In Theorem 14.11, show that it is enough to consider optional times
that take ﬁnitely many values. (Hint: Approximate from the right and use
the right-continuity of the paths.)
3. Let X, X1, X2, . . . be L´evy processes in Rd. Show that Xn
d→X in
D(R+, Rd) iﬀXn
1
d→X1 in Rd. Compare with Theorem 13.17.
4. Show that conditions (iii) and (iv) of Theorem 14.16 remain suﬃ-
cient if we replace ˆSξ by an arbitrary separating class. (Hint: Restate the
conditions in terms of Laplace transforms, and extend to ˆSξ by a suitable
approximation.)
5. Deduce Theorem 14.18 from Theorem 4.7. (Hint: First assume that
µ is diﬀuse and use Theorem 14.17. Then extend to the general case by a
suitable randomization.)
6. Strengthen the conclusion in Theorem 14.19 to (ξn, pnηn)
d→(ξ, η),
where ξ is a Cox process directed by η.
7. For any lcscH space S, let ξ, ξ1, ξ2, . . . be Cox processes on S directed
by η, η1, η2, . . . . Show that ξn
d→ξ iﬀηn
d→η. Prove the corresponding result
for p-thinnings with a ﬁxed p ∈(0, 1).
8. Let η, η1, η2, . . . be λ-randomizations of some point processes ξ, ξ1, ξ2,
. . . on an lcscH space S. Show that ξn
d→ξ iﬀηn
d→η.
9. Specialize Theorem 14.21 to suitably normalized sequences of i.i.d.
random variables, and compare with Corollary 14.7.
10. Characterize the L´evy processes on [0, 1] as special exchangeable-in-
crement processes, in terms of the coeﬃcients in Theorem 14.25.
11. Fix a diﬀuse, σ-ﬁnite measure µ on some Borel space S, and let ξ be
a µ-symmetric, simple point process on ξ. Show that P{ξB = 0} = f(µB),
where f is completely monotone, and conclude that ξ is a mixed Poisson or
sample process.
12. For an lcscH space S, let U ⊂ˆS be separating. Show that if K ⊂G
with K compact and G open, there exists some U ∈U with K ⊂U ◦⊂U ⊂
G. (Hint: First choose B, C ∈ˆS with K ⊂B◦⊂B ⊂C◦⊂C ⊂G.)

Chapter 15
Stochastic Integrals
and Quadratic Variation
Continuous local martingales and semimartingales; quadratic var-
iation and covariation; existence and basic properties of the in-
tegral; integration by parts and Itˆo’s formula; Fisk–Stratonovich
integral; approximation and uniqueness; random time-change; de-
pendence on parameter
This chapter introduces the basic notions of stochastic calculus in the special
case of continuous integrators.
As a ﬁrst major task, we shall construct
the quadratic variation [M] of a continuous local martingale M, using an
elementary approximation and completeness argument.
The processes M
and [M] will be related by some useful continuity and norm relations, notably
the elementary but powerful BDG inequalities.
Given the quadratic variation [M], we may next construct the stochastic
integral
 V dM for suitable progressive processes V , using a simple Hilbert
space argument. Combining with the ordinary Stieltjes integral
 V dA for
processes A of locally ﬁnite variation, we may ﬁnally extend the integral to
arbitrary continuous semimartingales X = M +A. The continuity properties
of quadratic variation carry over to the stochastic integral, and in conjunction
with the obvious linearity they characterize the integration.
The key result for applications is Itˆo’s formula, which shows how semi-
martingales are transformed under smooth mappings. The present substi-
tution rule diﬀers from the corresponding result for Stieltjes integrals, but
the two formulas can be brought into agreement by a suitable modiﬁcation
of the integral. We conclude the chapter with some special topics of im-
portance for applications, such as the transformation of stochastic integrals
under a random time-change, and the integration of processes depending on
a parameter.
The present material may be regarded as continuing the martingale theory
from Chapter 6. Though no results for Brownian motion are used explicitly
in this chapter, the existence of the Brownian quadratic variation in Chapter
11 may serve as a motivation. We shall also need the representation and
measurability of limits obtained in Chapter 3. The stochastic calculus de-
veloped in this chapter plays an important role throughout the remainder
of this book, especially in Chapters 16, 18, 19, and 20. In Chapter 23 the
theory is extended to possibly discontinuous semimartingales.
275

276
Foundations of Modern Probability
Throughout the chapter we let F = (Ft) be a right-continuous and com-
plete ﬁltration on R+. A process M is said to be a local martingale if it is
adapted to F and such that the stopped and shifted processes M τn −M0 are
true martingales for suitable optional times τn ↑∞. By a similar localization
we may deﬁne local L2-martingales, locally bounded martingales, locally in-
tegrable processes, and so on. The associated optional times τn are said to
form a localizing sequence.
Any continuous local martingale may clearly be reduced by localization
to a sequence of bounded, continuous martingales.
Conversely, it is seen
by dominated convergence that every bounded local martingale is a true
martingale. The following useful result may be less obvious.
Lemma 15.1 (localization) Fix any optional times τn ↑∞. Then a process
M is a local martingale iﬀM τn has this property for every n.
Proof: If M is a local martingale with localizing sequence (σn), and if τ
is an arbitrary optional time, then the processes (M τ)σn = (M σn)τ are true
martingales, so even M τ is a local martingale with localizing sequence (σn).
Conversely, assume that each process M τn is a local martingale with lo-
calizing sequence (σn
k). Since σn
k →∞a.s. for each n, we may choose some
indices kn with
P{σn
kn < τn ∧n} ≤2−n,
n ∈N.
Writing τ ′
n = τn ∧σn
kn, we get τ ′
n →∞a.s. by the Borel–Cantelli lemma, and
so the optional times τ ′′
n = infm≥n τ ′
m satisfy τ ′′
n ↑∞a.s. It remains to note
that the processes M τ ′′
n = (M τ ′
n)τ ′′
n are true martingales.
✷
The next result shows that every continuous martingale of ﬁnite variation
is a.s. constant. An extension appears as Lemma 22.11.
Proposition 15.2 (ﬁnite-variation martingales) If M is a continuous local
martingale of locally ﬁnite variation, then M = M0 a.s.
Proof: By localization we may reduce to the case when M0 = 0 and M
has bounded variation. In fact, let Vt denote the total variation of M on the
interval [0, t], and note that V is continuous and adapted. For each n ∈N
we may then introduce the optional time τn = inf{t ≥0; Vt = n}, and we
note that M τn −M0 is a continuous martingale with total variation bounded
by n. Note also that τn →∞and that if M τn = M0 a.s. for each n, then
even M = M0 a.s.
In the reduced case, ﬁx any t > 0, write tn,k = kt/n, and conclude from
the continuity of M that a.s.
Qn ≡

k≤n(Mtn,k −Mtn,k−1)2 ≤Vt max
k≤n |Mtn,k −Mtn,k−1| →0.
Since Qn ≤V 2
t , which is bounded by a constant, it follows by the martingale
property and dominated convergence that EM 2
t = EQn →0, and so Mt = 0
a.s. for each t > 0.
✷

15. Stochastic Integrals and Quadratic Variation
277
Our construction of stochastic integrals depends on the quadratic vari-
ation and covariation processes, so the latter need to be constructed ﬁrst.
Here we shall use a direct approach, which has the further advantage of giv-
ing some insight into the nature of the basic integration-by-parts formula of
Theorem 15.17. An alternative but less elementary approach would be to
use the Doob–Meyer decomposition in Chapter 22.
The construction utilizes predictable step processes of the form
Vt =

kξk1{t > τk} =

kηk1(τk,τk+1](t),
t ≥0,
(1)
where the τn are optional times with τn ↑∞a.s., and the ξk and ηk are
Fτk-measurable random variables for each k ∈N. For any process X we may
introduce the elementary integral process V · X, given as in Chapter 6 by
(V · X)t ≡

 t
0 V dX =

k
ξk(Xt −Xτk
t ) =

k
ηk(Xt
τk+1 −Xt
τk),
(2)
where the sums on the right converge, since there are only ﬁnitely many
nonzero terms. Note that (V · X)0 = 0 and that V · X inherits the possible
continuity properties of X. It is further useful to note that V · X = V · (X −
X0). The following simple estimate will be needed later.
Lemma 15.3 (L2-bound) Let M be a continuous L2-martingale with M0 =
0, and let V be a predictable step process with |V | ≤1. Then V · M is again
an L2-martingale, and we have E(V · M)2
t ≤EM 2
t .
Proof: First assume that the sum in (1) has only ﬁnitely many nonzero
terms. Then Corollary 6.14 shows that V · M is a martingale, and the L2-
bound follows by the computation
E(V · M)2
t = E

k
η2
k(M t
τk+1 −M t
τk)2 ≤E

k
(M t
τk+1 −M t
τk)2 = EM 2
t .
The estimate extends to the general case by Fatou’s lemma, and the martin-
gale property then extends by uniform integrability.
✷
Let us now introduce the space M2 of all L2-bounded, continuous mar-
tingales M with M0 = 0, and equip M2 with the norm ∥M∥= ∥M∞∥2.
Recall that ∥M ∗∥2 ≤2∥M∥by Proposition 6.16.
Lemma 15.4 (completeness) The space M2 is a Hilbert space.
Proof: Fix any Cauchy sequence M 1, M 2, . . . in M2. The sequence (M n
∞)
is then Cauchy in L2 and thus converges toward some element ξ ∈L2. In-
troduce the L2-martingale Mt = E[ξ|Ft], t ≥0, and note that M∞= ξ a.s.,
since ξ is F∞-measurable. Hence,
∥(M n −M)∗∥2 ≤2∥M n −M∥= 2∥M n
∞−M∞∥2 →0,

278
Foundations of Modern Probability
and so ∥M n −M∥→0. Moreover, (M n −M)∗→0 a.s. along some subse-
quence, which shows that M is a.s. continuous with M0 = 0.
✷
We are now ready to prove the existence of the quadratic variation and
covariation processes [M] and [M, N]. Extensions to possibly discontinuous
processes are considered in Chapter 23.
Theorem 15.5 (covariation) For any continuous local martingales M and
N, there exists an a.s. unique continuous process [M, N] of locally ﬁnite vari-
ation and with [M, N]0 = 0 such that MN −[M, N] is a local martingale. The
form [M, N] is a.s. symmetric and bilinear with [M, N] = [M −M0, N −N0]
a.s.
Furthermore, [M] = [M, M] is a.s. nondecreasing, and [M τ, N] =
[M τ, N τ] = [M, N]τ a.s. for every optional time τ.
Proof: The a.s. uniqueness of [M, N] follows from Proposition 15.2, and
the symmetry and bilinearity are immediate consequences. If [M, N] exists
with the stated properties and τ is an optional time, then by Lemma 15.1
the process M τN τ −[M, N]τ is a local martingale, and so is the process
M τ(N −N τ) by Corollary 6.14.
Hence, even M τN −[M, N]τ is a local
martingale, and so [M τ, N] = [M τ, N τ] = [M, N]τ a.s. Furthermore,
MN −(M −M0)(N −N0) = M0N0 + M0(N −N0) + N0(M −M0)
is a local martingale, and so [M −M0, N −N0] = [M, N] a.s. whenever either
side exists. If both [M + N] and [M −N] exist, then
4MN −([M + N] −[M −N])
= ((M + N)2 −[M + N]) −((M −N)2 −[M −N])
is a local martingale, and so we may take [M, N] = ([M + N] −[M −N])/4.
It is then enough to prove the existence of [M] when M0 = 0.
First assume that M is bounded. For each n ∈N, let τ n
0 = 0 and deﬁne
recursively
τ n
k+1 = inf{t > τ n
k ; |Mt −Mτ n
k | = 2−n},
k ≥0.
Clearly, τ n
k →∞as k →∞for ﬁxed n. Introduce the processes
V n
t =

kMτ n
k 1{t ∈(τ n
k , τ n
k+1]},
Qn
t =

k(Mt∧τ n
k −Mt∧τ n
k−1)2.
The V n are bounded predictable step processes, and we note that
M 2
t = 2(V n · M)t + Qn
t ,
t ≥0.
(3)
By Lemma 15.3 the integrals V n·M are continuous L2-martingales, and since
|V n −M| ≤2n for each n, we have
∥V m · M −V n · M∥= ∥(V m −V n) · M∥≤2−m+1∥M∥,
m ≤n.

15. Stochastic Integrals and Quadratic Variation
279
Hence, by Lemma 15.4 there exists some continuous martingale N such that
(V n · M −N)∗
P→0. The process [M] = M 2 −2N is again continuous, and
by (3) we have
(Qn −[M])∗= 2(N −V n · M)∗
P→0.
In particular, [M] is a.s. nondecreasing on the random time set T = {τ n
k ; n, k
∈N}, and the monotonicity extends by continuity to the closure T. Also
note that [M] is constant on each interval in T
c, since this is true for M and
hence also for every Qn. Thus, [M] is a.s. nondecreasing.
Turning to the unbounded case, we deﬁne τn = inf{t > 0; |Mt| = n},
n ∈N. The processes [M τn] exist as before, and we note that [M τm]τm =
[M τn]τm a.s. for all m < n. Hence, [M τm] = [M τn] a.s. on [0, τm], and since
τn →∞there exists a nondecreasing, continuous, and adapted process [M]
such that [M] = [M τn] a.s. on [0, τn] for each n. Here (M τn)2 −[M]τn is a
local martingale for each n, and so M 2 −[M] is a local martingale by Lemma
15.1.
✷
We proceed to establish a basic continuity property.
Proposition 15.6 (continuity) For any continuous local martingales Mn
starting at 0, we have M ∗
n
P→0 iﬀ[Mn]∞
P→0.
Proof: First let M ∗
n
P→0. Fix any ε > 0, and deﬁne τn = inf{t ≥0;
|Mn(t)| > ε}, n ∈N.
Write Nn = M 2
n −[Mn], and note that N τn
n
is a
true martingale on R+. In particular, E[Mn]τn ≤ε2, and so by Chebyshev’s
inequality
P{[Mn]∞> ε} ≤P{τn < ∞} + ε−1E[Mn]τn ≤P{M ∗
n > ε} + ε.
Here the right-hand side tends to zero as n →∞and then ε →0, which
shows that [Mn]∞
P→0.
The proof in the other direction is similar, except that we need to use
a localization argument together with Fatou’s lemma to see that a contin-
uous local martingale M with M0 = 0 and E[M]∞< ∞is necessarily L2-
bounded.
✷
Next we prove a pair of basic norm inequalities involving the quadratic
variation, known as the BDG inequalities. Partial extensions to discontinuous
martingales are established in Theorem 23.12.
Proposition 15.7 (norm inequalities, Burkholder, Millar, Gundy, Novikov)
There exist some constants cp ∈(0, ∞), p > 0, such that for any continuous
local martingale M with M0 = 0
c−1
p E[M]p/2
∞≤EM ∗p ≤cpE[M]p/2
∞,
p > 0.

280
Foundations of Modern Probability
The result is an immediate consequence of the following lemma.
Lemma 15.8 (positive components) There exist some constants cp < ∞,
p > 0, such that whenever M = X −Y is a local martingale for some
continuous, adapted processes X, Y ≥0 with X0 = Y0 = 0, we have
EX∗p ≤cpEY ∗p,
p > 0.
Proof: By optional stopping and monotone convergence, we may assume
that X and Y are bounded. Fix any constants s > 0, b > 1, and c ∈(0, b−1),
put τ = inf{t ≥0; Xt = s}, and deﬁne N = M −M τ. By optional sampling
we get as in Corollary 6.30
P{X∗≥bs} −P{Y ∗≥cs} ≤P{X∗≥bs, Y ∗< cs}
≤
P{τ < ∞, suptNt ≥(b −1 −c)s, inftNt > −cs}
≤
c
b −1P{X∗≥s}.
Multiplying by psp−1 and integrating over R+, we obtain by Lemma 2.4
b−pEX∗p −c−pEY ∗p ≤
c
b −1EX∗p,
p > 0.
It remains to choose c < (b −1)b−p.
✷
It is often important to decide whether a local martingale is in fact a true
martingale. The last proposition yields a useful criterion.
Corollary 15.9 (uniform integrability) Let M be a continuous local mar-
tingale satisfying E(|M0| + [M]1/2
∞) < ∞. Then M is a uniformly integrable
martingale.
Proof: By Proposition 15.7 we have EM ∗< ∞, and the martingale prop-
erty follows by dominated convergence.
✷
The basic properties of [M, N] suggest that we think of the covariation
process as a kind of inner product. A further justiﬁcation is given by the
following useful Cauchy–Buniakovsky-type inequalities.
Proposition 15.10 (Cauchy-type inequalities, Courr`ege) For any continu-
ous local martingales M and N we have a.s.
|[M, N]| ≤

|d[M, N]| ≤[M]1/2[N]1/2.
(4)
More generally, we have a.s. for any measurable processes U and V

 t
0 |UV d[M, N]| ≤(U 2 · [M])1/2
t
(V 2 · [N])1/2
t
,
t ≥0.

15. Stochastic Integrals and Quadratic Variation
281
Proof: Using the positivity and bilinearity of the covariation, we get a.s.
for any a, b ∈R and t > 0
0 ≤[aM + bN]t = a2[M]t + 2ab[M, N]t + b2[N]t.
By continuity we can choose a common exceptional null set for all a and b,
and so [M, N]2
t ≤[M]t[N]t a.s. Applying this inequality to the processes
M −M s and N −N s for any s < t, we obtain a.s.
|[M, N]t −[M, N]s| ≤([M]t −[M]s)1/2([N]t −[N]s)1/2,
(5)
and by continuity we may again choose a common null set. Now let 0 =
t0 < t1 < · · · < tn = t be arbitrary, and conclude from (5) and the classical
Cauchy–Buniakovsky inequality that
|[M, N]t| ≤

k
[M, N]tk −[M, N]tk−1
 ≤[M]1/2
t
[N]1/2
t
.
To get (4), it remains to take the supremum over all partitions of [0, t].
Next write dµ = d[M], dν = d[N], and dρ = |d[M, N]|, and conclude
from (4) that (ρI)2 ≤µI νI a.s. for every interval I. By continuity we may
choose the exceptional null set A to be independent of I. Expressing an
arbitrary open set G ⊂R+ as a disjoint union of open intervals Ik and using
the Cauchy–Buniakovsky inequality, we get on Ac
ρG =

kρIk ≤

k(µIkνIk)1/2 ≤

jµIj

kνIk
1/2
= (µG νG)1/2.
By Lemma 1.16 the last relation extends to any B ∈B(R+).
Now ﬁx any simple measurable functions f = 	
k ak1Bk and g =
	
k bk1Bk.
Using the Cauchy–Buniakovsky inequality again, we obtain on Ac
ρ|fg|
≤

k|akbk|ρBk ≤

k|akbk|(µBkνBk)1/2
≤

ja2
jµBj

kb2
kνBk
1/2
≤(µf 2νg2)1/2,
which extends by monotone convergence to any measurable functions f and
g on R+. In particular, in view of Lemma 1.34, we may take f(t) = Ut(ω)
and g(t) = Vt(ω) for ﬁxed ω ∈Ac.
✷
Let E denote the class of bounded, predictable step processes with jumps
at ﬁnitely many ﬁxed times. To motivate the construction of general stochas-
tic integrals and for subsequent needs, we shall establish a basic identity for
elementary integrals.
Lemma 15.11 (covariation of elementary integrals) For any continuous lo-
cal martingales M, N and processes U, V ∈E, the integrals U · M and V · N
are again continuous local martingales, and we have
[U · M, V · N] = (UV ) · [M, N] a.s.
(6)

282
Foundations of Modern Probability
Proof: We may clearly take M0 = N0 = 0. The ﬁrst assertion follows
by localization from Lemma 15.3. To prove (6), let Ut =
	
k≤n ξk1(tk,tk+1](t),
where ξk is bounded and Ftk-measurable for each k. By localization we may
assume M, N, and [M, N] to be bounded, so that M, N, and MN −[M, N]
are martingales on R+. Then
E(U · M)∞N∞
=
E

jξj(Mtj+1 −Mtj)

k(Ntk+1 −Ntk)
=
E

kξk(Mtk+1Ntk+1 −MtkNtk)
=
E

kξk

[M, N]tk+1 −[M, N]tk

=
E(U · [M, N])∞.
Replacing M and N by M τ and N τ for an arbitrary optional time τ, we get
E(U · M)τNτ = E(U · M τ)∞N τ
∞= E(U · [M τ, N τ])∞= E(U · [M, N])τ.
By Lemma 6.13 the process (U · M)N −U · [M, N] is then a martingale, so
[U · M, N] = U · [M, N] a.s. The general formula follows by iteration.
✷
In order to extend the stochastic integral V · M to more general pro-
cesses V , it is convenient to take (6) as the characteristic property. Given a
continuous local martingale M, let L(M) denote the class of all progressive
processes V such that (V 2 · [M])t < ∞a.s. for every t > 0.
Theorem 15.12 (stochastic integral, Itˆo, Kunita and Watanabe) For every
continuous local martingale M and process V ∈L(M), there exists an a.s.
unique continuous local martingale V ·M with (V ·M)0 = 0 such that [V ·M,
N] = V · [M, N] a.s. for every continuous local martingale N.
Proof: To prove the uniqueness, let M ′ and M ′′ be continuous local mar-
tingales with M ′
0 = M ′′
0 = 0 such that [M ′, N] = [M ′′, N] = V · [M, N] a.s.
for all continuous local martingales N. By linearity we get [M ′ −M ′′, N] = 0
a.s. Taking N = M ′ −M ′′ gives [M ′ −M ′′] = 0 a.s. But then (M ′ −M ′′)2 is
a local martingale starting at 0, and it easily follows that M ′ = M ′′ a.s.
To prove the existence, we may ﬁrst assume that ∥V ∥2
M = E(V 2·[M])∞<
∞. Since V is measurable, we get by Proposition 15.10 and the Cauchy–
Buniakovsky inequality
|E(V · [M, N])∞| ≤∥V ∥M∥N∥,
N ∈M2.
The mapping N →E(V · [M, N])∞is then a continuous linear functional on
M2, so by Lemma 15.4 there exists some element V · M ∈M2 with
E(V · [M, N])∞= E(V · M)∞N∞,
N ∈M2.
Now replace N by N τ for an arbitrary optional time τ. By Theorem 15.5
and optional sampling we get
E(V · [M, N])τ
=
E(V · [M, N]τ)∞= E(V · [M, N τ])∞
=
E(V · M)∞Nτ = E(V · M)τNτ.

15. Stochastic Integrals and Quadratic Variation
283
Since V is progressive, it follows by Lemma 6.13 that V ·[M, N]−(V ·M)N is
a martingale, which means that [V ·M, N] = V ·[M, N] a.s. The last relation
extends by localization to arbitrary continuous local martingales N.
In the general case, deﬁne τn = inf{t > 0; (V 2 · [M])t = n}. By the
previous argument there exist some continuous local martingales V · M τn
such that for any continuous local martingale N
[V · M τn, N] = V · [M τn, N] a.s.,
n ∈N.
(7)
For m < n it follows that (V · M τn)τm satisﬁes the corresponding relation
with [M τm, N], and so (V · M τn)τm = V · M τm a.s. Hence, there exists a
continuous process V · M with (V · M)τn = V · M τn a.s. for all n, and
Lemma 15.1 shows that V · M is again a local martingale. Finally, (7) yields
[V · M, N] = V · [M, N] a.s. on [0, τn] for each n, and so the same relation
holds on R+.
✷
By Lemma 15.11 we note that the stochastic integral V · M of the last
theorem extends the previously deﬁned elementary integral. It is also clear
that V · M is a.s. bilinear in the pair (V, M) and satisﬁes the following basic
continuity property.
Lemma 15.13 (continuity) For any continuous local martingales Mn and
processes Vn ∈L(Mn), we have (Vn · Mn)∗
P→0 iﬀ(V 2
n · [Mn])∞
P→0.
Proof: Recall that [Vn · Mn] = V 2
n · [Mn] and use Proposition 15.6.
✷
Before continuing the study of stochastic integrals, it is convenient to
extend the deﬁnition to a larger class of integrators. A process X is said
to be a continuous semimartingale if it can be written as a sum M + A,
where M is a continuous local martingale and A is a continuous, adapted
process of locally ﬁnite variation and with A0 = 0. By Proposition 15.2 the
decomposition X = M + A is then a.s. unique, and it is often referred to as
the canonical decomposition of X. By a continuous semimartingale in Rd we
mean a process X = (X1, . . . , Xd) such that the component processes Xk
are one-dimensional continuous semimartingales.
Let L(A) denote the class of progressive processes V such that the process
(V ·A)t =
 t
0 V dA exists in the sense of ordinary Stieltjes integration. For any
continuous semimartingale X = M + A we may write L(X) = L(M) ∩L(A),
and we deﬁne the integral of a process V ∈L(X) as the sum V · X =
V · M + V · A. Note that V · X is again a continuous semimartingale with
canonical decomposition V · M + V · A. For progressive processes V it is
further clear that V ∈L(X) iﬀV 2 ∈L([M]) and V ∈L(A).
From Lemma 15.13 we may easily deduce the following stochastic version
of the dominated convergence theorem.

284
Foundations of Modern Probability
Corollary 15.14 (dominated convergence) Fix a continuous semimartin-
gale X, and let U, V, V1, V2, . . . ∈L(X) with |Vn| ≤U and Vn →V . Then
(Vn · X −V · X)∗
t
P→0, t ≥0.
Proof: Assume that X = M + A. Since U ∈L(X), we have U 2 ∈L([M])
and U ∈L(A). Hence, by dominated convergence for ordinary Stieltjes inte-
grals, ((Vn−V )2·[M])t →0 and (Vn·A−V ·A)∗
t →0 a.s. By Lemma 15.13 the
former convergence implies (Vn·M−V ·M)∗
t
P→0, and the assertion follows. ✷
The next result extends the elementary chain rule of Lemma 1.23 to
stochastic integrals.
Proposition 15.15 (chain rule) Consider a continuous semimartingale X
and two progressive processes U and V , where V ∈L(X). Then U ∈L(V ·X)
iﬀUV ∈L(X), in which case U · (V · X) = (UV ) · X a.s.
Proof: Let M + A be the canonical decomposition of X.
Then U ∈
L(V · X) iﬀU 2 ∈L([V · M]) and U ∈L(V · A), whereas UV ∈L(X) iﬀ
(UV )2 ∈L([M]) and UV ∈L(A). Since [V · M] = V 2 · [M], the two pairs of
conditions are equivalent.
The formula U · (V · A) = (UV ) · A is elementary.
To see that even
U ·(V ·M) = (UV )·M a.s., let N be an arbitrary continuous local martingale,
and note that
[(UV ) · M, N]
=
(UV ) · [M, N] = U · (V · [M, N])
=
U · [V · M, N] = [U · (V · M), N].
✷
The next result shows how the stochastic integral behaves under optional
stopping.
Proposition 15.16 (optional stopping)
For any continuous semimartin-
gale X, process V ∈L(X), and optional time τ, we have a.s.
(V · X)τ = V · Xτ = (V 1[0,τ]) · X.
Proof: The relation is obvious for ordinary Stieltjes integrals, so we may
assume that X = M is a continuous local martingale. Then (V · M)τ is a
continuous local martingale starting at 0, and we have
[(V · M)τ, N]
=
[V · M, N τ] = V · [M, N τ] = V · [M τ, N]
=
V · [M, N]τ = (V 1[0,τ]) · [M, N].
Thus, (V · M)τ satisﬁes the conditions characterizing the integrals V · M τ
and (V 1[0,τ]) · M.
✷

15. Stochastic Integrals and Quadratic Variation
285
We may extend the deﬁnitions of quadratic variation and covariation to
arbitrary continuous semimartingales X and Y with canonical decomposi-
tions M + A and N + B, respectively, by putting [X] = [M] and [X, Y ] =
[M, N]. As a key step toward the development of a stochastic calculus, we
shall see how the covariation process can be expressed in terms of stochastic
integrals. In the martingale case the result is implicit in the proof of Theorem
15.5.
Theorem 15.17 (integration by parts) For any continuous semimartingales
X and Y , we have a.s.
XY = X0Y0 + X · Y + Y · X + [X, Y ].
(8)
Proof: We may take X = Y , since the general result will then follow by
polarization. First let X = M ∈M2, and deﬁne V n and Qn as in the proof
of Theorem 15.5. Then V n →M and |V n
t | ≤M ∗
t < ∞, and so Corollary
15.14 yields (V n · M)t
P→(M · M)t for each t ≥0. Thus, (8) follows in this
case as we let n →∞in the relation M 2 = V n · M + Qn, and it extends
by localization to general continuous local martingales M with M0 = 0. If
instead X = A, formula (8) reduces to A2 = 2A · A, which holds by Fubini’s
theorem.
Turning to the general case, we may assume that X0 = 0, since the
formula for general X0 will then follow by an easy computation from the
result for X −X0. In this case (8) reduces to X2 = 2X ·X +[M]. Subtracting
the formulas for M 2 and A2, it remains to prove that AM = A · M + M · A
a.s. Then ﬁx any t > 0, and introduce the processes
An
s = A(k−1)t/n,
M n
s = Mkt/n,
s ∈t(k −1, k]/n, k, n ∈N,
which satisfy
AtMt = (An · M)t + (M n · A)t,
n ∈N.
Here (An · M)t
P→(A · M)t by Corollary 15.14 and (M n · A)t →(M · A)t by
dominated convergence for ordinary Stieltjes integrals.
✷
The terms quadratic variation and covariation are justiﬁed by the follow-
ing result, which extends Theorem 11.9 for Brownian motion.
Proposition 15.18 (approximation, Fisk) Let X and Y be continuous se-
mimartingales, ﬁx any t > 0, and consider for every n ∈N a partition
0 = tn,0 < tn,1 < · · · < tn,kn = t such that maxk(tn,k −tn,k−1) →0. Then
ζn ≡

k(Xtn,k −Xtn,k−1)(Ytn,k −Ytn,k−1)
P→[X, Y ]t.
(9)
Proof: We may clearly assume that X0 = Y0 = 0. Introduce the pre-
dictable step processes
Xn
s = Xtn,k−1,
Y n
s = Ytn,k−1,
s ∈(tn,k−1, tn,k], k, n ∈N,

286
Foundations of Modern Probability
and note that
XtYt = (Xn · Y )t + (Y n · X)t + ζn,
n ∈N.
Since Xn →X and Y n →Y , and moreover (Xn)∗
t ≤X∗
t < ∞and (Y n)∗
t ≤
X∗
t < ∞, we get by Corollary 15.14 and Theorem 15.17
ζn
P→XtYt −(X · Y )t −(Y · X)t = [X, Y ]t.
✷
We proceed to prove a version of Itˆo’s formula, arguably the most im-
portant formula in modern probability. The result shows that the class of
continuous semimartingales is preserved under smooth mappings and exhibits
the canonical decomposition of the image process in terms of the components
of the original process. Extended versions appear in Corollaries 15.20 and
15.21 as well as in Theorems 19.5 and 23.7.
Let Ck = Ck(Rd) denote the class of k times continuously diﬀerentiable
functions on Rd. When f ∈C2, we write f ′
i and f ′′
ij for the ﬁrst- and second-
order partial derivatives of f. Here and below, summation over repeated
indices is understood.
Theorem 15.19 (substitution rule, Itˆo) Let X be a continuous semimar-
tingale in Rd, and ﬁx any f ∈C2(Rd). Then
f(X) = f(X0) + f ′
i(X) · Xi + 1
2f ′′
ij(X) · [Xi, Xj] a.s.
(10)
The result is often written in diﬀerential form as
df(X) = f ′
i(X) dXi + 1
2f ′′
ij(X) d[Xi, Xj].
It is suggestive to think of Itˆo’s formula as a second-order Taylor expansion
df(X) = f ′
i(X) dXi + 1
2f ′′
ij(X) dXidXj,
where the second-order diﬀerential dXidXj is interpreted as d[Xi, Xj].
If X has canonical decomposition M + A, we get the corresponding de-
composition of f(X) by substituting M i + Ai for Xi on the right of (10).
When M = 0, the last term vanishes and (10) reduces to the familiar sub-
stitution rule for ordinary Stieltjes integrals. In general, the appearance of
this Itˆo correction term shows that the Itˆo integral does not obey the rules
of ordinary calculus.
Proof of Theorem 15.19: For notational convenience we may assume that
d = 1, the general case being similar. Then ﬁx a one-dimensional, continuous
semimartingale X, and let C denote the class of functions f ∈C2 satisfying
(10), that is, such that
f(X) = f(X0) + f ′(X) · X + 1
2f ′′(X) · [X].
(11)

15. Stochastic Integrals and Quadratic Variation
287
The class C is clearly a linear subspace of C2 containing the functions f(x) ≡
1 and f(x) ≡x. We shall prove that C is even closed under multiplication
and hence contains all polynomials.
To see this, assume that (11) holds for both f and g. Then F = f(X) and
G = g(X) are continuous semimartingales, so using deﬁnition of the integral
together with Proposition 15.15 and Theorem 15.17, we get
(fg)(X) −(fg)(X0)
=
FG −F0G0 = F · G + G · F + [F, G]
=
F · (g′(X) · X + 1
2g′′(X) · [X])
+ G · (f ′(X) · X + 1
2f ′′(X) · [X]) + [f ′(X) · X, g′(X) · X]
=
(fg′ + f ′g)(X) · X + 1
2(fg′′ + 2f ′g′ + f ′′g)(X) · [X]
=
(fg)′(X) · X + 1
2(fg)′′(X) · [X].
Now let f ∈C2 be arbitrary. By Weierstrass’ approximation theorem, we
may choose some polynomials p1, p2, . . . such that sup|x|≤c |pn(x)−f ′′(x)| →0
for every c > 0. Integrating the pn twice yields polynomials fn satisfying
sup
|x|≤c
(|fn(x) −f(x)| ∨|f ′
n(x) −f ′(x)| ∨|f ′′
n(x) −f ′′(x)|) →0,
c > 0.
In particular, fn(Xt) →f(Xt) for each t > 0. Letting M +A be the canonical
decomposition of X and using dominated convergence for ordinary Stieltjes
integrals, we get for any t ≥0
(f ′
n(X) · A + 1
2f ′′
n(X) · [X])t →(f ′(X) · A + 1
2f ′′(X) · [X])t.
Similarly, (f ′
n(X) −f ′(X))2 · [M])t →0 for all t, and so by Lemma 15.13
(f ′
n(X) · M)t
P→(f ′(X) · M)t,
t ≥0.
Thus, equation (11) for the polynomials fn extends in the limit to the same
formula for f.
✷
We sometimes need a local version of the last theorem, involving stochas-
tic integrals up to the time ζ when X ﬁrst leaves a given domain D ⊂Rd. If
X is continuous and adapted, then ζ is clearly predictable, in the sense that ζ
is announced by some optional times τn ↑ζ such that τn < ζ a.s. on {ζ > 0}
for all n. In fact, writing ρ for the Euclidean metric in Rd, we may choose
τn = inf{t ∈[0, n]; ρ(Xt, Dc) ≤n−1},
n ∈N.
(12)
Say that X is a semimartingale on [0, ζ) if the stopped process Xτn is a
semimartingale in the usual sense for every n ∈N. In that case we may deﬁne
the covariation processes [Xi, Xj] on the interval [0, ζ) by the requirement
that [Xi, Xj]τn = [(Xi)τn, (Xj)τn] a.s. for every n. Stochastic integrals w.r.t.
X1, . . . , Xd are deﬁned on [0, ζ) in a similar way.

288
Foundations of Modern Probability
Corollary 15.20 (local Itˆo-formula) Fix a domain D ⊂Rd, and let X be
a continuous semimartingale on [0, ζ), where ζ is the ﬁrst time X leaves D.
Then (10) holds a.s. on [0, ζ) for any f ∈C2(D).
Proof: Choose some functions fn ∈C2(Rd) with fn(x) = f(x) when
ρ(x, Dc) ≥n−1. Applying Theorem 15.19 to fn(Xτn) with τn as in (12), we
get (10) on [0, τn]. Since n was arbitrary, the result extends to [0, ζ).
✷
By a complex-valued continuous semimartingale we mean a process of the
form Z = X + iY , where X and Y are real continuous semimartingales. The
bilinearity of the covariation process suggests that we deﬁne the quadratic
variation of Z as
[Z] = [Z, Z] = [X + iY, X + iY ] = [X] + 2i[X, Y ] −[Y ].
Let us write L(Z) for the class of processes W = U + iV with U, V ∈
L(X) ∩L(Y ). For such a process W we deﬁne the integral
W · Z = (U + iV ) · (X + iY ) = U · X −V · Y + i(U · Y + V · X).
Corollary 15.21 (conformal mapping)
Let f be an analytic function on
some domain D ⊂C. Then (10) holds for any D-valued continuous semi-
martingale Z.
Proof: Writing f(x + iy) = g(x, y) + ih(x, y) for x + iy ∈D, we get
g′
1 + ih′
1 = f ′,
g′
2 + ih′
2 = if ′,
and by iteration
g′′
11 + ih′′
11 = f ′′,
g′′
12 + ih′′
12 = if ′′,
g′′
22 + ih′′
22 = −f ′′.
Equation (10) now follows for Z = X + iY , as we apply Corollary 15.20 to
the semimartingale (X, Y ) and the functions g and h.
✷
We shall next introduce a modiﬁcation of the Itˆo integral that does obey
the rules of ordinary calculus. Assuming both X and Y to be continuous
semimartingales, we deﬁne the Fisk–Stratonovich integral by

 t
0 X ◦dY = (X · Y )t + 1
2[X, Y ]t,
t ≥0,
(13)
or in diﬀerential form X ◦dY = XdY + 1
2d[X, Y ], where the ﬁrst term on
the right is an ordinary Itˆo integral.
Corollary 15.22 (modiﬁed substitution rule, Fisk, Stratonovich) For any
continuous semimartingale X in Rd and function f ∈C3(Rd), we have
f(Xt) = f(X0) +

 t
0 f ′
i(X) ◦dXi a.s.,
t ≥0.

15. Stochastic Integrals and Quadratic Variation
289
Proof: By Itˆo’s formula,
f ′
i(X) = f ′
i(X0) + f ′′
ij(X) · Xj + 1
2f ′′′
ijk(X) · [Xj, Xk].
Using Itˆo’s formula again, together with (6) and (13), we get

0 f ′
i(X) ◦dXi
=
f ′
i(X) · Xi + 1
2[f ′
i(X), Xi]
=
f ′
i(X) · Xi + 1
2f ′′
ij(X) · [Xj, Xi] = f(X) −f(X0).
✷
The price we have to pay for this more convenient substitution rule is
using an integral that does not preserve the martingale property and that
requires even the integrand to be a continuous semimartingale.
It is the
latter restriction that forces us to impose stronger regularity conditions on
the function f in the substitution rule.
Our next task is to establish a basic uniqueness property, which justiﬁes
our reference to the process V · M in Theorem 15.12 as an integral.
Theorem 15.23 (uniqueness) The integral V · M in Theorem 15.12 is the
a.s. unique linear extension of the elementary stochastic integral such that
for every t > 0 the convergence (V 2
n · [M])t
P→0 implies (Vn · M)∗
t
P→0.
The statement follows immediately from Lemmas 15.11 and 15.13, to-
gether with the following approximation of progressive processes by pre-
dictable step processes.
Lemma 15.24 (approximation) For any continuous semimartingale X =
M +A and process V ∈L(X), there exist some processes V1, V2, . . . ∈E such
that a.s. ((Vn −V )2 · [M])t →0 and ((Vn −V ) · A)∗
t →0 for every t > 0.
Proof: It is enough to take t = 1, since we can then combine the processes
Vn for disjoint ﬁnite intervals to construct an approximating sequence on R+.
Furthermore, it suﬃces to consider approximations in the sense of conver-
gence in probability, since the a.s. versions will then follow for a suitable
subsequence. This allows us to perform the construction in steps, ﬁrst ap-
proximating V by bounded and progressive processes V ′, next approximating
each V ′ by continuous and adapted processes V ′′, and ﬁnally approximating
each V ′′ by predictable step processes V ′′′.
Here the ﬁrst and last steps are elementary, so we may concentrate on the
second step. Then let V be bounded. We need to construct some continuous,
adapted processes Vn such that ((Vn−V )2·[M])1 →0 and ((Vn−V )·A)∗
1 →0
a.s. Since the Vn can be taken to be uniformly bounded, we may replace the
former condition by (|Vn −V | · [M])1 →0 a.s. Thus, it is enough to establish
the approximation (|Vn −V |·A)1 →0 in the case when A is a nondecreasing,
continuous, adapted process with A0 = 0. Replacing At by At+t if necessary,
we may even assume that A is strictly increasing.

290
Foundations of Modern Probability
To construct the required approximations, we may introduce the inverse
process Ts = sup{t ≥0; At ≤s}, and deﬁne
V h
t = h−1

 t
T(At−h) V dA = h−1

 At
(At−h)+
V (Ts)ds,
t, h > 0.
By Lebesgue’s diﬀerentiation Theorem A1.4 we have V h ◦T →V ◦T as
h →0, a.e. on [0, A1]. Thus, by dominated convergence,

 1
0 |V h −V |dA =

 A1
0
|V h(Ts) −V (Ts)|ds →0.
The processes V h are clearly continuous. To prove that they are also adapted,
we note that the process T(At−h) is adapted for every h > 0 by the deﬁnition
of T. Since V is progressive, it is further seen that V ·A is adapted and hence
progressive. The adaptedness of (V ·A)T(At−h) now follows by composition. ✷
Though the class L(X) of stochastic integrands is suﬃcient for most pur-
poses, it is sometimes useful to allow the integration of slightly more general
processes. Given any continuous semimartingale X = M + A, let ˆL(X) de-
note the class of product-measurable processes V such that (V −˜V )·[M] = 0
and (V −˜V )·A = 0 a.s. for some process ˜V ∈L(X). For V ∈ˆL(X) we deﬁne
V ·X = ˜V ·X a.s. The extension clearly enjoys all the previously established
properties of stochastic integration.
It is often important to see how semimartingales, covariation processes,
and stochastic integrals are transformed by a random time-change. Let us
then consider a nondecreasing, right-continuous family of ﬁnite optional times
τs, s ≥0, here referred to as a ﬁnite random time-change τ. If even F is
right-continuous, then by Lemma 6.3 the same thing is true for the induced
ﬁltration Gs = Fτs, s ≥0. A random process is said to be τ-continuous if it
is a.s. continuous on R+ and constant on every interval [τs−, τs], s ≥0, where
τ0−= X0−= 0 by convention.
Theorem 15.25 (random time-change, Kazamaki) Let τ be a ﬁnite random
time-change with induced ﬁltration G, and let X = M + A be a τ-continuous
F-semimartingale. Then X◦τ is a continuous G-semimartingale with canon-
ical decomposition M ◦τ +A◦τ and with [X ◦τ] = [X]◦τ a.s. Furthermore,
V ∈L(X) implies V ◦τ ∈ˆL(X ◦τ) and
(V ◦τ) · (X ◦τ) = (V · X) ◦τ a.s.
(14)
Proof: It is easy to check that the time-change X →X ◦τ preserves
continuity, adaptedness, monotonicity, and the local martingale property.
In particular, X ◦τ is then a continuous G-semimartingale with canonical
decomposition M ◦τ +A◦τ. Since M 2−[M] is a continuous local martingale,
the same thing is true for the time-changed process M 2 ◦τ −[M] ◦τ, and so
[X ◦τ] = [M ◦τ] = [M] ◦τ = [X] ◦τ a.s.

15. Stochastic Integrals and Quadratic Variation
291
If V ∈L(X), we further note that V ◦τ is product-measurable, since this is
true for both V and τ.
Fixing any t ≥0 and using the τ-continuity of X, we get
(1[0,t] ◦τ) · (X ◦τ) = 1[0,τ −1
t
] · (X ◦τ) = (X ◦τ)τ −1
t
= (1[0,t] · X) ◦τ,
which proves (14) when V = 1[0,t].
If X has locally ﬁnite variation, the
result extends by a monotone class argument and monotone convergence to
arbitrary V ∈L(X). In general, Lemma 15.24 yields the existence of some
continuous, adapted processes V1, V2, . . . such that
 (Vn −V )2d[M] →0 and
 |(Vn −V )dA| →0 a.s. By (14) the corresponding properties hold for the
time-changed processes, and since the processes Vn ◦τ are right-continuous
and adapted, hence progressive, we obtain V ◦τ ∈ˆL(X ◦τ).
Now assume instead that the approximating processes V1, V2, . . . are pre-
dictable step processes. The previous calculation then shows that (14) holds
for each Vn, and by Lemma 15.13 the relation extends to V .
✷
We shall next consider stochastic integrals of processes depending on a
parameter. Given any measurable space (S, S), we say that a process V on
S × R+ is progressive if its restriction to S × [0, t] is S ⊗Bt ⊗Ft-measurable
for every t ≥0, where Bt = B([0, t]). A simple version of the following result
will be useful in Chapter 16.
Theorem 15.26 (dependence on parameter, Dol´eans, Stricker and Yor) Let
X be a continuous semimartingale, ﬁx a measurable space S, and consider a
progressive process Vs(t), s ∈S, t ≥0, such that Vs ∈L(X) for every s ∈S.
Then the process Ys(t) = (Vs ·X)t has a version that is progressive on S ×R+
and a.s. continuous for each s ∈S.
Proof: Let X have canonical decomposition M + A. Assume that there
exist some progressive processes V n
s on S × R+ such that for any t ≥0 and
s ∈S
((V n
s −Vs)2 · [M])t
P→0,
((V n
s −Vs) · A)∗
t
P→0.
Then Lemma 15.13 yields (V n
s ·X −Vs·X)∗
t
P→0 for every s and t. Proceeding
as in the proof of Proposition 3.31, we may choose a subsequence (nk(s)) ⊂N
that depends measurably on s such that the same convergence holds a.s. along
(nk(s)) for any s and t. Now deﬁne Ys,t = lim supk(V nk
s
·X)t whenever this is
ﬁnite, and put Ys,t = 0 otherwise. If we can choose versions of the processes
(V n
s · X)t which are progressive on S × R+ and a.s. continuous for each s,
then Ys,t is clearly a version of the process (Vs ·X)t with the same properties.
This argument will now be applied in three steps.
First we may reduce to the case of bounded and progressive integrands,
by taking V n = V 1{|V | ≤n}. Next we may apply the transformation in the
proof of Lemma 15.24, to reduce to the case of continuous and progressive in-
tegrands. In the ﬁnal step, we may approximate any continuous, progressive

292
Foundations of Modern Probability
process V by the predictable step processes V n
s (t) = Vs(2−n[2nt]). Here the
integrals V n
s ·X are elementary, and the desired continuity and measurability
are obvious by inspection.
✷
We turn to the related topic of functional representations. To motivate
the problem, note that the construction of the stochastic integral V · X
depends in a subtle way on the underlying probability measure P and ﬁl-
tration F. Thus, we cannot expect any universal representation F(V, X) of
the integral process V · X. In view of Proposition 3.31 one might still hope
for a modiﬁed representation F(µ, V, X), where µ denotes the distribution
of (V, X). Even this may be too optimistic, however, since in general the
canonical decomposition of X depends even on F.
Dictated by our needs in Chapter 18, we shall restrict our attention to a
very special situation, which is still general enough to cover most applications
of interest. Fixing any progressive functions σi
j and bi of suitable dimension
deﬁned on the path space C(R+, Rd), we may consider an arbitrary adapted
process X satisfying the stochastic diﬀerential equation
dXi
t = σi
j(t, X)dBj
t + bi(t, X)dt,
(15)
where B is a Brownian motion in Rr. A detailed discussion of such equa-
tions is given in Chapter 18. For the moment we shall need only the simple
fact from Lemma 18.1 that the coeﬃcients σi
j(t, X) and bi(t, X) are again
progressive. Write aij = σi
kσj
k.
Proposition 15.27 (functional representation) For any progressive func-
tions σ, b, and f of suitable dimension, there exists some measurable map-
ping
F : P(C(R+, Rd)) × C(R+, Rd) →C(R+, R)
(16)
such that whenever X is a solution to (15) with distribution µ and with
f i(X) ∈L(Xi) for all i, we have f i(X) · Xi = F(µ, X) a.s.
Proof: From (15) we note that X is a semimartingale with covariation
processes [Xi, Xj] = aij(X)·λ and drift components bi(X)·λ. Hence, f i(X) ∈
L(Xi) for all i iﬀthe processes (f i)2aii(X) and f ibi(X) are a.s. Lebesgue
integrable.
Note that this holds in particular when f is bounded.
Now
assume that f1, f2, . . . are progressive with
(f i
n −f i)2aii(X) · λ →0,
|(f i
n −f i)bi(X)| · λ →0.
(17)
Then (f i
n(X) · Xi −f i(X) · Xi)∗
t
P→0 for every t ≥0 by Lemma 15.13. Thus,
if f i
n(X) · Xi = Fn(µ, X) a.s. for some measurable mappings Fn as in (16),
then Proposition 3.31 yields a similar representation for the limit f i(X) · Xi.
As in the preceding proof, we may apply this argument in three steps:
ﬁrst reducing to the case when f is bounded, next to the case of continuous

15. Stochastic Integrals and Quadratic Variation
293
f, and ﬁnally to the case when f is a predictable step function. Here the
ﬁrst and last steps are again elementary. For the second step we may now
use the simpler approximation
fn(t, x) = n

 t
(t−n−1)+
f(s, x)ds,
t ≥0, n ∈N, x ∈C(R+, Rd).
By Lebesgue’s diﬀerentiation Theorem A1.4 we have fn(t, x) →f(t, x) a.e.
in t for each x ∈C(R+, Rd), and so (17) follows by dominated convergence. ✷
Exercises
1. Show that if M is a local martingale and ξ is an F0-measurable random
variable, then the process Nt = ξMt is again a local martingale.
2. Use Fatou’s lemma to show that every local martingale M ≥0 with
EM0 < ∞is a supermartingale. Also show by an example that M may
fail to be a martingale. (Hint: Let Mt = Xt/(1−t)+, where X is a Brownian
motion starting at 1, stopped when it reaches 0.)
3. Fix a continuous local martingale M. Show that M and [M] have a.s.
the same intervals of constancy. (Hint: For any r ∈Q+, put τ = inf{t > r;
[M]t > [M]r}. Then M τ is a continuous local martingale on [r, ∞) with
quadratic variation 0, so M τ is a.s. constant on [s, τ]. Use a similar argument
in the other direction.)
4. For any continuous local martingales Mn starting at 0 and associ-
ated optional times τn, show that (Mn)∗
τn
P→0 iﬀ[Mn]τn
P→0. State the
corresponding result for stochastic integrals.
5. Show that there exist some continuous semimartingales X1, X2, . . .
such that X∗
n
P→0 and yet [Xn]t ̸
P→0 for all t > 0. (Hint: Let B be a
Brownian motion stopped at time 1, put Ak2−n = B(k−1)+2−n, and interpolate
linearly. Deﬁne Xn = B −An.)
6. Consider a Brownian motion B and an optional time τ. Show that
EBτ = 0 when Eτ 1/2 < ∞and that EB2
τ = Eτ when Eτ < ∞. (Hint: Use
optional sampling and Proposition 15.7.)
7. Deduce the ﬁrst inequality in Proposition 15.10 from Proposition 15.18
and the classical Cauchy–Buniakovsky inequality.
8. Prove for any continuous semimartingales X and Y that [X + Y ]1/2 ≤
[X]1/2 + [Y ]1/2 a.s.
9. (Kunita and Watanabe) Let M and N be continuous local martingales,
and ﬁx any p, q, r > 0 with p−1 + q−1 = r−1.
Show that ∥[M, N]t∥2
2r ≤
∥[M]t∥p∥[N]t∥q for all t > 0.

294
Foundations of Modern Probability
10. Let M, N be continuous local martingales with M0 = N0 = 0. Show
that M⊥⊥N implies [M, N] ≡0 a.s.
Also show by an example that the
converse is false. (Hint: Let M = U · B and N = V · B for a Brownian
motion B and suitable U, V ∈L(B).)
11. Fix a continuous semimartingale X, and let U, V ∈L(X) with U = V
a.s. on some set A ∈F0. Show that U · X = V · X a.s. on A. (Hint: Use
Proposition 15.16.)
12. Fix a continuous local martingale M, and let U, U1, U2, . . . and V, V1,
V2, . . . ∈L(M) with |Un| ≤Vn, Un →U, Vn →V , and ((Vn −V ) · M)∗
t
P→0
for all t > 0.
Show that (Un · M)t
P→(U · M)t for all t.
(Hint: Write
(Un −U)2 ≤2(Vn −V )2 + 8V 2, and use Theorem 1.21 and Lemmas 3.2 and
15.13.)
13. Let B be a Brownian bridge. Show that Xt = Bt∧1 is a semimartingale
on R+ w.r.t. the induced ﬁltration. (Hint: Note that Mt = (1 −t)−1Bt is a
martingale on [0, 1), integrate by parts, and check that the compensator has
ﬁnite variation.)
14. Show by an example that the canonical decomposition of a continuous
semimartingale may depend on the ﬁltration. (Hint: Let B be Brownian
motion with induced ﬁltration F, put Gt = Ft∨σ(B1), and use the preceding
result.)
15. Show by stochastic calculus that t−pBt →0 a.s. as t →∞, where
B is a Brownian motion and p >
1
2. (Hint: Integrate by parts to ﬁnd the
canonical decomposition. Compare with the L1-limit.)
16. Extend Theorem 15.17 to a product of n semimartingales.
17. Consider a Brownian bridge X and a bounded, progressive process
V with
 1
0 Vtdt = 0 a.s.
Show that E
 1
0 V dX = 0.
(Hint: Integrate by
parts to get
 1
0 V dX =
 1
0 (V −U)dB, where B is a Brownian motion and
Ut = (1 −t)−1  1
t Vsds.)
18. Show that Proposition 15.18 remains valid for any ﬁnite optional times
t and tnk satisfying maxk(tnk −tn,k−1)
P→0.
19. Let M be a continuous local martingale. Find the canonical decom-
position of |M|p when p ≥2, and deduce for such a p the second relation in
Proposition 15.7. (Hint: Use Theorem 15.19. For the last part, use H¨older’s
inequality.)
20. Let M be a continuous local martingale with M0 = 0 and [M]∞≤1.
Show for any r ≥0 that P{supt Mt ≥r} ≤e−r2/2. (Hint: Consider the
supermartingale Z = exp(cM −c2[M]/2) for a suitable c > 0.)
21. Let X and Y be continuous semimartingales. Fix a t > 0 and a
sequence of partitions (tnk) of [0, t] with maxk(tnk −tn,k−1) →0. Show that
1
2
	
k(Ytnk + Ytn,k−1)(Xtnk −Xtn,k−1)
P→(Y ◦X)t. (Hint: Use Corollary 15.14
and Proposition 15.18.)

15. Stochastic Integrals and Quadratic Variation
295
22. A process is predictable if it is measurable with respect to the σ-
ﬁeld in R+ × Ωinduced by all predictable step processes. Show that every
predictable process is progressive. Conversely, given a progressive process X
and a constant h > 0, show that the process Yt = X(t−h)+ is predictable.
23.
Given a progressive process V and a nondecreasing, continuous,
adapted process A, show that there exists some predictable process ˜V with
|V −˜V | · A = 0 a.s. (Hint: Use Lemma 15.24.)
24. Use the preceding statement to give a short proof of Lemma 15.24.
(Hint: Begin with predictable V , using a monotone class argument.)
25. Construct the stochastic integral V · M by approximation from ele-
mentary integrals, using Lemmas 15.11 and 15.24. Show that the resulting
integral satisﬁes the relation in Theorem 15.12. (Hint: First let M ∈M2
and E(V 2 · [M])∞< ∞, and extend by localization.)
26. Let (V, B) d= (˜V , ˜B), where B and ˜B are Brownian motions on possibly
diﬀerent ﬁltered probability spaces and V ∈L(B), ˜V ∈L( ˜B). Show that
(V, B, V · B)
d= (˜V , ˜B, ˜V · ˜B). (Hint: Argue as in the proof of Proposition
15.27.)
27.
Let X be a continuous F-semimartingale.
Show that X remains
a semimartingale conditionally on F0, and that the conditional quadratic
variation agrees with [X]. Also show that if V ∈L(X), where V = σ(Y )
for some continuous process Y and measurable function σ, then V remains
conditionally X-integrable, and the conditional integral agrees with V · X.
(Hint: Conditioning on F0 preserves martingales.)

Chapter 16
Continuous Martingales
and Brownian Motion
Martingale characterization of Brownian motion; random time-
change of martingales; isotropic local martingales; integral repre-
sentations of martingales; iterated and multiple integrals; change
of measure and Girsanov’s theorem; Cameron–Martin theorem;
Wald’s identity and Novikov’s condition
This chapter deals with a wide range of applications of the stochastic calcu-
lus, the principal tools of which were introduced in the preceding chapter.
A recurrent theme is the notion of exponential martingales, which appear
in both a real and a complex variety. Exploring the latter yields an eﬀort-
less approach to L´evy’s celebrated martingale characterization of Brownian
motion as well as to the basic random time-change reduction of isotropic
continuous local martingales to a Brownian motion. By applying the latter
result to suitable compositions of Brownian motion with harmonic or ana-
lytic functions, we shall deduce some important information about Brownian
motion in Rd. Similar methods may be used to analyze a variety of other
transformations that lead to Gaussian processes.
As a further application of the exponential martingales, we shall derive
stochastic integral representations of Brownian functionals and martingales
and examine their relationship to the chaos expansions obtained by diﬀerent
methods in Chapter 11. In this context, we shall see how the previously
introduced multiple Wiener–Itˆo integrals can be expressed as iterated sin-
gle Itˆo integrals. A similar problem, of crucial importance for Chapter 18,
is to represent a continuous local martingale with absolutely continuous co-
variation processes in terms of stochastic integrals with respect to a suitable
Brownian motion.
Our last main topic is to examine the transformations induced by an
absolutely continuous change of probability measure. The density process
turns out to be a real exponential martingale, and any continuous local
martingale in the original setting will remain a martingale under the new
measure, apart from an additional drift term. The observation is useful for
applications, where it is often employed to remove the drift from a given
semimartingale. The appropriate change of measure then depends on the
process, and it becomes important to derive eﬀective criteria for a proposed
exponential process to be a true martingale.
296

16. Continuous Martingales and Brownian Motion
297
Our exposition in this chapter may be regarded as a continuation of the
discussion of martingales and Brownian motion from Chapters 6 and 11,
respectively. Changes of time and measure are both important for the theory
of stochastic diﬀerential equations, as developed in Chapters 18 and 20. The
time-change results for continuous martingales have a counterpart for point
processes explored in Chapter 22, where the general Poisson processes play
a role similar to that of the Gaussian processes here.
The results about
changes of measure are extended in Chapter 23 to the context of possibly
discontinuous semimartingales.
To elaborate on the new ideas, we begin with an introduction of complex
exponential martingales.
It is instructive to compare them with the real
versions appearing in Lemma 16.21.
Lemma 16.1 (complex exponential martingales) Let M be a real continuous
local martingale with M0 = 0. Then
Zt = exp(iMt + 1
2[M]t),
t ≥0,
is a complex local martingale satisfying Zt = 1 + i(Z · M)t a.s.
Proof: Applying Corollary 15.21 to the complex-valued semimartingale
Xt = iMt + 1
2[M]t and the entire function f(z) = ez, we get
dZt = Zt(dXt + 1
2d[X]t) = Zt(idMt + 1
2d[M]t −1
2d[M]t) = iZtdMt.
✷
The next result gives the basic connection between continuous martin-
gales and Gaussian processes. For any subset K of a Hilbert space, we write
ˆK for the closed linear subspace generated by K.
Lemma 16.2 (isometries and Gaussian processes) Fix a subset K of some
Hilbert space, and consider for each h ∈K a continuous local F-martingale
M h with M h
0 = 0 such that
[M h, M k]∞= ⟨h, k⟩a.s.,
h, k ∈K.
(1)
Then there exists some isonormal Gaussian process η⊥⊥F0 on ˆK with M h
∞=
ηh a.s. for all h ∈K.
Proof: Fix any linear combination Nt = u1M h1
t
+ · · · + unM hn
t , and con-
clude from (1) that
[N]∞=

j,kujuk[M hj, M hk]∞=

j,kujuk⟨hj, hk⟩= ∥h∥2,
where h = u1h1 + · · · + unhn.
The process Z = exp(iN + 1
2[N]) is a.s.
bounded, and so by Lemma 16.1 it is a uniformly integrable martingale.
Writing ξ = N∞, we hence obtain for any A ∈F0
PA = E[Z∞; A] = E[exp(iN∞+ 1
2[N]∞); A] = E[eiξ; A]e∥h∥2/2.

298
Foundations of Modern Probability
Since u1, . . . , un were arbitrary, we may conclude from the uniqueness the-
orem for characteristic functions that the random vector (M h1
∞, . . . , M hn
∞) is
independent of F0 and centered Gaussian with covariances ⟨hj, hk⟩. It is now
easy to construct a process η with the stated properties.
✷
As a ﬁrst application, we may establish the following basic characteriza-
tion of Brownian motion.
Theorem 16.3 (martingale characterization of Brownian motion, L´evy) Let
B = (B1, . . . , Bd) be a continuous local F-martingale in Rd with B0 = 0 and
[Bi, Bj]t ≡δijt a.s. Then B is an F-Brownian motion.
Proof: For ﬁxed s < t, we may apply Lemma 16.2 to the continuous local
martingales M i
r = Bi
r∧t −Bi
r∧s, r ≥s, i = 1, . . . , d, to see that the diﬀerences
Bi
t −Bi
s are i.i.d. N(0, t −s) and independent of Fs.
✷
The last theorem suggests the possibility of transforming an arbitrary
continuous local martingale M into a Brownian motion through a suitable
random time-change.
The result extends with the same proof to certain
higher-dimensional processes, and for convenience we consider directly the
version in Rd.
A continuous local martingale M = (M 1, . . . , M d) is said
to be isotropic if a.s. [M i] = [M j] and [M i, M j] = 0 for all i ̸= j. Note
in particular that this holds for Brownian motion in Rd.
When M is a
continuous local martingale in C, the condition is clearly equivalent to [M] =
0 a.s., or [ℜM] = [ℑM] and [ℜM, ℑM] = 0 a.s. For isotropic processes M,
we refer to [M 1] = · · · = [M d] or [ℜM] = [ℑM] as the rate process of M.
The proof is straightforward when [M]∞= ∞a.s., but in general it
requires a rather subtle extension of the ﬁltered probability space. To simplify
our statements, we assume the existence of any randomization variables we
may need. As in the elementary contexts of Chapter 5, this may require us to
pass from the original setup (Ω, A, F, P) to the product space (ˆΩ, ˆ
A, ˆF, ˆP),
where ˆΩ= Ω× [0, 1], ˆ
A = A ⊗B, ˆFt = Ft × [0, 1], and ˆP = P ⊗λ. Given
two ﬁltrations F and G on Ω, we say that G is a standard extension of F if
Ft ⊂Gt⊥⊥FtF for all t ≥0. This is precisely the condition needed to ensure
preservation of all adaptedness and conditioning properties. The notion is
still ﬂexible enough to admit a variety of useful constructions.
Theorem 16.4 (time-change reduction, Dambis, Dubins and Schwarz) Let
M be an isotropic continuous local F-martingale in Rd with M0 = 0, and
deﬁne
τs = inf{t ≥0; [M 1]t > s},
Gs = Fτs,
s ≥0.
Then there exist a standard extension ˆG of G and a ˆG-Brownian motion B
in Rd such that a.s. Bs = Mτs on [0, [M 1]∞) and M = B ◦[M 1].
Proof: We may take d = 1, the proof in higher dimensions being similar.
Introduce a Brownian motion X⊥⊥F with induced ﬁltration X, and put

16. Continuous Martingales and Brownian Motion
299
ˆGt = Gt ∨Xt. Since G⊥⊥X, it is clear that ˆG is a standard extension of both
G and X. In particular, X remains a Brownian motion under ˆG. Now deﬁne
Bs = Mτs +

 s
0 1{τr = ∞}dXr,
s ≥0.
(2)
Since M is τ-continuous by Proposition 15.6, Theorem 15.25 shows that the
ﬁrst term M ◦τ is a continuous G-martingale, and then also a ˆG-martingale,
with quadratic variation
[M ◦τ]s = [M]τs = s ∧[M]∞,
s ≥0.
The second term in (2) has quadratic variation s −s ∧[M]∞, and the covari-
ation vanishes since M ◦τ⊥⊥X. Thus, [B]s = s a.s., and so Theorem 16.3
shows that B is a ˆG-Brownian motion. Finally, Bs = Mτs for s < [M]∞,
which implies M = B ◦[M] a.s. by the τ-continuity of M.
✷
In two dimensions, isotropic martingales arise naturally through the com-
position of a complex Brownian motion B with an arbitrary (possibly mul-
tivalued) analytic function f. For a general continuous process X, we may
clearly choose a continuous evolution of f(X), as long as X avoids the pos-
sible singularities of f. Though no analytic functions exist in dimensions
d ≥3, it may still be useful to consider compositions with suitable harmonic
functions.
Theorem 16.5 (harmonic and analytic maps, L´evy)
(i) Let M be an isotropic continuous local martingale in Rd, and ﬁx an
harmonic function f such that M a.s. avoids the sigularities of f. Then
f(M) is a local martingale with [f(M)] = |∇f(M)|2 · [M 1].
(ii) Let M be a complex, isotropic continuous local martingale, and ﬁx an
analytic function f such that M a.s. avoids the singularities of f. Then
f(M) is again an isotropic local martingale with [ℜf(M)] = |f ′(M)|2 ·
[ℜM]. If B is a Brownian motion and f ′ ̸≡0, then [ℜf(B)] is a.s.
unbounded and strictly increasing.
Proof: (i) Using the isotropy of M, we get by Corollary 15.20
f(M) = f(M0) + f ′
i · M i + 1
2∆f(M) · [M 1].
Here the last term vanishes since f is harmonic, and so f(M) is a local
martingale. From the isotropy of M it is further seen that
[f(M)] =

i[f ′
i(M) · M i] =

i(f ′
i(M))2 · [M 1] = |∇f(M)|2 · [M 1].
(ii) Since f is analytic, we get by Corollary 15.21
f(M) = f(M0) + f ′(M) · M + 1
2f ′′(M) · [M].
(3)

300
Foundations of Modern Probability
Here the last term vanishes since M is isotropic. The same property also
yields
[f(M)] = [f ′(M) · M] = (f ′(M))2 · [M] = 0,
and so f(M) is again isotropic. Finally, writing M = X + iY and f ′(M) =
U + iV , we get
[ℜf(M)] = [U · X −V · Y ] = (U 2 + V 2) · [X] = |f ′(M)|2 · [ℜM].
If f ′ is not identically 0, it has at most countably many zeros. Hence, by
Fubini’s theorem
Eλ{t ≥0; f ′(Bt) = 0} =

 ∞
0
P{f ′(Bt) = 0}dt = 0,
and so [ℜf(B)] = |f ′(B)|2 · λ is a.s. strictly increasing. To see that it is also
a.s. unbounded, we note that f(B) converges a.s. on the set {[ℜf(B)] < ∞}.
However, f(B) diverges a.s. since f is nonconstant and the random walk
B0, B1, . . . is recurrent by Theorem 8.2.
✷
Combining the last two results, we may derive two basic properties of
Brownian motion in Rd, namely the polarity of singleton sets when d ≥2 and
the transience when d ≥3. Note that the latter property is a continuous-
time counterpart of Theorem 8.8 for random walks. Both properties play
important roles for the potential theory developed in Chapter 21. Deﬁne
τa = inf{t > 0; Bt = a}.
Theorem 16.6 (point polarity and transience, L´evy, Kakutani) For a Brow-
nian motion B in Rd, we have the following:
(i) if d ≥2, then τa = ∞a.s. for all a ∈Rd;
(ii) if d ≥3, then |Bt| →∞a.s. as t →∞.
Proof: (i) Here we may clearly take d = 2, so we may let B be a complex
Brownian motion. Applying Theorem 16.5 (ii) to the entire function ez, it
is seen that M = eB is a conformal local martingale with unbounded rate
[ℜM]. By Theorem 16.4 we have M −1 = X ◦[ℜM] a.s. for some Brownian
motion X, and since M ̸= 0 it follows that X a.s. avoids −1. Hence, τ−1 = ∞
a.s., and by the scaling and rotational symmetries of B we get τa = ∞a.s.
for every a ̸= 0. To extend the result to a = 0, we may conclude from the
Markov property at h > 0 that
P0{τ0 ◦θh < ∞} = E0PBh{τ0 < ∞} = 0,
h > 0.
As h →0, we get P0{τ0 < ∞} = 0, and so τ0 = ∞a.s.
(ii) Here we may take d = 3. For any a ̸= 0 we have τa = ∞a.s. by part
(i), and so by Theorem 16.5 (i) the process M = |B−a|−1 is a continuous local
martingale. By Fatou’s lemma M is then an L1-bounded supermartingale,
and so by Theorem 6.18 it converges a.s. toward some random variable ξ.
Since Mt
d→0 we have ξ = 0 a.s.
✷

16. Continuous Martingales and Brownian Motion
301
Combining part (i) of the last result with Theorem 17.11, we note that
a complex, isotropic continuous local martingale avoids every ﬁxed point
outside the origin. Thus, Theorem 16.5 (ii) applies to any analytic function
f with only isolated singularities.
Since f is allowed to be multivalued,
the result applies even to functions with essential singularities, such as to
f(z) = log(1 + z). For a simple application, we may consider the windings
of planar Brownian motion around a ﬁxed point.
Corollary 16.7 (skew-product representation, Galmarino)
Let B denote
complex Brownian motion starting at 1, and choose a continuous version
of V = arg B with V0 = 0. Then Vt ≡Y ◦(|B|−2 · λ)t a.s. for some real
Brownian motion Y ⊥⊥|B|.
Proof: Applying Theorem 16.5 (ii) with f(z) = log(1 + z), we note that
Mt = log |Bt| + iVt is a conformal martingale with rate [ℜM] = |B|−2 · λ.
Hence, by Theorem 16.4 there exists some complex Brownian motion Z =
X + iY with M = Z ◦[ℜM] a.s., and the assertion follows.
✷
For a nonisotropic continuous local martingale M in Rd, there is no single
random time-change that will reduce the process to a Brownian motion. How-
ever, we may transform each component M i separately, as in Theorem 16.4,
to obtain a collection of one-dimensional Brownian motions B1, . . . , Bd. If
the latter processes happen to be independent, they may clearly be combined
into a d-dimensional Brownian motion B = (B1, . . . , Bd). It is remarkable
that the required independence arises automatically whenever the original
components M i are strongly orthogonal, in the sense that [M i, M j] = 0 a.s.
for all i ̸= j.
Proposition 16.8 (orthogonality and independence, Knight) Let M 1, M 2,
. . . be strongly orthogonal, continuous local martingales starting at 0. Then
there exist some independent Brownian motions B1, B2, . . . such that M k =
Bk ◦[M k] a.s. for every k.
Proof: When [M k]∞= ∞a.s. for all k, the result is an easy consequence
of Lemma 16.2. In general, we may introduce a sequence of independent
Brownian motions X1, X2, . . . ⊥⊥F with induced ﬁltration X. Deﬁne
Bk
s = M k(τ k
s ) + Xk((s −[M k]∞)+),
s ≥0, k ∈N,
write ψt = −log(1 −t)+, and put Gt = Fψt + X(t−1)+, t ≥0. To check that
B1, B2, . . . have the desired joint distribution, we may clearly assume that
each [M k] is bounded. Then the processes N k
t = M k
ψt + Xk
(t−1)+ are strongly
orthogonal, continuous G-martingales with quadratic variations [N k]t =
[M k]ψt + (t −1)+, and we note that Bk
s = N k
σks , where σk
s = inf{t ≥0;
[N k]t > s}. The assertion now follows from the result for [M k]∞= ∞a.s. ✷

302
Foundations of Modern Probability
As a further application of Lemma 16.2, we consider a simple continuous-
time version of Theorem 9.19. Given a continuous semimartingale X on I =
R+ or [0, 1) and a progressive process T on I that takes values in ¯I = [0, ∞]
or [0, 1], respectively, we may deﬁne
(X ◦T −1)t =

I 1{Ts ≤t}dXs,
t ∈I,
as long as the integrals on the right exist. For motivation, we note that if ξ
is a random measure on I with “distribution function” Xt = ξ[0, t], t ∈I,
then X ◦T −1 is the distribution function of the transformed measure ξ ◦T −1.
Proposition 16.9 (measure-preserving progressive maps) Consider a Brow-
nian motion or bridge B and a progressive process T on R+ or [0, 1], respec-
tively, with λ ◦T −1 = λ a.s. Then B ◦T −1 d= B.
Proof: For Brownian motion the result is an immediate consequence of
Lemma 16.2, so we may assume that B is a Brownian bridge. Then Mt =
(1 −t)−1Bt is clearly a martingale on [0, 1), and so B is a semimartingale on
the same interval. Integrating by parts, we get
dBt = (1 −t)dMt −Mtdt ≡dXt −Mtdt.
(4)
Thus, [X] = [B]t ≡t a.s., and so X is a Brownian motion by Theorem 16.3.
Now let V be a bounded, progressive process on [0, 1] with nonrandom
integral V =
 1
0 Vtdt. Integrating by parts, we get for any u ∈[0, 1)

 u
0 VtMtdt
=
Mu

 u
0 Vtdt −

 u
0 dMt

 t
0 Vsds
=

 u
0 dMt

 1
t Vsds −Mu

 1
u Vtdt.
As u →1, we have (1 −u)Mu = Bu →0, and so the last term tends to zero.
Using dominated convergence and combining with (4), we get

 1
0 VtdBt =

 1
0 VtdXt −

 1
0 VtMtdt =

 1
0 (Vt −V t)dXt,
where V t = (1 −t)−1  1
t Vsds. Letting U be another bounded, progressive
process, we get by a simple calculation

 1
0 (Ut −U t)(Vt −V t)dt =

 1
0 UtVtdt −U V .
In particular, if Ur = 1{Tr ≤s} and Vr = 1{Tr ≤t}, the right-hand side
becomes s ∧t −st = E(BsBt), and the assertion follows by Lemma 16.2. ✷
We shall next consider a basic representation of martingales with respect
to a Brownian ﬁltration.

16. Continuous Martingales and Brownian Motion
303
Theorem 16.10 (Brownian martingales) Let F be the complete ﬁltration
induced by a Brownian motion B = (B1, . . . , Bd) in Rd. Then any local F-
martingale M is a.s. continuous, and there exist some (P × λ)-a.e. unique
processes V 1, . . . , V d ∈L(B1) such that
M = M0 +

k≤dV k · Bk a.s.
(5)
As a consequence we obtain the following representation of Brownian
functionals, which we prove ﬁrst.
Lemma 16.11 (Brownian functionals, Itˆo)
Let B = (B1, . . . , Bd) be a
Brownian motion in Rd, and ﬁx a B-measurable random variable ξ with
Eξ = 0 and Eξ2 < ∞. Then there exist some (P × λ)-a.e. unique processes
V 1, . . . , V d ∈L2(B1) such that ξ =
	
k(V k · Bk)∞a.s.
Proof (Dellacherie): Let H denote the Hilbert space of B-measurable
random variables ξ with Eξ = 0 and Eξ2 < ∞, and write H′ for the subspace
of elements ξ admitting an integral representation 	
k(V k · Bk)∞. For such a
ξ we get Eξ2 = E
	
k((V k)2 ·λ)∞, which implies the asserted uniqueness. By
the obvious completeness of L2(B1), it is further seen from the same formula
that H′ is closed. To prove H′ = H it remains to show that any ξ ∈H ⊖H′
vanishes a.s.
Then ﬁx any nonrandom functions u1, . . . , ud ∈L2(R). Put M =
	
k uk ·
Bk, and deﬁne the process Z as in Lemma 16.1. Then Z −1 = iZ · M =
i 	
k(Zuk)·Bk by Proposition 15.15, and so ξ ⊥(Z∞−1), or E ξ exp{i
	
k(uk·
Bk)∞} = 0.
Specializing to step functions uk and using the uniqueness
theorem for characteristic functions, we get
E[ξ; (Bt1, . . . , Btn) ∈C] = 0,
t1, . . . , tn ∈R+, C ∈Bn, n ∈N.
By a monotone class argument this extends to E[ξ; A] = 0 for arbitrary
A ∈F∞, and so ξ = E[ξ|F∞] = 0 a.s.
✷
Proof of Theorem 16.10: We may clearly take M0 = 0, and by suitable
localization we may assume that M is uniformly integrable. Then M∞exists
as an element in L1(F∞) and it may be approximated in L1 by some ran-
dom variables ξ1, ξ2, . . . ∈L2(F∞). The martingales M n
t = E[ξn|Ft] are a.s.
continuous by Lemma 16.11, and by Proposition 6.15 we get, for any ε > 0,
P{(∆M)∗> 2ε} ≤P{(M n −M)∗> ε} ≤ε−1E|ξn −M∞| →0.
Hence, (∆M)∗= 0 a.s., and so M is a.s. continuous. The remaining asser-
tions now follow by localization from Lemma 16.11.
✷
Our next theorem deals with the converse problem of ﬁnding a Brownian
motion B satisfying (5) when the representing processes V k are given. The
result plays a crucial role in Chapter 18.

304
Foundations of Modern Probability
Theorem 16.12 (integral representation, Doob) Let M be a continuous lo-
cal F-martingale in Rd with M0 = 0 such that [M i, M j] = V i
kV j
k · λ a.s. for
some F-progressive processes V i
k, 1 ≤i ≤d, 1 ≤k ≤r. Then there exists
some Brownian motion B in Rr with respect to a standard extension of F
such that M i = V i
k · Bk a.s. for all i.
Proof: For any t ≥0, let Nt and Rt be the null and range spaces of the
matrix Vt, and write N ⊥
t and R⊥
t for their orthogonal complements. Denote
the corresponding orthogonal projections by πNt, πRt, πN⊥
t , and πR⊥
t , respec-
tively. Note that Vt is a bijection from N ⊥
t to Rt, and write V −1
t
for the inverse
mapping from Rt to N ⊥
t . All these mappings are clearly Borel-measurable
functions of Vt, and hence again progressive.
Now introduce a Brownian motion X⊥⊥F in Rr with induced ﬁltration
X, and note that Gt = Ft ∨Xt, t ≥0, is a standard extension of both F and
X. Thus, V remains G-progressive and the martingale properties of M and
X are still valid for G. Consider in Rr the local G-martingale
B = V −1πR · M + πN · X.
The covariation matrix of B has density
(V −1πR)V V ′(V −1πR)′ + πNπ′
N = πN⊥π′
N⊥+ πNπ′
N = πN⊥+ πN = I,
and so Theorem 16.3 shows that B is a Brownian motion. Furthermore, the
process πR⊥· M = 0 vanishes a.s. since its covariation matrix has density
πR⊥V V ′π′
R⊥= 0. Hence, by Proposition 15.15,
V · B = V V −1πR · M + V πN · Y = πR · M = (πR + πR⊥) · M = M.
✷
We may next prove a Fubini-type theorem, which shows how the multiple
Wiener–Itˆo integrals deﬁned in Chapter 11 can be expressed in terms of
iterated Itˆo integrals. Then introduce for each n ∈N the simplex
∆n = {(t1, . . . , tn) ∈Rn
+; t1 < · · · < tn}.
Given a function f ∈L2(Rn
+, λn), we shall write ˆf = n! ˜f1∆n, where ˜f denotes
the symmetrization of f deﬁned in Chapter 11.
Theorem 16.13 (multiple and iterated integrals) Consider a Brownian mo-
tion B in R with associated multiple Wiener–Itˆo integrals In, and ﬁx any
f ∈L2(Rn
+). Then
Inf =

dBtn

dBtn−1 · · ·

ˆf(t1, . . . , tn)dBt1 a.s.
(6)

16. Continuous Martingales and Brownian Motion
305
Though a formal veriﬁcation is easy, the construction of the iterated in-
tegral on the right depends in a subtle way on the choice of suitable versions
in each step. We are implicitly asserting the existence of versions such that
the right-hand side exists.
Proof: We shall prove by induction that the iterated integral
V k
tk+1,...,tn =

dBtk

dBtk−1 · · ·

ˆf(t1, . . . , tn)dBt1
exists for almost all tk+1, . . . , tn, and that V k has a version supported by
∆n−k that is progressive as a process in tk+1 with parameters tk+2, . . . , tn.
Furthermore, we shall establish the relation
E

V k
tk+1,...,tn
2 =

· · ·

{ ˆf(t1, . . . , tn)}2dt1 · · · dtk.
(7)
This allows us, in the next step, to deﬁne V k+1
tk+2,...,tn for almost all tk+2, . . . , tn.
The integral V 0 = ˆf clearly has the stated properties.
Now assume
that a version of the integral V k−1
tk,...,tn has been constructed with the desired
properties. For any tk+1, . . . , tn such that (7) is ﬁnite, Theorem 15.26 shows
that the process
Xk
t,tk+1,...,tn =

 t
0 V k−1
tk,...,tndBtk,
t ≥0,
has a progressive version that is a.s. continuous in t for ﬁxed tk+1, . . . , tn. By
Proposition 15.16 we obtain
V k
tk+1,...,tn = Xk
tk+1,tk+1,...,tn a.s.,
tk+1, . . . , tn ≥0,
and the progressivity clearly carries over to V k, regarded as a process in tk+1
with parameters tk+2, . . . , tn. Since V k−1 is supported by ∆n−k+1, we may
choose Xk to be supported by R+ × ∆n−k, which ensures that V k will be
supported by ∆n−k. Finally, equation (7) for V k−1 yields
E

V k
tk+1,...,tn
2
=
E

 
V k−1
tk,...,tn
2 dtk
=

· · ·

{ ˆf(t1, . . . , tn)}2dt1 · · · dtk.
To prove (6), we note that the right-hand side is linear and L2-continuous
in f. Furthermore, the two sides agree for indicator functions of rectangular
boxes in ∆n. The relation extends by a monotone class argument to arbitrary
indicator functions in ∆n, and the further extension to L2(∆n) is immediate.
It remains to note that Inf = In ˜f = In ˆf for any f ∈L2(Rn
+).
✷
So far we have obtained two diﬀerent representations of Brownian func-
tionals with zero mean and ﬁnite variance, namely the chaos expansion in

306
Foundations of Modern Probability
Theorem 11.26 and the stochastic integral representation in Lemma 16.11.
We proceed to examine how they are related. For any function f ∈L2(Rn
+),
we deﬁne ft(t1, . . . , tn−1) = f(t1, . . . , tn−1, t) and, when ∥ft∥< ∞, write
In−1f(t) = In−1ft.
Proposition 16.14 (chaos and integral representations) Fix a Brownian
motion B in R, and let ξ be a B-measurable random variable with chaos
expansion 	
n≥1 Infn. Then ξ = (V · B)∞a.s., where
Vt =

n≥1In−1 ˆfn(t),
t ≥0.
Proof: For any m ∈N we get, as in the last proof,

dt

n≥m
E{In−1 ˆfn(t)}2 =

n≥m
∥ˆfn∥2 =

n≥m
E(Infn)2 < ∞.
(8)
Since integrals Inf with diﬀerent n are orthogonal, it follows that the series
for Vt converges in L2 for almost every t ≥0. On the exceptional set we
may redeﬁne Vt to be 0. As before, we may choose progressive versions of
the integrals In−1 ˆfn(t), and from the proof of Corollary 3.32 it is clear that
even the sum V can be chosen to be progressive. Applying (8) with m = 1,
we then obtain V ∈L(B).
Using Theorem 16.13, we get by a formal calculation
ξ =

n≥1
Infn =

n≥1

In−1 ˆfn(t)dBt =

dBt

n≥1
In−1 ˆfn(t) =

VtdBt.
To justify the interchange of integration and summation, we may use (8) and
conclude as m →∞that
E

dBt

n≥mIn−1 ˆfn(t)
2
=

dt

n≥mE{In−1 ˆfn(t)}2
=

n≥mE(Infn)2 →0.
✷
Let us now consider two diﬀerent probability measures P and Q on the
same measurable space (Ω, A), equipped with a right-continuous and P-
complete ﬁltration (Ft).
If Q ≪P on Ft, we denote the corresponding
density by Zt, so that Q = Zt · P on Ft. The martingale property depends
on the choice of probability measure, so we need to distinguish between P-
martingales and Q-martingales. Integration with respect to P is denoted by
E as usual, and we write F∞=

t Ft.
Lemma 16.15 (absolute continuity) Let Q = Zt · P on Ft for all t ≥0.
Then Z is a P-martingale, and it is further uniformly integrable iﬀQ ≪P
on F∞. More generally, an adapted process X is a Q-martingale iﬀXZ is a
P-martingale.

16. Continuous Martingales and Brownian Motion
307
Proof: For any adapted process X, we note that Xt is Q-integrable iﬀ
XtZt is P-integrable. If this holds for all t, we may write the Q-martingale
property of X as

A XsdQ =

A XtdQ,
A ∈Fs, s < t.
By the deﬁnition of Z, it is equivalent that
E[XsZs; A] = E[XtZt; A],
A ∈Fs, s < t,
which means that XZ is a P-martingale. This proves the last assertion, and
the ﬁrst statement follows as we take Xt ≡1.
Next assume that Z is uniformly P-integrable, say with L1-limit Z∞. For
any t < u and A ∈Ft we have QA = E[Zu; A]. As u →∞, it follows that
QA = E[Z∞; A], which extends by a monotone class argument to arbitrary
A ∈F∞. Thus, Q = Z∞· P on F∞. Conversely, if Q = ξ · P on F∞, then
Eξ = 1, and the P-martingale Mt = E[ξ|Ft] satisﬁes Q = Mt · P on Ft for
each t. But then Zt = Mt a.s. for each t, and Z is uniformly P-integrable
with limit ξ.
✷
By the last lemma and Theorem 6.27, we may henceforth assume that
the density process Z is rcll. The basic properties may then be extended to
optional times and local martingales as follows.
Lemma 16.16 (localization) Let Q = Zt · P on Ft for all t ≥0. Then we
have for any optional time τ
Q = Zτ · P on Fτ ∩{τ < ∞}.
(9)
Furthermore, an adapted rcll process X is a local Q-martingale iﬀXZ is a
local P-martingale.
Proof: By optional sampling
QA = E[Zτ∧t; A],
A ∈Fτ∧t, t ≥0,
so
Q[A; τ ≤t] = E[Zτ; A ∩{τ ≤t}],
A ∈Fτ, t ≥0,
and (9) follows by monotone convergence as t →∞.
To prove the last assertion, it is enough to show for any optional time τ
that Xτ is a Q-martingale iﬀ(XZ)τ is a P-martingale. This may be seen as
before if we note that Q = Zτ
t · P on Fτ∧t for each t.
✷
We shall also need the following positivity property.
Lemma 16.17 (positivity) For every t > 0 we have infs≤t Zs > 0 a.s. Q.

308
Foundations of Modern Probability
Proof: By Lemma 6.31 it is enough to show for each t > 0 that Zt > 0
a.s. Q. This is clear from the fact that Q{Zt = 0} = E[Zt; Zt = 0] = 0.
✷
In typical applications, the measure Q is not given at the outset but
needs to be constructed from the martingale Z. This requires some regularity
conditions on the underlying probability space.
Lemma 16.18 (existence) Fix any Polish space S, and let P be a probability
measure on Ω= D(R+, S), endowed with the right-continuous and complete
induced ﬁltration F. Furthermore, consider an F-martingale Z ≥0 with
Z0 = 1. Then there exists a probability measure Q on Ωwith Q = Zt · P on
Ft for all t ≥0.
Proof: For each t ≥0 we may introduce the probability measure Qt =
Zt · P on Ft, which may be regarded as a measure on D([0, t], S). Since the
spaces D([0, t], S) are Polish under the Skorohod topology, Corollary 5.15
ensures the existence of some probability measure Q on D(R+, S) with pro-
jections Qt, and it is easy to verify that Q has the stated properties.
✷
The following basic result shows how the drift term of a continuous semi-
martingale is transformed under a change of measure with a continuous den-
sity Z. An extension appears in Theorem 23.9.
Theorem 16.19 (transformation of drift, Girsanov, van Schuppen and
Wong) Let Q = Zt·P on Ft for each t ≥0, where Z is a.s. continuous. Then
for any continuous local P-martingale M, the process ˜
M = M −Z−1 · [M, Z]
is a local Q-martingale.
Proof: First assume that Z−1 is bounded on the support of [M]. Then
˜
M is a continuous P-semimartingale, and we get by Proposition 15.15 and
an integration by parts
˜
MZ −( ˜
MZ)0
=
˜
M · Z + Z · ˜
M + [ ˜
M, Z]
=
˜
M · Z + Z · M −[M, Z] + [ ˜
M, Z]
=
˜
M · Z + Z · M,
which shows that
˜
MZ is a local P-martingale.
Hence,
˜
M is a local Q-
martingale by Lemma 16.16.
For general M, we may deﬁne τn = inf{t ≥0; Zt < 1/n} and conclude as
before that ˜
M τn is a local Q-martingale for each n ∈N. Since τn →∞a.s. Q
by Lemma 16.17, it follows by Lemma 15.1 that ˜
M is a local Q-martingale. ✷
The next result shows how the basic notions of stochastic calculus are
preserved under a change of measure. Here [X]P will denote the quadratic
variation of X under the probability measure P.
We shall further write
LP(X) for the class of X-integrable processes V under P, and let (V · X)P
be the corresponding stochastic integral.

16. Continuous Martingales and Brownian Motion
309
Proposition 16.20 (preservation laws) Let Q = Zt·P on Ft for each t ≥0,
where Z is continuous. Then any continuous P-semimartingale X is also a
Q-semimartingale, and [X]P = [X]Q a.s. Q. Furthermore, LP(X) ⊂LQ(X),
and for any V ∈LP(X) we have (V · X)P = (V · X)Q a.s. Q. Finally, any
continuous local P-martingale M satisﬁes (V ·M)∼= V · ˜
M a.s. Q whenever
either side exists.
Proof: Consider a continuous P-semimartingale X = M + A, where M is
a continuous local P-martingale and A is a process of locally ﬁnite variation.
Under Q we may write X = ˜
M +Z−1 ·[M, Z]+A, where ˜
M is the continuous
local Q-martingale of Theorem 16.19, and we note that Z−1 · [M, Z] has
locally ﬁnite variation since Z > 0 a.s. Q by Lemma 16.17. Thus, X is also
a Q-semimartingale. The statement for [X] is now clear from Proposition
15.18.
Now assume that V ∈LP(X). Then V 2 ∈LP([X]) and V ∈LP(A), so
the same relations hold under Q, and we get V ∈LQ( ˜
M + A). Thus, to
get V ∈LQ(X), it remains to show that V ∈LQ(Z−1[M, Z]). Since Z > 0
under Q, it is equivalent to show that V ∈LQ([M, Z]). But this is clear by
Proposition 15.10, since [M, Z]Q = [ ˜
M, Z]Q and V ∈LQ( ˜
M).
To prove the last assertion, we note as before that LQ(M) = LQ( ˜
M). If
V belongs to either class, then by Proposition 15.15 we get under Q the a.s.
relations
(V · M)∼
=
V · M −Z−1 · [V · M, Z]
=
V · M −V Z−1 · [M, Z] = V · ˜
M.
✷
In particular, we note that if B is a P-Brownian motion in Rd, then ˜B is a
Q-Brownian motion by Theorem 16.3, since the two processes are continuous
martingales with the same covariation processes.
The preceding theory simpliﬁes when P and Q are equivalent on each Ft,
since in that case Z > 0 a.s. P by Lemma 16.17. If Z is also continuous, it
may be expressed as an exponential martingale. More general processes of
this type are considered in Theorem 23.8.
Lemma 16.21 (real exponential martingales) A continuous process Z > 0
is a local martingale iﬀit has an a.s. representation
Zt = E(M)t ≡exp(Mt −1
2[M]t),
t ≥0,
(10)
for some continuous local martingale M. In that case M is a.s. unique, and
for any continuous local martingale N we have [M, N] = Z−1 · [Z, N].
Proof: If M is a continuous local martingale, then so is E(M) by Itˆo’s
formula. Conversely, assume that Z > 0 is a continuous local martingale.
Then by Corollary 15.20,
log Z −log Z0 = Z−1 · Z −1
2Z−2 · [Z] = Z−1 · Z −1
2[Z−1 · Z],

310
Foundations of Modern Probability
and (10) follows with M = log Z0 + Z−1 · Z. The last assertion is clear from
this expression, and the uniqueness of M follows from Proposition 15.2.
✷
We shall now see how Theorem 16.19 can be used to eliminate the drift of
a continuous semimartingale, and we begin with the simple case of Brownian
motion B with a deterministic drift. Here we shall need the fact that E(B)
is a true martingale, as can be seen most easily by a direct computation.
By P ∼Q we mean that P ≪Q and Q ≪P. Write L2
loc for the class of
functions f : R+ →Rd such that |f|2 is locally Lebesgue integrable. For any
f ∈L2
loc we deﬁne f · λ = (f 1 · λ, . . . , f d · λ), where the components on the
right are ordinary Lebesgue integrals.
Theorem 16.22 (shifted Brownian motion, Cameron and Martin) Let F
be the complete ﬁltration induced by canonical Brownian motion B in Rd,
ﬁx a continuous function h : R+ →Rd with h0 = 0, and write Ph for the
distribution of B + h. Then Ph ∼P0 on Ft for all t ≥0 iﬀh = f · λ for
some f ∈L2
loc, in which case Ph = E(f · B)t · P0.
Proof: If Ph ∼P0 on each Ft, then by Lemmas 16.15 and 16.17 there
exists some P0-martingale Z > 0 such that Ph = Zt · P0 on Ft for each t ≥0.
Theorem 16.10 shows that Z is a.s. continuous, and by Lemma 16.21 it can
then be written as E(M) for some continuous local P0-martingale M. Using
Theorem 16.10 again, we note that M = V · B = 	
i V i · Bi a.s. for some
processes V i ∈L(B1), and in particular V ∈L2
loc a.s.
By Theorem 16.19 the process ˜B = B −[B, M] = B −V · λ is a Ph-
Brownian motion, and so, under Ph, the canonical process B has two semi-
martingale decompositions, namely
B = ˜B + V · λ = (B −h) + h.
By Proposition 15.2 the decomposition is a.s. unique, and so V · λ = h a.s.
Thus, h = f · λ for some nonrandom function f ∈L2
loc, and furthermore
λ{t ≥0; Vt ̸= ft} = 0 a.s., which implies M = V · B = f · B a.s.
Conversely, assume that h = f · λ for some f ∈L2
loc. Since M = f · B
is a time-changed Brownian motion under P0, the process Z = E(M) is a
P0-martingale, and by Lemma 16.18 there exists a probability measure Q on
C(R+, Rd) with Q = Zt · P0 on Ft for each t ≥0. Moreover, Theorem 16.19
shows that ˜B = B −[B, M] = B −h is a Q-Brownian motion, which means
that Q = Ph. In particular, Ph ∼P0 on each Ft.
✷
In more general cases, Theorem 16.19 and Lemma 16.21 may suggest that
we try to remove the drift of a semimartingale through a change of measure
of the form Q = E(M)t·P on Ft for each t ≥0, where M is a continuous local
martingale with M0 = 0. By Lemma 16.15 it is then necessary for Z = E(M)
to be a true martingale. This is ensured by the following condition.

16. Continuous Martingales and Brownian Motion
311
Theorem 16.23 (uniform integrability, Novikov) Let M be a continuous
local martingale with M0 = 0 such that Ee[M]∞/2 < ∞. Then E(M) is a
uniformly integrable martingale.
The result will ﬁrst be proved in a special case.
Lemma 16.24 (Wald’s identity) If B is a real Brownian motion and τ is
an optional time with Eeτ/2 < ∞, then E exp(Bτ −1
2τ) = 1.
Proof: We shall ﬁrst consider the special optional times
τb = inf{t ≥0; Bt = t −b},
b > 0.
Since the τb remain optional with respect to the right-continuous induced
ﬁltration, we may assume B to be canonical Brownian motion with associated
distribution P = P0. Deﬁning ht ≡t and Z = E(B), it is seen from Theorem
16.22 that Ph = Zt · P on Ft for each t ≥0. Since τb < ∞a.s. under both P
and Ph, Lemma 16.16 yields
E exp(Bτb −1
2τb) = EZτb = E[Zτb; τb < ∞] = Ph{τb < ∞} = 1.
In the general case, the stopped process Mt ≡Zt∧τb is a positive martin-
gale, and Fatou’s lemma shows that M is even a supermartingale on [0, ∞].
Since, moreover, EM∞= EZτb = 1 = EM0, it is clear from the Doob
decomposition that M is a true martingale on [0, ∞]. Hence, by optional
sampling,
1 = EMτ = EZτ∧τb = E[Zτ; τ ≤τb] + E[Zτb; τ > τb].
(11)
By the deﬁnition of τb and hypothesis on τ, we get as b →∞
E[Zτb; τ > τb] = e−bE[eτb/2; τ > τb] ≤e−bEeτ/2 →0,
so the last term in (11) tends to zero. Since, moreover, τb →∞, the ﬁrst
term on the right tends to EZτ by monotone convergence, and the desired
relation EZτ = 1 follows.
✷
Proof of Theorem 16.23: Since E(M) is always a supermartingale on
[0, ∞], it is enough to show under the stated condition that EE(M)∞= 1.
We may then use Theorem 16.4 and Proposition 6.9 to reduce to the state-
ment of Lemma 16.24.
✷
In particular, we obtain the following classical result for Brownian motion.
Corollary 16.25 (Brownian motion with drift, Girsanov) Consider in Rd
a Brownian motion B and a progressive process V with E exp{ 1
2(|V |2·λ)∞} <
∞. Then Q = E(V ′ · B)∞· P is a probability measure, and ˜B = B −V · λ is
a Q-Brownian motion.

312
Foundations of Modern Probability
Proof: Combine Theorems 16.19 and 16.23.
✷
Exercises
1. Assume in Theorem 16.4 that [M]∞= ∞a.s. Show that M is τ-
continuous in the sense of Theorem 15.25, and use Theorem 16.3 to conclude
that B = M ◦τ is a Brownian motion. Also show for any V ∈L(M) that
(V ◦τ) · B = (V · M) ◦τ a.s.
2. If B is a real Brownian motion and V ∈L(B), then X = V · B is
a time-changed Brownian motion. Express the required time-change τ in
terms of V , and verify that X is τ-continuous.
3. Let M be a real continuous local martingale. Show that M converges
a.s. on the set {supt Mt < ∞}. (Hint: Use Theorem 16.4.)
4. Let M be a nontrivial isotropic continuous local martingale in Rd, and
ﬁx an aﬃne transformation f on Rd. Show that even f(M) is isotropic iﬀf
is conformal (i.e., the composition of a rigid motion with a change of scale).
5.
Deduce Theorem 16.6 (ii) from Theorem 8.8.
(Hint: Deﬁne τ =
inf{t; |Bt| = 1}, and iterate the construction to form a random walk in Rd
with steps of size 1.)
6. Deduce Theorem 16.3 for d = 1 from Theorem 12.17. (Hint: Proceed
as above to construct a discrete-time martingale with jumps of size h. Let
h →0, and use a version of Proposition 15.18.)
7. Consider a real Brownian motion B and a family of progressive pro-
cesses V t ∈L2(B), t ≥0. Give necessary and suﬃcient conditions on the V t
for the existence of a Brownian motion B′, such that B′
t = (V t · B)∞a.s. for
each t. Verify the conditions in the case of Proposition 16.9.
8. Use Proposition 16.9 to give direct proofs of the relation τ1
d= τ2 in
Theorems 11.16 and 11.17. (Hint: Imitate the proof of Theorem 9.20.)

Chapter 17
Feller Processes and Semigroups
Semigroups, resolvents, and generators; closure and core; Hille–
Yosida theorem; existence and regularization; strong Markov prop-
erty; characteristic operator; diﬀusions and elliptic operators;
convergence and approximation
Our aim in this chapter is to continue the general discussion of continuous-
time Markov processes initiated in Chapter 7. We have already seen several
important examples of such processes, such as the pure jump-type processes
in Chapter 10, Brownian motion in Chapters 11 and 16, and the general
L´evy processes in Chapter 13. The present treatment will be supplemented
by detailed studies of diﬀusions in Chapters 18 and 20, and of excursions and
additive functionals in Chapters 19 and 22.
The crucial new idea is to regard the transition kernels as operators Tt
on an appropriate function space. The Chapman–Kolmogorov relation then
turns into the semigroup property TsTt = Ts+t, which suggests a formal
representation Tt = etA in terms of a generator A. Under suitable regularity
conditions—the so-called Feller properties—it is indeed possible to deﬁne
a generator A that describes the inﬁnitesimal evolution of the underlying
process X. Under further hypotheses, X will be shown to have continuous
paths iﬀA is (an extension of) an elliptic diﬀerential operator. In general,
the powerful Hille–Yosida theorem provides the precise conditions for the
existence of a Feller process corresponding to a given operator A.
Using the basic regularity theorem for submartingales from Chapter 6, it
will be shown that every Feller process has a version that is right-continuous
with left-hand limits (rcll). Given this fundamental result, it is straightfor-
ward to extend the strong Markov property to arbitrary Feller processes.
We shall also explore some profound connections with martingale theory.
Finally, we shall establish a general continuity theorem for Feller processes
and deduce a corresponding approximation of discrete-time Markov chains
by diﬀusions and other continuous-time Markov processes. The proofs of the
latter results will require some weak convergence theory from Chapter 14.
To clarify the connection between transition kernels and operators, let µ
be an arbitrary probability kernel on some measurable space (S, S). We may
then introduce an associated transition operator T, given by
Tf(x) = (Tf)(x) =

µ(x, dy)f(y),
x ∈S,
(1)
313

314
Foundations of Modern Probability
where f : S →R is assumed to be measurable and either bounded or non-
negative. Approximating f by simple functions, it is seen by monotone con-
vergence that Tf is again a measurable function on S. It is also clear that
T is a positive contraction operator, in the sense that 0 ≤f ≤1 implies
0 ≤Tf ≤1. A special role is played by the identity operator I, which cor-
responds to the kernel µ(x, ·) ≡δx. The importance of transition operators
for the study of Markov processes is due to the following simple fact.
Lemma 17.1 (semigroup property) The probability kernels µt, t ≥0, satisfy
the Chapman–Kolmogorov relation iﬀthe corresponding transition operators
Tt have the semigroup property
Ts+t = TsTt,
s, t ≥0.
(2)
Proof: For any B ∈S we have Ts+t1B(x) = µs+t(x, B) and
(TsTt)1B(x)
=
Ts(Tt1B)(x) =

µs(x, dy)(Tt1B)(y)
=

µs(x, dy)µt(y, B) = (µsµt)(x, B).
Thus, the Chapman–Kolmogorov relation is equivalent to Ts+t1B = (TsTt)1B
for any B ∈S. The latter relation extends to (2) by linearity and monotone
convergence.
✷
By analogy with the situation for the Cauchy equation, one might hope to
represent the semigroup in the form Tt = etA, t ≥0, for a suitable generator
A. For the formula to make sense, the operator A must be suitably bounded,
so that the exponential function can be deﬁned through a Taylor expansion.
We shall consider a simple case when such a representation exists.
Proposition 17.2 (pseudo-Poisson processes) Fix a measurable space S,
and let (Tt) be the transition semigroup of a pure jump-type Markov process
in S with bounded rate kernel α. Then Tt = etA for all t ≥0, where for any
bounded measurable function f : S →R
Af(x) =

(f(y) −f(x))α(x, dy),
x ∈S.
Proof: Choose a probability kernel µ and a constant c ≥0 such that
α(x, B) ≡cµ(x, B \ {x}). From Proposition 10.22 it is seen that the process
is pseudo-Poisson of the form X = Y ◦N, where Y is a discrete-time Markov
chain with transition kernel µ, and N is an independent Poisson process with
ﬁxed rate c. Letting T denote the transition operator associated with µ, we
get for any t ≥0 and f as stated,
Ttf(x)
=
Exf(Xt) =

n≥0Ex[f(Yn); Nt = n]
=

n≥0P{Nt = n}Exf(Yn)
=

n≥0e−ct(ct)n
n! T nf(x) = ect(T−I)f(x).

17. Feller Processes and Semigroups
315
Hence, Tt = etA holds for t ≥0 with
Af(x)
=
c(T −I)f(x) = c

(f(y) −f(x))µ(x, dy)
=

(f(y) −f(x))α(x, dy).
✷
For the further analysis, we assume S to be a locally compact, separable
metric space, and we write C0 = C0(S) for the class of continuous functions
f : S →R with f(x) →0 as x →∞. We make C0 into a Banach space by
introducing the norm ∥f∥= supx |f(x)|. A semigroup of positive contrac-
tion operators Tt on C0 is called a Feller semigroup if it has the additional
regularity properties
(F1) TtC0 ⊂C0, t ≥0,
(F2) Ttf(x) →f(x) as t →0, f ∈C0, x ∈S.
In Theorem 17.6 we show that (F1) and (F2) together with the semigroup
property imply the strong continuity
(F3) Ttf →f as t →0, f ∈C0.
For motivation, we proceed to clarify the probabilistic signiﬁcance of those
conditions. Then assume for simplicity that S is compact and further that
(Tt) is conservative in the sense that Tt1 = 1 for all t. For every initial state
x, we may then introduce an associated Markov process Xx
t , t ≥0, with
transition operators Tt.
Lemma 17.3 (Feller properties) If S is compact with metric ρ and (Tt) is
conservative, then
(F1) holds iﬀXx
t
d→Xy
t as x →y for ﬁxed t ≥0;
(F2) holds iﬀXx
t
P→x as t →0 for ﬁxed x;
(F3) holds iﬀsupx Ex[ρ(Xs, Xt) ∧1] →0 as s −t →0.
Proof: The ﬁrst two statements are obvious, so we shall prove only the
third one. Then choose a dense sequence f1, f2, . . . in C = C(S). By the
compactness of S we note that xn →x in S iﬀfk(xn) →fk(x) for each k.
Thus, ρ is topologically equivalent to the metric
ρ′(x, y) =

k2−k(|fk(x) −fk(y)| ∧1),
x, y ∈S.
Since S is compact, the identity mapping on S is uniformly continuous with
respect to ρ and ρ′, and so we may assume that ρ = ρ′.
Next we note that, for any f ∈C, x ∈S, and t, h ≥0,
Ex(f(Xt) −f(Xt+h))2
=
Ex(f 2 −2fThf −Thf 2)(Xt)
≤
∥f 2 −2fThf + Thf 2∥
≤
2∥f∥∥f −Thf∥+ ∥f 2 −Thf 2∥.

316
Foundations of Modern Probability
Assuming (F3), we get supx Ex|fk(Xs) −fk(Xt)| →0 as s −t →0 for ﬁxed
k, and so by dominated convergence supx Exρ(Xs, Xt) →0. Conversely, the
latter condition yields Thfk →fk for each k, which implies (F3).
✷
Our aim is now to construct the generator of an arbitrary Feller semigroup
(Tt) on C0.
In general, there is no bounded linear operator A satisfying
Tt = etA, and we need to look for a suitable substitute. For motivation, we
note that if p is a real-valued function on R+ with representation pt = eta,
then a can be recovered from p by either diﬀerentiation
t−1(pt −1) →a as t →0,
or integration

 ∞
0
e−λtptdt = (λ −a)−1,
λ > 0.
Motivated by the latter formula, we introduce for each λ > 0 the associ-
ated resolvent or potential Rλ, deﬁned as the Laplace transform
Rλf =

 ∞
0
e−λt(Ttf)dt,
f ∈C0.
Note that the integral exists, since Ttf(x) is bounded and right-continuous
in t ≥0 for ﬁxed x ∈S.
Theorem 17.4 (resolvents and generator) Let (Tt) be a Feller semigroup
on C0 with resolvents Rλ, λ > 0.
Then the operators λRλ are injective
contractions on C0 such that λRλ →I strongly as λ →∞. Furthermore,
the range D = RλC0 is independent of λ and dense in C0, and there exists
an operator A on C0 with domain D such that R−1
λ
= λ −A on D for every
λ > 0. Finally, A commutes on D with every Tt.
Proof: If f ∈C0, then (F1) shows that Ttf ∈C0 for every t, so by domi-
nated convergence we have even Rλf ∈C0. To prove the stated contraction
property, we may write for any f ∈C0
∥λRλf∥≤λ

 ∞
0
e−λt∥Ttf∥dt ≤λ∥f∥

 ∞
0
e−λtdt = ∥f∥.
A simple computation yields the resolvent equation
Rλ −Rµ = (µ −λ)RλRµ,
λ, µ > 0,
(3)
which shows that the operators Rλ commute and have the same range D. If
f = R1g with g ∈C0, we get by (3) and as λ →∞
∥λRλf −f∥
=
∥(λRλ −I)R1g∥= ∥(R1 −I)Rλg∥
≤
λ−1∥R1 −I∥∥g∥→0,
and the convergence extends by a simple approximation to the closure of D.

17. Feller Processes and Semigroups
317
Now introduce the one-point compactiﬁcation ˆS = S ∪{∆} of S and
extend any f ∈C0 to ˆC = C( ˆS) by putting f(∆) = 0. If D ̸= C0, then
by the Hahn–Banach theorem there exists some bounded linear functional
ϕ ̸≡0 on ˆC such that ϕR1f = 0 for all f ∈C0. By Riesz’s representation
Theorem A1.5 we may extend ϕ to a bounded, signed measure on ˆS. Letting
f ∈C0 and using (F2), we get by dominated convergence as λ →∞
0
=
λϕRλf =

ϕ(dx)

 ∞
0
λe−λtTtf(x)dt
=

ϕ(dx)

 ∞
0
e−sTs/λf(x)dt →ϕf,
and so ϕ ≡0. The contradiction shows that D is dense in C0.
To see that the operators Rλ are injective, let f ∈C0 with Rλ0f = 0 for
some λ0 > 0. Then (3) yields Rλf = 0 for every λ > 0, and since λRλf →f
as λ →∞, we get f = 0. Hence, the inverses R−1
λ
exist on D. Multiplying
(3) by R−1
λ
from the left and by R−1
µ
from the right, we get on D the relation
R−1
µ −R−1
λ
= µ −λ. Thus, the operator A = λ −R−1
λ
on D is independent
of λ.
To prove the ﬁnal assertion, note that Tt and Rλ commute for any t, λ > 0,
and write
Tt(λ −A)Rλ = Tt = (λ −A)RλTt = (λ −A)TtRλ.
✷
The operator A in Theorem 17.4 is called the generator of the semigroup
(Tt). The term is justiﬁed by the following lemma.
Lemma 17.5 (uniqueness) A Feller semigroup is uniquely determined by
its generator.
Proof: The operator A determines Rλ = (λ −A)−1 for all λ > 0. By the
uniqueness theorem for Laplace transforms, it then determines the measure
µ(dt) = Ttf(x)dt on R+ for any f ∈C0 and x ∈S. Since the density Ttf(x)
is right-continuous in t for ﬁxed x, the assertion follows.
✷
We now aim to show that any Feller semigroup is strongly continuous and
to derive abstract versions of Kolmogorov’s forward and backward equations.
Theorem 17.6 (strong continuity, forward and backward equations) Any
Feller semigroup (Tt) is strongly continuous and satisﬁes
Ttf −f =

 t
0 TsAfds,
f ∈D ≡dom(A), t ≥0.
(4)
Moreover, Ttf is diﬀerentiable at 0 iﬀf ∈D, and then
d
dt(Ttf) = TtAf = ATtf,
t ≥0.
(5)

318
Foundations of Modern Probability
Our proof depends on the following lemma, involving the Yosida approx-
imation
Aλ = λARλ = λ(λRλ −I),
λ > 0,
(6)
and the associated semigroup T λ
t = etAλ, t ≥0. The latter is clearly the
transition semigroup of a pseudo-Poisson process with rate λ based on the
transition operator λRλ.
Lemma 17.7 (Yosida approximation) For any f ∈D ≡dom(A) we have
∥Ttf −T λ
t f∥≤t∥Af −Aλf∥,
t, λ > 0,
(7)
and Aλf →Af as λ →∞. Furthermore, T λ
t f →Ttf as λ →∞for each
f ∈C0, uniformly for bounded t ≥0.
Proof: By Theorem 17.4 we have Aλf = λRλAf →Af for any f ∈D.
For ﬁxed λ > 0 it is further clear that h−1(T λ
h −I) →Aλ in the norm topology
as h →0. Now we have for any commuting contraction operators B and C
∥Bnf −Cnf∥
≤
∥Bn−1 + Bn−2C + · · · + Cn−1∥∥Bf −Cf∥
≤
n∥Bf −Cf∥.
Fixing any f ∈C0 and t, λ, µ > 0, we hence obtain as h = t/n →0
T λ
t f −T µ
t f

≤
n
T λ
h f −T µ
h f

=
t

T λ
h f −f
h
−T µ
h f −f
h
 →t
Aλf −Aµf
 .
For f ∈D it follows that T λ
t f is Cauchy convergent as λ →∞for ﬁxed t,
and since D is dense in C0, the same property holds for arbitrary f ∈C0.
Denoting the limit by ˜Ttf, we get in particular
T λ
t f −˜Ttf
 ≤t∥Aλf −Af∥,
f ∈D, t ≥0.
(8)
Thus, for each f ∈D we have T λ
t f →˜Ttf as λ →∞, uniformly for bounded
t, which again extends to all f ∈C0.
To identify ˜Tt, we may use the resolvent equation (3) to obtain, for any
f ∈C0 and λ, µ > 0,

 ∞
0
e−λtT µ
t µRµfdt = (λ −Aµ)−1µRµf =
µ
λ + µRνf,
(9)
where ν = λµ(λ + µ)−1. As µ →∞, we have ν →λ, and so Rνf →Rλ.
Furthermore,
∥T µ
t µRµf −˜Ttf∥≤∥µRµf −f∥+ ∥T µ
t f −˜Ttf∥→0,
so from (9) we get by dominated convergence
 e−λt ˜Ttfdt = Rλf. Hence, the
semigroups (Tt) and ( ˜Tt) have the same resolvent operators Rλ, and so they
agree by Lemma 17.5. In particular, (7) then follows from (8).
✷

17. Feller Processes and Semigroups
319
Proof of Theorem 17.6: The semigroup (T λ
t ) is clearly norm continuous in
t for each λ > 0, and so the strong continuity of (Tt) follows by Lemma 17.7
as λ →∞. Furthermore, we note that h−1(T λ
h −I) →Aλ as h ↓0. Using
the semigroup relation and continuity, we obtain more generally
d
dtT λ
t = AλT λ
t = T λ
t Aλ,
t ≥0,
which implies
T λ
t f −f =

 t
0 T λ
s Aλfds,
f ∈C0, t ≥0.
(10)
If f ∈D, then by Lemma 17.7 we get as λ →∞
∥T λ
s Aλf −TsAf∥≤∥Aλf −Af∥+ ∥T λ
s Af −TsAf∥→0,
uniformly for bounded s, and so (4) follows from (10) as λ →∞. By the
strong continuity of Tt we may diﬀerentiate (4) to get the ﬁrst relation in
(5); the second relation holds by Theorem 17.4.
Conversely, assume that h−1(Thf −f) →g for some pair of functions
f, g ∈C0. As h →0, we get
ARλf ←Th −I
h
Rλf = Rλ
Thf −f
h
→Rλg,
and so
f = (λ −A)Rλf = λRλf −ARλf = Rλ(λf −g) ∈D.
✷
In applications, the domain of a generator A is often hard to identify or
too large to be convenient for computations. It is then useful to restrict A to
a suitable subdomain. An operator A with domain D on some Banach space
B is said to be closed if its graph G = {(f, Af); f ∈D} is a closed subset of
B2. In general, we say that A is closable if the closure G is the graph of a
single-valued operator A, the so-called closure of A. Note that A is closable
iﬀthe conditions D ∋fn →0 and Afn →g imply g = 0.
When A is closed, a core for A is deﬁned as a linear subspace D ⊂D
such that the restriction A|D has closure A. In this case, A is clearly uniquely
determined by A|D. We shall give some conditions ensuring that D ⊂D is a
core when A is the generator of a Feller semigroup (Tt) on C0.
Lemma 17.8 (closure and cores) The generator A of a Feller semigroup is
closed, and for any λ > 0, a subspace D ⊂D ≡dom(A) is a core for A iﬀ
(λ −A)D is dense in C0.
Proof: Assume that f1, f2, . . . ∈D with fn →f and Afn →g. Then
(I −A)fn →f −g, and since R1 is bounded it follows that fn →R1(f −g).
Hence, f = R1(f −g) ∈D, and we have (I −A)f = f −g, so g = Af. Thus,
A is closed.

320
Foundations of Modern Probability
If D is a core for A, then for any g ∈C0 and λ > 0 there exist some
f1, f2, . . . ∈D with fn →Rλg and Afn →ARλg, and we get (λ −A)fn →
(λ −A)Rλg = g. Thus, (λ −A)D is dense in C0.
Conversely, assume that (λ −A)D is dense in C0. To show that D is a
core, ﬁx any f ∈D. By hypothesis we may choose some f1, f2, . . . ∈D with
gn ≡(λ −A)fn →(λ −A)f ≡g.
Since Rλ is bounded, we obtain fn = Rλgn →Rλg = f and thus
Afn = λfn −gn →λf −g = Af.
✷
A subspace D ⊂C0 is said to be invariant under (Tt) if TtD ⊂D for all
t ≥0. In particular, we note that, for any subset B ⊂C0, the linear span of

t TtB is an invariant subspace of C0.
Proposition 17.9 (invariance and cores, Watanabe) If A is the generator
of a Feller semigroup, then any dense invariant subspace D ⊂dom(A) is a
core for A.
Proof: By the strong continuity of (Tt), we note that R1 can be approx-
imated in the strong topology by some ﬁnite linear combinations L1, L2, . . .
of the operators Tt. Now ﬁx any f ∈D and deﬁne gn = Lnf. Noting that A
and Ln commute on D by Theorem 17.4, we get
(I −A)gn = (I −A)Lnf = Ln(I −A)f →R1(I −A)f = f.
Since gn ∈D and D is dense in C0, it follows that (I −A)D is dense in C0.
Hence, D is a core by Lemma 17.8.
✷
The L´evy processes in Rd are the archetypes of Feller processes, and we
proceed to identify their generators. Let C∞
0 denote the class of all inﬁnitely
diﬀerentiable functions f on Rd such that f itself and all its derivatives belong
to C0 = C0(Rd).
Theorem 17.10 (L´evy processes) Let Tt, t ≥0, be the transition operators
of a L´evy process in Rd with characteristics (a, b, ν). Then (Tt) is a Feller
semigroup, and C∞
0
is a core for the associated generator A. Moreover, we
have for any f ∈C∞
0
and x ∈Rd
Af(x)
=
1
2

i,jaijf ′′
ij(x) +

ibif ′
i(x)
+

 
f(x + y) −f(x) −

iyif ′
i(x)1{|y| ≤1}

ν(dy). (11)
In particular, a standard Brownian motion in Rd has generator 1
2∆, and
the uniform motion with velocity b ∈Rd has generator b∇, both on the core
C∞
0 . Here ∆and ∇denote the Laplace and gradient operators, respectively.

17. Feller Processes and Semigroups
321
Also note that the generator of the jump component has the same form as for
the pseudo-Poisson processes in Proposition 17.2, apart from a compensation
for small jumps by a linear drift term.
Proof of Theorem 17.10: As t →0, we have µ∗[t−1]
t
w→µ1. Thus, Corollary
13.20 yields µt/t
v→ν on Rd \ {0} and
at,h ≡t−1

|x|≤h xx′µt(dx) →ah,
bt,h ≡t−1

|x|≤h xµt(dx) →bh,
(12)
provided that h > 0 satisﬁes ν{|x| = h} = 0. Now ﬁx any f ∈C∞
0 , and write
t−1(Ttf(x) −f(x)) = t−1

(f(x + y) −f(x))µt(dy)
=
t−1

|y|≤h

f(x + y) −f(x) −

iyif ′
i(x) −1
2

i,jyiyjf ′′
ij(x)

µt(dy)
+ t−1

|y|>h(f(x + y) −f(x))µt(dy) +

i
bt,h
i f ′
i(x) + 1
2

i,j
at,h
ij f ′′
ij(x).
As t →0, the last three terms approach the expression in (11), though with
aij replaced by ah
ij and with the integral taken over {|x| > h}. To establish
the required convergence, it is then enough to show that the ﬁrst term on
the right tends to zero as h →0, uniformly for small t > 0. But this is clear
from (12), since the integrand is of the order h|y|2 by Taylor’s formula. From
the uniform boundedness of the derivatives of f, it may further be seen that
the convergence is uniform in x. Thus, C∞
0 ⊂dom(A) by Theorem 17.6, and
(11) holds on C∞
0 .
It remains to show that C∞
0 is a core for A. Since C∞
0 is dense in C0, it is
enough by Proposition 17.9 to show that it is also invariant under (Tt). Then
note that, by dominated convergence, the diﬀerentiation operators commute
with each Tt, and use condition (F1).
✷
We shall next characterize the class of linear operators A on C0 such that
that the closure ¯A is the generator of a Feller semigroup.
Theorem 17.11 (characterization of generators, Hille, Yosida) Let A be a
linear operator on C0 with domain D. Then A is closable and the closure ¯A
is the generator of a Feller semigroup on C0 iﬀthese conditions hold:
(i) D is dense in C0;
(ii) the range of λ0 −A is dense in C0 for some λ0 > 0;
(iii) if f ∨0 ≤f(x) for some f ∈D and x ∈S, then Af(x) ≤0.
Here condition (iii) is known as the positive maximum principle.
Proof: First assume that ¯A is the generator of a Feller semigroup (Tt).
Then (i) and (ii) hold by Theorem 17.4. To prove (iii), let f ∈D and x ∈S
with f + = f ∨0 ≤f(x). Then
Ttf(x) ≤Ttf +(x) ≤∥Ttf +∥≤∥f +∥= f(x),
t ≥0,

322
Foundations of Modern Probability
so h−1(Thf −f)(x) ≤0, and as h →0 we get Af(x) ≤0.
Conversely, assume that A satisﬁes (i), (ii), and (iii).
Let f ∈D be
arbitrary, choose x ∈S with |f(x)| = ∥f∥, and put g = f sgn f(x). Then
g ∈D with g+ ≤g(x), and so (iii) yields Ag(x) ≤0. Thus, we get for any
λ > 0
∥(λ −A)f∥≥λg(x) −Ag(x) ≥λg(x) = λ∥f∥.
(13)
To show that A is closable, let f1, f2, . . . ∈D with fn →0 and Afn →g. By
(i) we may choose g1, g2, . . . ∈D with gn →g, and by (13) we have
∥(λ −A)(gm + λfn)∥≥λ∥gm + λfn∥,
m, n ∈N, λ > 0.
As n →∞, we get ∥(λ −A)gm −λg∥≥λ∥gm∥. Here we may divide by λ
and let λ →∞to obtain ∥gm −g∥≥∥gm∥, which yields ∥g∥= 0 as m →∞.
Thus, A is closable, and from (13) we note that the closure ¯A satisﬁes
∥(λ −¯A)f∥≥λ∥f∥,
λ > 0, f ∈dom( ¯A).
(14)
Now assume that λn →λ > 0 and (λn −¯A)fn →g for some f1, f2, . . . ∈
dom( ¯A). By (14) the sequence (fn) is then Cauchy, say with limit f ∈C0.
By the deﬁnition of ¯A we get (λ −¯A)f = g, so g belongs to the range of
λ−¯A. Letting Λ denote the set of constants λ > 0 such that λ−¯A has range
C0, it follows in particular that Λ is closed. If we can show that Λ is open as
well, then in view of (ii) we have Λ = (0, ∞).
Then ﬁx any λ ∈Λ, and conclude from (14) that λ −¯A has a bounded
inverse Rλ with norm ∥Rλ∥≤λ−1. For any µ > 0 with |λ −µ|∥Rλ∥< 1, we
may form the bounded linear operator
˜Rµ =

n≥0(λ −µ)nRn+1
λ
,
and we note that
(µ −¯A) ˜Rµ = (λ −¯A) ˜Rµ −(λ −µ) ˜Rµ = I.
In particular, µ ∈Λ, which shows that λ ∈Λ◦.
We may next establish the resolvent equation (3). Then start from the
identity (λ −¯A)Rλ = (µ −¯A)Rµ = I. By a simple rearrangement,
(λ −¯A)(Rλ −Rµ) = (µ −λ)Rµ,
and (3) follows as we multiply from the left by Rλ. In particular, (3) shows
that the operators Rλ and Rµ commute for any λ, µ > 0.
Since Rλ(λ −¯A) = I on dom( ¯A) and ∥Rλ∥≤λ−1, we have for any
f ∈dom( ¯A) as λ →∞
∥λRλf −f∥= ∥Rλ ¯Af∥≤λ−1∥¯Af∥→0.
From (i) and the contractivity of λRλ, it follows easily that λRλ →I in the
strong topology. Now deﬁne Aλ as in (6) and let T λ
t = etAλ. As in the proof

17. Feller Processes and Semigroups
323
of Lemma 17.7, we get T λ
t f →Ttf for each f ∈C0 uniformly for bounded
t, where the Tt form a strongly continuous family of contraction operators
on C0 such that
 e−λtTtdt = Rλ for all λ > 0. To deduce the semigroup
property, ﬁx any f ∈C0 and s, t ≥0, and note that as λ →∞
(Ts+t −TsTt)f = (Ts+t −T λ
s+t)f + T λ
s (T λ
t −Tt)f + (T λ
s −Ts)Ttf →0.
The positivity of the operators Tt will follow immediately if we can show
that Rλ is positive for each λ > 0. Then ﬁx any function g ≥0 in C0, and
put f = Rλg, so that g = (λ −¯A)f. By the deﬁnition of ¯A, there exist
some f1, f2, . . . ∈D with fn →f and Afn →¯Af. If infx f(x) < 0, we have
infx fn(x) < 0 for all suﬃciently large n, and we may choose some xn ∈S
with fn(xn) ≤fn ∧0. By (iii) we have Afn(xn) ≥0, and so
inf
x (λ −A)fn(x) ≤(λ −A)fn(xn) ≤λfn(xn) = λ inf
x fn(x).
As n →∞, we get the contradiction
0 ≤inf
x g(x) = inf
x (λ −¯A)f(x) ≤λ inf
x f(x) < 0.
It remains to show that ¯A is the generator of the semigroup (Tt). But this
is clear from the fact that the operators λ −¯A are inverses to the resolvent
operators Rλ.
✷
From the proof we note that any operator A on C0 satisfying the positive
maximum principle in (iii) must be dissipative, in the sense that ∥(λ−A)f∥≥
λ∥f∥for all f ∈dom(A) and λ > 0. This leads to the following simple
observation, which will be needed later.
Lemma 17.12 (maximality) Let A be the generator of a Feller semigroup
on C0, and assume that A has a linear extension A′ satisfying the positive
maximum principle. Then A′ = A.
Proof: Fix any f ∈dom(A′), and put g = (I−A′)f. Since A′ is dissipative
and (I −A)R1 = I on C0, we get
∥f −R1g∥≤∥(I −A′)(f −R1g)∥= ∥g −(I −A)R1g∥= 0,
and so f = R1g ∈dom(A).
✷
Our next aim is to show how a nice Markov process can be associated
with every Feller semigroup (Tt). In order for the corresponding transition
kernels µt to have total mass 1, we need the operators Tt to be conservative,
in the sense that supf≤1 Ttf(x) = 1 for all x ∈S. This can be achieved by a
suitable extension.
Let us then introduce an auxiliary state ∆̸∈S and form the compactiﬁed
space ˆS = S ∪{∆}, where ∆is regarded as the point at inﬁnity when S is

324
Foundations of Modern Probability
noncompact, and otherwise as isolated from S. Note that any function f ∈C0
has a continuous extension to ˆS, obtained by putting f(∆) = 0. We may
now extend the original semigroup on C0 to a conservative semigroup on the
space ˆC = C( ˆS).
Lemma 17.13 (compactiﬁcation) Any Feller semigroup (Tt) on C0 admits
an extension to a conservative Feller semigroup ( ˆTt) on ˆC, given by
ˆTtf = f(∆) + Tt{f −f(∆)},
t ≥0, f ∈ˆC.
Proof: It is straightforward to verify that ( ˆTt) is a strongly continuous
semigroup on ˆC. To show that the operators ˆTt are positive, ﬁx any f ∈ˆC
with f ≥0, and note that g ≡f(∆) −f ∈C0 with g ≤f(∆). Hence,
Ttg ≤Ttg+ ≤∥Ttg+∥≤∥g+∥≤f(∆),
so ˆTtf = f(∆) −Ttg ≥0. The contraction and conservation properties now
follow from the fact that ˆTt1 = 1.
✷
Our next step is to construct an associated semigroup of Markov transi-
tion kernels µt on ˆS, satisfying
Ttf(x) =

f(y)µt(x, dy),
f ∈C0.
(15)
We say that a state x ∈ˆS is absorbing for (µt) if µt(x, {x}) = 1 for each
t ≥0.
Proposition 17.14 (existence) For any Feller semigroup (Tt) on C0, there
exists a unique semigroup of Markov transition kernels µt on ˆS satisfying
(15) and such that ∆is absorbing for (µt).
Proof: For ﬁxed x ∈S and t ≥0, the mapping f →ˆTtf(x) is a positive
linear functional on ˆC with norm 1, so by Riesz’s representation Theorem
A1.5 there exist some probability measures µt(x, ·) on ˆS satisfying
ˆTtf(x) =

f(y)µt(x, dy),
f ∈ˆC, x ∈ˆS, t ≥0.
(16)
The measurability of the right-hand side is clear by continuity. By a standard
approximation followed by a monotone class argument, we then obtain the
desired measurability of µt(x, B) for any t ≥0 and Borel set B ⊂ˆS. The
Chapman–Kolmogorov relation holds on ˆS by Lemma 17.1. Relation (15) is
a special case of (16), and from (16) we further get

f(y)µt(∆, dy) = ˆTtf(∆) = f(∆) = 0,
f ∈C0,
which shows that ∆is absorbing. The uniqueness of (µt) is a consequence of
the last two properties.
✷

17. Feller Processes and Semigroups
325
For any probability measure ν on ˆS, there exists by Theorem 7.4 a Markov
process Xν in ˆS with initial distribution ν and transition kernels µt. As
before, we denote the distribution of Xν by Pν and write Eν for the corre-
sponding integration operator. When ν = δx, we often prefer the simpler
forms Px and Ex, respectively. We may now extend Theorem 13.1 to a basic
regularization theorem for Feller processes.
Theorem 17.15 (regularization, Kinney) Let X be a Feller process in ˆS
with arbitrary initial distribution ν. Then X has an rcll version ˜X, which is
further such that Xt = ∆or Xt−= ∆implies ˜X ≡∆on [t, ∞). If (Tt) is
conservative and ν is restricted to S, then ˜X can be chosen to be rcll in S.
The idea of the proof is to construct a suﬃciently rich class of super-
martingales, to which the regularity theorems of Chapter 6 may be applied.
Let C+
0 denote the class of nonnegative functions in C0.
Lemma 17.16 (resolvents and excessive functions)
If f ∈C+
0 , then the
process Yt = e−tR1f(Xt), t ≥0, is a supermartingale under Pν for every ν.
Proof: Writing (Gt) for the ﬁltration induced by X, we get for any t, h ≥0
E[Yt+h|Gt]
=
E[e−t−hR1f(Xt+h)|Gt] = e−t−hThR1f(Xt)
=
e−t−h

 ∞
0
e−sTs+hf(Xt)ds
=
e−t

 ∞
h
e−sTsf(Xt)ds ≤Yt.
✷
Proof of Theorem 17.15: By Lemma 17.16 and Theorem 6.27, the process
f(Xt) has a.s. right- and left-hand limits along Q+ for any f ∈D ≡dom(A).
Since D is dense in C0, the stated property holds for every f ∈C0. By the
separability of C0 we may choose the exceptional null set N to be independent
of f. Now if x1, x2, . . . ∈ˆS are such that f(xn) converges for every f ∈C0,
it is clear from the compactness of ˆS that xn converges in the topology of ˆS.
Thus, on N c the process X itself has right- and left-hand limits Xt± along
Q+, and on N we may redeﬁne X to be 0. The process ˜Xt = Xt+ is then
rcll, and it remains to show that ˜X is a version of X, or equivalently, that
Xt+ = Xt a.s. for each t ≥0. But this is clear from the fact that Xt+h
P→Xt
as h ↓0, by Lemma 17.3 and dominated convergence.
Now ﬁx any f ∈C0 with f > 0 on S, and note from the strong continuity
of (Tt) that even R1f > 0 on S. Applying Lemma 6.31 to the supermartin-
gale Yt = e−tR1f( ˜Xt), we conclude that X ≡∆a.s. on the interval [ζ, ∞),
where ζ = inf{t ≥0; ∆∈{ ˜Xt, ˜Xt−}}. Discarding the exceptional null set,
we can make this hold identically. If (Tt) is conservative and ν is restricted
to S, then ˜Xt ∈S a.s. for every t ≥0. Thus, ζ > t a.s. for all t, and hence
ζ = ∞a.s. Again we may assume that this holds identically. Then ˜Xt and
˜Xt−take values in S, and the stated regularity properties remain valid in S. ✷

326
Foundations of Modern Probability
In view of the last theorem, we may choose Ωto be the space of all ˆS-
valued rcll functions such that the state ∆is absorbing, and let X be the
canonical process on Ω. Processes with diﬀerent initial distributions ν are
then distinguished by their distributions Pν on Ω. Thus, under Pν the process
X is Markov with initial distribution ν and transition kernels µt, and X has
all the regularity properties stated in Theorem 17.15. In particular, X ≡∆
on the interval [ζ, ∞), where ζ denotes the terminal time
ζ = inf{t ≥0; Xt = ∆or Xt−= ∆}.
We shall take (Ft) to be the right-continuous ﬁltration generated by X, and
put A = F∞=

t Ft. The shift operators θt on Ωare deﬁned as before by
(θtω)s = ωs+t,
s, t ≥0.
The process X with associated distributions Pν, ﬁltration F = (Ft), and
shift operators θt is called the canonical Feller process with semigroup (Tt).
We are now ready to state a general version of the strong Markov prop-
erty. The result extends the special versions obtained in Proposition 7.9 and
Theorems 10.16 and 11.11. A further instant of this property appears in
Theorem 18.11.
Theorem 17.17 (strong Markov property, Dynkin and Yushkevich, Blu-
menthal) For any canonical Feller process X, initial distribution ν, optional
time τ, and random variable ξ ≥0, we have
Eν[ξ ◦θτ|Fτ] = EXτξ a.s. Pν on {τ < ∞}.
Proof: By Lemmas 5.2 and 6.1 we may assume that τ < ∞.
Let G
denote the ﬁltration induced by X. Then Lemma 6.4 shows that the times
τn = 2−n[2nτ + 1] are G-optional, and by Lemma 6.3 we have Fτ ⊂Gτn for
all n. Thus, Proposition 7.9 yields
Eν[ξ ◦θτn; A] = Eν[EXτnξ; A],
A ∈Fτ, n ∈N.
(17)
To extend the relation to τ, we may ﬁrst assume that ξ = f1(Xt1) · · ·
fm(Xtm) for some f1, . . . , fm ∈C0 and t1 < · · · < tm. In that case ξ ◦θτn →
ξ ◦θτ by the right-continuity of X and the continuity of f1, . . . , fm. Writing
hk = tk −tk−1 with t0 = 0, it is further clear from the ﬁrst Feller property
and the right-continuity of X that
EXτnξ
=
Th1(f1Th2 · · · (fm−1Thmfm) · · ·)(Xτn)
→
Th1(f1Th2 · · · (fm−1Thmfm) · · ·)(Xτ) = EXτξ.
Thus, (17) extends to τ by dominated convergence on both sides. We may
ﬁnally use standard approximation and monotone class arguments to extend
the result to arbitrary ξ.
✷
As a simple application, we get the following useful zero–one law.

17. Feller Processes and Semigroups
327
Corollary 17.18 (zero–one law, Blumenthal) For any canonical Feller pro-
cess, we have
PxA = 0 or 1,
x ∈S, A ∈F0.
Proof: Taking τ = 0 in Theorem 17.17, we get for any x ∈S and A ∈F0
1A = Px[A|F0] = PX0A = PxA a.s. Px.
✷
To appreciate the last result, recall that F0 = F0+. In particular, we note
that Px{τ = 0} = 0 or 1 for any state x ∈S and F-optional time τ.
The strong Markov property is often used in the following extended form.
Corollary 17.19 (optional projection) For any canonical Feller process X,
nondecreasing adapted process A, and random variable ξ ≥0, we have
Ex

 ∞
0 (EXtξ)dAt = Ex

 ∞
0 (ξ ◦θt)dAt,
x ∈S.
(18)
Proof: We may assume that A0 = 0.
Introduce the right-continuous
inverse
τs = inf{t ≥0; At > s},
s ≥0,
and note that the times τs are optional by Lemma 6.6. By Theorem 17.17
we get
Ex[EXτsξ; τs < ∞] = Ex[Ex[ξ ◦θτs|Fτs]; τs < ∞] = Ex[ξ ◦θτs; τs < ∞].
Now τs < ∞iﬀs < A∞, so by integration
Ex

 A∞
0
(EXτsξ)ds = Ex

 A∞
0
(ξ ◦θτs)ds,
which is equivalent to (17.19).
✷
Next we shall prove that any martingale on the canonical space of a Feller
process X is a.s. continuous outside the discontinuity set of X. For Brow-
nian motion, the result was already noted as a consequence of the integral
representation in Theorem 16.10.
Theorem 17.20 (discontinuity sets) Let X be a canonical Feller process
with arbitrary initial distribution ν, and let M be a local Pν-martingale. Then
{t > 0; ∆Mt ̸= 0} ⊂{t > 0; Xt−̸= Xt} a.s.
(19)
Proof (Chung and Walsh): By localization we may reduce to the case
when M is uniformly integrable and hence of the form Mt = E[ξ|Ft] for
some ξ ∈L1. Let C denote the class of random variables ξ ∈L1 such that
the corresponding M satisﬁes (19). Then C is a linear subspace of L1. It is

328
Foundations of Modern Probability
further closed, since if M n
t = E[ξn|Ft] with ∥ξn∥1 →0, then P{supt |M n
t | >
ε} ≤ε−1E|ξn| →0 for all ε > 0, so supt |M n
t |
P→0.
Now let ξ = 
k≤n fk(Xtk) for some f1, . . . , fn ∈C0 and t1 < · · · < tn.
Writing hk = tk −tk−1, we note that
Mt =

k≤mfk(Xtk)Ttm+1−tgm+1(Xt),
t ∈[tm, tm+1],
(20)
where
gk = fkThk+1(fk+1Thk+2(· · · Thnfn) · · ·),
k = 1, . . . , n,
with the obvious conventions for t < t1 and t > tn. Since Ttg(x) is jointly
continuous in (t, x) for each g ∈C0, equation (20) deﬁnes a right-continuous
version of M satisfying (19), and so ξ ∈C. By a simple approximation it
follows that C contains all indicator functions of sets 
k≤n{Xtk ∈Gk} with
G1, . . . , Gn open. The result extends by a monotone class argument to any
X-measurable indicator function ξ, and a routine argument yields the ﬁnal
extension to L1.
✷
A basic role in the theory is played by the processes
M f
t = f(Xt) −f(X0) −

 t
0 Af(Xs)ds,
t ≥0, f ∈D ≡dom(A).
Lemma 17.21 (Dynkin’s formula) The processes M f are martingales un-
der any initial distribution ν for X. In particular, we have for any bounded
optional time τ
Exf(Xτ) = f(x) + Ex

 τ
0 Af(Xs)ds,
x ∈S, f ∈D.
(21)
Proof: For any t, h ≥0 we have
M f
t+h −M f
t = f(Xt+h) −f(Xt) −

 t+h
t
Af(Xs)ds = M f
h ◦θt,
so by the Markov property at t and Theorem 17.6
Eν[M f
t+h|Ft] −M f
t = Eν[M f
h ◦θt|Ft] = EXtM f
h = 0.
Thus, M f is a martingale, and (21) follows by optional sampling.
✷
As a preparation for the next major result, we shall introduce the optional
times
τh = inf{t ≥0; ρ(Xt, X0) > h},
h > 0,
where ρ denotes the metric in S. Note that a state x is absorbing iﬀτh = ∞
a.s. Px for every h > 0.
Lemma 17.22 (escape times) If x ∈S is nonabsorbing, then Exτh < ∞
for all suﬃciently small h > 0.

17. Feller Processes and Semigroups
329
Proof: If x is nonabsorbing, then µt(x, Bε
x) < p < 1 for some t, ε > 0,
where Bε
x = {y; ρ(x, y) ≤ε}. By Lemma 17.3 and Theorem 3.25 we may
choose h ∈(0, ε] so small that
µt(y, Bh
x) ≤µt(y, Bε
x) ≤p,
y ∈Bh
x.
Then Proposition 7.2 yields
Px{τh ≥nt} ≤Px

k≤n{Xkt ∈Bh
x} ≤pn,
n ∈Z+,
and so by Lemma 2.4
Exτh =

 ∞
0
P{τh ≥s}ds ≤t

n≥0
P{τh ≥nt} = t

n≥0
pn =
t
1 −p < ∞. ✷
We turn to a probabilistic description of the generator and its domain.
Say that A is maximal within a class of linear operators if A extends any
member of the class.
Theorem 17.23 (characteristic operator, Dynkin) For any f ∈dom(A) we
have Af(x) = 0 if x is absorbing; otherwise,
Af(x) = lim
h→0
Exf(Xτh) −f(x)
Exτh
.
(22)
Furthermore, A is the maximal operator on C0 with those properties.
Proof: Fix any f ∈dom(A). If x is absorbing, then Ttf(x) = f(x) for all
t, and so Af(x) = 0. For nonabsorbing x we get by Lemma 17.21
Exf(Xτh∧t) −f(x) = Ex

 τh∧t
0
Af(Xs)ds,
t, h > 0.
(23)
By Lemma 17.22 we have Eτh < ∞for suﬃciently small h > 0, and so
(23) extends by dominated convergence to t = ∞. Relation (22) now fol-
lows from the continuity of Af, together with the fact that ρ(Xs, x) ≤h
for all s < τh. Since the positive maximum principle holds for any extension
of A with the stated properties, the last assertion follows by Lemma 17.12. ✷
In the special case when S = Rd, let C∞
K denote the class of inﬁnitely
diﬀerentiable functions on Rd with bounded support. An operator A with
dom(A) ⊃C∞
K is said to be local on C∞
K if Af(x) = 0 whenever f vanishes
in some neighborhood of x. For a generator with this property, we note that
the positive maximum principle implies a local positive maximum principle,
in the sense if f ∈C∞
K has a local maximum ≥0 at some point x, then
Af(x) ≤0.
The following result gives the basic connection between diﬀusion processes
and elliptic diﬀerential operators.
This connection is explored further in
Chapters 18 and 21.

330
Foundations of Modern Probability
Theorem 17.24 (Feller diﬀusions and elliptic operators, Dynkin) Let A be
the generator of a Feller process X in Rd, and assume that C∞
K ⊂dom(A).
Then X is continuous on [0, ζ), a.s. Pν for every ν, iﬀA is local on C∞
K . In
that case there exist some functions aij, bi, c ∈C(Rd), where c ≥0 and the
matrix (aij) is symmetric, nonnegative deﬁnite, such that for any f ∈C∞
K
and x ∈R+,
Af(x) = 1
2

i,jaij(x)f ′′
ij(x) +

ibi(x)f ′
i(x) −c(x)f(x).
(24)
In the situation described by this result, we may choose Ωto consist of all
paths that are continuous on [0, ζ). The resulting Markov process is referred
to as a canonical Feller diﬀusion.
Proof: If X is continuous on [0, ζ), then A is local by Theorem 17.23.
Conversely, assume that A is local on C∞
K . Fix any x ∈Rd and 0 < h < m,
and choose f ∈C∞
K with f ≥0 and support {y; h ≤|y −x| ≤m}. Then
Af(y) = 0 for all y ∈Bh
x, so Lemma 17.21 shows that f(Xt∧τh) is a martingale
under Px. By dominated convergence we get Exf(Xτh) = 0, and since m was
arbitrary,
Px {|Xτh −x| ≤h or Xτh = ∆} = 1,
x ∈Rd, h > 0.
Applying the Markov property at ﬁxed times, we obtain for any initial dis-
tribution ν
Pν

t∈Q+
θ−1
t
{|Xτh −X0| ≤h or Xτh = ∆} = 1,
h > 0,
which implies
Pν

supt<ζ|∆Xt| ≤h

= 1,
h > 0.
Hence, under Pν, the path of X is a.s. continuous on [0, ζ).
To derive (24) for suitable aij, bi, and c, choose for each x ∈Rd some
functions f x
0 , f x
i , f x
ij ∈C∞
K such that for y close to x
f x
0 (y) = 1,
f x
i (y) = yi −xi,
f x
ij(y) = (yi −xi)(yj −xj),
and deﬁne
c(x) = −Af x
0 (x),
bi(x) = Af x
i (x),
aij(x) = Af x
ij(x).
Then (24) holds locally for any function f ∈C∞
K that agrees near x with a
second-degree polynomial. In particular, we may take f0(y) = 1, fi(y) = yi,
and fij(y) = yiyj near x to obtain
Af0(x) = −c(x),
Afi(x) = bi(x) −xic(x),
Afij(x) = aij(x) + xibj(x) + xjbi(x) −xixjc(x).

17. Feller Processes and Semigroups
331
This shows that c, bi, and aij = aji are continuous.
Applying the local positive maximum principle to f x
0 gives c(x) ≥0. By
the same principle applied to the function
f = −

iuif x
i
2 = −

ijuiujf x
ij,
we get 	
ij uiujaij(x) ≥0, which shows that (aij) is nonnegative deﬁnite.
Finally, consider an arbitrary f ∈C∞
K with a second-order Taylor expansion
˜f around x. Here the functions
gε
±(y) = ±(f(y) −˜f(y)) −ε|x −y|2,
ε > 0,
have a local maximum 0 at x, and so
Agε
±(x) = ±(Af(x) −A ˜f(x)) −ε

iaii(x) ≤0,
ε > 0.
Letting ε →0, we get Af(x) = A ˜f(x), which shows that (24) is generally
true.
✷
We shall next prove a basic convergence theorem for Feller processes,
which essentially generalizes the result for L´evy processes in Theorem 13.17.
Theorem 17.25 (convergence, Trotter, Sova, Kurtz, Mackeviˇcius) Let X,
X1, X2, . . . be Feller processes in S with semigroups (Tt), (T1,t), (T2,t), . . . and
generators A, A1, A2, . . . , and ﬁx a core D for A. Then these conditions are
equivalent:
(i) If f ∈D, there exist some fn ∈dom(An) with fn →f and Anfn →Af;
(ii) Tn,t →Tt strongly for each t > 0;
(iii) Tn,tf →Ttf for each f ∈C0, uniformly for bounded t > 0;
(iv) if Xn
0
d→X0 in S, then Xn
d→X in D(R+, ˆS).
For the proof we need two lemmas, the ﬁrst of which extends Lemma
17.7.
Lemma 17.26 (norm inequality)
Let (Tt) and (T ′
t) be Feller semigroups
with generators A and A′, respectively, where A′ is bounded. Then
∥Ttf −T ′
tf∥≤

 t
0 ∥(A −A′)Tsf∥ds,
f ∈dom(A), t ≥0.
(25)
Proof: Fix any f ∈dom(A) and t > 0. Since (T ′
s) is norm continuous, we
get by Theorem 17.6
∂
∂s(T ′
t−sTsf) = T ′
t−s(A −A′)Tsf,
0 ≤s ≤t.

332
Foundations of Modern Probability
Here the right-hand side is continuous in s, because of the strong continuity
of (Ts), the boundedness of A′, the commutativity of A and Ts, and the norm
continuity of (T ′
s). Hence,
Ttf −T ′
tf =

 t
0
∂
∂s(T ′
t−sTsf) ds =

 t
0 T ′
t−s(A −A′)Tsf ds,
and (25) follows by the contractivity of T ′
t−s.
✷
We shall next establish a continuity property for the Yosida approxima-
tions Aλ and Aλ
n of A and An, respectively.
Lemma 17.27 (continuity of Yosida approximation) Let A, A1, A2, . . . be
generators of some Feller semigroups satisfying condition (i) of Theorem
17.25. Then Aλ
n →Aλ strongly for every λ > 0.
Proof: By Lemma 17.8 it suﬃces to show that Aλ
nf →Aλf for every
f ∈(λ −A)D. Then deﬁne g ≡Rλf ∈D. By (i) we may choose some
gn ∈dom(An) with gn →g and Angn →Ag. Then fn ≡(λ −An)gn →
(λ −A)g = f, and so
∥Aλ
nf −Aλf∥
=
λ2∥Rλ
nf −Rλf∥
≤
λ2∥Rλ
n(f −fn)∥+ λ2∥Rλ
nfn −Rλf∥
≤
λ∥f −fn∥+ λ2∥gn −g∥→0.
✷
Proof of Theorem 17.25: First we show that (i) implies (iii). Since D is
dense in C0, it is enough to verify (iii) for f ∈D. Then choose some functions
fn as in (i) and conclude by Lemmas 17.7 and 17.26 that, for any n ∈N and
t, λ > 0,
∥Tn,tf −Ttf∥
≤
∥Tn,t(f −fn)∥+ ∥(Tn,t −T λ
n,t)fn∥+ ∥T λ
n,t(fn −f)∥
+ ∥(T λ
n,t −T λ
t )f∥+ ∥(T λ
t −Tt)f∥
≤
2∥fn −f∥+ t∥(Aλ −A)f∥+ t∥(An −Aλ
n)fn∥
+

 t
0 ∥(Aλ
n −Aλ)T λ
s f∥ds.
(26)
By Lemma 17.27 and dominated convergence, the last term tends to zero as
n →∞. For the third term on the right we get
∥(An −Aλ
n)fn∥
≤
∥Anfn −Af∥+ ∥(A −Aλ)f∥
+ ∥(Aλ −Aλ
n)f∥+ ∥Aλ
n(f −fn)∥,
which tends to ∥(A −Aλ)f∥by the same lemma. Hence, by (26)
lim sup
n→∞
sup
t≤u ∥Tn,tf −Ttf∥≤2u∥(Aλ −A)f∥,
u, λ > 0,

17. Feller Processes and Semigroups
333
and the desired convergence follows by Lemma 17.7 as we let λ →∞.
Conversely, (iii) trivially implies (ii), so the equivalence of (i) through (iii)
will follow if we can show that (ii) implies (i). Then ﬁx any f ∈D and λ > 0,
and deﬁne g = (λ −A)f and fn = Rλ
ng. Assuming (ii), we get by dominated
convergence fn →Rλg = f, and since (λ−An)fn = g = (λ−A)f, we further
note that Anfn →Af. Thus, even (i) holds.
It remains to show that conditions (i)—(iii) are equivalent to (iv). For
convenience we may then assume that S is compact and the semigroups (Tt)
and (Tn,t) are conservative.
First assume (iv).
We may establish (ii) by
showing for any f ∈C and t > 0 that T n
t f(xn) →Ttf(x) whenever xn →x
in S. Then assume that X0 = x and Xn
0 = xn. By Lemma 17.3 the process
X is a.s. continuous at t, so (iv) yields Xn
t
d→Xt, and the desired convergence
follows.
Conversely, assume that (i) through (iii) are fulﬁlled, and let Xn
0
d→X0.
To obtain Xn
fd
−→X, it is enough to show for any f0, . . . , fm ∈C and
0 = t0 < t1 · · · tm that
lim
n→∞E

k≤mfk(Xn
tk) = E

k≤mfk(Xtk).
(27)
This holds by hypothesis when m = 0. Proceeding by induction, we may use
the Markov property to rewrite (27) in the form
E

k<m
fk(Xn
tk) · T n
hmfm(Xn
tm−1) →E

k<m
fk(Xtk) · Thmfm(Xtm−1),
(28)
where hm = tm −tm−1. Now (ii) implies T n
hmfm →Thmfm, so it is equivalent
to prove (28) with T n
hm replaced by Thm. The resulting condition is of the
form (27) with m replaced by m−1. This completes the induction and shows
that Xn
fd
−→X.
To strengthen the conclusion to Xn
d→X, it suﬃces by Theorems 14.10
and 14.11 to show that ρ(Xn
τn, Xn
τn+hn)
P→0 for any ﬁnite optional times τn
and positive constants hn →0. By the strong Markov property we may prove
instead that ρ(Xn
0 , Xn
hn)
P→0 for any initial distributions νn. In view of the
compactness of S and Theorem 14.3, we may then assume that νn
w→ν for
some probability measure ν. Fixing any f, g ∈C and noting that T n
hng →g
by (iii), we get
Ef(Xn
0 )g(Xn
hn) = EfT n
hng(Xn
0 ) →Efg(X0),
where P ◦X−1
0
= ν. Then (Xn
0 , Xn
hn)
d→(X0, X0) as before, and in particular
ρ(Xn
0 , Xn
hn)
d→ρ(X0, X0) = 0. This completes the proof of (iv).
✷
From the last theorem and its proof we may easily deduce a similar ap-
proximation property for discrete-time Markov chains. The result extends
the approximations for random walks obtained in Corollary 13.20 and The-
orem 14.14.

334
Foundations of Modern Probability
Theorem 17.28 (approximation of Markov chains) Let Y 1, Y 2, . . . be dis-
crete-time Markov chains in S with transition operators U1, U2, . . . , and con-
sider a Feller process X in S with semigroup (Tt) and generator A. Fix a
core D for A, and assume that 0 < hn →0. Then conditions (i) through (iv)
of Theorem 17.25 remain equivalent for the operators and processes
An = h−1
n (Un −I),
Tn,t = U [t/hn]
n
,
Xn
t = Y n
[t/hn].
Proof: Let N be an independent, unit-rate Poisson process, and note
that the processes ˜Xn
t = Y n ◦Nt/hn are pseudo-Poisson with generators An.
Theorem 17.25 shows that (i) is equivalent to (iv) with Xn replaced by ˜Xn.
By the strong law of large numbers for N together with Theorem 3.28, it
is further seen that (iv) holds simultaneously for the processes Xn and ˜Xn.
Thus, (i) and (iv) are equivalent.
Since X is a.s. continuous at ﬁxed times, condition (iv) yields Xn
tn
d→Xt
whenever tn →t and the processes Xn and X start at ﬁxed points xn →x
in ˆS. Hence, Tn,tnf(xn) →Ttf(x) for any f ∈ˆC, and (iii) follows. Since (iii)
trivially implies (ii), it remains to show that (ii) implies (i).
Arguing as in the preceding proof, we need to show for any λ > 0 and
g ∈C0 that ˜Rλ
ng →Rλg, where ˜Rλ
n = (λ−An)−1. Now (ii) yields Rλ
ng →Rλg,
where Rλ
n =
 e−λtTn,tdt, so it remains to prove that (Rλ
n −˜Rλ
n)g →0. Then
note that
λRλ
ng −λ ˜Rλ
ng = Eg(Y n
κn−1) −Eg(Y n
˜κn−1),
where the random variables κn and ˜κn are independent of Y n and geometri-
cally distributed with parameters pn = 1 −e−λhn and ˜pn = λhn(1 + λhn)−1,
respectively. Since pn ∼˜pn, we have ∥P ◦κ−1
n −P ◦˜κ−1
n ∥→0, and the desired
convergence follows by Fubini’s theorem.
✷
Exercises
1. Examine how the proofs of Theorems 17.4 and 17.6 can be simpliﬁed
if we assume (F3) instead of the weaker condition (F2).
2.
Deduce Theorem 14.14 from Theorem 17.28.
Similarly, specialize
Theorem 17.25 to the case of L´evy processes.

Chapter 18
Stochastic Diﬀerential Equations
and Martingale Problems
Linear equations and Ornstein–Uhlenbeck processes; strong exis-
tence, uniqueness, and nonexplosion criteria; weak solutions and
local martingale problems; well-posedness and measurability; path-
wise uniqueness and functional solution; weak existence and con-
tinuity; transformation of SDEs; strong Markov and Feller prop-
erties
In this chapter we shall study classical stochastic diﬀerential equations (SDEs)
driven by a Brownian motion and clarify the connection with the associated
local martingale problems. Originally, the mentioned equations were devised
to provide a pathwise construction of diﬀusions and more general continuous
semimartingales. They have later turned out to be useful in a wide range
of applications, where they may provide models for a diversity of dynamical
systems with random perturbations. The coeﬃcients determine a possibly
time-dependent elliptic operator A as in Theorem 17.24, which suggests the
associated martingale problem of ﬁnding a process X such that the processes
M f in Lemma 17.21 become martingales. It turns out to be essentially equiv-
alent for X to be a weak solutions to the given SDE, as will be seen from the
fundamental Theorem 18.7.
The theory of SDEs utilizes the basic notions and ideas of stochastic
calculus, as developed in Chapters 15 and 16. Occasional references will be
made to other chapters, such as to Chapter 5 for conditional independence,
to Chapter 6 for martingale theory, to Chapter 14 for weak convergence,
and to Chapter 17 for Feller processes. Some further aspects of the theory
are displayed at the beginning of Chapter 20 as well as in Theorems 21.2
and 23.8.
The SDEs studied in this chapter are typically of the form
dXi
t = σi
j(t, X)dBj
t + bi(t, X)dt,
(1)
or more explicitly,
Xi
t = Xi
0 +

j

 t
0 σi
j(s, X)dBj
s +

 t
0 bi(s, X)ds,
t ≥0.
(2)
335

336
Foundations of Modern Probability
Here B = (B1, . . . , Br) is a Brownian motion in Rr with respect to some ﬁl-
tration F, and the solution X = (X1, . . . , Xd) is a continuous F-semimartin-
gale in Rd. Furthermore, the coeﬃcients σ and b are progressive functions of
suitable dimension, deﬁned on the canonical path space C(R+, Rd) equipped
with the induced ﬁltration Gt = σ{ws; s ≤t}, t ≥0. For convenience we
shall often refer to (1) as equation (σ, b).
For the integrals in (2) to exist in the sense of Itˆo and Lebesgue integra-
tion, X has to fulﬁll the integrability conditions

 t
0 (|aij(s, X)| + |bi(s, X)|)ds < ∞a.s.,
t ≥0,
(3)
where aij = σi
kσj
k or a = σσ′, and the bars denote any norms in the spaces of
d×d-matrices and d-vectors, respectively. For the existence and adaptedness
of the right-hand side, it is also necessary that the integrands in (2) be
progressive. This is ensured by the following result.
Lemma 18.1 (progressive functions) Let the function f on R+×C(R+, Rd)
be progressive for the induced ﬁltration G on C(R+, Rd), and let X be a
continuous and F-adapted process in Rd. Then the process Yt = f(t, X) is
F-progressive.
Proof: Fix any t ≥0. Since X is adapted, we note that πs(X) = Xs
is Ft-measurable for every s ≤t, where πs(w) = ws on C(R+, Rd). Since
Gt = σ{πs; s ≤t}, Lemma 1.4 shows that X is Ft/Gt-measurable. Hence, by
Lemma 1.8 the mapping ϕ(s, ω) = (s, X(ω)) is Bt ⊗Ft/Bt ⊗Gt-measurable
from [0, t] × Ωto [0, t] × C(R+, Rd), where Bt = B[0, t]. Also note that f is
Bt ⊗Gt-measurable on [0, t] × C(R+, Rd), since f is progressive. By Lemma
1.7 we conclude that Y = f ◦ϕ is Bt ⊗Ft/B-measurable on [0, t] × Ω.
✷
Equation (2) exhibits the solution process X as an Rd-valued semimartin-
gale with drift components bi(X) · λ and covariation processes [Xi, Xj] =
aij(X) · λ, where aij(w) = aij(·, w) and bi(w) = bi(·, w). It is natural to
regard the densities a(t, X) and b(t, X) as the local characteristics of X at
time t. Of special interest is the diﬀusion case, where σ and b have the form
σ(t, w) = σ(wt),
b(t, w) = b(wt),
t ≥0, w ∈C(R+, Rd),
(4)
for some measurable functions on Rd. In that case the local characteristics
at time t depend only on the current position Xt of the process, and the
progressivity holds automatically.
We shall distinguish between strong and weak solutions to an SDE (σ, b).
For the former, the ﬁltered probability space (Ω, F, P) is regarded as given,
along with an F-Brownian motion B and an F0-measurable random vector
ξ. A strong solution is then deﬁned as an adapted process X with X0 = ξ
a.s. satisfying (1). In case of a weak solution, only the initial distribution µ

18. Stochastic Diﬀerential Equations and Martingale Problems
337
is given, and the solution consists of the triple (Ω, F, P) together with an F-
Brownian motion B and an adapted process X with P ◦X−1
0
= µ satisfying
(1).
This leads to diﬀerent notions of existence and uniqueness for a given
equation (σ, b). Thus, weak existence is said to hold for the initial distribution
µ if there is a corresponding weak solution (Ω, F, P, B, X).
By contrast,
strong existence for the given µ means that there is a strong solution X for
every basic triple (F, B, ξ) such that ξ has distribution µ. We further say
that uniqueness in law holds for the initial distribution µ if the corresponding
weak solutions X have the same distribution. Finally, we say that pathwise
uniqueness holds for the initial distribution µ if, for any two solutions X and
Y on a common ﬁltered probability space with a given Brownian motion B
such that X0 = Y0 a.s. with distribution µ, we have X = Y a.s.
One of the simplest SDEs is the Langevin equation
dXt = dBt −Xtdt,
(5)
which is of great importance for both theory and applications. Integrating
by parts, we get from (5) the equation
d(etXt) = etdXt + etXtdt = etdBt,
which possesses the explicit solution
Xt = e−tX0 +

 t
0 e−(t−s)dBs,
t ≥0,
(6)
recognized as an Ornstein–Uhlenbeck process. Conversely, the process in (6)
is easily seen to satisfy (5). We may further note that θtX
d→Y as t →∞,
where Y denotes the stationary version of the process considered in Chapter
11. We can also get the stationary version directly from (6), by choosing X0
to be N(0, 1
2) and independent of B.
We turn to a more general class of equations that can be solved explicitly.
A further extension appears in Theorem 23.8.
Proposition 18.2 (linear equations)
Let U and V be continuous semi-
martingales, and put Z = exp(V −V0 −1
2[V ]). Then the equation dX =
dU + XdV has the unique solution
X = Z{X0 + Z−1 · (U −[U, V ])}.
(7)
Proof: Deﬁne Y = X/Z. Integrating by parts and noting that dZ = ZdV ,
we get
dU = dX −XdV = Y dZ + ZdY + d[Y, Z] −XdV = ZdY + d[Y, Z]
(8)
and, in particular,
[U, V ] = Z · [Y, V ] = [Y, Z].
(9)

338
Foundations of Modern Probability
Substituting (9) into (8) yields ZdY = dU −d[U, V ], which implies dY =
Z−1d(U −[U, V ]). To get (7) it remains to integrate from 0 to t and note
that Y0 = X0. Since all steps are reversible, the same argument shows that
(7) is indeed a solution.
✷
Though most SDEs have no explicit solution, we may still derive general
conditions for strong existence, pathwise uniqueness, and continuous depen-
dence on the initial conditions, by imitating the well-known Picard iteration
for ordinary diﬀerential equations. Recall that the relation <
⌢denotes in-
equality up to a constant factor.
Theorem 18.3 (strong solutions and stochastic ﬂows, Itˆo) Let σ and b be
bounded progressive functions satisfying a Lipschitz condition
(σ(w) −σ(w′))∗
t + (b(w) −b(w′))∗
t <
⌢(w −w′)∗
t,
t ≥0,
(10)
and ﬁx a Brownian motion B in Rr with respect to some complete ﬁltration
F. Then there exists a jointly continuous process X = (Xx
t ) on R+ × Rd
such that for any F0-measurable random vector ξ in Rd, equation (σ, b) has
the a.s. unique solution Xξ starting at ξ.
For one-dimensional diﬀusion equations, a stronger result is established
in Theorem 20.3. The solution process X = (Xx
t ) on R+ × Rd is called the
stochastic ﬂow generated by B. Our proof will be based on two lemmas, and
we begin with an elementary estimate.
Lemma 18.4 (Gronwall) Let f be a continuous function on R+ such that
f(t) ≤a + b

 t
0 f(s)ds,
t ≥0,
(11)
for some a, b ≥0. Then f(t) ≤aebt for all t ≥0.
Proof: We may write (11) as
d
dt

e−bt

 t
0 f(s)ds

≤ae−bt,
t ≥0.
It remains to integrate over [0, t] and combine with (11).
✷
To state the next result, let S(X) denote the process deﬁned by the right-
hand side of (2).
Lemma 18.5 (local contraction) Let σ and b be bounded, progressive func-
tions satisfying (10), and ﬁx any p ≥2. Then there exists some nondecreasing
function c on R+ such that, for any continuous adapted processes X and Y
in Rd and for arbitrary t ≥0,
E(S(X) −S(Y ))∗p
t ≤2E|X0 −Y0|p + ct

 t
0 E(X −Y )∗p
s ds.

18. Stochastic Diﬀerential Equations and Martingale Problems
339
Proof: By Proposition 15.7, condition (10), and Jensen’s inequality,
E(S(X) −S(Y ))∗p
t −2E|X0 −Y0|p
<
⌢
E((σ(X) −σ(Y )) · B)∗p
t + E((b(X) −b(Y )) · λ)∗p
t
<
⌢
E(|σ(X) −σ(Y )|2 · λ)p/2
t
+ E(|b(X) −b(Y )| · λ)p
t
<
⌢
E


 t
0 (X −Y )∗2
s ds

p/2
+ E


 t
0 (X −Y )∗
sds

p
≤
(tp/2−1 + tp−1)

 t
0 E(X −Y )∗p
s ds.
✷
Proof of Theorem 18.3: To prove the existence, ﬁx any F0-measurable
random vector ξ in Rd, put X0
t ≡ξ, and deﬁne recursively Xn = S(Xn−1)
for n ≥1. Since σ and b are bounded, we have E(X1 −X0)∗2
t < ∞, and by
Lemma 18.5
E(Xn+1 −Xn)∗2
t ≤ct

 t
0 E(Xn −Xn−1)∗2
s ds,
t ≥0, n ≥1.
Hence, by induction,
E(Xn+1 −Xn)∗2
t ≤cn
t tn
n! E(X1 −ξ)∗2
t < ∞,
t, n ≥0.
For any k ∈N we get
supn≥k(Xn −Xk)∗
t

2
≤

n≥k
(Xn+1 −Xn)∗
t

2
≤
(X1 −ξ)∗
t

2

n≥k(cn
t tn/n!)1/2 < ∞.
Thus, by Lemma 3.6 there exists a continuous adapted process X with X0 = ξ
such that (Xn −X)∗
t →0 a.s. and in L2 for each t ≥0. To see that X solves
equation (σ, b), we may use Lemma 18.5 to obtain
E(Xn −S(X))∗2
t ≤ct

 t
0 E(Xn−1 −X)∗2
s ds,
t ≥0.
As n →∞, we get E(X −S(X))∗2
t
= 0 for all t, which implies X = S(X)
a.s.
Now consider any two solutions X and Y with |X0 −Y0| ≤ε a.s. By
Lemma 18.5 we get for any p ≥2
E(X −Y )∗p
t ≤2εp + ct

 t
0 E(X −Y )∗p
s ds,
t ≥0,
and by Lemma 18.4 it follows that
E(X −Y )∗p
t ≤2εpectt,
t ≥0.
(12)
If X0 = Y0 a.s., we may take ε = 0 and conclude that X = Y a.s., which
proves the asserted uniqueness.
Letting Xx denote the solution X with
X0 = x a.s., we get by (12)

340
Foundations of Modern Probability
E|Xx −Xy|∗p
t ≤2|x −y|pectt,
t ≥0.
Taking p > d and applying Theorem 2.23 for each T > 0 with the met-
ric ρT(f, g) = (f −g)∗
T, we conclude that the process (Xx
t ) has a jointly
continuous version on R+ × Rd.
From the construction we note that if X and Y are solutions with X0 = ξ
and Y0 = η a.s., then X = Y a.s. on the set {ξ = η}. In particular, X = Xξ
a.s. when ξ takes countably many values. In general, we may approximate ξ
uniformly by random vectors ξ1, ξ2, . . . in Qd, and by (12) we get Xξn
t
→Xt
in L2 for all t ≥0. Since also Xξn
t
→Xξ
t a.s. by the continuity of the ﬂow, it
follows that Xt = Xξ
t a.s.
✷
It is often useful to allow the solutions to explode. As in Chapter 17, we
may then introduce an absorbing state ∆at inﬁnity, so that the path space
becomes C(R+, Rd) with Rd = Rd ∪{∆}. Deﬁne ζn = inf{t; |Xt| ≥n} for
each n, put ζ = supn ζn, and let Xt = ∆for t ≥ζ. Given a Brownian motion
B in Rr and an adapted process X in the extended path space, we say that
X or the pair (X, B) solves equation (σ, b) on the interval [0, ζ) if
Xt∧ζn = X0 +

 t∧ζn
0
σ(s, X)dBs +

 t∧ζn
0
b(s, X)ds,
t ≥0, n ∈N.
(13)
When ζ < ∞, we have |Xζn| →∞, and X is said to explode at time ζ.
Conditions for the existence and uniqueness of possibly exploding so-
lutions may be obtained from Theorem 18.3 by suitable localization. The
following result is then useful to decide whether explosion can actually oc-
cur.
Proposition 18.6 (explosion) Equation (σ, b) has no exploding solution if
σ(x)∗
t + b(x)∗
t <
⌢1 + x∗
t,
t ≥0.
(14)
Proof: By Proposition 15.16 we may assume that X0 is bounded. From
(13) and (14) we get for suitable constants ct < ∞
EX∗2
t∧ζn ≤2E|X0|2 + ct

 t
0 (1 + EX∗2
s∧ζn)ds,
t ≥0, n ∈N,
and so by Lemma 18.4
1 + EX∗2
t∧ζn ≤(1 + 2E|X0|2) exp(ctt) < ∞,
t ≥0, n ∈N.
As n →∞, we obtain EX∗2
t∧ζ < ∞, which implies ζ > t a.s.
✷
Our next aim is to characterize weak solutions to equation (σ, b) by a
martingale property that involves only the solution X. Then deﬁne
M f
t = f(Xt) −f(X0) −

 t
0 Asf(X)ds,
t ≥0, f ∈C∞
K ,
(15)

18. Stochastic Diﬀerential Equations and Martingale Problems
341
where the operators As are given by
Asf(x) = 1
2aij(s, x)f ′′
ij(xs) + bi(s, x)f ′
i(xs),
s ≥0, f ∈C∞
K .
(16)
In the diﬀusion case we may replace the integrand Asf(X) in (15) by the
expression Af(Xs), where A denotes the elliptic operator
Af(x) = 1
2aij(x)f ′′
ij(x) + bi(x)f ′
i(x),
f ∈C∞
K , x ∈Rd.
(17)
A continuous process X in Rd or its distribution P is said to solve the
local martingale problem for (a, b) if M f is a local martingale for every f ∈
C∞
K . When a and b are bounded, it is clearly equivalent for M f to be a
true martingale, and the original problem turns into a martingale problem.
The (local) martingale problem for (a, b) with initial distribution µ is said
to be well posed if it has exactly one solution Pµ.
For degenerate initial
distributions δx, we may write Px instead of Pδx. The next result gives the
basic equivalence between weak solutions to an SDE and solutions to the
associated local martingale problem.
Theorem 18.7 (weak solutions and martingale problems, Stroock and Varad-
han)
Let σ and b be progressive, and ﬁx any probability measure P on
C(R+, Rd).
Then equation (σ, b) has a weak solution with distribution P
iﬀP solves the local martingale problem for (σσ′, b).
Proof: Write a = σσ′. If (X, B) solves equation (σ, b), then
[Xi, Xj] = [σi
k(X) · Bk, σj
l (X) · Bl] = σi
kσj
l (X) · [Bk, Bl] = aij(X) · λ.
By Itˆo’s formula we get for any f ∈C∞
K
df(Xt)
=
f ′
i(Xt)dXi
t + 1
2f ′′
ij(Xt)d[Xi, Xj]t
=
f ′
i(Xt)σi
j(t, X)dBj
t + Atf(X)dt.
Hence, dM f
t = f ′
i(Xt)σi
j(t, X)dBj
t , and so M f is a local martingale.
Conversely, assume that X solves the local martingale problem for (a, b).
Considering functions f i
n ∈C∞
K with f i
n(x) = xi for |x| ≤n, it is clear by a
localization argument that the processes
M i
t = Xi
t −Xi
0 −

 t
0 bi(s, X)ds,
t ≥0,
(18)
are continuous local martingales. Similarly, we may choose f ij
n ∈C∞
K with
f ij
n (x) = xixj for |x| ≤n, to obtain the local martingales
M ij = XiXj −Xi
0Xj
0 −(Xiβj + Xjβi + αij) · λ,
where αij = aij(X) and βi = bi(X). Integrating by parts and using (18), we
get
M ij
=
Xi · Xj + Xj · Xi + [Xi, Xj] −(Xiβj + Xjβi + αij) · λ
=
Xi · M j + Xj · M i + [M i, M j] −αij · λ.

342
Foundations of Modern Probability
Hence, the last two terms on the right form a local martingale, and so by
Proposition 15.2
[M i, M j]t =

 t
0 aij(s, X)ds,
t ≥0.
By Theorem 16.12 there will then exist some Brownian motion B with respect
to a standard extension of the original ﬁltration such that
M i
t =

 t
0 σi
k(s, X)dBk
s ,
t ≥0.
Substituting this into (18) yields (2), which means that the pair (X, B) solves
equation (σ, b).
✷
For subsequent needs, we note that the previous construction can be made
measurable in the following sense.
Lemma 18.8 (functional representation) Let σ and b be progressive. Then
there exists some measurable mapping
F : P(C(R+, Rd)) × C(R+, Rd) × [0, 1] →C(R+, Rr),
such that if X is a process with distribution P that solves the local martingale
problem for (σσ′, b) and if ϑ⊥⊥X is U(0, 1), then B = F(P, X, ϑ) is a Brow-
nian motion in Rr and the pair (X, B) with induced ﬁltration solves equation
(σ, b).
Proof: In the previous construction of B, the only nonelementary step is
the stochastic integration with respect to (X, Y ) in Theorem 16.12, where
Y is an independent Brownian motion, and the integrand is a progressive
function of X obtained by some elementary matrix algebra. Since the pair
(X, Y ) is again a solution to a local martingale problem, Proposition 15.27
yields the desired functional representation.
✷
Combining the martingale formulation with a compactness argument, we
may deduce some general existence and continuity results.
Theorem 18.9 (weak existence and continuity, Skorohod) Let a and b be
bounded and progressive, and such that for each t ≥0 the functions a(t, ·)
and b(t, ·) are continuous on C(R+, Rd). Then the martingale problem for
(a, b) has a solution Pµ for every initial distribution µ. If the Pµ are unique,
then the mapping µ →Pµ is further weakly continuous.
Proof: For any ε > 0, t ≥0, and x ∈C(R+, Rd), deﬁne
σε(t, x) = σ((t −ε)+, x),
bε(t, x) = b((t −ε)+, x),

18. Stochastic Diﬀerential Equations and Martingale Problems
343
and let aε = σεσ′
ε. Since σ and b are progressive, the processes σε(s, X) and
bε(s, X), s ≤t, are measurable functions of X on [0, (t −ε)+]. Hence, a
strong solution Xε to equation (σε, bε) may be constructed recursively on the
intervals [(n−1)ε, nε], n ∈N, starting from an arbitrary random vector ξ⊥⊥B
in Rd with distribution µ. Note in particular that Xε solves the martingale
problem for the pair (aε, bε).
Applying Proposition 15.7 to equation (σε, bε) and using the boundedness
of σ and b, we get for any p > 0
E sup
0≤r≤h |Xε
t+r −Xε
t |p <
⌢hp/2 + hp <
⌢hp/2,
t, ε ≥0, h ∈[0, 1].
For p > 2d it follows by Corollary 14.9 that the family {Xε} is tight in
C(R+, Rd), and by Theorem 14.3 we may then choose some εn →0 such that
Xεn
d→X for a suitable X.
To see that X solves the martingale problem for (a, b), ﬁx any f ∈
C∞
K and s < t, and consider an arbitrary bounded, continuous function
g: C([0, s], Rd) →R. We need to show that
E

f(Xt) −f(Xs) −

 t
s Arf(X)dr

g(X) = 0.
Then note that Xε satisﬁes the corresponding equation for the operators Aε
r
constructed from the pair (aε, bε). Writing the two conditions as Eϕ(X) = 0
and Eϕε(Xε) = 0, respectively, it suﬃces by Theorem 3.27 to show that
ϕε(xε) →ϕ(x) whenever xε →x in C(R+, Rd). This follows easily from the
continuity conditions imposed on a and b.
Now assume that the solutions Pµ are unique, and let µn
w→µ. Arguing
as before, it is seen that (Pµn) is tight, and so by Theorem 14.3 it is also
relatively compact. If Pµn
w→Q along some subsequence, we note as before
that Q solves the martingale problem for (a, b) with initial distribution µ.
Hence Q = Pµ, and the convergence extends to the original sequence.
✷
Our next aim is to show how the well-posedness of the local martingale
problem for (a, b) extends from degenerate to arbitrary initial distributions.
This requires a basic measurability property, which will also be needed later.
Theorem 18.10 (measurability and mixtures, Stroock and Varadhan) Let
a and b be progressive and such that for every x ∈Rd the local martingale
problem for (a, b) has a unique solution Px with initial distribution δx. Then
(Px) is a kernel from Rd to C(R+, Rd), and the local martingale problem for
an arbitrary initial distribution µ has the unique solution Pµ =
 Pxµ(dx).
Proof: According to the proof of Theorem 18.7, it is enough to formulate
the local martingale problem in terms of functions f belonging to some count-
able subclass C ⊂C∞
K , consisting of suitably truncated versions of the coordi-
nate functions xi and their products xixj. Now deﬁne P = P(C(Rd, Rd)) and

344
Foundations of Modern Probability
PM = {Px; x ∈Rd}, and write X for the canonical process in C(R+, Rd). Let
D denote the class of measures P ∈P with degenerate projections P ◦X−1
0 .
Next let I consist of all measures P ∈P such that X satisﬁes the integrabil-
ity condition (3). Finally, put τ f
n = inf{t; |M f
t | ≥n}, and let L be the class
of measures P ∈P such that the processes M f,n
t
= M f(t ∧τ f
n) exist and are
martingales under P for all f ∈C and n ∈N. Then clearly PM = D ∩I ∩L.
To prove the asserted kernel property, it is enough to show that PM is
a measurable subset of P, since the desired measurability will then follow
by Theorem A1.7 and Lemma 1.37. The measurability of D is clear from
Lemma 1.36 (i). Even I is measurable, since the integrals on the left of (3)
are measurable by Fubini’s theorem. Finally, L ∩I is a measurable subset
of I, since the deﬁning condition is equivalent to countably many relations
of the form E[M f,n
t
−M f,n
s
; F] = 0, with f ∈C, n ∈N, s < t in Q+, and
F ∈Fs.
Now ﬁx any probability measure µ on Rd. The measure Pµ =
 Pxµ(dx)
has clearly initial distribution µ, and from the previous argument we note
that Pµ again solves the local martingale for (a, b). To prove the uniqueness,
let P be any measure with the stated properties. Then E[M f,n
t
−M f,n
s
; F|
X0] = 0 a.s. for all f, n, s < t, and F as above, and so P[ · |X0] is a.s. a
solution to the local martingale problem with initial distribution δX0. Thus,
P[ · |X0] = PX0 a.s., and we get P = EPX0 =
 Pxµ(dx) = Pµ. This extends
the well-posedness to arbitrary initial distributions.
✷
We return to the basic problem of constructing a Feller diﬀusion with
given generator A in (17) as the solution to a suitable SDE or the associated
martingale problem. The following result may be regarded as a converse to
Theorem 17.24.
Theorem 18.11 (strong Markov and Feller properties, Stroock and Varad-
han) Let a and b be measurable functions on Rd such that for every x ∈Rd
the local martingale problem for (a, b) with initial distribution δx has a unique
solution Px. Then the family (Px) satisﬁes the strong Markov property. If a
and b are also bounded and continuous, then the equation Ttf(x) = Exf(Xt)
deﬁnes a Feller semigroup (Tt) on C0, and the operator A in (17) extends
uniquely to the associated generator.
Proof: By Theorem 18.10 it remains to prove, for any state x ∈Rd and
bounded optional time τ, that
Px[X ◦θτ ∈· |Fτ] = PXτ a.s.
As in the previous proof, this is equivalent to countably many relations of
the form
Ex[{(M f,n
t
−M f,n
s
)1F} ◦θτ|Fτ] = 0 a.s.
(19)
with s < t and F ∈Fs, where M f,n denotes the process M f stopped at
τn = inf{t; |M f| ≥n}.
Now θ−1
τ Fs ⊂Fτ+s by Lemma 6.5, and in the

18. Stochastic Diﬀerential Equations and Martingale Problems
345
diﬀusion case
(M f,n
t
−M f,n
s
) ◦θτ = M f
(τ+t)∧σn −M f
τ∧σn,
where σn = τ + τn ◦θτ, which is again optional by Proposition 7.8. Thus,
(19) follows by optional sampling from the local martingale property of M f
under Px.
Now assume that a and b are also bounded and continuous, and deﬁne
Ttf(x) = Exf(Xt). By Theorem 18.9 we note that Ttf is continuous for
every f ∈C0 and t > 0, and from the continuity of the paths it is clear that
Ttf(x) is continuous in t for each x. To see that Ttf ∈C0, it remains to show
that |Xx
t |
P→∞as |x| →∞, where Xx has distribution Px. But this follows
from the SDE by the boundedness of σ and b if for 0 < r < |x| we write
P{|Xx
t | < r} ≤P{|Xx
t −x| > |x| −r} ≤E|Xx
t −x|2
(|x| −r)2
<
⌢
t + t2
(|x| −r)2,
and let |x| →∞for ﬁxed r and t. The last assertion is obvious from the
uniqueness in law together with Theorem 17.23.
✷
Establishing uniqueness in law is usually harder than proving weak ex-
istence. Some fairly general uniqueness criteria are obtained in Theorems
20.1 and 21.2. For the moment we shall only exhibit some transformations
that may simplify the problem. The following result, based on a change of
probability measure, is often useful to eliminate the drift term.
Proposition 18.12 (transformation of drift) Let σ, b, and c be progres-
sive functions of suitable dimension, where c is bounded. Then weak exis-
tence holds simultaneously for equations (σ, b) and (σ, b + σc). If, moreover,
c = σ′h for some progressive function h, then even uniqueness in law holds
simultaneously for the two equations.
Proof: Let X be a weak solution to equation (σ, b), deﬁned on the canon-
ical space for (X, B) with induced ﬁltration F and with probability measure
P. Deﬁne V = c(X), and note that (V 2 · λ)t is bounded for each t. By
Lemma 16.18 and Corollary 16.25 there exists a probability measure Q with
Q = E(V ′ · B)t · P on Ft for each t ≥0, and we note that ˜B = B −V · λ is a
Q-Brownian motion. Under Q we further get by Proposition 16.20
X −X0
=
σ(X) · ( ˜B + V · λ) + b(X) · λ
=
σ(X) · ˜B + (b + σc)(X) · λ,
which shows that X is a weak solution to the SDE (σ, b+σc). Since the same
argument applies to equation (σ, b + σc) with c replaced by −c, we conclude
that weak existence holds simultaneously for the two equations.
Now let c = σ′h, and assume that uniqueness in law holds for equation
(σ, b + ah). Further assume that (X, B) solves equation (σ, b) under both P

346
Foundations of Modern Probability
and Q. Choosing V and ˜B as before, it follows that (X, ˜B) solves equation
(σ, b+σc) under the transformed distributions E(V ′·B)t·P and E(V ′·B)t·Q for
(X, B). By hypothesis the latter measures then have the same X-marginal,
and the stated condition implies that E(V ′ · B) is X-measurable. Thus, the
X-marginals agree even for P and Q, which proves the uniqueness in law for
equation (σ, b). Again we may reverse the argument to get an implication in
the other direction.
✷
Next we shall see how an SDE of diﬀusion type can be transformed by
a random time-change. The method is used systematically in Chapter 20 to
analyze the one-dimensional case.
Proposition 18.13 (scaling) Fix some measurable functions σ, b, and c >
0 on Rd, where c is bounded away from 0 and ∞. Then weak existence and
uniqueness in law hold simultaneously for equations (σ, b) and (cσ, c2b).
Proof: Assume that X solves the local martingale problem for the pair
(a, b), and introduce the process V = c2(X)·λ with inverse (τs). By optional
sampling we note that M f
τs, s ≥0, is again a local martingale, and the process
Ys = Xτs satisﬁes
M f
τs = f(Ys) −f(Y0) −

 s
0 c2Af(Yr)dr.
Thus, Y solves the local martingale problem for (c2a, c2b).
Now let T denote the mapping on C(R+, Rd) leading from X to Y , and
write T ′ for the corresponding mapping based on c−1. Then T and T ′ are
mutual inverses, and so by the previous argument applied to both mappings,
a measure P ∈P(C(R+, Rd)) solves the local martingale problem for (a, b) iﬀ
P ◦T −1 solves the corresponding problem for (c2a, c2b). Thus, both existence
and uniqueness hold simultaneously for the two problems. By Theorem 18.7
the last statement translates immediately into a corresponding assertion for
the SDEs.
✷
Our next aim is to examine the connection between weak and strong solu-
tions. Under appropriate conditions, we shall further establish the existence
of a universal functional solution. To explain the subsequent terminology, let
G be the ﬁltration induced by the identity mapping (ξ, B) on the canonical
space Ω= Rd × C(R+, Rr), so that Gt = σ{ξ, Bt), t ≥0, where Bt
s = Bs∧t.
Writing W r for the r-dimensional Wiener measure, we may introduce for any
µ ∈P(Rd) the (µ ⊗W r)-completion Gµ
t of Gt. The universal completion Gt
is deﬁned as

µ Gµ
t , and we say that a function
F : Rd × C(R+, Rr) →C(R+, Rd)
(20)
is universally adapted if it is adapted to the ﬁltration G = (Gt).

18. Stochastic Diﬀerential Equations and Martingale Problems
347
Theorem 18.14 (pathwise uniqueness and functional solution) Let σ and
b be progressive and such that weak existence and pathwise uniqueness hold
for solutions to equation (σ, b) starting at ﬁxed points. Then strong existence
and uniqueness in law hold for any initial distribution, and there exists some
measurable and universally adapted function F as in (20) such that every
solution (X, B) to equation (σ, b) satisﬁes X = F(X0, B) a.s.
Note in particular that the function F above is independent of initial
distribution µ.
A key step in the proof is to establish the corresponding
result for a ﬁxed µ, which will be done in Lemma 18.17. Two further lemmas
will be needed, and we begin with a statement that clariﬁes the connection
between adaptedness, strong existence, and functional solutions.
Lemma 18.15 (transfer of strong solution) Consider a solution (X, B) to
equation (σ, b) such that X is adapted to the complete ﬁltration induced by X0
and B. Then X = F(X0, B) a.s. for some Borel-measurable function F as in
(20), and for any basic triple (F, ˜B, ξ) with ξ d= X0, the process ˜X = F(ξ, ˜B)
is F-adapted and such that the pair ( ˜X, ˜B) solves equation (σ, b).
Proof: By Lemma 1.13 we have X = F(X0, B) a.s. for some Borel-
measurable function F as stated. By the same result, there exists for ev-
ery t ≥0 a further representation of the form Xt = Gt(X0, Bt) a.s., and so
F(X0, B)t = Gt(X0, Bt) a.s. Hence, ˜Xt = Gt(ξ, ˜Bt) a.s., so ˜X is F-adapted.
Since, moreover, ( ˜X, ˜B)
d= (X, B), Proposition 15.27 shows that even the
former pair solves equation (σ, b).
✷
Next we shall see how even weak solutions can be transferred to any given
probability space with a speciﬁed Brownian motion.
Lemma 18.16 (transfer of weak solution) Let (X, B) solve equation (σ, b),
and consider any basic triple (F, ˜B, ξ) with ξ
d= X0. Then there exists a
process ˜X⊥⊥ξ, ˜BF with ˜X0 = ξ a.s. and ( ˜X, ˜B)
d= (X, B). Furthermore, the
ﬁltration G induced by ( ˜X, F) is a standard extension of F, and the pair
( ˜X, ˜B) with ﬁltration G solves equation (σ, b).
Proof: By Theorem 5.10 and Proposition 5.13 there exists a process
˜X⊥⊥ξ, ˜BF satisfying ( ˜X, ξ, ˜B) d= (X, X0, B), and in particular ˜X0 = ξ a.s. To
see that G is a standard extension of F, ﬁx any t ≥0 and deﬁne ˜B′ = ˜B−˜Bt.
Then ( ˜Xt, ˜Bt)⊥⊥˜B′ since the corresponding relation holds for (X, B), and so
˜Xt⊥⊥ξ, ˜Bt ˜B′. Since also ˜Xt⊥⊥ξ, ˜BF, Proposition 5.8 yields ˜Xt⊥⊥ξ, ˜Bt( ˜B′, F) and
hence ˜Xt⊥⊥FtF. But then ( ˜Xt, Ft)⊥⊥FtF by Corollary 5.7, which means that
Gt⊥⊥FtF.
Since standard extensions preserve martingales, Theorem 16.3 shows that
˜B remains a Brownian motion with respect to G. As in Proposition 15.27 it
may then be seen that the pair ( ˜X, ˜B) solves equation (σ, b).
✷

348
Foundations of Modern Probability
We are now ready to establish the crucial relationship between pathwise
uniqueness and strong existence.
Lemma 18.17 (pathwise uniqueness and strong existence, Yamada and Wa-
tanabe) Assume that weak existence and pathwise uniqueness hold for solu-
tions to equation (σ, b) with initial distribution µ. Then even strong existence
and uniqueness in law hold for such solutions, and there exists a measurable
function Fµ as in (20) such that any solution (X, B) with initial distribution
µ satisﬁes X = Fµ(X0, B) a.s.
Proof: Fix any solution (X, B) with initial distribution µ and associated
ﬁltration F.
By Lemma 18.16 there exists some process Y ⊥⊥X0,BF with
Y0 = X0 a.s. such that (Y, B) solves equation (σ, b) for the ﬁltration G induced
by (Y, F). Since G is a standard extension of F, the pair (X, B) remains a
solution for G, and the pathwise uniqueness yields X = Y a.s.
For each t ≥0 we have Xt⊥⊥X0,BXt and (Xt, Bt)⊥⊥(B −Bt), and so
Xt⊥⊥X0,BtXt a.s. by Proposition 5.8. Thus, Corollary 5.7 (ii) shows that X
is adapted to the complete ﬁltration induced by (X0, B). Hence, by Lemma
18.15 there exists a measurable function Fµ with X = Fµ(X0, B) a.s. and such
that, for any basic triple ( ˜F, ˜B, ξ) with ξ
d= X0, the process ˜X = Fµ(ξ, ˜B)
is ˜F-adapted and solves equation (σ, b) along with ˜B. In particular, ˜X
d= X
since (ξ, ˜B) d= (X0, B), and by the pathwise uniqueness ˜X is the a.s. unique
solution for the given triple ( ˜F, ˜B, ξ). This proves the uniqueness in law. ✷
Proof of Theorem 18.14: By Lemma 18.17 we have uniqueness in law for
solutions starting at ﬁxed points, and Theorem 18.10 shows that the corre-
sponding distributions Px form a kernel from Rd to C(R+, Rd). By Lemma
18.8 there exists a measurable mapping G such that if X has distribution
Px and ϑ⊥⊥X is U(0, 1), then B = G(Px, X, ϑ) is a Brownian motion in Rr
and the pair (X, B) solves equation (σ, b). Writing Qx for the distribution of
(X, B), it is clear from Lemmas 1.35 and 1.38 (ii) that the mapping x →Qx
is a kernel from Rd to C(R+, Rd+r).
Changing the notation, we may write (X, B) for the canonical process in
C(R+, Rd+r). By Lemma 18.17 we have X = Fx(x, B) = Fx(B) a.s. Qx, and
so
Qx[X ∈·|B] = δFx(B) a.s.,
x ∈Rd.
(21)
By Proposition 6.26 we may choose versions νx,w = Qx[X ∈·|B ∈dw] that
combine into a probability kernel ν from Rd×C(R+, Rr) to C(R+, Rd). From
(21) it is further seen that νx,w is a.s. degenerate for each x. Since the set D
of degenerate measures is measurable by Lemma 1.36 (i), we may modify ν
such that νx,wD ≡1. In that case
νx,w = δF(x,w),
x ∈Rd, w ∈C(R+, Rr),
(22)

18. Stochastic Diﬀerential Equations and Martingale Problems
349
for some function F as in (20), and the kernel property of ν implies that F
is product measurable. Comparing (21) and (22) gives F(x, B) = Fx(B) a.s.
for all x.
Now ﬁx any probability measure µ on Rd, and conclude as in Theorem
18.10 that Pµ =
 Pxµ(dx) solves the local martingale problem for (a, b)
with initial distribution µ. Hence, equation (σ, b) has a solution (X, B) with
distribution µ for X0. Since conditioning on F0 preserves martingales, the
equation remains conditionally valid given X0. By the pathwise uniqueness
in the degenerate case we get P[X = F(X0, B)|X0] = 1 a.s., and so X =
F(X0, B) a.s. In particular, the pathwise uniqueness extends to arbitrary
initial distributions µ.
Returning to the canonical setting, we may write (ξ, B) for the identity
mapping on the canonical space Rd × C(R+, Rr) with probability measure
µ⊗W r and induced completed ﬁltration Gµ. By Lemma 18.17 equation (σ, b)
has a Gµ-adapted solution X = Fµ(ξ, B) with X0 = ξ a.s., and the previous
discussion shows that even X = F(ξ, B) a.s. Hence, F is adapted to Gµ,
and since µ is arbitrary, the adaptedness extends to the universal completion
Gt =

µ Gµ
t , t ≥0.
✷

Chapter 19
Local Time, Excursions,
and Additive Functionals
Tanaka’s formula and semimartingale local time; occupation den-
sity, continuity and approximation; regenerative sets and pro-
cesses; excursion local time and Poisson process; Ray–Knight the-
orem; excessive functions and additive functionals; local time at
regular point; additive functionals of Brownian motion
The central theme of this chapter is the notion of local time, which we will
approach in three diﬀerent ways, namely via stochastic calculus, via excur-
sion theory, and via additive functionals. Here the ﬁrst approach leads in
particular to a useful extension of Itˆo’s formula and to an interpretation of
local time as an occupation density. Excursion theory will be developed for
processes that are regenerative at a ﬁxed state, and we shall prove the basic
Itˆo representation in terms of a Poisson process of excursions on the local
time scale. Among the many applications, we shall consider a version of
the Ray–Knight theorem about the spatial variation of Brownian local time.
Finally, we shall study continuous additive functionals (CAFs) and their po-
tentials, prove the existence of local time at a regular point, and show that
any CAF of one-dimensional Brownian motion is a mixture of local times.
The beginning of this chapter may be regarded as a continuation of the
stochastic calculus developed in Chapter 15. The present excursion theory
continues the elementary discussion for the discrete-time case in Chapter 7.
Though the theory of CAFs is formally developed for Feller processes, few
results from Chapter 17 will be needed beyond the strong Markov property
and its integrated version in Corollary 17.19. Both semimartingale local time
and excursion theory reappear in Chapter 20 as useful tools for studying
one-dimensional SDEs and diﬀusions. Our discussion of CAFs of Brownian
motion and their associated potentials is continued at the end of Chapter 22.
For the stochastic calculus approach to local time, consider an arbitrary
continuous semimartingale X in R. The semimartingale local time L0 of X
at 0 may be deﬁned through Tanaka’s formula
L0
t = |Xt| −|X0| −

 t
0 sgn(Xs−)dXs,
t ≥0,
(1)
where sgn(x−) = 1(0,∞)(x) −1(−∞,0](x). Note that the stochastic integral on
the right exists since the integrand is bounded and progressive. The process
350

19. Local Time, Excursions, and Additive Functionals
351
L0 is clearly continuous and adapted with L0
0 = 0. To motivate the deﬁnition,
we note that a formal application of Itˆo’s rule to the function f(x) = |x| yields
(1) with L0
t =

s≤t δ(Xs)d[X]s. The following result gives the basic properties
of local time at a ﬁxed point. Here we shall say that a nondecreasing function
f is supported by a Borel set A if the associated measure µ satisﬁes µAc = 0.
The support of f is the smallest closed set with this property.
Theorem 19.1 (semimartingale local time) Let L0 be the local time at 0 of
a continuous semimartingale X. Then L0 is a.s. nondecreasing, continuous,
and supported by the set Z = {t ≥0; Xt = 0}. Furthermore, we have a.s.
L0
t =

−|X0| −inf
s≤t

 s
0 sgn(X−)dX

∨0,
t ≥0.
(2)
The proof of the last assertion depends on an elementary lemma.
Lemma 19.2 (supporting function, Skorohod) Let f be a continuous func-
tion on R+ with f0 ≥0. Then there exists a unique nondecreasing, continu-
ous function g with g0 = 0 such that h = f + g ≥0 and
 1{h > 0}dg = 0,
namely,
gt = −inf
s≤t fs ∧0 = sup
s≤t (−fs) ∨0,
t ≥0.
(3)
Proof: The function in (3) clearly has the desired properties. To prove
the uniqueness, assume that both g and g′ have the stated properties, and
put h = f + g and h′ = f + g′.
If gt < g′
t for some t > 0, deﬁne
s = sup{r < t; gr = g′
r}, and note that h′ ≥h′ −h = g′ −g > 0 on
(s, t]. Hence, g′
s = g′
t, and so 0 < g′
t −gt ≤g′
s −gs = 0, a contradiction.
✷
Proof of Theorem 19.1: For each h > 0 we may choose a convex function
fh ∈C2 with fh(x) = −x for x ≤0 and fh(x) = x −h for x ≥h. Note that
fh(x) →|x| and f ′
h →sgn(x−) as h →0. By Itˆo’s formula we get, a.s. for
any t ≥0,
Y h
t ≡fh(Xt) −fh(X0) −

 t
0 f ′
h(Xs)dXs = 1
2

 t
0 f ′′
h(Xs)d[X]s,
and by Corollary 15.14 and dominated convergence we note that (Y h −L0)∗
t
P→0 for each t > 0. The ﬁrst assertion now follows from the fact that the
processes Y h are nondecreasing and satisfy

 ∞
0
1{Xs /∈[0, h]}dY h
s = 0 a.s.,
h > 0.
The last assertion is a consequence of Lemma 19.2.
✷
In particular, we may deduce a basic relationship between a Brownian
motion, its maximum process, and its local time at 0. The result improves
the elementary Proposition 11.13.

352
Foundations of Modern Probability
Corollary 19.3 (local time and maximum process, L´evy) Let L0 be the local
time at 0 of Brownian motion B, and deﬁne Mt = sups≤t Bs. Then
(L0, |B|) d= (M, M −B).
Proof: Deﬁne B′
t = −

s≤t sgn(Bs−)dBs and M ′
t = sups≤t B′
s, and con-
clude from (1) and (2) that L0 = M ′ and |B| = L0 −B′ = M ′ −B′. It
remains to note that B′ d= B by Theorem 16.3.
✷
The local time Lx at an arbitrary point x ∈R is deﬁned as the local time
of the process X −x at 0. Thus,
Lx
t = |Xt −x| −|X0 −x| −

 t
0 sgn(Xs −x−)dXs,
t ≥0.
(4)
The following result shows that the two-parameter process L = (Lx
t ) on
R+ × R has a version that is continuous in t and rcll (right-continuous with
left-hand limits) in x. In the martingale case we even have joint continuity.
Theorem 19.4 (regularization, Trotter, Yor) Let X be a continuous semi-
martingale with canonical decomposition M + A and local time L.
Then
L = (Lx
t ) has a version that is rcll in x, uniformly for bounded t, and satis-
ﬁes
Lx
t −Lx−
t
= 2

 t
0 1{Xs = x}dAs,
x ∈R, t ∈R+.
(5)
Proof: By the deﬁnition of L we have for any x ∈R and t ≥0
Lx
t
=
|Xt −x| −|X0 −x|
−

 t
0 sgn(Xs −x−)dMs −

 t
0 sgn(Xs −x−)dAs.
(6)
By dominated convergence the last term has the required continuity proper-
ties, and the discontinuities in the space variable are given by the right-hand
side of (5).
Since the ﬁrst two terms are trivially continuous in (t, x), it
remains to show that the ﬁrst integral in (6), denoted by Ix
t below, has a
jointly continuous version.
By localization we may then assume that the processes X −X0, [M]1/2,
and
 |dA| are all bounded by some constant c. Fix any p > 2. By Proposition
15.7 we get for any x < y
E(Ix −Iy)∗p
t ≤2pE(1(x,y](X) · M)∗p
t <
⌢E(1(x,y](X) · [M])p/2
t
.
(7)
To estimate the integral on the right, put y −x = h and choose f ∈C2 with
f ′′ ≥2 · 1(x,y] and |f ′| ≤2h. By Itˆo’s formula
1(x,y](X) · [M]
≤
1
2f ′′(X) · [X] = f(X) −f(X0) −f ′(X) · X
≤
4ch + |f ′(X) · M|,
(8)

19. Local Time, Excursions, and Additive Functionals
353
and by another application of Proposition 15.7
E(f ′(X) · M)∗p/2
t
<
⌢E((f ′(X))2 · [M])p/4
t
≤(2ch)p/2.
(9)
Combination of (7)—(9) gives E(Ix −Iy)∗p
t <
⌢(ch)p/2, and the desired conti-
nuity follows by Theorem 2.23.
✷
By the last result we may henceforth assume the local time Lx
t to be rcll
in x. The right-continuity is only a convention, consistent with our choice
of a left-continuous sign function in (4). If the occupation measure of the
ﬁnite variation component A of X is a.s. diﬀuse, then (5) shows that L is
a.s. continuous.
We proceed to give a simultaneous extension of Itˆo’s and Tanaka’s for-
mulas. Recall that any convex function f on R has a nondecreasing and
left-continuous left derivative f ′(x−). The same thing is then true when f
is the diﬀerence between two convex functions. In that case there exists a
unique signed measure µf with µf[x, y) = f ′(y−) −f ′(x−) for all x ≤y. In
particular, µf(dx) = f ′′(x)dx when f ∈C2.
Theorem 19.5 (occupation density, Meyer, Wang) Let X be a continuous
semimartingale with right-continous local time L. Then for any measurable
function f : R →R+ and outside a ﬁxed null set,

 t
0 f(Xs)d[X]s =

 ∞
−∞f(x)Lx
t dx,
t ≥0.
(10)
If f is the diﬀerence between two convex functions, then moreover
f(Xt) −f(X0) =

 t
0 f ′(X−)dX + 1
2

 ∞
−∞Lx
t µf(dx),
t ≥0.
(11)
In particular, Theorem 15.19 extends to any function f ∈C1(R) such that
f ′ is absolutely continuous with Radon–Nikod´ym derivative f ′′.
Note that (11) remains valid for the left-continuous version of L, provided
that f ′(X−) is replaced by the right derivative f ′(X+).
Proof: For f(x) ≡|x −a| equation (11) reduces to the deﬁnition of La
t .
Since the formula is also trivially true for aﬃne functions f(x) ≡ax + b,
it extends by linearity to the case when µf is supported by a ﬁnite set.
By linearity and a suitable truncation, it remains to prove (11) when µf is
positive with bounded support and f(−∞) = f ′(−∞) = 0. Then deﬁne for
every n ∈N the functions
gn(x) = f ′(2−n[2nx]−),
fn(x) =

 x
∞gn(u)du,
x ∈R,
and note that (11) holds for all fn. As n →∞, we get f ′
n(x−) = gn(x−) ↑
f ′(x−), and so Corollary 15.14 yields f ′
n(X−) · X
P→f ′(X−) · X.
Also

354
Foundations of Modern Probability
note that fn →f by monotone convergence.
It remains to show that
 Lx
t µfn(dx) →
 Lx
t µf(dx). Then let h be any bounded, right-continuous
function on R, and note that µfnh = µfhn with hn(x) = h(2−n[2nx + 1]).
Since hn →h, we get µfhn →µfh by dominated convergence.
Comparing (11) with Itˆo’s formula, we note that (10) holds a.s. for any
t ≥0 and f ∈C. Now both sides of (10) deﬁne random measures on R
for each t, and by suitable approximation and monotone class arguments we
may then choose the exceptional null set N to be independent of f. By the
continuity of each side, we may also choose N to be independent of t.
If f ∈C1 with f ′ as stated, then (11) applies with µf(dx) = f ′′(x)dx,
and the last assertion follows by (10).
✷
In particular, we note that the occupation measure at time t,
ηtA =

 t
0 1A(Xs)d[X]s,
A ∈B(R), t ≥0,
(12)
is a.s. absolutely continuous with density Lt. This leads to a simple construc-
tion of L.
Corollary 19.6 (right derivative) Outside a ﬁxed P-null set,
Lx
t = lim
h→0 ηt[x, x + h)/h,
t ≥0, x ∈R.
Proof: Use Theorem 19.5 and the right-continuity of L.
✷
Next we shall see how local time arises naturally in the context of regen-
erative processes. Then consider an rcll process X in some Polish space S
such that X is adapted to some right-continuous and complete ﬁltration F.
Fix a state a ∈S, and assume X to be regenerative at a, in the sense that
there exists some distribution Pa on the path space satisfying
P[θτX ∈·|Fτ] = Pa a.s. on {τ < ∞, Xτ = a},
(13)
for every optional time τ. The relation will often be applied to the hitting
times τr = inf{t ≥r; Xt = a}, which are optional for all r ≥0 by Theorem
6.7. In fact, when X is continuous, the optionality of τr follows already from
the elementary Lemma 6.6. In particular, we note that Fτ0 and θτ0X are
conditionally independent, given that τ0 < ∞. For simplicity we may hence-
forth take X to be the canonical process on the path space D = D(R+, S),
equipped with the distribution P = Pa.
Introducing the regenerative set Z = {t ≥0; Xt = a}, we may write
the last event in (13) simply as {τ ∈Z}. From the right-continuity of X
it is clear that Z ∋tn ↓t implies t ∈Z, which means that every point in
Z \ Z is isolated from the right. Since Z
c is open and hence a countable
union of disjoint open intervals, it follows that Zc is a countable union of
disjoint intervals of the form (u, v) or [u, v). With every such interval we

19. Local Time, Excursions, and Additive Functionals
355
may associate an excursion process Yt = X(t+u)∧v, t ≥0. Note that a is
absorbing for Y , in the sense that Yt = a for all t ≥inf{s > 0; Ys = a}. The
number of excursions may be ﬁnite or inﬁnite, and if Z is bounded there is
clearly a last excursion of inﬁnite length.
We begin with a classiﬁcation according to the local properties of Z.
Proposition 19.7 (local dichotomies) For any regenerative set Z we have
(i) either (Z)◦= ∅a.s., or Z◦= Z a.s.;
(ii) either a.s. all points of Z are isolated, or a.s. none of them is;
(iii) either λZ = 0 a.s., or supp(Z · λ) = Z a.s.
Recall that the set Z is said to be nowhere dense if (Z)◦= ∅and that Z
is perfect if Z has no isolated points. If Z◦= Z, then clearly supp(Z ·λ) = Z,
and no isolated points can exist.
Proof: By the regenerative property, we have for any optional time τ
P{τ = 0} = E[P[τ = 0|F0]; τ = 0] = (P{τ = 0})2,
and so P{τ = 0} = 0 or 1. If σ is another optional time, then τ ′ = σ + τ ◦θσ
is again optional by Proposition 7.8, and we get
P{τ ′ −h ≤σ ∈Z} = P{τ ◦θσ ≤h, σ ∈Z} = P{τ ≤h}P{σ ∈Z}.
Thus, P[τ ′ −σ ∈·|σ ∈Z] = P ◦τ −1, and in particular τ = 0 a.s. implies
τ ′ = σ a.s. on {σ ∈Z}.
(i) We may apply the previous argument to the optional times τ = inf Zc
and σ = τr. If τ > 0 a.s., then τ ◦θτr > 0 a.s. on {τr < ∞}, and so τr ∈Z◦
a.s. on the same set. Since the set {τr; r ∈Q+} is dense in Z, it follows
that Z = Z◦a.s. Now assume instead that τ = 0 a.s. Then τ ◦θτr = 0
a.s. on {τr < ∞}, and so τr ∈Zc a.s. on the same set. Hence, Z ⊂Zc a.s.,
and therefore Zc = R+ a.s. It remains to note that Zc = (Z)c, since Zc is a
disjoint union of intervals (u, v) or [u, v).
(ii) In this case we deﬁne τ = inf(Z \ {0}). If τ = 0 a.s., then τ ◦θτr = 0
a.s. on {τr < ∞}. Since every isolated point of Z is of the form τr for some
r ∈Q+, it follows that Z has a.s. no isolated points. If instead τ > 0 a.s., we
may deﬁne the optional times σn recursively by σn+1 = σn + τ ◦θσn, starting
from σ1 = τ. Then σn =
	
k≤n ξk, where the ξk are i.i.d. and distributed as
τ, so σn →∞a.s. by the law of large numbers. Thus, Z = {σn < ∞; n ∈N}
a.s., and a.s. all points of Z are isolated.
(iii) Here we may take τ = inf{t > 0; (Z · λ)t > 0}. If τ = 0 a.s., then
τ ◦θτr = 0 a.s. on {τr < ∞}, so τr ∈supp(Z · λ) a.s. on the same set. Hence,
Z ⊂supp(Z · λ) a.s., so the two sets agree a.s. If instead τ > 0 a.s., then
τ = τ + τ ◦θτ > τ a.s. on {τ < ∞}, which implies τ = ∞a.s. This yields
λZ = 0 a.s.
✷

356
Foundations of Modern Probability
To examine the global properties of Z, we may introduce the holding
time γ = inf Zc = inf{t > 0; Xt ̸= a}, which is optional by Lemma 6.6. The
following extension of Lemma 10.18 gives some more detailed information
about dichotomy (i) above.
Lemma 19.8 (holding time) The time γ is exponentially distributed with
mean m ∈[0, ∞], where m = 0 or ∞when X is continuous. Furthermore,
Z is a.s. nowhere dense when m = 0, and otherwise it is a.s. a locally ﬁnite
union of intervals [σ, τ). Finally, γ⊥⊥X ◦θγ when m < ∞.
Proof: The ﬁrst and last assertions may be proved as in Lemma 10.18,
and the statement for m = 0 was obtained in Proposition 19.7 (i). Now let
0 < m < ∞. Noting that γ ◦θγ = 0 a.s. on {γ ∈Z}, we get
0 = P{γ ◦θγ > 0, γ ∈Z} = P{γ > 0}P{γ ∈Z} = P{γ ∈Z},
so in this case γ /∈Z a.s. Put σ0 = 0, let σ1 = γ + τ0 ◦θγ, and deﬁne
recursively σn+1 = σn + σ1 ◦θσn. Write γn = σn + γ ◦θσn. Then σn →∞a.s.
by the law of large numbers, so Z = 
n[σn, γn). If X is continuous, then Z
is closed and the last case is excluded.
✷
The state a is said to be absorbing if m = ∞and instantaneous if m = 0.
In the former case clearly X ≡a and Z = R+ a.s., so to avoid trivial
exceptions we may henceforth assume that m < ∞. A separate treatment
is sometimes required for the elementary case when the recurrence time γ +
τ0+ ◦θγ is a.s. strictly positive. This clearly occurs when Z has a.s. only
isolated points or the holding time γ is positive.
We proceed to examine the set of excursions.
Since there is no ﬁrst
excursion in general, it is helpful ﬁrst to focus on excursions of long duration.
For any h ≥0, let Dh denote the set of excursion paths longer than h,
endowed with the σ-ﬁeld Dh generated by all evaluation maps πt, t ≥0.
Note that D0 is a Borel space and that Dh ∈D0 for all h. The number of
excursions in Dh will be denoted by κh. The following result is a continuous-
time version of Proposition 7.15.
Lemma 19.9 (long excursions) Fix any h > 0, and allow even h = 0 when
the recurrence time is positive. Then either κh = 0 a.s., or κh is geometrically
distributed with mean mh ∈[1, ∞]. In the latter case there exist some i.i.d.
processes Y 1
h , Y 2
h , . . . in Dh such that X has Dh-excursions Y j
h , j ≤κh. If
mh < ∞, then Y κh
h
is a.s. inﬁnite.
Proof: For t ∈(0, ∞], let κt
h denote the number of Dh-excursions com-
pleted at time t ∈[0, ∞], and note that κτt
h > 0 when τt = ∞. Writing
ph = P{κh > 0}, we obtain
ph
=
P{κτt
h > 0} + P{κτt
h = 0, κh ◦θτt > 0}
=
P{κτt
h > 0} + P{κτt
h = 0}ph.

19. Local Time, Excursions, and Additive Functionals
357
Since κt
h →κh as t →∞, we get ph = ph + (1 −ph)ph, and so ph = 0 or 1.
Now assume that ph = 1. Put σ0 = 0, let σ1 denote the end of the ﬁrst
Dh-excursion, and recursively deﬁne σn+1 = σn + σ1 ◦θσn. If all excursions
are ﬁnite, then clearly σn < ∞a.s. for all n, so κh = ∞a.s. Thus, the last
Dh-excursion is inﬁnite when κh < ∞. We may now proceed as in the proof
of Proposition 7.15 to construct some i.i.d. processes Y 1
h , Y 2
h , . . . in Dh such
that X has Dh-excursions Y j
h , j ≤κh. Since κh is the number of the ﬁrst
inﬁnite excursion, we note in particular that κh is geometrically distributed
with mean q−1
h , where qh is the probability that Y 1
h is inﬁnite.
✷
Now put ˆh = inf{h > 0; κh = 0 a.s.}.
For any h ∈(0, ˆh) we have
κh ≥1 a.s., and we may deﬁne νh as the distribution of the ﬁrst excursion
in Dh. The next result shows how the νh can be combined into a single
measure ν on D0, the so-called excursion law of X. For convenience we write
ν[ · |A] = ν(· ∩A)/νA whenever 0 < νA < ∞.
Lemma 19.10 (excursion law, Itˆo) There exists a measure ν on D0, unique
up to a normalization, such that νDh ∈(0, ∞) and νh = ν[ · |Dh] for all
h ∈(0, ˆh). Furthermore, ν is bounded iﬀthe recurrence time is a.s. positive.
Proof: Fix any h ≤k in (0, ˆh), and let Y 1
h , Y 2
h , . . . be such as in Lemma
19.9. Then the ﬁrst Dk-excursion is the ﬁrst element Y j
h in Dk, and since the
Y j
h are i.i.d. νh, we have
νk = νh[ · |Dk],
0 < h ≤k < ˆh.
(14)
Now ﬁx a k ∈(0, ˆh) and deﬁne ˜νh = νh/νhDk, h ∈(0, k]. Then (14) yields
˜νh′ = ˜νh(· ∩Dh′) for any h ≤h′ ≤k, and so ˜νh increases as h →0 toward a
measure ν with ν(· ∩Dh) = ˜νh for all h ≤k. For any h ∈(0, ˆh) we get
ν[ · |Dh] = ˜νh∧k[ · |Dh] = νh∧k[ · |Dh] = νh.
If ν′ is another measure with the stated property, then
ν(· ∩Dh)
νDk
=
νh
νhDk
= ν′(· ∩Dh)
ν′Dk
,
h ≤k < ˆh.
As h →0 for ﬁxed k, we get ν = rν′ with r = νDk/ν′Dk.
If the recurrence time is positive, then (14) remains true for h = 0, and
we may take ν = ν0. Otherwise, let h ≤k in (0, ˆh), and denote by κh,k the
number of Dh-excursions up to the ﬁrst completed excursion in Dk. For ﬁxed
k we have κh,k →∞a.s. as h →0, since Z is perfect and nowhere dense.
Now κh,k is geometrically distributed with mean
Eκh,k = (νhDk)−1 = (ν[Dk|Dh])−1 = νDh/νDk,
and so νDh →∞. Thus, ν is unbounded.
✷

358
Foundations of Modern Probability
When the regenerative set Z has a.s. only isolated points, then Lemma
19.9 already gives a complete description of the excursion structure. In the
complementary case when Z is a.s. perfect, we have the following fundamental
representation in terms of a local time process L and an associated Poisson
point process ξ, both of which are obtainable directly from the array of
holding times and excursions.
Theorem 19.11 (excursion local time and Poisson process, L´evy, Itˆo) Let
X be regenerative at a and such that the closure of Z = {t; Xt = a} is a.s.
perfect. Then there exist a nondecreasing, continuous, adapted process L on
R+, a.s. with support Z, and a Poisson process ξ on R+ × D0 with intensity
measure of the form λ ⊗ν such that Z · λ = cL a.s. for some constant c ≥0
and the excursions of X with associated L-values are given by the restriction
of ξ to [0, L∞]. Moreover, the product νL is a.s. unique.
Proof (beginning): If Eγ = c > 0, we may deﬁne ν = ν0/c and introduce
a Poisson process ξ on R+ × D0 with intensity measure λ ⊗ν. Let the points
of ξ be (σj, ˜Yj), j ∈N, and put σ0 = 0. By Proposition 10.17 the diﬀerences
˜γj = σj −σj−1 are independent and exponentially distributed with mean c.
Furthermore, by Proposition 10.6 the processes ˜Yj are independent of the σj
and i.i.d. ν0. Letting ˜κ be the ﬁrst index j such that ˜Yj is inﬁnite, it is seen
from Lemmas 19.8 and 19.9 that
{γj, Yj; j ≤κ} d= {˜γj, ˜Yj; j ≤˜κ},
(15)
where the quantities on the left are the holding times and subsequent excur-
sions of X. By Theorem 5.10 we may redeﬁne ξ such that (15) holds a.s.
The stated conditions then become fulﬁlled with L = Z · λ.
Turning to the case when Eγ = 0, we may deﬁne ν as in Lemma 19.10
and let ξ be Poisson λ ⊗ν, as before. For any h ∈(0, ˆh), the points of ξ in
R+ × Dh may be enumerated from the left as (σj
h, ˜Y j
h ), j ∈N, and we deﬁne
˜κh as the ﬁrst index j such that ˜Y j
h is inﬁnite. The processes ˜Y j
h are clearly
i.i.d. νh, and so by Lemma 19.9 we have
{Y j
h ; j ≤κh} d= {˜Y j
h ; j ≤˜κh},
h ∈(0, ˆh).
(16)
Since longer excursions form subarrays, the entire collections in (16) have
the same ﬁnite-dimensional distributions, and by Theorem 5.10 we may then
redeﬁne ξ such that all relations hold a.s.
Let τ j
h be the right endpoint of the jth excursion in Dh, and deﬁne
Lt = inf{σj
h; h, j > 0, τ j
h ≥t},
t ≥0.
We need the obvious facts that, for any t ≥0 and h, j > 0,
Lt < σj
h
⇒
t ≤τ j
h
⇒
Lt ≤σj
h.
(17)

19. Local Time, Excursions, and Additive Functionals
359
To see that L is a.s. continuous, we may assume that (16) holds identically.
Since ν is inﬁnite, we may further assume the set {σj
h; h, j > 0} to be dense
in the interval [0, L∞]. If ∆Lt > 0, there exist some i, j, h > 0 with Lt−<
σi
h < σj
h < Lt+. By (17) we get t−ε ≤τ i
h < τ j
h ≤t+ε for every ε > 0, which
is impossible. Thus, ∆Lt = 0 for all t.
To prove that Z ⊂supp L a.s., we may further assume Zω to be per-
fect and nowhere dense for each ω ∈Ω. If t ∈Z, then for every ε > 0
there exist some i, j, h > 0 with t −ε < τ i
h < τ j
h < t + ε, and by (17) we
get Lt−ε ≤σi
h < σj
h ≤Lt+ε. Thus, Lt−ε < Lt+ε for all ε > 0, so t ∈supp L. ✷
In the perfect case it remains to establish the a.s. relation Z · λ = cL for
a suitable c and to show that L is unique and adapted. To avoid repetition,
we postpone the proof of the former result until Theorem 19.13. The latter
statements are immediate consequences of the following result, which also
suggests many explicit constructions of L. Let ηtA denote the number of
excursions in a set A ∈D0 completed at time t ≥0. Note that η is an
adapted, measure-valued process on D0.
Proposition 19.12 (approximation) If A1, A2, . . . ∈D0 with ∞> νAn →
∞, then
sup
t≤u

ηtAn
νAn
−Lt

P→0,
u ≥0.
(18)
The convergence holds a.s. when the An are nested.
In particular, ηtDh/νDh →Lt a.s. as h →0 for ﬁxed t. Thus, L is a.s.
determined by the regenerative set Z.
Proof: Let ξ be such as in Theorem 19.11, and put ξs = ξ([0, s]×·). First
assume that the An are nested. For any s ≥0 we note that (ξsAn) d= (Ns νAn),
where N is a unit-rate Poisson process on R+. Since t−1Nt →1 a.s. by the
law of large numbers and the monotonicity of N, we get
ξsAn
νAn
→s a.s.,
s ≥0.
(19)
Just as in case of Proposition 3.24, we may strengthen (19) to
sup
s≤r

ξsAn
νAn
−s
 →0 a.s.,
r ≥0.
Without the nestedness assumption, the distributions on the left are the same
for ﬁxed n, and the convergence remains valid in probability. In both cases
we may clearly replace r by any positive random variable. Relation (18) now
follows, as we note that ξLt−≤ηt ≤ξLt for all t ≥0 and use the continuity
of L.
✷

360
Foundations of Modern Probability
The excursion local time L is described most conveniently in terms of its
right-continuous inverse
Ts = L−1
s
= inf{t ≥0; Lt > s},
s ≥0.
To state the next result, we may introduce the subset Z′ ⊂Z, obtained from
Z by omission of all points that are isolated from the right. Let us further
write l(u) for the length of an excursion path u ∈D0.
Theorem 19.13 (inverse local time) Let L, ξ, ν, and c be such as in The-
orem 19.11. Then T = L−1 is a generalized subordinator with characteristics
(c, ν ◦l−1) and a.s. range Z′ in R+, given a.s. by
Ts = cs +

 s+
0

l(u)ξ(dr du),
s ≥0.
(20)
Proof: We may clearly discard the null set where L is not continuous with
support Z. If Ts < ∞for some s ≥0, then Ts ∈supp L = Z by the deﬁnition
of T, and since L is continuous we get Ts ̸∈Z \Z′. Thus, T(R+) ⊂Z′ ∪{∞}
a.s. Conversely, assume that t ∈Z′. Then for any ε > 0 we have Lt+ε > Lt,
and so t ≤T ◦Lt ≤t + ε. As ε →0, we get T ◦Lt = t. Thus, Z′ ⊂T(R+)
a.s.
For each s ≥0 the time Ts is optional by Lemma 6.6. Furthermore, it is
clear from Proposition 19.12 that, as long as Ts < ∞, the process θsT −Ts
is obtainable from X ◦θTs by a measurable mapping that is independent of
s. By the regenerative property and Lemma 13.11, the process T is then
a generalized subordinator, and in particular it admits a representation as
in Theorem 13.4. Since the jumps of T agree with the lengths of the ex-
cursion intervals, we obtain (20) for a suitable c ≥0. By Lemma 1.22 the
double integral in (20) equals
 x(ξs ◦l−1)(dx), and so T has L´evy measure
E(ξ1 ◦l−1)= ν ◦l−1.
Substituting s = Lt into (20), we get a.s. for any t ∈Z′
t = T ◦Lt = cLt +

 Lt+
0

l(u)ξ(dr du) = cLt + (Zc · λ)t.
Hence, cLt = (Z · λ)t a.s., which extends by continuity to arbitrary t ≥0. ✷
To justify our terminology, we shall prove that the semimartingale and
excursion local times agree whenever both exist.
Proposition 19.14 (reconciliation) Let X be a continuous semimartingale
in R, which is regenerative at some point a ∈R with P{La
∞̸= 0} > 0. Then
the set Z = {t; Xt = a} is a.s. perfect and nowhere dense, and La is a version
of the excursion local time at a.

19. Local Time, Excursions, and Additive Functionals
361
Proof: By Theorem 19.1 the state a is nonabsorbing, and so Z is nowhere
dense by Lemma 19.8. Since P{La
∞̸= 0} > 0 and La is a.s. continuous
with support in Z, Proposition 19.7 shows that Z is a.s. perfect.
Let L
be a version of the excursion local time at a, and put T = L−1.
Deﬁne
Ys = La ◦Ts for s < L∞, and let Ys = ∞otherwise. By the continuity of
La we have Ys± = La ◦Ts± for every s < L∞. If ∆Ts > 0, we note that
La ◦Ts−= La ◦Ts, since (Ts−, Ts) is an excursion interval of X and La is
continuous with support in Z. Thus, Y is a.s. continuous on [0, L∞).
By Corollary 19.6 and Proposition 19.12 the process θsY −Ys is obtainable
from θTsX through the same measurable mapping for all s < L∞. By the
regenerative property and Lemma 13.11 it follows that Y is a generalized
subordinator, so by Theorem 13.4 and the continuity of Y there exists some
c ≥0 with Ys ≡cs a.s. on [0, L∞). For t ∈Z′ we have a.s. T ◦Lt = t, and
therefore
La
t = La ◦(T ◦Lt) = (La ◦T) ◦Lt = cLt.
This extends to R+ since both extremes are continuous with support in Z. ✷
For Brownian motion it is convenient to normalize local time according
to Tanaka’s formula, which leads to a corresponding normalization of the
excursion law ν. By the spatial homogeneity of Brownian motion, we may
restrict our attention to excursions from 0. The next result shows that ex-
cursions of diﬀerent length have the same distribution apart from a scaling.
For a precise statement, we may introduce the scaling operators Sr on D,
given by
(Srf)t = r1/2ft/r,
t ≥0, r > 0, f ∈D.
Theorem 19.15 (Brownian excursion) Let ν be the normalized excursion
law of Brownian motion. Then there exists a unique distribution ˆν on the
set of excursions of unit length such that
ν = (2π)−1/2

 ∞
0 (ˆν ◦S−1
r )r−3/2dr.
(21)
Proof: By Theorem 19.13 the inverse local time L−1 is a subordinator
with L´evy measure ν ◦l−1, where l(u) denotes the length of u. Furthermore,
L
d= M by Corollary 19.3, where Mt = sups≤t Bs, so by Theorem 13.10 the
measure ν ◦l−1 has density (2π)−1/2r−3/2, r > 0. As in Theorem 5.3, there
exists a probability kernel (νr) from (0, ∞) to D0 such that νr ◦l−1 ≡δr and
ν = (2π)−1/2

 ∞
0
νrr−3/2dr,
(22)
and we note that the measures νr are unique a.e. λ.
For any r > 0 the process ˜B = SrB is again a Brownian motion, and by
Corollary 19.6 the local time of ˜B equals ˜L = SrL. If B has an excursion
u ending at time t, then the corresponding excursion Sru of ˜B ends at rt,

362
Foundations of Modern Probability
and the local time for ˜B at the new excursion equals ˜Lrt = r1/2Lt. Thus, the
excursion process ˜ξ for ˜B is obtained from the process ξ for B through the
mapping Tr : (s, u) →(r1/2s, Sru). Since ˜ξ
d= ξ, each Tr leaves the intensity
measure λ ⊗ν invariant, and we get
ν ◦S−1
r
= r1/2ν,
r > 0.
(23)
Combining (22) and (23), we get for any r > 0

 ∞
0 (νx ◦S−1
r )x−3/2dx = r1/2

 ∞
0
νxx−3/2dx =

 ∞
0
νrxx−3/2dx,
and by the uniqueness in (22) we obtain
νx ◦S−1
r
= νrx,
x > 0 a.e. λ, r > 0.
By Fubini’s theorem, we may then ﬁx an x = c > 0 such that
νc ◦S−1
r
= νcr,
r > 0 a.s. λ.
Deﬁne ˆν = νc ◦S−1
1/c, and conclude that for almost every r > 0
νr = νc(r/c) = νc ◦S−1
r/c = νc ◦S−1
1/c ◦S−1
r
= ˆν ◦S−1
r .
Substituting this into (22) yields equation (21).
If µ is another probability measure with the stated properties, then for
almost every r > 0 we have µ ◦S−1
r
= ˆν ◦S−1
r
and hence
µ = µ ◦S−1
r
◦S−1
1/r = ˆν ◦S−1
r
◦S−1
1/r = ˆν.
Thus, ˆν is unique.
✷
By continuity of paths, an excursion of Brownian motion is either positive
or negative, and by symmetry the two possibilities have the same probability
1
2 under ˆν. This leads to the further decomposition ˆν = 1
2(ˆν++ˆν−). A process
with distribution ˆν+ is called a (normalized) Brownian excursion.
For subsequent needs we shall make a simple computation.
Lemma 19.16 (height distribution) Let ν be the excursion law of Brownian
motion. Then
ν{u ∈D0; suptut > h} = (2h)−1,
h > 0.
Proof: By Tanaka’s formula the process M = 2B ∨0−L0 = B +|B|−L0
is a martingale, and so we get for τ = inf{t ≥0; Bt = h}
E L0
τ∧t = 2E(Bτ∧t ∨0),
t ≥0.
Hence, by monotone and dominated convergence EL0
τ = 2E(Bτ ∨0) = 2h.
On the other hand, Theorem 19.11 shows that L0
τ is exponentially distributed
with mean (νAh)−1, where Ah = {u; supt ut ≥h}.
✷
The following result gives some remarkably precise information about the
spatial behavior of Brownian local time.

19. Local Time, Excursions, and Additive Functionals
363
Theorem 19.17 (space dependence, Ray, Knight) Let L be the local time
of Brownian motion B, and deﬁne τ = inf{t > 0; Bt = 1}. Then the process
St = L1−t
τ
, t ∈[0, 1], is a squared Bessel process of order 2.
Several proofs are known. Here we shall derive the result as an applica-
tion of the previously developed excursion theory.
Proof (Walsh): Fix any u ∈[0, 1], put σ = Lu
τ, and let ξ± denote the
Poisson processes of positive and negative excursions from u. Write Y for
the process B, stopped when it ﬁrst hits u. Then Y ⊥⊥(ξ+, ξ−) and ξ+⊥⊥ξ−,
so ξ+⊥⊥(ξ−, Y ). Since σ is ξ+-measurable, we obtain ξ+⊥⊥σ(ξ−, Y ) and hence
ξ+
σ ⊥⊥σ(ξ−
σ , Y ), which implies the Markov property of Lx
τ at x = u.
To derive the corresponding transition kernels, ﬁx any x ∈[0, u) and
write h = u−x. Put τ0 = 0, and let τ1, τ2, . . . be the right endpoints of those
excursions from x that reach u. Next deﬁne ζk = Lx
τk+1 −Lx
τk, k ≥0, so that
Lx
τ = ζ0 + · · · + ζκ with κ = sup{k; τk ≤τ}. By Lemma 19.16 the variables
ζk are i.i.d. and exponentially distributed with mean 2h. Since κ agrees with
the number of completed u-excursions before time τ that reach x and since
σ⊥⊥ξ−, it is further seen that κ is conditionally Poisson σ/2h, given σ.
We shall also need the fact that (σ, κ)⊥⊥(ζ0, ζ1, . . .). To see this, deﬁne
σk = Lu
τk.
Since ξ−is Poisson, we note that (σ1, σ2, . . .)⊥⊥(ζ1, ζ2, . . .), so
(σ, σ1, σ2, . . .)⊥⊥(Y, ζ1, ζ2, . . .). The desired relation now follows, since κ is a
measurable function of (σ, σ1, σ2, . . .) and ζ0 depends measurably on Y .
For any s ≥0 we may now compute
E

e−sLu−h
τ
 σ

=
E

Ee−sζ0κ+1 σ

= E

(1 + 2sh)−κ−1 σ

=
(1 + 2sh)−1 exp
 −sσ
1 + 2sh

.
In combination with the Markov property of Lx
τ, the last relation is equiva-
lent, via the substitutions u = 1 −t and 2s = (a −t)−1, to the martingale
property of the process
Mt = (a −t)−1 exp
 −L1−t
τ
2(a −t)

,
t ∈[0, a),
(24)
for arbitrary a > 0.
Now let X be a squared Bessel process of order 2, and note that L1
τ =
X0 = 0 by Theorem 19.4. Even X is Markov by Corollary 11.12, and to see
that X has the same transition kernel as L1−t
τ
, it is enough to show for an
arbitrary a > 0 that the process M in (24) remains a martingale when L1−t
τ
is replaced by Xt. This is easily veriﬁed by means of Itˆo’s formula if we note
that X is a weak solution to the SDE dXt = 2X1/2
t
dBt + 2dt.
✷
As an important application of the last result, we may show that the local
time is strictly positive on the range of the process.

364
Foundations of Modern Probability
Corollary 19.18 (range and support) For any continuous local martingale
M with local time L, we have outside a ﬁxed P-null set
{Lx
t > 0} =

infs≤tMs < x < sups≤tMs

,
x ∈R, t ≥0.
(25)
Proof: By Corollary 19.6 and the continuity of L, we have Lx
t = 0 for x
outside the interval in (25), except on a ﬁxed P-null set. To see that Lx
t > 0
otherwise, we may reduce by Theorem 16.3 and Corollary 19.6 to the case
when M is a Brownian motion B. Letting τu = inf{t ≥0; Bt = u}, it is seen
from Theorems 16.6 (i) and 18.16 that, outside a ﬁxed P-null set,
Lx
τu > 0,
0 ≤x < u ∈Q+.
(26)
If 0 ≤x < sups≤t Bs for some t and x, there exists some u ∈Q+ with
x < u < sups≤t Bs. But then τu < t, and (26) yields Lx
t ≥Lx
τu > 0. A similar
argument applies to the case when infs≤t Bs < x ≤0.
✷
Our third approach to local times is via additive functionals and their
potentials. To introduce those, consider a canonical Feller process X with
state space S, associated terminal time ζ, probability measures Px, transition
operators Tt, shift operators θt, and ﬁltration F. By a continuous additive
functional (CAF) of X we mean a nondecreasing, continuous, adapted pro-
cess A with A0 = 0 and Aζ∨t ≡Aζ, and such that
As+t = As + At ◦θs a.s.,
s, t ≥0,
(27)
where a.s. without qualiﬁcation means Px-a.s. for every x. By the continuity
of A, we may choose the exceptional null set to be independent of t. If it can
also be taken to be independent of s, then A is said to be perfect.
For a simple example, let f ≥0 be a bounded, measurable function on
S, and consider the associated elementary CAF
At =

 t
0 f(Xs)ds,
t ≥0.
(28)
More generally, given any CAF A and a function f as above, we may deﬁne
a new CAF f · A by (f · A)t =

s≤t f(Xs)dAs, t ≥0. A less trivial example is
given by the local time of X at a ﬁxed point x, whenever it exists in either
sense discussed earlier.
For any CAF A and constant α ≥0, we may introduce the associated
α-potential
U α
A(x) = Ex

 ∞
0
e−αtdAt,
x ∈S,
and put U α
Af = U α
f·A. In the special case when At ≡t∧ζ, we shall often write
U αf = U α
Af. Note in particular that U α
A = U αf = Rαf when A is given by
(28). If α = 0, we may omit the superscript and write U = U 0 and UA = U 0
A.
The next result shows that a CAF is determined by its α-potential whenever
the latter is ﬁnite.

19. Local Time, Excursions, and Additive Functionals
365
Lemma 19.19 (uniqueness) Let A and B be CAFs of some Feller process
X such that U α
A = U α
B < ∞for some α ≥0. Then A = B a.s.
Proof: Deﬁne Aα
t =

s≤t e−αsdAs, and conclude from (27) and the Markov
property at t that, for any x ∈S,
Ex[Aα
∞|Ft] −Aα
t = e−αtEx[Aα
∞◦θt|Ft] = e−αtU α
A(Xt).
(29)
Comparing with the same relation for B, it follows that Aα−Bα is a continu-
ous Px-martingale of ﬁnite variation, and so Aα = Bα a.s. Px by Proposition
15.2. Since x was arbitrary, we get A = B a.s.
✷
Given any CAF A of Brownian motion in Rd, we may introduce the
associated Revuz measure νA, given for any measurable function g ≥0 on Rd
by νAg = E(g · A)1, where E =
 Exdx. When A is given by (28), we get in
particular νAg = ⟨f, g⟩, where ⟨·, ·⟩denotes the inner product in L2(Rd). In
general, we need to prove that νA is σ-ﬁnite.
Lemma 19.20 (σ-ﬁniteness) For any CAF A of Brownian motion in Rd,
the associated Revuz measure νA is σ-ﬁnite.
Proof: Fix any integrable function f > 0 on Rd, and deﬁne
g(x) = Ex

 ∞
0
e−t−Atf(Xt)dt,
x ∈Rd.
Using Corollary 17.19, the additivity of A, and Fubini’s theorem, we get
U 1
Ag(x)
=
Ex

 ∞
0
e−tdAt EXt

 ∞
0
e−s−Asf(Xs)ds
=
Ex

 ∞
0
e−tdAt

 ∞
0
e−s−As◦θtf(Xs+t)ds
=
Ex

 ∞
0
eAtdAt

 ∞
t
e−s−Asf(Xs)ds
=
Ex

 ∞
0
e−s−Asf(Xs)ds

 s
0 eAtdAt
=
Ex

 ∞
0
e−s(1 −e−As)f(Xs)ds ≤E0

 ∞
0
e−sf(Xs + x)ds.
Hence, by Fubini’s theorem
e−1νAg
≤

U 1
Ag(x)dx ≤

dx E0

 ∞
0
e−sf(Xs + x)ds
=
E0

 ∞
0
e−sds

f(Xs + x)dx =

f(x)dx < ∞.
The assertion now follows since g > 0.
✷
Now let pt(x) denote the transition density (2πt)−d/2e−|x|2/2t of Brownian
motion in Rd, and put uα(x) =
 ∞
0 e−αtpt(x)dt. For any measure µ on Rd, we
may introduce the associated α-potential U αµ(x) =
 uα(x −y)µ(dy). The
following result shows that the Revuz measure has the same potential as the
underlying CAF.

366
Foundations of Modern Probability
Theorem 19.21 (α-potentials, Hunt, Revuz) Let A be a CAF of Brownian
motion in Rd with Revuz measure νA. Then U α
A = U ανA for every α ≥0.
Proof: By monotone convergence we may assume that α > 0. By Lemma
19.20 we may choose some positive functions fn ↑1 such that νfn·A1 =
νAfn < ∞for each n, and by dominated convergence we have U α
fn·A ↑U α
A
and U ανfn·A ↑U ανA. Thus, we may further assume that νA is bounded. In
that case, clearly, U α
A < ∞a.e.
Now ﬁx any bounded, continuous function f ≥0 on Rd, and note that
by dominated convergence U αf is again bounded and continuous. Writing
h = n−1 for an arbitrary n ∈N, we get by dominated convergence and the
additivity of A
νAU αf = E

 1
0 U αf(Xs)dAs = lim
n→∞E

j<nU αf(Xjh)Ah ◦θjh.
Noting that the operator U α is self-adjoint and using the Markov property,
we may write the expression on the right as

j<nEU αf(Xjh)EXjhAh = n

U αf(x)ExAhdx = n⟨f, U αE.Ah⟩.
To estimate the function U αE.Ah on the right, it is enough to consider
arguments x such that U α
A(x) < ∞. Using the Markov property of X and
the additivity of A, we get
U αE.Ah(x)
=
Ex

 ∞
0
e−αsEXsAhds = Ex

 ∞
0
e−αs(Ah ◦θs)ds
=
Ex

 ∞
0
e−αs(As+h −As)ds
=
(eαh −1)Ex

 ∞
0
e−αsAsds −eαhEx

 h
0 e−αsAsds. (30)
Integrating by parts gives
Ex

 ∞
0
e−αsAsds = α−1Ex

 ∞
0
e−αtdAt = α−1U α
A(x).
Thus, as n = h−1 →∞, the ﬁrst term on the right of (30) yields in the limit
the contribution ⟨f, U α
A⟩. The second term is negligible, since
⟨f, E.Ah⟩<
⌢EAh = h νA1 →0.
Hence,
⟨U ανA, f⟩= νAU αf = ⟨U α
A, f⟩,
and since f is arbitrary, we obtain U α
A = U ανA a.e.
To extend this to an identity, ﬁx any h > 0 and x ∈Rd.
Using the
additivity of A, the Markov property at h, the a.e. relation, Fubini’s theorem,
and the Chapman–Kolmogorov relation, we get

19. Local Time, Excursions, and Additive Functionals
367
eαhEx

 ∞
h
e−αsdAs
=
Ex

 ∞
0
e−αsdAs ◦θh
=
ExU α
A(Xh) = ExU ανA(Xh)
=

νA(dy)Exuα(Xh −y)
=
eαh

νA(dy)

 ∞
h
e−αsps(x −y)ds.
The required relation U α
A(x) = U ανA(x) now follows by monotone conver-
gence as h →0.
✷
It is now easy to show that a CAF is determined by its Revuz measure.
Corollary 19.22 (uniqueness) If A and B are CAFs of Brownian motion
in Rd with νA = νB, then A = B a.s.
Proof: By Lemma 19.20 we may assume that νA is bounded, so that
U α
A < ∞a.e. for all α > 0. Now νA determines U α
A by Theorem 19.21, and
from the proof of Lemma 19.19 we note that U α
A determines A a.s. Px when-
ever U α
A(x) < ∞. Since Px ◦X−1
h
≪λd for each h > 0, it follows that A ◦θh
is a.s. unique, and it remains to let h →0.
✷
We turn to the reverse problem of constructing a CAF associated with a
given potential. To motivate the following deﬁnition, we may take expected
values in (29) to get e−αtTtU α
A ≤U α
A.
A function f on S is said to be
uniformly α-excessive if it is bounded and measurable with 0 ≤e−αtTtf ≤f
for all t ≥0 and such that ∥Ttf −f∥→0 as t →0, where ∥· ∥denotes the
supremum norm.
Theorem 19.23 (excessive functions and CAFs, Volkonsky)
Let X be a
Feller process in S, and assume that f : S →R+ is uniformly α-excessive
for some α > 0. Then there exists an a.s. unique perfect CAF A of X with
U α
A = f.
Proof: For any bounded, measurable function g on S, we get by Fubini’s
theorem and the Markov property of X
1
2Ex


 ∞
0
e−αtg(Xt)dt

2
= Ex

 ∞
0
e−αtg(Xt)dt

 ∞
0
e−α(t+h)g(Xt+h)dh
=
Ex

 ∞
0
e−2αtg(Xt)dt

 ∞
0
e−αhThg(Xt)dh
=
Ex

 ∞
0
e−2αtgU αg(Xt)dt =

 ∞
0
e−2αtTtgU αg(x)dt
≤
∥U αg∥

 ∞
0
e−αtTt|g|(x)dt ≤∥U αg∥∥U α|g|∥.
(31)
Now introduce for each h > 0 the bounded, nonnegative functions

368
Foundations of Modern Probability
gh
=
h−1(f −e−αhThf),
fh
=
U αgh = h−1

 h
0 e−αsTsfds,
and deﬁne
Ah(t)
=

 t
0 gh(Xs)ds,
Mh(t)
=
Aα
h(t) + e−αtfh(Xt).
As in (29), we note that the processes Mh are martingales under Px for every
x. Using the continuity of the Ah, we get by Proposition 6.16 and (31), for
any x ∈S and as h, k →0,
Ex(Aα
h −Aα
k)∗2
<
⌢
Exsupt∈Q+|Mh(t) −Mk(t)|2 + ∥fh −fk∥2
<
⌢
Ex |Aα
h(∞) −Aα
k(∞)|2 + ∥fh −fk∥2
<
⌢
∥fh −fk∥∥fh + fk∥+ ∥fh −fk∥2 →0.
Hence, there exists some continuous process A independent of x, such that
Ex(Aα
h −Aα)∗2 →0 for every x.
For a suitable sequence hn →0 we have (Aα
hn →Aα)∗→0 a.s. Px for all
x, and it follows easily that A is a.s. a perfect CAF. Taking limits in the re-
lation fh(x) = ExAα
h(∞), we may also note that f(x) = ExAα(∞) = U α
A(x).
Thus, A has α-potential f.
✷
We will now use the last result to construct local times. Let us say that a
CAF A is supported by some set B ⊂S if its set of increase is a.s. contained
in the closure of the set {t ≥0; Xt ∈B}. In particular, a nonzero and
perfect CAF supported by a singleton set {x} is called a local time at x.
This terminology is clearly consistent with our earlier deﬁnitions of local
time. Writing τx = inf{t > 0; Xt = x}, we say that x is regular (for itself)
if τx = 0 a.s. Px. By Proposition 19.7 this holds iﬀPx-a.s. the random set
Zx = {t ≥0; Xt = x} has no isolated points.
Theorem 19.24 (additive functional local time, Blumenthal and Getoor) A
Feller process in S has a local time L at some point a ∈S iﬀa is regular. In
that case L is a.s. unique up to a normalization, and
U 1
L(x) = U 1
L(a)Exe−τa < ∞,
x ∈S.
(32)
Proof: Let L be a local time at a. Comparing with the renewal process
L−1
n , n ∈Z+, it is seen that supx,t Ex(Lt+h −Lt) < ∞for every h > 0, which
implies U 1
L(x) < ∞for all x. By the strong Markov property at τ = τa, we
get for any x ∈S
U 1
L(x)
=
Ex(L1
∞−L1
τ) = Exe−τ(L1
∞◦θτ)
=
Exe−τEaL1
∞= U 1
L(a)Exe−τ,

19. Local Time, Excursions, and Additive Functionals
369
proving (32). The uniqueness assertion now follows by Lemma 19.19.
To prove the existence of L, deﬁne f(x) = Exe−τ, and note that f is
bounded and measurable. Since τ ≤t+τ ◦θt, we may further conclude from
the Markov property at t that, for any x ∈S,
f(x)
=
Exe−τ ≥e−tEx(e−τ ◦θt)
=
e−tExEXte−τ = e−tExf(Xt) = e−tTtf(x).
Noting that σt = t + τ ◦θt is nondecreasing and tends to 0 a.s. Pa as t →0
by the regularity of a, we further obtain
0
≤
f(x) −e−hThf(x)
=
Ex(e−τ −e−σh) ≤Ex(e−τ −e−σh+τ)
=
Exe−τEa(1 −e−σh) ≤Ea(1 −e−σh) →0.
Thus, f is uniformly 1-excessive, and so by Theorem 19.23 there exists a
perfect CAF L with U 1
L = f.
To see that L is supported by the singleton {a}, we may write
Ex(L1
∞−L1
τ) = Exe−τEaL1
∞= Exe−τEae−τ = Exe−τ = ExL1
∞.
Hence, L1
τ = 0 a.s., so Lτ = 0 a.s., and the Markov property yields Lσt = Lt
a.s. for all rational t. Hence, a.s., L has no point of increase outside the
closure of {t ≥0; Xt = a}.
✷
The next result shows that every CAF of one-dimensional Brownian mo-
tion is a unique mixture of local times. Recall that νA denotes the Revuz
measure of the CAF A.
Theorem 19.25 (integral representation, Volkonsky, McKean and Tanaka)
Let X be a Brownian motion in R with local time L. Then a process A is a
CAF of X iﬀit has an a.s. representation
At =

 ∞
−∞Lx
t ν(dx),
t ≥0,
(33)
for some Radon measure ν on R. The latter is then unique and equals νA.
Proof: For any measure ν we may deﬁne an associated process A as in
(33). If ν is locally ﬁnite, it is clear from the continuity of L and by dominated
convergence that A is a.s. continuous, hence a CAF. In the opposite case, we
note that ν is inﬁnite in every neighborhood of some point a ∈R. Under
Pa and for any t > 0, the process Lx
t is further a.s. continuous and strictly
positive near x = a. Hence, At = ∞a.s. Pa, and A fails to be a CAF.
Next, conclude from Fubini’s theorem and Theorem 19.5 that
ELx
1 =

(EyLx
1)dy = E0

Lx−y
1
dy = 1.

370
Foundations of Modern Probability
Since Lx is supported by {x}, we get for any CAF A as in (33)
νAf
=
E(f · A)1 = E

ν(dx)

 1
0 f(Xt)dLx
t
=

f(x)ν(dx)ELx
1 = νf,
which shows that ν = νA.
Now consider an arbitrary CAF A. By Lemma 19.20 there exists some
function f > 0 with νAf < ∞. The process
Bt =

Lx
t νf·A(dx) =

Lx
t f(x)νA(dx),
t ≥0,
is then a CAF with νB = νf·A, and by Corollary 19.22 we get B = f · A a.s.
Thus, A = f −1 · B a.s., and (33) follows.
✷
Exercises
1. Show for any c ∈(0, 1
2) that Brownian local time Lx
t is a.s. H¨older
continuous in x with exponent c, uniformly for bounded x and t.
2. Give a new proof of the relation τ2
d= τ3 in Theorem 11.16, using
Corollary 19.3 and Lemma 11.15.
3. Give an explicit construction of the process X in Theorem 19.11, based
on the Poisson process ξ and the constant c. (Hint: Use Theorem 19.13 to
construct the time scale.)

Chapter 20
One-Dimensional SDEs
and Diﬀusions
Weak existence and uniqueness; pathwise uniqueness and com-
parison; scale function and speed measure; time-change represen-
tation; boundary classiﬁcation; entrance boundaries and Feller
properties; ratio ergodic theorem; recurrence and ergodicity
By a diﬀusion is usually understood a continuous strong Markov process,
sometimes required to possess additional regularity properties. The basic
example of a diﬀusion process is Brownian motion, which was ﬁrst introduced
and studied in Chapter 11.
More general diﬀusions, ﬁrst encountered in
Chapter 17, were studied extensively in Chapter 18 as solutions to suitable
stochastic diﬀerential equations (SDEs). This chapter focuses on the one-
dimensional case, which allows a more detailed analysis. Martingale methods
are used throughout the chapter, and we make essential use of results on
random time-change from Chapters 15 and 16, as well as on local time,
excursions, and additive functionals from Chapter 19.
After considering the Engelbert–Schmidt characterization of weak exis-
tence and uniqueness for the equation dXt = σ(Xt)dBt, we turn to a dis-
cussion of various pathwise uniqueness and comparison results for the cor-
responding equation with drift. Next we proceed to a systematic study of
regular diﬀusions, introduce the notions of scale function and speed measure,
and prove the basic representation of a diﬀusion on a natural scale as a time-
changed Brownian motion. Finally, we characterize the diﬀerent types of
boundary behavior, establish the Feller properties for a suitable extension of
the process, and examine the recurrence and ergodic properties in the various
cases.
To begin with the SDE approach, consider the general one-dimensional
diﬀusion equation (σ, b), given by
dXt = σ(Xt)dBt + b(Xt)dt.
(1)
From Theorem 18.11 we know that if weak existence and uniqueness in law
hold for (1), then the solution process X is a continuous strong Markov
process. It is clearly also a semimartingale.
In Proposition 18.12 we saw how the drift term can sometimes be elimi-
nated through a suitable change of the underlying probability measure. Un-
371

372
Foundations of Modern Probability
der suitable regularity conditions on the coeﬃcients, we may use the alter-
native approach of transforming the state space. Let us then assume that X
solves (1), and put Yt = p(Xt), where p ∈C1 has an absolutely continuous
derivative p′ with density p′′. By the generalized Itˆo formula of Theorem
19.5, we have
dYt
=
p′(Xt)dXt + 1
2p′′(Xt)d[X]t
=
(σp′)(Xt)dBt + ( 1
2σ2p′′ + bp′)(Xt)dt.
Here the drift term vanishes iﬀp solves the ordinary diﬀerential equation
1
2σ2p′′ + bp′ = 0.
(2)
If b/σ2 is locally integrable, then (2) has the explicit solutions
p′(x) = c exp

−2

 x
0 (bσ−2)(u)du

,
x ∈R,
where c is an arbitrary constant. The desired scale function p is then de-
termined up to an aﬃne transformation, and for c > 0 it is strictly increas-
ing with a unique inverse p−1. The mapping by p reduces (1) to the form
dYt = ˜σ(Yt)dBt, where ˜σ = (σp′) ◦p−1. Since the new equation is equivalent,
it is clear that weak or strong existence or uniqueness hold simultaneously
for the two equations.
Assuming that the drift has been removed, we are left with an equation
of the form
dXt = σ(Xt)dBt.
(3)
Here exact criteria for weak existence and uniqueness may be given in terms
of the singularity sets
Sσ
=

x ∈R;

 x+
x−σ−2(y)dy = ∞

,
Nσ
=
{x ∈R; σ(x) = 0}.
Theorem 20.1 (existence and uniqueness, Engelbert and Schmidt) Weak
existence holds for equation (3) with arbitrary initial distribution iﬀSσ ⊂Nσ.
In that case uniqueness in law holds for every initial distribution iﬀSσ = Nσ.
Our proof begins with a lemma, which will also be useful later. Given
any measure ν on R, we may introduce the associated singularity set
Sν = {x ∈R; ν(x−, x+) = ∞}.
If B is a one-dimensional Brownian motion with associated local time L, we
may also introduce the additive functional
As =

Lx
sν(dx),
s ≥0,
(4)

20. One-dimensional SDEs and Diﬀusions
373
Lemma 20.2 (singularity set) Let L be the local time of Brownian motion
B with arbitrary initial distribution, and let A be given by (4) in terms of
some measure ν on R. Then a.s.
inf{s ≥0; As = ∞} = inf{s ≥0; Bs ∈Sν}.
Proof: Fix any t > 0, and let R be the event where Bs /∈Sν on [0, t].
Noting that Lx
t = 0 a.s. for x outside the range B[0, t], we get a.s. on R
At =

 ∞
−∞Lx
t ν(dx) ≤ν(B[0, t]) supxLx
t < ∞
since B[0, t] is compact and Lx
t is a.s. continuous, hence bounded.
Conversely, suppose that Bs ∈Sν for some s < t. To show that At = ∞
a.s. on this event, we may reduce by means the strong Markov property to
the case when B0 = a is nonrandom in Sν. But then La
t > 0 a.s. by Tanaka’s
formula, and so by the continuity of L we get for small enough ε > 0
At =

 ∞
−∞Lx
t ν(dx) ≥ν(a −ε, a + ε)
inf
|x−a|<ε Lx
t = ∞.
✷
Proof of Theorem 20.1: First assume that Sσ ⊂Nσ. To prove the asserted
weak existence, let Y be a Brownian motion with arbitrary initial distribu-
tion µ, and deﬁne ζ = inf{s ≥0; Ys ∈Sσ}. By Lemma 20.2 the additive
functional
As =

 s
0 σ−2(Yr)dr,
s ≥0,
(5)
is continuous and strictly increasing on [0, ζ), and for t > ζ we have At = ∞.
Also note that Aζ = ∞when ζ = ∞, whereas Aζ may be ﬁnite when ζ < ∞.
In the latter case A jumps from Aζ to ∞at time ζ.
Now introduce the inverse
τt = inf{s > 0; As > t},
t ≥0.
(6)
The process τ is clearly continuous and strictly increasing on [0, Aζ], and
for t ≥Aζ we have τt = ζ. Also note that Xt = Yτt is a continuous local
martingale and, moreover,
t = Aτt =

 τt
0
σ−2(Yr)dr =

 t
0 σ−2(Xs)dτs,
t < Aζ.
Hence, for t ≤Aζ
[X]t = τt =

 t
0 σ2(Xs)ds.
(7)
Here both sides remain constant after time Aζ since Sσ ⊂Nσ, and so (7)
remains true for all t ≥0. Hence, Theorem 16.12 yields the existence of a
Brownian motion B satisfying (3), which means that X is a weak solution
with initial distribution µ.

374
Foundations of Modern Probability
To prove the converse implication, assume that weak existence holds for
any initial distribution. To show that Sσ ⊂Nσ, we may ﬁx any x ∈Sσ and
choose a solution X with X0 = x. Since X is a continuous local martingale,
Theorem 16.4 yields Xt = Yτt for some Brownian motion Y starting at x and
some random time-change τ satisfying (7). For A as in (5) and for t ≥0 we
have
Aτt =

 τt
0
σ−2(Yr)dr =

 t
0 σ−2(Xs)dτs =

 t
0 1{σ(Xs) > 0}ds ≤t.
(8)
Since As = ∞for s > 0 by Lemma 20.2, we get τt = 0 a.s., so Xt ≡x a.s.,
and by (7) x ∈Nσ.
Turning to the uniqueness assertion, assume that Nσ ⊂Sσ, and consider a
solution X with initial distribution µ. As before, we may write Xt = Yτt a.s.,
where Y is a Brownian motion with initial distribution µ and τ is a random
time-change satisfying (7). Deﬁne A as in (5), put χ = inf{t ≥0; Xt ∈Sσ},
and note that τχ = ζ ≡inf{s ≥0; Ys ∈Sσ}. Since Nσ ⊂Sσ, we get as in (8)
Aτt =

 τt
0
σ−2(Ys)ds = t,
t ≤χ.
Furthermore, As = ∞for s > ζ by Lemma 20.2, and so (8) implies τt ≤ζ
a.s. for all t, which means that τ remains constant after time χ. Thus, τ and
A are related by (6), so τ and then also X are measurable functions of Y .
Since the distribution of Y depends only on µ, the same thing is true for X,
which proves the asserted uniqueness in law.
To prove the converse, assume that Sσ is a proper subset of Nσ, and
ﬁx any x ∈Nσ \ Sσ. As before, we may construct a solution starting at x
by writing Xt = Yτt, where Y is a Brownian motion starting at x, and τ
is deﬁned as in (6) from the process A in (5). Since x /∈Sσ, Lemma 20.2
gives A0+ < ∞a.s., and so τt > 0 a.s. for t > 0, which shows that X is a.s.
nonconstant. Since x ∈Nσ, (3) has also the trivial solution Xt ≡x. Thus,
uniqueness in law fails for solutions starting at x.
✷
Proceeding with a study of pathwise uniqueness, we return to equation
(1), and let w(σ, ·) denote the modulus of continuity of σ.
Theorem 20.3 (pathwise uniqueness, Skorohod, Yamada and Watanabe)
Let σ and b be bounded, measurable functions on R satisfying

 ε
0 (w(σ, h))−2dh = ∞,
ε > 0,
(9)
and such that b is Lipschitz-continuous or σ ̸= 0. Then pathwise uniqueness
holds for equation (σ, b).
The signiﬁcance of condition (9) is clariﬁed by the following lemma, where
we are writing Lx
t (Y ) for the local time of the semimartingale Y .

20. One-dimensional SDEs and Diﬀusions
375
Lemma 20.4 (local time) Assume that σ satisﬁes (9), and for i = 1, 2 let
Xi solve equation (σ, bi). Then L0(X1 −X2) = 0 a.s.
Proof: Write Y = X1 −X2, Lx
t = Lx
t (Y ), and w(x) = w(σ, |x|). Using
(1) and Theorem 19.5, we get for any t > 0

 ∞
−∞
Lx
t dx
w2
x
=

 t
0
d[Y ]s
(w(Ys))2 =

 t
0
σ(X1
s) −σ(X2
s)
w(X1
s −X2
s)
2
ds ≤t < ∞.
By (1) and the right-continuity of L it follows that L0
t = 0 a.s.
✷
Proof of Theorem 20.3 for σ ̸= 0: By Propositions 18.12 and 18.13 com-
bined with a simple localization argument, we note that uniqueness in law
holds for equation (σ, b) when σ ̸= 0. To prove the pathwise uniqueness,
consider any two solutions X and Y with X0 = Y0 a.s. By Tanaka’s formula,
Lemma 20.4, and equation (σ, b) we get
d(Xt ∨Yt)
=
dXt + d(Yt −Xt)+
=
dXt + 1{Yt > Xt}d(Yt −Xt)
=
1{Yt ≤Xt}dXt + 1{Yt > Xt}dYt
=
σ(Xt ∨Yt)dBt + b(Xt ∨Yt)dt,
which shows that X ∨Y is again a solution. By the uniqueness in law we get
X
d= X ∨Y , and since X ≤X ∨Y , it follows that X = X ∨Y a.s., which
implies Y ≤X a.s. Similarly, X ≤Y a.s.
✷
The assertion for Lipschitz-continuous b is a special case of the following
comparison result.
Theorem 20.5 (comparison, Skorohod, Yamada) Let σ satisfy (9), and ﬁx
two functions b1 ≥b2, at least one of which is Lipschitz-continuous. For
i = 1, 2 let Xi solve equation (σ, bi), and assume that X1
0 ≥X2
0 a.s. Then
X1 ≥X2 a.s.
Proof: By symmetry we may assume that b1 is Lipschitz-continuous.
Since X2
0 ≤X1
0 a.s., we get by Tanaka’s formula and Lemma 20.4
(X2
t −X1
t )+
=

 t
0 1{X2
s > X1
s}

σ(X2
t ) −σ(X1
t )

dBt
+

 t
0 1{X2
s > X1
s}

b2(X2
s) −b1(X1
s)

ds.
Using the martingale property of the ﬁrst term, the Lipschitz continuity of
b1, and the condition b2 ≤b1, it follows that
E(X2
t −X1
t )+
≤
E

 t
0 1{X2
s > X1
s}

b1(X2
s) −b1(X1
s)

ds
<
⌢
E

 t
0 1{X2
s > X1
s}
X2
s −X1
s
 ds
=

 t
0 E(X2
s −X1
s)+ds.

376
Foundations of Modern Probability
By Gronwall’s lemma E(X2
t −X1
t )+ = 0, and hence X2
t ≤X1
t a.s.
✷
Under stronger assumptions on the coeﬃcients, we may strengthen the
conclusion to a strict inequality.
Theorem 20.6 (strict comparison) Let σ be Lipschitz-continuous, and ﬁx
two continuous functions b1 > b2. For i = 1, 2 let Xi solve equation (σ, bi),
and assume that X1
0 ≥X2
0 a.s. Then X1 > X2 on (0, ∞) a.s.
Proof: Since the bi are continuous with b1 > b2, there exists a locally
Lipschitz-continuous function b on R with b1 > b > b2, and by Theorem 18.3
equation (σ, b) has a solution X with X0 = X1
0 ≥X2
0 a.s. It suﬃces to show
that X1 > X > X2 a.s. on (0, ∞), which reduces the discussion to the case
when one of the functions bi is locally Lipschitz. By symmetry we may take
that function to be b1.
By the Lipschitz continuity of σ and b1, we may introduce the continuous
semimartingales
Ut
=

 t
0

b1(X2
s) −b2(X2
s)

ds,
Vt
=

 t
0
σ(X1
s) −σ(X2
s)
X1
s −X2
s
dBs +

 t
0
b1(X1
s) −b1(X2
s)
X1
s −X2
s
ds,
with 0/0 interpreted as 0, and write
d(X1
t −X2
t ) = dUt + (X1
t −X2
t )dVt.
Letting Z = exp(V −1
2[V ]) > 0, we get by Proposition 18.2
X1
t −X2
t = Zt(X1
0 −X2
0) + Zt

 t
0 Z−1
s

b1(X2
s) −b2(X2
s)

ds.
The assertion now follows since X1
0 ≥X2
0 a.s. and b1 > b2.
✷
We turn to a systematic study of one-dimensional diﬀusions. By a diﬀu-
sion on some interval I ⊂R we mean a continuous strong Markov process
taking values in I.
Termination will only be allowed at open end-points
of I.
We deﬁne τy = inf{t ≥0; Xt = y} and say that X is regular if
Px{τy < ∞} > 0 for any x ∈I◦and y ∈I. Let us further write τa,b = τa ∧τb.
Our ﬁrst aim is to transform the general diﬀusion process into a contin-
uous local martingale, using a suitable change of scale. This corresponds to
the removal of drift in the SDE (1).
Theorem 20.7 (scale function, Feller, Dynkin) Given any regular diﬀusion
X on I, there exists a continuous and strictly increasing function p: I →R
such that p(Xτa,b) is a Px-martingale for any a ≤x ≤b in I. Furthermore,
an increasing function p has the stated property iﬀ
Px{τb < τa} = px −pa
pb −pa
,
x ∈[a, b].
(10)

20. One-dimensional SDEs and Diﬀusions
377
A function p with the stated property is called a scale function for X, and
X is said to be on a natural scale if the scale function can be chosen to be
linear. In general, we note that Y = p(X) is a regular diﬀusion on a natural
scale.
We begin our proof with a study of the functions
pa,b(x) = Px{τb < τa},
ha,b(x) = Exτa,b,
a ≤x ≤b,
which play a basic role in the subsequent analysis.
Lemma 20.8 (hitting times) Consider a regular diﬀusion on I, and ﬁx any
a < b in I. Then
(i) pa,b is continuous and strictly increasing on [a, b];
(ii) ha,b is bounded on [a, b].
In particular, it is seen from (ii) that τa,b < ∞a.s. under Px for any
a ≤x ≤b.
Proof: (i) First we show that Px{τb < τa} > 0 for any a < x < b.
Then introduce the optional time σ1 = τa + τx ◦θτa and deﬁne recursively
σn+1 = σn + σ1 ◦θσn. By the strong Markov property the σn form a random
walk in [0, ∞] under each Px. If Px{τb < τa} = 0, we get τb ≥σn →∞a.s.
Px, and so Px{τb = ∞} = 1, which contradicts the regularity of X.
Using the strong Markov property at τy, we next obtain
Px{τb < τa} = Px{τy < τa}Py{τb < τa},
a < x < y < b.
(11)
Since Px{τa < τy} > 0, we have Px{τy < τa} < 1, which shows that Px{τb <
τa} is strictly increasing.
By symmetry it remains to prove that Py{τb < τa} is left-continuous on
(a, b]. By (11) it is equivalent to show for each x ∈(a, b) that the mapping
y →Px{τy < τa} is left-continuous on (x, b]. Then let yn ↑y, and note that
τyn ↑τy a.s. Px by the continuity of X. Hence, {τyn < τa} ↓{τy < τa}, which
implies convergence of the corresponding probabilities.
(ii) Fix any c ∈(a, b). By the regularity of X we may choose h > 0 so
large that
Pc{τa ≤h} ∧Pc{τb ≤h} = δ > 0.
If x ∈(a, c), we may use the strong Markov property at τx to get
δ ≤Pc{τa ≤h} ≤Pc{τx ≤h}Px{τa ≤h} ≤Px{τa ≤h} ≤Px{τa,b ≤h},
and similarly for x ∈(c, b). By the Markov property at h and induction on
n we obtain
Px{τa,b > nh} ≤(1 −δ)n,
x ∈[a, b], n ∈Z+,
and Lemma 2.4 yields
Exτa,b =

 ∞
0
Px{τa,b > t}dt ≤h

n≥0(1 −δ)n < ∞.
✷

378
Foundations of Modern Probability
Proof of Theorem 20.7: Let p be a locally bounded and measurable func-
tion on I such that M = p(Xτa,b) is a martingale under Px for any a < x < b.
Then
px
=
ExM0 = ExM∞= Exp(Xτa,b)
=
paPx{τa < τb} + pbPx{τb < τa}
=
pa + (pb −pa)Px{τb < τa},
and (10) follows, provided that pa ̸= pb.
To construct a function p with the stated properties, ﬁx any points u < v
in I, and deﬁne for arbitrary a ≤u and b ≥v in I
p(x) = pa,b(x) −pa,b(u)
pa,b(v) −pa,b(u),
x ∈[a, b].
(12)
To see that p is independent of a and b, consider any larger interval [a′, b′] in
I, and conclude from the strong Markov property at τa,b that, for x ∈[a, b],
Px{τb′ < τa′} = Px{τa < τb}Pa{τb′ < τa′} + Px{τb < τa}Pb{τb′ < τa′},
or
pa′,b′(x) = pa,b(x)(pa′,b′(b) −pa′,b′(a)) + pa′b′(a).
Thus, pa,b and pa′,b′ agree on [a, b] up to an aﬃne transformation and so give
rise to the same value in (12).
By Lemma 20.8 the constructed function is continuous and strictly in-
creasing, and it remains to show that p(Xτa,b) is a martingale under Px for
any a < b in I. Since the martingale property is preserved by aﬃne transfor-
mations, it is equivalent to show that pa,b(Xτa,b) is a Px-martingale. Then ﬁx
any optional time σ, and write τ = σ ∧τa,b. By the strong Markov property
at τ we get
Expa,b(Xτ)
=
ExPXτ{τb < τa} = Pxθ−1
τ {τb < τa}
=
Px{τb < τa} = pa,b(x),
and the desired martingale property follows by Lemma 6.13.
✷
To prepare for the next result, consider a Brownian motion B in R with
associated jointly continuous local time L. For any measure ν on R, we may
introduce as in (4) the associated additive functional A =
 Lxν(dx) and its
right-continuous inverse
σt = inf{s > 0; As > t},
t ≥0.
If ν ̸= 0, it is clear from the recurrence of B that A is a.s. unbounded, so
σt < ∞a.s. for all t, and we may deﬁne Xt = Bσt, t ≥0. We shall refer to
σ = (σt) as the random time-change based on ν and to the process X = B ◦σ
as the correspondingly time-changed Brownian motion.

20. One-dimensional SDEs and Diﬀusions
379
Theorem 20.9 (speed measure and time-change, Feller, Volkonsky, Itˆo and
McKean)
For any regular diﬀusion on a natural scale in I, there exists
a unique measure ν on I with ν[a, b] ∈(0, ∞) for all a < b in I◦such
that X is a time-changed Brownian motion based on some extension of ν to
¯I. Conversely, any such time-change of Brownian motion deﬁnes a regular
diﬀusion on I.
Here the extended measure ν is called the speed measure of the diﬀusion.
Contrary to what the term might suggest, we note that the process moves
slowly through regions where ν is large. The speed measure of Brownian
motion itself is clearly equal to Lebesgue measure. More generally, the speed
measure of a regular diﬀusion solving equation (3) has density σ−2.
To prove the uniqueness of ν we need the following lemma, which is also
useful for the subsequent classiﬁcation of boundary behavior. Here we shall
write σa,b = inf{s > 0; Bs /∈(a, b)}.
Lemma 20.10 (Green function) Let X be a time-changed Brownian motion
based on ν, ﬁx any measurable function f : I →R+, and let a < b in ¯I. Then
Ex

 τa,b
0
f(Xt)dt =

 b
a ga,b(x, y)f(y)ν(dy),
x ∈[a, b],
(13)
where
ga,b(x, y) = ExLy
σa,b = 2(x ∧y −a)(b −x ∨y)
b −a
,
x, y ∈[a, b].
(14)
If X is recurrent, the statement remains true with a = −∞or b = ∞.
Taking f ≡1 in (13), we get in particular the formula
ha,b(x) = Exτa,b =

 b
a ga,b(x, y)ν(dy),
x ∈[a, b],
(15)
which will be useful later.
Proof: Clearly, τa,b = A(σa,b) for any a, b ∈¯I, and also for a = −∞or
b = ∞when X is recurrent. Since Ly is supported by {y}, it follows by (4)
that

 τa,b
0
f(Xt)dt =

 σa,b
0
f(Bs)dAs =

 b
a f(y)Ly
σa,bν(dy).
Taking expectations gives (13) with ga,b(x, y) = ExLy
σa,b. To prove (14), we
note that by Tanaka’s formula and optional sampling
ExLy
σa,b∧s = Ex|Bσa,b∧s −y| −|x −y|,
s ≥0.
If a and b are ﬁnite, we may let s →∞and conclude by monotone and
dominated convergence that
ga,b(x, y) = (y −a)(b −x)
b −a
+ (b −y)(x −a)
b −a
−|x −y|,

380
Foundations of Modern Probability
which simpliﬁes to (14). The result for inﬁnite a or b follows immediately by
monotone convergence.
✷
The next lemma will enable us to construct the speed measure ν from
the functions ha,b in Lemma 20.8.
Lemma 20.11 (consistency) For any regular diﬀusion on a natural scale
in I, there exists a strictly concave function h on I◦such that for any a < b
in I
ha,b(x) = h(x) −x −a
b −a h(b) −b −x
b −a h(a),
x ∈[a, b].
(16)
Proof: Fix any u < v in I, and deﬁne for any a ≤u and b ≥v in I
h(x) = ha,b(x) −x −u
v −u ha,b(v) −v −x
v −u ha,b(u),
x ∈[a, b].
(17)
To see that h is independent of a and b, consider any larger interval [a′, b′] in
I, and conclude from the strong Markov property at τa,b that, for x ∈[a, b],
Exτa′,b′ = Exτa,b + Px{τa < τb}Eaτa′,b′ + Px{τb < τa}Ebτa′,b′,
or
ha′,b′(x) = ha,b(x) + b −x
b −a ha′,b′(a) + x −a
b −a ha′,b′(b).
(18)
Thus, ha,b and ha′,b′ agree on [a, b] up to an aﬃne function and therefore yield
the same value in (17).
If a ≤u and b ≥v, then (17) shows that h and ha,b agree on [a, b] up to
an aﬃne function, and (16) follows since ha,b(a) = ha,b(b) = 0. The formula
extends by means of (18) to arbitrary a < b in I.
✷
Since h is strictly concave, its left derivative h′
−is strictly decreasing and
left-continuous, and so it determines a measure ν on I◦satisfying
2ν[a, b) = h′
−(a) −h′
−(b),
a < b in I◦.
(19)
For motivation, we note that this expression is consistent with (15).
The proof of Theorem 20.9 requires some understanding of the behavior
of X at the endpoints of I. If an endpoint b does not belong to I, then by
hypothesis the motion terminates when X reaches b. It is clearly equivalent
to attach b to I as an absorbing endpoint. For convenience we may then
assume that I is a compact interval of the form [a, b], where either endpoint
may be inaccessible, in the sense that a.s. it cannot be reached in ﬁnite time
from a point in I◦.
For either endpoint b, the set Zb = {t ≥0; Xt = b} is regenerative under
Pb in the sense of Chapter 19. In particular, it is seen from Lemma 19.8
that b is either absorbing in the sense that Zb = R+ a.s. or reﬂecting in the
sense that Z◦
b = ∅a.s. In the latter case, we say that the reﬂection is fast if

20. One-dimensional SDEs and Diﬀusions
381
λZb = 0 and slow if λZb > 0. A more detailed discussion of the boundary
behavior will be given after the proof of the main theorem.
We shall ﬁrst prove Theorem 20.9 in a special case. The general result
will then be deduced by a pathwise comparison.
Proof of Theorem 20.9 for absorbing endpoints (M´el´eard): Let X have
distribution Px, where x ∈I◦, and put ζ = inf{t > 0; Xt ̸= I◦}. For any
a < b in I◦with x ∈[a, b] the process Xτa,b is a continuous martingale, so by
Theorem 19.5
h(Xt) = h(x) +

 t
0 h′
−(X)dX −

I
˜Lx
t ν(dx),
t ∈[0, ζ),
(20)
where ˜L denotes the local time of X.
Next conclude from Theorem 16.4 that X = B◦[X] a.s. for some Brownian
motion B starting at x. Using Theorem 19.5 twice, we get in particular for
any nonnegative measurable function f

I f(x)˜Lx
t dx =

 t
0 f(Xs)d[X]s =

 [X]t
0
f(Bs)ds =

I f(x)Lx
[X]tdt,
where L denotes the local time of B. Hence, ˜Lx
t = Lx
[X]t a.s. for t < ζ, and
so the last term in (20) equals A[X]t a.s.
For any optional time σ, put τ = σ ∧τa,b, and conclude from the strong
Markov property that
Ex[τ + ha,b(Xτ)]
=
Ex[τ + EXττa,b]
=
Ex[τ + τa,b ◦θτ] = Exτa,b = ha,b(x).
Writing Mt = h(Xt) + t, it follows by Lemma 6.13 that M τa,b is a Px-
martingale whenever x ∈[a, b] ⊂I◦. Comparing with (20) and using Propo-
sition 15.2, we obtain A[X]t = t a.s. for all t ∈[0, ζ). Since A is continuous
and strictly increasing on [0, ζ) with inverse σ, it follows that [X]t = σt a.s.
for t < ζ. The last relation extends to [ζ, ∞), provided that ν is given inﬁnite
mass at each endpoint. Then X = B ◦σ a.s. on R+.
Conversely, it is easily seen that B ◦σ is a regular diﬀusion on I whenever
σ is a random time-change based on some measure ν with the stated proper-
ties. To prove the uniqueness of ν, ﬁx any a < x < b in I◦and apply Lemma
20.10 with f(y) = (ga,b(x, y))−1 to see that ν(a, b) is determined by Px.
✷
Proof of Theorem 20.9, general case: Deﬁne ν on I◦as in (19), and extend
the deﬁnition to ¯I by giving inﬁnite mass to absorbing endpoints. To every
reﬂecting endpoint we attach a ﬁnite mass, to be speciﬁed later. Given a
Brownian motion B, we note as before that the correspondingly time-changed
process ˜X = B ◦σ is a regular diﬀusion on I. Letting ζ = sup{t; Xt ∈I◦}
and ˜ζ = sup{t; ˜Xt ∈I◦}, it is further seen from the previous case that Xζ
and ˜X
˜ζ have the same distribution for any starting position x ∈I◦.

382
Foundations of Modern Probability
Now ﬁx any a < b in I◦, and deﬁne recursively
χ1 = ζ + τa,b ◦θζ;
χn+1 = χn + χ1 ◦θχn,
n ∈N.
The processes Y a,b
n
= Xζ ◦θχn then form a Markov chain in the path space.
A similar construction for ˜X yields some processes ˜Y a,b
n , and we note that
(Y a,b
n )
d= (˜Y a,b
n ) for ﬁxed a and b. Since the processes Y a′,b′
n
for any smaller
interval [a′, b′] can be measurably recovered from those for [a, b] and similarly
for ˜Y a′,b′
n
, it follows that the whole collections (Y a,b
n ) and (˜Y a,b
n ) have the same
distribution. By Theorem 5.10 we may then assume that the two families
agree a.s.
Now assume that I = [a, b], where a is reﬂecting. From the properties
of Brownian motion we note that the level sets Za and ˜Za for X and ˜X
are a.s. perfect. Thus, we may introduce the corresponding excursion point
processes ξ and ˜ξ, local times L and ˜L, and inverse local times T and ˜T.
Since the excursions within [a, b) agree a.s. for X and ˜X, it is clear from the
law of large numbers that we may normalize the excursion laws for the two
processes such that the corresponding parts of ξ and ˜ξ agree a.s. Then even
T and ˜T agree, possibly apart from the lengths of excursions that reach b
and the drift coeﬃcient c in Theorem 19.13. For ˜X the latter is proportional
to the mass ν{a}, which may now be chosen such that c becomes the same
as for X. Note that this choice of ν{a} is independent of starting position x
for the processes X and ˜X.
If the other endpoint b is absorbing, then clearly X = ˜X a.s., and the
proof is complete. If b is instead reﬂecting, then the excursions from b agree
a.s. for X and ˜X. Repeating the previous argument with the roles of a and
b interchanged, we get X = ˜X a.s. after a suitable adjustment of the mass
ν{b}.
✷
We proceed to classify the boundary behavior of a regular diﬀusion on a
natural scale in terms of the speed measure ν. A right endpoint b is called
an entrance boundary for X if b is inaccessible and yet
lim
r→∞inf
y>x Py{τx ≤r} > 0,
x ∈I◦.
(21)
By the Markov property at times nr, n ∈N, the limit in (21) then equals
1. In particular, Py{τx < ∞} = 1 for all x < y in I◦. As we shall see in
Theorem 20.13, an entrance boundary is an endpoint where X may enter but
not exit.
The opposite situation occurs at an exit boundary, which is deﬁned as
an endpoint b that is accessible and yet naturally absorbing, in the sense
that it remains absorbing when the value of ν{b} is changed to zero.
If
b is accessible but not naturally absorbing, we have already seen how the
boundary behavior of X depends on the value of ν{b}. Thus, b in this case
is absorbing when ν{b} = ∞, slowly reﬂecting when ν{b} ∈(0, ∞), and fast

20. One-dimensional SDEs and Diﬀusions
383
reﬂecting when ν{b} = 0. For reﬂecting b it is further clear from Theorem
20.9 that the set Zb = {t ≥0; Xt = b} is a.s. perfect.
Theorem 20.12 (boundary behavior, Feller) Let ν be the speed measure of
a regular diﬀusion on a natural scale in some interval I = [a, b], and ﬁx any
u ∈I◦. Then
(i) b is accessible iﬀit is ﬁnite with
 b
u(b −x)ν(dx) < ∞;
(ii) b is accessible and reﬂecting iﬀit is ﬁnite with ν(u, b] < ∞;
(iii) b is an entrance boundary iﬀit is inﬁnite with
 b
u xν(dx) < ∞.
The stated conditions may be translated into corresponding criteria for
arbitrary regular diﬀusions. In the general case it is clear that exit and other
accessible boundaries may be inﬁnite, whereas entrance boundaries may be
ﬁnite. Explosion is said to occur when X reaches an inﬁnite boundary point
in ﬁnite time. An interesting example of a regular diﬀusion on (0, ∞) with 0
as an entrance boundary is given by the Bessel process Xt = |Bt|, where B
is a Brownian motion in Rd with d ≥2.
Proof of Theorem 20.12: (i) Since lim sups(±Bs) = ∞a.s., Theorem
20.9 shows that X cannot explode, so any accessible endpoint is ﬁnite. Now
assume that a < c < u < b < ∞. Then Lemma 20.8 shows that b is accessible
iﬀhc,b(u) < ∞, which by (15) is equivalent to
 b
u(b −x)ν(dx) < ∞.
(ii) In this case b < ∞by (i), and then Lemma 20.2 shows that b is
absorbing iﬀν(u, b] = ∞.
(iii) An entrance boundary b is inaccessible by deﬁnition, so if a < u < b,
we have τu = τu,b a.s. Arguing as in the proof of Lemma 20.8, we also note
that Eyτu is bounded for y > u. If b < ∞, we obtain the contradiction
Eyτu = hu,b(y) = ∞, so b must be inﬁnite. From (15) we get by monotone
convergence as y →∞
Eyτu = hu,∞(y) = 2

 ∞
u (x ∧y −u)ν(dx) →2

 ∞
u (x −u)ν(dx),
which is ﬁnite iﬀ
 ∞
u xν(dx) < ∞.
✷
We proceed to establish an important regularity property, which also
clariﬁes the nature of entrance boundaries.
Theorem 20.13 (entrance laws and Feller properties) Consider a regular
diﬀusion on some interval I, and form ¯I by attaching the possible entrance
boundaries to I. Then the original diﬀusion can be extended to a continuous
Feller process on ¯I.
Proof: For any f ∈Cb, a, x ∈I, and r, t ≥0, we get by the strong
Markov property at τx ∧r

384
Foundations of Modern Probability
Eaf(Xτx∧r+t)
=
EaTtf(Xτx∧r)
=
Ttf(x)Pa{τx ≤r} + Ea[Ttf(Xr); τx > r].
(22)
To show that Ttf is left-continuous at some y ∈I, ﬁx any a < y in I◦and
choose r > 0 so large that Pa{τy ≤r} > 0. As x ↑y, we have τx ↑τy and
hence {τx ≤r} ↓{τy ≤r}. Thus, the probabilities and expectations in (22)
converge to the corresponding expressions for τy, and we get Ttf(x) →Ttf(y).
The proof of the right-continuity is similar.
If an endpoint b is inaccessible but not of entrance type, and if f(x) →0
as x →b, then clearly even Ttf(x) →0 at b for each t > 0. Now assume that
∞is an entrance boundary, and consider a function f with a ﬁnite limit at
∞. We need to show that even Ttf(x) converges as x →∞for ﬁxed t. Then
conclude from Lemma 20.10 that as a →∞,
sup
x≥a Exτa = 2 sup
x≥a

 ∞
a (x ∧r −a)ν(dr) = 2

 ∞
a (r −a)ν(dr) →0.
(23)
Next we note that, for any a < x < y and r ≥0,
Py{τa ≤r}
≤
Py{τx ≤r, τa −τx ≤r}
=
Py{τx ≤r}Px{τa ≤r} ≤Px{τa ≤r}.
Thus Px ◦τ −1
a
converges vaguely as x →∞for ﬁxed a, and in view of (23)
the convergence holds even in the weak sense.
Now ﬁx any t and f, and introduce for each a the continuous function
ga(s) = Eaf(X(t−s)+). By the strong Markov property at τa ∧t and Theorem
5.4 we get for any x, y ≥a
|Ttf(x) −Ttf(y)| ≤|Exga(τa) −Eyga(τa)| + 2∥f∥(Px + Py){τa > t}.
Here the right-hand side tends to zero as x, y →∞and then a →∞,
because of (23) and the weak convergence of Px◦τ −1
a . Thus, Ttf(x) is Cauchy
convergent as x →∞, and we may denote the limit by Ttf(∞).
It is now easy to check that the extended operators Tt form a Feller semi-
group on C0(¯I). Finally, it is clear from Theorem 17.15 that the associated
process starting at a possible entrance boundary again has a continuous ver-
sion, in the topology of ¯I.
✷
We proceed to establish a ratio ergodic theorem for elementary additive
functionals of a recurrent diﬀusion.
Theorem 20.14 (ratio ergodic theorem, Derman, Motoo and Watanabe) Let
X be a regular, recurrent diﬀusion on a natural scale and with speed measure
ν, and ﬁx two measurable functions f, g : I →R+ with νf < ∞and νg > 0.
Then
lim
t→∞
 t
0 f(Xs)ds
 t
0 g(Xs)ds = νf
νg
a.s. Px,
x ∈I.

20. One-dimensional SDEs and Diﬀusions
385
Proof: Fix any a < b in I, put τ b
a = τb + τa ◦θτb, and deﬁne recursively
the optional times σ0, σ1, . . . by
σn+1 = σn + τ b
a ◦θσn,
n ≥0,
starting with σ0 = τa. Write

 σn
0
f(Xs)ds =

 σ0
0
f(Xs)ds +
n

k=1

 σk
σk−1
f(Xs)ds,
(24)
and note that the terms of the last sum are i.i.d. By the strong Markov
property and Lemma 20.10, we get for any x ∈I
Ex

 σk
σk−1
f(Xs)ds
=
Ea

 τb
0
f(Xs)ds + Eb

 τa
0
f(Xs)ds
=

f(y){g−∞,b(y, a) + ga,∞(y, b)}ν(dy)
=
2

f(y){(b −y ∨a)+ + (y ∧b −a)+}ν(dy)
=
2(b −a)νf.
From the same lemma it is further seen that the ﬁrst term in (24) is a.s.
ﬁnite. Hence, by the law of large numbers
lim
n→∞n−1

 σn
0
f(Xs)ds = 2(b −a)νf a.s. Px,
x ∈I.
Writing κt = sup{n ≥0; σn ≤t}, we get by monotone interpolation
lim
t→∞κ−1
t

 t
0 f(Xs)ds = 2(b −a)νf a.s. Px,
x ∈I.
(25)
This remains true when νf = ∞, since we may then apply (25) to some ap-
proximating functions fn ↑f with νfn < ∞and let n →∞. The assertion
now follows as we apply (25) to both f and g.
✷
We may ﬁnally describe the asymptotic behavior of the process, depend-
ing on the boundedness of the speed measure ν and the nature of the end-
points. It is then convenient ﬁrst to apply an aﬃne mapping that transforms
I◦into one of the intervals (0, 1), (0, ∞), and (∞, ∞). Since ﬁnite endpoints
may be either inaccessible, absorbing, or reﬂecting (represented below by
the brackets (, [, and [[, respectively), we need to distinguish between ten
diﬀerent cases.
A diﬀusion will be called ν-ergodic if it is recurrent and such that Px ◦
X−1
t
w→ν/νI for all x.
Furthermore, a recurrent diﬀusion is said to be
null-recurrent or positive recurrent, depending on whether |Xt|
P→∞or not.
Recall that absorption is said to occur at an endpoint b if Xt = b for all
suﬃciently large t.

386
Foundations of Modern Probability
Theorem 20.15 (recurrence and ergodicity, Feller, Maruyama and Tanaka)
A regular diﬀusion on a natural scale and with speed measure ν has the
following ergodic behavior, depending on starting position x and the nature
of the boundaries:
(−∞, ∞): ν-ergodic if ν is bounded, otherwise null-recurrent;
(0, ∞): converges to 0 a.s.;
[0, ∞): absorbed at 0 a.s.;
[[0, ∞): ν-ergodic if ν is bounded, otherwise null-recurrent;
(0, 1): converges to 0 or 1 with probabilities 1 −x and x, respectively;
[0, 1): absorbed at 0 or converges to 1 with probabilities 1 −x and x,
respectively;
[0, 1]: absorbed at 0 or 1 with probabilities 1 −x and x, respectively;
[[0, 1): converges to 1 a.s.;
[[0, 1]: absorbed at 1 a.s.;
[[0, 1]]: ν-ergodic.
We begin our proof with the relatively elementary recurrence properties,
which distinguish between the possibilities of absorption, convergence, and
recurrence.
Proof of recurrence properties:
[0, 1]: Relation (10) yields Px{τ0 < ∞} = 1 −x and Px{τ1 < ∞} = x.
[0, ∞): By (10) we have for any b > x
Px{τ0 < ∞} ≥Px{τ0 < τb} = (b −x)/b,
which tends to 1 as b →∞.
(−∞, ∞): The recurrence follows from the previous case.
[[0, ∞): Since 0 is reﬂecting, we have P0{τy < ∞} > 0 for some y > 0.
By the strong Markov property and the regularity of X, this extends to
arbitrary y. Arguing as in the proof of Lemma 20.8, we may conclude that
P0{τy < ∞} = 1 for all y > 0. The asserted recurrence now follows, as we
combine with the statement for [0, ∞).
(0, ∞): In this case X = B ◦[X] a.s. for some Brownian motion B.
Since X > 0, we have [X]∞< ∞a.s., and therefore X converges a.s. Now
Py{τa,b < ∞} = 1 for any 0 < a ≤y ≤b, so applying the Markov property at
an arbitrary time t > 0, we get a.s. either lim inft Xt ≤a or lim supt Xt ≥b.
Since a and b are arbitrary, it follows that X∞is an endpoint of (0, ∞) and
hence equals 0.
(0, 1): Arguing as in the previous case, we get a.s. convergence to either
0 or 1. To ﬁnd the corresponding probabilities, we conclude from (10) that
Px{τa < ∞} ≥Px{τa < τb} = b −x
b −a,
0 < a < x < b < 1.

20. One-dimensional SDEs and Diﬀusions
387
Letting b →1 and then a →0, we obtain Px{X∞= 0} ≥1 −x. Similarly,
Px{X∞= 1} ≥x, and so equality holds in both relations.
[0, 1): Again X converges to either 0 or 1 with probabilities 1 −x and x,
respectively. Furthermore, we note that
Px{τ0 < ∞} ≥Px{τ0 < τb} = (b −x)/b,
0 ≤x < b < 1,
which tends to 1−x as b →1. Thus, X gets absorbed when it approaches 0.
[[0, 1]]: Arguing as in the previous case, we get P0{τ1 < ∞} = 1, and by
symmetry we also have P1{τ0 < ∞} = 1.
[[0, 1]: Again we get P0{τ1 < ∞} = 1, so the same relation holds for Px.
[[0, 1): As before, we get P0{τb < ∞} = 1 for all b ∈(0, 1). By the strong
Markov property at τb and the result for [0, 1) it follows that P0{Xt →1} ≥b.
Letting b →1, we obtain Xt →1 a.s. under P0. The result for Px now follows
by the strong Markov property at τx, applied under P0.
✷
We shall prove the ergodic properties along the lines of Theorem 7.18,
which requires some additional lemmas.
Lemma 20.16 (coupling)
If X and Y are independent Feller processes,
then the pair (X, Y ) is again Feller.
Proof: Use Theorem 3.29 and Lemma 17.3.
✷
The next result is a continuous-time counterpart of Lemma 7.20.
Lemma 20.17 (strong ergodicity) For a regular, recurrent diﬀusion and for
arbitrary initial distributions µ1 and µ2, we have
lim
t→∞∥Pµ1 ◦θ−1
t
−Pµ2 ◦θ−1
t ∥= 0.
Proof: Let X and Y be independent with distributions Pµ1 and Pµ2,
respectively. By Theorem 20.13 and Lemma 20.16 the pair (X, Y ) can be
extended to a Feller diﬀusion, so by Theorem 17.17 it is again strong Markov
with respect to the induced ﬁltration G. Deﬁne τ = inf{t ≥0; Xt = Yt},
and note that τ is G-optional by Lemma 6.6. The assertion now follows as
in case of Lemma 7.20, provided we can show that τ < ∞a.s.
To see this, assume ﬁrst that I = R. The processes X and Y are then
continuous local martingales. By independence they remain local martingales
for the extended ﬁltration G, and so even X −Y is a local G-martingale.
Using the independence and recurrence of X and Y , we get [X −Y ]∞=
[X]∞+ [Y ]∞= ∞a.s., which shows that even X −Y is recurrent.
In
particular, τ < ∞a.s.
Next let I = [[0, ∞) or [[0, 1]], and deﬁne τ1 = inf{t ≥0; Xt = 0} and
τ2 = inf{t ≥0; Yt = 0}. By the continuity and recurrence of X and Y , we
get τ ≤τ1 ∨τ2 < ∞a.s.
✷
Our next result is similar to the discrete-time version in Lemma 7.21.

388
Foundations of Modern Probability
Lemma 20.18 (existence) Any regular, positive recurrent diﬀusion has an
invariant distribution.
Proof: By Theorem 20.13 we may regard the transition kernels µt with
associated operators Tt as deﬁned on ¯I, the interval I with possible entrance
boundaries adjoined. Since X is not null recurrent, we may choose a bounded
Borel set B and some x0 ∈I and tn →∞such that infn µtn(x0, B) > 0. By
Theorem 4.19 there exists some measure µ on ¯I with µI > 0 such that
µtn(x0, ·)
v→µ along a subsequence, in the topology of ¯I. The convergence
extends by Lemma 20.17 to arbitrary x ∈I, and so
Ttnf(x) →µf,
f ∈C0(¯I), x ∈I.
(26)
Now ﬁx any h ≥0 and f ∈C0(¯I), and note that even Thf ∈C0(¯I) by
Theorem 20.13. Using (26), the semigroup property, and dominated conver-
gence, we get for any x ∈I
µ(Thf) ←Ttn(Thf)(x) = Th(Ttnf)(x) →µf.
Thus, µµh = µ for all h, which means that µ is invariant on ¯I. In particular,
µ(¯I \ I) = 0 by the nature of entrance boundaries, and so the normalized
measure µ/µI is an invariant distribution on I.
✷
Our ﬁnal lemma provides the crucial connection between speed measure
and invariant distributions.
Lemma 20.19 (positive recurrence) For a regular, recurrent diﬀusion on a
natural scale and with speed measure ν, these conditions are equivalent:
(i) νI < ∞;
(ii) the process is positive recurrent;
(iii) an invariant distribution exists.
In that case, µ = ν/νI is the unique invariant distribution.
Proof: If the process is null recurrent, then clearly no invariant distribu-
tion exists, and the converse is also true by Lemma 20.18. Thus, (ii) and
(iii) are equivalent. Now ﬁx any bounded, measurable function f : I →R+
with bounded support. By Theorem 20.14, Fubini’s theorem, and dominated
convergence, we have for any distribution µ on I
t−1

 t
0 Eµf(Xs)ds = Eµ t−1

 t
0 f(Xs)ds →νf
νI .
If µ is invariant, we get µf = νf/νI, and so νI < ∞. If instead X is null
recurrent, then Eµf(Xs) →0 as s →∞, and we get νf/νI = 0, which
implies νI = ∞.
✷

20. One-dimensional SDEs and Diﬀusions
389
End of proof of Theorem 20.15: It remains to consider the cases when I
is either (∞, ∞), [[0, ∞), or [[0, 1]], since we have otherwise convergence or
absorption at some endpoint. In case of [[0, 1]] we note from Theorem 20.12
(ii) that ν is bounded. In the remaining cases ν may be unbounded, and
then X is null recurrent by Lemma 20.19. If ν is bounded, then µ = ν/νI
is invariant by the same lemma, and the asserted ν-ergodicity follows from
Lemma 20.17 with µ1 = µ.
✷
Exercise
1.
Derive from Theorem 20.14 a law of large numbers for a regular
recurrent diﬀusion with bounded speed measure ν. Discuss extensions to
unbounded ν.

Chapter 21
PDE-Connections
and Potential Theory
Backward equation and Feynman–Kac formula; uniqueness for
SDEs from existence for PDEs; harmonic functions and Dirich-
let’s problem; Green functions as occupation densities; sweeping
and equilibrium problems; dependence on conductor and domain;
time reversal; capacities and random sets
In Chapters 17 and 18 we saw how elliptic diﬀerential operators arise natu-
rally in probability theory as the generators of nice diﬀusion processes. This
fact is the ultimate cause of some profound connections between probability
theory and partial diﬀerential equations (PDEs). In particular, a suitable
extension of the operator 1
2∆appears as the generator of Brownian motion
in Rd, which leads to a close relationship between classical potential theory
and the theory of Brownian motion. More speciﬁcally, many basic problems
in potential theory can be solved by probabilistic methods, and, conversely,
various hitting distributions for Brownian motion can be given a potential
theoretic interpretation.
This chapter explores some of the mentioned connections. First we derive
the celebrated Feynman–Kac formula and show how existence of solutions to
a given Cauchy problem implies uniqueness of solutions to the associated
SDE. We then proceed with a probabilistic construction of Green functions
and potentials and solve the Dirichlet, sweeping, and equilibrium problems
of classical potential theory in terms of Brownian motion. Finally, we show
how Greenian capacities and alternating set functions can be represented in
a natural way in terms of random sets.
Some stochastic calculus from Chapters 15 and 18 is used at the begin-
ning of the chapter, and we also rely on the theory of Feller processes from
Chapter 17. As for Brownian motion, the present discussion is essentially
self-contained, apart from some elementary facts cited from Chapters 11 and
16. Occasionally we refer to Chapters 3 and 14 for some basic weak con-
vergence theory. Finally, the results at the end of the chapter require the
existence of Poisson processes from Proposition 10.4, as well as some basic
facts about the Fell topology listed in Theorem A2.5. Additional, though
essentially unrelated, results in probabilistic potential theory are given at
the ends of Chapters 19 and 22.
390

21. PDE-Connections and Potential Theory
391
To begin with the general PDE connections, we consider an arbitrary
Feller diﬀusion in Rd with associated semigroup operators Tt and generator
A. Recall from Theorem 17.6 that, for any f ∈dom(A), the function
u(t, x) = Ttf(x) = Exf(Xt),
t ≥0, x ∈Rd,
satisﬁes Kolmogorov’s backward equation ˙u = Au, where ˙u = ∂u/∂t. Thus,
u provides a probabilistic solution to the Cauchy problem
˙u = Au,
u(0, x) = f(x).
(1)
Let us now add a potential term vu to (1), where v : Rd →R+, and
consider the more general problem
˙u = Au −vu,
u(0, x) = f(x).
(2)
Here the solution may be expressed in terms of the elementary multiplicative
functional e−V , where
Vt =

 t
0 v(Xs)ds,
t ≥0.
Let C1,2 denote the class of functions f : R+ × Rd that are of class C1 in
the time variable and of class C2 in the space variables. Write Cb(Rd) and
C+
b (Rd) for the classes of bounded, continuous functions from Rd to R and
R+, respectively.
Theorem 21.1 (Cauchy problem, Feynman, Kac) Fix any f ∈Cb(Rd) and
v ∈C+
b (Rd), and let A be the generator of a Feller diﬀusion in Rd. Then
any bounded solution u ∈C1,2 to (2) is given by
u(t, x) = Exe−Vtf(Xt),
t ≥0, x ∈Rd.
(3)
Conversely, (3) solves (2) whenever f ∈dom(A).
The expression in (3) has an interesting interpretation in terms of killing.
To see this, we may introduce an exponential random variable γ⊥⊥X with
mean 1, and deﬁne ζ = inf{t ≥0; Vt > γ}. Letting ˜X denote the process X
killed at time ζ, we may express the right-hand side of (3) as Exf( ˜Xt),
with the understanding that f( ˜Xt) = 0 when t ≥ζ.
In other words,
u(t, x) = ˜Ttf(x), where ˜Tt is the transition operator of the killed process.
It is easy to verify directly from (3) that the family ( ˜Tt) is again a Feller
semigroup.
Proof of Theorem 21.1: Assume that u ∈C1,2 is bounded and solves (2),
and deﬁne for ﬁxed t > 0
Ms = e−Vsu(t −s, Xs),
s ∈[0, t].

392
Foundations of Modern Probability
Letting
m∼denote equality apart from (the diﬀerential of) a continuous local
martingale, it is clear from Lemma 17.21, Itˆo’s formula, and (2) that for s < t
dMs
=
e−Vs{du(t −s, Xs) −u(t −s, Xs)v(Xs)ds}
m∼
e−Vs{Au(t −s, Xs) −˙u(t −s, Xs) −u(t −s, Xs)v(Xs)}ds = 0.
Thus, M is a continuous local martingale on [0, t).
Since M is further
bounded, the martingale property extends to t, and we get
u(t, x) = ExM0 = ExMt = Exu(0, Xt) = Exe−Vtf(Xt).
Next let u be given by (3), where f ∈dom(A). Integrating by parts and
using Lemma 17.21, we obtain
d{e−Vtf(Xt)} = e−Vt{df(Xt) −(vf)(Xt)dt}
m∼e−Vt(Af −vf)(Xt)dt.
Taking expectations and diﬀerentiating at t = 0, we conclude that the gen-
erator of the semigroup ˜Ttf(x) = Exf( ˜Xt) = u(t, x) equals ˜A = A −v on
dom(A). Equation (2) now follows by the last assertion in Theorem 17.6. ✷
The converse part of Theorem 21.1 may often be improved in special cases.
In particular, if v = 0 and A = 1
2∆= 1
2
	
i ∂2/∂x2
i , so that X is a Brownian
motion and (2) reduces to the standard heat equation, then u(t, x) = Exf(Xt)
solves (2) for any bounded, continuous function f on Rd. To see this, we note
that u ∈C1,2 on (0, ∞)×Rd because of the smoothness of the Brownian tran-
sition density. We may then obtain (2) by applying the backward equation
to the function Thf(x) for a ﬁxed h ∈(0, t).
Let us now consider an SDE in Rd of the form
dXi
t = σi
j(Xt)dBj
t + bi(Xt)dt
(4)
and introduce the associated elliptic operator
Av(x) = 1
2aij(x)v′′
ij(x) + bi(x)v′
i(x),
x ∈Rd, v ∈C2,
where aij = σi
kσj
k. The next result shows how uniqueness in law for solutions
to (4) may be inferred from the existence of solutions to the associated Cauchy
problem (1).
Theorem 21.2 (uniqueness, Stroock and Varadhan) If the Cauchy problem
in (1) has a bounded solution on [0, ε] × Rd for some ε > 0 and every f ∈
C∞
0 (Rd), then uniqueness in law holds for the SDE (4).
Proof: Fix any f ∈C∞
0 and t ∈(0, ε], and let u be a bounded solution to
(1) on [0, t] × Rd. If X solves (4), we note as before that Ms = u(t −s, Xs)
is a martingale on [0, t], and so
Ef(Xt) = Eu(0, Xt) = EMt = EM0 = Eu(t, X0).

21. PDE-Connections and Potential Theory
393
Thus, the one-dimensional distributions of X on [0, ε] are uniquely deter-
mined by the initial distribution.
Now consider any two solutions X and Y with the same initial distribu-
tion. To prove that their ﬁnite-dimensional distributions agree, it is enough
to consider time sets 0 = t0 < t1 < · · · < tn where tk −tk−1 ≤ε for all
k. Assume that the distributions agree at t0, . . . , tn−1 = t, and ﬁx any set
C = π−1
t0,...,tn−1B with B ∈Bnd. By Theorem 18.7, both P ◦X−1 and P ◦Y −1
solve the local martingale problem for (a, b). If P{X ∈C} = P{Y ∈C} > 0,
it is seen as in case of Theorem 18.11 that the same property holds for the
conditional measures P[θtX ∈·|X ∈C] and P[θtY ∈·|Y ∈C]. Since the
corresponding initial distributions agree by hypothesis, the one-dimensional
result yields the extension
P{X ∈C, Xt+h ∈·} = P{Y ∈C, Yt+h ∈·},
h ∈(0, ε].
In particular, the distributions agree at times t0, . . . , tn. The general result
now follows by induction.
✷
We may now specialize to the case when X is Brownian motion in Rd. For
any closed set B ⊂Rd, we introduce the hitting time τB = inf{t > 0; Xt ∈B}
and associated hitting kernel
HB(x, dy) = Px{τB < ∞, XτB ∈dy},
x ∈Rd.
For suitable functions f, we shall further write HBf(x) =
 f(y)HB(x, dy).
By a domain in Rd we mean an open, connected subset D ⊂Rd.
A
function u : D →R is said to be harmonic if it belongs to C2(D) and
satisﬁes the Laplace equation ∆u = 0. We further say that u has the mean-
value property if it is locally bounded and measurable, and such that for any
ball B ⊂D with center x, the average of u over the boundary ∂B equals u(x).
The following analytic result is crucial for the probabilistic developments.
Lemma 21.3 (harmonic functions, Gauss, Koebe) A function u on some
domain D ⊂Rd is harmonic iﬀit has the mean-value property, and then
u ∈C∞(D).
Proof: First assume that u ∈C2(D), and ﬁx a ball B ⊂D with center x.
Writing τ = τ∂B and noting that Exτ < ∞, we get by Itˆo’s formula
Exu(Xτ) −u(x) = 1
2Ex

 τ
0 ∆u(Xs)ds.
Here the ﬁrst term on the left equals the average of u over ∂B because of the
spherical symmetry of Brownian motion. If u is harmonic, then the right-
hand side vanishes, and the mean-value property follows. If instead u is not
harmonic, we may choose B such that ∆u ̸= 0 on B. But then the right-hand
side is nonzero, and so the mean-value property fails.

394
Foundations of Modern Probability
It remains to show that every function u with the mean-value property is
inﬁnitely diﬀerentiable. Then ﬁx any inﬁnitely diﬀerentiable and spherically
symmetric probability density ϕ, supported by a ball of radius ε > 0 around
the origin. The mean-value property yields u = u ∗ϕ on the set where the
right-hand side is deﬁned, and by dominated convergence the inﬁnite diﬀer-
entiability of ϕ carries over to u ∗ϕ = u.
✷
Before proceeding to the potential theoretic developments, we need to
introduce a regularity condition on the domain D. Writing ζ = ζD = τDc, we
note that Px{ζ = 0} = 0 or 1 for every x ∈∂D by Corollary 17.18. When
this probability is 1, we say that x is regular for Dc or simply regular; if this
holds for every x ∈∂D, then the boundary ∂D is said to be regular and we
refer to D as a regular domain.
Regularity is a fairly weak condition. In particular, any domain with a
smooth boundary is regular, and we shall see that even various edges and
corners are allowed, provided they are not too sharp and directed inward.
By a spherical cone in Rd with vertex v and axis a ̸= 0 we mean a set of the
form C = {x; ⟨x −v, a⟩≥c|x −v|}, where c ∈(0, |a|].
Lemma 21.4 (cone condition, Zaremba) Fix a domain D ⊂Rd, and let
x ∈∂D be such that C ∩G ⊂Dc for some some spherical cone C with vertex
x and some neighborhood G of x. Then x is regular for Dc.
Proof: By compactness of the unit sphere in Rd, we may cover Rd by
C = C1 and ﬁnitely many congruent cones C2, . . . , Cn with vertex x. By
rotational symmetry
1 = Px{mink≤nτCk = 0} ≤

k≤nPx{τCk = 0} = nPx{τC = 0},
and so Px{τC = 0} > 0. Hence, Corollary 17.18 yields P{τC = 0} = 1, and
we get ζD ≤τC∩G = 0 a.s. Px.
✷
Now ﬁx a domain D ⊂Rd and a continuous function f : ∂D →R. A
function u on D is said to solve the Dirichlet problem (D, f) if u is harmonic
on D and continuous on D with u = f on ∂D. The solution may be inter-
preted as the electrostatic potential in D when the potential on the boundary
is given by f.
Theorem 21.5 (Dirichlet problem, Kakutani, Doob) For any regular do-
main D ⊂Rd and function f ∈Cb(∂D), a solution to the Dirichlet problem
(D, f) is given by
u(x) = Ex[f(XζD); ζD < ∞] = HDcf(x),
x ∈D.
(5)
This is the only bounded solution when ζD < ∞a.s., and if d ≥3 and
f ∈C0(∂D), it is the only solution in C0(D).

21. PDE-Connections and Potential Theory
395
Thus, HDc agrees with the sweeping (balayage) kernel in Newtonian po-
tential theory, which determines the harmonic measure on ∂D. The following
lemma clariﬁes the role of the regularity condition on ∂D.
Lemma 21.6 (regularity, Doob) A point b ∈∂D is regular for Dc iﬀ, for
any f ∈Cb(∂D), the function u in (5) satisﬁes u(x) →f(b) as D ∋x →b.
Proof: First assume that b is regular. For any t > h > 0 and x ∈D, we
get by the Markov property
Px{ζ > t} ≤Px{ζ ◦θh > t −h} = ExPXh{ζ > t −h}.
Here the right-hand side is continuous in x, by the continuity of the Gaussian
kernel and dominated convergence, so
lim sup
x→b
Px{ζ > t} ≤EbPXh{ζ > t −h} = Pb{ζ ◦θh > t −h}.
As h →0, the probability on the right tends to Pb{ζ > t} = 0, and so
Px{ζ > t} →0 as x →b, which means that Px ◦ζ−1
w→δ0. Since also
Px
w→Pb in C(R+, Rd), Theorem 3.28 yields Px ◦(X, ζ)−1
w→Pb ◦(X, 0)−1 in
C(R+, Rd) × [0, ∞]. By the continuity of the mapping (x, t) →xt it follows
that Px ◦X−1
ζ
w→Pb ◦X−1
0
= δb, and so u(x) →f(b) by the continuity of f.
Next assume the stated condition. If d = 1, then D is an interval, which
is obviously regular. Now assume that d ≥2. By the Markov property we
get for any f ∈Cb(∂D)
u(b) = Eb[f(Xζ); ζ ≤h] + Eb[u(Xh); ζ > h],
h > 0.
As h →0, it follows by dominated convergence that u(b) = f(b), and for
f(x) = e−|x−b| we get Pb{Xζ = b, ζ < ∞} = 1. Since a.s. Xt ̸= b for all
t > 0 by Theorem 16.6 (i), we may conclude that Pb{ζ = 0} = 1, and so b is
regular.
✷
Proof of Theorem 21.5: Let u be given by (5), ﬁx any closed ball in D
with center x and boundary S, and conclude by the strong Markov property
at τ = τS that
u(x) = Ex[f(Xζ); ζ < ∞] = ExEXτ[f(Xζ); ζ < ∞] = Exu(Xτ).
This shows that u has the mean-value property, and so by Lemma 21.3 it
is harmonic. From Lemma 21.6 it is further seen that u is continuous on D
with u = f on ∂D. Thus, u solves the Dirichlet problem (D, f).
Now assume that d ≥3 and f ∈C0(∂D). For any ε > 0 we have
|u(x)| ≤ε + ∥f∥Px{|f(Xζ)| > ε, ζ < ∞}.
(6)
Since X is transient by Theorem 16.6 (ii) and the set {y ∈∂D; |f(y)| > ε}
is bounded, the right-hand side of (6) tends to 0 as |x| →∞and then ε →0,
which shows that u ∈C0(D).

396
Foundations of Modern Probability
To prove the asserted uniqueness, it is clearly enough to assume f = 0
and show that any solution u with the stated properties is identically zero.
If d ≥3 and u ∈C0(D), then this is clear by Lemma 21.3, which shows that
harmonic functions can have no local maxima or minima. Next assume that
ζ < ∞a.s. and u ∈Cb(D). By Corollary 15.20 we have Exu(Xζ∧n) = u(x)
for any x ∈D and n ∈N, and as n →∞, we get by continuity and domi-
nated convergence u(x) = Exu(Xζ) = 0.
✷
To prepare for our probabilistic construction of the Green function in
a domain D ⊂Rd, we need to study the transition densities of Brownian
motion killed on the boundary ∂D. Recall that ordinary Brownian motion
in Rd has transition densities
pt(x, y) = (2πt)−d/2e−|x−y|2/2t,
x, y ∈Rd, t > 0.
(7)
By the strong Markov property and Theorem 5.4, we get for any t > 0,
x ∈D, and B ⊂B(D),
Px{Xt ∈B} = Px{Xt ∈B, t ≤ζ} + Ex[Tt−ζ1B(Xζ); t > ζ].
Thus, the killed process has transition densities
pD
t (x, y) = pt(x, y) −Ex[pt−ζ(Xζ, y); t > ζ],
x, y ∈D, t > 0.
(8)
The following symmetry and continuity properties of pD
t play a crucial role
in the sequel.
Theorem 21.7 (transition density, Hunt) For any domain D in Rd and
time t > 0, the function pD
t is symmetric and continuous on D2. If b ∈∂D
is regular, then pD
t (x, y) →0 as x →b for ﬁxed y ∈D.
Proof: From (7) we note that pt(x, y) is uniformly equicontinuous in (x, y)
for ﬁxed t > 0, and also for |x −y| > ε > 0 and variable t > 0. By (8) it
follows that pD
t (x, y) is equicontinuous in y ∈D for ﬁxed t > 0. To prove
the continuity in x ∈D for ﬁxed t > 0 and y ∈D, it is then enough to show
that Px{Xt ∈B, t ≤ζ} is continuous in x for ﬁxed t > 0 and B ∈B(D).
Letting h ∈(0, t), we get by the Markov property
Px{Xt ∈B, ζ ≥t} = Ex[PXh{Xt−h ∈B, ζ ≥t −h}; ζ > h].
Thus, for any x, y ∈D
|(Px −Py){Xt ∈B, t ≤ζ}|
≤(Px + Py){ζ ≤h} + ∥Px ◦X−1
h
−Py ◦X−1
h }∥,
which tends to 0 as y →x and then h →0. Combining the continuity in
x with the equicontinuity in y, we conclude that pD
t (x, y) is continuous in
(x, y) ∈D2 for ﬁxed t > 0.

21. PDE-Connections and Potential Theory
397
To prove the symmetry in x and y, it is now enough to establish the
integrated version

C Px{Xt ∈B, ζ > t}dx =

B Px{Xt ∈C, ζ > t}dx,
(9)
for any bounded sets B, C ∈B(D).
Then ﬁx any compact set F ⊂D.
Letting n ∈N and writing h = 2−nt and tk = kh, we get by Proposition 7.2

C Px{Xtk ∈F, k ≤2n; Xt ∈B}dx
=

F · · ·

F 1C(x0)1B(x2n)

k≤2n
ph(xk−1, xk)dx0 · · · dx2n.
Here the right-hand side is symmetric in the pair (B, C), because of the
symmetry of ph(x, y). By dominated convergence as n →∞we obtain (9)
with F instead of D, and the stated version follows by monotone convergence
as F ↑D.
To prove the last assertion, we recall from the proof of Lemma 21.6 that
Px ◦(ζ, X)−1
w→Pb ◦(0, X)−1 as x →b with b ∈∂D regular. In particular,
Px ◦(ζ, Xζ)
w→δ0,b, and by the boundedness and continuity of pt(x, y) for
|x −y| > ε > 0, it is clear from (8) that pD
t (x, y) →0.
✷
A domain D ⊂Rd is said to be Greenian if either d ≥3 or if d ≤2 and
Px{ζD < ∞} = 1 for all x ∈D. Since the latter probability is harmonic in x,
it is enough by Lemma 21.3 to verify the stated property for a single x ∈D.
Given a Greenian domain D, we may introduce the Green function
gD(x, y) =

 ∞
0
pD
t (x, y)dt,
x, y ∈D.
For any measure µ on D, we may further introduce the associated Green
potential
GDµ(x) =

gD(x, y)µ(dy),
x ∈D.
Writing GDµ = GDf when µ(dy) = f(y)dy, we get by Fubini’s theorem
Ex

 ζ
0 f(Xt)dt =

gD(x, y)f(y)dy = GDf(x),
x ∈D,
which identiﬁes gD as an occupation density for the killed process.
The next result shows that gD and GD agree with the Green function and
Green potential of classical potential theory. Thus, GDµ(x) may be inter-
preted as the electrostatic potential at x arising from a charge distribution
µ in D, when the boundary ∂D is grounded.
Theorem 21.8 (Green function) For any Greenian domain D ⊂Rd, the
function gD is symmetric on D2. Furthermore, gD(x, y) is harmonic in x ∈
D\{y} for each y ∈D, and if b ∈∂D is regular, then gD(x, y) →0 as x →b
for ﬁxed y ∈D.

398
Foundations of Modern Probability
The proof is straightforward when d ≥3, but for d ≤2 we need two
technical lemmas. We begin with a uniform estimate for large t.
Lemma 21.9 (uniform integrability) Let the domain D ⊂Rd be bounded
when d ≤2 and otherwise arbitrary, and ﬁx any ε > 0. Then
 ∞
t
pD
s (x, y)ds
→0 as t →∞, uniformly for x, y ∈D.
Proof: For d ≥3 we may take D = Rd, in which case the result is obvious
from (7). Next let d = 2. By obvious domination and scaling arguments, we
may then assume that |x| ≤1, y = 0, D = {z; |z| ≤2}, and t > 1. Writing
pt(x) = pt(x, 0), we get by (8)
pD
t (x, 0)
≤
pt(x) −E0[pt−ζ(1); ζ ≤t/2]
≤
pt(0) −pt(1)P0{ζ ≤t/2}
≤
pt(0)P0{ζ > t/2} + pt(0) −pt(1)
<
⌢
t−1P0{ζ > t/2} + t−2.
As in case of Lemma 20.8 (ii), we have E0ζ < ∞, and so by Lemma 2.4 the
right-hand side is integrable in t ∈[1, ∞). The proof for d = 1 is similar. ✷
We also need the fact that bounded sets have bounded Green potential.
Lemma 21.10 (boundedness) For any Greenian domain D ⊂Rd and boun-
ded set B ∈B(D), the function GD1B is bounded.
Proof: By domination and scaling together with the strong Markov prop-
erty, it suﬃces to take B = {x; |x| ≤1} and to show that GD1B(0) < ∞.
For d ≥3 we may further take D = Rd, in which case the result follows by a
simple computation. For d = 2 we may assume that D ⊃C ≡{x; |x| < 2}.
Write σ = ζC +τB ◦θζC and τ0 = 0, and recursively deﬁne τk+1 = τk +σ ◦θτk,
k ≥0. Putting b = (1, 0), we get by the strong Markov property at the times
τk
GD1B(0) = GC1B(0) + GC1B(b)

k≥1P0{τk < ζ}.
Here GC1B(0) ∨GC1B(b) < ∞by Lemma 21.9. By the strong Markov prop-
erty it is further seen that P0{τk < ζ} ≤pk, where p = supx∈B Px{σ < ζ}.
Finally, note that p < 1, since Px{σ < ζ} is harmonic and hence continuous
on B. The proof for d = 1 is similar.
✷
Proof of Theorem 21.8: The symmetry of gD is clear from Theorem 21.7.
If d ≥3, or if d = 2 and D is bounded, it is further seen from Theorem
21.7, Lemma 21.9, and dominated convergence that gD(x, y) is continuous
in x ∈D \ {y} for each y ∈D. Next we note that GD1B has the mean-
value property in D \ B for bounded B ∈B(D). The property extends by
continuity to the density gD(x, y), which is then harmonic in x ∈D \ {y} for
ﬁxed y ∈D, by Lemma 21.3.

21. PDE-Connections and Potential Theory
399
For d = 2 and unbounded D, we deﬁne Dn = {x ∈D; |x| < n}, and
note as before that gDn(x, y) has the mean-value property in x ∈Dn \ {y}
for each y ∈Dn. Now pDn
t
↑pD
t by dominated convergence, so gDn ↑gD, and
the mean-value property extends to the limit. For any x ̸= y in D, choose a
circular disk B around y with radius ε > 0 small enough that x /∈B ⊂D.
Then πε2gD(x, y) = GD1B(x) < ∞by Lemma 21.10. Thus, by Lemma 21.3
even gD(x, y) is harmonic in x ∈D \ {y}.
To prove the last assertion, ﬁx any y ∈D, and assume that x →b ∈∂D.
Choose a Greenian domain D′ ⊃D with b ∈D′. Since pD
t ≤pD′
t , and both
pD′
t (·, y) and gD′(·, y) are continuous at b whereas pD
t (x, y) →0 by Theorem
21.7, we get gD(x, y) →0 by Theorem 1.21.
✷
We proceed to show that a measure is determined by its Green potential
whenever the latter is ﬁnite. An extension appears as part of Theorem 21.12.
For convenience we write
P D
t µ(x) =

pD
t (x, y)µ(dy),
x ∈D, t > 0.
Theorem 21.11 (uniqueness) Let µ and ν be measures on some Greenian
domain D ⊂Rd such that GDµ = GDν < ∞. Then µ = ν.
Proof: For any t > 0 we have

 t
0 (P D
s µ)ds = GDµ −P D
t GDµ = GDν −P D
t GDν =

 t
0 (P D
s ν)ds.
(10)
By the symmetry of pD, we further get for any measurable function f : D →
R+

f(x)P D
s µ(x)dx
=

f(x)dx

pD
s (x, y)µ(dy)
=

µ(dy)

f(x)pD
s (x, y)dx =

P D
s f(y)µ(dy).
Hence,

f(x)dx

 t
0 P D
s µ(x)ds =

 t
0 ds

P D
s f(y)µ(dy) =

µ(dy)

 t
0 P D
s f(y)ds,
and similarly for ν, so by (10)

µ(dy)

 t
0 P D
s f(y)ds =

ν(dy)

 t
0 P D
s f(y)ds.
(11)
Assuming that f ∈C+
K(D), we get P D
s f →f as s →0, and so t−1  t
0 P D
s fds
→f. If we can take limits inside the outer integrations in (11), we obtain
µf = νf, which implies µ = ν since f is arbitrary.
To justify the argument, it suﬃces to show that sups P D
s f is µ- and ν-
integrable. Then conclude from Theorem 21.7 that f <
⌢pD
s (·, y) for ﬁxed

400
Foundations of Modern Probability
s > 0 and y ∈D, and from Theorem 21.8 that f <
⌢GDf.
The latter
property yields P D
s f <
⌢P D
s GDf ≤GDf, and by the former property we get
for any y ∈D and s > 0
µ(GDf) =

GDµ(x)f(x)dx <
⌢P D
s GDµ(y) ≤GDµ(y) < ∞,
and similarly for ν.
✷
Now let FD and KD denote the classes of closed and compact subsets of
D, and write Fr
D and Kr
D for the subclasses of sets with regular boundary.
For any B ∈FD we may introduce the associated hitting kernel
HD
B (x, dy) = Px{τB < ζD, XτB ∈dy},
x ∈D.
Note that if X has initial distribution µ, then the hitting distribution of Xζ
in B equals µHD
B =
 µ(dx)HD
B (x, ·).
The next result solves the sweeping problem of classical potential theory.
To avoid technical complications, here and below, we shall only consider
subsets with regular boundary. In general, the irregular part of the boundary
can be shown to be polar, in the sense of being a.s. avoided by a Brownian
motion. Given this result, one can easily remove all regularity restrictions.
Theorem 21.12 (sweeping and hitting) Fix a Greenian domain D ⊂Rd
with subset B ∈Fr
D, and let µ be a bounded measure on D with GDµ < ∞
on B. Then µHD
B is the unique measure ν on B with GDµ = GDν on B.
For an electrostatic interpretation, assume that a grounded conductor B
is inserted into a domain D with grounded boundary and charge distribution
µ. Then a charge distribution −µHD
B arises on B.
A lemma is needed for the proof. Here we deﬁne gD\B(x, y) = 0 whenever
x or y lies in B.
Lemma 21.13 (fundamental identity) For any Greenian domain D ⊂Rd
and subset B ∈Fr
D, we have
gD(x, y) = gD\B(x, y) +

B HD
B (x, dz)gD(z, y),
x, y ∈D.
Proof: Write ζ = ζD and τ = τB.
Subtracting relations (8) for the
domains D and D \ B, and using the strong Markov property at τ together
with Theorem 5.4, we get
pD
t (x, y) −pD\B
t
(x, y)
=
Ex[pt−τ(Xτ, y); τ < ζ ∧t] −Ex[pt−ζ(Xζ, y); τ < ζ < t]
=
Ex[pt−τ(Xτ, y); τ < ζ ∧t]
−Ex[EXτ[pt−τ−ζ(Xζ, y); ζ < t −τ]; τ < ζ ∧t]
=
Ex[pD
t−τ(Xτ, y); τ < ζ ∧t].

21. PDE-Connections and Potential Theory
401
Now integrate with respect to t to get
gD(x, y) −gD\B(x, y) = Ex[gD(Xτ, y); τ < ζ] =

HD
B (x, dz)gD(z, y).
✷
Proof of Theorem 21.12: Since ∂B is regular, we have HD
B (x, ·) = δx for
all x ∈B, so by Lemma 21.13 we get for all x ∈B and z ∈D

gD(x, y)HD
B (z, dy) =

gD(z, y)HD
B (x, dy) = gD(z, x).
Integrating with respect to µ(dz) gives GD(µHD
B )(x) = GDµ(x), which shows
that ν = µHD
B has the stated property.
Now consider any measure ν on B with GDµ = GDν on B. Noting that
gD\B(x, ·) = 0 on B whereas HD
B (x, ·) is supported by B, we get by Lemma
21.13 for any x ∈D
GDν(x)
=

ν(dz)gD(z, x) =

ν(dz)

gD(z, y)HD
B (x, dy)
=

HD
B (x, dy)GDν(y) =

HD
B (x, dy)GDµ(y).
Thus, µ determines GDν on D, and so ν is unique by Theorem 21.11.
✷
Let us now turn to the classical equilibrium problem. For any K ∈KD
we introduce the last exit or quitting time
γD
K = sup{t < ζD; Xt ∈K}
and the associated quitting kernel
LD
K(x, dy) = Px{γD
K > 0; X(γD
K) ∈dy}.
Theorem 21.14 (equilibrium measure and quitting, Chung) For any Green-
ian domain D ∈Rd and subset K ∈KD, there exists a measure µD
K on ∂K
with
LD
K(x, dy) = gD(x, y)µD
K(dy),
x ∈D.
(12)
Furthermore, µD
K is diﬀuse when d ≥2. If K ∈Kr
D, then µD
K is the unique
measure µ on K with GDµ = 1 on K.
Here µD
K is called the equilibrium measure of K relative to D, and its total
mass CD
K is called the capacity of K in D. For an electrostatic interpretation,
assume that a conductor K with potential 1 is inserted into a domain D with
grounded boundary. Then a charge distribution µD
K arises on the boundary
of K.
Proof of Theorem 21.14: Write γ = γD
K, and deﬁne
lε(x) = ε−1Px{0 < γ ≤ε},
ε > 0.

402
Foundations of Modern Probability
Using Fubini’s theorem, the simple Markov property, and dominated conver-
gence as ε →0, we get for any f ∈Cb(D) and x ∈D
GD(flε)(x)
=
Ex

 ζ
0 f(Xt)lε(Xt)dt
=
ε−1

 ∞
0
Ex[f(Xt)PXt{0 < γ ≤ε}; t < ζ]dt
=
ε−1

 ∞
0
Ex[f(Xt); t < γ ≤t + ε]dt
=
ε−1Ex

 γ
(γ−ε)+
f(Xt)dt
→
Ex[f(Xγ); γ > 0] = LD
Kf(x).
If f has compact support, then for each x we may replace f by the
bounded, continuous function f/gD(x, ·) to get as ε →0

f(y)lε(y)dy →

 LD
K(x, dy)f(y)
gD(x, y)
.
(13)
Here the left-hand side is independent of x, so the same thing is true for the
measure
µD
K(dy) = LD
K(x, dy)
gD(x, y) .
(14)
If d = 1, we have gD(x, x) < ∞, and (14) is trivially equivalent to (12). If
instead d ≥2, then singletons are polar, so the measure LD
K(x, ·) is diﬀuse,
and the same thing is true for µD
K. Thus, (12) and (14) are again equivalent.
We may further conclude from the continuity of X that LD
K(x, ·), and then
also µD
K is supported by ∂K.
Integrating (12) over D yields
Px{τK < ζD} = GDµD
K(x),
x ∈D,
and so for K ∈Kr
D we get GDµD
K = 1 on K. If ν is another measure on
K with GDν = 1 on K, then ν = µD
K by the uniqueness part of Theorem
21.12.
✷
The next result relates the equilibrium measures and capacities for dif-
ferent sets K ∈Kr
D.
Proposition 21.15 (consistency) For any Greenian domain D ⊂Rd with
subsets K ⊂B in Kr
D, we have
µD
K
=
µD
BHD
K = µD
BLD
K,
(15)
CD
K
=

B Px{τK < ζD}µD
B(dx).
(16)

21. PDE-Connections and Potential Theory
403
Proof: By Theorem 21.12 and the deﬁning properties of µD
B and µD
K, we
have on K
GD(µD
BHD
K) = GDµD
B = 1 = GDµD
K,
and so µD
BHD
K = µD
K by the same result. To prove the second relation in (15),
we note by Theorem 21.14 that, for any A ∈B(K),
µD
BLD
K(A)
=

µD
B(dx)

A gD(x, y)µD
K(dy)
=

A GDµD
B(y)µD
K(dy) = µD
K(A),
since GDµD
B = 1 on A ⊂B. Finally, (15) implies (16), since HD
K(x, K) =
Px{τK < ζD}.
✷
Some basic properties of capacities and equilibrium measures follow im-
mediately from Proposition 21.15. To explain the terminology, ﬁx any space
S along with a class of subsets U, closed under ﬁnite unions. For any function
h: U →R and sets U, U1, U2, . . . ∈U, we recursively deﬁne the diﬀerences
∆U1h(U)
=
h(U ∪U1) −h(U),
∆U1,...,Unh(U)
=
∆Un{∆U1,...,Un−1h(U)},
n > 1,
where the diﬀerence ∆Un in the last formula is taken with respect to U. Note
that the higher-order diﬀerences ∆U1,...,Un are invariant under permutations
of U1, . . . , Un. We say that h is alternating or completely monotone if
(−1)n+1∆U1,...,Unh(U) ≥0,
n ∈N, U, U1, U2, . . . ∈U.
Corollary 21.16 (dependence on conductor, Choquet) For any Greenian
domain D ⊂Rd, the capacity CD
K is alternating in K ∈Kr
D. Furthermore,
µD
Kn
w→µD
K as Kn ↓K or Kn ↑K in Kr
D.
Proof: Let ψ denote the path of Xζ, regarded as a random closed set in
D. Writing
hx(K) = Px{ψK ̸= ∅} = Px{τK < ζ},
x ∈D \ K,
we get by induction
(−1)n+1∆K1,...,Knhx(K) = Px{ψK = ∅, ψK1 ̸= ∅, . . . , ψKn ̸= ∅} ≥0,
and the ﬁrst assertion follows by Proposition 21.15 with K ⊂B◦.
To prove the last assertion, we note that trivially τKn ↓τK when Kn ↑K,
and that τKn ↑τK when Kn ↓K since the Kn are closed. In the latter
case we also note that 
n{τKn < ζ} = {τK < ζ} by compactness. Thus, in
both cases HD
Kn(x, ·)
w→HD
K(x, ·) for all x ∈D \

n Kn, and by dominated
convergence in Proposition 21.15 with B◦⊃

n Kn we get µD
Kn
w→µD
K.
✷
The next result solves an equilibrium problem involving two conductors.

404
Foundations of Modern Probability
Corollary 21.17 (condenser theorem) For any disjoint sets B ∈Fr
D and
K ∈Kr
D, there exists a unique signed measure ν on B ∪K with GDν = 0 on
B and GDν = 1 on K, namely
ν = µD\B
K
−µD\B
K
HD
B .
Proof: Applying Theorem 21.14 to the domain D \ B with subset K, we
get ν = µD\B
K
on K, and then ν = −µD\B
K
HD
B on B by Theorem 21.12.
✷
The symmetry between hitting and quitting kernels in Proposition 21.15
may be extended to an invariance under time reversal of the whole process.
More precisely, putting γ = γD
K, we may relate the stopped process Xζ
t = Xγ∧t
to its reversal ˜Xγ
t = X(γ−t)+. For convenience, we write Pµ =
 Pxµ(dx) and
refer to the induced measures as distributions, even when µ is not normalized.
Theorem 21.18 (time reversal) Fix a Greenian domain D ∈Rd with sub-
set K ∈Kr
D, and put γ = γD
K and µ = µD
K. Then Xγ
d= ˜Xγ under Pµ.
Proof: Let Px and Ex refer to the process Xζ. Fix any times 0 = t0 <
t1 < · · · < tn, and write sk = tn −tk and hk = tk −tk−1. For any continuous
functions f0, . . . , fn with compact supports in D, we deﬁne
f ε(x) = Ex

kfk(Xsk)lε(Xtn) = Ex

k≥1fk(Xsk)EXs1(f0lε)(Xt1),
where the last equality holds by the Markov property at s1. Proceeding as
in the proof of Theorem 21.14, we get

(f εGDµ)(x)dx =

GDf ε(y)µ(dy) →Eµ

kfk( ˜Xγ
tk)1{γ > tn}.
(17)
On the other hand, (13) shows that the measure lε(x)dx tends vaguely to
µ, and so by Theorem 21.7
Ex(f0lε)(Xt1) =

pD
t1(x, y)(f0lε)(y)dy →

pD
t1(x, y)f0(y)µ(dy).
Using dominated convergence, Fubini’s theorem, Proposition 7.2, Theorem
21.7, and the relation GDµ(x) = Px{γ > 0}, we obtain

(f εGDµ)(x)dx
→

GDµ(x)dx

f0(y)µ(dy)Ex

k>0fk(Xsk)pD
t1(Xs1, y)
=

f0(x0)µ(dx0)

· · ·

GDµ(xn)

k>0pD
hk(xk−1, xk)fk(xk)dxk
= Eµ

kfk(Xtk)GDµ(Xtn) = Eµ

kfk(Xtk)1{γ > tn}.
Comparing with (17), it is seen that Xγ and ˜Xγ have the same ﬁnite-
dimensional distributions.
✷

21. PDE-Connections and Potential Theory
405
We may now extend Proposition 21.15 to the case of possibly diﬀerent
Greenian domains D ⊂D′. Fixing any K ∈KD, we recursively deﬁne the
optional times
τj = γj−1 + τ D′
K ◦θγj−1,
γj = τj + γD
K ◦θτj,
j ≥1,
starting with γ0 = 0. Thus, τk and γk are the hitting and quitting times for K
during the kth D-excursion before time ζD′ that reaches K. The generalized
hitting and quitting kernels are given by
HD,D′
K
(x, ·) = Ex

kδX(τk),
LD,D′
K
(x, ·) = Ex

kδX(γk),
where the summations extend over all k ∈N with τk < ∞.
Theorem 21.19 (extended consistency relations) Let D ⊂D′ be Greenian
domains in Rd with regular compact subsets K ⊂K′. Then
µD
K = µD′
K′HD,D′
K
= µD′
K′LD,D′
K
.
(18)
Proof: Deﬁne lε = ε−1Px{γD
K ∈(0, ε]}. Proceeding as in the proof of
Theorem 21.14, we get for any x ∈D′ and f ∈Cb(D′)
GD′(flε)(x) = ε−1Ex

 ζD′
0
f(Xt)1{γD
K ◦θt ∈(0, ε]}dt →LD,D′
K
f(x).
If f has compact support in D, we may conclude as before that

f(y)µD
K(dy) ←

(flε)(y)dy →

 LD,D′
K
(x, dy)f(y)
gD′(x, y)
,
and so
LD,D′
K
(x, dy) = gD′(x, y)µD
K(dy).
Integrating with respect to µD′
K′, and noting that GD′µD′
K′ = 1 on K′ ⊃K, we
obtain the second expression for µD
K in (18).
To deduce the ﬁrst expression, we note that HD′
K HD,D′
K
= HD,D′
K
by the
strong Markov property at τK. Combining with the second expression in (18)
and using Theorem 21.18 and Proposition 21.15, we get
µD
K = µD′
K LD,D′
K
= µD′
K HD,D′
K
= µD′
K′HD′
K HD,D′
K
= µD′
K′HD,D′
K
.
✷
The last result enables us to study the equilibrium measure µD
K and capac-
ity CD
K as functions of both D and K. In particular, we obtain the following
continuity and monotonicity properties.
Corollary 21.20 (dependence on domain) For any regular compact set K ⊂
Rd, the measure µD
K is nonincreasing and continuous from above and below
as a function of the Greenian domain D ⊃K.

406
Foundations of Modern Probability
Proof: The monotonicity is clear from (18) with K = K′, since HD,D′
K
(x, ·)
≥δx for x ∈K ⊂D ⊂D′. It remains to prove that CD
K is continuous from
above and below in D for ﬁxed K. By dominated convergence it is then
enough to show that κDn
K →κD
K, where κD
K = sup{j; τj < ∞} is the number
of D-excursions hitting K.
When Dn ↑D, we need to show that if Xs, Xt ∈K and X ∈D on [s, t],
then X ∈Dn on [s, t] for suﬃciently large n. But this is clear from the
compactness of the path on the interval [s, t]. If instead Dn ↓D, we need
to show for any r < s < t with Xr, Xt ∈K and Xs /∈D that Xs /∈Dn for
suﬃciently large n. But this is obvious.
✷
Next we shall see how Greenian capacities can be expressed in terms of
random sets. Let χ denote the identity mapping on FD. Given any measure
ν on FD \ {∅} with ν{χK ̸= ∅} < ∞for all K ∈KD, we may introduce
a Poisson process η on FD \ {∅} with intensity measure ν and form the
associated random closed set ϕ = {F; η{F} > 0} in D. Letting πν denote
the distribution of ϕ, we note that
πν{χK = ∅} = P{η{χK ̸= ∅} = 0} = exp(−ν{χK ̸= ∅}),
K ∈KD.
Theorem 21.21 (Greenian capacities and random sets, Choquet) For any
Greenian domain D ⊂Rd, there exists a unique measure ν on FD \ {∅} such
that
CD
K = ν{χK ̸= ∅} = −log πν{χK = ∅},
K ⊂Kr
D.
Proof: Let ψ denote the path of Xζ in D. Choose sets Kn ↑D in Kr
D
with Kn ⊂K◦
n+1 for all n, and put µn = µD
Kn, ψn = ψKn, and χn = χKn.
Deﬁne
νp
n =

Px{ψp ∈· , ψn ̸= ∅}µp(dx),
n ≤p,
(19)
and conclude by the strong Markov property and Proposition 21.15 that
νq
n{χp ∈· , χm ̸= ∅} = νp
m,
m ≤n ≤p ≤q.
(20)
By Corollary 5.15 there exist some measures νn on FD, n ∈N, satisfying
νn{χp ∈·} = νp
n,
n ≤p,
(21)
and from (20) we note that
νn{ · , χm ̸= ∅} = νm,
m ≤n.
(22)
Thus, the measures νn agree on {χm ̸= ∅} for n ≥m, and we may deﬁne
ν = supn νn. By (22) we have ν{·, χn ̸= ∅} = νn for all n, so if K ∈Kr
D with
K ⊂K◦
n, we get by (19), (21), and Proposition 21.15
ν{χK ̸= ∅}
=
νn{χK ̸= ∅} = νn
n{χK ̸= ∅}
=

Px{ψnK ̸= ∅}µn(dx)
=

Px{τK < ζ}µn(dx) = CD
K.
The uniqueness of ν is clear by a monotone class argument.
✷

21. PDE-Connections and Potential Theory
407
The representation of capacities in terms of random sets may be extended
to the abstract setting of general alternating set functions. As in Chapter
14, we then ﬁx an lcscH space S with Borel σ-ﬁeld S, open sets G, closed
sets F, and compacts K. Write ˆS = {B ∈S; B ∈K}, and recall that a class
U ⊂ˆS is said to be separating if for any K ∈K and G ∈G with K ⊂G
there exists some U ∈U with K ⊂U ⊂G.
For any nondecreasing function h on a separating class U ⊂ˆS, we deﬁne
the associated inner and outer capacities h◦and ¯h by
h◦(G)
=
sup{h(U); U ∈U, U ⊂G},
G ∈G,
¯h(K)
=
inf{h(U); U ∈U, U ◦⊃K},
K ∈K.
Note that the formulas remain valid with U replaced by any separating sub-
class. For any random closed set ϕ in S, the associated hitting function h is
given by h(B) = P{ϕB ̸= ∅} for all B ∈ˆS.
Theorem 21.22 (alternating functions and random sets, Choquet) The hit-
ting function h of a random closed set in S is alternating with h = h on K
and h = h◦on G. Conversely, given a separating class U ⊂ˆS closed under
ﬁnite unions and an alternating function p : U →[0, 1] with p(∅) = 0, there
exists some random closed set with hitting function h such that h = ¯p on K
and h = p◦on G.
The algebraic part of the construction is clariﬁed by the following lemma.
Lemma 21.23 Let U ⊂ˆS be ﬁnite and closed under unions and let h: U →
[0, 1] be alternating with h(∅) = 0. Then there exists some point process ξ on
S with P{ξU > 0} = h(U) for all U ∈U.
Proof: The statement is obvious when U = {∅}. Proceeding by induction,
assume the assertion to be true when U is generated by at most n −1 sets,
and consider a class U generated by n nonempty sets B1, . . . , Bn. By scaling
we may assume that h(B1 ∪· · · ∪Bn) = 1.
For each j ∈{1, . . . , n}, let Uj be the class of unions formed by the sets
Bi \ Bj, i ̸= j, and deﬁne
hj(U) = ∆Uh(Bj) = h(Bj ∪U) −h(Bj),
U ∈Uj.
Then each hj is again alternating with hj(∅) = 0, so by the induction hy-
pothesis there exists some point process ξj on

i Bi\Bj with hitting function
hj. Note that hj remains the hitting function of ξj on all of U. Let us further
introduce a point process ξn+1 with
P

i{ξn+1Bi > 0} = (−1)n+1∆B1,...,Bnh(∅).
For 1 ≤j ≤n + 1 let νj denote the restriction of P ◦ξ−1
j
to the set Aj =

i<j{µBi > 0}, and put ν =
	
j νj. We may take ξ to be the canonical point
process on S with distribution ν.

408
Foundations of Modern Probability
To see that ξ has hitting function h, we note that for any U ∈U and
j ≤n
νj{µU > 0}
=
P{ξjB1 > 0, . . . , ξjBj−1 > 0, ξjU > 0}
=
(−1)j+1∆B1,...,Bj−1,Uhj(∅)
=
(−1)j+1∆B1,...,Bj−1,Uh(Bj).
It remains to show that, for any U ∈U \ {∅},

j≤n(−1)j+1∆B1,...,Bj−1,Uh(Bj) + (−1)n+1∆B1,...,Bnh(∅) = h(U).
This is clear from the fact that
∆B1,...,Bj−1,Uh(Bj) = ∆B1,...,Bj,Uh(∅) + ∆B1,...,Bj−1,Uh(∅).
✷
Proof of Theorem 21.22: The direct assertion can be proved in the same
way as Corollary 21.16. Conversely, let U and p be as stated. By Lemma
A2.7 we may assume U to be countable, say U = {U1, U2, . . .}. For each n,
let Un be the class of unions formed from U1, . . . , Un. By Lemma 21.23 there
exist some point processes ξ1, ξ2, . . . on S such that
P{ξnU > 0} = p(U),
U ∈Un, n ∈N.
The space F is compact by Theorem A2.5, and so by Theorem 14.3
there exists some random closed set ϕ in S such that supp ξn
d→ϕ along a
subsequence N ′ ⊂N. Writing hn and h for the associated hitting functions,
we get
h(B◦) ≤lim inf
n∈N′ hn(B) ≤lim sup
n∈N′
hn(B) = h(B),
B ∈ˆS,
and, in particular,
h(U ◦) ≤p(U) ≤h(U),
U ∈U.
Using the strengthened separation property K ⊂U ◦⊂U ⊂G, we may
easily conclude that h = p◦on G and h = ¯p on K.
✷
Exercises
1. Show that if ϕ1 and ϕ2 are independent random sets with distributions
πν1 and πν2, then ϕ1 ∪ϕ2 has distribution πν1+ν2.
2. Extend Theorem 21.22 to unbounded functions p. (Hint: Consider
the restrictions to compact sets, and proceed as in Theorem 21.21.)

Chapter 22
Predictability, Compensation,
and Excessive Functions
Accessible and predictable times; natural and predictable processes;
Doob–Meyer decomposition; quasi–left-continuity; compensation
of random measures; excessive and superharmonic functions; ad-
ditive functionals as compensators; Riesz decomposition
The purpose of this chapter is to present some fundamental, yet profound,
extensions of the theory of martingales and optional times from Chapter 6.
A basic role in the advanced theory is played by the notions of predictable
times and processes, as well as by various decomposition theorems, the most
important being the celebrated Doob–Meyer decomposition, a continuous-
time counterpart of the elementary Doob decomposition from Lemma 6.10.
Applying the Doob–Meyer decomposition to increasing processes and
their associated random measures leads to the notion of a compensator,
whose role is analogous to that of the quadratic variation for martingales. In
particular, the compensator can be used to transform a fairly general point
process to Poisson, in a similar way that a suitable time-change of a contin-
uous martingale was shown in Chapter 16 to lead to a Brownian motion.
The chapter concludes with some applications to classical potential the-
ory. To explain the main ideas, let f be an excessive function of Brownian
motion X on Rd. Then f(X) is a continuous supermartingale under Px for
every x, and so it has a Doob–Meyer decomposition M −A. Here A can be
chosen to be a continuous additive functional (CAF) of X, and we obtain an
associated Riesz decomposition f = UA + h, where UA denotes the potential
of A and h is the greatest harmonic minorant of f.
The present material is related in many ways to topics from earlier chap-
ters. Apart from the already mentioned connections, we shall occasionally
require some knowledge of random measures and point processes from Chap-
ter 10, of stable L´evy processes from Chapter 13, of stochastic calculus from
Chapter 15, of Feller processes from Chapter 17, of additive functionals and
their potentials from Chapter 19, and of Green potentials from Chapter 21.
The notions and results of this chapter play a crucial role for the analysis
of semimartingales and construction of general stochastic integrals in Chap-
ter 23.
All random objects in this chapter are assumed to be deﬁned on some
given probability space Ωwith a right-continuous and complete ﬁltration
409

410
Foundations of Modern Pobability
F. In the product space Ω× R+ we may introduce the predictable σ-ﬁeld P,
generated by all continuous, adapted processes on R+. The elements of P are
called predictable sets, and the P-measurable functions on Ω× R+ are called
predictable processes. Note that every predictable process is progressive.
The following lemma provides some useful characterizations of the pre-
dictable σ-ﬁeld.
Lemma 22.1 (predictable σ-ﬁeld) The predictable σ-ﬁeld is generated by
each of the following classes of sets or processes:
(i) F0 × R+ and the sets A × (t, ∞) with A ∈Ft, t ≥0;
(ii) F0 × R+ and the intervals (τ, ∞) for optional times τ;
(iii) the left-continuous, adapted processes.
Proof: Let P1, P2, and P3 be the σ-ﬁelds generated by the classes in (i),
(ii), and (iii), respectively. Since continuous functions are left-continuous, we
have trivially P ⊂P3. To see that P3 ⊂P1, it is enough to note that any
left-continuous process X can be approximated by the processes
Xn
t = X01[0,1](nt) +

k≥1Xk/n1(k,k+1](nt),
t ≥0.
Next we obtain P1 ⊂P2 by noting that the random time tA = t·1A +∞·1Ac
is optional for any t ≥0 and A ∈Ft. Finally, we may prove the relation
P2 ⊂P by noting that, for any optional time τ, the process 1(τ,∞) may be
approximated by the continuous, adapted processes Xn
t = (n(t −τ)+) ∧1,
t ≥0.
✷
A random variable τ in [0, ∞] is called a predictable time if it is announced
by some optional times τn ↑τ with τn < τ a.s. on {τ > 0} for all n. With
any optional time τ we may associate the σ-ﬁeld Fτ−generated by F0 and
the classes Ft ∩{τ > t} for arbitrary t > 0. The following result gives the
basic properties of the σ-ﬁelds Fτ−. It is interesting to note the similarity
with the results for the σ-ﬁelds Fτ in Lemma 6.1.
Lemma 22.2 (strict past) For any optional times σ and τ, we have
(i) Fσ ∩{σ < τ} ⊂Fτ−⊂Fτ;
(ii) if τ is predictable, then {σ < τ} ∈Fσ−∩Fτ−;
(iii) if τ is predictable and announced by (τn), then

n Fτn = Fτ−.
Proof: (i) For any A ∈Fσ we note that
A ∩{σ < τ} =

r∈Q+(A ∩{σ ≤r} ∩{r < τ}) ∈Fτ−,
since the intersections on the right are generators of Fτ−. Hence, Fσ∩{σ < τ}
∈Fτ−. The second relation holds since each generator of Fτ−lies in Fτ.
(ii) Assuming that (τn) announces τ, we get by (i)

22. Predictability, Compensation, and Excessive Functions
411
{τ ≤σ} = {τ = 0} ∪

n{τn < σ} ∈Fσ−.
(iii) For any A ∈Fτn we get by (i)
A = (A ∩{τn < τ}) ∪(A ∩{τn = τ = 0}) ∈Fτ−,
so

n Fτn ⊂Fτ−. Conversely, (i) yields for any t ≥0 and A ∈Ft
A ∩{τ > t} =

n(A ∩{τn > t}) ∈

nFτn−⊂

nFτn,
which shows that Fτ−⊂

n Fτn.
✷
Next we shall prove some elementary relations between predictable pro-
cesses and the σ-ﬁelds Fτ−. Similar results for progressive processes and the
σ-ﬁelds Fτ were obtained in Lemma 6.5.
Lemma 22.3 (predictability and strict past)
(i) For any optional time τ and predictable process X, the random variable
Xτ1{τ < ∞} is Fτ−-measurable.
(ii) For any predictable time τ and Fτ−-measurable random variable α, the
process Xt = α1{τ ≤t} is predictable.
Proof: (i) If X = 1A×(t,∞) for some t > 0 and A ∈Ft, then clearly
{Xτ1{τ < ∞} = 1} = A ∩{t < τ < ∞} ∈Fτ−.
We may now extend by a monotone class argument and subsequent approx-
imation, ﬁrst to arbitrary predictable indicator functions, and then to the
general case.
(ii) We may clearly assume α to be integrable. Choose an announcing
sequence (τn) for τ, and deﬁne
Xn
t = E[α|Fτn](1{0 < τn < t} + 1{τn = 0}),
t ≥0.
Then each Xn is left-continuous and adapted, hence predictable. Moreover,
Xn →X on R+ a.s. by Theorem 6.23 and Lemma 22.2 (iii).
✷
By a totally inaccessible time we mean an optional time τ such that
P{σ = τ < ∞} = 0 for every predictable time σ. An accessible time may
then be deﬁned as an optional time τ such that P{σ = τ < ∞} = 0 for every
totally inaccessible time σ. For any random time τ, we may introduce the
associated graph
[τ] = {(t, ω) ∈R+ × Ω; τ(ω) = t},
which allows us to express the previous condition on σ and τ as [σ] ∩[τ] = ∅
a.s. Given any optional time τ and set A ∈Fτ, the time τA = τ1A + ∞· 1Ac
is again optional and is called the restriction of τ to A. We shall prove a
basic decomposition of optional times. Related decompositions of increasing
processes and martingales are given in Propositions 22.17 and 23.16.

412
Foundations of Modern Pobability
Proposition 22.4 (decomposition of optional times) For any optional time
τ there exists an a.s. unique set A ∈Fτ ∩{τ < ∞} such that τA is accessible
and τAc is totally inaccessible.
Furthermore, there exist some predictable
times τ1, τ2, . . . with [τA] ⊂

n[τn] a.s.
Proof: Deﬁne
p = sup P

n{τ = τn < ∞},
(1)
where the supremum extends over all sequences of predictable times τn. Com-
bining sequences such that the probability in (1) approaches p, we may con-
struct a sequence (τn) for which the supremum is attained. For such a max-
imal sequence, we deﬁne A as the union in (1).
To see that τA is accessible, let σ be totally inaccessible. Then [σ]∩[τn] = ∅
a.s. for every n, so [σ] ∩[τA] = ∅a.s. If τAc is not totally inaccessible, then
P{τAc = τ0 < ∞} > 0 for some predictable time τ0, and we get a larger
value of p by joining τ0 to the previous sequence (τn). The contradiction
shows that A has the desired property.
To prove that A is a.s. unique, let B be another set with the stated prop-
erties. Then τA\B and τB\A are both accessible and totally inaccessible, and
so τA\B = τB\A = ∞a.s., which implies A = B a.s.
✷
We proceed to prove a version of the celebrated Doob–Meyer decomposi-
tion, a cornerstone in modern probability theory. By an increasing process we
mean a nondecreasing, right-continuous, and adapted process A with A0 = 0.
We say that A is integrable if EA∞< ∞. Recall that all submartingales are
assumed to be right-continuous. Local submartingales and locally integrable
processes are deﬁned by localization in the usual way.
Theorem 22.5 (decomposition of submartingales, Meyer, Dol´eans) A pro-
cess X is a local submartingale iﬀit has a decomposition X = M + A, where
M is a local martingale and A is a locally integrable, increasing, predictable
process. In that case M and A are a.s. unique.
We shall often refer to the process A above as the compensator of X,
especially when X is increasing.
Several proofs of this result are known,
most of which seem to require the deep section theorems. Here we shall give a
relatively short and elementary proof, based on Dunford’s weak compactness
criterion and an approximation of totally inaccessible times. For convenience,
we divide the proof into several lemmas.
Let (D) denote the class of measurable processes X such that the fam-
ily {Xτ} is uniformly integrable, where τ ranges over the set of all ﬁnite
optional times. By the following result it is enough to consider class (D)
submartingales.
Lemma 22.6 (uniform integrability) Any local submartingale X with X0 =
0 is locally of class (D).

22. Predictability, Compensation, and Excessive Functions
413
Proof: First reduce to the case when X is a true submartingale. Then
introduce for each n the optional time τ = n ∧inf{t > 0; |Xt| > n}. Here
|Xτ| ≤n ∨|Xτ|, which is integrable by Theorem 6.29, and so Xτ is of class
(D).
✷
An increasing process A is said to be natural if it is integrable and such
that E
 ∞
0 ∆MtdAt = 0 for any bounded martingale M. As a crucial step
in the proof of Theorem 22.5, we shall establish the following preliminary
decomposition, where the compensator A is shown to be natural rather than
predictable.
Lemma 22.7 (Meyer) Any submartingale X of class (D) has a decomposi-
tion X = M + A, where M is a uniformly integrable martingale and A is a
natural increasing process.
Proof (Rao): We may assume that X0 = 0. Introduce the n-dyadic times
tn
k = k2−n, k ∈Z+, and deﬁne for any process Y the associated diﬀerences
∆n
kY = Ytn
k+1 −Ytn
k. Let
An
t =

k<2ntE[∆n
kX|Ftn
k],
t ≥0, n ∈N,
and note that M n = X −An is a martingale on the n-dyadic set.
Writing τ n
r = inf{t; An
t > r} for n ∈N and r > 0, we get by optional
sampling for any n-dyadic time t
1
2E[An
t ; An
t > 2r]
≤
E[An
t −An
t ∧r] ≤E[An
t −An
τ n
r ∧t]
=
E[Xt −Xτ n
r ∧t] = E[Xt −Xτ n
r ∧t; An
t > r].
(2)
By the martingale property and uniform integrability, we further obtain
rP{An
t > r} ≤EAn
t = EXt <
⌢1,
and so the probability on the left tends to zero as r →∞, uniformly in t
and n. Since the random variables Xt −Xτ n
r ∧t are uniformly integrable by
(D), the same property holds for the variables An
t by (2) and Lemma 3.10.
In particular, the sequence (An
∞) is uniformly integrable, and each M n is a
uniformly integrable martingale.
By Lemma 3.13 there exists some random variable α ∈L1(F∞) such that
An
∞→α weakly in L1 along some subsequence N ′ ⊂N. Deﬁne
Mt = E[X∞−α|Ft],
A = X −M,
and note that A∞= α a.s. by Theorem 6.23. For any dyadic t and bounded
random variable ξ, we get by the martingale and self-adjointness properties
E(An
t −At)ξ
=
E(Mt −M n
t )ξ = E E[M∞−M n
∞|Ft]ξ
=
E(M∞−M n
∞)E[ξ|Ft]
=
E(An
∞−α)E[ξ|Ft] →0,

414
Foundations of Modern Pobability
as n →∞along N ′. Thus, An
t →At weakly in L1 for dyadic t. In particular,
we get for any dyadic s < t
0 ≤E[An
t −An
s; At −As < 0] →E[(At −As) ∧0] ≤0,
so the last expectation vanishes, and therefore At ≥As a.s.
By right-
continuity it follows that A is a.s. nondecreasing. Also note that A0 = 0
a.s., since An
0 = 0 for all n.
To see that A is natural, consider any bounded martingale N, and con-
clude by Fubini’s theorem and the martingale properties of N and An −A =
M −M n that
EN∞An
∞
=

kEN∞∆n
kAn =

kENtn
k∆n
kAn
=

kENtn
k∆n
kA = E

kNtn
k∆n
kA.
Now use weak convergence on the left and dominated convergence on the
right, and combine with Fubini’s theorem and the martingale property of N
to get
E

 ∞
0
Nt−dAt
=
EN∞A∞=

kEN∞∆n
kA =

kENtn
k+1∆n
kA
=
E

kNtn
k+1∆n
kA →E

 ∞
0
NtdAt.
Hence, E
 ∞
0 ∆NtdAt = 0, as required.
✷
To complete the proof of Theorem 22.5, it remains to show that the
compensator A in the last lemma is predictable. This will be inferred from
the following ingenious approximation of totally inaccessible times.
Lemma 22.8 (uniform approximation, Doob) Fix any totally inaccessible
time τ, put τn = 2−n[2nτ], and let Xn be a right-continuous version of the
process P[τn ≤t|Ft]. Then
lim
n→∞sup
t≥0 |Xn
t −1{τ ≤t}| = 0 a.s.
(3)
Proof: Since τn ↑τ, we may assume that X1
t ≥X2
t ≥· · · ≥1{τ ≤t}
for all t ≥0. Then Xn
t = 1 for t ∈[τ, ∞), and on the set {τ = ∞} we
have X1
t ≤P[τ < ∞|Ft] →0 a.s. as t →∞by Theorem 6.23.
Thus,
supn |Xn
t −1{τ ≤t}| →0 a.s. as t →∞, so to prove (3), it is enough to
show for each ε > 0 that the optional times
σn = inf{t ≥0; Xn
t −1{τ ≤t} > ε},
n ∈N,
tend a.s. to inﬁnity. The σn are clearly nondecreasing, and we denote their
limit by σ. Note that either σn ≤τ or σn = ∞for each n.

22. Predictability, Compensation, and Excessive Functions
415
By optional sampling, Theorem 5.4, and Lemma 6.1, we have
Xn
σ1{σ < ∞}
=
P[τn ≤σ < ∞|Fσ]
→
P[τ ≤σ < ∞|Fσ] = 1{τ ≤σ < ∞}.
Hence, Xn
σ →1{τ ≤σ} a.s. on {σ < ∞}, and so by right-continuity we have
on this set σn < σ for large enough n. Thus, σ is predictable and announced
by the times σn ∧n.
Next apply the optional sampling and disintegration theorems to the op-
tional times σn, to obtain
εP{σ < ∞}
≤
εP{σn < ∞} ≤E[Xn
σn; σn < ∞]
=
P{τn ≤σn < ∞} = P{τn ≤σn ≤τ < ∞}
→
P{τ = σ < ∞} = 0,
where the last equality holds since τ is totally inaccessible. Thus, σ = ∞
a.s.
✷
It is now easy to see that A has only accessible jumps.
Lemma 22.9 (accessibility) For any natural increasing process A and to-
tally inaccessible time τ, we have ∆Aτ = 0 a.s. on {τ < ∞}.
Proof: Rescaling if necessary, we may assume that A is a.s. continuous at
dyadic times. Deﬁne τn = 2−n[2nτ]. Since A is natural, we have
E

 ∞
0
P[τn > t|Ft]dAt = E

 ∞
0
P[τn > t|Ft−]dAt,
and since τ is totally inaccessible, it follows by Lemma 22.8 that
EAτ−= E

 ∞
0
1{τ > t}dAt = E

 ∞
0
1{τ ≥t}dAt = EAτ.
Hence, E[∆Aτ; τ < ∞] = 0, and so ∆Aτ = 0 a.s. on {τ < ∞}.
✷
Finally, we may show that A is predictable.
Lemma 22.10 (Dol´eans) Every natural increasing process is predictable.
Proof: Fix a natural increasing process A. Consider a bounded martingale
M and a predictable time τ < ∞announced by σ1, σ2, . . . . Then M τ −M σk
is again a bounded martingale, and since A is natural we get by dominated
convergence E∆Mτ∆Aτ = 0. In particular, we may take Mt = P[B|Ft] with
B ∈Fτ. By optional sampling we have Mτ = 1B and
Mτ−←Mσk = P[B|Fσk] →P[B|Fτ−].

416
Foundations of Modern Pobability
Thus, ∆Mτ = 1B −P[B|Fτ−], and so
E[∆Aτ; B] = E∆AτP[B|Fτ−] = E[E[∆Aτ|Fτ−]; B].
Since B was arbitrary in Fτ, we get ∆Aτ = E[∆Aτ|Fτ−] a.s., and so the
process A′
t = ∆Aτ1{τ ≤t} is predictable by Lemma 22.3 (ii). It is also
natural, since for any bounded martingale M
E∆Aτ∆Mτ = E∆AτE[∆Mτ|Fτ−] = 0.
By an elementary construction we have {t > 0; ∆At > 0} ⊂

n[τn] a.s.
for some optional times τn < ∞, and by Proposition 22.4 and Lemma 22.9
we may assume the latter to be predictable. Taking τ = τ1 in the previous
argument, we may conclude that the process A1
t = ∆Aτ11{τ1 ≤t} is both
natural and predictable. Repeating the argument for the process A −A1
with τ = τ2 and proceeding by induction, we may conclude that the jump
component Ad of A is predictable. Since A −Ad is continuous and hence
predictable, the predictability of A follows.
✷
For the uniqueness assertion we need the following extension of Proposi-
tion 15.2.
Lemma 22.11 (constancy criterion) A process M is a predictable martin-
gale of integrable variation iﬀMt ≡M0 a.s.
Proof: On the predictable σ-ﬁeld P we deﬁne the signed measure
µB = E

 ∞
0
1B(t)dMt,
B ∈P,
where the inner integral is an ordinary Lebesgue–Stieltjes integral. The mar-
tingale property implies that µ vanishes for sets B of the form F × (t, ∞)
with F ∈Ft. By Lemma 22.1 and a monotone class argument it follows that
µ = 0 on P.
Since M is predictable, the same thing is true for the process ∆Mt =
Mt −Mt−, and then also for the sets J± = {t > 0; ±∆Mt > 0}. Thus,
µJ± = 0, so ∆M = 0 a.s., and M is a.s. continuous. But then Mt ≡M0 a.s.
by Proposition 15.2.
✷
Proof of Theorem 22.5: The suﬃciency is obvious, and the uniqueness
holds by Lemma 22.11. It remains to prove that any local submartingale X
has the stated decomposition. By Lemmas 22.6 and 22.11 we may assume
that X is of class (D). Then Lemma 22.7 shows that X = M + A for some
uniformly integrable martingale M and some natural increasing process A,
and by Lemma 22.10 the latter process is predictable.
✷
The two conditions in Lemma 22.10 are, in fact, equivalent.

22. Predictability, Compensation, and Excessive Functions
417
Theorem 22.12 (natural and predictable processes, Dol´eans) An integrable,
increasing process is natural iﬀit is predictable.
Proof: If an integrable, increasing process A is natural, it is also pre-
dictable by Lemma 22.10. Now assume instead that A is predictable. By
Lemma 22.7 we have A = M + B for some uniformly integrable martingale
M and some natural increasing process B, and Lemma 22.10 shows that B
is predictable. But then A = B a.s. by Lemma 22.11, and so A is natural. ✷
The following useful result is essentially implicit in earlier proofs.
Lemma 22.13 (dual predictable projection) Let X and Y be locally inte-
grable, increasing processes, and assume that Y is predictable. Then X has
compensator Y iﬀE
 V dX = E
 V dY for every predictable process V ≥0.
Proof: First reduce by localization to the case when X and Y are inte-
grable. Then Y is the compensator of X iﬀM = Y −X is a martingale, that
is, iﬀEMτ = 0 for every optional time τ. This is equivalent to the stated
relation for V = 1[0,τ], and the general result follows by a straightforward
monotone class argument.
✷
We may now establish the fundamental connection between predictable
times and processes.
Theorem 22.14 (predictable times and processes, Meyer) For any optional
time τ, these conditions are equivalent:
(i) τ is predictable;
(ii) the process 1{τ ≤t} is predictable;
(iii) E∆Mτ = 0 for any bounded martingale M.
Proof (Chung and Walsh): Since (i) ⇒(ii) by Lemma 22.3 (ii), and (ii)
⇔(iii) by Theorem 22.12, it remains to show that (iii) ⇒(i).
We then
introduce the martingale Mt = E[e−τ|Ft] and the supermartingale
Xt = e−τ∧t −Mt = E[e−τ∧t −e−τ|Ft] ≥0,
t ≥0.
Here Xτ = 0 a.s. by optional sampling. Letting σ = inf{t ≥0; Xt−∧Xt = 0},
it is clear from Lemma 6.31 that {t ≥0; Xt = 0} = [σ, ∞) a.s., and in
particular, σ ≤τ a.s. Using optional sampling again, we get E(e−σ −e−τ) =
EXσ = 0, and so σ = τ a.s. Hence, Xt ∧Xt−> 0 a.s. on [0, τ). Finally, (iii)
yields
EXτ−= E(e−τ −Mτ−) = E(e−τ −Mτ) = EXτ = 0,
and so Xτ−= 0. It is now clear that τ is announced by the optional times
τn = inf{t; Xt < n−1}.
✷
To illustrate the power of the last result, we shall give a short proof of
the following useful statement, which can also be proved directly.

418
Foundations of Modern Pobability
Corollary 22.15 (restriction) For any predictable time τ and set A ∈Fτ−,
the restriction τA is again predictable.
Proof: The process 1A1{τ ≤t} = 1{τA ≤t} is predictable by Lemma
22.3, and so the time τA is predictable by Theorem 22.14.
✷
We may also use the last theorem to show that predictable martingales
are continuous.
Proposition 22.16 (predictable martingales) A local martingale is predict-
able iﬀit is a.s. continuous.
Proof: The suﬃciency is clear by deﬁnitions. To prove the necessity, we
note that, for any optional time τ,
M τ
t = Mt1[0,τ](t) + Mτ1(τ,∞)(t),
t ≥0.
Thus, predictability is preserved by optional stopping, so we may assume that
M is a uniformly integrable martingale. Now ﬁx any ε > 0, and introduce
the optional time τ = inf{t > 0; |∆Mt| > ε}.
Since the left-continuous
version Mt−is predictable, so is the process ∆Mt as well as the random set
A = {t > 0; |∆Mt| > ε}. Hence, the same thing is true for the random
interval [τ, ∞) = A ∪(τ, ∞), and so τ is predictable by Theorem 22.14.
Choosing an announcing sequence (τn), we conclude by optional sampling,
martingale convergence, and Lemmas 22.2 (iii) and 22.3 (i) that
Mτ−←Mτn = E[Mτ|Fτn] →E[Mτ|Fτ−] = Mτ.
Thus, τ = ∞a.s., and since ε was arbitrary, it follows that M is a.s. contin-
uous.
✷
The decomposition of optional times in Proposition 22.4 may now be ex-
tended to increasing processes. We say that an rcll process X or a ﬁltration
F is quasi–left-continuous if Xτ−= Xτ a.s. on {τ < ∞} or Fτ−= Fτ, re-
spectively, for every predictable time τ. We further say that X has accessible
jumps if Xτ−= Xτ a.s. on {τ < ∞} for every totally inaccessible time τ.
Proposition 22.17 (decomposition of increasing processes) Any purely dis-
continuous, increasing process A has an a.s. unique decomposition into in-
creasing processes Aq and Aa such that Aq is quasi–left-continuous and Aa has
accessible jumps. Furthermore, there exist some predictable times τ1, τ2, . . .
with disjoint graphs such that {t > 0; ∆Aa
t > 0} ⊂

n[τn] a.s. Finally, if A
is locally integrable with compensator ˆA, then Aq has compensator ( ˆA)c.
Proof: Introduce the locally integrable process Xt =
	
s≤t(∆As ∧1) with
compensator ˆX, and deﬁne Aq = A −Aa = 1{∆ˆX = 0} · A, or
Aq
t = At −Aa
t =

 t+
0
1{∆ˆXs = 0} dAs,
t ≥0.
(4)

22. Predictability, Compensation, and Excessive Functions
419
For any ﬁnite predictable time τ, the graph [τ] is again predictable by The-
orem 22.14, and so by Lemma 22.13,
E(∆Aq
τ ∧1) = E[∆Xτ; ∆ˆXτ = 0] = E[∆ˆXτ; ∆ˆXτ = 0] = 0,
which shows that Aq is quasi–left-continuous.
Now let τn,0 = 0, and recursively deﬁne the random times
τn,k = inf{t > τn,k−1; ∆ˆXt ∈(2−n, 2−n+1]},
n, k ∈N,
which are predictable by Theorem 22.14. Also note that {t > 0; ∆Aa
t > 0}
⊂
n,k[τnk] a.s. by the deﬁnition of Aa. Hence, if τ is a totally inaccessible
time, then ∆Aa
τ = 0 a.s. on {τ < ∞}, which shows that Aa has accessible
jumps.
To prove the uniqueness, assume that A has two decompositions Aq+Aa =
Bq + Ba with the stated properties. Then Y = Aq −Bq = Ba −Aa is quasi–
left-continuous with accessible jumps. Hence, by Proposition 22.4 we have
∆Yτ = 0 a.s. on {τ < ∞} for any optional time τ, which means that Y is
a.s. continuous. Since it is also purely discontinuous, we get Y = 0 a.s.
If A is locally integrable, we may replace (4) by Aq = 1{∆ˆA = 0}·A, and
we also note that ( ˆA)c = 1{∆ˆA = 0} · ˆA. Thus, Lemma 22.13 yields for any
predictable process V ≥0
E

V dAq
=
E

1{∆ˆA = 0}V dA
=
E

1{∆ˆA = 0}V d ˆA = E

V d( ˆA)c,
and the same lemma shows that Aq has compensator ( ˆA)c.
✷
By the compensator of an optional time τ we mean the compensator of
the associated jump process Xt = 1{τ ≤t}. The following result charac-
terizes the various categories of optional times in terms of the associated
compensators.
Corollary 22.18 (compensation of optional times)
Let τ be an optional
time with compensator A. Then
(i) τ is predictable iﬀA is a.s. constant apart from a possible unit jump;
(ii) τ is accessible iﬀA is a.s. purely discontinuous;
(iii) τ is totally inaccessible iﬀA is a.s. continuous.
In general, τ has the accessible part τD, where D = {∆Aτ > 0, τ < ∞}.
Proof: (i) If τ is predictable, then so is the process Xt = 1{τ ≤t} by
Theorem 22.14, and so A = X a.s. Conversely, if At = 1{σ ≤t} for some
optional time σ, then the latter is predictable by Theorem 22.14, and by
Lemma 22.13 we have
P{σ = τ < ∞}
=
E[∆Xσ; σ < ∞] = E[∆Aσ; σ < ∞]
=
P{σ < ∞} = EA∞= EX∞= P{τ < ∞}.
Thus, τ = σ a.s., and so τ is predictable.

420
Foundations of Modern Pobability
(ii) Clearly, τ is accessible iﬀX has accessible jumps, which holds by
Proposition 22.17 iﬀA = Ad a.s.
(iii) Here we note that τ is totally inaccessible iﬀX is quasi–left-contin-
uous, which holds by Proposition 22.17 iﬀA = Ac a.s.
The last assertion follows easily from (ii) and (iii).
✷
The next result characterizes quasi–left-continuity for ﬁltrations and mar-
tingales.
Proposition 22.19 (quasi–left-continuous ﬁltrations, Meyer) For any ﬁl-
tration F, these conditions are equivalent:
(i) Every accessible time is predictable;
(ii) Fτ−= Fτ on {τ < ∞} for every predictable time τ;
(iii) ∆Mτ = 0 a.s. on {τ < ∞} for every martingale M and predictable
time τ.
If the basic σ-ﬁeld in Ωis taken to be F∞, then Fτ−= Fτ on {τ = ∞}
for any optional time τ, and the relation in (ii) extends to all of Ω.
Proof: (i) ⇒(ii): Let τ be a predictable time, and ﬁx any B ∈Fτ ∩
{τ < ∞}. Then [τB] ⊂[τ], so τB is accessible and by (i) even predictable.
The process Xt = 1{τB ≤t} is then predictable by Theorem 22.14, and since
Xτ1{τ < ∞} = 1{τB ≤τ < ∞} = 1B,
Lemma 22.3 (i) yields B ∈Fτ−.
(ii) ⇒(iii): Fix any martingale M, and let τ be a bounded, predictable
time with announcing sequence (τn). Using (ii) and Lemma 22.2 (iii), we get
as before
Mτ−←Mτn = E[Mτ|Fτn] →E[Mτ|Fτ−] = E[Mτ|Fτ] = Mτ,
and so Mτ−= Mτ a.s.
(iii) ⇒(i): If τ is accessible, then by Proposition 22.4 there exist some
predictable times τn with [τ] ⊂

n[τn] a.s. By (iii) we have ∆Mτn = 0 a.s.
on {τn < ∞} for every martingale M and all n, and so ∆Mτ = 0 a.s. on
{τ < ∞}. Hence, τ is predictable by Theorem 22.14.
✷
In particular, quasi–left-continuity holds for canonical Feller processes
and their induced ﬁltrations.
Proposition 22.20 (quasi–left-continuity of Feller processes, Blumenthal,
Meyer) Let X be a canonical Feller process with arbitrary initial distribution,
and ﬁx any optional time τ. Then these conditions are equivalent:
(i) τ is predictable;
(ii) τ is accessible;
(iii) Xτ−= Xτ a.s. on {τ < ∞}.

22. Predictability, Compensation, and Excessive Functions
421
In the special case when X is a.s. continuous, we may conclude that every
optional time is predictable.
Proof: (ii) ⇒(iii): By Proposition 22.4 we may assume that τ is ﬁnite
and predictable. Fix an announcing sequence (τn) and a function f ∈C0.
By the strong Markov property, we get for any h > 0
E{f(Xτn) −f(Xτn+h)}2
=
E(f 2 −2fThf + Thf 2)(Xτn)
≤
∥f 2 −2fThf + Thf 2∥
≤
2∥f∥∥f −Thf∥+ ∥f 2 −Thf 2∥.
Letting n →∞and then h ↓0, it follows by dominated convergence on
the left and by strong continuity on the right that E{f(Xτ−) −f(Xτ)}2 =
0, which means that f(Xτ−) = f(Xτ) a.s.
Applying this to a sequence
f1, f2, . . . ∈C0 that separates points, we obtain Xτ−= Xτ a.s.
(iii) ⇒(i): By (iii) and Theorem 17.20 we have ∆Mτ = 0 a.s. on {τ < ∞}
for every martingale M, and so τ is predictable by Theorem 22.14.
(i) ⇒(ii): This is trivial.
✷
The following basic inequality will be needed in the proof of Theorem
23.12.
Proposition 22.21 (norm inequality, Garsia, Neveu) Consider a right- or
left-continuous, predictable, increasing process A and a random variable ζ ≥
0 such that a.s.
E[A∞−At|Ft] ≤E[ζ|Ft],
t ≥0.
(5)
Then
∥A∞∥p ≤p∥ζ∥p,
p ≥1.
In the left-continuous case, predictability is clearly equivalent to adapt-
edness. The appropriate interpretation of (5) is to take E[At|Ft] ≡At and to
choose right-continuous versions of the martingales E[A∞|Ft] and E[ζ|Ft].
For a right-continuous A, we may clearly choose ζ = Z∗, where Z is the
supermartingale on the left of (5). We also note that if A is the compensator
of an increasing process X, then (5) holds with ζ = X∞.
Proof: We shall only consider the right-continuous case, the case of a
left-continuous A being similar but simpler. It is enough to assume that
A is bounded, since we may otherwise replace A by the process A ∧u for
arbitrary u > 0, and let u →∞in the resulting formula. For each r > 0,
the random time τr = inf{t; At ≥r} is predictable by Theorem 22.14. By
optional sampling and Lemma 22.2 we note that (5) remains true with t
replaced by τr−. Since τr is Fτr−-measurable by the same lemma, we obtain
E[A∞−r; A∞> r]
≤
E[A∞−r; τr < ∞]
≤
E[A∞−Aτr−; τr < ∞]
≤
E[ζ; τr < ∞] ≤E[ζ; A∞≥r].

422
Foundations of Modern Pobability
Writing A∞= α and letting p−1 + q−1 = 1, we get by Fubini’s theorem,
H¨older’s inequality, and some easy calculus
∥α∥p
p
=
p2q−1E

 α
0 (α −r)rp−2dr
=
p2q−1

 ∞
0
E[α −r; α > r]rp−2dr
≤
p2q−1

 ∞
0
E[ζ; α ≥r]rp−2dr
=
p2q−1E ζ

 α
0 rp−2dr = pEζαp−1 ≤p∥ζ∥p∥α∥p−1
p
.
If ∥α∥p > 0, we may ﬁnally divide both sides by ∥α∥p−1
p
.
✷
We turn our attention to locally ﬁnite random measures ξ on (0, ∞) × S,
where S is a Polish space with Borel σ-ﬁeld S. Let ˆS denote the class of
bounded sets in S and say that ξ is adapted, predictable, or locally integrable
if the process ξtB = ξ((0, t] × B) has the corresponding property for every
B ∈ˆS. In the cases of adaptedness and predictability, it is clearly equivalent
that the relevant property holds for the measure-valued process ξt. Let us
further say that a process V on R+×S is predictable if it is P ⊗S-measurable,
where P denotes the predictable σ-ﬁeld in R+ × Ω.
Theorem 22.22 (compensation of random measures, Grigelionis, Jacod)
Let ξ be a locally integrable, adapted random measure on some product space
(0, ∞) × S, where S is Polish. Then there exists an a.s. unique predictable
random measure ˆξ on (0, ∞) × S such that E
 V dξ = E
 V dˆξ for every
predictable process V ≥0 on R+ × S.
The random measure ˆξ above is called the compensator of ξ. By Lemma
22.13 this extends the notion of compensator for real-valued processes. For
the proof of Theorem 22.22 we need a simple technical lemma, which can be
established by straightforward monotone class arguments.
Lemma 22.23 (predictability)
(i) For any predictable random measure ξ and predictable process V ≥0
on (0, ∞) × S, the process V · ξ is again predictable;
(ii) for any predictable process V ≥0 on (0, ∞)×S and predictable measure-
valued process ρ on S, the process Yt =
 Vt,sρt(ds) is again predictable.
Proof of Theorem 22.22: Since ξ is locally integrable, we may easily con-
struct a predictable process V > 0 on R+ × S such that E
 V dξ < ∞. If
the random measure ζ = V · ξ has compensator ˆζ, then by Lemma 22.23
the measure ˆξ = V −1 · ˆζ is the compensator of ξ. Thus, we may henceforth
assume that Eξ(S × (0, ∞)) = 1.
Write η = ξ(S × ·). Using the kernel operation ⊗of Chapter 1, we may
introduce the probability measure µ = P ⊗ξ on Ω×R+×S and its projection

22. Predictability, Compensation, and Excessive Functions
423
ν = P ⊗η onto Ω×R+. Applying Theorem 5.3 to the restrictions of µ and ν
to the σ-ﬁelds P ⊗S and P, respectively, we conclude that there exists some
probability kernel ρ from (Ω× R+, P) to (S, S) satisfying µ = ν ⊗ρ, or
P ⊗ξ = P ⊗η ⊗ρ
on (Ω× R+ × S, P × S).
Letting ˆη denote the compensator of η, we may introduce the random measure
ˆξ = ˆη ⊗ρ on R+ × S.
To see that ˆξ is the compensator of ξ, we ﬁrst note that ˆξ is predictable by
Lemma 22.23 (i). Next we consider an arbitrary predictable process V ≥0
on R+ × S, and note that the process Ys =
 Vs,tρt(ds) is again predictable
by Lemma 22.23 (ii). By Theorem 5.4 and Lemma 22.13 we get
E

V dˆξ = E

ˆη(dt)

Vs,tρt(ds) = E

η(dt)

Vs,tρt(ds) = E

V dξ.
It remains to note that ˆξ is a.s. unique by Lemma 22.13.
✷
Our next aim is to show how point processes satisfying a weak regularity
condition can be transformed to Poisson by means of suitable predictable
mappings. This will lead to various time-change results for point processes,
similar to the results for continuous local martingales in Chapter 16.
By an S-marked point process on (0, ∞) we mean an integer-valued ran-
dom measure ξ on (0, ∞) × S such that a.s. ξ([t] × S) ≤1 for all t > 0.
The condition implies that ξ is locally integrable, and so the associated com-
pensator ˆξ exists automatically. We say that ξ is quasi–left-continuous if
ξ([τ] × S) = 0 a.s. for every predictable time τ.
Theorem 22.24 (predictable mapping to Poisson) Fix a Polish space S and
a σ-ﬁnite measure space (S′, µ), let ξ be a quasi–left-continuous S-marked
point process on (0, ∞) with compensator ˆξ, and let T be a predictable map-
ping from R+ × S to S′ with ˆξ ◦T −1 = µ a.s. Then η = ξ ◦T −1 is a Poisson
process on S′ with Eη = µ.
Proof: For any disjoint measurable sets B1, . . . , Bn in S′ with ﬁnite µ-
measure, we need to show that ηB1, . . . , ηBn are independent Poisson random
variables with means µB1, . . . , µBn.
Then introduce for each k ≤n the
processes
Jk
t =

S

 t+
0
1Bk(Ts,x) ξ(ds dx),
ˆJk
t =

S

 t
0 1Bk(Ts,x) ˆξ(ds dx).
Here ˆJk
∞= µBk < ∞a.s. by hypothesis, so each Jk is a simple and integrable
point process on R+ with compensator ˆJk. For ﬁxed u1, . . . , un ≥0 we deﬁne
Xt =

k≤n{ukJk
t −(1 −e−uk) ˆJk
t },
t ≥0.

424
Foundations of Modern Pobability
The process Mt = e−Xt has bounded variation and ﬁnitely many jumps,
so by an elementary change of variables
Mt −1
=

s≤t∆e−Xs −

 t
0 e−XsdXc
s
=

k≤n

 t+
0
e−Xs−(1 −e−uk)d( ˆJk
s −Jk
s ).
Here the integrands are bounded and predictable, so M is a uniformly inte-
grable martingale, and we get EM∞= 1. Thus,
E exp

−

kukηBk

= exp

−

k(1 −e−uk)µBk

,
and the assertion follows by Theorem 4.3.
✷
The preceding theorem immediately yields a corresponding Poisson char-
acterization, similar to the characterization of Brownian motion in Theorem
16.3. The result may also be considered as an extension of Theorem 10.11.
Corollary 22.25 (Poisson characterization, Watanabe) Fix a Polish space
S and a measure µ on (0, ∞) × S with µ({t} × S) = 0 for all t > 0. Let ξ be
an S-marked, F-adapted point process on (0, ∞) with compensator ˆξ. Then
ξ is F-Poisson with Eξ = µ iﬀˆξ = µ a.s.
We may further deduce a basic time-change result, similar to Proposition
16.8 for continuous local martingales.
Corollary 22.26 (time-change to Poisson, Papangelou, Meyer)
Let N 1,
. . . , N n be counting processes on R+ with simple sum
	
k N k and a.s. un-
bounded and continuous compensators ˆN 1, . . . , ˆN n, and deﬁne τ k
s =inf{t > 0;
ˆN k > s} and Y k
s = N k(τ k
s ). Then Y 1, . . . , Y n are independent unit-rate Pois-
son processes.
Proof:
We may apply Theorem 22.24 to the random measures ξ =
(ξ1, . . . , ξn) and ˆξ = (ˆξ1, . . . , ξn) on {1, . . . , n} × R+ induced by (N 1, . . . , N n)
and ( ˆN 1, . . . , ˆN n), respectively, and to the predictable mapping Tk,t = (k, ˆN k
t )
on {1, . . . , n} × R+. It is then enough to verify that, a.s. for ﬁxed k and t,
ˆξk{s ≥0; ˆN k
s ≤t} = t,
ξk{s ≥0; ˆN k
s ≤t} = N k(τ k
t ),
which is clear by the continuity of ˆN k.
✷
There is a similar result for stochastic integrals with respect to p-stable
L´evy processes, as described in Proposition 13.9. For simplicity we consider
only the case when p < 1.
Proposition 22.27 (time-change of stable integrals) For a p ∈(0, 1), let X
be a strictly p-stable L´evy process, and consider a predictable process V ≥0
such that the process A = V p · λ is a.s. ﬁnite but unbounded. Deﬁne τs =
inf{t; At > s}, s ≥0. Then (V · X) ◦τ
d= X.

22. Predictability, Compensation, and Excessive Functions
425
Proof: Deﬁne a point process ξ on R+×(R\{0}) by ξB =
	
s 1B(s, ∆Xs),
and recall from Corollary 13.7 and Proposition 13.9 that ξ is Poisson with
intensity measure of the form λ ⊗ν, where ν(dx) = c±|x|−p−1dx for ±x > 0.
In particular, ξ has compensator ˆξ = λ ⊗ν. Let the predictable mapping
T on R+ × R be given by Ts,x = (As, xVs). Since A is continuous, we have
{As ≤t} = {s ≤τt} and Aτt = t. By Fubini’s theorem, we hence obtain for
any t, u > 0
(λ ⊗ν) ◦T −1([0, t] × (u, ∞))
=
(λ ⊗ν){(s, x); As ≤t, xVs > u}
=

 τt
0
ν{x; xVs > u}ds
=
ν(u, ∞)

 τt
0
V p
s ds = t ν(u, ∞),
and similarly for the sets [0, t] × (−∞, −u). Thus, ˆξ ◦T −1 = ˆξ = λ ⊗ν a.s.,
and so Theorem 22.24 yields ξ ◦T −1 d= ξ. Finally, we note that
(V · X)τt
=

 τt+
0

xVs ξ(ds dx) =

 ∞
0

xVs1{As ≤t} ξ(ds dx)
=

 t+
0

y (ξ ◦T −1)(dr dy),
where the process on the right has the same distribution as X.
✷
We turn to an important special case where the compensator can be
computed explicitly. By the natural compensator of a random measure ξ we
mean the compensator with respect to the induced ﬁltration.
Proposition 22.28 (natural compensator) Fix a Polish space (S, S), and
let (τ, ζ) be a random element in (0, ∞]×S with distribution µ. Then ξ = δτ,ζ
has the natural compensator
ˆξtB =

(0,t∧τ]
µ(dr × B)
µ([r, ∞] × S),
t ≥0, B ∈S.
(6)
Proof: The process ηtB on the right of (6) is clearly predictable for every
B ∈S. It remains to show that Mt = ξtB −ηtB is a martingale, hence
that E[Mt −Ms; A] = 0 for any s < t and A ∈Fs. Since Mt = Ms on
{τ ≤s}, and the set {τ > s} is a.s. an atom of Fs, it suﬃces to show that
E(Mt −Ms) = 0, or EMt ≡0. Then use Fubini’s theorem to get
EηtB
=
E

(0,t∧τ]
µ(dr × B)
µ([r, ∞] × S)
=

(0,∞] µ(dx)

(0,t∧x]
µ(dr × B)
µ([r, ∞] × S)
=

(0,t]
µ(dr × B)
µ([r, ∞] × S)

[r,∞] µ(dx) = µ((0, t] × B) = EξtB.
✷

426
Foundations of Modern Pobability
We shall now consider some applications to classical potential theory.
Then ﬁx a domain D ⊂Rd, and let Tt = T D
t
denote the transition operators
of Brownian motion X in D, killed at the boundary ∂D. A function f ≥0
on D is said to be excessive if Ttf ≤f for all t > 0 and Ttf →f as
t →0. In this case clearly Ttf ↑f. Note that if f is excessive, then f(X)
is a supermartingale under Px for every x ∈D. The basic example of an
excessive function is the Green potential GDν of a measure ν on a Greenian
domain D, provided this potential is ﬁnite.
Though excessivity is deﬁned globally in terms of the operators T D
t , it is
in fact a local property. For a precise statement, we say that a measurable
function f ≥0 on D is superharmonic if, for any ball B in D with center x,
the average of f over the sphere ∂B is bounded by f(x). As we shall see, it is
enough to consider balls in D of radius less than an arbitrary ε > 0. Recall
that f is lower semicontinuous if xn →x implies lim infn f(xn) ≥f(x).
Theorem 22.29 (superharmonic and excessive functions, Doob) Let f ≥0
be a measurable function on some domain D ⊂Rd. Then f is excessive iﬀ
it is superharmonic and lower semicontinuous.
For the proof we shall need two lemmas, the ﬁrst of which clariﬁes the
relation between the two continuity properties.
Lemma 22.30 (semicontinuity) Consider a measurable function f ≥0 on
some domain D ⊂Rd such that Ttf ≤f for all t > 0. Then f is excessive
iﬀit is lower semicontinuous.
Proof: First assume that f is excessive, and let xn →x in D. By Theorem
21.7 and Fatou’s lemma
Ttf(x)
=

pD
t (x, y)f(y)dy ≤lim inf
n→∞

pD
t (xn, y)f(y)dy
=
lim inf
n→∞Ttf(xn) ≤lim inf
n→∞f(xn),
and as t →0, we get f(x) ≤lim infn f(xn). Thus, f is lower semicontinuous.
Next assume that f is lower semicontinuous. Using the continuity of X
and Fatou’s lemma, we get as t →0 along an arbitrary sequence
f(x)
=
Exf(X0) ≤Ex lim inf
t→0
f(Xt) ≤lim inf
t→0
Exf(Xt)
=
lim inf
t→0
Ttf(x) ≤lim sup
t→0
Ttf(x) ≤f(x).
Thus, Ttf →f, and f is excessive.
✷
For smooth functions the superharmonic property is easy to describe.
Lemma 22.31 (smooth functions) A function f ≥0 in C2(D) is superhar-
monic iﬀ∆f ≤0, in which case f is also excessive.

22. Predictability, Compensation, and Excessive Functions
427
Proof: By Itˆo’s formula, the process
Mt = f(Xt) −1
2

 t
0 ∆f(Xs)ds,
t ∈[0, ζ),
(7)
is a continuous local martingale. Now ﬁx any closed ball B ⊂D with center
x, and write τ = τ∂B. Since Exτ < ∞, we get by dominated convergence
f(x) = Exf(Xτ) −1
2Ex

 τ
0 ∆f(Xs)ds.
Thus, f is superharmonic iﬀthe last expectation is ≤0, and the ﬁrst assertion
follows.
To prove the last statement, we note that the exit time ζ = τ∂D is pre-
dictable, say with announcing sequence (τn). If ∆f ≤0, we get from (7) by
optional sampling
Ex[f(Xt∧τn); t < ζ] ≤Exf(Xt∧τn) ≤f(x).
Hence, Fatou’s lemma yields Ex[f(Xt); t < ζ] = Ttf(x), and so f is excessive
by Lemma 22.30.
✷
Proof of Theorem 22.29: If f is excessive or superharmonic, then Lemma
22.30 shows that f ∧n has the same property for every n > 0. The con-
verse statement is also true—by monotone convergence and because the lower
semicontinuity is preserved by increasing limits. Thus, we may henceforth
assume that f is bounded.
Now assume that f is excessive on D. By Lemma 22.30 it is then lower
semicontinuous, so it remains to prove that f is superharmonic. Since the
property Ttf ≤f is preserved by passing to a subdomain, we may assume
that D is bounded.
For each h > 0 we deﬁne qh = h−1(f −Thf) and
fh = GDqh. Since f and D are bounded, we have GDf < ∞, and so fh =
h−1  h
0 Tsfds ↑f. By the strong Markov property it is further seen that, for
any optional time τ < ζ,
Exfh(Xτ)
=
ExEXτ

 ∞
0
qh(Xs)ds = Ex

 ∞
0
qh(Xs+τ)ds
=
Ex

 ∞
τ
qh(Xs)ds ≤fh(x).
In particular, fh is superharmonic for each h, and so by monotone conver-
gence the same thing is true for f.
Conversely, assume that f is superharmonic and lower semicontinuous.
To prove that f is excessive, it is enough by Lemma 22.30 to show that
Ttf ≤f for all t.
Then ﬁx a spherically symmetric probability density
ψ ∈C∞(Rd) with support in the unit ball, and put ψh(x) = h−dψ(x/h)
for each h > 0. Writing ρ for the Euclidean metric in Rd, we may deﬁne
fh = ψh ∗f on the set Dh = {x ∈D; ρ(x, Dc) > h}. Note that fh ∈C∞(Dh)

428
Foundations of Modern Pobability
for all h, that fh is superharmonic on Dh, and that fh ↑f. By Lemma 22.31
and monotone convergence we conclude that f is excessive on each set Dh.
Letting ζh denote the ﬁrst exit time from Dh, we obtain
Ex[f(Xt); t < ζh] ≤f(x),
h > 0.
As h →0, we have ζh ↑ζ and hence {t < ζh} ↑{t < ζ}. Thus, by monotone
convergence Ttf(x) ≤f(x).
✷
In view of the fact that excessive functions f need not be continuous, it
is remarkable that the supermartingale f(X) is a.s. continuous under Px for
every x.
Theorem 22.32 (continuity, Doob) Fix an excessive function f on some
domain D ⊂Rd, and let X be a Brownian motion killed at ∂D. Then the
process f(Xt) is a.s. continuous on [0, ζ).
The proof is based on the following invariance under time reversal of a
“stationary” version of Brownian motion. Here we are considering “distri-
butions” with respect to the σ-ﬁnite measure P =
 Pxdx, where Px is the
distribution of a Brownian motion in Rd starting at x.
Lemma 22.33 (time reversal, Doob) For any c > 0, the processes Yt = Xt
and ˜Yt = Xc−t on [0, c] are equally distributed under P.
Proof: Introduce the processes
Bt = Xt −X0,
˜Bt = Xc−t −Xc,
t ∈[0, c],
and note that B and ˜B are Brownian motions on [0, c] under each Px. Fix
any measurable function f ≥0 on C([0, c], Rd). By Fubini’s theorem and the
invariance of Lebesgue measure, we get
Ef(˜Y )
=
Ef(X0 −˜Bc + ˜B) =

Exf(x −˜Bc + ˜B) dx
=

E0f(x −˜Bc + ˜B) dx = E0

f(x −˜Bc + ˜B) dx
=
E0

f(x + ˜B) dx =

Exf(Y ) dx = Ef(Y ).
✷
Proof of Theorem 22.32: Since f ∧n is again excessive for each n > 0 by
Theorem 22.29, we may assume that f is bounded. As in the proof of the
same theorem, we may then approximate f by smooth excessive functions
fh ↑f on suitable subdomains Dh ↑D. Since fh(X) is a continuous super-
martingale up to the exit time ζh from Dh, Theorem 6.32 shows that f(X)
is a.s. right-continuous on [0, ζ) under any initial distribution µ. Using the
Markov property at rational times, we may extend the a.s. right-continuity
to the random time set T = {t ≥0; Xt ∈D}.

22. Predictability, Compensation, and Excessive Functions
429
To strengthen the result to a.s. continuity on T, we note that f(X) is
right-continuous on T, a.e. P. By Lemma 22.33 it follows that f(X) is also
left-continuous on T, a.e. P. Thus, f(X) is continuous on T, a.s. under Pµ
for arbitrary µ ≪λd. Since Pµ ◦X−1
h
≪λd for any µ and h > 0, we may
conclude that f(X) is a.s. continuous on T ∩[h, ∞) for any h > 0. This to-
gether with the right-continuity at 0 yields the asserted continuity on [0, ζ). ✷
If f is excessive, then f(X) is a supermartingale under Px for every x,
and so it has a Doob–Meyer decomposition f(X) = M −A. It is remarkable
that we can choose A to be a continuous additive functional (CAF) of X
independent of x. A similar situation was encountered in connection with
Theorem 19.23.
Theorem 22.34 (compensation by additive functional, Meyer) Let f be an
excessive function on some domain D ⊂Rd, and let Px denote the distribu-
tion of Brownian motion in D, killed at ∂D. Then there exists an a.s. unique
CAF A of X such that M = f(X) + A is a continuous, local Px-martingale
on [0, ζ) for every x ∈D.
The main diﬃculty in the proof is constructing a version of the process A
that compensates −f(X) under every measure Pµ. Here the following lemma
is helpful.
Lemma 22.35 (universal compensation) Consider an excessive function f
on some domain D ⊂Rd, a distribution m ∼λd on D, and a Pm-compensa-
tor A of −f(X) on [0, ζ). Then for any distribution µ and constant h > 0,
the process A ◦θh is a Pµ-compensator of −f(X ◦θh) on [0, ζ ◦θh).
In other words, the process Mt = f(Xt)+At−h◦θh is a local Pµ-martingale
on [h, ζ) for every µ and h.
Proof: For any bounded Pm-martingale M and initial distribution µ ≪m,
we note that M is also a Pµ-martingale. To see this, write k = dµ/dm, and
note that Pµ = k(X0) · Pm. It is equivalent to show that Nt = k(X0)Mt is a
Pm-martingale, which is clear since k(X0) is F0-measurable with mean 1.
Now ﬁx an arbitrary distribution µ and a constant h > 0. To prove the
stated property of A, it is enough to show for any bounded Pm-martingale
M that the process Nt = Mt−h ◦θh is a Pµ-martingale on [h, ∞). Then ﬁx
any times s < t and sets F ∈Fh and G ∈Fs. Using the Markov property at
h and noting that Pµ ◦X−1
h
≪m, we get
Eµ[Mt ◦θh; F ∩θ−1
h G]
=
Eµ[EXh[Mt; G]; F]
=
Eµ[EXh[Ms; G]; F]
=
Eµ[Ms ◦θh; F ∩θ−1
h G].
Hence, by a monotone class argument, Eµ[Mt ◦θh|Fh+s] = Ms ◦θh a.s.
✷

430
Foundations of Modern Pobability
Proof of Theorem 22.34: Let Aµ denote the Pµ-compensator of −f(X) on
[0, ζ), and note that Aµ is a.s. continuous, e.g. by Theorem 16.10. Fix any
distribution m ∼λd on D, and conclude from Lemma 22.35 that Am ◦θh is a
Pµ-compensator of −f(X ◦θh) on [0, ζ ◦θh) for any µ and h > 0. Since this
is also true for the process Aµ
t+h −Aµ
h, we get for any µ and h > 0
Aµ
t = Aµ
h + Am
t−h ◦θh,
t ≥h, a.s. Pµ.
(8)
Restricting h to the positive rationals, we may deﬁne
At = lim
h→0 Am
t−h ◦θh,
t > 0,
whenever the limit exists and is continuous and nondecreasing with A0 = 0,
and put A = 0 otherwise. By (8) we have A = Aµ a.s. Pµ for every µ, and
so A is a Pµ-compensator of −f(X) on [0, ζ) for every µ. For each h > 0
it follows by Lemma 22.35 that A ◦θh is a Pµ-compensator of −f(X ◦θh)
on [0, ζ ◦θh), and since this is also true for the process At+h −Ah, we get
At+h = Ah + At ◦θh a.s. Pµ. Thus, A is a CAF.
✷
We may now establish a probabilistic version of the classical Riesz decom-
position. To avoid technical diﬃculties, we restrict our attention to locally
bounded functions f. By the greatest harmonic minorant of f we mean a
harmonic function h ≤f that dominates all other such functions. Recall
that the potential UA of a CAF A of X is given by UA(x) = ExA∞.
Theorem 22.36 (Riesz decomposition)
Fix any locally bounded function
f ≥0 on some domain D ⊂Rd, and let X be Brownian motion on D, killed
at ∂D. Then f is excessive iﬀit has a representation f = UA +h, where A is
a CAF of X and h is harmonic with h ≥0. In that case A is the compensator
of −f(X), and h is the greatest harmonic minorant of f.
A similar result for uniformly α-excessive functions of an arbitrary Feller
process was obtained in Theorem 19.23. From the classical Riesz represen-
tation on Greenian domains, we know that UA may also be written as the
Green potential of a unique measure νA, so that f = GDνA + h. In the
special case when D = Rd with d ≥3, we recall from Theorem 19.21 that
νAB = E(1B · A)1. A similar representation holds in the general case.
Proof of Theorem 22.36: First assume that A is a CAF with UA < ∞.
By the additivity of A and the Markov property of X, we get for any t > 0
UA(x)
=
ExA∞= Ex(At + A∞◦θt)
=
ExAt + ExEXtA∞= ExAt + TtUA(x).
By dominated convergence ExAt ↓0 as t →0, and so UA is excessive. Even
UA + h is then excessive for any harmonic function h ≥0.

22. Predictability, Compensation, and Excessive Functions
431
Conversely, assume that f is excessive and locally bounded. By Theorem
22.34 there exists some CAF A such that M = f(X)+A is a continuous local
martingale on [0, ζ). For any localizing and announcing sequence τn ↑ζ, we
get
f(x) = ExM0 = ExMτn = Exf(Xτn) + ExAτn ≥ExAτn.
As n →∞, it follows by monotone convergence that UA ≤f.
By the additivity of A and the Markov property of X,
Ex[A∞|Ft]
=
At + Ex[A∞◦θt|Ft]
=
At + EXtA∞= Mt −f(Xt) + UA(Xt).
(9)
Writing h = f −UA, it follows that h(X) is a continuous local martingale.
Since h is locally bounded, we may conclude by optional sampling and dom-
inated convergence that h has the mean-value property. Thus, h is harmonic
by Lemma 21.3.
To prove the uniqueness of A, assume that f also has a representation
UB + k for some CAF B and some harmonic function k ≥0. Proceeding as
in (9), we get
At −Bt = Ex[A∞−B∞|Ft] + h(Xt) −k(Xt),
t ≥0,
so A−B is a continuous local martingale, and Proposition 15.2 yields A = B
a.s.
To see that h is the greatest harmonic minorant of f, consider any har-
monic minorant k ≥0. Since f −k is again excessive and locally bounded,
it has a representation UB + l for some CAF B and some harmonic function
l. But then f = UB + k + l, so A = B a.s. and h = k + l ≥k.
✷
For any suﬃciently regular measure ν on Rd, we may now construct an
associated CAF A of Brownian motion X such that A increases only when
X visits the support of ν. This clearly extends the notion of local time. For
convenience we may write GD(1D · ν) = GDν.
Proposition 22.37 (additive functionals induced by measures) Fix a mea-
sure ν on Rd such that U(1D · ν) is bounded for every bounded domain D.
Then there exists an a.s. unique CAF A of Brownian motion X such that
for any D
ExAζD = GDν(x),
x ∈D.
(10)
Conversely, ν is uniquely determined by A. Furthermore,
supp A ⊂{t ≥0; Xt ∈supp ν} a.s.
(11)
The proof is straightforward, given the classical Riesz decomposition, and
we shall indicate the main steps only.

432
Foundations of Modern Pobability
Proof: A simple calculation shows that GDν is excessive for any bounded
domain D. Since GDν ≤U(1D·ν), it is further bounded. Hence, by Theorem
22.36 there exist a CAF AD of X on [0, ζD) and a harmonic function hD ≥0
such that GDν = UAD + hD. In fact, hD = 0 by Riesz’ theorem.
Now consider another bounded domain D′ ⊃D, and note that GD′ν −
GDν is harmonic on D. (This is clear from the analytic deﬁnitions, and it
also follows under a regularity condition from Lemma 21.13.) Since AD and
AD′ are compensators of −GDν(X) and −GD′ν(X), respectively, we may
conclude that AD −AD′ is a martingale on [0, ζD), and so AD = AD′ a.s. up
to time ζD. Now choose a sequence of bounded domains Dn ↑Rd, and deﬁne
A = supn ADn, so that A = AD a.s. on [0, ζD) for all D.
It is easy to see that A is a CAF of X, and that (10) holds for any
bounded domain D. The uniqueness of ν is clear from the uniqueness in the
classical Riesz decomposition. Finally, we obtain (11) by noting that GDν is
harmonic on D \ supp ν for every D, so that GDν(X) is a local martingale
on the predictable set {t < ζD; Xt ̸∈supp ν}.
✷
Exercises
1. Show by an example that the σ-ﬁelds Fτ and Fτ−may diﬀer. (Hint:
Take τ to be constant.)
2. Give examples of optional times that are predictable; accessible but
not predictable; and totally inaccessible. (Hint: Use Corollary 22.18.)
3. Show by an example that a right-continuous, adapted process need
not be predictable. (Hint: Use Theorem 22.14.)
4. Show by an example that the compensator of an increasing, locally
integrable process may depend on the ﬁltration.
Further show that any
optional time can be made predictable by a change of ﬁltration.
5. Show that any increasing, predictable process has accessible jumps.
6. Show that the compensator A of a quasi–left-continuous local sub-
martingale is a.s. continuous. (Hint: Note that A has accessible jumps. Use
optional sampling at an arbitrary predictable time τ < ∞with announcing
sequence (τn).)
7. Extend Corollary 22.26 to possibly bounded compensators.
8. Show that any general inequality involving an increasing process A
and its compensator ˆA remains valid in discrete time. (Hint: Embed the
discrete-time process and ﬁltration into continuous time.)

Chapter 23
Semimartingales and General
Stochastic Integration
Predictable covariation and L2-integral; semimartingale integral
and covariation; general substitution rule; Dol´eans’ exponential
and change of measure; norm and exponential inequalities; mar-
tingale integral; decomposition of semimartingales; quasi-martin-
gales and stochastic integrators
In this chapter we shall use the previously established Doob–Meyer decom-
position to extend the stochastic integral of Chapter 15 to possibly discon-
tinuous semimartingales. The construction proceeds in three steps. First
we imitate the deﬁnition of the L2-integral V · M from Chapter 15, using a
predictable version ⟨M, N⟩of the covariation process. A suitable truncation
then allows us to extend the integral to arbitrary semimartingales X and
bounded, predictable processes V . The ordinary covariation [X, Y ] can now
be deﬁned by the integration-by-parts formula, and we may use a generalized
version of the BDG inequalities from Chapter 15 to extend the martingale
integral V · M to more general integrands V .
Once the stochastic integral is deﬁned, we may develop a stochastic cal-
culus for general semimartingales. In particular, we shall prove an extension
of Itˆo’s formula, solve a basic stochastic diﬀerential equation, and establish
a general Girsanov-type theorem for absolutely continuous changes of the
probability measure. The latter material extends the appropriate portions of
Chapters 16 and 18.
The stochastic integral and covariation process, together with the Doob–
Meyer decomposition from the preceding chapter, provide the tools for a
more detailed analysis of semimartingales. Thus, we may now establish two
general decompositions, similar to the decompositions of optional times and
increasing processes in Chapter 22. We shall further derive some exponential
inequalities for martingales with bounded jumps, characterize local quasi-
martingales as special semimartingales, and show that no continuous exten-
sion of the predictable integral exists beyond the context of semimartingales.
Throughout this chapter, M2 denotes the class of uniformly square-
integrable martingales. As in Lemma 15.4, we note that M2 is a Hilbert
space for the norm ∥M∥= (EM 2
∞)1/2. We deﬁne M2
0 as the closed linear
subspace of martingales M ∈M2 with M0 = 0. The corresponding classes
433

434
Foundations of Modern Probability
M2
loc and M2
0,loc are deﬁned as the sets of processes M such that the stopped
versions M τn belong to M2 or M2
0, respectively, for some sequence of optional
times τn →∞.
For every M ∈M2
loc we note that M 2 is a local submartingale. The cor-
responding compensator, denoted by ⟨M⟩, is called the predictable quadratic
variation of M. More generally, we may deﬁne the predictable covariation
⟨M, N⟩of two processes M, N ∈M2
loc as the compensator of MN, also
computable by the polarization formula
4⟨M, N⟩= ⟨M + N⟩−⟨M −N⟩.
Note that ⟨M, M⟩= ⟨M⟩. If M and N are continuous, then clearly ⟨M, N⟩=
[M, N] a.s. The following result collects some further useful properties.
Proposition 23.1 (predictable covariation) For any M, M n, N ∈M2
loc,
(i) ⟨M, N⟩= ⟨M −M0, N −N0⟩a.s.;
(ii) ⟨M⟩is a.s. increasing, and ⟨M, N⟩is a.s. symmetric and bilinear;
(iii) |⟨M, N⟩| ≤
 |d⟨M, N⟩| ≤⟨M⟩1/2⟨N⟩1/2 a.s.;
(iv) ⟨M, N⟩τ = ⟨M τ, N⟩= ⟨M τ, N τ⟩a.s. for any optional time τ;
(v) ⟨M n⟩∞
P→0 implies (M n −M n
0 )∗
P→0.
Proof: By Lemma 22.11 we note that ⟨M, N⟩is the a.s. unique predictable
process of locally integrable variation and starting at 0 such that MN −
⟨M, N⟩is a local martingale. The symmetry and bilinearity in (ii) follow
immediately, as does property (i), since MN0, M0N, and M0N0 are all local
martingales. Property (iii) is proved in the same way as Proposition 15.10,
and (iv) is obtained as in Theorem 15.5.
To prove (v), we may assume that M n
0 = 0 for all n. Let ⟨M n⟩∞
P→0.
Fix any ε > 0, and deﬁne τn = inf{t; ⟨M n⟩t ≥ε}.
Since ⟨M n⟩is pre-
dictable, even τn is predictable by Theorem 22.14 and is therefore announced
by some sequence τnk ↑τn. The latter may be chosen such that M n is an L2-
martingale and (M n)2 −⟨M n⟩a uniformly integrable martingale on [0, τnk]
for every k. By Proposition 6.16
E(M n)∗2
τnk <
⌢E(M n)2
τnk = E⟨M n⟩τnk ≤ε,
and as k →∞, we get E(M n)∗2
τn−<
⌢ε. Now ﬁx any δ > 0, and write
P{(M n)∗2 > δ} ≤P{τn < ∞} + 1
δE(M n)∗2
τn−<
⌢P{⟨M n⟩∞≥ε} + ε
δ.
Here the right-hand side tends to zero as n →∞and then ε →0.
✷
We shall now use the predictable quadratic variation to extend the Itˆo
integral from Chapter 15. As before, we let E denote the class of bounded,
predictable step processes V with jumps at ﬁnitely many ﬁxed times. The

23. Semimartingales and General Stochastic Integration
435
corresponding integral V · X will be referred to as the elementary predictable
integral.
Given any M ∈M2
loc, let L2(M) be the class of predictable processes
V such that (V 2 · ⟨M⟩)t < ∞a.s. for every t > 0. We shall ﬁrst consider
integrals V · M with M ∈M2
loc and V ∈L2(M). Here the integral process
belongs to M2
0,loc, the class of local L2-martingales starting at 0.
In the
following statement it is understood that M, N ∈M2
loc and that U and V
are predictable processes such that the stated integrals exist.
Theorem 23.2 (L2-integral, Courr`ege, Kunita and Watanabe)
The ele-
mentary predictable integral extends a.s. uniquely to a bilinear map of any
M ∈M2
loc and V ∈L2(M) into V ·M ∈M2
0,loc, such that if (V 2
n ·⟨Mn⟩)t
P→0
for some Vn ∈L2(Mn) and t > 0, then (Vn · Mn)∗
t
P→0. It has the following
additional properties, the ﬁrst of which characterizes the integral:
(i) ⟨V · M, N⟩= V · ⟨M, N⟩a.s. for all N ∈M2
loc;
(ii) U · (V · M) = (UV ) · M a.s.;
(iii) ∆(V · M) = V ∆M a.s.;
(iv) (V · M)τ = V · M τ = (V 1[0,τ]) · M a.s. for any optional time τ.
For the proof we need an elementary approximation property, correspond-
ing to Lemma 15.24 in the continuous case.
Lemma 23.3 (approximation) Let V be a predictable process with |V |p ∈
L(A), where A is increasing and p ≥1. Then there exist some V1, V2, . . . ∈E
with (|Vn −V |p · A)t →0 a.s. for all t > 0.
Proof: It is enough to establish the approximation (|Vn −V |)p · A)t
P→0.
By Minkowski’s inequality we may then approximate in steps, and by dom-
inated convergence we may ﬁrst reduce to the case when V is simple. Each
term may then be approximated separately, and so we may next assume that
V = 1B for some predictable set B. Approximating separately on disjoint
intervals, we may ﬁnally reduce to the case when B ⊂Ω× [0, t] for some
t > 0. The desired approximation is then obtained from Lemma 22.1 by a
monotone class argument.
✷
Proof of Theorem 23.2: As in Theorem 15.12, we may construct the inte-
gral V · M as the a.s. unique element of M2
0,loc satisfying (i). The mapping
(V, M) →V · M is clearly bilinear, and by the analogue of Lemma 15.11 it
extends the elementary predictable integral. Properties (ii) and (iv) may be
obtained in the same way as in Propositions 15.15 and 15.16. The stated
continuity property follows immediately from (i) and Proposition 23.1 (v).
To get the stated uniqueness, it is then enough to apply Lemma 23.3 with
A = ⟨M⟩and p = 2.

436
Foundations of Modern Probability
To prove (iii), we note from Lemma 23.3 with At = ⟨M⟩t +
	
s≤t(∆Ms)2
that there exist some processes Vn ∈E satisfying Vn∆M →V ∆M and
(Vn · M −V · M)∗→0 a.s. In particular, ∆(Vn · M) →∆(V · M) a.s., so (iii)
follows from the corresponding relation for the elementary integrals Vn · M.
The argument relies on the fact that 	
s≤t(∆Ms)2 < ∞a.s. To verify this,
we may assume that M ∈M2
0 and deﬁne tn,k = kt2−n for k ≤2n. By Fatou’s
lemma
E

s≤t(∆Ms)2
≤
E lim inf
n→∞

k(Mtn,k −Mtn,k−1)2
≤
lim inf
n→∞E

k(Mtn,k −Mtn,k−1)2 = EM 2
t < ∞.
✷
A semimartingale is deﬁned as a right-continuous, adapted process X
admitting a decomposition M + A, where M is a local martingale and A
is a process of locally ﬁnite variation starting at 0. If A has even locally
integrable variation, we may write X = (M + A −ˆA) + ˆA, where ˆA denotes
the compensator of A, and so we can then choose A to be predictable. In that
case the decomposition is a.s. unique by Propositions 15.2 and 22.16, and X
is called a special semimartingale with canonical decomposition M + A.
L´evy processes are the basic examples of semimartingales. In particular,
we note that a L´evy process is a special semimartingale iﬀits L´evy measure
ν satisﬁes
 (x2 ∧|x|)ν(dx) < ∞. From Theorem 22.5 it is further seen that
any local submartingale is a special semimartingale.
The next result extends the stochastic integration to general semimartin-
gales. At this stage we shall consider only locally bounded integrands, which
covers most applications of interest.
Theorem 23.4 (semimartingale integral, Dol´eans-Dade and Meyer)
The
L2-integral of Theorem 23.2 and the ordinary Lebesgue–Stieltjes integral ex-
tend a.s. uniquely to a bilinear mapping of any semimartingale X and locally
bounded, predictable process V into a semimartingale V · X. The mapping
satisﬁes properties (ii)—(iv) of Theorem 23.2, and for any locally bounded,
predictable processes V, V1, V2, . . . with V ≥|Vn| →0, we have (Vn · X)∗
t
P→0
for all t > 0. If X is a local martingale, then so is V · X.
Our proof relies on the following basic decomposition.
Lemma 23.5 (truncation, Dol´eans-Dade, Jacod and M´emin, Yan) Any lo-
cal martingale M can be decomposed into two local martingales M ′ and M ′′,
where M ′ has locally integrable variation and |∆M ′′| ≤1 a.s.
Proof: Deﬁne
At =

s≤t∆Ms1{|∆Ms| > 1
2},
t ≥0.
By optional sampling, we note that A has locally integrable variation. Let
ˆA denote the compensator of A, and put M ′ = A −ˆA and M ′′ = M −M ′.

23. Semimartingales and General Stochastic Integration
437
Then M ′ and M ′′ are again local martingales, and M ′ has locally integrable
variation. Furthermore,
|∆M ′′| ≤|∆M −∆A| + |∆ˆA| ≤1
2 + |∆ˆA|,
so it suﬃces to show that |∆ˆA| ≤1
2. Since the constructions of A and ˆA com-
mute with optional stopping, we may then assume that M and M ′ are uni-
formly integrable. Now ˆA is predictable, so the times τ = n∧inf{t; |∆ˆA| > 1
2}
are predictable by Theorem 22.14, and it is enough to show that |∆ˆAτ| ≤1
2
a.s. Clearly, E[∆Mτ|Fτ−] = E[∆M ′
τ|Fτ−] = 0 a.s., and so by Lemma 22.3
|∆ˆAτ|
=
|E[∆Aτ|Fτ−]| = |E[∆Mτ; |∆Mτ| > 1
2|Fτ−]|
=
|E[∆Mτ; |∆Mτ| ≤1
2|Fτ−]| ≤1
2.
✷
Proof of Theorem 23.4: By Lemma 23.5 we may write X = M +A, where
M is a local martingale with bounded jumps, hence a local L2-martingale,
and A has locally ﬁnite variation.
For any locally bounded, predictable
process V we may then deﬁne V · X = V · M + V · A, where the ﬁrst term is
the integral in Theorem 23.2, and the second term is an ordinary Lebesgue–
Stieltjes integral. If V ≥|Vn| →0, then (V 2
n · ⟨M⟩)t →0 and (Vn · A)∗
t →0
by dominated convergence, and so Theorem 23.2 yields (Vn · X)∗
t
P→0 for all
t > 0.
To prove the uniqueness, it suﬃces to prove that if M = A is a local L2-
martingale of locally ﬁnite variation, then V ·M = V ·A a.s. for every locally
bounded, predictable process V , where V ·M is the integral in Theorem 23.2
and V · A is an elementary Stieltjes integral. The two integrals clearly agree
when V ∈E. For general V , we may approximate as in Lemma 23.3 by
processes Vn ∈E such that ((Vn −V )2 · ⟨M⟩)∗→0 and (|Vn −V | · A)∗→0
a.s. But then (Vn · M)t
P→(V · M)t and (Vn · A)t →(V · A)t for every t > 0,
and the desired equality follows.
To prove the last assertion, we may reduce by means of Lemma 23.5 and
a suitable localization to the case when V is bounded and X has integrable
variation A. By Lemma 23.3 we may next choose some uniformly bounded
processes V1, V2, . . . ∈E such that (|Vn −V | · A)t →0 a.s. for every t ≥0.
Then (Vn · X)t →(V · X)t a.s. for all t, and by dominated convergence this
remains true in L1. Thus, the martingale property of Vn · X carries over to
V · X.
✷
For any semimartingales X and Y , the left-continuous versions X−=
(Xt−) and Y−= (Yt−) are locally bounded and predictable, so they can serve
as integrands in the general stochastic integral.
We may then deﬁne the
quadratic variation [X] and covariation [X, Y ] by the integration-by-parts
formulas

438
Foundations of Modern Probability
[X]
=
X2 −X2
0 −2X−· X,
[X, Y ]
=
XY −X0Y0 −X−· Y −Y−· X
=
([X + Y ] −[X −Y ])/4.
(1)
Here we list some basic properties of the covariation.
Theorem 23.6 (covariation) For any semimartingales X and Y ,
(i) [X, Y ] = [X −X0, Y −Y0] a.s.;
(ii) [X] is a.s. nondecreasing, and [X, Y ] is a.s. symmetric and bilinear;
(iii) |[X, Y ]| ≤
 |d[X, Y ]| ≤[X]1/2[Y ]1/2 a.s.;
(iv) ∆[X] = (∆X)2 and ∆[X, Y ] = ∆X∆Y a.s.;
(v) [V · X, Y ] = V · [X, Y ] a.s. for any locally bounded, predictable V ;
(vi) [Xτ, Y ] = [Xτ, Y τ] = [X, Y ]τ a.s. for any optional time τ;
(vii) if M, N ∈M2
loc, then [M, N] has compensator ⟨M, N⟩;
(viii) if A has locally ﬁnite variation, then [X, A]t =
	
s≤t ∆Xs∆As a.s.
Proof: The symmetry and bilinearity of [X, Y ] are obvious from (1), and
to get (i) it remains to check that [X, Y0] = 0.
(ii) We may extend Proposition 15.18 with the same proof to general
semimartingales. In particular, [X]s ≤[X]t a.s. for any s ≤t. By right-
continuity the exceptional null set can be chosen to be independent of s
and t, so [X] is a.s. nondecreasing. Relation (iii) may now be proved as in
Proposition 15.10.
(iv) By (1) and Theorem 23.2 (iii),
∆[X, Y ]t
=
∆(XY )t −∆(X−· Y )t −∆(Y−· X)t
=
XtYt −Xt−Yt−−Xt−∆Yt −Yt−∆Xt = ∆Xt∆Yt.
(v) For V ∈E the relation follows most easily from the extended version
of Proposition 15.18. Also note that both sides are a.s. linear in V . Now let
V, V1, V2, . . . be locally bounded and predictable with V ≥|Vn| →0. Then
Vn · [X, Y ] →0 by dominated convergence, and by Theorem 23.4 we have
[Vn · X, Y ] = (Vn · X)Y −(Vn · X)−· Y −(VnY−) · X
P→0.
Using a monotone class argument, we may now extend the relation to arbi-
trary V .
(vi) This follows from (v) with V = 1[0,τ].
(vii) Since M−·N and N−·M are local martingales, the assertion follows
from (1) and the deﬁnition of ⟨M, N⟩.
(viii) For step processes A the stated relation follows from the extended
version of Proposition 15.18. Now assume instead that ∆A ≤ε, and conclude

23. Semimartingales and General Stochastic Integration
439
from the same result and property (iii) together with the ordinary Cauchy–
Buniakovsky inequality that
[X, A]2
t ∨


s≤t∆Xs∆As

2 ≤[X]t[A]t ≤ε[X]t

 t
0 |dAs|.
The assertion now follows by a simple approximation.
✷
We may now extend the Itˆo formula of Theorem 15.19 to a substitution
rule for general semimartingales. By a semimartingale in Rd we mean a pro-
cess X = (X1, . . . , Xd) such that each component Xi is a one-dimensional
semimartingale.
Let [Xi, Xj]c denote the continuous components of the
ﬁnite-variation processes [Xi, Xj], and write f ′
i and f ′′
ij for the ﬁrst- and
second-order partial derivatives of f, respectively. Summation over repeated
indices is understood as before.
Theorem 23.7 (substitution rule, Kunita and Watanabe) Let X = (X1,
. . . , Xd) be a semimartingale in Rd, and ﬁx any f ∈C2(Rd). Then
f(Xt)
=
f(X0) +

 t
0 f ′
i(Xs−)dXi
s + 1
2

 t
0 f ′′
ij(Xs−)d[Xi, Xj]c
s
+

s≤t{∆f(Xs) −f ′
i(Xs−)∆Xi
s}.
(2)
Proof: Assuming that (2) holds for some function f ∈C2(Rd), we shall
prove for any k ∈{1, . . . , n} that (2) remains true for g(x) = xkf(x). Then
note that by (1)
g(X) = g(X0) + Xk
−· f(X) + f(X−) · Xk + [Xk, f(X)].
(3)
Writing ˆf(x, y) = f(x) −f(y) −f ′
i(y)(xi −yi), we get by (2) and property
(ii) of Theorem 23.2
Xk
−· f(X)
=
Xk
−f ′
i(X−) · Xi + 1
2Xk
−f ′′
ij(X−) · [Xi, Xj]c
+

sXk
s−ˆf(Xs, Xs−).
(4)
Next we note that, by properties (ii), (iv), (v), and (viii) of Theorem 23.6,
[Xk, f(X)]
=
f ′
i(X−) · [Xk, Xi] +

s∆Xk
s ˆf(Xs, Xs−)
=
f ′
i(X−) · [Xk, Xi]c +

s∆Xk
s ∆f(Xs).
(5)
Inserting (4) and (5) into (3), and using the elementary formulas
g′
i(x)
=
δikf(x) + xkf ′
i(x),
g′′
ij(x)
=
δikf ′
j(x) + δjkf ′
i(x) + xkf ′′
ij(x),
ˆg(x, y)
=
(xk −yk)(f(x) −f(y)) + yk ˆf(x, y),
we obtain after some simpliﬁcation the desired expression for g(X).

440
Foundations of Modern Probability
Equation (2) is trivially true for constant functions, and it extends by in-
duction and linearity to arbitrary polynomials. Now any function f ∈C2(Rd)
may be approximated by polynomials, in such a way that all derivatives up
to the second order tend uniformly to those of f on every compact set. To
prove (2) for f, it is then enough to show that the right-hand side tends to
zero in probability, as f and its ﬁrst- and second-order derivatives tend to
zero, uniformly on compact sets.
For the two integrals in (2), this is clear by the dominated convergence
property of Theorem 23.4, and it remains to consider the last term. Writing
Bt = {x ∈Rd; |x| ≤X∗
t } and ∥g∥B = supB |g|, we get by Taylor’s formula in
Rd

s≤t
| ˆf(Xs, Xs−)| <
⌢

i,j
∥f ′′
i,j∥Bt

s≤t
|∆Xs|2 ≤

i,j
∥f ′′
i,j∥Bt

i
[Xi]t →0.
The same estimate shows that the last term has locally ﬁnite variation.
✷
To illustrate the use of the general substitution rule, we shall prove a
partial extension of Proposition 18.2 to general semimartingales.
Theorem 23.8 (Dol´eans’ exponential) For any semimartingale X with X0
= 0, the equation Z = 1 + Z−· X has the a.s. unique solution
Zt = E(X) ≡exp(Xt −1
2[X]c
t)

s≤t(1 + ∆Xs)e−∆Xs,
t ≥0.
(6)
Note that the inﬁnite product in (6) is a.s. absolutely convergent, since
	
s≤t(∆Xs)2 ≤[X]t < ∞. However, we may have ∆Xs = −1 for some s > 0,
in which case Z = 0 for t ≥s. The process E(X) in (6) is called the Dol´eans
exponential of X. When X is continuous, we get E(X) = exp(X −1
2[X]),
in agreement with the notation of Lemma 16.21. For processes A of locally
ﬁnite variation, formula (6) simpliﬁes to
E(A) = exp(Ac
t)

s≤t(1 + ∆As),
t ≥0.
Proof of Theorem 23.8: To check that (6) is a solution, we may write
Z = f(Y, V ), where Y = X−1
2[X]c, V =
(1+∆X)e−∆X, and f(y, v) = eyv.
By Theorem 23.7 we get
Z −1
=
Z−· Y + eY−· V + 1
2Z−· [X]c
+
 
∆Z −Z−∆X −eY−∆V

.
(7)
Now eY−· V =
	 eY−∆V since V is of pure jump type, and furthermore
∆Z = Z−∆X. Hence, the right-hand side of (7) simpliﬁes to Z−· X, as
desired.

23. Semimartingales and General Stochastic Integration
441
To prove the uniqueness, let Z be an arbitrary solution, and put V =
Ze−Y , where Y = X −1
2[X]c as before. By Theorem 23.7 we get
V −1
=
e−Y−· Z −V−· Y + 1
2V−· [X]c −e−Y−· [X, Z]c
+
 
∆V + V−∆Y −e−Y−∆Z

=
V−· X −V−· X + 1
2V−· [X]c + 1
2V−· [X]c −V−· [X]c
+

{∆V + V−∆X −V−∆X}
=

∆V.
Thus, V is a purely discontinuous process of locally ﬁnite variation. We may
further compute
∆V
=
Ze−Y −Z−e−Y−= (Z−+ ∆Z)e−Y−−∆Y −Z−e−Y−
=
V−

(1 + ∆X)e−∆X −1

,
which shows that V = 1 + V−· A, with A =
	{(1 + ∆X)e−∆X −1}.
It remains to show that the homogeneous equation V = V−· A has the
unique solution V = 0.
Then deﬁne Rt =

(0,t] |dA|, and conclude from
Theorem 23.7 and the convexity of the function x →xn that
Rn = nRn−1
−
· R +

(∆Rn −nRn−1
−
∆R) ≥nRn−1
−
· R.
(8)
We may now prove by induction that
V ∗
t ≤V ∗
t Rn
t /n!,
t ≥0, n ∈Z+.
(9)
This is obvious for n = 0, and assuming (9) to be true for n−1, we get by (8)
V ∗
t = (V−· A)∗
t ≤
1
(n −1)!V ∗
t (Rn−1
−
· R)t ≤1
n!V ∗
t Rn
t ,
as required. Since Rn
t /n! →0 as n →∞, relation (9) yields V ∗
t = 0 for all
t > 0.
✷
The equation Z = 1 + Z−· X arises naturally in connection with changes
of probability measure. The following result extends Proposition 16.20 to
general local martingales.
Theorem 23.9 (change of measure, van Schuppen and Wong) Assume for
each t ≥0 that Q = Zt · P on Ft, and consider a local P-martingale M such
that the process [M, Z] has locally integrable variation and P-compensator
⟨M, Z⟩. Then ˜
M = M −Z−1
−· ⟨M, Z⟩is a local Q-martingale.
A lemma will be needed for the proof.
Lemma 23.10 (integration by parts) If X is a semimartingale and A is a
predictable process of locally ﬁnite variation, then AX = A · X + X−· A a.s.

442
Foundations of Modern Probability
Proof: We need to show that ∆A · X = [A, X] a.s., which by Theorem
23.6 (viii) is equivalent to

(0,t] ∆AsdXs =

s≤t∆As∆Xs,
t ≥0.
Here the sum on the right is absolutely convergent by the Cauchy-Buniakov-
sky inequality, so by dominated convergence on both sides, we may reduce to
the case when A is constant, apart from ﬁnitely many jumps. Using Lemma
22.3 and Theorem 22.14, we may next reduce to the case when A has at most
one jump, occurring at some predictable time τ. Introducing an announcing
sequence (τn) and writing Y = ∆A · X, we get by property (iv) of Theorem
23.2
Yτn∧t = 0 = Yt −Yt∧τ a.s.,
t ≥0, n ∈N.
Thus, even Y is constant apart from a possible jump at τ. Finally, property
(iii) of Theorem 23.2 yields ∆Yτ = ∆Aτ∆Xτ a.s. on {τ < ∞}.
✷
Proof of Theorem 23.9: For each n ∈N let τn = inf{t; Zt < 1/n}, and
note that τn →∞a.s. Q by Lemma 16.17. Hence, ˜
M is well deﬁned under Q,
and it suﬃces as in Lemma 16.15 to show that ( ˜
MZ)τn is a local P-martingale
for every n. Writing
m∼for equality apart from a local P-martingale, we may
conclude from Lemma 23.10 with X = Z and A = Z−1
−· ⟨M, Z⟩that, on
every interval [0, τn],
MZ
m∼[M, Z]
m∼⟨M, Z⟩= Z−· A
m∼AZ.
Thus, we get ˜
MZ = (M −A)Z
m∼0, as required.
✷
Using the last theorem, we may easily show that the class of semimartin-
gales is invariant under absolutely continuous changes of the probability mea-
sure. A special case of this statement was obtained as part of Proposition
16.20.
Corollary 23.11 (preservation law, Jacod) If Q ≪P on Ft for all t > 0,
then every P-semimartingale is also a Q-semimartingale.
Proof: Assume that Q = Zt · P on Ft for all t ≥0. We need to show
that every local P-martingale M is a Q-semimartingale. By Lemma 23.5 we
may then assume ∆M to be bounded, so that [M] is locally bounded. By
Theorem 23.9 it suﬃces to show that [M, Z] has locally integrable variation,
and by Theorem 23.6 (iii) it is then enough to prove that [Z]1/2 is locally
integrable. Now Theorem 23.6 (iv) yields
[Z]1/2
t
≤[Z]1/2
t−+ |∆Zt| ≤[Z]1/2
t−+ Z∗
t−+ |Zt|,
t ≥0,
and so the desired integrability follows by optional sampling.
✷

23. Semimartingales and General Stochastic Integration
443
Our next aim is to extend the BDG inequalities in Proposition 15.7 to
general local martingales. Such an extension turns out to be possible only
for exponents p ≥1.
Theorem 23.12 (norm inequalities, Burkholder, Davis, Gundy) There ex-
ist some constants cp ∈(0, ∞), p ≥1, such that for any local martingale M
with M0 = 0,
c−1
p E[M]p/2
∞≤EM ∗p ≤cpE[M]p/2
∞,
p ≥1.
(10)
As in Corollary 15.9, it follows in particular that M is a uniformly inte-
grable martingale whenever E[M]1/2
∞< ∞.
Proof for p = 1 (Davis): To exploit the symmetry of the argument, we
write M ♭and M ♯for the processes M ∗and [M]1/2, taken in either order. Put
J = ∆M, and deﬁne
At =

s≤tJs1{|Js| > 2J∗
s−},
t ≥0.
Since |∆A| ≤2∆J∗, we have

 ∞
0
|dAs| =

s|∆As| ≤2J∗≤4M ♯
∞.
Writing ˆA for the compensator of A and putting D = A −ˆA, we get
ED♭
∞∨ED♯
∞≤E

 ∞
0
|dDs| <
⌢E

 ∞
0
|dAs| <
⌢EM ♯
∞.
(11)
To get a similar estimate for N = M −D, we introduce the optional times
τr = inf{t; N ♯
t ∨J∗
t > r},
r > 0,
and note that
P{N ♭
∞> r}
≤
P{τr < ∞} + P{τr = ∞, N ♭
∞> r}
≤
P{N ♯
∞> r} + P{J∗> r} + P{N ♭
τr > r}.
(12)
Arguing as in the proof of Lemma 23.5, we get |∆N| ≤4J∗
−, and so
N ♯
τr ≤N ♯
∞∧(N ♯
τr−+ 4J∗
τr−) ≤N ♯
∞∧5r.
Since N 2 −[N] is a local martingale, we get by Chebyshev’s inequality or
Proposition 6.15, respectively,
r2P{N ♭
τr > r} <
⌢EN ♯2
τr <
⌢E(N ♯
∞∧r)2.
Hence, by Fubini’s theorem and elementary calculus,

 ∞
0
P{N ♭
τr > r}dr <
⌢

 ∞
0
E(N ♯
∞∧r)2r−2dr <
⌢EN ♯
∞.

444
Foundations of Modern Probability
Combining this with (11)—(12) and using Lemma 2.4, we get
EN ♭
∞
=

 ∞
0
P{N ♭
∞> r}dr
≤

 ∞
0

P{N ♯
∞> r} + P{J∗> r} + P{N ♭
τr > r}

dr
<
⌢
EN ♯
∞+ EJ∗<
⌢EM ♯
∞.
It remains to note that EM ♭
∞≤ED♭
∞+ EN ♭
∞.
✷
Extension to p > 1 (Garsia): For any t ≥0 and B ∈Ft, we may apply
(10) with p = 1 to the local martingale 1B(M −M t) to get a.s.
c−1
1 E[[M −M t]1/2
∞|Ft] ≤E[(M −M t)∗
∞|Ft] ≤c1E[[M −M t]1/2
∞|Ft].
Since
[M]1/2
∞−[M]1/2
t
≤[M −M t]1/2
∞
≤[M]1/2
∞,
M ∗
∞−M ∗
t ≤(M −M t)∗
∞≤2M ∗
∞,
the relation E[A∞−At|Ft] <
⌢E[ζ|Ft] required in Proposition 22.21 holds
with At = [M]1/2
t
and ζ = M ∗, as well as with At = M ∗
t and ζ = [M]1/2
∞.
Since also
∆M ∗
t ≤∆[M]1/2
t
= |∆Mt| ≤[M]1/2
t
∧2M ∗
t ,
we get in both cases ∆Aτ <
⌢E[ζ|Fτ] a.s. for every optional time τ, and so the
condition remains true for the left-continuous version A−. The proposition
then yields ∥A∞∥p <
⌢∥ζ∥p for every p ≥1, and (10) follows.
✷
We may use the last theorem to extend the stochastic integral to a larger
class of integrands. Then write M for the space of local martingales and M0
for the subclass of processes M with M0 = 0. For any M ∈M, let L(M)
denote the class of predictable processes V such that (V 2 · [M])1/2 is locally
integrable.
Theorem 23.13 (martingale integral, Meyer) The elementary predictable
integral extends a.s. uniquely to a bilinear map of any M ∈M and V ∈L(M)
into V · M ∈M0, such that if V, V1, V2, . . . ∈L(M) with |Vn| ≤V and
(V 2
n · [M])t
P→0 for some t > 0, then (Vn · M)∗
t
P→0. The mapping satisﬁes
properties (ii)—(iv) of Theorem 23.2, and it is further characterized by the
condition
[V · M, N] = V · [M, N] a.s.,
N ∈M.
(13)
Proof: For the construction of the integral, we may reduce by localization
to the case when E(M −M0)∗< ∞and E(V 2 · [M])1/2
∞
< ∞. For each
n ∈N deﬁne Vn = V 1{|V | ≤n}. Then Vn · M ∈M0 by Theorem 23.4, and

23. Semimartingales and General Stochastic Integration
445
by Theorem 23.12 we have E(Vn · M)∗< ∞. Using Theorems 23.6 (v) and
23.12, Minkowski’s inequality, and dominated convergence, we obtain
E(Vm · M −Vn · M)∗
<
⌢
E[(Vm −Vn) · M]1/2
∞
=
E((Vm −Vn)2 · [M])1/2
∞→0.
Hence, there exists a process V ·M with E(Vn ·M −V ·M)∗→0, and clearly
V · M ∈M0 and E(V · M)∗∞.
To prove (13), we note that the relation holds for each Vn by Theorem
23.6 (v). Since E[Vn · M −V · M]1/2
∞
→0 by Theorem 23.12, we get by
Theorem 23.6 (iii) for any N ∈M and t ≥0
|[Vn · M, N]t −[V · M, N]t| ≤[Vn · M −V · M]1/2
t
[N]1/2
t
P→0.
(14)
Next we note that, by Theorem 23.6 (iii) and (v),

 t
0 |Vnd[M, N]| =

 t
0 |d[Vn · M, N]| ≤[Vn · M]1/2
t
[N]1/2
t
.
As n →∞, we get by monotone convergence on the left and Minkowski’s
inequality on the right

 t
0 |V d[M, N]| ≤[V · M]1/2
t
[N]1/2
t
< ∞.
Hence, by dominated convergence Vn · [M, N] →V · [M, N], and (13) follows
by combination with (14).
To see that (13) determines V · M, it remains to note that if [M] = 0
a.s. for some M ∈M0, then M ∗= 0 a.s. by Theorem 23.12. To prove the
stated continuity property, we may reduce by localization to the case when
E(V 2·[M])1/2
∞< ∞. But then E(V 2
n ·[M])1/2
∞→0 by dominated convergence,
and Theorem 23.12 yields E(Vn · M)∗→0.
To prove the uniqueness of
the integral, it is enough to consider bounded integrands V . We may then
approximate as in Lemma 23.3 by uniformly bounded processes Vn ∈E with
((Vn −V )2 · [M])
P→0, and conclude that (Vn · M −V · M)∗
P→0.
Of the remaining properties in Theorem 23.2, relation (ii) may be proved
as before by means of (13), whereas (iii) and (iv) follow most easily by trun-
cation from the corresponding statements in Theorem 23.4.
✷
A semimartingale X = M + A is said to be purely discontinuous if there
exist some local martingales M 1, M 2, . . . of locally ﬁnite variation such that
E(M −M n)∗2 →0 for every t > 0. The property is clearly independent
of the choice of decomposition X = M + A. To motivate the terminology,
we note that any martingale M of locally ﬁnite variation may be written as
M = M0 + A −ˆA, where At =
	
s≤t ∆Ms and ˆA denotes the compensator of
A. Thus, M −M0 is in this case a compensated sum of jumps.

446
Foundations of Modern Probability
The reader should be cautioned that, although every process of locally
ﬁnite variation is a purely discontinuous semimartingale, it may not be purely
discontinuous in the sense of real analysis.
We shall now establish a fundamental decomposition of a general semi-
martingale X into a continuous and a purely discontinuous component, cor-
responding to the elementary decomposition of the quadratic variation [X]
into a continuous part and a jump part.
Theorem 23.14 (decomposition of semimartingales, Yoeurp, Meyer) Any
semimartingale X has an a.s. unique decomposition X = X0 + Xc + Xd,
where Xc is a continuous local martingale with Xc
0 = 0 and Xd is a purely
discontinuous semimartingale. Furthermore, [Xc] = [X]c and [Xd] = [X]d
a.s.
Proof: To decompose X it is enough to consider the martingale compo-
nent in any decomposition X = X0 + M + A, and by Lemma 23.5 we may
assume that M ∈M2
0,loc. We may then choose some optional times τn ↑∞
such that M τn ∈M2
0 for each n. It is enough to construct the desired de-
composition for each process M τn −M τn−1, where τ0 = 0, which reduces the
discussion to the case when M ∈M2
0. Now let C and D denote the classes of
continuous and purely discontinuous processes in M2
0, and note that both are
closed linear subspaces of the Hilbert space M2
0. The desired decomposition
will follow from Theorem 1.34 if we can show that D⊥⊂C.
Then let M ∈D⊥. To see that M is continuous, ﬁx any ε > 0, and put
τ = inf{t; ∆Mt > ε}. Deﬁne At = 1{τ ≤t}, let ˆA denote the compensator
of A, and put N = A −ˆA. Integrating by parts and using Lemma 22.13, we
get
1
2E ˆA2
τ ≤E

ˆAd ˆA = E

ˆAdA = E ˆAτ = EAτ ≤1,
so N is L2-bounded and hence lies in D. For any bounded martingale M ′,
EM ′
∞N∞
=
E

M ′dN = E

∆M ′dN
=
E

∆M ′dA = E[∆M ′
τ; τ < ∞],
where the ﬁrst equality is obtained as in the proof of Lemma 22.7, the second
is due to the predictability of M ′
−, and the third holds since ˆA is predictable
and hence natural. Letting M ′ →M in M2, we obtain
0 = EM∞N∞= E[∆Mτ; τ < ∞] ≥εP{τ < ∞}.
Thus, ∆M ≤ε a.s., and since ε is arbitrary we get ∆M ≤0 a.s. Similarly,
∆M ≥0 a.s., and the desired continuity follows.
Next assume that M ∈D and N ∈C, and choose martingales of locally
ﬁnite variation M n →M.
By Theorem 23.6 (vi) and (vii) and optional
sampling, we get for any optional time τ

23. Semimartingales and General Stochastic Integration
447
0 = E[M n, N]τ = EM n
τ Nτ →EMτNτ = E[M, N]τ,
and so [M, N] is a martingale by Lemma 6.13. By (15) it is also continuous,
so Proposition 15.2 yields [M, N] = 0 a.s. In particular, EM∞N∞= 0, which
shows that C ⊥D. The uniqueness assertion now follows easily.
To prove the last assertion, conclude from Theorem 23.6 (iv) that for any
M ∈M2
[M]t = [M]c
t +

s≤t(∆Ms)2,
t ≥0.
(15)
Now let M ∈D, and choose martingales of locally ﬁnite variation M n →M.
By Theorem 23.6 (vii) and (viii) we have [M n]c = 0 and E[M n −M]∞→0.
For any t ≥0, we get by Minkowski’s inequality and (15)


s≤t(∆M n
s )21/2 −

s≤t(∆Ms)21/2 ≤

s≤t(∆M n
s −∆Ms)21/2
≤[M n −M]1/2
t
P→0,
[M n]1/2
t
−[M]1/2
t
 ≤[M n −M]1/2
t
P→0.
Taking limits in relation (15) for M n, we get the formula for M without the
term [M]c
t, which shows that [M] = [M]d.
Now consider any M ∈M2. Using the strong orthogonality [M c, M d] =
0, we get a.s.
[M]c + [M]d = [M] = [M c + M d] = [M c] + [M d],
which shows that even [M c] = [M]c a.s. By the same argument together with
Theorem 23.6 (viii) we obtain [Xd] = [X]d a.s. for any semimartingale X. ✷
The last result immediately yields an explicit formula for the covariation
of two semimartingales.
Corollary 23.15 (decomposition of covariation)
For any semimartingale
X, the process Xc is the a.s. unique continuous local martingale M with
M0 = 0 such that [X −M] is purely discontinuous. Furthermore, we have
a.s. for any semimartingales X and Y
[X, Y ]t = [Xc, Y c] +

s≤t∆Xs∆Ys,
t ≥0.
(16)
In particular, we note that (V · X)c = V · Xc a.s. for any semimartingale
X and locally bounded, predictable process V .
Proof: If M has the stated properties, then [(X −M)c] = [X −M]c = 0
a.s., and so (X −M)c = 0 a.s. Thus, X −M is purely discontinuous. Formula
(16) holds by Theorem 23.6 (iv) and Theorem 23.14 when X = Y , and the
general result follows by polarization.
✷
The purely discontinuous component of a local martingale has a further
decomposition, similar to the decompositions of optional times and increasing
processes in Propositions 22.4 and 22.17.

448
Foundations of Modern Probability
Proposition 23.16 (decomposition of martingales, Yoeurp) Any purely dis-
continuous local martingale M has an a.s. unique decomposition M = M0 +
M q + M a with M q, M a ∈M0 purely discontinuous, such that M q is quasi–
left-continuous and M a has accessible jumps. Furthermore, there exist some
predictable times τ1, τ2, . . . with disjoint graphs such that {t; ∆M a
t ̸= 0} ⊂

n[τn] a.s. Finally, [M q] = [M]q and [M a] = [M]a a.s., and when M ∈M2
loc
we have ⟨M q⟩= ⟨M⟩c and ⟨M a⟩= ⟨M⟩d a.s.
Proof: Introduce the locally integrable process At =
	
s≤t{(∆Ms)2 ∧1}
with compensator ˆA, and deﬁne M q = M −M0 −M a = 1{∆ˆAt = 0} · M.
By Theorem 23.4 we have M q, M a ∈M0 and ∆M q = 1{∆ˆA = 0}∆M a.s.
Furthermore, M q and M a are purely discontinuous by Corollary 23.15. The
proof may now be completed as in the case of Proposition 22.17.
✷
We shall illustrate the use of the previous decompositions by proving two
exponential inequalities for martingales with bounded jumps.
Theorem 23.17 (exponential inequalities) Let M be a local martingale with
M0 = 0 such that |∆M| ≤c for some constant c ≤1. If also [M]∞≤1 a.s.,
we have
P{M ∗≥r} <
⌢exp{−1
2r2/(1 + rc)},
r ≥0,
(17)
whereas if ⟨M⟩∞≤1 a.s., then
P{M ∗≥r} <
⌢exp{−1
2r log(1 + rc)/c},
r ≥0.
(18)
For continuous martingales both bounds reduce to e−r2/2, which can also
be obtained directly by more elementary methods. For the proof of Theorem
23.17 we need two lemmas. We begin with a characterization of certain pure
jump-type martingales.
Lemma 23.18 (accessible jump-type martingales) Let N be a pure jump-
type process with integrable variation and accessible jumps.
Then N is a
martingale iﬀE[∆Nτ|Fτ−] = 0 a.s. for every ﬁnite predictable time τ.
Proof: By Proposition 22.17 there exist some predictable times τ1, τ2, . . .
with disjoint graphs such that {t > 0; ∆Nt ̸= 0} ⊂

n[τn].
Assuming
the stated condition, we get by Fubini’s theorem and Lemma 22.2 for any
bounded optional time τ
ENτ =

nE[∆Nτn; τn ≤τ] =

nE[E[∆Nτn|Fτn−]; τn ≤τ] = 0,
so N is a martingale by Lemma 6.13. Conversely, given any uniformly inte-
grable martingale N and ﬁnite predictable time τ, we have a.s. E[Nτ|Fτ−] =
Nτ−and hence E[∆Nτ|Fτ−] = 0.
✷

23. Semimartingales and General Stochastic Integration
449
For general martingales M, the process Z = eM−[M]/2 in Lemma 16.21 is
not necessarily a martingale. For many purposes, however, it can be replaced
by a similar supermartingale.
Lemma 23.19 (exponential supermartingales) Let M be a local martingale
with M0 = 0 and |∆M| ≤c < ∞a.s., and put a = f(c) and b = g(c), where
f(x) = −(x + log(1 −x)+)x−2,
g(x) = (ex −1 −x)x−2.
Then the processes X = eM−a[M] and Y = eM−b⟨M⟩are supermartingales.
Proof: In case of X we may clearly assume that c < 1. By Theorem 23.7
we get, in an obvious shorthand notation,
X−1
−· X = M −(a −1
2)[M]c +
 
e∆M−a(∆M)2 −1 −∆M

.
Here the ﬁrst term on the right is a local martingale, and the second term
is nonincreasing since a ≥1
2. To see that even the sum is nonincreasing, we
need to show that exp(x −ax2) ≤1 + x or f(−x) ≤f(c) whenever |x| ≤c.
But this is clear by a Taylor expansion of each side. Thus, X−1
−· X is a local
supermartingale, and since X > 0, the same thing is true for X−·(X−1
−·X) =
X. By Fatou’s lemma it follows that X is a true supermartingale.
In the case of Y , we may decompose M according to Theorem 23.14 and
Proposition 23.16 as M = M c + M q + M a, and conclude by Theorem 23.7
that
Y −1
−
· Y
=
M −b⟨M⟩c + 1
2[M]c +
 
e∆M−b∆⟨M⟩−1 −∆M

=
M + b([M q] −⟨M q⟩) −(b −1
2)[M]c
+
 
e∆M−b∆⟨M⟩−1 + ∆M + b(∆M)2
1 + b∆⟨M⟩

+
 1 + ∆M a + b(∆M a)2
1 + b∆⟨M a⟩
−1 −∆M a

.
Here the ﬁrst two terms on the right are martingales, and the third term is
nonincreasing since b ≥1
2. Even the ﬁrst sum of jumps is nonincreasing since
ex −1 −x ≤bx2 for |x| ≤c and ey ≤1 + y for y ≥0.
The last sum clearly deﬁnes a purely discontinuous process N of locally
ﬁnite variation and with accessible jumps. Fixing any ﬁnite predictable time
τ and writing ξ = ∆Mτ and η = ∆⟨M⟩τ, we note that
E

1 + ξ + bξ2
1 + bη
−1 −ξ

≤
E|1 + ξ + bξ2 −(1 + ξ)(1 + bη)|
=
bE|ξ2 −(1 + ξ)η| ≤b(2 + c)Eξ2.
Since
E

t(∆Mt)2 ≤E[M]∞= E⟨M⟩∞≤1,

450
Foundations of Modern Probability
we conclude that the total variation of N is integrable. Using Lemmas 22.3
and 23.18, we also note that a.s. E[ξ|Fτ−] = 0 and
E[ξ2|Fτ−] = E[∆[M]τ|Fτ−] = E[η|Fτ−] = η.
Thus,
E
" 1 + ξ + bξ2
1 + bη
−1 −ξ
 Fτ−
#
= 0,
and Lemma 23.18 shows that N is a martingale. The proof may now be
completed as before.
✷
Proof of Theorem 23.17: First assume that [M] ≤1 a.s. Fix any u > 0,
and conclude from Lemma 23.19 that the process
Xu
t = exp{uMt −u2f(uc)[M]t},
t ≥0,
is a positive supermartingale. Since [M] ≤1 and Xu
0 = 1, we get for any
r > 0
P{suptMt > r} ≤P{suptXu
t > eur−u2f(uc)} ≤e−ur+u2f(uc).
(19)
Now deﬁne F(x) = 2xf(x), and note that F is continuous and strictly in-
creasing from [0, 1) onto R+. Also note that F(x) ≤x/(1 −x) and hence
F −1(y) ≥y/(1 + y). Taking u = F −1(rc)/c in (19), we get
P{suptMt > r} ≤exp{−1
2rF −1(rc)/c} ≤exp{−1
2r2/(1 + rc)}.
Combining this with the same inequality for −M, we obtain (17).
If instead ⟨M⟩≤1 a.s., we may deﬁne G(x) = 2xg(x), and note that
G is a continuous and strictly increasing mapping onto R+. Furthermore,
G(x) ≤ex −1, and so G−1(y) ≥log(1 + y). Proceeding as before, we get
P{suptMt > r} ≤exp{−1
2rG−1(rc)/c} ≤exp{−1
2r log(1 + rc)/c},
and (18) follows.
✷
A quasi-martingale is deﬁned as an integrable, adapted, and right-contin-
uous process X such that
sup
π

k≤nE
Xtk −E[Xtk+1|Ftk]
 < ∞,
(20)
where the supremum extends over all ﬁnite partitions π of R+ of the form
0 = t0 < t1 < · · · < tn < ∞, and the last term is computed under the
conventions tn+1 = ∞and X∞= 0. In particular, we note that (20) holds
when X is the sum of an L1-bounded martingale and a process of integrable
variation starting at 0. The next result shows that this case is close to the
general situation. Here localization is deﬁned in the usual way in terms of a
sequence of optional times τn ↑∞.

23. Semimartingales and General Stochastic Integration
451
Theorem 23.20 (quasi-martingales, Rao) Any quasi-martingale is the dif-
ference between two nonnegative supermartingales. Thus, a process X with
X0 = 0 is a local quasi-martingale iﬀit is a special semimartingale.
Proof: For any t ≥0, let Pt denote the class of partitions π of the interval
[t, ∞) of the form t = t0 < t1 < · · · < tn, and deﬁne
η±
π =

k≤nE

(Xtk −E[Xtk+1|Ftk])±
 Ft

,
π ∈Pt,
where tn+1 = ∞and X∞= 0 as before. We claim that η+
π and η−
π are a.s.
nondecreasing under reﬁnements of π ∈Pt. To see this, it is clearly enough
to add one more division point u to π, say in the interval (tk, tk+1). Put
α = Xtk −Xu and β = Xu −Xtk+1. By subadditivity and Jensen’s inequality
we get the desired relation
E[E[α + β|Ftk]±|Ft]
≤
E [E[α|Ftk]± + E[β|Ftk]±| Ft]
≤
E [E[α|Ftk]± + E[β|Fu]±| Ft] .
Now ﬁx any t ≥0, and conclude from (20) that m±
t ≡supπ∈Pt Eη±
π < ∞.
For each n ∈N we may then choose some πn ∈Pt with Eη±
πn > m±
t −n−1.
The sequences (η±
πn) are Cauchy in L1, so they converge in L1 toward some
limits Y ±
t . Note also that E|η±
π −Y ±
t | < n−1 whenever π is a reﬁnement of
πn. Thus, η±
π →Y ±
t
in L1 along the directed set Pt.
Next ﬁx any s < t, let π ∈Pt be arbitrary, and deﬁne π′ ∈Ps by adding
the point s to π. Then
Y ±
s ≥η±
π′ = (Xs −E[Xt|Fs])± + E[η±
π |Fs] ≥E[η±
π |Fs].
Taking limits along Pt on the right, we get Y ±
s ≥E[Y ±
t |Fs] a.s., which means
that the processes Y ± are supermartingales. By Theorem 6.27 the right-hand
limits along the rationals Z±
t = Y ±
t+ then exist outside a ﬁxed null set, and
the processes Z± are right-continuous supermartingales. For π ∈Pt we have
Xt = η+
π −η−
π →Y +
t −Y −
t , and so Z+
t −Z−
t = Xt+ = Xt a.s.
✷
The next result shows that semimartingales are the most general processes
for which a stochastic integral with reasonable continuity properties can be
deﬁned. As before, E denotes the class of bounded, predictable step processes
with jumps at ﬁnitely many ﬁxed points.
Theorem 23.21 (stochastic integrators, Bichteler, Dellacherie)
A right-
continuous, adapted process X is a semimartingale iﬀfor any V1, V2, . . . ∈E
with ∥V ∗
n ∥∞→0 we have (Vn · X)t
P→0 for all t > 0.
The proof is based on three lemmas, the ﬁrst of which separates the
crucial functional-analytic part of the argument.

452
Foundations of Modern Probability
Lemma 23.22 (convexity and tightness)
For any tight, convex set K ⊂
L1(P), there exists a bounded random variable ρ > 0 with supξ∈K Eρξ < ∞.
Proof (Yan): Let B denote the class of bounded, nonnegative random
variables, and deﬁne C = {γ ∈B; supξ∈K E(γξ) < ∞}. We claim that, for
any γ1, γ2, . . . ∈C, there exists some γ ∈C with {γ > 0} =

n{γn > 0}.
Indeed, we may assume that γn ≤1 and supξ∈K E(γnξ) ≤1, in which case
we may choose γ = 	
n 2−nγn. It is then easy to construct a ρ ∈C such that
P{ρ > 0} = supγ∈C P{γ > 0}. Clearly,
{γ > 0} ⊂{ρ > 0} a.s.,
γ ∈C,
(21)
since we could otherwise choose a ρ′ ∈C with P{ρ′ > 0} > P{ρ > 0}.
To show that ρ > 0 a.s., we assume that instead P{ρ = 0} > ε > 0.
By the tightness of K we may choose r > 0 so large that P{ξ > r} ≤ε for
all ξ ∈K. Then P{ξ −β > r} ≤ε for all ξ ∈K and β ∈B. By Fatou’s
lemma we obtain P{ζ > r} ≤ε for all ζ in the L1-closure Z = K −B. In
particular, the random variable ζ0 = 2r1{ρ = 0} lies outside Z. Now Z is
convex and closed, so by a version of the Hahn–Banach theorem there exists
some γ ∈(L1)∗= L∞satisfying
sup
ξ∈K Eγξ −inf
β∈B Eγβ ≤sup
ζ∈Z Eγζ < Eγζ0 = 2rE[γ; ρ = 0].
(22)
Here γ ≥0, since we would otherwise get a contradiction by choosing
β = b1{γ < 0} for large enough b > 0. Hence, (22) reduces to supξ∈K Eγξ <
2rE[γ; ρ = 0], which implies γ ∈C and E[γ; ρ = 0] > 0. But this contradicts
(21), and therefore ρ > 0 a.s.
✷
Two further lemmas are needed for the proof of Theorem 23.21.
Lemma 23.23 (tightness and boundedness) Let T be the class of optional
times τ < ∞taking ﬁnitely many values, and consider a right-continuous,
adapted process X such that the family {Xτ; τ ∈T } is tight. Then X∗< ∞
a.s.
Proof: By Lemma 6.4 any bounded optional time τ can be approximated
from the right by optional times τn ∈T , and by right-continuity we have
Xτn →Xτ. Hence, Fatou’s lemma yields P{|Xτ| > r} ≤lim infn P{|Xτn| >
r}, and so the hypothesis remains true with T replaced by the class T of all
bounded optional times. By Lemma 6.6 the times τt,n = t ∧inf{s; |Xs| > n}
belong to T for all t > 0 and n ∈N, and as n →∞, we get
P{X∗> n} = sup
t>0 P{X∗
t > n} ≤sup
τ∈T
P{|Xτ| > n} →0.
✷
Lemma 23.24 (scaling) For any ﬁnite random variable ξ, there exists a
bounded random variable ρ > 0 with E|ρξ| < ∞.

23. Semimartingales and General Stochastic Integration
453
Proof: We may take ρ = (|ξ| ∨1)−1.
✷
Proof of Theorem 23.21: The necessity is clear from Theorem 23.4. Now
assume the stated condition. By Lemma 3.9 it is equivalent to assume for
each t > 0 that the family Kt = {(V · X)t; V ∈E1} is tight, where E1 =
{V ∈E; |V | ≤1}. The latter family is clearly convex, and by the linearity
of the integral the convexity carries over to Kt.
By Lemma 23.23 we have X∗< ∞a.s., and so by Lemma 23.24 there
exists some probability measure Q ∼P such that EQX∗
t =
 X∗
t dQ < ∞.
In particular, Kt ⊂L1(Q), and we note that Kt remains tight with respect
to Q. Hence, by Lemma 23.22 there exists some probability measure R ∼Q
with bounded density ρ = dR/dQ such that Kt is bounded in L1(R).
Now consider an arbitrary partition 0 = t0 < t1 < · · · < tn = t, and note
that

k≤nER
Xtk −ER[Xtk+1|Ftk]
 = ER(V · X)t + ER|Xt|,
(23)
where
Vs =

k<nsgn

ER[Xtk+1|Ftk] −Xtk

1(tk,tk+1](s),
s ≥0.
Since ρ is bounded and V ∈E1, the right-hand side of (23) is bounded by a
constant. Hence, the stopped process Xt is a quasi-martingale under R. By
Theorem 23.20 it is then an R-semimartingale, and since P ∼R, Corollary
23.11 shows that Xt is even a P-semimartingale. Since t is arbitrary, it fol-
lows that X itself is a P-semimartingale.
✷
Exercises
1.
Construct the quadratic variation [M] of a local L2-martingale M
directly as in Theorem 15.5, and prove a corresponding version of the inte-
gration-by-parts formula. Use [M] to deﬁne the L2-integral of Theorem 23.2.
2. Show that the approximation in Proposition 15.18 remains valid for
general semimartingales.
3. Consider a local martingale M starting at 0 and an optional time
τ. Use Theorem 23.12 to give conditions for the validity of the relations
EMτ = 0 and EM 2
τ = [M]τ.
4. Give an example of a sequence of L2-bounded martingales Mn such
that M ∗
n
P→0 and yet ⟨Mn⟩∞
P→∞. (Hint: Consider compensated Poisson
processes with large jumps.)
5. Give an example of a sequence of martingales Mn such that [Mn]∞
P→0
and yet M ∗
n
P→∞. (Hint: See the preceding problem.)
6. Show that ⟨Mn⟩∞
P→0 implies [Mn]∞
P→0.

454
Foundations of Modern Probability
7.
Give an example of a martingale M of bounded variation and a
bounded, progressive process V such that V 2 · ⟨M⟩= 0 and yet V · M ̸= 0.
Conclude that the L2-integral in Theorem 23.2 has no continuous extension
to progressive integrands.
8. Show that any general martingale inequality involving the processes
M, [M], and ⟨M⟩remains valid in discrete time. (Hint: Embed M and the
associated discrete ﬁltration into a martingale and ﬁltration on R+.)
9. Show that the a.s. convergence in Theorem 3.23 remains valid in Lp.
(Hint: Use Theorem 23.12 to reduce to the case when p < 1. Then truncate.)

Appendices
Here we list some results that play an important role in this
book but whose proofs are too long and technical to contribute
in any essential way to the understanding of the subject matter.
Proofs are given only for results that are not easily accessible in
the literature.
A1. Hard Results in Measure Theory
The basic facts of measure theory were reviewed in Chapter 1. In this ap-
pendix we list, mostly without proofs, some special or less elementary results
that are required in this book. Two of the quoted results are used more
frequently, namely the existence of Lebesgue measure in Corollary A1.2 and
the Borel nature of Polish spaces in Theorem A1.6. The remaining results
are needed only for special purposes.
We begin with a classical extension theorem. Given a set S, a family
A of subsets A ⊂S is called a ﬁeld if it is closed under ﬁnite unions and
intersections as well as under complementation. A measure on A is deﬁned
as a ﬁnitely additive function µ : A →R+ with µ∅= 0 such that µAn →0
whenever A1, A2, . . . ∈A with An ↓∅and µA1 < ∞.
Theorem A1.1 (extension, Carath´eodory) Any σ-ﬁnite measure on a ﬁeld
has a unique extension to a measure on the generated σ-ﬁeld.
Proof: See Billingsley (1986), Theorem 3.1.
✷
The next theorem asserts the existence of Lebesgue measure λ on R. Let
|I| denote the length of the interval I.
Corollary A1.2 (Lebesgue measure, Borel) There exists a unique measure
λ on (R, B) such that λI = |I| for any interval I ⊂R.
Proof: See Billingsley (1986), Sections 2 and 3.
✷
Two measures µ and ν on some measurable space (Ω, A) are said to
be orthogonal or mutually singular (written as µ ⊥ν) if µA = νAc = 0
for some A ∈A.
Recall that µ ≪ν if µA = 0 for every A ∈A with
νA = 0. The following result gives both the existence of densities and a
basic decomposition.
455

456
Foundations of Modern Probability
Theorem A1.3 (Lebesgue decomposition, Radon–Nikod´ym theorem) Let µ
and ν be σ-ﬁnite measures on some measurable space (Ω, A). Then ν has a
unique decomposition νa + νs, where νa ≪µ and νs ⊥µ. Furthermore, there
exists a µ-a.e. unique measurable function f : Ω→R+ such that νa = f · µ.
Proof: See Dudley (1989), Section 5.5.
✷
The next result extends the fundamental theorem of calculus to the con-
text of general measure theory.
Theorem A1.4 (diﬀerentiation, Lebesgue) Fix a locally ﬁnite measure µ =
f · λ + µs on R, where µs⊥λ, and consider a function F with µ(x, y] =
F(y) −F(x) for all x < y. Then F ′(x) = f(x) for x ∈R a.e. λ.
Proof: See Dudley (1989), Section 7.2.
✷
For any topological space S, let C(S) denote the class of continuous
functions f : S →R. If S is compact, then any such function is bounded,
and we may equip C(S) with the norm ∥f∥= supx |fx|. A bounded linear
functional on C(S) is deﬁned as a linear map ϕ : C(S) →R such that
∥ϕ∥≡sup{|ϕf|; ∥f∥= 1} < ∞. We say that ϕ is positive and write ϕ ≥0
if f ≥0 implies ϕf ≥0. In particular, if µ = µ+ −µ−is a bounded signed
measure on S, that is, the diﬀerence between two bounded positive measures
µ±, then the integral ϕ : f →µf ≡µ+f −µ−f deﬁnes a bounded linear
functional on C(S). A converse is given by the following result.
Theorem A1.5 (Riesz representation) Fix a compact metric space S, and
let ϕ be a bounded linear functional on C(S). Then ϕ has a unique extension
to a bounded signed measure µ on S. Furthermore, µ ≥0 iﬀϕ ≥0.
To state the next result, we say that two measurable spaces S and T are
Borel isomorphic if there exists a measurable bijection f : S →T such that
f −1 is also measurable. A Borel space is deﬁned as a measurable space that
is Borel isomorphic to a Borel subset of [0, 1]. The following result shows
that the most commonly occurring spaces are Borel.
Theorem A1.6 (Polish and Borel spaces) Any Borel-measurable subset of
a Polish space is a Borel space.
Proof: In Lemma 13.1.3 of Dudley (1989) it is shown that any Polish space
is Borel isomorphic to a Borel subset of [0, 1]∞. The latter space is in turn
Borel isomorphic to a Borel subset of [0, 1], as may be seen by an elemen-
tary argument involving binary expansions (cf. Theorem A.47 in Breiman
(1968)).
✷
If a mapping is invertible, then the measurability of the inverse can some-
times be inferred from the measurability of the range.

Appendices
457
Theorem A1.7 (range and inverse, Kuratowski)
Let f be a measurable
bijection between two Borel spaces S and T. Then even the inverse f −1 :
T →S is measurable.
Proof: See Parthasarathy (1967), Section I.3.
✷
We turn to the basic projection and section theorem, which plays such an
important role in the more advanced literature. For any measurable space
(Ω, F), the universal completion of F is deﬁned as the σ-ﬁeld F =

µ Fµ,
where Fµ denotes the completion with respect to µ, and the intersection
extends over all probability measures µ on F. For any spaces Ωand S, we
deﬁne the projection πA of a set A ⊂Ω×S onto Ωas the union 
s As, where
As = {ω ∈Ω; (ω, s) ∈A}, s ∈S.
Theorem A1.8 (projection and sections, Lusin, Choquet, Meyer)
Fix a
measurable space (Ω, F) and a Borel space (S, S), and consider a set A ∈
F ⊗S with projection πA onto Ω. Then
(i) πA belongs to the universal completion F of F;
(ii) for any probability measure P on F, there exists a random element ξ
in S such that (ω, ξ(ω)) ∈A holds P-a.s. on πA.
Proof: See Dellacherie and Meyer (1975), Section III.44.
✷
A2. Some Special Spaces
Here we collect some basic facts about various set, measure, and function
spaces of importance in probability theory. Though random processes with
paths in C(R+, Rd) or D(R+, Rd) and random measures on a variety of spaces
are considered throughout the book, most of the topological results men-
tioned here are not needed until Chapter 14, where they play a fundamental
role for the theory of convergence in distribution. Our plan is to begin with
the basic function spaces and then move on to some spaces of measures and
sets. Whenever appropriate accounts are available in the literature, we omit
the proofs.
We begin with a well-known classical result. On any space of functions
x: K →S, we introduce the evaluation maps πt : x →xt, t ∈K. Given some
metrics d in K and ρ in S, we deﬁne the associated modulus of continuity by
w(x, h) = sup{ρ(xs, xt); d(s, t) ≤h},
h > 0.

458
Foundations of Modern Probability
Theorem A2.1 (equicontinuity and compactness, Arzel`a, Ascoli) Fix two
metric spaces K and S, where K is compact and S is complete, and let D
be dense in K. Then a set A ⊂C(K, S) is relatively compact iﬀπtA is
relatively compact in S for every t ∈D and
lim
h→0 sup
x∈A w(x, h) = 0.
In that case, even 
t∈K πtA is relatively compact in S.
Proof: See Dudley (1989), Section 2.4.
✷
Next we ﬁx a separable, complete metric space (S, ρ) and consider the
space D(R+, S) of functions x: R+ →S that are right-continuous with left-
hand limits (rcll). It is easy to see that, for any ε, t > 0, such a function x
has at most ﬁnitely many jumps of size > ε before time t. In D(R+, S) we
introduce the modiﬁed modulus of continuity
˜w(x, t, h) = inf
(Ik) max
k
sup
r,s∈Ik
ρ(xr, xs),
x ∈D(R+, S), t, h > 0,
(1)
where the inﬁmum extends over all partitions of the interval [0, t) into subin-
tervals Ik = [u, v) such that v −u ≥h when v < t. Note that ˜w(x, t, h) →0
as h →0 for ﬁxed x ∈D(R+, S) and t > 0. By a time-change on R+ we
mean a monotone bijection λ : R+ →R+. Note that λ is continuous and
strictly increasing with λ0 = 0 and λ∞= ∞.
Theorem A2.2 (J1-topology, Skorohod, Prohorov, Kolmogorov) Fix a sep-
arable, complete metric space (S, ρ) and a dense set T ⊂R+. Then there
exists a separable and complete metric d in D(R+, S) such that d(xn, x) →0
iﬀ
sup
s≤t |λn(s) −s| + sup
s≤t ρ(xn ◦λn(s), x(s)) →0,
t > 0,
for some time-changes λn on R+. Furthermore, B(D(R+, S)) = σ{πt; t ∈T},
and a set A ⊂D(R+, S) is relatively compact iﬀπtA is relatively compact in
S for every t ∈T and
lim
h→0 sup
x∈A ˜w(x, t, h) = 0,
t > 0.
(2)
In that case 
s≤t πsA is relatively compact in S for every t ≥0.
Proof: See Ethier and Kurtz (1986), Sections 3.5 and 3.6, or Jacod and
Shiryaev (1987), Section VI.1.
✷
A suitably modiﬁed version of the last result applies to the space D([0, 1],
S). Here we deﬁne ˜w(x, h) in terms of partitions of [0, 1) into subintervals of
length ≥h and use time-changes λ that are increasing bijections on [0, 1].

Appendices
459
Turning to the case of measure spaces, let S be a locally compact, second-
countable Hausdorﬀ(lcscH) space S with Borel σ-ﬁeld S, and let ˆS denote
the class of bounded (i.e., relatively compact) sets in S.
The space S is
known to be Polish, and the family C+
K of continuous functions f : S →R+
with compact support is separable in the uniform metric. Furthermore, there
exists a sequence of compact sets Kn ↑S such that Kn ⊂K◦
n+1 for each n.
Let M(S) denote the class of measures on S that are locally ﬁnite (i.e.,
ﬁnite on ˆS). and write πB and πf for the mappings µ →µB and µ →µf =
 fdµ, respectively, on M(S). The vague topology in M(S) is generated by
the maps πf, f ∈C+
K, and we write the vague convergence of µn toward µ as
µn
v→µ. For any µ ∈M(S) we deﬁne ˆSµ = {B ∈ˆS; µ∂B = 0}.
Here we list some basic facts about the vague topology.
Theorem A2.3 (vague topology) Fix any lcscH space S. Then
(i) M(S) is Polish in the vague topology;
(ii) a set A ⊂M(S) is vaguely relatively compact iﬀsupµ∈A µf < ∞for
all f ∈C+
K;
(iii) if µn
v→µ and B ∈ˆS with µ∂B = 0, then µnB →µB;
(iv) B(M(S)) is generated by the maps πf, f ∈C+
K, and also for each
m ∈M(S) by the maps πB, B ∈ˆSm.
Proof: (i) Let f1, f2, . . . be dense in C+
K, and deﬁne
ρ(µ, ν) =

k2−k(|µfk −νfk| ∧1),
µ, ν ∈M(S).
(3)
It is easily seen that ρ metrizes the vague topology. In particular, M(S) is
homeomorphic to a subset of R∞and therefore separable. The completeness
of ρ will be clear once we have proved (ii).
(ii) The necessity is clear from the continuity of πf for each f ∈C+
K.
Conversely, assume that supµ∈A µf < ∞for all f ∈C+
K. Choose some com-
pact sets Kn ↑S with Kn ⊂K◦
n+1 for each n, and let the functions fn ∈C+
K
be such that 1Kn ≤fn ≤1Kn+1. For each n the set {fn · µ; µ ∈A} is uni-
formly bounded, and so by Theorem 14.3 it is even sequentially relatively
compact. A diagonal argument then shows that A itself is sequentially rela-
tively compact. Since M(S) is metrizable, the desired relative compactness
follows.
(iii) The proof is the same as for Theorem 3.25.
(iv) A topological basis in M(S) is formed by all ﬁnite intersections of
the sets {µ; a < µf < b} with 0 < a < b and f ∈C+
K.
Furthermore,
since M(S) is separable, every vaguely open set is a countable union of basis
elements. Thus, B(M(S)) = σ{πf; f ∈C+
K}. By a simple approximation
and monotone class argument it follows that B(M(S)) = σ{πB; B ∈ˆS}.
Now ﬁx any m ∈ˆS, put A = σ{πB; B ∈ˆSm}, and let D denote the class
of all D ∈ˆS such that πD is A-measurable. Fixing a metric d in S such that

460
Foundations of Modern Probability
all d-bounded closed sets are compact, we note that only countably many
d-spheres around a ﬁxed point have positive m-measure.
Thus, ˆSm con-
tains a topological basis. We also note that ˆSm is closed under ﬁnite unions,
whereas D is closed under bounded increasing limits. Since S is separable,
it follows that D contains every open set G ∈ˆS. For any such G, the class
D ∩G is a λ-system containing the π-system of all open sets in G, and by
a monotone class argument we get D∩G = ˆS ∩G. It remains to let G ↑S. ✷
Next we consider the space of all measure-valued rcll functions. Here we
may characterize compactness in terms of countably many one-dimensional
projections, a result needed for the proof of Theorem 14.26.
Theorem A2.4 (measure-valued functions) For any lcscH space S there
exists some countable set F ⊂C+
K(S) such that a set A ⊂D(R+, M(S)) is
relatively compact iﬀAf = {xf; x ∈A} is relatively compact in D(R+, R+)
for every f ∈F.
Proof: If A is relatively compact, then so is Af for every f ∈C+
K(S),
since the map x →xf is continuous from D(R+, M(S)) to D(R+, R+). To
prove the converse, choose a countable dense set F ⊂C+
K(S), closed under
addition, and assume that Af is relatively compact for every f ∈F. In
particular, supx∈A xtf < ∞for all t ≥0 and f ∈F, and so by Theorem
A2.3 the set {xt; x ∈A} is relatively compact in M(S) for every t ≥0. By
Theorem A2.2 it remains to verify (2), where ˜w is deﬁned in terms of the
complete metric ρ in (3) based on the class F.
If (2) fails, we may either choose some xn ∈A and tn →0 with lim supn
ρ(xn
tn, xn
0) > 0, or else there exist some xn ∈A and some bounded st < tn <
un with un −sn →0 such that
lim sup
n→∞
{ρ(xn
sn, xn
tn) ∧ρ(xn
tn, xn
un)} > 0.
(4)
In the former case it is clear from (3) that lim supn |xn
tnf −xn
0f| > 0 for some
f ∈F, which contradicts the relative compactness of Af.
Next assume (4). By (3) there exist some f, g ∈F such that
lim sup
n→∞
{|xn
snf −xn
tnf| ∧|xn
tng −xn
ung|} > 0.
(5)
Now for any four numbers a, a′, b, b′ ∈R, we have
1
2(|a| ∧|b′|) ≤(|a| ∧|a′|) ∨(|b| ∧|b′|) ∨(|a + a′| ∧|b + b′|).
Since F is closed under addition, (5) then implies the same relation with a
common f = g ∈F. But then (2) fails for Af, which by Theorem A2.2
contradicts the relative compactness of Af. Thus, (2) does hold for A, and
so A is relatively compact.
✷

Appendices
461
Given an lcscH space S, we introduce the classes G, F, and K of open,
closed, and compact subsets, respectively.
Here we may consider F as a
space in its own right, endowed with the Fell topology generated by the sets
{F ∈F; F ∩G ̸= ∅} and {F ∈F; F ∩K = ∅} for arbitrary G ∈G and
K ∈K. To describe the corresponding notion of convergence, we may ﬁx a
metrization ρ of the topology in S such that every closed ρ-ball is compact.
Theorem A2.5 (Fell topology) Fix any lcscH space S, and let F be the
class of closed sets F ⊂S, endowed with the Fell topology. Then
(i) F is compact, second-countable, and Hausdorﬀ;
(ii) Fn →F in F iﬀρ(s, Fn) →ρ(s, F) for all s ∈S;
(iii) {F ∈F; F ∩B ̸= ∅} is universally Borel measurable for every B ∈S.
Proof: First we show that the Fell topology is generated by the maps
F →ρ(s, F), s ∈S. To see that those mappings are continuous, put Bs,r =
{t ∈S; ρ(s, t) < r}, and note that
{F; ρ(s, F) < r} = {F; F ∩Br
s ̸= ∅},
{F; ρ(s, F) > r} = {F; F ∩¯Br
s = ∅}.
Here the sets on the right are open, by the deﬁnition of the Fell topology and
the choice of ρ. Thus, the Fell topology contains the ρ-topology.
To prove the converse, ﬁx any F ∈F and a net {Fi} ⊂F with directed
index set (I, ≺) such that Fi →F in the ρ-topology. We need to show that
convergence holds even in the Fell topology. Then let G ∈G be arbitrary
with F ∩G /∈∅. Fix any s ∈F ∩G. Since ρ(s, Fi) →ρ(s, F) = 0, we may
further choose some si ∈Fi with ρ(s, si) →0. Since G is open, there exists
some i ∈I such that sj ∈G for all j ≻i. Then also Fj ∩G /∈∅for all j ≻i.
Next consider any K ∈K with F ∩K = ∅. Deﬁne rs = 1
2ρ(s, F) for each
s ∈K and put Gs = Bs,rs. Since K is compact, it is covered by ﬁnitely many
balls Gsk. For each k we have ρ(sk, Fi) →ρ(sk, F), and so there exists some
ik ∈I such that Fj ∩Gsk = ∅for all j ≻ik. Letting i ∈I be such that i ≻ik
for all k, it is clear that Fj ∩K = ∅for all j ≻i.
Now we ﬁx any countable dense set D ⊂S, and assume that ρ(s, Fi) →
ρ(s, F) for all s ∈D. For any s, s′ ∈S we have
|ρ(s, Fj) −ρ(s, F)| ≤|ρ(s′, Fj) −ρ(s′, F)| + 2ρ(s, s′).
Given any s and ε > 0, we can make the left-hand side < ε, by choosing an
s′ ∈D with ρ(s, s′) < ε/3 and then an i ∈I such that |ρ(s′, Fj) −ρ(s′, F)| <
ε/3 for all j ≻i. This shows that the Fell topology is also generated by the
mappings F →ρ(s, F) with s restricted to D. But then F is homeomorphic
to a subset of R
∞
+ , which is second-countable and metrizable.
To prove that F is compact, it is now enough to show that every sequence
(Fn) ⊂F contains a convergent subsequence. Then choose a subsequence

462
Foundations of Modern Probability
such that ρ(s, Fn) converges in R+ for all s ∈D, and hence also for all s ∈S.
Since the family of functions ρ(s, Fn) is equicontinuous, even the limit f is
continuous, so the set F = {s ∈S; f(s) = 0} is closed.
To obtain Fn →F, we need to show that whenever F ∩G ̸= ∅or F ∩K = ∅
for some G ∈G or K ∈K, the same relation eventually holds even for Fn. In
the former case, we may ﬁx any s ∈F ∩G and note that ρ(s, Fn) →f(s) = 0.
Hence, we may choose some sn ∈Fn with sn →s, and since sn ∈G for large
n, we get Fn ∩G ̸= ∅. In the latter case, we assume that instead Fn ∩K ̸= ∅
along a subsequence. Then there exist some sn ∈Fn ∩K, and we note that
sn →s ∈K along a further subsequence. Here 0 = ρ(sn, Fn) →ρ(s, F),
which yields the contradiction s ∈F ∩K. This completes the proof of (i).
To prove (iii), we note that the mapping (s, F) →ρ(s, F) is jointly con-
tinuous and hence Borel measurable. Now S and F are both separable, so
the Borel σ-ﬁeld in S × F agrees with the product σ-ﬁeld S ⊗B(F). Since
s ∈F iﬀρ(s, F) = 0, it follows that {(s, F); s ∈F} belongs to S ⊗B(F).
Hence, so does {(s, F); s ∈F ∩B} for arbitrary B ∈S. The assertion now
follows by Theorem A1.8.
✷
We say that a class U ⊂ˆS is separating if for any K ⊂G with K ∈K
and G ∈G there exists some U ∈U with K ⊂U ⊂G. A preseparating class
I ⊂ˆS is such that the ﬁnite unions of I-sets form a separating class. When
S is Euclidean, we typically choose I to be a class of intervals or rectangles
and U as the corresponding class of ﬁnite unions.
Lemma A2.6 (separation)
For any monotone function h : ˆS →R, the
class ˆSh = {B ∈ˆS; h(B◦) = h(B)} is separating.
Proof: Fix a metric ρ in S such that every closed ρ-ball is compact, and
let K ∈K and G ∈G with K ⊂G. For any ε > 0, deﬁne Kε = {s ∈S;
d(s, K) < ε} and note that Kε = {s ∈S; ρ(s, K) ≤ε}. Since K is compact,
we have ρ(K, Gc) > 0, and so K ⊂Kε ⊂G for suﬃciently small ε > 0.
From the monotonicity of h it is further clear that Kε ∈ˆSh for almost every
ε > 0.
✷
We often need the separating class to be countable.
Lemma A2.7 (countable separation) Every separating class U ⊂ˆS con-
tains a countable separating subclass.
Proof: Fix a countable topological base B ⊂ˆS, closed under ﬁnite unions.
Choose for every B ∈B some compact sets KB,n ↓B with K◦
B,n ⊃B, and
then for each pair (B, n) ∈B × N some set UB,n ∈U with B ⊂UB,n ⊂K◦
B,n.
The family {UB,n} is clearly separating.
✷
The next result, needed for the proof of Theorem 14.28, relates the vague
and Fell topologies for integer-valued measures and their supports. Let N(S)

Appendices
463
denote the class of locally ﬁnite, integer-valued measures on S, and write
f→
for convergence in the Fell topology.
Proposition A2.8 (supports of measures) Let µ, µ1, µ2, . . . ∈N(S) with
supp µn
f→supp µ, where S is lcscH and µ is simple. Then
lim sup
n→∞(µnB ∧1) ≤µB ≤lim inf
n→∞µnB,
B ∈ˆSµ.
Proof: To prove the left inequality we may assume that µB = 0. Since
B ∈ˆSµ, we have even µB = 0, and so (supp µ) ∩B = ∅. By the convergence
of the supports, we get (supp µn) ∩B = ∅for large enough n, which implies
lim sup
n→∞(µnB ∧1) ≤lim sup
n→∞µnB = 0 = µB.
To prove the right inequality, we may assume that µB = m > 0. Since ˆSµ
is a separating ring, we may choose a partition B1, . . . , Bm ∈ˆSµ of B such
that µBk = 1 for each k. Then also µB◦
k = 1 for each k, so (supp µ)∩B◦
k ̸= ∅,
and by the convergence of the supports we get (supp µn) ∩B◦
k ̸= ∅for large
enough n. Hence,
1 ≤lim inf
n→∞µnB◦
k ≤lim inf
n→∞µnBk,
and so
µB = m ≤

k lim inf
n→∞µnBk ≤lim inf
n→∞

kµnBk = lim inf
n→∞µnB.
✷

Historical and Bibliographical Notes
The following notes were prepared with the modest intentions
of tracing the origins of some of the basic ideas in each chap-
ter, of giving precise references for the main results cited in the
text, and of suggesting some literature for further reading. No
completeness is claimed, and knowledgeable readers are likely to
notice misinterpretations and omissions, for which I appologize
in advance. A comprehensive history of modern probability the-
ory still remains to be written.
1. Elements of Measure Theory
The ﬁrst author to consider measures in the modern sense was Borel (1895,
1898), who constructed Lebesgue measure on the Borel σ-ﬁeld in R. The
corresponding integral was introduced by Lebesgue (1902, 1904), who also
established the dominated convergence theorem. The monotone convergence
theorem and Fatou’s lemma were later obtained by Levi (1906) and Fatou
(1906). Lebesgue also introduced the higher-dimensional Lebesgue measure
and proved a ﬁrst version of Fubini’s theorem, which was later generalized by
Fubini (1907) and Tonelli (1909). The integration theory was extended
to general measures and abstract spaces by Radon (1913) and Fr´echet
(1928).
Although the monotone class Theorem 1.1 had already been proved along
with related results by Sierpi´nski (1928), the result was not used in prob-
ability theory until Dynkin (1959–61). Less convenient versions had pre-
viously been employed by Halmos (1950–74) and Doob (1953). For the
remaining results of the chapter, we refer to the excellent historical notes in
Dudley (1989).
Surprisingly little general measure theory is needed for most purposes in
probability theory. The only hard result required from the beginning is the
existence of Lebesgue measure. Most of the quoted propositions are well
known and can be found in any textbook on real analysis. Many probability
texts, such as Lo`eve (1955–78) and Billingsley (1979–95), contain de-
tailed introductions to measure theory. There are also some excellent texts
in real analysis adapted to the needs of probabilists, such as Dudley (1989)
and Doob (1994).
464

Historical and Bibliographical Notes
465
2. Processes, Distributions, and Independence
The use of countably additive probability measures dates back to Borel
(1909), who constructed random variables as measurable functions on the
Lebesgue unit interval and proved Theorem 2.18 for independent events.
Cantelli (1917) noticed that the “easy” part remains true without the
independence assumption. Lemma 2.5 was proved by Jensen (1906) after
H¨older had obtained a special case.
The modern framework, with random variables as measurable functions
on an abstract probability space (Ω, A, P) and with expected values as P-
integrals over Ω, was used implicitly by Kolmogorov from (1928) on and
was later formalized in Kolmogorov (1933–56).
The latter monograph
also contains Kolmogorov’s zero–one law, discovered long before Hewitt
and Savage (1955) obtained theirs.
Early work in probability theory deals with properties depending only
on the ﬁnite-dimensional distributions.
Wiener (1923) was the ﬁrst au-
thor to construct the distribution of a process as a measure on a function
space. The general continuity criterion in Theorem 2.23, essentially due to
Kolmogorov, was ﬁrst published by Slutsky (1937), with minor exten-
sions later added by Lo`eve (1955–78) and Chentsov (1956). The general
search for regularity properties was initiated by Doob (1937, 1947). Soon
it became clear, especially through the work of L´evy (1934–35, 1937–54),
Doob (1951, 1953), and Kinney (1953), that most processes of interest have
right-continuous versions with left-hand limits.
More detailed accounts of the material in this chapter appear in many
textbooks, such as in Billingsley (1979–95), Itˆo (1978–84), and Williams
(1991). Further discussions of speciﬁc regularity properties appear in Lo`eve
(1955–78) and Cram´er and Leadbetter (1967). Earlier texts tend to give
more weight to distribution functions and their densities, less weight to mea-
sures and σ-ﬁelds.
3. Random Sequences, Series, and Averages
The weak law of large numbers was ﬁrst obtained by Bernoulli (1713)
for the sequences named after him. More general versions were then estab-
lished with increasing rigor by Bienaym´e (1853), Chebyshev (1867), and
Markov (1899). A necessary and suﬃcient condition for the weak law of
large numbers was ﬁnally obtained by Kolmogorov (1928–29).
Khinchin and Kolmogorov (1925) studied series of independent, dis-
crete random variables and showed that convergence holds under the condi-
tion in Lemma 3.16. Kolmogorov (1928–29) then obtained his maximum
inequality and showed that the three conditions in Theorem 3.18 are neces-
sary and suﬃcient for a.s. convergence. The equivalence with convergence in
distribution was later noted by L´evy (1937–54).

466
Foundations of Modern Probability
The strong law of large numbers for Bernoulli sequences was stated by
Borel (1909), but the ﬁrst rigorous proof is due to Faber (1910). The
simple criterion in Corollary 3.22 was obtained in Kolmogorov (1930). In
(1933–56) Kolmogorov showed that existence of the mean is necessary
and suﬃcient for the strong law of large numbers for general i.i.d. sequences.
The extension to exponents p ̸= 1 is due to Marcinkiewicz and Zygmund
(1937).
Proposition 3.24 was proved in stages by Glivenko (1933) and
Cantelli (1933).
Riesz (1909) introduced the notion of convergence in measure, for prob-
ability measures equivalent to convergence in probability, and showed that it
implies a.e. convergence along a subsequence. The weak compactness crite-
rion in Lemma 3.13 is due to Dunford (1939). The functional representation
of Proposition 3.31 appeared in Kallenberg (1996a), and Corollary 3.32
was given by Stricker and Yor (1978).
The theory of weak convergence was founded by Alexandrov (1940–
43), who proved in particular the so-called Portmanteau Theorem 3.25. The
continuous mapping Theorem 3.27 was obtained for a single function fn ≡f
by Mann and Wald (1943) and then in the general case by Prohorov
(1956) and Rubin. The coupling Theorem 3.30 is due for complete S to
Skorohod (1956) and in general to Dudley (1968).
More detailed accounts of the material in this chapter may be found
in many textbooks, such as in Lo`eve (1955–78) and Chow and Teicher
(1978–88). Additional results on random series and a.s. convergence appear
in Stout (1974) and Kwapie´n and Woyczy´nski (1992).
4. Characteristic Functions and Classical Limit Theo-
rems
The central limit theorem (a name ﬁrst used by P´olya (1920)) has a long
and glorious history, beginning with the work of de Moivre (1733–56), who
obtained the now-familiar approximation of binomial probabilities in terms
of the normal density function. Laplace (1774, 1812–20) stated the general
result in the modern integral form, but his proof was incomplete, as was the
proof of Chebyshev (1867, 1890).
The ﬁrst rigorous proof was given by Liapounov (1901), though under an
extra moment condition. Then Lindeberg (1922a) proved his fundamental
Theorem 4.12, which in turn led to the basic Proposition 4.9 in a series of
papers by Lindeberg (1922b) and L´evy (1922a–c).
Bernstein (1927)
obtained the ﬁrst extension to higher dimensions. The general problem of
normal convergence, regarded for two centuries as the central (indeed the
only) theoretical problem in probability, was eventually solved in the form of
Theorem 4.15, independently by Feller (1935) and L´evy (1935a). Slowly
varying functions were introduced and studied by Karamata (1930).
Though characteristic functions have been used in probability theory ever

Historical and Bibliographical Notes
467
since Laplace (1812–20), their ﬁrst use in a rigorous proof of a limit theorem
had to wait until Liapounov (1901). The ﬁrst general continuity theorem
was established by L´evy (1922c), who assumed the characteristic functions
to converge uniformly in some neighborhood of the origin. The deﬁnitive
version in Theorem 4.22 is due to Bochner (1933). Our direct approach to
Theorem 4.3 may be new, in avoiding the relatively deep Helly selection
theorem (1911–12).
The basic Corollary 4.5 was noted by Cram´er and
Wold (1936).
Introductions to characteristic functions and classical limit theorems may
be found in many textbooks, notably Lo`eve (1955–78). Feller (1966–71)
is a rich source of further information on Laplace transforms, characteristic
functions, and classical limit theorems. For more detailed or advanced results
on characteristic functions, see Lukacs (1960–70).
5. Conditioning and Disintegration
Though conditional densities have been computed by statisticians ever since
Laplace (1774), the ﬁrst general approach to conditioning was devised by
Kolmogorov (1933–56), who deﬁned conditional probabilities and expec-
tations as random variables on the basic probability space, using the Radon–
Nikod´ym theorem, which had recently become available through the work of
Radon (1913), Daniell (1920), and Nikod´ym (1930). His original notion
of conditioning with respect to a random vector was extended by Halmos
(1950–74) to general random elements and then by Doob (1953) to abstract
sub-σ-ﬁelds.
Our present Hilbert space approach to conditioning, essentially due to
von Neumann (1940), is more elementary and intuitive and avoids the use
of the relatively deep Radon–Nikod´ym theorem. It has the further advantage
of leading to the attractive interpretation of a martingale as a projective
family of random variables.
The existence of regular conditional distributions was studied by several
authors, beginning with Doob (1938). It leads immediately to the familiar
disintegration of measures on product spaces and to the frequently used but
rarely stated disintegration Theorem 5.4.
Measures on inﬁnite product spaces were ﬁrst considered by Daniell
(1918–19, 1919–20), who proved the extension Theorem 5.14 for countable
product spaces. Kolmogorov (1933–56) extended the result to arbitrary
index sets. 1Lomnicki and Ulam (1934) noted that no topological assump-
tions are needed for the construction of inﬁnite product measures, a result
that was later extended by Ionescu Tulcea (1949–50) to measures speci-
ﬁed by a sequence of conditional distributions.
The interpretation of the simple Markov property in terms of conditional
independence was indicated already by Markov (1906), and the formal
statement of Proposition 5.6 appears in Doob (1953). Further properties

468
Foundations of Modern Probability
of conditional independence have been listed by D¨ohler (1980) and others.
The transfer Theorem 5.10 is given in Kallenberg (1988).
The traditional approach to conditional expectations via the Radon–
Nikod´ym theorem appears in many textbooks, such as Billingsley (1979–
95).
6. Martingales and Optional Times
Martingales were ﬁrst introduced by Bernstein (1927, 1937) in his eﬀorts
to relax the independence assumption in the classical limit theorems. Both
Bernstein and L´evy (1935a–b, 1937–54) extended Kolmogorov’s maxi-
mum inequality and the central limit theorem to a general martingale con-
text. The term martingale (originally denoting part of a horse’s harness and
later used for a special gambling system) was introduced in the probabilistic
context by Ville (1939).
The ﬁrst martingale convergence theorem was obtained by Jessen (1934)
and L´evy (1935b), both of whom proved Theorem 6.23 for ﬁltrations gener-
ated by sequences of independent random variables. A submartingale version
of the same result appears in Sparre-Andersen and Jessen (1948). The
independence assumption was removed by L´evy (1937–54), who also noted
the simple martingale proof of Kolmogorov’s zero–one law and obtained his
conditional version of the Borel–Cantelli lemma.
The general convergence theorem for discrete-time martingales was proved
by Doob (1940), and the basic regularity theorems for continuous-time mar-
tingales ﬁrst appeared in Doob (1951). The theory was extended to sub-
martingales by Snell (1952) and Doob (1953). The latter book is also the
original source of such fundamental results as the martingale closure theorem,
the optional sampling theorem, and the Lp-inequality.
Though hitting times have long been used informally, general optional
times seem to appear for the ﬁrst time in Doob (1936). Abstract ﬁltrations
were not introduced until Doob (1953). Progressive processes were intro-
duced by Dynkin (1959–61), and the modern deﬁnition of the σ-ﬁelds Fτ is
due to Yushkevich.
Elementary introductions to martingale theory are given by many au-
thors, including Williams (1991). More information about the discrete-time
case is given by Neveu (1972–75) and Chow and Teicher (1978–88). For
a detailed account of the continuous-time theory and its relations to Markov
processes and stochastic calculus, see Dellacherie and Meyer (1975–87).
7. Markov Processes and Discrete-Time Chains
Markov chains in discrete time and with ﬁnitely many states were intro-
duced by Markov (1906), who proved the ﬁrst ergodic theorem, assuming

Historical and Bibliographical Notes
469
the transition probabilities to be strictly positive. Kolmogorov (1936a–b)
extended the theory to countable state spaces and arbitrary transition prob-
abilities. In particular, he noted the decomposition of the state space into ir-
reducible sets, classiﬁed the states with respect to recurrence and periodicity,
and described the asymptotic behavior of the n-step transition probabilities.
Kolmogorov’s original proofs were analytic. The more intuitive coupling ap-
proach was introduced by Doeblin (1938), long before the strong Markov
property had been formalized.
Bachelier had noted the connection between random walks and dif-
fusions, which inspired Kolmogorov (1931a) to give a precise deﬁnition
of Markov processes in continuous time. His treatment is purely analytic,
with the distribution speciﬁed by a family of transition kernels satisfying the
Chapman–Kolmogorov relation, previously noted in special cases by Chap-
man (1928) and Smoluchovsky.
Kolmogorov (1931a) makes no reference to sample paths. The transi-
tion to probabilistic methods began with the work of L´evy (1934–35) and
Doeblin (1938). Though the strong Markov property was used informally
by those authors (and indeed already by Bachelier (1900, 1901)), the result
was ﬁrst stated and proved in a special case by Doob (1945). General ﬁl-
trations were introduced in Markov process theory by Blumenthal (1957).
The modern setup, with a canonical process X deﬁned on the path space Ω,
equipped with a ﬁltration F, a family of shift operators θt, and a collection
of probability measures Px, was developed systematically by Dynkin (1959–
61, 1963–65). A weaker form of Theorem 7.23 appears in Blumenthal and
Getoor (1968), and the present version is from Kallenberg (1987, 1998).
Elementary introductions to Markov processes appear in many textbooks,
such as Rogers and Williams (1979–94) and Chung (1982). More de-
tailed or advanced accounts are given by Dynkin (1963–65), Blumen-
thal and Getoor (1968), Ethier and Kurtz (1986), Dellacherie and
Meyer (1975–87), and Sharpe (1988). Feller (1950–68) gives a masterly
introduction to Markov chains, later imitated by many authors. More de-
tailed accounts of the discrete-time theory appear in Kemeny, Snell, and
Knapp (1966) and Freedman (1971–83a). The coupling method, which fell
into oblivion after Doeblin’s untimely death in 1940, has recently enjoyed a
revival, as documented by the survey of Lindvall (1992).
8. Random Walks and Renewal Theory
Random walks originally arose in a wide range of applications, such as gam-
bling, queuing, storage, and insurance; their history can be traced back to the
origins of probability. The approximation of diﬀusion processes by random
walks dates back to Bachelier (1900, 1901). A further application was to
potential theory, where in the 1920s a method of discrete approximation was
devised, admitting a probabilistic interpretation in terms of a simple sym-

470
Foundations of Modern Probability
metric random walk. Finally, random walks played an important role in the
sequential analysis developed by Wald (1947).
The modern theory began with P´olya’s (1921) discovery that a simple
symmetric random walk on Zd is recurrent for d ≤2 and transient other-
wise. His result was later extended to Brownian motion by L´evy (1940)
and Kakutani (1944a). The general recurrence criterion in Theorem 8.4
was derived by Chung and Fuchs (1951), and the probabilistic approach
to Theorem 8.2 was found by Chung and Ornstein (1962). The ﬁrst con-
dition in Corollary 8.7 is, in fact, even necessary for recurrence, as was noted
independently by Ornstein (1969) and Stone (1969).
The reﬂection principle was ﬁrst used by Andr´e (1887) in his discussion
of the “ballot problem.” The systematic study of ﬂuctuation and absorp-
tion problems for random walks began with the work of Pollaczek (1930).
Ladder times and heights, ﬁrst introduced by Blackwell, were explored in
an inﬂuential paper by Feller (1949). The factorizations in Theorem 8.15
were originally derived by the Wiener–Hopf technique, which had been de-
veloped by Paley and Wiener (1934) as a general tool in Fourier analysis.
Theorem 8.16 is due for u = 0 to Sparre-Andersen (1953–54) and in gen-
eral to Baxter (1961). The former author used complicated combinatorial
methods, which were later simpliﬁed by Feller and others.
The ﬁrst renewal theorem was obtained by Erd¨os, Feller, and Pol-
lard (1949) for random walks on Z+. In that case, however, Chung pointed
out that the result is an easy consequence of Kolmogorov’s (1936a–b)
ergodic theorem for Markov chains on a countable state space.
Black-
well (1948, 1953) extended the result to random walks on R+. The ulti-
mate version for transient random walks on R is due to Feller and Orey
(1961). The ﬁrst coupling proof of Blackwell’s theorem was given by Lind-
vall (1977).
Our proof is a modiﬁcation of an argument by Athreya,
McDonald, and Ney (1978), which originally did not cover all cases. The
method seems to require the existence of a possibly inﬁnite mean. An ana-
lytic approach to the general case appears in Feller (1966–71).
Elementary introductions to random walks are given by many authors, in-
cluding Chung (1968–74), Feller (1950–68, 1966–71), and Lo`eve (1955–
78, 4th ed.). A detailed exposition of random walks on Zd is given by Spitzer
(1964–78).
9. Stationary Processes and Ergodic Theory
The history of ergodic theory dates back to Boltzmann’s (1887) work in sta-
tistical mechanics. Boltzmann’s ergodic hypothesis—the conjectural equality
between time and ensemble averages—was long accepted as a heuristic prin-
ciple. In probabilistic terms it amounts to the convergence t−1  t
0 f(Xs)ds →
Ef(X0), where Xt represents the state of the system (typically the conﬁgura-
tion of all molecules in a gas) at time t, and the expected value is computed

Historical and Bibliographical Notes
471
with respect to a suitable invariant probability measure on a compact sub-
manifold of the state space.
The ergodic hypothesis was sensationally proved as a mathematical the-
orem, ﬁrst in an L2-version by von Neumann (1932) and then in the a.e.
form by Birkhoff (1932). The intricate proof of the latter was simpliﬁed
by Yosida and Kakutani (1939), who noted how the result follows eas-
ily from Hopf’s (1937) maximal ergodic Lemma 9.7, and then by Garsia
(1965), who gave a simple proof of Hopf’s result. Khinchin (1933, 1934)
pioneered a translation of the results of ergodic theory into the probabilistic
setting of stationary sequences and processes.
Ergodic theory developed rapidly into a mathematical discipline in its
own right, and the ergodic theorem was extended in many directions. The
ergodic decomposition of invariant measures dates back to Krylov and Bo-
golioubov (1937), though the basic role of the invariant σ-ﬁeld was not
recognized until the work of Farrell (1962) and Varadarajan (1963).
de Finetti (1931, 1937) proved that an inﬁnite sequence of exchangeable
random variables is mixed i.i.d. The result became a cornerstone in his theory
of subjective probability and Bayesian statistics. Ryll-Nardzewski (1957)
noted that the theorem remains valid under the hypothesis of spreadability,
and B¨uhlmann (1960) extended the result to continuous time. The pre-
dictable sampling property in Theorem 9.19 was ﬁrst noted by Doob (1936)
for i.i.d. random variables and increasing sequences of predictable times. The
general result and its continuous-time counterpart appear in Kallenberg
(1988). Sparre-Andersen’s (1953–54) announcement of his Corollary 9.20
was (according to Feller) “a sensation greeted with incredulity, and the orig-
inal proof was of an extraordinary intricacy and complexity.” A simpliﬁed
argument (diﬀerent from ours) appears in Feller (1966–71).
Theorem 9.15 was proved by Furstenberg and Kesten (1960) before
the subadditive ergodic Theorem 9.14 became available. The latter result
was originally proved by Kingman (1968) under the stronger hypothesis
that the whole array (Xm,n) be stationary under simultaneous shifts in m
and n. The present extension and shorter proof are due to Liggett (1985).
Elementary introductions to stationary processes are given by Doob
(1953) and Cram´er and Leadbetter (1967). Exchangeability theory is
surveyed by Aldous (1985). Billingsley (1965) gives a nice introduction
to ergodic theory for probabilists. Some more advanced ergodic theorems
appear in Lo`eve (1955–78). For the theory of ergodic decompositions in
a very general setting, see Dynkin (1978). An alternative approach to the
latter is through Choquet theory, surveyed by Dellacherie and Meyer
(1975–87).

472
Foundations of Modern Probability
10. Poisson and Pure Jump-Type Markov Processes
The Poisson distribution was ﬁrst used by de Moivre (1711–12) and Pois-
son (1837) as an approximation to the binomial distribution. The associated
process arose much later from various applications. Thus, it was introduced
by Lundberg (1903) to model streams of insurance claims, by Ruther-
ford and Geiger (1908) to describe the process of radioactive decay, and
by Erlang (1909) to model the incoming traﬃc to a telephone exchange.
Poisson random measures in higher dimensions are implicit in the work of
L´evy (1934–35), whose treatment was later formalized by Itˆo (1942b).
Erlang obtained a version of Theorem 10.11 for simple point processes,
and the general result is essentially due to L´evy (1934–35). The Poisson
characterization in Corollary 10.10 was noted by R´enyi (1967). The general
assertions in Theorem 10.9 (i) and (iii) were proved in the author’s thesis and
were later published together with part (ii) in Kallenberg (1973a, 1975–
86). Similar results were obtained independently by M¨onch (1971) for part
(i) and by Grandell (1976) for part (ii).
Markov chains in continuous time have been studied by many authors,
beginning with Kolmogorov (1931a). The transition functions of general
pure jump-type Markov processes were studied by Pospiˇsil (1935–36) and
Feller (1936, 1940), and the corresponding sample path properties were
examined by Doeblin (1939b) and Doob (1942b). The ﬁrst continuous-
time version of the strong Markov property was obtained by Doob (1945).
Introductions to continuous-time Markov chains appear in many elemen-
tary textbooks, beginning with Feller (1950–68). For a more comprehen-
sive account, see Chung (1960). The underlying regenerative structure was
examined in detail by Kingman (1972).
For more information on Pois-
son and related point processes as well as on general random measures, see
Kallenberg (1975–86) and Daley and Vere-Jones (1988).
11. Gaussian Processes and Brownian Motion
The Gaussian density function ﬁrst appeared in the work of de Moiv-
re (1733–56), and the corresponding distribution became explicit through
the work of Laplace (1774, 1812–20).
The Gaussian law was popular-
ized by Gauss (1809) in his theory of errors and so became named after
him. Maxwell derived the Gaussian law as the velocity distribution for
the molecules in a gas, assuming the hypotheses of Proposition 11.2. Theo-
rem 11.3 was originally stated by Schoenberg (1938) as a relation between
positive deﬁnite and completely monotone functions, and the probabilistic in-
terpretation was later noted by Freedman (1962–63). Isonormal Gaussian
processes were introduced by Segal (1954).
The process of Brownian motion was introduced by Bachelier (1900,
1901) to model ﬂuctuations on the stock market. Bachelier discovered some

Historical and Bibliographical Notes
473
basic properties of the process, such as the relation Mt =d |Bt|. Einstein
(1905, 1906) later introduced the same process as a model for the physical
phenomenon of Brownian motion—the irregular movement of microscopic
particles suspended in a liquid.
The latter phenomenon, ﬁrst noted by
van Leeuwenhoek in the seventeenth century, is named after the botanist
Brown (1828) for his systematic observations of pollen grains. Einstein’s
theory was forwarded in support of the still-controversial molecular theory
of matter.
A more reﬁned model for the physical Brownian motion was
proposed by Langevin (1909) and Ornstein and Uhlenbeck (1930).
The mathematical theory of Brownian motion was put on a rigorous basis
by Wiener (1923), who constructed the associated distribution as a measure
on the space of continuous paths. The signiﬁcance of Wiener’s revolution-
ary paper was not fully recognized until after the pioneering work of Kol-
mogorov (1931a, 1933–56), L´evy (1934–35), and Feller (1936). Wiener
also introduced stochastic integrals of deterministic L2-functions, which were
later studied in further detail by Paley, Wiener, and Zygmund (1933).
The spectral representation of stationary processes, originally deduced from
Bochner’s (1932–48) theorem by Cram´er (1942), was later recognized as
equivalent to a general Hilbert space result due to Stone (1932). The chaos
expansion of Brownian functionals was discovered by Wiener (1938), and
the theory of multiple integrals with respect to Brownian motion was devel-
oped in a seminal paper of Itˆo (1951c).
The law of the iterated logarithm was discovered by Khinchin, ﬁrst
(1923, 1924) for Bernoulli sequences, and later (1933–48) for Brownian mo-
tion.
A systematic study of the Brownian paths was initiated by L´evy
(1937–54, 1948–65), who proved the existence of the quadratic variation in
(1940) and the arcsine laws in (1939, 1948–65).
Though many proofs of
the latter have since been given, the present deduction from basic symmetry
properties may be new. The strong Markov property was used implicitly
in the work of L´evy and others, but the result was not carefully stated and
proved until Hunt (1956).
Many modern probability texts contain detailed introductions to Brown-
ian motion. The books by Itˆo and McKean (1965–96), Freedman (1971–
83b), Karatzas and Shreve (1988–91), and Revuz and Yor (1991–94)
provide a wealth of further information on the subject. Further informa-
tion on multiple Wiener–Itˆo integrals is given by Kallianpur (1980), Del-
lacherie, Maisonneuve, and Meyer (1992), and Nualart (1995).
12. Skorohod Embedding and Invariance Principles
The ﬁrst functional limit theorems were obtained in (1931b, 1933a) by Kol-
mogorov, who considered special functionals of a random walk. Erd¨os
and Kac (1946, 1947) conceived the idea of an invariance principle that
would allow functional limit theorems to be extended from particular cases

474
Foundations of Modern Probability
to a general setting. They also treated some special functionals of a random
walk. The ﬁrst general functional limit theorems were obtained by Donsker
(1951–52) for random walks and empirical distribution functions, following
an idea of Doob (1949). A general theory based on sophisticated compact-
ness arguments was later developed by Prohorov (1956) and others.
Skorohod’s (1961–65) embedding theorem provided a new and proba-
bilistic approach to Donsker’s theorem. Extensions to the martingale context
were obtained by many authors, beginning with Dubins (1968). Lemma
12.19 appears in Dvoretzky (1972). Donsker’s weak invariance principle
was supplemented by a strong version due to Strassen (1964), which yields
extensions of many a.s. limit theorems for Brownian motion to suitable ran-
dom walks. In particular, his result yields a simple proof of the Hartman
and Wintner (1941) law of the iterated logarithm, which had originally
been deduced from some deep results of Kolmogorov (1929).
Billingsley (1968) gives many interesting applications and extensions
of Donsker’s theorem. For a wide range of applications of the martingale
embedding theorem, see Hall and Heyde (1980) and Durrett (1991–95).
Koml´os, Major, and Tusn´ady (1975–76) showed that the approximation
rate in the Skorohod embedding can be improved by a more delicate “strong
approximation.” For an exposition of their work and its numerous applica-
tions, see Cs¨org¨o and R´ev´esz (1981).
13. Independent Increments and Inﬁnite Divisibility
Until the 1920s, Brownian motion and the Poisson process were essentially
the only known processes with independent increments.
In (1924, 1925)
L´evy introduced the stable distributions and noted that they too could be
associated with suitable “decomposable” processes. de Finetti (1929) saw
the general connection between processes with independent increments and
inﬁnitely divisible distributions and posed the problem of characterizing the
latter. A partial solution for distributions with a ﬁnite second moment was
found by Kolmogorov (1932).
The complete solution was obtained in a revolutionary paper by L´evy
(1934–35), where the “decomposable” processes are analyzed by a virtuosic
blend of analytic and probabilistic methods, leading to an explicit descrip-
tion in terms of a jump and a diﬀusion component. As a byproduct, L´evy
obtained the general representation for the associated characteristic func-
tions. His analysis was so complete that only improvements in detail have
since been possible. In particular, Itˆo (1942b) showed how the jump com-
ponent can be expressed in terms of Poisson integrals. Analytic derivations
of the representation formula for the characteristic function were later given
by L´evy (1937–54) himself, by Feller (1937), and by Khinchin (1937).
The scope of the classical central limit problem was broadened by L´evy
(1925) to a general study of suitably normalized partial sums, obtained from

Historical and Bibliographical Notes
475
a single sequence of independent random variables. To include the case of
the classical Poisson approximation, Kolmogorov proposed a further ex-
tension to general triangular arrays, subject to the sole condition of uni-
formly asymptotically negligible elements. In this context, Feller (1937)
and Khinchin (1937) proved independently that the limiting distributions
are inﬁnitely divisible. It remained to characterize the convergence to a spec-
iﬁed limit, a problem that had already been solved in the Gaussian case by
Feller (1935) and L´evy (1935a). The ultimate solution was obtained inde-
pendently by Doeblin (1939) and Gnedenko (1939), and a comprehensive
exposition of the theory was published by Gnedenko and Kolmogorov
(1949–68).
The basic convergence Theorem 13.17 for L´evy processes and the asso-
ciated approximation result for random walks in Corollary 13.20 are essen-
tially due to Skorohod (1957), though with rather diﬀerent statements and
proofs. Lemma 13.22 appears in Doeblin (1939a). Our approach to the
basic representation theorem is a modernized version of L´evy’s proof, with
simpliﬁcations resulting from the use of basic point process and martingale
results.
Detailed accounts of the basic limit theory for null arrays are given by
Lo`eve (1955–78), Chow and Teicher (1978–88), and Feller (1966–71).
The positive case is treated in Kallenberg (1975–86). A modern intro-
duction to L´evy processes is given by Bertoin (1996). General independent
increment processes and associated limit theorems are treated in Jacod and
Shiryaev (1987). Extreme value theory is surveyed by Leadbetter, Lind-
gren, and Rootz´en (1983).
14. Convergence of Random Processes, Measures, and
Sets
After Donsker (1951–52) had proved his functional limit theorems for ran-
dom walks and empirical distribution functions, a general theory of weak con-
vergence in function spaces was developed by the Russian school, in seminal
papers by Prohorov (1956), Skorohod (1956, 1957), and Kolmogorov
(1956). Thus, Prohorov (1956) proved his fundamental compactness The-
orem 14.3, in a setting for separable and complete metric spaces. The ab-
stract theory was later extended in various directions by Le Cam (1957),
Varadarajan (1958), and Dudley (1966, 1967). The elementary inequal-
ity of Ottaviani is from (1939).
Originally Skorohod (1956) considered the space D([0, 1]) endowed with
four diﬀerent topologies, of which the J1-topology considered here is by far the
most important for applications. The theory was later extended to D(R+)
by Stone (1963) and Lindvall (1973). Tightness was originally veriﬁed
by means of various product moment conditions, developed by Chentsov
(1956) and Billingsley (1968), before the powerful criterion of Aldous

476
Foundations of Modern Probability
(1978) became available.
Kurtz (1975) and Mitoma (1983) noted that
criteria for tightness in D(R+, S) can often be expressed in terms of one-
dimensional projections, as in Theorem 14.26.
The weak convergence theory for random measures and point processes
began with Prohorov (1961), who noted the equivalence of (i) and (ii) in
Theorem 14.16 when S is compact. The equivalence with (iii) appears in
Debes, Kerstan, Liemant, and Matthes (1970). The one-dimensional
criteria in Proposition 14.17 and Theorems 14.16 and 14.28 are based on
results in Kallenberg (1973a, 1975–86, 1996b) and a subsequent remark by
Kurtz. Random sets had already been studied extensively by many authors,
including Choquet (1953–54), Kendall (1974), and Matheron (1975),
when an associated weak convergence theory was developed by Norberg
(1984).
The applications considered in this chapter have a long history. Thus,
primitive versions of Theorem 14.18 were obtained by Palm (1943), Khin-
chin (1955–60), and Ososkov (1956). The present version is due for S = R
to Grigelionis (1963) and for more general spaces to Goldman (1967) and
Jagers (1972). Limit theorems under simultaneous thinning and rescaling
of a given point process were obtained by R´enyi (1956), Nawrotzki (1962),
Belyaev (1963), and Goldman (1967). The general version in Theorem
14.19 was proved by Kallenberg (1975–86) after Mecke (1968) had ob-
tained his related characterization of Cox processes. Limit theorems for sam-
pling from a ﬁnite population and for general exchangeable sequences have
been proved in varying generality by many authors, including Chernov and
Teicher (1958), H´ajek (1960), Ros´en (1964), Billingsley (1968), and
Hagberg (1973). The results of Theorems 14.21 and 14.25 ﬁrst appeared
in Kallenberg (1973b).
Detailed accounts of weak convergence theory and its applications may be
found in several excellent textbooks and monographs, including Billings-
ley (1968), Pollard (1984), Ethier and Kurtz (1986), and Jacod and
Shiryaev (1987). More information on limit theorems for random measures
and point processes is available in Matthes, Kerstan, and Mecke (1978)
and Kallenberg (1975–86). A good general reference for random sets is
Matheron (1975).
15. Stochastic Integrals and Quadratic Variation
The ﬁrst stochastic integral with a random integrand was deﬁned by Itˆo
(1942a, 1944), who used Brownian motion as the integrator and assumed
the integrand to be product measurable and adapted. Doob (1953) noted
the connection with martingale theory. A ﬁrst version of the fundamental
Theorem 15.19 was proved by Itˆo (1951a). The result was later extended by
many authors. The compensated integral in Corollary 15.22 was introduced
by Fisk, and independently by Stratonovich (1966).

Historical and Bibliographical Notes
477
The existence of the quadratic variation process was originally deduced
from the Doob–Meyer decomposition. Fisk (1966) showed how the quadratic
variation can also be obtained directly from the process, as in Proposition
15.18. The present construction was inspired by Rogers and Williams
(1987).
The BDG inequalities were originally proved for p > 1 and dis-
crete time by Burkholder (1966). Millar (1968) noted the extension to
continuous martingales, in which context the further extension to arbitrary
p > 0 was obtained independently by Burkholder and Gundy (1970)
and Novikov (1971). Kunita and Watanabe (1967) introduced the co-
variation of two martingales and proved the associated characterization of
the integral. They further established some general inequalities related to
Proposition 15.10.
The Itˆo integral was extended to square-integrable martingales by Cour-
r`ege (1962–63) and Kunita and Watanabe (1967) and to continuous semi-
martingales by Dol´eans-Dade and Meyer (1970). The idea of localization
is due to Itˆo and Watanabe (1965). Theorem 15.25 was obtained by Kaza-
maki (1972) as part of a general theory of random time change. Stochastic
integrals depending on a parameter were studied by Dol´eans (1967b) and
Stricker and Yor (1978), and the functional representation of Proposition
15.27 ﬁrst appeared in Kallenberg (1996a).
Elementary introductions to Itˆo integration appear in many textbooks,
such as Chung and Williams (1983) and Øksendal (1985–95). For more
advanced accounts and for further information, see Ikeda and Watanabe
(1981–89), Rogers and Williams (1987), Karatzas and Shreve (1988–
91), and Revuz and Yor (1991–94).
16. Continuous Martingales and Brownian Motion
The fundamental characterization of Brownian motion in Theorem 16.3 was
proved by L´evy (1937–54), who also (1940) noted the conformal invariance
up to a time-change of complex Brownian motion and stated the polarity of
singletons. A rigorous proof of Theorem 16.6 was later provided by Kaku-
tani (1944a–b). Kunita and Watanabe (1967) gave the ﬁrst modern proof
of L´evy’s characterization theorem, based on Itˆo’s formula and exponential
martingales.
The history of the latter can be traced back to the funda-
mental Cameron and Martin (1944) paper containing Theorem 16.22 and
to Wald’s (1946, 1947) work in sequential analysis, where the identity of
Lemma 16.24 ﬁrst appeared in a version for random walks.
The integral representation in Theorem 16.10 is essentially due to Itˆo
(1951c), who noted its connection with multiple stochastic integrals and chaos
expansions. A one-dimensional version of Theorem 16.12 appears in Doob
(1953). The general time-change Theorem 16.4 was discovered independently
by Dambis (1965) and Dubins and Schwarz (1965), and a systematic study
of isotropic martingales was initiated by Getoor and Sharpe (1972). The

478
Foundations of Modern Probability
multivariate result in Proposition 16.8 was noted by Knight (1971), and
a version of Proposition 16.9 for general exchangeable processes appears in
Kallenberg (1989). The skew-product representation in Corollary 16.7 is
due to Galmarino (1963),
The Cameron–Martin theorem was gradually extended to more general
settings by many authors, including Maruyama (1954, 1955), Girsanov
(1960), and van Schuppen and Wong (1974). The martingale criterion of
Theorem 16.23 was obtained by Novikov (1972).
The material in this chapter is covered by many texts, including the ex-
cellent monographs by Karatzas and Shreve (1988–91) and Revuz and
Yor (1991–94). A more advanced and amazingly informative text is Jacod
(1979).
17. Feller Processes and Semigroups
Semigroup ideas are implicit in Kolmogorov’s pioneering (1931a) paper,
whose central theme is the search for local characteristics that will deter-
mine the transition probabilities through a system of diﬀerential equations,
the so-called Kolmogorov forward and backward equations. Markov chains
and diﬀusion processes were originally treated separately, but in (1935) Kol-
mogorov proposed a uniﬁed framework, with transition kernels regarded as
operators (initially operating on measures rather than on functions), and
with local characteristics given by an associated generator.
Kolmogorov’s ideas were taken up by Feller (1936), who obtained gen-
eral existence and uniqueness results for the forward and backward equations.
The abstract theory of contraction semigroups on Banach spaces was devel-
oped independently by Hille (1948) and Yosida (1948), both of whom
recognized its signiﬁcance for the theory of Markov processes. The power of
the semigroup approach became clear through the work of Feller (1952,
1954), who gave a complete description of the generators of one-dimensional
diﬀusions. In particular, Feller characterizes the boundary behavior of the
process in terms of the domain of the generator.
The systematic study of Markov semigroups began with the work of
Dynkin (1955a). The standard approach is to postulate strong continuity
instead of the weaker and more easily veriﬁed condition (F2). The positive
maximum principle appears in the work of Itˆo (1957), and the core condition
of Proposition 17.9 is due to Watanabe (1968).
The ﬁrst regularity theorem was obtained by Doeblin (1939b), who
gave conditions for the paths to be step functions. A suﬃcient condition for
continuity was then obtained by Fortet (1943). Finally, Kinney (1953)
showed that any Feller process has a version with rcll paths, after Dynkin
(1952) had obtained the same property under a H¨older condition. The use of
martingale methods for the study of Markov processes dates back to Kinney
(1953) and Doob (1954).

Historical and Bibliographical Notes
479
The strong Markov property for Feller processes was proved indepen-
dently by Dynkin and Yushkevich (1956) and by Blumenthal (1957)
after special cases had been considered by Doob (1945), Hunt (1956), and
Ray (1956). Blumenthal’s (1957) paper also contains his zero–one law.
Dynkin (1955a) introduced his “characteristic operator,” and a version of
Theorem 17.24 appears in Dynkin (1956).
There is a vast literature on approximation results for Markov chains and
Markov processes, covering a wide range of applications. The use of semi-
group methods to prove limit theorems can be traced back to Lindeberg’s
(1922a) proof of the central limit theorem. The general results in Theorems
17.25 and 17.28 were developed in stages by Trotter (1958a), Sova (1967),
Kurtz (1969–75), and Mackeviˇcius (1974). Our proof of Theorem 17.25
uses ideas from Goldstein (1976).
A splendid introduction to semigroup theory is given by the relevant
chapters in Feller (1966–71).
In particular, Feller shows how the one-
dimensional L´evy–Khinchin formula and associated limit theorems can be
derived by semigroup methods. More detailed and advanced accounts of the
subject appear in Dynkin (1963–65), Ethier and Kurtz (1986), and Del-
lacherie and Meyer (1975–87).
18. Stochastic Diﬀerential Equations and Martingale
Problems
Long before the existence of any general theory for SDEs, Langevin (1908)
proposed his equation to model the velocity of a Brownian particle. The so-
lution process was later studied by Ornstein and Uhlenbeck (1930) and
was thus named after them. A more rigorous discussion appears in Doob
(1942a).
The general idea of a stochastic diﬀerential equation goes back to Bern-
stein (1934, 1938), who proposed a pathwise construction of diﬀusion pro-
cesses by a discrete approximation, leading in the limit to a formal diﬀerential
equation driven by a Brownian motion. However, Itˆo (1942a, 1951b) was
the ﬁrst author to develop a rigorous and systematic theory, including a
precise deﬁnition of the integral, conditions for existence and uniqueness of
solutions, and basic properties of the solution process, such as the Markov
property and the continuous dependence on initial state. Similar results were
obtained, later but independently, by Gihman (1947, 1950–51).
The notion of a weak solution was introduced by Girsanov (1960), and
a version of the weak existence Theorem 18.9 appears in Skorohod (1961–
65). The ideas behind the transformations in Propositions 18.12 and 18.13
date back to Girsanov (1960) and Volkonsky (1958), respectively. The
notion of a martingale problem can be traced back to L´evy’s martingale
characterization of Brownian motion and Dynkin’s theory of the charac-
teristic operator. A comprehensive theory was developed by Stroock and

480
Foundations of Modern Probability
Varadhan (1969), who established the equivalence with weak solutions to
the associated SDEs, obtained general criteria for uniqueness in law, and de-
duced conditions for the strong Markov and Feller properties. The measura-
bility part of Theorem 18.10 is a slight extension of an exercise in Stroock
and Varadhan (1979).
Yamada and Watanabe (1971) proved that weak existence and path-
wise uniqueness imply strong existence and uniqueness in law. Under the
same conditions, they further established the existence of a functional solu-
tion, possibly depending on the initial distribution of the process; that depen-
dence was later removed by Kallenberg (1996a). Ikeda and Watanabe
(1981–89) noted how the notions of pathwise uniqueness and uniqueness in
law extend by conditioning from degenerate to arbitrary initial distributions.
The basic theory of SDEs is covered by many excellent textbooks on
diﬀerent levels, including Ikeda and Watanabe (1981–89), Rogers and
Williams (1987), and Karatzas and Shreve (1988–91). More informa-
tion on the martingale problem is available in Jacod (1979), Stroock and
Varadhan (1979), and Ethier and Kurtz (1986).
19. Local Time, Excursions, and Additive Functionals
Local time of Brownian motion at a ﬁxed point was discovered and explored
by L´evy (1939), who devised several explicit constructions, mostly of the
type of Proposition 19.12. Much of L´evy’s analysis is based on the obser-
vation in Corollary 19.3. The elementary Lemma 19.2 is due to Skorohod
(1961–62). Formula (1), ﬁrst noted for Brownian motion by Tanaka (1963),
was taken by Meyer (1976) as the basis for a general semimartingale ap-
proach. The general Itˆo–Tanaka formula in Theorem 19.5 was obtained inde-
pendently by Meyer (1976) and Wang (1977). Trotter (1958b) proved
that Brownian local time has a jointly continuous version, and the extension
to general continuous semimartingales in Theorem 19.4 was obtained by Yor
(1978).
Modern excursion theory originated with the seminal paper of Itˆo (1972),
which was partly inspired by earlier work of L´evy (1939). In particular, Itˆo
proved a version of Theorem 19.11, assuming the existence of local time.
Horowitz (1972) independently studied regenerative sets and noted their
connection with subordinators, equivalent to the existence of a local time. A
systematic theory of regenerative processes was developed by Maisonneuve
(1974).
The remarkable Theorem 19.17 was discovered independently by
Ray (1963) and Knight (1963), and the present proof is essentially due to
Walsh (1978). Our construction of the excursion process is close in spirit
to L´evy’s original ideas and to those in Greenwood and Pitman (1980).
Elementary additive functionals of integral type had been discussed ex-
tensively in the literature when Dynkin proposed a study of the general
case. The existence Theorem 19.23 was obtained by Volkonsky (1960),

Historical and Bibliographical Notes
481
and the construction of local time in Theorem 19.24 dates back to Blumen-
thal and Getoor (1964). The integral representation of CAFs in Theorem
19.25 was proved independently by Volkonsky (1958, 1960) and McKean
and Tanaka (1961). The characterization of additive functionals in terms
of suitable measures on the state space dates back to Meyer (1962), and
the explicit representation of the associated measures was found by Revuz
(1970) after special cases had been considered by Hunt (1957–58).
An excellent introduction to local time appears in Karatzas and Shreve
(1988–91). The books by Itˆo and McKean (1965–96) and Revuz and Yor
(1991–94) contain an abundance of further information on the subject. The
latter text may also serve as a good introduction to additive functionals
and excursion theory. For more information on the latter topics, the reader
may consult Blumenthal and Getoor (1968), Blumenthal (1992), and
Dellacherie, Maisonneuve, and Meyer (1992).
20. One-Dimensional SDEs and Diﬀusions
The study of continuous Markov processes and the associated parabolic dif-
ferential equations, initiated by Kolmogorov (1931a) and Feller (1936),
took a new direction with the seminal papers of Feller (1952, 1954), who
studied the generators of one-dimensional diﬀusions within the framework
of the newly developed semigroup theory. In particular, Feller gave a com-
plete description in terms of scale function and speed measure, classiﬁed the
boundary behavior, and showed how the latter is determined by the domain
of the generator. Finally, he identiﬁed the cases when explosion occurs, cor-
responding to the absorption cases in Theorem 20.15.
A more probabilistic approach to these results was developed by Dynkin
(1955b, 1959), who along with Ray (1956) continued Feller’s study of the
relationship between analytic properties of the generator and sample path
properties of the process. The idea of constructing diﬀusions on a natural
scale through a time change of Brownian motion is due to Hunt (1958)
and Volkonsky (1958), and the full description in Theorem 20.9 was com-
pleted by Volkonsky (1960) and Itˆo and McKean (1965–96). The present
stochastic calculus approach is based on ideas in M´el´eard (1986).
The ratio ergodic Theorem 20.14 was ﬁrst obtained for Brownian motion
by Derman (1954), by a method originally devised for discrete-time chains
by Doeblin (1938).
It was later extended to more general diﬀusions by
Motoo and Watanabe (1958).
The ergodic behavior of recurrent one-
dimensional diﬀusions was analyzed by Maruyama and Tanaka (1957).
For one-dimensional SDEs, Skorohod (1961–65) noticed that Itˆo’s orig-
inal Lipschitz condition for pathwise uniqueness can be replaced by a weaker
H¨older condition. He also obtained a corresponding comparison theorem.
The improved conditions in Theorems 20.3 and 20.5 are due to Yamada
and Watanabe (1971) and Yamada (1973), respectively. Perkins (1982)

482
Foundations of Modern Probability
and Le Gall (1983) noted how the use of semimartingale local time simpli-
ﬁes and uniﬁes the proofs of those and related results. The fundamental weak
existence and uniqueness criteria in Theorem 20.1 were discovered by Eng-
elbert and Schmidt (1984, 1985), whose (1981) zero–one law is implicit
in Lemma 20.2.
Elementary introductions to one-dimensional diﬀusions appear in Brei-
man (1968–92), Freedman (1971–83b), and Rogers and Williams (1987).
More detailed and advanced accounts are given by Dynkin (1963–65) and
Itˆo and McKean (1965–96). Further information on one-dimensional SDEs
may be obtained from the excellent books by Karatzas and Shreve (1988–
91) and Revuz and Yor (1991–94).
21. PDE-Connections and Potential Theory
The fundamental solution to the heat equation in terms of the Gaussian
kernel was obtained by Laplace (1809). A century later Bachelier (1900,
1901) noted the relationship between Brownian motion and the heat equa-
tion. The PDE connections were further explored by many authors, including
Kolmogorov (1931a), Feller (1936), Kac (1951), and Doob (1955). A
ﬁrst version of Theorem 21.1 was obtained by Kac (1949), who was in turn
inspired by Feynman’s (1948) work on the Schr¨odinger equation. Theorem
21.2 is due to Stroock and Varadhan (1969).
Green (1828), in his discussion of the Dirichlet problem, introduced the
functions named after him. The Dirichlet, sweeping, and equilibrium prob-
lems were all studied by Gauss (1840) in a pioneering paper on electrostatics.
The rigorous developments in potential theory began with Poincar´e (1890–
99), who solved the Dirichlet problem for domains with a smooth boundary.
The equilibrium measure was characterized by Gauss as the unique measure
minimizing a certain energy functional, but the existence of the minimum was
not rigorously established until Frostman (1935).
The ﬁrst probabilistic connections were made by Phillips and Wiener
(1923) and Courant, Friedrichs, and Lewy (1928), who solved the
Dirichlet problem in the plane by a method of discrete approximation, in-
volving a version of Theorem 21.5 for a simple symmetric random walk.
Kolmogorov and Leontovich (1933) evaluated a special hitting distri-
bution for two-dimensional Brownian motion and noted that it satisﬁes the
heat equation. Kakutani (1944b, 1945) showed how the harmonic measure
and sweeping kernel can be expressed in terms of a Brownian motion. The
probabilistic methods were extended and perfected by Doob (1954, 1955),
who noted the profound connections with martingale theory. A general po-
tential theory was later developed by Hunt (1957–58) for broad classes of
Markov processes.
The interpretation of Green functions as occupation densities was known
to Kac (1951), and a probabilistic approach to Green functions was devel-

Historical and Bibliographical Notes
483
oped by Hunt (1956). The connection between equilibrium measures and
quitting times, known already to Spitzer (1964) and Itˆo and McKean
(1965–96), was exploited by Chung (1973) to yield the explicit representa-
tion in Theorem 21.14.
Time reversal of diﬀusion processes was ﬁrst considered by Schr¨odinger
(1931). Kolmogorov (1936b, 1937) computed the transition kernels of the
reversed process, and gave necessary and suﬃcient conditions for symmetry.
The basic role of time reversal and duality in potential theory was recog-
nized by Doob (1954) and Hunt (1958). Proposition 21.15 and the related
construction in Theorem 21.21 go back to Hunt, but Theorem 21.19 may
be new. The measure ν in Theorem 21.21 is related to the “Kuznetsov mea-
sures,” discussed extensively in Getoor (1990). The connection between
random sets and alternating capacities was established by Choquet (1953–
54), and a corresponding representation of inﬁnitely divisible random sets
was obtained by Matheron (1975).
Elementary introductions to probabilistic potential theory appear in Bass
(1995) and Chung (1995), and to other PDE connections in Karatzas
and Shreve (1988–91). A detailed exposition of classical probabilistic po-
tential theory is given by Port and Stone (1978).
Doob (1984) pro-
vides a wealth of further information on both the analytic and probabilistic
aspects.
Introductions to Hunt’s work and the subsequent developments
are given by Chung (1982) and Dellacherie and Meyer (1975–87).
More advanced treatments appear in Blumenthal and Getoor (1968)
and Sharpe (1988).
22. Predictability, Compensation, and Excessive Func-
tions
The basic connection between superharmonic functions and supermartin-
gales was established by Doob (1954), who also proved that compositions of
excessive functions with Brownian motion are continuous. Doob further rec-
ognized the need for a general decomposition theorem for supermartingales,
generalizing the elementary Lemma 6.10. Such a result was eventually proved
by Meyer (1962, 1963), in the form of Lemma 22.7, after special decompo-
sitions in the Markovian context had been obtained by Volkonsky (1960)
and Shur (1961).
Meyer’s original proof was profound and clever.
The
present more elementary approach, based on Dunford’s (1939) weak com-
pactness criterion, was devised by Rao (1969a). The extension to general
submartingales was accomplished by Itˆo and Watanabe (1965) through
the introduction of local martingales.
Predictable and totally inaccessible times appear implicitly in the work
of Blumenthal (1957) and Hunt (1957–58), in the context of quasi–left-
continuity. A systematic study of optional times and their associated σ-ﬁelds
was initiated by Chung and Doob (1965). The basic role of the predictable

484
Foundations of Modern Probability
σ-ﬁeld became clear after Dol´eans (1967a) had proved the equivalence be-
tween naturalness and predictability for increasing processes, thereby estab-
lishing the ultimate version of the Doob–Meyer decomposition.
The mo-
ment inequality in Proposition 22.21 was obtained independently by Garsia
(1973) and Neveu (1972–75) after a more special result had been proved by
Burkholder, Davis, and Gundy (1972). The theory of optional and pre-
dictable times and σ-ﬁelds was developed by Meyer (1966), Dellacherie
(1972), and others into a “general theory of processes,” which has in many
ways revolutionized modern probability.
Natural compensators of optional times ﬁrst appeared in reliability the-
ory. More general compensators were later studied in the Markovian context
by Watanabe (1964) under the name of “L´evy systems.”
Grigelionis
(1971) and Jacod (1975) constructed the compensator of a general random
measure and introduced the related “local characteristics” of a general semi-
martingale. Watanabe (1964) proved that a simple point process with a
continuous and deterministic compensator is Poisson; a corresponding time-
change result was obtained independently by Meyer (1971) and Papan-
gelou (1972). The extension in Theorem 22.24 was given by Kallenberg
(1990), and general versions of Proposition 22.27 appear in Rosi´nski and
Woyczy´nski (1986) and Kallenberg (1992).
An authoritative account of the general theory, including a beautiful but
less elementary projection approach to the Doob–Meyer decomposition, due
to Dol´eans, is given by Dellacherie and Meyer (1975–87). Useful in-
troductions to the theory are contained in Elliott (1982) and Rogers and
Williams (1987). Our elementary proof of Lemma 22.10 uses ideas from
Doob (1984). Blumenthal and Getoor (1968) remains a good general
reference on additive functionals and their potentials. A detailed account of
random measures and their compensators appears in Jacod and Shiryaev
(1987). Applications to queuing theory are given by Br´emaud (1981), Bac-
celli and Br´emaud (1994), and Last and Brandt (1995).
23. Semimartingales and General Stochastic Integra-
tion
Doob (1953) conceived the idea of a stochastic integration theory for general
L2-martingales, based on a suitable decomposition of continuous-time sub-
martingales. Meyer’s (1962) proof of such a result opened the door to the
L2-theory, which was then developed by Courr`ege (1962–63) and Kunita
and Watanabe (1967). The latter paper contains in particular a version of
the general substitution rule. The integration theory was later extended in a
series of papers by Meyer (1967) and Dol´eans-Dade and Meyer (1970)
and reached its ﬁnal form with the notes of Meyer (1976) and the books
by Jacod (1979), M´etivier and Pellaumail (1979), and Dellacherie
and Meyer (1975–87).

Historical and Bibliographical Notes
485
The basic role of predictable processes as integrands was recognized by
Meyer (1967). By contrast, semimartingales were originally introduced in
an ad hoc manner by Dol´eans-Dade and Meyer (1970), and their ba-
sic preservation laws were only gradually recognized. In particular, Jacod
(1975) used the general Girsanov theorem of van Schuppen and Wong
(1974) to show that the semimartingale property is preserved under abso-
lutely continuous changes of the probability measure. The characterization
of general stochastic integrators as semimartingales was obtained indepen-
dently by Bichteler (1979) and Dellacherie (1980), in both cases with
support from analysts.
Quasimartingales were originally introduced by Fisk (1965) and Orey
(1966). The decomposition of Rao (1969b) extends a result by Kricke-
berg (1956) for L1-bounded martingales. Yoeurp (1976) combined a no-
tion of “stable subspaces” due to Kunita and Watanabe (1967) with the
Hilbert space structure of M2 to obtain an orthogonal decomposition of L2-
martingales, equivalent to the decompositions in Theorem 23.14 and Propo-
sition 23.16. Elaborating on those ideas, Meyer (1976) showed that the
purely discontinuous component admits a representation as a sum of com-
pensated jumps.
SDEs driven by general L´evy processes were already considered by Itˆo
(1951b). The study of SDEs driven by general semimartingales was initi-
ated by Dol´eans-Dade (1970), who obtained her exponential process as
a solution to the equation in Theorem 23.8. The scope of the theory was
later expanded by many authors, and a comprehensive account is given by
Protter (1990).
The martingale inequalities in Theorems 23.17 and 23.12 have ancient ori-
gins. Thus, a version of (18) for independent random variables was proved by
Kolmogorov (1929), whose original bound was later sharpened by Pro-
horov (1959).
The result was extended to discrete-time martingales by
Johnson, Schechtman, and Zinn (1985) and Hitczenko (1990). The
present statements appeared in Kallenberg and Sztencel (1991).
Early versions of the inequalities in Theorem 23.12 were proved by Khin-
chin (1923, 1924) for symmetric random walks and by Paley (1932) for
Walsh series. A version for independent random variables was obtained by
Marcinkiewicz and Zygmund (1937, 1938). The extension to discrete-
time martingales is due to Burkholder (1966) for p > 1 and to Davis
(1970) for p = 1. The result was extended to continuous time by Burk-
holder, Davis, and Gundy (1972), who also noted how the general re-
sult can be deduced from the statement for p = 1. The present proof is a
continuous-time version of Davis’ original argument.
Excellent introductions to semimartingales and stochastic integration are
given by Dellacherie and Meyer (1975–87) and Jacod and Shiryaev
(1987). Protter (1990) oﬀers an interesting alternative approach, originally
suggested by Meyer and by Dellacherie (1980). The book by Jacod
(1979) remains a rich source of further information on the subject.

Bibliography
This list includes only publications that are explicitly men-
tioned in the text or notes or are directly related to results cited
in the book. Knowledgeable readers will notice that many books
and papers of historical signiﬁcance have been omitted.
Aldous, D.J. (1978). Stopping times and tightness. Ann. Probab. 6, 335–340.
— (1985). Exchangeability and related topics. Lect. Notes in Math. 1117, 1–198.
Springer, Berlin.
Alexandrov, A.D. (1940–43). Additive set-functions in abstract spaces. Mat.
Sb. 8, 307–348; 9, 563–628; 13, 169–238.
Andr´e, D. (1887). Solution directe du probl`eme r´esolu par M. Bertrand. C.R.
Acad. Sci. Paris 105, 436–437.
Athreya, K., McDonald, D., and Ney, P. (1978). Coupling and the renewal
theorem. Amer. Math. Monthly 85, 809–814.
Baccelli, F. and Br´emaud, P. (1994). Elements of Queueing [sic] Theory.
Springer-Verlag, Berlin.
Bachelier, L. (1900). Th´eorie de la sp´eculation. Ann. Sci. ´Ecole Norm. Sup.
17, 21–86.
— (1901).
Th´eorie math´ematique du jeu.
Ann. Sci. ´Ecole Norm. Sup.
18,
143–210.
Bass, R.F. (1995). Probabilistic Techniques in Analysis. Springer-Verlag, New
York.
Bauer, H. (1968–72).
Probability Theory and Elements of Measure Theory.
Engl. trans., Holt, Rinehart & Winston, New York.
Baxter, G. (1961).
An analytic approach to ﬁnite ﬂuctuation problems in
probability. J. d’Analyse Math. 9, 31–70.
Belyaev, Y.K. (1963). Limit theorems for dissipative ﬂows. Theory Probab.
Appl. 8, 165–173.
Bernoulli, J. (1713). Ars Conjectandi. Thurnisiorum, Basel.
Bernstein, S.N. (1927). Sur l’extension du th´eor`eme limite du calcul des prob-
abilit´es aux sommes de quantit´es d´ependantes. Math. Ann. 97, 1–59.
— (1934).
Principes de la th´eorie des ´equations diﬀ´erentielles stochastiques.
Trudy Fiz.-Mat., Steklov Inst., Akad. Nauk. 5, 95–124.
— (1937). On some variations of the Chebyshev inequality (in Russian). Dokl.
Acad. Nauk SSSR 17, 275–277.
— (1938). ´Equations diff´erentielles stochastiques. Act. Sci. Ind. 738, 5–31.
486

Bibliography
487
Bertoin, J. (1996). L´evy Processes. Cambridge University Press, Cambridge.
Bichteler, K. (1979). Stochastic integrators. Bull. Amer. Math. Soc. 1, 761–
765.
Bienaym´e, J. (1853). Consid´erations `a l’appui de la d´ecouverte de Laplace sur
la loi de probabilit´e dans la m´ethode des moindres carr´es. C.R. Acad. Sci.
Paris 37, 309–324.
Billingsley, P. (1965). Ergodic Theory and Information. Wiley, New York.
— (1968). Convergence of Probability Measures. Wiley, New York.
— (1979–95). Probability and Measure, 3rd ed. Wiley, New York.
Birkhoff, G.D. (1932). Proof of the ergodic theorem. Proc. Natl. Acad. Sci.
USA 17, 656–660.
Blackwell, D. (1948). A renewal theorem. Duke Math. J. 15, 145–150.
— (1953). Extension of a renewal theorem. Paciﬁc J. Math. 3, 315–320.
Blumenthal, R.M. (1957). An extended Markov property. Trans. Amer. Math.
Soc. 82, 52–72.
— (1992). Excursions of Markov Processes. Birkh¨auser, Boston.
Blumenthal, R.M. and Getoor, R.K. (1964). Local times for Markov pro-
cesses. Z. Wahrscheinlichkeitstheorie verw. Gebiete 3, 50–74.
— (1968). Markov Processes and Potential Theory. Academic Press, New York.
Bochner, S. (1932–48). Vorlesungen ¨uber Fouriersche Integrale. Reprint ed.,
Chelsea, New York.
— (1933). Monotone Funktionen, Stieltjessche Integrale und harmonische Ana-
lyse. Math. Ann. 108, 378–410.
Boltzmann, L. (1887). ¨Uber die mechanischen Analogien des zweiten Haupt-
satzes der Thermodynamik. J. Reine Angew. Math. 100, 201–212.
Borel, E. (1895). Sur quelques points de la th´eorie des fonctions. Ann. Sci.
´Ecole Norm. Sup. (3) 12, 9–55.
— (1898). Le¸cons sur la Th´eorie des Fonctions. Gauthier-Villars, Paris.
— (1909).
Les probabilit´es d´enombrables et leurs applications arithm´etiques.
Rend. Circ. Mat. Palermo 27 247–271.
Breiman, L. (1968–92). Probability, 2nd ed. SIAM, Philadelphia.
Br´emaud, P. (1981). Point Processes and Queues. Springer-Verlag, New York.
Brown, R. (1828). A brief description of microscopical observations made in
the months of June, July and August 1827, on the particles contained in the
pollen of plants; and on the general existence of active molecules in organic
and inorganic bodies. Ann. Phys. 14, 294–313.
B¨uhlmann, H. (1960). Austauschbare stochastische Variabeln und ihre Grenz-
werts¨atze. Univ. Calif. Publ. Statist. 3, 1–35.
Burkholder, D.L. (1966). Martingale transforms. Ann. Math. Statist. 37,
1494–1504.

488
Foundations of Modern Probability
Burkholder, D.L., Davis, B.J., and Gundy, R.F. (1972). Integral inequal-
ities for convex functions of operators on martingales. Proc. 6th Berkeley
Symp. Math. Statist. Probab. 2, 223–240.
Burkholder, D.L. and Gundy, R.F. (1970). Extrapolation and interpolation
of quasi-linear operators on martingales. Acta Math. 124, 249–304.
Cameron, R.H. and Martin, W.T. (1944). Transformation of Wiener integrals
under translations. Ann. Math. 45, 386–396.
Cantelli, F.P. (1917). Su due applicazione di un teorema di G. Boole alla
statistica matematica. Rend. Accad. Naz. Lincei 26, 295–302.
— (1933). Sulla determinazione empirica della leggi di probabilit`a. Giorn. Ist.
Ital. Attuari 4, 421–424.
Chapman, S. (1928). On the Brownian displacements and thermal diﬀusion of
grains suspended in a non-uniform ﬂuid. Proc. Roy. Soc. London (A) 119,
34–54.
Chebyshev, P.L. (1867). Des valeurs moyennes. J. Math. Pures Appl. 12,
177–184.
— (1890). Sur deux th´eor`emes relatifs aux probabilit´es. Acta Math. 14, 305–315.
Chentsov, N.N. (1956). Weak convergence of stochastic processes whose trajec-
tories have no discontinuities of the second kind and the “heuristic” approach
to the Kolmogorov–Smirnov tests. Theory Probab. Appl. 1, 140–144.
Chernoff, H. and Teicher, H. (1958). A central limit theorem for sequences
of exchangeable random variables. Ann. Math. Statist. 29, 118–130.
Choquet, G. (1953–54). Theory of capacities. Ann. Inst. Fourier Grenoble 5,
131–295.
Chow, Y.S. and Teicher, H. (1978–88). Probability Theory: Independence,
Interchangeability, Martingales, 2nd ed. Springer-Verlag, New York.
Chung, K.L. (1960). Markov Chains with Stationary Transition Probabilities.
Springer-Verlag, Berlin.
— (1968–74). A Course in Probability Theory, 2nd ed. Academic Press, New
York.
— (1973). Probabilistic approach to the equilibrium problem in potential theory.
Ann. Inst. Fourier Grenoble 23, 313–322.
— (1982). Lectures from Markov Processes to Brownian Motion. Springer, New
York.
— (1995). Green, Brown, and Probability. World Scientiﬁc, Singapore.
Chung, K.L. and Doob, J.L. (1965). Fields, optionality and measurability.
Amer. J. Math. 87, 397–424.
Chung, K.L. and Fuchs, W.H.J. (1951). On the distribution of values of sums
of random variables. Mem. Amer. Math. Soc. 6.
Chung, K.L. and Ornstein, D. (1962). On the recurrence of sums of random
variables. Bull. Amer. Math. Soc. 68, 30–32.

Bibliography
489
Chung, K.L. and Walsh, J.B. (1974). Meyer’s theorem on previsibility. Z.
Wahrscheinlichkeitstheorie verw. Gebiete 29, 253–256.
Chung, K.L. and Williams, R.J. (1983–90). Introduction to Stochastic Inte-
gration, 2nd ed. Birkh¨auser, Boston.
Courant, R., Friedrichs, K., and Lewy, H. (1928).
¨Uber die partiellen
Diﬀerentialgleichungen der mathematischen Physik. Math. Ann. 100, 32–
74.
Courr`ege, P. (1962–63).
Int´egrales stochastiques et martingales de carr´e
int´egrable. Sem. Brelot–Choquet–Deny 7. Publ. Inst. H. Poincar´e.
Cram´er, H. (1942). On harmonic analysis in certain functional spaces. Ark.
Mat. Astr. Fys. 28B:12 (17 pp.).
Cram´er, H. and Leadbetter, M.R. (1967). Stationary and Related Stochastic
Processes. Wiley, New York.
Cram´er, H. and Wold, H. (1936). Some theorems on distribution functions.
J. London Math. Soc. 11, 290–295.
Cs¨org¨o, M. and R´ev´esz, P. (1981). Strong Approximations in Probability and
Statistics. Academic Press, New York.
Daley, D.J. and Vere-Jones, D. (1988). An Introduction to the Theory of
Point Processes. Springer-Verlag, New York.
Dambis, K.E. (1965). On the decomposition of continuous submartingales. The-
ory Probab. Appl. 10, 401–410.
Daniell, P.J. (1918–19). Integrals in an inﬁnite number of dimensions. Ann.
Math. (2) 20, 281–288.
— (1919–20). Functions of limited variation in an inﬁnite number of dimensions.
Ann. Math. (2) 21, 30–38.
— (1920). Stieltjes derivatives. Bull. Amer. Math. Soc. 26, 444–448.
Davis, B.J. (1970). On the integrability of the martingale square function. Israel
J. Math. 8, 187–190.
Debes, H., Kerstan, J., Liemant, A., and Matthes, K. (1970). Verallge-
meinerung eines Satzes von Dobrushin I. Math. Nachr. 47, 183–244.
Dellacherie, C. (1972). Capacit´es et Processus Stochastiques. Springer-Verlag,
Berlin.
— (1980). Un survol de la th´eorie de l’int´egrale stochastique. Stoch. Proc. Appl.
10, 115-144.
Dellacherie, C., Maisonneuve, B., and Meyer, P.A. (1992). Probabilit´es
et Potentiel, Vol. 5. Hermann, Paris.
Dellacherie, C. and Meyer, P.A. (1975–87). Probabilit´es et Potentiel, Vols.
1–4. Hermann, Paris. Engl. trans., North-Holland, Amsterdam 1978– .
Derman, C. (1954). Ergodic property of the Brownian motion process. Proc.
Natl. Acad. Sci. USA 40, 1155–1158.
Doeblin, W. (1938). Expos´e de la th´eorie des chaˆınes simples constantes de
Markov `a un nombre ﬁni d’´etats. Rev. Math. Union Interbalkan. 2, 77–105.

490
Foundations of Modern Probability
— (1939a). Sur les sommes d’un grand nombre de variables al´eatoires ind´epen-
dantes. Bull. Sci. Math. 63, 23–64.
— (1939b). Sur certains mouvements al´eatoires discontinus. Skand. Aktuarietid-
skr. 22, 211–222.
D¨ohler, R. (1980). On the conditional independence of random events. Theory
Probab. Appl. 25, 628–634.
Dol´eans(-Dade), C. (1967a). Processus croissants naturel et processus crois-
sants tr`es bien mesurable. C.R. Acad. Sci. Paris 264, 874–876.
— (1967b). Int´egrales stochastiques d´ependant d’un param`etre. Publ. Inst. Stat.
Univ. Paris 16, 23–34.
— (1970). Quelques applications de la formule de changement de variables pour
les semimartingales. Z. Wahrscheinlichkeitstheorie verw. Gebiete 16, 181–
194.
Dol´eans-Dade, C. and Meyer, P.A. (1970). Int´egrales stochastiques par rap-
port aux martingales locales. Lect. Notes in Math. 124, 77–107. Springer-
Verlag, Berlin.
Donsker, M. (1951–52). An invariance principle for certain probability limit
theorems. Mem. Amer. Math. Soc. 6.
— (1952). Justiﬁcation and extension of Doob’s heuristic approach to the Kol-
mogorov–Smirnov theorems. Ann. Math. Statist. 23, 277–281.
Doob, J.L. (1936). Note on probability. Ann. Math. (2) 37, 363–367.
— (1937). Stochastic processes depending on a continuous parameter. Trans.
Amer. Math. Soc. 42, 107–140.
— (1938). Stochastic processes with an integral-valued parameter. Trans. Amer.
Math. Soc. 44, 87–150.
— (1940). Regularity properties of certain families of chance variables. Trans.
Amer. Math. Soc. 47, 455–486.
— (1942a). The Brownian movement and stochastic equations. Ann. Math. 43,
351–369.
— (1942b). Topics in the theory of Markoﬀchains. Trans. Amer. Math. Soc. 52,
37–64.
— (1945).
Markoﬀchains—denumerable case.
Trans. Amer. Math. Soc. 58,
455–473.
— (1947). Probability in function space. Bull. Amer. Math. Soc. 53, 15–30.
— (1949). Heuristic approach to the Kolmogorov–Smirnov theorems. Ann. Math.
Statist. 20, 393–403.
— (1951). Continuous parameter martingales. Proc. 2nd Berkeley Symp. Math.
Statist. Probab., 269–277.
— (1953). Stochastic Processes. Wiley, New York.
— (1954). Semimartingales and subharmonic functions. Trans. Amer. Math.
Soc. 77, 86–121.

Bibliography
491
— (1955). A probability approach to the heat equation. Trans. Amer. Math.
Soc. 80, 216–280.
— (1984). Classical Potential Theory and its Probabilistic Counterpart. Springer-
Verlag, New York.
— (1994). Measure Theory. Springer-Verlag, New York.
Dubins, L.E. (1968).
On a theorem of Skorohod.
Ann. Math. Statist.
39,
2094–2097.
Dubins, L.E. and Schwarz, G. (1965). On continuous martingales. Proc. Natl.
Acad. Sci. USA 53, 913–916.
Dudley, R.M. (1966). Weak convergence of probabilities on nonseparable met-
ric spaces and empirical measures on Euclidean spaces. Illinois J. Math. 10,
109–126.
— (1967). Measures on non-separable metric spaces. Illinois J. Math. 11, 449–
453.
— (1968). Distances of probability measures and random variables. Ann. Math.
Statist. 39, 1563–1572.
— (1989). Real Analysis and Probability. Wadsworth, Brooks & Cole, Paciﬁc
Grove, CA.
Dunford, N. (1939). A mean ergodic theorem. Duke Math. J. 5, 635–646.
Durrett, R. (1984). Brownian Motion and Martingales in Analysis. Wads-
worth, Belmont, CA.
— (1991–95). Probability Theory and Examples, 2nd ed. Wadsworth, Brooks &
Cole, Paciﬁc Grove, CA.
Dvoretzky, A. (1972). Asymptotic normality for sums of dependent random
variables. Proc. 6th Berkeley Symp. Math. Statist. Probab. 2, 513–535.
Dynkin, E.B. (1952). Criteria of continuity and lack of discontinuities of the
second kind for trajectories of a Markov stochastic process (in Russian). Izv.
Akad. Nauk SSSR, Ser. Mat. 16, 563–572.
— (1955a). Inﬁnitesimal operators of Markov stochastic processes (in Russian).
Dokl. Akad. Nauk SSSR 105, 206–209.
— (1955b). Continuous one-dimensional Markov processes (in Russian). Dokl.
Akad. Nauk SSSR 105, 405–408.
— (1956). Markov processes and semigroups of operators. Inﬁnitesimal operators
of Markov processes. Theory Probab. Appl. 1, 25–60.
— (1959). One-dimensional continuous strong Markov processes. Theory Probab.
Appl. 4, 3–54.
— (1959–61). Theory of Markov Processes. Engl. trans., Prentice-Hall and Perg-
amon Press, Englewood Cliﬀs, NJ, and Oxford.
— (1963–65). Markov Processes, Vols. 1–2. Engl. trans., Springer-Verlag, Berlin.
— (1978). Suﬃcient statistics and extreme points. Ann. Probab. 6, 705–730.

492
Foundations of Modern Probability
Dynkin, E.B. and Yushkevich, A.A. (1956). Strong Markov processes. The-
ory Probab. Appl. 1, 134–139.
Einstein, A. (1905). On the movement of small particles suspended in a station-
ary liquid demanded by the molecular-kinetic theory of heat. Engl. trans.
in Investigations on the Theory of the Brownian Movement. Reprint ed.,
Dover, New York 1956.
— (1906). On the theory of Brownian motion. Engl. trans. in Investigations on
the Theory of the Brownian Movement. Reprint ed., Dover, New York 1956.
Elliott, R.J. (1982). Stochastic Calculus and Applications. Springer-Verlag,
New York.
Engelbert, H.J. and Schmidt, W. (1981). On the behaviour of certain func-
tionals of the Wiener process and applications to stochastic diﬀerential equa-
tions. Lect. Notes in Control and Inform. Sci. 36, 47–55.
— (1984). On one-dimensional stochastic diﬀerential equations with generalized
drift. Lect. Notes in Control and Inform. Sci. 69, 143–155. Springer-Verlag,
Berlin.
— (1985).
On solutions of stochastic diﬀerential equations without drift.
Z.
Wahrscheinlichkeitstheorie verw. Gebiete 68, 287–317.
Erd¨os, P., Feller, W., and Pollard, H. (1949). A theorem on power series.
Bull. Amer. Math. Soc. 55, 201–204.
Erd¨os, P. and Kac, M. (1946). On certain limit theorems in the theory of
probability. Bull. Amer. Math. Soc. 52, 292–302.
— (1947). On the number of positive sums of independent random variables.
Bull. Amer. Math. Soc. 53, 1011–1020.
Erlang, A.K. (1909). The theory of probabilities and telephone conversations.
Nyt. Tidskr. Mat. B 20, 33–41.
Ethier, S.N. and Kurtz, T.G. (1986). Markov Processes: Characterization
and Convergence. Wiley, New York.
Faber, G. (1910). ¨Uber stetige Funktionen, II. Math. Ann. 69, 372–443.
Farrell, R.H. (1962). Representation of invariant measures. Illinois J. Math.
6, 447–467.
Fatou, P. (1906). S´eries trigonom´etriques et s´eries de Taylor. Acta Math. 30,
335–400.
Fell, J.M.G. (1962). A Hausdorﬀtopology for the closed subsets of a locally
compact non-Hausdorﬀspace. Proc. Amer. Math. Soc. 13, 472–476.
Feller, W. (1935–37). ¨Uber den zentralen Grenzwertsatz der Wahrscheinlich-
keitsrechnung, I–II. Math. Z. 40, 521–559; 42, 301–312.
— (1936). Zur Theorie der stochastischen Prozesse (Existenz und Eindeutigkeits-
s¨atze). Math. Ann. 113, 113–160.
— (1937). On the Kolmogoroﬀ–P. L´evy formula for inﬁnitely divisible distribu-
tion functions. Proc. Yugoslav Acad. Sci. 82, 95–112.

Bibliography
493
— (1940). On the integro-diﬀerential equations of purely discontinuous Markoﬀ
processes. Trans. Amer. Math. Soc. 48, 488–515; 58, 474.
— (1949). Fluctuation theory of recurrent events. Trans. Amer. Math. Soc. 67,
98–119.
— (1950–68; 1966–71). An Introduction to Probability Theory and its Applica-
tions, Vol. 1 (3rd ed.) and Vol. 2 (2nd ed.). Wiley, New York.
— (1952). The parabolic diﬀerential equations and the associated semi-groups of
transformations. Ann. Math. 55, 468–519.
— (1954). Diﬀusion processes in one dimension. Trans. Amer. Math. Soc. 77,
1–31.
Feller, W. and Orey, S. (1961). A renewal theorem. J. Math. Mech. 10,
619–624.
Feynman, R.P. (1948). Space-time approach to nonrelativistic quantum me-
chanics. Rev. Mod. Phys. 20, 367–387.
Finetti, B. de (1929). Sulle funzioni ad incremento aleatorio. Rend. Acc. Naz.
Lincei 10, 163–168.
— (1931). Fuzione caratteristica di un fenomeno aleatorio. Atti Acc. Naz. Lincei
4, 251–299.
— (1937). La pr´evision: ses lois logiques, ses sources subjectives. Ann. Inst. H.
Poincar´e 7, 1–68.
Fisk, D.L. (1965). Quasimartingales. Trans. Amer. Math. Soc. 120, 369–389.
— (1966). Sample quadratic variation of continuous, second-order martingales.
Z. Wahrscheinlichkeitstheorie verw. Gebiete 6, 273–278.
Fortet, R. (1943).
Les fonctions al´eatoires du type de Markoﬀassoci´ees `a
certaines ´equations lin´eaires aux d´eriv´ees partielles du type parabolique. J.
Math. Pures Appl. 22, 177–243.
Fr´echet, M. (1928). Les Espaces Abstraits. Gauthier-Villars, Paris.
Freedman, D. (1962–63). Invariants under mixing which generalize de Finetti’s
theorem. Ann. Math. Statist. 33, 916–923; 34, 1194–1216.
— (1971–83a). Markov Chains, 2nd ed. Springer-Verlag, New York.
— (1971–83b). Brownian Motion and Diﬀusion, 2nd ed. Springer-Verlag, New
York.
Frostman, O. (1935).
Potentiel d’´equilibre et capacit´e des ensembles avec
quelques applications `a la th´eorie des fonctions. Medd. Lunds Univ. Mat.
Sem. 3, 1-118.
Fubini, G. (1907). Sugli integrali multipli. Rend. Acc. Naz. Lincei 16, 608–614.
Furstenberg, H. and Kesten, H. (1960). Products of random matrices. Ann.
Math. Statist. 31, 457–469.
Galmarino, A.R. (1963). Representation of an isotropic diﬀusion as a skew
product. Z. Wahrscheinlichkeitstheorie verw. Gebiete 1, 359–378.
Garsia, A.M. (1965). A simple proof of E. Hopf’s maximal ergodic theorem. J.
Math. Mech. 14, 381–382.

494
Foundations of Modern Probability
— (1973). Martingale Inequalities: Seminar Notes on Recent Progress. Math.
Lect. Notes Ser. Benjamin, Reading, MA.
Gauss, C.F. (1809). Theory of Motion of the Heavenly Bodies. Engl. trans.,
Dover, New York 1963.
— (1840). Allgemeine Lehrs¨atze in Beziehung auf die im vehrkehrten Verh¨altnisse
des Quadrats der Entfernung wirkenden Anziehungs- und Abstossungs-
Kr¨afte. Gauss Werke 5, 197–242. G¨ottingen 1867.
Getoor, R.K. (1990). Excessive Measures. Birkh¨auser, Boston.
Getoor, R.K. and Sharpe, M.J. (1972).
Conformal martingales.
Invent.
Math. 16, 271–308.
Gihman, I.I. (1947). On a method of constructing random processes (in Rus-
sian). Dokl. Akad. Nauk SSSR 58, 961–964.
— (1950–51). On the theory of diﬀerential equations for random processes, I–II
(in Russian). Ukr. Mat. J. 2:4, 37–63; 3:3, 317–339.
Gihman, I.I. and Skorohod, A.V. (1965–96). Introduction to the Theory of
Random Processes. Engl. trans., reprint, Dover, Mineola.
— (1971–79).
The Theory of Stochastic Processes, Vols. 1–3.
Engl. trans.,
Springer-Verlag, Berlin.
Girsanov, I.V. (1960). On transforming a certain class of stochastic processes
by absolutely continuous substitution of measures. Theory Probab. Appl. 5,
285–301.
Glivenko, V.I. (1933). Sulla determinazione empirica della leggi di probabilit`a.
Giorn. Ist. Ital. Attuari 4, 92–99.
Gnedenko, B.V. (1939). On the theory of limit theorems for sums of inde-
pendent random variables (in Russian). Izv. Akad. Nauk SSSR Ser. Mat.
181–232, 643–647.
Gnedenko, B.V. and Kolmogorov, A.N. (1949–68). Limit Distributions for
Sums of Independent Random Variables, 2nd Engl. ed.
Addison-Wesley,
Reading, MA.
Goldman, J.R. (1967). Stochastic point processes: Limit theorems. Ann. Math.
Statist. 38, 771–779.
Goldstein, J.A. (1976). Semigroup-theoretic proofs of the central limit theorem
and other theorems of analysis. Semigroup Forum 12, 189–206.
Grandell, J. (1976).
Doubly Stochastic Poisson Processes.
Lect. Notes in
Math. 529. Springer-Verlag, Berlin.
Green, G. (1828).
An essay on the application of mathematical analysis to
the theories of electricity and magnetism. Repr. in Mathematical Papers,
Chelsea, New York 1970.
Greenwood, P. and Pitman, J. (1980). Construction of local time and Poisson
point processes from nested arrays. J. London Math. Soc. (2) 22, 182–192.
Grigelionis, B. (1963). On the convergence of sums of random step processes
to a Poisson process. Theory Probab. Appl. 8, 172–182.

Bibliography
495
— (1971). On the representation of integer-valued measures by means of stochas-
tic integrals with respect to Poisson measure. Litovsk. Mat. Sb. 11, 93–108.
Hagberg, J. (1973).
Approximation of the summation process obtained by
sampling from a ﬁnite population. Theory Probab. Appl. 18, 790–803.
H´ajek, J. (1960). Limiting distributions in simple random sampling from a ﬁnite
population. Magyar Tud. Akad. Mat. Kutat´o Int. K¨ozl. 5, 361–374.
Hall, P. and Heyde, C.C. (1980). Martingale Limit Theory and its Applica-
tion. Academic Press, New York.
Halmos, P.R. (1950–74). Measure Theory, 2nd ed. Springer-Verlag, New York.
Hartman, P. and Wintner, A. (1941). On the law of the iterated logarithm.
J. Math. 63, 169–176.
Helly, E. (1911–12).
¨Uber lineare Funktionaloperatoren.
Sitzungsber. Nat.
Kais. Akad. Wiss. 121, 265–297.
Hewitt, E. and Savage, L.J. (1955). Symmetric measures on Cartesian prod-
ucts. Trans. Amer. Math. Soc. 80, 470–501.
Hille, E. (1948). Functional analysis and semi-groups. Amer. Math. Colloq.
Publ. 31, New York.
Hitczenko, P. (1990).
Best constants in martingale version of Rosenthal’s
inequality. Ann. Probab. 18, 1656–1668.
Hopf, E. (1937). Ergodentheorie. Springer-Verlag, Berlin.
Horowitz, J. (1972). Semilinear Markov processes, subordinators and renewal
theory. Z. Wahrscheinlichkeitstheorie verw. Gebiete 24, 167–193.
Hunt, G.A. (1956). Some theorems concerning Brownian motion. Trans. Amer.
Math. Soc. 81, 294–319.
— (1957–58). Markoﬀprocesses and potentials, I–III. Illinois J. Math. 1, 44–93,
316–369; 2, 151–213.
Ikeda, N. and Watanabe, S. (1981–89). Stochastic Diﬀerential Equations and
Diﬀusion Processes, 2nd ed. North-Holland and Kodansha, Amsterdam and
Tokyo.
Ionescu Tulcea, C.T. (1949–50).
Mesures dans les espaces produits.
Atti
Accad. Naz. Lincei Rend. 7, 208–211.
Itˆo,
K.
(1942a).
Diﬀerential
equations
determining
Markov
processes
(in Japanese). Zenkoku Shij¯o S¯ugaku Danwakai 244:1077, 1352–1400.
— (1942b). On stochastic processes (I) (Inﬁnitely divisible laws of probability).
Jap. J. Math. 18, 261–301.
— (1944). Stochastic integral. Proc. Imp. Acad. Tokyo 20, 519–524.
— (1946). On a stochastic integral equation. Proc. Imp. Acad. Tokyo 22, 32–35.
— (1951a). On a formula concerning stochastic diﬀerentials. Nagoya Math. J. 3,
55–65.
— (1951b).
On stochastic diﬀerential equations.
Mem. Amer. Math. Soc. 4,
1–51.

496
Foundations of Modern Probability
— (1951c). Multiple Wiener integral. J. Math. Soc. Japan 3, 157–169.
— (1957). Stochastic Processes (in Japanese). Iwanami Shoten, Tokyo.
— (1972).
Poisson point processes attached to Markov processes.
Proc. 6th
Berkeley Symp. Math. Statist. Probab. 3, 225–239.
— (1978–84). Introduction to Probability Theory. Engl. trans., Cambridge Uni-
versity Press, Cambridge.
Itˆo, K. and McKean, H.P. (1965–96). Diﬀusion Processes and their Sample
Paths. Reprint ed., Springer-Verlag, Berlin.
Itˆo, K. and Watanabe, S. (1965).
Transformation of Markov processes by
multiplicative functionals. Ann. Inst. Fourier 15, 15–30.
Jacod, J. (1975). Multivariate point processes: Predictable projection, Radon-
Nikodym derivative, representation of martingales. Z. Wahrscheinlichkeits-
theorie verw. Gebiete 31, 235–253.
— (1979). Calcul Stochastique et Probl`emes de Martingales. Lect. Notes in Math.
714. Springer-Verlag, Berlin.
Jacod, J. and Shiryaev, A.N. (1987). Limit Theorems for Stochastic Processes.
Springer, Berlin.
Jagers, P. (1972). On the weak convergence of superpositions of point processes.
Z. Wahrscheinlichkeitstheorie verw. Gebiete 22, 1–7.
Jensen, J.L.W.V. (1906). Sur les fonctions convexes et les in´egalit´es entre les
valeurs moyennes. Acta Math. 30, 175–193.
Jessen, B. (1934). The theory of integration in a space of an inﬁnite number of
dimensions. Acta Math. 63, 249–323.
Johnson, W.B., Schechtman, G., and Zinn, J. (1985). Best constants in mo-
ment inequalities for linear combinations of independent and exchangeable
random variables. Ann. Probab. 13, 234–253.
Kac, M. (1949). On distributions of certain Wiener functionals. Trans. Amer.
Math. Soc. 65, 1–13.
— (1951). On some connections between probability theory and diﬀerential and
integral equations. Proc. 2nd Berkeley Symp. Math. Statist. Probab., 189–
215. Univ. of California Press, Berkeley.
Kakutani, S. (1944a).
On Brownian motions in n-space.
Proc. Imp. Acad.
Tokyo 20, 648–652.
— (1944b). Two-dimensional Brownian motion and harmonic functions. Proc.
Imp. Acad. Tokyo 20, 706–714.
— (1945). Markoﬀprocess and the Dirichlet problem. Proc. Japan Acad. 21,
227–233.
Kallenberg, O. (1973a). Characterization and convergence of random mea-
sures and point processes. Z. Wahrscheinlichkeitstheorie verw. Gebiete 27,
9–21.
— (1973b). Canonical representations and convergence criteria for processes with
interchangeable increments. Z. Wahrscheinlichkeitstheorie verw. Gebiete 27,
23–36.

Bibliography
497
— (1975–86). Random Measures, 4th ed. Akademie-Verlag and Academic Press,
Berlin and London.
— (1987). Homogeneity and the strong Markov property. Ann. Probab. 15,
213–240.
— (1988). Spreading and predictable sampling in exchangeable sequences and
processes. Ann. Probab. 16, 508–534.
— (1989).
General Wald-type identities for exchangeable sequences and pro-
cesses. Probab. Th. Rel. Fields 83, 447–487.
— (1990). Random time change and an integral representation for marked stop-
ping times. Probab. Th. Rel. Fields 86, 167–202.
— (1992). Some time change representations of stable integrals, via predictable
transformations of local martingales. Stoch. Proc. Appl. 40, 199–223.
— (1996a). On the existence of universal functional solutions to classical SDEs.
Ann. Probab. 24, 196–205.
— (1996b). Improved criteria for distributional convergence of point processes.
Stoch. Proc. Appl. 64, 93–102.
— (1998). Components of the strong Markov property. In Stochastic Processes
& Related Topics: A Volume in Memory of Stamatis Cambanis, 1943–1995.
Birkh¨auser, Boston (to appear).
Kallenberg, O. and Sztencel, R. (1991). Some dimension-free features of
vector-valued martingales. Probab. Th. Rel. Fields 88, 215–247.
Kallianpur, G. (1980).
Stochastic Filtering Theory.
Springer-Verlag, New
York.
Karamata, J. (1930). Sur une mode de croissance r´eguli`ere des fonctions. Math-
ematica (Cluj) 4, 38–53.
Karatzas, I. and Shreve, S.E. (1988–91). Brownian Motion and Stochastic
Calculus, 2nd ed. Springer-Verlag, New York.
Kazamaki, N. (1972). Change of time, stochastic integrals and weak martin-
gales. Z. Wahrscheinlichkeitstheorie verw. Gebiete 22, 25–32.
Kemeny, J.G., Snell, J.L., and Knapp, A.W. (1966). Denumerable Markov
Chains. Van Nostrand, Princeton.
Kendall, D.G. (1974). Foundations of a theory of random sets. In Stochastic
Geometry (eds. E.F. Harding, D.G. Kendall), pp. 322–376. Wiley, New York.
Khinchin, A.Y. (1923). ¨Uber dyadische Br¨ucke. Math. Z. 18, 109–116.
— (1924).
¨Uber einen Satz der Wahrscheinlichkeitsrechnung. Fund. Math. 6,
9–20.
— (1933).
Zur mathematischen Begr¨unding der statistischen Mechanik.
Z.
Angew. Math. Mech. 13, 101–103.
— (1933–48). Asymptotische Gesetze der Wahrscheinlichkeitsrechnung. Reprint
ed., Chelsea, New York.

498
Foundations of Modern Probability
— (1934). Korrelationstheorie der station¨aren stochastischen Prozesse. Math.
Ann. 109, 604–615.
— (1937). Zur Theorie der unbeschr¨ankt teilbaren Verteilungsgesetze. Mat. Sb.
2, 79–119.
— (1938). Limit Laws for Sums of Independent Random Variables (in Russian).
Moscow and Leningrad.
— (1955–60). Mathematical Methods in the Theory of Queuing. Engl. trans.,
Griﬃn, London.
Khinchin, A.Y. and Kolmogorov, A.N. (1925). ¨Uber Konvergenz von Reihen
deren Glieder durch den Zufall bestimmt werden. Mat. Sb. 32, 668–676.
Kingman, J.F.C. (1968). The ergodic theory of subadditive stochastic processes.
J. Roy. Statist. Soc. (B) 30, 499–510.
— (1972). Regenerative Phenomena. Wiley, New York.
Kinney, J.R. (1953). Continuity properties of Markov processes. Trans. Amer.
Math. Soc. 74, 280–302.
Knight, F.B. (1963). Random walks and a sojourn density process of Brownian
motion. Trans. Amer. Math. Soc. 107, 56–86.
— (1971). A reduction of continuous, square-integrable martingales to Brownian
motion. Lect. Notes in Math. 190, 19–31. Springer-Verlag, Berlin.
Kolmogorov, A.N. (1928–29). ¨Uber die Summen durch den Zufall bestimmter
unabh¨angiger Gr¨ossen. Math. Ann. 99, 309–319; 102, 484–488.
— (1929). ¨Uber das Gesatz des iterierten Logarithmus. Math. Ann. 101, 126–
135.
— (1930). Sur la loi forte des grandes nombres. C.R. Acad. Sci. Paris 191,
910–912.
— (1931a). ¨Uber die analytischen Methoden in der Wahrscheinlichkeitsrechnung.
Math. Ann. 104, 415–458.
— (1931b). Eine Verallgemeinerung des Laplace–Liapounoﬀschen Satzes. Izv.
Akad. Nauk USSR, Otdel. Matem. Yestestv. Nauk 1931, 959–962.
— (1932). Sulla forma generale di un processo stocastico omogeneo (un problema
di B. de Finetti). Atti Accad. Naz. Lincei Rend. (6) 15, 805–808, 866–869.
— (1933a).
¨Uber die Grenzwerts¨atze der Wahrscheinlichkeitsrechnung.
Izv.
Akad. Nauk USSR, Otdel. Matem. Yestestv. Nauk 1933, 363–372.
— (1933b). Zur Theorie der stetigen zuf¨alligen Prozesse. Math. Ann. 108, 149–
160.
— (1933–56). Foundations of the Theory of Probability. Engl. trans., Chelsea,
New York.
— (1935). Some current developments in probability theory (in Russian). Proc.
2nd All-Union Math. Congr. 1, 349–358. Akad. Nauk SSSR, Leningrad.
— (1936a). Anfangsgr¨unde der Markoﬀschen Ketten mit unendlich vielen m¨og-
lichen Zust¨anden. Mat. Sb. 1, 607–610.
— (1936b). Zur Theorie der Markoﬀschen Ketten. Math. Ann. 112, 155–160.

Bibliography
499
— (1937). Zur Umkehrbarkeit der statistischen Naturgesetze. Math. Ann. 113,
766–772.
— (1956). On Skorohod convergence. Theory Probab. Appl. 1, 213–222.
Kolmogorov, A.N. and Leontovich, M.A. (1933). Zur Berechnung der mitt-
leren Brownschen Fl¨ache. Physik. Z. Sowjetunion 4, 1–13.
Koml´os, J., Major, P., and Tusn´ady, G. (1975–76). An approximation of
partial sums of independent r.v.’s and the sample d.f., I–II. Z. Wahrschein-
lichkeitstheorie verw. Gebiete 32, 111–131; 34, 33–58.
Krickeberg, K. (1956). Convergence of martingales with a directed index set.
Trans. Amer. Math. Soc. 83, 313–357.
Krylov, N. and Bogolioubov, N. (1937). La th´eorie g´en´erale de la mesure
dans son application `a l’´etude des syst`emes de la m´ecanique non lin´eaires.
Ann. Math. 38, 65–113.
Kunita, H. and Watanabe, S. (1967).
On square integrable martingales.
Nagoya Math. J. 30, 209–245.
Kurtz, T.G. (1969). Extensions of Trotter’s operator semigroup approximation
theorems. J. Funct. Anal. 3, 354–375.
— (1975). Semigroups of conditioned shifts and approximation of Markov pro-
cesses. Ann. Probab. 3, 618–642.
Kwapie´n, S. and Woyczy´nski, W.A. (1992). Random Series and Stochastic
Integrals: Single and Multiple. Birkh¨auser, Boston.
Langevin, P. (1908). Sur la th´eorie du mouvement brownien. C.R. Acad. Sci.
Paris 146, 530–533.
Laplace, P.S. de (1774).
M´emoire sur la probabilit´e des causes par les
´ev´enemens. Engl. trans. in Statistical Science 1, 359–378.
— (1809). M´emoire sur divers points d’analyse. Repr. in Oeuvres Compl`etes de
Laplace 14, 178–214. Gauthier-Villars, Paris 1886–1912.
— (1812–20).
Th´eorie Analytique des Probabilit´es, 3rd ed.
Repr. in Oeuvres
Compl`etes de Laplace 7. Gauthier-Villars, Paris 1886–1912.
Last, G. and Brandt, A. (1995). Marked Point Processes on the Real Line:
The Dynamic Approach. Springer-Verlag, New York.
Leadbetter, M.R., Lindgren, G., and Rootz´en, H. (1983). Extremes and
Related Properties of Random Sequences and Processes.
Springer-Verlag,
New York.
Lebesgue, H. (1902). Int´egrale, longeur, aire. Ann. Mat. Pura Appl. 7, 231–
359.
— (1904).
Le¸cons sur l’Int´egration et la Recherche des Fonctions Primitives.
Paris.
Le Cam, L. (1957). Convergence in distribution of stochastic processes. Univ.
California Publ. Statist. 2, 207–236.
Le Gall, J.F. (1983). Applications des temps locaux aux ´equations diﬀ´erentielles
stochastiques unidimensionelles. Lect. Notes in Math. 986, 15–31.

500
Foundations of Modern Probability
Levi, B. (1906). Sopra l’integrazione delle serie. Rend. Ist. Lombardo Sci. Lett.
(2) 39, 775–780.
L´evy, P. (1922a). Sur le rˆole de la loi de Gauss dans la theorie des erreurs. C.R.
Acad. Sci. Paris 174, 855–857.
— (1922b). Sur la loi de Gauss. C.R. Acad. Sci. Paris 1682–1684.
— (1922c). Sur la d´etermination des lois de probabilit´e par leurs fonctions ca-
ract´eristiques. C.R. Acad. Sci. Paris 175, 854–856.
— (1924). Th´eorie des erreurs. La loi de Gauss et les lois exceptionelles. Bull.
Soc. Math. France 52, 49–85.
— (1925). Calcul des Probabilit´es. Gauthier-Villars, Paris.
— (1934–35). Sur les int´egrales dont les ´el´ements sont des variables al´eatoires
ind´ependantes. Ann. Scuola Norm. Sup. Pisa (2) 3, 337–366; 4, 217–218.
— (1935a). Propri´et´es asymptotiques des sommes de variables al´eatoires ind´e-
pendantes ou enchain´ees. J. Math. Pures Appl. (8) 14, 347–402.
— (1935b).
Propri´et´es asymptotiques des sommes de variables al´eatoires en-
chain´ees. Bull. Sci. Math. (2) 59, 84–96, 109–128.
— (1937–54). Th´eorie de l’Addition des Variables Al´eatoires, 2nd ed. Gauthier-
Villars, Paris.
— (1939).
Sur certain processus stochastiques homog`enes.
Comp. Math.
7,
283–339.
— (1940). Le mouvement brownien plan. Amer. J. Math. 62, 487–550.
— (1948–65). Processus Stochastiques et Mouvement Brownien, 2nd ed. Gauthier-
Villars, Paris.
Liapounov, A.M. (1901). Nouvelle forme du th´eor`eme sur la limite des proba-
bilit´es. Mem. Acad. Sci. St. Petersbourg 12, 1–24.
Liggett, T.M. (1985). An improved subadditive ergodic theorem. Ann. Probab.
13, 1279–1285.
Lindeberg, J.W. (1922a). Eine neue Herleitung des Exponentialgesetzes in der
Wahrscheinlichkeitsrechnung. Math. Zeitschr. 15, 211–225.
— (1922b). Sur la loi de Gauss. C.R. Acad. Sci. Paris 174, 1400–1402.
Lindvall, T. (1973). Weak convergence of probability measures and random
functions in the function space D[0, ∞). J. Appl. Probab. 10, 109–121.
— (1977). A probabilistic proof of Blackwell’s renewal theorem. Ann. Probab.
5, 482–485.
— (1992). Lectures on the Coupling Method. Wiley, New York.
Liptser, R.S. and Shiryaev, A.N. (1977). Statistics of Random Processes,
I–II. Engl. trans., Springer-Verlag, Berlin.
Lo`eve, M. (1955–78). Probability Theory, Vols. 1–2, 4th ed. Springer-Verlag,
New York.
1Lomnicki, Z. and Ulam, S. (1934). Sur la th´eorie de la mesure dans les es-
paces combinatoires et son application au calcul des probabilit´es: I. Variables
ind´ependantes. Fund. Math. 23, 237–278.

Bibliography
501
Lukacs, E. (1960–70). Characteristic Functions, 2nd ed. Griﬃn, London.
Lundberg, F. (1903). Approximerad Framst¨allning av Sannolikhetsfunktionen.
˚
Aterf¨ors¨akring av Kollektivrisker. Thesis, Uppsala.
Mackeviˇcius, V. (1974). On the question of the weak convergence of random
processes in the space D[0, ∞). Lithuanian Math. Trans. 14, 620–623.
Maisonneuve, B. (1974). Syst`emes R´eg´en´eratifs. Ast´erique 15. Soc. Math. de
France.
Mann, H.B. and Wald, A. (1943). On stochastic limit and order relations.
Ann. Math. Statist. 14, 217–226.
Marcinkiewicz, J. and Zygmund, A. (1937). Sur les fonctions ind´ependantes.
Fund. Math. 29, 60–90.
— (1938). Quelques th´eor`emes sur les fonctions ind´ependantes. Studia Math. 7,
104–120.
Markov, A.A. (1899). The law of large numbers and the method of least squares
(in Russian). Izv. Fiz.-Mat. Obshch. Kazan Univ. (2) 8, 110–128.
— (1906). Extension of the law of large numbers to dependent events (in Rus-
sian). Bull. Soc. Phys. Math. Kazan (2) 15, 135–156.
Maruyama, G. (1954). On the transition probability functions of the Markov
process. Natl. Sci. Rep. Ochanomizu Univ. 5, 10–20.
— (1955). Continuous Markov processes and stochastic equations. Rend. Circ.
Mat. Palermo 4, 48–90.
Maruyama, G. and Tanaka, H. (1957). Some properties of one-dimensional
diﬀusion processes. Mem. Fac. Sci. Kyushu Univ. 11, 117–141.
Matheron, G. (1975). Random Sets and Integral Geometry. Wiley, London.
Matthes, K., Kerstan, J., and Mecke, J. (1974–82).
Inﬁnitely Divisible
Point Processes. Engl. ed., Wiley, Chichester 1978. Russian ed., Nauka,
Moscow 1982.
McKean, H.P. Jr. (1969). Stochastic Integrals. Academic Press, New York.
McKean, H.P. Jr. and Tanaka, H. (1961). Additive functionals of the Brow-
nian path. Mem. Coll. Sci. Univ. Kyoto, A 33, 479–506.
Mecke, J. (1968). Eine characteristische Eigenschaft der doppelt stochastischen
Poissonschen Prozesse. Z. Wahrscheinlichkeitstheorie verw. Gebiete 11, 74–
81.
M´el´eard, S. (1986). Application du calcul stochastique `a l’´etude des processus
de Markov r´eguliers sur [0, 1]. Stochastics 19, 41–82.
M´etivier, M. (1982). Semimartingales: A Course on Stochastic Processes. de
Gruyter, Berlin.
M´etivier, M. and Pellaumail, J. (1980). Stochastic Integration. Academic
Press, New York.
Meyer, P.A. (1962). A decomposition theorem for supermartingales. Illinois
J. Math. 6, 193–205.

502
Foundations of Modern Probability
— (1963). Decomposition of supermartingales: The uniqueness theorem. Illinois
J. Math. 7, 1–17.
— (1966). Probability and Potentials. Engl. trans., Blaisdell, Waltham.
— (1967).
Int´egrales stochastiques, I–IV. Lect. Notes in Math.
39, 72–162.
Springer-Verlag, Berlin.
— (1971). D´emonstration simpliﬁ´ee d’un th´eor`eme de Knight. Lect. Notes in
Math. 191, 191–195. Springer-Verlag, Berlin.
— (1976). Un cours sur les int´egrales stochastiques. Lect. Notes in Math. 511,
245–398. Springer-Verlag, Berlin.
Millar, P.W. (1968).
Martingale integrals.
Trans. Amer. Math. Soc. 133,
145–166.
Mitoma, I. (1983). Tightness of probabilities on C([0, 1]; S′) and D([0, 1]; S′).
Ann. Probab. 11, 989–999.
Moivre, A. de (1711–12). On the measurement of chance. Engl. trans., Int.
Statist. Rev. 52, 229–262.
— (1718–56). The Doctrine of Chances; or, a Method of Calculating the Proba-
bility of Events in Play, 3rd ed. (post.) Reprint ed., F. Case and Chelsea,
London and New York 1967.
— (1733–56). Approximatio ad Summam Terminorum Binomii a + b|n in Seriem
Expansi. Translated and edited in The Doctrine of Chances, 2nd and 3rd
eds. Reprint ed., F. Case and Chelsea, London and New York 1967.
M¨onch, G. (1971). Verallgemeinerung eines Satzes von A. R´enyi. Studia Sci.
Math. Hung. 6, 81–90.
Motoo, M. and Watanabe, H. (1958). Ergodic property of recurrent diﬀusion
process in one dimension. J. Math. Soc. Japan 10, 272–286.
Nawrotzki, K. (1962). Ein Grenzwertsatz f¨ur homogene zuf¨allige Punktfolgen
(Verallgemeinerung eines Satzes von A. R´enyi). Math. Nachr. 24, 201–217.
Neumann, J. von (1932). Proof of the quasi-ergodic hypothesis. Proc. Natl.
Acad. Sci. USA 18, 70–82.
— (1940). On rings of operators, III. Ann. Math. 41, 94–161.
Neveu, J. (1964–71). Mathematical Foundations of the Calculus of Probability.
Engl. trans., Holden-Day, San Francisco.
— (1972–75).
Discrete-Parameter Martingales.
Engl. trans., North-Holland,
Amsterdam.
Nikod´ym, O.M. (1930). Sur une g´en´eralisation des int´egrales de M. J. Radon.
Fund. Math. 15, 131–179.
Norberg, T. (1984). Convergence and existence of random set distributions.
Ann. Probab. 12, 726–732.
Novikov, A.A. (1971). On moment inequalities for stochastic integrals. Theory
Probab. Appl. 16, 538–541.
— (1972). On an identity for stochastic integrals. Theory Probab. Appl. 17,
717–720.

Bibliography
503
Nualart, D. (1995). The Malliavin Calculus and Related Topics. Springer-
Verlag, New York.
Øksendal, B. (1985–95). Stochastic Diﬀerential Equations, 4th ed. Springer-
Verlag, Berlin.
Orey, S. (1966). F-processes. Proc. 5th Berkeley Symp. Math. Statist. Probab.
2:1, 301–313.
Ornstein, D. (1969). Random walks. Trans. Amer. Math. Soc. 138, 1–60.
Ornstein, L.S. and Uhlenbeck, G.E. (1930). On the theory of Brownian
motion. Phys. Review 36, 823–841.
Ososkov, G.A. (1956). A limit theorem for ﬂows of homogeneous events. The-
ory Probab. Appl. 1, 248–255.
Ottaviani, G. (1939). Sulla teoria astratta del calcolo delle probabilit`a proposita
dal Cantelli. Giorn. Ist. Ital. Attuari 10, 10–40.
Paley, R.E.A.C. (1932). A remarkable series of orthogonal functions I. Proc.
London Math. Soc. 34, 241–264.
Paley, R.E.A.C. and Wiener, N. (1934). Fourier transforms in the complex
domain. Amer. Math. Soc. Coll. Publ. 19.
Paley, R.E.A.C., Wiener, N., and Zygmund, A. (1933). Notes on random
functions. Math. Z. 37, 647–668.
Palm, C. (1943). Intensit¨atsschwankungen in Fernsprechverkehr. Ericsson Tech-
nics 44, 1–189.
Papangelou, F. (1972). Integrability of expected increments of point processes
and a related random change of scale. Trans. Amer. Math. Soc. 165, 486–
506.
Parthasarathy, K.R. (1967). Probability Measures on Metric Spaces. Aca-
demic Press, New York.
Perkins, E. (1982). Local time and pathwise uniqueness for stochastic diﬀeren-
tial equations. Lect. Notes in Math. 920, 201–208. Springer-Verlag, Berlin.
Phillips, H.B. and Wiener, N. (1923). Nets and Dirichlet problem. J. Math.
Phys. 2, 105–124.
Poincar´e, H. (1890). Sur les ´equations aux d´eriv´ees partielles de la physique
math´ema-tique. Amer. J. Math. 12, 211–294.
— (1899). Th´eorie du Potentiel Newtonien. Gauthier-Villars, Paris.
Poisson, S.D. (1837). Recherches sur la Probabilit´e des Jugements en Mati`ere
Criminelle et en Mati`ere Civile, Pr´ec´ed´ees des R`egles G´en´erales du Calcul
des Probabilit´es. Bachelier, Paris.
Pollaczek, F. (1930). ¨Uber eine Aufgabe der Wahrscheinlichkeitstheorie, I–II.
Math. Z. 32, 64–100, 729–750.
Pollard, D. (1984).
Convergence of Stochastic Processes.
Springer-Verlag,
New York.
P´olya, G. (1920). ¨Uber den zentralen Grenzwertsatz der Wahrscheinlichkeits-
rechnung und das Momentenproblem. Math. Z. 8, 171–181.

504
Foundations of Modern Probability
— (1921).
¨Uber eine Aufgabe der Wahrscheinlichkeitsrechnung betreﬀend die
Irrfahrt im Strassennetz. Math. Ann. 84, 149–160.
Port, S.C. and Stone, C.J. (1978). Brownian Motion and Classical Potential
Theory. Academic Press, New York.
Pospiˇsil, B. (1935–36). Sur un probl`eme de M.M.S. Bernstein et A. Kolmogo-
roﬀ. ˇCasopis Pˇest. Mat. Fys. 65, 64–76.
Prohorov, Y.V. (1956). Convergence of random processes and limit theorems
in probability theory. Theory Probab. Appl. 1, 157–214.
— (1959). Some remarks on the strong law of large numbers. Theory Probab.
Appl. 4, 204–208.
— (1961). Random measures on a compactum. Soviet Math. Dokl. 2, 539–541.
Protter, P. (1990). Stochastic Integration and Diﬀerential Equations. Springer-
Verlag, Berlin.
Radon, J. (1913). Theorie und Anwendungen der absolut additiven Mengen-
funktionen. Wien Akad. Sitzungsber. 122, 1295–1438.
Rao, K.M. (1969a). On decomposition theorems of Meyer. Math. Scand. 24,
66–78.
— (1969b). Quasimartingales. Math. Scand. 24, 79–92.
Ray, D.B. (1956). Stationary Markov processes with continuous paths. Trans.
Amer. Math. Soc. 82, 452–493.
— (1963). Sojourn times of a diﬀusion process. Illinois J. Math. 7, 615–630.
R´enyi, A. (1956). A characterization of Poisson processes. Magyar Tud. Akad.
Mat. Kutato Int. K¨ozl. 1, 519–527.
— (1967). Remarks on the Poisson process. Studia Sci. Math. Hung. 2, 119–123.
Revuz, D. (1970). Mesures associ´ees aux fonctionnelles additives de Markov,
I–II. Trans. Amer. Math. Soc. 148, 501–531; Z. Wahrscheinlichkeitstheorie
verw. Gebiete 16, 336–344.
Revuz, D. and Yor, M. (1991–94).
Continuous Martingales and Brownian
Motion, 2nd ed. Springer, Berlin.
Riesz, F. (1909). Sur les suites de fonctions mesurables. C.R. Acad. Sci. Paris
148, 1303–1305.
Rogers, L.C.G. and Williams, D. (1979–94; 1987). Diﬀusions, Markov Pro-
cesses, and Martingales, Vol. 1 (2nd ed.) and Vol. 2. Wiley, Chichester.
Ros´en, B. (1964). Limit theorems for sampling from a ﬁnite population. Ark.
Mat. 5, 383–424.
Rosi´nski, J. and Woyczy´nski, W.A. (1986). On Itˆo stochastic integration
with respect to p-stable motion: Inner clock, integrability of sample paths,
double and multiple integrals. Ann. Probab. 14, 271–286.
Rutherford, E. and Geiger, H. (1908). An electrical method of counting
the number of particles from radioactive substances. Proc. Roy. Soc. A 81,
141–161.

Bibliography
505
Ryll-Nardzewski, C. (1957). On stationary sequences of random variables
and the de Finetti’s [sic] equivalence. Colloq. Math. 4, 149–156.
Schoenberg, I.J. (1938). Metric spaces and completely monotone functions.
Ann. Math. 39, 811–841.
Schr¨odinger, E. (1931). ¨Uber die Umkehrung der Naturgesetze. Sitzungsber.
Preuss. Akad. Wiss. Phys. Math. Kl. 144–153.
van Schuppen, J.H. and Wong, E. (1974). Transformation of local martingales
under a change of law. Ann. Probab. 2, 879–888.
Segal, I.E. (1954). Abstract probability spaces and a theorem of Kolmogorov.
Amer. J. Math. 76, 721–732.
Sharpe, M. (1988).
General Theory of Markov Processes.
Academic Press,
Boston.
Shiryaev, A.N. (1979–95). Probability, 2nd ed. Springer-Verlag, New York.
Shur, M.G. (1961). Continuous additive functionals of a Markov process. Dokl.
Akad. Nauk SSSR 137, 800–803.
Sierpi´nski, W. (1928). Une th´eor`eme g´en´erale sur les familles d’ensemble. Fund.
Math. 12, 206–210.
Skorohod, A.V. (1956).
Limit theorems for stochastic processes.
Theory
Probab. Appl. 1, 261–290.
— (1957). Limit theorems for stochastic processes with independent increments.
Theory Probab. Appl. 2, 122–142.
— (1961–62). Stochastic equations for diﬀusion processes in a bounded region,
I–II. Theory Probab. Appl. 6, 264–274; 7, 3–23.
— (1961–65). Studies in the Theory of Random Processes. Engl. trans., Addison-
Wesley, Reading, MA.
Slutsky, E.E. (1937). Qualche proposizione relativa alla teoria delle funzioni
aleatorie. Giorn. Ist. Ital. Attuari 8, 183–199.
Snell, J.L. (1952). Application of martingale system theorems. Trans. Amer.
Math. Soc. 73, 293–312.
Sova, M. (1967). Convergence d’op´erations lin´eaires non born´ees. Rev. Rou-
maine Math. Pures Appl. 12, 373–389.
Sparre-Andersen, E. (1953–54). On the ﬂuctuations of sums of random vari-
ables, I–II. Math. Scand. 1, 263–285; 2, 195–223.
Sparre-Andersen, E. and Jessen, B. (1948). Some limit theorems on set-
functions. Danske Vid. Selsk. Mat.-Fys. Medd. 25:5 (8 pp.).
Spitzer, F. (1964). Electrostatic capacity, heat ﬂow, and Brownian motion. Z.
Wahrscheinlichkeitstheorie verw. Gebiete 3, 110–121.
— (1964–76). Principles of Random Walk, 2nd ed. Springer-Verlag, New York.
Stone, C.J. (1963).
Weak convergence of stochastic processes deﬁned on a
semi-inﬁnite time interval. Proc. Amer. Math. Soc. 14, 694–696.
— (1969). On the potential operator for one-dimensional recurrent random walks.
Trans. Amer. Math. Soc. 136, 427–445.

506
Foundations of Modern Probability
Stone, M.H. (1932). Linear transformations in Hilbert space and their applica-
tions to analysis. Amer. Math. Soc. Coll. Publ. 15.
Stout, W.F. (1974). Almost Sure Convergence. Academic Press, New York.
Strassen, V. (1964). An invariance principle for the law of the iterated loga-
rithm. Z. Wahrscheinlichkeitstheorie verw. Gebiete 3, 211–226.
Stratonovich, R.L. (1966). A new representation for stochastic integrals and
equations. SIAM J. Control 4, 362–371.
Stricker, C. and Yor, M. (1978).
Calcul stochastique d´ependant d’un
param`etre. Z. Wahrscheinlichkeitstheorie verw. Gebiete 45, 109–133.
Stroock, D.W. (1993).
Probability Theory: An Analytic View.
Cambridge
University Press, Cambridge.
Stroock, D.W. and Varadhan, S.R.S. (1969). Diﬀusion processes with con-
tinuous coeﬃcients, I–II. Comm. Pure Appl. Math. 22, 345–400, 479–530.
— (1979). Multidimensional Diﬀusion Processes. Springer-Verlag, Berlin.
Tanaka, H. (1963). Note on continuous additive functionals of the 1-dimensional
Brownian path. Z. Wahrscheinlichkeitstheorie verw. Gebiete 1, 251–257.
Tonelli, L. (1909). Sull’integrazione per parti. Rend. Acc. Naz. Lincei (5) 18,
246–253.
Trotter, H.F. (1958a). Approximation of semi-groups of operators. Paciﬁc J.
Math. 8, 887–919.
— (1958b). A property of Brownian motion paths. Illinois J. Math. 2, 425–433.
Varadarajan, V.S. (1958). Weak convergence of measures on separable metric
spaces. On the convergence of probability distributions. Sankhy¯a 19, 15–26.
— (1963). Groups of automorphisms of Borel spaces. Trans. Amer. Math. Soc.
109, 191–220.
Ville, J. (1939).
´Etude Critique de la Notion du Collectif. Gauthier-Villars,
Paris.
Volkonsky, V.A. (1958). Random time changes in strong Markov processes.
Theory Probab. Appl. 3, 310–326.
— (1960). Additive functionals of Markov processes. Trudy Mosk. Mat. Obshc.
9, 143–189.
Wald, A. (1946). Diﬀerentiation under the integral sign in the fundamental
identity of sequential analysis. Ann. Math. Statist. 17, 493–497.
— (1947). Sequential Analysis. Wiley, New York.
Walsh, J.B. (1978). Excursions and local time. Ast´erisque 52–53, 159–192.
Wang, A.T. (1977). Generalized Itˆo’s formula and additive functionals of Brow-
nian motion. Z. Wahrscheinlichkeitstheorie verw. Gebiete 41, 153–159.
Watanabe, S. (1964). On discontinuous additive functionals and L´evy measures
of a Markov process. Japan. J. Math. 34, 53–79.
— (1968). A limit theorem of branching processes and continuous state branching
processes. J. Math. Kyoto Univ. 8, 141–167.

Bibliography
507
Wiener, N. (1923). Diﬀerential space. J. Math. Phys. 2, 131–174.
— (1938). The homogeneous chaos. Amer. J. Math. 60, 897–936.
Williams, D. (1991). Probability with Martingales. Cambridge University Press,
Cambridge.
Yamada, T. (1973). On a comparison theorem for solutions of stochastic diﬀer-
ential equations and its applications. J. Math. Kyoto Univ. 13, 497–512.
Yamada, T. and Watanabe, S. (1971).
On the uniqueness of solutions of
stochastic diﬀerential equations. J. Math. Kyoto Univ. 11, 155–167.
Yoeurp, C. (1976). D´ecompositions des martingales locales et formules expo-
nentielles. Lect. Notes in Math. 511, 432–480. Springer-Verlag, Berlin.
Yor, M. (1978). Sur la continuit´e des temps locaux associ´ee `a certaines semi-
martingales. Ast´erisque 52–53, 23–36.
Yosida, K. (1948).
On the diﬀerentiability and the representation of one-
parameter semigroups of linear operators. J. Math. Soc. Japan 1, 15–21.
Yosida, K. and Kakutani, S. (1939).
Birkhoﬀ’s ergodic theorem and the
maximal ergodic theorem. Proc. Imp. Acad. 15, 165–168.
Zaremba, S. (1909). Sur le principe du minimum. Bull. Acad. Sci. Cracovie.

Indices
Authors
Aldous, D.J., 262, 471, 475
Alexandrov, A.D., 53, 466
Andr´e, D., 142, 470
Arzel`a, C., 258, 458
Ascoli, G., 258, 458
Athreya, K.B., 470
Baccelli, F., 484
Bachelier, L., 206, 469, 472, 482
Banach, S., 26, 315, 317, 452
Bass, R.F., 483
Bauer, H., 486
Baxter, G., 146, 470
Bayes, T., 471
Belyaev, Y.K., 476
Bernoulli, J., 33, 465
Bernstein, S.N., 105, 466, 468, 479
Bertoin, J., 475
Bessel, F.W., 206
Bichteler, K., 451, 485
Bienaym´e, J., 40, 465
Billingsley, P., 455, 464–65, 468, 471,
474–76
Birkhoﬀ, G.D., 159, 471
Blackwell, D., 150, 470
Blumenthal, R.M., 326–27, 368, 420,
469, 479, 481, 483–84
Bochner, S., 77, 211, 467, 473
Bogolioubov, N., 164, 471
Bohl, 174
Boltzmann, L., 470
Borel, E., 2, 7, 24, 32–33, 455–56,
464–66
Brandt, A., 484
Breiman, L., 482
Br´emaud, P., 484
Brown, R., 203, 473
B¨uhlmann, H., 172, 471
Buniakovsky, V.Y., 17, 280
Burkholder, D.L., 279, 443, 477,
484–85
Cameron, R.H., 310, 477
Cantelli, F.P., 24, 32, 52, 465–66
Carath´eodory, C., 455
Cauchy, A.L., 16–17, 240, 391
Chapman, S., 119, 469
Chebyshev, P.L., 40, 465–66
Chentsov, N.N., 35, 465, 475
Chernov, H., 476
Choquet, G., 403, 406–7, 457, 471,
476, 483
Chow, Y.S., 466, 468, 475
Chung, K.L., 139, 222, 327, 401, 417,
469–70, 472, 477, 483
Courant, R., 482
Courr`ege, P., 280, 435, 477, 484
Cox, D., 180
Cram´er, H., 64, 211, 465, 467, 471,
473
Cs¨org¨o, M., 474
Daley, D.J., 472
Dambis, K.E., 298, 477
Daniell, P.J., 91, 467
Davis, B.J., 443, 484–85
Debes, H., 476
Dellacherie, C., 303, 451, 457, 468–69,
471, 473, 479, 481, 483–85
Derman, C., 384, 481
Dirac, P., 9
Dirichlet, P.G.L., 394
Doeblin, W., 248, 252, 469, 472, 475,
478, 481
D¨ohler, R., 468
Dol´eans(-Dade), C., 291, 412, 415,
417, 436, 440, 477, 484–85
Donsker, M.D., 225, 260, 474, 475
Doob, J.L., 7, 86–87, 101, 103-4,
106–8, 111–12, 114, 187, 304,
394–95, 414, 426, 428,
464–65, 467–69, 471–72, 474,
476–79, 482–84
Dubins, L.E., 298, 474, 477
509

510
Foundations of Modern Probability
Dudley, R.M., 56, 456, 464, 466, 475
Dunford, N., 46, 466, 483
Durrett, R., 474
Dvoretzky, A., 232, 474
Dynkin, E.B., 326, 328–330, 376, 464,
468–69, 471, 478–82
Einstein, A., 473
Elliott, R.J., 484
Engelbert, H.J., 372, 482
Erd¨os, P., 226, 470, 473
Erlang, A.K., 184, 472
Ethier, S.N., 458, 469, 476, 479–80
Faber, G., 466
Farrell, R.H., 163, 471
Fatou, P., 11, 464
Fell, J.M.G., 272, 461
Feller, W., 69, 71, 73, 142, 150, 251,
315, 376, 379, 383, 386,
466–67, 469–75, 478–79,
481–82
Feynman, R.P., 391, 482
Finetti, B. de, 168, 471, 474
Fisk, D.L., 285, 288, 476–77, 485
Fortet, R., 478
Fourier, J.B.J., 67
Fr´echet, M., 464
Freedman, D., 201, 469, 472–73, 482
Friedrichs, K., 482
Frostman, O., 482
Fubini, G., 14, 464
Fuchs, W.H.J., 139, 470
Furstenberg, H., 167, 471
Galmarino, A.R., 301, 478
Garsia, A.M., 160, 421, 444, 471, 484
Gauss, C.F., 67, 200, 472, 482
Geiger, H., 472
Getoor, R.K., 368, 469, 477, 481,
483–84
Gihman, I.I., 479
Girsanov, I.V., 308, 311, 478–79
Glivenko, V.I., 52, 466
Gnedenko, B.V., 252, 475
Goldman, J.R., 476
Goldstein, J.A., 479
Grandell, J., 472
Green, G., 379, 397, 482
Greenwood, P., 480
Grigelionis, B., 266, 422, 476, 484
Gronwall, 338
Gundy, R.F., 279, 443, 477, 484–85
Hagberg, J., 476
Hahn, H., 26, 317, 452
H´ajek, J., 476
Hall, P., 474
Halmos, P.R., 464, 467
Hartman, P., 225, 474
Hausdorﬀ, F., 177
Helly, E., 75, 467
Hermite, C., 215
Hewitt, E., 31, 465
Heyde, C.C., 474
Hilbert, D., 201, 277
Hille, E., 321, 478
Hitczenko, P., 485
H¨older, O., 16, 26, 35, 86, 465
Hopf, E., 145, 159, 471
Horowitz, J., 480
Hunt, G.A., 101, 206, 366, 396, 473,
479, 481–83
Ikeda, N., 477, 480
Ionescu Tulcea, C.T., 93, 467
Itˆo, K., 213, 215, 236, 282, 286, 303,
338, 357–58, 379, 465,
472–74, 476–83, 485
Jacod, J., 422, 436, 442, 458, 475–76,
478, 480, 484–85
Jagers, P., 476
Jensen, J.L.W.V., 26, 86, 465
Jessen, B., 109, 468
Johnson, W.B., 485
Kac, M., 226, 391, 473, 482
Kakutani, S., 160, 300, 394, 470–71,
477, 482
Kallenberg, O., 466, 468–69, 471–72,
475–78, 480, 484–85
Kallianpur, G., 473
Karamata, J., 73, 466
Karatzas, I., 473, 477–78, 480–83
Kazamaki, N., 290, 477
Kemeny, J.G., 469

Indices
511
Kendall, D., 476
Kerstan, J., 476
Kesten, H., 167, 471
Khinchin, A., 47, 73, 209, 239, 251,
465, 471, 473–76, 485
Kingman, J.F.C., 165, 180, 471–72
Kinney, J.R., 325, 465, 478
Knapp, A.W., 469
Knight, F.B., 301, 363, 478, 480
Koebe, P., 393
Kolmogorov, A.N., 30, 35, 47–48,
50–51, 81, 92, 119–20, 129,
131, 192, 240, 391, 458,
465–67, 469–70, 472–75, 478,
481–83, 485
Koml´os, J., 474
Krickeberg, K., 485
Kronecker, L., 50
Krylov, N., 164, 471
Kunita, H., 282, 435, 439, 477, 484–85
Kuratowski, K., 457
Kurtz, T.G., 331, 458, 469, 476,
479–80
Kuznetsov, S.E., 483
Kwapie´n, S., 466
Langevin, P., 337, 473, 479
Laplace, P.S. de, 61, 178, 393, 466–67,
472, 482
Last, G., 484
Leadbetter, M.R., 465, 471, 475
Lebesgue, H., 11, 14–15, 455–56, 464
Le Cam, L., 475
Leeuwenhoek, A. van, 473
Le Gall, J.F., 482
Leontovich, M.A., 482
Levi, B., 11, 464
L´evy, P., 48, 63, 67, 71, 73, 77, 105,
108–10, 184, 202, 205, 208,
235–36, 239–241, 298–300,
352, 358, 465–70, 472–75,
477, 479–80
Lewy, H., 482
Liapounov, A.M., 466–67
Liemant, A., 476
Liggett, T., 166, 471
Lindeberg, J.W., 67, 69, 466, 479
Lindgren, G., 475
Lindvall, T., 469–70, 475
Lipschitz, R., 338, 374–75
Liptser, R.S., 500
Lo`eve, M., 35, 464–67, 470–71, 475
WLomnicki, Z., 93, 467
Lukacs, E., 467
Lundberg, F., 472
Lusin, N.N., 457
Mackeviˇcius, V., 331, 479
Maisonneuve, B., 473, 480–81
Major, P., 474
Mann, H.B., 54, 466
Marcinkiewicz, J., 51, 466, 485
Markov, A.A., 118, 129, 465, 467–
68
Martin, W.T., 310, 477
Maruyama, G., 386, 478, 481
Matheron, G., 476, 483
Matthes, K., 476
Maxwell, J.C., 201, 472
McDonald, D., 470
McKean, H.P. Jr., 369, 379, 473,
481–83
Mecke, J., 180, 267, 476
M´el´eard, S., 381, 481
M´emin, J., 436
M´etivier, M., 484
Meyer, P.A., 114, 353, 412–13, 417,
420, 424, 429, 436, 444, 446,
457, 468–69, 471, 473, 477,
479–81, 483–85
Millar, P.W., 279, 477
Minkowski, H., 16, 86
Mitoma, I., 476
Moivre, A. de, 466, 472
M¨onch, G., 472
Morgan, A. de, 1
Motoo, M., 384, 481
Nawrotzski, K., 476
Neumann, J. von, 159, 174, 467, 471
Neveu, J., 421, 468, 484
Ney, P., 470
Nikod´ym, O.M., 82, 456, 467
Norberg, T., 272, 476
Novikov, A.A., 279, 311, 477–78
Nualart, D., 473

512
Foundations of Modern Probability
Øksendal, B., 477
Orey, S., 150, 470, 485
Ornstein, D., 139, 470
Ornstein, L.S., 204, 212, 337, 473,
479
Ososkov, G.A., 476
Ottaviani, G., 260, 475
Paley, R.E.A.C., 40, 218, 470, 473,
485
Palm, C., 476
Papangelou, F., 424, 484
Parseval, M.A., 139
Parthasarathy, K.R., 457
Pellaumail, J., 484
Perkins, E., 481
Phillips, H.B., 482
Picard, E., 338
Pitman, J.W., 480
Poincar´e, H., 482
Poisson, S.D., 65, 178, 472
Pollaczek, F., 470
Pollard, D., 476
Pollard, H., 470
P´olya, G., 466, 470
Port, S.C., 483
Pospiˇsil, B., 472
Prohorov, Y.V., 54, 257, 259, 261,
264, 458, 466, 474–76, 485
Protter, P., 485
Radon, J., 82, 456, 464, 467
Rao, K.M., 413, 451, 483, 485
Ray, D.B., 363, 479–81
R´enyi, A., 184, 472, 476
R´ev´esz, P., 474
Revuz, D., 365–66, 473, 477–78,
481–82
Riemann, G.F.B., 152
Riesz, F., 317, 324, 430–31, 456, 466
Rogers, L.C.G., 469, 477, 480, 482,
484
Rootz´en, H., 475
Ros´en, B., 476
Rosi´nski, J., 484
Rubin, H., 54, 466
Rutherford, E., 472
Ryll-Nardzewski, C., 168, 471
Savage, L.J., 31, 465
Schechtman, G., 485
Schmidt, W., 372, 482
Schoenberg, I.J., 201, 472
Schr¨odinger, E., 482–83
Schuppen, J.H. van, 308, 441, 478,
485
Schwarz, G., 298, 477
Schwarz, H.A., 17
Segal, I.E., 472
Sharpe, M., 469, 477, 483
Shiryaev, A.N., 458, 475–76, 484–
85
Shreve, S.E., 473, 477–78, 480–83
Shur, M.G., 483
Sierpi´nski, W., 2, 174, 464
Skorohod, A.V., 56, 221, 223, 247,
261, 263, 342, 351, 374–75,
458, 466, 474–75, 479–81
Slutsky, E., 465
Smoluchovsky, M., 119, 469
Snell, J.L., 107, 468–69
Sova, M., 331, 479
Sparre-Andersen, E., 143, 146, 172,
226, 468, 470–71
Spitzer, F., 470, 483
Stieltjes, T.J., 283, 436
Stone, C.J., 470, 475, 483
Stone, M.H., 63, 211, 473
Stout, W.F., 466
Strassen, V., 223, 474
Stratonovich, R.L., 288, 476
Stricker, C., 57, 291, 466, 477
Stroock, D.W., 341, 343–44, 392,
479–80, 482
Sztencel, R., 485
Tanaka, H., 350, 369, 386, 480–
81
Taylor, B., 67, 69
Teicher, H., 466, 468, 475–76
Tonelli, L., 14, 464
Trotter, H.F., 331, 352, 479–80
Tusn´ady, G., 474
Uhlenbeck, G.E., 204, 212, 337, 473,
479
Ulam, S., 93, 467

Indices
513
Varadarajan, V.S., 163, 257, 471, 475
Varadhan, S.R.S., 341, 343–44, 392,
480, 482
Vere-Jones, D., 472
Ville, J., 468
Volkonsky, V.A., 367, 369, 379,
479–81, 483
Wald, A., 54, 311, 466, 470, 477
Walsh, J.B., 327, 363, 417, 480
Wang, A.T., 353, 480
Watanabe, H., 384, 481
Watanabe, S., 282, 320, 348, 374, 424,
435, 439, 477–78, 480–81,
483–85
Weierstrass, K., 63, 287
Weyl, H., 174
Wiener, N., 145, 202–3, 210, 213, 216,
218, 465, 470, 473, 482
Williams, D., 465, 468–69, 477, 480,
482, 484
Williams, R.J., 477
Wintner, A., 225, 474
Wold, H., 64, 467
Wong, E., 308, 441, 478, 485
Woyczy´nski, W.A., 466, 484
Yamada, T., 348, 374–75, 480–81
Yan, J.A., 436, 452
Yoeurp, C., 446, 448, 485
Yor, M., 57, 291, 352, 466, 473,
477–78, 480–82
Yosida, K., 160, 318, 321, 471, 478
Yushkevich, A.A., 326, 468, 479
Zaremba, S., 394
Zinn, J., 485
Zygmund, A., 40, 51, 218, 466, 473,
485
Terms and Topics
absolute:
continuity, 13, 212, 306, 354, 441,
456
moment, 26
absorption:
of Markov process, 132, 188, 324,
328, 356
of diﬀusion, 382, 385–86
of supermartingale, 113
accessible:
set, boundary, 137, 383
time, 411, 419–20
jumps, 418, 448
adapted, 97, 422
additive functional, 364
a.e., almost everywhere, 12
allocation sequence, 171
almost:
everywhere, 12
invariant, 158
alternating function, 403, 407
analytic function, 288, 299
announcing sequence, 287, 410
aperiodic, 127
approximation of:
covariation, 285
empirical distributions, 228
exchangeable sums, 268
local time, 354, 359
Markov chains, 334
martingales, 230
predictable process, 435
progressive process, 289
random walks, 223, 232, 248, 263
renewal process, 227
arcsine laws, 208, 226, 248
Arzel`a–Ascoli theorem, 258, 458
a.s., almost surely, 24
atom, atomic, 9, 18
augmented ﬁltration, 101
averaging property, 82
backward equation, 192, 317, 391
balayage, sweeping, 395
BDG inequalities, 279, 443
Bernoulli sequence, 33
Bessel process, 206, 363
bilinear, 27
binary expansion, 33
Blumenthal’s zero–one law, 327
Borel–Cantelli lemma, 24, 32, 108

514
Foundations of Modern Probability
Borel:
isomorphism, space, 7, 456
set, σ-ﬁeld, 2
boundary behavior, 380–83, 394–95
bounded optional time, 104
Brownian:
bridge, 203, 228, 302
excursion, 361
motion, 202–10, 221, 223–25,
227–32, 260, 298–306,
310–11, 335–49, 352, 361–67,
369–76, 379, 392–406, 426–31
scaling, inversion, 203
CAF, continuous additive functional,
364
Cameron–Martin theorem, 310
canonical:
decomposition, 283, 436
process, space, ﬁltration, 123,
326, 330
capacity, 401–03, 406–07
Cartesian product, 2
Cauchy:
convergence in probability, 42
problem, 391–92
Cauchy–Buniakovsky inequality, 17,
280, 434, 438
centering, centered, 49, 200
central limit theorem, 67, 225, 260
chain rule for:
conditional independence, 88
conditioning, 82
integration, 12, 284
change of:
measure, 306–11, 441
scale, 372, 376
time, 290, 298, 346, 372–74,
378–79, 424
chaos expansion, 216, 306
Chapman–Kolmogorov equation,
119–20, 122, 128, 314
characteristic:
exponent, 240
function(al), 61–63, 67, 77, 178
measure, 192
operator, 329
characteristics, 239, 336
Chebyshev’s inequality, 40
closed, closure:
martingale, 108, 112
operator, 319
compactiﬁcation, 323–24
compactness:
vague, 75
weak, 76
weak L1, 46
in C and D, 458
comparison of solutions, 375–76
compensator, 412, 417–19, 422–25,
429–30
complete, completion:
ﬁltration, 100
function space, 16, 42
σ-ﬁeld, 13, 87
completely monotone, alternating,
403, 407
complex-valued process, 211, 288,
297–99
composition, 4
compound Poisson, 192, 246–47, 250
condenser theorem, 404
conditional:
distribution, 84
expectation, 81–82
independence 86–88, 90, 118, 168,
172, 181, 347
probability, 83
conductor, 400–04
cone condition, 394
conformal mapping, invariance, 288,
299
conservative semigroup, 315, 323
continuity:
set, 53
theorem, 63, 77
w.r.t. a time-change, 290
continuous:
additive functional, 364–70,
372–74, 378–79, 429–32
in probability, 172, 235, 271
mapping, 41, 54
martingale component, 446–47
contraction, 82, 86, 314

Indices
515
convergence:
in distribution, 42–43, 53–56,
63–64, 76–77, 256–73
in probability, 40–43, 57
of exchangeable processes, 269
of inﬁnitely divisible laws, 244–45
of L´evy processes, 247
of Markov processes, 331
of point processes, 265, 273
of random measures, 264
of random sets, 272
convex, concave:
functions, 26, 103, 353, 380
sets, 164, 452
convolution, 15, 30
core of generator, 319–20, 331, 334
countably additive, subadditive, 7
counting measure, 9
coupling, 129, 150
independent, 129–30, 387
Skorohod, 56, 90
covariance, 27, 200
covariation, 278, 280–82, 285, 434,
437–38
Cox process, 180–83, 266–67
Cram´er–Wold theorem, 64
cylinder set, 2, 92
(D) class submartingale, 412
Daniell–Kolmogorov theorem, 91–92
debut, 100
decomposition of:
increasing process, 418
martingale, 436, 446, 448
measure, 456
optional time, 412
submartingale, 103, 412
degenerate:
measure, 9, 18
random element, 28
delay, 148, 150
density, 12–13, 110, 456
diﬀerentiation theorem, 456
diﬀuse (random) measure, 9, 18, 180,
183, 248
diﬀusion, 330, 336, 376, 391
equation, 336, 344, 346, 371–76
Dirac measure, 9
Dirichlet problem, 394
discrete time, 120
disintegration, 85
dissection, 178, 184
dissipative, 323
distribution, 24
function, 25, 36
Dol´eans exponential, 440
domain, 393
of attraction, 73
of generator, 316, 319–21
dominated convergence, 11, 284, 436,
444
Donsker’s theorem, 225, 260
Doob decomposition, 103
Doob–Meyer decomposition, 412
dual predictable projection, 417
duality, 144
Dynkin’s formula, 328
eﬀective dimension, 137
elementary:
function, 213
additive functional, 364
stochastic integral, 105, 289, 435
elliptic operator, 330, 341, 392
embedded:
Markov chain, 189
martingale, 385
random variable, walk, 221–23
empirical distribution, 52, 163, 179,
228
entrance boundary, 382–83
equicontinuity, 62, 259, 261–62, 458
equilibrium measure, 401–03, 405
ergodic, 159, 163–64, 385
decomposition, 164
theorems, Markovian, 129–31,
194–95, 384, 386–87
theorems, in stationarity, 159–62,
165–67
evaluation map, 24, 177, 457
event, 23
excessive function, 325, 367, 426–30
exchangeable:
sequence, 168–70, 268
increment process, 172, 185,
269–71

516
Foundations of Modern Probability
excursion, 127, 355–62
existence:
of Markov processes, 120, 324
of random sequences, processes,
33, 91–93
of solutions to SDEs, 338, 342,
345–46, 372
exit boundary, 382–83
expectation, expected value, 25–26, 29
explosion, 190–91, 340, 383
exponential:
distribution, 188–90, 356
inequality, 448
martingale, process, 297, 309,
440, 449
extended real line, 5
extension of:
ﬁltration, 298
measure, 308, 455
probability space, 88
extreme:
element, 164
value, 207, 253
factorial measure, 169
fast reﬂection, 380
Fatou’s lemma, 11, 44–45
Fell topology, 272–73, 461
Feller process, semigroup, 315–34,
344, 364–65, 367–68, 383, 420
Feynman–Kac formula, 391
ﬁeld, 455
ﬁltration, 97
de Finetti’s theorem, 168
ﬁnite-dimensional distributions, 25,
119
ﬁnite-variation process, 276, 283, 416,
436
ﬁrst:
entry, 101
maximum, 143, 172, 208, 226,
248
Fisk–Stratonovich integral, 288
ﬁxed jump, 235
ﬂow, 161, 338
ﬂuctuations, 144–45
forward equation, 317
Fubini theorem, 14, 29, 85, 304
functional:
representation, 57, 292
solution, 347
fundamental identity, 400
Gaussian:
convergence, 69–71, 73
measure, process, 67, 200–04, 297
general theory of processes, 484
generated:
σ-ﬁeld, 2
ﬁltration, 5, 97
generating function, 61
generator, 314–23, 329–30
geometric distribution, 126, 356
Girsanov theorem, 308, 311, 441
Glivenko–Cantelli theorem, 52
graph:
of operator, 319
of optional time, 411
Green function, potential, 379, 397,
431
harmonic:
function, 299, 393
measure, 395
minorant, 430
heat equation, 392
Helly’s selection theorem, 75
Hermite polynomials, 215
Hewitt–Savage zero–one law, 31
Hille–Yosida theorem, 321
hitting:
function, 272, 407
kernel, 393, 405
time, 100, 377, 393
H¨older:
continuity, 35, 202, 261
inequality, 16, 86
holding time, 188, 356
homogeneous:
chaos, 216
kernel, 121, 192
hyper-contraction, 268
i.i.d., independent identically
distributed, 31, 33, 51, 66–67,
72–73, 243, 246

Indices
517
inaccessible boundary, 380
increasing process, 412
increment of function, measure, 36,
178, 184
independence, 27–33
independent-increment:
processes, 121, 192, 202, 235–36
random measures, 178, 184–85
indicator function, 5, 23
indistinguishable, 34
induced:
σ-ﬁeld, 2–5
ﬁltration, 5, 97, 290
inﬁnitely divisible, 243–46, 251
initial distribution, 118
inner product, 17
instantaneous state, 356
integrable:
function, 11
increasing process, 412
random vector, process 26
integral representation:
invariant distribution, 164
martingale, 303–04, 306
integration by parts, 285, 437–38,
441
intensity measure, 177
invariance principle, 227
invariant:
distribution, 125–26, 128–29,
193–94, 388
measure, 15
σ-ﬁeld, 158, 161
subspace, 320
inverse:
function, 3, 457
local time, 360
maximum process, 241
i.o., inﬁnitely often, 23, 31–32
irreducible, 128, 194
isometry, 210, 213, 297
isonormal, 201, 211
isotropic, 298
Itˆo:
correction term, 286
formula, 286–88, 353, 439
integral, 282, 289–90
J1-topology, 261, 458
Jensen’s inequality, 26, 86
jump transition kernel, 189
jump-type process, 187
kernel, 19, 34, 83, 122, 343
density, 110
hitting, quitting, sweeping, 395,
400–01, 405
transition, rate, 189, 118
killing, 391, 396
Kolmogorov:
extension theorem, 92
maximum inequality, 47
zero–one law, 30, 110
Kolmogorov–Chentsov criterion, 35,
261
ladder time, height, 143–47
λ-system, 2
Langevin equation, 337
Laplace:
operator, equation, 320, 393
transform, functional 61, 177–78,
181, 316
last:
return, zero, 142, 208, 226
exit, 401
law of the iterated logarithm, 209,
225, 227–28
lcscH space, 177
Lebesgue:
decomposition, 456
measure, 15, 455
unit interval, 33
level set, 204
L´evy:
characterization of Brownian
motion, 298
measure, 239
process, 239–43, 247–48, 263, 320,
436
system, 484
L´evy–Khinchin formula, 239–40
Lindeberg’s theorem, 69
linear:
equation, 337, 440
functional, 456

518
Foundations of Modern Probability
Lipschitz condition, 338, 375–76
local:
characteristics, 336, 484
condition, property 35, 82
operator, 329–30
martingale, submartingale, 276,
412
measurability, 237
substitution rule, 288
time, 350–54, 358–60, 363–64,
368–69, 373, 375, 378–79, 431
localization, 276
locally ﬁnite measure, kernel 9, 18,
177, 459
Lp-
boundedness, 44, 109
contraction, 86
convergence, 45, 109, 159–62
marked point process, 184, 423–24
Markov:
chain, 128–31, 193–95, 334
inequality, 40
process, 117-33, 204, 313–34, 344,
376–88
martingale, 102–14, 328
closure, 108, 112
convergence, 107–09, 112
decomposition, 436, 446, 448
embedding, 229
problem, 341–44
transform, 105
maximal, maximum:
ergodic lemma, 159
inequality, 47, 105–06, 260, 448
operator, 329
principle, 321, 329
process, 206, 352
mean, 25
recurrence time, 131, 195
mean-value property, 393
measurable:
group, 15
function, 3–7
set, space, 1–2
measure, 7–9, 455
determining, 9, 163
preserving, 157, 185, 302
space, 7
valued function, process, 170,
271, 460
median, 49
Minkowski’s inequality, 16, 86
modulus of continuity, 34, 224, 259,
374, 457–58
moment, 26
monotone:
class theorem, 2
convergence, 11, 82
moving average, 212
multiple stochastic integral, 213–15,
304
multiplicative functional, 391
natural:
absorption, 382
increasing process, 413, 415, 417
scale, 377
nonarithmetic, 150
nonnegative deﬁnite, 27, 211
normal, Gaussian, 67
norm inequalities, 16, 106, 279, 421,
443
nowhere dense, 355–56
null:
array, 65–66, 68, 71, 249–52, 265
recurrence, 129, 195, 385–86
set, 12
occupation:
density, 353, 397
times, measure, 126, 137, 148–50,
354
ONB, orthonormal basis, 201, 213
one-dimensional criteria, 183–84, 265,
271–73
optional:
projection, 327
sampling, 104, 112
skipping, 170
stopping, 105, 284
time, 97–101, 410–12, 419
Ornstein–Uhlenbeck process, 204,
212, 337
orthogonal:
functions, spaces, 17, 215–16

Indices
519
orthogonal (cont.)
martingales, processes, 237, 301
measures, 13, 455
parabolic equation, 391–92
parallelogram identity, 17
parameter dependence, 57, 291
path, 24, 406
pathwise uniqueness, 337–38, 347–48,
374
perfect, 355
period, 127–28
permutation, 30, 168
π-system, 2
Picard iteration, 338
point process, 178, 183, 265–67, 273
Poisson:
compound, 192, 246–47, 250
convergence, 65, 266
distribution, 65
integrals, 186
mixed, 185
process, 178–80, 184, 186, 188,
237, 266, 358, 406, 423–24
pseudo-, 191
polar set, 300, 400
polarization, 434, 438
Polish space, 7, 456
polynomial chaos, 216
Portmanteau theorem, 53
positive:
density, 307
functional, operator, 82, 314, 456
maximum principle, 321, 323,
329
recurrence, 129, 195, 385, 388
terms, 47, 68, 249
potential:
of additive functional, 364–66,
430
of function, measure, 365, 397
of semigroup, 316
term, 391
predictable:
covariation, quadratic variation,
230, 434
process, 410–12, 415–18, 421–23,
435–36, 441, 444
random measure, 422
sampling, 170
sequence, 103
step process, 105, 277, 434, 451
time, 170, 287, 410–412, 417–20,
448
prediction sequence, 169–70
preseparating class, 265, 462
preservation of:
semimartingales, 442
stochastic integrals, 309
probability, 23
generating function, 61
measure, space 23
product:
σ-ﬁeld, 2, 92
measure, 14–15, 29, 93
progressive, 99, 291, 336
Prohorov’s theorem, 257
projection, 17, 457
projective, 91–92
pseudo-Poisson, 191, 314
pull-out property, 82
purely:
atomic, 9
discontinuous, 418, 445–48
quadratic variation, 205, 230, 278–81,
437
quasi–left-continuous, 418, 420, 423,
448
quasi-martingale, 450–51
quitting time, kernel, 401, 405
Radon–Nikod´ym theorem, 82, 456
random:
element, variable, process, 24
matrix, 167
measure, 83, 177, 264, 422
sequence, 41, 55
series, 46–50
set, 272–73, 406–07
time, 97
walk, 31, 51, 73, 136–47, 221, 232,
248, 263
randomization, 90, 122, 222, 268
of point process, 180
variable, 89

520
Foundations of Modern Probability
rate:
function, kernel, 189
process, 298
ratio ergodic theorem, 384
Ray–Knight theorem, 363
rcll, 111
recurrence, 126, 128, 137–41, 194
time, 131, 195, 356
reﬂecting boundary, 380
reﬂection principle, 142, 207
regenerative set, process, 354
regular:
boundary, domain, set, point 368,
394–95
conditional distribution, 83
diﬀusion, 376
regularity, regularization of:
local time, 352
Markov process, 325
measure, 8
stochastic ﬂow, 338
submartingale, 107, 111
relative compactness, 46, 75–76, 257,
458
renewal:
measure, process, 148, 188,
227–28
theorem, 150
equation, 152
resolvent, 316–18, 325
equation, 316
restriction:
of measure, 8
of optional time, 411–12, 418
Revuz measure, 365–67, 369
Riemann integrable, 152
Riesz:
decomposition, 430–31
representation, 317, 324, 456
right-continuous:
ﬁltration, 98
process, 111
sample process, 179
sampling without replacement, 267
scale function, 376–77
Schwarz’s inequality, 17
SDE, stochastic diﬀerential equation,
335
sections, 14, 457
self-adjoint, 82
self-similar, 240
semicontinuous, 426
semigroup, 122, 161, 315
semimartingale, 283, 436, 439, 442,
451
separating class, 265, 407, 462
shift operators, 123, 157, 326
σ-ﬁeld, 1
σ-ﬁnite, 8
signed measure, 456
simple:
function, 5–6
measure, point process, 9, 178,
183–84, 265, 273
random walk, 142
singular(ity), 13, 372–73, 455
skew-product, 301
Skorohod:
coupling, 56, 90
embedding, 220–33
slow:
reﬂection, 381
variation, 73
space-homogeneous, 121, 124
special semimartingale, 436
spectral measure, representation, 211
speed measure, 379
spreadable, 168–70, 172
stable distribution, process, 240–41,
424
standard extension, 298, 304, 342, 347
stationary:
process, 125, 157, 161
random measure, 148
stochastic:
diﬀerential equation, 292, 355–49,
371–76, 392
ﬂow, 338
integral, 186, 210, 213, 282, 290,
435–36, 444
process, 24
Stone–Weierstrass theorem, 63, 287
stopping time, optional time, 97

Indices
521
Stratonovich integral, 288
strict past, 410–11
strong:
continuity, 315, 317
ergodicity, 130, 194, 387
existence, 337–38, 347
homogeneity, 132
law of large numbers, 50
Markov property, 124, 132, 187,
206, 326, 344
orthogonality, 301
solution, 336
stationarity, 169–70
subadditive, subadditivity:
ergodic theorem, 165
sequence, array, 165
of measures, 7
submartingale, 102–07, 111–12, 412
subordinator, 239, 241–42, 360
subsequence criterion, 40
subspace, 4, 24, 53, 257
substitution rule, 12, 286–88, 353, 439
superharmonic, 426
supermartingale, 103, 113–14, 325,
429
superposition, 266
support:
of additive functional, 368, 431
of local time, 351, 364
of measure, 9, 273, 463
sweeping, 395, 400
symmetry, symmetric:
diﬀerence, 1
point process, 185
random variable, 31, 140
set, 30
spherical, 201
terms, 47, 68, 249
symmetrization, 49, 140, 213
tail:
probabilities, 26, 40, 62
σ-ﬁeld, 30, 110
Tanaka’s formula, 350
Taylor expansion, 67, 69, 286
terminal time, 326
thinning, 180, 182, 266–67
three-series criterion, 48
tightness, 43, 62, 76, 257–59, 261–62,
264, 268, 271, 452
time:
change, 101, 290, 298, 301, 378,
424, 458
homogeneous, 121–22, 187
reversal, 404, 428
total variation, 129, 205
totally inaccessible, 411, 414
transfer, 36, 89, 347
transience, 126, 137, 141, 194, 300
transition:
density, 396
function, matrix, 128, 193
kernel, 118, 122
operator, semigroup, 192, 313–14
translation, 15
trivial, 28, 159
ultimately, 23
uncorrelated, 27, 200
uniform:
distribution, 33
excessivity, 367
integrability, 44–46, 86, 108, 111,
151, 280, 412
laws, 209
uniqueness in law, 337, 345–47, 372,
392
universal completion, 346, 457
upcrossings, 105–06
urn sequence, 169
vague topology, 75–76, 264, 459
variance, 27, 29
version of process, 34
Wald’s identity, 311
weak:
compactness, 76, 257
convergence, 42, 76, 255–74
existence, 337, 342, 345–46,
372
L1 compactness, 46
law of large numbers, 72
optionality, 98
solution, 336, 347
well posed, 341

522
Foundations of Modern Probability
Wiener:
integral, 210–12
process, Brownian motion, 203
Wiener–Hopf factorization, 145
Yosida approximation, 318, 332
zero–one laws, 30–31, 327
Symbols
|A|,
178
ˆA,
418
Aλ,
318, 365
Ac, A \ B,
1
A, Aµ,
13, 23
B, B(S),
2
ˆC,
324
C0, C∞
0 ,
315, 320
Ck,
286
C+
K,
75, 177
Cb(S),
42
C(K, S),
255
CD
K,
401
cov[ξ; A],
252
Dh, Dh,
356
D(R+, S),
261, 458
D([0, 1], S),
267
∆, ∇,
1, 237, 320, 323, 403
∂,
127, 393
δx,
9
d=,
25
d→,
42
E,
25, 177
E,
365
Ex, Eµ,
122
E[ξ; A],
26
E[ξ|F] = EFξ,
81
E, En,
213, 281
E(X),
309, 440
ˆFn,
52
F,
97, 272
F,
101
F+,
98
Fτ,
97
Fτ−,
410
F∞,
109
FD, Fr
D,
400
F ⊗G,
2
F ∨G, 
n Fn,
28
F⊥⊥G, F⊥⊥GH,
27, 86
f±,
11
f−1,
3
f′
i, f′′
ij,
286
f · A,
364
f ◦g,
4
f ⊗g,
215
⟨f, g⟩, f ⊥g,
17
f · µ,
12
f→,
463
fd
→,
256
ϕB,
272
GD, gD,
397
γD
K,
401
H⊗n,
212
HD
K,
400
ha,b,
377
I,
314
In,
213
K,
272
KD, Kr
D,
400
Lt, Lx
t ,
352, 358, 368
LD
K,
401
Lp,
16
L(X), ˆL(X),
282–83, 290, 444
L2(M),
435
L2(η),
216
λ,
15
⟨M⟩, ⟨M, N⟩,
230, 434
M, M0,
444
M2, M2
0, M2
loc,
277, 433–34
M(S),
18, 177
m∼,
442
ˆµ, ˜µ,
61
µt,
121
µD
K,
401

Indices
523
µf,
10
µ ◦f−1,
9
µ ∗ν,
15
µν, µ ⊗ν,
14, 19–20, 119
µ ⊥ν, µ ≪ν,
13
N(m, σ2),
67
N(S),
178
N,
2
ν,
239, 357
νA,
365
Ω, ω,
23
ΩT ,
2
P,
23
P,
428
Px, Pµ,
122
P ◦ξ−1,
24
P[A|F] = P FA,
83
P(S),
18
pa,b,
377
pn
ij, pt
ij,
128, 193
pt, pD
t ,
396
P→,
40
πB, πf, πt,
18, 24, 264
Q, Q+,
75, 102
Rλ,
316
R, R+, R, R+,
2, 5
rx,y,
126
ˆS,
323
ˆS,
177
ˆSµ,
264, 272, 459
σ{·},
2, 5
supp µ,
9
Tt, T λ
t ,
314, 318
τA, τB,
100, 411
τa, τa,b,
376
[τ],
411
θt,
123
U, Uα, UA, Uα
A,
364–65
V · X,
105, 282, 435–36, 444
v→,
75, 459
var[ξ; A],
48
wf, w(f, h), w(f, t, h),
34, 244, 259
˜w(f, t, h),
458
w→,
42
Xc, Xd,
446
Xτ,
105
X∗, X∗
t ,
106
X ◦dY ,
288
[X], [X, Y ],
230, 278, 437
ξ,
358
ˆξ,
422
Z,
354
Z, Z+,
5, 36
ζ, ζD,
326, 394
∅,
1
[[0, 1),
385
1,
36
1A, 1{·},
5, 23
2S,
1
<
⌢,
35

