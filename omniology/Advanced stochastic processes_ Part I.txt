Jan A. Van Casteren
Advanced stochastic processes:
Part I
Download free books at

ii 
 
Jan A. Van Casteren
Advanced Stochastic Processes  
Part I
Download free eBooks at bookboon.com

iii 
 
Advanced stochastic processes: Part I
2nd edition
Â© 2015 Jan A. Van Casteren & bookboon.com
ISBN 978-87-403-1115-0
The author is obliged to Department of Mathematics and Computer Science of the University of Antwerp 
for its material support. The author is also indebted to Freddy Delbaen (ETH, ZÃ¼rich), and the late 
Jean Haezendock (University of Antwerp). A big part of Chapter 5 is due to these people. The author is 
thankful for comments and logistic support by numerous students who have taken courses based on this 
text. In particular, he is grateful to Lieven Smits and Johan Van Biesen (former students at the University 
of Antwerp) who wrote part of the Chapters 1 and 2. The author gratefully acknowledges World Scientic 
Publishers (Singapore) for their permission to publish the contents of Chapter 4 which also makes up 
a substantial portion of Chapter 1 in [144]. The author also learned a lot from the book by Stirzaker 
[124]. Section 1 of Chapter 2 is taken from [124], and the author is indebted to David Stirzaker to allow 
him to include this material in this book. The author is also grateful to the people of Bookboon, among 
whom Karin Hamilton Jakobsen and Ahmed Zsolt Dakroub, who assisted him in the final stages of the 
preparation of this book.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
4 
Contents
Contents
Preface
i
Chapter 1.
Stochastic processes: prerequisites
1
1.
Conditional expectation
2
2.
Lemma of Borel-Cantelli
9
3.
Stochastic processes and projective systems of measures
10
4.
A deï¬nition of Brownian motion
16
5.
Martingales and related processes
17
Chapter 2.
Renewal theory and Markov chains
35
1.
Renewal theory
35
2.
Some additional comments on Markov processes
61
3.
More on Brownian motion
70
4.
Gaussian vectors.
76
5.
Radon-Nikodym Theorem
78
6.
Some martingales
78
Download free eBooks at bookboon.com
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
5 
Contents
Chapter 3.
An introduction to stochastic processes: Brownian motion,
Gaussian processes and martingales
89
1.
Gaussian processes
89
2.
Brownian motion and related processes
98
3.
Some results on Markov processes, on Feller semigroups and on the
martingale problem
117
4.
Martingales, submartingales, supermartingales and semimartingales 147
5.
Regularity properties of stochastic processes
151
6.
Stochastic integrals, ItË†oâ€™s formula
162
7.
Black-Scholes model
188
8.
An Ornstein-Uhlenbeck process in higher dimensions
197
9.
A version of Ferniqueâ€™s theorem
221
10.
Miscellaneous
223
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
6 
Contents
3.
A taste of ergodic theory
340
4.
Projective limits of probability distributions
357
5.
Uniform integrability
369
6.
Stochastic processes
373
7.
Markov processes
399
8.
The Doob-Meyer decomposition via Komlos theorem
409
Subjects for further research and presentations
423
Bibliography
425
Index
433
Chapter 4.
Stochastic diï¬€erential equations
243
1.
Solutions to stochastic diï¬€erential equations
243
2.
A martingale representation theorem
272
3.
Girsanov transformation
277
Chapter 5.
Some related results
295
1.
Fourier transforms
295
2.
Convergence of positive measures
324
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
i 
Preface
Preface
This book deals with several aspects of stochastic process theory:
Markov
chains, renewal theory, Brownian motion, Brownian motion as a Gaussian pro-
cess, Brownian motion as a Markov process, Brownian motion as a martingale,
stochastic calculus, ItË†oâ€™s formula, regularity properties, Feller-Dynkin semi-
groups and (strong) Markov processes. Brownian motion can also be seen as
limit of normalized random walks. Another feature of the book is a thorough
discussion of the Doob-Meyer decomposition theorem. It also contains some
features of stochastic diï¬€erential equations and the Girsanov transformation.
The ï¬rst chapter (Chapter 1) contains a (gentle) introduction to the theory
of stochastic processes.
It is more or less required to understand the main
part of the book, which consists of discrete (time) probability models (Chap-
ter 2), of continuous time models, in casu Brownian motion, Chapter 3, and
of certain aspects of stochastic diï¬€erential equations and Girsanovâ€™s transfor-
mation (Chapter 4). In the ï¬nal chapter (Chapter 5) a number of other, but
related, issues are treated. Several of these topics are explicitly used in the
main text (Fourier transforms of distributions, or characteristic functions of
random vectors, LÂ´evyâ€™s continuity theorem, Kolmogorovâ€™s extension theorem,
uniform integrability); some of them are treated, like the important Doob-Meyer
decomposition theorem, but are not explicitly used. Of course ItË†oâ€™s formula
implies that a C2-function composed with a local semi-martingale is again a
semi-martingale. The Doob-Meyer decomposition theorem yields that a sub-
martingale of class (DL) is a semi-martingale. Section 1 of Chapter 5 contains
several aspects of Fourier transforms of probability distributions (characteristic
functions). Among other results Bochnerâ€™s theorem is treated here. Section
2 contains convergence properties of positive measures. Section 3 gives some
results in ergodic theory, and gives the connection with the strong law of large
numbers (SLLN). Section 4 gives a proof of Kolmogorovâ€™s extension theorem
(for a consistent family of probability measures on Polish spaces). In Section
5 the reader ï¬nds a short treatment of uniform integrable families of functions
in an L1-space. For example Scheï¬€Â´eâ€™s theorem is treated. Section 6 in Chapter
5 contains a precise description of the regularity properties (like almost sure
right-continuity, almost sure existence of left limits) of stochastic processes like
submartingales, LÂ´evy processes, and others; it also contains a proof of Doobâ€™s
maximal inequality for submartingales. Section 7 of the same chapter contains
a description of Markov process theory starting from just one probability space
instead of a whole family. The proof of the Doob-Meyer decompositon theorem
is based on a result by Komlos: see Section 8. Throughout the book the reader
will be exposed to martingales, and related processes.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
ii 
Preface
Readership. From the description of the contents it is clear that the text
is designed for students at the graduate or master level. The author believes
that also Ph.D. students, and even researchers, might beneï¬t from these notes.
The reader is introduced in the following topics: Markov processes, Brownian
motion and other Gaussian processes, martingale techniques, stochastic diï¬€er-
ential equations, Markov chains and renewal theory, ergodic theory and limit
theorems.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
1 
Stochastic processes: prerequisites
CHAPTER 1
Stochastic processes: prerequisites
In this chapter we discuss a number of relevant notions related to the theory
of stochastic processes. Topics include conditional expectation, distribution of
Brownian motion, elements of Markov processes, and martingales. For com-
pleteness we insert the deï¬nitions of a Ïƒ-ï¬eld or Ïƒ-algebra, and concepts related
to measures.
1.1. Definition. A Ïƒ-algebra, or Ïƒ-ï¬eld, on a set â„¦is a subset A of the power
set P pâ„¦q with the following properties:
(i) â„¦P A;
(ii) A P A implies Ac :â€œ â„¦zA P A;
(iii) if pAnqnÄ›1 is a sequence in A, then
8
Ä
nâ€œ1
An belongs to A.
Let A be a Ïƒ-ï¬eld on â„¦. Unless otherwise speciï¬ed, a measure is an application
Âµ : A Ã‘ r0, 8s with the following properties:
â€š Âµ pHq â€œ 0;
â€š if pAnqnÄ›1 is a mutually disjoint sequence in A, then
Âµ
Ëœ 8
Ä
nâ€œ1
An
Â¸
â€œ
Ã¿
NÃ‘8
N
Ã¿
jâ€œ1
Âµ pAnq â€œ
8
Ã¿
nâ€œ1
Âµ pAnq .
If Âµ is measure on A for which Âµ pâ„¦q â€œ 1, then Âµ is called a probability measure;
if Âµ pâ„¦q Ä 1, then Âµ is called a sub-probability measure. If Âµ : A Ã‘ r0, 1s is a
probability space, then the triple pâ„¦, A, Âµq is called a probability space, and the
elements of A are called events.
Let M be a collection of subsets of P pâ„¦q, where â„¦is some set like in Deï¬nition
1.1. The smallest Ïƒ-ï¬eld containing M is called the Ïƒ-ï¬eld generated by M, and
it is often denoted by Ïƒ pMq. Let pâ„¦, A, Âµq be a sub-probability space, i.e. Âµ is
a sub-probability on the Ïƒ-ï¬eld A. Then, we enlarge â„¦with one point â–³, and
enlarge A to
Aâ–³:â€œ Ïƒ pA Y tâ–³uq â€œ
â£
A P P
`
â„¦â–³Ë˜
: A X â„¦P A
(
.
Then Âµâ–³: Aâ–³Ã‘ r0, 1s, deï¬ned by
Âµâ–³pAq â€œ Âµ pA X â„¦q ` p1 Â´ Âµ pâ„¦qq 1A pâ–³q ,
A P Aâ–³,
(1.1)
turns the space
`
â„¦â–³, Aâ–³, Âµâ–³Ë˜
into a probability space. Here â„¦â–³â€œ â„¦Y tâ–³u.
This kind of construction also occurs in the context of Markov processes with
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
2 
Stochastic processes: prerequisites
ï¬nite lifetime: see the equality (3.75) in (an outline of) the proof of Theorem
3.37. For the important relationship between Dynkin systems, or Î»-systems,
and Ïƒ-algebras, see Theorem 2.42.
1. Conditional expectation
1.2. Definition. Let pâ„¦, A, Pq be a probability space, and let A and B be
events in A such that P rBs Ä… 0. The quantity P
`
A
Ë‡Ë‡ B
Ë˜
â€œ P pA X Bq
P pBq
is then
called the conditional probability of the event A with respect to the event B.
We put P
`
A
Ë‡Ë‡ B
Ë˜
â€œ 0 if P pBq â€œ 0.
Consider a ï¬nite partition tB1, . . . , Bnu of â„¦with Bj P A for all j â€œ 1, . . . , n,
and let B be the subï¬eld of A generated by the partition tB1, . . . , Bnu, and
write
P
â€œ
A
Ë‡Ë‡ B
â€°
â€œ
nÃ¿
jâ€œ1
P
`
A
Ë‡Ë‡ Bj
Ë˜
1Bj.
Then P
â€œ
A
Ë‡Ë‡ B
â€°
is a B-measurable stochastic variable on â„¦, and
Å¼
B
P
â€œ
A
Ë‡Ë‡ B
â€°
dP â€œ
Å¼
B
1AdP
for all B P B.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
3 
Stochastic processes: prerequisites
Conversely, if f is a B-measurable stochastic variable on â„¦with the property
that for all B P B the equality
ÅŸ
B fdP â€œ
ÅŸ
B 1AdP holds, then f â€œ P
â€œ
A
Ë‡Ë‡ B
â€°
P-almost surely. This is true, because
ÅŸ
B
`
f Â´ P
â€œ
A
Ë‡Ë‡ B
â€°Ë˜
dP â€œ 0 for all B P B.
If B is a sub-ï¬eld (more precisely a sub-Ïƒ-ï¬eld, or sub-Ïƒ-algebra) generated by
a ï¬nite partition of â„¦, then for every A P A there exists one and only one class
of variables in L1 pâ„¦, B, Pq, which we denote by P
â€œ
A
Ë‡Ë‡ B
â€°
, with the following
property
Å¼
B
P
â€œ
A
Ë‡Ë‡ B
â€°
dP â€œ
Å¼
B
1AdP
for all B P B.
The variable Å™n
jâ€œ1 P
`
A
Ë‡Ë‡ Bj
Ë˜
1Bj is an element from the class P
â€œ
A
Ë‡Ë‡ B
â€°
.
If we ï¬x B P A with P pBq Ä… 0, then the measure A ÃÃ‘ P
`
A
Ë‡Ë‡ B
Ë˜
is a probability
measure on pâ„¦, Aq. If P pBq â€œ 0, then the measure A ÃÃ‘ P
`
A
Ë‡Ë‡ B
Ë˜
is the zero-
measure.
Let X be a P-integrable real or complex valued stochastic variable on â„¦. Then
X is also P
`
Â¨
Ë‡Ë‡ B
Ë˜
-integrable, and
Å¼
XdP
`
Â¨
Ë‡Ë‡ B
Ë˜
â€œ E rX1Bs
P pBq ,
provided P pBq Ä… 0.
This quantity is the average of the stochastic variable over the event B. As
before, it is easy to show that if B is a subï¬eld of A generated by a ï¬nite
partition tB1, . . . , Bnu of â„¦, then there exists, for every P-integrable real or
complex valued stochastic variable X on â„¦one and only one class of functions
in L1 pâ„¦, B, Pq, which we denote by E
â€œ
X
Ë‡Ë‡ B
â€°
with the property that
Å¼
B
E
â€œ
X
Ë‡Ë‡ B
â€°
dP â€œ
Å¼
B
X dP
for all B P B.
The variable Å™n
jâ€œ1
ÅŸ
XdP
`
Â¨
Ë‡Ë‡ Bj
Ë˜
1Bj is an element from the class E
â€œ
X
Ë‡Ë‡ B
â€°
.
The next theorem generalizes the previous properties to an arbitrary subï¬eld
(or more precisely sub-Ïƒ-ï¬eld) B of A.
1.3. Theorem (Theorem and deï¬nition). Let pâ„¦, A, Pq be a probability space
and let B be a subï¬eld of A. Then for every stochastic variable X PL1 pâ„¦, A, Pq
there exists one and only one class in L1 pâ„¦, B, Pq, which is denoted by E
â€œ
X
Ë‡Ë‡B
â€°
and which is called the conditional expectation of X with respect to B, with the
property that
Å¼
B
E
â€œ
X
Ë‡Ë‡ B
â€°
dP â€œ
Å¼
B
X dP
for all B P B.
If X â€œ 1A, with A P A, then we write P
â€œ
A
Ë‡Ë‡ B
â€°
instead of E
â€œ
1A
Ë‡Ë‡ B
â€°
; if B
is generated by just one stochastic variable Y , then we write E
â€œ
X
Ë‡Ë‡ Y
â€°
and
P
â€œ
A
Ë‡Ë‡ Y
â€°
instead of respectively E
â€œ
X
Ë‡Ë‡ Ïƒ pY q
â€°
and P
â€œ
A
Ë‡Ë‡ Ïƒ pY q
â€°
.
Proof. Suppose that X is real-valued; if X â€œ Re X ` iIm X is complex-
valued, then we apply the following arguments to Re X and Im X. Upon writ-
ing the real-valued stochastic variable X as X â€œ X` Â´ XÂ´, where XË˜ are
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
4 
Stochastic processes: prerequisites
non-negative stochastic variables in L1 pâ„¦, A, Pq, without loss of generality we
may and do assume that X Ä› 0.
Deï¬ne the measure Âµ : A Ã‘ r0, 8q by
ÂµpAq â€œ
Å¼
A
XdP, A P A. Then Âµ is ï¬nite measure which is absolutely contin-
uous with respect to the measure P. We restrict Âµ to the measurable space
pâ„¦, Bq; its absolute continuity with respect to P conï¬ned to pâ„¦, Bq is preserved.
From the Radon-Nikodym theorem it follows that there exists a unique class
Y P L1 pâ„¦, B, Pq such that, for all B P B, the following equality is valid:
ÂµpBq â€œ
Å¼
B
Y dP,
and hence
Å¼
B
XdP â€œ
Å¼
B
Y dP.
This proves Theorem1.3.
â–¡
If B is generated by a countable or ï¬nite partition tBj : j P Nu, then it is fairly
easy to give an explicit formula for the conditional expectation of a stochastic
X P L1 pâ„¦, A, Pq with respect to B:
E
â€œ
X
Ë‡Ë‡ B
â€°
â€œ
Ã¿
jPN
ÅŸ
Bj XdP
P pBjq 1Bj â€œ
Ã¿
jPN
E
â€œ
X
Ë‡Ë‡ Bj
â€°
1Bj.
Next let B be an arbitrary subï¬eld of A, let X belong to L1 pâ„¦, A, Pq, and let
B be an atom in B. The latter means that P pBq Ä… 0, and if A P B is such
that A Ä‚ B, then either P pAq â€œ 0 or P pBzAq â€œ 0. If Y represents E
â€œ
X
Ë‡Ë‡ B
â€°
,
then Y 1B â€œ b1B, P-almost surely, for some constant b. This follows from the
B-measurability of the variable Y together with the fact that B is an atom for
pâ„¦, B, Pq. So we get
ÅŸ
B XdP â€œ
ÅŸ
B E
â€œ
X
Ë‡Ë‡ B
â€°
dP â€œ
ÅŸ
Y 1BdP â€œ bP pBq, and hence
b â€œ
ÅŸ
B XdP
P pBq . Consequently, on the atom B we have:
E
â€œ
X
Ë‡Ë‡ B
â€°
â€œ
ÅŸ
B XdP
P pBq â€œ b,
P-almost surely.
In particular, for X â€œ 1A, we have on the atom B the equality
P
â€œ
A
Ë‡Ë‡ B
â€°
â€œ P pA X Bq
P pBq
,
P-almost surely.
If B is not an atom, then the conditional expectation on B need not be constant.
In the following theorem we collect some properties of conditional expectation.
For the notion of uniform integrability see Section 5.
1.4. Theorem. Let pâ„¦, A, Pq be a probability space, and let B be a subï¬eld of
A. Then the following assertions hold.
(1) If all events in B have probability 0 or 1 (in particular if B is the
trivial ï¬eld tH, â„¦u), then for all stochastic variables X P L1 pâ„¦, A, Pq
the equality E
â€œ
X
Ë‡Ë‡ B
â€°
â€œ E pXq is true P-almost surely.
(2) If X is a stochastic variable in L1 pâ„¦, A, Pq such that B and ÏƒpXq
are independent, then the equality E
â€œ
X
Ë‡Ë‡ B
â€°
â€œ E pXq is true P-almost
surely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
5 
Stochastic processes: prerequisites
(3) If a and b are real or complex constants, and if the stochastic variables
X and Y belong to L1 pâ„¦, A, Pq, then the equality
E
â€œ
aX ` bY
Ë‡Ë‡ B
â€°
â€œ aE
â€œ
X
Ë‡Ë‡ B
â€°
` bE
â€œ
Y
Ë‡Ë‡ B
â€°
is true P-almost surely.
(4) If X and Y are real stochastic variables in L1 pâ„¦, A, Pq such that X Ä
Y , then the inequality E
â€œ
X
Ë‡Ë‡ B
â€°
Ä E
â€œ
Y
Ë‡Ë‡ B
â€°
holds P-almost surely.
Hence the mapping X ÃÃ‘ E
â€œ
X
Ë‡Ë‡ B
â€°
is a mapping from L1 pâ„¦, A, Pq
onto L1 pâ„¦, B, Pq.
(5) (a) If pXn : n P Nq is a non-decreasing sequence of stochastic variables
in L1 pâ„¦, A, Pq, then
sup
n E
â€œ
Xn
Ë‡Ë‡ B
â€°
â€œ E
â€
sup
n Xn
Ë‡Ë‡ B
È·
,
P-almost surely.
(b) If pXn : n P Nq is any sequence of stochastic variables in
L1 pâ„¦, A, Pq which converges P-almost surely to a stochastic vari-
able X, and if there exists a stochastic variable Y P L1 pâ„¦, A, Pq
such that |Xn| Ä Y for all n P N, then
lim
nÃ‘8 E
â€œ
Xn
Ë‡Ë‡ B
â€°
â€œ E
â€
lim
nÃ‘8 Xn
Ë‡Ë‡ B
Ä±
,
P-almost surely, and in L1 pâ„¦, B, Pq.
The condition â€œ|Xn| Ä Y for all n P N with Y P L1 pâ„¦, A, Pqâ€
may be replaced with â€œthe sequence pXnqnPN is uniformly integrable in
the space L1 pâ„¦, A, Pqâ€ and still keep the second conclusion in (5b).
In order to have P-almost sure convergence the uniform integrability
condition should be replaced with the condition
inf
MÄ…0, MPR sup
nPN
E
â€œ
|Xn| , |Xn| Ä… M
Ë‡Ë‡ B
â€°
â€œ 0,
P-almost surely.
(1.2)
(6) If cpxq is a convex continuous function from R to R, and if X belongs
to L1 pâ„¦, A, Pq, then
c
`
E
â€œ
X
Ë‡Ë‡ B
â€°Ë˜
Ä E
â€œ
cpXq
Ë‡Ë‡ B
â€°
,
P-almost surely.
(7) Let p Ä› 1, and let X be a stochastic variable in Lp pâ„¦, A, Pq. Then the
stochastic variable E
â€œ
X
Ë‡Ë‡ B
â€°
belongs to Lp pâ„¦, B, Pq, and
â€ºâ€ºE
â€œ
X
Ë‡Ë‡ B
â€°â€ºâ€º
p Ä }X}p .
So the linear mapping X ÃÃ‘ E
â€œ
X
Ë‡Ë‡B
â€°
is a projection from Lp pâ„¦, A, Pq
onto Lp pâ„¦, B, Pq.
(8) (Tower property) Let B1 be another subï¬eld of A such that B Ä B1 Ä A.
If X belongs to L1 pâ„¦, A, Pq, then the equality
E
â€œ
E
â€œ
X
Ë‡Ë‡ B1â€° Ë‡Ë‡ B
â€°
â€œ E
â€œ
X
Ë‡Ë‡ B
â€°
holds P-almost surely.
(9) If X belongs to L1 pâ„¦, B, Pq, then E
â€œ
X
Ë‡Ë‡ B
â€°
â€œ X, P-almost surely.
(10) If X belongs to L1 pâ„¦, A, Pq, and if Z belongs to L8 pâ„¦, B, Pq, then
E
â€œ
ZX
Ë‡Ë‡ B
â€°
â€œ ZE
â€œ
X
Ë‡Ë‡ B
â€°
,
P-almost surely.
(11) If X belongs to L2 pâ„¦, A, Pq, then E
â€œ
Y
`
X Â´ E
`
X
Ë‡Ë‡ B
â€°Ë˜â€°
â€œ 0 for all
Y P L2 pâ„¦, B, Pq. Hence, the mapping X ÃÃ‘ E
â€œ
X
Ë‡Ë‡ B
â€°
is an orthogonal
projection from L2 pâ„¦, A, Pq onto L2 pâ„¦, B, Pq.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
6 
Stochastic processes: prerequisites
Observe that for B the trivial Ïƒ-ï¬eld, i.e. B â€œ tH, â„¦u, the condition in (1.2) is
the same as saying that the sequence pXnqn is uniformly integrable in the sense
that
inf
MÄ…0, MPR sup
nPN
E r|Xn| , |Xn| Ä… Ms â€œ 0.
(1.3)
Proof. We successively prove the items in Theorem 1.4.
(1) For every B P B we have to verify the equality:
Å¼
B
XdP â€œ
Å¼
B
E pXq dP.
If P pBq â€œ 0, then both members are 0; if P pBq â€œ 1, then both mem-
bers are equal to E pXq. This proves that the constant E pXq can be
identiï¬ed with the class E
â€œ
X
Ë‡Ë‡ B
â€°
.
(2) For every B P B we again have to verify the equality:
ÅŸ
B XdP â€œ
ÅŸ
B E pXq dP. Employing the independence of X and B P B this can be
seen as follows:
Å¼
B
X dP â€œ
Å¼
â„¦
X1B dP â€œ E rX1Bs â€œ E rXs E r1Bs â€œ
Å¼
B
E rXs dP.
(1.4)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
7 
Stochastic processes: prerequisites
(3) This assertion is clear.
(4) This assertion is clear.
(5) (a) For all B P B and n P N we have
ÅŸ
B E
â€œ
Xn
Ë‡Ë‡ B
â€°
dP â€œ
ÅŸ
B Xn dP. By
(4) we see that the sequence of conditional expectations
E
â€œ
Xn
Ë‡Ë‡ B
â€°
, n P N, increases P-almost surely.
The assertion in (5a) then follows from the monotone convergence
theorem.
(b) Put XËš
n â€œ supkÄ›n Xk, XËšËš
n
â€œ infkÄ›n Xk. Then we have Â´Y Ä
XËšËš
n
Ä Xn Ä XËš
n Ä Y , P-almost surely. Moreover, the sequences
pY Â´ XËš
nqnPN and pY ` XËšËš
n qnPN are increasing sequences consisting
of non-negative stochastic variables with Y Â´ lim supnÃ‘8 Xn and
Y `lim infnÃ‘8 Xn as their respective suprema. Since the sequence
pXnqnPN converges P-almost surely to X, it follows by (5a) together
with (4) that
E
â€œ
XËšËš
n
Ë‡Ë‡ B
â€°
Ã’ E
â€œ
XËšËš Ë‡Ë‡ B
â€°
and
E
â€œ
XËš
n
Ë‡Ë‡ B
â€°
Ã“ E
â€œ
XËšËš Ë‡Ë‡ B
â€°
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
8 
Stochastic processes: prerequisites
From the pointwise inequalities XËšËš
n
Ä Xn Ä XËš
n it then follows
that lim
nÃ‘8 E
â€œ
Xn
Ë‡Ë‡B
â€°
â€œ E
â€œ
X
Ë‡Ë‡ B
â€°
, P-almost surely.
Next let the
uniformly integrable sequence pXnqn in L1 pâ„¦, A, Pq be pointwise
convergent to X. Then lim
nÃ‘8 E r|Xn Â´ X|s â€œ 0. What we need is
that
lim
nÃ‘8 E
â€œ
|Xn Â´ X|
Ë‡Ë‡ B
â€°
â€œ 0.
(1.5)
Under the extra hypothesis (1.2) this can be achieved as follows:
lim sup
nÃ‘8 E
â€œ
|Xn Â´ X|
Ë‡Ë‡ B
â€°
Ä lim sup
nÃ‘8 E
â€œ
|Xn Â´ X| , |Xn Â´ X| Ä M
Ë‡Ë‡ B
â€°
` lim sup
nÃ‘8 E
â€œ
|Xn Â´ X, |Xn Â´ X| Ä… M|
Ë‡Ë‡ B
â€°
(apply what already has been proved in (5b), with |Xn Â´ X| in-
stead of Xn, to the ï¬rst term)
Ä lim sup
nÃ‘8 E
â€œ
|Xn Â´ X, |Xn Â´ X| Ä… M|
Ë‡Ë‡ B
â€°
.
(1.6)
In (1.6) we let M tend to 8, and employ (1.2) to conclude (1.5).
This completes the proof of item (5).
(6) Write cpxq as a countable supremum of aï¬ƒne functions
cpxq â€œ sup
nPN
Lnpxq,
(1.7)
where Lnpzq â€œ anz ` bn Ä cpzq, for all those z for which cpzq Äƒ 8,
i.e.
for appropriate constants an and bn.
Every stochastic variable
Ln pXq is integrable; by linearity (see (3)) we have Ln
`
E
â€œ
X
Ë‡Ë‡ B
â€°Ë˜
â€œ
E
â€œ
Ln pXq
Ë‡Ë‡ B
â€°
. Hence
Ln
`
E
â€œ
X
Ë‡Ë‡ B
â€°Ë˜
Ä E
â€œ
c pXq
Ë‡Ë‡ B
â€°
.
Consequently,
c
`
E
â€œ
X
Ë‡Ë‡ B
â€°Ë˜
â€œ sup
nPN
Ln
`
E
â€œ
X
Ë‡Ë‡ B
â€°Ë˜
Ä E
â€œ
c pXq
Ë‡Ë‡ B
â€°
.
The fact that convex function can be written in the form (1.7) can be
found in most books on convex analysis; see e.g. Chapter 3 in [28].
(7) It suï¬ƒces to apply item (6) to the function cpxq â€œ |x|p.
(8) This assertion is clear.
(9) This assertion is also obvious.
(10) This assertion is evident if Z is a ï¬nite linear combination of indicator
functions of events taken from B. The general case follows via a limiting
procedure.
(11) This assertion is clear if Y is a ï¬nite linear combination of indicator
functions of events taken from B. The general case follows via a limiting
procedure.
The proof of Theorem 1.4 is now complete.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
9 
Stochastic processes: prerequisites
2. Lemma of Borel-Cantelli
1.5. Definition. The limes superior or upper-limit of a sequence pAnqnPN in
a universe â„¦is the set A of those elements Ï‰ P â„¦with the property that Ï‰
belongs to inï¬nitely many Anâ€™s. In a formula:
A â€œ lim sup
nÃ‘8 An â€œ
Ä
nPN
Ä
kÄ›n
Ak.
The indicator-function 1A of the limes-superior of the sequence pAnqnPN is equal
to the lim sup of the sequence of its indicator-functions: 1A â€œ lim sup
nÃ‘8 1An.
The limes inferior or lower-limit of a sequence pAnqnPN in a universe â„¦is the set
A of those elements Ï‰ P â„¦with the property that, up to ï¬nitely many Akâ€™s, the
element (sample) Ï‰ belongs to all Anâ€™s. In a formula:
A â€œ lim inf
nÃ‘8 An â€œ
Ä
nPN
Ä
kÄ›n
Ak.
The indicator-function 1A of the limes-inferior of the sequence pAnqnPN is equal
to the lim inf of the sequence of its indicator-functions: 1A â€œ lim inf
nÃ‘8 1An.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
10 
Stochastic processes: prerequisites
1.6. Lemma. Let pÎ±nqnPN be a sequence of real numbers such that 0 Ä Î±n Äƒ 1.
Then limnÃ‘8
Å™n
kâ€œ1 Î±k Äƒ 8 if and only if limnÃ‘8
Å›n
kâ€œ1 p1 Â´ Î±kq Ä… 0.
Proof. For 0 Ä Î± Äƒ 1 the following elementary inequalities hold:
Â´
Î±
1 Â´ Î± Ä log p1 Â´ Î±q Ä Â´Î±.
Hence we see
Â´
nÃ¿
kâ€œ1
Î±k
1 Â´ Î±k
Ä log
Ëœ n
Åº
kâ€œ1
p1 Â´ Î±kq
Â¸
Ä Â´
nÃ¿
kâ€œ1
Î±k.
The assertion in Lemma 1.6 easily follows from these inequalities.
â–¡
1.7. Lemma (Lemma of Borel-Cantelli). Let pAnqnPN be a sequence of events,
and put A â€œ lim supnÃ‘8 An â€œ Å
nPN
Å¤
kÄ›n Ak.
(i) If Å™8
nâ€œ1 P pAnq Äƒ 8, then P pAq â€œ 0.
(ii) If the events An, n P N, are mutually P-independent, then the converse
statement is true as well: P pAq Äƒ 1 implies Å™8
kâ€œ1 P pAkq Äƒ 8, and
hence Å™8
kâ€œ1 P pAkq â€œ 8 if and only if P pAq â€œ 1.
Proof. (i) For P pAq we have the following estimate:
P pAq Ä inf
nPN
8
Ã¿
kâ€œn
P pAkq .
(1.8)
Since Å™8
nâ€œ1 P pAnq Äƒ 8, we see that the right-hand side of (1.8) is 0.
(ii) The statement in assertion (ii) is trivial if for inï¬nitely many numbers k the
equality P pAkq â€œ 1 holds. So we may assume that for all k P N the probability
P pAkq is strictly less than 1. Apply Lemma 1.6 with Î±k â€œ P pAkq to obtain that
Å™8
kâ€œ1 P pAkq Äƒ 8 if and only if
0 Äƒ lim
nÃ‘8
n
Åº
kâ€œ1
p1 Â´ P pAkqq â€œ lim
nÃ‘8
n
Åº
kâ€œ1
P pâ„¦zAkq
(the events pAkqnPN are independent)
â€œ lim
nÃ‘8 P
Ëœ nÄ
kâ€œ1
pâ„¦zAkq
Â¸
â€œ lim
nÃ‘8 P
Ëœ
â„¦z
nÄ
kâ€œ1
Ak
Â¸
â€œ 1 Â´ P pAq .
(1.9)
This proves assertion (ii) of Lemma 1.7.
â–¡
3. Stochastic processes and projective systems of measures
1.8. Definition. Consider a probability space pâ„¦, A, Pq and an index set I.
Suppose that for every t P I a measurable space pEt, Etq and an A-Et-measurable
mapping Xptq : â„¦Ã‘ Et are given. Such a family tXptq : t P Iu is called a
stochastic process.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
11 
Stochastic processes: prerequisites
1.9. Remark. The space â„¦is often called the sample path space, the space
Et is often called the state space of the state variable Xptq.
The Ïƒ-ï¬eld A
is often replaced with (some completion of) the Ïƒ-ï¬eld generated by the state
variables Xptq, t P I. This Ïƒ-ï¬eld is written as F. Let pS, Sq be some measurable
space. An F-S measurable mapping Y : â„¦Ã‘ S is called an S-valued stochastic
variable. Very often the state spaces are the same, i.e. pEt, Etq â€œ pE, Eq, for all
state variables Xptq, t P I.
In applications the index set I is often interpreted as the time set. So I can
be a ï¬nite index set, e.g. I â€œ t0, 1, . . . , nu, or an inï¬nite discrete time set, like
I â€œ N â€œ t0, 1, . . .u or I â€œ Z. The set I can also be a continuous time set: I â€œ R
or I â€œ R` â€œ r0, 8q. In the present text, most of the time we will consider
I â€œ r0, 8q. Let I be N, Z, R, or r0, 8q. In the so-called time-homogeneous or
stationary case we also consider mappings Ï‘s : â„¦Ã‘ â„¦, s P I, s Ä› 0, such that
XptqËÏ‘s â€œ Xpt`sq, P-almost surely. It follows that these translation mappings
Ï‘s : â„¦Ã‘ â„¦, s P I, are Ft-FtÂ´s-measurable, for all t Ä› s. If Y is a stochastic
variable, then Y Ë Ï‘s is measurable with respect to the Ïƒ-ï¬eld Ïƒ tXptq : t Ä› su.
The concept of time-homogeneity of the process pXptq : t P Iq can be explained
as follows. Let Y : â„¦Ã‘ R be a stochastic variable; e.g. Y â€œ Å›n
jâ€œ1 fj pX ptjqq,
where fj : E Ã‘ R, 1 Ä j Ä n, are bounded measurable functions. Deï¬ne the
transition probability P ps, Bq as follows: P ps, Bq â€œ P pXpsq P Bq, s P I, B P E.
The measure B ÃÃ‘ E rY Ë Ï‘s, Xpsq P Bs is absolutely continuous with respect to
the measure B ÃÃ‘ P ps, Bq, B P E. It follows that there exists a function Fps, xq,
called the Radon-Nikodym derivative of the measure B ÃÃ‘ E rY Ë Ï‘s, Xpsq P Bs
with respect B ÃÃ‘ P ps, Bq, such that E rY Ë Ï‘s, Xpsq P Bs â€œ
ÅŸ
F ps, xq P ps, dxq.
The function F ps, xq is usually written as
F ps, xq â€œ E
â€œ
Y Ë Ï‘s
Ë‡Ë‡ Xpsq P dx
â€°
â€œ E rY Ë Ï‘s, Xpsq P dxs
P rXpsq P dxs
.
1.10. Definition. The process pXptq : t P Iq is called time-homogeneous or
stationary in time, provided that for all bounded stochastic variables Y : â„¦Ã‘ R
the function
E
â€œ
Y Ë Ï‘s
Ë‡Ë‡ Xpsq P dx
â€°
is independent of s P I, s Ä› 0.
In practice we only have to verify the property in Deï¬nition 1.10 for Y of the
form Y â€œ Å›n
jâ€œ1 fj pX ptjqq, where fj : Etj Ã‘ R, 1 Ä j Ä n, are bounded
measurable functions. Then Y Ë Ï‘s â€œ Å›n
jâ€œ1 fj pX ptj ` sqq. This statement is a
consequence of the monotone class theorem.
3.1. Finite dimensional distributions. As above let pâ„¦, A, Pq be a prob-
ability space and let tXptq : t P Iu be a stochastic process where each state
variable Xptq has state space pEt, Etq. For every non-empty subset J of I we
write EJ â€œ Å›
tPJ Et and EJ â€œ btPJEt denotes the product-ï¬eld. We also write
XJ â€œ btPJXt. So that, if J â€œ tt1, . . . , tnu, then XJ â€œ pX pt1q , . . . , X ptnqq. The
mapping XJ is the product mapping from â„¦to EJ. The mapping XJ : â„¦Ã‘ EJ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
12 
Stochastic processes: prerequisites
is A-EJ-measurable. We can use it to deï¬ne the image measure PJ:
PJ pBq â€œ XJP pBq â€œ P
â€œ
XÂ´1
J B
â€°
â€œ P rÏ‰ P â„¦: XJpÏ‰q P Bs â€œ P rXJ P Bs ,
where B P EJ. Between the diï¬€erent probability spaces
`
EJ, EJ, PJ
Ë˜
there exist
relatively simple relationships. Let J and H be non-empty subsets of I such that
J Ä‚ H, and consider the EH-EJ-measurable projection mapping pH
J : EH Ã‘ EJ,
which â€forgetsâ€ the â€coordinatesâ€ in HzJ. If H â€œ I, then we write pJ â€œ pI
J.
For every pair J and H with J Ä‚ H Ä‚ I we have XJ â€œ pH
J Ë XH, and hence we
get PJ pBq â€œ pH
J PH pBq â€œ PH
â€œ
pH
J P B
â€°
, where B belongs to EJ. In particular
if H â€œ I, then PJ pBq â€œ pJP pBq â€œ P rpJ P Bs, where B belongs to EJ. If
J â€œ tt1, . . . , tnu is a ï¬nite set, then we have
PJ rB1 Ë† Â¨ Â¨ Â¨ Ë† Bns â€œ P
â€œ
XÂ´1
J
pB1 Ë† Â¨ Â¨ Â¨ Ë† Bnq
â€°
â€œ P rX pt1q P B1, . . . , X ptnq P Bns ,
with Bj P Etj, for 1 Ä j Ä n.
1.11. Remark. If the process tXptq : t P Iu is interpreted as the movement
of a particle, which at time t happens to be in the state spaces Et, and if
J â€œ tt1, . . . , tnu is a ï¬nite subset of I, then the probability measure PJ has the
following interpretation:
For every collection of sets B1 P Et1, . . . , Bn P Etn the number
PJ rB1 Ë† Â¨ Â¨ Â¨ Ë† Bns
is the probability that at time t1 the particle is in B1, at time t2 it is
in B2, . . ., and at time tn it is in Bn.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
13 
Stochastic processes: prerequisites
1.12. Definition. Let H be the collection of all ï¬nite subsets of I. Then the
family
â£`
EJ, EJ, PJ
Ë˜
: J P H
(
is called the family of ï¬nite-dimensional distri-
butions of the process tXptq : t P Iu; the one-dimensional distributions
â£`
Et, Et, Pttu
Ë˜
: t P I
(
are often called the marginals of the process.
The family of ï¬nite-dimensional distributions is a projective or consistent family
in the sense as explained in the following deï¬nition.
1.13. Definition. A family of probability spaces
â£`
EJ, EJ, PJ
Ë˜
: J P H
(
is
called a projective, a consistent system, or a cylindrical measure provided that
PJ pBq â€œ pH
J pPHq pBq â€œ PH
â€œ
pH
J P B
â€°
for all ï¬nite subsets J Ä‚ H, J, H P H, and for all sets B P EJ.
1.14. Theorem (Theorem of Kolmogorov). Let
â£`
EJ, EJ, PJ
Ë˜
: J P H
(
be a
projective system of probability spaces.
Suppose that every space Et is a Ïƒ-
compact metrizable Hausdorï¬€space. Then there exists a unique probability space
`
EI, EI, PI
Ë˜
with the property that for all ï¬nite subsets J P H the equality
PJ pBq â€œ PI rpJ P Bs holds for all B P EJ.
Theorem 5.81 is the same as Theorem 1.14, but formulated for Polish and
Souslin spaces; its proof can be found in Chapter 5. Theorem 1.14 is the same
as Theorem 3.1. The reason that the conclusion in Theorem 1.14 holds for Ïƒ-
compact metrizable topological Hausdorï¬€spaces is the fact that a ï¬nite Borel
measure Âµ on a metrizable Ïƒ-compact space E is regular in the sense that
ÂµpBq â€œ
sup
KÄ‚B, K compact
ÂµpKq â€œ
inf
UÄ„K, U open ÂµpUq,
B any Borel subset E. (1.10)
1.15. Lemma. Let E be a Ïƒ-compact metrizable Hausdorï¬€space.
Then the
equality in (1.10) holds for all Borel subsets B of E.
Proof. The equalities in (1.10) can be deduced by proving that the collec-
tion D deï¬ne by
D â€œ
"
B P BE : sup
KÄ‚B
ÂµpKq â€œ inf
UÄ„B ÂµpUq
*
â€œ
"
B P BE : sup
FÄ‚B
ÂµpFq â€œ inf
UÄ„B ÂµpUq
*
(1.11)
contains the open subsets of E, is closed under taking complements, and is
closed under taking mutually disjoint countable unions. The second equality
holds because every closed subset of E is a countable union of compact subsets.
In (1.11) the sets K are taken from the compact subsets, the sets U from the
open subsets, and the sets F from the closed subsets of E. It is clear that D is
closed under taking complements. Let px, yq ÃÃ‘ dpx, yq be a metric on E which
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
14 
Stochastic processes: prerequisites
is compatible with its topology. Let F be a closed subset of E, and deï¬ne Un
by
Un â€œ
"
x P E : inf
yPF d px, yq Äƒ 1
n
*
.
Then the subset Un is open, Un`1 Ä„ Un, and F â€œ Å Un. It follows that Âµ pFq â€œ
infn Âµ pUnq, and consequently, F belongs to D. In other words the collection D
contains the closed, and so the open subsets of E. Next let pBnqn be a sequence
of subsets in D. Fix Îµ Ä… 0, and choose closed subsets Fn Ä‚ Bn, and open
subsets Un Ä„ Bn, such that
Âµ pBnzFnq Ä Îµ2Â´nÂ´1,
and
Âµ pUnzBnq Ä Îµ2Â´n.
(1.12)
From (1.12) it follows that
Âµ
ËœËœ 8
Ä
nâ€œ1
Un
Â¸
z
Ëœ 8
Ä
nâ€œ1
Bn
Â¸Â¸
Ä Âµ
Ëœ 8
Ä
nâ€œ1
pUnzBnq
Â¸
Ä
8
Ã¿
nâ€œ1
Âµ pUnzBnq Ä Îµ
8
Ã¿
nâ€œ1
2Â´n â€œ Îµ.
(1.13)
From (1.13 it follows that
Âµ
Ëœ 8
Ä
nâ€œ1
Bn
Â¸
â€œ inf
#
ÂµpUq : U Ä„
8
Ä
nâ€œ1
Bn,
U open
+
.
(1.14)
The same argumentation shows that
Âµ
ËœËœ 8
Ä
nâ€œ1
Bn
Â¸
z
Ëœ 8
Ä
nâ€œ1
Fn
Â¸Â¸
Ä
8
Ã¿
nâ€œ1
Âµ pBnzFnq Ä Îµ
8
Ã¿
nâ€œ1
2Â´nÂ´1 â€œ 1
2Îµ.
(1.15)
From (1.15) it follows that
Âµ
ËœËœ 8
Ä
nâ€œ1
Bn
Â¸
z
Ëœ NÎµ
Ä
nâ€œ1
Fn
Â¸Â¸
Ä Îµ
(1.16)
for NÎµ large enough. From (1.16 it follows that
Âµ
Ëœ 8
Ä
nâ€œ1
Bn
Â¸
â€œ sup
#
ÂµpFq : F Ä‚
8
Ä
nâ€œ1
Bn,
F closed
+
.
(1.17)
From (1.14) and (1.17) it follows that Å¤8
nâ€œ1 Bn belongs to D. As already men-
tioned, since every closed subset is the countable union of compact subsets the
supremum over closed subsets in (1.17) may replaced with a supremum over
compact subsets. Altogether, this completes the proof of Lemma 1.15.
â–¡
It is a nice observation that a locally compact Hausdorï¬€space is metrizable and
Ïƒ-compact if and only if it is a Polish space. This is part of Theorem 5.3 (page
29) in Kechris [68]. This theorem reads as follows.
1.16. Theorem. Let E be a locally compact Hausdorï¬€space. The following
assertions are equivalent:
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
15 
Stochastic processes: prerequisites
(1) The space E is second countable, i.e. E has a countable basis for its
topology.
(2) The space E is metrizable and Ïƒ-compact.
(3) The space E has a metrizable one-point compactiï¬cation (or Alexan-
droï¬€compactiï¬cation).
(4) The space E is Polish, i.e. E is complete metrizable and separable.
(5) The space E is homeomorphic to an open subset of a compact metrizable
space.
A second-countable locally-compact Hausdorï¬€space is Polish: let pUiqi be a
countable basis of open subsets with compact closures pKiqi, and let Vi be an
open subset with compact closure and containing Ki. From Urysohnâ€™s Lemma,
let 0 Ä fi Ä 1 be continuous functions identically 0 oï¬€Vi, identically 1 on Ki,
and put
dpx, yq â€œ
8
Ã¿
iâ€œ1
2Â´i |fipxq Â´ fipyq| `
Ë‡Ë‡Ë‡Ë‡
1
Å™8
iâ€œ1 2Â´ifipxq Â´
1
Å™8
iâ€œ1 2Â´ifipyq
Ë‡Ë‡Ë‡Ë‡ ,
x, y P E.
(1.18)
The triangle inequality for the usual absolute value shows that this is a metric.
This metric gives the same topology, and it is straightforward to verify its
completeness. For this argument see Garrett [57].
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
16 
Stochastic processes: prerequisites
4. A deï¬nition of Brownian motion
In this section we give a (preliminary) deï¬nition of Brownian motion.
4.1. Gaussian measures on Rd. For every t Ä… 0 we deï¬ne the Gaussian
kernel on Rd as the function
pd pt, x, yq â€œ
1
p2Ï€tqd{2 exp
Ëœ
Â´|x Â´ y|2
2t
Â¸
.
Then we have
ÅŸ
pd pt, x, zq dz â€œ 1, and
pdps, x, zqppt, z, yq â€œ pdps ` t, x, yqpd
Ë† st
s ` t, sx ` ty
s ` t , z
Ë™
.
Hence the function pd pt, x, yq satisï¬es the equation of Chapman-Kolmogorov:
Å¼
pdps, x, zqpdpt, z, yqdz â€œ pd ps ` t, x, yq .
This property will enable us to consider d-dimensional Brownian motion as a
Markov process. Next we calculate the ï¬nite-dimensional distributions of the
Brownian motion.
4.2. Finite dimensional distributions of Brownian motion. Let 0 Äƒ
t1 Äƒ Â¨ Â¨ Â¨ Äƒ tn Äƒ 8 be a sequence of time instances in p0, 8q, and ï¬x x0 P Rd.
Deï¬ne the probability measure Px0;t1,...,tn on the Borel ï¬eld of Rd Ë† Â¨ Â¨ Â¨ Ë† Rd (n
times) by (t0 â€œ 0)
Px0;t1,...,tn rB1 Ë† Â¨ Â¨ Â¨ Ë† Bns â€œ
Å¼
B1
. . .
Å¼
Bn
dxn . . . dx1
n
Åº
jâ€œ1
pd ptj Â´ tjÂ´1, xjÂ´1, xjq ,
(1.19)
where B1, . . . , Bn are Borel subsets of Rd. Then, with Bk â€œ Rd, we have
Px0;t1,...,tkÂ´1,tk,tk`1,...,tn
â€œ
B1 Ë† Â¨ Â¨ Â¨ Ë† BkÂ´1 Ë† Rd Ë† Bk`1 Ë† Â¨ Â¨ Â¨ Ë† Bn
â€°
â€œ
Å¼
B1
. . .
Å¼
BkÂ´1
Å¼
Rd
Å¼
Bk`1
. . .
Å¼
Bn
dxn . . . dxk`1 dxk dxkÂ´1 . . . dx1
kÂ´1
Åº
jâ€œ1
pd ptj Â´ tjÂ´1, xjÂ´1, xjq
pd ptk Â´ tkÂ´1, xkÂ´1, xkq pd ptk`1 Â´ tk, xk, xk`1q
n
Åº
jâ€œk`2
p ptj Â´ tjÂ´1, xjÂ´1, xjq
(Chapman-Kolmogorov)
â€œ
Å¼
B1
. . .
Å¼
BkÂ´1
Å¼
Bk`1
. . .
Å¼
Bn
dxn . . . dxk`1 dxkÂ´1 . . . dx1
kÂ´1
Åº
jâ€œ1
pd ptj Â´ tjÂ´1, xjÂ´1, xjq
pd ptk`1 Â´ tkÂ´1, xkÂ´1, xk`1q
n
Åº
jâ€œk`2
p ptj Â´ tjÂ´1, xjÂ´1, xjq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
17 
Stochastic processes: prerequisites
â€œ Px0;t1,...,tkÂ´1,tk`1,...,tn rB1 Ë† Â¨ Â¨ Â¨ Ë† BkÂ´1 Ë† Bk`1 Ë† Â¨ Â¨ Â¨ Ë† Bns .
(1.20)
It follows that the family
$
&
%
Â¨
ËRd Ë† Â¨ Â¨ Â¨ Ë† Rd
looooooomooooooon
n times
, Bd b Â¨ Â¨ Â¨ b Bd
looooooomooooooon
n times
, Px0;t1,...,tn
Ë›
â€š; 0 Äƒ t1 Äƒ Â¨ Â¨ Â¨ Äƒ tn Äƒ 8, n P N
,
.
-
is a projective or consistent system. Such families are also called cylindrical
measures. The extension theorem of Kolmogorov implies that in the present
situation a cylindrical measure can be considered as a genuine measure on the
product ï¬eld of â„¦:â€œ
`
RdË˜r0,8q. This is the measure corresponding to Brownian
motion starting at x0. More precisely, the theorem of Kolmogorov says that
there exists a probability space pâ„¦, F, Px0q and state variables Xptq : â„¦Ã‘ Rd,
t Ä› 0, such that
Px0 rX pt1q P B1, . . . , X ptnq P Bns â€œ Px0;t1,...,tn rB1 Ë† Â¨ Â¨ Â¨ Ë† Bns ,
where the subsets Bj, 1 Ä j Ä n, belong to Bd. It is assumed that
Px0 rXp0q â€œ x0s â€œ 1.
5. Martingales and related processes
Let pâ„¦, F, Pq be a probability space, and let tFt : t P Iu be a family of subï¬elds
of F, indexed by a totally ordered index set pI, Äq. Suppose that the family
tFt : t P Iu is increasing in the sense that s Ä t implies Fs Ä Ft. Such a family
of Ïƒ-ï¬elds is called a ï¬ltration. A stochastic process tXptq : t P Iu, where Xptq,
t P I, are mappings from â„¦to Et, is called adapted, or more precisely, adapted
to the ï¬ltration tFt : t P Iu if every Xptq is Ft-Et-measurable. For the Ïƒ-ï¬eld
Ft we often take (some completion of) the Ïƒ-ï¬eld generated by Xpsq, s Ä t:
Ft â€œ Ïƒ tXpsq : s Ä tu.
1.17. Definition. An adapted process tXptq : t P Iu with state space pR, Bq
is called a super-martingale if every variable Xptq is P-integrable, and if s Ä t,
s, t P I, implies E
â€œ
Xptq
Ë‡Ë‡ Fs
â€°
Ä Xpsq, P-almost surely. An adapted process
tXptq : t P Iu with state space pR, Bq is called a sub-martingale if every variable
Xptq is P-integrable, and if s Ä t, s, t P I, implies E
â€œ
Xptq
Ë‡Ë‡ Fs
â€°
Ä› Xpsq, P-
almost surely. If an adapted process is at the same time a super- and a sub-
martingale, then it is called a martingale.
The martingale in the following example is called a closed martingale.
1.18. Example. Let X8 belong to L1 pâ„¦, F, Pq, and let tFt : t P r0, 8qu be a
ï¬ltration in F. Put Xptq â€œ E
â€œ
X8
Ë‡Ë‡ Ft
â€°
, t Ä› 0. Then the process tXptq: t Ä› 0u
is a martingale with respect to the ï¬ltration tFt : t P r0, 8qu.
The following theorem shows that uniformly integrable martingales are closed
martingales.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
18 
Stochastic processes: prerequisites
1.19. Theorem (Doobâ€™s theorem). Any uniformly integrable martingale
tXptq:t Ä› 0u
in L1 pâ„¦, F, Pq
converges P-almost surely and in mean (i.e.
in L1 pâ„¦, F, Pq) to a stochastic
variable X8 such that for every t Ä› 0 the equality Xptq â€œ E
â€œ
X8
Ë‡Ë‡ Ft
â€°
holds
P-almost surely.
Let F be a subset of L1 pâ„¦, F, Pq. Then F is uniformly integrable if for every
Îµ Ä… 0 there exists a function g P L1 pâ„¦, F, Pq such that
ÅŸ
t|f|Ä›|g|u |f| dP Ä Îµ for all
f P F. Since P is a ï¬nite positive measure we may assume that g is a (large)
positive constant.
1.20. Theorem. Sub-martingales constitute a convex cone:
(i) A positive linear combination of sub-martingales is again a sub-martin-
gale; the space of sub-martingales forms a convex cone.
(ii) A convex function of a sub-martingale is a sub-martingale.
Not all martingales are closed, as is shown in the following example.
1.21. Example. Fix t Ä… 0, and x, y P Rd. Let
tpâ„¦, F, Pxq , pXptq, t Ä› 0q , pÏ‘t : t Ä› 0q , pRn, Bnqu
be Brownian motion starting at x P Rd, and put, as above,
pd pt, x, yq â€œ
1
p2Ï€tqd{2 exp
Ëœ
Â´|x Â´ y|2
2t
Â¸
.
The process s ÃÃ‘ p pt Â´ s, Xpsq, yq is Px-martingale on the half-open interval
r0, tq.
5.1. Stopping times. A stochastic variable T : â„¦Ã‘ r0, 8s is called a
stopping time with respect to the ï¬ltration tFt : t Ä› 0u, if for every t Ä› 0 the
event tT Ä tu belongs to Ft. If T is a stopping time, the process t ÃÃ‘ 1rTÄts is
adapted to tFt : t Ä› 0u. The meaning of a stopping is the following one. The
moment T is the time that some phenomena happens. If at a given time t the
information contained in Ft suï¬ƒces to conclude whether or not this phenomena
occurred before time t, then T is a stopping time. Let
tpâ„¦, F, Pxq , pXptq, t Ä› 0q , pÏ‘t : t Ä› 0q , pRn, Bnqu
be Brownian motion starting at x P Rd, let p : Rd Ã‘ p0, 8q be a strictly positive
continuous function, and O an open subset of Rd. The ï¬rst exit time from O,
or the ï¬rst hitting time of the complement of O, deï¬ned by
T â€œ inf
â£
t Ä… 0 : Xptq P RdzO
(
is a (very) relevant stopping time. The time T is a so-called terminal stopping
time: on the event tT Ä… su it satisï¬es s ` T Ë Ï‘s â€œ T. Other relevant stopping
times are:
Ï„Î¾ â€œ inf
"
t Ä… 0 :
Å¼ t
0
p pXpsqq ds Ä… Î¾
*
,
Î¾ Ä› 0.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
19 
Stochastic processes: prerequisites
Such stopping times are used for (stochastic) time change:
Ï„Î¾ ` Ï„Î· Ë Ï‘Ï„Î¾ â€œ Ï„Î¾`Î·,
Î¾,
Î· Ä› 0.
Note that the mapping Î¾ ÃÃ‘ Ï„Î¾ is the inverse of the mapping t ÃÃ‘
ÅŸt
0 p pXpsqq ds.
Also note the equality: tÏ„Î¾ Äƒ tu â€œ
!ÅŸt
0 p pXpsqq Ä… Î¾
)
,
ÅŸ8
0 p pXpsqq ds Ä… Î¾ Ä… 0.
The mapping Î¾ ÃÃ‘ Ï„Î¾ is strictly increasing from the interval
â€œ
0,
ÅŸ8
0 p pXpsqq ds
Ë˜
onto r0, 8q. Arbitrary stopping times T are often approximated by â€œdiscreteâ€
stopping times: T â€œ limnÃ‘8 Tn, where Tn â€œ 2Â´n r2nTs. Notice that T Ä Tn`1 Ä
Tn Ä T ` 2Â´n, and that tTn â€œ k2Â´nu â€œ tpk Â´ 1q2Â´n Äƒ T Ä k2Â´nu, k P N.
1.22. Theorem. Let pâ„¦, F, Pq be a probability space, and let tFt : t Ä› 0u be a
ï¬ltration in F. The following assertions hold true:
(1) constant times are stopping times: for every t Ä› 0 ï¬xed the time T â€ t
is a stopping time;
(2) if S and T are stopping times, then so are min pS, Tq and max pS, Tq;
(3) If T is a stopping time, then the collection FT deï¬ned by
FT â€œ tA P F : A X tT Ä ts P Ft, for all t Ä› 0u
is a subï¬eld of F;
(4) If S and T are stopping times, then S`T ËÏ‘S is a stopping time as well,
provided the paths of the process are P-almost surely right-continuous
and the same is true for the ï¬ltration tFt : t Ä› 0u.
The ï¬ltration tFt : t Ä› 0u is right-continuous if Ft â€œ Å
sÄ…t Fs, t Ä› 0. The (sam-
ple) paths t ÃÃ‘ Xptq are said to be P-almost surely right-continuous, provided
for all t Ä› 0 we have Xptq â€œ limsÃ“t Xpsq, P-almost surely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
20 
Stochastic processes: prerequisites
The following theorem shows that in many cases ï¬xed times can be replaced
with stopping times. In particular this is true if we study (right-continuous)
sub-martingales, super-martingales or martingales.
1.23. Theorem (Doobâ€™s optional sampling theorem). Let pXptq : t Ä› 0q be a
uniformly integrable process in L1 pâ„¦, F, Pq which is a sub-martingale with re-
spect to the ï¬ltration pFt : t Ä› 0q. Let S and T be stopping times such that
S Ä T. Then E
â€œ
XpTq
Ë‡Ë‡ FS
â€°
Ä› XpSq, P-almost surely.
Similar statements hold for super-martingales and martingales.
Notice that XpTq stands for the stochastic variable Ï‰ ÃÃ‘ X pTpÏ‰qq pÏ‰q â€œ
X pTpÏ‰q, Ï‰q.
We conclude this introduction with a statement of the decomposition theorem
of Doob-Meyer. A process tXptq : t Ä› 0u is of class (DL) if for every t Ä… 0 the
family
tXpÏ„q : 0 Ä Ï„ Ä t, Ï„ is an pFtq -stopping timeu
is uniformly integrable. An Ft-martingale tMptq : t Ä› 0u is of class (DL), an
increasing adapted process tAptq : t Ä› 0u in L1pâ„¦, F, Pq is of class (DL) and
hence the sum tMptq ` Aptq : t Ä› 0u is of class (DL). If tXptq : t Ä› 0u is a
submartingale and if Âµ is a real number, then the process tmax pXptq, Âµq : t Ä› 0u
is a sub-martingale of class (DL). Processes of class (DL) are important in the
Doob-Meyer decomposition theorem. Let pâ„¦, F, Pq be a probability space, let
tFt : t Ä› 0u be a right-continuous ï¬ltration in F and let tXptq : t Ä› 0u be right
continuous sub-martingale of class (DL) which possesses almost sure left limits.
We mention the following version of the Doob-Meyer decomposition theorem.
See Remark 3.54 as well.
1.24. Theorem. Let tXptq : t Ä› 0u be a sub-martingale of class (DL) which
has P almost surely left limits, and which is right-continuous. Then there ex-
ists a unique predictable right continuous increasing process tAptq : t Ä› 0u with
Ap0q â€œ 0 such that the process tXptq Â´ Aptq : t Ä› 0u is an Ft-martingale.
A process pÏ‰, tq ÃÃ‘ XptqpÏ‰q â€œ X pt, Ï‰q is predictable if it is measurable with
respect to the Ïƒ-ï¬eld generated by tA Ë† pa, bs : A P Fa, a Äƒ bu. For more details
on c`adl`ag sub-martingales, see Theorem 3.77. The following proposition says
that a non-negative right-continuous sub-martingale is of class (DL).
1.25. Proposition. Let pâ„¦, F, Pq be a probability space, let pFtqtÄ›0 be a ï¬ltration
of Ïƒ-ï¬elds contained in F. Suppose that t ÃÃ‘ Xptq is a right-continuous sub-
martingale relative to the ï¬ltration pFtqtÄ›0 attaining its values in r0, 8q. Then
the family tXptq : t Ä› 0u is of class (DL).
In fact it suï¬ƒces to assume that there exists a real number m such that Xptq Ä›
Â´m P-almost surely. This follows from Proposition 1.25 by considering Xptq`m
instead of Xptq.
If t ÃÃ‘ Mptq is a continuous martingale in L2 pâ„¦, F, Pq, then t ÃÃ‘ |Mptq|2 is a
non-negative sub-martingale, and so it splits as the sum of a martingale t ÃÃ‘
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
21 
Stochastic processes: prerequisites
|Mptq|2 Â´âŸ¨M, MâŸ©ptq and an increasing process t ÃÃ‘ âŸ¨M Äƒ MâŸ©ptq, the quadratic
variation process of Mptq.
Proof of Proposition 1.25. Fix t Ä… 0, and let Ï„ : â„¦Ã‘ r0, ts be a
stopping time. Let for m P N the stopping time Ï„m : â„¦Ã‘ r0, 8s be deï¬ned by
Ï„m â€œ inf ts Ä… 0 : Xpsq Ä… mu if Xpsq Ä… m for some s Äƒ 8, otherwise Ï„m â€œ 8.
Then the event tXpÏ„q Ä… mu is contained in the event tÏ„m Ä Ï„u. Hence,
E rXpÏ„q : XpÏ„q Ä… ms Ä E rXptq : XpÏ„q Ä… ms Ä E rXptq : Ï„m Ä Ï„s
Ä E rXptq : Ï„m Ä ts .
(1.21)
Since, P-almost surely, Ï„m Ã’ 8 for m Ã‘ 8, it follows that
lim
mÃ‘8 sup tE rXpÏ„q : XpÏ„q Ä… ms : Ï„ P r0, ts : Ï„ stopping timeu â€œ 0.
Consequently, the sub-martingale t ÃÃ‘ Xptq is of class (DL). The proof of Propo-
sition 1.25 is complete now.
â–¡
It is perhaps useful to insert the following proposition.
1.26. Proposition. Processes of the form Mptq`Aptq, with Mptq a martingale
and with Aptq an increasing process in L1 pâ„¦, F, Pq are of class (DL).
Proof. Let tXptq â€œ Mptq ` Aptq : t Ä› 0u be the decomposition of the
sub-martingale tXptq : t Ä› 0u in a martingale tMptq : t Ä› 0u and an increasing
process tAptq : t Ä› 0u with Ap0q â€œ 0 and 0 Ä Ï„ Ä t be any Ft-stopping time.
Here t is some ï¬xed time. For N P N we have
E p|XpÏ„q| : |XpÏ„q| Ä› Nq Ä E p|MpÏ„q| : |XpÏ„q| Ä› Nq ` E pApÏ„q : |XpÏ„q| Ä› Nq
Ä E p|Mptq| : |XpÏ„q| Ä› Nq ` E pApÏ„q : |XpÏ„q| Ä› Nq
Ä E p|Mptq| ` Aptq : |XpÏ„q| Ä› Nq
Ä E
Ë†
|Mptq| ` Aptq : sup
0ÄsÄt |Xpsq| Ä› N
Ë™
.
Since, by the Doobâ€™s maximality theorem 1.28,
NP
"
sup
0ÄsÄt |Xpsq| Ä› N
*
Ä NP
"
sup
0ÄsÄt |Mpsq| Ä› N
2
*
` NP
"
sup
0ÄsÄt Apsq Ä› N
2
*
Ä 2E p|Mptq| ` Aptqq ,
it follows that
lim
NÃ‘8 sup tE p|XpÏ„q| : |XpÏ„q| Ä› Nq : 0 Ä Ï„ Ä t, Ï„ stopping timeu â€œ 0.
This proves Proposition 1.26.
â–¡
First we formulate and prove Doobâ€™s maximal inequality for time-discrete sub-
martingales.
In Theorem 1.27 the sequence i ÃÃ‘ Xi is deï¬ned on a ï¬ltered
probability space pâ„¦, Fi.PqiPN, and in Theorem 1.28 the process t ÃÃ‘ Xptq is
deï¬ned on a ï¬ltered probability space pâ„¦, Ft.PqtÄ›0.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
22 
Stochastic processes: prerequisites
1.27. Theorem (Doobâ€™s maximal inequality). Let pXiqiPN be a sub-martingale
w.r.t. a ï¬ltration pFiqiPN. Let Sn â€œ max1ÄiÄn Xi be the running maximum of
Xi. Then for any â„“Ä… 0,
P rSn Ä› â„“s Ä 1
â„“E
â€œ
X`
n 1tSnÄ›â„“u
â€°
Ä 1
â„“E
â€œ
X`
n
â€°
,
(1.22)
where X`
n â€œ Xn _ 0. In particular, if Xi is a martingale and Mn â€œ max
1ÄiÄn |Xi|,
then
P rMn Ä› â„“s Ä 1
â„“E
â€œ
|Xn| 1tMnÄ›â„“u
â€°
Ä 1
â„“E r|Xn|s .
(1.23)
Proof. Let Ï„â„“â€œ inf ti Ä› 1 : Xi Ä› â„“u. Then P rSn Ä› â„“s â€œ Å™n
iâ€œ1 P rÏ„â„“â€œ is.
For each 1 Ä i Ä n,
P rÏ„â„“â€œ is â€œ E
â€œ
1tXiÄ›â„“u1tÏ„â„“â€œiu
â€°
Ä 1
â„“E
â€œ
X`
i 1tÏ„â„“â€œiu
â€°
.
(1.24)
Note that tÏ„â„“â€œ iu P Fi, and X`
i
is a sub-martingale because Xi itself is a
sub-martingale while Ï†pxq â€œ x` â€œ x _ 0 â€œ maxpx, 0q is an increasing convex
function. Therefore
E
â€œ
X`
n 1tÏ„â„“â€œiu
Ë‡Ë‡ Fi
â€°
â€œ 1tÏ„â„“â€œiuE
â€œ
X`
n
Ë‡Ë‡ Fi
â€°
Ä› 1tÏ„â„“â€œiu
`
E
â€œ
Xn
Ë‡Ë‡ Fi
â€°Ë˜` Ä› 1tÏ„â„“â€œiuX`
i ,
and hence E
â€œ
X`
i 1tÏ„â„“â€œiu
â€°
Ä E
â€œ
X`
n 1tÏ„â„“â€œiu
â€°
.
Substituting this inequality into
(1.24) and then summing over 1 Ä i Ä n then yields (1.22). The inequality in
(1.23) follows by applying (1.22 to the sub-martingale |Xi|.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
â–¶â–¶enroll by September 30th, 2014 and 
â–¶â–¶save up to 16% on the tuition!
â–¶â–¶pay in 10 installments / 2 years
â–¶â–¶Interactive Online education
â–¶â–¶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
23 
Stochastic processes: prerequisites
Next we formulate and prove Doobâ€™s maximal inequality for continuous time
sub-martingales.
1.28. Theorem (Doobâ€™s maximal inequality). Let pXptqqtÄ›0 be a sub-martingale
w.r.t. a ï¬ltration pFtqtÄ›0. Let Sptq â€œ sup0ÄsÄt Xpsq be the running maximum
of Xptq. Suppose that the process t ÃÃ‘ Xptq is P-almost surely continuous from
the right (and possesses left limits P-almost surely). Then for any â„“Ä… 0,
P rSptq Ä› â„“s Ä 1
â„“E
â€œ
Xptq`1tSptqÄ›â„“u
â€°
Ä 1
â„“E
â€œ
X`ptq
â€°
,
(1.25)
where X`ptq â€œ Xptq _ 0 â€œ max pXptq, 0q.
In particular, if t ÃÃ‘ Xptq is a
martingale and Mptq â€œ sup
0ÄsÄt |Xptq|, then
P rMptq Ä› â„“s Ä 1
â„“E
â€œ
|Xptq| 1tMptqÄ›â„“u
â€°
Ä 1
â„“E r|Xptq|s .
(1.26)
Proof. Let, for every N P N, Ï„N be the pFtqtÄ›0-stopping time deï¬ned
by Ï„N â€œ inf tt Ä… 0 : Xptq` Ä› Nu. In addition deï¬ne the double sequence of
processes Xn.Nptq by
Xn,Nptq â€œ X
`
2Â´n r2nts ^ Ï„N
Ë˜
.
Theorem 1.28 follows from Theorem 1.27 by applying it the processes t ÃÃ‘
Xn,Nptq, n P N, N P N. As a consequence of Theorem 1.27 we see that Theorem
1.28 is true for the double sequence t ÃÃ‘ Xn,Nptq, because, essentially speaking,
these processes are discrete-time processes with the property that the processes
pn, tq ÃÃ‘ Xn,Nptq` attain P-almost surely their values in the interval r0, Ns.
Then we let n Ã‘ 8 to obtain Theorem 1.28 for the processes t ÃÃ‘ X pt ^ Ï„Nq,
N P N. Finally we let N Ã‘ 8 to obtain the full result in Theorem 1.28.
â–¡
5.2. Additive processes. In this ï¬nal section we introduce the notion
of additive and multiplicative processes. Let E be a second countable locally
compact Hausdorï¬€space. In the non-time-homogeneous case we consider real-
valued processes which depend on two time parameters: pt1, t2q ÃÃ‘ Z pt1, t2q,
0 Ä t1 Ä t2 Ä T. It is assumed that for all 0 Ä t1 Ä t2 Ä T, the variable
Z pt1, t2q only depends, or is measurable with respect to, Ïƒ tXpsq : t1 Ä s Ä t2u.
Such a process is called additive if
Z pt1, t2q â€œ Z pt1, tq ` Z pt, t2q ,
t1 Ä t Ä t2.
The process Z is called multiplicative if
Z pt1, t2q â€œ Z pt1, tq Â¨ Z pt, t2q ,
t1 Ä t Ä t2.
Let p : r0, Ts Ë† E Ã‘ R be a continuous function, and let tXptq : 0 Ä t Ä Tu be
an E-valued process which has left limits in E, and which is right-continuous
(i.e. it is c`adl`ag). Put Z pt1, t2q â€œ
ÅŸt2
t1 p ps, Xpsqq ds. Then the process pt1, t2q ÃÃ‘
Z pt1, t2q, 0 Ä t1 Ä t2 Ä T is additive, and the process pt1, t2q ÃÃ‘ exp pZ pt1, t2qq,
0 Ä t1 Ä t2 Ä T, is multiplicative.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
24 
Stochastic processes: prerequisites
Next we consider the particular case that we deal with time-homogeneous pro-
cesses like Brownian motion:
tpâ„¦, F, Pxq , pXptq, t Ä› 0q , pÏ‘t : t Ä› 0q , pRn, Bnqu ,
which represents Brownian motion starting at x P Rd.
An adapted process
t ÃÃ‘ Zptq is called additive if Z ps ` tq â€œ Z psq ` Z ptq Ë Ï‘s, Px-almost surely,
for all s, t Ä› 0. It is called multiplicative provided Z ps ` tq â€œ Z psq Â¨ Z ptq Ë Ï‘s,
Px-almost surely, for all s, t Ä› 0. Examples of additive processes are integrals
of the form Zptq â€œ
ÅŸt2
0 p pXpsqq ds, where x ÃÃ‘ ppxq is a continuous (or Borel)
function on Rd, or stochastic integrals (ItË†o, Stratonovich integrals) of the form
Zptq â€œ
ÅŸt
0 p pXpsqq dXpsq. Such integrals have to be interpreted in some L2-
sense.
More details will be given in Section 6.
If t ÃÃ‘ Zptq is an additive
process, then its exponent t ÃÃ‘ exp pZptqq is a multiplicative process. If T is a
terminal stopping time, then the process t ÃÃ‘ 1tTÄ…tu is a multiplicative process.
Let pXnqnPN be a sequence of non-negative i.i.d. random variables each of which
has density f1 Ä› 0.
Suppose that fn is the density of the distribution of
Å™n
jâ€œ1 Xj.
Note â€œi.i.d.â€
means â€œindependent, identically distributedâ€.
Then
P
Â« nÃ¿
jâ€œ1
Xj Ä t
ï¬€
â€œ
Å¼ t
0
fnpsqds, and hence
Å¼ t
0
fn`1psqds â€œ P
Â«n`1
Ã¿
jâ€œ1
Xj Ä t
ï¬€
â€œ P
Â« nÃ¿
jâ€œ1
Xj ` Xn`1 Ä t
ï¬€
â€œ
Å¼ t
0
fnpÏqf1pt Â´ ÏqdÏ.
It follows that
Å¼ t
0
fnpsqds Â´
Å¼ t
0
fn`1pÏqdÏ â€œ
Å¼ t
0
fnpsqds Â´
Å¼ t
0
Å¼ Ï
0
fnpsqf1pÏ Â´ sqds dÏ
â€œ
Å¼ t
0
fnpsqds Â´
Å¼ t
0
fnpsq
Å¼ t
s
f1pÏ Â´ sqdÏ ds
â€œ
Å¼ t
0
fnpsq
Ë†
1 Â´
Å¼ t
s
f1pÏ Â´ sqdÏ
Ë™
ds
â€œ
Å¼ t
0
fnpsq
Å¼ 8
t
f1pÏ Â´ sqdÏ ds
â€œ
Å¼ t
0
fnpsq
Å¼ 8
tÂ´s
f1pÏqdÏ ds.
(1.27)
If f1psq â€œ Î»eÂ´Î»s, then fnpsq â€œ Î»nsnÂ´1
pn Â´ 1q!eÂ´Î»s. This follows by induction.
5.3. Continuous time discrete processes. Here we suppose that the
process
tpâ„¦, F, Pq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pS, Squ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
25 
Stochastic processes: prerequisites
is governed by a time-homogeneous or stationary transition probabilities:
pj,iptq â€œ P
â€œ
Xptq â€œ j
Ë‡Ë‡ Xp0q â€œ i
â€°
â€œ P
â€œ
Xpt ` sq â€œ j
Ë‡Ë‡ Xpsq â€œ i
â€°
,
i, j P S,
(1.28)
for all s Ä› 0. Here, S is a discrete state space, e.g. S â€œ Z, S â€œ Zn, S â€œ N, or
S â€œ t0, Nu. The measurable space pâ„¦, Fq is called the sample or sample path
space. Its elements Ï‰ P â„¦are called realizations. The mappings Xptq : â„¦Ã‘ S
are called the state variables; the application t ÃÃ‘ XptqpÏ‰q is called a sample
path or realization. The translation operators Ï‘t, t Ä› 0, are mappings from
â„¦to â„¦with the property that: Xpsq Ë Ï‘t â€œ Xps ` tq, P-almost surely. For
the time being these operators will not be used; they are very convenient to
express the Markov property in the time-homogeneous case. We assume that
the Chapman-Kolmogorov conditions are satisï¬ed:
pj,i ps ` tq â€œ
Ã¿
kPS
pj,kpsqpk,iptq, i, j P S, s, t Ä› 0.
(1.29)
In fact the Markov property is a consequence of the Chapman-Kolmogorov
identity (1.29). From the Chapman-Kolmogorov (1.29) the following important
identity follows:
P ps ` tq â€œ PpsqPptq,
s, t Ä› 0.
(1.30)
The identity in (1.30) is called the semigroup property; the identity has to be
interpreted as matrix multiplication. Suppose that the functions t ÃÃ‘ pj,iptq, j,
i P S, are right diï¬€erentiable at t â€œ 0. The latter means that the following
limits exist:
qj,i â€œ lim
â–³Ã“0
pj,i pâ–³q Â´ pj,ip0q
â–³
,
i, j P S.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
26 
Stochastic processes: prerequisites
We assume that pj,ip0q â€œ Î´j,i, where Î´j,i is the Dirac delta function: Î´j,i â€œ 0 if
j â€° i, and Î´j,j â€œ 1. Put Q â€œ pqj,iqi,jPS. Then the matrix Q is a Kolmogorov
matrix in the sense that qj,i Ä› 0 for j â€° i and Å™
jPS qj,i â€œ 0. It follows that
qi,i â€œ Â´ Å™
jPS,jâ€°i qj,i Ä 0. The reason that the oï¬€-diagonal entries qj,i, j â€° i, are
non-negative is due to the fact that for j â€° i we have
qj,i â€œ lim
tÃ“0
pj,iptq Â´ pj,ip0q
t
â€œ lim
tÃ“0
pj,iptq Â´ Î´j,ip0q
t
â€œ lim
tÃ“0
pj,iptq
t
Ä› 0.
In addition, we have
Ã¿
jPS
qj,i â€œ
Ã¿
jPS
lim
tÃ“0
pj,iptq Â´ pj,ip0q
t
â€œ lim
tÃ“0
Ã¿
jPS
pj,iptq Â´ pj,ip0q
t
â€œ lim
tÃ“0
Å™
jPS pj,iptq Â´ Å™
jPS pj,ip0q
t
â€œ lim
tÃ“0
1 Â´ 1
t
â€œ 0,
(1.31)
provided we may interchange the summation and the limit. Finally we have the
following general fact. Let t ÃÃ‘ Pptq be the matrix function t ÃÃ‘ ppj,iptqqi,jPS.
Then Pptq satisï¬es the Kolmogorov backward and forward diï¬€erential equation:
dPptq
dt
â€œ QPptq â€œ PptqQ,
t Ä› 0.
(1.32)
The ï¬rst equality in (1.32) is called the Kolmogorov forward equation, and the
second one the Kolmogorov backward equation. The solution of this matrix-
valued diï¬€erential equation is given by Pptq â€œ etQPp0q.
But since Pp0q â€œ
ppj,ip0qqj,iPS â€œ pÎ´j,iqi,jPS is the identity matrix, it follows that Pptq â€œ etQ. The
equalities in (1.32) hold true, because by the semigroup property (1.30) we have:
P pt ` â–³ptqq Â´ P ptq
â–³ptq
â€œ P pâ–³ptqq Â´ Pp0q
â–³ptq
P ptq â€œ P ptq P pâ–³ptqq Â´ Pp0q
â–³ptq
. (1.33)
Then we let â–³ptq tend to 0 in (1.33) to obtain (1.32).
5.4. Poisson process. We begin with a formal deï¬nition.
1.29. Definition. A Poisson process
tpâ„¦, F, Pq , pXptq, t Ä› 0q , pÏ‘t, t Ä› 0q , pN, Nqu
(see (1.46) below) is a continuous time process Xptq, t Ä› 0, with values in
N â€œ t0, 1, . . .u which possesses the following properties:
(a) For âˆ†t Ä… 0 suï¬ƒciently small the transition probabilities satisfy:
pi`1,ipâˆ†tq â€œ P
â€œ
X pt ` âˆ†tq â€œ i ` 1
Ë‡Ë‡ Xptq â€œ i
â€°
â€œ Î»âˆ†t ` o pâˆ†tq ;
pi,ipâˆ†tq â€œ P
â€œ
X pt ` âˆ†tq â€œ i
Ë‡Ë‡ Xptq â€œ i
â€°
â€œ 1 Â´ Î»âˆ†t ` o pâˆ†tq ;
pj,ipâˆ†tq â€œ P
â€œ
X pt ` âˆ†tq â€œ j
Ë‡Ë‡ Xptq â€œ i
â€°
â€œ o pâˆ†tq ;
pj,ipâˆ†tq â€œ 0,
j Äƒ i.
(1.34)
(b) The probability transitions ps, i; t, jq ÃÃ‘ P
â€œ
X ptq â€œ j
Ë‡Ë‡ Xpsq â€œ i
â€°
, t Ä… s,
only depend on t Â´ s and j Â´ i.
(c) The process tXptq : t Ä› 0u has the Markov property.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
27 
Stochastic processes: prerequisites
Item (b) says that the Poisson process is homogeneous in time and in space: (b)
is implicitly used in (a). Note that a Poisson process is not continuous, because
when it moves it makes a jump. Put
piptq â€œ pi0ptq â€œ pj`i,jptq â€œ P
â€œ
Xptq â€œ j ` i
Ë‡Ë‡ Xp0q â€œ i
â€°
,
i, j P N.
(1.35)
1.30. Proposition. Let the process
tpâ„¦, F, Pq , pXptq, t Ä› 0q , pÏ‘t, t Ä› 0q , pN, Nqu
possess properties (a) and (b) in Deï¬nition 1.29. Then the following equality
holds for all t Ä› 0 and i P N:
piptq â€œ pÎ»tqi
i! eÂ´Î»t.
(1.36)
1.31. Remark. It is noticed that the equalities in (1.42), (1.40), and (1.44) only
depend on properties (a) and (b) in Deï¬nition 1.29. So that from (a), and (b)
we obtain
d
dtpiptq ` Î»piptq â€œ Î» pÎ»tqiÂ´1
pi Â´ 1q!eÂ´Î»t â€œ Î»piÂ´1ptq,
i Ä› 1,
(1.37)
and hence
pj,iptq â€œ pjÂ´iptq â€œ P
â€œ
Xptq â€œ j
Ë‡Ë‡ Xp0q â€œ i
â€°
â€œ pÎ»tqjÂ´i
pj Â´ iq!eÂ´Î»t,
j Ä› i.
(1.38)
If 0 Ä j Äƒ i, then pj,iptq â€œ 0.
Proof. By deï¬nition we see that pjp0q â€œ P
â€œ
Xp0q â€œ j
Ë‡Ë‡ Xp0q â€œ 0
â€°
â€œ Î´0,j,
and so p0p0q â€œ 1 and pjp0q â€œ 0 for j â€° 0. Let us ï¬rst prove that the functions
t ÃÃ‘ piptq, i Ä› 1, satisfy the diï¬€erential equation in (1.45) below. First suppose
that i Ä› 2, and we consider:
pi pt ` âˆ†tq Â´ piptq â€œ P rX pt ` âˆ†tq â€œ is Â´ piptq
â€œ
iÃ¿
kâ€œ0
P rX pt ` âˆ†tq â€œ i, Xptq â€œ ks Â´ piptq
â€œ
iÃ¿
kâ€œ0
P
â€œ
X pt ` âˆ†tq â€œ i
Ë‡Ë‡ Xptq â€œ k
â€°
P rXptq â€œ ks Â´ piptq
â€œ P
â€œ
X pt ` âˆ†tq â€œ i
Ë‡Ë‡Xptq â€œ i
â€°
piptq ` P
â€œ
X pt ` âˆ†tq â€œ i
Ë‡Ë‡Xptq â€œ i Â´ 1
â€°
piÂ´1ptq
`
iÂ´2
Ã¿
kâ€œ0
P
â€œ
X pt ` âˆ†tq â€œ i
Ë‡Ë‡ Xptq â€œ k
â€°
pkptq Â´ piptq
â€œ p1 Â´ Î»âˆ†t ` o pâˆ†tqq piptq ` pÎ»âˆ†t ` o pâˆ†tqq piÂ´1ptq `
iÂ´2
Ã¿
kâ€œ0
pkptqo pâˆ†tq Â´ piptq
â€œ Â´Î»âˆ†tpiptq ` Î»âˆ†tpiÂ´1ptq `
iÃ¿
kâ€œ0
pkptqo pâˆ†tq .
(1.39)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
28 
Stochastic processes: prerequisites
From (1.39) we obtain
d
dtpiptq â€œ Â´Î»piptq ` Î»piÂ´1ptq.
(1.40)
Next we consider i â€œ 0:
p0 pt ` âˆ†tq Â´ p0ptq â€œ P rX pt ` âˆ†tq â€œ 0s Â´ p0ptq
â€œ P
â€œ
X pt ` âˆ†tq â€œ 0
Ë‡Ë‡ Xptq â€œ 0
â€°
P rXptq â€œ 0s Â´ p0ptq
â€œ P
â€œ
X pt ` âˆ†tq â€œ 0
Ë‡Ë‡ Xptq â€œ 0
â€°
p0ptq Â´ p0ptq â€œ pÂ´Î»âˆ†t ` o pâˆ†tqq p0ptq. (1.41)
From (1.41) we get the equation
d
dtp0ptq â€œ Â´Î»p0ptq.
(1.42)
For i â€œ 1 we have:
p1 pt ` âˆ†tq Â´ p1ptq â€œ P rX pt ` âˆ†tq â€œ 1s Â´ p1ptq
â€œ P
â€œ
X pt ` âˆ†tq â€œ 1
Ë‡Ë‡ Xptq â€œ 1
â€°
P rXptq â€œ 1s Â´ p1ptq
` P
â€œ
X pt ` âˆ†tq â€œ 1
Ë‡Ë‡ Xptq â€œ 0
â€°
P rXptq â€œ 0s
â€œ P
â€œ
X pt ` âˆ†tq â€œ 1
Ë‡Ë‡ Xptq â€œ 1
â€°
p1ptq Â´ p1ptq
` P
â€œ
X pt ` âˆ†tq â€œ 1
Ë‡Ë‡ Xptq â€œ 0
â€°
p0ptq
â€œ pÂ´Î»âˆ†t ` o pâˆ†tqq p1ptq ` pÎ»âˆ†t ` o pâˆ†tqq p0ptq.
(1.43)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
29 
Stochastic processes: prerequisites
From (1.43) we obtain:
d
dtp1ptq â€œ Â´Î»p1ptq ` Î»p0ptq.
(1.44)
By deï¬nition we see that pjp0q â€œ P
â€œ
Xp0q â€œ j
Ë‡Ë‡ Xp0q â€œ 0
â€°
â€œ Î´0,j, and so p0p0q â€œ
1 and pjp0q â€œ 0 for j â€° 0. From (1.42) we get p0ptq â€œ eÂ´Î»t. From (1.40) and
(1.44) we obtain
d
dt
`
eÎ»tpiptq
Ë˜
â€œ Î»eÎ»tpiÂ´1ptq,
i Ä› 1.
(1.45)
By induction it follows that piptq â€œ pÎ»tqi
i! eÂ´Î»t.
This completes the proof of
Proposition 1.30.
â–¡
In the Proposition 1.33 below we show that a process
tpâ„¦, F, Pq , pXptq, t Ä› 0q , pÏ‘t, t Ä› 0q , pN, Nqu
(1.46)
which satisï¬es (a) and (b) of Deï¬nition 1.29 is a time-homogeneous Markov
process if and only if its increments are P-independent. First we prove a lemma,
which is of independent interest.
1.32. Lemma. Let the functions piptq be deï¬ned as in (1.35). Then the equality
piptq â€œ P rXps ` tq Â´ Xpsq â€œ is
(1.47)
holds for all i P N and all s, t Ä› 0.
Proof. Using the space and time invariance properties of the process Xptq
shows:
P rXps ` tq Â´ Xpsq â€œ is â€œ
8
Ã¿
kâ€œ0
P rX ps ` tq Â´ Xpsq â€œ i, Xpsq â€œ ks
â€œ
8
Ã¿
kâ€œ0
P rX ps ` tq â€œ i ` k, Xpsq â€œ ks
â€œ
8
Ã¿
kâ€œ0
P
â€œ
X ps ` tq â€œ i ` k
Ë‡Ë‡ Xpsq â€œ k
â€°
P rXpsq â€œ ks
(space and time invariance properties of piptq)
â€œ
8
Ã¿
kâ€œ0
piptqP rXpsq â€œ ks â€œ piptq.
(1.48)
The conclusion in Lemma 1.32 follows from (1.48).
â–¡
The following proposition says that a time and space-homogeneous process sat-
isfying the equalities in (1.34) of Deï¬nition 1.29 is a Poisson process if and only
if its increments are P-independent.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
30 
Stochastic processes: prerequisites
1.33. Proposition. The process tXptq : t Ä› 0u possessing properties (a) and
(b) of Deï¬nition 1.29 possesses the Markov property if and only if its increments
are P-independent. Moreover, the equalities
P rXptq Â´ Xpsq â€œ j Â´ is â€œ P
â€œ
Xptq â€œ j
Ë‡Ë‡ Xpsq â€œ i
â€°
â€œ pjÂ´ipt Â´ sq â€œ pÎ»pt Â´ sqqjÂ´i
pj Â´ iq!
eÂ´Î»ptÂ´sq
(1.49)
hold for all t Ä› s Ä› 0 and for all j Ä› i, i, j P N.
Proof. First assume that the process in (1.46) has the Markov property.
Let tn`1 Ä… tn Ä… Â¨ Â¨ Â¨ Ä… t1 Ä… t0 â€œ 0, and let ik, 1 Ä k Ä n ` 1, be nonnegative
integers. Then by induction we have
P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n ` 1s
â€œ
8
Ã¿
kâ€œ0
P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n ` 1, X ptnq â€œ ks
â€œ
8
Ã¿
kâ€œ0
P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n ` 1, X ptnq â€œ ks
P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n, X ptnq â€œ ks
Ë† P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n, X ptnq â€œ ks
â€œ
8
Ã¿
kâ€œ0
P
â€œ
X ptn`1q Â´ X ptnq â€œ in`1
Ë‡Ë‡ X ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, X ptnq â€œ k,
1 Ä â„“Ä ns
Ë† P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, X ptnq â€œ k, 1 Ä â„“Ä n, s
(Markov property)
â€œ
8
Ã¿
kâ€œ0
P
â€œ
X ptn`1q Â´ X ptnq â€œ in`1
Ë‡Ë‡ X ptnq â€œ k
â€°
Ë† P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n, X ptnq â€œ ks
â€œ
8
Ã¿
kâ€œ0
P
â€œ
X ptn`1q â€œ in`1 ` k
Ë‡Ë‡ X ptnq â€œ k
â€°
Ë† P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n, X ptnq â€œ ks
(homogeneity in space and time of the function t ÃÃ‘ pin`1ptq)
â€œ
8
Ã¿
kâ€œ0
pin`1 ptn`1 Â´ tnq P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n, X ptnq â€œ ks
(apply equality (1.47) in Lemma 1.29)
â€œ
8
Ã¿
kâ€œ0
P rX ptn`1q Â´ X ptnq â€œ in`1s
P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä n, X ptnq â€œ ks
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
31 
Stochastic processes: prerequisites
â€œ P rX ptn`1q Â´ X ptnq â€œ in`1s P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä ns .
(1.50)
By induction and employing (1.50) it follows that
P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“, 1 Ä â„“Ä ns â€œ
n
Åº
â„“â€œ1
P rX ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“s
â€œ
n
Åº
â„“â€œ1
piâ„“ptâ„“Â´ tâ„“Â´1q .
(1.51)
We still have to prove the converse statement, i.e. to prove that if the increments
of the process Xptq are P-independent, then the process Xptq has the Markov
property. Therefore we take states 0 â€œ i0, i1, . . . , in, in`1, and times 0 â€œ t0 Äƒ
t1 Äƒ Â¨ Â¨ Â¨ Äƒ tn Äƒ tn`1, and we consider the conditional probability:
P
â€œ
X ptn`1q â€œ in`1
Ë‡Ë‡ X pt0q â€œ i0, . . . , X ptnq â€œ in
â€°
â€œ P rX ptn`1q â€œ in`1, X pt0q â€œ i0, . . . , X ptnq â€œ ins
P rX pt0q â€œ i0, . . . , X ptnq â€œ ins
â€œ P rX pt0q â€œ i0, X ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“Â´ iâ„“Â´1, 1 Ä â„“Ä n ` 1s
P rX pt0q â€œ i0, X ptâ„“q Â´ X ptâ„“Â´1q â€œ iâ„“Â´ iâ„“Â´1, 1 Ä â„“Ä ns
(increments are P-independent)
â€œ P rX ptn`1q Â´ X ptnq â€œ in`1 Â´ ins
â€œ P
â€œ
X ptn`1q â€œ in`1
Ë‡Ë‡ X ptnq â€œ in
â€°
.
(1.52)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Masterâ€™s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top masterâ€™s programmes
â€¢ 33rd place Financial Times worldwide ranking: MSc 
International Business
â€¢ 1st place: MSc International Business
â€¢ 1st place: MSc Financial Economics
â€¢ 2nd place: MSc Management of Learning
â€¢ 2nd place: MSc Economics
â€¢ 2nd place: MSc Econometrics and Operations Research
â€¢ 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier â€˜Beste Studiesâ€™ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Advanced stochastic processes: Part I
32 
Stochastic processes: prerequisites
The ï¬nal equality in (1.52) follows by invoking another application of the fact
that increments are P-independent. More precisely, since X ptn`1q Â´ X ptnq and
X ptnq Â´ Xp0q are P-independent we have
P
â€œ
X ptn`1q â€œ in`1
Ë‡Ë‡ X ptnq â€œ in
â€°
â€œ P rX ptn`1q Â´ X ptnq â€œ in`1 Â´ in, X ptnq Â´ Xp0q â€œ ins
P rX ptnq Â´ Xp0q â€œ ins
â€œ P rX ptn`1q Â´ X ptnq â€œ in`1 Â´ ins .
(1.53)
The equalities in (1.49) follow from equality (1.47) in Lemma 1.32, from (1.53),
from the deï¬nition of the function piptq (see equality (1.37)), and from the
explicit value of piptq (see (1.36) in Proposition 1.30). This completes the proof
of Proposition 1.33.
â–¡
Let pâ„¦, F, Pq be a probability space and let the process t ÃÃ‘ Nptq and the proba-
bility measures Pj, j P N in
!
pâ„¦, F, PjqjPN , pNptq : t Ä› 0q , pÏ‘s : s Ä› 0q , pN, Nq
)
have the following properties:
(a) It has independent increments: Npt ` hq Â´ Nptq is independent of
F0
t â€œ Ïƒ pNpsq Â´ Np0q : 0 Ä s Ä tq .
(b) Constant intensity: the chance of arrival in any interval of length h is
the same:
P rN pt ` hq Â´ Nptq Ä› 1s â€œ Î»h ` ophq.
(c) Rarity of jumps Ä› 2:
P rN pt ` hq Â´ Nptq Ä› 2s â€œ ophq.
(d) the measures Pj, j Ä› 1, are deï¬ned by: PjrAs â€œ P
â€œ
A
Ë‡Ë‡ Np0q â€œ j
â€°
;
moreover, it is assumed that P0rNp0q â€œ 0s â€œ 1.
The following theorem and its proof are taken from Stirzaker [126] Theorem
(13) page 74.
1.34. Theorem. Suppose that the process Nptq and the probability measures
satisfy (a), (b), (c) and (d). Then the process Nptq is a Poisson process and
Pj rNptq â€œ ks â€œ pÎ»tqkÂ´j
pk Â´ jq!eÂ´Î»pkÂ´jq,
k Ä› j.
(1.54)
Proof. In view of Proposition 1.33 it suï¬ƒces to prove the identity in (1.54).
To this end we put
fnptq â€œ P0 rNptq â€œ ns â€œ P
â€œ
Nptq â€œ n
Ë‡Ë‡ Np0q â€œ 0
â€°
â€œ P rNptq Â´ Np0q â€œ ns .
Then we have, for n Ä› 2 ï¬xed,
fnpt ` hq â€œ P0 rN pt ` hq â€œ ns â€œ
nÃ¿
kâ€œ0
P0 rN pt ` hq Â´ Nptq â€œ k, Nptq â€œ n Â´ ks
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
33 
Stochastic processes: prerequisites
(the variables Npt ` hq Â´ Nptq and Nptq are P0-independent)
â€œ
nÃ¿
kâ€œ0
P0 rN pt ` hq Â´ Nptq â€œ ks Ë† P0 rNptq â€œ n Â´ ks
â€œ P0 rN pt ` hq Â´ Nptq â€œ 0s Ë† P0 rNptq â€œ ns
` P0 rN pt ` hq Â´ Nptq â€œ 1s Ë† P0 rNptq â€œ n Â´ 1s
`
nÃ¿
kâ€œ2
P0 rN pt ` hq Â´ Nptq â€œ ks Ë† P0 rNptq â€œ n Â´ ks
â€œ p1 Â´ P0 rN pt ` hq Â´ Nptq Ä› 1sq Ë† P0 rNptq â€œ ns
` P0 rN pt ` hq Â´ Nptq Ä› 1s Ë† P0 rNptq â€œ n Â´ 1s
Â´ P0 rN pt ` hq Â´ Nptq Ä› 2s Ë† P0 rNptq â€œ n Â´ 1s
`
nÃ¿
kâ€œ2
P0 rN pt ` hq Â´ Nptq â€œ ks Ë† P0 rNptq â€œ n Â´ ks
â€œ p1 Â´ Î»h ` ophqq Ë† fnptq ` pÎ»h ` ophqq fnÂ´1ptq ` ophq
nÃ¿
kâ€œ1
fnÂ´kptq
â€œ p1 Â´ Î»hq fnptq ` Î»hfnÂ´1ptq ` ophq.
(1.55)
Observe that a similar argument yields
f1pt ` hq â€œ p1 Â´ Î»hq f1ptq ` Î»hf0ptq ` ophq,
(1.56)
and also
f0pt ` hq â€œ p1 Â´ Î»hq f0ptq ` ophq.
(1.57)
From (1.55), (1.56) and (1.57) we obtain by rearranging, dividing by h and
allowing h Ã“ 0:
f 1
nptq â€œ Â´Î»fnptq ` Î»fnÂ´1ptq,
n Ä› 1,
f 1
0ptq â€œ Â´Î»fptq.
These equations can be solved by induction relative to n. A alternative way is
to consider the generating function
Gps, tq :â€œ E0
â€œ
esNptqâ€°
â€œ
8
Ã¿
nâ€œ0
snP0 rNptq â€œ ns â€œ
8
Ã¿
nâ€œ0
snfnptq.
Then BGps, tq
Bt
â€œ Î»ps Â´ 1qGps, tq, and so Gps, tq â€œ eÎ»tpsÂ´1q.
It follows that
P0 rNptq â€œ ns â€œ fnptq â€œ eÂ´Î»tpÎ»tqn
n! . Consequently, for k Ä› j we obtain
Pj rNptq â€œ ks â€œ P
â€œ
Nptq â€œ k
Ë‡Ë‡ Np0q â€œ j
â€°
â€œ P
â€œ
Nptq Â´ Np0q â€œ k Â´ j
Ë‡Ë‡ Np0q â€œ j
â€°
â€œ P rNptq Â´ Np0q â€œ k Â´ js â€œ eÂ´Î»pkÂ´jq pÎ»tqkÂ´j
pk Â´ jq! â€œ (RHS of (1.54).
This completes the proof of Theorem 1.34.
â–¡
Download free eBooks at bookboon.com

Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
35 
Renewal theory and Markov chains
CHAPTER 2
Renewal theory and Markov chains
Our main topic in this chapter is a discussion on renewal theory, classiï¬cation
properties of irreducible Markov chains, and a discussion on invariant measures.
Its contents is mainly taken from Stirzaker [126].
1. Renewal theory
Let pXrqrPN be a sequence of independent identically distributed random vari-
ables with the property that P rXr Ä… 0s Ä… 0. Put Sn â€œ Å™n
râ€œ1 Xr, S0 â€œ 0, and
deï¬ne the renewal process Nptq by Nptq â€œ max tn : Sn Ä tu, t Ä› 0. The mean
mptq â€œ E rNptqs is called the renewal function. We have Nptq Ä› n if and only
if Sn Ä t, and hence
P rNptq â€œ ns â€œ P rSn Ä ts Â´ P rSn`1 Ä ts ,
and
(2.1)
E rNptqs â€œ
8
Ã¿
râ€œ1
P rNptq Ä› rs â€œ
8
Ã¿
râ€œ1
P rSr Ä ts .
(2.2)
For more details see e.g. [4] (for birth-death processes) and [126] (for renewal
theory).
2.1. Theorem. If E rXrs Ä… 0, then Nptq has ï¬nite moments for all t Äƒ 8.
Proof. Since E rXrs Ä… 0 there exists Îµ Ä… 0 such that P rXr Ä› Îµs Ä› Îµ.
Put Mptq â€œ max
â£
n : Îµ Å™n
râ€œ1 1tXrÄ›Îµu Ä t
(
. Since Îµ Å™n
râ€œ1 1tXrÄ›Îµu Ä Å™n
râ€œ1 Xr it
follows that Nptq Ä Mptq, and hence, with m â€œ ttÎµÂ´1u,
E rNptqs Ä E rMptqs â€œ
8
Ã¿
nâ€œ1
P rMptq Ä› ns â€œ
8
Ã¿
nâ€œ1
P
Â«
Îµ
nÃ¿
râ€œ1
1tXrÄ›Îµu Ä t
ï¬€
â€œ
8
Ã¿
nâ€œ1
Ã¿
Î›Ä‚t1,...,nu, #Î›Äm
P rXj Ä› Îµ, j P Î›, Xj Äƒ Îµ, j R Î›s
â€œ
8
Ã¿
nâ€œ1
Ã¿
Î›Ä‚t1,...,nu, #Î›Äm
P rX1 Ä› Îµs#Î› p1 Â´ P rX1 Ä› ÎµsqnÂ´#Î›
â€œ
8
Ã¿
nâ€œ1
n^m
Ã¿
kâ€œ0
Ë†n
k
Ë™
P rX1 Ä› Îµsk p1 Â´ P rX1 Ä› ÎµsqnÂ´k
Ä
m
Ã¿
kâ€œ0
P rX1 Ä› Îµsk
8
Ã¿
nâ€œk
Ë†n
k
Ë™
p1 Â´ P rX1 Ä› ÎµsqnÂ´k
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
36 
Renewal theory and Markov chains
â€œ
m
Ã¿
kâ€œ0
P rX1 Ä› Îµsk
8
Ã¿
nâ€œ0
Ë†n ` k
n
Ë™
p1 Â´ P rX1 Ä› Îµsqn
â€œ
1
P rXr Ä› Îµu
Ë†Z t
Îµ
^
` 1
Ë™
.
(2.3)
In the ï¬nal equality in (2.3) we used the equality:
8
Ã¿
nâ€œ0
Ë†n ` k
n
Ë™
zk â€œ
1
p1 Â´ zqk`1
for |z| Äƒ 1. The inequality in (2.3) shows Theorem 2.1.
â–¡
It follows that E rNptqs is ï¬nite whenever E rXrs is strictly positive. This fact
will be used in Theorem 2.2.
2.2. Theorem. The following equality is valid:
E
â€œ
SNptq`1
â€°
â€œ E rX1s E rNptq ` 1s .
The equality in Theorem 2.2 is called Waldâ€™s equation.
Proof. The time Nptq ` 1 is a stopping time with respect to the ï¬ltration
Fn â€œ Ïƒ pXr : 0 Ä r Ä nq â€œ Ïƒ pSr Â´ rE rX1s : 0 Ä r Ä nq .
Notice that the process n ÃÃ‘ Sn Â´ nE rX1s is a martingale, and hence
E
â€œ
SpNptq`1q^n Â´ ppNptq ` 1q ^ nq E rX1s
â€°
â€œ E
â€œ
SpNptq`1q^0 Â´ ppNptq ` 1q ^ 0q E rX1s
â€°
â€œ 0.
(2.4)
Since E rNptqs is ï¬nite, from (2.4) we get by letting n tend to 8:
0 â€œ lim
nÃ‘8 E
â€œ
SpNptq`1q^n Â´ ppNptq ` 1q ^ nq E rX1s
â€°
â€œ E
â€œ
SpNptq`1q Â´ ppNptq ` 1qq E rX1s
â€°
.
(2.5)
Consequently, the conclusion in Theorem 2.2 follows.
â–¡
2.3. Theorem. Let pXrqrPN be a sequence of independent, identically distributed
random variables such that P rXr â€œ 0s â€œ 0. Put S0 â€œ 0 and Sn â€œ Å™n
râ€œ1 Xr. Let
the process Nptq be deï¬ned as in (2.2). Let Fptq be the distribution function of
the variable Xr. Put mptq â€œ E rNptqs. Then mptq satisï¬es the renewal equation:
mptq â€œ Fptq `
Å¼ t
0
mpt Â´ sqdFpsq â€œ
8
Ã¿
kâ€œ1
pÂµËš
Fqk r0, ts,
(2.6)
where ÂµFpa, bs â€œ Fpbq Â´ Fpaq, and Âµ1 Ëš Âµ2pa, bs â€œ
ÅŸ8
0
ÅŸ8
0 1pa,bsps ` tqdÂµ1psqdÂµ2ptq,
0 Ä a Äƒ b (i.e. convolution product of the measures Âµ1 and Âµ2). Moreover,
Ë†
1 Â´
Å¼ 8
0
eÂ´Î»sdFpsq
Ë™
Ë† Î»
Å¼ 8
0
eÂ´Î»tmptq dt â€œ
Å¼ 8
0
eÂ´Î»sdFpsq.
If Xr are independent exponentially distributed random variables, and thus the
process pNptq : t Ä› 0q is Poisson of parameter Î» Ä… 0, then mptq â€œ Î»t.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
37 
Renewal theory and Markov chains
Proof. On the event tX1 Ä… tu we have Nptq â€œ 0, and hence by using
conditional expectation we see
mptq â€œ E rNptqs â€œ E
â€œ
Nptq1tX1Ätu
â€°
â€œ E
â€œ
E
â€œ
Nptq1tX1Ätu
Ë‡Ë‡ Ïƒ pX1q
â€°â€°
â€œ E
â€œ
1tX1ÄtuE
â€œ
Nptq Â´ N pX1q
Ë‡Ë‡ Ïƒ pX1q
â€°â€°
` E
â€œ
1tX1ÄtuE
â€œ
N pX1q
Ë‡Ë‡ Ïƒ pX1q
â€°â€°
(on the event tX1 Ä tu we have N pX1q â€œ 1)
â€œ E
â€œ
1tX1ÄtuE
â€œ
Nptq Â´ N pX1q
Ë‡Ë‡ Ïƒ pX1q
â€°â€°
` E
â€œ
1tX1ÄtuE
â€œ
1
Ë‡Ë‡ Ïƒ pX1q
â€°â€°
(the distribution of NptqÂ´Npsq, t Ä… s, is the same as the distribution of NptÂ´sq)
â€œ E
â€œ
1tX1ÄtuE
â€œ
N pt Â´ X1q
Ë‡Ë‡ Ïƒ pX1q
â€°â€°
` E
â€œ
1tX1ÄtuE
â€œ
1
Ë‡Ë‡ Ïƒ pX1q
â€°â€°
â€œ E
â€œ
N pt Â´ X1q 1tX1Ätu
â€°
` E
â€œ
1tX1Ätu
â€°
â€œ
Å¼ t
0
m pt Â´ xq dFpxq ` Fptq.
(2.7)
This completes the proof of Theorem 2.3.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
38 
Renewal theory and Markov chains
2.4. Lemma. Suppose P rXr Äƒ 8s â€œ 1. Then
lim
tÃ‘8 Nptq â€œ 8,
P-almost surely.
(2.8)
Proof. Put Z â€œ lim
tÃ‘8 Nptq â€œ sup
tÄ›0 Nptq. Observe that
Nptq`1
Ã¿
kâ€œ1
Xk Ä› t, and
hence by letting t Ã‘ 8, the event tZ Äƒ 8u is contained in
Z`1
Ä
râ€œ1
tXr â€œ 8u, and
thus
P rZ Äƒ 8s â€œ P
Â«Z`1
Ä
râ€œ1
tXr â€œ 8u , Z Äƒ 8
ï¬€
Ä P
Â« 8
Ä
râ€œ1
tXr â€œ 8u
ï¬€
Ä
8
Ã¿
râ€œ1
P rXr â€œ 8s â€œ 0.
(2.9)
The result in Lemma 2.4 follows from (2.9).
â–¡
Since limtÃ‘8 Nptq â€œ 8 P-almost surely, we have lim
tÃ‘8
Nptq ` 1
Nptq
â€œ 1 P-almost
surely. The following proposition follows from the strong â€œlawâ€ of large numbers
(SSLN).
2.5. Proposition. Let pXrqrPN be a sequence of non-negative independent, iden-
tically distributed random variables in L1 pâ„¦, F, Pq such that P rXr Äƒ 8s â€œ 1.
Then
lim
tÃ‘8
SNptq`1
Nptq ` 1 â€œ lim
tÃ‘8
SNptq
Nptq â€œ E rX1s ,
P-almost surely.
(2.10)
2.6. Theorem (First renewal theorem). Let the hypotheses be as in Proposition
2.5. Then
lim
tÃ‘8
Nptq
t
â€œ
1
E rX1s,
P-almost surely.
(2.11)
Proof. By deï¬nition we have SNptq Ä t Äƒ SNptq`1, therefore
SNptq
Nptq Ä
t
Nptq Ä Nptq ` 1
Nptq
SNptq`1
Nptq ` 1.
(2.12)
The result in (2.11) now follows from (2.12) in conjunction with (2.8) and (2.10).
This proves Theorem 2.6.
â–¡
The proof of the following theorem is somewhat more intricate.
2.7. Theorem (Elementary renewal theorem). Let the hypotheses be as in
Proposition 2.5. As above, put mptq â€œ E rNptqs. Then
lim
tÃ‘8
mptq
t
â€œ
1
E rX1s.
(2.13)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
39 
Renewal theory and Markov chains
2.8. Remark. From Theorem 2.6 and 2.7 it follows that the family
"Nptq
t
: t Ä› 0
*
is uniformly integrable. Here we use Scheï¬€Â´eâ€™s theorem.
Proof of Theorem 2.7. This equality has to be considered as two in-
equalities. First we have t Äƒ SNptq`1, and hence by Theorem 2.6 we see
t Äƒ E
â€œ
SNptq`1
â€°
â€œ E rX1s pE rNptqs ` 1q â€œ E rX1s pmptq ` 1q .
(2.14)
The inequality in (2.14) is equivalent to
mptq
t
Ä›
1
E rX1s Â´ 1
t .
(2.15)
From (2.15) we see
lim inf
tÃ‘8
mptq
t
Ä› lim inf
tÃ‘8
Ë†
1
E rX1s Â´ 1
t
Ë™
â€œ
1
E rX1s.
(2.16)
For the second inequality we proceed as follows. Fix a strictly positive real
number a, and put Naptq â€œ max tn P N : Å™n
râ€œ1 min pa, Xrq Ä tu. Then Nptq Ä
Naptq. Moreover, by Theorem 2.2 we have
t Ä› E
â€œ
SNaptq
â€°
â€œ E
â€œ
SNaptq`1 Â´ min
`
a, XNaptq`1
Ë˜â€°
â€œ E rmin pa, X1qs E rNaptq ` 1s Â´ E
â€œ
min
`
a, XNaptq`1
Ë˜â€°
Ä› E rmin pa, X1qs E rNptq ` 1s Â´ a â€œ pmptq ` 1q E rmin pa, X1qs Â´ a.
(2.17)
Hence, from (2.17) we obtain:
mptq
t
Ä
1
E rmin pa, X1qs ` a Â´ E rmin pa, X1qs
tE rmin pa, X1qs .
(2.18)
From (2.18) we deduce:
lim sup
tÃ‘8
mptq
t
Ä
1
E rmin pa, X1qs,
for all large a Ä… 0.
(2.19)
By letting a Ã‘ 8 in (2.19) we see
lim sup
tÃ‘8
mptq
t
Ä
1
E rX1s.
(2.20)
A combination of the inequalities (2.16) and (2.20) yields the result in Theorem
2.7.
â–¡
Next we extend these renewal theorems a little bit, by introducing a renewal-
reward process pRnqnPN, where â€œcostsâ€ are considered as negative rewards. We
are also interested in the cumulative reward up to time t: Cptq (the reward is
collected at the end of any interval); Ciptq (the reward is collected at the start of
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
40 
Renewal theory and Markov chains
any interval); CPptq (the reward accrues during any given time interval). More
precisely we have:
Cptq â€œ
Nptq
Ã¿
jâ€œ1
Rj,
terminal reward at the end of time interval,
(2.21)
Ciptq â€œ
Nptq`1
Ã¿
jâ€œ1
Rj,
initial reward at the beginning of time interval,
(2.22)
CPptq â€œ
Nptq
Ã¿
jâ€œ1
Rj ` PNptq`1,
partial rewards during time interval.
(2.23)
For the corresponding reward functions we write
cptq â€œ E rCptqs ,
ciptq â€œ E rCiptqs
and cpptq â€œ E rCPptqs .
(2.24)
We are interested in the rates of reward: Cptq
t
, Ciptq
t
, and CPptq
t
. It is assumed
that the renewal process Nptq is deï¬ned by inter-arrival times Xr, r P N. As
above these inter-arrival times are non-negative, independent and identically
distributed on a probability space pâ„¦, F, Pq. It is also assumed that the renewal-
reward process Rn, n P N, consists of independent and identically distributed
random variables in the space L1 pâ„¦, F, Pq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Advanced stochastic processes: Part I
41 
Renewal theory and Markov chains
The following theorem will be proved.
2.9. Theorem (Renewal-reward theorem). Suppose that 0 Äƒ E rX1s Äƒ 8,
E r|R1|s Äƒ 8, and that the sequence pnÂ´1PnqnPN is uniformly bounded in n P N
and Ï‰, and has the property that limnÃ‘8 nÂ´1Pn â€œ 0, P-almost surely. Let the
notation be as in (2.21), (2.22), (2.23), and (2.24). Then the following time
average limits exist P-almost surely and they are identiï¬ed as E rR1s
E rX1s:
lim
tÃ‘8
Cptq
t
â€œ lim
tÃ‘8
Ciptq
t
â€œ lim
tÃ‘8
CPptq
t
â€œ E rR1s
E rX1s,
P-almost surely.
(2.25)
The following equalities hold as well:
lim
tÃ‘8
cptq
t
â€œ lim
tÃ‘8
ciptq
t
â€œ lim
tÃ‘8
cPptq
t
â€œ E rR1s
E rX1s.
(2.26)
Observe that the quotient E rR1s
E rX1s can be interpreted as the â€œexpected reward
accruing in a cycleâ€ divided by â€œexpected duration of a cycleâ€.
Other conditions on the sequence pPn : n P Nq can be given while retaining the
conclusion in Theorem 2.9. For example the following conditions could be im-
posed. The sequence pPn : n P Nq is P-independent and identically distributed,
or there are ï¬nite deterministic constants c1 and c2 such that |Pn| Ä c1n`c2 |Rn|
and lim
nÃ‘8
Pn
n â€œ 0. In these cases the sequence
Ë†Pn
n : n P N
Ë™
is uniformly inte-
grable and lim
nÃ‘8
Pn
n â€œ 0 P-almost surely.
Proof. By employing Theorem 2.2 and the strong law of large numbers we
have
lim
tÃ‘8
Cptq
t
â€œ lim
tÃ‘8
Å™Nptq
kâ€œ1 Rk
Nptq
Nptq
t
â€œ E rR1s
E rX1s.
(2.27)
In exactly the same manner, with Nptq ` 1 replacing Nptq, we see lim
tÃ‘8
Ciptq
t
â€œ
E rR1s
E rX1s. By hypothesis we know that lim
nÃ‘8
Pn
n â€œ 0 P-almost surely. Since
lim
tÃ‘8 Nptq â€œ 8 P-almost surely
we see that lim
tÃ‘8
PNptq`1
Nptq ` 1 â€œ 0. This together with (2.27) shows that
lim
tÃ‘8
CPptq
t
â€œ E rR1s
E rX1s.
These arguments take care of the P-almost sure convergence.
Next we consider the convergence of the time averaged expected values. For
convergence of time average of the reward function ciptq â€œ E rCiptqs we use
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
42 
Renewal theory and Markov chains
Waldâ€™s equation (see Theorem 2.2) and the elementary renewal Theorem 2.7.
More precisely we have:
ciptq â€œ E rCiptqs â€œ E
Â«Nptq`1
Ã¿
jâ€œ1
Rj
ï¬€
â€œ E rR1s pE rNptqs ` 1q .
(2.28)
Then we divide by t, take the limit in (2.28) as t tends to 8. An appeal to
Theorem 2.6 then shows the existence of the limit lim
tÃ‘8
ciptq
t
â€œ E rR1s
E rX1s which
is the second part of (2.26) in Theorem 2.9. First observe that lim
nÃ‘8
Rn
n â€œ 0
P-almost surely. This can be seen by an appeal to the Borel-Cantelli lemma. In
fact we have
8
Ã¿
nâ€œ1
P
â€|Rn|
n
Ä… Îµ
È·
â€œ
8
Ã¿
nâ€œ1
P
â€|R1|
Îµ
Ä… n
È·
Ä
Å¼ 8
0
P
â€|R1|
Îµ
Ä… x
È·
dx Ä E
â€|R1|
Îµ
È·
.
(2.29)
From (2.29) together with the Borel-Cantelli lemma it follows that lim
nÃ‘8
Rn
n â€œ 0
P-almost surely. Consequently, the sequence
"Rn
n : n P N
*
is P-uniformly in-
tegrable. Then we have
Ë‡Ë‡RNptq`1
Ë‡Ë‡
t
Ä Nptq ` 1
t
Å™Nptq`1
kâ€œ1
|Rn|
Nptq ` 1
,
(2.30)
and hence by Waldâ€™s equality
E
Â«Ë‡Ë‡RNptq`1
Ë‡Ë‡
t
ï¬€
Ä E
Â«
Nptq ` 1
t
Å™Nptq`1
kâ€œ1
|Rn|
Nptq ` 1
ï¬€
â€œ mptq ` 1
t
E r|R1|s .
(2.31)
By the strong law of large numbers and by the elementary renewal theorem 2.7
we see that the families of random variables
Å™Nptq`1
kâ€œ1
|Rn|
t
â€œ Nptq ` 1
t
Å™Nptq`1
kâ€œ1
|Rn|
Nptq ` 1
,
t Ä… 0,
(2.32)
is uniformly integrable. Consequently the family
"RNptq`1
t
: t Ä… 0
*
is uniformly
integrable, and hence it converges pointwise and in L1 pâ„¦, F, Pq to 0. Since
cptq
t
â€œ 1
t
Ëœ
E
Â«Nptq`1
Ã¿
kâ€œ1
Rk
ï¬€
Â´ E
â€œ
RNptq`1
â€°
Â¸
â€œ mptq ` 1
t
E rR1s Â´ E
â€œ
RNptq`1
â€°
t
.
(2.33)
The right-hand side of (2.33) converges to E rR1s
E rX1s. This proves the ï¬rst part of
(2.26) in Theorem 2.9. In order to prove the third part we need the uniform
integrability of the family
"PNptq`1
t
: t Ä› 1
*
. This fact is not entirely trivial.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
43 
Renewal theory and Markov chains
Let the ï¬nite constant C be such that |Pn`1| Ä Cpn ` 1q for all n P N and P-
almost surely; by hypothesis such a constant exists. From Remark 2.8 it follows
that the family
"Nptq ` 1
t
: t Ä› 1
*
is uniformly integrable. Since
Ë‡Ë‡PNptq`1
Ë‡Ë‡
t
â€œ
Ë‡Ë‡PNptq`1
Ë‡Ë‡
Nptq ` 1
Nptq ` 1
t
Ä C Nptq ` 1
t
(2.34)
it follows that the family
"PNptq`1
t
: t Ä› 1
*
is uniformly integrable as well. If
t Ã’ 8, then Nptq Ã’ 8, and lim
tÃ‘8
Nptq
t
â€œ
1
E rX1s in L1 pâ„¦, F, Pq as well as P-
almost surely: see Lemma 2.4, theorems 2.6, 2.7, and Remark 2.8. From (2.34)
it follows that lim
tÃ‘8
E
â€œË‡Ë‡PNptq`1
Ë‡Ë‡â€°
t
â€œ 0, which concludes the proof of Theorem
2.9.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planetâ€™s 
electricity needs. Already today, SKFâ€™s innovative know-
how is crucial to running a large proportion of the 
worldâ€™s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Advanced stochastic processes: Part I
44 
Renewal theory and Markov chains
1.1. Renewal theory and Markov chains. Next we consider this re-
newal theory in the context of strong Markov chains. Let pâ„¦, F, Pq be a proba-
bility space and let Xm, m P N, be a Markov chain on pâ„¦, F, Pq with state space
pS, Sq. Fix two states j and k P S. Deï¬ne the sequence of stopping times T prq
k ,
r P N, as follows:
T pr`1q
k
â€œ min
!
n Ä… T prq
k
: Xn â€œ k
)
,
T p0q
k
â€œ 0.
(2.35)
If Xn Â­â€œ k for n Ä… T prq
k , then we put T pr`1q
k
â€œ 8. The sequence of diï¬€erences
T prq
k
Â´ T prÂ´1q
k
, r Ä› 1, are Pj-independent and identically distributed.
2.10. Theorem. Let f : r0, 8s Ë† S Ã‘ R be a bounded measurable function.
Then
T pr`sq
k
â€œ T prq
k
` T psq
k
Ë Ï‘T prq
k
on
!
T prq
k
Äƒ 8
)
, and
(2.36)
Ej
â€
f
Â´
T pr`sq
k
, XT pr`sq
k
Â¯
1tT prq
k
Äƒ8u
Ë‡Ë‡ FT prq
k
Ä±
â€œ Ej
â€
f
Â´
T pr`sq
k
, XT pr`sq
k
Â¯
1tT prq
k
Äƒ8u
Ë‡Ë‡ Ïƒ
Â´
T prq
k , XT prq
k
Â¯Ä±
â€œ Ej
â€
f
Â´
T pr`sq
k
, XT pr`sq
k
Â¯
1tT prq
k
Äƒ8u
Ë‡Ë‡ Ïƒ
Â´
T prq
k
Â¯Ä±
â€œ Ï‰ ÃÃ‘ EX
T prq
k
pÏ‰qpÏ‰q
â€
Ï‰1 ÃÃ‘ f
Â´
T prq
k pÏ‰q ` T psq
k
pÏ‰1q , XT psq
k
pÏ‰1q pÏ‰1q
Â¯Ä±
1tT prq
k
Äƒ8upÏ‰q
â€œ Ï‰ ÃÃ‘ Ek
â€
Ï‰1 ÃÃ‘ f
Â´
T prq
k pÏ‰q ` T psq
k
pÏ‰1q , XT psq
k
pÏ‰1q pÏ‰1q
Â¯Ä±
1tT prq
k
Äƒ8upÏ‰q.
(2.37)
Consequently, conditioned on the event
!
T prq
k
Äƒ 8
)
the stochastic variable
T pr`sq
k
Â´ T prq
k
and the Ïƒ-ï¬eld FT prq
k
are Pj-independent.
Suppose that Pk
â€
T prq
k
Äƒ 8
Ä±
â€œ 1 and Pj
â€
T p1q
k
Äƒ 8
Ä±
Ä… 0. Then
Pj
â€
T pr`1q
k
Äƒ 8
Ä±
â€œ Pj
â€
T p1q
k
Äƒ 8
Ä±
,
and the variables T pr`1q
k
Â´ T prq
k , r P N, have the same distribution with respect
to the probability measure A ÃÃ‘ Pj
â€
A
Ë‡Ë‡ T p1q
k
Äƒ 8
Ä±
.
Here PjpAq â€œ P
â€œ
A
Ë‡Ë‡ X0 â€œ j
â€°
, A P F, j P S. Theorem 2.10 is a consequence of
the strong Markov property.
Proof. First we prove (2.36). On the event
!
T prq
k
Äƒ 8
)
we have
T pr`1q
k
â€œ min
!
n Ä… T prq
k
: Xn â€œ k
)
â€œ min
!
n Ä… T prq
k
: XnÂ´T prq
k
Ë Ï‘T prq
k
â€œ k
)
â€œ T prq
k
` min
!
n Â´ T prq
k
Ä› 1 : XnÂ´T prq
k
Ë Ï‘T prq
k
â€œ k
)
â€œ T prq
k
` min
!
m Ä› 1 : Xm Ë Ï‘T prq
k
â€œ k
)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
45 
Renewal theory and Markov chains
â€œ T prq
k
` T p1q
k
Ë Ï‘T prq
k .
(2.38)
The equality in (2.38) shows (2.36) in case s â€œ 1. We use (2.38) with s respec-
tively r ` s instead of r to obtain (2.36) by induction on s. More precisely we
have
T prq
k
` T ps`1q
k
Ë Ï‘T prq
k
â€œ T prq
k
`
Â´
T psq
k
` T p1q
k
Ë Ï‘T psq
k
Â¯
Ë Ï‘T prq
k
(2.39)
â€œ T prq
k
` T psq
k
Ë Ï‘T prq
k
` T p1q
k
Ë Ï‘T prq
k
`T psq
k
ËÏ‘
T prq
k
(induction hypothesis)
â€œ T pr`sq
k
` T p1q
k
Ë Ï‘T pr`sq
k
â€œ T pr`s`1q
k
,
(2.40)
where in (2.39) we employed (2.38) with s instead of r and in (2.40) we used
r ` s instead of r. The equality in (2.40) shows (2.36) for s`1 assuming that it
is true for s. Since by (2.38) the equality in (2.36) is true for s â€œ 1, induction
shows the equality in (2.36).
Next we will prove the equality in (2.37). From equality (2.36) we get
Ej
â€
f
Â´
T pr`sq
k
, XT pr`sq
k
Â¯
1tT prq
k
Äƒ8u
Ë‡Ë‡ FT prq
k
Ä±
â€œ Ej
â€
f
Ë†
T prq
k
` T psq
k
Ë Ï‘T prq
k , XT prq
k
`T psq
k
ËÏ‘
T prq
k
Ë™
1tT prq
k
Äƒ8u
Ë‡Ë‡ FT prq
k
È·
â€œ Ej
â€
f
Â´
T prq
k
` T psq
k
Ë Ï‘T prq
k , XT psq
k
Ë Ï‘T prq
k
Â¯
1tT prq
k
Äƒ8u
Ë‡Ë‡ FT prq
k
Ä±
(the variable T prq
k
is FT prq
k -measurable in combination with the strong Markov
property)
â€œ Ï‰ ÃÃ‘ EX
T prq
k
pÏ‰qpÏ‰q
â€
f
Â´
T prq
k pÏ‰q ` T psq
k , XT psq
k
Â¯Ä±
1tT prq
k
Äƒ8upÏ‰q
â€œ Ï‰ ÃÃ‘ Ek
â€
f
Â´
T prq
k pÏ‰q ` T psq
k , XT psq
k
Â¯Ä±
1tT prq
k
Äƒ8upÏ‰q.
(2.41)
The equalities in (2.41) show that the ï¬rst, penultimate and ultimate quantity
in (2.37) are equal. Another appeal to the strong Markov property shows that
the ï¬rst and second quantity in (2.37) coincide. Since on the event
!
T prq
k
Äƒ 8
)
the equality XT prq
k
â€œ k holds, the second and third quantity in (2.37) are equal
as well. This proves that all quantities in (2.37) in Theorem 2.10 are the same.
We still have to prove that on the event
!
T prq
k
Äƒ 8
)
the stochastic variable
T pr`sq
k
Â´ T prq
k
and the Ïƒ-ï¬eld FT prq
k
are Pj-independent. This can be achieved
as follows. Let the event A be FT prq
k -measurable and let g : r0, 8s Ã‘ R be a
bounded measurable function. Then we have
Ej
â€
g
Â´
T pr`sq
k
Â´ T prq
k
Â¯
1A 1tT prq
k
Äƒ8u
Ä±
â€œ Ej
â€
g
Â´
T psq
k
Ë Ï‘T prq
k
Â¯
1A 1tT prq
k
Äƒ8u
Ä±
(2.42)
â€œ Ej
â€
Ej
â€
g
Â´
T psq
k
Ë Ï‘T prq
k
Â¯
1A
Ë‡Ë‡ FT prq
k
Ä±
1tT prq
k
Äƒ8u
Ä±
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
46 
Renewal theory and Markov chains
â€œ Ej
â€
Ej
â€
g
Â´
T psq
k
Ë Ï‘T prq
k
Â¯ Ë‡Ë‡ FT prq
k
Ä±
1A 1tT prq
k
Äƒ8u
Ä±
(strong Markov property: (2.37))
â€œ Ej
â€
EX
T prq
k
â€
g
Â´
T psq
k
Â¯Ä±
1A 1tT prq
k
Äƒ8u
È·
â€œ Ej
â€
Ek
â€
g
Â´
T psq
k
Â¯Ä±
1A 1tT prq
k
Äƒ8u
Ä±
â€œ Ek
â€
g
Â´
T psq
k
Â¯Ä±
Ej
â€
1A 1tT prq
k
Äƒ8u
Ä±
(2.43)
(another appeal to the strong Markov property: (2.37))
â€œ Ej
â€
Ej
â€
g
Â´
T psq
k
Â¯
Ë Ï‘T prq
k 1tT prq
k
Äƒ8u
Ë‡Ë‡ FT prq
k
Ä±Ä± Ej
â€
1A 1tT prq
k
Äƒ8u
Ä±
Pj
â€
T prq
k
Äƒ 8
Ä±
â€œ Ej
â€
Ej
â€
g
Â´
T psq
k
Ë Ï‘T prq
k
Â¯
1tT prq
k
Äƒ8u
Ë‡Ë‡ FT prq
k
Ä±Ä±
Ej
â€
1A
Ë‡Ë‡ T prq
k
Äƒ 8
Ä±
(use (2.36))
â€œ Ej
â€
Ej
â€
g
Â´
T pr`sq
k
Â´ T prq
k
Â¯
1tT prq
k
Äƒ8u
Ë‡Ë‡ FT prq
k
Ä±Ä±
Ej
â€
1A
Ë‡Ë‡ T prq
k
Äƒ 8
Ä±
â€œ Ej
â€
g
Â´
T pr`sq
k
Â´ T prq
k
Â¯
1tT prq
k
Äƒ8u
Ä±
Ej
â€
1A
Ë‡Ë‡ T prq
k
Äƒ 8
Ä±
.
(2.44)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
47 
Renewal theory and Markov chains
From (2.44) the Pj-independence of T pr`sq
k
Â´T prq
k
and the Ïƒ-ï¬eld FT prq
k
conditioned
on the event
!
T prq
k
Äƒ 8
)
follows. Since the expressions in (2.42) and (2.43) are
equal it follows that the Pj
â€
Â¨
Ë‡Ë‡ T p1q
k
Äƒ 8
Ä±
-distribution of the variable T pr`1q
k
Â´
T prq
k
does not depend on r, provided that
Pj
â€â£
T 1
k Äƒ 8
(
z
!
T prq
k
Äƒ 8
)Ä±
â€œ 0.
(2.45)
By the strong Markov property it follows that
Pj
â€
T pr`1q
k
Äƒ 8
Ä±
â€œ Pj
â€
T p1q
k
Äƒ 8
Ä±
Pk
â€
T p1q
k
Äƒ 8
Ä±r
.
(2.46)
Since, by assumption, Pk
â€
T p1q
k
Äƒ 8
Ä±
â€œ 1, (2.46) implies that the probabilities
Pj
â€
T prq
k
Äƒ 8
Ä±
do not depend on r P N, and hence (2.45) follows. This proves
Theorem 2.10.
â–¡
2.11. Definition. Let j P S. If Pj
â€
T p1q
j
Äƒ 8
Ä±
â€œ 1, then j is called recurrent
(or persistent).
If Pj
â€
T p1q
j
Äƒ 8
Ä±
Äƒ 1, then j is called a transient state.
A
recurrent state for which Ej
â€
T p1q
j
Ä±
â€œ 8 is called a null state. A recurrent state
for which Ej
â€
T p1q
j
Ä±
Äƒ 8 is called a non-null or positive state.
From (2.46) it follows that Pj
â€
T prq
j
Äƒ 8
Ä±
â€œ Pj
â€
T p1q
j
Äƒ 8
Ä±r
, and hence if a
state j is recurrent it is expected to be visited inï¬nitely many times.
Let
N k â€œ Å™8
nâ€œ1 1tXnâ€œku be the number of visits to the state k, and put Î½k
j â€œ
Ej
â€œ
N kâ€°
â€œ E
â€œ
N k Ë‡Ë‡ X0 â€œ j
â€°
. Then
Î½k
j â€œ
8
Ã¿
nâ€œ1
ppnq
jk â€œ
8
Ã¿
nâ€œ1
P
â€œ
Xn â€œ k
Ë‡Ë‡ X0 â€œ j
â€°
.
(2.47)
We also have
â£
N k Ä› r ` 1
(
â€œ
!
T pr`1q
k
Äƒ 8
)
and hence by (2.46) we get
Pj
â€
T pr`1q
k
Äƒ 8
Ä±
â€œ Pj
â€œ
N k Ä› r ` 1
â€°
â€œ Pj
â€œ
N k Ä… 0
â€°
Pk
â€œ
N k Ä… 0
â€°r
â€œ Pj
â€
T p1q
k
Äƒ 8
Ä±
Pk
â€
T p1q
k
Äƒ 8
Ä±r
.
(2.48)
From (2.47) and (2.48) it follows that
Î½k
j â€œ
8
Ã¿
nâ€œ1
ppnq
jk â€œ
8
Ã¿
nâ€œ1
P
â€œ
Xn â€œ k
Ë‡Ë‡ X0 â€œ j
â€°
â€œ Pj
â€œ
N k Ä… 0
â€° 8
Ã¿
râ€œ1
Pk
â€œ
N k Ä… 0
â€°r .
(2.49)
Suppose that the state j communicates with k, i.e. suppose that ppnq
jk Ä… 0 for
some integer n Ä› 1. From (2.49) it follows that the state k is recurrent if and
only if Å™8
nâ€œ1 ppnq
jk â€œ 8. The state k is transient if and only if Å™8
nâ€œ1 ppnq
jk Äƒ 8.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
48 
Renewal theory and Markov chains
2.12. Theorem. Suppose that the states j and k intercommunicate. Then either
both states are recurrent or both states are transient.
Proof. Since the states j and k intercommunicate the exist positive inte-
gers m and n such that ppmq
jk
Ä… 0 and ppnq
kj Ä… 0. For any positive integer r we
then have
ppm`r`nq
jj
Ä› ppmq
jk pprq
kk ppnq
kj
(2.50)
By summing over r in (2.50) we see that Å™8
râ€œ1 pprq
jj Äƒ 8 if and only if Å™8
râ€œ1 pprq
kk Äƒ
8. From this fact together with (2.49) the statement in Theorem 2.12 follows.
â–¡
2.13. Definition. A Markov chain with state space S is called irreducible of all
states communicate, i.e. for every j, k P S there exists n P N such that ppnq
j,k Ä… 0.
If X is irreducible and all states and one, and so all states, are recurrent, then
X is called recurrent.
2.14. Theorem. Let X be a recurrent and irreducible Markov chain. Put
vk
j â€œ E
Â»
â€“
T p1q
kÃ¿
uâ€œ1
1tXuâ€œju
Ë‡Ë‡ X0 â€œ k
ï¬
ï¬‚â€œ Ek
Â»
â€“
T p1q
kÃ¿
uâ€œ1
1tXuâ€œju
ï¬
ï¬‚.
(2.51)
Then 0 Äƒ vk
j Äƒ 8, j, k P S, and vk
j â€œ Å™
iPS vk
i pij. In other words the vector
`
vk
j : j P S
Ë˜
is an invariant measure for X.
Proof. First we prove that 0 Äƒ vk
j Äƒ 8. Therefore we notice that
vk
j â€œ Ek
Â»
â€“
T p1q
kÃ¿
uâ€œ1
1tXuâ€œju
ï¬
ï¬‚â€œ
8
Ã¿
râ€œ0
Pk
â€
T p1q
k
Ä› T pr`1q
j
Ä±
â€œ
8
Ã¿
râ€œ0
Pk
â€
T p1q
k
Ä› T p1q
j
Ä± Â´
Pj
â€
T p1q
k
Ä› T p1q
j
Ä±Â¯r
,
(2.52)
where we used the equality:
Pk
â€
T p1q
k
Ä› T pr`1q
j
Ä±
â€œ Pk
â€
T p1q
k
Ä› T p1q
j
Ä± Â´
Pj
â€
T p1q
k
Ä› T p1q
j
Ä±Â¯r
.
(2.53)
Suppose j Â­â€œ k; for j â€œ k we have vk
k â€œ 1. The equality in (2.53) follows from
the strong Markov property as follows. For r â€œ 0 the equality is clear. For
r Ä› 1 we have
Pk
â€
T p1q
k
Ä› T pr`1q
j
Ä±
â€œ Pk
â€
T p1q
k
Ä› T pr`1q
j
, T p1q
k
Ä› T prq
j
` 1
Ä±
â€œ Pk
â€
T prq
j
` T p1q
k
Ë Ï‘T prq
j
Ä› T prq
j
` T p1q
j
Ë Ï‘T prq
j , T p1q
k
Ä› T prq
j
` 1
Ä±
â€œ Ek
â€
Pk
â€
T p1q
k
Ë Ï‘T prq
j
Ä› T p1q
j
Ë Ï‘T prq
j
Ë‡Ë‡ FT prq
j
Ä±
, T p1q
k
Ä› T prq
j
` 1
Ä±
(strong Markov property)
â€œ Ek
â€
PX
T prq
j
â€
T p1q
k
Ä› T p1q
j
Ä±
, T p1q
k
Ä› T prq
j
` 1
È·
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
49 
Renewal theory and Markov chains
â€œ Ek
â€
Pj
â€
T p1q
k
Ä› T p1q
j
Ä±
, T p1q
k
Ä› T prq
j
` 1
Ä±
â€œ Pj
â€
T p1q
k
Ä› T p1q
j
Ä±
Pk
â€
T p1q
k
Ä› T prq
j
` 1
Ä±
(induction with respect to r)
â€œ
Â´
Pj
â€
T p1q
k
Ä› T p1q
j
Ä±Â¯r
Pk
â€
T p1q
k
Ä› T p1q
j
Ä±
.
(2.54)
Since Pk
â€
T p1q
k
Ä› T p1q
j
Ä±
Ä… 0 it follows by (2.52) that vk
j Ä… 0. By the same equality
and using the fact that Pj
â€
T p1q
k
Ä› T p1q
j
Ä±
Äƒ 1 we see vk
j Äƒ 8.
Next we prove the equality: vk
j â€œ Å™
iPS vk
i pij. Therefore we write
vk
j â€œ Ek
Â»
â€“
T p1q
kÃ¿
nâ€œ1
1tXnâ€œju
ï¬
ï¬‚â€œ
8
Ã¿
nâ€œ1
Pk
â€
Xn â€œ j, T p1q
k
Ä› n
Ä±
â€œ
Ã¿
iPS
8
Ã¿
nâ€œ1
Pk
â€
Xn â€œ j, XnÂ´1 â€œ i, T p1q
k
Ä› n
Ä±
â€œ
Ã¿
iPS
8
Ã¿
nâ€œ1
Ek
â€
Pk
â€œ
Xn â€œ j
Ë‡Ë‡ FnÂ´1
â€°
, XnÂ´1 â€œ i, T p1q
k
Ä› n
Ä±
(Markov property)
â€œ
Ã¿
iPS
8
Ã¿
nâ€œ1
Ek
â€
PXnÂ´1 rX1 â€œ js , XnÂ´1 â€œ i, T p1q
k
Ä› n
Ä±
â€œ
Ã¿
iPS
Pi rX1 â€œ js
8
Ã¿
nâ€œ0
Pk
â€
Xn â€œ i, T p1q
k
Â´ 1 Ä› n
Ä±
â€œ
Ã¿
iPS
Pi rX1 â€œ js Ek
Â»
â€“
T p1q
k
Â´1
Ã¿
nâ€œ0
1tXnâ€œiu
ï¬
ï¬‚
â€œ
Ã¿
iPS
Pi rX1 â€œ js Ek
Â»
â€“
T p1q
kÃ¿
nâ€œ1
1tXnâ€œiu
ï¬
ï¬‚.
(2.55)
In the last equality of (2.55) we used the equality
Ek
Â»
â€“
T p1q
k
Â´1
Ã¿
nâ€œ0
1tXnâ€œiu
ï¬
ï¬‚â€œ Ek
Â»
â€“
T p1q
kÃ¿
nâ€œ1
1tXnâ€œiu
ï¬
ï¬‚,
which is evident for i Â­â€œ k and both are equal to 1 for i â€œ k. As a consequence
from (2.55) we see that vk
j â€œ Å™
iPS vk
i pij.
â–¡
2.15. Corollary. Let the row vector vk :â€œ
`
vk
j : j P S
Ë˜
be as in equality (2.51)
of Theorem 2.14. Then vk is minimal invariant measure in the sense that if
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
50 
Renewal theory and Markov chains
x â€œ pxj : j P Sq is another invariant measure such that xk â€œ 1. Then xj Ä› vk
j ,
j P S.
Proof. We write:
xj â€œ pkj `
Ã¿
sPS, sÂ­â€œk
xspsj
â€œ Pk
â€
X1 â€œ j, T p1q
k
Ä› 1
Ä±
`
Ã¿
s1PS, s1Â­â€œk
Ã¿
s2PS
xs2ps2s1ps1j
â€œ Pk
â€
X1 â€œ j, T p1q
k
Ä› 1
Ä±
`
Ã¿
s1PS, s1Â­â€œk
pks1ps1j `
Ã¿
s1PS, s1Â­â€œk
Ã¿
s2PS, s2Â­â€œk
xs2ps2s1ps1j
Ä› Pk
â€
X1 â€œ j, T p1q
k
Ä› 1
Ä±
` Pk
â€
X2 â€œ j, T p1q
k
Ä› 2
Ä±
` Â¨ Â¨ Â¨ ` Pk
â€
Xn â€œ j, T p1q
k
Ä› n
Ä±
.
(2.56)
Upon letting n tend to 8 in (2.56) we see that xj Ä› vk
j . This proves Corollary
2.15.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
51 
Renewal theory and Markov chains
2.16. Theorem. Let X be a irreducible Markov chain with transition matrix
P â€œ ppijqpi,jqPSË†S .
The following assertions hold:
(a) If any state is non-null recurrent, then all states are.
(b) The chain is non-null recurrent if and only if there exists a stationary
distribution Ï€ or invariant measure. If this is the case, then
Ï€k â€œ
1
Ek
â€
T p1q
k
Ä±
and
vk
j â€œ Ï€j
Ï€k
(see (2.51)).
(2.57)
As a consequence of (2.57) stationary distributions are unique.
Proof. (a) The proof of assertion will follow from the proof of assertion
(b).
(b) Let k be a state which is non-null recurrent. By Theorem 2.12 it follows
that the chain is recurrent. By Theorem 2.14 the vector
`
vk
j : j P S
Ë˜
as deï¬ned
in (2.51) is an invariant vector. Since k is non-null recurrent it follows that
0 Äƒ Ek
â€
T p1q
k
Ä±
Äƒ 8, and that the vector
Ëœ
vk
j
Ï€k
: j P S
Â¸
, with Ï€k â€œ
1
Ek
â€
T p1q
k
Ä±,
is a stationary vector. It follows that if the irreducible chain X contains at
least one non-null recurrent state, then there exists a stationary distribution.
Next suppose that there exists a stationary distribution Ï€ :â€œ pÏ€j : j P Sq. Then
Ï€k â€œ Å™
jPS Ï€jppnq
jk for all n P N. Since the chain is irreducible, and the vector is
a probability vector, at least one Ï€j0 Â­â€œ 0. By irreducibility there exists n P N
such that ppnq
j0k Â­â€œ 0, and hence Ï€k Â­â€œ 0, k P S. Consider for any given k P S the
vector x â€œ
Ë†Ï€j
Ï€k
: j P S
Ë™
. Then xk â€œ 1 and by Corollary 2.15 xj Ä› vk
j for all
j P S. It follows that
Ek
â€
T p1q
k
Ä±
â€œ
Ã¿
jPS
vk
j Ä
Ã¿
jPS
Ï€j
Ï€k
â€œ 1
Ï€k
.
(2.58)
Therefore k is non-null recurrent for all k P S. It follows that if there exists
one non-null recurrent vector k P S, then all states in S are non-null recurrent.
Altogether this proves assertion (a), and also a large part of (b). From (2.58)
the ï¬rst equality in (2.57) follows. Finally we will show the second equality
in (2.57). The vector x Â´ vk is invariant and, by Corollary 2.15 Ï€j
Ï€k
Â´ vk
j Ä› 0.
Hence we obtain, for all positive integers n,
0 â€œ 1 Â´ vk
k â€œ
Ã¿
iPS
Ë† Ï€i
Ï€k
Â´ vk
i
Ë™
ppnq
ik Ä›
Ë†Ï€j
Ï€k
Â´ vk
j
Ë™
ppnq
jk .
(2.59)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
52 
Renewal theory and Markov chains
In (2.59) we choose n in such a way that ppnq
jk Ä… 0. By irreducibility this is
possible. It follows that (see (2.51))
vk
j â€œ E
Â»
â€“
T p1q
kÃ¿
uâ€œ1
1tXuâ€œju
Ë‡Ë‡ X0 â€œ k
ï¬
ï¬‚â€œ Ek
Â»
â€“
T p1q
kÃ¿
uâ€œ1
1tXuâ€œju
ï¬
ï¬‚â€œ Ï€j
Ï€k
â€œ
Ek
â€
T p1q
k
Ä±
Ej
â€
T p1q
j
Ä±. (2.60)
The second equality in (2.57) is the same as (2.60). This concludes the proof of
Theorem 2.16.
â–¡
Let k be a non-null recurrent state, and suppose that the state is j intercom-
municates with k. Then both states are non-null or positive recurrent. Next we
deï¬ne the renewal process Nkpnq, n P N, as follows:
Nkpnq â€œ max
!
r : T prq
k
Ä n
)
.
(2.61)
Notice the inequalities:
T pNkpnqq
k
Ä n Äƒ T pNkpn`1qq
k
,
and hence T pmq
k
â€œ n if m â€œ Nkpnq. We are interested in the following type of
limits:
lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
ppâ„“q
kj â€œ lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
P
â€œ
Xâ„“â€œ j
Ë‡Ë‡ X0 â€œ k
â€°
â€œ lim
nÃ‘8 E
Â«
1
n
nÃ¿
â„“â€œ1
1tXâ„“â€œju
Ë‡Ë‡ X0 â€œ k
ï¬€
.
(2.62)
Put m â€œ Nkpnq. Then T pmq
k
â€œ n, and consequently we see
1
n
nÃ¿
â„“â€œ1
1tXâ„“â€œju â€œ Nkpnq
n
1
m
m
Ã¿
uâ€œ1
T puq
kÃ¿
â„“â€œT puÂ´1q
k
`1
1tXâ„“â€œju.
(2.63)
Notice that for j â€œ k we have
1
m
m
Ã¿
uâ€œ1
T puq
kÃ¿
â„“â€œT puÂ´1q
k
`1
1tXâ„“â€œju â€œ 1,
and consequently,
1
n
nÃ¿
â„“â€œ1
1tXâ„“â€œku â€œ Nkpnq
n
.
Hence, we observe that (see Theorem 2.6)
lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
1tXâ„“â€œku â€œ lim
nÃ‘8
Nkpnq
n
â€œ
1
E
â€
T p1q
k
Ë‡Ë‡ X0 â€œ k
Ä± â€œ 1
Âµk
, Pk-almost surely.
(2.64)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
53 
Renewal theory and Markov chains
We also see that
Njpnq
n
â€œ 1
n
nÃ¿
â„“â€œ1
1tXâ„“â€œju â€œ Nkpnq
n
1
m
m
Ã¿
uâ€œ1
T puq
kÃ¿
â„“â€œT puÂ´1q
k
`1
1tXâ„“â€œju.
(2.65)
From the strong law of large numbers we get:
lim
mÃ‘8
1
m
m
Ã¿
uâ€œ1
T puq
kÃ¿
â„“â€œT puÂ´1q
k
`1
1tXâ„“â€œju â€œ E
Â»
â€“
T p1q
kÃ¿
uâ€œ1
1tXuâ€œju
Ë‡Ë‡ X0 â€œ k
ï¬
ï¬‚â€œ vk
j .
(2.66)
From (2.63), (2.64), and (2.65) we obtain:
1
E
â€
T p1q
j
Ë‡Ë‡ X0 â€œ j
Ä± â€œ lim
nÃ‘8
Njpnq
n
â€œ lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
1tXâ„“â€œju
â€œ lim
nÃ‘8
Nkpnq
n
1
m
m
Ã¿
uâ€œ1
T puq
kÃ¿
â„“â€œT puÂ´1q
k
`1
1tXâ„“â€œju â€œ
vk
j
E
â€
T p1q
k
Ë‡Ë‡ X0 â€œ k
Ä±.
(2.67)
The equality in (2.67) together with Theorem 2.9 shows the following theorem.
2.17. Theorem. Let the sequence of stopping times
Â´
T prq
k
Â¯
rPN be deï¬ned as in
(2.35), and let vk
j be deï¬ned as in (2.66).
Suppose that the states j and k
intercommunicate and that one of them is non-null recurrent, then the other is
also non-null recurrent. Moreover,
lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
1tXâ„“â€œju â€œ
1
E
â€
T p1q
j
Ë‡Ë‡ X0 â€œ j
Ä± â€œ
vk
j
E
â€
T p1q
k
Ë‡Ë‡ X0 â€œ k
Ä±,
and
(2.68)
lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
ppâ„“q
kj â€œ lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
P
â€œ
Xâ„“â€œ j
Ë‡Ë‡ X0 â€œ k
â€°
â€œ
1
E
â€
T p1q
j
Ë‡Ë‡ X0 â€œ j
Ä± â€œ
vk
j
E
â€
T p1q
k
Ë‡Ë‡ X0 â€œ k
Ä±.
(2.69)
Hence, with Ï€j â€œ lim
nÃ‘8
1
n
nÃ¿
â„“â€œ1
ppâ„“q
kj , Âµj â€œ E
â€
T p1q
j
Ë‡Ë‡ X0 â€œ j
Ä±
, and vk
j as in equality
(2.66) we have Ï€j â€œ 1
Âµj
â€œ vk
j
Âµk
.
1.1.1. Random walks. In this example the state space is Z, and the process
Xn, n P N, has a transition probability matrix with the following entries: piÂ´1,i â€œ
q, pi`1,i â€œ p, 0 Äƒ p â€œ 1 Â´ q Äƒ 1, and pj,i â€œ 0, j â€° i Ë˜ 1. Such a random walk
can be realized by putting Xn â€œ Å™n
kâ€œ0 Sk, where S0 is the initial state (which
may be random), the variables Sk, k P N, k Ä› 1, are P-independent of each
other and are also P-independent of S0. Moreover, each variable Sk, k Ä› 1, is
a Bernoulli variable taking the value `1 with probability p and the value Â´1
with probability q. This Markov chain is irreducible: every state communicates
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
54 
Renewal theory and Markov chains
with every other one. The set of states is closed. The corresponding inï¬nite
transition matrix looks as follows:
Â¨
Ëš
Ëš
Ëš
Ëš
Ëš
Ëš
Ëš
Ë
...
...
...
...
...
...
...
q
0
p
0
. . .
. . .
0
q
0
p
. . .
. . .
0
0
q
0
...
...
...
...
...
...
...
Ë›
â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€š
.
The state 0 has period two pp2n`1q
00
â€œ 0, and pp2nq
00
â€œ
Ë†2n
n
Ë™
pnqn. In order to
check transiency (or recurrence) we need to calculate
8
Ã¿
nâ€œ0
pp2nq
00
â€œ
8
Ã¿
nâ€œ0
Ë†2n
n
Ë™
pnqn.
(2.70)
By Stirlingâ€™s formula we have n! â€
?
2Ï€nnneÂ´n, which means that
lim
nÃ‘8
n!
?
2Ï€nnneÂ´n â€œ 1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENTâ€¦
     RUN FASTER.
          RUN LONGER..
                RUN EASIERâ€¦
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Advanced stochastic processes: Part I
55 
Renewal theory and Markov chains
Since
Ë†2n
n
Ë™
â€œ p2nq!
pn!q2 â€
?
4Ï€n p2nq2n eÂ´2n
2Ï€n2n`1eÂ´2n
â€œ
4n
?Ï€n
(2.71)
the sum in (2.70) is ï¬nite if and only if the sum
8
Ã¿
nâ€œ1
p4pqqn
?Ï€n Äƒ 8.
(2.72)
If p â€œ 1 Â´ q â€°
1
2, then 4pq Äƒ 1, and hence the sum in (2.72) is ï¬nite, and
so the unrestricted asymmetric random walk in Z is transient.
However, if
p â€œ q â€œ 1
2, then 4pq â€œ 1 and the sum in (2.72) diverges, and so the symmetric
unrestricted random walk in Z is recurrent. One may also do similar calculations
for symmetric random walks in Z2, Z3, and Zd, d Ä› 4. It turns out that in Z2 the
2n-th symmetric transition probability pp2nq
00
satisï¬es (for n Ã‘ 8) pp2nq
00
â€ 1
Ï€n,
and hence the sum Å™8
nâ€œ0 pp2nq
00
â€œ 8. It follows that the symmetric random walk
in Z2 is recurrent. The corresponding return probability pp2nq
00
for the symmetric
random walk in Z3 possesses the following asymptotic behavior:
pp2nq
00
â€ 1
2
Ë† 3
Ï€
Ë™3{2
1
n3{2.
Hence the sum Å™8
nâ€œ0 pp2nq
00
Äƒ 8, and so the state 0 is transient. The 2n-th return
probabilities of the symmetric random walk in Zd satisï¬es
pp2nq
00
â€ cd
nd{2,
n Ã‘ 8,
for some constant cd and hence the sum Å™8
nâ€œ0 pp2nq
00
Äƒ 8 in dimensions d Ä› 3.
So in dimensions d Ä› 3 the symmetric random walk is transient, and in the
dimension d â€œ 1, 2, the symmetric random walk is recurrent.
We come back to the one-dimensional situation, and we reconsider the return
times to a state k P Z: T p1q
k
â€œ inf tn Ä› 1 : Xn â€œ ku. Notice that Sk, k P N, are
the step sizes which are Ë˜1. Also observe that Xk â€œ Å™k
jâ€œ0 Sj. We consider the
moment generating function Gj,kpsq â€œ Ej
â€
sT p1q
k
Ä±
, 0 Ä s Äƒ 1. Observe that on
the event
!
T p1q
k
â€œ 8
)
the quantity sT p1q
k
has to be interpreted as 0. In addition,
we have Pj
â€
T p1q
k
Ä… T p1q
kÂ´1
Ä±
â€œ Pj
â€
T p1q
kÂ´1 Äƒ 8
Ä±
for k Ä… j, k, j P Z. Then it follows
that T p1q
k
â€œ T p1q
kÂ´1 ` T p1q
k
Ë Ï‘T p1q
kÂ´1, Pj-almost surely, k Ä… j, k, j P Z. Then by the
strong Markov property we get
Gj,kpsq â€œ Ej
â€
sT p1q
k
Ä±
â€œ Ej
Â«
s
T p1q
kÂ´1`T p1q
k
ËÏ‘
T p1q
kÂ´1, T p1q
kÂ´1 Äƒ 8
ï¬€
â€œ Ej
Â«
sT p1q
kÂ´1Ej
Â«
s
T p1q
k
ËÏ‘
T p1q
kÂ´1 Ë‡Ë‡ GT p1q
kÂ´1
ï¬€
, T p1q
kÂ´1 Äƒ 8
ï¬€
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
56 
Renewal theory and Markov chains
(Markov property)
â€œ Ej
â€
sT p1q
kÂ´1EX
T p1q
kÂ´1
â€
sT p1q
k
Ä±
, T p1q
kÂ´1 Äƒ 8
È·
â€œ Ej
â€
sT p1q
kÂ´1EkÂ´1
â€
sT p1q
k
Ä±Ä±
â€œ Ej
â€
sT p1q
kÂ´1
Ä±
EkÂ´1
â€
sT p1q
k
Ä±
.
(2.73)
From (2.73) we see by induction with respect to k that
Gj,kpsq â€œ
kÂ´1
Åº
â„“â€œj
Gâ„“,â„“`1psq â€œ G0,1psqkÂ´j.
(2.74)
In the ï¬nal step of (2.74) we used the fact that the Pâ„“-distribution of T p1q
â„“`1 is
the same as the P0-distribution of T p1q
1 . This follows from the fact that the
variables Sm, m P N, m Ä› 1, are independent identically (Bernoulli) distributed
random variables. Notice that T p1q
1
â€œ 1 ` T p0q
1
Ë Ï‘1, P0-almost surely. Here
T p0q
1
â€œ inf tn Ä› 0 : Xn â€œ 1u. Again we use the Markov property to obtain:
G0,1psq â€œ E0
â€
esT p1q
1
Ä±
â€œ E0
â€
s1`T p0q
1
ËÏ‘1Ä±
â€œ sE0
â€
E0
â€
sT p1q
1
ËÏ‘1 Ë‡Ë‡ G1
Ä±Ä±
â€œ sE0
â€
EX1
â€
sT p0q
1
Ä±Ä±
â€œ sE0
â€
EX1
â€
sT p0q
1
Ä±
, X1 â€œ 1s
Ä±
` sE0
â€
EX1
â€
sT p0q
1
Ä±
, X1 â€œ Â´1
Ä±
â€œ sE0
â€
E1
â€
sT p0q
1
Ä±
, X1 â€œ 1
Ä±
` sE0
â€
EÂ´1
â€
sT p0q
1
Ä±
, X1 â€œ Â´1
Ä±
(notice that T p0q
1
â€œ 0 P1-almost surely, and T p0q
1
â€œ T p1q
1
PÂ´1-almost surely)
â€œ sp ` sqEÂ´1
â€
sT p1q
1
Ä±
â€œ sp ` sqGÂ´1,1psq
â€œ sp ` sqG0,2psq â€œ sp ` sqG0,1psq2.
(2.75)
In the ï¬nal step of (2.75) we employed (2.74) with j â€œ Â´1 and k â€œ 1. From
(2.75) we infer
G0,1psq â€œ 1 Â´ p1 Â´ 4pqs2q1{2
2qs
.
(2.76)
By a similar token (i.e. by interchanging p and q) we also get
G1,0psq â€œ 1 Â´ p1 Â´ 4pqs2q1{2
2ps
.
(2.77)
Next we rewrite G0,0psq:
G0,0psq â€œ E0
â€
sT p1q
0
Ä±
â€œ E0
â€
s1`T p0q
0
ËÏ‘1Ä±
â€œ sE0
â€
E0
â€
sT p0q
0
ËÏ‘1 Ë‡Ë‡ G1
Ä±Ä±
â€œ sE0
â€
EX1
â€
sT p1q
0
Ä±Ä±
(on the event tX1 â€œ Ë˜1u the equality T p0q
0
â€œ T p1q
0
holds PX1-almost surely)
â€œ sE0
â€
EX1
â€
sT p1q
0
Ä±
, X1 â€œ 1
Ä±
` sE0
â€
EX1
â€
sT p1q
0
Ä±
, X1 â€œ Â´1
Ä±
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
57 
Renewal theory and Markov chains
â€œ sE0
â€
E1
â€
sT p1q
0
Ä±
, X1 â€œ 1
Ä±
` sE0
â€
EÂ´1
â€
sT p1q
0
Ä±
, X1 â€œ Â´1
Ä±
â€œ spE1
â€
sT p1q
0
Ä±
` sqEÂ´1
â€
sT p1q
0
Ä±
((space) translation invariance)
â€œ spE1
â€
sT p1q
0
Ä±
` sqE0
â€
sT p1q
1
Ä±
â€œ spG1,0psq ` sqG0,1psq
(employ the equalities in (2.76) and (2.77))
â€œ sp1 Â´ p1 Â´ 4pqs2q1{2
2ps
` sq1 Â´ p1 Â´ 4pqs2q1{2
2qs
â€œ 1 Â´
`
1 Â´ 4pqs2Ë˜1{2 .
Then we infer
P0
â€
T p1q
0
Äƒ 8
Ä±
â€œ
lim
sÃ’1, sÄƒ1 G0,0psq â€œ 1 Â´ p1 Â´ 4pqq1{2
â€œ 1 Â´ |1 Â´ 2p| â€œ 1 Â´ |q Â´ p| .
As a consequence we see that the non-symmetric random walk, i.e. the one with
q â€° p, is transient, and that the symmetric random walk (i.e. p â€œ q â€œ 1
2) is
recurrent. However, since
E0
â€
T p1q
0
Ä±
â€œ
lim
sÃ’1,sÄƒ1 G1
0,0psq â€œ
lim
sÃ’1,sÄƒ1
s
p1 Â´ s2q3{2 â€œ 8,
it follows that the symmetric random walk is not positive recurrent.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Advanced stochastic processes: Part I
58 
Renewal theory and Markov chains
In the following lemma we prove some of the relevant equalities concerning
stopping times and one-dimensional random walks.
2.18. Lemma. Employing the above notation and hypotheses yields the following
equalities:
(i) The equality T p1q
j
â€œ 1 ` T p0q
j
Ë Ï‘1 holds Pk-almost surely for all states k,
j P Z.
(ii) For k Ä… j, k, j P Z the equality T p1q
k
â€œ T p1q
kÂ´1`T p1q
k ËÏ‘T p1q
kÂ´1 holds Pj-almost
surely.
Proof. First let us prove assertion (i). Let j and k be states in Z. Then
Pk-almost surely we have
1 ` T p0q
j
Ë Ï‘1 â€œ 1 ` inf tn Ä› 0 : Xn Ë Ï‘1 â€œ ju
â€œ inf tn ` 1 : n Ä› 0, Xn`1 â€œ ju â€œ inf tn Ä› 1 Xn â€œ ju â€œ T p1q
j .
(2.78)
The equality in (2.78) shows assertion (i). Next we prove the somewhat more
diï¬ƒcult equality in (ii). As remarked above we have
Pj
â€
T p1q
k
Ä… T p1q
kÂ´1
Ä±
â€œ Pj
â€
T p1q
kÂ´1 Äƒ 8
Ä±
.
Indeed, in order to visit the state k Ä… j the process Xn, starting from j has
to visit the state k Â´ 1, and hence Pj
â€
T p1q
kÂ´1 Äƒ T p1q
k
Ä±
â€œ Pj
â€
T p1q
kÂ´1 Äƒ 8
Ä±
. Without
loss of generality we may and shall assume that in the following arguments
we consider the process Xn on the event
!
T p1q
kÂ´1 Äƒ 8
)
. (Otherwise we would
automatically have T p1q
kÂ´1 ` T p1q
k
Ë Ï‘T p1q
kÂ´1 â€œ T p1q
k .) Next on the event
!
T p1q
kÂ´1 Äƒ 8
)
we write:
T p1q
kÂ´1 ` T p1q
k
Ë Ï‘T p1q
kÂ´1 â€œ T p1q
kÂ´1 ` inf
!
n Ä› 1 : Xn Ë Ï‘T p1q
kÂ´1 â€œ k
)
â€œ inf
!
T p1q
kÂ´1 ` n : n Ä› 1, Xn`T p1q
kÂ´1 â€œ k
)
â€œ inf
!
n Ä… T p1q
kÂ´1 : Xn â€œ k
)
â€œ T p1q
k .
(2.79)
Assertion (ii) follows from (2.79). Altogether this proves Lemma 2.18.
â–¡
Perhaps it is useful to prove in an explicit manner that the one-dimensional
random walk is a Markov chain. This is the content of the next lemma.
2.19. Lemma. Let tSn : n P N, n Ä› 1u be independent identically distributed
random variables taking their values in Z. Put X0 â€œ S0 be the initial value
of the process Xn, n P N, where Xn â€œ Å™n
mâ€œ0 Sm. Put
Ej rf pX0, X1, . . . , Xnqs â€œ E rf pX0 ` j, X1 ` j, . . . , Xn ` jqs
(2.80)
for all bounded functions f : Zn`1 Ã‘ R, j P Z, n P N. Then the equality in
(2.80) expresses the fact that the process
!
pâ„¦, G, PjqjPZ , pXn, n P Nq , pÏ‘n, n P Nq , Z
)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
59 
Renewal theory and Markov chains
is a space homogeneous process, with the property that the distribution of the
process pXn`1 Â´ XnqnPN does not depend on the initial value j.
It is also a
time-homogeneous Markov chain.
Proof. The ï¬rst equality say that the ï¬nite dimensional distributions of
the process pXnqnPN are homogeneous in space. If
f px0, x1, . . . , xnq â€œ g px1 Â´ x0, x2 Â´ x1, . . . , xn Â´ xnÂ´1q ,
then from (2.80) we see that
Ej rf pX0, X1, . . . , Xnqs â€œ E rf pX0 ` j, X1 ` j, . . . , Xn ` jqs
â€œ E rg pX1 Â´ X0, X2 Â´ X1, . . . , Xn Â´ XnÂ´1qs
â€œ Ej rg pX1 Â´ X0, X2 Â´ X1, . . . , Xn Â´ XnÂ´1qs .
(2.81)
The equality in (2.81) shows that the distribution of the process
pXn`1 Â´ XnqnPN
does not depend on the initial value j. Next we prove the Markov property. Let
f be any bounded function on Z. To this end we consider:
Ej
â€œ
f pXn`1q
Ë‡Ë‡ Gn
â€°
â€œ E
â€œ
f pXn`1 ` jq
Ë‡Ë‡ Gn
â€°
â€œ E
â€œ
f pXn`1 Â´ Xn ` Xn ` jq
Ë‡Ë‡ Gn
â€°
(the variable Xn`1 Â´ Xn and the Ïƒ-ï¬eld Gn are P-independent)
â€œ Ï‰ ÃÃ‘ E rÏ‰1 ÃÃ‘ f pXn`1 pÏ‰1q Â´ Xn pÏ‰1q ` Xn pÏ‰q ` jqs
(the P-distribution of Xn`1 pÏ‰1qÂ´Xn pÏ‰1q neither depends on n nor on the initial
value X0 pÏ‰1q)
â€œ Ï‰ ÃÃ‘ E rÏ‰1 ÃÃ‘ f pX1 pÏ‰1q Â´ X0 pÏ‰1q ` Xn pÏ‰q ` jqs
(choose X0 pÏ‰1q â€œ j)
â€œ Ï‰ ÃÃ‘ E rÏ‰1 ÃÃ‘ f pX1 pÏ‰1q Â´ j ` Xn pÏ‰q ` jqs
â€œ Ï‰ ÃÃ‘ E rÏ‰1 ÃÃ‘ f pX1 pÏ‰1q ` Xn pÏ‰qqs
â€œ Ï‰ ÃÃ‘ EXnpÏ‰q rÏ‰1 ÃÃ‘ f pX1 pÏ‰1qqs â€œ EXn rf pX1qs .
(2.82)
The equality in (2.82) proves Lemma 2.19.
â–¡
2.20. Remark. It would have been suï¬ƒcient to take f of the form f â€œ 1k,
k P Z.
2.21. Remark. Lemma 2.19 proves more than just the Markov property for a
random walk. It only uses the fact that the increments Sn are identically P-
distributed and independent, and that the process pXnqnPN possesses the same
Pj-distribution as the P-distribution of the process pXn ` jqnPN, j P Z. The
proof only simpliï¬es a little bit if one uses the random walk properties in an
explicit manner.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
60 
Renewal theory and Markov chains
1.1.2. Some remarks. From a historic point of view the references [6, 47,
151] are quite relevant. The references [10, 43] are relatively speaking good
accessible. The reference [153] gives a detailed treatment of martingale theory.
Citations, like [54, 140, 142, 145] establish a precise relationship between
Feller operators, Markov processes, and solutions to the martingale problem.
The references [49, 50] establish a relationship between hedging strategies (in
mathematical ï¬nance) and (backward) stochastic diï¬€erential equations.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
61 
Renewal theory and Markov chains
2. Some additional comments on Markov processes
In this section we will discuss some topics related to Markov chains and Markov
processes. We consider a quadruple
tpâ„¦, F, Pq , pXn, n P Nq , pÏ‘n, n P Nq , pS, Squ .
(2.83)
In (2.83) the triple pâ„¦, F, Pq stands for a probability space, â„¦is called the
â€œsample spaceâ€, F is a Ïƒ-ï¬eld on â„¦, and P is a probability measure on F. The
Ïƒ-ï¬eld F is called the Ïƒ-ï¬eld of events. The symbol pS, Sq stands for the state
space of our process pXn : n P Nq. In the present situation the state space S is
discrete and countable with the discrete Ïƒ-ï¬eld S.
Let pâ„¦, F, Pq be a probability space and let Xj : â„¦Ã‘ S, j P N â€œ t0, 1, 2, . . .u,
be state variables. It is assumed that the Ïƒ-ï¬eld F is generated by the state
variables Xj, j P N. Let Ï‘k : â„¦Ã‘ â„¦, k P N, be time shift operators, which are
also called time translation operators: Xj Ë Ï‘k â€œ Xj`k, j, k P N. For a bounded
Ïƒ pXj : j P Nq-measurable stochastic variable F : â„¦Ã‘ R and x P S we write
Ex rFs â€œ E
â€œ
F
Ë‡Ë‡ X0 â€œ x
â€°
â€œ E rF, X0 â€œ xs
P rX0 â€œ xs .
We also write
Tx,y â€œ P rX1 â€œ y, X0 â€œ xs
P rX0 â€œ xs
â€œ Px rX1 â€œ ys â€œ P
â€œ
X1 â€œ y
Ë‡Ë‡ X0 â€œ x
â€°
.
Here x has the interpretation of state at time 0, and y is the state at time
1. Let Gn, n P N, be the internal memory up to the moment n. Hence Gn â€œ
Ïƒ pXj : 0 Ä j Ä nq.
2.22. Theorem. Suppose that pXn : n P Nq is a stochastic process with values
in a discrete countable state space S with the discrete Ïƒ-ï¬eld S.
The state
variables Xn, n P N, are deï¬ned on a probability space pâ„¦, F, Pq. Write, as
above, Tx,y â€œ P
â€œ
X1 â€œ y
Ë‡Ë‡ X0 â€œ x
â€°
, x, y P S. Then the following assertions are
equivalent:
(1) For all ï¬nite sequences of states ps0, . . . , sn`1q in S the following iden-
tity holds:
P
`
Xn`1 â€œ sn`1
Ë‡Ë‡ X0 â€œ s0, . . . , Xn â€œ sn
Ë˜
â€œ Tsn,sn`1;
(2.84)
(2) For all bounded functions f : S Ã‘ R and for all times n P N the
following equality holds:
E
â€œ
f pXn`1q
Ë‡Ë‡ Gn
â€°
â€œ EXn rf pX1qs P-almost surely;
(2.85)
(3) For all bounded functions f0, . . . , fk op S and for all times n P N the
following equality holds P-almost surely:
E
â€œ
f0pXnqf1pXn`1q . . . fkpXn`kq
Ë‡Ë‡ Gn
â€°
â€œ EXn rf0pX0qf1pX1q . . . fkpXkqs ; (2.86)
(4) For all bounded measurable functions F : pâ„¦, Fq Ã‘ R (stochastic vari-
ables) and for all n P N the following identity holds:
E
â€œ
F Ë Ï‘n
Ë‡Ë‡ Gn
â€°
â€œ EXn rFs P-almost surely;
(2.87)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
62 
Renewal theory and Markov chains
(5) For all bounded functions f : S Ã‘ R and for all pGnqnPN-stopping times
Ï„ : â„¦Ã‘ r0, 8s the following equality holds:
E
â€œ
fpXÏ„`1q
Ë‡Ë‡ GÏ„
â€°
â€œ EXÏ„ rfpX1qs
P-almost surely on the event
tÏ„ Äƒ 8u ;
(2.88)
(6) For all bounded measurable functions F : pâ„¦, Fq Ã‘ R (random vari-
ables) and for all stopping times Ï„ the following identity holds:
E
â€œ
F Ë Ï‘Ï„
Ë‡Ë‡ GÏ„
â€°
â€œ EXÏ„ rFs
P-almost surely on the event
tÏ„ Äƒ 8u .
(2.89)
Before we prove Theorem 2.22 we make some remarks and give some explana-
tion.
2.23. Remark. Let â„¦â€œ SN, equipped with the product Ïƒ-ï¬eld, and let Xj :
â„¦Ã‘ S be deï¬ned by XjpÏ‰q â€œ Ï‰j where Ï‰ â€œ pÏ‰0, . . . , wj, . . .q belongs to â„¦. If
Ï‘k : â„¦Ã‘ â„¦is deï¬ned by Ï‘k pÏ‰0, . . . , Ï‰j, . . .q â€œ pÏ‰k, . . . , Ï‰j`k, . . .q, then it follows
that Xj Ë Ï‘k â€œ Xj`k.
2.24. Remark. Instead of one probability space pâ„¦, F, Pq we often consider a
family of probability spaces pâ„¦, F, PxqxPS.
The probabilities Px, x P S, are
determined by
Ex rFs â€œ E
â€œ
F
Ë‡Ë‡ X0 â€œ x
â€°
â€œ E rF, X0 â€œ xs
P rX0 â€œ xs ,
x P S.
(2.90)
Here F : â„¦Ã‘ R is F-BR-measurable, and hence by deï¬nition it is a random or
stochastic variable. Since Px rAs â€œ Ex r1As, A P F, and Px râ„¦s â€œ Ex r1s â€œ 1, the
measure Px is a probability measure on F.
2.25. Remark. Let F : â„¦Ã‘ R be a bounded stochastic variable. The variable
EXn rFs is a stochastic variable which is measurable with respect to the Ïƒ-ï¬eld
Ïƒ pXnq, i.e. the Ïƒ-ï¬eld generated by Xn. In fact we have
EXnpÏ‰q rFs â€œ E
â€œ
F
Ë‡Ë‡ X0 â€œ XnpÏ‰q
â€°
â€œ E rF, X0 â€œ XnpÏ‰qs
P rX0 â€œ XnpÏ‰qs
â€œ E
â€œ
Ï‰1 ÃÃ‘ F pÏ‰1q Ë† 1tX0â€œXnpÏ‰qu pÏ‰1q
â€°
.
(2.91)
If we ï¬x Ï‰ P â„¦, then in (2.91) everything is determined, and there should be no
ambiguity any more.
2.26. Remark. Fix n P N. The Ïƒ-ï¬eld Gn is generated by events of the form
tpX0, X1, . . . , Xnq â€œ ps0, s1, . . . , snqu .
Here ps0, s1, . . . , snq varies over Sn`1. It follows that
Gn â€œ Ïƒ
â£
tpX0, X1, . . . , Xnq â€œ ps0, s1, . . . , xnqu : ps0, s1, . . . , snq P Sn`1(
â€œ
â£
tpX0, X1, . . . , Xnq P Bu : B P Sbpn`1q(
â€œ Ïƒ pX0, X1, . . . , Xnq .
(2.92)
The Ïƒ-ï¬eld in (2.92) is the smallest Ïƒ-ï¬eld rendering all state variables Xj,
0 Ä j Ä n, measurable. It is noticed that Gn Ä‚ F.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
63 
Renewal theory and Markov chains
2.27. Remark. Next we discuss conditional expectations. Again let F : â„¦Ã‘ R
be a bounded stochastic variable. If we write Z â€œ E
â€œ
F
Ë‡Ë‡ Gn
â€°
, then we mean
the following:
(1) The stochastic variable Z is Gn-BR-measurable. This a qualitative as-
pect of the notion of conditional expectation.
(2) The stochastic variable Z possesses the property that E rF, Asâ€œE rZ, As
for all events A P Gn. This is the quantitative aspect of the notion of
conditional expectation.
Notice that the property in (2) is equivalent to the following one: the stochastic
variable Z satisï¬es the equality E
â€œ
F
Ë‡Ë‡ A
â€°
â€œ E
â€œ
Z
Ë‡Ë‡ A
â€°
for all events A P Gn.
2.28. Remark. Let G be a sub-Ïƒ-ï¬eld of F. The mapping F ÃÃ‘ E
â€œ
F
Ë‡Ë‡ G
â€°
is an
orthogonal projection from L2 pâ„¦, F, Pq onto L2 pâ„¦, G, Pq. Let F P L2 pâ„¦, F, Pq,
and put Z â€œ E
â€œ
F
Ë‡Ë‡ G
â€°
. In fact we have to verify the following conditions:
(1) Z P L2 pâ„¦, G, Pq;
(2) If G P L2 pâ„¦, G, Pq, then the following inequality is satisï¬ed:
E
â€œ
|F Â´ Z|2â€°
Ä E
â€œ
|F Â´ G|2â€°
.
This claim is left as an exercise for the reader. For more details on conditional
expectations see Section 1 in Chapter 1.
2.29. Remark. Next we will give an explicit formula for the conditional ex-
pectation in the setting of a enumerable discrete state space S.
Let Gn â€œ
Ïƒ pX0, X1, . . . , Xnq where Xj : â„¦Ã‘ S, 0 Ä j Ä n, are state variables with a
discrete countable state space S. In addition, let F : â„¦Ã‘ R be a bounded
stochastic variable. Then we have
E
â€œ
F
Ë‡Ë‡ Gn
â€°
â€œ
Ã¿
i0,...,inPS
E
â€œ
F
Ë‡Ë‡ X0 â€œ i0, . . . , Xn â€œ in
â€°
1tX0â€œi0u Â¨ Â¨ Â¨ 1tXnâ€œinu. (2.93)
Writing the conditional expectation in (2.93) in an explicit manner as a function
of Ï‰ yields
E
â€œ
F
Ë‡Ë‡ Gn
â€°
pÏ‰q
â€œ
Ã¿
i0,...,inPS
E
â€œ
F
Ë‡Ë‡ X0 â€œ i0, . . . , Xn â€œ in
â€°
1tX0â€œi0upÏ‰q Â¨ Â¨ Â¨ 1tXnâ€œinupÏ‰q.
(2.94)
From (2.93) and also (2.94) it is clear that the conditional expectation
E
â€œ
F
Ë‡Ë‡ Gn
â€°
is Gn-measurable.
2.30. Remark. Put G â€œ G8 â€œ Ïƒ pX0, . . . , Xn, . . .q â€œ Ïƒ
`
X
Ë˜
where X : â„¦Ã‘ SN
is the variable deï¬ned by X pÏ‰q â€œ pX0pÏ‰q, . . . , XnpÏ‰q, . . .q, Ï‰ P â„¦. Then
G â€œ G8
(2.95)
â€œ
â£â£
X P B
(
: B is measurable with respect to the product Ïƒ-ï¬eld on SN(
.
2.31. Remark. Let Ï„ : â„¦Ã‘ N Y t8u be a random variable. This random
variable is called a stopping time relative the ï¬ltration pGnqnPN, or, more brieï¬‚y,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
64 
Renewal theory and Markov chains
Ï„ is called a pGnqnPN-stopping time, provided that for every k P N an event of
the form tÏ„ Ä ku is Gk-measurable. The latter property is equivalent to the
following one. For every k P N the event tÏ„ â€œ ku is Gk-measurable. Note that
tÏ„ â€œ ku â€œ tÏ„ Ä ku z tÏ„ Ä k Â´ 1u, k P N, k Ä› 1, and tÏ„ Ä ku â€œ Yk
jâ€œ0 tÏ„ â€œ ju.
From these equalities it follows that Ï„ is a pGnqnPN-stopping time if and only if
for every k P N the event tÏ„ â€œ ku is Gk-measurable.
2.32. Remark. Let B be a subset of S. Important examples of stopping times
are
Ï„ 0
B â€œ inf tk Ä› 0 : Xk P Bu
on
Y8
kâ€œ0 tXk P Bu
and 8 elsewhere;
Ï„ 1
B â€œ inf tk Ä› 1 : Xk P Bu
on
Y8
kâ€œ1 tXk P Bu
and 8 elsewhere.
(2.96)
Similarly we also write Ï„ s
B â€œ inf tk Ä› s : Xk P Bu on the event Y8
kâ€œs tXk P Bu,
and Ï„ s
B â€œ 8 elsewhere. The time Ï„ 0
B is called the ï¬rst income time, and Ï„ 1
B is
called the ï¬rst hitting time, or the ï¬rst income time after 0.
We also notice that Ï„ 1
B â€œ min tk Ä› 1 : Xk P Bu on Y8
kâ€œ1 tXk P Bu and Ï„ 1
B â€œ 8
on X8
â„“â€œ1 tXâ„“P SzBu. In addition: 1 ` Ï„ 0
B Ë Ï‘1 â€œ Ï‘1
B.
2.33. Remark. Again let Ï„ : â„¦Ã‘ N Y t8u be a pGnqnPN-stopping time. The
Ïƒ-ï¬eld GÏ„ containing the information from the past of Ï„ is deï¬ned by
GÏ„ â€œ XkPN tA P F : A X tÏ„ Ä ku P Gku
â€œ Ïƒ pXj^Ï„ : j P Nq
(2.97)
where Xj^Ï„pÏ‰q â€œ Xj^Ï„pÏ‰qpÏ‰q, Ï‰ P â„¦.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
65 
Renewal theory and Markov chains
2.34. Remark. Let F be a stochastic variable. What is meant by F Ë Ï‘k and
F Ë Ï‘Ï„ on the event tÏ„ Äƒ 8u? Here k P N, and Ï„ is a pGnqnPN-stopping time.
For F â€œ Å›n
jâ€œ0 fj pXjq we write:
F Ë Ï‘k â€œ
n
Åº
jâ€œ0
fj pXjq Ë Ï‘k â€œ
n
Åº
jâ€œ0
fj pXj`kq ,
and on the event tÏ„ Äƒ 8u
F Ë Ï‘Ï„ â€œ
n
Åº
jâ€œ0
fj pXjq Ë Ï‘Ï„ â€œ
n
Åº
jâ€œ0
fj pXj`Ï„q .
(2.98)
2.35. Proposition. Let
Â´
T pnq
x,y
Â¯
px,yqPSË†S be a sequence of square matrices with
positive entries, possibly with inï¬nite countably many entries (when S is count-
able, not ï¬nite). Put
T 0
x,y â€œ I, T 1
x,y â€œ T p1q
x,y,
T n
x,y â€œ
Ã¿
s1,...,snPS
n`1
Åº
jâ€œ1
TsjÂ´1,sj,
s0 â€œ x,
sn`1 â€œ y.
(2.99)
The equalities in (2.99) are to be considered as matrix multiplications.
Fix
1 Ä n1 Äƒ Â¨ Â¨ Â¨ Äƒ nk Ä n, and let the measure space
`
Sk, bk
jâ€œ1S, Âµ0,x
n1,...,nk,n`1,y
Ë˜
,
px, yq P S Ë† S, n P N be determined by the equalities:
Å¼
Sk
n
Åº
jâ€œ1
fj psjq dÂµ0,s0
n1,...,nk,n`1,sn`1 ps1, . . . , skq
â€œ
Ã¿
ps1,...,skqPSk
k`1
Åº
jâ€œ1
T pnjÂ´njÂ´1q
sjÂ´1,sj
fj psjq ,
fj P L8 pS, Sq ,
(2.100)
where ps0, sn`1q â€œ px, yq P S Ë† S, n0 â€œ 0, and nk`1 â€œ n ` 1. Then for every
1 Ä j0 Ä n, and fj P L8 pE, Eq, 1 Ä j Ä n, this family satisï¬es the following
equality:
Å¼
Sn
n
Åº
jâ€œ1
fj psjq dÂµ0,s0
1,...,n,n`1,sn`1 ps1, . . . , snq
(2.101)
â€œ
Å¼
SnÂ´1
n
Åº
jâ€œ1, jâ€°j0
fj psjq dÂµ0,s0
n,sn`1 ps1, . . . , sj0Â´1, sj0`1, . . . , snq T 2
sj0Â´1,sj0`1
where T 2
x,y â€œ Å™
zPS T p1q
x,z T p1q
z,y for all px, yq P S Ë† S (matrix multiplication). Let
1 Ä n1 Äƒ Â¨ Â¨ Â¨ Äƒ nk Ä n, and put
Âµ0,x
n1,...,nk,n`1 pB0 Ë† Bq â€œ
Ã¿
yPS
1B0pxqÂµ0,x
n1,...,nk,n`1,y pBq ,
B0 P S, B P bkS.
(2.102)
Suppose that the matrices
Â´
T pnq
x,y
Â¯
px,yqPSË†S, n P N, are stochastic.
Then the
measures in (2.102) do not depend on n`1. Moreover, the following assertions
are equivalent:
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
66 
Renewal theory and Markov chains
(a) The family of measure spaces
â£`
Sk`1, bk`1S, Âµ0,x
n1,...,nk,n`1
Ë˜
: 1 Ä n1 Äƒ Â¨ Â¨ Â¨ Äƒ nk Ä n, n P N
(
(2.103)
is a consistent family of probability measure spaces.
(b) The family of measure spaces deï¬ned in (2.100) is consistent.
(c) For every n P N and px, yq P S Ë† S the equality T pnq
x,y â€œ T n
x,y holds.
Suppose that the family in (2.103) is a consistent family of probability spaces.
Then the corresponding process
tpâ„¦, F, PxqxPS , pXn : n P Nq , pÏ‘n, n P Nq , pS, Squ .
(2.104)
is a Markov chain if and only if for px, yq P S Ë† S and n, m P N the following
matrix multiplication equality holds:
T pn`mq
x,y
â€œ
`
Ã¿
zPS
T pnq
x,z T pmq
z,y â€œ
Ã¿
zPS
T n
x,zT m
z,y.
(2.105)
This means that
Px rX0 P B0, . . . , Xn P Bns â€œ 1B0pxqÂµ0,x
1,...,n,n`1 pB1 Ë† Â¨ Â¨ Â¨ Ë† Bnq ,
for Bj P S, 0 Ä j Ä n, and that the family in (2.104) possesses the Markov
property if and only (2.105) holds.
In addition, we have T pnq
x,y â€œ Px rXn â€œ ys, x, y P S; i.e. the quantities T pnq
x,y
represent the n time step transition probabilities from the state x to the state y.
2.36. Theorem. Let the notation be as in Theorem 2.22. The following asser-
tions are equivalent:
(1) For every s P S, for every bounded function f : S Ã‘ R, and for all
n P N the following equality holds Ps-almost surely:
Es
â€œ
f pXn`1q
Ë‡Ë‡ Gn
â€°
â€œ EXn rf pX1qs .
(2.106)
(2) For every bounded function f : S Ã‘ R, and for all n P N the following
equality holds P-almost surely:
E
â€œ
f pXn`1q
Ë‡Ë‡ Gn
â€°
â€œ EXn rf pX1qs .
(2.107)
2.37. Remark. From the proof it follows that in Theorem 2.36 we may replace
the stochastic variable f pX1q by any bounded stochastic variable Y : â„¦Ã‘ R.
At the same f pXn`1q â€œ f pX1q Ë Ï‘n has to be replaced by Y Ë Ï‘n.
2.38. Remark. Theorem 2.36 together with Remark 2.37 shows that through-
out in Theorem 2.22 we may replace the probability P with Ps for any s P S.
Consequently, we could have deï¬ned a time-homogeneous Markov chain as a
quadruple
tpâ„¦, F, PsqsPS , pXn : n P Nq , pÏ‘k, k P Nq , pS, Squ
satisfying the equivalent conditions in Theorem 2.22 with Ps, for all s P E,
instead of P.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
67 
Renewal theory and Markov chains
Proof of Theorem 2.36. (1) Ã¹Ã± (2) Let s P S, f : S Ã‘ R a bounded
function, and n P N. From (2.106) we infer
Es rf pXn`1q , As â€œ Es rEXn rf pX1qs , As
for all A P Gn.
(2.108)
From (2.108) we infer
E rf pXn`1q , A, X0 â€œ ss
â€œ E rEXn rf pXn`1qs , A, X0 â€œ ss
for all A P Gn, and s P S.
(2.109)
By summing over s P S in (2.109) we obtain
E rf pXn`1q , As â€œ E rEXn rf pXn`1qs , As
for all A P Gn.
(2.110)
From (2.110) the equality in (2.107) easily follows.
(2) Ã¹Ã± (1) Let f : S Ã‘ R and n P N be such that (2.107) holds. Then, since all
events of the form tX0 â€œ su, s P S, belong to Gn, (2.107) implies that (2.109)
holds for f and hence by dividing by P rX0 â€œ ss, for s P S, we obtain (2.108).
Hence (2.106) follows.
All this completes the proof of Theorem 2.36.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
68 
Renewal theory and Markov chains
The following theorem is similar to the formulation of Theorem 2.36 but now
with stopping times and having remark 2.37 taken into account:
2.39. Theorem. Let the notation be as in Theorem 2.22, and let Ï„ : â„¦Ã‘ r0, 8s
be a pGnqnPN-stopping time. The following assertions are equivalent:
(1) For every s P S, and for every bounded stochastic variable Y : â„¦Ã‘ R
the following equality holds Ps-almost surely on the event tÏ„ Äƒ 8u:
Es
â€œ
Y Ë Ï‘Ï„
Ë‡Ë‡ GÏ„
â€°
â€œ EXÏ„ rY s .
(2.111)
(2) For every bounded stochastic variable Y : â„¦Ã‘ R the following equality
holds P-almost surely on the event tÏ„ Äƒ 8u:
E
â€œ
Y Ë Ï‘Ï„
Ë‡Ë‡ GÏ„
â€°
â€œ EXÏ„ rY s .
(2.112)
2.40. Remark. Let Ï„ : â„¦Ã‘ NYt8u be a pGnqnPN-stopping time, and let A P GÏ„.
Let m P N Y t8u. Put Ï„m â€œ m1â„¦zA ` Ï„1A. Then Ï„m is a pGnqnPN-stopping time.
If PrAs Äƒ 1 and m â€œ 8, then Ï„m â€œ 8 on the event â„¦zA which is non-negligible.
2.41. Definition. Let â„¦be a set and let S be a collection of subsets of â„¦. Then
S is called a Dynkin system, if it has the following properties:
(a) â„¦P S;
(b) if A and B belong to S and if A Äš B, then AzB belongs to S;
(c) if pAn : n P Nq is an increasing sequence of elements of S, then the union
Å¤8
nâ€œ1 An belongs to S.
In the literature Dynkin systems are also called Î»-systems: see e.g. [3].
A
Ï€-system is a collection of subsets which is closed under ï¬nite intersections. A
Dynkin system which is also a Ï€-system is a Ïƒ-ï¬eld. The following result on
Dynkin systems, known as the Ï€-Î» theorem, gives a stronger result.
2.42. Theorem. Let M be a collection of subsets of â„¦, which is stable under
ï¬nite intersections, so that M is a Ï€-system on â„¦. The Dynkin system generated
by M coincides with the Ïƒ-ï¬eld generated by M.
Proof. Let D pMq be the smallest Dynkin-system containing M, i.e. D pMq
is the Dynkin-system generated by M. For all A P D pMq, we deï¬ne:
Î“pAq :â€œ tB P D pMq : A X B P D pMqu .
then we have
(1) if A belongs to M, M Ä‚ Î“pAq,
(2) for all A P M, Î“pAq is a Dynkin system on â„¦.
(3) if A belongs to M, then D pMq Ä‚ Î“pAq,
(4) if B belongs to D pMq, then M Ä‚ Î“pBq,
(5) for all B P D pMq the inclusion, D pMq Ä‚ Î“pBq holds.
It follows that D pMq is also a Ï€-system. It is esay to see that a Dynkin system
which is at the same time a Ï€-system is in fact a Ïƒ-ï¬eld (or Ïƒ-algebra). This
completes the proof of Theorem 2.42.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
69 
Renewal theory and Markov chains
2.43. Theorem. Let â„¦be a set and let M be a collection of subsets of â„¦, which
is stable (or closed) under ï¬nite intersections. Let H be a vector space of real
valued functions on â„¦satisfying:
(i) The constant function 1 belongs to H and 1A belongs to H for all
A P M;
(ii) if pfn : n P Nq is an increasing sequence of non-negative functions in H
such that f â€œ supnPN fn is ï¬nite (bounded), then f belongs to H.
Then H contains all real valued functions (bounded) functions on â„¦, that are
ÏƒpMq measurable.
Proof. Put D â€œ tA Ä â„¦: 1A P Hu.
Then by (i) â„¦belongs to D and
D Äš M. If A and B are in D and if B Äš A, then BzA belongs to D. If
pAn : n P Nq is an increasing sequence in D, then 1YAn â€œ supn 1An belongs to
D by (ii). Hence D is a Dynkin system, that contains M. Since M is closed
under ï¬nite intersection, it follows by Theorem 2.42 that D Äš ÏƒpMq. If f Ä› 0 is
measurable with respect to ÏƒpMq, then f â€œ sup
n 2Â´n Ã¿n2n
jâ€œ1 1tfÄ›j2Â´nu. Since the
subsets tf Ä› j2Â´nu, j, n P N, belong to ÏƒpMq, we see that f is a member of H.
Here we employed the fact that ÏƒpMq Ä D. If f is Ïƒ pMq-measurable, then we
write f as a diï¬€erence of two non-negative Ïƒ pMq-measurable functions.
â–¡
The previous theorems (Theorem 2.42 and Theorem 2.43) are used in the fol-
lowing form. Let â„¦be a set and let pSi, SiqiPI be a family of measurable spaces,
indexed by an arbitrary set I. For each i P I, let Mi denote a collection of
subsets of Si, closed under ï¬nite intersection, which generates the Ïƒ-ï¬eld Si,
and let fi : â„¦Ã‘ Si be a map from â„¦to Si. In this context the following two
propositions follow.
2.44. Proposition. Let M be the collection of all sets of the form Å
iPJ f Â´1
i
pAiq,
Ai P Mi, i P J, J Ä I, J ï¬nite. Then M is a collection of subsets of â„¦which is
stable under ï¬nite intersection and ÏƒpMq â€œ Ïƒ pfi : i P Iq.
2.45. Proposition. Let H be a vector space of real-valued functions on â„¦such
that:
(i) the constant function 1 belongs to H;
(ii) if phn : n P Nq is an increasing sequence of non-negative functions in H
such that h â€œ supn hn is ï¬nite (bounded), then h belongs to H;
(iii) H contains all products of the form Å›
iPJ 1Ai Ë fi, J Ä I, J ï¬nite, and
Ai P Mi, i P J.
Under these assumptions H contains all real-valued functions (bounded) func-
tions in Ïƒpfi : i P Iq.
The theorems 2.42 and 2.43, and the propositions 2.44 and 2.45 are called the
monotone class theorem.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
70 
Renewal theory and Markov chains
In the propositions 2.44 and 2.45 we may take Si â€œ S, Mi the collection of ï¬nite
subsets of Si, and fi â€œ Xi, i P I â€œ N.
3. More on Brownian motion
Further on in this book on stochastic processes we will discuss Brownian motion
in more detail. In fact we will consider Brownian motion as a Gaussian process,
as a Markov process, and as a martingale (which includes a discussion on ItË†o
calculus). In addition Brownian motion can be viewed as weak limit of a scaled
symmetric random walk. For this result we need a Functional Central Limit
Theorem (FCLT) which is a generalization of the classical central limit theorem.
2.46. Theorem (Multivariate Classical Central Limit Theorem). Let pâ„¦, F, Pq
be a probability space, and let tZn : n P Nu be a sequence of P-independent and
P-identically distributed random variables with values in Rd in L1 `
â„¦, F, P; RdË˜
.
Let Âµ â€œ E rZ1s, and let D be the dispersion matrix of Z1 (i.e. the variance-
covariance of the random vector Z1). Then there exists a centered Gaussian (or
multivariate normal) random vector X with dispersion matrix D such that the
sequence
Xn :â€œ Z1 ` Â¨ Â¨ Â¨ ` Zn Â´ nÂµ
?n
converges weakly (or in distribution) to a centered random vector X with dis-
persion matrix D as n Ã‘ 8. The latter means that lim
nÃ‘8 E rf pZnqs â€œ E rf pZqs
for all bounded continuous functions f : Rd Ã‘ R.
Notice that by a non-trivial density argument we only need to prove the equality
lim
nÃ‘8 E
â€
f
Ë†Z1 ` Â¨ Â¨ Â¨ ` Zn Â´ nÂµ
?n
Ë™È·
â€œ E rf pXqs
for all functions f of the form fpxq â€œ eÂ´iâŸ¨x,Î¾âŸ©, x P Rd, Î¾ P Rd.
Next let us give a (formal) deï¬nition of Brownian motion.
2.47. Definition. A one-dimensional Brownian motion with drift Âµ and diï¬€u-
sion coeï¬ƒcient Ïƒ2 is a stochastic process tXptq : t Ä› 0u with continuous sam-
ple paths having independent Gaussian increments with mean and variance of
an increment Xpt ` sq Â´ Xptq given by sÂµ â€œ E rXpt ` sq Â´ Xptqs and sÏƒ2 â€œ
E
â€œ
pXpt ` sq Â´ Xptqq2â€°
, s, t Ä› 0. If X0 â€œ x, then this Brownian is said to start
at x. A Brownian motion with drift Âµ â€œ 0, and Ïƒ2 â€œ 1 is called a standard
Brownian motion.
One of the problems is whether or not such a process exists. One way of resolv-
ing this problem is to put the Functional Central Limit Theorem at work. Let
us prepare for this approach. Let tZj : j P Nu be a sequence of centered inde-
pendent identically distributed real valued random variables in L1 pâ„¦, F, Pq with
variance Ïƒ2 â€œ E rZ2
1s. For example these variables could be Bernoulli variables
taking the values `Ïƒ and Â´Ïƒ with the same probability 1
2. Put S0 â€œ Z0 â€œ 0,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
71 
Renewal theory and Markov chains
Sn â€œ Z1 ` Â¨ Â¨ Â¨ , `Zn, n P N, n Ä› 1. Deï¬ne for each scale parameter n Ä› 1 the
stochastic process Xpnqptq by
Xpnqptq â€œ Stntu
?n â€œ
Å™tntu
kâ€œ0 Zk
?n
,
t Ä› 0.
(2.113)
Here tntu is the integer part of nt, i.e. the largest integer k for which k Ä nt Äƒ
k ` 1. The it is relatively easy to see that
E
â€œ
Xpnqptq
â€°
â€œ 0,
and
Var
`
Xpnqptq
Ë˜
â€œ E
â€œ
Xpnqptq2â€°
â€œ tÏƒ2.
(2.114)
Then the classical CLT (Central Limit Theorem) implies that there exists a
process tXptq : t Ä› 0u with the property that for every m P N, for every choice
pt1, . . . , tmq of m positive real numbers, and every bounded continuous function
f : Rm Ã‘ C the following limit equality holds:
lim
nÃ‘8 E
â€œ
f
`
Xpnqptq
Ë˜â€°
â€œ E rf pXptqqs .
(2.115)
The equality in (2.115) says the ï¬nite-dimensional distributions of the sequence
of processes
â£
Xpnqptq : t Ä› 0
(
nPN converges weakly to the ï¬nite-dimensional
distributions of the process tXptq : t Ä› 0u.
This limit should then be one-
dimensional Brownian motion with drift zero and variance Ïƒ2.
A posteriori
we know that Brownian motion should be P-almost surely continuous. How-
ever the processes
â£
Xpnqptq : t Ä› 0
(
nPN have jumps. It would be nice if we were
able to replace these processes which have jumps by processes without jumps.
Therefore we employ linear interpolation. This can be done as follows. We
introduce the following interpolating sequence of continuous processes:
r
Xpnqptq â€œ Stntu
?n ` pnt Â´ tntuq Ztntu`1
?n ,
t Ä› 0.
(2.116)
Let m and n be positive integers. Then on the half open interval
â€m
n , m ` 1
n
Ë™
the variable Xnptq is constant in time t at level Sm
n , while r
Xnptq changes linearly
from
Sm
n
at time t â€œ m
n to Sm`1
?n â€œ Sm
?n ` Zm`1
?n
at time t â€œ m ` 1
n
.
(2.117)
It can be proved that the sequence of stochastic processes
!
r
Xpnqptq : t Ä› 0
)
nPN
converges weakly to Brownian motion with drift Âµ and variance Ïƒ2. This is
the contents of the following FCLT (Functional Central Limit Theorem). The
following result also goes under the name â€œDonskerâ€™s invariance principleâ€: see,
e.g., [15] or [42].
2.48. Theorem (Functional Central Limit Theorem). Let
!
r
Xpnqptq : t P r0, Ts
)
,
n P N, and tXptq : t P r0, Tsu be stochastic processes possessing sample paths
which are P-almost surely continuous with the property that the ï¬nite-dimen-
sional distributions of the sequence
!
r
Xpnqptq : t P r0, Ts
)
nPN converge weakly to
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
72 
Renewal theory and Markov chains
those of tXptq : t P r0, Tsu.
Then the sequence
!
r
Xpnqptq : t P r0, Ts
)
nPN con-
verges weakly to tXptq : t P r0, Tsu if and only if for every Îµ Ä… 0 the following
equality holds:
lim
Î´Ã“0 sup
nPN
P
Â«
sup
0Äs,tÄT, |sÂ´t|ÄÎ´
Ë‡Ë‡Ë‡ r
Xpnqpsq Â´ r
Xpnqpsq
Ë‡Ë‡Ë‡ Ä› Îµ
ï¬€
â€œ 0.
(2.118)
This result is based on Prohorovâ€™s tightness theorem and the Arzela-Ascoli
characterization of compact subsets of Cr0, Ts.
2.49. Theorem (Prohorov theorem). Let pPn : n P Nq be a sequence of proba-
bility measures on a separable complete metrizable topological space S with Borel
Ïƒ-ï¬eld S. Then the following assertions are equivalent:
(i) For every Îµ Ä… 0 there exists a compact subset KÎµ of S such that
Pn rKÎµs Ä› 1 Â´ Îµ for all n P N.
(ii) Every subsequence of pPn : n P Nq has a subsequence which converges
weakly to a probability measure on pS, Sq.
A sequence pPnqn satisfying (i) (or (ii)) in Theorem 2.49 is called a Prohorov
set. Theorem 2.48 can be proved by applying Theorem 2.49 with Pn equal to
the P-distribution of the process
!
r
Xpnqptq : 0 Ä t Ä T
)
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
73 
Renewal theory and Markov chains
2.50. Theorem (Arzela-Ascoli). Endow Cr0, Ts with the topology of uniform
convergence. A subset A of Cr0, Ts has compact closure if and only if it has the
following properties:
(i) sup
Ï‰PA
|Ï‰p0q| Äƒ 8;
(ii) The subset A is equi-continuous in the sense that
lim
Î´Ã“0
sup
0Äs,tÄT, |sÂ´t|ÄÎ´
sup
Ï‰PA
|Ï‰psq Â´ Ï‰ptq| â€œ 0.
From (i) and (ii) it follows that sup
Ï‰PA
sup
sPr0,Ts
|Ï‰psq| Äƒ 8, and hence A is uniformly
bounded. The result which is relevant here reads as follows. It is the same as
Theorem T.8.4 in Bhattacharaya and Waymire [15].
2.51. Theorem. Let pPnqn be a sequence of probability measures on Cr0, Ts.
Then pPnqn is tight if and only if the following two conditions hold.
(i) For each Î· Ä… 0 there is a number B such that
Pn rÏ‰ P Cr0, Ts : |Ï‰p0q| Ä… Bs Äƒ Î·,
n â€œ 1, 2, . . .
(ii) For each Îµ Ä… 0, Î· Ä… 0, there is a 0 Äƒ Î´ Äƒ 1 such that
Pn
Â«
Ï‰ P Cr0, Ts :
sup
0Äs,tÄT, |sÂ´t|ÄÎ´
|Ï‰psq Â´ Ï‰ptq| Ä› Îµ
ï¬€
Ä Î·,
n â€œ 1, 2, . . .
Proof. If the sequence pPnqn is tight, then given Î· Ä… 0 there is a compact
subset K of C pr0, Tsq such that PnpKq Ä… 1 Â´ Î· for all n. By the Arzela-Ascoli
theorem (Theorem 2.50), if B Ä… supÏ‰PK |Ï‰p0q|, then
Pn rÏ‰ P Cr0, Ts : |Ï‰p0q| Ä› Bs Ä Pn rKcs Ä 1 Â´ p1 Â´ Î·q â€œ Î·.
Also given Îµ Ä… 0 select Î´ Ä… 0 such that sup
Ï‰PK
sup
0Äs,tÄT, |sÂ´t|ÄÎ´
|Ï‰psq Â´ Ï‰ptq| Äƒ Îµ. Then
Pn
Â«
Ï‰ P Cr0, Ts :
sup
0Äs,tÄT, |sÂ´t|ÄÎ´
|Ï‰psq Â´ Ï‰ptq| Ä› Îµ
ï¬€
Ä Pn rKcs Äƒ Î· for all n Ä› 1.
The converse goes as follows. Given Î· Ä… 0, ï¬rst select B using (i) such that
Pn rÏ‰ P C pr0, Tsq : |Ï‰p0q| Ä Bs Ä› 1 Â´ 1
2Î·, for n Ä› 1. Select Î´r Ä… 0 using (ii)
such that
Pn
Â«
Ï‰ P C pr0, Tsq :
sup
0Äs,tÄT, |sÂ´t|ÄÎ´
|Ï‰psq Â´ Ï‰ptq| Äƒ 1
r
ï¬€
Ä› 1 Â´ 2Â´pr`1qÎ·
for n Ä› 1.
Now take K to be the uniform closure of
8
Ä
râ€œ1
#
Ï‰ P C pr0, Tsq : |Ï‰p0q| Ä B,
sup
0Äs,tÄT, |sÂ´t|ÄÎ´
|Ï‰psq Â´ Ï‰ptq| Äƒ 1
r
+
.
Then PnpKq Ä… 1Â´Î· for n Ä› 1, and K is compact by the Arzela-Ascoli theorem.
This completes the proof Theorem 2.51.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
74 
Renewal theory and Markov chains
For convenience of the reader we formulate some limit theorems which are rel-
evant in the main text of this book. The formulations are taken from Stirzaker
[126].
For proofs the reader is also referred to Stirzaker.
For convenience
we also insert proofs which are based on Birkhoï¬€â€™s ergodic theorem. Deï¬ne
Sn â€œ Å™nÂ´1
kâ€œ0 Xk, where the variables tXkukPN Ä‚ L1 pâ„¦, F, Pq are independent and
identically distributed (i.i.d.). Then we have the following three classic results.
2.52. Theorem (Central limit theorem, standard version). If E rXks â€œ Âµ and
0 Äƒ var pXkq â€œ Ïƒ2 Äƒ 8, then
lim
nÃ‘8 P
â€Sn Â´ nÂµ
pnÏƒ2q1{2 Ä x
È·
â€œ Î¦pxq,
x P R,
where Î¦pxq is the standard normal distribution, i.e. Î¦pxq â€œ
1
?
2Ï€
Å¼ x
Â´8
eÂ´ 1
2 x2 dx.
Proof. Let f : R Ã‘ C be a bounded C2-function with a bounded second
derivative. Then by Taylorâ€™s formula (or by integration by parts) we have
fpyq â€œ fp0q ` yf 1p0q ` 1
2y2f 2p0q `
Å¼ 1
0
p1 Â´ sq y2 tf 2 psyq Â´ f 2p0qu ds. (2.119)
Put Yn,k â€œ Xk Â´ Âµ
Ïƒ?n . Inserting y â€œ Yn,k into (2.119) yields
f pYn,kq â€œ fp0q`Yn,kf 1p0q` 1
2Y 2
n,kf 2p0q`
Å¼ 1
0
p1 Â´ sq Y 2
n,k tf 2 psYn,kq Â´ f 2p0qu ds.
(2.120)
Then we take expectations in (2.120) to obtain:
E rf pYn,kqs â€œ fp0q ` 1
2nf 2p0q `
Å¼ 1
0
p1 Â´ sq E
â€œ
Y 2
n,k tf 2 psYn,kq Â´ f 2p0qu
â€°
ds.
(2.121)
Put
Îµnptq â€œ n
Å¼ 1
0
p1 Â´ sqE
â€œ
Y 2
n,1
`
1 Â´ eÂ´istYn,1Ë˜â€°
ds,
t P R,
and choose fpyq â€œ eÂ´ity. Observe that, uniformly in t on compact subsets of
R, limnÃ‘8 Îµnptq â€œ 0. Then, since the variables Yn,k, 1 Ä k Ä n, are i.i.d., from
(2.121) we get
E
â€œ
eÂ´itYn,kâ€°
â€œ 1 Â´ t2
2n ` t2Îµnptq
n
.
(2.122)
From (2.122) we infer
E
â€
eÂ´it Å™n
kâ€œ1 Yn,k
Ä±
â€œ
`
E
â€œ
eÂ´itYn,1â€°Ë˜n â€œ
Ë†
1 Â´ t2
2n ` t2Îµnptq
n
Ë™n
.
(2.123)
Let Y : â„¦Ã‘ R be a standard normally distributed random variable. From the
properties of the sequence tÎµnptqun and (2.123) we see that, for every 0 Äƒ R Äƒ 8,
lim
nÃ‘8 sup
|t|ÄR
!
E
â€
eÂ´it Å™n
kâ€œ1 Yn,k Â´ eÂ´itY Ä±)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
75 
Renewal theory and Markov chains
â€œ lim
nÃ‘8 sup
|t|ÄR
!
E
â€
eÂ´it Å™n
kâ€œ1 Yn,k
Ä±
Â´ eÂ´ 1
2 t2)
â€œ lim
nÃ‘8 sup
|t|ÄR
"
E
â€
eÂ´it Å™n
kâ€œ1 Yn,k
Ä±
Â´
Ë†
1 Â´ t2
2n ` t2Îµnptq
n
Ë™n*
â€œ 0.
(2.124)
The conclusion in Theorem 2.52 then follows from (2.124) together with LÂ´evyâ€™s
continuity theorem: see Theorem 5.42, and Theorem 5.43 assertions (9) and
(10).
â–¡
2.53. Theorem (Weak law of large numbers). If E rXks â€œ Âµ Äƒ 8, then for all
Îµ Ä… 0,
lim
nÃ‘8 P
â€Ë‡Ë‡Ë‡Ë‡
Sn
n Â´ Âµ
Ë‡Ë‡Ë‡Ë‡ Ä… Îµ
È·
â€œ 0.
For a proof of the following theorem see (the proof of) Theorem 5.60. It is
proved as a consequence of the (pointwise) ergodic theorem of Birkhoï¬€: see
Theorems 5.59 and 5.66, and Corollary 5.67.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
76 
Renewal theory and Markov chains
2.54. Theorem (Strong law of large numbers). The equality
lim
nÃ‘8
Sn
n â€œ Âµ,
holds P-almost surely
(2.125)
for some ï¬nite constant Âµ, if and only if E r|Xk|s Äƒ 8, and then Âµ â€œ E rX1s.
Moreover, the limit in (2.125) also exists in L1-sense.
We will show that Theorem 2.53 is a consequence of Theorem 2.54.
Proof of Theorem 2.53. Let Îµ Ä… 0 be arbitrary, and let tXkuk and Âµ
be as in Theorem 2.53. Then
P
â€Ë‡Ë‡Ë‡Ë‡
Sn Â´ nÂµ
n
Ë‡Ë‡Ë‡Ë‡ Ä› Îµ
È·
Ä 1
ÎµE
â€Ë‡Ë‡Ë‡Ë‡
Sn
n Â´ Âµ
Ë‡Ë‡Ë‡Ë‡
È·
.
(2.126)
By the L1-version of Theorem 2.54 it follows that the right-had side of (2.126)
converges to 0. This shows that Theorem 2.53 is a consequence of Theorem
2.54.
â–¡
The central limit theorem is the principal reason for the appearance of the nor-
mal (or â€œbell-shapedâ€) distribution in so many statistical and scientiï¬c contexts.
The ï¬rst version of this theorem was proved by Abraham de Moivre before 1733.
The laws of large numbers supply a solid foundation for our faith in the useful-
ness and good behavior of averages. In particular, as we have remarked above,
they support one of our most appealing interpretations of probability as long-
term relative frequency. The ï¬rst version of the weak law was proved by James
Bernoulli around 1700; and the ï¬rst form of the strong law by Emile Borel in
1909. We include proofs of these results in the form as stated. As noted above
a proof of Theorem 2.54 will be based on Birkhoï¬€â€™s ergodic theorem.
2.55. Remark. The following papers and books give information about the
central limit theorem in the context of Steinâ€™s method which stems from Stein
[124]: see Barbour and Hall [9], Barbour and Chen [8], Chen, Goldstein and
Shao [31], Nourdin and Peccati [101], Berckmoes et al [13]. This is a very inter-
esting and elegant method to prove convergence and give estimates for partial
sums of so-called standard triangular arrays (STA). It yields sharp estimates:
see the forthcoming paper [14].
4. Gaussian vectors.
The following theorem gives a deï¬nition of a Gaussian (or a multivariate nor-
mally distributed) vector purely in terms of its characteristic function (Fourier
transform of its distribution.
2.56. Theorem. Let pâ„¦, F, Pq be a probability space, and let X â€œ pX1, . . . , Xnq
be an Rn-valued Gaussian vector in the sense that there exists a vector Âµ :â€œ
pÂµ1, . . . , Âµnq P Rn and a symmetric square matrix Ïƒ :â€œ pÏƒj,kqn
j,kâ€œ1 such that the
characteristic function of the vector X is given by
E
â€œ
eÂ´iâŸ¨Î¾,XâŸ©â€°
â€œ eÂ´iâŸ¨Î¾,ÂµâŸ©Â´ 1
2
Å™n
j,kâ€œ1 Î¾jÎ¾kÏƒj,k for all Î¾ â€œ pÎ¾1, . . . , Î¾nq P Rn.
(2.127)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
77 
Renewal theory and Markov chains
Then for every 1 Ä j Ä n the variable Xj belongs to L2 pâ„¦, F, Pq, Âµj â€œ E rXjs,
and
Ïƒj,k â€œ cov pXj, Xkq â€œ E rpXj Â´ E rXjsq pXk Â´ E rXksqs .
(2.128)
Proof. Put Y â€œ X Â´ Âµ, and ï¬x Îµ Ä… 0. Then the equality in (2.127) is
equivalent to
E
â€œ
eÂ´iâŸ¨Î¾,Y âŸ©â€°
â€œ eÂ´ 1
2
Å™n
j,kâ€œ1 Î¾jÎ¾kÏƒj,k for all Î¾ â€œ pÎ¾1, . . . , Î¾nq P Rn.
(2.129)
From Cauchyâ€™s theorem and the equality
1
?
2Ï€
Å¼ 8
Â´8
eÂ´ 1
2 Î·2dÎ· â€œ 1 we obtain
eÂ´ 1
2 Îµ|Y |2 â€œ
1
`?
2Ï€Îµ
Ë˜n
Å¼
Rn eÂ´iâŸ¨Î·,Y âŸ©eÂ´ 1
2Îµ |Î·|2 dÎ· â€œ
1
`?
2Ï€
Ë˜n
Å¼
Rn eÂ´iâŸ¨?ÎµÎ·,Y âŸ©eÂ´ 1
2 |Î·|2 dÎ·.
(2.130)
From (2.129) and (2.130) we infer:
E
â€
eÂ´iâŸ¨Î¾,Y âŸ©eÂ´ 1
2 Îµ|Y |2Ä±
â€œ
1
`?
2Ï€
Ë˜n
Å¼
Rn E
â€
eÂ´iâŸ¨Î¾`?ÎµÎ·,Y âŸ©Ä±
eÂ´ 1
2 |Î·|2 dÎ·
(employ (2.129) with Î¾ ` ?ÎµÎ· instead of Î¾)
â€œ
1
`?
2Ï€
Ë˜n
Å¼
Rn eÂ´ 1
2
Å™n
j,kâ€œ1pÎ¾j`?ÎµÎ·jqpÎ¾k`?ÎµÎ·kqÏƒj,keÂ´ 1
2|Î·|2 dÎ·.
(2.131)
Next we take 1 Ä â„“1, â„“2 Ä n, and we diï¬€erentiate the right-hand side and
left-hand side of (2.131) with respect to Î¾â„“2 and the result with respect Î¾â„“1. In
addition we write a negative sign in front of this. Then we obtain:
E
â€
eÂ´iâŸ¨Î¾,Y âŸ©Yâ„“1Yâ„“2eÂ´ 1
2 Îµ|Y |2Ä±
â€œ
1
`?
2Ï€
Ë˜n
Å¼
Rn eÂ´ 1
2
Å™n
j,kâ€œ1pÎ¾j`?ÎµÎ·jqpÎ¾k`?ÎµÎ·kqÏƒj,keÂ´ 1
2 |Î·|2
Â¨
ËÏƒâ„“1,â„“2 ` Ïƒâ„“2,â„“1
2
Â´
Ëœ nÃ¿
jâ€œ1
`
Î¾j ` ?ÎµÎ·j
Ë˜ Ïƒj,â„“2 ` Ïƒâ„“1,j
2
Â¸2Ë›
â€šdÎ·.
(2.132)
Inserting Î¾ â€œ 0 into (2.132) yields:
E
â€
Yâ„“1Yâ„“2eÂ´ 1
2 Îµ|Y |2Ä±
â€œ
1
`?
2Ï€
Ë˜n
Å¼
Rn eÂ´ 1
2 Îµ Å™n
j, kâ€œ1 Î·jÎ·kÏƒj,keÂ´ 1
2 |Î·|2
Â¨
ËÏƒâ„“1,â„“2 ` Ïƒâ„“2,â„“1
2
Â´ Îµ
Ëœ nÃ¿
jâ€œ1
Î·j
Ïƒj,â„“2 ` Ïƒâ„“1,j
2
Â¸2Ë›
â€šdÎ·. (2.133)
First assume that â„“1 â€œ â„“2 â€œ â„“. Then the left-hand side of (2.133) increases to
E rY 2
â„“s, and the right-hand side increases to
1
`?
2Ï€
Ë˜n
Å¼
Rn eÂ´ 1
2 |Î·|2 dÎ· Ïƒâ„“,â„“â€œ Ïƒâ„“,â„“if Îµ
decreases to zero. Consequently, Yâ„“P L2 pâ„¦, F, Pq and E rY 2
â„“s â€œ Ïƒâ„“,â„“, 1 Ä â„“Ä n.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
78 
Renewal theory and Markov chains
It follows that Yâ„“belongs to L1 pâ„¦, F, Pq, and that we also have that Yâ„“1Yâ„“2 P
L1 pâ„¦, F, Pq. By applying the same procedure as above we also obtain that
E rYâ„“1Yâ„“2s â€œ Ïƒâ„“1,â„“2 ` Ïƒâ„“2,â„“1
2
â€œ Ïƒâ„“1,â„“2.
(2.134)
In (2.134) we employed the symmetry of the matrix pÏƒâ„“1,â„“2qn
â„“1,â„“2â€œ1. Again we ï¬x
1 Ä â„“Ä n, and we diï¬€erentiate the equality in (2.131) with respect to Î¾â„“to
obtain
iE
â€
eÂ´iâŸ¨Î¾,Y âŸ©Yâ„“eÂ´ 1
2 Îµ|Y |2Ä±
â€œ
1
`?
2Ï€
Ë˜n
Å¼
Rn dÎ· eÂ´ 1
2
Å™n
j,kâ€œ1pÎ¾j`?ÎµÎ·jq `
Î¾k ` ?ÎµÎ·k
Ë˜
eÂ´ 1
2 |Î·|2
nÃ¿
jâ€œ1
`
Î¾j ` ?ÎµÎ·j
Ë˜ Ïƒj,â„“` Ïƒâ„“,j
2
.
(2.135)
In (2.135) we set Î¾ â€œ 0, and we let Îµ Ã“ 0 to obtain E rYâ„“s â€œ 0, and hence Xâ„“P
L1 pâ„¦, F, Pq and E rXâ„“s â€œ Âµâ„“. This completes the proof of Theorem 2.56.
â–¡
5. Radon-Nikodym Theorem
We begin by formulating a convenient version of Radon-Nikodymâ€™s theorem.
For a proof the reader is referred to Bauer [10] or Stroock [130].
2.57. Theorem (Radon-Nikodym theorem). Let pâ„¦, F, Âµq be a Ïƒ-ï¬nite measure
space, and let Î½ be a ï¬nite measure on F. Suppose that Î½ is absolute continuous
relative to Âµ, i.e. ÂµpBq â€œ 0 implies Î½pBq â€œ 0. Then there exists a function
f P L1 pâ„¦, F, Âµq such that Î½pBq â€œ
ÅŸ
B f dÂµ for all B P F. In particular the
function f is F-measurable.
The following corollary follows from Theorem 2.57 by taking F â€œ B, Âµ the
measure P conï¬ned to B, and Î½pBq â€œ E rX, Bs, B P B.
2.58. Corollary. Let pâ„¦, A, Pq be a probability space, and let B be a subï¬eld
(i.e. a sub-Ïƒ-ï¬eld) of A. Let X be a stochastic variable in L1 pâ„¦, A, Pq. Then
there exists a B-measurable variable Z on â„¦with the following properties:
(1) (qualitative property) the variable Z is B-measurable;
(2) (quantitative property) for every B P B the equality E rZ, Bsâ€œE rX, Bs
holds.
The variable Z is called the conditional expectation of X, and is denoted by
Z â€œ E
â€œ
X
Ë‡Ë‡ B
â€°
. The existence is guaranteed by the Radon-Nikodym theorem.
6. Some martingales
Let E be a locally compact Hausdorï¬€space which is second countable, and let
tpâ„¦, F, Pxq , pXptq, t Ä› 0q , pÏ‘t, t Ä› 0q , pE, Equ
(2.136)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
79 
Renewal theory and Markov chains
be a time-homogeneous strong Markov process with right-continuous paths,
which also have left limits in the state space E on their life time. Put Sptqfpxq â€œ
Ex rf pXptqqs, f P C0pEq, and assume that Sptqf P C0pEq whenever f P C0pEq.
Here a real or complex valued function f belongs to C0pEq provided that it is
continuous and that for every Îµ Ä… 0 the subset tx P E : |fpxq| Ä› Îµu is compact
in E. Let the operator L be the generator of this process. This means that
its domain DpLq consists of those functions f P C0pEq for which the limit
Lf â€œ lim
tÃ“0
Sptqf Â´ f
t
exists in C0pEq equipped with the supremum norm, i.e.
}f}8 â€œ supxPE |fpxq|, f P C0pEq. The Markov property of the process in (2.136)
together with the right continuity of paths implies that the family tSptq : t Ä› 0u
is a Feller, or, more properly, a Feller-Dynkin semigroup.
(1) The semigroup property can be expressed as follows:
S pt1 ` t2q â€œ S pt1q S pt2q ,
t1, t2 Ä› 0,
Sp0q â€œ I.
(2) Moreover, the right-continuity of paths implies
lim
tÃ“0 Sptqfpxq â€œ lim
tÃ“0 Ex rf pXptqqs â€œ Ex rf pXp0qqs â€œ fpxq,
f P C0pEq.
(3) In addition, if 0 Ä f Ä 1, then 0 Ä Sptqf Ä 1.
A semigroup with the properties (1), (2) and (3) is a called a Feller, or Feller-
Dynkin semigroup. In fact, it can be proved that a Feller-Dynkin semigroup
tSptq : t Ä› 0u satisï¬es
lim
sÃ‘t, sÄ…0 }Spsqf Â´ Sptqf}8 â€œ 0,
t Ä› 0,
f P C0pEq.
Let tSptq : t Ä› 0u be a Feller-Dynkin semigroup. Then it can be shown that
there a exists a Markov process, as in (2.136) with right-continuous paths such
that Sptqfpxq â€œ Ex rf pXptqqs, f P C0pEq, t Ä› 0. For details, see Blumenthal
and Getoor [20]. Similar results are true for states spaces which are Polish; see,
e.g., [146].
Let t ÃÃ‘ Mptq, t Ä› 0, be an adapted right-continuous multiplicative process,
i.e. Mp0q â€œ 1 and MpsqMptq Ë Ï‘s â€œ Mps ` tq, s, t Ä› 0. Put SMptqfpxq â€œ
Ex rMptqf pXptqqs, f P C0pEq, t Ä› 0. Assume that the operators SMptq leave
the space C0pEq invariant, so that SMptqf belongs to C0pEq whenever f P
C0pEq. Then the family tSMptq : t Ä› 0u has the semigroup property SMps`tq â€œ
SMpsqSMptq, s, t Ä› 0, and limtÃ“0 SMptqfpxq â€œ fpxq, t Ä› 0, f P C0pEq. If, in ad-
dition, for every f P C0pEq there exists a Î´ Ä… 0 such that sup0ÄtÄÎ´ }SMptqf}8 Äƒ
8, then
lim
tÃ“0 }SMptqf Â´ f}8 â€œ 0,
f P C0pEq.
(2.137)
Moreover, there a exists a closed densely deï¬ned linear operator LM such that
LMf â€œ C0pEq- lim
tÃ“0
SMptqf Â´ f
t
(2.138)
for f P D pLMq, the domain of LM. If Mptq â€œ 1, then LM â€œ L.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
80 
Renewal theory and Markov chains
2.59. Proposition. The following processes are Px-martingales:
t ÃÃ‘ Mptqf pXptqq Â´ Mp0qfpXp0qq Â´
Å¼ t
0
MpsqLMf pXpsq dsq ,
t Ä› 0, f P D pLMq ,
(2.139)
s ÃÃ‘ MpsqEXpsq rMpt Â´ sqf pXpt Â´ sqqs , 0 Ä s Ä t, f P C0pEq,
(2.140)
s ÃÃ‘ MpsqEXpsq rMpt Â´ s Â´ uqp pu, Xpt Â´ s Â´ uq, yqs , 0 Ä s Ä t Â´ u.
(2.141)
In (2.141) it is assumed that there exists a â€œreferenceâ€ measure m on the Borel
ï¬eld E together with an density function ppt, x, yq, pt, x, yq P p0, 8q Ë† E Ë† E
such that Ex rf pXptqqs â€œ
ÅŸ
p pt, x, yq fpyq dmpyq for all f P C0pEq and for all
x P E and all t Ä… 0. From the semigroup property it follows that pps ` t, x, yq â€œ
ÅŸ
pps, x, zqppt, z, yqdmpzq for m-almost all y P E. Assuming that mpOq Ä… 0
for all non-empty open subsets of E, and that the function pt, x, yq ÃÃ‘ ppt, x, yq
is continuous on p0, 8q Ë† E Ë† E, it follows that the equality pps ` t, x, yq â€œ
ÅŸ
pps, x, zqppt, z, yqdmpzq holds for s, t Ä… 0 and for all x, y P E.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
81 
Renewal theory and Markov chains
The following corollary is the same as Proposition 2.59 with M â€œ 1.
2.60. Corollary. The following processes are Px-martingales:
t ÃÃ‘ f pXptqq Â´ fpXp0qq Â´
Å¼ t
0
Lf pXpsq dsq ,
t Ä› 0,
f P D pLq ,
(2.142)
s ÃÃ‘ EXpsq rf pXpt Â´ sqqs , 0 Ä s Ä t, f P C0pEq,
(2.143)
s ÃÃ‘ p pt Â´ s, Xpsq, yq , 0 Ä s Äƒ t.
(2.144)
Like in Proposition 2.59 in (2.144) it is assumed that there exists a â€œreferenceâ€
strictly positive Borel measure m such that for a (unique) continuous density
function ppt, x, yq the identity Ex rf pXptqqs â€œ
ÅŸ
p pt, x, yq fpyq dmpyq holds for
all f P C0pEq and for all x P E and all t Ä… 0.
2.61. Lemma. Let the continuous density be as in Proposition 2.59, and let
z P E. Then the following equality holds for all 0 Ä s Äƒ t and for all y P E:
Ez rp pt Â´ s, Xpsq, yqs â€œ ppt, x, yq.
(2.145)
Proof of Lemma 2.61. Let the notation be as in Lemma 2.61. Then by
the identity of Chapman-Kolmogorov we have
Ez rp pt Â´ s, Xpsq, yqs â€œ
Å¼
p ps, z, wq ppt Â´ s, w, yqdmpwq â€œ ppt, x, yq.
(2.146)
The equality in (2.146) is the same as the one in (2.145), which completes the
proof of Lemma 2.61.
â–¡
Proof of Proposition 2.59. First let f belong to the domain of LM,
and let t2 Ä… t1 Ä› 0. Then we have
Ex
â€
M pt2q f pX pt2qq Â´ Mp0qf pXp0qq Â´
Å¼ t2
0
MpsqLMf pXpsqq ds
Ë‡Ë‡ Ft1
È·
Â´ M pt1q f pX pt2qq ` Mp0qf pXp0qq `
Å¼ t1
0
MpsqLMf pXpsqq ds
â€œ Ex
â€
M pt1q
Ë†
M pt2 Â´ t1q f pX pt2 Â´ t1qq Â´ Mp0qf pXp0qq
Â´
Å¼ t2Â´t1
0
MpsqLMf pXpsqq ds
Ë™
Ë Ï‘t1
Ë‡Ë‡ Ft1
È·
(Markov property)
â€œ M pt1q EXpt1q
â€
M pt2 Â´ t1q f pX pt2 Â´ t1qq Â´ Mp0qf pXp0qq
Â´
Å¼ t2Â´t1
0
MpsqLMf pXpsqq ds
È·
(deï¬nition of the operator SMptq; put z â€œ X pt1q, and t â€œ t2 Â´ t1)
â€œ M pt1q
Ë†
SM ptq fpzq Â´ Ez rMp0qfpXp0qqs Â´
Å¼ t
0
SMpsqLMfpzq ds
Ë™
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
82 
Renewal theory and Markov chains
â€œ M pt1q
Ë†
SM ptq fpzq Â´ Ez rMp0qf pXp0qqs Â´
Å¼ t
0
B
BsSMpsqfpzq ds
Ë™
â€œ M pt1q pSM ptq fpzq Â´ Ez rMp0qf pXp0qqs Â´ SMptqfpzq ` SMp0qfpzqq â€œ 0.
(2.147)
The equalities in (2.147) show the equality in (2.139).
Let f P C0pEq and t Ä… 0. In order to show that the process
s ÃÃ‘ MpsqEXpsq rMpt Â´ sqf pXpt Â´ sqqs
is a Px-martingale we proceed as follows:
MpsqEXpsq rMpt Â´ sqf pXpt Â´ sqqs
(Markov property)
â€œ MpsqEx
â€œ
Mpt Â´ sq Ë Ï‘sf pXpt Â´ sqq Ë Ï‘s
Ë‡Ë‡ Fs
â€°
â€œ Ex
â€œ
MpsqMpt Â´ sq Ë Ï‘sf pXptqq
Ë‡Ë‡ Fs
â€°
â€œ Ex
â€œ
Mptqf pXptqq
Ë‡Ë‡ Fs
â€°
.
(2.148)
It is clear that the process in (2.148) is a martingale. This proves that the
process in (2.140) is a martingale. A similar argument shows the equality:
MpsqEXpsq rMpt Â´ s Â´ uqp pu, Xpt Â´ s Â´ uq, yqs
â€œ Ex
â€œ
Mpt Â´ uqp pu, Xpt Â´ uq, yq
Ë‡Ë‡ Fs
â€°
, 0 Ä s Äƒ t Â´ u.
(2.149)
Again it is clear that the process in (2.149) as a function of s is a Px-martingale.
Altogether this proves Proposition 2.59.
â–¡
Proof of Corollary 2.60. The fact that the processes in (2.142) and
(2.143) are Px-martingales is an immediate consequence of (2.139) and (2.140)
respectively by inserting MpÏq â€œ 1 for all 0 Ä Ï Ä t. If MpÏq â€œ 1 for all
0 Äƒ Ï Äƒ t, then by Lemma 2.61 we get
MpsqEXpsq rMpt Â´ s Â´ uqp pu, Xpt Â´ s Â´ uq, yqs
â€œ EXpsq rp pu, Xpt Â´ s Â´ uq, yqs â€œ p pt Â´ s, Xpsq, yq .
(2.150)
On the other hand by the Markov property we also have:
EXpsq rp pu, Xpt Â´ s Â´ uq, yqs â€œ Ex
â€œ
p pu, Xpt Â´ uq, yq
Ë‡Ë‡ Fs
â€°
.
(2.151)
As a consequence of (2.150) and (2.151) we see that the process in (2.144) is a
martingale. This completes the proof of Corollary 2.60.
â–¡
2.62. Remark. In general the process s ÃÃ‘ p pt Â´ s, Xpsq, yq, 0 Ä s Äƒ t, is not a
closed martingale. In many concrete examples we have lim
sÃ’t,sÄƒt p pt Â´ s, Xpsq, yq â€œ
0, Px-almost surely, on the one hand, and Ex rp pt Â´ s, Xpsq, yqs â€œ p pt, x, yq Ä…
0 on the other.
For an example of this situation take d-dimensional Brow-
nian motion.
By Scheï¬€Â´eâ€™s theorem it follows that the Px-martingale s ÃÃ‘
p pt Â´ s, Xpsq, yq, 0 Ä s Äƒ t, can not be a closed martingale. If it were, then
there would exist an Ft-measurable variable Fptq â€œ limsÃ’,sÄƒt p pt Â´ s, Xpsq, yq
with the property that p pt Â´ s, Xpsq, yq â€œ Ex
â€œ
Fptq
Ë‡Ë‡ Fs
â€°
. Since Fptq â€œ 0, Px-
almost surely, this is a contradiction.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
83 
Renewal theory and Markov chains
In the following corollary we consider a special multiplicative process: Mpsq â€œ
1tTÄ…su, where T is a terminal stopping time, i.e. T â€œ s ` T Ë Ï‘s, Px-almost
surely, on the event tT Ä… su for all s Ä… 0 and for all x P E.
2.63. Corollary. The following processes are Px-martingales:
t ÃÃ‘ 1tTÄ…tuf pXptqq Â´ 1tTÄ…0ufpXp0qq Â´
Å¼ t^T
0
LMf pXpsq dsq ,
t Ä› 0,
f P D pLMq ,
(2.152)
s ÃÃ‘ 1tTÄ…suEXpsq rf pXpt Â´ sqq , T Ä… t Â´ ss , 0 Ä s Ä t, f P C0pEq,
(2.153)
s ÃÃ‘ 1tTÄ…su
`
p pt Â´ s, Xpsq, yq Â´ EXpsq rp pt Â´ s Â´ T, XpTq, yq , T Äƒ t Â´ ss
Ë˜
,
0 Ä s Äƒ t.
(2.154)
In (2.141) it is assumed that there exists a â€œreferenceâ€ measure m on the Borel
ï¬eld E together with an density function ppt, x, yq, pt, x, yq P p0, 8qË†E Ë†E such
that Ex rf pXptqqs â€œ
ÅŸ
p pt, x, yq fpyq dmpyq for all f P C0pEq and for all x P E
and all t Ä… 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
84 
Renewal theory and Markov chains
It is noticed that the deï¬nition of LMfpxq is only deï¬ned pointwise, and that
for certain points x P E the limit
LMfpxq:â€œ lim
tÃ“0
Ex rMptqf pXptqqs Â´ Ex rMp0qf pXp0qqs
t
does not even exist.
A good example is obtained by taking for T the exit
time from an open subset U: T â€œ Ï„U â€œ inf ts Ä… 0 : Xpsq P EzUu.
If the
lim
tÃ“0
Px rT Ä ts
t
â€œ 0 for all x P U, then LMfpxq â€œ Lfpxq for x P U.
Proof of Corollary 2.63. It is only (2.154) which needs some explana-
tion; the others are direct consequences of Proposition 2.59. To this end we ï¬x
0 Äƒ u Äƒ t. Then by (2.141) the process:
s ÃÃ‘ 1tTÄ…suEXpsq rp pu, Xpt Â´ s Â´ uq, yq , T Ä… t Â´ s Â´ us
is a martingale on the closed interval r0, t Â´ us. Next we rewrite
EXpsq rp pu, Xpt Â´ s Â´ uq, yq , T Ä… t Â´ s Â´ us
â€œ EXpsq rp pu, Xpt Â´ s Â´ uq, yqs Â´ EXpsq rp pu, Xpt Â´ s Â´ uq, yq , T Ä t Â´ s Â´ us
(2.155)
(the process Ï ÃÃ‘ p pt Â´ s Â´ Ï, XpÏq, yq is Pz-martingale with z â€œ Xpsq; put
u â€œ t Â´ s in the ï¬rst term, and u â€œ t Â´ s Â´ T in the second term of the
right-hand side of (2.155))
â€œ EXpsq rp pt Â´ s, Xp0q, yqs Â´ EXpsq rp pt Â´ s Â´ T, XpTq, yq , T Ä t Â´ s Â´ us .
(2.156)
By letting u Ã“ 0 in (2.156) and using (2.141) of Proposition 2.59 we obtain that
the process in (2.154) is a Px-martingale. This completes the proof of Corollary
2.63.
â–¡
Next let
â£
pâ„¦, F, Pxq , pBptq, t Ä› 0q , pÏ‘t, t Ä› 0q ,
`
Rd, BRd
Ë˜(
be the Markov process of Brownian motion. Another application of martingale
theory is the following example. Let U be an open subset of Rd with smooth
enough boundary BU (C1 will do), and let f : BU Ã‘ R be a bounded continuous
function on the boundary BU of U. Let u : U Ã‘ R be a continuous function
such that upxq â€œ fpxq for x P BU and such that âˆ†upxq â€œ 0 for x P U. Let Ï„U
be the ï¬rst exit time from U: Ï„U â€œ inf
â£
s Ä… 0 : Bpsq P RdzU
(
. Then
upxq â€œ Ex rf pB pÏ„Uqq : Ï„U Äƒ 8s ` lim
tÃ‘8 Ex ru pB ptqq : Ï„U â€œ 8s .
(2.157)
Notice that the ï¬rst expression in (2.157) makes sense, because it can be proved
that Brownian motion is Px-almost surely continuous for x P Rd. The proof
uses the following facts: stopped martingales are again martingales, and the
processes
t ÃÃ‘ f pBptqq Â´ f pBp0qq Â´ 1
2
Å¼ t
0
âˆ†f pBpsqq ds,
f P Cb
`
RdË˜
, âˆ†f P Cb
`
RdË˜
,
(2.158)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
85 
Renewal theory and Markov chains
are martingales. The fact that a process of the form (2.158) is a martingale
follows from (2.142) in Corollary 2.60. It can also be proved using the equality
B
Btpd pt, x, yq â€œ 1
2âˆ†ypd pt, x, yq
(2.159)
where
pd pt, x, yq â€œ
1
b
p2Ï€tqdeÂ´ |xÂ´y|2
2t .
A proof of (2.158) runs as follows. Pick t2 Ä… t1 Ä› 0 en a function f P Cb
`
RdË˜
,
such that âˆ†f also belongs to Cb
`
RdË˜
. Then we have:
Ex
â€
f pB pt2qq Â´ f pB p0qq Â´ 1
2
Å¼ t2
0
âˆ†f pBpsqq ds
Ë‡Ë‡ Ft1
È·
Â´ f pB pt1qq ` f pB p0qq ` 1
2
Å¼ t1
0
âˆ†f pBpsqq ds
â€œ Ex
â€Ë†
f pB pt2 Â´ t1qq Â´ f pB p0qq Â´ 1
2
Å¼ t2Â´t1
0
âˆ†f pBpsqq ds
Ë™
Ë Ï‘t1
Ë‡Ë‡ Ft1
È·
(Markov property of Brownian motion)
â€œ EBpt1q
â€
f pB pt2 Â´ t1qq Â´ f pB p0qq Â´ 1
2
Å¼ t2Â´t1
0
âˆ†f pBpsqq ds
È·
(put z â€œ B pt1q, and t â€œ t2 Â´ t1)
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs Â´ 1
2
Å¼ t
0
Ez râˆ†f pBpsqqs ds
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs Â´ 1
2
Å¼ t
0
Å¼
Rd pd ps, z, yq âˆ†f pyq dy ds
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs Â´ lim
ÎµÃ“0
1
2
Å¼ t
Îµ
Å¼
Rd pd ps, z, yq âˆ†f pyq dy
(integration by parts)
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs Â´ lim
ÎµÃ“0
Å¼ t
Îµ
Å¼
Rd
1
2âˆ†ypd ps, z, yq f pyq dy ds
(use the equality in (2.159))
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs Â´ lim
ÎµÃ“0
Å¼ t
Îµ
Å¼
Rd
B
Bspd ps, z, yq f pyq dy ds
(interchange integration and diï¬€erentiation)
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs Â´ lim
ÎµÃ“0
Å¼ t
Îµ
B
Bs
Å¼
Rd pd ps, z, yq f pyq dy ds
(fundamental rule of calculus)
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
86 
Renewal theory and Markov chains
Â´ lim
ÎµÃ“0
Ë†Å¼
Rd pd pt, z, yq f pyq dy Â´
Å¼
Rd pd pÎµ, z, yq f pyq dy
Ë™
â€œ Ez rf pBptqqs Â´ Ez rf pBp0qqs Â´ Ez rf pBptqqs ` lim
ÎµÃ“0 Ez rf pBpÎµqqs
â€œ lim
ÎµÃ“0 Ez rf pBpÎµqqs Â´ Ez rf pBp0qqs â€œ 0.
(2.160)
From Doobâ€™s optional sampling theorem it follows that processes of the form
t ÃÃ‘ f pB pÏ„U ^ tqq Â´ f pBp0qq Â´ 1
2
Å¼ Ï„U^t
0
âˆ†f pBpsqq ds,
f P Cb
`
RdË˜
, (2.161)
f P Cb
`
RdË˜
, âˆ†f P Cb
`
RdË˜
, are Px-martingales for x P U. We can apply this
property to our harmonic function u. It follows that the process
t ÃÃ‘ u pB pÏ„U ^ tqqÂ´u pBp0qqÂ´ 1
2
Å¼ Ï„U^t
0
âˆ†u pBpsqq ds â€œ u pB pÏ„U ^ tqqÂ´u pBp0qq
(2.162)
is a martingale. Consequently, from (2.162) we get
upxq â€œ u pBp0qq â€œ Ex ru pB pÏ„U ^ tqqs
â€œ Ex ru pB pÏ„U ^ tqq , Ï„U Ä ts ` Ex ru pB pÏ„U ^ tqq , Ï„U Ä… ts
â€œ Ex ru pB pÏ„Uqq , Ï„U Ä ts ` Ex ru pBptqq , Ï„U Ä… ts
(2.163)
In (2.163) we let t Ã‘ 8 to obtain the equality in (2.157).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
87 
Renewal theory and Markov chains
2.64. Proposition. Let t ÃÃ‘ M1ptq and t ÃÃ‘ M2ptq be two continuous martin-
gales in L2 pâ„¦, F, Pq with covariation process t ÃÃ‘ âŸ¨M1, M2âŸ©ptq, so that in partic-
ular the process t ÃÃ‘ M1ptqM2ptq Â´ âŸ¨M1, M2âŸ©ptq is a martingale in L1 pâ„¦, F, Pq.
Then the process
t ÃÃ‘ pM1ptq Â´ M1psqq pM2ptq Â´ M2psqq Â´ âŸ¨M1, M2âŸ©ptq ` âŸ¨M1, M2âŸ©psq,
t Ä› s,
(2.164)
is a martingale.
In fact by ItË†o calculus we have the following integration by parts formula:
pM1ptq Â´ M1psqq pM2ptq Â´ M2psqq
â€œ
Å¼ t
s
pM1pÏq Â´ M1psqq dM2pÏq `
Å¼ t
s
pM2pÏq Â´ M2psqq dM1pÏq
` âŸ¨M1, M2âŸ©ptq Â´ âŸ¨M1, M2âŸ©psq,
t Ä› s.
(2.165)
Proof of Proposition 2.64. Fix t2 Ä… t1 Ä› s. Then we calculate:
E
â€œ
pM1 pt2q Â´ M1 psqq
`
M2 pt2q Â´ M2 psq
Ë‡Ë‡ Ft1
Ë˜â€°
Â´ E
â€œ
âŸ¨M1, M2âŸ©pt2q Â´ âŸ¨M1, M2âŸ©psq
Ë‡Ë‡ Ft1
â€°
Â´ pM1 pt1q Â´ M1 psqq pM2 pt1q Â´ M2 psqq ` âŸ¨M1, M2âŸ©pt1q Â´ âŸ¨M1, M2âŸ©psq
â€œ E
â€œ
pM1 pt2q Â´ M1 psqq pM2 pt2q Â´ M2 psqq
Ë‡Ë‡ Ft1
â€°
Â´ E
â€œ
âŸ¨M1, M2âŸ©pt2q Â´ âŸ¨M1, M2âŸ©pt1q
Ë‡Ë‡ Ft1
â€°
Â´ pM1 pt1q Â´ M1 psqq pM2 pt1q Â´ M2 psqq
â€œ E rpM1 pt2q Â´ M1 pt1q ` M1 pt1q Â´ M1 psqq
pM2 pt2q Â´ M2 pt1q ` M2 pt1q Â´ M2 psqq
Â´ âŸ¨M1, M2âŸ©pt2q ` âŸ¨M1, M2âŸ©pt1q
Ë‡Ë‡ Ft1
â€°
Â´ pM1 pt1q Â´ M1 psqq pM2 pt1q Â´ M2 psqq
â€œ E
â€œ
pM1 pt2q Â´ M1 pt1qq pM2 pt2q Â´ M2 pt1qq
Ë‡Ë‡ Ft1
â€°
Â´ E
â€œ
âŸ¨M1, M2âŸ©pt2q ` âŸ¨M1, M2âŸ©pt1q
Ë‡Ë‡ Ft1
â€°
` E
â€œ
pM1 pt1q Â´ M1 psqq pM2 pt2q Â´ M2 pt1qq
Ë‡Ë‡ Ft1
â€°
` E
â€œ
pM1 pt2q Â´ M1 pt1qq pM2 pt1q Â´ M2 psqq
Ë‡Ë‡ Ft1
â€°
` E
â€œ
pM1 pt1q Â´ M1 psqq pM2 pt1q Â´ M2 psqq
Ë‡Ë‡ Ft1
â€°
Â´ pM1 pt1q Â´ M1 psqq pM2 pt1q Â´ M2 psqq
â€œ E
â€œ
M1 pt2q M2 pt2q Â´ âŸ¨M1, M2âŸ©pt2q ` âŸ¨M1, M2âŸ©pt1q Â´ M1 pt1q M2 pt1q
Ë‡Ë‡ Ft1
â€°
Â´ E
â€œ
M1 psq pM2 pt2q Â´ M2 pt1qq
Ë‡Ë‡ Ft1
â€°
Â´ E
â€œ
pM1 pt2q Â´ M1 pt1qq M2 psq
Ë‡Ë‡ Ft1
â€°
` E
â€œ
pM1 pt1q Â´ M1 psqq pM2 pt1q Â´ M2 psqq
Ë‡Ë‡ Ft1
â€°
Â´ pM1 pt1q Â´ M1 psqq pM2 pt1q Â´ M2 psqq â€œ 0.
(2.166)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
88 
Renewal theory and Markov chains
In the ï¬nal step of (2.166) we employed the martingale property of the following
processes:
t ÃÃ‘ M1ptqM2ptq Â´ âŸ¨M1, M2âŸ©ptq, t ÃÃ‘ M1ptq,
and t ÃÃ‘ M2ptq.
This completes the proof of Proposition 2.64.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
â–¶â–¶enroll by September 30th, 2014 and 
â–¶â–¶save up to 16% on the tuition!
â–¶â–¶pay in 10 installments / 2 years
â–¶â–¶Interactive Online education
â–¶â–¶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
89 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
CHAPTER 3
An introduction to stochastic processes: Brownian
motion, Gaussian processes and martingales
In this chapter of the book we will study several aspects of Brownian motion:
Brownian motion as a Gaussian process, Brownian motion as a Markov process,
Brownian motion as a martingale. It also includes a discussion on stochastic
integrals and ItË†oâ€™s formula.
1. Gaussian processes
We begin with an important extension theorem of Kolmogorov, which enables
us to construct stochastic processes like Gaussian processes, LÂ´evy processes,
Poisson processes and others. It is also useful for the construction of Markov
processes. In Theorem 3.1 the symbol â„¦J, J Ä I, stands for the product space
â„¦J â€œ Å›
jPJ â„¦j endowed with the product Ïƒ-ï¬eld FJ. By saying that the system
tpâ„¦J, FJ, PJq : J Ä I, J ï¬niteu is a projective system (or a consistent system,
or a cylindrical measure) we mean that
PJ1
â€œ
pJ1
J2 P A
â€°
â€œ PJ1
â€`
pJ1
J2
Ë˜Â´1 pAq
Ä±
â€œ PJ2 rAs ,
where A P FJ2, and where J2 Ä J1 Ä I, J1 ï¬nite. The mapping pJ1
J2, J2 Ä J1, is
deï¬ned by pJ1
J2 pÏ‰jqjPJ1 â€œ pÏ‰jqjPJ2. In practice this means that in order to prove
that the system tpâ„¦J, FJ, PJq : J Ä I,
J
ï¬niteu is a projective system indeed,
we have to show an equality of the form (j0 R J):
PJYtj0u rB Ë† â„¦j0s â€œ PJ rBs ,
B P FJ.
The following proposition says that under certain conditions a cylindrical mea-
sure in fact is a genuine measure.
3.1. Theorem (Extension theorem of Kolmogorov). Let
tpâ„¦J, FJ, PJq : J Ä I, J ï¬niteu
be a projective system of probability spaces (or distributions). Suppose that each
â„¦i is a metrizable and Ïƒ-compact Hausdorï¬€space endowed with its Borel ï¬eld
Ai. Then there exists a unique probability measure PI on pâ„¦I, AIq, such that
PI rpJ P As â€œ PI
`
pÂ´1
J pAq
Ë˜
â€œ PJpAq
(3.1)
for every J Ä I, J ï¬nite, and for every A P AJ.
For an extensive discussion on Kolmogorovâ€™s extension theorem see, e.g., the
Probability Theory lecture notes of B. Driver [40]. These lecture notes include
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
90 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
a discussion on standard Borel spaces and on Polish spaces. The Kolmogorovâ€™s
extension theorem is also valid if the spaces â„¦i are Polish spaces, or Souslin
spaces which are continuous images of Polish spaces. For more details see Ap-
pendix 17.6 in [40]. The reader may also consult [21] or [137]. In Theorem
7.4.3 of [21] the author shows that ï¬nite positive measures on Souslin spaces
are regular and concentrated on Ïƒ-compact subsets. Bogachevâ€™s book contains
lots of information on Souslin spaces. In fact much material which is presented
in this book, can also be found in the lecture notes by Bruce Driver. A proof of
Kolmogorovâ€™s extension theorem is supplied in Section 4 of Chapter 5: see (the
proof of) Theorem 5.81.
Next we recall Bochnerâ€™s theorem.
3.2. Theorem. (Bochner) Let Ï† : Rn Ã‘ C be a continuous complex function,
that is positive deï¬nite in the sense that for all r P N
rÃ¿
k,â„“â€œ1
Î»kÎ»â„“Ï†
`
Î¾k Â´ Î¾â„“Ë˜
Ä› 0,
(3.2)
for all Î»1, . . . , Î»r P C and for all Î¾1, . . . , Î¾r P Rn. Then there exists a unique
non-negative Borel measure Âµ on Rn such that its Fourier transform
Å¼
exppÂ´i âŸ¨Î¾, xâŸ©qdÂµpxq
is equal to Ï†pÎ¾q for Î¾ P Rn. In particular ÂµpRnq â€œ Ï†p0q.
3.3. Example. Let, for every i P I, Pi, i P I, be a probability measures on â„¦i
and deï¬ne PJ on â„¦J, J Ä I, J ï¬nite, by PJpAq â€œ Pj1 bÂ¨ Â¨ Â¨bPjnpAq, where A be-
longs to AJ and where J â€œ pj1, . . . , jnq. Then the family tPJ : J Ä‚ I, J ï¬niteu
is a consistent system or cylindrical measure.
3.4. Example. Let Ïƒ : I Ë† I Ã‘ R be a symmetric (i.e. Ïƒpi, jq â€œ Ïƒpj, iq for all i,
j in I) function such that for every ï¬nite subset J â€œ pj1, . . . , jnq of I the matrix
pÏƒpi, jqqi,jPJ is positive-deï¬nite in the sense that
Ã¿
i,jPJ
Ïƒpi, jqÎ¾iÎ¾j Ä› 0,
(3.3)
for all Î¾j1, . . . , Î¾jn P R. In the non-degenerate case we shall assume that the
inequality in (3.3) is strict whenever the vector pÎ¾j1, . . . , Î¾jnq is non-zero. De-
ï¬ne the process pi, Ï‰q ÃÃ‘ XipÏ‰q by XipÏ‰q â€œ Ï‰i, where Ï‰ P â„¦I â€œ RI is given
by Ï‰ â€œ pÏ‰iqiPI. Let Âµ â€œ pÂµiq P RI be a map from I to R. There exists a
unique probability measure P on the Ïƒ-ï¬eld on â„¦I generated by pXiqiPI with the
following property:
E
Ëœ
exp
Ëœ
Â´i
Ã¿
jPJ
Î¾jXj
Â¸Â¸
â€œ exp
Ëœ
Â´i
Ã¿
jPJ
Î¾jÂµj
Â¸
exp
Ëœ
Â´1
2
Ã¿
i,jPJ
Ïƒpi, jqÎ¾iÎ¾j
Â¸
. (3.4)
This measure possesses the following additional properties:
E pXjq â€œ Âµj,
j P I,
and cov pXi, Xjq â€œ Ïƒpi, jq,
i, j P I.
(3.5)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
91 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Notice that
nÃ¿
u,vâ€œ1
Î¾uÎ¾vcov pXju, Xjvq Ä› 0 whenever Î¾1, . . . , Î¾n belong to R. For
a proof of this result we shall employ both Bochnerâ€™s theorem as well as Kol-
mogorovâ€™s extension theorem. Therefore let J â€œ pj1, . . . , jnq be a ï¬nite subset
of I, let Î»k, 1 Ä k Ä r, be complex numbers and let Î¾k, 1 Ä k Ä r, be vectors in
Rn â€ RJ. Put Î»1
k â€œ Î»k exp
`
i Å™n
uâ€œ1 Î¾k
juÂµk
ju
Ë˜
and let U be an orthogonal matrix
with the property that the matrix pUÏƒU Â´1pu, vqqn
u,vâ€œ1 has the diagonal form
`
UÏƒU Â´1pu, vq
Ë˜
â€œ
Â¨
Ëš
Ëš
Ë
s2
1
0
. . .
0
0
s2
2
. . .
0
...
...
...
...
0
0
0
s2
n
Ë›
â€¹â€¹â€š.
We also write
`
Î·â„“
1, . . . , Î·â„“
n
Ë˜
â€œ U
Â¨
Ëš
Ë
Î¾â„“
j1...
Î¾â„“
jn
Ë›
â€¹â€š.
We may and do suppose that the eigenvalues s1, . . . , sm, m Ä n, are non-zero
and the others (if any) are 0. Then we get
rÃ¿
k,â„“â€œ1
Î»kÎ»â„“exp
Ëœ
Â´1
2
nÃ¿
u,vâ€œ1
Ïƒpju, jvq
`
Î¾â„“
ju Â´ Î¾k
ju
Ë˜ `
Î¾â„“
jv Â´ Î¾k
jv
Ë˜
Â¸
Ë† exp
Ëœ
Â´i
nÃ¿
uâ€œ1
`
Î¾â„“
ju Â´ Î¾k
ju
Ë˜
Âµju
Â¸
â€œ
rÃ¿
k,â„“â€œ1
Î»1
kÎ»1
â„“exp
Ëœ
Â´1
2
nÃ¿
u,vâ€œ1
`
UÏƒU Â´1Ë˜
pu, vq
`
Î·â„“
u Â´ Î·k
u
Ë˜ `
Î·â„“
v Â´ Î·k
v
Ë˜
Â¸
â€œ
rÃ¿
k,â„“â€œ1
Î»1
kÎ»1
â„“exp
Ëœ
Â´1
2
nÃ¿
uâ€œ1
s2
u
`
Î·â„“
u Â´ Î·k
u
Ë˜2
Â¸
â€œ
rÃ¿
k,â„“â€œ1
Î»1
kÎ»1
â„“exp
Ëœ
Â´1
2
m
Ã¿
uâ€œ1
s2
u
`
Î·â„“
u Â´ Î·k
u
Ë˜2
Â¸
â€œ
rÃ¿
k,â„“â€œ1
Î»1
kÎ»1
â„“
1
p
?
2Ï€qm
1
Å›m
uâ€œ1 su
Å¼
. . .
Å¼
dx1 . . . dxm
exp
Ëœ
Â´i
m
Ã¿
uâ€œ1
`
Î·â„“
u Â´ Î·k
u
Ë˜
xu
Â¸
exp
Ëœ
Â´1
2
m
Ã¿
uâ€œ1
x2
u
s2
u
Â¸
â€œ
1
p
?
2Ï€qm
1
Å›m
uâ€œ1 su
Å¼
. . .
Å¼
dx1 . . . dxm
Ë‡Ë‡Ë‡Ë‡Ë‡
rÃ¿
kâ€œ1
Î»1
k exp
Ëœ
i
m
Ã¿
uâ€œ1
Î·â„“
uxu
Â¸Ë‡Ë‡Ë‡Ë‡Ë‡
2
exp
Ëœ
Â´1
2
m
Ã¿
uâ€œ1
x2
u
s2
u
Â¸
Ä› 0.
(3.6)
From Bochnerâ€™s Theorem 3.2 it follows that there exists a probability measure
Î J on RJ such that, for all Î¾ P Rn,
Å¼
RJ exp
Ëœ
Â´i
nÃ¿
uâ€œ1
Î¾uxu
Â¸
dÎ J
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
92 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
â€œ exp
Ëœ
Â´i
nÃ¿
uâ€œ1
Î¾uÂµu
Â¸
exp
Ëœ
Â´1
2
nÃ¿
u,vâ€œ1
Ïƒpju, jvqÎ¾uÎ¾v
Â¸
.
(3.7)
Deï¬ne the probability measure PJ on â„¦J â€œ Å›
jPJ â„¦j by
PJ ppXj1, . . . , Xjnq P Bq â€œ Î JpBq,
where B is a Borel subset of RJ. The collection pâ„¦J, AJ, PJq is a projective
system, because let J1 :â€œ tj0uYJ be a subset of I, which is of size 1` size J â€œ
1 ` n and let B be a Borel subset of RJ. The Fourier transform of the measure
B ÃÃ‘ Î J1 rR Ë† Bs is given by the function:
pÎ¾j1, . . . , Î¾jnq ÃÃ‘
Å¼
RJ exp
Ëœ
Â´i
Ã¿
jPJ
Î¾jxj
Â¸
Î J1 rR Ë† dxs
â€œ
Å¼
RJ
Å¼
R
exp
Ëœ
Â´i
Ã¿
jPJ1
Î¾jxj
Â¸
Î J1 rdy Ë† dxs
â€œ exp
Ëœ
Â´i
Ã¿
jPJ1
Î¾jÂµj
Â¸
exp
Ëœ
Â´1
2
Ã¿
i,jPJ1
Ïƒpi, jqÎ¾iÎ¾j
Â¸
â€œ exp
Ëœ
Â´i
Ã¿
jPJ
Î¾jÂµj
Â¸
exp
Ëœ
Â´1
2
Ã¿
i,jPJ
Ïƒpi, jqÎ¾iÎ¾j
Â¸
â€œ
Å¼
RJ eÂ´i Å™
jPJ Î¾jxj Î Jpdxq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
93 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In the previous formula we used the equality Î¾j0 â€œ 0 several times: J1 â€œ J Ytj0u.
It follows that Î J rBs â€œ Î J1 rR Ë† Bs. An application of the extension theorem
of Kolmogorov yields the desired result in Example 3.4.
Suppose that the matrix pÏƒpju, jvqqn
u,vâ€œ1 be non-degenerate (i.e. suppose that
its determinant is non-zero) and let pÎ±pu, vqqn
u,vâ€œ1 be its inverse. Then
P ppXj1, . . . , Xjnq P Bq
(3.8)
â€œ pdet Î±q1{2
p2Ï€qn{2
Å¼
. . .
Å¼
dx1 . . . dxn1Bpx1, . . . , xnq
exp
Ëœ
Â´1
2
nÃ¿
u,vâ€œ1
Î±pu, vq pxu Â´ Âµuq pxv Â´ Âµvq
Â¸
.
Equality (3.8) can be proved by showing that the Fourier transforms of both
measures in (3.8) coincide. In the following propositions (Propositions 3.5 and
3.6) we mention some elementary facts on Gaussian vectors. Gaussian vectors
are multivariate normally distributed random vectors.
3.5. Proposition. Let pâ„¦, F, Pq be a probability space and let Xi : â„¦ÃÃ‘ Rni,
i â€œ 1, 2, be random vectors with the property that the random vector XpÏ‰q :â€œ
pX1pÏ‰q, X2pÏ‰qq is Gaussian in the sense that (n â€œ n1 ` n2)
E
Ëœ
exp
Ëœ
Â´i
nÃ¿
kâ€œ1
Î¾kXk
Â¸Â¸
â€œ exp
Ëœ
Â´i
nÃ¿
kâ€œ1
Î¾kÂµk Â´ 1
2
nÃ¿
k,â„“â€œ1
Ïƒpk, â„“qÎ¾kÎ¾â„“
Â¸
,
(3.9)
where the matrix Ïƒpk, â„“qn
k,â„“â€œ1 is positive deï¬nite and where pÂµ1, . . . , Âµnq is a vec-
tor in Rn. The vectors X1 and X2 are P-independent if and only if they are
uncorrelated in the sense that
E
`
X1
i X2
j
Ë˜
â€œ E
`
X1
i
Ë˜
E
`
X2
j
Ë˜
(3.10)
for all 1 Ä i Ä n1 and for all 1 Ä j Ä n2.
Proof. The necessity is clear. For the suï¬ƒciency we proceed as follows.
Put
`
X1, X2Ë˜
â€œ pX1, . . . , Xn1, Xn1`1, . . . , Xn1`n2q .
Since the vectors X1 and X2 are uncorrelated (see (3.10)), it follows that
nÃ¿
k,â„“â€œ1
Ïƒpk, â„“qÎ¾kÎ¾â„“â€œ
n1
Ã¿
k,â„“â€œ1
Ïƒpk, â„“qÎ¾kÎ¾â„“`
nÃ¿
k,â„“â€œn1`1
Ïƒpk, â„“qÎ¾kÎ¾â„“.
(3.11)
From (3.9) it follows that
E
Ëœ
exp
Ëœ
Â´i
nÃ¿
kâ€œ1
Î¾kXk
Â¸Â¸
â€œ E
Ëœ
exp
Ëœ
Â´i
n1
Ã¿
kâ€œ1
Î¾kXk
Â¸Â¸
E
Ëœ
exp
Ëœ
Â´i
n1`n2
Ã¿
kâ€œn1`1
Î¾kXk
Â¸Â¸
(3.12)
and hence that the random vectors X1 and X2 are independent.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
94 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.6. Proposition. Let pâ„¦, F, Pq be a probability space.
(a) Let Q : Rm Ã‘ Rn be a linear map. If X : â„¦Ã‘ Rm is a Gaussian
vector, then so is QX.
(b) A random vector X : â„¦Ã‘ Rn is Gaussian if and only if for every
Î¾ P Rn the random variable Ï‰ ÃÃ‘ âŸ¨Î¾, XpÏ‰qâŸ©is Gaussian.
Proof. (a) A random vector X is Gaussian if and only if the Fourier trans-
form of the measure B ÃÃ‘ P pX P Bq is of the form
Î¾ ÃÃ‘ exp
Ë†
Â´i âŸ¨Î¾, ÂµâŸ©Â´ 1
2 âŸ¨ÏƒÎ¾, Î¾âŸ©
Ë™
.
By a standard result on image measures the Fourier transform of the measure
B ÃÃ‘ P pQX P Bq, where X : â„¦Ã‘ Rn is Gaussian and where B is a Borel subset
of Rm, is given by
Î¾ ÃÃ‘ E rexp pÂ´i âŸ¨Î¾, QXâŸ©qs â€œ E rexp pÂ´i âŸ¨QËšÎ¾, XâŸ©qs
â€œ exp pÂ´i âŸ¨QËšÎ¾, ÂµâŸ©q exp
Ë†
Â´1
2 âŸ¨ÏƒQËšÎ¾, QËšÎ¾âŸ©
Ë™
.
(3.13)
This proves (a). It also proves that the dispersion matrix of QX is given by
QÏƒQËš.
(b) For the necessity we apply (a) with the linear map Qx :â€œ âŸ¨Î¾, xâŸ©, x P Rn,
where Î¾ P Rn is ï¬xed. For the suï¬ƒciency we again ï¬x Î¾ P Rn. Since Y :â€œ âŸ¨Î¾, XâŸ©
is a Gaussian variable we have
E pexp pÂ´i âŸ¨Î¾, XâŸ©qq â€œ E pexp pÂ´iY qq
â€œ exp pÂ´iEpY qq exp
Ë†
Â´1
2E pY Â´ EpY qq2
Ë™
â€œ exp pÂ´i âŸ¨Î¾, ÂµâŸ©q exp
Ë†
Â´1
2 âŸ¨ÏƒÎ¾, Î¾âŸ©
Ë™
,
(3.14)
where Âµ â€œ EpXq and where
Ïƒpk, â„“q â€œ cov pXk, Xâ„“q â€œ E pXk Â´ EpXkqq pXâ„“Â´ E pXâ„“qq .
This completes the proof of (b).
â–¡
3.7. Theorem. Let Ïƒ : I Ë†I Ã‘ R be a positive-deï¬nite function and let Âµ : I Ã‘
R be a map. There exists a probability space pâ„¦, F, Pq together with a Gaussian
process pt, Ï‰q ÃÃ‘ XtpÏ‰q â€œ Xpt, Ï‰q, t P I, Ï‰ P â„¦, such that EpXtq â€œ Âµt and such
that covpXs, Xtq â€œ Ïƒps, tq for all s, t P I.
Proof. The proof is essentially given in Example 3.4.
â–¡
We conclude this section with the introduction of Brownian motion and Brow-
nian bridge as Gaussian processes. First we show that the function Ïƒ : r0, 8q Ë†
r0, 8q Ã‘ R, deï¬ned by Ïƒpu, vq â€œ minpu, vq, u, v P r0, 8q, and, for t Ä› 0 ï¬xed,
the function Ïƒt : r0, ts Ë† r0, ts Ã‘ R, deï¬ned by Ïƒtpu, vq â€œ t minpu, vq Â´ uv, u,
v P r0, ts, are positive deï¬nite.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
95 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.8. Proposition. The functions Ïƒpu, vq â€œ minpu, vq, u, v P r0, 8q, Ïƒtpu, vq â€œ
t minpu, vq Â´ uv, u, v P r0, ts, and ÏƒRpu, vq â€œ 1
2 exp pÂ´ |u Â´ v|q, u, v P R, are
positive deï¬nite. In addition, the function Ïƒ0pu, vq deï¬ned by
Ïƒ0pu, vq â€œ 1
2 exp
`
Â´pu ` vq
Ë˜
pexp p2 minpu, vqq Â´ 1q, u, v Ä› 0,
is positive deï¬nite.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
96 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Let 0 â€œ s0 Äƒ s1 Äƒ s2 Äƒ s3 Äƒ Â¨ Â¨ Â¨ Äƒ sn Äƒ t and let Î»1, . . . , Î»n be
complex numbers. The following identities are valid:
nÃ¿
jâ€œ1
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
kâ€œj
Î»kpt Â´ skq
Ë‡Ë‡Ë‡Ë‡Ë‡
2
tpsj Â´ sjÂ´1q
pt Â´ sjqpt Â´ sjÂ´1q
â€œ
nÃ¿
jâ€œ1
nÃ¿
k1â€œj
nÃ¿
k2â€œj
Î»k1Î»k2 pt Â´ sk1q pt Â´ sk2q
"
sj
t Â´ sj
Â´
sjÂ´1
t Â´ sjÂ´1
*
â€œ
nÃ¿
k1â€œ1
nÃ¿
k2â€œ1
minpk1,k2q
Ã¿
jâ€œ1
Î»k1Î»k2
"
sj
t Â´ sj
Â´
sjÂ´1
t Â´ sjÂ´1
*
pt Â´ sk1q pt Â´ sk2q
â€œ
nÃ¿
k1â€œ1
nÃ¿
k2â€œ1
Î»k1Î»k2
sminpk1,k2q
t Â´ sminpk1,k2q
pt Â´ sk1q pt Â´ sk2q
â€œ
nÃ¿
k1â€œ1
nÃ¿
k2â€œ1
Î»k1Î»k2sminpk1,k2q
`
t Â´ smaxpk1,k2q
Ë˜
â€œ
nÃ¿
k1,k2â€œ1
Î»k1Î»k2Ïƒt psk1, sk2q
(3.15)
and hence the function Ïƒt is positive deï¬nite. Since
nÃ¿
j,kâ€œ1
Î»jÎ»kt minpsj, skq â€œ
nÃ¿
j,kâ€œ1
Î»jÎ»kÏƒtpsj, skq `
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
jâ€œ1
Î»jsj
Ë‡Ë‡Ë‡Ë‡Ë‡
2
,
it follows that the function Ïƒ is positive deï¬nite as well.
In order to prove that the function ÏƒR is positive deï¬nite we ï¬rst notice that
the Fourier transform of the function t ÃÃ‘ exp pÂ´ |t|q is given by
Å¼ 8
Â´8
eÂ´iÎ¾teÂ´|t|dt â€œ 2
Å¼ 8
0
cos pÎ¾tq eÂ´tdt
â€œ 2Re
Å¼ 8
0
eÂ´tp1Â´iÎ¾qdt â€œ 2Re
1
1 Â´ iÎ¾ â€œ
2
1 ` Î¾2.
(3.16)
Hence upon taking the inverse Fourier transform we obtain:
1
2eÂ´|tÂ´s| â€œ 1
2Ï€
Å¼ 8
Â´8
exp piÎ¾pt Â´ sqq
Î¾2 ` 1
dÎ¾.
(3.17)
Let Î»1, . . . , Î»n be complex numbers and let s1, . . . , sn be real numbers. From
(3.16) and (3.17) it follows that
nÃ¿
k,â„“â€œ1
Î»kÎ»â„“
1
2 exp pÂ´ |sk Â´ sâ„“|q â€œ 1
2Ï€
Å¼ 8
Â´8
1
Î¾2 ` 1
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
kâ€œ1
Î»k exp piÎ¾skq
Ë‡Ë‡Ë‡Ë‡Ë‡
2
dÎ¾.
(3.18)
An easier way to establish the positive-deï¬niteness of ÏƒRpu, vq is the following.
For Î»1, . . . , Î»n in C and for real numbers s1, . . . , sn we write
nÃ¿
k,â„“â€œ1
Î»kÎ»â„“exp pÂ´ |sk Â´ sâ„“|q
â€œ
nÃ¿
k,â„“â€œ1
Î»kÎ»â„“min
`
exp
`
Â´psk Â´ sâ„“q
Ë˜
, exp
`
Â´psâ„“Â´ skq
Ë˜Ë˜
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
97 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
â€œ
nÃ¿
k,â„“â€œ1
exppÂ´skqÎ»k exppÂ´sâ„“qÎ»â„“min
`
exp
`
2sk
Ë˜
, exp
`
2sâ„“
Ë˜Ë˜
â€œ
Å¼ 8
0
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
kâ€œ1
exp pÂ´skq Î»k1r0,expp2skqspÎ¾q
Ë‡Ë‡Ë‡Ë‡Ë‡
2
dÎ¾ Ä› 0.
A similar argument can be used to prove that the function Ïƒ0pu, vq is positive
deï¬nite.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Masterâ€™s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top masterâ€™s programmes
â€¢ 33rd place Financial Times worldwide ranking: MSc 
International Business
â€¢ 1st place: MSc International Business
â€¢ 1st place: MSc Financial Economics
â€¢ 2nd place: MSc Management of Learning
â€¢ 2nd place: MSc Economics
â€¢ 2nd place: MSc Econometrics and Operations Research
â€¢ 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier â€˜Beste Studiesâ€™ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Advanced stochastic processes: Part I
98 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We now give existence theorems for the Wiener process (or Brownian motion),
for Brownian bridge and for the oscillator process.
3.9. Theorem. The following assertions are true.
(a) There exists a probability space pâ„¦, F, Pq together with a real-valued
Gaussian process tbpsq : s Ä› 0u, called Wiener process or Brownian mo-
tion, such that Epbpsqq â€œ 0 and such that E pbps1qbps2qq â€œ minps1, s2q
for all s1, s2 Ä› 0.
(b) Fix t Ä… 0. There exists a probability space pâ„¦, F, Pq together with a real-
valued Gaussian process tXtpsq : t Ä› s Ä› 0u, called Brownian bridge,
such that EpXtpsqq â€œ 0 and such that
E pXtps1qXtps2qq â€œ minps1, s2q Â´ s1s2
t
for all s1, s2 P r0, ts.
(c) There exists a probability space pâ„¦, F, Pq together with a real-valued
Gaussian process tqpsq : s P Ru, called oscillator process, which is cen-
tered, i.e. Epqpsqq â€œ 0 and which is such that
E pqps1qqps2qq â€œ 1
2 exp pÂ´ |s1 Â´ s2|q
for all s1, s2 P R.
(d) There exists a probability space pâ„¦, F, Pq together with a real-valued
Gaussian process tXpsq : s Ä› 0u, called Ornstein-Uhlenbeck process,
such that EpXpsqq â€œ 0 and such that
E pXps1qXps2qq â€œ 1
2 exp
`
Â´ps1 ` s2q
Ë˜ `
exp
`
2 minps1, s2q
Ë˜
Â´ 1
Ë˜
(3.19)
â€œ 1
2
`
exp pÂ´ |s1 Â´ s2|q Â´ exp
`
Â´ps1 ` s2q
Ë˜Ë˜
for all s1, s2 Ä› 0.
2. Brownian motion and related processes
In what follows x and y are real numbers and so is Âµ. Let tbpsq : s Ä› 0u be
Brownian motion (starting in 0) on a probability space pâ„¦, F, Pq (i.e. E rbpsqs â€œ
0 and E rb ps1q b ps2qs â€œ min ps1, s2q). Then the process tx ` bpsq ` Âµs : s Ä› 0u
is a Brownian motion with drift Âµ starting at x.
Let tXtpsq : 0 Ä s Ä tu be
a Brownian bridge on a probability space pâ„¦, F, Pq.
Then the process s ÃÃ‘
Â´
1 Â´ s
t
Â¯
x ` s
t y ` Xtpsq 0 Ä s Ä t is called pinned Brownian motion, namely
pinned at x at time 0 and pinned at y at time t.
Let tbjpsq : s Ä› 0u, 1 Ä
j Ä d, be d independent Brownian motions on the probability space pâ„¦, F, Pq.
The process tpb1psq, . . . , bdpsqq : s Ä› 0u is called d-dimensional Brownian motion.
The characteristic function for d-dimensional Brownian motion starting at x P
Rd is given by:
Ex
â€
eÂ´i Å™n
jâ€œ1âŸ¨Xpsjq,Î¾jâŸ©Ä±
â€œ eÂ´i Å™n
jâ€œ1âŸ¨Î¾j,xâŸ©eÂ´ 1
2
Å™n
j,kâ€œ1âŸ¨Î¾j,Î¾kâŸ©minpsj,skq
â€œ eÂ´i Å™n
jâ€œ1âŸ¨Î¾j,xâŸ©eÂ´ 1
2
Å™n
â„“â€œ1psâ„“Â´sâ„“Â´1q|
Å™n
jâ€œâ„“Î¾j|
2
,
(3.20)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
99 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
where x0 â€œ x and where 0 â€œ s0 Äƒ s1 Äƒ Â¨ Â¨ Â¨ Äƒ sn. A similar deï¬nition can be
given for d-dimensional Brownian bridge and for the d-dimensional oscillator
process. Notice that a d-dimensional process tbpsq â€œ pb1psq, . . . , bdpsqq : s Ä› 0u
is a d-dimensional Brownian motion, starting at 0, on the probability space
pâ„¦, F, Pq if and only if E pbjps1q, bkps2qq â€œ Î´j,k minps1, s2q.
Let us prove the
above equalities.
3.10. Theorem. Let 0 â€œ s0 Äƒ s1 Äƒ Â¨ Â¨ Â¨ Äƒ sn Äƒ 8. Fix the vectors x and
Î¾1, . . . , Î¾n in Rd. Put s0 â€œ 0 and x0 â€œ x. The following equalities are valid:
nÃ¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
jâ€œâ„“
Î¾j
Ë‡Ë‡Ë‡Ë‡Ë‡
2
â€œ
nÃ¿
j,kâ€œ1
âŸ¨Î¾j, Î¾kâŸ©min psj, skq ;
(3.21)
Å¼
Rd dx1 . . .
Å¼
Rd dxn exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xjâŸ©
Â¸
(3.22)
n
Åº
jâ€œ1
1
`a
2Ï€ psj Â´ sjÂ´1q
Ë˜d exp
Ëœ
Â´ |xj Â´ xjÂ´1|2
2 psj Â´ sjÂ´1q
Â¸
â€œ exp
Ëœ
Â´i
âŸ¨nÃ¿
jâ€œ1
Î¾j, x
âŸ©Â¸
exp
Ëœ
Â´1
2
nÃ¿
j,kâ€œ1
âŸ¨Î¾j, Î¾kâŸ©min psj, skq
Â¸
.
(3.23)
For a and b P Rd we write pa ` biq2 â€œ |a|2 ` 2i âŸ¨a, bâŸ©Â´ |b|2.
Proof. In order to see the ï¬rst equality we write
nÃ¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
jâ€œâ„“
Î¾j
Ë‡Ë‡Ë‡Ë‡Ë‡
2
â€œ
nÃ¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q
nÃ¿
j1,j2â€œâ„“
âŸ¨Î¾j1, Î¾j2âŸ©
â€œ
nÃ¿
j1,j2â€œ1
minpj1,j2q
Ã¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q âŸ¨Î¾j1, Î¾j2âŸ©â€œ
nÃ¿
j1,j2â€œ1
`
sminpj1,j2q Â´ s0
Ë˜
âŸ¨Î¾j1, Î¾j2âŸ©
â€œ
nÃ¿
j1,j2â€œ1
sminpj1,j2q âŸ¨Î¾j1, Î¾j2âŸ©. â€œ
nÃ¿
j1,j2â€œ1
min psj1, sj2q âŸ¨Î¾j1, Î¾j2âŸ©.
(3.24)
For the second equality we proceed as follows:
Å¼
Rd dx1 . . .
Å¼
Rd dxn exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xjâŸ©
Â¸
n
Åº
jâ€œ1
1
`a
2Ï€ psj Â´ sjÂ´1q
Ë˜d exp
Ëœ
Â´ |xj Â´ xjÂ´1|2
2 psj Â´ sjÂ´1q
Â¸
(3.25)
(substitute xj â€œ x ` y1 ` Â¨ Â¨ Â¨ ` yj)
â€œ exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xâŸ©
Â¸ Å¼
Rd dy1 . . .
Å¼
Rd dyn exp
Ëœ
Â´i
nÃ¿
â„“â€œ1
âŸ¨nÃ¿
jâ€œâ„“
Î¾j, yâ„“
âŸ©Â¸
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
100 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
n
Åº
jâ€œ1
1
`a
2Ï€ psj Â´ sjÂ´1q
Ë˜d exp
Ëœ
Â´
|yj|2
2 psj Â´ sjÂ´1q
Â¸
(substitute yâ„“â€œ psâ„“Â´ sâ„“Â´1q1{2 zâ„“)
â€œ exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xâŸ©
Â¸ Å¼
Rd dz1 . . .
Å¼
Rd dzn
exp
Ëœ
Â´i
nÃ¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q1{2
nÃ¿
jâ€œâ„“
âŸ¨Î¾j, zâ„“âŸ©
Â¸
n
Åº
jâ€œ1
1
`?
2Ï€
Ë˜d exp
Ëœ
Â´|zj|2
2
Â¸
â€œ exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xâŸ©
Â¸
exp
Â¨
ËÂ´1
2
nÃ¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
jâ€œâ„“
Î¾j
Ë‡Ë‡Ë‡Ë‡Ë‡
2Ë›
â€š
n
Åº
â„“â€œ1
1
`?
2Ï€
Ë˜d
Å¼
Rd dzâ„“exp
Â¨
ËÂ´1
2
Ëœ
zâ„“` i?sâ„“Â´ sâ„“Â´1
nÃ¿
jâ€œâ„“
Î¾j
Â¸2Ë›
â€š,
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
101 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
From Cauchyâ€™s theorem, it then follows that
Å¼
Rd dx1 . . .
Å¼
Rd dxn exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xjâŸ©
Â¸
(3.26)
n
Åº
jâ€œ1
1
`a
2Ï€ psj Â´ sjÂ´1q
Ë˜d exp
Ëœ
Â´ |xj Â´ xjÂ´1|2
2 psj Â´ sjÂ´1q
Â¸
(3.27)
â€œ exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xâŸ©
Â¸
exp
Â¨
ËÂ´1
2
nÃ¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
jâ€œâ„“
Î¾j
Ë‡Ë‡Ë‡Ë‡Ë‡
2Ë›
â€š
(3.28)
n
Åº
â„“â€œ1
1
`?
2Ï€
Ë˜d
Å¼
Rd dzâ„“exp
Ë†
Â´1
2 |zâ„“|2
Ë™
(3.29)
â€œ exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xâŸ©
Â¸
exp
Â¨
ËÂ´1
2
nÃ¿
â„“â€œ1
psâ„“Â´ sâ„“Â´1q
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
jâ€œâ„“
Î¾j
Ë‡Ë‡Ë‡Ë‡Ë‡
2Ë›
â€š
(3.30)
(ï¬rst equality)
â€œ exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, xâŸ©
Â¸
exp
Ëœ
Â´1
2
nÃ¿
j,kâ€œ1
âŸ¨Î¾j, Î¾kâŸ©min psj, skq
Â¸
.
This completes the proof of Theorem 3.10.
â–¡
In the following proposition we collect a number of interesting properties of the
(ï¬nite dimensional) joint distributions of some of the Gaussian processes we
introduced so far.
3.11. Proposition. Let tbpsq : s Ä› 0u be d-dimensional Brownian motion and
let
tXtpsq : 0 Ä s Ä tu
be d-dimensional Brownian bridge. In addition let x and y be vectors in Rd and
let Q : Rd Ã‘ Rd be an orthogonal linear map. Also ï¬x a strictly positive number
a.
(a) The joint distributions of the processes
tbpsq : s Ä… 0u
and
"
sb
Ë†1
s
Ë™
: s Ä… 0
*
coincide.
(b) The joint distributions of the processes
tbpasq : s Ä› 0u
and
â£?ab psq : s Ä› 0
(
coincide.
(c) The joint distributions of the processes
tqpsq : s P Ru
and
"
eÂ´sb
Ë†e2s
2
Ë™
: s P R
*
coincide.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
102 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(d) The joint distributions of the processes
tXptq : t Ä› 0u
and
"
eÂ´tb
Ë†e2t Â´ 1
2
Ë™
: t Ä› 0
*
coincide. The process tXptq : t Ä› 0u also possesses the same joint dis-
tribution as
!ÅŸt
0 exp pÂ´pt Â´ sqq dbpsq : t Ä› 0
)
.
(e) The joint distributions of the following processes also coincide:
Â´
1 Â´ s
t
Â¯
x ` s
t y ` Xtpsq,
0 Äƒ s Äƒ t,
(3.31)
Â´
1 Â´ s
t
Â¯
x ` s
t y `
Â´
1 Â´ s
t
Â¯
b
Ë† st
t Â´ s
Ë™
,
0 Äƒ s Äƒ t,
(3.32)
Â´
1 Â´ s
t
Â¯
x ` s
t y ` bpsq Â´ s
t bptq,
0 Äƒ s Äƒ t.
(3.33)
(f) The process tQbpsq : s Ä› 0u is d-dimensional Brownian motion and so
its joint distribution coincides with that of tbpsq : s Ä› 0u.
Notice that instead of the â€œdistributionâ€ of a random variable or a stochastic
process, the name â€œlawâ€ is in vogue.
3.12. Remark. Put bxptq â€œ x ` bptq. Then tbxptq : t Ä› 0u is Brownian motion
that starts in x. Put Xxptq â€œ exppÂ´tqx`Xptq. Then the process tXxptq : t Ä› 0u
is the Ornstein-Uhlenbeck process of initial velocity x.
3.13. Remark. The stochastic integral
ÅŸt
0 exppÂ´pt Â´ sqqdbpsq can be deï¬ned as
the L2-limit of Å™n
jâ€œ1 eÂ´ptÂ´sjÂ´1q pbpsjq Â´ bpsjÂ´1qq, whenever max
1ÄjÄn psj Â´ sjÂ´1q tends
to zero. Here 0 â€œ s0 Äƒ s1 Äƒ Â¨ Â¨ Â¨ Äƒ sn â€œ t is a subdivision of the interval r0, ts.
3.14. Remark. Let f : Rd Ã‘ C be a bounded Borel measurable function. Then
E rfpXxptqqs is given by
E rf pXxptqqs â€œ
Å¼
f
Â´
eÂ´tx `
?
1 Â´ eÂ´2ty
Â¯ exp
`
Â´ |y|2Ë˜
p?Ï€qd
dy.
Moreover the Ornstein-Uhlenbeck process is a strong Markov process.
3.15. Remark. Let tbxptq : t Ä› 0u be Brownian motion that starts at x (and
has drift zero). Fix s Ä… 0. The processes
tbxps ` tq Â´ bxpsq : t Ä› 0u
and
tbxptq Â´ x : t Ä› 0u
possess the same (joint) distribution. In order to see this one may calculate the
Fourier transforms, or characteristic functions, of their distributions.
3.16. Remark. Suppose that the Markov process
tpâ„¦, F, Pxq , pXptq, t Ä› 0q , pÏ‘t, t Ä› 0q , pRn, Bqu
(3.34)
is Brownian motion in Rn, and put p0pt, x, yq â€œ
1
p2Ï€tqn{2 exp
Ëœ
Â´|x Â´ y|2
2t
Â¸
,
t Ä… 0, x, y P Rn. Deï¬ne the measure Âµx,y
0,t by
Âµt,y
0,xpAq â€œ Ex r1Ap0pt Â´ s, Xpsq, yqs ,
(3.35)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
103 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
where the event A belongs to Fs â€œ Ïƒ pXpuq : u Ä sq, for s Äƒ t. Since the process
s ÃÃ‘ p0pt Â´ s, Xpsq, yq is a Px-martingale on the half-open interval 0 Ä s Äƒ t,
it follows that the quantity Âµt,y
0,xpAq is well-deï¬ned: its value does not depend
on s, as long as A belongs to Fs and s Äƒ t. From the monotone class theorem
it follows that Âµx,y
0,t can be considered as a positive measure on the Ïƒ-ï¬eld FtÂ´
given by FtÂ´ â€œ Ïƒ pXpsq : 0 Ä s Äƒ tq. Then the measure Âµt,y
0,x deï¬ned in (3.35)
is called the conditional Brownian bridge measure. It can be normalized upon
dividing it by the density p0pt, x, yq.
Proof of Proposition 3.11. Since all the indicated processes are d-dim-
ensional Gaussian (the deï¬nition of a d-dimensional Gaussian process should be
obvious: in fact in the discussion of 3.4 and in Theorem 3.7. The expected value
Âµ should be map from I to Rd and the entries of the diï¬€usion matrix Ïƒ should
be d Ë† d-matrices), it suï¬ƒces to show that the corresponding expectations and
covariance matrices are the same for the indicated processes. In most cases this
is a simple exercise. For example let us prove (f). Let qpk, â„“q be the entries of
the matrix Q. Then
E
Â´
pQbps1qqj pQbps2qqk
Â¯
â€œ
dÃ¿
mâ€œ1
qpj, mq
dÃ¿
nâ€œ1
qpk, nqE pbmps1qbnps2qq
â€œ
dÃ¿
mâ€œ1
qpj, mq
dÃ¿
nâ€œ1
qpk, nqÎ´m,n minps1, s2q â€œ
dÃ¿
mâ€œ1
qpj, mqqpk, mq minps1, s2q
â€œ pQQËšq pj, kq minps1, s2q â€œ Î´j,k minps1, s2q.
(3.36)
This proves that tQbpsq : s Ä› 0u is again d-dimensional Brownian motion. This
completes the brief outline of the proof of Proposition 3.11.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
104 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In the proof of the existence of a continuous version of Brownian motion, we
shall employ the following maximal inequality of LÂ´evy.
3.17. Theorem. (LÂ´evy) Let X1, . . . , Xn be random variables with values in Rd.
Suppose that the joint distribution of X1, . . . , Xn is invariant under any change
of sign px1, . . . , xnq ÃÃ‘ pÏµ1x1, . . . , Ïµnxnq, where Ïµj â€œ Ë˜1. Put Sk â€œ Å™k
jâ€œ1 Xj.
Then for any Î» Ä… 0
P
Ë†
max
1ÄkÄn |Sk| Ä› Î»
Ë™
Ä 2P p|Sn| Ä› Î»q .
(3.37)
If d â€œ 1, then
P
Ë†
max
1ÄkÄn Sk Ä› Î»
Ë™
Ä 2P pSn Ä› Î»q .
(3.38)
Proof. We prove (3.37). Put
Ak â€œ
kÂ´1
Ä
jâ€œ1
t|Sj| Äƒ Î»u X t|Sk| Ä› Î»u
and put A â€œ Å¤n
kâ€œ1 Ak. Write Tk â€œ Å™k
jâ€œ1 XjÂ´Å™n
jâ€œk`1 Xj. Then Sk â€œ 1
2Sn ` 1
2Tk
and so
t|Sk| Ä› Î»u Ä‚ t|Sn| Ä› Î»u Y t|Tk| Ä› Î»u .
Hence, from the invariance of the joint distribution of pX1, . . . , Xnq under sign
changes we see
P pAkq â€œ P pAk, |Sk| Ä› Î»q
Ä P pAk, |Sn| Ä› Î»q ` P pAk, |Tk| Ä› Î»q â€œ 2P pAk, |Sn| Ä› Î»q .
Since the events Ak, 1 Ä k Ä n, are mutually disjoint, we infer
P
Ë†
max
1ÄkÄn |Sk| Ä› Î»
Ë™
â€œ PpAq â€œ
nÃ¿
kâ€œ1
PpAkq Ä 2
nÃ¿
kâ€œ1
P pAk, |Sn| Ä› Î»q Ä 2P p|Sn| Ä› Î»q .
This proves (3.37). The proof of (3.38) is similar and will be left to the reader.
Altogether this completes the proof Theorem 3.17.
â–¡
Let tXptq : t Ä› 0u be Brownian motion on the probability space pâ„¦, F, Pq. We
shall prove that there exists a continuous process tbptq : t Ä› 0u, that is indistin-
guishable from the process tXptq : t Ä› 0u. This means that PpXptq â€œ bptqq â€œ 1
for all t Ä› 0.
3.18. Theorem. Let tXptq : t Ä› 0u be Brownian motion on some probability
space pâ„¦, F, Pq. Then there exists stochastic process tbptq : t Ä› 0u which is P-
almost surely continuous, and that is also a Brownian motion on the probability
space pâ„¦, F, Pq and that is indistinguishable from the process tXpsq : s Ä› 0u.
Here we suppose that F contains the P-zero sets.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
105 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Without loss of generality we may and do assume that the Brownian
motion tXpsq : s Ä› 0u has drift 0 and diï¬€usion matrix identity. For the proof
we shall rely on Theorem 3.17 and on the Borel-Cantelli lemma, which reads as
follows. Let pAn : n P Nq be a sequence of events with Å™8
nâ€œ1 PpAnq Äƒ 8. Then
P
`Å8
mâ€œ1
Å¤8
nâ€œm An
Ë˜
â€œ 0. In Theorem 3.18 we choose the sequence pAn : n P Nq
as follows. Let D be the set of non-negative dyadic rational numbers and put
An â€œ
#
max
0ÄkÄƒn2n
sup
qPDXrk2Â´n,pk`1q2Â´ns
Ë‡Ë‡Xpqq Â´ Xpk2Â´nq
Ë‡Ë‡ Ä… 1
n
+
.
An application of Theorem 3.17, with Xpt`jÎ´2Â´mqÂ´Xpt`pjÂ´1qÎ´2Â´mq replacing
Xj yields
P
Ë†
max
1ÄjÄ2m
Ë‡Ë‡X
`
t ` jÎ´2Â´mË˜
Â´ Xptq
Ë‡Ë‡ Ä› Î±
Ë™
Ä 2P p|Xpt ` Î´q Â´ Xptq| Ä› Î±q
Ä 2
Î±4E |Xpt ` Î´q Â´ Xptq|4 â€œ 2Î´2
Î±4
1
`?
2Ï€
Ë˜d
Å¼
Rd exp
Ë†
Â´1
2 |y|2
Ë™
|y|4 dy
â€œ 2Î´2 p2d ` d2q
Î±2
.
(3.39)
In (3.39) we let m tend to inï¬nity to obtain:
P
Ë†
sup
0ÄqÄ1,qPD
|Xpt ` qÎ´q Â´ Xptq| Ä… Î±
Ë™
Ä 2Î´2 p2d ` d2q
Î±4
.
(3.40)
Hence, with Jn,k â€œ rk2Â´n, pk ` 1q2Â´ns (see also (3.46) below), and with t â€œ k2Â´n
and Î´ â€œ 2Â´n,
P
Ëœ
max
0ÄkÄƒn2n
sup
qPDXJn,k
Ë‡Ë‡Xpqq Â´ Xpk2Â´nq
Ë‡Ë‡ Ä… 1
n
Â¸
Ä
n2nÂ´1
Ã¿
kâ€œ0
P
Ëœ
sup
qPDXJn,k
Ë‡Ë‡Xpqq Â´ Xpk2Â´nq
Ë‡Ë‡ Ä… 1
n
Â¸
Ä n2n2 p2d2Â´2n ` d22Â´2nq
pnÂ´1q4
â€œ 2 p2d ` d2q n5
2n
Ä 6d2n5
2n
.
(3.41)
Since the sequence in (3.41) is summable, we may apply Borel-Cantelliâ€™s lemma
to conclude that P-almost surely, for all t Ä… 0, the path q ÃÃ‘ Xpqq is uniformly
continuous on DXr0, ts. So it makes sense to deï¬ne the P-almost surely continu-
ous function s ÃÃ‘ bpsq by bpsq â€œ limqÃ‘s,qPD Xpsq. It is not so diï¬ƒcult to see that
the process tbpsq : s Ä› 0u is also a Brownian motion. In fact let Î¾1, . . . , Î¾n be n
vectors in Rd and suppose 0 â€œ s0 Äƒ s1 Äƒ Â¨ Â¨ Â¨ Äƒ sn. Then we choose sequences
0 â€œ q0pmq Äƒ s1 Äƒ q1pmq Äƒ s2 Äƒ q2pmq Äƒ snÂ´1 Äƒ Â¨ Â¨ Â¨ Äƒ qnÂ´1pmq Äƒ sn Äƒ qnpmq,
m P N, in D, such that qkpmq Ã“ sk, if m tends to inï¬nity and this for 1 Ä k Ä n.
Since tXpsq : s Ä› 0u is d-dimensional Brownian motion we have
E
Ëœ
exp
Ëœ
Â´i
nÃ¿
kâ€œ1
âŸ¨Î¾k, X pqkpmqqâŸ©
Â¸Â¸
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
106 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
â€œ exp
Â¨
ËÂ´1
2
nÃ¿
jâ€œ1
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
kâ€œj
Î¾k
Ë‡Ë‡Ë‡Ë‡Ë‡
2
pqjpmq Â´ qjÂ´1pmqq
Ë›
â€š.
(3.42)
In (3.42) we let m tend to 8 to obtain
E
Ëœ
exp
Ëœ
Â´i
nÃ¿
kâ€œ1
âŸ¨Î¾k, b pskqâŸ©
Â¸Â¸
â€œ exp
Â¨
ËÂ´1
2
nÃ¿
jâ€œ1
Ë‡Ë‡Ë‡Ë‡Ë‡
nÃ¿
kâ€œj
Î¾k
Ë‡Ë‡Ë‡Ë‡Ë‡
2
psj Â´ sjÂ´1q
Ë›
â€š.
(3.43)
This equality shows that tbpsq : s Ä› 0u is a Brownian motion. In order to prove
that it cannot be distinguished from the process tXpsq : s Ä› 0u, we notice ï¬rst
that
E pexp pÂ´i âŸ¨Î¾, Xpt ` sq Â´ XptqâŸ©qq â€œ exp
Ë†
Â´1
2 |Î¾|2 s
Ë™
,
Î¾ P Rd.
(3.44)
Hence, for Î¾ P Rd,
E |exp pÂ´i âŸ¨Î¾, XptqâŸ©q Â´ exp pÂ´i âŸ¨Î¾, bptqâŸ©q|2
â€œ E p2 Â´ exp pi âŸ¨Î¾, Xptq Â´ bptqâŸ©q Â´ exp pÂ´i âŸ¨Î¾, Xptq Â´ bptqâŸ©qq
â€œ
lim
qÃ“t,qPD p2 Â´ E pexp pÂ´i âŸ¨Î¾, Xpqq Â´ XptqâŸ©qq Â´ E pexp pÂ´i âŸ¨Î¾, Xptq Â´ XpqqâŸ©qqq
â€œ 2 Â´ 2 lim
qÃ“t,qPD exp
Ë†
Â´1
2 |Î¾|2 pq Â´ tq
Ë™
â€œ 0.
(3.45)
From (3.45) it readily follows that the processes tXpsq :s Ä› 0u and tbpsq :s Ä› 0u
cannot be distinguished.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Advanced stochastic processes: Part I
107 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In this proof of Theorem 3.18 we have also used the fourth moment
E |Xpt ` sq Â´ Xptq|4 .
From (3.44) it follows that this moment does not depend on t and hence
E |Xpt ` sq Â´ Xptq|4 â€œ E |Xpsq Â´ Xp0q|4 â€œ E |Xpsq|4 .
A way of computing E |Xpsq|4 is the following:
E |Xpsq|4 â€œ
Ëœ dÃ¿
jâ€œ1
B2
BÎ¾2
j
Â¸2
E pexp pÂ´i âŸ¨Î¾, XpsqâŸ©qq
Ë‡Ë‡
Î¾â€œ0
â€œ
Ëœ dÃ¿
jâ€œ1
B2
BÎ¾2
j
Â¸2
exp
Ë†
Â´1
2 |Î¾|2 s
Ë™ Ë‡Ë‡
Î¾â€œ0
â€œ
`
2ds2 Â´ 2s3 |Î¾|2 ` s4 |Î¾|4 Â´ 2ds3 |Î¾|2 ` d2s2Ë˜
exp
Ë†
Â´1
2 |Î¾|2
Ë™ Ë‡Ë‡
Î¾â€œ0
â€œ
`
2ds2 Â´ 2pd ` 1qs2 |Î¾|2 ` s4 |Î¾|4 ` d2s2Ë˜
exp
Ë†
Â´1
2 |Î¾|2 s
Ë™ Ë‡Ë‡
Î¾â€œ0
â€œ 2ds2 ` d2s2.
(3.46)
In the following theorem we compute the ï¬nite dimensional distributions of d-
dimensional Brownian motion starting at 0 and possessing drift Âµ. Therefore
we deï¬ne the Gaussian kernel ppt, x, yq by ppt, x, yq â€œ
1
p2Ï€tq
1
2 d exp
Ëœ
Â´|x Â´ y|2
2t
Â¸
.
Notice the Chapman-Kolmogorov identity
pps, x, zqppt, z, yq â€œ pps ` t, x, yqp
Ë† st
s ` t, sx ` ty
s ` t , z
Ë™
.
3.19. Theorem. Let tbpsq : s Ä› 0u be d-dimensional Brownian motion with dif-
fusion matrix identity, with drift 0 and which starts in 0.
Let f1, . . . , fn be
bounded Borel measurable functions on Rd and let 0 â€œ s0 Äƒ s1 Äƒ Â¨ Â¨ Â¨ Äƒ sn.
Then
E
Ëœ n
Åº
jâ€œ1
fjpx ` bpsjq ` Âµsjq
Â¸
(3.47)
â€œ
Å¼
Rd . . .
Å¼
Rd dx1 . . . dxn
n
Åº
jâ€œ1
fjpxjq
n
Åº
jâ€œ1
p psj Â´ sjÂ´1, xjÂ´1 Â´ ÂµsjÂ´1, xj Â´ Âµsjq ,
where x0 â€œ x.
3.20. Remark. Equality (3.47) determines the joint distribution of the process
tXpsq :â€œ x ` bpsq ` Âµs : s Ä› 0u .
This will follow from the monotone class theorem. The vector Âµ is the so-called
drift vector and the process X â€œ tXpsq : s Ä› 0u starts at x in Rd.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
108 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.21. Remark. Another consequence of equality (3.47) is the fact that the
random vector bptqÂ´bpsq, t Ä… s ï¬xed, is independent of the Ïƒ-ï¬eld generated by
the process tbpÏƒq : 0 Ä Ïƒ Ä su. This fact also follows from (3.48) below together
with the monotone class theorem. For Î¾ P Rd, Î¾j P Rd, 1 Ä j Ä n, t Ä… s Ä› sn Ä…
Â¨ Â¨ Â¨ s1 Ä… s0 â€œ 0 the following identity is valid and relevant:
E
Ëœ
exp
Ëœ
Â´i âŸ¨Î¾, bptq Â´ bpsqâŸ©Â´ i
nÃ¿
jâ€œ1
âŸ¨Î¾j, bpsjqâŸ©
Â¸Â¸
â€œ exp
Ëœ
Â´1
2 |Î¾|2 pt Â´ sq Â´ 1
2
nÃ¿
j,kâ€œ1
minpsj, skq âŸ¨Î¾j, Î¾kâŸ©
Â¸
â€œ E pexp pÂ´i âŸ¨Î¾, bptq Â´ bpsqâŸ©qq E
Ëœ
exp
Ëœ
Â´i
nÃ¿
jâ€œ1
âŸ¨Î¾j, bpsjqâŸ©
Â¸Â¸
.
(3.48)
In other words a Brownian motion (diï¬€usion matrix identity) is a Gaussian
process tbpsq : s Ä› 0u with independent increments bptq Â´ bpsq, t Ä… s, with
mean ÂµptÂ´sq and covariance matrix covpbkptqÂ´bkpsq, bâ„“ptqÂ´bâ„“psqq â€œ Î´k,â„“ptÂ´sq.
Proof. Theorem 3.10 shows that the equality in (3.47) holds for functions
fj, 1 Ä j Ä n, of the form
fjpxq â€œ
Å¼
exp pÂ´i âŸ¨Î¾, xâŸ©q dÂµjpÎ¾q,
(3.49)
where Âµj â€œ Î´Î¾j is the Dirac measure Î¾j. Fubiniâ€™s theorem then implies that
(3.47) also holds for functions fj, 1 Ä j Ä n, of the form (3.49) with ÂµjpBq â€œ
ÅŸ
B gjpÎ¾q dÎ¾, with gj P L1 `
RdË˜
, 1 Ä j Ä n. Since, by the Stone-Weierstrass the-
orem functions of the form (3.49) with ÂµjpBq â€œ
ÅŸ
B gjpÎ¾q dÎ¾ where gj P L1 `
RdË˜
,
are dense in the space C0
`
RdË˜
, it follows that (3.47) holds for functions fj P
C0
`
RdË˜
, 1 Ä j Ä d. By approximating indicator functions of open subsets from
below by functions in C0
`
RdË˜
it follows that the equality in (3.47) holds for
functions fj which are indicator functions of open subsets. A Dynkin argument
(or the monotone class theorem) then shows that (3.47) is also true if the func-
tions fj are indicator functions of Borel subsets Bj, 1 Ä j Ä n. But then this
equality also holds for bounded Borel functions fj, 1 Ä j Ä n.
This completes the proof of Theorem 3.19.
â–¡
Next we want to deï¬ne standard Brownian motion, with drift vector Âµ, that
starts at x P Rd.
3.22. Definition. The standard Brownian motion, starting at x P Rd and with
drift Âµ is deï¬ned as the canonical Gaussian process tXpsq : s Ä› 0u deï¬ned on
pâ„¦, F, Pxq with the property that the increments Xpt ` hq Â´ Xptq are mutually
independent and have Px-expectation Âµh. Moreover it starts Px-almost surely at
x, i.e. PxpXp0q â€œ xq â€œ 1 and cov pXkpt ` hq Â´ Xkptq, Xâ„“pt ` hq Â´ Xâ„“pt ` hqq â€œ
Î´k,â„“h. The covariance is of course also taken with respect to Px. The process is
canonical because for â„¦we take â„¦â€œ C
`
r0, 8q, RdË˜
, for Xptq we take XptqpÏ‰q â€œ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
109 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Ï‰ptq, Ï‰ P â„¦. For F we take the Ïƒ-ï¬eld in â„¦, generated by the state variables
tXpsq : s Ä› 0u. For all this we often write
â£
pâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q ,
`
Rd, B
Ë˜(
.
Here the shift or translation operators Ï‘t, t Ä› 0, are deï¬ned by Ï‘tpÏ‰qpsq â€œ
Ï‰ps ` tq, Ï‰ P â„¦. We also introduce the ï¬ltration pFt : t Ä› 0q deï¬ned as the full
history: Ft is the Ïƒ-ï¬eld generated by the variables Xpsq, 0 Ä s Ä t. We also
shall need the right closure Ft` deï¬ned by Ft` â€œ Å
sÄ…t Fs.
In the following result we give some interesting martingale properties for Brow-
nian motion.
3.23. Proposition. Let
â£
pâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q ,
`
Rd, B
Ë˜(
be standard Brownian motion that starts at x P Rd and that has drift Âµ. For
t Ä… s the variable Xptq Â´ Xpsq does not depend on the Ïƒ-ï¬eld Fs. The following
processes are Px-martingales with respect to the ï¬ltration Ft, t Ä› 0:
t ÃÃ‘ Xptq Â´ tÂµ,
t ÃÃ‘ |Xptq Â´ tÂµ|2 Â´ dt.
Proof. The fact that the increment Xptq Â´ Xpsq does not depend on the
past Fs is explained in Remark 3.21 following Theorem 3.19. The other asser-
tions are consequences of this. Let s and t be positive real numbers. Then we
have
Ex
`
Xps ` tq Â´ ps ` tqÂµ
Ë‡Ë‡ Fs
Ë˜
Â´ pXpsq Â´ sÂµq
â€œ Ex
`
Xps ` tq Â´ Xpsq
Ë‡Ë‡ Fs
Ë˜
Â´ tÂµ
(increments are independent of the past)
â€œ Ex pXps ` tq Â´ Xpsqq Â´ tÂµ â€œ tÂµ Â´ tÂµ â€œ 0.
(3.50)
Similarly, but more complicated, we also see
Ex
â€œ
|Xps ` tq Â´ ps ` tqÂµ|2 Â´ dps ` tq Â´ |Xpsq Â´ sÂµ|2 ` ds
Ë‡Ë‡ Fs
â€°
â€œ Ex
â€œ
|Xps ` tq Â´ Xpsq Â´ tÂµ ` Xpsq Â´ sÂµ|2 Â´ dt Â´ |Xpsq Â´ sÂµ|2 Ë‡Ë‡ Fs
â€°
â€œ Ex
â€œ
|Xps ` tq Â´ Xpsq Â´ tÂµ|2 Â´ dt ` âŸ¨Xps ` tq Â´ Xpsq Â´ tÂµ, Xpsq Â´ sÂµâŸ©
Ë‡Ë‡ Fs
â€°
(use (3.50))
â€œ Ex
â€œ
|Xps ` tq Â´ Xpsq Â´ tÂµ|2 Ë‡Ë‡ Fs
â€°
Â´ dt
(again an application of (3.50))
â€œ Ex
â€œ
|Xps ` tq Â´ Xpsq Â´ tÂµ|2â€°
Â´ dt
â€œ
dÃ¿
kâ€œ1
cov pXkps ` tq Â´ Xkpsq, Xkps ` tq Â´ Xkpsqq Â´ dt â€œ dt Â´ dt â€œ 0.
(3.51)
This proves Proposition 3.23.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
110 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
So far we have looked at Brownian motion as a Gaussian process.
On the
other hand it is also a Markov process. We would like to discuss that now. In
fact mathematically speaking equality (3.47) in Theorem 3.19 is an equivalent
form of the Markov property. As already indicated in Remark 3.20 following
Theorem 3.19 the monotone class theorem is important for the proofs of the
several versions of the Markov property.
3.24. Definition. Let â„¦be a set and let S be a collection of subsets of â„¦. Then
S is a Dynkin system if it has the following properties:
(a) â„¦P S;
(b) if A and B belong to S and if A Äš B, then AzB belongs to S;
(c) if pAn : n P Nq is an increasing sequence of elements of S, then the union
Å¤8
nâ€œ1 An belongs to S.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planetâ€™s 
electricity needs. Already today, SKFâ€™s innovative know-
how is crucial to running a large proportion of the 
worldâ€™s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Advanced stochastic processes: Part I
111 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The following result on Dynkin systems is well-known.
3.25. Theorem. Let M be a collection of subsets of â„¦, which is stable under
ï¬nite intersections. The Dynkin system generated by M coincides with the Ïƒ-
ï¬eld generated by M.
3.26. Theorem. Let â„¦be a set and let M be a collection of subsets of â„¦, which
is stable (or closed) under ï¬nite intersections. Let H be a vector space of real
valued functions on â„¦satisfying:
(i) The constant function 1 belongs to H and 1A belongs to H for all A P M;
(ii) if pfn : n P Nq is an increasing sequence of non-negative functions in H such
that f â€œ supnPN fn is ï¬nite (bounded), then f belongs to H.
Then H contains all real valued functions (bounded) functions on â„¦, that are
ÏƒpMq measurable.
Proof. Put D â€œ tA Ä â„¦: 1A P Hu.
Then by (i) â„¦belongs to D and
D Äš M. If A and B are in D and if B Äš A, then BzA belongs to D. If
pAn : n P Nq is an increasing sequence in D, then 1YAn â€œ supn 1An belongs to
D by (ii). Hence D is a Dynkin system, that contains M. Since M is closed
under ï¬nite intersection, it follows by Theorem 3.25 that D Äš ÏƒpMq. If f Ä› 0
is measurable with respect to ÏƒpMq, then
f â€œ sup
n 2Â´n Ã¿n2n
jâ€œ1 1tfÄ›j2Â´nu.
(3.52)
Since 1tfÄ›j2Â´nu, j, n P N, belong to ÏƒpMq, we see that f belongs to H. Here we
employed the fact that ÏƒpMq Ä D. If f is ÏƒpMq-measurable, then we write f
as a diï¬€erence of two non-negative ÏƒpMq-measurable functions.
â–¡
The previous theorems (Theorems 3.25 and 3.26) are used in the following form.
Let â„¦be a set and let pEi, EiqiPI be a family of measurable spaces, indexed by an
arbitrary set I. For each i P I, let Si denote a collection of subsets of Ei, closed
under ï¬nite intersection, which generates the Ïƒ-ï¬eld Ei, and let fi : â„¦Ã‘ Ei be
a map from â„¦to Ei. In this context the following two propositions follow.
3.27. Proposition. Let M be the collection of all sets of the form
Ä
iPJ
f Â´1
i
pAiq,
Ai P Si,
i P J, J Ä I, J ï¬nite. Then M is a collection of subsets of â„¦which is stable
under ï¬nite intersection and ÏƒpMq â€œ Ïƒ pfi : i P Iq.
3.28. Proposition. Let H be a vector space of real-valued functions on â„¦such
that:
(i) the constant function 1 belongs to H;
(ii) if phn : n P Nq is an increasing sequence of non-negative functions in H
such that h â€œ supn hn is ï¬nite (bounded), then h belongs to H;
(iii) H contains all products of the form Å›
iPJ 1Ai Ë fi, J Ä I, J ï¬nite, and
Ai P Si, i P J.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
112 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Under these assumptions H contains all real-valued functions (bounded) func-
tions in Ïƒpfi : i P Iq.
The Theorems 3.25 and 3.26 and the Propositions 3.27 and 3.28 are called the
monotone class theorem.
In the following theorem F is the Ïƒ-ï¬eld generated by tXpsq : s Ä› 0u and Ft is
the Ïƒ-ï¬eld generated by the past or full history, i.e. Ft â€œ Ïƒ tXpsq : 0 Ä s Ä tu.
If T is an pFt`q-stopping time we write
FT` â€œ
Ä
tÄ›0
tA P F : A X tT Ä tu P Ft`u .
An pFt`q-stopping is an F-measurable map T from â„¦to r0, 8s with the property
that tT Ä tu belongs to Ft` for all t Ä› 0.
Notice that stopping times may take inï¬nite values. Often this is very interest-
ing.
3.29. Theorem. Let
â£
pâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q ,
`
Rd, B
Ë˜(
, x P Rd,
be d-dimensional Brownian motions. Then the following conditions are veriï¬ed:
(a1) For every Î± Ä… 0, for every t Ä› 0 and for every open subset U of Rd,
the set
â£
x P Rd : PxpXptq P Uq Ä… Î±
(
is open;
(a2) For every Î± Ä… 0, for every t Ä› 0 and for every compact subset K of
Rd, the set
â£
x P Rd : PxpXptq P Kq Ä› Î±
(
is compact;
(b) For every open subset U of Rd and for every x P U, the equality
lim
tÃ“0 Px pXptq P Uq â€œ 1 is valid.
Moreover d-dimensional Brownian motion has the following properties:
(i) For all t Ä› 0 and for all bounded random variables Y : â„¦Ã‘ C the equality
Ex pY Ë Ï‘t | Ftq â€œ EXptqpY q
(3.53)
holds Px-almost surely for all x P Rd;
(ii) For all ï¬nite tuples 0 Ä t1 Äƒ t2 Äƒ . . . Äƒ tn Äƒ 8 together with Borel subsets
B1, . . . , Bn of Rd the equality
Px pXpt1q P B1, . . . , Xptnq P Bnq
â€œ
Å¼
B1
. . .
Å¼
BnÂ´1
Å¼
Bn
Pptn Â´ tnÂ´1, xnÂ´1, dxnqPptnÂ´1 Â´ tnÂ´2, xnÂ´2, dxnÂ´1q
. . . Ppt2 Â´ t1, x1, dx2qPpt1, x, dx1q
(3.54)
is valid for all x P Rd (here PxpXptq P Bq â€œ Ppt, x, Bq);
(iii) For every pFt`q-stopping time T and for every bounded random variable
Y : â„¦Ã‘ C the equality
Ex pY Ë Ï‘T | FT`q â€œ EXpTq pY q ,
(3.55)
holds Px-almost surely on tT Äƒ 8u for all x P Rd;
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
113 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(iv) Let B1 be the Borel ï¬eld of r0, 8q. For every bounded function F : r0, 8q Ë†
â„¦Ã‘ C, which is measurable with respect to BbF, and for every pFt`q-stopping
time T the equality
Ex ptÏ‰ ÃÃ‘ F pTpÏ‰q, Ï‘TpÏ‰qqu | FT`q â€œ
â£
Ï‰1 ÃÃ‘ EXpTpÏ‰1qq tÏ‰ ÃÃ‘ F pTpÏ‰1q, Ï‰qu
(
(3.56)
holds Px-almost surely tT Äƒ 8u for all x P Rd.
Since d-dimensional Brownian motion veriï¬es (a1), (a2) and (b), the properties
in (i), (ii), (iii) and (iv) are all equivalent. Properties (i) and (ii) are always
equivalent and also (iii) and (iv). The implication (iii) Ã± (ii) is also clear. For
the reverse implication the full strength of (a1), (a2) and (b) is employed. The
fact that Brownian motion possesses property (ii) is a consequence of Theorem
3.19. In fact the right continuity of paths is very important. Since we have
proved that Brownian motion possesses continuous paths Px-almost surely this
condition is veriï¬ed. Property (i) is called the Markov property and property
(iii) is called the strong Markov property. Equality (3.56) is called the strong
time-dependent Markov property. We shall not prove this result. It is part of the
general theory of Markov processes and their sample path properties. It is also
closely connected to the theory of Feller semigroups. As in Theorem 3.29 let
â£
pâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q ,
`
Rd, B
Ë˜(
be Brownian motion starting
in x. In fact the family of operators tPptq : t Ä› 0u deï¬ned by rPptqfs pxq â€œ
Ex pfpXptqq, f P L8pRdq, t Ä› 0, is a Feller semigroup, because it possesses the
properties mentioned in the following deï¬nition.
In what follows E is a second countable locally compact Hausdorï¬€space, e.g.
E â€œ Rd. We deï¬ne a Feller semigroup as follows.
3.30. Definition. A family tPptq : t Ä› 0u of operators deï¬ned on L8pEq is a
Feller semigroup, or, more precisely, a Feller-Dynkin semigroup on C0pEq if it
possesses the following properties:
(i) It leaves C0pEq invariant: PptqC0pEq Ä C0pEq for t Ä› 0;
(ii) It is a semigroup: Pps ` tq â€œ Ppsq Ë Pptq for all s, t Ä› 0, and Pp0q â€œ I;
(iii) It consists of contraction operators: }Pptqf}8 Ä }f}8 for all t Ä› 0 and
for all f P C0pEq;
(iv) It is positivity preserving: f Ä› 0, f P C0pEq, implies Pptqf Ä› 0;
(v) It is continuous for t â€œ 0: limtÃ“0 rPptqfs pxq â€œ fpxq, for all f P C0pEq
and for all x P E.
In the presence of (iii) and (ii), property (v) is equivalent to:
(v1) limtÃ“0 }Pptqf Â´ f}8 â€œ 0 for all f P C0pEq.
So that a Feller semigroup is in fact strongly continuous in the sense that, for
every f P C0pEq,
lim
sÃ‘t }Ppsqf Â´ Pptqf}8 â€œ 0.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
114 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
It is perhaps useful to observe that C0pEq, equipped with the supremum-norm
}Â¨}8 is a Banach space (in fact it is a Banach algebra). A function f : E Ã‘ C
belongs to C0pEq if it is continuous and if for every Ïµ Ä… 0, there exists a compact
subset K of E such that |fpxq| Äƒ Ïµ for x R K. We need one more deï¬nition.
Let tPptq : t Ä› 0u be a Feller semigroup. Deï¬ne for U an open subset of E, the
transition probability Ppt, x, Uq, t Ä› 0, x P E, by
Ppt, x, Uq â€œ sup trPptqus pxq : 0 Ä u Ä 1U, u P C0pEqu .
This transition function can be extended to all Borel subsets by writing
Ppt, x, Kq â€œ inf tPpt, x, Uq : U open U Äš Ku ,
for K a compact subset of E. If B is a Borel subset of E, then we write
Ppt, x, Bq â€œ inf tPpt, x, Uq : U Äš B, U open u
â€œ sup tPpt, x, Kq : K Ä B, K compact u .
It then follows that the mapping B ÃÃ‘ Ppt, x, Bq is a Borel measure on E, the
Borel ï¬eld of E. The Feller semigroup is said to be conservative if, for all t Ä› 0
and for all x P E, Ppt, x, Eq â€œ 1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
115 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We want to conclude this section with a convergence result for Gaussian pro-
cesses.
3.31. Proposition. Let
Â´
Xpnq
s
: s P I
Â¯
, n P N, be a sequence of Gaussian pro-
cesses. Let pXs : s P Iq be a process with property that
E rXuXvs â€œ lim
nÃ‘8 E
â€œ
Xpnq
u Xpnq
v
â€°
,
for all u and v in I and
E rXus â€œ lim
nÃ‘8 E
â€œ
Xpnq
u
â€°
,
for all u P I.
Also suppose that, in weak sense,
lim
nÃ‘8
`
Xpnq
u1 , . . . , Xpnq
um
Ë˜
â€œ pXu1, . . . , Xumq
for all ï¬nite subsets pu1, . . . , umq of I. Then the process pXs : s P Iq is Gaussian
as well.
Proof. Let Î¾1, . . . , Î¾m be real numbers, and let u1, . . . , um be members of
I. Then
E
Ëœ
exp
Ëœ
Â´i
m
Ã¿
kâ€œ1
Î¾kXpnq
uk
Â¸Â¸
â€œ exp
Ëœ
Â´i
m
Ã¿
kâ€œ1
Î¾kE
`
Xpnq
uk
Ë˜
Â´ 1
2
m
Ã¿
k,â„“â€œ1
Î¾kÎ¾â„“cov
`
Xpnq
uk , Xpnq
uâ„“
Ë˜
Â¸
.
Next let n tend to inï¬nity to obtain (here we employ LÂ´evyâ€™s theorem on weak
convergence):
E
Ëœ
exp
Ëœ
Â´i
m
Ã¿
kâ€œ1
Î¾kXuk
Â¸Â¸
â€œ exp
#
Â´i
m
Ã¿
kâ€œ1
Î¾kE rXuks Â´ 1
2
m
Ã¿
k,â„“â€œ1
Î¾kÎ¾â„“E rpXuk Â´ E pXukqq pXuâ„“Â´ E pXuâ„“qqs
+
.
So the result in Proposition 3.31 follows.
â–¡
For LÂ´evyâ€™s weak convergence theorem see Theorem 5.42.
3.32. Theorem. Brownian motion is a Markov process. More precisely, (3.53)
is satisï¬ed.
Proof. Let F be a bounded stochastic variable.
We have to show the
following identity:
Ex
â€œ
F Ë Ï‘t
Ë‡Ë‡ Ft
â€°
â€œ EXptq rFs ,
Px-almost surely.
It suï¬ƒces to show that
Ex rF Ë Ï‘t Ë† Gs â€œ Ex
â€œ
EXptq rFs G
â€°
(3.57)
for all bounded stochastic variables F and for all bounded Ft-measurable func-
tions G. By an application of the monotone class theorem twice (see Proposi-
tion 3.28) it suï¬ƒces to take F of the form F â€œ Å›m
jâ€œ1 fj pX psjqq, 0 Ä s1 Äƒ s2 Äƒ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
116 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Â¨ Â¨ Â¨ sm Äƒ 8, and G of the form G â€œ Å›n
jâ€œ1 gj pX ptjqq, 0 Ä t1 Äƒ t2 Äƒ Â¨ Â¨ Â¨ Äƒ tn Äƒ t.
Here f1, . . . , fm and g1, . . . , gm are bounded continuous functions from Rd to R
or C. Once the monotone class theorem is applied to the vector space
â£
G P L8 pâ„¦, Ftq : Ex
â€œ
EXptq rFs Ë† G
â€°
â€œ Ex rF Ë Ï‘t Ë† Gs
(
,
where F is as above, and once to the vector space
â£
F P L8 pâ„¦, Fq : EXptq rFs â€œ Ex
â€œ
F Ë Ï‘t
Ë‡Ë‡ Ft
â€°
,
Px-almost surely
(
.
Then (3.57) may be rewritten as
Ex rf1 pX ps1 ` tqq Â¨ Â¨ Â¨ fm pX psm ` tqq g1 pX pt1qq Â¨ Â¨ Â¨ gn pX ptnqqs
â€œ Ex
â€œ
EXptq rf1 pX ps1qq Â¨ Â¨ Â¨ fm pX psmqqs g1 pX pt1qq Â¨ Â¨ Â¨ gn pX ptnqq
â€°
.
(3.58)
Put Ï„j â€œ tj, 1 Ä j Ä n, Ï„n`k â€œ sk `t, 1 Ä k Ä m; hj â€œ gj, 1 Ä j Ä n, hn`k â€œ fk,
1 Ä k Ä m. By deï¬nition we have
Ex rf1 pX ps1 ` tqq Â¨ Â¨ Â¨ fm pX psm ` tqq g1 pX pt1qq Â¨ Â¨ Â¨ gn pX ptnqqs
â€œ Ex rhj px pÏ„1qq Â¨ Â¨ Â¨ hn`m pX pÏ„n`mqqs
â€œ
Å¼
. . .
Å¼
dx1 . . . dxn`mh1 px1q Â¨ Â¨ Â¨ hn`m pxn`mq
p pÏ„1, x, x1q Â¨ Â¨ Â¨ p pÏ„n`m Â´ Ï„n`mÂ´1, xn`mÂ´1, xn`mq .
(3.59)
Next we rewrite the right-hand side of (3.58):
Ex
â€œ
EXptq rf1 pX ps1qq Â¨ Â¨ Â¨ fm pX psmqqs g1 pX pt1qq Â¨ Â¨ Â¨ gn pX ptnqq
â€°
â€œ Ex
â€
g1 pX pt1qq Â¨ Â¨ Â¨ gn pX ptnqq
Å¼
. . .
Å¼
dy1 . . . dymf1 py1q Â¨ Â¨ Â¨ fm pymq
p ps1, Xptq, y1q Â¨ Â¨ Â¨ p psm Â´ smÂ´1, ymÂ´1, ymq
È·
â€œ
Å¼
. . .
Å¼
dz1 . . . dzng1 pz1q Â¨ Â¨ Â¨ gn pznq
p pt1, x, z1q Â¨ Â¨ Â¨ p ptn Â´ tnÂ´1, znÂ´1, znq
Å¼
dzp pt Â´ tn, zn, zq
Å¼
. . .
Å¼
dy1 . . . dymf1 py1q Â¨ Â¨ Â¨ fm pymq
p ps1, z, y1q Â¨ Â¨ Â¨ p psm Â´ smÂ´1, ymÂ´1, ymq
(Chapman-Kolmogorov:
ÅŸ
p pt Â´ tn, zn, zq p ps1, z, yq dz â€œ p ps1 ` t Â´ tn, zn, yq)
â€œ
Å¼
. . .
Å¼
dz1 . . . dzng1 pz1q Â¨ Â¨ Â¨ gn pznq
Å¼
. . .
Å¼
dy1 Â¨ Â¨ Â¨ dymf py1q Â¨ Â¨ Â¨ fm pymq
p pt1, x, z1q Â¨ Â¨ Â¨ p ptn Â´ tnÂ´1, znÂ´1, znq
p ps1 ` t Â´ tn, zn, y1q Â¨ Â¨ Â¨ p psm Â´ smÂ´1, ymÂ´1, ymq
â€œ Ex rf1 pX ps1 ` tqq Â¨ Â¨ Â¨ fm pX psm ` tqq g1 pX pt1qq Â¨ Â¨ Â¨ gn pX ptnqqs .
(3.60)
Since the expressions in (3.59) and (3.60) are the same, this proves the Markov
property of Brownian motion. The proof of Theorem 3.32 is now complete.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
117 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3. Some results on Markov processes, on Feller semigroups and on
the martingale problem
Let E be a second countable locally compact Hausdorï¬€space, let Eâ–³be its
one-point compactiï¬cation or, if E is compact, let â–³be an isolated point of
Eâ–³â€œ E Å¤ â–³. Deï¬ne the path space â„¦as follows. The path space â„¦is a subset
of
`
Eâ–³Ë˜r0,8q with the following properties:
(i) If Ï‰ belongs to â„¦, if t Ä› 0 is such that Ï‰ptq â€œ â–³and if s Ä› t, then
Ï‰psq â€œ â–³;
(ii) Put Î¶pÏ‰q â€œ inf ts Ä… 0 : Ï‰psq â€œ â–³u for Ï‰ P â„¦. If Ï‰ belongs to â„¦, then Ï‰
possesses left limits in Eâ–³on the interval r0, Î¶s and it is right-continuous
on r0, 8q;
(iii) If Ï‰ belongs to â„¦, if t Ä› 0 is such that Ï‰ptq belongs to E, then the closure
of the set tÏ‰psq : 0 Ä s Ä tu is a compact subset of E or, equivalently,
if t Ä… 0 is such that Ï‰ptÂ´q â€œ â–³and if s Ä› t, then Ï‰psq â€œ â–³.
3.33. Definition. The random variable Î¶, deï¬ned in (iii.) is called the life
time of Ï‰. A path Ï‰ P â„¦is said to be cadlag on its life time. We also deï¬ne
the state variables Xptq : â„¦Ã‘ Eâ–³by XptqpÏ‰q â€œ Xpt, Ï‰q â€œ Ï‰ptq, t Ä› 0,
Ï‰ P â„¦.
The translation or shift operators are deï¬ned in the following way:
rÏ‘tpÏ‰qspsq â€œ Ï‰ps ` tq, s, t Ä… 0 and Ï‰ P â„¦. The largest subset of
`
Eâ–³Ë˜r0,8q
with the properties (i), (ii) and (iii) is sometimes written as D
`
r0, 8q , Eâ–³Ë˜
or
as DEâ–³pr0, 8qq. Let F be a Ïƒ-ï¬eld on â„¦. A function Y : â„¦Ã‘ C is called a
random variable if it is measurable with respect to F. Of course C is supplied
with its Borel ï¬eld. The so-called state space E is also equipped with its Borel
ï¬eld E and Eâ–³is also equipped with its Borel ï¬eld Eâ–³. The path Ï‰â–³is given
by Ï‰â–³psq â€œ â–³, s Ä› 0. Unless speciï¬ed otherwise we write â„¦â€œ Dpr0, 8q , Eâ–³q.
The space Dpr0, 8q , Eâ–³q is also called Skorohod space. In addition let F be a
Ïƒ-ï¬eld on â„¦and let tFt : t Ä› 0u be a ï¬ltration on â„¦. Suppose Ft Ä F, t Ä› 0,
and suppose that every state variable Xptq, t Ä› 0, is measurable with respect to
Ft. (This is the case where e.g. Ft is the Ïƒ-ï¬eld generated by tXpsq : s Ä tu.)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
118 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We also want to make a digression to operator theory. Let L be a linear operator
with domain DpLq and range RpLq contained in C0pEq. The operator L is said
to be closable if the closure of its graph is again the graph of an operator. Here
the graph of L, GpLq, is deï¬ned by GpLq â€œ tpf, Lfq : f P DpLqu. Its closure
is the closure of GpLq in the cartesian product C0pEq Ë† C0pEq. If the closure
of GpLq is the graph of an operator, then this operator is, by deï¬nition, the
closure of L. It is written as L. Sometimes L is called the smallest closure of L.
3.34. Definition. Let L be a linear operator with domain and range in C0pEq.
(i) The operator L is said to be dissipative if, for all Î» Ä… 0 and for all
f P DpLq,
}Î»f Â´ Lf}8 Ä› Î» }f}8 .
(3.61)
(ii) The operator L is said to verify the maximum principle if for every f P
DpLq with sup tRe fpxq : x P Eu strictly positive, there exists x0 P E
with the property that
Re fpx0q â€œ sup tRe fpxq : x P Eu
and
Re Lfpx0q Ä 0.
(iii) The martingale problem is said to be uniquely solvable, or well-posed,
for the operator L, if for every x P E there exists a unique probability
P â€œ Px which satisï¬es:
(a) For every f P DpLq the process
fpXptqq Â´ fpXp0qq Â´
Å¼ t
0
LfpXpsqqds,
t Ä› 0,
is a P-martingale;
(b) PpXp0q â€œ xq â€œ 1.
(iv) The operator L is said to solve the martingale problem maximally if
for L the martingale problem is uniquely solvable and if its closure L is
maximal for this property. This means that, if L1 is any linear operator
with domain and range in C0pEq, which extends L and for which the
martingale problem is uniquely solvable, then L coincides with L1.
(v) The operator L is said to be the (inï¬nitesimal) generator of a Feller
semigroup
tPptq : t Ä› 0u ,
if L â€œ s-lim
tÃ“0
Pptq Â´ I
t
. This means that a function f belongs to DpLq
whenever Lf :â€œ lim
tÃ“0
Pptqf Â´ f
t
exists in C0pEq.
An operator which veriï¬es the maximum principle is dissipative (see e.g. [141],
p. 14) and can be considered as kind of a generalized second order derivative
operator. A prototype of such an operator is the Laplace operator. An operator
for which the martingale problem is uniquely solvable is closable. This follows
from (3.125) below. Our main result says that linear operators in C0pEq which
maximally solve the martingale problem are generators of Feller semigroups and
conversely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
119 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.35. Definition. Next suppose that, for every x P E, a probability measure
Px on F is given. Suppose that for every bounded random variable Y : â„¦Ã‘ R
the equality Ex pY Ë Ï‘t | Ftq â€œ EXptqpY q holds Px-almost surely for all x P E
and for all t Ä› 0. Then the process
tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ
is called a Markov process. If the ï¬xed time t may be replaced with a stopping
time T, the process tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ is called a
strong Markov process.
By deï¬nition Pâ–³pAq â€œ 1ApÏ‰â–³q â€œ Î´Ï‰â–³pAq.
Here A
belongs to F. If the process tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ is a
Markov process, then we write
Ppt, x, Bq â€œ PxpXptq P Bq,
t Ä› 0,
B P E,
x P E,
(3.62)
for the corresponding transition function. The operator family tPptq : t Ä› 0u is
deï¬ned by rPptqfspxq â€œ Ex pfpXptqqq, f P C0pEq.
An relevant book on Markov processes is Ethier and Kurtz [54]. An elementary
theory of diï¬€usions is given in Durrett [45]. In this aspect the books of Stroock
and Varadhan [133], Stroock [132] [131], and Ikeda and Watanabe [61] are of
interest as well.
We shall mainly be interested in the case that the function Pptqf is a mem-
ber of C0pEq whenever f is so.
In the following theorem F is the Ïƒ-ï¬eld
generated by tXpsq : s Ä› 0u and Ft is the Ïƒ-ï¬eld generated by the past or
full history, i.e. Ft â€œ Ïƒ tXpsq : 0 Ä s Ä tu. If T is a stopping time we write
FT` â€œ Å
tÄ›0 tA P F : A X tT Ä tu P Ft`u.
3.36. Theorem. Let pâ„¦, F, Pxq, x P E, be probability spaces with the following
properties:
(a1) For every Î± Ä… 0, for every t Ä› 0 and for every open subset U of E, the
set tx P E : PxpXptq P Uq Ä… Î±u is open;
(a2) For every Î± Ä… 0, for every t Ä› 0 and for every compact subset K of E,
the set tx P E : PxpXptq P Kq Ä› Î±u is compact;
(c) For every open subset U of E and for every x P U, the equality
lim
tÃ“0 Px pXptq P Uq â€œ 1 is valid.
The following assertions are equivalent:
(i) For all t Ä› 0 and for all bounded random variables Y : â„¦Ã‘ C the equality
Ex pY Ë Ï‘t | Ftq â€œ EXptqpY q
(3.63)
holds Px-almost surely for all x P E;
(ii) For all ï¬nite tuples 0 Ä t1 Äƒ t2 Äƒ . . . Äƒ tn Äƒ 8 together with Borel subsets
B1, . . . , Bn of E the equality
Px pXpt1q P B1, . . . , Xptnq P Bnq
â€œ
Å¼
B1
. . .
Å¼
BnÂ´1
Å¼
Bn
Pptn Â´ tnÂ´1, xnÂ´1, dxnqPptnÂ´1 Â´ tnÂ´2, xnÂ´2, dxnÂ´1q
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
120 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
. . . Ppt2 Â´ t1, x1, dx2qPpt1, x, dx1q
(3.64)
is valid for all x P E (here PxpXptq P Bq â€œ Ppt, x, Bq);
(iii) For every pFt`q-stopping time T and for every bounded random variable
Y : â„¦Ã‘ C the equality
Ex pY Ë Ï‘T | FT`q â€œ EXpTq pY q ,
(3.65)
holds Px-almost surely on tT Äƒ 8u for all x P E;
(iv) Let B be the Borel ï¬eld of r0, 8q. For every bounded function F : r0, 8q Ë†
â„¦Ã‘ C, which is measurable with respect to BbF, and for every pFt`q-stopping
time T the equality
Ex ptÏ‰ ÃÃ‘ F pTpÏ‰q, Ï‘TpÏ‰qqu | FT`q â€œ
â£
Ï‰1 ÃÃ‘ EXpTpÏ‰1qq tÏ‰ ÃÃ‘ F pTpÏ‰1q, Ï‰qu
(
(3.66)
holds Px-almost surely tT Äƒ 8u for all x P E.
Equality (3.66) is called the strong time-dependent Markov property. We shall
not prove this result.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
121 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.37. Theorem. Let tPptq : t Ä› 0u be a Feller semigroup. There exists a col-
lection of probabilities pPxqxPE on the Ïƒ-ï¬eld F generated by the state variables
tXptq : t Ä› 0u deï¬ned on â„¦:â€œ D
`
r0, 8q , Eâ–³Ë˜
in such a way that
Ex rf pXpt1q, . . . , Xptnqqs â€œ
Å¼
f pXpt1q, . . . , Xptnqq dPx
â€œ
Å¼
. . .
Å¼
fpx1, x2, . . . , xnqPptn Â´ tnÂ´1, xnÂ´1, dxnqPptnÂ´1 Â´ tnÂ´2, xnÂ´2, dxnÂ´1q
. . . Ppt2 Â´ t1, x1, dx2qPpt1, x, dx1q,
(3.67)
where f is any bounded complex or non-negative Borel measurable function de-
ï¬ned on Eâ–³Ë† . . . Ë† Eâ–³, that vanishes outside of E Ë† . . . Ë† E. Let the measure
spaces pâ„¦, F, PxqxPE be as in (3.67). The process
tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ
is a strong Markov process.
The proof of this result is quite technical. The ï¬rst part follows from a well-
known theorem of Kolmogorov on projective systems of measures: see Theorems
1.14, 3.1, 5.81. In the second part we must show that the indicated path space
has full measure, so that no information is lost. Proofs are omitted. They can
be found in for example Blumenthal and Getoor [20], Theorem 9.4. p. 46.
For a discussion in the context of Polish spaces see, e.g., Sharpe [120] or Van
Casteren [146]. For the convenience of the reader we include an outline of the
proof of Theorem 3.37. The following lemma is needed in the proof.
3.38. Lemma. Let pâ„¦, Ft, Pq be a probability space, and let t ÃÃ‘ Y ptq, be a
supermartingale, which attains positive values. Fix t Ä… 0 and let D be a dense
countable subset of r0, 8q. Then
P
â€
Y ptq Ä… 0,
inf
0ÄƒsÄƒt, sPD Y psq â€œ 0
È·
â€œ 0.
(3.68)
Proof. Let psjqj be an enumeration of the set D X r0, 8q. Fix n, N P N,
and deï¬ne the stopping time Sn,N by
Sn,N â€œ min
"
sj :
min
1ÄjÄN Y psjq Äƒ 2Â´n
*
.
Then we have Y pSn,Nq Äƒ 2Â´n on the event tSn,N Äƒ 8u. In addition, by the
supermartingale property (for discrete stopping times) we infer
E
â€
Y ptq, min
1ÄjÄN Y psjq Äƒ 2Â´n
È·
Ä E rY ptq, Sn,N Äƒ ts
â€œ E rY ptq, min pSn,N, tq Äƒ ts
Ä E rY pmin pSn,N, tqq , min pSn,N, tq Äƒ ts
â€œ E rY pSn,Nq , Sn,N Äƒ ts
Ä E
â€œ
2Â´n, Sn,N Äƒ t
â€°
Ä 2Â´n.
(3.69)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
122 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In (3.69) we let N Ã‘ 8 to obtain:
E
â€
Y ptq,
inf
0ÄƒsÄƒt, sPD Y psq Äƒ 2Â´n
È·
Ä 2Â´n.
(3.70)
In (3.70) we let n Ã‘ 8 to get:
E
â€
Y ptq,
inf
0ÄƒsÄƒt, sPD Y psq â€œ 0
È·
â€œ 0.
(3.71)
Let Î± Ä… 0 be arbitrary. From (3.71) it follows that
P
â€
Y ptq Ä… Î±,
inf
0ÄƒsÄƒt, sPD Y psq â€œ 0
È·
Ä 1
Î±E
â€
Y ptq,
inf
0ÄƒsÄƒt, sPD Y psq â€œ 0
È·
â€œ 0.
(3.72)
Then in (3.72) we let Î± Ã“ 0 to complete the proof of Lemma 3.38.
â–¡
Let tPptq : t Ä› 0u be a Feller-Dynkin semigroup acting on C0pEq where E is a
locally compact Hausdorï¬€space. In the proof of Theorem 3.37 we will also use
the resolvent operators tRpÎ±q : Î± Ä… 0u: RpÎ±qfpxq â€œ
ÅŸ8
0 eÂ´Î±tPptqfpxq dt, Î± Ä… 0,
f P C0pEq. An important property is the resolvent equation:
RpÎ²q Â´ RpÎ±q â€œ pÎ± Â´ Î²q RpÎ±qRpÎ²q,
Î±, Î² Ä… 0.
The latter property is a consequence of the semigroup property.
3.39. Remark. The space E is supposed to be a second countable (i.e.
it
is a topological space with a countable base for its topology) locally compact
Hausdorï¬€space (in particular it is a Polish space). A second-countable locally-
compact Hausdorï¬€space is Polish.
Let pUiqi be a countable basis of open
subsets with compact closures, choose for each i P N, yi P Ui, together with a
continuous function fi : E Ã‘ r0, 1s such that fi pyiq â€œ 1 and such that fi pyq â€œ 0
for y R Ui. Since a locally compact Hausdorï¬€space is completely regular this
choice is possible. Put
dpx, yq â€œ
8
Ã¿
iâ€œ1
2Â´i |fipxq Â´ fipyq| `
Ë‡Ë‡Ë‡Ë‡
1
Å™8
iâ€œ1 2Â´ifipxq Â´
1
Å™8
iâ€œ1 2Â´ifipyq
Ë‡Ë‡Ë‡Ë‡ ,
x, y P E.
This metric gives the same topology, and it is not too diï¬ƒcult to verify its
completeness. For this notice that the sequence pfiqi separates the points of E,
and therefore the algebraic span (i.e. the linear span of the ï¬nite products of
the functions fi) is dense in C0pEq for the topology of uniform convergence. A
proof of the fact that a locally compact space is completely regular can be found
in Willard [152] Theorem 19.3. The connection with Urysohnâ€™s metrization
theorem is also explained. A related construction can be found in Garrett [57]:
see Dixmier [39] Appendix V as well.
3.40. Remark. Next we present the notion of Skorohod space. Let D pr0, 1s, Rq
be the space of real-valued functions Ï‰ deï¬ned on the interval r0, 1s that are
right-continuous and have left-hand limits, i.e., Ï‰ptq â€œ Ï‰ pt`q â€œ limsÃ“t Ï‰psq for
all 0 Ä t Äƒ 1, and Ï‰ ptÂ´q â€œ limsÃ’t Ï‰psq exists for all 0 Äƒ t Ä 1. (In probabilistic
literature, such a function is also said to be a cadlag function, â€œcadlagâ€ being an
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
123 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
acronym for the French â€œcontinu `a droite, limites `a gaucheâ€.) The supremum
norm on D pr0, 1s, Rq, given by
}Ï‰}8 â€œ sup
tPr0,1s
|Ï‰ptq| ,
Ï‰ P D pr0, 1s, Rq ,
turns the space D pr0, 1s, Rq into a Banach space which is non-separable. This
non-separability causes well-known problems of measurability in the theory of
weak convergence of measures on the space. To overcome this inconvenience,
A.V. Skorohod introduced a metric (and topology) under which the space be-
comes a separable metric space. Although the original metric introduced by
Skorohod has a drawback in the sense that the metric space obtained is not
complete, it turned out (see Kolmogorov [70]) that it is possible to construct
an equivalent metric (i.e., giving the same topology) under which the space
D pr0, 1s, Rq becomes a separable and complete metric space. Such metric space
the term Polish space is often used.
This metric is deï¬ned as follows, and
taken from Paulauskas in [110]. Let Î› denote the class of strictly increasing
continuous mappings of r0, 1s onto itself. For Î» P Î›, let
}Î»} â€œ
sup
0ÄsÄƒtÄ1
Ë‡Ë‡Ë‡Ë‡log Î»ptq Â´ Î»psq
t Â´ s
Ë‡Ë‡Ë‡Ë‡ .
Then for Ï‰1 and Ï‰2 P D pr0, 1s, Rq we deï¬ne
d pÏ‰1, Ï‰2q â€œ inf
Î»PÎ› max p}Î»} , }Ï‰1 Â´ Ï‰2 Ë Î³}8q .
The topology generated by this metric is called the Skorohod topology and
the complete separable metric space D pr0, 1s, Rq is called the Skorohod space.
This space is very important in the theory of stochastic processes. The general
theory of weak convergence of probability measures on metric spaces and, in
particular, on the space D pr0, 1s, Rq is well developed. This theory was started
in the fundamental papers like Chentsov [33], Kolmogorov [70], Prohorov [112],
Skorohod [122].
A well-known reference on these topics is Billingsley [17].
Generalizations of the Skorohod space are worth mentioning. Instead of real-
valued functions on r0, 1s it is possible to consider functions deï¬ned on r0, 8q and
taking values in a metric space E. The space of cadlag functions obtained in this
way is denoted by D pr0, 8q, Eq and if E is a Polish space, then D pr0, 8q, Eq,
with the appropriate topology, is also a Polish space, see Ethier and Kurtz [54]
and Pollard [111], where these spaces are treated systematically.
Outline of a proof of Theorem 3.37. Firstly, the Riesz representa-
tion theorem, applied to the functionals f ÃÃ‘ Pptqfpxq, f P C0pEq, pt, xq P
r0, 8q Ë† E, provides a family of sub-probability measures B ÃÃ‘ P pt, x, Bq,
B P E, pt, xq P r0, 8q Ë† E, with P p0, x, Bq â€œ Î´x pBq â€œ 1Bpxq. From the semi-
group property, i.e. Pps ` tq â€œ PpsqPptq, s, t Ä› 0, it follows that the family
tP pt, x, Â¨q : pt, xq P r0, 8qu obeys the Chapman-Kolmogorov identity:
P ps ` t, x, Bq â€œ
Å¼
P pt, y, Bq P ps, x, dyq ,
B P E, s Ä› 0, t Ä› 0, x P E. (3.73)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
124 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The measures B ÃÃ‘ Ppt, x, Bq, B P E, are inner and outer regular in the sense
that, for all Borel subsets B (i.e. B P E),
P pt, x, Bq â€œ sup tPpt, x, Kq : K Ä‚ B, K compactu
â€œ inf tP pt, x, Oq : O Ä„ B, O openu .
(3.74)
In general we have 0 Ä P pt, x, Bq Ä 1, pt, x, Bq P r0, 8q Ë† E Ë† E. In order
to apply Kolmogorovâ€™s extension theorem we need that, for every x P E, the
function t ÃÃ‘ Ppt, x, Eq is constant. Since Pp0, x, Eq â€œ 1 this constant must be
1. This can be achieved by adding an absorption point â–³to E. So instead of
E we consider the state space Eâ–³â€œ E Y tâ–³u, which, topologically speaking,
can be considered as the one-point compactiï¬cation of E, if E is not compact.
If E is compact, â–³is an isolated point of Eâ–³. Let Eâ–³be the Borel ï¬eld of Eâ–³.
Then the new family of probability measures tN pt, x, Â¨q : pt, xq P r0, 8q Ë† Eu is
deï¬ned as follows:
N pt, x, Bq â€œ P pt, x, B X Eq ` p1 Â´ P pt, x, Eqq 1B pâ–³q , pt, xq P r0, 8q Ë† E,
N pt, â–³, Bq â€œ 1B pâ–³q ,
t Ä› 0, B P Eâ–³.
(3.75)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENTâ€¦
     RUN FASTER.
          RUN LONGER..
                RUN EASIERâ€¦
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Advanced stochastic processes: Part I
125 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Compare this construction with the one in (1.1). The family
N :â€œ tN pt, x, Â¨q : pt, xq P r0, 8q Ë† Eu
again satisï¬es the Chapman-Kolmogorov identity with state space Eâ–³instead of
E. Notice that N pt, x, Bq â€œ P pt, x, Bq whenever pt, x, Bq belongs to r0, 8qË†EË†
E. Employing the family N we deï¬ne a family of probability spaces as follows.
For every x0 P E, and every increasing n-tuple 0 Ä t1 Äƒ Â¨ Â¨ Â¨ Äƒ tn Äƒ 8 in r0, qn
we consider the probability space
``
Eâ–³Ë˜n , bnEâ–³, Px0,t1,...,tn
Ë˜
: the probability
measure Px0,t1,...,tn is deï¬ned by
Px0,t1,...,tnpBq â€œ
Å¼
. . .
Å¼
B
N pt1 Â´ t0, x0, dx1q Â¨ Â¨ Â¨ N ptn Â´ tnÂ´1, xnÂ´1, dxnq ,
(3.76)
where B P bnEâ–³. By an appeal to the Chapman-Kolmogorov identity it follows
that, for x0 P E ï¬xed, the family of probability spaces:
â£``
Eâ–³Ë˜n , bnEâ–³, Px0,t1,...,tn
Ë˜
: 0 Ä t1 Äƒ Â¨ Â¨ Â¨ Äƒ tn Äƒ 8, n P N
(
(3.77)
is a projective system of probability spaces. Put râ„¦â–³â€œ
`
Eâ–³Ë˜r0,8q, and equip this
space with the product Ïƒ-ï¬eld rFâ–³:â€œ br0,8qEâ–³. In addition, write r
XptqpÏ‰q â€œ
Ï‰ptq, Ï‘tÏ‰psq â€œ Ï‰ps ` tq, s, t Ä› 0, Ï‰ P râ„¦â–³. The variables r
Xptq, t Ä› 0, are called
the state variables, and the mappings Ï‘t, t Ä› 0, are called the (time) translation
or shift operators. By Kolmogorovâ€™s extension theorem there exists, for every
x P Eâ–³, a probability measure rPx on the Ïƒ-ï¬eld rFâ–³such that
rPx
â€Â´
r
X pt1q , Â¨ Â¨ Â¨ , r
X ptnq
Â¯
P B
Ä±
â€œ Px,t1,...,tn rBs .
(3.78)
In (3.78) B belongs to bnEâ–³, and 0 Ä t1 Äƒ Â¨ Â¨ Â¨ Äƒ tn Äƒ 8 is an arbitrary increas-
ing n-tuple in r0, 8q. Another appeal to the Chapman-Kolmogorov identity and
the monotone class theorem shows that the quadruple
!Â´
râ„¦â–³, rFâ–³, rPx
Â¯
,
Â´
r
Xptq, t Ä› 0
Â¯
, pÏ‘t, t Ä› 0q ,
`
Eâ–³, Eâ–³Ë˜)
(3.79)
is a Markov process relative to the internal history, i.e. relative to the ï¬ltration
rFâ–³
t â€œ Ïƒ
Â´
r
Xpsq : 0 Ä s Ä t
Â¯
, t Ä› 0. Moreover, we have rPx
â€
r
Xp0q â€œ x
Ä±
â€œ 1, and,
by the Markov property, we also have, for x P Eâ–³, t Ä… s Ä› 0,
rPx
â€
r
Xptq â€œ â–³, r
Xpsq â€œ â–³
Ä±
â€œ rEx
â€
rPx
â€
r
Xpt Â´ sq Ë Ï‘s â€œ â–³
Ë‡Ë‡ rFâ–³Ä±
, r
Xpsq â€œ â–³
Ä±
(Markov property)
â€œ rEx
â€
rP r
Xpsq rXpt Â´ sq â€œ â–³s , r
Xpsq â€œ â–³
Ä±
â€œ rEx
â€
rPâ–³
â€
r
Xpt Â´ sq â€œ â–³
Ä±
, r
Xpsq â€œ â–³
Ä±
â€œ N pt Â´ s, â–³, tâ–³uq Â¨ N ps, x, tâ–³uq
â€œ N ps, x, tâ–³uq â€œ rPx
â€
r
Xpsq â€œ â–³
Ä±
.
(3.80)
The equality in (3.80) says that once the process t ÃÃ‘ r
Xptq enters â–³it stays
there. In other words â–³is an absorption point for the process r
X. Deï¬ne, for t Ä…
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
126 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
0, the mapping rPptq : C
`
Eâ–³Ë˜
Ã‘ C
`
Eâ–³Ë˜
by rPptqfpxq â€œ rEx
â€
f
Â´
r
Xptq
Â¯Ä±
, f P
C
`
Eâ–³Ë˜
. From the Markov property of the process r
X, and since the semigroup
t ÃÃ‘ Pptq is a Feller-Dynkin semigroup, it follows that the mappings rPptq, t Ä› 0,
constitute a Feller (or Feller-Dynkin semigroup) on C
`
Eâ–³Ë˜
. Consequently, for
any f P C
`
Eâ–³Ë˜
, and any t0 Ä› 0, we have
lim
s,tÃ‘t0, s, tÄ›0 sup
xPEâ–³
rEx
â€Ë‡Ë‡Ë‡f
Â´
r
Xptq
Â¯
Â´ f
Â´
r
Xpsq
Â¯Ë‡Ë‡Ë‡
Ä±
â€œ 0.
(3.81)
Let D be the collection of non-negative dyadic rational numbers. Since the
space Eâ–³is compact-metrizable, it follows from (3.81) that, for all x P Eâ–³, the
following limits
lim
sÃ’t, sPD
r
Xpsq,
and
lim
sÃ“t, sPD
r
Xpsq,
(3.82)
exist in Eâ–³rPx-almost surely. Deï¬ne the mapping Ï€ : râ„¦â–³Ã‘ â„¦by
Ï€pÏ‰qptq â€œ
lim
sÃ“t, sPD
r
Xpsq pÏ‰q â€œ: Xptq pÏ€pÏ‰qq ,
t Ä› 0,
Ï‰ P râ„¦â–³.
(3.83)
Then we have that, for every x P Eâ–³ï¬xed, the processes t ÃÃ‘ Xptq Ë Ï€ and t ÃÃ‘
r
Xptq are rPx-indistinguishable in the sense that there exists an event râ„¦â–³,1 Ä‚ râ„¦â–³
such that rPx
â€
râ„¦â–³,1Ä±
â€œ 1 and such that for all t P r0, 8q the equality r
Xptq â€œ
XptqËÏ€ holds on the event râ„¦â–³,1. This assertion is a consequence of the following
argument. For every pt, xq P r0, 8q Ë† Eâ–³and for every f P C
`
Eâ–³Ë˜
we see
rEx
â€
f pXptq Ë Ï€q Â´ f
Â´
r
Xptq
Â¯Ä±
â€œ
lim
sÃ“t, sPD
rEx
â€
f
Â´
r
Xpsq
Â¯
Â´ f
Â´
r
Xptq
Â¯Ä±
â€œ rEx
â€
f
Â´
r
Xptq
Â¯
Â´ f
Â´
r
Xptq
Â¯Ä±
â€œ 0.
(3.84)
Since the space Eâ–³is second countable, the space C
`
Eâ–³Ë˜
is separable, the
equalities in (3.82) and (3.84) imply that, up to an event which is rPx-negligible
r
Xptq â€œ Xptq Ë Ï€ for all t Ä› 0. See Deï¬nition 5.88 as well. In addition, we have
that, for Ï‰ P râ„¦the realization t ÃÃ‘ Ï€pÏ‰qptq belongs to the Skorohod space â„¦, i.e.
it is continuous from the right and possesses left limits. We still need to show
that r
Xptq P E implies that the closure of the orbit
!
r
Xpsq : 0 Ä s Ä t, s P D
)
is a closed, and so, compact subset of E. For this purpose we choose a strictly
positive function f P C0 pEq which we extend to a function, again called f, such
that f pâ–³q â€œ 0. It is convenient to employ the resolvent operators RpÎ±q, Î± Ä… 0,
here. We will prove that, for Î± Ä… 0 ï¬xed, the process t ÃÃ‘ eÂ´Î±tR pÎ±q f
Â´
r
Xptq
Â¯
is rPx-supermartingale relative to the ï¬ltration
!
rFâ–³
t ; t Ä› 0
)
. Therefore, let t2 Ä…
t1 Ä› 0. Then we write:
rEx
â€
eÂ´Î±t2RpÎ±qf
Â´
r
X pt2q
Â¯ Ë‡Ë‡ rFâ–³
t1
Ä±
â€œ rEx
â€
eÂ´Î±t2
Å¼ 8
0
eÂ´Î±srE r
Xpt2q
â€
f
Â´
r
Xpsq
Â¯Ä±
ds
Ë‡Ë‡ rFâ–³
t1
È·
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
127 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(Markov property)
â€œ rEx
â€
eÂ´Î±t2
Å¼ 8
0
eÂ´Î±srEx
â€
f
Â´
r
X ps ` t2q
Â¯ Ë‡Ë‡ rFâ–³
t2
Ä±
ds
Ë‡Ë‡ rFâ–³
t1
È·
(Fubiniâ€™s theorem and tower property of condiitonal expectation)
â€œ rEx
â€
eÂ´Î±t2
Å¼ 8
0
eÂ´Î±sf
Â´
r
X ps ` t2q
Â¯
ds
Ë‡Ë‡ rFâ–³
t1
È·
â€œ rEx
â€Å¼ 8
t2
eÂ´Î±sf
Â´
r
X psq
Â¯
ds
Ë‡Ë‡ rFâ–³
t1
È·
(the function f is non-negative and t2 Ä… t1)
Ä rEx
â€Å¼ 8
t1
eÂ´Î±sf
Â´
r
X psq
Â¯
ds
Ë‡Ë‡ rFâ–³
t1
È·
â€œ rEx
â€
eÂ´Î±t1
Å¼ 8
0
eÂ´Î±sf
Â´
r
X ps ` t1q
Â¯
ds
Ë‡Ë‡ rFâ–³
t1
È·
(Fubiniâ€™s theorem in combinaton with the Markov property)
â€œ eÂ´Î±t1
Å¼ 8
0
eÂ´Î±srE r
Xpt1q
â€
f
Â´
r
X psq
Â¯Ä±
ds â€œ eÂ´Î±t1RpÎ±qf
Â´
r
X pt1q
Â¯
.
(3.85)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Advanced stochastic processes: Part I
128 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Put rY ptq â€œ eÂ´Î±tRpÎ±qf
Â´
r
X ptq
Â¯
, and ï¬x x P E. From (3.85) we see that the
process t ÃÃ‘ rY ptq is a rPx-supermartingale relative to the ï¬ltration
Â´
rFâ–³
t
Â¯
tÄ›0.
From Lemma 3.38 with rY ptq instead of Y ptq and rPx in place of P we infer
rPx
â€
r
Xptq P E,
inf
sPDXp0,tq
rY psq â€œ 0
È·
â€œ rPx
â€
rY ptq Ä… 0,
inf
sPDXp0,tq
rY psq â€œ 0
È·
â€œ 0.
(3.86)
From (3.86) we see that, rPx-almost surely, r
Xptq P E implies infsPDXp0,tq rY psq Ä… 0.
Consequently, for every x P E, the equality
rPx
â€
r
Xptq P E
Ä±
â€œ rPx
â€
r
Xptq P E, closure
!
r
Xpsq : s P D X p0, tq
)
Ä‚ E
Ä±
, (3.87)
holds. In other words: the closure of the orbit
!
r
Xpsq : s P D X p0, tq
)
is con-
tained in E whenever r
Xptq belongs to E. We are almost at the end of the proof.
We still have to carry over the Markov process in (3.79) to a process of the form
tpâ„¦, F, Pxq , pXptq, t Ä› 0q , pÏ‘t, t Ä› 0q , pE, Equ
(3.88)
with â„¦â€œ D
`
r0, 8q , Eâ–³Ë˜
the Skorohod space of paths with values in Eâ–³. This
can be done as follows. Deï¬ne the state variables Xptq : â„¦Ã‘ Eâ–³by XptqpÏ‰q â€œ
Ï‰ptq, Ï‰ P â„¦, and let Ï‘t : â„¦Ã‘ â„¦be deï¬ned as above, i.e. Ï‘tpÏ‰qpsq â€œ Ï‰ps ` tq,
Ï‰ P â„¦. Let the mapping Ï€ : râ„¦Ã‘ â„¦be deï¬ned as in (3.83). Then, as shown
above, for every x P E, the processes r
Xptq and XptqËÏ€ are rPx-indistinguishable.
The probability measures Px, x P E, are deï¬ned by Px rAs â€œ rPx rÏ€ P As where A
is a Borel subset of â„¦. Then all ingredients of (3.88) are deï¬ned. It is clear that
the quadruple in (3.88) is a Markov process. Since the paths, or realizations,
are right-continuous, it represents a strong Markov process.
This completes an outline of the proof of Theorem 3.37.
â–¡
As above L is a linear operator with domain DpLq and range RpLq in C0pEq.
Suppose that the domain DpLq of L is dense in C0pEq. The problem we want to
address is the following. Give necessary and suï¬ƒcient conditions on the operator
L in order that for every x P E there exists a unique probability measure Px on
F with the following properties:
(i) For every f P DpLq the process fpXptqq Â´ fpXp0qq Â´
ÅŸt
0 LfpXpsqqds,
t Ä› 0, is a Px-martingale;
(ii) PxpXp0q â€œ xq â€œ 1.
Here we suppose â„¦â€œ D
`
r0, 8q , Eâ–³Ë˜
(Skorohod space) and F is the Ïƒ-ï¬eld gen-
erated by the state variables Xptq, t Ä› 0. Let Ppâ„¦q be the set of all probability
measures on F and deï¬ne the subset P 1pâ„¦q of Ppâ„¦q by
P 1pâ„¦q â€œ
Ä
xPEâ–³
"
P P Ppâ„¦q : PrXp0q â€œ xs â€œ 1 and for every f P DpLq the process
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
129 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
fpXptqq Â´ fpXp0qq Â´
Å¼ t
0
LfpXpsqqds, t Ä› 0, is a P-martingale
*
.
(3.89)
Let pvj : j P Nq be a sequence of continuous functions deï¬ned on E with the
following properties:
(i) v0 â€ 1;
(ii) }vj}8 Ä 1 and vj belongs to DpLq for j Ä› 1;
(iii) The linear span of vj, j Ä› 0, is dense in CpEâ–³q.
In addition let pfk : k P Nq be a sequence in DpLq such that the linear span
of tpfk, Lfkq : k P Nu is dense in the graph GpLq :â€œ tpf, Lfq : f P DpLqu of the
operator L. Moreover let psj : j P Nq be an enumeration of the set Q X r0, 8q.
The subset P 1pâ„¦q may be described as follows:
P 1pâ„¦q â€œ
8
Ä
nâ€œ1
8
Ä
kâ€œ1
8
Ä
mâ€œ1
Ä
pj1,...,jm`1qPNm`1
Ä
0Äsj1Äƒ...Äƒsjm`1
(3.90)
"
P P Ppâ„¦q : inf
xPE max
1ÄjÄn
Ë‡Ë‡Ë‡Ë‡
Å¼
vjpXp0qqdP Â´ vjpxq
Ë‡Ë‡Ë‡Ë‡ â€œ 0,
Å¼ Ë†
fkpXpsjm`1qq Â´
Å¼ sjm`1
0
LfkpXpsqqds
Ë™ Åºm
kâ€œ1 vjk pXpsjkqq dP
â€œ
Å¼ Ë†
fkpXpsjmqq Â´
Å¼ sjm
0
LfkpXpsqqds
Ë™ Åºm
kâ€œ1 vjk pXpsjkqq dP
*
.
It follows that P 1pâ„¦q is a weakly closed subset of Ppâ„¦q. In fact we shall prove
that, if for the operator L, the martingale problem is uniquely solvable, then
the set P 1pâ„¦q is compact metrizable for the metric d pP1, P2q given by
dpP1, P2q â€œ
Ã¿
Î›Ä‚N,|Î›|Äƒ8 2Â´|Î›| Ã¿
pâ„“jqjPÎ›
Ë‡Ë‡Ë‡Ë‡Ë‡
Å¼ Åº
jPÎ›
2Â´jÂ´â„“jvj
`
X
`
sâ„“j
Ë˜Ë˜
d pP2 Â´ P1q
Ë‡Ë‡Ë‡Ë‡Ë‡ .
(3.91)
The following result should be compared to the comments in 6.7.4. of [133]. It
is noticed that in Proposition 3.41 below the uniqueness of the solutions to the
martingale problem is not used.
3.41. Proposition. The set P 1pâ„¦q supplied with the metric d deï¬ned in (3.91)
is a compact Hausdorï¬€space.
Proof. Let pPn : n P Nq be any sequence in P 1pâ„¦q.
Let pPnâ„“: â„“P Nq be
a subsequence with the property that for every m P N, for every m-tuple
pj1, . . . , jmq in Nm and for every m-tuple psj1, . . . , sjmq P Qm the limit
lim
â„“Ã‘8
Å¼ Åºm
kâ€œ1 vjk pX psjkqq dPnâ„“
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
130 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
exists. We shall prove that for every m P N, for every m-tuple pj1, . . . , jmq in
Nm and for every m-tuple ptj1, . . . , tjmq P r0, 8qm the limit
lim
â„“Ã‘8
Å¼ Åºm
kâ€œ1 ujk pX ptjkqq dPnâ„“
(3.92)
exists for all sequences puj : j P Nq in C0pEq. But then there exists, by Kol-
mogorovâ€™s extension theorem, a probability measure P such that
lim
â„“Ã‘8
Å¼ Åºm
kâ€œ1 ujk pX ptjkqq dPnâ„“â€œ
Å¼ Åºm
kâ€œ1 ujk pX ptjkqq dP,
(3.93)
for all m P N, for all pj1, . . . , jmq P Nm and for all ptj1, . . . , tjmq P r0, 8qm. From
the description (3.89) of P 1pâ„¦q it then readily follows that P is a member of
P 1pâ„¦q. So the existence of the limit in (3.92) remains to be veriï¬ed together
with the fact that Dpr0, 8q , Eâ–³q has full P-measure. Let t be in Q. Since,
for every j P N, the process vjpXpsqq Â´ vjpXp0qq Â´
ÅŸs
0 LvjpXpÏƒqqdÏƒ, s Ä› 0, is a
martingale for the measures Pnâ„“, we infer
Å¼ Å¼ t
0
LvjpXpsqqdsdPnâ„“â€œ
Å¼
vjpXptqqdPnâ„“Â´
Å¼
vjpXp0qqdPnâ„“.
and hence the limit limâ„“Ã‘8
ÅŸ ÅŸt
0 LvjpXpsqqdsdPnâ„“exists.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
131 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Next let t0 be in r0, 8q. Again using the martingale property we see
Å¼
vj pXpt0qq d pPnâ„“Â´ Pnkq
â€œ
Å¼ Ë†Å¼ t
0
Lvj pXpsqq ds
Ë™
d pPnâ„“Â´ Pnkq `
Å¼
vjpXp0qqd pPnâ„“Â´ Pnkq
Â´
Å¼ Ë†Å¼ t
t0
Lvj pXpsqq ds
Ë™
d pPnâ„“Â´ Pnkq ,
(3.94)
where t is any number in Q X r0, 8q. From (3.94) we infer
Ë‡Ë‡Ë‡Ë‡
Å¼
vj pXpt0qq d pPnâ„“Â´ Pnkq
Ë‡Ë‡Ë‡Ë‡
Ä
Ë‡Ë‡Ë‡Ë‡
Å¼ Ë†Å¼ t
0
Lvj pXpsqq ds
Ë™
d pPnâ„“Â´ Pnkq
Ë‡Ë‡Ë‡Ë‡ `
Ë‡Ë‡Ë‡Ë‡
Å¼
vjpXp0qqd pPnâ„“Â´ Pnkq
Ë‡Ë‡Ë‡Ë‡
` 2 |t Â´ t0| }Lvj}8 .
(3.95)
If we let â„“and k tend to inï¬nity, we obtain
lim sup
â„“,kÃ‘8
Ë‡Ë‡Ë‡Ë‡
Å¼
vj pXpt0qq d pPnâ„“Â´ Pnkq
Ë‡Ë‡Ë‡Ë‡ Ä 2 |t Â´ t0| }Lvj}8 .
(3.96)
Consequently for every s Ä› 0 the limit limâ„“Ã‘8
ÅŸ
vj pXpsqq dPnâ„“exists.
The
inequality
Ë‡Ë‡Ë‡Ë‡
Å¼
vj pXptqq dPnâ„“Â´
Å¼
vj pXpt0qq dPnâ„“
Ë‡Ë‡Ë‡Ë‡ â€œ
Ë‡Ë‡Ë‡Ë‡
Å¼ Å¼ t
t0
Lvj pXpsqq dsdPnâ„“
Ë‡Ë‡Ë‡Ë‡
Ä |t Â´ t0| }Lvj}8
shows that the functions t ÃÃ‘ limâ„“Ã‘8
ÅŸ
vj pXptqq dPnâ„“, j P N, are continuous.
Since the linear span of pvj : j Ä› 1q is dense in C0pEq, it follows that for
v P C0pEq and for every t Ä› 0 the limit
t ÃÃ‘ lim
â„“Ã‘8
Å¼
v pXptqq dPnâ„“
(3.97)
exists and that this limit, as a function of t, is continuous. The following step
consists in proving that for every t0 P r0, 8q the equality
lim
tÃ‘t0 lim sup
â„“Ã‘8
Å¼
|vj pXptqq Â´ vj pXpt0qq| dPnâ„“â€œ 0
(3.98)
holds. For t Ä… s the following (in-)equalities are valid:
Ë†Å¼
|vj pXptqq Â´ vj pXpsqq| dPnâ„“
Ë™2
Ä
Å¼
|vj pXptqq Â´ vj pXpsqq|2 dPnâ„“
â€œ
Å¼
|vjpXptqq|2 dPnâ„“Â´
Å¼
|vjpXpsqq|2 dPnâ„“
Â´ 2Re
Å¼
pvjpXptqq Â´ vjpXpsqqq vjpXpsqqdPnâ„“
â€œ
Å¼
|vjpXptqq|2 dPnâ„“Â´
Å¼
|vjpXpsqq|2 dPnâ„“
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
132 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Â´ 2Re
Å¼ Ë†Å¼ t
s
LvjpXpÏƒqqdÏƒ
Ë™
vjpXpsqqdPnâ„“
Ä
Å¼
|vjpXptqq|2 dPnâ„“Â´
Å¼
|vjpXpsqq|2 dPnâ„“` 2pt Â´ sq }Lvj}8 .
(3.99)
Hence (3.97) together with (3.99) implies (3.93).
By (3.93), we may apply
Kolmogorovâ€™s theorem to prove that there exists a probability measure P on
â„¦1 :â€œ pEâ–³qr0,8q with the property that
Å¼
m
Åº
kâ€œ1
vjkpXpsjkqqdP â€œ lim
â„“Ã‘8
Å¼
m
Åº
kâ€œ1
vjkpXpsjkqqdPnâ„“,
(3.100)
holds for all m P N and for all psj1, . . . , sjmq P r0, 8qm. It then also follows that
the equality in (3.100) is also valid for all m-tuples f1, . . . , fm in CpEâ–³q instead
of vj1, . . . , vjm. This is true because the linear span of the sequence pvj : j P Nq is
dense in CpEâ–³q. In addition we conclude that the processes fpXptqqÂ´fpXp0qqÂ´
ÅŸt
0 LfpXpsqqds, t Ä› 0, f P DpLq are P-martingales.
We still have to show
that Dpr0, 8q , Eâ–³q has P-measure 1. From (3.98) it essentially follows that
set of Ï‰ P pEâ–³qr0,8q for which the left and right hand limits exist in Eâ–³has
â€fullâ€ P-measure. First let f Ä› 0 be in C0pEq. Then the process rGÎ»fs ptq :â€œ
E
`ÅŸ8
t eÂ´Î»ÏƒfpXpÏƒqqdÏƒ | Ft
Ë˜
is a P-supermartingale with respect to the ï¬ltration
tFt : t Ä› 0u. It follows that the limits limtÃ’t0 rGÎ»fs ptq and limtÃ“t0 rGÎ»fs ptq both
exist P-almost surely for all t0 Ä› 0 and for all f P C0pEq. In particular these
limits exist P-almost surely for all f P DpLq. By the martingale property it
follows that, for f P DpLq,
Ë‡Ë‡fpXptqq Â´ Î»eÎ»t rGÎ»fs ptq
Ë‡Ë‡ â€œ
Ë‡Ë‡Ë‡Ë‡Î»eÎ»tE
Ë†Å¼ 8
t
eÂ´Î»Ïƒ pfpXpÏƒqq Â´ fpXptqqq dÏƒ | Ft
Ë™Ë‡Ë‡Ë‡Ë‡
â€œ
Ë‡Ë‡Ë‡Ë‡Î»eÎ»tE
Ë†Å¼ 8
t
eÂ´Î»Ïƒ
Ë†Å¼ Ïƒ
t
LfpXpsqqds
Ë™
dÏƒ | Ft
Ë™Ë‡Ë‡Ë‡Ë‡
Ä Î»eÎ»t
Å¼ 8
t
eÂ´Î»ÏƒpÏƒ Â´ tq }Lf}8 dÏƒ â€œ Î»Â´1 }Lf}8 .
Consequently, we may conclude that, for all s, t Ä› 0,
|fpXptqq Â´ fpXpsqq| Ä 2Î»Â´1 }Lf}8 `
Ë‡Ë‡Î»eÎ»t rGÎ»fs ptq Â´ Î»eÎ»s rGÎ»fs psq
Ë‡Ë‡
and hence that the limits limtÃ“s fpXptqq and limtÃ’s fpXptqq exist P-almost surely
for all f P DpLq. By separability and density of DpLq it follows that the limits
limtÃ“s Xptq and limtÃ’s Xptq exist P-almost surely for all s Ä› 0. Put ZpsqpÏ‰q â€œ
limtÃ“s,tPQ XptqpÏ‰q, t Ä› 0. Then, for P-almost all Ï‰ and for all s Ä› 0, ZpsqpÏ‰q is
well-deï¬ned, possesses left limits and is right continuous. In addition we have
E pfpZpsqqgpsqq â€œ E pfpXps`qqgpXpsqqq â€œ lim
tÃ“s E pfpXptqqgpXpsqqq
â€œ E pfpXpsqqgpXpsqqq , for all f, g P C0pEq
and for all s Ä› 0: see (3.98). But then we may conclude that Xpsq â€œ Zpsq P-
almost surely for all s Ä› 0. Hence we may replace X with Z and consequently
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
133 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(see the arguments in the proof of Theorem 9.4. of Blumenthal and Getoor
[[20], p. 49])
P
`
Ï‰ P â„¦1 : Ï‰ is right continuous and has left limits in Eâ–³Ë˜
â€œ 1.
Fix s Ä… t. We are going to show that the set of paths Ï‰ P pEâ–³qr0,8q for which
Ï‰psq â€œ XpsqpÏ‰q belongs to E and for which, Ï‰ptÂ´q â€œ limÏ„Ã’t XpÏ„qpÏ‰q â€œ â–³
possesses P-measure 0. It suï¬ƒces to prove that, for f P C0pEq, 1 Ä› fpxq Ä… 0
for all x P E ï¬xed, the following integral equalities hold:
E rfpXpsqq, fpXptÂ´qq â€œ 0s â€œ
Å¼
fpXpsqq1tfâ€œ0upXptÂ´qq dP â€œ 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
134 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
This can be achieved as follows. From the (in-)equalities
E pfpXpsqq, fpXptqq â€œ 0q
â€œ lim
nÃ‘8 E
Â´
fpXpsqq
Â´
1 Â´ pfpXptqqq1{nÂ¯Â¯
â€œ lim
nÃ‘8 E
`
fpXpsqq
`
1 Â´ fpXptqq1{nË˜Ë˜
â€œ lim
nÃ‘8 E
Ëœ
fpXpsqq
Å¼ 1{n
0
fpXptqqÏƒ log
1
fpXptqqdÏƒ
Â¸
â€œ lim
nÃ‘8
Å¼ 1{n
0
E
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™
dÏƒ
â€œ lim
nÃ‘8
Å¼ 1{n
0
pE Â´ Enâ„“q
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™
dÏƒ
` lim
nÃ‘8
Å¼ 1{n
0
Enâ„“
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™
dÏƒ
Ä
Å¼ 1
0
Ë‡Ë‡Ë‡Ë‡E
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™
Â´Enâ„“
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™Ë‡Ë‡Ë‡Ë‡ dÏƒ
` Enâ„“pfpXpsqq, fpXptqq â€œ 0q ,
we conclude that
E pfpXpsqq, fpXptqq â€œ 0q â€œ lim
nÃ‘8 E
`
fpXpsqq
`
1 Â´ fpXptqq1{nË˜Ë˜
Ä
Å¼ 1
0
Ë‡Ë‡Ë‡Ë‡E
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™
Â´Enâ„“
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™Ë‡Ë‡Ë‡Ë‡ dÏƒ.
Since the function x ÃÃ‘ fpxqÏƒ log
1
fpxq belongs to C0pEq for every Ïƒ Ä… 0, we
obtain upon letting â„“tend to 8, that E pfpXpsqq, fpXptqq â€œ 0q â€œ 0, where
s Ä… t. To see this apply Scheï¬€Â´eâ€™s theorem (see e.g. Bauer [[10], Corollary
2.12.5.
p.
105]) to the sequence Ïƒ ÃÃ‘ Enâ„“
Ë†
fpXpsqqfpXptqqÏƒ log
1
fpXptqq
Ë™
.
From description (3.90), it then follows that P belongs to P 1pâ„¦q: it is also clear
that the limits in (3.92) exist.
â–¡
3.42. Proposition. Suppose that for every x P E the martingale problem is
uniquely solvable. Deï¬ne the map F : P 1pâ„¦q Ã‘ Eâ–³by FpPq â€œ x, where P P
P 1pâ„¦q is such that PpXp0q â€œ xq â€œ 1. Also notice that FpPâ–³q â€œ â–³. Then
F is a homeomorphism from P 1pâ„¦q onto Eâ–³. In fact it follows that for every
u P C0pEq and for every s Ä› 0, the function x ÃÃ‘ ExpupXpsqq belongs to C0pEq.
Proof. Since the martingale problem is uniquely solvable for every x P E
the map F is a one-to-one map from the compact metric Hausdorï¬€space P 1pâ„¦q
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
135 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
onto Eâ–³(see Proposition 3.41). Let for x P E the probability Px be the unique
solution to the martingale problem:
(i) For every f P DpLq the process fpXptqq Â´ fpXp0qq Â´
ÅŸt
0 LfpXpsqqds,
t Ä› 0, is a Px-martingale;
(ii) PxpXp0q â€œ xq â€œ 1.
Then, by deï¬nition FpPxq â€œ x, x P E, and FpPâ–³q â€œ â–³.
Moreover, since
for every x P E the martingale problem is uniquely solvable we see P 1pâ„¦q â€œ
â£
Px : x P Eâ–³(
. Let pxâ„“: â„“P Nq be a sequence in Eâ–³with the property that
limâ„“Ã‘8 d pPxâ„“, Pxq â€œ 0 for some x P Eâ–³. Then limâ„“Ã‘8 |vj pxâ„“q Â´ vjpxq| â€œ 0, for
all j P N, where, as above, the span of the sequence pvj : j P Nq is dense in
C
`
Eâ–³Ë˜
. It follows that limâ„“Ã‘8 xâ„“â€œ x in Eâ–³. Consequently the mapping F
is continuous. Since F is a continuous bijective map from one compact metric
Hausdorï¬€space P 1pâ„¦q onto another such space Eâ–³, its inverse is continuous as
well. Among others this implies that, for every s P Q X r0, 8q and for every
j Ä› 1, the function x ÃÃ‘
ÅŸ
vj pXpsqq dPx belongs to C0pEq. Since the linear span
of the sequence pvj : j Ä› 1q is dense in C0pEq it also follows that for every
v P C0pEq, the function x ÃÃ‘
ÅŸ
v pXpsqq dPx belongs to C0pEq. Next let s0 Ä› 0
be arbitrary. For every j Ä› 1 and every s P Q X r0, 8q, s Ä… s0, we have by the
martingale property:
sup
xPE
|Ex pvjpXpsqqq Â´ Ex pvjpXps0qqq| â€œ sup
xPE
Ë‡Ë‡Ë‡Ë‡
Å¼ s
s0
Ex pLvj pXpÏƒqqq dÏƒ
Ë‡Ë‡Ë‡Ë‡
Ä ps Â´ s0q }Lvj}8 .
(3.101)
Consequently, for every s P r0, 8q, the function x ÃÃ‘ Ex pvj pXpsqqq, j Ä› 1,
belongs to C0pEq. It follows that, for every v P C0pEq and every s Ä› 0, the
function x ÃÃ‘ Ex pvpXpsqqq belongs to C0pEq. This proves Proposition 3.42.
â–¡
The proof of the following proposition may be copied from Ikeda and Watanabe
[61], Theorem 5.1. p. 205.
3.43. Proposition. Suppose that for every x P Eâ–³the martingale problem:
(i) For every f P DpLq the process fpXptqq Â´ fpXp0qq Â´
ÅŸt
0 LfpXpsqqds,
t Ä› 0, is a P-martingale;
(ii) PpXp0q â€œ xq â€œ 1,
has a unique solution P â€œ Px. Then the process
tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ
is a strong Markov process.
Proof. Fix x P E and let T be a stopping time and choose a realization of
A ÃÃ‘ Ex r1A Ë Ï‘T | FTs ,
A P F.
Fix any Ï‰ P â„¦for which
A ÃÃ‘ QypAq :â€œ Ex r1A Ë Ï‘T | FTs pÏ‰q,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
136 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
is deï¬ned for all A P F. Here, by deï¬nition, y â€œ Ï‰pTpÏ‰qq. Notice that, sice the
space E is a topological Hausdorï¬€space that satisï¬es the second countability
axiom, this construction can be performed for Px-almost all Ï‰. Let f be in DpLq
and ï¬x t2 Ä… t1 Ä› 0. Moreover ï¬x C P Ft1. Then Ï‘Â´1
T pCq is a member of Ft1`T.
Put Mfptq â€œ fpXptqq Â´ fpXp0qq Â´
ÅŸt
0 LfpXpsqqds, t Ä› 0. We have
Ey pMfpt2q1Cq â€œ Ey pMfpt1q1Cq .
(3.102)
We also have
Å¼ Ë†
fpXpt2qq Â´ fpXp0qq Â´
Å¼ t2
0
LfpXpsqqds
Ë™
1CdQy
(3.103)
â€œ Ex
â€Ë†
f pXpt2 ` Tqq Â´ fpXpTqq Â´
Å¼ t2
0
Lf pXps ` Tqq ds
Ë™
1C Ë Ï‘T | FT
È·
pÏ‰q
â€œ Ex
â€Ë†
f pXpt2 ` Tqq Â´ fpXpTqq Â´
Å¼ t2`T
T
Lf pXpsqq ds
Ë™
p1C Ë Ï‘Tq | FT
È·
pÏ‰q
â€œ Ex
â€
Ex
â€Ë†
f pXpt2 ` Tqq Â´ fpXpTqq Â´
Å¼ t2`T
T
Lf pXpsqq ds
Ë™
| Ft1`T
È·
.
1C Ë Ï‘T | FT
È·
pÏ‰q.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
137 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
By Doobâ€™s optional sampling theorem, the process
f pXpt ` Tqq Â´ fpXpTqq Â´
Å¼ t`T
T
Lf pXpsqq ds
is a Px-martingale with respect to the ï¬elds Ft`T, t Ä› 0. So from (3.103) we
obtain:
Å¼ Ë†
fpXpt2qq Â´ fpXp0qq Â´
Å¼ t2
0
LfpXpsqqds
Ë™
1CdQy
â€œ Ex
â€Ë†
f pXpt1 ` Tqq Â´ fpXpTqq Â´
Å¼ t1`T
T
Lf pXpsqq ds
Ë™
1C Ë Ï‘T | FT
È·
pÏ‰q
â€œ
Å¼ Ë†
fpXpt1qq Â´ fpXp0qq Â´
Å¼ t1
0
LfpXpsqqds
Ë™
1CdQy.
(3.104)
It follows that, for f P DpLq, the process Mfptq is a Py- as well as a Qy-
martingale. Since PyrXp0q â€œ ys â€œ 1 and since
QypXp0q â€œ yq â€œ Ex
â€œ
1tXp0qâ€œyu Ë Ï‘T | FT
â€°
pÏ‰q
â€œ Ex
â€œ
1tXpTqâ€œyu | FT
â€°
pÏ‰q â€œ 1tXpTqâ€œyupÏ‰q â€œ 1,
(3.105)
we conclude that the probabilities Py and Qy are the same. Equality (3.105)
follows, because, by deï¬nition, y â€œ XpTqpÏ‰q â€œ Ï‰pTpÏ‰qq. Since Py â€œ Qy, it then
follows that
PXpTqpÏ‰qpAq â€œ Ex r1A Ë Ï‘T | FTs pÏ‰q,
A P F.
Or putting it diï¬€erently:
PXpTqpAq â€œ Ex r1A Ë Ï‘T | FTs ,
A P F.
(3.106)
However, this is exactly the strong Markov property and completes the proof of
Proposition 3.43.
â–¡
The following proposition can be proved in the same manner as Theorem 5.1
Corollary in Ikeda and Watanabe [61], p. 206.
3.44. Proposition. If an operator L generates a Feller semigroup, then the
martingale problem is uniquely solvable for L.
Proof. Let tPptq : t Ä› 0u be the Feller semigroup generated by L and let
tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ
be the associated strong Markov process (see Theorem 3.37). If f belongs to
DpLq, then the process Mfptq :â€œ fpXptqq Â´ fpXp0qq Â´
ÅŸt
0 LfpXpsqqds, t Ä› 0, is
a Px-martingale for all x P E. This can be seen as follows. Fix t2 Ä… t1 Ä› 0.
Then
Ex rMfpt2q | Ft1s
â€œ Mfpt1q ` Ex
Ë†Ë†
fpXpt2qq Â´
Å¼ t2
t1
LfpXpsqqds
Ë™
| Ft1
Ë™
Â´ fpXpt1qq
â€œ Mfpt1q ` Ex
â€Ë†
fpXpt2 Â´ t1 ` t1qq Â´
Å¼ t2Â´t1
0
LfpXps ` t1qqds
Ë™
| Ft1
È·
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
138 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Â´ fpXpt1qq
(Markov property)
â€œ Mfpt1q ` EXpt1q
Ë†
fpXpt2 Â´ t1qq Â´
Å¼ t2Â´t1
0
LfpXpsqqds
Ë™
Â´ fpXpt1qq. (3.107)
Next we compute, for y P E and s Ä… 0, the quantity:
Ey
Ë†
fpXpsqq Â´
Å¼ s
0
LfpXpÏƒqqdÏƒ
Ë™
Â´ fpyq
â€œ rPpsqfs pyq Â´
Å¼ s
0
rPpÏƒqpLfqs pyqdÏƒ Â´ fpyq
â€œ rPpsqfs pyq Â´
Å¼ s
0
d
dÏƒ rPpÏƒqfs pyqdÏƒ Â´ fpyq
â€œ rPpsqfss pyq Â´ prPpsqfs pyq Â´ rPp0qfs pyqq Â´ fpyq â€œ 0.
(3.108)
Hence from (3.107) and (3.108) it follows that the process Mfptq, t Ä› 0, is
a Px-martingale. Next we shall prove the uniqueness of the solutions of the
martingale problem associated to the operator L. Let P1
x and P2
x be solutions
â€startingâ€ in x P E. We have to show that these probabilities coincide. Let f
belong to DpLq and let T be a stopping time. Then, via partial integration, we
infer
Î»
Å¼ 8
0
eÂ´Î»t
"
fpXpt ` Tqq Â´
Å¼ t`T
T
LfpXpÏ„qqdÏ„ Â´ fpXpTqq
*
dt ` fpXpTqq
â€œ Î»
Å¼ 8
0
eÂ´Î»t
"
fpXpt ` Tqq Â´
Å¼ t`T
T
LfpXpÏ„qqdÏ„
*
dt
â€œ Î»
Å¼ 8
0
eÂ´Î»tfpXpt ` Tqqdt Â´ Î»
Å¼ 8
0
eÂ´Î»t
Å¼ t
0
LfpXpÏ„ ` TqqdÏ„dt
â€œ Î»
Å¼ 8
0
eÂ´Î»tfpXpt ` Tqqdt Â´ Î»
Å¼ 8
0
Ë†Å¼ 8
Ï„
eÂ´Î»tdt
Ë™
LfpXpÏ„ ` TqqdÏ„
â€œ
Å¼ 8
0
eÂ´Î»t rpÎ»I Â´ Lqfs pXpt ` Tqqdt.
(3.109)
From Doobâ€™s optional sampling theorem together with (3.109) we obtain:
Å¼ 8
0
eÂ´Î»tE1
x ppÎ»I Â´ LqfpXpt ` Tqq | FTq dt Â´ fpXpTqq
â€œ Î»
Å¼ 8
0
eÂ´Î»tE1
x
"Ë†
fpXpt ` Tqq Â´
Å¼ t`T
T
LfpXpÏ„qqdÏ„ Â´ fpXpTqq
Ë™
| FT
*
dt
â€œ 0
â€œ Î»
Å¼ 8
0
eÂ´Î»tE2
x
"Ë†
fpXpt ` Tqq Â´
Å¼ t`T
T
LfpXpÏ„qqdÏ„ Â´ fpXpTqq
Ë™
| FT
*
dt
â€œ
Å¼ 8
0
eÂ´Î»tE2
x ppÎ»I Â´ LqfpXpt ` Tqq | FTq dt Â´ fpXpTqq.
(3.110)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
139 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Next we set
rRpÎ»qfs pxq â€œ
Å¼ 8
0
eÂ´Î»t rPptqfs pxqdt,
x P E, Î» Ä… 0, f P C0pEq.
(3.111)
Then
pÎ»I Â´ LqRpÎ»qf â€œ f, f P C0pEq, RpÎ»qpÎ»I Â´ Lqf â€œ f, f P DpLq.
(3.112)
Among other things we see that RpÎ»I Â´ Lq â€œ C0pEq, Î» Ä… 0. From (3.110) it
then follows that, for g P C0pEq,
Å¼ 8
0
eÂ´Î»tE1
x pgpXpt ` Tqq | FTq dt â€œ
Å¼ 8
0
eÂ´Î»trPptqgspXpTqqdt
â€œ
Å¼ 8
0
eÂ´Î»tE2
x pgpXpt ` Tqq | FTq dt.
(3.113)
Since Laplace transforms are unique, since g belongs to C0pEq and since paths
are right continuous, we conclude
E1
x pgpXpt ` Tqq | FTq â€œ rPptqgspXpTqq â€œ E2
x pgpXpt ` Tqq | FTq ,
(3.114)
whenever g belongs to C0pEq, whenever t Ä› 0 and whenever T is a stopping
time. The ï¬rst equality in (3.114) holds P1
x-almost surely and the second P2
x-
almost surely. As in Theorem 3.36 it then follows that
E1
x
Â´Åºn
jâ€œ1 fjpXptjqq
Â¯
â€œ E2
x
Â´Åºn
jâ€œ1 fjpXptjqq
Â¯
(3.115)
for n â€œ 1, 2, . . . and for f1, . . . , fn in C0pEq. But then the probabilities P1
x and
P2
x are the same. This proves Proposition 3.44.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
140 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The theorem we want to prove reads as follows.
3.45. Theorem. Let L be a linear operator with domain DpLq and range RpLq
in C0pEq. Let â„¦be the path space â„¦â€œ D
`
r0, 8q , Eâ–³Ë˜
. The following assertions
are equivalent:
(i) The operator L is closable and its closure generates a Feller semigroup;
(ii) The operator L solves the martingale problem maximally and its domain
DpLq is dense in C0pEq;
(iii) The operator L veriï¬es the maximum principle, its domain DpLq is
dense in C0pEq and there exists Î»0 Ä… 0 such that the range R pÎ»0I Â´ Lq
is dense in C0pEq.
3.46. Remark. The hard part in (iii) is usually the range property: there exists
Î»0 Ä… 0 such that the range R pÎ»0I Â´ Lq is dense in C0pEq. The theorem also
shows, in conjunction with the results on Feller semigroups and Markov pro-
cesses, the relations which exist between the unique solvability of the martingale
problem, the strong Markov property and densely deï¬ned operators verifying
the maximum principle together with the range property. However if L is in fact
a second order diï¬€erential operator, then we want to read of the range property
from the coeï¬ƒcients. There do exist results in this direction. The interested
reader is referred to the literature: Stroock and Varadhan [133] and also Ikeda
and Watanabe [61].
In what follows we shall assume that the equivalence of (i) and (iii) already has
been established. A proof can be found in [141], Theorem 2.2., p.14. In the
proof of (ii) Ã± (i) we shall use this result. We shall also show the implication
(i) Ã± (ii).
Proof. (ii) Ã± (i). Let, for x P E, the probability Px be the unique solution
of the martingale problem associated to the operator L. From Proposition 3.43
it follows that the process tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ is a
strong Markov process. Deï¬ne the operators tPptq : t Ä› 0u as follows:
rPptqfspxq â€œ Ex pfpXptqqq ,
f P C0pEq,
t Ä› 0.
(3.116)
We also deï¬ne the operators tRpÎ»q : Î» Ä… 0u as follows:
rRpÎ»qfspxq â€œ
Å¼ 8
0
eÂ´Î»trPptqfspxqdt,
f P C0pEq,
Î» Ä… 0.
(3.117)
From Proposition 3.42 it follows that the operators Pptq leave C0pEq invariant
and hence we also have RpÎ»qC0pEq Ä C0pEq. From the Markov property it fol-
lows that tPptq : t Ä› 0u is a Feller semigroup and that the family tRpÎ»q : Î» Ä… 0u
is a resolvent family in the sense that
Pps ` tq â€œ Ppsq Ë Pptq,
s, t Ä› 0,
(3.118)
RpÎ»2q Â´ RpÎ»1q â€œ pÎ»1 Â´ Î»2q RpÎ»1q Ë RpÎ»2q,
Î»1, Î»2 Ä… 0.
(3.119)
For Î» Ä… 0 ï¬xed the operator rL is deï¬ned in C0pEq as follows:
rL : RpÎ»qf ÃÃ‘ Î»RpÎ»qf Â´ f,
f P C0pEq.
(3.120)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
141 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Here the domain DprLq is given by DprLq â€œ tRpÎ»qf : f P C0pEqu. The operator
rL is well-deï¬ned. For, if f1 and f2 in C0pEq are such that RpÎ»qf1 â€œ RpÎ»qf2, then
by the resolvent property (3.119) we see ÂµRpÂµqf1 â€œ ÂµRpÂµqf2, Âµ Ä… 0. Let Âµ tend
8, to obtain f1 â€œ f2. Since the operator RpÎ»q is continuous, the operator rL is
closed. Next we shall prove that rL is an extension of L. By partial integration,
it follows that, for f P DpLq,
eÂ´Î»t
"
fpXptqq Â´ fpXp0qq Â´
Å¼ t
0
LfpXpÏ„qqdÏ„
*
` Î»
Å¼ t
0
eÂ´Î»s
"
fpXpsqq Â´ fpXp0qq Â´
Å¼ s
0
LfpXpÏ„qqdÏ„
*
ds
â€œ eÂ´Î»tfpXptqq Â´ fpXp0qq `
Å¼ t
0
eÂ´Î»spÎ»I Â´ LqfpXpsqqds.
(3.121)
As a consequence upon applying (3.121) once more, the processes
"
eÂ´Î»tfpXptqq Â´ fpXp0qq `
Å¼ t
0
eÂ´Î»spÎ»I Â´ LqfpXpsqqds : t Ä› 0
*
,
f P DpLq,
(3.122)
are Px-martingales for all x P E. Here we employ the fact that the processes
"
fpXptqq Â´ fpXp0qq Â´
Å¼ t
0
LfpXpsqqds : t Ä› 0
*
,
f P DpLq,
are Px-martingales.
This is part of assertion (ii).
From assertion (3.122) it
follows that
0 â€œ Ex
Ë†
eÂ´Î»tfpXptqq Â´ fpXp0qq `
Å¼ t
0
eÂ´Î»spÎ»I Â´ LqfpXpsqqds
Ë™
,
f P DpLq.
(3.123)
Let t tend to inï¬nity in (3.123) to obtain
0 â€œ Â´Ex pfpXp0qqq `
Å¼ 8
0
eÂ´Î»sEx ppÎ»I Â´ LqfpXpsqqq ds,
f P DpLq.
(3.124)
From (3.124) we obtain fpxq â€œ
ÅŸ8
0 eÂ´Î»s rPpsqpÎ»I Â´ Lqfs pxqds, f P DpLq. Or
writing this diï¬€erently f â€œ RpÎ»qpÎ»I Â´ Lqf, f P DpLq. Let f belong to DpLq.
Then f â€œ RpÎ»qg, with g â€œ pÎ»I Â´ Lqf and hence f belongs to DprLq. Moreover
we see
rLf â€œ rLpRpÎ»qgq â€œ Î»RpÎ»qg Â´ g â€œ Î»f Â´ pÎ»f Â´ Lfq â€œ Lf.
(3.125)
It follows that rL is a closed linear extension of L. In addition we have RpÎ»I Â´
rLq â€œ C0pEq. We shall show that the operator rL veriï¬es the maximum principle.
This can be achieved as follows. Let f in C0pEq be such that, for some x0 P E,
Re pRpÎ»qfqpx0q â€œ sup tRe RpÎ»qfpxq : x P Eu Ä… 0.
(3.126)
Then Re pRpÎ»qfqpx0q Ä› Re RpÎ»qfpXptqq, t Ä› 0, and hence
Re pRpÎ»qfqpx0q Ä› Re
Å¼ 8
0
eÂ´Î»sEXptq pfpXpsqqq ds,
t Ä› 0.
(3.127)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
142 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
So that, upon employing the Markov property, we obtain for t Ä› 0:
Re pRpÎ»qfqpx0q Ä› Re
Å¼ 8
0
eÂ´Î»sEx0
`
EXptq pfpXpsqqq
Ë˜
ds
â€œ Re Ex0 prRpÎ»qfs pXptqq .
(3.128)
Hence, for Âµ Ä… 0, we obtain
1
ÂµRe pRpÎ»qfqpx0q â€œ
Å¼ 8
0
eÂ´ÂµtRe RpÎ»qfpx0qdt
Ä› Re
Å¼ 8
0
eÂ´ÂµtEx0 prRpÎ»qfs pXptqqq dt
â€œ Re RpÂµqRpÎ»qfpx0q
(resolvent equation (3.119)
â€œ Re RpÎ»qfpx0q Â´ RpÂµqfpx0q
Âµ Â´ Î»
.
(3.129)
Consequently: rÎ»Re RpÎ»qfs px0q Ä Re rÂµRpÂµqfs px0q, Âµ Ä… Î». Let Âµ tend to
inï¬nity, use right continuity of paths and the continuity of f to infer
Re rLRpÎ»qfpx0q â€œ Re tÎ»RpÎ»qfpx0q Â´ fpx0qu Ä 0.
(3.130)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
143 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
This proves that rL veriï¬es the maximum principle. Employing the implication
(iii) Ã± (i) in Theorem 3.45 yields that rL is the generator of a Feller semigroup.
From Proposition 3.44 it then follows that for rL the martingale problem is
uniquely solvable. Since L solves the martingale problem maximally and since
rL extends L, it follows that rL â€œ L, the closure of L. Consequently the operator
L is closable and its closure generates a Feller semigroup.
(i) Ã± (ii) Let the closure of L, L, be the generator of a Feller semigroup.
From Proposition 3.44 it follows that for L the martingale problem is uniquely
solvable. Hence this is true for L. We still have to prove that L is maximal with
respect to this property. Let L1 be any closed linear extension of L for which
the martingale problem is uniquely solvable. Deï¬ne Ä‚
L1 in the same fashion as
in the proof of the implication (ii) Ã± (i), with L1 replacing L. Then rL1 is a
closed linear operator, which extends L1. So that rL1 extends L. As in the proof
of the implication (ii) Ã± (i) it also follows that rL1 generates a Feller semigroup.
Since, by (i), the closure of L, also generates a Feller semigroup, we conclude by
uniqueness of generators, that L â€œ rL1. Since rL1 Äš L1 â€œ L1 Äš L Äš L, it follows
that the closure of L coincides with L1. This proves the maximality property
of L, and so the proof of Theorem 3.45 is complete.
â–¡
In fact a careful analysis of the proof of Theorem 3.45 shows the following result.
3.47. Proposition. Let L be a densely deï¬ned operator for which the martin-
gale problem is uniquely solvable, and which is maximal for this property. Then
there exists a unique closed linear extension L0 of L, which is the generator of
a Feller semigroup.
Proof. Existence. Let tPx : x P Eu be the solution for L, and assume that
for all f P C0pEq the function x ÃÃ‘ rPptqfs pxq belongs to C0pEq for all t Ä› 0.
Here Pptqfpxq is deï¬ned by
rPptqfs pxq â€œ Ex pfpXptqqq ,
rRpÎ»qfs pxq â€œ
Å¼ 8
0
eÂ´Î»s rPpsqfs pxqds,
L0pRpÎ»qfq :â€œ Î»RpÎ»qf Â´ f,
f P C0pEq.
Here t Ä› 0 and Î» Ä… 0 is ï¬xed. Then, as follows from the proof of Theorem 3.45,
the operator L0 generates a Feller semigroup.
Uniqueness. Let L1 and L2 be closed linear extensions of L, which both generate
Feller semigroups. Let
â£
pâ„¦, F, P1
xq, pXptq : t Ä› 0q, pÏ‘t : t Ä› 0q, pE, Eq
(
respectively
â£
pâ„¦, F, P2
xq, pXptq : t Ä› 0q, pÏ‘t : t Ä› 0q, pE, Eq
(
be the corresponding Markov processes.
For every f P DpLq, the process
fpXptqq Â´ fpXp0qq Â´
ÅŸt
0 LfpXpsqqds, t Ä› 0, is a martingale with respect to P1
x
as well as with respect to P2
x. Uniqueness implies P1
x â€œ P2
x and hence L1 â€œ L2.
The proof of Proposition 3.47 is complete now.
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
144 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.48. Corollary. Let L be a densely deï¬ned linear operator with domain DpLq
and range RpLq in C0pEq. The following assertions are equivalent:
(i) Some extension of L generates a Feller semigroup.
(ii) For some extension of L the martingale problem is uniquely solvable for
every x P E.
Proof. (i) Ã¹Ã± (ii). Let L0 be an extension of L that generates a Feller semi-
group. Let tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ be the corresponding
Markov process. For x P E the probability Px is the unique solution for the
martingale problem starting in x.
(ii) Ã¹Ã± (i). Let L0 be an extension of L for which the martingale problem is
uniquely solvable for every x P E. Also suppose that L0 is maximal for this
property. Let tPx : x P Eu be the unique solution of the corresponding martin-
gale problem. Deï¬ne the operators Pptq, t Ä› 0, by rPptqfs pxq â€œ Ex pfpXptqqq,
f P C0pEq. From the proof of Theorem 3.45 it follows that tPptq : t Ä› 0u is a
Feller semigroup with generator L0.
This completes the proof of Corollary 3.48.
â–¡
3.49. Example. Let L0 be an unbounded generator of a Feller semigroup in
C0pEq and let Âµk and Î½k, 1 Ä k Ä n, be ï¬nite (signed) Borel measures on E.
Deï¬ne the operator Lâƒ—Âµ,âƒ—Î½ as follows:
D pLâƒ—Âµ,âƒ—Î½q â€œ
nÄ
kâ€œ1
"
f P DpL0q :
Å¼
L0fdÂµk â€œ
Å¼
fdÎ½k
*
,
Lâƒ—Âµ,âƒ—Î½f â€œ L0f,
f P D pLâƒ—Âµ,âƒ—Î½q .
Then the martingale problem is uniquely solvable for Lâƒ—Âµ,âƒ—Î½. In fact let
tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ
be the strong Markov process associated to the Feller semigroup generated by
L0. Then P â€œ Px solves the martingale problem
(a) For every f P DpLâƒ—Âµ,âƒ—Î½q the process
fpXptqq Â´ fpXp0qq Â´
Å¼ t
0
Lâƒ—Âµ,âƒ—Î½fpXpsqqds,
t Ä› 0,
is a P-martingale;
(b) PpXp0q â€œ xq â€œ 1,
uniquely. This can be seen as follows. We may and do suppose that the func-
tionals f ÃÃ‘
ÅŸ
L0fdÂµk Â´
ÅŸ
fdÎ½k, f P DpL0q, 1 Ä k Ä n, are linearly independent.
If some Âµk belongs to D pLËš
0q, then D pLâƒ—Âµ,âƒ—Î½q is not dense and if none of the
measures Âµk belongs to D pLËš
0q, then D pLâƒ—Âµ,âƒ—Î½q is dense in C0pEq. In either case
there exists a unique extension, in fact L0, of Lâƒ—Âµ,âƒ—Î½ which generates a Feller semi-
group. Therefore we choose functions uk P DpL0q, 1 Ä k Ä n, in such a way
that
ÅŸ
L0ukdÂµâ„“Â´
ÅŸ
ukdÎ½â„“â€œ Î´k,â„“, 1 Ä k, â„“Ä n. Suppose that P1
x and P2
x are prob-
abilities, that start in x, with the property that for all f P D pLâƒ—Âµ,âƒ—Î½q the process
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
145 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
t ÃÃ‘ fpXptqq Â´ fpXp0qq Â´
ÅŸt
0 L0fpXpsqqds is a P1
x- as well as a P2
x-martingale.
As in (3.110) we see that for all f P DpL0q (vk â€œ pÎ»I Â´ L0q uk, 1 Ä k Ä n):
fpxq Â´
nÃ¿
kâ€œ1
Ë†Å¼
L0fdÂµk Â´
Å¼
fdÎ½k
Ë™
ukpxq
(3.131)
â€œ
Å¼ 8
0
eÂ´Î»sE1
x
Ëœ
pÎ»I Â´ L0q
Ëœ
f Â´
nÃ¿
kâ€œ1
Ë†Å¼
L0fdÂµk Â´
Å¼
fdÎ½k
Ë™
uk
Â¸
pXpsqq
Â¸
ds
â€œ
Å¼ 8
0
eÂ´Î»sE2
x
Ëœ
pÎ»I Â´ L0q
Ëœ
f Â´
nÃ¿
kâ€œ1
Ë†Å¼
L0fdÂµk Â´
Å¼
fdÎ½k
Ë™
uk
Â¸
pXpsqq
Â¸
ds.
Write f â€œ pÎ»I Â´ L0qÂ´1 g â€œ RpÎ»qg. From (3.131) we obtain
RpÎ»qgpxq Â´
nÃ¿
kâ€œ1
Ë†Å¼
pÎ»RpÎ»qg Â´ gq dÂµk Â´
Å¼
RpÎ»qgdÎ½k
Ë™
ukpxq
(3.132)
â€œ
Å¼ 8
0
eÂ´Î»sE1
x
Â«
gpXpsqq Â´
nÃ¿
kâ€œ1
Ë†Å¼
pÎ»RpÎ»qg Â´ gq dÂµk Â´
Å¼
RpÎ»qgdÎ½k
Ë™
vkpXpsqq
ï¬€
ds
â€œ
Å¼ 8
0
eÂ´Î»sE2
x
Â«
gpXpsqq Â´
nÃ¿
kâ€œ1
Ë†Å¼
pÎ»RpÎ»qg Â´ gq dÂµk Â´
Å¼
RpÎ»qgdÎ½k
Ë™
vkpXpsqq
ï¬€
ds.
Put ÃÃ‘
F pÎ»q â€œ pF1pÎ»q, . . . , FnpÎ»qq and put UpÎ»q â€œ puk,â„“pÎ»qq, where, for 1 Ä k Ä n,
FkpÎ»q â€œ
Å¼ 8
0
eÂ´Î»s `
E1
x rpÎ»I Â´ L0qukpXpsqqs Â´ E2
x rpÎ»I Â´ L0qukpXpsqqs
Ë˜
ds,
and where uk,â„“, 1 Ä k, â„“Ä n, is given by
uk,â„“pÎ»q â€œ
Å¼
Î»RpÎ»quâ„“dÂµk Â´
Å¼
uâ„“dÂµk Â´
Å¼
RpÎ»quâ„“dÎ½k.
Since (3.132) is valid for all g P C0pEq, it follows that ÃÃ‘
F pÎ»q â€œ UpÎ»qÃÃ‘
F pÎ»q.
Since, in addition limÎ»Ã‘8 UpÎ»q â€œ 0, we see FkpÎ»q â€œ 0 for all Î» Ä… 0 and
for 1 Ä k Ä n.
So that
ÅŸ8
0 eÂ´Î»sE1
x pukpXpsqqq ds â€œ
ÅŸ8
0 eÂ´Î»sE2
x rukpXpsqqs ds
for all Î» Ä… 0 and for all 1 Ä k Ä n. Again an application of (3.132) yields
E1
x rgpXpsqqs â€œ E2
x rgpXpsqqs for all g P C0pEq. Since these arguments are valid
for any x P E, we conclude just as in Proposition 2.9 and its Corollary on page
206 of Ikeda and Watanabe [61]), that P1
x â€œ P2
x â€œ Px, x P E, In particular
we may take E â€œ r0, 1s, L0f â€œ 1
2f 2, DpL0q â€œ tf P C2r0, 1s : f 1p0q â€œ f 1p1q â€œ 0u,
Âµk pIq â€œ
ÅŸÎ²k
Î±k 1Ipsqds, Î½k â€œ 0, 0 Ä Î±k Äƒ Î²k Ä 1, 1 Ä k Ä n. Then L0 generates
the Feller semigroup of reï¬‚ected Brownian motion: see Liggett [86], Example
5.8., p. 45. For the operator Lâƒ—Âµ,âƒ—Î½ the martingale problem is uniquely (but not
maximally uniquely) solvable. However it does not generate a Feller semigroup.
The previous arguments do not seem to be entirely correct.
It ought to be
replaced with some results in Section 10 (e.g. Theorem 3.110).
Problem. We want to close this section with the following question. Suppose
that the operator L possesses a unique extension L0, that generates a Feller
semigroup. Is it true that for L the martingale problem is uniquely solvable?
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
146 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In general the answer is no, but if we require that L solves the martingale
problem maximally, then the answer is yes, provided as sample space we take
the Skorohod space. This result is proved in Theorem 3.45.
For the time being we will not pursue the Markov property. However, we will
continue with Brownian motion and stochastic integrals.
First we give the
deï¬nition of some interesting processes.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
147 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
4. Martingales, submartingales, supermartingales and
semimartingales
Let pâ„¦, F, Pq be a probability space and let tFt : t Ä› 0u be an increasing family
of Ïƒ-ï¬elds in F. If necessary we suppose that the ï¬ltration tFt : t Ä› 0u is right
continuous, i.e. Ft â€œ Å
sÄ…t Fs, or complete in the sense that, for every t Ä… 0,
the Ïƒ-ï¬eld Ft contains all A P F, with PpAq â€œ 0.
Let tHptq : t Ä› 0u be a collection of R-valued functions deï¬ned on â„¦. Such a
family is called a (real-valued) process.
3.50. Definition. The following processes and Ïƒ-ï¬elds will play a role in the
sequel.
(a) The process tHptq : t Ä› 0u is said to be adapted or non-anticipating if,
for every t Ä› 0, the variable Hptq is measurable with respect to Ft.
(b1 The symbol Î› denotes the Ïƒ-ï¬eld (â€œ Ïƒ-algebra) of subsets of r0, 8qË†â„¦,
which is generated by the adapted processes which are right-continuous
and which possess left limits. These are the so-called cadlag processes.
(b2) The process tHptq : t Ä› 0u is said to be optional if the function pt, Ï‰q Ã‘
Hpt, Ï‰q is measurable with respect to Î›.
(c1) The symbol Î  denotes the Ïƒ-ï¬eld of subsets of r0, 8q Ë† â„¦, which is
generated by the adapted processes which are left-continuous adapted
processes.
(c2) The process tHptq : t Ä› 0u is said to be predictable if the function
pt, Ï‰q Ã‘ Hpt, Ï‰q is measurable with respect to Î .
3.51. Proposition. The collection tpa, bs Ë† A: 0 Ä a Äƒ b, A P Fau generates the
Ïƒ-ï¬eld Î .
Proof. Let A belong to Fa. The variable Ï‰ ÃÃ‘ 1pa,bspsq1ApÏ‰q is measurable
with respect to Fs and the function s ÃÃ‘ 1pa,bspsq1ApÏ‰q is left continuous. This
proves that pa, bs Ë† A belongs to Î .
Conversely let F be adapted and left continuous. Put
Fnps, Ï‰q â€œ
Ã¿8
kâ€œ0 F
`
k2Â´n, Ï‰
Ë˜
1pk2Â´n,pk`1q2Â´nspsq â€œ F
`
pr2nss Â´ 1q 2Â´n, Ï‰
Ë˜
.
Then, by left continuity, limnÃ‘8 Fnps, Ï‰q â€œ Fps, Ï‰q, P-almost surely. Moreover
the processes tFnptq : t Ä› 0u are adapted and are measurable with respect to
the Ïƒ-ï¬eld generated by tpa, bs Ë† A : 0 Ä a Äƒ b, A P Fau. All this completes the
proof of Proposition 3.51.
â–¡
3.52. Remark. Since 1pa,bspsq Ë† 1ApÏ‰q â€œ lim
nÃ‘8 1ran,bnqpsq1ApÏ‰q, where an Ã“ a and
where bn Ã“ b, it follows that Î  Ä Î›. Here we employ Proposition 3.51.
3.53. Definition. Let tXptq : t Ä› 0u be an adapted process.
(a) The family tXptq : t Ä› 0u is a martingale if E p|Xptq|q Äƒ 8, t Ä› 0, and
if, for every t Ä… s Ä› 0, E pXptq | Fsq â€œ Xpsq, P-almost surely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
148 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(b) The family tXptq : t Ä› 0u is a submartingale if E p|Xptq|q Äƒ 8, t Ä› 0,
and if, for every t Ä… s Ä› 0, E pXptq | Fsq Ä› Xpsq, P-almost surely.
(c) The family tXptq : t Ä› 0u is a supermartingale if E p|Xptq|q Äƒ 8, t Ä› 0,
and if, for every t Ä… s Ä› 0, E pXptq | Fsq Ä Xpsq, P-almost surely.
(d) It is P-almost surely of ï¬nite variation (on r0, ts) if
sup
!Ã¿n
jâ€œ1 |Xptjq Â´ XptjÂ´1q| : 0 Ä t0 Äƒ t1 Äƒ . . . Äƒ tn Äƒ 8
)
Äƒ 8,
Â´
sup
!Ã¿n
jâ€œ1 |Xptjq Â´ XptjÂ´1q| : 0 Ä t0 Äƒ t1 Äƒ . . . Äƒ tn Ä t
)
Äƒ 8,
Â¯
P-almost surely.
(e) It is a local martingale if there exists an increasing sequence of stopping
times pTn : n P Nq for which limnÃ‘8 Tn â€œ 8, P-almost surely, and for
which the processes
tXpTn ^ tq : t Ä› 0u ,
n â€œ 1, 2, . . .
are martingales with respect to the ï¬ltration tFTn^t : t Ä› 0u.
(f) Let T be a stopping time. The process tXptq : t Ä› 0u is a local martin-
gale on r0, Tq if there exists a sequence of stopping times pTn : n P Nq
which is increasing for which limnÃ‘8 Tn â€œ T, P-almost surely, and for
which the processes tXpTn ^ tq : t Ä› 0u, n â€œ 1, 2, . . . are martingales
with respect to the ï¬ltration tFTn^t : t Ä› 0u.
(g) The deï¬nition of â€œlocal submartingaleâ€, â€œlocal supermartingaleâ€ and
â€œbeing locally P-almost surely of ï¬nite variationâ€ are now self-explan-
atory.
(h) The process tXptq : t Ä› 0u is called a semi-martingale if it can be writ-
ten in the form Xptq â€œ Mptq ` Aptq, where tMptq : t Ä› 0u is a mar-
tingale and where tAptq : t Ä› 0u is an adapted process which is ï¬nite
variation, P-almost surely, on r0, ts for every t Ä… 0, and for which
E |Aptq| Äƒ 8, t Ä› 0.
(i) The process tXptq : t Ä› 0u is of class (DL) if for every t Ä… 0 the family
tXpÏ„q : 0 Ä Ï„ Ä t, Ï„ is a pFtq -stopping timeu
is uniformly integrable.
3.54. Remark. Let tXptq : t Ä› 0u be a semi-martingale. The decomposition
Xptq â€œ Mptq ` Aptq, where tMptq : t Ä› 0u is a martingale and where for every
t Ä… 0 the process tAptq : t Ä› 0u is P-almost surely of ï¬nite variation and where
tAptq : t Ä› 0u is predictable and right continuous P-almost surely is unique,
provided Ap0q â€œ 0, P-almost surely. This follows from the fact that a right-
continuous martingale which is predictable and of ï¬nite variation is necessarily
constant: this is a consequence of the uniqueness part of the Doob-Meyer de-
composition: see Theorem 1.24.
A proof of the Doob-Meyer decomposition
theorem may start as follows. Put
Xjptq â€œ E
â€
X
Ë†r2jts
2j
Ë™ Ë‡Ë‡Ë‡ Ft
È·
and
(3.133)
Ajptq â€œ Ajp0q `
Ã¿
0ÄkÄƒ2jt
E
â€
X
Ë†k ` 1
2j
Ë™
Â´ X
Ë† k
2j
Ë™ Ë‡Ë‡Ë‡ Fk2Â´j
È·
,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
149 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
and prove Mjptq :â€œ Xjptq Â´ Ajptq is a martingale. Then let j Ã‘ 8 to obtain:
Xptq â€œ Mptq ` Aptq, where Mptq â€œ limjÃ‘8 Mjptq and Aptq â€œ limjÃ‘8 Ajptq.
3.55. Remark. An Ft-martingale tMptq : t Ä› 0u is of class (DL), an increasing
adapted process tAptq : t Ä› 0u in L1pâ„¦, F, Pq is of class (DL) and hence the sum
tMptq ` Aptq : t Ä› 0u
is of class (DL). If tXptq : t Ä› 0u is a submartingale and if Âµ is a real number,
then the process tmax pXptq, Âµq : t Ä› 0u is a submartingale of class (DL). Pro-
cesses of class (DL) are important in the Doob-Meyer decomposition theorem.
We continue with some examples of martingales, submartingales and the like.
3.56. Example. Let T : â„¦Ã‘ r0, 8s be a stopping time. Since T is a stopping
time and since the process
â£
1tTÄƒtu : t Ä› 0
(
is left continuous, it is predictable.
It follows that the process
â£
1tTÄ›tu : t Ä› 0
(
is predictable as well.
3.57. Example. Let I be an open interval in R and let Ï† : I Ã‘ pÂ´8, 8q be an
increasing convex function. If tXptq : t Ä› 0u is a submartingale with values in
I, then the process tÏ†pXptqq : t Ä› 0u is also a submartingale. For let t Ä… s Ä› 0.
Then by the Jensen inequality and the monotonicity of Ï† it follows that
E rÏ†pXptqq | Fss Ä› Ï† rE pXptq | Fsqs Ä› Ï† pXpsqq .
3.58. Example. Let pBptq, P0q be one-dimensional Brownian motion starting
in 0. Then tBptq : t Ä› 0u is a martingale. Since the deï¬nition of martingale also
makes sense for vector valued processes, we also see that an RÎ½-valued Brownian
motion is a martingale.
3.59. Example. Let pBptq, P0q be RÎ½-valued Brownian motion starting in 0.
The process
â£
|Bptq|2 Â´ Î½t : t Ä› 0
(
is a martingale.
3.60. Example. Let tXptq, Pxu be a (strong) Markov process such that
Ex rfpXptqqs â€œ
Å¼
ppt, x, yqfpyqdmpyq,
f Ä› 0,
where the density ppt, x, yq veriï¬es the Chapman-Kolmogorov identity:
pps ` t, x, yq â€œ
Å¼
pps, x, zqppt, z, yqdmpzq.
The process tppt Â´ s, Xpsq, yq : 0 Ä s Äƒ tu is a martingale on r0, tq. For example
for Xptq we may take Bptq, d-dimensional Brownian motion. Then
ppt, x, yq â€œ pdpt, x, yq â€œ
1
`?
2Ï€t
Ë˜d exp
Ëœ
Â´|x Â´ y|2
2t
Â¸
.
3.61. Example. Let tXptq : t Ä› 0u be a right-continuous martingale and let T
be a stopping time. The process tX pT ^ tq : t Ä› 0u is a martingale with respect
to tFt : t Ä› 0u and also with respect to the ï¬ltration tFT^t : t Ä› 0u.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
150 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.62. Example. This is a standard example of a closed martingale, i.e.
a
martingale which is written as conditional expectations on Ïƒ-ï¬elds taken from
a ï¬ltration. Let Y be an random variable in L1 pâ„¦, F, Pq. The process s ÃÃ‘
E rY | Fss, s Ä› 0, is a martingale.
We want to insert an inequality on the second moment of a martingale. This is
a special case of the Burkholder-Davis-Gundy inequality.
3.63. Proposition. Let tMptq : t Ä› 0u be a continuous martingale with Mp0q â€œ
0. Then
E
`
Mptq2Ë˜
Ä E
`
M Ëšptq2Ë˜
Ä 4E
`
Mptq2Ë˜
.
Here M Ëšptq â€œ sup0ÄsÄt |Mpsq|.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
151 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Deï¬ne for Î¾ Ä… 0 the stopping time TÎ¾ by
TÎ¾ â€œ inf tt Ä… 0 : M Ëšptq Ä› Î¾u .
Then tM Ëšptq Ä… Î¾u Ä tTÎ¾ Äƒ tu and tTÎ¾ Äƒ tu Ä tM Ëšptq Ä› Î¾u and hence, since
|Mptq| is a submartingale we obtain upon using Doobâ€™s optional sampling
E
`
M Ëšptq2Ë˜
â€œ
Å¼ 8
0
P
`
M Ëšptq2 Ä… Î»
Ë˜
dÎ»
(make the substitution Î» â€œ Î¾2)
â€œ 2
Å¼ 8
0
Î¾P pM Ëšptq Ä… Î¾q dÎ¾ Ä 2
Å¼ 8
0
Î¾P pTÎ¾ Äƒ tq dÎ¾
â€œ 2
Å¼ 8
0
E p|MpTÎ¾q| : TÎ¾ Äƒ tq dÎ¾
(Doobâ€™s optional sampling)
Ä 2
Å¼ 8
0
E p|Mptq| : TÎ¾ Äƒ tq dÎ¾
â€œ 2
Å¼ 8
0
E p|Mptq| : M Ëšptq Ä› Î¾q dÎ¾
â€œ 2E p|Mptq| M Ëšptqq
(Cauchy-Schwarzâ€™ inequality)
Ä 2
`
E
`
Mptq2Ë˜Ë˜1{2 `
E
`
M Ëšptq2Ë˜Ë˜1{2 .
Consequently E pM Ëšptq2q Ä 4E pMptq2q. This completes the proof of Proposition
3.63.
â–¡
3.64. Remark. The method of works very well if E pM Ëšptq2q is ï¬nite. If this
is not the case we may use a localization technique. The reader should provide
the details. Perhaps truncating is also possible.
5. Regularity properties of stochastic processes
In Theorem 3.18 we proved that Brownian motion possesses a continuous ver-
sion. We want to amplify this result. In fact we shall prove that Brownian
motion has HÂ¨older continuous paths of any order Î± Äƒ 1
2. This means that for
every Î± Äƒ 1
2 and for every a Ä… 0, a P R, there exists a random variable Cpbq,
depending on Brownian motion such that for all 0 Ä s Äƒ t Ä a, the inequality
|bptq Â´ bpsq| Ä Cpbq |t Â´ s|Î±
holds P-almost surely. This will be the content of Theorem 3.67 below. We
begin with a rather general result, due to Kolmogorov, for arbitrary stochastic
processes.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
152 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.65. Theorem. Fix a ï¬nite interval ra, bs. Let tXpsq : a Ä s Ä bu be a stochas-
tic process on the probability space pâ„¦, F, Pq. Suppose that there exist constants
K, r and p, such that 0 Äƒ r Äƒ p Äƒ 8 and such that
E p|Xptq Â´ Xpsq|pq Ä K |t Â´ s|1`r
(3.134)
for all a Ä s, t Ä b. Fix 0 Äƒ Î± Äƒ r{p. Then there exists a random variable
CpXq, which is ï¬nite P-almost surely, such that
|Xptq Â´ Xpsq| Ä CpXq |t Â´ s|Î±
(3.135)
for all dyadic rational numbers s and t in the interval ra, bs. In particular it
follows that a process X â€œ tXpsq : a Ä s Ä bu verifying (3.134) has a HÂ¨older
continuous version of order Î±, Î± Äƒ r{p.
Proof. It suï¬ƒces to prove (3.135), because the version problem can be
taken care of as in Theorem 3.18. Without loss of generality we may and do
suppose that a â€œ 0 and that b â€œ 1. Otherwise we consider the process Y deï¬ned
by Y psq â€œ X ppa0 ` spb0 Â´ a0qq, 0 Ä s Ä 1, where a0 and b0 are dyadic rational
with a0 Ä a and with b Ä b0 and where outside of the interval ra, bs the process
X is deï¬ned by Xptq â€œ Xpaq, if a0 Ä t Ä a, and Xptq â€œ Xpbq, if b Ä t Ä b0.
Put Ïµ â€œ r Â´ Î±p. Then
P p|Xptq Â´ Xpsq| Ä› |t Â´ s|Î±q Ä |t Â´ s|Â´Î±p E p|Xptq Â´ Xpsq|pq Ä K |t Â´ s|1`Ïµ ,
(3.136)
so that
P
Ë†Ë‡Ë‡Ë‡Ë‡X
Ë†k ` 1
2n
Ë™
Â´ X
Ë† k
2n
Ë™Ë‡Ë‡Ë‡Ë‡ Ä› 2Â´nÎ±
Ë™
Ä K2Â´n2Â´nÏµ.
(3.137)
Hence
8
Ã¿
nâ€œ1
2nÂ´1
Ã¿
kâ€œ0
P
Ë†Ë‡Ë‡Ë‡Ë‡X
Ë†k ` 1
2n
Ë™
Â´ X
Ë† k
2n
Ë™Ë‡Ë‡Ë‡Ë‡ Ä› 2Â´nÎ±
Ë™
Ä K
8
Ã¿
nâ€œ1
2n2Â´n2Â´nÏµ â€œ
K
2Ïµ Â´ 1.
(3.138)
By the Borel-Cantelli lemma it follows that
P
Ëœ 8
Ä
mâ€œ1
Ä
nÄ›m
"
max
0ÄkÄ2nÂ´1
Ë‡Ë‡Ë‡Ë‡X
Ë†k ` 1
2n
Ë™
Â´ X
Ë† k
2n
Ë™Ë‡Ë‡Ë‡Ë‡ Ä 2Â´nÎ±
*Â¸
â€œ 1.
(3.139)
Hence there exists a random integer Î½pXq with the following property: For
P-almost all Ï‰ the inequality
max
0ÄkÄ2nÂ´1
Ë‡Ë‡Ë‡Ë‡X
Ë†k ` 1
2n
Ë™
Â´ X
Ë† k
2n
Ë™Ë‡Ë‡Ë‡Ë‡ Ä 2Â´nÎ±
(3.140)
is valid for n Ä› Î½pXq. Next let n Ä› Î½pXq and let t be a dyadic rational in the
interval rk2Â´n, pk ` 1q2Â´ns. Write t â€œ k2Â´n ` Å™m
jâ€œ1 Î³j2Â´nÂ´j, each Î³j equals 0 or
1. Then
Ë‡Ë‡Ë‡Ë‡Xptq Â´ X
Ë† k
2n
Ë™Ë‡Ë‡Ë‡Ë‡ Ä
m
Ã¿
jâ€œ1
Î³j
2Î±pn`jq Ä
1
2Î± Â´ 1
1
2nÎ±.
(3.141)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
153 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Similarly we have, with t â€œ â„“2Â´N, N Ä› n, pk ` 1q2Â´n â€œ â„“2Â´N ` Å™m1
jâ€œ1 Î³1
j2Â´NÂ´j,
Î³1
j equals 0 or 1,
Ë‡Ë‡Ë‡Ë‡Xptq Â´ X
Ë†k ` 1
2n
Ë™Ë‡Ë‡Ë‡Ë‡ Ä
m1
Ã¿
jâ€œ1
Î³1
j
2Î±pN`jq Ä
1
2Î± Â´ 1
1
2NÎ± Ä
1
2Î± Â´ 1
1
2nÎ±.
(3.142)
Next let s and t be dyadic rationale numbers with 0 Äƒ t Â´ s Ä 2Â´Î½pXq. Take
n P N with 2Â´nÂ´1 Ä tÂ´s Äƒ 2Â´n and pick k in such a way that k2Â´nÂ´1 Ä s Äƒ pk`
1q2Â´nÂ´1. Then pk`1q2Â´nÂ´1 Ä t â€œ tÂ´s`s Äƒ 2Â´n `pk`1q2Â´nÂ´1 â€œ pk`3q2Â´nÂ´1.
It follows that, since t belongs to rpk ` 1q2Â´nÂ´1, pk ` 2q2Â´nÂ´1s or to the interval
rpk ` 2q2Â´nÂ´1, pk ` 3q2Â´nÂ´1s,
|Xptq Â´ Xpsq|
Ä
Ë‡Ë‡Ë‡Ë‡Xptq Â´ X
Ë†k ` 2
2n`1
Ë™Ë‡Ë‡Ë‡Ë‡ `
Ë‡Ë‡Ë‡Ë‡X
Ë†k ` 2
2n`1
Ë™
Â´ X
Ë†k ` 1
2n`1
Ë™Ë‡Ë‡Ë‡Ë‡ `
Ë‡Ë‡Ë‡Ë‡X
Ë†k ` 1
2n`1
Ë™
Â´ Xpsq
Ë‡Ë‡Ë‡Ë‡
Ä
3
2Î± Â´ 12Â´pn`1qÎ± Ä
3
2Î± Â´ 1 |t Â´ s|Î± .
(3.143)
If 1 Ä› tÂ´s Ä… 2Â´Î½pXq, we choose k and â„“P N in such a way that 2Î½pXq Ä… â„“Ä… k Ä› 0
and that â„“2Â´Î½pXq Äƒ t Ä pâ„“` 1q2Â´Î½pXq and k2Â´Î½pXq Äƒ s Ä pk ` 1q2Â´Î½pXq. Then
we get
|Xptq Â´ Xpsq| Ä
Ë‡Ë‡Ë‡Ë‡Xptq Â´ X
Ë†â„“` 1
2Î½pXq
Ë™Ë‡Ë‡Ë‡Ë‡ `
jâ€œâ„“
Ã¿
jâ€œk
Ë‡Ë‡Ë‡Ë‡X
Ë†j ` 1
2Î½pXq
Ë™
Â´ X
Ë†
j
2Î½pXq
Ë™Ë‡Ë‡Ë‡Ë‡
`
Ë‡Ë‡Ë‡Ë‡X
Ë†
k
2Î½pXq
Ë™
Â´ Xpsq
Ë‡Ë‡Ë‡Ë‡
Ä 2 ` 2Î½pXq
2Î± Â´ 1 2Â´Î±Î½pXq Ä 2 ` 2Î½pXq
2Î± Â´ 1
|t Â´ s|Î± .
(3.144)
From (3.143) and (3.144) the result in Theorem 3.65 follows.
â–¡
In order to apply the previous result to Brownian motion, we insert a general
equality for a Gaussian variable X.
3.66. Proposition. Let X : â„¦Ã‘ R be a non-constant Gaussian variable. Then
its distribution is given by
P pX P Bq â€œ
1
`
2Ï€E
`
X2 Â´ pE pXqq2Ë˜Ë˜1{2
Å¼
B
exp
Ëœ
Â´1
2
|x Â´ EpXq|2
E pX2q Â´ pE pXqq2
Â¸
dxq
(3.145)
and its moments E p|X Â´ EpXq|pq, p Ä… Â´1, are given by
E p|X Â´ EpXq|pq â€œ 2
1
2 pÎ“
`1
2p ` 1
2
Ë˜
?Ï€
Ë†b
E
`
X2 Â´ pEpXqq2Ë˜Ë™p
.
(3.146)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
154 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Equality (3.145) follows from formula (3.8) and formula (3.146) is
proved by using (3.145). The formal arguments read (we write Y â€œ X Â´EpXq):
E p|Y |pq â€œ
1
p2Ï€E pY 2qq1{2
Å¼
|y|p exp
Ë†
Â´1
2
y2
EpY 2q
Ë™
dy
â€œ
Â´a
EpY 2q
Â¯p
2
?
2Ï€
Å¼ 8
0
yp exp
Ë†
Â´1
2y2
Ë™
dy
â€œ
Â´a
EpY 2q
Â¯p 2
1
2pÎ“
` 1
2p ` 1
2
Ë˜
?Ï€
.
The latter is the same as (3.146).
â–¡
3.67. Theorem. Let tbpsq : s Ä› 0u be d-dimensional Brownian motion. This
process is P-almost surely HÂ¨older continuous of order Î± for any Î± Äƒ 1
2.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
155 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. It suï¬ƒces to prove Theorem 3.67 for 1-dimensional Brownian mo-
tion. So suppose d â€œ 1 and let Î± Äƒ 1{2. Choose p Ä… 1 so large that Î± Äƒ 1
2 Â´ 1
p.
From inequality (3.146) in Proposition 3.66 with X â€œ bptq Â´ bpsq we obtain
E p|bptq Â´ bpsq|pq â€œ E p|bpt Â´ sq|pq â€œ Cp
`
E
`
|bpt Â´ sq|2Ë˜Ë˜p{2
â€œ Cp |t Â´ s|p{2 â€œ Cp |t Â´ s|1`r ,
(3.147)
where r â€œ p{2 Â´ 1 Ä… pÎ±. An application of Theorem 3.65 yields the desired
result.
â–¡
The following theorem says that Brownian motion is nowhere diï¬€erentiable.
3.68. Theorem. Fix Î± Ä… 1
2. Then with probability one, t ÃÃ‘ bptq is nowhere
HÂ¨older continuous of order Î±. More precisely
P
Ë†
inf
0ÄtÄ1
â€
lim sup
hÃ‘0
|bpt ` hq Â´ bptq|
|h|Î±
È·
â€œ 8
Ë™
â€œ 1.
Proof. For a proof we refer the reader to the literature; e.g. Simon [[121],
Theorem 5.4. p. 46].
â–¡
In the theory of stochastic integration we will have a need for the following
lemma. The following lemma can also be proved by the strong law of large
numbers: see e.g. Smythe [123].
3.69. Lemma. Let tbpsq : s Ä› 0u be one-dimensional Brownian motion. Then,
P-almost surely, limnÃ‘8
Å™2nÂ´1
kâ€œ0 |b ppk ` 1q2Â´ntq Â´ b pk2Â´ntq|2 â€œ t.
Proof. Put â–³k,n â€œ |b ppk ` 1q2Â´ntq Â´ b pk2Â´ntq|2Â´2Â´nt. Then the variables
â–³k,n, 0 Ä k Ä 2n Â´ 1, are independent and have expectation 0. So that
E
Ëœ2nÂ´1
Ã¿
kâ€œ0
â–³k,n
Â¸2
â€œ
2nÂ´1
Ã¿
kâ€œ0
E pâ–³k,nq2 â€œ
2nÂ´1
Ã¿
kâ€œ0
E
Â´Ë‡Ë‡b
`
2Â´nt
Ë˜Ë‡Ë‡2 Â´ 2Â´nt
Â¯2
â€œ 2n Â´
E
Ë‡Ë‡b
`
2Â´nt
Ë˜Ë‡Ë‡4 Â´ 2E
Ë‡Ë‡b
`
2Â´nt
Ë˜Ë‡Ë‡2 2Â´nt ` 2Â´2nt2Â¯
â€œ 2 Ë† 2Â´nt2.
(3.148)
Tchebychevâ€™s inequality gives
P
Â¨
Ë
Ëœ2nÂ´1
Ã¿
kâ€œ0
â–³k,n
Â¸2
Ä… Ïµ
Ë›
â€šÄ 2
Ïµt22Â´n.
Hence
8
Ã¿
nâ€œ1
P
Â¨
Ë
Ëœ2nÂ´1
Ã¿
kâ€œ0
â–³k,n
Â¸2
Ä… Ïµ
Ë›
â€šÄ 2t2
Ïµ . Thus we may apply the Borel-Cantelli
lemma to prove the claim in Lemma 3.69.
â–¡
3.70. Proposition. Brownian motion is nowhere of bounded variation.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
156 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Just as in the previous lemma we have that, for t Ä… s Ä› 0,
lim
nÃ‘8
2nÂ´1
Ã¿
kâ€œ0
Ë‡Ë‡b
`
s ` pk ` 1q2Â´npt Â´ sq
Ë˜
Â´ b
`
s ` k2Â´npt Â´ sq
Ë˜Ë‡Ë‡2 Â´ pt Â´ sq â€œ 0,
P-almost surely. Since Brownian paths are almost surely continuous it follows
that (for Î´ Ä… 0)
0 Äƒ t Â´ s Ä lim
nÃ‘8
2nÂ´1
Ã¿
kâ€œ0
Ë‡Ë‡b
`
s ` pk ` 1q2Â´npt Â´ sq
Ë˜
Â´ bp
`
s ` k2Â´npt Â´ sq
Ë˜Ë‡Ë‡2
Ä lim inf
nÃ‘8
max
0Äâ„“Ä2n
Ë‡Ë‡b
`
s ` pâ„“` 1q2Â´npt Â´ sq
Ë˜
Â´ bp
`
s ` â„“2Â´npt Â´ sq
Ë˜Ë‡Ë‡
Ë†
2nÂ´1
Ã¿
kâ€œ0
Ë‡Ë‡b
`
s ` pk ` 1q2Â´npt Â´ sq
Ë˜
Â´ bp
`
s ` k2Â´npt Â´ sq
Ë˜Ë‡Ë‡
Ä
sup
sÄÏƒ1,Ïƒ2Ät,|Ïƒ2Â´Ïƒ1|ÄÎ´
|bpÏƒ2q Â´ bpÏƒ1q| Ë† variation of b on the interval rs, ts.
The statement in the Proposition 3.70 now follows from the continuity of paths.
â–¡
Next we will see how to transfer properties of discrete time semi-martingales
to continuous time semi-martingales. Most of the results in the remainder of
this section are taken from Bhattacharya and Waymire [15]. We begin with an
upcrossing inequality for a discrete time sub-martingale. Consider a sequence
tZn : n P Nu of real-valued random variables and sigma-ï¬elds F1 Ä‚ F2 Ä‚ Â¨ Â¨ Â¨ ,
such that, for every n P N, the variable Zn is Fn-measurable. An upcrossing of
an interval pa, bq by tZnu is a passage to a value equal to or exceeding b from an
value equal to or below a at an earlier time. Deï¬ne the random variables Xn,
n P N, by Xn â€œ max pZn Â´ a, 0q. If the process tZnu is a sub-martingale, then
so is the process tXnu. The upcrossings of p0, bÂ´aq by tXnu are the upcrossings
of the interval pa, bq by tZnu. We deï¬ne the successive upcrossing times Î·2k,
k P N, of tXnu as follows:
Î·1 â€œ inf tn Ä› 1 : Xn â€œ 0u ;
Î·2 â€œ inf tn Ä› Î·1 : Xn Ä› b Â´ au ;
Î·2k`1 â€œ inf tn Ä› Î·2k : Xn â€œ 0u ;
Î·2k`2 â€œ inf tn Ä› Î·2k`1 : Xn Ä› b Â´ au .
Then every Î·k is an tFnu-stopping time. Fix N P N and put Ï„k â€œ min pÎ·k, Nq.
Then every Ï„k is also a stopping time and Ï„k â€œ N for k Ä… tN{2u, the largest
integer smaller than or equal to N{2. It follows that XÏ„2k â€œ XN for k Ä… tn{2u
and we also have Î·k Ä› k and so k Ä Ï„k Ä N. Let UNpa, bq be the number of
upcrossings of pa, bq by the process tZnu at time N. That means
UNpa, bq â€œ sup tk Ä› 1 : Î·2k Ä Nu
(3.149)
with the convention that the supremum over the empty set is 0. Notice that
UNpa, bq is also the number of upcrossings of the interval p0, b Â´ aq by tXnu in
time N.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
157 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.71. Proposition (Upcrossing inequality). Let tZnu be an tFnu-submartin-
gale. For each pair pa, bq, a Äƒ b, the expected number of upcrossings of pa, bq by
Z1, . . . , ZN satisï¬es the inequality:
E pUNpa, bqq Ä E pmax pZN Â´ a, 0q Â´ max pZ1 Â´ a, 0qq
b Â´ a
Ä E pmax pZN Â´ Z1, 0qq
b Â´ a
.
(3.150)
Proof. Since XÏ„2k â€œ XN for k Ä… tN{2u, we may write (setting Ï„0 â€œ 1):
XN Â´ X1 â€œ
tN{2u`1
Ã¿
kâ€œ1
`
XÏ„2kÂ´1 Â´ XÏ„2kÂ´2
Ë˜
`
tN{2u`1
Ã¿
kâ€œ1
`
XÏ„2k Â´ XÏ„2kÂ´1
Ë˜
.
(3.151)
Next let Î½ be the largest integer k with the property that Î·k Ä N, i.e. Î½ is
the last time Ä N of an upcrossing or a downcrossing. It readily follows that
UNpa, bq â€œ tÎ½{2u. If Î½ is even, then
XÏ„2k Â´ XÏ„2kÂ´1 Ä› b Â´ a
provided
2k Â´ 1 Äƒ Î½;
XÏ„2k Â´ XÏ„2kÂ´1 â€œ XN Â´ XN â€œ 0
provided
2k Â´ 1 Ä… Î½.
(3.152)
Now suppose that Î½ is odd. Then we have
XÏ„2k Â´ XÏ„2kÂ´1 Ä› b Â´ a
provided
2k Â´ 1 Äƒ Î½;
XÏ„2k Â´ XÏ„2kÂ´1 â€œ XÏ„2k Â´ XÎ½ Ä› XÏ„2k Â´ 0 â€œ XÏ„2k
provided
2k Â´ 1 â€œ Î½;
XÏ„2k Â´ XÏ„2kÂ´1 â€œ XN Â´ XN â€œ 0
provided
2k Â´ 1 Ä… Î½.
(3.153)
From (3.152) and (3.153) it follows that
tN{2u`1
Ã¿
kâ€œ1
`
XÏ„2k Â´ XÏ„2kÂ´1
Ë˜
Ä›
tÎ½{2u
Ã¿
kâ€œ1
`
XÏ„2k Â´ XÏ„2kÂ´1
Ë˜
Ä› tÎ½{2upb Â´ aq â€œ pb Â´ aqUNpa, bq.
(3.154)
Consequently
XN Â´ X1 Ä›
tN{2u`1
Ã¿
kâ€œ1
`
XÏ„2kÂ´1 Â´ XÏ„2kÂ´2
Ë˜
` pb Â´ aqUNpa, bq.
(3.155)
So far we did not make use of the fact that the process tXnu is a sub-martingale.
It then follows that the process tXÏ„k : k P Nu is a tFÏ„nu-martingale and hence
k ÃÃ‘ E pXÏ„kq is an increasing sequence of non-negative real numbers. So that
(3.155) yields
E pXN Â´ X1q Ä›
tN{2u`1
Ã¿
kâ€œ1
E
`
XÏ„2k Â´ XÏ„2kÂ´1
Ë˜
` pb Â´ aqE pUNpa, bqq
Ä› pb Â´ aqE pUNpa, bqq .
(3.156)
The desired result in Proposition 3.71 follows from (3.156).
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
158 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.72. Theorem. (Sub-martingale convergence theorem) Let tZnu be a sub-mar-
tingale with the property that supnPN E p|Zn|q Äƒ 8. Then the sequence tZnu
converges almost surely to an integrable random variable Z8. Moreover we have
E p|Z8|q Ä lim infnÃ‘8 E p|Zn|q.
3.73. Remark. In general we do not have E pZ8q â€œ limnÃ‘8 E pZnq. In fact
there exist martingales tMn : n P Nu such that Mn Ä› 0, such that EpMnq â€œ 1,
n P N, and such that M8 â€œ limnÃ‘8 Mn â€œ 0, P-almost surely. To be speciï¬c,
let tbpsq : s Ä› 0u be Î½-dimensional Brownian motion starting at x P RÎ½ and let
ppt, x, yq be the corresponding transition density. Fix t Ä… 0 and y Â­â€œ x and put
Mn â€œ p pt{n, bpt Â´ t{nq, yq
ppt, x, yq
.
(3.157)
The process tMn : n P Nu deï¬ned in (3.157) is Px-martingale with respect to
the sigma-ï¬elds Fn generated by bpsq, 0 Ä s Ä t Â´ t{n.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
â–¶â–¶enroll by September 30th, 2014 and 
â–¶â–¶save up to 16% on the tuition!
â–¶â–¶pay in 10 installments / 2 years
â–¶â–¶Interactive Online education
â–¶â–¶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
159 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Let Upa, bq be the total number of upcrossings of pa, bq by the pro-
cess tZn : n P Nu. Then UNpa, bq Ã’ Upa, bq as N Ã’ 8. Therefore, by monotone
convergence,
E
`
pUpa, bq
Ë˜
â€œ lim
NÃ‘8 E pUNpa, bqq Ä sup
NPN
E p|ZN|q ` |a|
b Â´ a
Äƒ 8.
(3.158)
In particular it follows that Upa, bq Äƒ 8 P-almost surely. Hence
P plim inf Zn Äƒ a Äƒ b Äƒ lim sup Znq Ä P pUpa, bq â€œ 8q â€œ 0.
(3.159)
Since
tlim inf Zn Äƒ lim sup Znu â€œ
Ä
aÄƒb,a,bPQ
tlim inf Zn Äƒ a Äƒ b Äƒ lim sup Znu
it follows from (3.159) that P plim inf Zn Äƒ lim sup Znq â€œ 0. By Fatouâ€™s lemma
it follows that E p|Z8|q â€œ E plim infn |Zn|q Ä lim inf E p|Zn|q Äƒ 8.
This completes the proof of Theorem 3.72.
â–¡
3.74. Corollary. A non-negative martingale tZnu converges almost surely to
a ï¬nite limit Z8. Also E pZ8q Ä E pZ1q.
Remark. Convergence properties for supermartingales tZnu are obtained from
the sub-martingale results applied to tÂ´Znu.
Since a semi-martingale is a
diï¬€erence of two sub-martingales, we also have convergence results for semi-
martingales.
3.75. Definition. A continuous time process tXptq : t P Ru is called stochasti-
cally continuous at t0 if for every Îµ Ä… 0
lim
tÃ‘t0 P p|Xptq Â´ Xpt0q| Ä… Îµq â€œ 0.
(3.160)
3.76. Remark. Brownian motion possesses almost surely continuous sample
paths and is stochastically continuous for every t Ä› 0.
On the other hand
a Poisson process is stochastically continuous, but its sample paths are step
functions with unit jumps. In fact, for t Ä… s, Xptq Ä› Xpsq P-almost surely and,
again for t Ä… s, P pXptq Â´ Xpsq â€œ nq â€œ eÂ´Î»ptÂ´sq
`
Î»pt Â´ sq
Ë˜n
n!
and hence, always
for t Ä… s and for Ïµ Ä… 0,
P pXptq Â´ Xpsq Ä› Ïµq Ä eÂ´Î»ptÂ´sq
8
Ã¿
nâ€œ1
`
Î»pt Â´ sq
Ë˜n
n!
â€œ 1 Â´ eÂ´Î»ptÂ´sq.
3.77. Theorem. Let tXptq : t Ä› 0u be a sub-martingale or a super-martingale
that is stochastically continuous at each t Ä› 0.
Then there exists a process
!
r
Xptq : t Ä› 0
)
with the following properties:
(i) (stochastic equivalence)
!
r
Xptq
)
is equivalent to tXptqu in the sense
that
P
Â´
r
Xptq â€œ Xptq
Â¯
â€œ 1
for every
t Ä› 0;
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
160 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(ii) (sample path regularity) with probability 1 the sample paths of the pro-
cess
!
r
Xptq : t Ä› 0
)
are bounded on compact intervals ra, bs, a Äƒ b Äƒ 8,
are right-continuous and possess left-hand limits at each t Ä… 0 (in other
words
!
r
Xptq : t Ä› 0
)
is cadlag).
Proof. Fix T Ä… 0 and let QT denote the set of rational numbers in r0, Ts.
Write QT â€œ Å¤8
nâ€œ1 Rn, where Rn is a ï¬nite subset of r0, Ts and where T P R1 Ä‚
R2 Ä‚ R2 Ä‚ Â¨ Â¨ Â¨ . By Doobâ€™s maximal inequality for sub-martingales we have
P
Ë†
max
tPRn |Xptq| Ä… Î»
Ë™
Ä E |XpTq|
Î»
,
n â€œ 1, 2, . . .
and hence
P
Ë†
sup
tPQT
|Xptq| Ä… Î»
Ë™
Ä lim
nÃ‘8 P
Ë†
max
tPRn |Xptq| Ä… Î»
Ë™
Ä E |XpTq|
Î»
,
n â€œ 1, 2, . . .
For Doobâ€™s maximal inequality see e.g. Proposition 3.107 or Theorem 5.110.
In particular, the paths of tXptq : t P QTu are bounded with probability 1. Let
pc, dq be any interval in R and let U tTupc, dq denote the number of upcrossings of
pc, dq by the process tXptq : t P QTu. Then U tTupc, dq is the limit of the number
U tnupc, dq of upcrossings of pc, dq by tXptq : t P Rnu as n tends to 8. By the
upcrossing inequality we have
E
`
U tnupc, dq
Ë˜
Ä E p|XpTq|q ` |c|
d Â´ c
.
(3.161)
Since U tnupc, dq increases with n it follows from (3.161) that
E
`
U tTupc, dq
Ë˜
Ä E p|XpTq|q ` |c|
d Â´ c
,
(3.162)
and hence that U tTupc, dq is almost surely ï¬nite. Taking unions over all intervals
pc, dq, with c, d P Q, and c Äƒ d, it follows with probability 1 that the process
tXptq : t P QTu has only ï¬nitely many upcrossings of any interval. In particular,
therefore, left- and right-hand limits must exist at each t Äƒ T P-almost surely.
To construct a right-continuous version of tXptqu we deï¬ne
!
r
Xptq : t Ä› 0
)
as
follows: r
Xptq â€œ limsÃ“t,sPQ Xpsq for t Äƒ T. That this process
!
r
Xptq
)
is stochas-
tically equivalent to tXptqu follows from the stochastic continuity of the process
tXptqu.
Further details are left to the reader.
This completes the proof of
Theorem 3.77.
â–¡
Next we prove Doobâ€™s optional sampling for continuous time sub-martingales
(that are right-continuous) and a similar result holds for martingales (where the
inequality sign in (3.163) is replaced with an equality) and for super-martingales
(where the inequality is reversed). For discrete sub-martingales the result will
be taken for granted: see Theorems 5.104 and 5.114.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
161 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.78. Theorem. Let tXptq : t Ä› 0u be a right-continuous sub-martingale of class
(DL) and let T be a stopping time. Suppose t Ä› s. Then
E
â€œ
X
`
minpt, Tq
Ë˜ Ë‡Ë‡ Fs
â€°
Ä› X
`
minps, Tq
Ë˜
,
P-almost surely.
(3.163)
Proof. Put sn â€œ 2Â´nr2nss, tn â€œ 2Â´nr2nts and Tn â€œ 2Â´nr2nTs. If A belongs
to Fs, then A also belongs to Fsn for all n P N. From Doobâ€™s optional sampling
for discrete time sub-martingales we infer, upon using the (DL)-property,
E rX pminptn, Tnqq 1As Ä› E rX pminpsn, Tnqq 1As .
(3.164)
Upon letting n tend to 8 and using the right-continuity of the process t ÃÃ‘ Xptq,
t Ä› 0, we infer
E rX pminpt, Tqq 1As Ä› E rX pminps, Tqq 1As ,
(3.165)
where A P Fs is arbitrary.
Consequently the result in (3.163) follows from
(3.165), and so the proof of Theorem is complete 3.78.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
162 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
6. Stochastic integrals, ItË†oâ€™s formula
The assumptions are as in Section 4. The process tbptq : t Ä› 0u is assumed to
be one-dimensional Brownian motion and hence the process t ÃÃ‘ bptq2 Â´ t is a
martingale: see Proposition 3.23. The following proposition contains the basic
ingredients of (the deï¬nition of) a stochastic integral.
3.79. Proposition. Let s1, . . . , sn and t1, . . . , tn be non-negative numbers for
which sjÂ´1 Äƒ tjÂ´1 Ä sj Äƒ tj, 2 Ä j Ä n. Let f1, . . . , fn be bounded random
variables which are measurable with respect to Fs1, . . . , Fsn respectively. Put
Y ps, Ï‰q â€œ
Ã¿n
jâ€œ1 fjpÏ‰q1psj,tjspsq
and write
Å¼ t
0
Y ps, Â¨qdbpsq â€œ
Ã¿n
jâ€œ1 fj tbpminpt, tjqq Â´ bpminpt, sjqqu .
The following assertions hold true:
(a) The process
!ÅŸt
0 Y psqdbpsq : t Ä› 0
)
is a martingale and the process
"Â´ÅŸt
0 Y psqdbpsq
Â¯2
: t Ä› 0
*
is a submartingale.
(b) The process
"Â´ÅŸt
0 Y psqdbpsq
Â¯2
Â´
ÅŸt
0 Y psq2ds : t Ä› 0
*
is a martingale.
(c) (ItË†o isometry) The following equality is valid:
E
Â«Ë†Å¼ t
0
Y psqdbpsq
Ë™2ï¬€
â€œ E
â€Å¼ t
0
Y psq2ds
È·
.
(3.166)
The equality in assertion (c) is called the ItË†o isometry.
It is an extremely
important equality: the entire ItË†o calculus is justiï¬ed by the use of the equality
in (3.166).
Proof. The more or less straightforward calculations are left as an exercise
to the reader. We insert some ways to simplify the computations. Let F and G
be predictable processes of the form Fpsq â€œ f1pu,8qpsq and Gpsq â€œ g1pv,8qpsq,
where f is measurable for the Ïƒ-ï¬eld Fu and g for Fv. Put
ItpFq â€œ
Å¼ t
0
Fpsqdbpsq :â€œ f pbptq Â´ bpminpu, tqqq
and similarly write
ItpGq â€œ
Å¼ t
0
Gpsqdbpsq â€œ g pbptq Â´ bpminpv, tqqq .
Without loss of generality we assume v Ä› u (otherwise we interchange the
role of F and G). We begin with a proof of (a). Upon employing linearity it
suï¬ƒces to show that the process t ÃÃ‘ ItpFq is a martingale. (Also notice that
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
163 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
ÅŸt
0 f1pu,vspsqdbpsq â€œ ItpFq Â´ ItpF1q, where F1psq â€œ f1pv,8qpsq.) Fix t Ä… s Ä› 0 and
consider
E
`
ItpFq
Ë‡Ë‡ Fs
Ë˜
Â´ IspFq â€œ E
`
ItpFq Â´ IspFq
Ë‡Ë‡ Fs
Ë˜
â€œ E
`
f pbptq Â´ bpminpu, tqq Â´ bpsq ` bpminpu, sqqq
Ë‡Ë‡ Fs
Ë˜
â€œ E
`
E
`
f pbptq Â´ bpminpu, tqq Â´ bpsq ` bpminpu, sqqq
Ë‡Ë‡ Fminpmaxpu,sq,tq
Ë˜ Ë‡Ë‡ Fs
Ë˜
â€œ E
`
fE
`
pbptq Â´ bpminpu, tqq Â´ bpsq ` bpminpu, sqqq
Ë‡Ë‡ Fminpmaxpu,sq,tq
Ë˜ Ë‡Ë‡ Fs
Ë˜
(Brownian motion is a martingale)
â€œ E
`
f ppbpminpmaxpu, sq, tqq Â´ bpminpu, tqq Â´ bpsq ` bpminpu, sqqqq
Ë‡Ë‡ Fs
Ë˜
â€œ 0,
proving that the process t ÃÃ‘ ItpFq is a martingale indeed.
Next we shall
prove that the process t ÃÃ‘ ItpFqItpGq Â´
ÅŸt
0 FpÏ„qGpÏ„qdÏ„ is a martingale. Using
bilinearity in F and G yields a proof of (b) and hence also of (c). Again we ï¬x
t Ä… s and consider
E
Ë†
ItpFqItpGq Â´
Å¼ t
0
FpÏ„qGpÏ„qdÏ„
Ë‡Ë‡ Fs
Ë™
Â´
Ë†
IspFqIspGq Â´
Å¼ s
0
FpÏ„qGpÏ„qdÏ„
Ë™
â€œ E
Ë†
ItpFqItpGq Â´
Å¼ t
0
FpÏ„qGpÏ„qdÏ„ Â´
Ë†
IspFqIspGq Â´
Å¼ s
0
FpÏ„qGpÏ„qdÏ„
Ë™ Ë‡Ë‡ Fs
Ë™
â€œ E
Ë†
pItpFq Â´ IspFqq pItpGq Â´ IspGqq Â´
Å¼ t
s
FpÏ„qGpÏ„qdÏ„
Ë‡Ë‡ Fs
Ë™
` E
`
IspFq pItpGq Â´ IspGqq ` pItpFq Â´ IspFqq IspGq
Ë‡Ë‡ Fs
Ë˜
â€œ E
Ë†
pItpFq Â´ IspFqq pItpGq Â´ IspGqq Â´
Å¼ t
s
FpÏ„qGpÏ„qdÏ„
Ë‡Ë‡ Fs
Ë™
` IspFqE
`
ItpGq Â´ IspGq
Ë‡Ë‡ Fs
Ë˜
` E
`
ItpFq Â´ IspFq
Ë‡Ë‡ Fs
Ë˜
IspGq
(use the martingale property of ItpFq and ItpGq)
â€œ E
â€
pItpFq Â´ IspFqq pItpGq Â´ IspGqq Â´
Å¼ t
s
FpÏ„qGpÏ„q dÏ„
Ë‡Ë‡ Fs
È·
â€œ E
â€œ
fg pbptq Â´ b pminpmaxpu, sq, tqqq
`
bptq Â´ b
`
minpmaxpv, sq, tq
Ë˜Ë˜
Â´fg pt Â´ minpmaxpu, v, sq, tqq
Ë‡Ë‡ Fs
â€°
(use v Ä› u and put us,t â€œ minpmaxpu, sq, tq, vs,t â€œ minpmaxpv, sq, tq)
â€œ E
â€
fg
Â´`
bptq Â´ b
`
vs,t
Ë˜Ë˜2
`fg
`
b
`
vs,t
Ë˜
Â´ b
`
us,t
Ë˜Ë˜ `
bptq Â´ b
`
vs,t
Ë˜Ë˜
Â´ fg pt Â´ minpmaxpu, v, sq, tqq
Ë‡Ë‡ Fs
Ë˜â€°
â€œ E
â€
fg
Â´`
bptq Â´ b
`
vs,t
Ë˜Ë˜2 Â´ pt Â´ vs,tq
Â¯ Ë‡Ë‡ Fs
Ä±
` E
â€œ`
fg
`
b
`
vs,t
Ë˜
Â´ b
`
us,t
Ë˜Ë˜ `
bptq Â´ b
`
vs,t
Ë˜Ë˜Ë˜ Ë‡Ë‡ Fs
â€°
â€œ E
â€
fgE
â€Â´`
bptq Â´ b
`
vs,t
Ë˜Ë˜2 Â´ pt Â´ vs,tq
Â¯ Ë‡Ë‡ Fvs,t
Ä± Ë‡Ë‡ Fs
Ä±
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
164 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
` E
â€œ
fg
`
b
`
vs,t
Ë˜
Â´ b
`
us,t
Ë˜Ë˜
Ë† E
â€œ`
bptq Â´ b
`
vs,t
Ë˜Ë˜ Ë‡Ë‡ Fvs,t
â€° Ë‡Ë‡ Fs
â€°
(the processes tbpsqu and tbpsq2 Â´ su are martingales)
â€œ E
`
fg.0
Ë‡Ë‡ Fs
Ë˜
` E
`
fg
`
b
`
vs,t
Ë˜
Â´ b
`
us,t
Ë˜Ë˜
.0
Ë‡Ë‡ Fs
Ë˜
â€œ 0.
The latter yields a proof of (b) (via bilinearity). Altogether this ï¬nishes the
proof of Proposition 3.79.
â–¡
3.80. Definition. A process of the form
Fps, Ï‰q â€œ
Ã¿n
jâ€œ1 fjpÏ‰q1psj,tjspsq,
where 0 Ä sjÂ´1 Äƒ tjÂ´1 Ä sj Äƒ tj, 2 Ä j Ä n, and where the functions f1, . . . , fn
are bounded and measurable with respect to Fs1, . . . , Fsn respectively is called
a simple predictable process.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
165 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.81. Definition. Again let b be Brownian motion with drift zero and let Î 2pbq
be the vector space of all predictable processes F with the property that
}F}2
b :â€œ E
Ë†Å¼ 8
0
|Fpsq|2 ds
Ë™
Äƒ 8.
Let Q be the Ïƒ-additive measure, deï¬ned on the predictable ï¬eld Î , determined
by
Q pA Ë† ps, tsq â€œ E r1As pt Â´ sq â€œ PpAqpt Â´ sq,
A P Fs.
(3.167)
The measure Q is called the DolÂ´eans measure for Brownian motion.
Then it follows that Î 2pbq â€œ L2 pr0, 8q Ë† â„¦, Î , Qq. Moreover we have
}F}2
b â€œ
Å¼
|F|2 dQ,
F P Î 2pbq.
It also follows that, for given F P Î 2pbq, there exists a sequence of simple
processes pFn : n P Nq, which are predictable, such that limnÃ‘8 }Fn Â´ F}b â€œ 0.
Hence in view of Proposition 3.79 it is obvious how to deï¬ne
ÅŸt
0 Fpsq dbpsq, t Ä› 0,
for F P Î 2pbq. In fact
Å¼ t
0
Fpsqdbpsq â€œ L2- lim
nÃ‘8
Å¼ t
0
Fnpsqdbpsq,
where the sequence pFn : n P Nq veriï¬es limnÃ‘8 }Fn Â´ F}b â€œ 0 and where Fn
belongs to Î 2pbq. Let Î 3pbq be the vector space of all predictable processes F for
which the integrals
ÅŸt
0 |Fpsq|2 ds are ï¬nite P-almost surely for all t Ä… 0. In order
to extend the deï¬nition of stochastic integral to processes F P Î 3pbq we proceed
as follows. Deï¬ne the stopping times Tn, n P N, in the following fashion:
Tn â€œ inf
"
t Ä… 0 :
Å¼ t
0
|Fpsq|2 ds Ä… n
*
.
(3.168)
We also write Fnpsq â€œ Fpsq1tTnÄ…su and we observe that Fn is a predictable
process with
ÅŸ
|Fnpsq|2 ds Ä n. Moreover it follows that for n Ä… m the expression
Å¼ t
0
Fnpsqdbpsq Â´
Å¼ t
0
Fmpsqdbpsq â€œ
Å¼
Fpsq1pTm,minpTn,tqspsqdbpsq
(3.169)
vanishes almost everywhere on the event tTm Ä… tu. So it makes sense to write
Å¼ t
0
Fpsqdbpsq â€œ
Å¼ t
0
Fmpsqdbpsq,
on
tTm Ä… tu.
Since limnÃ‘8 Tn â€œ 8, P-almost surely, the quantity
ÅŸt
0 Fpsqdbpsq is unambigu-
ously deï¬ned. Hence the integral
ÅŸ
Fpsqdbpsq is well deï¬ned for processes F
belonging to Î 3pbq.
3.82. Corollary. Let b be Brownian motion and let F and G be processes in
Î 3pbq. The following processes are local martingales:
"Å¼ t
0
Fpsqdbpsq : t Ä› 0
*
,
"Å¼ t
0
Gpsqdbpsq : t Ä› 0
*
;
(3.170)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
166 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
#Ë†Å¼ t
0
Fpsqdbpsq
Ë™2
Â´
Å¼ t
0
|Fpsq|2 ds : t Ä› 0
+
;
(3.171)
"Å¼ t
0
Fpsqdbpsq
Å¼ t
0
Gpsqdbpsq Â´
Å¼ t
0
FpsqGpsqds : t Ä› 0
*
.
(3.172)
Put Xptq â€œ
ÅŸt
0 Fpsqdbpsq and Y ptq â€œ
ÅŸt
0 Gpsqdbpsq. The following identity is
valid:
XptqY ptq Â´
Å¼ t
0
FpsqGpsqds â€œ
Å¼ t
0
FpsqY psqdbpsq `
Å¼ t
0
XpsqGpsqdbpsq.
(3.173)
Proof. The assertions (3.170), (3.171) and (3.172) follow from Proposition
3.79 together with taking appropriate limits. For the proof of (3.173) we ï¬rst
take F â€ G â€ 1. Then (3.173) reduces to showing that
bptq2 Â´ 2
Å¼ t
0
bpsqdbpsq Â´ t â€œ 0.
(3.174)
Notice that (3.174) is equivalent to 2
ÅŸt
0 bpsqdbpsq â€œ bptq2 Â´ t,
t Ä› 0. For the
proof of (3.174) we use Lemma 3.69. to conclude:
bptq2 Â´ 2
Å¼ t
0
bpsqdbpsq Â´ t
â€œ lim
nÃ‘8
Ëœ
bptq2 Â´ 2
2nÂ´1
Ã¿
kâ€œ0
b
`
k2Â´nt
Ë˜ `
b
`
pk ` 1q2Â´nt
Ë˜
Â´ b
`
k2Â´nt
Ë˜
Â´ t
Ë˜
Â¸
â€œ lim
nÃ‘8
Ëœ2nÂ´1
Ã¿
kâ€œ0
Â´
b
`
pk ` 1q2Â´nt
Ë˜2 Â´ b
`
k2Â´nt
Ë˜2Â¯
Â´2
2nÂ´1
Ã¿
kâ€œ0
b
`
k2Â´nt
Ë˜ `
b
`
pk ` 1q2Â´nt
Ë˜
Â´ b
`
k2Â´nË˜Ë˜
Â´ t
Â¸
â€œ lim
nÃ‘8
Ëœ2nÂ´1
Ã¿
kâ€œ0
`
b
`
pk ` 1q2Â´nt
Ë˜
Â´ b
`
k2Â´nt
Ë˜Ë˜2 Â´ t
Â¸
â€œ 0.
For the proof of (3.173) we then take Fpsq â€œ f1ps1,8qpsq and Gpsq â€œ g1ps2,8q,
where f is bounded and measurable with respect to Fs1 and g is measurable
with respect to Fs2. Formula (3.174) will then yield the desired result. Then we
pass over to linear combinations and ï¬nally to limits. This completes the proof
of Corollary 3.82.
â–¡
3.83. Proposition. Stochastic integrals with integrands in Î 3pbq are continuous
P-almost surely.
Proof. It suï¬ƒces to prove the result for integrands in Î 2pbq. Since Brow-
nian motion is almost surely continuous, it follows that stochastic integrals of
simple predictable processes are continuous. Let F be in Î 2pbq and choose a
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
167 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
sequence pFnqnPN of simple predictable processes with the property that
Ë†
E
Ë†Å¼ t0
0
|Fpsq Â´ Fnpsq|2 ds
Ë™Ë™1{2
â€œ lim
â„“Ã‘8
Ë†
E
Ë†Å¼ t0
0
|Fn`â„“psq Â´ Fnpsq|2 ds
Ë™Ë™1{2
Ä
8
Ã¿
â„“â€œ1
Ë†
E
Ë†Å¼ t0
0
|Fn`â„“psq Â´ Fn`â„“Â´1psq|2 ds
Ë™Ë™1{2
Ä
8
Ã¿
â„“â€œ1
2Â´nÂ´â„“Â´2 â€œ 2Â´nÂ´1.
From Proposition 3.63 it follows that, for k P N,
Ëœ
E
Â«
sup
0ÄtÄt0
Ë‡Ë‡Ë‡Ë‡
Å¼ t
0
pFn`kpsq Â´ Fnpsqq dbpsq
Ë‡Ë‡Ë‡Ë‡
2ï¬€Â¸ 1
2
Ä
kÃ¿
â„“â€œ1
Ëœ
E
Â«
sup
0ÄtÄt0
Ë‡Ë‡Ë‡Ë‡
Å¼ t
0
pFn`â„“psq Â´ Fn`â„“Â´1psqq dbpsq
Ë‡Ë‡Ë‡Ë‡
2ï¬€Â¸ 1
2
Ä 2
8
Ã¿
â„“â€œ1
Ëœ
E
Â«Ë‡Ë‡Ë‡Ë‡
Å¼ t0
0
pFn`â„“psq Â´ Fn`â„“Â´1psqq dbpsq
Ë‡Ë‡Ë‡Ë‡
2ï¬€Â¸ 1
2
â€œ 2
8
Ã¿
â„“â€œ1
Ë†
E
â€Å¼ t0
0
|Fn`â„“psq Â´ Fn`â„“Â´1psq|2 ds
È·Ë™ 1
2
Ä 2Â´n.
(3.175)
From (3.175) the sample path continuity of stochastic integrals immediately
follows. This completes the proof of Proposition 3.83.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Masterâ€™s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top masterâ€™s programmes
â€¢ 33rd place Financial Times worldwide ranking: MSc 
International Business
â€¢ 1st place: MSc International Business
â€¢ 1st place: MSc Financial Economics
â€¢ 2nd place: MSc Management of Learning
â€¢ 2nd place: MSc Economics
â€¢ 2nd place: MSc Econometrics and Operations Research
â€¢ 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier â€˜Beste Studiesâ€™ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Advanced stochastic processes: Part I
168 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.84. Remark. The theory in this section can be extended to (continuous)
martingales instead of Brownian motion. To be precise, let t ÃÃ‘ Mptq be a
continuous martingale with quadratic variation process t ÃÃ‘ âŸ¨M, MâŸ©ptq. Then
the process t ÃÃ‘ Mptq2 Â´ âŸ¨M, MâŸ©ptq is a martingale, and the space Î 2pbq should
be replaced with Î 2pMq, the space of all predictable processes t ÃÃ‘ Fptq with
the property that
}F}2
M â€œ E
â€Å¼ 8
0
|Fpsq|2 d âŸ¨M, MâŸ©psq
È·
Äƒ 8.
(3.176)
The corresponding DolÂ´eans measure QM is given by
QM pA Ë† ps, tsq â€œ E r1A pâŸ¨M, MâŸ©ptq Â´ âŸ¨M, MâŸ©psqqs ,
A P Fs,
s Äƒ t. (3.177)
It follows that
Î 2pMq â€œ L2 pâ„¦Ë† r0, 8q, Î , QMq .
The space Î 3pMq consists of those predictable processes t ÃÃ‘ Fptq which have
the property that
ÅŸt
0 |Fpsq|2 d âŸ¨M, MâŸ©s are ï¬nite P-almost surely for all t Ä… 0.
The deï¬nition of stochastic integral to processes F P Î 3pMq we proceed as
follows. Deï¬ne the stopping times Tn, n P N, in the following fashion:
Tn â€œ inf
"
t Ä… 0 :
Å¼ t
0
|Fpsq|2 d âŸ¨M, MâŸ©psq Ä… n
*
.
(3.178)
As in the case of Brownian motion these stopping times can be used to deï¬ne
stochastic integrals of the form
ÅŸt
0 Fpsq dMpsq, F P Î 3pMq. These integrals are
then local martingales.
Next we extend the equality in (3.173) to the multi-dimensional situation.
3.85. Proposition. Let s ÃÃ‘ Ïƒpsq â€œ pÏƒjkpsqq1Äj,kÄÎ½ be a matrix with predictable
entries and with the property that the expression
Î½Ã¿
j,kâ€œ1
Å¼ t
0
E |Ïƒjkpsq|2 ds
(3.179)
is ï¬nite for every t Ä… 0. Put aijpsq â€œ Å™Î½
kâ€œ1 ÏƒikpsqÏƒjkpsq, 1 Ä i, j Ä Î½. Further-
more let tbpsq â€œ pb1psq, . . . , bÎ½psqq : s Ä› 0u be Î½-dimensional Brownian motion.
Put Mjptq â€œ Å™Î½
kâ€œ1
ÅŸt
0 Ïƒjkpsqdbkpsq, 1 Ä j Ä Î½. Then the following identity is
valid:
MiptqMjptq
(3.180)
â€œ
Î½Ã¿
kâ€œ1
Å¼ t
0
MipsqÏƒjkpsqdbkpsq `
Î½Ã¿
kâ€œ1
Å¼ t
0
ÏƒikpsqMjpsqdbkpsq `
Å¼ t
0
aijpsqds.
Proof. First we suppose Î½ â€œ 2, M1ptq â€œ b1ptq and M2ptq â€œ b2ptq. Then
(3.180) reads as follows:
b1ptqb2ptq â€œ
Å¼ t
0
b1psqdb2psq `
Å¼ t
0
b2psqdb1psq.
(3.181)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
169 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In order to prove (3.181) we write
b1ptqb2ptq Â´
Å¼ t
0
b1psqdb2psq Â´
Å¼ t
0
b2psqdb1psq
â€œ lim
nÃ‘8
2nÂ´1
Ã¿
kâ€œ0
#
b1
`
pk ` 1q2Â´nt
Ë˜
b2
`
pk ` 1q2Â´nt
Ë˜
Â´ b1
`
k2Â´nt
Ë˜
b2
`
k2Â´nt
Ë˜
Â´ b1
`
k2Â´nt
Ë˜ `
b2
`
pk ` 1q2Â´nt
Ë˜
Â´ b2
`
k2Â´nt
Ë˜Ë˜
Â´ b2
`
k2Â´nt
Ë˜ `
b1
`
pk ` 1q2Â´nt
Ë˜
Â´ b1
`
k2Â´nt
Ë˜Ë˜
+
â€œ lim
nÃ‘8
2nÂ´1
Ã¿
kâ€œ0
`
b1
`
pk ` 1q2Â´nt
Ë˜
Â´ b1
`
k2Â´nt
Ë˜Ë˜ `
b2
`
pk ` 1q2Â´nt
Ë˜
Â´ b2
`
k2Â´nt
Ë˜Ë˜
.
(3.182)
The limit in (3.182) vanishes, because by independence and martingale proper-
ties of the processes b1 and b2, we infer
E
Â«2nÂ´1
Ã¿
kâ€œ0
`
b1
`
pk ` 1q2Â´nt
Ë˜
Â´ b1
`
k2Â´nt
Ë˜Ë˜ `
b2
`
pk ` 1q2Â´nt
Ë˜
Â´ b2
`
k2Â´nt
Ë˜Ë˜
ï¬€2
â€œ E
Ëœ2nÂ´1
Ã¿
kâ€œ0
`
b1
`
pk ` 1q2Â´nt
Ë˜
Â´ b1
`
k2Â´nt
Ë˜Ë˜2 `
b2
`
pk ` 1q2Â´nt
Ë˜
Â´ b2
`
k2Â´nt
Ë˜Ë˜2
Â¸
â€œ
2nÂ´1
Ã¿
kâ€œ0
E
â€œ
b1
`
pk ` 1q2Â´nt
Ë˜
Â´ b1
`
k2Â´nt
Ë˜â€°2 E
`
b2
`
pk ` 1q2Â´nt
Ë˜
Â´ b2
`
k2Â´nt
Ë˜Ë˜2
â€œ
2nÂ´1
Ã¿
kâ€œ0
`
2Â´nt
Ë˜2 â€œ 2Â´nt2.
(3.183)
From Borel-Cantelliâ€™s lemma it then easily follows that the limit in (3.182) van-
ishes and hence that equality (3.181) is true. The validity of (3.180) is then
checked for the special case that Ïƒjkpsq â€œ fjk1psjk,8qpsq, where fjk is measurable
with respect to Fsjk. The general statement follows via bi-linearity and a lim-
iting procedure together with equality (3.173) in Corollary 5.142. The proof of
Proposition 3.85 is now complete.
â–¡
Next let Mptq â€œ pM1ptq, . . . , MÎ½ptqq be a Î½-dimensional martingale as in Propo-
sition 3.85 and let Aptq â€œ pA1ptq, . . . , AÎ½ptqq be an adapted Î½-dimensional pro-
cess that P-almost surely is of bounded variation on r0, ts for every t Ä… 0. This
means that
sup
nPN
sup
0Äs0Äƒs1ÄƒÂ¨Â¨Â¨snÄt |Apsjq Â´ ApsjÂ´1q|
is ï¬nite P-almost surely for all t Ä… 0.
It follows that the random set function ÂµA : pa, bs ÃÃ‘ Apbq Â´ Apaq extends
to an RÎ½-valued measure on r0, ts for every t Ä… 0. Stieltjes integrals of the
form
ÅŸt
0 FpsqdApsq may be interpreted as
ÅŸt
0 FpsqdApsq â€œ
ÅŸt
0 FpsqdÂµApsq. The
process A may have jumps. This is not the case for the process M. The latter
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
170 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
follows from Proposition 3.83. The process X :â€œ A ` M is a Î½-dimensional
semi-martingale with the property that E
`
|Mptq|2Ë˜
Äƒ 8, t Ä… 0. Put
JXptq â€œ
Ã¿
sÄt pXpsq Â´ XpsÂ´qq
â€œ
Ã¿
sÄt
pMpsq Â´ MpsÂ´qq `
Ã¿
sÄt
pApsq Â´ ApsÂ´qq â€œ JAptq.
The deï¬nition of JAptq does not pose to much of a problem. In fact for P-almost
all Ï‰ the sum
Ã¿
sÄt
|Aps, Ï‰q Â´ ApsÂ´, Ï‰q| Äƒ 8. The process tXptq Â´ JXptq : t Ä› 0u
is P-almost surely continuous.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
171 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The following result is the fundamental theorem in stochastic calculus.
3.86. Theorem (ItË†oâ€™s formula). Let X â€œ pX1, . . . , XÎ½q â€œ A ` M be a Î½-
dimensional local semi-martingale as described above, and let f : RÎ½ Ã‘ R be a
twice continuously diï¬€erentiable function. Put aijptq â€œ Å™Î½
kâ€œ1 ÏƒikptqÏƒjkptq, 1 Ä i,
j Ä Î½. Then, P-almost surely,
fpXptqq
â€œ fpXp0qq `
Ã¿
sÄt
Ë†
fpXpsqq Â´ f pXpsÂ´qq Â´ âˆ‡f pXpsÂ´qq . pXpsq Â´ XpsÂ´qq
Ë™
`
Å¼ t
0
âˆ‡f pXpsÂ´qq Â¨ dXpsq ` 1
2
Î½Ã¿
i,jâ€œ1
Å¼ t
0
DiDjfpXpsqqaijpsqds.
(3.184)
Before we prove Theorem 3.86 we want to make some comments and we want to
give a reformulation of ItË†oâ€™s formula. Moreover, we shall not prove ItË†oâ€™s formula
in its full generality. We shall content ourselves with a proof with A â€ 0.
Remark. The integral
ÅŸt
0 âˆ‡f pXpsÂ´qq dXpsq has the interpretation:
Å¼ t
0
âˆ‡f pXpsÂ´qq dXpsq
â€œ
Î½Ã¿
iâ€œ1
Ë†Å¼ t
0
Dif pXpsÂ´qq dMipsq `
Å¼ t
0
Dif pXpsÂ´qq dAipsq
Ë™
(3.185)
â€œ
Î½Ã¿
iâ€œ1
Ë†Å¼ t
0
Dif pXpsÂ´qq dMipsq `
Å¼ t
0
Dif pXpsÂ´qq dAipsq
Ë™
â€œ
Î½Ã¿
iâ€œ1
Ëœ Î½Ã¿
kâ€œ1
Å¼ t
0
Dif pXpsÂ´qq Ïƒikpsqdbkpsq `
Å¼ t
0
Dif pXpsÂ´qq dAipsq
Â¸
.
Here X â€œ M ` A is the decomposition of the semi-martingale in a martingale
part M and a process A which is locally of bounded variation.
For Î½-dimensional Brownian motion we have the following corollary.
3.87. Corollary. Let bptq â€œ pb1ptq, . . . , bÎ½ptqq be Î½-dimensional Brownian mo-
tion. Let f : RÎ½ Ã‘ R be a twice continuously diï¬€erentiable function. Then,
P-almost surely,
fpbptqq â€œ fpbp0qq `
Å¼ t
0
âˆ‡fpbpsqqdbpsq ` 1
2
Å¼ t
0
â–³fpbpsqqds.
(3.186)
In fact it suï¬ƒces to suppose that the functions D1f, . . . , DÎ½f and D2
1f, . . . , D2
Î½f
are continuous. Next we reformulate ItË†oâ€™s formula.
3.88. Theorem. Let X â€œ pX1, . . . , XÎ½q be a Î½-dimensional right continuous
semi-martingale as in Theorem 3.86 and let f : RÎ½ Ã‘ R be a twice continuously
diï¬€erentiable function. Then, P-almost surely,
fpXptqq â€œ fpXp0qq `
Å¼ t
0
âˆ‡f pXpsÂ´qq Â¨ dXpsq
(3.187)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
172 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
`
Î½Ã¿
i,jâ€œ1
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒd rXi, Xjs psq,
where
rXi, Xjs ptq â€œ
Å¼ t
0
aijpsqds `
Ã¿
sÄt
pXipsq Â´ XipsÂ´qq pXjpsq Â´ XjpsÂ´qq .
(3.188)
Remark. In the proof below we employ the following notation. Let Mi be
martingale of the form
Miptq :â€œ
Î½Ã¿
kâ€œ1
Å¼ t
0
Ïƒikpsqdbkpsq.
Then quadratic covariation process âŸ¨Mi, MjâŸ©ptq satisï¬es
âŸ¨Mi, MjâŸ©ptq â€œ
Î½Ã¿
kâ€œ1
Å¼ t
0
ÏƒikpsqÏƒjkpsq ds.
Proof of Theorems 3.88 and 3.86. Since, for a and b in RÎ½
fpbq Â´ fpaq â€œ âˆ‡fpaq.pb Â´ aq
(3.189)
`
Î½Ã¿
i,jâ€œ1
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ Ïƒqa ` Ïƒbq dÏƒ Ë† pbi Â´ aiqpbj Â´ ajq
and since
rXi, Xjs ptq â€œ
Å¼ t
0
aijpsqds `
Ã¿
sÄt
pXipsq Â´ XipsÂ´qq pXjpsq Â´ XjpsÂ´qq ,
it follows that
Î½Ã¿
i,jâ€œ1
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒd rXi, Xjs psq
â€œ
Î½Ã¿
i,jâ€œ1
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒaijpsqds
`
Î½Ã¿
i,jâ€œ1
Ã¿
sÄt
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒ
Ë† pXipsq Â´ XipsÂ´qq pXjpsq Â´ XjpsÂ´qq
â€œ
Î½Ã¿
i,jâ€œ1
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒaijpsqds
`
Ã¿
sÄt
tfpXpsqq Â´ f pXpsÂ´qq Â´ âˆ‡f pXpsÂ´qq . pXpsq Â´ XpsÂ´qqu . (3.190)
So the formulas in Theorem 3.88 and Theorem 3.86 are equivalent. Also notice
that, since
ÅŸt
0 aijpsqds is a continuous process of ï¬nite variation (locally), we
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
173 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
have
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒaijpsqds
â€œ
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsÂ´qq dÏƒaijpsqds
â€œ 1
2
Å¼ t
0
DiDjf pXpsÂ´qq aijpsqds.
Hence it suï¬ƒces to prove equality (3.187) in Theorem 3.88. Assume Xp0q â€œ
Mp0q and hence Ap0q â€œ 0.
Upon stopping we may and do assume that in
X â€œ M ` A, |XptÂ´q| Ä L and varAptÂ´q Ä L.
This can be achieved by
replacing Xptq with Xpminpt, Ï„qq, where Ï„ is the stopping time deï¬ned by
Ï„ â€œ inf ts Ä… 0 : max p|Mpsq| , varApsqq Ä… Lu .
Here varApsq is deï¬ned by
varApsq â€œ sup
# nÃ¿
jâ€œ1
|Apsjq Â´ ApsjÂ´1q| : 0 Ä s0 Äƒ s1 Äƒ . . . Äƒ sn â€œ s
+
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Advanced stochastic processes: Part I
174 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Next we deï¬ne, for every n P N, the sequence of stopping times tTn,k : k P Nu
as follows:
Tn,0 â€œ 0;
Tn,k`1 â€œ inf
"
s Ä… Tn,k : max ps Â´ Tn,k, |Xpsq Â´ XpTn,kq|q Ä… 1
n
*
.
(3.191)
Since
max pTn,k`1 Â´ Tn,k, |XpTn,k`1q Â´ XpTn,kq|q Ä› 1
n,
it follows that lim
kÃ‘8 Tn,k â€œ 8, P-almost surely. Moreover, since
max pTn,k`1 Â´ Tn,k, |XpTn,k`1Â´q Â´ XpTn,kq|q Ä 1
n,
we have Tn,k`1 Â´ Tn,k Ä 1
n. Next we write:
fpXptqq Â´ fpXp0qq
â€œ
8
Ã¿
kâ€œ0
tf pX pTn,k`1 ^ tÂ´qq Â´ f pX pTn,k ^ tqq
`f pX pTn,k`1 ^ tqq Â´ f pX pTn,k`1 ^ tÂ´qqu
â€œ
8
Ã¿
kâ€œ0
#Å¼ Tn,k`1^tÂ´
Tn,k^t
âˆ‡f pX pTn,k ^ tqq Â¨ dXpsq
`
Î½Ã¿
i,jâ€œ1
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqX pTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Ë† pXi pTn,k`1 ^ tÂ´q Â´ Xi pTn,k ^ tqq pXj pTn,k`1 ^ tÂ´q Â´ Xj pTn,k ^ tqq
` f pX pTn,k`1 ^ tqq Â´ f pX pTn,k`1 ^ tÂ´qq
+
.
(3.192)
On the other hand we also have:
Å¼ t
0
âˆ‡f pXpsÂ´qq dXpsq
`
Î½Ã¿
i,jâ€œ1
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒd rXi, Xjs psq
â€œ
8
Ã¿
kâ€œ0
#Å¼ Tn,k`1^tÂ´
Tn,k^t
âˆ‡f pXpsÂ´qq Â¨ dXpsq
`
Î½Ã¿
i,jâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒd rXi, Xjs psq
` âˆ‡f pX pTn,k`1 ^ tÂ´qq . pX pTn,k`1 ^ tq Â´ X pTn,k`1 ^ tÂ´qq
`
Î½Ã¿
i,jâ€œ1
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqX pTn,k`1 ^ tÂ´q ` ÏƒX pTn,k`1 ^ tqq dÏƒ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
175 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Ë† pXi pTn,k`1 ^ tq Â´ Xi pTn,k`1 ^ tÂ´qq pXj pTn,k`1 ^ tq Â´ Xj pTn,k`1 ^ tÂ´qq
+
â€œ
8
Ã¿
kâ€œ0
#Å¼ Tn,k`1^tÂ´
Tn,k^t
âˆ‡f pXpsÂ´qq Â¨ dXpsq
`
Î½Ã¿
i,jâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒd rXi, Xjs psq
` f pX pTn,k`1 ^ tqq Â´ f pX pTn,k`1 ^ tÂ´qq
+
.
(3.193)
Upon subtracting (3.193) from (3.192) we infer by employing Proposition 3.85:
fpXptqq Â´ fpXp0qq Â´
Å¼ t
0
âˆ‡f pXpsÂ´qq dXpsq
Â´
Î½Ã¿
i,jâ€œ1
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒd rXi, Xjs psq
â€œ
8
Ã¿
kâ€œ0
#
Â´
Å¼ Tn,k`1^tÂ´
Tn,k^t
pâˆ‡f pXpsÂ´qq Â´ âˆ‡f pX pTn,kqqq Â¨ dXpsq
`
Î½Ã¿
i,jâ€œ1
Å¼ Tn,k`1^tÂ´
Tn,k^t
"Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqX pTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Â´
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒ
*
d rXi, Xjs psq
`
Î½Ã¿
i,jâ€œ1
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqX pTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Ë†
"
pXi pTn,k`1 ^ tÂ´q Â´ Xi pTn,k ^ tqq pXj pTn,k`1 ^ tÂ´q Â´ Xj pTn,k ^ tqq
Â´ rXi, Xjs pTn,k`1 ^ tÂ´q ` rXi, Xjs pTn,k ^ tq
*+
â€œ
8
Ã¿
kâ€œ0
#
Â´
Å¼ Tn,k`1^tÂ´
Tn,k^t
pâˆ‡f pXpsÂ´qq Â´ âˆ‡f pX pTn,kqqq Â¨ dXpsq
`
Î½Ã¿
i,jâ€œ1
Å¼ Tn,k`1^tÂ´
Tn,k^t
Å¼ 1
0
p1 Â´ Ïƒq tDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq
Â´DiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqqu dÏƒd rXi, Xjs psq
`
Î½Ã¿
i,jâ€œ1
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Ë†
#Å¼ Tn,k`1^tÂ´
Tn,k^t
pXipsÂ´q Â´ Xi pTn,k ^ tqq dXjpsq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
176 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
`
Å¼ Tn,k`1^tÂ´
Tn,k^t
pXjpsÂ´q Â´ Xj pTn,k ^ tqq dXipsq
++
.
(3.194)
We shall estimate the following quantities:
E
Â¨
Ë
Ëœ 8
Ã¿
kâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
pDif pXpsÂ´qq Â´ Dif pX pTn,k ^ tqqq Â¨ dMipsq
Â¸2Ë›
â€š; (3.195)
E
ËœË‡Ë‡Ë‡Ë‡Ë‡
8
Ã¿
kâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
pDif pXpsÂ´qq Â´ Dif pX pTn,k ^ tqqq Â¨ dAipsq
Ë‡Ë‡Ë‡Ë‡Ë‡
Â¸
;
(3.196)
E
ËœË‡Ë‡Ë‡Ë‡Ë‡
8
Ã¿
kâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
Å¼ 1
0
p1 Â´ Ïƒq tDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq
Â´DiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqqu dÏƒd rXi, Xjs psq
Ë‡Ë‡Ë‡Ë‡Ë‡
Â¸
;
(3.197)
E
ËœËœ 8
Ã¿
kâ€œ0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Ë†
Å¼ Tn,k`1^tÂ´
Tn,k^t
pXipsÂ´q Â´ Xi pTn,k ^ tqq dMjpsq
Â¸2Â¸
;
(3.198)
E
ËœË‡Ë‡Ë‡Ë‡Ë‡
8
Ã¿
kâ€œ0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Ë†
Å¼ Tn,k`1^tÂ´
Tn,k^t
pXipsÂ´q Â´ Xi pTn,k ^ tqq dAjpsq
Ë‡Ë‡Ë‡Ë‡Ë‡
Â¸
.
(3.199)
Since the process
ÅŸu
0 pDif pXpsÂ´qq Â´ Dif pX pTn,k ^ tqqq dMipsq, u Ä› 0, is a mar-
tingale, the quantity in (3.195) veriï¬es
E
Â¨
Ë
Ëœ 8
Ã¿
kâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
pDif pXpsÂ´qq Â´ Dif pX pTn,k ^ tqqq Â¨ dMipsq
Â¸2Ë›
â€š
â€œ
8
Ã¿
kâ€œ0
E
Â¨
Ë
ËœÅ¼ Tn,k`1^tÂ´
Tn,k^t
pDif pXpsÂ´qq Â´ Dif pX pTn,k ^ tqqq Â¨ dMipsq
Â¸2Ë›
â€š
â€œ
8
Ã¿
kâ€œ0
E
ËœÅ¼ Tn,k`1^tÂ´
Tn,k^t
pDif pXpsÂ´qq Â´ Dif pX pTn,k ^ tqqq2 Â¨ d âŸ¨MiâŸ©psq
Â¸
Ä
sup
x,yPRÎ½:|yÂ´x|Ä1{n,maxp|x|,|y|qÄ2L
|Difpyq Â´ Difpxq|2 .E pâŸ¨MiâŸ©ptqq .
(3.200)
Similarly we obtain an estimate for the quantity in (3.198):
E
ËœËœ 8
Ã¿
kâ€œ0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
177 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Ë†
Å¼ Tn,k`1^tÂ´
Tn,k^t
pXipsÂ´q Â´ Xi pTn,k ^ tqq dMjpsq
Â¸2Ë›
â€š
â€œ E
Ëœ 8
Ã¿
kâ€œ0
Ë†Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Ë™2
Ë†
ËœÅ¼ Tn,k`1^tÂ´
Tn,k^t
pXipsÂ´q Â´ Xi pTn,k ^ tqq dMjpsq
Â¸2Ë›
â€š
Ä 1
2 sup
|y|Ä2L
|DiDjfpyq| E
Ëœ 8
Ã¿
kâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
pXipsÂ´q Â´ Xi pTn,k ^ tqq2 d âŸ¨MjâŸ©psq
Â¸
Ä 1
2 sup
|y|Ä2L
|DiDjfpyq| Ë† 1
n2E pâŸ¨MjâŸ©ptqq .
(3.201)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planetâ€™s 
electricity needs. Already today, SKFâ€™s innovative know-
how is crucial to running a large proportion of the 
worldâ€™s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Advanced stochastic processes: Part I
178 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The other estimates are even easier:
â€œ E
ËœË‡Ë‡Ë‡Ë‡Ë‡
8
Ã¿
kâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
pDif pXpsÂ´qq Â´ Dif pX pTn,kqqq Â¨ dAipsq
Ë‡Ë‡Ë‡Ë‡Ë‡
Â¸
Ä
sup
x,yPRÎ½:|yÂ´x|Ä1{n,maxp|x|,|y|qÄ2L
|Difpyq Â´ Difpxq| .E
Ë†Å¼ t
0
|dAipsq|
Ë™
,
(3.202)
E
ËœË‡Ë‡Ë‡Ë‡Ë‡
8
Ã¿
kâ€œ0
Å¼ Tn,k`1^tÂ´
Tn,k^t
Å¼ 1
0
p1 Â´ Ïƒq tDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq
Â´DiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqqu dÏƒd rXi, Xjs psq
Ë‡Ë‡Ë‡Ë‡Ë‡
Â¸
Ä 1
2
sup
x,yPRÎ½:|yÂ´x|Ä1{n,maxp|x|,|y|qÄ2L
|DiDjfpyq Â´ DiDjfpxq|
Ë† E
Ë†Å¼ t
0
|d rXi, Xjs psq|
Ë™
Ä 1
2
sup
x,yPRÎ½:|yÂ´x|Ä1{n,maxp|x|,|y|qÄ2L
|DiDjfpyq Â´ DiDjfpxq|
Ë†
a
E prXi, Xis ptqq
b
E prXj, Xjs ptqq,
and
(3.203)
E
ËœË‡Ë‡Ë‡Ë‡Ë‡
8
Ã¿
kâ€œ0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpTn,k ^ tq ` ÏƒX pTn,k`1 ^ tÂ´qq dÏƒ
Ë†
Å¼ Tn,k`1^tÂ´
Tn,k^t
pXipsÂ´q Â´ Xi pTn,k ^ tqq dAjpsq
Ë‡Ë‡Ë‡Ë‡Ë‡
Â¸
Ä 1
2n
sup
yPRÎ½,|y|Ä2L
|DiDjfpyq| E
Ë†Å¼ t
0
|dAjpsq|
Ë™
.
(3.204)
The inequality (3.203) will be established shortly.
The quantities (3.200),
(3.201), (3.202), (3.203) and (3.204) tend to zero if n tends to inï¬nity. Conse-
quently, from (3.194) it then follows that, P-almost surely,
fpXptqq â€œ fpXp0qq `
Å¼ t
0
âˆ‡fpXpsqqdXpsq
(3.205)
`
Î½Ã¿
i,jâ€œ1
Å¼ t
0
Å¼ 1
0
p1 Â´ ÏƒqDiDjf pp1 Â´ ÏƒqXpsÂ´q ` ÏƒXpsqq dÏƒd rXi, Xjs psq.
So that the formula of ItË†o has been established now. For completeness we prove
the inequality
E
Ë†Å¼ t
0
|d rXi, Xjs psq|
Ë™
Ä
a
E prXi, Xis ptqq
b
E prXj, Xjs ptqq.
(3.206)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
179 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
A proof of (3.206) will establish (3.203). For an appropriate sequence of subdivi-
sions 0 â€œ spnq
0
Äƒ spnq
1
Äƒ Â¨ Â¨ Â¨ Äƒ spnq
Nn â€œ t we have with, temporarily, rXis â€œ rXi, Xis,
Å¼ t
0
|d rXi, Xjs psq| â€œ lim
nÃ‘8
Nn
Ã¿
kâ€œ1
Ë‡Ë‡Ë‡rXi, Xjs
Â´
spnq
k
Â¯
Â´ rXi, Xjs
Â´
spnq
kÂ´1
Â¯Ë‡Ë‡Ë‡
Ä lim
nÃ‘8
Nn
Ã¿
kâ€œ1
c
rXis
Â´
spnq
k
Â¯
Â´ rXis
Â´
spnq
kÂ´1
Â¯c
rXjs
Â´
spnq
k
Â¯
Â´ rXjs
Â´
spnq
kÂ´1
Â¯
Ä lim
nÃ‘8
Ëœ Nn
Ã¿
kâ€œ1
Â´
rXi, Xis
Â´
spnq
k
Â¯
Â´ rXi, Xis
Â´
spnq
kÂ´1
Â¯Â¯Â¸1{2
Ëœ Nn
Ã¿
kâ€œ1
Â´
rXj, Xjs
Â´
spnq
k
Â¯
Â´ rXj, Xjs
Â´
spnq
kÂ´1
Â¯Â¯Â¸1{2
â€œ prXi, Xis ptq Â´ rXi, Xis p0qq1{2 prXj, Xjs ptq Â´ rXj, Xjs p0qq1{2
(3.207)
Taking expectations and using the inequality of Cauchy-Schwartz once more
yields the desired result.
This completes the proofs of Theorems 3.86 and 3.88.
â–¡
Remark. In the proof of equality (3.194) there is a gap. It is correct if the
process A â€ 0. In order to make the proof complete, Proposition 3.85 has to be
supplemented with equalities of the form (Miptq â€œ Å™Î½
kâ€œ1
ÅŸt
0 Ïƒikpsqdbkpsq):
MiptqAjptq â€œ
Å¼ t
0
MipsqdAjpsq `
Î½Ã¿
kâ€œ1
Å¼ t
0
ÏƒikpsqAjpsqdbkpsq;
AiptqAjptq â€œ
Å¼ t
0
AipsqdAjpsq `
Å¼ t
0
AjpsqdAipsq.
This kind of equalities is true for continuous processes. If jumps are present
even more care has to be taken. We continue with some examples. We begin
with the heat equation.
Example 1. (Heat equation) Let U be an open subset of RÎ½, let f : U Ã‘ R be
a function in C0pEq and let u : r0, 8q Ë† U Ã‘ R be a solution to the following
problem:
$
&
%
Bu
Bt
â€œ 1
2âˆ†u in r0, 8q Ë† U;
u
is continuous on r0, 8q Ë† U and up0, xq â€œ fpxq.
Moreover we assume that
lim
xÃ‘b,xPU upt, xq â€œ 0 if b belongs to BU. Then upt, xq â€œ
Ex rfpbptqq : Ï„ Ä… ts, where Ï„ is the exit time of U: Ï„ â€œ inf ts Ä… 0 : bpsq P RÎ½zUu.
Of course tbpsq : s Ä› 0u stands for Î½-dimensional Brownian motion. In order to
prove this claim we ï¬x t Ä… 0 and we consider the process tMpsq : 0 Ä s Ä tu
deï¬ned by Mpsq â€œ upt Â´ s, bpsqq1tÏ„Ä…su. An application of ItË†oâ€™s formula yields
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
180 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
the following identities:
Mpsq Â´ Mp0q â€œ Â´
Å¼ s
0
Bu
Bt pt Â´ r, bprqq1tÏ„Ä…rudr `
Å¼ s
0
âˆ‡upt Â´ r, bprqq1tÏ„Ä…ru Â¨ dbprq
` 1
2
Å¼ s
0
âˆ†upt Â´ r, bprqq1tÏ„Ä…rudr
â€œ
Å¼ s
0
"
Â´Bu
Bt pt Â´ r, bprqq ` 1
2âˆ†upt Â´ r, bprqq
*
1tÏ„Ä…rudr
`
Å¼ s
0
âˆ‡upt Â´ r, bprqq1tÏ„Ä…ru Â¨ dbprq
â€œ
Å¼ s
0
âˆ‡upt Â´ r, bprqq1tÏ„Ä…ru Â¨ dbprq.
Consequently, the process tMpsq : 0 Ä s Ä tu is a martingale. It follows that
upt, xq â€œ Ex pupt, bp0qqq â€œ ExpMp0qq â€œ ExpMptqq
â€œ Ex
`
up0, bptqq1tÏ„Ä…tu
Ë˜
â€œ Ex
`
fpbptqq1tÏ„Ä…tu
Ë˜
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
181 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Example 2. Let U be an open subset of RÎ½, let f belong to C0pUq and let
g : r0, 8q Ë† U Ã‘ R be a function in C0pEq and let u : r0, 8q Ë† U Ã‘ R be a
solution to the following problem:
$
&
%
Bu
Bt â€œ 1
2âˆ†u ` g in r0, 8q Ë† U;
u is continuous on r0, 8q Ë† U and up0, xq â€œ fpxq.
Moreover we assume that limxÃ‘b,xPU upt, xq â€œ 0 if b belongs to BU.
Then
upt, xq â€œ Ex pfpbptqq : Ï„ Ä… tq ` Ex
Â´ÅŸminpt,Ï„q
0
gpt Â´ r, bprqqdr
Â¯
, where, as in Ex-
ample 1, Ï„ is the exit time of U. Also as in Example 1, tbpsq : s Ä› 0u stands for
Î½-dimensional Brownian motion. A proof can be given following the same lines
as in the previous example.
Example 3.
(Feynman-Kac formula) Let U be an open subset of RÎ½, let
f belong to C0pUq and let V : U Ã‘ R be an appropriate function and let
u : r0, 8q Ë† U Ã‘ R be a solution to the following problem:
$
&
%
Bu
Bt â€œ 1
2âˆ†u Â´ V u in r0, 8q Ë† U;
u is continuous on r0, 8q Ë† U and up0, xq â€œ fpxq.
Moreover we want that limxÃ‘b,xPU upt, xq â€œ 0 if b belongs to BU. Then upt, xq â€œ
Ex
Â´
exp
Â´
Â´
ÅŸt
0 V pbprqqdr
Â¯
fpbptqq : Ï„ Ä… t
Â¯
.
For the proof we ï¬x t Ä… 0 and we consider the process tMpsq : 0 Ä s Ä tu deï¬ned
by Mpsq â€œ upt Â´ s, bpsqq exp
`
Â´
ÅŸs
0 V pbprqqdr
Ë˜
1tÏ„Ä…su and we apply ItË†oâ€™s formula
to obtain:
Mpsq Â´ Mp0q
â€œ
Å¼ s
0
"
Â´Bu
Bt pt Â´ r, bprqq ` 1
2âˆ†upt Â´ r, bprqq Â´ V pbprqqupt Â´ r, bprqq
*
exp
Ë†
Â´
Å¼ r
0
V pbpÏqqdÏ
Ë™
1tÏ„Ä…rudr
`
Å¼ s
0
âˆ‡upt Â´ r, bprqq exp
Ë†
Â´
Å¼ r
0
V pbpÏqqdÏ
Ë™
1tÏ„Ä…ru Â¨ dbprq
â€œ
Å¼ s
0
âˆ‡upt Â´ r, bprqq exp
Ë†
Â´
Å¼ r
0
V pbpÏqqdÏ
Ë™
1tÏ„Ä…ru Â¨ dbprq.
Here we used the fact that u is supposed to be a solution of our initial value
problem. It follows that the process tMpsq : 0 Ä s Ä tu is a martingale. Hence
we may conclude that
upt, xq â€œ ExrMp0qs â€œ Ex rMptqs
â€œ Ex
â€
up0, bptqq exp
Ë†
Â´
Å¼ t
0
V pbpÏqqdÏ
Ë™
: Ï„ Ä… t
È·
â€œ Ex
â€
fpbptqq exp
Ë†
Â´
Å¼ t
0
V pbpÏqqdÏ
Ë™
: Ï„ Ä… t
È·
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
182 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Example 4. (Cameron-Martin or Girsanov transformation). Let U be an open
subset of RÎ½, let f belong to C0pUq and let c : U Ã‘ RÎ½ be an appropriate vector
ï¬eld on U and let u : r0, 8q Ë† U Ã‘ R be a solution to the following problem:
$
&
%
Bu
Bt
â€œ 1
2âˆ†u ` c.âˆ‡u in r0, 8q Ë† U;
u
is continuous on r0, 8q Ë† U and up0, xq â€œ fpxq.
Moreover we want that limxÃ‘b,xPU upt, xq â€œ 0 if b belongs to BU. Then upt, xq â€œ
Ex pexp pZptqq fpbptqq : Ï„ Ä… tq, where Zptq â€œ
ÅŸt
0 cpbprqq Â¨ dbprq Â´ 1
2
ÅŸt
0 |cpbprqq|2 dr.
For a proof we ï¬x t Ä… 0 and we consider the process tMpsq : 0 Ä s Ä tu deï¬ned
by Mpsq â€œ upt Â´ s, bpsqq exp pZpsqq 1tÏ„Ä…su. An application of ItË†oâ€™s formula to
the function fps, x, yq â€œ upt Â´ s, xq exppyq will yield the following result
Mpsq Â´ Mp0q
â€œ
Å¼ s
0
Â´Bu
Bt pt Â´ r, bprqq exp pZprqq 1tÏ„Ä…rudr
`
Å¼ s
0
âˆ‡upt Â´ r, bprqq exp pZprqq 1tÏ„Ä…ru Â¨ dbprq
`
Å¼ s
0
upt Â´ r, bprqq exp pZprqq dZprq
` 1
2
Å¼ minps,Ï„q
0
âˆ†upt Â´ r, bprqq exp pZprqq 1tÏ„Ä…rudr
`
Î½Ã¿
jâ€œ1
Å¼ s
0
Djupt Â´ r, bprqq exp pZprqq 1tÏ„Ä…rud âŸ¨bj, ZâŸ©prq
` 1
2
Å¼ s
0
upt Â´ r, bprqq exp pZprqq 1tÏ„Ä…rud âŸ¨Z, ZâŸ©prq
â€œ
Å¼ s
0
"
Â´Bu
Bt pt Â´ r, bprqq ` 1
2âˆ†upt Â´ r, bprqq ` cpbprqq.âˆ‡upt Â´ r, bprqq
*
exp pZprqq 1tÏ„Ä…rudr
`
Å¼ s
0
tâˆ‡upt Â´ r, bprqq ` upt Â´ r, bprqqcpbprqqu exp pZprqq 1tÏ„Ä…ru Â¨ dbprq
Â´ 1
2
Å¼ s
0
upt Â´ r, bprqq exp pZprqq |cpbprqq|2 1tÏ„Ä…rudr
` 1
2
Å¼ s
0
upt Â´ r, bprqq exp pZprqq |cpbprqq|2 1tÏ„Ä…rudr
â€œ
Å¼ s
0
tâˆ‡upt Â´ r, bprqq ` upt Â´ r, bprqqcpbprqqu exp pZprqq 1tÏ„Ä…ru Â¨ dbprq.
As above it will follow that upt, xq â€œ Ex pexp pZptqq fpbptqq : Ï„ Ä… tq.
Example 5. (Stochastic diï¬€erential equation). Let pÏƒpxqqÎ½
j,kâ€œ1, x P RÎ½, be a
continuous square matrix valued function and let cpxq be a so-called drift vec-
tor ï¬eld (see the previous example). Suppose that the process tXxpsq : s Ä› 0u
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
183 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
satisï¬es the following (stochastic) integral equation:
Xxptq â€œ x `
Å¼ t
0
cpXxpsqqds `
Å¼ t
0
ÏƒpXxpsqq Â¨ dbpsq.
In other words the process tXxpsq : s Ä› 0u is a solution of the following stochas-
tic diï¬€erential equation:
dXxptq â€œ cpXxptqqdt ` ÏƒpXxptqq Â¨ dbptq
together with Xxp0q â€œ x. The integral
ÅŸt
0 ÏƒpXxpsqqdbpsq has the interpretation
Å¼ t
0
ÏƒpXxpsqqdbpsq â€œ
Ëœ Î½Ã¿
kâ€œ1
Å¼ t
0
ÏƒjkpXxpsqqdbkpsq
Â¸Î½
jâ€œ1
.
Next let u : r0, 8q Ë† RÎ½ Ã‘ R be a twice continuously diï¬€erentiable function.
Then, by ItË†oâ€™s lemma,
u pt Â´ s, Xxpsqq Â´ u pt, Xxp0qq
â€œ Â´
Å¼ s
0
Bu
Bt pt Â´ r, Xxprqq dr
`
Å¼ s
0
âˆ‡u pt Â´ r, Xxprqq Â¨ dXxprq
` 1
2
Î½Ã¿
j,kâ€œ1
Å¼ s
0
DjDku pt Â´ r, Xxprqq d
âŸ¨
Xx
j , Xx
k
âŸ©
prq.
Next we compute
d
âŸ¨
Xx
j , Xx
k
âŸ©
prq â€œ
Î½Ã¿
m,nâ€œ1
Ïƒjm
`
Xx
j mprq
Ë˜
Ïƒkn pXxprqq d âŸ¨bm, bnâŸ©prq
â€œ
Î½Ã¿
mâ€œ1
Ïƒjm pXxprqq Ïƒkm pXxprqq dr â€œ pÏƒ pXxprqq Ïƒ pXxprqqÏ„qjk dr,
where ÏƒpxqÏ„ is the transposed matrix of Ïƒpxq. Next we introduce the diï¬€erential
operator L as follows:
rLfs pxq â€œ 1
2
Î½Ã¿
j,kâ€œ1
pÏƒpxqÏƒpxqÏ„qjk DjDkfpxq `
Î½Ã¿
jâ€œ1
cjpxqDjfpxq.
For our twice continuously diï¬€erential function u we obtain:
u pt Â´ s, Xxpsqq Â´ u pt, Xxp0qq
â€œ Â´
Å¼ s
0
Bu
Bt pt Â´ r, Xxprqq dr
`
Î½Ã¿
jâ€œ1
Å¼ s
0
cj pXxprqq Dju pt Â´ r, Xxprqq dr
`
Å¼ s
0
âˆ‡u pt Â´ r, Xxprqq Ïƒ pXxprqq Â¨ dbprq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
184 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
` 1
2
Î½Ã¿
j,kâ€œ1
Å¼ s
0
pÏƒ pXxprqq Ïƒ pXxprqqÏ„qj,k DjDku pt Â´ r, Xxprqq dr
â€œ
Å¼ s
0
âˆ‡u pt Â´ r, Xxprqq Ïƒ pXxprqq Â¨ dbprq `
Å¼ s
0
Ë†
L Â´ B
Bt
Ë™
u pt Â´ r, Xxprqq dr.
So that, if
Ë†
L Â´ B
Bt
Ë™
u â€ 0, then, for 0 Ä s Ä t,
u pt Â´ s, Xxpsqq Â´ u pt, Xxp0qq â€œ
Å¼ s
0
âˆ‡u pt Â´ r, Xxprqq Ïƒ pXxprqq dbprq,
and hence, the process Mpsq :â€œ u pt Â´ s, Xxpsqq is a martingale on the interval
r0, ts. It follows that
upt, xq â€œ EpMp0qq â€œ EpMptqq â€œ E pu p0, Xxptqqq â€œ E pf pXxptqqq
where up0, xq â€œ fpxq. For more details on stochastic diï¬€erential equations see
Chapter 4.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
185 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Example 6. (Quantum mechanical magnetic ï¬eld). Let âƒ—a be an appropriate
vector ï¬eld on RÎ½ and let Hpâƒ—a, V q â€œ 1
2 piâˆ‡` âƒ—aq2 ` V be the (quantum mechan-
ical) Hamiltonian of a particle under the inï¬‚uence of the scalar potential V in
a magnetic ï¬eld âƒ—Bpxq with vector potential âƒ—apxq: i.e. âƒ—B â€œ âˆ‡Ë† âƒ—a. Let f be a
function in C0 pRÎ½q and let u : r0, 8q Ë† RÎ½ Ã‘ R be a solution to the following
problem:
$
&
%
Bu
Bt
â€œ Â´Hpâƒ—a, V qu in r0, 8q Ë† RÎ½;
u
is continuous on r0, 8q Ë† RÎ½ and up0, xq â€œ fpxq.
Moreover we want that lim
xÃ‘8 upt, xq â€œ 0. Then upt, xq â€œ Ex
â€œ
eZptqfpbptqq
â€°
, where
Zptq â€œ Â´i
Å¼ t
0
âƒ—apbpsqq Â¨ dbpsq Â´ 1
2i
Å¼ t
0
âˆ‡Â¨ âƒ—apbpsqqds Â´
Å¼ t
0
V pbpsqqds
with âˆ‡Â¨ âƒ—a â€œ
Î½Ã¿
jâ€œ1
Baj
Bxj
. Put Mpsq â€œ upt Â´ s, bpsqq exp pZpsqq, 0 Äƒ s Äƒ t. An
application of ItË†oâ€™s formula to the function fps, x, yq â€œ upt Â´ s, xq exppyq will
yield the following result
Mpsq Â´ Mp0q â€œ fps, bpsq, Zpsqq Â´ fp0, bp0q, Zp0qq
â€œ
Å¼ s
0
Bf
Bs pÏƒ, bpÏƒq, ZpÏƒqq dÏƒ `
Å¼ s
0
âˆ‡xfpÏƒ, bpÏƒq, ZpÏƒqq Â¨ dbpÏƒq
`
Å¼ s
0
Bf
By pÏƒ, bpÏƒq, ZpÏƒqq Â¨ dZpÏƒq ` 1
2
Å¼ s
0
âˆ†xfpÏƒ, bpÏƒq, ZpÏƒqqdÏƒ
` 1
2
Î½Ã¿
jâ€œ1
Å¼ s
0
B2
ByBxj
fpÏƒ, bpÏƒq, ZpÏƒqqd âŸ¨Z, bjâŸ©pÏƒq
` 1
2
Î½Ã¿
jâ€œ1
Å¼ s
0
B2f
BxjBypÏƒ, bpÏƒq, ZpÏƒqq d âŸ¨bj, ZâŸ©pÏƒq
` 1
2
Å¼ s
0
B2f
By2 pÏƒ, bpÏƒq, ZpÏƒqqd âŸ¨Z, ZâŸ©pÏƒq
â€œ
Å¼ s
0
Bf
Bs pÏƒ, bpÏƒq, ZpÏƒqq dÏƒ `
Å¼ s
0
âˆ‡xfpÏƒ, bpÏƒq, ZpÏƒqq Â¨ dbpÏƒq
`
Å¼ s
0
fpÏƒ, bpÏƒq, ZpÏƒqq Â¨ dZpÏƒq ` 1
2
Å¼ s
0
âˆ†xfpÏƒ, bpÏƒq, ZpÏƒqqdÏƒ
Â´ i
Î½Ã¿
jâ€œ1
Å¼ s
0
Bf
Bxj
pÏƒ, bpÏƒq, ZpÏƒqqajpb
`
Ïƒq
Ë˜
dÏƒ
` 1
2
Å¼ s
0
fpÏƒ, bpÏƒq, ZpÏƒqq
Î½Ã¿
jâ€œ1
aj pbpÏƒqq2 dÏƒ
â€œ Â´
Å¼ s
0
Bu
Bt pt Â´ Ïƒ, bpÏƒqq eZpÏƒqdÏƒ `
Å¼ s
0
âˆ‡xu pt Â´ Ïƒ, bpÏƒqq eZpÏƒq Â¨ dbpÏƒq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
186 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
`
Å¼ s
0
u pt Â´ Ïƒ, bpÏƒqq eZpÏƒq Â¨ dZpÏƒq ` 1
2
Å¼ s
0
âˆ†xu pt Â´ Ïƒ, bpÏƒqq eZpÏƒqdÏƒ
Â´ i
Î½Ã¿
jâ€œ1
Å¼ s
0
Bu
Bxj
pt Â´ Ïƒ, bpÏƒqq eZpÏƒqajpbpÏƒqdÏƒ
` 1
2
Å¼ s
0
u pt Â´ Ïƒ, bpÏƒqq eZpÏƒq
Î½Ã¿
jâ€œ1
aj pbpÏƒqq2 dÏƒ
â€œ
Å¼ s
0
"
Â´Bu
Bt ` 1
2âˆ†xu Â´ iâƒ—apbpÏƒqq.âˆ‡xu Â´ 1
2 |âƒ—apbpÏƒqq|2 u
Â´1
2iâˆ‡Â¨ âƒ—apbpÏƒqqu Â´ V pbpÏƒqqu
*
pt Â´ Ïƒ, bpÏƒqq eZpÏƒqdÏƒ
`
Å¼ s
0
âˆ‡xu pt Â´ Ïƒ, bpÏƒqq eZpÏƒq Â¨ dbpÏƒq Â´ i
Å¼ s
0
u pt Â´ Ïƒ, bpÏƒqq eZpÏƒqâƒ—apbpÏƒqq Â¨ dbpÏƒq
â€œ
Å¼ s
0
"
Â´ B
Bt Â´ 1
2 piâˆ‡` âƒ—aq2 Â´ V
*
u pt Â´ Ïƒ, bpÏƒqq eZpÏƒqdÏƒ
`
Å¼ s
0
âˆ‡xu pt Â´ Ïƒ, bpÏƒqq eZpÏƒq Â¨ dbpÏƒq Â´ i
Å¼ s
0
u pt Â´ Ïƒ, bpÏƒqq eZpÏƒqâƒ—apbpÏƒqq Â¨ dbpÏƒq
â€œ
Å¼ s
0
âˆ‡xu pt Â´ Ïƒ, bpÏƒqq eZpÏƒq Â¨ dbpÏƒq Â´ i
Å¼ s
0
u pt Â´ Ïƒ, bpÏƒqq eZpÏƒqâƒ—apbpÏƒqq Â¨ dbpÏƒq.
Here we used the fact that the function u satisï¬es the diï¬€erential equation. The
claim in the beginning of the example then follows as in Example 4.
Example 7. A geometric Brownian motion (GBM) (occasionally called expo-
nential Brownian motion) is a continuous-time stochastic process in which the
logarithm of the randomly varying quantity follows a Brownian motion, also
called a Wiener process: see e.g. Ross [116] Section 10.3.2. It is applicable
to mathematical modelling of some phenomena in ï¬nancial markets. It is used
particularly in the ï¬eld of option pricing because a quantity that follows a GBM
may take any positive value, and only the fractional changes of the random vari-
ate are signiï¬cant. This is a reasonable approximation of stock price dynamics
except for rare events.
A stochastic process St is said to follow a GBM if it satisï¬es the following
stochastic diï¬€erential equation:
dSptq â€œ ÂµSptq dt ` ÏƒSptq dWptq
where Wptq is a Wiener process or Brownian motion and Âµ (â€œthe percentage
driftâ€ or â€œdrift rateâ€) and Ïƒ (â€œthe (percentage or ratio) volatilityâ€) are constants.
For an arbitrary initial value Sp0q the equation has the analytic solution
Sptq â€œ Sp0q exp
Ë†Ë†
Âµ Â´ Ïƒ2
2
Ë™
t ` ÏƒWptq
Ë™
,
which is a log-normally distributed random variable with expected value given
by ErSptqs â€œ eÂµtSp0q and variance by VarpSptqq â€œ e2ÂµtSp0q2 Â´
eÏƒ2t Â´ 1
Â¯
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
187 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The correctness of the solution can be veriï¬ed using ItË†oâ€™s lemma. The random
variable log
Ë† Sptq
Sp0q
Ë™
is normally distributed with mean
`
Âµ Â´ 1
2Ïƒ2Ë˜
t and variance
Ïƒ2t, which reï¬‚ects the fact that increments of a GBM are normal relative to the
current price, which is why the process has the name â€œgeometricâ€.
Example 8. The term Black-Scholes refers to three closely related concepts:
1. The Black-Scholes model is a mathematical model of the market for an
equity, in which the equityâ€™s price is a stochastic process.
2. The Black-Scholes PDE is a partial diï¬€erential equation which (in the
model) must be satisï¬ed by the price of a derivative on the equity.
3. The Black-Scholes formula is the result obtained by solving the Black-
Scholes PDE for a European call option.
Fischer Black and Myron Scholes ï¬rst articulated the Black-Scholes formula in
their 1973 paper, â€œThe Pricing of Options and Corporate Liabilities.â€: see [19].
The foundation for their research relied on work developed by scholars such
as Jack L. Treynor, Paul Samuelson, A. James Boness, Sheen T. Kassouf, and
Edward O. Thorp. The fundamental insight of Black-Scholes is that the option
is implicitly priced if the stock is traded.
Robert C. Merton was the ï¬rst to publish a paper expanding the mathematical
understanding of the options pricing model and coined the term â€œBlack-Scholesâ€
options pricing model.
Merton and Scholes received the 1997 The Sveriges Riksbank Prize in Economic
Sciences in Memory of Alfred Nobel for this and related work. Though ineligible
for the prize because of his death in 1995, Black was mentioned as a contributor
by the Swedish academy.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
188 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
7. Black-Scholes model
The text in this section is taken from Wikipedia (English version). The Black-
Scholes model of the market for a particular equity makes the following explicit
assumptions:
1. It is possible to borrow and lend cash at a known constant risk-free
interest rate.
2. The price follows a geometric Brownian motion with constant drift and
volatility.
3. There are no transaction costs.
4. The stock does not pay a dividend (see below for extensions to handle
dividend payments).
5. All securities are perfectly divisible (i.e. it is possible to buy any frac-
tion of a share).
6. There are no restrictions on short selling.
7. There is no arbitrage opportunity.
From these ideal conditions in the market for an equity (and for an option on
the equity), the authors show that it is possible to create a hedged position,
consisting of a long position in the stock and a short position in [calls on the
same stock], whose value will not depend on the price of the stock.
Notation. We deï¬ne the following quantities:
- S, the price of the stock (please note as below).
- V pS, tq, the price of a ï¬nancial derivative as a function of time and
stock price.
- CpS, tq the price of a European call and PpS, tq the price of a European
put option.
- K, the strike of the option.
- r, the annualized risk-free interest rate, continuously compounded.
- Âµ, the drift rate of S, annualized.
- Ïƒ, the volatility of the stock; this is the square root of the quadratic
variation of the stockâ€™s log price process.
- t a time in years; we generally use now â€œ 0, expiry â€œ T.
- Î , the value of a portfolio.
- R, the accumulated proï¬t or loss following a delta-hedging trading
strategy.
- Npxq denotes the standard normal cumulative distribution function,
Npxq â€œ
1
?
2Ï€
Å¼ x
Â´8
eÂ´ 1
2 z2 dz.
- N 1pxq â€œ
1
?
2Ï€eÂ´ 1
2 x2 denotes the standard normal probability density
function.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
189 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Black-Scholes PDE. Simulated Geometric Brownian Motions with Parameters
from Market Data
In the model as described above, we assume that the underlying asset (typically
the stock) follows a geometric Brownian motion. That is,
dSptq â€œ ÂµSptq dt ` ÏƒSptq dWptq,
where Wptq is a Brownian motion; the dW term here stands in for any and all
sources of uncertainty in the price history of a stock.
The payoï¬€of an option V pS, Tq at maturity is known. To ï¬nd its value at an
earlier time we need to know how V evolves as a function of S and T. By ItË†oâ€™s
lemma for two variables we have
dV pSptq, tq â€œ BV pSptq, tq
BS
dSptq ` BV pSptq, tq
Bt
dt ` 1
2
B2V pSptq, tq
B2S
d xS, Sy ptq
â€œ
Ë†
ÂµSptqBV pSptq, tq
BS
` BV pSptq, tq
Bt
` 1
2Ïƒ2Sptq2B2V pSptq, tq
BS2
Ë™
dt
` ÏƒSptqBV pSptq, tq
BS
dWptq.
(3.208)
Now consider a trading strategy under which one holds aptq units of a single
option with value Sptq and bptq units of a bond with value Î²ptq at time t. The
value V pSptq, tq of the portfolio of the trading strategy paptq, bptqq is then given
by
V pSptq, tq â€œ aptqSptq ` bptqÎ²ptq.
(3.209)
Observe that (3.209) is equivalent to
bptq â€œ V pSptq, tq Â´ aptqSptq
Î²ptq
.
In addition, aptq â€œ BV pSptq, tq
Bs
, which is called the delta hedging rule. Assum-
ing, like in the Black-Sholes model, that the strategy paptq, bptqq is self-ï¬nancing,
which by deï¬nition implies
dV pSptq, tq â€œ aptq dSptq ` bptq dÎ²ptq,
(3.210)
we get
dV ptq â€œ ÂµaptqSptq dt ` bptq dÎ²ptq ` ÏƒaptqSptq dWptq.
(3.211)
Assume that the process t ÃÃ‘ Î²ptq, i.e., the bond price, is of bounded varia-
tion. By equating the terms with dWptq in (3.208) and (3.211) we see aptq â€œ
BV pSptq, tq
BS
.
From this and again equating the other terms in (3.208) and
(3.211) and using (3.209) we also obtain
Ë†BV pSptq, tq
Bt
` 1
2Ïƒ2Sptq2B2V pSptq, tq
BS2
Ë™
dt
â€œ bptq dÎ²ptq â€œ
Ë†
V pSptq, tq Â´ SptqBV pSptq, tq
Bs
Ë™ dÎ²ptq
Î²ptq .
(3.212)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
190 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
If the interest rate for the bond is constant, i.e., if dÎ²ptq â€œ rÎ²ptq dt, or, what
amounts to the same, Î²ptq â€œ Î²p0qert, then from (3.212) it also follows that
BV pSptq, tq
Bt
` 1
2Ïƒ2Sptq2B2V pSptq, tq
BS2
â€œ r
Ë†
V pSptq, tq Â´ SptqBV pSptq, tq
Bs
Ë™
.
(3.213)
If we trade in a single option continuously trades in the stock in order to hold
Â´BV
BS shares, then at time t, the value of these holdings will be
Î ptq â€œ V pSptq, tq Â´ SptqBV pSptq, tq
BS
.
The composition of this portfolio, called the delta-hedge portfolio, will vary from
time-step to time-step. Let Rptq denote the accumulated proï¬t or loss from
following this strategy. Then over the time period rt, t ` dts, the instantaneous
proï¬t or loss is
dRptq â€œ dV pSptq, tq Â´ BV pSptq, tq
BS
dSptq.
By substituting in the equations above we get
dRptq â€œ
Ë†BV pSptq, tq
Bt
` 1
2Ïƒ2S2B2V pSptq, tq
BS2
Ë™
dt.
This equation contains no dWptq term. That is, it is entirely risk free (delta
neutral). Black, Scholes and Merton reason that under their ideal conditions,
the rate of return on this portfolio must be equal at all times to the rate of return
on any other risk free instrument; otherwise, there would be opportunities for
arbitrage. Now assuming the risk free rate of return is r we must have over the
time period rt, t ` dts (Black-Scholes assumption):
rÎ ptq dt â€œ dRptq â€œ
Ë†BV pSptq, tq
Bt
` 1
2Ïƒ2S2B2V pSptq, tq
BS2
Ë™
dt.
Observe that the Black-Sholes assumption comes down to the assumption of
self-ï¬nancing, because the results If we now substitute in for Î ptq and divide
through by dt we obtain the Black-Scholes PDE:
BV pSptq, tq
Bt
` 1
2Ïƒ2S2B2V pSptq, tq
BS2
` rS BV pSptq, tq
BS
Â´ rV pSptq, tq â€œ 0. (3.214)
Observe that the Black-Sholes assumption comes down to the assumption of
self-ï¬nancing, because the resulting partial diï¬€erential equation in (3.213) and
(3.214) is the same. With the assumptions of the Black-Scholes model, this
partial diï¬€erential equation holds whenever V is twice diï¬€erentiable with respect
to S and once with respect to t. Above we used the method of arbitrage-free
pricing (â€œdelta-hedgingâ€) to derive some PDE governing option prices given the
Black-Scholes model. It is also possible to use a risk-neutrality argument. This
latter method gives the price as the expectation of the option payoï¬€under a
particular probability measure, called the risk-neutral measure, which diï¬€ers
from the real world measure.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
191 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Black-Scholes formula. The Black-Scholes formula is used for obtaining the price
of European put and call options. It is obtained by solving the Black-Scholes
PDE as discussed - see derivation below.
The value of a call option in terms of the Black-Scholes parameters is given by:
CpS, tq â€œ C pSptq, tq â€œ SptqNpd1q Â´ KeÂ´rpTÂ´tqNpd2q with
(3.215)
d1 â€œ
logp S
Kq `
Â´
r ` Ïƒ2
2
Â¯
pT Â´ tq
Ïƒ
?
T Â´ t
and
d2 â€œ d1 Â´ Ïƒ
?
T Â´ t.
(3.216)
The price of a put option is:
PpS, tq â€œ P pSptq, tq â€œ KeÂ´rpTÂ´tqNpÂ´d2q Â´ SptqNpÂ´d1q.
(3.217)
For both, as above:
1. NpÂ¨q is the standard normal or cumulative distribution function.
2. T Â´ t is the time to maturity.
3. S â€œ Sptq is the spot price of the underlying asset at time t.
4. K is the strike price.
5. r is the risk free interest rate (annual rate, expressed in terms of con-
tinuous compounding).
6. Ïƒ is the volatility in the log-returns of the underlying asset.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENTâ€¦
     RUN FASTER.
          RUN LONGER..
                RUN EASIERâ€¦
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Advanced stochastic processes: Part I
192 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Interpretation. The quantities N pd1q and N pd2q are the probabilities of the
option expiring in-the-money under the equivalent exponential martingale prob-
ability measure (numÂ´eraire = stock) and the equivalent martingale probability
measure (numÂ´eraire = risk free asset), respectively. The equivalent martingale
probability measure is also called the risk-neutral probability measure. Note
that both of these are probabilities in a measure theoretic sense, and neither of
these is the true probability of expiring in-the-money under the real probability
measure.
Derivation. We now show how to get from the general Black-Scholes PDE to
a speciï¬c valuation for an option. Consider as an example the Black-Scholes
price of a call option, for which the PDE above has boundary conditions
Cp0, tq â€œ 0 for all t
CpS, tq Ã‘ S as S Ã‘ 8
CpS, Tq â€œ maxpS Â´ K, 0q.
The last condition gives the value of the option at the time that the option
matures. The solution of the PDE gives the value of the option at any earlier
time, E rmaxpS Â´ K, 0qs. In order to solve the PDE we transform the equation
into a diï¬€usion equation which may be solved using standard methods. To this
end we introduce the change-of-variable transformation
Ï„ â€œ T Â´ t,
upx, Ï„q â€œ C
Â´
KexÂ´prÂ´ 1
2 Ïƒ2qÏ„, T Â´ Ï„
Â¯
erÏ„, and x â€œ log S
K `pr Â´ Ïƒ2
2 qÏ„.
Note: in fact in case we consider a call option we replace V pSptq, tq with
C pSptq, tq. Instead of u we may also consider
vpx, tq â€œ V
Â´
KexÂ´prÂ´ 1
2 Ïƒ2qpTÂ´tq, t
Â¯
erpTÂ´tq.
In case we consider a European call option we take as ï¬nal value for v: vpx, Tq â€œ
V pKex, Tq â€œ C pKex, Tq â€œ max pKex Â´ K, 0q â€œ K max pex Â´ 1, 0q. Then the
Black-Scholes PDE becomes a diï¬€usion equation
Bu
BÏ„ â€œ 1
2Ïƒ2B2u
Bx2.
The terminal condition CpS, Tq â€œ maxpS Â´ K, 0q now becomes an initial con-
dition
upx, 0q â€œ u0pxq â€ K max pex Â´ 1, 0q .
Using the standard method for solving a diï¬€usion equation we have
upx, Ï„q â€œ
1
Ïƒ
?
2Ï€Ï„
Å¼ 8
Â´8
u0pyqeÂ´pxÂ´yq2{p2Ïƒ2Ï„q dy.
After some calculations we obtain
upx, Ï„q â€œ Kex`Ïƒ2Ï„{2N pd1q Â´ KN pd2q
where
d1 â€œ x ` Ïƒ2Ï„
Ïƒ?Ï„
and d2 â€œ
x
Ïƒ?Ï„ .
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
193 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Substituting for u, x, and Ï„, we obtain the value of a call option in terms of the
Black-Scholes parameters is given by
CpS, tq â€œ SNpd1q Â´ KeÂ´rpTÂ´tqNpd2q,
where d1 and d2 are as in (3.216). The price of a put option may be computed
from this by the put-call parity and simpliï¬es to
PpS, tq â€œ KeÂ´rpTÂ´tqNpÂ´d2q Â´ SNpÂ´d1q.
Risk neutral measure. Suppose our economy consists of 2 assets, a stock and
a risk-free bond, and that we use the Black-Scholes model. In the model the
evolution of the stock price can be described by Geometric Brownian Motion:
dSptq â€œ ÂµSptq dt ` ÏƒSptq dWptq
where Wptq is a standard Brownian motion with respect to the physical measure.
If we deï¬ne
Ä‚
Wptq â€œ Wptq ` Âµ Â´ r
Ïƒ
t,
Girsanovâ€™s theorem states that there exists a measure Q under which Ä‚
Wptq is a
standard Brownian motion, i.e., a Brownian motion without a drift term and
such that EQ
â€
Ä‚
Wptq2Ä±
â€œ t. For a more thorough discussion on the Girsanovâ€™s
theorem, which is in fact (much) more general, see assertion (4) in Proposition
4.24 in Chapter 4 Section 3. The quantity Âµ Â´ r
Ïƒ
is known as the market price
of risk. Diï¬€erentiating and rearranging yields:
dWptq â€œ dÄ‚
Wptq Â´ Âµ Â´ r
Ïƒ
dt.
Put this back in the original equation:
dSptq â€œ rSptq dt ` ÏƒSptq dÄ‚
Wptq.
The probability Q is the unique risk-neutral measure for the model. The (dis-
counted) payoï¬€process of a derivative on the stock Hptq â€œ EQ
`
HpTq
Ë‡Ë‡ Ft
Ë˜
is
a martingale under Q. Since S and H are Q-martingales we can invoke the
martingale representation theorem to ï¬nd a replicating strategy â€“ a holding of
stocks and bonds that pays oï¬€Hptq at all times t Ä T. The measure Q is given
by QpAq â€œ E
â€œ
eÂ´ZpTq1A
â€°
, A P FT, where
Zptq â€œ 1
2
Â´Âµ Â´ r
Ïƒ
Â¯2
t ` Âµ Â´ r
Ïƒ
Wptq.
In fact a more general result is true. Let s ÃÃ‘ hpsq be a predictable process such
that E
â€
exp
Ë†1
2
Å¼ T
0
|hpsq|2 ds
Ë™È·
Äƒ 8. Put
Zhptq â€œ
Å¼ t
0
hpsqdWpsq ` 1
2
Å¼ t
0
|hpsq|2 ds.
Deï¬ne the measure Qh by QhpAq â€œ E
â€œ
eÂ´ZhpTq1A
â€°
, A P FT.
Put Whptq â€œ
Wptq `
ÅŸt
0 hpsq ds. Then the process Wh is a Brownian motion relative to the
measure Qh. The proof of this result uses LÂ´evyâ€™s characterization of Brownian
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
194 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
motion: see Corollary 4.7. It says that a process Wh is a Qh-Brownian motion
if and only if the following two conditions are satisï¬ed:
(1) The quadratic variation of Wh satisï¬es âŸ¨Wh, WhâŸ©ptq â€œ t.
(2) The process Wh is a local martingale relative to the measure Qh.
(For a proof of this result see Theorem 4.5.) In our case we have âŸ¨Wh, WhâŸ©ptq â€œ
âŸ¨W, WâŸ©ptq â€œ t, and so (1) is satisï¬ed. In order to establish (2) we use ItË†o
calculus to obtain:
eÂ´ZhptqWhptq â€œ
Å¼ t
0
eÂ´ZhpsqdWpsq Â´
Å¼ t
0
eÂ´ZhpsqWhpsqhpsq dWpsq.
Since the process t ÃÃ‘ eÂ´Zhptq is a martingale we see that the process Wh is a
local Qh-martingale.
We like to spend more time on the Black-Sholes model and the corresponding
risk-neutral measure. Again we have trading strategy paptq, bptqq of a ï¬nancial
asset and a bond. Its portfolio value V ptq :â€œ V pSptq, tq is given by V ptq â€œ
aptqSptq ` bptqÎ²ptq.
Here Sptq is the price of the option at time t and Î²ptq
is the price of the bond at time t. It is assumed that the process t ÃÃ‘ Sptq
follows a geometric Brownian motion: dSptq â€œ ÂµSptq dt`ÏƒSptq dWptq, or Sptq â€œ
Sp0qeÏƒWptq`pÂµÂ´ 1
2 Ïƒ2qt. Let rSptq be the discounted price of the option, i.e.,
rSptq â€œ Î²p0q
Î²ptq Sptq.
(3.218)
Put Ä‚
Wptq â€œ Wptq `
ÅŸt
0 qpsq ds, where
qpsq â€œ 1
Ïƒ
Ë†
Âµ Â´ Î²1psq
Î²psq
Ë™
.
Then the process rSptq satisï¬es the equation
drSptq â€œ ÏƒÎ²p0q
Î²ptq Sptq d
Ë† 1
Ïƒ
Å¼ t
0
Ë†
Âµ Â´ Î²1psq
Î²psq
Ë™
ds ` Wptq
Ë™
â€œ Ïƒ rSptq dÄ‚
Wptq. (3.219)
Put Zqptq â€œ
Å¼ t
0
qpsq dWpsq ` 1
2
Å¼ t
0
qpsq2 ds. By Girsanovâ€™s theorem the process
t ÃÃ‘ Ä‚
Wptq is a (standard) Brownian motion under the measure Qq given by
QqpAq â€œ E
â€œ
eÂ´ZqpTq1A
â€°
, A P FT. The solution rSptq of the SDE in (3.219) can
be written in the form
rSptq â€œ rSp0qeÏƒÄ‚
WptqÂ´ 1
2 Ïƒ2t.
(3.220)
Assume that the portfolio is self-ï¬nancing we will show that
V ptq â€œ EQq
â€ Î²ptq
Î²pTqh pSpTqq
Ë‡Ë‡ Ft
È·
,
t P r0, Ts,
(3.221)
where V pTq is equal to the contingent claim h pSpTqq at the time of maturity
T. Of course, EQq â€œ
F
Ë‡Ë‡ Ft
â€°
denotes the conditional expectation of F relative
Qq, given the Ïƒ-ï¬eld Ft â€œ Ïƒ pWpsq : s Ä tq of the variable F P L1 pâ„¦, FT, Qqq
with respect to the probability measure Qq. Another application of ItË†oâ€™s lemma
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
195 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
together with the deï¬nition of rSptq, Ä‚
Wptq and rV ptq â€œ Î²p0q
Î²ptq V ptq shows the
following result
drV ptq â€œ Â´Î²p0qÎ²1ptq
Î²ptq2
V ptq dt ` Î²p0q
Î²ptq dV ptq
(the hedging strategy paptq, bptqq is self-ï¬nancing)
â€œ Â´Î²p0qÎ²1ptq
Î²ptq2
V ptq dt ` Î²p0q
Î²ptq paptq dSptq ` bptqdÎ²ptqq
(employ the equation for the option price Sptq)
â€œ Â´Î²p0qÎ²1ptq
Î²ptq2
V ptq dt ` Î²p0q
Î²ptq Sptq
Ë†
Âµaptq dt ` bptqÎ²1ptq
Î²ptq dt ` ÏƒdWptq
Ë™
â€œ Â´Î²p0qÎ²1ptq
Î²ptq2
paptqSptq ` bptqÎ²ptqq dt
` Î²p0q
Î²ptq Sptq
Ë†
Âµaptq dt ` bptqÎ²1ptq
Î²ptq dt ` ÏƒdWptq
Ë™
â€œ ÏƒaptqÎ²p0q
Î²ptq Sptq d
" 1
Ïƒ
Å¼ t
0
Ë†
Âµ Â´ Î²1psq
Î²psq
Ë™
ds ` Wptq
*
â€œ ÏƒaptqrSptq dÄ‚
Wptq.
(3.222)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Advanced stochastic processes: Part I
196 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In fact the equality in (3.222) could also have been obtained by observing that
drV ptq â€œ aptq drSptq,
and drSptq â€œ ÏƒdÄ‚
Wptq.
(3.223)
From (3.222) we infer
rV ptq â€œ rV p0q ` Ïƒ
Å¼ t
0
apsq dÄ‚
Wpsq,
(3.224)
and hence, the process t ÃÃ‘ rV ptq is a martingale with respect to the measure
Qq. So from (3.224) we get
Î²p0q
Î²ptq V ptq â€œ rV ptq â€œ EQq â€
rV pTq
Ë‡Ë‡ Ft
Ä±
â€œ EQq
â€ Î²p0q
Î²pTqV pTq
Ë‡Ë‡ Ft
È·
,
(3.225)
and hence
V ptq â€œ EQq
â€ Î²ptq
Î²pTqV pTq
Ë‡Ë‡ Ft
È·
â€œ EQq
â€ Î²ptq
Î²pTqh pSpTqq
Ë‡Ë‡ Ft
È·
.
(3.226)
In addition, we observe that
SptqÎ²pTq
Î²ptq eÂ´ 1
2 Ïƒ2pTÂ´tq`ÏƒpÄ‚
WpTqÂ´Ä‚
Wptqq
â€œ Sptq exp
Ë†Å¼ T
t
Ë†Î²1psq
Î²psq Â´ 1
2Ïƒ2
Ë™
ds ` Ïƒ
Â´
Ä‚
WpTq Â´ Ä‚
Wptq
Â¯Ë™
â€œ Sp0q exp
Ë†
ÏƒWptq `
Ë†
Âµ Â´ 1
2Ïƒ2
Ë™
t
Ë™
Ë† exp
Ë†Å¼ T
t
Ë†Î²1psq
Î²psq Â´ 1
2Ïƒ2
Ë™
ds ` Ïƒ
Ë†
WpTq Â´ Wptq `
Å¼ T
t
qpsq ds
Ë™Ë™
â€œ Sp0qepÂµÂ´ 1
2Ïƒ2qT`ÏƒWpTq â€œ SpTq.
(3.227)
Inserting the equality for SpTq from (3.227) into (3.226) yields
V ptq â€œ EQq
â€ Î²ptq
Î²pTqh
Ë†
SptqÎ²pTq
Î²ptq eÂ´ 1
2 Ïƒ2pTÂ´tq`ÏƒpÄ‚
WpTqÂ´Ä‚
Wptqq
Ë™ Ë‡Ë‡ Ft
È·
.
(3.228)
Since the variable Sptq is measurable with respect to Ft, Since process t ÃÃ‘ Ä‚
Wptq
is a Qq-Brownian motion, the variable Ä‚
WpTq Â´ Ä‚
Wptq and the Ïƒ-ï¬eld Ft are Qq-
independent.
Moreover, the process t ÃÃ‘ Î²ptq is supposed to deterministic.
Hence, since the variable Sptq is measurable with respect to Ft, we deduce that
V ptq â€œ V pSptq, tq
â€œ
1
?
2Ï€
Å¼ 8
Â´8
Î²ptq
Î²pTqh
Ë†
xÎ²pTq
Î²ptq eÂ´ 1
2 Ïƒ2pTÂ´tq`Ïƒ
?
TÂ´ty
Ë™
eÂ´ 1
2 y2 dy
Ë‡Ë‡
xâ€œSptq . (3.229)
Hence if the pay-oï¬€, i.e. the value of the call option at expiry (time of maturity
T), is given by h pSpTqq â€œ max tSpTq Â´ K, 0u, then the value of the portfolio
at time t Ä T is given by the formula in (3.229). If Î²ptq â€œ Î²p0qert, then this
integral can be rewritten as in (3.215) with C pS, tq â€œ C pSptq, tq â€œ V pSptq, tq â€œ
V ptq. Similarly, if h pSpTqq â€œ max tK Â´ SpTq, 0u, then P pS, tq â€œ P pSptq, tq â€œ
V pSptq, tq â€œ V ptq is the price of a European put option: see the somewhat
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
197 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
more explicit expression in (3.217). For a modern treatment of several stock
price models see, e.g., Gulisashvili [60].
8. An Ornstein-Uhlenbeck process in higher dimensions
Part of this text is taken from [146]. Let C pt, sq, t Ä› s, t, s P R, be a family of
d Ë† d matrices with real entries, with the following properties:
(a) Cpt, tq â€œ I, t P R, (I stands for the identity matrix).
(b) The following identity holds: Cpt, sqCps, Ï„q â€œ Cpt, Ï„q holds for all real
numbers t, s, Ï„ for which t Ä› s Ä› Ï„.
(c) The matrix valued function pt, s, xq ÃÃ‘ Cpt, sqx is continuous as a func-
tion from the set
â£
pt, sq P Rd Ë† Rd : t Ä› s
(
Ë† Rd to Rd.
Deï¬ne the backward propagator YC on Cb
`
RdË˜
by YCps, tqfpxq â€œ f pCpt, sqxq,
x P Rd, s Ä t, and f P Cb
`
RdË˜
. Then YC is a backward propagator on the space
Cb
`
RdË˜
, which is Ïƒ
`
Cb
`
RdË˜
, M
`
RdË˜Ë˜
-continuous. Here the symbol M
`
RdË˜
stands for the vector space of all signed measures on Rd. The operator family
tYCps, tq : s Ä tu satisï¬es YC ps1, s2q YC ps2, s3q â€œ YC ps1, s3q, s1 Ä s2 Ä s3.
Let Wptq be standard m-dimensional Brownian motion on pâ„¦, Ft, Pq and let
ÏƒpÏq be a deterministic continuous function which takes its values in the space
of d Ë† m-matrices. Put QpÏq â€œ ÏƒpÏqÏƒpÏqËš. Another interesting example is the
following:
YC,Q ps, tq fpxq
â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f
Ëœ
Cpt, sqx `
Ë†Å¼ t
s
Cpt, ÏqQpÏqCpt, ÏqËšdÏ
Ë™1{2
y
Â¸
dy
â€œ E
â€
f
Ë†
Cpt, sqx `
Å¼ t
s
Cpt, ÏqÏƒpÏq dWpÏq
Ë™È·
,
(3.230)
where QpÏq â€œ ÏƒpÏqÏƒpÏqËš is a positive-deï¬nite d Ë† d matrix. Then the propaga-
tors YC,Q and YC,S are backward propagators on Cb
`
RdË˜
. We will prove this.
The equality of the expressions in (3.230) is a consequence of the following ar-
guments. Let the variable Î¾ P Rd have the standard normal distribution. Fix
t Ä› Ï„. Both variables
XÏ„,xptq :â€œ C pt, Ï„q x `
Å¼ t
Ï„
C pt, Ïq ÏƒpÏqdWpÏq,
t Ä› Ï„, and
Cpt, Ï„qx `
Ë†Å¼ t
Ï„
Cpt, ÏqQpÏqCpt, ÏqËšdÏ
Ë™1{2
Î¾,
t Ä› Ï„,
(3.231)
are Rd-valued Gaussian vectors. A calculation shows that they have the same
expectation and the same covariance matrix with entries given by (3.242) below
with s â€œ t.
Next suppose that the forward propagator C on Rd consists of contractive op-
erators, i.e. Cpt, sqCpt, sqËš Ä I (this inequality is to be taken in matrix sense).
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
198 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Choose a family S pt, sq of square d Ë† d-matrices such that Cpt, sqCpt, sqËš `
S pt, sq S pt, sqËš â€œ I, and put
YC,S ps, tq fpxq â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f pCpt, sqx ` Spt, sqyq dy.
(3.232)
In fact the example in (3.232) is a special case of the example in (3.230) provided
QpÏq is given by the following limit:
QpÏq â€œ lim
hÃ“0
I Â´ C pÏ Â´ hq C pÏ Â´ hqËš
h
(3.233)
If QpÏq is as in (3.233), then
S pt, sq S pt, sqËš â€œ I Â´ C pt, sq C pt, sqËš â€œ
Å¼ t
s
C pt, Ïq QpÏqC pt, ÏqËš dÏ.
The following auxiliary lemma will be useful. Condition (3.234) is satisï¬ed if the
three pairs pC1, S1q, pC2, S2q, and pC3, S3q satisfy: C1CËš
1 `S1SËš
1 â€œ C2CËš
2 `S2SËš
2 â€œ
C3CËš
3 ` S3SËš
3 â€œ I. It also holds if C2 â€œ C pt2, t1q, and
SjSËš
j â€œ
Å¼ tj
tjÂ´1
C ptj, Ïq ÏƒpÏqÏƒpÏqËšC ptj, ÏqËš dÏ,
j â€œ 1, 2,
and
S3SËš
3 â€œ
Å¼ t2
t0
C pt2, Ïq ÏƒpÏqÏƒpÏqËšC pt2, ÏqËš dÏ.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
199 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.89. Lemma. Let C1, S1, C2, S2, and C3, S3 be dË†d-matrices with the following
properties:
C3 â€œ C2C1,
and
C2S1SËš
1CËš
2 ` S2SËš
2 â€œ S3SËš
3.
(3.234)
Let f P Cb
`
RdË˜
, and put
Y1,2fpxq â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f pC1x ` S1yq dy;
(3.235)
Y2,3fpxq â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f pC2x ` S2yq dy;
(3.236)
Y1,3fpxq â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f pC3x ` S3yq dy.
(3.237)
Then Y1,2Y2,3 â€œ Y1,3.
Proof. Let the matrices Cj and Sj, 1 Ä j Ä 3, be as in (3.234).
Let
f P Cb
`
RdË˜
. First we assume that the matrices S1 and C2 are invertible, and
we put A3 â€œ SÂ´1
1 CÂ´1
2 S3, and A2 â€œ SÂ´1
1 CÂ´1
2 S2.
Then, using the equalities
in (3.234) we see A3AËš
3 â€œ I ` A2AËš
2. We choose a d Ë† d-matrix A such that
AËšA â€œ I`AËš
2A2, and we put D â€œ pAÂ´1qËš AËš
2A3. Then we have AËš
3A3 â€œ I`DËšD.
Let f P Cb
`
RdË˜
. Let the vectors py1, y2q P Rd Ë† Rd and py, zq P Rd Ë† Rd be such
that
Ë†
y1
y2
Ë™
â€œ
Ë†
A3
Â´A2AÂ´1
0
AÂ´1
Ë™ Ë†
y
z
Ë™
.
(3.238)
Since
A2AËš
2 pI ` A2AËš
2qÂ´1 â€œ A2 pI ` AËš
2A2qÂ´1 AËš
2,
we obtain
det pI ` A2AËš
2q â€œ det pI ` AËš
2A2q .
Hence, the absolute value of the determinant of the matrix in the right-hand
side of (3.238) can be rewritten as:
Ë‡Ë‡Ë‡Ë‡det
Ë†
A3
Â´A2AÂ´1
0
AÂ´1
Ë™Ë‡Ë‡Ë‡Ë‡
2
â€œ
Ë‡Ë‡det A3 pdet AqÂ´1Ë‡Ë‡2
â€œ det pA3AËš
3q
det pAËšAq â€œ det pI ` A2AËš
2q
det pI ` AËš
2A2q â€œ 1.
(3.239)
From (3.238) and (3.239) it follows that the corresponding volume elements
satisfy: dy1 dy2 â€œ dy dz. We also have
|y1|2 ` |y2|2 â€œ |y|2 ` |z Â´ Dy|2 .
(3.240)
Employing the substitution (3.238) together with the equalities dy1 dy2 â€œ dy dz
and (3.240) and applying Fubiniâ€™s theorem we obtain:
Y1,2Y2,3fpxq â€œ
1
p2Ï€qd
Ä³
eÂ´ 1
2p|y1|2`|y2|2qf pC2C1x ` C2S1y1 ` S2y2q dy1dy2
â€œ
1
p2Ï€qd
Ä³
eÂ´ 1
2p|y|2`|zÂ´Dy|2qf pC3x ` S3yq dy dz
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
200 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f pC3x ` S3yq dy â€œ Y1,3fpxq
(3.241)
for all f P Cb
`
RdË˜
.
If the matrices S1 and C2 are not invertible, then we
replace the C1 with C1,Îµ â€œ eÂ´ÎµC1 and S1,Îµ satisfying C1,ÎµCËš
1,Ïµ ` S1,ÎµSËš
1,Îµ â€œ I,
and limÎµÃ“0 S1,Îµ â€œ S1.
We take S2,Îµ â€œ eÂ´ÎµS2 instead of S2.
In addition, we
choose the matrices C2,Îµ, Îµ Ä… 0, in such a way that C2,ÎµCËš
2,Ïµ ` S2,ÎµSËš
2,Îµ â€œ I, and
limÎµÃ“0 C2,Îµ â€œ C2.
This completes the proof of Lemma 3.89.
â–¡
We formulate a proposition in which an Ornstein-Uhlenbeck process plays a
central role.
Here Ï ÃÃ‘ ÏƒpÏq is a deterministic square matrix function, and
QpÏq â€œ ÏƒpÏqÏƒpÏqËš.
3.90. Proposition. Put XÏ„,xptq â€œ C pt, Ï„q x `
ÅŸt
Ï„ C pt, Ïq ÏƒpÏqdWpÏq. Then the
process XÏ„,xptq is Gaussian. Its expectation is given by E rXÏ„,xptqs â€œ C pt, Ï„q x,
and its covariance matrix has entries (s, t Ä› Ï„
P-cov
`
XÏ„,x
j psq, XÏ„,x
k ptq
Ë˜
â€œ
ËœÅ¼ minps,tq
Ï„
C ps, Ïq QpÏqC pt, ÏqËš dÏ
Â¸
j,k
(3.242)
Let
â£
pâ„¦, F, PÏ„,xq , pXptq, t Ä› 0q ,
`
Rd, BdË˜(
be the corresponding time-inhomogen-
eous Markov process.
By deï¬nition, the P-distribution of the process t ÃÃ‘
XÏ„,xptq, t Ä› Ï„, is the PÏ„,x-distribution of the process t ÃÃ‘ Xptq, t Ä› Ï„. Then this
process is generated by the family operators Lptq, t Ä› 0, where
Lptqfpxq â€œ 1
2
dÃ¿
j,kâ€œ1
Qj,kptqDjDkfpxq ` âŸ¨âˆ‡fpxq, AptqxâŸ©.
(3.243)
Here the matrix-valued function Aptq is given by Aptq â€œ lim
hÃ“0
Cpt ` h, tq Â´ I
h
.
The semigroup esLptq, s Ä› 0, is given by
esLptqfpxq
â€œ E
â€
f
Ë†
esAptqx `
Å¼ s
0
epsÂ´ÏqAptqÏƒptqdWpÏq
Ë™È·
â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f
Ëœ
esAptqx `
Ë†Å¼ s
0
eÏAptqQptqeÏAptqËšdÏ
Ë™1{2
y
Â¸
dy
â€œ
Å¼
p ps, x, y; tq fpyqdy
(3.244)
where, with QAptqpsq â€œ
Å¼ s
0
eÏAptqQptqeÏAptqËšdÏ, the integral kernel p ps, x, y; tq is
given by
p ps, x, y; tq
â€œ
1
p2Ï€qd{2 `
det QAptqpsq
Ë˜d{2e
Â´
Â´ 1
2
âŸ¨
pQAptqpsqq
Â´1pyÂ´esAptqxq,yÂ´esAptqx
âŸ©Â¯
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
201 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
If all eigenvalues of the matrix Aptq have strictly negative real part, then the
measure
B ÃÃ‘
1
p2Ï€qd{2
Å¼
eÂ´ 1
2|y|21B
Ë†Å¼ 8
0
eÏAptqQptqeÏAptqËšdÏ y
Ë™
dy
deï¬nes an invariant measure for the semigroup esLptq, s Ä› 0.
A Markov process of the form
â£
pâ„¦, F, PÏ„,xq , pXptq, t Ä› 0q ,
`
Rd, BRd
Ë˜(
is called
a (generalized) Ornstein-Uhlenbeck process. It is time-homogeneous by putting
Cpt, sq â€œ eÂ´ptÂ´sqA, where A is a square d Ë† d-matrix. We will elaborate on the
time-homogeneous case. In this case we write, for x, b P Rd,
Sptqfpxq :â€œ E
â€
f
Ë†
eÂ´tAx `
`
I Â´ eÂ´tAË˜
b `
Å¼ t
0
eÂ´ptÂ´sqAÏƒ dBpsq
Ë™È·
,
(3.245)
where f : Rd Ã‘ C is a bounded Borel measurable function. If f belongs to
C0
`
RdË˜
, then Sptqf does so as well. For brevity we write
Xxptq â€œ eÂ´tAx `
`
I Â´ eÂ´tAË˜
b `
Å¼ t
0
eÂ´ptÂ´sqAÏƒ dWpsq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360Â°
thinking.
Â© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
202 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
It also follows that for such functions limtÃ“0 Sptqfpxq â€œ fpxq for all x P Rd.
Since we also have the semigroup property S pt1 ` t2q f â€œ S pt1q S pt2q f for all
t1, t2 Ä› 0, it follows that the semigroup t ÃÃ‘ Sptq is in fact a Feller semigroup.
Theorem 3.37 implies that there exists a time-homogeneous Markov process
â£
pâ„¦, F, PxqxPRd , pXptq, t Ä› 0q , pÏ‘t, t Ä› 0q ,
`
Rd, BRd
Ë˜(
such that for a bounded Borel function f we have
Ex rf pXptqqs â€œ E rf pXxptqqs â€œ Sptqfpxq, x P Rd.
(3.246)
Nest we prove the semigroup property. First we observe that, for x P Rd and
t1, t2 Ä› 0,
Xx pt1 ` t2q â€œ eÂ´t2AXx pt1q`
`
I Â´ eÂ´t2AË˜
b`
Å¼ t2
0
eÂ´pt2Â´sqAÏƒ dW ps ` t1q . (3.247)
Let
`
â„¦W, FW, P
Ë˜
be the probability space on which the process t ÃÃ‘ Wptq is a
Brownian motion. Let
`
FW
t
Ë˜
tÄ›0 be the internal history of the Brownian motion
tWptq : t Ä› 0u, so that FW
t
â€œ Ïƒ pWpsq : s Ä tq. Then by the equality in (3.247)
we have
E
â€œ
f pXx pt1 ` t2qq
Ë‡Ë‡ FW
t1
â€°
(3.248)
â€œ E
â€
f
Ë†
eÂ´t2AXx pt1q `
`
I Â´ eÂ´t2AË˜
b `
Å¼ t2
0
eÂ´pt2Â´sqAÏƒ dW ps ` t1q
Ë™ Ë‡Ë‡ FW
t1
È·
We employ the fact that the state variable Xx pt1q is FW
t1 -measurable, and that
Å¼ t1`t2
t1
eÂ´pt1`t2Â´sqAÏƒ dWpsq â€œ
Å¼ t2
0
eÂ´pt2Â´sqAÏƒ d tW ps ` t1q Â´ W pt1qu
is P-independent of FW
t1 and possesses the same P-distribution as the variable
ÅŸt2
0 eÂ´pt2Â´sqAÏƒ dW psq to conclude from (3.248) the following equality:
E
â€œ
f pXx pt1 ` t2qq
Ë‡Ë‡ FW
t1
â€°
â€œ E
â€
f
Ë†
eÂ´t2Az `
`
I Â´ eÂ´t2AË˜
b `
Å¼ t2
0
eÂ´pt2Â´sqAÏƒ dW psq
Ë™È· Ë‡Ë‡
zâ€œXxpt1q
â€œ E rf pXz pt2qqs
Ë‡Ë‡
zâ€œXxpt1q .
(3.249)
From (3.249) it follows that the process t ÃÃ‘ Xxptq is a Markov process and
that, by the deï¬nition of the operators Sptq, t Ä› 0,
S pt1 ` t2q fpxq â€œ E rf pXx pt1 ` t2qqs
â€œ E
â€
E rf pXz pt2qqs
Ë‡Ë‡
zâ€œXxpt1q
Ä±
â€œ E rS pt2q f pXx pt1qqs
â€œ S pt1q S pt2q fpxq.
(3.250)
We calculate the diï¬€erential dXxptq and the covariation process
@
Xx
j1, Xx
j2
D
ptq:
dXxptq â€œ Â´A pXxptq Â´ bq dt ` Ïƒ dWpsq,
and
(3.251)
@
Xx
j1, Xx
j2
D
ptq â€œ
Å¼ t
0
Â´
eÂ´sAÏƒÏƒËšeÂ´sAËšÂ¯
j1,j2 ds â€œ cov
`
Xx
j1ptq, Xx
j2ptq
Ë˜
.
(3.252)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
203 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In other words the process t ÃÃ‘ Xxptq satisï¬es the equation
Xxptq â€œ x `
Å¼ t
0
A pb Â´ Xxpsqq ds `
Å¼ t
0
Ïƒ dWpsq.
(3.253)
Since its covariation is deterministic we have that the covariation coincides with
its covariance: see (3.252). Let f : Rd Ã‘ C be a bounded continuous function
with bounded and continuous ï¬rst and second order derivatives. Next we apply
ItË†oâ€™s lemma, and employ (3.251) and (3.252) to obtain
f pXxptqq Â´ f pXxp0qq â€œ
Å¼ t
0
âˆ‡f pXxpsqq Â¨ tÂ´A pXxpsq Â´ bqu ds
` 1
2
dÃ¿
j1,j2â€œ1
Å¼ t
0
Dj1Dj2f pXxpsqq
Â´
eÂ´sAÏƒÏƒËšeÂ´sAËšÂ¯
j1,j2 ds
`
Å¼ t
0
âˆ‡f pXxpsqq Â¨ Ïƒ dWpsq.
(3.254)
Upon taking expectations in the right-hand and left-hand sides of (3.254), using
the fact that the stochastic integral in (3.254) ia a martingale, and letting t Ã“ 0
shows:
LAfpxq :â€œ lim
tÃ“0
Sptqfpxq Â´ fpxq
t
â€œ lim
tÃ“0
E rf pXxptqq Â´ f pXxp0qqs
t
â€œ Â´ pApx Â´ bqq Â¨ âˆ‡fpxq ` 1
2
dÃ¿
j1,j2â€œ1
pÏƒÏƒËšqj1,j2 Dj1Dj2fpxq.
(3.255)
In the following proposition we collect the main properties of the time-homo-
geneous Ornstein-Uhlenbeck process t ÃÃ‘ Xxptq. It is adapted from Proposition
3.90. In adition, Ïƒ â€œ ÏƒpÏq is independent of Ï.
3.91. Proposition. Put Xxptq â€œ eÂ´tAx `
`
I Â´ eÂ´tAË˜
b `
ÅŸt
0 eÂ´ptÂ´ÏqAÏƒ dWpÏq.
Then the process Xxptq is Gaussian. Its expectation is given by E rXxptqs â€œ
eÂ´tAx `
`
I Â´ eÂ´tAË˜
b, and its covariance matrix has entries
P-cov
`
Xx
j1psq, Xx
j2ptq
Ë˜
â€œ
ËœÅ¼ minps,tq
0
eÂ´psÂ´ÏqAÏƒÏƒËšeÂ´ptÂ´ÏqAËš dÏ
Â¸
j1,j2
(3.256)
Let
â£
pâ„¦, F, PÏ„,xq , pXptq, t Ä› 0q ,
`
Rd, BdË˜(
be the corresponding time-inhomogen-
eous Markov process. By deï¬nition, the P-distribution of the process t ÃÃ‘ Xxptq,
t Ä› Ï„, is the Px-distribution of the process t ÃÃ‘ Xptq, t Ä› 0. Then this process
is generated by the operator LA, t Ä› 0, where
LAfpxq â€œ 1
2
dÃ¿
j1,j2â€œ1
pÏƒÏƒËšqj1,j2 Dj1Dj2fpxq Â´ âŸ¨âˆ‡fpxq, Apx Â´ bqâŸ©.
(3.257)
The semigroup esLA, s Ä› 0, is given by
esLAfpxq
â€œ E
â€
f
Ë†
eÂ´sApx Â´ bq ` b `
Å¼ s
0
eÂ´psÂ´ÏqAÏƒ dWpÏq
Ë™È·
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
204 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
â€œ
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|2f
Ëœ
eÂ´sApx Â´ bq ` b `
Ë†Å¼ s
0
eÂ´ÏAÏƒÏƒËšeÂ´ÏAËš dÏ
Ë™1{2
y
Â¸
dy
â€œ
Å¼
pA ps, x, yq fpyq dy
(3.258)
where, with QApsq â€œ
Å¼ s
0
eÂ´ÏAÏƒÏƒËšeÂ´ÏAËš dÏ, the integral kernel pA ps, x, yq is given
by
pA ps, x, yq â€œ
1
p2Ï€qd{2 pdet QApsqqd{2epÂ´ 1
2âŸ¨pQApsqqÂ´1pyÂ´eÂ´sApxÂ´bqÂ´bq,yÂ´eÂ´sApxÂ´bqÂ´bâŸ©q.
If all eigenvalues of the matrix A have strictly positive real part, then the measure
B ÃÃ‘
1
p2Ï€qd{2
Å¼
eÂ´ 1
2 |y|21B
Ë†
b `
Å¼ 8
0
eÂ´ÏAÏƒÏƒËšeÂ´ÏAËšy dÏ
Ë™
dy
(3.259)
deï¬nes an invariant measure for the semigroup esLA, s Ä› 0.
Proof. The results in Proposition 3.91 follow more or less directly from
those in Proposition 3.90. The result in (3.259) follows by letting s Ã‘ 8 in
the second equality of (3.258) or in the deï¬nition of the probability density
pA ps, x, yq.
â–¡
For more information about invariant, or stationary, measures see, e.g., [146]
(Chapter 10) and the references therein like Meyn and Tweedie [97].
In order to apply our results on the Ornstein-Uhlenbeck process to bond pricing
and determining interest rates in ï¬nancial mathematics the identities and results
in the following proposition are very useful. It will be applied in the context of
the Vasicek model.
3.92. Proposition. Let the notation and hypotheses be as in Proposition 3.91.
Put
Apt, Tq â€œ
Å¼ TÂ´t
0
eÂ´ÏA dÏ â€œ
Å¼ T
t
eÂ´Ïs ds â€œ AÂ´1 `
I Â´ eÂ´pTÂ´tqAË˜
,
0 Ä t Ä T,
where the last equality is only valid if A is invertible. Let y be a vector in Rd.
The following assertions hold true.
(1) The following identity is true for 0 Ä t Äƒ T:
Å¼ T
t
Xxpsq ds â€œ Apt, Tq pXxptq Â´ bq ` pT Â´ tqb `
Å¼ T
t
A pÏ, Tq Ïƒ dWpÏq. (3.260)
(2) The random vector
ÅŸT
t Xxpsq ds is Gaussian (or, what is the same, mul-
tivariate normally distributed) with conditional expectation given by
E
â€Å¼ T
t
Xxpsq ds
Ë‡Ë‡ Ft
È·
â€œ E
â€Å¼ T
t
Xxpsq ds
Ë‡Ë‡ Xxptq
È·
â€œ Apt, Tq pXxptq Â´ bq`pT Â´tqb,
(3.261)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
205 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
and covariance matrix given by (1 Ä j1, j2 Ä d)
cov
Ë†Å¼ T
t
Xx
j1psq ds
Ë‡Ë‡ Xxptq,
Å¼ T
t
Xx
j2psq ds
Ë‡Ë‡ Xxptq
Ë™
â€œ
Ë†Å¼ T
t
A pÏ, Tq ÏƒÏƒËšA pÏ, TqËš dÏ
Ë™
j1,j2
.
(3.262)
(3) The random variable
âŸ¨
y,
ÅŸT
t Xxpsq ds
âŸ©
is normally distributed with con-
ditional expectation given by
E
â€âŸ¨
y,
Å¼ T
t
Xxpsq ds
âŸ©Ë‡Ë‡ Ft
È·
â€œ E
â€âŸ¨
y,
Å¼ T
t
Xxpsq ds
âŸ©Ë‡Ë‡ Xxptq
È·
â€œ âŸ¨y, Apt, Tq pXxptq Â´ bqâŸ©` pT Â´ tq âŸ¨y, bâŸ©,
(3.263)
and variance given by
var
Ë†âŸ¨
y,
Å¼ T
t
Xxpsq ds
âŸ©Ë‡Ë‡ Xxptq
Ë™
â€œ
Å¼ T
t
Ë‡Ë‡ÏƒËšA pÏ, TqËš y
Ë‡Ë‡2 dÏ.
(3.264)
(4) The conditional expectation of exp
Â´
Â´
âŸ¨
y,
ÅŸT
t Xxpsq ds
âŸ©Â¯
given Ft is log-
normal, and
E
â€
exp
Ë†
Â´
âŸ¨
y,
Å¼ T
t
Xxpsq ds
âŸ©Ë™ Ë‡Ë‡ Ft
È·
â€œ E
â€
exp
Ë†
Â´
âŸ¨
y,
Å¼ T
t
Xxpsq ds
âŸ©Ë™ Ë‡Ë‡ Xxptq
È·
â€œ exp
Ë†
Â´ âŸ¨y, Apt, Tq pXxptq Â´ bqâŸ©Â´ pT Â´ tq âŸ¨y, bâŸ©` 1
2
Å¼ T
t
Ë‡Ë‡ÏƒËšA pÏ, TqËš y
Ë‡Ë‡2 dÏ
Ë™
.
(3.265)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
206 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. (1) From (3.247) we see, for s Ä› t,
Xx psq â€œ eÂ´psÂ´tqA pXx ptq Â´ bq ` b `
Å¼ s
t
eÂ´psÂ´ÏqAÏƒ dW pÏq .
(3.266)
Then we integrate the expressions in (3.266) against s for t Ä s Ä T, and we
interchange the integrals with respect to ds and dWpÏq to obtain the equality
in (3.260). This proves assertion (1).
(2) Although the process t ÃÃ‘
ÅŸT
t A pÏ, Tq dWpÏq is not a martingale, it has
enough properties of a martingale that its expectation is 0, and that its quadratic
covariation matrix is given by the expression in (3.262). The reason for all this
relies on the equality:
Å¼ T
t
A pÏ, Aq dWpÏq â€œ
Å¼ T
0
A pÏ, Tq dWpÏq Â´
Å¼ t
0
A pÏ, Tq dWpÏq,
(3.267)
combined with the fact that the process t ÃÃ‘
ÅŸt
0 A pÏ, Tq dWpÏq is a martingale.
So we can apply the ItË†o isometry and its consequences to complete the proof
of assertion (2).
An alternative way of understanding this reads as follows.
Processes of the form s ÃÃ‘ Xxpsq, s Ä 0, and t ÃÃ‘
ÅŸT
t Xxpsq ds, 0 Ä t Ä T,
consist of Gaussian vectors with known means and variances. For s Ä› t we use
the representation in (3.266) for Xxpsq, and for
ÅŸT
t Xxpsq ds we employ (3.260).
(3) The proof of this assertion follows the same line as the proof of the assertion
in (2).
(4) If the stochastic variable Z is normally distributed with expectation Âµ and
variance v2 â€œ E
â€œ
pZ Â´ Âµq2â€°
, then E
â€œ
eZâ€°
â€œ eÂµ` 1
2v2. This result is applied to the
variable Z â€œ Â´
âŸ¨
y,
ÅŸT
t Xxpsq ds
âŸ©
to obtain the equality in (3.265).
This completes the proof of Proposition 3.92.
â–¡
3.93. Lemma. Let the notation and hypotheses be as in the proposition 3.91 and
3.92. Suppose that the matrix A is invertible. The following equality holds for
0 Ä t Ä T:
Å¼ T
t
A pÏ, Tq ÏƒÏƒËšA pÏ, TqËš dÏ
â€œ pT Â´ tqAÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´ A pt, Tq AÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´ AÂ´1ÏƒÏƒËš pAËšqÂ´1 A pt, TqËš
`
Å¼ TÂ´t
0
eÂ´ÏAAÂ´1ÏƒÏƒËš pAËšqÂ´1 eÂ´ÏAËš dÏ.
(3.268)
If the invertible matrix A is such that AÏƒÏƒËš â€œ ÏƒÏƒËšAËš, then the following equality
is valid for 0 Ä t Ä T:
Å¼ T
t
A pÏ, Tq ÏƒÏƒËšA pÏ, TqËš dÏ
â€œ pT Â´ tqAÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´ A pt, Tq AÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´ 1
2 pApt, Tqq2 ÏƒÏƒËš pAËšqÂ´1
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
207 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
â€œ
Ë†
T Â´ t Â´ A pt, Tq Â´ 1
2A pApt, Tqq2
Ë™
AÂ´1ÏƒÏƒËš pAËšqÂ´1 .
(3.269)
Observe that an equality of the form AÏƒÏƒËš â€œ ÏƒÏƒËšAËš holds whenever A â€œ AËš
and the matrix ÏƒÏƒËš is a â€œfunctionâ€ of A. In particular this is true when d â€œ 1
and A â€œ a is a real number.
Proof. Since A is invertible we have A pÏ, Tq â€œ
`
I Â´ eÂ´pTÂ´ÏqAË˜
AÂ´1, and so
Å¼ T
t
A pÏ, Tq ÏƒÏƒËšA pÏ, TqËš dÏ
â€œ
Å¼ T
t
`
I Â´ eÂ´pTÂ´ÏqAË˜
AÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´
I Â´ eÂ´pTÂ´ÏqAËšÂ¯
dÏ
â€œ
Å¼ TÂ´t
0
`
I Â´ eÂ´ÏAË˜
AÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´
I Â´ eÂ´ÏAËšÂ¯
dÏ
â€œ pT Â´ tqAÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´ A pt, Tq AÂ´1ÏƒÏƒËš pAËšqÂ´1 Â´ AÂ´1ÏƒÏƒËš pAËšqÂ´1 A pt, TqËš
`
Å¼ TÂ´t
0
eÂ´ÏAAÂ´1ÏƒÏƒËš pAËšqÂ´1 eÂ´ÏAËš dÏ.
(3.270)
The ï¬nal equality in (3.270) proves (3.268). Next we also assume that AÏƒÏƒËš â€œ
ÏƒÏƒËšAËš. Then ÏƒÏƒËšeÂ´ÏAËš â€œ eÂ´ÏAÏƒÏƒËš, and hence
Å¼ TÂ´t
0
eÂ´ÏAAÂ´1ÏƒÏƒËš pAËšqÂ´1 eÂ´ÏAËš dÏ
â€œ
Å¼ TÂ´t
0
eÂ´2ÏA dÏ AÂ´1ÏƒÏƒËš pAËšqÂ´1 eÂ´ÏAËš
â€œ 1
2
`
I Â´ e2pTÂ´tqAË˜
AÂ´2ÏƒÏƒËš pAËšqÂ´1 eÂ´ÏAËš.
(3.271)
A simple calculation shows
1
2
`
I Â´ eÂ´2pTÂ´tqAË˜
â€œ Apt, TqA Â´ 1
2 pApt, Tqq2 A2,
(3.272)
and so the equalities in (3.271) show
Å¼ TÂ´t
0
eÂ´ÏAAÂ´1ÏƒÏƒËš pAËšqÂ´1 eÂ´ÏAËš dÏ â€œ
Å¼ TÂ´t
0
eÂ´2ÏA dÏ AÂ´1ÏƒÏƒËš pAËšqÂ´1
â€œ
Ë†
Apt, Tq Â´ 1
2 pApt, Tqq2 A
Ë™
AÂ´1ÏƒÏƒËš pAËšqÂ´1 .
(3.273)
A combination of (3.270) and (3.273) together with the equality ÏƒÏƒËšA pt, TqËš â€œ
A pt, Tq ÏƒÏƒËš then yields the equality in (3.269), completing the proof of Lemma
3.93.
â–¡
Before we discuss the Vasicek model we insert Girsanovâ€™s theorem formulated
in a way as we will use it in Theorem 3.101. In fact we will formulate it in a
multivariate context.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
208 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.94. Theorem. Let tXptq : 0 Ä t Ä tu be an ItË†o process satisfying
dXptq â€œ vptq dt ` uptq dWptq. 0 Ä t Ä T.
Suppose there exists a process tÎ¸ptq : 0 Ä t Ä Tu, with the property that
P
â€Å¼ T
0
|Ï‘ptq|2 dt Äƒ 8
È·
â€œ 1,
such that the process vptq Â´ uptqÎ¸ptq has this property as well. Assume further-
more that the process t ÃÃ‘ Eptq, 0 Ä t Ä T, deï¬ned by
Eptq â€œ exp
Ë†
Â´
Å¼ t
0
Î¸psq dWpsq Â´ 1
2
Å¼ t
0
|Î¸psq|2 ds
Ë™
(3.274)
is a P-martingale, which is guaranteed provided E rEptqs â€œ 1 for 0 Ä t Ä T.
Deï¬ne the measure PËš such that dPËš
dP â€œ EpTq. Then
t ÃÃ‘ W Ëšptq :â€œ Wptq `
Å¼ t
0
Î¸psq ds,
t P r0, Ts,
is a Brownian motion w.r.t. PËš and the process tXptq : 0 Ä t Ä Tu has a rep-
resentation w.r.t. W Ëšptq given by
dXptq â€œ pvptq Â´ uptqÎ¸ptqq dt ` uptq dW Ëšptq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
209 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We shortly show that tEptq : 0 Ä t Ä Tu is a diï¬€usion process.
Set Y ptq â€œ
ÅŸt
0 Î¸psq dWpsq, 0 Ä t Ä T, and consider the function fpt, xq P C2 pr0, Ts, Rq
deï¬ned by
fpt, xq â€œ exp
Ë†
Â´x Â´ 1
2
Å¼ t
0
|Î¸psq|2 ds
Ë™
.
Then we clearly have that Eptq â€œ f pt, Y ptqq. By ItË†oâ€™s formula we have
dEptq â€œ Â´1
2 |Î¸ptq|2 Eptq dt Â´ EptqÎ¸ptq dWptq ` 1
2Eptq d âŸ¨Y, Y âŸ©ptq
â€œ Â´1
2 |Î¸ptq|2 Eptq dt Â´ EptqÎ¸ptq dWptq ` 1
2Eptq |Î¸ptq|2 dt
â€œ Â´Î¸ptqEptq dWptq.
(3.275)
Hence, it follows that
Eptq â€œ Ep0q Â´
Å¼ t
0
Î¸psqEpsq dWpsq,
which in general is a local martingale for which E rEptqs Ä 1.
It is a sub-
martingale, but not necessarily a martingale. If, for 0 Ä t Ä T, the expecta-
tion E rEptqs â€œ 1, then t ÃÃ‘ Eptq, 0 Ä t Ä T, is a martingale. If Novikovâ€™s
condition, i.e., if E
â€
exp
Â´
1
2
ÅŸT
0 |Î¸ptq|2 dt
Â¯Ä±
Äƒ 8 is satisï¬ed, then the process
tEptq : 0 Ä t Ä Tu is a martingale. For details on this condition, see Corollary
4.27 in Chapter 4. For more results on (local) exponential martingales see sub-
section 1.3 of Chapter 4 as well. In section 3 of the same chapter the reader may
ï¬nd some more information on Girsanovâ€™s theorem. In particular, see assertion
(4) of Proposition 4.24 and Theorem 4.25.
8.1. The Vasicek model. In this subsection we want to employ the results
in Proposition 3.92 with d â€œ 1 to ï¬nd the bond prices in the Vasicek model.
Until now we were always working in the physical probability space pâ„¦, F, Pq.
In order to calculate the fair price of a ï¬nancial instrument one often uses the
method of risk-neutral pricing. Through this technique the price of a ï¬nancial
asset is the expectation of its discounted pay-oï¬€at the so-called risk-neutral
measure Q. The risk-neutral measure is equivalent to the physical measure P.
Suppose for example that tSptqusÄ›0 is the price of a certain asset at time t.
The price of our asset at time t discounted to time 0 is then given by rSptq :â€œ
eÂ´
ÅŸt
0 rpuq duSptq. As a main property of the risk-neutral measure, the family of
discounted prices
!
rSptq
)
tÄ›0 is a Q-martingale. This means that for every s,
0 Ä s Ä t, we have
E
â€
rSptq
Ë‡Ë‡ Fs
Ä±
â€œ E
â€
eÂ´
ÅŸt
0 rpuq duSptq
Ë‡Ë‡ Fs
Ä±
â€œ eÂ´
ÅŸs
0 rpuq duSpsq â€œ rSpsq,
(3.276)
where expectations E are with respect to Q. Because of this property, a risk-
neutral measure is also called an equivalent martingale measure. Roughly speak-
ing, the existence of such a measure is equivalent with the no-arbitrage assump-
tion. We will use this martingale property to price a zero-coupon bond. That
is a ï¬nancial debt instrument that pays the holder a ï¬xed amount named the
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
210 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
face value at maturity T. For simplicity we take 1 as face value. The price of a
zero-coupon bond is then given by the following theorem.
3.95. Theorem. Consider a zero-coupon bond which pays an amount of 1 at
maturity T. The price at time t Ä T is then
Ppt, Tq â€œ E
â€
eÂ´
ÅŸT
t rpsq ds Ë‡Ë‡ Ft
Ä±
.
(3.277)
Proof. We use the above explained property that the discounted price
eÂ´
ÅŸt
0 rpsq dsPpt, Tq is a martingale, and the trivial fact that PpT, Tq â€œ 1,
eÂ´
ÅŸt
0 rpsq dsPpt, Tq â€œ E
â€
eÂ´
ÅŸT
0 rpsq dsPpT, Tq
Ë‡Ë‡ Ft
Ä±
â€œ E
â€
eÂ´
ÅŸT
0 rpsq ds Ë‡Ë‡ Ft
Ä±
â€œ eÂ´
ÅŸt
0 rpsq dsE
â€
eÂ´
ÅŸT
t rpsq ds Ë‡Ë‡ Ft
Ä±
.
(3.278)
The bondâ€™s price can thus be written as Ppt, Tq â€œ E
â€
eÂ´
ÅŸT
t rpsq ds Ë‡Ë‡ Ft
Ä±
. This
completes the proof of Theorem 3.95.
â–¡
Formula (3.277) is an expression of the bondâ€™s price for an arbitrary chosen
interest rate process. We will now apply this to our Vasicek model trptqutÄ›0.
We will investigate three methods that all lead to the same result stated in the
following theorem. We follow the approach of Mamon in [94]. For an alternative
approach see [114] as well.
3.96. Theorem. Consider a zero-coupon bond which pays an amount of 1 at
maturity T. Suppose that under the risk-neutral measure the short rate follows
an Ornstein-Uhlenbeck process: drptq â€œ a pb Â´ rptqq dt`Ïƒ dWptq. The fair price
of the bond at time t Ä T is then given by
Ppt, Tq â€œ eÂ´Apt,Tqrptq`Dpt,Tq,
(3.279)
where
Apt, Tq â€œ 1 Â´ eÂ´apTÂ´tq
a
,
and
Dpt, Tq â€œ pApt, Tq Â´ T ` tq pa2b Â´ Ïƒ2{2q
a2
Â´ Ïƒ2Apt, Tq2
4a
.
(3.280)
Equation (3.279) is an aï¬ƒne term structure model. In fact, the bond yield ytpTq
is deï¬ned as the constant interest rate at which the price of the bond grows to
itâ€™s face value, i.e., Ppt, TqeytpTqpTÂ´tq â€œ 1. We thus ï¬nd that
ytpTq â€œ Â´ log Ppt, Tq
T Â´ t
â€œ Apt, Tqrptq Â´ Dpt, Tq
T Â´ t
,
which is indeed aï¬ƒne in rptq. The yield curve or term structure at time t is the
graph pT, ytpTqq.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
211 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
8.1.1. Bond price implied by the distribution of the short rate. The ï¬rst
method to calculate the bond price is quite straightforward. It calculates the
conditional expectation in formula (3.277) by determining the distribution of
E
â€ÅŸT
t rpsq ds
Ë‡Ë‡ Ft
Ä±
.
First proof of Theorem 3.96. Because formula (3.277) shows that the
bondâ€™s price at time t is conditional on Ft, we may assume that rptq is a pa-
rameter. Using formula (3.266) (for d â€œ 1, and A â€œ 1) with starting time t we
ï¬nd, for s Ä… t,
rpsq â€œ rptqeÂ´apsÂ´tq ` b
`
1 Â´ eÂ´apsÂ´tqË˜
`
Å¼ s
t
eÂ´apsÂ´ÏqÏƒ dWpÏq.
We want to determine the distribution of eÂ´
ÅŸT
t rpsq ds conditioned by Ft. Note
that because of the Markov property of the Otnstein-Uhlenbeck process (or
more generally for diï¬€usion processes: see the equality in (3.249)), this distri-
bution will only depend on rptq. Letâ€™s start by determining the distribution of
ÅŸT
t rpsq ds given Ft. This distribution is normal, and essentially speaking this it
follows from Proposition 3.92 and Lemma 3.93. First of all from assertion (3)
in Proposition 3.92 we get by (3.263)
E
â€Å¼ T
t
rpsq ds
Ë‡Ë‡ Ft
È·
â€œ E
â€Å¼ T
t
rpsq ds
Ë‡Ë‡ rptq
È·
â€œ Apt, Tq prptq Â´ bq ` pT Â´ tqb.
(3.281)
Secondly from (3.264) and (3.269) in Lemma 3.93 we get
var
Ë†Å¼ T
t
Xxpsq ds
Ë‡Ë‡ Xxptq
Ë™
â€œ
Å¼ T
t
Ïƒ2 pA pÏ, Tqq2 dÏ
â€œ Ïƒ2
a2
Â´
T Â´ t Â´ A pt, Tq Â´ a
2 pApt, Tqq2Â¯
.
(3.282)
The equality in (3.279) of Theorem 3.96 then follows from (3.282) and (3.265)
in (4) of Proposition 3.92.
â–¡
8.1.2. Bond price by solving the PDE. A second method that is proposed to
calculate the bondâ€™s price in the Vasicek model, is by solving partial diï¬€erential
equations. More precisely, we will derive a PDE for the bondâ€™s price by using
martingales.
Taking into account the Markov property of the process trptqutÄ›0 (see equality
in (3.249)) one can introduce the following variable:
Ppt, Tq â€œ E
â€
eÂ´
ÅŸT
t rpsq ds Ë‡Ë‡ Ft
Ä±
â€œ E
â€
eÂ´
ÅŸT
t rpsq ds Ë‡Ë‡ rptq
Ä±
â€œ E
â€
eÂ´
ÅŸT
t rpsqpzq dsÄ± Ë‡Ë‡
zâ€œrptqâ€œ: P pt, T, rptqq .
(3.283)
Here rpsq, s Ä… t, is the function of rptq given by
rpsq â€œ rptqeÂ´apsÂ´tq ` b
`
1 Â´ eapsÂ´tqË˜
`
Å¼ s
t
eÂ´apsÂ´Ïq dWpÏq.
(3.284)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
212 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We now provide a second proof of Theorem 3.96.
Second proof of Theorem 3.96. We will apply ItË†oâ€™s formula to the
function fpt, xq â€œ eÂ´
ÅŸt
0 rpsq dsPpt, T, xq. Then we obtain
E
â€
eÂ´
ÅŸT
0 rpsq ds Â´ P p0, T, rp0qq
Ë‡Ë‡ Ft
Ä±
â€œ eÂ´
ÅŸt
0 rpsq dsP pt, T, rptqq Â´ P p0, T, rp0qq
â€œ
Å¼ t
0
â€
Â´rpuqeÂ´
ÅŸu
0 rpsq dsP pu, T, rpuqq ` eÂ´
ÅŸu
0 rpsq dsBP pu, T, rpuqq
Bu
È·
du
`
Å¼ t
0
â€
eÂ´
ÅŸu
0 rpsq dsBP pu, T, rpuqq
Brpuq
È·
pa pb Â´ rpuqq du ` ÏƒdWpuqq
` Ïƒ2
2
Å¼ t
0
â€
eÂ´
ÅŸu
0 rpsq dsB2P pu, T, rpuqq
Brpuq2
È·
du.
(3.285)
Put
fptq â€œ Â´rptqeÂ´
ÅŸt
0 rpsq dsP pt, T, rptqq ` eÂ´
ÅŸt
0 rpsq dsBP pt, T, rptqq
Bt
`
â€
eÂ´
ÅŸt
0 rpsq dsBP pt, T, rptqq
Brpuq
È·
pa pb Â´ rptqqq
` Ïƒ2
2 eÂ´
ÅŸt
0 rpsq dsB2P pt, T, rptqq
Brptq2
.
(3.286)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
213 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
From the equality in (3.285) it follows that the process t ÃÃ‘
ÅŸt
0 fpuq du is a
martingale. By Lemma 3.97 below it follows that fptq â€œ 0 P-almost surely.
From (3.286) it then follows that the function Ppt, T, xq satisï¬es the following
diï¬€erential equation:
Â´xP pt, T, xq ` BP pt, T, xq
Bt
` BP pt, T, xq
Bx
pa pb Â´ xqq ` Ïƒ2
2
B2P pt, T, xq
Bx2
â€œ 0.
(3.287)
From (3.283) and (3.284) it follows that
BPpt, T, xq
Bx
â€œ Â´1
a
`
1 Â´ eÂ´apTÂ´tqË˜
Ppt, T, xq â€œ Â´Apt, TqPpt, T, xq.
(3.288)
From (3.288) we easily infer that
P pt, T, xq â€œ C pt, Tq eÂ´Apt,Tqx.
(3.289)
Inserting this expression for P pt, T, xq into (3.287) yields the ï¬rst order equation
Â´x `
1
Cpt, Tq
BCpt, Tq
Bt
Â´ BApt, Tq
Bt
x Â´ Apt, Tq tapb Â´ xqu ` Ïƒ2
2 Apt, Tq2 â€œ 0.
(3.290)
Because Â´1 Â´ BApt, Tq
Bt
` aApt, Tq â€œ 0, the equality in (3.290) implies:
1
Cpt, Tq
BCpt, Tq
Bt
Â´ abApt, Tq ` Ïƒ2
2 Apt, Tq2 â€œ 0.
(3.291)
Since CpT, Tq â€œ P pT, T, 0q â€œ 1 from (3.291) we infer Cpt, Tq â€œ eDpt,Tq and
hence
Ppt, Tq â€œ P pt, T, rptqq â€œ eÂ´Apt,Tqrptq`Dpt,Tq,
which completes the proof of Theorem 3.96 by employing the PDE as formulated
in (3.287).
â–¡
The equation in (3.287) is called the PDE for the bond price in the Vasicek
model.
3.97. Lemma. Let
`
â„¦, pFtqtÄ›0 , P
Ë˜
be ï¬ltered probability space, and let the right-
continuous adapted process tfptqutÄ›0 be such that for some sequence of stopping
times pÏ„nqnPN, which increases to 8, the integrals
ÅŸt
0 |fpsq| 1r1,Ï„ns ds are ï¬nite P-
almost surely. If the process t ÃÃ‘
ÅŸt
0 fpsq ds is a local martingale, then fptq â€œ 0
P-almost surely for almost all t.
Proof. Fix 0 Äƒ T Äƒ 8. By localizing at stopping times pÏ„ 1
nqnPN, Ï„ 1
n Ä Ï„n,
n P N, Ï„n Ã’ 8 (n Ã‘ 8) we may assume that
E
â€Å¼ T
0
|fpsq| ds
È·
Äƒ 8.
(3.292)
Otherwise we replace fptq with f ptq 1r0,Ï„ 1nsptq, and prove that f ptq 1r0,Ï„ 1nsptq â€œ 0
for all n P N. But then fptq â€œ 0, by letting n Ã‘ 8. So we assume that (3.292)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
214 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
is satisï¬ed. Then for 0 Ä s Äƒ t Ä T we have
Å¼ s
0
fpÏq dÏ ` E
â€Å¼ t
s
fpÏq dÏ
Ë‡Ë‡ Fs
È·
â€œ E
â€Å¼ t
0
fpÏq dÏ
Ë‡Ë‡ Fs
È·
â€œ
Å¼ s
0
fpÏq dÏ.
(3.293)
From (3.293) we infer that E
â€ÅŸt
s fpÏq dÏ
Ë‡Ë‡ Fs
Ä±
â€œ 0, P-almost surely, for all 0 Ä
s Äƒ t Äƒ T. diï¬€erentiating with respect to t then results in E
â€œ
fptq
Ë‡Ë‡ Fs
â€°
â€œ 0
P-almost surely for all 0 Ä s Äƒ t Äƒ T. But then, by the right-continuity of the
process tfptqutÄ›0 it follows that
fpsq â€œ lim
tÃ“s E
â€œ
fptq
Ë‡Ë‡ Fs
â€°
â€œ 0,
P-almost surely.
This completes the proof of Lemma 3.97.
â–¡
8.1.3. Bond prices using forward rates. The third and last method to calcu-
late a bondâ€™s price in the Vasicek model, is based upon the concept of forward
rates. Indeed, in the Heath-Jarrow-Morton pricing paradigm the closed-form
of the bondâ€™s price follows directly from the short rate dynamics under the so-
called forward measure. Suppose we are at time t. We want to know the rate
of interest in the period of time between T1 en T2 with t Äƒ T1 Äƒ T2. This is
called the forward rate for the period between T1 and T2 and we denote it by
f pt, T1, T2q. When the rates between time t and T1 and between time t and T2
are known - write R1 and R2 - we must have:
eR1pT1Â´tqefpt,T1,T2qpT2Â´T1q â€œ eR2pT2Â´tq.
Hence, we ï¬nd for the forward rate
f pt, T1, T2q â€œ R2 pT2 Â´ tq Â´ R1 pT1 Â´ tq
T2 Â´ T1
.
Applying this in our framework of bond prices, R1 and R2 equal the bond yields:
R1 â€œ Â´ log P pt, T1q
T1 Â´ t
,
R2 â€œ Â´ log P pt, T2q
T2 Â´ t
,
such that the forward rate is given by
f pt, T1, T2q â€œ Â´ log P pt, T2q Â´ log P pt, T1q
T2 Â´ T1
.
When T1 and T2 come inï¬nitesimally close to each other, we obtain a so-called
instantaneous forward rate. The instantaneous forward rate at time T Ä… t is
fpt, Tq â€œ Â´ lim
t1Ã‘T
log P pt, Tq Â´ log P pt, t1q
T Â´ t1
â€œ Â´B log P pt, t1q
Bt1
Ë‡Ë‡
t1â€œT .
Solving this partial diï¬€erential equation for P pt, Tq on rt, Ts we ï¬nd immedi-
ately that
P pt, Tq â€œ eÂ´
ÅŸT
t fpt,sq ds.
(3.294)
Later on we will see that the link between the instantaneous forward rate and
the short rate is the so-called forward measure. In the sequel, we will need two
properties of conditional expectations under change of measure. These results
can be found in [32]. In the following theorems P is a probability measure on a
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
215 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Ïƒ-algebra F, the probability measure Q ! P is such that dQ
dP â€œ Z. Furthermore
G is a sub-Ïƒ-algebra of F. The symbol E denotes expectation w.r.t. P, while
EQ stands for expectation w.r.t. Q.
3.98. Theorem. In the notation of above, it holds that
dQ
Ë‡Ë‡
G
dP
Ë‡Ë‡
G
â€œ E
â€œ
Z
Ë‡Ë‡ G
â€°
.
Proof. Take an arbitrary B P G. We need to show that
QpBq â€œ E
â€œ
E
â€œ
Z
Ë‡Ë‡ G
â€°
1B
â€°
.
Indeed:
E
â€œ
E
â€œ
Z
Ë‡Ë‡ G
â€°
1B
â€°
â€œ E
â€œ
E
â€œ
Z1B
Ë‡Ë‡ G
â€°â€°
â€œ E rZ1Bs â€œ QpBq.
This completes the proof of Theorem 3.98.
â–¡
3.99. Theorem. For any F-measurable random variable X :
E
â€œ
Z
Ë‡Ë‡ G
â€°
EQ â€œ
X
Ë‡Ë‡ G
â€°
â€œ E
â€œ
ZX
Ë‡Ë‡ G
â€°
.
Proof. Let Y â€œ E
â€œ
Z
Ë‡Ë‡ G
â€°
. Take B P G arbitrary, then:
EQ â€œ
1BE
â€œ
ZX
Ë‡Ë‡ G
â€°â€°
â€œ E
â€œ
Y 1BE
â€œ
ZX
Ë‡Ë‡ G
â€°â€°
â€œ E
â€œ
E
â€œ
Y 1BZX
Ë‡Ë‡ G
â€°â€°
â€œ E rY 1BZXs â€œ EQ rY 1BXs â€œ EQ â€œ
EQ â€œ
1BY X
Ë‡Ë‡ G
â€°â€°
â€œ EQ â€œ
1BEQ â€œ
Y X
Ë‡Ë‡ G
â€°â€°
.
In the ï¬rst step we used that 1BE
â€œ
ZX
Ë‡Ë‡ G
â€°
is G-mesurable. Hence we could
apply Theorem 3.98 which tells us that dQ
Ë‡Ë‡
Gâ€œ Y dP
Ë‡Ë‡
G. Because the previous
reasoning holds for all B P G we must have:
E
â€œ
ZX
Ë‡Ë‡ G
â€°
â€œ EQ â€œ
Y X
Ë‡Ë‡ G
â€°
â€œ Y EQ â€œ
X
Ë‡Ë‡ G
â€°
what proves the claim in Theorem 3.99.
â–¡
As well as the economic term forward rates, we introduce the concept of a
numÂ´eraire.
A numÂ´eraire is a tradeable economic security in terms of which
the relative prices of other assets can be expressed. This allows us not only to
compare diï¬€erent ï¬nancial instruments at a certain moment, it makes it also
possible to compare the prices of assets at diï¬€erent times. A typical example
of a numÂ´eraire is money. The random variable Mptq â€œ e
ÅŸt
0 rpsq ds represents the
value at time t of an asset which was invested in the money market at time
0 with value 1. Recall that in accordance with the deï¬nition of a risk-neutral
measure Q, the price of an asset relative to the money market is a martingale.
In our new notation the expressions in (3.276) become:
E
â€ Sptq
Mptq
Ë‡Ë‡ Fs
È·
â€œ E
â€
eÂ´
ÅŸt
0 rpuq duSptq
Ë‡Ë‡ Fs
Ä±
â€œ eÂ´
ÅŸs
0 rpuq duSpsq â€œ Spsq
Mpsq,
with 0 Ä s Ä t. We say that Q is an equivalent martingale measure for the
numÂ´eraire tMptqutÄ›0. Let Nptq be the price at time t of another traded asset.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
216 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Suppose that QËš is an equivalent martingale measure for tNptqutÄ›0, i.e. for all
0 Ä s Ä t:
EËš
â€ Sptq
Nptq
Ë‡Ë‡ Fs
È·
â€œ Spsq
Npsq.
We can also deï¬ne this measure on the basis of the Radon-Nikodym derivative
of QËš w.r.t. Q.
3.100. Theorem. Suppose that Q is an equivalent martingale measure for the
numÂ´eraire tMptqutÄ›0. Let QËš be an absolutely continuous measure w.r.t. Q
deï¬ned by the Radon-Nikodym derivative:
Î“t :â€œ dQËš
dQ
Ë‡Ë‡
Ftâ€œ Mp0q
Mptq
Nptq
Np0q,
(3.295)
where Nptq Ä… 0 is the price at time t of a particular asset. Then QËš is an
equivalent martingale measure for tNptq : t Ä› 0u.
Proof. Denote expectations w.r.t.
Q by E and w.r.t.
QËš by EËš.
Let
Sptq be the price of an asset at time t Ä› 0 and assume Sptq P L2 pâ„¦, Ft, Qq X
L2 pâ„¦, Ft, QËšq. For t Ä› s Ä› 0 we ï¬nd using Theorem 3.99
EËš
â€ Sptq
Nptq
Ë‡Ë‡ Fs
È·
â€œ E
â€Mp0qNptq
MptqNp0q
Sptq
Nptq
Ë‡Ë‡ Fs
È·
{E
â€Mp0qNptq
MptqNp0q
Ë‡Ë‡ Fs
È·
â€œ Mp0q
Np0q E
â€ Sptq
Mptq
Ë‡Ë‡ Fs
È· Np0q
Mp0q
Mpsq
Npsq â€œ Spsq
Npsq.
The proof of Theorem 3.100 is complete now.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
â€¢ STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
â€¢ PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
â€¢ STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
217 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Note that the measures Q and QËš are equivalent because of the strictly posi-
tiveness of the Radon-Nikodym derivative. We already mention the following
theorem which transforms the dynamics of a process under Q to a process under
QËš.
3.101. Theorem. Let Q be an equivalent martingale measure for tMptqutÄ›0 and
let QËš be deï¬ned by equation (3.295). Assume tXptq : 0 Ä t Ä tu a diï¬€usion
process with dynamics under Q
dXptq â€œ b pt, Xptqq dt ` Ïƒ pt, Xptqq dWptq.
Let also Mptq and Nptq have dynamics under Q given by
dMptq â€œ mM dt ` ÏƒM dWptq,
dNptq â€œ mN dt ` ÏƒN dWptq.
Then the dynamics of tXptq : 0 Ä t Ä tu under QËš is given by
dXptq â€œ b pt, Ï‰q dt Â´ Ïƒ pt, Ï‰q
Ë† ÏƒM
Mptq Â´ ÏƒN
Nptq
Ë™
dt ` Ïƒ pt, Ï‰q dW Ëšptq,
where
W Ëšptq â€œ Wptq `
Å¼ t
0
Ë† ÏƒM
Mpsq Â´ ÏƒN
Npsq
Ë™
ds.
Proof. It is clear that we want to apply Girsanovâ€™s Theorem 3.94. But then
we need to know how Î¸ pt, Ï‰q in expression (3.274) looks like. From expression
(3.275) we know that
dÎ“t â€œ Â´Î¸ pt, Â¨q Î“t dWptq.
(3.296)
On the other hand:
dÎ“t â€œ Mp0q
Np0q d
Ë† Nptq
Mptq
Ë™
â€œ Mp0q
Np0q
dNptqMptq Â´ NptqdMptq
Mptq2
â€œ
Mp0q
Np0qMptq2 ppmN dt ` ÏƒN dWptqq Mptq Â´ Nptq pmM dt ` ÏƒM dWptqqq .
(3.297)
Because tÎ“t : 0 Ä t Ä Tu is a martingale we must have that the coeï¬ƒcient of dt
is 0, hence
dÎ“t â€œ
Mp0q
Np0qMptq2 pÏƒN dWptqMptq Â´ NptqÏƒM dWptqq
â€œ
Ë† ÏƒN
Nptq Â´ ÏƒM
Mptq
Ë™
Î“t dWptq.
Comparing this with (3.296) we have that
Î¸pt, Ï‰q â€œ ÏƒM
Mptq Â´ ÏƒN
Nptq.
Finally applying Girsanovâ€™s Theorem 3.94 to this we have
dXptq â€œ b pt, Ï‰q dt Â´ Ïƒ pt, Ï‰q
Ë† ÏƒM
Mptq Â´ ÏƒN
Nptq
Ë™
dt ` Ïƒ pt, Ï‰q dW Ëšptq,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
218 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
with
W Ëšptq â€œ Wptq `
Å¼ t
0
Ë† ÏƒM
Mpsq Â´ ÏƒN
Npsq
Ë™
ds.
Altogether this completes the proof of Theorem 3.101.
â–¡
In order to make the link between the short rate rptq and the instantaneous
forward rate fpt, Tq, we introduce a new measure QT. Suppose again that Q is
the risk neutral measure w.r.t. the money market and E the expectation w.r.t.
Q.
3.102. Definition. Take T Ä› 0. The forward measure QT is deï¬ned on FT by
setting
Î“T :â€œ dQT
dQ â€œ Mp0q
MpTqPpT, TqP p0, Tq â€œ eÂ´
ÅŸT
0 rpsq dsP p0, Tq ,
where
Mptq â€œ e
ÅŸt
0 rpsq ds,
and P pt, Tq â€œ E
â€
eÂ´
ÅŸT
t rpsq ds Ë‡Ë‡ Ft
Ä±
.
By the previous theorem we conclude that QT is an equivalent martingale mea-
sure which has a bond with maturity T as numÂ´eraire.
For t Äƒ T we can easily calculate Î“t as follows:
Î“t :â€œ E
â€œ
Î“T
Ë‡Ë‡ Ft
â€°
â€œ
Mp0q
P p0, TqE
â€PpT, Tq
MpTq
Ë‡Ë‡ Ft
È·
â€œ
1
P p0, Tq
P pt, Tq
Mptq
â€œ eÂ´
ÅŸt
0 rpsq ds P pt, Tq
P p0, Tq,
where we used in the second to last equality that Q has tMptqutÄ›0 as numÂ´eraire.
Now we have all theoretical background information to formulate the third proof
of Theorem 3.96.
Third proof of Theorem 3.96. Denote as before the expectation w.r.t.
Q by E and the expectation w.r.t. QT by ET. We have by Theorem 3.99 that
for any FT-measurable random variable X and t Ä T
ET rXjFts â€œ Î“Â´1
t E
â€œ
XÎ“T
Ë‡Ë‡ Ft
â€°
â€œ E
â€
X Î“T
Î“t
Ë‡Ë‡ Ft
È·
â€œ E
â€
X MptqPpT, Tq
MpTqP pt, Tq
Ë‡Ë‡ Ft
È·
â€œ E
Â«
X eÂ´
ÅŸT
t rpsq ds
P pt, Tq
ï¬€
.
We want to express the forward rate in terms of the short rate. We got a formula
for the bonds price in function of both of them. Diï¬€erentiating expression (16)
towards T gives
BP pt, Tq
BT
â€œ E
â€
Â´rpTqeÂ´
ÅŸT
t rpsq ds Ë‡Ë‡ Ft
Ä±
â€œ ET â€œ
Â´rpTqP pt, Tq
Ë‡Ë‡ Ft
â€°
â€œ Â´ET â€œ
rpTq
Ë‡Ë‡ Ft
â€°
P pt, Tq .
(3.298)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
219 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In the second step we used the above reasoning with X â€œ Â´rpTqP pt, Tq. Dif-
ferentiating now formula (3.294) with respect to T gives
BP pt, Tq
BT
â€œ Â´P pt, Tq fpt, Tq.
(3.299)
Comparing (3.298) en (3.299) we get the link between short rate and forward
rate
fpt, Tq â€œ ET â€œ
rpTq
Ë‡Ë‡ Ft
â€°
.
(3.300)
Considering the right hand side of (3.300) we will need to describe the dynamics
of rptq under QT . Applying ItË†oâ€™s formula on fpt, xq â€œ e
ÅŸt
0 rpsq ds we immediately
ï¬nd that dMptq â€œ rptqMptq dt. In the notation of Theorem 3.101 we thus have
ÏƒM â€œ 0. If we then apply this theorem with Xptq â€œ rptq, QËš â€œ QT, Ïƒ pt, Xptqq â€œ
Ïƒ, b pt, Xptqq â€œ a pb Â´ rptqq and ÏƒN â€œ Â´ÏƒA pt, Tq P pt, Tq we obtain:
drptq â€œ
`
ab Â´ Ïƒ2A pt, Tq Â´ arptq
Ë˜
dt ` Ïƒ dW Tptq
â€œ a
Ë†
b Â´ Ïƒ2
a2
`
1 Â´ eÂ´apTÂ´tqË˜
Â´ rt
Ë™
dt ` Ïƒ dW Tptq
(3.301)
where W Tptq is the QT-Brownian motion deï¬ned by
W Tptq â€œ Wptq ` Ïƒ
Å¼ t
0
A ps, Tq ds.
Expression (3.301) resembles an ordinary Vasicek process, except that the term
b Â´ Ïƒ2
a2
`
1 Â´ eÂ´apTÂ´tqË˜
does depend upon t and is thus not a constant. However,
we will use a similar reasoning as in the classical situation to solve the SDE for
rptq on the interval rt, Ts. First, we apply ItË†oâ€™s formula on gpt, xq â€œ eatx:
d
`
eatrptq
Ë˜
â€œ abeat dt Â´ 1 Â´ eÂ´apTÂ´tq
a
Ïƒ2eat dt ` Ïƒeat dW Tptq
â€œ abeat dt Â´ Ïƒ2
a
`
eat Â´ eÂ´apTÂ´2tqË˜
dt ` Ïƒeat dW Tptq.
Integrating from t to T gives
eaTrpTq Â´ eatrptq
â€œ ab
Å¼ T
t
eas ds Â´ Ïƒ2
a
Å¼ T
t
`
eas Â´ eÂ´apTÂ´2sqË˜
ds ` Ïƒ
Å¼ T
t
eas dW Tpsq
â€œ b
`
eaT Â´ eatË˜
Â´ Ïƒ2
a
â€1
a
`
eaT Â´ eatË˜
Â´ 1
2a
`
eaT Â´ eÂ´apTÂ´2tqË˜È·
` Ïƒ
Å¼ T
t
eas dW Tpsq
â€œ b
`
eaT Â´ eatË˜
Â´ Ïƒ2
2a2
Â´
eaT Â´ 2eat ` eÂ´apT Â´2tqÂ¯
` Ïƒ
Å¼ T
t
eas dW Tpsq.
Thus we have that
rpTq â€œ rptqeÂ´apTÂ´tq ` b
`
1 Â´ eÂ´apTÂ´tqË˜
Â´ Ïƒ2
2a2
`
1 Â´ 2eÂ´apTÂ´tq ` eÂ´2apTÂ´tqË˜
` Ïƒ
Å¼ T
t
eÂ´apTÂ´sq dW Tpsq.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
220 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
And hence,
fpt, sq â€œ Es â€œ
rpsq
Ë‡Ë‡ Ft
â€°
â€œ rptqeÂ´apsÂ´tq ` b
`
1 Â´ eÂ´apsÂ´tqË˜
Â´ Ïƒ2
a2
`
1 Â´ 2eÂ´apsÂ´tq ` eÂ´2apsÂ´tqË˜
â€œ rptqeÂ´apsÂ´tq `
Ë†
b Â´ Ïƒ2
2a2
Ë™ `
1 Â´ eÂ´apsÂ´tqË˜
` Ïƒ2
2a2
`
eÂ´apsÂ´tq Â´ eÂ´2apsÂ´tqË˜
.
Integrating results in
Å¼ T
t
Es â€œ
rpsq
Ë‡Ë‡ Ft
â€°
ds â€œ rptq
a
`
1 Â´ eÂ´apTÂ´tqË˜
`
Ë†
b Â´ Ïƒ2
2a2
Ë™ Ë†
T Â´ t Â´ 1 Â´ eÂ´apTÂ´tq
a
Ë™
` Ïƒ2
2a3
`
1 Â´ eÂ´apTÂ´tqË˜
Â´ Ïƒ2
4a3
`
1 Â´ eÂ´2apTÂ´tqË˜
â€œ rptqA pt, Tq `
Ë†
b Â´ Ïƒ2
2a2
Ë™
pT Â´ t Â´ A pt, Tqq ` Ïƒ2
4aA pt, Tq2
â€œ rptqA pt, Tq Â´ Dpt, Tq.
(3.302)
Reminding formula (3.294) and formula (3.300) we ï¬nd again that
Ppt, Tq â€œ eÂ´Apt,Tqrt`Dpt,Tq.
This completes the third proof of Theorem 3.96.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
221 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
9. A version of Ferniqueâ€™s theorem
The following theorem is due to Fernique. We follow the proof of H.H. Kuo
[77].
3.103. Theorem. Let pâ„¦, F, Pq be a probability space and let X : â„¦Ã‘ Rd be a
Gaussian vector with mean zero. Put
Î± â€œ sup
u,vÄ…0
1
pu ` vq2 log P p|X| Ä vq
P p|X| Ä… uq.
(3.303)
Then Î± Ä… 0 and
E
Ë†
exp
Ë†1
2Î· |X|2
Ë™Ë™
Äƒ 8 for Î· Äƒ Î±.
(3.304)
For the proof we shall need two lemmas. The ï¬rst one contains the main idea.
3.104. Lemma. Let pâ„¦, F, Pq and X be as in Theorem 3.103. Let s Ä… 0 be such
that P p|X| Ä sq Ä… 0 and ï¬x t Ä… s. Then
P p|X| Ä… tq
P p|X| Ä sq Ä
Ëœ
P
`
|X| Ä… pt Â´ sq{
?
2
Ë˜
P p|X| Ä sq
Â¸2
.
(3.305)
Proof. Let pâ„¦b â„¦, F b F, P b Pq be the tensor product space of pâ„¦, F, Pq
with itself and deï¬ne Xi, i â€œ 1, 2, by XipÏ‰1, Ï‰2q â€œ XpÏ‰iq. Then the variables
X1 and X2 are independent with respect P b P and their P b P-distribution
coincides with the P-distribution of X. We shall prove Lemma 3.104. for s â€œ v
and t â€œ u
?
2 ` v. Since the vector pX1, X2q is Gaussian with respect to P b P
and since the components of X1 Â´ X2 are uncorrelated with the components
of X1 ` X2 (with respect to the probability P b P), it follows that the vectors
X1 Â´ X2 and X1 ` X2 are independent. Notice that
ÅŸ
XdP â€œ
ÅŸ
X1dP b P â€œ
ÅŸ
X2dP b P â€œ 0 and that the covariance matrices of X, of pX1 Â´ X2q {
?
2 and
of pX1 ` X2q {
?
2 all coincide. It follows that the joint distributions of pX1, X2q
and of
Ë†X1 Â´ X2
?
2
, X1 ` X2
?
2
Ë™
are the same as well. Hence the following (in-
)equalities are now self-explanatory:
P p|X| Ä vq P
Â´
|X| Ä… u
?
2 ` v
Â¯
â€œ P b P p|X1| Ä vq Ë† P b P
Â´
|X2| Ä… u
?
2 ` v
Â¯
â€œ P b P
Â´
|X1| Ä v
and
|X2| Ä… u
?
2 ` v
Â¯
â€œ P b P
Â´
|X1 Â´ X2| Ä v
?
2
and
|X1 ` X2| Ä… 2u ` v
?
2
Â¯
Ä P b P
Â´Ë‡Ë‡|X1| Â´ |X2|
Ë‡Ë‡ Ä v
?
2
and
|X1| ` |X2| Ä… 2u ` v
?
2
Â¯
Ä P b P p|X1| Ä… u and
|X2| Ä… uq â€œ P p|X| Ä… uq2 .
(3.306)
Inequality (3.305) in Lemma 3.104 follows from (3.306).
â–¡
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
222 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.105. Lemma. Let pâ„¦, F, Pq and X be as in Theorem 3.103. Let v Ä… 0 be such
that P p|X| Ä vq Ä… 0 and ï¬x â„“P N and ï¬x u Ä… 0. Then the following inequality
is valid:
P
Â´
|X| Ä… u
`?
2
Ë˜â„“` v
Â´`?
2
Ë˜â„“Â´ 1
Â¯ `?
2 ` 1
Ë˜Â¯
P p|X| Ä vq
Ä
Ë†P p|X| Ä… uq
P p|X| Ä vq
Ë™2â„“
.
(3.307)
Proof. For â„“â€œ 0 this assertion is trivial and for â„“â€œ 1 it is the same
as inequality (3.305) in Lemma 3.104. Next suppose that (3.307) is already
established for â„“. We are going to prove (3.307) with â„“` 1 replacing â„“. Again
we invoke inequality (3.305) to obtain
P
Â´
|X| Ä… u
`?
2
Ë˜â„“`1 ` v
Â´`?
2
Ë˜â„“`1 Â´ 1
Â¯ `?
2 ` 1
Ë˜Â¯
P p|X| Ä vq
Ä
Â¨
Ë
P
Â´
|X| Ä…
Â´
u
`?
2
Ë˜â„“`1 ` v
Â´`?
2
Ë˜â„“`1 Â´ 1
Â¯ `?
2 ` 1
Ë˜
Â´ v
Â¯
{
?
2
Â¯
P p|X| Ä vq
Ë›
â€š
2
â€œ
Â¨
Ë
P
Â´
|X| Ä… u
`?
2
Ë˜â„“` v
Â´`?
2
Ë˜â„“Â´ 1
Â¯ `?
2 ` 1
Ë˜Â¯
P p|X| Ä vq
Ë›
â€š
2
(induction hypothesis)
Ä
Ë†P p|X| Ä… uq
P p|X| Ä vq
Ë™2â„“`1
.
(3.308)
The inequality in (3.308) completes the proof of Lemma 3.105.
â–¡
Proof of Theorem 3.103. If X â€ 0, then there is nothing to prove. So
suppose X â€° 0 and choose strictly positive real numbers u and v for which
P p|X| Ä… uq
P p|X| Ä vq Äƒ 1. Put
Î±pu, vq â€œ
1
pu ` vq2 log P p|X| Ä vq
P p|X| Ä… uq and
Î²pu, vq â€œ P p|X| Ä vq
Ë†P p|X| Ä… uq
P p|X| Ä vq
Ë™v2 `
1 `
?
2
Ë˜2
2 pu ` vq2
.
Then Î±pu, vq Ä… 0 and Î²pu, vq â€œ P p|X| Ä vq exp
Â´
Â´ 1
2Î±pu, vqv2 `
1 `
?
2
Ë˜2Â¯
Äƒ 1.
For s Ä› u choose â„“P N in such a way that
u
Â´?
2
Â¯â„“`1
` v
Ë†Â´?
2
Â¯â„“`1
Â´ 1
Ë™ Â´?
2 ` 1
Â¯
Ä… s
Ä› u
Â´?
2
Â¯â„“
` v
Ë†Â´?
2
Â¯â„“
Â´ 1
Ë™ Â´?
2 ` 1
Â¯
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
223 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Then
2â„“Ä…
`
s ` v
`
1 `
?
2
Ë˜Ë˜2
2 pu ` vq2
Ä…
s2
2 pu ` vq2 ` v2 `
1 `
?
2
Ë˜2
2 pu ` vq2
and hence
P p|X| Ä… sq Ä P
Ë†
|X| Ä… u
Â´?
2
Â¯â„“
` v
Ë†Â´?
2
Â¯â„“
Â´ 1
Ë™ Â´?
2 ` 1
Â¯Ë™
(inequality (3.307) in Lemma 3.105)
Ä P p|X| Ä vq
Ë†P p|X| Ä… uq
P p|X| Ä vq
Ë™2â„“
Ä Î²pu, vq exp
Ë†
Â´1
2Î±pu, vqs2
Ë™
Äƒ exp
Ë†
Â´1
2Î±pu, vqs2
Ë™
.
(3.309)
If 0 Ä Î· Äƒ Î±, then we choose u, v Ä… 0 in such a way that Î± Ä… Î±pu, vq Ä… Î·.
Then, for s Ä› u, P p|X| Ä… sq Äƒ exp
`
Â´ 1
2Î±pu, vqs2Ë˜
. Consequently, we get from
(3.309):
E
Ë†
exp
Ë†1
2Î· |X|2
Ë™
: |X| Ä… u
Ë™
â€œ
Å¼ 8
0
P
Ë†
exp
Ë†1
2Î· |X|2
Ë™
Ä… Î¾, |X| Ä… u
Ë™
dÎ¾
(substitute Î¾ â€œ exp
`1
2Î·s2Ë˜
)
Ä exp
Ë†1
2Î·u2
Ë™
P p|X| Ä… uq ` Î·
Å¼ 8
u
P p|X| Ä… sq exp
Ë†1
2Î·s2
Ë™
sds
Ä exp
Ë†1
2Î·u2
Ë™
P p|X| Ä… uq ` Î·
Å¼ 8
u
exp
Ë†
Â´1
2 pÎ±pu, vq Â´ Î·q s2
Ë™
sds
Ä exp
Ë†1
2Î·u2
Ë™
`
Î·
Î±pu, vq Â´ Î· exp
Ë†
Â´1
2 pÎ±pu, vq Â´ Î·q u2
Ë™
Ä
Î±pu, vq
Î±pu, vq Â´ Î· exp
Ë†1
2Î·u2
Ë™
.
(3.310)
From (3.310) we infer
E
Ë†
exp
Ë†1
2Î· |X|2
Ë™Ë™
Ä 2Î±pu, vq Â´ Î·
Î±pu, vq Â´ Î· exp
Ë†1
2Î·u2
Ë™
.
(3.311)
Inequality (3.311) yields the desired result in Theorem 3.103.
â–¡
10. Miscellaneous
We begin this section with the Doobâ€™s optional stopping property for discrete
time submartingales.
Let tXpnq : n P Nu be a submartingale relative to the
ï¬ltration tFn : n P Nu. Here the random variables Xpnq are deï¬ned on a prob-
ability space pâ„¦, F, Pq. The following result was used in inequality (3.164), the
basic step for the continuous time version of the following proposition.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
224 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.106. Proposition. Let Ï„ be a stopping time. The process
tXpminpn, Ï„qq : n P Nu
is a submartingale with respect to the ï¬ltration tFn : n P Nu as well as with
respect to the ï¬ltration
â£
Fminpn,Ï„q : n P N
(
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
â€œThe perfect start 
of a successful, 
international career.â€
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
225 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Let m and n be natural numbers with m Äƒ n and let A be a
member of Fm. Then we have
E pX pminpn, Ï„qq 1Aq Â´ E pX pminpm, Ï„qq 1Aq
â€œ
nÃ¿
kâ€œm`1
tE pX pminpk, Ï„qq 1Aq Â´ E pX pminpk Â´ 1, Ï„qq 1Aqu
â€œ
nÃ¿
kâ€œm`1
â£
E
`
pX pminpk, Ï„qq Â´ X pminpk Â´ 1, Ï„qqq 1AXtÏ„Ä›ku
Ë˜(
â€œ
nÃ¿
kâ€œm`1
E
â£
E
`
pX pminpk, Ï„qq Â´ X pminpk Â´ 1, Ï„qqq 1AXtÏ„Ä›ku
Ë˜ Ë‡Ë‡ FkÂ´1
(
(the event AXtÏ„ Ä› ku belongs to FkÂ´1 for k Ä› m`1, and the variable Xpk Â´1q
is FkÂ´1-measurable)
â€œ
nÃ¿
kâ€œm`1
E
``
E
`
Xpkq
Ë‡Ë‡ FkÂ´1
Ë˜
Â´ Xpk Â´ 1q
Ë˜
1AXtÏ„Ä›ku
Ë˜
(submartingale property of the process tXpkq : k P Nu)
Ä›
nÃ¿
kâ€œm`1
E
`
0 Ë† 1AXtÏ„Ä›ku
Ë˜
â€œ 0.
(3.312)
The inequality in (3.312) proves that the process tXpminpk, Ï„qq : k P Nu is a sub-
martingale for the ï¬ltration tFk : k P Nu. Since the Ïƒ-ï¬eld Fminpk,Ï„ is contained
in the Ïƒ-ï¬eld Fk, k P N, it also follows that the process
tXpminpk, Ï„qq : k P Nu
is also a submartingale with respect to the ï¬ltration
â£
Fminpk,Ï„q : k P N
(
because
we have
E
`
Xpminpm ` 1, Ï„qq
Ë‡Ë‡ Fminpm,Ï„q
Ë˜
â€œ E
`
E
`
Xpm ` 1q
Ë‡Ë‡ Fm
Ë˜ Ë‡Ë‡ Fminpm,Ï„q
Ë˜
Ä› E
`
E
`
Xpminpm ` 1, Ï„qq
Ë‡Ë‡ Fm
Ë˜ Ë‡Ë‡ Fminpm,Ï„q
Ë˜
(employ (3.312))
Ä› E
`
Xpminpm, Ï„qq
Ë‡Ë‡ Fminpm,Ï„q
Ë˜
â€œ Xpminpm, Ï„qq.
(3.313)
The inequalities (3.312) and (3.313) together prove the results in Theorem 3.106.
â–¡
Next we prove Doobâ€™s maximal inequality for martingales.
3.107. Proposition. Let tMpnq : n P Nu be a martingale. Put
MpnqËš â€œ max
kÄn |Mpnq|.
The following inequalities are valid:
P rMpnqËš Ä› Î»s Ä 1
Î»E r|Mpnq| : MpnqËš Ä› Î»s ;
(3.314)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
226 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
P rMpnqËš Ä› Î»s Ä 1
Î»2E
â€œ
|Mpnq|2 : MpnqËš Ä› Î»
â€°
.
(3.315)
Let tMptq : t Ä› 0u be a continuous time martingale that is right continuous and
possesses left limits.
Put MptqËš â€œ sup0ÄsÄt |Mpsq|.
Again inequalities like
(3.314) and (3.315) are true:
P tMptqËš Ä› Î»u Ä 1
Î»E t|Mptq| : MptqËš Ä› Î»u ;
(3.316)
P tMptqËš Ä› Î»u Ä 1
Î»2E
â£
|Mptq|2 : MptqËš Ä› Î»
(
.
(3.317)
Proof. We begin by establishing inequality (3.314). Deï¬ne the events Ak,
1 Ä k Ä n, by A0 â€œ t|Mp0q| Ä› Î»u,
Ak â€œ t|Mpjq| Äƒ Î», 0 Ä j Ä k Â´ 1, |Mpkq| Ä› Î»u ,
1 Ä k Ä n.
Then Å¤n
kâ€œ0 Ak â€œ tMpnqËš Ä› Î»u, Ak X Aâ„“â€œ H, for k Â­â€œ â„“, 1 Ä k, â„“Ä n, and
Ak is Fk-measurable for 1 Ä k Ä n. Moreover on the event Ak the inequality
|Mpkq| Ä› Î» is valid. From the martingale property it then follows that:
P pMpnqËš Ä› Î»q â€œ
nÃ¿
kâ€œ0
P pAkq Ä 1
Î»
nÃ¿
kâ€œ0
E p1Ak |Mpkq|q
â€œ 1
Î»
nÃ¿
kâ€œ0
E
`
1Ak
Ë‡Ë‡E
`
Mpnq
Ë‡Ë‡ Fk
Ë˜Ë‡Ë‡Ë˜
â€œ 1
Î»
nÃ¿
kâ€œ0
E
`Ë‡Ë‡E
`
1AkMpnq
Ë‡Ë‡ Fk
Ë˜Ë‡Ë‡Ë˜
Ä 1
Î»
nÃ¿
kâ€œ0
E
`
E
`
1Ak |Mpnq|
Ë‡Ë‡ Fk
Ë˜Ë˜
â€œ 1
Î»
nÃ¿
kâ€œ0
E p1Ak |Mpnq|q â€œ 1
Î»E p|Mpnq| : MpnqËš Ä› Î»q .
(3.318)
Notice that inequality (3.318) is the same as (3.314).
The proof of (3.315)
goes along the same lines. The fact is used that the process
â£
|Mpnq|2 : n P N
(
constitutes a submartingale. The details read as follows. The events Ak, 1 Ä
k Ä n, are deï¬ned as in the proof of (3.314). The argument in (3.318) is adapted
as below:
P pMpnqËš Ä› Î»q â€œ
nÃ¿
kâ€œ0
P pAkq Ä 1
Î»2
nÃ¿
kâ€œ0
E
`
1Ak |Mpkq|2Ë˜
Ä 1
Î»2
nÃ¿
kâ€œ0
E
`
1AkE
`
|Mpnq|2 Ë‡Ë‡ Fk
Ë˜Ë˜
Ä 1
Î»2
nÃ¿
kâ€œ0
E
`
1Ak |Mpnq|2Ë˜
â€œ 1
Î»2
nÃ¿
kâ€œ0
E
`
1Ak |Mpnq|2Ë˜
â€œ 1
Î»2E
`
|Mpnq|2 : MpnqËš Ä› Î»
Ë˜
.
(3.319)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
227 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Again we notice that (3.319) is the same as (3.315). The inequalities in (3.316)
and (3.317) are based on a time discretization of the martingale tMptq : t Ä› 0u.
Therefore we write Npjq :â€œ M pj2Â´ntq and we notice that tNpjq : j P Nu is
a martingale for the ï¬ltration tFj2Â´nt : j P Nu.
From (3.314) we obtain the
inequality:
P
Ë†
max
0ÄjÄ2n |Npjq| Ä› Î»
Ë™
Ä 1
Î»E p|Mptq| : MptqËš Ä› Î»q .
(3.320)
Inequality (3.317) is obtained from (3.320) upon letting tend n to 8. The proof
of (3.317) follows in the same manner from (3.315).
â–¡
We continue with a proof of the (DL)-property of martingales. More precisely
we shall prove the following proposition.
3.108. Proposition. Let tMpsq : s Ä› 0u be a right continuous martingale on
the probability space pâ„¦, F, Pq. Fix t Ä› 0. Then the collection of random vari-
ables
tMpÏ„q : 0 Ä Ï„ Ä t, Ï„ stopping timeu
is uniformly integrable.
Proof. Fix a stopping time 0 Ä Ï„ Ä t and write Ï„n â€œ min p2Â´nr2nts, tq.
Then 0 Ä Ï„n Ä t and every Ï„n is a stopping time. Moreover Ï„n Ã“ Ï„ if n tends
to 8.
Since the pair pMpÏ„nq, Mptqq is a martingale for the pair of Ïƒ-ï¬elds
pFÏ„n, Ftq (Use Proposition 3.106 for martingales), the pair p|M pÏ„nq| , |Mptq|q is
a submartingale with respect to the same pair of Ïƒ-ï¬elds. As a consequence we
obtain:
E p|MpÏ„q| : |MpÏ„q| Ä› Î»q â€œ E
Â´
lim inf
nÃ‘8
Ë‡Ë‡MpÏ„nq1t|MpÏ„nq|Ä›Î»u
Ë‡Ë‡
Â¯
(Fatouâ€™s lemma)
Ä lim inf
nÃ‘8 E
`
|MpÏ„nq| 1t|MpÏ„nq|Ä›Î»u
Ë˜
(submartingale property)
Ä lim inf
nÃ‘8 E
`
E
`
|Mptq|
Ë‡Ë‡ FÏ„n
Ë˜
1t|MpÏ„nq|Ä›Î»u
Ë˜
â€œ lim inf
nÃ‘8 E
`
|Mptq| 1t|MpÏ„nq|Ä›Î»u
Ë˜
â€œ lim inf
nÃ‘8 E p|Mptq| : |M pÏ„nq| Ä› Î»q
Ä E p|Mptq| : |Mptq| Ä› Î»q .
(3.321)
This proves Proposition 3.108.
â–¡
Remark. In the proof of Proposition 3.108. we did use a discrete approximation
of a stopping time. However we could have avoided this and consider directly the
pair pMpÏ„q, Mptqq. From Proposition 3.107 we see that this pair is a martingale
with respect to the pair of Ïƒ-ï¬elds pFÏ„, Ftq. This will then imply inequality
(3.321) with Ï„ replacing Ï„n.
On the other hand the discrete approximation
of stopping times as performed in the proof of Proposition 3.108 is kind of
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
228 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
a standard procedure for passing from discrete time valued stopping times to
continuous time valued stopping times. This is a good reason to insert this kind
of argument.
The main result of Section 3 of this chapter says that linear operators in C0pEq
which maximally solve the martingale problem are generators of Feller semi-
groups and conversely. In the sequel we want to verify the claim in the example
of Section 3. Its statement is correct, but its proof is erroneous. Example 3.49
in Section 3 reads as follows.
3.109. Example. Let L0 be an unbounded generator of a Feller semigroup in
C0pEq and let Âµk and Î½k, 1 Ä k Ä n, be ï¬nite (signed) Borel measures on E.
Deï¬ne the operator Lâƒ—Âµ,âƒ—Î½ as follows:
D pLâƒ—Âµ,âƒ—Î½q â€œ
nÄ
kâ€œ1
"
f P DpL0q :
Å¼
L0fdÂµk â€œ
Å¼
fdÎ½k
*
,
Lâƒ—Âµ,âƒ—Î½f â€œ L0f,
f P D pLâƒ—Âµ,âƒ—Î½q .
Then the martingale problem is uniquely solvable for Lâƒ—Âµ,âƒ—Î½. In fact let
tpâ„¦, F, Pxq , pXptq : t Ä› 0q , pÏ‘t : t Ä› 0q , pE, Equ
be the strong Markov process associated to the Feller semigroup generated by
L0. Then P â€œ Px solves the martingale problem
(a) For every f P DpLâƒ—Âµ,âƒ—Î½q the process
fpXptqq Â´ fpXp0qq Â´
Å¼ t
0
Lâƒ—Âµ,âƒ—Î½fpXpsqqds,
t Ä› 0,
is a P-martingale;
(b) PpXp0q â€œ xq â€œ 1,
uniquely. In particular we may take E â€œ r0, 1s, L0f â€œ 1
2f 2,
DpL0q â€œ
â£
f P C2r0, 1s : f 1p0q â€œ f 1p1q â€œ 0
(
,
Âµk pIq â€œ
ÅŸÎ²k
Î±k 1Ipsqds, Î½k â€œ 0, 0 Ä Î±k Äƒ Î²k Ä 1, 1 Ä k Ä n. Then L0 generates
the Feller semigroup of reï¬‚ected Brownian motion: see Liggett [86], Example
5.8, p. 45. For the operator Lâƒ—Âµ,âƒ—Î½ the martingale problem is uniquely (but not
maximally uniquely) solvable. However it does not generate a Feller semigroup.
From the result in Theorem 3.45 this can be seen as follows. Deï¬ne the func-
tionals Î›j : DpL0q Ã‘ C, 1 Ä j Ä n, as follows:
Î›jpfq â€œ
Å¼
L0fdÂµj Â´
Å¼
fdÎ½j,
1 Ä j Ä n.
We may and do suppose that the functionals Î›j, 1 Ä j Ä n, are linearly
independent and that their linear span does not contain linear combinations of
Dirac measures. The latter implies that, for every x0 P E and for every function
u P DpL0q, the convex subsets
D pL1q X ttg P C0pEq : Re g Ä Re gpx0qu ` uu
and
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
229 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
D pL1q X tth P C0pEq : Re h Ä› Re hpx0qu ` uu
are non-void. The latter follows from a Hahn-Banach argument. Hopefully,
it will also imply that the quantities in (3.322) and (3.323) coincide.
Since
DpL2
0q forms a core for L0 we may choose functions uk, 1 Ä k Ä n, such that
Î›jpukq â€œ Î´jk and such that every uk, 1 Ä k Ä n is in the vector of the two
spacesâ£
u P DpL2
0q : Rp1qu P DpL1q
(
and
â£
u P DpL2
0q : Rp2qu P DpL1q
(
.
As operator L1 we take L1 â€œ Lâƒ—Âµ,âƒ—Î½ and for T we take Tf â€œ Å™n
jâ€œ1 Î›jpfquk,
f P DpL0q.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
â–¶â–¶enroll by September 30th, 2014 and 
â–¶â–¶save up to 16% on the tuition!
â–¶â–¶pay in 10 installments / 2 years
â–¶â–¶Interactive Online education
â–¶â–¶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
230 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The remainder of this section is devoted to the proof of the following result.
Whenever appropriate we write RpÎ»q for the operator pÎ»I Â´ L0qÂ´1.
3.110. Theorem. Let L0 be the generator of a Feller semigroup in C0pEq and
let L1 and T be linear operators with the following properties: the operator I Â´T
has domain DpL0q and range D pL1q, L1 veriï¬es the maximum principle, the
vector sum of the spaces RpI Â´ Tq and R pL1pI Â´ Tqq is dense in C0pEq, and
the operator L1pI Â´ Tq Â´ pI Â´ TqL0 can be considered as a continuous linear
operator in the domain of L0. More precisely, it is assumed that
lim sup
Î»Ã‘8
}pL1pI Â´ Tq Â´ pI Â´ TqL0q RpÎ»q} Äƒ 1.
Then there exists at most one linear extension L of the operator L1 for which
LT is bounded and that generates a Feller semigroup.
In particular, if the
martingale problem is solvable for L1, then it is uniquely solvable for L1.
Before we actually prove this result we like to make some comments. In order
to have existence and uniqueness for the extension L on RpTq it suï¬ƒces that
for every v P RpTq and for every x0 P E the following two expressions are equal:
lim
ÏµÃ“0
inf
fPDpL1q
"
Re L1fpx0q : inf
yPE Re pfpyq Â´ vpyqq Ä… Re pfpx0q Â´ vpx0qq Â´ Ïµ
*
;
(3.322)
lim
ÏµÃ“0
sup
fPDpL1q
"
Re L1fpx0q : sup
yPE
Re pfpyq Â´ vpyqq Äƒ Re pfpx0q Â´ vpx0qq ` Ïµ
*
.
(3.323)
This common value is then by deï¬nition Re L2vpx0q. The value of L2vpx0q is
then given by rL2vs px0q â€œ Re rL2vs px0q Â´ iRe rL2pivqs px0q for v P RpTq. Let
Î›j, 1 Ä j Ä n, be as in the example of section 1. For every x0 P E and for
every 1 Ä k Ä n there exist functions gk and hk P DpL0q with the following
properties: Î›â„“pgkq â€œ Î›â„“phkq â€œ Î´k,â„“, Re gkpxq Ä Re gkpx0q and Re hkpx0q Ä
hkpxq for all x P E and Re L1 phk Â´ gkq px0q â€œ 0. It then readily follows that
the two expressions in (3.322) and (3.323) are equal for functions v in the linear
span of u1, . . . , un. Notice that the function Re hk attains its minimum at x0
and that the function Re gk attains its maximum at x0.
In order to deï¬ne
rL1uks px0q we choose functions gk and hk with Î›â„“pgkq â€œ Re Î›â„“phkq â€œ Â´Î´k,â„“in
such a way that the function Re gk attains its maximum at x0 and that the
function Re hk attains its minimum at the same point x0. Moreover we may
and do suppose that Re L1 pgk Â´ hkq px0q â€œ 0. The value rL2uks px0q is then
given by rL2uks px0q â€œ rL1 pgk ` ukqs px0q â€œ rL1 phk ` ukqs px0q.
Proof of Theorem 3.110. Let rL be any linear operator which extends
L1 and that has the property that its domain D
Â´
rL
Â¯
contains RpTq â€œ TDpL0q.
We also suppose that rL veriï¬es the maximum principle. Let L1 be the restriction
of rL to RpI Â´Tq and let L2 be the operator rL conï¬ned to RpTq. We shall prove
that the operator L1 has a unique extension that generates a Feller semigroup.
We start with the construction of a family of kind of intertwining operators
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
231 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
tV pÎ»q : Î» Ä… 0 and largeu. This is done as follows. The symbol RpÎ»q is always
used to denote the operator RpÎ»q â€œ pÎ»I Â´ L0qÂ´1. Deï¬ne the operator V by
V â€œ L1pI Â´ Tq Â´ pI Â´ TqL0
(3.324)
and deï¬ne the operator V pÎ»q, Î» Ä… }L2T}Î², via the equality
V pÎ»q â€œ Î» pÎ»I Â´ L2TqÂ´1 V.
(3.325)
Then we have:
pÎ»I Â´ L1q pI Â´ Tq ` pÎ»I Â´ L2q T V pÎ»q
Î»
â€œ pI Â´ Tq pÎ»I Â´ L0 Â´ V pÎ»qq .
(3.326)
An equivalent form of (3.326) is the equality
pÎ»I Â´ L1q pI Â´ Tq ` pÎ»I Â´ L2q T V pÎ»q
Î»
â€œ pI Â´ Tq ppÎ»I Â´ L0q Â´ V pÎ»qq
(3.327)
â€œ pI Â´ Tq pÎ»I Â´ L0q Â´ pI Â´ TqV pÎ»q â€œ pI Â´ Tq pI Â´ V pÎ»qRpÎ»qq pÎ»I Â´ L0q .
Next we shall prove that the martingale problem is solvable for L1. We do this
by showing that the operator L1 extends to a generator L of a Feller semigroup.
For large positive lambda we deï¬ne the operators GpÎ»q in C0pEq as follows. For
f of the form f â€œ pI Â´ Tqg, with g â€œ pI Â´ V pÎ»qRpÎ»qqpÎ»I Â´ L0qh, we write
GpÎ»qf â€œ GpÎ»qpI Â´ Tqg â€œ
Ë†
I Â´ T ` T V pÎ»q
Î»
Ë™
h.
(3.328)
and if the function f is of the form f â€œ pÎ»I Â´ L1q pI Â´ Tqg we write
GpÎ»qf â€œ GpÎ»qpÎ»I Â´ L1qpI Â´ Tqg â€œ pI Â´ Tqg.
(3.329)
If pÎ»I Â´ L1q pI Â´ Tqg1 â€œ pI Â´ Tqg2, then, since I Â´ T is mapping attaining
values in the domain of L1, we see that pI Â´ Tqg1 Â´ pI Â´ Tqg2 belongs to
DpL1q and hence the following identities are mutually equivalent (we write
g2 â€œ pI Â´ V pÎ»qRpÎ»qq pÎ»I Â´ L0q h2):
pI Â´ Tqg1 â€œ
Ë†
I Â´ T ` T V pÎ»q
Î»
Ë™
h2;
pI Â´ Tqg1 Â´ pI Â´ Tqh2 â€œ T V pÎ»q
Î»
h2;
pÎ»I Â´ L1q ppI Â´ Tqg1 Â´ pI Â´ Tqh2q â€œ pÎ»I Â´ L1q T V pÎ»q
Î»
h2;
pI Â´ Tqg2 â€œ pÎ»I Â´ L1q
Ë†
I Â´ T ` T V pÎ»q
Î»
Ë™
h2;
pI Â´ Tq pI Â´ V pÎ»qRpÎ»qq pÎ»I Â´ L0q h2 â€œ pÎ»I Â´ L1q
Ë†
I Â´ T ` T V pÎ»q
Î»
Ë™
h2;
pÎ»I Â´ L1q pI Â´ Tqh2 ` pÎ»I Â´ L2q T V pÎ»q
Î»
h2 â€œ pÎ»I Â´ L1q
Ë†
I Â´ T ` T V pÎ»q
Î»
Ë™
h2.
(3.330)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
232 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Since g2 â€œ pI Â´ V pÎ»qRpÎ»qqpÎ»I Â´ L0qh2 it follows that
Â´
Î»I Â´ rL
Â¯ `
pI Â´ Tq pg1 Â´ h2q Â´ T V pÎ»q
Î»
h2
Ë˜
pÎ»I Â´ L1q ppI Â´ Tqg1 Â´ pI Â´ Tqh2q Â´ pÎ»I Â´ L2q T V pÎ»q
Î»
h2
â€œ pI Â´ Tqg2 Â´ pÎ»I Â´ L1q pI Â´ Tqh2 Â´ pÎ»I Â´ L2q T V pÎ»q
Î»
h2
â€œ pI Â´ Tq pI Â´ V pÎ»qRpÎ»qq pÎ»I Â´ L0q h2 Â´ pÎ»I Â´ L1q pI Â´ Tqh2
Â´ pÎ»I Â´ L2q T V pÎ»q
Î»
h2
â€œ pÎ»I Â´ L1q pI Â´ Tqh2 ` pÎ»I Â´ L2q T V pÎ»q
Î»
h2 Â´ pÎ»I Â´ L1q pI Â´ Tqh2
Â´ pÎ»I Â´ L2q T V pÎ»q
Î»
h2 â€œ 0.
(3.331)
Since the operator rL veriï¬es the maximum principle, it is dissipative, and so
the zero space of Î»I Â´ rL is trivial.
We conclude from (3.331) the identity
TV pÎ»qRpÎ»qh2 â€œ pI Â´Tqg1Â´pI Â´Tqh2 and so the function TV pÎ»qRpÎ»qh2 belongs
to DpL1q. Hence it follows that (3.330) is satisï¬ed and consequently that the
operator GpÎ»q is well-deï¬ned. Next we pick h1 and h2 in the domain of L0 and
we write
f â€œ Î»pI Â´ Tq pÎ»I Â´ L0 Â´ V pÎ»qq h2 ` pÎ»I Â´ L1q pI Â´ Tq ph1 Â´ Î»h2q .
(3.332)
A calculation will yield the following identities:
GpÎ»qf â€œ pI Â´ Tqh1 ` TV pÎ»qh2;
Î»GpÎ»qf Â´ f â€œ L1pI Â´ Tqh1 ` L2TV pÎ»qh2 â€œ rL pGpÎ»qfq .
(3.333)
Consequently we get
Â´
Î»I Â´ rL
Â¯
GpÎ»qf â€œ f, for f of the form (3.332). Since
we know }V pÎ»qRpÎ»q}Î² Äƒ 1 and since, by assumption the subspace RpI Â´ Tq `
RpL1pI Â´ Tqq is dense in C0pEq, it follows that the range RpÎ»I Â´ rLq is dense
for Î» Ä… 0, Î» large. Since the operator rL satisï¬es the maximum principle and
since rL â€œ L1pI Â´ Tq ` L2T it follows that the operator L that assigns to
GpÎ»qf the function Î»GpÎ»qf Â´ f, f P RpI Â´ Tq ` RpL1pI Â´ Tqq, is well deï¬ned
and satisï¬es the maximum principle.
Below we shall show that the family
tGpÎ»q : Î» Ä… 0,
Î» largeu is a resolvent family indeed: see (3.337). The closure
of its graph contains the graph
tppI Â´ Tqh1 ` Th2, L1pI Â´ Tqh1 ` L2Th2q : h1, h2 P DpL0qu .
Denote the operator with graph tpGpÎ»qf, Î»GpÎ»qf Â´ fq : f P C0pEqu again by L.
From the previous remarks it follows that the operator L veriï¬es the maximum
principle, pÎ»I Â´ LqGpÎ»qf â€œ f for f P C0pEq and that it is densely deï¬ned. The
latter follows because its domain contains all vectors of the form
pI Â´ Tqf1 ` L1pI Â´ Tqf2 â€œ pI Â´ Tq pf1 ` pI Â´ TqL1pI Â´ Tqf2 ` TL0f2q ` TV f2.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
233 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
From a general argument it then follows that the operator L is the generator of
a Feller semigroup: for more details see [141], Theorem 2.2 page 14. Next let
h1 and h2 belong to DpL0q. Then we have
Î»
â€ºâ€ºGpÎ»q
`
pI Â´ Tqh1 ` pÎ»I Â´ L1q pI Â´ Tqh2
Ë˜â€ºâ€º
8
â€œ Î» }GpÎ»qpI Â´ Tqh1 ` pI Â´ Tqh2}8
(the operator rL is dissipative)
Ä
â€ºâ€ºâ€º
Â´
Î»I Â´ rL
Â¯ `
GpÎ»qpI Â´ Tqh1 ` pI Â´ Tqh2
Ë˜â€ºâ€ºâ€º
8
â€œ }pI Â´ Tqh1 ` pÎ»I Â´ L1q pI Â´ Tqh2}8 .
(3.334)
Since the vector sum of the spaces RpI Â´Tq and RpL1pI Â´Tqq is dense it follows
from (3.334) that the operator GpÎ»q extends as a continuous linear operator to
all of C0pEq. Moreover it is dissipative in the sense that
Î» }GpÎ»q} Ä 1.
(3.335)
Next we prove that the operator GpÎ»q is positive in the sense that f Ä› 0,
f P C0pEq, implies GpÎ»qf Ä› 0. So let f P C0pEq be non-negative. There exist
sequences of functions pgnq and phnq in the space DpL0q, for which
f â€œ lim
nÃ‘8 ppI Â´ Tqhn ` pÎ»I Â´ L1q pI Â´ Tqgnq .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
234 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Put fn â€œ pI Â´ Tqhn ` pÎ»I Â´ L1q pI Â´ Tqgn. Then
Â´
Î»I Â´ rL
Â¯
GpÎ»qfn â€œ fn (see
(3.332) and (3.333)). Since the operator rL veriï¬es the maximum principle it
follows that
Î»Re GpÎ»qfn Ä› inf
yPE Re
Â´
Î»I Â´ rL
Â¯
GpÎ»qfnpyq â€œ inf
yPE Re fnpyq
(3.336)
and hence Re Î»GpÎ»qf â€œ Re limnÃ‘8 Î»GpÎ»qfn Ä› 0. A similar argument will show
that the operator GpÎ»q sends real functions to real function and hence GpÎ»q is
positivity preserving. Next we prove that the family tGpÎ»q : Î» Ä… 0,
largeu is
a resolvent family. So let Î» and Âµ be large positive real numbers. We want to
prove the identity
GpÎ»q Â´ GpÂµq Â´ pÂµ Â´ Î»qGpÂµqGpÎ»q â€œ 0.
(3.337)
First pick the function f P DpL0q and apply the operator in (3.337) to the
function pÎ»I Â´ L1q pI Â´ Tqf and employ identity GpÎ»q
Â´
Î»I Â´ rL
Â¯
f â€œ f, for f
belonging to D
Â´
rL
Â¯
to obtain
pGpÎ»q Â´ GpÂµq Â´ pÂµ Â´ Î»qGpÂµqGpÎ»qq pÎ»I Â´ L1q pI Â´ Tqf â€œ 0.
The operator in (3.337) also sends functions in the space RpI Â´Tq to 0, because
we may apply (3.333) to see that
Â´
ÂµI Â´ rL
Â¯
pGpÎ»q Â´ GpÂµq Â´ pÂµ Â´ Î»qGpÂµqGpÎ»qq pI Â´ Tqf â€œ 0
for f P DpL0q. Finally we show that the resolvent family tGpÎ»q : Î» Ä… 0 largeu
is strongly continuous in the sense that limÎ»Ã‘8 Î»RpÎ»qf â€œ f for all f P C0pEq.
Of course it suï¬ƒces to prove this equality for a subset with a dense span. Next
we consider f P DpL0q and we estimate
}pI Â´ Tqf Â´ Î»GpÎ»qpI Â´ Tqf}8
as follows:
}pI Â´ Tqf Â´ Î»GpÎ»qpI Â´ Tqf}8
Ä 1
Î» }pÎ»I Â´ L1q ppI Â´ Tqf Â´ Î»GpÎ»qpI Â´ Tqfq}8
â€œ 1
Î» }pÎ»I Â´ L1q pI Â´ Tqf Â´ Î»pI Â´ Tqf}8 â€œ 1
Î» }L1pI Â´ Tqf}8 .
(3.338)
Again this expression tends to zero. For brevity we write
FpÎ»q â€œ pI Â´ V pÎ»qRpÎ»qqÂ´1 f.
For f P DpL0q the following equalities are valid:
pÎ»GpÎ»q Â´ Iq L1pI Â´ Tqf Â´ L1pI Â´ Tqf
â€œ Î»2GpÎ»qpI Â´ Tqf Â´ Î»pI Â´ Tqf Â´ L1pI Â´ Tqf
â€œ
â£
Î»2pI Â´ TqRpÎ»q ` TV pÎ»qRpÎ»q2 Â´ Î»pI Â´ TqpI Â´ V pÎ»qRpÎ»qq
(
FpÎ»q
Â´ L1pI Â´ Tqf
â€œ
â£
pI Â´ TqÎ»L0RpÎ»q ` Î»2TV pÎ»qRpÎ»q2 ` Î»pI Â´ TqV pÎ»qRpÎ»q
(
FpÎ»q
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
235 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Â´ L1pI Â´ Tqf
Ã‘ tpI Â´ TqL0 ` TV ` pI Â´ TqV u f Â´ L1pI Â´ Tqf â€œ 0.
(3.339)
From (3.338) together with (3.339) we conclude that limÎ»Ã‘8 pÎ»GpÎ»qf Â´ fq â€œ 0
for all in the span of RpI Â´ Tq and R pL1pI Â´ Tqq. By assumption this span is
dense and consequently the resolvent family tGpÎ»q : Î» Ä… 0, Î» largeu is strongly
continuous. In order to conclude the proof of the existence result we choose f1
and f2 in the space DpL0q and we notice the following identities:
GpÎ»q tpI Â´ Tq pI Â´ V pÎ»qRpÎ»qq pÎ»I Â´ L0qf1 ` pÎ»I Â´ L1qpI Â´ Tqf2u
â€œ pI Â´ Tqpf1 ` f2q ` TV pÎ»qRpÎ»qf1,
and so the space GpÎ»qC0pEq contains the linear span of the spaces RpI Â´ Tq
and R pTV pÎ»qRpÎ»qq.
From the resolvent equation it is clear that the space
GpÎ»qC0pEq does not depend on the variable Î».
So we see that the space
GpÎ±qC0pEq contains, for a given function f P DpL0q the family tÎ»TV pÎ»qRpÎ»qf :
Î» Ä› Î±u. Hence the function TV f â€œ lim
Î»Ã‘8 Î»TV pÎ»qRpÎ»qf belongs to the closure of
the space GpÎ±qC0pEq. Since L1pI Â´Tqf â€œ TV f `pI Â´Tq pL1pI Â´ Tqf ` TL0fq,
for f P DpL0q, we conclude that the range of L1pI Â´ Tq is contained in the clo-
sure of GpÎ±qC0pEq. Since the latter space also contains RpI Â´Tq it follows from
the density of the space
RpI Â´ Tq ` R pL1pI Â´ Tqq
in C0pEq that the domain of the resolvent, i.e. GpÎ±qC0pEq is dense in C0pEq.
From the previous discussion it also follows that the operator which assigns to
GpÎ»qf the function Î»GpÎ»qf Â´ f extends the operator L1 restricted to RpI Â´ Tq.
It is now also clear that the subspace tGpÎ±qf : f P C0pEqu is dense and so it is
clear that the there exists a Feller semigroup generated by the operator L with
graph tpGpÎ±qf, Î±GpÎ±qf Â´ fq : f P C0pEqu.
For the uniqueness we proceed as follows. Let P1
x and P2
x be two solutions for the
martingale problem. We deï¬ne the family of operators tSptq : t Ä› 0u as follows:
Sptqfpxq â€œ E1
xfpXptqÂ´E2
xfpXptqq from the martingale property, it then follows
that S1ptqf â€œ SptqrLf for f belonging to the subspace RpI Â´ Tq ` RpL1pI Â´ Tqq.
Moreover we have Sp0qfpxq â€œ 0 for all functions f P C0pEq. Then we write (for
f1 and f2 P DpL0q)
0 â€œ
Å¼ 8
0
Ë†
Â´ B
Bt
Ë™
eÂ´Î»tSptqGpÎ»q ppI Â´ Tqf1 ` TL1pI Â´ Tqf2q dt
â€œ
Å¼ 8
0
eÂ´Î»tSptq
Â´
Î»I Â´ rL
Â¯
GpÎ»q ppI Â´ Tqf1 ` TL1pI Â´ Tqf2q dt
â€œ
Å¼ 8
0
eÂ´Î»tSptq ppI Â´ Tqf1 ` TL1pI Â´ Tqf2q dt.
(3.340)
Consequently SptqpI Â´ Tqf1 â€œ SptqTL1pI Â´ Tqf2 â€œ 0 for all functions f1 and fn
in the space DpL0q. We also have, upon using (3.340) the following equality:
Å¼ t
0
SpÏ„qL1pI Â´ TqfdÏ„ â€œ SptqpI Â´ Tqf Â´ Sp0qf â€œ 0.
(3.341)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
236 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Since by assumption the sum of the vector spaces RpI Â´ Tq and RpL1q is dense
in the space C0pEq, we conclude Sptq â€ 0 and hence from a general result on
uniqueness of the martingale problem, we ï¬nally obtain that P1
x â€œ P2
x for all
x P E. For more details see Proposition 2.9 (Corollary p. 206 of Ikeda and
Watanabe [61]). This completes the proof of Theorem 3.110.
â–¡
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
237 
Index
Index
D: dyadic rational numbers, 380
K: strike price, 191
NpÂ¨q: normal distribution, 191
P 1pâ„¦q: compact metrizable Hausdorï¬€
space, 129
S: spot price, 191
T: maturity time, 191
Î»-system, 1, 68
GÎ´-set, 332, 334
M: space of complex measures on RÎ½, 298
Âµx,y
0,t , 103
Ï€-system, 68
Ïƒ-algebra, 1, 3
Ïƒ-ï¬eld, 1, 3
Ïƒ: volatility, 191
r: risk free interest rate, 191
(DL)-property, 416
adapted process, 17, 374, 389, 406
additive process, 23, 24
aï¬ƒne function, 8
aï¬ƒne term structure model, 210
Alexandroï¬€compactiï¬cation, 301
almost sure convergence of
sub-martingales, 386
arbitrage-free, 190
backward propagator, 197
Banach algebra, 298, 303
Bernoulli distributed random variable, 56
Bernoulli topology, 310
Beurling-Gelfand formula, 302, 303
Birkhoï¬€â€™s ergodic theorem, 74
birth-dearth process, 35
Black-Scholes model, 187, 190
Black-Scholes parameters, 193
Black-Scholes PDE, 190
Bochnerâ€™s theorem, 90, 91, 308, 314
Boolean algebra of subsets, 361
Borel-Cantelliâ€™s lemma, 42, 105
Brownian bridge, 94, 98, 99, 101
Brownian bridge measure
conditional, 103
Brownian motion, 1, 16â€“18, 24, 84, 94, 98,
101, 102, 105, 108â€“110, 113, 115, 181,
189, 193, 197, 243, 283, 290, 291
continuous, 104
distribution of, 107
geometric, 188
HÂ¨older continuity of, 154
pinned, 98
standard, 70
Brownian motion with drift, 98
cadlag modiï¬cation, 395
cadlag process, 376
Cameron-Martin Girsanov formula, 277
Cameron-Martin transformation, 182, 280
canonical process, 109
CarathÂ´eodory measurable set, 363
CarathÂ´eodoryâ€™s extension theorem, 361,
362, 364
central limit theorem, 74
multivariate, 70
Chapman-Kolmogorov identity, 16, 25,
81, 107, 116, 149
characteristic function, 76, 102, 390
characteristic function (Fourier
transform), 98
classiï¬cation properties of Markov chains,
35
closed martingale, 17, 150
compact-open topology, 310
complex Radon measure, 296
conditional Brownian bridge measure, 103
conditional expectation, 2, 3, 78
conditional expectation as orthogonal
projection, 5
conditional expectation as projection, 5
conditional probability kernel, 399
consistent family of probability spaces, 66
consistent system of probability measures,
13, 360
content, 362
exended, 362
continuity theorem of LÂ´evy, 324
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
238 
Index
contractive operator, 197
convergence in probability, 371, 386
convex function and aï¬ƒne functions, 8
convolution product of measures, 298
convolution semigroup of measures, 314
convolution semigroup of probability
measures, 391
coupling argument, 288
covariance matrix, 108, 197, 200, 203
cylinder measure, 360
cylinder set, 358, 367
cylindrical measure, 89, 125
decomposition theorem of Doob-Meyer, 20
delta hedge portfolio, 190
density function, 80
Dirichlet problem, 265
discounted pay-oï¬€, 209
discrete state space, 25
discrete stopping time, 19
dispersion matrix, 94
dissipative operator, 118
distribution of random variable, 102
distributional solution, 266
DolÂ´eans measure, 168
Donskerâ€™s invariance principle, 71
Doobâ€™s convergence theorem, 17, 18
Doobâ€™s maximal inequality, 21, 23, 160,
384
Doobâ€™s maximality theorem, 21
Doobâ€™s optional sampling theorem, 20, 86,
381, 388, 409
Doob-Meyer decomposition
for discrete sub-martingales, 383
Doob-Meyer decomposition theorem, 148,
149, 295, 384, 410, 419, 421
downcrossing, 157
Dynkin system, 1, 68, 111, 300, 378
Elementary renewal theorem, 38
equi-integrable family, 369
ergodic theorem, 295
ergodic theorem in L2, 342
ergodic theorem of Birkhoï¬€, 76, 340, 344,
354
European call option, 188
European put option, 188
event, 1
exit time, 84
exponential Brownian motion, 186
exponential local martingale, 254, 255
exponential martingale probability
measure, 192
extended content, 362
extension theorem
of Kolmogorov, 360
exterior measure, 364
face value, 210
Feller semigroup, 79, 113, 114, 120, 121,
140, 264
conservative, 114
generator of, 118, 137, 140, 143, 144
strongly continuous, 113
Feller-Dynkin semigroup, 79, 122, 264
Feynman-Kac formula, 181
ï¬ltration, 109, 264
right closure of, 109
ï¬nite partition, 3
ï¬nite-dimensional distribution, 373
ï¬rst hitting time, 18
forward propagator, 197
forward rate, 214
Fourier transform, 90, 93, 96, 102, 251
Fubiniâ€™s theorem, 199
full history, 109
function
positive-deï¬nite, 305
functional central limit theorem (FCLT),
70, 71
Gaussian kernel, 16, 107
Gaussian process, 89, 110, 115, 200, 203
Gaussian variable, 153
Gaussian vector, 76, 93, 94
GBM, 186
geometric Brownian motion, 189
generator of Feller semigroup, 118, 137,
140, 144, 228, 230, 231, 233
generator of Markov process, 200, 203
geometric Brownian motion, 188
geometric Brownian motion = GBM, 186
Girsanov transformation, 182, 243, 280
Girsanovâ€™s theorem, 193
graph, 232
Gronwallâ€™s inequality, 246
HÂ¨older continuity of Brownian motion,
154
HÂ¨older continuity of processes, 151
Hahn decomposition, 295
Hahn-Kolmogorovâ€™s extension theorem,
364
harmonic function, 86
hedging strategy, 188
Hermite polynomial, 258
Hilbert cube, 333, 334
hitting time, 18
i.i.d. random variables, 24
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
239 
Index
index set, 11
indistinguishable processes, 104, 374, 386
information from the future, 374
initial reward, 40
integration by parts formula, 282
interest rate model, 204
internal history, 374, 394
invariant measure, 35, 48, 51, 201, 204
minimal, 50
irreducible Markov chain, 48, 51, 54
ItË†o calculus, 87, 278, 279
ItË†o isometry, 162
ItË†o representation theorem, 274
ItË†oâ€™s lemma, 189, 270
Jensen inequality, 149
Kolmogorov backward equation, 26
Kolmogorov forward equation, 26
Kolmogorov matrix, 26
Kolmogorovâ€™s extension theorem, 13, 17,
89â€“91, 93, 125, 130, 357, 360, 361,
366
Komlosâ€™ theorem, 295, 409, 420
LÂ´evyâ€™s weak convergence theorem, 115
LÂ´evy process, 89, 389, 390, 392
LÂ´evyâ€™s characterization of Brownian
motion, 194, 249
law of random variable, 102
Lebesgue-Stieltjes measure, 364
lemma of Borel-Cantelli, 10, 152
lexicographical ordering, 333
life time, 79, 117
local martingale, 194, 252, 264, 267, 268,
271, 278, 280
local time, 292
locally compact Hausdorï¬€space, 15
marginal distribution, 373
marginal of process, 13
Markov chain, 35, 44, 58, 59, 66
irreducible, 48, 54
recurrent, 48
Markov chain recurrent, 48
Markov process, 1, 16, 29, 30, 61, 79, 89,
102, 110, 113, 115, 119, 144, 202, 406,
408
strong, 119, 406
time-homogeneous, 407
Markov property, 25, 26, 30, 31, 46, 82,
110, 113, 142
strong, 44
martingale, 1, 17, 20, 80â€“82, 85â€“88, 103,
109, 243, 280, 281, 378, 382, 396
(DL)-property, 227
closed, 17
local, 194
maximal inequality for, 225
martingale measure, 209, 281
martingale problem, 118, 128, 137, 140,
143, 144, 228, 230, 231, 235, 264, 265
uniquely solvable, 118
well-posed, 118
martingale property, 131
martingale representation theorem, 263,
275
maximal ergodic theorem, 351
maximal inequality of Doob, 386
maximal inequality of LÂ´evy, 104
maximal martingale inequality, 225
maximum principle, 118, 140, 141, 143,
232
measurable mapping, 377
measure
invariant, 48, 201, 204
mesaure
invariant, 204
mesure
stationary, 204
metrizable space, 15
Meyer process, 419
minimal invariant measure, 50
modiï¬cation, 374
monotone class theorem, 69, 103, 107,
110, 112, 116, 378, 394, 398, 401, 404
alternative, 378
multiplicative process, 23, 24, 79
multivariate classical central limit
theorem, 70
multivariate normal distributed vector, 76
multivariate normally distributed random
vector, 93
negative-deï¬nite function, 314, 316, 396
no-arbitrage assumption, 209
non-null recurrent state, 51
non-null state, 47
non-positive recurrent random walk, 57
non-time-homogeneous process, 23
normal cumulative distribution, 188
normal distribution, 197
Novikov condition, 281
Novikovâ€™s condition, 209
null state, 47
numÂ´eraire, 215
number of upcrossings, 156, 379, 380
one-point compactiï¬cation, 15
operator
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
240 
Index
dissipative, 118
operator which maximally solves the
martingale problem, 118, 140, 228
Ornstein-Uhlenbeck process, 98, 102, 200,
201, 210
orthogonal projection, 340
oscillator process, 98, 99
outer measure, 363, 364
partial reward, 40
partition, 4
path, 373
path space, 117
pathwise solutions to SDE, 288, 289
unique, 291, 292
pathwise solutions to SDEâ€™s, 244
payoï¬€process
discounted, 193
PDE for bond price in the Vasicek model,
213
pe-measure, 362
persistent state, 47
pinned Brownian motion, 98
Poisson process, 26, 27, 29, 36, 89, 159
Polish space, 15, 90, 123, 334, 335, 360,
361, 366
portfolio
delta hedge, 190
positive state, 47
positive-deï¬nite function, 297, 302, 305,
314
positive-deï¬nite matrix, 90, 96, 197
positivity preserving operators, 345
pre-measure, 363, 364
predictable process, 20, 193, 418
probability kernel, 399, 408
probability measure, 1
probability space, 1
process
Gaussian, 200, 203
increasing, 21
predictable, 20
process adapted to ï¬ltration, 374
process of class (DL), 20, 21, 148, 149,
161, 409â€“411, 420, 421
progressively measurable process, 377
Prohorov set, 72, 335, 337â€“339
projective system of probability measures,
13, 121, 360
projective system of probability spaces,
125
propagator
backward, 197
quadratic covariation process, 249, 264,
279
quadratic variation process, 253
Radon-Nikodym derivative, 11, 408
Radon-Nikodym theorem, 4, 78, 408
random walk, 58
realization, 25, 373
recurrent Markov chain, 48
recurrent state, 47
recurrent symmetric random walk, 55
reference measure, 80, 81, 83
reï¬‚ected Brownian motion, 228
renewal function, 35
renewal process, 35, 40
renewal-reward process, 39, 40
renewal-reward theorem, 41
resolvent family, 122
return time, 55
reward
initial, 40
partial, 40
terminal, 40
reward function, 40
Riemann-Stieltjes integral, 364
Riesz representation theorem, 295, 296,
305
right closure of ï¬ltration, 109
right-continuous ï¬ltration, 374
right-continuous paths, 19
ring of subsets, 361
risk-neutral measure, 193, 209
risk-neutral probability measure, 192
running maximum, 23
sample path, 25
sample path space, 11, 25
sample space, 25
semi-martingale, 419
semi-ring, 364
semi-ring of subsets, 361, 362
semigroup
Feller, 264
Feller-Dynkin, 264
shift operator, 109, 117
Skorohod space, 117, 122, 128
Skorohod-Dudley-Wichura representation
theorem, 283, 286
Souslin space, 90, 361, 365, 366
space-homogeneous process, 29
spectral radius, 303
standard Brownian motion, 70
state
non-null, 47
null, 47
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
241 
Index
persistent, 47
positive, 47
recurrent, 47
state space, 11, 17, 79, 117, 400, 406
discrete, 25
state variable, 11, 25, 117
state variables, 125
state:transient, 47
stationary distribution, 25, 51
stationary measure, 204
stationary process, 11
step functions with unit jumps, 159
Stieltjes measure, 364
Stirlingâ€™s formula, 54
stochastic diï¬€erential equation, 182
stochastic integral, 102, 253
stochastic process, 10
stochastic variable, 11, 371
stochastically continuous process, 159
stochastically equivalent processes, 374
stopped ï¬ltration, 377
stopping time, 18, 20, 44, 58, 64, 68, 112,
252, 374â€“377, 381, 382, 405
discrete, 19
terminal, 18, 24
strong law of large numbers, 41, 76, 155,
340, 344
strong law of large numbers (SLLN), 38
strong Markov process, 102, 119, 121, 140,
406
strong Markov property, 44, 48, 113
strong solution to SDE, 244
strong solutions to SDE
unique, 244
strong time-dependent Markov property,
113, 120
strongly continuous Feller semigroup, 113
sub-martingale, 378, 381, 384
sub-probability kernel, 406
sub-probability measure, 1
submartingale, 17, 20, 227
submartingale convergence theorem, 158
submartingale of class (DL), 421
super-martingale, 378
supermartingale, 17, 20
Tanakaâ€™s example, 292
terminal reward, 40
terminal stopping time, 18, 24, 83
theorem
ItË†o representation, 274
Kolmogorovâ€™s extension, 278
martingale representation, 275
of Arzela-Ascoli, 72, 73
of Bochner, 90, 304, 308
of Doob-Meyer, 20
of Dynkin-Hunt, 397
of Fernique, 221
of Fubini, 199, 330
of Girsanov, 277, 280
of Helly, 334
of Komlos, 409
of LÂ´evy, 253, 270, 290
of Prohorov, 72
of Radon-Nikodym, 290
of Riemann-Lebesgue, 300
of Scheï¬€Â´e, 39, 278, 369
of Schoenberg, 314
of Stone-Weierstrass, 301, 305
Skorohod-Dudley-Wichura
representation, 283, 286
time, 11
time change, 19
stochastic, 19
time-dependent Markov process, 200, 203
time-homogeneous process, 11, 29
time-homogeneous transition probability,
25
time-homogenous Markov process, 407
topology of uniform convergence on
compact subsets, 310
tower property of conditional expectation,
5
transient non-symmetric random walk, 57
transient state, 47
transient symmetric random walk, 55
transition function, 119
transition matrix, 51
translation operator, 11, 25, 109, 117,
400, 406
translation variables, 125
uniformly distributed random variable,
394
uniformly integrable family, 5, 6, 20, 39,
369, 388
uniformly integrable martingale, 389
uniformly integrable sequence, 385
unique pathwise solutions to SDE, 244
uniqueness of the Doob-Meyer
decomposition, 417
unitary operator, 340, 342
upcrossing inequality, 156, 157, 383
upcrossing times, 156
upcrossings, 156
vague convergence, 371
vague topology, 310, 334
vaguely continuous convolution semigroup
of measures, 315
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
242 
Index
vaguely continuous convolution semigroup
of probability measures, 389, 390
Vasicek model, 204, 210
volatility, 188
von Neumannâ€™s ergodic theorem, 340
Waldâ€™s equation, 36
weak convergence, 325
weak law of large numbers, 75, 340
weak solutions, 264
weak solutions to SDEâ€™s, 244, 277, 280,
288
unique, 265, 292
weak solutions to stochastic diï¬€erential
equations, 265
weak topology, 310
weakËš-topology, 334
weakly compact set, 338, 339
Wiener process, 98
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Masterâ€™s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top masterâ€™s programmes
â€¢ 33rd place Financial Times worldwide ranking: MSc 
International Business
â€¢ 1st place: MSc International Business
â€¢ 1st place: MSc Financial Economics
â€¢ 2nd place: MSc Management of Learning
â€¢ 2nd place: MSc Economics
â€¢ 2nd place: MSc Econometrics and Operations Research
â€¢ 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier â€˜Beste Studiesâ€™ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

To See Part 2 download
Advanced stochastic processes: Part 2
Download free eBooks at bookboon.com

