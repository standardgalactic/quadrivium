Jan A. Van Casteren
Advanced stochastic processes:
Part I
Download free books at

ii 
 
Jan A. Van Casteren
Advanced Stochastic Processes  
Part I
Download free eBooks at bookboon.com

iii 
 
Advanced stochastic processes: Part I
2nd edition
© 2015 Jan A. Van Casteren & bookboon.com
ISBN 978-87-403-1115-0
The author is obliged to Department of Mathematics and Computer Science of the University of Antwerp 
for its material support. The author is also indebted to Freddy Delbaen (ETH, Zürich), and the late 
Jean Haezendock (University of Antwerp). A big part of Chapter 5 is due to these people. The author is 
thankful for comments and logistic support by numerous students who have taken courses based on this 
text. In particular, he is grateful to Lieven Smits and Johan Van Biesen (former students at the University 
of Antwerp) who wrote part of the Chapters 1 and 2. The author gratefully acknowledges World Scientic 
Publishers (Singapore) for their permission to publish the contents of Chapter 4 which also makes up 
a substantial portion of Chapter 1 in [144]. The author also learned a lot from the book by Stirzaker 
[124]. Section 1 of Chapter 2 is taken from [124], and the author is indebted to David Stirzaker to allow 
him to include this material in this book. The author is also grateful to the people of Bookboon, among 
whom Karin Hamilton Jakobsen and Ahmed Zsolt Dakroub, who assisted him in the final stages of the 
preparation of this book.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
4 
Contents
Contents
Preface
i
Chapter 1.
Stochastic processes: prerequisites
1
1.
Conditional expectation
2
2.
Lemma of Borel-Cantelli
9
3.
Stochastic processes and projective systems of measures
10
4.
A deﬁnition of Brownian motion
16
5.
Martingales and related processes
17
Chapter 2.
Renewal theory and Markov chains
35
1.
Renewal theory
35
2.
Some additional comments on Markov processes
61
3.
More on Brownian motion
70
4.
Gaussian vectors.
76
5.
Radon-Nikodym Theorem
78
6.
Some martingales
78
Download free eBooks at bookboon.com
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
5 
Contents
Chapter 3.
An introduction to stochastic processes: Brownian motion,
Gaussian processes and martingales
89
1.
Gaussian processes
89
2.
Brownian motion and related processes
98
3.
Some results on Markov processes, on Feller semigroups and on the
martingale problem
117
4.
Martingales, submartingales, supermartingales and semimartingales 147
5.
Regularity properties of stochastic processes
151
6.
Stochastic integrals, Itˆo’s formula
162
7.
Black-Scholes model
188
8.
An Ornstein-Uhlenbeck process in higher dimensions
197
9.
A version of Fernique’s theorem
221
10.
Miscellaneous
223
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
6 
Contents
3.
A taste of ergodic theory
340
4.
Projective limits of probability distributions
357
5.
Uniform integrability
369
6.
Stochastic processes
373
7.
Markov processes
399
8.
The Doob-Meyer decomposition via Komlos theorem
409
Subjects for further research and presentations
423
Bibliography
425
Index
433
Chapter 4.
Stochastic diﬀerential equations
243
1.
Solutions to stochastic diﬀerential equations
243
2.
A martingale representation theorem
272
3.
Girsanov transformation
277
Chapter 5.
Some related results
295
1.
Fourier transforms
295
2.
Convergence of positive measures
324
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
i 
Preface
Preface
This book deals with several aspects of stochastic process theory:
Markov
chains, renewal theory, Brownian motion, Brownian motion as a Gaussian pro-
cess, Brownian motion as a Markov process, Brownian motion as a martingale,
stochastic calculus, Itˆo’s formula, regularity properties, Feller-Dynkin semi-
groups and (strong) Markov processes. Brownian motion can also be seen as
limit of normalized random walks. Another feature of the book is a thorough
discussion of the Doob-Meyer decomposition theorem. It also contains some
features of stochastic diﬀerential equations and the Girsanov transformation.
The ﬁrst chapter (Chapter 1) contains a (gentle) introduction to the theory
of stochastic processes.
It is more or less required to understand the main
part of the book, which consists of discrete (time) probability models (Chap-
ter 2), of continuous time models, in casu Brownian motion, Chapter 3, and
of certain aspects of stochastic diﬀerential equations and Girsanov’s transfor-
mation (Chapter 4). In the ﬁnal chapter (Chapter 5) a number of other, but
related, issues are treated. Several of these topics are explicitly used in the
main text (Fourier transforms of distributions, or characteristic functions of
random vectors, L´evy’s continuity theorem, Kolmogorov’s extension theorem,
uniform integrability); some of them are treated, like the important Doob-Meyer
decomposition theorem, but are not explicitly used. Of course Itˆo’s formula
implies that a C2-function composed with a local semi-martingale is again a
semi-martingale. The Doob-Meyer decomposition theorem yields that a sub-
martingale of class (DL) is a semi-martingale. Section 1 of Chapter 5 contains
several aspects of Fourier transforms of probability distributions (characteristic
functions). Among other results Bochner’s theorem is treated here. Section
2 contains convergence properties of positive measures. Section 3 gives some
results in ergodic theory, and gives the connection with the strong law of large
numbers (SLLN). Section 4 gives a proof of Kolmogorov’s extension theorem
(for a consistent family of probability measures on Polish spaces). In Section
5 the reader ﬁnds a short treatment of uniform integrable families of functions
in an L1-space. For example Scheﬀ´e’s theorem is treated. Section 6 in Chapter
5 contains a precise description of the regularity properties (like almost sure
right-continuity, almost sure existence of left limits) of stochastic processes like
submartingales, L´evy processes, and others; it also contains a proof of Doob’s
maximal inequality for submartingales. Section 7 of the same chapter contains
a description of Markov process theory starting from just one probability space
instead of a whole family. The proof of the Doob-Meyer decompositon theorem
is based on a result by Komlos: see Section 8. Throughout the book the reader
will be exposed to martingales, and related processes.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
ii 
Preface
Readership. From the description of the contents it is clear that the text
is designed for students at the graduate or master level. The author believes
that also Ph.D. students, and even researchers, might beneﬁt from these notes.
The reader is introduced in the following topics: Markov processes, Brownian
motion and other Gaussian processes, martingale techniques, stochastic diﬀer-
ential equations, Markov chains and renewal theory, ergodic theory and limit
theorems.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
1 
Stochastic processes: prerequisites
CHAPTER 1
Stochastic processes: prerequisites
In this chapter we discuss a number of relevant notions related to the theory
of stochastic processes. Topics include conditional expectation, distribution of
Brownian motion, elements of Markov processes, and martingales. For com-
pleteness we insert the deﬁnitions of a σ-ﬁeld or σ-algebra, and concepts related
to measures.
1.1. Definition. A σ-algebra, or σ-ﬁeld, on a set Ωis a subset A of the power
set P pΩq with the following properties:
(i) ΩP A;
(ii) A P A implies Ac :“ ΩzA P A;
(iii) if pAnqně1 is a sequence in A, then
8
ď
n“1
An belongs to A.
Let A be a σ-ﬁeld on Ω. Unless otherwise speciﬁed, a measure is an application
µ : A Ñ r0, 8s with the following properties:
‚ µ pHq “ 0;
‚ if pAnqně1 is a mutually disjoint sequence in A, then
µ
˜ 8
ď
n“1
An
¸
“
ÿ
NÑ8
N
ÿ
j“1
µ pAnq “
8
ÿ
n“1
µ pAnq .
If µ is measure on A for which µ pΩq “ 1, then µ is called a probability measure;
if µ pΩq ď 1, then µ is called a sub-probability measure. If µ : A Ñ r0, 1s is a
probability space, then the triple pΩ, A, µq is called a probability space, and the
elements of A are called events.
Let M be a collection of subsets of P pΩq, where Ωis some set like in Deﬁnition
1.1. The smallest σ-ﬁeld containing M is called the σ-ﬁeld generated by M, and
it is often denoted by σ pMq. Let pΩ, A, µq be a sub-probability space, i.e. µ is
a sub-probability on the σ-ﬁeld A. Then, we enlarge Ωwith one point △, and
enlarge A to
A△:“ σ pA Y t△uq “
␣
A P P
`
Ω△˘
: A X ΩP A
(
.
Then µ△: A△Ñ r0, 1s, deﬁned by
µ△pAq “ µ pA X Ωq ` p1 ´ µ pΩqq 1A p△q ,
A P A△,
(1.1)
turns the space
`
Ω△, A△, µ△˘
into a probability space. Here Ω△“ ΩY t△u.
This kind of construction also occurs in the context of Markov processes with
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
2 
Stochastic processes: prerequisites
ﬁnite lifetime: see the equality (3.75) in (an outline of) the proof of Theorem
3.37. For the important relationship between Dynkin systems, or λ-systems,
and σ-algebras, see Theorem 2.42.
1. Conditional expectation
1.2. Definition. Let pΩ, A, Pq be a probability space, and let A and B be
events in A such that P rBs ą 0. The quantity P
`
A
ˇˇ B
˘
“ P pA X Bq
P pBq
is then
called the conditional probability of the event A with respect to the event B.
We put P
`
A
ˇˇ B
˘
“ 0 if P pBq “ 0.
Consider a ﬁnite partition tB1, . . . , Bnu of Ωwith Bj P A for all j “ 1, . . . , n,
and let B be the subﬁeld of A generated by the partition tB1, . . . , Bnu, and
write
P
“
A
ˇˇ B
‰
“
nÿ
j“1
P
`
A
ˇˇ Bj
˘
1Bj.
Then P
“
A
ˇˇ B
‰
is a B-measurable stochastic variable on Ω, and
ż
B
P
“
A
ˇˇ B
‰
dP “
ż
B
1AdP
for all B P B.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
3 
Stochastic processes: prerequisites
Conversely, if f is a B-measurable stochastic variable on Ωwith the property
that for all B P B the equality
ş
B fdP “
ş
B 1AdP holds, then f “ P
“
A
ˇˇ B
‰
P-almost surely. This is true, because
ş
B
`
f ´ P
“
A
ˇˇ B
‰˘
dP “ 0 for all B P B.
If B is a sub-ﬁeld (more precisely a sub-σ-ﬁeld, or sub-σ-algebra) generated by
a ﬁnite partition of Ω, then for every A P A there exists one and only one class
of variables in L1 pΩ, B, Pq, which we denote by P
“
A
ˇˇ B
‰
, with the following
property
ż
B
P
“
A
ˇˇ B
‰
dP “
ż
B
1AdP
for all B P B.
The variable řn
j“1 P
`
A
ˇˇ Bj
˘
1Bj is an element from the class P
“
A
ˇˇ B
‰
.
If we ﬁx B P A with P pBq ą 0, then the measure A ÞÑ P
`
A
ˇˇ B
˘
is a probability
measure on pΩ, Aq. If P pBq “ 0, then the measure A ÞÑ P
`
A
ˇˇ B
˘
is the zero-
measure.
Let X be a P-integrable real or complex valued stochastic variable on Ω. Then
X is also P
`
¨
ˇˇ B
˘
-integrable, and
ż
XdP
`
¨
ˇˇ B
˘
“ E rX1Bs
P pBq ,
provided P pBq ą 0.
This quantity is the average of the stochastic variable over the event B. As
before, it is easy to show that if B is a subﬁeld of A generated by a ﬁnite
partition tB1, . . . , Bnu of Ω, then there exists, for every P-integrable real or
complex valued stochastic variable X on Ωone and only one class of functions
in L1 pΩ, B, Pq, which we denote by E
“
X
ˇˇ B
‰
with the property that
ż
B
E
“
X
ˇˇ B
‰
dP “
ż
B
X dP
for all B P B.
The variable řn
j“1
ş
XdP
`
¨
ˇˇ Bj
˘
1Bj is an element from the class E
“
X
ˇˇ B
‰
.
The next theorem generalizes the previous properties to an arbitrary subﬁeld
(or more precisely sub-σ-ﬁeld) B of A.
1.3. Theorem (Theorem and deﬁnition). Let pΩ, A, Pq be a probability space
and let B be a subﬁeld of A. Then for every stochastic variable X PL1 pΩ, A, Pq
there exists one and only one class in L1 pΩ, B, Pq, which is denoted by E
“
X
ˇˇB
‰
and which is called the conditional expectation of X with respect to B, with the
property that
ż
B
E
“
X
ˇˇ B
‰
dP “
ż
B
X dP
for all B P B.
If X “ 1A, with A P A, then we write P
“
A
ˇˇ B
‰
instead of E
“
1A
ˇˇ B
‰
; if B
is generated by just one stochastic variable Y , then we write E
“
X
ˇˇ Y
‰
and
P
“
A
ˇˇ Y
‰
instead of respectively E
“
X
ˇˇ σ pY q
‰
and P
“
A
ˇˇ σ pY q
‰
.
Proof. Suppose that X is real-valued; if X “ Re X ` iIm X is complex-
valued, then we apply the following arguments to Re X and Im X. Upon writ-
ing the real-valued stochastic variable X as X “ X` ´ X´, where X˘ are
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
4 
Stochastic processes: prerequisites
non-negative stochastic variables in L1 pΩ, A, Pq, without loss of generality we
may and do assume that X ě 0.
Deﬁne the measure µ : A Ñ r0, 8q by
µpAq “
ż
A
XdP, A P A. Then µ is ﬁnite measure which is absolutely contin-
uous with respect to the measure P. We restrict µ to the measurable space
pΩ, Bq; its absolute continuity with respect to P conﬁned to pΩ, Bq is preserved.
From the Radon-Nikodym theorem it follows that there exists a unique class
Y P L1 pΩ, B, Pq such that, for all B P B, the following equality is valid:
µpBq “
ż
B
Y dP,
and hence
ż
B
XdP “
ż
B
Y dP.
This proves Theorem1.3.
□
If B is generated by a countable or ﬁnite partition tBj : j P Nu, then it is fairly
easy to give an explicit formula for the conditional expectation of a stochastic
X P L1 pΩ, A, Pq with respect to B:
E
“
X
ˇˇ B
‰
“
ÿ
jPN
ş
Bj XdP
P pBjq 1Bj “
ÿ
jPN
E
“
X
ˇˇ Bj
‰
1Bj.
Next let B be an arbitrary subﬁeld of A, let X belong to L1 pΩ, A, Pq, and let
B be an atom in B. The latter means that P pBq ą 0, and if A P B is such
that A Ă B, then either P pAq “ 0 or P pBzAq “ 0. If Y represents E
“
X
ˇˇ B
‰
,
then Y 1B “ b1B, P-almost surely, for some constant b. This follows from the
B-measurability of the variable Y together with the fact that B is an atom for
pΩ, B, Pq. So we get
ş
B XdP “
ş
B E
“
X
ˇˇ B
‰
dP “
ş
Y 1BdP “ bP pBq, and hence
b “
ş
B XdP
P pBq . Consequently, on the atom B we have:
E
“
X
ˇˇ B
‰
“
ş
B XdP
P pBq “ b,
P-almost surely.
In particular, for X “ 1A, we have on the atom B the equality
P
“
A
ˇˇ B
‰
“ P pA X Bq
P pBq
,
P-almost surely.
If B is not an atom, then the conditional expectation on B need not be constant.
In the following theorem we collect some properties of conditional expectation.
For the notion of uniform integrability see Section 5.
1.4. Theorem. Let pΩ, A, Pq be a probability space, and let B be a subﬁeld of
A. Then the following assertions hold.
(1) If all events in B have probability 0 or 1 (in particular if B is the
trivial ﬁeld tH, Ωu), then for all stochastic variables X P L1 pΩ, A, Pq
the equality E
“
X
ˇˇ B
‰
“ E pXq is true P-almost surely.
(2) If X is a stochastic variable in L1 pΩ, A, Pq such that B and σpXq
are independent, then the equality E
“
X
ˇˇ B
‰
“ E pXq is true P-almost
surely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
5 
Stochastic processes: prerequisites
(3) If a and b are real or complex constants, and if the stochastic variables
X and Y belong to L1 pΩ, A, Pq, then the equality
E
“
aX ` bY
ˇˇ B
‰
“ aE
“
X
ˇˇ B
‰
` bE
“
Y
ˇˇ B
‰
is true P-almost surely.
(4) If X and Y are real stochastic variables in L1 pΩ, A, Pq such that X ď
Y , then the inequality E
“
X
ˇˇ B
‰
ď E
“
Y
ˇˇ B
‰
holds P-almost surely.
Hence the mapping X ÞÑ E
“
X
ˇˇ B
‰
is a mapping from L1 pΩ, A, Pq
onto L1 pΩ, B, Pq.
(5) (a) If pXn : n P Nq is a non-decreasing sequence of stochastic variables
in L1 pΩ, A, Pq, then
sup
n E
“
Xn
ˇˇ B
‰
“ E
„
sup
n Xn
ˇˇ B
ȷ
,
P-almost surely.
(b) If pXn : n P Nq is any sequence of stochastic variables in
L1 pΩ, A, Pq which converges P-almost surely to a stochastic vari-
able X, and if there exists a stochastic variable Y P L1 pΩ, A, Pq
such that |Xn| ď Y for all n P N, then
lim
nÑ8 E
“
Xn
ˇˇ B
‰
“ E
”
lim
nÑ8 Xn
ˇˇ B
ı
,
P-almost surely, and in L1 pΩ, B, Pq.
The condition “|Xn| ď Y for all n P N with Y P L1 pΩ, A, Pq”
may be replaced with “the sequence pXnqnPN is uniformly integrable in
the space L1 pΩ, A, Pq” and still keep the second conclusion in (5b).
In order to have P-almost sure convergence the uniform integrability
condition should be replaced with the condition
inf
Mą0, MPR sup
nPN
E
“
|Xn| , |Xn| ą M
ˇˇ B
‰
“ 0,
P-almost surely.
(1.2)
(6) If cpxq is a convex continuous function from R to R, and if X belongs
to L1 pΩ, A, Pq, then
c
`
E
“
X
ˇˇ B
‰˘
ď E
“
cpXq
ˇˇ B
‰
,
P-almost surely.
(7) Let p ě 1, and let X be a stochastic variable in Lp pΩ, A, Pq. Then the
stochastic variable E
“
X
ˇˇ B
‰
belongs to Lp pΩ, B, Pq, and
››E
“
X
ˇˇ B
‰››
p ď }X}p .
So the linear mapping X ÞÑ E
“
X
ˇˇB
‰
is a projection from Lp pΩ, A, Pq
onto Lp pΩ, B, Pq.
(8) (Tower property) Let B1 be another subﬁeld of A such that B Ď B1 Ď A.
If X belongs to L1 pΩ, A, Pq, then the equality
E
“
E
“
X
ˇˇ B1‰ ˇˇ B
‰
“ E
“
X
ˇˇ B
‰
holds P-almost surely.
(9) If X belongs to L1 pΩ, B, Pq, then E
“
X
ˇˇ B
‰
“ X, P-almost surely.
(10) If X belongs to L1 pΩ, A, Pq, and if Z belongs to L8 pΩ, B, Pq, then
E
“
ZX
ˇˇ B
‰
“ ZE
“
X
ˇˇ B
‰
,
P-almost surely.
(11) If X belongs to L2 pΩ, A, Pq, then E
“
Y
`
X ´ E
`
X
ˇˇ B
‰˘‰
“ 0 for all
Y P L2 pΩ, B, Pq. Hence, the mapping X ÞÑ E
“
X
ˇˇ B
‰
is an orthogonal
projection from L2 pΩ, A, Pq onto L2 pΩ, B, Pq.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
6 
Stochastic processes: prerequisites
Observe that for B the trivial σ-ﬁeld, i.e. B “ tH, Ωu, the condition in (1.2) is
the same as saying that the sequence pXnqn is uniformly integrable in the sense
that
inf
Mą0, MPR sup
nPN
E r|Xn| , |Xn| ą Ms “ 0.
(1.3)
Proof. We successively prove the items in Theorem 1.4.
(1) For every B P B we have to verify the equality:
ż
B
XdP “
ż
B
E pXq dP.
If P pBq “ 0, then both members are 0; if P pBq “ 1, then both mem-
bers are equal to E pXq. This proves that the constant E pXq can be
identiﬁed with the class E
“
X
ˇˇ B
‰
.
(2) For every B P B we again have to verify the equality:
ş
B XdP “
ş
B E pXq dP. Employing the independence of X and B P B this can be
seen as follows:
ż
B
X dP “
ż
Ω
X1B dP “ E rX1Bs “ E rXs E r1Bs “
ż
B
E rXs dP.
(1.4)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
7 
Stochastic processes: prerequisites
(3) This assertion is clear.
(4) This assertion is clear.
(5) (a) For all B P B and n P N we have
ş
B E
“
Xn
ˇˇ B
‰
dP “
ş
B Xn dP. By
(4) we see that the sequence of conditional expectations
E
“
Xn
ˇˇ B
‰
, n P N, increases P-almost surely.
The assertion in (5a) then follows from the monotone convergence
theorem.
(b) Put X˚
n “ supkěn Xk, X˚˚
n
“ infkěn Xk. Then we have ´Y ď
X˚˚
n
ď Xn ď X˚
n ď Y , P-almost surely. Moreover, the sequences
pY ´ X˚
nqnPN and pY ` X˚˚
n qnPN are increasing sequences consisting
of non-negative stochastic variables with Y ´ lim supnÑ8 Xn and
Y `lim infnÑ8 Xn as their respective suprema. Since the sequence
pXnqnPN converges P-almost surely to X, it follows by (5a) together
with (4) that
E
“
X˚˚
n
ˇˇ B
‰
Ò E
“
X˚˚ ˇˇ B
‰
and
E
“
X˚
n
ˇˇ B
‰
Ó E
“
X˚˚ ˇˇ B
‰
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
8 
Stochastic processes: prerequisites
From the pointwise inequalities X˚˚
n
ď Xn ď X˚
n it then follows
that lim
nÑ8 E
“
Xn
ˇˇB
‰
“ E
“
X
ˇˇ B
‰
, P-almost surely.
Next let the
uniformly integrable sequence pXnqn in L1 pΩ, A, Pq be pointwise
convergent to X. Then lim
nÑ8 E r|Xn ´ X|s “ 0. What we need is
that
lim
nÑ8 E
“
|Xn ´ X|
ˇˇ B
‰
“ 0.
(1.5)
Under the extra hypothesis (1.2) this can be achieved as follows:
lim sup
nÑ8 E
“
|Xn ´ X|
ˇˇ B
‰
ď lim sup
nÑ8 E
“
|Xn ´ X| , |Xn ´ X| ď M
ˇˇ B
‰
` lim sup
nÑ8 E
“
|Xn ´ X, |Xn ´ X| ą M|
ˇˇ B
‰
(apply what already has been proved in (5b), with |Xn ´ X| in-
stead of Xn, to the ﬁrst term)
ď lim sup
nÑ8 E
“
|Xn ´ X, |Xn ´ X| ą M|
ˇˇ B
‰
.
(1.6)
In (1.6) we let M tend to 8, and employ (1.2) to conclude (1.5).
This completes the proof of item (5).
(6) Write cpxq as a countable supremum of aﬃne functions
cpxq “ sup
nPN
Lnpxq,
(1.7)
where Lnpzq “ anz ` bn ď cpzq, for all those z for which cpzq ă 8,
i.e.
for appropriate constants an and bn.
Every stochastic variable
Ln pXq is integrable; by linearity (see (3)) we have Ln
`
E
“
X
ˇˇ B
‰˘
“
E
“
Ln pXq
ˇˇ B
‰
. Hence
Ln
`
E
“
X
ˇˇ B
‰˘
ď E
“
c pXq
ˇˇ B
‰
.
Consequently,
c
`
E
“
X
ˇˇ B
‰˘
“ sup
nPN
Ln
`
E
“
X
ˇˇ B
‰˘
ď E
“
c pXq
ˇˇ B
‰
.
The fact that convex function can be written in the form (1.7) can be
found in most books on convex analysis; see e.g. Chapter 3 in [28].
(7) It suﬃces to apply item (6) to the function cpxq “ |x|p.
(8) This assertion is clear.
(9) This assertion is also obvious.
(10) This assertion is evident if Z is a ﬁnite linear combination of indicator
functions of events taken from B. The general case follows via a limiting
procedure.
(11) This assertion is clear if Y is a ﬁnite linear combination of indicator
functions of events taken from B. The general case follows via a limiting
procedure.
The proof of Theorem 1.4 is now complete.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
9 
Stochastic processes: prerequisites
2. Lemma of Borel-Cantelli
1.5. Definition. The limes superior or upper-limit of a sequence pAnqnPN in
a universe Ωis the set A of those elements ω P Ωwith the property that ω
belongs to inﬁnitely many An’s. In a formula:
A “ lim sup
nÑ8 An “
č
nPN
ď
kěn
Ak.
The indicator-function 1A of the limes-superior of the sequence pAnqnPN is equal
to the lim sup of the sequence of its indicator-functions: 1A “ lim sup
nÑ8 1An.
The limes inferior or lower-limit of a sequence pAnqnPN in a universe Ωis the set
A of those elements ω P Ωwith the property that, up to ﬁnitely many Ak’s, the
element (sample) ω belongs to all An’s. In a formula:
A “ lim inf
nÑ8 An “
ď
nPN
č
kěn
Ak.
The indicator-function 1A of the limes-inferior of the sequence pAnqnPN is equal
to the lim inf of the sequence of its indicator-functions: 1A “ lim inf
nÑ8 1An.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
10 
Stochastic processes: prerequisites
1.6. Lemma. Let pαnqnPN be a sequence of real numbers such that 0 ď αn ă 1.
Then limnÑ8
řn
k“1 αk ă 8 if and only if limnÑ8
śn
k“1 p1 ´ αkq ą 0.
Proof. For 0 ď α ă 1 the following elementary inequalities hold:
´
α
1 ´ α ď log p1 ´ αq ď ´α.
Hence we see
´
nÿ
k“1
αk
1 ´ αk
ď log
˜ n
ź
k“1
p1 ´ αkq
¸
ď ´
nÿ
k“1
αk.
The assertion in Lemma 1.6 easily follows from these inequalities.
□
1.7. Lemma (Lemma of Borel-Cantelli). Let pAnqnPN be a sequence of events,
and put A “ lim supnÑ8 An “ Ş
nPN
Ť
kěn Ak.
(i) If ř8
n“1 P pAnq ă 8, then P pAq “ 0.
(ii) If the events An, n P N, are mutually P-independent, then the converse
statement is true as well: P pAq ă 1 implies ř8
k“1 P pAkq ă 8, and
hence ř8
k“1 P pAkq “ 8 if and only if P pAq “ 1.
Proof. (i) For P pAq we have the following estimate:
P pAq ď inf
nPN
8
ÿ
k“n
P pAkq .
(1.8)
Since ř8
n“1 P pAnq ă 8, we see that the right-hand side of (1.8) is 0.
(ii) The statement in assertion (ii) is trivial if for inﬁnitely many numbers k the
equality P pAkq “ 1 holds. So we may assume that for all k P N the probability
P pAkq is strictly less than 1. Apply Lemma 1.6 with αk “ P pAkq to obtain that
ř8
k“1 P pAkq ă 8 if and only if
0 ă lim
nÑ8
n
ź
k“1
p1 ´ P pAkqq “ lim
nÑ8
n
ź
k“1
P pΩzAkq
(the events pAkqnPN are independent)
“ lim
nÑ8 P
˜ nč
k“1
pΩzAkq
¸
“ lim
nÑ8 P
˜
Ωz
nď
k“1
Ak
¸
“ 1 ´ P pAq .
(1.9)
This proves assertion (ii) of Lemma 1.7.
□
3. Stochastic processes and projective systems of measures
1.8. Definition. Consider a probability space pΩ, A, Pq and an index set I.
Suppose that for every t P I a measurable space pEt, Etq and an A-Et-measurable
mapping Xptq : ΩÑ Et are given. Such a family tXptq : t P Iu is called a
stochastic process.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
11 
Stochastic processes: prerequisites
1.9. Remark. The space Ωis often called the sample path space, the space
Et is often called the state space of the state variable Xptq.
The σ-ﬁeld A
is often replaced with (some completion of) the σ-ﬁeld generated by the state
variables Xptq, t P I. This σ-ﬁeld is written as F. Let pS, Sq be some measurable
space. An F-S measurable mapping Y : ΩÑ S is called an S-valued stochastic
variable. Very often the state spaces are the same, i.e. pEt, Etq “ pE, Eq, for all
state variables Xptq, t P I.
In applications the index set I is often interpreted as the time set. So I can
be a ﬁnite index set, e.g. I “ t0, 1, . . . , nu, or an inﬁnite discrete time set, like
I “ N “ t0, 1, . . .u or I “ Z. The set I can also be a continuous time set: I “ R
or I “ R` “ r0, 8q. In the present text, most of the time we will consider
I “ r0, 8q. Let I be N, Z, R, or r0, 8q. In the so-called time-homogeneous or
stationary case we also consider mappings ϑs : ΩÑ Ω, s P I, s ě 0, such that
Xptq˝ϑs “ Xpt`sq, P-almost surely. It follows that these translation mappings
ϑs : ΩÑ Ω, s P I, are Ft-Ft´s-measurable, for all t ě s. If Y is a stochastic
variable, then Y ˝ ϑs is measurable with respect to the σ-ﬁeld σ tXptq : t ě su.
The concept of time-homogeneity of the process pXptq : t P Iq can be explained
as follows. Let Y : ΩÑ R be a stochastic variable; e.g. Y “ śn
j“1 fj pX ptjqq,
where fj : E Ñ R, 1 ď j ď n, are bounded measurable functions. Deﬁne the
transition probability P ps, Bq as follows: P ps, Bq “ P pXpsq P Bq, s P I, B P E.
The measure B ÞÑ E rY ˝ ϑs, Xpsq P Bs is absolutely continuous with respect to
the measure B ÞÑ P ps, Bq, B P E. It follows that there exists a function Fps, xq,
called the Radon-Nikodym derivative of the measure B ÞÑ E rY ˝ ϑs, Xpsq P Bs
with respect B ÞÑ P ps, Bq, such that E rY ˝ ϑs, Xpsq P Bs “
ş
F ps, xq P ps, dxq.
The function F ps, xq is usually written as
F ps, xq “ E
“
Y ˝ ϑs
ˇˇ Xpsq P dx
‰
“ E rY ˝ ϑs, Xpsq P dxs
P rXpsq P dxs
.
1.10. Definition. The process pXptq : t P Iq is called time-homogeneous or
stationary in time, provided that for all bounded stochastic variables Y : ΩÑ R
the function
E
“
Y ˝ ϑs
ˇˇ Xpsq P dx
‰
is independent of s P I, s ě 0.
In practice we only have to verify the property in Deﬁnition 1.10 for Y of the
form Y “ śn
j“1 fj pX ptjqq, where fj : Etj Ñ R, 1 ď j ď n, are bounded
measurable functions. Then Y ˝ ϑs “ śn
j“1 fj pX ptj ` sqq. This statement is a
consequence of the monotone class theorem.
3.1. Finite dimensional distributions. As above let pΩ, A, Pq be a prob-
ability space and let tXptq : t P Iu be a stochastic process where each state
variable Xptq has state space pEt, Etq. For every non-empty subset J of I we
write EJ “ ś
tPJ Et and EJ “ btPJEt denotes the product-ﬁeld. We also write
XJ “ btPJXt. So that, if J “ tt1, . . . , tnu, then XJ “ pX pt1q , . . . , X ptnqq. The
mapping XJ is the product mapping from Ωto EJ. The mapping XJ : ΩÑ EJ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
12 
Stochastic processes: prerequisites
is A-EJ-measurable. We can use it to deﬁne the image measure PJ:
PJ pBq “ XJP pBq “ P
“
X´1
J B
‰
“ P rω P Ω: XJpωq P Bs “ P rXJ P Bs ,
where B P EJ. Between the diﬀerent probability spaces
`
EJ, EJ, PJ
˘
there exist
relatively simple relationships. Let J and H be non-empty subsets of I such that
J Ă H, and consider the EH-EJ-measurable projection mapping pH
J : EH Ñ EJ,
which ”forgets” the ”coordinates” in HzJ. If H “ I, then we write pJ “ pI
J.
For every pair J and H with J Ă H Ă I we have XJ “ pH
J ˝ XH, and hence we
get PJ pBq “ pH
J PH pBq “ PH
“
pH
J P B
‰
, where B belongs to EJ. In particular
if H “ I, then PJ pBq “ pJP pBq “ P rpJ P Bs, where B belongs to EJ. If
J “ tt1, . . . , tnu is a ﬁnite set, then we have
PJ rB1 ˆ ¨ ¨ ¨ ˆ Bns “ P
“
X´1
J
pB1 ˆ ¨ ¨ ¨ ˆ Bnq
‰
“ P rX pt1q P B1, . . . , X ptnq P Bns ,
with Bj P Etj, for 1 ď j ď n.
1.11. Remark. If the process tXptq : t P Iu is interpreted as the movement
of a particle, which at time t happens to be in the state spaces Et, and if
J “ tt1, . . . , tnu is a ﬁnite subset of I, then the probability measure PJ has the
following interpretation:
For every collection of sets B1 P Et1, . . . , Bn P Etn the number
PJ rB1 ˆ ¨ ¨ ¨ ˆ Bns
is the probability that at time t1 the particle is in B1, at time t2 it is
in B2, . . ., and at time tn it is in Bn.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
13 
Stochastic processes: prerequisites
1.12. Definition. Let H be the collection of all ﬁnite subsets of I. Then the
family
␣`
EJ, EJ, PJ
˘
: J P H
(
is called the family of ﬁnite-dimensional distri-
butions of the process tXptq : t P Iu; the one-dimensional distributions
␣`
Et, Et, Pttu
˘
: t P I
(
are often called the marginals of the process.
The family of ﬁnite-dimensional distributions is a projective or consistent family
in the sense as explained in the following deﬁnition.
1.13. Definition. A family of probability spaces
␣`
EJ, EJ, PJ
˘
: J P H
(
is
called a projective, a consistent system, or a cylindrical measure provided that
PJ pBq “ pH
J pPHq pBq “ PH
“
pH
J P B
‰
for all ﬁnite subsets J Ă H, J, H P H, and for all sets B P EJ.
1.14. Theorem (Theorem of Kolmogorov). Let
␣`
EJ, EJ, PJ
˘
: J P H
(
be a
projective system of probability spaces.
Suppose that every space Et is a σ-
compact metrizable Hausdorﬀspace. Then there exists a unique probability space
`
EI, EI, PI
˘
with the property that for all ﬁnite subsets J P H the equality
PJ pBq “ PI rpJ P Bs holds for all B P EJ.
Theorem 5.81 is the same as Theorem 1.14, but formulated for Polish and
Souslin spaces; its proof can be found in Chapter 5. Theorem 1.14 is the same
as Theorem 3.1. The reason that the conclusion in Theorem 1.14 holds for σ-
compact metrizable topological Hausdorﬀspaces is the fact that a ﬁnite Borel
measure µ on a metrizable σ-compact space E is regular in the sense that
µpBq “
sup
KĂB, K compact
µpKq “
inf
UĄK, U open µpUq,
B any Borel subset E. (1.10)
1.15. Lemma. Let E be a σ-compact metrizable Hausdorﬀspace.
Then the
equality in (1.10) holds for all Borel subsets B of E.
Proof. The equalities in (1.10) can be deduced by proving that the collec-
tion D deﬁne by
D “
"
B P BE : sup
KĂB
µpKq “ inf
UĄB µpUq
*
“
"
B P BE : sup
FĂB
µpFq “ inf
UĄB µpUq
*
(1.11)
contains the open subsets of E, is closed under taking complements, and is
closed under taking mutually disjoint countable unions. The second equality
holds because every closed subset of E is a countable union of compact subsets.
In (1.11) the sets K are taken from the compact subsets, the sets U from the
open subsets, and the sets F from the closed subsets of E. It is clear that D is
closed under taking complements. Let px, yq ÞÑ dpx, yq be a metric on E which
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
14 
Stochastic processes: prerequisites
is compatible with its topology. Let F be a closed subset of E, and deﬁne Un
by
Un “
"
x P E : inf
yPF d px, yq ă 1
n
*
.
Then the subset Un is open, Un`1 Ą Un, and F “ Ş Un. It follows that µ pFq “
infn µ pUnq, and consequently, F belongs to D. In other words the collection D
contains the closed, and so the open subsets of E. Next let pBnqn be a sequence
of subsets in D. Fix ε ą 0, and choose closed subsets Fn Ă Bn, and open
subsets Un Ą Bn, such that
µ pBnzFnq ď ε2´n´1,
and
µ pUnzBnq ď ε2´n.
(1.12)
From (1.12) it follows that
µ
˜˜ 8
ď
n“1
Un
¸
z
˜ 8
ď
n“1
Bn
¸¸
ď µ
˜ 8
ď
n“1
pUnzBnq
¸
ď
8
ÿ
n“1
µ pUnzBnq ď ε
8
ÿ
n“1
2´n “ ε.
(1.13)
From (1.13 it follows that
µ
˜ 8
ď
n“1
Bn
¸
“ inf
#
µpUq : U Ą
8
ď
n“1
Bn,
U open
+
.
(1.14)
The same argumentation shows that
µ
˜˜ 8
ď
n“1
Bn
¸
z
˜ 8
ď
n“1
Fn
¸¸
ď
8
ÿ
n“1
µ pBnzFnq ď ε
8
ÿ
n“1
2´n´1 “ 1
2ε.
(1.15)
From (1.15) it follows that
µ
˜˜ 8
ď
n“1
Bn
¸
z
˜ Nε
ď
n“1
Fn
¸¸
ď ε
(1.16)
for Nε large enough. From (1.16 it follows that
µ
˜ 8
ď
n“1
Bn
¸
“ sup
#
µpFq : F Ă
8
ď
n“1
Bn,
F closed
+
.
(1.17)
From (1.14) and (1.17) it follows that Ť8
n“1 Bn belongs to D. As already men-
tioned, since every closed subset is the countable union of compact subsets the
supremum over closed subsets in (1.17) may replaced with a supremum over
compact subsets. Altogether, this completes the proof of Lemma 1.15.
□
It is a nice observation that a locally compact Hausdorﬀspace is metrizable and
σ-compact if and only if it is a Polish space. This is part of Theorem 5.3 (page
29) in Kechris [68]. This theorem reads as follows.
1.16. Theorem. Let E be a locally compact Hausdorﬀspace. The following
assertions are equivalent:
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
15 
Stochastic processes: prerequisites
(1) The space E is second countable, i.e. E has a countable basis for its
topology.
(2) The space E is metrizable and σ-compact.
(3) The space E has a metrizable one-point compactiﬁcation (or Alexan-
droﬀcompactiﬁcation).
(4) The space E is Polish, i.e. E is complete metrizable and separable.
(5) The space E is homeomorphic to an open subset of a compact metrizable
space.
A second-countable locally-compact Hausdorﬀspace is Polish: let pUiqi be a
countable basis of open subsets with compact closures pKiqi, and let Vi be an
open subset with compact closure and containing Ki. From Urysohn’s Lemma,
let 0 ď fi ď 1 be continuous functions identically 0 oﬀVi, identically 1 on Ki,
and put
dpx, yq “
8
ÿ
i“1
2´i |fipxq ´ fipyq| `
ˇˇˇˇ
1
ř8
i“1 2´ifipxq ´
1
ř8
i“1 2´ifipyq
ˇˇˇˇ ,
x, y P E.
(1.18)
The triangle inequality for the usual absolute value shows that this is a metric.
This metric gives the same topology, and it is straightforward to verify its
completeness. For this argument see Garrett [57].
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
16 
Stochastic processes: prerequisites
4. A deﬁnition of Brownian motion
In this section we give a (preliminary) deﬁnition of Brownian motion.
4.1. Gaussian measures on Rd. For every t ą 0 we deﬁne the Gaussian
kernel on Rd as the function
pd pt, x, yq “
1
p2πtqd{2 exp
˜
´|x ´ y|2
2t
¸
.
Then we have
ş
pd pt, x, zq dz “ 1, and
pdps, x, zqppt, z, yq “ pdps ` t, x, yqpd
ˆ st
s ` t, sx ` ty
s ` t , z
˙
.
Hence the function pd pt, x, yq satisﬁes the equation of Chapman-Kolmogorov:
ż
pdps, x, zqpdpt, z, yqdz “ pd ps ` t, x, yq .
This property will enable us to consider d-dimensional Brownian motion as a
Markov process. Next we calculate the ﬁnite-dimensional distributions of the
Brownian motion.
4.2. Finite dimensional distributions of Brownian motion. Let 0 ă
t1 ă ¨ ¨ ¨ ă tn ă 8 be a sequence of time instances in p0, 8q, and ﬁx x0 P Rd.
Deﬁne the probability measure Px0;t1,...,tn on the Borel ﬁeld of Rd ˆ ¨ ¨ ¨ ˆ Rd (n
times) by (t0 “ 0)
Px0;t1,...,tn rB1 ˆ ¨ ¨ ¨ ˆ Bns “
ż
B1
. . .
ż
Bn
dxn . . . dx1
n
ź
j“1
pd ptj ´ tj´1, xj´1, xjq ,
(1.19)
where B1, . . . , Bn are Borel subsets of Rd. Then, with Bk “ Rd, we have
Px0;t1,...,tk´1,tk,tk`1,...,tn
“
B1 ˆ ¨ ¨ ¨ ˆ Bk´1 ˆ Rd ˆ Bk`1 ˆ ¨ ¨ ¨ ˆ Bn
‰
“
ż
B1
. . .
ż
Bk´1
ż
Rd
ż
Bk`1
. . .
ż
Bn
dxn . . . dxk`1 dxk dxk´1 . . . dx1
k´1
ź
j“1
pd ptj ´ tj´1, xj´1, xjq
pd ptk ´ tk´1, xk´1, xkq pd ptk`1 ´ tk, xk, xk`1q
n
ź
j“k`2
p ptj ´ tj´1, xj´1, xjq
(Chapman-Kolmogorov)
“
ż
B1
. . .
ż
Bk´1
ż
Bk`1
. . .
ż
Bn
dxn . . . dxk`1 dxk´1 . . . dx1
k´1
ź
j“1
pd ptj ´ tj´1, xj´1, xjq
pd ptk`1 ´ tk´1, xk´1, xk`1q
n
ź
j“k`2
p ptj ´ tj´1, xj´1, xjq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
17 
Stochastic processes: prerequisites
“ Px0;t1,...,tk´1,tk`1,...,tn rB1 ˆ ¨ ¨ ¨ ˆ Bk´1 ˆ Bk`1 ˆ ¨ ¨ ¨ ˆ Bns .
(1.20)
It follows that the family
$
&
%
¨
˝Rd ˆ ¨ ¨ ¨ ˆ Rd
looooooomooooooon
n times
, Bd b ¨ ¨ ¨ b Bd
looooooomooooooon
n times
, Px0;t1,...,tn
˛
‚; 0 ă t1 ă ¨ ¨ ¨ ă tn ă 8, n P N
,
.
-
is a projective or consistent system. Such families are also called cylindrical
measures. The extension theorem of Kolmogorov implies that in the present
situation a cylindrical measure can be considered as a genuine measure on the
product ﬁeld of Ω:“
`
Rd˘r0,8q. This is the measure corresponding to Brownian
motion starting at x0. More precisely, the theorem of Kolmogorov says that
there exists a probability space pΩ, F, Px0q and state variables Xptq : ΩÑ Rd,
t ě 0, such that
Px0 rX pt1q P B1, . . . , X ptnq P Bns “ Px0;t1,...,tn rB1 ˆ ¨ ¨ ¨ ˆ Bns ,
where the subsets Bj, 1 ď j ď n, belong to Bd. It is assumed that
Px0 rXp0q “ x0s “ 1.
5. Martingales and related processes
Let pΩ, F, Pq be a probability space, and let tFt : t P Iu be a family of subﬁelds
of F, indexed by a totally ordered index set pI, ďq. Suppose that the family
tFt : t P Iu is increasing in the sense that s ď t implies Fs Ď Ft. Such a family
of σ-ﬁelds is called a ﬁltration. A stochastic process tXptq : t P Iu, where Xptq,
t P I, are mappings from Ωto Et, is called adapted, or more precisely, adapted
to the ﬁltration tFt : t P Iu if every Xptq is Ft-Et-measurable. For the σ-ﬁeld
Ft we often take (some completion of) the σ-ﬁeld generated by Xpsq, s ď t:
Ft “ σ tXpsq : s ď tu.
1.17. Definition. An adapted process tXptq : t P Iu with state space pR, Bq
is called a super-martingale if every variable Xptq is P-integrable, and if s ď t,
s, t P I, implies E
“
Xptq
ˇˇ Fs
‰
ď Xpsq, P-almost surely. An adapted process
tXptq : t P Iu with state space pR, Bq is called a sub-martingale if every variable
Xptq is P-integrable, and if s ď t, s, t P I, implies E
“
Xptq
ˇˇ Fs
‰
ě Xpsq, P-
almost surely. If an adapted process is at the same time a super- and a sub-
martingale, then it is called a martingale.
The martingale in the following example is called a closed martingale.
1.18. Example. Let X8 belong to L1 pΩ, F, Pq, and let tFt : t P r0, 8qu be a
ﬁltration in F. Put Xptq “ E
“
X8
ˇˇ Ft
‰
, t ě 0. Then the process tXptq: t ě 0u
is a martingale with respect to the ﬁltration tFt : t P r0, 8qu.
The following theorem shows that uniformly integrable martingales are closed
martingales.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
18 
Stochastic processes: prerequisites
1.19. Theorem (Doob’s theorem). Any uniformly integrable martingale
tXptq:t ě 0u
in L1 pΩ, F, Pq
converges P-almost surely and in mean (i.e.
in L1 pΩ, F, Pq) to a stochastic
variable X8 such that for every t ě 0 the equality Xptq “ E
“
X8
ˇˇ Ft
‰
holds
P-almost surely.
Let F be a subset of L1 pΩ, F, Pq. Then F is uniformly integrable if for every
ε ą 0 there exists a function g P L1 pΩ, F, Pq such that
ş
t|f|ě|g|u |f| dP ď ε for all
f P F. Since P is a ﬁnite positive measure we may assume that g is a (large)
positive constant.
1.20. Theorem. Sub-martingales constitute a convex cone:
(i) A positive linear combination of sub-martingales is again a sub-martin-
gale; the space of sub-martingales forms a convex cone.
(ii) A convex function of a sub-martingale is a sub-martingale.
Not all martingales are closed, as is shown in the following example.
1.21. Example. Fix t ą 0, and x, y P Rd. Let
tpΩ, F, Pxq , pXptq, t ě 0q , pϑt : t ě 0q , pRn, Bnqu
be Brownian motion starting at x P Rd, and put, as above,
pd pt, x, yq “
1
p2πtqd{2 exp
˜
´|x ´ y|2
2t
¸
.
The process s ÞÑ p pt ´ s, Xpsq, yq is Px-martingale on the half-open interval
r0, tq.
5.1. Stopping times. A stochastic variable T : ΩÑ r0, 8s is called a
stopping time with respect to the ﬁltration tFt : t ě 0u, if for every t ě 0 the
event tT ď tu belongs to Ft. If T is a stopping time, the process t ÞÑ 1rTďts is
adapted to tFt : t ě 0u. The meaning of a stopping is the following one. The
moment T is the time that some phenomena happens. If at a given time t the
information contained in Ft suﬃces to conclude whether or not this phenomena
occurred before time t, then T is a stopping time. Let
tpΩ, F, Pxq , pXptq, t ě 0q , pϑt : t ě 0q , pRn, Bnqu
be Brownian motion starting at x P Rd, let p : Rd Ñ p0, 8q be a strictly positive
continuous function, and O an open subset of Rd. The ﬁrst exit time from O,
or the ﬁrst hitting time of the complement of O, deﬁned by
T “ inf
␣
t ą 0 : Xptq P RdzO
(
is a (very) relevant stopping time. The time T is a so-called terminal stopping
time: on the event tT ą su it satisﬁes s ` T ˝ ϑs “ T. Other relevant stopping
times are:
τξ “ inf
"
t ą 0 :
ż t
0
p pXpsqq ds ą ξ
*
,
ξ ě 0.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
19 
Stochastic processes: prerequisites
Such stopping times are used for (stochastic) time change:
τξ ` τη ˝ ϑτξ “ τξ`η,
ξ,
η ě 0.
Note that the mapping ξ ÞÑ τξ is the inverse of the mapping t ÞÑ
şt
0 p pXpsqq ds.
Also note the equality: tτξ ă tu “
!şt
0 p pXpsqq ą ξ
)
,
ş8
0 p pXpsqq ds ą ξ ą 0.
The mapping ξ ÞÑ τξ is strictly increasing from the interval
“
0,
ş8
0 p pXpsqq ds
˘
onto r0, 8q. Arbitrary stopping times T are often approximated by “discrete”
stopping times: T “ limnÑ8 Tn, where Tn “ 2´n r2nTs. Notice that T ď Tn`1 ď
Tn ď T ` 2´n, and that tTn “ k2´nu “ tpk ´ 1q2´n ă T ď k2´nu, k P N.
1.22. Theorem. Let pΩ, F, Pq be a probability space, and let tFt : t ě 0u be a
ﬁltration in F. The following assertions hold true:
(1) constant times are stopping times: for every t ě 0 ﬁxed the time T ” t
is a stopping time;
(2) if S and T are stopping times, then so are min pS, Tq and max pS, Tq;
(3) If T is a stopping time, then the collection FT deﬁned by
FT “ tA P F : A X tT ď ts P Ft, for all t ě 0u
is a subﬁeld of F;
(4) If S and T are stopping times, then S`T ˝ϑS is a stopping time as well,
provided the paths of the process are P-almost surely right-continuous
and the same is true for the ﬁltration tFt : t ě 0u.
The ﬁltration tFt : t ě 0u is right-continuous if Ft “ Ş
sąt Fs, t ě 0. The (sam-
ple) paths t ÞÑ Xptq are said to be P-almost surely right-continuous, provided
for all t ě 0 we have Xptq “ limsÓt Xpsq, P-almost surely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
20 
Stochastic processes: prerequisites
The following theorem shows that in many cases ﬁxed times can be replaced
with stopping times. In particular this is true if we study (right-continuous)
sub-martingales, super-martingales or martingales.
1.23. Theorem (Doob’s optional sampling theorem). Let pXptq : t ě 0q be a
uniformly integrable process in L1 pΩ, F, Pq which is a sub-martingale with re-
spect to the ﬁltration pFt : t ě 0q. Let S and T be stopping times such that
S ď T. Then E
“
XpTq
ˇˇ FS
‰
ě XpSq, P-almost surely.
Similar statements hold for super-martingales and martingales.
Notice that XpTq stands for the stochastic variable ω ÞÑ X pTpωqq pωq “
X pTpωq, ωq.
We conclude this introduction with a statement of the decomposition theorem
of Doob-Meyer. A process tXptq : t ě 0u is of class (DL) if for every t ą 0 the
family
tXpτq : 0 ď τ ď t, τ is an pFtq -stopping timeu
is uniformly integrable. An Ft-martingale tMptq : t ě 0u is of class (DL), an
increasing adapted process tAptq : t ě 0u in L1pΩ, F, Pq is of class (DL) and
hence the sum tMptq ` Aptq : t ě 0u is of class (DL). If tXptq : t ě 0u is a
submartingale and if µ is a real number, then the process tmax pXptq, µq : t ě 0u
is a sub-martingale of class (DL). Processes of class (DL) are important in the
Doob-Meyer decomposition theorem. Let pΩ, F, Pq be a probability space, let
tFt : t ě 0u be a right-continuous ﬁltration in F and let tXptq : t ě 0u be right
continuous sub-martingale of class (DL) which possesses almost sure left limits.
We mention the following version of the Doob-Meyer decomposition theorem.
See Remark 3.54 as well.
1.24. Theorem. Let tXptq : t ě 0u be a sub-martingale of class (DL) which
has P almost surely left limits, and which is right-continuous. Then there ex-
ists a unique predictable right continuous increasing process tAptq : t ě 0u with
Ap0q “ 0 such that the process tXptq ´ Aptq : t ě 0u is an Ft-martingale.
A process pω, tq ÞÑ Xptqpωq “ X pt, ωq is predictable if it is measurable with
respect to the σ-ﬁeld generated by tA ˆ pa, bs : A P Fa, a ă bu. For more details
on c`adl`ag sub-martingales, see Theorem 3.77. The following proposition says
that a non-negative right-continuous sub-martingale is of class (DL).
1.25. Proposition. Let pΩ, F, Pq be a probability space, let pFtqtě0 be a ﬁltration
of σ-ﬁelds contained in F. Suppose that t ÞÑ Xptq is a right-continuous sub-
martingale relative to the ﬁltration pFtqtě0 attaining its values in r0, 8q. Then
the family tXptq : t ě 0u is of class (DL).
In fact it suﬃces to assume that there exists a real number m such that Xptq ě
´m P-almost surely. This follows from Proposition 1.25 by considering Xptq`m
instead of Xptq.
If t ÞÑ Mptq is a continuous martingale in L2 pΩ, F, Pq, then t ÞÑ |Mptq|2 is a
non-negative sub-martingale, and so it splits as the sum of a martingale t ÞÑ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
21 
Stochastic processes: prerequisites
|Mptq|2 ´⟨M, M⟩ptq and an increasing process t ÞÑ ⟨M ă M⟩ptq, the quadratic
variation process of Mptq.
Proof of Proposition 1.25. Fix t ą 0, and let τ : ΩÑ r0, ts be a
stopping time. Let for m P N the stopping time τm : ΩÑ r0, 8s be deﬁned by
τm “ inf ts ą 0 : Xpsq ą mu if Xpsq ą m for some s ă 8, otherwise τm “ 8.
Then the event tXpτq ą mu is contained in the event tτm ď τu. Hence,
E rXpτq : Xpτq ą ms ď E rXptq : Xpτq ą ms ď E rXptq : τm ď τs
ď E rXptq : τm ď ts .
(1.21)
Since, P-almost surely, τm Ò 8 for m Ñ 8, it follows that
lim
mÑ8 sup tE rXpτq : Xpτq ą ms : τ P r0, ts : τ stopping timeu “ 0.
Consequently, the sub-martingale t ÞÑ Xptq is of class (DL). The proof of Propo-
sition 1.25 is complete now.
□
It is perhaps useful to insert the following proposition.
1.26. Proposition. Processes of the form Mptq`Aptq, with Mptq a martingale
and with Aptq an increasing process in L1 pΩ, F, Pq are of class (DL).
Proof. Let tXptq “ Mptq ` Aptq : t ě 0u be the decomposition of the
sub-martingale tXptq : t ě 0u in a martingale tMptq : t ě 0u and an increasing
process tAptq : t ě 0u with Ap0q “ 0 and 0 ď τ ď t be any Ft-stopping time.
Here t is some ﬁxed time. For N P N we have
E p|Xpτq| : |Xpτq| ě Nq ď E p|Mpτq| : |Xpτq| ě Nq ` E pApτq : |Xpτq| ě Nq
ď E p|Mptq| : |Xpτq| ě Nq ` E pApτq : |Xpτq| ě Nq
ď E p|Mptq| ` Aptq : |Xpτq| ě Nq
ď E
ˆ
|Mptq| ` Aptq : sup
0ďsďt |Xpsq| ě N
˙
.
Since, by the Doob’s maximality theorem 1.28,
NP
"
sup
0ďsďt |Xpsq| ě N
*
ď NP
"
sup
0ďsďt |Mpsq| ě N
2
*
` NP
"
sup
0ďsďt Apsq ě N
2
*
ď 2E p|Mptq| ` Aptqq ,
it follows that
lim
NÑ8 sup tE p|Xpτq| : |Xpτq| ě Nq : 0 ď τ ď t, τ stopping timeu “ 0.
This proves Proposition 1.26.
□
First we formulate and prove Doob’s maximal inequality for time-discrete sub-
martingales.
In Theorem 1.27 the sequence i ÞÑ Xi is deﬁned on a ﬁltered
probability space pΩ, Fi.PqiPN, and in Theorem 1.28 the process t ÞÑ Xptq is
deﬁned on a ﬁltered probability space pΩ, Ft.Pqtě0.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
22 
Stochastic processes: prerequisites
1.27. Theorem (Doob’s maximal inequality). Let pXiqiPN be a sub-martingale
w.r.t. a ﬁltration pFiqiPN. Let Sn “ max1ďiďn Xi be the running maximum of
Xi. Then for any ℓą 0,
P rSn ě ℓs ď 1
ℓE
“
X`
n 1tSněℓu
‰
ď 1
ℓE
“
X`
n
‰
,
(1.22)
where X`
n “ Xn _ 0. In particular, if Xi is a martingale and Mn “ max
1ďiďn |Xi|,
then
P rMn ě ℓs ď 1
ℓE
“
|Xn| 1tMněℓu
‰
ď 1
ℓE r|Xn|s .
(1.23)
Proof. Let τℓ“ inf ti ě 1 : Xi ě ℓu. Then P rSn ě ℓs “ řn
i“1 P rτℓ“ is.
For each 1 ď i ď n,
P rτℓ“ is “ E
“
1tXiěℓu1tτℓ“iu
‰
ď 1
ℓE
“
X`
i 1tτℓ“iu
‰
.
(1.24)
Note that tτℓ“ iu P Fi, and X`
i
is a sub-martingale because Xi itself is a
sub-martingale while φpxq “ x` “ x _ 0 “ maxpx, 0q is an increasing convex
function. Therefore
E
“
X`
n 1tτℓ“iu
ˇˇ Fi
‰
“ 1tτℓ“iuE
“
X`
n
ˇˇ Fi
‰
ě 1tτℓ“iu
`
E
“
Xn
ˇˇ Fi
‰˘` ě 1tτℓ“iuX`
i ,
and hence E
“
X`
i 1tτℓ“iu
‰
ď E
“
X`
n 1tτℓ“iu
‰
.
Substituting this inequality into
(1.24) and then summing over 1 ď i ď n then yields (1.22). The inequality in
(1.23) follows by applying (1.22 to the sub-martingale |Xi|.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
23 
Stochastic processes: prerequisites
Next we formulate and prove Doob’s maximal inequality for continuous time
sub-martingales.
1.28. Theorem (Doob’s maximal inequality). Let pXptqqtě0 be a sub-martingale
w.r.t. a ﬁltration pFtqtě0. Let Sptq “ sup0ďsďt Xpsq be the running maximum
of Xptq. Suppose that the process t ÞÑ Xptq is P-almost surely continuous from
the right (and possesses left limits P-almost surely). Then for any ℓą 0,
P rSptq ě ℓs ď 1
ℓE
“
Xptq`1tSptqěℓu
‰
ď 1
ℓE
“
X`ptq
‰
,
(1.25)
where X`ptq “ Xptq _ 0 “ max pXptq, 0q.
In particular, if t ÞÑ Xptq is a
martingale and Mptq “ sup
0ďsďt |Xptq|, then
P rMptq ě ℓs ď 1
ℓE
“
|Xptq| 1tMptqěℓu
‰
ď 1
ℓE r|Xptq|s .
(1.26)
Proof. Let, for every N P N, τN be the pFtqtě0-stopping time deﬁned
by τN “ inf tt ą 0 : Xptq` ě Nu. In addition deﬁne the double sequence of
processes Xn.Nptq by
Xn,Nptq “ X
`
2´n r2nts ^ τN
˘
.
Theorem 1.28 follows from Theorem 1.27 by applying it the processes t ÞÑ
Xn,Nptq, n P N, N P N. As a consequence of Theorem 1.27 we see that Theorem
1.28 is true for the double sequence t ÞÑ Xn,Nptq, because, essentially speaking,
these processes are discrete-time processes with the property that the processes
pn, tq ÞÑ Xn,Nptq` attain P-almost surely their values in the interval r0, Ns.
Then we let n Ñ 8 to obtain Theorem 1.28 for the processes t ÞÑ X pt ^ τNq,
N P N. Finally we let N Ñ 8 to obtain the full result in Theorem 1.28.
□
5.2. Additive processes. In this ﬁnal section we introduce the notion
of additive and multiplicative processes. Let E be a second countable locally
compact Hausdorﬀspace. In the non-time-homogeneous case we consider real-
valued processes which depend on two time parameters: pt1, t2q ÞÑ Z pt1, t2q,
0 ď t1 ď t2 ď T. It is assumed that for all 0 ď t1 ď t2 ď T, the variable
Z pt1, t2q only depends, or is measurable with respect to, σ tXpsq : t1 ď s ď t2u.
Such a process is called additive if
Z pt1, t2q “ Z pt1, tq ` Z pt, t2q ,
t1 ď t ď t2.
The process Z is called multiplicative if
Z pt1, t2q “ Z pt1, tq ¨ Z pt, t2q ,
t1 ď t ď t2.
Let p : r0, Ts ˆ E Ñ R be a continuous function, and let tXptq : 0 ď t ď Tu be
an E-valued process which has left limits in E, and which is right-continuous
(i.e. it is c`adl`ag). Put Z pt1, t2q “
şt2
t1 p ps, Xpsqq ds. Then the process pt1, t2q ÞÑ
Z pt1, t2q, 0 ď t1 ď t2 ď T is additive, and the process pt1, t2q ÞÑ exp pZ pt1, t2qq,
0 ď t1 ď t2 ď T, is multiplicative.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
24 
Stochastic processes: prerequisites
Next we consider the particular case that we deal with time-homogeneous pro-
cesses like Brownian motion:
tpΩ, F, Pxq , pXptq, t ě 0q , pϑt : t ě 0q , pRn, Bnqu ,
which represents Brownian motion starting at x P Rd.
An adapted process
t ÞÑ Zptq is called additive if Z ps ` tq “ Z psq ` Z ptq ˝ ϑs, Px-almost surely,
for all s, t ě 0. It is called multiplicative provided Z ps ` tq “ Z psq ¨ Z ptq ˝ ϑs,
Px-almost surely, for all s, t ě 0. Examples of additive processes are integrals
of the form Zptq “
şt2
0 p pXpsqq ds, where x ÞÑ ppxq is a continuous (or Borel)
function on Rd, or stochastic integrals (Itˆo, Stratonovich integrals) of the form
Zptq “
şt
0 p pXpsqq dXpsq. Such integrals have to be interpreted in some L2-
sense.
More details will be given in Section 6.
If t ÞÑ Zptq is an additive
process, then its exponent t ÞÑ exp pZptqq is a multiplicative process. If T is a
terminal stopping time, then the process t ÞÑ 1tTątu is a multiplicative process.
Let pXnqnPN be a sequence of non-negative i.i.d. random variables each of which
has density f1 ě 0.
Suppose that fn is the density of the distribution of
řn
j“1 Xj.
Note “i.i.d.”
means “independent, identically distributed”.
Then
P
« nÿ
j“1
Xj ď t
ﬀ
“
ż t
0
fnpsqds, and hence
ż t
0
fn`1psqds “ P
«n`1
ÿ
j“1
Xj ď t
ﬀ
“ P
« nÿ
j“1
Xj ` Xn`1 ď t
ﬀ
“
ż t
0
fnpρqf1pt ´ ρqdρ.
It follows that
ż t
0
fnpsqds ´
ż t
0
fn`1pρqdρ “
ż t
0
fnpsqds ´
ż t
0
ż ρ
0
fnpsqf1pρ ´ sqds dρ
“
ż t
0
fnpsqds ´
ż t
0
fnpsq
ż t
s
f1pρ ´ sqdρ ds
“
ż t
0
fnpsq
ˆ
1 ´
ż t
s
f1pρ ´ sqdρ
˙
ds
“
ż t
0
fnpsq
ż 8
t
f1pρ ´ sqdρ ds
“
ż t
0
fnpsq
ż 8
t´s
f1pρqdρ ds.
(1.27)
If f1psq “ λe´λs, then fnpsq “ λnsn´1
pn ´ 1q!e´λs. This follows by induction.
5.3. Continuous time discrete processes. Here we suppose that the
process
tpΩ, F, Pq , pXptq : t ě 0q , pϑt : t ě 0q , pS, Squ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
25 
Stochastic processes: prerequisites
is governed by a time-homogeneous or stationary transition probabilities:
pj,iptq “ P
“
Xptq “ j
ˇˇ Xp0q “ i
‰
“ P
“
Xpt ` sq “ j
ˇˇ Xpsq “ i
‰
,
i, j P S,
(1.28)
for all s ě 0. Here, S is a discrete state space, e.g. S “ Z, S “ Zn, S “ N, or
S “ t0, Nu. The measurable space pΩ, Fq is called the sample or sample path
space. Its elements ω P Ωare called realizations. The mappings Xptq : ΩÑ S
are called the state variables; the application t ÞÑ Xptqpωq is called a sample
path or realization. The translation operators ϑt, t ě 0, are mappings from
Ωto Ωwith the property that: Xpsq ˝ ϑt “ Xps ` tq, P-almost surely. For
the time being these operators will not be used; they are very convenient to
express the Markov property in the time-homogeneous case. We assume that
the Chapman-Kolmogorov conditions are satisﬁed:
pj,i ps ` tq “
ÿ
kPS
pj,kpsqpk,iptq, i, j P S, s, t ě 0.
(1.29)
In fact the Markov property is a consequence of the Chapman-Kolmogorov
identity (1.29). From the Chapman-Kolmogorov (1.29) the following important
identity follows:
P ps ` tq “ PpsqPptq,
s, t ě 0.
(1.30)
The identity in (1.30) is called the semigroup property; the identity has to be
interpreted as matrix multiplication. Suppose that the functions t ÞÑ pj,iptq, j,
i P S, are right diﬀerentiable at t “ 0. The latter means that the following
limits exist:
qj,i “ lim
△Ó0
pj,i p△q ´ pj,ip0q
△
,
i, j P S.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
26 
Stochastic processes: prerequisites
We assume that pj,ip0q “ δj,i, where δj,i is the Dirac delta function: δj,i “ 0 if
j ‰ i, and δj,j “ 1. Put Q “ pqj,iqi,jPS. Then the matrix Q is a Kolmogorov
matrix in the sense that qj,i ě 0 for j ‰ i and ř
jPS qj,i “ 0. It follows that
qi,i “ ´ ř
jPS,j‰i qj,i ď 0. The reason that the oﬀ-diagonal entries qj,i, j ‰ i, are
non-negative is due to the fact that for j ‰ i we have
qj,i “ lim
tÓ0
pj,iptq ´ pj,ip0q
t
“ lim
tÓ0
pj,iptq ´ δj,ip0q
t
“ lim
tÓ0
pj,iptq
t
ě 0.
In addition, we have
ÿ
jPS
qj,i “
ÿ
jPS
lim
tÓ0
pj,iptq ´ pj,ip0q
t
“ lim
tÓ0
ÿ
jPS
pj,iptq ´ pj,ip0q
t
“ lim
tÓ0
ř
jPS pj,iptq ´ ř
jPS pj,ip0q
t
“ lim
tÓ0
1 ´ 1
t
“ 0,
(1.31)
provided we may interchange the summation and the limit. Finally we have the
following general fact. Let t ÞÑ Pptq be the matrix function t ÞÑ ppj,iptqqi,jPS.
Then Pptq satisﬁes the Kolmogorov backward and forward diﬀerential equation:
dPptq
dt
“ QPptq “ PptqQ,
t ě 0.
(1.32)
The ﬁrst equality in (1.32) is called the Kolmogorov forward equation, and the
second one the Kolmogorov backward equation. The solution of this matrix-
valued diﬀerential equation is given by Pptq “ etQPp0q.
But since Pp0q “
ppj,ip0qqj,iPS “ pδj,iqi,jPS is the identity matrix, it follows that Pptq “ etQ. The
equalities in (1.32) hold true, because by the semigroup property (1.30) we have:
P pt ` △ptqq ´ P ptq
△ptq
“ P p△ptqq ´ Pp0q
△ptq
P ptq “ P ptq P p△ptqq ´ Pp0q
△ptq
. (1.33)
Then we let △ptq tend to 0 in (1.33) to obtain (1.32).
5.4. Poisson process. We begin with a formal deﬁnition.
1.29. Definition. A Poisson process
tpΩ, F, Pq , pXptq, t ě 0q , pϑt, t ě 0q , pN, Nqu
(see (1.46) below) is a continuous time process Xptq, t ě 0, with values in
N “ t0, 1, . . .u which possesses the following properties:
(a) For ∆t ą 0 suﬃciently small the transition probabilities satisfy:
pi`1,ip∆tq “ P
“
X pt ` ∆tq “ i ` 1
ˇˇ Xptq “ i
‰
“ λ∆t ` o p∆tq ;
pi,ip∆tq “ P
“
X pt ` ∆tq “ i
ˇˇ Xptq “ i
‰
“ 1 ´ λ∆t ` o p∆tq ;
pj,ip∆tq “ P
“
X pt ` ∆tq “ j
ˇˇ Xptq “ i
‰
“ o p∆tq ;
pj,ip∆tq “ 0,
j ă i.
(1.34)
(b) The probability transitions ps, i; t, jq ÞÑ P
“
X ptq “ j
ˇˇ Xpsq “ i
‰
, t ą s,
only depend on t ´ s and j ´ i.
(c) The process tXptq : t ě 0u has the Markov property.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
27 
Stochastic processes: prerequisites
Item (b) says that the Poisson process is homogeneous in time and in space: (b)
is implicitly used in (a). Note that a Poisson process is not continuous, because
when it moves it makes a jump. Put
piptq “ pi0ptq “ pj`i,jptq “ P
“
Xptq “ j ` i
ˇˇ Xp0q “ i
‰
,
i, j P N.
(1.35)
1.30. Proposition. Let the process
tpΩ, F, Pq , pXptq, t ě 0q , pϑt, t ě 0q , pN, Nqu
possess properties (a) and (b) in Deﬁnition 1.29. Then the following equality
holds for all t ě 0 and i P N:
piptq “ pλtqi
i! e´λt.
(1.36)
1.31. Remark. It is noticed that the equalities in (1.42), (1.40), and (1.44) only
depend on properties (a) and (b) in Deﬁnition 1.29. So that from (a), and (b)
we obtain
d
dtpiptq ` λpiptq “ λ pλtqi´1
pi ´ 1q!e´λt “ λpi´1ptq,
i ě 1,
(1.37)
and hence
pj,iptq “ pj´iptq “ P
“
Xptq “ j
ˇˇ Xp0q “ i
‰
“ pλtqj´i
pj ´ iq!e´λt,
j ě i.
(1.38)
If 0 ď j ă i, then pj,iptq “ 0.
Proof. By deﬁnition we see that pjp0q “ P
“
Xp0q “ j
ˇˇ Xp0q “ 0
‰
“ δ0,j,
and so p0p0q “ 1 and pjp0q “ 0 for j ‰ 0. Let us ﬁrst prove that the functions
t ÞÑ piptq, i ě 1, satisfy the diﬀerential equation in (1.45) below. First suppose
that i ě 2, and we consider:
pi pt ` ∆tq ´ piptq “ P rX pt ` ∆tq “ is ´ piptq
“
iÿ
k“0
P rX pt ` ∆tq “ i, Xptq “ ks ´ piptq
“
iÿ
k“0
P
“
X pt ` ∆tq “ i
ˇˇ Xptq “ k
‰
P rXptq “ ks ´ piptq
“ P
“
X pt ` ∆tq “ i
ˇˇXptq “ i
‰
piptq ` P
“
X pt ` ∆tq “ i
ˇˇXptq “ i ´ 1
‰
pi´1ptq
`
i´2
ÿ
k“0
P
“
X pt ` ∆tq “ i
ˇˇ Xptq “ k
‰
pkptq ´ piptq
“ p1 ´ λ∆t ` o p∆tqq piptq ` pλ∆t ` o p∆tqq pi´1ptq `
i´2
ÿ
k“0
pkptqo p∆tq ´ piptq
“ ´λ∆tpiptq ` λ∆tpi´1ptq `
iÿ
k“0
pkptqo p∆tq .
(1.39)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
28 
Stochastic processes: prerequisites
From (1.39) we obtain
d
dtpiptq “ ´λpiptq ` λpi´1ptq.
(1.40)
Next we consider i “ 0:
p0 pt ` ∆tq ´ p0ptq “ P rX pt ` ∆tq “ 0s ´ p0ptq
“ P
“
X pt ` ∆tq “ 0
ˇˇ Xptq “ 0
‰
P rXptq “ 0s ´ p0ptq
“ P
“
X pt ` ∆tq “ 0
ˇˇ Xptq “ 0
‰
p0ptq ´ p0ptq “ p´λ∆t ` o p∆tqq p0ptq. (1.41)
From (1.41) we get the equation
d
dtp0ptq “ ´λp0ptq.
(1.42)
For i “ 1 we have:
p1 pt ` ∆tq ´ p1ptq “ P rX pt ` ∆tq “ 1s ´ p1ptq
“ P
“
X pt ` ∆tq “ 1
ˇˇ Xptq “ 1
‰
P rXptq “ 1s ´ p1ptq
` P
“
X pt ` ∆tq “ 1
ˇˇ Xptq “ 0
‰
P rXptq “ 0s
“ P
“
X pt ` ∆tq “ 1
ˇˇ Xptq “ 1
‰
p1ptq ´ p1ptq
` P
“
X pt ` ∆tq “ 1
ˇˇ Xptq “ 0
‰
p0ptq
“ p´λ∆t ` o p∆tqq p1ptq ` pλ∆t ` o p∆tqq p0ptq.
(1.43)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
29 
Stochastic processes: prerequisites
From (1.43) we obtain:
d
dtp1ptq “ ´λp1ptq ` λp0ptq.
(1.44)
By deﬁnition we see that pjp0q “ P
“
Xp0q “ j
ˇˇ Xp0q “ 0
‰
“ δ0,j, and so p0p0q “
1 and pjp0q “ 0 for j ‰ 0. From (1.42) we get p0ptq “ e´λt. From (1.40) and
(1.44) we obtain
d
dt
`
eλtpiptq
˘
“ λeλtpi´1ptq,
i ě 1.
(1.45)
By induction it follows that piptq “ pλtqi
i! e´λt.
This completes the proof of
Proposition 1.30.
□
In the Proposition 1.33 below we show that a process
tpΩ, F, Pq , pXptq, t ě 0q , pϑt, t ě 0q , pN, Nqu
(1.46)
which satisﬁes (a) and (b) of Deﬁnition 1.29 is a time-homogeneous Markov
process if and only if its increments are P-independent. First we prove a lemma,
which is of independent interest.
1.32. Lemma. Let the functions piptq be deﬁned as in (1.35). Then the equality
piptq “ P rXps ` tq ´ Xpsq “ is
(1.47)
holds for all i P N and all s, t ě 0.
Proof. Using the space and time invariance properties of the process Xptq
shows:
P rXps ` tq ´ Xpsq “ is “
8
ÿ
k“0
P rX ps ` tq ´ Xpsq “ i, Xpsq “ ks
“
8
ÿ
k“0
P rX ps ` tq “ i ` k, Xpsq “ ks
“
8
ÿ
k“0
P
“
X ps ` tq “ i ` k
ˇˇ Xpsq “ k
‰
P rXpsq “ ks
(space and time invariance properties of piptq)
“
8
ÿ
k“0
piptqP rXpsq “ ks “ piptq.
(1.48)
The conclusion in Lemma 1.32 follows from (1.48).
□
The following proposition says that a time and space-homogeneous process sat-
isfying the equalities in (1.34) of Deﬁnition 1.29 is a Poisson process if and only
if its increments are P-independent.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
30 
Stochastic processes: prerequisites
1.33. Proposition. The process tXptq : t ě 0u possessing properties (a) and
(b) of Deﬁnition 1.29 possesses the Markov property if and only if its increments
are P-independent. Moreover, the equalities
P rXptq ´ Xpsq “ j ´ is “ P
“
Xptq “ j
ˇˇ Xpsq “ i
‰
“ pj´ipt ´ sq “ pλpt ´ sqqj´i
pj ´ iq!
e´λpt´sq
(1.49)
hold for all t ě s ě 0 and for all j ě i, i, j P N.
Proof. First assume that the process in (1.46) has the Markov property.
Let tn`1 ą tn ą ¨ ¨ ¨ ą t1 ą t0 “ 0, and let ik, 1 ď k ď n ` 1, be nonnegative
integers. Then by induction we have
P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n ` 1s
“
8
ÿ
k“0
P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n ` 1, X ptnq “ ks
“
8
ÿ
k“0
P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n ` 1, X ptnq “ ks
P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n, X ptnq “ ks
ˆ P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n, X ptnq “ ks
“
8
ÿ
k“0
P
“
X ptn`1q ´ X ptnq “ in`1
ˇˇ X ptℓq ´ X ptℓ´1q “ iℓ, X ptnq “ k,
1 ď ℓď ns
ˆ P rX ptℓq ´ X ptℓ´1q “ iℓ, X ptnq “ k, 1 ď ℓď n, s
(Markov property)
“
8
ÿ
k“0
P
“
X ptn`1q ´ X ptnq “ in`1
ˇˇ X ptnq “ k
‰
ˆ P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n, X ptnq “ ks
“
8
ÿ
k“0
P
“
X ptn`1q “ in`1 ` k
ˇˇ X ptnq “ k
‰
ˆ P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n, X ptnq “ ks
(homogeneity in space and time of the function t ÞÑ pin`1ptq)
“
8
ÿ
k“0
pin`1 ptn`1 ´ tnq P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n, X ptnq “ ks
(apply equality (1.47) in Lemma 1.29)
“
8
ÿ
k“0
P rX ptn`1q ´ X ptnq “ in`1s
P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď n, X ptnq “ ks
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
31 
Stochastic processes: prerequisites
“ P rX ptn`1q ´ X ptnq “ in`1s P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď ns .
(1.50)
By induction and employing (1.50) it follows that
P rX ptℓq ´ X ptℓ´1q “ iℓ, 1 ď ℓď ns “
n
ź
ℓ“1
P rX ptℓq ´ X ptℓ´1q “ iℓs
“
n
ź
ℓ“1
piℓptℓ´ tℓ´1q .
(1.51)
We still have to prove the converse statement, i.e. to prove that if the increments
of the process Xptq are P-independent, then the process Xptq has the Markov
property. Therefore we take states 0 “ i0, i1, . . . , in, in`1, and times 0 “ t0 ă
t1 ă ¨ ¨ ¨ ă tn ă tn`1, and we consider the conditional probability:
P
“
X ptn`1q “ in`1
ˇˇ X pt0q “ i0, . . . , X ptnq “ in
‰
“ P rX ptn`1q “ in`1, X pt0q “ i0, . . . , X ptnq “ ins
P rX pt0q “ i0, . . . , X ptnq “ ins
“ P rX pt0q “ i0, X ptℓq ´ X ptℓ´1q “ iℓ´ iℓ´1, 1 ď ℓď n ` 1s
P rX pt0q “ i0, X ptℓq ´ X ptℓ´1q “ iℓ´ iℓ´1, 1 ď ℓď ns
(increments are P-independent)
“ P rX ptn`1q ´ X ptnq “ in`1 ´ ins
“ P
“
X ptn`1q “ in`1
ˇˇ X ptnq “ in
‰
.
(1.52)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Advanced stochastic processes: Part I
32 
Stochastic processes: prerequisites
The ﬁnal equality in (1.52) follows by invoking another application of the fact
that increments are P-independent. More precisely, since X ptn`1q ´ X ptnq and
X ptnq ´ Xp0q are P-independent we have
P
“
X ptn`1q “ in`1
ˇˇ X ptnq “ in
‰
“ P rX ptn`1q ´ X ptnq “ in`1 ´ in, X ptnq ´ Xp0q “ ins
P rX ptnq ´ Xp0q “ ins
“ P rX ptn`1q ´ X ptnq “ in`1 ´ ins .
(1.53)
The equalities in (1.49) follow from equality (1.47) in Lemma 1.32, from (1.53),
from the deﬁnition of the function piptq (see equality (1.37)), and from the
explicit value of piptq (see (1.36) in Proposition 1.30). This completes the proof
of Proposition 1.33.
□
Let pΩ, F, Pq be a probability space and let the process t ÞÑ Nptq and the proba-
bility measures Pj, j P N in
!
pΩ, F, PjqjPN , pNptq : t ě 0q , pϑs : s ě 0q , pN, Nq
)
have the following properties:
(a) It has independent increments: Npt ` hq ´ Nptq is independent of
F0
t “ σ pNpsq ´ Np0q : 0 ď s ď tq .
(b) Constant intensity: the chance of arrival in any interval of length h is
the same:
P rN pt ` hq ´ Nptq ě 1s “ λh ` ophq.
(c) Rarity of jumps ě 2:
P rN pt ` hq ´ Nptq ě 2s “ ophq.
(d) the measures Pj, j ě 1, are deﬁned by: PjrAs “ P
“
A
ˇˇ Np0q “ j
‰
;
moreover, it is assumed that P0rNp0q “ 0s “ 1.
The following theorem and its proof are taken from Stirzaker [126] Theorem
(13) page 74.
1.34. Theorem. Suppose that the process Nptq and the probability measures
satisfy (a), (b), (c) and (d). Then the process Nptq is a Poisson process and
Pj rNptq “ ks “ pλtqk´j
pk ´ jq!e´λpk´jq,
k ě j.
(1.54)
Proof. In view of Proposition 1.33 it suﬃces to prove the identity in (1.54).
To this end we put
fnptq “ P0 rNptq “ ns “ P
“
Nptq “ n
ˇˇ Np0q “ 0
‰
“ P rNptq ´ Np0q “ ns .
Then we have, for n ě 2 ﬁxed,
fnpt ` hq “ P0 rN pt ` hq “ ns “
nÿ
k“0
P0 rN pt ` hq ´ Nptq “ k, Nptq “ n ´ ks
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
33 
Stochastic processes: prerequisites
(the variables Npt ` hq ´ Nptq and Nptq are P0-independent)
“
nÿ
k“0
P0 rN pt ` hq ´ Nptq “ ks ˆ P0 rNptq “ n ´ ks
“ P0 rN pt ` hq ´ Nptq “ 0s ˆ P0 rNptq “ ns
` P0 rN pt ` hq ´ Nptq “ 1s ˆ P0 rNptq “ n ´ 1s
`
nÿ
k“2
P0 rN pt ` hq ´ Nptq “ ks ˆ P0 rNptq “ n ´ ks
“ p1 ´ P0 rN pt ` hq ´ Nptq ě 1sq ˆ P0 rNptq “ ns
` P0 rN pt ` hq ´ Nptq ě 1s ˆ P0 rNptq “ n ´ 1s
´ P0 rN pt ` hq ´ Nptq ě 2s ˆ P0 rNptq “ n ´ 1s
`
nÿ
k“2
P0 rN pt ` hq ´ Nptq “ ks ˆ P0 rNptq “ n ´ ks
“ p1 ´ λh ` ophqq ˆ fnptq ` pλh ` ophqq fn´1ptq ` ophq
nÿ
k“1
fn´kptq
“ p1 ´ λhq fnptq ` λhfn´1ptq ` ophq.
(1.55)
Observe that a similar argument yields
f1pt ` hq “ p1 ´ λhq f1ptq ` λhf0ptq ` ophq,
(1.56)
and also
f0pt ` hq “ p1 ´ λhq f0ptq ` ophq.
(1.57)
From (1.55), (1.56) and (1.57) we obtain by rearranging, dividing by h and
allowing h Ó 0:
f 1
nptq “ ´λfnptq ` λfn´1ptq,
n ě 1,
f 1
0ptq “ ´λfptq.
These equations can be solved by induction relative to n. A alternative way is
to consider the generating function
Gps, tq :“ E0
“
esNptq‰
“
8
ÿ
n“0
snP0 rNptq “ ns “
8
ÿ
n“0
snfnptq.
Then BGps, tq
Bt
“ λps ´ 1qGps, tq, and so Gps, tq “ eλtps´1q.
It follows that
P0 rNptq “ ns “ fnptq “ e´λtpλtqn
n! . Consequently, for k ě j we obtain
Pj rNptq “ ks “ P
“
Nptq “ k
ˇˇ Np0q “ j
‰
“ P
“
Nptq ´ Np0q “ k ´ j
ˇˇ Np0q “ j
‰
“ P rNptq ´ Np0q “ k ´ js “ e´λpk´jq pλtqk´j
pk ´ jq! “ (RHS of (1.54).
This completes the proof of Theorem 1.34.
□
Download free eBooks at bookboon.com

Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
35 
Renewal theory and Markov chains
CHAPTER 2
Renewal theory and Markov chains
Our main topic in this chapter is a discussion on renewal theory, classiﬁcation
properties of irreducible Markov chains, and a discussion on invariant measures.
Its contents is mainly taken from Stirzaker [126].
1. Renewal theory
Let pXrqrPN be a sequence of independent identically distributed random vari-
ables with the property that P rXr ą 0s ą 0. Put Sn “ řn
r“1 Xr, S0 “ 0, and
deﬁne the renewal process Nptq by Nptq “ max tn : Sn ď tu, t ě 0. The mean
mptq “ E rNptqs is called the renewal function. We have Nptq ě n if and only
if Sn ď t, and hence
P rNptq “ ns “ P rSn ď ts ´ P rSn`1 ď ts ,
and
(2.1)
E rNptqs “
8
ÿ
r“1
P rNptq ě rs “
8
ÿ
r“1
P rSr ď ts .
(2.2)
For more details see e.g. [4] (for birth-death processes) and [126] (for renewal
theory).
2.1. Theorem. If E rXrs ą 0, then Nptq has ﬁnite moments for all t ă 8.
Proof. Since E rXrs ą 0 there exists ε ą 0 such that P rXr ě εs ě ε.
Put Mptq “ max
␣
n : ε řn
r“1 1tXrěεu ď t
(
. Since ε řn
r“1 1tXrěεu ď řn
r“1 Xr it
follows that Nptq ď Mptq, and hence, with m “ ttε´1u,
E rNptqs ď E rMptqs “
8
ÿ
n“1
P rMptq ě ns “
8
ÿ
n“1
P
«
ε
nÿ
r“1
1tXrěεu ď t
ﬀ
“
8
ÿ
n“1
ÿ
ΛĂt1,...,nu, #Λďm
P rXj ě ε, j P Λ, Xj ă ε, j R Λs
“
8
ÿ
n“1
ÿ
ΛĂt1,...,nu, #Λďm
P rX1 ě εs#Λ p1 ´ P rX1 ě εsqn´#Λ
“
8
ÿ
n“1
n^m
ÿ
k“0
ˆn
k
˙
P rX1 ě εsk p1 ´ P rX1 ě εsqn´k
ď
m
ÿ
k“0
P rX1 ě εsk
8
ÿ
n“k
ˆn
k
˙
p1 ´ P rX1 ě εsqn´k
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
36 
Renewal theory and Markov chains
“
m
ÿ
k“0
P rX1 ě εsk
8
ÿ
n“0
ˆn ` k
n
˙
p1 ´ P rX1 ě εsqn
“
1
P rXr ě εu
ˆZ t
ε
^
` 1
˙
.
(2.3)
In the ﬁnal equality in (2.3) we used the equality:
8
ÿ
n“0
ˆn ` k
n
˙
zk “
1
p1 ´ zqk`1
for |z| ă 1. The inequality in (2.3) shows Theorem 2.1.
□
It follows that E rNptqs is ﬁnite whenever E rXrs is strictly positive. This fact
will be used in Theorem 2.2.
2.2. Theorem. The following equality is valid:
E
“
SNptq`1
‰
“ E rX1s E rNptq ` 1s .
The equality in Theorem 2.2 is called Wald’s equation.
Proof. The time Nptq ` 1 is a stopping time with respect to the ﬁltration
Fn “ σ pXr : 0 ď r ď nq “ σ pSr ´ rE rX1s : 0 ď r ď nq .
Notice that the process n ÞÑ Sn ´ nE rX1s is a martingale, and hence
E
“
SpNptq`1q^n ´ ppNptq ` 1q ^ nq E rX1s
‰
“ E
“
SpNptq`1q^0 ´ ppNptq ` 1q ^ 0q E rX1s
‰
“ 0.
(2.4)
Since E rNptqs is ﬁnite, from (2.4) we get by letting n tend to 8:
0 “ lim
nÑ8 E
“
SpNptq`1q^n ´ ppNptq ` 1q ^ nq E rX1s
‰
“ E
“
SpNptq`1q ´ ppNptq ` 1qq E rX1s
‰
.
(2.5)
Consequently, the conclusion in Theorem 2.2 follows.
□
2.3. Theorem. Let pXrqrPN be a sequence of independent, identically distributed
random variables such that P rXr “ 0s “ 0. Put S0 “ 0 and Sn “ řn
r“1 Xr. Let
the process Nptq be deﬁned as in (2.2). Let Fptq be the distribution function of
the variable Xr. Put mptq “ E rNptqs. Then mptq satisﬁes the renewal equation:
mptq “ Fptq `
ż t
0
mpt ´ sqdFpsq “
8
ÿ
k“1
pµ˚
Fqk r0, ts,
(2.6)
where µFpa, bs “ Fpbq ´ Fpaq, and µ1 ˚ µ2pa, bs “
ş8
0
ş8
0 1pa,bsps ` tqdµ1psqdµ2ptq,
0 ď a ă b (i.e. convolution product of the measures µ1 and µ2). Moreover,
ˆ
1 ´
ż 8
0
e´λsdFpsq
˙
ˆ λ
ż 8
0
e´λtmptq dt “
ż 8
0
e´λsdFpsq.
If Xr are independent exponentially distributed random variables, and thus the
process pNptq : t ě 0q is Poisson of parameter λ ą 0, then mptq “ λt.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
37 
Renewal theory and Markov chains
Proof. On the event tX1 ą tu we have Nptq “ 0, and hence by using
conditional expectation we see
mptq “ E rNptqs “ E
“
Nptq1tX1ďtu
‰
“ E
“
E
“
Nptq1tX1ďtu
ˇˇ σ pX1q
‰‰
“ E
“
1tX1ďtuE
“
Nptq ´ N pX1q
ˇˇ σ pX1q
‰‰
` E
“
1tX1ďtuE
“
N pX1q
ˇˇ σ pX1q
‰‰
(on the event tX1 ď tu we have N pX1q “ 1)
“ E
“
1tX1ďtuE
“
Nptq ´ N pX1q
ˇˇ σ pX1q
‰‰
` E
“
1tX1ďtuE
“
1
ˇˇ σ pX1q
‰‰
(the distribution of Nptq´Npsq, t ą s, is the same as the distribution of Npt´sq)
“ E
“
1tX1ďtuE
“
N pt ´ X1q
ˇˇ σ pX1q
‰‰
` E
“
1tX1ďtuE
“
1
ˇˇ σ pX1q
‰‰
“ E
“
N pt ´ X1q 1tX1ďtu
‰
` E
“
1tX1ďtu
‰
“
ż t
0
m pt ´ xq dFpxq ` Fptq.
(2.7)
This completes the proof of Theorem 2.3.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
38 
Renewal theory and Markov chains
2.4. Lemma. Suppose P rXr ă 8s “ 1. Then
lim
tÑ8 Nptq “ 8,
P-almost surely.
(2.8)
Proof. Put Z “ lim
tÑ8 Nptq “ sup
tě0 Nptq. Observe that
Nptq`1
ÿ
k“1
Xk ě t, and
hence by letting t Ñ 8, the event tZ ă 8u is contained in
Z`1
ď
r“1
tXr “ 8u, and
thus
P rZ ă 8s “ P
«Z`1
ď
r“1
tXr “ 8u , Z ă 8
ﬀ
ď P
« 8
ď
r“1
tXr “ 8u
ﬀ
ď
8
ÿ
r“1
P rXr “ 8s “ 0.
(2.9)
The result in Lemma 2.4 follows from (2.9).
□
Since limtÑ8 Nptq “ 8 P-almost surely, we have lim
tÑ8
Nptq ` 1
Nptq
“ 1 P-almost
surely. The following proposition follows from the strong “law” of large numbers
(SSLN).
2.5. Proposition. Let pXrqrPN be a sequence of non-negative independent, iden-
tically distributed random variables in L1 pΩ, F, Pq such that P rXr ă 8s “ 1.
Then
lim
tÑ8
SNptq`1
Nptq ` 1 “ lim
tÑ8
SNptq
Nptq “ E rX1s ,
P-almost surely.
(2.10)
2.6. Theorem (First renewal theorem). Let the hypotheses be as in Proposition
2.5. Then
lim
tÑ8
Nptq
t
“
1
E rX1s,
P-almost surely.
(2.11)
Proof. By deﬁnition we have SNptq ď t ă SNptq`1, therefore
SNptq
Nptq ď
t
Nptq ď Nptq ` 1
Nptq
SNptq`1
Nptq ` 1.
(2.12)
The result in (2.11) now follows from (2.12) in conjunction with (2.8) and (2.10).
This proves Theorem 2.6.
□
The proof of the following theorem is somewhat more intricate.
2.7. Theorem (Elementary renewal theorem). Let the hypotheses be as in
Proposition 2.5. As above, put mptq “ E rNptqs. Then
lim
tÑ8
mptq
t
“
1
E rX1s.
(2.13)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
39 
Renewal theory and Markov chains
2.8. Remark. From Theorem 2.6 and 2.7 it follows that the family
"Nptq
t
: t ě 0
*
is uniformly integrable. Here we use Scheﬀ´e’s theorem.
Proof of Theorem 2.7. This equality has to be considered as two in-
equalities. First we have t ă SNptq`1, and hence by Theorem 2.6 we see
t ă E
“
SNptq`1
‰
“ E rX1s pE rNptqs ` 1q “ E rX1s pmptq ` 1q .
(2.14)
The inequality in (2.14) is equivalent to
mptq
t
ě
1
E rX1s ´ 1
t .
(2.15)
From (2.15) we see
lim inf
tÑ8
mptq
t
ě lim inf
tÑ8
ˆ
1
E rX1s ´ 1
t
˙
“
1
E rX1s.
(2.16)
For the second inequality we proceed as follows. Fix a strictly positive real
number a, and put Naptq “ max tn P N : řn
r“1 min pa, Xrq ď tu. Then Nptq ď
Naptq. Moreover, by Theorem 2.2 we have
t ě E
“
SNaptq
‰
“ E
“
SNaptq`1 ´ min
`
a, XNaptq`1
˘‰
“ E rmin pa, X1qs E rNaptq ` 1s ´ E
“
min
`
a, XNaptq`1
˘‰
ě E rmin pa, X1qs E rNptq ` 1s ´ a “ pmptq ` 1q E rmin pa, X1qs ´ a.
(2.17)
Hence, from (2.17) we obtain:
mptq
t
ď
1
E rmin pa, X1qs ` a ´ E rmin pa, X1qs
tE rmin pa, X1qs .
(2.18)
From (2.18) we deduce:
lim sup
tÑ8
mptq
t
ď
1
E rmin pa, X1qs,
for all large a ą 0.
(2.19)
By letting a Ñ 8 in (2.19) we see
lim sup
tÑ8
mptq
t
ď
1
E rX1s.
(2.20)
A combination of the inequalities (2.16) and (2.20) yields the result in Theorem
2.7.
□
Next we extend these renewal theorems a little bit, by introducing a renewal-
reward process pRnqnPN, where “costs” are considered as negative rewards. We
are also interested in the cumulative reward up to time t: Cptq (the reward is
collected at the end of any interval); Ciptq (the reward is collected at the start of
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
40 
Renewal theory and Markov chains
any interval); CPptq (the reward accrues during any given time interval). More
precisely we have:
Cptq “
Nptq
ÿ
j“1
Rj,
terminal reward at the end of time interval,
(2.21)
Ciptq “
Nptq`1
ÿ
j“1
Rj,
initial reward at the beginning of time interval,
(2.22)
CPptq “
Nptq
ÿ
j“1
Rj ` PNptq`1,
partial rewards during time interval.
(2.23)
For the corresponding reward functions we write
cptq “ E rCptqs ,
ciptq “ E rCiptqs
and cpptq “ E rCPptqs .
(2.24)
We are interested in the rates of reward: Cptq
t
, Ciptq
t
, and CPptq
t
. It is assumed
that the renewal process Nptq is deﬁned by inter-arrival times Xr, r P N. As
above these inter-arrival times are non-negative, independent and identically
distributed on a probability space pΩ, F, Pq. It is also assumed that the renewal-
reward process Rn, n P N, consists of independent and identically distributed
random variables in the space L1 pΩ, F, Pq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Advanced stochastic processes: Part I
41 
Renewal theory and Markov chains
The following theorem will be proved.
2.9. Theorem (Renewal-reward theorem). Suppose that 0 ă E rX1s ă 8,
E r|R1|s ă 8, and that the sequence pn´1PnqnPN is uniformly bounded in n P N
and ω, and has the property that limnÑ8 n´1Pn “ 0, P-almost surely. Let the
notation be as in (2.21), (2.22), (2.23), and (2.24). Then the following time
average limits exist P-almost surely and they are identiﬁed as E rR1s
E rX1s:
lim
tÑ8
Cptq
t
“ lim
tÑ8
Ciptq
t
“ lim
tÑ8
CPptq
t
“ E rR1s
E rX1s,
P-almost surely.
(2.25)
The following equalities hold as well:
lim
tÑ8
cptq
t
“ lim
tÑ8
ciptq
t
“ lim
tÑ8
cPptq
t
“ E rR1s
E rX1s.
(2.26)
Observe that the quotient E rR1s
E rX1s can be interpreted as the “expected reward
accruing in a cycle” divided by “expected duration of a cycle”.
Other conditions on the sequence pPn : n P Nq can be given while retaining the
conclusion in Theorem 2.9. For example the following conditions could be im-
posed. The sequence pPn : n P Nq is P-independent and identically distributed,
or there are ﬁnite deterministic constants c1 and c2 such that |Pn| ď c1n`c2 |Rn|
and lim
nÑ8
Pn
n “ 0. In these cases the sequence
ˆPn
n : n P N
˙
is uniformly inte-
grable and lim
nÑ8
Pn
n “ 0 P-almost surely.
Proof. By employing Theorem 2.2 and the strong law of large numbers we
have
lim
tÑ8
Cptq
t
“ lim
tÑ8
řNptq
k“1 Rk
Nptq
Nptq
t
“ E rR1s
E rX1s.
(2.27)
In exactly the same manner, with Nptq ` 1 replacing Nptq, we see lim
tÑ8
Ciptq
t
“
E rR1s
E rX1s. By hypothesis we know that lim
nÑ8
Pn
n “ 0 P-almost surely. Since
lim
tÑ8 Nptq “ 8 P-almost surely
we see that lim
tÑ8
PNptq`1
Nptq ` 1 “ 0. This together with (2.27) shows that
lim
tÑ8
CPptq
t
“ E rR1s
E rX1s.
These arguments take care of the P-almost sure convergence.
Next we consider the convergence of the time averaged expected values. For
convergence of time average of the reward function ciptq “ E rCiptqs we use
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
42 
Renewal theory and Markov chains
Wald’s equation (see Theorem 2.2) and the elementary renewal Theorem 2.7.
More precisely we have:
ciptq “ E rCiptqs “ E
«Nptq`1
ÿ
j“1
Rj
ﬀ
“ E rR1s pE rNptqs ` 1q .
(2.28)
Then we divide by t, take the limit in (2.28) as t tends to 8. An appeal to
Theorem 2.6 then shows the existence of the limit lim
tÑ8
ciptq
t
“ E rR1s
E rX1s which
is the second part of (2.26) in Theorem 2.9. First observe that lim
nÑ8
Rn
n “ 0
P-almost surely. This can be seen by an appeal to the Borel-Cantelli lemma. In
fact we have
8
ÿ
n“1
P
„|Rn|
n
ą ε
ȷ
“
8
ÿ
n“1
P
„|R1|
ε
ą n
ȷ
ď
ż 8
0
P
„|R1|
ε
ą x
ȷ
dx ď E
„|R1|
ε
ȷ
.
(2.29)
From (2.29) together with the Borel-Cantelli lemma it follows that lim
nÑ8
Rn
n “ 0
P-almost surely. Consequently, the sequence
"Rn
n : n P N
*
is P-uniformly in-
tegrable. Then we have
ˇˇRNptq`1
ˇˇ
t
ď Nptq ` 1
t
řNptq`1
k“1
|Rn|
Nptq ` 1
,
(2.30)
and hence by Wald’s equality
E
«ˇˇRNptq`1
ˇˇ
t
ﬀ
ď E
«
Nptq ` 1
t
řNptq`1
k“1
|Rn|
Nptq ` 1
ﬀ
“ mptq ` 1
t
E r|R1|s .
(2.31)
By the strong law of large numbers and by the elementary renewal theorem 2.7
we see that the families of random variables
řNptq`1
k“1
|Rn|
t
“ Nptq ` 1
t
řNptq`1
k“1
|Rn|
Nptq ` 1
,
t ą 0,
(2.32)
is uniformly integrable. Consequently the family
"RNptq`1
t
: t ą 0
*
is uniformly
integrable, and hence it converges pointwise and in L1 pΩ, F, Pq to 0. Since
cptq
t
“ 1
t
˜
E
«Nptq`1
ÿ
k“1
Rk
ﬀ
´ E
“
RNptq`1
‰
¸
“ mptq ` 1
t
E rR1s ´ E
“
RNptq`1
‰
t
.
(2.33)
The right-hand side of (2.33) converges to E rR1s
E rX1s. This proves the ﬁrst part of
(2.26) in Theorem 2.9. In order to prove the third part we need the uniform
integrability of the family
"PNptq`1
t
: t ě 1
*
. This fact is not entirely trivial.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
43 
Renewal theory and Markov chains
Let the ﬁnite constant C be such that |Pn`1| ď Cpn ` 1q for all n P N and P-
almost surely; by hypothesis such a constant exists. From Remark 2.8 it follows
that the family
"Nptq ` 1
t
: t ě 1
*
is uniformly integrable. Since
ˇˇPNptq`1
ˇˇ
t
“
ˇˇPNptq`1
ˇˇ
Nptq ` 1
Nptq ` 1
t
ď C Nptq ` 1
t
(2.34)
it follows that the family
"PNptq`1
t
: t ě 1
*
is uniformly integrable as well. If
t Ò 8, then Nptq Ò 8, and lim
tÑ8
Nptq
t
“
1
E rX1s in L1 pΩ, F, Pq as well as P-
almost surely: see Lemma 2.4, theorems 2.6, 2.7, and Remark 2.8. From (2.34)
it follows that lim
tÑ8
E
“ˇˇPNptq`1
ˇˇ‰
t
“ 0, which concludes the proof of Theorem
2.9.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planet’s 
electricity needs. Already today, SKF’s innovative know-
how is crucial to running a large proportion of the 
world’s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Advanced stochastic processes: Part I
44 
Renewal theory and Markov chains
1.1. Renewal theory and Markov chains. Next we consider this re-
newal theory in the context of strong Markov chains. Let pΩ, F, Pq be a proba-
bility space and let Xm, m P N, be a Markov chain on pΩ, F, Pq with state space
pS, Sq. Fix two states j and k P S. Deﬁne the sequence of stopping times T prq
k ,
r P N, as follows:
T pr`1q
k
“ min
!
n ą T prq
k
: Xn “ k
)
,
T p0q
k
“ 0.
(2.35)
If Xn ­“ k for n ą T prq
k , then we put T pr`1q
k
“ 8. The sequence of diﬀerences
T prq
k
´ T pr´1q
k
, r ě 1, are Pj-independent and identically distributed.
2.10. Theorem. Let f : r0, 8s ˆ S Ñ R be a bounded measurable function.
Then
T pr`sq
k
“ T prq
k
` T psq
k
˝ ϑT prq
k
on
!
T prq
k
ă 8
)
, and
(2.36)
Ej
”
f
´
T pr`sq
k
, XT pr`sq
k
¯
1tT prq
k
ă8u
ˇˇ FT prq
k
ı
“ Ej
”
f
´
T pr`sq
k
, XT pr`sq
k
¯
1tT prq
k
ă8u
ˇˇ σ
´
T prq
k , XT prq
k
¯ı
“ Ej
”
f
´
T pr`sq
k
, XT pr`sq
k
¯
1tT prq
k
ă8u
ˇˇ σ
´
T prq
k
¯ı
“ ω ÞÑ EX
T prq
k
pωqpωq
”
ω1 ÞÑ f
´
T prq
k pωq ` T psq
k
pω1q , XT psq
k
pω1q pω1q
¯ı
1tT prq
k
ă8upωq
“ ω ÞÑ Ek
”
ω1 ÞÑ f
´
T prq
k pωq ` T psq
k
pω1q , XT psq
k
pω1q pω1q
¯ı
1tT prq
k
ă8upωq.
(2.37)
Consequently, conditioned on the event
!
T prq
k
ă 8
)
the stochastic variable
T pr`sq
k
´ T prq
k
and the σ-ﬁeld FT prq
k
are Pj-independent.
Suppose that Pk
”
T prq
k
ă 8
ı
“ 1 and Pj
”
T p1q
k
ă 8
ı
ą 0. Then
Pj
”
T pr`1q
k
ă 8
ı
“ Pj
”
T p1q
k
ă 8
ı
,
and the variables T pr`1q
k
´ T prq
k , r P N, have the same distribution with respect
to the probability measure A ÞÑ Pj
”
A
ˇˇ T p1q
k
ă 8
ı
.
Here PjpAq “ P
“
A
ˇˇ X0 “ j
‰
, A P F, j P S. Theorem 2.10 is a consequence of
the strong Markov property.
Proof. First we prove (2.36). On the event
!
T prq
k
ă 8
)
we have
T pr`1q
k
“ min
!
n ą T prq
k
: Xn “ k
)
“ min
!
n ą T prq
k
: Xn´T prq
k
˝ ϑT prq
k
“ k
)
“ T prq
k
` min
!
n ´ T prq
k
ě 1 : Xn´T prq
k
˝ ϑT prq
k
“ k
)
“ T prq
k
` min
!
m ě 1 : Xm ˝ ϑT prq
k
“ k
)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
45 
Renewal theory and Markov chains
“ T prq
k
` T p1q
k
˝ ϑT prq
k .
(2.38)
The equality in (2.38) shows (2.36) in case s “ 1. We use (2.38) with s respec-
tively r ` s instead of r to obtain (2.36) by induction on s. More precisely we
have
T prq
k
` T ps`1q
k
˝ ϑT prq
k
“ T prq
k
`
´
T psq
k
` T p1q
k
˝ ϑT psq
k
¯
˝ ϑT prq
k
(2.39)
“ T prq
k
` T psq
k
˝ ϑT prq
k
` T p1q
k
˝ ϑT prq
k
`T psq
k
˝ϑ
T prq
k
(induction hypothesis)
“ T pr`sq
k
` T p1q
k
˝ ϑT pr`sq
k
“ T pr`s`1q
k
,
(2.40)
where in (2.39) we employed (2.38) with s instead of r and in (2.40) we used
r ` s instead of r. The equality in (2.40) shows (2.36) for s`1 assuming that it
is true for s. Since by (2.38) the equality in (2.36) is true for s “ 1, induction
shows the equality in (2.36).
Next we will prove the equality in (2.37). From equality (2.36) we get
Ej
”
f
´
T pr`sq
k
, XT pr`sq
k
¯
1tT prq
k
ă8u
ˇˇ FT prq
k
ı
“ Ej
„
f
ˆ
T prq
k
` T psq
k
˝ ϑT prq
k , XT prq
k
`T psq
k
˝ϑ
T prq
k
˙
1tT prq
k
ă8u
ˇˇ FT prq
k
ȷ
“ Ej
”
f
´
T prq
k
` T psq
k
˝ ϑT prq
k , XT psq
k
˝ ϑT prq
k
¯
1tT prq
k
ă8u
ˇˇ FT prq
k
ı
(the variable T prq
k
is FT prq
k -measurable in combination with the strong Markov
property)
“ ω ÞÑ EX
T prq
k
pωqpωq
”
f
´
T prq
k pωq ` T psq
k , XT psq
k
¯ı
1tT prq
k
ă8upωq
“ ω ÞÑ Ek
”
f
´
T prq
k pωq ` T psq
k , XT psq
k
¯ı
1tT prq
k
ă8upωq.
(2.41)
The equalities in (2.41) show that the ﬁrst, penultimate and ultimate quantity
in (2.37) are equal. Another appeal to the strong Markov property shows that
the ﬁrst and second quantity in (2.37) coincide. Since on the event
!
T prq
k
ă 8
)
the equality XT prq
k
“ k holds, the second and third quantity in (2.37) are equal
as well. This proves that all quantities in (2.37) in Theorem 2.10 are the same.
We still have to prove that on the event
!
T prq
k
ă 8
)
the stochastic variable
T pr`sq
k
´ T prq
k
and the σ-ﬁeld FT prq
k
are Pj-independent. This can be achieved
as follows. Let the event A be FT prq
k -measurable and let g : r0, 8s Ñ R be a
bounded measurable function. Then we have
Ej
”
g
´
T pr`sq
k
´ T prq
k
¯
1A 1tT prq
k
ă8u
ı
“ Ej
”
g
´
T psq
k
˝ ϑT prq
k
¯
1A 1tT prq
k
ă8u
ı
(2.42)
“ Ej
”
Ej
”
g
´
T psq
k
˝ ϑT prq
k
¯
1A
ˇˇ FT prq
k
ı
1tT prq
k
ă8u
ı
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
46 
Renewal theory and Markov chains
“ Ej
”
Ej
”
g
´
T psq
k
˝ ϑT prq
k
¯ ˇˇ FT prq
k
ı
1A 1tT prq
k
ă8u
ı
(strong Markov property: (2.37))
“ Ej
„
EX
T prq
k
”
g
´
T psq
k
¯ı
1A 1tT prq
k
ă8u
ȷ
“ Ej
”
Ek
”
g
´
T psq
k
¯ı
1A 1tT prq
k
ă8u
ı
“ Ek
”
g
´
T psq
k
¯ı
Ej
”
1A 1tT prq
k
ă8u
ı
(2.43)
(another appeal to the strong Markov property: (2.37))
“ Ej
”
Ej
”
g
´
T psq
k
¯
˝ ϑT prq
k 1tT prq
k
ă8u
ˇˇ FT prq
k
ıı Ej
”
1A 1tT prq
k
ă8u
ı
Pj
”
T prq
k
ă 8
ı
“ Ej
”
Ej
”
g
´
T psq
k
˝ ϑT prq
k
¯
1tT prq
k
ă8u
ˇˇ FT prq
k
ıı
Ej
”
1A
ˇˇ T prq
k
ă 8
ı
(use (2.36))
“ Ej
”
Ej
”
g
´
T pr`sq
k
´ T prq
k
¯
1tT prq
k
ă8u
ˇˇ FT prq
k
ıı
Ej
”
1A
ˇˇ T prq
k
ă 8
ı
“ Ej
”
g
´
T pr`sq
k
´ T prq
k
¯
1tT prq
k
ă8u
ı
Ej
”
1A
ˇˇ T prq
k
ă 8
ı
.
(2.44)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
47 
Renewal theory and Markov chains
From (2.44) the Pj-independence of T pr`sq
k
´T prq
k
and the σ-ﬁeld FT prq
k
conditioned
on the event
!
T prq
k
ă 8
)
follows. Since the expressions in (2.42) and (2.43) are
equal it follows that the Pj
”
¨
ˇˇ T p1q
k
ă 8
ı
-distribution of the variable T pr`1q
k
´
T prq
k
does not depend on r, provided that
Pj
”␣
T 1
k ă 8
(
z
!
T prq
k
ă 8
)ı
“ 0.
(2.45)
By the strong Markov property it follows that
Pj
”
T pr`1q
k
ă 8
ı
“ Pj
”
T p1q
k
ă 8
ı
Pk
”
T p1q
k
ă 8
ır
.
(2.46)
Since, by assumption, Pk
”
T p1q
k
ă 8
ı
“ 1, (2.46) implies that the probabilities
Pj
”
T prq
k
ă 8
ı
do not depend on r P N, and hence (2.45) follows. This proves
Theorem 2.10.
□
2.11. Definition. Let j P S. If Pj
”
T p1q
j
ă 8
ı
“ 1, then j is called recurrent
(or persistent).
If Pj
”
T p1q
j
ă 8
ı
ă 1, then j is called a transient state.
A
recurrent state for which Ej
”
T p1q
j
ı
“ 8 is called a null state. A recurrent state
for which Ej
”
T p1q
j
ı
ă 8 is called a non-null or positive state.
From (2.46) it follows that Pj
”
T prq
j
ă 8
ı
“ Pj
”
T p1q
j
ă 8
ır
, and hence if a
state j is recurrent it is expected to be visited inﬁnitely many times.
Let
N k “ ř8
n“1 1tXn“ku be the number of visits to the state k, and put νk
j “
Ej
“
N k‰
“ E
“
N k ˇˇ X0 “ j
‰
. Then
νk
j “
8
ÿ
n“1
ppnq
jk “
8
ÿ
n“1
P
“
Xn “ k
ˇˇ X0 “ j
‰
.
(2.47)
We also have
␣
N k ě r ` 1
(
“
!
T pr`1q
k
ă 8
)
and hence by (2.46) we get
Pj
”
T pr`1q
k
ă 8
ı
“ Pj
“
N k ě r ` 1
‰
“ Pj
“
N k ą 0
‰
Pk
“
N k ą 0
‰r
“ Pj
”
T p1q
k
ă 8
ı
Pk
”
T p1q
k
ă 8
ır
.
(2.48)
From (2.47) and (2.48) it follows that
νk
j “
8
ÿ
n“1
ppnq
jk “
8
ÿ
n“1
P
“
Xn “ k
ˇˇ X0 “ j
‰
“ Pj
“
N k ą 0
‰ 8
ÿ
r“1
Pk
“
N k ą 0
‰r .
(2.49)
Suppose that the state j communicates with k, i.e. suppose that ppnq
jk ą 0 for
some integer n ě 1. From (2.49) it follows that the state k is recurrent if and
only if ř8
n“1 ppnq
jk “ 8. The state k is transient if and only if ř8
n“1 ppnq
jk ă 8.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
48 
Renewal theory and Markov chains
2.12. Theorem. Suppose that the states j and k intercommunicate. Then either
both states are recurrent or both states are transient.
Proof. Since the states j and k intercommunicate the exist positive inte-
gers m and n such that ppmq
jk
ą 0 and ppnq
kj ą 0. For any positive integer r we
then have
ppm`r`nq
jj
ě ppmq
jk pprq
kk ppnq
kj
(2.50)
By summing over r in (2.50) we see that ř8
r“1 pprq
jj ă 8 if and only if ř8
r“1 pprq
kk ă
8. From this fact together with (2.49) the statement in Theorem 2.12 follows.
□
2.13. Definition. A Markov chain with state space S is called irreducible of all
states communicate, i.e. for every j, k P S there exists n P N such that ppnq
j,k ą 0.
If X is irreducible and all states and one, and so all states, are recurrent, then
X is called recurrent.
2.14. Theorem. Let X be a recurrent and irreducible Markov chain. Put
vk
j “ E
»
–
T p1q
kÿ
u“1
1tXu“ju
ˇˇ X0 “ k
ﬁ
ﬂ“ Ek
»
–
T p1q
kÿ
u“1
1tXu“ju
ﬁ
ﬂ.
(2.51)
Then 0 ă vk
j ă 8, j, k P S, and vk
j “ ř
iPS vk
i pij. In other words the vector
`
vk
j : j P S
˘
is an invariant measure for X.
Proof. First we prove that 0 ă vk
j ă 8. Therefore we notice that
vk
j “ Ek
»
–
T p1q
kÿ
u“1
1tXu“ju
ﬁ
ﬂ“
8
ÿ
r“0
Pk
”
T p1q
k
ě T pr`1q
j
ı
“
8
ÿ
r“0
Pk
”
T p1q
k
ě T p1q
j
ı ´
Pj
”
T p1q
k
ě T p1q
j
ı¯r
,
(2.52)
where we used the equality:
Pk
”
T p1q
k
ě T pr`1q
j
ı
“ Pk
”
T p1q
k
ě T p1q
j
ı ´
Pj
”
T p1q
k
ě T p1q
j
ı¯r
.
(2.53)
Suppose j ­“ k; for j “ k we have vk
k “ 1. The equality in (2.53) follows from
the strong Markov property as follows. For r “ 0 the equality is clear. For
r ě 1 we have
Pk
”
T p1q
k
ě T pr`1q
j
ı
“ Pk
”
T p1q
k
ě T pr`1q
j
, T p1q
k
ě T prq
j
` 1
ı
“ Pk
”
T prq
j
` T p1q
k
˝ ϑT prq
j
ě T prq
j
` T p1q
j
˝ ϑT prq
j , T p1q
k
ě T prq
j
` 1
ı
“ Ek
”
Pk
”
T p1q
k
˝ ϑT prq
j
ě T p1q
j
˝ ϑT prq
j
ˇˇ FT prq
j
ı
, T p1q
k
ě T prq
j
` 1
ı
(strong Markov property)
“ Ek
„
PX
T prq
j
”
T p1q
k
ě T p1q
j
ı
, T p1q
k
ě T prq
j
` 1
ȷ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
49 
Renewal theory and Markov chains
“ Ek
”
Pj
”
T p1q
k
ě T p1q
j
ı
, T p1q
k
ě T prq
j
` 1
ı
“ Pj
”
T p1q
k
ě T p1q
j
ı
Pk
”
T p1q
k
ě T prq
j
` 1
ı
(induction with respect to r)
“
´
Pj
”
T p1q
k
ě T p1q
j
ı¯r
Pk
”
T p1q
k
ě T p1q
j
ı
.
(2.54)
Since Pk
”
T p1q
k
ě T p1q
j
ı
ą 0 it follows by (2.52) that vk
j ą 0. By the same equality
and using the fact that Pj
”
T p1q
k
ě T p1q
j
ı
ă 1 we see vk
j ă 8.
Next we prove the equality: vk
j “ ř
iPS vk
i pij. Therefore we write
vk
j “ Ek
»
–
T p1q
kÿ
n“1
1tXn“ju
ﬁ
ﬂ“
8
ÿ
n“1
Pk
”
Xn “ j, T p1q
k
ě n
ı
“
ÿ
iPS
8
ÿ
n“1
Pk
”
Xn “ j, Xn´1 “ i, T p1q
k
ě n
ı
“
ÿ
iPS
8
ÿ
n“1
Ek
”
Pk
“
Xn “ j
ˇˇ Fn´1
‰
, Xn´1 “ i, T p1q
k
ě n
ı
(Markov property)
“
ÿ
iPS
8
ÿ
n“1
Ek
”
PXn´1 rX1 “ js , Xn´1 “ i, T p1q
k
ě n
ı
“
ÿ
iPS
Pi rX1 “ js
8
ÿ
n“0
Pk
”
Xn “ i, T p1q
k
´ 1 ě n
ı
“
ÿ
iPS
Pi rX1 “ js Ek
»
–
T p1q
k
´1
ÿ
n“0
1tXn“iu
ﬁ
ﬂ
“
ÿ
iPS
Pi rX1 “ js Ek
»
–
T p1q
kÿ
n“1
1tXn“iu
ﬁ
ﬂ.
(2.55)
In the last equality of (2.55) we used the equality
Ek
»
–
T p1q
k
´1
ÿ
n“0
1tXn“iu
ﬁ
ﬂ“ Ek
»
–
T p1q
kÿ
n“1
1tXn“iu
ﬁ
ﬂ,
which is evident for i ­“ k and both are equal to 1 for i “ k. As a consequence
from (2.55) we see that vk
j “ ř
iPS vk
i pij.
□
2.15. Corollary. Let the row vector vk :“
`
vk
j : j P S
˘
be as in equality (2.51)
of Theorem 2.14. Then vk is minimal invariant measure in the sense that if
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
50 
Renewal theory and Markov chains
x “ pxj : j P Sq is another invariant measure such that xk “ 1. Then xj ě vk
j ,
j P S.
Proof. We write:
xj “ pkj `
ÿ
sPS, s­“k
xspsj
“ Pk
”
X1 “ j, T p1q
k
ě 1
ı
`
ÿ
s1PS, s1­“k
ÿ
s2PS
xs2ps2s1ps1j
“ Pk
”
X1 “ j, T p1q
k
ě 1
ı
`
ÿ
s1PS, s1­“k
pks1ps1j `
ÿ
s1PS, s1­“k
ÿ
s2PS, s2­“k
xs2ps2s1ps1j
ě Pk
”
X1 “ j, T p1q
k
ě 1
ı
` Pk
”
X2 “ j, T p1q
k
ě 2
ı
` ¨ ¨ ¨ ` Pk
”
Xn “ j, T p1q
k
ě n
ı
.
(2.56)
Upon letting n tend to 8 in (2.56) we see that xj ě vk
j . This proves Corollary
2.15.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
51 
Renewal theory and Markov chains
2.16. Theorem. Let X be a irreducible Markov chain with transition matrix
P “ ppijqpi,jqPSˆS .
The following assertions hold:
(a) If any state is non-null recurrent, then all states are.
(b) The chain is non-null recurrent if and only if there exists a stationary
distribution π or invariant measure. If this is the case, then
πk “
1
Ek
”
T p1q
k
ı
and
vk
j “ πj
πk
(see (2.51)).
(2.57)
As a consequence of (2.57) stationary distributions are unique.
Proof. (a) The proof of assertion will follow from the proof of assertion
(b).
(b) Let k be a state which is non-null recurrent. By Theorem 2.12 it follows
that the chain is recurrent. By Theorem 2.14 the vector
`
vk
j : j P S
˘
as deﬁned
in (2.51) is an invariant vector. Since k is non-null recurrent it follows that
0 ă Ek
”
T p1q
k
ı
ă 8, and that the vector
˜
vk
j
πk
: j P S
¸
, with πk “
1
Ek
”
T p1q
k
ı,
is a stationary vector. It follows that if the irreducible chain X contains at
least one non-null recurrent state, then there exists a stationary distribution.
Next suppose that there exists a stationary distribution π :“ pπj : j P Sq. Then
πk “ ř
jPS πjppnq
jk for all n P N. Since the chain is irreducible, and the vector is
a probability vector, at least one πj0 ­“ 0. By irreducibility there exists n P N
such that ppnq
j0k ­“ 0, and hence πk ­“ 0, k P S. Consider for any given k P S the
vector x “
ˆπj
πk
: j P S
˙
. Then xk “ 1 and by Corollary 2.15 xj ě vk
j for all
j P S. It follows that
Ek
”
T p1q
k
ı
“
ÿ
jPS
vk
j ď
ÿ
jPS
πj
πk
“ 1
πk
.
(2.58)
Therefore k is non-null recurrent for all k P S. It follows that if there exists
one non-null recurrent vector k P S, then all states in S are non-null recurrent.
Altogether this proves assertion (a), and also a large part of (b). From (2.58)
the ﬁrst equality in (2.57) follows. Finally we will show the second equality
in (2.57). The vector x ´ vk is invariant and, by Corollary 2.15 πj
πk
´ vk
j ě 0.
Hence we obtain, for all positive integers n,
0 “ 1 ´ vk
k “
ÿ
iPS
ˆ πi
πk
´ vk
i
˙
ppnq
ik ě
ˆπj
πk
´ vk
j
˙
ppnq
jk .
(2.59)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
52 
Renewal theory and Markov chains
In (2.59) we choose n in such a way that ppnq
jk ą 0. By irreducibility this is
possible. It follows that (see (2.51))
vk
j “ E
»
–
T p1q
kÿ
u“1
1tXu“ju
ˇˇ X0 “ k
ﬁ
ﬂ“ Ek
»
–
T p1q
kÿ
u“1
1tXu“ju
ﬁ
ﬂ“ πj
πk
“
Ek
”
T p1q
k
ı
Ej
”
T p1q
j
ı. (2.60)
The second equality in (2.57) is the same as (2.60). This concludes the proof of
Theorem 2.16.
□
Let k be a non-null recurrent state, and suppose that the state is j intercom-
municates with k. Then both states are non-null or positive recurrent. Next we
deﬁne the renewal process Nkpnq, n P N, as follows:
Nkpnq “ max
!
r : T prq
k
ď n
)
.
(2.61)
Notice the inequalities:
T pNkpnqq
k
ď n ă T pNkpn`1qq
k
,
and hence T pmq
k
“ n if m “ Nkpnq. We are interested in the following type of
limits:
lim
nÑ8
1
n
nÿ
ℓ“1
ppℓq
kj “ lim
nÑ8
1
n
nÿ
ℓ“1
P
“
Xℓ“ j
ˇˇ X0 “ k
‰
“ lim
nÑ8 E
«
1
n
nÿ
ℓ“1
1tXℓ“ju
ˇˇ X0 “ k
ﬀ
.
(2.62)
Put m “ Nkpnq. Then T pmq
k
“ n, and consequently we see
1
n
nÿ
ℓ“1
1tXℓ“ju “ Nkpnq
n
1
m
m
ÿ
u“1
T puq
kÿ
ℓ“T pu´1q
k
`1
1tXℓ“ju.
(2.63)
Notice that for j “ k we have
1
m
m
ÿ
u“1
T puq
kÿ
ℓ“T pu´1q
k
`1
1tXℓ“ju “ 1,
and consequently,
1
n
nÿ
ℓ“1
1tXℓ“ku “ Nkpnq
n
.
Hence, we observe that (see Theorem 2.6)
lim
nÑ8
1
n
nÿ
ℓ“1
1tXℓ“ku “ lim
nÑ8
Nkpnq
n
“
1
E
”
T p1q
k
ˇˇ X0 “ k
ı “ 1
µk
, Pk-almost surely.
(2.64)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
53 
Renewal theory and Markov chains
We also see that
Njpnq
n
“ 1
n
nÿ
ℓ“1
1tXℓ“ju “ Nkpnq
n
1
m
m
ÿ
u“1
T puq
kÿ
ℓ“T pu´1q
k
`1
1tXℓ“ju.
(2.65)
From the strong law of large numbers we get:
lim
mÑ8
1
m
m
ÿ
u“1
T puq
kÿ
ℓ“T pu´1q
k
`1
1tXℓ“ju “ E
»
–
T p1q
kÿ
u“1
1tXu“ju
ˇˇ X0 “ k
ﬁ
ﬂ“ vk
j .
(2.66)
From (2.63), (2.64), and (2.65) we obtain:
1
E
”
T p1q
j
ˇˇ X0 “ j
ı “ lim
nÑ8
Njpnq
n
“ lim
nÑ8
1
n
nÿ
ℓ“1
1tXℓ“ju
“ lim
nÑ8
Nkpnq
n
1
m
m
ÿ
u“1
T puq
kÿ
ℓ“T pu´1q
k
`1
1tXℓ“ju “
vk
j
E
”
T p1q
k
ˇˇ X0 “ k
ı.
(2.67)
The equality in (2.67) together with Theorem 2.9 shows the following theorem.
2.17. Theorem. Let the sequence of stopping times
´
T prq
k
¯
rPN be deﬁned as in
(2.35), and let vk
j be deﬁned as in (2.66).
Suppose that the states j and k
intercommunicate and that one of them is non-null recurrent, then the other is
also non-null recurrent. Moreover,
lim
nÑ8
1
n
nÿ
ℓ“1
1tXℓ“ju “
1
E
”
T p1q
j
ˇˇ X0 “ j
ı “
vk
j
E
”
T p1q
k
ˇˇ X0 “ k
ı,
and
(2.68)
lim
nÑ8
1
n
nÿ
ℓ“1
ppℓq
kj “ lim
nÑ8
1
n
nÿ
ℓ“1
P
“
Xℓ“ j
ˇˇ X0 “ k
‰
“
1
E
”
T p1q
j
ˇˇ X0 “ j
ı “
vk
j
E
”
T p1q
k
ˇˇ X0 “ k
ı.
(2.69)
Hence, with πj “ lim
nÑ8
1
n
nÿ
ℓ“1
ppℓq
kj , µj “ E
”
T p1q
j
ˇˇ X0 “ j
ı
, and vk
j as in equality
(2.66) we have πj “ 1
µj
“ vk
j
µk
.
1.1.1. Random walks. In this example the state space is Z, and the process
Xn, n P N, has a transition probability matrix with the following entries: pi´1,i “
q, pi`1,i “ p, 0 ă p “ 1 ´ q ă 1, and pj,i “ 0, j ‰ i ˘ 1. Such a random walk
can be realized by putting Xn “ řn
k“0 Sk, where S0 is the initial state (which
may be random), the variables Sk, k P N, k ě 1, are P-independent of each
other and are also P-independent of S0. Moreover, each variable Sk, k ě 1, is
a Bernoulli variable taking the value `1 with probability p and the value ´1
with probability q. This Markov chain is irreducible: every state communicates
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
54 
Renewal theory and Markov chains
with every other one. The set of states is closed. The corresponding inﬁnite
transition matrix looks as follows:
¨
˚
˚
˚
˚
˚
˚
˚
˝
...
...
...
...
...
...
...
q
0
p
0
. . .
. . .
0
q
0
p
. . .
. . .
0
0
q
0
...
...
...
...
...
...
...
˛
‹‹‹‹‹‹‹‚
.
The state 0 has period two pp2n`1q
00
“ 0, and pp2nq
00
“
ˆ2n
n
˙
pnqn. In order to
check transiency (or recurrence) we need to calculate
8
ÿ
n“0
pp2nq
00
“
8
ÿ
n“0
ˆ2n
n
˙
pnqn.
(2.70)
By Stirling’s formula we have n! „
?
2πnnne´n, which means that
lim
nÑ8
n!
?
2πnnne´n “ 1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENT…
     RUN FASTER.
          RUN LONGER..
                RUN EASIER…
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Advanced stochastic processes: Part I
55 
Renewal theory and Markov chains
Since
ˆ2n
n
˙
“ p2nq!
pn!q2 „
?
4πn p2nq2n e´2n
2πn2n`1e´2n
“
4n
?πn
(2.71)
the sum in (2.70) is ﬁnite if and only if the sum
8
ÿ
n“1
p4pqqn
?πn ă 8.
(2.72)
If p “ 1 ´ q ‰
1
2, then 4pq ă 1, and hence the sum in (2.72) is ﬁnite, and
so the unrestricted asymmetric random walk in Z is transient.
However, if
p “ q “ 1
2, then 4pq “ 1 and the sum in (2.72) diverges, and so the symmetric
unrestricted random walk in Z is recurrent. One may also do similar calculations
for symmetric random walks in Z2, Z3, and Zd, d ě 4. It turns out that in Z2 the
2n-th symmetric transition probability pp2nq
00
satisﬁes (for n Ñ 8) pp2nq
00
„ 1
πn,
and hence the sum ř8
n“0 pp2nq
00
“ 8. It follows that the symmetric random walk
in Z2 is recurrent. The corresponding return probability pp2nq
00
for the symmetric
random walk in Z3 possesses the following asymptotic behavior:
pp2nq
00
„ 1
2
ˆ 3
π
˙3{2
1
n3{2.
Hence the sum ř8
n“0 pp2nq
00
ă 8, and so the state 0 is transient. The 2n-th return
probabilities of the symmetric random walk in Zd satisﬁes
pp2nq
00
„ cd
nd{2,
n Ñ 8,
for some constant cd and hence the sum ř8
n“0 pp2nq
00
ă 8 in dimensions d ě 3.
So in dimensions d ě 3 the symmetric random walk is transient, and in the
dimension d “ 1, 2, the symmetric random walk is recurrent.
We come back to the one-dimensional situation, and we reconsider the return
times to a state k P Z: T p1q
k
“ inf tn ě 1 : Xn “ ku. Notice that Sk, k P N, are
the step sizes which are ˘1. Also observe that Xk “ řk
j“0 Sj. We consider the
moment generating function Gj,kpsq “ Ej
”
sT p1q
k
ı
, 0 ď s ă 1. Observe that on
the event
!
T p1q
k
“ 8
)
the quantity sT p1q
k
has to be interpreted as 0. In addition,
we have Pj
”
T p1q
k
ą T p1q
k´1
ı
“ Pj
”
T p1q
k´1 ă 8
ı
for k ą j, k, j P Z. Then it follows
that T p1q
k
“ T p1q
k´1 ` T p1q
k
˝ ϑT p1q
k´1, Pj-almost surely, k ą j, k, j P Z. Then by the
strong Markov property we get
Gj,kpsq “ Ej
”
sT p1q
k
ı
“ Ej
«
s
T p1q
k´1`T p1q
k
˝ϑ
T p1q
k´1, T p1q
k´1 ă 8
ﬀ
“ Ej
«
sT p1q
k´1Ej
«
s
T p1q
k
˝ϑ
T p1q
k´1 ˇˇ GT p1q
k´1
ﬀ
, T p1q
k´1 ă 8
ﬀ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
56 
Renewal theory and Markov chains
(Markov property)
“ Ej
„
sT p1q
k´1EX
T p1q
k´1
”
sT p1q
k
ı
, T p1q
k´1 ă 8
ȷ
“ Ej
”
sT p1q
k´1Ek´1
”
sT p1q
k
ıı
“ Ej
”
sT p1q
k´1
ı
Ek´1
”
sT p1q
k
ı
.
(2.73)
From (2.73) we see by induction with respect to k that
Gj,kpsq “
k´1
ź
ℓ“j
Gℓ,ℓ`1psq “ G0,1psqk´j.
(2.74)
In the ﬁnal step of (2.74) we used the fact that the Pℓ-distribution of T p1q
ℓ`1 is
the same as the P0-distribution of T p1q
1 . This follows from the fact that the
variables Sm, m P N, m ě 1, are independent identically (Bernoulli) distributed
random variables. Notice that T p1q
1
“ 1 ` T p0q
1
˝ ϑ1, P0-almost surely. Here
T p0q
1
“ inf tn ě 0 : Xn “ 1u. Again we use the Markov property to obtain:
G0,1psq “ E0
”
esT p1q
1
ı
“ E0
”
s1`T p0q
1
˝ϑ1ı
“ sE0
”
E0
”
sT p1q
1
˝ϑ1 ˇˇ G1
ıı
“ sE0
”
EX1
”
sT p0q
1
ıı
“ sE0
”
EX1
”
sT p0q
1
ı
, X1 “ 1s
ı
` sE0
”
EX1
”
sT p0q
1
ı
, X1 “ ´1
ı
“ sE0
”
E1
”
sT p0q
1
ı
, X1 “ 1
ı
` sE0
”
E´1
”
sT p0q
1
ı
, X1 “ ´1
ı
(notice that T p0q
1
“ 0 P1-almost surely, and T p0q
1
“ T p1q
1
P´1-almost surely)
“ sp ` sqE´1
”
sT p1q
1
ı
“ sp ` sqG´1,1psq
“ sp ` sqG0,2psq “ sp ` sqG0,1psq2.
(2.75)
In the ﬁnal step of (2.75) we employed (2.74) with j “ ´1 and k “ 1. From
(2.75) we infer
G0,1psq “ 1 ´ p1 ´ 4pqs2q1{2
2qs
.
(2.76)
By a similar token (i.e. by interchanging p and q) we also get
G1,0psq “ 1 ´ p1 ´ 4pqs2q1{2
2ps
.
(2.77)
Next we rewrite G0,0psq:
G0,0psq “ E0
”
sT p1q
0
ı
“ E0
”
s1`T p0q
0
˝ϑ1ı
“ sE0
”
E0
”
sT p0q
0
˝ϑ1 ˇˇ G1
ıı
“ sE0
”
EX1
”
sT p1q
0
ıı
(on the event tX1 “ ˘1u the equality T p0q
0
“ T p1q
0
holds PX1-almost surely)
“ sE0
”
EX1
”
sT p1q
0
ı
, X1 “ 1
ı
` sE0
”
EX1
”
sT p1q
0
ı
, X1 “ ´1
ı
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
57 
Renewal theory and Markov chains
“ sE0
”
E1
”
sT p1q
0
ı
, X1 “ 1
ı
` sE0
”
E´1
”
sT p1q
0
ı
, X1 “ ´1
ı
“ spE1
”
sT p1q
0
ı
` sqE´1
”
sT p1q
0
ı
((space) translation invariance)
“ spE1
”
sT p1q
0
ı
` sqE0
”
sT p1q
1
ı
“ spG1,0psq ` sqG0,1psq
(employ the equalities in (2.76) and (2.77))
“ sp1 ´ p1 ´ 4pqs2q1{2
2ps
` sq1 ´ p1 ´ 4pqs2q1{2
2qs
“ 1 ´
`
1 ´ 4pqs2˘1{2 .
Then we infer
P0
”
T p1q
0
ă 8
ı
“
lim
sÒ1, să1 G0,0psq “ 1 ´ p1 ´ 4pqq1{2
“ 1 ´ |1 ´ 2p| “ 1 ´ |q ´ p| .
As a consequence we see that the non-symmetric random walk, i.e. the one with
q ‰ p, is transient, and that the symmetric random walk (i.e. p “ q “ 1
2) is
recurrent. However, since
E0
”
T p1q
0
ı
“
lim
sÒ1,să1 G1
0,0psq “
lim
sÒ1,să1
s
p1 ´ s2q3{2 “ 8,
it follows that the symmetric random walk is not positive recurrent.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Advanced stochastic processes: Part I
58 
Renewal theory and Markov chains
In the following lemma we prove some of the relevant equalities concerning
stopping times and one-dimensional random walks.
2.18. Lemma. Employing the above notation and hypotheses yields the following
equalities:
(i) The equality T p1q
j
“ 1 ` T p0q
j
˝ ϑ1 holds Pk-almost surely for all states k,
j P Z.
(ii) For k ą j, k, j P Z the equality T p1q
k
“ T p1q
k´1`T p1q
k ˝ϑT p1q
k´1 holds Pj-almost
surely.
Proof. First let us prove assertion (i). Let j and k be states in Z. Then
Pk-almost surely we have
1 ` T p0q
j
˝ ϑ1 “ 1 ` inf tn ě 0 : Xn ˝ ϑ1 “ ju
“ inf tn ` 1 : n ě 0, Xn`1 “ ju “ inf tn ě 1 Xn “ ju “ T p1q
j .
(2.78)
The equality in (2.78) shows assertion (i). Next we prove the somewhat more
diﬃcult equality in (ii). As remarked above we have
Pj
”
T p1q
k
ą T p1q
k´1
ı
“ Pj
”
T p1q
k´1 ă 8
ı
.
Indeed, in order to visit the state k ą j the process Xn, starting from j has
to visit the state k ´ 1, and hence Pj
”
T p1q
k´1 ă T p1q
k
ı
“ Pj
”
T p1q
k´1 ă 8
ı
. Without
loss of generality we may and shall assume that in the following arguments
we consider the process Xn on the event
!
T p1q
k´1 ă 8
)
. (Otherwise we would
automatically have T p1q
k´1 ` T p1q
k
˝ ϑT p1q
k´1 “ T p1q
k .) Next on the event
!
T p1q
k´1 ă 8
)
we write:
T p1q
k´1 ` T p1q
k
˝ ϑT p1q
k´1 “ T p1q
k´1 ` inf
!
n ě 1 : Xn ˝ ϑT p1q
k´1 “ k
)
“ inf
!
T p1q
k´1 ` n : n ě 1, Xn`T p1q
k´1 “ k
)
“ inf
!
n ą T p1q
k´1 : Xn “ k
)
“ T p1q
k .
(2.79)
Assertion (ii) follows from (2.79). Altogether this proves Lemma 2.18.
□
Perhaps it is useful to prove in an explicit manner that the one-dimensional
random walk is a Markov chain. This is the content of the next lemma.
2.19. Lemma. Let tSn : n P N, n ě 1u be independent identically distributed
random variables taking their values in Z. Put X0 “ S0 be the initial value
of the process Xn, n P N, where Xn “ řn
m“0 Sm. Put
Ej rf pX0, X1, . . . , Xnqs “ E rf pX0 ` j, X1 ` j, . . . , Xn ` jqs
(2.80)
for all bounded functions f : Zn`1 Ñ R, j P Z, n P N. Then the equality in
(2.80) expresses the fact that the process
!
pΩ, G, PjqjPZ , pXn, n P Nq , pϑn, n P Nq , Z
)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
59 
Renewal theory and Markov chains
is a space homogeneous process, with the property that the distribution of the
process pXn`1 ´ XnqnPN does not depend on the initial value j.
It is also a
time-homogeneous Markov chain.
Proof. The ﬁrst equality say that the ﬁnite dimensional distributions of
the process pXnqnPN are homogeneous in space. If
f px0, x1, . . . , xnq “ g px1 ´ x0, x2 ´ x1, . . . , xn ´ xn´1q ,
then from (2.80) we see that
Ej rf pX0, X1, . . . , Xnqs “ E rf pX0 ` j, X1 ` j, . . . , Xn ` jqs
“ E rg pX1 ´ X0, X2 ´ X1, . . . , Xn ´ Xn´1qs
“ Ej rg pX1 ´ X0, X2 ´ X1, . . . , Xn ´ Xn´1qs .
(2.81)
The equality in (2.81) shows that the distribution of the process
pXn`1 ´ XnqnPN
does not depend on the initial value j. Next we prove the Markov property. Let
f be any bounded function on Z. To this end we consider:
Ej
“
f pXn`1q
ˇˇ Gn
‰
“ E
“
f pXn`1 ` jq
ˇˇ Gn
‰
“ E
“
f pXn`1 ´ Xn ` Xn ` jq
ˇˇ Gn
‰
(the variable Xn`1 ´ Xn and the σ-ﬁeld Gn are P-independent)
“ ω ÞÑ E rω1 ÞÑ f pXn`1 pω1q ´ Xn pω1q ` Xn pωq ` jqs
(the P-distribution of Xn`1 pω1q´Xn pω1q neither depends on n nor on the initial
value X0 pω1q)
“ ω ÞÑ E rω1 ÞÑ f pX1 pω1q ´ X0 pω1q ` Xn pωq ` jqs
(choose X0 pω1q “ j)
“ ω ÞÑ E rω1 ÞÑ f pX1 pω1q ´ j ` Xn pωq ` jqs
“ ω ÞÑ E rω1 ÞÑ f pX1 pω1q ` Xn pωqqs
“ ω ÞÑ EXnpωq rω1 ÞÑ f pX1 pω1qqs “ EXn rf pX1qs .
(2.82)
The equality in (2.82) proves Lemma 2.19.
□
2.20. Remark. It would have been suﬃcient to take f of the form f “ 1k,
k P Z.
2.21. Remark. Lemma 2.19 proves more than just the Markov property for a
random walk. It only uses the fact that the increments Sn are identically P-
distributed and independent, and that the process pXnqnPN possesses the same
Pj-distribution as the P-distribution of the process pXn ` jqnPN, j P Z. The
proof only simpliﬁes a little bit if one uses the random walk properties in an
explicit manner.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
60 
Renewal theory and Markov chains
1.1.2. Some remarks. From a historic point of view the references [6, 47,
151] are quite relevant. The references [10, 43] are relatively speaking good
accessible. The reference [153] gives a detailed treatment of martingale theory.
Citations, like [54, 140, 142, 145] establish a precise relationship between
Feller operators, Markov processes, and solutions to the martingale problem.
The references [49, 50] establish a relationship between hedging strategies (in
mathematical ﬁnance) and (backward) stochastic diﬀerential equations.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
61 
Renewal theory and Markov chains
2. Some additional comments on Markov processes
In this section we will discuss some topics related to Markov chains and Markov
processes. We consider a quadruple
tpΩ, F, Pq , pXn, n P Nq , pϑn, n P Nq , pS, Squ .
(2.83)
In (2.83) the triple pΩ, F, Pq stands for a probability space, Ωis called the
“sample space”, F is a σ-ﬁeld on Ω, and P is a probability measure on F. The
σ-ﬁeld F is called the σ-ﬁeld of events. The symbol pS, Sq stands for the state
space of our process pXn : n P Nq. In the present situation the state space S is
discrete and countable with the discrete σ-ﬁeld S.
Let pΩ, F, Pq be a probability space and let Xj : ΩÑ S, j P N “ t0, 1, 2, . . .u,
be state variables. It is assumed that the σ-ﬁeld F is generated by the state
variables Xj, j P N. Let ϑk : ΩÑ Ω, k P N, be time shift operators, which are
also called time translation operators: Xj ˝ ϑk “ Xj`k, j, k P N. For a bounded
σ pXj : j P Nq-measurable stochastic variable F : ΩÑ R and x P S we write
Ex rFs “ E
“
F
ˇˇ X0 “ x
‰
“ E rF, X0 “ xs
P rX0 “ xs .
We also write
Tx,y “ P rX1 “ y, X0 “ xs
P rX0 “ xs
“ Px rX1 “ ys “ P
“
X1 “ y
ˇˇ X0 “ x
‰
.
Here x has the interpretation of state at time 0, and y is the state at time
1. Let Gn, n P N, be the internal memory up to the moment n. Hence Gn “
σ pXj : 0 ď j ď nq.
2.22. Theorem. Suppose that pXn : n P Nq is a stochastic process with values
in a discrete countable state space S with the discrete σ-ﬁeld S.
The state
variables Xn, n P N, are deﬁned on a probability space pΩ, F, Pq. Write, as
above, Tx,y “ P
“
X1 “ y
ˇˇ X0 “ x
‰
, x, y P S. Then the following assertions are
equivalent:
(1) For all ﬁnite sequences of states ps0, . . . , sn`1q in S the following iden-
tity holds:
P
`
Xn`1 “ sn`1
ˇˇ X0 “ s0, . . . , Xn “ sn
˘
“ Tsn,sn`1;
(2.84)
(2) For all bounded functions f : S Ñ R and for all times n P N the
following equality holds:
E
“
f pXn`1q
ˇˇ Gn
‰
“ EXn rf pX1qs P-almost surely;
(2.85)
(3) For all bounded functions f0, . . . , fk op S and for all times n P N the
following equality holds P-almost surely:
E
“
f0pXnqf1pXn`1q . . . fkpXn`kq
ˇˇ Gn
‰
“ EXn rf0pX0qf1pX1q . . . fkpXkqs ; (2.86)
(4) For all bounded measurable functions F : pΩ, Fq Ñ R (stochastic vari-
ables) and for all n P N the following identity holds:
E
“
F ˝ ϑn
ˇˇ Gn
‰
“ EXn rFs P-almost surely;
(2.87)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
62 
Renewal theory and Markov chains
(5) For all bounded functions f : S Ñ R and for all pGnqnPN-stopping times
τ : ΩÑ r0, 8s the following equality holds:
E
“
fpXτ`1q
ˇˇ Gτ
‰
“ EXτ rfpX1qs
P-almost surely on the event
tτ ă 8u ;
(2.88)
(6) For all bounded measurable functions F : pΩ, Fq Ñ R (random vari-
ables) and for all stopping times τ the following identity holds:
E
“
F ˝ ϑτ
ˇˇ Gτ
‰
“ EXτ rFs
P-almost surely on the event
tτ ă 8u .
(2.89)
Before we prove Theorem 2.22 we make some remarks and give some explana-
tion.
2.23. Remark. Let Ω“ SN, equipped with the product σ-ﬁeld, and let Xj :
ΩÑ S be deﬁned by Xjpωq “ ωj where ω “ pω0, . . . , wj, . . .q belongs to Ω. If
ϑk : ΩÑ Ωis deﬁned by ϑk pω0, . . . , ωj, . . .q “ pωk, . . . , ωj`k, . . .q, then it follows
that Xj ˝ ϑk “ Xj`k.
2.24. Remark. Instead of one probability space pΩ, F, Pq we often consider a
family of probability spaces pΩ, F, PxqxPS.
The probabilities Px, x P S, are
determined by
Ex rFs “ E
“
F
ˇˇ X0 “ x
‰
“ E rF, X0 “ xs
P rX0 “ xs ,
x P S.
(2.90)
Here F : ΩÑ R is F-BR-measurable, and hence by deﬁnition it is a random or
stochastic variable. Since Px rAs “ Ex r1As, A P F, and Px rΩs “ Ex r1s “ 1, the
measure Px is a probability measure on F.
2.25. Remark. Let F : ΩÑ R be a bounded stochastic variable. The variable
EXn rFs is a stochastic variable which is measurable with respect to the σ-ﬁeld
σ pXnq, i.e. the σ-ﬁeld generated by Xn. In fact we have
EXnpωq rFs “ E
“
F
ˇˇ X0 “ Xnpωq
‰
“ E rF, X0 “ Xnpωqs
P rX0 “ Xnpωqs
“ E
“
ω1 ÞÑ F pω1q ˆ 1tX0“Xnpωqu pω1q
‰
.
(2.91)
If we ﬁx ω P Ω, then in (2.91) everything is determined, and there should be no
ambiguity any more.
2.26. Remark. Fix n P N. The σ-ﬁeld Gn is generated by events of the form
tpX0, X1, . . . , Xnq “ ps0, s1, . . . , snqu .
Here ps0, s1, . . . , snq varies over Sn`1. It follows that
Gn “ σ
␣
tpX0, X1, . . . , Xnq “ ps0, s1, . . . , xnqu : ps0, s1, . . . , snq P Sn`1(
“
␣
tpX0, X1, . . . , Xnq P Bu : B P Sbpn`1q(
“ σ pX0, X1, . . . , Xnq .
(2.92)
The σ-ﬁeld in (2.92) is the smallest σ-ﬁeld rendering all state variables Xj,
0 ď j ď n, measurable. It is noticed that Gn Ă F.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
63 
Renewal theory and Markov chains
2.27. Remark. Next we discuss conditional expectations. Again let F : ΩÑ R
be a bounded stochastic variable. If we write Z “ E
“
F
ˇˇ Gn
‰
, then we mean
the following:
(1) The stochastic variable Z is Gn-BR-measurable. This a qualitative as-
pect of the notion of conditional expectation.
(2) The stochastic variable Z possesses the property that E rF, As“E rZ, As
for all events A P Gn. This is the quantitative aspect of the notion of
conditional expectation.
Notice that the property in (2) is equivalent to the following one: the stochastic
variable Z satisﬁes the equality E
“
F
ˇˇ A
‰
“ E
“
Z
ˇˇ A
‰
for all events A P Gn.
2.28. Remark. Let G be a sub-σ-ﬁeld of F. The mapping F ÞÑ E
“
F
ˇˇ G
‰
is an
orthogonal projection from L2 pΩ, F, Pq onto L2 pΩ, G, Pq. Let F P L2 pΩ, F, Pq,
and put Z “ E
“
F
ˇˇ G
‰
. In fact we have to verify the following conditions:
(1) Z P L2 pΩ, G, Pq;
(2) If G P L2 pΩ, G, Pq, then the following inequality is satisﬁed:
E
“
|F ´ Z|2‰
ď E
“
|F ´ G|2‰
.
This claim is left as an exercise for the reader. For more details on conditional
expectations see Section 1 in Chapter 1.
2.29. Remark. Next we will give an explicit formula for the conditional ex-
pectation in the setting of a enumerable discrete state space S.
Let Gn “
σ pX0, X1, . . . , Xnq where Xj : ΩÑ S, 0 ď j ď n, are state variables with a
discrete countable state space S. In addition, let F : ΩÑ R be a bounded
stochastic variable. Then we have
E
“
F
ˇˇ Gn
‰
“
ÿ
i0,...,inPS
E
“
F
ˇˇ X0 “ i0, . . . , Xn “ in
‰
1tX0“i0u ¨ ¨ ¨ 1tXn“inu. (2.93)
Writing the conditional expectation in (2.93) in an explicit manner as a function
of ω yields
E
“
F
ˇˇ Gn
‰
pωq
“
ÿ
i0,...,inPS
E
“
F
ˇˇ X0 “ i0, . . . , Xn “ in
‰
1tX0“i0upωq ¨ ¨ ¨ 1tXn“inupωq.
(2.94)
From (2.93) and also (2.94) it is clear that the conditional expectation
E
“
F
ˇˇ Gn
‰
is Gn-measurable.
2.30. Remark. Put G “ G8 “ σ pX0, . . . , Xn, . . .q “ σ
`
X
˘
where X : ΩÑ SN
is the variable deﬁned by X pωq “ pX0pωq, . . . , Xnpωq, . . .q, ω P Ω. Then
G “ G8
(2.95)
“
␣␣
X P B
(
: B is measurable with respect to the product σ-ﬁeld on SN(
.
2.31. Remark. Let τ : ΩÑ N Y t8u be a random variable. This random
variable is called a stopping time relative the ﬁltration pGnqnPN, or, more brieﬂy,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
64 
Renewal theory and Markov chains
τ is called a pGnqnPN-stopping time, provided that for every k P N an event of
the form tτ ď ku is Gk-measurable. The latter property is equivalent to the
following one. For every k P N the event tτ “ ku is Gk-measurable. Note that
tτ “ ku “ tτ ď ku z tτ ď k ´ 1u, k P N, k ě 1, and tτ ď ku “ Yk
j“0 tτ “ ju.
From these equalities it follows that τ is a pGnqnPN-stopping time if and only if
for every k P N the event tτ “ ku is Gk-measurable.
2.32. Remark. Let B be a subset of S. Important examples of stopping times
are
τ 0
B “ inf tk ě 0 : Xk P Bu
on
Y8
k“0 tXk P Bu
and 8 elsewhere;
τ 1
B “ inf tk ě 1 : Xk P Bu
on
Y8
k“1 tXk P Bu
and 8 elsewhere.
(2.96)
Similarly we also write τ s
B “ inf tk ě s : Xk P Bu on the event Y8
k“s tXk P Bu,
and τ s
B “ 8 elsewhere. The time τ 0
B is called the ﬁrst income time, and τ 1
B is
called the ﬁrst hitting time, or the ﬁrst income time after 0.
We also notice that τ 1
B “ min tk ě 1 : Xk P Bu on Y8
k“1 tXk P Bu and τ 1
B “ 8
on X8
ℓ“1 tXℓP SzBu. In addition: 1 ` τ 0
B ˝ ϑ1 “ ϑ1
B.
2.33. Remark. Again let τ : ΩÑ N Y t8u be a pGnqnPN-stopping time. The
σ-ﬁeld Gτ containing the information from the past of τ is deﬁned by
Gτ “ XkPN tA P F : A X tτ ď ku P Gku
“ σ pXj^τ : j P Nq
(2.97)
where Xj^τpωq “ Xj^τpωqpωq, ω P Ω.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
65 
Renewal theory and Markov chains
2.34. Remark. Let F be a stochastic variable. What is meant by F ˝ ϑk and
F ˝ ϑτ on the event tτ ă 8u? Here k P N, and τ is a pGnqnPN-stopping time.
For F “ śn
j“0 fj pXjq we write:
F ˝ ϑk “
n
ź
j“0
fj pXjq ˝ ϑk “
n
ź
j“0
fj pXj`kq ,
and on the event tτ ă 8u
F ˝ ϑτ “
n
ź
j“0
fj pXjq ˝ ϑτ “
n
ź
j“0
fj pXj`τq .
(2.98)
2.35. Proposition. Let
´
T pnq
x,y
¯
px,yqPSˆS be a sequence of square matrices with
positive entries, possibly with inﬁnite countably many entries (when S is count-
able, not ﬁnite). Put
T 0
x,y “ I, T 1
x,y “ T p1q
x,y,
T n
x,y “
ÿ
s1,...,snPS
n`1
ź
j“1
Tsj´1,sj,
s0 “ x,
sn`1 “ y.
(2.99)
The equalities in (2.99) are to be considered as matrix multiplications.
Fix
1 ď n1 ă ¨ ¨ ¨ ă nk ď n, and let the measure space
`
Sk, bk
j“1S, µ0,x
n1,...,nk,n`1,y
˘
,
px, yq P S ˆ S, n P N be determined by the equalities:
ż
Sk
n
ź
j“1
fj psjq dµ0,s0
n1,...,nk,n`1,sn`1 ps1, . . . , skq
“
ÿ
ps1,...,skqPSk
k`1
ź
j“1
T pnj´nj´1q
sj´1,sj
fj psjq ,
fj P L8 pS, Sq ,
(2.100)
where ps0, sn`1q “ px, yq P S ˆ S, n0 “ 0, and nk`1 “ n ` 1. Then for every
1 ď j0 ď n, and fj P L8 pE, Eq, 1 ď j ď n, this family satisﬁes the following
equality:
ż
Sn
n
ź
j“1
fj psjq dµ0,s0
1,...,n,n`1,sn`1 ps1, . . . , snq
(2.101)
“
ż
Sn´1
n
ź
j“1, j‰j0
fj psjq dµ0,s0
n,sn`1 ps1, . . . , sj0´1, sj0`1, . . . , snq T 2
sj0´1,sj0`1
where T 2
x,y “ ř
zPS T p1q
x,z T p1q
z,y for all px, yq P S ˆ S (matrix multiplication). Let
1 ď n1 ă ¨ ¨ ¨ ă nk ď n, and put
µ0,x
n1,...,nk,n`1 pB0 ˆ Bq “
ÿ
yPS
1B0pxqµ0,x
n1,...,nk,n`1,y pBq ,
B0 P S, B P bkS.
(2.102)
Suppose that the matrices
´
T pnq
x,y
¯
px,yqPSˆS, n P N, are stochastic.
Then the
measures in (2.102) do not depend on n`1. Moreover, the following assertions
are equivalent:
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
66 
Renewal theory and Markov chains
(a) The family of measure spaces
␣`
Sk`1, bk`1S, µ0,x
n1,...,nk,n`1
˘
: 1 ď n1 ă ¨ ¨ ¨ ă nk ď n, n P N
(
(2.103)
is a consistent family of probability measure spaces.
(b) The family of measure spaces deﬁned in (2.100) is consistent.
(c) For every n P N and px, yq P S ˆ S the equality T pnq
x,y “ T n
x,y holds.
Suppose that the family in (2.103) is a consistent family of probability spaces.
Then the corresponding process
tpΩ, F, PxqxPS , pXn : n P Nq , pϑn, n P Nq , pS, Squ .
(2.104)
is a Markov chain if and only if for px, yq P S ˆ S and n, m P N the following
matrix multiplication equality holds:
T pn`mq
x,y
“
`
ÿ
zPS
T pnq
x,z T pmq
z,y “
ÿ
zPS
T n
x,zT m
z,y.
(2.105)
This means that
Px rX0 P B0, . . . , Xn P Bns “ 1B0pxqµ0,x
1,...,n,n`1 pB1 ˆ ¨ ¨ ¨ ˆ Bnq ,
for Bj P S, 0 ď j ď n, and that the family in (2.104) possesses the Markov
property if and only (2.105) holds.
In addition, we have T pnq
x,y “ Px rXn “ ys, x, y P S; i.e. the quantities T pnq
x,y
represent the n time step transition probabilities from the state x to the state y.
2.36. Theorem. Let the notation be as in Theorem 2.22. The following asser-
tions are equivalent:
(1) For every s P S, for every bounded function f : S Ñ R, and for all
n P N the following equality holds Ps-almost surely:
Es
“
f pXn`1q
ˇˇ Gn
‰
“ EXn rf pX1qs .
(2.106)
(2) For every bounded function f : S Ñ R, and for all n P N the following
equality holds P-almost surely:
E
“
f pXn`1q
ˇˇ Gn
‰
“ EXn rf pX1qs .
(2.107)
2.37. Remark. From the proof it follows that in Theorem 2.36 we may replace
the stochastic variable f pX1q by any bounded stochastic variable Y : ΩÑ R.
At the same f pXn`1q “ f pX1q ˝ ϑn has to be replaced by Y ˝ ϑn.
2.38. Remark. Theorem 2.36 together with Remark 2.37 shows that through-
out in Theorem 2.22 we may replace the probability P with Ps for any s P S.
Consequently, we could have deﬁned a time-homogeneous Markov chain as a
quadruple
tpΩ, F, PsqsPS , pXn : n P Nq , pϑk, k P Nq , pS, Squ
satisfying the equivalent conditions in Theorem 2.22 with Ps, for all s P E,
instead of P.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
67 
Renewal theory and Markov chains
Proof of Theorem 2.36. (1) ùñ (2) Let s P S, f : S Ñ R a bounded
function, and n P N. From (2.106) we infer
Es rf pXn`1q , As “ Es rEXn rf pX1qs , As
for all A P Gn.
(2.108)
From (2.108) we infer
E rf pXn`1q , A, X0 “ ss
“ E rEXn rf pXn`1qs , A, X0 “ ss
for all A P Gn, and s P S.
(2.109)
By summing over s P S in (2.109) we obtain
E rf pXn`1q , As “ E rEXn rf pXn`1qs , As
for all A P Gn.
(2.110)
From (2.110) the equality in (2.107) easily follows.
(2) ùñ (1) Let f : S Ñ R and n P N be such that (2.107) holds. Then, since all
events of the form tX0 “ su, s P S, belong to Gn, (2.107) implies that (2.109)
holds for f and hence by dividing by P rX0 “ ss, for s P S, we obtain (2.108).
Hence (2.106) follows.
All this completes the proof of Theorem 2.36.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
68 
Renewal theory and Markov chains
The following theorem is similar to the formulation of Theorem 2.36 but now
with stopping times and having remark 2.37 taken into account:
2.39. Theorem. Let the notation be as in Theorem 2.22, and let τ : ΩÑ r0, 8s
be a pGnqnPN-stopping time. The following assertions are equivalent:
(1) For every s P S, and for every bounded stochastic variable Y : ΩÑ R
the following equality holds Ps-almost surely on the event tτ ă 8u:
Es
“
Y ˝ ϑτ
ˇˇ Gτ
‰
“ EXτ rY s .
(2.111)
(2) For every bounded stochastic variable Y : ΩÑ R the following equality
holds P-almost surely on the event tτ ă 8u:
E
“
Y ˝ ϑτ
ˇˇ Gτ
‰
“ EXτ rY s .
(2.112)
2.40. Remark. Let τ : ΩÑ NYt8u be a pGnqnPN-stopping time, and let A P Gτ.
Let m P N Y t8u. Put τm “ m1ΩzA ` τ1A. Then τm is a pGnqnPN-stopping time.
If PrAs ă 1 and m “ 8, then τm “ 8 on the event ΩzA which is non-negligible.
2.41. Definition. Let Ωbe a set and let S be a collection of subsets of Ω. Then
S is called a Dynkin system, if it has the following properties:
(a) ΩP S;
(b) if A and B belong to S and if A Ě B, then AzB belongs to S;
(c) if pAn : n P Nq is an increasing sequence of elements of S, then the union
Ť8
n“1 An belongs to S.
In the literature Dynkin systems are also called λ-systems: see e.g. [3].
A
π-system is a collection of subsets which is closed under ﬁnite intersections. A
Dynkin system which is also a π-system is a σ-ﬁeld. The following result on
Dynkin systems, known as the π-λ theorem, gives a stronger result.
2.42. Theorem. Let M be a collection of subsets of Ω, which is stable under
ﬁnite intersections, so that M is a π-system on Ω. The Dynkin system generated
by M coincides with the σ-ﬁeld generated by M.
Proof. Let D pMq be the smallest Dynkin-system containing M, i.e. D pMq
is the Dynkin-system generated by M. For all A P D pMq, we deﬁne:
ΓpAq :“ tB P D pMq : A X B P D pMqu .
then we have
(1) if A belongs to M, M Ă ΓpAq,
(2) for all A P M, ΓpAq is a Dynkin system on Ω.
(3) if A belongs to M, then D pMq Ă ΓpAq,
(4) if B belongs to D pMq, then M Ă ΓpBq,
(5) for all B P D pMq the inclusion, D pMq Ă ΓpBq holds.
It follows that D pMq is also a π-system. It is esay to see that a Dynkin system
which is at the same time a π-system is in fact a σ-ﬁeld (or σ-algebra). This
completes the proof of Theorem 2.42.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
69 
Renewal theory and Markov chains
2.43. Theorem. Let Ωbe a set and let M be a collection of subsets of Ω, which
is stable (or closed) under ﬁnite intersections. Let H be a vector space of real
valued functions on Ωsatisfying:
(i) The constant function 1 belongs to H and 1A belongs to H for all
A P M;
(ii) if pfn : n P Nq is an increasing sequence of non-negative functions in H
such that f “ supnPN fn is ﬁnite (bounded), then f belongs to H.
Then H contains all real valued functions (bounded) functions on Ω, that are
σpMq measurable.
Proof. Put D “ tA Ď Ω: 1A P Hu.
Then by (i) Ωbelongs to D and
D Ě M. If A and B are in D and if B Ě A, then BzA belongs to D. If
pAn : n P Nq is an increasing sequence in D, then 1YAn “ supn 1An belongs to
D by (ii). Hence D is a Dynkin system, that contains M. Since M is closed
under ﬁnite intersection, it follows by Theorem 2.42 that D Ě σpMq. If f ě 0 is
measurable with respect to σpMq, then f “ sup
n 2´n ÿn2n
j“1 1tfěj2´nu. Since the
subsets tf ě j2´nu, j, n P N, belong to σpMq, we see that f is a member of H.
Here we employed the fact that σpMq Ď D. If f is σ pMq-measurable, then we
write f as a diﬀerence of two non-negative σ pMq-measurable functions.
□
The previous theorems (Theorem 2.42 and Theorem 2.43) are used in the fol-
lowing form. Let Ωbe a set and let pSi, SiqiPI be a family of measurable spaces,
indexed by an arbitrary set I. For each i P I, let Mi denote a collection of
subsets of Si, closed under ﬁnite intersection, which generates the σ-ﬁeld Si,
and let fi : ΩÑ Si be a map from Ωto Si. In this context the following two
propositions follow.
2.44. Proposition. Let M be the collection of all sets of the form Ş
iPJ f ´1
i
pAiq,
Ai P Mi, i P J, J Ď I, J ﬁnite. Then M is a collection of subsets of Ωwhich is
stable under ﬁnite intersection and σpMq “ σ pfi : i P Iq.
2.45. Proposition. Let H be a vector space of real-valued functions on Ωsuch
that:
(i) the constant function 1 belongs to H;
(ii) if phn : n P Nq is an increasing sequence of non-negative functions in H
such that h “ supn hn is ﬁnite (bounded), then h belongs to H;
(iii) H contains all products of the form ś
iPJ 1Ai ˝ fi, J Ď I, J ﬁnite, and
Ai P Mi, i P J.
Under these assumptions H contains all real-valued functions (bounded) func-
tions in σpfi : i P Iq.
The theorems 2.42 and 2.43, and the propositions 2.44 and 2.45 are called the
monotone class theorem.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
70 
Renewal theory and Markov chains
In the propositions 2.44 and 2.45 we may take Si “ S, Mi the collection of ﬁnite
subsets of Si, and fi “ Xi, i P I “ N.
3. More on Brownian motion
Further on in this book on stochastic processes we will discuss Brownian motion
in more detail. In fact we will consider Brownian motion as a Gaussian process,
as a Markov process, and as a martingale (which includes a discussion on Itˆo
calculus). In addition Brownian motion can be viewed as weak limit of a scaled
symmetric random walk. For this result we need a Functional Central Limit
Theorem (FCLT) which is a generalization of the classical central limit theorem.
2.46. Theorem (Multivariate Classical Central Limit Theorem). Let pΩ, F, Pq
be a probability space, and let tZn : n P Nu be a sequence of P-independent and
P-identically distributed random variables with values in Rd in L1 `
Ω, F, P; Rd˘
.
Let µ “ E rZ1s, and let D be the dispersion matrix of Z1 (i.e. the variance-
covariance of the random vector Z1). Then there exists a centered Gaussian (or
multivariate normal) random vector X with dispersion matrix D such that the
sequence
Xn :“ Z1 ` ¨ ¨ ¨ ` Zn ´ nµ
?n
converges weakly (or in distribution) to a centered random vector X with dis-
persion matrix D as n Ñ 8. The latter means that lim
nÑ8 E rf pZnqs “ E rf pZqs
for all bounded continuous functions f : Rd Ñ R.
Notice that by a non-trivial density argument we only need to prove the equality
lim
nÑ8 E
„
f
ˆZ1 ` ¨ ¨ ¨ ` Zn ´ nµ
?n
˙ȷ
“ E rf pXqs
for all functions f of the form fpxq “ e´i⟨x,ξ⟩, x P Rd, ξ P Rd.
Next let us give a (formal) deﬁnition of Brownian motion.
2.47. Definition. A one-dimensional Brownian motion with drift µ and diﬀu-
sion coeﬃcient σ2 is a stochastic process tXptq : t ě 0u with continuous sam-
ple paths having independent Gaussian increments with mean and variance of
an increment Xpt ` sq ´ Xptq given by sµ “ E rXpt ` sq ´ Xptqs and sσ2 “
E
“
pXpt ` sq ´ Xptqq2‰
, s, t ě 0. If X0 “ x, then this Brownian is said to start
at x. A Brownian motion with drift µ “ 0, and σ2 “ 1 is called a standard
Brownian motion.
One of the problems is whether or not such a process exists. One way of resolv-
ing this problem is to put the Functional Central Limit Theorem at work. Let
us prepare for this approach. Let tZj : j P Nu be a sequence of centered inde-
pendent identically distributed real valued random variables in L1 pΩ, F, Pq with
variance σ2 “ E rZ2
1s. For example these variables could be Bernoulli variables
taking the values `σ and ´σ with the same probability 1
2. Put S0 “ Z0 “ 0,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
71 
Renewal theory and Markov chains
Sn “ Z1 ` ¨ ¨ ¨ , `Zn, n P N, n ě 1. Deﬁne for each scale parameter n ě 1 the
stochastic process Xpnqptq by
Xpnqptq “ Stntu
?n “
řtntu
k“0 Zk
?n
,
t ě 0.
(2.113)
Here tntu is the integer part of nt, i.e. the largest integer k for which k ď nt ă
k ` 1. The it is relatively easy to see that
E
“
Xpnqptq
‰
“ 0,
and
Var
`
Xpnqptq
˘
“ E
“
Xpnqptq2‰
“ tσ2.
(2.114)
Then the classical CLT (Central Limit Theorem) implies that there exists a
process tXptq : t ě 0u with the property that for every m P N, for every choice
pt1, . . . , tmq of m positive real numbers, and every bounded continuous function
f : Rm Ñ C the following limit equality holds:
lim
nÑ8 E
“
f
`
Xpnqptq
˘‰
“ E rf pXptqqs .
(2.115)
The equality in (2.115) says the ﬁnite-dimensional distributions of the sequence
of processes
␣
Xpnqptq : t ě 0
(
nPN converges weakly to the ﬁnite-dimensional
distributions of the process tXptq : t ě 0u.
This limit should then be one-
dimensional Brownian motion with drift zero and variance σ2.
A posteriori
we know that Brownian motion should be P-almost surely continuous. How-
ever the processes
␣
Xpnqptq : t ě 0
(
nPN have jumps. It would be nice if we were
able to replace these processes which have jumps by processes without jumps.
Therefore we employ linear interpolation. This can be done as follows. We
introduce the following interpolating sequence of continuous processes:
r
Xpnqptq “ Stntu
?n ` pnt ´ tntuq Ztntu`1
?n ,
t ě 0.
(2.116)
Let m and n be positive integers. Then on the half open interval
„m
n , m ` 1
n
˙
the variable Xnptq is constant in time t at level Sm
n , while r
Xnptq changes linearly
from
Sm
n
at time t “ m
n to Sm`1
?n “ Sm
?n ` Zm`1
?n
at time t “ m ` 1
n
.
(2.117)
It can be proved that the sequence of stochastic processes
!
r
Xpnqptq : t ě 0
)
nPN
converges weakly to Brownian motion with drift µ and variance σ2. This is
the contents of the following FCLT (Functional Central Limit Theorem). The
following result also goes under the name “Donsker’s invariance principle”: see,
e.g., [15] or [42].
2.48. Theorem (Functional Central Limit Theorem). Let
!
r
Xpnqptq : t P r0, Ts
)
,
n P N, and tXptq : t P r0, Tsu be stochastic processes possessing sample paths
which are P-almost surely continuous with the property that the ﬁnite-dimen-
sional distributions of the sequence
!
r
Xpnqptq : t P r0, Ts
)
nPN converge weakly to
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
72 
Renewal theory and Markov chains
those of tXptq : t P r0, Tsu.
Then the sequence
!
r
Xpnqptq : t P r0, Ts
)
nPN con-
verges weakly to tXptq : t P r0, Tsu if and only if for every ε ą 0 the following
equality holds:
lim
δÓ0 sup
nPN
P
«
sup
0ďs,tďT, |s´t|ďδ
ˇˇˇ r
Xpnqpsq ´ r
Xpnqpsq
ˇˇˇ ě ε
ﬀ
“ 0.
(2.118)
This result is based on Prohorov’s tightness theorem and the Arzela-Ascoli
characterization of compact subsets of Cr0, Ts.
2.49. Theorem (Prohorov theorem). Let pPn : n P Nq be a sequence of proba-
bility measures on a separable complete metrizable topological space S with Borel
σ-ﬁeld S. Then the following assertions are equivalent:
(i) For every ε ą 0 there exists a compact subset Kε of S such that
Pn rKεs ě 1 ´ ε for all n P N.
(ii) Every subsequence of pPn : n P Nq has a subsequence which converges
weakly to a probability measure on pS, Sq.
A sequence pPnqn satisfying (i) (or (ii)) in Theorem 2.49 is called a Prohorov
set. Theorem 2.48 can be proved by applying Theorem 2.49 with Pn equal to
the P-distribution of the process
!
r
Xpnqptq : 0 ď t ď T
)
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
73 
Renewal theory and Markov chains
2.50. Theorem (Arzela-Ascoli). Endow Cr0, Ts with the topology of uniform
convergence. A subset A of Cr0, Ts has compact closure if and only if it has the
following properties:
(i) sup
ωPA
|ωp0q| ă 8;
(ii) The subset A is equi-continuous in the sense that
lim
δÓ0
sup
0ďs,tďT, |s´t|ďδ
sup
ωPA
|ωpsq ´ ωptq| “ 0.
From (i) and (ii) it follows that sup
ωPA
sup
sPr0,Ts
|ωpsq| ă 8, and hence A is uniformly
bounded. The result which is relevant here reads as follows. It is the same as
Theorem T.8.4 in Bhattacharaya and Waymire [15].
2.51. Theorem. Let pPnqn be a sequence of probability measures on Cr0, Ts.
Then pPnqn is tight if and only if the following two conditions hold.
(i) For each η ą 0 there is a number B such that
Pn rω P Cr0, Ts : |ωp0q| ą Bs ă η,
n “ 1, 2, . . .
(ii) For each ε ą 0, η ą 0, there is a 0 ă δ ă 1 such that
Pn
«
ω P Cr0, Ts :
sup
0ďs,tďT, |s´t|ďδ
|ωpsq ´ ωptq| ě ε
ﬀ
ď η,
n “ 1, 2, . . .
Proof. If the sequence pPnqn is tight, then given η ą 0 there is a compact
subset K of C pr0, Tsq such that PnpKq ą 1 ´ η for all n. By the Arzela-Ascoli
theorem (Theorem 2.50), if B ą supωPK |ωp0q|, then
Pn rω P Cr0, Ts : |ωp0q| ě Bs ď Pn rKcs ď 1 ´ p1 ´ ηq “ η.
Also given ε ą 0 select δ ą 0 such that sup
ωPK
sup
0ďs,tďT, |s´t|ďδ
|ωpsq ´ ωptq| ă ε. Then
Pn
«
ω P Cr0, Ts :
sup
0ďs,tďT, |s´t|ďδ
|ωpsq ´ ωptq| ě ε
ﬀ
ď Pn rKcs ă η for all n ě 1.
The converse goes as follows. Given η ą 0, ﬁrst select B using (i) such that
Pn rω P C pr0, Tsq : |ωp0q| ď Bs ě 1 ´ 1
2η, for n ě 1. Select δr ą 0 using (ii)
such that
Pn
«
ω P C pr0, Tsq :
sup
0ďs,tďT, |s´t|ďδ
|ωpsq ´ ωptq| ă 1
r
ﬀ
ě 1 ´ 2´pr`1qη
for n ě 1.
Now take K to be the uniform closure of
8
č
r“1
#
ω P C pr0, Tsq : |ωp0q| ď B,
sup
0ďs,tďT, |s´t|ďδ
|ωpsq ´ ωptq| ă 1
r
+
.
Then PnpKq ą 1´η for n ě 1, and K is compact by the Arzela-Ascoli theorem.
This completes the proof Theorem 2.51.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
74 
Renewal theory and Markov chains
For convenience of the reader we formulate some limit theorems which are rel-
evant in the main text of this book. The formulations are taken from Stirzaker
[126].
For proofs the reader is also referred to Stirzaker.
For convenience
we also insert proofs which are based on Birkhoﬀ’s ergodic theorem. Deﬁne
Sn “ řn´1
k“0 Xk, where the variables tXkukPN Ă L1 pΩ, F, Pq are independent and
identically distributed (i.i.d.). Then we have the following three classic results.
2.52. Theorem (Central limit theorem, standard version). If E rXks “ µ and
0 ă var pXkq “ σ2 ă 8, then
lim
nÑ8 P
„Sn ´ nµ
pnσ2q1{2 ď x
ȷ
“ Φpxq,
x P R,
where Φpxq is the standard normal distribution, i.e. Φpxq “
1
?
2π
ż x
´8
e´ 1
2 x2 dx.
Proof. Let f : R Ñ C be a bounded C2-function with a bounded second
derivative. Then by Taylor’s formula (or by integration by parts) we have
fpyq “ fp0q ` yf 1p0q ` 1
2y2f 2p0q `
ż 1
0
p1 ´ sq y2 tf 2 psyq ´ f 2p0qu ds. (2.119)
Put Yn,k “ Xk ´ µ
σ?n . Inserting y “ Yn,k into (2.119) yields
f pYn,kq “ fp0q`Yn,kf 1p0q` 1
2Y 2
n,kf 2p0q`
ż 1
0
p1 ´ sq Y 2
n,k tf 2 psYn,kq ´ f 2p0qu ds.
(2.120)
Then we take expectations in (2.120) to obtain:
E rf pYn,kqs “ fp0q ` 1
2nf 2p0q `
ż 1
0
p1 ´ sq E
“
Y 2
n,k tf 2 psYn,kq ´ f 2p0qu
‰
ds.
(2.121)
Put
εnptq “ n
ż 1
0
p1 ´ sqE
“
Y 2
n,1
`
1 ´ e´istYn,1˘‰
ds,
t P R,
and choose fpyq “ e´ity. Observe that, uniformly in t on compact subsets of
R, limnÑ8 εnptq “ 0. Then, since the variables Yn,k, 1 ď k ď n, are i.i.d., from
(2.121) we get
E
“
e´itYn,k‰
“ 1 ´ t2
2n ` t2εnptq
n
.
(2.122)
From (2.122) we infer
E
”
e´it řn
k“1 Yn,k
ı
“
`
E
“
e´itYn,1‰˘n “
ˆ
1 ´ t2
2n ` t2εnptq
n
˙n
.
(2.123)
Let Y : ΩÑ R be a standard normally distributed random variable. From the
properties of the sequence tεnptqun and (2.123) we see that, for every 0 ă R ă 8,
lim
nÑ8 sup
|t|ďR
!
E
”
e´it řn
k“1 Yn,k ´ e´itY ı)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
75 
Renewal theory and Markov chains
“ lim
nÑ8 sup
|t|ďR
!
E
”
e´it řn
k“1 Yn,k
ı
´ e´ 1
2 t2)
“ lim
nÑ8 sup
|t|ďR
"
E
”
e´it řn
k“1 Yn,k
ı
´
ˆ
1 ´ t2
2n ` t2εnptq
n
˙n*
“ 0.
(2.124)
The conclusion in Theorem 2.52 then follows from (2.124) together with L´evy’s
continuity theorem: see Theorem 5.42, and Theorem 5.43 assertions (9) and
(10).
□
2.53. Theorem (Weak law of large numbers). If E rXks “ µ ă 8, then for all
ε ą 0,
lim
nÑ8 P
„ˇˇˇˇ
Sn
n ´ µ
ˇˇˇˇ ą ε
ȷ
“ 0.
For a proof of the following theorem see (the proof of) Theorem 5.60. It is
proved as a consequence of the (pointwise) ergodic theorem of Birkhoﬀ: see
Theorems 5.59 and 5.66, and Corollary 5.67.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
76 
Renewal theory and Markov chains
2.54. Theorem (Strong law of large numbers). The equality
lim
nÑ8
Sn
n “ µ,
holds P-almost surely
(2.125)
for some ﬁnite constant µ, if and only if E r|Xk|s ă 8, and then µ “ E rX1s.
Moreover, the limit in (2.125) also exists in L1-sense.
We will show that Theorem 2.53 is a consequence of Theorem 2.54.
Proof of Theorem 2.53. Let ε ą 0 be arbitrary, and let tXkuk and µ
be as in Theorem 2.53. Then
P
„ˇˇˇˇ
Sn ´ nµ
n
ˇˇˇˇ ě ε
ȷ
ď 1
εE
„ˇˇˇˇ
Sn
n ´ µ
ˇˇˇˇ
ȷ
.
(2.126)
By the L1-version of Theorem 2.54 it follows that the right-had side of (2.126)
converges to 0. This shows that Theorem 2.53 is a consequence of Theorem
2.54.
□
The central limit theorem is the principal reason for the appearance of the nor-
mal (or “bell-shaped”) distribution in so many statistical and scientiﬁc contexts.
The ﬁrst version of this theorem was proved by Abraham de Moivre before 1733.
The laws of large numbers supply a solid foundation for our faith in the useful-
ness and good behavior of averages. In particular, as we have remarked above,
they support one of our most appealing interpretations of probability as long-
term relative frequency. The ﬁrst version of the weak law was proved by James
Bernoulli around 1700; and the ﬁrst form of the strong law by Emile Borel in
1909. We include proofs of these results in the form as stated. As noted above
a proof of Theorem 2.54 will be based on Birkhoﬀ’s ergodic theorem.
2.55. Remark. The following papers and books give information about the
central limit theorem in the context of Stein’s method which stems from Stein
[124]: see Barbour and Hall [9], Barbour and Chen [8], Chen, Goldstein and
Shao [31], Nourdin and Peccati [101], Berckmoes et al [13]. This is a very inter-
esting and elegant method to prove convergence and give estimates for partial
sums of so-called standard triangular arrays (STA). It yields sharp estimates:
see the forthcoming paper [14].
4. Gaussian vectors.
The following theorem gives a deﬁnition of a Gaussian (or a multivariate nor-
mally distributed) vector purely in terms of its characteristic function (Fourier
transform of its distribution.
2.56. Theorem. Let pΩ, F, Pq be a probability space, and let X “ pX1, . . . , Xnq
be an Rn-valued Gaussian vector in the sense that there exists a vector µ :“
pµ1, . . . , µnq P Rn and a symmetric square matrix σ :“ pσj,kqn
j,k“1 such that the
characteristic function of the vector X is given by
E
“
e´i⟨ξ,X⟩‰
“ e´i⟨ξ,µ⟩´ 1
2
řn
j,k“1 ξjξkσj,k for all ξ “ pξ1, . . . , ξnq P Rn.
(2.127)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
77 
Renewal theory and Markov chains
Then for every 1 ď j ď n the variable Xj belongs to L2 pΩ, F, Pq, µj “ E rXjs,
and
σj,k “ cov pXj, Xkq “ E rpXj ´ E rXjsq pXk ´ E rXksqs .
(2.128)
Proof. Put Y “ X ´ µ, and ﬁx ε ą 0. Then the equality in (2.127) is
equivalent to
E
“
e´i⟨ξ,Y ⟩‰
“ e´ 1
2
řn
j,k“1 ξjξkσj,k for all ξ “ pξ1, . . . , ξnq P Rn.
(2.129)
From Cauchy’s theorem and the equality
1
?
2π
ż 8
´8
e´ 1
2 η2dη “ 1 we obtain
e´ 1
2 ε|Y |2 “
1
`?
2πε
˘n
ż
Rn e´i⟨η,Y ⟩e´ 1
2ε |η|2 dη “
1
`?
2π
˘n
ż
Rn e´i⟨?εη,Y ⟩e´ 1
2 |η|2 dη.
(2.130)
From (2.129) and (2.130) we infer:
E
”
e´i⟨ξ,Y ⟩e´ 1
2 ε|Y |2ı
“
1
`?
2π
˘n
ż
Rn E
”
e´i⟨ξ`?εη,Y ⟩ı
e´ 1
2 |η|2 dη
(employ (2.129) with ξ ` ?εη instead of ξ)
“
1
`?
2π
˘n
ż
Rn e´ 1
2
řn
j,k“1pξj`?εηjqpξk`?εηkqσj,ke´ 1
2|η|2 dη.
(2.131)
Next we take 1 ď ℓ1, ℓ2 ď n, and we diﬀerentiate the right-hand side and
left-hand side of (2.131) with respect to ξℓ2 and the result with respect ξℓ1. In
addition we write a negative sign in front of this. Then we obtain:
E
”
e´i⟨ξ,Y ⟩Yℓ1Yℓ2e´ 1
2 ε|Y |2ı
“
1
`?
2π
˘n
ż
Rn e´ 1
2
řn
j,k“1pξj`?εηjqpξk`?εηkqσj,ke´ 1
2 |η|2
¨
˝σℓ1,ℓ2 ` σℓ2,ℓ1
2
´
˜ nÿ
j“1
`
ξj ` ?εηj
˘ σj,ℓ2 ` σℓ1,j
2
¸2˛
‚dη.
(2.132)
Inserting ξ “ 0 into (2.132) yields:
E
”
Yℓ1Yℓ2e´ 1
2 ε|Y |2ı
“
1
`?
2π
˘n
ż
Rn e´ 1
2 ε řn
j, k“1 ηjηkσj,ke´ 1
2 |η|2
¨
˝σℓ1,ℓ2 ` σℓ2,ℓ1
2
´ ε
˜ nÿ
j“1
ηj
σj,ℓ2 ` σℓ1,j
2
¸2˛
‚dη. (2.133)
First assume that ℓ1 “ ℓ2 “ ℓ. Then the left-hand side of (2.133) increases to
E rY 2
ℓs, and the right-hand side increases to
1
`?
2π
˘n
ż
Rn e´ 1
2 |η|2 dη σℓ,ℓ“ σℓ,ℓif ε
decreases to zero. Consequently, YℓP L2 pΩ, F, Pq and E rY 2
ℓs “ σℓ,ℓ, 1 ď ℓď n.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
78 
Renewal theory and Markov chains
It follows that Yℓbelongs to L1 pΩ, F, Pq, and that we also have that Yℓ1Yℓ2 P
L1 pΩ, F, Pq. By applying the same procedure as above we also obtain that
E rYℓ1Yℓ2s “ σℓ1,ℓ2 ` σℓ2,ℓ1
2
“ σℓ1,ℓ2.
(2.134)
In (2.134) we employed the symmetry of the matrix pσℓ1,ℓ2qn
ℓ1,ℓ2“1. Again we ﬁx
1 ď ℓď n, and we diﬀerentiate the equality in (2.131) with respect to ξℓto
obtain
iE
”
e´i⟨ξ,Y ⟩Yℓe´ 1
2 ε|Y |2ı
“
1
`?
2π
˘n
ż
Rn dη e´ 1
2
řn
j,k“1pξj`?εηjq `
ξk ` ?εηk
˘
e´ 1
2 |η|2
nÿ
j“1
`
ξj ` ?εηj
˘ σj,ℓ` σℓ,j
2
.
(2.135)
In (2.135) we set ξ “ 0, and we let ε Ó 0 to obtain E rYℓs “ 0, and hence XℓP
L1 pΩ, F, Pq and E rXℓs “ µℓ. This completes the proof of Theorem 2.56.
□
5. Radon-Nikodym Theorem
We begin by formulating a convenient version of Radon-Nikodym’s theorem.
For a proof the reader is referred to Bauer [10] or Stroock [130].
2.57. Theorem (Radon-Nikodym theorem). Let pΩ, F, µq be a σ-ﬁnite measure
space, and let ν be a ﬁnite measure on F. Suppose that ν is absolute continuous
relative to µ, i.e. µpBq “ 0 implies νpBq “ 0. Then there exists a function
f P L1 pΩ, F, µq such that νpBq “
ş
B f dµ for all B P F. In particular the
function f is F-measurable.
The following corollary follows from Theorem 2.57 by taking F “ B, µ the
measure P conﬁned to B, and νpBq “ E rX, Bs, B P B.
2.58. Corollary. Let pΩ, A, Pq be a probability space, and let B be a subﬁeld
(i.e. a sub-σ-ﬁeld) of A. Let X be a stochastic variable in L1 pΩ, A, Pq. Then
there exists a B-measurable variable Z on Ωwith the following properties:
(1) (qualitative property) the variable Z is B-measurable;
(2) (quantitative property) for every B P B the equality E rZ, Bs“E rX, Bs
holds.
The variable Z is called the conditional expectation of X, and is denoted by
Z “ E
“
X
ˇˇ B
‰
. The existence is guaranteed by the Radon-Nikodym theorem.
6. Some martingales
Let E be a locally compact Hausdorﬀspace which is second countable, and let
tpΩ, F, Pxq , pXptq, t ě 0q , pϑt, t ě 0q , pE, Equ
(2.136)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
79 
Renewal theory and Markov chains
be a time-homogeneous strong Markov process with right-continuous paths,
which also have left limits in the state space E on their life time. Put Sptqfpxq “
Ex rf pXptqqs, f P C0pEq, and assume that Sptqf P C0pEq whenever f P C0pEq.
Here a real or complex valued function f belongs to C0pEq provided that it is
continuous and that for every ε ą 0 the subset tx P E : |fpxq| ě εu is compact
in E. Let the operator L be the generator of this process. This means that
its domain DpLq consists of those functions f P C0pEq for which the limit
Lf “ lim
tÓ0
Sptqf ´ f
t
exists in C0pEq equipped with the supremum norm, i.e.
}f}8 “ supxPE |fpxq|, f P C0pEq. The Markov property of the process in (2.136)
together with the right continuity of paths implies that the family tSptq : t ě 0u
is a Feller, or, more properly, a Feller-Dynkin semigroup.
(1) The semigroup property can be expressed as follows:
S pt1 ` t2q “ S pt1q S pt2q ,
t1, t2 ě 0,
Sp0q “ I.
(2) Moreover, the right-continuity of paths implies
lim
tÓ0 Sptqfpxq “ lim
tÓ0 Ex rf pXptqqs “ Ex rf pXp0qqs “ fpxq,
f P C0pEq.
(3) In addition, if 0 ď f ď 1, then 0 ď Sptqf ď 1.
A semigroup with the properties (1), (2) and (3) is a called a Feller, or Feller-
Dynkin semigroup. In fact, it can be proved that a Feller-Dynkin semigroup
tSptq : t ě 0u satisﬁes
lim
sÑt, są0 }Spsqf ´ Sptqf}8 “ 0,
t ě 0,
f P C0pEq.
Let tSptq : t ě 0u be a Feller-Dynkin semigroup. Then it can be shown that
there a exists a Markov process, as in (2.136) with right-continuous paths such
that Sptqfpxq “ Ex rf pXptqqs, f P C0pEq, t ě 0. For details, see Blumenthal
and Getoor [20]. Similar results are true for states spaces which are Polish; see,
e.g., [146].
Let t ÞÑ Mptq, t ě 0, be an adapted right-continuous multiplicative process,
i.e. Mp0q “ 1 and MpsqMptq ˝ ϑs “ Mps ` tq, s, t ě 0. Put SMptqfpxq “
Ex rMptqf pXptqqs, f P C0pEq, t ě 0. Assume that the operators SMptq leave
the space C0pEq invariant, so that SMptqf belongs to C0pEq whenever f P
C0pEq. Then the family tSMptq : t ě 0u has the semigroup property SMps`tq “
SMpsqSMptq, s, t ě 0, and limtÓ0 SMptqfpxq “ fpxq, t ě 0, f P C0pEq. If, in ad-
dition, for every f P C0pEq there exists a δ ą 0 such that sup0ďtďδ }SMptqf}8 ă
8, then
lim
tÓ0 }SMptqf ´ f}8 “ 0,
f P C0pEq.
(2.137)
Moreover, there a exists a closed densely deﬁned linear operator LM such that
LMf “ C0pEq- lim
tÓ0
SMptqf ´ f
t
(2.138)
for f P D pLMq, the domain of LM. If Mptq “ 1, then LM “ L.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
80 
Renewal theory and Markov chains
2.59. Proposition. The following processes are Px-martingales:
t ÞÑ Mptqf pXptqq ´ Mp0qfpXp0qq ´
ż t
0
MpsqLMf pXpsq dsq ,
t ě 0, f P D pLMq ,
(2.139)
s ÞÑ MpsqEXpsq rMpt ´ sqf pXpt ´ sqqs , 0 ď s ď t, f P C0pEq,
(2.140)
s ÞÑ MpsqEXpsq rMpt ´ s ´ uqp pu, Xpt ´ s ´ uq, yqs , 0 ď s ď t ´ u.
(2.141)
In (2.141) it is assumed that there exists a “reference” measure m on the Borel
ﬁeld E together with an density function ppt, x, yq, pt, x, yq P p0, 8q ˆ E ˆ E
such that Ex rf pXptqqs “
ş
p pt, x, yq fpyq dmpyq for all f P C0pEq and for all
x P E and all t ą 0. From the semigroup property it follows that pps ` t, x, yq “
ş
pps, x, zqppt, z, yqdmpzq for m-almost all y P E. Assuming that mpOq ą 0
for all non-empty open subsets of E, and that the function pt, x, yq ÞÑ ppt, x, yq
is continuous on p0, 8q ˆ E ˆ E, it follows that the equality pps ` t, x, yq “
ş
pps, x, zqppt, z, yqdmpzq holds for s, t ą 0 and for all x, y P E.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
81 
Renewal theory and Markov chains
The following corollary is the same as Proposition 2.59 with M “ 1.
2.60. Corollary. The following processes are Px-martingales:
t ÞÑ f pXptqq ´ fpXp0qq ´
ż t
0
Lf pXpsq dsq ,
t ě 0,
f P D pLq ,
(2.142)
s ÞÑ EXpsq rf pXpt ´ sqqs , 0 ď s ď t, f P C0pEq,
(2.143)
s ÞÑ p pt ´ s, Xpsq, yq , 0 ď s ă t.
(2.144)
Like in Proposition 2.59 in (2.144) it is assumed that there exists a “reference”
strictly positive Borel measure m such that for a (unique) continuous density
function ppt, x, yq the identity Ex rf pXptqqs “
ş
p pt, x, yq fpyq dmpyq holds for
all f P C0pEq and for all x P E and all t ą 0.
2.61. Lemma. Let the continuous density be as in Proposition 2.59, and let
z P E. Then the following equality holds for all 0 ď s ă t and for all y P E:
Ez rp pt ´ s, Xpsq, yqs “ ppt, x, yq.
(2.145)
Proof of Lemma 2.61. Let the notation be as in Lemma 2.61. Then by
the identity of Chapman-Kolmogorov we have
Ez rp pt ´ s, Xpsq, yqs “
ż
p ps, z, wq ppt ´ s, w, yqdmpwq “ ppt, x, yq.
(2.146)
The equality in (2.146) is the same as the one in (2.145), which completes the
proof of Lemma 2.61.
□
Proof of Proposition 2.59. First let f belong to the domain of LM,
and let t2 ą t1 ě 0. Then we have
Ex
„
M pt2q f pX pt2qq ´ Mp0qf pXp0qq ´
ż t2
0
MpsqLMf pXpsqq ds
ˇˇ Ft1
ȷ
´ M pt1q f pX pt2qq ` Mp0qf pXp0qq `
ż t1
0
MpsqLMf pXpsqq ds
“ Ex
„
M pt1q
ˆ
M pt2 ´ t1q f pX pt2 ´ t1qq ´ Mp0qf pXp0qq
´
ż t2´t1
0
MpsqLMf pXpsqq ds
˙
˝ ϑt1
ˇˇ Ft1
ȷ
(Markov property)
“ M pt1q EXpt1q
„
M pt2 ´ t1q f pX pt2 ´ t1qq ´ Mp0qf pXp0qq
´
ż t2´t1
0
MpsqLMf pXpsqq ds
ȷ
(deﬁnition of the operator SMptq; put z “ X pt1q, and t “ t2 ´ t1)
“ M pt1q
ˆ
SM ptq fpzq ´ Ez rMp0qfpXp0qqs ´
ż t
0
SMpsqLMfpzq ds
˙
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
82 
Renewal theory and Markov chains
“ M pt1q
ˆ
SM ptq fpzq ´ Ez rMp0qf pXp0qqs ´
ż t
0
B
BsSMpsqfpzq ds
˙
“ M pt1q pSM ptq fpzq ´ Ez rMp0qf pXp0qqs ´ SMptqfpzq ` SMp0qfpzqq “ 0.
(2.147)
The equalities in (2.147) show the equality in (2.139).
Let f P C0pEq and t ą 0. In order to show that the process
s ÞÑ MpsqEXpsq rMpt ´ sqf pXpt ´ sqqs
is a Px-martingale we proceed as follows:
MpsqEXpsq rMpt ´ sqf pXpt ´ sqqs
(Markov property)
“ MpsqEx
“
Mpt ´ sq ˝ ϑsf pXpt ´ sqq ˝ ϑs
ˇˇ Fs
‰
“ Ex
“
MpsqMpt ´ sq ˝ ϑsf pXptqq
ˇˇ Fs
‰
“ Ex
“
Mptqf pXptqq
ˇˇ Fs
‰
.
(2.148)
It is clear that the process in (2.148) is a martingale. This proves that the
process in (2.140) is a martingale. A similar argument shows the equality:
MpsqEXpsq rMpt ´ s ´ uqp pu, Xpt ´ s ´ uq, yqs
“ Ex
“
Mpt ´ uqp pu, Xpt ´ uq, yq
ˇˇ Fs
‰
, 0 ď s ă t ´ u.
(2.149)
Again it is clear that the process in (2.149) as a function of s is a Px-martingale.
Altogether this proves Proposition 2.59.
□
Proof of Corollary 2.60. The fact that the processes in (2.142) and
(2.143) are Px-martingales is an immediate consequence of (2.139) and (2.140)
respectively by inserting Mpρq “ 1 for all 0 ď ρ ď t. If Mpρq “ 1 for all
0 ă ρ ă t, then by Lemma 2.61 we get
MpsqEXpsq rMpt ´ s ´ uqp pu, Xpt ´ s ´ uq, yqs
“ EXpsq rp pu, Xpt ´ s ´ uq, yqs “ p pt ´ s, Xpsq, yq .
(2.150)
On the other hand by the Markov property we also have:
EXpsq rp pu, Xpt ´ s ´ uq, yqs “ Ex
“
p pu, Xpt ´ uq, yq
ˇˇ Fs
‰
.
(2.151)
As a consequence of (2.150) and (2.151) we see that the process in (2.144) is a
martingale. This completes the proof of Corollary 2.60.
□
2.62. Remark. In general the process s ÞÑ p pt ´ s, Xpsq, yq, 0 ď s ă t, is not a
closed martingale. In many concrete examples we have lim
sÒt,săt p pt ´ s, Xpsq, yq “
0, Px-almost surely, on the one hand, and Ex rp pt ´ s, Xpsq, yqs “ p pt, x, yq ą
0 on the other.
For an example of this situation take d-dimensional Brow-
nian motion.
By Scheﬀ´e’s theorem it follows that the Px-martingale s ÞÑ
p pt ´ s, Xpsq, yq, 0 ď s ă t, can not be a closed martingale. If it were, then
there would exist an Ft-measurable variable Fptq “ limsÒ,săt p pt ´ s, Xpsq, yq
with the property that p pt ´ s, Xpsq, yq “ Ex
“
Fptq
ˇˇ Fs
‰
. Since Fptq “ 0, Px-
almost surely, this is a contradiction.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
83 
Renewal theory and Markov chains
In the following corollary we consider a special multiplicative process: Mpsq “
1tTąsu, where T is a terminal stopping time, i.e. T “ s ` T ˝ ϑs, Px-almost
surely, on the event tT ą su for all s ą 0 and for all x P E.
2.63. Corollary. The following processes are Px-martingales:
t ÞÑ 1tTątuf pXptqq ´ 1tTą0ufpXp0qq ´
ż t^T
0
LMf pXpsq dsq ,
t ě 0,
f P D pLMq ,
(2.152)
s ÞÑ 1tTąsuEXpsq rf pXpt ´ sqq , T ą t ´ ss , 0 ď s ď t, f P C0pEq,
(2.153)
s ÞÑ 1tTąsu
`
p pt ´ s, Xpsq, yq ´ EXpsq rp pt ´ s ´ T, XpTq, yq , T ă t ´ ss
˘
,
0 ď s ă t.
(2.154)
In (2.141) it is assumed that there exists a “reference” measure m on the Borel
ﬁeld E together with an density function ppt, x, yq, pt, x, yq P p0, 8qˆE ˆE such
that Ex rf pXptqqs “
ş
p pt, x, yq fpyq dmpyq for all f P C0pEq and for all x P E
and all t ą 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
84 
Renewal theory and Markov chains
It is noticed that the deﬁnition of LMfpxq is only deﬁned pointwise, and that
for certain points x P E the limit
LMfpxq:“ lim
tÓ0
Ex rMptqf pXptqqs ´ Ex rMp0qf pXp0qqs
t
does not even exist.
A good example is obtained by taking for T the exit
time from an open subset U: T “ τU “ inf ts ą 0 : Xpsq P EzUu.
If the
lim
tÓ0
Px rT ď ts
t
“ 0 for all x P U, then LMfpxq “ Lfpxq for x P U.
Proof of Corollary 2.63. It is only (2.154) which needs some explana-
tion; the others are direct consequences of Proposition 2.59. To this end we ﬁx
0 ă u ă t. Then by (2.141) the process:
s ÞÑ 1tTąsuEXpsq rp pu, Xpt ´ s ´ uq, yq , T ą t ´ s ´ us
is a martingale on the closed interval r0, t ´ us. Next we rewrite
EXpsq rp pu, Xpt ´ s ´ uq, yq , T ą t ´ s ´ us
“ EXpsq rp pu, Xpt ´ s ´ uq, yqs ´ EXpsq rp pu, Xpt ´ s ´ uq, yq , T ď t ´ s ´ us
(2.155)
(the process ρ ÞÑ p pt ´ s ´ ρ, Xpρq, yq is Pz-martingale with z “ Xpsq; put
u “ t ´ s in the ﬁrst term, and u “ t ´ s ´ T in the second term of the
right-hand side of (2.155))
“ EXpsq rp pt ´ s, Xp0q, yqs ´ EXpsq rp pt ´ s ´ T, XpTq, yq , T ď t ´ s ´ us .
(2.156)
By letting u Ó 0 in (2.156) and using (2.141) of Proposition 2.59 we obtain that
the process in (2.154) is a Px-martingale. This completes the proof of Corollary
2.63.
□
Next let
␣
pΩ, F, Pxq , pBptq, t ě 0q , pϑt, t ě 0q ,
`
Rd, BRd
˘(
be the Markov process of Brownian motion. Another application of martingale
theory is the following example. Let U be an open subset of Rd with smooth
enough boundary BU (C1 will do), and let f : BU Ñ R be a bounded continuous
function on the boundary BU of U. Let u : U Ñ R be a continuous function
such that upxq “ fpxq for x P BU and such that ∆upxq “ 0 for x P U. Let τU
be the ﬁrst exit time from U: τU “ inf
␣
s ą 0 : Bpsq P RdzU
(
. Then
upxq “ Ex rf pB pτUqq : τU ă 8s ` lim
tÑ8 Ex ru pB ptqq : τU “ 8s .
(2.157)
Notice that the ﬁrst expression in (2.157) makes sense, because it can be proved
that Brownian motion is Px-almost surely continuous for x P Rd. The proof
uses the following facts: stopped martingales are again martingales, and the
processes
t ÞÑ f pBptqq ´ f pBp0qq ´ 1
2
ż t
0
∆f pBpsqq ds,
f P Cb
`
Rd˘
, ∆f P Cb
`
Rd˘
,
(2.158)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
85 
Renewal theory and Markov chains
are martingales. The fact that a process of the form (2.158) is a martingale
follows from (2.142) in Corollary 2.60. It can also be proved using the equality
B
Btpd pt, x, yq “ 1
2∆ypd pt, x, yq
(2.159)
where
pd pt, x, yq “
1
b
p2πtqde´ |x´y|2
2t .
A proof of (2.158) runs as follows. Pick t2 ą t1 ě 0 en a function f P Cb
`
Rd˘
,
such that ∆f also belongs to Cb
`
Rd˘
. Then we have:
Ex
„
f pB pt2qq ´ f pB p0qq ´ 1
2
ż t2
0
∆f pBpsqq ds
ˇˇ Ft1
ȷ
´ f pB pt1qq ` f pB p0qq ` 1
2
ż t1
0
∆f pBpsqq ds
“ Ex
„ˆ
f pB pt2 ´ t1qq ´ f pB p0qq ´ 1
2
ż t2´t1
0
∆f pBpsqq ds
˙
˝ ϑt1
ˇˇ Ft1
ȷ
(Markov property of Brownian motion)
“ EBpt1q
„
f pB pt2 ´ t1qq ´ f pB p0qq ´ 1
2
ż t2´t1
0
∆f pBpsqq ds
ȷ
(put z “ B pt1q, and t “ t2 ´ t1)
“ Ez rf pBptqqs ´ Ez rf pBp0qqs ´ 1
2
ż t
0
Ez r∆f pBpsqqs ds
“ Ez rf pBptqqs ´ Ez rf pBp0qqs ´ 1
2
ż t
0
ż
Rd pd ps, z, yq ∆f pyq dy ds
“ Ez rf pBptqqs ´ Ez rf pBp0qqs ´ lim
εÓ0
1
2
ż t
ε
ż
Rd pd ps, z, yq ∆f pyq dy
(integration by parts)
“ Ez rf pBptqqs ´ Ez rf pBp0qqs ´ lim
εÓ0
ż t
ε
ż
Rd
1
2∆ypd ps, z, yq f pyq dy ds
(use the equality in (2.159))
“ Ez rf pBptqqs ´ Ez rf pBp0qqs ´ lim
εÓ0
ż t
ε
ż
Rd
B
Bspd ps, z, yq f pyq dy ds
(interchange integration and diﬀerentiation)
“ Ez rf pBptqqs ´ Ez rf pBp0qqs ´ lim
εÓ0
ż t
ε
B
Bs
ż
Rd pd ps, z, yq f pyq dy ds
(fundamental rule of calculus)
“ Ez rf pBptqqs ´ Ez rf pBp0qqs
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
86 
Renewal theory and Markov chains
´ lim
εÓ0
ˆż
Rd pd pt, z, yq f pyq dy ´
ż
Rd pd pε, z, yq f pyq dy
˙
“ Ez rf pBptqqs ´ Ez rf pBp0qqs ´ Ez rf pBptqqs ` lim
εÓ0 Ez rf pBpεqqs
“ lim
εÓ0 Ez rf pBpεqqs ´ Ez rf pBp0qqs “ 0.
(2.160)
From Doob’s optional sampling theorem it follows that processes of the form
t ÞÑ f pB pτU ^ tqq ´ f pBp0qq ´ 1
2
ż τU^t
0
∆f pBpsqq ds,
f P Cb
`
Rd˘
, (2.161)
f P Cb
`
Rd˘
, ∆f P Cb
`
Rd˘
, are Px-martingales for x P U. We can apply this
property to our harmonic function u. It follows that the process
t ÞÑ u pB pτU ^ tqq´u pBp0qq´ 1
2
ż τU^t
0
∆u pBpsqq ds “ u pB pτU ^ tqq´u pBp0qq
(2.162)
is a martingale. Consequently, from (2.162) we get
upxq “ u pBp0qq “ Ex ru pB pτU ^ tqqs
“ Ex ru pB pτU ^ tqq , τU ď ts ` Ex ru pB pτU ^ tqq , τU ą ts
“ Ex ru pB pτUqq , τU ď ts ` Ex ru pBptqq , τU ą ts
(2.163)
In (2.163) we let t Ñ 8 to obtain the equality in (2.157).
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
87 
Renewal theory and Markov chains
2.64. Proposition. Let t ÞÑ M1ptq and t ÞÑ M2ptq be two continuous martin-
gales in L2 pΩ, F, Pq with covariation process t ÞÑ ⟨M1, M2⟩ptq, so that in partic-
ular the process t ÞÑ M1ptqM2ptq ´ ⟨M1, M2⟩ptq is a martingale in L1 pΩ, F, Pq.
Then the process
t ÞÑ pM1ptq ´ M1psqq pM2ptq ´ M2psqq ´ ⟨M1, M2⟩ptq ` ⟨M1, M2⟩psq,
t ě s,
(2.164)
is a martingale.
In fact by Itˆo calculus we have the following integration by parts formula:
pM1ptq ´ M1psqq pM2ptq ´ M2psqq
“
ż t
s
pM1pρq ´ M1psqq dM2pρq `
ż t
s
pM2pρq ´ M2psqq dM1pρq
` ⟨M1, M2⟩ptq ´ ⟨M1, M2⟩psq,
t ě s.
(2.165)
Proof of Proposition 2.64. Fix t2 ą t1 ě s. Then we calculate:
E
“
pM1 pt2q ´ M1 psqq
`
M2 pt2q ´ M2 psq
ˇˇ Ft1
˘‰
´ E
“
⟨M1, M2⟩pt2q ´ ⟨M1, M2⟩psq
ˇˇ Ft1
‰
´ pM1 pt1q ´ M1 psqq pM2 pt1q ´ M2 psqq ` ⟨M1, M2⟩pt1q ´ ⟨M1, M2⟩psq
“ E
“
pM1 pt2q ´ M1 psqq pM2 pt2q ´ M2 psqq
ˇˇ Ft1
‰
´ E
“
⟨M1, M2⟩pt2q ´ ⟨M1, M2⟩pt1q
ˇˇ Ft1
‰
´ pM1 pt1q ´ M1 psqq pM2 pt1q ´ M2 psqq
“ E rpM1 pt2q ´ M1 pt1q ` M1 pt1q ´ M1 psqq
pM2 pt2q ´ M2 pt1q ` M2 pt1q ´ M2 psqq
´ ⟨M1, M2⟩pt2q ` ⟨M1, M2⟩pt1q
ˇˇ Ft1
‰
´ pM1 pt1q ´ M1 psqq pM2 pt1q ´ M2 psqq
“ E
“
pM1 pt2q ´ M1 pt1qq pM2 pt2q ´ M2 pt1qq
ˇˇ Ft1
‰
´ E
“
⟨M1, M2⟩pt2q ` ⟨M1, M2⟩pt1q
ˇˇ Ft1
‰
` E
“
pM1 pt1q ´ M1 psqq pM2 pt2q ´ M2 pt1qq
ˇˇ Ft1
‰
` E
“
pM1 pt2q ´ M1 pt1qq pM2 pt1q ´ M2 psqq
ˇˇ Ft1
‰
` E
“
pM1 pt1q ´ M1 psqq pM2 pt1q ´ M2 psqq
ˇˇ Ft1
‰
´ pM1 pt1q ´ M1 psqq pM2 pt1q ´ M2 psqq
“ E
“
M1 pt2q M2 pt2q ´ ⟨M1, M2⟩pt2q ` ⟨M1, M2⟩pt1q ´ M1 pt1q M2 pt1q
ˇˇ Ft1
‰
´ E
“
M1 psq pM2 pt2q ´ M2 pt1qq
ˇˇ Ft1
‰
´ E
“
pM1 pt2q ´ M1 pt1qq M2 psq
ˇˇ Ft1
‰
` E
“
pM1 pt1q ´ M1 psqq pM2 pt1q ´ M2 psqq
ˇˇ Ft1
‰
´ pM1 pt1q ´ M1 psqq pM2 pt1q ´ M2 psqq “ 0.
(2.166)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
88 
Renewal theory and Markov chains
In the ﬁnal step of (2.166) we employed the martingale property of the following
processes:
t ÞÑ M1ptqM2ptq ´ ⟨M1, M2⟩ptq, t ÞÑ M1ptq,
and t ÞÑ M2ptq.
This completes the proof of Proposition 2.64.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
89 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
CHAPTER 3
An introduction to stochastic processes: Brownian
motion, Gaussian processes and martingales
In this chapter of the book we will study several aspects of Brownian motion:
Brownian motion as a Gaussian process, Brownian motion as a Markov process,
Brownian motion as a martingale. It also includes a discussion on stochastic
integrals and Itˆo’s formula.
1. Gaussian processes
We begin with an important extension theorem of Kolmogorov, which enables
us to construct stochastic processes like Gaussian processes, L´evy processes,
Poisson processes and others. It is also useful for the construction of Markov
processes. In Theorem 3.1 the symbol ΩJ, J Ď I, stands for the product space
ΩJ “ ś
jPJ Ωj endowed with the product σ-ﬁeld FJ. By saying that the system
tpΩJ, FJ, PJq : J Ď I, J ﬁniteu is a projective system (or a consistent system,
or a cylindrical measure) we mean that
PJ1
“
pJ1
J2 P A
‰
“ PJ1
”`
pJ1
J2
˘´1 pAq
ı
“ PJ2 rAs ,
where A P FJ2, and where J2 Ď J1 Ď I, J1 ﬁnite. The mapping pJ1
J2, J2 Ď J1, is
deﬁned by pJ1
J2 pωjqjPJ1 “ pωjqjPJ2. In practice this means that in order to prove
that the system tpΩJ, FJ, PJq : J Ď I,
J
ﬁniteu is a projective system indeed,
we have to show an equality of the form (j0 R J):
PJYtj0u rB ˆ Ωj0s “ PJ rBs ,
B P FJ.
The following proposition says that under certain conditions a cylindrical mea-
sure in fact is a genuine measure.
3.1. Theorem (Extension theorem of Kolmogorov). Let
tpΩJ, FJ, PJq : J Ď I, J ﬁniteu
be a projective system of probability spaces (or distributions). Suppose that each
Ωi is a metrizable and σ-compact Hausdorﬀspace endowed with its Borel ﬁeld
Ai. Then there exists a unique probability measure PI on pΩI, AIq, such that
PI rpJ P As “ PI
`
p´1
J pAq
˘
“ PJpAq
(3.1)
for every J Ď I, J ﬁnite, and for every A P AJ.
For an extensive discussion on Kolmogorov’s extension theorem see, e.g., the
Probability Theory lecture notes of B. Driver [40]. These lecture notes include
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
90 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
a discussion on standard Borel spaces and on Polish spaces. The Kolmogorov’s
extension theorem is also valid if the spaces Ωi are Polish spaces, or Souslin
spaces which are continuous images of Polish spaces. For more details see Ap-
pendix 17.6 in [40]. The reader may also consult [21] or [137]. In Theorem
7.4.3 of [21] the author shows that ﬁnite positive measures on Souslin spaces
are regular and concentrated on σ-compact subsets. Bogachev’s book contains
lots of information on Souslin spaces. In fact much material which is presented
in this book, can also be found in the lecture notes by Bruce Driver. A proof of
Kolmogorov’s extension theorem is supplied in Section 4 of Chapter 5: see (the
proof of) Theorem 5.81.
Next we recall Bochner’s theorem.
3.2. Theorem. (Bochner) Let φ : Rn Ñ C be a continuous complex function,
that is positive deﬁnite in the sense that for all r P N
rÿ
k,ℓ“1
λkλℓφ
`
ξk ´ ξℓ˘
ě 0,
(3.2)
for all λ1, . . . , λr P C and for all ξ1, . . . , ξr P Rn. Then there exists a unique
non-negative Borel measure µ on Rn such that its Fourier transform
ż
expp´i ⟨ξ, x⟩qdµpxq
is equal to φpξq for ξ P Rn. In particular µpRnq “ φp0q.
3.3. Example. Let, for every i P I, Pi, i P I, be a probability measures on Ωi
and deﬁne PJ on ΩJ, J Ď I, J ﬁnite, by PJpAq “ Pj1 b¨ ¨ ¨bPjnpAq, where A be-
longs to AJ and where J “ pj1, . . . , jnq. Then the family tPJ : J Ă I, J ﬁniteu
is a consistent system or cylindrical measure.
3.4. Example. Let σ : I ˆ I Ñ R be a symmetric (i.e. σpi, jq “ σpj, iq for all i,
j in I) function such that for every ﬁnite subset J “ pj1, . . . , jnq of I the matrix
pσpi, jqqi,jPJ is positive-deﬁnite in the sense that
ÿ
i,jPJ
σpi, jqξiξj ě 0,
(3.3)
for all ξj1, . . . , ξjn P R. In the non-degenerate case we shall assume that the
inequality in (3.3) is strict whenever the vector pξj1, . . . , ξjnq is non-zero. De-
ﬁne the process pi, ωq ÞÑ Xipωq by Xipωq “ ωi, where ω P ΩI “ RI is given
by ω “ pωiqiPI. Let µ “ pµiq P RI be a map from I to R. There exists a
unique probability measure P on the σ-ﬁeld on ΩI generated by pXiqiPI with the
following property:
E
˜
exp
˜
´i
ÿ
jPJ
ξjXj
¸¸
“ exp
˜
´i
ÿ
jPJ
ξjµj
¸
exp
˜
´1
2
ÿ
i,jPJ
σpi, jqξiξj
¸
. (3.4)
This measure possesses the following additional properties:
E pXjq “ µj,
j P I,
and cov pXi, Xjq “ σpi, jq,
i, j P I.
(3.5)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
91 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Notice that
nÿ
u,v“1
ξuξvcov pXju, Xjvq ě 0 whenever ξ1, . . . , ξn belong to R. For
a proof of this result we shall employ both Bochner’s theorem as well as Kol-
mogorov’s extension theorem. Therefore let J “ pj1, . . . , jnq be a ﬁnite subset
of I, let λk, 1 ď k ď r, be complex numbers and let ξk, 1 ď k ď r, be vectors in
Rn ” RJ. Put λ1
k “ λk exp
`
i řn
u“1 ξk
juµk
ju
˘
and let U be an orthogonal matrix
with the property that the matrix pUσU ´1pu, vqqn
u,v“1 has the diagonal form
`
UσU ´1pu, vq
˘
“
¨
˚
˚
˝
s2
1
0
. . .
0
0
s2
2
. . .
0
...
...
...
...
0
0
0
s2
n
˛
‹‹‚.
We also write
`
ηℓ
1, . . . , ηℓ
n
˘
“ U
¨
˚
˝
ξℓ
j1...
ξℓ
jn
˛
‹‚.
We may and do suppose that the eigenvalues s1, . . . , sm, m ď n, are non-zero
and the others (if any) are 0. Then we get
rÿ
k,ℓ“1
λkλℓexp
˜
´1
2
nÿ
u,v“1
σpju, jvq
`
ξℓ
ju ´ ξk
ju
˘ `
ξℓ
jv ´ ξk
jv
˘
¸
ˆ exp
˜
´i
nÿ
u“1
`
ξℓ
ju ´ ξk
ju
˘
µju
¸
“
rÿ
k,ℓ“1
λ1
kλ1
ℓexp
˜
´1
2
nÿ
u,v“1
`
UσU ´1˘
pu, vq
`
ηℓ
u ´ ηk
u
˘ `
ηℓ
v ´ ηk
v
˘
¸
“
rÿ
k,ℓ“1
λ1
kλ1
ℓexp
˜
´1
2
nÿ
u“1
s2
u
`
ηℓ
u ´ ηk
u
˘2
¸
“
rÿ
k,ℓ“1
λ1
kλ1
ℓexp
˜
´1
2
m
ÿ
u“1
s2
u
`
ηℓ
u ´ ηk
u
˘2
¸
“
rÿ
k,ℓ“1
λ1
kλ1
ℓ
1
p
?
2πqm
1
śm
u“1 su
ż
. . .
ż
dx1 . . . dxm
exp
˜
´i
m
ÿ
u“1
`
ηℓ
u ´ ηk
u
˘
xu
¸
exp
˜
´1
2
m
ÿ
u“1
x2
u
s2
u
¸
“
1
p
?
2πqm
1
śm
u“1 su
ż
. . .
ż
dx1 . . . dxm
ˇˇˇˇˇ
rÿ
k“1
λ1
k exp
˜
i
m
ÿ
u“1
ηℓ
uxu
¸ˇˇˇˇˇ
2
exp
˜
´1
2
m
ÿ
u“1
x2
u
s2
u
¸
ě 0.
(3.6)
From Bochner’s Theorem 3.2 it follows that there exists a probability measure
ΠJ on RJ such that, for all ξ P Rn,
ż
RJ exp
˜
´i
nÿ
u“1
ξuxu
¸
dΠJ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
92 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
“ exp
˜
´i
nÿ
u“1
ξuµu
¸
exp
˜
´1
2
nÿ
u,v“1
σpju, jvqξuξv
¸
.
(3.7)
Deﬁne the probability measure PJ on ΩJ “ ś
jPJ Ωj by
PJ ppXj1, . . . , Xjnq P Bq “ ΠJpBq,
where B is a Borel subset of RJ. The collection pΩJ, AJ, PJq is a projective
system, because let J1 :“ tj0uYJ be a subset of I, which is of size 1` size J “
1 ` n and let B be a Borel subset of RJ. The Fourier transform of the measure
B ÞÑ ΠJ1 rR ˆ Bs is given by the function:
pξj1, . . . , ξjnq ÞÑ
ż
RJ exp
˜
´i
ÿ
jPJ
ξjxj
¸
ΠJ1 rR ˆ dxs
“
ż
RJ
ż
R
exp
˜
´i
ÿ
jPJ1
ξjxj
¸
ΠJ1 rdy ˆ dxs
“ exp
˜
´i
ÿ
jPJ1
ξjµj
¸
exp
˜
´1
2
ÿ
i,jPJ1
σpi, jqξiξj
¸
“ exp
˜
´i
ÿ
jPJ
ξjµj
¸
exp
˜
´1
2
ÿ
i,jPJ
σpi, jqξiξj
¸
“
ż
RJ e´i ř
jPJ ξjxj ΠJpdxq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
93 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In the previous formula we used the equality ξj0 “ 0 several times: J1 “ J Ytj0u.
It follows that ΠJ rBs “ ΠJ1 rR ˆ Bs. An application of the extension theorem
of Kolmogorov yields the desired result in Example 3.4.
Suppose that the matrix pσpju, jvqqn
u,v“1 be non-degenerate (i.e. suppose that
its determinant is non-zero) and let pαpu, vqqn
u,v“1 be its inverse. Then
P ppXj1, . . . , Xjnq P Bq
(3.8)
“ pdet αq1{2
p2πqn{2
ż
. . .
ż
dx1 . . . dxn1Bpx1, . . . , xnq
exp
˜
´1
2
nÿ
u,v“1
αpu, vq pxu ´ µuq pxv ´ µvq
¸
.
Equality (3.8) can be proved by showing that the Fourier transforms of both
measures in (3.8) coincide. In the following propositions (Propositions 3.5 and
3.6) we mention some elementary facts on Gaussian vectors. Gaussian vectors
are multivariate normally distributed random vectors.
3.5. Proposition. Let pΩ, F, Pq be a probability space and let Xi : ΩÞÑ Rni,
i “ 1, 2, be random vectors with the property that the random vector Xpωq :“
pX1pωq, X2pωqq is Gaussian in the sense that (n “ n1 ` n2)
E
˜
exp
˜
´i
nÿ
k“1
ξkXk
¸¸
“ exp
˜
´i
nÿ
k“1
ξkµk ´ 1
2
nÿ
k,ℓ“1
σpk, ℓqξkξℓ
¸
,
(3.9)
where the matrix σpk, ℓqn
k,ℓ“1 is positive deﬁnite and where pµ1, . . . , µnq is a vec-
tor in Rn. The vectors X1 and X2 are P-independent if and only if they are
uncorrelated in the sense that
E
`
X1
i X2
j
˘
“ E
`
X1
i
˘
E
`
X2
j
˘
(3.10)
for all 1 ď i ď n1 and for all 1 ď j ď n2.
Proof. The necessity is clear. For the suﬃciency we proceed as follows.
Put
`
X1, X2˘
“ pX1, . . . , Xn1, Xn1`1, . . . , Xn1`n2q .
Since the vectors X1 and X2 are uncorrelated (see (3.10)), it follows that
nÿ
k,ℓ“1
σpk, ℓqξkξℓ“
n1
ÿ
k,ℓ“1
σpk, ℓqξkξℓ`
nÿ
k,ℓ“n1`1
σpk, ℓqξkξℓ.
(3.11)
From (3.9) it follows that
E
˜
exp
˜
´i
nÿ
k“1
ξkXk
¸¸
“ E
˜
exp
˜
´i
n1
ÿ
k“1
ξkXk
¸¸
E
˜
exp
˜
´i
n1`n2
ÿ
k“n1`1
ξkXk
¸¸
(3.12)
and hence that the random vectors X1 and X2 are independent.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
94 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.6. Proposition. Let pΩ, F, Pq be a probability space.
(a) Let Q : Rm Ñ Rn be a linear map. If X : ΩÑ Rm is a Gaussian
vector, then so is QX.
(b) A random vector X : ΩÑ Rn is Gaussian if and only if for every
ξ P Rn the random variable ω ÞÑ ⟨ξ, Xpωq⟩is Gaussian.
Proof. (a) A random vector X is Gaussian if and only if the Fourier trans-
form of the measure B ÞÑ P pX P Bq is of the form
ξ ÞÑ exp
ˆ
´i ⟨ξ, µ⟩´ 1
2 ⟨σξ, ξ⟩
˙
.
By a standard result on image measures the Fourier transform of the measure
B ÞÑ P pQX P Bq, where X : ΩÑ Rn is Gaussian and where B is a Borel subset
of Rm, is given by
ξ ÞÑ E rexp p´i ⟨ξ, QX⟩qs “ E rexp p´i ⟨Q˚ξ, X⟩qs
“ exp p´i ⟨Q˚ξ, µ⟩q exp
ˆ
´1
2 ⟨σQ˚ξ, Q˚ξ⟩
˙
.
(3.13)
This proves (a). It also proves that the dispersion matrix of QX is given by
QσQ˚.
(b) For the necessity we apply (a) with the linear map Qx :“ ⟨ξ, x⟩, x P Rn,
where ξ P Rn is ﬁxed. For the suﬃciency we again ﬁx ξ P Rn. Since Y :“ ⟨ξ, X⟩
is a Gaussian variable we have
E pexp p´i ⟨ξ, X⟩qq “ E pexp p´iY qq
“ exp p´iEpY qq exp
ˆ
´1
2E pY ´ EpY qq2
˙
“ exp p´i ⟨ξ, µ⟩q exp
ˆ
´1
2 ⟨σξ, ξ⟩
˙
,
(3.14)
where µ “ EpXq and where
σpk, ℓq “ cov pXk, Xℓq “ E pXk ´ EpXkqq pXℓ´ E pXℓqq .
This completes the proof of (b).
□
3.7. Theorem. Let σ : I ˆI Ñ R be a positive-deﬁnite function and let µ : I Ñ
R be a map. There exists a probability space pΩ, F, Pq together with a Gaussian
process pt, ωq ÞÑ Xtpωq “ Xpt, ωq, t P I, ω P Ω, such that EpXtq “ µt and such
that covpXs, Xtq “ σps, tq for all s, t P I.
Proof. The proof is essentially given in Example 3.4.
□
We conclude this section with the introduction of Brownian motion and Brow-
nian bridge as Gaussian processes. First we show that the function σ : r0, 8q ˆ
r0, 8q Ñ R, deﬁned by σpu, vq “ minpu, vq, u, v P r0, 8q, and, for t ě 0 ﬁxed,
the function σt : r0, ts ˆ r0, ts Ñ R, deﬁned by σtpu, vq “ t minpu, vq ´ uv, u,
v P r0, ts, are positive deﬁnite.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
95 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.8. Proposition. The functions σpu, vq “ minpu, vq, u, v P r0, 8q, σtpu, vq “
t minpu, vq ´ uv, u, v P r0, ts, and σRpu, vq “ 1
2 exp p´ |u ´ v|q, u, v P R, are
positive deﬁnite. In addition, the function σ0pu, vq deﬁned by
σ0pu, vq “ 1
2 exp
`
´pu ` vq
˘
pexp p2 minpu, vqq ´ 1q, u, v ě 0,
is positive deﬁnite.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
96 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Let 0 “ s0 ă s1 ă s2 ă s3 ă ¨ ¨ ¨ ă sn ă t and let λ1, . . . , λn be
complex numbers. The following identities are valid:
nÿ
j“1
ˇˇˇˇˇ
nÿ
k“j
λkpt ´ skq
ˇˇˇˇˇ
2
tpsj ´ sj´1q
pt ´ sjqpt ´ sj´1q
“
nÿ
j“1
nÿ
k1“j
nÿ
k2“j
λk1λk2 pt ´ sk1q pt ´ sk2q
"
sj
t ´ sj
´
sj´1
t ´ sj´1
*
“
nÿ
k1“1
nÿ
k2“1
minpk1,k2q
ÿ
j“1
λk1λk2
"
sj
t ´ sj
´
sj´1
t ´ sj´1
*
pt ´ sk1q pt ´ sk2q
“
nÿ
k1“1
nÿ
k2“1
λk1λk2
sminpk1,k2q
t ´ sminpk1,k2q
pt ´ sk1q pt ´ sk2q
“
nÿ
k1“1
nÿ
k2“1
λk1λk2sminpk1,k2q
`
t ´ smaxpk1,k2q
˘
“
nÿ
k1,k2“1
λk1λk2σt psk1, sk2q
(3.15)
and hence the function σt is positive deﬁnite. Since
nÿ
j,k“1
λjλkt minpsj, skq “
nÿ
j,k“1
λjλkσtpsj, skq `
ˇˇˇˇˇ
nÿ
j“1
λjsj
ˇˇˇˇˇ
2
,
it follows that the function σ is positive deﬁnite as well.
In order to prove that the function σR is positive deﬁnite we ﬁrst notice that
the Fourier transform of the function t ÞÑ exp p´ |t|q is given by
ż 8
´8
e´iξte´|t|dt “ 2
ż 8
0
cos pξtq e´tdt
“ 2Re
ż 8
0
e´tp1´iξqdt “ 2Re
1
1 ´ iξ “
2
1 ` ξ2.
(3.16)
Hence upon taking the inverse Fourier transform we obtain:
1
2e´|t´s| “ 1
2π
ż 8
´8
exp piξpt ´ sqq
ξ2 ` 1
dξ.
(3.17)
Let λ1, . . . , λn be complex numbers and let s1, . . . , sn be real numbers. From
(3.16) and (3.17) it follows that
nÿ
k,ℓ“1
λkλℓ
1
2 exp p´ |sk ´ sℓ|q “ 1
2π
ż 8
´8
1
ξ2 ` 1
ˇˇˇˇˇ
nÿ
k“1
λk exp piξskq
ˇˇˇˇˇ
2
dξ.
(3.18)
An easier way to establish the positive-deﬁniteness of σRpu, vq is the following.
For λ1, . . . , λn in C and for real numbers s1, . . . , sn we write
nÿ
k,ℓ“1
λkλℓexp p´ |sk ´ sℓ|q
“
nÿ
k,ℓ“1
λkλℓmin
`
exp
`
´psk ´ sℓq
˘
, exp
`
´psℓ´ skq
˘˘
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
97 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
“
nÿ
k,ℓ“1
expp´skqλk expp´sℓqλℓmin
`
exp
`
2sk
˘
, exp
`
2sℓ
˘˘
“
ż 8
0
ˇˇˇˇˇ
nÿ
k“1
exp p´skq λk1r0,expp2skqspξq
ˇˇˇˇˇ
2
dξ ě 0.
A similar argument can be used to prove that the function σ0pu, vq is positive
deﬁnite.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Advanced stochastic processes: Part I
98 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We now give existence theorems for the Wiener process (or Brownian motion),
for Brownian bridge and for the oscillator process.
3.9. Theorem. The following assertions are true.
(a) There exists a probability space pΩ, F, Pq together with a real-valued
Gaussian process tbpsq : s ě 0u, called Wiener process or Brownian mo-
tion, such that Epbpsqq “ 0 and such that E pbps1qbps2qq “ minps1, s2q
for all s1, s2 ě 0.
(b) Fix t ą 0. There exists a probability space pΩ, F, Pq together with a real-
valued Gaussian process tXtpsq : t ě s ě 0u, called Brownian bridge,
such that EpXtpsqq “ 0 and such that
E pXtps1qXtps2qq “ minps1, s2q ´ s1s2
t
for all s1, s2 P r0, ts.
(c) There exists a probability space pΩ, F, Pq together with a real-valued
Gaussian process tqpsq : s P Ru, called oscillator process, which is cen-
tered, i.e. Epqpsqq “ 0 and which is such that
E pqps1qqps2qq “ 1
2 exp p´ |s1 ´ s2|q
for all s1, s2 P R.
(d) There exists a probability space pΩ, F, Pq together with a real-valued
Gaussian process tXpsq : s ě 0u, called Ornstein-Uhlenbeck process,
such that EpXpsqq “ 0 and such that
E pXps1qXps2qq “ 1
2 exp
`
´ps1 ` s2q
˘ `
exp
`
2 minps1, s2q
˘
´ 1
˘
(3.19)
“ 1
2
`
exp p´ |s1 ´ s2|q ´ exp
`
´ps1 ` s2q
˘˘
for all s1, s2 ě 0.
2. Brownian motion and related processes
In what follows x and y are real numbers and so is µ. Let tbpsq : s ě 0u be
Brownian motion (starting in 0) on a probability space pΩ, F, Pq (i.e. E rbpsqs “
0 and E rb ps1q b ps2qs “ min ps1, s2q). Then the process tx ` bpsq ` µs : s ě 0u
is a Brownian motion with drift µ starting at x.
Let tXtpsq : 0 ď s ď tu be
a Brownian bridge on a probability space pΩ, F, Pq.
Then the process s ÞÑ
´
1 ´ s
t
¯
x ` s
t y ` Xtpsq 0 ď s ď t is called pinned Brownian motion, namely
pinned at x at time 0 and pinned at y at time t.
Let tbjpsq : s ě 0u, 1 ď
j ď d, be d independent Brownian motions on the probability space pΩ, F, Pq.
The process tpb1psq, . . . , bdpsqq : s ě 0u is called d-dimensional Brownian motion.
The characteristic function for d-dimensional Brownian motion starting at x P
Rd is given by:
Ex
”
e´i řn
j“1⟨Xpsjq,ξj⟩ı
“ e´i řn
j“1⟨ξj,x⟩e´ 1
2
řn
j,k“1⟨ξj,ξk⟩minpsj,skq
“ e´i řn
j“1⟨ξj,x⟩e´ 1
2
řn
ℓ“1psℓ´sℓ´1q|
řn
j“ℓξj|
2
,
(3.20)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
99 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
where x0 “ x and where 0 “ s0 ă s1 ă ¨ ¨ ¨ ă sn. A similar deﬁnition can be
given for d-dimensional Brownian bridge and for the d-dimensional oscillator
process. Notice that a d-dimensional process tbpsq “ pb1psq, . . . , bdpsqq : s ě 0u
is a d-dimensional Brownian motion, starting at 0, on the probability space
pΩ, F, Pq if and only if E pbjps1q, bkps2qq “ δj,k minps1, s2q.
Let us prove the
above equalities.
3.10. Theorem. Let 0 “ s0 ă s1 ă ¨ ¨ ¨ ă sn ă 8. Fix the vectors x and
ξ1, . . . , ξn in Rd. Put s0 “ 0 and x0 “ x. The following equalities are valid:
nÿ
ℓ“1
psℓ´ sℓ´1q
ˇˇˇˇˇ
nÿ
j“ℓ
ξj
ˇˇˇˇˇ
2
“
nÿ
j,k“1
⟨ξj, ξk⟩min psj, skq ;
(3.21)
ż
Rd dx1 . . .
ż
Rd dxn exp
˜
´i
nÿ
j“1
⟨ξj, xj⟩
¸
(3.22)
n
ź
j“1
1
`a
2π psj ´ sj´1q
˘d exp
˜
´ |xj ´ xj´1|2
2 psj ´ sj´1q
¸
“ exp
˜
´i
⟨nÿ
j“1
ξj, x
⟩¸
exp
˜
´1
2
nÿ
j,k“1
⟨ξj, ξk⟩min psj, skq
¸
.
(3.23)
For a and b P Rd we write pa ` biq2 “ |a|2 ` 2i ⟨a, b⟩´ |b|2.
Proof. In order to see the ﬁrst equality we write
nÿ
ℓ“1
psℓ´ sℓ´1q
ˇˇˇˇˇ
nÿ
j“ℓ
ξj
ˇˇˇˇˇ
2
“
nÿ
ℓ“1
psℓ´ sℓ´1q
nÿ
j1,j2“ℓ
⟨ξj1, ξj2⟩
“
nÿ
j1,j2“1
minpj1,j2q
ÿ
ℓ“1
psℓ´ sℓ´1q ⟨ξj1, ξj2⟩“
nÿ
j1,j2“1
`
sminpj1,j2q ´ s0
˘
⟨ξj1, ξj2⟩
“
nÿ
j1,j2“1
sminpj1,j2q ⟨ξj1, ξj2⟩. “
nÿ
j1,j2“1
min psj1, sj2q ⟨ξj1, ξj2⟩.
(3.24)
For the second equality we proceed as follows:
ż
Rd dx1 . . .
ż
Rd dxn exp
˜
´i
nÿ
j“1
⟨ξj, xj⟩
¸
n
ź
j“1
1
`a
2π psj ´ sj´1q
˘d exp
˜
´ |xj ´ xj´1|2
2 psj ´ sj´1q
¸
(3.25)
(substitute xj “ x ` y1 ` ¨ ¨ ¨ ` yj)
“ exp
˜
´i
nÿ
j“1
⟨ξj, x⟩
¸ ż
Rd dy1 . . .
ż
Rd dyn exp
˜
´i
nÿ
ℓ“1
⟨nÿ
j“ℓ
ξj, yℓ
⟩¸
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
100 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
n
ź
j“1
1
`a
2π psj ´ sj´1q
˘d exp
˜
´
|yj|2
2 psj ´ sj´1q
¸
(substitute yℓ“ psℓ´ sℓ´1q1{2 zℓ)
“ exp
˜
´i
nÿ
j“1
⟨ξj, x⟩
¸ ż
Rd dz1 . . .
ż
Rd dzn
exp
˜
´i
nÿ
ℓ“1
psℓ´ sℓ´1q1{2
nÿ
j“ℓ
⟨ξj, zℓ⟩
¸
n
ź
j“1
1
`?
2π
˘d exp
˜
´|zj|2
2
¸
“ exp
˜
´i
nÿ
j“1
⟨ξj, x⟩
¸
exp
¨
˝´1
2
nÿ
ℓ“1
psℓ´ sℓ´1q
ˇˇˇˇˇ
nÿ
j“ℓ
ξj
ˇˇˇˇˇ
2˛
‚
n
ź
ℓ“1
1
`?
2π
˘d
ż
Rd dzℓexp
¨
˝´1
2
˜
zℓ` i?sℓ´ sℓ´1
nÿ
j“ℓ
ξj
¸2˛
‚,
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
101 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
From Cauchy’s theorem, it then follows that
ż
Rd dx1 . . .
ż
Rd dxn exp
˜
´i
nÿ
j“1
⟨ξj, xj⟩
¸
(3.26)
n
ź
j“1
1
`a
2π psj ´ sj´1q
˘d exp
˜
´ |xj ´ xj´1|2
2 psj ´ sj´1q
¸
(3.27)
“ exp
˜
´i
nÿ
j“1
⟨ξj, x⟩
¸
exp
¨
˝´1
2
nÿ
ℓ“1
psℓ´ sℓ´1q
ˇˇˇˇˇ
nÿ
j“ℓ
ξj
ˇˇˇˇˇ
2˛
‚
(3.28)
n
ź
ℓ“1
1
`?
2π
˘d
ż
Rd dzℓexp
ˆ
´1
2 |zℓ|2
˙
(3.29)
“ exp
˜
´i
nÿ
j“1
⟨ξj, x⟩
¸
exp
¨
˝´1
2
nÿ
ℓ“1
psℓ´ sℓ´1q
ˇˇˇˇˇ
nÿ
j“ℓ
ξj
ˇˇˇˇˇ
2˛
‚
(3.30)
(ﬁrst equality)
“ exp
˜
´i
nÿ
j“1
⟨ξj, x⟩
¸
exp
˜
´1
2
nÿ
j,k“1
⟨ξj, ξk⟩min psj, skq
¸
.
This completes the proof of Theorem 3.10.
□
In the following proposition we collect a number of interesting properties of the
(ﬁnite dimensional) joint distributions of some of the Gaussian processes we
introduced so far.
3.11. Proposition. Let tbpsq : s ě 0u be d-dimensional Brownian motion and
let
tXtpsq : 0 ď s ď tu
be d-dimensional Brownian bridge. In addition let x and y be vectors in Rd and
let Q : Rd Ñ Rd be an orthogonal linear map. Also ﬁx a strictly positive number
a.
(a) The joint distributions of the processes
tbpsq : s ą 0u
and
"
sb
ˆ1
s
˙
: s ą 0
*
coincide.
(b) The joint distributions of the processes
tbpasq : s ě 0u
and
␣?ab psq : s ě 0
(
coincide.
(c) The joint distributions of the processes
tqpsq : s P Ru
and
"
e´sb
ˆe2s
2
˙
: s P R
*
coincide.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
102 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(d) The joint distributions of the processes
tXptq : t ě 0u
and
"
e´tb
ˆe2t ´ 1
2
˙
: t ě 0
*
coincide. The process tXptq : t ě 0u also possesses the same joint dis-
tribution as
!şt
0 exp p´pt ´ sqq dbpsq : t ě 0
)
.
(e) The joint distributions of the following processes also coincide:
´
1 ´ s
t
¯
x ` s
t y ` Xtpsq,
0 ă s ă t,
(3.31)
´
1 ´ s
t
¯
x ` s
t y `
´
1 ´ s
t
¯
b
ˆ st
t ´ s
˙
,
0 ă s ă t,
(3.32)
´
1 ´ s
t
¯
x ` s
t y ` bpsq ´ s
t bptq,
0 ă s ă t.
(3.33)
(f) The process tQbpsq : s ě 0u is d-dimensional Brownian motion and so
its joint distribution coincides with that of tbpsq : s ě 0u.
Notice that instead of the “distribution” of a random variable or a stochastic
process, the name “law” is in vogue.
3.12. Remark. Put bxptq “ x ` bptq. Then tbxptq : t ě 0u is Brownian motion
that starts in x. Put Xxptq “ expp´tqx`Xptq. Then the process tXxptq : t ě 0u
is the Ornstein-Uhlenbeck process of initial velocity x.
3.13. Remark. The stochastic integral
şt
0 expp´pt ´ sqqdbpsq can be deﬁned as
the L2-limit of řn
j“1 e´pt´sj´1q pbpsjq ´ bpsj´1qq, whenever max
1ďjďn psj ´ sj´1q tends
to zero. Here 0 “ s0 ă s1 ă ¨ ¨ ¨ ă sn “ t is a subdivision of the interval r0, ts.
3.14. Remark. Let f : Rd Ñ C be a bounded Borel measurable function. Then
E rfpXxptqqs is given by
E rf pXxptqqs “
ż
f
´
e´tx `
?
1 ´ e´2ty
¯ exp
`
´ |y|2˘
p?πqd
dy.
Moreover the Ornstein-Uhlenbeck process is a strong Markov process.
3.15. Remark. Let tbxptq : t ě 0u be Brownian motion that starts at x (and
has drift zero). Fix s ą 0. The processes
tbxps ` tq ´ bxpsq : t ě 0u
and
tbxptq ´ x : t ě 0u
possess the same (joint) distribution. In order to see this one may calculate the
Fourier transforms, or characteristic functions, of their distributions.
3.16. Remark. Suppose that the Markov process
tpΩ, F, Pxq , pXptq, t ě 0q , pϑt, t ě 0q , pRn, Bqu
(3.34)
is Brownian motion in Rn, and put p0pt, x, yq “
1
p2πtqn{2 exp
˜
´|x ´ y|2
2t
¸
,
t ą 0, x, y P Rn. Deﬁne the measure µx,y
0,t by
µt,y
0,xpAq “ Ex r1Ap0pt ´ s, Xpsq, yqs ,
(3.35)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
103 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
where the event A belongs to Fs “ σ pXpuq : u ď sq, for s ă t. Since the process
s ÞÑ p0pt ´ s, Xpsq, yq is a Px-martingale on the half-open interval 0 ď s ă t,
it follows that the quantity µt,y
0,xpAq is well-deﬁned: its value does not depend
on s, as long as A belongs to Fs and s ă t. From the monotone class theorem
it follows that µx,y
0,t can be considered as a positive measure on the σ-ﬁeld Ft´
given by Ft´ “ σ pXpsq : 0 ď s ă tq. Then the measure µt,y
0,x deﬁned in (3.35)
is called the conditional Brownian bridge measure. It can be normalized upon
dividing it by the density p0pt, x, yq.
Proof of Proposition 3.11. Since all the indicated processes are d-dim-
ensional Gaussian (the deﬁnition of a d-dimensional Gaussian process should be
obvious: in fact in the discussion of 3.4 and in Theorem 3.7. The expected value
µ should be map from I to Rd and the entries of the diﬀusion matrix σ should
be d ˆ d-matrices), it suﬃces to show that the corresponding expectations and
covariance matrices are the same for the indicated processes. In most cases this
is a simple exercise. For example let us prove (f). Let qpk, ℓq be the entries of
the matrix Q. Then
E
´
pQbps1qqj pQbps2qqk
¯
“
dÿ
m“1
qpj, mq
dÿ
n“1
qpk, nqE pbmps1qbnps2qq
“
dÿ
m“1
qpj, mq
dÿ
n“1
qpk, nqδm,n minps1, s2q “
dÿ
m“1
qpj, mqqpk, mq minps1, s2q
“ pQQ˚q pj, kq minps1, s2q “ δj,k minps1, s2q.
(3.36)
This proves that tQbpsq : s ě 0u is again d-dimensional Brownian motion. This
completes the brief outline of the proof of Proposition 3.11.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
104 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In the proof of the existence of a continuous version of Brownian motion, we
shall employ the following maximal inequality of L´evy.
3.17. Theorem. (L´evy) Let X1, . . . , Xn be random variables with values in Rd.
Suppose that the joint distribution of X1, . . . , Xn is invariant under any change
of sign px1, . . . , xnq ÞÑ pϵ1x1, . . . , ϵnxnq, where ϵj “ ˘1. Put Sk “ řk
j“1 Xj.
Then for any λ ą 0
P
ˆ
max
1ďkďn |Sk| ě λ
˙
ď 2P p|Sn| ě λq .
(3.37)
If d “ 1, then
P
ˆ
max
1ďkďn Sk ě λ
˙
ď 2P pSn ě λq .
(3.38)
Proof. We prove (3.37). Put
Ak “
k´1
č
j“1
t|Sj| ă λu X t|Sk| ě λu
and put A “ Ťn
k“1 Ak. Write Tk “ řk
j“1 Xj´řn
j“k`1 Xj. Then Sk “ 1
2Sn ` 1
2Tk
and so
t|Sk| ě λu Ă t|Sn| ě λu Y t|Tk| ě λu .
Hence, from the invariance of the joint distribution of pX1, . . . , Xnq under sign
changes we see
P pAkq “ P pAk, |Sk| ě λq
ď P pAk, |Sn| ě λq ` P pAk, |Tk| ě λq “ 2P pAk, |Sn| ě λq .
Since the events Ak, 1 ď k ď n, are mutually disjoint, we infer
P
ˆ
max
1ďkďn |Sk| ě λ
˙
“ PpAq “
nÿ
k“1
PpAkq ď 2
nÿ
k“1
P pAk, |Sn| ě λq ď 2P p|Sn| ě λq .
This proves (3.37). The proof of (3.38) is similar and will be left to the reader.
Altogether this completes the proof Theorem 3.17.
□
Let tXptq : t ě 0u be Brownian motion on the probability space pΩ, F, Pq. We
shall prove that there exists a continuous process tbptq : t ě 0u, that is indistin-
guishable from the process tXptq : t ě 0u. This means that PpXptq “ bptqq “ 1
for all t ě 0.
3.18. Theorem. Let tXptq : t ě 0u be Brownian motion on some probability
space pΩ, F, Pq. Then there exists stochastic process tbptq : t ě 0u which is P-
almost surely continuous, and that is also a Brownian motion on the probability
space pΩ, F, Pq and that is indistinguishable from the process tXpsq : s ě 0u.
Here we suppose that F contains the P-zero sets.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
105 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Without loss of generality we may and do assume that the Brownian
motion tXpsq : s ě 0u has drift 0 and diﬀusion matrix identity. For the proof
we shall rely on Theorem 3.17 and on the Borel-Cantelli lemma, which reads as
follows. Let pAn : n P Nq be a sequence of events with ř8
n“1 PpAnq ă 8. Then
P
`Ş8
m“1
Ť8
n“m An
˘
“ 0. In Theorem 3.18 we choose the sequence pAn : n P Nq
as follows. Let D be the set of non-negative dyadic rational numbers and put
An “
#
max
0ďkăn2n
sup
qPDXrk2´n,pk`1q2´ns
ˇˇXpqq ´ Xpk2´nq
ˇˇ ą 1
n
+
.
An application of Theorem 3.17, with Xpt`jδ2´mq´Xpt`pj´1qδ2´mq replacing
Xj yields
P
ˆ
max
1ďjď2m
ˇˇX
`
t ` jδ2´m˘
´ Xptq
ˇˇ ě α
˙
ď 2P p|Xpt ` δq ´ Xptq| ě αq
ď 2
α4E |Xpt ` δq ´ Xptq|4 “ 2δ2
α4
1
`?
2π
˘d
ż
Rd exp
ˆ
´1
2 |y|2
˙
|y|4 dy
“ 2δ2 p2d ` d2q
α2
.
(3.39)
In (3.39) we let m tend to inﬁnity to obtain:
P
ˆ
sup
0ďqď1,qPD
|Xpt ` qδq ´ Xptq| ą α
˙
ď 2δ2 p2d ` d2q
α4
.
(3.40)
Hence, with Jn,k “ rk2´n, pk ` 1q2´ns (see also (3.46) below), and with t “ k2´n
and δ “ 2´n,
P
˜
max
0ďkăn2n
sup
qPDXJn,k
ˇˇXpqq ´ Xpk2´nq
ˇˇ ą 1
n
¸
ď
n2n´1
ÿ
k“0
P
˜
sup
qPDXJn,k
ˇˇXpqq ´ Xpk2´nq
ˇˇ ą 1
n
¸
ď n2n2 p2d2´2n ` d22´2nq
pn´1q4
“ 2 p2d ` d2q n5
2n
ď 6d2n5
2n
.
(3.41)
Since the sequence in (3.41) is summable, we may apply Borel-Cantelli’s lemma
to conclude that P-almost surely, for all t ą 0, the path q ÞÑ Xpqq is uniformly
continuous on DXr0, ts. So it makes sense to deﬁne the P-almost surely continu-
ous function s ÞÑ bpsq by bpsq “ limqÑs,qPD Xpsq. It is not so diﬃcult to see that
the process tbpsq : s ě 0u is also a Brownian motion. In fact let ξ1, . . . , ξn be n
vectors in Rd and suppose 0 “ s0 ă s1 ă ¨ ¨ ¨ ă sn. Then we choose sequences
0 “ q0pmq ă s1 ă q1pmq ă s2 ă q2pmq ă sn´1 ă ¨ ¨ ¨ ă qn´1pmq ă sn ă qnpmq,
m P N, in D, such that qkpmq Ó sk, if m tends to inﬁnity and this for 1 ď k ď n.
Since tXpsq : s ě 0u is d-dimensional Brownian motion we have
E
˜
exp
˜
´i
nÿ
k“1
⟨ξk, X pqkpmqq⟩
¸¸
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
106 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
“ exp
¨
˝´1
2
nÿ
j“1
ˇˇˇˇˇ
nÿ
k“j
ξk
ˇˇˇˇˇ
2
pqjpmq ´ qj´1pmqq
˛
‚.
(3.42)
In (3.42) we let m tend to 8 to obtain
E
˜
exp
˜
´i
nÿ
k“1
⟨ξk, b pskq⟩
¸¸
“ exp
¨
˝´1
2
nÿ
j“1
ˇˇˇˇˇ
nÿ
k“j
ξk
ˇˇˇˇˇ
2
psj ´ sj´1q
˛
‚.
(3.43)
This equality shows that tbpsq : s ě 0u is a Brownian motion. In order to prove
that it cannot be distinguished from the process tXpsq : s ě 0u, we notice ﬁrst
that
E pexp p´i ⟨ξ, Xpt ` sq ´ Xptq⟩qq “ exp
ˆ
´1
2 |ξ|2 s
˙
,
ξ P Rd.
(3.44)
Hence, for ξ P Rd,
E |exp p´i ⟨ξ, Xptq⟩q ´ exp p´i ⟨ξ, bptq⟩q|2
“ E p2 ´ exp pi ⟨ξ, Xptq ´ bptq⟩q ´ exp p´i ⟨ξ, Xptq ´ bptq⟩qq
“
lim
qÓt,qPD p2 ´ E pexp p´i ⟨ξ, Xpqq ´ Xptq⟩qq ´ E pexp p´i ⟨ξ, Xptq ´ Xpqq⟩qqq
“ 2 ´ 2 lim
qÓt,qPD exp
ˆ
´1
2 |ξ|2 pq ´ tq
˙
“ 0.
(3.45)
From (3.45) it readily follows that the processes tXpsq :s ě 0u and tbpsq :s ě 0u
cannot be distinguished.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Advanced stochastic processes: Part I
107 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In this proof of Theorem 3.18 we have also used the fourth moment
E |Xpt ` sq ´ Xptq|4 .
From (3.44) it follows that this moment does not depend on t and hence
E |Xpt ` sq ´ Xptq|4 “ E |Xpsq ´ Xp0q|4 “ E |Xpsq|4 .
A way of computing E |Xpsq|4 is the following:
E |Xpsq|4 “
˜ dÿ
j“1
B2
Bξ2
j
¸2
E pexp p´i ⟨ξ, Xpsq⟩qq
ˇˇ
ξ“0
“
˜ dÿ
j“1
B2
Bξ2
j
¸2
exp
ˆ
´1
2 |ξ|2 s
˙ ˇˇ
ξ“0
“
`
2ds2 ´ 2s3 |ξ|2 ` s4 |ξ|4 ´ 2ds3 |ξ|2 ` d2s2˘
exp
ˆ
´1
2 |ξ|2
˙ ˇˇ
ξ“0
“
`
2ds2 ´ 2pd ` 1qs2 |ξ|2 ` s4 |ξ|4 ` d2s2˘
exp
ˆ
´1
2 |ξ|2 s
˙ ˇˇ
ξ“0
“ 2ds2 ` d2s2.
(3.46)
In the following theorem we compute the ﬁnite dimensional distributions of d-
dimensional Brownian motion starting at 0 and possessing drift µ. Therefore
we deﬁne the Gaussian kernel ppt, x, yq by ppt, x, yq “
1
p2πtq
1
2 d exp
˜
´|x ´ y|2
2t
¸
.
Notice the Chapman-Kolmogorov identity
pps, x, zqppt, z, yq “ pps ` t, x, yqp
ˆ st
s ` t, sx ` ty
s ` t , z
˙
.
3.19. Theorem. Let tbpsq : s ě 0u be d-dimensional Brownian motion with dif-
fusion matrix identity, with drift 0 and which starts in 0.
Let f1, . . . , fn be
bounded Borel measurable functions on Rd and let 0 “ s0 ă s1 ă ¨ ¨ ¨ ă sn.
Then
E
˜ n
ź
j“1
fjpx ` bpsjq ` µsjq
¸
(3.47)
“
ż
Rd . . .
ż
Rd dx1 . . . dxn
n
ź
j“1
fjpxjq
n
ź
j“1
p psj ´ sj´1, xj´1 ´ µsj´1, xj ´ µsjq ,
where x0 “ x.
3.20. Remark. Equality (3.47) determines the joint distribution of the process
tXpsq :“ x ` bpsq ` µs : s ě 0u .
This will follow from the monotone class theorem. The vector µ is the so-called
drift vector and the process X “ tXpsq : s ě 0u starts at x in Rd.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
108 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.21. Remark. Another consequence of equality (3.47) is the fact that the
random vector bptq´bpsq, t ą s ﬁxed, is independent of the σ-ﬁeld generated by
the process tbpσq : 0 ď σ ď su. This fact also follows from (3.48) below together
with the monotone class theorem. For ξ P Rd, ξj P Rd, 1 ď j ď n, t ą s ě sn ą
¨ ¨ ¨ s1 ą s0 “ 0 the following identity is valid and relevant:
E
˜
exp
˜
´i ⟨ξ, bptq ´ bpsq⟩´ i
nÿ
j“1
⟨ξj, bpsjq⟩
¸¸
“ exp
˜
´1
2 |ξ|2 pt ´ sq ´ 1
2
nÿ
j,k“1
minpsj, skq ⟨ξj, ξk⟩
¸
“ E pexp p´i ⟨ξ, bptq ´ bpsq⟩qq E
˜
exp
˜
´i
nÿ
j“1
⟨ξj, bpsjq⟩
¸¸
.
(3.48)
In other words a Brownian motion (diﬀusion matrix identity) is a Gaussian
process tbpsq : s ě 0u with independent increments bptq ´ bpsq, t ą s, with
mean µpt´sq and covariance matrix covpbkptq´bkpsq, bℓptq´bℓpsqq “ δk,ℓpt´sq.
Proof. Theorem 3.10 shows that the equality in (3.47) holds for functions
fj, 1 ď j ď n, of the form
fjpxq “
ż
exp p´i ⟨ξ, x⟩q dµjpξq,
(3.49)
where µj “ δξj is the Dirac measure ξj. Fubini’s theorem then implies that
(3.47) also holds for functions fj, 1 ď j ď n, of the form (3.49) with µjpBq “
ş
B gjpξq dξ, with gj P L1 `
Rd˘
, 1 ď j ď n. Since, by the Stone-Weierstrass the-
orem functions of the form (3.49) with µjpBq “
ş
B gjpξq dξ where gj P L1 `
Rd˘
,
are dense in the space C0
`
Rd˘
, it follows that (3.47) holds for functions fj P
C0
`
Rd˘
, 1 ď j ď d. By approximating indicator functions of open subsets from
below by functions in C0
`
Rd˘
it follows that the equality in (3.47) holds for
functions fj which are indicator functions of open subsets. A Dynkin argument
(or the monotone class theorem) then shows that (3.47) is also true if the func-
tions fj are indicator functions of Borel subsets Bj, 1 ď j ď n. But then this
equality also holds for bounded Borel functions fj, 1 ď j ď n.
This completes the proof of Theorem 3.19.
□
Next we want to deﬁne standard Brownian motion, with drift vector µ, that
starts at x P Rd.
3.22. Definition. The standard Brownian motion, starting at x P Rd and with
drift µ is deﬁned as the canonical Gaussian process tXpsq : s ě 0u deﬁned on
pΩ, F, Pxq with the property that the increments Xpt ` hq ´ Xptq are mutually
independent and have Px-expectation µh. Moreover it starts Px-almost surely at
x, i.e. PxpXp0q “ xq “ 1 and cov pXkpt ` hq ´ Xkptq, Xℓpt ` hq ´ Xℓpt ` hqq “
δk,ℓh. The covariance is of course also taken with respect to Px. The process is
canonical because for Ωwe take Ω“ C
`
r0, 8q, Rd˘
, for Xptq we take Xptqpωq “
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
109 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
ωptq, ω P Ω. For F we take the σ-ﬁeld in Ω, generated by the state variables
tXpsq : s ě 0u. For all this we often write
␣
pΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q ,
`
Rd, B
˘(
.
Here the shift or translation operators ϑt, t ě 0, are deﬁned by ϑtpωqpsq “
ωps ` tq, ω P Ω. We also introduce the ﬁltration pFt : t ě 0q deﬁned as the full
history: Ft is the σ-ﬁeld generated by the variables Xpsq, 0 ď s ď t. We also
shall need the right closure Ft` deﬁned by Ft` “ Ş
sąt Fs.
In the following result we give some interesting martingale properties for Brow-
nian motion.
3.23. Proposition. Let
␣
pΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q ,
`
Rd, B
˘(
be standard Brownian motion that starts at x P Rd and that has drift µ. For
t ą s the variable Xptq ´ Xpsq does not depend on the σ-ﬁeld Fs. The following
processes are Px-martingales with respect to the ﬁltration Ft, t ě 0:
t ÞÑ Xptq ´ tµ,
t ÞÑ |Xptq ´ tµ|2 ´ dt.
Proof. The fact that the increment Xptq ´ Xpsq does not depend on the
past Fs is explained in Remark 3.21 following Theorem 3.19. The other asser-
tions are consequences of this. Let s and t be positive real numbers. Then we
have
Ex
`
Xps ` tq ´ ps ` tqµ
ˇˇ Fs
˘
´ pXpsq ´ sµq
“ Ex
`
Xps ` tq ´ Xpsq
ˇˇ Fs
˘
´ tµ
(increments are independent of the past)
“ Ex pXps ` tq ´ Xpsqq ´ tµ “ tµ ´ tµ “ 0.
(3.50)
Similarly, but more complicated, we also see
Ex
“
|Xps ` tq ´ ps ` tqµ|2 ´ dps ` tq ´ |Xpsq ´ sµ|2 ` ds
ˇˇ Fs
‰
“ Ex
“
|Xps ` tq ´ Xpsq ´ tµ ` Xpsq ´ sµ|2 ´ dt ´ |Xpsq ´ sµ|2 ˇˇ Fs
‰
“ Ex
“
|Xps ` tq ´ Xpsq ´ tµ|2 ´ dt ` ⟨Xps ` tq ´ Xpsq ´ tµ, Xpsq ´ sµ⟩
ˇˇ Fs
‰
(use (3.50))
“ Ex
“
|Xps ` tq ´ Xpsq ´ tµ|2 ˇˇ Fs
‰
´ dt
(again an application of (3.50))
“ Ex
“
|Xps ` tq ´ Xpsq ´ tµ|2‰
´ dt
“
dÿ
k“1
cov pXkps ` tq ´ Xkpsq, Xkps ` tq ´ Xkpsqq ´ dt “ dt ´ dt “ 0.
(3.51)
This proves Proposition 3.23.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
110 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
So far we have looked at Brownian motion as a Gaussian process.
On the
other hand it is also a Markov process. We would like to discuss that now. In
fact mathematically speaking equality (3.47) in Theorem 3.19 is an equivalent
form of the Markov property. As already indicated in Remark 3.20 following
Theorem 3.19 the monotone class theorem is important for the proofs of the
several versions of the Markov property.
3.24. Definition. Let Ωbe a set and let S be a collection of subsets of Ω. Then
S is a Dynkin system if it has the following properties:
(a) ΩP S;
(b) if A and B belong to S and if A Ě B, then AzB belongs to S;
(c) if pAn : n P Nq is an increasing sequence of elements of S, then the union
Ť8
n“1 An belongs to S.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planet’s 
electricity needs. Already today, SKF’s innovative know-
how is crucial to running a large proportion of the 
world’s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Advanced stochastic processes: Part I
111 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The following result on Dynkin systems is well-known.
3.25. Theorem. Let M be a collection of subsets of Ω, which is stable under
ﬁnite intersections. The Dynkin system generated by M coincides with the σ-
ﬁeld generated by M.
3.26. Theorem. Let Ωbe a set and let M be a collection of subsets of Ω, which
is stable (or closed) under ﬁnite intersections. Let H be a vector space of real
valued functions on Ωsatisfying:
(i) The constant function 1 belongs to H and 1A belongs to H for all A P M;
(ii) if pfn : n P Nq is an increasing sequence of non-negative functions in H such
that f “ supnPN fn is ﬁnite (bounded), then f belongs to H.
Then H contains all real valued functions (bounded) functions on Ω, that are
σpMq measurable.
Proof. Put D “ tA Ď Ω: 1A P Hu.
Then by (i) Ωbelongs to D and
D Ě M. If A and B are in D and if B Ě A, then BzA belongs to D. If
pAn : n P Nq is an increasing sequence in D, then 1YAn “ supn 1An belongs to
D by (ii). Hence D is a Dynkin system, that contains M. Since M is closed
under ﬁnite intersection, it follows by Theorem 3.25 that D Ě σpMq. If f ě 0
is measurable with respect to σpMq, then
f “ sup
n 2´n ÿn2n
j“1 1tfěj2´nu.
(3.52)
Since 1tfěj2´nu, j, n P N, belong to σpMq, we see that f belongs to H. Here we
employed the fact that σpMq Ď D. If f is σpMq-measurable, then we write f
as a diﬀerence of two non-negative σpMq-measurable functions.
□
The previous theorems (Theorems 3.25 and 3.26) are used in the following form.
Let Ωbe a set and let pEi, EiqiPI be a family of measurable spaces, indexed by an
arbitrary set I. For each i P I, let Si denote a collection of subsets of Ei, closed
under ﬁnite intersection, which generates the σ-ﬁeld Ei, and let fi : ΩÑ Ei be
a map from Ωto Ei. In this context the following two propositions follow.
3.27. Proposition. Let M be the collection of all sets of the form
č
iPJ
f ´1
i
pAiq,
Ai P Si,
i P J, J Ď I, J ﬁnite. Then M is a collection of subsets of Ωwhich is stable
under ﬁnite intersection and σpMq “ σ pfi : i P Iq.
3.28. Proposition. Let H be a vector space of real-valued functions on Ωsuch
that:
(i) the constant function 1 belongs to H;
(ii) if phn : n P Nq is an increasing sequence of non-negative functions in H
such that h “ supn hn is ﬁnite (bounded), then h belongs to H;
(iii) H contains all products of the form ś
iPJ 1Ai ˝ fi, J Ď I, J ﬁnite, and
Ai P Si, i P J.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
112 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Under these assumptions H contains all real-valued functions (bounded) func-
tions in σpfi : i P Iq.
The Theorems 3.25 and 3.26 and the Propositions 3.27 and 3.28 are called the
monotone class theorem.
In the following theorem F is the σ-ﬁeld generated by tXpsq : s ě 0u and Ft is
the σ-ﬁeld generated by the past or full history, i.e. Ft “ σ tXpsq : 0 ď s ď tu.
If T is an pFt`q-stopping time we write
FT` “
č
tě0
tA P F : A X tT ď tu P Ft`u .
An pFt`q-stopping is an F-measurable map T from Ωto r0, 8s with the property
that tT ď tu belongs to Ft` for all t ě 0.
Notice that stopping times may take inﬁnite values. Often this is very interest-
ing.
3.29. Theorem. Let
␣
pΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q ,
`
Rd, B
˘(
, x P Rd,
be d-dimensional Brownian motions. Then the following conditions are veriﬁed:
(a1) For every α ą 0, for every t ě 0 and for every open subset U of Rd,
the set
␣
x P Rd : PxpXptq P Uq ą α
(
is open;
(a2) For every α ą 0, for every t ě 0 and for every compact subset K of
Rd, the set
␣
x P Rd : PxpXptq P Kq ě α
(
is compact;
(b) For every open subset U of Rd and for every x P U, the equality
lim
tÓ0 Px pXptq P Uq “ 1 is valid.
Moreover d-dimensional Brownian motion has the following properties:
(i) For all t ě 0 and for all bounded random variables Y : ΩÑ C the equality
Ex pY ˝ ϑt | Ftq “ EXptqpY q
(3.53)
holds Px-almost surely for all x P Rd;
(ii) For all ﬁnite tuples 0 ď t1 ă t2 ă . . . ă tn ă 8 together with Borel subsets
B1, . . . , Bn of Rd the equality
Px pXpt1q P B1, . . . , Xptnq P Bnq
“
ż
B1
. . .
ż
Bn´1
ż
Bn
Pptn ´ tn´1, xn´1, dxnqPptn´1 ´ tn´2, xn´2, dxn´1q
. . . Ppt2 ´ t1, x1, dx2qPpt1, x, dx1q
(3.54)
is valid for all x P Rd (here PxpXptq P Bq “ Ppt, x, Bq);
(iii) For every pFt`q-stopping time T and for every bounded random variable
Y : ΩÑ C the equality
Ex pY ˝ ϑT | FT`q “ EXpTq pY q ,
(3.55)
holds Px-almost surely on tT ă 8u for all x P Rd;
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
113 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(iv) Let B1 be the Borel ﬁeld of r0, 8q. For every bounded function F : r0, 8q ˆ
ΩÑ C, which is measurable with respect to BbF, and for every pFt`q-stopping
time T the equality
Ex ptω ÞÑ F pTpωq, ϑTpωqqu | FT`q “
␣
ω1 ÞÑ EXpTpω1qq tω ÞÑ F pTpω1q, ωqu
(
(3.56)
holds Px-almost surely tT ă 8u for all x P Rd.
Since d-dimensional Brownian motion veriﬁes (a1), (a2) and (b), the properties
in (i), (ii), (iii) and (iv) are all equivalent. Properties (i) and (ii) are always
equivalent and also (iii) and (iv). The implication (iii) ñ (ii) is also clear. For
the reverse implication the full strength of (a1), (a2) and (b) is employed. The
fact that Brownian motion possesses property (ii) is a consequence of Theorem
3.19. In fact the right continuity of paths is very important. Since we have
proved that Brownian motion possesses continuous paths Px-almost surely this
condition is veriﬁed. Property (i) is called the Markov property and property
(iii) is called the strong Markov property. Equality (3.56) is called the strong
time-dependent Markov property. We shall not prove this result. It is part of the
general theory of Markov processes and their sample path properties. It is also
closely connected to the theory of Feller semigroups. As in Theorem 3.29 let
␣
pΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q ,
`
Rd, B
˘(
be Brownian motion starting
in x. In fact the family of operators tPptq : t ě 0u deﬁned by rPptqfs pxq “
Ex pfpXptqq, f P L8pRdq, t ě 0, is a Feller semigroup, because it possesses the
properties mentioned in the following deﬁnition.
In what follows E is a second countable locally compact Hausdorﬀspace, e.g.
E “ Rd. We deﬁne a Feller semigroup as follows.
3.30. Definition. A family tPptq : t ě 0u of operators deﬁned on L8pEq is a
Feller semigroup, or, more precisely, a Feller-Dynkin semigroup on C0pEq if it
possesses the following properties:
(i) It leaves C0pEq invariant: PptqC0pEq Ď C0pEq for t ě 0;
(ii) It is a semigroup: Pps ` tq “ Ppsq ˝ Pptq for all s, t ě 0, and Pp0q “ I;
(iii) It consists of contraction operators: }Pptqf}8 ď }f}8 for all t ě 0 and
for all f P C0pEq;
(iv) It is positivity preserving: f ě 0, f P C0pEq, implies Pptqf ě 0;
(v) It is continuous for t “ 0: limtÓ0 rPptqfs pxq “ fpxq, for all f P C0pEq
and for all x P E.
In the presence of (iii) and (ii), property (v) is equivalent to:
(v1) limtÓ0 }Pptqf ´ f}8 “ 0 for all f P C0pEq.
So that a Feller semigroup is in fact strongly continuous in the sense that, for
every f P C0pEq,
lim
sÑt }Ppsqf ´ Pptqf}8 “ 0.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
114 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
It is perhaps useful to observe that C0pEq, equipped with the supremum-norm
}¨}8 is a Banach space (in fact it is a Banach algebra). A function f : E Ñ C
belongs to C0pEq if it is continuous and if for every ϵ ą 0, there exists a compact
subset K of E such that |fpxq| ă ϵ for x R K. We need one more deﬁnition.
Let tPptq : t ě 0u be a Feller semigroup. Deﬁne for U an open subset of E, the
transition probability Ppt, x, Uq, t ě 0, x P E, by
Ppt, x, Uq “ sup trPptqus pxq : 0 ď u ď 1U, u P C0pEqu .
This transition function can be extended to all Borel subsets by writing
Ppt, x, Kq “ inf tPpt, x, Uq : U open U Ě Ku ,
for K a compact subset of E. If B is a Borel subset of E, then we write
Ppt, x, Bq “ inf tPpt, x, Uq : U Ě B, U open u
“ sup tPpt, x, Kq : K Ď B, K compact u .
It then follows that the mapping B ÞÑ Ppt, x, Bq is a Borel measure on E, the
Borel ﬁeld of E. The Feller semigroup is said to be conservative if, for all t ě 0
and for all x P E, Ppt, x, Eq “ 1.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
115 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We want to conclude this section with a convergence result for Gaussian pro-
cesses.
3.31. Proposition. Let
´
Xpnq
s
: s P I
¯
, n P N, be a sequence of Gaussian pro-
cesses. Let pXs : s P Iq be a process with property that
E rXuXvs “ lim
nÑ8 E
“
Xpnq
u Xpnq
v
‰
,
for all u and v in I and
E rXus “ lim
nÑ8 E
“
Xpnq
u
‰
,
for all u P I.
Also suppose that, in weak sense,
lim
nÑ8
`
Xpnq
u1 , . . . , Xpnq
um
˘
“ pXu1, . . . , Xumq
for all ﬁnite subsets pu1, . . . , umq of I. Then the process pXs : s P Iq is Gaussian
as well.
Proof. Let ξ1, . . . , ξm be real numbers, and let u1, . . . , um be members of
I. Then
E
˜
exp
˜
´i
m
ÿ
k“1
ξkXpnq
uk
¸¸
“ exp
˜
´i
m
ÿ
k“1
ξkE
`
Xpnq
uk
˘
´ 1
2
m
ÿ
k,ℓ“1
ξkξℓcov
`
Xpnq
uk , Xpnq
uℓ
˘
¸
.
Next let n tend to inﬁnity to obtain (here we employ L´evy’s theorem on weak
convergence):
E
˜
exp
˜
´i
m
ÿ
k“1
ξkXuk
¸¸
“ exp
#
´i
m
ÿ
k“1
ξkE rXuks ´ 1
2
m
ÿ
k,ℓ“1
ξkξℓE rpXuk ´ E pXukqq pXuℓ´ E pXuℓqqs
+
.
So the result in Proposition 3.31 follows.
□
For L´evy’s weak convergence theorem see Theorem 5.42.
3.32. Theorem. Brownian motion is a Markov process. More precisely, (3.53)
is satisﬁed.
Proof. Let F be a bounded stochastic variable.
We have to show the
following identity:
Ex
“
F ˝ ϑt
ˇˇ Ft
‰
“ EXptq rFs ,
Px-almost surely.
It suﬃces to show that
Ex rF ˝ ϑt ˆ Gs “ Ex
“
EXptq rFs G
‰
(3.57)
for all bounded stochastic variables F and for all bounded Ft-measurable func-
tions G. By an application of the monotone class theorem twice (see Proposi-
tion 3.28) it suﬃces to take F of the form F “ śm
j“1 fj pX psjqq, 0 ď s1 ă s2 ă
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
116 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
¨ ¨ ¨ sm ă 8, and G of the form G “ śn
j“1 gj pX ptjqq, 0 ď t1 ă t2 ă ¨ ¨ ¨ ă tn ă t.
Here f1, . . . , fm and g1, . . . , gm are bounded continuous functions from Rd to R
or C. Once the monotone class theorem is applied to the vector space
␣
G P L8 pΩ, Ftq : Ex
“
EXptq rFs ˆ G
‰
“ Ex rF ˝ ϑt ˆ Gs
(
,
where F is as above, and once to the vector space
␣
F P L8 pΩ, Fq : EXptq rFs “ Ex
“
F ˝ ϑt
ˇˇ Ft
‰
,
Px-almost surely
(
.
Then (3.57) may be rewritten as
Ex rf1 pX ps1 ` tqq ¨ ¨ ¨ fm pX psm ` tqq g1 pX pt1qq ¨ ¨ ¨ gn pX ptnqqs
“ Ex
“
EXptq rf1 pX ps1qq ¨ ¨ ¨ fm pX psmqqs g1 pX pt1qq ¨ ¨ ¨ gn pX ptnqq
‰
.
(3.58)
Put τj “ tj, 1 ď j ď n, τn`k “ sk `t, 1 ď k ď m; hj “ gj, 1 ď j ď n, hn`k “ fk,
1 ď k ď m. By deﬁnition we have
Ex rf1 pX ps1 ` tqq ¨ ¨ ¨ fm pX psm ` tqq g1 pX pt1qq ¨ ¨ ¨ gn pX ptnqqs
“ Ex rhj px pτ1qq ¨ ¨ ¨ hn`m pX pτn`mqqs
“
ż
. . .
ż
dx1 . . . dxn`mh1 px1q ¨ ¨ ¨ hn`m pxn`mq
p pτ1, x, x1q ¨ ¨ ¨ p pτn`m ´ τn`m´1, xn`m´1, xn`mq .
(3.59)
Next we rewrite the right-hand side of (3.58):
Ex
“
EXptq rf1 pX ps1qq ¨ ¨ ¨ fm pX psmqqs g1 pX pt1qq ¨ ¨ ¨ gn pX ptnqq
‰
“ Ex
„
g1 pX pt1qq ¨ ¨ ¨ gn pX ptnqq
ż
. . .
ż
dy1 . . . dymf1 py1q ¨ ¨ ¨ fm pymq
p ps1, Xptq, y1q ¨ ¨ ¨ p psm ´ sm´1, ym´1, ymq
ȷ
“
ż
. . .
ż
dz1 . . . dzng1 pz1q ¨ ¨ ¨ gn pznq
p pt1, x, z1q ¨ ¨ ¨ p ptn ´ tn´1, zn´1, znq
ż
dzp pt ´ tn, zn, zq
ż
. . .
ż
dy1 . . . dymf1 py1q ¨ ¨ ¨ fm pymq
p ps1, z, y1q ¨ ¨ ¨ p psm ´ sm´1, ym´1, ymq
(Chapman-Kolmogorov:
ş
p pt ´ tn, zn, zq p ps1, z, yq dz “ p ps1 ` t ´ tn, zn, yq)
“
ż
. . .
ż
dz1 . . . dzng1 pz1q ¨ ¨ ¨ gn pznq
ż
. . .
ż
dy1 ¨ ¨ ¨ dymf py1q ¨ ¨ ¨ fm pymq
p pt1, x, z1q ¨ ¨ ¨ p ptn ´ tn´1, zn´1, znq
p ps1 ` t ´ tn, zn, y1q ¨ ¨ ¨ p psm ´ sm´1, ym´1, ymq
“ Ex rf1 pX ps1 ` tqq ¨ ¨ ¨ fm pX psm ` tqq g1 pX pt1qq ¨ ¨ ¨ gn pX ptnqqs .
(3.60)
Since the expressions in (3.59) and (3.60) are the same, this proves the Markov
property of Brownian motion. The proof of Theorem 3.32 is now complete.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
117 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3. Some results on Markov processes, on Feller semigroups and on
the martingale problem
Let E be a second countable locally compact Hausdorﬀspace, let E△be its
one-point compactiﬁcation or, if E is compact, let △be an isolated point of
E△“ E Ť △. Deﬁne the path space Ωas follows. The path space Ωis a subset
of
`
E△˘r0,8q with the following properties:
(i) If ω belongs to Ω, if t ě 0 is such that ωptq “ △and if s ě t, then
ωpsq “ △;
(ii) Put ζpωq “ inf ts ą 0 : ωpsq “ △u for ω P Ω. If ω belongs to Ω, then ω
possesses left limits in E△on the interval r0, ζs and it is right-continuous
on r0, 8q;
(iii) If ω belongs to Ω, if t ě 0 is such that ωptq belongs to E, then the closure
of the set tωpsq : 0 ď s ď tu is a compact subset of E or, equivalently,
if t ą 0 is such that ωpt´q “ △and if s ě t, then ωpsq “ △.
3.33. Definition. The random variable ζ, deﬁned in (iii.) is called the life
time of ω. A path ω P Ωis said to be cadlag on its life time. We also deﬁne
the state variables Xptq : ΩÑ E△by Xptqpωq “ Xpt, ωq “ ωptq, t ě 0,
ω P Ω.
The translation or shift operators are deﬁned in the following way:
rϑtpωqspsq “ ωps ` tq, s, t ą 0 and ω P Ω. The largest subset of
`
E△˘r0,8q
with the properties (i), (ii) and (iii) is sometimes written as D
`
r0, 8q , E△˘
or
as DE△pr0, 8qq. Let F be a σ-ﬁeld on Ω. A function Y : ΩÑ C is called a
random variable if it is measurable with respect to F. Of course C is supplied
with its Borel ﬁeld. The so-called state space E is also equipped with its Borel
ﬁeld E and E△is also equipped with its Borel ﬁeld E△. The path ω△is given
by ω△psq “ △, s ě 0. Unless speciﬁed otherwise we write Ω“ Dpr0, 8q , E△q.
The space Dpr0, 8q , E△q is also called Skorohod space. In addition let F be a
σ-ﬁeld on Ωand let tFt : t ě 0u be a ﬁltration on Ω. Suppose Ft Ď F, t ě 0,
and suppose that every state variable Xptq, t ě 0, is measurable with respect to
Ft. (This is the case where e.g. Ft is the σ-ﬁeld generated by tXpsq : s ď tu.)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
118 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We also want to make a digression to operator theory. Let L be a linear operator
with domain DpLq and range RpLq contained in C0pEq. The operator L is said
to be closable if the closure of its graph is again the graph of an operator. Here
the graph of L, GpLq, is deﬁned by GpLq “ tpf, Lfq : f P DpLqu. Its closure
is the closure of GpLq in the cartesian product C0pEq ˆ C0pEq. If the closure
of GpLq is the graph of an operator, then this operator is, by deﬁnition, the
closure of L. It is written as L. Sometimes L is called the smallest closure of L.
3.34. Definition. Let L be a linear operator with domain and range in C0pEq.
(i) The operator L is said to be dissipative if, for all λ ą 0 and for all
f P DpLq,
}λf ´ Lf}8 ě λ }f}8 .
(3.61)
(ii) The operator L is said to verify the maximum principle if for every f P
DpLq with sup tRe fpxq : x P Eu strictly positive, there exists x0 P E
with the property that
Re fpx0q “ sup tRe fpxq : x P Eu
and
Re Lfpx0q ď 0.
(iii) The martingale problem is said to be uniquely solvable, or well-posed,
for the operator L, if for every x P E there exists a unique probability
P “ Px which satisﬁes:
(a) For every f P DpLq the process
fpXptqq ´ fpXp0qq ´
ż t
0
LfpXpsqqds,
t ě 0,
is a P-martingale;
(b) PpXp0q “ xq “ 1.
(iv) The operator L is said to solve the martingale problem maximally if
for L the martingale problem is uniquely solvable and if its closure L is
maximal for this property. This means that, if L1 is any linear operator
with domain and range in C0pEq, which extends L and for which the
martingale problem is uniquely solvable, then L coincides with L1.
(v) The operator L is said to be the (inﬁnitesimal) generator of a Feller
semigroup
tPptq : t ě 0u ,
if L “ s-lim
tÓ0
Pptq ´ I
t
. This means that a function f belongs to DpLq
whenever Lf :“ lim
tÓ0
Pptqf ´ f
t
exists in C0pEq.
An operator which veriﬁes the maximum principle is dissipative (see e.g. [141],
p. 14) and can be considered as kind of a generalized second order derivative
operator. A prototype of such an operator is the Laplace operator. An operator
for which the martingale problem is uniquely solvable is closable. This follows
from (3.125) below. Our main result says that linear operators in C0pEq which
maximally solve the martingale problem are generators of Feller semigroups and
conversely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
119 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.35. Definition. Next suppose that, for every x P E, a probability measure
Px on F is given. Suppose that for every bounded random variable Y : ΩÑ R
the equality Ex pY ˝ ϑt | Ftq “ EXptqpY q holds Px-almost surely for all x P E
and for all t ě 0. Then the process
tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ
is called a Markov process. If the ﬁxed time t may be replaced with a stopping
time T, the process tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ is called a
strong Markov process.
By deﬁnition P△pAq “ 1Apω△q “ δω△pAq.
Here A
belongs to F. If the process tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ is a
Markov process, then we write
Ppt, x, Bq “ PxpXptq P Bq,
t ě 0,
B P E,
x P E,
(3.62)
for the corresponding transition function. The operator family tPptq : t ě 0u is
deﬁned by rPptqfspxq “ Ex pfpXptqqq, f P C0pEq.
An relevant book on Markov processes is Ethier and Kurtz [54]. An elementary
theory of diﬀusions is given in Durrett [45]. In this aspect the books of Stroock
and Varadhan [133], Stroock [132] [131], and Ikeda and Watanabe [61] are of
interest as well.
We shall mainly be interested in the case that the function Pptqf is a mem-
ber of C0pEq whenever f is so.
In the following theorem F is the σ-ﬁeld
generated by tXpsq : s ě 0u and Ft is the σ-ﬁeld generated by the past or
full history, i.e. Ft “ σ tXpsq : 0 ď s ď tu. If T is a stopping time we write
FT` “ Ş
tě0 tA P F : A X tT ď tu P Ft`u.
3.36. Theorem. Let pΩ, F, Pxq, x P E, be probability spaces with the following
properties:
(a1) For every α ą 0, for every t ě 0 and for every open subset U of E, the
set tx P E : PxpXptq P Uq ą αu is open;
(a2) For every α ą 0, for every t ě 0 and for every compact subset K of E,
the set tx P E : PxpXptq P Kq ě αu is compact;
(c) For every open subset U of E and for every x P U, the equality
lim
tÓ0 Px pXptq P Uq “ 1 is valid.
The following assertions are equivalent:
(i) For all t ě 0 and for all bounded random variables Y : ΩÑ C the equality
Ex pY ˝ ϑt | Ftq “ EXptqpY q
(3.63)
holds Px-almost surely for all x P E;
(ii) For all ﬁnite tuples 0 ď t1 ă t2 ă . . . ă tn ă 8 together with Borel subsets
B1, . . . , Bn of E the equality
Px pXpt1q P B1, . . . , Xptnq P Bnq
“
ż
B1
. . .
ż
Bn´1
ż
Bn
Pptn ´ tn´1, xn´1, dxnqPptn´1 ´ tn´2, xn´2, dxn´1q
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
120 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
. . . Ppt2 ´ t1, x1, dx2qPpt1, x, dx1q
(3.64)
is valid for all x P E (here PxpXptq P Bq “ Ppt, x, Bq);
(iii) For every pFt`q-stopping time T and for every bounded random variable
Y : ΩÑ C the equality
Ex pY ˝ ϑT | FT`q “ EXpTq pY q ,
(3.65)
holds Px-almost surely on tT ă 8u for all x P E;
(iv) Let B be the Borel ﬁeld of r0, 8q. For every bounded function F : r0, 8q ˆ
ΩÑ C, which is measurable with respect to BbF, and for every pFt`q-stopping
time T the equality
Ex ptω ÞÑ F pTpωq, ϑTpωqqu | FT`q “
␣
ω1 ÞÑ EXpTpω1qq tω ÞÑ F pTpω1q, ωqu
(
(3.66)
holds Px-almost surely tT ă 8u for all x P E.
Equality (3.66) is called the strong time-dependent Markov property. We shall
not prove this result.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
121 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.37. Theorem. Let tPptq : t ě 0u be a Feller semigroup. There exists a col-
lection of probabilities pPxqxPE on the σ-ﬁeld F generated by the state variables
tXptq : t ě 0u deﬁned on Ω:“ D
`
r0, 8q , E△˘
in such a way that
Ex rf pXpt1q, . . . , Xptnqqs “
ż
f pXpt1q, . . . , Xptnqq dPx
“
ż
. . .
ż
fpx1, x2, . . . , xnqPptn ´ tn´1, xn´1, dxnqPptn´1 ´ tn´2, xn´2, dxn´1q
. . . Ppt2 ´ t1, x1, dx2qPpt1, x, dx1q,
(3.67)
where f is any bounded complex or non-negative Borel measurable function de-
ﬁned on E△ˆ . . . ˆ E△, that vanishes outside of E ˆ . . . ˆ E. Let the measure
spaces pΩ, F, PxqxPE be as in (3.67). The process
tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ
is a strong Markov process.
The proof of this result is quite technical. The ﬁrst part follows from a well-
known theorem of Kolmogorov on projective systems of measures: see Theorems
1.14, 3.1, 5.81. In the second part we must show that the indicated path space
has full measure, so that no information is lost. Proofs are omitted. They can
be found in for example Blumenthal and Getoor [20], Theorem 9.4. p. 46.
For a discussion in the context of Polish spaces see, e.g., Sharpe [120] or Van
Casteren [146]. For the convenience of the reader we include an outline of the
proof of Theorem 3.37. The following lemma is needed in the proof.
3.38. Lemma. Let pΩ, Ft, Pq be a probability space, and let t ÞÑ Y ptq, be a
supermartingale, which attains positive values. Fix t ą 0 and let D be a dense
countable subset of r0, 8q. Then
P
„
Y ptq ą 0,
inf
0ăsăt, sPD Y psq “ 0
ȷ
“ 0.
(3.68)
Proof. Let psjqj be an enumeration of the set D X r0, 8q. Fix n, N P N,
and deﬁne the stopping time Sn,N by
Sn,N “ min
"
sj :
min
1ďjďN Y psjq ă 2´n
*
.
Then we have Y pSn,Nq ă 2´n on the event tSn,N ă 8u. In addition, by the
supermartingale property (for discrete stopping times) we infer
E
„
Y ptq, min
1ďjďN Y psjq ă 2´n
ȷ
ď E rY ptq, Sn,N ă ts
“ E rY ptq, min pSn,N, tq ă ts
ď E rY pmin pSn,N, tqq , min pSn,N, tq ă ts
“ E rY pSn,Nq , Sn,N ă ts
ď E
“
2´n, Sn,N ă t
‰
ď 2´n.
(3.69)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
122 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In (3.69) we let N Ñ 8 to obtain:
E
„
Y ptq,
inf
0ăsăt, sPD Y psq ă 2´n
ȷ
ď 2´n.
(3.70)
In (3.70) we let n Ñ 8 to get:
E
„
Y ptq,
inf
0ăsăt, sPD Y psq “ 0
ȷ
“ 0.
(3.71)
Let α ą 0 be arbitrary. From (3.71) it follows that
P
„
Y ptq ą α,
inf
0ăsăt, sPD Y psq “ 0
ȷ
ď 1
αE
„
Y ptq,
inf
0ăsăt, sPD Y psq “ 0
ȷ
“ 0.
(3.72)
Then in (3.72) we let α Ó 0 to complete the proof of Lemma 3.38.
□
Let tPptq : t ě 0u be a Feller-Dynkin semigroup acting on C0pEq where E is a
locally compact Hausdorﬀspace. In the proof of Theorem 3.37 we will also use
the resolvent operators tRpαq : α ą 0u: Rpαqfpxq “
ş8
0 e´αtPptqfpxq dt, α ą 0,
f P C0pEq. An important property is the resolvent equation:
Rpβq ´ Rpαq “ pα ´ βq RpαqRpβq,
α, β ą 0.
The latter property is a consequence of the semigroup property.
3.39. Remark. The space E is supposed to be a second countable (i.e.
it
is a topological space with a countable base for its topology) locally compact
Hausdorﬀspace (in particular it is a Polish space). A second-countable locally-
compact Hausdorﬀspace is Polish.
Let pUiqi be a countable basis of open
subsets with compact closures, choose for each i P N, yi P Ui, together with a
continuous function fi : E Ñ r0, 1s such that fi pyiq “ 1 and such that fi pyq “ 0
for y R Ui. Since a locally compact Hausdorﬀspace is completely regular this
choice is possible. Put
dpx, yq “
8
ÿ
i“1
2´i |fipxq ´ fipyq| `
ˇˇˇˇ
1
ř8
i“1 2´ifipxq ´
1
ř8
i“1 2´ifipyq
ˇˇˇˇ ,
x, y P E.
This metric gives the same topology, and it is not too diﬃcult to verify its
completeness. For this notice that the sequence pfiqi separates the points of E,
and therefore the algebraic span (i.e. the linear span of the ﬁnite products of
the functions fi) is dense in C0pEq for the topology of uniform convergence. A
proof of the fact that a locally compact space is completely regular can be found
in Willard [152] Theorem 19.3. The connection with Urysohn’s metrization
theorem is also explained. A related construction can be found in Garrett [57]:
see Dixmier [39] Appendix V as well.
3.40. Remark. Next we present the notion of Skorohod space. Let D pr0, 1s, Rq
be the space of real-valued functions ω deﬁned on the interval r0, 1s that are
right-continuous and have left-hand limits, i.e., ωptq “ ω pt`q “ limsÓt ωpsq for
all 0 ď t ă 1, and ω pt´q “ limsÒt ωpsq exists for all 0 ă t ď 1. (In probabilistic
literature, such a function is also said to be a cadlag function, “cadlag” being an
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
123 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
acronym for the French “continu `a droite, limites `a gauche”.) The supremum
norm on D pr0, 1s, Rq, given by
}ω}8 “ sup
tPr0,1s
|ωptq| ,
ω P D pr0, 1s, Rq ,
turns the space D pr0, 1s, Rq into a Banach space which is non-separable. This
non-separability causes well-known problems of measurability in the theory of
weak convergence of measures on the space. To overcome this inconvenience,
A.V. Skorohod introduced a metric (and topology) under which the space be-
comes a separable metric space. Although the original metric introduced by
Skorohod has a drawback in the sense that the metric space obtained is not
complete, it turned out (see Kolmogorov [70]) that it is possible to construct
an equivalent metric (i.e., giving the same topology) under which the space
D pr0, 1s, Rq becomes a separable and complete metric space. Such metric space
the term Polish space is often used.
This metric is deﬁned as follows, and
taken from Paulauskas in [110]. Let Λ denote the class of strictly increasing
continuous mappings of r0, 1s onto itself. For λ P Λ, let
}λ} “
sup
0ďsătď1
ˇˇˇˇlog λptq ´ λpsq
t ´ s
ˇˇˇˇ .
Then for ω1 and ω2 P D pr0, 1s, Rq we deﬁne
d pω1, ω2q “ inf
λPΛ max p}λ} , }ω1 ´ ω2 ˝ γ}8q .
The topology generated by this metric is called the Skorohod topology and
the complete separable metric space D pr0, 1s, Rq is called the Skorohod space.
This space is very important in the theory of stochastic processes. The general
theory of weak convergence of probability measures on metric spaces and, in
particular, on the space D pr0, 1s, Rq is well developed. This theory was started
in the fundamental papers like Chentsov [33], Kolmogorov [70], Prohorov [112],
Skorohod [122].
A well-known reference on these topics is Billingsley [17].
Generalizations of the Skorohod space are worth mentioning. Instead of real-
valued functions on r0, 1s it is possible to consider functions deﬁned on r0, 8q and
taking values in a metric space E. The space of cadlag functions obtained in this
way is denoted by D pr0, 8q, Eq and if E is a Polish space, then D pr0, 8q, Eq,
with the appropriate topology, is also a Polish space, see Ethier and Kurtz [54]
and Pollard [111], where these spaces are treated systematically.
Outline of a proof of Theorem 3.37. Firstly, the Riesz representa-
tion theorem, applied to the functionals f ÞÑ Pptqfpxq, f P C0pEq, pt, xq P
r0, 8q ˆ E, provides a family of sub-probability measures B ÞÑ P pt, x, Bq,
B P E, pt, xq P r0, 8q ˆ E, with P p0, x, Bq “ δx pBq “ 1Bpxq. From the semi-
group property, i.e. Pps ` tq “ PpsqPptq, s, t ě 0, it follows that the family
tP pt, x, ¨q : pt, xq P r0, 8qu obeys the Chapman-Kolmogorov identity:
P ps ` t, x, Bq “
ż
P pt, y, Bq P ps, x, dyq ,
B P E, s ě 0, t ě 0, x P E. (3.73)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
124 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The measures B ÞÑ Ppt, x, Bq, B P E, are inner and outer regular in the sense
that, for all Borel subsets B (i.e. B P E),
P pt, x, Bq “ sup tPpt, x, Kq : K Ă B, K compactu
“ inf tP pt, x, Oq : O Ą B, O openu .
(3.74)
In general we have 0 ď P pt, x, Bq ď 1, pt, x, Bq P r0, 8q ˆ E ˆ E. In order
to apply Kolmogorov’s extension theorem we need that, for every x P E, the
function t ÞÑ Ppt, x, Eq is constant. Since Pp0, x, Eq “ 1 this constant must be
1. This can be achieved by adding an absorption point △to E. So instead of
E we consider the state space E△“ E Y t△u, which, topologically speaking,
can be considered as the one-point compactiﬁcation of E, if E is not compact.
If E is compact, △is an isolated point of E△. Let E△be the Borel ﬁeld of E△.
Then the new family of probability measures tN pt, x, ¨q : pt, xq P r0, 8q ˆ Eu is
deﬁned as follows:
N pt, x, Bq “ P pt, x, B X Eq ` p1 ´ P pt, x, Eqq 1B p△q , pt, xq P r0, 8q ˆ E,
N pt, △, Bq “ 1B p△q ,
t ě 0, B P E△.
(3.75)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENT…
     RUN FASTER.
          RUN LONGER..
                RUN EASIER…
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Advanced stochastic processes: Part I
125 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Compare this construction with the one in (1.1). The family
N :“ tN pt, x, ¨q : pt, xq P r0, 8q ˆ Eu
again satisﬁes the Chapman-Kolmogorov identity with state space E△instead of
E. Notice that N pt, x, Bq “ P pt, x, Bq whenever pt, x, Bq belongs to r0, 8qˆEˆ
E. Employing the family N we deﬁne a family of probability spaces as follows.
For every x0 P E, and every increasing n-tuple 0 ď t1 ă ¨ ¨ ¨ ă tn ă 8 in r0, qn
we consider the probability space
``
E△˘n , bnE△, Px0,t1,...,tn
˘
: the probability
measure Px0,t1,...,tn is deﬁned by
Px0,t1,...,tnpBq “
ż
. . .
ż
B
N pt1 ´ t0, x0, dx1q ¨ ¨ ¨ N ptn ´ tn´1, xn´1, dxnq ,
(3.76)
where B P bnE△. By an appeal to the Chapman-Kolmogorov identity it follows
that, for x0 P E ﬁxed, the family of probability spaces:
␣``
E△˘n , bnE△, Px0,t1,...,tn
˘
: 0 ď t1 ă ¨ ¨ ¨ ă tn ă 8, n P N
(
(3.77)
is a projective system of probability spaces. Put rΩ△“
`
E△˘r0,8q, and equip this
space with the product σ-ﬁeld rF△:“ br0,8qE△. In addition, write r
Xptqpωq “
ωptq, ϑtωpsq “ ωps ` tq, s, t ě 0, ω P rΩ△. The variables r
Xptq, t ě 0, are called
the state variables, and the mappings ϑt, t ě 0, are called the (time) translation
or shift operators. By Kolmogorov’s extension theorem there exists, for every
x P E△, a probability measure rPx on the σ-ﬁeld rF△such that
rPx
”´
r
X pt1q , ¨ ¨ ¨ , r
X ptnq
¯
P B
ı
“ Px,t1,...,tn rBs .
(3.78)
In (3.78) B belongs to bnE△, and 0 ď t1 ă ¨ ¨ ¨ ă tn ă 8 is an arbitrary increas-
ing n-tuple in r0, 8q. Another appeal to the Chapman-Kolmogorov identity and
the monotone class theorem shows that the quadruple
!´
rΩ△, rF△, rPx
¯
,
´
r
Xptq, t ě 0
¯
, pϑt, t ě 0q ,
`
E△, E△˘)
(3.79)
is a Markov process relative to the internal history, i.e. relative to the ﬁltration
rF△
t “ σ
´
r
Xpsq : 0 ď s ď t
¯
, t ě 0. Moreover, we have rPx
”
r
Xp0q “ x
ı
“ 1, and,
by the Markov property, we also have, for x P E△, t ą s ě 0,
rPx
”
r
Xptq “ △, r
Xpsq “ △
ı
“ rEx
”
rPx
”
r
Xpt ´ sq ˝ ϑs “ △
ˇˇ rF△ı
, r
Xpsq “ △
ı
(Markov property)
“ rEx
”
rP r
Xpsq rXpt ´ sq “ △s , r
Xpsq “ △
ı
“ rEx
”
rP△
”
r
Xpt ´ sq “ △
ı
, r
Xpsq “ △
ı
“ N pt ´ s, △, t△uq ¨ N ps, x, t△uq
“ N ps, x, t△uq “ rPx
”
r
Xpsq “ △
ı
.
(3.80)
The equality in (3.80) says that once the process t ÞÑ r
Xptq enters △it stays
there. In other words △is an absorption point for the process r
X. Deﬁne, for t ą
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
126 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
0, the mapping rPptq : C
`
E△˘
Ñ C
`
E△˘
by rPptqfpxq “ rEx
”
f
´
r
Xptq
¯ı
, f P
C
`
E△˘
. From the Markov property of the process r
X, and since the semigroup
t ÞÑ Pptq is a Feller-Dynkin semigroup, it follows that the mappings rPptq, t ě 0,
constitute a Feller (or Feller-Dynkin semigroup) on C
`
E△˘
. Consequently, for
any f P C
`
E△˘
, and any t0 ě 0, we have
lim
s,tÑt0, s, tě0 sup
xPE△
rEx
”ˇˇˇf
´
r
Xptq
¯
´ f
´
r
Xpsq
¯ˇˇˇ
ı
“ 0.
(3.81)
Let D be the collection of non-negative dyadic rational numbers. Since the
space E△is compact-metrizable, it follows from (3.81) that, for all x P E△, the
following limits
lim
sÒt, sPD
r
Xpsq,
and
lim
sÓt, sPD
r
Xpsq,
(3.82)
exist in E△rPx-almost surely. Deﬁne the mapping π : rΩ△Ñ Ωby
πpωqptq “
lim
sÓt, sPD
r
Xpsq pωq “: Xptq pπpωqq ,
t ě 0,
ω P rΩ△.
(3.83)
Then we have that, for every x P E△ﬁxed, the processes t ÞÑ Xptq ˝ π and t ÞÑ
r
Xptq are rPx-indistinguishable in the sense that there exists an event rΩ△,1 Ă rΩ△
such that rPx
”
rΩ△,1ı
“ 1 and such that for all t P r0, 8q the equality r
Xptq “
Xptq˝π holds on the event rΩ△,1. This assertion is a consequence of the following
argument. For every pt, xq P r0, 8q ˆ E△and for every f P C
`
E△˘
we see
rEx
”
f pXptq ˝ πq ´ f
´
r
Xptq
¯ı
“
lim
sÓt, sPD
rEx
”
f
´
r
Xpsq
¯
´ f
´
r
Xptq
¯ı
“ rEx
”
f
´
r
Xptq
¯
´ f
´
r
Xptq
¯ı
“ 0.
(3.84)
Since the space E△is second countable, the space C
`
E△˘
is separable, the
equalities in (3.82) and (3.84) imply that, up to an event which is rPx-negligible
r
Xptq “ Xptq ˝ π for all t ě 0. See Deﬁnition 5.88 as well. In addition, we have
that, for ω P rΩthe realization t ÞÑ πpωqptq belongs to the Skorohod space Ω, i.e.
it is continuous from the right and possesses left limits. We still need to show
that r
Xptq P E implies that the closure of the orbit
!
r
Xpsq : 0 ď s ď t, s P D
)
is a closed, and so, compact subset of E. For this purpose we choose a strictly
positive function f P C0 pEq which we extend to a function, again called f, such
that f p△q “ 0. It is convenient to employ the resolvent operators Rpαq, α ą 0,
here. We will prove that, for α ą 0 ﬁxed, the process t ÞÑ e´αtR pαq f
´
r
Xptq
¯
is rPx-supermartingale relative to the ﬁltration
!
rF△
t ; t ě 0
)
. Therefore, let t2 ą
t1 ě 0. Then we write:
rEx
”
e´αt2Rpαqf
´
r
X pt2q
¯ ˇˇ rF△
t1
ı
“ rEx
„
e´αt2
ż 8
0
e´αsrE r
Xpt2q
”
f
´
r
Xpsq
¯ı
ds
ˇˇ rF△
t1
ȷ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
127 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(Markov property)
“ rEx
„
e´αt2
ż 8
0
e´αsrEx
”
f
´
r
X ps ` t2q
¯ ˇˇ rF△
t2
ı
ds
ˇˇ rF△
t1
ȷ
(Fubini’s theorem and tower property of condiitonal expectation)
“ rEx
„
e´αt2
ż 8
0
e´αsf
´
r
X ps ` t2q
¯
ds
ˇˇ rF△
t1
ȷ
“ rEx
„ż 8
t2
e´αsf
´
r
X psq
¯
ds
ˇˇ rF△
t1
ȷ
(the function f is non-negative and t2 ą t1)
ď rEx
„ż 8
t1
e´αsf
´
r
X psq
¯
ds
ˇˇ rF△
t1
ȷ
“ rEx
„
e´αt1
ż 8
0
e´αsf
´
r
X ps ` t1q
¯
ds
ˇˇ rF△
t1
ȷ
(Fubini’s theorem in combinaton with the Markov property)
“ e´αt1
ż 8
0
e´αsrE r
Xpt1q
”
f
´
r
X psq
¯ı
ds “ e´αt1Rpαqf
´
r
X pt1q
¯
.
(3.85)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Advanced stochastic processes: Part I
128 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Put rY ptq “ e´αtRpαqf
´
r
X ptq
¯
, and ﬁx x P E. From (3.85) we see that the
process t ÞÑ rY ptq is a rPx-supermartingale relative to the ﬁltration
´
rF△
t
¯
tě0.
From Lemma 3.38 with rY ptq instead of Y ptq and rPx in place of P we infer
rPx
„
r
Xptq P E,
inf
sPDXp0,tq
rY psq “ 0
ȷ
“ rPx
„
rY ptq ą 0,
inf
sPDXp0,tq
rY psq “ 0
ȷ
“ 0.
(3.86)
From (3.86) we see that, rPx-almost surely, r
Xptq P E implies infsPDXp0,tq rY psq ą 0.
Consequently, for every x P E, the equality
rPx
”
r
Xptq P E
ı
“ rPx
”
r
Xptq P E, closure
!
r
Xpsq : s P D X p0, tq
)
Ă E
ı
, (3.87)
holds. In other words: the closure of the orbit
!
r
Xpsq : s P D X p0, tq
)
is con-
tained in E whenever r
Xptq belongs to E. We are almost at the end of the proof.
We still have to carry over the Markov process in (3.79) to a process of the form
tpΩ, F, Pxq , pXptq, t ě 0q , pϑt, t ě 0q , pE, Equ
(3.88)
with Ω“ D
`
r0, 8q , E△˘
the Skorohod space of paths with values in E△. This
can be done as follows. Deﬁne the state variables Xptq : ΩÑ E△by Xptqpωq “
ωptq, ω P Ω, and let ϑt : ΩÑ Ωbe deﬁned as above, i.e. ϑtpωqpsq “ ωps ` tq,
ω P Ω. Let the mapping π : rΩÑ Ωbe deﬁned as in (3.83). Then, as shown
above, for every x P E, the processes r
Xptq and Xptq˝π are rPx-indistinguishable.
The probability measures Px, x P E, are deﬁned by Px rAs “ rPx rπ P As where A
is a Borel subset of Ω. Then all ingredients of (3.88) are deﬁned. It is clear that
the quadruple in (3.88) is a Markov process. Since the paths, or realizations,
are right-continuous, it represents a strong Markov process.
This completes an outline of the proof of Theorem 3.37.
□
As above L is a linear operator with domain DpLq and range RpLq in C0pEq.
Suppose that the domain DpLq of L is dense in C0pEq. The problem we want to
address is the following. Give necessary and suﬃcient conditions on the operator
L in order that for every x P E there exists a unique probability measure Px on
F with the following properties:
(i) For every f P DpLq the process fpXptqq ´ fpXp0qq ´
şt
0 LfpXpsqqds,
t ě 0, is a Px-martingale;
(ii) PxpXp0q “ xq “ 1.
Here we suppose Ω“ D
`
r0, 8q , E△˘
(Skorohod space) and F is the σ-ﬁeld gen-
erated by the state variables Xptq, t ě 0. Let PpΩq be the set of all probability
measures on F and deﬁne the subset P 1pΩq of PpΩq by
P 1pΩq “
ď
xPE△
"
P P PpΩq : PrXp0q “ xs “ 1 and for every f P DpLq the process
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
129 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
fpXptqq ´ fpXp0qq ´
ż t
0
LfpXpsqqds, t ě 0, is a P-martingale
*
.
(3.89)
Let pvj : j P Nq be a sequence of continuous functions deﬁned on E with the
following properties:
(i) v0 ” 1;
(ii) }vj}8 ď 1 and vj belongs to DpLq for j ě 1;
(iii) The linear span of vj, j ě 0, is dense in CpE△q.
In addition let pfk : k P Nq be a sequence in DpLq such that the linear span
of tpfk, Lfkq : k P Nu is dense in the graph GpLq :“ tpf, Lfq : f P DpLqu of the
operator L. Moreover let psj : j P Nq be an enumeration of the set Q X r0, 8q.
The subset P 1pΩq may be described as follows:
P 1pΩq “
8
č
n“1
8
č
k“1
8
č
m“1
č
pj1,...,jm`1qPNm`1
č
0ďsj1ă...ăsjm`1
(3.90)
"
P P PpΩq : inf
xPE max
1ďjďn
ˇˇˇˇ
ż
vjpXp0qqdP ´ vjpxq
ˇˇˇˇ “ 0,
ż ˆ
fkpXpsjm`1qq ´
ż sjm`1
0
LfkpXpsqqds
˙ źm
k“1 vjk pXpsjkqq dP
“
ż ˆ
fkpXpsjmqq ´
ż sjm
0
LfkpXpsqqds
˙ źm
k“1 vjk pXpsjkqq dP
*
.
It follows that P 1pΩq is a weakly closed subset of PpΩq. In fact we shall prove
that, if for the operator L, the martingale problem is uniquely solvable, then
the set P 1pΩq is compact metrizable for the metric d pP1, P2q given by
dpP1, P2q “
ÿ
ΛĂN,|Λ|ă8 2´|Λ| ÿ
pℓjqjPΛ
ˇˇˇˇˇ
ż ź
jPΛ
2´j´ℓjvj
`
X
`
sℓj
˘˘
d pP2 ´ P1q
ˇˇˇˇˇ .
(3.91)
The following result should be compared to the comments in 6.7.4. of [133]. It
is noticed that in Proposition 3.41 below the uniqueness of the solutions to the
martingale problem is not used.
3.41. Proposition. The set P 1pΩq supplied with the metric d deﬁned in (3.91)
is a compact Hausdorﬀspace.
Proof. Let pPn : n P Nq be any sequence in P 1pΩq.
Let pPnℓ: ℓP Nq be
a subsequence with the property that for every m P N, for every m-tuple
pj1, . . . , jmq in Nm and for every m-tuple psj1, . . . , sjmq P Qm the limit
lim
ℓÑ8
ż źm
k“1 vjk pX psjkqq dPnℓ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
130 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
exists. We shall prove that for every m P N, for every m-tuple pj1, . . . , jmq in
Nm and for every m-tuple ptj1, . . . , tjmq P r0, 8qm the limit
lim
ℓÑ8
ż źm
k“1 ujk pX ptjkqq dPnℓ
(3.92)
exists for all sequences puj : j P Nq in C0pEq. But then there exists, by Kol-
mogorov’s extension theorem, a probability measure P such that
lim
ℓÑ8
ż źm
k“1 ujk pX ptjkqq dPnℓ“
ż źm
k“1 ujk pX ptjkqq dP,
(3.93)
for all m P N, for all pj1, . . . , jmq P Nm and for all ptj1, . . . , tjmq P r0, 8qm. From
the description (3.89) of P 1pΩq it then readily follows that P is a member of
P 1pΩq. So the existence of the limit in (3.92) remains to be veriﬁed together
with the fact that Dpr0, 8q , E△q has full P-measure. Let t be in Q. Since,
for every j P N, the process vjpXpsqq ´ vjpXp0qq ´
şs
0 LvjpXpσqqdσ, s ě 0, is a
martingale for the measures Pnℓ, we infer
ż ż t
0
LvjpXpsqqdsdPnℓ“
ż
vjpXptqqdPnℓ´
ż
vjpXp0qqdPnℓ.
and hence the limit limℓÑ8
ş şt
0 LvjpXpsqqdsdPnℓexists.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
131 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Next let t0 be in r0, 8q. Again using the martingale property we see
ż
vj pXpt0qq d pPnℓ´ Pnkq
“
ż ˆż t
0
Lvj pXpsqq ds
˙
d pPnℓ´ Pnkq `
ż
vjpXp0qqd pPnℓ´ Pnkq
´
ż ˆż t
t0
Lvj pXpsqq ds
˙
d pPnℓ´ Pnkq ,
(3.94)
where t is any number in Q X r0, 8q. From (3.94) we infer
ˇˇˇˇ
ż
vj pXpt0qq d pPnℓ´ Pnkq
ˇˇˇˇ
ď
ˇˇˇˇ
ż ˆż t
0
Lvj pXpsqq ds
˙
d pPnℓ´ Pnkq
ˇˇˇˇ `
ˇˇˇˇ
ż
vjpXp0qqd pPnℓ´ Pnkq
ˇˇˇˇ
` 2 |t ´ t0| }Lvj}8 .
(3.95)
If we let ℓand k tend to inﬁnity, we obtain
lim sup
ℓ,kÑ8
ˇˇˇˇ
ż
vj pXpt0qq d pPnℓ´ Pnkq
ˇˇˇˇ ď 2 |t ´ t0| }Lvj}8 .
(3.96)
Consequently for every s ě 0 the limit limℓÑ8
ş
vj pXpsqq dPnℓexists.
The
inequality
ˇˇˇˇ
ż
vj pXptqq dPnℓ´
ż
vj pXpt0qq dPnℓ
ˇˇˇˇ “
ˇˇˇˇ
ż ż t
t0
Lvj pXpsqq dsdPnℓ
ˇˇˇˇ
ď |t ´ t0| }Lvj}8
shows that the functions t ÞÑ limℓÑ8
ş
vj pXptqq dPnℓ, j P N, are continuous.
Since the linear span of pvj : j ě 1q is dense in C0pEq, it follows that for
v P C0pEq and for every t ě 0 the limit
t ÞÑ lim
ℓÑ8
ż
v pXptqq dPnℓ
(3.97)
exists and that this limit, as a function of t, is continuous. The following step
consists in proving that for every t0 P r0, 8q the equality
lim
tÑt0 lim sup
ℓÑ8
ż
|vj pXptqq ´ vj pXpt0qq| dPnℓ“ 0
(3.98)
holds. For t ą s the following (in-)equalities are valid:
ˆż
|vj pXptqq ´ vj pXpsqq| dPnℓ
˙2
ď
ż
|vj pXptqq ´ vj pXpsqq|2 dPnℓ
“
ż
|vjpXptqq|2 dPnℓ´
ż
|vjpXpsqq|2 dPnℓ
´ 2Re
ż
pvjpXptqq ´ vjpXpsqqq vjpXpsqqdPnℓ
“
ż
|vjpXptqq|2 dPnℓ´
ż
|vjpXpsqq|2 dPnℓ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
132 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
´ 2Re
ż ˆż t
s
LvjpXpσqqdσ
˙
vjpXpsqqdPnℓ
ď
ż
|vjpXptqq|2 dPnℓ´
ż
|vjpXpsqq|2 dPnℓ` 2pt ´ sq }Lvj}8 .
(3.99)
Hence (3.97) together with (3.99) implies (3.93).
By (3.93), we may apply
Kolmogorov’s theorem to prove that there exists a probability measure P on
Ω1 :“ pE△qr0,8q with the property that
ż
m
ź
k“1
vjkpXpsjkqqdP “ lim
ℓÑ8
ż
m
ź
k“1
vjkpXpsjkqqdPnℓ,
(3.100)
holds for all m P N and for all psj1, . . . , sjmq P r0, 8qm. It then also follows that
the equality in (3.100) is also valid for all m-tuples f1, . . . , fm in CpE△q instead
of vj1, . . . , vjm. This is true because the linear span of the sequence pvj : j P Nq is
dense in CpE△q. In addition we conclude that the processes fpXptqq´fpXp0qq´
şt
0 LfpXpsqqds, t ě 0, f P DpLq are P-martingales.
We still have to show
that Dpr0, 8q , E△q has P-measure 1. From (3.98) it essentially follows that
set of ω P pE△qr0,8q for which the left and right hand limits exist in E△has
”full” P-measure. First let f ě 0 be in C0pEq. Then the process rGλfs ptq :“
E
`ş8
t e´λσfpXpσqqdσ | Ft
˘
is a P-supermartingale with respect to the ﬁltration
tFt : t ě 0u. It follows that the limits limtÒt0 rGλfs ptq and limtÓt0 rGλfs ptq both
exist P-almost surely for all t0 ě 0 and for all f P C0pEq. In particular these
limits exist P-almost surely for all f P DpLq. By the martingale property it
follows that, for f P DpLq,
ˇˇfpXptqq ´ λeλt rGλfs ptq
ˇˇ “
ˇˇˇˇλeλtE
ˆż 8
t
e´λσ pfpXpσqq ´ fpXptqqq dσ | Ft
˙ˇˇˇˇ
“
ˇˇˇˇλeλtE
ˆż 8
t
e´λσ
ˆż σ
t
LfpXpsqqds
˙
dσ | Ft
˙ˇˇˇˇ
ď λeλt
ż 8
t
e´λσpσ ´ tq }Lf}8 dσ “ λ´1 }Lf}8 .
Consequently, we may conclude that, for all s, t ě 0,
|fpXptqq ´ fpXpsqq| ď 2λ´1 }Lf}8 `
ˇˇλeλt rGλfs ptq ´ λeλs rGλfs psq
ˇˇ
and hence that the limits limtÓs fpXptqq and limtÒs fpXptqq exist P-almost surely
for all f P DpLq. By separability and density of DpLq it follows that the limits
limtÓs Xptq and limtÒs Xptq exist P-almost surely for all s ě 0. Put Zpsqpωq “
limtÓs,tPQ Xptqpωq, t ě 0. Then, for P-almost all ω and for all s ě 0, Zpsqpωq is
well-deﬁned, possesses left limits and is right continuous. In addition we have
E pfpZpsqqgpsqq “ E pfpXps`qqgpXpsqqq “ lim
tÓs E pfpXptqqgpXpsqqq
“ E pfpXpsqqgpXpsqqq , for all f, g P C0pEq
and for all s ě 0: see (3.98). But then we may conclude that Xpsq “ Zpsq P-
almost surely for all s ě 0. Hence we may replace X with Z and consequently
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
133 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(see the arguments in the proof of Theorem 9.4. of Blumenthal and Getoor
[[20], p. 49])
P
`
ω P Ω1 : ω is right continuous and has left limits in E△˘
“ 1.
Fix s ą t. We are going to show that the set of paths ω P pE△qr0,8q for which
ωpsq “ Xpsqpωq belongs to E and for which, ωpt´q “ limτÒt Xpτqpωq “ △
possesses P-measure 0. It suﬃces to prove that, for f P C0pEq, 1 ě fpxq ą 0
for all x P E ﬁxed, the following integral equalities hold:
E rfpXpsqq, fpXpt´qq “ 0s “
ż
fpXpsqq1tf“0upXpt´qq dP “ 0.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
134 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
This can be achieved as follows. From the (in-)equalities
E pfpXpsqq, fpXptqq “ 0q
“ lim
nÑ8 E
´
fpXpsqq
´
1 ´ pfpXptqqq1{n¯¯
“ lim
nÑ8 E
`
fpXpsqq
`
1 ´ fpXptqq1{n˘˘
“ lim
nÑ8 E
˜
fpXpsqq
ż 1{n
0
fpXptqqσ log
1
fpXptqqdσ
¸
“ lim
nÑ8
ż 1{n
0
E
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙
dσ
“ lim
nÑ8
ż 1{n
0
pE ´ Enℓq
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙
dσ
` lim
nÑ8
ż 1{n
0
Enℓ
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙
dσ
ď
ż 1
0
ˇˇˇˇE
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙
´Enℓ
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙ˇˇˇˇ dσ
` EnℓpfpXpsqq, fpXptqq “ 0q ,
we conclude that
E pfpXpsqq, fpXptqq “ 0q “ lim
nÑ8 E
`
fpXpsqq
`
1 ´ fpXptqq1{n˘˘
ď
ż 1
0
ˇˇˇˇE
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙
´Enℓ
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙ˇˇˇˇ dσ.
Since the function x ÞÑ fpxqσ log
1
fpxq belongs to C0pEq for every σ ą 0, we
obtain upon letting ℓtend to 8, that E pfpXpsqq, fpXptqq “ 0q “ 0, where
s ą t. To see this apply Scheﬀ´e’s theorem (see e.g. Bauer [[10], Corollary
2.12.5.
p.
105]) to the sequence σ ÞÑ Enℓ
ˆ
fpXpsqqfpXptqqσ log
1
fpXptqq
˙
.
From description (3.90), it then follows that P belongs to P 1pΩq: it is also clear
that the limits in (3.92) exist.
□
3.42. Proposition. Suppose that for every x P E the martingale problem is
uniquely solvable. Deﬁne the map F : P 1pΩq Ñ E△by FpPq “ x, where P P
P 1pΩq is such that PpXp0q “ xq “ 1. Also notice that FpP△q “ △. Then
F is a homeomorphism from P 1pΩq onto E△. In fact it follows that for every
u P C0pEq and for every s ě 0, the function x ÞÑ ExpupXpsqq belongs to C0pEq.
Proof. Since the martingale problem is uniquely solvable for every x P E
the map F is a one-to-one map from the compact metric Hausdorﬀspace P 1pΩq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
135 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
onto E△(see Proposition 3.41). Let for x P E the probability Px be the unique
solution to the martingale problem:
(i) For every f P DpLq the process fpXptqq ´ fpXp0qq ´
şt
0 LfpXpsqqds,
t ě 0, is a Px-martingale;
(ii) PxpXp0q “ xq “ 1.
Then, by deﬁnition FpPxq “ x, x P E, and FpP△q “ △.
Moreover, since
for every x P E the martingale problem is uniquely solvable we see P 1pΩq “
␣
Px : x P E△(
. Let pxℓ: ℓP Nq be a sequence in E△with the property that
limℓÑ8 d pPxℓ, Pxq “ 0 for some x P E△. Then limℓÑ8 |vj pxℓq ´ vjpxq| “ 0, for
all j P N, where, as above, the span of the sequence pvj : j P Nq is dense in
C
`
E△˘
. It follows that limℓÑ8 xℓ“ x in E△. Consequently the mapping F
is continuous. Since F is a continuous bijective map from one compact metric
Hausdorﬀspace P 1pΩq onto another such space E△, its inverse is continuous as
well. Among others this implies that, for every s P Q X r0, 8q and for every
j ě 1, the function x ÞÑ
ş
vj pXpsqq dPx belongs to C0pEq. Since the linear span
of the sequence pvj : j ě 1q is dense in C0pEq it also follows that for every
v P C0pEq, the function x ÞÑ
ş
v pXpsqq dPx belongs to C0pEq. Next let s0 ě 0
be arbitrary. For every j ě 1 and every s P Q X r0, 8q, s ą s0, we have by the
martingale property:
sup
xPE
|Ex pvjpXpsqqq ´ Ex pvjpXps0qqq| “ sup
xPE
ˇˇˇˇ
ż s
s0
Ex pLvj pXpσqqq dσ
ˇˇˇˇ
ď ps ´ s0q }Lvj}8 .
(3.101)
Consequently, for every s P r0, 8q, the function x ÞÑ Ex pvj pXpsqqq, j ě 1,
belongs to C0pEq. It follows that, for every v P C0pEq and every s ě 0, the
function x ÞÑ Ex pvpXpsqqq belongs to C0pEq. This proves Proposition 3.42.
□
The proof of the following proposition may be copied from Ikeda and Watanabe
[61], Theorem 5.1. p. 205.
3.43. Proposition. Suppose that for every x P E△the martingale problem:
(i) For every f P DpLq the process fpXptqq ´ fpXp0qq ´
şt
0 LfpXpsqqds,
t ě 0, is a P-martingale;
(ii) PpXp0q “ xq “ 1,
has a unique solution P “ Px. Then the process
tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ
is a strong Markov process.
Proof. Fix x P E and let T be a stopping time and choose a realization of
A ÞÑ Ex r1A ˝ ϑT | FTs ,
A P F.
Fix any ω P Ωfor which
A ÞÑ QypAq :“ Ex r1A ˝ ϑT | FTs pωq,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
136 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
is deﬁned for all A P F. Here, by deﬁnition, y “ ωpTpωqq. Notice that, sice the
space E is a topological Hausdorﬀspace that satisﬁes the second countability
axiom, this construction can be performed for Px-almost all ω. Let f be in DpLq
and ﬁx t2 ą t1 ě 0. Moreover ﬁx C P Ft1. Then ϑ´1
T pCq is a member of Ft1`T.
Put Mfptq “ fpXptqq ´ fpXp0qq ´
şt
0 LfpXpsqqds, t ě 0. We have
Ey pMfpt2q1Cq “ Ey pMfpt1q1Cq .
(3.102)
We also have
ż ˆ
fpXpt2qq ´ fpXp0qq ´
ż t2
0
LfpXpsqqds
˙
1CdQy
(3.103)
“ Ex
„ˆ
f pXpt2 ` Tqq ´ fpXpTqq ´
ż t2
0
Lf pXps ` Tqq ds
˙
1C ˝ ϑT | FT
ȷ
pωq
“ Ex
„ˆ
f pXpt2 ` Tqq ´ fpXpTqq ´
ż t2`T
T
Lf pXpsqq ds
˙
p1C ˝ ϑTq | FT
ȷ
pωq
“ Ex
„
Ex
„ˆ
f pXpt2 ` Tqq ´ fpXpTqq ´
ż t2`T
T
Lf pXpsqq ds
˙
| Ft1`T
ȷ
.
1C ˝ ϑT | FT
ȷ
pωq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
137 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
By Doob’s optional sampling theorem, the process
f pXpt ` Tqq ´ fpXpTqq ´
ż t`T
T
Lf pXpsqq ds
is a Px-martingale with respect to the ﬁelds Ft`T, t ě 0. So from (3.103) we
obtain:
ż ˆ
fpXpt2qq ´ fpXp0qq ´
ż t2
0
LfpXpsqqds
˙
1CdQy
“ Ex
„ˆ
f pXpt1 ` Tqq ´ fpXpTqq ´
ż t1`T
T
Lf pXpsqq ds
˙
1C ˝ ϑT | FT
ȷ
pωq
“
ż ˆ
fpXpt1qq ´ fpXp0qq ´
ż t1
0
LfpXpsqqds
˙
1CdQy.
(3.104)
It follows that, for f P DpLq, the process Mfptq is a Py- as well as a Qy-
martingale. Since PyrXp0q “ ys “ 1 and since
QypXp0q “ yq “ Ex
“
1tXp0q“yu ˝ ϑT | FT
‰
pωq
“ Ex
“
1tXpTq“yu | FT
‰
pωq “ 1tXpTq“yupωq “ 1,
(3.105)
we conclude that the probabilities Py and Qy are the same. Equality (3.105)
follows, because, by deﬁnition, y “ XpTqpωq “ ωpTpωqq. Since Py “ Qy, it then
follows that
PXpTqpωqpAq “ Ex r1A ˝ ϑT | FTs pωq,
A P F.
Or putting it diﬀerently:
PXpTqpAq “ Ex r1A ˝ ϑT | FTs ,
A P F.
(3.106)
However, this is exactly the strong Markov property and completes the proof of
Proposition 3.43.
□
The following proposition can be proved in the same manner as Theorem 5.1
Corollary in Ikeda and Watanabe [61], p. 206.
3.44. Proposition. If an operator L generates a Feller semigroup, then the
martingale problem is uniquely solvable for L.
Proof. Let tPptq : t ě 0u be the Feller semigroup generated by L and let
tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ
be the associated strong Markov process (see Theorem 3.37). If f belongs to
DpLq, then the process Mfptq :“ fpXptqq ´ fpXp0qq ´
şt
0 LfpXpsqqds, t ě 0, is
a Px-martingale for all x P E. This can be seen as follows. Fix t2 ą t1 ě 0.
Then
Ex rMfpt2q | Ft1s
“ Mfpt1q ` Ex
ˆˆ
fpXpt2qq ´
ż t2
t1
LfpXpsqqds
˙
| Ft1
˙
´ fpXpt1qq
“ Mfpt1q ` Ex
„ˆ
fpXpt2 ´ t1 ` t1qq ´
ż t2´t1
0
LfpXps ` t1qqds
˙
| Ft1
ȷ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
138 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
´ fpXpt1qq
(Markov property)
“ Mfpt1q ` EXpt1q
ˆ
fpXpt2 ´ t1qq ´
ż t2´t1
0
LfpXpsqqds
˙
´ fpXpt1qq. (3.107)
Next we compute, for y P E and s ą 0, the quantity:
Ey
ˆ
fpXpsqq ´
ż s
0
LfpXpσqqdσ
˙
´ fpyq
“ rPpsqfs pyq ´
ż s
0
rPpσqpLfqs pyqdσ ´ fpyq
“ rPpsqfs pyq ´
ż s
0
d
dσ rPpσqfs pyqdσ ´ fpyq
“ rPpsqfss pyq ´ prPpsqfs pyq ´ rPp0qfs pyqq ´ fpyq “ 0.
(3.108)
Hence from (3.107) and (3.108) it follows that the process Mfptq, t ě 0, is
a Px-martingale. Next we shall prove the uniqueness of the solutions of the
martingale problem associated to the operator L. Let P1
x and P2
x be solutions
”starting” in x P E. We have to show that these probabilities coincide. Let f
belong to DpLq and let T be a stopping time. Then, via partial integration, we
infer
λ
ż 8
0
e´λt
"
fpXpt ` Tqq ´
ż t`T
T
LfpXpτqqdτ ´ fpXpTqq
*
dt ` fpXpTqq
“ λ
ż 8
0
e´λt
"
fpXpt ` Tqq ´
ż t`T
T
LfpXpτqqdτ
*
dt
“ λ
ż 8
0
e´λtfpXpt ` Tqqdt ´ λ
ż 8
0
e´λt
ż t
0
LfpXpτ ` Tqqdτdt
“ λ
ż 8
0
e´λtfpXpt ` Tqqdt ´ λ
ż 8
0
ˆż 8
τ
e´λtdt
˙
LfpXpτ ` Tqqdτ
“
ż 8
0
e´λt rpλI ´ Lqfs pXpt ` Tqqdt.
(3.109)
From Doob’s optional sampling theorem together with (3.109) we obtain:
ż 8
0
e´λtE1
x ppλI ´ LqfpXpt ` Tqq | FTq dt ´ fpXpTqq
“ λ
ż 8
0
e´λtE1
x
"ˆ
fpXpt ` Tqq ´
ż t`T
T
LfpXpτqqdτ ´ fpXpTqq
˙
| FT
*
dt
“ 0
“ λ
ż 8
0
e´λtE2
x
"ˆ
fpXpt ` Tqq ´
ż t`T
T
LfpXpτqqdτ ´ fpXpTqq
˙
| FT
*
dt
“
ż 8
0
e´λtE2
x ppλI ´ LqfpXpt ` Tqq | FTq dt ´ fpXpTqq.
(3.110)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
139 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Next we set
rRpλqfs pxq “
ż 8
0
e´λt rPptqfs pxqdt,
x P E, λ ą 0, f P C0pEq.
(3.111)
Then
pλI ´ LqRpλqf “ f, f P C0pEq, RpλqpλI ´ Lqf “ f, f P DpLq.
(3.112)
Among other things we see that RpλI ´ Lq “ C0pEq, λ ą 0. From (3.110) it
then follows that, for g P C0pEq,
ż 8
0
e´λtE1
x pgpXpt ` Tqq | FTq dt “
ż 8
0
e´λtrPptqgspXpTqqdt
“
ż 8
0
e´λtE2
x pgpXpt ` Tqq | FTq dt.
(3.113)
Since Laplace transforms are unique, since g belongs to C0pEq and since paths
are right continuous, we conclude
E1
x pgpXpt ` Tqq | FTq “ rPptqgspXpTqq “ E2
x pgpXpt ` Tqq | FTq ,
(3.114)
whenever g belongs to C0pEq, whenever t ě 0 and whenever T is a stopping
time. The ﬁrst equality in (3.114) holds P1
x-almost surely and the second P2
x-
almost surely. As in Theorem 3.36 it then follows that
E1
x
´źn
j“1 fjpXptjqq
¯
“ E2
x
´źn
j“1 fjpXptjqq
¯
(3.115)
for n “ 1, 2, . . . and for f1, . . . , fn in C0pEq. But then the probabilities P1
x and
P2
x are the same. This proves Proposition 3.44.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
140 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The theorem we want to prove reads as follows.
3.45. Theorem. Let L be a linear operator with domain DpLq and range RpLq
in C0pEq. Let Ωbe the path space Ω“ D
`
r0, 8q , E△˘
. The following assertions
are equivalent:
(i) The operator L is closable and its closure generates a Feller semigroup;
(ii) The operator L solves the martingale problem maximally and its domain
DpLq is dense in C0pEq;
(iii) The operator L veriﬁes the maximum principle, its domain DpLq is
dense in C0pEq and there exists λ0 ą 0 such that the range R pλ0I ´ Lq
is dense in C0pEq.
3.46. Remark. The hard part in (iii) is usually the range property: there exists
λ0 ą 0 such that the range R pλ0I ´ Lq is dense in C0pEq. The theorem also
shows, in conjunction with the results on Feller semigroups and Markov pro-
cesses, the relations which exist between the unique solvability of the martingale
problem, the strong Markov property and densely deﬁned operators verifying
the maximum principle together with the range property. However if L is in fact
a second order diﬀerential operator, then we want to read of the range property
from the coeﬃcients. There do exist results in this direction. The interested
reader is referred to the literature: Stroock and Varadhan [133] and also Ikeda
and Watanabe [61].
In what follows we shall assume that the equivalence of (i) and (iii) already has
been established. A proof can be found in [141], Theorem 2.2., p.14. In the
proof of (ii) ñ (i) we shall use this result. We shall also show the implication
(i) ñ (ii).
Proof. (ii) ñ (i). Let, for x P E, the probability Px be the unique solution
of the martingale problem associated to the operator L. From Proposition 3.43
it follows that the process tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ is a
strong Markov process. Deﬁne the operators tPptq : t ě 0u as follows:
rPptqfspxq “ Ex pfpXptqqq ,
f P C0pEq,
t ě 0.
(3.116)
We also deﬁne the operators tRpλq : λ ą 0u as follows:
rRpλqfspxq “
ż 8
0
e´λtrPptqfspxqdt,
f P C0pEq,
λ ą 0.
(3.117)
From Proposition 3.42 it follows that the operators Pptq leave C0pEq invariant
and hence we also have RpλqC0pEq Ď C0pEq. From the Markov property it fol-
lows that tPptq : t ě 0u is a Feller semigroup and that the family tRpλq : λ ą 0u
is a resolvent family in the sense that
Pps ` tq “ Ppsq ˝ Pptq,
s, t ě 0,
(3.118)
Rpλ2q ´ Rpλ1q “ pλ1 ´ λ2q Rpλ1q ˝ Rpλ2q,
λ1, λ2 ą 0.
(3.119)
For λ ą 0 ﬁxed the operator rL is deﬁned in C0pEq as follows:
rL : Rpλqf ÞÑ λRpλqf ´ f,
f P C0pEq.
(3.120)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
141 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Here the domain DprLq is given by DprLq “ tRpλqf : f P C0pEqu. The operator
rL is well-deﬁned. For, if f1 and f2 in C0pEq are such that Rpλqf1 “ Rpλqf2, then
by the resolvent property (3.119) we see µRpµqf1 “ µRpµqf2, µ ą 0. Let µ tend
8, to obtain f1 “ f2. Since the operator Rpλq is continuous, the operator rL is
closed. Next we shall prove that rL is an extension of L. By partial integration,
it follows that, for f P DpLq,
e´λt
"
fpXptqq ´ fpXp0qq ´
ż t
0
LfpXpτqqdτ
*
` λ
ż t
0
e´λs
"
fpXpsqq ´ fpXp0qq ´
ż s
0
LfpXpτqqdτ
*
ds
“ e´λtfpXptqq ´ fpXp0qq `
ż t
0
e´λspλI ´ LqfpXpsqqds.
(3.121)
As a consequence upon applying (3.121) once more, the processes
"
e´λtfpXptqq ´ fpXp0qq `
ż t
0
e´λspλI ´ LqfpXpsqqds : t ě 0
*
,
f P DpLq,
(3.122)
are Px-martingales for all x P E. Here we employ the fact that the processes
"
fpXptqq ´ fpXp0qq ´
ż t
0
LfpXpsqqds : t ě 0
*
,
f P DpLq,
are Px-martingales.
This is part of assertion (ii).
From assertion (3.122) it
follows that
0 “ Ex
ˆ
e´λtfpXptqq ´ fpXp0qq `
ż t
0
e´λspλI ´ LqfpXpsqqds
˙
,
f P DpLq.
(3.123)
Let t tend to inﬁnity in (3.123) to obtain
0 “ ´Ex pfpXp0qqq `
ż 8
0
e´λsEx ppλI ´ LqfpXpsqqq ds,
f P DpLq.
(3.124)
From (3.124) we obtain fpxq “
ş8
0 e´λs rPpsqpλI ´ Lqfs pxqds, f P DpLq. Or
writing this diﬀerently f “ RpλqpλI ´ Lqf, f P DpLq. Let f belong to DpLq.
Then f “ Rpλqg, with g “ pλI ´ Lqf and hence f belongs to DprLq. Moreover
we see
rLf “ rLpRpλqgq “ λRpλqg ´ g “ λf ´ pλf ´ Lfq “ Lf.
(3.125)
It follows that rL is a closed linear extension of L. In addition we have RpλI ´
rLq “ C0pEq. We shall show that the operator rL veriﬁes the maximum principle.
This can be achieved as follows. Let f in C0pEq be such that, for some x0 P E,
Re pRpλqfqpx0q “ sup tRe Rpλqfpxq : x P Eu ą 0.
(3.126)
Then Re pRpλqfqpx0q ě Re RpλqfpXptqq, t ě 0, and hence
Re pRpλqfqpx0q ě Re
ż 8
0
e´λsEXptq pfpXpsqqq ds,
t ě 0.
(3.127)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
142 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
So that, upon employing the Markov property, we obtain for t ě 0:
Re pRpλqfqpx0q ě Re
ż 8
0
e´λsEx0
`
EXptq pfpXpsqqq
˘
ds
“ Re Ex0 prRpλqfs pXptqq .
(3.128)
Hence, for µ ą 0, we obtain
1
µRe pRpλqfqpx0q “
ż 8
0
e´µtRe Rpλqfpx0qdt
ě Re
ż 8
0
e´µtEx0 prRpλqfs pXptqqq dt
“ Re RpµqRpλqfpx0q
(resolvent equation (3.119)
“ Re Rpλqfpx0q ´ Rpµqfpx0q
µ ´ λ
.
(3.129)
Consequently: rλRe Rpλqfs px0q ď Re rµRpµqfs px0q, µ ą λ. Let µ tend to
inﬁnity, use right continuity of paths and the continuity of f to infer
Re rLRpλqfpx0q “ Re tλRpλqfpx0q ´ fpx0qu ď 0.
(3.130)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
143 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
This proves that rL veriﬁes the maximum principle. Employing the implication
(iii) ñ (i) in Theorem 3.45 yields that rL is the generator of a Feller semigroup.
From Proposition 3.44 it then follows that for rL the martingale problem is
uniquely solvable. Since L solves the martingale problem maximally and since
rL extends L, it follows that rL “ L, the closure of L. Consequently the operator
L is closable and its closure generates a Feller semigroup.
(i) ñ (ii) Let the closure of L, L, be the generator of a Feller semigroup.
From Proposition 3.44 it follows that for L the martingale problem is uniquely
solvable. Hence this is true for L. We still have to prove that L is maximal with
respect to this property. Let L1 be any closed linear extension of L for which
the martingale problem is uniquely solvable. Deﬁne Ă
L1 in the same fashion as
in the proof of the implication (ii) ñ (i), with L1 replacing L. Then rL1 is a
closed linear operator, which extends L1. So that rL1 extends L. As in the proof
of the implication (ii) ñ (i) it also follows that rL1 generates a Feller semigroup.
Since, by (i), the closure of L, also generates a Feller semigroup, we conclude by
uniqueness of generators, that L “ rL1. Since rL1 Ě L1 “ L1 Ě L Ě L, it follows
that the closure of L coincides with L1. This proves the maximality property
of L, and so the proof of Theorem 3.45 is complete.
□
In fact a careful analysis of the proof of Theorem 3.45 shows the following result.
3.47. Proposition. Let L be a densely deﬁned operator for which the martin-
gale problem is uniquely solvable, and which is maximal for this property. Then
there exists a unique closed linear extension L0 of L, which is the generator of
a Feller semigroup.
Proof. Existence. Let tPx : x P Eu be the solution for L, and assume that
for all f P C0pEq the function x ÞÑ rPptqfs pxq belongs to C0pEq for all t ě 0.
Here Pptqfpxq is deﬁned by
rPptqfs pxq “ Ex pfpXptqqq ,
rRpλqfs pxq “
ż 8
0
e´λs rPpsqfs pxqds,
L0pRpλqfq :“ λRpλqf ´ f,
f P C0pEq.
Here t ě 0 and λ ą 0 is ﬁxed. Then, as follows from the proof of Theorem 3.45,
the operator L0 generates a Feller semigroup.
Uniqueness. Let L1 and L2 be closed linear extensions of L, which both generate
Feller semigroups. Let
␣
pΩ, F, P1
xq, pXptq : t ě 0q, pϑt : t ě 0q, pE, Eq
(
respectively
␣
pΩ, F, P2
xq, pXptq : t ě 0q, pϑt : t ě 0q, pE, Eq
(
be the corresponding Markov processes.
For every f P DpLq, the process
fpXptqq ´ fpXp0qq ´
şt
0 LfpXpsqqds, t ě 0, is a martingale with respect to P1
x
as well as with respect to P2
x. Uniqueness implies P1
x “ P2
x and hence L1 “ L2.
The proof of Proposition 3.47 is complete now.
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
144 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.48. Corollary. Let L be a densely deﬁned linear operator with domain DpLq
and range RpLq in C0pEq. The following assertions are equivalent:
(i) Some extension of L generates a Feller semigroup.
(ii) For some extension of L the martingale problem is uniquely solvable for
every x P E.
Proof. (i) ùñ (ii). Let L0 be an extension of L that generates a Feller semi-
group. Let tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ be the corresponding
Markov process. For x P E the probability Px is the unique solution for the
martingale problem starting in x.
(ii) ùñ (i). Let L0 be an extension of L for which the martingale problem is
uniquely solvable for every x P E. Also suppose that L0 is maximal for this
property. Let tPx : x P Eu be the unique solution of the corresponding martin-
gale problem. Deﬁne the operators Pptq, t ě 0, by rPptqfs pxq “ Ex pfpXptqqq,
f P C0pEq. From the proof of Theorem 3.45 it follows that tPptq : t ě 0u is a
Feller semigroup with generator L0.
This completes the proof of Corollary 3.48.
□
3.49. Example. Let L0 be an unbounded generator of a Feller semigroup in
C0pEq and let µk and νk, 1 ď k ď n, be ﬁnite (signed) Borel measures on E.
Deﬁne the operator L⃗µ,⃗ν as follows:
D pL⃗µ,⃗νq “
nč
k“1
"
f P DpL0q :
ż
L0fdµk “
ż
fdνk
*
,
L⃗µ,⃗νf “ L0f,
f P D pL⃗µ,⃗νq .
Then the martingale problem is uniquely solvable for L⃗µ,⃗ν. In fact let
tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ
be the strong Markov process associated to the Feller semigroup generated by
L0. Then P “ Px solves the martingale problem
(a) For every f P DpL⃗µ,⃗νq the process
fpXptqq ´ fpXp0qq ´
ż t
0
L⃗µ,⃗νfpXpsqqds,
t ě 0,
is a P-martingale;
(b) PpXp0q “ xq “ 1,
uniquely. This can be seen as follows. We may and do suppose that the func-
tionals f ÞÑ
ş
L0fdµk ´
ş
fdνk, f P DpL0q, 1 ď k ď n, are linearly independent.
If some µk belongs to D pL˚
0q, then D pL⃗µ,⃗νq is not dense and if none of the
measures µk belongs to D pL˚
0q, then D pL⃗µ,⃗νq is dense in C0pEq. In either case
there exists a unique extension, in fact L0, of L⃗µ,⃗ν which generates a Feller semi-
group. Therefore we choose functions uk P DpL0q, 1 ď k ď n, in such a way
that
ş
L0ukdµℓ´
ş
ukdνℓ“ δk,ℓ, 1 ď k, ℓď n. Suppose that P1
x and P2
x are prob-
abilities, that start in x, with the property that for all f P D pL⃗µ,⃗νq the process
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
145 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
t ÞÑ fpXptqq ´ fpXp0qq ´
şt
0 L0fpXpsqqds is a P1
x- as well as a P2
x-martingale.
As in (3.110) we see that for all f P DpL0q (vk “ pλI ´ L0q uk, 1 ď k ď n):
fpxq ´
nÿ
k“1
ˆż
L0fdµk ´
ż
fdνk
˙
ukpxq
(3.131)
“
ż 8
0
e´λsE1
x
˜
pλI ´ L0q
˜
f ´
nÿ
k“1
ˆż
L0fdµk ´
ż
fdνk
˙
uk
¸
pXpsqq
¸
ds
“
ż 8
0
e´λsE2
x
˜
pλI ´ L0q
˜
f ´
nÿ
k“1
ˆż
L0fdµk ´
ż
fdνk
˙
uk
¸
pXpsqq
¸
ds.
Write f “ pλI ´ L0q´1 g “ Rpλqg. From (3.131) we obtain
Rpλqgpxq ´
nÿ
k“1
ˆż
pλRpλqg ´ gq dµk ´
ż
Rpλqgdνk
˙
ukpxq
(3.132)
“
ż 8
0
e´λsE1
x
«
gpXpsqq ´
nÿ
k“1
ˆż
pλRpλqg ´ gq dµk ´
ż
Rpλqgdνk
˙
vkpXpsqq
ﬀ
ds
“
ż 8
0
e´λsE2
x
«
gpXpsqq ´
nÿ
k“1
ˆż
pλRpλqg ´ gq dµk ´
ż
Rpλqgdνk
˙
vkpXpsqq
ﬀ
ds.
Put ÝÑ
F pλq “ pF1pλq, . . . , Fnpλqq and put Upλq “ puk,ℓpλqq, where, for 1 ď k ď n,
Fkpλq “
ż 8
0
e´λs `
E1
x rpλI ´ L0qukpXpsqqs ´ E2
x rpλI ´ L0qukpXpsqqs
˘
ds,
and where uk,ℓ, 1 ď k, ℓď n, is given by
uk,ℓpλq “
ż
λRpλquℓdµk ´
ż
uℓdµk ´
ż
Rpλquℓdνk.
Since (3.132) is valid for all g P C0pEq, it follows that ÝÑ
F pλq “ UpλqÝÑ
F pλq.
Since, in addition limλÑ8 Upλq “ 0, we see Fkpλq “ 0 for all λ ą 0 and
for 1 ď k ď n.
So that
ş8
0 e´λsE1
x pukpXpsqqq ds “
ş8
0 e´λsE2
x rukpXpsqqs ds
for all λ ą 0 and for all 1 ď k ď n. Again an application of (3.132) yields
E1
x rgpXpsqqs “ E2
x rgpXpsqqs for all g P C0pEq. Since these arguments are valid
for any x P E, we conclude just as in Proposition 2.9 and its Corollary on page
206 of Ikeda and Watanabe [61]), that P1
x “ P2
x “ Px, x P E, In particular
we may take E “ r0, 1s, L0f “ 1
2f 2, DpL0q “ tf P C2r0, 1s : f 1p0q “ f 1p1q “ 0u,
µk pIq “
şβk
αk 1Ipsqds, νk “ 0, 0 ď αk ă βk ď 1, 1 ď k ď n. Then L0 generates
the Feller semigroup of reﬂected Brownian motion: see Liggett [86], Example
5.8., p. 45. For the operator L⃗µ,⃗ν the martingale problem is uniquely (but not
maximally uniquely) solvable. However it does not generate a Feller semigroup.
The previous arguments do not seem to be entirely correct.
It ought to be
replaced with some results in Section 10 (e.g. Theorem 3.110).
Problem. We want to close this section with the following question. Suppose
that the operator L possesses a unique extension L0, that generates a Feller
semigroup. Is it true that for L the martingale problem is uniquely solvable?
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
146 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In general the answer is no, but if we require that L solves the martingale
problem maximally, then the answer is yes, provided as sample space we take
the Skorohod space. This result is proved in Theorem 3.45.
For the time being we will not pursue the Markov property. However, we will
continue with Brownian motion and stochastic integrals.
First we give the
deﬁnition of some interesting processes.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
147 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
4. Martingales, submartingales, supermartingales and
semimartingales
Let pΩ, F, Pq be a probability space and let tFt : t ě 0u be an increasing family
of σ-ﬁelds in F. If necessary we suppose that the ﬁltration tFt : t ě 0u is right
continuous, i.e. Ft “ Ş
sąt Fs, or complete in the sense that, for every t ą 0,
the σ-ﬁeld Ft contains all A P F, with PpAq “ 0.
Let tHptq : t ě 0u be a collection of R-valued functions deﬁned on Ω. Such a
family is called a (real-valued) process.
3.50. Definition. The following processes and σ-ﬁelds will play a role in the
sequel.
(a) The process tHptq : t ě 0u is said to be adapted or non-anticipating if,
for every t ě 0, the variable Hptq is measurable with respect to Ft.
(b1 The symbol Λ denotes the σ-ﬁeld (“ σ-algebra) of subsets of r0, 8qˆΩ,
which is generated by the adapted processes which are right-continuous
and which possess left limits. These are the so-called cadlag processes.
(b2) The process tHptq : t ě 0u is said to be optional if the function pt, ωq Ñ
Hpt, ωq is measurable with respect to Λ.
(c1) The symbol Π denotes the σ-ﬁeld of subsets of r0, 8q ˆ Ω, which is
generated by the adapted processes which are left-continuous adapted
processes.
(c2) The process tHptq : t ě 0u is said to be predictable if the function
pt, ωq Ñ Hpt, ωq is measurable with respect to Π.
3.51. Proposition. The collection tpa, bs ˆ A: 0 ď a ă b, A P Fau generates the
σ-ﬁeld Π.
Proof. Let A belong to Fa. The variable ω ÞÑ 1pa,bspsq1Apωq is measurable
with respect to Fs and the function s ÞÑ 1pa,bspsq1Apωq is left continuous. This
proves that pa, bs ˆ A belongs to Π.
Conversely let F be adapted and left continuous. Put
Fnps, ωq “
ÿ8
k“0 F
`
k2´n, ω
˘
1pk2´n,pk`1q2´nspsq “ F
`
pr2nss ´ 1q 2´n, ω
˘
.
Then, by left continuity, limnÑ8 Fnps, ωq “ Fps, ωq, P-almost surely. Moreover
the processes tFnptq : t ě 0u are adapted and are measurable with respect to
the σ-ﬁeld generated by tpa, bs ˆ A : 0 ď a ă b, A P Fau. All this completes the
proof of Proposition 3.51.
□
3.52. Remark. Since 1pa,bspsq ˆ 1Apωq “ lim
nÑ8 1ran,bnqpsq1Apωq, where an Ó a and
where bn Ó b, it follows that Π Ď Λ. Here we employ Proposition 3.51.
3.53. Definition. Let tXptq : t ě 0u be an adapted process.
(a) The family tXptq : t ě 0u is a martingale if E p|Xptq|q ă 8, t ě 0, and
if, for every t ą s ě 0, E pXptq | Fsq “ Xpsq, P-almost surely.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
148 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(b) The family tXptq : t ě 0u is a submartingale if E p|Xptq|q ă 8, t ě 0,
and if, for every t ą s ě 0, E pXptq | Fsq ě Xpsq, P-almost surely.
(c) The family tXptq : t ě 0u is a supermartingale if E p|Xptq|q ă 8, t ě 0,
and if, for every t ą s ě 0, E pXptq | Fsq ď Xpsq, P-almost surely.
(d) It is P-almost surely of ﬁnite variation (on r0, ts) if
sup
!ÿn
j“1 |Xptjq ´ Xptj´1q| : 0 ď t0 ă t1 ă . . . ă tn ă 8
)
ă 8,
´
sup
!ÿn
j“1 |Xptjq ´ Xptj´1q| : 0 ď t0 ă t1 ă . . . ă tn ď t
)
ă 8,
¯
P-almost surely.
(e) It is a local martingale if there exists an increasing sequence of stopping
times pTn : n P Nq for which limnÑ8 Tn “ 8, P-almost surely, and for
which the processes
tXpTn ^ tq : t ě 0u ,
n “ 1, 2, . . .
are martingales with respect to the ﬁltration tFTn^t : t ě 0u.
(f) Let T be a stopping time. The process tXptq : t ě 0u is a local martin-
gale on r0, Tq if there exists a sequence of stopping times pTn : n P Nq
which is increasing for which limnÑ8 Tn “ T, P-almost surely, and for
which the processes tXpTn ^ tq : t ě 0u, n “ 1, 2, . . . are martingales
with respect to the ﬁltration tFTn^t : t ě 0u.
(g) The deﬁnition of “local submartingale”, “local supermartingale” and
“being locally P-almost surely of ﬁnite variation” are now self-explan-
atory.
(h) The process tXptq : t ě 0u is called a semi-martingale if it can be writ-
ten in the form Xptq “ Mptq ` Aptq, where tMptq : t ě 0u is a mar-
tingale and where tAptq : t ě 0u is an adapted process which is ﬁnite
variation, P-almost surely, on r0, ts for every t ą 0, and for which
E |Aptq| ă 8, t ě 0.
(i) The process tXptq : t ě 0u is of class (DL) if for every t ą 0 the family
tXpτq : 0 ď τ ď t, τ is a pFtq -stopping timeu
is uniformly integrable.
3.54. Remark. Let tXptq : t ě 0u be a semi-martingale. The decomposition
Xptq “ Mptq ` Aptq, where tMptq : t ě 0u is a martingale and where for every
t ą 0 the process tAptq : t ě 0u is P-almost surely of ﬁnite variation and where
tAptq : t ě 0u is predictable and right continuous P-almost surely is unique,
provided Ap0q “ 0, P-almost surely. This follows from the fact that a right-
continuous martingale which is predictable and of ﬁnite variation is necessarily
constant: this is a consequence of the uniqueness part of the Doob-Meyer de-
composition: see Theorem 1.24.
A proof of the Doob-Meyer decomposition
theorem may start as follows. Put
Xjptq “ E
„
X
ˆr2jts
2j
˙ ˇˇˇ Ft
ȷ
and
(3.133)
Ajptq “ Ajp0q `
ÿ
0ďkă2jt
E
„
X
ˆk ` 1
2j
˙
´ X
ˆ k
2j
˙ ˇˇˇ Fk2´j
ȷ
,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
149 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
and prove Mjptq :“ Xjptq ´ Ajptq is a martingale. Then let j Ñ 8 to obtain:
Xptq “ Mptq ` Aptq, where Mptq “ limjÑ8 Mjptq and Aptq “ limjÑ8 Ajptq.
3.55. Remark. An Ft-martingale tMptq : t ě 0u is of class (DL), an increasing
adapted process tAptq : t ě 0u in L1pΩ, F, Pq is of class (DL) and hence the sum
tMptq ` Aptq : t ě 0u
is of class (DL). If tXptq : t ě 0u is a submartingale and if µ is a real number,
then the process tmax pXptq, µq : t ě 0u is a submartingale of class (DL). Pro-
cesses of class (DL) are important in the Doob-Meyer decomposition theorem.
We continue with some examples of martingales, submartingales and the like.
3.56. Example. Let T : ΩÑ r0, 8s be a stopping time. Since T is a stopping
time and since the process
␣
1tTătu : t ě 0
(
is left continuous, it is predictable.
It follows that the process
␣
1tTětu : t ě 0
(
is predictable as well.
3.57. Example. Let I be an open interval in R and let φ : I Ñ p´8, 8q be an
increasing convex function. If tXptq : t ě 0u is a submartingale with values in
I, then the process tφpXptqq : t ě 0u is also a submartingale. For let t ą s ě 0.
Then by the Jensen inequality and the monotonicity of φ it follows that
E rφpXptqq | Fss ě φ rE pXptq | Fsqs ě φ pXpsqq .
3.58. Example. Let pBptq, P0q be one-dimensional Brownian motion starting
in 0. Then tBptq : t ě 0u is a martingale. Since the deﬁnition of martingale also
makes sense for vector valued processes, we also see that an Rν-valued Brownian
motion is a martingale.
3.59. Example. Let pBptq, P0q be Rν-valued Brownian motion starting in 0.
The process
␣
|Bptq|2 ´ νt : t ě 0
(
is a martingale.
3.60. Example. Let tXptq, Pxu be a (strong) Markov process such that
Ex rfpXptqqs “
ż
ppt, x, yqfpyqdmpyq,
f ě 0,
where the density ppt, x, yq veriﬁes the Chapman-Kolmogorov identity:
pps ` t, x, yq “
ż
pps, x, zqppt, z, yqdmpzq.
The process tppt ´ s, Xpsq, yq : 0 ď s ă tu is a martingale on r0, tq. For example
for Xptq we may take Bptq, d-dimensional Brownian motion. Then
ppt, x, yq “ pdpt, x, yq “
1
`?
2πt
˘d exp
˜
´|x ´ y|2
2t
¸
.
3.61. Example. Let tXptq : t ě 0u be a right-continuous martingale and let T
be a stopping time. The process tX pT ^ tq : t ě 0u is a martingale with respect
to tFt : t ě 0u and also with respect to the ﬁltration tFT^t : t ě 0u.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
150 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.62. Example. This is a standard example of a closed martingale, i.e.
a
martingale which is written as conditional expectations on σ-ﬁelds taken from
a ﬁltration. Let Y be an random variable in L1 pΩ, F, Pq. The process s ÞÑ
E rY | Fss, s ě 0, is a martingale.
We want to insert an inequality on the second moment of a martingale. This is
a special case of the Burkholder-Davis-Gundy inequality.
3.63. Proposition. Let tMptq : t ě 0u be a continuous martingale with Mp0q “
0. Then
E
`
Mptq2˘
ď E
`
M ˚ptq2˘
ď 4E
`
Mptq2˘
.
Here M ˚ptq “ sup0ďsďt |Mpsq|.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
151 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Deﬁne for ξ ą 0 the stopping time Tξ by
Tξ “ inf tt ą 0 : M ˚ptq ě ξu .
Then tM ˚ptq ą ξu Ď tTξ ă tu and tTξ ă tu Ď tM ˚ptq ě ξu and hence, since
|Mptq| is a submartingale we obtain upon using Doob’s optional sampling
E
`
M ˚ptq2˘
“
ż 8
0
P
`
M ˚ptq2 ą λ
˘
dλ
(make the substitution λ “ ξ2)
“ 2
ż 8
0
ξP pM ˚ptq ą ξq dξ ď 2
ż 8
0
ξP pTξ ă tq dξ
“ 2
ż 8
0
E p|MpTξq| : Tξ ă tq dξ
(Doob’s optional sampling)
ď 2
ż 8
0
E p|Mptq| : Tξ ă tq dξ
“ 2
ż 8
0
E p|Mptq| : M ˚ptq ě ξq dξ
“ 2E p|Mptq| M ˚ptqq
(Cauchy-Schwarz’ inequality)
ď 2
`
E
`
Mptq2˘˘1{2 `
E
`
M ˚ptq2˘˘1{2 .
Consequently E pM ˚ptq2q ď 4E pMptq2q. This completes the proof of Proposition
3.63.
□
3.64. Remark. The method of works very well if E pM ˚ptq2q is ﬁnite. If this
is not the case we may use a localization technique. The reader should provide
the details. Perhaps truncating is also possible.
5. Regularity properties of stochastic processes
In Theorem 3.18 we proved that Brownian motion possesses a continuous ver-
sion. We want to amplify this result. In fact we shall prove that Brownian
motion has H¨older continuous paths of any order α ă 1
2. This means that for
every α ă 1
2 and for every a ą 0, a P R, there exists a random variable Cpbq,
depending on Brownian motion such that for all 0 ď s ă t ď a, the inequality
|bptq ´ bpsq| ď Cpbq |t ´ s|α
holds P-almost surely. This will be the content of Theorem 3.67 below. We
begin with a rather general result, due to Kolmogorov, for arbitrary stochastic
processes.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
152 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.65. Theorem. Fix a ﬁnite interval ra, bs. Let tXpsq : a ď s ď bu be a stochas-
tic process on the probability space pΩ, F, Pq. Suppose that there exist constants
K, r and p, such that 0 ă r ă p ă 8 and such that
E p|Xptq ´ Xpsq|pq ď K |t ´ s|1`r
(3.134)
for all a ď s, t ď b. Fix 0 ă α ă r{p. Then there exists a random variable
CpXq, which is ﬁnite P-almost surely, such that
|Xptq ´ Xpsq| ď CpXq |t ´ s|α
(3.135)
for all dyadic rational numbers s and t in the interval ra, bs. In particular it
follows that a process X “ tXpsq : a ď s ď bu verifying (3.134) has a H¨older
continuous version of order α, α ă r{p.
Proof. It suﬃces to prove (3.135), because the version problem can be
taken care of as in Theorem 3.18. Without loss of generality we may and do
suppose that a “ 0 and that b “ 1. Otherwise we consider the process Y deﬁned
by Y psq “ X ppa0 ` spb0 ´ a0qq, 0 ď s ď 1, where a0 and b0 are dyadic rational
with a0 ď a and with b ď b0 and where outside of the interval ra, bs the process
X is deﬁned by Xptq “ Xpaq, if a0 ď t ď a, and Xptq “ Xpbq, if b ď t ď b0.
Put ϵ “ r ´ αp. Then
P p|Xptq ´ Xpsq| ě |t ´ s|αq ď |t ´ s|´αp E p|Xptq ´ Xpsq|pq ď K |t ´ s|1`ϵ ,
(3.136)
so that
P
ˆˇˇˇˇX
ˆk ` 1
2n
˙
´ X
ˆ k
2n
˙ˇˇˇˇ ě 2´nα
˙
ď K2´n2´nϵ.
(3.137)
Hence
8
ÿ
n“1
2n´1
ÿ
k“0
P
ˆˇˇˇˇX
ˆk ` 1
2n
˙
´ X
ˆ k
2n
˙ˇˇˇˇ ě 2´nα
˙
ď K
8
ÿ
n“1
2n2´n2´nϵ “
K
2ϵ ´ 1.
(3.138)
By the Borel-Cantelli lemma it follows that
P
˜ 8
ď
m“1
č
něm
"
max
0ďkď2n´1
ˇˇˇˇX
ˆk ` 1
2n
˙
´ X
ˆ k
2n
˙ˇˇˇˇ ď 2´nα
*¸
“ 1.
(3.139)
Hence there exists a random integer νpXq with the following property: For
P-almost all ω the inequality
max
0ďkď2n´1
ˇˇˇˇX
ˆk ` 1
2n
˙
´ X
ˆ k
2n
˙ˇˇˇˇ ď 2´nα
(3.140)
is valid for n ě νpXq. Next let n ě νpXq and let t be a dyadic rational in the
interval rk2´n, pk ` 1q2´ns. Write t “ k2´n ` řm
j“1 γj2´n´j, each γj equals 0 or
1. Then
ˇˇˇˇXptq ´ X
ˆ k
2n
˙ˇˇˇˇ ď
m
ÿ
j“1
γj
2αpn`jq ď
1
2α ´ 1
1
2nα.
(3.141)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
153 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Similarly we have, with t “ ℓ2´N, N ě n, pk ` 1q2´n “ ℓ2´N ` řm1
j“1 γ1
j2´N´j,
γ1
j equals 0 or 1,
ˇˇˇˇXptq ´ X
ˆk ` 1
2n
˙ˇˇˇˇ ď
m1
ÿ
j“1
γ1
j
2αpN`jq ď
1
2α ´ 1
1
2Nα ď
1
2α ´ 1
1
2nα.
(3.142)
Next let s and t be dyadic rationale numbers with 0 ă t ´ s ď 2´νpXq. Take
n P N with 2´n´1 ď t´s ă 2´n and pick k in such a way that k2´n´1 ď s ă pk`
1q2´n´1. Then pk`1q2´n´1 ď t “ t´s`s ă 2´n `pk`1q2´n´1 “ pk`3q2´n´1.
It follows that, since t belongs to rpk ` 1q2´n´1, pk ` 2q2´n´1s or to the interval
rpk ` 2q2´n´1, pk ` 3q2´n´1s,
|Xptq ´ Xpsq|
ď
ˇˇˇˇXptq ´ X
ˆk ` 2
2n`1
˙ˇˇˇˇ `
ˇˇˇˇX
ˆk ` 2
2n`1
˙
´ X
ˆk ` 1
2n`1
˙ˇˇˇˇ `
ˇˇˇˇX
ˆk ` 1
2n`1
˙
´ Xpsq
ˇˇˇˇ
ď
3
2α ´ 12´pn`1qα ď
3
2α ´ 1 |t ´ s|α .
(3.143)
If 1 ě t´s ą 2´νpXq, we choose k and ℓP N in such a way that 2νpXq ą ℓą k ě 0
and that ℓ2´νpXq ă t ď pℓ` 1q2´νpXq and k2´νpXq ă s ď pk ` 1q2´νpXq. Then
we get
|Xptq ´ Xpsq| ď
ˇˇˇˇXptq ´ X
ˆℓ` 1
2νpXq
˙ˇˇˇˇ `
j“ℓ
ÿ
j“k
ˇˇˇˇX
ˆj ` 1
2νpXq
˙
´ X
ˆ
j
2νpXq
˙ˇˇˇˇ
`
ˇˇˇˇX
ˆ
k
2νpXq
˙
´ Xpsq
ˇˇˇˇ
ď 2 ` 2νpXq
2α ´ 1 2´ανpXq ď 2 ` 2νpXq
2α ´ 1
|t ´ s|α .
(3.144)
From (3.143) and (3.144) the result in Theorem 3.65 follows.
□
In order to apply the previous result to Brownian motion, we insert a general
equality for a Gaussian variable X.
3.66. Proposition. Let X : ΩÑ R be a non-constant Gaussian variable. Then
its distribution is given by
P pX P Bq “
1
`
2πE
`
X2 ´ pE pXqq2˘˘1{2
ż
B
exp
˜
´1
2
|x ´ EpXq|2
E pX2q ´ pE pXqq2
¸
dxq
(3.145)
and its moments E p|X ´ EpXq|pq, p ą ´1, are given by
E p|X ´ EpXq|pq “ 2
1
2 pΓ
`1
2p ` 1
2
˘
?π
ˆb
E
`
X2 ´ pEpXqq2˘˙p
.
(3.146)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
154 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Equality (3.145) follows from formula (3.8) and formula (3.146) is
proved by using (3.145). The formal arguments read (we write Y “ X ´EpXq):
E p|Y |pq “
1
p2πE pY 2qq1{2
ż
|y|p exp
ˆ
´1
2
y2
EpY 2q
˙
dy
“
´a
EpY 2q
¯p
2
?
2π
ż 8
0
yp exp
ˆ
´1
2y2
˙
dy
“
´a
EpY 2q
¯p 2
1
2pΓ
` 1
2p ` 1
2
˘
?π
.
The latter is the same as (3.146).
□
3.67. Theorem. Let tbpsq : s ě 0u be d-dimensional Brownian motion. This
process is P-almost surely H¨older continuous of order α for any α ă 1
2.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
155 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. It suﬃces to prove Theorem 3.67 for 1-dimensional Brownian mo-
tion. So suppose d “ 1 and let α ă 1{2. Choose p ą 1 so large that α ă 1
2 ´ 1
p.
From inequality (3.146) in Proposition 3.66 with X “ bptq ´ bpsq we obtain
E p|bptq ´ bpsq|pq “ E p|bpt ´ sq|pq “ Cp
`
E
`
|bpt ´ sq|2˘˘p{2
“ Cp |t ´ s|p{2 “ Cp |t ´ s|1`r ,
(3.147)
where r “ p{2 ´ 1 ą pα. An application of Theorem 3.65 yields the desired
result.
□
The following theorem says that Brownian motion is nowhere diﬀerentiable.
3.68. Theorem. Fix α ą 1
2. Then with probability one, t ÞÑ bptq is nowhere
H¨older continuous of order α. More precisely
P
ˆ
inf
0ďtď1
„
lim sup
hÑ0
|bpt ` hq ´ bptq|
|h|α
ȷ
“ 8
˙
“ 1.
Proof. For a proof we refer the reader to the literature; e.g. Simon [[121],
Theorem 5.4. p. 46].
□
In the theory of stochastic integration we will have a need for the following
lemma. The following lemma can also be proved by the strong law of large
numbers: see e.g. Smythe [123].
3.69. Lemma. Let tbpsq : s ě 0u be one-dimensional Brownian motion. Then,
P-almost surely, limnÑ8
ř2n´1
k“0 |b ppk ` 1q2´ntq ´ b pk2´ntq|2 “ t.
Proof. Put △k,n “ |b ppk ` 1q2´ntq ´ b pk2´ntq|2´2´nt. Then the variables
△k,n, 0 ď k ď 2n ´ 1, are independent and have expectation 0. So that
E
˜2n´1
ÿ
k“0
△k,n
¸2
“
2n´1
ÿ
k“0
E p△k,nq2 “
2n´1
ÿ
k“0
E
´ˇˇb
`
2´nt
˘ˇˇ2 ´ 2´nt
¯2
“ 2n ´
E
ˇˇb
`
2´nt
˘ˇˇ4 ´ 2E
ˇˇb
`
2´nt
˘ˇˇ2 2´nt ` 2´2nt2¯
“ 2 ˆ 2´nt2.
(3.148)
Tchebychev’s inequality gives
P
¨
˝
˜2n´1
ÿ
k“0
△k,n
¸2
ą ϵ
˛
‚ď 2
ϵt22´n.
Hence
8
ÿ
n“1
P
¨
˝
˜2n´1
ÿ
k“0
△k,n
¸2
ą ϵ
˛
‚ď 2t2
ϵ . Thus we may apply the Borel-Cantelli
lemma to prove the claim in Lemma 3.69.
□
3.70. Proposition. Brownian motion is nowhere of bounded variation.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
156 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Just as in the previous lemma we have that, for t ą s ě 0,
lim
nÑ8
2n´1
ÿ
k“0
ˇˇb
`
s ` pk ` 1q2´npt ´ sq
˘
´ b
`
s ` k2´npt ´ sq
˘ˇˇ2 ´ pt ´ sq “ 0,
P-almost surely. Since Brownian paths are almost surely continuous it follows
that (for δ ą 0)
0 ă t ´ s ď lim
nÑ8
2n´1
ÿ
k“0
ˇˇb
`
s ` pk ` 1q2´npt ´ sq
˘
´ bp
`
s ` k2´npt ´ sq
˘ˇˇ2
ď lim inf
nÑ8
max
0ďℓď2n
ˇˇb
`
s ` pℓ` 1q2´npt ´ sq
˘
´ bp
`
s ` ℓ2´npt ´ sq
˘ˇˇ
ˆ
2n´1
ÿ
k“0
ˇˇb
`
s ` pk ` 1q2´npt ´ sq
˘
´ bp
`
s ` k2´npt ´ sq
˘ˇˇ
ď
sup
sďσ1,σ2ďt,|σ2´σ1|ďδ
|bpσ2q ´ bpσ1q| ˆ variation of b on the interval rs, ts.
The statement in the Proposition 3.70 now follows from the continuity of paths.
□
Next we will see how to transfer properties of discrete time semi-martingales
to continuous time semi-martingales. Most of the results in the remainder of
this section are taken from Bhattacharya and Waymire [15]. We begin with an
upcrossing inequality for a discrete time sub-martingale. Consider a sequence
tZn : n P Nu of real-valued random variables and sigma-ﬁelds F1 Ă F2 Ă ¨ ¨ ¨ ,
such that, for every n P N, the variable Zn is Fn-measurable. An upcrossing of
an interval pa, bq by tZnu is a passage to a value equal to or exceeding b from an
value equal to or below a at an earlier time. Deﬁne the random variables Xn,
n P N, by Xn “ max pZn ´ a, 0q. If the process tZnu is a sub-martingale, then
so is the process tXnu. The upcrossings of p0, b´aq by tXnu are the upcrossings
of the interval pa, bq by tZnu. We deﬁne the successive upcrossing times η2k,
k P N, of tXnu as follows:
η1 “ inf tn ě 1 : Xn “ 0u ;
η2 “ inf tn ě η1 : Xn ě b ´ au ;
η2k`1 “ inf tn ě η2k : Xn “ 0u ;
η2k`2 “ inf tn ě η2k`1 : Xn ě b ´ au .
Then every ηk is an tFnu-stopping time. Fix N P N and put τk “ min pηk, Nq.
Then every τk is also a stopping time and τk “ N for k ą tN{2u, the largest
integer smaller than or equal to N{2. It follows that Xτ2k “ XN for k ą tn{2u
and we also have ηk ě k and so k ď τk ď N. Let UNpa, bq be the number of
upcrossings of pa, bq by the process tZnu at time N. That means
UNpa, bq “ sup tk ě 1 : η2k ď Nu
(3.149)
with the convention that the supremum over the empty set is 0. Notice that
UNpa, bq is also the number of upcrossings of the interval p0, b ´ aq by tXnu in
time N.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
157 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.71. Proposition (Upcrossing inequality). Let tZnu be an tFnu-submartin-
gale. For each pair pa, bq, a ă b, the expected number of upcrossings of pa, bq by
Z1, . . . , ZN satisﬁes the inequality:
E pUNpa, bqq ď E pmax pZN ´ a, 0q ´ max pZ1 ´ a, 0qq
b ´ a
ď E pmax pZN ´ Z1, 0qq
b ´ a
.
(3.150)
Proof. Since Xτ2k “ XN for k ą tN{2u, we may write (setting τ0 “ 1):
XN ´ X1 “
tN{2u`1
ÿ
k“1
`
Xτ2k´1 ´ Xτ2k´2
˘
`
tN{2u`1
ÿ
k“1
`
Xτ2k ´ Xτ2k´1
˘
.
(3.151)
Next let ν be the largest integer k with the property that ηk ď N, i.e. ν is
the last time ď N of an upcrossing or a downcrossing. It readily follows that
UNpa, bq “ tν{2u. If ν is even, then
Xτ2k ´ Xτ2k´1 ě b ´ a
provided
2k ´ 1 ă ν;
Xτ2k ´ Xτ2k´1 “ XN ´ XN “ 0
provided
2k ´ 1 ą ν.
(3.152)
Now suppose that ν is odd. Then we have
Xτ2k ´ Xτ2k´1 ě b ´ a
provided
2k ´ 1 ă ν;
Xτ2k ´ Xτ2k´1 “ Xτ2k ´ Xν ě Xτ2k ´ 0 “ Xτ2k
provided
2k ´ 1 “ ν;
Xτ2k ´ Xτ2k´1 “ XN ´ XN “ 0
provided
2k ´ 1 ą ν.
(3.153)
From (3.152) and (3.153) it follows that
tN{2u`1
ÿ
k“1
`
Xτ2k ´ Xτ2k´1
˘
ě
tν{2u
ÿ
k“1
`
Xτ2k ´ Xτ2k´1
˘
ě tν{2upb ´ aq “ pb ´ aqUNpa, bq.
(3.154)
Consequently
XN ´ X1 ě
tN{2u`1
ÿ
k“1
`
Xτ2k´1 ´ Xτ2k´2
˘
` pb ´ aqUNpa, bq.
(3.155)
So far we did not make use of the fact that the process tXnu is a sub-martingale.
It then follows that the process tXτk : k P Nu is a tFτnu-martingale and hence
k ÞÑ E pXτkq is an increasing sequence of non-negative real numbers. So that
(3.155) yields
E pXN ´ X1q ě
tN{2u`1
ÿ
k“1
E
`
Xτ2k ´ Xτ2k´1
˘
` pb ´ aqE pUNpa, bqq
ě pb ´ aqE pUNpa, bqq .
(3.156)
The desired result in Proposition 3.71 follows from (3.156).
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
158 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.72. Theorem. (Sub-martingale convergence theorem) Let tZnu be a sub-mar-
tingale with the property that supnPN E p|Zn|q ă 8. Then the sequence tZnu
converges almost surely to an integrable random variable Z8. Moreover we have
E p|Z8|q ď lim infnÑ8 E p|Zn|q.
3.73. Remark. In general we do not have E pZ8q “ limnÑ8 E pZnq. In fact
there exist martingales tMn : n P Nu such that Mn ě 0, such that EpMnq “ 1,
n P N, and such that M8 “ limnÑ8 Mn “ 0, P-almost surely. To be speciﬁc,
let tbpsq : s ě 0u be ν-dimensional Brownian motion starting at x P Rν and let
ppt, x, yq be the corresponding transition density. Fix t ą 0 and y ­“ x and put
Mn “ p pt{n, bpt ´ t{nq, yq
ppt, x, yq
.
(3.157)
The process tMn : n P Nu deﬁned in (3.157) is Px-martingale with respect to
the sigma-ﬁelds Fn generated by bpsq, 0 ď s ď t ´ t{n.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
159 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Let Upa, bq be the total number of upcrossings of pa, bq by the pro-
cess tZn : n P Nu. Then UNpa, bq Ò Upa, bq as N Ò 8. Therefore, by monotone
convergence,
E
`
pUpa, bq
˘
“ lim
NÑ8 E pUNpa, bqq ď sup
NPN
E p|ZN|q ` |a|
b ´ a
ă 8.
(3.158)
In particular it follows that Upa, bq ă 8 P-almost surely. Hence
P plim inf Zn ă a ă b ă lim sup Znq ď P pUpa, bq “ 8q “ 0.
(3.159)
Since
tlim inf Zn ă lim sup Znu “
ď
aăb,a,bPQ
tlim inf Zn ă a ă b ă lim sup Znu
it follows from (3.159) that P plim inf Zn ă lim sup Znq “ 0. By Fatou’s lemma
it follows that E p|Z8|q “ E plim infn |Zn|q ď lim inf E p|Zn|q ă 8.
This completes the proof of Theorem 3.72.
□
3.74. Corollary. A non-negative martingale tZnu converges almost surely to
a ﬁnite limit Z8. Also E pZ8q ď E pZ1q.
Remark. Convergence properties for supermartingales tZnu are obtained from
the sub-martingale results applied to t´Znu.
Since a semi-martingale is a
diﬀerence of two sub-martingales, we also have convergence results for semi-
martingales.
3.75. Definition. A continuous time process tXptq : t P Ru is called stochasti-
cally continuous at t0 if for every ε ą 0
lim
tÑt0 P p|Xptq ´ Xpt0q| ą εq “ 0.
(3.160)
3.76. Remark. Brownian motion possesses almost surely continuous sample
paths and is stochastically continuous for every t ě 0.
On the other hand
a Poisson process is stochastically continuous, but its sample paths are step
functions with unit jumps. In fact, for t ą s, Xptq ě Xpsq P-almost surely and,
again for t ą s, P pXptq ´ Xpsq “ nq “ e´λpt´sq
`
λpt ´ sq
˘n
n!
and hence, always
for t ą s and for ϵ ą 0,
P pXptq ´ Xpsq ě ϵq ď e´λpt´sq
8
ÿ
n“1
`
λpt ´ sq
˘n
n!
“ 1 ´ e´λpt´sq.
3.77. Theorem. Let tXptq : t ě 0u be a sub-martingale or a super-martingale
that is stochastically continuous at each t ě 0.
Then there exists a process
!
r
Xptq : t ě 0
)
with the following properties:
(i) (stochastic equivalence)
!
r
Xptq
)
is equivalent to tXptqu in the sense
that
P
´
r
Xptq “ Xptq
¯
“ 1
for every
t ě 0;
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
160 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
(ii) (sample path regularity) with probability 1 the sample paths of the pro-
cess
!
r
Xptq : t ě 0
)
are bounded on compact intervals ra, bs, a ă b ă 8,
are right-continuous and possess left-hand limits at each t ą 0 (in other
words
!
r
Xptq : t ě 0
)
is cadlag).
Proof. Fix T ą 0 and let QT denote the set of rational numbers in r0, Ts.
Write QT “ Ť8
n“1 Rn, where Rn is a ﬁnite subset of r0, Ts and where T P R1 Ă
R2 Ă R2 Ă ¨ ¨ ¨ . By Doob’s maximal inequality for sub-martingales we have
P
ˆ
max
tPRn |Xptq| ą λ
˙
ď E |XpTq|
λ
,
n “ 1, 2, . . .
and hence
P
ˆ
sup
tPQT
|Xptq| ą λ
˙
ď lim
nÑ8 P
ˆ
max
tPRn |Xptq| ą λ
˙
ď E |XpTq|
λ
,
n “ 1, 2, . . .
For Doob’s maximal inequality see e.g. Proposition 3.107 or Theorem 5.110.
In particular, the paths of tXptq : t P QTu are bounded with probability 1. Let
pc, dq be any interval in R and let U tTupc, dq denote the number of upcrossings of
pc, dq by the process tXptq : t P QTu. Then U tTupc, dq is the limit of the number
U tnupc, dq of upcrossings of pc, dq by tXptq : t P Rnu as n tends to 8. By the
upcrossing inequality we have
E
`
U tnupc, dq
˘
ď E p|XpTq|q ` |c|
d ´ c
.
(3.161)
Since U tnupc, dq increases with n it follows from (3.161) that
E
`
U tTupc, dq
˘
ď E p|XpTq|q ` |c|
d ´ c
,
(3.162)
and hence that U tTupc, dq is almost surely ﬁnite. Taking unions over all intervals
pc, dq, with c, d P Q, and c ă d, it follows with probability 1 that the process
tXptq : t P QTu has only ﬁnitely many upcrossings of any interval. In particular,
therefore, left- and right-hand limits must exist at each t ă T P-almost surely.
To construct a right-continuous version of tXptqu we deﬁne
!
r
Xptq : t ě 0
)
as
follows: r
Xptq “ limsÓt,sPQ Xpsq for t ă T. That this process
!
r
Xptq
)
is stochas-
tically equivalent to tXptqu follows from the stochastic continuity of the process
tXptqu.
Further details are left to the reader.
This completes the proof of
Theorem 3.77.
□
Next we prove Doob’s optional sampling for continuous time sub-martingales
(that are right-continuous) and a similar result holds for martingales (where the
inequality sign in (3.163) is replaced with an equality) and for super-martingales
(where the inequality is reversed). For discrete sub-martingales the result will
be taken for granted: see Theorems 5.104 and 5.114.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
161 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.78. Theorem. Let tXptq : t ě 0u be a right-continuous sub-martingale of class
(DL) and let T be a stopping time. Suppose t ě s. Then
E
“
X
`
minpt, Tq
˘ ˇˇ Fs
‰
ě X
`
minps, Tq
˘
,
P-almost surely.
(3.163)
Proof. Put sn “ 2´nr2nss, tn “ 2´nr2nts and Tn “ 2´nr2nTs. If A belongs
to Fs, then A also belongs to Fsn for all n P N. From Doob’s optional sampling
for discrete time sub-martingales we infer, upon using the (DL)-property,
E rX pminptn, Tnqq 1As ě E rX pminpsn, Tnqq 1As .
(3.164)
Upon letting n tend to 8 and using the right-continuity of the process t ÞÑ Xptq,
t ě 0, we infer
E rX pminpt, Tqq 1As ě E rX pminps, Tqq 1As ,
(3.165)
where A P Fs is arbitrary.
Consequently the result in (3.163) follows from
(3.165), and so the proof of Theorem is complete 3.78.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
162 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
6. Stochastic integrals, Itˆo’s formula
The assumptions are as in Section 4. The process tbptq : t ě 0u is assumed to
be one-dimensional Brownian motion and hence the process t ÞÑ bptq2 ´ t is a
martingale: see Proposition 3.23. The following proposition contains the basic
ingredients of (the deﬁnition of) a stochastic integral.
3.79. Proposition. Let s1, . . . , sn and t1, . . . , tn be non-negative numbers for
which sj´1 ă tj´1 ď sj ă tj, 2 ď j ď n. Let f1, . . . , fn be bounded random
variables which are measurable with respect to Fs1, . . . , Fsn respectively. Put
Y ps, ωq “
ÿn
j“1 fjpωq1psj,tjspsq
and write
ż t
0
Y ps, ¨qdbpsq “
ÿn
j“1 fj tbpminpt, tjqq ´ bpminpt, sjqqu .
The following assertions hold true:
(a) The process
!şt
0 Y psqdbpsq : t ě 0
)
is a martingale and the process
"´şt
0 Y psqdbpsq
¯2
: t ě 0
*
is a submartingale.
(b) The process
"´şt
0 Y psqdbpsq
¯2
´
şt
0 Y psq2ds : t ě 0
*
is a martingale.
(c) (Itˆo isometry) The following equality is valid:
E
«ˆż t
0
Y psqdbpsq
˙2ﬀ
“ E
„ż t
0
Y psq2ds
ȷ
.
(3.166)
The equality in assertion (c) is called the Itˆo isometry.
It is an extremely
important equality: the entire Itˆo calculus is justiﬁed by the use of the equality
in (3.166).
Proof. The more or less straightforward calculations are left as an exercise
to the reader. We insert some ways to simplify the computations. Let F and G
be predictable processes of the form Fpsq “ f1pu,8qpsq and Gpsq “ g1pv,8qpsq,
where f is measurable for the σ-ﬁeld Fu and g for Fv. Put
ItpFq “
ż t
0
Fpsqdbpsq :“ f pbptq ´ bpminpu, tqqq
and similarly write
ItpGq “
ż t
0
Gpsqdbpsq “ g pbptq ´ bpminpv, tqqq .
Without loss of generality we assume v ě u (otherwise we interchange the
role of F and G). We begin with a proof of (a). Upon employing linearity it
suﬃces to show that the process t ÞÑ ItpFq is a martingale. (Also notice that
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
163 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
şt
0 f1pu,vspsqdbpsq “ ItpFq ´ ItpF1q, where F1psq “ f1pv,8qpsq.) Fix t ą s ě 0 and
consider
E
`
ItpFq
ˇˇ Fs
˘
´ IspFq “ E
`
ItpFq ´ IspFq
ˇˇ Fs
˘
“ E
`
f pbptq ´ bpminpu, tqq ´ bpsq ` bpminpu, sqqq
ˇˇ Fs
˘
“ E
`
E
`
f pbptq ´ bpminpu, tqq ´ bpsq ` bpminpu, sqqq
ˇˇ Fminpmaxpu,sq,tq
˘ ˇˇ Fs
˘
“ E
`
fE
`
pbptq ´ bpminpu, tqq ´ bpsq ` bpminpu, sqqq
ˇˇ Fminpmaxpu,sq,tq
˘ ˇˇ Fs
˘
(Brownian motion is a martingale)
“ E
`
f ppbpminpmaxpu, sq, tqq ´ bpminpu, tqq ´ bpsq ` bpminpu, sqqqq
ˇˇ Fs
˘
“ 0,
proving that the process t ÞÑ ItpFq is a martingale indeed.
Next we shall
prove that the process t ÞÑ ItpFqItpGq ´
şt
0 FpτqGpτqdτ is a martingale. Using
bilinearity in F and G yields a proof of (b) and hence also of (c). Again we ﬁx
t ą s and consider
E
ˆ
ItpFqItpGq ´
ż t
0
FpτqGpτqdτ
ˇˇ Fs
˙
´
ˆ
IspFqIspGq ´
ż s
0
FpτqGpτqdτ
˙
“ E
ˆ
ItpFqItpGq ´
ż t
0
FpτqGpτqdτ ´
ˆ
IspFqIspGq ´
ż s
0
FpτqGpτqdτ
˙ ˇˇ Fs
˙
“ E
ˆ
pItpFq ´ IspFqq pItpGq ´ IspGqq ´
ż t
s
FpτqGpτqdτ
ˇˇ Fs
˙
` E
`
IspFq pItpGq ´ IspGqq ` pItpFq ´ IspFqq IspGq
ˇˇ Fs
˘
“ E
ˆ
pItpFq ´ IspFqq pItpGq ´ IspGqq ´
ż t
s
FpτqGpτqdτ
ˇˇ Fs
˙
` IspFqE
`
ItpGq ´ IspGq
ˇˇ Fs
˘
` E
`
ItpFq ´ IspFq
ˇˇ Fs
˘
IspGq
(use the martingale property of ItpFq and ItpGq)
“ E
„
pItpFq ´ IspFqq pItpGq ´ IspGqq ´
ż t
s
FpτqGpτq dτ
ˇˇ Fs
ȷ
“ E
“
fg pbptq ´ b pminpmaxpu, sq, tqqq
`
bptq ´ b
`
minpmaxpv, sq, tq
˘˘
´fg pt ´ minpmaxpu, v, sq, tqq
ˇˇ Fs
‰
(use v ě u and put us,t “ minpmaxpu, sq, tq, vs,t “ minpmaxpv, sq, tq)
“ E
”
fg
´`
bptq ´ b
`
vs,t
˘˘2
`fg
`
b
`
vs,t
˘
´ b
`
us,t
˘˘ `
bptq ´ b
`
vs,t
˘˘
´ fg pt ´ minpmaxpu, v, sq, tqq
ˇˇ Fs
˘‰
“ E
”
fg
´`
bptq ´ b
`
vs,t
˘˘2 ´ pt ´ vs,tq
¯ ˇˇ Fs
ı
` E
“`
fg
`
b
`
vs,t
˘
´ b
`
us,t
˘˘ `
bptq ´ b
`
vs,t
˘˘˘ ˇˇ Fs
‰
“ E
”
fgE
”´`
bptq ´ b
`
vs,t
˘˘2 ´ pt ´ vs,tq
¯ ˇˇ Fvs,t
ı ˇˇ Fs
ı
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
164 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
` E
“
fg
`
b
`
vs,t
˘
´ b
`
us,t
˘˘
ˆ E
“`
bptq ´ b
`
vs,t
˘˘ ˇˇ Fvs,t
‰ ˇˇ Fs
‰
(the processes tbpsqu and tbpsq2 ´ su are martingales)
“ E
`
fg.0
ˇˇ Fs
˘
` E
`
fg
`
b
`
vs,t
˘
´ b
`
us,t
˘˘
.0
ˇˇ Fs
˘
“ 0.
The latter yields a proof of (b) (via bilinearity). Altogether this ﬁnishes the
proof of Proposition 3.79.
□
3.80. Definition. A process of the form
Fps, ωq “
ÿn
j“1 fjpωq1psj,tjspsq,
where 0 ď sj´1 ă tj´1 ď sj ă tj, 2 ď j ď n, and where the functions f1, . . . , fn
are bounded and measurable with respect to Fs1, . . . , Fsn respectively is called
a simple predictable process.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
165 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.81. Definition. Again let b be Brownian motion with drift zero and let Π2pbq
be the vector space of all predictable processes F with the property that
}F}2
b :“ E
ˆż 8
0
|Fpsq|2 ds
˙
ă 8.
Let Q be the σ-additive measure, deﬁned on the predictable ﬁeld Π, determined
by
Q pA ˆ ps, tsq “ E r1As pt ´ sq “ PpAqpt ´ sq,
A P Fs.
(3.167)
The measure Q is called the Dol´eans measure for Brownian motion.
Then it follows that Π2pbq “ L2 pr0, 8q ˆ Ω, Π, Qq. Moreover we have
}F}2
b “
ż
|F|2 dQ,
F P Π2pbq.
It also follows that, for given F P Π2pbq, there exists a sequence of simple
processes pFn : n P Nq, which are predictable, such that limnÑ8 }Fn ´ F}b “ 0.
Hence in view of Proposition 3.79 it is obvious how to deﬁne
şt
0 Fpsq dbpsq, t ě 0,
for F P Π2pbq. In fact
ż t
0
Fpsqdbpsq “ L2- lim
nÑ8
ż t
0
Fnpsqdbpsq,
where the sequence pFn : n P Nq veriﬁes limnÑ8 }Fn ´ F}b “ 0 and where Fn
belongs to Π2pbq. Let Π3pbq be the vector space of all predictable processes F for
which the integrals
şt
0 |Fpsq|2 ds are ﬁnite P-almost surely for all t ą 0. In order
to extend the deﬁnition of stochastic integral to processes F P Π3pbq we proceed
as follows. Deﬁne the stopping times Tn, n P N, in the following fashion:
Tn “ inf
"
t ą 0 :
ż t
0
|Fpsq|2 ds ą n
*
.
(3.168)
We also write Fnpsq “ Fpsq1tTnąsu and we observe that Fn is a predictable
process with
ş
|Fnpsq|2 ds ď n. Moreover it follows that for n ą m the expression
ż t
0
Fnpsqdbpsq ´
ż t
0
Fmpsqdbpsq “
ż
Fpsq1pTm,minpTn,tqspsqdbpsq
(3.169)
vanishes almost everywhere on the event tTm ą tu. So it makes sense to write
ż t
0
Fpsqdbpsq “
ż t
0
Fmpsqdbpsq,
on
tTm ą tu.
Since limnÑ8 Tn “ 8, P-almost surely, the quantity
şt
0 Fpsqdbpsq is unambigu-
ously deﬁned. Hence the integral
ş
Fpsqdbpsq is well deﬁned for processes F
belonging to Π3pbq.
3.82. Corollary. Let b be Brownian motion and let F and G be processes in
Π3pbq. The following processes are local martingales:
"ż t
0
Fpsqdbpsq : t ě 0
*
,
"ż t
0
Gpsqdbpsq : t ě 0
*
;
(3.170)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
166 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
#ˆż t
0
Fpsqdbpsq
˙2
´
ż t
0
|Fpsq|2 ds : t ě 0
+
;
(3.171)
"ż t
0
Fpsqdbpsq
ż t
0
Gpsqdbpsq ´
ż t
0
FpsqGpsqds : t ě 0
*
.
(3.172)
Put Xptq “
şt
0 Fpsqdbpsq and Y ptq “
şt
0 Gpsqdbpsq. The following identity is
valid:
XptqY ptq ´
ż t
0
FpsqGpsqds “
ż t
0
FpsqY psqdbpsq `
ż t
0
XpsqGpsqdbpsq.
(3.173)
Proof. The assertions (3.170), (3.171) and (3.172) follow from Proposition
3.79 together with taking appropriate limits. For the proof of (3.173) we ﬁrst
take F ” G ” 1. Then (3.173) reduces to showing that
bptq2 ´ 2
ż t
0
bpsqdbpsq ´ t “ 0.
(3.174)
Notice that (3.174) is equivalent to 2
şt
0 bpsqdbpsq “ bptq2 ´ t,
t ě 0. For the
proof of (3.174) we use Lemma 3.69. to conclude:
bptq2 ´ 2
ż t
0
bpsqdbpsq ´ t
“ lim
nÑ8
˜
bptq2 ´ 2
2n´1
ÿ
k“0
b
`
k2´nt
˘ `
b
`
pk ` 1q2´nt
˘
´ b
`
k2´nt
˘
´ t
˘
¸
“ lim
nÑ8
˜2n´1
ÿ
k“0
´
b
`
pk ` 1q2´nt
˘2 ´ b
`
k2´nt
˘2¯
´2
2n´1
ÿ
k“0
b
`
k2´nt
˘ `
b
`
pk ` 1q2´nt
˘
´ b
`
k2´n˘˘
´ t
¸
“ lim
nÑ8
˜2n´1
ÿ
k“0
`
b
`
pk ` 1q2´nt
˘
´ b
`
k2´nt
˘˘2 ´ t
¸
“ 0.
For the proof of (3.173) we then take Fpsq “ f1ps1,8qpsq and Gpsq “ g1ps2,8q,
where f is bounded and measurable with respect to Fs1 and g is measurable
with respect to Fs2. Formula (3.174) will then yield the desired result. Then we
pass over to linear combinations and ﬁnally to limits. This completes the proof
of Corollary 3.82.
□
3.83. Proposition. Stochastic integrals with integrands in Π3pbq are continuous
P-almost surely.
Proof. It suﬃces to prove the result for integrands in Π2pbq. Since Brow-
nian motion is almost surely continuous, it follows that stochastic integrals of
simple predictable processes are continuous. Let F be in Π2pbq and choose a
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
167 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
sequence pFnqnPN of simple predictable processes with the property that
ˆ
E
ˆż t0
0
|Fpsq ´ Fnpsq|2 ds
˙˙1{2
“ lim
ℓÑ8
ˆ
E
ˆż t0
0
|Fn`ℓpsq ´ Fnpsq|2 ds
˙˙1{2
ď
8
ÿ
ℓ“1
ˆ
E
ˆż t0
0
|Fn`ℓpsq ´ Fn`ℓ´1psq|2 ds
˙˙1{2
ď
8
ÿ
ℓ“1
2´n´ℓ´2 “ 2´n´1.
From Proposition 3.63 it follows that, for k P N,
˜
E
«
sup
0ďtďt0
ˇˇˇˇ
ż t
0
pFn`kpsq ´ Fnpsqq dbpsq
ˇˇˇˇ
2ﬀ¸ 1
2
ď
kÿ
ℓ“1
˜
E
«
sup
0ďtďt0
ˇˇˇˇ
ż t
0
pFn`ℓpsq ´ Fn`ℓ´1psqq dbpsq
ˇˇˇˇ
2ﬀ¸ 1
2
ď 2
8
ÿ
ℓ“1
˜
E
«ˇˇˇˇ
ż t0
0
pFn`ℓpsq ´ Fn`ℓ´1psqq dbpsq
ˇˇˇˇ
2ﬀ¸ 1
2
“ 2
8
ÿ
ℓ“1
ˆ
E
„ż t0
0
|Fn`ℓpsq ´ Fn`ℓ´1psq|2 ds
ȷ˙ 1
2
ď 2´n.
(3.175)
From (3.175) the sample path continuity of stochastic integrals immediately
follows. This completes the proof of Proposition 3.83.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

Advanced stochastic processes: Part I
168 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.84. Remark. The theory in this section can be extended to (continuous)
martingales instead of Brownian motion. To be precise, let t ÞÑ Mptq be a
continuous martingale with quadratic variation process t ÞÑ ⟨M, M⟩ptq. Then
the process t ÞÑ Mptq2 ´ ⟨M, M⟩ptq is a martingale, and the space Π2pbq should
be replaced with Π2pMq, the space of all predictable processes t ÞÑ Fptq with
the property that
}F}2
M “ E
„ż 8
0
|Fpsq|2 d ⟨M, M⟩psq
ȷ
ă 8.
(3.176)
The corresponding Dol´eans measure QM is given by
QM pA ˆ ps, tsq “ E r1A p⟨M, M⟩ptq ´ ⟨M, M⟩psqqs ,
A P Fs,
s ă t. (3.177)
It follows that
Π2pMq “ L2 pΩˆ r0, 8q, Π, QMq .
The space Π3pMq consists of those predictable processes t ÞÑ Fptq which have
the property that
şt
0 |Fpsq|2 d ⟨M, M⟩s are ﬁnite P-almost surely for all t ą 0.
The deﬁnition of stochastic integral to processes F P Π3pMq we proceed as
follows. Deﬁne the stopping times Tn, n P N, in the following fashion:
Tn “ inf
"
t ą 0 :
ż t
0
|Fpsq|2 d ⟨M, M⟩psq ą n
*
.
(3.178)
As in the case of Brownian motion these stopping times can be used to deﬁne
stochastic integrals of the form
şt
0 Fpsq dMpsq, F P Π3pMq. These integrals are
then local martingales.
Next we extend the equality in (3.173) to the multi-dimensional situation.
3.85. Proposition. Let s ÞÑ σpsq “ pσjkpsqq1ďj,kďν be a matrix with predictable
entries and with the property that the expression
νÿ
j,k“1
ż t
0
E |σjkpsq|2 ds
(3.179)
is ﬁnite for every t ą 0. Put aijpsq “ řν
k“1 σikpsqσjkpsq, 1 ď i, j ď ν. Further-
more let tbpsq “ pb1psq, . . . , bνpsqq : s ě 0u be ν-dimensional Brownian motion.
Put Mjptq “ řν
k“1
şt
0 σjkpsqdbkpsq, 1 ď j ď ν. Then the following identity is
valid:
MiptqMjptq
(3.180)
“
νÿ
k“1
ż t
0
Mipsqσjkpsqdbkpsq `
νÿ
k“1
ż t
0
σikpsqMjpsqdbkpsq `
ż t
0
aijpsqds.
Proof. First we suppose ν “ 2, M1ptq “ b1ptq and M2ptq “ b2ptq. Then
(3.180) reads as follows:
b1ptqb2ptq “
ż t
0
b1psqdb2psq `
ż t
0
b2psqdb1psq.
(3.181)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
169 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In order to prove (3.181) we write
b1ptqb2ptq ´
ż t
0
b1psqdb2psq ´
ż t
0
b2psqdb1psq
“ lim
nÑ8
2n´1
ÿ
k“0
#
b1
`
pk ` 1q2´nt
˘
b2
`
pk ` 1q2´nt
˘
´ b1
`
k2´nt
˘
b2
`
k2´nt
˘
´ b1
`
k2´nt
˘ `
b2
`
pk ` 1q2´nt
˘
´ b2
`
k2´nt
˘˘
´ b2
`
k2´nt
˘ `
b1
`
pk ` 1q2´nt
˘
´ b1
`
k2´nt
˘˘
+
“ lim
nÑ8
2n´1
ÿ
k“0
`
b1
`
pk ` 1q2´nt
˘
´ b1
`
k2´nt
˘˘ `
b2
`
pk ` 1q2´nt
˘
´ b2
`
k2´nt
˘˘
.
(3.182)
The limit in (3.182) vanishes, because by independence and martingale proper-
ties of the processes b1 and b2, we infer
E
«2n´1
ÿ
k“0
`
b1
`
pk ` 1q2´nt
˘
´ b1
`
k2´nt
˘˘ `
b2
`
pk ` 1q2´nt
˘
´ b2
`
k2´nt
˘˘
ﬀ2
“ E
˜2n´1
ÿ
k“0
`
b1
`
pk ` 1q2´nt
˘
´ b1
`
k2´nt
˘˘2 `
b2
`
pk ` 1q2´nt
˘
´ b2
`
k2´nt
˘˘2
¸
“
2n´1
ÿ
k“0
E
“
b1
`
pk ` 1q2´nt
˘
´ b1
`
k2´nt
˘‰2 E
`
b2
`
pk ` 1q2´nt
˘
´ b2
`
k2´nt
˘˘2
“
2n´1
ÿ
k“0
`
2´nt
˘2 “ 2´nt2.
(3.183)
From Borel-Cantelli’s lemma it then easily follows that the limit in (3.182) van-
ishes and hence that equality (3.181) is true. The validity of (3.180) is then
checked for the special case that σjkpsq “ fjk1psjk,8qpsq, where fjk is measurable
with respect to Fsjk. The general statement follows via bi-linearity and a lim-
iting procedure together with equality (3.173) in Corollary 5.142. The proof of
Proposition 3.85 is now complete.
□
Next let Mptq “ pM1ptq, . . . , Mνptqq be a ν-dimensional martingale as in Propo-
sition 3.85 and let Aptq “ pA1ptq, . . . , Aνptqq be an adapted ν-dimensional pro-
cess that P-almost surely is of bounded variation on r0, ts for every t ą 0. This
means that
sup
nPN
sup
0ďs0ăs1ă¨¨¨snďt |Apsjq ´ Apsj´1q|
is ﬁnite P-almost surely for all t ą 0.
It follows that the random set function µA : pa, bs ÞÑ Apbq ´ Apaq extends
to an Rν-valued measure on r0, ts for every t ą 0. Stieltjes integrals of the
form
şt
0 FpsqdApsq may be interpreted as
şt
0 FpsqdApsq “
şt
0 FpsqdµApsq. The
process A may have jumps. This is not the case for the process M. The latter
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
170 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
follows from Proposition 3.83. The process X :“ A ` M is a ν-dimensional
semi-martingale with the property that E
`
|Mptq|2˘
ă 8, t ą 0. Put
JXptq “
ÿ
sďt pXpsq ´ Xps´qq
“
ÿ
sďt
pMpsq ´ Mps´qq `
ÿ
sďt
pApsq ´ Aps´qq “ JAptq.
The deﬁnition of JAptq does not pose to much of a problem. In fact for P-almost
all ω the sum
ÿ
sďt
|Aps, ωq ´ Aps´, ωq| ă 8. The process tXptq ´ JXptq : t ě 0u
is P-almost surely continuous.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
171 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The following result is the fundamental theorem in stochastic calculus.
3.86. Theorem (Itˆo’s formula). Let X “ pX1, . . . , Xνq “ A ` M be a ν-
dimensional local semi-martingale as described above, and let f : Rν Ñ R be a
twice continuously diﬀerentiable function. Put aijptq “ řν
k“1 σikptqσjkptq, 1 ď i,
j ď ν. Then, P-almost surely,
fpXptqq
“ fpXp0qq `
ÿ
sďt
ˆ
fpXpsqq ´ f pXps´qq ´ ∇f pXps´qq . pXpsq ´ Xps´qq
˙
`
ż t
0
∇f pXps´qq ¨ dXpsq ` 1
2
νÿ
i,j“1
ż t
0
DiDjfpXpsqqaijpsqds.
(3.184)
Before we prove Theorem 3.86 we want to make some comments and we want to
give a reformulation of Itˆo’s formula. Moreover, we shall not prove Itˆo’s formula
in its full generality. We shall content ourselves with a proof with A ” 0.
Remark. The integral
şt
0 ∇f pXps´qq dXpsq has the interpretation:
ż t
0
∇f pXps´qq dXpsq
“
νÿ
i“1
ˆż t
0
Dif pXps´qq dMipsq `
ż t
0
Dif pXps´qq dAipsq
˙
(3.185)
“
νÿ
i“1
ˆż t
0
Dif pXps´qq dMipsq `
ż t
0
Dif pXps´qq dAipsq
˙
“
νÿ
i“1
˜ νÿ
k“1
ż t
0
Dif pXps´qq σikpsqdbkpsq `
ż t
0
Dif pXps´qq dAipsq
¸
.
Here X “ M ` A is the decomposition of the semi-martingale in a martingale
part M and a process A which is locally of bounded variation.
For ν-dimensional Brownian motion we have the following corollary.
3.87. Corollary. Let bptq “ pb1ptq, . . . , bνptqq be ν-dimensional Brownian mo-
tion. Let f : Rν Ñ R be a twice continuously diﬀerentiable function. Then,
P-almost surely,
fpbptqq “ fpbp0qq `
ż t
0
∇fpbpsqqdbpsq ` 1
2
ż t
0
△fpbpsqqds.
(3.186)
In fact it suﬃces to suppose that the functions D1f, . . . , Dνf and D2
1f, . . . , D2
νf
are continuous. Next we reformulate Itˆo’s formula.
3.88. Theorem. Let X “ pX1, . . . , Xνq be a ν-dimensional right continuous
semi-martingale as in Theorem 3.86 and let f : Rν Ñ R be a twice continuously
diﬀerentiable function. Then, P-almost surely,
fpXptqq “ fpXp0qq `
ż t
0
∇f pXps´qq ¨ dXpsq
(3.187)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
172 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
`
νÿ
i,j“1
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσd rXi, Xjs psq,
where
rXi, Xjs ptq “
ż t
0
aijpsqds `
ÿ
sďt
pXipsq ´ Xips´qq pXjpsq ´ Xjps´qq .
(3.188)
Remark. In the proof below we employ the following notation. Let Mi be
martingale of the form
Miptq :“
νÿ
k“1
ż t
0
σikpsqdbkpsq.
Then quadratic covariation process ⟨Mi, Mj⟩ptq satisﬁes
⟨Mi, Mj⟩ptq “
νÿ
k“1
ż t
0
σikpsqσjkpsq ds.
Proof of Theorems 3.88 and 3.86. Since, for a and b in Rν
fpbq ´ fpaq “ ∇fpaq.pb ´ aq
(3.189)
`
νÿ
i,j“1
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqa ` σbq dσ ˆ pbi ´ aiqpbj ´ ajq
and since
rXi, Xjs ptq “
ż t
0
aijpsqds `
ÿ
sďt
pXipsq ´ Xips´qq pXjpsq ´ Xjps´qq ,
it follows that
νÿ
i,j“1
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσd rXi, Xjs psq
“
νÿ
i,j“1
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσaijpsqds
`
νÿ
i,j“1
ÿ
sďt
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσ
ˆ pXipsq ´ Xips´qq pXjpsq ´ Xjps´qq
“
νÿ
i,j“1
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσaijpsqds
`
ÿ
sďt
tfpXpsqq ´ f pXps´qq ´ ∇f pXps´qq . pXpsq ´ Xps´qqu . (3.190)
So the formulas in Theorem 3.88 and Theorem 3.86 are equivalent. Also notice
that, since
şt
0 aijpsqds is a continuous process of ﬁnite variation (locally), we
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
173 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
have
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσaijpsqds
“
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXps´qq dσaijpsqds
“ 1
2
ż t
0
DiDjf pXps´qq aijpsqds.
Hence it suﬃces to prove equality (3.187) in Theorem 3.88. Assume Xp0q “
Mp0q and hence Ap0q “ 0.
Upon stopping we may and do assume that in
X “ M ` A, |Xpt´q| ď L and varApt´q ď L.
This can be achieved by
replacing Xptq with Xpminpt, τqq, where τ is the stopping time deﬁned by
τ “ inf ts ą 0 : max p|Mpsq| , varApsqq ą Lu .
Here varApsq is deﬁned by
varApsq “ sup
# nÿ
j“1
|Apsjq ´ Apsj´1q| : 0 ď s0 ă s1 ă . . . ă sn “ s
+
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

Advanced stochastic processes: Part I
174 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Next we deﬁne, for every n P N, the sequence of stopping times tTn,k : k P Nu
as follows:
Tn,0 “ 0;
Tn,k`1 “ inf
"
s ą Tn,k : max ps ´ Tn,k, |Xpsq ´ XpTn,kq|q ą 1
n
*
.
(3.191)
Since
max pTn,k`1 ´ Tn,k, |XpTn,k`1q ´ XpTn,kq|q ě 1
n,
it follows that lim
kÑ8 Tn,k “ 8, P-almost surely. Moreover, since
max pTn,k`1 ´ Tn,k, |XpTn,k`1´q ´ XpTn,kq|q ď 1
n,
we have Tn,k`1 ´ Tn,k ď 1
n. Next we write:
fpXptqq ´ fpXp0qq
“
8
ÿ
k“0
tf pX pTn,k`1 ^ t´qq ´ f pX pTn,k ^ tqq
`f pX pTn,k`1 ^ tqq ´ f pX pTn,k`1 ^ t´qqu
“
8
ÿ
k“0
#ż Tn,k`1^t´
Tn,k^t
∇f pX pTn,k ^ tqq ¨ dXpsq
`
νÿ
i,j“1
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqX pTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
ˆ pXi pTn,k`1 ^ t´q ´ Xi pTn,k ^ tqq pXj pTn,k`1 ^ t´q ´ Xj pTn,k ^ tqq
` f pX pTn,k`1 ^ tqq ´ f pX pTn,k`1 ^ t´qq
+
.
(3.192)
On the other hand we also have:
ż t
0
∇f pXps´qq dXpsq
`
νÿ
i,j“1
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσd rXi, Xjs psq
“
8
ÿ
k“0
#ż Tn,k`1^t´
Tn,k^t
∇f pXps´qq ¨ dXpsq
`
νÿ
i,j“0
ż Tn,k`1^t´
Tn,k^t
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσd rXi, Xjs psq
` ∇f pX pTn,k`1 ^ t´qq . pX pTn,k`1 ^ tq ´ X pTn,k`1 ^ t´qq
`
νÿ
i,j“1
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqX pTn,k`1 ^ t´q ` σX pTn,k`1 ^ tqq dσ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
175 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
ˆ pXi pTn,k`1 ^ tq ´ Xi pTn,k`1 ^ t´qq pXj pTn,k`1 ^ tq ´ Xj pTn,k`1 ^ t´qq
+
“
8
ÿ
k“0
#ż Tn,k`1^t´
Tn,k^t
∇f pXps´qq ¨ dXpsq
`
νÿ
i,j“0
ż Tn,k`1^t´
Tn,k^t
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσd rXi, Xjs psq
` f pX pTn,k`1 ^ tqq ´ f pX pTn,k`1 ^ t´qq
+
.
(3.193)
Upon subtracting (3.193) from (3.192) we infer by employing Proposition 3.85:
fpXptqq ´ fpXp0qq ´
ż t
0
∇f pXps´qq dXpsq
´
νÿ
i,j“1
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσd rXi, Xjs psq
“
8
ÿ
k“0
#
´
ż Tn,k`1^t´
Tn,k^t
p∇f pXps´qq ´ ∇f pX pTn,kqqq ¨ dXpsq
`
νÿ
i,j“1
ż Tn,k`1^t´
Tn,k^t
"ż 1
0
p1 ´ σqDiDjf pp1 ´ σqX pTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
´
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσ
*
d rXi, Xjs psq
`
νÿ
i,j“1
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqX pTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
ˆ
"
pXi pTn,k`1 ^ t´q ´ Xi pTn,k ^ tqq pXj pTn,k`1 ^ t´q ´ Xj pTn,k ^ tqq
´ rXi, Xjs pTn,k`1 ^ t´q ` rXi, Xjs pTn,k ^ tq
*+
“
8
ÿ
k“0
#
´
ż Tn,k`1^t´
Tn,k^t
p∇f pXps´qq ´ ∇f pX pTn,kqqq ¨ dXpsq
`
νÿ
i,j“1
ż Tn,k`1^t´
Tn,k^t
ż 1
0
p1 ´ σq tDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq
´DiDjf pp1 ´ σqXps´q ` σXpsqqu dσd rXi, Xjs psq
`
νÿ
i,j“1
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
ˆ
#ż Tn,k`1^t´
Tn,k^t
pXips´q ´ Xi pTn,k ^ tqq dXjpsq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
176 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
`
ż Tn,k`1^t´
Tn,k^t
pXjps´q ´ Xj pTn,k ^ tqq dXipsq
++
.
(3.194)
We shall estimate the following quantities:
E
¨
˝
˜ 8
ÿ
k“0
ż Tn,k`1^t´
Tn,k^t
pDif pXps´qq ´ Dif pX pTn,k ^ tqqq ¨ dMipsq
¸2˛
‚; (3.195)
E
˜ˇˇˇˇˇ
8
ÿ
k“0
ż Tn,k`1^t´
Tn,k^t
pDif pXps´qq ´ Dif pX pTn,k ^ tqqq ¨ dAipsq
ˇˇˇˇˇ
¸
;
(3.196)
E
˜ˇˇˇˇˇ
8
ÿ
k“0
ż Tn,k`1^t´
Tn,k^t
ż 1
0
p1 ´ σq tDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq
´DiDjf pp1 ´ σqXps´q ` σXpsqqu dσd rXi, Xjs psq
ˇˇˇˇˇ
¸
;
(3.197)
E
˜˜ 8
ÿ
k“0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
ˆ
ż Tn,k`1^t´
Tn,k^t
pXips´q ´ Xi pTn,k ^ tqq dMjpsq
¸2¸
;
(3.198)
E
˜ˇˇˇˇˇ
8
ÿ
k“0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
ˆ
ż Tn,k`1^t´
Tn,k^t
pXips´q ´ Xi pTn,k ^ tqq dAjpsq
ˇˇˇˇˇ
¸
.
(3.199)
Since the process
şu
0 pDif pXps´qq ´ Dif pX pTn,k ^ tqqq dMipsq, u ě 0, is a mar-
tingale, the quantity in (3.195) veriﬁes
E
¨
˝
˜ 8
ÿ
k“0
ż Tn,k`1^t´
Tn,k^t
pDif pXps´qq ´ Dif pX pTn,k ^ tqqq ¨ dMipsq
¸2˛
‚
“
8
ÿ
k“0
E
¨
˝
˜ż Tn,k`1^t´
Tn,k^t
pDif pXps´qq ´ Dif pX pTn,k ^ tqqq ¨ dMipsq
¸2˛
‚
“
8
ÿ
k“0
E
˜ż Tn,k`1^t´
Tn,k^t
pDif pXps´qq ´ Dif pX pTn,k ^ tqqq2 ¨ d ⟨Mi⟩psq
¸
ď
sup
x,yPRν:|y´x|ď1{n,maxp|x|,|y|qď2L
|Difpyq ´ Difpxq|2 .E p⟨Mi⟩ptqq .
(3.200)
Similarly we obtain an estimate for the quantity in (3.198):
E
˜˜ 8
ÿ
k“0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
177 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
ˆ
ż Tn,k`1^t´
Tn,k^t
pXips´q ´ Xi pTn,k ^ tqq dMjpsq
¸2˛
‚
“ E
˜ 8
ÿ
k“0
ˆż 1
0
p1 ´ σqDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
˙2
ˆ
˜ż Tn,k`1^t´
Tn,k^t
pXips´q ´ Xi pTn,k ^ tqq dMjpsq
¸2˛
‚
ď 1
2 sup
|y|ď2L
|DiDjfpyq| E
˜ 8
ÿ
k“0
ż Tn,k`1^t´
Tn,k^t
pXips´q ´ Xi pTn,k ^ tqq2 d ⟨Mj⟩psq
¸
ď 1
2 sup
|y|ď2L
|DiDjfpyq| ˆ 1
n2E p⟨Mj⟩ptqq .
(3.201)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planet’s 
electricity needs. Already today, SKF’s innovative know-
how is crucial to running a large proportion of the 
world’s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

Advanced stochastic processes: Part I
178 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The other estimates are even easier:
“ E
˜ˇˇˇˇˇ
8
ÿ
k“0
ż Tn,k`1^t´
Tn,k^t
pDif pXps´qq ´ Dif pX pTn,kqqq ¨ dAipsq
ˇˇˇˇˇ
¸
ď
sup
x,yPRν:|y´x|ď1{n,maxp|x|,|y|qď2L
|Difpyq ´ Difpxq| .E
ˆż t
0
|dAipsq|
˙
,
(3.202)
E
˜ˇˇˇˇˇ
8
ÿ
k“0
ż Tn,k`1^t´
Tn,k^t
ż 1
0
p1 ´ σq tDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq
´DiDjf pp1 ´ σqXps´q ` σXpsqqu dσd rXi, Xjs psq
ˇˇˇˇˇ
¸
ď 1
2
sup
x,yPRν:|y´x|ď1{n,maxp|x|,|y|qď2L
|DiDjfpyq ´ DiDjfpxq|
ˆ E
ˆż t
0
|d rXi, Xjs psq|
˙
ď 1
2
sup
x,yPRν:|y´x|ď1{n,maxp|x|,|y|qď2L
|DiDjfpyq ´ DiDjfpxq|
ˆ
a
E prXi, Xis ptqq
b
E prXj, Xjs ptqq,
and
(3.203)
E
˜ˇˇˇˇˇ
8
ÿ
k“0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXpTn,k ^ tq ` σX pTn,k`1 ^ t´qq dσ
ˆ
ż Tn,k`1^t´
Tn,k^t
pXips´q ´ Xi pTn,k ^ tqq dAjpsq
ˇˇˇˇˇ
¸
ď 1
2n
sup
yPRν,|y|ď2L
|DiDjfpyq| E
ˆż t
0
|dAjpsq|
˙
.
(3.204)
The inequality (3.203) will be established shortly.
The quantities (3.200),
(3.201), (3.202), (3.203) and (3.204) tend to zero if n tends to inﬁnity. Conse-
quently, from (3.194) it then follows that, P-almost surely,
fpXptqq “ fpXp0qq `
ż t
0
∇fpXpsqqdXpsq
(3.205)
`
νÿ
i,j“1
ż t
0
ż 1
0
p1 ´ σqDiDjf pp1 ´ σqXps´q ` σXpsqq dσd rXi, Xjs psq.
So that the formula of Itˆo has been established now. For completeness we prove
the inequality
E
ˆż t
0
|d rXi, Xjs psq|
˙
ď
a
E prXi, Xis ptqq
b
E prXj, Xjs ptqq.
(3.206)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
179 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
A proof of (3.206) will establish (3.203). For an appropriate sequence of subdivi-
sions 0 “ spnq
0
ă spnq
1
ă ¨ ¨ ¨ ă spnq
Nn “ t we have with, temporarily, rXis “ rXi, Xis,
ż t
0
|d rXi, Xjs psq| “ lim
nÑ8
Nn
ÿ
k“1
ˇˇˇrXi, Xjs
´
spnq
k
¯
´ rXi, Xjs
´
spnq
k´1
¯ˇˇˇ
ď lim
nÑ8
Nn
ÿ
k“1
c
rXis
´
spnq
k
¯
´ rXis
´
spnq
k´1
¯c
rXjs
´
spnq
k
¯
´ rXjs
´
spnq
k´1
¯
ď lim
nÑ8
˜ Nn
ÿ
k“1
´
rXi, Xis
´
spnq
k
¯
´ rXi, Xis
´
spnq
k´1
¯¯¸1{2
˜ Nn
ÿ
k“1
´
rXj, Xjs
´
spnq
k
¯
´ rXj, Xjs
´
spnq
k´1
¯¯¸1{2
“ prXi, Xis ptq ´ rXi, Xis p0qq1{2 prXj, Xjs ptq ´ rXj, Xjs p0qq1{2
(3.207)
Taking expectations and using the inequality of Cauchy-Schwartz once more
yields the desired result.
This completes the proofs of Theorems 3.86 and 3.88.
□
Remark. In the proof of equality (3.194) there is a gap. It is correct if the
process A ” 0. In order to make the proof complete, Proposition 3.85 has to be
supplemented with equalities of the form (Miptq “ řν
k“1
şt
0 σikpsqdbkpsq):
MiptqAjptq “
ż t
0
MipsqdAjpsq `
νÿ
k“1
ż t
0
σikpsqAjpsqdbkpsq;
AiptqAjptq “
ż t
0
AipsqdAjpsq `
ż t
0
AjpsqdAipsq.
This kind of equalities is true for continuous processes. If jumps are present
even more care has to be taken. We continue with some examples. We begin
with the heat equation.
Example 1. (Heat equation) Let U be an open subset of Rν, let f : U Ñ R be
a function in C0pEq and let u : r0, 8q ˆ U Ñ R be a solution to the following
problem:
$
&
%
Bu
Bt
“ 1
2∆u in r0, 8q ˆ U;
u
is continuous on r0, 8q ˆ U and up0, xq “ fpxq.
Moreover we assume that
lim
xÑb,xPU upt, xq “ 0 if b belongs to BU. Then upt, xq “
Ex rfpbptqq : τ ą ts, where τ is the exit time of U: τ “ inf ts ą 0 : bpsq P RνzUu.
Of course tbpsq : s ě 0u stands for ν-dimensional Brownian motion. In order to
prove this claim we ﬁx t ą 0 and we consider the process tMpsq : 0 ď s ď tu
deﬁned by Mpsq “ upt ´ s, bpsqq1tτąsu. An application of Itˆo’s formula yields
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
180 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
the following identities:
Mpsq ´ Mp0q “ ´
ż s
0
Bu
Bt pt ´ r, bprqq1tτąrudr `
ż s
0
∇upt ´ r, bprqq1tτąru ¨ dbprq
` 1
2
ż s
0
∆upt ´ r, bprqq1tτąrudr
“
ż s
0
"
´Bu
Bt pt ´ r, bprqq ` 1
2∆upt ´ r, bprqq
*
1tτąrudr
`
ż s
0
∇upt ´ r, bprqq1tτąru ¨ dbprq
“
ż s
0
∇upt ´ r, bprqq1tτąru ¨ dbprq.
Consequently, the process tMpsq : 0 ď s ď tu is a martingale. It follows that
upt, xq “ Ex pupt, bp0qqq “ ExpMp0qq “ ExpMptqq
“ Ex
`
up0, bptqq1tτątu
˘
“ Ex
`
fpbptqq1tτątu
˘
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
181 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Example 2. Let U be an open subset of Rν, let f belong to C0pUq and let
g : r0, 8q ˆ U Ñ R be a function in C0pEq and let u : r0, 8q ˆ U Ñ R be a
solution to the following problem:
$
&
%
Bu
Bt “ 1
2∆u ` g in r0, 8q ˆ U;
u is continuous on r0, 8q ˆ U and up0, xq “ fpxq.
Moreover we assume that limxÑb,xPU upt, xq “ 0 if b belongs to BU.
Then
upt, xq “ Ex pfpbptqq : τ ą tq ` Ex
´şminpt,τq
0
gpt ´ r, bprqqdr
¯
, where, as in Ex-
ample 1, τ is the exit time of U. Also as in Example 1, tbpsq : s ě 0u stands for
ν-dimensional Brownian motion. A proof can be given following the same lines
as in the previous example.
Example 3.
(Feynman-Kac formula) Let U be an open subset of Rν, let
f belong to C0pUq and let V : U Ñ R be an appropriate function and let
u : r0, 8q ˆ U Ñ R be a solution to the following problem:
$
&
%
Bu
Bt “ 1
2∆u ´ V u in r0, 8q ˆ U;
u is continuous on r0, 8q ˆ U and up0, xq “ fpxq.
Moreover we want that limxÑb,xPU upt, xq “ 0 if b belongs to BU. Then upt, xq “
Ex
´
exp
´
´
şt
0 V pbprqqdr
¯
fpbptqq : τ ą t
¯
.
For the proof we ﬁx t ą 0 and we consider the process tMpsq : 0 ď s ď tu deﬁned
by Mpsq “ upt ´ s, bpsqq exp
`
´
şs
0 V pbprqqdr
˘
1tτąsu and we apply Itˆo’s formula
to obtain:
Mpsq ´ Mp0q
“
ż s
0
"
´Bu
Bt pt ´ r, bprqq ` 1
2∆upt ´ r, bprqq ´ V pbprqqupt ´ r, bprqq
*
exp
ˆ
´
ż r
0
V pbpρqqdρ
˙
1tτąrudr
`
ż s
0
∇upt ´ r, bprqq exp
ˆ
´
ż r
0
V pbpρqqdρ
˙
1tτąru ¨ dbprq
“
ż s
0
∇upt ´ r, bprqq exp
ˆ
´
ż r
0
V pbpρqqdρ
˙
1tτąru ¨ dbprq.
Here we used the fact that u is supposed to be a solution of our initial value
problem. It follows that the process tMpsq : 0 ď s ď tu is a martingale. Hence
we may conclude that
upt, xq “ ExrMp0qs “ Ex rMptqs
“ Ex
„
up0, bptqq exp
ˆ
´
ż t
0
V pbpρqqdρ
˙
: τ ą t
ȷ
“ Ex
„
fpbptqq exp
ˆ
´
ż t
0
V pbpρqqdρ
˙
: τ ą t
ȷ
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
182 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Example 4. (Cameron-Martin or Girsanov transformation). Let U be an open
subset of Rν, let f belong to C0pUq and let c : U Ñ Rν be an appropriate vector
ﬁeld on U and let u : r0, 8q ˆ U Ñ R be a solution to the following problem:
$
&
%
Bu
Bt
“ 1
2∆u ` c.∇u in r0, 8q ˆ U;
u
is continuous on r0, 8q ˆ U and up0, xq “ fpxq.
Moreover we want that limxÑb,xPU upt, xq “ 0 if b belongs to BU. Then upt, xq “
Ex pexp pZptqq fpbptqq : τ ą tq, where Zptq “
şt
0 cpbprqq ¨ dbprq ´ 1
2
şt
0 |cpbprqq|2 dr.
For a proof we ﬁx t ą 0 and we consider the process tMpsq : 0 ď s ď tu deﬁned
by Mpsq “ upt ´ s, bpsqq exp pZpsqq 1tτąsu. An application of Itˆo’s formula to
the function fps, x, yq “ upt ´ s, xq exppyq will yield the following result
Mpsq ´ Mp0q
“
ż s
0
´Bu
Bt pt ´ r, bprqq exp pZprqq 1tτąrudr
`
ż s
0
∇upt ´ r, bprqq exp pZprqq 1tτąru ¨ dbprq
`
ż s
0
upt ´ r, bprqq exp pZprqq dZprq
` 1
2
ż minps,τq
0
∆upt ´ r, bprqq exp pZprqq 1tτąrudr
`
νÿ
j“1
ż s
0
Djupt ´ r, bprqq exp pZprqq 1tτąrud ⟨bj, Z⟩prq
` 1
2
ż s
0
upt ´ r, bprqq exp pZprqq 1tτąrud ⟨Z, Z⟩prq
“
ż s
0
"
´Bu
Bt pt ´ r, bprqq ` 1
2∆upt ´ r, bprqq ` cpbprqq.∇upt ´ r, bprqq
*
exp pZprqq 1tτąrudr
`
ż s
0
t∇upt ´ r, bprqq ` upt ´ r, bprqqcpbprqqu exp pZprqq 1tτąru ¨ dbprq
´ 1
2
ż s
0
upt ´ r, bprqq exp pZprqq |cpbprqq|2 1tτąrudr
` 1
2
ż s
0
upt ´ r, bprqq exp pZprqq |cpbprqq|2 1tτąrudr
“
ż s
0
t∇upt ´ r, bprqq ` upt ´ r, bprqqcpbprqqu exp pZprqq 1tτąru ¨ dbprq.
As above it will follow that upt, xq “ Ex pexp pZptqq fpbptqq : τ ą tq.
Example 5. (Stochastic diﬀerential equation). Let pσpxqqν
j,k“1, x P Rν, be a
continuous square matrix valued function and let cpxq be a so-called drift vec-
tor ﬁeld (see the previous example). Suppose that the process tXxpsq : s ě 0u
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
183 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
satisﬁes the following (stochastic) integral equation:
Xxptq “ x `
ż t
0
cpXxpsqqds `
ż t
0
σpXxpsqq ¨ dbpsq.
In other words the process tXxpsq : s ě 0u is a solution of the following stochas-
tic diﬀerential equation:
dXxptq “ cpXxptqqdt ` σpXxptqq ¨ dbptq
together with Xxp0q “ x. The integral
şt
0 σpXxpsqqdbpsq has the interpretation
ż t
0
σpXxpsqqdbpsq “
˜ νÿ
k“1
ż t
0
σjkpXxpsqqdbkpsq
¸ν
j“1
.
Next let u : r0, 8q ˆ Rν Ñ R be a twice continuously diﬀerentiable function.
Then, by Itˆo’s lemma,
u pt ´ s, Xxpsqq ´ u pt, Xxp0qq
“ ´
ż s
0
Bu
Bt pt ´ r, Xxprqq dr
`
ż s
0
∇u pt ´ r, Xxprqq ¨ dXxprq
` 1
2
νÿ
j,k“1
ż s
0
DjDku pt ´ r, Xxprqq d
⟨
Xx
j , Xx
k
⟩
prq.
Next we compute
d
⟨
Xx
j , Xx
k
⟩
prq “
νÿ
m,n“1
σjm
`
Xx
j mprq
˘
σkn pXxprqq d ⟨bm, bn⟩prq
“
νÿ
m“1
σjm pXxprqq σkm pXxprqq dr “ pσ pXxprqq σ pXxprqqτqjk dr,
where σpxqτ is the transposed matrix of σpxq. Next we introduce the diﬀerential
operator L as follows:
rLfs pxq “ 1
2
νÿ
j,k“1
pσpxqσpxqτqjk DjDkfpxq `
νÿ
j“1
cjpxqDjfpxq.
For our twice continuously diﬀerential function u we obtain:
u pt ´ s, Xxpsqq ´ u pt, Xxp0qq
“ ´
ż s
0
Bu
Bt pt ´ r, Xxprqq dr
`
νÿ
j“1
ż s
0
cj pXxprqq Dju pt ´ r, Xxprqq dr
`
ż s
0
∇u pt ´ r, Xxprqq σ pXxprqq ¨ dbprq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
184 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
` 1
2
νÿ
j,k“1
ż s
0
pσ pXxprqq σ pXxprqqτqj,k DjDku pt ´ r, Xxprqq dr
“
ż s
0
∇u pt ´ r, Xxprqq σ pXxprqq ¨ dbprq `
ż s
0
ˆ
L ´ B
Bt
˙
u pt ´ r, Xxprqq dr.
So that, if
ˆ
L ´ B
Bt
˙
u ” 0, then, for 0 ď s ď t,
u pt ´ s, Xxpsqq ´ u pt, Xxp0qq “
ż s
0
∇u pt ´ r, Xxprqq σ pXxprqq dbprq,
and hence, the process Mpsq :“ u pt ´ s, Xxpsqq is a martingale on the interval
r0, ts. It follows that
upt, xq “ EpMp0qq “ EpMptqq “ E pu p0, Xxptqqq “ E pf pXxptqqq
where up0, xq “ fpxq. For more details on stochastic diﬀerential equations see
Chapter 4.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
185 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Example 6. (Quantum mechanical magnetic ﬁeld). Let ⃗a be an appropriate
vector ﬁeld on Rν and let Hp⃗a, V q “ 1
2 pi∇` ⃗aq2 ` V be the (quantum mechan-
ical) Hamiltonian of a particle under the inﬂuence of the scalar potential V in
a magnetic ﬁeld ⃗Bpxq with vector potential ⃗apxq: i.e. ⃗B “ ∇ˆ ⃗a. Let f be a
function in C0 pRνq and let u : r0, 8q ˆ Rν Ñ R be a solution to the following
problem:
$
&
%
Bu
Bt
“ ´Hp⃗a, V qu in r0, 8q ˆ Rν;
u
is continuous on r0, 8q ˆ Rν and up0, xq “ fpxq.
Moreover we want that lim
xÑ8 upt, xq “ 0. Then upt, xq “ Ex
“
eZptqfpbptqq
‰
, where
Zptq “ ´i
ż t
0
⃗apbpsqq ¨ dbpsq ´ 1
2i
ż t
0
∇¨ ⃗apbpsqqds ´
ż t
0
V pbpsqqds
with ∇¨ ⃗a “
νÿ
j“1
Baj
Bxj
. Put Mpsq “ upt ´ s, bpsqq exp pZpsqq, 0 ă s ă t. An
application of Itˆo’s formula to the function fps, x, yq “ upt ´ s, xq exppyq will
yield the following result
Mpsq ´ Mp0q “ fps, bpsq, Zpsqq ´ fp0, bp0q, Zp0qq
“
ż s
0
Bf
Bs pσ, bpσq, Zpσqq dσ `
ż s
0
∇xfpσ, bpσq, Zpσqq ¨ dbpσq
`
ż s
0
Bf
By pσ, bpσq, Zpσqq ¨ dZpσq ` 1
2
ż s
0
∆xfpσ, bpσq, Zpσqqdσ
` 1
2
νÿ
j“1
ż s
0
B2
ByBxj
fpσ, bpσq, Zpσqqd ⟨Z, bj⟩pσq
` 1
2
νÿ
j“1
ż s
0
B2f
BxjBypσ, bpσq, Zpσqq d ⟨bj, Z⟩pσq
` 1
2
ż s
0
B2f
By2 pσ, bpσq, Zpσqqd ⟨Z, Z⟩pσq
“
ż s
0
Bf
Bs pσ, bpσq, Zpσqq dσ `
ż s
0
∇xfpσ, bpσq, Zpσqq ¨ dbpσq
`
ż s
0
fpσ, bpσq, Zpσqq ¨ dZpσq ` 1
2
ż s
0
∆xfpσ, bpσq, Zpσqqdσ
´ i
νÿ
j“1
ż s
0
Bf
Bxj
pσ, bpσq, Zpσqqajpb
`
σq
˘
dσ
` 1
2
ż s
0
fpσ, bpσq, Zpσqq
νÿ
j“1
aj pbpσqq2 dσ
“ ´
ż s
0
Bu
Bt pt ´ σ, bpσqq eZpσqdσ `
ż s
0
∇xu pt ´ σ, bpσqq eZpσq ¨ dbpσq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
186 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
`
ż s
0
u pt ´ σ, bpσqq eZpσq ¨ dZpσq ` 1
2
ż s
0
∆xu pt ´ σ, bpσqq eZpσqdσ
´ i
νÿ
j“1
ż s
0
Bu
Bxj
pt ´ σ, bpσqq eZpσqajpbpσqdσ
` 1
2
ż s
0
u pt ´ σ, bpσqq eZpσq
νÿ
j“1
aj pbpσqq2 dσ
“
ż s
0
"
´Bu
Bt ` 1
2∆xu ´ i⃗apbpσqq.∇xu ´ 1
2 |⃗apbpσqq|2 u
´1
2i∇¨ ⃗apbpσqqu ´ V pbpσqqu
*
pt ´ σ, bpσqq eZpσqdσ
`
ż s
0
∇xu pt ´ σ, bpσqq eZpσq ¨ dbpσq ´ i
ż s
0
u pt ´ σ, bpσqq eZpσq⃗apbpσqq ¨ dbpσq
“
ż s
0
"
´ B
Bt ´ 1
2 pi∇` ⃗aq2 ´ V
*
u pt ´ σ, bpσqq eZpσqdσ
`
ż s
0
∇xu pt ´ σ, bpσqq eZpσq ¨ dbpσq ´ i
ż s
0
u pt ´ σ, bpσqq eZpσq⃗apbpσqq ¨ dbpσq
“
ż s
0
∇xu pt ´ σ, bpσqq eZpσq ¨ dbpσq ´ i
ż s
0
u pt ´ σ, bpσqq eZpσq⃗apbpσqq ¨ dbpσq.
Here we used the fact that the function u satisﬁes the diﬀerential equation. The
claim in the beginning of the example then follows as in Example 4.
Example 7. A geometric Brownian motion (GBM) (occasionally called expo-
nential Brownian motion) is a continuous-time stochastic process in which the
logarithm of the randomly varying quantity follows a Brownian motion, also
called a Wiener process: see e.g. Ross [116] Section 10.3.2. It is applicable
to mathematical modelling of some phenomena in ﬁnancial markets. It is used
particularly in the ﬁeld of option pricing because a quantity that follows a GBM
may take any positive value, and only the fractional changes of the random vari-
ate are signiﬁcant. This is a reasonable approximation of stock price dynamics
except for rare events.
A stochastic process St is said to follow a GBM if it satisﬁes the following
stochastic diﬀerential equation:
dSptq “ µSptq dt ` σSptq dWptq
where Wptq is a Wiener process or Brownian motion and µ (“the percentage
drift” or “drift rate”) and σ (“the (percentage or ratio) volatility”) are constants.
For an arbitrary initial value Sp0q the equation has the analytic solution
Sptq “ Sp0q exp
ˆˆ
µ ´ σ2
2
˙
t ` σWptq
˙
,
which is a log-normally distributed random variable with expected value given
by ErSptqs “ eµtSp0q and variance by VarpSptqq “ e2µtSp0q2 ´
eσ2t ´ 1
¯
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
187 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The correctness of the solution can be veriﬁed using Itˆo’s lemma. The random
variable log
ˆ Sptq
Sp0q
˙
is normally distributed with mean
`
µ ´ 1
2σ2˘
t and variance
σ2t, which reﬂects the fact that increments of a GBM are normal relative to the
current price, which is why the process has the name “geometric”.
Example 8. The term Black-Scholes refers to three closely related concepts:
1. The Black-Scholes model is a mathematical model of the market for an
equity, in which the equity’s price is a stochastic process.
2. The Black-Scholes PDE is a partial diﬀerential equation which (in the
model) must be satisﬁed by the price of a derivative on the equity.
3. The Black-Scholes formula is the result obtained by solving the Black-
Scholes PDE for a European call option.
Fischer Black and Myron Scholes ﬁrst articulated the Black-Scholes formula in
their 1973 paper, “The Pricing of Options and Corporate Liabilities.”: see [19].
The foundation for their research relied on work developed by scholars such
as Jack L. Treynor, Paul Samuelson, A. James Boness, Sheen T. Kassouf, and
Edward O. Thorp. The fundamental insight of Black-Scholes is that the option
is implicitly priced if the stock is traded.
Robert C. Merton was the ﬁrst to publish a paper expanding the mathematical
understanding of the options pricing model and coined the term “Black-Scholes”
options pricing model.
Merton and Scholes received the 1997 The Sveriges Riksbank Prize in Economic
Sciences in Memory of Alfred Nobel for this and related work. Though ineligible
for the prize because of his death in 1995, Black was mentioned as a contributor
by the Swedish academy.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
188 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
7. Black-Scholes model
The text in this section is taken from Wikipedia (English version). The Black-
Scholes model of the market for a particular equity makes the following explicit
assumptions:
1. It is possible to borrow and lend cash at a known constant risk-free
interest rate.
2. The price follows a geometric Brownian motion with constant drift and
volatility.
3. There are no transaction costs.
4. The stock does not pay a dividend (see below for extensions to handle
dividend payments).
5. All securities are perfectly divisible (i.e. it is possible to buy any frac-
tion of a share).
6. There are no restrictions on short selling.
7. There is no arbitrage opportunity.
From these ideal conditions in the market for an equity (and for an option on
the equity), the authors show that it is possible to create a hedged position,
consisting of a long position in the stock and a short position in [calls on the
same stock], whose value will not depend on the price of the stock.
Notation. We deﬁne the following quantities:
- S, the price of the stock (please note as below).
- V pS, tq, the price of a ﬁnancial derivative as a function of time and
stock price.
- CpS, tq the price of a European call and PpS, tq the price of a European
put option.
- K, the strike of the option.
- r, the annualized risk-free interest rate, continuously compounded.
- µ, the drift rate of S, annualized.
- σ, the volatility of the stock; this is the square root of the quadratic
variation of the stock’s log price process.
- t a time in years; we generally use now “ 0, expiry “ T.
- Π, the value of a portfolio.
- R, the accumulated proﬁt or loss following a delta-hedging trading
strategy.
- Npxq denotes the standard normal cumulative distribution function,
Npxq “
1
?
2π
ż x
´8
e´ 1
2 z2 dz.
- N 1pxq “
1
?
2πe´ 1
2 x2 denotes the standard normal probability density
function.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
189 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Black-Scholes PDE. Simulated Geometric Brownian Motions with Parameters
from Market Data
In the model as described above, we assume that the underlying asset (typically
the stock) follows a geometric Brownian motion. That is,
dSptq “ µSptq dt ` σSptq dWptq,
where Wptq is a Brownian motion; the dW term here stands in for any and all
sources of uncertainty in the price history of a stock.
The payoﬀof an option V pS, Tq at maturity is known. To ﬁnd its value at an
earlier time we need to know how V evolves as a function of S and T. By Itˆo’s
lemma for two variables we have
dV pSptq, tq “ BV pSptq, tq
BS
dSptq ` BV pSptq, tq
Bt
dt ` 1
2
B2V pSptq, tq
B2S
d xS, Sy ptq
“
ˆ
µSptqBV pSptq, tq
BS
` BV pSptq, tq
Bt
` 1
2σ2Sptq2B2V pSptq, tq
BS2
˙
dt
` σSptqBV pSptq, tq
BS
dWptq.
(3.208)
Now consider a trading strategy under which one holds aptq units of a single
option with value Sptq and bptq units of a bond with value βptq at time t. The
value V pSptq, tq of the portfolio of the trading strategy paptq, bptqq is then given
by
V pSptq, tq “ aptqSptq ` bptqβptq.
(3.209)
Observe that (3.209) is equivalent to
bptq “ V pSptq, tq ´ aptqSptq
βptq
.
In addition, aptq “ BV pSptq, tq
Bs
, which is called the delta hedging rule. Assum-
ing, like in the Black-Sholes model, that the strategy paptq, bptqq is self-ﬁnancing,
which by deﬁnition implies
dV pSptq, tq “ aptq dSptq ` bptq dβptq,
(3.210)
we get
dV ptq “ µaptqSptq dt ` bptq dβptq ` σaptqSptq dWptq.
(3.211)
Assume that the process t ÞÑ βptq, i.e., the bond price, is of bounded varia-
tion. By equating the terms with dWptq in (3.208) and (3.211) we see aptq “
BV pSptq, tq
BS
.
From this and again equating the other terms in (3.208) and
(3.211) and using (3.209) we also obtain
ˆBV pSptq, tq
Bt
` 1
2σ2Sptq2B2V pSptq, tq
BS2
˙
dt
“ bptq dβptq “
ˆ
V pSptq, tq ´ SptqBV pSptq, tq
Bs
˙ dβptq
βptq .
(3.212)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
190 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
If the interest rate for the bond is constant, i.e., if dβptq “ rβptq dt, or, what
amounts to the same, βptq “ βp0qert, then from (3.212) it also follows that
BV pSptq, tq
Bt
` 1
2σ2Sptq2B2V pSptq, tq
BS2
“ r
ˆ
V pSptq, tq ´ SptqBV pSptq, tq
Bs
˙
.
(3.213)
If we trade in a single option continuously trades in the stock in order to hold
´BV
BS shares, then at time t, the value of these holdings will be
Πptq “ V pSptq, tq ´ SptqBV pSptq, tq
BS
.
The composition of this portfolio, called the delta-hedge portfolio, will vary from
time-step to time-step. Let Rptq denote the accumulated proﬁt or loss from
following this strategy. Then over the time period rt, t ` dts, the instantaneous
proﬁt or loss is
dRptq “ dV pSptq, tq ´ BV pSptq, tq
BS
dSptq.
By substituting in the equations above we get
dRptq “
ˆBV pSptq, tq
Bt
` 1
2σ2S2B2V pSptq, tq
BS2
˙
dt.
This equation contains no dWptq term. That is, it is entirely risk free (delta
neutral). Black, Scholes and Merton reason that under their ideal conditions,
the rate of return on this portfolio must be equal at all times to the rate of return
on any other risk free instrument; otherwise, there would be opportunities for
arbitrage. Now assuming the risk free rate of return is r we must have over the
time period rt, t ` dts (Black-Scholes assumption):
rΠptq dt “ dRptq “
ˆBV pSptq, tq
Bt
` 1
2σ2S2B2V pSptq, tq
BS2
˙
dt.
Observe that the Black-Sholes assumption comes down to the assumption of
self-ﬁnancing, because the results If we now substitute in for Πptq and divide
through by dt we obtain the Black-Scholes PDE:
BV pSptq, tq
Bt
` 1
2σ2S2B2V pSptq, tq
BS2
` rS BV pSptq, tq
BS
´ rV pSptq, tq “ 0. (3.214)
Observe that the Black-Sholes assumption comes down to the assumption of
self-ﬁnancing, because the resulting partial diﬀerential equation in (3.213) and
(3.214) is the same. With the assumptions of the Black-Scholes model, this
partial diﬀerential equation holds whenever V is twice diﬀerentiable with respect
to S and once with respect to t. Above we used the method of arbitrage-free
pricing (“delta-hedging”) to derive some PDE governing option prices given the
Black-Scholes model. It is also possible to use a risk-neutrality argument. This
latter method gives the price as the expectation of the option payoﬀunder a
particular probability measure, called the risk-neutral measure, which diﬀers
from the real world measure.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
191 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Black-Scholes formula. The Black-Scholes formula is used for obtaining the price
of European put and call options. It is obtained by solving the Black-Scholes
PDE as discussed - see derivation below.
The value of a call option in terms of the Black-Scholes parameters is given by:
CpS, tq “ C pSptq, tq “ SptqNpd1q ´ Ke´rpT´tqNpd2q with
(3.215)
d1 “
logp S
Kq `
´
r ` σ2
2
¯
pT ´ tq
σ
?
T ´ t
and
d2 “ d1 ´ σ
?
T ´ t.
(3.216)
The price of a put option is:
PpS, tq “ P pSptq, tq “ Ke´rpT´tqNp´d2q ´ SptqNp´d1q.
(3.217)
For both, as above:
1. Np¨q is the standard normal or cumulative distribution function.
2. T ´ t is the time to maturity.
3. S “ Sptq is the spot price of the underlying asset at time t.
4. K is the strike price.
5. r is the risk free interest rate (annual rate, expressed in terms of con-
tinuous compounding).
6. σ is the volatility in the log-returns of the underlying asset.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENT…
     RUN FASTER.
          RUN LONGER..
                RUN EASIER…
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

Advanced stochastic processes: Part I
192 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Interpretation. The quantities N pd1q and N pd2q are the probabilities of the
option expiring in-the-money under the equivalent exponential martingale prob-
ability measure (num´eraire = stock) and the equivalent martingale probability
measure (num´eraire = risk free asset), respectively. The equivalent martingale
probability measure is also called the risk-neutral probability measure. Note
that both of these are probabilities in a measure theoretic sense, and neither of
these is the true probability of expiring in-the-money under the real probability
measure.
Derivation. We now show how to get from the general Black-Scholes PDE to
a speciﬁc valuation for an option. Consider as an example the Black-Scholes
price of a call option, for which the PDE above has boundary conditions
Cp0, tq “ 0 for all t
CpS, tq Ñ S as S Ñ 8
CpS, Tq “ maxpS ´ K, 0q.
The last condition gives the value of the option at the time that the option
matures. The solution of the PDE gives the value of the option at any earlier
time, E rmaxpS ´ K, 0qs. In order to solve the PDE we transform the equation
into a diﬀusion equation which may be solved using standard methods. To this
end we introduce the change-of-variable transformation
τ “ T ´ t,
upx, τq “ C
´
Kex´pr´ 1
2 σ2qτ, T ´ τ
¯
erτ, and x “ log S
K `pr ´ σ2
2 qτ.
Note: in fact in case we consider a call option we replace V pSptq, tq with
C pSptq, tq. Instead of u we may also consider
vpx, tq “ V
´
Kex´pr´ 1
2 σ2qpT´tq, t
¯
erpT´tq.
In case we consider a European call option we take as ﬁnal value for v: vpx, Tq “
V pKex, Tq “ C pKex, Tq “ max pKex ´ K, 0q “ K max pex ´ 1, 0q. Then the
Black-Scholes PDE becomes a diﬀusion equation
Bu
Bτ “ 1
2σ2B2u
Bx2.
The terminal condition CpS, Tq “ maxpS ´ K, 0q now becomes an initial con-
dition
upx, 0q “ u0pxq ” K max pex ´ 1, 0q .
Using the standard method for solving a diﬀusion equation we have
upx, τq “
1
σ
?
2πτ
ż 8
´8
u0pyqe´px´yq2{p2σ2τq dy.
After some calculations we obtain
upx, τq “ Kex`σ2τ{2N pd1q ´ KN pd2q
where
d1 “ x ` σ2τ
σ?τ
and d2 “
x
σ?τ .
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
193 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Substituting for u, x, and τ, we obtain the value of a call option in terms of the
Black-Scholes parameters is given by
CpS, tq “ SNpd1q ´ Ke´rpT´tqNpd2q,
where d1 and d2 are as in (3.216). The price of a put option may be computed
from this by the put-call parity and simpliﬁes to
PpS, tq “ Ke´rpT´tqNp´d2q ´ SNp´d1q.
Risk neutral measure. Suppose our economy consists of 2 assets, a stock and
a risk-free bond, and that we use the Black-Scholes model. In the model the
evolution of the stock price can be described by Geometric Brownian Motion:
dSptq “ µSptq dt ` σSptq dWptq
where Wptq is a standard Brownian motion with respect to the physical measure.
If we deﬁne
Ă
Wptq “ Wptq ` µ ´ r
σ
t,
Girsanov’s theorem states that there exists a measure Q under which Ă
Wptq is a
standard Brownian motion, i.e., a Brownian motion without a drift term and
such that EQ
”
Ă
Wptq2ı
“ t. For a more thorough discussion on the Girsanov’s
theorem, which is in fact (much) more general, see assertion (4) in Proposition
4.24 in Chapter 4 Section 3. The quantity µ ´ r
σ
is known as the market price
of risk. Diﬀerentiating and rearranging yields:
dWptq “ dĂ
Wptq ´ µ ´ r
σ
dt.
Put this back in the original equation:
dSptq “ rSptq dt ` σSptq dĂ
Wptq.
The probability Q is the unique risk-neutral measure for the model. The (dis-
counted) payoﬀprocess of a derivative on the stock Hptq “ EQ
`
HpTq
ˇˇ Ft
˘
is
a martingale under Q. Since S and H are Q-martingales we can invoke the
martingale representation theorem to ﬁnd a replicating strategy – a holding of
stocks and bonds that pays oﬀHptq at all times t ď T. The measure Q is given
by QpAq “ E
“
e´ZpTq1A
‰
, A P FT, where
Zptq “ 1
2
´µ ´ r
σ
¯2
t ` µ ´ r
σ
Wptq.
In fact a more general result is true. Let s ÞÑ hpsq be a predictable process such
that E
„
exp
ˆ1
2
ż T
0
|hpsq|2 ds
˙ȷ
ă 8. Put
Zhptq “
ż t
0
hpsqdWpsq ` 1
2
ż t
0
|hpsq|2 ds.
Deﬁne the measure Qh by QhpAq “ E
“
e´ZhpTq1A
‰
, A P FT.
Put Whptq “
Wptq `
şt
0 hpsq ds. Then the process Wh is a Brownian motion relative to the
measure Qh. The proof of this result uses L´evy’s characterization of Brownian
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
194 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
motion: see Corollary 4.7. It says that a process Wh is a Qh-Brownian motion
if and only if the following two conditions are satisﬁed:
(1) The quadratic variation of Wh satisﬁes ⟨Wh, Wh⟩ptq “ t.
(2) The process Wh is a local martingale relative to the measure Qh.
(For a proof of this result see Theorem 4.5.) In our case we have ⟨Wh, Wh⟩ptq “
⟨W, W⟩ptq “ t, and so (1) is satisﬁed. In order to establish (2) we use Itˆo
calculus to obtain:
e´ZhptqWhptq “
ż t
0
e´ZhpsqdWpsq ´
ż t
0
e´ZhpsqWhpsqhpsq dWpsq.
Since the process t ÞÑ e´Zhptq is a martingale we see that the process Wh is a
local Qh-martingale.
We like to spend more time on the Black-Sholes model and the corresponding
risk-neutral measure. Again we have trading strategy paptq, bptqq of a ﬁnancial
asset and a bond. Its portfolio value V ptq :“ V pSptq, tq is given by V ptq “
aptqSptq ` bptqβptq.
Here Sptq is the price of the option at time t and βptq
is the price of the bond at time t. It is assumed that the process t ÞÑ Sptq
follows a geometric Brownian motion: dSptq “ µSptq dt`σSptq dWptq, or Sptq “
Sp0qeσWptq`pµ´ 1
2 σ2qt. Let rSptq be the discounted price of the option, i.e.,
rSptq “ βp0q
βptq Sptq.
(3.218)
Put Ă
Wptq “ Wptq `
şt
0 qpsq ds, where
qpsq “ 1
σ
ˆ
µ ´ β1psq
βpsq
˙
.
Then the process rSptq satisﬁes the equation
drSptq “ σβp0q
βptq Sptq d
ˆ 1
σ
ż t
0
ˆ
µ ´ β1psq
βpsq
˙
ds ` Wptq
˙
“ σ rSptq dĂ
Wptq. (3.219)
Put Zqptq “
ż t
0
qpsq dWpsq ` 1
2
ż t
0
qpsq2 ds. By Girsanov’s theorem the process
t ÞÑ Ă
Wptq is a (standard) Brownian motion under the measure Qq given by
QqpAq “ E
“
e´ZqpTq1A
‰
, A P FT. The solution rSptq of the SDE in (3.219) can
be written in the form
rSptq “ rSp0qeσĂ
Wptq´ 1
2 σ2t.
(3.220)
Assume that the portfolio is self-ﬁnancing we will show that
V ptq “ EQq
„ βptq
βpTqh pSpTqq
ˇˇ Ft
ȷ
,
t P r0, Ts,
(3.221)
where V pTq is equal to the contingent claim h pSpTqq at the time of maturity
T. Of course, EQq “
F
ˇˇ Ft
‰
denotes the conditional expectation of F relative
Qq, given the σ-ﬁeld Ft “ σ pWpsq : s ď tq of the variable F P L1 pΩ, FT, Qqq
with respect to the probability measure Qq. Another application of Itˆo’s lemma
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
195 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
together with the deﬁnition of rSptq, Ă
Wptq and rV ptq “ βp0q
βptq V ptq shows the
following result
drV ptq “ ´βp0qβ1ptq
βptq2
V ptq dt ` βp0q
βptq dV ptq
(the hedging strategy paptq, bptqq is self-ﬁnancing)
“ ´βp0qβ1ptq
βptq2
V ptq dt ` βp0q
βptq paptq dSptq ` bptqdβptqq
(employ the equation for the option price Sptq)
“ ´βp0qβ1ptq
βptq2
V ptq dt ` βp0q
βptq Sptq
ˆ
µaptq dt ` bptqβ1ptq
βptq dt ` σdWptq
˙
“ ´βp0qβ1ptq
βptq2
paptqSptq ` bptqβptqq dt
` βp0q
βptq Sptq
ˆ
µaptq dt ` bptqβ1ptq
βptq dt ` σdWptq
˙
“ σaptqβp0q
βptq Sptq d
" 1
σ
ż t
0
ˆ
µ ´ β1psq
βpsq
˙
ds ` Wptq
*
“ σaptqrSptq dĂ
Wptq.
(3.222)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

Advanced stochastic processes: Part I
196 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In fact the equality in (3.222) could also have been obtained by observing that
drV ptq “ aptq drSptq,
and drSptq “ σdĂ
Wptq.
(3.223)
From (3.222) we infer
rV ptq “ rV p0q ` σ
ż t
0
apsq dĂ
Wpsq,
(3.224)
and hence, the process t ÞÑ rV ptq is a martingale with respect to the measure
Qq. So from (3.224) we get
βp0q
βptq V ptq “ rV ptq “ EQq ”
rV pTq
ˇˇ Ft
ı
“ EQq
„ βp0q
βpTqV pTq
ˇˇ Ft
ȷ
,
(3.225)
and hence
V ptq “ EQq
„ βptq
βpTqV pTq
ˇˇ Ft
ȷ
“ EQq
„ βptq
βpTqh pSpTqq
ˇˇ Ft
ȷ
.
(3.226)
In addition, we observe that
SptqβpTq
βptq e´ 1
2 σ2pT´tq`σpĂ
WpTq´Ă
Wptqq
“ Sptq exp
ˆż T
t
ˆβ1psq
βpsq ´ 1
2σ2
˙
ds ` σ
´
Ă
WpTq ´ Ă
Wptq
¯˙
“ Sp0q exp
ˆ
σWptq `
ˆ
µ ´ 1
2σ2
˙
t
˙
ˆ exp
ˆż T
t
ˆβ1psq
βpsq ´ 1
2σ2
˙
ds ` σ
ˆ
WpTq ´ Wptq `
ż T
t
qpsq ds
˙˙
“ Sp0qepµ´ 1
2σ2qT`σWpTq “ SpTq.
(3.227)
Inserting the equality for SpTq from (3.227) into (3.226) yields
V ptq “ EQq
„ βptq
βpTqh
ˆ
SptqβpTq
βptq e´ 1
2 σ2pT´tq`σpĂ
WpTq´Ă
Wptqq
˙ ˇˇ Ft
ȷ
.
(3.228)
Since the variable Sptq is measurable with respect to Ft, Since process t ÞÑ Ă
Wptq
is a Qq-Brownian motion, the variable Ă
WpTq ´ Ă
Wptq and the σ-ﬁeld Ft are Qq-
independent.
Moreover, the process t ÞÑ βptq is supposed to deterministic.
Hence, since the variable Sptq is measurable with respect to Ft, we deduce that
V ptq “ V pSptq, tq
“
1
?
2π
ż 8
´8
βptq
βpTqh
ˆ
xβpTq
βptq e´ 1
2 σ2pT´tq`σ
?
T´ty
˙
e´ 1
2 y2 dy
ˇˇ
x“Sptq . (3.229)
Hence if the pay-oﬀ, i.e. the value of the call option at expiry (time of maturity
T), is given by h pSpTqq “ max tSpTq ´ K, 0u, then the value of the portfolio
at time t ď T is given by the formula in (3.229). If βptq “ βp0qert, then this
integral can be rewritten as in (3.215) with C pS, tq “ C pSptq, tq “ V pSptq, tq “
V ptq. Similarly, if h pSpTqq “ max tK ´ SpTq, 0u, then P pS, tq “ P pSptq, tq “
V pSptq, tq “ V ptq is the price of a European put option: see the somewhat
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
197 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
more explicit expression in (3.217). For a modern treatment of several stock
price models see, e.g., Gulisashvili [60].
8. An Ornstein-Uhlenbeck process in higher dimensions
Part of this text is taken from [146]. Let C pt, sq, t ě s, t, s P R, be a family of
d ˆ d matrices with real entries, with the following properties:
(a) Cpt, tq “ I, t P R, (I stands for the identity matrix).
(b) The following identity holds: Cpt, sqCps, τq “ Cpt, τq holds for all real
numbers t, s, τ for which t ě s ě τ.
(c) The matrix valued function pt, s, xq ÞÑ Cpt, sqx is continuous as a func-
tion from the set
␣
pt, sq P Rd ˆ Rd : t ě s
(
ˆ Rd to Rd.
Deﬁne the backward propagator YC on Cb
`
Rd˘
by YCps, tqfpxq “ f pCpt, sqxq,
x P Rd, s ď t, and f P Cb
`
Rd˘
. Then YC is a backward propagator on the space
Cb
`
Rd˘
, which is σ
`
Cb
`
Rd˘
, M
`
Rd˘˘
-continuous. Here the symbol M
`
Rd˘
stands for the vector space of all signed measures on Rd. The operator family
tYCps, tq : s ď tu satisﬁes YC ps1, s2q YC ps2, s3q “ YC ps1, s3q, s1 ď s2 ď s3.
Let Wptq be standard m-dimensional Brownian motion on pΩ, Ft, Pq and let
σpρq be a deterministic continuous function which takes its values in the space
of d ˆ m-matrices. Put Qpρq “ σpρqσpρq˚. Another interesting example is the
following:
YC,Q ps, tq fpxq
“
1
p2πqd{2
ż
e´ 1
2 |y|2f
˜
Cpt, sqx `
ˆż t
s
Cpt, ρqQpρqCpt, ρq˚dρ
˙1{2
y
¸
dy
“ E
„
f
ˆ
Cpt, sqx `
ż t
s
Cpt, ρqσpρq dWpρq
˙ȷ
,
(3.230)
where Qpρq “ σpρqσpρq˚ is a positive-deﬁnite d ˆ d matrix. Then the propaga-
tors YC,Q and YC,S are backward propagators on Cb
`
Rd˘
. We will prove this.
The equality of the expressions in (3.230) is a consequence of the following ar-
guments. Let the variable ξ P Rd have the standard normal distribution. Fix
t ě τ. Both variables
Xτ,xptq :“ C pt, τq x `
ż t
τ
C pt, ρq σpρqdWpρq,
t ě τ, and
Cpt, τqx `
ˆż t
τ
Cpt, ρqQpρqCpt, ρq˚dρ
˙1{2
ξ,
t ě τ,
(3.231)
are Rd-valued Gaussian vectors. A calculation shows that they have the same
expectation and the same covariance matrix with entries given by (3.242) below
with s “ t.
Next suppose that the forward propagator C on Rd consists of contractive op-
erators, i.e. Cpt, sqCpt, sq˚ ď I (this inequality is to be taken in matrix sense).
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
198 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Choose a family S pt, sq of square d ˆ d-matrices such that Cpt, sqCpt, sq˚ `
S pt, sq S pt, sq˚ “ I, and put
YC,S ps, tq fpxq “
1
p2πqd{2
ż
e´ 1
2 |y|2f pCpt, sqx ` Spt, sqyq dy.
(3.232)
In fact the example in (3.232) is a special case of the example in (3.230) provided
Qpρq is given by the following limit:
Qpρq “ lim
hÓ0
I ´ C pρ ´ hq C pρ ´ hq˚
h
(3.233)
If Qpρq is as in (3.233), then
S pt, sq S pt, sq˚ “ I ´ C pt, sq C pt, sq˚ “
ż t
s
C pt, ρq QpρqC pt, ρq˚ dρ.
The following auxiliary lemma will be useful. Condition (3.234) is satisﬁed if the
three pairs pC1, S1q, pC2, S2q, and pC3, S3q satisfy: C1C˚
1 `S1S˚
1 “ C2C˚
2 `S2S˚
2 “
C3C˚
3 ` S3S˚
3 “ I. It also holds if C2 “ C pt2, t1q, and
SjS˚
j “
ż tj
tj´1
C ptj, ρq σpρqσpρq˚C ptj, ρq˚ dρ,
j “ 1, 2,
and
S3S˚
3 “
ż t2
t0
C pt2, ρq σpρqσpρq˚C pt2, ρq˚ dρ.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

Advanced stochastic processes: Part I
199 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.89. Lemma. Let C1, S1, C2, S2, and C3, S3 be dˆd-matrices with the following
properties:
C3 “ C2C1,
and
C2S1S˚
1C˚
2 ` S2S˚
2 “ S3S˚
3.
(3.234)
Let f P Cb
`
Rd˘
, and put
Y1,2fpxq “
1
p2πqd{2
ż
e´ 1
2 |y|2f pC1x ` S1yq dy;
(3.235)
Y2,3fpxq “
1
p2πqd{2
ż
e´ 1
2 |y|2f pC2x ` S2yq dy;
(3.236)
Y1,3fpxq “
1
p2πqd{2
ż
e´ 1
2 |y|2f pC3x ` S3yq dy.
(3.237)
Then Y1,2Y2,3 “ Y1,3.
Proof. Let the matrices Cj and Sj, 1 ď j ď 3, be as in (3.234).
Let
f P Cb
`
Rd˘
. First we assume that the matrices S1 and C2 are invertible, and
we put A3 “ S´1
1 C´1
2 S3, and A2 “ S´1
1 C´1
2 S2.
Then, using the equalities
in (3.234) we see A3A˚
3 “ I ` A2A˚
2. We choose a d ˆ d-matrix A such that
A˚A “ I`A˚
2A2, and we put D “ pA´1q˚ A˚
2A3. Then we have A˚
3A3 “ I`D˚D.
Let f P Cb
`
Rd˘
. Let the vectors py1, y2q P Rd ˆ Rd and py, zq P Rd ˆ Rd be such
that
ˆ
y1
y2
˙
“
ˆ
A3
´A2A´1
0
A´1
˙ ˆ
y
z
˙
.
(3.238)
Since
A2A˚
2 pI ` A2A˚
2q´1 “ A2 pI ` A˚
2A2q´1 A˚
2,
we obtain
det pI ` A2A˚
2q “ det pI ` A˚
2A2q .
Hence, the absolute value of the determinant of the matrix in the right-hand
side of (3.238) can be rewritten as:
ˇˇˇˇdet
ˆ
A3
´A2A´1
0
A´1
˙ˇˇˇˇ
2
“
ˇˇdet A3 pdet Aq´1ˇˇ2
“ det pA3A˚
3q
det pA˚Aq “ det pI ` A2A˚
2q
det pI ` A˚
2A2q “ 1.
(3.239)
From (3.238) and (3.239) it follows that the corresponding volume elements
satisfy: dy1 dy2 “ dy dz. We also have
|y1|2 ` |y2|2 “ |y|2 ` |z ´ Dy|2 .
(3.240)
Employing the substitution (3.238) together with the equalities dy1 dy2 “ dy dz
and (3.240) and applying Fubini’s theorem we obtain:
Y1,2Y2,3fpxq “
1
p2πqd
ĳ
e´ 1
2p|y1|2`|y2|2qf pC2C1x ` C2S1y1 ` S2y2q dy1dy2
“
1
p2πqd
ĳ
e´ 1
2p|y|2`|z´Dy|2qf pC3x ` S3yq dy dz
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
200 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
“
1
p2πqd{2
ż
e´ 1
2 |y|2f pC3x ` S3yq dy “ Y1,3fpxq
(3.241)
for all f P Cb
`
Rd˘
.
If the matrices S1 and C2 are not invertible, then we
replace the C1 with C1,ε “ e´εC1 and S1,ε satisfying C1,εC˚
1,ϵ ` S1,εS˚
1,ε “ I,
and limεÓ0 S1,ε “ S1.
We take S2,ε “ e´εS2 instead of S2.
In addition, we
choose the matrices C2,ε, ε ą 0, in such a way that C2,εC˚
2,ϵ ` S2,εS˚
2,ε “ I, and
limεÓ0 C2,ε “ C2.
This completes the proof of Lemma 3.89.
□
We formulate a proposition in which an Ornstein-Uhlenbeck process plays a
central role.
Here ρ ÞÑ σpρq is a deterministic square matrix function, and
Qpρq “ σpρqσpρq˚.
3.90. Proposition. Put Xτ,xptq “ C pt, τq x `
şt
τ C pt, ρq σpρqdWpρq. Then the
process Xτ,xptq is Gaussian. Its expectation is given by E rXτ,xptqs “ C pt, τq x,
and its covariance matrix has entries (s, t ě τ
P-cov
`
Xτ,x
j psq, Xτ,x
k ptq
˘
“
˜ż minps,tq
τ
C ps, ρq QpρqC pt, ρq˚ dρ
¸
j,k
(3.242)
Let
␣
pΩ, F, Pτ,xq , pXptq, t ě 0q ,
`
Rd, Bd˘(
be the corresponding time-inhomogen-
eous Markov process.
By deﬁnition, the P-distribution of the process t ÞÑ
Xτ,xptq, t ě τ, is the Pτ,x-distribution of the process t ÞÑ Xptq, t ě τ. Then this
process is generated by the family operators Lptq, t ě 0, where
Lptqfpxq “ 1
2
dÿ
j,k“1
Qj,kptqDjDkfpxq ` ⟨∇fpxq, Aptqx⟩.
(3.243)
Here the matrix-valued function Aptq is given by Aptq “ lim
hÓ0
Cpt ` h, tq ´ I
h
.
The semigroup esLptq, s ě 0, is given by
esLptqfpxq
“ E
„
f
ˆ
esAptqx `
ż s
0
eps´ρqAptqσptqdWpρq
˙ȷ
“
1
p2πqd{2
ż
e´ 1
2 |y|2f
˜
esAptqx `
ˆż s
0
eρAptqQptqeρAptq˚dρ
˙1{2
y
¸
dy
“
ż
p ps, x, y; tq fpyqdy
(3.244)
where, with QAptqpsq “
ż s
0
eρAptqQptqeρAptq˚dρ, the integral kernel p ps, x, y; tq is
given by
p ps, x, y; tq
“
1
p2πqd{2 `
det QAptqpsq
˘d{2e
´
´ 1
2
⟨
pQAptqpsqq
´1py´esAptqxq,y´esAptqx
⟩¯
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
201 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
If all eigenvalues of the matrix Aptq have strictly negative real part, then the
measure
B ÞÑ
1
p2πqd{2
ż
e´ 1
2|y|21B
ˆż 8
0
eρAptqQptqeρAptq˚dρ y
˙
dy
deﬁnes an invariant measure for the semigroup esLptq, s ě 0.
A Markov process of the form
␣
pΩ, F, Pτ,xq , pXptq, t ě 0q ,
`
Rd, BRd
˘(
is called
a (generalized) Ornstein-Uhlenbeck process. It is time-homogeneous by putting
Cpt, sq “ e´pt´sqA, where A is a square d ˆ d-matrix. We will elaborate on the
time-homogeneous case. In this case we write, for x, b P Rd,
Sptqfpxq :“ E
„
f
ˆ
e´tAx `
`
I ´ e´tA˘
b `
ż t
0
e´pt´sqAσ dBpsq
˙ȷ
,
(3.245)
where f : Rd Ñ C is a bounded Borel measurable function. If f belongs to
C0
`
Rd˘
, then Sptqf does so as well. For brevity we write
Xxptq “ e´tAx `
`
I ´ e´tA˘
b `
ż t
0
e´pt´sqAσ dWpsq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

Advanced stochastic processes: Part I
202 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
It also follows that for such functions limtÓ0 Sptqfpxq “ fpxq for all x P Rd.
Since we also have the semigroup property S pt1 ` t2q f “ S pt1q S pt2q f for all
t1, t2 ě 0, it follows that the semigroup t ÞÑ Sptq is in fact a Feller semigroup.
Theorem 3.37 implies that there exists a time-homogeneous Markov process
␣
pΩ, F, PxqxPRd , pXptq, t ě 0q , pϑt, t ě 0q ,
`
Rd, BRd
˘(
such that for a bounded Borel function f we have
Ex rf pXptqqs “ E rf pXxptqqs “ Sptqfpxq, x P Rd.
(3.246)
Nest we prove the semigroup property. First we observe that, for x P Rd and
t1, t2 ě 0,
Xx pt1 ` t2q “ e´t2AXx pt1q`
`
I ´ e´t2A˘
b`
ż t2
0
e´pt2´sqAσ dW ps ` t1q . (3.247)
Let
`
ΩW, FW, P
˘
be the probability space on which the process t ÞÑ Wptq is a
Brownian motion. Let
`
FW
t
˘
tě0 be the internal history of the Brownian motion
tWptq : t ě 0u, so that FW
t
“ σ pWpsq : s ď tq. Then by the equality in (3.247)
we have
E
“
f pXx pt1 ` t2qq
ˇˇ FW
t1
‰
(3.248)
“ E
„
f
ˆ
e´t2AXx pt1q `
`
I ´ e´t2A˘
b `
ż t2
0
e´pt2´sqAσ dW ps ` t1q
˙ ˇˇ FW
t1
ȷ
We employ the fact that the state variable Xx pt1q is FW
t1 -measurable, and that
ż t1`t2
t1
e´pt1`t2´sqAσ dWpsq “
ż t2
0
e´pt2´sqAσ d tW ps ` t1q ´ W pt1qu
is P-independent of FW
t1 and possesses the same P-distribution as the variable
şt2
0 e´pt2´sqAσ dW psq to conclude from (3.248) the following equality:
E
“
f pXx pt1 ` t2qq
ˇˇ FW
t1
‰
“ E
„
f
ˆ
e´t2Az `
`
I ´ e´t2A˘
b `
ż t2
0
e´pt2´sqAσ dW psq
˙ȷ ˇˇ
z“Xxpt1q
“ E rf pXz pt2qqs
ˇˇ
z“Xxpt1q .
(3.249)
From (3.249) it follows that the process t ÞÑ Xxptq is a Markov process and
that, by the deﬁnition of the operators Sptq, t ě 0,
S pt1 ` t2q fpxq “ E rf pXx pt1 ` t2qqs
“ E
”
E rf pXz pt2qqs
ˇˇ
z“Xxpt1q
ı
“ E rS pt2q f pXx pt1qqs
“ S pt1q S pt2q fpxq.
(3.250)
We calculate the diﬀerential dXxptq and the covariation process
@
Xx
j1, Xx
j2
D
ptq:
dXxptq “ ´A pXxptq ´ bq dt ` σ dWpsq,
and
(3.251)
@
Xx
j1, Xx
j2
D
ptq “
ż t
0
´
e´sAσσ˚e´sA˚¯
j1,j2 ds “ cov
`
Xx
j1ptq, Xx
j2ptq
˘
.
(3.252)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
203 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In other words the process t ÞÑ Xxptq satisﬁes the equation
Xxptq “ x `
ż t
0
A pb ´ Xxpsqq ds `
ż t
0
σ dWpsq.
(3.253)
Since its covariation is deterministic we have that the covariation coincides with
its covariance: see (3.252). Let f : Rd Ñ C be a bounded continuous function
with bounded and continuous ﬁrst and second order derivatives. Next we apply
Itˆo’s lemma, and employ (3.251) and (3.252) to obtain
f pXxptqq ´ f pXxp0qq “
ż t
0
∇f pXxpsqq ¨ t´A pXxpsq ´ bqu ds
` 1
2
dÿ
j1,j2“1
ż t
0
Dj1Dj2f pXxpsqq
´
e´sAσσ˚e´sA˚¯
j1,j2 ds
`
ż t
0
∇f pXxpsqq ¨ σ dWpsq.
(3.254)
Upon taking expectations in the right-hand and left-hand sides of (3.254), using
the fact that the stochastic integral in (3.254) ia a martingale, and letting t Ó 0
shows:
LAfpxq :“ lim
tÓ0
Sptqfpxq ´ fpxq
t
“ lim
tÓ0
E rf pXxptqq ´ f pXxp0qqs
t
“ ´ pApx ´ bqq ¨ ∇fpxq ` 1
2
dÿ
j1,j2“1
pσσ˚qj1,j2 Dj1Dj2fpxq.
(3.255)
In the following proposition we collect the main properties of the time-homo-
geneous Ornstein-Uhlenbeck process t ÞÑ Xxptq. It is adapted from Proposition
3.90. In adition, σ “ σpρq is independent of ρ.
3.91. Proposition. Put Xxptq “ e´tAx `
`
I ´ e´tA˘
b `
şt
0 e´pt´ρqAσ dWpρq.
Then the process Xxptq is Gaussian. Its expectation is given by E rXxptqs “
e´tAx `
`
I ´ e´tA˘
b, and its covariance matrix has entries
P-cov
`
Xx
j1psq, Xx
j2ptq
˘
“
˜ż minps,tq
0
e´ps´ρqAσσ˚e´pt´ρqA˚ dρ
¸
j1,j2
(3.256)
Let
␣
pΩ, F, Pτ,xq , pXptq, t ě 0q ,
`
Rd, Bd˘(
be the corresponding time-inhomogen-
eous Markov process. By deﬁnition, the P-distribution of the process t ÞÑ Xxptq,
t ě τ, is the Px-distribution of the process t ÞÑ Xptq, t ě 0. Then this process
is generated by the operator LA, t ě 0, where
LAfpxq “ 1
2
dÿ
j1,j2“1
pσσ˚qj1,j2 Dj1Dj2fpxq ´ ⟨∇fpxq, Apx ´ bq⟩.
(3.257)
The semigroup esLA, s ě 0, is given by
esLAfpxq
“ E
„
f
ˆ
e´sApx ´ bq ` b `
ż s
0
e´ps´ρqAσ dWpρq
˙ȷ
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
204 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
“
1
p2πqd{2
ż
e´ 1
2 |y|2f
˜
e´sApx ´ bq ` b `
ˆż s
0
e´ρAσσ˚e´ρA˚ dρ
˙1{2
y
¸
dy
“
ż
pA ps, x, yq fpyq dy
(3.258)
where, with QApsq “
ż s
0
e´ρAσσ˚e´ρA˚ dρ, the integral kernel pA ps, x, yq is given
by
pA ps, x, yq “
1
p2πqd{2 pdet QApsqqd{2ep´ 1
2⟨pQApsqq´1py´e´sApx´bq´bq,y´e´sApx´bq´b⟩q.
If all eigenvalues of the matrix A have strictly positive real part, then the measure
B ÞÑ
1
p2πqd{2
ż
e´ 1
2 |y|21B
ˆ
b `
ż 8
0
e´ρAσσ˚e´ρA˚y dρ
˙
dy
(3.259)
deﬁnes an invariant measure for the semigroup esLA, s ě 0.
Proof. The results in Proposition 3.91 follow more or less directly from
those in Proposition 3.90. The result in (3.259) follows by letting s Ñ 8 in
the second equality of (3.258) or in the deﬁnition of the probability density
pA ps, x, yq.
□
For more information about invariant, or stationary, measures see, e.g., [146]
(Chapter 10) and the references therein like Meyn and Tweedie [97].
In order to apply our results on the Ornstein-Uhlenbeck process to bond pricing
and determining interest rates in ﬁnancial mathematics the identities and results
in the following proposition are very useful. It will be applied in the context of
the Vasicek model.
3.92. Proposition. Let the notation and hypotheses be as in Proposition 3.91.
Put
Apt, Tq “
ż T´t
0
e´ρA dρ “
ż T
t
e´ρs ds “ A´1 `
I ´ e´pT´tqA˘
,
0 ď t ď T,
where the last equality is only valid if A is invertible. Let y be a vector in Rd.
The following assertions hold true.
(1) The following identity is true for 0 ď t ă T:
ż T
t
Xxpsq ds “ Apt, Tq pXxptq ´ bq ` pT ´ tqb `
ż T
t
A pρ, Tq σ dWpρq. (3.260)
(2) The random vector
şT
t Xxpsq ds is Gaussian (or, what is the same, mul-
tivariate normally distributed) with conditional expectation given by
E
„ż T
t
Xxpsq ds
ˇˇ Ft
ȷ
“ E
„ż T
t
Xxpsq ds
ˇˇ Xxptq
ȷ
“ Apt, Tq pXxptq ´ bq`pT ´tqb,
(3.261)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
205 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
and covariance matrix given by (1 ď j1, j2 ď d)
cov
ˆż T
t
Xx
j1psq ds
ˇˇ Xxptq,
ż T
t
Xx
j2psq ds
ˇˇ Xxptq
˙
“
ˆż T
t
A pρ, Tq σσ˚A pρ, Tq˚ dρ
˙
j1,j2
.
(3.262)
(3) The random variable
⟨
y,
şT
t Xxpsq ds
⟩
is normally distributed with con-
ditional expectation given by
E
„⟨
y,
ż T
t
Xxpsq ds
⟩ˇˇ Ft
ȷ
“ E
„⟨
y,
ż T
t
Xxpsq ds
⟩ˇˇ Xxptq
ȷ
“ ⟨y, Apt, Tq pXxptq ´ bq⟩` pT ´ tq ⟨y, b⟩,
(3.263)
and variance given by
var
ˆ⟨
y,
ż T
t
Xxpsq ds
⟩ˇˇ Xxptq
˙
“
ż T
t
ˇˇσ˚A pρ, Tq˚ y
ˇˇ2 dρ.
(3.264)
(4) The conditional expectation of exp
´
´
⟨
y,
şT
t Xxpsq ds
⟩¯
given Ft is log-
normal, and
E
„
exp
ˆ
´
⟨
y,
ż T
t
Xxpsq ds
⟩˙ ˇˇ Ft
ȷ
“ E
„
exp
ˆ
´
⟨
y,
ż T
t
Xxpsq ds
⟩˙ ˇˇ Xxptq
ȷ
“ exp
ˆ
´ ⟨y, Apt, Tq pXxptq ´ bq⟩´ pT ´ tq ⟨y, b⟩` 1
2
ż T
t
ˇˇσ˚A pρ, Tq˚ y
ˇˇ2 dρ
˙
.
(3.265)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

Advanced stochastic processes: Part I
206 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. (1) From (3.247) we see, for s ě t,
Xx psq “ e´ps´tqA pXx ptq ´ bq ` b `
ż s
t
e´ps´ρqAσ dW pρq .
(3.266)
Then we integrate the expressions in (3.266) against s for t ď s ď T, and we
interchange the integrals with respect to ds and dWpρq to obtain the equality
in (3.260). This proves assertion (1).
(2) Although the process t ÞÑ
şT
t A pρ, Tq dWpρq is not a martingale, it has
enough properties of a martingale that its expectation is 0, and that its quadratic
covariation matrix is given by the expression in (3.262). The reason for all this
relies on the equality:
ż T
t
A pρ, Aq dWpρq “
ż T
0
A pρ, Tq dWpρq ´
ż t
0
A pρ, Tq dWpρq,
(3.267)
combined with the fact that the process t ÞÑ
şt
0 A pρ, Tq dWpρq is a martingale.
So we can apply the Itˆo isometry and its consequences to complete the proof
of assertion (2).
An alternative way of understanding this reads as follows.
Processes of the form s ÞÑ Xxpsq, s ď 0, and t ÞÑ
şT
t Xxpsq ds, 0 ď t ď T,
consist of Gaussian vectors with known means and variances. For s ě t we use
the representation in (3.266) for Xxpsq, and for
şT
t Xxpsq ds we employ (3.260).
(3) The proof of this assertion follows the same line as the proof of the assertion
in (2).
(4) If the stochastic variable Z is normally distributed with expectation µ and
variance v2 “ E
“
pZ ´ µq2‰
, then E
“
eZ‰
“ eµ` 1
2v2. This result is applied to the
variable Z “ ´
⟨
y,
şT
t Xxpsq ds
⟩
to obtain the equality in (3.265).
This completes the proof of Proposition 3.92.
□
3.93. Lemma. Let the notation and hypotheses be as in the proposition 3.91 and
3.92. Suppose that the matrix A is invertible. The following equality holds for
0 ď t ď T:
ż T
t
A pρ, Tq σσ˚A pρ, Tq˚ dρ
“ pT ´ tqA´1σσ˚ pA˚q´1 ´ A pt, Tq A´1σσ˚ pA˚q´1 ´ A´1σσ˚ pA˚q´1 A pt, Tq˚
`
ż T´t
0
e´ρAA´1σσ˚ pA˚q´1 e´ρA˚ dρ.
(3.268)
If the invertible matrix A is such that Aσσ˚ “ σσ˚A˚, then the following equality
is valid for 0 ď t ď T:
ż T
t
A pρ, Tq σσ˚A pρ, Tq˚ dρ
“ pT ´ tqA´1σσ˚ pA˚q´1 ´ A pt, Tq A´1σσ˚ pA˚q´1 ´ 1
2 pApt, Tqq2 σσ˚ pA˚q´1
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
207 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
“
ˆ
T ´ t ´ A pt, Tq ´ 1
2A pApt, Tqq2
˙
A´1σσ˚ pA˚q´1 .
(3.269)
Observe that an equality of the form Aσσ˚ “ σσ˚A˚ holds whenever A “ A˚
and the matrix σσ˚ is a “function” of A. In particular this is true when d “ 1
and A “ a is a real number.
Proof. Since A is invertible we have A pρ, Tq “
`
I ´ e´pT´ρqA˘
A´1, and so
ż T
t
A pρ, Tq σσ˚A pρ, Tq˚ dρ
“
ż T
t
`
I ´ e´pT´ρqA˘
A´1σσ˚ pA˚q´1 ´
I ´ e´pT´ρqA˚¯
dρ
“
ż T´t
0
`
I ´ e´ρA˘
A´1σσ˚ pA˚q´1 ´
I ´ e´ρA˚¯
dρ
“ pT ´ tqA´1σσ˚ pA˚q´1 ´ A pt, Tq A´1σσ˚ pA˚q´1 ´ A´1σσ˚ pA˚q´1 A pt, Tq˚
`
ż T´t
0
e´ρAA´1σσ˚ pA˚q´1 e´ρA˚ dρ.
(3.270)
The ﬁnal equality in (3.270) proves (3.268). Next we also assume that Aσσ˚ “
σσ˚A˚. Then σσ˚e´ρA˚ “ e´ρAσσ˚, and hence
ż T´t
0
e´ρAA´1σσ˚ pA˚q´1 e´ρA˚ dρ
“
ż T´t
0
e´2ρA dρ A´1σσ˚ pA˚q´1 e´ρA˚
“ 1
2
`
I ´ e2pT´tqA˘
A´2σσ˚ pA˚q´1 e´ρA˚.
(3.271)
A simple calculation shows
1
2
`
I ´ e´2pT´tqA˘
“ Apt, TqA ´ 1
2 pApt, Tqq2 A2,
(3.272)
and so the equalities in (3.271) show
ż T´t
0
e´ρAA´1σσ˚ pA˚q´1 e´ρA˚ dρ “
ż T´t
0
e´2ρA dρ A´1σσ˚ pA˚q´1
“
ˆ
Apt, Tq ´ 1
2 pApt, Tqq2 A
˙
A´1σσ˚ pA˚q´1 .
(3.273)
A combination of (3.270) and (3.273) together with the equality σσ˚A pt, Tq˚ “
A pt, Tq σσ˚ then yields the equality in (3.269), completing the proof of Lemma
3.93.
□
Before we discuss the Vasicek model we insert Girsanov’s theorem formulated
in a way as we will use it in Theorem 3.101. In fact we will formulate it in a
multivariate context.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
208 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.94. Theorem. Let tXptq : 0 ď t ď tu be an Itˆo process satisfying
dXptq “ vptq dt ` uptq dWptq. 0 ď t ď T.
Suppose there exists a process tθptq : 0 ď t ď Tu, with the property that
P
„ż T
0
|ϑptq|2 dt ă 8
ȷ
“ 1,
such that the process vptq ´ uptqθptq has this property as well. Assume further-
more that the process t ÞÑ Eptq, 0 ď t ď T, deﬁned by
Eptq “ exp
ˆ
´
ż t
0
θpsq dWpsq ´ 1
2
ż t
0
|θpsq|2 ds
˙
(3.274)
is a P-martingale, which is guaranteed provided E rEptqs “ 1 for 0 ď t ď T.
Deﬁne the measure P˚ such that dP˚
dP “ EpTq. Then
t ÞÑ W ˚ptq :“ Wptq `
ż t
0
θpsq ds,
t P r0, Ts,
is a Brownian motion w.r.t. P˚ and the process tXptq : 0 ď t ď Tu has a rep-
resentation w.r.t. W ˚ptq given by
dXptq “ pvptq ´ uptqθptqq dt ` uptq dW ˚ptq.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

Advanced stochastic processes: Part I
209 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We shortly show that tEptq : 0 ď t ď Tu is a diﬀusion process.
Set Y ptq “
şt
0 θpsq dWpsq, 0 ď t ď T, and consider the function fpt, xq P C2 pr0, Ts, Rq
deﬁned by
fpt, xq “ exp
ˆ
´x ´ 1
2
ż t
0
|θpsq|2 ds
˙
.
Then we clearly have that Eptq “ f pt, Y ptqq. By Itˆo’s formula we have
dEptq “ ´1
2 |θptq|2 Eptq dt ´ Eptqθptq dWptq ` 1
2Eptq d ⟨Y, Y ⟩ptq
“ ´1
2 |θptq|2 Eptq dt ´ Eptqθptq dWptq ` 1
2Eptq |θptq|2 dt
“ ´θptqEptq dWptq.
(3.275)
Hence, it follows that
Eptq “ Ep0q ´
ż t
0
θpsqEpsq dWpsq,
which in general is a local martingale for which E rEptqs ď 1.
It is a sub-
martingale, but not necessarily a martingale. If, for 0 ď t ď T, the expecta-
tion E rEptqs “ 1, then t ÞÑ Eptq, 0 ď t ď T, is a martingale. If Novikov’s
condition, i.e., if E
”
exp
´
1
2
şT
0 |θptq|2 dt
¯ı
ă 8 is satisﬁed, then the process
tEptq : 0 ď t ď Tu is a martingale. For details on this condition, see Corollary
4.27 in Chapter 4. For more results on (local) exponential martingales see sub-
section 1.3 of Chapter 4 as well. In section 3 of the same chapter the reader may
ﬁnd some more information on Girsanov’s theorem. In particular, see assertion
(4) of Proposition 4.24 and Theorem 4.25.
8.1. The Vasicek model. In this subsection we want to employ the results
in Proposition 3.92 with d “ 1 to ﬁnd the bond prices in the Vasicek model.
Until now we were always working in the physical probability space pΩ, F, Pq.
In order to calculate the fair price of a ﬁnancial instrument one often uses the
method of risk-neutral pricing. Through this technique the price of a ﬁnancial
asset is the expectation of its discounted pay-oﬀat the so-called risk-neutral
measure Q. The risk-neutral measure is equivalent to the physical measure P.
Suppose for example that tSptqusě0 is the price of a certain asset at time t.
The price of our asset at time t discounted to time 0 is then given by rSptq :“
e´
şt
0 rpuq duSptq. As a main property of the risk-neutral measure, the family of
discounted prices
!
rSptq
)
tě0 is a Q-martingale. This means that for every s,
0 ď s ď t, we have
E
”
rSptq
ˇˇ Fs
ı
“ E
”
e´
şt
0 rpuq duSptq
ˇˇ Fs
ı
“ e´
şs
0 rpuq duSpsq “ rSpsq,
(3.276)
where expectations E are with respect to Q. Because of this property, a risk-
neutral measure is also called an equivalent martingale measure. Roughly speak-
ing, the existence of such a measure is equivalent with the no-arbitrage assump-
tion. We will use this martingale property to price a zero-coupon bond. That
is a ﬁnancial debt instrument that pays the holder a ﬁxed amount named the
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
210 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
face value at maturity T. For simplicity we take 1 as face value. The price of a
zero-coupon bond is then given by the following theorem.
3.95. Theorem. Consider a zero-coupon bond which pays an amount of 1 at
maturity T. The price at time t ď T is then
Ppt, Tq “ E
”
e´
şT
t rpsq ds ˇˇ Ft
ı
.
(3.277)
Proof. We use the above explained property that the discounted price
e´
şt
0 rpsq dsPpt, Tq is a martingale, and the trivial fact that PpT, Tq “ 1,
e´
şt
0 rpsq dsPpt, Tq “ E
”
e´
şT
0 rpsq dsPpT, Tq
ˇˇ Ft
ı
“ E
”
e´
şT
0 rpsq ds ˇˇ Ft
ı
“ e´
şt
0 rpsq dsE
”
e´
şT
t rpsq ds ˇˇ Ft
ı
.
(3.278)
The bond’s price can thus be written as Ppt, Tq “ E
”
e´
şT
t rpsq ds ˇˇ Ft
ı
. This
completes the proof of Theorem 3.95.
□
Formula (3.277) is an expression of the bond’s price for an arbitrary chosen
interest rate process. We will now apply this to our Vasicek model trptqutě0.
We will investigate three methods that all lead to the same result stated in the
following theorem. We follow the approach of Mamon in [94]. For an alternative
approach see [114] as well.
3.96. Theorem. Consider a zero-coupon bond which pays an amount of 1 at
maturity T. Suppose that under the risk-neutral measure the short rate follows
an Ornstein-Uhlenbeck process: drptq “ a pb ´ rptqq dt`σ dWptq. The fair price
of the bond at time t ď T is then given by
Ppt, Tq “ e´Apt,Tqrptq`Dpt,Tq,
(3.279)
where
Apt, Tq “ 1 ´ e´apT´tq
a
,
and
Dpt, Tq “ pApt, Tq ´ T ` tq pa2b ´ σ2{2q
a2
´ σ2Apt, Tq2
4a
.
(3.280)
Equation (3.279) is an aﬃne term structure model. In fact, the bond yield ytpTq
is deﬁned as the constant interest rate at which the price of the bond grows to
it’s face value, i.e., Ppt, TqeytpTqpT´tq “ 1. We thus ﬁnd that
ytpTq “ ´ log Ppt, Tq
T ´ t
“ Apt, Tqrptq ´ Dpt, Tq
T ´ t
,
which is indeed aﬃne in rptq. The yield curve or term structure at time t is the
graph pT, ytpTqq.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
211 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
8.1.1. Bond price implied by the distribution of the short rate. The ﬁrst
method to calculate the bond price is quite straightforward. It calculates the
conditional expectation in formula (3.277) by determining the distribution of
E
”şT
t rpsq ds
ˇˇ Ft
ı
.
First proof of Theorem 3.96. Because formula (3.277) shows that the
bond’s price at time t is conditional on Ft, we may assume that rptq is a pa-
rameter. Using formula (3.266) (for d “ 1, and A “ 1) with starting time t we
ﬁnd, for s ą t,
rpsq “ rptqe´aps´tq ` b
`
1 ´ e´aps´tq˘
`
ż s
t
e´aps´ρqσ dWpρq.
We want to determine the distribution of e´
şT
t rpsq ds conditioned by Ft. Note
that because of the Markov property of the Otnstein-Uhlenbeck process (or
more generally for diﬀusion processes: see the equality in (3.249)), this distri-
bution will only depend on rptq. Let’s start by determining the distribution of
şT
t rpsq ds given Ft. This distribution is normal, and essentially speaking this it
follows from Proposition 3.92 and Lemma 3.93. First of all from assertion (3)
in Proposition 3.92 we get by (3.263)
E
„ż T
t
rpsq ds
ˇˇ Ft
ȷ
“ E
„ż T
t
rpsq ds
ˇˇ rptq
ȷ
“ Apt, Tq prptq ´ bq ` pT ´ tqb.
(3.281)
Secondly from (3.264) and (3.269) in Lemma 3.93 we get
var
ˆż T
t
Xxpsq ds
ˇˇ Xxptq
˙
“
ż T
t
σ2 pA pρ, Tqq2 dρ
“ σ2
a2
´
T ´ t ´ A pt, Tq ´ a
2 pApt, Tqq2¯
.
(3.282)
The equality in (3.279) of Theorem 3.96 then follows from (3.282) and (3.265)
in (4) of Proposition 3.92.
□
8.1.2. Bond price by solving the PDE. A second method that is proposed to
calculate the bond’s price in the Vasicek model, is by solving partial diﬀerential
equations. More precisely, we will derive a PDE for the bond’s price by using
martingales.
Taking into account the Markov property of the process trptqutě0 (see equality
in (3.249)) one can introduce the following variable:
Ppt, Tq “ E
”
e´
şT
t rpsq ds ˇˇ Ft
ı
“ E
”
e´
şT
t rpsq ds ˇˇ rptq
ı
“ E
”
e´
şT
t rpsqpzq dsı ˇˇ
z“rptq“: P pt, T, rptqq .
(3.283)
Here rpsq, s ą t, is the function of rptq given by
rpsq “ rptqe´aps´tq ` b
`
1 ´ eaps´tq˘
`
ż s
t
e´aps´ρq dWpρq.
(3.284)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
212 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
We now provide a second proof of Theorem 3.96.
Second proof of Theorem 3.96. We will apply Itˆo’s formula to the
function fpt, xq “ e´
şt
0 rpsq dsPpt, T, xq. Then we obtain
E
”
e´
şT
0 rpsq ds ´ P p0, T, rp0qq
ˇˇ Ft
ı
“ e´
şt
0 rpsq dsP pt, T, rptqq ´ P p0, T, rp0qq
“
ż t
0
„
´rpuqe´
şu
0 rpsq dsP pu, T, rpuqq ` e´
şu
0 rpsq dsBP pu, T, rpuqq
Bu
ȷ
du
`
ż t
0
„
e´
şu
0 rpsq dsBP pu, T, rpuqq
Brpuq
ȷ
pa pb ´ rpuqq du ` σdWpuqq
` σ2
2
ż t
0
„
e´
şu
0 rpsq dsB2P pu, T, rpuqq
Brpuq2
ȷ
du.
(3.285)
Put
fptq “ ´rptqe´
şt
0 rpsq dsP pt, T, rptqq ` e´
şt
0 rpsq dsBP pt, T, rptqq
Bt
`
„
e´
şt
0 rpsq dsBP pt, T, rptqq
Brpuq
ȷ
pa pb ´ rptqqq
` σ2
2 e´
şt
0 rpsq dsB2P pt, T, rptqq
Brptq2
.
(3.286)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

Advanced stochastic processes: Part I
213 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
From the equality in (3.285) it follows that the process t ÞÑ
şt
0 fpuq du is a
martingale. By Lemma 3.97 below it follows that fptq “ 0 P-almost surely.
From (3.286) it then follows that the function Ppt, T, xq satisﬁes the following
diﬀerential equation:
´xP pt, T, xq ` BP pt, T, xq
Bt
` BP pt, T, xq
Bx
pa pb ´ xqq ` σ2
2
B2P pt, T, xq
Bx2
“ 0.
(3.287)
From (3.283) and (3.284) it follows that
BPpt, T, xq
Bx
“ ´1
a
`
1 ´ e´apT´tq˘
Ppt, T, xq “ ´Apt, TqPpt, T, xq.
(3.288)
From (3.288) we easily infer that
P pt, T, xq “ C pt, Tq e´Apt,Tqx.
(3.289)
Inserting this expression for P pt, T, xq into (3.287) yields the ﬁrst order equation
´x `
1
Cpt, Tq
BCpt, Tq
Bt
´ BApt, Tq
Bt
x ´ Apt, Tq tapb ´ xqu ` σ2
2 Apt, Tq2 “ 0.
(3.290)
Because ´1 ´ BApt, Tq
Bt
` aApt, Tq “ 0, the equality in (3.290) implies:
1
Cpt, Tq
BCpt, Tq
Bt
´ abApt, Tq ` σ2
2 Apt, Tq2 “ 0.
(3.291)
Since CpT, Tq “ P pT, T, 0q “ 1 from (3.291) we infer Cpt, Tq “ eDpt,Tq and
hence
Ppt, Tq “ P pt, T, rptqq “ e´Apt,Tqrptq`Dpt,Tq,
which completes the proof of Theorem 3.96 by employing the PDE as formulated
in (3.287).
□
The equation in (3.287) is called the PDE for the bond price in the Vasicek
model.
3.97. Lemma. Let
`
Ω, pFtqtě0 , P
˘
be ﬁltered probability space, and let the right-
continuous adapted process tfptqutě0 be such that for some sequence of stopping
times pτnqnPN, which increases to 8, the integrals
şt
0 |fpsq| 1r1,τns ds are ﬁnite P-
almost surely. If the process t ÞÑ
şt
0 fpsq ds is a local martingale, then fptq “ 0
P-almost surely for almost all t.
Proof. Fix 0 ă T ă 8. By localizing at stopping times pτ 1
nqnPN, τ 1
n ď τn,
n P N, τn Ò 8 (n Ñ 8) we may assume that
E
„ż T
0
|fpsq| ds
ȷ
ă 8.
(3.292)
Otherwise we replace fptq with f ptq 1r0,τ 1nsptq, and prove that f ptq 1r0,τ 1nsptq “ 0
for all n P N. But then fptq “ 0, by letting n Ñ 8. So we assume that (3.292)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
214 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
is satisﬁed. Then for 0 ď s ă t ď T we have
ż s
0
fpρq dρ ` E
„ż t
s
fpρq dρ
ˇˇ Fs
ȷ
“ E
„ż t
0
fpρq dρ
ˇˇ Fs
ȷ
“
ż s
0
fpρq dρ.
(3.293)
From (3.293) we infer that E
”şt
s fpρq dρ
ˇˇ Fs
ı
“ 0, P-almost surely, for all 0 ď
s ă t ă T. diﬀerentiating with respect to t then results in E
“
fptq
ˇˇ Fs
‰
“ 0
P-almost surely for all 0 ď s ă t ă T. But then, by the right-continuity of the
process tfptqutě0 it follows that
fpsq “ lim
tÓs E
“
fptq
ˇˇ Fs
‰
“ 0,
P-almost surely.
This completes the proof of Lemma 3.97.
□
8.1.3. Bond prices using forward rates. The third and last method to calcu-
late a bond’s price in the Vasicek model, is based upon the concept of forward
rates. Indeed, in the Heath-Jarrow-Morton pricing paradigm the closed-form
of the bond’s price follows directly from the short rate dynamics under the so-
called forward measure. Suppose we are at time t. We want to know the rate
of interest in the period of time between T1 en T2 with t ă T1 ă T2. This is
called the forward rate for the period between T1 and T2 and we denote it by
f pt, T1, T2q. When the rates between time t and T1 and between time t and T2
are known - write R1 and R2 - we must have:
eR1pT1´tqefpt,T1,T2qpT2´T1q “ eR2pT2´tq.
Hence, we ﬁnd for the forward rate
f pt, T1, T2q “ R2 pT2 ´ tq ´ R1 pT1 ´ tq
T2 ´ T1
.
Applying this in our framework of bond prices, R1 and R2 equal the bond yields:
R1 “ ´ log P pt, T1q
T1 ´ t
,
R2 “ ´ log P pt, T2q
T2 ´ t
,
such that the forward rate is given by
f pt, T1, T2q “ ´ log P pt, T2q ´ log P pt, T1q
T2 ´ T1
.
When T1 and T2 come inﬁnitesimally close to each other, we obtain a so-called
instantaneous forward rate. The instantaneous forward rate at time T ą t is
fpt, Tq “ ´ lim
t1ÑT
log P pt, Tq ´ log P pt, t1q
T ´ t1
“ ´B log P pt, t1q
Bt1
ˇˇ
t1“T .
Solving this partial diﬀerential equation for P pt, Tq on rt, Ts we ﬁnd immedi-
ately that
P pt, Tq “ e´
şT
t fpt,sq ds.
(3.294)
Later on we will see that the link between the instantaneous forward rate and
the short rate is the so-called forward measure. In the sequel, we will need two
properties of conditional expectations under change of measure. These results
can be found in [32]. In the following theorems P is a probability measure on a
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
215 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
σ-algebra F, the probability measure Q ! P is such that dQ
dP “ Z. Furthermore
G is a sub-σ-algebra of F. The symbol E denotes expectation w.r.t. P, while
EQ stands for expectation w.r.t. Q.
3.98. Theorem. In the notation of above, it holds that
dQ
ˇˇ
G
dP
ˇˇ
G
“ E
“
Z
ˇˇ G
‰
.
Proof. Take an arbitrary B P G. We need to show that
QpBq “ E
“
E
“
Z
ˇˇ G
‰
1B
‰
.
Indeed:
E
“
E
“
Z
ˇˇ G
‰
1B
‰
“ E
“
E
“
Z1B
ˇˇ G
‰‰
“ E rZ1Bs “ QpBq.
This completes the proof of Theorem 3.98.
□
3.99. Theorem. For any F-measurable random variable X :
E
“
Z
ˇˇ G
‰
EQ “
X
ˇˇ G
‰
“ E
“
ZX
ˇˇ G
‰
.
Proof. Let Y “ E
“
Z
ˇˇ G
‰
. Take B P G arbitrary, then:
EQ “
1BE
“
ZX
ˇˇ G
‰‰
“ E
“
Y 1BE
“
ZX
ˇˇ G
‰‰
“ E
“
E
“
Y 1BZX
ˇˇ G
‰‰
“ E rY 1BZXs “ EQ rY 1BXs “ EQ “
EQ “
1BY X
ˇˇ G
‰‰
“ EQ “
1BEQ “
Y X
ˇˇ G
‰‰
.
In the ﬁrst step we used that 1BE
“
ZX
ˇˇ G
‰
is G-mesurable. Hence we could
apply Theorem 3.98 which tells us that dQ
ˇˇ
G“ Y dP
ˇˇ
G. Because the previous
reasoning holds for all B P G we must have:
E
“
ZX
ˇˇ G
‰
“ EQ “
Y X
ˇˇ G
‰
“ Y EQ “
X
ˇˇ G
‰
what proves the claim in Theorem 3.99.
□
As well as the economic term forward rates, we introduce the concept of a
num´eraire.
A num´eraire is a tradeable economic security in terms of which
the relative prices of other assets can be expressed. This allows us not only to
compare diﬀerent ﬁnancial instruments at a certain moment, it makes it also
possible to compare the prices of assets at diﬀerent times. A typical example
of a num´eraire is money. The random variable Mptq “ e
şt
0 rpsq ds represents the
value at time t of an asset which was invested in the money market at time
0 with value 1. Recall that in accordance with the deﬁnition of a risk-neutral
measure Q, the price of an asset relative to the money market is a martingale.
In our new notation the expressions in (3.276) become:
E
„ Sptq
Mptq
ˇˇ Fs
ȷ
“ E
”
e´
şt
0 rpuq duSptq
ˇˇ Fs
ı
“ e´
şs
0 rpuq duSpsq “ Spsq
Mpsq,
with 0 ď s ď t. We say that Q is an equivalent martingale measure for the
num´eraire tMptqutě0. Let Nptq be the price at time t of another traded asset.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
216 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Suppose that Q˚ is an equivalent martingale measure for tNptqutě0, i.e. for all
0 ď s ď t:
E˚
„ Sptq
Nptq
ˇˇ Fs
ȷ
“ Spsq
Npsq.
We can also deﬁne this measure on the basis of the Radon-Nikodym derivative
of Q˚ w.r.t. Q.
3.100. Theorem. Suppose that Q is an equivalent martingale measure for the
num´eraire tMptqutě0. Let Q˚ be an absolutely continuous measure w.r.t. Q
deﬁned by the Radon-Nikodym derivative:
Γt :“ dQ˚
dQ
ˇˇ
Ft“ Mp0q
Mptq
Nptq
Np0q,
(3.295)
where Nptq ą 0 is the price at time t of a particular asset. Then Q˚ is an
equivalent martingale measure for tNptq : t ě 0u.
Proof. Denote expectations w.r.t.
Q by E and w.r.t.
Q˚ by E˚.
Let
Sptq be the price of an asset at time t ě 0 and assume Sptq P L2 pΩ, Ft, Qq X
L2 pΩ, Ft, Q˚q. For t ě s ě 0 we ﬁnd using Theorem 3.99
E˚
„ Sptq
Nptq
ˇˇ Fs
ȷ
“ E
„Mp0qNptq
MptqNp0q
Sptq
Nptq
ˇˇ Fs
ȷ
{E
„Mp0qNptq
MptqNp0q
ˇˇ Fs
ȷ
“ Mp0q
Np0q E
„ Sptq
Mptq
ˇˇ Fs
ȷ Np0q
Mp0q
Mpsq
Npsq “ Spsq
Npsq.
The proof of Theorem 3.100 is complete now.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

Advanced stochastic processes: Part I
217 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Note that the measures Q and Q˚ are equivalent because of the strictly posi-
tiveness of the Radon-Nikodym derivative. We already mention the following
theorem which transforms the dynamics of a process under Q to a process under
Q˚.
3.101. Theorem. Let Q be an equivalent martingale measure for tMptqutě0 and
let Q˚ be deﬁned by equation (3.295). Assume tXptq : 0 ď t ď tu a diﬀusion
process with dynamics under Q
dXptq “ b pt, Xptqq dt ` σ pt, Xptqq dWptq.
Let also Mptq and Nptq have dynamics under Q given by
dMptq “ mM dt ` σM dWptq,
dNptq “ mN dt ` σN dWptq.
Then the dynamics of tXptq : 0 ď t ď tu under Q˚ is given by
dXptq “ b pt, ωq dt ´ σ pt, ωq
ˆ σM
Mptq ´ σN
Nptq
˙
dt ` σ pt, ωq dW ˚ptq,
where
W ˚ptq “ Wptq `
ż t
0
ˆ σM
Mpsq ´ σN
Npsq
˙
ds.
Proof. It is clear that we want to apply Girsanov’s Theorem 3.94. But then
we need to know how θ pt, ωq in expression (3.274) looks like. From expression
(3.275) we know that
dΓt “ ´θ pt, ¨q Γt dWptq.
(3.296)
On the other hand:
dΓt “ Mp0q
Np0q d
ˆ Nptq
Mptq
˙
“ Mp0q
Np0q
dNptqMptq ´ NptqdMptq
Mptq2
“
Mp0q
Np0qMptq2 ppmN dt ` σN dWptqq Mptq ´ Nptq pmM dt ` σM dWptqqq .
(3.297)
Because tΓt : 0 ď t ď Tu is a martingale we must have that the coeﬃcient of dt
is 0, hence
dΓt “
Mp0q
Np0qMptq2 pσN dWptqMptq ´ NptqσM dWptqq
“
ˆ σN
Nptq ´ σM
Mptq
˙
Γt dWptq.
Comparing this with (3.296) we have that
θpt, ωq “ σM
Mptq ´ σN
Nptq.
Finally applying Girsanov’s Theorem 3.94 to this we have
dXptq “ b pt, ωq dt ´ σ pt, ωq
ˆ σM
Mptq ´ σN
Nptq
˙
dt ` σ pt, ωq dW ˚ptq,
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
218 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
with
W ˚ptq “ Wptq `
ż t
0
ˆ σM
Mpsq ´ σN
Npsq
˙
ds.
Altogether this completes the proof of Theorem 3.101.
□
In order to make the link between the short rate rptq and the instantaneous
forward rate fpt, Tq, we introduce a new measure QT. Suppose again that Q is
the risk neutral measure w.r.t. the money market and E the expectation w.r.t.
Q.
3.102. Definition. Take T ě 0. The forward measure QT is deﬁned on FT by
setting
ΓT :“ dQT
dQ “ Mp0q
MpTqPpT, TqP p0, Tq “ e´
şT
0 rpsq dsP p0, Tq ,
where
Mptq “ e
şt
0 rpsq ds,
and P pt, Tq “ E
”
e´
şT
t rpsq ds ˇˇ Ft
ı
.
By the previous theorem we conclude that QT is an equivalent martingale mea-
sure which has a bond with maturity T as num´eraire.
For t ă T we can easily calculate Γt as follows:
Γt :“ E
“
ΓT
ˇˇ Ft
‰
“
Mp0q
P p0, TqE
„PpT, Tq
MpTq
ˇˇ Ft
ȷ
“
1
P p0, Tq
P pt, Tq
Mptq
“ e´
şt
0 rpsq ds P pt, Tq
P p0, Tq,
where we used in the second to last equality that Q has tMptqutě0 as num´eraire.
Now we have all theoretical background information to formulate the third proof
of Theorem 3.96.
Third proof of Theorem 3.96. Denote as before the expectation w.r.t.
Q by E and the expectation w.r.t. QT by ET. We have by Theorem 3.99 that
for any FT-measurable random variable X and t ď T
ET rXjFts “ Γ´1
t E
“
XΓT
ˇˇ Ft
‰
“ E
„
X ΓT
Γt
ˇˇ Ft
ȷ
“ E
„
X MptqPpT, Tq
MpTqP pt, Tq
ˇˇ Ft
ȷ
“ E
«
X e´
şT
t rpsq ds
P pt, Tq
ﬀ
.
We want to express the forward rate in terms of the short rate. We got a formula
for the bonds price in function of both of them. Diﬀerentiating expression (16)
towards T gives
BP pt, Tq
BT
“ E
”
´rpTqe´
şT
t rpsq ds ˇˇ Ft
ı
“ ET “
´rpTqP pt, Tq
ˇˇ Ft
‰
“ ´ET “
rpTq
ˇˇ Ft
‰
P pt, Tq .
(3.298)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
219 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
In the second step we used the above reasoning with X “ ´rpTqP pt, Tq. Dif-
ferentiating now formula (3.294) with respect to T gives
BP pt, Tq
BT
“ ´P pt, Tq fpt, Tq.
(3.299)
Comparing (3.298) en (3.299) we get the link between short rate and forward
rate
fpt, Tq “ ET “
rpTq
ˇˇ Ft
‰
.
(3.300)
Considering the right hand side of (3.300) we will need to describe the dynamics
of rptq under QT . Applying Itˆo’s formula on fpt, xq “ e
şt
0 rpsq ds we immediately
ﬁnd that dMptq “ rptqMptq dt. In the notation of Theorem 3.101 we thus have
σM “ 0. If we then apply this theorem with Xptq “ rptq, Q˚ “ QT, σ pt, Xptqq “
σ, b pt, Xptqq “ a pb ´ rptqq and σN “ ´σA pt, Tq P pt, Tq we obtain:
drptq “
`
ab ´ σ2A pt, Tq ´ arptq
˘
dt ` σ dW Tptq
“ a
ˆ
b ´ σ2
a2
`
1 ´ e´apT´tq˘
´ rt
˙
dt ` σ dW Tptq
(3.301)
where W Tptq is the QT-Brownian motion deﬁned by
W Tptq “ Wptq ` σ
ż t
0
A ps, Tq ds.
Expression (3.301) resembles an ordinary Vasicek process, except that the term
b ´ σ2
a2
`
1 ´ e´apT´tq˘
does depend upon t and is thus not a constant. However,
we will use a similar reasoning as in the classical situation to solve the SDE for
rptq on the interval rt, Ts. First, we apply Itˆo’s formula on gpt, xq “ eatx:
d
`
eatrptq
˘
“ abeat dt ´ 1 ´ e´apT´tq
a
σ2eat dt ` σeat dW Tptq
“ abeat dt ´ σ2
a
`
eat ´ e´apT´2tq˘
dt ` σeat dW Tptq.
Integrating from t to T gives
eaTrpTq ´ eatrptq
“ ab
ż T
t
eas ds ´ σ2
a
ż T
t
`
eas ´ e´apT´2sq˘
ds ` σ
ż T
t
eas dW Tpsq
“ b
`
eaT ´ eat˘
´ σ2
a
„1
a
`
eaT ´ eat˘
´ 1
2a
`
eaT ´ e´apT´2tq˘ȷ
` σ
ż T
t
eas dW Tpsq
“ b
`
eaT ´ eat˘
´ σ2
2a2
´
eaT ´ 2eat ` e´apT ´2tq¯
` σ
ż T
t
eas dW Tpsq.
Thus we have that
rpTq “ rptqe´apT´tq ` b
`
1 ´ e´apT´tq˘
´ σ2
2a2
`
1 ´ 2e´apT´tq ` e´2apT´tq˘
` σ
ż T
t
e´apT´sq dW Tpsq.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
220 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
And hence,
fpt, sq “ Es “
rpsq
ˇˇ Ft
‰
“ rptqe´aps´tq ` b
`
1 ´ e´aps´tq˘
´ σ2
a2
`
1 ´ 2e´aps´tq ` e´2aps´tq˘
“ rptqe´aps´tq `
ˆ
b ´ σ2
2a2
˙ `
1 ´ e´aps´tq˘
` σ2
2a2
`
e´aps´tq ´ e´2aps´tq˘
.
Integrating results in
ż T
t
Es “
rpsq
ˇˇ Ft
‰
ds “ rptq
a
`
1 ´ e´apT´tq˘
`
ˆ
b ´ σ2
2a2
˙ ˆ
T ´ t ´ 1 ´ e´apT´tq
a
˙
` σ2
2a3
`
1 ´ e´apT´tq˘
´ σ2
4a3
`
1 ´ e´2apT´tq˘
“ rptqA pt, Tq `
ˆ
b ´ σ2
2a2
˙
pT ´ t ´ A pt, Tqq ` σ2
4aA pt, Tq2
“ rptqA pt, Tq ´ Dpt, Tq.
(3.302)
Reminding formula (3.294) and formula (3.300) we ﬁnd again that
Ppt, Tq “ e´Apt,Tqrt`Dpt,Tq.
This completes the third proof of Theorem 3.96.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
221 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
9. A version of Fernique’s theorem
The following theorem is due to Fernique. We follow the proof of H.H. Kuo
[77].
3.103. Theorem. Let pΩ, F, Pq be a probability space and let X : ΩÑ Rd be a
Gaussian vector with mean zero. Put
α “ sup
u,vą0
1
pu ` vq2 log P p|X| ď vq
P p|X| ą uq.
(3.303)
Then α ą 0 and
E
ˆ
exp
ˆ1
2η |X|2
˙˙
ă 8 for η ă α.
(3.304)
For the proof we shall need two lemmas. The ﬁrst one contains the main idea.
3.104. Lemma. Let pΩ, F, Pq and X be as in Theorem 3.103. Let s ą 0 be such
that P p|X| ď sq ą 0 and ﬁx t ą s. Then
P p|X| ą tq
P p|X| ď sq ď
˜
P
`
|X| ą pt ´ sq{
?
2
˘
P p|X| ď sq
¸2
.
(3.305)
Proof. Let pΩb Ω, F b F, P b Pq be the tensor product space of pΩ, F, Pq
with itself and deﬁne Xi, i “ 1, 2, by Xipω1, ω2q “ Xpωiq. Then the variables
X1 and X2 are independent with respect P b P and their P b P-distribution
coincides with the P-distribution of X. We shall prove Lemma 3.104. for s “ v
and t “ u
?
2 ` v. Since the vector pX1, X2q is Gaussian with respect to P b P
and since the components of X1 ´ X2 are uncorrelated with the components
of X1 ` X2 (with respect to the probability P b P), it follows that the vectors
X1 ´ X2 and X1 ` X2 are independent. Notice that
ş
XdP “
ş
X1dP b P “
ş
X2dP b P “ 0 and that the covariance matrices of X, of pX1 ´ X2q {
?
2 and
of pX1 ` X2q {
?
2 all coincide. It follows that the joint distributions of pX1, X2q
and of
ˆX1 ´ X2
?
2
, X1 ` X2
?
2
˙
are the same as well. Hence the following (in-
)equalities are now self-explanatory:
P p|X| ď vq P
´
|X| ą u
?
2 ` v
¯
“ P b P p|X1| ď vq ˆ P b P
´
|X2| ą u
?
2 ` v
¯
“ P b P
´
|X1| ď v
and
|X2| ą u
?
2 ` v
¯
“ P b P
´
|X1 ´ X2| ď v
?
2
and
|X1 ` X2| ą 2u ` v
?
2
¯
ď P b P
´ˇˇ|X1| ´ |X2|
ˇˇ ď v
?
2
and
|X1| ` |X2| ą 2u ` v
?
2
¯
ď P b P p|X1| ą u and
|X2| ą uq “ P p|X| ą uq2 .
(3.306)
Inequality (3.305) in Lemma 3.104 follows from (3.306).
□
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
222 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.105. Lemma. Let pΩ, F, Pq and X be as in Theorem 3.103. Let v ą 0 be such
that P p|X| ď vq ą 0 and ﬁx ℓP N and ﬁx u ą 0. Then the following inequality
is valid:
P
´
|X| ą u
`?
2
˘ℓ` v
´`?
2
˘ℓ´ 1
¯ `?
2 ` 1
˘¯
P p|X| ď vq
ď
ˆP p|X| ą uq
P p|X| ď vq
˙2ℓ
.
(3.307)
Proof. For ℓ“ 0 this assertion is trivial and for ℓ“ 1 it is the same
as inequality (3.305) in Lemma 3.104. Next suppose that (3.307) is already
established for ℓ. We are going to prove (3.307) with ℓ` 1 replacing ℓ. Again
we invoke inequality (3.305) to obtain
P
´
|X| ą u
`?
2
˘ℓ`1 ` v
´`?
2
˘ℓ`1 ´ 1
¯ `?
2 ` 1
˘¯
P p|X| ď vq
ď
¨
˝
P
´
|X| ą
´
u
`?
2
˘ℓ`1 ` v
´`?
2
˘ℓ`1 ´ 1
¯ `?
2 ` 1
˘
´ v
¯
{
?
2
¯
P p|X| ď vq
˛
‚
2
“
¨
˝
P
´
|X| ą u
`?
2
˘ℓ` v
´`?
2
˘ℓ´ 1
¯ `?
2 ` 1
˘¯
P p|X| ď vq
˛
‚
2
(induction hypothesis)
ď
ˆP p|X| ą uq
P p|X| ď vq
˙2ℓ`1
.
(3.308)
The inequality in (3.308) completes the proof of Lemma 3.105.
□
Proof of Theorem 3.103. If X ” 0, then there is nothing to prove. So
suppose X ‰ 0 and choose strictly positive real numbers u and v for which
P p|X| ą uq
P p|X| ď vq ă 1. Put
αpu, vq “
1
pu ` vq2 log P p|X| ď vq
P p|X| ą uq and
βpu, vq “ P p|X| ď vq
ˆP p|X| ą uq
P p|X| ď vq
˙v2 `
1 `
?
2
˘2
2 pu ` vq2
.
Then αpu, vq ą 0 and βpu, vq “ P p|X| ď vq exp
´
´ 1
2αpu, vqv2 `
1 `
?
2
˘2¯
ă 1.
For s ě u choose ℓP N in such a way that
u
´?
2
¯ℓ`1
` v
ˆ´?
2
¯ℓ`1
´ 1
˙ ´?
2 ` 1
¯
ą s
ě u
´?
2
¯ℓ
` v
ˆ´?
2
¯ℓ
´ 1
˙ ´?
2 ` 1
¯
.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
223 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Then
2ℓą
`
s ` v
`
1 `
?
2
˘˘2
2 pu ` vq2
ą
s2
2 pu ` vq2 ` v2 `
1 `
?
2
˘2
2 pu ` vq2
and hence
P p|X| ą sq ď P
ˆ
|X| ą u
´?
2
¯ℓ
` v
ˆ´?
2
¯ℓ
´ 1
˙ ´?
2 ` 1
¯˙
(inequality (3.307) in Lemma 3.105)
ď P p|X| ď vq
ˆP p|X| ą uq
P p|X| ď vq
˙2ℓ
ď βpu, vq exp
ˆ
´1
2αpu, vqs2
˙
ă exp
ˆ
´1
2αpu, vqs2
˙
.
(3.309)
If 0 ď η ă α, then we choose u, v ą 0 in such a way that α ą αpu, vq ą η.
Then, for s ě u, P p|X| ą sq ă exp
`
´ 1
2αpu, vqs2˘
. Consequently, we get from
(3.309):
E
ˆ
exp
ˆ1
2η |X|2
˙
: |X| ą u
˙
“
ż 8
0
P
ˆ
exp
ˆ1
2η |X|2
˙
ą ξ, |X| ą u
˙
dξ
(substitute ξ “ exp
`1
2ηs2˘
)
ď exp
ˆ1
2ηu2
˙
P p|X| ą uq ` η
ż 8
u
P p|X| ą sq exp
ˆ1
2ηs2
˙
sds
ď exp
ˆ1
2ηu2
˙
P p|X| ą uq ` η
ż 8
u
exp
ˆ
´1
2 pαpu, vq ´ ηq s2
˙
sds
ď exp
ˆ1
2ηu2
˙
`
η
αpu, vq ´ η exp
ˆ
´1
2 pαpu, vq ´ ηq u2
˙
ď
αpu, vq
αpu, vq ´ η exp
ˆ1
2ηu2
˙
.
(3.310)
From (3.310) we infer
E
ˆ
exp
ˆ1
2η |X|2
˙˙
ď 2αpu, vq ´ η
αpu, vq ´ η exp
ˆ1
2ηu2
˙
.
(3.311)
Inequality (3.311) yields the desired result in Theorem 3.103.
□
10. Miscellaneous
We begin this section with the Doob’s optional stopping property for discrete
time submartingales.
Let tXpnq : n P Nu be a submartingale relative to the
ﬁltration tFn : n P Nu. Here the random variables Xpnq are deﬁned on a prob-
ability space pΩ, F, Pq. The following result was used in inequality (3.164), the
basic step for the continuous time version of the following proposition.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
224 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
3.106. Proposition. Let τ be a stopping time. The process
tXpminpn, τqq : n P Nu
is a submartingale with respect to the ﬁltration tFn : n P Nu as well as with
respect to the ﬁltration
␣
Fminpn,τq : n P N
(
.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

Advanced stochastic processes: Part I
225 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Proof. Let m and n be natural numbers with m ă n and let A be a
member of Fm. Then we have
E pX pminpn, τqq 1Aq ´ E pX pminpm, τqq 1Aq
“
nÿ
k“m`1
tE pX pminpk, τqq 1Aq ´ E pX pminpk ´ 1, τqq 1Aqu
“
nÿ
k“m`1
␣
E
`
pX pminpk, τqq ´ X pminpk ´ 1, τqqq 1AXtτěku
˘(
“
nÿ
k“m`1
E
␣
E
`
pX pminpk, τqq ´ X pminpk ´ 1, τqqq 1AXtτěku
˘ ˇˇ Fk´1
(
(the event AXtτ ě ku belongs to Fk´1 for k ě m`1, and the variable Xpk ´1q
is Fk´1-measurable)
“
nÿ
k“m`1
E
``
E
`
Xpkq
ˇˇ Fk´1
˘
´ Xpk ´ 1q
˘
1AXtτěku
˘
(submartingale property of the process tXpkq : k P Nu)
ě
nÿ
k“m`1
E
`
0 ˆ 1AXtτěku
˘
“ 0.
(3.312)
The inequality in (3.312) proves that the process tXpminpk, τqq : k P Nu is a sub-
martingale for the ﬁltration tFk : k P Nu. Since the σ-ﬁeld Fminpk,τ is contained
in the σ-ﬁeld Fk, k P N, it also follows that the process
tXpminpk, τqq : k P Nu
is also a submartingale with respect to the ﬁltration
␣
Fminpk,τq : k P N
(
because
we have
E
`
Xpminpm ` 1, τqq
ˇˇ Fminpm,τq
˘
“ E
`
E
`
Xpm ` 1q
ˇˇ Fm
˘ ˇˇ Fminpm,τq
˘
ě E
`
E
`
Xpminpm ` 1, τqq
ˇˇ Fm
˘ ˇˇ Fminpm,τq
˘
(employ (3.312))
ě E
`
Xpminpm, τqq
ˇˇ Fminpm,τq
˘
“ Xpminpm, τqq.
(3.313)
The inequalities (3.312) and (3.313) together prove the results in Theorem 3.106.
□
Next we prove Doob’s maximal inequality for martingales.
3.107. Proposition. Let tMpnq : n P Nu be a martingale. Put
Mpnq˚ “ max
kďn |Mpnq|.
The following inequalities are valid:
P rMpnq˚ ě λs ď 1
λE r|Mpnq| : Mpnq˚ ě λs ;
(3.314)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
226 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
P rMpnq˚ ě λs ď 1
λ2E
“
|Mpnq|2 : Mpnq˚ ě λ
‰
.
(3.315)
Let tMptq : t ě 0u be a continuous time martingale that is right continuous and
possesses left limits.
Put Mptq˚ “ sup0ďsďt |Mpsq|.
Again inequalities like
(3.314) and (3.315) are true:
P tMptq˚ ě λu ď 1
λE t|Mptq| : Mptq˚ ě λu ;
(3.316)
P tMptq˚ ě λu ď 1
λ2E
␣
|Mptq|2 : Mptq˚ ě λ
(
.
(3.317)
Proof. We begin by establishing inequality (3.314). Deﬁne the events Ak,
1 ď k ď n, by A0 “ t|Mp0q| ě λu,
Ak “ t|Mpjq| ă λ, 0 ď j ď k ´ 1, |Mpkq| ě λu ,
1 ď k ď n.
Then Ťn
k“0 Ak “ tMpnq˚ ě λu, Ak X Aℓ“ H, for k ­“ ℓ, 1 ď k, ℓď n, and
Ak is Fk-measurable for 1 ď k ď n. Moreover on the event Ak the inequality
|Mpkq| ě λ is valid. From the martingale property it then follows that:
P pMpnq˚ ě λq “
nÿ
k“0
P pAkq ď 1
λ
nÿ
k“0
E p1Ak |Mpkq|q
“ 1
λ
nÿ
k“0
E
`
1Ak
ˇˇE
`
Mpnq
ˇˇ Fk
˘ˇˇ˘
“ 1
λ
nÿ
k“0
E
`ˇˇE
`
1AkMpnq
ˇˇ Fk
˘ˇˇ˘
ď 1
λ
nÿ
k“0
E
`
E
`
1Ak |Mpnq|
ˇˇ Fk
˘˘
“ 1
λ
nÿ
k“0
E p1Ak |Mpnq|q “ 1
λE p|Mpnq| : Mpnq˚ ě λq .
(3.318)
Notice that inequality (3.318) is the same as (3.314).
The proof of (3.315)
goes along the same lines. The fact is used that the process
␣
|Mpnq|2 : n P N
(
constitutes a submartingale. The details read as follows. The events Ak, 1 ď
k ď n, are deﬁned as in the proof of (3.314). The argument in (3.318) is adapted
as below:
P pMpnq˚ ě λq “
nÿ
k“0
P pAkq ď 1
λ2
nÿ
k“0
E
`
1Ak |Mpkq|2˘
ď 1
λ2
nÿ
k“0
E
`
1AkE
`
|Mpnq|2 ˇˇ Fk
˘˘
ď 1
λ2
nÿ
k“0
E
`
1Ak |Mpnq|2˘
“ 1
λ2
nÿ
k“0
E
`
1Ak |Mpnq|2˘
“ 1
λ2E
`
|Mpnq|2 : Mpnq˚ ě λ
˘
.
(3.319)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
227 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Again we notice that (3.319) is the same as (3.315). The inequalities in (3.316)
and (3.317) are based on a time discretization of the martingale tMptq : t ě 0u.
Therefore we write Npjq :“ M pj2´ntq and we notice that tNpjq : j P Nu is
a martingale for the ﬁltration tFj2´nt : j P Nu.
From (3.314) we obtain the
inequality:
P
ˆ
max
0ďjď2n |Npjq| ě λ
˙
ď 1
λE p|Mptq| : Mptq˚ ě λq .
(3.320)
Inequality (3.317) is obtained from (3.320) upon letting tend n to 8. The proof
of (3.317) follows in the same manner from (3.315).
□
We continue with a proof of the (DL)-property of martingales. More precisely
we shall prove the following proposition.
3.108. Proposition. Let tMpsq : s ě 0u be a right continuous martingale on
the probability space pΩ, F, Pq. Fix t ě 0. Then the collection of random vari-
ables
tMpτq : 0 ď τ ď t, τ stopping timeu
is uniformly integrable.
Proof. Fix a stopping time 0 ď τ ď t and write τn “ min p2´nr2nts, tq.
Then 0 ď τn ď t and every τn is a stopping time. Moreover τn Ó τ if n tends
to 8.
Since the pair pMpτnq, Mptqq is a martingale for the pair of σ-ﬁelds
pFτn, Ftq (Use Proposition 3.106 for martingales), the pair p|M pτnq| , |Mptq|q is
a submartingale with respect to the same pair of σ-ﬁelds. As a consequence we
obtain:
E p|Mpτq| : |Mpτq| ě λq “ E
´
lim inf
nÑ8
ˇˇMpτnq1t|Mpτnq|ěλu
ˇˇ
¯
(Fatou’s lemma)
ď lim inf
nÑ8 E
`
|Mpτnq| 1t|Mpτnq|ěλu
˘
(submartingale property)
ď lim inf
nÑ8 E
`
E
`
|Mptq|
ˇˇ Fτn
˘
1t|Mpτnq|ěλu
˘
“ lim inf
nÑ8 E
`
|Mptq| 1t|Mpτnq|ěλu
˘
“ lim inf
nÑ8 E p|Mptq| : |M pτnq| ě λq
ď E p|Mptq| : |Mptq| ě λq .
(3.321)
This proves Proposition 3.108.
□
Remark. In the proof of Proposition 3.108. we did use a discrete approximation
of a stopping time. However we could have avoided this and consider directly the
pair pMpτq, Mptqq. From Proposition 3.107 we see that this pair is a martingale
with respect to the pair of σ-ﬁelds pFτ, Ftq. This will then imply inequality
(3.321) with τ replacing τn.
On the other hand the discrete approximation
of stopping times as performed in the proof of Proposition 3.108 is kind of
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
228 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
a standard procedure for passing from discrete time valued stopping times to
continuous time valued stopping times. This is a good reason to insert this kind
of argument.
The main result of Section 3 of this chapter says that linear operators in C0pEq
which maximally solve the martingale problem are generators of Feller semi-
groups and conversely. In the sequel we want to verify the claim in the example
of Section 3. Its statement is correct, but its proof is erroneous. Example 3.49
in Section 3 reads as follows.
3.109. Example. Let L0 be an unbounded generator of a Feller semigroup in
C0pEq and let µk and νk, 1 ď k ď n, be ﬁnite (signed) Borel measures on E.
Deﬁne the operator L⃗µ,⃗ν as follows:
D pL⃗µ,⃗νq “
nč
k“1
"
f P DpL0q :
ż
L0fdµk “
ż
fdνk
*
,
L⃗µ,⃗νf “ L0f,
f P D pL⃗µ,⃗νq .
Then the martingale problem is uniquely solvable for L⃗µ,⃗ν. In fact let
tpΩ, F, Pxq , pXptq : t ě 0q , pϑt : t ě 0q , pE, Equ
be the strong Markov process associated to the Feller semigroup generated by
L0. Then P “ Px solves the martingale problem
(a) For every f P DpL⃗µ,⃗νq the process
fpXptqq ´ fpXp0qq ´
ż t
0
L⃗µ,⃗νfpXpsqqds,
t ě 0,
is a P-martingale;
(b) PpXp0q “ xq “ 1,
uniquely. In particular we may take E “ r0, 1s, L0f “ 1
2f 2,
DpL0q “
␣
f P C2r0, 1s : f 1p0q “ f 1p1q “ 0
(
,
µk pIq “
şβk
αk 1Ipsqds, νk “ 0, 0 ď αk ă βk ď 1, 1 ď k ď n. Then L0 generates
the Feller semigroup of reﬂected Brownian motion: see Liggett [86], Example
5.8, p. 45. For the operator L⃗µ,⃗ν the martingale problem is uniquely (but not
maximally uniquely) solvable. However it does not generate a Feller semigroup.
From the result in Theorem 3.45 this can be seen as follows. Deﬁne the func-
tionals Λj : DpL0q Ñ C, 1 ď j ď n, as follows:
Λjpfq “
ż
L0fdµj ´
ż
fdνj,
1 ď j ď n.
We may and do suppose that the functionals Λj, 1 ď j ď n, are linearly
independent and that their linear span does not contain linear combinations of
Dirac measures. The latter implies that, for every x0 P E and for every function
u P DpL0q, the convex subsets
D pL1q X ttg P C0pEq : Re g ď Re gpx0qu ` uu
and
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
229 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
D pL1q X tth P C0pEq : Re h ě Re hpx0qu ` uu
are non-void. The latter follows from a Hahn-Banach argument. Hopefully,
it will also imply that the quantities in (3.322) and (3.323) coincide.
Since
DpL2
0q forms a core for L0 we may choose functions uk, 1 ď k ď n, such that
Λjpukq “ δjk and such that every uk, 1 ď k ď n is in the vector of the two
spaces␣
u P DpL2
0q : Rp1qu P DpL1q
(
and
␣
u P DpL2
0q : Rp2qu P DpL1q
(
.
As operator L1 we take L1 “ L⃗µ,⃗ν and for T we take Tf “ řn
j“1 Λjpfquk,
f P DpL0q.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

Advanced stochastic processes: Part I
230 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
The remainder of this section is devoted to the proof of the following result.
Whenever appropriate we write Rpλq for the operator pλI ´ L0q´1.
3.110. Theorem. Let L0 be the generator of a Feller semigroup in C0pEq and
let L1 and T be linear operators with the following properties: the operator I ´T
has domain DpL0q and range D pL1q, L1 veriﬁes the maximum principle, the
vector sum of the spaces RpI ´ Tq and R pL1pI ´ Tqq is dense in C0pEq, and
the operator L1pI ´ Tq ´ pI ´ TqL0 can be considered as a continuous linear
operator in the domain of L0. More precisely, it is assumed that
lim sup
λÑ8
}pL1pI ´ Tq ´ pI ´ TqL0q Rpλq} ă 1.
Then there exists at most one linear extension L of the operator L1 for which
LT is bounded and that generates a Feller semigroup.
In particular, if the
martingale problem is solvable for L1, then it is uniquely solvable for L1.
Before we actually prove this result we like to make some comments. In order
to have existence and uniqueness for the extension L on RpTq it suﬃces that
for every v P RpTq and for every x0 P E the following two expressions are equal:
lim
ϵÓ0
inf
fPDpL1q
"
Re L1fpx0q : inf
yPE Re pfpyq ´ vpyqq ą Re pfpx0q ´ vpx0qq ´ ϵ
*
;
(3.322)
lim
ϵÓ0
sup
fPDpL1q
"
Re L1fpx0q : sup
yPE
Re pfpyq ´ vpyqq ă Re pfpx0q ´ vpx0qq ` ϵ
*
.
(3.323)
This common value is then by deﬁnition Re L2vpx0q. The value of L2vpx0q is
then given by rL2vs px0q “ Re rL2vs px0q ´ iRe rL2pivqs px0q for v P RpTq. Let
Λj, 1 ď j ď n, be as in the example of section 1. For every x0 P E and for
every 1 ď k ď n there exist functions gk and hk P DpL0q with the following
properties: Λℓpgkq “ Λℓphkq “ δk,ℓ, Re gkpxq ď Re gkpx0q and Re hkpx0q ď
hkpxq for all x P E and Re L1 phk ´ gkq px0q “ 0. It then readily follows that
the two expressions in (3.322) and (3.323) are equal for functions v in the linear
span of u1, . . . , un. Notice that the function Re hk attains its minimum at x0
and that the function Re gk attains its maximum at x0.
In order to deﬁne
rL1uks px0q we choose functions gk and hk with Λℓpgkq “ Re Λℓphkq “ ´δk,ℓin
such a way that the function Re gk attains its maximum at x0 and that the
function Re hk attains its minimum at the same point x0. Moreover we may
and do suppose that Re L1 pgk ´ hkq px0q “ 0. The value rL2uks px0q is then
given by rL2uks px0q “ rL1 pgk ` ukqs px0q “ rL1 phk ` ukqs px0q.
Proof of Theorem 3.110. Let rL be any linear operator which extends
L1 and that has the property that its domain D
´
rL
¯
contains RpTq “ TDpL0q.
We also suppose that rL veriﬁes the maximum principle. Let L1 be the restriction
of rL to RpI ´Tq and let L2 be the operator rL conﬁned to RpTq. We shall prove
that the operator L1 has a unique extension that generates a Feller semigroup.
We start with the construction of a family of kind of intertwining operators
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
231 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
tV pλq : λ ą 0 and largeu. This is done as follows. The symbol Rpλq is always
used to denote the operator Rpλq “ pλI ´ L0q´1. Deﬁne the operator V by
V “ L1pI ´ Tq ´ pI ´ TqL0
(3.324)
and deﬁne the operator V pλq, λ ą }L2T}β, via the equality
V pλq “ λ pλI ´ L2Tq´1 V.
(3.325)
Then we have:
pλI ´ L1q pI ´ Tq ` pλI ´ L2q T V pλq
λ
“ pI ´ Tq pλI ´ L0 ´ V pλqq .
(3.326)
An equivalent form of (3.326) is the equality
pλI ´ L1q pI ´ Tq ` pλI ´ L2q T V pλq
λ
“ pI ´ Tq ppλI ´ L0q ´ V pλqq
(3.327)
“ pI ´ Tq pλI ´ L0q ´ pI ´ TqV pλq “ pI ´ Tq pI ´ V pλqRpλqq pλI ´ L0q .
Next we shall prove that the martingale problem is solvable for L1. We do this
by showing that the operator L1 extends to a generator L of a Feller semigroup.
For large positive lambda we deﬁne the operators Gpλq in C0pEq as follows. For
f of the form f “ pI ´ Tqg, with g “ pI ´ V pλqRpλqqpλI ´ L0qh, we write
Gpλqf “ GpλqpI ´ Tqg “
ˆ
I ´ T ` T V pλq
λ
˙
h.
(3.328)
and if the function f is of the form f “ pλI ´ L1q pI ´ Tqg we write
Gpλqf “ GpλqpλI ´ L1qpI ´ Tqg “ pI ´ Tqg.
(3.329)
If pλI ´ L1q pI ´ Tqg1 “ pI ´ Tqg2, then, since I ´ T is mapping attaining
values in the domain of L1, we see that pI ´ Tqg1 ´ pI ´ Tqg2 belongs to
DpL1q and hence the following identities are mutually equivalent (we write
g2 “ pI ´ V pλqRpλqq pλI ´ L0q h2):
pI ´ Tqg1 “
ˆ
I ´ T ` T V pλq
λ
˙
h2;
pI ´ Tqg1 ´ pI ´ Tqh2 “ T V pλq
λ
h2;
pλI ´ L1q ppI ´ Tqg1 ´ pI ´ Tqh2q “ pλI ´ L1q T V pλq
λ
h2;
pI ´ Tqg2 “ pλI ´ L1q
ˆ
I ´ T ` T V pλq
λ
˙
h2;
pI ´ Tq pI ´ V pλqRpλqq pλI ´ L0q h2 “ pλI ´ L1q
ˆ
I ´ T ` T V pλq
λ
˙
h2;
pλI ´ L1q pI ´ Tqh2 ` pλI ´ L2q T V pλq
λ
h2 “ pλI ´ L1q
ˆ
I ´ T ` T V pλq
λ
˙
h2.
(3.330)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
232 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Since g2 “ pI ´ V pλqRpλqqpλI ´ L0qh2 it follows that
´
λI ´ rL
¯ `
pI ´ Tq pg1 ´ h2q ´ T V pλq
λ
h2
˘
pλI ´ L1q ppI ´ Tqg1 ´ pI ´ Tqh2q ´ pλI ´ L2q T V pλq
λ
h2
“ pI ´ Tqg2 ´ pλI ´ L1q pI ´ Tqh2 ´ pλI ´ L2q T V pλq
λ
h2
“ pI ´ Tq pI ´ V pλqRpλqq pλI ´ L0q h2 ´ pλI ´ L1q pI ´ Tqh2
´ pλI ´ L2q T V pλq
λ
h2
“ pλI ´ L1q pI ´ Tqh2 ` pλI ´ L2q T V pλq
λ
h2 ´ pλI ´ L1q pI ´ Tqh2
´ pλI ´ L2q T V pλq
λ
h2 “ 0.
(3.331)
Since the operator rL veriﬁes the maximum principle, it is dissipative, and so
the zero space of λI ´ rL is trivial.
We conclude from (3.331) the identity
TV pλqRpλqh2 “ pI ´Tqg1´pI ´Tqh2 and so the function TV pλqRpλqh2 belongs
to DpL1q. Hence it follows that (3.330) is satisﬁed and consequently that the
operator Gpλq is well-deﬁned. Next we pick h1 and h2 in the domain of L0 and
we write
f “ λpI ´ Tq pλI ´ L0 ´ V pλqq h2 ` pλI ´ L1q pI ´ Tq ph1 ´ λh2q .
(3.332)
A calculation will yield the following identities:
Gpλqf “ pI ´ Tqh1 ` TV pλqh2;
λGpλqf ´ f “ L1pI ´ Tqh1 ` L2TV pλqh2 “ rL pGpλqfq .
(3.333)
Consequently we get
´
λI ´ rL
¯
Gpλqf “ f, for f of the form (3.332). Since
we know }V pλqRpλq}β ă 1 and since, by assumption the subspace RpI ´ Tq `
RpL1pI ´ Tqq is dense in C0pEq, it follows that the range RpλI ´ rLq is dense
for λ ą 0, λ large. Since the operator rL satisﬁes the maximum principle and
since rL “ L1pI ´ Tq ` L2T it follows that the operator L that assigns to
Gpλqf the function λGpλqf ´ f, f P RpI ´ Tq ` RpL1pI ´ Tqq, is well deﬁned
and satisﬁes the maximum principle.
Below we shall show that the family
tGpλq : λ ą 0,
λ largeu is a resolvent family indeed: see (3.337). The closure
of its graph contains the graph
tppI ´ Tqh1 ` Th2, L1pI ´ Tqh1 ` L2Th2q : h1, h2 P DpL0qu .
Denote the operator with graph tpGpλqf, λGpλqf ´ fq : f P C0pEqu again by L.
From the previous remarks it follows that the operator L veriﬁes the maximum
principle, pλI ´ LqGpλqf “ f for f P C0pEq and that it is densely deﬁned. The
latter follows because its domain contains all vectors of the form
pI ´ Tqf1 ` L1pI ´ Tqf2 “ pI ´ Tq pf1 ` pI ´ TqL1pI ´ Tqf2 ` TL0f2q ` TV f2.
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
233 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
From a general argument it then follows that the operator L is the generator of
a Feller semigroup: for more details see [141], Theorem 2.2 page 14. Next let
h1 and h2 belong to DpL0q. Then we have
λ
››Gpλq
`
pI ´ Tqh1 ` pλI ´ L1q pI ´ Tqh2
˘››
8
“ λ }GpλqpI ´ Tqh1 ` pI ´ Tqh2}8
(the operator rL is dissipative)
ď
›››
´
λI ´ rL
¯ `
GpλqpI ´ Tqh1 ` pI ´ Tqh2
˘›››
8
“ }pI ´ Tqh1 ` pλI ´ L1q pI ´ Tqh2}8 .
(3.334)
Since the vector sum of the spaces RpI ´Tq and RpL1pI ´Tqq is dense it follows
from (3.334) that the operator Gpλq extends as a continuous linear operator to
all of C0pEq. Moreover it is dissipative in the sense that
λ }Gpλq} ď 1.
(3.335)
Next we prove that the operator Gpλq is positive in the sense that f ě 0,
f P C0pEq, implies Gpλqf ě 0. So let f P C0pEq be non-negative. There exist
sequences of functions pgnq and phnq in the space DpL0q, for which
f “ lim
nÑ8 ppI ´ Tqhn ` pλI ´ L1q pI ´ Tqgnq .
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

Advanced stochastic processes: Part I
234 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Put fn “ pI ´ Tqhn ` pλI ´ L1q pI ´ Tqgn. Then
´
λI ´ rL
¯
Gpλqfn “ fn (see
(3.332) and (3.333)). Since the operator rL veriﬁes the maximum principle it
follows that
λRe Gpλqfn ě inf
yPE Re
´
λI ´ rL
¯
Gpλqfnpyq “ inf
yPE Re fnpyq
(3.336)
and hence Re λGpλqf “ Re limnÑ8 λGpλqfn ě 0. A similar argument will show
that the operator Gpλq sends real functions to real function and hence Gpλq is
positivity preserving. Next we prove that the family tGpλq : λ ą 0,
largeu is
a resolvent family. So let λ and µ be large positive real numbers. We want to
prove the identity
Gpλq ´ Gpµq ´ pµ ´ λqGpµqGpλq “ 0.
(3.337)
First pick the function f P DpL0q and apply the operator in (3.337) to the
function pλI ´ L1q pI ´ Tqf and employ identity Gpλq
´
λI ´ rL
¯
f “ f, for f
belonging to D
´
rL
¯
to obtain
pGpλq ´ Gpµq ´ pµ ´ λqGpµqGpλqq pλI ´ L1q pI ´ Tqf “ 0.
The operator in (3.337) also sends functions in the space RpI ´Tq to 0, because
we may apply (3.333) to see that
´
µI ´ rL
¯
pGpλq ´ Gpµq ´ pµ ´ λqGpµqGpλqq pI ´ Tqf “ 0
for f P DpL0q. Finally we show that the resolvent family tGpλq : λ ą 0 largeu
is strongly continuous in the sense that limλÑ8 λRpλqf “ f for all f P C0pEq.
Of course it suﬃces to prove this equality for a subset with a dense span. Next
we consider f P DpL0q and we estimate
}pI ´ Tqf ´ λGpλqpI ´ Tqf}8
as follows:
}pI ´ Tqf ´ λGpλqpI ´ Tqf}8
ď 1
λ }pλI ´ L1q ppI ´ Tqf ´ λGpλqpI ´ Tqfq}8
“ 1
λ }pλI ´ L1q pI ´ Tqf ´ λpI ´ Tqf}8 “ 1
λ }L1pI ´ Tqf}8 .
(3.338)
Again this expression tends to zero. For brevity we write
Fpλq “ pI ´ V pλqRpλqq´1 f.
For f P DpL0q the following equalities are valid:
pλGpλq ´ Iq L1pI ´ Tqf ´ L1pI ´ Tqf
“ λ2GpλqpI ´ Tqf ´ λpI ´ Tqf ´ L1pI ´ Tqf
“
␣
λ2pI ´ TqRpλq ` TV pλqRpλq2 ´ λpI ´ TqpI ´ V pλqRpλqq
(
Fpλq
´ L1pI ´ Tqf
“
␣
pI ´ TqλL0Rpλq ` λ2TV pλqRpλq2 ` λpI ´ TqV pλqRpλq
(
Fpλq
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
235 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
´ L1pI ´ Tqf
Ñ tpI ´ TqL0 ` TV ` pI ´ TqV u f ´ L1pI ´ Tqf “ 0.
(3.339)
From (3.338) together with (3.339) we conclude that limλÑ8 pλGpλqf ´ fq “ 0
for all in the span of RpI ´ Tq and R pL1pI ´ Tqq. By assumption this span is
dense and consequently the resolvent family tGpλq : λ ą 0, λ largeu is strongly
continuous. In order to conclude the proof of the existence result we choose f1
and f2 in the space DpL0q and we notice the following identities:
Gpλq tpI ´ Tq pI ´ V pλqRpλqq pλI ´ L0qf1 ` pλI ´ L1qpI ´ Tqf2u
“ pI ´ Tqpf1 ` f2q ` TV pλqRpλqf1,
and so the space GpλqC0pEq contains the linear span of the spaces RpI ´ Tq
and R pTV pλqRpλqq.
From the resolvent equation it is clear that the space
GpλqC0pEq does not depend on the variable λ.
So we see that the space
GpαqC0pEq contains, for a given function f P DpL0q the family tλTV pλqRpλqf :
λ ě αu. Hence the function TV f “ lim
λÑ8 λTV pλqRpλqf belongs to the closure of
the space GpαqC0pEq. Since L1pI ´Tqf “ TV f `pI ´Tq pL1pI ´ Tqf ` TL0fq,
for f P DpL0q, we conclude that the range of L1pI ´ Tq is contained in the clo-
sure of GpαqC0pEq. Since the latter space also contains RpI ´Tq it follows from
the density of the space
RpI ´ Tq ` R pL1pI ´ Tqq
in C0pEq that the domain of the resolvent, i.e. GpαqC0pEq is dense in C0pEq.
From the previous discussion it also follows that the operator which assigns to
Gpλqf the function λGpλqf ´ f extends the operator L1 restricted to RpI ´ Tq.
It is now also clear that the subspace tGpαqf : f P C0pEqu is dense and so it is
clear that the there exists a Feller semigroup generated by the operator L with
graph tpGpαqf, αGpαqf ´ fq : f P C0pEqu.
For the uniqueness we proceed as follows. Let P1
x and P2
x be two solutions for the
martingale problem. We deﬁne the family of operators tSptq : t ě 0u as follows:
Sptqfpxq “ E1
xfpXptq´E2
xfpXptqq from the martingale property, it then follows
that S1ptqf “ SptqrLf for f belonging to the subspace RpI ´ Tq ` RpL1pI ´ Tqq.
Moreover we have Sp0qfpxq “ 0 for all functions f P C0pEq. Then we write (for
f1 and f2 P DpL0q)
0 “
ż 8
0
ˆ
´ B
Bt
˙
e´λtSptqGpλq ppI ´ Tqf1 ` TL1pI ´ Tqf2q dt
“
ż 8
0
e´λtSptq
´
λI ´ rL
¯
Gpλq ppI ´ Tqf1 ` TL1pI ´ Tqf2q dt
“
ż 8
0
e´λtSptq ppI ´ Tqf1 ` TL1pI ´ Tqf2q dt.
(3.340)
Consequently SptqpI ´ Tqf1 “ SptqTL1pI ´ Tqf2 “ 0 for all functions f1 and fn
in the space DpL0q. We also have, upon using (3.340) the following equality:
ż t
0
SpτqL1pI ´ Tqfdτ “ SptqpI ´ Tqf ´ Sp0qf “ 0.
(3.341)
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
236 
An introduction to stochastic processes:  
Brownian motion, Gaussian processes and martingales
Since by assumption the sum of the vector spaces RpI ´ Tq and RpL1q is dense
in the space C0pEq, we conclude Sptq ” 0 and hence from a general result on
uniqueness of the martingale problem, we ﬁnally obtain that P1
x “ P2
x for all
x P E. For more details see Proposition 2.9 (Corollary p. 206 of Ikeda and
Watanabe [61]). This completes the proof of Theorem 3.110.
□
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

Advanced stochastic processes: Part I
237 
Index
Index
D: dyadic rational numbers, 380
K: strike price, 191
Np¨q: normal distribution, 191
P 1pΩq: compact metrizable Hausdorﬀ
space, 129
S: spot price, 191
T: maturity time, 191
λ-system, 1, 68
Gδ-set, 332, 334
M: space of complex measures on Rν, 298
µx,y
0,t , 103
π-system, 68
σ-algebra, 1, 3
σ-ﬁeld, 1, 3
σ: volatility, 191
r: risk free interest rate, 191
(DL)-property, 416
adapted process, 17, 374, 389, 406
additive process, 23, 24
aﬃne function, 8
aﬃne term structure model, 210
Alexandroﬀcompactiﬁcation, 301
almost sure convergence of
sub-martingales, 386
arbitrage-free, 190
backward propagator, 197
Banach algebra, 298, 303
Bernoulli distributed random variable, 56
Bernoulli topology, 310
Beurling-Gelfand formula, 302, 303
Birkhoﬀ’s ergodic theorem, 74
birth-dearth process, 35
Black-Scholes model, 187, 190
Black-Scholes parameters, 193
Black-Scholes PDE, 190
Bochner’s theorem, 90, 91, 308, 314
Boolean algebra of subsets, 361
Borel-Cantelli’s lemma, 42, 105
Brownian bridge, 94, 98, 99, 101
Brownian bridge measure
conditional, 103
Brownian motion, 1, 16–18, 24, 84, 94, 98,
101, 102, 105, 108–110, 113, 115, 181,
189, 193, 197, 243, 283, 290, 291
continuous, 104
distribution of, 107
geometric, 188
H¨older continuity of, 154
pinned, 98
standard, 70
Brownian motion with drift, 98
cadlag modiﬁcation, 395
cadlag process, 376
Cameron-Martin Girsanov formula, 277
Cameron-Martin transformation, 182, 280
canonical process, 109
Carath´eodory measurable set, 363
Carath´eodory’s extension theorem, 361,
362, 364
central limit theorem, 74
multivariate, 70
Chapman-Kolmogorov identity, 16, 25,
81, 107, 116, 149
characteristic function, 76, 102, 390
characteristic function (Fourier
transform), 98
classiﬁcation properties of Markov chains,
35
closed martingale, 17, 150
compact-open topology, 310
complex Radon measure, 296
conditional Brownian bridge measure, 103
conditional expectation, 2, 3, 78
conditional expectation as orthogonal
projection, 5
conditional expectation as projection, 5
conditional probability kernel, 399
consistent family of probability spaces, 66
consistent system of probability measures,
13, 360
content, 362
exended, 362
continuity theorem of L´evy, 324
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
238 
Index
contractive operator, 197
convergence in probability, 371, 386
convex function and aﬃne functions, 8
convolution product of measures, 298
convolution semigroup of measures, 314
convolution semigroup of probability
measures, 391
coupling argument, 288
covariance matrix, 108, 197, 200, 203
cylinder measure, 360
cylinder set, 358, 367
cylindrical measure, 89, 125
decomposition theorem of Doob-Meyer, 20
delta hedge portfolio, 190
density function, 80
Dirichlet problem, 265
discounted pay-oﬀ, 209
discrete state space, 25
discrete stopping time, 19
dispersion matrix, 94
dissipative operator, 118
distribution of random variable, 102
distributional solution, 266
Dol´eans measure, 168
Donsker’s invariance principle, 71
Doob’s convergence theorem, 17, 18
Doob’s maximal inequality, 21, 23, 160,
384
Doob’s maximality theorem, 21
Doob’s optional sampling theorem, 20, 86,
381, 388, 409
Doob-Meyer decomposition
for discrete sub-martingales, 383
Doob-Meyer decomposition theorem, 148,
149, 295, 384, 410, 419, 421
downcrossing, 157
Dynkin system, 1, 68, 111, 300, 378
Elementary renewal theorem, 38
equi-integrable family, 369
ergodic theorem, 295
ergodic theorem in L2, 342
ergodic theorem of Birkhoﬀ, 76, 340, 344,
354
European call option, 188
European put option, 188
event, 1
exit time, 84
exponential Brownian motion, 186
exponential local martingale, 254, 255
exponential martingale probability
measure, 192
extended content, 362
extension theorem
of Kolmogorov, 360
exterior measure, 364
face value, 210
Feller semigroup, 79, 113, 114, 120, 121,
140, 264
conservative, 114
generator of, 118, 137, 140, 143, 144
strongly continuous, 113
Feller-Dynkin semigroup, 79, 122, 264
Feynman-Kac formula, 181
ﬁltration, 109, 264
right closure of, 109
ﬁnite partition, 3
ﬁnite-dimensional distribution, 373
ﬁrst hitting time, 18
forward propagator, 197
forward rate, 214
Fourier transform, 90, 93, 96, 102, 251
Fubini’s theorem, 199
full history, 109
function
positive-deﬁnite, 305
functional central limit theorem (FCLT),
70, 71
Gaussian kernel, 16, 107
Gaussian process, 89, 110, 115, 200, 203
Gaussian variable, 153
Gaussian vector, 76, 93, 94
GBM, 186
geometric Brownian motion, 189
generator of Feller semigroup, 118, 137,
140, 144, 228, 230, 231, 233
generator of Markov process, 200, 203
geometric Brownian motion, 188
geometric Brownian motion = GBM, 186
Girsanov transformation, 182, 243, 280
Girsanov’s theorem, 193
graph, 232
Gronwall’s inequality, 246
H¨older continuity of Brownian motion,
154
H¨older continuity of processes, 151
Hahn decomposition, 295
Hahn-Kolmogorov’s extension theorem,
364
harmonic function, 86
hedging strategy, 188
Hermite polynomial, 258
Hilbert cube, 333, 334
hitting time, 18
i.i.d. random variables, 24
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
239 
Index
index set, 11
indistinguishable processes, 104, 374, 386
information from the future, 374
initial reward, 40
integration by parts formula, 282
interest rate model, 204
internal history, 374, 394
invariant measure, 35, 48, 51, 201, 204
minimal, 50
irreducible Markov chain, 48, 51, 54
Itˆo calculus, 87, 278, 279
Itˆo isometry, 162
Itˆo representation theorem, 274
Itˆo’s lemma, 189, 270
Jensen inequality, 149
Kolmogorov backward equation, 26
Kolmogorov forward equation, 26
Kolmogorov matrix, 26
Kolmogorov’s extension theorem, 13, 17,
89–91, 93, 125, 130, 357, 360, 361,
366
Komlos’ theorem, 295, 409, 420
L´evy’s weak convergence theorem, 115
L´evy process, 89, 389, 390, 392
L´evy’s characterization of Brownian
motion, 194, 249
law of random variable, 102
Lebesgue-Stieltjes measure, 364
lemma of Borel-Cantelli, 10, 152
lexicographical ordering, 333
life time, 79, 117
local martingale, 194, 252, 264, 267, 268,
271, 278, 280
local time, 292
locally compact Hausdorﬀspace, 15
marginal distribution, 373
marginal of process, 13
Markov chain, 35, 44, 58, 59, 66
irreducible, 48, 54
recurrent, 48
Markov chain recurrent, 48
Markov process, 1, 16, 29, 30, 61, 79, 89,
102, 110, 113, 115, 119, 144, 202, 406,
408
strong, 119, 406
time-homogeneous, 407
Markov property, 25, 26, 30, 31, 46, 82,
110, 113, 142
strong, 44
martingale, 1, 17, 20, 80–82, 85–88, 103,
109, 243, 280, 281, 378, 382, 396
(DL)-property, 227
closed, 17
local, 194
maximal inequality for, 225
martingale measure, 209, 281
martingale problem, 118, 128, 137, 140,
143, 144, 228, 230, 231, 235, 264, 265
uniquely solvable, 118
well-posed, 118
martingale property, 131
martingale representation theorem, 263,
275
maximal ergodic theorem, 351
maximal inequality of Doob, 386
maximal inequality of L´evy, 104
maximal martingale inequality, 225
maximum principle, 118, 140, 141, 143,
232
measurable mapping, 377
measure
invariant, 48, 201, 204
mesaure
invariant, 204
mesure
stationary, 204
metrizable space, 15
Meyer process, 419
minimal invariant measure, 50
modiﬁcation, 374
monotone class theorem, 69, 103, 107,
110, 112, 116, 378, 394, 398, 401, 404
alternative, 378
multiplicative process, 23, 24, 79
multivariate classical central limit
theorem, 70
multivariate normal distributed vector, 76
multivariate normally distributed random
vector, 93
negative-deﬁnite function, 314, 316, 396
no-arbitrage assumption, 209
non-null recurrent state, 51
non-null state, 47
non-positive recurrent random walk, 57
non-time-homogeneous process, 23
normal cumulative distribution, 188
normal distribution, 197
Novikov condition, 281
Novikov’s condition, 209
null state, 47
num´eraire, 215
number of upcrossings, 156, 379, 380
one-point compactiﬁcation, 15
operator
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
240 
Index
dissipative, 118
operator which maximally solves the
martingale problem, 118, 140, 228
Ornstein-Uhlenbeck process, 98, 102, 200,
201, 210
orthogonal projection, 340
oscillator process, 98, 99
outer measure, 363, 364
partial reward, 40
partition, 4
path, 373
path space, 117
pathwise solutions to SDE, 288, 289
unique, 291, 292
pathwise solutions to SDE’s, 244
payoﬀprocess
discounted, 193
PDE for bond price in the Vasicek model,
213
pe-measure, 362
persistent state, 47
pinned Brownian motion, 98
Poisson process, 26, 27, 29, 36, 89, 159
Polish space, 15, 90, 123, 334, 335, 360,
361, 366
portfolio
delta hedge, 190
positive state, 47
positive-deﬁnite function, 297, 302, 305,
314
positive-deﬁnite matrix, 90, 96, 197
positivity preserving operators, 345
pre-measure, 363, 364
predictable process, 20, 193, 418
probability kernel, 399, 408
probability measure, 1
probability space, 1
process
Gaussian, 200, 203
increasing, 21
predictable, 20
process adapted to ﬁltration, 374
process of class (DL), 20, 21, 148, 149,
161, 409–411, 420, 421
progressively measurable process, 377
Prohorov set, 72, 335, 337–339
projective system of probability measures,
13, 121, 360
projective system of probability spaces,
125
propagator
backward, 197
quadratic covariation process, 249, 264,
279
quadratic variation process, 253
Radon-Nikodym derivative, 11, 408
Radon-Nikodym theorem, 4, 78, 408
random walk, 58
realization, 25, 373
recurrent Markov chain, 48
recurrent state, 47
recurrent symmetric random walk, 55
reference measure, 80, 81, 83
reﬂected Brownian motion, 228
renewal function, 35
renewal process, 35, 40
renewal-reward process, 39, 40
renewal-reward theorem, 41
resolvent family, 122
return time, 55
reward
initial, 40
partial, 40
terminal, 40
reward function, 40
Riemann-Stieltjes integral, 364
Riesz representation theorem, 295, 296,
305
right closure of ﬁltration, 109
right-continuous ﬁltration, 374
right-continuous paths, 19
ring of subsets, 361
risk-neutral measure, 193, 209
risk-neutral probability measure, 192
running maximum, 23
sample path, 25
sample path space, 11, 25
sample space, 25
semi-martingale, 419
semi-ring, 364
semi-ring of subsets, 361, 362
semigroup
Feller, 264
Feller-Dynkin, 264
shift operator, 109, 117
Skorohod space, 117, 122, 128
Skorohod-Dudley-Wichura representation
theorem, 283, 286
Souslin space, 90, 361, 365, 366
space-homogeneous process, 29
spectral radius, 303
standard Brownian motion, 70
state
non-null, 47
null, 47
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
241 
Index
persistent, 47
positive, 47
recurrent, 47
state space, 11, 17, 79, 117, 400, 406
discrete, 25
state variable, 11, 25, 117
state variables, 125
state:transient, 47
stationary distribution, 25, 51
stationary measure, 204
stationary process, 11
step functions with unit jumps, 159
Stieltjes measure, 364
Stirling’s formula, 54
stochastic diﬀerential equation, 182
stochastic integral, 102, 253
stochastic process, 10
stochastic variable, 11, 371
stochastically continuous process, 159
stochastically equivalent processes, 374
stopped ﬁltration, 377
stopping time, 18, 20, 44, 58, 64, 68, 112,
252, 374–377, 381, 382, 405
discrete, 19
terminal, 18, 24
strong law of large numbers, 41, 76, 155,
340, 344
strong law of large numbers (SLLN), 38
strong Markov process, 102, 119, 121, 140,
406
strong Markov property, 44, 48, 113
strong solution to SDE, 244
strong solutions to SDE
unique, 244
strong time-dependent Markov property,
113, 120
strongly continuous Feller semigroup, 113
sub-martingale, 378, 381, 384
sub-probability kernel, 406
sub-probability measure, 1
submartingale, 17, 20, 227
submartingale convergence theorem, 158
submartingale of class (DL), 421
super-martingale, 378
supermartingale, 17, 20
Tanaka’s example, 292
terminal reward, 40
terminal stopping time, 18, 24, 83
theorem
Itˆo representation, 274
Kolmogorov’s extension, 278
martingale representation, 275
of Arzela-Ascoli, 72, 73
of Bochner, 90, 304, 308
of Doob-Meyer, 20
of Dynkin-Hunt, 397
of Fernique, 221
of Fubini, 199, 330
of Girsanov, 277, 280
of Helly, 334
of Komlos, 409
of L´evy, 253, 270, 290
of Prohorov, 72
of Radon-Nikodym, 290
of Riemann-Lebesgue, 300
of Scheﬀ´e, 39, 278, 369
of Schoenberg, 314
of Stone-Weierstrass, 301, 305
Skorohod-Dudley-Wichura
representation, 283, 286
time, 11
time change, 19
stochastic, 19
time-dependent Markov process, 200, 203
time-homogeneous process, 11, 29
time-homogeneous transition probability,
25
time-homogenous Markov process, 407
topology of uniform convergence on
compact subsets, 310
tower property of conditional expectation,
5
transient non-symmetric random walk, 57
transient state, 47
transient symmetric random walk, 55
transition function, 119
transition matrix, 51
translation operator, 11, 25, 109, 117,
400, 406
translation variables, 125
uniformly distributed random variable,
394
uniformly integrable family, 5, 6, 20, 39,
369, 388
uniformly integrable martingale, 389
uniformly integrable sequence, 385
unique pathwise solutions to SDE, 244
uniqueness of the Doob-Meyer
decomposition, 417
unitary operator, 340, 342
upcrossing inequality, 156, 157, 383
upcrossing times, 156
upcrossings, 156
vague convergence, 371
vague topology, 310, 334
vaguely continuous convolution semigroup
of measures, 315
Download free eBooks at bookboon.com

Advanced stochastic processes: Part I
242 
Index
vaguely continuous convolution semigroup
of probability measures, 389, 390
Vasicek model, 204, 210
volatility, 188
von Neumann’s ergodic theorem, 340
Wald’s equation, 36
weak convergence, 325
weak law of large numbers, 75, 340
weak solutions, 264
weak solutions to SDE’s, 244, 277, 280,
288
unique, 265, 292
weak solutions to stochastic diﬀerential
equations, 265
weak topology, 310
weak˚-topology, 334
weakly compact set, 338, 339
Wiener process, 98
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

To See Part 2 download
Advanced stochastic processes: Part 2
Download free eBooks at bookboon.com

