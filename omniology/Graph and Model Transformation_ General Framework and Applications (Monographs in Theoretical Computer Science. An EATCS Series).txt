Monographs in Theoretical Computer Science
An EATCS Series
Hartmut Ehrig
Claudia Ermel
Ulrike Golas
Frank Hermann
Graph and 
Model 
Transformation
General Framework and Applications
www.allitebooks.com

ttp://www.springer.com/series/
More information about this series at h
n Theoretical Computer Science
An EATCS Series
On behalf of the European Association
for Theoretical Computer Science (EATCS)
Advisory Board:
Editors: M. Henzinger   J. Hromkovič   M. Nielsen   G. Rozenberg  
A. Salomaa
S. Albers   H. Attiya   G. Ausiello   M. Broy   C. Calude   A. Condon   
A. Czumaj   P. Degano   J. Diaz   P. Gastin   G. Gottlob   D. Harel   
J. Hartmanis   R. Heckel   L.A. Hemaspaandra   T. Henzinger    
M. Hermenegildo   B. Jonsson   J. Karhumäki   L. Kari   M. Koutny   
D. Kozen   T. Leighton   H. Lin   G. Mauri   M. Nivat   D. Niwiński   
C. Papadimitriou   D. Peleg   D. Sannella   U. Schöning   D. Scott   
P.G. Spirakis   D. Wagner   E. Welzl   M. Wirsing 
Founding Editors: W. Brauer
G. Rozenberg
A. Salomaa
Monographs i
776
www.allitebooks.com

www.allitebooks.com

 • 
Hartmut Ehrig
Claudia Ermel • Ulrike Golas
Frank Hermann
Graph and Model
Transformation
General Framework and Applications
www.allitebooks.com

 
Springer-Verlag GmbH Berlin Heidelberg is part of Springer Science+Business Media (www.springer.com)
ISSN 1431-2654
ISBN 978-3-662-47979-7
ISBN 9
(eBook)
DOI 10.1007/978-3-662-47980-3
Springer Heidelberg New York Dordrecht London
Library of Congress Control Number: 
Printed on acid-free paper
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of 
the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, 
recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or 
information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar 
methodology now known or hereafter developed. 
The use of general descriptive names, registered names, trademarks, service marks, etc. in this 
publication does not imply, even in the absence of a specific statement, that such names are exempt
from the relevant protective laws and regulations and therefore free for general use. 
The publisher, the authors and the editors are safe to assume that the advice and information in this 
book are believed to be true and accurate at the date of publication. Neither the publisher nor the 
authors or the editors give a warranty, express or implied, with respect to the material contained herein 
or for any errors or omissions that may have been made. 
© Springer-Verlag Berlin Heidelberg 2015
78-3-662-47980-3
ISSN 2193-2069
(electronic)
Monographs in Theoretical Computer Science. An EATCS Series
Claudia Ermel
Hartmut Ehrig
Berlin, Germany
Technische Universität Berlin
Series Editors
Monika Henzinger
Juraj Hromkovič
Mogens Nielsen
Department of Computer Science
Aarhus, Denmark
Turku Centre of Computer Science
Grzegorz Rozenberg
Leiden Centre of Advanced
Leiden University
Leiden, The Netherlands
Arto Salomaa
Turku, Finland
Computer Science
Wien, Austria
Faculty of Science
Universität Wien
Aarhus Universitet
ETH Zentrum
Department of Computer Science
Swiss Federal Institute of Technology
Zürich, Switzerland
Institut für Informatik
versität 
Berlin
Ulrike Golas
Humboldt-Uni
zu 
and
Konrad-Zuse-Zentrum für
Berlin, Germany
Informationstechnik
Interdisciplinary Centre for Security
Frank Hermann
Reliability and Trust
University of Luxembourg
Luxembourg
and
Berlin, Germany
Carmeq GmbH
Institut für Softwaretechnik
und Theoretische Informatik
Berlin, Germany
Technische Universität Berlin
Institut für Softwaretechnik
und Theoretische Informatik
Berlin, Germany
2015954661
www.allitebooks.com

Preface
Graphs are important structures in mathematics, computer science and several other
research and application areas. The concepts of graph transformation and graph
grammars started in the late 1960s and early 1970s to become of interest in pic-
ture processing and computer science. The main idea was to generalise well-known
rewriting techniques from strings and trees to graphs. Today, graph transformation
techniques are playing a central role in theoretical computer science, as well as in
several application areas, such as software engineering, concurrent and distributed
systems, and especially visual modelling techniques and model transformations.
The state of the art of graph transformation techniques was presented in the
“Handbook of Graph Grammars and Computing by Graph Transformation” in 1997,
and later, especially for algebraic graph transformation, in the EATCS monograph
“Fundamentals of Algebraic Graph Transformation” in 2006. In that monograph,
called the FAGT-book, the important application area of model transformations was
presented as a detailed example only. Since then, the algebraic approach of triple
graph grammars has been developed and is presented in this book, which allows not
only model transformation, but also model integration and synchronisation as well
as analysis techniques, including correctness, completeness, functional behaviour
and conﬂict resolution. Moreover, the theory of algebraic graph transformation pre-
sented in the FAGT-book is extended in this book with regard to the abstract frame-
work based on M-adhesive categories, and by multi-amalgamated transformations,
including the powerful concept of (nested) application conditions. The theory is
applied in this book to self-adaptive systems and enterprise modelling, and it is sup-
ported by various tools, extending the tool AGG, well-known from the FAGT-book.
Altogether this new book can be considered as a continuation of the FAGT-book,
leading to a new state of the art of graph and model transformation in 2014.
The material of this book was developed by the groups in Berlin and Luxem-
bourg in close cooperation with several international partners, including Gabriele
Taentzer, Karsten Ehrig, Fernando Orejas, Reiko Heckel, Andy Schürr, Annegret
Habel, Barbara König, Leen Lambers, and Christoph Brandt. Many thanks to all of
them. Chap. 10 on self-adaptive systems is co-authored by Antonio Bucchiarone,
Patrizio Pelliccione, and Olga Runge.
V
www.allitebooks.com

VI
Preface
Finally, we thank Grzegorz Rozenberg and all other editors of the EATCS Mono-
graphs series, and those of Springer, especially Ronan Nugent, for smooth publica-
tion.
Berlin, Spring 2015
Hartmut Ehrig
Claudia Ermel
Ulrike Golas
Frank Hermann
www.allitebooks.com

Contents
Part I Introduction to Graph and Model Transformation
1
General Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.1
General Overview of Graph and Model Transformation . . . . . . . . . . .
5
1.1.1
What Is Graph Transformation? . . . . . . . . . . . . . . . . . . . . . . . .
5
1.1.2
What Is the Algebraic Approach to Graph Transformation? .
6
1.1.3
What Is Model Transformation? . . . . . . . . . . . . . . . . . . . . . . . .
8
1.1.4
How Can Algebraic Graph Transformation Support Model
Transformation? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.1.5
Historical Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.2
The Chapters of This Book and the Main Results . . . . . . . . . . . . . . . . 10
1.2.1
Part I–Introduction to Graph and Model Transformation . . . . 10
1.2.2
Part II–M-Adhesive Transformation Systems. . . . . . . . . . . . . 10
1.2.3
Part III–Model Transformation Based on Triple Graph
Grammars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.2.4
Part IV–Application Domains, Case Studies and Tool
Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.2.5
Appendices A and B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.2.6
Hints for Reading This Book . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2
Graph Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2.1
Graphs, Typed Graphs, and Attributed Graphs . . . . . . . . . . . . . . . . . . 13
2.2
Graph Transformation with Application Conditions . . . . . . . . . . . . . . 16
2.3
Results for Graph Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.3.1
Local Church–Rosser and Parallelism Theorem . . . . . . . . . . . 26
2.3.2
Concurrency Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
2.3.3
Amalgamation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
2.3.4
Embedding and Extension Theorem. . . . . . . . . . . . . . . . . . . . . 35
2.3.5
Critical Pairs and Local Conﬂuence Theorem . . . . . . . . . . . . . 38
VII
www.allitebooks.com

VIII
Contents
3
Model Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
3.1
Introduction to Model Transformation . . . . . . . . . . . . . . . . . . . . . . . . . 43
3.2
Model Transformation by Graph Transformation . . . . . . . . . . . . . . . . 48
3.3
Introduction to Triple Graph Grammars . . . . . . . . . . . . . . . . . . . . . . . . 52
3.4
Model Transformation Based on TGGs . . . . . . . . . . . . . . . . . . . . . . . . 60
Part II M-Adhesive Transformation Systems
4
Adhesive and M-Adhesive Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.1
M-Adhesive Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
4.2
Overview of Diﬀerent Adhesive and HLR Notions . . . . . . . . . . . . . . . 69
4.2.1
From Adhesive to M-Adhesive Categories . . . . . . . . . . . . . . . 70
4.2.2
Partial Map and Partial Van Kampen Square Adhesive
Categories
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
4.3
Results and Additional HLR Properties for M-Adhesive Categories
74
4.3.1
Basic HLR Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
4.3.2
Additional HLR Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
4.3.3
Finite Coproducts and E′–M′ Pair Factorisation . . . . . . . . . . 77
4.4
Finitary M-Adhesive Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
4.4.1
Basic Notions of Finitary M-Adhesive Categories. . . . . . . . . 79
4.4.2
Additional HLR Properties in Finitary M-Adhesive
Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
4.4.3
Finitary Restriction of M-Adhesive Categories . . . . . . . . . . . 82
4.4.4
Functorial Constructions of Finitary M-Adhesive Categories 84
4.5
Preservation of Additional HLR Properties . . . . . . . . . . . . . . . . . . . . . 85
4.5.1
Binary Coproducts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
5
M-Adhesive Transformation Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
5.1
Rules and Transformations with Application Conditions . . . . . . . . . . 91
5.2
Results for Transformations with Application Conditions . . . . . . . . . 100
5.2.1
Local Church–Rosser and Parallelism Theorem . . . . . . . . . . . 101
5.2.2
Concurrency Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
5.2.3
Embedding and Extension Theorem. . . . . . . . . . . . . . . . . . . . . 110
5.2.4
Critical Pairs and Local Conﬂuence Theorem . . . . . . . . . . . . . 114
5.3
Process Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
5.3.1
Permutation Equivalence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
5.3.2
Subobject Transformation Systems . . . . . . . . . . . . . . . . . . . . . 128
5.3.3
Analysis Based on Petri Nets . . . . . . . . . . . . . . . . . . . . . . . . . . 134
6
Multi-amalgamated Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
6.1
Kernel Rules, Multi Rules, and Complement Rules . . . . . . . . . . . . . . 139
6.2
Amalgamated Rules and Transformations . . . . . . . . . . . . . . . . . . . . . . 146
6.3
Results for Amalgamated Transformations . . . . . . . . . . . . . . . . . . . . . 151
6.3.1
Parallel Independence of Amalgamated Transformations . . . 151
6.3.2
Other Results for Amalgamated Transformations . . . . . . . . . . 157
6.4
Interaction Schemes and Maximal Matchings . . . . . . . . . . . . . . . . . . . 157
www.allitebooks.com

Contents
IX
6.4.1
Main Results for Amalgamated Transformations Based on
Maximal Matchings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
6.4.2
Semantics for Elementary Nets . . . . . . . . . . . . . . . . . . . . . . . . . 162
Part III Model Transformation Based on Triple Graph Grammars
7
Model Transformation and Model Integration . . . . . . . . . . . . . . . . . . . . . 171
7.1
Triple Graphs form an M-adhesive Category . . . . . . . . . . . . . . . . . . . 171
7.2
Derivation of Operational Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
7.3
Model Transformation Based on Forward Rules . . . . . . . . . . . . . . . . . 184
7.4
Model Transformation Based on Forward Translation Rules . . . . . . . 192
7.4.1
Translation Attributes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
7.4.2
Execution via Forward Translation Rules . . . . . . . . . . . . . . . . 195
7.5
Model Integration Based on Integration Rules . . . . . . . . . . . . . . . . . . . 200
7.5.1
Model Integration Rules and Transformations . . . . . . . . . . . . 200
7.5.2
Model Integration as Model Transformation . . . . . . . . . . . . . . 204
7.5.3
Consistency Checking of Integrated Models . . . . . . . . . . . . . . 206
7.6
Flattening of Triple Graph Grammars . . . . . . . . . . . . . . . . . . . . . . . . . . 208
8
Analysis of Model Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
8.1
Syntactical Correctness and Completeness. . . . . . . . . . . . . . . . . . . . . . 216
8.2
Functional Behaviour and Information Preservation . . . . . . . . . . . . . . 220
8.2.1
Functional Behaviour and Eﬃcient Execution . . . . . . . . . . . . 220
8.2.2
Information Preservation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
8.3
Reduction of Nondeterminism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
9
Model Synchronisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
9.1
General Concept for Change Propagation . . . . . . . . . . . . . . . . . . . . . . 252
9.2
Basic Model Synchronisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
9.2.1
Derived Operational Rules for Synchronisation . . . . . . . . . . . 258
9.2.2
Execution of Basic Synchronisation . . . . . . . . . . . . . . . . . . . . . 264
9.2.3
Correctness and Invertibility of Model Synchronisation . . . . 271
9.3
Concurrent Model Synchronisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
9.3.1
Concurrent Synchronisation Problem. . . . . . . . . . . . . . . . . . . . 281
9.3.2
Concurrent Model Synchronisation with Conﬂict Resolution 283
9.3.3
Correctness and Compatibility . . . . . . . . . . . . . . . . . . . . . . . . . 288
9.4
Related and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
Part IV Application Domains, Case Studies and Tool Support
10
Modelling and Static Analysis of Self-adaptive Systems by Graph
Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
10.1 Modelling Self-adaptive Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
10.1.1 Running Example: A Car Logistics System (CLS) . . . . . . . . . 300
10.1.2 Framework for Rule-Based Dynamic Adaptation . . . . . . . . . . 302
10.1.3 Modelling SA Systems by Graph Transformation . . . . . . . . . 304
www.allitebooks.com

X
Contents
10.2 Static Analysis of Self-adaptive Systems . . . . . . . . . . . . . . . . . . . . . . . 313
10.3 Automating the Approach by AGG . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320
10.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
10.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
11
Enterprise Modelling and Model Integration . . . . . . . . . . . . . . . . . . . . . . 327
11.1 Enterprise Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327
11.2 Inter-modelling by Triple Graph Grammars . . . . . . . . . . . . . . . . . . . . . 333
11.3 Model Transformation Between Business and IT Service Models . . 338
11.4 Model Integration Between Business and IT Service Models . . . . . . 343
11.5 Summary of Achievements and Related Work . . . . . . . . . . . . . . . . . . . 348
12
Tool Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
12.1 The Attributed Graph Grammar System AGG 2.0. . . . . . . . . . . . . . . . 352
12.1.1 Editing and Simulating Graph Transformation Systems . . . . 352
12.1.2 Rule Application Control. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
12.1.3 Rule Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
12.1.4 Analysis of Graph Transformation Systems . . . . . . . . . . . . . . 361
12.2 ActiGra: Checking Consistency Between Control Flow and
Functional Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364
12.2.1 Case Study: A Conference Scheduling System . . . . . . . . . . . . 366
12.2.2 Integrating Activity Models with Graph Transformation . . . . 367
12.2.3 Plausibility Checks for Integrated Behaviour Models . . . . . . 371
12.3 Controlled EMF Model Transformation with EMF Henshin . . . . . . . 377
12.3.1 Example: Personal Mobility Manager . . . . . . . . . . . . . . . . . . . 380
12.3.2 EMF Henshin Transformation Units . . . . . . . . . . . . . . . . . . . . 382
12.3.3 Application Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385
12.4 Bidirectional EMF Model Transformation with HenshinTGG . . . . . . . 387
12.4.1 The Visual TGG Editor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387
12.4.2 Generation of Forward Translation Rules . . . . . . . . . . . . . . . . 391
12.4.3 Conﬂict Analysis Based on AGG . . . . . . . . . . . . . . . . . . . . . . . 393
12.4.4 Performing Model Transformation in HenshinTGG . . . . . . . . . 394
12.5 Related Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
A
Basic Notions of Category Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
A.1 Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
A.2 Construction of Categories, and Duality . . . . . . . . . . . . . . . . . . . . . . . . 402
A.3 Monomorphisms, Epimorphisms, and Isomorphisms . . . . . . . . . . . . . 403
A.4 Pushouts and Pullbacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
A.5 Binary Coproducts and Initial Objects . . . . . . . . . . . . . . . . . . . . . . . . . 407
A.6 Functors, Functor Categories, and Comma Categories . . . . . . . . . . . . 408
A.7 Isomorphism and Equivalence of Categories . . . . . . . . . . . . . . . . . . . . 410

Contents
XI
B
Proofs and Additional Properties for Parts II and III . . . . . . . . . . . . . . . 413
B.1
Derived Properties of Limits and Colimits . . . . . . . . . . . . . . . . . . . . . . 413
B.2
Proofs for Sect. 4.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
B.2.1
Proof of Fact 4.36 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
B.2.2
Proof of Fact 4.38 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
B.2.3
Proof of Fact 4.40 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
B.3
Construction of M-Adhesive Categories . . . . . . . . . . . . . . . . . . . . . . . 421
B.4
Proofs for Sect. 4.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424
B.4.1
Proof of Fact 4.51 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424
B.4.2
Proof of Fact 4.54 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 426
B.4.3
Proof of Fact 4.55 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
B.4.4
Proof of Fact 4.56 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432
B.5
Proofs for Sect. 6.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433
B.5.1
Proof of Fact 6.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433
B.5.2
Proof of Fact 6.16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
B.5.3
Proof of Theorem 6.17 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
B.5.4
Proof of Theorem 6.24 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438
B.6
Proofs for Chap. 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
B.6.1
Proof for Lem. 7.9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
B.6.2
Proof for Fact 7.36 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
B.6.3
Proof for Fact 7.52 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467

Part I
Introduction to Graph and Model
Transformation

3
This ﬁrst part of the book provides a general introduction to graph transforma-
tion and model transformations. After a general introduction in Chap. 1, we present
in Chap. 2 graphs, typed graphs and attributed graphs in the sense of [EEPT06] and
graph transformation with application conditions. In contrast to basic application
conditions in [EEPT06] we introduce the more powerful nested application condi-
tions in the sense of [HP05] and present the following main results in this more
general framework: Local Church–Rosser and Parallelism Theorem, Concurrency,
Amalgamation, Embedding and Extension Theorem as well as Critical Pair Anal-
ysis and Local Conﬂuence Theorem. All these results have been shown without
application conditions in [EEPT06], except amalgamation, which is an important
extension in this book. These theorems are carefully motivated by running exam-
ples, but they are stated without proofs in Chap. 2, because they are special cases of
corresponding results in the general framework of M-adhesive transformation sys-
tems presented in Part II. In Chap. 3, we introduce model transformations in general
and model transformation based on graph transformation as motivated in Sect. 1.1.4.
Especially, we introduce triple graph grammars and show how they can be used to
deﬁne model transformation, model integration and model synchronisation. More-
over, the main results concerning analysis of model transformations are illustrated
by running examples, while the full theory, including proofs, is given in Part III.

Chapter 1
General Introduction
1.1 General Overview of Graph and Model Transformation
In this general introduction we give a general overview of graph and model trans-
formation and a short overview of the parts and chapters of this book. The main
questions are the following:
• What is graph transformation?
• What is the algebraic approach to graph transformation?
• What is model transformation?
• How can algebraic graph transformation support model transformation?
1.1.1 What Is Graph Transformation?
Graphs are important structures in mathematics, computer science and several other
research and application areas. A graph consists of nodes, also called vertices;
edges; and two functions assigning source and target nodes to each edge. In fact,
there are several variants of graphs, like labelled, typed, and attributed graphs, which
will be considered in this book, because they are important for diﬀerent kinds of ap-
plications. Properties of graphs, like shortest paths, are studied within graph theory,
where in general the structure of the graph is not changed. Graph transformation,
in contrast, is a formal approach for structural modiﬁcations of graphs via the ap-
plication of transformation rules. A graph rule, also called production p = (L, R),
consists of a left-hand side graph L, a right-hand side graph R, and a mechanism
specifying how to replace L by R as shown schematically in Fig. 1.1.
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
5
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_1

6
1 General Introduction
L
R
p=(L,R)
Fig. 1.1 Rule-based modiﬁcation of graphs
This graph replacement mechanism is diﬀerent in each of the following main
graph transformation approaches presented in Volume 1 of the Handbook of Graph
Grammars and Computing by Graph Transformation [Roz97]:
• Node Label Replacement Approach
• Hyperedge Replacement Approach
• Algebraic Approach
• Logical Approach
• Theory of 2-Structures
• Programmed Graph Replacement Approach
In all approaches, a graph transformation system consists of a set of rules; more-
over, a graph transformation system together with a distinct start graph forms a
graph grammar.
1.1.2 What Is the Algebraic Approach to Graph Transformation?
In this book, we present the algebraic approach of graph transformation, where a
(basic) graph G = (V, E, s, t) is an algebra with base sets V (vertices), E (edges), and
operations s: E →V (source) and t: E →V (target). Graph morphisms are special
cases of algebra homomorphisms f = (fV : V1 →V2, fE : E1 →E2). This means
that a graph morphism is required to be compatible with the operations source and
target. It is important to note that graphs and graph morphisms deﬁne a category
Graphs, such that categorical constructions and results are applicable in the alge-
braic approach of graph transformation. In fact, an important concept is the gluing
construction of graphs, which corresponds to the pushout construction in the cate-
gory Graphs. Pushouts are unique up to isomorphism and have useful composition
and decomposition properties. The main conceptual idea of gluing is the following:
Given graphs G1 and G2 with common intersection G0, the gluing G3 of G1 and
G2 along G0, written G3 = G1 +G0 G2, is given by the union G3 of G1 and G2 and
shown in the gluing diagram in Fig. 1.2, which is a pushout diagram in the category
Graphs.

1.1 General Overview of Graph and Model Transformation
7
G0

/ G1

(PO)
G2
/ G3
Fig. 1.2 Gluing (pushout) diagram of graphs
L

K

o
/
(1)
(2)
R

G
D
o
/ H
Fig. 1.3 Direct graph transformation
A production p = (L ←K →R) in the algebraic approach is given not only
by left- and right-hand side graphs L and R, but, in addition, by a gluing graph K
and (injective) graph morphisms from K to L and R. Given a context graph D with
morphism K →D, a direct graph transformation from a graph G to a graph H via
a production p, written G =⇒H via p, is given by two gluing (pushout) diagrams as
shown in Fig. 1.3. This means that G is the gluing of L and D along K, and H the
gluing of R and D along K. In other words, L is replaced by R, while the context
D remains unchanged. This deﬁnition of direct graph transformation is elegant, be-
cause it is well deﬁned (up to isomorphism) and symmetric. However, it leaves open
how to apply a production p to a given host graph G and how to calculate the host
graph H. In order to apply a production p = (L ←K →R) to a graph G, we ﬁrst
have to ﬁnd an occurrence of L in G, given by a graph morphism m: L →G, called
match morphism. Then, we have to construct D and H in such a way that (1) and (2)
become gluing (pushout) diagrams in Fig. 1.3. Roughly spoken, D is constructed by
deleting from G all parts of L which are not in K, written G\(L\K). In order to avoid
that D becomes a partial graph, where some edges have no source or target, a certain
gluing condition (see Chap. 2) has to be satisﬁed, which makes sure that D becomes
a well-deﬁned graph, and diagram (1) in Fig. 1.3 is a pushout diagram. This means,
given a production p = (L ←K →R) and a match m: L →G satisfying the gluing
condition, we obtain in a ﬁrst step the context graph D and gluing (pushout) diagram
(1) and in a second step diagram (2) by gluing (pushout) construction. The ﬁrst step
corresponds to the deletion of L \ K from G and the second step to the addition of
R \ K leading to H, written G =⇒H via p and m. This algebraic approach is called
double pushout (DPO) approach, because a direct transformation consists of two
pushouts in the category Graphs (see Fig. 1.3). An important variant of the alge-
braic approach is the single pushout (SPO) approach, where a direct transformation
is deﬁned by a single pushout in the category PGraphs of graphs and partial graph

8
1 General Introduction
morphisms. In this book, we mainly present the algebraic DPO approach of graph
transformation. Moreover, we allow replacing the category of graphs by a suitable
axiomatic category (see M-adhesive categories in Chap. 4). This leads to the con-
cept of M-adhesive transformation systems in the algebraic approach, which can be
specialised to transformation systems for diﬀerent kinds of graphs, Petri nets, and
other kinds of high-level replacement systems.
1.1.3 What Is Model Transformation?
Model-driven software development (MDD) has been used successfully within the
last two decades for the generation of software systems. Especially, UML dia-
grams [UML15] are useful for modelling diﬀerent views of systems on an abstract
level independently of speciﬁc implementations. In this case, models are UML di-
agrams, but in general models can be any kind of visual or textual artefacts. This
culminates in the well-known slogan “Everything is a Model” stated in [Béz05].
Model transformation means deﬁning transformations between (diﬀerent) models. It
plays a central role in MDD and several other applications. Model transformations in
MDD are especially used to refactor models, to translate them to intermediate mod-
els, and to generate code. According to [CH06], we distinguish between endogenous
and exogenous transformations. Endogenous transformations take place within one
modelling language and exogenous ones are translations between diﬀerent model
languages. Moreover, model-to-model transformations are usually distinguished
from model-to-text transformations. Typical examples of model-to-model transfor-
mations are the transformation S2P from statecharts to Petri nets in [EEPT06] and
CD2RDBM from class diagrams to relational database models in this book. Impor-
tant properties for most kinds of model transformations are type consistency, ter-
mination, syntactical and semantic correctness, completeness, functional behaviour
and information preservation. We will discuss this topic in the next subsection and
in Part III of this book.
1.1.4 How Can Algebraic Graph Transformation Support Model
Transformation?
In [CH06], an overview of various model transformation approaches is given fol-
lowing object-oriented, rule-based, constraint-based and imperative concepts. In
the following, we show how algebraic graph transformation can support the deﬁni-
tion and analysis of rule-based model transformations [Tae10]. Especially for visual
models, graph transformation is a natural choice for manipulating their underlying
graph structures. The double pushout (DPO) approach introduced above can be in-
terpreted as a kind of in-place transformation, where the source graph is transformed
step by step into the target graph. Using the DPO approach for typed graphs—with

1.1 General Overview of Graph and Model Transformation
9
diﬀerent type graphs for source and target domain—allows us to ensure type con-
sistency by construction [EEPT06]. The rich theory of the DPO approach provides
support for the veriﬁcation of other properties of model transformations discussed
above [EE08]. Even better support for the veriﬁcation of these properties is given
by the triple graph grammar (TGG) approach [KS06, EEE+07] presented in Chap. 3
and Part III of this book. A triple graph consists of a source graph, a target graph, and
a correspondence graph. The last one is mapped to the source and the target graph
in order to establish a correspondence between elements of these graphs. The TGG
approach is closely related to the DPO approach, in the way that graphs are replaced
by triple graphs and TGG rules are usually nondeleting. The main additional idea is
the following: From each TGG rule, a forward and a backward rule can be derived
automatically, which allows us to construct type-consistent and syntactically correct
forward and backward transformations between the source model and target model
domains.
1.1.5 Historical Notes
Historically, graph grammars and transformations were ﬁrst studied as “web gram-
mars” by Pfalz and Rosenfeld [PR69] in order to deﬁne rule-based image recogni-
tion. Pratt [Pra71] used pair graph grammars for string-to-graph translations, similar
to the concept of the triple graph grammar approach. The historical roots of the al-
gebraic approach were presented by Ehrig, Pfender, and Schneider [EPS73]. The
ﬁrst introduction to the DPO approach—including the well-known Local Church–
Rosser Theorem—was presented by Ehrig and Rosen in [ER76, Ehr79]. The ﬁrst
book on graph grammars was published by Nagl [Nag79] with its main focus on the
Chomsky hierarchy, implementation and applications. The concept of graph trans-
formation has at least three diﬀerent historical roots:
1. from Chomsky grammars on strings to graph grammars,
2. from term rewriting to graph rewriting,
3. from textual description to visual modelling.
Motivated by these roots, the concept of “Computing by Graph Transforma-
tion” was developed as a basic paradigm in the ESPRIT Basic Research Actions
COMPUGRAPH and APPLIGRAPH, and continued in the TMR Networks GET-
GRATS and SEGRAVIS in the period 1990–2006. The state of the art of graph
transformation and their applications of 15 years ago is documented in three vol-
umes of the “Handbook of Graph Grammars and Computing by Graph Transforma-
tion” [Roz97, EEKR99, EKMR99], where [Roz97] includes an introduction to the
algebraic SPO and DPO approaches. A ﬁrst detailed part of the theory of the DPO
approach was published in the EATCS Monographs in TCS [EEPT06], while the
newer developments are presented in this book. We present its main concepts, based
on the extended theory of M-adhesive transformation systems [EGH10], including
results for parallelism, concurrency and amalgamation [EGH+14]; results for sys-

10
1 General Introduction
tems with nested application conditions concerning embedding, critical pairs and
local conﬂuence [EGH+12]; characterisations of constructions based on the notion
of ﬁnitary M-adhesive categories [GBEG14]; multi-amalgamation [GHE14]; con-
currency based on permutation equivalence [HCE14]; and model transformation and
model synchronisation based on triple graph grammars [HEGO14, HEO+13].
1.2 The Chapters of This Book and the Main Results
1.2.1 Part I–Introduction to Graph and Model Transformation
Part I of this book is an introduction to graph and model transformation based on the
algebraic approach to graph grammars in the classical sense of [Ehr79] and triple
graph grammars introduced in [Sch94], respectively. After a general introduction
in Chap. 1 we present in Chap. 2 graphs, typed graphs and attributed graphs in the
sense of [EEPT06] and graph transformation with application conditions. In contrast
to basic application conditions in [EEPT06] we introduce the more powerful nested
application conditions in the sense of [HP05] and present the following main results
in this more general framework: Local Church–Rosser and Parallelism Theorem,
Concurrency, Amalgamation, Embedding and Extension Theorems as well as Criti-
cal Pair Analysis and Local Conﬂuence Theorem. All these results have been shown
without application conditions in [EEPT06], except amalgamation, which is an im-
portant extension in this book. All these results are carefully motivated by running
examples, but they are stated without proofs in Chap. 2, because they are special
cases of corresponding results in the general framework of M-adhesive transforma-
tion systems presented in Part II. In Chap. 3, we introduce model transformations
in general and model transformation based on graph transformation as motivated
in Sect. 1.1.4. In particular, we introduce triple graph grammars and show how they
can be used to deﬁne model transformation, model integration and model synchroni-
sation. The main results concerning analysis of model transformations are illustrated
by running examples, while the full theory including proofs is given in Part III.
1.2.2 Part II–M-Adhesive Transformation Systems
The algebraic approach to graph transformation is not restricted to graphs of the
form G = (V, E, s, t), as considered in Sect. 1.1.1, but has been generalised to a
large variety of diﬀerent types of graphs and other kinds of high-level structures,
such as labelled graphs, typed graphs, hypergraphs and diﬀerent kinds of low and
high-level Petri nets. The extension from graphs to high-level structures was intro-
duced in [EHKP91a, EHKP91b], leading to the theory of high-level replacement
(HLR) systems. In [EHPP04] the concept of HLR systems was joined to that of
www.allitebooks.com

1.2 The Chapters of This Book and the Main Results
11
adhesive categories of Lack and Sobocinsky in [LS04], leading to the concepts
of adhesive HLR categories used in [EEPT06] and M-adhesive categories in this
book, where all these concepts are introduced in Chap. 4. Moreover, this chapter
includes an overview of diﬀerent adhesive and HLR notions and several results
concerning HLR properties, which are used in the general theories of Chapters 5
and 6 and for the construction of M-adhesive categories. In fact, M-adhesive cat-
egories and transformation systems constitute a suitable general framework for an
abstract theory of graph and model transformations, which can be instantiated to
various kinds of high-level structures, especially to those mentioned above. All the
concepts and results—introduced for graph transformation in Chap. 2—are care-
fully presented and proven in Chap. 5 for M-adhesive transformation systems and
in Chap. 6 for multi-amalgamated transformations. Finally it is shown in Chap. 6
how multi-amalgamation can be used to deﬁne the semantics of elementary Petri
nets.
1.2.3 Part III–Model Transformation Based on Triple Graph
Grammars
Following the informal introduction to model transformation in Chap. 3 of Part I, we
present the formal theory of graph transformation based on triple graph grammars
in Part III. In Chap. 7, we give the foundations of triple graph grammars leading
to model transformation and model integration. It is important to note that trans-
formation and integration are based on operational rules, which can be generated
automatically from the triple graph grammar rules. A ﬂattening construction allows
us to show the equivalence of model transformations based on triple graph grammars
and plain graph grammars. In Chap. 8, we present several analysis techniques for
model transformations, which are supported by tools discussed in Part II. Important
properties, which can be guaranteed or analysed in Chap. 8, include correctness and
completeness, functional behaviour and information preservation, as well as con-
ﬂict resolution and optimisation. In Chap. 9 model transformation techniques are
applied to model synchronisation, which is an important technique to keep or gain
consistency of source and target models after changing one or both of them. This
leads to unidirectional and concurrent model synchronisation, respectively.
1.2.4 Part IV–Application Domains, Case Studies and Tool Support
In Part IV we present diﬀerent application domains and case studies according to
diﬀerent parts of the theory given in Parts II and III, respectively. Moreover we
give an overview of diﬀerent tools, which support modelling and analysis of sys-
tems using graph transformation techniques presented in this book. In Chap. 10, we
introduce self-adaptive systems and show how they can be modelled and analysed

12
1 General Introduction
using graph transformation systems in Chap. 2, including a case study concerning
business processes. The application domain of enterprise modelling is considered in
Chap. 11, based on Chapters 3, 7 and 8, together with a case study on model trans-
formation between business and IT service models. Chap. 12 includes a discussion
of the following tools :
1. The Attributed Graph Grammar System AGG 2.0
2. ActiGra: Checking Consistency between Control Flow and Functional Be-
haviour
3. Controlled EMF Model Transformation with EMF Henshin
4. Bidirectional EMF Model Transformation with HenshinTGG
1.2.5 Appendices A and B
Appendix A presents basic notions of category theory and provides a short summary
of the categorical terms used throughout this book. We introduce categories, show
how to construct them, and present some basic constructions such as pushouts and
pullbacks. In addition, we give some speciﬁc categorical results which are needed
for the main part of the book. For a more detailed introduction to category theory
see [EM85, EM90, AHS90, EMC+01]. Appendix B provides diﬀerent properties as
well as some more technical proofs and additional properties for Parts II and III.
1.2.6 Hints for Reading This Book
For a gentle introduction to graph transformation from an application point of view
we propose starting with Chap. 2 and continuing with Chapters 10 and 11. The
general framework in Part II requires some knowledge in category theory as given
in Appendix A. For readers interested mainly in model transformation, we propose
starting with Chap. 3 and continuing with Chapters 7, 8 and 11, where some parts re-
quire basic knowledge of graph transformation presented in Chap. 2. Finally model
synchronisation in Chap. 9 should be studied after Chapters 3, 7 and 8.
The main parts of the theory for graph transformation systems without applica-
tion conditions were presented already in our ﬁrst book [EEPT06]. This ﬁrst book
includes also a discussion and case study for model transformations, but the theory
based on triple graph grammars in Part III is not included in [EEPT06].

Chapter 2
Graph Transformation
In this chapter, we introduce graphs and graph transformation. In Sect. 2.1, we de-
ﬁne graphs, typed graphs, and typed attributed graphs with their corresponding mor-
phisms. Transformations of these graphs are introduced in Sect. 2.2, together with
application conditions and two shift properties. In Sect. 2.3, important results for
graph transformations are motivated and explained.
2.1 Graphs, Typed Graphs, and Attributed Graphs
Graphs and graph-like structures are the main basis for (visual) models. Basically, a
graph consists of nodes, also called vertices, and edges, which link two nodes. Here,
we consider graphs which may have parallel edges as well as loops. A graph mor-
phism then maps the nodes and edges of the domain graph to those of the codomain
graph such that the source and target nodes of each edge are preserved by the map-
ping.
Deﬁnition 2.1 (Graph and graph morphism). A graph G = (VG, EG, sG, tG) con-
sists of a set VG of nodes, a set EG of edges, and two functions sG, tG : EG →VG
mapping to each edge its source and target node.
EG1
VG1
EG1
VG1
sG1
tG1
sG2
tG2
fE
fV
=
Given graphs G1 and G2, a graph morphism f : G1 →G2,
f = (fV, fE), consists of two functions fV : VG1 →VG2, fE :
EG1 →EG2 such that sG2 ◦fE = fV ◦sG1 and tG2 ◦fE = fV ◦tG1.
Graphs and graph morphisms form the category Graphs,
together with the componentwise compositions and identi-
ties.
△
An important extension of plain graphs is the introduction of types. A type graph
deﬁnes a node type alphabet as well as an edge type alphabet, which can be used to
assign a type to each element of a graph. This typing is done by a graph morphism
into the type graph. Type graph morphisms then have to preserve the typing.
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_2
13

14
2 Graph Transformation
P
T
P
R
S
idle
idle
P
T
P
R
P
F2
R
G
T
idle
idle
active
crit
g
P
T
R
F1
F2
TG
idle
active
crit
typeG
typeS
Fig. 2.1 Example typed graph and typed graph morphism
Deﬁnition 2.2 (Typed graph and typed graph morphism). A type graph is a
distinguished graph TG. Given a type graph TG, a tuple GT = (G, typeG) of a graph
G and a graph morphism typeG : G →TG is called a typed graph.
G1
G2
TG
f
typeG1
typeG2
=
Given typed graphs GT
1 and GT
2 , a typed graph morphism
f : GT
1 →GT
2 is a graph morphism f : G1 →G2 such that
typeG2 ◦f = typeG1. Given a type graph TG, typed graphs
and typed graph morphisms form the category GraphsTG,
together with the componentwise compositions and identi-
ties.
△
If the typing is clear in the context, we may not explicitly mention it and consider
only the typed graph G with implicit typing typeG.
Example 2.3. To illustrate our deﬁnitions and results in the following sections, we
introduce an example describing a mutual exclusion algorithm closely following
Dijkstra’s work [Dij65] and extending our example in [EGH+14]. In our system,
we have an arbitrary number of processes P and resources R. To each resource, a
turn variable T may be connected assigning it to a process. Each process may be
idle or active and has a ﬂag with possible values 0, 1, 2, initially set to 0, which
is graphically described by no ﬂag at all at this process. Moreover, a label crit
marks a process which has entered its critical section actually using the resource.
Thus, the type graph used for our example is TG = (VTG, ETG, sTG, tTG) with VTG =
{P, T, R, F1, F2} and ETG = {active, idle, crit}, as shown in the right of Fig. 2.1.
In the left of this ﬁgure, a system S is modelled containing a resource and two idle
processes, where one of them is connected via a turn variable to the resource. There
is an injective graph morphism g : S →G extending S by another active process
with a ﬂag and a turn to an additional resource. Both S and G are typed over TG.
In drawings of graphs, nodes are drawn by circles and edges by arrows point-
ing from the source to the target node. The actual mapping of the elements can be
concluded by positions or is conveyed by indices, if necessary.
△
Attributed graphs are graphs extended by an underlying data structure given by
an algebra (see [EEPT06]), such that nodes and edges of a graph may carry attribute

2.1 Graphs, Typed Graphs, and Attributed Graphs
15
values. For the formal deﬁnition, these attributes are represented by edges into the
corresponding data domain, which is given by a node set. An attributed graph is
based on an E-graph that has, in addition to the standard graph nodes and edges, a
set of data nodes as well as node and edge attribute edges.
Deﬁnition 2.4 (Attributed graph and attributed graph morphism). An E-graph
GE = (VG
G, VG
D, EG
G, EG
NA, EG
EA, (sG
i , tG
i )i∈{G,NA,EA}) consists of graph nodes VG
G, data
nodes VG
D, graph edges EG
G, node attribute edges EG
NA, and edge attribute edges EG
EA,
EG
G
VG
G
EG
EA
EG
NA
VG
D
sG
EA
tG
EA
sG
NA
tG
NA
sG
G
tG
G
according to the following signature.
For E-graphs GE
1 and GE
2 , an E-
graph morphism f : GE
1 →GE
2 is a tu-
ple f = (( fVi : VG1
i
→VG2
i )i∈{G,D}, (fE j :
EG1
j
→EG2
j ) j∈{G,NA,EA}) such that f
commutes with all source and target
functions.
An attributed graph G over a data signature DSIG = (S D, OPD) with attribute
value sorts S ′
D ⊆S D is given by G = (GE, DG), where GE is an E-graph and DG is
a DSIG-algebra such that ∪s∈S ′
DDG,s = VG
D.
For attributed graphs G1 = (GE
1 , DG1) and G2 = (GE
2 , DG2), an attributed graph
morphism f : G1 →G2 is a pair f = (fG, fD) with an E-graph morphism fG : GE
1 →
GE
2 and an algebra homomorphism fD : DG1 →DG2 such that fG,VD(x) = fD,s(x) for
all x ∈DG1,s, s ∈S ′
D.
Attributed graphs and attributed graph morphisms form the category AGraphs,
together with the componentwise compositions and identities.
△
As for standard typed graphs, an attributed type graph deﬁnes a set of types which
can be used to assign types to the nodes and edges of an attributed graph. The typing
itself is done by an attributed graph morphism between the attributed graph and the
attributed type graph.
Deﬁnition 2.5 (Typed attributed graph and morphism).
An attributed type
graph is a distinguished attributed graph ATG = (TG, Z), where Z is the ﬁnal DSIG-
algebra.
A tuple GT = (G, typeG) of an attributed graph G together with an attributed
graph morphism typeG : G →ATG is then called a typed attributed graph.
Given typed attributed graphs GT
1 = (G1, typeG1) and GT
2 = (G2, typeG2), a typed
attributed graph morphism f : GT
1 →GT
2 is an attributed graph morphism f : G1 →
G2 such that typeG2 ◦f = typeG1.
For a given attributed type graph ATG, typed attributed graphs and typed at-
tributed graph morphisms form the category AGraphsATG, together with the compo-
nentwise compositions and identities.
△
Example 2.6. Considering the model from Ex. 2.3, we may also use attributes to
model the state of a process instead of the connected loop. In addition, a Boolean
attribute of the resource can describe if it is currently in use. Moreover, only one type

16
2 Graph Transformation
P : process
state = ”crit”
T : turn
P : process
state = ”idle”
R : resource
inUse = false
T : turn
P : process
state = ”idle”
F : flag
value = 2
R : resource
inUse = true
G
P : process
state : String
T : turn
R : resource
inUse : bool
F : flag
value : int
ATG
typeG
Fig. 2.2 Example with typed attributed graphs
of ﬂag connects P and T with an integer value of 1 or 2. The corresponding typed
attributed graphs G and ATG are shown in Fig. 2.2 in a UML class diagram-like
style.
△
2.2 Graph Transformation with Application Conditions
In [EEPT06], transformation systems based on a categorical foundation were in-
troduced which can be instantiated to various graphs and graph-like structures. In
this section, we present the implementation of this theory for transformations of
typed graphs using rules extended with application conditions. Those have been
introduced in [EEPT06], but no full theory was developed there.
Basically, a condition describes whether a graph contains a certain structure as a
subgraph.
Deﬁnition 2.7 (Graph condition). A (nested) graph condition ac over a graph P
is of the form ac = true, ac = ¬ac′, ac = ∃(a, ac′′), ac = ∧i∈Iaci, or ac = ∨i∈Iaci,
where ac′ is a graph condition over P, a : P →C is a morphism, ac′′ is a graph
condition over C, and (aci)i∈I with an index set I are graph conditions over P.
△
For simplicity, false abbreviates ¬true, ∃a abbreviates ∃(a, true), and ∀(a, ac)
abbreviates ¬ ∃(a, ¬ac).
A graph condition is satisﬁed by a morphism into a graph if the required structure
exists, which can be veriﬁed by the existence of suitable morphisms.
Deﬁnition 2.8 (Satisfaction of graph conditions). Given a graph condition ac over
P
C
G
ac′
ac
a
p
q
P, a morphism p : P →G satisﬁes ac, written
p |= ac, if
• ac = true,
• ac = ¬ac′ and p ̸|= ac′,
• ac =
∃(a, ac′) and there exists an injective morphism q with q ◦a = p and
q |= ac′,

2.2 Graph Transformation with Application Conditions
17
• ac = ∧i∈Iaci and ∀i ∈I : p |= aci, or
• ac = ∨i∈Iaci and ∃i ∈I : p |= aci.
△
A rule is a general description of local changes that may occur in graphs. Mainly,
it consists of a deletion and a construction part, deﬁned by the rule morphisms l and
r, respectively. In addition, an application condition restricts the application of this
rule to certain graphs.
Deﬁnition 2.9 (Rule). A rule p = (L
l
←−K
r
−→R, ac) consists of graphs L, K,
and R, called left-hand side, gluing, and right-hand side, respectively, two injective
morphisms l and r, and a graph condition ac over L, called application condition.
△
A transformation describes the application of a rule to a graph via a match. It can
only be applied if the match satisﬁes the application condition.
Deﬁnition 2.10 (Transformation). Given a rule p = (L
l
←−K
r
−→R, ac), a graph
L
K
R
G
D
H
ac
l
r
f
g
m
k
n
(1)
(2)
G, and a morphism m : L →G, called
match, such that m |= ac, a direct trans-
formation G =
p,m
==⇒H from G to a graph
H is given by the pushouts (1) and (2).
A sequence of direct transformations
is called a transformation.
△
Remark 2.11. Note that for the construction of pushout (1) we have to construct the
pushout complement of m◦l, which is only possible if the so-called gluing condition
is satisﬁed (see [EEPT06]). Intuitively, gluing points are all elements in L that are
preserved in K. A dangling point is a node x in L such that m(x) in G is the source
or target of an edge with no preimage in L. In addition, identiﬁcation points are
elements in L that are mapped noninjectively by m. The gluing condition is fulﬁlled
if all dangling and identiﬁcation points are also gluing points.
△
Example 2.12. Now we introduce the rules for the mutual exclusion algorithm. Its
main aim is to ensure that at any time at most one process is using each resource.
A diﬀerent variant of this algorithm implemented by graph transformation can be
found in [EEPT06], where the lack of application conditions induces a much more
complex model including more types and additional rules for handling a single re-
source. Using application conditions we can simplify the models, forgo additional
edges representing the next executable step of the system, and extend the context
to an arbitrary number of resources. This example is based on and extends the one
presented in [EGH+14].
Initially, each process is idle and for each resource the turn variable is connected
to an arbitrary process, enabling it to use that resource. If a process P wants to use
some resource R it becomes active and points the ﬂag F1 to R. If, in addition, it
has the turn for R, it may proceed to use it, which is described by an F2-ﬂag to
the resource and a crit loop at the process. Otherwise, if the turn for R belongs to

18
2 Graph Transformation
P
R
P
R
P
R
F1
P
R
T
idle
idle
active
r1
l1
∃a1
setFlag
P
T
P
R
F1
P
T
P
R
F1
P
T
P
R
F1
P
T
P
R
F1
F1
P
T
P
R
F1
F2
r2
l2
¬ ∃a2
¬ ∃b2
∧
setTurn
P
T
F1
R
P
T
R
P
T
R
F2
crit
r3
l3
enter
P
F2
T
R
P
T
R
P
R
T
crit
active
idle
r4
l4
exit
P
R
T
P
R
P
R
F1
P
R
T
F2
P
R
T
r5
l5
¬ ∃a5
¬ ∃b5
∧
disableR
P
R
P
R
T
P
R
T
P
R
P
R
R
T
P
R
R
T
F1
F1
idle
idle
idle
idle
idle
idle
r6
l6
¬ ∃a6
∀b6
∃c6
∧
enableR
Fig. 2.3 The rules for the mutual exclusion algorithm

2.2 Graph Transformation with Application Conditions
19
P
1
R
2
P
R
P
R
F1
P
R
T
idle
idle
active
r1
l1
∃a1
setFlag
P
T
P
R
P
F2
R
T
F1
P
T
P
R
P
F2
R
T
P
1
T
P
R
2
P
F2
R
T
idle
idle
active
crit
idle
active
crit
idle
active
active
crit
c1
b1
m1
G
H1
Fig. 2.4 A rule application
another process P′, P must wait until P′ is not ﬂagging R. At this point the process
may get the turn for R and start using it. When P has ﬁnished using R, the ﬂag and
crit are removed, and the process is idle again. As an extension of this normal
behaviour, a resource may be disabled, denoted by eliminating its turn variable, if
there is no ﬂag present for it. Moreover, a resource may be enabled again if all other
resources have at least two requests waiting.
The rules setFlag, setTurn, enter, and exit in Fig. 2.3 describe the standard
behaviour of the system. With setFlag, a process becomes active and sets its F1-
ﬂag to a resource. Note that this rule has a positive application condition requiring
that the resource has a turn variable noting it as enabled. If a process has set an
F1-ﬂag to a resource whose turn variable points to another process with no ﬂag to
the resource, the turn variable can be assigned to the ﬁrst process via setTurn.
Here, the application condition forbids the process having the turn of the resource
from ﬂagging it. The rule enter describes that, if a process has the turn of and
points to a resource R with an F1-ﬂag, then this ﬂag is replaced by an F2-ﬂag, and
a loop crit is added to the process. When the process is ﬁnished, the rule exit is
executed, deleting the loop and the ﬂag, making the process idle again. Moreover,
with the rules disableR and enableR, a resource can be disabled or enabled if the
corresponding application conditions are fulﬁlled.
In the ﬁgures, the application condition true is not drawn. Application conditions
Q(a, ac), with Q ∈{ ∃, ¬ ∃, ∀}, are drawn by the morphism a marked by Qa
and combined with a drawing of ac, and conjunctions of application conditions are
marked by ∧between the morphisms.
Consider the rule setFlag with the match m1 depicted in the left of Fig. 2.4. Note
that m1 matches the process and resource of the rule setFlag to the middle process
and lower resource in G, respectively, as indicated by the small numbers, such that
m1 satisﬁes the gluing condition as well as the application condition ∃a1. This

20
2 Graph Transformation
leads to the direct transformation G =
setFlag,m1
========⇒H1 inserting an F1-ﬂag from the
now active process to the resource, as shown in Fig. 2.4. The graph H1 is obtained
from G by removing m1(L1 −K1) and adding R1 −K1.
Note that we could easily have a rule setFlag without any application condition.
In particular it is enough to include in the left-hand side of the rule the turn variable
pointing to R. In contrast to that, the application condition ∀(b6, ∃c6) of the rule
enableR cannot be removed, although it is also a positive application condition. In
particular, this condition is nested twice, which is needed to specify that every other
enabled resource has two waiting processes.
△
Graph conditions can be shifted over graph morphisms into equivalent conditions
over the codomain [HP09, EHL10]. For this shift construction, all surjective over-
lappings of the codomains of the shift and condition morphisms have to be collected.
P
C
P′
C′
ac
Shift(b, ac)
ac′
Shift(b′, ac′)
a
b
b′
a′
Here, we only explain this construction and give
an example; for the full deﬁnition see Def. 5.3.
The shift construction is recursively deﬁned.
For a graph condition ac =
∃(a, ac′) and
a shift morphism b we construct the set F =
{(a′, b′) | (a′, b′) jointly surjective, b′ injective,
b′ ◦a = a′ ◦b} and deﬁne Shift(b, ac) = ∨(a′,b′)∈F ∃(a′, Shift(b′, ac′)).
Example 2.13. Consider the application condition ∀(b6, ∃c6) of the rule enableR,
which is an application condition over the left-hand side of this rule. We want to
shift this condition over the morphism v shown at the top of Fig. 2.5. The ﬁrst
step of the construction is shown in the upper part of Fig. 2.5, it results in the in-
termediate application condition Shift(v, ∀(b6, ∃c6)) = ∀(d1, Shift(v1, ∃c6)) ∧
∀(d2, Shift(v2, ∃c6)). Since vi has to be injective and the resulting graph has to be
an overlapping of the codomains of v and b6 such that the diagram commutes, only
these two solutions are possible. In a second step, the second part of the application
condition has to be shifted over the two new morphisms v1 and v2. The result is
shown in the lower part of Fig. 2.5, leading to the resulting application condition
Shift(v, ∀(b6, ∃c6)) = ∀(d1, ∃e1 ∨∃e2) ∧∀(d2, ∃e3).
△
Similarly to the shift construction, we can also merge a graph condition over a
graph morphism. The diﬀerence lies in diﬀerent injective morphisms to be required,
with a′ being injective instead of b′. Additionally, b′ has to be a match morphism for
the merge construction, which is no restriction at all if the class of match morphisms
contains all morphisms. Again, here we only explain this construction and give an
P
C
P′
C′
(=)
ac
Merge(b, ac)
ac′
Merge(b′, ac′)
a
b
b′
a′
example; for the full deﬁnition see Def. 5.5.
The merge construction is recursively deﬁned.
For a graph condition ac =
∃(a, ac′) and a
merge morphism b we construct the set F ′ =
{(a′, b′) | (a′, b′) jointly surjective, a′ injective,
b′ match, b′ ◦a = a′ ◦b} and deﬁne Merge(b,
ac) = ∨(a′,b′)∈F ′ ∃(a′, Merge(b′, ac′)).
www.allitebooks.com

2.2 Graph Transformation with Application Conditions
21
P
R
P
T
R
P
R
R
T
P
R
R
T
P
R
T
R
T
P
R
R
T
F1
F1
P
R
R
T
F1
F1
T
P
R
R
T
F1
F1
P
R
R
T
F1
F1
idle
idle
idle
idle
idle
idle
idle
idle
idle
v
v1
v2
∀b6
∀d1
∀d2
∃c6
∃e1
∃e2
∃e3
w1
w2
w3
∧
∨
Fig. 2.5 Shift of the application condition ∀(b6, ∃c6) over a morphism
Intuitively, the constructions “merge” and “shift” diﬀer in the directions of iden-
tiﬁcations. If the merge construction yields the depicted diagram, it means that iden-
tiﬁcations along the given graph morphism b : P →P′ must subsume the identi-
ﬁcation performed via a : P →C. Further identiﬁcations along b′ may occur on
elements in C\a(P), if the class of matches permits those. In contrast to that, the
shift construction requires that the identiﬁcations along b be subsumed by those via
a, and it generally permits identiﬁcations along a′ on elements in P′\b(P).
Example 2.14. On the left of Fig. 2.6, the shift of the graph condition ac = ( ∃a :
P →C, true) along the graph morphism b : P →P′ is depicted. The shift con-
struction yields a graph condition over P′ with Shift(b, ac) = ∨i=1,...,4( ∃a′
i : P′ →
C′
i, true). The four graphs C′
i, with corresponding graph morphisms a′
i : P′ →C′
i
and b′
i : C →C′
i, are obtained by all jointly surjective pairs ensuring that the dia-
gram commutes with injective b′
i. In particular, C′
3 is the pushout object of a and b,
while for the graphs C′
1 and C′
2 the node 4 is glued together with both nodes 1 and
2 without or with additional gluing of both edges. For the graph C′
4, node 4 is glued
together with node 3.
Consider the class of match morphisms given by all morphisms. On the right
of Fig. 2.6, the merge of the graph condition ac along the graph morphism b is de-
picted. The merge construction yields a graph condition over P′ with Merge(b, ac) =
∨i=1,...,3( ∃a′′
i : P′ →C′′
i , true). The identiﬁcation of the nodes 1 and 2 along the
graph morphism b is transferred to the graph morphisms b′′
i : C →C′′
i . The three
graphs C′′
i , with corresponding graph morphisms a′
i : P′ →C′
i and b′
i : C →C′
i, are

22
2 Graph Transformation
1
2
P
1, 2
3
C
1, 2
4
P′
1, 2, 4
3
C′
1
1, 2, 4
3
C′
2
1, 2
3
4
C′
3
1, 2
3, 4
C′
4
a
a′
i
b
b′
i
Shift(b, ac)
1
2
P
1, 2
3
C
1, 2
4
P′
1, 2, 3
4
C′′
1
1, 2
3
4
C′′
2
1, 2
3, 4
C′′
3
a
a′′
i
b
b′′
i
Merge(b, ac)
Fig. 2.6 Comparison of shift and merge construction
obtained by all jointly surjective pairs making the diagram commute with injective
a′′
i . In this case, C′′
2 is the pushout object of (a, b), while for the graphs C′′
1 and C′′
3
the node 3 is glued together with nodes (1, 2) or 4, respectively.
△
Remark 2.15. In the context of model transformations based on typed attributed
graphs with inheritance in Part III, we may consider match morphisms that are in-
jective on the graph part, but may reﬁne types and may identify data values. In this
case, the merge construction yields conditions where node types can be reﬁned via
b′, but only on nodes that do not occur in P due to the requirement that a′ has to be
injective. This choice of match morphisms allows us to identify only graph nodes
via b that are also identiﬁed via a. But note that identiﬁcations on data values would
still be possible via b.
△
The satisfaction of a graph condition ac = ( ∃a : P →C, ac′) is deﬁned for arbi-
trary matches p: P →G. This general deﬁnition is important, because a restriction
to injective matches would be problematic for several application domains. For ex-
ample, if objects are attributed graphs and a condition contains variables, it should
be possible to evaluate some of these variables to the same value, which is forbidden
by injectivity.
More speciﬁcally, in the category AGraphsATG, graph conditions are often at-
tributed via a term algebra with variables TOP(X) and instance graphs are attributed
via a concrete data algebra A. In most cases, TOP(X) is not isomorphic to A and non-
injective matches p may reﬁne types along a type inheritance relation. This means

2.2 Graph Transformation with Application Conditions
23
1 : T
value = x
size = y
1 : T
value = x
size = y
2 : T
value = x
1 : T
value = 5
size = 5
2 : T
value = 5
size = 8
P
C
AG
a
p
∄inj. q : q ◦a = m
Fig. 2.7 Nonsatisfaction of a condition for a noninjective match
that the required injective graph morphism q : C →G according to Def. 2.8 does
not exist and a graph condition of the form ac = ( ∃a : P →C, ac′) is never satisﬁed
if TOP(X) is not isomorphic to A.
Example 2.16. Consider the graph condition ac = ( ∃a : P →C, true) shown in the
top row of Fig. 2.7. It speciﬁes that for any node of type T (graph P) there has to be
a second node of the same type with the same value for the attribute value (graph
C). The graphs of the condition are attributed via the term algebra TOP(X) with
variables x and y. In contrast to that, the instance graph AG = (G, D) is attributed
via a data algebra D using integers for the values of the attributes value and size.
For the node 1 of type T in AG, both attributes are assigned the same value, 5.
Therefore, the variables x and y in C have to be evaluated to 5 for any morphism
q : C →AG. This means that q is not injective, and therefore the graph condition
ac is not satisﬁed by AG.
△
In order to overcome this general problem for the satisﬁability of graph condi-
tions for noninjective matches, we need to derive sub-conditions that handle each of
the speciﬁc cases of possible noninjective matches p : P →G. Instead of specifying
these sub-conditions explicitly, we will provide the general concept of AC schemata,
where we specify a base condition and provide a general construction from which
the induced concrete conditions can be derived. Such an AC schema consists of the
disjunction of all merges of an application condition along surjective morphisms
starting from its domain.
Deﬁnition 2.17 (AC schema).
Given a condition ac over P and the set EP =
{e | e surjective, dom(e) = P} of all surjective morphisms with domain P, the AC
schema ac over P is given by ac = W
f∈EP ∃(f, Merge(f, ac)).
△
P
P′
G
ac
Merge(e, ac)
p
e
m
The satisfaction of an AC schema by a graph
morphism p only depends on the satisfaction of
one component of the corresponding epi–mono
factorisation m ◦e = p, i.e., p |= ac if and only
if m |= Merge(e, ac) (see Fact 5.8). Although Def. 2.17 speciﬁes that an AC schema

24
2 Graph Transformation
1 : T
value = x
size = y
1 : T
value = x
size = y
2 : T
value = x
1 : T
value = 5
size = 5
1 : T
value = 5
size = 5
2 : T
value = 5
1 : T
value = 5
size = 5
2 : T
value = 5
size = 8
P
C
P′
C′
AG
a
ae
m
e
e′
p
∃inj. q : q ◦ae = p
Fig. 2.8 Satisfaction of an AC schema for a noninjective match
induces a possibly inﬁnite disjunction, this means that only one of these elements
has to be constructed for checking satisfaction of the condition for a concrete match.
The epi–mono factorisation of this match yields the epimorphism that is used for the
merge construction. Intuitively, AC schemata are a way to specify a graph condition
that allows for further identiﬁcations by the match, because these identiﬁcations are
transferred recursively to the subcomponents of the graph condition. Moreover, if p
is injective, then the satisfaction of an AC schema coincides with classical satisfac-
tion, because the factorisation is trivially p = p ◦id.
Example 2.18. From the graph condition ac = ( ∃a : P →C, true) in Fig. 2.7 we
construct the AC schema ac = W
f∈EP ∃(f, ∃(af , true)), where all f ∈EP are
surjective and represent diﬀerent instantiations of the variables x and y. Moreover,
the graph condition ∃(af , true) represents the corresponding instantiation for the
additional node, 2.
To check if the graph morphism p : P →AG satisﬁes ac, we construct the epi–
mono factorisation p = m ◦e in Fig. 2.8, where the morphism e ∈EP is used for
the merge construction. The graphs P′ and C′ share the same algebra with AG. The
graph constraint ac′ =
∃(ae, true) represents an instance of the AC schema ac
that is used for checking satisﬁability. The identiﬁcation of the variables x and y is
transferred to this instance, and we ﬁnd an injective graph morphism q : C′ →AG
such that q ◦ae = m. This means that the AC schema ac is satisﬁed by p, while the
underlying graph condition ac is not satisﬁed by p, as shown in Ex. 2.16.
△
Similarly to an application condition over the left-hand side L, which is a pre-
application condition, it is also possible to deﬁne post-application conditions over
the right-hand side R of a rule. These application conditions over R can be translated
to equivalent application conditions over L (and vice versa) [HP09] using a shift
construction. Therefore, we can restrict our rules to application conditions over L.

2.2 Graph Transformation with Application Conditions
25
P
R
P
R
T
P
R
P
R
R
T
P
R
R
T
F1
F1
P
R
R
T
P
R
R
T
F1
F1
P
R
R
T
T
P
R
R
T
F1
F1
T
idle
idle
idle
idle
idle
idle
idle
idle
idle
r6
l6
∀b6
∃c6
∀b∗
6
∃c∗
6
enableR
Fig. 2.9 Shift of the application condition from the left- to the right-hand side
As for the shift over morphisms, here we only motivate the construction and give an
example; for the complete deﬁnition see Def. 5.15.
L
K
R
Y
Z
X
acR
ac′
L(p∗, ac′
R)
L(p, acR)
l
r
l∗
r∗
b
c
a
(2)
(1)
The shift of a graph
condition acR =
∃(a,
ac′
R) over a rule p is re-
cursively deﬁned by L(p,
acR) =
∃(b, L(p∗, ac′
R))
if a ◦r has a pushout complement (1) and p∗= (Y
l∗
←−Z
r∗
−→X) is the derived rule
by constructing pushout (2), or L(p, acR) = false otherwise,
Example 2.19. Suppose we want to translate the application condition ∀(b6, ∃c6)
of the rule enableR to the right-hand side. Basically, this means applying the rule
to the ﬁrst graph of the application condition, leading to a span which is applied
as a rule to the second graph. The result is shown in Fig. 2.9, i.e., the translated
application condition is ∀(b∗
6, ∃c∗
6).
△
A set of rules constitutes a graph transformation system, and, combined with a
start graph, a graph grammar. The language of such a grammar contains all graphs
derivable from the start graph.
Deﬁnition 2.20 (Graph transformation system and grammar). A graph trans-
formation system GS = (P) consists of a set of rules P.
A graph grammar GG = (GS, S ) consists of a graph transformation system GS
and a start graph S .
The language L of a graph grammar GG is deﬁned by
L = {G | ∃transformation S =
∗⇒G via P}.
△

26
2 Graph Transformation
2.3 Results for Graph Transformations
In [EEPT06], important results for transformation systems without application con-
ditions were proven. Here, we motivate and state the results and as far as necessary
the underlying concepts for the corresponding theorems with application conditions,
based on graphs. For the full deﬁnitions, results, and proofs in the more general set-
ting of M-adhesive categories see Chap. 5.
2.3.1 Local Church–Rosser and Parallelism Theorem
This ﬁrst result is concerned with parallel and sequential independence of direct
transformations. We study under what conditions two direct transformations applied
to the same graph can be applied in arbitrary order leading to the same result. This
leads to the Local Church–Rosser Theorem. Moreover, the corresponding rules can
be applied in parallel in this case, leading to the Parallelism Theorem.
First, we deﬁne the notion of parallel and sequential independence. Two direct
transformations G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2 are parallel independent if p1 does
not delete anything p2 uses and does not create or delete anything to invalidate ac2,
and vice versa.
Deﬁnition 2.21 (Parallel independence). Two direct transformations G =
p1,m1
===⇒H1
and G =
p2,m2
===⇒H2 are parallel independent if there are morphisms d12 : L1 →D2 and
d21 : L2 →D1 such that f2◦d12 = m1, f1◦d21 = m2, g2◦d12 |= ac1, and g1◦d21 |= ac2.
L1
K1
R1
L2
K2
R2
G
D1
H1
D2
H2
ac1
ac2
l1
r1
f1
g1
m1
k1
n1
l2
r2
f2
g2
m2
k2
n2
d12
d21
△
Analogously, two direct transformations G =
p1,m1
===⇒H1 =
p2,m2
===⇒G′ are sequentially
independent if p1 does not create something p2 uses, p2 does not delete something
p1 uses or creates, p1 does not delete or create anything, thereby initially validating
ac2, and p2 does not delete or create something invalidating ac1.
Deﬁnition 2.22 (Sequential independence). Two direct transformations G =
p1,m1
===⇒
H1 =
p2,m2
===⇒G′ are sequentially independent if there are morphisms d12 : R1 →D2
and d21 : L2 →D1 such that f2 ◦d12 = n1, g1 ◦d21 = m2, f1 ◦d21 |= ac2, and
g2 ◦d12 |= L((R1
r1
←−K1
l1
−→L1), ac1).

2.3 Results for Graph Transformations
27
R1
K1
L1
L2
K2
R2
H1
D1
G
D2
G′
ac1
ac2
r1
l1
g1
f1
n1
k1
m1
l2
r2
f2
g2
m2
k2
n2
d12
d21
△
Example 2.23. The pair H1 ⇐
setFlag,m1
========= G =
exit,m′
=====⇒G′ of direct transformations in
Fig. 2.10 is parallel independent. The left rule application is the one already con-
sidered in Fig. 2.4, while m′ matches the process of the rule exit to the uppermost
process in G. The morphisms d12 and d21 exist such that b1 ◦d21 = m′, b2 ◦d12 = m1,
and c2 ◦d12 |= ∃a1.
The sequence H1 =
setTurn,m2
========⇒H2 =
setFlag,m3
========⇒H3 of direct transformations in
Fig. 2.11 is sequentially dependent. Note that m2 matches the processes of the
rule setTurn to the lower processes in H1, but in reverse order, while m3 maps
the process of the rule setFlag to the lowest process in H2. The morphisms d12
and d21 exist such that c1 ◦d21 = m3, b2 ◦d12 = m∗
2, and b1 ◦d21 |= ∃a1, but
c2 ◦d12 ̸|= R(setTurn, ¬ ∃a2 ∧¬ ∃b2). The transformations are sequentially de-
pendent, since the rule setFlag adds a second ﬂag, which is forbidden by the appli-
cation condition ¬ ∃a2 of the rule setTurn. Note that the transformations without
application conditions would be sequentially independent.
△
The idea of a parallel rule is, in case of parallel independence, to apply both rules
in parallel. For two rules p1 and p2, the parallel rule p1 + p2 is constructed as the
P
1
R
2
P
R
P
R
F1
P
R
T
idle
idle
active
l2
r2
∃a1
setFlag
P
F2
T
R
P
T
R
P
R
T
crit
active
idle
r4
l4
exit
P
T
P
R
P
F2
R
T
F1
P
T
P
R
P
F2
R
T
P
1
T
P
R
2
P
F2
R
T
idle
idle
active
crit
idle
active
crit
idle
active
active
crit
b1
c1
m1
G
H1
G′
P
T
P
R
P
R
T
P
T
P
R
P
R
T
idle
idle
idle
idle
idle
m′
c2
b2
d12
d21
Fig. 2.10 Parallel independent transformations

28
2 Graph Transformation
P
2
T
P
1
R
F1
P
T
P
R
F1
P
T
P
R
F1
P
T
P
R
F1
F1
P
T
P
R
F1
F2
r2
l2
¬ ∃a2
¬ ∃b2
∧
setTurn
P
1
R
P
R
P
R
F1
P
R
T
idle
idle
active
r1
l1
∃a1
setFlag
P
2
T
P
1
R
P
F2
R
T
F1
P
T
P
R
P
F2
R
T
F1
P
T
P
1
R
P
F2
R
T
F1
idle
active
active
crit
idle
active
active
crit
idle
active
active
crit
c1
b1
m2
m∗
2
H2
H1
H3
P
T
P
R
P
F2
R
T
F1
P
T
P
R
P
F2
R
T
F1
F1
active
active
crit
active
active
active
crit
c2
b2
m3
d12
d21
Fig. 2.11 Sequentially dependent transformations
disjoint union of all three components of the rules, denoted by +. For the application
conditions we have to make sure that both single rules can be applied in any order.
Deﬁnition 2.24 (Parallel rule). Given rules p1 = (L1
l1
←−K1
r1
−→R1, ac1) and
p2 = (L2
l2
←−K2
r2
−→R2, ac2), the parallel rule p1 + p2 = (L1 + L2
l1+l2
←−K1 + K2
r1+r2
−→
L1
K1
R1
L2
K2
R2
L1 + L2
K1 + K2
R1 + R2
ac1
ac
ac2
l1+l2
r1+r2
l1
r1
l2
r2
iK1
iK2
iL1
iL2
iR1
iR2
R1 + R2, ac) is deﬁned by
the componentwise disjoint
unions
of
the
left-hand
sides, gluings, and right-
hand sides including the
morphisms,
and
ac
=
Shift(iL1, ac1) ∧L(p1 + p2,
Shift(iR1, R(p1, ac1)))
∧
Shift(iL2, ac2) ∧L(p1 + p2, Shift(iR2, R(p2, ac2))).
△
Example 2.25. The parallel rule setFlag + exit is shown in the upper row of
Fig. 2.12, where we have only depicted those application conditions which are rea-
sonable in our system, while we have ignored illegal ones like turn variables point-
ing to multiple resources or processes that are simultaneously idle and active. The
application G =
setFlag+exit,m1+m′
===============⇒H′ of this parallel rule is shown in Fig. 2.12 and
combines the eﬀects of both rules to G leading to the graph H′, where both the upper
process became idle and the middle process became active.
△

2.3 Results for Graph Transformations
29
setFlag + exit
T
P
R
T
P
R
T
P
R
F2
T
P
R
F2
T
P
R
F2
active
crit
idle
active
crit
active
crit
∃a
∃b
∨
P
1
R
P
R
F1
P
R
P
R
T
P
idle
idle
idle
active
r
l
P
1
T
P
R
P
F2
R
T
P
T
P
R
P
R
T
P
T
P
R
P
R
T
F1
idle
idle
active
crit
idle
idle
active
idle
m1 + m′
c′
b′
H′
G
Fig. 2.12 Parallel rule and transformation
With these notions of independence and parallel rule, we are able to formulate
the Local Church–Rosser and Parallelism Theorem. Note that this theorem is the
instantiation of Theorem 5.26 to graphs.
Theorem 2.26 (Local Church–Rosser and Parallelism Theorem).
Given two
parallel independent direct transformations G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2, there
is a graph G′ together with direct transformations H1 =
p2,m′
2
===⇒G′ and H2 =
p1,m′
1
===⇒G′
such that G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒G′ and G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒G′ are sequentially
independent.
H1
H2
G
G′
p1,m1
p1+p2,m
p2,m2
p2,m′
2
p1,m′
1
Given two sequentially independent direct
transformations G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒G′, there
is a graph H2 together with direct transfor-
mations G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒G′ such that
G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2 are parallel in-
dependent.
In any case of independence, there is a parallel transformation G =
p1+p2,m
=====⇒G′
and, vice versa, a direct transformation G =
p1+p2,m
=====⇒G′ via the parallel rule p1 + p2
can be sequentialised both ways.
△

30
2 Graph Transformation
2.3.2 Concurrency Theorem
In contrast to the Local Church–Rosser and Parallelism Theorem, the Concurrency
Theorem is concerned with the execution of sequentially dependent transformations.
In this case, we cannot commute subsequent direct transformations, as done for
independent transformations, nor are we able to apply the corresponding parallel
rule. Nevertheless, it is possible to apply both transformations concurrently using
a so-called E-concurrent rule and shifting the application conditions of the single
rules to an equivalent concurrent application condition.
Given an arbitrary sequence G =
p1,m1
===⇒H =
p2,m2
===⇒G′ of direct transformations it
is possible to construct an E-concurrent rule p1 ∗E p2. The graph E is an overlap
of the right-hand side of the ﬁrst rule and the left-hand side of the second rule. The
construction of the concurrent application condition is again based on the two shift
constructions.
Deﬁnition 2.27 (Concurrent rule). Given rules p1 = (L1
l1
←−K1
r1
−→R1, ac1)
and p2 = (L2
l2
←−K2
r2
−→R2, ac2), a graph E with jointly surjective morphisms
e1 : R1 →E and e2 : L2 →E is an E-dependency relation of p1 and p2 if the
pushout complements (1) of e1 ◦r1 and (2) of e2 ◦l2 exist.
R1
K1
L1
L2
K2
R2
E
C1
L
C2
R
K
ac1
ac2
ac
r1
l1
t1
s1
e1
v1
u1
l2
r2
s2
t2
e2
v2
u2
w1
w2
(1)
(2)
(3)
(4)
(5)
Given an E-dependency relation (E, e1, e2) of p1 and p2, the E-concurrent rule
p1∗E p2 = (L
s1◦w1
←−K
t2◦w2
−→R, ac) is constructed by pushouts (1), (2), (3), (4), and pull-
back (5), with ac = Shift(u1, ac1) ∧L(p∗, Shift(e2, ac2)) for p∗= (L
s1
←−C1
t1
−→E).
R1
K1
L1
L2
K2
R2
E
C1
C2
G
D1
H
D2
G′
ac1
ac2
r1
l1
t1
e1
v1
l2
r2
s2
e2
v2
m1
n2
k1
k2
c2
c1
f1
g1
f2
g2
h
n1
m2
(6)
(7)

2.3 Results for Graph Transformations
31
A sequence G =
p1,m1
===⇒H =
p2,m2
===⇒G′ is called E-related if there exist h : E →H,
c1 : C1 →D1, and c2 : C2 →D2 such that h is injective, h ◦e1 = n1, h ◦e2 = m2,
c1 ◦v1 = k1, c2 ◦v2 = k2, and (6) and (7) are pushouts
△
Example 2.28. In Fig. 2.13, the E-concurrent rule construction is depicted, leading
to the E-related sequence H1 =
setTurn,m2
========⇒H2 =
setFlag,m3
========⇒H3 of the direct transforma-
tions already considered in Fig. 2.11. Note that e1 matches the processes of setTurn
to the two processes in the same order and e2 matches the process of setFlag to the
upper process. Moreover, acL = Shift(u1, ac2) ∧L(p∗, Shift(e2, ac1)) is not depicted
explicitly. Leaving out invalid models like idle processes with ﬂags, it evaluates to
true.
△
For a sequence G =
p1,m1
===⇒H =
p2,m2
===⇒G′ of direct transformations we can con-
struct an E-dependency relation such that the sequence is E-related. Then the E-
concurrent rule p1 ∗E p2 allows us to construct a direct transformation G =
p1∗E p2
=====⇒G′
via p1 ∗E p2. Vice versa, each direct transformation G =
p1∗E p2
=====⇒G′ via the E-
concurrent rule p1∗E p2 can be sequentialised, leading to an E-related transformation
sequence G =
p1,m1
===⇒H =
p2,m2
===⇒G′ of direct transformations via p1 and p2. Note that
this theorem is the instantiation of Theorem 5.30 to graphs.
P
T
P
R
F1
P
T
P
R
F1
P
2
T
P
1
R
F1
P
T
P
R
F1
F1
P
T
P
R
F1
F2
r2
l2
¬ ∃a2
¬ ∃b2
∧
setTurn
P
1
R
P
R
P
R
F1
P
R
T
idle
idle
active
r1
l1
∃a1
setFlag
P
P
R
T
F1
P
P
R
T
F1
P
2
P
1
T
F1
R
u1
e1
idle
idle
idle
L
R
P
P
F1
R
T
P
P
R
F1
T
F1
e2
active
P
P
R
T
F1
l
r
K
Fig. 2.13 E-concurrent rule construction

32
2 Graph Transformation
Theorem 2.29 (Concurrency Theorem). For rules p1 and p2 and an E-concurrent
rule p1 ∗E p2 we have:
H
G
G′
p1∗E p2,m
p1,m1
p2,m2
• Given an E-related transformation sequence
G =
p1,m1
===⇒H =
p2,m2
===⇒G′, there is a synthesis
construction leading to a direct transforma-
tion G =
p1∗E p2,m
======⇒G′ via the E-concurrent rule
p1 ∗E p2.
• Given a direct transformation G =
p1∗E p2,m
======⇒G′, there is an analysis construction
leading to an E-related transformation sequence G =
p1,m1
===⇒H =
p2,m2
===⇒G′.
• The synthesis and analysis constructions are inverse to each other up to isomor-
phism.
△
2.3.3 Amalgamation
With amalgamation, we synchronise a number of rule applications. The idea is to
model a certain number of actions which are similar for each step with a subrule,
while corresponding complement rules describe the eﬀects of each rule application
outside this subrule.
Deﬁnition 2.30 (Subrule and complement rule).
A rule p0 is a subrule of a
rule p1 if there are injective morphisms s1,L : L0 →L1, s1,K : K0 →K1, and
s1,R : R0 →R1 such that diagrams (1) and (2) are pullbacks, the pushout com-
plement (1′) of K0 →L0 →L1 exists, and the application conditions ac0 and
ac1 are compatible, i.e., there is some application condition ac′
1 over L10 such that
ac1 ≡Shift(s1,L, ac0) ∧L(p∗
1, Shift(v1, ac′
1)), where p∗
1 = (L1
u1
←−L10
v1
−→E1) and
(3) is a pushout.
L0
K0
R0
L1
K1
R1
ac0
ac1
L0
K0
L1
L10
R0
E1
ac′
1
l0
r0
l1
r1
s1,L
s1,K
s1,R
l0
w1
s1,L
u1
r0
e11
v1
(1)
(2)
(1′)
(3)
A rule p1 is a complement rule of p1 with respect to p0 if p1 = p0 ∗E1 p1 for some
E1-dependency relation.
△
Example 2.31. We want to model some additional behaviour of the system. A pro-
cess with an F1-ﬂag to this resource can be redirected to a diﬀerent resource (rule
p7), and a resource may be disabled and marked for update if the process having its
turn is not active (rule p8). Note that we also have to adapt the type graph, adding
the update-loop for a resource.

2.3 Results for Graph Transformations
33
P
T
R
P
R
P
R
P
2
R
3
R
4
F1
P
1
T
P
P
R
F1
R
P
P
R
F1
R
P
T
R
P
R
P
R
update
r7
l7
r0
l0
r8
l8
s7,L
s8,L
P
R
3,4
F1
P
T
P
R
R
F1
P
T
R
R
F1
P
1,2
T
P
R
T
P
R
T
active
active
¬ ∃a7
¬ ∃b7
¬ ∃c7
∧
∧
¬ ∃a8
active
¬ ∃a0
active
Fig. 2.14 The subrule p0 of the rules p7 and p8
P
P
R
1
R
2
F1
P
P
R
F1
R
P
P
R
F1
R
r7
l7
P
P
R
1,2
F1
¬ ∃c7
P
R
P
R
P
R
update
r8
l8
Fig. 2.15 The complement rules p7 and p8
Rule p7 is depicted at the top of Fig. 2.14 and shows the redirection of the F1-ﬂag
of the process. Rule p8 is shown at the bottom of this ﬁgure and adds the update-
marker. In the middle row of Fig. 2.14, the subrule p0 is shown which disables the
resource. This rule is actually a valid subrule of p7 and p8, because the given squares
are pullbacks, in both cases the pushout complements exist, and for the application
conditions we have that aci ≡Shift(si,L, ac0) ∧L(p∗
i , Shift(vi, ac′
i)) for i = 7, 8.
The complement rules p7 and p8 are given in Fig. 2.15. Note, that the application
condition ¬ ∃c7 is translated into an application condition ¬ ∃c7, while we do not
need an application condition for p8.
△
The construction of an amalgamated rule generalises the one of a parallel rule,
where all rules are glued together along the subrule. Here, we only give the construc-

34
2 Graph Transformation
P
2
R
3
R
4
F1
P
1
T
P
P
R
F1
R
P
P
R
F1
R
update
r
l
P
R
3,4
F1
P
T
P
R
R
F1
P
T
R
R
F1
P
1,2
T
active
active
¬ ∃˜a∧
¬ ∃˜b
¬ ∃˜c
∧
P
2
T
P
1
R
3
P
R
4
T
F1
idle
active
idle
P
T
P
F1
P
R
R
P
T
P
R
F1
P
R
m
c
b
idle
idle
idle
idle
active
active
update
H′
Fig. 2.16 The amalgamated rule ˜p of p7 and p8
tion for two rules, but in general an arbitrary number of rules can be amalgamated
iteratively (see Def. 6.9).
Deﬁnition 2.32 (Amalgamated rule). Given a common subrule p0 of rules p1 and
ac0
ac2
ac1
˜ac
L0
K0
R0
L1
K1
R1
L2
K2
R2
˜L
˜K
˜R
l0
r0
l1
r1
l2
r2
s1,L
s1,K
s1,R
s2,L
s2,K
s2,R
˜l
˜r
t1,L
t1,K
t1,R
t2,L
t2,K
t2,R
p2, the amalgamated rule ˜p =
p1 ⊕p0 p2 is given by ˜p = ( ˜L
˜l
←−
˜K
˜r
−→˜R, ˜ac), where ˜L, ˜K, and ˜R
are the pushouts of the left-hand
sides,
gluings,
and
right-hand
sides, respectively, ˜l and ˜r are the
uniquely existing morphisms, and
˜ac = Shift(t1,L, ac1) ∧Shift(t2,L,
ac2).
△
Example 2.33. The amalgamated rule ˜p = p7 ⊕p0 p8 is shown in the upper rows of
Fig. 2.16. It combines the eﬀects of p7 and p8, where both rules disable the same
resource. The application of this amalgamated rule to the graph H′ from Fig. 2.12 is
shown in Fig. 2.16. Note that m maps the left-hand side of the rule to the lower part
of H′, but in reverse order. Simultaneously, the resource is disabled, its update-ﬂag
is set, and the F1-ﬂag of the process is redirected.
△

2.3 Results for Graph Transformations
35
Two direct transformations of the same graph are amalgamable if both matches
agree on the subrule and are independent outside. In this case, the amalgamation
theorem states that we can apply the amalgamated rule to realise the eﬀects of both
rules in one step. Note that this theorem is the instantiation of Theorem 6.17 to
graphs for two amalgamable rules.
Theorem 2.34 (Amalgamation Theorem). For rules p1 and p2 with amalgamated
rule ˜p = p1 ⊕p0 p2, consider the complement rules qi of ˜p w. r. t. pi, i.e., ˜p = p1 ∗E′
1
q1 = p2 ∗E′
2 q2. Then we have:
H
Gi
G
˜p, ˜m
pi,mi
qi
• Given amalgamable direct transformations G =
p1,m1
===⇒
G1 and G =
p2,m2
===⇒G2, there is an amalgamated trans-
formation G =
˜p, ˜m
==⇒H and direct transformations
G1 =
q1=⇒H and G2 =
q2=⇒H such that G =
p1,m1
===⇒G1 =
q1=⇒
H and G =
p2,m2
===⇒G2 =
q2=⇒H are decompositions of G =
˜p, ˜m
==⇒H.
• Given an amalgamated direct transformation G =
˜p, ˜m
==⇒H, there are transforma-
tions G =
p1,m1
===⇒G1 =
q1=⇒H and G =
p2,m2
===⇒G2 =
q2=⇒H such that the direct transfor-
mations G =
p1,m1
===⇒G1 and G =
p2,m2
===⇒G2 are amalgamable.
• The synthesis and analysis constructions are inverse to each other up to isomor-
phism.
△
2.3.4 Embedding and Extension Theorem
For the Embedding and Extension Theorem, we analyse under what conditions a
transformation t : G0 =
∗⇒Gn can be extended to a transformation t′ : G′
0 =
∗⇒G′
n
via an extension morphism k0 : G0 →G′
0 (see Fig. 2.17). The idea is to obtain an
extension diagram (1), which is deﬁned by pushouts (2i)–(5i) for all i = 1, . . . , n,
where the same rules p1, . . . , pn are applied in the same order in t and t′.
It is important to note that this is not always possible, because there may be some
elements in G′
0 invalidating an application condition or forbidding the deletion of
something which can still be deleted in G0. But we are able to give a necessary and
suﬃcient consistency condition to allow such an extension. This result is important
for all kinds of applications where we have a large graph G′
0, but only small subparts
of G′
0 have to be changed by the rules p1, . . . , pn. In this case, we choose a suitable
small subgraph G0 of G′
0 and construct a transformation t : G0 =
∗⇒Gn via p1, . . . , pn
ﬁrst. Then we compute the derived span of this transformation, which we extend in a
second step via the inclusion k0 : G0 →G′
0 to a transformation t′ : G′
0 =
∗⇒G′
n via the
same rules p1, . . . , pn. Since we only have to compute the small transformation from
G0 to Gn and the extension of Gn to G′
n, this makes the computation of G′
0 ⇒G′
n
more eﬃcient.
The derived span connects the ﬁrst and the last graph of a transformation and
describes in one step, similarly to a rule, the changes between them. Over the derived

36
2 Graph Transformation
G0
Gn
G′
0
G′
n
∗
∗
t
t′
k0
kn
(1)
Li
Ki
Ri
G′
i−1
D′
i
G′
i
Gi−1
Di
Gi
aci
fi
gi
li
ri
f ′
i
g′
i
ji
di
mi
ki−1
ni
ki
(2i)
(3i)
(4i)
(5i)
Fig. 2.17 Embedding and extension: sequence (left) and intermediate step (right)
span we can also deﬁne a derived application condition which becomes useful later
for the Local Conﬂuence Theorem.
Deﬁnition 2.35 (Derived span and application condition). Given a transforma-
tion t : G0 =
∗⇒Gn via rules p1, . . . , pn, the derived span der(t) is inductively deﬁned
by
der(t) =

G0
f1
←−D1
g1
−→G1 for t : G0 =
p1,m1
===⇒G1
G0
d′
0◦d
←−D
gn◦dn
−→Gn for t : G0 =
∗⇒Gn−1 =
pn,mn
===⇒Gn with
der(G0 =
∗⇒Gn−1) = (G0
d′
0
←−D′ d′
n−1
−→Gn−1)
and pullback (PB)
Gn−1
Dn
Gn
D′
G0
D
d′
0
d′
n−1
fn
gn
d
dn
(PB)
Moreover, the derived application condition ac(t) is deﬁned by
ac(t) =

Shift(m1, ac1)
for t : G0 =
p1,m1
===⇒G1
ac(G0 =
∗⇒Gn−1)
for t : G0 =
∗⇒Gn−1 =
pn,mn
===⇒Gn
∧L(p∗
n, Shift(mn, acn))
with p∗
n = der(G0 =
∗⇒Gn−1)
△
Example 2.36. Consider the transformation G =
setFlag
======⇒H1 =
setTurn
======⇒H2 =
setFlag
======⇒
H3 from Figs. 2.4 and 2.11. The derived span of this transformation and its derived
application condition are shown in Fig. 2.18 and combine all changes applied in
the single transformation steps. Note that the derived application condition actually
forbids matching both resources or idle processes noninjectively.
△
For the consistency condition, we need the concept of initial pushouts. This is a
categorical formalisation of boundary and context leading to the smallest pushout
over a morphism. Intuitively, the boundary contains all elements of the domain new

2.3 Results for Graph Transformations
37
P
T
P
R
P
F2
R
T
P
T
P
R
P
F2
R
T
idle
idle
active
crit
active
crit
H3
G
P
T
P
R
P
F2
R
T
F1
F1
active
active
active
crit
P
T
P
R
P
F2
R
T
idle
idle
active
crit
∃a
Fig. 2.18 The derived span of G =
∗⇒H3
elements in the codomain are connected to. All these new elements and their con-
nections are then collected in the context.
For k0 to be boundary-consistent, we have to ﬁnd a morphism from the boundary
to the derived span, which means that no element in the boundary is deleted by
the transformation. Moreover, we need AC consistency; therefore k0 has to fulﬁll a
summarised set of application conditions collected from all rules and shifted to G0.
We say that k0 is consistent with respect to t if it is both boundary-consistent and
AC-consistent. Consistency of k0 is both necessary and suﬃcient for embedding a
transformation t : G0 =
∗⇒Gn via k0. Note that this theorem is the instantiation of
Theorem 5.34 to graphs.
Theorem 2.37 (Embedding and Extension Theorem). Given a transformation t :
G0 =
∗⇒Gn and a morphism k0 : G0 →G′
0 which is consistent with respect to t, there
B
G0
D
Gn
C
G′
0
G′
n
kn
b∗
b
d∗
0
d∗
n
c
a
k0
∗
∗
(6)
(1)
exists an extension diagram (1)
over t and k0.
Vice versa, given a transfor-
mation t : G0 =
∗⇒Gn with an ex-
tension diagram (1) and an initial
pushout (6) over k0 : G0 →G′
0,
as motivated above, we have that:
1. k0 is consistent with respect to t : G0 =
∗⇒Gn.
2. There is a rule p∗= (der(t), ac(t)) leading to a direct transformation G′
0 =
p∗
=⇒G′
n.
3. G′
n is the pushout of the context C and Gn along the boundary B, i.e., G′
n =
Gn +B C.
△
Example 2.38. We embed the graph G0 = G from Fig. 2.4 into a larger context
graph G′
0, where an additional process has an F1-ﬂag pointing to the lower resource.
The boundary B and context graph C are shown in the left of Fig. 2.19, where the
boundary only contains the lower resource to which the new process is connected.
Since this resource is not deleted, the extension morphism k0 is boundary-consistent.
Moreover, it is AC-consistent, because the derived application condition is fulﬁlled.

38
2 Graph Transformation
P
T
P
R
P
F2
R
T
P
T
P
R
P
F2
R
T
idle
idle
active
crit
active
crit
k0
H3
G
P
T
P
R
P
F2
R
T
F1
F1
active
active
active
crit
R
B
P
T
P
R
P
F2
R
T
P
F1
P
T
P
R
P
F2
R
T
P
F1
idle
idle
active
crit
active
active
crit
active
G′
3
G′
0
P
T
P
R
P
F2
R
T
F1
F1
P
F1
active
active
active
active
crit
R
P
F1
active
C
Fig. 2.19 The embedding and extension of G into G′
0
Therefore, we have consistency and can construct the transformation G′
0 =⇒∗G′
3 as
shown in Fig. 2.19, where G′
3 is the pushout of H3 and C along B.
△
2.3.5 Critical Pairs and Local Conﬂuence Theorem
A transformation system is called conﬂuent if, for all transformations G =
∗⇒H1
and G =
∗⇒H2, there is an object X together with transformations H1 =
∗⇒X and
H2 =
∗⇒X. Local conﬂuence means that this property holds for all pairs of direct
transformations G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2.
H1
H2
G
X
∗
∗
∗∗
H1
H2
G
X
p1,m1
p2,m2
∗∗
Conﬂuence is an impor-
tant property of a transfor-
mation system, because, in
spite of local nondetermin-
ism concerning the appli-
cation of a rule, we have
global determinism for conﬂuent transformation systems. Global determinism
means that, for each pair of terminating transformations G =
∗⇒H and G =
∗⇒H′

2.3 Results for Graph Transformations
39
with the same source object, the target objects H and H′ are equal or isomorphic. A
transformation G =
∗⇒H is called terminating if no rule is applicable to H anymore.
This means that each transformation sequence terminates after a ﬁnite number of
steps.
The Local Church–Rosser Theorem shows that, for two parallel independent di-
rect transformations G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2, there is a graph G′ together
with direct transformations H1 =
p2,m′
2
===⇒G′ and H2 =
p1,m′
1
===⇒G′. This means that we can
apply the rules p1 and p2 with given matches in an arbitrary order. If each pair of
rules is parallel independent for all possible matches, then it can be shown that the
corresponding transformation system is conﬂuent.
In the following, we discuss local conﬂuence for the general case in which
G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2 are not necessarily parallel independent. According
to a general result for rewriting systems, it is suﬃcient to consider local conﬂuence,
provided that the transformation system is terminating [Plu95].
The main idea is to study critical pairs. For a pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 of di-
rect transformations to constitute a critical pair, the matches o1 and o2 are allowed
to violate the application conditions, while they induce new ones that have to be
respected by a parallel dependent extension of the critical pair. These induced ap-
plication conditions make sure that the extension respects the application conditions
of the given rules and that there is indeed a conﬂict.
Deﬁnition 2.39 (Critical pair). Given rules p1 = (L1
l1
←−K1
r1
−→R1, ac1) and
p2 = (L2
l2
←−K2
r2
−→R2, ac2), a pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 of direct transformations
without application conditions is a critical pair (for transformations with applica-
tion conditions) if (o1, o2) are jointly surjective and there exists an extension of the
pair via an injective morphism m : K →G such that m |= acK = acE
K ∧acC
K, with
L1
K1
R1
L2
K2
R2
K
N1
P1
N2
P2
ac1
ac2
acK
l1
r1
v1
w1
o1
u1
t1
l2
r2
v2
w2
o2
u2
t2
z2
z1
• extension application condition: acE
K = Shift(o1, ac1) ∧Shift(o2, ac2) and
• conﬂict inducing application condition: acC
K = ¬(acz1 ∧acz2), with
if ∃z1 : v1 ◦z1 = o2 then acz1 = L(p∗
1, Shift(w1 ◦z1, ac2)) else acz1 = false,
with p∗
1 = (K
v1
←−N1
w1
−→P1)
if ∃z2 : v2 ◦z2 = o1 then acz2 = L(p∗
2, Shift(w2 ◦z2, ac1)) else acz2 = false,
with p∗
2 = (K
v2
←−N2
w2
−→P2)
△

40
2 Graph Transformation
T
P
R
F1
T
P
R
F2
idle
idle
¬ ∃a21
¬ ∃b21
∧
P
T
R
F1
P
T
R
P
T
R
active
idle
v1
w1
K
P1
P2
P
R
P
R
idle
idle
w2
v2
P
T
P
R
F1
T
P
R
F1
P
T
P
R
F2
T
P
R
F2
idle
idle
idle
idle
¬ ∃a′
21
¬ ∃a′
22
¬ ∃b′
21
¬ ∃b′
22
∧
∧
∧
P
T
P
R
F1
P
T
P
R
P
T
P
R
active
idle
v′
1
w′
1
K′
P′
1
P′
2
P
P
R
P
P
R
idle
idle
w′
2
v′
2
Fig. 2.20 The critical pairs of setFlag and disableR
Example 2.40. In Fig. 2.20, the two critical pairs of the rules setFlag and
disableR are shown, together with the application conditions acK and acK′. Both
critical pairs overlap the resources of the two rules, leading to a dependency, since
activating the idle process by setflag forbids the disabling of the resource by
disableR. Note, that acC
K and acC
K′ evaluate to true, meaning that whenever we ﬁnd
a match from K or K′ respecting the application condition acE
K or acE
K′, respectively,
we deﬁnitely have a conﬂict of this sort.
△
Every pair of parallel dependent direct transformations is an extension of a criti-
cal pair. Note that this theorem is the instantiation of Theorem 5.41 to graphs.
Theorem 2.41 (Completeness Theorem).
For each pair of parallel dependent
P1
K
P2
H1
G
H2
p1,o1
p1,m1
p2,o2
p2,m2
m
(1)
(2)
direct transformations H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2
there is a critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2
with induced application condition acK and an
injective morphism m : K →G with m |= acK
leading to extension diagrams (1) and (2).
△
In order to show local conﬂuence it is suﬃcient to show strict AC conﬂuence of
all its critical pairs. As discussed above, conﬂuence of a critical pair P1 ⇐K ⇒P2
means the existence of an object K′ together with transformations P1 =
∗⇒K′ and
P2 =
∗⇒K′. Strictness is a technical condition which means, intuitively, that the parts
www.allitebooks.com

2.3 Results for Graph Transformations
41
P1
P2
K
K′
p1,o1
p2,o2
∗∗
which are preserved by both transformations of the
critical pair are also preserved in the common object
K′. For strict AC conﬂuence of a critical pair, the trans-
formations of the strict solution of the critical pair must
be extendable to G, which means that each application
condition of both transformations must be satisﬁed in
the bigger context.
Deﬁnition 2.42 (Strict AC conﬂuence). A critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 with
induced application conditions acK is strictly AC conﬂuent if it is
1. conﬂuent without application conditions, i.e., there are transformations P1 =
∗⇒K′
and P2 =
∗⇒K′ eventually disregarding the application conditions,
2. strict, i.e., given derived spans der(Ki =
pi,oi
===⇒Pi) = (K
vi
←−Ni
wi
−→Pi) and
der(Pi =
∗⇒K′) = (Pi
vi+2
←−Ni+2
wi+2
−→K′) for i = 1, 2 and pullback (1), there exist
morphisms z3, z4 such that diagrams (2), (3), and (4) commute, and
3. for ti : K =
pi,oi
===⇒Pi =
∗⇒K′ it holds that acK ⇒ac(ti) for i = 1, 2, where ac(ti) is
the derived application condition of ti.
K
N1
N2
P1
N
P2
N3
N4
K′
(1)
(2)
(3)
(4)
v1
w1
v2
w2
v3
w3
v4
w4
z1
z2
z3
z4
△
Using this notion of strict AC conﬂuence we can state a suﬃcient condition for a
transformation system to be locally conﬂuent. Note that this theorem is the instanti-
ation of Theorem 5.44 to graphs.
Theorem 2.43 (Local Conﬂuence Theorem). A transformation system is locally
conﬂuent if all its critical pairs are strictly AC conﬂuent.
△
Example 2.44. The critical pairs in Ex. 2.40 as well as all other critical pairs of
our mutual exclusion example are strictly conﬂuent. Therefore, the transformation
system is locally conﬂuent. Although it is not terminating, it is also conﬂuent.
△

Chapter 3
Model Transformation
This chapter is an introduction to model transformation, which is a key compo-
nent of model-driven development. Sect. 3.1 describes the relevance and concepts
of model transformations in general. Using the notions of typed attributed graphs
in Chap. 2, Sect. 3.2 presents the main aspects of model transformations based on
graph transformation on a general level. As a speciﬁc instantiation of these con-
cepts, Sect. 3.3 introduces triple graph grammars (TGGs) as a powerful technique
for bidirectional model transformations. Sect. 3.3 provides an overview of how these
concepts are used as a foundation for Part III. This chapter is based on previous
work [Erm09, EE10, HHK10, EEE+07, HEGO14].
3.1 Introduction to Model Transformation
Model transformations are a key concept for modular and distributed model-driven
development (MDD). They are used thoroughly for model optimisation and other
forms of model evolution. Moreover, model transformations are used to map models
between diﬀerent domains in order to perform code generation or to apply analysis
techniques.
In this multi-domain context, modelling languages are the primary way in which
system developers communicate and design systems. Many domain-speciﬁc mod-
elling languages (DSMLs) are visual modelling languages (that contain also textual
elements) providing a highly specialised set of domain concepts [CSW08]. A visual
syntax presents a model in a diagrammatical (two-dimensional) way and is often
suitable for presenting models in an intuitive and understandable way.
In the MDD context, DSMLs are proposed whose type systems formalise the ap-
plication structure, behaviour, and requirements within particular domains. DSMLs
are described using meta models, which deﬁne the relationships among concepts
in a domain by class diagrams and specify language properties by constraints using
OCL [Obj14b] associated with these domain concepts. Graphical modelling features
enable the integration of concepts that are commonly used by domain experts. This
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_3
43

44
3 Model Transformation
Association
Class
source
destination
Transition
PNode
arc
t1:Transition
a1:arc
a2:arc
a3:arc
p3:Place
tokens=0
p2:Place
tokens=2
p1:Place
tokens=4
Meta-meta-
model
Meta-model
Model
Attribute
Place
tokens: integer
ModelElement
name: String
Classifier
DataType
type
Generalisation
parent
child
Fig. 3.1 Relations between meta model levels
helps ﬂatten learning curves, eases the accessibility to a broader range of domain
experts, such as system engineers and experienced software architects, and helps
them to ensure that software systems meet user needs. A meta model describes the
various kinds of model elements of a DSML, and the way they are arranged, related,
and constrained. Notably, meta models are notated as class diagrams and hence are
visual models. Meta model elements provide a typing scheme for model elements.
This typing is expressed by the meta relation between a model element and its meta
element (from the meta model). A model conforms to a meta model if each model el-
ement has its meta element deﬁned within the meta model, and the given constraints
are satisﬁed.
The growing number of meta models has emphasised the need for an integration
framework for all available meta models by providing a new item, the meta meta
model, dedicated to the deﬁnition of meta models. In the same way models are
deﬁned in conformance with their meta model, meta models are deﬁned by means
of the meta meta model language. An overview of diﬀerent levels of meta modelling
is given in Fig. 3.1, where the sample model is a Petri net, the meta model is a
class diagram deﬁning the structural knowledge of Petri net concepts (Place, tokens,

3.1 Introduction to Model Transformation
45
Model 2
Model 1
Model 1i
Model 2i
…
…
Abstract
Concrete
Domain 1
Domain 2
…
vertical
vertical
horizontal
horizontal
platform
independent
platform
specific
Fig. 3.2 Model transformations in model-driven development
Transition and arc), and the meta meta model shows the key model elements for
modelling class diagrams (the meta model language).
Model transformations are the links between the artefacts of MDD. Diﬀerent
kinds of model transformations are proposed that cover diﬀerent application do-
mains and diﬀerent steps of a sound software production process, including busi-
ness modelling, requirements engineering, conceptual modelling and model-based
code generation techniques. According to the taxonomy of model transformations
by Mens et. al. [MG06], they can be categorised in two dimensions, as depicted in
Fig. 3.2.
First of all, exogeneous model transformations take as input a model of one lan-
guage and produce as output a model of another language, while input and output
models of an endogeneous model transformations belong to the same language. The
second dimension separates horizontal model transformations that do not change
the level of abstraction from vertical model transformations, which explicitly do
change the level of abstraction. Examples of model transformations in these dimen-
sions as listed in [MG06] are: model refactoring (endogeneous, horizontal), formal
model reﬁnement (exogeneous, horizontal), language migration (endogeneous, ver-
tical) and code generation (exogeneous, vertical).
In MDD, model transformations are (partially) automated. This automation re-
duces the required amount of manual work for software development, such that the
software engineering process is supposed to become less error-prone and more ef-

46
3 Model Transformation
Source 
meta model
Source model
Transformation 
definition
Target 
meta model
Transformation 
engine
Target model
Conforms To
Executes
Conforms To
Refers to
Refers to
Reads
Writes
Fig. 3.3 Basic principle of model transformations (from [CH06])
ﬁcient. The issue is “the model is the code” rather than “the code is the model”
[PM07]. The automated transformation process is also referred to as “correct-by-
construction”, as opposed to “construct-by-correction” [Sch06].
The vision of MDD proposes the following principles for the software devel-
opment process to reduce the complexity in designing and implementing modern
software [Sel08]:
• Modelling at diﬀerent abstraction levels
MDD promotes the extensive and systematic use of models from a very early
phase of the design cycle. System requirements and design are captured by
high-level (often visual) engineering models (using popular and standardised
modelling languages like UML [UML15], XML Schemes [WWW04], SysML
[Sys14] or BPMN [OMG14]) or by Domain-Speciﬁc Languages (DSLs) whose
concepts closely reﬂect the concepts of the problem domain at a suitable abstrac-
tion level abstracting away technological implementation detail. For the design
of DSLs in the context of MDD, meta modelling is used [CSW08]. A meta model
is a model of the concepts expressed by a modelling language.
• Automating model transformations
In MDD, the key idea is to automate model transformations. This includes (but is
not limited to) the ability to generate code, i.e., to transform models expressing
high-level domain-speciﬁc concepts into equivalent programs (e.g., Java code,
XML documents, XML schemes, etc.). Fig. 3.3 shows the basic principle under-
lying model transformations [CH06].
Source as well as target models have to conform to their respective meta models.
Therefore, the deﬁnition of the transformation has to be compatible with the meta
models involved. The transformation deﬁnition is applied to a concrete model us-
ing a transformation engine. Model transformations between diﬀerent modelling
languages are called exogenous. For certain model transformations (e.g., model
refactoring), the source and target meta models may be the same. Such model
transformations are called endogenous.

3.1 Introduction to Model Transformation
47
A model-to-model transformation may also have the purpose of utilising anal-
ysis techniques available for the target domain. The formal analysis of design
models can be carried out by generating appropriate mathematical models using
automated model transformations. Problems detected by automated analysis can
be ﬁxed by model reﬁnement prior to investing in manual coding for implemen-
tation.
For executable modelling languages, automated model transformations can also
be used to simulate high-level models in order to validate the suitability of the
modelled system behaviour in an early development phase.
• Using tools that adhere to open industry standards
Model-Driven Architecture (MDA) [Sel08] is OMG’s initiative to support MDD
with a set of open industry standards, including the ability to exchange models
between diﬀerent tools. Standards allow tool builders to focus on their speciﬁc
area of expertise. The basic OMG standards refer to modelling languages (UML
[UML15], MOF [MOF15]) and model transform deﬁnitions (QVT [QVT15]).
The promises of MDD are manifold [VSB+06]: development time will be re-
duced; the model becomes “timeless” and is never outdated since it changes with
the domain and not with the technology; the generated code is correct if the
model is; documentation may be generated from the model and is thus consistent
with the code (which is also generated); systems are easier adaptable (platform-
independent); tasks can be easier divided in complex projects; analysis and valida-
tion on model basis lead to earlier error detection before code is generated.
Model transformations appear in several contexts, e.g., in the various facets of
model-driven architecture [MDA15] encompassing model reﬁnement and interop-
erability of system components. The involved languages can be closely related or
they can be more heterogeneous, e.g., in the special case of model refactoring, the
source language and the target language are the same. From a general point of view,
a model transformation MT : LS ⇛LT transforms models from the (domain-
speciﬁc) source language LS to models of the target language LT.
In the following, we list main challenges for model transformations as presented
in [HHK10]. They concern functional as well as nonfunctional aspects. Some of
these challenges were initially presented by Schürr et. al. [SK08] for the speciﬁc
scope of model transformation approaches based on triple graph grammars (TGGs).
At ﬁrst, we consider the dimension of functional aspects, which concern the re-
liability of the produced results. Depending on the concrete application of a model
transformation MT : LS ⇛LT, some of the following properties may have to be
ensured.
1. Syntactical Correctness: For each model MS ∈LS that is transformed by MT
the resulting model MT has to be syntactically correct, i.e., MT ∈LT.
2. Semantical Correctness: The semantics of each model MS ∈LS that is trans-
formed by MT has to be preserved or reﬂected, respectively.
3. Completeness: The model transformation MT can be performed on each model
MS ∈LS . Additionally, it can be required that MT reaches all models MT ∈LT.

48
3 Model Transformation
4. Functional Behaviour: For each source model MS ∈LS , the model transforma-
tion MT will always terminate and lead to the same resulting target model MT.
In the second dimension, we treat nonfunctional aspects. They concern usability
and applicability properties of model transformations. Depending on the applica-
tion domain, some of the following challenges may be required in addition to the
functional ones listed above.
1. Eﬃciency: Model transformations should have polynomial space and time com-
plexity. Furthermore, there may be further time constraints that need to be re-
spected, depending on the application domain and the intended way of use.
2. Intuitive speciﬁcation: The speciﬁcation of model transformations can be per-
formed based on patterns that describe how model fragments in a source model
correspond to model fragments in a target model. If the source (or target) lan-
guage is a visual language, then the components of the model transformation can
be visualised using the concrete syntax of the visual language.
3. Maintainability: Extensions and modiﬁcations of a model transformation should
only require little eﬀort. Side eﬀects of local changes should be handled and
analysed automatically.
4. Expressiveness: Special control conditions and constructs have to be available in
order to handle more complex models, which e.g., contain substructures with a
partial ordering or hierarchies.
5. Bidirectional model transformations: The speciﬁcation of a model transforma-
tion should provide the basis for both a model transformation from the source to
the target language and a model transformation in the reverse direction.
The power of bidirectional model transformations is based on the simultaneous
support of transformations in both forward and backward direction. This way, mod-
els can be maintained in two repositories—one for diagrams in the source domain
and one for diagrams in the target domain. The modellers can work in separate
teams, and the speciﬁed model transformations are used to support the interchange
between these groups and their models. In particular, a modeller can generate mod-
els in one domain from models in another domain using the concepts for model
transformation in Chap. 7 and he can validate and ensure syntactical correctness
and completeness using the results and analysis techniques in Chap. 8.
In Sects. 3.2 and 3.3, we introduce suitable techniques for the speciﬁcation of
model transformations based on graph transformation. Part III presents the for-
mal techniques for model transformations based on triple graph grammars (TGGs),
which provide validated and veriﬁed capabilities for a wide range of the challenges
listed above.
3.2 Model Transformation by Graph Transformation
While meta modelling provides a declarative approach to DSML deﬁnition, gram-
mars are more constructive, i.e., closer to the implementation. Due to their appeal-

3.2 Model Transformation by Graph Transformation
49
Table 3.1 Mapping meta modelling notions to graph terminology
Meta modelling notion
Graph terminology
Model
Type graph TG
Inheritance
Node type inheritance in TG
Class
Node in type graph TG
Association
Edge in type graph TG
Multiplicities
Node and edge type multiplicities in TG
Class attributes
Attribute types belonging to node types
Model instance
TG-typed, attributed graph G with typing morphism G →TG
Object
Node in TG-typed graph G
Reference
Edge in TG-typed graph G that must not violate certain multiplicity
constraints.
ing visual form, graph grammars can directly be used as high-level visual spec-
iﬁcation mechanism for DSMLs [BEdLT04]. Deﬁning the abstract syntax of vi-
sual models as graphs, a graph grammar deﬁnes directly the DSML grammar.
The induced graph language determines the corresponding DSML. Visual lan-
guage parsers can be immediately deduced from such a graph grammar. Further-
more, abstract syntax graphs are also the starting point for visual modelling of
model behaviour [Erm06, dLVA04, Var02, HKT02] and model transformations
[MVVK05, MVDJ05, SAL+03, Sch94].
Meta modelling is closely related to graph typing, where a type graph takes the
role of the meta model, and an instance graph, typed over the type graph, corre-
sponds to a model conforming to a meta model. In order to better map meta mod-
elling concepts to typed, attributed graphs, the graph transformation theory has been
enhanced in [BEdLT04] with node type inheritance facilities, and it has been shown
how typed graph transformation with inheritance can be ﬂattened to simple typed
graph transformation. Meta modelling and graph transformation can be integrated
by identifying symbol classes with node types and associations with edge types.
Table 3.1 shows a comparison of main meta modelling notions to their coun-
terparts in the terminology of typed graphs. Classes in a meta model correspond
to nodes in a type graph. Associations between classes can be seen as edges in a
type graph. Class inheritance and multiplicity constraints of association ends can
be deﬁned in the type graph by node type inheritance and graph constraints for
specifying edge multiplicities. Objects as instantiations of classes of a meta model
are comparable to nodes in a graph which is typed over a type graph. Objects can
be linked to each other by setting reference values. Such references correspond to
edges in a typed attributed graph. The notion of being a model conforming to a meta
model can be adequately formalised for typed graphs by the existence of a typing
morphism from an instance graph to the type graph. OCL constraints can be trans-
lated to graph constraints or to graph transformation rules (syntax rules), as has been
shown in [WTEK08, BKPPT00, AHRT14]. Thus, declarative as well as constructive

50
3 Model Transformation
1:Place
2:Transition
L
R
1:Place
2:Transition
1:Place
2:Transition
:arc
K
l
r
createPreArc()
Fig. 3.4 Syntax rule adding a Petri net arc
elements may be used for DSML deﬁnition based on typed graph transformation.
An example for a rule from the syntax grammar for Petri nets is shown in Fig. 3.4,
where an arc is inserted between a place node and a transition node. Note that the
graphs in this rule conform to the meta model (are typed over the type graph) shown
in the center of Fig. 3.1.
TGS  
incS
/ TGS T
TGT
? _
incT
o
GS
typeGS
O
r1
+3 . . .
rn
+3 Gn
typeGn
O
GT
typeGT
O
o
The classical approach to model
transformation based on typed, attri-
buted graph transformation [EE05,
Erm09] does not require any spe-
ciﬁc structuring techniques or restric-
tions on transformation rules. The
type graph is given by an integrated
type graph TGS T consisting of the type graphs for the source and target language,
and, additionally, reference nodes with arcs mapping source elements to target ele-
ments. It constitutes a single graph, such that the division in source and target com-
ponents is not explicit. We express model transformations directly by TGS T-typed
graph transformation rules L ←K →R where basically L contains relevant source
model elements and some context, while R \ K basically represents target model
elements that correspond to the relevant source model elements. The model trans-
formation starts with graph GS typed over TGS . As TGS is a subgraph of TGS T, GS
is also typed over TGS T. During the model transformation process, the intermediate
graphs GS = G1; . . . ;Gn are all typed over TGS T. To delete all items in Gn which
are not typed over TGT, we can construct a restriction (a pullback in the category
GraphsATG), which deletes all those items in one step. In addition to normal graph
transformation rules, we also use rule schemes to express parallel transformation
steps of arbitrary many similar model element patterns.
Remark 3.1 (Notation for domain components). In the context of model transforma-
tions, we always diﬀerentiate between source and target domains. For this reason,
we denote the speciﬁc domain of graphs and graph morphisms in superscript (e.g.,
source graph GS ). Thereby, that we can place all further information as index (e.g.,
the ﬁrst graph of a sequence G1).
△
The following general concept of model transformations integrates the described
constructions and deﬁnes special properties that are relevant for model transforma-
tions. By tS >(G), we denote the retyping of G that is initially typed over TGS to a

3.2 Model Transformation by Graph Transformation
51
model that is typed over the integrated type graph TGS T. Furthermore, tT<(G) spec-
iﬁes a restriction of G typed over TGS T to a model G′ typed over TGT only, which
can be constructed as pullback of G →TGS T ←TGT. The execution of the graph
transformation systems may be controlled via a control condition restricting the pos-
sible transformations. Such conditions will be explained exemplarily based on triple
graph grammars thereafter.
Deﬁnition 3.2 (General concept of model transformations based on graph
transformation). Let GRAPHS be the category of plain graphs Graphs or triple
graphs TrGraphs.
1. Given a source language LS ⊆GRAPHSTGS and a target language LT ⊆
GRAPHSTGT, a model transformation MT : L(TGS ) ⇛L(TGT) from L(TGS )
to L(TGT) is given by MT = (L(TGS ), L(TGT), TGST, tS , tT, GTS) where TGST is
an integrated type graph with injective type graph morphisms (TGS −
tS−→TGST ←
tT−−
TGT), and GTS a graph transformation system with nondeleting rules R typed
over TGST and a control condition for GTS-transformations. Moreover, a con-
sistency relation MTC ⊆L(TGS ) × L(TGT) for MT deﬁnes all consistent pairs
(GS ,GT) of source and target models.
2. A model transformation sequence via MT, in short, MT-sequence, is given by
(GS ,G1 =⇒∗Gn,GT), where GS ∈L(TGS ),GT ∈L(TGT) and G1 =⇒∗Gn is a
GTS-transformation satisfying the control condition of GTS with G1 = tS >(GS )
and GT = tT<(Gn), as deﬁned above.
3. The model transformation relation MTR ⊆L(TGS ) × L(TGT) deﬁned by MT is
given by: (GS ,GT) ∈MTR ⇔∃MT −sequence (GS ,G1 =⇒∗Gn,GT).
4. MT : L(TGS ) ⇛L(TGT) is called
a. syntactically correct, if for all (GS ,GT) ∈MTR we have GS ∈LS , GT ∈LT
and (GS ,GT) ∈MTC,
b. total, if for each GS ∈LS there is a pair (GS ,GT) ∈MTR,
c. surjective, if for each GT ∈LT there is a pair (GS ,GT) ∈MTR,
d. complete, if MTR is total and surjective,
e. functional, if MTR is right unique.
△
Most examples of model transformations based on plain graph transformation
considered in the literature adhere to this general concept. A typical example is
the model transformation SC2PN from state charts to Petri nets (see Chapter 14
of [EEPT06] with restriction construction instead of deleting rules): The control
condition is given by layers, where the rules with negative application conditions
are applied as long as possible in one layer, and suitable termination criteria have to
be satisﬁed before switching to the next layer. But also model transformations based
on triple rules adhere to this concept.
We implemented this approach in our tool AGG [AGG14, BEL+10, RET12] (see
also Chap. 12), supporting the deﬁnition of type graphs, typed attributed graph rules
and constraints. Further graph transformation systems for domain-speciﬁc model
transformations are VIATRA2 [BNS+05] and the Graph Rewriting and Transfor-
mation Language (GReAT) [SAL+03]. In VIATRA2, developers deﬁne graph pat-

52
3 Model Transformation
terns and graph transformation rules as components using a textual domain-speciﬁc
programming language. The components are assembled into complex model trans-
formations by abstract state machine rules. In GReAT, meta models of the source
and target models are used to establish the vocabulary of L and R and to ensure that
the transformation produces a well-formed target model.
The classical approach on graph transformation-based model transformation has
been extended to support the transformation of EMF models in Eclipse, thus bridg-
ing the gap between MDD tools and those for graph transformation. The Eclipse
Modeling Framework (EMF) [EMF14] has evolved to one of the standard technolo-
gies to deﬁne modelling languages. EMF is based on MOF [MOF15] and provides
a (meta) modelling and code generation framework for Eclipse applications based
on structured data models. Containment relations, i.e., aggregations, deﬁne an own-
ership relation between objects. Thereby, they induce a tree structure in instance
models, implying some constraints that must be ensured at runtime. As semantical
constraints for containment edges, the MOF speciﬁcation states that “an object may
have at most one container”, and that “cyclic containment is invalid”.
A transformation framework for EMF models is presented in [ABJ+10, BEK+06],
where containment edges are modelled as graph edges of a special containment
type. The problem is guaranteeing that EMF model transformations deﬁned by
graph transformation always satisfy the EMF containment constraints. In [BET12],
these constraints are translated to special kinds of EMF model transformation rules
such that their application leads to consistent transformation results only. EMF
model transformation is supported by our tool Henshin (formerly called EMF Tiger)
[BEL+10, ABJ+10] and its extension HenshinTGG for handling model transforma-
tions based on triple graph grammars, which are introduced in the next section. The
tools AGG, Henshin and HenshinTGG are described in more detail in Chap. 12.
3.3 Introduction to Triple Graph Grammars
Triple graph grammars (TGGs) are a well established concept for the speciﬁca-
tion and execution of bidirectional model transformations within model-driven soft-
ware engineering. They form a speciﬁc case of model transformation based on
graph transformation described in Sect. 3.2 before. Since their introduction by
Schürr [Sch94], TGGs have been applied in several case studies and they have
shown a convenient combination of formal and intuitive speciﬁcation abilities. In
addition to having the general advantages of bidirectional model transformations,
TGGs simplify the design of model transformations. A single set of triple rules
is suﬃcient to generate the operational rules for the forward and backward model
transformations. Thereby, TGGs enhance usability as well as consistency in MDD.
Furthermore, model transformations based on TGGs preserve a given source model
by creating a separate target model together with a correspondence structure. This
way, the given models are not modiﬁed, which is especially important for database-
driven model repositories. Moreover, TGGs specify model transformations based

3.3 Introduction to Triple Graph Grammars
53
on the abstract syntax of DSLs and are therefore not restricted to speciﬁc types of
modelling languages.
The key idea for the execution of model transformations via TGGs is to preserve
the given source model and to add the missing target and correspondence elements
in separate but connected components. For this reason, the transformation rules add
new structures and do not necessarily need to delete existing elements. The resulting
target model is obtained by type restriction. Indeed, nondeleting triple rules are suf-
ﬁcient for many case studies. However, in general it may be very diﬃcult, if not im-
possible, to specify a model transformation whose validity depends on some global
properties of the given models. An example may be automata minimisation, where
we transform a ﬁnite automaton into an automaton with the same behaviour, but with
the smallest possible set of states. In this case, the transformation should translate
any two states with the same behaviour into a single state. However, knowing if two
states have the same behaviour is a global property of the given automaton. Never-
theless, a possible way of simplifying the model transformation is performing some
additional preprocessing of the source model or postprocessing of the target model.
For this reason and as it is common praxis for TGGs, we consider transformation
rules that are nondeleting.
Triple graph grammars [Sch94] are a well-known approach for bidirectional
model transformations. In [KS06], the basic concepts of triple graph grammars are
formalised in a set-theoretical way, which is generalised and extended in [EEE+07]
to typed attributed graphs. In this section, we present triple graph transformation
systems with application conditions. They form an instantiation of M-adhesive
transformation systems deﬁned in Chap. 5, as we show in Chap. 7. We can use
any kind of graph inside triple graphs, as long as they form an M-adhesive category
(see Chap. 4). This means that we can have triple graphs (or, better, triple struc-
tures) consisting of many kinds of graphical structures. In this book, we use typed
attributed triple graphs.
Deﬁnition 3.3 (Triple graph). A triple graph G = (GS ←
sG−−GC −
tG−→GT) consists of
graphs GS , GC, and GT, called source, correspondence, and target graphs, and two
graph morphisms sG and tG mapping the correspondence to the source and target
(GS
mS 
G
GC
sG
o
mC 
tG / GT)
mT 
(HS
R
m

HC
sH
o
tH / HT)
graphs. A triple graph morphism m = (mS , mC,
mT) : G →H matches the single graphs and
preserves the correspondence part. Formally,
a triple graph morphism m consists of graph
morphisms mS : GS →HS , mC : GC →HC
and mT : GT →HT such that mS ◦sG = sH ◦mC
and mT ◦tG = tH ◦mC.
A typed triple graph (G, typeG) is given by a typing morphism typeG : G →TG
from the triple graph G into a given triple type graph TG. A typed triple graph
morphism f : (G1, typeG1) →(G2, typeG2) is a triple graph morphism f such that
typeG2 ◦f = typeG1.
△
Triple graphs and typed triple graphs, together with the componentwise com-
positions and identities, form the categories TrGraphs and TrGraphsTG, where

54
3 Model Transformation
src
Association
name: String
FKey
cols
fkeys
references
dest
fcols
pkey
attrs
parent
CT
AT
AC
1
1
1
0..1
Class 
name: String
Attribute
name: String
datatype: String
is_primary: boolean
Table
name: String
Column
type: String
name: String
1
1
1
1
1
TGS
TGC
TGT
Fig. 3.5 Triple type graph for CD2RDBM
Graphs is the category of graphs (see Def. 2.1). Using the category of attributed
graphs AGraphs (see Def. 2.4) for the triple components, we derive the categories
ATrGraphs and ATrGraphsATG of (typed) attributed triple graphs.
Deﬁnition 3.4 (Category of typed attributed triple graphs).
Typed attributed
triple graphs and typed attributed triple graph morphisms form the category
ATrGraphsATG.
△
Deﬁnition 3.5 (Base categories of triple graphs). Triple graphs and triple graph
morphisms form the category TrGraphs. Analogously, category ATrGraphs of at-
tributed triple graphs is given by attributed triple graphs and attributed triple graph
morphims. Moreover, given a triple graph TG in TrGraphs, we obtain category
TrGraphsTG consisting of typed triple graphs typed over TG.
△
Example 3.6 (Triple type graph). Fig. 3.5 shows the triple type graph TG of the
triple graph grammar TGG for the running example of a model transformation
CD2RDBM from class diagrams to database models, which is based on the ex-
ample presented in [EEE+07, HEGO14]. The source component TGS deﬁnes the
structure of class diagrams while the target component TGT speciﬁes the structure
of relational database models. Classes in the source component (node type Class)
correspond to tables in the target component, attributes correspond to columns, and
associations to foreign keys. Throughout the example, elements are arranged left,
center, and right according to the component types source, correspondence and tar-
get. Attributes of structural nodes and edges are depicted within their containing
structural nodes and edges. Note that the correspondence component is important
for the relation of the source elements to their aligned target elements. For this rea-
son, it is used in practical scenarios to navigate via the traceability links from source
structures to target structures and vice versa. The morphisms between the three com-
ponents are illustrated by dashed arrows. The depicted multiplicity constraints are
ensured by the triple rules of the grammar shown in Fig. 3.8. Moreover, the source
language contains only those class diagrams in which each class hierarchy has at
most one primary attribute.
△

3.3 Introduction to Triple Graph Grammars
55
VISUAL NOTATION
employee
Company
cID:INTEGER
Person
pID:INTEGER
Customer
employee
cID
pID
FK
FK
INTEGER
INTEGER
Company
cID
PK
INTEGER
Person
pID
PK
INTEGER
GC
T6:FKey
T8:fkeys 
T14:cols
S7:Association 
name="employee"
S5:Class 
name="Company"
S9:Class 
name="Person"
S12:Class 
name="Customer"
S13:Attribute 
name="pId"
datatype="INTEGER"
is_primary=true
T18:Column 
type="INTEGER"
name="pId"
T12:Table 
name="Person"
T1:Column 
type="INTEGER"
name="cId"
T7:references
C2:
CT
C5:
CT
C3:
AT
C4:
CT
C6:
AC
GS
GT
S3:Attribute 
name="cId"
datatype="INTEGER"
is_primary=true
T10:Table 
name="employee"
T16:FKey
T4:Column 
type="INTEGER"
name="cId"
T19:Column 
type="INTEGER"
name="pId"
T5:fcols
T2:cols
T3:pkey
T17:fcols
T11:fkeys 
T15:references
C1:
AC
T13:pkey
S4:attrs
S11:parent
S10:attrs
S8:dest
S6:src
T9:Table
name="Company"
ABSTRACT SYNTAX
Fig. 3.6 Triple graph instance for CD2RDBM
Example 3.7 (Triple graph). Fig. 3.6 shows an instance triple graph G = (GS ←
GC →GT) that is typed over TG from Ex. 3.6. The lower part of the ﬁgure shows
the triple graph G that speciﬁes the abstract syntax of the class diagram, the database
model and the correspondence links. The corresponding visualisation is provided
at the top of Fig. 3.6, where foreign keys are marked with FK and primary keys
are marked with PK. The triple graph speciﬁes a company (class Company and ta-
ble Company) and its employees (class Person and table Person) as well as its
customers (class Customer and table Person). Customers have a dedicated ID (at-
tribute cust_id and column cust_id).
△
Triple rules construct the source, correspondence, and target parts in one step.
Each triple rule speciﬁes a pattern of consistent corresponding fragments in its re-
quired context. In Sect. 7.3, we derive the operational rules for model transformation
from these triple rules.

56
3 Model Transformation
L
m

 s
tr
& R
n

(1)
G  s
f
&
H
(LS
trS
'
mS

LC
sL
o
trC
&
tL
/
mC

LT)
trT
'
mT

(RS
nS

RC
sR
o
tR
/
nC

RT)
nT

(GS
f S
'
GC
sG
o
f C
&
tG
/ GT)
f T
'
(HS
HC
sH
o
tH
/ HT)
Fig. 3.7 Triple transformation step
(LS
trS 
L
LC
sL
o
trC 
tL / LT)
trT 
(RS
R
tr 
RC
sR
o
tR / RT)
A triple rule tr is given by an M-morphism
tr = (trS , trC, trT) : L →R (injective on the graph
component and an isomorphism on the data part),
and without loss of generality we assume tr to be
an inclusion. Since triple rules are nondeleting,
there is no need for the more general concept of
a span of morphisms for a rule p = (L ←
l−K −
r→R) in an M-adhesive transformation
system (see Chap. 5). The morphism l can be chosen as l = id and we omit the
intermediate object K.
Deﬁnition 3.8 (Triple rule and transformation). A triple rule tr = (tr : L →
R, ac) consists of triple graphs L and R, an M-morphism tr : L →R, and an appli-
cation condition ac over L. Given a triple graph G, a triple rule tr = (tr, ac) and a
match m: L →G with m |= ac, a direct triple transformation G =
tr,m
==⇒H of G via
tr and m is given by pushout (1) in Fig. 3.7, which is constructed as the componen-
twise pushouts in the S -, C-, and T-components, where the morphisms sH and tH
are induced by the pushout of the correspondence component. In addition to H, we
obtain co-match n : R →H and transformation inclusion f : G ,→H. A direct
transformation is also called triple graph transformation (TGT) step.
△
Application conditions of triple rules are used to restrict the application of the
rules to certain contexts as deﬁned in Chap. 2. A triple rule tr: L →R with an
application condition ac over L is applicable if the match m: L →G satisﬁes the
application condition ac, i.e., m |= ac. Roughly spoken, an application condition
is a Boolean formula over some additional context structure for the left-hand side
L (see Defs. 2.7 and 2.8). In our running example, we will exlusively use negative
application conditions (NACs) [HHT96]. A NAC has the form ac = ¬( ∃a: L →C)
and is used to avoid the application of a rule if the match for L can be extended to
the forbidden context C. A match m: L →G satisﬁes a NAC ac = ¬( ∃a: L →C)
if there is no embedding q: C →G ∈M that is compatible with m, i.e., such that
q ◦a = m. From now on, a triple rule denotes a rule with application conditions,
while the absence of application conditions is explicitly mentioned.

3.3 Introduction to Triple Graph Grammars
57
:Table
name=an
:Column
name=n
type=t
:Class
name=n
:CT
:Table
name=n
Class2Table(n:String)
++
++
++
:parent
S1:Class
:Class
name=n
:CT
:Table
:CT
Subclass2Table(n:String)
++
++
++
:cols
:AC
S1:Class
:Attribute
name=n
datatype=t
is_primary=false
:attrs
C1:
CT
T1:Table
++
++
++
++
++
Attr2Column(n:String, t:String)
++
++
++
++
++
++
++
++
++
++
++
++
++
++
:attrs
:cols
:AC
S1:Class
:Attribute
name=n
datatype=t
is_primary=true
:attrs
C1:
CT
T1:Table
++
++
++
++
:Column
name=n
type=t
PrimaryAttr2Column(n:String, t:String)
:pKey
++
:Column
:pKey
:Attribute
is_primary=true
NAC1
NAC2
++
++
++
++
++
++
++
++
:Class
:src
:Class
:dest
:FKey
:Table
:fkeys
:references
:pkey
:CT
:AT
:CT
++
++
++
++
++
++
:fcols
:Association
name = an
:Column
type=t1
name="src_"+cn1
Association2Table(an:String)
++
:Column 
type = t2
name = cn2
++
++
:Table
++
++
++
++
++
++
:pkey
:Column 
type = t1
name = cn1
++
:FKey
:fkeys
++
++
:fcols
:Column
type=t2
name="tgt_"+cn2
++
++
++
:references
++
++
Fig. 3.8 Rules for the model transformation CD2RDBM
Note that, due to the structure of the triple rules, both double [EEPT06] and
single pushout approach [EHK+96] are equivalent in this case.
Example 3.9 (Triple rules and triple transformation step). The triple rules in Fig. 3.8
are the rules of the grammar TGG for the model transformation CD2RDBM. They
are presented in short notation, i.e., left- and right-hand sides of a rule are de-
picted in one triple graph. Elements which are created by the rule are labelled with
“++” and additionally marked by green line colouring. Rule Class2Table syn-
chronously creates a class with name n together with the corresponding table in

58
3 Model Transformation
S1:Class
C1
:CT
T1:Table
:parent
S1:Class
:Class
C1
:CT
T1:Table
:CT
:Column
:cols
:AC
S1:Class
:Attribute
:attrs
C1:
CT
T1:Table
:parent
:CT
(PO)
tr
L
G
R
H
:Class
:Column
:cols
:AC
S1:Class
:Attribute
:attrs
C1:
CT
T1:Table
Fig. 3.9 Triple graph transformation step via rule Subclass2Table (without data values)
the relational database. Accordingly, subclasses are connected to the tables of its
superclasses by rule Subclass2Table. Note that this rule creates the new class
node together with an edge of type parent, implying that our compact case study
does not handle the case of multiple inheritance. Finally, rule Attr2Column creates
attributes with type t together with their corresponding columns in the database
component. Rule PrimaryAttr2Column extends Attr2Column by creating ad-
ditionally a link of type pkey for the column and by setting the attribute value
is_primary = true. This rule contains NACs, which are speciﬁed in short no-
tation. The NAC-only elements are speciﬁed by red line colouring and additionally
with a surrounding frame with label NAC. A complete NAC is obtained by compos-
ing the left-hand side of a rule with the marked NAC-only elements. The source
and target NACs ensure that there is neither a primary attribute in the class diagram
nor a primary key in the database model present when applying the rule. More for-
mally, the depicted NACs are actually NAC schemata (see Def. 2.17), such that the
NACs also forbid the cases when some of the speciﬁed variables are evaluated to the
same values. Rule Association2Table creates an association between two classes
and the corresponding table, together with two foreign keys, where the parameters
an, cn1, cn2, t1 and t2 are used to set the names and types of the created nodes.
Fig. 3.9 shows a triple graph transformation step G =
tr,m
==⇒H via rule tr =
Subclass2Table, where we omitted the attribute values of the nodes and reduced
the node types to the starting letters. The top line shows the rule with its left- and
right-hand sides and the bottom line shows the given triple graph G and the resulting
triple graph H. The eﬀect of this step is the addition of a new subclass that is related
to the existing table corresponding to the existing class.
△
Remark 3.10 (Possible extensions of the example). The example CD2RDBM pro-
vides a simplistic view on the general problem to deﬁne an object relational map-
ping. A possible extension would be to take into account multiplicities on associ-
ations. In that case, the TGG could be extended by an additional rule that would
create an association with cardinality 1 −n (source multiplicity x..1 and destination

3.3 Introduction to Triple Graph Grammars
59
L
R
G
tr
C
T
C
T
C
T
A
C
A
C
pK
pK
L
R
G'
H'
(PO)
tr
C
T
C
T
C
T
A
C
A
C
pK
C
T
A
C
pK
A
C
Fig. 3.10 Violation of NAC and satisfaction of NAC for rule PrimaryAttr2Column
multiplicity y..n) together with a single foreign key in the target domain (database
model). The existing rule Association2Table would be reﬁned to handle only the
case for associations with cardinality n −m (source multiplicity x..∗and destination
multiplicity y..∗) using attribute conditions. The example also simpliﬁes that data
type names used for nodes of type Attribute (datatype = t) in class diagrams
and for nodes of type Column (type = t) in database diagrams coincide. There are
several ways to extend the TGG to deﬁne a mapping from certain data type names in
one domain to diﬀerently named ones in the other domain. For example, this could
be handled by specialising the rules for each pair of corresponding data type names
or by using a constant structural fragment from which the name mapping informa-
tion can be matched by the rules and used for the attribute assignments. Finally,
one could consider composed primary keys in the database domain, which would
require further extensions of the TGG.
△
Example 3.11 (Triple transformation with NACs). The left component of Fig. 3.10
shows a violation of the target NAC for rule PrimaryAttr2Column, whose target
NAC forbids the presence of an existing primary key at the matched table. In its
right component, the ﬁgure shows a NAC consistent transformation step, where no
primary key is present and also the existing attribute is assumed to be not a primary
one.
△
A triple graph transformation system TGS = (TR) is based on triple graphs and
a set of rules TR over them. A triple graph grammar TGG = (TR, S ) contains in
addition a triple start graph S . For triple graph grammars, the generated language is
given by all triple graphs G that can be derived from the start graph S via rules in TR.
The source language L(TGG)S contains all graphs that are the source component
of a derived triple graph. Similarly, the target language L(TGG)T contains all deriv-
able target components. A triple graph grammar generates the language L(TGG)
of integrated models, where each integrated model contains a source model and its
corresponding target model. This language induces the model transformation rela-
tion MTR that deﬁnes the set of all consistent pairs (GS ,GT) of source and target
models. Any other pair of models is seen to be inconsistent.

60
3 Model Transformation
Deﬁnition 3.12 (Triple graph grammar and triple language).
A triple graph
grammar TGG = (TR, S ) consists of a set TR of triple rules and a triple graph S
called triple start graph.
A language of triple graphs generated by TGG is given by L(TGG) = {G | ∃
triple transformation S =
∗⇒G via rules in TR}. The source language L(TGG)S =
{GS | (GS ←
sG−−GC −
tG−→GT) ∈L(TGG)} contains all graphs that are the source
component of a derived triple graph. Similarly, the target language L(TGG)T =
{GT | (GS ←
sG−−GC −
tG−→GT) ∈L(TGG)} contains all derivable target components.
The model transformation relation MTR = {(GS ,GT) ∈L(TGG)S × L(TGG)T |
∃G = (GS ←GC →GT) ∈L(TGG)} deﬁnes the set of all consistent pairs (GS ,GT)
of source and target models.
△
Example 3.13 (Triple language). The triple graph in Fig. 3.6 shows an instance triple
graph G = (GS ←GC →GT) of the triple language L(TGG) for the language
CD2RDBM. It can be constructed via the transformation sequence ∅=
Class2Table
=========⇒
G1 =
Class2Table
=========⇒G2 =
SubClass2Table
============⇒G3 =
Attribute2Column
==============⇒G4 =
PrimaryAttribute2Column
====================⇒
G5 =
Association2Table
==============⇒G6. The triple language contains all such triple graphs that
can be created via the triple rules.
△
3.4 Model Transformation Based on TGGs
In Part III, we present the techniques and results for model transformation based
on TGGs (see Def. 3.2). We cover diﬀerent execution and analysis techniques in
diﬀerent transformation scenarios.
Part III starts with Chap. 7, which presents the automatic derivation of opera-
tional rules from a given TGG:
• operational rules for forward model transformations, i.e., transforming a model
of the source language into a corresponding one of the target language
• operational rules for backward model transformations, i.e., transforming a model
of the target language into a corresponding one of the source language
• operational rules for model integrations, i.e., taking a pair of existing source and
target models and extending them to an integrated model that is consistent (if
possible)
• operational rules for model synchronisation, i.e., taking and integrated model
together with updates on both domains and propagating the changes from one
domain to the other, including the handling of conﬂicts
• operational rules for consistency checking, i.e., checking whether a given inte-
grated model is consistent
Furthermore, Chap. 7 presents appropriate execution algorithms for forward/
backward model transformations and model integrations. We focus on both the for-
mal point of view based on category theory and the implementation point of view

3.4 Model Transformation Based on TGGs
61
using an encoding of the formal control conditions via Boolean-valued attributes as
a kind of caching structure and a ﬂattening construction to enable the use of plain
graph transformation tools. As the main result, we provide suﬃcient criteria for
ensuring the fundamental composition and decomposition result for TGGs that is
the basis for the results in Chapters 8 and 9. The decomposition result ensures that
a triple graph transformation sequence can be decomposed into two operational se-
quences, where one is used for a kind of parsing of the inputs and the other performs
the actual creation of the relevant elements for the output. Vice versa, the compo-
sition result ensures that two operational sequences can be composed if a certain
consistency condition is satisﬁed.
Chap. 8 provides results for the analysis of model transformations and model
integrations based on TGGs concerning the following three out of four properties
of the dimension of functional aspects presented in Sect. 3.1, which concerns the
reliability of the produced results:
1. Syntactical Correctness: For each model MS ∈LS that is transformed by MT
the resulting model MT has to be syntactically correct, i.e., MT ∈LT.
2. Completeness: The model transformation MT can be performed on each model
MS ∈LS . Additionally, it can be required that MT reaches all models MT ∈LT.
3. Functional Behaviour: For each source model MS ∈LS , the model transforma-
tion MT will always terminate and lead to the same resulting target model MT.
As a general requirement, Chap. 8 assumes the validity of the (de-)composition
result for TGGs, for which Theorem 7.21 in Chap. 7 provides a suﬃcient condi-
tion. The main results show that model transformations and integrations based on
TGGs ensure syntactical correctness and completeness. Since some TGGs do not
show functional behaviour for the derived operations, we provide suﬃcient condi-
tions that ensure functional behaviour. These conditions are based on the notion of
critical pairs and can be analysed statically using the tool AGG. We also show how
the operational rules of a TGG can be extended by special application conditions
to remove conﬂicts, which is used to improve eﬃciency of the execution and for
showing functional behaviour in a more complex case. In addition, we show that
model transformations based on TGGs are always information preserving in a weak
sense and provide a suﬃcient condition for showing that they are completely infor-
mation preserving, i.e., that the input can be reconstructed from the output without
requiring any other information than the output model itself.
Chap. 9 presents the most complex case of model transformations—namely
model synchronisation—where several diﬀerent operations have to be combined.
Model synchronisation is an important technique for keeping and gaining consis-
tency of source and target models after changing one or both of them. We provide
suﬃcient conditions and general results for ensuring
1. Syntactical Correctness: For each synchronisation of an integrated model M ∈
L(TG) with updates on the source and target domains, the result of the model
synchronisation is a consistent integrated model M′ ∈L(TGG) together with
corresponding updates on the source and target domains. Moreover, if no update
is required, then the synchronisation preserves the inputs.

62
3 Model Transformation
2. Completeness: The model synchronisation can be performed for any integrated
model M ∈L(TG).
3. Invertibility: The propagation of changes is symmetric in the following sense.
Propagating changes from the ﬁrst domain and then propagating the obtained
changes back yields the initially given update on the ﬁrst domain. If this prop-
erty is required for a restricted set of updates only, we use the notion of weak
invertibility.
In the basic case, model synchronisation is performed in a unidirectional way,
i.e., an update on one domain is propagated to the corresponding domain. The more
general cases handle concurrent updates on both domains, conﬂict resolution and
nondeterminism.

Part II
M-Adhesive Transformation Systems

65
This second part of the book presents the algebraic approach to graph transfor-
mation in the general framework of M-adhesive categories, which instantiate to
graphs of the form G = (V, E, s, t) considered in Chap. 2, but also to a large va-
riety of further types of graphs and other kinds of high-level structures, such as
labelled graphs, typed graphs, hypergraphs and diﬀerent kinds of low- and high-
level Petri nets. The extension from graphs to high-level structures was introduced
in [EHKP91a, EHKP91b], leading to the theory of high-level replacement (HLR)
systems. In [EHPP04] the concept of HLR systems was joined to that of adhe-
sive categories of Lack and Sobocinsky in [LS04], leading to the concepts of ad-
hesive HLR categories used in [EEPT06] and M-adhesive categories in this book,
where all these concepts are introduced in Chap. 4. Moreover, this chapter includes
an overview of diﬀerent adhesive and HLR notions and several results concern-
ing HLR properties, which are used in the general theories of Chapters 5 and 6
and for the construction of M-adhesive categories. In fact, M-adhesive categories
and transformation systems constitute a suitable general framework for an abstract
theory of graph and model transformations, which can be instantiated to various
kinds of high-level structures,especially to those mentioned above. All the concepts
and results—introduced for graph transformation in Chap. 2—are carefully pre-
sented and proven in Chap. 5 for M-adhesive transformation systems and in Chap. 6
for multi-amalgamated transformations. Finally it is shown in Chap. 6 how multi-
amalgamation can be used to deﬁne the semantics of elementary Petri nets.

Chapter 4
Adhesive and M-Adhesive Categories
In this chapter, we introduce adhesive and M-adhesive categories as the categorical
foundation of graph and model transformations and present various constructions
and properties. In Sect. 4.1, we introduce M-adhesive categories based on the notion
of van Kampen squares. Diﬀerent versions of adhesive categories are compared to
the one we use in this book in Sect. 4.2. In Sect. 4.3, we introduce some additional
properties which are needed for results in M-adhesive categories, as well as derive
results that hold in any such category. A special variant of M-adhesive categories
using only ﬁnite objects is presented in Sect. 4.4. In Sect. 4.5, we show that M-
adhesive categories are closed under certain categorical constructions and analyse
how far several of the additional properties are also preserved. This chapter is based
on [EGH+14, Gol10].
4.1 M-Adhesive Categories
For the transformation of not only graphs, but also high-level structures such as Petri
nets and algebraic speciﬁcations, high-level replacement (HLR) categories were es-
tablished in [EHKP91a, EHKP91b], which require a list of so-called HLR properties
to hold. They were based on a morphism class M used for the rule morphisms. This
framework allowed a rich theory of transformations for all HLR categories, but the
HLR properties were diﬃcult and lengthy to verify for each category.
Adhesive categories were introduced in [LS04] as a categorical framework for
deriving process congruences from reaction rules. They require a certain compati-
bility of pushouts and pullbacks, called the van Kampen property, for pushouts along
monomorphisms in the considered category. Later, they were extended to quasiad-
hesive categories in [JLS07], where the van Kampen property has to hold only for
pushouts along regular monomorphisms.
Adhesive categories behave well also for transformations, but interesting cate-
gories as typed attributed graphs are neither adhesive nor quasiadhesive. Combin-
ing adhesive and HLR categories leads to adhesive HLR categories in [EHPP04,
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_4
67

68
4 Adhesive and M-Adhesive Categories
EPT04], where a subclass M of monomorphisms is considered and only pushouts
over M-morphisms have to fulﬁll the van Kampen property. They were slightly
extended to weak adhesive HLR categories in [EEPT06], where a weaker version
of the van Kampen property is suﬃcient to show the main results of graph and
HLR transformations also for transformations in weak adhesive HLR categories.
Not only many kinds of graphs, but also Petri nets and algebraic high-level nets
are weak adhesive HLR categories, which allows to apply the theory to all these
kinds of structures. In [EEPT06], the main theory including all the proofs for trans-
formations in weak adhesive HLR categories can be found, while an introduction
including motivation and examples for all the results is given in [PE07].
In this book, we use a slightly diﬀerent version, the so-called M-adhesive cat-
egories. The diﬀerences between several variants of adhesive categories are anal-
ysed in detail in the following section. Their main property is (a variant of) the van
Kampen property, which is a special compatibility of pushouts and pullbacks in a
commutative cube. The idea of a van Kampen square is that of a pushout which is
stable under pullbacks, and, vice versa, where pullbacks are stable under combined
pushouts and pullbacks.
Deﬁnition 4.1 (Van Kampen square). A commutative cube (2) with pushout (1)
in the bottom face and where the back faces are pullbacks fulﬁlls the van Kampen
property if the following statement holds: the top face is a pushout if and only if
A′
B′
A
B
C′
D′
C
D
A
B
C
D
m′
a
f ′
g′
b
m
f
n′
c
d
n
g
m
f
n
g
(1)
(2)
the front faces are
pullbacks.
A pushout (1) is
a
van
Kampen
square if the van
Kampen
property
holds for all com-
mutative cubes (2)
with (1) in the bot-
tom face.
Given a morphism class M, a pushout (1) with m ∈M is an M-van Kampen
square if the van Kampen property holds for all commutative cubes (2) with (1) in
the bottom face and b, c, d ∈M.
△
It might be expected that, at least in the category Sets, every pushout is a
van Kampen square. Unfortunately, this is not true, but at least pushouts along
monomorphisms are van Kampen squares in Sets and several other categories.
For an M-adhesive category, we consider a category C together with a morphism
class M of monomorphisms. We require pushouts along M-morphisms to be M-
van Kampen squares, along with some rather technical conditions for the morphism
class M called PO–PB compatibility, which are needed to ensure compatibility of
M with pushouts and pullbacks.
Deﬁnition 4.2 (PO–PB compatibility). A morphism class M in a category C is
called PO–PB compatible if

4.2 Overview of Diﬀerent Adhesive and HLR Notions
69
1. M is a class of monomorphisms, contains all identities, and is closed under com-
position (f : A →B ∈M, g : B →C ∈M ⇒g ◦f ∈M).
2. C has pushouts and pullbacks along M-morphisms, and M-morphisms are
closed under pushouts and pullbacks.
△
Remark 4.3. From Items 1 and 2, it follows that M contains all isomorphisms and
is also closed under decomposition, i.e., g ◦f ∈M, g ∈M implies f ∈M. In
fact, isomorphisms can be obtained by pushouts or pullbacks along identities, and
the pullback of (g ◦f, g) is (id, f) such that the pullback closure of M implies that
f ∈M [Hei10].
△
Deﬁnition 4.4 (M-adhesive category). A category C with a PO–PB compatible
morphism class M is called an M-adhesive category if pushouts in C along M-
morphisms are M-van Kampen squares.
△
Examples for M-adhesive categories are the categories Sets of sets, Graphs of
graphs, GraphsTG of typed graphs, Hypergraphs of hypergraphs, ElemNets of el-
ementary Petri nets, and PTNets of place/transition nets, all together with the class
M of injective morphisms, as well as the category Specs of algebraic speciﬁcations
with the class Mstrict of strict injective speciﬁcation morphisms, the category PTSys
of place/transition systems with the class Mstrict of strict morphisms, and the cat-
egory AGraphsATG of typed attributed graphs with the class MD−iso of injective
graph morphisms with isomorphic data part. The proof that Sets is an M-adhesive
category is shown in [EEPT06], while the proofs for most of the other categories
can be done using the Construction Theorem in the following Sect. 4.5.
4.2 Overview of Diﬀerent Adhesive and HLR Notions
Several variants of HLR and adhesive categories have been introduced in the litera-
ture as categorical frameworks for graph transformation and HLR systems based on
Adhesive
Partial map adhesive
Partial van Kam-
pen square adhesive
Adhesive HLR
Weak adhesive HLR
Vertical weak
adhesive HLR
= M-adhesive
Horizontal weak
adhesive HLR
×
×
×
×
?
?
+
+
Fig. 4.1 Hierarchy of adhesive categories

70
4 Adhesive and M-Adhesive Categories
the DPO approach. In this section, we compare and relate diﬀerent relevant notions
and build up a hierarchy between them, as shown in Fig. 4.1.
4.2.1 From Adhesive to M-Adhesive Categories
Adhesive categories have been introduced by Lack and Sobocinski [LS04] as a cat-
egorical framework for graph transformation systems, which allows to verify the
variety of axiomatic HLR properties required for the theory of high-level replace-
ment systems in [EHKP91b]. Adhesive categories are based on the property that
pushouts along monomorphisms are van Kampen squares.
Deﬁnition 4.5 (Adhesive category). C is an adhesive category if:
1. C has pushouts along monomorphisms.
2. C has pullbacks.
3. Pushouts in C along monomorphisms are van Kampen squares.
△
Important examples of adhesive categories are the categories Sets of sets, Graphs
of graphs, and GraphsTG of typed graphs, while the category AGraphsATG of
typed attributed graphs is not adhesive. But in the latter case, pushouts along M-
morphisms are van Kampen squares for the class Mmono−iso of all monomorphisms
which are isomorphic on the data type part. In fact, AGraphsATG is an adhesive
HLR category.
Deﬁnition 4.6 (Adhesive HLR category). A category C with a PO–PB compat-
ible morphism class M is called an adhesive HLR category if pushouts along M-
morphisms are van Kampen squares.
△
It can be shown that the class Mmono of all monomorphisms in an adhesive
category C fulﬁlls these properties [LS04], such that (C, Mmono) is also an adhe-
sive HLR category, leading to the implication “adhesive implies adhesive HLR”
in Fig. 4.1. This implication is proper, because AGraphsATG is not adhesive, but
(AGraphsATG, Mmono−iso) is an adhesive HLR category [EEPT06].
However, there are important examples, like the category (PTNets, Mmono) of
place/transition nets with the class Mmono of all monos, which are not adhesive HLR,
but only weak adhesive HLR categories. This means that the corresponding van
Kampen property holds for van Kampen cubes, where all horizontal or all vertical
morphisms are M-morphisms. We call these two cases horizontal or vertical weak
adhesive HLR.
Deﬁnition 4.7 (Weak adhesive HLR category). Consider a category C with a PO–
PB compatible morphism class M.
• (C, M) is horizontal weak adhesive HLR if pushouts in C along m ∈M are
horizontal weak van Kampen squares, i.e., the van Kampen property holds for
commutative cubes with f, m ∈M (see Def. 4.1).

4.2 Overview of Diﬀerent Adhesive and HLR Notions
71
• (C, M) is vertical weak adhesive HLR if pushouts in C along m ∈M are vertical
weak van Kampen squares, i.e., the van Kampen property holds for commutative
cubes with b, c, d ∈M (see Def. 4.1).
• (C, M) is a weak adhesive HLR category if it is horizontal and vertical weak
adhesive HLR.
△
Remark 4.8. In the horizontal case, the closure of M under pushouts and pullbacks
implies that all horizontal morphisms are in M. Similarly, in the vertical case it
follows that a ∈M.
△
Using this deﬁnition, we have the implications on the right-hand side of Fig. 4.1
between the diﬀerent variants of “adhesive HLR”. The category (PTNets, Mmono)
shows that the implication from “adhesive HLR” to “weak adhesive HLR” is proper.
Recently, we recognised by inspection of the proofs for weak adhesive HLR
categories that it is suﬃcient to consider vertical weak adhesive HLR categories
in order to obtain all the important properties. For this reason, we use the short
name M-adhesive category for this important class of categories. Note, that this is in
contrast to some other work like [BEGG10], where weak adhesive HLR categories
are called M-adhesive.
Fact 4.9. An M-adhesive category is a vertical weak adhesive HLR category.
△
Proof. This follows directly from Defs. 4.4 and 4.7.
⊓⊔
4.2.2 Partial Map and Partial Van Kampen Square Adhesive
Categories
Another variant of adhesive categories has been introduced by Heindel [Hei10],
called partial map adhesive categories. They are based on the requirement that
pushouts along M-morphisms are hereditary [Ken91]. Hereditary pushouts in a cat-
egory C are those pushouts that are preserved by the embedding into the associ-
ated category ParM(C) of partial maps over C. Heindel has shown that hereditary
pushouts can be characterised by a variant of van Kampen squares, called partial van
Kampen squares, which are closely related to weak van Kampen squares in weak
adhesive HLR categories. This leads to the new concept of partial map adhesive
categories, which are equivalent to partial van Kampen square adhesive categories.
The concepts in this section are based on an admissible class M of monomor-
phisms according to [Hei10], which we call PB compatible in analogy to PO–PB
compatibility in Def. 4.2.
Deﬁnition 4.10 (PB compatibility). A morphism class M in a category C is called
PB compatible if
1. M is a class of monomorphisms, contains all identities, and is closed under com-
position (f : A →B ∈M, g : B →C ∈M ⇒g ◦f ∈M).

72
4 Adhesive and M-Adhesive Categories
2. C has pullbacks along M-morphisms, and M-morphisms are closed under pull-
backs.
△
A partial map category is constructed by the objects of a given category and spans
of morphisms within this category.
Deﬁnition 4.11 (Partial map category). Given a category C with a PB-compatible
morphism class M, the partial map category ParM(C) of M-partial maps over C is
deﬁned as follows:
• The objects are all objects in C.
• The morphisms from A to B are (isomorphism classes of) spans (A
m
←−A′
f
−→B)
with f, m ∈C, m ∈M, called M-partial maps (m, f) : A →B.
• The identities are identical spans and the composition of spans is deﬁned by
pullbacks.
△
For any partial map category, we ﬁnd an inclusion functor from its underlying
category. If this functor preserves a pushout, this pushout is called hereditary. This
leads to the deﬁnition of a partial map adhesive category, where all pushouts along
M-morphisms are hereditary.
Deﬁnition 4.12 (Hereditary pushout). Given a category C with a PB-compatible
morphism class M, the inclusion functor I : C →ParM(C), called graphing functor
in [Hei10], is deﬁned by the identity on objects, and maps each morphism f : A →B
in C to the M-partial map I(f) = (id, f) : A →B in ParM(C).
A pushout in C is called hereditary if it is preserved by I.
△
Deﬁnition 4.13 (Partial map adhesive category).
A category C with a PB-
compatible morphism class M is a partial map adhesive category if pushouts along
M-morphisms exist and are hereditary.
△
Remark 4.14. If C has pushouts along M-morphisms, a suﬃcient condition for
(C, M) to be partial map adhesive is the existence of a cofree construction lead-
ing to a right adjoint functor R for the inclusion functor I. In this case, I is left
adjoint and preserves all colimits, especially pushouts along M-morphisms, such
that these pushouts are hereditary.
In the case of sets and monomorphisms, the partial map category ParMmono(Sets)
is isomorphic to the category of sets and partial functions, where R(X) is the ex-
tension of a set X by one distinguished (“undeﬁned”) element. In this and several
other examples, the construction of a right adjoint R is much easier than the explicit
veriﬁcation of the van Kampen property.
△
For hereditary pushouts, we ﬁnd an equivalent property using so-called partial
van Kampen squares. These are closely related to vertical weak van Kampen squares
in Def. 4.7, but the assumption and conclusion concerning d ∈M is diﬀerent.
Deﬁnition 4.15 (Partial van Kampen square). Given a morphism class M, a com-
mutative cube (2) with pushout (1) in the bottom face and where the back faces are
pullbacks with b, c ∈M fulﬁlls the partial van Kampen property if the following
statement holds: the top face is a pushout if and only if the front faces are pullbacks
with d ∈M.

4.2 Overview of Diﬀerent Adhesive and HLR Notions
73
A′
B′
A
B
C′
D′
C
D
A
B
C
D
m′
a
f ′
g′
b
m
f
n′
c
d
n
g
m
f
n
g
(1)
(2)
A pushout (1)
with m ∈M is a
partial van Kam-
pen square if the
partial van Kampen
property holds for
all
commutative
cubes (2) with (1)
in the bottom face.
△
Deﬁnition 4.16 (Partial van Kampen square adhesive category). A category C
with a PB-compatible morphism class M is a partial van Kampen square adhesive
category if pushouts along M-morphisms exist and are partial van Kampen squares.
△
The following theorem shows that partial van Kampen square and partial map
adhesive categories are in fact equivalent.
Theorem 4.17 (Equivalence of partial map and partial van Kampen square ad-
hesive categories). Given a category C with a PB compatible morphism class M
such that C has pushouts along M-morphisms. Then pushouts along M-morphisms
are hereditary if and only if they are partial van Kampen squares.
△
Proof. The proof is sketched in [Hei10] based on results in [Hei09].
⊓⊔
Remark 4.18. As indicated in [Hei10], the statement and proof remains valid if
“pushouts along M-morphisms” is replaced by arbitrary “pushouts”.
△
In [Hei10], it is shown that adhesive categories are also partial map adhesive for
the morphism class Mmono. Moreover, an example of a category lSet of list sets is
given, which is partial map adhesive, but not adhesive. Together with Theorem 4.17
this leads to the implication and equivalence on the left-hand side of Fig. 4.1.
In the following, we will analyse the relationship between partial map adhesive
categories and the diﬀerent adhesive HLR notions. As a ﬁrst step, it is shown in
[Hei10] that PB compatibility already implies PO–PB compatibility in partial van
Kampen square adhesive categories.
Theorem 4.19 (Equivalence of PB and PO–PB compatibility). Given a partial
van Kampen square adhesive category (C, M), we have that PB compatibility is
equivalent to PO–PB compatibility.
△
Proof. It suﬃces to show that M is closed under pushouts in partial van Kampen
square adhesive categories.

74
4 Adhesive and M-Adhesive Categories
A
A
A
B
C
C
C
D
id
id
f
f
m
m
f
id
id
n
n
g
Consider a pushout with m ∈M in
the bottom of the commutative cube on
the right, which has pullbacks in the back
squares with id, f ∈M and a pushout in
the top. The partial van Kampen property
implies that the front squares are pull-
backs with n ∈M; hence M is closed
under pushouts.
⊓⊔
Using this result, we can show that partial van Kampen square adhesive cate-
gories are also M-adhesive.
Theorem 4.20 (Partial van Kampen square adhesive categories are M-adhe-
sive). Given a partial van Kampen square adhesive category (C, M), (C, M) is an
M-adhesive category.
△
Proof. Given a partial van Kampen square adhesive category (C, M), M is already
PO–PB compatible by Theorem 4.19. Moreover, pushouts along M-morphisms sat-
isfy the vertical weak van Kampen square property, because we only have to con-
sider commutative cubes with a, b, c, d ∈M, in contrast to partial van Kampen
squares, where the equivalence holds under the assumption that a, b, c ∈M. Hence,
(C, M) is a vertical weak adhesive HLR and therefore an M-adhesive category by
deﬁnition.
⊓⊔
By Theorem 4.20, we have the implication from “partial van Kampen square
adhesive” to “M-adhesive” in Fig. 4.1. Up to now it is open whether also the reverse
direction holds.
In [Hei10] it is shown that the category lSet of list sets is partial map adhesive—
and hence partial van Kampen square adhesive—but violates the property that
pushouts over M-morphisms are van Kampen squares. Therefore this category is
not horizontal weak adhesive HLR, and also not weak adhesive HLR. This implies
that there is no implication from “partial van Kampen square adhesive” to “weak ad-
hesive HLR” in Fig. 4.1. It follows that there are no implications from “M-adhesive”
to “weak adhesive HLR” and to “horizontal weak adhesive HLR”.
4.3 Results and Additional HLR Properties for M-Adhesive
Categories
In this section, we collect various results that hold in M-adhesive categories and
follow from the M-van Kampen property, as well as additional HLR properties that
are needed and have to be required. These results and properties are used to show
the main theorems of graph transformation in [EEPT06] as well as various results
in the following chapters.

4.3 Results and Additional HLR Properties for M-Adhesive Categories
75
4.3.1 Basic HLR Properties
In [EHKP91b], the following HLR properties were required for HLR categories.
In the following, we call them basic HLR properties to distinguish them from the
additional ones introduced later. All basic HLR properties are valid in M-adhesive
categories and can be proven using the M-van Kampen property.
Deﬁnition 4.21 (Basic HLR properties). The following properties are called basic
HLR properties:
A′
B′
A
B
C′
D′
C
D
A
B
E
C
D
F
m′
a
f ′
g′
b
m
f
n′
c
d
n
g
k
l
u
s
r
v
w
(1)
(2)
(3)
1. Pushouts along M-morphisms are pullbacks. Given the above pushout (1) with
k ∈M, then (1) is also a pullback.
2. M-pushout–pullback decomposition. Given the above commutative diagram—
where (1)+(2) is a pushout, (2) is a pullback, w ∈M, and (l ∈M or k ∈M)—(1)
and (2) are pushouts and also pullbacks.
3. Cube pushout–pullback property. Given the above commutative cube (3)—where
all morphisms in the top and bottom faces are M-morphisms, the top face is a
pullback, and the front faces are pushouts—the following statement holds: the
bottom face is a pullback if and only if the back faces of the cube are pushouts:
4. Uniqueness of pushout complements. Given k : A →B ∈M and s : B →D,
there is, up to isomorphism, at most one C with l : A →C and u : C →D such
that (1) is a pushout.
△
All these HLR properties are valid in M-adhesive categories.
Theorem 4.22 (HLR properties in M-adhesive categories).
Given an M-
adhesive category (C, M), the following HLR properties are valid:
1. Pushouts along M-morphisms are pullbacks,
2. M-pushout–pullback decomposition,
3. Cube pushout–pullback property,
4. Uniqueness of pushout complements.
△
Proof. See [EEPT06], where these properties are shown for weak adhesive HLR
categories, but the proofs only use the vertical van Kampen property, i.e., are also
valid in M-adhesive categories.
⊓⊔

76
4 Adhesive and M-Adhesive Categories
4.3.2 Additional HLR Properties
The following additional HLR properties are essential to prove the main results for
graph transformation and HLR systems in [EEPT06]. For the Parallelism Theorem
(see Theorems 2.26 and 5.26), binary coproducts compatible with M are required
in order to construct parallel rules. Initial pushouts are used in order to deﬁne the
gluing condition and to show that consistency in the Embedding Theorem (see The-
orems 2.37 and 5.34) is not only suﬃcient, but also necessary. In connection with
the Concurrency Theorem (see Theorems 2.29 and 5.30) and for completeness of
critical pairs (see Theorems 2.41 and 5.41), an E′–M′ pair factorisation is used
such that the class M′ satisﬁes the M–M′ pushout–pullback decomposition prop-
erty. Moreover, a standard construction for E′–M′ pair factorisation uses an E–M′
factorisation of morphisms in C, where E′ is constructed from E using binary co-
products. For the Amalgamation Theorem (see Theorems 2.34 and 6.17), we need
eﬀective pushouts.
As far as we know, these additional HLR properties cannot be concluded from
the axioms of M-adhesive categories; at least we do not know proofs for nontrivial
classes E, E′, M, and M′.
Note that for M′ = M, the M–M′ pushout–pullback decomposition property is
the M pushout–pullback decomposition property, which is already valid in general
M-adhesive categories.
Deﬁnition 4.23 (Additional HLR properties). An M-adhesive category (C, M)
fulﬁlls the additional HLR properties if all of the following items hold:
A
B
K
f
e
m
1. Binary coproducts: C has binary coproducts.
2. E–M factorisation: Given a morphism class E, for
each f : A →B there is a factorisation over e : A →
K ∈E and m : K →B ∈M such that m ◦e = f, and
this factorisation is unique up to isomorphism.
A1
B
K
A2
f1
f2
e1
e2
m
3. E′–M′ pair factorisation: Given a morphism class
M′ and a class of morphism pairs with common
codomain E′, for each pair of morphisms f1 : A1 →
B, f2 : A2 →B there is a factorisation over e1 :
A1 →K, e2 : A2 →K, m : K →B with (e1, e2) ∈E′
and m ∈M′ such that m ◦e1 = f1 and m ◦e2 = f2.
4. Initial pushouts over M′: Given a morphism class
B
A
E
C
D
F
B
E
C
F
b
c
m
n
a
f
g
b∗
c∗
a
g
b∗
c∗
(1)
(2)
(3)
M′, for each f : A →
D ∈M′ there exists an
initial pushout (1) with
b, c ∈M. (1) is an ini-
tial pushout if the fol-
lowing condition holds:
for all pushouts (2) with
m, n ∈M there exist unique morphisms b∗, c∗∈M such that m◦b∗= b, n◦c∗= c,
and (3) is a pushout.

4.3 Results and Additional HLR Properties for M-Adhesive Categories
77
A
B
C
D
D′
A
B
C
D′
b
c
a
d
c′
e
d′
a
d′
b
c′
(4)
(5)
5. Eﬀective pushouts: Given a
pullback (4) and a pushout (5)
with all morphisms being M-
morphisms, also the induced
morphism e : D →D′ is an
M-morphism.
△
Remark 4.24. In the setting of eﬀective pushouts, the morphism e has to be a
monomorphism [LS05a]. But up to now we were not able to show that it is actually
an M-morphism if the class M does not contain all monomorphisms.
△
4.3.3 Finite Coproducts and E′–M′ Pair Factorisation
For the construction of coproducts, it often makes sense to use pushouts over M-
initial objects in the following sense.
Deﬁnition 4.25 (M-initial object). An initial object I in (C, M) is called M-initial
if for each object A ∈C the unique morphism iA : I →A is in M.
△
Note that if (C, M) has one M-initial object then all initial objects are M-initial
due to M being closed under isomorphisms and composition.
In the M-adhesive categories (Sets, M), (Graphs, M), (GraphsTG, M),
(ElemNets, M), and (PTNets, M) we have M-initial objects deﬁned by the empty
set, empty graphs, and empty nets, respectively. But in (AGraphsATG, M), there is
no M-initial object. The initial attributed graph (∅, TDSIG) with term algebra TDSIG
of the data type signature DSIG is not M-initial because the data type part of the
unique morphism (∅, TDSIG) →(G, D) is, in general, not an isomorphism.
The existence of an M-initial object implies that we have ﬁnite coproducts.
Fact 4.26 (Existence of ﬁnite coproducts). For each M-adhesive category (C, M)
with M-initial object, (C, M) has ﬁnite coproducts, where the injections into co-
products are in M.
△
Proof. It suﬃces to show this for the binary case.
I
A
B
A + B
(1)
iB
inA
iA
inB
The coproduct A + B of A and B can be constructed by the
pushout (1), which exists because of iA, iB ∈M. This also
implies inA, inB ∈M, since M-morphisms are closed under
pushouts in M-adhesive categories.
⊓⊔
Note that an M-adhesive category may still have coproducts even if it does not
have an M-initial object. For example, the M-adhesive category (AGraphsATG, M)
has no M-initial object, but ﬁnite coproducts, as shown in [EEPT06].
For the construction of parallel rules in [EEPT06] the compatibility of the mor-
phism class M with (ﬁnite) coproducts was required. In fact, ﬁnite coproducts (if
they exist) are always compatible with M in M-adhesive categories, as shown in
[EHL10].

78
4 Adhesive and M-Adhesive Categories
Fact 4.27 (Finite coproducts compatible with M). For each M-adhesive category
(C, M) with ﬁnite coproducts, ﬁnite coproducts are compatible with M, i.e., fi ∈M
for i = 1, . . . , n implies that f1 + · · · + fn ∈M.
△
Proof. It suﬃces to show this for the binary case n = 2. For f : A →B ∈M, we
A
B
A + C
B + C
C
D
B + C
B + D
f
f+idC
g
idB+g
(1)
(2)
have pushout (1) with (f + idC) ∈
M, since M-morphisms are closed
under pushouts. Similarly, we have
(idB + g) ∈M in pushout (2) for
g : C →D. Hence, (f +g) = (idB+
g) ◦(f + idC) ∈M by composition
of M-morphisms.
⊓⊔
Based on an E–M′ factorisation and binary coproducts, we obtain a standard
construction for an E′–M′ pair factorisation with E′ induced by E.
Fact 4.28 (Construction of E′–M′ pair factorisation). Given a category C with an
E–M′ factorisation and binary coproducts, C has also an E′–M′ pair factorisation
for the class E′ = {(eA : A →C, eB : B →C) | eA, eB ∈C with induced e : A + B →
C ∈E}.
△
Proof. Given fA : A →D and fB : B →D with induced f : A + B →D, we
consider the E–M′ factorisation f = m ◦e of f with e ∈E and m ∈M′, and deﬁne
A
D
C
B
A + B
f
inA
inB
fA
fB
eA
eB
m
e
eA = e ◦inA and eB = e ◦inB.
Then (eA, eB) ∈E′ and m ∈M′ deﬁnes an E′–M′
pair factorisation of (fA, fB) which is unique up to iso-
morphism, since each other E′–M′ pair factorisation
also leads to an E–M′ factorisation via the induced mor-
phism in E, and E–M′ factorisations are unique up to
isomorphism.
⊓⊔
4.4 Finitary M-Adhesive Categories
Although in most application areas of graph and model transformations only ﬁnite
models are considered, the theory has been developed for general graphs, including
also inﬁnite graphs. It is implicitly assumed that the results can be restricted to ﬁnite
graphs and to attributed graphs with a ﬁnite graph part, where the data algebra may
be inﬁnite. Obviously, not only Sets and Graphs are M-adhesive categories, but
also the full subcategories Setsﬁn of ﬁnite sets and Graphsﬁn of ﬁnite graphs. In this
section, we consider the general restriction of an M-adhesive category (C, M) to
ﬁnite objects, leading to a category (Cﬁn, Mﬁn), where Mﬁn is the restriction of M
to morphisms between ﬁnite objects. This section is based on [GBEG14].

4.4 Finitary M-Adhesive Categories
79
4.4.1 Basic Notions of Finitary M-Adhesive Categories
Intuitively, we are interested in those objects where the graph or net part is ﬁnite.
An object A is called ﬁnite if A has (up to isomorphism) only a ﬁnite number of
M-subobjects, i.e., only ﬁnite many M-morphisms m : A′ →A up to isomorphism.
Deﬁnition 4.29 (M-subobject and ﬁnite object). Given an object A in an M-
A′
1
A′
2
A
m1
i
m2
adhesive category (C, M), an M-subobject of A is an iso-
morphism class of morphisms m : A′ →A ∈M, where
m1 : A′
1 →A and m2 : A′
2 →A belong to the same M-subobject
of A if there is an isomorphism i: A′
1 ˜→A′
2 with m1 = m2 ◦i. By
MSub(A), we denote the set of all M-subobjects of A.
A is called ﬁnite if it has ﬁnitely many M-subobjects.
△
Finitary M-adhesive categories are M-adhesive categories with ﬁnite objects
only. Note that the notion “ﬁnitary” depends on the class M of monomorphisms
and “C is ﬁnitary” must not be confused with “C is ﬁnite” in the sense of having a
ﬁnite number of objects and morphisms.
Deﬁnition 4.30 (Finitary M-adhesive category). An M-adhesive category (C, M)
is called ﬁnitary if each object A ∈C is ﬁnite.
△
In (Sets, Mmono), the ﬁnite objects are the ﬁnite sets. Graphs in (Graphs, Mmono)
and (GraphsTG, Mmono) are ﬁnite if the node and edge sets have ﬁnite cardinal-
ity, while TG itself may be inﬁnite. Petri nets in (ElemNets, Mmono) and (PTNets,
Mmono) are ﬁnite if the number of places and transitions is ﬁnite. A typed attributed
graph GT = ((GE, DG), type) in (AGraphsATG, Mmono−iso) is ﬁnite if the graph part
of GT, i.e., all vertex and edge sets except the set VD of data vertices generated from
DG, is ﬁnite, while the attributed type graph ATG or the data type part DG may be
inﬁnite, because M-morphisms are isomorphisms on the data type part.
Finite M-intersections are a generalisation of pullbacks to an arbitrary but ﬁnite
number of M-subobjects and, thus, a special case of limits.
Deﬁnition 4.31 (Finite M-intersection). Given an M-adhesive category (C, M)
A′
A
Ai
Aj
B
n′
i
mi
n′
j
mj
a
ni
nj
and morphisms mi : Ai →B ∈M with the same
codomain object B and i ∈I for a ﬁnite set I, a
ﬁnite M-intersection of (mi)i∈I is an object A with
morphisms ni : A →Ai, such that mi ◦ni = mj ◦
nj for all i, j ∈I and for each other object A′ with
morphisms (n′
i : A′ →Ai)i∈I with mi ◦n′
i = mj ◦n′
j
for i, j ∈I there is a unique morphism a : A′ →A
with ni ◦a = n′
i for all i ∈I.
△
Remark 4.32. Note that ﬁnite M-intersections can be constructed by iterated pull-
backs. Hence, they always exist in M-adhesive categories. Moreover, since pull-
backs preserve M-morphisms, the morphisms ni are also in M.
△

80
4 Adhesive and M-Adhesive Categories
4.4.2 Additional HLR Properties in Finitary M-Adhesive
Categories
In the case of a ﬁnitary M-adhesive category (C, M), we are able to show that the
additional HLR properties from Def. 4.23 are valid for suitable classes E and E′,
and M′ = M.
4.4.2.1 Binary Coproducts
For ﬁnitary M-adhesive categories with an M-initial object, we directly obtain bi-
nary coproducts.
Fact 4.33 (Binary coproducts). Given a ﬁnitary M-adhesive category (C, M) with
M-initial object, C has binary coproducts.
△
Proof. This follows directly from Fact 4.26.
⊓⊔
4.4.2.2 E–M Factorisation
The reason for the existence of an E–M factorisation of morphisms in ﬁnitary
M-adhesive categories is the fact that we only need ﬁnite intersections of M-
subobjects, and no inﬁnite intersections as required for general M-adhesive cate-
gories. Moreover, we ﬁx the choice of the class E to extremal morphisms w. r. t. M.
Deﬁnition 4.34 (Extremal E–M factorisation). Given an M-adhesive category
A
B
B
f
e
m
(C, M), the class E of all extremal morphisms w. r. t. M is de-
ﬁned by E := {e ∈C | ∀m, g ∈C, m ◦g = e : m ∈M ⇒
m isomorphism}.
For a morphism f : A →B in C, an extremal E–M fac-
torisation of f is given by an object B and morphisms e : A →B ∈E and
m: B →B ∈M such that m ◦e = f.
△
Remark 4.35. In several example categories, the class E consists of all epimor-
phisms. But this is not necessarily the case for extremal morphisms w. r. t. M, as
shown below.
If we require M to be the class of all monomorphisms and consider only epimor-
phisms e, g in the deﬁnition of E, then E is the class of all extremal epimorphisms
in the sense of [AHS90].
△
Fact 4.36 (Existence of extremal E–M factorisation). Given a ﬁnitary M-ad-
hesive category (C, M), we can construct an extremal E–M factorisation for each
morphism in C.
△

4.4 Finitary M-Adhesive Categories
81
Construction 4.37. For f : A →B consider all M-subobjects mi : Bi →B such that
A
B
Bi
B
f
ei
mi
e
m
mi
there exists ei : A →Bi with f = mi ◦ei, leading
to a suitable ﬁnite index set I. Now m: B →B is
constructed as an M-intersection of (mi)i∈I and
e : A →B is the induced unique morphism with
mi ◦e = ei for all i ∈I.
△
Proof. See Appendix B.2.1.
⊓⊔
Fact 4.38 (Uniqueness of extremal E–M factorisation). In an M-adhesive cate-
gory (C, M), extremal E–M factorisations are unique up to isomorphism.
△
Proof. See Appendix B.2.2.
⊓⊔
In the categories (Sets, M), (Graphs, M), (GraphsTG, M), (ElemNets, M), and
(PTNets, M) with the classes M of all monomorphisms, the extremal E–M fac-
torisation is exactly the well-known epi–mono factorisation of morphisms which
also works for inﬁnite objects, because these categories have not only ﬁnite but also
general intersections.
For (AGraphsATG, M), the extremal E–M factorisation of (fG, fD) : (G, D) →
(G′, D′) with ﬁnite (or inﬁnite) G and G′ is given by ( fG, fD) = (mG, mD) ◦(eG, eD),
where eG is an epimorphism, mG a monomorphism, and mD an isomorphism. In
general, eD, and hence also (eG, eD), is not an epimorphism, since eD has to be
essentially the same as fD, because mD is an isomorphism. This means that the class
E, which depends on M, is not necessarily a class of epimorphisms.
4.4.2.3 E′–M Pair Factorisation
For ﬁnitary M-adhesive categories, we consider the special case M′ = M and use
the extremal E–M factorisation to construct an E′–M pair factorisation in a standard
way.
Fact 4.39 (Existence and uniqueness of E′–M pair factorisation). Given a ﬁni-
tary M-adhesive category (C, M) with an M-initial object (or ﬁnite coproducts),
we can construct a unique E′–M pair factorisation for each pair of morphisms in
C with the same codomain, where E′ = {(eA : A →C, eB : B →C) | eA, eB ∈C with
induced e: A + B →C ∈E}.
△
Proof. This follows directly from Fact 4.28.
⊓⊔
4.4.2.4 Initial Pushouts
As with the extremal E–M factorisation, we are able to construct initial pushouts in
ﬁnitary M-adhesive categories by ﬁnite M-intersections of M-subobjects.

82
4 Adhesive and M-Adhesive Categories
Fact 4.40 (Initial pushouts). A ﬁnitary M-adhesive category has initial pushouts.
△
Construction 4.41. Given m : L →G, we consider all those M-subobjects bi : Bi →
L of L and ci : Ci →G of G such that there is a pushout (Pi) over m. Since L and G
B
Bi
L
C
Ci
G
B
L
C
G
ui
vi
bi
ci
a
ai
m
b
c
a
m
b
c
(Qi)
(Pi)
(1)
are ﬁnite this leads to a ﬁ-
nite index set I for all (Pi)
with i ∈I. Now construct
b : B →L as the ﬁnite M-
intersection of (bi)i∈I and
c : C →G as the ﬁnite
M-intersection of (ci)i∈I.
Then there is a unique a: B →C such that (Qi) commutes for all i ∈I and the outer
diagram (1) is the initial pushout over m.
△
Proof. See Appendix B.2.3.
⊓⊔
4.4.2.5 Additional HLR Properties
The following theorem summarises that, except for eﬀective pushouts, the additional
HLR properties from Def. 4.23 are valid for all ﬁnitary M-adhesive categories.
Theorem 4.42 (Additional HLR properties in ﬁnitary M-adhesive categories).
Given a ﬁnitary M-adhesive category (C, M), the following additional HLR prop-
erties hold:
1. (C, M) has initial pushouts.
2. (C, M) has a unique extremal E–M factorisation, where E is the class of all
extremal morphisms w. r. t. M.
If (C, M) has an M-initial object, we also have that:
3. (C, M) has ﬁnite coproducts.
4. (C, M) has a unique E′–M′ pair factorisation for the classes M′ = M and E′
induced by E.
△
Proof. Item 1 follows from Fact 4.40, Item 2 follows from Facts 4.36 and 4.38,
Item 3 follows from Fact 4.33, and Item 4 follows from Fact 4.39.
⊓⊔
For a concrete ﬁnitary M-adhesive category, we still need to show that it has
eﬀective pushouts to ensure all additional HLR properties from Def. 4.23.
4.4.3 Finitary Restriction of M-Adhesive Categories
In this subsection, we show that for any M-adhesive category (C, M) the restriction
(Cﬁn, Mﬁn) to ﬁnite objects is a ﬁnitary M-adhesive category, where Mﬁn is the

4.4 Finitary M-Adhesive Categories
83
corresponding restriction of M. In this case, the inclusion functor I : Cﬁn →C
preserves M-morphisms, such that ﬁnite objects in Cﬁn w. r. t. Mﬁn are exactly the
ﬁnite objects in C w. r. t. M.
Deﬁnition 4.43 (Finitary restriction of M-adhesive category). Given an M-ad-
hesive category (C, M) the restriction to all ﬁnite objects of (C, M) deﬁnes the
full subcategory Cﬁn of C, and (Cﬁn, Mﬁn) with Mﬁn = M ∩Cﬁn is called ﬁnitary
restriction of (C, M).
△
Remark 4.44. Note that an object A in C is ﬁnite in (C, M) if and only if A is ﬁ-
nite in (Cﬁn, Mﬁn). Even if M is the class of all monomorphisms in C, Mﬁn is not
necessarily the class of all monomorphisms in Cﬁn.
△
In order to prove that (Cﬁn, Mﬁn) is an M-adhesive category, we show that the
inclusion functor Iﬁn : Cﬁn →C creates and preserves pushouts and pullbacks along
Mﬁn and M, respectively.
Deﬁnition 4.45 (Creation and preservation of pushouts and pullbacks). Given
an M-adhesive category (C, M) and a full subcategory C′ of C with M′ = M ∩C′,
an inclusion functor I : C′ →C creates pushouts along M if for each pushout (1)
in C with f, h ∈C′ and f ∈M′ we have that D ∈C′ such that (1) is a pushout in
C′.
A
B
C
D
(1)
h
k
f
g
I creates pullbacks along M if for each pullback (1) in C
with g, k ∈C′ and g ∈M′ we have that A ∈C′ such that (1) is
a pullback in C′.
I preserves pushouts (pullbacks) along M′ if each pushout
(pullback) (1) in C′ with f ∈M′ (g ∈M′) is also a pushout
(pullback) in C with f ∈M (g ∈M).
△
Fact 4.46 (Creation and preservation of pushouts and pullbacks). Given an M-
adhesive category (C, M), the inclusion functor Iﬁn : Cﬁn →C creates pushouts
and pullbacks along M and preserves pushouts and pullbacks along Mﬁn.
△
Proof. 1. Iﬁn creates pushouts along M. Given pushout (1) in C with A, B,C ∈Cﬁn
and f ∈M, also g ∈M. It remains to show that D ∈Cﬁn.
A′
B′
A
B
C′
D′
C
D
f ′
a
h′
k′
b
f
h
g′
c
d
g
k
For any subobject d : D′ →D ∈M
we obtain subobjects b : B′ →B ∈
M and c : C′ →C ∈M by pull-
back constructions in the front faces
of the cube. Now we construct the
back faces as pullbacks with subob-
ject a : A′ →A ∈M, and the M-van
Kampen property implies that the top
face is a pushout.
Consider the M-subobject function Φ : MSub(D) →MSub(B) × MSub(C)
deﬁned by Φ([d]) = ([b], [c]) in the construction above. Φ is injective since
pushouts are unique up to isomorphism. MSub(B) and MSub(C) are ﬁnite, hence
also MSub(B)×MSub(C) is ﬁnite, and injectivity of Φ implies that also MSub(D)
is ﬁnite. This means that D ∈Cﬁn.
www.allitebooks.com

84
4 Adhesive and M-Adhesive Categories
2. Iﬁn creates pullbacks along M. Given pullback (1) in C with B,C, D ∈Cﬁn and
g ∈M, also f ∈M. Moreover, each M-subobject of A is also an M-subobject
of B, because f ∈M. Hence B ∈Cﬁn implies that A ∈Cﬁn and (1) is also a
pullback in Cﬁn with f ∈Mﬁn.
3. Iﬁn preserves pushouts along Mﬁn. Given pushout (1) in Cﬁn with f ∈Mﬁn, also
f ∈M. Since Iﬁn creates pushouts along M by Item 1, the pushout (1′) of f ∈M
and h in C is also a pushout in Cﬁn. By uniqueness of pushouts this means that
(1) and (1′) are isomorphic and hence (1) is also a pushout in C.
4. Similarly, we can show that Iﬁn preserves pullbacks along Mﬁn using the fact that
Iﬁn creates pullbacks along M, as shown in Item 2.
⊓⊔
Using this result we are able to show that the ﬁnitary restriction of an M-adhesive
category leads to a ﬁnitary M-adhesive category.
Theorem 4.47 (Finitary restriction). The ﬁnitary restriction (Cﬁn, Mﬁn) of an M-
adhesive category (C, M) is a ﬁnitary M-adhesive category.
△
Proof. An object A in C is ﬁnite in (C, M) if and only if it is ﬁnite in (Cﬁn, Mﬁn).
Hence, all objects in (Cﬁn, Mﬁn) are ﬁnite. Moreover, Mﬁn is a class of monomor-
phisms, contains all identities and is closed under composition, because this is valid
for M. (Cﬁn, Mﬁn) has pushouts along Mﬁn because (C, M) has pushouts along M
and Iﬁn creates pushouts along M by Fact 4.46. This also implies that Mﬁn is pre-
served by pushouts along Mﬁn in Cﬁn. Similarly, (Cﬁn, Mﬁn) has pullbacks along
Mﬁn and Mﬁn is preserved by pullbacks along Mﬁn in Cﬁn. Finally, the M-van
Kampen property of (C, M) implies that of (Cﬁn, Mﬁn) using the fact that Iﬁn pre-
serves pushouts and pullbacks along Mﬁn and creates pushouts and pullbacks along
M.
⊓⊔
A direct consequence of Theorem 4.47 is the fact that ﬁnitary restrictions of
(Sets, M), (Graphs, M), (GraphsTG, M), (ElemNets, M), (PTNets, M), and
(AGraphsATG, M) are all ﬁnitary M-adhesive categories satisfying not only the
axioms of M-adhesive categories, but also the additional HLR properties as stated
in Theorem 4.42, except for eﬀective pushouts.
For an adhesive category C, which is based on the class of all monomorphisms,
there may be monomorphisms in Cﬁn which are not monomorphisms in C. Thus it
is not clear whether the ﬁnite objects in C and Cﬁn are the same. This problem is
avoided for M-adhesive categories, where ﬁnitariness depends on M. For adhesive
categories, the restriction to ﬁnite objects leads to an adhesive category if the inclu-
sion functor I : Cﬁn →C preserves monomorphisms. Currently, we are not aware of
any adhesive category failing this property, or whether this can be shown in general.
4.4.4 Functorial Constructions of Finitary M-Adhesive Categories
Similarly to general M-adhesive categories, also ﬁnitary M-adhesive categories are
closed under product, slice, coslice, functor, and comma categories under suitable

4.5 Preservation of Additional HLR Properties
85
conditions [EEPT06]. It suﬃces to show this for functor and comma categories,
because all others are special cases.
Fact 4.48 (Finitary functor category). Given a ﬁnitary M-adhesive category (C,
M) and a category X with a ﬁnite class of objects, also the functor category
(Funct(X, C), MF) is a ﬁnitary M-adhesive category, where MF is the class of
all M-functor transformations t : F′ →F, i.e., t(X): F′(X) →F(X) ∈M for all
objects X in X.
△
Proof. (Funct(X, C), MF) is an M-adhesive category (see [EEPT06]) and it re-
mains to show that each F : X →C is ﬁnite. W. l. o. g. we have objects X1, . . . , Xn
in X. We want to show that there are only ﬁnitely many M-functor transformations
t : F′ →F up to isomorphism. Since F(Xk) ∈C and C is a ﬁnitary M-adhesive
category we have ik ∈N diﬀerent choices for t(Xk) : F′(Xk) →F(Xk) ∈M. Hence,
altogether we have at most i = i1 · . . . · in ∈N diﬀerent t : F′ →F up to isomor-
phism.
⊓⊔
For inﬁnite, even discrete, X, the functor category is not ﬁnitary. For example,
consider C = Setsﬁn. The object (2i)i∈N with 2i = {1, 2} has an inﬁnite number of
subobjects (1i)i∈N with 1i = {1}, because in each component i ∈N we have two
choices of injective functions f1/2 : {1} →{1, 2}. Hence (2i)i∈N is not ﬁnite and
Funct(X, C) is not ﬁnitary.
Fact 4.49 (Finitary comma category). Given ﬁnitary M-adhesive categories (A,
M1), (B, M2) and functors F : A →C, G : B →C, where F preserves
pushouts along M1 and G preserves pullbacks along M2, the comma category
ComCat(F,G; I) with M = (M1×M2)∩ComCat(F,G; I) is a ﬁnitary M-adhesive
category.
△
Proof. ComCat(F,G; I) is an M-adhesive category (see [EEPT06]). It remains to
show that each object (A, B, op =
h
opk : F(A) →G(B)
i
k∈I) is ﬁnite.
F(Ai)
G(Bj)
F(A)
G(B)
(1)
opk
i,j
opk
F(m1,i)
G(m2, j)
By assumption, A and B are ﬁnite with a ﬁnite
number of subobjects m1,i : Ai →A ∈M1 for i ∈I1
and m2,j : Bj →B ∈M2 for j ∈I2. Hence, we have
at most |I1|·|I2| M-subobjects of (A, B, op), where for
each i, j, k there is at most one opk
i,j such that diagram
(1) commutes. This is due to the fact that G preserves
pullbacks along M2, and therefore G(m2,j) is a monomorphism in C.
⊓⊔
Remark 4.50. Note that I in ComCat(F,G; I) is not required to be ﬁnite.
△
4.5 Preservation of Additional HLR Properties
Similarly to the special case of ﬁnitary M-adhesive categories, also M-adhesive
categories are closed under diﬀerent categorical constructions. This means that we

86
4 Adhesive and M-Adhesive Categories
can construct new M-adhesive categories from given ones. In this section, we anal-
yse how far also the additional HLR properties for M-adhesive categories deﬁned
in Def. 4.23 can be obtained from the categorical constructions if the underlying
M-adhesive categories fulﬁll these properties. This work is based on [PEL08] and
extended to general comma categories and subcategories. Here, we only state the
results; the proofs can be found in Appendix B.4, and for examples, see [PEL08].
4.5.1 Binary Coproducts
In most cases, binary coproducts can be constructed in the underlying categories,
with some compatibility requirements for the preservation of binary coproducts.
Note that we do not have to analyse the compatibility of binary coproducts with M,
as done in [PEL08], since this is a general result in M-adhesive categories, as shown
in Fact 4.27.
Fact 4.51. If the M-adhesive categories (C, M1), (D, M2), and (Cj, Mj) for j ∈J
have binary coproducts then also the following M-adhesive categories have binary
coproducts:
1. the general comma category (G, (×j∈J Mj) ∩MorG), if for all i ∈I Fi preserves
binary coproducts,
2. any full subcategory (C′, M1|C′) of C, if
(i) the inclusion functor reﬂects binary coproducts or
(ii) C′ has an initial object I and, in addition, we have general pushouts in C′ or
iA : I →A ∈M for all A ∈C′,
3. the comma category (F, (M1 × M2) ∩MorF), if F : C →X preserves binary
coproducts,
4. the product category (C × D, M1 × M2),
5. the slice category (C\X, M1 ∩MorC\X),
6. the coslice category (X\C, M1 ∩MorX\C), if C has general pushouts,
7. the functor category ([X, C], M1-functor transformations).
△
Proof. See Appendix B.4.1.
⊓⊔
4.5.1.1 Epi–M Factorisation
For epi–M factorisations, we obtain the same results as for E′–M′ pair factorisa-
tions by replacing the class of morphism pairs E′ by the class of all epimorphisms
and M′ by M. We do not explicitely state these results here, but they can be easily
deduced from the results in the following subsection.

4.5 Preservation of Additional HLR Properties
87
4.5.1.2 E′–M′ Pair Factorisation
For most of the categorical constructions, the E′–M′ pair factorisation from the
underlying categories is preserved. But for functor categories, we need a stronger
property, the E′–M′ diagonal property, for this result.
Deﬁnition 4.52 (Strong E′–M′ pair factorisation). An E′–M′ pair factorisation
B
A
K
C
L
e
e′
n
m
d
b
a
is called strong if the following E′–M′ diagonal property
holds:
Given (e, e′) ∈E′, m ∈M′, and morphisms a, b, n as
shown in the following diagram, with n ◦e = m ◦a and
n ◦e′ = m ◦b, there exists a unique d : K →L such that
m ◦d = n, d ◦e = a, and d ◦e′ = b.
△
Fact 4.53. In an M-adhesive category (C, M), the following properties hold:
1. If (C, M) has a strong E′–M′ pair factorisation, then the E′–M′ pair factorisa-
tion is unique up to isomorphism.
B1
A1
K1
C1
B2
A2
K2
C2
e1
e′
1
m1
e2
e′
2
m2
b
a
d
c
g1
g2
f1
f2
2. A strong E′–M′ pair factorisation is
functorial, i.e., given morphisms a, b, c,
f1, g1, f2, g2 as shown in the right di-
agram with c ◦f1 =
f2 ◦a and c ◦
g1 = g2 ◦b, and E′–M′ pair factori-
sations ((e1, e′
1), m1) and ((e2, e′
2), m2) of
f1, g1 and f2, g2, respectively, there ex-
ists a unique d : K1 →K2 such that
d ◦e1 = e2 ◦a, d ◦e′
1 = e′
2 ◦b, and
c ◦m1 = m2 ◦d.
△
Proof. See [PEL08].
⊓⊔
Fact 4.54. Given M-adhesive categories (Cj, Mj), (C, M1), and (D, M2) with E′
j–
M′
j, E′
1–M′
1, and E′
2–M′
2 pair factorisations, respectively, the following M-adhesive
categories have an E′–M′ pair factorisation and preserve strongness:
1. the general comma category (G, (×j∈J Mj) ∩MorG) with M′ = (×j∈J M′
j) and
E′ = {((e j, ), (e′
j)) | (ej, e′
j) ∈E′
j} ∩(MorG × MorG), if Gi(M′
ℓi) ⊆Isos for all
i ∈I,
2. any full subcategory (C′, M1|C′) of C with M′ = M′
1|C′ and E′ = E′
1|(C′×C′), if
the inclusion functor reﬂects the E′
1–M′
1 pair factorisation,
3. the comma category (F, (M1 × M2) ∩MorF) with M′ = (M′
1 × M′
2) ∩MorF
and E′ = {((e1, e2), (e′
1, e′
2)) | (e1, e′
1) ∈E′
1, (e2, e′
2) ∈E′
2} ∩(MorF × MorF), if
G(M′
2) ⊆Isos,
4. the product category (C × D, M1 × M2) with M′ = M′
1 × M′
2 and E′ =
{((e1, e2), (e′
1, e′
2))| (e1, e′
1) ∈E′
1, (e2, e′
2) ∈E′
2},
5. the slice category (C\X, M1 ∩MorC\X) with M′ = M′
1 ∩MorC\X and E′ =
E′
1 ∩(MorC\X × MorC\X),

88
4 Adhesive and M-Adhesive Categories
6. the coslice category (X\C, M1 ∩MorX\C) with M′ = M′
1 ∩MorX\C and E′ =
E′
1 ∩(MorX\C × MorX\C), if M′
1 is a class of monomorphisms,
7. the functor category ([X, C], M1-functor transformations) with the class M′ of
all M′
1-functor transformations and E′ = {(e, e′) | e, e′ functor transformations,
(e(x), e′(x)) ∈E′
1 for all x ∈X}, if E′
1–M′
1 is a strong pair factorisation in C.
△
Proof. See Appendix B.4.2.
⊓⊔
4.5.1.3 Initial Pushouts
In general, the construction of initial pushouts from the underlying categories is
complicated since the existence of the boundary and context objects have to be
ensured. In many cases, this is only possible under very strict limitations.
Fact 4.55. If the M-adhesive categories (C, M1), (D, M2), and (Cj, Mj) for j ∈J
have initial pushouts over M′
1, M′
2, and M′
j, respectively, then also the following
M-adhesive categories have initial pushouts over M′-morphisms:
1. the general comma category (G, (×j∈J Mj)∩MorG) with M′ = ×j∈J M′
j∩MorG,
if for all i ∈I Fi preserves pushouts along Mki-morphisms and Gi(Mℓi) ⊆Isos,
2. any full subcategory (C′, M1|C′) of C with M′ = M′
1|C′, if the inclusion functor
reﬂects initial pushouts over M′-morphisms,
3. the comma category (F, (M1 ×M2)∩MorF) with M′ = M′
1 ×M′
2, if F preserves
pushouts along M1-morphisms and G(M2) ⊆Isos,
4. the product category (C × D, M1 × M2) with M′ = M′
1 × M′
2,
5. the slice category (C\X, M1 ∩MorC\X) with M′ = M′
1 ∩MorC\X,
6. the coslice category (X\C, M1 ∩MorX\C) with M′ = M′
1 ∩MorX\C, if for f :
(A, a′) →(D, d′) ∈M′
(i) the initial pushout over f in C can be extended to a valid square in X\C or
(ii) a′ : X →A ∈M1 and the pushout complement of a′ and f in C exists,
7. the functor category ([X, C], M1-functor transformations) with M′ = M′
1-func-
tor transformations, if C has arbitrary limits and intersections of M1-subobjects.
△
Proof. See Appendix B.4.3.
⊓⊔
4.5.1.4 Eﬀective Pushouts
Eﬀective pushouts are also preserved by categorical constructions. Using Rem. 4.24,
we already know for the regarded situation that the induced morphism is a monomor-
phism. We only have to show that it is indeed an M-morphism. This is the case if
pullbacks, pushouts, and their induced morphisms are constructed componentwise.

4.5 Preservation of Additional HLR Properties
89
Fact 4.56. If the M-adhesive categories (C, M1), (D, M2), and (Cj, Mj) for j ∈J
have eﬀective pushouts then also the following M-adhesive categories have eﬀective
pushouts:
1. the general comma category (G, (×j∈J Mj) ∩MorG),
2. any full subcategory (C′, M1|C′) of C,
3. the comma category (F, (M1 × M2) ∩MorF),
4. the product category (C × D, M1 × M2),
5. the slice category (C\X, M1 ∩MorC\X),
6. the coslice category (X\C, M1 ∩MorX\C),
7. the functor category ([X, C], M1-functor transformations).
△
Proof. See Appendix B.4.4.
⊓⊔

Chapter 5
M-Adhesive Transformation Systems
In this chapter, we introduce M-adhesive transformation systems based on the M-
adhesive categories introduced in Chap. 4. They describe a powerful framework for
the deﬁnition of transformations of various models. By using a very general variant
of application conditions we extend the expressive power of the transformations. For
this chapter, we assume we have an M-adhesive category with initial object, binary
coproducts, an E–M factorisation and an E′–M pair factorisation (see Sect. 4.3).
In Sect. 5.1, we give a short introduction to conditions and constraints and de-
ﬁne rules and transformations with application conditions. This is the generali-
sation of the theory presented in Sect. 2.2 for graphs to M-adhesive categories.
Various results for transformations with application conditions, which were mo-
tivated on an intuitive level in Sect. 2.3, are presented in the general setting of
M-adhesive transformation systems in Sect. 5.2. As a running example, we use
a model of an elevator control and analyse its behaviour. Application conditions in-
duce additional dependencies for transformation steps. In Sect. 5.3, we show that
the notion of equivalence for transformation sequences with application conditions
can be described and analysed adequately using the notion of permutation equiv-
alence, which generalises the notion of switch equivalence. This chapter is based
on [EGH+14, EGH+12, Gol10, HCE14].
5.1 Rules and Transformations with Application Conditions
Nested conditions were introduced in [HP05, HP09] to express properties of objects
in a category. They are expressively equivalent to ﬁrst-order formulas on graphs.
Later, we will use them to express application conditions for rules to increase the ex-
pressiveness of transformations. We only present the general theory for M-adhesive
categories in this section; for examples of conditions and their constructions, see
Sect. 2.2.
Basically, a condition describes the existence or nonexistence of a certain struc-
ture for an object.
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_5
91

92
5 M-Adhesive Transformation Systems
Deﬁnition 5.1 (Condition). A (nested) condition ac over an object P is of the form
• ac = true,
• ac = ∃(a, ac′), where a : P →C is a morphism and ac′ is a condition over C,
• ac = ¬ac′, where ac′ is a condition over P,
• ac = ∧i∈Iaci, where (aci)i∈I with an index set I are conditions over P, or
• ac = ∨i∈Iaci, where (aci)i∈I with an index set I are conditions over P.
Moreover, false abbreviates ¬true, ∃a abbreviates ∃(a, true), and ∀(a, ac) abbre-
viates ¬ ∃(a, ¬ac).
△
A condition is satisﬁed by a morphism into an object if the required structure
exists, which can be veriﬁed by the existence of suitable morphisms.
Deﬁnition 5.2 (Satisfaction of condition). Given a condition ac over P a mor-
phism p : P →G satisﬁes ac, written p |= ac, if
• ac = true,
P
C
G
ac′
ac
a
p
q
• ac =
∃(a, ac′) and there exists a mor-
phism q ∈M with q ◦a = p and q |= ac′,
• ac = ¬ac′ and p ̸|= ac′,
• ac = ∧i∈Iaci and ∀i ∈I : p |= aci, or
• ac = ∨i∈Iaci and ∃i ∈I : p |= aci.
Two conditions ac and ac′ over P are semantically equivalent, denoted by ac  ac′,
if p |= ac ⇔p |= ac′ for all morphisms p with domain P.
△
As shown in [HP09, EHL10], conditions can be shifted over morphisms into
equivalent conditions over the codomain. For this shift construction, all E′-overlap-
pings of the codomain of the shift morphism and the codomain of the condition
morphism have to be collected.
Deﬁnition 5.3 (Shift over morphism). Given a condition ac over P and a mor-
phism b : P →P′, Shift(b, ac) is a condition over P′ deﬁned by
• Shift(b, ac) = true if ac = true,
P
C
P′
C′
(=)
ac
Shift(b, ac)
ac′
Shift(b′, ac′)
a
b
b′
a′
• Shift(b, ac)
=
∨(a′,b′)∈F
∃(a′, Shift(b′,
ac′)) if ac = ∃(a, ac′) and F = {(a′, b′) ∈
E′ | b′ ∈M, b′ ◦a = a′ ◦b},
• Shift(b, ac) = ¬Shift(b, ac′) if ac = ¬ac′,
• Shift(b, ac)
=
∧i∈IShift(b, aci) if ac
=
∧i∈Iaci, or
• Shift(b, ac) = ∨i∈IShift(b, aci) if ac = ∨i∈Iaci.
△
Fact 5.4. Given a condition ac over P and morphisms b : P →P′, b′ : P′ →P′′,
and p : P′ →G,
• p |= Shift(b, ac) if and only if p ◦b |= ac and
• Shift(b′, Shift(b, ac))  Shift(b′ ◦b, ac).

5.1 Rules and Transformations with Application Conditions
93
P
P′
P′′
G
Shift(b, ac)
Shift(b′, Shift(b, ac))
Shift(b′ ◦b, ac)
ac
b
b′
p◦b
p
△
Proof. We show the ﬁrst statement by structural induction.
Basis. The equivalence holds trivially for the condition ac = true.
Induction step. Consider a condition ac = ∃(a, ac′) with the corresponding shift
construction, Shift(b, ac), along morphism b.
P
C
P′
C′
G
ac
Shift
(b, ac)
ac′
Shift
(b′, ac′)
a
b
b′
a′
p
q
“⇒” Suppose p |= Shift(b, ac), i.e., there ex-
ists (a′, b′) ∈F such that p |= ∃(a′, Shift(b′,
ac′)). This means that there exists a morphism
q : C′ →G ∈M with q ◦a′ = p and
q |= Shift(b′, ac′). By induction hypothesis,
q◦b′ |= ac′, i.e., we have a morphism q◦b′ ∈M
with q ◦b′ ◦a = q ◦a′ ◦b = p ◦b and
p ◦b |= ∃(a, ac′) = ac.
P
C
P′
C′
G
ac
Shift
(b, ac)
ac′
Shift
(b′, ac′)
a
b
b′
a′
p
q′
q
“⇐” If p ◦b |=
∃(a, ac′) then there
exists q ∈M with p◦b = q◦a and q |= ac′.
Now consider the E′–M pair factorisation
((a′, b′), q′) of p and q. Since q, q′ ∈M, by
M-decomposition it follows that b′ ∈M,
and q′ ◦a′ ◦b = p ◦b = q ◦a = q′ ◦b′ ◦a
implies that a′ ◦b = b′ ◦a, i.e., (a′, b′) ∈F .
By induction hypothesis, q = q′ ◦b′ |= ac′
implies that q′ |= Shift(b′, ac′), and therefore p |= ∃(a′, Shift(b′, ac′)), i.e., p |=
Shift(b, ac).
Similarly, this holds for composed conditions.
The second statement follows directly from the ﬁrst one: for a morphism q :
P′′ →G, we have that q |= Shift(b′ ◦b, ac) ⇔q ◦b′ ◦b |= ac ⇔q ◦b′ |=
Shift(b, ac) ⇔q |= Shift(b′, Shift(b, ac)).
⊓⊔
As with the shift construction, we can also merge a condition over a morphism.
The diﬀerence lies in diﬀerent M-morphisms to be required, with a′ ∈M instead of
b′ ∈M. Additionally, b′ has to be from a distinguished morphism class O of match
morphisms.
Deﬁnition 5.5 (Merge over morphism). Given a condition ac over P and a mor-
phism b : P →P′, Merge(b, ac) is a condition over P′ deﬁned by
• Merge(b, ac) = true if ac = true,

94
5 M-Adhesive Transformation Systems
P
C
P′
C′
(=)
ac
Merge(b, ac)
ac′
Merge(b′, ac′)
a
b
b′
a′
• Merge(b, ac) = ∨(a′,b′)∈F ′ ∃(a′, Merge(b′,
ac′)) if ac = ∃(a, ac′) and F ′ = {(a′, b′) ∈
E′ | a′ ∈M, b′ ∈O, b′ ◦a = a′ ◦b},
• Merge(b, ac) = ¬Merge(b, ac′) if ac = ¬ac′,
• Merge(b, ac) = ∧i∈IMerge(b, aci) if ac =
∧i∈Iaci,
• Merge(b, ac) = ∨i∈IMerge(b, aci) if ac = ∨i∈Iaci.
△
The merge construction is used to specify schemata of conditions, which are in-
spired by a construction proposed in [KHM06] for negative application conditions.
An AC schema consists of the disjunction of all merges of a condition along E-
morphisms starting from its domain.
Deﬁnition 5.6 (AC schema). Given a condition ac over P and the set EP = {e ∈
E | dom(e) = P} of all E-morphisms with domain P, the AC schema ac over P is
given by ac = W
f∈EP ∃(f, Merge(f, ac)).
△
The satisfaction of an AC schema by a morphism only depends on the satisfaction
of one component of the corresponding E–M factorisation of the morphism. To
prove this, we ﬁrst show a slightly more general result for disjunctions over the set
EP .
Lemma 5.7 (Satisfaction of disjunction). Consider the set EP = {e ∈E | dom(e) =
P
P′
C
G
ac
ac′
e
ac′
f
p
e
m
f
g
P} of all E-morphisms with domain P, a condi-
tion ac = W
f∈EP ∃(f, ac′
f ) over P, and a mor-
phism p : P →G with an E–M factorisation
m◦e = p. Then p |= ac if and only if m |= ac′
e.
△
Proof. The following equivalences prove this:
p |= ac ⇔∃f ∈EP : p |= ∃(f, ac′
f )
(Def. 5.2)
⇔∃f ∈EP, g ∈M : g ◦f = p ∧g |= ac′
f
(Def. 5.2)
⇔m |= ac′
e ∧m ◦e = p
(Def. 4.23)
⊓⊔
Fact 5.8 (AC schema satisfaction). Given an AC schema ac over P and a mor-
phism p: P →G with an E–M factorisation m ◦e = p, p |= ac if and only if
m |= Merge(e, ac).
△
P
P′
G
ac
Merge(e, ac)
p
e
m
Proof. By Def. 5.6 we have that ac
=
W
f∈EP ∃(f, Merge(f, ac)). We can directly ap-
ply Lem. 5.7, leading to the required result.
⊓⊔
Remark 5.9. If p : P →G is an M-morphism, then the satisfaction of an AC schema
coincides with classical satisfaction, because the factorisation is trivially p = p ◦
id.
△

5.1 Rules and Transformations with Application Conditions
95
In contrast to conditions, constraints describe global requirements for objects.
They can be interpreted as conditions over the initial object, which means that a
constraint ∃(iC, true) with the initial morphism iC into C is valid for an object G if
there exists a morphism c : C →G. This constraint expresses that the existence of
C as a part of G is required.
Deﬁnition 5.10 (Constraint). Given an initial object A, a condition ac over A is
called a constraint.
△
The satisfaction of a constraint is that of the corresponding conditions, adapted
to the special case of a condition over an initial object.
Deﬁnition 5.11 (Satisfaction of constraint). Given a constraint ac (over the initial
object A), an object G satisﬁes ac, written G |= ac, if
• ac = true,
A
C
G
ac′
ac
iC
c
• ac =
∃(iC, ac′) and there exists a mor-
phism c ∈M with c |= ac′,
• ac = ¬ac′ and G ̸|= ac′,
• ac = ∧i∈Iaci and ∀i ∈I : G |= aci, or
• ac = ∨i∈Iaci and ∃i ∈I : G |= aci.
△
In [EEPT06], transformation systems based on a categorical foundation using
weak adhesive HLR categories were introduced which can be instantiated to vari-
ous graphs and graph-like structures. In addition, application conditions extend the
standard approach of transformations. Here, we present the theory of transforma-
tions in M-adhesive categories for rules with application conditions in general.
A rule is a general description of local changes that may occur in objects of
the transformation system. Mainly, it consists of some deletion part and some con-
struction part, deﬁned by the rule morphisms l and r, respectively. In addition, an
application condition restricts the application of this rule to certain objects.
Deﬁnition 5.12 (Rule). A rule p = (L
l
←−K
r
−→R, ac) consists of objects L,
K, and R, called left-hand side, gluing, and right-hand side, respectively, two mor-
phisms l and r with l, r ∈M, and a condition ac over L, called application condi-
tion.
△
A transformation describes the application of a rule to an object via a match. It
can only be applied if the match satisﬁes the application condition.
Deﬁnition 5.13 (Transformation). Given a rule p = (L
l
←−K
r
−→R, ac), an object
L
K
R
G
D
H
ac
l
r
f
g
m
k
n
(1)
(2)
G, and a morphism m : L →G, called
match, such that m |= ac, a direct trans-
formation G =
p,m
==⇒H from G to an object
H is given by the pushouts (1) and (2).
A sequence of direct transformations
is called a transformation.
△

96
5 M-Adhesive Transformation Systems
Remark 5.14. Note that for the construction of the pushout (1) we have to construct
the pushout complement of m ◦l, which is only possible if the so-called gluing
condition is satisﬁed (see [EEPT06]).
△
In analogy to the application condition over L, which is a pre-application con-
dition, it is also possible to deﬁne post-application conditions over the right-hand
side R of a rule. Since these application conditions over R can be translated into
equivalent application conditions over L (and vice versa), we can restrict our rules
to application conditions over L.
Deﬁnition 5.15 (Shift over rule). Given a rule p = (L
l
←−K
r
−→R, ac) and a
condition acR over R, L(p, acR) is a condition over L deﬁned by
• L(p, acR) = true if acR = true,
L
K
R
Y
Z
X
acR
ac′
L(p∗, ac′
R)
L(p, acR)
l
r
l∗
r∗
b
c
a
(2)
(1)
• L(p, acR) =
∃(b, L(p∗, ac′
R)) if
acR = ∃(a, ac′
R), a◦r has a pushout
complement (1), and p∗= (Y
l∗
←−
Z
r∗
−→X) is the derived rule by
constructing
pushout
(2);
L(p,
∃(a, ac′
R)) = false otherwise,
• L(p, acR) = ¬L(p, ac′
R) if acR = ¬ac′
R,
• L(p, acR) = ∧i∈IL(p, acR,i) if acR = ∧i∈IacR,i, or
• L(p, acR) = ∨i∈IL(p, acR,i) if acR = ∨i∈IacR,i.
Dually, for a condition acL over L we deﬁne R(p, acL) = L(p−1, acL), where the
inverse rule p−1 without application conditions is deﬁned by p−1 = (R
r
←−K
l
−→
L).
△
Fact 5.16. Given a transformation G =
p,m
==⇒H via a rule p = (L
l
←−K
r
−→R, ac)
L
K
R
G
D
H
G′
D′
H′
L(p, acR)
acR
l
r
f
g
m
k
n
m′
k′
n′
f ′
g′
and a condition acR over R, m |= L(p, acR)
if and only if n |= acR.
Dually, for a condition acL over L we
have that m |= acL if and only if n |=
R(p, acL).
Moreover,
for
any
transformation
G′ =
m′,p′
===⇒H′ we have that m′ |= Shift(m,
L(p, acR)) if and only if m′ |= L(p′, Shift(n,
acR)) for p′ = (G
f
←−D
g
−→H).
△
Proof. We show the ﬁrst statement by structural induction.
Basis. The equivalence holds trivially for the condition acR = true.
Induction step. Consider a condition acR = ∃(a, ac′
R).
Case 1: a ◦r has a pushout complement (1) and L(p, acR) = ∃(b, L(p∗, ac′
R))
from the construction.

5.1 Rules and Transformations with Application Conditions
97
“⇒” Suppose m |= L(p, acR), i.e., there exists q ∈M with q ◦b = m and
q |= L(p∗, ac′
R). Now construct pullback (3′) and obtain the induced morphism c′;
and by M-pushout–pullback decomposition (Theorem 4.22), both (2′) and (3′) are
pushouts. By uniqueness of pushout complements (Theorem 4.22), (2′) and (2) are
L
K
Y
Z′
G
D
L
K
R
Y
Z
X
G
D
H
l
r
l∗
r∗
b
c
a
q
p
f
g
m
n
l
b
c′
q
f
m
k
(2′)
(3′)
(2)
(1)
(3)
(4)
equivalent such
that there exists
a
pushout
(3)
equivalent to (3′)
and a decompo-
sition of G =
p,m
==⇒
H into pushouts
(1)–(4). By PO–
PB compatibility of M, q ∈M implies that p ∈M, and by induction hypothesis,
p |= ac′
R, i.e., n |= acR.
“⇐” If n |= acR, there exists p ∈M with p ◦a = n and p |= ac′
R. As above,
we can decompose G =
p,m
==⇒H into pushouts (1)–(4), with q ∈M, q ◦b = m, and
q |= L(p∗, ac′
R) such that m |= L(p, acR).
Case 2: a◦r has no pushout complement and L(p, acR) = false. Suppose n |= acR;
then we have, by the construction above, a pushout complement (1) of a ◦r, which
is a contradiction. Therefore, n ̸|= acR and m ̸|= false.
Similarly, this holds for composed conditions.
The second statement follows from the dual constructions.
For the third statement, we have that m′ |= Shift(m, L(p, acR)) ⇔m′ ◦m |=
L(p, acR) ⇔n′ ◦n |= acR ⇔n′ |= Shift(n, acR) ⇔m′ |= L(p′, Shift(n, acR)), which
follows from the ﬁrst statement, Fact 5.4, and the composition of pushouts.
⊓⊔
A set of rules constitutes an M-adhesive transformation system, and combined
with a start object an M-adhesive grammar. The language of such a grammar con-
tains all objects derivable from the start object.
Deﬁnition 5.17 (M-adhesive transformation system and grammar).
An M-
adhesive transformation system AS = (C, M, P) consists of an M-adhesive cate-
gory (C, M) and a set of rules P.
An M-adhesive grammar AG = (AS, S ) consists of an M-adhesive transforma-
tion system AS and a start object S .
The language L of an M-adhesive grammar AG is deﬁned by
L = {G | ∃transformation S =
∗⇒G via P}.
△
Example 5.18 (Elevator). Now we introduce our running example for this chapter,
an elevator control. The type of control we model is used in buildings where the
elevator transports people from or to one main stop; in our example this is the lowest
ﬂoor. This situation occurs, for example, in apartment buildings or multistory car
parks. Each ﬂoor in the building is equipped with a call button. Such external call
requests are served by the elevator only if it is in downwards mode in order to
transport people to the main stop. When inside the elevator, internal stop requests

98
5 M-Adhesive Transformation Systems
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
ext
floor
down
up
elevator
request
down
up
on
holds
int
ext
higher_than
next_up
G
TG
Fig. 5.1 The type graph TG and a model G of Elevator
floor
elevator
floor
floor
elevator
floor
floor
floor
request
elevator
floor
floor
request
elevator
floor
elevator
floor
floor
request
floor
elevator
floor
down
next_up
on
next_up
on
next_up
on
holds
next_up
on
holds
next_up
on
higher_than
holds
next_up
on
down
( ∃pos1
∃pos2)
∃pos3
∧
∧
∨
¬ ∃neg1
moveDown
floor
request
floor
floor
request
holds
int
holds
int
¬ ∃neg
intRequest
floor
request
floor
floor
request
down
elevator
holds
int
holds
int
down
on
∃pos
processIntDown
Fig. 5.2 Three rules for processing internal requests in the Elevator example
for each ﬂoor can be delivered. These are served as soon as the elevator car reaches
the requested ﬂoor, both in upwards and in downwards mode. As long as there are
remaining requests in the running direction, the direction of the elevator car is not
changed. If the elevator car arrives at a ﬂoor, all requests for this ﬂoor are deleted.
We model this system using typed graphs (see Sect. 2.1). In the right of Fig. 5.1,
the type graph TG for our elevator example is depicted. This type graph expresses
that an elevator car of type elevator exists, which can be on a speciﬁc floor.

5.1 Rules and Transformations with Application Conditions
99
floor
elevator
floor
floor
elevator
floor
floor
elevator
floor
floor
floor
request
elevator
floor
floor
request
elevator
floor
elevator
floor
floor
request
floor
elevator
floor
down
next_up
on
next_up
on
next_up
next_up
on
holds
next_up
on
holds
next_up
on
higher_than
holds
next_up
on
down
( ∃pos1
∃pos2)
∃pos3
∧
∧
∨
¬ ∃neg1
moveDown
r
l
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
ext
down
next_up
next_up
next_up
holds
ext
down
on
next_up
next_up
next_up
holds
ext
c1
b1
m1
G
H1
Fig. 5.3 Application of the rule moveDown
Moreover, the elevator can be in upwards or downwards mode. Floors are connected
by next_up edges expressing which ﬂoor is directly above another ﬂoor. Moreover,
higher_than edges express that a ﬂoor is arranged higher in the building than
another ﬂoor. Each ﬂoor can hold requests of two diﬀerent types. The ﬁrst type
is an external request expressing that an external call for the elevator car on this
ﬂoor is given. The second type is an internal request expressing that an internal
call from within the elevator car is given for stopping it on this ﬂoor.
In the left of Fig. 5.1, a graph G typed over this type graph TG is shown, describ-
ing a four story building, where the elevator car is on the second ﬂoor in downwards
mode with an external call request on the ground ﬂoor. Note that G contains alto-
gether six higher_than edges from each ﬂoor which is higher than another ﬂoor
(corresponding to the transitive closure of opposite edges of next_up); these are
not depicted.
In Fig. 5.2, three rules are shown modelling part of the elevator control for in-
ternal stop requests. Note that only the left- and right-hand sides of the rules are
depicted—the gluing consists of all nodes and edges occurring in both L and R. The
morphisms map the obvious elements by type and position and are therefore not
explicitly marked.

100
5 M-Adhesive Transformation Systems
At the top of Fig. 5.2, we have the rule moveDown describing that the elevator
car moves down one ﬂoor. The combined application condition on L consists of
three positive application conditions ( ∃posi for i = 1, 2, 3) and a negative one
(¬ ∃neg1). This combined application condition states that some request has to be
present on the next lower ﬂoor (pos1) or some other lower ﬂoor (pos2), no request
should be present on the elevator ﬂoor (neg1), and the elevator car is in downwards
mode (pos3). Note that both pos1 and pos2 are necessary because the satisfaction of
application conditions depends on injective morphisms.
As a second rule, intRequest describes that an internal stop request is made
on some ﬂoor under the condition that no internal request is already given for this
ﬂoor. The third rule processIntDown describes that an internal stop request is pro-
cessed for a speciﬁc ﬂoor under the condition that the elevator is on this ﬂoor and in
downwards mode.
In Fig. 5.3, the application of the rule moveDown to the graph G from Fig. 5.1 is
shown, where also the gluing graph of the rule is explicitly depicted. Note that the
match m1 satisﬁes the application condition, because m1 |= ∃pos2 for the request
on the lowest ﬂoor (remember the implicit higher_than edges between the ﬂoors),
m1 |= ∃pos3 since the elevator is in downwards mode, and m1 |= ¬ ∃neg1 with no
request on the current ﬂoor.
△
5.2 Results for Transformations with Application Conditions
In this section, we present the main important results for M-adhesive transforma-
tion systems for rules with application conditions, generalising the corresponding
well-known theorems for rules without application conditions [EEPT06] and with
negative application conditions [Lam10]. The intuition and motivation for these re-
sults has already been given in Sect. 2.3—here we now state the full deﬁnitions,
results and proofs. Note that the Local Church–Rosser, Parallelism, Concurrency,
Embedding, Extension and Local Conﬂuence Theorems are stated and proven in
[EGH+14, EGH+12] for the case of rules with application conditions; in addition,
we present new examples.
Most of the proofs are based on the corresponding statements for rules without
application conditions and Facts 5.4 and 5.16, stating that application conditions
can be shifted over morphisms and rules. The idea is the following: We switch from
transformations with application conditions to the corresponding transformations
transformations with ACs
transformations without ACs
result with ACs
result without ACs
without application
conditions, use the
results for transfor-
mations without ap-
plication conditions,
and lift the results without application conditions to the corresponding ones with ap-
plication conditions.

5.2 Results for Transformations with Application Conditions
101
In the following, let pi = (Li
li
←−Ki
ri
−→Ri, aci) be a rule with a left application
condition and pi = (Li
li
←−Ki
ri
−→Ri) the underlying plain rule for i ∈N. For
every direct transformation G =
pi,mi
===⇒H via such a rule pi, there is a direct trans-
formation G =
pi,mi
===⇒H via the underlying plain rule pi, called the underlying plain
transformation.
5.2.1 Local Church–Rosser and Parallelism Theorem
The Local Church–Rosser Theorem is concerned with parallel and sequential in-
dependence of direct transformations. We study under what conditions two direct
transformations applied to the same graph can be applied in arbitrary order, leading
to the same result.
For parallel independence of two direct transformations H1 ⇐
p1== G =
p2=⇒H2, the
ﬁrst obvious condition is that the underlying plain transformations have to be paral-
lel independent. In addition, we have to require that the matches of p2 and p1 in H1
and H2, respectively, satisfy the application conditions of the corresponding rule.
Deﬁnition 5.19 (Parallel independence). Two direct transformations G =
p1,m1
===⇒H1
and G =
p2,m2
===⇒H2 are parallel independent if there are morphisms d12 : L1 →D2
and d21 : L2 →D1 such that f2 ◦d12 = m1, f1 ◦d21 = m2, g2 ◦D12 |= ac1, and
g1 ◦d21 |= ac2.
L1
K1
R1
L2
K2
R2
G
D1
H1
D2
H2
ac1
ac2
l1
r1
f1
g1
m1
k1
n1
l2
r2
f2
g2
m2
k2
n2
d12
d21
△
Example 5.20. The pair H1 ⇐
moveDown,m1
========== G =
intRequest,m2
===========⇒H2 of direct transfor-
mations in Fig. 5.4 is parallel dependent. The left rule application is the one al-
ready considered in Fig. 5.3, while m2 matches the ﬂoor in the left-hand side of
intRequest to the current ﬂoor with the elevator. The morphisms d12 and d21 ex-
ist such that f1 ◦d21 = m2, f2 ◦d12 = m1, and m′
2 = g1 ◦d21 |= ¬ ∃neg. But
m′
1 = g2 ◦d12 ̸|= ¬ ∃neg1, since the rule intRequest added a request at the current
ﬂoor with the elevator forbidding the application of the rule moveDown. Therefore,
the transformations are parallel dependent. Note that the underlying plain transfor-
mations are parallel independent.
For sequential independence of transformations G =
p1=⇒H1 =
p2=⇒G′ we need the
sequential independence of the underlying plain rules. Moreover, the match of p2 in

102
5 M-Adhesive Transformation Systems
floor
elevator
floor
floor
elevator
floor
floor
elevator
floor
floor
floor
request
elevator
floor
floor
request
elevator
floor
elevator
floor
floor
request
floor
elevator
floor
down
next_up
on
next_up
on
next_up
next_up
on
holds
next_up
on
holds
next_up
on
higher_than
holds
next_up
on
down
( ∃pos1
∃pos2)
∃pos3
∧
∧
∨
¬ ∃neg1
moveDown
l
r
floor
request
floor
floor
floor
request
holds
int
holds
int
¬ ∃neg
r
l
m2
g2
f2
d12
d21
intRequest
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
ext
down
next_up
next_up
next_up
holds
ext
down
on
next_up
next_up
next_up
holds
ext
f1
g1
m1
G
H1
H2
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
request
down
on
next_up
next_up
next_up
holds
ext
int
holds
down
on
next_up
next_up
next_up
holds
ext
Fig. 5.4 Parallel dependent transformations
G has to satisfy its corresponding application condition and the co-match of p1 to G′
has to satisfy the shifted application condition R(p1, ac1). The deﬁnition of sequen-
tial independence for transformation steps with NACs goes back to [HHT96] for
graph transformation, and is generalised to adhesive systems in [LEOP08, Lam10].
Deﬁnition 5.21 (Sequential independence). Two direct transformations G =
p1,m1
===⇒
H1 =
p2,m2
===⇒G′ are sequentially independent if there are morphisms d12 : R1 →D2
and d21 : L2 →D1 such that f2 ◦d12 = n1, g1 ◦d21 = m2, g2 ◦d12 |= R(p1, ac1), and
f1 ◦d21 |= ac2.
R1
K1
L1
L2
K2
R2
H1
D1
G
D2
G′
ac1
ac2
r1
l1
g1
f1
n1
k1
m1
l2
r2
f2
g2
m2
k2
n2
d12
d21
△
Example 5.22. The sequence H2 =
processIntDown,m0
==============⇒G =
intRequest,m3
===========⇒H3 of direct
transformations in Fig. 5.5 is sequentially independent. Note that m0 matches the
ﬂoor in the left-hand side of processIntDown to the current ﬂoor with the elevator,
while m3 matches the ﬂoor of the left-hand side of intRequest to the ﬂoor one

5.2 Results for Transformations with Application Conditions
103
floor
request
floor
floor
floor
request
down
elevator
holds
int
holds
int
down
on
∃pos
processIntDown
l
r
floor
request
floor
floor
floor
request
holds
int
holds
int
¬ ∃neg
r
l
m3
g3
f3
d12
d21
intRequest
floor
floor
floor
floor
down
elevator
request
request
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
ext
down
on
next_up
next_up
next_up
holds
ext
down
on
next_up
next_up
next_up
holds
ext
int
holds
g0
f0
m0
n0
G
H2
H3
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
request
down
on
next_up
next_up
next_up
holds
ext
int
holds
down
on
next_up
next_up
next_up
holds
ext
Fig. 5.5 Sequentially independent transformations
level down. The morphisms d12 and d21 exist such that g0 ◦d21 = m3, f3 ◦d12 = n0,
g3 ◦d12 |= R(processIntDown, ∃pos), and f0 ◦d21 |= ¬ ∃neg.
△
In the case of parallel independence of two direct transformations via rules p1 and
p2, the parallel rule p1 + p2 can be deﬁned by binary coproducts of the components
of the rules.
Deﬁnition 5.23 (Parallel rule). Given rules p1 = (L1
l1
←−K1
r1
−→R1, ac1) and
p2 = (L2
l2
←−K2
r2
−→R2, ac2), the parallel rule p1 + p2 = (L1 + L2
l1+l2
←−K1 + K2
r1+r2
−→
L1
K1
R1
L2
K2
R2
L1 + L2
K1 + K2
R1 + R2
ac1
ac
ac2
l1+l2
r1+r2
l1
r1
l2
r2
iK1
iK2
iL1
iL2
iR1
iR2
R1 + R2, ac) is deﬁned by
the componentwise coprod-
ucts of the left-hand sides,
glueings,
and
right-hand
sides including the mor-
phisms, and ac = Shift(iL1,
ac1) ∧L(p1 + p2, Shift(iR1,
R(p1, ac1))) ∧Shift(iL2, ac2)
∧L(p1 + p2, Shift(iR2, R(p2, ac2))).
A direct transformation via a parallel rule is called parallel transformation.
△
The parallel rule is well deﬁned and, in particular, its morphisms are actually
M-morphisms.
Fact 5.24. The morphisms l1+l2 : K1+K2 →L1+L2 and r1+r2 : K1+K2 →R1+R2
are in M.
△
Proof. This follows directly from Fact 4.27.
⊓⊔

104
5 M-Adhesive Transformation Systems
floor
floor
request
floor
floor
floor
floor
request
floor
request
down
elevator
floor
floor
request
down
elevator
floor
request
floor
request
floor
request
int
holds
int
holds
holds
int
down
on
holds
int
down
on
holds
int
holds
int
holds
int
¬ ∃neg1
( ∃pos1
∃pos2)
∧
∨
∧
¬ ∃neg2
processIntDown+intRequest
floor
floor
floor
floor
down
elevator
request
request
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
request
down
on
next_up
next_up
next_up
holds
ext
int
holds
down
on
next_up
next_up
next_up
holds
ext
down
on
next_up
next_up
next_up
holds
ext
int
holds
m0 + m′
3
H2
H3
Fig. 5.6 Parallel rule and transformation
Example 5.25. In the upper row of Fig. 5.6, the parallel rule processIntDown +
intRequest is shown. We have only depicted the relevant application conditions
and left out those which should not appear in a valid model, for example, graphs
with two ﬂoors holding the same request. The application conditions describe
for various overlappings of the two ﬂoors that there is an elevator in downwards
mode at the upper ﬂoor and no internal request at the lower one. The application
H2 =
processIntDown+intRequest,m0+m′
3
===========================⇒H3 of this parallel rule is shown in Fig. 5.6 and
combines the eﬀects of both rules to H2, leading to the graph H3.
△
Now we present the Local Church–Rosser and Parallelism Theorem, which is
an abstraction of Theorem 2.26, by replacing graphs by objects from a suitable M-
adhesive category.
Theorem 5.26 (Local Church–Rosser and Parallelism Theorem).
Given two
H1
H2
G
G′
p1,m1
p1+p2,m
p2,m2
p2,m′
2
p1,m′
1
parallel independent direct transformations
G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2, there is an
object G′ together with direct transformations
H1 =
p2,m′
2
===⇒G′ and H2 =
p1,m′
1
===⇒G′ such that
G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒G′ and G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒
G′ are sequentially independent.

5.2 Results for Transformations with Application Conditions
105
Given two sequentially independent direct transformations G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒
G′, there is an object H2 together with direct transformations G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒G′
such that G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2 are parallel independent.
In any case of independence, there is a parallel transformation G =
p1+p2,m
=====⇒G′,
and, vice versa, a direct transformation G =
p1+p2,m
=====⇒G′ via the parallel rule p1 + p2
can be sequentialised both ways.
△
Proof. Consider the parallel independent direct transformations G =
p1,m1
===⇒H1 and
G =
p2,m2
===⇒H2. Then the underlying plain transformations G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒
H2 are also parallel independent.
L1
K1
R1
L2
K2
R2
G
D1
H1
D2
H2
ac1
ac2
l1
r1
f1
g1
m1
k1
n1
l2
r2
f2
g2
m2
k2
n2
d12
d21
By the Local Church–Rosser Theorem without application conditions [EEPT06],
there are an object G′ and plain direct transformations H1 =
p2,m′
2
===⇒G′ ⇐
p1,m′
1
==== H2 such
that the plain transformations G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒G′ and G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒G′ are
sequentially independent.
Since the two direct transformations are parallel independent, there are mor-
phisms d12 : L1 →D2 and d21 : L2 →D1 such that m1 = f2 ◦d12 and m2 = f1 ◦d21.
Moreover, we have that m′
1 = g2 ◦d12 and m′
2 = g1 ◦d21 from the proof of the
plain Local Church–Rosser Theorem. By assumption, g2 ◦d12 = m′
1 |= ac1 and
g1 ◦d21 = m′
2 |= ac2; therefore the transformations H2 =
p1,m′
1
===⇒G′ and H1 =
p2,m′
2
===⇒G′
are well deﬁned.
The plain transformations G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒G′ are sequentially independent,
with morphisms d21 : L2 →D1 such that g1 ◦d21 = m′
2 and d′
12 : R1 →D′
2 such that
f ′
2 ◦d′
12 = n1.
R1
K1
L1
L2
K2
R2
H1
D1
G
D′
2
G′
ac1
ac2
r1
l1
g1
f1
n1
k1
m1
l2
r2
f ′
2
g′
2
m′
2
k′
2
n′
2
d′
12
d21

106
5 M-Adhesive Transformation Systems
L1
K1
R1
D2
D
D′
2
H2
D′
1
G′
r1
l1
d′
12
d12
g2
g′
2
(1)
(2)
(3)
(4)
By precondition, f1 ◦d21 = m2 |= ac2.
The proof of the plain Local Church–Rosser
Theorem shows that the diagrams (1)–(4) are
pushouts, and therefore g2◦d12 |= ac1  L(R(p1,
ac1)) implies that g′
2 ◦d′
12 |= R(p1, ac1) using
Fact 5.16. Therefore, also the transformations
G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒G′ are sequentially inde-
pendent.
Similarly, the transformations G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒G′ can be shown to be sequen-
tially independent.
The second statement follows from the ﬁrst one by using the inverse rule and
duality of parallel and sequential independence.
For parallelism, given sequentially independent transformations G =
p1,m1
===⇒H1
=
p2,m′
2
===⇒G′, the Parallelism Theorem without application conditions [EEPT06] states
that there is a parallel transformation G =
p1+p2,m
=====⇒G′ with m1 = m◦iL1 and n′
2 = n◦iR2.
L1
R2
G
D
G′
L1 + L2
K1 + K2
R1 + R2
l1+l2
r1+r2
iL1
iR2
m1
n′
2
m
n
f
g
k
By assumption, m1 |= ac1 and m′
2 |= ac2. Using Facts 5.4 and 5.16 and Def. 5.23,
we have that m1 |= ac1 ⇔m |= Shift(iL1, ac1) and m′
2 |= ac2 ⇔n′
2 = n ◦iR2 |=
R(p2, ac2) ⇔n |= Shift(iR2, R(p2, ac2)) ⇔L(p1 + p2, Shift(iR2, R(p2, ac2))). Sim-
ilarly, the sequentially independent transformation G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒G′ implies
that m |= Shift(iL2, ac2) and m |= L(p1 + p2, Shift(iR1, R(p1, ac1))). Thus, m |= ac,
i.e., the parallel transformation satisﬁes the application condition.
Vice versa, let G =
p1+p2,m
=====⇒G′ be a parallel transformation. Then there is an under-
lying plain parallel transformation and, by the Parallelism Theorem without applica-
tion conditions [EEPT06], there is a sequentially independent direct transformation
G =
p1,m1
===⇒H1 =
p2,m′
2
===⇒G′ with m1 = m ◦iL1 and n′
2 = n ◦iR2. By assumption, m |= acL.
From the equivalences above it follows that m1 |= ac1 and m′
2 |= ac2, i.e., the direct
transformations satisfy the application conditions. Similarly, this holds for the se-
quentially independent direct transformation G =
p2,m2
===⇒H2 =
p1,m′
1
===⇒G′ with m2 |= ac2
and m′
1 |= ac1.
⊓⊔
5.2.2 Concurrency Theorem
Sequentially dependent transformations G =
p1=⇒H =
p2=⇒G′ cannot be combined
using the parallel rule. Instead, we use an E-dependency relation and construct

5.2 Results for Transformations with Application Conditions
107
an E-concurrent rule p1 ∗E p2 for p1 and p2. The resulting E-concurrent trans-
formation G =
p1∗E p2
=====⇒leads to the same result G′ as the E-related transformations
G =
p1=⇒H =
p2=⇒G′. The connection between E-related and E-concurrent transforma-
tions is established in the Concurrency Theorem.
The construction of an E-concurrent rule is based on an E-dependency relation
which guarantees the existence of suitable pushout complements. The application
condition of the E-concurrent rule guarantees that, whenever it is applicable, the
rules p1 and, afterwards, p2 can be applied.
Deﬁnition 5.27 (Concurrent rule). Given rules p1 = (L1
l1
←−K1
r1
−→R1, ac1)
and p2 = (L2
l2
←−K2
r2
−→R2, ac2), an object E with morphisms e1 : R1 →E and
e2 : L2 →E such that (e1, e2) ∈E′ is an E-dependency relation of p1 and p2 if the
pushout complements (1) of e1 ◦r1 and (2) of e2 ◦l2 exist.
Given an E-dependency relation (E, e1, e2) of p1 and p2 the E-concurrent rule
p1 ∗E p2 = (L
s1◦w1
←−K
t2◦w2
−→R, ac) is constructed by pushouts (1)–(4) and pullback
(5), with ac = Shift(u1, ac1) ∧L(p∗, Shift(e2, ac2)) and p∗= (L
s1
←−C1
t1
−→E).
R1
K1
L1
L2
K2
R2
E
C1
L
C2
R
K
ac1
ac2
ac
r1
l1
t1
s1
e1
v1
u1
l2
r2
s2
t2
e2
v2
u2
w1
w2
(1)
(2)
(3)
(4)
(5)
A sequence G =
p1,m1
===⇒H =
p2,m2
===⇒G′ is called E-related if there exist h : E →H,
c1 : C1 →D1, and c2 : C2 →D2 such that h ◦e1 = n1, h ◦e2 = m2, c1 ◦v1 = k1,
c2 ◦v2 = k2, and (6) and (7) are pushouts.
R1
K1
L1
L2
K2
R2
E
C1
C2
G
D1
H
D2
G′
ac1
ac2
r1
l1
t1
e1
v1
l2
r2
s2
e2
v2
m1
n2
k1
k2
c2
c1
f1
g1
f2
g2
h
n1
m2
(6)
(7)
A direct transformation via an E-concurrent rule is called E-concurrent transfor-
mation.
△
Example 5.28. In Fig. 5.7, a sequentially dependent transformation sequence is
shown applying ﬁrst the rule inRequest, followed by the rule moveDown. Note

108
5 M-Adhesive Transformation Systems
floor
floor
floor
floor
down
elevator
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
down
next_up
next_up
next_up
on
int
holds
down
on
next_up
next_up
next_up
int
holds
intRequest
moveDown
G1
G2
G3
Fig. 5.7 A sequentially dependent transformation
floor
elevator
floor
floor
elevator
floor
floor
elevator
floor
floor
floor
request
elevator
floor
floor
request
elevator
floor
elevator
floor
floor
request
floor
elevator
floor
down
next_up
on
next_up
on
next_up
next_up
on
holds
next_up
on
holds
next_up
on
higher_than
holds
next_up
on
down
( ∃pos1
∃pos2)
¬ ∃neg1
∧
∧
∨
∃pos3
moveDown
r
l
floor
elevator
floor
floor
elevator
floor
floor
elevator
floor
request
floor
elevator
floor
request
floor
elevator
floor
request
floor
elevator
floor
next_up
on
next_up
on
next_up
on
int
holds
next_up
next_up
int
holds
next_up
on
int
holds
l
r
floor
request
floor
floor
floor
request
holds
int
holds
int
¬ ∃neg
r
l
intRequest
Fig. 5.8 E-concurrent rule construction
that these two rules cannot be switched because G1 does not fulﬁll the application
condition ∃pos1 ∨∃pos2. The corresponding E-dependency relation and the con-
struction of the E-concurrent rule is depicted in Fig. 5.8. In this case, E results
from overlapping the ﬂoor of the right-hand side of the rule intRequest with the
lower ﬂoor of the left-hand side of the rule moveDown. The resulting rule is shown
in the upper part of Fig. 5.9. Note that the application condition is only depicted
for those graphs that may actually occur in valid models. Moreover, the transla-
tion L(p∗, Shift(e2, ∃pos1 ∨∃pos2)) evaluates to true and is therefore ignored. The

5.2 Results for Transformations with Application Conditions
109
floor
elevator
floor
request
floor
elevator
floor
floor
elevator
floor
floor
floor
request
elevator
floor
elevator
floor
request
floor
elevator
floor
down
next_up
on
int
holds
next_up
on
next_up
next_up
on
holds
int
next_up
on
holds
down
on
next_up
¬ ∃neg′
∃pos′
3
¬ ∃neg′
1
∧
∧
intRequest∗E moveDown
r
l
floor
floor
floor
floor
down
elevator
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
down
on
next_up
next_up
next_up
down
next_up
next_up
next_up
down
on
next_up
next_up
next_up
int
holds
G1
G3
Fig. 5.9 The application of the E-concurrent rule
application of the E-concurrent rule to G1 is shown in Fig. 5.9, leading to the E-
concurrent transformation G1 =
intRequest∗EmoveDown
=================⇒G3.
△
For a given transformation sequence G =
p1=⇒H =
p2=⇒G′, we are able to compute
the corresponding E-dependency relation using the E′–M pair factorisation.
Fact 5.29. For a transformation G =
p1,m1
===⇒H =
p2,m2
===⇒G′, there is an E-dependency
relation E such that G =
p1,m1
===⇒H =
p2,m2
===⇒G′ is E-related.
△
Proof. Given a transformation G =
p1,m1
===⇒H =
p2,m2
===⇒H′ with co-match n1 for the ﬁrst
direct transformation, let (e1, e2) ∈E′, h ∈M be an E′–M pair factorisation of n1
R1
K1
L1
L2
K2
R2
E
C1
C2
G
D1
H
D2
G′
ac1
ac2
r1
l1
t1
e1
v1
l2
r2
s2
e2
v2
m1
n2
k1
k2
c2
c1
f1
g1
f2
g2
h
n1
m2
(6)
(7)
(1)
(2)

110
5 M-Adhesive Transformation Systems
and m2 with h ◦e1 = n1 and h ◦e2 = m2. Now we construct (6) as the pullback of
h and g1 and obtain an induced morphism v1. From h ∈M, (6) being a pullback,
and (1) + (6) being a pushout it follows that (1) and (6) are pushouts using the M-
pushout–pullback decomposition (see Theorem 4.22). Analogously, diagrams (2)
and (7) are pushouts. Thus, E with (e1, e2) ∈E′ is an E-dependency relation and
G =
p1,m1
===⇒H =
p2,m2
===⇒G′ is E-related.
⊓⊔
Now we present the Concurrency Theorem, which is an abstraction of Theo-
rem 2.29 by replacing graphs by objects from a suitable M-adhesive category.
Theorem 5.30 (Concurrency Theorem). For rules p1 and p2 and an E-concurrent
rule p1 ∗E p2 we have:
H
G
G′
p1∗E p2,m
p1,m1
p2,m2
• Given an E-related transformation sequence
G =
p1,m1
===⇒H =
p2,m2
===⇒G′, there is a synthesis
construction leading to a direct transforma-
tion G =
p1∗E p2,m
======⇒G′ via the E-concurrent rule
p1 ∗E p2.
• Given a direct transformation G =
p1∗E p2,m
======⇒G′, there is an analysis construction
leading to an E-related transformation sequence G =
p1,m1
===⇒H =
p2,m2
===⇒G′.
• The synthesis and analysis constructions are inverse to each other up to isomor-
phism.
△
Proof. Let G =
p1,m1
===⇒H =
p2,m2
===⇒G′ be E-related. Then the underlying plain trans-
formation is E-related and, by the Concurrency Theorem without application con-
ditions [EEPT06], there is an E-concurrent transformation G =
p1∗E p2,m
======⇒G′ with
m ◦u1 = m1.
By assumption, m1 |= ac1 and m2 |= ac2. From Facts 5.4 and 5.16 it follows
that m1 |= ac1 ∧m2 |= ac2 ⇔m |= Shift(u1, ac1) ∧h |= Shift(e2, ac2) ⇔m |=
Shift(u1, ac1)∧m |= L(p∗, Shift(e2, ac2)) ⇔m |= Shift(u1, ac1)∧L(p∗, Shift(e2, ac2))
= ac. Thus, m |= ac, i.e., the E-concurrent transformation satisﬁes the application
condition.
Vice versa, let G =
p,m
==⇒G′ be an E-concurrent transformation. Then the under-
lying plain direct transformation is E-concurrent and, by the Concurrency Theo-
rem without application conditions [EEPT06], there is an E-related transformation
G =
p1,m1
===⇒H =
p2,m2
===⇒G′. By assumption, m |= ac. As shown above, this is equivalent
to m1 |= ac1 and m2 |= ac2, i.e., the E-related transformation satisﬁes the application
conditions.
The bijective correspondence follows from the fact that all constructions are
unique up to isomorphism.
⊓⊔
5.2.3 Embedding and Extension Theorem
The Embedding and Extension Theorem allows us to extend a transformation to a
larger context (see Fig. 5.10). An extension diagram describes how a transformation

5.2 Results for Transformations with Application Conditions
111
G0
Gn
G′
0
G′
n
∗
∗
t
t′
k0
kn
(1)
Li
Ki
Ri
G′
i−1
D′
i
G′
i
Gi−1
Di
Gi
aci
fi
gi
li
ri
f ′
i
g′
i
mi
ki−1
ni
ki
(2i)
(3i)
(4i)
(5i)
Fig. 5.10 Embedding and extension: sequence (left) and intermediate step (right)
t : G0 =
∗⇒Gn can be extended to a transformation t′ : G′
0 =
∗⇒G′
n via the same
rules and an extension morphism k0 : G0 →G′
0. For each rule application and
transformation step, we have two double pushout diagrams (2i)–(5i), where the rule
pi is applied to both Gi−1 and G′
i−1.
A suﬃcient and necessary condition for this extension is the consistency of an ex-
tension morphism. It is based on the notions of derived span and derived application
condition of a transformation. The derived span describes the combined changes of
a transformation by condensing it into a single span. The derived application condi-
tion summarises all application conditions of a transformation into a single one.
Deﬁnition 5.31 (Derived span and application condition). Given a transforma-
tion t : G0 =
∗⇒Gn via rules p1, . . . , pn, the derived span der(t) is inductively deﬁned
by
der(t) =

G0
f1
←−D1
g1
−→G1 for t : G0 =
p1,m1
===⇒G1
G0
d′
0◦d
←−D
gn◦dn
−→Gn for t : G0 =
∗⇒Gn−1 =
pn,mn
===⇒Gn with pullback (PB) and
der(G0 =
∗⇒Gn−1) = (G0
d′
0
←−D′ d′
n−1
−→Gn−1)
Gn−1
Dn
Gn
D′
G0
D
d′
0
d′
n−1
fn
gn
d
dn
(PB)
Moreover, the derived application condition ac(t) is deﬁned by
ac(t) =

Shift(m1, ac1)
for t : G0 =
p1,m1
===⇒G1
ac(G0 =
∗⇒Gn−1)
for t : G0 =
∗⇒Gn−1 =
pn,mn
===⇒Gn
∧L(p∗
n, Shift(mn, acn))
with p∗
n = der(G0 =
∗⇒Gn−1)
△
Example 5.32. Consider the transformation G1
=
intRequest
========⇒
G2
=
moveDown
======⇒
G3
=
processIntDown
============⇒G4, where the ﬁrst part of the transformation is shown in Fig. 5.9,
while the last direct transformation step deletes the request on the second lowest
ﬂoor. The derived span of this transformation and its derived application condition

112
5 M-Adhesive Transformation Systems
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
down
on
next_up
next_up
next_up
int
holds
¬ ∃neg1
¬ ∃neg
∧
floor
floor
floor
floor
down
elevator
floor
floor
floor
floor
down
elevator
floor
floor
floor
floor
down
elevator
down
on
next_up
next_up
next_up
down
next_up
next_up
next_up
down
on
next_up
next_up
next_up
G1
G4
Fig. 5.11 The derived span and derived application condition of G1 =
∗⇒G4
are shown in Fig. 5.11 and combine all changes applied in the single transformation
steps. Note that in the translation of the derived application condition, several parts
evaluate to true and are therefore not depicted.
△
The notion of consistency combines that of boundary consistency, ensuring the
preservation of certain structures, and AC consistency, ensuring that the application
conditions hold.
Deﬁnition 5.33 (Consistency). Given a transformation t : G0 =
∗⇒Gn with derived
span der(t) = (G0
d∗
0
←−D
d∗
n
−→Gn) and derived application condition ac(t), and a
morphism k0 : G0 →G′
0 ∈M′:
•
B
G0
D
Gn
C
G′
0
b∗
b
d∗
0
d∗
n
c
a
k0
(6)
k0 is boundary-consistent with
respect to t if there exists an
initial pushout (6) over k0 (see
Def. 4.23) and a morphism
b∗∈M with d∗
0 ◦b∗= b.
• k0
is
AC-consistent
with
respect to t if k0 |= ac(t).
• k0 is consistent with respect to t if k0 is both boundary- and AC-consistent with
respect to t.
△
The consistency condition is suﬃcient and necessary for the construction of
extension diagrams, provided that we have initial pushouts over M′-morphisms.
Moreover, we are able to give a direct construction of G′
n in the extension diagram,
which avoids constructing the complete transformation t′ : G′
0 =
∗⇒G′
n.

5.2 Results for Transformations with Application Conditions
113
Theorem 5.34 (Embedding and Extension Theorem). Given a transformation
t : G0 =
∗⇒Gn and a morphism k0 : G0 →G′
0 ∈M′ which is consistent with respect
to t, there is an extension diagram over t and k0.
Vice versa, given a transformation t : G0 =
∗⇒Gn with an extension diagram (1)
and initial pushout (6) over k0 : G0 →G′
0 ∈M′ as above, we have that:
1. k0 is consistent with respect to t : G0 =
∗⇒Gn.
2. There is a rule p∗= (der(t), ac(t)) leading to a direct transformation G′
0 =
p∗
=⇒G′
n.
3. G′
n is the pushout of C and Gn along B, i.e., G′
n = Gn +B C.
△
Proof. Let t : G0 =
∗⇒Gn be a transformation and k0 : G0 →G′
0 ∈M′ consistent
with respect to t. Then k0 is boundary-consistent with respect to the underlying
plain transformation t and, by the Embedding Theorem for rules without application
conditions [EEPT06], there is a plain extension diagram over t and k0.
By assumption, k0 |= ac(t). It remains to show that the application condition
aci is fulﬁlled for each single transformation step in the extension diagram, i.e.,
ki−1 ◦mi |= aci for i = 1, . . . , n. This is proven by induction over the number of
direct transformation steps n.
Basis. For a transformation t : G0 =⇒G0 of length 0, k0 |= ac(t) = true. For a
transformation t : G0 =
p1,m1
===⇒G1 of length 1, k0 |= ac(t) = Shift(m1, ac1) if and only
Li
Ki
Ri
G′
i−1
D′
i
G′
i
Gi−1
Di
Gi
aci
fi
gi
li
ri
f ′
i
g′
i
mi
ki−1
ni
ki
(2i)
(3i)
(4i)
(5i)
if k0 ◦m1 |= ac1.
Induction hypothesis. For a transfor-
mation t : G0 =
∗⇒Gi of length i ≥1,
k0 |= ac(t) ⇔kj−1 ◦mj |= acj for
j = 1, . . . , i.
Induction step. Consider now the
transformation t : G0 =
∗⇒Gi =⇒Gi+1.
Then we have that:
k0 |= ac(G0 =
∗⇒Gi+1)
⇔k0 |= ac(G0 =
∗⇒Gi) ∧L(der(G0 =
∗⇒Gi), Shift(mi+1, aci+1)) Def. 5.31
⇔k0 |= ac(G0 =
∗⇒Gi) ∧ki |= Shift(mi+1, aci+1)
Fact 5.16
⇔k0 |= ac(G0 =
∗⇒Gi) ∧ki ◦mi+1 |= aci+1
Fact 5.4
⇔kj−1 ◦mj |= acj for j = 1, . . . , i + 1
Induction hypothesis
This means that the resulting plain extension diagram is actually valid for all direct
transformation steps, i.e., it is an extension diagram over t and k0.
G0
Gn
G′
0
G′
n
∗
∗
t
t′
k0
kn
(1)
Vice versa, let t : G0 =
∗⇒Gn be a transformation with an
extension diagram (1) and initial pushout (6) over k0 ∈M′.
By the Extension Theorem for rules without application
conditions [EEPT06], k0 is boundary-consistent with re-
spect to the underlying plain transformation t with mor-
phism b∗: B →D such that d∗
0 ◦b∗= b. By assumption,
(1) is an extension diagram, i.e., t′ : G′
0 =
∗⇒G′
n is a transformation via the rules
p1, . . . , pn with ki−1 ◦mi |= aci for i = 1, . . . , n. This means that k0 |= ac(t), and
hence it is consistent with respect to t. Moreover, Items 2 and 3 are valid. which

114
5 M-Adhesive Transformation Systems
floor
floor
floor
floor
floor
down
elevator
floor
floor
floor
floor
down
elevator
floor
floor
floor
floor
down
elevator
down
on
next_up
next_up
next_up
down
next_up
next_up
next_up
down
on
next_up
next_up
next_up
k0
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
floor
request
down
on
next_up
next_up
next_up
ext
holds
ext
holds
down
next_up
next_up
next_up
ext
holds
down
on
next_up
next_up
next_up
ext
holds
C
G
H1
B
G1
G4
floor
floor
floor
floor
down
elevator
down
on
next_up
next_up
next_up
k′
0
G1
H2
floor
floor
floor
floor
down
elevator
request
request
down
next_up
next_up
next_up
ext
holds
int
holds
on
Fig. 5.12 The embedding of G1 into G and H2
follows directly from the corresponding results for the underlying plain transforma-
tion.
⊓⊔
Example 5.35. We can embed the graph G0 = G1 from Fig. 5.9 into the larger con-
text graph G′
0 = G from Fig. 5.3, where G contains an additional external request on
the lowest ﬂoor. The boundary B contains only this lowest ﬂoor, while the context
graph C adds the additional request to this ﬂoor, as shown in the left of Fig. 5.12.
Since this ﬂoor is not deleted, the extension morphism k0 is boundary-consistent.
Moreover, it is AC-consistent—because there is no request on the second or third
ﬂoor, the derived application condition is fulﬁlled. Therefore, we have consistency
and can construct the transformation G′
0 =
∗⇒G′
3 = H1, where H1 is constructed as
the pushout of G4 and C along B.
In contrast, the morphism k′
0 : G1 →H2 in the right of Fig. 5.12 is not consistent,
because it does not satisfy the application condition ¬ ∃neg1.
△
5.2.4 Critical Pairs and Local Conﬂuence Theorem
Conﬂuence is the property ensuring the functional behaviour of transformation sys-
tems. A system is conﬂuent if whenever an object G can be transformed into two
objects H1 and H2, these can be transformed into a common object G′. A slightly

5.2 Results for Transformations with Application Conditions
115
H1
H2
G
X
∗
∗
∗∗
H1
H2
G
X
p1,m1
p2,m2
∗∗
weaker property is local
conﬂuence, where we only
ask this property for direct
transformations of G into
H1 and H2. Conﬂuence co-
incides with local conﬂu-
ence when the given transformation system is terminating, as shown in [New42].
For parallel independent transformations, the Local Church–Rosser Theorem en-
sures conﬂuence (see, e.g., [EEPT06]). In general, however, not all pairs of direct
transformations are parallel independent. It remains to analyse the parallel depen-
dent ones.
The intuition behind using critical pairs to check (local) conﬂuence is that we do
not have to study all possible cases of parallel dependent pairs of rule applications,
but only some minimal ones which are built by gluing the left-hand sides of these
pairs. A critical pair for the rules p1, p2 is a pair of parallel dependent transforma-
tions, P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2, where o1 and o2 are in E′. A completeness lemma,
showing that every pair of parallel dependent rule applications embeds a critical
pair, justiﬁes why it is enough to consider the conﬂuence of these cases.
As shown in [Plu93, Plu05], the conﬂuence of all critical pairs is not a suﬃcient
condition for the local conﬂuence of a general transformation system, as it is in the
case of term rewriting. Instead, a stronger notion of conﬂuence is needed, called
strict conﬂuence. In [Plu05, EEPT06] it is shown for plain rules that strict conﬂu-
ence of all critical pairs implies the local conﬂuence of a transformation system. In
the following we show how to extend these results to rules with application condi-
tions, which considerably complicate the conﬂuence analysis. We introduce a new
notion of strict AC conﬂuence of critical pairs for an adequate handling of applica-
tion conditions, leading to local conﬂuence of the transformation system.
First, we present a new simple but weak notion of critical pairs. We know that all
pairs of rule applications are potentially nonconﬂuent, even if their underlying plain
transformations are parallel independent. Thus, we deﬁne as weak critical pairs all
the minimal contexts of all pairs of plain rule applications.
Deﬁnition 5.36 (Weak critical pair).
Given rules p1 = (p1, ac1) and p2 =
(p2, ac2), a pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 of plain transformations is a weak critical
pair for (p1, p2), if (o1, o2) ∈E′.
L1
K1
R1
L2
K2
R2
K
N1
P1
N2
P2
ac1
ac2
acK
l1
r1
v1
w1
o1
t1
l2
r2
v2
w2
o2
t2
z12
z21

116
5 M-Adhesive Transformation Systems
Every weak critical pair induces an application condition acK = acE
K ∧acC
K on K
with
• extension application condition: acE
K = Shift(o1, ac1) ∧Shift(o2, ac2) and
• conﬂict-inducing application condition: acC
K = ¬(acz21 ∧acz12), with
if ( ∃z12 : v2 ◦z12 = o1 then acz12 = L(p∗
2, Shift(w2 ◦z12, ac1)) else acz12 = false,
with p∗
2 = (K
v2
←−N2
w2
−→P2)
if ( ∃z21 : v1 ◦z21 = o2 then acz21 = L(p∗
1, Shift(w1 ◦z21, ac2)) else acz21 = false,
with p∗
1 = (K
v1
←−N1
w1
−→P1)
△
The two application conditions acE
K and acC
K are used to characterise the exten-
sions of K that may give rise to a conﬂuence conﬂict. If a morphism m : K →G
models acE
K then m ◦o1 and m ◦o2 are two matches of p1 and p2, respectively,
satisfying their associated application conditions. If these two plain transformations
are parallel independent then acC
K is precisely the condition that ensures that the two
transformations with application conditions are parallel dependent.
We can prove that each pair of parallel dependent transformations is an extension
of a weak critical pair.
Fact 5.37. For
each
pair
of
parallel
dependent
direct
transformations
P1
K
P2
H1
G
H2
p1,o1
p1,m1
p2,o2
p2,m2
m
(1)
(2)
H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 there is a weak critical
pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 with induced appli-
cation condition acK and morphism m : K →
G ∈M with m |= acK, leading to extension
diagrams (1) and (2).
△
Proof. Consider the parallel dependent transformations H1 ⇐
p,m1
==== G =
p2,m2
===⇒H2. For
m1 and m2 there exists an E′–M pair factorisation with an object K and morphisms
m ∈M, (o1, o2) ∈E′ such that m1 = m ◦o1 and m2 = m ◦o2. Using the Restric-
tion Theorem without application conditions [EEPT06] we obtain transformation
K =
p1,o1
===⇒P1 and K =
p2,o2
===⇒Pi, leading to the required plain extension diagrams.
L1
K1
R1
L2
K2
R2
K
N1
P1
N2
P2
G
D1
H1
D2
H2
l1
r1
v1
w1
o1
t1
l2
r2
v2
w2
o2
t2
z12
z21
d12
d21
m
u1
s1
u2
s2
f1
g1
f2
g2
m1
m2
By assumption, m1 = m◦o1 |= ac1. By Fact 5.4 it follows that m |= Shift(o1, ac1).
Similarly, m2 |= ac2 implies that m |= Shift(o2, ac2). Consequently, m |= Shift(o1,
ac1) ∧Shift(o2, ac2) = acE
K.
It remains to show that m |= acC
K = ¬(acz21 ∧acz12) = ¬acz21 ∨¬acz12). Since
H1 ⇐
p,m1
==== G =
p2,m2
===⇒H2 are parallel dependent, we have at least one of the following
cases:

5.2 Results for Transformations with Application Conditions
117
1. ∄d12 : f2 ◦d12 = m1. Then also ∄z12 : v2 ◦z12 = o1, because otherwise we could
deﬁne d12 = u2 ◦z12. By deﬁnition, acz12 = false. This means that m ̸|= acz12, i.e.,
m |= acC
K.
2.
∃d12 : f2 ◦d12 = m1, but g2 ◦d12 ̸|= ac1. If ∄z12 : v2 ◦z12 = o1 then acz12 =
false and m |= acC
K as in Case 1. Otherwise, acz12 = L(p∗
2, Shift(w2 ◦z12, ac1)).
Using Facts 5.4 and 5.16, we have that m |= L(p∗
2, Shift(w2 ◦z12, ac1)) ⇔s2 |=
Shift(w2 ◦z12, ac1) ⇔s2 ◦w2 ◦z12 |= ac1. From f2 ∈M and f2 ◦d12 = m1 =
m ◦o1 = m ◦v2 ◦z12 = f2 ◦u2 ◦z12 it follows that u2 ◦z12 = d12. Thus, using
g2 ◦d12 = g2 ◦u2 ◦z12 = s2 ◦w2 ◦z12 it follows that m ̸|= acz12, i.e., m |= acC
K.
3. ∄d21 : f1 ◦d21 = m2. Similarly to Case 1, acz21 = false and m |= acC
K.
4. ∃d21 : f1◦d21 = m2, but g1◦d21 ̸|= ac2. Similarly to Case 2, either ∄z21 : v1◦z21 =
o2 and acz21 = false, or acz21 = L(p∗
1, Shift(w1◦z21, ac2)) and g1◦d21 ̸|= ac2 implies
that m ̸|= acz21. In both cases, it follows that m |= acC
K.
⊓⊔
It can be shown that the conﬂict-inducing application condition acC
K is character-
istic for parallel dependency.
Fact 5.38. Consider a pair of transformations H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 embedding
a weak critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 with morphism m ∈M and m |= acE
K.
Then we have that H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 is parallel dependent if and only if
m |= acC
K.
△
Proof. “⇒”. This follows from Fact 5.37.
“⇐”. If the pair of underlying plain transformations is parallel dependent, then also
H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 is parallel dependent. Otherwise, we have morphisms d12
and d21 with f2 ◦d12 = m1 = m ◦o1 and f1 ◦d21 = m2 = m ◦o2. Since N2 is a pull-
back object we obtain a unique morphism z12 with v2 ◦z12 = o1 and u2 ◦z12 = d12.
Similarly, the pullback object N1 induces a unique morphism z21 with v1 ◦z21 = o2
and u1 ◦z21 = d21.
L1
K1
R1
L2
K2
R2
K
N1
P1
N2
P2
G
D1
H1
D2
H2
l1
r1
v1
w1
o1
t1
l2
r2
v2
w2
o2
t2
z12
z21
d12
d21
m
u1
s1
u2
s2
f1
g1
f2
g2
m1
m2
As shown in the proof of Fact 5.37, in this case m |= acz12 ⇔g2 ◦d12 |= ac1 and
m |= acz21 ⇔g1 ◦d21 |= ac2. By assumption, m |= acC
K and, by deﬁnition of acC
K,
m ̸|= acz12 or m ̸|= acz21. If m ̸|= acz12 then g2 ◦d12 ̸|= ac1, and similarly if m ̸|= acz21
then g1 ◦d21 ̸|= ac2. Therefore, at least one of the application conditions is not ful-
ﬁlled and the pair H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 is parallel dependent.
⊓⊔

118
5 M-Adhesive Transformation Systems
floor
elevator
floor
floor
floor
elevator
floor
request
floor
floor
elevator
floor
floor
next_up
on
next_up
on
next_up
on
int
holds
intRequest
moveDown
floor
elevator
floor
floor
elevator
floor
request
floor
elevator
floor
next_up
on
next_up
on
next_up
on
int
holds
intRequest
moveDown
floor
elevator
floor
floor
elevator
floor
request
floor
elevator
floor
next_up
on
next_up
on
next_up
on
int
holds
intRequest
moveDown
Fig. 5.13 Three weak critical pairs for moveDown and intRequest
Example 5.39. For the rules moveDown and intRequest, three weak critical pairs
exist as shown in Fig. 5.13. As analysed in Ex. 5.20, the pair H1 ⇐
moveDown,m1
==========
G =
intRequest,m2
===========⇒H2 of direct transformations in Fig. 5.4 is parallel dependent. The
second weak critical pair can be embedded into this pair of transformations. Note
that this critical pair actually consists of plain transformations, but not valid trans-
formations with application conditions, because ∃pos3 is not fulﬁlled by o1. K co-
incides with the left-hand side of the rule moveDown. The application condition acK
is given by acK = acE
K = ( ∃pos1∨∃pos2)∧∃pos3∧¬ ∃neg1. Actually, we had to
include neg′ : K →P2, stemming from shifting the application condition of the rule
intRequest over the morphism o2. But if any request on the upper ﬂoor is forbid-
den (¬ ∃neg1), so is an internal request (¬ ∃neg′), meaning ¬ ∃neg1 ⇒¬ ∃neg′;
therefore this part of the application condition can be ignored. The conﬂict-inducing
application condition acC
K turns out to be equivalent to true. In particular, this means
that any pair of transformations H1 ⇐
moveDown
======= G =
intRequest
========⇒H2 embedding this
weak critical pair is parallel dependent since the corresponding extension would
trivially satisfy acC
K.
△
Not every weak critical pair may be embedded in a parallel dependent pair of rule
applications. Weak critical pairs without an extension m satisfying acK are useless
for checking local conﬂuence, because no extension of parallel dependent transfor-
mation exists. Therefore, we extend our notion of critical pair in the sense that they
are also complete and each of them is embedded in at least one case of parallel de-
pendence. In particular, a critical pair is a weak critical pair such that there is at least
one extension satisfying acK.

5.2 Results for Transformations with Application Conditions
119
Deﬁnition 5.40 (Critical pair). Given rules p1 = (p1, ac1) and p2 = (p2, ac2), a
weak critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 is a critical pair if there exists an extension
of the pair via a morphism m : K →G ∈M such that m ◦o1 = m1, m ◦o2 = m2,
and m |= acK.
△
Note that this new notion of critical pairs is diﬀerent from the one for rules with
negative application conditions in [Lam10]. The main diﬀerence is that critical pairs
in our sense may disregard the application conditions. In the case that all application
conditions are negative application conditions, the above notion of critical pairs does
not coincide with the notion deﬁned in [Lam10], although they are in some sense
equivalent. In [Lam10], so-called produce–forbid critical pairs may contain, in ad-
dition to an overlap of the left-hand sides of the rules, a part of the corresponding
negative application conditions. In our notion, this additional part would be included
in acC
K.
Also, critical pairs as deﬁned above are complete. Moreover, the converse prop-
erty also holds, in the sense that each critical pair can be extended to a pair of parallel
dependent rule applications.
Theorem 5.41 (Completeness Theorem).
For each pair of parallel dependent
P1
K
P2
H1
G
H2
p1,o1
p1,m1
p2,o2
p2,m2
m
(1)
(2)
direct transformations H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2
there is a critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2
and a morphism m : K →G ∈M with m |=
acK, leading to extension diagrams (1) and (2).
Moreover, for each critical pair P1 ⇐
p1,o1
====
K =
p2,o2
===⇒P2 for (p1, p2) there is a parallel de-
pendent pair H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 and a morphism m : K →G ∈M such that
m |= acK, leading to to extension diagrams (1) and (2).
△
Proof. By Fact 5.37, for parallel dependent H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 there is a weak
critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 with m |= acK, leading to extension diagrams (1)
and (2). Since this extension exists, the weak critical pair is indeed a critical pair.
Conversely, it follows from the deﬁnition of critical pair that each critical pair
can be extended to a pair of parallel dependent transformations.
⊓⊔
Example 5.42. Due to Theorem 5.41, the weak critical pair in Ex. 5.39 is actually a
critical pair. In particular, the parallel dependent transformations depicted in Fig. 5.4
satisfy acK.
△
In order to show local conﬂuence, we have to require that all critical pairs be
conﬂuent. However, even in the case of plain graph transformation rules, this is not
suﬃcient to show local conﬂuence [Plu93, Plu05]. For transformations without ap-
plication conditions, the strict conﬂuence of critical pairs ensures that the conﬂuent
transformations of the critical pair can be extended to the original pair of transfor-
mations. However, if we consider application conditions we may be unable to apply
some of these rules if the corresponding matches of the extensions fail to satisfy the

120
5 M-Adhesive Transformation Systems
application conditions. Therefore, we compute a derived application condition ac(t)
(see Def. 5.31), collecting all application conditions in the transformation, which is
used in the notion of strict AC conﬂuence.
Deﬁnition 5.43 (Strict AC conﬂuence). A critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 with
induced application conditions acK is strictly AC-conﬂuent if it is
1.
K
N1
N2
P1
N
P2
N3
N4
K′
(1)
(2)
(3)
(4)
v1
w1
v2
w2
v3
w3
v4
w4
z1
z2
z3
z4
conﬂuent without applica-
tion conditions, i.e., there
are plain transformations
P1 =
∗⇒K′ and P2 =
∗⇒K′,
2. strict, i.e., given derived
spans der(Pi =
pi,oi
===⇒Ki) =
(K
vi
←−Ni
wi
−→Pi) and
der(Pi =
∗⇒K′) = (Pi
vi+2
←−
Ni+2
wi+2
−→K′) for i = 1, 2
and pullback (1), there ex-
ist morphisms z3, z4 such that diagrams (2), (3), and (4) commute, and
3. for ti : K =
pi,oi
===⇒Pi =
∗⇒K′ it holds that acK ⇒ac(ti) for i = 1, 2.
△
Theorem 5.44 (Local Conﬂuence Theorem). A transformation system is locally
conﬂuent if all its critical pairs are strictly AC-conﬂuent.
△
Proof. For parallel independent direct transformations Theorem 5.26 implies that
we have local conﬂuence.
For a parallel dependent pair of transformations H1 ⇐
p1,m1
==== G =
p2,m2
===⇒H2 we ﬁnd
a critical pair P1 ⇐
p1,o1
==== K =
p2,o2
===⇒P2 and embedding diagrams (5) and (6) with a
G
K
K′
G′
P1
H1
P2
H2
p1,o1
p1,m1
p2,o2
p2,m2
m
t1
t′
1
t2
t′
2
(5)
(6)
(7)
(8)
(9)
∗∗
∗∗
morphism m ∈M such that m |= acK
(Theorem 5.41). By assumption, this crit-
ical pair is conﬂuent without application
conditions, i.e., we have diagram (7). The
Local Conﬂuence Theorem without ap-
plication conditions (see [EEPT06]) im-
plies that we have corresponding exten-
sions t′
1 of t1 and t′
2 of t2 in diagrams (8)
and (9).
Since the extension diagrams exist, the
Extension Theorem without application
conditions (see [EEPT06]) implies that m
is boundary-consistent w. r .t. t1 and t2 as
well as t1 : K =
p1,o1
===⇒P1 =⇒t1 K′ and t2 : K =
p2,o2
===⇒P2 =⇒t2 K′.
It remains to show that all direct transformations in t
′
1 : G =
p1,m1
===⇒H1 =
t′
1=⇒G′
and t
′
2 : G =
p2,m2
===⇒H2 =
t′
2=⇒G′ satisfy their corresponding application conditions.
This means that we have to show that m is AC-consistent w. r. t. t1 and t2, i.e., m |=

5.2 Results for Transformations with Application Conditions
121
floor
elevator
floor
floor
elevator
floor
request
floor
elevator
floor
floor
elevator
floor
floor
elevator
floor
next_up
on
next_up
on
next_up
on
next_up
on
int
holds
floor
floor
floor
floor
down
elevator
request
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
ext
down
on
next_up
next_up
next_up
holds
ext
floor
floor
floor
floor
down
elevator
request
request
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
ext
int
holds
down
on
next_up
next_up
next_up
holds
ext
floor
floor
floor
floor
down
elevator
request
down
on
next_up
next_up
next_up
holds
ext
moveDown
intRequest
ProcessIntDown
moveDown
id
moveDown
intRequest
ProcessIntDown
moveDown
id
m
Fig. 5.14 Strict AC conﬂuence of the critical pair in Examples 5.39 and 5.42
ac(t1) and m |= ac(t2). By AC conﬂuence, especially AC compatibility, we have that
acK ⇒ac(t1) and acK ⇒ac(t2). Since m |= acK it follows that m |= ac(t1) and
m |= ac(t2). Now Theorem 5.34 implies that t′
1 and t′
2 as well as t
′
1 and t
′
2 are valid
transformations, even with application conditions.
⊓⊔
Example 5.45. Using Fig. 5.14, we want to show that the critical pair in Exam-
ples 5.39 and 5.42 is strictly AC-conﬂuent. First of all, when applying ﬁrst the
rule processIntDown and then the rule moveDown to P2 as rules without appli-
cation conditions, we obtain K′ = P1 as a conﬂuent model (see Fig. 5.14). This
is a strict solution, since it deletes none of the two ﬂoors and the edge between
them nor the elevator—these four elements are the only structures preserved by
the critical pair. To show AC compatibility, we have to analyse the transforma-
tions t1 : K =
moveDown
======⇒P1 = K′ and t2 : K =
intRequest
========⇒P2 =
processIntDown
============⇒

122
5 M-Adhesive Transformation Systems
P3 =
moveDown
======⇒K′. Since ac(t1) = acK we have that acK ⇒ac(t). Similarly, we have
ac(t2) = acK ∧∃pos′ ∧¬ ∃neg′ with pos′ = pos3 and, as explained in Ex. 5.39,
¬ ∃negac1 ⇒neg′. Therefore acK ⇒ac(t2) and the critical pair is AC-compatible.
Now Theorem 5.44 implies that the pair H1 ⇐
moveDown,m1
========== G =
intRequest,m2
===========⇒H2
from Fig. 5.4 is locally conﬂuent, as shown in the outer diagram of Fig. 5.14. This
means that if the elevator is in downwards mode with a request on the lowest ﬂoor,
we can ﬁrst process a new internal request on the actual ﬂoor and then continue
moving downwards instead of moving downwards immediately.
△
Remark 5.46. As shown in [HP09], in the case of graphs, application conditions
are expressively equivalent to ﬁrst-order graph formulas. This means that the satis-
ﬁability problem for application conditions is undecidable and, as a consequence,
constructing the set of critical pairs for a transformation system with arbitrary ap-
plication conditions would be a noncomputable problem. Similarly, showing logical
consequence, and in particular AC compatibility, and therefore showing strict con-
ﬂuence, is also undecidable. However, in [OEP08, Pen08], techniques are presented
to tackle the satisﬁability and the deduction problems in practice. Obviously, this
kind of techniques would be important in our context for computing critical pairs.
Nevertheless, it must be taken into account that, as shown in [Plu05], checking local
conﬂuence for terminating graph transformation systems is undecidable, even in the
case of rules without application conditions.
△
5.3 Process Analysis
This section presents general techniques for the analysis of processes of M-adhesive
transformation systems, i.e., of equivalence classes of executions diﬀering only for
the interleaving of the same transformation steps. The main problem in this context
is to analyse whether a sequence of transformation steps can be rearranged in order
to generate all possible equivalent executions, or some speciﬁc and possibly better
ones. We deﬁne processes of M-adhesive transformation systems based on subob-
ject transformation systems inspired by processes for Petri nets [RE96] and adhesive
rewriting systems [BCH+06]. For this purpose, we use the concept of permutation
equivalence [Her09, HCE14] for transformation systems with negative application
conditions (NACs) in M-adhesive categories. Permutation equivalence is coarser
than switch equivalence with NACs and has interesting applications in the area of
business processes [BHE09b, BHG11]. This section is based on [Her09, HCE14].
In the main results of this section, we show that processes represent equivalence
classes of permutation-equivalent transformation sequences. Moreover, they can be
analysed eﬃciently by complete ﬁring sequences of a Petri net, which can be con-
structed eﬀectively as a dependency net of a given transformation sequence. Most
constructions and results are illustrated by a case study of a typed attributed graph
transformation system. Tool support for the analysis is available by the tool AGT-
M [HCEK10, BHE09b], based on Wolfram Mathematica. This section is based

5.3 Process Analysis
123
worksOn
Person
accessLevel:nat
Task
accessLevel:nat
started
R
:worksOn
1:Person
2:Task
K
1:Person
L
stopTask
ATG
Type Graph
R
:worksOn
1:Person
2:Task
K
1:Person
2:Task
L
:started
finishTask
2:Task
1:Person
2:Task
1:Person
2:Task
startTask
L
K
R
NAC1
2:Task
accessLevel=lv
2:Task
accessLevel=lv
3:started
:worksOn
2:Task
accessLevel=lv
2:Task
accesLevel=lv
1:Person
accessLevel=add(lv,x)
1:Person
accessLevel=add(lv,x)
1:Person
accessLevel=add(lv,x)
1:Person
accessLevel=add(lv,x)
continueTask
L
K
R
NAC2=R
3:started
NAC1
2:Task
accessLevel=lv
3:started
2:Task
accessLevel=lv
3:started
:worksOn
2:Task
accessLevel=lv
3:started
:worksOn
2:Task
accesLevel=lv
:Person
1:Person
accessLevel=add(lv,x)
1:Person
accessLevel=add(lv,x)
1:Person
accessLevel=add(lv,x)
1:Person
accessLevel=add(lv,x)
3:started
Fig. 5.15 Typed attributed graph transformation system GTS
on [CHS08, Her09, HCEK10, HCE14]. We present all results for transformation
systems with NACs as a special kind of general application condition.
General Assumption: We generally assume M-adhesive transformation sys-
tems with eﬀective pushouts (see Def. 4.23.5) and E–M factorisation for the mor-
phism class O of the matches.
Example 5.47 (Typed attributed graph transformation system). As a running exam-
ple for the analysis of permutation equivalence, we use the following typed at-
tributed graph transformation system with the match morphism class O contain-
ing all morphisms that are injective on the graph part, i.e., possibly noninjective
on data values. The type graph ATG speciﬁes persons and tasks: a task is active
if it has a “:started” loop, and it can be assigned to a person with a “:worksOn”
edge. Moreover, the attribute “accessLevel” speciﬁes the required access level of
tasks and the allowed maximal access level of persons. Rule “startTask” is used
to start a task, where the access level of the task can be at most equal to the ac-
cess level of the considered person and the NAC schema ensures that the task is
not started already. Rules “stopTask” and “ﬁnishTask” removes the assignment of
a person, where “ﬁnishTask” additionally deletes the marker “:started” to specify
that the task has been completed. Finally, rule “continueTask” assigns an already

124
5 M-Adhesive Transformation Systems
G1
w1:worksOn
⇒
⇒
⇒
G0
G2
G3
G4
⇒
aL=accessLevel
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
w2:worksOn
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
Fig. 5.16 Transformation sequence d of GTS
started task to a person. This rule contains two NAC schemata (see Def. 5.6) which
forbid the assignment of persons to already assigned tasks—if either another per-
son is already assigned to that task (“NAC1”) or the person himself is already
assigned (“NAC2”). Fig. 5.16 shows a NAC-consistent transformation sequence
d = (G0 =
continueTask,f1
===========⇒G1 =
stopTask, f2
========⇒G2 =
continueTask, f3
===========⇒G3 =
stopTask, f4
========⇒G4) of GTS.
The ﬁrst graph of the transformation sequence contains exactly one task, which is
ﬁrst assigned to node “1:Person”, and then, after being stopped, to node “2:Person”.
The NAC schemata of rule “continueTask” are checked at graphs G0 and G2. The
instantiated NACs n′ : L →N′ with N′ according to Fact 5.8 and Def. 5.5 contain an
edge of type worksOn. Since G0 and G2 do not contain an edge of this type there is
no embedding q from N′ into these graphs such that the NAC schemata are satisﬁed
by the matches. Therefore, the transformation sequence is NAC-consistent, because
the remaining steps do not involve NACs.
△
5.3.1 Permutation Equivalence
The classical theory of the DPO approach introduces an equivalence among transfor-
mation sequences, called switch equivalence, that relates the sequences that diﬀer
only in the order in which independent transformation steps are performed. More
precisely, two sequences are switch-equivalent if each of them can be obtained from
the other by repeatedly exchanging consecutive transformation steps that are se-
quentially independent (see Def. 5.21).
Deﬁnition 5.48 (Switch equivalence for transformation sequences).
Let d =
(d1; . . . ; dk; dk+1; . . . ; dn) be a transformation sequence, where dk and dk+1 are two
sequentially independent transformation steps, and let d′ be obtained from d by
switching them according to the Local Church–Rosser Theorem (Theorem 5.26).
Then, d′ is a switching of d, written d
sw∼d′. The switch equivalence, denoted by

5.3 Process Analysis
125
w2:worksOn
⇒
⇒
⇒
G0
⇒
aL=accessLevel
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
w1:worksOn
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
4:started
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
G1’
G2’
G3’
G4
Fig. 5.17 Permutation-equivalent transformation sequence d′ of GTS
sw≈, is the smallest equivalence on transformation sequences containing both sw∼and
the isomorphism relation .1
△
In our opinion, however, the switch equivalence for NAC-consistent sequences
is too restrictive, for the following reason. Suppose that d1; d2 are sequentially in-
dependent without considering application conditions, but that after the switching
d′
2; d′
1 is not NAC-consistent. Then either d′
2 does not satisfy the NACs, which means
that d2 can ﬁre after d1 because d1 deletes some resource that would represent a for-
bidden context for d2; or the NACs of d′
1 are not satisﬁed, because d2 creates a re-
source that matches (part of) a NAC of the transformation rule of d1. In both cases,
we argue that there is no information ﬂow from d1 to d2, and therefore that there
is no conceptual obstacle to the possibility that the two steps occur in the opposite
order (even if not consecutively) in another equivalent transformation sequence.
These considerations justify the following deﬁnition of permutation equiva-
lence [Her09, HCE14] for NAC-consistent transformation sequences, which is
coarser than the corresponding switch equivalence in the sense that it equates more
sequences.
Deﬁnition 5.49 (Permutation equivalence of transformation sequences). Two
NAC-consistent transformation sequences d and d′ are permutation-equivalent,
written d
π≈d′, if, disregarding the NACs, they are switch-equivalent as per
Def. 5.48. The equivalence class π-Equ(d) of all permutation-equivalent transfor-
mation sequences of d is given by π-Equ(d) = {d′ | d′
π≈d}.
△
Example 5.50 (Permutation equivalence). Fig. 5.17 shows a NAC-consistent trans-
formation sequence d′ = (G0 =
continueTask,f ′
1
===========⇒G′
1 =
stopTask, f ′
2
========⇒G′
2 =
continueTask,f ′
3
===========⇒
G′
3
=
stopTask, f ′
4
========⇒
G4), which is permutation-equivalent to the transformation
sequence d of Fig. 5.16, by performing the following switchings of steps
disregarding NACs (we denote by (d′
i; d′
j) the result of switching (dj; di)):
1 Informally, transformation sequences d and d′ are isomorphic (d  d′) if they have the same
length and there are isomorphisms between the corresponding objects of d and d′ compatible with
the involved morphisms.

126
5 M-Adhesive Transformation Systems
N

L
n
o
(7)
e 
f

(3)
K
o
o
/
/
ke 
k

(4)
R
e∗
f ∗

N′
L′
o
n′
o

m 
(5)
K′
o
o
/
/


(6)
R′
m∗
G
D
o
o
/
/ H
Fig. 5.18 Construction of instantiated rules and transformation steps
(d2; d3), (d1; d′
3), (d′
2; d4), (d′
1; d′
4). The equivalent transformation sequences are not
switch-equivalent with NACs, because there is no pair of independent consecutive
transformation steps in any of the transformation sequences.
△
While general matches for M-adhesive transformation systems lead to extended
concepts for NACs and NAC satisfaction, we now show that we can reduce the
analysis of a concrete given transformation sequence to the case of M-matches by
instantiating the rules and transformation diagrams along the given matches. Note
in particular that, for transformation steps along M-matches, the instantiated trans-
formation steps coincide with the given ones.
Deﬁnition 5.51 (Instantiated rules and transformation sequences). Let G =
p,f
==⇒
H be a NAC-consistent transformation step via a rule p = ((L ←- K ,→R), N) with
NAC schemata N. Let f = m ◦e be the extremal E–M factorisation of match f. The
instantiated transformation step is given by G =
p′,m
===⇒H with instantiated rule p′
derived via e and constructed as follows according to Fig. 5.18. Construct pullback
(PB) (5) leading to pushouts (POs) (3) and (5) by PB splitting and M-pushout–
pullback decomposition (see Def. 4.21). Construct PO (4) leading to PO (6) by PO
splitting. Instantiate each NAC schema n : L →N in N along morphism e (square
(7) according to Fact 5.8 and Def. 5.5), leading to new NACs n′ : L′ ,→N′. Let
N′ be the new set of NACs consisting of all NACs n′ : L′ ,→N′ obtained from
all n ∈N. The instantiated rule is given by p′ = ((L′ ←- K′ ,→R′), N′) and the
instantiated transformation step is deﬁned by G =
p′,m
===⇒H with m ∈M via DPO
diagram ((5) + (6)).
Let d be a transformation sequence; then the instantiated transformation sequence
dI is derived by instantiating each transformation step as deﬁned above.
△
Example 5.52 (Instantiation of transformation sequence). The instantiation of the
transformation sequence d in Fig. 5.16 via rules of Fig. 5.15 is performed according
to Def. 5.51. We derive an instantiated transformation sequence dI. By deﬁnition,
the lower line of the DPO diagrams coincides with the one of d in Fig. 5.16. The
instantiated rules for the four steps are depicted in Figs. 5.19 and 5.20 (rules “stop1”,
“stop2”, “cont1”, and “cont2”) and they are used in the following sections for the
analysis of permutation equivalence.
△

5.3 Process Analysis
127
R
w2:worksOn
2:Person
3:Task
K
2:Person
3:Task
L
2:Person
4=stop2
R
w1:worksOn
1:Person
3:Task
K
1:Person
3:Task
L
1:Person
2=stop1
T
Super Object
w1:worksOn
4:started
w2:worksOn
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
3:Task
3:Task
Fig. 5.19 Super object T and two rules of process Prc(d)
1=cont1
L
K
R
NAC2=R
4:started
NAC1
3:started
w2:worksOn
3:Task
aL=3
1:Person
aL=5
2:Person
aL=4
1:Person
aL=5
3:Task
aL=3
4:started
w1:worksOn
1:Person
aL=5
3:Task
aL=3
4:started
1:Person
aL=5
3:Task
aL=3
3=cont2
L
K
R
NAC2=R
4:started
NAC1
3:started
w1:worksOn
3:Task
aL=3
1:Person
aL=5
2:Person
aL=4
3:Task
aL=3
4:started
w2:worksOn
3:Task
aL=3
4:started
3:Task
aL=3
2:Person
aL=4
2:Person
aL=4
2:Person
aL=4
Fig. 5.20 Further rules of STS STS(d)
Fact 5.53 (Reduction of permutation equivalence for general matches to M-
matches). Two transformation sequences d and d′ with general matches are
permutation-equivalent if and only if their instantiated transformation sequences dI
and d′
I with M-matches are permutation-equivalent, i.e., d
π≈d′ ⇔dI
π≈d′
I.
△
Proof (Idea). The full proof (see [HCE14]) ﬁrst shows that switch equivalence dis-
regarding NACs is implied for both directions using Def. 5.48. In a second step, we
showed that the transformation sequences are additionally NAC consistent. There-
fore, d
π≈d′ ⇔dI
π≈d′
I.
⊓⊔
Remark 5.54 (Permutation equivalence for general matches). By the above fact, we
can base our analysis techniques in the following on the derived transformation se-

128
5 M-Adhesive Transformation Systems
d = (. . . di . . . ) o
analysis
/
O
Def. 5.51

d′ = (. . . d′
k . . . )
O
Def. 5.51

dI = (. . . di,I . . . ) o
analysis
/

Fact 5.53
O
d′
I = (. . . d′
k,I . . . )
d'k,I
d'k
Li
Ki
Ri
L'i
K'i
R'i
G'k-1
D'k
G'k
(3k)
(4k)
(1)
(2)
...
...
di,I
di
Li
Ki
Ri
L'i
K'i
R'i
Gi-1
Di
Gi
(3i)
(4i)
(1)
(2)
...
...
Fig. 5.21 Correspondence between transformation sequences and their instantiations
quences with M-morphisms only as depicted in Fig. 5.21. Given a transformation
sequence d, we ﬁrst instantiate d according to Def. 5.51, such that the lower trans-
formation diagrams form a new transformation sequence dI with M-matches only
and all NAC morphisms n′ : L′ →N′ are M-morphisms. Thereafter, we can analyse
permutation equivalence for dI and derive the analysis results for d via Fact 5.53.
In particular, the derived permutation-equivalent transformation sequences d′
I of dI
can be composed with the upper DPO diagrams of the instantiation, leading to
permutation-equivalent transformation sequences d′ of d.
△
5.3.2 Subobject Transformation Systems
We now present subobject transformation systems (STSs) as a formal framework
for the concurrent semantics of M-adhesive transformation systems. This concept
generalises the notion of elementary nets, which form the category of process nets
for P/T Petri nets, in the way that STSs form the category of process transformation
systems for M-adhesive transformation systems. Subobject transformation systems
are essentially double pushout transformation systems over the lattice of subobjects
Sub(T)M of a given object T of an M-adhesive category C. By |C| we denote the
class of objects of C.
Deﬁnition 5.55 (Category of M-subobjects).
Let T be an object of an M-
adhesive category C. Given two M-morphisms a : A ,→T and a′ : A′ ,→T,
they are equivalent if there exists an isomorphism φ : A →A′ such that a = a′ ◦φ.
An M-subobject [a : A ,→T] of T is an equivalence class of M-morphisms with
target T. The category of M-subobjects of T, denoted by SubM(T), has the M-
subobjects of T as objects. Furthermore, there is an arrow from [a : A ,→T] to

5.3 Process Analysis
129
[b : B ,→T] if there exists a morphism f : A →B such that a = b ◦f; in this case
f is an M-morphism and it is unique up to isomorphism (therefore SubM(T) is a
partial order), and we write [a : A ,→T] ⊆[b : B ,→T].
Usually we will denote an M-subobject [a : A ,→T] simply by A, leaving the
M-morphism a implicit, and correspondingly we write A ⊆B if [a : A ,→T] ⊆[b :
B ,→T] and denote the corresponding embedding by f : A ,→B.
△
If M is the class of all monomorphisms of C, as for adhesive categories, then
SubM(T) for T ∈|C| is the standard category of subobjects of T. The following no-
tions of “intersection” and “union” will be used in the deﬁnition of direct derivations
of an STS.
Deﬁnition 5.56 (Intersection and union in SubM(T)). Let A, B ∈|SubM(T)| be
two M-subobjects, with T ∈|C|. The product of A and B in SubM(T) is called their
intersection, denoted by A ∩B. The coproduct of A and B in SubM(T) is called
union, denoted by A ∪B.
△
Since pushouts are not eﬀective in general, we require this property by our gen-
eral assumption. As shown in [HCE14] for M-adhesive transformation systems
based on [LS04], intersections and unions exist, and SubM(T) is a distributive lat-
tice for any T ∈C.
Remark 5.57 (Unions in SubM(T) for (AGraphsATG, M)). The M-adhesive cat-
egory (AGraphsATG, M) has eﬀective pushouts, because by commutativity of the
diagram in item 5 of Def. 4.23, the morphism d is an isomorphism on the data part.
Therefore, the union A ∪B of two M-subobjects A and B can be constructed as the
pushout over the intersection A ∩B in C.
△
Deﬁnition 5.58 (STS with NACs). A subobject transformation system (STS) with
NACs S = (T, P, π) over an M-adhesive category C with eﬀective unions consists
of a super object T ∈C, a set of rule names P—also called productions—and a
function π, which maps each rule name q ∈P to a rule with negative application
conditions ((L, K, R), N), where L, K, and R are objects in SubM(T), K ⊆L, K ⊆R
and its NACs N are given by N = (N, ν), consisting of a set N of names for the NACs
together with a function ν mapping each NAC name i ∈N to a NAC ν(i), which is
given by a subobject ν(i) = Ni ∈SubM(T) with L ⊆Ni ⊆T. The short notation N[i]
refers to a NAC Ni of rule p with ν(i) = Ni.
△
Direct derivations (G =
q⇒G′) with NACs in an STS correspond to transformation
steps with NACs in an M-adhesive TS, but the construction is simpliﬁed, because
morphisms between two subobjects are unique. There is no need for pattern match-
ing, and for this reason, we use the notion of derivations within an STS in contrast
to transformation sequences in an M-adhesive TS, and we use names {p1, . . . , pn}
for rules in an M-adhesive TS and {q1, . . . , qn} for rules in an STS.
Deﬁnition 5.59 (Direct derivations in an STS). Let S = (T, P, π) be a subobject
transformation system with NACs, let π(q) = ((L, K, R), N) be a production with

130
5 M-Adhesive Transformation Systems
NACs, and let G ∈|SubM(T)|. Then there is a direct derivation disregarding NACs
from G to G′ using q if G′ ∈|SubM(T)| and there is an object D ∈SubM(T) such
that:
(i)
L ∪D = G;
(ii) L ∩D = K;
(iii) D ∪R = G′, and (iv) D ∩R = K.
We say that there is a direct derivation with NACs from G to G′ using q, if in addition
to all the conditions above it also holds that N[i] ⊈G for each N[i] in N. In both
cases we write G =
q⇒G′.
△
Given a transformation sequence d with matches in M, we can construct its cor-
responding STS, which we will use for the analysis of its processes in a similar way
to that presented for adhesive systems in [BCH+06].
Deﬁnition 5.60 (STS of a transformation sequence with M-matches). Let d =
(G0 =
p1,m1
===⇒. . . =
pn,mn
===⇒Gn) be a NAC-consistent transformation sequence in an M-
adhesive TS with matches in M. The STS with NACs generated by d is given by
STS(d) = (T, P, π) and its components are constructed as follows. T is an arbitrarily
chosen but ﬁxed colimit of the sequence of DPO diagrams given by d; P = {i |
0 < i ≤n} is a set of natural numbers that contains a canonical rule occurrence
name for each rule occurrence in d. For each k ∈P, π(k) is deﬁned as π(k) =
((Lk, Kk, Rk), Nk), where each component X of a production pk (X ∈{Lk, Kk, Rk})
is regarded as a subobject of T via the natural embedding inT(X). Furthermore, for
each k ∈{1, . . . , n} the NACs Nk = (Nk, ν) are constructed as follows. Let JNk be the
set of subobjects of T which are possible images of NACs of production (pk, Nk),
with respect to the match inT : Lk ,→T; namely,
JNk = {[j : N ,→T] ∈SubM(T) | ∃(n : Lk ,→N) ∈Nk ∧j ◦n = inT(Lk)}.
Then the NAC names Nk are given by Nk = {i | 0 < i ≤|JNk|} and the function ν
is an arbitrary but ﬁxed bijective function ν : Nk →JNk mapping NAC names to
corresponding subobjects.
△
When analysing permutation equivalence in concrete case studies we consider
only transformation sequences such that the colimit object T is ﬁnite, i.e., has
ﬁnitely many M-subobjects, in order to ensure termination. Finiteness is guaran-
teed if each rule of TS has ﬁnite left- and right-hand sides, and if the start object of
the transformation sequence is ﬁnite. For typed attributed graphs, this means that T
is ﬁnite on the structural part, but the carrier sets of the data algebra for the attribu-
tion component may by inﬁnite (M-morphisms in AGraphsATG are isomorphisms
on the data part).
Remark 5.61. Note that during the construction of STS(d) the set of instantiated
NACs for a NAC of a rule p applied in d may be empty, which means that the
NAC n cannot be found within T. This would be the case for rule continueTask if
we replace the variable lv within the NACs by the constant 4, i.e., the NAC pattern
would never be present in the transformation sequence. Furthermore, if we require
T to be ﬁnite, the sets of NACs in STS(d) are ﬁnite.
△

5.3 Process Analysis
131
Example 5.62 (Derived STS STS(d)). For the transformation sequence in Fig. 5.16
the construction leads to the STS as shown in Figs. 5.19 and 5.20. The transforma-
tion sequence d involves the rules “continueTask” and “stopTask”, and thus the de-
rived STS contains the rule occurrences “cont1”, “cont2”, “stop1” and “stop2”.
△
Deterministic processes for DPO graph transformation systems are introduced
in [CMR96] and characterised as occurrence grammars in [Bal00]: these concepts
generalise the corresponding notions for Petri nets [Rei85], and are generalised
further in [BCH+06] to adhesive transformation systems. By Def. 5.60, we gen-
eralise these notions and deﬁne the process of a transformation sequence d in an
M-adhesive transformation system. The process consists of the STS derived from d
together with an embedding v relating the STS with the M-adhesive TS of the given
transformation sequence.
Deﬁnition 5.63 (Process of a transformation sequence with NACs). Let d =
(G0 =
q1,m1
===⇒. . . =
qn,mn
===⇒Gn) be a NAC-consistent transformation sequence in an M-
adhesive transformation system TS = (PTS, πTS). The process Prc(d) = (STS(d), µ)
of d consists of the derived STS STS(d) = (T, P, π) of d together with the mapping
µ : STS(d) →TS given by µ : P →PTS, µ(i) = qi for each step i of d.
△
Note that the mapping µ induces a function µπ : π(P) →πTS(PTS) mapping
each rule in STS(d) to the corresponding rule in TS, where µπ(π(q)) = πTS(µ(q)).
Given the process Prc(d) = ((T, P, π), µ) of a derivation d, often we will denote
by seq(d) ∈P∗the sequence of production names of Prc(d) that corresponds to the
order in which productions are applied in d; from the canonical choice of production
names in P (see Def. 5.60) it follows that seq(d) = (1, 2, . . . , n), where n is the length
of d.
The notion of processes for transformation sequences corresponds to the notion
of processes for Petri nets given by an occurrence net together with a Petri net mor-
phism into the system Petri net. Moreover, as shown in [CHS08] the process con-
struction yields a pure STS, meaning that no rule deletes and produces again the
same part of a subobject, i.e., L ∩R = K. This terminology is borrowed from the
theory of elementary net systems, where a system which does not contain transi-
tions with a self-loop is called “pure”. Therefore, the class of pure STSs can be seen
as a generalisation of elementary nets to the setting of M-adhesive transformation
systems, and thus as a generalisation of the Petri net class of occurrence nets.
The following relations between the rules of an STS with NACs specify the pos-
sible dependencies among them: the ﬁrst four relations are discussed in [CHS08],
while the last two are introduced in [Her09, HCE14].
Deﬁnition 5.64 (Relations on rules). Let q1 and q2 be two rules in an STS S =
(T, P, π) with π(qi) = ((Li, Ki, Ri), Ni) for i ∈{1, 2}. The relations on rules are deﬁned
on P as shown in Table 5.1.
△
In words, q1 <rc q2 (read: “q1 causes q2 by read causality”) if q1 produces an
element which is used but not consumed by q2. Analogously, q1 <wc q2 (read: “q1
causes q2 by write causality”) if q1 produces an element which is consumed by

132
5 M-Adhesive Transformation Systems
Table 5.1 Relations on rules in an STS
Name
Notation
Condition
Read Causality
q1 <rc q2
R1 ∩K2 ⊈K1
Write Causality
q1 <wc q2
R1 ∩L2 ⊈K1 ∪K2
Deactivation
q1 <d q2
K1 ∩L2 ⊈K2
Independence
q1 ^ q2
(L1 ∪R1) ∩(L2 ∪R2) ⊆K1 ∩K2
Weak NAC Enabling
q1<wen[i]q2
0 < i ≤|N2| ∧L1 ∩N2[i] ⊈K1 ∪L2
Weak NAC Disabling
q1<wdn[i]q2
0 < i ≤|N1| ∧N1[i] ∩R2 ⊈L1 ∪K2
Table 5.2 Relations on rules in the example STS
cont1 <wc stop1 stop1<wen[1]cont1 stop2<wen[2]cont1 cont1<wdn[1]cont1 cont2<wdn[2]cont2
cont2 <wc stop2 stop1<wen[1]cont2 stop2<wen[2]cont2 cont2<wdn[1]cont1 cont1<wdn[2]cont2
q2 and q1 <d q2 (read: “q1 is deactivated by q2”) precisely when q1 preserves an
element which is consumed by q2, meaning that q1 is not applicable afterwards.
Furthermore q1 ^ q2 if they overlap only on items that are preserved by both.
Finally, q1 <wen[i] q2 (read: “q1 weakly enables q2 at i”) if q1 deletes a piece of the
NAC N[i] of q2; instead q1 <wdn[i] q2 (“q2 weakly disables q1 at i”) if q2 produces a
piece of the NAC N[i] of q1. It is worth stressing that the relations introduced above
are not transitive in general.
Example 5.65 (Relations of an STS). The rules of STS(d) in Ex. 5.62 are related by
the dependencies listed in Table 5.2.
△
Deﬁnition 5.66 (STS-switch equivalence of sequences disregarding NACs). Let
S = (T, P, π) be an STS, let d be a derivation in S disregarding NACs and
let s = ⟨q1, . . . , qn⟩be its corresponding sequence of rule occurrence names. If
qk ^ qk+1, then the sequence s′ = ⟨q1, . . . , qk+1, qk, . . . , qn⟩is STS-switch-equivalent
to the sequence s, written s
sw∼S s′. Switch equivalence
sw≈S of rule sequences is
the transitive closure of sw∼S .
△
In order to characterise the set of possible permutations of transformation steps
of a given transformation sequence, we now deﬁne suitable conditions for permu-
tations of rule occurrences. We call rule sequences s of a derived STS STS(d) le-
gal sequences if they are switch-equivalent without NACs to the sequence of rules
seq(d) of d and if the following condition concerning NACs holds: For every NAC
N[i] of a rule qk, either there is a rule which deletes part of N[i] and is applied before
qk, or there is a rule which produces part of N[i] and is applied after qk−1. In both
cases, N[i] cannot be present when applying qk, because the STS STS(d) is a sort of
“unfolding” of the transformation sequence, and every subobject is created at most

5.3 Process Analysis
133
once and deleted at most once (see [CHS08]). Note that the ﬁrst condition already
ensures that each rule name in P occurs exactly once in a legal sequence s.
Deﬁnition 5.67 (Legal sequence). Let d = (d1; . . . ; dn) be a NAC-consistent trans-
formation sequence in an M-adhesive TS, and let STS(d) = (T, P, πN) be its derived
STS. A sequence s = ⟨q1; . . . ; qn⟩of rule names of P is locally legal at position
k ∈{1, . . . , n} with respect to d if the following conditions hold:
1. s
sw≈STS(d) seq(d)
2. ∀NAC Nk[i] of qk :
 ∃e ∈{1, . . . , k −1} : qe<wen[i]qk or
∃l ∈{k, . . . , n} : qk<wdn[i]ql.
!
A sequence s of rule names is legal with respect to d, if it is locally legal at all
positions k ∈{1, ..., n} with respect to d.
△
Deﬁnition 5.68 (STS equivalence of rule sequences). Let d be a NAC-consistent
transformation sequence of an M-adhesive TS and let Prc(d) = (STS(d), µ) be its
derived process. Two sequences s, s′ of rule names in STS(d) are STS-equivalent,
written s ≈STS(d) s′, if they are legal sequences with respect to d. The set of all STS-
equivalent sequences of Prc(d) is given by Seq(d) = {s | s ≈STS(d) seq(d)}. More-
over, the speciﬁed class of transformation sequences of Seq(d) is given by Trafo(s) =
[trafoSTS(d)(s)] for single sequences and Trafo(Seq(d)) = S
s∈Seq(d) Trafo(s) for the
complete set.
△
Theorem 5.69 (Characterisation of permutation equivalence based on STSs).
Given the process Prc(d) of a NAC-consistent transformation sequence d.
1. The class of permutation-equivalent transformation sequences of d coincides
with the set of derived transformation sequences of the process Prc(d) of d:
π-Equ(d) = Trafo(Seq(d))
2. The mapping Trafo deﬁnes a bijective correspondence between STS-equivalent
sequences of rule names and permutation-equivalent transformation sequences:
Trafo : Seq(d) −
∼→(π-Equ(d))/
△
Proof (Idea). Let d be a NAC-consistent transformation sequence in an M-adhesive
TS and let Prc(d) = (S, µ) be the process of d with S = (T, P, π). We have to show
that each STS-equivalent rule sequence s′ of seq(d) in S deﬁnes a permutation-
equivalent transformation sequence trafoS TS (d)(s′) of d; and vice versa, for each
permutation-equivalent transformation sequence d′ of d there is an STS-equivalent
rule sequence s′ of seq(d) in S such that d′  trafoS TS (d)(s′).
∀s′ ∈P∗: s′ ≈STS(d) seq(d) ⇒trafoS TS (d)(s′)
π≈d
(1)
∀d′ :
d′
π≈d ⇒∃s′. s′ ≈STS(d) seq(d) ∧trafoS TS (d)(s′)  d′ (2)
The proof is based on Thm. 1 in [Her09], which concerns the results (1) and
(2) for the case of adhesive transformation systems with NACs and monomor-
phic matches and is extended to the case of M-adhesive transformation systems
in [HCE14]. By Def. 5.68 we have that d′
∈Trafo(Prc(d)) is equivalent to
d′  trafoSTS(d)(s′) and s′ ≈STS(d) seq(d). Using (1) and (2) above together with
Def. 5.49, we derive π-Equ(d) = Trafo(Prc(d)).
⊓⊔

134
5 M-Adhesive Transformation Systems
According to Theorem 5.69, the construction of the process Prc(d) of a transfor-
mation sequence d speciﬁes the equivalence class of all transformation sequences
which are permutation-equivalent to d. In the next section, we present an eﬃcient
analysis technique for processes based on Petri nets.
5.3.3 Analysis Based on Petri Nets
In order to eﬃciently analyse the process of a transformation sequence, we present
the construction of its dependency net, given by a P/T Petri net which speciﬁes only
the dependencies between the transformation steps. All details about the internal
structure of the objects and the transformation rules are excluded. The names of
the generated places of the dependency net are composed of constant symbols and
numbers, where constant symbols s are denoted by s. We use the monoidal notation
of P/T Petri nets according to [MM90] and ISO/IEC 15909-1:2004 [ISO04], which
is equivalent to the classical notation of P/T Petri nets [Rei85].
Deﬁnition 5.70 (Dependency net DNet of a transformation sequence).
Let d
be a NAC-consistent transformation sequence of an M-adhesive TS, let STS(d) =
(T, P, π) be the generated STS of d and let s = seq(d) = ⟨q1, . . . , qn⟩be the sequence
of rule names in STS(d) according to the steps in d. The dependency net of d is given
by the following marked Petri net DNet(d) = (Net, M), Net = (PL, TR, pre, post):
• TR = P = {i | 1 ≤i ≤|P|}
• PL = {p(q) | q ∈TR} ∪{p(q′<xq) | q, q′ ∈TR, x ∈{rc, wc, d}, q′ <x q}
∪{p(q,N[i]) | q ∈TR, π(q) = ((Lq, Kq, Rq), N), 0 < i ≤|N|, q ≮wdn[i] q}
• pre(q) = p(q) ⊕
X
q′<xq
x∈{rc,wc,d}
p(q′<xq) ⊕
X
q′<wdn[i]q
q′,q
p(q′,N[i]) ⊕
X
p(q,N[i])∈PL
p(q,N[i])
• post(q) =
X
q<xq′
x∈{rc,wc,d}
p(q<xq′) ⊕
X
q<wen[i]q′
p(q′,N[i]) ⊕
X
p(q,N[i])∈PL
p(q,N[i])
• M =
X
q∈TR
p(q) ⊕
X
q′<wdn[i]q
p(q′,N[i])∈PL
p(q′,N[i])
△
Fig. 5.22 shows how the dependency net is constructed algorithmically. The con-
struction steps are performed in the order in which they appear in the table. Each
step is shown as a rule, where gray lines and plus signs mark the elements to be

5.3 Process Analysis
135
STS(d) = (T,P,¼)
DNet(d) = ((PL,TR,pre,post),M)
1. For each q ∊ P
2. For all q,q' ∊P, q <x q', x ∈{rc,wc,d }
3. For all q∊P with NACs N and
for all 0<i≤|N| with q≮wdn[i]q
a) For N[i] of q
b) For all q' ∊P: q' <wen[i] q
c) For all q' ∊P: q <wdn[i] q'
p(q<xq' )
q'
+
+
+
q
p(q,N[i])
q
+
+
p(q,N[i])
q'
+
q'
+
+
p(q,N[i])
p(q)
q
+
+
+
+
+
+
Fig. 5.22 Visualisation of the construction of the Petri net
inserted. The matched context that is preserved by a rule is marked by black lines,
e.g., in Step 2 the new place “p(q <x q′)” is inserted between the already existing
transitions q and q′. The tokens of the initial marking of the net are represented by
bullets that are connected to their places via arcs. In the ﬁrst step, each rule q of the
STS is encoded as a transition and it is connected to a marked place, which prevents
the transition from ﬁring more than once. In Step 2, between each pair of transitions
in each of the relations <rc, <wc and <d, a new place is created in order to enforce
the corresponding dependency. The rest of the construction is concerned with places
which correspond to NACs and can contain several tokens in general. Each token in
such a place represents the absence of a piece of the NAC; therefore if the place is
empty, the NAC is complete.
In this case, by Step (3a) the transition cannot ﬁre. Consistently with this intu-
ition, if q′ <wen[i] q, i.e., transition q′ consumes part of the NAC N[i] of q, then by
Step (3b) q′ produces a token in the place corresponding to N[i]. Symmetrically, if
q<wdn[i] q′, i.e., q′ produces part of NAC N[i] of q, then by Step (3c) q′ consumes
a token from the place corresponding to N[i]. Notice that each item of a NAC is
either already in the start graph of the transformation sequence or produced by a
single rule. If a rule generates part of one of its NACs, say N[i] (q <wdn[i] q), then
by the acyclicity of Prc(d) the NAC N[i] cannot be completed before the ﬁring of
q: therefore we ignore it in the third step of the construction of the dependency net.
Examples of such weakly self-disabling rules are rules (1 = cont1) and (3 = cont2)
in Fig. 5.20, where the speciﬁc NACs coincide with the right-hand sides of the rules
(NAC2 = R).
Note that the constructed net in general is not a safe one, because the places
for the NACs can contain several tokens. Nevertheless it is a bounded P/T net. The
bound is the maximum of 1 and the maximal number of adjacent edges at a NAC
place minus 2.

136
5 M-Adhesive Transformation Systems
1
3
2
4
p(1<wc 2)
p(2)
p(1,N[2])
p(1)
p(3)
p(3<wc 4)
p(3,N[1])
p(4)
(cont1)
(stop1)
(cont2)
(stop2)
Fig. 5.23 Dependency net DNet(d) as Petri net
Example 5.71 (Dependency net). Consider the transformation sequence d in
Fig. 5.16 from Ex. 5.47 and its derived STS in Ex. 5.62. The marked Petri net in
Fig. 5.23 is the dependency net DNet(d) according to Def. 5.70. The places encod-
ing the write causality relation are “p(1 <wc 2)” and “p(3 <wc 4)”. For the NAC
dependencies we have the places p(1,N[2]) for the second instantiated NAC in
the ﬁrst transformation step of d and p(3,N[1]) for the third transformation step
and its ﬁrst instantiated NAC. The other two instantiated NACs are not considered,
because the corresponding rules are weakly self-disabling (q <wdn[i] q). At the be-
ginning, transitions 1 and 2 (cont1 and cont2) are enabled. The ﬁring sequences
according to the transformation sequences d and d′ in Figs. 5.16 and 5.17 can be
executed and they are the only complete ﬁring sequences of this net. Thus, the net
speciﬁes exactly the transformation sequences which are permutation-equivalent to
d.
△
We now show that we can exploit the constructed Petri net DNet(d) to charac-
terise STS equivalence of sequences of rule occurrences by Fact 5.73. Note that
according to Def. 5.70 each sequence s of rule names in the STS of Prc(d) can be
interpreted as a sequence of transitions in the derived marked Petri net DNet(d), and
vice versa. This correspondence allows us to transfer the results of the analysis of
the dependency net back to the STS. Notice that the construction of the dependency
net (Def. 5.70) ensures that each transition can ﬁre at most once by construction.
Deﬁnition 5.72 (Transition-complete ﬁring sequences). A ﬁring sequence of a
Petri net is called transition-complete if each transition of the net occurs exactly
once. The set of transition-complete ﬁring sequences of a dependency net DNet(d)
is denoted by FSeq(DNet(d)).
△
Fact 5.73 (Characterisation of STS equivalence based on Petri nets). Given the
process Prc(d) and the dependency net DNet(d) of a NAC-consistent transformation
sequence d of an M-adhesive transformation system with M-matches, the class of
STS-equivalent sequences of seq(d) coincides with the set of transition-complete
ﬁring sequences in the dependency net DNet(d), i.e., Seq(d) = FSeq(DNet(d)).
△
Remark 5.74 (Bijective correspondence). Analogously to Theorem 5.69, there is
also a bijective correspondence between STS sequences and transition-complete

5.3 Process Analysis
137
ﬁring sequences, which is in this case directly given by the identity function
id : Seq(d) −
∼→FSeq(DNet(d)).
△
Proof (Idea). The proof (see [HCE14]) shows that s
≈STS(d)
seq(d) iﬀs is a
transition-complete ﬁring sequence of DNet(d). Direction “⇒” uses the property
that s is a legal sequence with respect to d in STS(d) and thus s is a permutation of
seq(d) and each transition occurs exactly once in s. For each transition, we can en-
sure its activation using Def. 5.70. Direction “⇐” starts with the transition-complete
ﬁring sequence s of DNet(d) and shows that s is a legal sequence with respect to d
in STS(d), i.e., that the two conditions in Def. 5.67 hold.
⊓⊔
In order to solve the challenge of computing the set of all permutation-equivalent
transformation sequences for a given one, we can now combine the presented re-
sults, leading to our forth main result by Theorem 5.75 below, where we show that
the analysis of permutation equivalence can be completely performed on the depen-
dency net DNet(d).
Theorem 5.75 (Analysis of permutation equivalence based on Petri nets). Given
the process Prc(d) and the dependency net DNet(d) of a NAC-consistent transfor-
mation sequence d.
1. The class of permutation-equivalent transformation sequences of d coincides
with the set of derived transformation sequences using DNet(d):
π-Equ(d) = Trafo(FSeq(DNet(d))).
2. The mapping Trafo according to Def. 5.68 deﬁnes a bijective correspondence
between transition-complete ﬁring sequences and permutation-equivalent trans-
formation sequences:
Trafo : FSeq(DNet(d)) −
∼→(π-Equ(d))/.
△
Proof. By combining the characterisations of Theorem 5.69 and Fact 5.73 we
derive the equality π-Equ(d) = Trafo(FSeq(DNet(d))), and the bijection Trafo :
FSeq(DNet(d)) −
∼→(π-Equ(d))/ is given by Trafo : Seq(d) −
∼→(π-Equ(d))/ of The-
orem 5.69 with Seq(d) = FSeq(DNet(d)) in Fact 5.73.
⊓⊔
Remark 5.76 (Analysis of permutation equivalence). We now describe how the pre-
sented results can be used for an eﬃcient analysis of permutation equivalence, i.e.,
for the generation of the complete set of permutation-equivalent transformation se-
quences for a given one and for checking permutation equivalence of speciﬁc ones.
Given a NAC-consistent transformation sequence with general matches and NAC
schemata, we can ﬁrst reduce the analysis problem to the derived instantiated trans-
formation sequence with M-matches and standard NACs according to Fact 5.53 and
Rem. 5.54. According to Theorem 5.75, we can perform the analysis of permutation
equivalence based on Petri nets by ﬁrst constructing the dependency net DNet(d).
For the generation of all permutation-equivalent sequences, we construct the com-
plete reachability graph of DNet(d), where each path speciﬁes one permutation-
equivalent transformation sequence up to isomorphism. If only speciﬁc reorderings
of the transformation steps shall be checked, then the corresponding ﬁring sequences
are checked for being executable in DNet(d).
△

138
5 M-Adhesive Transformation Systems
Another computational model closely related to transformation systems with
NACs are Petri nets with inhibitor arcs (or inhibitor nets) [JK95, BP99, KK04,
BBCP04]. In such nets, a transition cannot ﬁre if there are tokens on its inhibitor
places, i.e., on the places that are linked to it with inhibitor arcs.2 Therefore these
places play a role conceptually similar to NACs’.
Note that the proposed notion of permutation equivalence would be original also
in the framework of inhibitor nets. In fact, if we encode the system of Ex. 5.47 into
an inhibitor net (by forgetting the graphical structure), the standard semantics for
such nets would not consider equivalent the ﬁring sequences corresponding to the
two transformation sequences d of Fig. 5.16 and d′ of Fig. 5.17.
2 For simplicity we consider only the case of unweighted inhibitor arcs.

Chapter 6
Multi-amalgamated Transformations
In this chapter, we introduce amalgamated transformations. An amalgamated rule
is based on a kernel rule, which deﬁnes a ﬁxed part of the match, and multi rules,
which extend this ﬁxed match. From a kernel and a multi rule, a complement rule
can be constructed which characterises the eﬀect of the multi rule exceeding the
kernel rule. If multiple rules can be applied using the same kernel rule, as a ﬁrst
main result the Multi-amalgamation Theorem states that a bundle of s-amalgamable
transformations is equivalent to a corresponding amalgamated transformation. An
interaction scheme is deﬁned by a kernel rule and available multi rules, leading
to a bundle of multi rules that speciﬁes in addition how often each multi rule is
applied. Amalgamated rules are in general standard rules in M-adhesive transfor-
mation systems; thus all the results follow. In addition, we are able to reﬁne parallel
independence of amalgamated rules based on the induced multi rules. If we extend
an interaction scheme as large as possible we can describe the transformation for
an unknown number of matches, which otherwise would have to be deﬁned by an
inﬁnite number of rules. This leads to maximal matchings, which are useful for
deﬁning the semantics of models. For this chapter, we require an M-adhesive cate-
gory with binary coproducts as well as initial and eﬀective pushouts (see Sect. 4.3).
The theoretical results in this chapter are based on [GHE14].
In Sect. 6.1, kernel, multi and complement rules are presented. In Sect. 6.2, we
introduce amalgamated rules and transformations and show some important results
in Sect. 6.3. In Sect. 6.4, we deﬁne interaction schemes and maximal matching and
use these concepts for the ﬁring semantics of elementary Petri nets modelled by
typed graphs using amalgamation. This chapter is based on [EGH+14, Gol11].
6.1 Kernel Rules, Multi Rules, and Complement Rules
In the following, a bundle represents a family of morphisms or transformation steps
with the same domain, which means that a bundle of things always starts at the same
object.
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_6
139

140
6 Multi-amalgamated Transformations
A kernel morphism describes how a smaller rule, the kernel rule, is embedded
into a larger rule, the multi rule. The multi rule has its name because it can be
applied multiple times for a given kernel rule match, as described later. We need
some more technical preconditions to make sure that the embeddings of the L-, K-,
and R-components as well as the application conditions are consistent and allow us
to construct a complement rule.
Deﬁnition 6.1 (Kernel morphism). Given rules p0 = (L0
l0
←−K0
r0
−→R0, ac0) and
L0
K0
R0
L1
K1
R1
ac0
ac1
p0 :
p1 :
l0
r0
l1
r1
s1,L
s1,K
s1,R
s1
(11)
(21)
p1 = (L1
l1
←−K1
r1
−→R1, ac1), a
kernel morphism s1 : p0 →p1,
s1 = (s1,L, s1,K, s1,R) consists of
M-morphisms s1,L : L0 →L1,
s1,K : K0 →K1, and s1,R : R0 →
R1 such that the diagrams (11) and (21) are pullbacks, (11) has a pushout complement
(1′
1) for s1,L ◦l0, and ac1 ⇒Shift(s1,L, ac0). In this case, p0 is called kernel rule and
L0
K0
L1
L10
R0
E1
ac′
1
l0
w1
s1,L
u1
r0
e11
v1
(1′
1)
(31)
p1 multi rule.
ac0 and ac1 are complement-compatible
w. r. t. s1 if there is some application con-
dition ac′
1 on the pushout complement L10
such that ac1

Shift(s1,L, ac0) ∧L(p∗
1,
Shift(v1, ac′
1)) for the pushout (31) and p∗
1 =
(L1
u1
←−L10
v1
−→E1).
△
Remark 6.2. The complement-compatibility makes sure that there is a decomposi-
tion of ac1 into parts on L0 and L10. The latter are used later for the application
conditions of the complement rule, which ensure the equivalence of the composi-
tion.
△
Example 6.3. To explain the concept of amalgamation, in our example we model a
small transformation system for switching the direction of edges in labeled graphs,
where we have diﬀerent labels for edges—black and dotted ones. The kernel rule p0
is depicted in Fig. 6.1. It selects a node with a black loop, deletes this loop, and adds
a dotted loop, all of this if no dotted loop is already present. The matches are deﬁned
by the numbers at the nodes and can be induced for the edges by their position.
In Fig. 6.2, two multi rules p1 and p2 are shown which extend the rule p0 and
in addition reverse an edge if no backward edge is present. They also inherit the
application condition of p0, forbidding a dotted loop at the selected node. There is
a kernel morphism s1 : p0 →p1, as shown in the top of Fig. 6.2, with pullbacks
(11), (21) and pushout complement (1′
1). Similarly, there is a kernel morphism s2 :
p0 →p2, as shown in the bottom of Fig. 6.2, with pullbacks (12), (22) and pushout
complement (1′
2).
For the application conditions, it holds that ac1 = Shift(s1,L, ac0) ∧¬ ∃a1 
Shift(s1,L, ac0) ∧L(p∗
1, Shift(v1, ¬ ∃a′
1)) with a′
1 as shown in the left of Fig. 6.3.
We have that Shift(v1, ¬ ∃a′
1) = ¬ ∃a11, because square (∗) is the only possible
commuting square leading to morphism (a11, b11) being jointly surjective and b11

6.1 Kernel Rules, Multi Rules, and Complement Rules
141
p0 :
ac0
ac0 = ¬ ∃a0
1
L0
1
K0
1
R0
1
L0
1
l0
r0
a0
Fig. 6.1 The kernel rule p0 deleting a loop at a node
p0 :
ac0
1
L0
1
K0
1
R0
p1 :
ac1
ac1 = Shift(s1,L, ac0) ∧¬ ∃a1
1
2
L1
1
2
K1
1
2
R1
1
L0
1
K0
1
2
L1
1
2
L10
1
2
L1
1
2
p0 :
ac0
1
L0
1
K0
1
R0
1
L0
1
K0
p2 :
ac2
ac2 = Shift(s2,L, ac0) ∧¬ ∃a2
1
3
L2
1
3
K2
1
3
R2
1
3
L2
1
3
L20
1
3
L2
1
3
l0
r0
l1
r1
s1,L
s1,K
s1,R
l0
s1,L
u1
w1
a1
l0
r0
l2
r2
s2,L
s2,K
s2,R
l0
s2,L
u2
w2
a2
(11)
(21)
(1′
1)
(12)
(22)
(1′
2)
Fig. 6.2 The multi rules p1 and p2 describing the reversion of an edge
being injective. L(p∗
1, ¬ ∃a11) = ¬ ∃a1, as shown by the two pushout squares
(PO1) and (PO2) in the middle of Fig. 6.3. Thus ac′
1 = ¬ ∃a′
1, and ac0 and ac1 are
complement-compatible w. r. t. s1. Similarly, it can be shown that ac0 and ac2 are
complement-compatible w. r. t. s2.
△
For a given kernel morphism, the complement rule is the remainder of the multi
rule after the application of the kernel rule, i.e., it describes what the multi rule does
in addition to the kernel rule.

142
6 Multi-amalgamated Transformations
1
2
L10
1
2
E1
1
2
L1
1
2
L10
1
2
E1
1
2
L10
1
2
L1
1
2
1
2
1
2
1
2
1
2
1
2
1
2
v1
u1
v1
u11
b11
a′
1
a1
a′
1
a11
a11
a1
(∗)
(PO1)
(PO2)
Fig. 6.3 Constructions for the application conditions
Theorem 6.4 (Existence of complement rule). Given rules p0 = (L0
l0
←−K0
r0
−→
R0, ac0) and p1 = (L1
l1
←−K1
r1
−→R1, ac1), and a kernel morphism s1 : p0 →p1,
there exists a rule p1 = (L1
l1
←−K1
r1
−→R1, ac1) and a jointly epimorphic cospan
R0
e11
−→E1
e12
←−L1 such that the E1-concurrent rule p0∗E1 p1 exists and p1 = p0∗E1 p1
for rules without application conditions. Moreover, if ac0 and ac1 are complement-
compatible w. r. t. s1 then p1  p0 ∗E1 p1 also for rules with application conditions.
L0
K0
R0
L1
K1
R1
L1
L10
E1
R10
R1
K1
ac0
ac1
ac1
ac′
1
l0
r0
l1
r1
u1
v1
u1
v1
s1,L
w1
e11
e12
w1
t1
l1
r1
l10
r10
(1′
1)
(31)
(81) + (91)
(91)
(131)
△
Proof. First, we consider the construction without application conditions. Since s1
is a kernel morphism the following diagrams (11) and (21) are pullbacks and we
have a pushout complement (1′
1) for s1,L ◦l0. Now construct the pushout (31) and
the initial pushout (41) over s1,R with b1, c1 ∈M.
L0
K0
R0
L1
K1
R1
L0
K0
R0
L1
L10
E1
l0
r0
l1
r1
s1,L
s1,K
s1,R
l0
r0
u1
v1
s1,L
w1
e11
(11)
(21)
(1′
1)
(31)

6.1 Kernel Rules, Multi Rules, and Complement Rules
143
B1
C1
R0
R1
P1
S 1
K0
b1
c1
s1,R
s12
s11
s13
r0
(41)
(51)
Consider P1 as the pullback object of r0 and b1, and
the pushout (51) where we obtain an induced morphism
s13 : S 1 →R0 with s13 ◦s12 = b1, s13 ◦s11 = r0, and
s13 ∈M by eﬀective pushouts.
Since (11) is a pullback, Lem. B.1 implies that there
is a unique morphism l10 : K1 →L10 with l10 ◦s1,K =
w1, u1 ◦l10 = l1, and l10 ∈M, and we can construct
pushouts (61)–(91) as a decomposition of pushout (31),
which leads to L1 and K1 of the complement rule, and with (71) + (91) being a
pushout, e11 and e12 are jointly epimorphic.
L0
K0
L1
L10
K1
K0
S 1
R0
K1
K1
R10
L10
L1
E1
l0
u1
s1,L
w1
l1
l10
s1,K
s11
s1,K
s13
s14
u12
v11
w1
l10
u11
l1
e12
u1
e11
(1′
1)
(81)
(91)
(61)
(71)
The pushout (41) can be decomposed into pushouts (101) and (111), obtaining the
right-hand side R1 of the complement rule, while pullback (21) can be decomposed
into pushout (61) and square (121), which is a pullback by Lem. B.2.
B1
C1
S 1
R1
R0
R1
K0
K1
S 1
K1
R0
R1
s12
s13
u13
s1,R
t1
s11
s13
s1,K
s14
s1,R
v11
v12
(101)
(111)
(61)
(121)
Now Lem. B.1 implies that there is a unique morphism r1 : K1 →R1 with
r1 ◦s14 = u13, t1 ◦r1 = v12, and r1 ∈M. With pushout (71) there is a unique mor-
phism v1 : R10 →R1 and by pushout decomposition of (111) = (71) + (131) square
(131) is a pushout.
S 1
R0
R1
R1
K1
S 1
R0
K1
R10
R1
R1
S 1
R0
K1
R10
R1
s14
r1
s13
v12
t1
u12
v1
s13
s14
u12
w1
s1,R
v1
v12
s13
u13
s1,R
t1
s14
v12
r1
(111)
(71)
(71)
(131)
Moreover, (81) + (91) as a pushout over M-morphisms is also a pullback which
completes the construction of the rule, and p1 = p0 ∗E1 p1 for rules without applica-
tion conditions.
For the application conditions, suppose ac1  Shift(s1,L, ac0) ∧L(p∗
1, Shift(v1,
ac′
1)) for p∗
1 = (L1
u1
←−L10
v1
−→E1) with v1 = e12 ◦u11 and ac′
1 over L10. Now deﬁne
ac1 = Shift(u11, ac′
1), which is an application condition on L1.

144
6 Multi-amalgamated Transformations
We have to show that (p1, acp0∗E1 p1)  (p1, ac1). By construction of the E1-
concurrent rule we have that L(p∗
1, Shift(e12, ac1))  L(p∗
1, Shift(e12, Shift(u11, ac′
1)))
 L(p∗
1, Shift(e12 ◦u11, ac′
1))  L(p∗
1, Shift(v1, ac′
1)). It follows that acp0∗E1 p1 
Shift(s1,L, ac0)∧L(p∗
1, Shift(e12, ac1))  Shift(s1,L, ac0)∧L(p∗
1, Shift(v1, ac′
1))  ac1.
L0
L1
K1
K0
L10
S 1
K1
L1
R10
R0
S 1
E1
K1
L1
K1
R10
R1
C1
R1
B1
S 1
R0
l0
s11
s13
s13
l1◦s14
l1
r1
u13
s12
l1
v11
w1
u1
u11
e12
u1
v1
s1,R
l1
l10
r10
r1
s1,L
s1,K
s14
u12
l10
l1
u1
e12
w1
t1
s13
b1
(11)
(61)
(71)
(81)
(91)
(81) + (91)
(71) + (91)
(91)
(101)
(131)
(111)
⊓⊔
Remark 6.5. Note that by construction the interface K0 of the kernel rule has to be
preserved in the complement rule. The construction of p1 is not unique w. r. t. the
property p1 = p0 ∗E1 p1, since other choices for S 1 with M-morphisms s11 and s13
also lead to a well-deﬁned construction. In particular, one could choose S 1 = R0,
leading to p1 = E1
u1
←−R10
v1
−→R1. Our choice represents the smallest possible
complement, which should be preferred in most application areas.
△
Deﬁnition 6.6 (Complement rule). Given rules p0 = (L0
l0
←−K0
r0
−→R0, ac0) and
p1 = (L1
l1
←−K1
r1
−→R1, ac1), and a kernel morphism s1 : p0 →p1 such that ac0
and ac1 are complement-compatible w. r. t. s1, the rule p1 = (L1
l1
←−K1
r1
−→R1, ac1)
constructed in Theorem 6.4 is called complement rule (of s1).
If we choose ac1 = true, this leads to the weak complement rule (of s1) p1 =
(L1
l1
←−K1
r1
−→R1, true), which is deﬁned even if ac0 and ac1 are not complement-
compatible.
△
Example 6.7. Consider the kernel morphism s1 depicted in Fig. 6.2. Using Theo-
rem 6.4 we obtain the complement rule depicted in the top row of Fig. 6.4 with the
application condition ac1 = ¬ ∃a1 constructed in the right of Fig. 6.3. The diagrams
in Fig. 6.5 show the complete construction as done in the proof. Similarly, we obtain
a complement rule for the kernel morphism s2 : p0 →p2 in Fig. 6.2, which is shown
in the bottom row of Fig. 6.4.
△
Each direct transformation via a multi rule can be decomposed into a direct trans-
formation via the kernel rule followed by a direct transformation via the (weak)
complement rule.
www.allitebooks.com

6.1 Kernel Rules, Multi Rules, and Complement Rules
145
p1 :
ac1
ac1 = ¬ ∃a1
1
2
L1
1
2
K1
1
2
R1
1
2
L1
1
2
p2 :
ac2
ac2 = ¬ ∃a2
1
3
L2
1
3
K2
1
3
R2
1
3
L2
1
3
l1
r1
a1
l2
r2
a2
Fig. 6.4 The complement rules for the kernel morphisms
1
L0
1
K0
1
S 1
1
R0
1
2
L1
1
2
K1
1
2
K1
1
2
R10
1
2
L10
1
2
L1
1
2
E1
1
2
R10
1
2
R1
1
R0
1
2
L1
1
2
K1
1
2
R1
1
S 1
1
2
C1
1
B1
1
S 1
1
2
K1
l0
s11
s13
l1
v11
w1
u11
e12
l1
r1
u13
u1
v1
s1,R
u1
s13
l1◦s14
s1,L
s1,K
s14
u12
l10
l1
u1
s13
e12
w1
t1
s12
l1
l10
r10
r1
(11)
(61)
(71)
(71) + (91)
(91)
(131)
(111)
(101)
(81)
(91)
(81) + (91)
Fig. 6.5 The construction of the complement rule for the kernel morphism s1

146
6 Multi-amalgamated Transformations
Fact 6.8. Given rules p0 = (L0
l0
←−K0
r0
−→R0, ac0) and p1 = (L1
l1
←−K1
r1
−→
R1, ac1), a kernel morphism s1
:
p0
→
p1, and a direct transformation
G
G0
G1
p0,m0
p1,m1
p1,m1
t1 : G =
p1,m1
===⇒G1, t1 can be decomposed into
the transformation G =
p0,m0
===⇒G0 =
p1,m1
===⇒G1 with
m0 = m1◦s1,L using either the weak complement
rule p1 or the complement rule p1 if ac0 and
ac1 are complement-compatible with respect to
s1.
△
Proof. If ac0 and ac1 are complement-compatible then we have that p1  p0 ∗E1 p1.
The analysis part of the Concurrency Theorem now implies the decomposition into
G =
p0,m0
===⇒G0 =
p1,m1
===⇒G1 with m0 = m1 ◦s1,L.
If ac0 and ac1 are not complement-compatible we can apply the analysis part
of the Concurrency Theorem without application conditions leading to a decom-
position into G =
p0,m0
===⇒G0 =
p1,m1
===⇒G1 with m0 = m1 ◦s1,L for rules without ap-
plication conditions. Since ac1 ⇒Shift(s1,L, ac0) and m1 |= ac1 we have that
m1 |= Shift(s1,L, ac0) ⇔m0 = m1 ◦s1,L |= ac0. Moreover, ac1 = true and m1 |= ac1.
This means that this is also a decomposition for rules with application conditions.
⊓⊔
6.2 Amalgamated Rules and Transformations
Now we consider not only single kernel morphisms, but bundles of them over a
ﬁxed kernel rule. The idea is to combine the multi rules of such a bundle to an amal-
gamated rule by gluing them along their common elements deﬁned by the kernel
rule.
Deﬁnition 6.9 (Multi-amalgamated rule).
Given rules pi = (Li
li
←−Ki
ri
−→
Ri, aci) for i = 0, . . . , n and a bundle of kernel morphisms s = (si : p0 →pi)i=1,...,n,
the (multi-)amalgamated rule ˜ps = ( ˜Ls
˜ls
←−˜Ks
˜rs
−→˜Rs, ˜acs) is constructed as the
componentwise colimit of the kernel morphisms.
ac0
aci
˜acs
L0
K0
R0
Li
Ki
Ri
˜Ls
˜Ks
˜Rs
p0 :
pi :
˜ps :
l0
r0
li
ri
si,L
si,K
si,R
˜ls
˜rs
ti,L
ti,K
ti,R
si
ti
(1i)
(2i)
(14i)
(15i)
This means that we construct
˜Ls = Colimit((si,L)i=1,...,n),
˜Ks = Colimit((si,K)i=1,...,n), and
˜Rs = Colimit((si,R)i=1,...,n), with
˜acs = V
i=1,...,n Shift(ti,L, aci), and
˜ls and ˜rs are induced by (ti,L ◦
li)i=1,...,n and (ti,R ◦ri)i=1,...,n, re-
spectively.
△
This deﬁnition is well-deﬁned. Moreover, if the application conditions of the
kernel morphisms are complement-compatible, this also holds for the application

6.2 Amalgamated Rules and Transformations
147
˜ps :
˜acs
˜acs = ¬ ∃b1 ∧¬ ∃b2 ∧¬ ∃b3 ∧¬ ∃b4
1
2
3
4
˜Ls
1
2
3
4
˜Ks
1
2
3
4
˜Rs
1
2
3
4
5
6
7
G
1
2
3
4
5
6
7
D
1
2
3
4
5
6
7
H
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
˜Ls
˜ls
˜rs
f
g
˜m
˜k
˜n
b1
b2
b3
b4
Fig. 6.6 An amalgamated transformation
condition of the amalgamated rule with respect to the morphisms from the original
kernel and multi rules.
Fact 6.10. The amalgamated rule as deﬁned in Def. 6.9 is well deﬁned and we have
kernel morphisms ti = (ti,L, ti,K, ti,R) : pi →˜ps for i = 0, 1, . . . , n. If ac0 and aci are
complement-compatible w. r. t. si for all i = 1, . . . , n then also aci and ˜
acs as well as
ac0 and ˜acs are complement compatible w. r. t. ti and t0, respectively.
△
Proof. See Appendix B.5.1.
⊓⊔
The application of an amalgamated rule yields an amalgamated transformation.
Deﬁnition 6.11 (Amalgamated transformation). The application of an amalga-
mated rule to a graph G is called an amalgamated transformation.
△
Example 6.12. Consider the bundle s = (s1, s2, s3 = s1) of the kernel morphisms
depicted in Fig. 6.2. The corresponding amalgamated rule ˜ps is shown in the top
row of Fig. 6.6. This amalgamated rule can be applied to the graph G, leading to the
amalgamated transformation depicted in Fig. 6.6, where the application condition
˜acs is obviously fulﬁlled by the match ˜m.
△
If we have a bundle of direct transformations of an object G, where for each
transformation one of the multi rules is applied, we want to analyse if the amalga-
mated rule is applicable to G combining all the single transformation steps. These
transformations are compatible, i.e., multi-amalgamable, if the matches agree on the
kernel rules, and are independent outside.

148
6 Multi-amalgamated Transformations
Deﬁnition 6.13 (Multi-amalgamable). Given a bundle of kernel morphisms s =
(si : p0 →pi)i=1,...,n, a bundle of direct transformations steps (G =
pi,mi
===⇒Gi)i=1,...n is
s-multi-amalgamable, or in short s-amalgamable, if
L0
Li
L j
G
si,L
mi
sj,L
mj
m0
• it has consistent matches, i.e., mi◦si,L = mj◦
s j,L =: m0 for all i, j = 1, . . . , n and
• it has weakly independent matches, i.e., for
all i , j consider the pushout complements
(1′
i) and (1′
j) for which there exist morphisms pi j : Li0 →Dj and pji : L j0 →Di
such that f j ◦pij = mi ◦ui and fi ◦pji = mj ◦uj.
Moreover, if ac0 and aci are complement-compatible we require gj ◦pi j |= ac′
i for
all j , i.
L0
K0
K0
Li
Li0
Lj0
Ki
Kj
Lj
G
Di
Dj
Ri
Rj
Gi
G j
ac′
i
ac′
j
ac0
si,L
sj,L
mi
mj
l0
wi
ui
l0
w j
uj
si,K
li
ki
fi
sj,K
l j
k j
f j
pi j
pji
rj
gj
nj
ri
gi
ni
(1′
i)
(1′
j)
△
As with to the characterisation of parallel independence in [EEPT06], we can
give a set-theoretical characterisation of weak independence.
Fact 6.14. For graphs and other set-based structures, weakly independent matches
means that
mi(Li) ∩mj(L j) ⊆m0(L0) ∪(mi(li(Ki)) ∩mj(lj(Kj)))
L0
Li
Ki
L j
Kj
G
si,L
sj,L
mi
mj
m0
li
l j
for all i , j = 1, . . . , n, i.e., the
elements in the intersection of the
matches mi and m j are either pre-
served by both transformations,
or are also matched by m0.
△
Proof. We have to prove the equivalence of mi(Li)∩mj(Lj) ⊆m0(L0)∪(mi(li(Ki))∩
mj(lj(Kj))) for all i , j = 1, . . . , n with the deﬁnition of weakly independent
matches.
“⇐” Let x = mi(yi) = mj(yj), and suppose x < m0(L0). Since (1′
i) is a pushout we
have that yi = ui(zi) ∈ui(Li0\wi(K0)), and x = mi(ui(zi)) = f j(pi(zi)) = mj(yj), and
by pushout properties y j ∈l j(Kj) and x ∈mj(lj(Kj)). Similarly, x ∈mi(li(Ki)).
“⇒” For x ∈Li0, x = wi(k) deﬁne pi j(x) = kj(sj,K(k)); then f j(pi j(x)) =
f j(kj(s j,K(k))) = mj(l j(s j,K(k))) = mj(s j,L(l0(k))) = mi(si,L(l0(k))) = mi(ni(wi(k))) =
mi(ui(x)). Otherwise, x < wi(K0), i.e., ui(x) < si,L(L0), and we deﬁne pi j(x) = y with
f j(y) = mi(ui(x)). This y exists, because either mi(ui(x)) < mj(Lj) or mi(ui(x)) ∈

6.2 Amalgamated Rules and Transformations
149
1
2
3
4
5
6
7
G
1
2
3
4
5
6
7
G1
1
2
3
4
5
6
7
G2
1
2
3
4
5
6
7
G3
p1, m1
p2, m2
p1, m3
Fig. 6.7 An s-amalgamable bundle of direct transformations
mj(L j) and then mi(ui(x)) ∈mj(l j(Kj)), and in both cases mi(ui(x)) ∈f j(Dj). Simi-
larly, we can deﬁne p ji with the required property.
⊓⊔
Example 6.15. Consider the bundle s = (s1, s2, s3 = s1) of kernel morphisms from
Ex. 6.12. For the graph G given in Fig. 6.6 we ﬁnd matches m0 : L0 →G, m1 :
L1 →G, m2 : L2 →G, and m3 : L1 →G mapping all nodes from the left-
hand side to their corresponding nodes in G, except for m3 mapping node 2 in L1
to node 4 in G. For all these matches, the corresponding application conditions are
fulﬁlled and we can apply the rules p1, p2, p1, respectively, leading to the bundle of
direct transformations depicted in Fig. 6.7. This bundle is s-amalgamable, because
the matches m1, m2, and m3 agree on the match m0, and are weakly independent,
because they only overlap in m0.
△
For an s-amalgamable bundle of direct transformations, each single transforma-
tion step can be decomposed into an application of the kernel rule followed by an
application of the (weak) complement rule, as shown in Fact 6.8. Moreover, all ker-
nel rule applications lead to the same object, and the following applications of the
complement rules are parallel independent.
Fact 6.16. Given a bundle of kernel morphisms s = (si : p0 →pi)i=1,...,n and an
G
G0
Gi
G j
p0,m0
pi,mi
pj,mj
pi,mi
pj,m j
s-amalgamable bundle of direct transformations
(G =
pi,mi
===⇒Gi)i=1,...,n, each direct transformation
G =
pi,mi
===⇒Gi can be decomposed into a trans-
formation G =
p0,m0
===⇒G0 =
pi,mi
===⇒Gi, where pi is
the (weak) complement rule of si. Moreover, the
transformations G0 =
pi,mi
===⇒Gi are pairwise par-
allel independent.
△
Proof. See Appendix B.5.2.
⊓⊔
If a bundle of direct transformations of an object G is s-amalgamable we can
apply the amalgamated rule directly to G, leading to a parallel execution of all the
changes done by the single transformation steps.

150
6 Multi-amalgamated Transformations
Theorem 6.17 (Multi-amalgamation Theorem).
Consider a bundle of kernel
morphisms s = (si : p0 →pi)i=1,...,n.
H
Gi
G
˜ps, ˜m
pi,mi
qi
1. Synthesis. Given an s-amalgamable bundle of di-
rect transformations (G =
pi,mi
===⇒Gi)i=1,...,n, there is an
amalgamated transformation G =
˜ps, ˜m
===⇒H and trans-
formations Gi =
qi=⇒H over the complement rules qi of
the kernel morphisms ti : pi →˜ps such that G =
pi,mi
===⇒Gi =
qi=⇒H is a decomposition
of G =
˜ps, ˜m
===⇒H.
2. Analysis. Given an amalgamated transformation G =
˜ps, ˜m
===⇒H, there are si-related
transformations G =
pi,mi
===⇒Gi =
qi=⇒H for i = 1, . . . , n such that the bundle (G =
pi,mi
===⇒
Gi)i=1,...,n is s-amalgamable.
3. Bijective Correspondence. The synthesis and analysis constructions are inverse
to each other up to isomorphism.
△
Proof. See Appendix B.5.3.
⊓⊔
Remark 6.18. Note that qi can be constructed as the amalgamated rule of the kernel
morphisms (pK0 →p j)j,i, where pK0 = (K0
idK0
←−K0
idK0
−→K0, true)) and pj is the
complement rule of pj.
For n = 2, the Multi-amalgamation Theorem specialises to the Amalgamation
Theorem in [BFH87, EGH+14] for rules without application conditions. Moreover,
if p0 is the empty rule, this is the Parallelism Theorem in [EHL10], since the trans-
formations are parallel independent for an empty kernel match.
△
Example 6.19. As already observed in Ex. 6.15, the transformations G =
p1,m1
===⇒G1,
G =
p2,m2
===⇒G2, and G =
p1,m3
===⇒G3 shown in Fig. 6.7 are s-amalgamable for the bundle
s = (s1, s2, s3 = s1) of kernel morphisms. Applying Fact 6.16, we can decom-
pose these transformations into a transformation G =
p0,m0
===⇒G0 followed by trans-
formations G0 =
p1,m1
===⇒G1, G0 =
p2,m2
===⇒G2, and G0 =
p1,m3
===⇒G3 via the complement
rules, which are pairwise parallel independent. These transformations are depicted
in Fig. 6.8.
Moreover, Theorem 6.17 implies that we obtain for this bundle of direct transfor-
mations an amalgamated transformation G =
˜ps, ˜m
===⇒H, which is the transformation al-
ready shown in Fig. 6.6. Vice versa, the analysis of this amalgamated transformation
leads to the s-amalgamable bundle of transformations G =
p1,m1
===⇒G1, G =
p2,m2
===⇒G2,
and G =
p1,m3
===⇒G3 in Fig. 6.7.
△
For an M-adhesive transformation system with amalgamation we deﬁne a set of
kernel morphisms and allow all kinds of amalgamated transformations using bun-
dles from this set.
Deﬁnition 6.20 (M-adhesive grammar with amalgamation).
An M-adhesive
transformation system with amalgamation AS A = (C, M, P, S) is an M-adhesive

6.3 Results for Amalgamated Transformations
151
1
2
3
4
5
6
7
G
1
2
3
4
5
6
7
G0
1
2
3
4
5
6
7
G1
1
2
3
4
5
6
7
G2
1
2
3
4
5
6
7
G3
p0, m0
p1, m1
p2, m2
p1, m3
Fig. 6.8 The decomposition of the s-amalgamable bundle
transformation system (C, M, P) with a set of kernel morphisms S between rules in
P.
An M-adhesive grammar with amalgamation AGA = (AS A, S 0) consists of an
M-adhesive transformation system with amalgamation AS A and a start object S 0.
The language L of an M-adhesive grammar with amalgamation AGA is deﬁned
by
L = {G | ∃amalgamated transformation S 0 =
∗⇒G},
where all amalgamated rules over arbitrary bundles of kernel morphisms in S are
allowed to be used.
△
Remark 6.21. Note that by including the kernel morphism idp : p →p for a rule p
into the set S the transformation G =
p,m
==⇒H is also an amalgamated transformation
for this kernel morphism as the only one considered in the bundle.
△
6.3 Results for Amalgamated Transformations
Since amalgamated rules are normal rules in an M-adhesive transformation system
with only a special way of constructing them, we obtain all the results from Sect. 5.2
also for amalgamated transformations. Especially for parallel independence, we can
analyse this property in more detail to connect the result to the underlying kernel
and multi rules.
6.3.1 Parallel Independence of Amalgamated Transformations
The parallel independence of two amalgamated transformations of the same object
can be reduced to the parallel independence of the involved transformations via the

152
6 Multi-amalgamated Transformations
multi rules if the application conditions are handled properly. This leads to two new
notions of parallel independence for amalgamated transformations and bundles of
transformations.
Deﬁnition 6.22 (Parallel amalgamation and bundle independence). Given two
bundles of kernel morphisms s = (si : p0 →pi)i=1,...,n and s′ = (s′
j : p′
0 →
p′
j) j=1,...,n′, and two bundles of s- and s′-amalgamable transformations (G =
pi,mi
===⇒
Gi)i=1,...,n and (G =
p′
j,m′
j
===⇒G′
j) j=1,...,n′ leading to the amalgamated transformations
G =
˜ps, ˜m
===⇒H and G =
˜ps′, ˜m′
====⇒H′, we have that
• G =
˜ps, ˜m
===⇒H and G =
˜ps′, ˜m′
====⇒H′ are parallel amalgamation independent if they
are parallel independent, i.e., there are morphisms ˜rs and ˜rs′ with f ◦˜rs′ = ˜m′,
f ′ ◦˜rs = ˜m, g ◦˜rs′ |=
˜acs′, and g′ ◦˜rs |=
˜acs, and in addition we have that
gi ◦di ◦˜rs′ |= Shift(t′
j,L, ac′
j) and g′
j ◦d′
j ◦˜rs |= Shift(ti,L, aci) for all i = 1, . . . , n,
j = 1, . . . , n′.
Li
L′
j
˜Ls
˜Ks
˜Rs
˜Ls′
˜Ks′
˜Rs′
G
Di
Hi
D′
j
H′
j
D
H
D′
H′
˜acs
˜acs′
aci
ac′
j
ti,L
t′
j,L
di
d′
j
fi
f ′
j
gi
g′
j
˜ls
˜rs
f
g
˜m
˜k
˜n
˜ls′
˜rs′
f ′
g′
˜m′
˜k′
˜n′
˜rs
˜rs′
• (G =
pi,mi
===⇒Gi)i=1,...,n and (G =
p′
j,m′
j
===⇒G′
j) j=1,...,n′ are parallel bundle independent if
they are pairwise parallel independent for all i, j, i.e., there are morphisms ri j
and r′
ji with f ′
j ◦rij = mi, fi ◦r′
ji = m′
j, g′
j ◦ri j |= aci, and gi ◦r′
ji |= ac′
j, and in
addition we have for the induced morphisms ˜rs : ˜Ls →D′ and ˜rs′ : ˜Ls′ →D that
g ◦˜rs′ |= ˜acs′ and g′ ◦˜rs |= ˜acs.
Li
Ki
Ri
L′
j
K′
j
R′
j
G
Di
Hi
D′
j
H′
j
aci
ac′
j
li
ri
fi
gi
mi
ki
ni
l′
j
r′
j
f ′
j
g′
j
m′
j
k′
j
n′
j
ri j
r′
ji
△
Remark 6.23. Note that all objects and morphisms in the above diagrams originate
from the construction in the proof of Theorem 6.17 and the parallel independence.
△

6.3 Results for Amalgamated Transformations
153
L′
0
K′
0
R′
0
L′
1
K′
1
R′
1
L′
1
p′
0 :
p′
1 :
ac′
1 = ¬ ∃a′
1
1
1
1
2
1
2
1
2
1
2
1
2
1
Y
1
X
1
Z
˜ps
˜ps′
a′
l′
0
r′
0
l′
1
r′
1
s′
1,L
s′
1,K
s′
1,R
Fig. 6.9 A counterexample for parallel independence of amalgamated transformations
Two amalgamated transformations are parallel amalgamation independent if and
only if the corresponding bundles of transformations are parallel bundle indepen-
dent.
Theorem 6.24 (Characterisation of parallel independence). Given two bundles
of kernel morphisms s = (si : p0 →pi)i=1,...,n and s′ = (s′
j : p′
0 →p′
j)j=1,...,n′,
and two bundles of s- and s′-amalgamable transformations (G =
pi,mi
===⇒Gi)i=1,...,n and
(G =
p′
j,m′
j
===⇒G′
j) j=1,...,n′ leading to the amalgamated transformations G =
˜ps, ˜m
===⇒H and
G =
˜ps′, ˜m′
====⇒H′, the following holds: (G =
pi,mi
===⇒Gi)i=1,...,n and (G =
p′
j,m′
j
===⇒G′
j) j=1,...,n′ are
parallel bundle independent if and only if G =
˜ps, ˜m
===⇒H and G =
˜ps′, ˜m′
====⇒H′ are parallel
amalgamation independent.
△
Proof. See Appendix B.5.4.
⊓⊔
Remark 6.25. Note that the additional veriﬁcation of the application conditions is
necessary because the common eﬀect of all rule applications may invalidate the
amalgamated application condition, although the single applications of the multi
rules behave well. For example, consider the kernel morphism s′
1 in Fig. 6.9, where
the bundles s = (s′
1, s′
1) and s′ = (s′
1, s′
1) are applied to the graph X. Although
all pairs of applications of the rule p′
1 to X are pairwise parallel independent, the
amalgamated transformations are not parallel independent because they invalidate
the application condition.
Similarly, a positive condition may be fulﬁlled for the amalgamated rule, but not
for all single multi rules.
△
Given two amalgamated rules, the parallel rule can be constructed as an amal-
gamated rule using some componentwise coproduct constructions of the kernel and
multi rules.

154
6 Multi-amalgamated Transformations
1
2
R1
1
2
K1
1
2
L1
1
2
L′
1
1
2
K′
1
1
2
R′
1
1
2
3
4
5
6
7
G1
1
2
3
4
5
6
7
D1
1
2
3
4
5
6
7
G
1
2
3
4
5
6
7
D′
1
1
2
3
4
5
6
7
G′
1
l1
r1
l′
1
r′
1
f1
g1
f ′
1
g′
1
m1
k1
n1
m′
1
k′
1
n′
1
r11
r′
11
Fig. 6.10 Parallel independence of the transformations G =
p1,m1
===⇒G1 and G =
p′
1,m′
1
===⇒G′
1
Fact 6.26. Given two bundles of kernel morphisms s = (si : p0 →pi)i=1,...,n and
s′ = (s′
j : p′
0 →p′
j) j=1,...,n′ leading to amalgamated rules ˜ps and ˜ps′, respectively,
the parallel rule ˜ps + ˜ps′ is constructed by ˜ps + ˜ps′ = ˜pt as the amalgamated rule of
the bundle of kernel morphisms t = (ti : p0+p′
0 →pi+p′
0, t′
j : p0+p′
0 →p0+p′
j).
△
Proof. This follows directly from the general construction of colimits and their
compatibility.
⊓⊔
Example 6.27. Consider the amalgamated transformation G =
˜ps, ˜m
===⇒H in Fig. 6.6 and
the bundle of kernel morphisms s′ = (s′
1) using the kernel morphism depicted in
Fig. 6.9. The amalgamated rule ˜ps′ can also be applied to G via match ˜m′ matching
the nodes 1 and 2 in L′
1 to the nodes 2 and 5 in G, respectively. This results in the
amalgamated transformation G =
˜ps′, ˜m′
====⇒G′
1.
For the analysis of parallel amalgamation independence, we ﬁrst analyse the pair-
wise parallel independence of the transformations G =
pi,mi
===⇒Gi and G =
p′
1,m′
1
===⇒G′
1
for i = 1, 2, 3, with m′
1 = ˜m′. This is done exemplarily for i = 1 in Fig. 6.10,
where we do not show the application conditions. The morphisms r11 and r′
11 are
marked in their corresponding domains D′
1 and D1, leading to f ′
1 ◦r11 = m1 and
f1 ◦r′
11 = m′
1. Moreover, g ◦r′
11 |= ac′
1, because there are no ingoing edges into
node 2, and g′ ◦r11 |= ac1, because there is no dotted loop at node 1 and no reverse
edge. Thus, both transformations are parallel independent, and this follows analo-
gously for i = 2, 3. Moreover, the induced morphism ˜rs′ : ˜Ls′ = L′
1 →D leads
to g ◦˜rs′ |= ˜acs′ = ac′
1. In the other direction, ˜rs : ˜Ls →D′ = D′
1 ensures that
g′
1 ◦˜rs |= ˜acs. Thus, the two bundles are parallel bundle independent and, using The-
orem 6.24, it follows that G =
˜ps, ˜m
===⇒H and G =
˜ps′, ˜m′
====⇒H′ are parallel amalgamation
independent.

6.3 Results for Amalgamated Transformations
155
p00 :
p00 = p0 + p′
0
ac00 = ¬ ∃a00 ∧¬ ∃b00
1
5
L00
1
5
K00
1
5
R00
1
5
L00
1
5
1
5
L00
K00
R00
p10 :
p10 = p1 + p′
0
ac10 = ¬ ∃a10 ∧¬ ∃b10 ∧¬ ∃c10 ∧¬ ∃d10 ∧
¬ ∃e10 ∧¬ ∃f10
1
2
5
L10
1
2
5
K10
1
2
5
R10
1
2
5
L10
1
2
5
1
2
5
1
2
5
1
2
5
1
2
5
1
2
5
L00
K00
R00
p20 :
p20 = p2 + p′
0
ac20 = ¬ ∃a20 ∧¬ ∃b20 ∧¬ ∃c20 ∧¬ ∃d20 ∧
¬ ∃e20 ∧¬ ∃f20
1
3
5
L20
1
3
5
K20
1
3
5
R20
1
3
5
L20
1
3
5
1
3
5
1
3
5
1
3
5
1
3
5
1
3
5
L00
K00
R00
p01 :
p01 = p0 + p′
1
ac01 = ¬ ∃a01 ∧¬ ∃b01 ∧¬ ∃c01 ∧¬ ∃d01 ∧
¬ ∃e01 ∧¬ ∃f01 ∧¬ ∃g01 ∧¬ ∃h01
1
6
5
L01
1
6
5
K20
1
6
5
R01
1
6
5
L01
1
6
5
1
6
5
1
6
5
5
1
6
5
1
6
5
1
6
5
1
6
5
1
6
l00
r00
b00
a00
l10
r10
s10,L
s10,K
s10,R
a10
b10
f10
e10
d10
c10
l20
r20
s20,L
s20,K
s20,R
a20
b20
f20
e20
d20
c20
l01
r01
s01,L
s01,K
s01,R
a01
b01
h01
g01
f01
e01
d01
c01
Fig. 6.11 The kernel morphisms leading to the parallel rule

156
6 Multi-amalgamated Transformations
˜pt :
˜act
1
2
3
4
5
6
˜Lt
1
2
3
4
5
6
˜Kt
1
2
3
4
5
6
˜Rt
1
2
3
4
5
6
7
G
1
2
3
4
5
6
7
Dt
1
2
3
4
5
6
7
G′
˜lt
˜rt
ft
gt
˜mt
˜kt
˜nt
Fig. 6.12 A parallel amalgamated graph transformation
The construction of this parallel rule according to Fact 6.26 is shown in Fig. 6.11.
The parallel rule ˜ps + ˜ps′ = ˜pt is the amalgamated rule of the bundle of kernel
morphisms t = (s10 = s1 + idp′
0, s20 = s2 + idp′
0, s10 = s1 + idp′
0, s01 = idp0 + s′
1).
The corresponding parallel rule is depicted in the top of Fig. 6.12, where we omit
showing the application condition act due to its length. It leads to the amalgamated
transformation G =
˜pt, ˜mt
===⇒G′ depicted in Fig. 6.12.
△
As in any M-adhesive transformation system, also for amalgamated transfor-
mations the Local Church–Rosser and Parallelism Theorem holds. This is a direct
instantiation of Theorem 2.26 to amalgamated transformations. For the analysis of
parallel independence and the construction of the parallel rule we may use the re-
sults from Theorem 6.24 and Fact 6.26, respectively.
Theorem 6.28 (Local Church–Rosser and Parallelism Theorem).
Given two
H1
H2
G
G′
˜ps
˜pt
˜ps′
˜ps′
˜ps
parallel independent amalgamated transforma-
tions G =
˜ps=⇒H1 and G =
˜ps′
==⇒H2, there is an
object G′ together with direct transformations
H1 =
˜ps′
==⇒G′ and H2 =
˜ps=⇒G′ such that G =
˜ps=⇒
H1 =
˜ps′
==⇒G′ and G =
˜ps′
==⇒H2 =
˜ps=⇒G′ are sequen-
tially independent.
Given two sequentially independent direct transformations G =
˜ps=⇒H1 =
˜ps′
==⇒G′,
there is an object H2 with direct transformations G =
˜ps′
==⇒H2 =
˜ps=⇒G′ such that
G =
˜ps=⇒H1 and G =
˜ps′
==⇒H2 are parallel independent.
In any case of independence, there is a parallel transformation G =
˜pt=⇒G′ via the
parallel rule ˜ps + ˜ps′ = ˜pt and, vice versa, a direct transformation G =
˜pt=⇒G′ can be
sequentialised both ways.
△

6.4 Interaction Schemes and Maximal Matchings
157
Proof. This follows directly from Theorem 5.26, where all transformations are
amalgamated transformations.
⊓⊔
Example 6.29. In addition to the results from Ex. 6.27, from Theorem 6.28 we ob-
tain amalgamated transformations H =
˜ps′
==⇒G′ and H′ =
˜ps=⇒G′, with G =
˜ps=⇒G =
˜ps′
==⇒
G′ and G =
˜ps′
==⇒H′ =
˜ps=⇒G′ being sequentially independent transformation se-
quences.
△
6.3.2 Other Results for Amalgamated Transformations
For M-adhesive transformation systems with amalgamation, also the other results
stated in Sect. 5.2 are valid for amalgamated transformations. But additional results
for the analysis of the results for amalgamated rules based on the underlying kernel
and multi rules are future work:
• For the Concurrency Theorem, two amalgamated rules leading to parallel de-
pendent amalgamated transformations can be combined to an E-concurrent rule
and the corresponding transformation. It would be interesting to analyse if this
E-concurrent rule could be constructed as an amalgamated rule based on the un-
derlying kernel and multi rules.
• For the Embedding and Extension Theorem, an amalgamated rule can be embed-
ded if the embedding morphism is consistent. Most likely, consistency w. r. t. an
amalgamated transformation can be formulated as a consistency property w. r. t.
the bundle of transformations.
• For the Local Conﬂuence Theorem, if all critical pairs depending on all available
amalgamated rules are strictly AC-conﬂuent then the M-adhesive transformation
system with amalgamation is locally conﬂuent. It would be interesting to ﬁnd a
new notion of critical pairs depending not on the amalgamated rules, but on the
kernel morphisms. For arbitrary amalgamated rules, any bundle of kernel mor-
phisms had to be analysed. It would be more eﬃcient if some kinds of minimal
bundles were suﬃcient for constructing all critical pairs or dependent transfor-
mations of the M-adhesive transformation system with amalgamation.
6.4 Interaction Schemes and Maximal Matchings
For many interesting application areas, including the operational semantics of Petri
nets and statcharts, we do not want to deﬁne the matches for the multi rules explic-
itly, but to obtain them dependent on the object to be transformed. In this case, only
an interaction scheme is given, which deﬁnes a set of kernel morphisms but does
not include a count of how often each multi rule is used in the bundle leading to the
amalgamated rule.

158
6 Multi-amalgamated Transformations
Deﬁnition 6.30 (Interaction scheme). A kernel rule p0 and a set of multi rules
{p1, . . . , pk} with kernel morphisms si : p0 →pi form an interaction scheme is =
{s1, . . . , sk}.
△
When given an interaction scheme, we want to apply as many rules occurring in
the interaction scheme as often as possible over a certain kernel rule match. Here we
consider two diﬀerent possible maximal matchings: maximal weakly independent
and maximal weakly disjoint matchings. For maximal weakly independent match-
ings, we require the matchings of the multi rules to be weakly independent to ensure
that the resulting bundle of transformations is amalgamable. This is the minimal re-
quirement to meet the deﬁnition. In addition, for maximal weakly disjoint matchings
the matches of the multi rules should be disjoint up to the kernel rule match. This
variant is preferred for implementation, because it eases the computation of addi-
tional matches when we can rule out model parts that were already matched.
Deﬁnition 6.31 (Maximal weakly independent matching). Given an object G and
an interaction scheme is = {s1, . . . , sk}, a maximal weakly independent matching
m = (m0, m1, . . . , mn) is deﬁned as follows:
1. Set i = 0. Choose a kernel matching m0 : L0 →G such that G =
p0,m0
===⇒G0 is a
valid transformation.
2. As long as possible: Increase i, choose a multi rule ˆpi = pj with j ∈{1, . . . , k},
and ﬁnd a match mi : Lj →G such that mi ◦sj,L = m0, G =
pj,mi
===⇒Gi is a valid
transformation, the matches m1, . . . , mi are weakly independent, and mi , mℓfor
all ℓ= 1, . . . , i −1.
3. If no more valid matches for any rule in the interaction scheme can be found,
return m = (m0, m1, . . . , mn).
The maximal weakly independent matching leads to a bundle of kernel morphisms
s = (si : p0 →ˆpi) and an s-amalgamable bundle of direct transformations G =
ˆpi,mi
===⇒
Gi.
△
Deﬁnition 6.32 (Maximal weakly disjoint matching).
Given an object G and
an interaction scheme is = {s1, . . . , sk}, a maximal weakly disjoint matching
m = (m0, m1, . . . , mn) is deﬁned as follows:
1. Set i = 0. Choose a kernel matching m0 : L0 →G such that G =
p0,m0
===⇒G0 is a
valid transformation.
L0
L j
ˆLℓ
G
s j,L
ˆsℓ,L
mi
mℓ
(Piℓ)
2. As long as possible: Increase i, choose a multi rule ˆpi =
pj with j ∈{1, . . . , k}, and ﬁnd a match mi : Lj →G such
that mi ◦sj,L = m0, G =
pj,mi
===⇒Gi is a valid transformation,
the matches m1, . . . , mi are weakly independent, and mi ,
mℓand the square (Piℓ) is a pullback for all ℓ= 1, . . . , i −
1.
3. If no more valid matches for any rule in the interaction scheme can be found,
return m = (m0, m1, . . . , mn).

6.4 Interaction Schemes and Maximal Matchings
159
The maximal weakly disjoint matching leads to a bundle of kernel morphisms s =
(si : p0 →ˆpi) and an s-amalgamable bundle of direct transformations G =
ˆpi,mi
===⇒
Gi.
△
Note that for maximal weakly disjoint matchings, the pullback requirement al-
ready implies the existence of the morphisms for the weakly independent matches.
Only the property for the application conditions has to be checked in addition.
Fact 6.33. Given an object G, a bundle of kernel morphisms s = (s1, . . . , sn), and
matches m1, . . . , mn leading to a bundle of direct transformations G =
pi,mi
===⇒Gi such
that mi ◦si,L = m0 and square (Pi j) is a pullback for all i , j, the bundle G =
pi,mi
===⇒Gi
is s-amalgamable for transformations without application conditions.
△
Proof. By construction, the matches mi agree on the match m0 of the kernel rule. It
remains to show that they are weakly independent.
Given the transformations G =
pi,mi
===⇒Gi with pushouts (20i) and (21i), consider
the following cube, where the bottom face is pushout (20i), the back right face is
pullback (1i), and the front right face is pullback (Pi j). Now construct the pullback
of fi and m j as the front left face, and from m j◦sj,L◦l0 = mi◦si,L◦l0 = mi◦li◦si,K =
fi ◦ki ◦si,K we obtain a morphism p with ˆf ◦p = s j,L ◦l0 and ˆm ◦p = ki ◦si,K.
K0
L0
Ki
Li
P
Lj
Di
G
Ki
Ri
Di
Gi
Li
G
l0
si,K
p
sj,L
si,L
li
ki
ˆf
ˆm
mj
fi
mi
fi
li
mi
ri
ki
gi
ni
(20i)
(21i)
From pullback composition and decomposition of the right and left faces it fol-
lows that also the back left face is a pullback. Now the M-van Kampen property
can be applied, leading to a pushout in the top face. Since pushout complements
are unique up to isomorphism, we can substitute the top face by pushout (1′
i) with
P  L j0. Thus we have found the morphism pji := ˆm with fi ◦p ji = mj ◦ui. This
construction can be applied for all pairs i, j leading to weakly independent matches
without application conditions.
⊓⊔
This fact leads to a set-theoretical characterisation of maximal weakly disjoint
matchings.
Fact 6.34. For graphs and graph-based structures, valid matches m0, m1, . . . , mn
with mi ◦si,L = m0 for all i = 1, . . . , n form a maximal weakly disjoint matching
without application conditions if and only if mi(Li) ∩mj(L j) = m0(L0).
△
Proof. Valid matches means that the transformations G =
pi,mi
===⇒are well deﬁned. In
graphs and graph-like structures, (Pi j) is a pullback if and only if mi(Li) ∩m j(Lj) =
m0(L0). Then Fact 6.33 implies that the matches form a maximal weakly disjoint
matching without application conditions.
⊓⊔

160
6 Multi-amalgamated Transformations
1
2
3
4
X′
1
2
3
4
X
1
2
3
4
X′′
c
a
b
d
e
c
a
b
d
e
c
a
b
d
e
˜ps, ˜m
˜ps′, ˜m′
Fig. 6.13 Application of an amalgamated rule via maximal matchings
Example 6.35. Consider the interaction scheme is = (s1, s2) deﬁned by the kernel
morphisms s1 and s2 in Fig. 6.2, the graph X depicted in the middle of Fig. 6.13,
and the kernel rule match m0 mapping the node 1 in L0 to the node 1 in X.
If we choose maximal weakly independent matchings, the construction works as
follows, deﬁning the following matches, where f is the edge from 1 to 2 in L1 and g
the reverse edge in L2:
i = 1 : ˆp1 = p1, m1 : 2 7→3, f 7→c,
i = 2 : ˆp2 = p1, m2 : 2 7→4, f 7→d,
i = 3 : ˆp3 = p2, m3 : 3 7→2, g 7→a,
i = 4 : ˆp4 = p1, m4 : 2 7→4, f 7→e,
i = 5 : ˆp5 = p2, m5 : 3 7→2, g 7→b.
Thus, we ﬁnd ﬁve diﬀerent matches, three for the multi rule p1 and two for the
multi rule p2. Note that in addition to the overlapping m0, the matches m3 and m5
overlap in the node 2, while m2 and m4 overlap in the node 4. But since these matches
are still weakly independent, because the nodes 2 and 4 are not deleted by the rule
applications, this is a valid maximal weakly independent matching. It leads to the
bundle s = (s1, s1, s1, s2, s2) and the amalgamated rule ˜ps, which can be applied to
X, leading to the amalgamated transformation X =
˜ps, ˜m
===⇒X′ as shown in the left of
Fig. 6.13.
If we choose maximal weakly disjoint matchings instead, the matches m4 and
m5 are no longer valid because they overlap with m2 and m3, respectively, in
more than the match m0. Thus we obtain the maximal weakly disjoint matching
(m0, m1, m2, m3), the corresponding bundle s′ = (s1, s1, s2) leading to the amalga-
mated rule ˜ps′ and the amalgamated transformation X =
˜ps′, ˜m′
====⇒X′′ depicted in the
right of Fig. 6.13. Note that this matching is not unique; also, (m0, m1, m2, m4) could
have been chosen as a maximal weakly disjoint matching.
△
6.4.1 Main Results for Amalgamated Transformations Based on
Maximal Matchings
If we allow applying amalgamated rules only via maximal matchings, the main re-
sults from Sect. 5.2 do not hold instantly as is the case for arbitrary matchings. The

6.4 Interaction Schemes and Maximal Matchings
161
main problem is that the amalgamated transformations obtained from the construc-
tions are in general not applied via maximal matchings. The analysis and deﬁnition
of properties ensuring these results is future work:
• The Local Church–Rosser Theorem guarantees that for parallel independent
amalgamated transformations G =
˜ps=⇒H1 and G =
˜ps′
==⇒H2 via maximal match-
ings there exist transformations H1 =
˜ps′
==⇒G′ and H2 =
˜ps=⇒G′. But in general, these
resulting transformations will not be via maximal matchings, since ˜ps′ or ˜ps may
create new matchings for s or s′, respectively. Thus, we have to ﬁnd properties
that make sure that no new matches, or at least no new disjoint matches, are
created.
• For the Parallelism Theorem, the property of maximal weakly independent
matchings is transferred to the application of the parallel rule, as shown below.
• For the Concurrency Theorem, we have to formulate results concerning the con-
struction of an E-concurrent rule as an amalgamated rule based on the underlying
kernel and multi rules before relating the results to maximal matchings.
• For the Embedding and Extension Theorem, embedding an object G with a max-
imal matching into a larger context G′ in general enables more matches, i.e., the
application of the amalgamated rule to G′ may not be maximal. We need to de-
ﬁne properties to restrict the embedding to certain parts outside the matches of
the multi rules to ensure that the same matchings are maximal in G and G′.
• For the Local Conﬂuence Theorem, maximal matchings may actually lead to
fewer critical pairs if we have additional information about the objects to be
transformed, since some conﬂicting transformations may not occur at all due to
maximal matchings.
In case of parallel independent transformations, the property of a maximal
weakly independent matching is transferred to the application of the parallel rule.
Note that for maximal weakly disjoint matchings, we have to require in addition that
the matches of the two amalgamated transformations not overlap.
Theorem 6.36 (Parallelism of maximal weakly independent matchings). Given
parallel independent amalgamated transformations G =
˜ps, ˜m
===⇒H1 and G =
˜ps′, ˜m′
====⇒H2
leading to the induced transformations G =
˜pt, ˜mt
===⇒G′ via the parallel rule ˜pt = ˜ps +
˜ps′, the following holds: if G =
˜ps, ˜m
===⇒H1 and G =
˜ps′, ˜m′
====⇒H2 are transformations via
maximal weakly independent matchings then also G =
˜pt, ˜mt
===⇒G′ is a transformation
via a maximal weakly independent matching.
△
Proof. Consider parallel independent amalgamated transformations G =
˜ps, ˜m
===⇒H1
and G =
˜ps′, ˜m′
====⇒H2 via maximal weakly independent matchings (m0, m1, . . . , mn)
with ˜m ◦ti,L = mi and (m′
0, m′
1, . . . , m′
n′) with ˜m′ ◦t′
j,L = m′
j, respectively. Then
we have the matching m = ([m0, m′
0], ([mi, m′
0])i=1,...,n, ([m0, m′
j])j=1,...,n′) for the
parallel transformation G =
˜pt, ˜mt
===⇒G′, with [mi, m′
0] ◦(si,L + idL0) = [m0, m′
0] and
[m0, m′
j] ◦(idL0 + s′
j,L) = [m0, m′
0]. We have to show the maximality of m.

162
6 Multi-amalgamated Transformations
t
t′
t′′
G
t
t′
t′′
H
place
token
transition
at
pre
post
Fig. 6.14 The ﬁring semantics and type graph for elementary Petri nets
Suppose m is not maximal. This means that there is, w. l. o. g., some match ˆm :
Lk + L′
0 →G such that ˆm ◦(sk,L + idL′
0) = [m0, m′
0] and ˆm , [mi, m′
0] for all i =
1, . . . , n such that (m, ˆm) is also weakly independent. Then we ﬁnd a match ˆmk :=
ˆm ◦iLk for the rule pk with ˆmk ◦sk,L = m0 and ˆmk , mi for all i. It follows that
(m0, m1, . . . , mn, ˆmk) are also weakly independent, which is a contradiction to the
maximality of (m0, m1, . . . , mn).
⊓⊔
6.4.2 Semantics for Elementary Nets
As a concrete and more complex example, we use amalgamation and maximal
matchings to model the operational semantics of elementary Petri nets. Using amal-
gamation allows the description of a semantical step in an unknown surrounding
with only one interaction scheme. We do not need speciﬁc rules for each occurring
situation as is the case for Petri nets with standard graph transformation.
In the following, we present a semantics for the ﬁring behaviour of elementary
Petri nets using graph transformation and amalgamation. Elementary Petri nets are
nets where at most one token is allowed on each place. A transition t is activated
if there is a token on each pre-place of t and all post-places of t are token-free. In
this case, the transition may ﬁre, leading to the follower marking where the tokens
on all the pre-places of t are deleted and at all post-places of t a token appears. An
example is depicted on the right of Fig. 6.14, where the transition t in the elementary
Petri net G is activated on the left and the follower marking is depicted on the right,
leading to the elementary Petri net H.
We model these nets by typed graphs. The type graph is depicted on the left of
Fig. 6.14 and consists simply of places, transitions, the corresponding pre- and post-
arcs, and tokens attached to their places. For the following examples, we use the
well-known concrete syntax of Petri nets, modelling a place by a circle, a transition
by a rectangle, and a token by a small ﬁlled circle placed on its place.

6.4 Interaction Schemes and Maximal Matchings
163
p0 :
ac0 = ∀(a0, ∃a′
0) ∧¬ ∃b0
t
L0
t
K0
t
R0
t
L0
t
p
t
p
t
L0
t
p
l0
r0
a0
a′
0
b0
Fig. 6.15 The kernel rule selecting an activated transition
In Figs. 6.15 and 6.16, three rules, p0, p1, and p2, are shown, which, combined as
an amalgamated rule with maximal weakly disjoint matchings, will result in a ﬁring
step of the net. The rule p0 in Fig. 6.15 selects a transition t which is not changed at
all. But note that the application condition restricts this rule to be only applicable if
there is no empty pre-place of t and we have only empty post-places. This means that
the transition t is activated in the elementary net. The rule p1 describes the ﬁring of
a pre-place, where the token on this place is deleted. It only inherits the application
condition of p0 to guarantee a kernel morphism s1 : p0 →p1, as shown at the top of
Fig. 6.16. s1 is indeed a kernel morphism because (1) and (2) are pullbacks and (3)
is the required pushout complement. ac0 and ac1 are complement-compatible w. r. t.
s1 with ac′
1 = true. Similarly, rule p2 describes the ﬁring of a post-place, where
a token is added on this place. Again, there is a kernel morphism s2 : p0 →p2,
as shown in the bottom of Fig. 6.16 with pullbacks (1′) and (2)′, (1′) is already a
pushout, and ac0 and ac2 are complement-compatible w. r. t. s2 with ac′
2 = true.
Theorem 6.37 (Equivalence of amalgamated transformation and ﬁring step).
Using the interaction scheme is = {s1 : p0 →p1, s2 : p0 →p2} of the rules
deﬁned in Figs. 6.15 and 6.16 with maximal weakly disjoint matchings, the derived
amalgamated transformations are equivalent to the ﬁring steps of elementary Petri
nets.
△
For the multi rules in Fig. 6.16, the complement rules are the rules p1 and p2
themselves but with empty application condition true, because they contain every-
thing which is done in addition to p0, including the connection with K0, while the
application condition is already ensured by p0.
Now consider the interaction scheme is = {s1, s2} leading to the bundle of kernel
morphisms s = (s1, s1, s1, s2, s2). The construction of the corresponding amalga-
mated rule ˜ps is shown in Fig. 6.17 without application conditions. This amalga-
mated rule can be applied to the elementary Petri net G as depicted in Fig. 6.18,
leading to the amalgamated transformation G =
˜ps, ˜m
===⇒H.
Moreover, we can ﬁnd a bundle of transformations G =
m1,p1
===⇒G1, G =
m2,p1
===⇒G2,
G =
m3,p1
===⇒G3, G =
m4,p2
===⇒G4, and G =
m5,p2
===⇒G5 with the resulting nets depicted in
Fig. 6.19 and matches m0 : t 7→t, m1 : p1 7→q1, m2 : p1 7→q2, m3 : p1 7→q3,
m4 : p2 7→q4, and m3 : p2 7→q5. This bundle is s-amalgamable, because it has

164
6 Multi-amalgamated Transformations
p0 :
ac0
t
L0
t
K0
t
R0
p1 :
ac1
ac1 = Shift(s1,L, ac0)
t
p1
L1
t
p1
K1
t
p1
R1
t
L0
t
K0
t
p1
L1
t
p1
L10
p0 :
ac0
t
L0
t
K0
t
R0
p2 :
ac2
ac2 = Shift(s2,L, ac0)
t
p2
L2
t
p2
K2
t
p2
R2
l0
r0
l1
r1
s1,L
s1,K
s1,R
l0
s1,L
u1
w1
l0
r0
l2
r2
s2,L
s2,K
s2,R
(1)
(2)
(3)
(1′)
(2′)
Fig. 6.16 The multi rules describing the handling of each place
L0
K0
R0
L1
K1
R1
L2
K2
R2
˜ps:
˜Ls
˜Ks
˜Rs
3×
2×
l0
r0
l2
r2
l1
r1
˜ls
˜rs
Fig. 6.17 The construction of the amalgamated rule

6.4 Interaction Schemes and Maximal Matchings
165
˜ps :
˜acs
˜Ls
˜Ks
˜Rs
t
t′
t′′
G
t
q1
q2
q3
q4
q5
t′
q6
t′′
q7
D
t
t′
t′′
H
˜ls
˜rs
˜f
˜g
˜m
˜k
˜n
Fig. 6.18 An amalgamated transformation
p1,m1
p1,m2
p1,m3
p2,m4
p2,m5
Fig. 6.19 An s-amalgamable transformation bundle

166
6 Multi-amalgamated Transformations
consistent matches with m0 matching the transition t from p0 to the transition t in
G, and all matches are weakly independent; they only overlap in L0. (m0, . . . , m5)
is both a maximal weakly independent and a maximal weakly disjoint matching,
because no other match can be found extending the kernel rule match, and all these
matches are disjoint up to the selected transition t.
If we always use maximal matchings, any application of an amalgamated rule
created from the interaction scheme is = {s1, s2} is a valid ﬁring step of a transition
in the elementary net. For example, to ﬁre the transition t′ in G the bundle s′ =
(s1, s2) leads to the required amalgamated rule. In general, for a transition with m
pre- and n post-arcs, the corresponding bundle s = ((s1)i=1,...,m, (s2) j=1,...,n) leads
to the amalgamated rule ﬁring this transition via a maximal matching. Note that
each maximal weakly independent matching is already a maximal weakly disjoint
matching due to the net structure.
For elementary Petri nets we only need one kernel rule and two multi rules to
describe the complete ﬁring semantics for all well-deﬁned nets. We neither need
inﬁnite many rules, which are diﬃcult to analyse, nor any control or helper structure
when using amalgamation. This eases the modelling of the semantics and prevents
errors [GHE14].

Part III
Model Transformation Based on Triple
Graph Grammars

169
This third part presents model transformation, model integration and model syn-
chronisation based on triple graph grammars. Following up on the informal intro-
duction to model transformation in Chap. 3 of Part I, we present the formal theory of
graph transformation based on triple graph grammars. In Chap. 7, we give the foun-
dations of triple graph grammars leading to model transformation and model inte-
gration. It is important to note that transformation and integration are based on oper-
ational rules, which can be generated automatically from the triple graph grammar
rules. A ﬂattening construction allows us to show the equivalence of model trans-
formations based on triple graph grammars and plain graph grammars. In Chap. 8,
we present several analysis techniques for model transformations, which are sup-
ported by tools discussed in Part IV. Important properties, which are analysed in
Chap. 8, include correctness and completeness, functional behaviour and informa-
tion preservation, as well as conﬂict resolution and optimisation. In Chap. 9, model
transformation techniques are applied to model synchronisation, which is an impor-
tant technique for gaining and keeping consistency of source and target models after
changing one or both of them. This leads to unidirectional and concurrent model
synchronisation, respectively.

Chapter 7
Model Transformation and Model Integration
In this chapter, we describe the formal framework for model transformation and
model integration based on triple graph grammars. For this purpose, we use triple
graph transformation systems as introduced in Chap. 3 and show in Sect. 7.1 that
they instantiate the general framework of M-adhesive transformation systems pre-
sented in Chap. 5. This ensures that all results for M-adhesive transformation sys-
tems hold for the speciﬁc case of triple graph transformation systems. A triple graph
grammar is a constructive speciﬁcation of a language of integrated models, which
are speciﬁed by their underlying abstract syntax graphs. Based on this general con-
cept, we ﬁrst derive a transformation system for forward model transformations,
which are deﬁned in Sect. 7.3. In Sect. 7.4, we introduce forward translation rules
as an alternative to forward rules and show the equivalence of model transforma-
tions based on either forward or forward translation rules. The concept of forward
translation rules simpliﬁes the control mechanism for executing model transforma-
tions. In addition to that, it oﬀers improved capabilities for analysis and execu-
tion, which we will study in detail in Chap. 8. Model integration is a technique
to integrate two given models—one from the source and one from the target lan-
guage. In Sect. 7.5, we present model integration based on TGGs and show for-
mally that this concept is closely related to model transformations. The last section
(Sect. 7.6) of this chapter relates the presented concepts based on TGGs with stan-
dard model transformations based on plain graph grammars. The chapter is based
on [Her11, HEGO14, EEE+07, EEH08c, HHK10, GEH11].
7.1 Triple Graphs form an M-adhesive Category
A triple graph is an integrated model G = (GS ←GC →GT) containing a source
model GS from the source language, a target model GT from the target language,
and explicit correspondences between them speciﬁed via a correspondence model
GC.
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_7
171

172
7 Model Transformation and Model Integration
The category of triple graphs can be constructed from underlying M-adhesive
categories of typed attributed graphs.
Fact 7.1 (Construction of categories of triple graphs). The category of typed at-
tributed triple graphs in Def. 3.4 and the base categories for triple graphs in Def. 3.5
can be constructed as follows.
• The category TrGraphs of triple graphs and triple graph morphisms can be
constructed as functor category [X, Graphs] over the category Graphs of graphs
with schema category X = ({S,C, T}, {s: C →S, t: C →T, idS , idC, idT}).
• The category ATrGraphs of attributed triple graphs can be constructed as the
functor category [X, AGraphs] over the category AGraphs of attributed graphs
with the same schema category as above.
• The category TrGraphsTG of typed triple graphs (or ATrGraphsATG of typed
attributed triple graphs) for a given triple graph TG in TrGraphs (or ATG in
ATrGraphs) can be constructed as slice category TrGraphs\TG over TrGraphs
(or ATrGraphs\ATG over ATrGraphs).
△
Proof. A triple graph G = (GS ←
sG−−GC −
tG−→GT) is represented by a functor G: X →
Graphs with G(S ) = GS , G(C) = GC, G(T) = GT and G(s) = sG, G(t) = tG. The
compatibility condition for triple graph morphisms follows from the compatibility
condition of functor transformations that form the morphisms in a functor category.
The typing and attribution extensions are compatible with the construction of the
functor category.
⊓⊔
Theorem 7.2 (Category of triple graphs is M-adhesive).
The categories
TrGraphs, TrGraphsTG, ATrGraphs, and ATrGraphsATG are M-adhesive.
△
Proof. Using Fact 7.1, we derive the categories as functor and slice constructions
over M-adhesive categories (Graphs, M) and (AGraphs, M) and can apply Theo-
rem B.13 to derive that the constructed categories are again M-adhesive categories.
⊓⊔
By Theorem 7.2, we can conclude that the results in Chapters 4 to 6 for M-
adhesive categories hold for triple graphs and triple graph transformations. In par-
ticular, we will apply the theory and analysis for critical pairs and conﬂuence (see
Sect. 5.2.4 in Chap. 5) in Chap. 8 for analysing functional behaviour and informa-
tion preservation. Using Theorem 7.2, we derive the classes of M-morphisms for
the diﬀerent kinds of triple graphs as constructions from the M-adhesive categories
Graphs and AGraphs. The class of M-morphisms is given by all triple graph mor-
phisms that are injective on the graph part and isomorphisms on the data part.
From the application point of view a model transformation should be injective
on the structural part, i.e., the transformation rules are applied along matches that
do not identify structural elements. Thus, the translation of each element is explic-
itly speciﬁed and there is no confusion. But it would be too restrictive to require
injectivity of the matches also on the data and variable nodes, because we must
allow two diﬀerent variables to be mapped to the same data value. For this rea-
son we introduce the notion of almost injective matches, which requires matches

7.2 Derivation of Operational Rules
173
to be injective except for the data value nodes. This way, attribute values can still
be speciﬁed as terms within a rule and matched noninjectively to the same value.
For the rest of this chapter, we generally require almost injective matching for the
transformation sequences. Moreover, we require that application conditions contain
almost injective morphisms only. For the constructions, we can assume without loss
of generality that each almost injective morphism f = (fG, fD): G →H is given by
f = (incG, fD), i.e., fG is an inclusion.
Deﬁnition 7.3 (Almost injective match). An attributed triple graph morphism m :
L →G is called almost injective if it is noninjective at most for the set of variables
and data values.
△
Remark 7.4 (Restriction of application conditions to almost injective internal mor-
phisms). The internal morphisms of an application condition are not restricted by
deﬁnition. If we consider almost injective matches, it is suﬃcient to use almost
injective morphisms for the internal morphisms of an application condition. The
reason is that those internal morphisms that are not almost injective can never be
completed with a compatible mediating morphism q: P →G. Thus, they are not
relevant and do not restrict the applicability of the rule. Therefore, we use applica-
tion conditions with almost injective internal morphisms only. Note that this restric-
tion is compatible with the notion of AC schemata. Given an AC schema ac (see
Def. 5.6), where ac contains almost injective internal morphisms only, the induced
application condition ac also contains almost injective internal morphisms only due
to the merge construction (see Def. 5.5).
△
Following the discussion and explanations for almost injective morphisms above,
we generally require almost injective morphisms for TGGs as stated by our general
assumption below.
Remark 7.5 (General assumption). The formal results in this chapter are presented
for TGGs that are executed via almost injective matches and where all internal mor-
phisms of application conditions are almost injective.
△
7.2 Derivation of Operational Rules
The operational rules for executing forward and backward model transformations
are derived from the set of triple rules of a given TGG. This process requires us
to split the application conditions of the triple rules and to distribute them to the
corresponding derived rules. For this reason, we need to specify a restriction of ap-
plication conditions, which ensures that the split can be performed. This restriction,
however, is not problematic from an application point of view, which we will also
see in our running example.
Deﬁnition 7.6 (Special application conditions). Given a triple rule tr : L →R, an
application condition ac = ∃(a, ac′) over L with a : L →P is an

174
7 Model Transformation and Model Integration
• S -application condition if aC, aT are identities, i.e., PC = LC, PT = LT, and ac′
is an S -application condition over P,
• S -extending application condition if aS is an identity, i.e., PS = LS , and ac′ is an
S -extending application condition over P.
S -application condition
S -extending application condition
(LS
aS 
ac
LC
sL
o
idC
L 
tL
/ LT)
idT
L 
(PS
ac′
PC = LC
sP
o
tP / PT = LT)
(LS
idS
L 
ac
LC
sL
o
aC 
tL / LT)
aT 
(PS = LS
ac′
PC
sPo
tP / PT)
• T-application condition if aS , aC are identities, i.e., PS = LS , PC = LC, and ac′
is a T-application condition over P,
• T-extending application condition if aT is an identity, i.e., PT = LT, and ac′ is a
T-extending application condition over P,
T-application condition
T-extending application condition
(LS
idS
L 
ac
LC
sL
o
idC
L 
tL
/ LT)
aT 
(PS = LS
ac′
PC = LC
sPo
tP
/ PT)
(LS
aS 
ac
LC
sLo
aC 
tL
/ LT)
idT
L 
(PS
ac′
PC
sPo
tP/ PT = LT)
• ST-application condition if aC is an identity, i.e., PC = LC, and ac′ is an ST-
application condition over P.
S T-application condition
(LS
aS 
ac
LC
sL
o
idC
L 
tL
/ LT)
aT 
(PS
ac′
PC = LC
sP
o
tP
/ PT)
Moreover, true is an S - (S -extending, ST-, T-, T-extending) application condition,
and if ac, aci are S - (S -extending, ST-, T-, T-extending) application conditions so
are ¬ac, ∧i∈Iaci, and ∨i∈Iaci.
△
During the generation of the operational rules, each application condition ac of
a triple rule tr ∈TR has to be transferred to the operational rules. This transfer is
achieved by decomposing ac into (1) a part on the source rule and an S -extending
application condition for the forward rule, or (2) a part on the target rule and a T-
extending application condition for the backward rule, or (3) an ST-condition for
the source–target rules and an empty remainder for the model integration rules.

7.2 Derivation of Operational Rules
175
LS
idLS
)
aS

toS (ac′
S )
∅
o
/
)

∅
)

LS
aS

ac′
S
LC
sL
o
tL
/
aC

LT
aT

PS
idPS
)
toS (ac′′
S )
∅
o
/
)
∅
)
PS
ac′′
S
PC
sP
o
tP
/ PT
RS
idRS

toF(ac′
F)
LC
trS ◦sL
o
tL
/
aC

LT
aT

LS
idLS

trS
i
ac′
F
LC
sL
o
tL
/
aC

idLC
i
LT
aT

idLT
i
RS
toF(ac′′
F)
PC
trS ◦sP
o
tP
/ PT
PS
trS
i
ac′′
F
=
LS
PC
sP
o
tP
/
idPC
i
PT
idPT
i
∅
)

toT(ac′
T)
∅
o
/
)

LT
idLT
)
aT

LS
aS

ac′
T
LC
sL
o
tL
/
aC

LT
aT

∅
)
toT(ac′′
T )
∅
o
/
)
PT
idPT
)
PS
ac′′
T
PC
sP
o
tP
/ PT
LS
aS

toB(ac′
B)
LC
sL
o
trT ◦tL
/
aC

RT
idRS

LS
aS

idLS
i
ac′
B
LC
sL
o
tL
/
aC

idLC
i
LT
idLT

trT
i
PS
toB(ac′′
B)
PC
sP
o
trT ◦tP
/ RT
PS
idPS
i
ac′′
B
PC
sP
o
tP
/
idPC
i
PT
trT
i
=
LT
LS
idLS
)
aS

toST(ac′
ST)
∅
o
/
)

LT
idLT
)
aT

LS
aS

ac′
ST
LC
sL
o
tL
/
idLC

LT
aT

PS
idPS
)
toST(ac′′
ST)
∅
o
/
)
PT
idPT
)
PS
ac′′
ST
PC
sP
o
tP
/
=
LC
PT
Fig. 7.1 Translation of application conditions for the construction of operational rules
Deﬁnition 7.7 (Translated application condition).
Consider a triple rule tr =
(tr: L →R, ac); then an application condition ac can be translated as follows, ac-
cording to Fig. 7.1. The data component for each inclusion ∅→X for a triple graph
X is given by an identity, i.e., the construction does not change the data component.
• Given an application condition ac′
S over L, we deﬁne an application condition
toS (ac′
S ) over LS = (LS ←∅→∅) by
– toS (true) = true,
– toS ( ∃(a, ac′′
S )) = ∃((aS , id∅, id∅), toS (ac′′
S )), and

176
7 Model Transformation and Model Integration
– recursively deﬁned for composed application conditions.
• Given an S -extending application condition ac′
F over L, we deﬁne an application
condition toF(ac′
F) over LF = (RS ←
trS ◦sL
−−−−−LC −
tL−→LT) by
– toF(true) = true,
– toF( ∃(a, ac′′
F)) = ∃((idRS , aC, aT), toF(ac′′
F)), and
– recursively deﬁned for composed application conditions.
• Given an application condition ac′
T over L, we deﬁne an application condition
toT(ac′
T) over LT = (∅←∅→LT) by
– toT(true) = true,
– toT( ∃(a, ac′′
T)) = ∃((id∅, id∅, aT), toS (ac′′
T)), and
– recursively deﬁned for composed application conditions.
• Given a T-extending application condition ac′
B over L, we deﬁne an application
condition toB(ac′
B) over LB = (LS ←
sL−−LC −
trT ◦tL
−−−−→RT) by
– toB(true) = true,
– toB( ∃(a, ac′′
B)) = ∃((aS , aC, idRT ), toB(ac′′
B)), and
– recursively deﬁned for composed application conditions.
• Given an application condition ac′
ST over L, we deﬁne an application condition
toST(ac′
ST) over LST = (LS ←∅→LT) by
– toST(true) = true,
– toST( ∃(a, ac′′
ST)) = ∃((aS , id∅, aT), toST(ac′′
ST)), and
– recursively deﬁned for composed application conditions.
△
In order to assign an application condition ac to the derived operational rules, we
have to be able to decompose it properly.
Deﬁnition 7.8 (S - and T-consistent application conditions). Given a triple rule
tr = (tr: L →R, ac), ac is
• S -consistent if it can be decomposed into ac  ac′
S ∧ac′
F such that ac′
S 
Shift((idLS , ∅LC, ∅LT ), toS (ac′
S )) and ac′
F is an S -extending application condi-
tion.
• T-consistent if it can be decomposed into ac  ac′
T ∧ac′
B such that ac′
T 
Shift((∅LS , ∅LC, idLT ), toT(ac′
T)) and ac′
B is a T-extending application condition.
• ST-consistent if it can be decomposed into ac  ac′
ST such that ac′
ST

Shift((idLS , ∅LC, idLT ), toS T(ac′
ST)).
If ac is S -consistent (T-consistent, ST-consistent), we also say that tr is S -consistent
(T-consistent, ST-consistent).
△

7.2 Derivation of Operational Rules
177
The consistency conditions for application conditions in Def. 7.8 can be checked
as follows. First of all, for an S -consistent application condition we require that we
be able to split it into a conjunction of an application condition ac′
S that concerns the
source component only and an application condition ac′
F that does not restrict source
structures. Thus, a modeller should use application conditions that are already of
this form. Furthermore, we require that ac′
S  Shift((idLS , ∅LC, ∅LT ), toS (ac′
S )). By
Lem. 7.9 we show that our general assumption (see Rem. 7.5) already ensures this
condition. This means that the additional condition is guaranteed by using almost
injective morphisms for matches and application conditions.
Lemma 7.9 (Validity of S -consistency for almost injective morphisms). Let ac
be an S -application condition for a triple rule tr = (L →R) and ac′ = Shift((idLS ,
∅LC, ∅LT ), toS (ac)). Let further all morphisms in ac be almost injective. Then, ac′ ≡
ac for almost injective matches, i.e.: for each almost injective morphism m: L →G
it holds that m |= ac ⇔m |= ac′.
△
Proof. See Appendix B.6.1.
⊓⊔
Example 7.10 (Consistent application conditions). Two of the triple rules in Fig. 3.8
described in Ex. 3.9 contain application conditions. The application condition of rule
Association2ForeignKey is both, a T-application condition and an S -extending
application condition. The rule PrimaryAttr2Column contains a conjunction of
two NACs, where NAC1 is an application condition that is an S -application condition
and a T-extending application condition and NAC2 is an application condition that
is a T-application condition and an S -extending application condition. Therefore,
all application conditions are S -consistent and T-consistent, because they can be
decomposed as required using ac  (ac∧true). Moreover, all application conditions
are ST-consistent, because they are each either S - or T-consistent.
△
From a triple rule, we can derive a source rule trS and a target rule trT, which
specify the changes made by this rule in the source and target components, respec-
tively. Similarly, we derive a source–target rule trST specifying the changes made by
this rule in the source and target components synchronously. Additionally, we derive
the forward rule trF describing the changes made by the rule to the correspondence
and target parts, the backward rule trB concerning the correspondence and source
parts, and the integration rule trI concerning the correspondence parts. Intuitively,
these rules require that their counterparts (source, target, and source–target, respec-
tively) have been applied already. Intuitively, source rules are used to parse a given
source model in order to control the actual forward model transformation via for-
ward rules from source to target models. Vice versa, target rules are used to parse
a given target model in order to control the actual backward model transformation
via backward rules from target to source models. Source–target rules are used to
parse a given pair of source and target models in order to control the actual model
integration via integration rules, yielding a fully integrated model. Technically, the
source rules recreate the given source model, such that the matches can be used
to induce partial matches for the forward rules that transform the model into the
corresponding target model.

178
7 Model Transformation and Model Integration
(LS
trS

LC
sL
o
trC

tL / LT)
trT

(RS
RC
sRo
tR / RT)
triple rule tr
(LS
trS

∅
o

/ ∅)

(RS
∅
o
/ ∅)
source rule trS
(∅

∅
o

/ LT)
trT

(∅
∅
o
/ RT)
target rule trT
(LS
trS

∅
o

/ LT)
trT

(RS
∅
o
/ RT)
source-target rule trS T
(RS
id
LC
trS ◦sL
o
trC

tL
/ LT)
trT

(RS
RC
sR
o
tR
/ RT)
forward rule trF
(LS
trS

LC
sL
o
trC

trT ◦tL / RT)
id
(RS
RC
sR
o
tR
/ RT)
backward rule trB
(RS
id
LC
trS ◦sL
o
trC

trT ◦tL / RT)
id
(RS
RC
sR
o
tR
/ RT)
integration rule trI
operational rule
left-hand side
right-hand side
rule morphism
source rule
trS : LS →RS
LS = (LS ←∅→∅)
RS = (RS ←∅→∅)
trS = (trS , ∅, ∅)
target rule
trT : LT →RT
LT = (∅←∅→LT)
RT = (∅←∅→RT)
trT = (∅, ∅, trT)
forward rule
trF : LF →RF
LF =
(RS ←
trS ◦sL
−−−−−LC −
tL−→LT)
RF = R
trF = (idS
R, trC, trT)
backward rule
trB : LB →RB
LB =
(LS ←
sL−−LC −
trT ◦tL
−−−−→RT)
RB = R
trB = (trS , trC, idT
R)
source–target rule
trST : LST →RST
LST =
(LS ←∅→LT)
RS = (RS ←∅→RT)
trS = (trS , ∅, trT)
integration rule
trI : LI →RI
LI =
(RS ←
trS ◦sL
−−−−−LC −
trT ◦tL
−−−−→RT)
RI = R
trI = (idS
R, trC, idT
R)
Fig. 7.2 The main components of derived operational rules for model transformation
Deﬁnition 7.11 (Derived operational rules without application conditions).
Given a triple rule tr = (tr: L →R, ac), we derive its operational rules trS , trT, trS T,
trF, trB, trI without application conditions according to Fig. 7.2. The data compo-
nent for each inclusion ∅→X for a triple graph X is given by an identity, i.e., the
construction does not change the data component.
△
We combine the translated application conditions with the derived rules without
application conditions, leading to the derived rules of a triple rule with application
conditions.
Deﬁnition 7.12 (Derived operational rules). Given a triple rule tr = (tr: L →
R, ac), we derive its operational rules without application conditions according
to Def. 7.11. If tr contains an application condition ac of L, then the derivation
is extended as deﬁned below, requiring additional consistency conditions. If ac
is an S -consistent application condition, we derive ac  ac′
S ∧ac′
F and we ob-
tain the source rule trS = (trS , acS ) with acS = toS (ac′
S ) and the forward rule

7.2 Derivation of Operational Rules
179
Class2TableS(n:String)
:Class
name=n
++
:parent
S1:Class
:Class
name=n
Subclass2TableS(n:String)
++
++
S1:Class
:Attribute
name=n
datatype=t
is_primary=false
:attrs
++
++
Attr2ColumnS(n:String, t:String)
++
++
++
++
++
:Class
name=n
:CT
:Table
name=n
Class2TableF(n:String)
++
++
:parent
S1:Class
:Class
name=n
:CT
:Table
:CT
Subclass2TableF(n:String)
++
++
++
++
++
:Column
name=n
type=t
:cols
:AC
S1:Class
:Attribute
name=n
datatype=t
is_primary=false
:attrs
C1:
CT
T1:Table
++
++
++
Attr2ColumnF(n:String, t:String)
++
++
++
++
Fig. 7.3 Derived source rules (left) and forward rules (right) for CD2RDBM
trF = (trF, acF) with acF = toF(ac′
F). If ac is a T-consistent application condi-
tion, we derive ac  ac′
T ∧ac′
B and we obtain the target rule trT = (trT, acT) with
acT = toT(ac′
T) and the backward rule trB = (trB, acB) with acB = toB(ac′B). If ac
is an ST-application condition, we obtain the source–target rule trST = (trST, acST)
with acST = toST(ac) and the integration rule trI = (trI, true). By TRS , TRT, TRST,
TRF, TRB and TRI, we denote the sets of all source, target, source–target, forward,
backward and integration rules derived from TR.
△
Remark 7.13 (Symmetry of forward and backward case). According to Def. 7.12,
the deﬁnition of operational rules shows symmetries. Source rules are symmetric to
target rules and forward rules are symmetric to backward rules. For this reason, all
further constructions can be presented based on source and forward rules and the
symmetric constructions and results for target and backward rules follow immedi-
ately.
△
Example 7.14 (Derived operational rules). The derived operational source and for-
ward rules for the model transformation CD2RDBM are depicted in Fig. 7.3. The
derived operational target and backward rules follow by the symmetry in Def. 7.12.
Intuitively, the source rules are obtained by deleting all elements in the correspon-
dence and target components, including the components of the application condi-
tions. The forward rules are obtained by removing all double plus signs in the source
component and by removing the application conditions on the source component.
The derived operational source–target and integration rules for the model transfor-
mation CD2RDBM are depicted in Figs. 7.4 and 7.5. Intuitively, the source–target
rules are obtained by deleting all elements in the correspondence component, in-

180
7 Model Transformation and Model Integration
:Class
name=n
:Table
name=n
Class2TableST(n:String)
++
++
++
++
:Class
name=n
:CT
:Table
name=n
Class2TableI(n:String)
++
++
++
:parent
S1:Class
:Class
name=n
:Table
Subclass2TableST(n:String)
++
++
++
++
:parent
S1:Class
:Class
name=n
:CT
:Table
:CT
Subclass2TableI(n:String)
++
++
++
:Column
name=n
type=t
:cols
S1:Class
:Attribute
name=n
datatype=t
is_primary=false
:attrs
T1:Table
++
++
++
++
Attr2ColumnST(n:String, t:String)
++
++
++
++
++
:Column
name=n
type=t
:cols
:AC
S1:Class
:Attribute
name=n
datatype=t
is_primary=false
:attrs
C1:
CT
T1:Table
++
Attr2ColumnI(n:String, t:String)
++
++
:attrs
:cols
S1:Class
:Attribute
name=n
datatype=t
is_primary=true
:attrs
T1:Table
++
++
++
:Column
name=n
type=t
PrimaryAttr2ColumnST(n:String, t:String)
:pKey
++
:Column
:pKey
:Attribute
is_primary=true
NAC1
NAC2
++
++
++
++
++
++
:cols
:AC
S1:Class
:Attribute
name=n
datatype=t
is_primary=true
:attrs
C1:
CT
T1:Table
++
:Column
name=n
type=t
:pKey
++
++
PrimaryAttr2ColumnI(n:String, t:String)
Fig. 7.4 Derived source–target and integration rules for CD2RDBM (part 1)

7.2 Derivation of Operational Rules
181
:Class
:src
:Class
:dest
:FKey
:Table
:fkeys
:references
:pkey
:CT
:AT
:CT
:fcols
:Association
name = an
:Column
type=t1
name="src_"+cn1
Association2TableI(an:String)
++
:Column 
type = t2
name = cn2
++
++
:Table
:pkey
:Column 
type = t1
name = cn1
:FKey
:fkeys
:fcols
:Column
type=t2
name="tgt_"+cn2
:references
:Table
name=an
:FKey
:Table
:fkeys
:references
:pkey
++
++
:fcols
:Column
type=t1
name="src_"+cn1
Association2TableST(an:String)
:Column 
type = t2
name = cn2
:Table
++
++
++
++
:pkey
:Column 
type = t1
name = cn1
++
:FKey
:fkeys++
++
:fcols
:Column
type=t2
name="tgt_"+cn2
++
++
++
:references
++
++
:Table
name=an ++
++
:Class
:src
:Class
:dest
++
++
:Association
name = an
++
++
Fig. 7.5 Derived source–target and integration rules for CD2RDBM (part 2)
cluding the components of the application conditions. The integration rules are ob-
tained by removing all double plus signs in the source and target components and
by removing the application conditions on the source and target components.
△
In the following, we want to split each triple rule into the corresponding source
and forward rules. Each triple rule without application conditions is the E-concurrent
rule of its source and forward rules as well as the E-concurrent rule of its target and
backward rules (see also the proof for Thm. 1 in [EEE+07]). Moreover, each triple
rule without application conditions is the E-concurrent rule of its source–target and
integration rules (see also the proof for Lem. 1 in [EEH08a]).
Fact 7.15 (Splitting of triple rule without application condition). Given a triple
rule tr = (tr: L →R) without application conditions, we have that tr = trS ∗E1 trF =
trT ∗E2 trB = trST ∗E3 trI with E1, E2 and E3 being the domains of trF, trB and trI,
respectively.
△
Proof. At ﬁrst, we show that tr = trS ∗E1 trF where E1 = LF. Triple graph mor-
phisms e1,F and e2,F are obtained from pushouts (1F) and (2F) in ATrGraphsATG
(see Fig. 7.6). Using tr = trF ◦(trS , id, id) we obtain trS ∗E trF = tr. Symmetri-
cally, we derive that tr = trT ∗E2 trB where E2 = LB by exchanging trS with trT

182
7 Model Transformation and Model Integration
LS
=
(LS ←∅→∅)
trS
/
(id,∅,∅) 
(1F)
RS
=
(RS ←∅→∅)
=e1,F
(id,∅,∅)
)
LF
=
(RS ←LC→LT )
trF
/
id=e2,F
u
(2F)
RF
=
(RS ←RC→RT )
id
L
=
(LS ←LC→LT )
(trS ,id,id)
/ LF
=
(RS ←LC→LT )
trF=(id,trC,trT )
/ R
=
(RS ←RC→RT )
tr
1
LT
=
(∅←∅→LT )
trT
/
(∅,∅,id) 
(1B)
RT
=
(∅←∅→RT )
=e1,B
(∅,∅,id)
)
LB
=
(LS ←LC→RT )
trB
/
id=e2,B
u
(2B)
RB
=
(RS ←RC→RT )
id
L
=
(LS ←LC→LT )
(id,id,trT )
/ LB
=
(LS ←LC→RT )
trB=(trS ,trC,id)
/ R
=
(RS ←RC→RT )
tr
1
LST
=
(LS ←∅→LT )
trST
/
(id,∅,id) 
(1I)
RST
=
(RS ←∅→RT )
=e1,I
(id,∅,id)
)
LI
=
(RS ←LC→RT )
trI
/
id=e2,I
u
(2I)
RI
=
(RS ←RC→RT )
id
L
=
(LS ←LC→LT )
(trS ,id,trT )
/ LI
=
(RS ←LC→RT )
trI=(id,trC,id)
/ R
=
(RS ←RC→RT )
tr
1
Fig. 7.6 Splitting of triple rules via forward, backward and integration rules (from top to bottom)
and trF with trB. Analogously, we derive that tr = trST ∗E3 trI where E3 = LI by
exchanging trS with trST and trF with trI. In that case, e1,I = (id, ∅, id), e2,I = id,
and tr = trI ◦(trS , id, trT).
⊓⊔
In case of S -consistency, each triple rule is the E-concurrent rule of its source
and forward rules. Similarly, in case of T-consistency, each triple rule is the E-
concurrent rule of its target and backward rules (see also Fact 5.17 in [Gol11]).
Moreover, in case of an ST-application condition, each triple rule is the E-concurrent
rule of its source–target and its integration rule. This correspondence is made ex-
plicit in Prop. 7.16 below and used to show the composition and decomposition
theorem for TGGs in Theorem 7.21, which builds the basis for the correctness and
completeness properties in Sect. 8.1.
Proposition 7.16 (Splitting of triple rule with application condition). Given a
triple rule tr = (tr: L →R, ac) with S -consistent ac, tr = trS ∗E1 trF with E1 = LF.
Dually, if ac is T-consistent we have that tr = trT ∗E2 trB with E2 = LB. If ac is
ST-consistent, we have that tr = trST ∗E3 trI with E3 = LI.
△
Proof. By Fact 7.15 we know that this holds for triple rules without applica-
tion conditions. It remains to show the property for the application conditions.
By Def. 5.27, the application condition ac∗of (trS ∗LF trF) is given by ac∗=

7.2 Derivation of Operational Rules
183
L
a

ac′
F
L
a

idL
o
iL
/
(PO)
(PO)
LF
aF

acF
P
ac′′
F
P
idP
o
iP
/ PF
toF(ac′′
F)
iL = (trS , idLC, idLT )
iP = (trS , idPC, idPT )
a
= (idLS , aC, aT)
aF = (idRS , aC, aT)
Fig. 7.7 Obtaining P as pushout complement from left shift construction
Shift(u1, ac1) ∧L(p∗, Shift(e2, ac2)) with u1 = (idLS , ∅LC, ∅LT ), ac1 = acS , p∗=
(L ←
idL
−−−L −
(trS ,idLC ,idLT )
−−−−−−−−−−→LF), e2 = e2,F = idLF and ac2 = acF. Thus, we have that
ac∗= Shift((idLS , ∅LC, ∅LT ), acS ) ∧L((L ←
idL
−−−L −
(trS ,idLC ,idLT )
−−−−−−−−−−→LF), Shift(idE1, acF)).
We show that ac = ac′
S ∧ac′
F  ac∗in two steps:
1. ac′
S  Shift((idLS , ∅LC, ∅LT ), acS ). Since acS = toS (ac′
S ) and ac is S -consistent,
we can conclude directly that ac′
S  Shift((idLS , ∅LC, ∅LT ), toS (ac′
S )).
2. ac′
F  L((L ←
idL
−−−L −
(trS ,idLC ,idLT )
−−−−−−−−−−→LF), Shift(idLF, acF)). Shift(idLF, acF)  acF by
Item 1 of Fact 5.4, and therefore ac′
F  L((L ←
idL
−−−L −
(trS ,idLC ,idLT )
−−−−−−−−−−→LF), acF). With
acF = toF(ac′
F) this is obvious for ac′
F = true. Consider ac′
F = ∃(a, ac′′
F) with
L((LS ←PC →PT) →(RS ←PC →PT), toF(ac′′
F))  ac′′
F. Then (PS = LS ←
sP−−
PC −
tP−→PT) is the pushout complement constructed for the left shift construction
(see Fig. 7.7). Thus, we have that L((L −
(trS ,idLC ,idLT )
−−−−−−−−−−→LF), toF( ∃(a, ac′′
F))) 
L((L ←
idL
−−−L −
(trS ,idLC ,idLT )
−−−−−−−−−−→LF), ∃((idRS , aC, aT), toF(ac′′
F)))  ∃((idLS , aC, aT),
L((P ←
idP
−−−(LS ←PC →PT) →(RS ←PC →PT)), toF(ac′′
F))  ∃(a, ac′′
F) =
ac′
F. This can be recursively done, leading to the result that indeed L((L ←
idL
−−−
L −
(trS ,idLC ,idLT )
−−−−−−−−−−→LF), Shift(idLF, acF))  ac′
F.
It follows that ac  ac′
S ∧ac′
F  Shift((idLS , ∅LC, ∅LT ), acS ) ∧L((L −
(trS ,idLC ,idLT )
−−−−−−−−−−→
E1), Shift(idE1, acF)).
Dually, we can obtain the result for the splitting into target and backward rules for
a T-consistent application condition ac  ac′
T ∧ac′
B  Shift((∅LS , ∅LC, idLT ), acT)∧
L((L −
(idLS ,idLC ,trT )
−−−−−−−−−−→E2), Shift(idE2, acB)).
Analogously, we can obtain the result for the splitting into source–target and inte-
gration rules for an ST-consistent application condition ac. We show that Shift((idLS ,
∅LC, idLT ), acST)  ac. With acST = toST(ac) this is obviously true for ac = true.
Consider ac =
∃(a, ac′′) and suppose Shift((idPS , ∅LC, idPT ), toST(ac′′)) = ac′′.
Then we have that (PS ←
sP−−PC = LC −
tP−→PT) is the only square that we have
to consider in the shift construction; for the correspondence component, (C) is
the only jointly epimorphic extension we have to consider because all morphisms
in the application conditions are identities in the correspondence component. For

184
7 Model Transformation and Model Integration
any square (1) with a monomorphism bS and (bS , cS ) jointly epimorphic, it fol-
lows that bS is an epimorphism, i. e., PS
 QS . For any square (2) with a
monomorphism bT and (bT, cT) jointly epimorphic, it follows that bT is an epi-
morphism, i. e., PT  QT. This means that (S ) and (T) are the only epimor-
phic extensions that we obtain in the source and target components. It follows that
Shift((idLS , ∅LC, idLT ), toST( ∃(a, ac′′)))  ∃(a, Shift((idPS , ∅LS , idPT ), toST(ac′′))
 ∃(a, ac′′
ST) = ac′
ST. This can be recursively done, leading to the result that indeed
Shift((idLS , ∅LC, idPT ), acST)  ac.
LS
idLS /
aS 
(1)
LS
cS

PS
bS / QS
LT
idLT /
aT 
(2)
LT
cT

PT
bT / QT
LS
idLS /
aS 
(S )
LS
aS

PS
idPS
/ PS
∅
/

(C)
∅

LC
idLC
/ LC
LT
idLT /
aT 
(T)
LT
aT

PT
idPT
/ PT
Therefore, ac  Shift((idLS , ∅LC, idLT ), acST).
⊓⊔
7.3 Model Transformation Based on Forward Rules
In order to perform model transformations that are compatible with the consistency
speciﬁcation of a TGG, the triple rules of the TGG are used to generate operational
rules. These operational rules have to be executed in a controlled way. This section
presents the execution of forward transformations using the control condition source
consistency and backward transformations using the control condition target consis-
tency. In Sect. 7.4, we use extended operational rules for simplifying and improving
both, analysis and execution techniques.
The general idea of model transformations based on TGGs from source to tar-
get models is to take the given source model and apply forward rules in order to
complete the missing elements in the correspondence and target components. This
process has to be driven by a suitable control condition, which ensures termination,
correctness and completeness of the transformation with respect to the triple lan-
guage L(TGG) generated by the TGG. This control condition has been formalised
by the notion of source consistency in [EEE+07, EEHP09, GEH11]. As we show
in Chap. 8, source consistency ensures syntactical correctness and completeness. In
combination with an additional static condition on the rules, termination is ensured
as well.
Example 7.17 (Inconsistent transformation sequence via forward rules). The for-
ward transformation sequence G0 =
tr1,F,m1,F
======⇒G1 =
tr2,F,m2,F
======⇒G2 in Fig. 7.8 is incon-
sistent. Types are abbreviated by the ﬁrst letter. The two nodes of type Class are
translated into two nodes of type Table using the forward rule Class2TableF for
each step. However, the edge of type parent between the two nodes of type Class

7.3 Model Transformation Based on Forward Rules
185
L1,F
R1,F
G0
G1
G2
C
C
C
tr1,F
C
T
C
C
T
L2,F
R2,F
C
tr2,F
C
T
C
T
C
T
m1,F
m2,F
n1,F
n2,F
f1,F
f2,F
Fig. 7.8 Inconsistent forward sequence
was not handled by one of the two transformation steps. Still, we could execute fur-
ther forward transformation steps via rules Class2TableF or SubClass2TableF.
However, there is no extension of this sequence that would yield a triple graph
Gn ∈L(TGG). Thus, the result will never be consistent with the given TGG. In-
tuitively, each further step would need to eﬀectively translate again a node of type
Class.
△
As illustrated by Ex. 7.17, matches for forward rules have to be consistent with
the given source model. The main idea of source consistency is the following: Let us
consider a source model GS ∈L(TGS ). If there is a target model GT ∈L(TGT), such
that there is a triple graph G = (GS ←GC →GT) of the triple language L(TGG),
we know that GT corresponds to GS according to the TGG. Otherwise, there is
no consistent model transformation sequence starting with GS . The challenge is to
compute such a triple graph G ∈L(TGG), if it exists. By deﬁnition, G ∈L(TGG)
means that there is a triple sequence ∅=
tr∗
=⇒G via triple rules tr ∈TR. It turns out that
this sequence can be decomposed into a source sequence sS = ⟨∅=
tr∗
S=⇒Gn,0 = GS ⟩
with GS = (GS ←∅→∅) via source rules trS ∈TRS and a forward sequence
sF = ⟨GS =
tr∗
F
==⇒Gn,n = G⟩via forward rules trF ∈TRF. In addition to that, the se-
quences correspond stepwise to each other concerning the applied rules and the used
matches. The exact correspondence is characterised by the notion of source consis-
tency. The remaining challenge is to compute possible source sequences from a
given source model, which intuitively means to parse the source model. In Sect. 7.4,
we provide an eﬃcient technique for this purpose.
In a ﬁrst step, we analyse how a triple transformation sequence can be decom-
posed into a transformation applying ﬁrst the source rules followed by a sequence of
forward rules. Match consistency of the decomposed transformation means that the
co-matches of the source rules deﬁne the source part of the matches of the forward
rules. This notion provides the basis for the actual control condition source consis-
tency for forward model transformations. Note that triple transformation sequences
always satisfy the application conditions of the corresponding rules.
Deﬁnition 7.18 (Source and match consistency).
Given a sequence (tri)i=1,...,n
of triple rules with S -consistent application conditions leading to corresponding
sequences (tri,S )i=1,...,n and (tri,F)i=1,...,n of source and forward rules. A triple trans-

186
7 Model Transformation and Model Integration
Li,S
tri,S
/
mi,S 
Ri,S
=
(RS ←∅→∅)
ni,S 
Li,F
tri,F
/
=
(RS ←LC→LT )
mi,F 
Ri,F
ni,F 
. . .
/ Gi,0
/ Gi+1,0
/
inci
5
. . .
/ Gn,i
/ Gn,i+1
/ . . .
(inci ◦ni,S )S = mS
i,F
Fig. 7.9 Match and source consistency conditions
Forward Sequence
L1,F
R1,F
G0
G1
G2
C
C
C
tr1,F
C
T
C
C
T
L2,F
R2,F
tr2,F
C
T
C
m1,F
m2,F
n1,F
n2,F
f1,F
f2,F
L1,S
R1,S
G0,0
G1,0
G2,0
tr1,S
C
C
L2,S
R2,S
tr2,S
C
C
C
m1,S
m2,S
n1,S
n2,S
f1,S
f2,S
Source Sequence
C
C
C
T
C
C
T
C
Fig. 7.10 Consistent forward sequence: source sequence (top) and forward sequence (bottom)
formation sequence ∅= G0,0 =
tr∗
S=⇒Gn,0 =
tr∗
F
==⇒Gn,n via ﬁrst tr1,S , . . . , trn,S and then
tr1,F, . . . , trn,F with matches mi,S and mi,F and co-matches ni,S and ni,F, respectively,
is match consistent if the source component of the match mi,F is uniquely deﬁned
by the co-match ni,S (see Fig. 7.9).
A triple transformation Gn,0 =
tr∗
F
==⇒Gn,n is called source consistent if there is a
match consistent sequence G0,0 =
tr∗
S=⇒Gn,0 =
tr∗
F
==⇒Gn,n.
△
Example 7.19 (Consistent transformation sequence via forward rules). The forward
transformation sequence G0 =
tr1,F,m1,F
======⇒G1 =
tr2,F,m2,F
======⇒G2 in the bottom of Fig. 7.10 is
source consistent. The compatible source sequence G0,0 = ∅=
tr1,S ,m1,S
======⇒G1,0 =
tr2,S ,m2,S
======⇒
G2,0 = G0 provides co-matches ni,S that induce the source component mS
i,F of the

7.3 Model Transformation Based on Forward Rules
187
forward matches mi,F of the forward sequence. Intuitively, each forward step is trig-
gered by a corresponding source step until the given source model GS
0 is completely
constructed by the source rules. In fact, the ﬁrst source step creates the upper node
of type Class and the second source step creates the remaining node and edge.
△
As mentioned in the beginning of this section, the triple rules tri ∈TR generate
the language of consistent integrated models L(TGG). Therefore, is is important
that there is a compatibility between the transformation sequences via the triple rules
tri ∈TR and the consistent transformation sequences via forward rules. This com-
patibility is expressed by the decomposition and composition property. The main
idea is that we can split a transformation G0 =
tr1=⇒G1 ⇒. . . =
trn=⇒Gn via triple rules
tri ∈TR into transformations G0 =
tr1,S
==⇒G′
0 =
tr1,F
==⇒G1 ⇒. . . =
trn,S
==⇒G′
n−1 =
trn,F
==⇒Gn.
Deﬁnition 7.20 (Decomposition and composition (forward case)). A TGG satis-
ﬁes the decomposition and composition property for forward sequences if the fol-
lowing holds:
1. Decomposition: For each triple transformation sequence
(1) G0 =
tr1=⇒G1 ⇒. . . =
trn=⇒Gn via rules in TR
there is a corresponding match consistent triple transformation sequence
(2) G0 = G0,0 =
tr1,S
==⇒G1,0 ⇒. . . =
trn,S
==⇒Gn,0 =
tr1,F
==⇒Gn,1 ⇒. . . =
trn,F
==⇒Gn,n = Gn
via rules in TRS and TRF.
2. Composition: For each match consistent triple transformation sequence (2) as
above there is a canonical triple transformation sequence (1) as above.
3. Bijective Correspondence: Composition and decomposition are inverse to each
other.
△
A suﬃcient condition for the (de)composition property of TGGs in the forward
case is that the application conditions of triple rules are S -consistent application
conditions as stated by Theorem 7.21 [EEE+07, EHS09, GEH11] below. The proof
shows that a decomposition into a match consistent transformation can be found in
general, but the composition of match consistent transformations into transforma-
tions via the corresponding triple rules requires the additional condition. The inves-
tigation of further suﬃcient criteria to ensure the (de)composition property forms a
future research topic for TGGs.
Theorem 7.21 (Decomposition and composition). For triple transformation se-
quences with S -consistent application conditions, the decomposition and composi-
tion property for forward sequences holds.
△
Proof. At ﬁrst, we concern only triple rules without ACs (see Fig. 7.11).
1. Decomposition: Given the TGT sequence (1) G0 =
tr1=⇒G1 ⇒. . . =
trn=⇒Gn we ﬁrst
consider the case n = 1. A TGT step G0 =
tr1=⇒G1 can be decomposed uniquely
into a match consistent TGT sequence G0 = G0,0 =
tr1,S
==⇒G1,0 =
tr1,F
==⇒G1,1 = G1.

188
7 Model Transformation and Model Integration
G0,0
tr1,S
+3
tr1,T

tr1
#+
G1,0
tr2,S
+3
tr1,F

G2,0 . . .
tr3,S
+3
tr1,F

Gn,0
tr1,F

G0,1
tr1,B
+3
tr2,T

G1,1
tr2,S
+3
tr2,T

tr2
$,
G2,1 . . .
tr3,S
+3
tr2,F

Gn,1
tr2,F

. . .
tr1,B
+3
trn,T

. . .
tr2,B
+3
trn,T

. . . . . .
trn,S
+3
trn,T

trn
$,
. . .
trn,F

G0,n
tr1,B
+3 G1,n
tr2,B
+3 G2,n . . .
tr3,B
+3 Gn,n
Fig. 7.11 Composition and decomposition of triple sequences
By Fact 7.15 we have shown that tr1 can be represented as E-concurrent rule
tr1 = tr1,S ∗E tr1,F. Using the Concurrency Theorem the TGT step G0 =
tr1=⇒G1
can be decomposed uniquely into an E-related sequence as given above. In this
special case, an E-relation is equivalent to the fact that the S -components of
the co-match of G0,0 =
tr1,S
==⇒G1,0 and the match of G1,0 =
tr1,F
==⇒G1,1 coincide,
which corresponds exactly to match consistency. Using this construction for
i = 1, . . . , n the transformation sequence (1) can be decomposed canonically
to an intermediate version between (1) and (2) called (1.5): G0 = G0,0 =
tr1,S
==⇒
G1,0 =
tr1,F
==⇒G1,1 =
tr2,S
==⇒G2,1 =
tr2,F
==⇒G2,2 =⇒. . . =
trn,S
==⇒Gn,n1 =
trn,F
==⇒Gn,n, where
each subsequence Gi1,i1 =
tri,S
==⇒Gi,i1 =
tri,F
==⇒Gi,i is match consistent. Moreover,
G1,0 =
tr1,F
==⇒G1,1 =
tr2,S
==⇒G2,1 is sequentially independent, because we have a
morphism d: L2 →G1,0, with L2 = (LS
2 ←∅→∅) and d = (mS
2 , ∅, ∅).
The morphism m2 : L2 →G1,1 is the match of G1,1 =
tr2,S
==⇒G2,1, because the S-
components of G1,0 and G1,1 are equal according to the forward rule tr1,F. Now
the Local Church–Rosser Theorem (Theorem 5.26) leads to an equivalent se-
quentially independent sequence G1,0 =
tr2,S
==⇒G2,0 =
tr1,F
==⇒G2,1 such that G0,0 =
tr1,S
==⇒
G1,0 =
tr2,S
==⇒G2,0 =
tr1,F
==⇒G2,1 =
tr2,F
==⇒G2,2 is match consistent. The iteration of this
shift between tri,F and tr j,S leads to a shift-equivalent transformation sequence
(2) G0 = G0,0 =
tr1,S
==⇒G1,0 ⇒. . . =
trn,S
==⇒Gn,0 =
tr1,F
==⇒Gn,1 ⇒. . . =
trn,F
==⇒Gn,n = Gn,
which is still match consistent.
2. Composition: Vice versa, each match consistent transformation sequence (2)
leads to a canonical sequence (1.5) by inverse shift equivalence, where each sub-
sequence as above is match consistent. In fact, match consistency of (2) implies
that the corresponding subsequences are sequentially independent in order to al-
low inverse shifts in an order opposite to that in Item 1, using again the Local
Church–Rosser Theorem. Match consistent subsequences of (1.5) are E-related,

7.3 Model Transformation Based on Forward Rules
189
as discussed in Item 1, which allows to apply the Concurrency Theorem to obtain
the TGT sequence (1).
3. Bijective Correspondence: The bijective correspondence of composition and de-
composition is a direct consequence of the bijective correspondence in the Local
Church–Rosser and the Concurrency Theorem, where the bijective correspon-
dence for the Local Church–Rosser Theorem is not explicitly formulated in The-
orem 5.26, but is a direct consequence of the proof in analogy to Theorem 5.30.
Now we consider the case of triple rules with ACs. We use the facts that tri =
tri,S ∗Ei tri,F, as shown in Prop. 7.16, and that the transformations via tri,S and tr j,F
are sequentially independent for i > j, as shown above for rules without application
conditions. This result can be extended to triple rules with application conditions,
as shown in the following.
It suﬃces to show that the transformations G1,0 =
tr1,F,m1
=====⇒G1,1 =
tr2,S ,m2
=====⇒G2,1 are se-
quentially independent. From the sequential independence without application con-
ditions we obtain morphisms i : R1,F →G1,1 with i = n1 and j : L2,S →G1,0 with
g1 ◦j = m2.
It remains to show the compatibility with the application conditions (see
Fig. 7.12):
•
j |= ac2,S (see Fig. 7.12(a)): ac2,S = toS (ac′
2,S ). For ac′
2,S = true, also ac2,S =
true and therefore j |= ac2,S . Suppose ac′
2,S = ∃(a, ac′′
2,S ), leading to ac2,S =
∃((aS , id∅, id∅), toS (ac′′
2,S )). Moreover, tr1,F is a forward rule, i.e., it does not
change the source component and GS
1,1 = GS
1,0. We know that m2 = g1 ◦j |= ac2,S ,
which means that there exists p : P →G1,1 with p ◦a = g1 ◦j, p |= toS (ac′′
2,S ),
and pC = ∅, pT = ∅. Then there exists q : P →G1,0 with q = (pS , ∅, ∅),
q ◦a = (pS ◦aS , ∅, ∅) = j, and q |= toS (ac′′
2,S ) because all objects occurring in
toS (ac′′
2,S ) have empty correspondence and target components. This means that
j |= ac2,S for this case, and can be shown recursively for composed ac2,S .
• g2 ◦n1 |= acR := R(tr1F, ac1F) (see Fig. 7.12(b)): ac1,F = toF(ac′
1,F), where ac′
1,F
is an S -extending application condition. For ac′
1,F = true also ac1,F = true and
acR = true, therefore g2 ◦n1 |= acR. Now suppose ac′
1,F = ∃(a, ac′′
1,F), lead-
ing to ac1,F =
∃((idRS
1 , aC, aT), toF(ac′′
1,F)) and acR =
∃((idRS
1 , bC, bT), ac′
R)
by componentwise pushout construction for the right shift with ac′
R = R(u,
toF(ac′′
1,F)). Moreover, tr2,S is a source rule, which means that gC
2 and gT
2 are iden-
tities. From the shift property of application conditions we know that n1 |= acR,
using m1 |= ac1,F. This means that there is a morphism p : P →G1,1 with
p ◦a = n1, p |= ac′
R, and pS = nS
1 . It follows that g2 ◦p ◦a = g2 ◦n1 and
g2 ◦p = (gS
2 ◦pS , pC, pT) |= ac′
R, because it only diﬀers from p in the S -
component, which is identical in all objects occurring in ac′
R. This means that
g2 ◦n1 |= acR = ∃(a, ac′
R), and can be shown recursively for composed acR.
⊓⊔
Remark 7.22 (Composition and decomposition for backward case). For each TGT
sequence G0 =
tr∗
=⇒Gn there is also a corresponding match consistent backward TGT
sequence G0 = G00 =
tr1,T
==⇒G01 =⇒. . . =
trn,T
==⇒G0n =
tr1,F
==⇒G1n =⇒. . . =
trn,F
==⇒Gnn = Gn

190
7 Model Transformation and Model Integration
L1,F
R1,F
G1,0
G1,1
L2,S
R2,S
G2,1
tr1,F
g1
m1
i=n1
j
tr2,S
g2
m2
n2
(PS
∅
∅)
(LS
2
∅
∅)
GS
1,0
GC
1,0
GT
1,0
GS
1,0 =
GS
1,1
GC
1,1
GT
1,1
toS (ac′′
2,S )
ac2,S
sG1,0
tG1,0
sG1,1
tG1,1
aS
jS
id
gC
1
gT
1
pS
(a) j |= ac2,S
RS
1
LC
1
LT
1
PS
=
RS
1
PC
PT
RS
1
RC
1
RT
1
P′S
=
RS
1
P′C
P′T
trS
1 ◦sL
tL
sP
tP
id
aC
aT
sR
tR
sP′
tP′
id
bC
bT
id
trC
1
trT
1
id
uC
uT
P′S
=
RS
1
P′C
P′T
RS
1
RC
1
RT
1
GS
11
GC
11
GT
11
GS
21
=
GC
11
GC
21
GT
21
=
GT
11
ac′
R
acR
sP
tP
sR
tR
sG10
tG10
sG11
tG11
id
bC
bT
nS
1
nC
1
nT
1
gS
2
id
id
nS
1 =pS
pC
pT
(b) g2 ◦n1 |= acR := R(tr1,F, ac1,F)
Fig. 7.12 Constructions for showing compatibility with the application conditions
based on target and backward rules, leading to a backward model transformation
MTB : L(TGT) ⇛L(TGS ) with similar results as in the forward case.
△
Based on source consistent forward transformations we deﬁne model transfor-
mations, where we assume that the start graph of the given TGG is the empty graph.
Deﬁnition 7.23 (Model transformation based on forward rules). A (forward)
model transformation sequence (GS ,G0 =
tr∗
F=⇒Gn,GT) is given by a source graph
GS , a target graph GT, and a source consistent forward transformation G0 =
tr∗
F=⇒Gn
with G0 = (GS
∅
←−∅
∅
−→∅) and GT
n = GT.
A (forward) model transformation MTF : VLS ⇛VLT is deﬁned by all (for-
ward) model transformation sequences.
△
Example 7.24 (Model transformation sequence). Fig. 7.13 shows the resulting triple
graph G of a transformation sequence G0 =
tr∗
F
==⇒Gn via forward rules. This sequence

7.3 Model Transformation Based on Forward Rules
191
GC
T6:FKey
T8:fkeys 
T14:cols
S5:Association 
name="employee"
S3:Class 
name="Company"
S7:Class 
name="Person"
S11:Class 
name="Customer"
S10:Attribute 
name="pId"
datatype="INTEGER"
is_primary=true
T18:Column 
type="INTEGER"
name="pId"
T12:Table 
name="Person"
T1:Column 
type="INTEGER"
name="cId"
T7:references
C2:
CT
C6:
CT
C3:
AT
C4:
CT
C5:
AC
GS
GT
S1:Attribute 
name="cId"
datatype="INTEGER"
is_primary=true
T10:Table 
name="employee"
T16:FKey
T4:Column 
type="INTEGER"
name="cId"
T19:Column 
type="INTEGER"
name="pId"
T5:fcols
T2:cols
T3:pkey
T17:fcols
T11:fkeys 
T15:references
C1:
AC
T13:pkey
S2:attrs
S8:parent
S9:attrs
S6:dest
S4:src
T9:Table
name="Company"
Forward transformation sequence: G0 =
Class2tableF
==========⇒G1 =
Class2tableF
==========⇒G2 =
Subclass2TableF
=============⇒
G3 =
PrimaryAttribute2ColumnF
=====================⇒G4 =
PrimaryAttribute2ColumnF
=====================⇒G5 =
Association2TableF
===============⇒G6 = Gn.
Step
Matched Elements
Created Elements
1
S3
C2, T9
2
S7
C4, T12
3
S7 −S8, S11, C4, T12
C6
4
S1 −S3, C2, T9
C1, T1 −T3
5
S7, S9 −S10, C4, T12
C5, T13 −T14, T18
6
S3 −S7, C2, C4, T1, T3, T9, T12 −T13, T18 C3, T4 −T8, T10 −T11, T15 −T17, T19
Fig. 7.13 Forward model transformation for CD2RDBM: result (top) and forward transformation
sequence (bottom)
speciﬁes a model transformation sequence (GS ,G0 =
tr∗
F
==⇒Gn,GT) from a source
model GS to a target model GT via forward rules, where G0 = (GS ←∅→∅).
The table in the bottom of the ﬁgure shows the corresponding steps with numbers
for matched and created elements. According to the numbers of the elements, the
correspondence and target components are completely created during the forward
model transformation sequence. Moreover, there is a source sequence ∅=
tr∗
S=⇒G0
such that ∅=
tr∗
S=⇒G0 =
tr∗
F
==⇒Gn is match consistent. The co-matches of the source
steps are given by the numbers for the source elements in the forward matches. In-
deed, we can inspect the ﬁgure and conclude that the sequence ∅=
tr∗
S=⇒G0 =
tr∗
F
==⇒Gn
is match consistent, because the source elements of each forward match are created
by the corresponding source rule applications in ∅=
tr∗
S=⇒G0.
△

192
7 Model Transformation and Model Integration
Similar to the structuring concepts for plain graph grammars [KKvT10], tech-
niques for rule reﬁnement and control structures have been introduced for TGGs to
improve the development process concerning usability and maintainability. We refer
you to [ASLS14] for an overview. In the next section, we present how the control
condition “source consistency” can be encoded by additional attributes, which is
used for analysis and implementation purposes.
7.4 Model Transformation Based on Forward Translation Rules
While the concept of model transformations based on source consistent forward
sequences in Sect. 7.3 provides an abstract formal basis for model transformations
based on TGGs, this section presents a possible encoding of the control condition
source consistency by extending the forward rules. This concept has been introduced
in [HEOG10b] and extended in [HEGO10, HEGO14]. The main idea is to extend the
operational forward rules with additional markers for keeping track of the elements
that have been translated during the execution of a forward transformation. This
concept achieves the following goals.
1. Simpliﬁcation of execution: The complex and descriptive control condition source
consistency that is based on the existence and compatibility of a source sequence
is replaced by a constructive check of marker values of the resulting graph.
2. Improvement of formal analysis: The general results for conﬂuence analysis for
M-adhesive transformation systems based on critical pair analysis cannot be ap-
plied directly to systems with forward rules and would need to be accompanied
with additional techniques in order to capture the eﬀect of the control condi-
tion source consistency. The encoding of this condition within the triple graphs
enables us to apply the critical pair analysis directly as performed in Sect. 8.2.
3. Implementation of the approach: The resulting execution strategy for model
transformations based on forward translation rules has a constructive nature that
can be implemented as an extension to existing graph transformation engines. It
has been used for realising the implementation in the tool HenshinTGG and it
has a close correspondence to the pointer structures that are used in execution
algorithms of other TGG tools.
The main idea is to extend the source component of the triple graph by addi-
tional Boolean-valued attributes that specify for each element whether it has been
already translated. The main result in this section shows that model transformations
based on source consistent forward TGT sequences are equivalent to those based on
complete forward translation TGT sequences, as stated by Fact 7.36. The control
condition source consistency is ensured by the completeness of forward translation
TGT sequences, which are based on the generated forward translation rules. For
this reason, the check of source consistency for forward TGT sequences is reduced
to a check for whether all translation attributes are set to “T”, which ensures that
the model is completely translated. Note that the encoding via translation attributes

7.4 Model Transformation Based on Forward Translation Rules
193
requires the general assumption (see Rem. 7.5), which states that matches and ap-
plication conditions are based on almost injective morphisms. This ensures that the
translation markers are independent from each other, because the morphisms do not
identify structural elements.
In many practical applications, model transformations are required to preserve
the source model in order to use database-driven model repositories. For this rea-
son, we have presented in [HEOG10a] how the translation attributes can be exter-
nalised using the concept of triple graphs with interfaces. The translation attributes
are equivalently replaced by external pointer structures such that the model trans-
formation can be performed without any modiﬁcation of the source model. This
concept corresponds to the transformation algorithm in [SK08], which uses a sepa-
rate set of translated elements. Furthermore, it shows how the source sequence for
a source consistent forward sequence in the previous section can be computed by
an implementation with additional pointer structures, as explained at the end of this
section.
7.4.1 Translation Attributes
The extension of forward rules to forward translation rules is based on new attributes
that control the translation process to ensure the source consistency condition. For
each node, edge and attribute of a graph a new attribute is created and labelled with
the preﬁx “tr”. Given an attributed graph AG = (G, D) and a family of subsets
M ⊆G for nodes and edges, we call AG′ a graph with translation attributes over AG
if it extends AG with one Boolean-valued attribute tr_x for each element x (node or
edge) in M and one Boolean-valued attribute tr_x_a for each attribute associated
to such an element x in M. In order to distinguish between a triple rule tr and the
preﬁx tr of a translation attribute, we use a diﬀerent font shape (typewriter). The
family M together with all these additional translation attributes is denoted by AttM.
Deﬁnition 7.25 (Family with translation attributes). Given an attributed graph
AG
=
(G, D) (see Def. 2.4), we denote by |G|
=
(VG
G, VD
G , EG
G, ENA
G , EEA
G )
the underlying family of sets containing all nodes and edges. Let M
⊆
|G| with (VG
M, VD
M, EG
M, ENA
M , EEA
M ); then a family with translation attributes for
(G, M) extends M by additional translation attributes and is given by AttM =
(VG
M, VD
M, EG
M, ENA, EEA) with:
• ENA = ENA
M
·∪{tr_x | x ∈VG
M} ·∪{tr_x_a | a ∈ENA
M , srcNA
G (a) = x ∈VG
G},
• EEA = EEA
M
·∪{tr_x | x ∈EG
M} ·∪{tr_x_a | a ∈EEA
M , srcEA
G (a) = x ∈EG
G}.
△
Deﬁnition 7.26 (Graph with translation attributes). Given an attributed graph
AG = (G, D) (see Def. 2.4) and a family of subsets M ⊆|G| with {T, F} ⊆VD
M, let
AttM be a family with translation attributes for (G, M) according to Def. 7.25. Then
AG′ = (G′, D) is a graph with translation attributes over AG, where the domains |G′|

194
7 Model Transformation and Model Integration
M  
/
 _

(PO)
AttM

|G|
/ |G′|
Fig. 7.14 Triple graph with translation attributes: construction
T1:Table
 name=“Company“
S3:Association 
tr=F
name = “employee“
tr_name=F
S1:Class 
tr=T
name=“Company“
tr_name=T
S5:Class 
tr=T
name=“Person“
tr_name=T
T2:Table 
name=“Person“
C1:
CT
C3:
CT
C2:
CT
HS
HT
S7:Class 
tr=T
name=“Customer“
tr_name=T
HC
S4:dest
tr=F
S6:parent
tr=T
S2:src
tr=F
Fig. 7.15 Triple graph with translation attributes: example
of G′ are given by the gluing via the pushout of |G| and AttM over M (see Fig. 7.14)
and the source and target functions of G′ are deﬁned as follows:
• srcG
G′ = srcG
G, trgG
G′ = trgG
G,
• srcX
G′(z) =
( srcX
G(z) z ∈EX
G
x
z = tr_x or z = tr_x_a for X ∈{NA, EA},
• trgX
G′(z) =
( trgX
G(z) z ∈EX
G
T or F z = tr_x or z = tr_x_a for X ∈{NA, EA}.
Attv
M, where v = T or v = F, denotes a family with translation attributes where
all attributes are set to v. Moreover, we denote by AG ⊕AttM that AG is extended
by the translation attributes in AttM, i.e., AG ⊕AttM = (G′, D) for AG′ = (G′, D), as
deﬁned above. Analogously, we use the notion AG ⊕Attv
M for translation attributes
with value v and we use the short notation Attv(AG) := AG ⊕Attv
|G|.
△
Example 7.27 (Triple graph with translation attributes). Fig. 7.15 shows the triple
graph H = (HS ←HC →HT) which is extended by some translation attributes
in the source component. The translation attributes with value “T” indicate that

7.4 Model Transformation Based on Forward Translation Rules
195
the owning elements have been translated during a model transformation sequence
using forward translation rules, which are deﬁned in Def. 7.29 hereafter. The re-
maining elements (edges S2, S4, node S3 and the attribute name of S3) in the source
component are still marked with translation attributes set to “F”. These elements
can still be matched for a continuation of the translation and may be translated at
later steps.
△
The concept of forward translation rules, which we have introduced in
[HEOG10b], extends the construction of forward rules by additional translation at-
tributes in the source component. As described in Ex. 7.27, the translation attributes
are used to keep track of the elements that have been translated so far. Since triple
rules may create new attributes for existing nodes by deﬁnition, we also have to keep
track of the translation of the attributes. The separate handling of nodes and their at-
tributes is used, e.g., in synchronisation scenarios [HEO+11a]. At the beginning,
the source model of a model transformation sequence is extended by translation
attributes that are all set to “F” and, step by step, they are set to “T” when their
containing elements are translated by a forward translation rule.
7.4.2 Execution via Forward Translation Rules
The extension of forward rules to forward translation rules integrates additional
translation attributes on the source component that keep track of the elements that
have been translated during the execution of a forward transformation.
The application conditions of a forward translation rule are derived from the
forward rule by adding translation attributes with value T to all additional elements
that are not contained in the left hand side LFT of the forward translation rule trFT.
Therefore, we introduce the construction tExt in Def. 7.28 below that extends an
application condition with additional translation attributes, which are set to the value
T. The third argument X of this construction speciﬁes the triple components that are
extended. This enables us to use this construction for several kinds of operational
translation rules in this book, such as the consistency creating rules in Def. 7.44.
Deﬁnition 7.28 (T-Extension of application conditions).
Given an application
condition ac over P, a triple graph with translation attributes P′ (extended premise
graph) and a subset of triple components X ⊆{S,C, T}, the T-extension tExt(ac, P′, X)
of ac is given by
• tExt(true, P′, X) = true,
• tExt(¬(ac′), P′, X) = ¬(tExt(ac′, P′, X)),
• tExt(ac1 ∧ac2, P′, X) = tExt(ac1, P′, X) ∧tExt(ac2, P′, X),
• tExt(ac1 ∨ac2, P′, X) = tExt(ac1, P′, X) ∨tExt(ac2, P′, X),
• tExt( ∃(a = (incP, aD): P →C, ac′), P′, X) = ∃(aE : P′ →C′, tExt(ac′,C′, X))
with C′ = P′ +P C ⊕∪x∈X(AttT
Cx\Px) and aE = (incPE, aD) given by the algebra
homomorphism aD on the data part and the inclusion incPE on the graph part
(derived from incP).
△

196
7 Model Transformation and Model Integration
:parent
S1:Class
:Class
name=n
:CT
:Table
:CT
Subclass2Table(n:String)
++
++
++
S2:parent
tr=[F)T]
S3:Class
name=n
tr=[F)T]
tr_name=[F)T]
:CT
:Table
:CT
Subclass2TableFT(n:String)
S1:Class
tr=T
S2:parent
tr=F
:CT
:Table
Subclass2TableFT(n:String)
S1:Class
tr=T
LHS
S2:parent
tr=T
S3:Class
name=n
tr=T
tr_name=T
:CT
:Table
S1:Class
tr=T
RHS
:CT
++
TGG-Triple Rule
Forward Translation Rule
Forward Translation Rule (explicit LHS and RHS)
S3:Class
name=n
tr=F
tr_name=F
)
++
++
++
++
++
Fig. 7.16 Forward translation rule Subclass2TableFT(n : String)
Deﬁnition 7.29 (Forward translation rule).
Consider a triple rule tr = (tr:
L →R, ac) with S -consistent application condition. Let trS = (trS : LS →RS ,
acS ) be the derived source rule and trF = (trF : LF →RF, acF) be the derived for-
ward rule with ac  acS ∧acF. The forward translation rule of tr is given by
trFT = (trFT : LFT ←
lFT−−KFT −
rFT
−−→RFT, acFT), deﬁned as follows:
• LFT = LF ⊕AttT
LS ⊕AttF
RS \LS ,
• KFT = LF ⊕AttT
LS ,
• RFT = RF ⊕AttT
LS ⊕AttT
RS \LS = RF ⊕AttT
RS ,
• lFT and rFT are the induced inclusions,
• acFT = tExt(ac, LFT, {S }).
Given a set of triple rules TR, we denote by TRFT the set of all trFT with tr ∈TR.
△
Remark 7.30 (Construction of application conditions). The construction of the ap-
plication condition for a forward translation rule trFT starts with the left hand side
LFT that contains translation attributes and adds additional translation attributes re-
cursively for each new element in the premise and conclusion graphs PFT and CFT.
Note that initially LFT plays the role of the ﬁrst premise PFT of a nested application
condition. Note further that (PFT +PC) is the union of PFT and C with shared P (con-
structed as a pushout) and for an S -extending application condition ac the forward
translation application condition acFT does not contain any additional translation
attributes because CS = PS for all contained morphisms a: P →C.
△
Example 7.31 (Derived forward translation rules). The rule “Subclass2TableFT” in
Fig. 7.16 is the derived forward translation rule of the triple rule “Subclass2Table”

7.4 Model Transformation Based on Forward Translation Rules
197
:Column
name=n
type=t
:cols
:AC
S1:Class
:Attribute
tr=[F)T]
name=n
tr_name=[F)T]
datatype=t
tr_datatype=[F)T]
is_primary=true
tr_is_primary=[F)T]
:attrs
tr=[F)T]
C1:
CT
T1:Table
++
++
++
PrimaryAttr2ColumnFT(n:String, t:String)
:pKey
++
:Column
:pKey
:Attribute
tr=T
is_primary=true
tr_is_primary=T
:attrs
tr=T
NAC1
NAC2
:cols
:AC
S1:Class
:Attribute
name=n
datatype=t
is_primary=true
:attrs
C1:
CT
T1:Table
++
++
:Column
name=n
type=t
PrimaryAttr2Column(n:String, t:String)
:pKey
++
:pKey
:Attribute
is_primary=true
:attrs
NAC1
TGG-Triple Rule
Forward Translation Rule
++
++
++
++
++
++
++
++
++
++
++
++
++
++
:Column
NAC2
Fig. 7.17 Forward translation rule with NACs PrimaryAttribute2ColumnFT(n : String)
in Fig. 3.8. Note that we abbreviate “tr_x” for an item (node or edge) x by “tr” and
“tr_x_a” by “tr_type(a)” in the ﬁgures to increase readability. The compact nota-
tion of forward translation rules speciﬁes the modiﬁcation of translation attributes
by “[F ⇒T]”, meaning that the attribute is matched with the value “F” and set
to “T” during the transformation step. The detailed complete notation of a forward
translation rule is shown on the right of Fig. 7.16 for “Subclass2TableFT”.
Fig. 7.17 shows the forward translation rule with NACs “PrimaryAttr2ColumnFT”
derived from the triple rule “PrimaryAttr2Column” in Fig. 3.8. According to
Def. 7.29 the source elements of the triple rule are extended by translation attributes
and changed by the rule from “F” to “T” if the owning elements are created by the
triple rule. Furthermore, the forward translation rule contains both, the source and
the target NACs of the triple rule, where the NAC only elements in the source NACs
are extended by translation attributes set to “T”. Thus, a source NAC concerns only
elements that have been translated so far.
△
Since forward translation rules are deleting attribution edges only, each NAC-
consistent match is applicable according to Fact 7.32 below, which was ﬁrst pre-
sented in [HEGO10]. Note that in the general case of deleting rules the additional
gluing condition has to be checked [EEPT06]. This ensures, in particular, that edges
do not become dangling due to the deletion of nodes.
Fact 7.32 (Gluing condition for forward translation rules). Let trFT be a forward
translation rule and mFT : LFT →G be an almost injective match; then the gluing
condition is satisﬁed, i.e., there is the transformation step G =
trFT,mFT
=====⇒H.
△

198
7 Model Transformation and Model Integration
Proof. According to Def. 9.8 in [EEPT06] we need to check that DP ∪IP ⊆GP.
First of all, by the restriction of the match, the set IP may only contain data elements
which are in GP. Furthermore, the set DP does only contain nodes. The rule is only
deleting on attribution edges, and thus DP ∪IP ⊆GP.
⊓⊔
Now, we deﬁne model transformations based on forward translation rules via al-
most injective matches in a similar way as for forward rules in Def. 7.23. We replace
the control condition source consistency of the forward sequence by requiring that
the forward translation sequence be complete.
Deﬁnition 7.33 (Complete forward translation sequence). A forward translation
sequence G0 =
tr∗
FT
==⇒Gn with almost injective matches is called complete if no further
forward translation rule is applicable and all translation attributes in Gn are set to
true (“T”).
△
Deﬁnition 7.34 (Model transformation based on forward translation rules). A
model transformation sequence (GS , G′
0 =
tr∗
FT
==⇒G′
n,GT) based on forward translation
rules TRFT consists of a source graph GS , a target graph GT, and a complete TGT
sequence G′
0 =
tr∗
FT
==⇒G′
n typed over TG′ = TG ⊕AttF
|TGS | ⊕AttT
|TGS | based on TRFT with
G′
0 = (AttF(GS ) ←∅→∅) and G′
n = (AttT(GS ) ←GC →GT).
A model transformation MT : L(TGS ) ⇛L(TGT) based on TRFT is de-
ﬁned by all model transformation sequences as above with GS ∈L(TGS ) and
GT ∈L(TGT). All the corresponding pairs (GS ,GT) deﬁne the model transfor-
mation relation MTFT,R ⊆L(TGS ) × L(TGT) based on TRFT. The model transfor-
mation is terminating if there are no inﬁnite TGT sequences via TRFT starting with
G′
0 = (AttF(GS ) ←∅→∅) for some source graph GS .
△
Example 7.35 (Model transformation via forward translation rules). Fig. 7.18 shows
the resulting triple graph with translation attributes of a forward translation se-
quence. The execution starts by taking the source model GS (see Fig. 7.13) and ex-
tending it with translation attributes according to Def. 7.34, i.e., G′
0 = (AttF(GS ) ←
∅→∅). We can execute the forward translation sequence shown in the bottom
part of Fig. 7.18 with G′
6 being the triple graph G′ in Fig. 7.18. The triple graph
G′ is indeed completely translated, because all translation attributes are set to “T”.
No further forward translation rule is applicable and we derive the resulting target
model GT by restricting G′ to its target component, i.e., GT = G′T. According to
the equivalence of the model transformation concepts based on forward and forward
translation rules in Fact 7.36 below, we can further conclude that GT can be equiv-
alently obtained via a source consistent forward transformation sequence based on
forward rules without translation attributes.
△
By Fact 7.36 below we show that the model transformation sequences based on
forward translation rules with NACs are in one-to-one correspondence with model
transformation sequences based on forward rules with NACs, i.e., based on source
consistent forward sequences. For this reason, we can equivalently use both concepts

7.4 Model Transformation Based on Forward Translation Rules
199
G'C
T6:FKey
T8:fkeys 
T14:cols
S5:Association 
tr=T
name="employee"
tr_name=T
S3:Class 
tr=T
name="Company"
tr_name=T
S7:Class 
tr=T
name="Person"
tr_name=T
S11:Class 
tr=T
name="Customer"
tr_name=T
S10:Attribute 
tr=T
name="pId"
tr-name=T
datatype="INTEGER"
tr_datatype=T
is_primary=true
tr_is_primary=T
T18:Column 
type="INTEGER"
name="pId"
T12:Table 
name="Person"
T1:Column 
type="INTEGER"
name="cId"
T7:references
C2:
CT
C6:
CT
C3:
AT
C4:
CT
C5:
AC
G'S
G' T
S1:Attribute 
tr=T
name="cId"
tr-name=T
datatype="INTEGER"
tr_datatype=T
is_primary=true
tr_is_primary=T
T10:Table 
name="employee"
T16:FKey
T4:Column 
type="INTEGER"
name="cId"
T19:Column 
type="INTEGER"
name="pId"
T5:fcols
T2:cols
T3:pkey
T17:fcols
T11:fkeys 
T15:references
C1:
AC
T13:pkey
S2:attrs
tr=T
S8:parent
tr=T
S9:attrs
tr=T
S6:dest
S4:src
tr=T
T9:Table
name="Company"
Forward translation sequence: G′
0 =
Class2TableFT
===========⇒G′
1 =
Class2TableFT
===========⇒G′
2 =
Subclass2TableFT
=============⇒
G′
3 =
PrimaryAttr2ColFT
==============⇒G′
4 =
PrimaryAttr2ColFT
==============⇒G′
5 =
Association2TableFT
================⇒G′
6 = G′.
Fig. 7.18 Triple graph instance obtained from forward translation sequence for CD2RDBM
and choose one of them depending on the particular needs. While the concept based
on source consistency shows advantages in formal proofs, the concept based on
forward translation rules shows advantages concerning analysis and eﬃciency, as
we will show in Sect. 8.2.1. It will be part of future work to extend the result to
a corresponding result that generalises from the case with NACs to the case with
general application conditions.
Fact 7.36 (Equivalence of forward transformation and forward translation se-
quences). Given a source model GS ∈L(TGS ), the sets of forward rules TRF and
corresponding forward translation rules TRFT, the following statements are equiv-
alent for almost injective matches.
1. There is a model transformation sequence (GS , G0 =
tr∗
F=⇒Gn,GT) based on TRF
with G0 = (GS ←∅→∅) and Gn = (GS ←GC →GT)

200
7 Model Transformation and Model Integration
2. There is a model transformation sequence (GS , G′
0 =
tr∗
FT
==⇒G′
n,GT) based on TRFT
with G′
0 = (AttF(GS ) ←∅→∅) and G′
n = (AttT(GS ) ←GC →GT).
Moreover, the model transformation relation MTF,R for the model transformation
based on forward rules coincides with the model transformation relation MTFT,R for
the model transformation based on forward translation rules, i.e., MTF,R = MTFT,R.
△
Proof. See Appendix B.6.2.
⊓⊔
7.5 Model Integration Based on Integration Rules
The main purpose of model integration is to establish a correspondence between var-
ious models, especially between source and target models. From the analysis point
of view, model integration supports correctness checks of syntactical dependencies
between diﬀerent views and models. This section presents model integration based
on triple graph grammars and shows the close relationship between model transfor-
mation and model integration. For each model transformation sequence there is a
unique model integration sequence, and vice versa. The main concepts and results
were ﬁrst presented in [EEH08a, EEH08b].
The general problem of model integration is constructing an integrated model
G = (GS ←GC →GT) for a given pair (GS ,GT) of source and target models. For
this purpose, two separate kinds of operational triple rules are derived from each
triple rule tr: the integration rule trI and the source–target rule trS T. These rules are
the basis for deﬁning and constructing model integration sequences from (GS ,GT)
to G. Of course, not each pair (GS ,GT) allows us to construct such a model inte-
gration sequence. In Theorem 7.41, we characterise existence and construction of
model integration sequences from (GS ,GT) to G by model transformation sequences
from GS to GT. This main result is based on the canonical decomposition result (see
Theorem 7.21) and a similar decomposition result of triple transformation sequences
into source–target and model integration sequences.
7.5.1 Model Integration Rules and Transformations
Given models GS ∈L(TGS ) and GT ∈L(TGT), the aim of model integration is
to construct an integrated model G ∈L(TGG) such that G restricted to source and
target is equal to GS and GT, respectively, i.e., projS (G) = GS and projT(G) = GT.
In analogy to model transformations, we use the operational rules derived from the
given triple rules tri: the source–target rules tri,ST and the integration rules tri,I.
Given a transformation sequence G0 =
tr∗
I=⇒Gn via integration rules with G0 =
(GS ←∅→GT), we want to make sure that the unrelated pair (GS ,GT) ∈

7.5 Model Integration Based on Integration Rules
201
Li,ST
tri,ST
/
mi,ST 
Ri,ST
=
(RS ←∅→RT )
ni,ST 
Li,I
tri,I
/
=
(RS ←LC→RT )
mi,I 
Ri,I
ni,I 
. . .
/ Gi,0
/ Gi+1,0
/
inci
5
. . .
/ Gn,i
/ Gn,i+1
/ . . .
(inci ◦ni,ST)S = mS
i,I
Fig. 7.19 Source–target consistency conditions
L(TGS )×L(TGT) is transformed into an integrated model G = Gn with projS (G) =
GS and pro jT(G) = GT. Of course, this is not possible for all pairs (GS ,GT) ∈
L(TGS ) × L(TGT), but only for speciﬁc pairs. In order to be sure that G0 =
tr∗
I=⇒Gn
integrates all parts of GS and GT, we require that ∅=
∗⇒G0 be given by ∅=
tr∗
ST
==⇒G0
based on the same triple rule sequence tr∗as G0 =
tr∗
I=⇒Gn. Moreover, the co-matches
in ∅=
tr∗
ST
==⇒G0 have to be compatible with the matches in G0 =
tr∗
I=⇒Gn. Finally, we
need to ensure that a model integration can be performed for a given pair GS ,GT if
there is at least one integrated model G = (GS ←GC →GT) ∈L(TGG) which con-
tains both models. This leads to the formal condition of source–target consistency
of transformation sequences via integration rules.
Deﬁnition 7.37 (Source–target consistency). Consider a sequence (tri)i=1,...,n of
triple rules with ST-application conditions leading to corresponding sequences
(tri,ST)i=1,...,n and (tri,I)i=1,...,n of source–target and integration rules (see Fig. 7.2
and Def. 7.12). A triple transformation sequence G0,0 =
tr∗
ST
==⇒Gn,0 =
tr∗
I=⇒Gn,n via ﬁrst
tr1,ST, . . . , trn,ST and then tr1,I, . . . , trn,I with matches mi,ST and mi,I and co-matches
ni,ST and ni,I, respectively, is match consistent if the source and target components
of the match mi,I are uniquely deﬁned by the co-match ni,ST (see Fig. 7.19).
A triple transformation Gn,0 =
tr∗
I=⇒Gn,n is called source–target consistent if there
is a match consistent sequence G0,0 =
tr∗
ST
==⇒Gn,0 =
tr∗
I=⇒Gn,n.
△
Deﬁnition 7.38 (Model integration based on integration rules).
A model in-
tegration sequence ((GS ,GT),G0 =
tr∗
I=⇒Gn,G) is given by a source graph GS , a
target graph GT, a triple graph G, and a source–target-consistent transformation
G0 =
tr∗
I=⇒Gn with G0 = (GS
∅
←−∅
∅
−→GT) and Gn = G.
A model integration MI : L(TGG)S × L(TGG)T ⇛L(TGG) is deﬁned by all
model integration sequences.
△
Deﬁnition 7.39 (Decomposition and composition for model integration).
A
TGG satisﬁes the decomposition and decomposition property for integration se-
quences if the following holds:

202
7 Model Transformation and Model Integration
G0,0
tr1,ST
+3
tr1
'/
G1,0
tr2,ST
+3
tr1,I

G2,0 . . .
tr3,ST
+3
tr1,I

Gn,0
tr1,I

G1,1
tr2,ST
+3
tr2
(0
G2,1 . . .
tr3,ST
+3
tr2,I

Gn,1
tr2,I

. . . . . .
trn,ST
+3
trn
(0
. . .
trn,I

Gn,n
Fig. 7.20 Composition and decomposition of triple sequences for model integration
1. Decomposition: For each triple transformation sequence
(1) G0 =
tr1=⇒G1 ⇒. . . =
trn=⇒Gn via rules in TR
there is a corresponding match consistent triple transformation sequence
(2) G0 = G0,0 =
tr1,ST
===⇒G1,0 ⇒. . . =
trn,ST
===⇒Gn,0 =
tr1,I
==⇒Gn,1 ⇒. . . =
trn,I
==⇒Gn,n = Gn
via rules in TRST and TRI.
2. Composition: For each match consistent triple transformation sequence (2) as
above there is a canonical triple transformation sequence (1) as above.
3. Bijective Correspondence: Composition and decomposition are inverse to each
other.
△
Theorem 7.40 (Decomposition and composition for model integration).
For
triple transformation sequences with S - and T-application conditions the decom-
position and composition property for integration sequences holds.
△
Proof. At ﬁrst, we consider only triple rules without ACs (see Fig. 7.20).
1. Decomposition: Given a TGT sequence (1) G0 =
tr1=⇒G1 ⇒. . . =
trn=⇒Gn we ﬁrst
consider the case n = 1. The TGT step G0 =
tr1=⇒G1 can be decomposed uniquely
into a match consistent TGT sequence G0 = G0,0 =
tr1,ST
===⇒G1,0 =
tr1,I
==⇒G1,1 = G1.
By Fact 7.15 we have shown that tr1 can be represented as E-concurrent rule
tr1 = tr1,ST ∗E tr1,I. Using the Concurrency Theorem, the TGT step G0 =
tr1=⇒G1
can be decomposed uniquely into an E-related sequence as given above. In this
special case, an E-relation is equivalent to the fact that the S - and T-components
of the co-match of G0,0 =
tr1,ST
===⇒G1,0 and the match of G1,0 =
tr1,I
==⇒G1,1 coincide on
the source and target components, which corresponds exactly to match consis-
tency. Using this construction for i = 1, . . . , n, the transformation sequence (1)
can be decomposed canonically into an intermediate version between (1) and (2)
called (1.5): G0 = G0,0 =
tr1,ST
===⇒G1,0 =
tr1,I
==⇒G1,1 =
tr2,ST
===⇒G2,1 =
tr2,I
==⇒G2,2 =⇒. . . =
trn,ST
===⇒
Gn,n1 =
trn,I
==⇒Gn,n where each subsequence Gi1,i1 =
tri,ST
===⇒Gi,i1 =
tri,I
==⇒Gi,i is match
consistent. Moreover, G1,0 =
tr1,I
==⇒G1,1 =
tr2,ST
===⇒G2,1 is sequentially independent, be-
cause we have a morphism d: L2,ST →G1,0, with L2,ST = (LS
2 ←∅→LT
2 )

7.5 Model Integration Based on Integration Rules
203
L1,I
R1,I
G1,0
G1,1
L2,ST
R2,ST
G2,1
tr1,I
g1
m1,I
i=n1,I
j
tr2,ST
g2
m2,ST
n2,ST
(PS
∅
PT)
(LS
2
∅
LT
2 )
GS
1,0
GC
1,0
GT
1,0
GS
1,0 =
GS
1,1
GC
1,1
GT
1,1
toST(ac′′
2 )
toST(ac2)
sG1,0
tG1,0
sG1,1
tG1,1
aS
aT
jS
jS
id
gC
1
id
pS
pT
Fig. 7.21 Constructions for showing compatibility with ST-application conditions
and d = (mS
2,ST, ∅, mT
2,ST). The morphism m2,ST : L2,ST →G1,1 is the match of
G1,1 =
tr2,ST
===⇒G2,1, because the S - and T-components of G1,0 and G1,1 are equal
according to the integration rule tr1,I. Now, the Local Church–Rosser Theo-
rem (Theorem 5.26) leads to an equivalent sequentially independent sequence
G1,0 =
tr2,ST
===⇒G2,0 =
tr1,I
==⇒G2,1 such that G0,0 =
tr1,ST
===⇒G1,0 =
tr2,ST
===⇒G2,0 =
tr1,I
==⇒G2,1 =
tr2,I
==⇒
G2,2 is match consistent. The iteration of this shift between tri,I and tr j,ST leads to
a shift-equivalent transformation sequence (2) G0 = G0,0 =
tr1,ST
===⇒G1,0 ⇒. . . =
trn,ST
===⇒
Gn,0 =
tr1,I
==⇒Gn,1 ⇒. . . =
trn,I
==⇒Gn,n = Gn, which is still match consistent.
2. Composition: Vice versa, each match consistent transformation sequence (2)
leads to a canonical sequence (1.5) by inverse shift equivalence where each sub-
sequence as above is match consistent. In fact, match consistency of (2) implies
that the corresponding subsequences are sequentially independent in order to al-
low inverse shifts in an order opposite to that in Item 1 using again the Local
Church–Rosser Theorem. Match consistent subsequences of (1.5) are E-related,
as discussed in Item 1, which allows us to apply the Concurrency Theorem to
obtain the TGT sequence (1).
3. Bijective Correspondence: The bijective correspondence of composition and de-
composition is a direct consequence of the bijective correspondence in the Local
Church–Rosser and the Concurrency Theorem, where the bijective correspon-
dence for the Local Church–Rosser Theorem is not explicitly formulated in The-
orem 5.26, but is a direct consequence of the proof in analogy to Theorem 5.30.
Now, we consider the case of triple rules with ACs. We use the facts that tri =
tri,ST ∗Ei tri,I, as shown in Prop. 7.16, and the transformations via tri,ST and tr j,I are
sequentially independent for i > j as shown above for rules without application
conditions. This result can be extended to triple rules with application conditions as
shown in the following.
It suﬃces to show that the transformations G1,0 =
tr1,I,m1
====⇒G1,1 =
tr2,ST,m2
=====⇒G2,1 are se-
quentially independent. From the sequential independence without application con-
ditions we obtain morphisms i : R1,I →G1,1 with i = n1 and j : L2,ST →G1,0 with
g1 ◦j = m2.

204
7 Model Transformation and Model Integration
It remains to show the compatibility with the application conditions (see
Fig. 7.21). We show that j |= ac2,ST. ac2,ST = toST(ac2), where ac2 is an ST-
application condition. For ac2 = true, also ac2,ST = true and therefore j |= ac2,ST.
Suppose ac2 = ∃(a, ac′′
2 ), leading to ac2,ST = ∃((aS , id∅, aT), toST(ac′′
2 )). More-
over, tr1,I is an integration rule, i.e., it does not change the source and target compo-
nents: GS
1,1 = GS
1,0 and GT
1,1 = GT
1,0.
We know that m2,ST = g1 ◦j |= ac2,S , which means that there exists p : P →G1,1
with p ◦a = g1 ◦j, p |= toST(ac′′
2 ), and pC = ∅. Then there exists q : P →G1,0
with q = (pS , ∅, pT), q ◦a = (pS ◦aS , ∅, pT ◦aT) = j, and q |= toST(ac′′
2 ) because
all objects occurring in toST(ac′′
2 ) have empty correspondence components. This
means that j |= ac2,S for this case, and can be shown recursively for composed
ac2,S .
⊓⊔
7.5.2 Model Integration as Model Transformation
From a general point of view, we want to analyse which pairs (GS ,GT) ∈L(TGS ) ×
L(TGT) can be integrated. Intuitively, these are those which are related by the
model transformation MT : L(TGS ) ⇛L(TGT) (see also Theorem 8.4). In fact,
model integration sequences can be characterised by unique model transformation
sequences.
Theorem 7.41 (Characterisation of model integration sequences). Each model
integration sequence ((GS ,GT),G0 =
tr∗
I=⇒Gn,G) corresponds uniquely to a model
transformation sequence (GS ,G′
0 =
tr∗
F
==⇒Gn,GT), where tr∗
I and tr∗
F are based on the
same rule sequence tr∗.
△
Proof. ((GS ,GT),G0 =
tr∗
I=⇒Gn,G) is a model integration sequence
⇔[def]
exists source–target consistent G0 =
tr∗
I=⇒Gn with G0 = (GS ←∅→GT)
and Gn = (GS ←GC →GT) = G
⇔[def]
∅=
tr∗
ST
==⇒G0 =
tr∗
I=⇒Gn is ST-match consistent with with G0 = (GS ←∅→
GT) and Gn = G
⇔[Theorem 7.40] exists ∅=
tr∗
=⇒Gn with Gn = (GS ←GC →GT)
⇔[Theorem 7.21] exists ∅=
tr∗
S=⇒G′
0 =
tr∗
F
==⇒Gn match consistent with Gn = (GS ←GC →
GT)
⇔[def]
exists source consistent G0 =
tr∗
F
==⇒Gn with G0 = (GS ←∅→∅) and
Gn = (GS ←GC →GT)
⇔[def]
(GS ,G0 =
tr∗
F
==⇒Gn,GT) is a model transformation sequence.
⊓⊔
Coming back to the example of a model transformation from class diagrams to
database models, we describe the relevance and value of the given theorems from
the more practical view.

7.5 Model Integration Based on Integration Rules
205
GC
T6:FKey
T8:fkeys 
T14:cols
S5:Association 
name="employee"
S3:Class 
name="Company"
S7:Class 
name="Person"
S11:Class 
name="Customer"
S10:Attribute 
name="pId"
datatype="INTEGER"
is_primary=true
T18:Column 
type="INTEGER"
name="pId"
T12:Table 
name="Person"
T1:Column 
type="INTEGER"
name="cId"
T7:references
C2:
CT
C6:
CT
C3:
AT
C4:
CT
C5:
AC
GS
GT
S1:Attribute 
name="cId"
datatype="INTEGER"
is_primary=true
T10:Table 
name="employee"
T16:FKey
T4:Column 
type="INTEGER"
name="cId"
T19:Column 
type="INTEGER"
name="pId"
T5:fcols
T2:cols
T3:pkey
T17:fcols
T11:fkeys 
T15:references
C1:
AC
T13:pkey
S2:attrs
S8:parent
S9:attrs
S6:dest
S4:src
T9:Table
name="Company"
Fig. 7.22 Model integration for CD2RDBM: result graph of integration sequence
Integration sequence:
G0
=
Class2tableI
==========⇒
G1
=
Class2tableI
==========⇒
G2
=
Subclass2TableI
============⇒
G3
=
PrimaryAttribute2ColumnI
====================⇒
G4 =
PrimaryAttribute2ColumnI
====================⇒G5 =
Association2TableI
===============⇒G6 = Gn.
Corresponding forward transformation sequence:
G0 = H0 =
Class2tableF
==========⇒H1 =
Class2tableF
==========⇒H2 =
Subclass2TableF
=============⇒H3 =
PrimaryAttribute2ColumnF
=====================⇒
H4 =
PrimaryAttribute2ColumnF
=====================⇒H5 =
Association2TableF
===============⇒H6 = G6.
Integration Sequence
Step
Matched Elements
Created Elements
1
S3, T9
C2
2
S7, T12
C4
3
S7 −S8, S11, C4, T12
C6
4
S1 −S3, C2, T1 −T3, T9
C1
5
S7, S9 −S10, C4, T12 −T14, T18
C5
6
S3 −S7, C2, C4, T1, T3 −T13, T15 −T19
C3
Step
Matched Elements
Created Elements
1
S3
C2, T9
2
S7
C4, T12
3
S7 −S8, S11, C4, T12
C6
4
S1 −S3, C2, T9
C1, T1 −T3
5
S7, S9 −S10, C4, T12
C5, T13 −T14, T18
6
S3 −S7, C2, C4, T1, T3, T9, T12 −T13, T18 C3, T4 −T8, T10 −T11, T15 −T17, T19
Fig. 7.23 CD2RDBM: integration sequence (top) and corresponding forward sequence (bottom)

206
7 Model Transformation and Model Integration
Example 7.42 (Model integration sequence). Fig. 7.22 shows the resulting triple
graph G of a model integration sequence ((GS ,GT),G0 =
tr∗
I=⇒Gn,G) via integration
rules, where G0 = (GS ←∅→GT). The upper table in Fig. 7.23 shows the cor-
responding steps with numbers for matched and created elements. According to the
numbers for the elements, the correspondence component is completely created dur-
ing the model integration sequence. The source as well as the target elements of each
match are created by the corresponding source–target rule application in ∅=
tr∗
ST
==⇒G0.
Therefore, ∅=
tr∗
ST
==⇒G0 =
tr∗
I=⇒Gn is match consistent. According to Theorem 7.41,
there is a corresponding model transformation sequence (GS ,G0 =
tr∗
F
==⇒Gn,GT) via
forward rules with G0 = (GS ←∅→∅). Thus, there is a match consistent transfor-
mation sequence ∅=
tr∗
S=⇒G′
0 =
tr∗
F
==⇒Gn. Numbers for the corresponding matched and
created elements are provided in the lower table in Fig. 7.23, where co-matches of
the source steps are given by the numbers for the source elements of the matches in
the forward transformation sequence.
△
Remark 7.43 (Model integration with translation markers). The execution of model
integrations can be performed using translation attributes in an analogous way to
that presented for model transformations in the previous section.
△
7.5.3 Consistency Checking of Integrated Models
While model transformation and model integration aim to complete missing struc-
tures of triple graphs, consisteny checking is performed to validate that a given triple
graph is consistent with respect to a given TGG. In order to perform a consistency
check, we use a further kind of operational rule—the consistency creating rules
for marking the currently consistent substructures. Technically, consistency creat-
ing rules are used to compute maximal subgraphs Gk of a given triple graph G typed
over TG, such that Gk ∈L(TGG). In the special case that G ∈L(TGG), we know
that Gk  G. Each consistency creating rule switches labels from F to T for those
elements that would be created by the corresponding TGG rule in TR. This means
that elements in the left hand side LCC = R are labelled with T if they are also con-
tained in L, and they are labelled with F otherwise. Accordingly, all elements in the
right hand side RCC are labelled with T. We extend Def. 7.29 for forward translation
rules to also deﬁne backward translation rules and consistency creating rules.
Deﬁnition 7.44 (Operational translation rules). Given a triple rule tr = (L →R)
and its derived source rule trS = (LS →RS ), target rule trT = (LT →RT), forward
rule trF = (LF →RF), and backward rule trB = (LB →RB), the derived translation
rules of tr are given by the consistency creating rule trCC = (LCC ←
lCC
−−−KCC −
rCC
−−→RCC),
the forward translation rule trFT = (LFT ←
lFT−−KFT −
rFT
−−→RFT), and the backward
translation rule trBT = (LBT ←
lBT−−KBT −
rBT
−−→RBT) deﬁned in Fig. 7.24 using the
notation based on translation attributes.

7.5 Model Integration Based on Integration Rules
207
main components
new AC for each
ac of tr
trCC
LCC
KCC
? _
lCC
o
 
rCC
/ RCC
(R ⊕AttT
L ⊕AttF
R\L)
(R ⊕AttT
L)
(R ⊕AttT
L ⊕AttT
R\L)
acCC = tExt(ac,
LCC,
{S,C, T})
trFT
LFT
KFT
? _
lFT
o
 
rFT
/ RFT
(LF ⊕AttT
LS ⊕AttF
RS \LS )
(LF ⊕AttT
LS )
(RF ⊕AttT
LS ⊕AttT
RS \LS )
acFT = tExt(ac,
LFT,
{S })
trBT
LBT
KBT
? _
lBT
o
 
rBT
/ RBT
(LB ⊕AttT
LT ⊕AttF
RT \LT )
(LB ⊕AttT
LT )
(RB ⊕AttT
LT ⊕AttT
RT \LT )
acBT = tExt(ac,
LBT,
{T})
Fig. 7.24 Components of derived operational translation rules
Moreover, the application conditions are given by acCC = tExt(ac, LCC, {S,C, T}),
acFT = tExt(ac, LFT, {S }), and acBT = tExt(ac, LBT, {T}) (see Def. 7.28).
By TRCC, TRFT, TRBT we denote the sets of all derived consistency creating,
forward translation and backward translation rules, respectively.
△
Remark 7.45 (Construction of operational rules). Note that in Fig. 7.24 (B +A C)
is the union of B and C with shared A, as explained in Rem. 7.30. For instance,
(LFT +L P) is the union of LFT and P with shared L. Recall that G ⊕AttT
M denotes
the addition of translation attributes for all the elements and attributes included in
M ⊆G to the graph G. All these attributes are set to T.
△
As with the completeness of forward translation sequences in Def. 7.33, we de-
ﬁne the execution via consistency creating sequences by Def. 7.46 below as an ex-
haustive application of the rules to the input graph and check whether the output
graph contains any element marked with F. Consistency creating sequences are
used for computing a maximal consistent part of a given triple graph. A consis-
tency creating sequence starts at a triple graph G′
0 = AttF(G), i.e., at a triple graph
where all elements are marked with F. Each application of a consistency creating
rule modiﬁes some translation attributes of an intermediate triple graph G′
i from F
to T and preserves the structural part G contained in G′
i. Therefore, the resulting
triple graph G′
n extends G with translation attributes only, i.e., some are set to T and
the remaining ones to F.
Deﬁnition 7.46 (Consistency creating sequence). Given a triple graph grammar
TGG = (TG, ∅, TR), let TRCC be the set of all consistency creating rules of TR
and let G be a triple graph G typed over TG. A consistency creating sequence s =
(G,G′
0 =
tr∗
CC
==⇒G′
n,Gn) is given by a TGT sequence G′
0 =
tr∗
CC
==⇒G′
n via TRCC with G′
0 =
AttF(G) and G′
n = G ⊕AttT
Gn ⊕AttF
G\Gn, where Gn is the subgraph of G derived from

208
7 Model Transformation and Model Integration
Fig. 7.25 Triple graph at the end of a consistency creating sequence
G′
0 =
tr∗
CC
==⇒G′
n by restricting G′
n to all T-marked elements. The consistency creating
sequence s is called terminated if there is no rule in TRCC which is applicable to
the result graph G′
n. In this case, the triple graph G′
n is called a maximal consistency
marking of G. A triple graph G′ is called completely T-marked if G′ = AttT(G) for
a given triple graph G, i.e., all translation attributes in G′ are set to “T”.
△
Example 7.47 (Consistency creating sequence). Fig. 7.25 shows the resulting triple
graph G′
n of a consistency creating sequence s = (G,G′
0 =
tr∗
CC
==⇒G′
n,Gn) via con-
sistency creating rules with G′
0 = AttF(G). No further consistency creating rule
is applicable. Some translation markers were not modiﬁed, such that the consis-
tency creating sequence is not complete. In more detail, G′
n = G ⊕AttT
Gn ⊕AttF
G\Gn,
where Gn is the subgraph of G derived from G′
0 =
tr∗
CC
==⇒G′
n by restricting G′
n to all
T-marked elements. The F-marked elements are the Association node and its ad-
jacent edges.
△
7.6 Flattening of Triple Graph Grammars
Triple graphs are a direct extension of single plain graphs, i.e., graphs consisting
of one graph component instead of three in the case of triple graphs. As shown in
the previous sections, this additional structural information provides the basis for
an elegant and formal notion of model transformations and model integrations. The
T1:Table
tr=F
name=“Company“
tr_name=T
S3:Association 
tr=F
name="employee"
tr_name=F
S1:Class 
tr=T
name=“Company“
tr_name=T
S5:Class 
tr=T
name=“Person“
tr_name=T
T8:Table 
tr=T
name=“Person“
tr_name=T
C1:CT
tr=T
C2:CT
tr=T
HS
HT
S7:Class 
tr=T
name=“Customer“
tr_name=T
HC
S4:dest
tr=F
S6:parent
tr=T
S2:src
tr=F
C3:CT
tr=T

7.6 Flattening of Triple Graph Grammars
209
natural question arises whether this additional structure can be encoded within plain
graphs. And in fact, many implementations [GHL12, SK08, LAVS12, HGN+14]
for executing model transformations based on TGGs use plain graphs, where triple
components are encoded by an additional pointer structure and mappings between
the triple components are encoded as plain edges. This reduces the eﬀorts for imple-
mentation, as existing graph transformation engines and development environments
can be reused.
This section presents a general ﬂattening construction from TGGs to plain graph
grammars that is compatible with the encoding used in many tools. The main con-
cepts and results were ﬁrst presented in [EEH08c, EEH08d]. Since morphisms be-
tween the triple components are encoded by sets of edges, the class of suitable TGGs
has to be restricted. Triple graphs may not contain edges in their correspondence
components, i.e., correspondence graphs have to be discrete graphs. As the main
result (see Theorem 7.57), we show that the encoding for model transformations
based on the restricted class of TGGs is correct and complete, i.e., the underlying
transformation sequences are in one-to-one correspondence.
Remark 7.48 (General assumption). The results for the ﬂattening construction in
this section are presented for TGGs without application conditions and where the
triple graphs do not contain edges in the correspondence component. We are quite
conﬁdent that the results can be extended to systems with application conditions,
where we refer to [MEE13, MEE12] for the ﬁrst general results in this direction
based on the general results for M-functors between M-adhesive transformation
systems.
△
Triple graphs can be interpreted as plain graphs consisting of three distinguish-
able subcomponents and edges of special type for interconnection between the com-
ponents. This idea leads to the general ﬂattening construction for triple graphs and
triple graph morphisms. Since interconnections are encoded as plain edges, there is
no possibility to encode interconnections between edges of diﬀerent components.
This means that edges in the correspondence component cannot be related to edges
in the source and target components. For this reason, the correspondence component
of a triple graph is required to contain only nodes to apply the ﬂattening construc-
tion. This condition can be generally achieved by requiring that the type graph TGC
for the correspondence component be discrete, i.e., TGC must not contain edges.
Deﬁnition 7.49 (Flattening construction).
Given a triple graph G = (GS ←
sG−−
GC −
tG−→GT), the ﬂattening F (G) of G is a plain graph deﬁned by the disjoint union
F (G) = GS + GC + GT + LinkS (G) + LinkT(G) with additional edges (links) below:
• LinkS (G) = {(x, y) | x ∈GC
V, y ∈GS
V, sG(x) = y},
• LinkT(G) = {(x, y) | x ∈GC
V, y ∈GT
V, tG(x) = y},
• sF (G)((x, y)) = x, (x, y) ∈LinkS ∪LinkT,
• tF (G)((x, y)) = y, (x, y) ∈LinkS ∪LinkT.
Given a triple graph morphism f = (f S , f C, f T) : G →G′, the ﬂattening F (f) :
F (G) →F (G′) is deﬁned by F (f) = f S + f C+ f T + fLS + fLT with fLS : LinkS (G) →

210
7 Model Transformation and Model Integration
T6:FKey
T8:fkeys 
T14:cols
S5:Association 
name="employee"
S3:Class 
name="Company"
S7:Class 
name="Person"
S11:Class 
name="Customer"
S10:Attribute 
name="pId"
datatype="INTEGER"
is_primary=true
T18:Column 
type="INTEGER"
name="pId"
T12:Table 
name="Person"
T1:Column 
type="INTEGER"
name="cId"
T7:references
C2:
CT
C6:
CT
C3:
AT
C4:
CT
C5:
AC
F(G)
S1:Attribute 
name="cId"
datatype="INTEGER"
is_primary=true
T10:Table 
name="employee"
T16:FKey
T4:Column 
type="INTEGER"
name="cId"
T19:Column 
type="INTEGER"
name="pId"
T5:fcols
T2:cols T3:pkey
T17:fcols
T11:fkeys 
T15:references
C1:
AC
T13:pkey
S2:attrs
S8:parent
S9:attrs
S6:dest
S4:src
T9:Table
name="Company"
(C1,S1)
(C2,S3)
(C3,S5)
(C4,S7)
(C5,S10)
(C1,T1)
(C2,T9)
(C3,T10)
(C4,T12)
(C5,T18)
(C6,S11)
(C6,T19)
Fig. 7.26 Flattened triple graph F (G)
LinkS (G′), fLT : LinkT(G) →LinkT(G′) deﬁned by fLS ((x, y)) = (f C(x), f S (y)) and
fLT((x, y)) = (f C(x), f T(y)).
△
Remark 7.50. Note that the ﬂattening construction does not specify mappings of
edges in GC
E. Therefore, we generally assume that GC
E = ∅by requiring that TGC
E =
∅for the type graph TG. Analogously, we require that TGC does not contain any
attribute to ensure that GC does not contain any attribute.
△
Example 7.51 (Flattening construction). The graph in Fig. 7.26 shows the plain
graph F (G) obtained by ﬂattening the triple graph G = (GS ←
sG−−GC −
tG−→GT) in
Fig. 7.13. The additional edges in LinkS (G) and LinkT(G) deﬁne the mappings sG
and tG from the correspondence component to the source and target components.
The ﬂat graph consists of the following components:
• the subgraphs GS ,GC and GT,
• the edges in LinkS (G) corresponding to the morphism GS ←
sG−−GC, deﬁned by
LinkS (G) = {(C1, S1), (C2, S3), (C3, S5), (C4, S7), (C5, S10), (C6, S11)} (where the
numbers refer to the numbered nodes in Fig. 7.26), with sF (G)((C1, S1)) =
C1, tF (G)((C1, S1)) = S1 (analogously for all other edges in LinkS (G)),
• and the edges in LinkT(G) corresponding to the morphism GC −
tG−→GT, deﬁned by
LinkT(G) = {(C1, T1), (C2, T9), (C3, T10), (C4, T12), (C5, T18), (C6, T19)}, with
sF (G)((C1, T1)) = C1, tF (G)((C1, T1)) = T1 (analogously for all other edges in
LinkT).
△

7.6 Flattening of Triple Graph Grammars
211
The ﬂattening construction induces a functor from the category of typed at-
tributed triple graphs to typed attributed graphs. The functor ensures several im-
portant properties. The functor is compatible with typing, and preserves, creates
and reﬂects pushouts and pullbacks.
Fact 7.52 (Properties of the ﬂattening construction).
1. The ﬂattening construction deﬁnes a functor F : ATrGraphs →AGraphs,
which preserves pushouts.
2. Given an attributed triple type graph TG = (TGS ←TGC →TGT) with TGC
EG =
TGC
ENA = TGC
EEA = ∅and ﬂattening F (TG), the typed ﬂattening construction
is the functor FTG : ATrGraphsTG →AGraphsF (TG) deﬁned by FTG(G, t) =
(F (G), F (t)) and FTG(f) = F (f). We sometimes write FTG = F for short.
3. The typed ﬂattening FTG is injective on objects. FTG is injective on morphisms
and creates morphisms, i.e., for all m′ : FTG(L) →FTG(G) in AGraphsF (TG)
there is a unique morphism m : L →G with FTG(m) = m′. Especially we have
FTG(A)  FTG(B) iﬀA  B.
4. FTG preserves and reﬂects pushouts, i.e., (1) pushout in ATrGraphsTG iﬀ(2)
is pushout in AGraphsF (TG), and FTG creates pushouts, i.e., given r : L →R,
m : L →G in ATrGraphsTG and pushout (3) with H, n′, f ′ in AGraphsF (TG),
there are unique G′, n, f in ATrGraphsTG, s.t. (1) is pushout in ATrGraphsTG
with FTG(G′)  H, FTG(n) = n′, and FTG(f) = f ′.
L
(1)
r
/
m 
R
n
G
f
/ G′
FTG(L)
(2)
FTG(r) /
FTG(m)

FTG(R)
FTG(n)

FTG(G)
FTG(f) / FTG(G′)
FTG(L)
(3)
FTG(r) /
FTG(m)

FTG(R)
n′

FTG(G)
f ′
/ H
5. FTG preserves, reﬂects and creates pullbacks.
△
Proof. See Appendix B.6.3.
⊓⊔
Remark 7.53 (Flattening
functor).
The
typed
ﬂattening
construction
F :
ATrGraphsTG →AGraphsF (TG) is in general not surjective and hence deﬁnes no
isomorphism or equivalence of categories ATrGraphsTG and AGraphsF (TG). There
are graphs (H, typeH) in AGraphsF (TG) which are not functional in the sense that for
TG = (TGS ←TGC →TGT) one node in HC = type−1
H (TGC) is connected in H with
zero or more than one node in HS = type−1
H (TGS ) or in HT = type−1
H (TGT). In this
case, we do not obtain graph morphisms sH : HC →HS or tH : HC →HT and hence
no triple graph (HS ←HC →HT). Moreover, in the literature [GK08, KW07],
triple graph applications exist where plain graphs are used which have multiple
edges connecting the same correspondence node to various elements of the source
and target language. This approach does not correspond to pure morphism-based
triple graphs and hence is not covered by our translation construction.
△
Using Fact 7.52 above, the ﬂattening functor can be extended to translate triple
graph grammars.

212
7 Model Transformation and Model Integration
Deﬁnition 7.54 (Translation of triple graph grammars). Given a triple graph
grammar TGG = (TG, SG, TR) with triple type graph TG, start graph SG and triple
rules tr : L →R in TrGraphsTG, the translation F (TGG) of TGG is the graph
grammar F (TGG) = (F (TG), F (SG), F (TR)) with type graph F (TG), start graph
F (SG), and rules F (TR) = {F (tr) : F (L) →F (R) | (tr : L →R) ∈TR}.
△
Theorem 7.55 (Translation and creation of triple graph transformations).
Given a triple graph grammar TGG = (TG, SG, TR) with translation F (TGG) =
(F (TG), F (SG), F (TR)), the following hold.
1. Each TGT sequence trafo: SG =
tr1,m1
====⇒G1 =⇒. . . =
trn,mn
====⇒Gn via TGG can be
translated into a ﬂattened graph transformation
F (trafo): F (SG) =
F (tr1),F (m1)
=========⇒F (G1) =⇒. . . =
F (trn),F (mn)
=========⇒F (Gn) via F (TGG).
2. Vice versa, each graph transformation sequence
trafo′ : F (SG) =
F (tr1),m′
1
======⇒G′
1 =⇒. . . =
F (trn),m′
n
======⇒G′
n via F (TGG)
creates a unique (up to isomorphism) TGT sequence
trafo: SG =
tr1,m1
====⇒G1 =⇒. . . =
trn,mn
====⇒Gn via TGG
with F (trafo) = trafo′, i.e., F (mi) = m′
i and F (Gi) = G′
i for i = 1 . . . n.
△
Proof. Using the general assumption that the TGG has no application conditions
(see Rem. 7.48); this result follows from Fact 7.52.
⊓⊔
Finally, we show that the ﬂattening functor yields a one-to-one correspondence
between the model transformation sequences via TGGs and their ﬂattened versions
for systems without application conditions (see Rem. 7.48 for this restriction).
Deﬁnition 7.56 (Translation of model transformation based on forward rules).
Given a triple graph grammar TGG = (TG, SG, TR) with model transformation
MT : L(TGS ) ⇛L(TGT), the following hold.
1. MT = (L(TG′S ), L(TG′T), TG, tS , tT, TRF) is a model model transforamtion
according to Def. 3.2 with TG′S
= (TGS
←∅→∅), TG′T
= (∅←
∅→TGT), inclusions tS = (incTGS , ∅, ∅): (TGS ←∅→∅) →TG and
tT = (∅, ∅, incTGT ): (∅←∅→TGT) →TG.
2. The translated model transformation F (MT) is a plain model transformation
deﬁned by F (MT) = (F (LS ), F (LT), F (TG), F (tS ), F (tT), F (TRF)), where
F : TrGraphsTG →GraphsF (TG) is the typed ﬂattening functor (see Def. 7.54).
3. Each graph transformation sequence trafo′ : G′
0 =
F (tr1,F),m′
1
=======⇒G′
1 =⇒. . . =
F (trn,F),m′
n
=======⇒
G′
n satisﬁes the plain control condition if G′
0 = F (G0) and the uniquely created
triple graph transformation trafo : G0 =
tr1,F,m1
=====⇒G1 =⇒. . . =
trn,F,mn
=====⇒Gn (by Theo-
rem 7.55) is source consistent.
△
Theorem 7.57 (Properties of translation). Given a triple graph grammar TGG =
(TG, SG, TR) with model transformation MT : L(TGS ) ⇛L(TGT) and the trans-
lated plain model transformation F (MT), the following hold.

7.6 Flattening of Triple Graph Grammars
213
1. There is a bijective correspondence (up to isomorphism) between model trans-
formation sequences of MT and F (MT) , and
2. F (MT) being functional is equivalent to MT being functional.
△
Proof. Given an MT model transformation sequence (GS , G1 =
tr∗
F=⇒G,GT), we ob-
tain by Def. 7.56 the F (MT) model transformation sequence (F (GS ), F (G1) =
F (tr∗
F)
====⇒
F (Gn), F (GT)), because F (tr∗
F) satisﬁes the plain control condition, t<
S (GS ) = G1
implies F (tS )<(F (GS )) = F (G1), and t<
T(Gn) = GT implies F (tT)<(F (GT)) =
F (Gn) because F preserves pullbacks by Fact 7.52. Vice versa, each F (MT) model
transformation sequence creates a unique MT model transformation sequence using
again Def. 7.56 and the fact that F creates pushouts and pullbacks by Fact 7.52.
Injectivity of F by Fact 7.52 implies that we have a bijective correspondence (up to
isomorphism) between MT and F (MT) model transformation sequences. This im-
plies that F (MT) being functional is equivalent to MT being functional.
⊓⊔

Chapter 8
Analysis of Model Transformations
Model transformations based on TGGs as presented in Chap. 7 provide an excel-
lent framework for analysing and verifying a major part of the properties that may
have to be ensured in an application scenario with regard to the ﬁrst dimension
of challenges for model transformations—the functional dimension—presented in
Sect. 3.1. The ﬁrst two sections of this chapter (Sects. 8.1 and 8.2) present powerful
analysis techniques that are based on the introduced model transformation concepts.
1. Syntactical correctness and completeness: Syntactical correctness of a transfor-
mation method means that if we can transform any source model GS into a model
GT using the method, then the model GT is a valid target model and, more-
over, the pair (GS ,GT) is consistent with respect to the speciﬁcation of the model
transformation provided by the triple graph grammar. Completeness, on the other
hand, means that for any consistent pair (GS ,GT) according to the speciﬁcation
our transformation method will be able to build GT from GS .
2. Functional and strong functional behaviour: Functional behaviour means that
for each source model GS each forward transformation starting with GS leads to
a unique valid target model GT. Strong functional behaviour means, in addition,
that also the forward transformation from GS to GT is essentially unique, i.e.,
unique up to switchings of independent transformation steps.
3. Information and complete information preservation: In case of bidirectional
model transformations, information preservation means that for each forward
transformation from GS to GT there is also a backward transformation from GT
to GS . Complete information preservation means in addition that each backward
transformation starting with GT leads to the same GS .
△
It is the main aim of this chapter to analyse under which conditions the prop-
erties deﬁned above can be guaranteed and how these conditions can be checked
with suitable tool support. Additional important properties as listed in Sect. 3.1, like
semantic correctness, are not considered in this chapter, but the interested reader is
referred to [BHE09a, HHK10].
As the ﬁrst main results, we show in Sect. 8.1 that the presented approaches
for model transformations ensure syntactical correctness and completeness (see
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_8
215

216
8 Analysis of Model Transformations
Theorem 8.4, Cor. 8.5 and Theorem 8.9). In Sect. 8.2, we show as a second group
of main results how functional behaviour of model transformations can be eﬃ-
ciently analysed (see Theorems 8.29 and 8.32) with automated tool support. There-
for, we provide a suﬃcient condition for termination (see Facts 8.13 and 8.21),
which is often satisﬁed for practical applications, and if not, it can be usually
achieved with minor eﬀorts. Moreover, we present how model transformations
based on TGGs are analysed with respect to information preservation (see Theo-
rems 8.36 and 8.39) based on the techniques developed earlier. Information preser-
vation is one aspect relevant for the bidirectional characteristics of model transfor-
mations, and thus already concerns the nonfunctional dimension of challenges. In
Sect. 8.3, we study techniques for reducing nondeterminism. This chapter is based
on [Her11, HEGO14, EEE+07, EEH08c, HHK10, GEH11].
Remark 8.1 (General assumption). The formal results in this chapter are presented
for TGGs that ensure the composition and decomposition property for forward se-
quences (Def. 7.20) and for integration sequences (Def. 7.39). Chap. 7 presents suf-
ﬁcient conditions for these properties by Theorems 7.21 and 7.40. These conditions
mainly require that the application conditions be compatible application condition
schemata with almost injective morphisms and the execution be performed via al-
most injective matches.
△
Remark 8.2 (Validity of results for equivalent concepts). The formal results in this
chapter are presented for model transformations based on forward rules. Using
the equivalence results in Chap. 7, we automatically derive corresponding results
for model transformations based on forward translation rules (Fact 7.36), ﬂattened
TGGs (Theorem 7.57), and model integrations (Theorem 7.41).
△
8.1 Syntactical Correctness and Completeness
The central challenges for model transformations are to ensure syntactical correct-
ness and completeness. As one of the main advantages over other approaches for
model transformation, we can generally ensure syntactical correctness and com-
pleteness for the presented approaches in Chap. 7 for model transformation (see
Theorems 8.4 and 8.7 and Cor. 8.5) and for model integration (see Theorem 8.9).
The main results of this section are based on [HEGO14]. Syntactical Correctness
of a model transformation based on TGGs states that each successful execution of
a model transformation starting with a valid source model GS yields a target model
GT which exactly corresponds to GS according to the language of integrated mod-
els L(TGG). Completeness means that all valid source models can be transformed.
Moreover, we do not only show that our model transformations are left total with
respect to source models, but they are also right total. This means that for each valid
target model GT there is a source model which can be transformed into GT.
In [EEE+07, EEHP09] we have proven that source consistency ensures (syn-
tactical) correctness and completeness of model transformations based on forward

8.1 Syntactical Correctness and Completeness
217
rules with respect to the language L(TGG) of integrated models. Syntactical cor-
rectness means that every model transformation sequence (GS , G0 =
tr∗
F=⇒Gn,GT) via
forward rules leads to an integrated model Gn = (GS ←GC →GT) which is
contained in L(TGG). In other words, source consistent forward transformations
generate correct model transformations, according to the class of transformations
speciﬁed by the given TGG. Completeness means that for any integrated model
G = (GS ←GC →GT) ∈L(TGG), there is a corresponding model transformation
sequence (GS , G0 =
tr∗
F=⇒G,GT). Intuitively, this means that any valid transformation
speciﬁed by a TGG can be implemented by a source consistent forward transforma-
tion.
Note that the model transformation relation MTF,R is in general not a function
from L(TGS ) to L(TGT), but we study functional behaviour in Sect. 8.2.1.
Deﬁnition 8.3 (Syntactical correctness and completeness). A model transforma-
tion MT : L(TGS ) ⇛L(TGT) based on forward rules is
• syntactically
correct
if
for
each
model
transformation
sequence
(GS ,
G0 =
tr∗
F
==⇒Gn,GT) there is G ∈L(TGG) with G = (GS ←GC →GT) imply-
ing further that GS ∈L(TGG)S and GT ∈L(TGG)T, and it is
• complete if for each GS ∈L(TGG)S there is G = (GS ←GC →GT) ∈L(TGG)
with a model transformation sequence (GS ,G0 =
tr∗
F
==⇒Gn,GT) and Gn = G. Vice
versa, for each GT ∈L(TGG)T there is G = (GS ←GC →GT) ∈L(TGG) with
a model transformation sequence (GS ,G0 =
tr∗
F
==⇒Gn,GT) and Gn = G.
△
Note that we deﬁne syntactical correctness and completeness concerning forward
model transformations. If we consider Def. 8.3 for both directions of a bidirectional
model transformation, i.e., for the forward and backward directions, we derive a
more speciﬁc deﬁnition. In that case, the conditions for correctness and complete-
ness are both required for all source and target models. The following result (based
on [HEGO14, GEH11]) shows that model transformations based on forward rules
are syntactically correct and complete.
Theorem 8.4 (Syntactical correctness and completeness). Each model transfor-
mation MT : L(TGS ) ⇛L(TGT) based on forward rules is syntactically correct
and complete.
△
Proof. 1. (Syntactical Correctness)
Given a model transformation sequence (GS ,G0 =
tr∗
F
==⇒Gn,GT), the source con-
sistency of G0 =
tr∗
F
==⇒Gn implies a match consistent sequence ∅=
tr∗
S=⇒G0 =
tr∗
F
==⇒Gn.
Using the general assumption (see Rem. 8.1) we can apply the composition part
of Def. 7.20 and have a corresponding TGT sequence ∅=
tr∗
=⇒Gn. This implies
for G = Gn that G ∈L(TGG) with G = (GS ←GC →GT), and hence also
GS ∈L(TGG)S and GT ∈L(TGG)T.

218
8 Analysis of Model Transformations
2. (Completeness)
Given GS ∈L(TGG)S , we have by deﬁnition of L(TGG)S some G = (GS ←
GC →GT) ∈L(TGG). This means that we have a TGT sequence ∅=
tr∗
=⇒G.
Using the general assumption (see Rem. 8.1) we can apply the decomposition
part of Def. 7.20 and have a match consistent sequence ∅=
tr∗
S=⇒G0 =
tr∗
F
==⇒G, which
deﬁnes a model transformation sequence (GS ,G0 =
tr∗
F
==⇒G,GT) using G = (GS ←
GC →GT). Vice versa (concerning GT ∈L(TGG)T), we use Rem. 7.22.
⊓⊔
Based on the corresponding equivalence result in Chap. 7 (see Fact 7.36), we
can directly conclude the following result (see also [Her11]), which shows that
model transformations based on forward translation rules are syntactically correct
and complete.
Corollary 8.5 (Syntactical correctness and completeness based on translation
rules). Each model transformation MT : L(TGS ) ⇛L(TGT) based on forward
translation rules is syntactically correct and complete.
△
Proof. This follows direcly from Theorem 8.4 due to Fact 7.36.
Model transformations based on forward rules are source consistent. They deﬁne
model transformations in the general notion of Def. 3.2 using source consistency as
control condition.
Example 8.6 (Model transformation based on forward rules). Consider a triple
graph grammar TGG = (TG, ∅, TR) with source rules TRS and forward rules
TRF deﬁning the triple graph languages LS = L(TGG)S and LT = L(TGG)T.
Let TR be typed over TG = (TGS
←TGC
→TGT) with tS
: (TGS
←
∅→∅) →TG and tT : (∅←∅→TGT) →TG being type graph em-
beddings and GTS = (TRF) with “source consistency” as control condition, i.e.,
G1 =
tr∗
F
==⇒Gn satisﬁes the control condition if it is source consistent. Then, the
model transformation MT : L(TGS ) ⇛L(TGT) based on forward rules is given
by MT = (L(TGS ), L(TGT), TG, tS , tT, TRF).
△
We show by Theorem 8.7 below that the general notions of correctness, totality,
surjectivity and completeness in Def. 3.2 can be guaranteed for model transforma-
tions based on forward rules. This is possible, if the source language LS coincides
with the source language L(TGG)S derived from the TGG and, vice versa, the target
language LT coincides with the target language L(TGG)T derived from the TGG.
Therefore, we require that LS = L(TGG)S and LT = L(TGG)T. This allows us
to apply the correctness and completeness results for TGGs (see Theorem 8.4) that
ensure completeness (which implies totality and surjectivity by deﬁnition) and syn-
tactical correctness concerning LS = L(TGG)S and LT = L(TGG)T.
Theorem 8.7 (General properties of model transformation based on forward
rules). Let MT : L(TGS ) ⇛L(TGT) be a model transformation in the sense of
Def. 3.2 with MT = (L(TGS ), L(TGT), TGST, tS , tT, TRF). Let forward rules TRF be

8.1 Syntactical Correctness and Completeness
219
derived from the triple graph grammar TGG, source language LS = L(TGG)S ,
and target language LT = L(TGG)T and let the consistency relation MTC be given
by MTC = {(GS ,GT) | ∃G = (GS ←GC →GT) ∈L(TGG)}. Then
• each model transformation sequence (GS , G1 =
tr∗
F=⇒Gn, GT) in the sense of
Def. 7.23 is a model transformation sequence in the sense of Def. 3.2 and vice
versa.
• Moreover, MT is syntactically correct, total, surjective and complete in the sense
of Def. 3.2.
△
Proof. Each model transformation sequence in the sense of Def. 7.23 is also one in
the sense of Def. 3.2, and vice versa, because
•
h
G0 = tS >(GS )
i
⇔
h
G0 typed over (TGS ←∅→∅) and projS (G1) = GS i
and
•
h
GT = tT<(Gn)
i
⇔
h
projT(Gn) = GTi
.
MT is syntactically correct in the sense of Def. 3.2, because Theorem 8.4 ensures
that for each source consistent G0 =
tr∗
F=⇒Gn with G0 = tS >(GS ) we have G = (GS ←
GC →GT) ∈L(TGG) with GS ∈L(TGG)S ⊆L(TGS ) and GT = tT<(Gn) ∈
L(TGG)T ⊆L(TGT), and Gn ∈L(TGG) implies (GS ,GT) ∈MTC.
MT is total, because for each GS ∈L(TGG)S we have by deﬁnition G ∈L(TGG)
with pro jS (G) = GS . G ∈L(TGG) implies ∅=
tr∗
=⇒G, and hence, by Theo-
rem 7.21, a match consistent sequence ∅=
tr∗
S=⇒G0 =
tr∗
F=⇒G. This implies a model
transformation sequence (GS , G0 =
tr∗
F=⇒G,GT) with projS (G0) = projS (G) = GS
and hence (GS ,GT) ∈MTR, which implies that MT is total. Similarly we ﬁnd, for
each GT ∈L(TGG)T, a triple graph G ∈L(TGG) with GS = projS (G) such that
(GS ,GT) ∈MTR. This shows that MT is surjective.
⊓⊔
Similarly to forward and backward model transformations based on TGGs, the
derived operation of model integration is syntactically correct and complete.
Deﬁnition 8.8 (Syntactical correctness and completeness of model integration).
A model integration MI : L(TGS ) × L(TGS ) ⇛L(TG) based on integration rules
is
• syntactically correct if for each model integration sequence ((GS ,GT),
G0 =
tr∗
I=⇒Gn,G) we have a triple graph G ∈L(TGG) with G = Gn = (GS ←
GC →GT), implying further that GS ∈L(TGG)S and GT ∈L(TGG)T, and it is
• complete if for each G = (GS ←GC →GT) ∈L(TGG) there is a model
integration sequence ((GS ,GT),G0 =
tr∗
I=⇒Gn,G) with Gn = G.
△
Theorem 8.9 (Syntactical correctness and completeness of model integration).
Each model integration MI : L(TGS ) × L(TGT) ⇛L(TG) based on integration
rules is syntactically correct and complete.
△

220
8 Analysis of Model Transformations
Proof. 1. Syntactical correctness: Given a model integration sequence ((GS ,GT),
G0 =
tr∗
I=⇒Gn,G), the source–target consistency of G0 =
tr∗
I=⇒Gn implies a match
consistent sequence ∅=
tr∗
ST
==⇒G0 =
tr∗
I=⇒Gn. Using the general assumption (see
Rem. 8.1) we can apply the composition part of Def. 7.39 and have a correspond-
ing TGT sequence ∅=
tr∗
=⇒Gn. This implies for G = Gn that G ∈L(TGG) with
G = (GS ←GC →GT), and hence also GS ∈L(TGG)S and GT ∈L(TGG)T.
2. Completeness: Given G ∈L(TGG), we have a TGT sequence ∅=
tr∗
=⇒G, and
using the general assumption (see Rem. 8.1) we can apply the decomposition
part of Def. 7.39 and have a match consistent sequence ∅=
tr∗
ST
==⇒G0 =
tr∗
I=⇒G,
which deﬁnes a model integration sequence ((GS ,GT),G0 =
tr∗
I=⇒Gn,G) using G =
(GS ←GC →GT).
⊓⊔
8.2 Functional Behaviour and Information Preservation
As shown in Sect. 8.1, we can ensure syntactical correctness and completeness for
model transformations based on forward rules and equivalently for those based
on forward translation rules using Fact 7.36. This section concentrates on the
analysis of functional behaviour and information preservation. Several formal re-
sults are available concerning termination [EEHP09, GHL10], functional behaviour
[HEOG10b, GHL10], and optimisation with respect to the eﬃciency of their exe-
cution [HEGO10, KLKS10, GHL10]. The main results of this section are based on
[HEGO14, Her11, EEE+07].
8.2.1 Functional Behaviour and Eﬃcient Execution
At ﬁrst, we consider the general notion of functional behaviour that can be applied to
arbitrary transformation systems, in particular to sets of operational rules of a TGG.
Functional behaviour of a transformation system means that a transformation system
yields unique results for the same input if the sequences are terminated. Termination
of a transformation sequence means that the construction of this sequence ends at a
graph to which no further forward translation rule is applicable.
Deﬁnition 8.10 (Functional behaviour of a transformation system). A transfor-
mation system TS = (R) with transformation rules R has functional behaviour if for
each two terminated transformation sequences G ⇒∗H1 and G ⇒∗H2 via TS and
starting at G the resulting graphs are isomorphic, i.e., H1  H2.
△
Functional behaviour of a model transformation means that each model of the
source domain-speciﬁc language (DSL) LS is transformed into a unique model of

8.2 Functional Behaviour and Information Preservation
221
the target language, where we require LS ⊆L(TGG)S in order to ensure correct-
ness and completeness by Theorem 8.4. The source DSL can form any subset of
L(TGG)S and it can be speciﬁed by the type graph TGS together with additional
well-formedness constraints. In many cases, model transformations should ensure
the crucial property of functional behaviour. Moreover, in order to ensure eﬃcient
executions of model transformations, backtracking should be reduced or eliminated,
respectively. Backtracking is necessary due to the possible choice of a suitable for-
ward rule and match used for the translation of a particular source element. There-
fore, backtracking is performed if a transformation sequence terminates and is not
completed successfully, because some parts of the source model have not been trans-
lated. In the case of FT rules, this means that an execution of MT requires backtrack-
ing if there are terminating TGT sequences (AttF(GS ) ←∅→∅) =
tr∗
FT
==⇒G′
n with
G
′S
n , AttT(GS ). As we will show by Theorems 8.29 and 8.32, functional behaviour
and elimination of backtracking are closely related topics (see [HEGO14]).
Deﬁnition 8.11 (Functional behaviour of model transformations).
Given a
source DSL LS
⊆L(TGG)S , a model transformation MT based on forward
translation rules has functional behaviour if each execution of MT starting at a
source model GS
∈LS leads to a unique (up to isomorphism) target model
GT ∈L(TGG)T.
△
K
p2,o2"*
p1,o1t|
P1
∗"*
P2
∗t|
K′
The standard way to analyse functional behaviour is to
check whether the underlying transformation system is con-
ﬂuent, i.e., all diverging derivation paths starting at the same
model ﬁnally meet again. According to Newman’s Lemma
[New42], conﬂuence can be shown by proving local conﬂu-
ence and additionally ensuring termination. More precisely, local conﬂuence means
that whenever a graph K can be transformed in one step into two graphs P1 and P2,
these graphs can be transformed into a graph K′, as shown in the diagram on the
right. Let us start with the analysis of termination.
Deﬁnition 8.12 (Termination). A system of operational translation rules TRX with
X ∈{CC, FT, BT} is terminating if each transformation sequence via TRX is ter-
minating, i.e., the sequence ends at a graph to which no further translation rule
(CC, FT, BT) is applicable.
△
For showing termination of a system of forward translation rules according to
Def. 8.12, we have the following Fact 8.13, which is a direct extension of Thm. 1 in
[HEGO10]. It provides a simple and suﬃcient condition for termination that can be
checked statically.
Fact 8.13 (Termination). Given a set of operational translation rules TRX with
X ∈{CC, FT, BT}, TRX is terminating if all input graphs are ﬁnite on the graph part
(E-graph component) and each rule modiﬁes at least one translation attribute from
F to T.
△

222
8 Analysis of Model Transformations
Proof. The input triple graphs are ﬁnite on the graph part, and thus contain ﬁnitely
many translation attributes. Each translation rule modiﬁes at least one translation
attribute from F to T. According to Def. 7.44, none of the translation rules changes
a translation attribute from T to F. Therefore, each transformation sequence stops
after ﬁnitely many steps.
⊓⊔
Local conﬂuence can be shown by checking conﬂuence of all critical pairs
(P1 ⇐= K =⇒P2) (see Sects. 2.3.5 and 5.2.4), which represent the minimal objects
where a conﬂuence conﬂict may occur. A critical pair describes a minimal conﬂict,
where minimality means that only overlappings of the rule components are consid-
ered for the graph K.
While termination of model transformations based on forward rules or forward
translation rules can be ensured quite easily by checking that all TGGtriple rules are
creating on the source component (see Fact 8.13), the conditions for local conﬂu-
ence are usually more restrictive. In fact, the system of forward translation rules of
our case study CD2RDBM terminates but is not locally conﬂuent. However, we can
show in Ex. 8.34 that the model transformation has functional behaviour. Indeed,
functional behaviour of a model transformation does not require general conﬂu-
ence of the underlying system of operational rules. Conﬂuence only needs to be
ensured for transformation paths which lead to completely translated models. More
precisely, derivation paths leading to a point for backtracking do not inﬂuence the
functional behaviour. For this reason, we introduce so-called ﬁlter NACs that extend
the model transformation rules in order to avoid misleading paths that cause back-
tracking, such that the backtracking for the extended system is reduced substantially.
By Fact 8.20 we ensure that the overall behaviour of the model transformation with
respect to the model transformation relation is still preserved. As the ﬁrst important
result we show in Theorem 8.29 that functional behaviour of a model transformation
is ensured by termination and strict conﬂuence of all signiﬁcant critical pairs of the
system of forward translation rules enriched by ﬁlter NACs, where signiﬁcant crit-
ical pairs are a subset of all critical pairs. Furthermore, we are able to characterise
strong functional behaviour of a terminating model transformation based on forward
translation rules with ﬁlter NACs in Theorem 8.32 by the condition that there is no
signiﬁcant critical pair at all. Compared with functional behaviour we additionally
ensure by strong functional behaviour that the model transformation sequences are
unique up to switch equivalence.
The addition of ﬁlter NACs therefore has two advantages. On the one hand, the
analysis of functional behaviour is improved, because the possible conﬂicts between
the transformation rules are reduced and we will show in this section that ﬁlter NACs
allow us to verify functional behaviour for our case study CD2RDBM. On the other
hand, ﬁlter NACs improve the eﬃciency of the execution by cutting oﬀpossible
backtracking paths. Filter NACs are based on the following notion of misleading
graphs, which can be seen as model fragments that are responsible for the back-
tracking of a model transformation.
Deﬁnition 8.14 (Translatable and misleading graphs). A triple graph with trans-
lation attributes G is translatable if there is a transformation sequence G =
tr∗
FT
==⇒H

8.2 Functional Behaviour and Information Preservation
223
S2:parent
tr=F
S3:Class
tr=F
name=n
tr_name=F
S1:Class
S3:Class
tr=T
name=n
tr_name=T
S1:Class
:CT
)!
S2:parent
tr=F
:Table
name=n
G1
G2
Fig. 8.1 Step G1 =
Class2TableFT
=========⇒G2 with misleading graph G2
LHS
RHS
NAC
:CT
:Table
S1:Class
tr=T
name=n
tr_name=T
S1:Class
tr=F
name=n
tr_name=F
S1:Class
tr=F
name=n
tr_name=F
:parent
tr=F
)
:Class
Fig. 8.2 A forward translation rule with ﬁlter NAC: Class2TableFN
via forward translation rules such that H is completely translated (see Def. 7.33). A
triple graph with translation attributes G is misleading if for every triple graph G′
with translation attributes that contains G (G′ ⊇G) we have that G′ not translat-
able.
△
Example 8.15 (Misleading graph). Consider the transformation step shown in
Fig. 8.1. The resulting graph G2 is misleading according to Def. 8.14, because the
edge S2 is labelled with a translation attribute set to F, but there is no rule which may
change this attribute in any bigger context at any later stage of the transformation.
The only rule which allows one to change the translation attribute of a parent-
edge is Subclass2TableFT, but it requires that the source node S3 be labelled with
a translation attribute set to F. However, forward translation rules do not modify
translation attributes from T to F, and moreover they do not change the structure of
the source component.
△
Deﬁnition 8.16 (Filter NAC). A ﬁlter NAC n for a forward translation rule trFT :
LFT ←KFT →RFT is given by a morphism n : LFT →N, such that there is a TGT
step N =
trFT,n
===⇒M with M being misleading. The extension of trFT by some set of
ﬁlter NACs is called forward translation rule trFN with ﬁlter NACs.
△
Example 8.17 (Forward translation rule with ﬁlter NACs). The rule Class2TableFT
is extended by a ﬁlter NAC in Fig. 8.2, which is obtained from the graph G1 of
the transformation step G1 =
Class2TableFT
=========⇒G2 in Fig. 8.1, where G2 is misleading
according to Ex. 8.15.
△

224
8 Analysis of Model Transformations
A direct construction of ﬁlter NACs according to Def. 8.16 would be ineﬃcient,
because the size of the considered graphs to be checked is unbounded. For this
reason we use eﬃcient techniques as presented in [HEGO14, HEOG10b], which
support the generation of ﬁlter NACs and allow us to bound the size without losing
generality. At ﬁrst we present an automated technique for a subset of ﬁlter NACs
and thereafter an interactive generation technique leading to a much larger set of
ﬁlter NACs. The ﬁrst procedure in Fact 8.18 below is based on a suﬃcient criterion
for checking the misleading property. Concerning our example, this automated gen-
eration leads to the ﬁlter NAC shown in Fig. 8.2 for the rule Class2TableFT for an
incoming edge of type “parent”.
Fact 8.18 (Automated generation of ﬁlter NACs). Given a triple graph grammar,
the following procedure applied to each triple rule tr ∈TR generates ﬁlter NACs
for the derived forward translation rules TRFT leading to forward translation rules
TRFN with ﬁlter NACs:
• Outgoing Edges: Check whether the following properties hold
– tr creates a node (x : Tx) in the source component and the type graph allows
outgoing edges of type “ Te” for nodes of type “ Tx”, but tr does not create
an edge (e : Te) with source node x.
– Each rule in TR which creates an edge (e : Te) also creates its source node.
– Extend LFT to N by adding an outgoing edge (e : Te) at x together with
a target node. Add a translation attribute for e with value F. The inclusion
n : LFT →N is a NAC-consistent match for tr.
For each node x of tr fulﬁlling the above conditions, the ﬁlter NAC (n : LFT →N)
is generated for trFT, leading to trFN.
• Incoming Edges: Dual case, this time for an incoming edge (e : Te).
• TRFN is the extension of TRFT by all ﬁlter NACs constructed above.
△
Proof. Consider a generated NAC (n : LFT →N) for a node x in tr with an outgoing
edge e in N \ L. A transformation step N =
trFT,n
===⇒M exists according to Fact 7.32 and
leads to a graph M, where the edge e is still labelled with a translation attribute set
to “F”, but x is labelled with “T”, because it is matched by the rule. Now, consider
a graph H′ ⊇M, such that H′ is a graph with translation attributes over a graph
without translation attributes H, i.e., H′ = H ⊕AttH0 for H0 ⊆H′, meaning that
H′ has at most one translation attribute for each element in H without translation
attributes.
In order to have M misleading (Def. 8.14), it remains to show that H′ is not
translatable. Forward translation rules only modify translation attributes from “F”
to “T”; they do not increase the number of translation attributes of a graph and
no structural element is deleted. Thus, each graph Hi in a TGT sequence H′ =
tr∗
FT
==⇒
Hn will contain the edge e labelled with “F”, because the rules, which modify the
translation attribute of e, are not applicable due to x being labelled with “T” in each
graph Hi in the sequence, and there is only one translation attribute for x in H′.
Thus, each Hn is not completely translated, and therefore M is misleading. This

8.2 Functional Behaviour and Information Preservation
225
means that (n : LFT →N) is a ﬁlter NAC of trFT. Dualising the proof leads to the
result for a generated NAC w.r.t. an incoming edge.
⊓⊔
The following interactive technique for deriving ﬁlter NACs was presented
in [HEGO14, HEOG10b] and is based on the generation of critical pairs, which
deﬁne conﬂicts of rule applications in a minimal context. By the completeness of
critical pairs (Theorem 5.41) we know that for each pair of two parallel dependent
transformation steps there is a critical pair which can be embedded. If a critical
pair P1 ⇐
tr1,FT
==== K =
tr2,FT
===⇒P2 contains a misleading graph P1, we use the overlapping
graph K as a ﬁlter NAC of the rule tr1,FT. However, checking the misleading prop-
erty needs manual interaction. But in some cases, these manual results of identiﬁed
misleading graphs can be reused for more general static conditions. Indeed, the con-
ditions used in Fact 8.18 were inspired by ﬁrst applying the interactive method to
our case study. Moreover, we are currently working on a technique that uses a suﬃ-
cient criterion to check the misleading property automatically, and we are conﬁdent
that this approach will provide a powerful generation technique.
Fact 8.19 (Interactive generation of ﬁlter NACs). Given a set of forward transla-
tion rules, we generate the set of critical pairs P1 ⇐
tr1,FT,m1
====== K =
tr2,FT,m2
=====⇒P2. If P1 (or
similarly P2) is misleading, we generate a new ﬁlter NAC m1 : L1,FT →K for tr1,FT
leading to tr1,FN, such that K =
tr1,FN,m1
======⇒P1 violates the ﬁlter NAC. Hence, the critical
pair for tr1,FT and tr2,FT is no longer a critical pair for tr1,FN and tr2,FT. But this
construction may lead to new critical pairs for the forward translation rules with
ﬁlter NACs. The procedure is repeated until no further ﬁlter NAC can be found or
validated. This construction, starting with TRFT, always terminates if the structural
part of each graph of a rule is ﬁnite.
△
Proof. The constructed NACs are ﬁlter NACs, because the transformation step
K =
tr1,FT,m1
=====⇒P1 contains the misleading graph P1. The procedure terminates, because
the critical pairs are bounded by the number of possible pairwise overlappings of
the left hand sides of the rules. The number of overlappings can be bounded by con-
sidering only constants and variables as possible attribute values.
⊓⊔
Based on the ﬂattening construction presented in Sect. 7.6 we derive an equiva-
lent plain graph transformation system from the system of forward translation rules.
Since the system of forward translation rules ensures source consistency for com-
plete transformation sequences by construction, the derived ﬂattened grammar also
ensures source consistency for complete transformation sequences. For this reason,
we do not need to extend the analysis techniques for critical pairs and can use the
critical pair analysis engine of AGG [AGG14].
Concerning our case study CD2RDBM, the interactive generation terminates af-
ter the second round, which is typical for practical applications, because the number
of already translated elements in the new occurring critical pairs usually decreases.
Furthermore, several NACs can be combined if they diﬀer only on some translation
attributes.

226
8 Analysis of Model Transformations
According to Fact 8.20 below, ﬁlter NACs do not change the behaviour of model
transformations as presented in [HEGO14, Her11]. The only eﬀect is that they ﬁlter
out derivation paths which would lead to misleading graphs, i.e., to backtracking for
the computation of the model transformation sequence. This means that the ﬁlter
NACs ﬁlter out backtracking paths.
Fact 8.20 (Equivalence of transformations with ﬁlter NACs).
Given a triple
graph grammar TGG = (TG, ∅, TR) with forward translation rules TRFT and ﬁl-
ter NACs leading to TRFN, let G0 = (GS ←∅→∅) be a triple graph typed over
TG and G′
0 = (AttF(GS ) ←∅→∅); then the following statements are equivalent
for almost injective matches:
1. There is a complete TGT sequence G′
0 =
tr∗
FT,m∗
FT
=====⇒G′ via TRFT.
2. There is a complete TGT sequence G′
0 =
tr∗
FN,m∗
FT
======⇒G′ via TRFN.
△
Proof. Sequence 1 consists of the same transformation diagrams as Sequence 2.
NAC consistency of sequence 2 implies NAC consistency of sequence 1, because
each step in Sequence 2 involves a superset of the NACs for the corresponding step
in Sequence 1. For the inverse direction, consider a step Gi−1 =
tr(i,FT),m(i,FT)
========⇒Gi, which
leads to the step Gi−1 =
tr(i,FN),m(i,FT)
========⇒Gi if NACs are not considered. Assume that mFT
does not satisfy some NAC of trFN. This implies that a ﬁlter NAC (n : Li,FT →N)
is not fulﬁlled, because all other NACs are fulﬁlled by NAC consistency of Se-
quence 1. Thus, there is a triple morphism q : N →Gi−1 with q ◦n = mi,FT. By
Thm. 6.18 (Restriction Thm.) in [EEPT06] we have that the transformation step
Gi−1 =
tr(i,FN),m(i,FT)
========⇒Gi can be restricted to N =
tr(i,FT),n
=====⇒H with embedding H →Gi. By
Def. 8.16 of ﬁlter NACs we know that N =
tr(i,FT),n
=====⇒H and H is misleading, which
implies by Def. 8.14 that Gi is not translatable. This is a contradiction to the com-
pletely translated graph Gn in sequence 1, and therefore the ﬁlter NAC is fulﬁlled,
leading to NAC consistency of sequence 2.
⊓⊔
The equivalence above implies that we can check termination of a model trans-
formation based on forward translation rules with ﬁlter NACs by checking that it is
terminating without ﬁlter NACs.
Fact 8.21 (Termination with ﬁlter NACs). Given TRFN and TRFT as in Fact 8.20,
TRFN is terminating if TRFT is terminating.
△
Proof. Since TRFT is terminating, we know that all transformation sequences via
TRFT terminate. Since TRFN ⊆TRFT by construction, we automatically derive that
the transformation sequences via TRFN are a subset of the ones via TRFT. Hence, all
transformation sequences via TRFN terminate.
⊓⊔
In order to analyse functional behaviour we generate the critical pairs for the sys-
tem of forward translation rules and show by Theorem 8.29 that strict conﬂuence of
“signiﬁcant” critical pairs ensures functional behaviour. A critical pair is signiﬁcant
if it can be embedded into two transformation sequences via forward translation

8.2 Functional Behaviour and Information Preservation
227
Fig. 8.3 Unreachable patterns U1 and U2
rules that start at the same source model GS , which belongs to the source domain-
speciﬁc language LS . This implies that a critical pair containing a misleading graph
automatically is not signiﬁcant. For this reason, some of the nonsigniﬁcant critical
pairs can be eliminated with the presented automatic and interactive techniques for
generating ﬁlter NACs in Facts 8.18 and 8.19.
Deﬁnition 8.22 (Signiﬁcant critical pair). A critical pair (P1 ⇐
tr1,FN
==== K =
tr2,FN
===⇒P2)
for a set of forward translation rules with ﬁlter NACs TRFN is called signiﬁcant if it
can be embedded into a parallel dependent pair (G′
1 ⇐
tr1,FN
==== G′ =
tr2,FN
===⇒G′
2) such that
there is GS ∈LS ⊆L(TGG)S and G′
0 =
tr∗
FN
==⇒G′ with G′
0 = (AttF(GS ) ←∅→∅).
G′
1
G′
0
tr∗
FN
+3 G′
tr2,FN
)1
tr1,FN
-5
G′
2
△
The pragmatic solution for analysing critical pairs would be to start generating
critical pairs and inspect overlapping graphs of some pairs. If we detect that an over-
lapping graph already contains an unreachable pattern, we can conclude that this
critical pair is not signiﬁcant, because it cannot be embedded in a forward trans-
lation sequence. Intuitively, an unreachable pattern cannot be reached by applying
forward translation rules to a valid initial graph of a forward translation. Note that
the notion of unreachable patterns is more restrictive than the notion of misleading
graphs.
Deﬁnition 8.23 (Unreachable pattern). A graph U is called unreachable pattern
if there is no forward translation sequence G′
0 =⇒∗G with G′
0
S = AttF(GS ) and
GS ∈L(TGG)S such that there is an M-morphism u: U →G (i.e., such that U is
contained in G).
△
Example 8.24 (Unreachable patterns). The graph U1 in Fig. 8.3 contains a Class
node with two primary Attribute nodes. This pattern cannot occur in a valid
source model GS ∈L(TGG)S , because the rule PrimaryAttr2Column is the only
S3:Attribute
is_primary=true
S1:Class
S2:attrs
U1
S5:Attribute
is_primary=true
S4:attrs
C1:
CT
T1:Table
C2:
CT
U2
S3:Attribute
is_primary=true
S1:Class
S2:attrs
S6:Attribute
is_primary=true
S5:attrs
S4:Class

228
8 Analysis of Model Transformations
rule that creates primary Attribute nodes, and its source NAC prohibits the cre-
ation of a second one for the same Class node. Therefore, graph U1 is unreachable:
it cannot be embedded in a forward translation sequence starting with a consistent
source model as required otherwise, because forward translation rules only modify
translation attributes on the source component.
The graph U2 in Fig. 8.3 contains two classes with each containing a primary
attribute, and both Class nodes are connected to the same table. We show that U2
is unreachable by contraposition. Assume that U2 is not unreachable, i.e., there is
a transformation sequence via forward translation rules G′ =⇒∗H′ such that G′S =
AttF(GS ), GS ∈L(TGG)S and H′ contains U2. Therefore, at least one of the Class
nodes was connected to the table via the rule Subclass2TableFT. This means as
well that both classes are within the same class hierarchy in GS . Now, we explain
why this leads to a contradiction. The condition GS ∈L(TGG)S means that the
source model GS belongs to a consistent integrated triple graph G (i.e., G = (GS ←
GC →GT) ∈L(TGG)). Thus, G is constructed by applying the triple rules of TGG.
In order to create the two attribute nodes with is_primary = true, we have to
apply the rule PrimaryAttr2Column twice using the same Table node, because
the classes belong to the same hierarchy. This would mean that each of the two
steps would create a primary key for that table. Thus, the second step would not
be possible due to the target NAC of the rule. Therefore, the graph G cannot be
constructed via the triple rules, and thus G < L(TGG). This is a contradiction, and
therefore U2 is an unreachable pattern.
△
Based on the notion of unreachable graphs, we deﬁne negative constraints, which
we call ﬁlter constraints (Def. 8.25), because they are used to ﬁlter out nonsigniﬁcant
critical pairs. They forbid the presence of unreachable patterns. As we will see for
our example, ﬁlter constraints are only used for the generation of critical pairs, but
can reduce the number of ﬁlter NACs required for showing functional behaviour.
The reason for this is that the conditions for a graph to be an unreachable pattern
and to be misleading partially overlap in a semantic way.
Deﬁnition 8.25 (Filter constraint). A ﬁlter constraint is given by a negative con-
straint c = ¬ ∃(p: ∅→U, true), where U is an unreachable pattern. We call c a
strict ﬁlter constraint if for all transformation steps G =
trFT
==⇒H via a forward trans-
lation rule trFT, where U is embedded into H via an M-morphism u: U →H, we
can conclude that also G is unreachable.
△
Remark 8.26 (Relationship between ﬁlter constraints and ﬁlter NACs). Filter con-
straints are related to ﬁlter NACs, but none of them is a special case of the other.
First of all, a ﬁlter NAC ¬( ∃n: L →N, true) is a condition over L for a speciﬁc
triple rule tr = (L →R), while a ﬁlter constraint c = ¬ ∃(p: ∅→U, true) is
a condition over the initial object ∅. This means that the ﬁlter NAC concerns the
applicability of a single rule, while a ﬁlter constraint is independent from the triple
rules. Secondly, a ﬁlter constraint contains an unreachable pattern U (see Defs. 8.23
and 8.25), while a ﬁlter NAC contains a graph N that can be transformed into a
misleading graph M (see Defs. 8.14 and 8.16). If we consider the system without

8.2 Functional Behaviour and Information Preservation
229
c1 = ¬ ∃(∅: ∅→U1, true)
c2 = ¬ ∃(∅: ∅→U2, true)
Fig. 8.4 Filter constraints based on graphs U1 and U2 from Fig. 8.3
ﬁlter NACs, we know that the unreachable patterns will not occur in any partial
model translation sequence, but it might be that misleading graphs occur. Note that
some misleading graphs can be unreachable patterns, e.g., one can combine a mis-
leading graph with an unreachable pattern and obtain a new graph that is then both,
unreachable and misleading. Vice versa, each unreachable pattern is misleading by
deﬁnition, because there in no valid sequence in which it can be embedded.
Practically, a NAC with an unreachable pattern would have no eﬀect as unreach-
able patterns never occur in valid sequences anyhow. On the other hand, a con-
straint with a misleading graph could be deﬁned. However, it could be transformed
into NACs, which usually improves eﬃciency as the condition checks are reduced.
Thus, unreachable patterns are appropriate for constraints and misleading graphs
are a suitable notion for obtaining relevant NACs. Concerning the analysis of crit-
ical pairs, a ﬁlter constraint generally reduces the number of critical overlapping
graphs, while a ﬁler NAC concerns only the overlapping graphs that are relevant for
the speciﬁc rule.
△
Example 8.27 (Filter constraint). Consider the two constraints in Fig. 8.4. They are
ﬁlter constraints, because they are based on the graphs U1 and U2, which are un-
reachable patters as shown in Ex. 8.24.
△
Using the concept of ﬁlter constraints, we show that they can be used as global
constraints when generating critical pairs. They will ensure that all the nonsigniﬁ-
cant critical pairs that contain the speciﬁed negative pattern will already be ﬁltered
out during the generation process.
Lemma 8.28 (Filtering of critical pairs). Given a ﬁlter constraint c = ¬ ∃(p: ∅→
U, true), all graphs (K, P1, P2) of signiﬁcant critical pairs (P1 ⇐= K =⇒P2) satisfy c,
i.e., K |= c ∧P1 |= c ∧P2 |= c.
△
Proof. Let c = ¬ ∃(p: ∅→U, true) be a ﬁlter constraint; then U is unreachable.
Let c′ = ∃(p: ∅→U, true), i.e., leaving out the negation, and let (P1 ⇐= K =⇒
P2) be a critical pair. Assume that one of the graphs K, P1 or P2 does not satisfy
c, i.e., X |= c′ with X ∈{K, P1, P2}. This implies that there is an M-morphism
x: U →X. By Def. 8.23 (unreachable pattern), we can conclude that there is no
forward translation sequence G′
0 ⇒∗G with G′
0
S = AttF(GS ) and GS ∈L(TGG)S .
Therefore, we can conclude by Def. 8.22 that the critical pair is not signiﬁcant. This
is a contradiction, and we can conclude that the assumption is wrong. Therefore, all
graphs of the critical pair satisfy c.
⊓⊔

230
8 Analysis of Model Transformations
Using the notion of signiﬁcant critical pairs, we can provide our ﬁrst main result
of this section on functional behaviour as presented in [HEGO14, HEOG10b]. It
states that a model transformation has functional behaviour and does not require
backtracking, if the signiﬁcant critical pairs are strictly conﬂuent.
Theorem 8.29 (Functional behaviour).
Let MTFT be a model transformation
based on forward translation rules TRFT with model transformation relation MTFT,R
and source DSL LS . Furthermore, let TRFN extend TRFT with ﬁlter NACs such that
TRFN is terminating and all signiﬁcant critical pairs are strictly conﬂuent. Then,
MTFT has functional behaviour. Moreover, the model transformation MTFN based
on TRFN does not require backtracking and MTFN deﬁnes the same model transfor-
mation relation, i.e., MTFN,R = MTFT,R.
△
Proof. For functional behaviour of the model transformation we have to show that
each source model GS ∈LS is transformed into a unique (up to isomorphism) com-
pletely translated target model GT, which means that there is a completely translated
triple model G′ with G′T = GT, and furthermore GT ∈L(TGG)T.
For GS
∈LS
⊆L(TGG)S we have by deﬁnition of L(TGG) that there
is a GT
∈L(TGG)T and a TGT sequence ∅=
tr∗
=⇒(GS
←GC →GT) via
TR. Using the decomposition theorem with NACs, we obtain a match consis-
tent TGT sequence ∅=
tr∗
S=⇒
(GS
←∅→∅) =
tr∗
F
==⇒
(GS
←GC
→GT)
by general assumption (Rem. 8.1), and by Fact 7.36 a complete TGT sequence
G′
0 = (AttF(GS ) ←∅→∅) =
tr∗
FT
==⇒(AttT(GS ) ←GC →GT) = G′. This
means that (GS ,G′
0 =
tr∗
FT
==⇒G′,GT) is a model transformation sequence based on
TRFT. Assume that we also have a complete forward translation sequence G′
0 =
(AttF(GS ) ←∅→∅) =
tr∗
FT
==⇒(AttT(GS ) ←GC →GT) = G
′. By Fact 8.20 we also
have the complete TGT sequences G′
0 =
tr∗
FN
==⇒G′ and G′
0 =
tr∗
FN
==⇒G
′. Using the precon-
dition that TRFN is terminating and all signiﬁcant critical pairs are strictly conﬂuent,
we show that all diverging transformation sequences can be merged again. Consider
the possible transformation sequences starting at G′
0 (which form a graph of trans-
formation steps) and two diverging steps (G′
i+1 ⇐
p1,m1
==== G′
i =
p2,m2
===⇒G′′
i+1). If they are
parallel independent, we can apply the local Church–Rosser theorem (LCR), The-
orem 5.26, and derive the merging steps (G′
i+1 =
p2,m′
2
===⇒H ⇐
p1,m′
1
==== G′′
i+1). If they are
parallel dependent diverging steps, we know by completeness of critical pairs (The-
orem 5.41) that there is a critical pair, and by Def. 8.22 we know that this pair is
signiﬁcant, because we consider transformations sequences starting at G′
0. This pair
is strictly conﬂuent by precondition. Therefore, these steps can be merged again.
Now, any new diverging situation can be merged by either LCR for parallel inde-
pendent steps or by strict conﬂuence of critical pairs for parallel dependent steps. By
precondition the system is terminating. In combination, this implies that G′  G
′,
and hence GT  G
T.
Backtracking is not required, because the termination of TRFN with strict con-
ﬂuence of signiﬁcant critical pairs implies unique normal forms as shown above.

8.2 Functional Behaviour and Information Preservation
231
Therefore, any terminating TGT sequence (AttF(GS ) ←∅→∅) =
tr∗
FN
==⇒G′
n leads to
a unique G′
n up to isomorphism, and by correctness and completeness (Theorem 8.4
and Fact 7.36) we have that G′S
n = AttT(GS ).
The model transformation relation is the same, because we have the equivalence
of the model transformation sequences (Fact 8.20).
⊓⊔
If the set of generated critical pairs of a system of forward translation rules with
ﬁlter NACs TRFN is empty, we can directly conclude from Theorem 8.29 that the
corresponding system TRFT without ﬁlter NACs has functional behaviour. More-
over, from an eﬃciency point of view, the set of rules should be compact in order
to minimise the eﬀort for pattern matching. In the optimal case, the rule set ensures
that each transformation sequence of the model transformation is itself unique up to
switch equivalence, meaning that it is unique up to the order of sequentially indepen-
dent steps. For this reason, we introduce the notion of strong functional behaviour
with respect to a given source domain-speciﬁc language LS .
Deﬁnition 8.30 (Strong functional behaviour of model transformations).
A
model transformation based on forward translation rules TRFN with ﬁlter NACs
and the source DSL LS ⊆L(TGG)S has strong functional behaviour if for each
GS
∈LS there is a GT
∈L(TGG)T and a model transformation sequence
(GS ,G′
0 =
tr∗
FN
==⇒G′
n,GT) based on forward translation rules, and moreover,
• any partial TGT sequence G′
0 =
tri,∗
FN
==⇒G′
i terminates, i.e., there are ﬁnitely many
extended sequences G′
0 =
tri,∗
FN
==⇒G′
i =
tr j,∗
FN
==⇒G′
j, and
• each two TGT sequences G′
0 =
tr∗
FN
==⇒G′
n and G′
0 =
tr∗
FN
==⇒G
′
m with completely trans-
lated graphs G′
n and G
′
m are switch-equivalent up to isomorphism.
△
Remark 8.31 (Strong functional behaviour).
1. The sequences being terminating means that no rule in TRFN is applicable any-
more. However, it is not required that the sequences be complete, i.e., that G′
n
and G
′
m are completely translated.
2. Strong functional behaviour implies functional behaviour, because G′
n and G
′
m
completely translated implies that G′
0 =
tr∗
FN
==⇒G′
n and G′
0 =
tr∗
FN
==⇒G
′
m are terminating
TGT sequences.
△
The second main result of this section shows that strong functional behaviour of
model transformations based on forward translation rules with ﬁlter NACs can be
completely characterised by the absence of signiﬁcant critical pairs, as presented
in [HEGO14, HEOG10b].
Theorem 8.32 (Strong functional behaviour). A model transformation based on
terminating forward translation rules TRFN with ﬁlter NACs has strong functional
behaviour and does not require backtracking, leading to polynomial time complexity
if and only if TRFN has no signiﬁcant critical pair.
△

232
8 Analysis of Model Transformations
Proof. Direction “⇐”: Assume that TRFN has no signiﬁcant critical pair. As in
the proof of Theorem 8.29 we obtain for each GS ∈LS a GT ∈L(TGG)T and
a complete TGT sequence G′
0 =
tr∗
FT
==⇒G′ and a model transformation (GS ,G′
0 =
tr∗
FT
==⇒
G′,GT) based on TRFT underlying TRFN. By Fact 8.20 we also have a complete TGT
sequence G′
0 =
tr∗
FN
==⇒G′, and hence also a model transformation (GS ,G′
0 =
tr∗
FT
==⇒G′,GT)
based on TRFT underlying TRFN. In order to show strong functional behaviour let
G′
0 =
tr∗
FN
==⇒G′
n and G′
0 =
tr∗
FN
==⇒G
′
m be two terminating TGT sequences with m, n ≥1.
We have to show that they are switch-equivalent up to isomorphism. We show by
induction on the combined length n + m that both sequences can be extended to
switch-equivalent sequences.
For n + m = 2 we have n = m = 1 with t1 : G′
0 =
trFN,m
====⇒G′
1 and t1 : G′
0 =
trFN,m
====⇒G
′
1.
If trFN = trFN and m = m, then both are isomorphic with isomorphism i : G
′
1 −
∼→
G′
1, such that t1 ≈i ◦t1. If not, then t1 and t1 are parallel independent, because
otherwise we would have a signiﬁcant critical pair by completeness of critical pairs
in Theorem 5.41. By the local Church–Rosser theorem, Theorem 5.26, we have
t2 : G′
1 =
trFN
==⇒G′
2 and t2 : G
′
1 =
trFN
==⇒G′
2, such that t2 ◦t1 ≈t2 ◦t1 : G′
0 =⇒∗G′
2.
Now assume that for t1 : G′
0 =⇒∗G′
n−1 and t1 : G′
0 =⇒∗G
′
m we have extensions
t2 : G′
n−1 =⇒∗H, t2 : G
′
m =⇒∗H, such that t2 ◦t1 ≈t2 ◦t1.
G′
0
t1 +3∗
t1 
∗
G′
n−1
t
+3
t2
 ∗
G′
n
t3
 ∗
G
′
m
t2
+3∗H
t3
+3∗K
For a step t : G′
n−1 =⇒G′
n we have to show that t ◦t1 and t1 can be extended to
switch-equivalent sequences. By induction hypothesis and deﬁnition of signiﬁcant
critical pairs also t and t2 can be extended by t3 : G′
n =⇒∗K, t3 : H =⇒∗K, such
that t3 ◦t ≈t3 ◦t2. Now, the composition closure of switch equivalence implies
t3 ◦t ◦t1 ≈t3 ◦t2 ◦t1 : G′
0 =⇒∗K. This completes the induction proof.
Now, we use that G′
n and G
′
m are both terminal, which implies that t3 and t3 ◦t2
must be isomorphisms. This shows that G′
0 =
tr∗
FN
==⇒G′
n and G′
0 =
tr∗
FN
==⇒G
′
m are switch-
equivalent up to isomorphism.
Direction “⇒”:Assume now that TRFN has strong functional behaviour and that
TRFN has a signiﬁcant critical pair. We have to show a contradiction in this case.
Let P1 ⇐
tr1,FN
==== K =
tr2,FN
===⇒P2 be the signiﬁcant critical pair which can be embedded
into a parallel dependent pair G1 ⇐
tr1,FN
==== G′ =
tr2,FN
===⇒G2, such that there is GS ∈LS
with G′
0 =
tr∗
FN
==⇒G′ and G′
0 = (AttF(GS ) ←∅→∅). Since TRFN is terminating we
have terminating sequences G1 =⇒∗G1n and G2 =⇒∗G2m via TRFN. By composition
we have the following terminating TGT sequences:
1. G′
0 =
trFN
==⇒G′ =
tr1,FN
===⇒G1 =⇒∗G1n and
2. G′
0 =
trFN
==⇒G′ =
tr2,FN
===⇒G2 =⇒∗G2m.

8.2 Functional Behaviour and Information Preservation
233
Since TRFN has strong functional behaviour both are switch-equivalent up to iso-
morphism. For simplicity assume G1n = G2m instead of G1n  G2m. This implies
n = m and that G′ =
tr1,FN
===⇒G1 =⇒∗G1n is switch-equivalent to G′ =
tr2,FN
===⇒G2 =⇒∗G1n.
This means that tr2,FN occurs in G1 =⇒∗G1n and can be shifted in G′ =
tr1,FN
===⇒G1 =⇒∗
G1n, such that we obtain G′ =
tr2,FN
===⇒G2 =⇒∗G1n.
But this implies that in an intermediate step we can apply the parallel rule tr1,FN +
tr2,FN, leading to parallel independence of G′ =
tr1,FN
===⇒G1 and G′ =
tr2,FN
===⇒G2, which is
a contradiction. Hence, TRFN has no signiﬁcant critical pair.
It remains to show that strong functional behaviour implies that backtracking is
not required. This is a direct consequence of Theorem 8.29, since we do not have
any signiﬁcant critical pair, and therefore all of them are strictly conﬂuent.
⊓⊔
Remark 8.33 (Analysis with AGG via ﬂattening). We use the tool AGG to analyse
critical pairs and dependencies of plain graph transformation rules. In order to anal-
yse the operational rules of a TGG, we therefore apply the ﬂattening construction
(see Def. 7.49) and derive the plain graph transformation rules. By the equivalence
result for the ﬂattening construction (see Theorem 7.55), we know that there is a
one-to-one correspondence between transformation sequences in each of the sys-
tems. Therefore, functional behaviour of one of the systems implies functional be-
haviour of the other. This means that the analysis in AGG based on the ﬂattened
rules is sound and complete with respect to the system of triple rules.
△
Example 8.34 (Functional and strong functional behaviour). We analyse functional
behaviour of the model transformation CD2RDBM. By Fact 8.21, CD2RDBM is ter-
minating, because all TGGrules are creating in the source component. For analysing
local conﬂuence we use the tool AGG [AGG14] (version 2.07, see Rem. 8.33) for
the generation of critical pairs. The set of derived forward translation rules from the
rules TR in Fig. 3.8 is given by TRFT = { Class2TableFT, Subclass2TableFT,
Attr2ColumnFT, PrimaryAttr2ColumnFT, Association2TableFT }. We per-
form the following steps.
1. We obtain the initial table of critical pairs as shown in Fig. 8.5. In order to prevent
a memory overﬂow, we set a limit for the the maximum number of generated
critical pairs per rule pair and conﬂict kind to 200. This limit becomes eﬀective
for the pair (5, 5), which shows that there are 200 or more critical pairs for this
rule pair. In the next steps, we apply reduction techniques and do not reach this
limit anymore.
2. Now, we use the concept of ﬁlter constraints to ﬁler out nonsigniﬁcant critical
pairs by setting the multiplicity (maximum values only) constraints depicted in
Fig. 11.9. We can do this, because the multiplicity constraints are ensured by the
triple rules as well as by the source rules, the forward rules and the forward trans-
lation rules. Formally, the multiplicity constraints correspond to ﬁlter constraints,
which contain unreachable patterns that violate the maximum multiplicity con-
straints. As a result of this step, we obtain the table in Fig. 8.6.

234
8 Analysis of Model Transformations
Fig. 8.5 Table of critical pairs—initial table for the TGG Class2Table
Fig. 8.6 Table of critical pairs after setting the multiplicity constraints
Fig. 8.7 Table of critical pairs without pairs of identical rules and matches

8.2 Functional Behaviour and Information Preservation
235
S2:parent
tr=F
S3:Class
tr=F
name=n
tr_name=F
:CT
:Table
S1:Class
tr=T
S3:Class
tr=T
name=n
tr_name=T
:CT
:Table
S1:Class
tr=T
:CT
:Table
S2:parent
tr=F
K
P2
S3:Class
tr=T
name=n
tr_name=T
:CT
:Table
S1:Class
tr=T
:CT
S2:parent
tr=T
P1
!
Subclass2TableFT
Class2TableFT
Fig. 8.8 Critical pair for the rules Subclass2TableFT and Class2TableFT
Fig. 8.9 Table of critical pairs—after inserting the ﬁlter NAC for rule 2
Fig. 8.10 Table of critical pairs after inserting the ﬁlter constraints

236
8 Analysis of Model Transformations
3. Some of the critical pairs are pairs with identical rules and matches (diagonal
line). These pairs are directly strictly conﬂuent, because P1  P2. We activate the
corresponding AGG CPA option to omit the pairs of identical rules and matches
and derive the table in Fig. 8.7.
4. The critical pair of the rule pair (SubClass2TableFT, Class2TableFT) is shown
in Fig. 8.8. This critical pair describes the conﬂict that the rule Class2TableFT
is about to translate a Class node that has a parent node. This conﬂict can
by solved by the ﬁlter NAC discussed in Ex. 8.17 and shown in Fig. 8.2. We
exchange the forward translation rule Class2TableFT with the extended rule
with ﬁlter NACs Class2TableFN from Fig. 8.2, which we would also obtain by
the automated generation according to Fact 8.18. This leads to the table shown
in Fig. 8.9.
5. The remaining two critical pairs contain unreachable patterns in the overlapping
graphs. They specify conﬂicts of the rule PrimaryAttr2Column with itself. The
corresponding overlapping graphs K of the critical pairs contain two primary
attribute nodes, which belong in one case to one Class and in the other case
to two Classes that are connected to the same Table. The two unreachable
patterns in Fig. 8.3 can be embedded into the overlapping graphs. All of the
overlapping graphs of the two critical pairs are unreachable. We use the two ﬁlter
constraints in Fig. 8.4 based on the two unreachable patterns observed in the
previous step to ﬁlter out the nonsigniﬁcant critical pairs. The resulting table of
critical pairs is shown in Fig. 8.10 and no longer contains any critical pair.
Thus, we can apply Theorem 8.32 and derive that the model transformation
based on the forward translation rules with ﬁlter NACs TRFN has strong functional
behaviour and does not require backtracking. Furthermore, by Theorem 8.29 we
can conclude that the model transformation based on the forward translation rules
TRFT without ﬁlter NACs has functional behaviour. As an example, Fig. 7.18 shows
the resulting triple graph of a model transformation starting with the class diagram
GS .
△
8.2.2 Information Preservation
Model transformations are information preserving if for any forward transformation
sequence there is a corresponding backward transformation sequence yielding the
initial source model. If a model transformation is not complete, this directly implies
that it is not information preserving. This has a practical impact. In fact, several TGG
tools do not support backtracking, such that they cannot ensure completeness. This
implies that the execution of backward transformations may stop without creating a
valid source model for some target models [GHL10, SK08, KLKS10]. This section
provides results for analysing and ensuring information preservation for TGG model
transformations according to Chap. 7 in general. In addition to that, we provide
results for the stricter notion of complete information preservation. These results
hold even if tools do not perform backtracking.

8.2 Functional Behaviour and Information Preservation
237
In this section, we analyse whether and how a source model can be reconstructed
from the computed target model as presented in [HEGO14, EEE+07, Her11]. For
this purpose, we distinguish between forward and backward model transformations.
Interestingly, it turns out that complete information preservation is ensured by func-
tional behaviour of the backward model transformation. We present the techniques
for model transformations based on forward rules. According to the equivalence
result in Fact 7.36, we also know that these techniques provide the same results
for model transformations based on forward translation rules. Moreover, due to the
symmetric deﬁnition of TGGs, the results can be applied dually for backward model
transformations.
Deﬁnition 8.35 (Information preserving model transformation).
A forward
model transformation based on forward rules is information preserving, if for each
forward model transformation sequence (GS ,G0 =
tr∗
F
==⇒Gn,GT) there is a backward
model transformation sequence (GT,G′
0 =
tr
′∗
B
==⇒G′
m,G′S ) with GS = G′S , i.e., the
source model GS can be reconstructed from the resulting target model GT via a
target consistent backward transformation sequence.
△
By Theorem 8.36 we show that model transformations based on forward rules
are information preserving as presented in [EEE+07, HEGO14].
Theorem 8.36 (Information preserving model transformation). Each forward
model transformation based on forward rules is information preserving.
△
Proof. Given a set of triple rules TR with derived forward rules TRF and backward
rules TRB. By Theorem 7.21 and Rem. 7.22 applied to the source consistent forward
sequence G0 =
tr∗
F=⇒Gn via TRF we derive the target consistent backward transforma-
tion G′
0 = (GT ←∅→∅) =
tr∗
B=⇒Gn via TRB with GS
n = GS . This means that we have
a backward model transformation sequence (GT,G′
0 =
tr∗
B=⇒Gn,G′S ) with GS = G′S .
⊓⊔
Example 8.37 (Information preserving model transformation CD2RDBM). The
model transformation CD2RDBM is information preserving, because it consists of
model transformation sequences based on forward rules, which ensure source con-
sistency of the forward sequences by deﬁnition. Therefore, the presented source
model GS of the triple graph in Fig. 7.18 can be reconstructed by a target consistent
backward transformation sequence starting at the model G′
0 = (∅←∅→GT).
But there are several possible target consistent backward transformation sequences
starting at G′
0. The reason is that the rule Subclass2TableB can be applied arbitrar-
ily often without having an inﬂuence concerning the target consistency, because the
rule is identical on the target component. This means that the inheritance informa-
tion within a class diagram has no explicit counterpart within a relational database
model.

238
8 Analysis of Model Transformations
T1:Table
 name="Company"
S1:Class 
name="Company"
S5:Class 
name="Person"
T8:Table 
name="Person"
C1:
CT
C3:
CT
G’S
GT
T1:Table
 name="Company"
S1:Class 
name="Company"
S5:Class 
name="Person"
S7:Class 
name="otherName"
T8:Table 
name="Person"
C1:
CT
C4:
CT
C3:
CT
GS
GT
T1:Table
 name="Company"
T8:Table 
name="Person"
GT
Triple Graph G’
Triple Graph G
S6:parent
Fig. 8.11 Two possible target consistent backward transformations
There are many possible target consistent backward transformation sequences
for the same derived target model GT where two of them are presented in Fig. 8.11.
The source model GS can be transformed into G = (GS ←GC →GT). But starting
with GT, both depicted backward transformation sequences are possible and target
consistent. The resulting source graphs GS and G′S , however, diﬀer with respect to
the class node S 7 and the edge S 6 in GS . Hence, some information of GS cannot be
reconstructed uniquely and therefore, is partially lost in the target model GT.
△
According to Theorem 8.36 each model transformation based on forward rules
is information preserving. But the reconstruction of a corresponding source model
from a derived target model is in general not unique. In order to ensure uniqueness of
the reconstruction we now present the notion of complete information preservation.
This stronger notion ensures that all information contained in a source model of a
source domain-speciﬁc language (DSL) can be reconstructed from the derived target
model itself. More precisely, starting with the target model, each backward model
transformation sequence will produce the original source model. This ensures that
only one backward model transformation sequence has to be constructed. Intuitively,
this means that the model transformation is invertible.
Deﬁnition 8.38 (Complete information preservation). A forward model transfor-
mation with source DSL LS is completely information preserving if it is information
preserving, and furthermore, given a source model GS ∈LS and the resulting tar-
get model GT of a forward model transformation sequence, each partial backward
transformation sequence starting with GT terminates and produces the given source
model GS as result.
△
We can verify complete information preservation by showing functional be-
haviour of the corresponding backward model transformation with respect to the de-
rived target models L′
T ⊆MT(LS ) ⊆L(TGG)T as presented in [Her11, HEGO14].

8.3 Reduction of Nondeterminism
239
Theorem 8.39 (Completely information preserving model transformation).
Given a forward model transformation MT, it is completely information preserv-
ing if the corresponding backward model transformation according to Rem. 7.22
has functional behaviour with respect to the target language L′T = MT(LS ).
△
Proof. By Theorem 8.36 we know that MT is information preserving. For a model
transformation sequence (GS ,G0 =
tr∗
F=⇒Gn,GT), we additionally know that GT ∈
L(TGG)T by Theorem 8.4, and furthermore, that GT ∈L′T = MT(LS ). Using
the functional behaviour of the corresponding backward model transformation ac-
cording to Def. 8.11 for the language L′T we know that for each model HT the
backward model transformation yields a unique HS ∈L(TGG)S . Therefore, each
backward model transformation sequence (GT,G′
0 =
tr∗
B=⇒G′
n,G′S ) leads to a unique
G′S ∈L(TGG)S . Furthermore, there is a backward model transformation sequence
(GT,G′′0 =
tr∗
B=⇒G′′n,GS ) by Theorem 8.36, implying GS  G′S , i.e., the model trans-
formation is completely information preserving.
⊓⊔
Example 8.40 (Complete information preservation). The model transformation
MT1 = CD2RDBM is not completely information preserving. Consider, e.g., the
source model GS in Fig. 8.11 of Ex. 8.37, where two backward model transforma-
tion sequences are possible starting with the same derived target model GT. This
means that the backward model transformation has no functional behaviour with
respect to MT1(LS ) = MT(L(TGG)S ) = L(TGG)T = LT.
However, we can also consider the inverse model transformation, i.e., swap-
ping the forward and backward direction, leading to the model transformation
MT2 = RDBM2CD from relational database models to class diagrams. In this case,
the model transformation is completely information preserving, meaning that each
relational database model MDB can be transformed into a class diagram MCD, and
each database model MDB can be completely and uniquely reconstructed from its de-
rived class diagram MCD. In other words, each class diagram resulting from a model
transformation sequence of RDBM2CD contains all information that was present in
the given database model. According to Ex. 8.34 we know that the model transfor-
mation CD2RDBM has functional behaviour, and hence the backward model trans-
formation of RDBM2CD has functional behaviour with respect to L(TGG)T being
equal to the source language L(TGG)S of CD2RDBM. For this reason, we can ap-
ply Theorem 8.39, and have that RDBM2CD is completely information preserving.
In particular, foreign keys are completely represented by associations, and primary
keys by primary attributes. There is no structure within the database model which is
not explicitly represented within the class diagram.
△
8.3 Reduction of Nondeterminism
Transformation systems in general cannot ensure deterministic behaviour. Nonde-
terminism is caused by the choice of the transformation rule and its match at each

240
8 Analysis of Model Transformations
Fig. 8.12 Additional TGG rule for showing the eﬀect of conservative policies
step during a transformation. The general concept for reducing nondeterminism is to
analyse functional behaviour based on critical pairs as presented in Sect. 8.2 before
and reﬁne the rule set using ﬁlter NACs. This section presents two further practi-
cal concepts for reducing nondeterminism while ensuring completeness. The ﬁrst
one is using policies for transformation rules and the second one is restricting the
operational rules to an eﬀective subset called kernel translation rules.
Example 8.41 (Additional rule with nondeterminism). Consider the triple rule (6)
Association2ForeignKey in Fig. 8.12, which we can use as an additional rule for
the TGG CD2RDBM to handle 1 −n associations in the class diagram via foreign
keys in the source table in the database model. The rule contains an attribute compu-
tation in the target component: the value of name is derived by combining the name
of the association an and the name of the primary key of the destination Column. We
now consider the corresponding backward rule (6B) Association2ForeignKeyB.
In order to apply the rule, the matching process of a transformation engine has to
ﬁnd assignments for all variables, i.e., for an and cn. The match for the nodes on
the left hand side of the rule (black part without ++) provides enough information
to assign the variable cn, but for the variable an we need to ﬁnd a value solving
the constraint that (an+ "_"+cn) is equal to the name of node T4. In general, there
can be several solutions if the character "_" occurs several times in the string ex-
pression. An eﬃcient approach would be to assign an to the substring from the
S1:Class
:src
S2:Class
:dest
:FKey
T2:Table
:cols
:fkeys
:references
T3:pkey
C1
:CT
:AFK
C2
:CT
++
++
++
++
++
++
:fcols
:Association
name = an
:Column
type=t
name=an+"_"+cn
(6) Association2ForeignKey(an:String, cn:String)
++
T4:Column 
type = t
name = cn
:Column
:pKey
NAC1
++
++
T1:Table
++
++
++
++
++
++
S1:Class
:src
S2:Class
:dest
T5:FKey
T8:Table
T3:cols
T2:fkeys
T7:references
T9:pkey
C1
:CT
:AFK
C2
:CT
++
++
T6:fcols
:Association
name = an
T4:Column
type=t
name=an+"_"+cn
(6B) Association2ForeignKeyB(an:String, cn:String)
++
T10:Column 
type = t
name = cn
:Column
:pKey
NAC1
++
T1:Table
++
++

8.3 Reduction of Nondeterminism
241
beginning until the ﬁrst occurrence of "_". But this would neglect further potential
choices. However, this is enough if we are only interested in obtaining one solu-
tion, as long as the backward transformation for the possible target models can be
completed.
△
In order to reduce nondeterminism for attribute assignments, we present the con-
cept of policies. The main idea of a policy for an operational rule is to restrict the
matches using additional attribute conditions in order to eliminate ambiguous re-
sults. Attribute conditions are given by equations over attribute values, i.e., they
require that some expressions be evaluated equally. In our case study, we use one
attribute condition (see Ex. 8.44).
A policy can be arbitrarily restrictive in general. However, if a policy is too re-
strictive, the model transformation may no longer be complete. Thus, we need to
ensure that the model transformation can still be executed successfully for all valid
inputs. For this reason, we introduce the notion of a conservative policy. In the case
of forward transformations, a policy for the set of forward translation rules is con-
servative if all valid source models can be translated. This ensures that the model
transformation is still complete.
Deﬁnition 8.42 (Policy for operational translation rules). An attribute condition
attCon for a (triple) rule tr : L →R is a set of equations for attribute values.
A match m : L →G satisﬁes attCon—written m |= attCon—if the evaluation
of attribute values satisﬁes each equation. Given a TGG, let TRFT be the derived
set of forward translation rules. A policy pol : TRFT →TR′
FT for restricting the
applications of the rules in TRFT maps each rule trFT ∈TRFT to an extended rule
tr′
FT ∈TR′
FT, where tr′
FT is given by trFT extended by a set of additional attribute
conditions AttCpol(trFT). The policy pol is called conservative if the derived model
transformation relation MT′
FT,R ⊆L(TGG)S × L(TGG)T based on TR′
FT is left total
and is contained in the model transformation relation MTFT,R derived from TRFT,
i.e., MT′
FT,R ⊆MTFT,R.
A policy for backward translation rules TRBT is deﬁned analogously by replac-
ing FT with BT and it is conservative if the derived model transformation relation
MT′
BT,R ⊆L(TGG)T × L(TGG)S is left total and contained in MTBT,R.
△
In order to automatically check that a policy is conservative we provide a suﬃ-
cient condition by Fact 8.43 below based on the analysis of dependencies between
rules [EEPT06]. Intuitively, two transformation steps G0 =
p1,m1
===⇒G1 =
p2,m2
===⇒G2 are
sequentially independent if (1) there is no use–delete dependency (the ﬁrst step uses
(creates or reads) an element (node, edge, or attribute) that is deleted by p2 in the
second step) and (2) there is no forbid–produce dependency. A produce–forbid de-
pendency occurs if the ﬁrst step forbids a pattern by a negative application condition
of p1 and the second step produces some elements of it, such that applying the sec-
ond step ﬁrst will disable the execution of the ﬁrst step thereafter.
A policy restricts the applicability of rules. The main challenge is to ensure that
the restrictions are not too strict. In more detail, for each valid input model of an
operational transformation sequence we have to ensure that there is an equivalent

242
8 Analysis of Model Transformations
transformation sequence respecting all restrictions of the policy. The key idea is
to check for each restriction of a rule p whether there are rules that could depend
on the execution of p. If we can show that there is no dependency on all possible
subsequent steps in an operational transformation sequence, we can conclude that
all steps via p can be shifted to the end of the sequence. This allows us to focus on p
itself. As stated by Fact 8.43 below, it is then suﬃcient to show that for each match
of p there is an equivalent match satisfying the conservative policy.
Fact 8.43 (Conservative policy). Let pol : TRFT →TR′
FT be a policy, such that for
each rule tr′
FT = pol(trFT) in TR′
FT with tr : L →R the following conditions hold.
1. Given a match m : L →G for trFT, there is also a match m′ : L →G for tr′
FT
satisfying AttCpol(trFT).
2. If AttCpol(trFT) , ∅, then for each rule tr2 ∈TRFT with trFT , tr2 the pair
(trFT, tr2) is sequentially independent.
Then, the policy pol is conservative (cf. Def. 8.42). A similar fact holds for a policy
pol : TRBT →TR′
BT concerning backward translation rules.
△
Proof (Idea). According to Def. 8.42, the policy pol is conservative if the derived
model transformation relation MT′
FT,R is left total. The model transformation rela-
tion MTR based on TRFT is left total due to the completeness result for TGG model
transformations based on forward translation rules (cf. Theorem 8.4). Thus, given a
source model GS ∈L(TGG)S , there is a complete forward translation sequence sFT
via TRFT. We have to show that there is also a complete forward translation sequence
s′
FT via TR′
FT. First of all, MT′
FT,R ⊆MTFT,R, because the additional attribute con-
ditions only restrict the possible transformation sequences and no additional ones
are possible. Item (1) in Fact 8.43 ensures that for each step si,FT in sFT via TRFT,
there is a step s′
i,FT via TR′
FT, but this step may diﬀer on the resulting triple graph.
However, item (2) ensures that there is no subsequent step in sFT via a diﬀerent rule
that is sequentially dependent on neither si,FT nor s′
i,FT. Therefore, we can iteratively
exchange the original steps with corresponding ones via TR′
FT, shift them to the end
of the the sequence, and continue with the next step that is not via TR′
FT. Finally, we
derive a complete forward translation sequence s′
FT via TR′
FT. For the full proof see
Fact 7 in [HEO+11b].
⊓⊔
Example 8.44 (Nonconservative policy). Fig. 8.13 shows the backward translation
rule (6BT) and its extension (6BT′) with a policy. The policy is an attribute condi-
tion concerning the variable an. It ensures that the match for the nodes will fully
determine the values for all variables. For each match of rule (6BT), there is a match
for rule 6BT′, because the condition requires that an be equal to a term. This term
uses string functions substr and pos, which have to be left total relations in or-
der to be algebra operations. Therefore, the policy satisﬁes the ﬁrst condition of
Def. 8.42. However, it does not satisfy the second condition. Since the rule translates
nodes of type Column, there are possible dependencies on rules that use a node of
type Column as context node. This is the case for the rule Association2TableBT.

8.3 Reduction of Nondeterminism
243
Fig. 8.13 Backward translation rule (6BT) without and rule (6BT ′) with policy
:Class
:src
:Class
:dest
:Table
tr=T
:cols
tr=[F)T]
:fkeys
tr=[F)T]
:references
tr=[F)T]
:pkey
tr=T
:CT
:AFK
:CT
++
++
:fcols
tr=[F)T]
:Association
name = an
:Column
tr=[F)T]
type=t
tr_type=[F)T]
name=fN
tr_name=[F)T]
(6BT’) Association2ForeignKeyBT,2()
++
:Column 
tr=T
type = t
tr_type=T
name = cn
tr_name=T
:Column
tr=T
:pKey
tr=T
NAC1
++
++
++
:Fkey
tr=[F)T]
:Table
tr=T
:Class
:src
:Class
:dest
:Table
tr=T
:cols
tr=[F)T]
:fkeys
tr=[F)T]
:references
tr=[F)T]
:pkey
tr=T
:CT
:AFK
:CT
++
++
:fcols
tr=[F)T]
:Association
name = an
:Column
tr=[F)T]
type=t
tr_type=[F)T]
name=an+"_"+cn
tr_name=[F)T]
(6BT) Association2ForeignKeyBT(an:String, cn:String)
++
:Column 
tr=T
type = t
tr_type=T
name = cn
tr_name=T
:Column
tr=T
:pKey
tr=T
NAC1
++
++
++
:Fkey
tr=[F)T]
:Table
tr=T
policy:
an=substr(fn,0,pos("_",fn)-1)

244
8 Analysis of Model Transformations
Therefore, the policy is not conservative if we consider all rules of CD2RDBM. If
we would drop the rule Association2TableBT, then the policy would be conserva-
tive, because the second condition of Def. 8.42 would be satisﬁed in that case. Note
that we will use a conservative policy explicitly for optimising a TGG for model
synchronisation in Ex. 9.21 in Chap. 9.
△
In order to ensure termination of the sets of operational rules using Fact 8.13, we
restrict the sets to those that modify at least one translation attribute. For this pur-
pose, we distinguish between several subsets of the triple rules of a TGG depending
on their eﬀects concerning the creation of elements in the triple components.
Deﬁnition 8.45 (Creating and identic triple rules). Let TR be a set of triple rules.
We distinguish between the following subsets:
• the set of creating rules TR+ = {tr ∈TR | tr , id},
• the set of source creating rules TR+s = {tr ∈TR | trS , id},
• the set of source identic rules TR1s = {tr ∈TR | trS = id},
• the set of target creating rules TR+t = {tr ∈TR | trT , id},
• the set of target identic rules TR1t = {tr ∈TR | trT = id}, and
• the set of identic rules TR1 = {tr ∈TR | tr = id}.
△
Based on the diﬀerent kinds of creating rules, we derive the eﬀective operational
rules that ensure termination. We call these rules kernel translation rules. In the
case of forward translation rules, the kernel forward translation rules TR+s
FT ⊆TRFT
are those forward translation rules that are derived from the source creating triple
rules TR+s ⊆TR of the triple rules TR. The remaining forward translation rules
TR1s
FT = TRFT \ TR+s
FT are those derived from the source identic triple rules TR1s.
Vice versa, the kernel backward translation rules TR+t
BT ⊆TRBT are the backward
translation rules that are derived from the target creating triple rules TR+t ⊆TR, and
TR1t
BT are the remaining backward translation rules derived from the target identic
triple rules. Finally, the kernel consistency creating triple rules TR+
CC ⊆TRCC are
those consistency creating rules that are derived from the creating triple rules TR+ =
{(tr: L →R) ∈TR | L , R}.
Deﬁnition 8.46 (Kernel translation rules). Let TR be a set of triple rules. We
distinguish between the following sets of rules:
• the set of kernel consistency creating rules TR+
CC = {trCC ∈TRCC | tr ∈TR+},
• the set of kernel forward translation rules TR+s
FT = {trFT ∈TRFT | tr ∈TR+s}, and
• the set of kernel backward translation rules TR+t
BT = {trBT ∈TRBT | tr ∈TR+t}.
△
The notion of kernel translation rules automatically ensures termination accord-
ing to Lem. 8.47 below. We generally assume that the input models are ﬁnite on the
structure part, i.e., the carrier sets of the data values can be inﬁnite, but the graph
nodes and all sets of edges are ﬁnite.

8.3 Reduction of Nondeterminism
245
Lemma 8.47 (Termination of rules with conservative policies). Let TGG =
(TG, ∅, TR) be a triple graph grammar. Let further TR+
CC, TR+s
FT, and TR+t
BT be the
derived sets of operational translation rules for consistency creating, forward trans-
lation, and backward translation, respectively, according to Def. 7.44 and possibly
extended by some policies. Then, the transformation systems TR+
CC, TR+s
FT, and TR+t
BT
are terminating for any input triple graph that is ﬁnite on the graph part.
△
Proof. This is a direct consequence of Fact 8.13, because each rule of the sets
TR+
CC, TR+s
FT, and TR+t
BT changes at least one translation attribute.
⊓⊔
The restriction of the set of operational rules to those that change the marking
can cause the model transformation not to be complete anymore. Thus, it cannot
be ensured anymore that for an arbitrary valid input model there is a valid oper-
ational transformation sequence via forward or backward translation rules, respec-
tively. However, we can use the same idea as for conservative policies and check that
the remaining rules do not depend on the omitted ones (TR1s
FT and TR1t
BT), as stated
by Rem. 8.48 below. The main idea is the following. If we can show that none of
the remaining triple rules depends on the source identic triple rules, we can actually
omit the source identic ones. The reason is that for each forward transformation se-
quence, we can shift the steps along source identic rules to the end and obtain an
equivalent sequence. Since all steps along source identic triple rules do not change
the marking of the source model, we further derive that these steps can be removed,
yielding still a complete forward translation sequence. This ensures that the rules
that do not change any translation attribute can be omitted while still all valid input
models can be processed successfully.
Remark 8.48 (Shifting of independent steps). Consider two sets P1 and P2 of rules
such that each pair (p1, p2) ∈P1 × P2 is sequentially independent. Then, there is a
transformation sequence (G =
r∗
=⇒H) via (P1 ∪P2) if and only if there are transforma-
tion sequences s1 = (G =
p∗
=⇒G1) via P2 and s2 = (G1 =
q∗
=⇒H) via P1 with the same
G1. This result is shown by Fact 3 in App. A.2 in [HEO+11b].
△
Based on the result on shifting independent steps, we introduce the notion of
kernel-grounded operational translation rules and show thereafter that this property
allows us to restrict the sets of rules appropriately, such that termination and com-
pleteness are ensured.
Deﬁnition 8.49 (Kernel-grounded and deterministic sets of operational trans-
lation rules).
Let TGG = (TG, ∅, TR) be a triple graph grammar from which
we obtain the operational translation rules TRCC, TRFT, and TRBT. They are called
kernel-grounded if the pairs (TR1s
FT, TR+s
FT) and (TR1t
BT, TR+t
BT) are sequentially inde-
pendent. This means that there is no pair (p1, p2) of sequentially dependent rules
with either (p1, p2) ∈(TR1s
FT × TR+s
FT) or (p1, p2) ∈(TR1t
BT × TR+t
BT).
The sets of operational translation rules TRCC, TRFT, and TRBT (possibly ex-
tended by conservative policies) are called deterministic if they have functional be-
haviour and do not require backtracking.
△

246
8 Analysis of Model Transformations
Example 8.50 ((Non-)kernel-grounded operational rules and determinism). The op-
erational rules of the TGG CD2RDBM are not kernel-grounded, because some back-
ward translation rules depend on the target-identic backward translation rule (2BT)
SubClass2TableBT. For instance, rule (3BT) Attr2ColumnBT depends on it: (2BT)
SubClass2TableBT creates a C2T node and (3BT) Attr2ColumnBT uses a C2T node
as context node. If we consider a very restricted TGG CD2RDBM2, which uses the
rule set TR = { Class2Table, Attr2Column }, then we obtain sets of operational
translation rules that are kernel grounded and deterministic. By Fact 9.24 in Chap. 9,
we show that the operational rules for the TGG of our case study on model synchro-
nisation are indeed kernel-grounded and deterministic as well.
△
The tool AGG [AGG14] supports the automated analysis of dependencies be-
tween rules. We apply this analysis engine to check whether a policy is conservative
and that the reduced sets of operational rules are suﬃcient to ensure completeness
of the propagation operations.
Remark 8.51 (Analysis of operational rules). In order to check that the sets of op-
erational translation rules are kernel-grounded and deterministic, we describe how
the preconditions of Def. 8.49 are checked using the tool AGG. The condition that
they have functional behaviour and do not require backtracking can be checked via
Theorem 8.29.
1. Sequential independence of the pairs (TR1s
FT, TR+s
FT) and (TR1t
BT, TR+t
BT): we can use
the tool AGG for the analysis of rule dependencies based on the generation of
critical pairs according to Fact 2 in [HEO+11b].
2. Applied policies are conservative: According to Fact 8.43, this requires that the
additional application conditions according to the policy restrict the evaluation
of attribute values only, i.e., the assignment of variables. We have to show that
the existence of matches is preserved for each rule and that other rules are not
sequentially dependent. For the latter, we can again use the tool AGG and validate
that the corresponding table entries show the value 0. The preservation of the
existence of matches can be ensured by checking that the aﬀected variables are
free in the unmodiﬁed rule (trFT or trBT ), i.e., they are not part of a term that is
connected to a node in the LHS (LFT or LBT).
△
Moreover, we can apply the presented results for showing that the derived model
transformation relations are left total. In particular, left totality of the relations is
required in Chap. 9 for ensuring completeness of model synchronisations via TGGs.
Remark 8.52 (Left totality). If the sets of operational translation rules of a TGG are
kernel-grounded, we can conclude that the forward model transformation relations
MTF,R : L(TGS ) ⇒L(TGT) based on TR+s
FT and the backward model transformation
relation MTB,R : L(TGT) ⇒L(TGS ) based on TR+s
BT specify left total relations as
shown by Fact 5 in [HEO+11b]. This means that the model transformations can be
performed on reduced sets of operational translation rules. Source identic triple rules
TR1s
FT are not used for forward translations and target identic triple rules TR1t
BT are not
used for backward translations. According to Def. 8.42, we can specify conservative

8.3 Reduction of Nondeterminism
247
policies in order to reduce the number of possible transformation sequences and
derive left total model transformation relations MT′
FT,R and MT′
BT,R that use these
policies.
△

Chapter 9
Model Synchronisation
Bidirectional model transformations are a key concept for model generation
and synchronisation within model-driven engineering (MDE, see [Ste10, QVT15,
CFH+09]). Triple graph grammars (TGGs) have been successfully applied in sev-
eral case studies for bidirectional model transformation, model integration and
synchronisation [KW07, SK08, GW09, GH09], and in the implementation of
QVT [GK10]. This chapter provides a TGG framework for model synchronisa-
tion that ensures correctness and completeness based on the theory of TGGs. It
is inspired by work on incremental synchronisation by Giese et al. [GW09, GH09],
and the model synchronisation framework by Diskin [Dis11]. The chapter is based
on [HEO+11a, HEEO12, HEO+13]. The main ideas and results are the following:
1. Models are synchronised by propagating changes from a source model to a cor-
responding target model using forward and backward propagation operations.
The operations are speciﬁed by a TGG model framework, inspired by symmetric
replica synchronisers [Dis11] and realised by model transformations based on
TGGs [EEHP09] (see Chap. 7). The speciﬁed TGG also deﬁnes consistency of
source and target models.
2. Since TGGs deﬁne, in general, nondeterministic model transformations, the de-
rived synchronisation operations are, in general, nondeterministic. But we are
able to provide suﬃcient static conditions based on TGGs to ensure that the op-
erations are deterministic.
3. The ﬁrst main result shows that a TGG synchronisation framework with deter-
ministic synchronisation operations is correct, i.e., consistency preserving, and
complete (see Theorems 9.25 and 9.29). We also give suﬃcient static conditions
for invertibility and weak invertibility of the framework, where “weak” restricts
invertibility to a subclass of inputs.
4. The second main result shows that a TGG synchronisation framework for concur-
rent model synchronisation based on deterministic propagation operations is cor-
rect and complete (see Theorem 9.41). Concurrent model synchronisation means
that updates may occur on both domains simultaneously, which requires addi-
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_9
249

250
9 Model Synchronisation
Fig. 9.1 Forward propagation
tional conﬂict resolution and may cause nondeterminism due to user interaction
during conﬂict resolution.
Deriving a synchronisation framework from a TGG has the following practical
beneﬁts. Consistency of the related domains is deﬁned declaratively and in a pattern-
based style, using the rules of a TGG. Consistency of source and target models is
always ensured after executing the synchronisation operations (correctness) and the
synchronisation can be performed for all valid inputs (completeness). The required
static conditions for deterministic behaviour and the additional conditions for invert-
ibility can be checked automatically using the tool support of AGG [AGG14]. The
extension of this approach to the general case of nondeterministic synchronisation
operations based on nondeterministic TGGs is described in [GHN+13].
Remark 9.1 (General assumption). As in Chap. 8, the formal results in this chap-
ter are presented for TGGs that ensure the composition and decomposition property
for forward sequences (Def. 7.20) and for integration sequences (Def. 7.39). Chap. 7
presents suﬃcient conditions for these properties by Theorems 7.21 and 7.40. These
conditions mainly require that the application conditions be compatible applica-
tion condition schemata with almost injective morphisms and the execution be per-
formed via almost injective matches. Moreover, the formal results in this chapter are
presented for triple graph grammars with negative application conditions (NACs).
An extension to general nested application conditions is future work. Several case
studies show that NACs are usually suﬃcient to restrict the applicability of triple
rules in the context of model synchronisation.
△
Throughout this chapter, we use a simple running example, which is adapted
from [DXC11a, HEO+13]. The example considers the synchronisation of two or-
ganisational diagrams as shown in Fig. 9.1. Diagrams in the ﬁrst domain—depicted
left—provide a view on employees of the marketing department of a company, while
diagrams in the second domain—depicted right—show all employees. Furthermore,
both domains diﬀer on the type of information they specify. Diagrams on the left
show the base and bonus salary values of each person, while diagrams in the second
domain show only the total salary for each person, but additionally, they provide the
birth dates (marked by “*”). Therefore, both domains contain exclusive information
and none of them can be interpreted as a view—deﬁned by a query—of the other.

9 Model Synchronisation
251
Both diagrams together with some correspondence structure build up an inte-
grated model, where we refer to the ﬁrst diagram as the source model and to the
second diagram as the target model. An integrated model is called consistent if:
• corresponding persons coincide on names,
• salary values are equal to the sums of corresponding base and bonus values, and
• persons in the source domain are exactly those who are marked with M in the
target domain.
Example 9.2 (Update propagation). The ﬁrst row of Fig. 9.1 shows a consistent in-
tegrated model M in a visual notation. The source model of M consists of two per-
sons belonging to the marketing department (depicted as persons with label M and
without pencils) and the target model additionally contains the person Alex Archer
belonging to the technical department (depicted as a person with label T and with
pencil). The ﬁrst column shows an update of the source model, where the person
Paul Page is removed and some attribute values of the person Lily Lee are modi-
ﬁed. This change is propagated to the target domain, leading to a target update (right
column) and a new integrated model (bottom row).
△
The synchronisation problem is to propagate a model update in such a way that
the resulting integrated model is consistent. Looking at Fig. 9.1, this requires that the
source model update of removing the person Paul Page and changing the attributes
LastName and Bonus of the person Lily Lee is propagated in an appropriate way to
the target domain. In this example, this means that the executed forward propagation
(fPpg) shall remove the person Paul Page and update the attribute values of Lily
Lee in the target model, such that the unchanged birth date value and consistency is
preserved.
Remark 9.3 (Choice of the example). This chapter uses a rather simple example for
model synchronisation to keep the ﬁgures and constructions compact. It is suﬃ-
cient to illustrate the relevant aspects and can serve as a reference to design more
complex ones. In fact, it is closely related to the even simpler benchmark example
for bidirectional model transformation and synchronisation presented in [ACG+14].
Note that the example CD2RDBM used throughout Chapters 7 and 8 does not en-
sure all conditions for our general results in this chapter concerning correctness and
completeness and we discuss the corresponding problems of them in Rem. 9.27.
△
Synchronisation scenarios like the one in our example are present in many do-
mains. Consider for example synchronisations between diﬀerent kinds of visual
models for software development, models for software analysis, and even source
code. Synchronisations between these domains often need to provide mechanisms
that do not require that one model be completely obtainable from the other. In other
words, none of the models is just a view of the other. In this chapter, we show how
this ﬂexibility in the synchronisation process is possible based on the formal no-
tion of TGGs. Stepwise, we develop the required formal techniques and illustrate
them on the running example in Fig. 9.1, whose intermediate steps are presented in
Fig. 9.16 of Sect. 9.2.

252
9 Model Synchronisation
Sect. 9.1 presents the general concept for change propagation and Sect. 9.2 intro-
duces the model synchronisation framework based on TGGs for the basic case, i.e.,
where updates are propagated from one side to the other. Sect. 9.2.3 shows that the
derived synchronisation framework is correct and complete under suﬃcient static
conditions. Moreover, it provides suﬃcient conditions that ensure compatibility of
the propagation operations, namely invertibility. Sect. 9.3 extends the framework to
the concurrent case, where updates may occur on both domains simultanously. The
propagation of both updates additionally requires us to resolve occurring conﬂicts
with optional user input.
9.1 General Concept for Change Propagation
This section describes the basic framework for model synchronisation, where triple
graphs describe pairs of interrelated models and triple graph grammars (TGGs) are
used as a tool to specify classes of consistent interrelated models (see Chap. 7). The
framework is a simpliﬁed version of symmetric delta lenses proposed by Diskin et
al. [Dis11]. Based on the notion of a TGG model framework, we deﬁne synchroni-
sation problems and the propagation operations which are used to solve them. We
present and discuss explicit properties concerning correctness, completeness and
invertibility.
In general, model synchronisation aims to achieve consistency among interre-
lated models. We consider a model as a kind of graph. Moreover, we assume that
a pair of interrelated models (MS , MT), called source and target models, are repre-
sented by a triple graph G = (GS ←GC →GT), which we also call an integrated
model. The source graph GS represents MS and the target graph GT represents MT.
The two graph morphisms sG : GC →GS and tG : GC →GT specify a correspon-
dence r : GS ↔GT, which relates the elements of GS with their corresponding
elements of GT and vice versa. For simplicity, we use double arrows (↔) as an
equivalent shorter notation for triple graphs whenever the explicit correspondence
graph can be omitted.
Example 9.4 (Type graph). The triple type graph TG of our example is shown in
Fig. 9.2. It speciﬁes that models of the source domain contain persons, including
their detailed salary information (bonus and base salary) and their names. Models of
the target domain additionally contain the department to which a person is assigned,
his or her birth date, and a single value for his or her complete salary, while the
details about bonus and base salary are not provided.
△
Example 9.5 (Triple rules). The triple rules of the TGG are depicted in a compact
notation in Fig. 9.3. Left and right hand sides of a rule are depicted in one triple
graph, where the elements to be created have the label “++”. They exist in the right-
hand side of the triple rule only. The ﬁrst rule (Person2FirstMarketingP) inserts a
new department with name Marketing and the NAC ensures that none of the exist-
ing departments is named equally. The rule creates a person of the new department

9.1 General Concept for Change Propagation
253
dep
TGS
TGC
TGT
PP
Department
name: String
Person
FirstName: String
LastName: String
Birth: String
Salary: Real
Person
FirstName: String
LastName: String
Base: Real
Bonus: Real
Fig. 9.2 Triple type graph TG
in the target model as well as a corresponding person in the source model. Note
that the left hand side of this rule is empty, i.e., it does not require existing struc-
tures. The rule Person2NextMarketingP is used to extend both models with further
persons in the marketing department. The left hand side of this rule contains the de-
partment node with name Marketing. Note that the attributes of the created persons
are not set with these rules. This is possible in our formal framework of attributed
graph transformation based on the notion of E-graphs (see Chap. 2, [EEPT06]). The
main advantage is that we can propagate changes of attribute values without the
need for deleting and recreating the owning structural nodes. This is important from
the eﬃciency and application point of view. Thus, rules 3–6 concern the creation
of attribute values only. Rules 3 (FName2FName) and 4 (LName2LName) cre-
ate new corresponding values for ﬁrst and last names, respectively. The next rule
(Empty2Birth) assigns the birth date of a person in the target component and does
not change the source component. Finally, rule 6 (DetailedSalary2Salary) assigns
the detailed salary values (bonus and base) in the source component and the sum
of them in the target component. Rule 7 (Empty2OtherDepartment) creates a new
department that is not named Marketing, but does not change the source model. The
negative application condition (NAC) ensures that the used attribute value is diﬀer-
ent from Marketing. The last rule Empty2OtherP of the TGG creates a new person
of a department that is diﬀerent from the marketing department. Therefore, there
are no correspondences to the source model and the rule directly creates the person,
including all attribute values.
△
A TGG model framework speciﬁes the possible correspondences between models
and updates of models for a given TGG according to Def. 9.6 below. More precisely,
a model framework is deﬁned as consisting of the classes of well-typed source and
target models, the class of correspondences between source and target models (i.e.,
the class of well-typed triple graphs), the subset of consistent correspondences (i.e.,
the class of triple graphs deﬁned by the given TGG) and the classes of source and
target updates. In particular, a model update δ : G →G′ is speciﬁed as a graph
modiﬁcation consisting of two inclusions, δ : G ←- I ,→G′. This notion is inspired
by the derived spans of graph transformation sequences (see Def. 5.31). The intu-
ition of a graph modiﬁcation is that the inclusion I ,→G speciﬁes the elements that

254
9 Model Synchronisation
1:Person2FirstMarketingP()
:PP
++
++
:Person ++
:dep
:Person
++
++
++
NAC
:PP
++
++
2:Person2NextMarketingP()
:Person
++
:dep
Person
++
++
++
:Department
name="Marketing"
++
++
:Department
name="Marketing"
1:Department
name="Marketing"
3:FName2FName(n:String)
:PP
Person
FirstName = n
++
Person
FirstName = n
++
:PP
Person
LastName = n
++
Person
LastName = n
++
Person
Birth = b ++
:PP
Person
Salary=base+bonus ++
Person
Base = base
Bonus = bonus
++
++
4:LName2LName(n:String)
5:Empty2Birth(b:String)
6:DetailedSalary2Salary(base:Real,bonus:Real)
1:Department
:dep
NAC
Person
FirstName = nF
LastName = nL
Birth = b
Salary = s
++
++
++
++
++
++
1:Department
name=“Marketing“
8:Empty2OtherP(nF:String,nL:String,b:String,s:Real)
1:Department
name=n
++
++
NAC
7:Empty2OtherDepartment(n:String)
n="Marketing":String
:Department
name=n
++
++
NAC
Fig. 9.3 Triple rules

9.1 General Concept for Change Propagation
255
are deleted from G (all the elements that are not in I) and I ,→G′ speciﬁes all the
elements that are added by δ (all the elements in G′ that are not in I). Therefore,
the elements in I are the elements that remain invariant after the modiﬁcation. In-
tuitively, one can also interprete a graph modiﬁcation as a DPO rule that describes
the complete update as one step and contains the complete graphs and not just some
parts of them. Finally, it may be noted that graph modiﬁcations look like triple
graphs; however, their role is diﬀerent: triple graphs are used to make explicit the
interrelations between two integrated models, while graph modiﬁcations are used to
describe updates on a given model.
Given a TGG with type graph TG = (TGS ←TGC →TGT), we refer by L(TGG)
to the language of consistent integrated models, and by L(TGS ), L(TGT) to the
languages of source and target models typed over TGS and TGT, respectively.
Deﬁnition 9.6 (TGG model framework).
Let TGG = (TG, ∅, TR) be a triple
graph grammar with empty start graph ∅and triple type graph TG containing source
and target components TGS and TGT, and a set TR of triple rules. The derived TGG
model framework MF(TGG) = (L(TGS ), L(TGT), R,C, ∆S , ∆T) consists of source
domain L(TGS ), target domain L(TGT), the set R of correspondence relations given
by R = L(TG), the set C of consistent correspondence relations C ⊆R given by
C = L(TGG), (i.e., R contains all integrated models and C all consistent integrated
ones), and sets ∆S , ∆T of graph modiﬁcations for the source and target domains,
given by ∆S = {a : GS →G′S | GS ,G′S ∈L(TGS ), and a is a graph modiﬁcation}
and ∆T = {b : GT →G′T | GT,G′T ∈L(TGT), and b is a graph modiﬁcation},
respectively.
△
Given a TGG model framework, the synchronisation problem is to provide suit-
able total and deterministic forward and backward operations fPpg and bPpg that
propagate updates on one model (GS or GT) to the other model. The propagation
operations are executed via graph transformations. The operations are deterministic
if they ensure unique results for any input. They are total if they provide results for
all inputs. In other words, the propagation operations have to be proper functions
which is not satisﬁed by arbitrary graph transformation systems. Note that one can
consider also scenarios where update propagation is not necessarily deterministic,
i.e., the propagation of a source update would provide diﬀerent possible target up-
dates. For full details of this extended case and the corresponding results for the
nondeterministic scenario we refer you to [GHN+13].
The conceptual idea of forward propagation is the following. Given an integrated
model (a correspondence relation) GS ↔GT and an update a : GS →G′S , the
operation fPpg must propagate the update a to GT, returning as results an update
b : GT →G′T and a correspondence relation G′S ↔G′T. Similarly, bPpg is
the dual operation that propagates updates on target models to updates on source
models. The eﬀect of these operations is depicted schematically in the diagrams
in Fig. 9.4, which we call synchronisation tiles, where we use solid lines for the
inputs and dashed lines for the outputs [Dis11]. Note that, in a common tool envi-
ronment, the required input for these operations is either available directly or can
be obtained. For example, the graph modiﬁcation of a model update can be derived

256
9 Model Synchronisation
GS o
r
/
a 
u:fPpg
GT
b
G′S o
r′
/ G′T
GS o
r
/
a 
w:bPpg
GT
b
G′S o
r′
/ G′T
Fig. 9.4 Synchronisation operations
∀c ∈C :
GS o
c
/
1 
u:fPpg
GT
1
GS o
c
/ GT
(a1)
∀G′S ∈L(TGG)S :
GS o
r
/
a 
u:fPpg
GT
b
G′S o
r′:C
/ G′T
(a2)
∀c ∈C :
GS o
c
/
1 
w:bPpg
GT
1
GS o
c
/ GT
(b1)
∀G′T ∈L(TGG)T :
GS o
r
/
a 
w:bPpg
GT
b
G′S o
r′:C
/ G′T
(b2)
GS o
r
/
a1 
u:fPpg
GT
b
u:bPpg
GS
/
r
o
o
r
/
a2

u:fPpg
GT
b
GS
1 o
r1
/ G′T
GS
2
/
r2
o
o
r2
/ G′T
(c1)
GS o
r
/
a1 
u:fPpg
GT
b
u:bPpg
GS
/
r
o
a2

G′S o
r′
/ G′T
G′S
/
r′
o
(d1)
GT o
r
/
b1 
u:bPpg
GS
a
u:fPpg
GT
/
r
o
o
r
/
b2

u:bPpg
GS
a
GT
1 o
r1
/ G′S
GT
2
/
r2
o
o
r2
/ G′S
(c2)
GT o
r
/
b1 
u:bPpg
GS
a
u:fPpg
GT
/
r
o
b2

G′T o
r′
/ G′S
G′T
/
r′
o
(d2)
Fig. 9.5 Laws for correct and (weak) invertible synchronisation frameworks
via standard diﬀerence computation and the initial correspondence can be computed
based on TGG integration concepts (see Chap. 7, [EEH08a, KW07]). Note also that
determinism of fPpg means that the resulting correspondence G′S ↔G′T and the
update b : GT →G′T are uniquely determined up to isomorphism. The propaga-
tion operations are correct if they additionally preserve consistency as speciﬁed by
laws (a1)–(b2) in Fig. 9.5. Law (a2) means that fPpg always produces consistent
correspondences from consistent updated source models G′S . Law (a1) means that
if the given update is the identity and the given correspondence is consistent, then
fPpg changes nothing. Laws (b1) and (b2) are the dual versions concerning bPpg.
Moreover, the sets L(TGG)S and L(TGG)T specify the consistent source and tar-
get models, which are given by the source and target components of the integrated
models in C = L(TGG).
Deﬁnition 9.7 (Synchronisation problem and framework). Let MF = (L(TGS ),
L(TGT), R,C, ∆S , ∆T) be a TGG model framework. The forward synchronisa-
tion problem is to construct a total and deterministic operation fPpg : R ⊗
∆S
→
R × ∆T leading to the left diagram in Fig. 9.4, where R ⊗∆S
=
{(r, a) ∈R × ∆S | r: GS ↔GT, a: GS →G′S }, i.e., a and r coincide on GS . The pair

9.1 General Concept for Change Propagation
257
Fig. 9.6 Counterexample for invertibility
(r, a) ∈R⊗∆S is called premise and (r′, b) ∈R × ∆T is called solution of the forward
synchronisation problem, written fPpg(r, a) = (r′, b). The backward synchronisation
problem is to construct a total and deterministic operation bPpg leading to the right
diagram in Fig. 9.4. The operation fPpg is called correct with respect to C if axioms
(a1) and (a2) in Fig. 9.5 are satisﬁed and, symmetrically, bPpg is called correct
with respect to C if axioms (b1) and (b2) are satisﬁed.
Given total and deterministic propagation operations fPpg and bPpg derived
from TGG, the derived synchronisation framework Synch(TGG) is given by
Synch(TGG) = (MF(TGG), fPpg, bPpg). It is called correct if fPpg and bPpg are
correct; it is weakly invertible if axioms (c1) and (c2) in Fig. 9.5 are satisﬁed; and it
is invertible if additionally axioms (d1) and (d2) in Fig. 9.5 are satisﬁed.
△
Invertibility (laws (d1) and (d2)) means that the propagation operations are es-
sentially inverse of each other. For instance, axiom (d1) states that if we propagate
an update a1 : GS →GS
1 to GT, obtaining as result an update b, and now we propa-
gate update b to GS , we obtain the same result GS
1 . However, notice that we do not
require that the resulting update a2 : GS →GS
1 coincide with a1. In particular, it may
be possible that the set of elements of GS that are not modiﬁed by a1 may not co-
incide with the set of elements that are not modiﬁed by a2, even if they produce the
same result GS
1 (see Ex. 9.8 below). However, as we show in Sect. 9.2.3, we are able
to ensure the more ﬂexible notion of weak invertibility (laws (c1) and (c2)) for our
example. More precisely, weak invertibility expresses that the two operations are
the inverse of each other, up to certain information that may be lost when applying
the operations. For instance, in axiom (c1) the intuition is that update b, the result of
propagation of update a1, may ignore part of the information added by a1, because
this kind of information may not be relevant for target models. As a consequence,
when propagating b to GS this information would be lost. However, weak invert-
ibility also states that no information added by update b would be ignored when
propagating it back to GS . Thus, update b is recovered in the last propagation step.
The reason is that all that information was, in some sense, included in update a1, so
it must be relevant for source models.
Example 9.8 (Invertibility and weak invertibility). Consider a model update b1 of
a given target model, as depicted in Fig. 9.6, where a new person (Paul Page) is

258
9 Model Synchronisation
Fig. 9.7 Example for weak invertibility
added together with his birth date, leading to a target model G′T. The propagation
via bPpg yields an update a, whose resulting source model G′S includes that per-
son without his birth date. Now, the propagation of a via fPpg yields an update b2
whose resulting target model G′′T does not contain any information about the birth
date. Therefore, G′T , G′′T, meaning that Synch(TGG) is not invertible, since law
(d2) does not hold. However, if we continue the diagram and perform an additional
backward propagation as in Fig. 9.7, we derive a source update that coincides again
with a, i.e., the diagrams satisfy law (c2) of weak invertibility.
△
9.2 Basic Model Synchronisation
This section shows how to construct the synchronisation operations for the basic
case, where updates from one domain are propagated to the other domain to achieve
a consistent state. The more general case of simultaneous updates on both domains
is presented in Sect. 9.3.
The synchronisation operation fPpg of a TGG synchronisation framework (see
Def. 9.7) is derived as a composition of auxiliary operations, which are executed
based on the sets of operational rules of the TGG.
9.2.1 Derived Operational Rules for Synchronisation
The auxiliary operations for the propagation operations fPpg and bPpg are based
on the sets of operational rules of the speciﬁed TGG. The used sets are the derived
consistency creating rules, the forward translation rules and the backward transla-
tion rules (see Def. 7.44). The consistency creating rules are used to mark the still
consistent parts of the current state of the integrated model while the forward and
backward translation rules are used to propagate the update from one domain to the
other.

9.2 Basic Model Synchronisation
259
1: Person2FirstMarketingPCC()
:dep
tr=[F⇒T]
NAC
:Department
tr=[F⇒T]
name="Marketing"
tr_name=[F⇒T]
:Department
name="Marketing"
tr=T
:Person
tr=[F⇒T]
:Person
tr=[F⇒T]
:PP
tr=[F⇒T]
2: Person2NextMarketingPCC()
:Department
tr=T
name=“Marketing“
:dep
tr=[F⇒T]
:Person
tr=[F⇒T]
:Person
tr=[F⇒T]
:PP
tr=[F⇒T]
3: FName2FNameCC()
:Person
tr=T
FirstName = n
tr_FirstName=[F⇒T]
:Person
FirstName = n
tr=T
tr_FirstName=[F⇒T]
:PP
tr=T
Fig. 9.8 Derived operational triple rules: TRCC (part 1)
In general, each intermediate phase during the execution of a propagation opera-
tion prepares the application of the operational rules in the subsequent phase. Hence,
the sets of operational rules have to be compatible up to a certain extent.
Remark 9.9 (Interdependencies between operational rules). The consistency creat-
ing rules (TRCC) are used for marking the already consistent parts of a given in-
tegrated model in the second sub-phase of the synchronisation. The forward and
backward translation rules are used for the third sub-phase. This third sub-phase
can be interpreted as a completion of the computed sequence of the second sub-
phase. We show in Sect. 9.2.3 that this continuation is always possible if the sets
of operational rules are deterministic (Theorem 9.25), for which we also provide an
automated check and analysis. If a TGG does not ensure deterministic sets of op-
erational rules, the computed maximal subgraph via TRCC may be too large to ﬁnd
a corresponding completion via forward (backward) translation rules. In this case,
a possible solution would be to perform backtracking for sub-phases 2 and 3 of the
synchronisation, as discussed in Sect. 9.3.
△
Example 9.10 (Derived sets of consistency creating rules). Figs. 9.8 and 9.9 show
the set of the consistency creating rules derived from the triple rules in Ex. 9.5
according to Def. 7.44. They do not modify the structure of a triple graph, but only
the translation attributes. They are used for marking consistent substructures of a

260
9 Model Synchronisation
6: Empty2BirthCC()
:Person
tr=T
Birth = b
tr_Birth=[F⇒T]
5: DetailedSalary2SalaryCC()
:Person
Base = base
Bonus = bonus
tr=T
tr_Base=[F⇒T]
tr_Bonus=[F⇒T]
:Person
tr=T
Salary=base+bonus
tr_Salary=[F⇒T]
:PP
tr=T
:PP
tr=T
:Person
tr=T
2:dep
tr=[F⇒T]
NAC
3:Person
FirstName = nF
LastName = nL
Birth = b
Salary = s
tr=[F⇒T]
tr_FirstName=[F⇒T]
tr_LastName=[F⇒T]
tr_Birth=[F⇒T]
tr_Salary=[F⇒T]
1:Department
name=“Marketing“
1:Department
tr=T
NAC
7: Empty2OtherDepartmentCC()
n="Marketing":String
:Department
tr=[F⇒T]
name=n
tr_name=[F⇒T]
8: Empty2OtherPCC()
4: LName2LNameCC()
:Person
tr=T
LastName = n
tr_LastName=[F⇒T]
:Person
LastName = n
tr=T
tr_LastName=[F⇒T]
:PP
tr=T
Fig. 9.9 Derived operational triple rules: TRCC (part 2)
given triple graph, i.e., of a given integrated model. For that purpose, we apply
all derived consistency creating rules as long as possible to a given triple G with all
translation attributes set to “F”. Thus, we compute a maximal consistent triple graph
that is contained in G. Intuitively, for each element x ∈R (node, edge, or attribute) of
a triple rule tr = (L →R), a separate translation attribute (tr or tr_x) is added for
the consistency creating rule trCC. If an element x ∈R is preserved by the triple rule
tr (x ∈L), then the consistency creating rule preserves it as well and the translation

9.2 Basic Model Synchronisation
261
1: Person2FirstMarketingPFT()
:PP
++
++
:Person ++
:dep
++
++
NAC
:PP
++
++
2: Person2NextMarketingPFT()
:Person
++
:dep
++
++
:Department
name="Marketing"
++
++
:Department
name="Marketing"
:Department
name="Marketing"
:Person
tr=[F⇒T]
:Person
tr=[F⇒T]
3: FName2FNameFT()
:PP
4: LName2LNameFT()
:Person
FirstName = n
tr=T
tr_FirstName=[F⇒T]
:Person
FirstName = n
++
:PP
:Person
LastName = n
++
5: DetailedSalary2SalaryFT()
:PP
Person
Salary=base+bonus ++
:Person
Base = base
Bonus = bonus
tr=T
tr_Base=[F⇒T]
tr_Bonus=[F⇒T]
:Person
LastName = n
tr=T
tr_LastName=[F⇒T]
6: Empty2BirthFT()
:PP
Person
Birth = b ++
:Person
tr=T
Fig. 9.10 Derived operational triple rules: TRFT (part 1)
attribute has value T. Otherwise, if x ∈R is created by tr (x ∈R\L), then it becomes
a preserved element in the consistency creating rule trCC and the corresponding
translation attribute is changed from F to T. In visual notation, this means that all
plus signs are replaced by additional translation attributes whose values are changed
from F to T, and we denote such a modiﬁcation by [F ⇒T].
△
Example 9.11 (Derived sets of forward translation rules). Figs. 9.10 and 9.11 show
the set of the forward translation rules derived from the triple rules in Ex. 9.5 accord-
ing to Def. 7.44. These rules are used for translating a source model into its corre-
sponding target model. For this reason, the rules are only modifying the translation
attributes on the source component. Intuitively, for each element x in the source

262
9 Model Synchronisation
1:Department
:dep
Person
FirstName = nF
LastName = nL
Birth = b
Salary = s
++
++
++
++
++
++
NAC
1:Department
name=“Marketing“
8: Empty2OtherPFT()
NAC
7: Empty2OtherDepartmentFT(n:String)
n="Marketing":String
:Department
name=n
++
++
Fig. 9.11 Derived operational triple rules: TRFT (part 2)
1: Person2FirstMarketingPBT()
:PP
++
++
:dep
tr=[F⇒T]
++
NAC
:Department
tr=[F⇒T]
name="Marketing"
tr_name=[F⇒T]
:Department
name="Marketing"
tr=T
:Person
++
:Person
tr=[F⇒T]
Fig. 9.12 Derived operational triple rules: TRBT (part 1)
component RS (node, edge, or attribute) of a triple rule tr = (L →R) a separate
translation attribute (tr or tr_x) is added for the forward translation rule trFT. If an
element x ∈RS is preserved by the triple rule tr, then the forward translation rule
preserves it as well and the translation attribute has value T. Otherwise, if x ∈RS
is created by tr, then it becomes a preserved element in the forward translation rule
trFT and the corresponding translation attribute is changed from F to T. In visual
notation, this means that each plus sign in the source component of a triple rule is
replaced by an additional translation attribute whose value changes from F to T.
Note that the rules 6–8 are contained in TR1s
FT, i.e., they are identities on the
source component and, according to Def. 9.7, they are not used for fPpg, which
is based on TR+s
FT. This is important to ensure termination (see Lem. 8.47) and we
show by Fact 9.24 that the derived sets of operational rules are kernel-grounded
(see Def. 8.49). This is a suﬃcient condition to guarantee that the reduced set still
ensures completeness according to Rem. 8.52 and Theorem 9.25.
△
Example 9.12 (Derived sets of backward translation rules). Figs. 9.12 and 9.13
show the set of the backward translation rules derived from the triple rules in Ex. 9.5

9.2 Basic Model Synchronisation
263
2:dep
tr=[F⇒T]
NAC
3:Person
FirstName = nF
LastName = nL
Birth = b
Salary = s
tr=[F⇒T]
tr_FirstName=[F⇒T]
tr_LastName=[F⇒T]
tr_Birth=[F⇒T]
tr_Salary=[F⇒T]
1:Department
name=“Marketing“
1:Department
tr=T
8: Empty2OtherPBT()
NAC
7: Empty2OtherDepartmentBT()
n="Marketing":String
:Department
tr=[F⇒T]
name=n
tr_name=[F⇒T]
3: FName2FNameBT()
:PP
4: LName2LNameBT()
:Person
tr=T
FirstName = n
tr_FirstName=[F⇒T]
:Person
FirstName = n
++
:PP
:Person
tr=T
LastName = n
tr_LastName=[F⇒T]
:Person
LastName = n
++
5: DetailedSalary2SalaryBT()
:PP
:Person
tr=T
Salary=
   base+bonus
tr_Salary=[F⇒T]
policy
base=bonus
:Person
Base = base
Bonus = bonus
++
++
6: Empty2BirthBT()
:Person
:PP
:Person
tr=T
Birth = b
tr_Birth=[F⇒T]
2: Person2NextMarketingPBT()
:Department
tr=T
name=“Marketing“
:PP
++
++
:dep
tr=[F⇒T]
++
:Person
++
:Person
tr=[F⇒T]
Fig. 9.13 Derived operational triple rules: TRBT (part 2)

264
9 Model Synchronisation
according to Def. 7.44. They are derived dually to the case of forward translation
rules and used for the translation of target models into their corresponding source
models. Thus, they do only modify translation attributes on the target component.
Intuitively, for each element x in the target component RT (node, edge, or attribute)
of a triple rule tr = (L →R), a separate translation attribute (tr or tr_x) is added
for the backward translation rule trBT. If an element x ∈RT is preserved by the triple
rule tr, then the backward translation rule preserves it as well and the translation at-
tribute has value T. Otherwise, if x ∈RT is created by tr, then it becomes a preserved
element in the backward translation rule trBT and the corresponding translation at-
tribute is changed from F to T. In visual notation, this means that all plus signs in
the target component are replaced by additional translation attributes whose values
are changed from F to T. Note that all backward translation rules are used for bPpg
in contrast to the operation fPpg before.
△
9.2.2 Execution of Basic Synchronisation
In the following, we show how to construct the operation fPpg of a TGG synchro-
nisation framework (see Def. 9.7) as a composition of auxiliary operations ⟨fAln,
Del, fAdd⟩. Intuitively, the operation fAln removes correspondences that become
dangling via the given update, the operation Del computes the maximal consistent
sub triple graph of the current state and removes inconsistent elements on the cor-
respondence and target components, but not on the source component. Finally, the
operation fAdd propagates the elements on the source component that are not yet
consistent already by performing suitable forward transformation steps. Symmetri-
cally, the operations ⟨bAln, Del, bAdd⟩are used to deﬁne the operation bPpg for
the backward direction. By Def. 9.7, the propagation operations have to be total
and deterministic, i.e., they have to provide unique results for all inputs. There-
fore, we will require that the given TGG provide deterministic sets of operational
translation rules, meaning that the algorithmic execution of the forward translation,
backward translation, and consistency creating rules ensure functional behaviour
(unique results) and not require backtracking. For this purpose, additional policies
can be deﬁned that restrict the matches of operational translation rules as presented
in Sect. 8.3 by Fact 8.43. Rem. 9.22 in Sect. 9.2.3 provides suﬃcient conditions
for deterministic operational translation rules. Additional static conditions and au-
tomated checks are provided in [HEO+11b].
The general synchronisation process is performed as follows (see Def. 9.13 and
Fig. 9.14, where we use double arrows (↔) for correspondence in the signature of
the operations, and the explicit triple graphs for the construction details). Given two
corresponding models GS and GT and an update of GS via the graph modiﬁcation
a = (GS ←
a1−−DS −
a2−→G′S ) with G′S ∈L(TGG)S , the forward propagation fPpg of the
model update a is performed in three steps via the auxiliary operations fAln, Del,
and fAdd. At ﬁrst, the deletion performed in a is reﬂected in the correspondence
relation between GS and GT by calculating the forward alignment remainder via

9.2 Basic Model Synchronisation
265
Signature
Deﬁnition of Components
GS o
r=(s,t)
/
a=
(a1,a2) 
u:fAln
GT
1
G′S o
r′=(s′,t′)
/ GT
GS
(PB)
GC
s
o
t
/ GT
DS?
a1
O
DC?
a∗
1
O
s∗
o
s′ = a2 ◦s∗,
t′ = t ◦a∗
1
GS o
r=(s,t)
/
a=
(f S ,1) 
⇓:Del
GT
b=
(f T ,1)

GS
k o
r′=(sk,tk):C / GT
k
G = (GS
GC
s
o
t / GT)
∅
tr∗+3 Gk = (GS
k
?f S
O
?
f
O
GC
k
?f C
O
sk
o
tk / GT
k )
?f T
O
∅=
tr∗
=⇒Gk
is
maximal
w.r.t.
Gk ⊆G
∀G′S ∈L(TGG)S :
GS o
r=(s,t):C
/
a=
(1,a2) 
u:fAdd
GT
b=
(1,b2)

G′S o
r′=(s′,t′)
/ G′T
(GS
 _
a2 
G
GC
s
o
t
/
 _
1 
GT) _
1 
(G′S
 _
1 
G0
 _
g 
GC _

a2◦s
o
t
/ GT)
 _
b2 
(G′S
G′
tr∗
F 
G′C
s′
o
t′
/ G′T)
G0 =
tr∗
F
==⇒G′
with G′ ∈L(TGG)
Fig. 9.14 Auxiliary operations fAln, Del and fAdd
the operation fAln. This step deletes all correspondence elements whose elements
in GS have been deleted. In the second step, performed via the operation Del, the
two maximal subgraphs GS
k ⊆GS and GT
k ⊆GT are computed such that they form a
consistent integrated model in L(TGG) according to the TGG. All elements that are
in GT but not in GT
k are deleted, i.e., the new target model is given by GT
k . Finally, in
the last step (operation fAdd), the elements in G′S that extend GS
k are transformed
to corresponding structures in G′T, i.e., GT
k is extended by these new structures. The
result of fAdd, and hence also fPpg, is an integrated model G′ = (G′S ↔G′T).
Since graph transformation is nondeterministic in general, we require that the sets
of operational translation rules be deterministic (see Def. 8.49) in order to ensure
unique results for both the second and the third step of the propagation operation
fPpg.
Deﬁnition 9.13 (Auxiliary TGG operations). Let TGG = (TG, ∅, TR) be a TGG
with deterministic sets TRCC, TR+s
FT, and TR+s
BT of operational translation rules and
let further MF(TGG) be the derived TGG model framework.
1. The auxiliary operation fAln computing the forward alignment remainder is given
by fAln(r, a) = r′, as speciﬁed in the upper part of Fig. 9.14. The square marked
by (PB) is a pullback (see Def. A.22, [EEPT06]), meaning that DC is the inter-
section of DS and GC.
2. Let r = (s, t): GS ↔GT be a correspondence relation; then the result of the
auxiliary operation Del is the maximal consistent subgraph GS
k ↔GT
k of r, given
by Del(r) = (a, r′, b), which is speciﬁed in the middle part of Fig. 9.14.

266
9 Model Synchronisation
3. Let r = (s, t): GS ↔GT be a consistent correspondence relation, a = (1, a2) :
GS →G′S be a source modiﬁcation and G′S ∈L(TGG)S . The result of the
auxiliary operation fAdd, for propagating the additions of source modiﬁcation
a, is a consistent model G′S ↔G′T extending GS ↔GT, and is given by
fAdd(r, a) = (r′, b), according to the lower part of Fig. 9.14.
△
Remark 9.14 (Auxiliary TGG operations). Intuitively, the operation fAln constructs
the new correspondence graph DC from the given GC by deleting all correspon-
dence elements in GC whose associated elements in GS are deleted via the update
a and, for this reason, do not occur in DS . The operation Del is executed by ap-
plying consistency creating rules (see Def. 7.44) to the given integrated model until
no rule is applicable anymore. If, at the end, GS ↔GT is completely marked, the
integrated model is already consistent; otherwise, the result is the largest consistent
integrated model included in GS ↔GT. Technically, the application of the con-
sistency creating rules corresponds to a maximal triple rule sequence, as shown in
the right middle part of Fig. 9.14 and discussed in more detail in [HEO+11a]. Fi-
nally, fAdd is executed by applying forward translation rules (see Sect. 7.4.2) to
G′S ↔GT until all the elements in G′S are marked with T. Intuitively, these TGT
steps form a model transformation of G′S extending GT. Technically, the application
of the forward translation rules corresponds to a source-consistent forward sequence
from G0 to G′, as shown in the right lower part of Fig. 9.14. By correctness of model
transformations (see Theorem 8.7, [EEHP09, HEGO14]), the sequence implies con-
sistency of G′ as stated above. The constructions for these auxiliary operations are
provided in full detail in [HEO+11b]. Note that the constructions for Del and fAdd
yield unique results due to the requirement that the operational translation rules be
deterministic (see Def. 9.13).
△
The auxiliary operation Del is based on the execution of consistency creating
rules. The computed resulting triple graph Gk is required to be consistent (Gk ∈
L(TGG)). This result is ensured by the equivalence of maximal triple and complete
extended consistency creating sequences according to Fact 9.15 below and shown
by Fact 11 in [HEO+11b].
Fact 9.15 (Equivalence of maximal triple and complete extended consistency
creating sequences). Given a set of nonidentic consistency creating rules TRCC and
G ∈L(TG), the following statements are equivalent for almost injective matches:
1. There is a TGT sequence s = (∅=
tr∗
=⇒Gk) via TR with injective embedding
f : Gk →G, such that s is f-maximal, i.e., any extension of s via TR is not
compatible with f.
2. There is a terminated consistency creating sequence s′ = (G′
0 =
tr∗
CC
==⇒G′
k) via TRCC
with G′
0 = AttF(G), i.e., all translation attributes are set to F.
Moreover, the sequences correspond via G′
k = G ⊕AttT
Gk ⊕AttF
G\Gk.
△
Proof. For the full proof, see [HEO+11b].
⊓⊔

9.2 Basic Model Synchronisation
267
:dep
:PP
tr=T
G3
G3
Graph Representation
Visual Notation
'S
M
Paul Parker
Base=3000
Bonus=2000
M
Paul Page
*1945-01-01
Salary=4000
M
Paul Parker
Base=3000
Bonus=2000
M
Paul Page
*1945-01-01
Salary=4000
M
Paul Page
*1945-01-01
Salary=4000
M
Paul Page
*1945-01-01
Salary=4000
M
Paul Parker
Base=3000
Bonus=2000
'T
:Department
tr=T
name="Marketing"
tr_name=T
:dep
:PP
tr=T
G2
G2
'S
'T
:Department
tr=T
name="Marketing"
tr_name=T
:Person
tr=T
FirstName="Paul"
tr_FirstName=T
LastName="Page"
tr_LastName=F
Birth="1945-01-01"
tr_birth=F
Salary=4000
tr_Salary=F
:Person
tr=T
FirstName="Paul"
tr_FirstName=T
LastName="Parker"
tr_LastName=F
Base=3000
tr_Base=F
Bonus=2000
tr_Bonus=F
:dep
:PP
tr=T
G1
G1
'S
'T
:Department
tr=T
name="Marketing"
tr_name=T
:Person
tr=T
FirstName="Paul"
tr_FirstName=F
LastName="Page"
tr_LastName=F
Birth="1945-01-01"
tr_birth=F
Salary=4000
tr_Salary=F
:Person
tr=T
FirstName="Paul"
tr_FirstName=F
LastName="Parker"
tr_LastName=F
Base=3000
tr_Base=F
Bonus=2000
tr_Bonus=F
:dep
:PP
tr=F
G0
G0
'S
'T
:Department
tr=F
name="Marketing"
tr_name=F
:Person
tr=F
FirstName="Paul"
tr_FirstName=F
LastName="Page"
tr_LastName=F
Birth="1945-01-01"
tr_birth=F
Salary=4000
tr_Salary=F
:Person
tr=F
FirstName="Paul"
tr_FirstName=F
LastName="Parker"
tr_LastName=F
Base=3000
tr_Base=F
Bonus=2000
tr_Bonus=F
1:Person2FirstPersonPCC()
3:FName2FNameCC()
6:Empty2BirthCC()
M
Paul Parker
Base=3000
Bonus=2000
:Person
tr=T
FirstName="Paul"
tr_FirstName=T
LastName="Parker"
tr_LastName=F
Base=3000
tr_Base=F
Bonus=2000
tr_Bonus=F
:Person
tr=T
FirstName="Paul"
tr_FirstName=T
LastName="Page"
tr_LastName=F
Birth="1945-01-01"
tr_birth=T
Salary=4000
tr_Salary=F
tr=F
tr=T
tr=T
tr=T
Fig. 9.15 Marking sequence: visual notation and graph representation

268
9 Model Synchronisation
Example 9.16 (Marking sequence). Consider the marking sequence in Fig. 9.15 with
transformation steps G′
0 =
1:Person2FirstPersonPCC
=================⇒G′
1 =
3:FName2FNameCC
=============⇒G′
2 =
6:Empty2BirthCC
===========⇒
G′
3. The upper part of the ﬁgure depicts the steps in visual notation, where consis-
tent parts are indicated by gray boxes with checkmarks. The lower part shows the
abstract syntax including the modiﬁcation of the translation attributes. Each modi-
ﬁcation is highlighted via a box around the changed translation attribute. All trans-
lation attributes of the initial graph G′
0 = G ⊕AttF
G are set to F, and in each step
some markers are set to T. The graph G′
3 still contains some markers with value F
and no further rule is applicable. Thus, the sequence is terminated and corresponds
to an f-maximal triple sequence ∅= G0 =
1:Person2FirstPersonP
===============⇒G1 =
3:FName2FName
============⇒
G2 =
6:Empty2Birth
==========⇒G3 with f : G3 →G. The graph G3 is given by all the elements
in G′
3 that are marked with T.
△
Example 9.17 (Forward propagation via operation fPpg). Fig. 9.16 shows the appli-
cation of the three steps of the synchronisation operation fPpg to the visual models
of our running example. After removing the dangling correspondence node of the
alignment in the ﬁrst step (fAln), the maximal consistent subgraph of the integrated
model is computed (Del) by stepwise marking the consistent parts. Explicit trans-
lation markers are omitted, but indicated by visually marking the consistent parts,
i.e., those elements whose translation markers are set to T. Consistent parts are indi-
cated by gray boxes with checkmarks in the visual notation and by bold face font in
the graph representation. Note that the node Alex Archer is part of the target graph
in this maximal consistent subgraph, even though it is not in correspondence with
any element of the source graph. This is possible, because the node Alex Archer is
connected to a diﬀerent department (see rule 8:Empty2OtherP in Fig. 9.3). More-
over, the attributes Base and Bonus of Lily Archer in the source component are
not marked, because they are inconsistent with the attribute Salary according to the
triple rule 5:DetailedSalary2SalaryCC in Fig. 9.9 (Base + Bonus , Salary). In the
ﬁnal step (fAdd), the inconsistent elements in the target model are removed and the
remaining new elements of the update are propagated towards the target model by
model transformation, such that all elements are ﬁnally marked as consistent.
△
The constructions for the auxiliary operations fAln, Del, and fAdd provide the ba-
sis for the propagation operation fPpg. Together with its symmetric version, namely
the backward propagation operation bPpg, we derive the TGG synchronisation
framework according to Def. 9.18. The forward and backward propagation oper-
ations fPpg and bPpg are called complete if they yield valid results for any valid
input. Completeness of the synchronisation operations is an important property in
the context of TGGs, and therefore it is worth emphasising it explicitly, while it is
implicitly included already within the signature in Fig. 9.17.
Deﬁnition 9.18 (Derived TGG synchronisation framework). Let TGG = (TG,
∅, TR) be a TGG with deterministic sets TRCC, TR+s
FT, and TR+s
BT of derived oper-
ational translation rules (consistency creating, source creating forward translation,
and target creating backward translation rules) and with derived model framework

9.2 Basic Model Synchronisation
269
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=4000
Paul Page
*1945-01-01
Salary=5000
Paul Page
Base=3500
Bonus=1500
Lily Lee
Base=3000
Bonus=1000
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=4000
Paul Page
*1945-01-01
Salary=5000
Lily Archer
Base=3000
Bonus=2000
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=4000
Paul Page
*1945-01-01
Salary=5000
Lily Archer
Base=3000
Bonus=2000
Alex Archer
*1955-01-01
Salary=6000
Lily Archer
*1965-01-01
Salary=5000
Lily Archer
Base=3000
Bonus=2000
:Person
FirstName="Lily"
LastName="Archer"
Base=3000
Bonus=2000
:dep
:Department
name="Marketing"
:Person
FirstName="Lily"
LastName="Lee"
Birth="1965-01-01"
Salary=4000
:dep
:Person
FirstName="Paul"
LastName="Page"
Birth="1945-01-01"
Salary=5000
:Department
name="Technical"
:dep
:Person
FirstName="Alex"
LastName="Archer"
Birth="1955-01-01"
Salary=6000
:PP
a1
b1
Gk
Gk
:Person
FirstName="Lily"
LastName="Archer"
Base=3000
Bonus=2000
:dep
:Department
name="Marketing"
:Person
FirstName="Lily"
LastName="Lee"
Birth="1965-01-01"
Salary=4000
:dep
:Person
FirstName="Paul"
LastName="Page"
Birth="1945-01-01"
Salary=5000
:Department
name="Technical"
:dep
:Person
FirstName="Alex"
LastName="Archer"
Birth="1955-01-01"
Salary=6000
:PP
GT
G'S
:Person
FirstName="Lily"
LastName="Archer"
Base=3000
Bonus=2000
:dep
:Department
name="Marketing"
:Person
FirstName="Lily"
LastName="Archer"
Birth="1965-01-01"
Salary=5000
:Department
name="Technical"
:dep
:Person
FirstName="Alex"
LastName="Archer"
Birth="1955-01-01"
Salary=6000
:PP
G'T
G'S
a1
b2
-1
S
T
a
1
:Person
FirstName="Lily"
LastName="Lee"
Base=3000
Bonus=1000
:Person
FirstName="Paul"
LastName="Page"
Base=3500
Bonus=1500
:dep
:Department
name="Marketing"
:Person
FirstName="Lily"
LastName="Lee"
Birth="1965-01-01"
Salary=4000
:dep
:Person
FirstName="Paul"
LastName="Page"
Birth="1945-01-01"
Salary=5000
:Department
name="Technical"
:dep
:Person
FirstName="Alex"
LastName="Archer"
Birth="1955-01-01"
Salary=6000
:PP
:PP
GT
GS
Graph Representation
Visual Notation
M
M
M
M
M
M
M
M
M
M
M
M
T
T
T
T
Fig. 9.16 Forward propagation in detail: visual notation and graph representation

270
9 Model Synchronisation
Signature
Deﬁnition of Components
∀G′S ∈L(TGG)S :
GS o
r
/
a 
u:fPpg
GT
b
G′S o
r′
/ G′T
GS o
r
/
aA
%
u:fAln
a
/
GT
1

b
o
•
a1
O
1
DS o
r1
/
aD
%
⇓:Del
GT
bD

•
a′
1
O
1
GS
k o
r2
/
af
%
u:fAdd
GT
k
bf

•
1O
a2◦a′
1

G′S o
r′
/ G′T
a = (a1, a2) = (GS ←
a1−−DS −
a2−→G′S ), aA = (a1, 1), aD = (a′
1, 1), af = (1, a2 ◦a′
1)
b = bf ◦bD
Fig. 9.17 Synchronisation operation fPpg—formal deﬁnition
/* == alignment remainder == */
forall(correpondence nodes without image in the source model){
delete these elements }
/* ==== delete === */
while(there is a triple rule tr:L->R with R\L is unmarked in G){
apply the consistency creating rule of tr to G }
forall(unmarked nodes and edges from the target model){
delete these elements }
/* ===== add ===== */
while(there is a forward translation rule applicable to G){
apply to G the forward translation rule }
Fig. 9.18 Synchronisation operation fPpg—algorithm
MF(TGG); then the operation fPpg of the derived TGG synchronisation framework
Synch(TGG) is given by the composition of the auxiliary operations for the for-
ward direction (fAln, Del, fAdd), as described in Rem. 9.19 according to Fig. 9.17.
Symmetrically—not shown explicitly—we obtain bPpg as the composition of the
auxiliary operations for the backward direction (bAln, Del, bAdd). Synch(TGG) is
called complete if its propagation operations are complete, i.e., they always yield a
result for any valid input.
△
Remark 9.19 (Construction of fPpg according to Fig. 9.17). Consider a not nec-
essarily consistent integrated model r: GS
↔GT and a source model update
a: GS →G′S . If G′S ∈L(TGG)S , we compute fPpg(r, a) as follows. First, fAln

9.2 Basic Model Synchronisation
271
computes the correspondence (DS ↔GT), where DS is the part of GS that is pre-
served by update a. Then, Del computes its maximal consistent integrated submodel
(GS
k ↔GT
k ). Finally, fAdd composes the embedding GS
k →G′S with correspon-
dence (GS
k ↔GT
k ) leading to (G′S ↔GT
k ), which is then extended into the inte-
grated model (G′S ↔G′T) via forward transformation. Note that this execution is
only possible if G′S ∈L(TGG)S . If G′S < L(TGG)S , the above execution fails and
the result is given by b = (1, 1): GT →GT, together with the correspondence rela-
tion r′ = (∅, ∅), and additionally an error message is provided. Fig. 9.18 describes
this construction algorithmically in pseudocode, leaving out the error handling.
△
Fact 9.20 (Case study: termination of synchronisation operations). The derived
synchronisation operations fPpg and bPpg for our example TGG terminate.
△
Proof. According to Def. 9.18, the synchronisation operations are based on the
sets TR+
CC, TR+s
FT, and TR+s
BT of operational translation rules. Hence, we can apply
Lem. 8.47 and derive that the synchronisation operations are terminating.
⊓⊔
9.2.3 Correctness and Invertibility of Model Synchronisation
In this section, we present our main results for unidirectional model synchronisation
concerning the properties correctness, completeness and invertibility of the synchro-
nisation framework. According to Def. 9.7, correctness requires that the synchroni-
sation operations ensure laws (a1)–(b2) and are deterministic (see Def. 8.49), i.e.,
they have functional behaviour (see Def. 8.10) and do not require backtracking.
Concerning determinism, Theorem 9.23 below provides a suﬃcient condition based
on the notion of critical pairs (see Def. 2.39 and Def. 5.40, based on [EEPT06]). In
order to ensure this condition, Sect. 8.3 presents the concept of additional propaga-
tion policies that eliminate nondeterminism. They can be seen as application con-
ditions for the rules, and are called conservative if they preserve the completeness
result. Fact 8.43 provides a suﬃcient static condition for checking this property and
we perform the automated analysis of this condition for our example TGG using the
tool AGG [AGG14] as described below. Note again that we generally require almost
injective matching (see Def. 7.3 in Sect. 7.4.2).
Example 9.21 (Conservative policy). In Fig. 9.19, the backward translation
rule 5:DetailedSalary2SalaryBT from Ex. 9.12 is extended to the rule 5’:
DetailedSalary2SalaryBT,2 by a policy in the form of an additional application con-
dition in order to ensure determinism. Since the left hand side of this rule speciﬁes
only the sum of the salary of a person, the values of the base and bonus components
are not ﬁxed via a match. The application condition (see Def. 2.9 and Def. 5.12
based on [EEPT06]) requires that both values be set to half the amount of the salary
sum. Now, this is possible for each number, such that we can conclude that the pol-
icy is conservative (Fact 8.43), which is important for ensuring completeness of the
propagation operation bPpg (see Theorem 9.25).
△

272
9 Model Synchronisation
5: DetailedSalary2SalaryBT()
:PP
:Person
tr=T
Salary=
   base+bonus
tr_Salary=[F⇒T]
policy
base=bonus
:Person
Base = base
Bonus = bonus
++
++
5': DetailedSalary2SalaryBT,2()  
:PP
:Person
tr=T
Salary=salary
tr_Salary=[F⇒T]
:Person
Base = 0.5∗salary
Bonus = 0.5∗salary
++
++
(equivalent rule, optimized for execution)
Fig. 9.19 Backward translation rule without (5) and with (5′) conservative policy
Now we investigate the most important property that has to be checked for the
operational translation rules in order to ensure correct propagation operations—
deterministic behaviour. First of all, this means that their execution has functional
behaviour, i.e., ensures unique results (see Sect. 8.2.1 and Def. 8.10). In addition
to that, their execution does not require backtracking. This means that once an op-
erational translation rule is applied, we do not have to undo the step during the
synchronisation process.
A system of operational translation rules has functional behaviour and does not
require backtracking if all signiﬁcant critical pairs are strictly conﬂuent, as shown
by Fact 9 in [HEO+11b], based on the corresponding result for forward translation
rules (see Theorem 8.29).
Remark 9.22 (Analysis of functional behaviour and backtracking). The tool
AGG [AGG14] provides an analysis engine for generating the complete set of crit-
ical pairs. On this basis, Rem. 8.51 provides suﬃcient conditions for deterministic
operational translation rules and we provide the analysis results for our example
TGG in Fact 9.24.
△
Theorem 9.23 below shows that termination and strict conﬂuence of the set of
signiﬁcant critical pairs ensures the required conditions for deterministic behaviour.
Theorem 9.23 (Deterministic synchronisation operations). Let TGG be a triple
graph grammar and let TR+
CC, TR+s
FT, and TR+t
BT be the derived sets of kernel transla-
tion rules. If the signiﬁcant critical pairs of the sets of operational translation rules
are strictly conﬂuent and the systems of rules are terminating, then the sets of op-
erational translation rules are deterministic (see Def. 8.49), which implies that the
derived synchronisation operations fPpg and bPpg are deterministic as well.
△
Proof (Idea). The operations fAln and bAln are given by pullback constructions,
which are unique up to isomorphism by deﬁnition. Therefore, they are deterministic.

9.2 Basic Model Synchronisation
273
Fig. 9.20 Dependency analysis with AGG for TRFT—ﬁelds with “1” contain dependencies
Termination of Del, fAdd, and bAdd is ensured according to Lem. 8.47, because the
operational translation rules are given by TR+
CC, TR+s
FT, and TR+t
BT. By Theorem 8.29
we know that functional behaviour of the transformation systems is ensured and
backtracking is not required if all signiﬁcant critical pairs are strictly conﬂuent and
the system is terminating. This ensures that the operations Del, fAdd, and bAdd are
deterministic. Thus, also the operations fPpg and bPpg are deterministic. For the
full proof, see Fact 1 in [HEO+11b].
⊓⊔
By Fact 9.20, we know that the synchronisation operations in the running exam-
ple are terminating. Fact 9.24 below shows that the derived sets of operational rules
are deterministic and kernel-grounded (see Def. 8.49) using the fact that they are
terminating (Theorem 9.23) and using the sets of critical pairs generated with the
tool AGG.
Fact 9.24 (Case study: determinism). The derived sets of operational rules for
fPpg and bPpg of our example TGG are deterministic and kernel-grounded.
△
Proof. We use the critical pair analysis engine of the tool AGG to show that the sets
are kernel-grounded and deterministic (see Def. 8.49). First, we show that they are
kernel grounded, i.e., the marking changing forward translation rules TR+s
FT (back-
ward translation rules TR+t
BT) do not depend on the marking preserving rules TR1s
FT
(TR1t
BT).
Concerning the set TRFT, we used AGG to derive the dependency table depicted
in Fig. 9.20. The source identic rules are the rules with numbers 6 to 8. There is
no dependency (entry > 0) for any pair (p, q) with p ≥6 and q ≤5. Moreover,
there are no target identic backward translation rules, because all triple rules are

274
9 Model Synchronisation
Fig. 9.21 Critical pair analysis with AGG for TRCC—ﬁelds with “1” contain conﬂicts
Fig. 9.22 Critical pair analysis with AGG for TRFT—ﬁelds with “1” contain conﬂicts
creating on the target component. Therefore, the sets of operational translation rules
are kernel-grounded.
By Fact 9.20, we know that the transformation systems based on the operational
translation rules are terminating. Concerning the set TRCC, we derive the resulting
table of critical pairs via AGG as depicted in Fig. 9.21. The only generated critical
pair is (p1, p1) for p1 = Person2FirstMarketingPCC and it is strictly conﬂuent by

9.2 Basic Model Synchronisation
275
Fig. 9.23 Dependency analysis with AGG for TRBT—ﬁelds with “1” contain dependencies
Fig. 9.24 Critical pair analysis with AGG for TRBT—ﬁelds with “1” contain conﬂicts
applying rule p2 = Person2NextMarketingPCC to the remaining structure, and since
p2 does not contain any NAC we automatically have strict conﬂuence.
Concerning the set TRFT, we derived the resulting table depicted in Fig. 9.22,
where we used the constraint that there are no two departments with name Market-
ing. This is always ensured for the language L(TGG) due to the NACs of the ﬁrst
two rules (see Def. 8.25 and Lem. 8.28).
The only signiﬁcant critical pair is strictly conﬂuent via one transformation step
using the rule p2 = Person2NextMarketingPFT, where no NAC is involved.

276
9 Model Synchronisation
The set TRBT is not functional, because there is a choice of how to split the salary
into base and bonus. We can restrict the choice for the rule DetailedSalary2Salary
to base = bonus = 1/2·salary as a policy, which is shown by the additional positive
application condition in Fig. 9.12. We apply Fact 8.43 and derive that the policy is
conservative. First of all, no other rule depends on this rule, which we have veriﬁed
by the generated dependency table by AGG in Fig. 9.23. Moreover, any match for
the original rule implies that there is a match for the restricted rule, because the
restricted values are real numbers. We derive the table of generated critical pairs de-
picted in Fig. 9.24, where the only signiﬁcant critical pair is again strictly conﬂuent
via one transformation step using rule p2 = Person2NextMarketingPBT, where no
NAC is involved.
Summing up, the sets of operational translation rules are kernel-grounded and all
signiﬁcant critical pairs are strictly conﬂuent, such that we can apply Theorem 9.23
and derive that the derived sets of operational rules are deterministic.
⊓⊔
We now analyse correctness and completeness. A correct synchronisation frame-
work has to satisfy laws (a1)–(b2) in Def. 9.7. Intuitively, the propagation operations
have to preserve consistent inputs. First of all, if the given integrated model is al-
ready consistent and the given update does not change anything, then the resulting
integrated model has to be the given one and the resulting update on the opposite
domain has to be the identity (laws (a1) and (b1)). Most importantly, given an arbi-
trary integrated model together with a source update dS : GS →G′S with consistent
new source model G′S ∈L(TGG)S , the forward propagation via fPpg has to pro-
vide a new consistent integrated model G′S ↔G′T ∈L(TGG). Completeness of a
synchronisation framework Synch(TGG) requires that the operations fPpg and bPpg
can be successfully applied to all consistent source models G′S ∈L(TGG)S and tar-
get models G′T ∈L(TGG)T, respectively. This property is of general importance in
the context of TGGs, and therefore we explicitly show it together with correctness in
Theorem 9.25 below. Both results are ensured if the sets of the operational rules are
deterministic as in Theorem 9.23 and, additionally, if they are kernel-grounded (see
Def. 8.49), i.e., the eﬀective forward and backward translation rules do not depend
on any source or target identic translation rule, respectively. This second condition
is important for laws (a1)–(b2), because it ensures that the computed transforma-
tion sequences via auxiliary operations Del, fAdd, and bAdd can be composed in a
consistent way.
Theorem 9.25 (Correctness and completeness). Let Synch(TGG) be a derived
TGG synchronisation framework such that the sets of operational translation rules
derived from TGG are kernel-grounded and deterministic (see Def. 8.49). Then
Synch(TGG) is correct and complete.
△
Proof (Idea). By Theorem 9.23, the provided constructions of operations fPpg and
bPpg based on the operational translation rules have functional behaviour, i.e., for
each input the computation yields a unique output. Thus, the derived synchronisa-
tion framework is complete.
In order to show correctness, we have to show laws (a1) and (a2) of Def. 9.7.
The precondition G ∈L(TGG) of law (a1) implies that there is a triple sequence

9.2 Basic Model Synchronisation
277
∅=
tr∗
=⇒G via TR, and by Fact 9.15 there is a corresponding complete consistency
creating sequence. Moreover, there is a corresponding forward translation sequence
via TRFT by Thm. 1 in [HEGO10]. Using the precondition that the operational trans-
lation rules are kernel-grounded, we can conclude that all steps via TR1s
FT can be
shifted to the end. Thus, no further forward translation rule in TR+s
FT is applicable.
The functional behaviour of the operation fPpg and the given identical source up-
date ds = idGS ensure the requested result, i.e., we derive the target update dT = idGT
and the integrated model G′ = G. In order to show law (a2), we can use precondition
G′S ∈L(TGG)S , which implies that there is a source consistent forward sequence
sF starting at G′S and a corresponding complete forward translation sequence. Since
the operational rules are kernel-grounded we can conclude by Rem. 8.52 that there is
a complete forward translation sequence s+s
FT via TR+s
FT. Due to functional behaviour
of the operation Del we derive a consistency creating sequence that corresponds to
the ﬁrst part of sF, and therefore to a sequence sFT via forward translation rules.
Since the sets of operational rules are kernel-grounded, we can conclude that the
steps via TR+s
FT do not depend on TR1s
FT. This allows us to complete sFT using TR+s
FT,
where we can shift the source identic steps via TR1s
FT to the end. Thus, we derive
a complete forward translation sequence, where we can omit the steps via TR1s
FT at
the end. Functional behaviour of TR+s
FT implies that this sequence corresponds to the
complete forward translation sequence s+s
FT, and therefore to a source consistent for-
ward sequence s+s
F leading to G′. Thus, G′ ∈L(TGG) by Theorem 8.7. For the full
proof see Lemma 3 in [HEO+11b].
⊓⊔
The initially derived set of backward transformation rules for our running exam-
ple is not completely deterministic because of the nondeterministic choice of base
and bonus values for propagating the change of a salary value. Therefore, we have
deﬁned a conservative policy for the responsible backward triple rule by ﬁxing the
propagated values of modiﬁed salary values to bonus = base = 0.5 · salary. By
Fact 8.43 in Sect. 8.3, we have provided a suﬃcient static condition for checking
that a policy is conservative; we have validated our example and have shown that
the derived sets of operational rules for fPpg and bPpg are deterministic and kernel-
grounded (see Fact 9.24 in Sect. 9.2.2). For this reason, we can apply Theorem 9.25
and conclude that the derived TGG synchronisation framework is correct and com-
plete (see Fact 9.26 below).
Fact 9.26 (Case study: correctness and completeness). The derived synchronisa-
tion framework for our example TGG is correct and complete.
△
Proof. By Fact 9.24, we know that the sets of operational rules of our example TGG
are deterministic and kernel-grounded. This allows us to apply Theorem 9.25 and
we derive that the derived synchronisation framework is correct and complete.
⊓⊔
Remark 9.27 (Model synchronisation for CD2RDBM). The TGG CD2RDBM of our
example for Chapters 7 and 8 does not satisfy the conditions we require in The-
orem 9.25 to ensure a correct and complete model synchronisation framework. In
fact, the operational translation rules are not deterministic as required by Theo-
rem 9.25 for the following reason (see also Ex. 8.50). The backward translation

278
9 Model Synchronisation
rules are not terminating, because the rule SubClass2TableBT is identic on the tar-
get domain and it cannot be omitted, because several other rules depend on it, e.g.,
an application of rule Attr2ColumnBT (see Fig. 3.8 for the TGG rules) may de-
pend on the correspondence node that is created by SubClass2TableBT. However,
from an application point of view, one can argue that the inheritance information
of a class diagram gets lost via the forward model transformation, and thus it is
just natural to omit the creation of new inheritance links via the backward transfor-
mation. Indeed, leaving out the rule SubClass2TableBT seems to be the practical
choice to obtain a model synchronisation framework that is possibly correct and
complete. Future work may provide alternative conditions that also handle TGGs
like CD2RDBM.
△
Now we present techniques and results for analysing invertibility of a model
synchronisation framework. Intuitively, invertibility means that the propagation op-
erations are inverse to each other (see Def. 9.7). Weak invertibility requires this
property for a restricted set of inputs, namely those where the given update on one
domain can be interpreted as the result of a propagation of an update from the corre-
sponding opposite domain. In addition to the conditions for ensuring a correct syn-
chronisation framework (Theorem 9.25), the notions of pure and tight TGGs allow
us to ensure these properties in Theorem 9.29 below. If the source identic triple rules
are empty rules on the source and correspondence components, and analogously for
the target-identic triple rules, then we say that the TGG is pure. This condition is
used to ensure weak invertibility according to Theorem 9.29 below. In the more spe-
ciﬁc case that all triple rules of a TGG are creating on the source and target compo-
nents (TR = TR+s = TR+t), the TGG is called tight, because the derived forward and
backward rules are strongly related. Eﬀectively, a tight TGG ensures for the opera-
tional forward and backward translation rules that each of them changes at least one
translation attribute. In other words, for each triple rule tr there is a derived forward
translation rule trFT ∈TR+s
FT and a derived backward translation rule trBT ∈TR+t
BT.
This additional property ensures invertibility according to Theorem 9.29 below.
Deﬁnition 9.28 (Pure and tight TGG). A TGG is called pure if TR1s ⊆TRT and
TR1t ⊆TRS . It is called tight if the sets of source and target creating rules TR+s and
TR+t coincide with the set of triple rules TR, i.e., TR = TR+s = TR+t.
△
Theorem 9.29 (Invertibility and weak invertibility). Let Synch(TGG) be a de-
rived TGG synchronisation framework such that the sets of operational translation
rules of TGG are kernel-grounded and deterministic (see Def. 8.49), TGG is pure
and at most one set of operational translation rules was extended by a conservative
policy; then Synch(TGG) is weakly invertible. If, moreover, TGG is tight and there
was no policy applied at all, then Synch(TGG) is also invertible.
△
Proof (Idea). To prove the weak invertibility law (c1) in Fig. 9.5, we can ﬁrst show
that the intermediate triple graphs after applying (bAln, Del) and (fAln, Del) accord-
ing to Figs. 9.14 and 9.17 are the same for the steps in the last two diagrams of (c1).
We compute all three diagrams of (c1) and obtain consistency creating sequences

9.2 Basic Model Synchronisation
279
via Del for each diagram using the precondition that the operational rules are de-
terministic (which subsumes termination). Moreover, we derive that the second and
the third diagrams contain the same intermediate triple graph Gl. Afterwards, the
auxiliary operations fAdd and bAdd for all three diagrams can be executed. We can
use the composition and decomposition result for TGGs and the requirements that
the TGG be pure, deterministic and preserve functional behaviour. If at most one set
of operational translation rules is extended by a conservative policy, the proof shows
that backward transformation sequences are not eliminated by the policy. This al-
lows us to obtain the resulting diagrams according to law (c1). The proof for axiom
(c2) follows out of the symmetry of the deﬁnitions. To prove invertibility (laws (d1)
and (d2)), we use the preconditions that no policy is applied and that the TGG is
tight, i.e., all rules are source and target creating. This ensures that for each forward
translation sequence there is a corresponding backward translation sequence. For
the full proof see Thm. 1 in [HEO+11b], where sets of operational rules are called
deterministic if they are kernel-grounded and deterministic using the notions of this
chapter.
⊓⊔
In our example TGG, the sets of operational translation rules are kernel-grounded
and deterministic according to Fact 9.24 in Sect. 9.2.2. Moreover, the TGG is pure
and we have used the conservative policy for the backward direction only. Thus,
Theorem 9.29 ensures that Synch(TGG) is weakly invertible (see Fact 9.30 below).
Fact 9.30 (Case study: weak invertibility). The derived synchronisation frame-
work for our example TGG is weakly invertible.
△
Proof. In order to apply Theorem 9.29 concerning weak invertibility, we have to
show that the TGG is pure (see Def. 9.28) and at most one set of operational rules
was restricted by a conservative policy (see Def. 8.49). The used policy for the
set of backward translation rules is conservative, which we have shown already in
Fact 9.26. No further policy is applied and the TGG is pure, because each rule is
either creating on the source and target component, or it is creating either on the
source or the target component and empty on the other components. Therefore, we
can apply Theorem 9.29 and derive weak invertibility.
⊓⊔
An intuitive example for weak invertibility is shown in Ex. 9.8 in Sect. 9.1, where
we also show by counterexample that the derived synchronisation framework for our
example TGG is not invertible in the general sense. The reason is that information
about birth dates is stored in one domain only. The automated validation for our ex-
ample TGG with eight rules was performed in 25 seconds on a standard consumer
notebook via the analysis engine of the tool AGG [AGG14]. We are conﬁdent that
the scalability of this approach can be signiﬁcantly improved with additional opti-
misations.
Remark 9.31 (Applicability of the approach). We have provided suﬃcient condi-
tions ensuring correctness and completeness (Theorem 9.25) which can be checked
statically. In the following, we discuss these restrictions with respect to relevant
application scenarios.

280
9 Model Synchronisation
1. Determinism: Most importantly, we require that the derived sets of operational
rules be deterministic, i.e., the forward and backward propagation operations en-
sure unique results. In several application domains, this property is already a
requirement by the domain experts, i.e., has to be ensured anyhow. For example,
unique results are often required for the synchronisation between visual models
and implementation code, i.e., for code generation and reverse engineering. Note
as well that one can modify existing triple rules to enforce determinism based on
the discussed critical pair analysis of a TGG using the tool AGG. For example,
the designer may insert additional correspondence nodes (trace links) to enforce
determinism and avoid conﬂicts between rules. The condition for determinism
does not seem to conﬁne the expressiveness of TGG rules. In a large-scale indus-
trial project, we have used a TGG for the fully automated translation of satellite
control software [HGN+14], where the used TGG contains more than 200 rules.
The forward translation has functional behaviour as required by the industrial
partner. As a general recommendation based on the experiences from this project,
we can state that a designer of a TGG should divide the rules in small groups,
such that there are no cyclic dependencies between the groups.
2. Kernel-grounded sets of operational rules: Intuitively, the restriction to kernel-
grounded rules concerns the possibility that one domain may contain information
that is not present in the corresponding opposite domain. When translating from
one domain to another, we apply only those rules that are changing at least one
translation attribute (TR+s
FT and TR+t
BT). Thus, we require that the structures that
concern only one domain be handled separately by triple rules that are the identity
on the corresponding opposite domain (TR1s
FT and TR1t
BT). In addition to that, these
sets of rules do not create structures that may be needed by the ﬁrst group of
rules. This means that the restriction to kernel-grounded sets of operational rules
restricts the freedom mainly of how to design the TGG and usually not of the
problem and application domain.
The result on invertibility (Theorem 9.29) requires additional properties. Weak
invertibility is ensured if the TGG is pure and at most one of the sets of operational
rules is extended by a conservative policy. While this condition is not very restrictive
in the experience of the authors, the stronger condition for invertibility requiring a
tight TGG practically means that all pieces of information in one domain are also
reﬂected in the corresponding opposite domain. This result is consistent with Diskin
et al.’s analysis of strong invertibility [DXC+11b].
△
In the case that the speciﬁed TGG does not ensure deterministic synchronisation
operations, there are still two options for performing synchronisation that ensure
correctness and completeness. On the one hand, the triple rules can be modiﬁed
in a suitable way, such that the TGG can be veriﬁed to be deterministic. For this
purpose, the critical pair analysis engine of the tool AGG [AGG14] can be used
to analyse conﬂicts between the generated operational translation rules. Moreover,
backtracking can be reduced or even eliminated by generating additional application
conditions for the operational translation rules using the automatic generation of
ﬁlter NACs (see Fact 8.18 based on [HEGO10, HEGO14]). On the other hand, the

9.3 Concurrent Model Synchronisation
281
TGG can be used directly, leading to nondeterministic synchronisation operations,
which may provide several possible synchronisation results [GHN+13].
9.3 Concurrent Model Synchronisation
Based on the basic framework for model synchronisation in the previous sections,
we now provide a correct TGG framework for concurrent model synchronisation,
where concurrent model updates in diﬀerent domains have to be merged into a con-
sistent solution. In this case, we have the additional problem of detecting and solv-
ing conﬂicts between given updates. Such conﬂicts may be hard to detect, since they
may be caused by concurrent updates on apparently unrelated elements of the given
models. Furthermore, there may be apparently contradictory updates on related ele-
ments of the given domains which may not be real conﬂicts.
This section is based on [HEEO12]. The main idea and results for the approach
for concurrent model synchronisation based on TGGs are as follows:
1. Model synchronisation is performed by propagating the changes from one model
of one domain to a corresponding model in another domain using forward and
backward propagation operations. The propagated changes are compared with
the given local update. Possible conﬂicts are resolved in a semiautomated way.
2. The operations are realised by model transformations based on TGGs [HEO+11a]
and tentative merge constructions solving conﬂicts [EET11]. The speciﬁed TGG
also deﬁnes consistency of source and target models.
3. In general, the operation of model synchronisation is nondeterministic, since
there may be several conﬂict resolutions. The diﬀerent possible solutions can
be visualised to the modellers, who then decide which modiﬁcations to accept or
discard.
4. The main result shows that the concurrent TGG synchronisation framework is
correct and compatible with the basic synchronisation framework (see Sect. 9.2),
where only single updates are considered at the same time.
9.3.1 Concurrent Synchronisation Problem
Concurrent model synchronisation aims to provide a consistent merging solution for
a pair of concurrent updates that are performed on two interrelated models. This sec-
tion provides a formal speciﬁcation of the concurrent synchronisation problem and
the corresponding notion of correctness. At ﬁrst, we motivate the general problem
with a compact example.
Example 9.32 (Concurrent model synchronisation problem). Fig. 9.25 shows two
models in correspondence. Two model updates have to be synchronised concur-
rently: on the source side (model update dS
1 ), the node Paul Page is deleted and

282
9 Model Synchronisation
Fig. 9.25 Concurrent model synchronisation: compact example
the family name of Lilly Lee changes due to her marriage; moreover, since she is
married, her bonus is raised from 1,000 to 2,000. On the target side (model update
dT
1 ), Paul Page is switching from the marketing to the technical department (in the
visualisation in Fig. 9.25 this is indicated by a diﬀerent role icon and the label M is
replaced by label T). The department change is combined with a salary raise from
5,000 to 6,000. After performing the updates dS
2 and dT
2 , a “consistently integrated
model” is derived that reﬂects as many changes as possible from the original updates
in both domains and resolves inconsistencies, e.g., by computing the new Salary of
Lily Lee in the target domain as the sum of the updated source attributes Base and
Bonus. Note that Paul Page is not deleted in the target domain by the concurrent
model synchronisation because in this case the changes required by dT
1 could not
have been realised. This conﬂict can be considered an apparent one. If a person
leaves the marketing department, but not the company, its node should remain in the
target model. Thus, a concurrent model synchronisation technique has to include an
adequate conﬂict resolution strategy.
△
The concurrent model synchronisation problem is visualised in Fig. 9.26, where
we use solid lines for the inputs and dashed lines for the outputs. Given an inte-
grated model G0 = (GS
0 ↔GT
0 ) and two model updates dS
1 = (GS
0 →GS
1 ) and
dT
1 = (GT
0 →GT
1 ), the required result consists of updates dS
2 = (GS
1 →GS
2 )
and dT
2 = (GT
1 →GT
2 ) and a consistently integrated model G2 = (GS
2 ↔GT
2 ).
The solution for this problem is a concurrent synchronisation operation CSynch,
which is left total but in general nondeterministic, which we indicate by a wiggly
arrow “{” in Def. 9.33 below. The set of inputs is given by (Rel ⊗∆S ⊗∆T) =
{(r, dS , dT) ∈Rel × ∆S × ∆T | r: GS
0 ↔GT
0 , dS : GS
0 →G2S , dT : GT
0 →G2T}, i.e., r
coincides with dS on GS
0 and with dT on GT
0 .
Deﬁnition 9.33 (Concurrent model synchronisation problem and framework).
Given a triple graph grammar TGG, the concurrent model synchronisation problem
is to construct a left total and nondeterministic operation CSynch : (Rel⊗∆S ⊗∆T) {
(Rel × ∆S × ∆T) leading to the signature diagram in Fig. 9.26, called concurrent syn-
T
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=4000
Paul Page
*1945-01-01
Salary=5000
Paul Page
Base=3500
Bonus=1500
Lily Lee
Base=3000
Bonus=1000
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=4000
Lily Archer
Base=3000
Bonus=2000
M
M
M
M
M
M
T
T
Alex Archer
*1955-01-01
Salary=6000
Lily Archer
*1965-01-01
Salary=5000
Lily Archer
Base=3000
Bonus=2000
M
M
T
Paul Page
*1945-01-01
Salary=6000
T
Paul Page
*1945-01-01
Salary=6000

9.3 Concurrent Model Synchronisation
283
Signature
Laws
GS
1
dS
2 
GS
0
dS
1
o
o
r0
/
:CSynch

GT
0
dT
1 / GT
1
dT
2

GS
2 o
r2
/ GT
2
∀c ∈C :
GS
1 
⇓:CSynch
GS
1
o
o
c / GT
1 / GT
1
GS o
c
/ GT
(a)
GS
1
dS
2 
⇓:CSynch
GS
0 o
r0 /
dS
1
o
GT
0
dT
1 / GT
1
dT
2

G2S o
r2:C
/ G2T
(b)
Fig. 9.26 Signature and laws for correct concurrent model synchronisation frameworks
chronisation tile with concurrent synchronisation operation CSynch. Given a pair
(prem, sol) ∈CSynch, the triple prem = (r0, dS
1 , dT
1 ) ∈Rel⊗∆S ⊗∆T is called premise
and sol = (r2, dS
2 , dT
2 ) ∈Rel × ∆S × ∆T is called a solution of the synchronisation
problem, written sol ∈CSynch(prem). The operation CSynch is called correct with
respect to the consistency relation C if laws (a) and (b) in Fig. 9.26 are satisﬁed for
all solutions. Given a concurrent synchronisation operation CSynch, the concurrent
synchronisation framework CSynch is given by CSynch = (TGG, CSynch). It is
called correct if the operation CSynch is correct.
△
Correctness of a concurrent synchronisation operation CSynch according to
Fig. 9.26 ensures that any resulting integrated model G2 = (GS
2 ↔GT
2 ) is con-
sistent (law (b)) and the synchronisation of an unchanged and already consistently
integrated model always yields the identity of the input as output (law (a)).
9.3.2 Concurrent Model Synchronisation with Conﬂict Resolution
In addition to the propagation operations used for the basic model synchronisation
framework in Sect. 9.2, the concurrent case requires additional steps. The most im-
portant one is conﬂict resolution, and we use the constructions and results for con-
ﬂict resolution in a single domain according to [EET11]. Note that we apply conﬂict
resolution either to two conﬂicting target model updates (one of them induced by
a forward propagation operation fPpg) or to two conﬂicting source model updates
(one of them induced by backward propagation). Hence, we here consider updates
over standard graphs and not over triple graphs. Moreover, we use additional TGG-
speciﬁc operations that restrict the constructed intermediate models to those that are
consistent with the given TGG.
Two graph modiﬁcations (G ←Di →Hi), (i = 1, 2) are called conﬂict-free
if they do not interfere with each other, i.e., if one modiﬁcation does not delete
a graph element, the other one needs to perform its changes. Conﬂict-free graph
modiﬁcations can be merged to one graph modiﬁcation (G ←D →H) that realises
both original graph modiﬁcations simultaneously.

284
9 Model Synchronisation
If two graph modiﬁcations are not conﬂict-free, then at least one conﬂict oc-
curs which can be of the following kinds: (1) delete–delete conﬂict: both modiﬁca-
tions delete the same graph element, or (2) delete–insert conﬂict: m1 deletes a node
which shall be the source or target of a new edge inserted by m2 (or vice versa).
Of course, several of such conﬂicts may occur simultaneously. In [EET11], we pro-
pose a merge construction that resolves conﬂicts by giving insertion priority over
deletion in case of delete–insert conﬂicts. The result is a merged graph modiﬁcation
where the changes of both original graph modiﬁcations are realised as far as possi-
ble.1 We call this construction tentative merge because usually the modeller is asked
to ﬁnish the conﬂict resolution manually, e.g., by opting for deletion instead of in-
sertion of certain conﬂicting elements. The resolution strategy to prioritise insertion
over deletion preserves all model elements that are parts of conﬂicts and allows us
to highlight these elements to support manual conﬂict resolution. We summarise the
main eﬀects of the conﬂict resolution strategy by Fact 9.34 below (see also Thm. 3
in [EET11] for the construction).
Fact 9.34 (Conﬂict resolution by tentative merge construction). Given two con-
ﬂicting graph modiﬁcations mi = G
Di
=⇒Hi (i = 1, 2) (i.e., they are not conﬂict-free).
The tentative merge construction yields the merged graph modiﬁcation m = (G ←
D →H) and resolves conﬂicts as follows:
1. If (m1, m2) are in delete–delete conﬂict, with both m1 and m2 deleting x ∈G, then
x is deleted by m.
2. If (m1, m2) are in delete–insert conﬂict, there is an edge e2 created by m2 with
x = s(e2) or x = t(e2) preserved by m2, but deleted by m1. Then x is preserved by
m (and vice versa for (m2, m1) in delete–insert conﬂict).
△
Note that attributed nodes, which shall be deleted on the one hand and change
their values on the other hand, would cause delete/insert–conﬂicts and therefore
would not be deleted by the tentative merge construction. Attributes which are dif-
ferently changed by both modiﬁcations would lead (tentatively) to attributes with
two values. In many cases, the domain languages require single-valued attributes,
which means that the user has to restore the conﬂict and choose the value for the
attribute.
G0
m1
/
m2  u:Res
G1

G2
/ H
Throughout the paper, we depict conﬂict resolution based on
the tentative merge construction and manual modiﬁcations as
shown to the right, where m1 and m2 are conﬂicting graph mod-
iﬁcations, and H is their merge after conﬂict resolution. The
dashed lines correspond to derived graph modiﬁcations (G1 ←D3 →H) and
(G2 ←D4 →H) with interfaces D3 and D4.
Example 9.35 (Conﬂict resolution by tentative merge construction). Consider the
conﬂict resolution square 3:Res in the upper right part of Fig. 9.29. The ﬁrst mod-
iﬁcation dT
1,F deletes the node for Paul Page and updates the attribute values for
1 Note that the conﬂict-free case is a special case of the tentative merge construction.

9.3 Concurrent Model Synchronisation
285
GS
1
u:CCS
dS
1,C
0
GS
0
dS
1
o
dS
1,C◦dS
1

GS
1,C
GT
0
w:CCT
dT
1,C◦dT
1 
dT
1
/ GT
1
dT
1,C
n
GT
1,C
Fig. 9.27 Consistency creating operations
Surname and Salary of Lily Lee. The second modiﬁcation dT
1 relinks the node of
Paul Page from the marketing department to the technical department and updates
his Salary attribute. The result of the tentative merge construction keeps the Paul
Page node, due to the policy that nodes that are needed as source or target for newly
inserted edges or attributes will be preserved. Technically, the attribute values are
not preserved automatically. This means that the tentative merge construction only
yields the structure node of Paul Page (and the updated attribute), and the modeller
should conﬁrm that the remaining attribute values should be preserved (this is nec-
essary for the attribute values for FirstName, LastName and Birth of the node for
Paul Page).
Variant: As a slight variant to the above example, let us consider the case that the
modiﬁcation dT
1 also modiﬁes the surname of Lily from “Lee” to “Smith”. Since the
same attribute is updated diﬀerently by both modiﬁcations, we now have two tenta-
tive attribute values for this attribute (we would indicate this by <Archer|Smith> as
attribute value for the Surname attribute of Lily). This can be solved by the user as
well, who should select the proper attribute value.
△
The merge construction cannot be applied directly to detect and solve conﬂicts
in concurrent model synchronisation. The problem is that source and target updates
occur in diﬀerent graphs and not the same one. To solve this problem we use the
forward and backward propagation operations (Sect. 9.2), allowing us to see the
eﬀects of each source or target update on the other domain, so that we can apply
the merge construction. In addition, we use two further operations, CCS and CCT,
to reduce a given domain model to a maximal consistent submodel according to the
TGG.
Given a source update dS
1 : GS
0 →GS
1 , the consistency creating operation CCS
(left part of Fig. 9.27) computes a maximal consistent subgraph GS
1,C ∈L(TGG)S
of the given source model GS
1 . The resulting update from GS
0 to GS
1 is derived by
update composition dS
1,C ◦dS
1 . The dual operation CCT (right part of Fig. 9.27)
works analogously on the target component.
Remark 9.36 (Execution of consistency creating operation CCS). Given a source
model GS
1 , the consistency creating operation CCS is executed by computing ter-
minated forward sequences (H0 =
tr∗
F
==⇒Hn) with H0 = (GS
1 ←∅→∅). If the sets
of operational rules of the TGG are deterministic (see Def. 8.49 and Rem. 8.51),
then backtracking is not necessary. If GS
1 is already consistent, then GS
1,C = GS
1 ,

286
9 Model Synchronisation
Signature
GS
1
dS
2 
GS
0
dS
1
o
o
r0
/
⇓:fSynch
GT
0
dT
1
/ GT
1
dT
2

GS
2 o
r2
/ GT
2
Deﬁnition
of
Components
GS
1
u1:CCS
dS
F
0
dS
2,FCB
/
GS
0
dS
1
o
o
r0
/
dS
1,CC

u2:fPpg
GT
0
dT
1,F

dT
1
/
u3:Res
GT
1
dT
2,FC

GS
1,C o
r1,F
/
dS
2,CB 
w5:bPpg
GT
1,F
d′T
2,FC
/
dT
2,CC

GT
2,FC
dT
B
n
w4:CCT
GS
2,FCB o
r2,FCB
/ GT
2,FCB
dS
2,FCB = dS
2,CB ◦dS
F
GS
2 = GS
2,FCB
dT
2,FCB = dT
B ◦dT
2,FC
GT
2 = GT
2,FCB
(r2, dS
2 , dT
2 ) = (r2,FCB, dS
2,FCB, dT
2,FCB)
Fig. 9.28 Concurrent model synchronisation with conﬂict resolution (forward case: fSynch)
which can be checked via the operation CCS. Otherwise, the operation CCS cre-
ates a maximal consistent subgraph GS
1,C of GS
1 . GS
1,C is maximal in the sense that
there is no larger consistent submodel HS of GS
1 , i.e., with GS
1,C ⊆HS ⊆GS
1 and
HS ∈L(TGG)S . From the practical point of view, the operation CCS is performed
using forward translation rules (see Sect. 7.4), which mark in each step the elements
of a given source model that have been translated so far. This construction is well
deﬁned due to the equivalence with the corresponding triple sequence (∅=
tr∗
=⇒Hn)
via the triple rules TR of the TGG (see Fact 7.36 and App. B in [HEEO11]).
△
The concurrent model synchronisation operation CSynch derived from the given
TGG is executed in ﬁve steps. Moreover, it combines the operations fSynch and
bSynch depending on the order in which the steps are performed. The used propa-
gation operations fPpg, bPpg are required to be correct and we can take the derived
propagation operations according to Sect. 9.2. The steps of the operation fSynch are
depicted in Fig. 9.28 and Construction 9.37 describes the steps for both operations.
Construction 9.37 (Operations fSynch and bSynch). In the ﬁrst step (operation
CCS), a maximal consistent subgraph GS
1,C ∈L(TGG)S of GS
1 is computed (see
Rem. 9.36). In Step 2, the update dS
1,CC is forward propagated to the target do-
main via the operation fPpg. This leads to the pair (r1,F, dT
1,F), and thus to the pair
(dT
1,F, dT
1 ) of target updates, which may show conﬂicts. Step 3 applies the conﬂict
resolution operation Res including optional manual modiﬁcations. In order to en-
sure consistency of the resulting target model GT
2,FC, we apply the consistency cre-
ating operation CCT (see Rem. 9.36) for the target domain and derive the target
model GT
2,FCB ∈L(TGG)T in Step 4. Finally, the derived target update dT
2,CC is

9.3 Concurrent Model Synchronisation
287
Fig. 9.29 Concurrent model synchronisation with conﬂict resolution applied to the organisational
model example
backward propagated to the source domain via the operation bPpg, leading to the
source model GS
2,FCB and the source update dS
2,CB. Altogether, we have constructed
a nondeterministic solution (r2, dS
2 , dT
2 ) of the operation fSynch for the premise
(r0, dS
1 , dT
1 ) with (r2, dS
2 , dT
2 ) = (r2,FCB, dS
2,FCB, dT
2,FCB) (see Fig. 9.28). The concur-
rent synchronisation operation bSynch is executed analogously via the dual con-
structions. Starting with CCT in Step 1, it continues via bPpg in Step 2, Res in
Step 3, and CCS in Step 4, and ﬁnishes with fPpg in Step 5. The nondeterministic
operation CSynch = (fSynch ∪bSynch) is obtained by joining the two concurrent
synchronisation operations fSynch and bSynch.
△
Example 9.38 (Concurrent model synchronisation with conﬂict resolution). The
steps in Fig. 9.29 specify the execution of the concurrent synchronisation in
Ex. 9.32. Since the given model GS
0 is consistent, Step 1 (1:CCS) can be omit-
ted, i.e., GS
1,C = GS
1 and dS
1,CC = dS
1 . Step 2:fPpg propagates the source update to
the target domain: The attributes of the node for Lilly Lee are updated and the node
representing Paul Page is deleted. The resolution 3:Res resolves the conﬂict be-
tween the target model update dT
1 and the propagated source model update on the
target side dT
1,F (see Ex. 9.35). We assume that the user selected the old attribute
value for the birthday of Paul Page. Step 4:CCT does not change anything, since
the model is consistent already. Finally, all elements that were introduced during
the conﬂict resolution and concern the source domain are propagated to the source
model via (5:bPpg). This concerns only Paul Page, who now is assigned to the
technical department. According to the TGG, such persons are not reﬂected in the
source model, such that the backward propagation does not change anything in the
source model. The result of the concurrent model synchronisation with conﬂict res-
T
T
T
T
M
M
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=4000
Paul Page
*1945-01-01
Salary=5000
Paul Page
Base=3500
Bonus=1500
Lily Lee
Base=3000
Bonus=1000
M
M
M
T
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=4000
Paul Page
*1945-01-01
Salary=6000
T
M
M
Alex Archer
*1955-01-01
Salary=6000
Lily Archer
*1965-01-01
Salary=5000
Lily Archer
Base=3000
Bonus=2000
M
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=5000
Paul Page
*1945-01-01
Salary=6000
Lily Archer
Base=3000
Bonus=2000
M
T
T
M
Alex Archer
*1955-01-01
Salary=6000
Lily Lee
*1965-01-01
Salary=5000
Paul Page
*1945-01-01
Salary=6000

288
9 Model Synchronisation
olution is r2,FCB, where as many as possible of both proposed update changes have
been kept and insertion got priority over deletion.
Variant: Let us consider the case that both modiﬁcations dT
1 dT
1,F insert addition-
ally an edge of type married between the nodes of Lilly Lee and Alex Archer. The
conﬂict resolution operation 3:Res would yield two married edges between the two
nodes. But the subsequent consistency creating operation 4:CCT would detect that
this is an inconsistent state and would delete one of the two married edges. Note
that the user can already detect this conﬂict in Step 3 and resolve it by deleting one
of the edges.
△
Remark 9.39 (Execution and termination of concurrent model synchronisation).
Note that the eﬃciency of the execution of the concurrent synchronisation opera-
tions can be signiﬁcantly improved by reusing parts of previously computed trans-
formation sequences as described in App. B in [HEEO11]. In [HEO+11a], we have
provided suﬃcient static conditions that ensure termination of the propagation op-
erations and they can be applied similarly for the consistency creating operations.
Update cycles cannot occur, because the second propagation step does not lead to a
new conﬂict.
△
Note that the operation CSynch is nondeterministic for several reasons: the
choice between fSynch and bSynch, the reduction of domain models to maximal
consistent sub graphs, and the semi-automated conﬂict resolution strategy.
Deﬁnition 9.40 (Derived concurrent TGG synchronisation framework).
Let
fPpg and bPpg be correct basic synchronisation operations for a triple graph gram-
mar TGG and let the operation CSynch be derived from fPpg and bPpg according
to Construction 9.37. Then the derived concurrent TGG synchronisation framework
is given by CSynch = (TGG, CSynch).
△
9.3.3 Correctness and Compatibility
Our main results show correctness of the derived concurrent TGG synchronisation
framework (Def. 9.40) and its compatibility with the derived basic TGG synchroni-
sation framework (Sect. 9.2). Correctness of a concurrent model synchronisation
framework requires that the nondeterministic synchronisation operation CSynch
ensures laws (a) and (b) in Def. 9.33. In other words, CSynch guarantees consis-
tency of the resulting integrated model and, moreover, the synchronisation of an
unchanged and already consistently integrated model always yields the identity of
the input as output (law (a)).
According to Theorem 9.41 below, correctness of given forward and backward
propagation operations ensures correctness of the concurrent model synchronisation
framework.
Theorem 9.41 (Correctness of concurrent model synchronisation).
Let fPpg
and bPpg be correct basic synchronisation operations for a triple graph gram-

9.3 Concurrent Model Synchronisation
289
mar TGG. Then the derived concurrent TGG synchronisation framework CSynch =
(TGG, CSynch) (see Def. 9.40) is correct (see Def. 9.33).
△
Proof.
∀c ∈C :
GS
1

⇓:CSynch
GS
1
o
o c / GT
1 / GT
1

GS o
c
/ GT
(a)
Law (a) in Fig. 9.26: Let (r, dS
1 , dT
1 ) ∈
(R ⊗∆S ⊗∆T) with r = c ∈C =
L(TGG) and identities dS
1
= idS :
GS
0 →GS
0 , dT
1
= idT : GT
0
→GT
0 ,
such
that
G
=
(GS ↔GT)
=
(GS
0 ↔GT
0 ) = G0. We have to show that the operation CSynch yields (c, idS , idT)
as result, i.e., no further result is possible.
We apply the operation fSynch according to Fig. 9.28 and Construction 9.37.
Since r = G0 ∈L(TGG) and GS
1 = GS
0 ∈L(TGG)S we know that there is a model
transformation sequence sF = (GS
1 ,G′
0 =
tr∗
F
==⇒G′
n,GT
1 ) based on forward rules using
the completeness result for model transformations based on forward rules (see The-
orem 8.4). Therefore, the operation CCS yields the maximal consistent subgraph
GS
1,C = GS
0 and update dS
1,CC = idS . By correctness of the operation fPpg (law (a1)
in Fig. 9.5) we derive that the second step yields the target model GT
1,F = GT
0 , the
correspondence r1,F = r and the target update dT
1,F = idT. Therefore, the resolu-
tion in Step 3 concerns the updates dT
1 = idT and dT
1,F = idT, which are parallel
independent by deﬁnition, leading to the merging result GT
2,FC = GT
0 and updates
dT
2,FC = idT and d′T
2,FC = idT. This means that manual modiﬁcation is not neces-
sary and therefore not executed. Again, since GT
0 ∈L(TGG)T we know that there
is a model transformation sequence sB = (GT
0 , H′
0 =
tr∗
B=⇒H′
n,GS
1 ) based on backward
translation rules using the dual version of the completeness result for model trans-
formations based on forward rules (see Theorem 8.4). Therefore, the operation CCT
yields the maximal consistent subgraph GT
2,FCB = GT
0 and update dT
B = idT. By cor-
rectness of the operation bPpg (law (b1) in Fig. 9.5) we derive that Step 5 yields the
source model GS
2,FCB = GS
0 , the correspondence r2,FCB = r1,F = r = c and the source
update dS
2,CB = idS . Altogether, the operation fSynch yields the result (c, idS , idT) as
required by law (a). The same result holds for the operation bSynch using the sym-
metry of the precondition and the symmetric deﬁnition of TGGs and the derived
operations. Therefore, the result holds for the concurrent synchronisation operation
CSynch.
GS
1
dS
2 
⇓:CSynch
GS
0 o r0 /
dS
1
o
GT
0
dT
1 / GT
1
dT
2

G2S o
r2:C
/ G2T
(b)
Law (b) in Fig. 9.26: Let (r0, dS
1 , dT
1 ) ∈(R ⊗
∆S ⊗∆T) as depicted on the right and in
Fig. 9.26. We have to show that the concurrent
synchronisation operation yields a consistent
correspondence r2 ∈L(TGG).
We apply the concurrent synchronisation
operation fSynch according to Fig. 9.28 and Construction 9.37. All steps are well

290
9 Model Synchronisation
GS
1 ∈L(TGG)S ,
GS
0 o
r0
/
dS  u:fPpg
GT
0
dT

GS
1 o
r1
/ G1T
⇒
GS
1
id 
GS
0
dS
o
o
r0
/
:CSynch

GT
0
id / GT
0
dT

GS
1 o
r1
/ GT
1
Fig. 9.30 Compatibility with synchronisation of single updates (forward case)
deﬁned according to Rem. 9.39. Step 4 (operation CCT) provides a maximal consis-
tent subgraph GT
2,FCB ∈L(TGG)T. Therefore, we can apply law (b2) in Fig. 9.5 and
derive that the operation bPpg in Step 5 yields a consistent correspondence r2 (see
Theorem 9.25). The proof for the concurrent synchronisation operation bSynch is
analogous using the symmetric deﬁnition of TGGs and the dual deﬁnitions of the
steps according to Rem. 9.39. Therefore, the concurrent synchronisation operation
CSynch always yields a consistent correspondence r2 ∈L(TGG).
⊓⊔
Example 9.42 (Correctness and compatibility). In Sect. 9.2, we have presented a
suitable realisation of correct propagation operations derived from the given TGG.
This allows us to apply the following main results in Theorem 9.41 and Theo-
rem 9.44 to our case study and we derive a concurrent model synchronisation frame-
work that is correct and compatible with the basic model synchronisation frame-
work.
△
In addition to correctness, we show that the concurrent TGG synchronisation
framework is compatible with the basic synchronisation framework. This means
that the propagation operations (fPpg, bPpg) (see Sect. 9.2) provide the same result
as the concurrent synchronisation operation CSynch if one update of one domain
is the identity. Fig. 9.30 visualises the case for the forward propagation operation
fPpg. Given a forward propagation (depicted left) with solution (r1, dT), a speciﬁc
solution of the corresponding concurrent synchronisation problem (depicted right)
is given by sol = (r1, id, dT), i.e., the resulting integrated model and the resulting
updates are the same. Due to the symmetric deﬁnition of TGGs, we can show the
same result concerning the backward propagation operation, leading to the general
result of compatibility in Theorem 9.44.
Deﬁnition 9.43 (Compatibility of concurrent with basic model synchronisa-
tion). Let fPpg, bPpg be basic TGG synchronisation operations and let CSynch be
a concurrent TGG synchronisation operation for a given TGG. The nondeterminis-
tic synchronisation operation CSynch is compatible with the propagation operations
fPpg and bPpg if the following condition holds for the forward case (see Fig. 9.30)
and a similar one for the backward case:
∀(dS , r0) ∈∆S ⊗Rel, with (dS : GS
0 →GS
1 ) ∧(GS
1 ∈L(TGG)S ):
(id, fPpg(dS , r0)) ∈CSynch(dS , r0, id)
△

9.4 Related and Future Work
291
Theorem 9.44 (Compatibility of concurrent with basic model synchronisation).
Let fPpg and bPpg be correct basic synchronisation operations for a given TGG and
let the operation CSynch be derived from fPpg and bPpg according to Construc-
tion 9.37. Then, the derived concurrent TGG synchronisation operation CSynch is
compatible with propagation operations fPpg, bPpg.
△
Proof. Let CSynch be obtained from the derived forward and backward synchroni-
sation operations fSynch and bSynch, i.e., CSynch = (fSynch ∪bSynch). Ac-
cording to Def. 9.43, we have to show for the forward case that
∀(dS , r0) ∈
∆S ⊗R with dS : GS
0 →GS
1 ∧GS
1
∈L(TGG)S it holds that (id, fPpg(dS , r0)) ∈
CSynch(dS , r0, id). The result for the backward case holds by dualisation due to
the symmetric deﬁnition of TGGs and the derived operations.
Let r0 = (GS
0 ↔GT
0 ) with GS
0 ∈L(TGG)S and let dS : GS
0 →GS
1 be a source
model update. Let further (r1, dT) be the result of applying fPpg to (dS , r0) with
r1 = (GS
1 ↔GT
1 ) and dT : GT
0 →GT
1 . We show that (id, r1, dT) ∈fSynch(dS , r0, id)
according to Fig. 9.28 and Construction 9.37. Since GS
1 ∈L(TGG)S , we have that
Step 1 (CCS) yields the maximal consistent subgraph GS
1,C = GS
1 (see Rem. 9.36)
and source update dS
F = id: GS
1 →GS
1 . Thus, Step 2 applies the operation fPpg
to the same input as in the precondition, such that we derive the correspondence
r1,F = r1 and target model update dT
1,F = dT. By correctness of fPpg (law (a2) in
Fig. 9.5) we know that r1 = r1,F ∈L(TGG), and therefore GT
1 ∈L(TGG)T. In Step
3 (operation Res), the merge construction is applied to dT and the target update
id, which does not delete or create anything (the corresponding minimal rule is the
empty rule). This means that the updates are conﬂict-free and the merge construction
yields the target updates d′T
2,FC = id and dT
2,FC = dT. Since GT
1 ∈L(TGG)T (see
Step 2 above), Step 4 yields the maximal consistent subgraph GT
2,FCB = GT
1 (see
Rem. 9.36) and the target update dT
B = id: GT
1 →GT
1 . Therefore, the target update
dT
2,CC = dT
B ◦d′T
2,FC is given by dT
2,CC = id. By r1 = r1,F ∈L(TGG) (see Step 2 above)
and correctness of operation bPpg (law (b1) in Fig. 9.5) we know that Step 5 yields
the source model update dS
2,CB = id and correspondence r2,FCB = r1 ∈L(TGG).
This leads to the source model update dS
2,FCB = dS
2,CB ◦dS
F = id. All together, we
have that s = (id, r1, dT) ∈CSynch(dS , r0, id), i.e., s is a valid solution for the
concurrent synchronisation problem of CSynch(dS , r0, id).
⊓⊔
9.4 Related and Future Work
The presented approach to (concurrent) model synchronisation is based on the for-
mal results and the constructions for performing model transformations via TGGs
in Chapters 7 and 8. It is inspired by Schürr et al. [Sch94, SK08] and Giese et
al. [GH09, GW09], respectively. The constructions formalise the main ideas of
model synchronisation based on TGGs in order to show correctness and complete-
ness of the approach based on the results known for TGG model transformations.
Moreover, we have extended the approach to the case of concurrent model syn-

292
9 Model Synchronisation
chronisation, where updates can occur concurrently on both domains, including the
resolution of possible merging conﬂicts.
Given an integrated model GS ↔GT and an update on one domain, either
GS or GT, the basic synchronisation problem is to propagate the given changes
to the other domain. This problem has been studied at a formal level by several
authors (see, for instance, [FGM+07, HMT08, Ste10, BCF+10, XSHT11, HPW11,
DXC11a, DXC+11b, HEO+11a]). Many of these approaches [FGM+07, HMT08,
Ste10, XSHT11] are state-based, meaning that they consider that the synchroni-
sation operations take as parameter the states of the models before and after the
modiﬁcation and yield new states of models. However, in [BCF+10, DXC11a] it is
shown that state-based approaches are not adequate in general for solving the prob-
lem. Instead, our approach in this chapter as well as a number of other approaches
(see, for instance, [BCF+10, HPW11, DXC+11b]) are delta-based, meaning that the
synchronisation operations take modiﬁcations as parameters and return modiﬁca-
tions as results. These results can be seen as an instantiation, in terms of TGGs, of
the abstract algebraic approach presented in [DXC+11b]. Let us look into the related
approaches and concepts in more detail.
Egyed et. al [EDG+11] discuss challenges and opportunities for change propa-
gation in multiple view systems based on model transformations concerning con-
sistency (correctness and completeness), partiality, and the need for bidirectional
change propagation and user interaction. Our presented approach based on TGGs
reﬂects these issues. In particular, TGGs automatically ensure consistency for those
consistency constraints that can be speciﬁed with a triple rule. This means that the
eﬀort for consistency checking with respect to domain language constraints is sub-
stantially reduced.
Stevens developed an abstract state-based view on symmetric model synchro-
nisation based on the concept of constraint maintainers [Ste10], and Diskin de-
scribed a more general delta-based view within the tile algebra framework [Dis11,
DXC+11b]. These tile operations inspired the constructions for the basic synchro-
nisation operations (Sects. 9.2 and 9.3). Concurrent updates are a central challenge
in multi-domain modelling, as discussed in [XSHT11], where the general idea of
combining propagation operations with conﬂict resolution is used as well. How-
ever, the paper does not focus on concrete propagation and resolution operations
and requires that model updates be computed as model diﬀerences. The latter can
lead to unintended results by hiding the insertion of new model elements that are
similar to deleted ones.
Merging of model modiﬁcations usually means that nonconﬂicting parts are
merged automatically, while conﬂicts have to be resolved manually. A survey on
model versioning approaches and on (semiautomatic) conﬂict resolution strategies
is given in [ASW09]. A category-theoretical approach formalising model versioning
is given in [RRLW09]. As in our approach, modiﬁcations are considered as spans
of morphisms for describing a partial mapping of models, and merging of model
changes is based on pushout constructions. In contrast to [RRLW09], we consider
an automatic conﬂict resolution strategy according to [EET11] that is formally de-
ﬁned.

9.4 Related and Future Work
293
Bidirectional transformation frameworks originate from the lens framework pro-
posed by Foster et al. [FGM+07]. Lenses consider the asymmetric synchronisation,
where one model is a view of the other, and deﬁne a state-based framework for
asymmetric synchronisation. “State-based” means that the synchroniser takes the
states of models before and after update as input, and produces new states of models
as output. Inspired by the lens framework, several researchers propose state-based
frameworks for symmetric synchronisation [Ste10, HPW11, Dis08]. As a more gen-
eral case, symmetric synchronisation allows neither of the models to be a view of
the other. However, as Diskin et al. [DXC11a] point out, state-based bidirectional
transformations actually mix two diﬀerent operations, namely delta discovery (cor-
respondence relations between models or between diﬀerent versions of a model)
and delta propagation, leading to several semantic problems. To ﬁx these problems,
several researchers [BCF+10, DXC11a, Dis11, DXC+11b, HPW12] propose delta-
based frameworks, where deltas are taken as input and output. Typical delta-based
frameworks include delta lens [DXC11a] for the asymmetric cases, and symmetric
delta lens [DXC+11b] and edit lens [HPW12] for the symmetric cases.
The model synchronisation framework used in this chapter is a simpliﬁed ver-
sion of the symmetric delta lens (sd-lens) framework proposed by Diskin et al.
[DXC+11b]. The diﬀerence is that we do not consider the weak undoability laws
(fUndo) and (bUndo) deﬁned there. In addition, Diskin et al. [DXC+11b] also reﬁne
an sd-lens as an alignment framework and a consistency maintainer. Our approach
is consistent with this reﬁnement as well. The alignment framework corresponds to
fAln and bAln operations. The consistency maintainer is implemented by Del, fAdd,
and bAdd operations, which ﬁrst mark the consistent parts of the integrated model,
then propagate the changes, and ﬁnally delete the remaining inconsistent parts. As
a result, the presented TGG approach serves as a proof of concept for the theory of
symmetric delta lenses.
The BiG system proposed by Hidaka et al. [HHI+10] is a bidirectional graph
synchronisation system. Diﬀerent from our work based on symmetric TGG speciﬁ-
cation, the BiG system is based on an unidirectional graph transformation language,
UnQL [BFS00], and thus is asymmetric by nature. Accordingly, the BiG system
adopts an asymmetric synchronisation framework (a variant of the basic lens frame-
work [FGM+07]), while our work adopts a simpliﬁed version of the symmetric delta
lens [DXC+11b]. In an asymmetric framework, one model has to be a view of the
other, and it is not possible to synchronise two models each containing information
not presented in the other.
Giese et al. [GW09] introduced incremental synchronisation techniques based
on TGGs in order to preserve consistent structures of the given models by revok-
ing previously performed forward propagation steps and their dependent ones. This
idea is generalised by the auxiliary operation Del in the present framework, which
ensures the preservation of maximal consistent substructures and extends the appli-
cation of synchronisation to TGGs that are not tight or contain rules with negative
application conditions. Giese et al. [GH09] and Greenyer et al. [GPR11] proposed
extending the preservation of substructures by allowing for the reuse of any partial
substructure of a rule causing nondeterministic behaviour. However, a partial reuse

294
9 Model Synchronisation
can cause unintended results. Consider, e.g., the deletion of a person A in the source
domain and the addition of a new person with the same name; then the old birth date
of person A could be reused.
In order to improve eﬃciency, Giese et al. [GW09, GH09] proposed avoiding the
computation of already consistent substructures by encoding the matches and depen-
dencies of rule applications within the correspondences. In the present framework,
the operation Del can be extended conservatively by storing the matches and depen-
dency information separately, such that the provided correctness and completeness
results can be preserved as presented in Sect. 9.2.3.
Becker et al. presented a generally nondeterministic synchronisation approach
based on TGGs [BNW08] using the PROGRES approach [SWZ99] with the focus
on integration, i.e., construction of missing correspondence links. The algorithm
requires user interaction at each rule application, where some integration rules are
in conﬂict for partial matches. For general TGGs, such integrations may require
backtracking to achieve a resulting model that is fully integrated. In principle, it
might be possible to adapt this algorithm in order to apply the main results in this
chapter on correctness and completeness, since the actual steps are performed via
the operational rules of a TGG.
In future work, we plan to develop extended characterisations of the correctness
and maximality criteria of a concurrent synchronisation procedure. In Sect. 9.3, cor-
rectness is deﬁned explicitly in terms of the two laws formulated in Sect. 9.2 and,
implicitly, in terms of the properties of compatibility with basic model synchroni-
sation proven in Theorem 9.44. We think that this can be strengthened by relating
correctness of a synchronisation procedure with the total or partial realisation of
the given source and target updates, for a suitable notion of realisation. At a diﬀer-
ent level, we also believe that studying in detail, from both theoretical and practical
viewpoints, the combination of fSynch and bSynch operations should also be a rel-
evant matter. The main parts of the basic model synchronisation framework have
been implemented in the tool HenshinTGG (Sect. 12.4) and we plan to extend the
implementation to the concurrent case.

Part IV
Application Domains, Case Studies and
Tool Support

297
This fourth part of this book treats diﬀerent application domains and case stud-
ies according to diﬀerent parts of the theory given in Parts II and III, respectively.
Moreover we give an overview of diﬀerent tools, which support modeling and anal-
ysis of systems using graph transformation techniques presented in this book. In
Chap. 10, we introduce self-adaptive systems and show how they can be modelled
and analysed using graph transformation systems in Chap. 2, including a case study
concerning business processes. The application domain of enterprise modelling is
considered in Chap. 11, based on Chapters 3, 7 and 8, together with a case study on
model transformation between business and IT service models. Chap. 12 includes a
discussion of the following tools:
1. The Attributed Graph Grammar system AGG 2.0,
2. ActiGra: Checking consistency between control ﬂow and functional behaviour,
3. Controlled EMF model transformation with EMF Henshin,
4. Bidirectional EMF model transformation with HenshinTGG.

Chapter 10
Modelling and Static Analysis of Self-adaptive
Systems by Graph Transformation
Software systems nowadays require continuous operation despite changes both in
user needs and in their operational environments. Self-adaptive systems are typically
instrumented with tools to autonomously perform adaptation to these changes while
maintaining some desired properties. In this chapter, we model and analyse self-
adaptive systems by means of typed, attributed graph grammars. The interplay of
diﬀerent grammars representing the application and the adaptation logic is realised
by an adaptation manager. Within this formal framework we deﬁne consistency and
operational properties that are maintained despite adaptations, and we give static
conditions for their veriﬁcation. The overall approach is supported by AGG 2.0
(see Sect. 12.1). A case study modelling a business process that adapts to changing
environment conditions is used to demonstrate and validate the formal framework
[BKM+12]. The modelling framework described in this chapter is based on joint
work of the authors with Antonio Bucchiarone, Patrizio Pellicione and Olga Runge
[EER+10, BEE+13, BEE+15].
The chapter is organised as follows. In Sect. 10.1, we show how self-adaptive sys-
tems can be modelled in our approach based on graph transformation. Section 10.2
describes how to formally verify desirable consistency and operational properties of
self-adaptive systems. Section 10.3 discusses aspects related to the automation of
the approach. In Sect. 10.4, we compare our approach with related work, and we
conclude in Sect. 10.5. For full details of our case study, the reader is referred to our
technical report [BEE+13].
10.1 Modelling Self-adaptive Systems
The high degree of variability that characterises modern systems requires us to de-
sign them with runtime evolution in mind. Self-adaptive systems are a variant of
fault-tolerant systems that autonomously decide how to adapt the system at run-
time to the internal reconﬁguration and optimisation requirements or to environment
changes and threats [BMSG+09]. A classiﬁcation of modelling dimensions for self-
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_10
299

300
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
adaptive systems can be found in [ALMW09], where the authors distinguish be-
tween goals (what the system is supposed to do), changes (causes for adaptation),
mechanisms (system reactions to changes) and eﬀects (the impact of adaptation upon
the system).
The initial four self-* properties of self-adaptive systems are self-conﬁguration,
self-healing,1 self-optimisation, and self-protection [KC03]. Self-conﬁguration
comprises component installation and conﬁguration based on some high-level poli-
cies. Self-healing deals with automatic discovery of system failures, and with tech-
niques to recover from them. Typically, the runtime behaviour of the system is mon-
itored to determine whether a change is needed. Self-optimisation monitors the sys-
tem status and adjusts parameters to increase performance when possible. Finally,
self-protection aims to detect external threats and mitigate their eﬀects [WHW+06].
In [BPVR09], the authors modelled and veriﬁed dynamic software architec-
tures and self-healing systems (called self-repairing systems) by means of hyper-
graphs and graph grammars. The work in [EER+10] shows how to formally model
self-healing systems by using algebraic graph transformations [EEPT06] and to
prove consistency and operational properties. In this chapter, we extend the work
in [EER+10] by formally modelling and analyzing self-adaptive systems based on
the framework of algebraic graph transformation. Our modelling and validation
framework is supposed to be used oﬄine to evaluate and evolve a self-adaptive sys-
tem: the framework helps the developer to decide which adaptation solutions used
and logged in the past have desired properties and should become part of the ﬁnal
system model. Since we aim at modelling in a general way the concepts of self-
awareness, context-awareness, self-monitoring and self-adaptation, our modelling
framework is in principle applicable to systems with diﬀerent kinds of self-* prop-
erties. The aim of our analysis is to show operational properties of self-adaptive
systems concerning overall conﬂicts and dependencies of normal system behaviour
and adaptations.
Self-adaptive systems are modelled in our approach as a set of typed attributed
graph grammars where three kinds of system rules are distinguished: normal, con-
text, and adaptation rules. Normal rules deﬁne the normal and ideal behaviour of the
system. Context rules deﬁne context ﬂags (adaptation hooks) that trigger adaptation
rules. Adaptation rules in diﬀerent adaptation grammars deﬁne the adaptation logic.
10.1.1 Running Example: A Car Logistics System (CLS)
The Car Logistics System (CLS) scenario will be used throughout the chapter to ex-
plain our approach to modelling self-adaptive systems. At the automobile terminal
of the Bremerhaven sea port [BPSR09], nearly two million new vehicles are handled
each year; the business goal is to deliver them from the manufacturer to the dealer.
To achieve that goal, several intermediate business activities are involved. These in-
1 Following [RGSS09], we consider self-healing and self-repair as synonymous.

10.1 Modelling Self-adaptive Systems
301
clude unloading and storing cars from a ship, applying to them treatments to meet
the customer’s requirements and distributing them to the retailers. The company
“Logistics IT Solutions” wants to develop a service-based application (the CLS) to
support the delivery of vehicles from the ship to the retailers. The CLS must imple-
ment the business process depicted in Fig. 10.1 by invoking and orchestrating the
set of available services in a proper way. Each business activity of the process is ex-
ecuted invoking a set of available services (i.e., Car Check Service, Unloading Service,
etc.) that can be atomic or composite (i.e., Store Car Service). Additional services,
i.e., services that are not directly attached to the business process, are deﬁned and
they can be used during the application execution. For example, the Wait For Treat-
ment Service may be invoked when a vehicle that needs a treatment has to wait some
time because of a long queue in the treatment station.
Fig. 10.1 Business process and services of the Car Logistics Scenario
The CLS executes the business process presented before for each vehicle under
the following assumptions: (i) each business activity is executed in the deﬁned order;
(ii) the context in which the business process is executed can evolve in time.
Assume now the following two cases that may happen at runtime:
• A vehicle is severely damaged during its movement from the ship to the storage
area: The vehicle has been unloaded from the ship and has requested a ticket
(using the Request Ticket Service) to park in the storage area. It receives a pre-
cise ticket and starts to move to the storage (using the Move To Storage Service).
While moving, the vehicle is severely damaged and then it stops. In this case, the
business process does not know how to proceed and the booked ticket cannot be
used.
• A vehicle arrives at a service point in the treatment area, but the required service
is busy and cannot be executed immediately: The vehicle is ready to undergo
a service as ordered by the customer (concerning, e.g., painting or equipment),
but there are already a number of vehicles waiting for this service. In this case,
the corresponding business service cannot proceed in an expected way (such as
treating the vehicles right after their arrival).
Ship 
Unloading
Storage
Technical 
Treatment
Consignment
Truck 
Loading
Wait For 
Treatment 
Service
Pull To 
Treatment 
Service
Drop Ticket 
Service
Car Repair 
Service
Move To 
Terminal 
Service
Unloading 
Service
Equipment
Service
Car Check
Service
Cleaning
Service
Painting
Service
Treatment 
Report Service
Move To 
Treatment 
Service
Store Car
Service
Move To 
Storage 
Service
Move To 
Consignment
Service
Loading 
Service
Other Available Services
Request
Ticket
Service
Move To 
Storage 
Service
Move To 
Place 
Service

302
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
In each of these cases, the business process should not proceed as planned. A sys-
tem adaptation is required. In the next section we present a framework for rule-based
dynamic adaptation to model and analyse systems that exhibit the aforementioned
characteristics and problems.
10.1.2 Framework for Rule-Based Dynamic Adaptation
The framework manages the dynamic adaptation by specifying when and how adap-
tation is triggered, how the choice among the possible adaptations is performed, and,
ﬁnally, how the nature of adaptations can be characterised.
Requirements
To be able to execute system behaviour also in case of unexpected situations, an
adaptation framework needs to address the following problems:
Context-awareness: To relate the application execution to the context, the applica-
tion must be context-aware, i.e., during the execution, information on the underlying
environment can be obtained (e.g., relevant information on entities involved, status
of the business process execution, human activities, etc.). To be adaptable, an ap-
plication should provide adaptation hooks, i.e., context information on parts of the
application’s structure and behaviour. The adaptation hooks should be used to select
the most suitable adaptation strategy.
Separation of concerns: The adaptation logic should be developed separately from
the application logic by some adaptation manager. The adaptation logic can be cre-
ated and/or changed after the application has been deployed without modifying the
running application. At runtime, the adaptation manager should check the context
(adaptation hooks) to control whether any adaptations are required, and reconﬁgure
the system in the best suitable way.
Components
Our adaptation framework (AF) is composed of three fundamental components as
illustrated by Fig. 10.2: the Application Logic describes how the application evolves
(by application rules); the Context Monitor watches properties of the application op-
erational environment and how they evolve (by adaptation hooks and context rules);
the Adaptation Manager speciﬁes how a system is adapted in the case of adaptation
needs (using adaptation rules).
According to the scenario in Sect. 10.1.1, the considered self-adaptive system
is the Car Logistics application. Its application logic describes what the diﬀerent

10.1 Modelling Self-adaptive Systems
303
Fig. 10.2 Adaptation framework
activities are that can be executed (i.e., Ship Unloading, Storage, Technical Treatment,
Consignment, and Truck Loading), the set of available services that can be used to re-
alise such activities (i.e., Store Car Service, Move To Treatment Service, Cleaning Service,
etc.) and the assumed behaviour of the overall application. The behaviour describes
the order of the activities a car must execute plus a set of business policies (in terms
of activity preconditions).
The Context Monitor continuously monitors the context at ﬁxed intervals. It is
deﬁned as a set of rules, called context rules, which once applied add adaptation
hooks to the system to trigger the adaptation process. The system is monitored at
regular time intervals, and an adaptation problem is sent to the Adaptation Manager
if one or more adaptation hooks are found. In response, the Adaptation Manager
returns an adaptation solution to the application logic that aims to do its best to
“recover”, so that the blocked activity can be executed and the main process can
continue.
Formalisation
The formal model of a self-adaptive system is a set of graph grammars typed over
the same type graph. A main system grammar consists of system rules modelling
normal behaviour (the Application Logic) and context rules modelling changes that
require adaptation by generating adaptation hooks. Context Monitoring is modelled
by context constraints in the main system grammar that are violated in the pres-
ence of adaptation hooks and trigger the (semiautomatic) selection of a correspond-
ing adaptation grammar (the Adaptation Logic). An adaptation grammar contains
adaptation rules modelling reactions to the detection of context changes. The inter-
play of the diﬀerent grammars representing the adaptation logic is realised by the
Adaptation Manager.
Ordering adaptations
Diﬀerent adaptations may be applicable during the system execution. The choice
of which adaptation to apply may inﬂuence the time required for performing the
adaptation, or even the ﬁnal result. In our framework, adaptations are selected by
the adaptation manager.

304
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
Nature of adaptations
We consider two classes of adaptations that can be applied and treated in diﬀerent
ways [CHK+01, LBM10], in particular:
Corrective Adaptations take care of adapting the application when the current im-
plementation instance cannot proceed with the execution in the current context (i.e.,
a car is damaged). The main objective is to recover the application and hence fo-
cus on the self-healing property. The adaptation starts from the actual context state
and performs the necessary changes to bring the application and its context to the
expected state where it can be executed again. In our framework, an adaptation is
corrective if each adaptation state can be repaired, i.e., the normal state before the
adaptation became necessary is reestablished.
Enhancing Adaptations augment existing services of the application; this may for
instance change the nonfunctional properties of the service, or provide new services
with the same or expanded functionalities. In our framework, an adaptation is en-
hancing if each adaptation state can become a normal state, possibly by adding new
functionalities and services. The adaptation result is not necessarily identical with
the normal state before the adaptation became necessary.
10.1.3 Modelling SA Systems by Graph Transformation
In this section, we show how to model self-adaptive systems in the formal frame-
work of algebraic graph transformation. Speciﬁcally, typed attributed graphs, intro-
duced in Def. 2.5 in Chap. 2, are used to model the static part of the system. Typed
attributed graphs are enriched with constraints that self-adaptive systems have to
satisfy even during adaptation. Moreover, we model the behaviour and the adapta-
tion of self-adaptive systems by means of graph grammars, introduced in Def. 2.20.
We use the Car Logistics System running example and the AGG tool (see Sect. 12.1)
to show how practitioners can model and simulate self-adaptive systems.
Example 10.1 (CLS type graph and initial state). Figure 10.3 depicts the type graph
for the Car Logistics System, which contains types used for modelling the “normal”
aspects of the car logistics scenario, as well as the context types used for adaptation,
e.g., the hooks (context ﬂags) that trigger the adaptation rules.
In the integrated type graph in Fig. 10.1, we have the following types for normal
behaviour:
•
Start, End and BusinessActivity are the main business activities, which are ordered,
i.e., linked by directed arcs of type next.
•
Service is a service station belonging (linked) to a BusinessActivity. A service may
be a composite service. Then it contains other services which are ordered (linked

10.1 Modelling Self-adaptive Systems
305
Fig. 10.3 CLS type graph
by next arcs). Containment of sub-services in a composite service is modelled by
c edges from the sub-services to its composite service.
•
Vehicle is a car running through the business process. At the beginning it will be
linked (by a v link) to the Start activity and is ready to enter a service.
• A todo link between a vehicle and each service of each BusinessActivity is gener-
ated when a Vehicle starts the business process. The successful processing of a
service leads to the deletion of the corresponding todo link. When all services be-
longing to the business process have been processed (all todo links are removed),
the Vehicle arrives at the End activity as a completed product with a precise treat-
ment executed and ready to be delivered to a retailer.
For adaptation handling we have the following types:
•
Context is the super-type for all possible context signals, including adaptation
hooks. These hooks are used for triggering the adaptation grammars. We specify
two main context types, AdaptV and AdaptS.
•
AdaptV with reﬁnements Damage and Queue denotes that a car is damaged and
needs to be repaired (SlightlyDamaged) or disposed (SeverelyDamaged), or a car is
in a queue.
•
AdaptS with reﬁnements NotAvailable and Wait denotes that a service is not avail-
able or there is a queue at a service, respectively. The reﬁnement Wait denotes that
cars in the current business activity should queue up and wait to be processed.
•
AdService is an adaptation service not directly attached to a BusinessActivity. Such
additional services are used according to an adaptation scenario.
• An edge of type extraSrvBy connects a Vehicle to an adaptation service.
• Edges of type queue connect the Vehicles in a queue at a service.
Figure 10.4 displays the initial state graph of a scenario with two vehicles.
△
In order to model global consistency and adaptation constraints of a self-adaptive
system, we use (TG-typed) graph conditions and constraints. A graph condition is

306
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
Fig. 10.4 Initial state graph of the Car Logistics case study
Fig. 10.5 Graph constraint noFalseServiceConnect
given by a graph morphism c : P →C (where P is called premise and C conclusion).
The condition c : P →C is satisﬁed by a graph G, written G |= c, if the existence
of an injective graph morphism p : P →G implies the existence of an injective
graph morphism q : C →G, such that q ◦c = p. Graph conditions can be negated
or combined by logical connectors (e.g., ¬c). See Defs. 2.7 and 5.1 and Ex. 2.16 for
some examples of graph conditions.
Technically, graph constraints describe global requirements for objects.. They
are conditions over the initial object in the category of typed, attributed graphs.
This means that, for instance, a constraint ∃(iC, true) with the initial morphism iC
into C is valid for a graph G if there exists a morphism c : C →G. This constraint
expresses that the existence of C as a part of G is required (see Def. 5.10 in Chap. 5).
Example 10.2 (Graph constraints for the Car Logistics system).
The set Cconsist =
{noFalseServiceConnect, sameBAforComp, noEqualContextFlags} contains consis-
tency constraints that have to be satisﬁed throughout all states of the car logistics
model. Constraint noFalseServiceConnect, depicted in Fig. 10.5, means that there
must be no next or containment loops, a vehicle must not be served (todo edge) by
a service which is a container of other services, and a sub-service must not be a
composite service.

10.1 Modelling Self-adaptive Systems
307
Fig. 10.6 The normal behaviour rule ServiceToDo
Constraint sameBAforComp (not depicted) means that all sub-services belong-
ing to the same composite service are linked to the same BusinessActivity and to
the same composite service node. Constraint noEqualContextFlags (not depicted)
requires that the same element (vehicle or service) be not marked by more than one
adaptation hook of the same type.
Moreover, we have two sets of adaptation constraints, C1
adapt = {Damage} and
C2
adapt = {Wait}, describing adaptation hooks that are required to hold for certain
adaptations to occur, i.e., constraint Wait requires the existence of a Wait ﬂag at a
service, and constraint Damage requires a Damage ﬂag at a vehicle.
△
We now model the behaviour of the main scenario and the adaptations by diﬀer-
ent graph grammars (according to Def. 2.20 in Chap. 2). Whenever an adaptation
becomes necessary, the respective adaptation rules are added to the main grammar.
In the main grammar CarLogisticsScenario (Ex. 10.3), normal behaviour is mod-
elled. Moreover, context ﬂags (e.g., adaptation hooks) can be generated.
Example 10.3 (Rules modelling the Car Logistics scenario).
Here, we describe
the rules for the normal behaviour of Vehicles running through BusinessActivities
smoothly.2 To save space, we depict only the left- (LHS) and right-hand sides (RHS)
for a rule. The interface consists of those nodes and edges that are present both in
LHS and in RHS and mapped to each other by equal numbers.
The ﬁrst step for each Vehicle is to enter the business process. Then, all services
of the Vehicle’s BusinessActivities are marked as to do by creating todo edges be-
tween the Vehicle and each service not yet marked (by applying rule ServiceToDo in
Fig. 10.6 as long as possible). Three negative application conditions (NACs) ensure
that a todo edge is created only if there is not already a todo edge between the vehicle
and the service (NAC ServiceNotDone), the vehicle is not in an adaptation state (NAC
NoAdaptV) and it is not linked to a composite service (NAC NoSubService).
Next, rule EnterBP moves the Vehicle to the ﬁrst BusinessActivity. When a ser-
vice is processed, the corresponding todo edge is removed by rule DoService. For
processing a composite service consisting of ordered sub-services, rule DoSubSer-
vice processes a sub-service only if its previous services in the queue have already
been processed. A Vehicle can move to the next BusinessActivity when all services
2 The complete set of rules with all details is given in [BEE+13]

308
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
Fig. 10.7 The context rules SlightlyDamage and SeverelyDamage
of the previous one are done (rule NextBA). Finally, when there are no more services
to do, the business process for the Vehicle is ﬁnished (rule FinishBP).
In addition to the normal behaviour rules, the main grammar contains context
rules that are applicable at any time and mark a Vehicle or Service with an adaptation
hook, i.e., they create a node of one of the context node types AdaptV or AdaptS,
respectively. In case a car is damaged, rules SlightlyDamage or SeverelyDamage mark
it by an adaptation hook of kind either “SlightlyDamaged” or “SeverelyDamaged”
as illustrated in Fig. 10.7.
Another context rule Queue (not depicted) marks a service of the technical treatment
area and a vehicle with context nodes of type Wait and Queue, respectively, if a
service station in the technical treatment area is busy and the treatment cannot be
executed immediately.
△
All above introduced adaptation hooks guide the adaptation manager to select a
suitable adaptation grammar realising the adaptation. We may have diﬀerent adap-
tation grammars that are suitable for the same adaptation hook. For instance, if a
damaged car is in the midst of a composite service, ﬁrst a rollback adaptation has
to be performed, and then a repair adaptation. The adaptation manager coordinates
the diﬀerent adaptation grammars such that the rules of the most suitable adaptation
grammars are imported into the main grammar. These rules perform the necessary
adaptations at the host graph so that the “normal behaviour rules” can proceed and
maybe new adaptation hooks are set. Note that in AGG the modeller plays the role
of an adaptation manager and imports the necessary adaptation rules into the main
grammar. After adaptation, the adaptation rules are removed from the main gram-
mar, and the application of the “normal behaviour rules” continues.
Example 10.4 (Rollback adaptation). A rollback adaptation is needed when a dam-
aged vehicle is in the midst of a composite service, as depicted in Fig. 10.8. In this
case, the already ﬁnished sub-services are “rolled back” by applying rule RollBack as
long as possible before the vehicle is moved to the treatment area to be repaired.
△
Example 10.5 (Repair adaptation). A repair adaptation becomes necessary when a
vehicle is marked by a context ﬂag as being slightly damaged. We require that the
vehicle to be repaired be not in the midst of a composite service anymore. (If it is, the

10.1 Modelling Self-adaptive Systems
309
Fig. 10.8 The rollback adaptation rule RollBack
Fig. 10.9 The repair adaptation rule TakePullToTreatmentService
rollback adaptation has to be selected by the adaptation manager to be performed
before the repair adaptation.) When repair is needed, two additional services are
evoked, i.e., the Vehicle is linked to them, one after the other. Rule TakePullToTreat-
mentService in Fig. 10.9 uses an extra service to pull up the damaged Vehicle to the
treatment area.
Rule TakeRepairService (not depicted) allocates an extra repair service for the
slightly damaged Vehicle. A slightly damaged Vehicle is repaired (i.e., the adapta-
tion hook is removed) by rule RepairVehicle.After repair, the Vehicle should continue
its normal behaviour at the point where the adaptation hook was set. The compos-
ite service it left before (which has rolled back by applying the rollback adaptation)
may now start again from the beginning. Note that the Vehicle does not forget which
services have been done already and which are still to be done.
△
Example 10.6 (Dispose adaptation). A severely damaged vehicle that cannot be re-
paired is disposed of by the dispose adaptation. This adaptation grammar also con-
tains the rules TakePullToTreatmentService and TakeRepairService that are analogous to
the corresponding rules in the repair adaptation in Ex. 10.5, with the slight diﬀerence
that the context ﬂag is now always of kind SeverelyDamaged.
Using rule TakeDisposingService in Fig. 10.10, a severely damaged Vehicle is
picked up by the disposing service.
Before the vehicle can be disposed of, its todo links and all ﬂags of kind Slight-
lyDamaged or SeverelyDamaged are removed by applying the rules RemoveToDo and
RemoveDamageFlag as long as possible. Finally, the vehicle is disposed of by rule
DisposeVehicle. In our model, a disposed vehicle remains in the graph without any
links to other objects.
△
Example 10.7 (Wait-at-queue adaptation). The wait-at-queue adaptation becomes
necessary when a service station in the technical treatment area is busy and the

310
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
Fig. 10.10 The dispose adaptation rule TakeDisposingService
Fig. 10.11 The wait-at-queue adaptation rule Enqueue
treatment cannot be executed immediately. When a car arrives at the treatment area
and discovers that there is a queue it should queue up and wait. Rule Enqueue in
Fig. 10.11 enqueues all Vehicles waiting for this service. In doing so the Queue ﬂag
is shifted along the queue link.
Vehicles in a queue are served in the order of their arrival by applying rule DoSer-
vice. Finally, the Wait ﬂag at the busy service and the Queue ﬂag at the last Vehicle
are removed by rule RemoveWait after the whole queue has been processed.
△
An SA system is deﬁned in Def. 10.8 by a typed graph grammar where the system
rules can be partitioned into normal, context and adaptation rules. Moreover, we
have two kinds of constraints, namely consistency and adaptation constraints.
Deﬁnition 10.8 (Self-adaptive system in AGT framework). A self-adaptive sys-
tem (SA system) is given by SAS = (GG, Csys), where:
• GG = (TG, Ginit, Rsys) is a typed graph grammar with type graph TG, a TG-
typed initial graph Ginit, and a set of TG-typed rules Rsys (system rules), deﬁned
by Rsys = Rnorm ∪Rcont ∪Radapt, where Rnorm (normal rules), Rcont (context rules)
and Radapt (adaptation rules) are pairwise disjoint.

10.1 Modelling Self-adaptive Systems
311
• Csys is a set of TG-typed graph constraints, called system constraints, with Csys =
Cconsist ∪Cadapt, where Cconsist (called consistency constraints) and Cadapt (called
adaptation constraints) are pairwise disjoint.
We distinguish reachable, adaptation and normal states, where reachable states
are partitioned into normal and adaptation states.
• Reach(SAS) = {G | Ginit
∗
=⇒G via Rsys}, i.e., all states reachable via system
rules,
• Adapt(SAS) = {G | G ∈Reach(SAS) ∧∃C ∈Cadapt : G ⊨C}, the adaptation
states, i.e., all reachable states satisfying some adaptation constraints,
• Norm(SAS) = {G | G ∈Reach(SAS) ∧∀C ∈Cadapt : G ⊭C}, the normal states,
i.e., reachable states not satisfying any adaptation constraints.
For SA systems SAS, we require that
1. each pair of a context and a normal rule (p, r) ∈Rcont × Rnorm be sequentially
independent (see Def. 5.21); this means that context rules can be applied in-
dependently of the normal system behaviour occurring in diﬀerent parts of the
system),
2. SAS is system consistent: all reachable states are consistent, i.e., they fulﬁll the
consistency constraints: ∀G ∈Reach(SAS), ∀C ∈Cconsist : G ⊨C,
3. SAS is normal-state consistent, i.e., normal rules must not create adaptation
hooks: the initial state is normal and all normal rules preserve and reﬂect normal
states: Ginit ∈Norm(SAS) and ∀G0
r
=⇒G1 via r ∈Rnorm [G0 ∈Norm(SAS) ⇔
G1 ∈Norm(SAS)],
4. the set of adaptation rules Radapt is conﬂuent and terminating, i.e., adaptation
results are unique and do not depend on the order or location of the adaptation
rule applications.
△
The requirements of SA systems can be concluded in a static way by inspecting
the corresponding rules. This means, e.g., that we do not need to check the con-
sistency of all states reachable via system rules; instead, we only check Ginit for
consistency and then check whether the system rules preserve consistent states. In
particular, we can check statically that diﬀerent adaptations do not interfere with
each other, i.e., they are conﬂuent and terminating (see Requirement 4). This prop-
erty is interesting if more than one set of adaptation rules has to be used to adapt a
given state, which is a highly relevant practical problem.
Example 10.9 (Car Logistics system as SA system). We deﬁne the Car Logistics SA
system CLS = (GG,Csys) by the type graph TG in Fig. 10.3, the initial state Ginit in
Fig. 10.4, and the following sets of rules and constraints:
• Rnorm = {ServiceToDo, EnterBP,DoService, DoSubService,NextBA, FinishBP},
• Rcont = {SlightlyDamage, SeverelyDamage, Queue},
• Radapt = R1
adapt ∪R2
adapt ∪R3
adapt ∪R4
adapt with R1
adapt = {Rollback},
• R2
adapt = {TakePullToTreatmentService, TakeRepairService, RepairVehicle},

312
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
• R3
adapt = {TakePullToTreatmentService,TakeRepairService,TakeDisposingService, Re-
moveTodo, RemoveDamageFlag, DisposeVehicle},
• R4
adapt = {Enqueue, DoService, RemoveWait},
• Cconsist = {noFalseServiceConnect, sameBAforComp, noEqualContextFlags},
• Cadapt = C1
adapt ∪C2
adapt with C1
adapt = {Damage} and C2
adapt = {Wait}.
The normal rules in Rnorm and the context rules in Rcont have been explained in
Ex. 10.3. The adaptation rules in R1
adapt to R4
adapt have been introduced in Ex. 10.4
to Ex. 10.7, respectively. The consistency constraints in Cconsist have been explained
in Ex. 10.2 and model the desired structural properties. The adaptation constraints
in Cadapt model properties that have to be valid only if the corresponding adaptation
is running. The adaptation constraints Damage and Wait require the existence of the
corresponding adaptation hook.
Checking the requirements for SA systems in Def. 10.8, we ﬁnd that:
1. We have sequential independence for each pair of context and normal rules
(p, r) ∈Rcont × Rnorm, which we have checked using the automatic depen-
dency analysis of AGG. Each of the pairs (SlightlyDamage,r), (SeverelyDamage,r)
and (Queue,r) with r being a normal rule is sequentially independent (i.e., there
are no dependencies for each rule pair).
2. CLS is system consistent, because for all C ∈Cconsist, Ginit |= C and for all G0
r
=⇒G1 via r ∈Rsys and G0 ∈Consist(S AS ) we also have G1 ∈Consist(S AS ).
This can be concluded since no system rules manipulate the structure of services.
3. CLS is normal-state consistent, because Ginit ∈Norm(S AS ) and for all G0
r
=⇒
G1 via r ∈Rnorm and for all C ∈CAdapt we have that [G0 ̸|= C ⇔G1 ̸|= C].
This can be concluded since no normal rule manipulates (inserts or deletes) any
adaptation hooks (subtype of type Context), which is required by the adaptation
constraints to hold.
4. With regard to conﬂuence, we have used AGG to check the sets of adaptation
rules for critical pairs (i.e., minimal conﬂicts; see Def. 5.40) and found that there
are no critical pairs, and hence no conﬂicts for any rule pairs within the same
adaptation rule set. AGG has computed some conﬂicts between diﬀerent adap-
tation rule sets: there is, e.g., a conﬂict when the adaptation rule Rollback would
be applied after the adaptation rule RepairVehicle. Note that this conﬂict can be
disregarded since the adaptation manager has to make sure to apply the roll-
back adaptation (if necessary) before evoking the repair adaptation, and not af-
terwards. Similarly, conﬂicts between rules for repairing and rules for disposing
vehicles can be ignored since we expect that in presence of severely damaged
cars, the adaptation manager selects the Dispose adaptation ﬁrst, and applies the
Repair adaptation afterwards, when all severely damaged cars have been dis-
posed of. Under these restrictions on the application order of adaptation rule
sets, the union Radapt of all adaptation rule sets is conﬂuent.
With regard to termination, we argue as follows: The rollback adaptation R1
adapt
terminates as there are only a ﬁnite number of services to roll back within a com-
posite service, and a todo edge may be inserted only once between a vehicle and a
service. The repair adaptation R2
adapt terminates due to a ﬁnite number of slightly

10.2 Static Analysis of Self-adaptive Systems
313
damaged vehicles, and due to the NACs of the repair rules ensuring that each
rule is applicable only once for each damaged vehicle. For the dispose adapta-
tion R3
adapt, we have one rule, RemoveDamageFlag, that might be applicable twice,
if a car has two Damage ﬂags. No car has more than two ﬂags, due to NACs of
the corresponding context rules. For the wait-at-queue adaptation R4
adapt, NACs
ensure that each vehicle is enqueued only once by the rule Enqueue. The remain-
ing rules only delete todo edges and are terminating due to the ﬁnite number of
vehicles in the system. Hence, all adaptation rule sets are conﬂuent and terminat-
ing.
△
10.2 Static Analysis of Self-adaptive Systems
In this section, we deﬁne desirable operational properties of SA systems and pro-
pose static analysis techniques to verify them. One of the main ideas of SA sys-
tems is that they are monitored in regular time intervals and it is checked whether
the current system state is an adaptation state. In this case one or more adaptation
hooks have been created in the last time interval by context rules. With the enhanc-
ing-adaptation property below, we require that a system in an adaptation state be
eventually adapted, i.e., transformed again to a normal state, possibly by adding
new functionalities to the system and using new services. Moreover, corrective self-
adaptation means that the state will be recovered, i.e., the normal state after adap-
tation is the same as if no adaptation had occurred. In the following, we use the
notation G ⇒! G′ to denote a transformation where the rules are applied as long
as possible; we write G ⇒∗G′ to denote a transformation where the rules are ap-
plied arbitrarily often, and the transformation G ⇒+ G′ consists of at least one rule
application.
Deﬁnition 10.10 (Self-adaptation classes). An SA system SAS is called
1. enhancing if each adaptation state is adapted to become a normal state (unique
up to isomorphism), possibly by adding new functionalities and services. In more
detail:
∀Ginit ⇒∗G via (Rnorm ∪Rcont) with G ∈Adapt(SAS) ∃G ⇒! G′ via Radapt
with G′ ∈Norm(SAS).
2. corrective if each adaptation state is adapted in a corrective way (repaired). In
more detail:
∀Ginit ⇒∗G via (q1 . . . qn) ∈(Rnorm ∪Rcont)∗with G ∈Adapt(SAS) ∃G ⇒! G′
via Radapt with G′ ∈Norm(SAS) and ∃Ginit ⇒∗G′ via (r1 . . . rm) ∈R∗
norm, where
(r1 . . . rm) is the subsequence of all normal rules in (q1 . . . qn).
△
Remark 10.11. By deﬁnition, each corrective SAS is also enhancing, but not vice
versa. The additional requirement for corrective self-adaptation means that the sys-
tem state G′ obtained after adaptation is not only normal, but can also be generated
by all normal rules in the given mixed sequence (q1 . . . qn) of normal and context

314
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
rules, as if no context rule had been applied. We will see that our SA system CLS
is corrective, considering only the repair adaptation for slightly damaged vehicles,
but CLS together with the wait-at-queue adaptation is enhancing only, but not cor-
rective.
△
In Def. 10.12, we deﬁne adaptation properties, which imply that the SA system is
corrective/enhancing under suitable conditions, stated in Theorem 10.14. We want
to ensure that for each context rule that adds an adaptation hook, there is a suit-
able adaptation grammar containing one or more adaptation rules leading again to
a state without this adaptation hook, even if they are not applied immediately after
its occurrence but later, when the context monitor reveals that the adaptation must
be invoked. This means that other normal and context rules may have been applied
before the occurrence of the adaptation hook is monitored.
Deﬁnition 10.12 (Self-adaptation (SA) properties). Let G0 be a reachable state in
the SA system SAS. SAS has the
1. direct adaptation property if the adaptation can be performed directly, i.e.,
∀G0
p
=⇒G1 via p ∈Rcont ∃G1 ⇒∗G0 via Radapt,
2. normal adaptation property if the necessary adaptation can be performed up to
normal transformations, leading to a possibly diﬀerent normal state that is reach-
able from the state before the adaptation hook was set, i.e., ∀G0
p
=⇒G1 via
p ∈Rcont ∃G1 ⇒+ G2 via Radapt s.t. ∃G0 ⇒∗G2 via Rnorm,
3. rollback adaptation property if the necessary adaptation can be performed up to
normal transformations, leading to a possibly diﬀerent normal state from which
the state before the adaptation hook was set is reachable, i.e., ∀G0
p
=⇒G1 via
p ∈Rcont ∃G1 ⇒+ G2 via Radapt s.t. ∃G2 ⇒∗G0 via Rnorm.
△
Remark 10.13. Note that the normal and rollback adaptation property only diﬀer in
the direction of G0 ⇒∗G2 and G2 ⇒∗G0 via Rnorm. For the normal and the rollback
adaptation properties, it is required that the adapted state G2 be related to the old
state G0 by a normal transformation. The direct adaptation property implies both
the normal and the rollback property using G2 = G0.
△
Theorem 10.14 (Self-adaptation classes and their SA properties).
An SA system SAS is
I. corrective, if we have property 1 below
II. enhancing, if we have
a) property 2 or b) properties 3 and 4 below.
1. SAS has the direct adaptation property.
2. SAS has the normal adaptation property.
3. SAS has the rollback adaptation property.
4. Each pair (r, q) ∈Rnorm × Radapt is sequentially independent.
△

10.2 Static Analysis of Self-adaptive Systems
315
Proof.
I. Given Ginit ⇒∗G via (q1, . . . qn) ∈(Rnorm ∪Rcont)∗with G ∈Adapt(SAS), we
have n ≥1, because Ginit ∈Norm(SAS) since S AS is normal-state consistent. By
sequential independence we can switch the order of (q1, . . . qn), s.t. ﬁrst all normal
rules ri ∈Rnorm and then all context rules pi ∈Rcont are applied. For example let
us consider Ginit ⇒+ G via (r1, p1, r2, p2, r3) with ri ∈Rnorm and pj ∈Rcont. Then
sequential independence leads by the Local Church–Rosser theorem to equivalent
sequences in subdiagrams (1), (2), (3) respectively.
Ginit
r1 +3 G1
r2
$
p1 +3 G2
r2
+3
(1)
G3
r3
 (
p2
+3 G4
r3 +3
(2)
G
R+
adapt
fn
G′
2
p1
6>
r3
'
(3)
G′
4
p2
;C
R+
adapt
iq
G′
3 = G′
p1
7?
By the direct adaptation property 1, we have that G′
4 ⇒∗G′
3 and G ⇒∗G′
4
via R∗
adapt. With G′ = G′
3 we have that G ⇒+ G′ via R∗
adapt and Ginit ⇒∗G′ via
(r1, r2, r3) ∈R∗
norm, where (r1, r2, r3) is the subsequence (r1, p1, r2, p2, r3), which
consists of only normal rules, and normal-state consistency implies Ginit,G′ ∈
Norm(SAS). Note that in the adaptation sequence G ⇒+ G′, the (possible) adap-
tations due to the adaptation hooks caused by p1, p2 ∈Rcont are performed in oppo-
site order. In general, the sequence (q1, . . . qn) (n ≥1) contains at least one rule in
Rcont, because otherwise G < Adapt(SAS) (due to normal-state consistency), which
is a contradiction to the assumption G ∈Adapt(SAS). This implies that we have an
adaptation sequence G ⇒+ G′ via Radapt. Since adaptation rules are conﬂuent and
terminating, all possible adaptation transformations G ⇒+ G lead to the same result
G  G′. Hence SAS is corrective.
II a) We can proceed as above up to the point, where ﬁrst all normal and then all
context rules are applied. As shown in our example, the normal adaptation property
2 leads ﬁrst to an adaptation transformation G ⇒+ G5 via Radapt with G′
4 ⇒∗G5
via Rnorm, and then we can switch rules in (4) according to the sequential indepen-
dence of context and normal rules. Finally the normal adaptation property 2 leads to
G5 ⇒+ G6 via Radapt, with G′
5 ⇒∗G6 via Rnorm.
Ginit
r1 +3 G1
r2
#
p1 +3 G2
r2 +3
(1)
G3
r3
#
p2 +3 G4
r3 +3
(2)
G
R+
adapt
'
G′
2
p1
;C
r3
"
(3)
G′
4
p2
<D
(4)
R∗
norm
+3 G5
R+
adapt

G′
3
p1
<D
R∗
norm
"
G6 = G′
G′
5
R∗
norm
?G
p1
:B

316
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
Altogether, we obtain for G′ = G6 an adaptation transformation G ⇒+ G5 ⇒+
G6 = G′ and a normal rule transformation Ginit ⇒∗G′
3 ⇒∗G′
5 ⇒∗G6 = G′, which
implies G′ ∈Norm(SAS) by normal-state consistency. In general, G ∈Adapt(SAS)
implies that we have at least one context rule in the given sequence and hence an
adaptation transformation G ⇒+ G′ of length n ≥1. Since adaptation rules are con-
ﬂuent and terminating, all possible adaptation transformations G ⇒+ G lead to the
same result, G  G′. Hence, SAS is enhancing.
II b) Again, we proceed as above up to the point, where ﬁrst all normal and then
all context rules are applied. Due to property 3, we have the rollback adaptation
property which leads in our example to a normal transformation sequence G5 ⇒∗G′
4
via Rnorm after an adaptation transformation G ⇒+ G5 via Radapt and to a normal
transformation sequence G′
5 ⇒∗G′
3 via Rnorm after an adaptation transformation
G′
4 ⇒+ G′
5 via Radapt. Due to property 4, we can switch rules in square (4), leading
to G ⇒+ G6 via Radapt and to G6 ⇒∗G′
3 via Rnorm.
Ginit
r1 +3 G1
r2
#
p1 +3 G2
r2 +3
(1)
G3
r3
#
p2 +3 G4
r3 +3
(2)
G
R+
adapt
'
G′
2
p1
;C
r3
"
(3)
G′
4
p2
;C
R+
adapt
"
G5
R+
adapt

R∗
norm
ks
(4)
G′
3
p1
<D
G′
5
R∗
norm
ks
G6 = G′
R∗
norm
ks
Altogether, we obtain for G′ = G6 an adaptation transformation G ⇒+ G5 ⇒+
G6 = G′ and normal rule transformations Ginit ⇒∗G′
3 ⇐∗G′
5 ⇐∗G6 = G′. Fi-
nally, since normal rules preserve and reﬂect also adaptation states due to normal
state consistency, we can conclude that G6 = G′ ∈Norm(SAS): if G′ was an adap-
tation state, then also G′
3 would be an adaptation state since normal rules preserve
adaptation states. Since adaptation rules are conﬂuent and terminating, all possible
adaptation transformations G ⇒+ G lead to the same result G  G′. Hence, SAS is
enhancing.
⊓⊔
Remark 10.15. Note that our suﬃcient conditions for Theorem 10.14 are also nec-
essary in case that the context rules are sequentially independent. It is advisable to
model the set of context rules in this way because usually the need for adaptation
may arise in any possible state from independent sources of disturbances issued by
the environment. In our example, the context rules are all independent, i.e., if they
are applicable in a sequence, their order can be swapped.
△
In Theorem 10.18 we deﬁne static conditions for the direct, normal and rollback
adaptation properties. By Theorem 10.14, these static conditions are also suﬃcient
conditions for the nature of our self-adaptive system. We then make use of the static
conditions to verify the properties of the diﬀerent adaptations of our Car Logistics
Systems case study.
In part 1 of Theorem 10.18 we require that for each context rule p the inverse rule
p−1 be SAS-equivalent to the concurrent rule q∗constructed from an adaptation rule

10.2 Static Analysis of Self-adaptive Systems
317
sequence (q1, . . . , qn) ∈Radapt. We will explain shortly the notions SAS-equivalent
rules, inverse rule and concurrent rule before stating Theorem 10.18.
SAS-equivalent rules model the same possible system changes:
Deﬁnition 10.16 (SAS-equivalent rules). Let SAS be an SA system and r1, r2 ∈
Rsys be two system rules of SAS. Two rules r1 and r2 are called SAS-equivalent
(written r1 ≃r2) if ( ∃G
r1
=⇒G′) ⇐⇒( ∃G
r2
=⇒G′) with G ∈Reach(SAS).
△
Remark 10.17 (Suﬃcient conditions for SAS-equivalent rules). An obvious suﬃ-
cient condition for checking SAS-equivalence of two rules is that the rules are iso-
morphic (two rules are isomorphic if they are componentwise isomorphic). Some-
times, this condition is too strong (as we will see later for our example). A weaker
suﬃcient condition is that the two rules are “isomorphic up to ﬁxed objects”, i.e.,
one rule may contain more elements than the other rule under the condition that
these additional elements are 1) preserved by the rule and 2) available in all states
reachable by rules of the corresponding grammar. Moreover, 3) all NACs that are
not isomorphic for both rules have to hold in all reachable states. Obviously, in this
case the rules are applicable at the same matches and result in the same transforma-
tion. Note that conditions 1) to 3) can be checked statically by inspecting the initial
state and the rules.
△
For p = (L ←I →R) with negative application condition nac : L →N
it is possible to construct the inverse rule p−1 = (R ←I →L) with equivalent
nac′ : R →N′, such that G
p
=⇒G′ implies G′
p−1
=⇒G, and vice versa (see Def. 5.15).
A concurrent rule summarises a given rule sequence in one equivalent rule (see
Def. 5.27). In a nutshell, a concurrent rule p ∗E q is constructed from two rules,
p = (Lp ←Kp →Rp) and q = (Lq ←Kq →Rq), that may be sequentially
dependent via an overlapping graph E by modelling all deletions and creations of
elements that are modelled either in p or in q. The application of the concurrent rule
then has the same eﬀect as applying p ﬁrst, and applying q subsequently, where the
co-match of p and the match of q overlap, as deﬁned in their overlapping graph E
(see Theorem 5.30).
The concurrent adaptation rule (p1∗. . .∗pn)E with E = (E1, . . . , En−1) for a longer
sequence is constructed in an iterated way by (p1∗. . .∗pn)E = p1∗E1 p2∗E2. . .∗En−1 pn.
In Theorem 10.18 we require as weaker conditions that each context rule p have
a corresponding adaptation sequence (q1 ∗. . . ∗qn) ∈Radapt, which is not necessar-
ily inverse to p. We require that q be applicable after p has been applied, which is
not a real static condition, but it can be argued from the context whether it is ful-
ﬁlled. In part 2 of Theorem 10.18 it is suﬃcient to require for the normal adaptation
property that we be able to construct a concurrent rule p ∗E0 (q1, . . . , qn)E which
is SAS-equivalent to a concurrent rule r constructed from a normal rule sequence
(r1, . . . , rm) ∈Rnorm. Analogously, for the rollback adaptation property we require
that p ∗E0 (q1, . . . , qn)E be SAS-equivalent to an inverse concurrent normal rule r−1 .
Theorem 10.18 (Veriﬁcation of self-adaptation properties).
Let SAS be an SA system and G a reachable system state. SAS has

318
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
1. the direct adaptation property if for each context rule p there is an adaptation
rule sequence that directly reverses the eﬀect of the context rule, i.e., ∀p ∈Rcont
∃q = (q1 ∗. . . ∗qn)E via E = (E1, . . . , En−1) and n ≥1, qi ∈Radapt with q ≃p−1.
2. the normal (resp. rollback) adaptation property if for each context rule p there
is an adaptation rule sequence that reverses the eﬀect of the context rule up to
normal rule applications, i.e., ∀p ∈Rcont we have
(a) ∃q = (q1 ∗. . . ∗qn)E via E = (E1, . . . , En−1) and n ≥1, qi ∈Radapt, and q is
applicable after p has been applied,
(b) ∀overlappings E0 of p and q leading to a concurrent rule p ∗E0 q ∃r =
(r1 ∗. . . ∗rm)E′ with m ≥1 via E′ = (E′
1, . . . , E′
m−1) with ri ∈Rnorm such that
p ∗E0 q ≃r (resp. p ∗E0 q ≃r−1 in case of rollback).
△
Proof.
1. Given the context rule p = (L
l
←−K
r
−→R) with NACs naci,L : L →Ni,L(i ∈I),
the inverse rule is given by p−1 = (R
r
←−K
l
−→L) with corresponding NACs
naci,R : R →Ni,R. Now, given p ∈Rcont and G0 ∈Reach(SAS) with G0
p
=⇒G1,
we have by assumption (q1, . . . , qn) ∈R∗
adapt with (q1 ∗. . . ∗qn)E ≃p−1, and
by construction of p−1 also G1
p−1
=⇒G0 and hence also G1
(q1∗...∗qn)E
=⇒
G0 by SAS
equivalence, which implies by the Concurrency Theorem that G1
∗
=⇒G0 via
Radapt.
2. Given G0 ∈Reach(SAS) and G0
p
=⇒G1 with p ∈Rcont, by (a) ∃q = (q1 ∗
. . . ∗qn)E with n ≥1 and qi ∈Radapt, and q is applicable after p has been
applied. Since G0
p
=⇒G1 we also have G1
q
=⇒G2 for some G2 and hence
G0
p
=⇒G1
q
=⇒G2. According to Fact 5.29, an overlapping E0 of p and q exists,
such that G0
p
=⇒G1
q
=⇒G2 are E0-related and hence G0
p∗E0q
=⇒G2. By (b), we
have ∃r = (r1 ∗. . . ∗rm)E′ with m ≥1 and ri ∈Rnorm such that p ∗E0 q ≃r in
the case of the normal adaptation property (resp. p ∗E0 q ≃r−1 in the case of the
rollback adaptation property). Hence, in case of the normal adaptation property,
G0
p∗E0q
=⇒G2 implies G0
r
=⇒G2. Now, G0
r
=⇒G2 and G1
q
=⇒G2 via concurrent
rules r and q imply by Concurrency Theorem sequences G0
+
=⇒G2 via Rnorm
and G1
+
=⇒G2 via Radapt, leading to the normal adaptation property. Similarly,
in the case of the rollback adaptation property, we have that G0
p∗E0q
=⇒G2 implies
G0
r−1
=⇒G2, such that G2
r
=⇒G0. Now, G2
r
=⇒G0 and G1
q
=⇒G2 via concurrent
rules r and q with n, m ≥1 imply sequences G2
+
=⇒G0 via Rnorm and G1
+
=⇒G2
via Radapt, leading to the rollback adaptation property.
⊓⊔
In the following Examples 10.19 and 10.20, we verify the self-adaptation prop-
erties for diﬀerent variants of our Car Logistics System case study, CLS, consider-
ing diﬀerent adaptations. Two more examples are elaborated on in [BEE+13], in-
cluding a counterexample, where the self-adaptation properties do not hold. In all

10.2 Static Analysis of Self-adaptive Systems
319
Fig. 10.12 Concurrent adaptation rule q constructed from sequence s in CLS Repair
examples we have the same normal rules, Rnorm = {ServiceToDo, EnterBP, DoSer-
vice, DoSubService, NextBA, FinishBP}, and a subset of the context rules, Rcont =
{SlightlyDamage,SeverelyDamage, Queue}, of CLS. Hence, we have sequential inde-
pendence of context rules and normal rules, and, since CLS is normal-state consis-
tent, also CLS Repair,CLS RollbackAndRepair,CLS Queue, and CLS Dispose are normal-state
consistent.
Example 10.19 (SA system CLS Repair is corrective). In CLS Repair, we analyse the
repair adaptation of CLS . This means that we have one context rule Rcont = {Slightly-
Damage} (Fig. 10.7), and the set of adaptation rules Radapt = R2
adapt = {TakePullTo-
TreatmentService, TakeRepairService, RepairVehicle}. Moreover, Cadapt = {Damage} is
the set of adaptation constraints.
According to Theorem 10.14, we have to show that CLS Repair has the direct adap-
tation property (property 1). According to Theorem 10.18, CLS Repair has the direct
adaptation property if for p = SlightlyDamage we have (q1, . . . , qn) ∈Radapt with
q = (q1 ∗. . . ∗qn)E ≃p−1, where q is the concurrent rule of the adaptation rule
sequence (q1, . . . , qn). This means that we have to ﬁnd an adaptation rule sequence
that results in a concurrent rule q which is SAS-equivalent to the inverse context rule
p = SlightlyDamage (i.e., it removes the SlightlyDamaged ﬂag).
We consider the adaptation rule sequence s = {TakePullToTreatmentService,Take-
RepairService, RepairVehicle} together with suitable dependencies (overlappings) of
the right-hand side of qi and the left-hand side of qi+1, and construct a concurrent
rule from this sequence in an iterated way. In AGG, the construction of concurrent
rules from rule sequences can be computed automatically. For our sequence, we get
the concurrent adaptation rule depicted in Fig. 10.12.
The concurrent adaptation rule q is SAS-equivalent to the inverse context rule p =
SlightlyDamage due to the following argumentation: The additional elements in rule q
w.r.t. rule p (the PullToTreatment and Repair nodes) are preserved by q, and are always
there in all possible states, since no system rule ever adds or deletes PullToTreatment
and Repair nodes.
Hence, CLS Repair has the direct adaptation property, and due to Theorem 10.14,
we can conclude that CLS Repair is corrective.
△
Example 10.20 (SA system CLS Queue is enhancing). In CLS Queue, we consider the
wait-at-queue adaptation. This means that we have one context rule Rcont = {Queue}
and the following set of adaptation rules: Radapt = {Enqueue, DoService, RemoveWait}.
Moreover, Cadapt = {Wait} is the set of adaptation constraints.

320
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
Fig. 10.13 Concurrent adaptation rule q constructed from sequence s in CLS Queue
According to Theorem 10.14, we show that CLS Queue has the normal adapta-
tion property (property 2). According to Theorem 10.18, CLS Queue has the normal
adaptation property if for p = Queue we have that
(a) ∃q = (q1 ∗. . . ∗qn)E via E = (E1, . . . , En−1) and n ≥1, qi ∈Radapt and q is
applicable after p has been applied,
(b) ∀overlappings E0 of p and q, leading to a concurrent rule p ∗E0 q ∃r =
(r1 ∗. . . ∗rm)E′ via E′ = (E′
1, . . . , E′
m−1) with ri ∈Rnorm such that p ∗E q ≃r.
For the context rule p = Queue, we have a sequence of adaptation rules s =
{Enqueue, DoService, RemoveWait} that results in the concurrent rule q shown in
Fig. 10.13. Since the right-hand side of p equals the left-hand side of q, we can
conclude that q is applicable after p has been applied, as required in (a).
We then construct according to (b) the concurrent rule Queue ∗Eq which equals
rule q in Fig. 10.13 but does not contain the context nodes Wait and Queue and
their adjacent edges. Obviously, this rule Queue ∗Eq is isomorphic to a concurrent
rule r constructed by the sequence of normal rules (DoService ∗E′ DoService), which
removes two todo edges from two diﬀerent vehicles to the same service in one step.
Hence, Queue ∗Eq and r are SAS-equivalent.
Thus, CLS Queue has the normal adaptation property, and due to Theorem 10.14,
we can conclude that CLS Queue is enhancing.
△
We give two further explicit examples in [BEE+13], using our static conditions
to show that CLS RollbackAndRepair is enhancing and that CLS Dispose does not satisfy
the suﬃcient conditions for SA properties.
10.3 Automating the Approach by AGG
AGG3 (see Sect. 12.1) is a well-established tool environment for typed attributed
graph transformation. Graphs in AGG are deﬁned by a type graph with node type
inheritance and may be attributed by any kind of Java object. Graph transformations
3 AGG (Attributed Graph Grammars): http://www.tfs.tu-berlin.de/agg

10.3 Automating the Approach by AGG
321
can be equipped with arbitrary computations on Java objects described by Java ex-
pressions. Sect. 12.1 presents an extensive description of the AGG environment,
consisting of several visual editors, an interpreter, and a set of validation tools.
As shown in the previous sections, our framework for modelling and analysing
SA systems is supported by the AGG tool for modelling both the initial conﬁgura-
tion of the system and also the possible conﬁgurations that the system can reach in
the case of adaptations. A simulation of adaptations is performed by applying adap-
tation rules within AGG so that practitioners can get conﬁdence on the system and
its evolutions.
From the modelling point of view, referring to the example, within AGG the
model engineer can perform the system design in a visual way: the business process
and services shown in Fig. 10.1 can be directly mapped to elements of the initial
state graph depicted in Fig. 10.4. Furthermore, graph constraints can be graphically
represented, as illustrated in Sect. 10.1.3. The behaviour and the evolution of the
system are also graphically represented within AGG in a rule-based, intuitive way.
From the analysis point of view, dependencies between rules and conﬂicts be-
tween rules in a minimal context (critical pairs) can be computed fully automati-
cally. The results support our argumentation, showing that the suﬃcient conditions
for our two theorems are satisﬁed in our examples. Moreover, the construction of
concurrent rules from rule sequences is also fully automatic. It is only required that
the modeller deﬁne a suitable object ﬂow between the rules of the sequence to deﬁne
the overlapping graphs of rules and to get a unique resulting concurrent rule.
In the following, we discuss some aspects to assess the applicability of the pro-
posed analysis techniques.
Practical relevance of assumptions: For the Car Logistics case study, we found
the assumptions for SA systems very helpful for structuring the model (by distin-
guishing diﬀerent sets of rules for normal behaviour, context changes and diﬀerent
adaptations). The suﬃcient conditions we checked for applying our results did not
prove to be too strong. Instead, whenever our model did not satisfy one of the suf-
ﬁcient conditions, the changes we implemented in the model did not only result in
the satisfaction of the conditions but also in a more systematic and concise model.
Achieved degree of automation: All our analysis techniques are static, i.e., they
check rule properties only. Yet, some of the techniques require manual eﬀort, i.e.,
reasoning about rule properties that are not supported by AGG in a fully automatic
way. For instance, although AGG implements checking suﬃcient conditions for ter-
mination of rule sets, for our example these suﬃcient conditions turned out to be too
strong. So we had to argue about termination by inspecting the rules “manually”.
Similarly, since up to now there is no automatic check for SAS equivalence of
rules implemented, we had to perform these checks by hand by inspecting the rules
ourselves. Critical pair analysis is a powerful instrument assisting with checking
conﬂuence of rule sets. A suﬃcient condition for the conﬂuence of a system is (ter-
mination and) the absence of critical pairs. But if critical pairs are found, indicating
potential conﬂicts, manual eﬀort is needed to show whether these critical pairs could

322
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
really lead to conﬂicts in a speciﬁc system or not. Usually, these hints are very help-
ful for the modeller and show where problems lie and the model should be adapted.
Currently, the adaptation manager selects the most suitable adaptation grammar
manually. In future, this decision could be supported by deﬁning priorities for adap-
tation grammars depending on the severity of the disturbance (“treat worst case
ﬁrst”). This is currently not supported by AGG. Finding suitable adaptation se-
quences using an adaptation grammar is realised in a semiautomatic way by sim-
ulation: by applying the adaptation rules nondeterministically, the adaptation is per-
formed automatically, and by keeping track manually of the used rules and their
matches, the rule sequence and its object ﬂow are determined. The object ﬂow of
the used rule sequence is then the input to AGG’s automatic construction of a con-
current adaptation rule. It would be desirable if for larger grammars AGG could
automatically record the rule application order and their matches when applying
rules from the grammar. The recorded sequence and its object ﬂow derived from the
match overlappings could then be used to construct a concurrent rule fully automat-
ically from a simulation run.
Time and memory consumption: The time consumption for the fully automatic
computation of dependency and conﬂict tables in our example4 depends on the num-
ber of rules in the corresponding grammar and the number of objects (nodes and
edges) in the rules. Time increases exponentially for large rules. For analysing con-
ﬂicts of the wait-and-queue adaptation with the largest number of objects in rules,
AGG took 115 seconds; all other conﬂict and dependency tables were computed in
less than 4 seconds.5 It is hence advisable to use more but smaller rules instead of
describing the system by fewer and larger rules. For the fully automatic computation
of concurrent rules from rule sequences that were used in our example, AGG used
less than one second.
Scalability: Obviously, time and memory consumption grows when the modelled
system becomes larger. However, when the system becomes more complex w.r.t.
the number of rules and the size of the system graphs, we ﬁnd that the size of rules
(modelling only local eﬀects) remains nearly stable. It is in the hands of the mod-
eller to formulate a rule set that can remain small enough to be analysed properly.
The size of the system graphs does not inﬂuence the performance of our static anal-
yses. Up to now, AGG can analyse rules with up to 20 – 30 elements in reasonable
time.
Addition of rules at runtime: Since our framework for modelling SA systems is
modular, i.e., based on diﬀerent rule sets, we can simulate adding new rule sets
(adaptation grammars) to the system at runtime. To add a new adaptation hook to
the system, the type graph must be updated by adding the new adaptation hook type.
Ideally, this type is a subtype of a more general adaptation hook type. In this case,
4 Measured on a standard notebook with an Intel dual-core processor and 2 GB of memory.
5 Explicit benchmark values for our case study can be found in [BEE+13].

10.4 Related Work
323
the existing rules do not have to be updated at all, only a new context rule and a
new adaptation grammar speciﬁc to the new adaptation hook have to be added to
the system. The adaptation manager realises the selection of available adaptation
grammars and this may include new grammars when needed.
10.4 Related Work
In this section, we compare our work with related approaches to adaptive system
modelling and analysis, focusing on context-awareness, self-adaptiveness, formali-
sation and tool support, which we see as main aspects of SA system modelling.
Own previous work: In [BPVR09], we proposed for the ﬁrst time an approach to
modelling self-repairing system architectures as typed (hyper-)graph grammars and
veriﬁed them w.r.t. dependencies and conﬂicts of rules modelling the environment,
the normal system and repair actions. This approach was extended in [EER+10] to
modelling self-healing (SH) systems using algebraic graph transformation. In this
book, we have built on the preliminary suﬃcient conditions formulated in [EER+10]
and generalised the approach to the class of adaptive systems that is identiﬁed in
Sect. 10.1.1. This approach includes enhancing adaptive systems, i.e., systems that
enhance existing services of the application and can be adapted to become normal
again, but up to new functionalities or services. For ensuring that a system is indeed
enhancing, we now check statically the normal (or rollback) adaptation property,
requiring that there be adaptation rule sequences leading back to normal states (in-
stead of looking only for inverse adaptation rules as in [EER+10]). We also now
allow for more general static conditions to ensure corrective behaviour; for the di-
rect adaptation property, we require the existence of a sequence of adaptation rules
that reverses the eﬀect of the context rule (up to normal rules) instead of a single in-
verse rule. [BCG+12] presents a conceptual framework, where adaptation is deﬁned
as the runtime modiﬁcation of the control data. Our approach is compatible with
this framework, in the sense that the control data can be identiﬁed by the dividing
of the set of rules into rules that correspond to normal system behaviour and rules
that implement adaptation mechanisms.
Software Architectures: There is a wealth of Architecture Description Languages
(ADLs) and architectural notations which provide support for dynamic software
architectures analysis [BCDW04].
[BB09] proposed an approach called Genie that oﬀers management of structural
variability of adaptive systems. Genie can be considered as an ADL with genera-
tive capabilities for reconﬁguring from one system structure to another according to
changes in the environment and for deciding what kind of structural reconﬁguration
has to be performed. The main limit of this approach is the absence of a way to guar-
antee desired properties of the systems after each adaptation execution; the language
is not supported by any formal framework. From the modelling point of view, the

324
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
approach is speciﬁcally architectural, whereas we propose a general approach that
can be used at diﬀerent levels of abstraction. For instance, our case study presents
the business process of a service-oriented scenario.
[GCH+04] introduced an SA-based self-adaptation framework, called Rainbow,
using external mechanisms and an SA model to monitor a managed system, de-
tect problems, determine a course of action, and carry out the adaptation actions.
Rainbow, by making use of architectural styles, provides infrastructures with ex-
plicit customisation points. The deﬁnition of these customisation points limits the
dynamicity of the approach; in particular, the context is not considered as a part of
the system model that can evolve during the system lifecycle. In our approach, we
do not rely on predeﬁned customisation points to manage the adaptation, but we
monitor properties of the context to understand where and how to adapt the system.
[HIM00] presented an approach specifying software architecture styles using hy-
peredge replacement systems. The authors use graph rewriting combined with con-
straint solving to specify how components evolve and communicate. With respect to
our approach, the limits are: (i) the way they check the system correctness, and (ii)
the tool support. Regarding system correctness, they need to inspect all the reachable
system states for each property to be veriﬁed. In our approach, we deﬁne operational
properties (corrective, enhancing, direct (normal) adaptation, etc.) that we check in a
static way by inspecting only the related rules without producing all reachable states
explicitly. Moreover, their formal framework is not supported by a tool, whereas our
formal framework is supported by AGG to model and analyse self-adaptive systems.
[BHTV05] presented an approach checking whether an architecture is a reﬁne-
ment of another one by deﬁning relationships between abstract and concrete styles.
Reﬁnement involves a reachability analysis for a target conﬁguration from a given
initial conﬁguration. Reachability is analysed by model checking and simulation,
which requires us to a priori restrict the systems to ﬁnite state systems by restricting
the number of dynamic model elements that can be created by the transformation
rules. Static analysis techniques, as applied by us, do not have this limitation. More-
over, we do not only consider reﬁnements but more general system adaptations.
[BG08] presented a graph transformation-based approach to modelling correct
self-adaptive systems on a high level of abstraction. The approach considers dif-
ferent levels of abstraction according to the reference architecture by [KM07]. The
correctness of the modelled self-adaptive systems is checked by using simulation
and invariant checking techniques. Invariant checking is mainly used to verify that
a given set of graph transformations will never reach a forbidden state. The veriﬁ-
cation is eﬃcient and the complexity is linear in the number of rules and properties
to be checked. The limitation of this approach is that a unique model is used for
application and adaptation logics. This means that when a new adaptation case is
added, the overall model must be reﬁned. In our approach, the adaptation logic is
developed separately from the application logic in terms of adaptation rules. The
adaptation logic can be modiﬁed without requiring us to change the application.
Service-Oriented Computing: In the community of Service Oriented Computing,
various approaches supporting self-healing have been deﬁned, e.g.: for triggering re-

10.5 Summary
325
pair strategies as a consequence of a requirement violation [SZK05]; for optimising
QoS of service-based applications [CPEV05]; for satisfying some application con-
straints [VGS+05]. Repair strategies usually are speciﬁed by means of policies for
managing the dynamics of the execution environment [BGP07, CNM06]. The goals
of the strategies proposed by the aforementioned approaches range from service
selection to rebinding and application reconﬁguration [PLS08]. Some techniques
enable the deﬁnition of various adaptation strategies but they all lack a coherent de-
sign approach for supporting designers in this complex task.
Summarising, our approach abstracts from particular languages and notations
and can be applied at diﬀerent levels of granularity. We provide a coherent design
approach that allows software engineers to model and analyse self-adaptive systems
within the same framework. Once a suitable level of abstraction has been identiﬁed,
the system can be modelled together with adaptation strategies and mechanisms.
The system speciﬁcation is then used to formally verify operational properties.
10.5 Summary
In this chapter, we have modelled and analysed self-adaptive systems using al-
gebraic graph transformation and graph constraints. We have deﬁned consistency
properties that include system consistency, normal state consistency, and adaptation
state consistency. Furthermore, we have deﬁned operational properties that include
self-adaptation, corrective self-adaptation and enhancing self-adaptation; we also
have deﬁned direct, normal, and rollback adaptation properties concerning the be-
haviour of adaptations w.r.t. their inﬂuence on the normal system behaviour. Our
analysis detects in which class of self-adaptive systems a given system belongs (en-
hancing, corrective), and which properties we have with respect to the kind of adap-
tation (direct, normal, rollback). The classiﬁcation helps us to reason about system
behaviour, where systems with the rollback adaptation property may be in more dan-
ger of repeated failures than systems with normal adaptation property, since states
that preceded failures are reached again after the adaptation. Note that the oper-
ational properties concern all reachable system states, whereas they are checked
in a static way by inspecting only the rules without producing all reachable states
explicitly.
The main results concerning operational properties of SA systems are sum-
marised in Fig. 10.14, where most of the static conditions in Theorems 10.14
and 10.18 can be automatically checked by the AGG tool. We have needed man-
ual eﬀort to show the termination of properties and SAS equivalence of rules, but
it was always possible to perform the analysis statically. Although static conditions
lead to overapproximation of systems, we have found that the conditions to check
were reasonable enough to be expected to hold in SA systems and did not restrict
our intuitive notion of SA system properties. Exemplarily, the diﬀerent properties

326
10 Modelling and Static Analysis of Self-adaptive Systems by Graph Transformation
Fig. 10.14 Static SAS analysis
are veriﬁed for diﬀerent adaptations of our car logistics system in a seaport termi-
nal.
In our approach, the selection of an adaptation grammar is done by a human adap-
tation manager who selects the most suitable adaptation. In an extended approach, a
distinguished kind of control attribute (like, e.g., failure counter or timeout parame-
ter) might be used to select automatically between diﬀerent variants of adaptations.
Note that states with additional control attributes (typed over control types) would
still be normal states in our framework (not violating adaptation constraints). Our
results hence can be extended in a straightforward way by reformulating the more
ﬂexible operational properties of enhancing and corrective systems to hold “up to
changed control attributes”. We refrained from this extension here to keep proofs
clear and simple.
Future work is needed to further automate the checks currently needing manual
eﬀort with AGG. To enhance the practical usability of static analysis, a continuous
optimisation of the performance of the critical pair analysis AGG is in progress.
Finally, the implementation of a logging feature for recording the order and matches
of applied rules in AGG would be very helpful for automating the selection of rule
sequences in our adaptation framework.

Chapter 11
Enterprise Modelling and Model Integration
The aim of enterprise modelling is to support and improve the design, docu-
mentation, analysis and administration of business objects and operations based
on adequate modelling techniques [FG98, SAB98]. For this purpose, domain-
speciﬁc enterprise models shall provide the basis for communication between peo-
ple with diﬀerent professional backgrounds [Fra02]. This chapter presents how
model transformation and integration techniques presented in Part III can be ap-
plied to automate and improve the modelling tasks within a distributed enterprise
modelling framework. Sect. 11.1 describes the main aspects of enterprise mod-
elling and presents the used enterprise modelling framework. Sect. 11.2 illustrates
how the alignment of diﬀerent domains within the framework can be speciﬁed
by triple graph grammars. Sects. 11.3 and 11.4 demonstrate the application of
model transformation and integration techniques to concrete domain models. Fi-
nally, Sect. 11.5 discusses the achievements, their relevance and related work. This
chapter is based on the results of a research collaboration between Technische Uni-
versität Berlin, the University of Luxembourg and Credit Suisse, which were pub-
lished in [BHE09c, BHEE10, BH10, Her11, Bra13].
11.1 Enterprise Modelling
Enterprise models provide representations of the structures, processes, resources,
involved actors, executed functions, goals, and constraints relevant for the modelled
enterprise. For this reason, enterprise modelling has to provide an agile modelling
process, which is integrated across the diﬀerent business functions [FG98]. An agile
modelling process additionally reduces the required time frames for adapting the
models according to change requests, which can occur quite frequently during the
lifetime of an enterprise. Moreover, adequate modelling techniques should support
the propagation of changes from one domain to others. This way, the knowledge and
expertise of enterprise modellers can be focussed on their main domain, which is an
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_11
327

328
11 Enterprise Modelling and Model Integration
Fig. 11.1 Enterprise model framework
important requirement for decentralised and distributed models occurring especially
in large multinational enterprises.
In order to master the high complexity of an enterprise in its whole, visual mod-
elling techniques have been successfully applied. They provide intuitive notations
and high abstraction capabilities. Clearly, visual models cannot replace all textual
models in all domains. But still, where suitable, they often show high beneﬁts. Fur-
thermore, enterprise models are usually not only used for the design and documenta-
tion of enterprises, but also for the analysis and management of operations. In partic-
ular, process analysis concerns, e.g., the question whether certain business processes
can be performed in a diﬀerent but more suitable way, such that some goals can be
achieved in an optimised way. In combination with formal abstract syntax deﬁni-
tions, visual modelling techniques can enable veriﬁed automated analyses, which
can support error detection and thus quality assurance of the models.
In order to satisfy the requirements in enterprise modelling, we apply formal
techniques based on graph and model transformation of Parts II and III, which pro-
vide powerful and eﬃcient techniques for model transformation and integration.
Their formal foundation ensures correct analysis results and the automated tool sup-
port provides eﬃcient checks. The techniques provide the basis for an agile and de-
centralised modelling process, including distribution of models and eﬃcient change
propagation.
The integration of diﬀerent enterprise models requires, on the one hand, the appli-
cation of techniques that ensure certain quality and consistency requirements and,
on the other hand, the application of techniques for setting up and maintaining a
common understanding of the enterprise by the modellers. While this chapter ap-
plies suitable techniques for the ﬁrst requirement based on the concepts in Part III,
the common understanding is supposed to be set up and maintained based on so-
phisticated techniques in the area of ontology engineering [FG98].
The main domains of enterprise modelling can be captured by the enterprise
modelling framework in Fig. 11.1, introduced by Brandt et al. [BHE09c, BH10,
Bra13]. It shows diﬀerent coordinates (X, Y, Z) and each of them represents a con-
tainer for several domain-speciﬁc models. For instance, coordinate (S, B, M) repre-

11.1 Enterprise Modelling
329
sents all service models for the business universe using a machine-centric modelling
language. We denote the set of the models in one coordinate by MX,Y,Z and refer to
a speciﬁc model by the notation MX,Y,Z for a model MX,Y,Z ∈MX,Y,Z. Clearly, there
are several further perspectives and aspects within an enterprise which are also rel-
evant for enterprise modelling, but they go beyond the scope of this chapter. How-
ever, the general techniques provided in this book show good potential that they can
also improve the modelling process in further domains, as discussed and evaluated
in [BH10, Bra13].
The separation of models into business and IT domain models is a common stan-
dard (see, e.g., [CIO99]). The main idea is to separate the application and task ori-
ented view of services, processes and rules in the business universe from speciﬁc
realisations via implemented components in the IT domain to provide automation
for these applications and tasks. The alignment between both domains, however, is
usually not complete. Parts of a business domain model can be automated via a cor-
responding IT model. Other parts of the business domain model may stay without
IT support. Vice versa, parts of an IT model may automate a corresponding business
model. However, the IT may have their own speciﬁc services, processes and rules
for which there is no correspondence in the business domain models. Therefore,
neither a top-down nor a bottom-up relationship is appropriate in the general case.
Besides diﬀerentiating between business and IT model domains, Fig. 11.1 cate-
gorises their content into service, process, and rule models. Moreover, it separates
according to the primarily used concepts, depending on whether they are machine-
centric concepts or human-centric concepts, i.e., whether they are meant for doc-
umentation and human interaction (human-centric domain) or primarily for execu-
tion and automated analysis (machine-centric domain). The separation into diﬀerent
model spaces leads to a separation of concerns while allowing for an overlapping on
common aspects. This reduces the complexity for domain modelling, but requires a
sound approach for model transformation and integration to handle the inter-model
dependencies.
In this chapter we will use ABT-Reo diagrams [Arb04, Arb05, BHEE10], which
are based on Abstract Behaviour Types and Reo connectors. ABTs specify system
components and are represented by blocks having ports. Reo connectors specify the
diﬀerent types of links between ports of ABTs and such structures can be composed
to form a single new ABT.
Remark 11.1 (Scope of the chapter within the model framework). The enterprise
model framework as shown in Fig. 11.1 encompasses the development of many
diﬀerent aspects. This chapter presents suitable intra- and and inter-modelling tech-
niques focussed on machine-centric business and IT service models given by ABT-
Reo diagrams, which can be used as a single modelling language for both types
of service models. These ABT-Reo models are intended to be aligned with their
corresponding human-centric service models. The scope of this chapter concerns
the model transformation and integration of ABT-Reo service models as illustrated
in Fig. 11.2. The techniques are general with respect to diﬀerent domain-speciﬁc
languages, because they are based on the underlying abstract syntax graphs of the

330
11 Enterprise Modelling and Model Integration
Fig. 11.2 Scope of this chapter
Fig. 11.3 Human-centric service models (left: business domain, right: IT domain)
models. Thus, there is a good potential that they can be applied for several other
dimensions in the enterprise model framework, too.
△
Human-centric service models are diagram-like language artefacts that sketch
service instances as well as their connections, and we present two examples for
human-centric service models in the business and IT domains.
Example 11.2 (Human-centric service models for business and IT domains). The
model on the left of Fig. 11.3 is a fragment of a human-centric business service
model. The departments “Investment Banking” and “Private Banking” are depart-
ments at Credit Suisse. Information exchanged between the two parties must com-
ply with the Chinese Wall Policy [BN89]. The policy deﬁnes what information is
allowed to be exchanged between the two departments. To guarantee that the policy
is respected a ﬁlter will suppress illegal messages between the two service instances
in the diagram. Each service instance represents a department. Therefore, the policy
is realised as a ﬁlter in a service model. This business view completely abstracts
Investment Banking
Private Banking
...
NW4
NW7
...

11.1 Enterprise Modelling
331
F1:Filter
Private_Banking:Department
Investment_Banking:Department
private
public
private
public
Reo-
connectors
ABT-
components
Investment Banking
Private Banking
ABT-Reo syntax
Human-centric syntax
Fig. 11.4 ABT-Reo instance in the business universe
away IT details. The fragment of a human-centric IT service model on the right
of Fig. 11.3 corresponds to the business model and shows interconnected network
zones “NW4” and “NW7”, which are connected via a secured connection.
△
For a concrete alignment between the business and IT model fragments in
Fig. 11.3, the private banking department can be mapped to the network zone
“NW4” and the investment banking department can be mapped to the network zone
“NW7”. The connector between the investment and the banking department in the
business universe is then related to the connections between networks “NW4” and
“NW7”.
Human-centric service models as they have just been introduced are only syntax
artefacts. A corresponding semantics can be assigned by the help of an alignment
with machine-centric models, as presented in [BHE09c, BHEE10, BH10]. The cor-
responding types of machine-centric models that we use in this case study are ab-
stract behaviour types and Reo connectors [Arb05, KB06, Arb04, AR02]. The rea-
son why we use abstract behaviour types and Reo connectors to specify services and
service landscapes is because of their support for exogenous coordination. In addi-
tion to that, abstract behaviour types focus on incoming and outgoing messages and,
therefore, abstract away implementation details of services. This frees an ABT-Reo
model from implementation aspects and reduces the overall complexity of models.
Example 11.3 (Machine-centric business model). Fig. 11.4 shows the human-centric
business model from Fig. 11.3 and a corresponding machine-centric business ser-
vice model. Here, two abstract behaviour types are used to represent the investment
and the private banking department. Messages running between these two abstract
behaviour types have to pass through diﬀerent Reo connectors. While messages via
private connectors are not visible to the outside, those along public connectors are
visible. The ﬁlter in the middle of the diagram listens to messages and will suppress
private messages targeting a public connector. This ﬁlter can be interpreted as a for-
mal speciﬁcation of an organisational security policy, like the Chinese Wall Policy.

332
11 Enterprise Modelling and Model Integration
E1:E/D
public
E2:E/D
public
NW4:LAN
NW7:LAN
private
private
private
private
ABT-Reo syntax
Human-centric syntax
NW4
NW7
Fig. 11.5 ABT-Reo instance M1 of the IT universe
For example, the ﬁlter may ensure that the communicated data does not contain
ﬁles which contain both address and balance information. Using model checking it
is possible to prove that no private message will ﬁnally pass by a public connec-
tor.
△
Example 11.4 (Machine-centric IT model). Fig. 11.5 shows the human-centric IT
model from Fig. 11.3 and a corresponding ABT-Reo diagram M1 specifying the
structure of a part of a network composed of local area networks (LANs). It con-
tains four ABT elements that are connected via Reo connectors. The two outer ABT
elements represent the LANs “NW4” and “NW7” while the two inner ones de-
note encryption/decryption nodes, i.e., the communication between both LANs is
encrypted.
△
While the concrete (DSL) syntax of ABT-Reo models is more compact and intu-
itive, a precise and detailed speciﬁcation and analysis is based on the abstract syntax,
which enables us, e.g., to explicitly specify properties of ports that are implicit only
in the concrete notion.
Example 11.5 (Abstract syntax of machine-centric model). Fig. 11.6 shows frag-
ments of the models from Fig. 11.5 on the left and the corresponding abstract syn-
tax graph on the right. Bold bullets in ABT-Reo notation correspond to nodes of
type “Point” and arrows (Reo connectors) correspond to nodes of type “Reo” in the
abstract syntax graph. They are attached respectively to external input and external
output ports according to the direction of the Reo connectors. Each point glues one
input to one output port, e.g., the left Reo connector in the ABT-Reo diagram cor-
responds to the left Reo node in the abstract syntax graph and the communication
data enters the connector via the input port at the bottom and exits the connector via
the output port at the top.
△

11.2 Inter-modelling by Triple Graph Grammars
333
E1:E/D
NW4:LAN
private
private
NW4 : ABT
LAN : String
:name
 : ExtIP
:port
 : Point
:glue
 : ExtOP
:glue
 : Reo
 : ExtIP
:port
 : Point
:glue
:glue
 : ExtOP
E1 : ABT
E/D : String
:name
:port
 : ExtOP
:port
 : Point
:glue
 : ExtIP
:glue
 : Reo
:port
 : ExtOP
:port
 : Point
:glue
:glue
 : ExtIP
:port
:port
:name
:name
Abstract syntax
ABT-Reo 
syntax
private : String
NW4
Human-centric 
syntax
Fig. 11.6 Part of M1 in Fig. 11.5 in visual notation and abstract syntax
Similarly to the deﬁnition of a meta model of a visual language according to
the OMG MOF approach [Obj14a], a type graph speciﬁes the general structure of
abstract syntax graphs. A graph of the language is typed over its type graph via a
graph morphism that maps each element to its type element in the type graph, i.e.,
each node to a node and each edge to an edge in the type graph (see Def. 2.2).
Example 11.6 (Type graph). The structure of ABT-Reo diagrams in abstract syntax
is given by the type graph TGABT−Reo in Fig. 11.7 containing the main types “ABT”
for abstract behaviour type nodes, “Reo” for Reo connectors, “Port” for ports and
“Point” for points that glue together input and output ports of both ABT nodes and
Reo connectors. Ports of elementary ABT nodes and Reo connectors are external,
i.e., they are used for external communication with other elements. ABT nodes can
also be composite, i.e., they may contain a further speciﬁed internal structure in-
volving other ABT nodes and Reo connectors. In this case their external ports are
connected to complementary internal ports, such that the communication is trans-
ferred through the borders of the composite ABT nodes.
△
11.2 Inter-modelling by Triple Graph Grammars
In the following, we use the concept of triple graphs, an extension of plain graphs
dividing elements into source, target and correspondence sections which are con-
nected by graph morphisms as presented Chap. 7. This extension improves the def-

334
11 Enterprise Modelling and Model Integration
AR      
ElABT   
CompABT
ExtP
IntP
IP
OP
ExtOP
IntOP
IntIP
ExtIP
ELABT
CompABT
ABT
Reo
Point
OP
IntP
IP
ExtP
Port
glue
junction
TGABT-Reo
AR
String
name
Legend
ExtIP
IntIP
IntOP
ExtOP
= ABT/Reo
= Elementary ABT
= Composite ABT
= External Port
= Internal Port
= Input Port
= Output Port
= External Input Port
= Internal Input Port
= Internal Output Port
= External Output Port
= Inheritance relation
= Edge type
port
Fig. 11.7 Type graph TGABT−Reo for ABT-Reo models
Filter
E/D
public
E/D
public
NW4:LAN
NW7:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
private
private
private
public
MS,B,M
MS,I,M
Fig. 11.8 Triple graph with models MS,B,M and MS,I,M
inition of model transformations, where models of a source language are translated
to models of a target language and correspondence elements can be used to guide
the creation of the sequence of transformation steps. Similarly, triple graph transfor-
mations are suitable for model integration, which takes a source and a target model
and sets up the missing correspondences between both models—if possible.
Example 11.7 (Triple graph). The triple graph in Fig. 11.8 shows an integrated
model consisting of a business service model in the source component (left) and
an IT service model in the target component (right). These models are the ABT-Reo
diagrams from Figs. 11.4 and 11.5. The corresponding elements of both models
are related by graph morphisms (indicated in grey) from the correspondence graph

11.2 Inter-modelling by Triple Graph Grammars
335
Source
Target
Correspondence
Point
A2A
P2P
ABT
Point
Abstract
Syntax
...
TGABT-Reo
TGC
TGABT-Reo
...
DSL 
Syntax
Source
Target
Correspondence
Name
Name
...
TGABT-Reo
TGC
TGABT-Reo
...
P
A
ELABT
CompABT
ELABT
CompABT
ABT
Fig. 11.9 Triple type graph TGB2IT
(middle) to source and target, respectively. In detail, the departments in the busi-
ness model correspond to the LAN nodes in the IT model as the local area networks
“NW4” and “NW7” are used in the private banking and investment banking depart-
ments. The ﬁlter in the business model corresponds to the composed structure of
two encryption nodes in the IT model. The node type “E/D” denotes encryption and
decryption capabilities.
△
Model transformation as well as model integration do not require deletion dur-
ing the transformation. Technically, both techniques compute graph transformation
sequences, yielding a consistent triple graph (see Chap. 7 for the formal details).
In the case of model integration, the result is exactly the computed triple graph of
the transformation sequence and in the case of model transformations the result is
obtained by restricting the resulting triple graph to its target component. For this rea-
son, it is suﬃcient to consider triple rules that are nondeleting. This implies that the
ﬁrst step in the DPO graph transformation approach (see Chap. 2) can be omitted,
because the creation of elements is performed in the second step.
Example 11.8 (Triple graph grammar). The triple graph grammar TGGB2IT
=
(TGB2IT, S B2IT, TRB2IT) speciﬁes how business service models and IT service mod-
els given as ABT-Reo diagrams are related and its type graph is shown in Fig. 11.9
in abstract syntax and DSL syntax (syntax of the domain-speciﬁc languages). The
language of ABT-Reo diagrams is used for both, the source and the target language,
and the type graph shows a correspondence between the relevant types, which are
“ABT” for abstract behaviour type elements and “Point” for the gluing points be-
tween input and output ports of ABT elements and Reo connectors. The start graph
S B2IT is empty and Figs. 11.10 and 11.11 show some of the triple rules of TRB2IT.

336
11 Enterprise Modelling and Model Integration
L=
R=
Complete
notation
Compact
notation
name = "LAN"
 : ELABT
name = "Department"
 : ELABT
name = "LAN"
 : ELABT
name = "Department"
 : ELABT
++
++
++
++
++
:LAN
:Department
:A
++
++
++
++
++
Compact
notation
Abstract Syntax
DSL 
Syntax
 : A2A
 : A2A
Fig. 11.10 Triple rule “DepartmentToLAN”
Each rule speciﬁes a pattern that describes how particular fragments of business and
IT models shall be related.
The ﬁrst rule “DepartmentToLAN” synchronously creates two ABT elements
and a correspondence node that relates them. This reﬂects the general correspon-
dence between departments in the business view and the installed local area net-
works in the IT view. The rule is presented in complete and in compact notation as
well as using the DSL syntax. The complete notion shows that a triple rule consists
of a triple graph for the left-hand side (the upper one in the ﬁgure), a triple graph
for the right-hand side (the lower one in the ﬁgure) and the relating morphism in
between. Recall that triple rules are nondeleting and the intermediate graph K as it
appears for plain graph transformation rules in Chap. 2 is not needed.
The compact notation for triple rules combines the left- and the right-hand sides
of a rule, i.e., the rule is shown by a single triple graph with special annotations.
All elements that are created by the rule, i.e., which appear in the right-hand side
only, are marked by double plus signs. The DSL syntax of the rule shows the ABT
diagrams in visual notation, where the attribute “name” is used as the label of the
visual elements.
The rules in Fig. 11.11 are presented in DSL syntax using the compact notation.
Similarly to the ﬁrst rule, rule “PublicToPublic” has also an empty left-hand side. It
synchronously creates two Reo connectors on both sides and they are related by the
points at their input and output ports. The rule “FilterToED” is slightly more com-
plex and shows how ﬁlters in business models correspond to encrypted connections
in the related IT model. This reﬂects the abstract business requirement of hiding
conﬁdential information and its possible implementation by encryption in the IT
domain. Note that the left-hand side of this rule corresponds to the right-hand side
of the rule “PublicToPublic”.
Private connections leading to related and secured public connections are re-
lated by the rule “PrivateInToPrivateIn”. The last rule, “FilteredOutToPrivateOut”
in Fig. 11.11, speciﬁes how outgoing communication from a secured connection is
handled. The private outgoing connection in an IT model corresponds to the gluing
of the ﬁltered public connection to the target ABT element, which is deﬁned by the

11.2 Inter-modelling by Triple Graph Grammars
337
PublicToPublic
:P
:P
++
++
++
++
++
++
++
++
++
:public++
++
:public
++
FilterToED
:Filter
:E/D
:E/D
:A
:A
++
++
++
++
++
++
++
++
S1:public
++
:P
:P
T1:public
++
S2:Filter
T2:E/D
T3:public
T1:LAN
:private
S1:Department
:private
S3:public
:A
:A
++
++
:P
:P
PrivateInToPrivateIn
T3:E/D
:A
S1:Filter
T1:E/D
T2:public
T3:E/D
T4:LAN
private
S2:Department
S3:public
:A
:A
:A
++
++
FilteredOutToPrivateOut
:P
:P
name = "Department"
S2 : ELABT
 : ExtIP
 : Point
:glue
:port
++
++
++
attach
Fig. 11.11 Further triple rules of TGGB2IT
box with the label “attach”. This box speciﬁes the explicit creation of elements in
the source component based on the underlying abstract syntax, where an input port
for the ABT node “S2” and the linking edges to the existing nodes are created.
The presented rules suﬃce for the examples in this chapter. However, the TGG
can be extended by further rules to cover the complete language of ABT-Reo mod-
els [BHEE10]. For example, symmetric communication via public channels as de-
picted in Fig. 11.4 would require an additional triple rule to extend public connec-
tions by corresponding ones in opposite direction.
△
Considering the model framework in Fig. 11.1, one may experience the follow-
ing scenarios during the development of the models. First of all, two models that
should be integrated may be unrelated; thus performing model integration may de-

338
11 Enterprise Modelling and Model Integration
tect conﬂicts between them. Furthermore, some model instances within the model
framework may be missing at the beginning, e.g., business process models and IT
service models usually exist while business service models do not. The interesting
challenge is to automatically retrieve parts of the missing models from the existing
ones in order to improve interoperability between system components and enter-
prise components in general. For this purpose, model transformation can be applied
on business process models to derive IT process models, and on IT service models to
derive basic business service models. The results can be checked against integration
conﬂicts with respect to the other existing models.
The following sections show that triple graph grammars are a suitable basis for
the described needs. We exemplarily show how operational rules for model trans-
formation and integration are derived from the original triple graph grammar. The
underlying formal construction enables an automatic derivation of the operational
rules, as described in [Sch94, KW07, EEE+07]. The application of the operational
rules is controlled, such that correctness and completeness with respect to the pat-
terns are ensured for the resulting models [EEHP09, HEGO14]. The techniques are
illustrated based on the given scenario of IT and business service models given by
ABT-Reo diagrams.
11.3 Model Transformation Between Business and IT Service
Models
As described in Sect. 11.2, triple rules can be used to specify how two models can
be created simultaneously. Thus, triple rules allow the modeller to deﬁne patterns
of correspondences between model fragments. Based on these triple rules the op-
erational forward rules for model transformations from models of the source lan-
guage to models of the target language are derived automatically as described in
Chap. 7. Since triple rules have a symmetric character, the backward rules for back-
ward model transformations from models of the target to models of the source lan-
guage are also derived automatically. In this section we present both directions and
show the application in our scenario for the forward case.
The operational rules for forward model transformations are source and forward
rules. Both kinds are derived from the triple rules that specify pattern by pattern
how integrated models are created, i.e., how source and target models are developed
synchronously. Given a triple rule, its source rule is given by removing all elements
in the correspondence and target component. Its forward rule is derived by replacing
the source component on the left-hand side by the source component on the right-
hand side. The forward rule requires a complete fragment in the source component
of an integrated model and completes the missing parts for the correspondence and
target components. Intuitively, the source rules specify how a source model can be
constructed and the forward rules specify how source models can be completed to
integrated models. Given a source model, the forward rules are used for the actual

11.3 Model Transformation Between Business and IT Service Models
339
Triple Rule
FilterToED
Forward Rule 
FilterToEDF
:Filter
:E/D
:E/D
:A
:A
++
++
++
++
++
++
++
++
S1:public
++
:P
:P
T1:public
++
S2:Filter
:E/D
:E/D
:A
:A
++
++
++
++
++
++
++
S1:public
:P
:P
T1:public
++
:Filter
++
S1:public
++
Source Rule
FilterToEDS
Fig. 11.12 Derived source and forward rules
transformation steps leading to an integrated model and the source rules are used
for controlling the application of the forward rules [EEHP09, HEGO14].
Example 11.9 (Operational rules). Fig. 11.12 shows the triple rule “FilterToED”,
its derived source rule “FilterToEDS ” and its forward rule “FilterToEDF”. Note that
the source component is now identical in the left- and right-hand side of the forward
rule by construction. The forward rule is used to transform a ﬁlter into two ABT
nodes of the type “E/D”, which implement the encryption and decryption of com-
munication data. As described in Sect. 11.1, the underlying idea is that conﬁdential
communication in a business universe is ﬁltered out while in the IT universe the data
is encrypted for public channels. Since the left-hand side of the forward rule already
contains all source elements of the right-hand side of the triple rule, the items “S1”
and “S2” appear on both the left- and the right-hand side.
△
A forward model transformation is performed by taking a given source model
and ﬁrst extending it to a triple graph G0 with an empty correspondence and an
empty target component. The transformation starts with this triple graph. Each step
of the transformation starts with the computation of the possible matches from the
left-hand sides of the forward rules to the current triple graph. A valid match ac-
cording to the on-the-ﬂy construction in [EEHP09] is chosen and the forward step
is performed. The matching can be performed equivalently using special translation
markers as presented in [HEGO14]. The resulting target model is obtained by re-
stricting the ﬁnal triple graph to its target component. This construction leads to a
source consistent forward sequence that deﬁnes the model transformation sequence
in the sense of Part III.

340
11 Enterprise Modelling and Model Integration
PublicToPublicF
DepartmentToLANF
DepartmentToLANF
Business Model MS,B,M
:Filter
public
:LAN
:LAN
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:P
:P
:Filter
:LAN
:LAN
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:Filter
:LAN
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:Filter
Private_Banking:Department
Investment_Banking:Department
private
public
Fig. 11.13 Model transformation sequence, part 1

11.3 Model Transformation Between Business and IT Service Models
341
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:A
:A
Business Model
MS,B,M
IT Model
MS,I,M
:P
:P
Correspondence
FilterOutToPrivateOutF
PrivateInToPrivateInF
FilterToEDF
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:A
:A
:P
:P
:Filter
:E/D
public
:E/D
:LAN
:LAN
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:A
:A
:P
:P
Fig. 11.14 Model transformation sequence, part 2

342
11 Enterprise Modelling and Model Integration
Example 11.10 (Model transformation). Using the presented triple rules and their
derived forward rules, the business service model MS,B,M is transformed to the IT
service model MS,I,M . The model transformation sequence consists of the following
six forward transformation steps and is shown in Figs. 11.13 and 11.14:
G0 =
DepartmentToLANF
=============⇒G1 =
DepartmentToLANF
=============⇒G2 =
PublicToPublicF
===========⇒G3 =
FilterToEDF
========⇒G4
=
PrivateInToPrivateInF
===============⇒G5 =
FilteredOutToPrivateOutF
=================⇒G6, where G0 = (MS,B,M ←∅→∅).
Each step completes a fragment of the source model by the missing elements in the
correspondence and target component. The matches of the forward rules do not over-
lap on their eﬀective elements. Those eﬀective elements are the ones that are created
by the corresponding triple rule in its source component (RS \ LS ), i.e., elements
that are visualised by plus signs in the source components of the triple rule. Further-
more, the full transformation sequence has to ensure that each element in MS,B,M
is matched by exactly one eﬀective element of a forward rule. Both properties are
ensured by the formal condition called “source consistency”, which controls the
forward transformation (see Chap. 7). Therefore, each source element is translated
exactly once and the resulting triple graph is a well-formed integrated model. The
resulting triple graph G6 is shown at the bottom of Fig. 11.14 and coincides almost
with the triple graph in Fig. 11.8. Only the labels “NW4” and “NW7” for the nodes
of type “LAN” are left blank. Such labels (explicit object identiﬁers) cannot be de-
termined by the information of any source model, and therefore the triple rules cre-
ate blank labels. But note that real attributes are processed and computed during the
model transformation, e.g., the connector type “public” is speciﬁed as an attribute
of a Reo connector in the abstract syntax. The result of of the forward transforma-
tion is given by the target component MS,I,M of G6 = (MS,B,M ←G6,C →MS,I,M).
Fig. 11.15 shows the model transformation in one step from its source model as
input to its target model as output. Note that some transformation steps in this se-
quence are sequentially independent, e.g., the second and the third step are indepen-
dent. They can be switched leading to an equivalent sequence.
△
As presented in Theorem 8.4 in Chap. 8, model transformations based on TGGs
ensure correctness in the following sense. Each model transformation sequence from
a source model GS to a target model GT guarantees that there is a corresponding
consistent integrated model G ∈L(TGG), i. e., G = (GS ←GC →GT) ∈L(TGG).
This ensures that the descriptive triple patterns as speciﬁed by the triple rules of the
TGG are adhered to by the model transformation. Moreover, model transformations
based on TGGs are complete in the sense that they always yield a target model GT
for a given source model GS of the source language L(TGG)S , which is the projec-
tion of the language of consistent integrated models to the source component. The
result in Theorem 8.4 goes beyond the available results for other graph transfor-
mation approaches, which only ensure that the resulting target models are correctly
typed according to the target meta model. In addition to the correctness and com-
pleteness result, the triple graph transformation approach beneﬁts from its intuitive
triple patterns of corresponding fragments, which substantially increases usability
and maintainability.

11.4 Model Integration Between Business and IT Service Models
343
:Filter
Private_Banking:Department
Investment_Banking:Department
private
public
Business Model MS,B,M
:E/D
public
:E/D
:LAN
:LAN
private
private
IT Model MS,I,M
Forward MT
Fig. 11.15 Model transformation of service models
11.4 Model Integration Between Business and IT Service Models
The purposes of model integration are interoperability in general and the analysis of
consistency within the overall enterprise model in particular. Conceptually, the chal-
lenge of model integration is diﬀerent from model transformation. However, both
techniques can be based on triple graph transformation, and thus they are strongly
related in our case. The used TGG is the same—the only diﬀerences occur in the
derivation of operational rules and the deﬁnition of the control conditions for the
execution. This section presents the constructions and the application to the case
study.
Analogously to forward rules, integration rules are derived from the set of triple
rules, which describe the patterns of the relations between two models. An integra-
tion rule is obtained from a triple rule by replacing the source and the target com-
ponents of the left-hand side by the source and target components of the right-hand
side, such that only the correspondence part remains diﬀerent. This way, a match of
the rule requires that all fragments of the triple pattern in the source and target com-
ponent be present before applying the rule, such that only the correspondences are
added to complete the triple pattern. Similarly to source rules for the forward model
transformation, source–target rules are used to control the execution of model inte-
grations. They are obtained be removing the correspondence part from the original
triple rule.
Example 11.11 (Source–target and integration rules). Fig. 11.16 shows the triple
rule “FilterToED”, its derived source–target rule “FilterToEDS T” and its integration
rule “FilterToEDI”, according to Def. 7.11. The triple rule synchronously extends a
public connector by a ﬁlter in the business model and its corresponding two de/en-
cryption elements in the IT model. Thus, an application of the integration rule com-
pletes the correspondence structure of existing and already related public connectors
that have adjacent ﬁlter and de/encryption elements.
△

344
11 Enterprise Modelling and Model Integration
Triple Rule
FilterToED
Integration Rule
FilterToEDI
:Filter
:E/D
:E/D
:A
:A
++
++
++
++
++
++
++
++
S1:public
++
:P
:P
T1:public
++
S2:Filter
T2:E/D
T3:E/D
:A
:A
++
++
++
++
++
S1:public
:P
:P
T1:public
++
Source-target rule
FilterToEDST
:Filter
:E/D
:E/D
++
++
++
S1:public
++
T1:public
Fig. 11.16 Derived integration rule FilterToEDI
Model integration based on triple graph transformation is deﬁned by integration
sequences, in which the derived model integration rules are applied. Given a source
and a target model, their integration is performed by completing the correspondence
structure that relates both models. The consistency of a model integration is ensured
by a formal condition, called source–target (S –T-)consistency (see Def. 7.37). This
condition ensures that the given source and target models are completely parsed
using the inverted triple rules restricted to the source and target component, respec-
tively. Thus, each fragment of the models is processed and integrated exactly once.
Example 11.12 (Model integration). Figs. 11.17 to 11.19 show the integration of
the models MS,B,M and MS,I,M, i.e., the creation of the correspondence relation be-
tween them via a correspondence graph. The model integration is based on an S –
T-consistent integration sequence consisting of the following six steps using the
derived model integration rules:
G0 =
DepartmentToLANI
=============⇒G1 =
DepartmentToLANI
=============⇒G2 =
PublicToPublicI
==========⇒G3 =
FilterToEDI
========⇒G4
=
PrivateInToPrivateInI
==============⇒G5 =
FilteredOutToPrivateOutI
=================⇒G6, with G0 = (MS,B,M ←∅→MS,I,M).
In the ﬁrst four steps, some fragments of the source and target components
are completed by the missing elements in the correspondence component. But
note that in the two last steps, nothing changes on the correspondence compo-
nent. The reason is the following. The triple rules “PrivateInToPrivateIn” and
“FilteredOutToPrivateOut” extend integrated fragments in the source and target
model by connecting Reo elements and they do not create any correspondence node.
Therefore, the derived integration rules do not create correspondences either. But
these integration rules are necessary to ensure correct integrations in the way that
the positions of the corresponding private Reo connectors are checked.

11.4 Model Integration Between Business and IT Service Models
345
PublicToPublicI
DepartmentToLANI
DepartmentToLANI
Business Model MS,B,M
IT Model MS,I,M
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:P
:P
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
Fig. 11.17 Model integration sequence, part 1

346
11 Enterprise Modelling and Model Integration
Business Model
MS,B,M
IT Model
MS,I,M
Correspondence
FilterOutToPrivateOutI
PrivateInToPrivateInI
FilterToEDI
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:A
:A
:P
:P
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:A
:A
:P
:P
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:A
:A
:P
:P
Fig. 11.18 Model integration sequence, part 2

11.4 Model Integration Between Business and IT Service Models
347
Integration
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
:A
:A
:A
:A
:P
:P
Business Model
MS,B,M
IT Model
MS,I,M
Correspondence
:Filter
:E/D
public
:E/D
:LAN
:LAN
private
private
Private_Banking:Department
Investment_Banking:Department
private
public
Business Model
MS,B,M
IT Model
MS,I,M
Correspondence
Fig. 11.19 Model integration for service models
The matches of the integration rules do not overlap on their eﬀective elements,
which are those that are created by the triple rule in the source and target components
(RS ∪RT \LS ∪LT). Furthermore, each element in MS,B,M and MS,I,M is matched by an
eﬀective element of an integration rule. Both properties are ensured formally by the
S –T consistency condition (see Def. 7.37), which controls the integration sequence.
This way, each source element and each target element is integrated exactly once
and the resulting triple graph is a well-formed integrated model. The resulting triple
graph G6 is shown at the bottom of Fig. 11.18 and coincides with the triple graph in
Fig. 11.8.
The result of the model integration is the completely integrated triple graph of
the sequence and it is shown in the bottom part of Fig. 11.19, where the model
integration is presented in a single step from the pair of the source and target model
as input to the integrated model as output.
△
Integration rules are used to establish or update the correspondences between
two models. The model framework in Fig. 11.1 shows many coordinates, where

348
11 Enterprise Modelling and Model Integration
models should be integrated. Two models are consistent with each other if they can
be completely integrated; otherwise they show conﬂicts. Consistency between the
models is ensured by checking S –T consistency (see Def. 7.37), which means that
the integration has to conform to a parsing of the existing source and target model.
11.5 Summary of Achievements and Related Work
The described and illustrated techniques for model transformation and integration
improve the interoperability between the business and the IT service models given
by ABT-Reo diagrams. The techniques are general, such that they should be applica-
ble to other visual languages and coordinates in the model framework for enterprise
modelling in Fig. 11.1 as well. The beneﬁts of the techniques can be described as
follows. Model transformation enables the construction of model stubs that can be
reﬁned by the experts for the speciﬁc domain. Model integration establishes the
correspondences between the existing models, e.g., for data interchange, and, fur-
thermore, conﬂicts between models can be detected and highlighted. According to
Theorems 8.4 and 8.9, model transformation and model integration based on triple
graph grammars are syntactically correct and complete.
Both techniques can be used as the basis for more complex scenarios, includ-
ing those where conﬂicts exist between existing models in diﬀerent dimensions of
the model framework. For instance, the IT model may contain some communica-
tion paths that are not modelled in the business model. Those fragments have to
be synchronised and can be detected as remainders when computing the integration
sequences with maximal coverage. The synchronisation can be supported by the ap-
plication of the derived forward and backward triple rules in the way that additional
fragments in one model are translated to new ones in the other model (see Chap. 9
for the formal details on model synchronisation based on TGGs). Conﬂicts are de-
tected and presented to the modeller, who is responsible for solving them. Moreover,
we further studied in [BHEE10, EHSB11, EHSB13] how to propagate constraints
between diﬀerent domains and to analyse and ensure their validity. Such constraints
can specify functional and nonfunctional properties that can be relevant for diﬀerent
domains in the model framework.
There is a wide range of literature spanning various aspects of enterprise mod-
elling. We like to discuss some of the well-known available approaches on a
general basis. The concept of multi-perspective enterprise modelling (MEMO) is
a comprehensive framework presented in [Fra02]. The MEMO method provides
semiformal domain-speciﬁc modelling languages that are focussed on the con-
crete modelling domains of enterprises. The ISO standard 19439:2006 [ISO06]
speciﬁes a general framework for enterprise modelling and enterprise integration
based on the GERAM framework (generalised enterprise reference architecture and
methodology, [BN96]), where several aspects and dimensions are distinguished in a
partly similar way to that in the MEMO method.

11.5 Summary of Achievements and Related Work
349
Compared with enterprise modelling based on general modelling languages like
UML, as presented in [Mar00], domain-speciﬁc modelling techniques provide spe-
ciﬁc modelling concepts and notations which are appropriate for the modelling tasks
instead of providing generic ones from which the speciﬁc ones have to be manually
constructed and derived. For this reason, the uniﬁed enterprise modelling language
[Ver02, ABV07] does not aim to provide one universal enterprise modelling lan-
guage, but rather provides techniques for integrating models of existing domain-
speciﬁc languages based on merging their ontologies. We have also followed this
line in this chapter, which illustrates model transformation and integration tech-
niques on one particular DSL: ABT-Reo (abstract behaviour types (ABT) and Reo
connectors). The new contribution is the application of the formal techniques based
on graph transformation to ensure several important properties, e.g., syntactical cor-
rectness and completeness.

Chapter 12
Tool Support
The more graph transformations are applied in various application domains, the
more tools supporting modelling, simulation and analysis of graph transformation
system become crucial for the promotion of graph transformation in industry. In this
chapter, we present four related modelling environments that have been developed
at Technische Universität Berlin and that support the speciﬁcation, simulation and
analysis of behavioural models and model transformations based on algebraic graph
transformation.
We start in Sect. 12.1 with the tool environment AGG. For over 20 years, the
strength of AGG has been its consequent implementation of analysis techniques for
algebraic graph transformation systems [LB93, TER99, Tae04, EEPT06]. Recently,
AGG has been extended to better support new concepts for rule application con-
trol (like nested application conditions) and rule synthesis (like amalgamation of
rules), as presented in Part II of this volume. This has made AGG better suited for
deﬁning and executing complex model transformation systems [RET12]. Sect. 12.2
presents ActiGra, a visual modelling language combining activity models to deﬁne
the control ﬂow and graph transformation rules specifying the activity semantics.
Based on AGG’s conﬂict and dependency analysis techniques, favourable and criti-
cal signs concerning model consistency are visualised directly in the activity model.
In Sect. 12.3, we introduce EMF Henshin, an Eclipse plugin supporting modelling
and execution of EMF model transformations, i.e., transformations of models con-
forming to a meta model given in the EMF Ecore format. In EMF Henshin, we have
lifted implicit and explicit control structures from graph transformation to EMF
model transformation. The visual EMF Henshin environment provides intuitive vi-
sual editors for rule application conditions and explicit control structures on rules.
Recently, EMF Henshin has been extended to support model transformations based
on triple graph grammars (TGGs). In Sect. 12.4, we present the visual TGG mod-
elling and analysis environment HenshinTGG, building on EMF Henshin and AGG.
Related tools to our four modelling environments are discussed in Sect. 12.5.
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3_12
351

352
12 Tool Support
12.1 The Attributed Graph Grammar System AGG 2.0
AGG [AGG14, Tae04] (the Attributed Graph Grammar system) is a well-established
integrated development environment for algebraic graph transformation systems,
developed and extended over the past 20 years at Technische Universität Berlin.
The environment supports the speciﬁcation of algebraic graph transformation sys-
tems based on typed attributed graphs with node type inheritance, graph rules with
application conditions, and graph constraints. It oﬀers several analysis techniques
for graph transformation systems, including graph parsing, consistency checking of
graphs as well as conﬂict and dependency detection in transformations by critical
pair analysis of graph rules, an important instrument to support the conﬂuence check
of graph transformation systems.
Model transformations have recently been identiﬁed as a key subject in model-
driven development (MDD). Graph transformations oﬀer useful concepts for MDD,
while the software engineering community can generate interesting challenges for
the graph transformation community. In the past six years, those new challenges
have led to the augmentation of AGG by new tool features. In this section, we de-
scribe some of those challenges, the formal approaches developed to solve them,
and the impact they have had on recent developments of new features of AGG, lead-
ing to AGG 2.0 [RET12]. In particular, the modelling scope and validation support
in AGG has been extended by features for rule application control and rule synthe-
sis. AGG 2.0 now supports the speciﬁcation of complex control structures for rule
application comprising the deﬁnition of control and object ﬂow for rule sequences
and nested application conditions.
Structure of this section: The basic features and the tool environment of AGG
in 2006 have been introduced in [EEPT06]. We summarise these features in
Sect. 12.1.1 along a running example on semantics deﬁnition for visual modelling
languages (VLs). In Sect. 12.1.2, we introduce the new features for rule applica-
tion control. Furthermore, new possibilities for rule synthesis by constructing rules
from existing ones (e.g., inverse, minimal, amalgamated, and concurrent rules) have
been realised. We introduce the new rule synthesis support in Sect. 12.1.3. Last but
not least, AGG 2.0 provides more ﬂexible usability of the critical pair analysis. We
review the basic concepts of critical pair analysis in AGG in Sect. 12.1.4 and demon-
strate the new features when analyzing graph transformation systems for conﬂicts
and dependencies.
12.1.1 Editing and Simulating Graph Transformation Systems
In AGG, graphs consist of two disjoint sets of nodes and edges. In correspondence
to the theory (see Def. 2.1), we may have multiple edges between a single pair of
nodes. Each graph object (node or edge) is associated with exactly one type from
a given type set. The type set consists of the set of node types and the set of edge
types. As in the theory, node types and edge types may be represented as nodes

12.1 The Attributed Graph Grammar System AGG 2.0
353
Fig. 12.1 Attributed type graph with node type inheritance in AGG 2.0
and edges of a type graph (see Def. 2.2). The type graph may contain multiplicity
constraints on edge types that constrain how many objects may be connected by
instances of a certain edge type. A multiplicity constraint on a node type restricts
the number of instances of this node type.
Another important principle for handling complex graph structures stems from
object-oriented programming, where class inheritance extends typing by allowing
the deﬁnition of more abstract types, and more concrete types, inheriting from
the abstract ones. In graph transformation, we speak of node type inheritance
[BEdLT04, EEPT05, EEPT06]. In AGG 2.0, a type graph with node type inheri-
tance may be deﬁned by inserting generalisation edges between concrete and ab-
stract node types (parent types). Inheritance allows a much denser form of graph
transformation systems, since similar rules can be abstracted into one rule: a node
in a rule’s left-hand side that is typed over an abstract node type may be matched to
any instance graph node that is in the clan of the rule node, i.e., the instance node’s
type node in the type graph is connected by a path of generalisation edges to the
abstract node’s type node.
In AGG, attributes may be deﬁned for graph objects. An attribute is declared for
a graph object type in the type graph by specifying a name and a type (a Java type)
for it. As in the theory, all graph objects of the same type share their attribute decla-
rations (see Def. 2.5). The values of attributes may be chosen individually for graph
objects in instance graphs. AGG requires that each attribute occurring in a graph ob-
ject in an instance graph be bound to exactly one value. In rules, attributes may be
bound to variables (in a rule’s LHS) or can be equipped with arbitrary computations
on Java objects described by Java expressions (in a rule’s RHS).
Figure 12.1 depicts an attributed type graph with node type inheritance, mod-
elling the language of elementary Petri nets. An elementary Petri net consists of
PN-Nodes which can be either Transitions or Places. PN-Nodes are connected via pre-
arcs and post-arcs. We distinguish between two special kinds of Places, namely In-
Places and Out-Places, where In-Places are meant to be connected to Transitions via
pre-arcs only, and Out-Places should be connected by post-arcs only. The clan of the
PN-Node consists of the node types Transition, Place, In-Place, OutPlace and PN-Node
itself. All Places can carry Tokens, which is modelled by the on-edge from type Token
to type Place, where the multiplicity “1” at its end means that each Token instance

354
12 Tool Support
must be connected via on-edge to exactly one Place instance. On the other hand, mul-
tiplicity “0..1” at the beginning of the on-edge means that a Place instance may carry
at most one Token. The multiplicity “*” at pre- and post-arcs means that in principle
a PN-Node may be connected to any number of PN-Nodes. Transitions are attributed
by a Boolean attribute called isActivated. In instance graphs (concrete Petri nets), the
value of this attribute is meant to be true if the transition is enabled to ﬁre; else it
will be set to false.
Basically, a graph transformation rule according to Def. 5.12 is represented in
AGG by a left-hand side L, a right-hand side R and mappings from L to R for all
graph objects that are preserved by the rule.1 The mappings are visualised by equal
numbers in the rule sides L and R. Hence, a rule in AGG corresponds to the span
p = (L
l←K
r→R) deﬁning a DPO rule, where the gluing K consists of those graph
objects that are preserved (i.e., marked by numbers in AGG). Alternatively, AGG
oﬀers an option for the current graph grammar to be interpreted according to the
SPO approach (by disabling the dangling and identiﬁcation condition). In this case,
dangling edges will be deleted, and identiﬁcation conﬂicts are handled by automatic
deletion as well. Attributes can be deﬁned also for rules, where the left-hand side
may contain constants or variables as attribute values, but no Java expressions. The
right-hand side may contain Java expressions in addition, but no unbound variables
(that do not occur already in the left-hand side). The scope of a variable is its rule.
A rule is applied to an instance graph G by ﬁnding a match (graph morphism)
from its left-hand side L into G. If no match can be found, or if the gluing condition
according to the DPO approach is not satisﬁed (see Def. 5.13), the rule is not appli-
cable. Otherwise, graph objects in the image of the match that are not mapped to R
by the rule are deleted, and graph objects in R that have not been mapped from L
by the rule are created. A graph G is transformed in-place to the new instance graph
that results from the rule application. In the case of multiple matches from L to G,
AGG may choose a match randomly, or the user may choose a match manually.
The AGG environment consists of a graphical user interface comprising sev-
eral visual editors, an interpreter, and a set of validation tools. The basic interpreter
supports simulation of graph transformation systems by stepwise transformation of
graphs as well as by applying rules in random order at nondeterministic matches as
long as possible.
Figure 12.2 displays the basic graphical user interface of AGG. The tree view 1
shows the elements of the current graph grammar (a type graph, one or more in-
stance graphs, an arbitrary number of rules, and, optionally, graph constraints deﬁn-
ing required or forbidden graph patterns in instance graphs; see Sect. 12.1.2). The
rule editor 2 shows a rule for ﬁring an elementary Petri net transition (according
to the type graph of elementary Petri nets in Fig. 12.1). Below, the instance graph
editor 3 contains an elementary Petri net. The current rule is applicable to this in-
stance graph, and the match is indicated by corresponding mapping numbers in the
rule’s left-hand side and the graph. Some Place nodes from the rule’s left-hand side
1 We consider rules with application conditions in Sect. 12.1.2.

12.1 The Attributed Graph Grammar System AGG 2.0
355
Fig. 12.2 AGG user interface with tree view 1 , rule editor 2 and instance graph editor 3
are mapped to nodes of type In-Place, which is type-compatible due to the node type
inheritance relation deﬁned in the type graph.
Note that this rule works only for ﬁring a transition with exactly three input and
two output places. We would run into problems with the Petri net semantics if we
tried to apply this rule to a transition with four marked input places: the rule would
remove only three of the input tokens. We will see in the next section how rule
application conditions can help to solve such problems.
12.1.2 Rule Application Control
To further enhance the expressiveness of graph transformations, rules may contain
application conditions (see Defs. 5.1 and 5.12, which are also called nested ap-
plication conditions in [HP09] and general application conditions in AGG 2.0).
Application conditions are as powerful as ﬁrst-order logic on graphs and provide
a mechanism to control the rule application (see [GBEE11] for an extensive case
study). In addition to application conditions, AGG supports the deﬁnition of at-
tribute conditions, which can be deﬁned in a text editor. A rule may have a set of
attribute conditions (Boolean Java expressions over a rule’s set of variables). All
attribute conditions have to be evaluated to true for the rule to be applicable.
AGG also supports graph constraints according to Def. 5.10, i.e., graph condi-
tions that are required to hold globally (for every graph in a transformation) and

356
12 Tool Support
Fig. 12.3 Nested application conditions in AGG
are not coupled with rules. The concept of graph constraints allows for consistency
checking. AGG can be conﬁgured in a way to stop the running transformation when
a graph constraint is violated by the current instance graph.
Furthermore, control structures deﬁned on rules, such as layers or sequences,
restrict the choice of rules to be applied. Often, rule sequences are supposed to be
applied to the same subset of graph objects. Here, AGG supports the deﬁnition of
object ﬂow between rules in a sequence, restricting the matches of subsequent rules.
Application Conditions
Let us recall that a rule with application condition in AGG corresponds to the span
p = (L←K→R, ac) (see Def. 5.12). Application conditions in AGG basically consist
of positive application conditions (PACs), negative application conditions (NACs),
and general application conditions (GACs), which may be deﬁned separately in any
number for each rule. PACs and NACs require or forbid the presence of certain
structures in the graph for the rule to be applied. Note that PACs and NACs are spe-
cial GACs, deﬁned by a morphism from L to the PAC (or NAC) graph. A rule with
a PAC is applicable if there exists a morphism from the PAC graph to the instance
graph that extends the match injectively. Vice versa, a rule with a NAC is applica-
ble only if such a morphism from the NAC graph to the instance graph does not
exist. According to the theory, GACs are arbitrary conditions over L (see Def. 5.1).
The conjunction of all of its PACs, NACs and GACs comprises a rule’s application
condition ac.
An example is displayed in Fig. 12.3, where the activation of an elementary Petri
net transition is checked: The rule ActivationCheck sets the transition attribute isActi-
vated to true if two conditions, called PreCond and PostCond, are satisﬁed: PostCond
is the NAC shown in Fig. 12.3 (b) which forbids the existence of a marked place in
the transition’s post-domain, and PreCond is a nested application condition shown
in Fig. 12.3 (c) which requires that on each place in the transition’s pre-domain,
there must be one token. Note that this condition cannot be expressed by using sim-
ple NACs or PACs. Figure 12.3 (a) depicts the context menu entries for generating
general application conditions (GACs) in AGG 2.0.

12.1 The Attributed Graph Grammar System AGG 2.0
357
Fig. 12.4 Rules RemovePre and AddPost for Petri net ﬁring
Fig. 12.5 Object ﬂow deﬁnition for rule sequences in AGG
Object Flow for Rule Sequences
Object ﬂow between rules has been deﬁned in [JLM+09] as partial rule dependen-
cies relating nodes of the RHS of one rule to (type-compatible) nodes of the LHS
of a (not necessarily direct) subsequent rule in a given rule sequence. Object ﬂow
thus enhances the expressiveness of graph transformation systems and reduces the
match ﬁnding eﬀort.
In AGG 2.0, object ﬂow can be deﬁned between subsequent rules in a rule se-
quence, and the rule sequence can be applied to a given graph respecting the object
ﬂow. An example is the deﬁnition of a Petri net transition ﬁring step by the rule
sequence (ActivationCheck, RemovePre*, AddPost*, DeActivate) with object ﬂow. The se-
quence deﬁnes that the rule ActivationCheck (see Fig. 12.3) is applied once, followed
by the rules RemovePre (removing a token from a pre-domain place), AddPost (adding
a token to a post-domain place), which are shown in Fig. 12.4, and DeActivate (setting
the transition attribute isActivated back to false).
In the sequence, the rules RemovePre and AddPost are applied as long as possible
(denoted by “*”), and the rule DeActivate is applied once. To restrict the application
of the rule sequence to exactly one transition, we need to express that the transition
in the matches of all rules is the same. This is done by deﬁning the object ﬂow, e.g.,
by mapping the transition from the RHS of rule ActivationCheck to the LHSs of rules
RemovePre and AddPost, as depicted in Fig. 12.5.
An example of a ﬁring step by applying the rule sequence with object ﬂow is
shown in Fig. 12.6, where the left transition in the net was selected, found activated
and ﬁred.
12.1.3 Rule Synthesis
AGG 2.0 supports various ways to automatic construction of new rules from existing
ones (rule synthesis). Obviously, the deﬁnition of a rule sequence with object ﬂow

358
12 Tool Support
Fig. 12.6 Firing step resulting from applying a rule sequence with object ﬂow
is neither simple nor very intuitive for modelling Petri net transition ﬁring steps for
transitions with an arbitrary number of pre- and post-domain places. A way closer to
the inherent Petri net semantics (a transition removes the tokens from all of its pre-
domain places and adds tokens to all of its post-domain places in one atomic step)
would be to construct a single rule modelling the ﬁring behaviour of a transition.
Construction of Concurrent Rules
A concurrent rule summarises a given rule sequence in one equivalent rule (see
Def. 5.27). Recall, an E-concurrent rule p ∗E q = (L ←K →R) is constructed
from two rules, p = (Lp ←Kp →Rp) and q = (Lq ←Kq →Rq), that may be
sequentially dependent via a graph E, where E is an overlapping of the right-hand
side of the ﬁrst rule and the left-hand side of the second rule (see Def. 2.27).
In AGG 2.0, we can construct a concurrent rule from a given rule sequence with
the following options concerning the overlappings of one rule’s RHS with the suc-
ceeding rule’s LHS:
1. compute maximal overlappings according to rule dependencies;
2. compute all possible overlappings (this usually yields a large number of concur-
rent rules);
3. compute overlappings based on the previously deﬁned object ﬂow between the
given rules;
4. compute the parallel rule (no overlappings), where rule graphs are disjointly uni-
ﬁed, with NACs constructed according to [Lam10].
As an example, Fig. 12.7 shows the concurrent rule constructed from the rule
sequence (ActivationCheck, RemovePre(3), AddPost(2), DeActivate).2 Since an object ﬂow
is deﬁned for this sequence, we choose option (3) by object ﬂow for computing rule
overlappings. Constraints on the type graph (e.g., “a Token node is connected to
exactly one Place node”) prevent the generation of unnecessary NACs.
2 Note that a concurrent rule can be constructed only for a ﬁnite rule sequence.

12.1 The Attributed Graph Grammar System AGG 2.0
359
Fig. 12.7 Concurrent rule generated from a rule sequence in AGG
Construction of Amalgamated Rules
Still, the construction of concurrent rules from rule sequences is not ﬂexible enough
for deﬁning Petri net ﬁring, since, in general, the number of places in a transition’s
pre- and post-domain is not known a priori. What we need here is a concept of
rule synthesis that allows us to apply rules to as many matches as we ﬁnd in the
current instance graph in a synchronised way. This kind of rule synthesis by so-
called amalgamated rules is also supported in AGG 2.0.
If a set of rules p1, . . . , pn share a common subrule p0, a set of multi-
amalgamable3 transformations G
(pi,mi)
=⇒Gi (1 ≤i ≤n) leads to an amalgamated
transformation G
˜p, ˜m
=⇒H via the amalgamated rule ˜p = p1 +p0 . . .+p0 pn, constructed
as the gluing of p1, . . . , pn along p0.
We call p0 kernel rule, and p1, . . . , pn multi rules (see Def. 6.1). A kernel rule
together with its embeddings in any number of multi rules is called rule scheme
(RS) in AGG. An amalgamated transformation G
˜p
=⇒H is a transformation via the
amalgamated rule ˜p (see Def. 6.11).
This concept is very useful for specifying ∀-quantiﬁed operations on recurring
graph patterns (e.g., in model refactorings). The eﬀect is that the kernel rule is ap-
plied only once while multi rules are applied as often as suitable matches are found.
Figure 12.8 depicts the rule scheme with a kernel rule and two multi rules spec-
ifying the ﬁring of a Petri net transition with arbitrary many pre- and post-domain
places. The kernel rule has the same application condition as the rule ActivationCheck
(see Fig. 12.3). Note that we do not need the isActivated ﬂag anymore because the
check and the complete ﬁring step are performed by a single application of the amal-
gamated rule. The amalgamated rule constructed, for example, along a match to an
activated transition with three pre- and two post-domain places is similar to the rule
in Fig. 12.7 but has no NACs because the match into the host graph is predeﬁned by
construction.
The deﬁnition of elementary Petri net ﬁring by a rule scheme is the most intuitive
and most ﬂexible one: we simply state that if a transition fulﬁlls a certain activation
3 In multi-amalgamable transformations, the matches mi agree on the p0 and are independent out-
side (see Def. 6.13).

360
12 Tool Support
Fig. 12.8 Rule scheme deﬁning a transition ﬁring step in Petri nets
Fig. 12.9 Inverse rule of the rule AddPost
condition, from each pre-domain place (independently of their number) a token will
be removed, and to each post-domain place (independently of their number) a token
will be added.
For a larger case study using amalgamated rules to deﬁne the behavioural seman-
tics of statecharts, see [GBEE11].
Construction of Inverse Rules
For a given rule, the inverse rule has LHS and RHS exchanged. Moreover, applica-
tion conditions are shifted over the rule. Figure 12.9 displays the inverse rule of the
rule AddPost (see Fig. 12.4), where an existing token is removed. The shifted NAC
requires that there be exactly one token on the place for the rule to be applicable.
Construction of Minimal Rules
A new challenge from MDD comes from the ﬁeld of model versioning, where the
new notion of graph modiﬁcation [TELW10], deﬁned by a span G ←D →H,
has been established to formalise model diﬀerences for visual models. Based on
graph modiﬁcations, so-called minimal rules may be extracted from a given span to
exploit conﬂict detection techniques for rules. A minimal rule comprises the eﬀects
of a given rule in a minimal context. Via the context menu, AGG 2.0 supports the
extraction of a minimal rule from a selected rule (interpreted as graph modiﬁcation).
For example, the minimal rule of the rule in Fig. 12.7 is depicted in Fig. 12.10. It
does not contain the arcs connecting the places and transitions, since these arcs are
not changed by the rule. It contains the place nodes (because edges connected to

12.1 The Attributed Graph Grammar System AGG 2.0
361
Fig. 12.10 Minimal rule of the concurrent rule in Fig. 12.7
them are deleted or generated), the token nodes (either deleted or generated) and the
transition node (its attribute is possibly changed).
12.1.4 Analysis of Graph Transformation Systems
AGG supports several kinds of validations which comprise graph parsing, consis-
tency checking of graphs (via graph constraints), applicability checking of rule se-
quences, and conﬂict and dependency detection by critical pair analysis of graph
rules. We concentrate in this section on the critical pair analysis and the new us-
ability features in AGG 2.0. Graph parsing and consistency checking is described
already in [EEPT06]. The critical pair analysis (CPA) is the unique feature in AGG
that is not supported by any other graph transformation tools. On the contrary, many
tools (including our own developments described in Sects. 12.2 and 12.4) make use
of the AGG API (application programming interface) to invoke the CPA of AGG
and import the results into their development environments.
Critical Pair Analysis (CPA)
We recall from Sect. 5.2.4 that a suﬃcient condition for a graph transformation sys-
tem to be conﬂuent is to show local conﬂuence for each pair of transformations
G =
p1,m1
===⇒H1 and G =
p2,m2
===⇒H2, provided that the transformation system is termi-
nating. The main idea behind showing local conﬂuence for each possible transfor-
mation pair is to study critical pairs (see Def. 5.40). According to Theorem 5.44, a
transformation system with ACs is locally conﬂuent if all its critical pairs are strictly
AC-conﬂuent (Def. 5.43).
AGG 2.0 implements the critical pair analysis for rules with NACs and PACs,
but not for rules with more complex general (nested) application conditions. Recall
that, following from Def. 2.21, two direct transformations H1 =
p1,m1
===⇒G =
p2,m2
===⇒H2
are parallel dependent if we have one of the following kinds of conﬂict:

362
12 Tool Support
Fig. 12.11 CPA of rule pair (RemovePre, RemovePre), detecting a delete–use conﬂict
1. Delete–use conﬂict: The application of p1 deletes a graph object that is used by
p2 (it is in the match of p2).
2. Produce–forbid conﬂict: The application of p1 generates graph objects in such a
way that p2 cannot be applied after p1 because the NAC of p2 is violated.
3. Change–use-attribute conﬂict: The application of p1 changes attributes that are
in the match of p2.
4. Change–forbid-attribute conﬂict: The application of p1 changes attributes to val-
ues that are forbidden by the NAC of p2.
An example for a critical pair is illustrated in Fig. 12.11, where the classical for-
ward conﬂict in Petri nets is detected when analyzing the rule pair (RemovePre, Re-
movePre). As indicated in the conﬂict view, we have a delete–use conﬂict since two
transitions need to remove the same token from their common pre-domain place.
In analogy to conﬂict detection by critical pair analysis, AGG also supports the
detection of sequential dependencies (again, rules with NACs and PACs are sup-
ported, but not with general application conditions). Recall that, following from
Def. 2.22, two direct transformations G =
p1,m1
===⇒H1 =
p2,m2
===⇒G′ are sequentially de-
pendent (i.e., the second direct transformation is triggered by the ﬁrst one) if we
have one of the following kinds of dependency:
1. Produce–use dependency: The application of p1 produces graph objects p2 uses.
2. Delete–forbid dependency: The application of p1 deletes graph objects, thereby
initially validating the NAC of p2.
3. Change–use-attribute dependency: The application of p1 changes attributes that
are in the match of p2.
4. Change–forbid-attribute dependency: The application of p1 changes attributes to
values, thereby initially validating the NAC of p2.
AGG exploits the following relationship between parallel and sequential depen-
dency: G =
p1,m1
===⇒H1 =
p2,m2
===⇒G′ are sequentially dependent iﬀG ⇐
p−1
1 ,m∗
1
===== H1 =
p2,m2
===⇒G′
are parallel dependent. According to this relationship, AGG constructs the inverse
rule p−1
1
(shifting NACs and PACs if necessary) and applies critical pair analysis
to compute potential conﬂicts for the rule pair (p−1
1 , p2) in minimal context. These
conﬂicts correspond to the potential sequential dependencies of the original rule pair
(p1, p2) in the following way:

12.1 The Attributed Graph Grammar System AGG 2.0
363
Fig. 12.12 CPA of rule pair (AddPost, RemovePre), detecting a produce–use dependency
1. A delete–use conﬂict of (p−1
1 , p2) corresponds to a produce–use dependency of
(p1, p2).
2. A produce–forbid conﬂict of (p−1
1 , p2) corresponds to a delete–forbid dependency
of (p1, p2).
3. A change–use-attribute conﬂict of (p−1
1 , p2) corresponds to a change–use-
attribute dependency of (p1, p2).
4. A change–forbid-attribute conﬂict of (p−1
1 , p2) corresponds to a change–forbid-
attribute dependency of (p1, p2).
An example of a sequential dependency detected by AGG for the Petri net ﬁring
rules AddPost and RemovePre is depicted in Fig. 12.12. As indicated in the depen-
dency view, we have a produce–use dependency since the second transition needs to
remove the same token that has been produced by the ﬁrst transition. Obviously, this
corresponds to a delete–use conﬂict of the inverse rule AddPost−1 and RemovePre.
New Usability Features for CPA in AGG 2.0
Selection of rules for CPA. So far, the CPA can be evoked on a graph grammar,
yielding the critical pairs for each possible rule pair of the grammar. AGG 2.0 pro-
vides free selection of rule sets to be analysed. This feature has proved to be very
convenient, e.g., for a case study, where self-healing systems are modelled by sev-
eral rule sets (normal system behaviour rules, context-changing rules, repair rules).
These sets are analysed for conﬂicts with each other (see Chap. 10).
Modularisation of a model into diﬀerent sub-grammars. In AGG 2.0, rule sets
may be imported into an existing grammar (provided the type graph of the imported
grammar is a subgraph of the type graph of the importing grammar). This supports
modularisation of a model without destroying the possibility to analyse the com-
plete system. In a case study on modelling and analysing adaptive systems by graph
transformation [BEE+13], we made heavy use of this modularisation feature by im-
porting adaptation rule sets to the system grammar whenever the need for system
adaptation arose.

364
12 Tool Support
Interrupt and resume running CPA. As a further usability feature, AGG 2.0 al-
lows the user to interrupt a running critical pair analysis and to resume it later. This
feature is very handy for complex computations which may take some time. A par-
tial CPA result may be stored and reloaded.
Generation of Filter NACs. If during CPA, critical pairs are found that are in-
spected by the user and found not to be causing real conﬂicts, additional NACs for
these rules may be generated automatically that contain the critical overlapping re-
gion. A new CPA of the rules together with these new Filter NACs does not show the
previous critical pair anymore (see Def. 8.16). Possibly, new critical pairs are found
due to the ﬁlter NACs. These may be extinguished by generating corresponding ﬁl-
ter NACs for them, too. The procedure is repeated until no further critical pairs due
to ﬁlter NACs are found. The construction always terminates if the structural part of
each graph of a rule is ﬁnite, as shown in Fact 8.19.
Summarising, AGG 2.0 extends the existing features now coherently with sup-
port for application conditions and object ﬂow, and for automatic construction of
amalgamated, concurrent, inverse and minimal rules. Moreover, the critical pair
analysis has become more usable due to experiences from several case studies.
The critical pair analysis features oﬀered by AGG are also used by our graph
transformation-based tools ActiGra (a tool for checking consistency between con-
trol ﬂow and functional behaviour; see Sect. 12.2), EMF Henshin (an EMF model
transformation engine; see Sect. 12.3), as well as HenshinTGG (the extension of EMF
Henshin to triple graph grammars; see Sect. 12.4).
12.2 ActiGra: Checking Consistency Between Control Flow and
Functional Behaviour
In model-driven software engineering, models are key artifacts which serve as bases
for automatic code generation. Moreover, they can be used for analyzing the sys-
tem behaviour prior to implementing the system. In particular, it is interesting to
know whether integrated parts of a model are consistent. For behavioural models,
this means ﬁnding out whether the modelled system actions are executable in gen-
eral or under certain conditions only. For example, an action in a model run might
prevent one of the following actions occurring because the preconditions of this fol-
lowing action are not satisﬁed anymore. This situation is usually called a conﬂict.
Correspondingly, it is interesting to know which actions do depend on other actions,
i.e., an action may be performed only if another action has occurred before. We call
such situations causalities. This section presents a plausibility checking approach
regarding the consistency of the control ﬂow and the functional behaviour given
by actions modelled as graph transformation rules. Intuitively, consistency means
that for a given initial state there is at least one model run that can be completed
successfully.

12.2 ActiGra: Checking Consistency Between Control Flow and Functional Behaviour
365
We combine activity models deﬁning the control ﬂow and graph transformation
rules in an integrated behaviour model, where a rule is assigned to each simple ac-
tivity in the activity model. Given a system state typed over a given type graph,
the behaviour of an integrated behaviour model can be executed by applying the
speciﬁed actions in the predeﬁned order. The plausibility check allows us to analyse
an integrated behaviour model for favourable and critical signs concerning consis-
tency. Favourable signs are, e.g., situations where rules are triggered by other rules
that precede them in the control ﬂow. On the other hand, critical signs are, e.g.,
situations where a rule causes a conﬂict with a second rule that should be applied
after the ﬁrst one along the control ﬂow, or where a rule depends sequentially on the
eﬀects of a second rule which is scheduled by the control ﬂow to be applied after the
ﬁrst one. An early feedback to the modeller indicating this kind of information in a
natural way in the behavioural model is desirable to better understand the model.
For integrated behaviour models, suﬃcient consistency criteria have been de-
veloped already in [JLMT08]. The analysis consists of generating sets of rule se-
quences, describing potential model runs, and investigating them with respect to
their applicability to initial states in a static way. The advantage thereof is that it is
possible to declare consistency of a behavioural model without having to simulate
each potential model run. However, especially for an inﬁnite set of potential runs
(in case of loops), this technique may lead to diﬃculties. Moreover, it is based on
suﬃcient criteria leading to false negatives.
In this section, we follow a diﬀerent approach, focusing on plausibility reason-
ing on integrated behaviour models and convenient visualisation of the static anal-
ysis results. This approach is complementary to [JLMT08], since we opt for back-
annotating lightweight static analysis results. They do not only visualise the reasons
for successful consistency analysis with more elaborate analysis techniques as pre-
sented in [JLMT08]; in addition, the visualisation of these lightweight results al-
lows for plausibility reasoning on the integrated behaviour model also in the case
of potential inconsistencies or false negatives or when consistency analysis results
of the more elaborate techniques cannot be obtained. For plausibility reasoning, we
determine conﬂicts and existing as well as nonexisting causalities (i.e., sequential
dependencies) between rules depending on the control ﬂow. On the one hand, they
can lead to the detection of potential inconsistencies in the integrated behaviour
model, and on the other hand they can lead to a better understanding of the reasons
for model consistency. This lightweight technique seems to be very appropriate for
allowing for early plausibility reasoning during development steps of integrated be-
haviour models. We visualise the results of our plausibility checks in an integrated
development environment called ActiGra.4 Potential inconsistencies and reasons
for consistency are directly visualised within integrated behaviour models, e.g., as
coloured arcs between activity nodes, and by detailed conﬂict and causality views.
The section is structured as follows: Section 12.2.1 presents our running exam-
ple. In Sect. 12.2.2, we introduce our approach to integrated behaviour modelling
and review the underlying formal concepts for static analysis based on graph trans-
4 http://www.tfs.tu-berlin.de/actigra

366
12 Tool Support
Fig. 12.13 Type graph (a) and instance graph (b) for the Conference Scheduling System, modelled
with the ActiGra environment
formation as much as needed. Diﬀerent forms of plausibility checking are presented
in Sect. 12.2.3, where we validate our approach by checking a model of a conference
scheduling system.5
12.2.1 Case Study: A Conference Scheduling System
This case study6 models planning tasks for conferences. Its type graph is shown in
Fig. 12.13 (a). A Conference contains Persons, Presentations, Sessions and Slots.
A Person gives one or more Presentations and may chair arbitrary many Sessions.
Note that a session chair may give one or more presentations in the session he or she
chairs. A Presentation is in at most one Session and scheduled in at most one Slot.
Slots are linked as a list by next arcs and used by Sessions.
Figure 12.13 (b) depicts a sample instance graph of an initial session plan before
presentations are scheduled into time slots.7 This instance graph conforms to the
type graph. The obvious task is to ﬁnd a valid assignment for situations like the
one in Fig. 12.13 (b), assigning the presentations to available time slots such that
the following conditions are satisﬁed: (1) there are no simultaneous presentations
given by the same presenter, (2) no presenter is chairing another session running
5 More details on the case study can be found in [EGLT11].
6 Taken from the tool contest on Graph-Based Tools 2008 [RV10].
7 Due to space limitations, we do not show name attributes here.

12.2 ActiGra: Checking Consistency Between Control Flow and Functional Behaviour
367
Fig. 12.14 Visual appearance of activity model building blocks
simultaneously, (3) nobody chairs two sessions simultaneously, (4) the presentations
in one session are given not in parallel but in consecutive time slots, and (5) unused
time slots are only at the begin or end of the conference. Moreover, it should be
possible to generate arbitrary conference plans like the one in Fig. 12.13 (b). This is
useful for testing the assignment procedure.
12.2.2 Integrating Activity Models with Graph Transformation
Our approach to behaviour modelling integrates activity models with graph trans-
formation rules, i.e., the application order of rules is controlled by activity models.
A rule describes the behaviour of a simple activity and is deﬁned over a given type
graph. The reader is supposed to be familiar with object-oriented modelling using
the UML [UML15]. Therefore, we present our approach to integrated behaviour
modelling from the perspective of its graph transformation-based semantics.
Integrated behaviour models
As in [JLM+09], we deﬁne well-structured activity models as consisting of a start
activity s, an activity block B, and an end activity e such that there is a transition
between s and B and another one between B and e. Figure 12.14 illustrates the visual
appearance of activity model building blocks.
An activity block can be a simple activity, a sequence of blocks, a fork–join struc-
ture, a decision–merge structure, or a loop. In addition, we allow complex activities
which stand for nested well-structured activity models. In this hierarchy, we forbid
nesting cycles. Activity blocks are connected by transitions (directed arcs). Deci-
sions have an explicit if-guard and implicit else-guard which equals the negated
if-guard, and loops have a loop-guard with corresponding implicit else-guard.
In our formalisation, an integrated behaviour model is a well-structured activity
model A together with a type graph such that each simple activity a occurring in
A is equipped with a typed graph transformation rule ra and each if or loop guard
is either user-deﬁned or equipped with a typed guard pattern. We have simple and
application-checking guard patterns: a simple guard pattern is a graph that has to

368
12 Tool Support
Fig. 12.15 Activity model ScheduleControl and rule scheduleAfter
Fig. 12.16 Graph rule initialSchedule
be found; an application-checking guard pattern is allowed for a transition entering
a loop or decision followed by a simple activity in the loop-body or if-branch, re-
spectively, and checks the applicability of this activity; it is formalised by a graph
constraint (see Def. 5.10) and visualised by the symbol [∗]. User-deﬁned guards are
evaluated by the user at run time to true or false. An initial state for an integrated
behaviour model is given by a typed instance graph.
Example 12.1. Let us assume the system state depicted in Fig. 12.13 is the initial
state of our integrated behaviour model. The activity diagram ScheduleControl is
shown in the left part of Fig. 12.15. Its ﬁrst step performs the initial scheduling
of sessions and presentations into time slots by applying rule initialSchedule (see
Fig. 12.16) as long as possible. The numerous conditions for this scheduling step
are modelled by eight NACs. The sample NAC twoPres shown in Fig. 12.16 means
that the rule must not be applied if the presenter holds already another presentation
in the same slot.8
As second step, two loops are executed taking care to group the remaining pre-
sentations of a session into consecutive time slots, i.e., a presentation is scheduled
in a free time slot either directly before or after a slot where there is already a sched-
uled presentation of the same session. The rule scheduleAfter is shown in the right
part of Fig. 12.15. The rule scheduleBefore looks quite similar; only the direction
of the next edge between the two slots is reversed. Both rules basically have the
same NACs as rule initialSchedule, ensuring the required conditions for the sched-
ule (see [BEL+10]). The NAC shown here ensures that the session chair does not
hold a presentation in the time slot intended for the current scheduling.
△
8 For the complete case study with all rules and NACs, see [BEL+10].

12.2 ActiGra: Checking Consistency Between Control Flow and Functional Behaviour
369
As in [JLM+09], we deﬁne a control ﬂow relation on integrated behaviour mod-
els.9 Intuitively, two activities or guards (a, b) are control ﬂow-related whenever b is
performed or checked after a. Moreover, we deﬁne an against-control ﬂow relation
which contains all pairs of activities or guards that are reverse to the control ﬂow
relation.
The control ﬂow relation CFRA of an activity model A contains all pairs (x, y)
where x and y are activities or guards such that properties (1)–(4) hold:
(1) (x, y) ∈CFRA if there is a transition from activity x to activity y.
(2) (x, y) ∈CFRA if activity x has an outgoing transition with guard y.
(3) (x, y) ∈CFRA if activity y has an incoming transition with guard x.
(4) If (x, y) ∈CFRA and (y, z) ∈CFRA, then also (x, z) ∈CFRA.
The against-control ﬂow relation ACFRA of an activity model A contains all pairs
(x, y) such that (y, x) is in CFRA.
The ActiGra tool
From the modeller’s view, the main components of ActiGra are the following views,
which are organised as a special Eclipse perspective, illustrated in Fig. 12.17.
1. The Tree View
1 gives an overview of all elements of an ActiGra, as usual
in Eclipse applications. This view oﬀers support to add/delete elements such as
object graphs, graph constraints or rules, and to edit element names. By double-
clicking on an element, the visual view for this type of element is opened.
2. The Type Graph View 2 visualises a type graph and supports freehand editing
of node types, edge types, generalisation edges and multiplicities. The palette on
the right-hand side contains the drawing tools.
3. The Instance Graph View 3 visualises an instance graph and supports free-hand
editing of instance graphs. The palette on the right-hand side contains tools to
draw nodes and edges of the corresponding types.
4. The Activity Diagram View 4 is a visual editor for well-structured activity dia-
grams. The panel contains all activity diagram elements. Simple activities contain
the name of a rule which is applied when the corresponding activity is executed.
5. The Rule View
5 is a multi view editor consisting of editor panels for a rule’s
left- and right-hand sides (LHS, RHS) and (optionally) for one or more negative
application conditions (NACs). Editing is supported as in the instance graph view,
but in addition, mappings from the LHS to the RHS and to the NACs can be
deﬁned to identify common graph nodes. Mappings are visualised by equal node
numbers and node colours. The mappings between edges can be inferred from
the node mappings.
6. The Graph Constraint View (not shown in Fig. 12.17) is a visual editor for graph
constraints which are used as guards for decision or loop activities. The execution
of such an activity checks the guard on the current object graph and chooses the
9 In contrast to [JLM+09], we include guards into the control ﬂow relation.

370
12 Tool Support
Fig. 12.17 The ActiGra perspective
corresponding branch if the graph constraint is fulﬁlled, or the alternative branch
if it is violated.
Simulation of integrated behaviour models
The semantics Sem(A) of an integrated behaviour model A consisting of a start ac-
tivity s, an activity block B, and an end activity e is the set of sequences SB, where
each sequence consists of rules alternated with graph constraints (stemming from
guard patterns), generated by the main activity block B (for a formal deﬁnition of
the semantics, see [JLM+09]).10 For a block being a simple activity a inscribed by
a rule ra, SB = {ra}. For a sequence block B = X →Y, we construct SB = SX seq SY,
i.e., the set of sequences that are concatenations of a sequence in S X and a sequence
in SY. For decision blocks, we construct the union of sequences of both branches
(preceded by the if guard pattern and the negated guard pattern, respectively, in the
case that the if guard is not user-deﬁned); for loop blocks, we construct sequences
containing the body of the loop i times (0 ≤i ≤n) (where each body sequence is pre-
ceded by the loop guard pattern and the repetition of body sequences is concluded
10 Note that Sem(A) does not depend on the initial state of A. Moreover, we have a slightly more
general semantics compared to [JLM+09], since we do not have only rules in the sequences of SB,
but also graph constraints.

12.2 ActiGra: Checking Consistency Between Control Flow and Functional Behaviour
371
with the negated guard pattern in the case that the loop guard is not user-deﬁned).
In contrast to [JLM+09], we restrict fork–join blocks to one simple activity in each
branch and build a parallel rule from all branch rules [Lam10, EEPT06].11 We plan
to omit this restriction, however, when integrating object ﬂow [JLM+09] into our
approach, since then it would be possible to build unique concurrent rules for each
fork–join branch. For B a complex activity inscribed by the name of the integrated
behaviour model X, SB = Sem(X).
Consider a sequence s ∈Sem(A) of rules alternated with graph constraints and a
start graph S , representing an initial state for A. We then say that each graph trans-
formation sequence starting with S , applying each rule to the current instance graph
and evaluating each graph constraint to true for the current instance graph in the
order of occurrence in s, represents a complete simulation run of A. An integrated
behaviour model A is consistent with respect to a start graph S , representing an ini-
tial state for A, if there is a sequence s ∈Sem(A) leading to a complete simulation
run. In particular, if A contains user-deﬁned guards, usually more than one complete
simulation run should exist.
In ActiGra we can execute simulation runs on selected activity models. Chosen
activities are highlighted and the completion of simulation runs is indicated. User-
deﬁned guards are evaluated interactively. If a simulation run cannot be completed,
an error message tells the user which activity could not be executed.
12.2.3 Plausibility Checks for Integrated Behaviour Models
We now consider how to check plausibility regarding consistency of the control ﬂow
and the functional behaviour given by actions bundled in object rules. Thereby, we
proceed as follows: We characterise desired properties for an integrated behaviour
model and its initial state as being consistent. We determine the favourable as well
as critical signs12 for these properties to hold, show how the checks are supported
by ActiGra and illustrate by our case study, which conclusions can be drawn by the
modeller to validate our approach.
For the plausibility checks we wish to detect potential conﬂicts and causalities
[EGLT11] between rules and guards occurring in the sequences of Sem(A). Since in
A simple activities, fork/joins as well as simple guard patterns correspond to rules,13
we just call them rules for simplicity. Thereby, we disregard rules stemming from
11 This fork–join semantics is slightly more severe than in [JLM+09], which allows all interleavings
of rules from diﬀerent branches no matter if they lead to the same result.
12 In most cases, these favourable and critical signs merely describe potential reasons for the prop-
erty to be fulﬁlled or not, respectively. For example, some critical pair describes which kind of
rule overlap may be responsible for a critical conﬂict. By inspecting this overlap, the modeller may
realise that the potential critical conﬂict may actually occur and adapt the model to avoid it. On the
other hand, he may realise that it does not occur since the overlap corresponds to an invalid system
state, intermediate rules deactivate the conﬂict, etc.
13 For each simple guard pattern we can derive a guard rule (without side-eﬀects) for the guarded
branch and a negated guard rule for the alternative branch (as described in [JLM+09]). Application-

372
12 Tool Support
simple activities belonging to some fork/join block, since they do not occur as such
in Sem(A). Instead, the corresponding parallel rule for the fork/join is analysed.
As an exception to this convention, the plausibility check in Sect. 12.2.3 inspects
consistency of fork/joins and analyses also the enclosed simple activities.
Inspecting initialisation
If for some sequence in Sem(A) the ﬁrst rule is applicable, then the correspond-
ing sequence can lead to a complete simulation run. Otherwise, the correspond-
ing sequence leads to an incomplete run. Given an integrated behaviour model A
with initial state S , the ﬁrst plausibility check computes automatically for which
sequences in Sem(A) the ﬁrst rule is applicable to S . The modeller then may in-
spect the simulation run(s) that should complete for correct initialisation (desired
property). We identify the favourable signs as the set of possible initialisations:
FaIA = {r | r is ﬁrst rule of sequence in Sem(A) and r is applicable to S }. We iden-
tify the critical signs as the set of impossible initialisations:
CrIA = {r | r is ﬁrst rule of a sequence in Sem(A) and r is not applicable to S }.
ActiGra visualises the result of this plausibility check by highlighting the ele-
ments of FaIA in green. Rules belonging to CrIA are highlighted in red.14
Example 12.2. Let us assume the system state in Fig. 12.13 (b) is an initial state.
The left part of Fig. 12.15 shows the initialisation check result for the activity model
ScheduleControl. We have FaIScheduleControl = {initialS chedule} and CrIScheduleControl
= {scheduleAfter, scheduleBefore}. Thus, complete simulation runs on our initial
state never start with scheduleAfter or scheduleBefore, but always with initialSched-
ule.
△
Inspecting trigger causalities along control ﬂow direction
If a rule a may trigger a rule b and b is performed after a, then it may be advan-
tageous for the completion of a corresponding simulation run. If for some rule b
no rule a is performed before b that may trigger b, this may lead to an incom-
plete simulation run and the modeller may decide to add some triggering rule or
adapt the post-condition of some previous rule in order to create a trigger for b.
Alternatively, the initial state could be adapted such that b is applicable to the
start graph. Given an integrated behaviour model A with initial state S , this plau-
sibility check computes automatically, for each rule a in A, which predecessor
rules may trigger a. The modeller may inspect each rule a for enough predeces-
sor rules to trigger a then (desired property). We identify the favourable signs
as the set of potential trigger causalities for some rule a along the control ﬂow:
checking guard patterns are evaluated for simulation but disregarded by the plausibility checks,
since they are not independent guards but check for the application of succeeding rules only.
14 Concerning fork/join blocks in FaIA or CrIA, ActiGra colours the fork bar.

12.2 ActiGra: Checking Consistency Between Control Flow and Functional Behaviour
373
Fig. 12.18 Potential trigger causalities along the control ﬂow in the activity model GenConfPlans
FaTrAlA(a) = {(b, a) | (b, a) ∈CFRA such that b may trigger a}. We say that FaTrAlA
= {FaTrAlA(a) | a is a rule in A} is the set of potential trigger causalities in A along
the control ﬂow. For this check, the dependency analysis based on critical pairs
oﬀered by AGG 2.0 (see Sect. 12.1.4) is used by ActiGra. We identify the crit-
ical signs as the set of nontriggered rules along the control ﬂow that are not ap-
plicable to the initial state: CrNonTrAlA = {a | a is rule in A such that FaTrAlA(a)
= ∅and a is not applicable to S }.
ActiGra visualises the result of this plausibility check by displaying dashed
green arrows from b to a selected rule a for each pair of rules (b, a) in FaTrAlA(a). If
no rule is selected, then all pairs in FaTrAlA are displayed by dashed green arrows.
Clicking on such an arrow from b to a opens a detail view, showing the reason(s)
why b may trigger a as discovered by CPA. Conversely, ActiGra highlights each
rule belonging to CrNonTrAlA in red. Moreover, when right-clicking on such a rule
its applicability to the initial state can be checked.
Example 12.3. Consider the activity model GenConfPlans in Fig. 12.18 for gener-
ating conference plans, assuming an empty initial state. The set of potential trigger
causalities along the control ﬂow for createSession is given by
FaTrAlGenConfPlans (createSession) = {(createPerson + createPaper, createSession),
(createPerson, createSession)}.
Here, we learn that we need at least one execution of a loop containing the rule
createPerson (a rule with an empty left-hand side) to ensure a complete simulation
run containing createSession. In AGG terms, we have a produce–use dependency of
the rule pair (createPerson, createSession).
Consider the draft activity diagram B for generating conference plans shown in
Fig. 12.19. Here, the set FaTrAlB(Person2Pres) of potential trigger causalities along
the control ﬂow is empty (in ActiGra, it is highlighted in red). Moreover, this rule
is not applicable to the initial state of our model. Hence, we run into an incomplete
simulation run if guard <add a new Presentation> is chosen by the user. One way
to repair this situation is to insert one or more triggering rules before the rule Per-
son2Pres(as, e.g., in Fig. 12.18).
△

374
12 Tool Support
Fig. 12.19 Nontriggered rule Person2Pres along the control ﬂow in activity model B
Inspecting conﬂicts along the control ﬂow direction
If a rule a may disable a rule b, and b is performed after a, then this may lead to an in-
complete simulation run. On the other hand, if for some rule a no rule b performed
before a exists that may disable rule a, then the application of a is not impeded.
Given an integrated behaviour model A with initial state S , this plausibility check
computes automatically, for each rule a in A, which successor rules b in A may be
disabled by a. The modeller then may inspect each rule a in A for the absence of
rules performed before a disabling rule a (desired property). We identify the crit-
ical signs as the set of potential conﬂicts along the control ﬂow caused by rule a:
CrDisAlA(a) = {(a, b) | a, b are rules in A, (a, b) ∈CFRA and a may disable b}. We say
that CrDisAlA = {CrDisAlA(a) | a is a rule in A} is the set of potential conﬂicts along
the control ﬂow in A. For this check, the conﬂict analysis based on critical pairs of-
fered by AGG 2.0 (see Sect. 12.1.4) is used by ActiGra. We identify the favourable
signs as the set of nondisabled rules along the control ﬂow: FaNonDisAlA = {a | a
in A and ∄(b, a) ∈CrDisAlA }.
ActiGra visualises the result of this plausibility check by displaying faint red
arrows from a to b for each pair of rules (a, b) in CrDisAlA. If the rule a is selected,
a bold red arrow from a to b for each pair of rules (a, b) in CrDisAlA(a) is shown.
Clicking on such an arrow opens a detail view, showing the reason(s) why a may
disable b as discovered by CPA. Each rule a in A belonging to FaNonDisAlA is
highlighted in green.
Example 12.4. Consider the activity model SchedulingControl in Fig. 12.20 (a).
Here, the set of potential conﬂicts along the control ﬂow caused by the rule ini-
tialSchedule is given by
CrDisAlSchedulingControl(initialSchedule) = {(initialSchedule, initialSchedule),
(initialSchedule, scheduleAfter),
(initialSchedule, scheduleBefore)}.15
This gives the modeller a hint that in fact a scheduling might not terminate suc-
cessfully in the case that rule initialSchedule creates a situation where not all remain-
ing presentations can be scheduled in a way satisfying all conditions. The detail view
of potential conﬂicts for the pair (initialSchedule, scheduleAfter) in Fig. 12.20 (b)
shows a potential produce–forbid conﬂict where the rule initialSchedule (Fig. 12.16)
15 Note that one pair in this set may indicate more than one conﬂict potentially occurring between
the corresponding rules.

12.2 ActiGra: Checking Consistency Between Control Flow and Functional Behaviour
375
Fig. 12.20 (a) Potential conﬂicts along the control ﬂow caused by rule initialSchedule; (b) Detail
view of potential conﬂict of the rules initialSchedule and scheduleAfter
produces an edge from 2:Pres to 0:Slot, and the rule scheduleAfter then must not
schedule 4:Pres to 0:Slot because of the NAC depicted in Fig. 12.15.
△
Inspecting trigger causalities against control ﬂow direction
If a rule a may trigger a rule b and b is performed before a, then it might be the
case that their order should be switched in order to obtain a complete simulation
run. Given an integrated behaviour model A with initial state S , this plausibility
check automatically computes for each rule a in A which successor rules of a may
trigger a. The modeller then may inspect for each rule a in A that no rule performed
after a exists that needs to be switched to a position before a in order to trigger its
application (desired property). We identify the critical signs as the set of potential
causalities against control ﬂow triggered by a: CrTrAgA(a) = {(a, b) | a, b rules in A
and (a, b) ∈ACFRA such that a may trigger b}. We say that CrTrAgA = {CrTrAgA(a)
| a is a rule in A} is the set of potential trigger causalities against control ﬂow in A.
We identify the favourable signs as the set of rules not triggered against control
ﬂow: FaNoTrAgA = {a | a is rule in A and ∄(b, a) ∈CrTrAgA }.
ActiGra visualises the result of this plausibility check by displaying a dashed
red arrow from a selected rule a to b for each pair of rules (a, b) in CrTrAgA(a). If
no rule in particular is selected, then all pairs in CrTrAgA are displayed by dashed
red arrows. Clicking on such an arrow from a to b opens a detail view, showing
the reason(s) why a may trigger b as discovered by CPA. Conversely, each rule
belonging to FaNoTrAgA is highlighted in green.
Example 12.5. In the activity diagram GenConfPlans in Fig. 12.21, we get the set
of potential causalities against control ﬂow CrTrAgGenConfPlans (createS ession) =
{(createSession, Person2Pres)}. The causality (createSession, Person2Pres) indi-
cates that the rule Person2Pres might be modelled too early in the control ﬂow since
the rule createSession is needed to trigger the rule Person2Pres completely.
△

376
12 Tool Support
Fig. 12.21 Trigger causality against control ﬂow (createSession, Person2Pres)
Inspecting causalities in fork/joins
We may not only consider the consistent sequential composition of rules as before,
but consider also the parallel application of rules as speciﬁed by fork/join activities.
Whenever a rule pair (a, b) belonging to the same fork/join may be causally de-
pendent, it is not possible to change their application order in any situation without
changing the result. However, the parallel application of the rules (a, b) implies that
their application order should not matter.
Given an integrated behaviour model A with initial state S , this plausibility check
determines automatically for each fork/join in A if potential causalities between the
enclosed simple activities exist. The modeller may inspect each fork/join for its
parallel execution not to be disturbed then (desired property).
We need some more elaborate considerations for this case, since we wish to anal-
yse simple activities within a fork/join block that are normally disregarded, as they
only occur in the form of the corresponding parallel rule in S em(A). In particular,
we deﬁne a fork/join relation FJRA consisting of all rule pairs (a, b) belonging to the
same fork/join block. We identify the critical signs as the set of potential causali-
ties between diﬀerent fork/join branches: CrFJCaA = {(a, b)|(a, b) ∈FJRA and (a, b)
causally dependent}.16 We identify the favourable signs as the set of fork/join struc-
tures with independent branches: FaFJNoCaA = {fj|fj is fork/join in A and (a, b) <
CrFJCaA for each (a, b) with a,b in diﬀerent branches of fj}.
ActiGra visualises the result of this plausibility check by displaying in each
fork/join block a dashed red arrow from a to b for each (a, b) ∈CrFJCaA. The
detail view shows the reason(s) why (a, b) are causally dependent, as discovered by
CSA, and why this dependency might disturb parallel execution. On the other hand,
each fork/join in FaFJNoCaA is highlighted by green fork and join bars.
Example 12.6. The set of potential causalities between diﬀerent fork/join branches
depicted in Fig. 12.22 is given by {(createPerson, Person2Pres)}. We may have a
dependency (shown in the detail view) if the rule createPerson creates a Person node
that is used by the rule Person2Pres to link it to a Presentation node.
△
16 Here, we do not only regard trigger causalities between a and b, but also causalities making the
application of the rule a irreversible, as described in [Lam10].

12.3 Controlled EMF Model Transformation with EMF Henshin
377
Fig. 12.22 Potential causality between diﬀerent fork/join branches and its detail view
Summarising, ActiGra leverages the critical pair analysis of AGG to detect pos-
sibly unwanted interactions in integrated behavioural models. Please note that our
approach to plausibility reasoning can easily be adapted to any other approach where
modelling techniques describing the control ﬂow of operations are integrated with
operational rules, as, e.g., the integration of live sequence charts with object rules
in [LMEP08]. The ActiGra approach and tool have recently been applied success-
fully to analyse aspect-oriented models [MHMT13]. In this case study, a crisis man-
agement system is modelled using ActiGra, and model consistency is analysed at
the level of requirements modelling.
A further reﬁnement step in activity-based behaviour modelling would be the
speciﬁcation of object ﬂow between activities. Additionally speciﬁed object ﬂow be-
tween two activities would further determine their interrelation. In this case, previ-
ously determined potential conﬂicts and causalities might not occur anymore. Thus,
the plausibility checks would become more exact with additionally speciﬁed object
ﬂow. A ﬁrst formalisation of integrated behaviour models with object ﬂow based on
graph transformation is presented in [JLM+09]. An extension of plausibility checks
to this kind of activity models is left for future work.
To conclude, integrated behaviour models head towards a better integration of
structural and behavioural modelling of (software) systems. Plausibility checks pro-
vide lightweight static analysis checks supporting the developer in constructing con-
sistent models.
12.3 Controlled EMF Model Transformation with EMF Henshin
In graph transformation tools, the application of rules may be controlled implicitly
as in AGG (Sect. 12.1), i.e., by a ﬁxed strategy such as “apply rules in arbitrary or-
der as long as possible” and by providing negative application conditions for rules.
Alternatively, control strategies may be deﬁned explicitly as in Fujaba [FNTZ00],
where an activity diagram (story diagram) deﬁnes loops or conditions on rule ap-
plications. Explicit control structures raise the expressiveness of transformation sys-
tems since they provide means to regulate the transformation process without having
to introduce helper structures into the rules.
In this section, we lift implicit and explicit control structures from graph transfor-
mation to EMF model transformation and introduce an extension of the tool EMF

378
12 Tool Support
Henshin17 by visual editors for control structures. EMF Henshin is an Eclipse plug-
in supporting visual modelling and execution of EMF model transformations, i.e.,
transformations of models conforming to a meta model given in the EMF Ecore
format.18 The transformation approach we use in our tool is based on graph trans-
formation concepts which are lifted to EMF model transformation by also taking
containment relations in meta models into account [ABJ+10, BESW10].
The Eclipse Modeling Framework EMF [EMF14] is a modelling and code gen-
eration facility for building tools and other applications based on a structured data
model. Based on a meta model, EMF provides tools and runtime support to produce
a set of Java classes for the meta model, a set of adapter classes that enable viewing
and command-based editing of models conforming to the meta model, and a ba-
sic (tree-based) editor. EMF provides the foundation for interoperability with other
EMF-based tools, e.g., OCL checkers.
The conceptual similarities of modelling based on typed attributed graphs and
object-based modelling as performed by EMF are shown in Table 12.1, which is an
extension of Table 3.1 by the EMF-speciﬁc concept of containment.
Table 12.1 Mapping EMF notions to typed attributed graph terminology
EMF notion
Typed attributed graph terminology
EMF model
Type graph with attribution, inheritance and multiplicities; edges can be marked
as containments
Instance model Typed attributed graph with containment edges
Class
Node in type graph
Object
Node in typed graph
Association
Edge in type graph (with possible multiplicities or containment mark)
Reference
Edge in typed graph that satisﬁes multiplicity and containment constraints
Containment relations, i.e., aggregations, deﬁne an ownership relation between
objects. Thereby, they induce a tree structure in model instantiations. In MOF and
EMF, this tree structure is further used to implement a mapping to XML, known
as XMI (XML Meta data Interchange) [XMI08]. Containment implies a few con-
straints for model instantiations that must be ensured at runtime. As semantical con-
straints for containment edges, the MOF speciﬁcation [Obj14a] states the following:
“An object may have at most one container” and “Cyclic containment is invalid”.
EMF provides full implementation of instance models that always ensures these
constraints. In [BET12], containment constraints of EMF model transformations are
translated to a special kind of well-formed graph transformation rule whose appli-
cation leads to consistent transformation results only, i.e., they must not delete con-
tained objects without deleting their containment relations as well, and they must
17
http://www.eclipse.org/modeling/emft/henshin/,
originating
from
EMF
Tiger
[EMT09,
BEK+06, BEL+10]
18 Note that we use the terms meta model and model in this section, which are called EMF model
and model instance in the EMF documentation, respectively.

12.3 Controlled EMF Model Transformation with EMF Henshin
379
Fig. 12.23 EMF Henshin GUI with visual editors for graphs and rules
not generate objects without relating them to precisely one container. Moreover,
containment cycles must not be produced by rule applications.
Applying EMF model transformation rules in EMF Henshin changes an EMF
model in-place, i.e., the model is modiﬁed directly. Note that we speak of EMF
model transformation in a general sense, comprising not only source-to-target
model-to-model transformations but also model refactorings or simulation of the
system’s behaviour.19 The EMF Henshin transformation engine provides classes that
can freely be integrated into existing Java projects relying on EMF.
Figure 12.23 depicts the basic GUI of our EMF Henshin tool (without the ex-
tensions for control structure deﬁnition). The tree view
1 allows the modeller to
import EMF EPackages containing the basic meta model(s) deﬁning the domain of
the transformation. The initial model is edited in a visual editor 2. In the rule editor
3, transformation rules can be created by editing a rule’s left-hand side (LHS) and
right-hand side (RHS), similarly to rule visualisation in AGG. The property view 4
shows additional information for selected objects. Note that all information edited
using the editors in 2, 3 and 4 can also be obtained via the tree view 1.
The rule displayed in Fig. 12.23, 3, deﬁnes an operation adding a Request object
and linking it to existing Departure and a Destination objects. This rule can now be
applied to the current model (Fig. 12.23,
2), leading to the transformed graph
shown in Fig. 12.24, where a Request object has now been created and linked to the
19 As in our running example, where we handle the simulation of a personal mobility manager
based on a web service.

380
12 Tool Support
Fig. 12.24 Transformed graph after applying the rule RequestRouteMap
Departure object named “Berlin” and the Destination object named “Potsdam”. The
layout of newly added objects is computed automatically but may be adjusted by
the user.
In this section, we describe the extension of EMF Henshin supporting the use of
the control structures (called EMF Henshin transformation units), e.g., constructs
for nondeterministic rule choices, rule sequences or conditional rule applications.
Those constructs may be nested to deﬁne more complex control structures. Passing
of model elements as parameters from one unit to another is also possible. Apart
from control units deﬁned over sets of rules, we now also support the graphical
deﬁnition of application conditions for individual rules. These are application con-
ditions in the sense of Def. 5.1, allowing for arbitrary nesting. Several application
conditions can be combined by logical connectors.
The section on EMF Henshin is structured as follows: Section 12.3.1 presents our
running example, the simulation of a personal mobility manager (PMM) based on
a web service. Along the PMM example, we introduce the usage of transformation
units and application conditions in Sects. 12.3.2 and 12.3.3, respectively.
12.3.1 Example: Personal Mobility Manager
As a running example, we specify and simulate the operational behaviour of a Per-
sonal Mobility Manager (PMM), a reactive service-based application designed to
satisfy requirements related to individual user mobility [LMEP08]. The aim of the
system is to help the user ﬁnd an adequate route from a departure place to a des-
tination and to propose an adequate means of transportation (either car or bike) by
taking the current traﬃc intensity into account. We model the control ﬂow of mes-
sages that are exchanged between the user, the PMM and the corresponding web
service. To keep things simple, we do not model the actual web service here but
simulate its responses by suitable variable assignments.
The modelling domain is speciﬁed by the meta model depicted in Fig. 12.25.
We have model elements for a user, the user’s departure and destination locations,
the means of transport, and requests sent to the web service. A Route element con-
tains a route given as response by the mobility web service, and a JamStatus element
contains the response returned by the web service concerning the traﬃc on a given
route. Edges with white triangles as arrowheads are inheritance relations; the re-

12.3 Controlled EMF Model Transformation with EMF Henshin
381
Fig. 12.25 Meta-model for the Personal Mobility Manager
Fig. 12.26 EMF model transformation rules for the Personal Mobility Manager
maining edges denote associations with multiplicities, where multiplicity “0..1” at
the target of an association means that a source object of a correspondingly typed
reference is linked to at most one target object of the corresponding class. Note that
we do not use containment edges in this example. Utilising EMF Henshin to model
a case study with containment relations is described in [BET12].
Basic PMM actions are modelled by EMF model transformation rules, as shown
in Fig. 12.26.
The rule ChooseDestination creates a Destination object where the name of the des-
tination is an input parameter; the rules RequestRouteMap and ResponseRouteMap
realise the creation of a route (modelled by a Route object) via a web service call.
Having called this web service more than once, one of the returned routes is cho-
sen by the user using the rule ChooseRoute. For a given route, the web service is

382
12 Tool Support
used by the rules RequestJamStatus and ResponseJamStatus to get information about
the current traﬃc situation on this route. Depending on the information obtained by
the web service (and coded in the JamStatus node), the means of transport can be
changed from the default means “car” (as presented in the start graph in Fig. 12.23)
to the alternative means “bike”. This is realised by applying the rules ForbidCar and
SelectBike. At last, the information about traﬃc (JamStatus node) and possible alter-
native routes which have not been chosen are deleted using the rules DeleteJamStatus
and DeleteUnusedRoute.
In the next subsection, we explain the use of EMF Henshin transformation units
to encapsulate and control the order of rule applications.
12.3.2 EMF Henshin Transformation Units
EMF Henshin transformation units may be arbitrarily nested inside each other. The
most basic unit is an EMF model transformation rule (like the rules depicted in
Fig. 12.26). An EMF Henshin transformation unit may be of type IndependentUnit
(of all applicable subunits, one is applied arbitrarily), SequentialUnit (all subunits
are applied sequentially20 in a given order), LoopUnit (its subunit is applied as long
as possible), ConditionalUnit (its subunits are applied depending on the evaluation
of a given condition unit), and PriorityUnit (the applicable subunit with the highest
priority is applied next). A unit is applicable (and returns true) if it can be success-
fully executed. PriorityUnits and IndependentUnits are always applicable, while Se-
quentialUnits are applicable only if all subunits are applicable the deﬁned number
of times in the given order; a LoopUnit is applicable if its subunit is applicable. A
ConditionalUnit is applicable if either the then subunit (in case the condition is true)
or the else subunit (in case the condition is false) is applicable.
EMF Henshin transformation units may be deﬁned in the tree view or, alterna-
tively, in a visual editor. The tree view shows all transformation units and their
nesting hierarchy. The visual editor for one unit shows the unit in a left view and
one selected subunit in a right view (see Fig. 12.27). The unit view shows the unit’s
name as header, a set of parameters shown as boxes in the left column, and the
names and kinds of its subunits in the right column. Subunits of a SequentialUnit
have a counter indicating their number of applications. A unit and a subunit may
share parameters shown by the colouring of the parameter ﬁelds (see bottom part
of Fig. 12.27, where the unit trafﬁcWS shares the parameter route with the subunit
RequestJamStatus). Arrows from (to) parameter boxes to (from) subunits indicate
which parameters are input (output) of which subunit. Parameter passing between
units serves as a match control mechanism; thus, the modeller may deﬁne, e.g., that
a unit must be applied to the very node that has been generated by the previously
applied unit.
20 Optionally more than once by deﬁning a counter for each subunit.

12.3 Controlled EMF Model Transformation with EMF Henshin
383
Fig. 12.27 EMF Henshin GUI with transformation unit editor
Fig. 12.28 EMF Henshin transformation unit decideMeans
The transformation unit mainUnit shown in Fig. 12.27 is the main control structure
for the PMM example. It is a SequentialUnit (symbolised by a ﬁlm strip as icon in
the upper left corner) containing four subunits. This means that each subunit is ap-
plied as often as indicated by its counter, in the given order from top to bottom. The
ﬁrst subunit, ChooseDestination is a transformation rule, marked by gear wheels (see
Fig. 12.26 for the rule deﬁnition). This rule has an input parameter, the destination
dest, a user-deﬁned parameter. The second subunit of the main unit is a Sequential-
Unit (to be applied three times). The unit trafﬁcWS is shown with its contents in the
view to the right: it contains in turn four rules realising the web service requests and
processing the responses. The rule ResponseRouteMap produces an output parameter
of type Route which serves again as input parameter for the rule RequestJamStatus.
The third subunit of mainUnit, decideMeans, is a ConditionalUnit (symbolised by
an if-then-else icon). Clicking on its ﬁeld, a detailed view of this unit is opened (see
Fig. 12.28).
Here, a condition called AllRoutesJammed (which will be discussed in Sect. 12.3.3)
is checked; it is given as application condition of the empty rule. If the condition is
evaluated to true, the two rules ForbidCar and SelectBike in the sequential unit switch-
ToBike are applied in this order. Otherwise, the rule ChooseRoute is applied and the
parameter route is returned to the parent unit mainUnit.
Figure 12.29 illustrates the situation after applying the unit decideMeans, where
all routes have been found to be jammed and the bicycle is selected as transport
means.
The last child unit of mainUnit is the LoopUnit collectGarbage (with a loop as icon
symbol). This unit applies its subunit as long as possible (see Fig. 12.30). It contains

384
12 Tool Support
Fig. 12.29 Intermediate state where the bicycle is selected as transport means
Fig. 12.30 EMF Henshin transformation unit collectGarbage
Fig. 12.31 EMF Henshin interaction scheme DeleteAllRoutesAndJamsInOneStep
an IndependentUnit with two rules, DeleteJamStatus and DeleteUnusedRoute, which
perform the garbage collection. One of the applicable subunits in an IndependentU-
nit is selected randomly (hence, it has a die as icon symbol).
Alternatively, an interaction scheme may be deﬁned (see Def. 6.30), replacing
the LoopUnit collectGarbage: the interaction scheme shown in Fig. 12.31 consists
of an empty kernel rule DeleteAllRoutesAndJamInOneStep and one multi rule called
DeleteRouteAndJamPair. Note that EMF Henshin implements maximal weakly dis-
joint matchings according to Def. 6.32. Thus, by specifying an empty kernel rule,
we ensure that the connected Route-JamStatus node pairs, found by the matching
process, do not overlap.
The application of the interaction scheme deletes all such pairs of a Route and a
JamStatus node in one step, provided that they are not used anymore (i.e., there is no
user connected to the corresponding Route node). The visualisation of rule schemes

12.3 Controlled EMF Model Transformation with EMF Henshin
385
is similar to the visualisation in AGG (see Fig. 12.8 in Sect. 12.1.3). But in addition
to AGG, EMF Henshin allows nesting of multi rules in arbitrary depth.
12.3.3 Application Conditions
In addition to (explicit) control structures, called transformation units, EMF Hen-
shin also implements application conditions for transformation rules according to
Def. 5.12. Recall that, like transformation units, application conditions can be
nested. Moreover, application conditions may be negated, and several application
conditions may be combined by using the logical connectors AND and OR.
Let us consider once more the ConditionalUnit decideMeans from our PMM ex-
ample (see Fig. 12.28). Here, the condition AllRoutesJammed is expressed by an
empty rule21 with a nested application condition, shown in Fig. 12.32. Since we
cannot use directly universal quantiﬁers “ ∀” in graph conditions, we reformulate
the condition “All routes have a jam status and are jammed” using existential quan-
tiﬁers “ ∃” only. Hence, we get the logically equivalent expression “There is no
route that has not been given a jam status or that is free”.
In view
1 of Fig. 12.32, the empty rule is shown together with the outermost
condition graph (a condition over LHS ). In the tree view of
1, it can be seen
that we require ∄Route, i.e., a morphism from the graph Route (consisting of a
single Route node) into the host graph must not exist for the rule to be applicable.
Since this application condition is nested, we require a further condition for the
Route graph, formulated as disjunction (OR-construct) over two more conditions:
(∄HasNoJamStatus ∨∃IsFree). This formula can be seen in the tree view of
2, as well as in the corresponding visual hierarchical view where the formula is
depicted as an OR block with two compartments. Clicking on one of the two parts
of the disjunction in the visual view (or on one of the two OR branches in the
tree view) opens the next level, either for the formula ∄HasNoJamStatus in
3 or
for the formula ∃IsFree in
4. Here, we have arrived at the basic level of graph
morphisms. The complete nested application condition AllRoutesJammed means that
the empty rule is applicable (returns true) if there exists no route that has either no
JamStatus node or that has a JamStatus node with attribute jam=false. Recall that in
this case (all routes are jammed) the unit decideMeans (see Fig. 12.28) applies the
unit switchToBike; otherwise a route is chosen for the car as transport means.
Summarising, in this section, we have presented three extensions for support-
ing controlled EMF transformations in our EMF transformation environment EMF
Henshin. The ﬁrst extension supports the visual deﬁnition of EMF Henshin transfor-
mation units, which may be hierarchically nested (the basic unit being a rule) and
which restrict the possible rule application sequences in a suitable way. The second
extension concerns the deﬁnition of (nested) interaction schemes to allow for amal-
21 Note that we allow arbitrary transformation units as conditions in ConditionalUnits. While this
may lead to side eﬀects if a unit diﬀerent from the empty rule is used, the conceptual advantage is
that components of EMF Henshin transformation units always are transformation units in turn.

386
12 Tool Support
Fig. 12.32 Empty rule AllRoutesJammed with application condition
gamated EMF model transformations. This proved to be very useful for specifying
operations on recurring model patterns. The third extension supports the deﬁnition
of application conditions for transformation rules, where conditions may be nested
and combined by logical connectors such as AND and OR.
For execution, EMF Henshin rules and transformation units can be used in other
Java projects by instantiating the class RuleApplication or UnitApplication, respectively.
The class RuleApplication requires a Rule instance from the EMF Henshin meta
model. Once instantiated, the rule can be applied by calling the execute() method
of RuleApplication. Transformation units can be executed in a similar way by us-
ing the class UnitApplication. The multi view EMF Henshin editor is available via
the following GitHub repository: https://github.com/de-tu-berlin-tfs/
Henshin-Editor.
Apart from the PMM example, EMF Henshin has been applied also for larger
case studies, e.g., for model refactorings [AT13, ABJ+10] and model-to-model
transformations such as the Ecore2Genmodel case study of the Transformation Tool
Contest 2010 [BEJ10]. Recently, EMF Henshin has been used by the Luxembourg-
based satellite operator SES to translate proprietary satellite control procedures into
the open-source software SPELL (Satellite Procedure Execution Language and Li-
brary), a standardised satellite control language. For this purpose, the EMF Henshin
editor has been extended to HenshinTGG, supporting visual model transformation
with triple graph grammars [HGN+14], which will be described in the next section.

12.4 Bidirectional EMF Model Transformation with HenshinTGG
387
Fig. 12.33 Workﬂow overview of using HenshinTGG for EMF model transformation
12.4 Bidirectional EMF Model Transformation with HenshinTGG
In this section, we continue the idea of using graph transformation concepts to re-
alise EMF model transformations. We consider a recent extension of the tool EMF
Henshin to specify model transformations based on triple graph grammars (TGGs).
We present the visual TGG modelling and analysis environment HenshinTGG
[EHGB12] building on the EMF model transformation engine EMF Henshin
that was described in Sect. 12.3. In contrast to existing TGG implementations
[GHL12, ALPS11, BGH+05, LAS+14b, HLG+13], HenshinTGG does not only spec-
ify and perform EMF model transformations by TGGs but generates forward trans-
lation rules (synthesised from forward and source rules) according to Sect. 7.4, and
oﬀers a converter to translate forward translation rules to the graph transformation
analyser AGG (see Sect. 12.1) in order to beneﬁt from AGG’s critical pair analysis
for conﬂict detection. Figure 12.33 presents an overview of the overall workﬂow
using the main tool features of HenshinTGG.
The section on HenshinTGG is structured as follows: we present our visual TGG
editor in Sect. 12.4.1 and describe the generation of forward translation rules based
on Sect. 7.4 in Sect. 12.4.2. An example for a conﬂict analysis of forward translation
rules converted to AGG based on critical pairs is presented in Sect. 12.4.3, while
Sect. 12.4.4 explains the automatic EMF model translation.
12.4.1 The Visual TGG Editor
Recall the main constructions and results of model transformations based on TGGs
as given in Sect. 7.3. To demonstrate the features of our tool HenshinTGG, we imple-
ment the well-known model transformation from class diagrams to database models
(see Ex. 3.6). The triple type graph, underlying a model transformation, is deﬁned by
three diﬀerent EMF models for the source, correspondence, and target components.
Example 12.7 (EMF models for CD2RDBM model transformation). Figure 12.34
depicts the three EMF models implementing the type graph TG of the triple graph
grammar TGG for our CD2RDBM model transformation (see Ex. 3.6). The source
1) import 
EMF models
Imports
3) draw 
triple rules
Rules
2) draw source 
models
Graphs
4) generate 
forward 
translation 
rules
FT Rules
Translated 
Graphs
7) execute 
FT rules
5) conflict 
analysis
Critical Pairs
6) add filter 
NACs

388
12 Tool Support
Fig. 12.34 EMF models comprising the triple type graph for the CD2RDBM model transformation
component TGS deﬁnes the structure of class diagrams while in the target compo-
nent the structure of relational database models is speciﬁed. Classes correspond to
tables, attributes to columns, and associations to foreign keys. Morphisms starting
at a correspondence part are indicated by dashed arrows and are modelled by intra-
model references in EMF.
△
The HenshinTGG editor uses EMF models as type graphs and EMF instance mod-
els conforming to the respective EMF models as typed (attributed) graphs.22 The
three EMF models in Fig. 12.34 have been edited outside the visual TGG editor
using the graphical GMF editor for EMF, but any other EMF model editor or gen-
erator can be used as well. The morphisms are implemented as references between
the types of the three diﬀerent EMF models. EMF models are imported into the vi-
sual TGG editor, which enables the use of previously produced EMF models. The
names of the three imported EMF models, source, correspondence and target, that
comprise the triple type graph are shown in the top compartment, Imports, of the
tree view 1 in Fig. 12.35.
Once a triple type graph is available (i.e., the three EMF models have been im-
ported), triple graphs typed over this type graph may be edited, e.g., for modifying
inputs and intermediate states when testing model transformations. The visual TGG
editor supports editing of triple graph nodes and edges by oﬀering the available
types in the palette of the triple graph panel 2. Only triple graphs conforming to
the triple type graph can be created. Moreover, only source triple graph elements
can be created and modiﬁed in the left-hand part of the editor, correspondence
graph elements in the center, and target graph elements in the right part. The separa-
tors between the diﬀerent triple panels can be moved using the mouse. Morphisms
from correspondence to source and target elements are drawn as edges across the
separators. Figure 12.35 displays a sample triple graph, OrderDetails, containing a
complete source part (the class diagram) but incomplete corresponding target and
correspondence graphs.
22 For more details on the formal correspondence of typed attributed graphs and EMF models, see
Table 12.1.

12.4 Bidirectional EMF Model Transformation with HenshinTGG
389
Fig. 12.35 Graphical user interface of the visual TGG editor
Recall that triple graphs can be generated by applying triple rules to a start triple
graph G (see Def. 3.8). Triple rules synchronously build up the source, target and
correspondence graph, i.e., they are nondeleting.
Example 12.8 (Triple rules). The triple rules shown in Fig. 12.36 are part of the rules
of the grammar TGG for the model transformation CD2RDBM (see Ex. 3.9).
In HenshinTGG, triple rules are drawn in short notation, i.e., left- and right-hand
sides of a rule are depicted in one triple graph. Elements which are created by the
rule are labeled by "++". The rule CD2RDBM (see 3 in Fig. 12.35) synchronously
creates a class diagram together with the corresponding database. Analogously, the
rule Class2Table creates a class with a name as input parameter together with the
corresponding table in the relational database. A subclass is connected to the table of
its superclass by the rule Subclass2Table. Attributes of a certain datatype are created
together with their corresponding columns in the database component via the rule
Attr2Column.
△
The visual HenshinTGG editor for triple rules consists of three panel parts like
the visual triple graph editor (see
2 in Fig. 12.35). But in addition to the triple
graph editor, the rule editor palette oﬀers a "++" to mark elements as created (and
to unmark marked elements if necessary). Note that HenshinTGG checks triple rules
for consistency at editing time, i.e., if a node is "++"-marked, all incident edges are
marked automatically, as well.
HenshinTGG supports negative application conditions for triple rules that forbid
the presence of certain structures when applying a rule [EEHP09, GEH11]. A visual

390
12 Tool Support
Fig. 12.36 Some rules for the model transformation CD2RDBM (HenshinTGG screenshots)
Fig. 12.37 Triple rule C2T with NAC ClassesBeforeAssocs
NAC editor can be opened via the tree view and consists of a three panel triple graph
editor again. A rule may have several NACs; the one to be shown in the visual NAC
editor has to be selected in the tree view. Figure 12.37 depicts the rule Class2Table
with an additional NAC that forbids the synchronous creation of a class and a table
if there are associations in the same class diagram.
The morphism from the rule to one of its NACs is indicated by equal numbers for
mapped nodes (in Fig. 12.37, the ClassDiagram node is mapped to the NAC). Edges
are mapped accordingly automatically. The rule palette entry Mapping supports the
deﬁnition of a mapping from the triple rule to a NAC. Note that only unmarked

12.4 Bidirectional EMF Model Transformation with HenshinTGG
391
elements (without "++") can be mapped to NAC elements, a consistency property
which is also checked automatically by the editor.
A triple rule can be applied by clicking the button Execute Rule in the rule’s tool
bar (the upper right corner in Fig. 12.35), and selecting the graph the rule should be
applied to. The result is shown in the view of the selected graph.
12.4.2 Generation of Forward Translation Rules
From each triple rule tr, so-called operational rules can be automatically derived
[Sch94] for parsing a model of the source or target language (source and target
rules) and for model transformations from source to target or backwards (forward
and backward rules), as deﬁned in Def. 7.12.
According to Sect. 7.4, the extension of forward rules to forward translation rules
is based on additional Boolean attributes for all elements in the source component,
called translation attributes, that control the translation process by keeping track of
the elements which have been translated so far. This ensures that each element in
the source graph is translated exactly once.
Let us recall the algorithm for constructing forward translation rules from triple
rules from Def. 7.29: For each triple rule tr, initialise the forward translation rule
trFT = trF by the forward rule trF. Add an additional Boolean attribute isTranslated
to each source element (node, edge or attribute) of trFT. In the left-hand side of trFT,
for each source element, the value of the isTranslated attribute is set to false if the
element is generated by the source rule trS of tr; otherwise it is set to true. In the
right-hand side of trFT, the value of all isTranslated attributes is set to true. For all
source elements in NACs, the attribute isTranslated is set to true as well.
Note that in contrast to forward translation rules, pure forward rules need addi-
tional control conditions to ensure correct executions, such as the source consistency
condition deﬁned in Def. 7.18.
In HenshinTGG, forward translation rules are computed automatically. The trans-
lation attributes for nodes and edges and node attributes are kept separately as an ex-
ternal pointer structure in order to keep the source model unchanged. In the source
graph editor panel of a forward translation rule, all elements that are still to be trans-
lated are marked by a "<tr>" tag.
Example 12.9 (Forward translation rule). Figure 12.38 shows the forward transla-
tion rule FT_SubClass2Table generated from the triple rule SubClass2Table. The
Class node, its attribute and its incident edge are marked by a "<tr>" tag so as to be
translated, since these model elements correspond to the model elements generated
by the source rule of the triple rule SubClass2Table.
△
Forward translation rules can be edited in a restricted visual triple rule editor,
which allows for a manual extension of additional NACs. All other rule editor op-
erations are blocked because forward translation rules are generated automatically
and should not be changed manually. Figure 12.39 shows the abstract syntax of the

392
12 Tool Support
Fig. 12.38 Forward translation rule FT_SubClass2Table
Fig. 12.39 Rule FT_SubClass2Table in abstract EMF Henshin syntax
forward translation rule FT_SubClass2Table from Fig. 12.38, as it is represented in
EMF Henshin, where left-hand and right-hand sides of a rule are kept separately,
with morphisms inbetween. We can see how the translation attributes of source ele-
ments are switched from false to true.
For matching, we internally keep two tables (hashmaps), “TranslatedNodes” and
“TranslatedEdges”, based on the IDs of the elements of an EMF instance model.
These tables are constructed and updated dynamically during transformation exe-
cution. A match is valid if for each matched element we have one of the following
cases:
• its translation attribute is true and its ID is present in the corresponding table of
translated elements, or
• its translation attribute is false and its ID is not present in the corresponding table
of translated elements.

12.4 Bidirectional EMF Model Transformation with HenshinTGG
393
Fig. 12.40 Incomplete forward translation sequence: parent edge could not be translated
12.4.3 Conﬂict Analysis Based on AGG
According to Def. 7.33, a forward translation sequence G0 =
tr∗
FT
==⇒Gn is called com-
plete if Gn is completely translated, i.e., all translation attributes of Gn are set to true.
A model transformation based on forward translation rules with NACs (consisting
of a source graph GS , a target graph GT, and a complete forward translation se-
quence G0 =
tr∗
FT
==⇒Gn) is terminating if each forward translation rule changes at least
one translation attribute from false to true; it is correct if each forward translation
results in a triple graph that can be generated by triple rules, and it is complete if
for each source graph there is a forward translation sequence that results in a triple
graph that can be generated by triple rules.
However, not all terminating forward translation sequences are complete. A
counterexample is a forward translation rule sequence applied to the triple graph
TwoClasses consisting of a parent class named Client and a subclass named Pre-
miumClient connected to class Client by a parent edge (see the source graph in
Fig. 12.40).
The incomplete forward translation sequence is as follows: FT_CD2DB trans-
lates the ClassDiagram node to a Database node. In the next two steps, FT_Class-
2Table is applied to the class PremiumClient and to the class Client (in arbitrary
order). The sequence is terminating (no forward translation rule can be applied any-
more), but the result after applying this sequence is a triple graph where not all
translation attributes are set to true, i.e., not all source model elements have been
translated: the parent edge could not be translated (the result is a “misleading graph”
in the sense of Def. 8.14). In HenshinTGG, elements that could not be translated are
highlighted in red and reported as error message in a separate window, showing
the (partial) translation result (see Fig. 12.40). This allows the user to reason about
possible conﬂicts between rule applications. The reason why the parent edge was
not translated by the given forward translation sequence is a conﬂict between the

394
12 Tool Support
rule FT_Class2Table (applied to the class PremiumClient) and FT_SubClass2Table,
which could not be applied to the class PremiumClient after the application of the
rule FT_Class2Table.
In order to ensure completeness in the general case, the execution of model trans-
formations may require backtracking (not implemented in HenshinTGG). However,
as shown in Theorem 8.29, we get functional behaviour of the forward translation
(i.e., the translation yields complete and unique results) without backtracking if the
signiﬁcant critical pairs between forward translation rules extended by ﬁlter NACs
(see Def. 8.16) are strictly conﬂuent and the system is terminating.
In order to make use of Theorem 8.29, we have to 1) perform a critical pair
analysis on our set of forward translation rules to ﬁnd rules in need of ﬁlter NACs,
2) extend these rules by adding ﬁlter NACs according the procedure in Fact 8.19,
3) repeat steps 1) and 2) on the extended rule set until no more ﬁlter NACs are
necessary.
HenshinTGG implements a converter from triple rules in EMF Henshin to AGG,
which provides a critical pair analysis engine (see Sect. 12.1.4). Recall that a crit-
ical pair (see Def. 5.40) is a conﬂict between two rules in minimal context, and it
is signiﬁcant if the overlapping graph can be embedded in a possible intermediate
state of a model transformation sequence. In particular, it is not signiﬁcant if a frag-
ment in the source component cannot be embedded into a valid source model due to
language constraints.
Figure 12.41 shows the (only) critical pair between the rules FT_Class2Table
and FT_SubClass2Table as computed by the AGG critical pair analyser. In the view
at the bottom, the critical overlapping graph of both rules’ left-hand sides is shown,
and it is indicated that we have a change–use-attr conﬂict, since both rules want to
access and change the isTranslated attribute of the subclass. Note that this attribute
is not plainly visible like other attributes since it is added internally when generating
FT rules (see Fig. 12.38 and Fig. 12.39). Nevertheless, AGG treats isTranslated
attributes as normal attributes and hence ﬁnds a change–use-attribute conﬂict for
this attribute that both rules intend to change from false to true.
12.4.4 Performing Model Transformation in HenshinTGG
The conﬂict shown in Fig. 12.41 is a misleading graph according to Def. 8.14;
hence we add a ﬁlter NAC to the rule FT_Class2Table that forbids its application
to classes which have a parent class. Figure 12.42 shows the rule FT_Class2Table,
now extended by a ﬁlter NAC.
According to Fact 8.18, ﬁlter NACs can in principle be generated automati-
cally. Note, however, that the generation of ﬁlter NACs is not yet supported by
HenshinTGG. A new run of the critical pair analysis does not ﬁnd any more criti-
cal pairs. Hence, according to Theorem 8.29, our model transformation system has
functional behaviour, since it is conﬂuent and terminating (due to the "<tr>" tags,
all elements are translated only once).

12.4 Bidirectional EMF Model Transformation with HenshinTGG
395
Fig. 12.41 Critical pair between rules FT_Class2Table and FT_SubClass2Table computed by
AGG
Fig. 12.42 Rule FT_Class2Table with ﬁlter NAC (top)
HenshinTGG supports the automatic forward translation of a given source model
by oﬀering a button Execute Forward Translation in the toolbar of the EMF source
model to be translated. On pressing the button the forward translation rules are
executed in arbitrary order; conﬂuence of the transformation system guarantees a
unique result. The resulting target triple graph is shown in the same window as the
source model since the translation is performed in-place. Figure 12.43 shows the
target triple which is the result of translating the source model “TwoClasses”. In ad-
dition, the sequence of applied forward translation rules is shown to the modeller in
the message window. For debugging purposes, also single forward translation rule
applications can be executed, analogously as for triple rules.
Summarising, HenshinTGG extends the EMF Henshin engine by features based
on triple graph grammars (TGGs) used for bidirectional model transformation,
based on the formal deﬁnitions for TGGs from Chap. 7 (see also [Sch94, EEHP09,
HEGO10]) and supports conﬂict analysis via the converter to AGG. The explicit
marking of edges overcomes the restriction in [GHL12] that rules are required to
create at least one node. Recently, HenshinTGG has been extended to include also

396
12 Tool Support
Fig. 12.43 Result of the forward translation of the source model TwoClasses
the generation of rules for backward translation (BT), for consistency creation (CC),
and for model integration (IT). Furthermore, HenshinTGG supports the execution and
simulation of model synchronisation and integration operations on TGGs: forward
model transformation (=FT=>), backward model transformation (=BT=>), model
integration (=IT=), consistency checking (=CC=), state-based forward and back-
ward propagation (=S-fPpg=> , <=S-bPpg=), and delta-based forward and back-
ward propagation (=D-fPpg=>, <=D-bPpg=). HenshinTGG allows the user to man-
ually use the analysis and optimisations techniques presented in [HEGO10] in order
to improve eﬃciency. The automated generation of ﬁlter NACs [HEGO10] can be
implemented as a direct extension and is future work.
Recently, HenshinTGG has been used by the Luxembourg-based satellite operator
SES for developing the open-source software SPELL (Satellite Procedure Execu-
tion Language and Library), a standardised satellite control language [HGN+14].
The challenge was to convert existing control procedures from proprietary program-
ming languages to SPELL. Using HenshinTGG as model transformation engine to
automate this process guaranteed a high-quality translation through automatic con-
sistency testing.
HenshinTGG is available at GitHub (see http://de-tu-berlin-tfs.github.
io/Henshin-Editor/ and the WIKI manual of HenshinTGG https://github.
com/de-tu-berlin-tfs/Henshin-Editor/wiki for more information).
12.5 Related Tools
Tools Related to AGG 2.0
AGG is one of the standard graph transformation tools implementing the alge-
braic approach. Other graph transformation tools, such as Fujaba [Fuj07], Via-

12.5 Related Tools
397
Tra [VIA14], VMTS [VMT14], GrGen [GrG06], and Groove [Gro08], implement
diﬀerent kinds of graph transformation approaches. Some kinds of rule application
control structures are oﬀered by all of these tools, e.g., Fujaba uses story diagrams,
a kind of activity diagram. Groove also supports nested application conditions as
well as universal quantiﬁcation using amalgamation.
Concerning the veriﬁcation of graph transformation systems, VIATRA and
Groove concentrate on some kind of model checking, while AGG is the only tool
that consequently implements the theoretical results available for algebraic graph
transformation. These results are mainly concerned with conﬂict and dependency
detection of rules and static applicability checks for rule sequences.
Tools related to ActiGra
Our approach complements existing approaches that give a denotational semantics
to activity diagrams by formal models. This semantics is used for validation pur-
poses thereafter. For example, Eshuis [EW04] proposes a denotational semantics for
a restricted class of activity models by means of labeled transition systems. Model
checking is used to check properties. Störrle [Sto04] deﬁnes a denotational seman-
tics for the control ﬂow of UML 2.0 activity models including procedure calls by
means of Petri nets. The standard Petri net theory provides an analysis of properties
like reachability or deadlock-freeness. Both works stick to simple activities not fur-
ther reﬁned. In [EGSW07], business process models and web services are equipped
with a combined graph transformation semantics and consistency can be validated
by the model checker GROOVE. In contrast, we take integrated behaviour mod-
els and check for potential conﬂict and causality inconsistencies between activity-
specifying rules directly. Thus, our technique is not a “pushbutton” technique which
checks a temporal formula specifying a desired property, but oﬀers additional views
on activity models where users can conveniently investigate intended and unin-
tended conﬂicts and causalities between activities. Conﬂicts and causalities are not
just reported as such but reasons for consistencies and inconsistencies can also be
investigated in depth.
Fujaba [FNTZ98], VMTS23 and GReAT24 are graph transformation tools for
specifying and applying graph transformation rules along the control ﬂow speciﬁed
by activity models. However, controlled rule applications are not further validated
with regard to conﬂict and causality inconsistencies within these tools. Conﬂicts and
causalities of pairs of rule-speciﬁed activities have been considered in various appli-
cation contexts such as use case integration [HHT02], feature modelling [JWEG07],
model inconsistency detection [MSD06], and aspect-oriented modelling [MMT09].
Although sometimes embedded in explicit control ﬂow, it has not been taken into
account for inconsistency analysis. In the ActiGra approach, we analyse potential
23 Visual Modeling and Transformation System: http://vmts.aut.bme.hu/
24 Graph Rewriting and Transformation: http://www.isis.vanderbilt.edu/tools/great

398
12 Tool Support
conﬂict and causality inconsistencies between rule-speciﬁed activities w.r.t. the con-
trol ﬂow to specify their execution order.
Tools related to EMF Henshin
There are a number of model transformation engines which can modify mod-
els in EMF format, such as ATL [JK05], EWL [KPPR07], Tefkat [LS05b], VIA-
TRA2 [VB07], MOMENT [Bor07]. For ATL, a formal semantics based on Maude
has been introduced recently [TV10]. Formal semantics deﬁned in Maude for MO-
MENT and for ATL might be exploited for analyzing EMF model transformations.
None of these tool environments supports visual editing of control structures.
Graph transformation tools like PROGRES [SWZ99], AGG [AGG14], Fujaba
[FNTZ00] and MoTMoT [FOT10] feature visual editors which also support the
deﬁnition of control structures, e.g., by story diagrams in Fujaba, which were ex-
tended by implicit control in [MV08]. The tool GrGen.NET [GK08] also supports
the arbitrary nesting of application conditions but is based on a textual speciﬁca-
tion language. MoTMoT (Model-driven, Template-based, Model Transformer) is a
compiler from visual model transformations to repository manipulation code. The
compiler takes models conforming to a UML proﬁle for Story Driven Modelling
as input and outputs Java Metadata Interface (JMI) code. Control structures are
expressed by activity diagrams. Since the MoTMoT code generator is built using
AndroMDA, adding support for other repository platforms (like EMF) is possible
in principle and consists of adding a new set of code templates.
To the best of our knowledge, none of the existing EMF model transformation
approaches (whether based on graph transformation or not) support conﬂuence and
termination analysis of EMF model transformation rules yet. Here, the EMF Hen-
shin approach and tool environment serves as a bridge to make well-established tool
features and formal techniques for graph transformation available for model-driven
development based on EMF.
Tools related to HenshinTGG
General model transformation tools such as ATL [JABK08] and MOMENT2-
MT [MOM12] are usually used to perform in-place model transformations and do
not restrict the structure of transformation rules. Thus, they do not ensure TGG-
speciﬁc properties like preservation of source models [Sch94] and syntactical cor-
rectness and completeness [EEHP09]. Moreover, the forward and backward trans-
formations are manually speciﬁed and not generated from a single speciﬁcation.
While ATL and MOMENT2-MT use textual speciﬁcation techniques, graph trans-
formation tools like EMF Henshin (in-place) [ABJ+10] and Fujaba [Fuj07] oﬀer
the visual speciﬁcation of transformation rules, i.e., a form of visual programming
interface. The benchmarking framework in [ACG+14] provides means to compare
tools for bidirectional model transformations on an abstract level.

12.5 Related Tools
399
In addition to HenshinTGG, further TGG tools based on EMF are available
[LAS+14b, HLG+13]. The TGG interpreter [GK10] provides a feature to deﬁne
OCL expressions as rule conditions, while formal application conditions cannot
be speciﬁed. However, the formal results concerning correctness and complete-
ness [EEHP09] are not available for systems with OCL conditions. The TGG tools
MOTE (model transformation engine) [GW09] and eMoﬂon [ALPS11] perform a
compilation to the Fujaba tool suite [BGH+05, Fuj07] for the execution of model
transformations. While eMoﬂon supports the speciﬁcation of TGGs with negative
application conditions (NACs), this is not the case for MOTE. MOTE oﬀers certain
optimisation strategies concerning eﬃciency. Since correctness cannot be ensured
for all optimisations, the tool executes dynamic runtime checks to validate that a
model transformation sequence was executed correctly [GHL12]. Moreover, MOTE
uses a relaxed notion of correspondences for triple graphs, where correspondence
nodes may link an arbitrary number of source and target nodes [GHL12].
In order to improve eﬃciency of TGG tools, suitable static and dynamic con-
ditions have been studied that allow us to completely avoid backtracking. Klar et
al. [KLKS10] use a restricted class of TGGs for which they describe explicit dy-
namic conditions based on pre-checking contextual edges when translating a node.
Lauder et al. [LAVS12] leverage these restrictions on TGGs and introduce the no-
tion of precedence TGGs, where rules are required to form a partial order con-
cerning the execution. However, these conditions are not checked statically. Giese
et al. [GHL12] present eﬃciency conditions for a restricted class of TGGs, where
each forward rule has to translate at least one source node and may not be in conﬂict
with another rule via a critical pair. The ﬁrst condition excludes examples where the
translation of a single edge or attribute is handled separately by one rule [HEEO12],
and the second condition excludes the well-studied case study on the object rela-
tional mapping [EEHP09]. The tool was extended by a prototypical export [GHL12]
of so-called bookkeeping rules to AGG for conﬂict analysis, but it does not provide
reimport and evaluation. An overview of further possible improvements concerning
caching and reuse of existing structures for incremental model synchronisation is
studied in [LAS14a].

Appendix A
Basic Notions of Category Theory
In this appendix, we give a short summary of the categorical terms used throughout
this book based on [EEPT06]. We introduce categories, show how to construct them,
and present some basic constructions such as pushouts and pullbacks. In addition,
we give some speciﬁc categorical results which are needed for the main part of
the book. For a more detailed introduction to category theory, see [EM85, EM90,
AHS90, EMC+01].
A.1 Categories
In general, a category is a mathematical structure that has objects and morphisms,
with a composition operation on the morphisms and an identity morphism for each
object.
Deﬁnition A.1 (Category). A category C = (ObC, MorC, ◦, id) is deﬁned by
• a class ObC of objects;
• for each pair of objects A, B ∈ObC, a set MorC(A, B) of morphisms;
• for all objects A, B,C ∈ObC, a composition operation ◦(A,B,C) : MorC(B,C) ×
MorC(A, B) →MorC(A,C); and
• for each object A ∈ObC, an identity morphism idA ∈MorC(A, A),
such that the following conditions hold:
1. Associativity. For all objects A, B,C, D ∈ObC and morphisms f : A →B, g :
B →C and h : C →D, it holds that (h ◦g) ◦f = h ◦(g ◦f).
2. Identity. For all objects A, B ∈ObC and morphisms f : A →B, it holds that
f ◦idA = f and idB ◦f = f.
△
Remark A.2. Instead of f ∈MorC(A, B), we write f : A →B and leave out the
index for the composition operation, since it is clear which one to use. For such a
morphism f, A is called its domain and B its codomain.
△
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3
401

402
A Basic Notions of Category Theory
Example A.3. 1. The basic example of a category is the category Sets , with the
object class of all sets and with all functions f : A →B as morphisms. The
composition is deﬁned for f : A →B and g : B →C by (g ◦f)(x) = g(f(x)) for
all x ∈A, and the identity is the identical mapping idA : A →A : x 7→x.
2. The class of all graphs as objects and the class of all graph morphisms (as deﬁned
in Def. 2.1) form the category Graphs; the composition is given componentwise
and the identities are the pairwise identities on nodes and edges.
3. Typed graphs and typed graph morphisms (see Def. 2.2) form the category
GraphsTG.
△
A.2 Construction of Categories, and Duality
There are various ways to construct new categories from given ones. The ﬁrst way
that we describe here is the Cartesian product of two categories, which is deﬁned
by the Cartesian products of the class of objects and the sets of morphisms with
componentwise composition and identities.
Deﬁnition A.4 (Product category). Given two categories C and D, the product cat-
egory C × D is deﬁned by
• ObC×D = ObC × ObD;
• MorC×D((A, A′), (B, B′)) = MorC(A, B) × MorD(A′, B′);
• for morphisms f : A →B, g : B →C ∈MorC and f ′ : A′ →B′, g′ : B′ →C′ ∈
MorD, we deﬁne (g, g′) ◦(f, f ′) = (g ◦f, g′ ◦f ′);
• id(A,A′) = (idA, idA′).
△
Another construction is that of a slice or a coslice category. Here the objects are
morphisms of a category C, to or from a distinguished object X, respectively. The
morphisms are morphisms in C that connect the object morphisms so as to lead to
commutative diagrams.
Deﬁnition A.5 (Slice category). Given a category C and an object X ∈ObC, the
slice category C \X is deﬁned as follows:
• ObC\X = {f : A →X| A ∈ObC, f ∈MorC(A, X)};
• MorC\X(f : A →X, g : B →X) = {m : A →B| g ◦m = f};
A
B
C
X
n
m
f
g
h
• for morphisms m ∈MorC\X(f : A →X, g :
B →X) and n ∈MorC\X(g : B →X, h :
C →X), we have n ◦m as deﬁned in C for
m : A →B and n : B →C;
• idf:A→X = idA ∈MorC.
△
Example A.6. Given a type graph TG, the category GraphsTG can be considered
as the slice category Graphs\TG. Each typed graph is represented in this slice
category by its typing morphism, and the typed graph morphisms are exactly the
morphisms in the slice category.
△

A.3 Monomorphisms, Epimorphisms, and Isomorphisms
403
Deﬁnition A.7 (Coslice category). Given a category C and an object X ∈ObC, then
the coslice category X\C is deﬁned as follows:
• ObX\C = {f : X →A| A ∈ObC, f ∈MorC(X, A)};
• MorX\C( f : X →A, g : X →B) = {m : A →B| g = m ◦f};
A
B
C
X
n
m
f
g
h
• for morphisms m ∈MorX\C( f : X →A, g :
X →B) and n ∈MorX\C(g : X →B, h :
X →C), we have n ◦m as deﬁned in C for
m : A →B and n : B →C;
• id f:X→A = idA ∈MorC.
△
As the last construction in this section, we introduce the dual category. For the
dual category, we use the objects of a given category, but reverse all arrows, i.e.,
morphisms.
Deﬁnition A.8 (Dual category). Given a category C, the dual category Cop is de-
ﬁned by
• OBCop = ObC;
• MorCop(A, B) = MorC(B, A);
•
f ◦Cop g = g ◦C f for all f : A →B, g : B →C;
• idCop
A
= idC
A for all A ∈ObCop.
△
The duality principle asserts that for each construction (statement) there is a dual
construction. If a statement holds in all categories, then the dual statement holds in
all categories, too. Some examples of dual constructions are monomorphisms and
epimorphisms, pushouts and pullbacks, and initial and ﬁnal objects, which will be
described in the following sections.
A.3 Monomorphisms, Epimorphisms, and Isomorphisms
In this section, we consider a category C and analyse some important types of mor-
phisms, namely monomorphisms, epimorphisms, and isomorphisms.
Intuitively speaking, two objects are isomorphic if they have the same structure.
Morphisms that preserve this structure are called isomorphisms.
Deﬁnition A.9 (Isomorphism). A morphism i : A →B is called an isomorphism if
A
B
i−1
i
there exists a morphism i−1 : B →A such that i ◦i−1 = idB and
i−1 ◦i = idA.
Two objects A and B are isomorphic, written A  B, if there
is an isomorphism i : A →B.
△
Remark A.10. If i is an isomorphism, then i is both a monomorphism and an epi-
morphism. For every isomorphism i, the inverse morphism i−1 is unique.
△
Example A.11. • In Sets, Graphs, and GraphsTG, the isomorphisms are exactly
those morphisms that are (componentwise) injective and surjective.

404
A Basic Notions of Category Theory
• In product, slice, and coslice categories, the isomorphisms are exactly those mor-
phisms that are (componentwise) isomorphisms in the underlying category.
△
Deﬁnition A.12 (Monomorphism and epimorphism). Given a category C, a
A
B
C
f
g
m
morphism m : B →C is called a monomorphism
if, for all morphisms f, g : A →B ∈MorC, it
holds that m ◦f = m ◦g ⇒f = g.
A
B
C
f
g
e
A morphism e : A →B ∈MorC is called
an epimorphism if, for all morphisms f, g : B →
C ∈MorC, it holds that f ◦e = g◦e ⇒f = g.
△
Remark A.13. Monomorphisms and epimorphisms are dual notions, i.e., a mono-
morphism in a category C is an epimorphism in the dual category Cop, and vice
versa.
△
Fact A.14 (Monomorphisms and epimorphisms).
• In Sets, the monomorphisms are all injective mappings, and the epimorphisms
are all surjective mappings.
• In Graphs and GraphsTG, the monomorphisms and epimorphisms are exactly
those morphisms that are injective and surjective, respectively.
• In a slice category, the monomorphisms are exactly the monomorphisms of the
underlying category. The epimorphisms of the underlying category are epimor-
phisms in the slice category, but not necessarily vice versa.
• In a coslice category, the epimorphisms are exactly the epimorphisms of the un-
derlying category. The monomorphisms of the underlying category are monomor-
phisms in the slice category, but not necessarily vice versa.
△
In general, a factorisation of a morphism decomposes it into morphisms with spe-
cial properties. In an epi–mono factorisation, these morphisms are an epimorphism
and a monomorphism.
Deﬁnition A.15 (Epi–mono and (weak) E–M factorisations). Given a category C
A
B
C
f
e
m
and morphisms f : A →B, e : A →C, and m :
C →B with m◦e = f, if e is an epimorphism and
m is a monomorphism then e and m are called an
epi–mono factorisation of f:
If for every morphism f we can ﬁnd such
morphisms e and m, with f = m ◦e, and this decomposition is unique up to iso-
morphism, then the category C is said to have an epi–mono factorisation.
C has an E–M factorisation for given morphism classes E and M if for each
f there is a decomposition, unique up to isomorphism, f = m ◦e with e ∈E and
m ∈M. Usually E is a subclass of epimorphisms and M is a subclass of monomor-
phisms.
If we require only f = m ◦e with e ∈E and m ∈M, but not necessarily
uniqueness up to isomorphism, we have a weak E–M factorisation.
△

A.4 Pushouts and Pullbacks
405
The categories Sets, Graphs, and GraphsTG, have epi–mono factorisations.
Deﬁnition A.16 (Jointly epimorphic). A morphism pair (e1, e2) with ei : Ai →B
(i = 1, 2) is called jointly epimorphic if, for all g, h : B →C with g ◦ei = h ◦ei for
i = 1, 2, we have g = h.
△
In the categories Sets, Graphs, and GraphsTG, “jointly epimorphic” means
“jointly surjective”.
A.4 Pushouts and Pullbacks
Intuitively, a pushout is an object that emerges from gluing two objects along a
common subobject. In addition, we introduce the dual concept of a pullback and the
construction of both in speciﬁc categories.
Deﬁnition A.17 (Pushout). Given morphisms f : A →B and g : A →C ∈MorC,
a pushout (D, f ′, g′) over f and g is deﬁned by
A
B
C
D
X
f
g
k
h
f ′
g′
x
• a pushout object D and
• morphisms f ′ : C →D and g′ : B →D
with f ′ ◦g = g′ ◦f,
such that the following universal property is fulﬁlled:
for all objects X with morphisms h : B →X and k :
C →X with k ◦g = h ◦f, there is a unique morphism
x : D →X such that x ◦g′ = h and x ◦f ′ = k:
△
Remark A.18. The pushout object D is unique up to isomorphism. This means that
if (X, k, h) is also a pushout over f and g, then x : D
∼
−→X is an isomorphism with
x ◦g′ = h and x ◦f ′ = k. Vice versa, if (D, f ′, g′) is a pushout over f and g and
x : D
∼
−→X is an isomorphism, then (X, k, h) is also a pushout over f and g, where
k = x ◦f ′ and h = x ◦g′. Uniqueness up to isomorphism follows directly from the
corresponding universal properties (see Lem. A.21).
△
Fact A.19 (Pushout constructions).
1. In Sets, a pushout over morphisms f : A →B and g : A →C can be constructed
as follows. Let
∼f,g= t({(a1, a2) ∈A × A| f(a1) = f(a2) ∨g(a1) = g(a2)})
be the transitive closure of Kern(f) and Kern(g); ∼f,g is an equivalence relation.
We deﬁne the object D and the morphisms as:
• D = A|∼f,g
∪B\f(A)
∪C\g(A),
•
f ′ : C →D : x 7→
( [a]
:
∃a ∈A : g(a) = x
x
:
otherwise
,

406
A Basic Notions of Category Theory
• g′ : B →D : x 7→
([a]
:
∃a ∈A : f(a) = x
x
:
otherwise
.
2. In Graphs and GraphsTG, pushouts can be constructed componentwise in Sets.
3. If the categories C and D have pushouts, the pushouts in the product category
can be constructed componentwise.
4. If the category C has pushouts, the pushouts in the slice category C \X can be
constructed over the pushouts in C. Given objects f : A →X, g : B →X,
f : A →X
g : B →X
h : C →X
d : D →X
A
B
C
D
X
m
n
h
g
t
s
d
m
n
t
s
(2)
(1)
and h : C →X,
and morphisms m
and n in C \X as
in (1), it holds that
g ◦m = f = h ◦n
by the deﬁnition of
morphisms in C \X.
We construct the pushout (2) in C over C
n
←−A
m
−→B. From (2), we obtain the
induced morphism d : D →X as the pushout object, and morphisms s and t with
d ◦s = g and d ◦t = h, leading to the pushout (1) in C \X.
This construction works analogously for the coslice category X\C.
△
In various situations, we need a reverse construction of a pushout. This is called
the pushout complement.
Deﬁnition A.20 (Pushout complement). Given morphisms f : A →B and n :
B →D, A
g
−→C
m
−→D is the pushout complement of f and n if (D, m, n) is the
pushout over f and g.
△
Pushout squares can be decomposed if the ﬁrst square is a pushout, and can be
composed, preserving their pushout properties.
Lemma A.21 (Pushout composition and decomposition). Given the following
A
B
C
D
E
F
(2)
(1)
commutative diagram, the following hold:
• Pushout composition.
If (1) and (2) are pushouts,
then (1) + (2) is also a pushout.
• Pushout decomposition. If (1) and (1) + (2) are pushouts, then (2) is also a
pushout.
△
The dual construction of a pushout is a pullback. Pullbacks can be seen as a
generalised intersection of objects over a common object.
Deﬁnition A.22 (Pullback). Given morphisms f : C →D and g : B →D, a
pullback (A, f ′, g′) over f and g is deﬁned by

A.5 Binary Coproducts and Initial Objects
407
A
B
C
D
X
f
g
k
h
f ′
g′
x
• a pullback object A and
• morphisms f ′ : A →B and g′ : A →C
with g ◦f ′ = f ◦g′,
such that the following universal property is fulﬁlled:
for all objects X with morphisms h : X →B and k :
X →C, with f ◦k = g ◦h, there is a unique morphism
x : X →A such that f ′ ◦x = h and g′ ◦x = k:
△
Fact A.23 (Pullback constructions).
1. In Sets, the pullback C
πg
←−A
π f
−→B over morphisms f : C →D and g : B →D
is constructed by A = S
d∈D f −1(d) × g−1(d) with morphisms f ′ : A →B :
(x, y) 7→y and g′ : A →C : (x, y) 7→x.
2. In Graphs and GraphsTG, pullbacks can be constructed componentwise in Sets.
3. The category PTNets has pullbacks, but they cannot be constructed component-
wise (see [EEPT06]).
4. In a product, slice, or coslice category, the construction of pullbacks is dual to
the construction of pushouts if the underlying categories have pullbacks.
△
Pullback squares can be decomposed if the last square is a pushout, and can be
composed, preserving their pullback properties.
Lemma A.24 (Pullback composition and decomposition). Given the following
A
B
C
D
E
F
(2)
(1)
commutative diagram, the following hold:
• Pullback composition.
If (1) and (2) are pullbacks, then
(1) + (2) is also a pullback.
• Pullback decomposition. If (2) and (1) + (2) are pullbacks, then (1) is also a
pullback.
△
A.5 Binary Coproducts and Initial Objects
Binary coproducts can be seen as a generalisation of the disjoint union of sets and
graphs in a categorical framework. Analogously, initial objects are the categorical
representation of the empty set and the empty graph. Note, however, that the con-
struction of binary coproducts and initial objects of algebras is much more diﬃcult.
Deﬁnition A.25 (Binary coproduct). Given two objects A, B ∈ObC, the binary
coproduct (A + B, iA, iB) is given by
• a coproduct object A + B and
• morphisms iA : A →A + B and iB : B →A + B,

408
A Basic Notions of Category Theory
A
A + B
B
X
f
g
iA
iB
[f,g]
such that the following universal property is ful-
ﬁlled: for all objects X with morphisms f
:
A →X and g : B →X, there is a morphism
[ f, g] : A + B →X such that [ f, g] ◦iA = f and
[ f, g] ◦iB = g:
△
Remark A.26. Given two morphisms f : A →A′ and g : B →B′, there is a unique
A
A + B
B
A′
A′ + B′
B′
f
g
iA
iB
i′
A
i′
B
f+g
coproduct morphism f + g : A + B →A′ + B′,
induced by the binary coproduct A + B and the
morphisms iA′ ◦f and iB′ ◦g:
△
Example A.27. • In Sets, the coproduct object A + B is the disjoint union A
∪B of
A and B, and iA and iB are inclusions. For A ∩B = ∅, we use the representation
A
∪B = A ∪B, and for A ∩B , ∅, we use A
∪B = A × {1} ∪B × {2}.
• In Graphs and GraphsTG, the coproduct can be constructed componentwise in
Sets.
• In a product or slice category, coproducts can be constructed componentwise if
the underlying categories have coproducts.
• In a coslice category, the coproduct of objects f : X →A and g : X →B is
constructed as the pushout of f and g in the underlying category.
△
Deﬁnition A.28 (Initial object). In a category C, an object I is called initial if, for
each object A, there exists a unique morphism iA : I →A.
△
Example A.29. • In Sets, the initial object is the empty set.
• In Graphs and GraphsTG, the initial object is the empty graph.
• In a product category A × B, the initial object is the tuple (I1, I2), where I1, I2 are
the initial objects in A and B (if they exist).
• If C has an initial object I, the initial object in a slice category C \X is the unique
morphism I →X.
• In general, a coslice category has no initial object.
△
Remark A.30. The dual concept of an initial object is that of a ﬁnal object, i.e., an
object Z such that there exists a unique morphism zA : A →Z for each object A.
Each set Z with card(Z) = 1 is ﬁnal in Sets.
Initial objects are unique up to isomorphism.
△
A.6 Functors, Functor Categories, and Comma Categories
Functors are mappings between diﬀerent categories which are compatible with com-
position and the identities. Together with natural transformations, this leads to the
concept of functor categories. Another interesting construction for building new cat-
egories is that of comma categories.

A.6 Functors, Functor Categories, and Comma Categories
409
Deﬁnition A.31 (Functor). Given two categories C and D, a functor F : C →D is
given by F = (FOb, FMor), with
• a mapping FOb : ObC →ObD and
• a mapping FMor(A,B) : MorC(A, B) →MorD(FOb(A), FOb(B)) of the morphisms
for each pair of objects A, B ∈ObC,
such that the following apply:
1. For all morphisms f : A →B and g : B →C ∈MorC, it holds that F(g ◦f) =
F(g) ◦F(f).
2. For all objects A ∈ObC, it holds that F(idA) = idF(A).
△
Remark A.32. For simplicity, we have left out the indices and have written F(A) and
F( f) for both objects and morphisms.
△
To compare functors, natural transformations are used. Functors and natural
transformations form a category, called a functor category.
Deﬁnition A.33 (Natural transformation). Given two categories C and D and
F(A)
F(B)
G(A)
G(B)
αA
F( f)
αB
G(f)
functors F,G : C →D, a natural transformation α :
F ⇒G is a family of morphisms α = (αA)A∈ObC
with αA : F(A) →G(A) ∈MorD, such that, for
all morphisms f : A →B ∈MorC, it holds that
αB ◦F( f) = G( f) ◦αA:
△
Deﬁnition A.34 (Functor category). Given two categories C and D, the functor
category [C, D] is deﬁned by the class of all functors F : C →D as the objects,
and by natural transformations as the morphisms. The composition of the natural
transformations α : F ⇒G and β : G ⇒H is the componentwise composition
in D, which means that β ◦α = (βA ◦αA)A∈ObC, and the identities are given by the
identical natural transformations deﬁned componentwise over the identities idF(A) ∈
D.
△
Fact A.35 (Constructions in functor categories).
• In a functor category [C, D], natural transformations are monomorphisms, epi-
morphisms, and isomorphisms if they are componentwise monomorphisms, epi-
morphisms, and isomorphisms, respectively, in D.
• If the category D has pushouts, then pushouts can be constructed “pointwise” in
a functor category [C, D].
• The construction of pullbacks is dual to the construction of pushouts if the un-
derlying category D has pullbacks.
△
In the following, we deﬁne comma categories and show under what conditions
pushouts and pullbacks can be constructed.
Deﬁnition A.36 (Comma category). Given two functors F : A →C and G :
B →C and an index set I, the comma category ComCat(F, G; I) is deﬁned by the

410
A Basic Notions of Category Theory
F(A)
G(B)
F(A′)
G(B)
F(fA)
G(fB)
opi
op′
i
class of all triples (A, B, op), with A ∈ObA, B ∈ObB,
and op = [opi]i∈I, where opi ∈MorC(F(A),G(B)), as
objects; a morphism f : (A, B, op) →(A′, B′, op′) in
ComCat(F, G; I) is a pair f = ( fA : A →A′, fB : B →
B′) of morphisms in A and B such that G(fB) ◦opi =
op′
i ◦F( fA) for all i ∈I.
The composition of morphisms in ComCat(F, G; I) is deﬁned componentwise,
and identities are pairs of identities in the component categories A and B.
△
Remark A.37. The short notation (F,G) for ComCat(F, G; I), where |I| = 1, ex-
plains the name “comma category”.
Note that we have ComCat(F, G; ∅) = A × B.
△
Fact A.38 (Constructions in comma categories).
1. In a comma category ComCat(F, G; I) with F : A →C, G : B →C, and an
index set I, morphisms are monomorphisms, epimorphisms and isomorphisms
if they are componentwise monomorphisms, epimorphisms and isomorphisms,
respectively, in A and B.
2. If the categories A and B have pushouts and F preserves pushouts, then
ComCat(F, G; I) has pushouts, which can be constructed componentwise.
3. If the categories A and B have pullbacks and G preserves pullbacks, then
ComCat(F, G; I) has pullbacks, which can be constructed componentwise.
△
A.7 Isomorphism and Equivalence of Categories
In the following, we deﬁne the isomorphism and equivalence of categories.
Deﬁnition A.39 (Isomorphism of categories). Two categories C and D are called
isomorphic, written C  D, if there are functors F : C →D and G : D →C such
that G ◦F = IDC and F ◦G = IDD, where IDC and IDD are the identity functors
on C and D, respectively.
△
Remark A.40. Isomorphisms of categories can be considered as isomorphisms in
the “category of all categories” Cat, where the objects are all categories and the
morphisms are all functors. Note, however, that the collection of all categories is,
in general, no longer a “proper” class in the sense of axiomatic set theory. For this
reason, Cat is not a “proper” category.
△
Fact A.41 (Isomorphic categories). The category Graphs of graphs is isomorphic
to the functor category [S, Sets], where the “schema category” S is given by the
schema S : · ⇒·.
△
Deﬁnition A.42 (Equivalence of categories). Two categories C and D are called
equivalent, written C ≡D, if there are functors F : C →D and G : D →C
and natural transformations α : G ◦F ⇒IDC and β : F ◦G ⇒IDD that are

A.7 Isomorphism and Equivalence of Categories
411
componentwise isomorphisms, i.e., αA : G(F(A))
∼
−→A and βB : F(G(B))
∼
−→B
are isomorphisms for all A ∈C and B ∈D, respectively.
△
Remark A.43. If C and D are isomorphic or equivalent then all “categorical” prop-
erties of C are shared by D, and vice versa. If C and D are isomorphic, then we have
a bijection between objects and between morphisms of C and D. If they are only
equivalent, then there is only a bijection of the corresponding isomorphism classes
of objects and morphisms of C and D. However, the cardinalities of correspond-
ing isomorphism classes may be diﬀerent; for example all sets M with cardinality
|M| = n are represented by the set Mn = {0, . . . , n−1}. Taking the sets Mn (n ∈N) as
objects and all functions between these sets as morphisms, we obtain a category N,
which is equivalent—but not isomorphic—to the category FinSets of all ﬁnite sets
and functions between ﬁnite sets.
△

Appendix B
Proofs and Additional Properties for Parts II
and III
In this chapter, we present diﬀerent properties as well as some more technical proofs
for the results in Parts II and III.
B.1 Derived Properties of Limits and Colimits
In the following, we formulate and prove diﬀerent properties of diagrams concern-
ing pullbacks, pushouts, pushout complements, and colimits in M-adhesive cate-
gories where the additional HLR properties (see Def. 4.23) hold.
A
B
C
D
A
B
C′
D
C
m
n
f
g
m
n′
f ′
g
n
f
c
(1)
(2)
Lemma B.1. If (1) is a pushout,
(2) is a pullback, and n′ ∈M then
there exists a unique morphism
c : C′ →C such that c ◦f ′ = f,
n ◦c = n′, and c ∈M.
△
Proof. Since (2) is a pullback, n′ ∈M implies that m ∈M, and then also
n
∈
M because (1) is a pushout. Construct the pullback (3) with v, v′
∈
M, and since n′ ◦f
=
g ◦m
=
n ◦f there exists a unique morphism
f ∗: A →C′′ with v ◦f ∗= f ′ and v′ ◦f ∗= f. Now consider the following cube (4),
A
C′′
C′
C
D
A
C′′
A
C
A
C′
B
D
f ′
f ∗
f
v
n
v′
n′
f ∗
idA
idA
v
v′
f
m
f ′
m
n′
g
n
(3)
(4)
where
the
bottom face
is
pushout
(1), the back
left face is a
pullback be-
cause m
∈
M, the front
left face is
pullback (2), and the front right face is pullback (3). By pullback composition and
decomposition also the back right face is a pullback, and then the M-van Kampen
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3
413

414
B Proofs and Additional Properties for Parts II and III
A
C′′
A
C′′
f ∗
f ∗
idA
idC′′
(5)
property implies that the top face is a pushout. Since (5)
is a pushout and pushout objects are unique up to isomor-
phism this implies that v is an isomorphism and C′′  C′.
Now deﬁne c := v′ ◦v−1 : C →C′ and we have that
c ◦f ′ = v′ ◦v−1 ◦f ′ = v′ ◦f ∗= f, n ◦c = n ◦v′ ◦v−1 = n′,
and c ∈M by decomposition of M-morphisms.
⊓⊔
A
B
C
D
E
F
f
f ′
m
n
o
g
g′
(1)
(2)
Lemma B.2. If (1) + (2) is a pullback, (1) is a
pushout, (2) commutes, and o ∈M then also
(2) is a pullback.
△
Proof. With o ∈M, (1) + (2) a pullback,
A
B
B
C
D
E
F
f
b
f ′
m
n
o
g
g′
(4)
(3)
and (1) a pushout, we have that m, n ∈
M. Construct the pullback (3) of o and
g′; it follows that n ∈M and we get an
induced morphism b : B →B with g ◦
b = g, n ◦b = n, and by decomposition
of M-morphisms b ∈M.
A
C
B
D
B
m
n
b◦f
f ′
n
f
b
(4)
By pullback decomposition, also (4) is a pullback
and we can apply Lem. B.1 with pushout (1) and n ∈
M to obtain a unique morphism b ∈M with n ◦b = n
and b ◦b ◦f = f. Now n ∈M and n ◦b ◦b = n ◦b = n
implies that b ◦b = idB, and similarly n ∈M and
n ◦b ◦b = n ◦b = n implies that b ◦b = idB, which
means that B and B are isomorphic such that also (2) is a pullback.
⊓⊔
A′
B′
A
B
C′
D′
C
D
m′
a
f ′
g′
b
m
f
n′
c
n
g
d
Lemma B.3. Given the following com-
mutative cube with the bottom face as
a pushout, the front right face has a
pushout complement over g◦b if the back
left face has a pushout complement over
f ◦a.
△
Proof. Construct the initial pushout (1)
over f. Since the back left face has a pushout complement there is a morphism
A′
B′
A
B
C′
D′
C
D
Bf
C f
Bf
B
C f
D
m′
a
f ′
g′
b
m
f
n′
c
d
n
g
a f
bf
c f
b∗
m◦bf
n◦c f
af
g
(2)
(1)
b∗: Bf →A′ such
that a◦b∗= bf . The
bottom face being a
pushout implies that
(2) as the composi-
tion is the initial
pushout over g. Now
b ◦m′ ◦b∗= m ◦
a ◦b∗= m ◦bf , and
the pushout comple-
ment of g ◦b exists.
⊓⊔

B.1 Derived Properties of Limits and Colimits
415
A
B
C
D
E
F
m
n
f
f ′
o
g
g′
(1)
(2)
Lemma B.4. Given pullbacks (1) and (2) with
pushout complements over f ′ ◦m and g′ ◦n,
respectively, also (1) + (2) has a pushout com-
plement over (g′ ◦f ′) ◦m.
△
Proof. Let C′ and E′ be the pushout complements of (1) and (2), respectively. By
A
B
C
C′
D
E
E′
F
A
B
C′
C
D
E′
G
F
m
n
f
n∗
f ∗
f ′
o
g
o∗
g∗
g′
c
e
m
n∗
f ∗
f ′
g′
e
c
g∗
(1′)
(2′)
(1′)
(3)
(4)
Lem. B.1 there are mor-
phisms c and e such that
c ◦f
=
f ∗, n∗◦c =
n, e ◦g = g∗, and o∗◦
e = o. Now (2′) can be
decomposed into pushouts
(3) and (4), and (1′) + (4)
is also a pushout and the
pushout complement of (g′ ◦f ′) ◦m.
⊓⊔
Lemma B.5. Given the following pushouts (1i) and (3i) with bi ∈M for i = 1, . . . , n,
morphisms fij : Bi →C j with cj ◦fi j = di for all i , j, and the limit (2) of (cj) j=1,...,n
such that gi is the induced morphism into E using cj ◦fi j ◦bi = di ◦bi = ci ◦ai,
(4) is the colimit of (hi)i=1,...,n, where li is the induced morphism from pushout (3i)
compared with e ◦gi = ci ◦ei ◦gi = ci ◦ai = di ◦bi.
Ai
Ci
Bi
D
C j
Ai
E
Bi
Fi
D
Ai
E
C j
D
E
Fi
D
ai
bi
ci
di
fij
c j
gi
bi
hi
ki
di
li
e
ej
e
c j
i, j:fi j◦bi
i= j:ai
gi
ci◦ai
hi
li
e
(3i)
(1i)
(2)
(4)
△
Proof. We prove this by induction over n.
A1
C1
B1
D
C1
C1
D
C1
D
D
ai
bi
ci
di
ei
e
ci
hi
li
e
(11)
(2)
(41)
I.B. n = 1: For n = 1,
we have that C1 is the limit
of c1, i.e., E = C1; it fol-
lows that F1 = C1 for the
pushout (31) = (11), and
obviously (41) is a colimit.
I.S. n →n + 1: Consider the pushouts (1i) with bi ∈M for i = 1, . . . , n + 1,
morphisms fij : Bi →C j with c j ◦fi j = di for all i , j, the limits (2n) and (2n+1)
of (ci)i=1,...,n and (ci)i=1,...,n+1, respectively, leading to pullback (5n+1) by construction
of limits. Moreover, gin and gin+1 are the induced morphisms into En and En+1, re-
spectively, leading to pushouts (3in) and (3in+1). By induction hypothesis, (4n) is the
colimit of (hin)i=1,...,n, and we have to show that (4n+1) is the colimit of (hin+1)i=1,...,n+1.

416
B Proofs and Additional Properties for Parts II and III
Ai
Ci
Bi
D
En
Ci
D
Ai
En
Bi
Fin
En
Fin
D
En+1
Cn+1
En
D
En+1
Ci
D
Ai
En+1
Bi
Fin+1
En+1
Fin+1
D
ai
bi
ci
di
ein
en
ci
gin
bi
hin
kin
hin
lin
en
en+1n+1
pn+1
cn+1
en
ein+1
en+1
ci
gin+1
bi
hin+1
kin+1
hin+1
lin+1
en+1
(1i)
(2n)
(3in)
(4n)
(5n+1)
(2n+1)
(3in+1)
(4n+1)
Bn+1
En
Ci
D
fn+1i
dn+1
mn+1
ein
en
ci
(2n)
Since (2n) is a limit and ci ◦fn+1i = dn+1 for all i = 1, . . . , n,
we obtain a unique morphism mn+1 with ein ◦mn+1 = fn+1i and
en ◦mn+1 = dn+1. Since (1n+1) = (6n+1) + (5n+1) is a pushout
and (5n+1) is a pullback, by M-pushout–pullback decompo-
sition (see Def. 4.21) also (5n+1) and (6n+1) are pushouts,
and it follows that Fn+1n+1 = En. From pushout (3in+1) and
hin◦pn+1◦gin+1 = hin◦gin = kin◦bi we get an induced morphism
qin+1 with qin+1 ◦hin+1 = hin ◦pn+1 and qin+1 ◦kin+1 = kin, and
from pushout decomposition with (3in+1) + (7in+1) = (3in) also (7in+1) is a pushout.
An+1
En+1
Bn+1
En
Cn+1
D
Ai
En+1
Bi
Fin+1
En
Fin
gn+1n+1
bn+1
pn+1
mn+1
en+1n+1
cn+1
en
dn+1
an+1
gin+1
bi
hin+1
kin+1
pn+1
hin
qin+1
kin
gin
(6n+1)
(5n+1)
(3in+1)
(7in+1)
To show that (4n+1) is a colimit, consider an object X and morphisms (xi) and y
with xi ◦hin+1 = y for i = 1, . . . , n and xn+1 ◦pn+1 = y. From pushout (7in+1) we
obtain a unique morphism zi with zi ◦qin+1 = xi and zi ◦hin = xn+1. Now colimit (4n)
induces a unique morphism z with z◦en = xn+1 and z◦lin = zi. It follows directly that
z ◦lin+1 = z ◦lin ◦qin+1 = zi ◦qin+1 = xi and z ◦en+1 = z ◦en ◦pn+1 = xn+1 ◦pn+1 = y.
The uniqueness of z follows directly from the construction; thus (4n+1) is the re-
quired colimit.
En+1
En
Fin+1
D
X
En+1
En
Fin+1
Fin
X
En
Fin
D
X
pn+1
hin+1
lin+1
en en+1
xi
xn+1
z
y
pn+1
hin+1
hin
qin+1
xn+1
xi
zi
hin
lin
en
z
zi
xn+1
(7in+1)
(4n)
⊓⊔

B.1 Derived Properties of Limits and Colimits
417
Ai
C
Bi
Di
C
Di
E
+Ai
+Bi
C
E
Ai
+Ai
C
Bi
+Bi
E
ai
bi
ci
di
ci
c
ei
b
a
e
c
bi
b
iAi
iBi
e
a
ai
ei◦di
(1i)
(2)
(3)
=
=
=
Lemma B.6. Given the
diagrams (1i) for i
=
1, . . . , n, (2), and (3),
with b = +bi, and a and
e induced by the coprod-
ucts +Ai and +Bi, re-
spectively, we have:
1. If (1i) are pushouts and (2) a colimit then also (3) is a pushout.
2. If (3) is a pushout then we ﬁnd a decomposition into pushouts (1i) and colimit (2)
with ei ◦di = e ◦iBi.
△
Proof. 1. Given an object X and morphisms y, z with y ◦a = z ◦b. From pushout
(1i) we obtain with z ◦iBi ◦bi = z ◦b ◦iAi = y ◦a ◦iAi = y ◦ai a unique morphism xi
with xi ◦ci = y and xi ◦di = z ◦iBi. Now colimit (2) implies a unique morphism x
with x ◦c = y and x ◦ei = xi. It follows that x ◦e ◦iBi = x ◦ei ◦di = xi ◦di = z ◦iBi,
and since z is unique w. r. t. z ◦iBi it follows that z = x ◦e. Uniqueness of x follows
from the uniqueness of x and xi, and hence (3) is a pushout.
+Ai
+Bi
C
E
X
Ai
C
Bi
X
Di
C
Di
E
X
Bi
+Bi
Z
b
a
e
c
y
z
x
ai
bi
ci
di
z◦iBi
y
xi
ci
c
ei
y
x
xi
iBi
z
z◦iBi
(3)
(1i)
(2)
2. Deﬁne ai := a◦iAi. Now construct pushouts (1i). With e◦iBi ◦bi = e◦b◦iAi = c◦ai,
each pushout (1i) induces a unique morphism ei with ei ◦di = e ◦iBi and ei ◦ci = c.
Given an object X and morphisms y, yi with yi ◦ci = y, we obtain a morphism z with
z ◦iBi = yi ◦di from coproduct +Bi. Then we have that y ◦a ◦iAi = yi ◦ci ◦ai =
yi ◦di ◦bi = z ◦iBi ◦bi = z ◦b ◦iAi, and from coproduct +Ai it follows that
y ◦a = z ◦b. Now pushout (3) implies a unique morphism x with x ◦c = y and
x ◦e = z. From pushout (1i), using x ◦ei ◦di = x ◦e ◦iBi = z ◦iBi = yi ◦di and
x ◦ei ◦ci = x ◦c = y = yi ◦ci, it follows that x ◦ei = yi; thus (2) is a colimit.
Ai
C
Bi
E
Di
C
Di
E
X
Bi
+Bi
X
+Ai
+Bi
C
E
X
ai
bi
ci
di
e◦iBi
c
ei
ci
c
ei
y
x
yi
iBi
z
yi◦di
b
a
e
c
y
z
x
(1i)
(2)
(3)
⊓⊔

418
B Proofs and Additional Properties for Parts II and III
Ai
Bi
Ci
Di
A
B
C
D
fi
gi
hi
ki
f
g
h
k
(5i)
(10)
Lemma B.7. Given
colimits
(1)–(4)
such that (5i) is a pushout for all i =
1, . . . , n and (6k)–(9k) commute for all
k = 1, . . . , m, also (10) is a pushout.
Ai
Aj
A
Bi
Bj
B
Ci
C j
C
Di
Dj
D
Ai
Bi
Aj
Bj
Ai
Ci
Aj
C j
Bi
Di
Bj
Dj
Ci
Di
C j
Dj
ak
ai
aj
bk
bi
bj
ck
ci
c j
dk
di
dj
fi
ak
bk
f j
gi
ak
ck
gj
hi
bk
dk
hj
ki
ck
dk
k j
(1)
(2)
(3)
(4)
(6k)
(7k)
(8k)
(9k)
△
Proof. The morphisms f, g, h, and k are uniquely induced by the colimits. We show
this exemplarily for the morphism f: From colimit (1), with b j◦fj◦ak = bj◦bk◦fi =
bi ◦fi we obtain a unique morphism f with f ◦ai = bi ◦fi. It follows directly that
k ◦g = h ◦f.
Ai
Aj
A
B
A
B
C
D
X
Ai
Bi
Ci
Di
X
ak
ai
aj
bi◦fi
bj◦f j
f
f
g
h
k
z
y
x
fi
gi
hi
ki
z◦bi
y◦ci
xi
(1)
(10)
(5i)
Di
D j
D
X
Bi
Bj
B
X
bk
bi
bj
z◦bi
z◦bj
z
dk
di
dj
xi
xj
x
(4)
(2)
Now consider an object X and mor-
phisms y, z with y ◦g = z ◦f. From each
pushout (5i) with y ◦ci ◦gi = y ◦g ◦ai =
z ◦f ◦ai = z ◦bi ◦fi we obtain a unique
morphism xi with xi ◦ki = y ◦ci and
xi ◦hi = z ◦bi.
For all k = 1, . . . , m, xj ◦dk ◦ki = x j ◦
kj ◦ck = y◦c j ◦ck = y◦ci and x j ◦dk ◦hi =
xj ◦h j ◦bk = z ◦bj ◦bk = z ◦bi, and pushout (5i) implies that xi = x j ◦dk. This
means that colimit (4) implies a unique x with x ◦di = xi. Now consider colimit (2),
and x ◦h ◦bi = x ◦di ◦hi = xi ◦hi = z ◦bi implies that x ◦h = z. Similarly, x ◦k = y,
and the uniqueness follows from the uniqueness of x with respect to (4). Thus, (10)
is indeed a pushout.
⊓⊔

B.1 Derived Properties of Limits and Colimits
419
+Ai
+Bi
C
D
+fi
c
d
e
(5)
Lemma B.8. Consider colimits (1) and (2) such that (3i)
commutes for all i = 1, . . . , n, f is an epimorphism, and
(4) is a pushout with f induced by colimit (1). Then also (5)
is a pushout, where c and d are induced from the coprod-
ucts.
A
Ai
A
B
Bi
B
A
B
Ai
Bi
A
B
C
D
ai
a
ai
bi
b
bi
f
ai
bi
fi
f
c
d
e
(1)
(2)
(3i)
(4)
△
Proof. Since (1) is a colimit and bi ◦fi ◦ai = bi ◦bi ◦f = b ◦f, we actually get
A
Ai
A
B
ai
a
ai
b◦f
bi◦fi
f
(1)
an induced f with f ◦ai = bi ◦fi and f ◦a = b ◦f. From the
coproducts, we obtain induced morphisms c with c◦iAi = c◦ai
and d with d ◦iBi = d ◦bi. Moreover, for all i = 1, . . . , n we
have that d ◦(+fi) ◦iAi = d ◦iBi ◦fi = d ◦bi ◦fi = d ◦f ◦ai =
e ◦c ◦ai = e ◦c ◦iAi. Uniqueness of the induced coproduct
morphisms leads to d ◦(+fi) = e ◦c, i.e., (5) commutes.
We have to show that (5) is a pushout. Given morphisms x, y
with x◦c = y◦(+fi), we have that y◦iBi ◦bi◦f = y◦iBi ◦fi◦ai =
y ◦(+fi) ◦iAi ◦ai = x ◦c ◦iAi ◦ai = x ◦c ◦ai ◦ai = x ◦c ◦a for all i = 1, . . . , n.
Since f is an epimorphism we have that y ◦iBi ◦bi = y ◦iBj ◦bj for all i, j. Now
deﬁne y′ := y ◦iBi ◦bi, and from colimit (2) we obtain a unique morphism y with
y ◦bi = y ◦iBi and y ◦b = y′.
Ai
+Ai
C
Bi
+Bi
D
Ai
+Ai
Bi
+Bi
+Ai
+Bi
C
D
X
+fi
c
d
e
y
z
x
iBi
d◦bi
d
iAi
c◦ai
c
iAi
fi
+fi
iBi
(5)
Now x ◦c ◦ai = x ◦c ◦iAi = y ◦(+fi) ◦iAi = y ◦iBi ◦fi = y ◦bi ◦fi = y ◦f ◦ai
and x ◦c ◦a = x ◦c ◦ai ◦ai = y ◦f ◦i ◦ai = y ◦f ◦a, and the uniqueness of the
induced colimit morphism implies that y ◦f = x ◦c.
B
Bi
B
X
A
Ai
A
X
A
B
C
D
X
bi
b
bi
y′
y◦iBi
y
ai
a
ai
y◦f◦a
y◦f◦ai
y◦f
f
c
d
e
y
z
x
(2)
(1)
(4)

420
B Proofs and Additional Properties for Parts II and III
This means that X can be compared to pushout (4), and we obtain a unique mor-
phism z with z ◦d = y and z ◦e = x. Now z ◦d ◦iBi = z ◦d ◦bi = y ◦bi = y ◦iBi, and
it follows that z ◦d = y. Similarly, the uniqueness of z w. r. t. to the pushout property
of (5) follows; thus (5) is a pushout.
⊓⊔
B.2 Proofs for Sect. 4.4
B.2.1 Proof of Fact 4.36
Proof. The construction is always well deﬁned, since there is at least the trivial M-
subobject mi = idB with ei = f and at most ﬁnitely many M-subobjects. It follows
that mi ∈M and therefore also m ∈M, because M is closed under composition.
A
B
B′
B
f
e
m
e′
m′
mi
mi
It remains to show that e ∈E. Let e = m′ ◦e′
be a factorisation of e with m′ ∈M. Then we
have that m ◦m′ is an M-subobject of B and m ◦
m′ ◦e′ = f, and, hence, B′ = Bi, m ◦m′ = mi,
and e′ = ei for some i ∈I. This implies that there
exists mi : B →Bi = B′ with mi ◦mi = m. Now,
mi ◦mi ◦m′ = m ◦m′ = mi and since mi ∈M we have that mi is a monomorphism
which implies that mi ◦m′ = idB′. Similarly, m ◦m′ ◦mi = mi ◦mi = m and since
m ∈M we have that m is a monomorphism which implies that m′◦mi = idB. Hence,
m′ and mi are mutually inverse isomorphisms and e ∈E.
⊓⊔
B.2.2 Proof of Fact 4.38
Proof. For two extremal E–M factorisations m1 ◦e1 = m2 ◦e2 = f of a morphism
A
A
B1
B2
B
e1
m1
e2
m2
e
n1
n2
f : A →B, we construct a pullback over m1, m2 ∈M,
leading to morphisms n1, n2 ∈M. The universal
property of the pullback induces a unique morphism
e : A →A which, together with n1, n2, factors
e1, e2 ∈E. Since these are extremal, n1 and n2 are
isomorphisms and the two extremal E–M factorisa-
tions are isomorphic.
⊓⊔
B.2.3 Proof of Fact 4.40
Proof. We have to show that (1) is the initial pushout over m. The construction
is well-deﬁned, since I is ﬁnite by construction, and we have at least the trivial

B.3 Construction of M-Adhesive Categories
421
L
L
G
G
m
m
idL
idG
(4)
pushout (4) over m. Since ﬁnite M-intersections can be con-
structed by iterated pullbacks, we show by induction that (Qi)
and hence also (1) = (Qi) + (Pi) are pushouts.
I.B. For I = {1}, we have that (Q1) = (P1) = (1) = (4) by
construction.
I.S. Let I = {1, . . . , n + 1}. Now consider the M-intersections B1n and C1n for
pushouts (Pi)i=1,...,n, leading to the pushout in the front left face of the commutative
cube by the induction hypothesis. The top and bottom faces are pullbacks using the
B1n+1
Bn+1
C1n+1
Cn+1
B1n
L
C1n
G
un+1
a1n+1
bn+1
an+1
vn+1
b1n
a1n
m
c1n
cn+1
M-intersection construction. The right
front face is the pushout (Pn+1). Since
all horizontal morphisms are in M, us-
ing the cube pushout–pullback prop-
erty (see Theorem 4.22) it follows that
the back faces are pushouts. This
means, in particular, that (Qn+1) is a
pushout, and by pushout composition
so is (1).
B
L
B′ = Bi0
C
G
C′ = Ci0
b
c
b′
c′
a
m
a′
(1)
(1′)
(1) is initial, because every other pushout
(1′) over m with b′ ∈M is equal to (Pi0) for
some i0 ∈I. Hence, the initiality property
is given by the pushout (Qi0) as constructed
above.
⊓⊔
B.3 Construction of M-Adhesive Categories
To enhance ﬂexibility, we use an extension of comma categories [Pra07], where we
relax the restrictions on the domain of the functors compared to standard comma
categories, which allows us to adjust the category to describe diﬀerent operations
on the objects.
Deﬁnition B.9 (General comma category).
Given index sets I and J, cate-
gories Cj for j ∈J and Xi for i ∈I, and for each i ∈I two functors
Fi : Cki →Xi, Gi : Cℓi →Xi with ki, ℓi ∈J, the general comma category
GComCat((Cj)j∈J, (Fi,Gi)i∈I; I, J) is deﬁned by
Fi(Aki)
Gi(Aℓi)
Fi(A′
ki)
Gi(A′
ℓi)
Fi(hki)
Gi(hℓi)
opi
op′
i
• objects ((Aj ∈Cj) j∈J, (opi)i∈I), where opi : Fi(Aki)
→Gi(Aℓi) is a morphism in Xi,
• morphisms h : ((Aj), (opi)) →((A′
j), (op′
i)) as tu-
ples h = ((h j : Aj →A′
j)j∈J) such that for all i ∈I
we have that op′
i ◦Fi(hki) = Gi(hℓi) ◦opi.
△
A standard comma category is an instantiation of a general comma category.
Lemma B.10. A comma category A = ComCat(F : C →X,G : D →X, I) is a
special case of a general comma category.
△

422
B Proofs and Additional Properties for Parts II and III
Proof. With I as given, J = {1, 2}, C1 = C, C2 = D, Xi = X, Fi = F and Gi = G
for all i ∈I; the resulting general comma category is obviously isomorphic to A.
⊓⊔
Product, slice and coslice categories are special cases of comma categories.
Lemma B.11. For product, slice and coslice categories, we have the following iso-
morphic comma categories:
1. C × D  ComCat(!C : C →1, !D : D →1, ∅),
2. C\X  ComCat(idC : C →C, X : 1 →C, {1}) and
3. X\C  ComCat(X : 1 →C, idC : C →C, {1}),
where 1 is the ﬁnal category, !C : C →1 is the ﬁnal morphism from C, and X : 1 →
C maps 1 ∈1 to X ∈C.
△
Proof. This is obvious.
⊓⊔
In a general comma category, pushouts can be constructed componentwise in the
underlying categories if the domain functors of the operations preserve pushouts.
This is a generalisation of the corresponding result in [PEL08] for comma cate-
gories.
Lemma B.12. Consider a general comma category G
=
GComCat((Cj) j∈J,
(Fi,Gi)i∈I; I, J) based on M-adhesive categories (Cj, Mj), where Fi preserves
pushouts along Mki-morphisms.
Aj
Bj
C j
Dj
A
B
C
D
f
g′
g
f ′
f j
g′
j
gj
f ′
j
(1) j
(1)
For objects A = ((Aj), (opA
i )), B =
((Bj), (opB
i )), and C = ((C j), (opC
i )) ∈G
and morphisms f = (f j) : A →B,
g = (gj) : A →C with f ∈×j∈J Mj,
we have: The diagram (1) is a pushout
in G iﬀfor all j ∈J (1)j is a pushout
in Cj, with D = ((Dj), (opD
j )), f ′ = (f ′
j), and g′ = (g′
j).
△
Proof. “⇐” Given the morphisms f and g in (1), and the pushouts (1)j in Cj for
j ∈J. We have to show that (1) is a pushout in G.
Since Fi preserves pushouts along Mki-morphisms, with fki ∈Mki the diagram
(2)i is a pushout for all i ∈I. Then D = ((Dj), (opD
i )) is an object in G, where, for i ∈
I, opD
i is induced by pushout (2)i and Gi(f ′
ℓi)◦opC
i ◦Fi(gki) = Gi(f ′
ℓi)◦Gi(gℓi)◦opA
i =
Gi(g′
ℓi)◦Gi(fℓi)◦opA
i = Gi(g′
ℓi)◦opB
i ◦Fi(fki). It holds that opD
i ◦Fi(f ′
ki) = Gi(f ′
ℓi)◦opC
i
and opD
i ◦Fi(g′
ki) = Gi(g′
ℓi) ◦opB
i . Therefore f ′ = (f ′
j) and g′ = (g′
j) are morphisms
in G such that (1) commutes.
It remains to show that (1) is a pushout. Given an object X = ((Xj), (opX
i )) and
morphisms h = (hj) : B →X and k = (kj) : C →X in G such that h ◦f = k ◦g,
from pushouts (1)j we obtain unique morphisms x j : Dj →X j such that x j ◦g′
j = hj
and x j ◦f ′
j = k j for all j ∈J.

B.3 Construction of M-Adhesive Categories
423
Fi(Aki)
Fi(Bki)
Fi(Cki)
Fi(Dki)
Gi(Aℓi)
Gi(Bℓi)
Gi(Cℓi)
Gi(Dℓi)
Gi(Xℓi)
Fi(Xki)
Fi(fki)
Fi(g′
ki)
Fi(gki)
Fi(f ′
ki)
Gi(fℓi)
Gi(g′
ℓi)
Gi(gℓi)
Gi( f ′
ℓi)
opA
i
opB
i
opC
i
opD
i
Fi(hki)
Fi(kki)
Fi(xki)
Gi(hℓi)
Gi(kℓi)
Gi(xℓi)
opX
i
(2)i
Since (2)i is a pushout, from Gi(xℓi) ◦opD
i ◦Fi(g′
ki) = Gi(xℓi) ◦Gi(g′
ℓi) ◦opB
i =
Gi(hℓi) ◦opB
i = opX
i ◦F(hki) = opX
i ◦Fi(xki) ◦Fi(g′
ki) and Gi(xℓi) ◦opD
i ◦Fi(f ′
ki) =
Gi(xℓi) ◦Gi(f ′
ℓi) ◦opC
i = Gi(kℓi) ◦opC
i = opX
i ◦Fi(kℓi) = opX
i ◦Fi(xki) ◦Fi(f ′
ki) it
follows that Gi(xℓi) ◦opD
i = opX
i ◦Fi(xki). Therefore x = (xj) ∈G, and x is unique
with respect to x ◦g′ = h and x ◦f ′ = k.
“⇒” Given the pushout (1) in G we have to show that (1)j are pushouts in Cj
for all j ∈J. Since (Cj, Mj) is an M-adhesive category there exists a pushout (1′)j
over f j ∈Mj and g j in Cj.
Aj
Bj
C j
E j
A
B
C
E
f
g∗
g
f ∗
f j
g∗
j
gj
f ∗
j
(1′) j
(1′)
Therefore (using “⇐”) there is a cor-
responding pushout (1′) in G over f
and g with E = ((E j), (opE
i )), f ∗=
(f ∗
j ) and g∗= (g∗
j). Since pushouts are
unique up to isomorphism it follows
that E  D, which means E j  Dj and
therefore (1)j is a pushout in Cj for all j ∈J.
⊓⊔
We extend the Construction Theorem in [EEPT06] to general comma categories
and full subcategories. Basically, it holds that, under some consistency properties, if
the underlying categories are M-adhesive categories so are the constructed ones.
Theorem B.13 (Construction Theorem). If (C, M1), (D, M2), and (Cj, Mj) for
j ∈J are M-adhesive categories, then also the following categories are M-
adhesive categories:
1. the general comma category (G, (×j∈J Mj)∩MorG) with G = GComCat((Cj)j∈J,
(Fi,Gi)i∈I; I, J), where, for all i ∈I, Fi : Cki →Xi preserves pushouts along
Mki-morphisms and Gi : Cℓi →Xi preserves pullbacks along Mℓi-morphisms,
2. any full subcategory (C′, M1|C′) of C, where pushouts and pullbacks along M1
are created and reﬂected by the inclusion functor,

424
B Proofs and Additional Properties for Parts II and III
3. the comma category (F, (M1 × M2) ∩MorF), with F = ComCat(F,G; I), where
F : C →X preserves pushouts along M1-morphisms and G : D →X preserves
pullbacks along M2-morphisms,
4. the product category (C × D, M1 × M2),
5. the slice category (C\X, M1 ∩MorC\X),
6. the coslice category (X\C, M1 ∩MorX\C),
7. the functor category ([X, C], M1-functor transformations).
△
Proof. For the general comma category, it is easy to show that M is a class
of monomorphisms closed under isomorphisms, composition, and decomposition
since this holds for all components Mj.
Pushouts along M-morphisms are constructed componentwise in the underly-
ing categories as shown in Lem. B.12. The pushout object is the componentwise
pushout object, where the operations are uniquely deﬁned using the property that Fi
preserves pushouts along Mki morphisms.
Analogously, pullbacks along M-morphisms are constructed componentwise,
where the operations of the pullback object are uniquely deﬁned using the prop-
erty that Gi preserves pullbacks along Mℓi-morphisms.
The M-van Kampen property follows, since in a proper cube, all pushouts and
pullbacks can be decomposed, leading to proper cubes in the underlying categories,
where the M-van Kampen property holds. The subsequent recomposition yields the
M-van Kampen property for the general comma category.
For a full subcategory C′ of C deﬁne M′ = M1|C′. By reﬂection, pushouts and
pullbacks along M′-morphisms in C′ exist. Obviously, M′ is a class of monomor-
phisms with the required properties. Since we only restrict the objects and mor-
phisms, the M-van Kampen property is inherited from C.
As shown in Lemmas B.10 and B.11, product, slice, coslice, and comma cate-
gories are instantiations of general comma categories. Obviously, the ﬁnal category
1 is an M-adhesive category and the functors !C, !D, idC, and X preserve pushouts
and pullbacks. Thus, the proposition follows directly from the general comma cate-
gory for these constructions.
The proof for the functor category is explicitly given in [EEPT06].
⊓⊔
B.4 Proofs for Sect. 4.5
B.4.1 Proof of Fact 4.51
Proof. 1. If Cj has binary coproducts for all j ∈J and Fi preserves binary co-
products for all i ∈I, then the coproduct of two objects A = ((Aj), (opA
i )) and
B = ((Bj), (opB
i )) in G is the object A + B = ((Aj + Bj), (opA+B
i
)), where opA+B
i
is the unique morphism induced by Gi(iAℓi) ◦opA
i and Gi(iBℓi) ◦opB
i . If also Gi
preserves coproducts then opA+B
i
= opA
i + opB
i .

B.4 Proofs for Sect. 4.5
425
Fi(Aki)
Fi(Aki + Bki)
Fi(Bki)
Gi(Aℓi)
Gi(Aℓi + Bℓi)
Gi(Bℓi)
Fi(iAki )
Fi(iBki )
Gi(iAℓi )
Gi(iBℓi )
opA
i
opA+B
i
opB
i
2. If the inclusion functor reﬂects binary coproducts this is obvious.
I
A
B
A +I B
iA
iB
Otherwise, if we have an initial object I, given A, B ∈C′
we can construct the pushout over iA : I →A, iB : I →
B, which exists because iA, iB ∈M or due to general
pushouts. In this case, the pushout object is also the co-
product of A and B, because for any object in compari-
son to the coproduct the morphisms agree via iA and iB on I, and the constructed
pushout induces also the coproduct morphism.
3. This follows directly from Item 1, since the comma category is an instantia-
tion of general comma categories. The coproduct of objects (A1, A2, (opA
i )) and
(B1, B2, (opB
i )) of the comma category is the object A + B = (A1 + B1, A2 +
B2, opA+B
i
).
4. Since C × D  ComCat(!C : C →1, !D : D →1, ∅) (see Lem. B.11) and !C pre-
serves coproducts this follows from Item 3. The coproduct of objects (A1, A2) and
(B1, B2) of the product category is the componentwise coproduct (A1+B1, A2+B2)
in C and D, respectively.
A
A + B
B
X
a′
[a′,b′]
b′
5. Since C\X  ComCat(idC : C →C, X : 1 →
C, {1}) (see Lem. B.11) and idC preserves co-
products this follows from Item 3. In the slice
category, the coproduct of (A, a′) and (B, b′)
is the object (A + B, [a′, b′]) which consists of
the coproduct A+B in C together with the morphism [a′, b′] : A+B →X induced
by a′ and b′.
X
A
B
A +X B
b′
b
a′
a
6. If C has general pushouts, given two objects (A, a′) and
(B, b′) in X\C we construct the pushout over a′ and b′
in C. The coproduct of (A, a′) and (B, b′) is the pushout
object A +X B together with the coslice morphism b ◦
a′ = a ◦b′. For any object (C, c′) in comparison to the
coproduct, the coslice morphism c′ ensures that the morphisms agree via a′ and
b′ in X such that the pushout also induces the coproduct morphism.
7. If C has binary coproducts, the coproduct of two functors A, B : X →C in [X, C]
is the componentwise coproduct functor A + B with A + B(x) = A(x) + B(x) for
an object x ∈X and A + B(h) = A(h) + B(h) for a morphism h ∈X.
⊓⊔

426
B Proofs and Additional Properties for Parts II and III
B.4.2 Proof of Fact 4.54
Proof. 1. Given objects A = ((Aj), (opA
i )), B = ((Bj), (opB
i )), C = ((C j), (opC
i )), and
morphisms f = (f j) : A →C, g = (gj) : B →C in G, we have an E′
j–M′
j pair
factorisation ((ej, e′
j), mj) of fj, g j in Cj.
Fi(Bki)
Fi(Aki)
Fi(Kki)
Fi(Cki)
Gi(Bℓi)
Gi(Aℓi)
Gi(Kℓi)
Gi(Cℓi)
Fi(eki)
Fi(e′
ki)
Fi(mki)
Gi(eℓi)
Gi(e′
ℓi)
Gi(mℓi)
opB
i
opA
i
opK
i =Gi(mℓi)−1◦opC
i ◦Fi(mki)
opC
i
Fi(gki)
Gi(gℓi)
Fi(fki)
Gi(fℓi)
If Gi(mℓi) is an isomorphism, we have an object K = ((Kj), (opK
i = Gi(mℓi)−1 ◦
opC
i ◦Fi(mki))) in G. By deﬁnition, m = (mj) : K →C is a morphism in G. For
e = (ej) we have opK
i ◦Fi(eki) = Gi(mℓi)−1 ◦opC
i ◦Fi(mki) ◦Fi(eki) = Gi(mℓi)−1 ◦
opC
i ◦Fi(fki) = Gi(mℓi)−1 ◦Gi(fℓi) ◦opA
i = Gi(eℓi) ◦opA
i , and an analogous result
for e′ = (e′
j); therefore e and e′ are morphisms in G. This means that ((e, e′), m)
is an E′–M′ pair factorisation in G.
((Bj), (opB
i ))
((Aj), (opA
i ))
((Kj), (opK
i ))
((C j), (opC
i ))
((Lj), (opL
i ))
(e j)
(e′
j)
(n j)
(mj)
(dj)
(b j)
(aj)
To show the E′–M′ diagonal
property, we consider (e, e′) =
((ej), (e′
j)) ∈E′, m = (mj) ∈
M′, and morphisms a = (aj),
b = (bj), n = (nj) in G. Since
(ej, e′
j) ∈E′
j and mj ∈M′
j,
we get a unique morphism dj :
Kj →Lj in Cj with mj ◦dj = n j, dj ◦e j = a j, and dj ◦e′
j = b j.
Fi(Kki)
Fi(Lki)
Fi(Cki)
Gi(Kℓi)
Gi(Lℓi)
Gi(Cℓi)
Fi(dki)
Fi(mki)
Fi(nki)
Gi(dℓi)
Gi(mℓi)
Gi(nℓi)
opK
i
opL
i
opC
i
It remains to show that d = (dj) ∈
G, i.e., the compatibility with the
operations. For all i ∈I we have
that Gi(mℓi)◦opL
i ◦Fi(dki) = opC
i ◦
Fi(mki) ◦Fi(dki) = opC
i ◦Fi(nki) =
Gi(nℓi) ◦opK
i = Gi(mℓi) ◦Gi(dℓi) ◦
opK
i , and since Gi(mℓi) is an iso-
morphism it follows that opL
i ◦
Fi(dki) = Gi(dℓi)◦opK
i , i.e., d ∈G.
2. This is obvious.
3. This follows directly from Item 1, since any comma category is an instantiation
of a general comma category. For morphisms f = (f1, f2) and g = (g1, g2) in F
we construct the componentwise pair factorisations ((e1, e′
1), m1) of f1, g1 with
(e1, e′
1) ∈E′
1 and m1 ∈M′
1, and ((e2, e′
2), m2) of f2, g2 with (e2, e′
2) ∈E′
2 and
m2 ∈M′
2. This leads to morphisms e = (e1, e2), e′ = (e′
1, e′
2), and m = (m1, m2) in

B.4 Proofs for Sect. 4.5
427
F, and an E′–M′ pair factorisation with (e, e′) ∈E′ and m ∈M′. If the E′
1–M′
1
and the E′
2–M′
2 pair factorisations are strong then also E′–M′ is a strong pair
factorisation.
4. Since C × D  ComCat(!C : C →1, !D : D →1, ∅) (see Lem. B.11) and
!D(M′
2) ⊆{id1} = Isos this follows from Item 3. For morphisms f = (f1, f2)
and g = (g1, g2) in C × D we construct the componentwise pair factorisations
((e1, e′
1), m1) of f1, g1 with (e1, e′
1) ∈E′
1 and m1 ∈M′
1, and ((e2, e′
2), m2) of f2, g2
with (e2, e′
2) ∈E′
2 and m2 ∈M′
2. This leads to morphisms e = (e1, e2), e′ =
(e′
1, e′
2), and m = (m1, m2) in C×D, and an E′–M′ pair factorisation with (e, e′) ∈
E′ and m ∈M′. If the E′
1–M′
1 and the E′
2–M′
2 pair factorisations are strong then
also E′–M′ is a strong pair factorisation.
5. Since C\X  ComCat(idC : C →C, X : 1 →C, {1}) (see Lem. B.11) and
X(M′
2) ⊆X({id1}) = {idX} ⊆Isos this follows from Item 3. Given morphisms f
and g in C\X, an E′
1–M′
1 pair factorisation of f and g in C is also an E′
1–M′
1 of
f and g in C\X. If the E′
1–M′
1 pair factorisation is strong in C this is also true for
C\X.
6. Given morphisms f : (A, a′) →(C, c′) and g : (B, b′) →(C, c′) in X\C,
we have an E′
1–M′
1 pair factorisation ((e, e′), m) of f and g in C. This is a
pair factorisation in X\C if e ◦a′ = e′ ◦b′, because then (K, e ◦a′) and
(K, e′ ◦b′) is the same object in X\C. If m is a monomorphism, this follows
from m ◦e ◦a′ = f ◦a′ = c′ = g ◦b′ = m ◦e′ ◦b′.
(B, b′)
(A, a′)
(K, k′)
(C, c′)
(L, l′)
X
A
B
K
C
e
e′
n
m
d
b
a
a′
e
b′
e′
m
f
g
To prove that strongness is preserved we have to show the E′
1–M′
1 diagonal prop-
erty in X\C. Since it holds in C, given (e, e′) ∈E′, m ∈M′, and morphisms a, b, n
in X\C with n ◦e = m ◦a and n ◦e′ = m ◦b we get an induced unique d : K →L
with d◦e = a, d◦e′ = b, and m◦d = n from the diagonal property in C. It remains
to show that d is a valid morphism in X\C. Since m ◦d ◦k′ = n ◦k′ = c′ = m ◦l′
and m is a monomorphism it follows that d ◦k′ = l′ and thus d ∈X\C.
7. Given morphisms f = (f(x))x∈X and g = (g(x))x∈X in [X, C], we have an E′
1–M′
1
pair factorisation ((ex, e′
x), mx) with mx : Kx →C(x) of f(x), g(x) in C for all
(B(x)
A(x)
Kx
C(y)
Ky
ex e′
x
C(h)◦mx
my
Kh
e′
y◦B(h)
ey◦A(h)
x ∈X. We have to show that K(x) = Kx can
be extended to a functor and that e = (ex)x∈X,
e′ = (e′
x)x∈X, and m = (mx)x∈X are functor
transformations. For a morphism h : x →y
in X we use the E′
1–M′
1 diagonal property
in C with (ex, e′
x) ∈E′
1, my ∈M′
1 to deﬁne
Kh : Kx →Ky as the unique induced morphism with my ◦Kh = C(h) ◦mx,
Kh ◦ex = ey ◦A(h), and Kh ◦e′
x = e′
y ◦B(h).

428
B Proofs and Additional Properties for Parts II and III
Using the uniqueness property of the strong pair factorisation in C, we can show
that K with K(x) = Kx, K(h) = Kh is a functor and by construction e, e′, and m
are functor transformations. This means that (e, e′) ∈E′ and m ∈M′, i.e., this is
an E′–M′ pair factorisation of f and g.
B(x)
A(x)
Kx
C(x)
B(y)
A(y)
Ky
C(y)
ex
e′
x
mx
ey
e′
y
my
B(h)
A(h)
Kh
C(h)
g(x)
g(y)
f(x)
f(y)
The E′–M′ diagonal property can be shown as follows. Given (e, e′) ∈E′, m ∈
M′, and morphisms a, b, n in [X, C] from the E′
1–M′
1 diagonal property in C, we
obtain a unique morphism dx : K(x) →L(x) for x ∈X. It remains to show that
d = (dx)x∈X is a functor transformation, i.e., we have to show for all h : x →y ∈
X that L(h) ◦dx = dy ◦K(h).
B(x)
A(x)
K(x)
C(x)
L(x)
B(y)
A(y)
K(y)
C(y)
L(y)
e(x)
e′(x)
n(x)
m(x)
dx
b(x)
a(x)
e(y)
e′(y)
n(y)
m(y)
dy
b(y)
a(y)
A(h)
B(h)
K(h)
L(h)
C(h)
Because (e(x), e′(x)) ∈E′
1 and m(y) ∈M′
1, the E′
1–M′
1 diagonal property can
be applied. This means that there is a unique k : K(x) →L(y) with k ◦e(x) =
L(h) ◦a(x), k ◦e′(x) = L(h) ◦b(x), and m(y) ◦k = n(y) ◦K(h).
B(x)
A(x)
K(x)
C(y)
L(y)
e(x)
e′(x)
n(y)◦K(h)
m(y)
k
L(h)◦b(x)
L(h)◦a(x)
For L(h) ◦dx we have that L(h) ◦dx ◦e(x) =
L(h)◦a(x), L(h)◦dx◦e′(x) = L(h)◦b(x) and
m(y) ◦L(h) ◦dx = C(h) ◦m(x) ◦dx = C(h) ◦
n(x) = n(y) ◦K(h). Similarly, for dy ◦K(h)
we have that dy ◦K(h) ◦e(x) = dy ◦e(y) ◦
A(h) = a(y)◦A(h) = L(h)◦a(x), dy ◦K(h)◦
e′(x) = dy ◦e′(y) ◦B(h) = b(y) ◦B(h) =
L(h) ◦b(x), and m(y) ◦dy ◦K(h) = n(y) ◦K(h). Thus, from the uniqueness of k it
follows that k = L(h) ◦dx = dy ◦K(h) and d is a functor transformation.
⊓⊔

B.4 Proofs for Sect. 4.5
429
B.4.3 Proof of Fact 4.55
Proof. 1. Given f = (fj) : A →D ∈M′, we have initial pushouts (1)j over f j ∈M′
j
Bj
A j
C j
D j
bj
c j
a j
f j
(1)j
in Cj with bj, c j ∈M j. Since Gi(Mℓi) ⊆Isos, Gi(bℓi)−1
and Gi(cℓi)−1 exist. Deﬁne objects B = ((Bj), (opB
i
=
Gi(bℓi)−1 ◦opA
i ◦Fi(bki))) and C = ((C j), (opC
i = Gi(cℓi)−1 ◦
opD
i ◦Fi(cki)) in G. Then we have that
• Gi(bℓi) ◦opB
i
= Gi(bℓi) ◦Gi(bℓi)−1 ◦opA
i ◦Fi(bki) =
opA
i ◦Fi(bki),
• Gi(cℓi) ◦opC
i = Gi(cℓi) ◦Gi(cℓi)−1 ◦opD
i ◦Fi(cki) = opD
i ◦Fi(cki),
• Gi(cℓi) ◦Gi(aℓi) ◦opB
i = Gi(fℓi) ◦Gi(bℓi) ◦opB
i = Gi(fℓi) ◦opA
i ◦Fi(bki) =
opD
i ◦Fi(fki) ◦Fi(bki) = opD
i ◦Fi(cki) ◦Fi(aki) = Gi(cℓi) ◦opC
i ◦Fi(aki) and since
Gi(cℓi) is an isomorphism this implies that Gi(aℓi) ◦opB
i = opC
i ◦Fi(aki), which
means that a = (aj), b = (bj), and c = (cj) are morphisms in G with b, c ∈M′,
(1) is a valid square in G, and by Lem. B.12 also a pushout.
((Bj), (opB
i ))
((Aj), (opA
i ))
((C j), (opC
i ))
((Dj), (opD
i ))
((Aj), (opA
i ))
((E j), (opE
i ))
((Dj), (opD
i ))
((F j), (opF
i ))
b
c
a
f
d
e
f
g
(1)
(2)
It remains to show the initiality. For any pushout (2) in G with d = (dj), e =
(ej) ∈M, Lem. B.12 implies that the components (2)j are pushouts in Cj. The
initiality of pushout (1) j implies that there are unique morphisms b∗
j : Bj →E j
and c∗
j : C j →F j with dj ◦b∗
j = bj, ej ◦c∗
j = c j, and b∗
j, c∗
j ∈Mj such that (3) j is
a pushout.
Aj
E j
Dj
F j
Bj
E j
C j
F j
((Bj), (opB
i ))
((Aj), (opA
i ))
((E j), (opE
i ))
((F j), (opF
i ))
dj
ej
f j
gj
b∗
j
c∗
j
aj
gj
b∗
c∗
a
g
(2) j
(3) j
(3)
With Gi(dℓi) ◦Gi(b∗
ℓi) ◦opB
i = Gi(bℓi) ◦opB
i = opA
i ◦Fi(bki) = opA
i ◦Fi(dki) ◦
Fi(b∗
ki) = Gi(dℓi) ◦opE
i ◦Fi(b∗
ki) and Gi(dℓi) being an isomorphism it follows that
Gi(b∗
ℓi) ◦opB
i
= opE
i ◦Fi(b∗
ki) and therefore b∗= (b∗
j) ∈G, and analogously
c∗= (c∗
j) ∈G. This means that we have unique morphisms b∗, c∗∈M′ with
d ◦b∗= b and e ◦c∗= c, and by Lem. B.12 (3) composed of (3) j is a pushout.
Therefore (1) is the initial pushout over f in G.
2. This is obvious.
3. Since comma categories are an instantiation of general comma categories, this
follows directly from Item 1. The initial pushout of f = (f1, f2) : (A1, A2,
(opA
i )) →(D1, D2, (opD
i )) ∈M′
1 × M′
2 is the componentwise initial pushout in C
and D, with B = (B1, B2, (opB
i = G(b2)−1 ◦opA
i ◦F(b1))) and C = (C1,C2, (opC
i =
G(c1)−1 ◦opD
i ◦F(c1))).

430
B Proofs and Additional Properties for Parts II and III
4. Since C × D  ComCat(!C : C →1, !D : D →1, ∅) (see Lem. B.11), !C
preserves pushouts, and !D(M2) ⊆{id1} = Isos, this follows from Item 3. The
initial pushout (3) over a morphism (f1, f2) : (A1, A2) →(D1, D2) ∈M′
1 × M′
2 is
the componentwise product of the initial pushouts over f1 in C and f2 in D.
B
A
C
D
X
b
c
a
f
b′
c′
d′
a′
5. Since C\X  ComCat(idC : C →C, X : 1 →
C, {1}), idC preserves pushouts, and X(M2) =
X({id1}) = {idX} ⊆Isos, this follows from
Item 3. The initial pushout over f : (A, a′) →
(D, d′) ∈M′
1 in C\X is given by the initial
pushout over f in C, with objects (B, b′), (C, c′),
b′ = a′ ◦b, and c′ = d′ ◦c.
B
A
C
D
b
c
a
f
(1)
6. Given objects (A, a′) and (D, d′) and a morphism f : A →
D in X\C with f ∈M′
1, the initial pushout (1) over f in
C exists by assumption. For any pushout (2) in X\C with
d, e ∈M1, the corresponding diagram (3) is a pushout in
C. Since (1) is an initial pushout in C there exist unique
morphisms b∗: B →E and c∗: C →F such that d ◦b∗= b, e ◦c∗= c,
b∗, c∗∈M1, and (4) is a pushout in C.
(A, a′)
(E, e′)
(D, d′)
(F, f ′)
A
E
D
F
B
E
C
F
d
e
f
g
d
e
f
g
b∗
c∗
a
g
(2)
(3)
(4)
(i) If diagram (1) has a valid extension via morphisms b′ : X →B, c′ : X →C in
X\C, then this is also a pushout in X\C. With d ◦b∗◦b′ = b ◦b′ = a′ = d ◦e′
and d being a monomorphism it follows that b∗◦b = e′ and thus b∗∈X\C,
and analogously c∗∈X\C. This means that (4) is also a pushout in X\C.
(ii)If a′ : X →A ∈M1 and the pushout complement of f ◦a′ in C exists, we
can construct the unique pushout complement (5) in C, and the corresponding
diagram (6) is a pushout in X\C.
X
A
H
D
(X, idX)
(A, a′)
(H, h′)
(D, d′)
B
X
C
H
a′
h
h′
f
a′
h
h′
f
b∗
X
c∗
X
a
h′
(5)
(6)
(7)
It remains to show the initiality of (6). For any pushout (2), e′ : X →E is
unique with respect to d ◦e′ = a′ because d is a monomorphism. Since (1) is
an initial pushout in C and (5) is a pushout, there are morphisms b∗
X : B →X
and c∗
X : C →H such that b∗
X, c∗
X ∈M1, a′ ◦b∗
X = b, h ◦c∗
X = c, and (7) is a
pushout in C. With e ◦c∗◦a = c ◦a = h ◦c∗
X ◦a = h ◦h′ ◦b∗
X = f ◦a′ ◦b∗
X =
f ◦d ◦e′ ◦b∗
X = e ◦g ◦e′ ◦b∗
X and e being a monomorphism it follows that
c∗◦a = g ◦e′ ◦b∗
X.

B.4 Proofs for Sect. 4.5
431
B
X
A
E
C
H
D
F
X
E
H
F
b∗
X
a′
d
c∗
X
h
e
a
h′
f
g
b
e′
c
i
c∗
e′
i
h′
g
(7)
(5)
(3)
(8)
Pushout (7) implies that there is a unique i : H →F with c∗= i ◦c∗
X and
i ◦h′ = g ◦e′. It further follows that e ◦i = h using the pushout properties
of H. By pushout decomposition, (8) is a pushout in C and the corresponding
square in X\C is also a pushout. Therefore, (6) is an initial pushout over f in
X\C.
7. If C has intersections of M1-subobjects this means that given ci : Ci →D ∈M1
with i ∈I for some index set I the corresponding diagram has a limit (C, (c′
i :
C →Ci)i∈I, c : C →D) in C with ci ◦c′
i = c and c, c′
i ∈M1 for all i ∈I.
Let M denote the class of all M1-functor transformations. Given f : A →D ∈
M′, by assumption we can construct componentwise the initial pushout (1x) over
f(x) in C for all x ∈X, with b0(x), c0(x) ∈M1.
B0(x)
A(x)
C0(x)
D(x)
C0(x)
D(x)
Ci(x)
B
A
C
D
b0(x)
c0(x)
a0(x)
f(x)
c0(x)
d′
i(x)
ci(x)
b
c
a
f
(1)x
(2)
(3)
Deﬁne (C, (c′
i : C →Ci)i∈I, c : C →D) as the limit in [X, C] of all those ci :
Ci →D ∈M such that for all x ∈X there exists a d′
i(x) : C0(x) →Ci(X) ∈M1
with ci(x) ◦d′
i(x) = c0(x) (2), which deﬁnes the index set I. Limits in [X, C] are
constructed componentwise in C, and if C has intersections of M1-subobjects it
follows that also [X, C] has intersections of M-subobjects. Hence c, c′
i ∈M and
C(x) is the limit of ci(x) in C. Now we construct the pullback (3) over c ∈M and
f in [X, C], and since M-morphisms are closed under pullbacks also b ∈M.
B0(x)
B(x)
A(x)
C0(x)
C(x)
D(x)
Ci(x)
b′(x)
b(x)
c′(x)
c(x)
a0(x)
a(x)
f(x)
d′
i(x)
c′
i(x)
ci(x)
c0(x)
b0(x)
(4)x
(3)x
For x ∈X, C(x) being the limit of ci(x),
the family (d′
i(x))i∈I with (2) implies
that there is a unique morphism c′(x) :
C0(x) →C(x) with c′
i(x) ◦c′(x) = d′
i(x)
and c(x) ◦c′(x) = c0(x). Then (3)x is
a pullback and c(x) ◦c′(x) ◦a0(x) =
c0(x) ◦a0(x) = f(x) ◦b0(x) implies the
existence of a unique b′(x) : B0(x) →
B(x) with b(x) ◦b′(x)
=
b0(x) and
a(x)◦b′(x) = c′(x)◦a0(x). M1 is closed
under decomposition, b0(x) ∈M1, and b(x) ∈M1 implies that b′(x) ∈M1.
Since (1)x is a pushout, (3)x is a pullback, the whole diagram commutes, and
c(x), b′(x) ∈M1, the M1 pushout–pullback property implies that (3)x and (4)x

432
B Proofs and Additional Properties for Parts II and III
are both pushouts and pullbacks in C and hence (3) and (4) are both pushouts
and pullbacks in [X, C].
A
B1
D
C1
B0(x)
A(x)
B1(x)
C0(x)
D(x)
C1(x)
b1
c1
a1
f
b0(x)
b1(x)
c0(x)
c1(x)
a0(x)
a1(x)
f(x)
c∗
1(x)
b∗
1(x)
(5)
(1)x
(5)x
It remains to show the
initiality of (3) over f.
Given a pushout (5)
with b1, c1 ∈M in
[X, C], (5x) is a push-
out in C for all x ∈X.
Since (1x) is an initial
pushout in C, there ex-
ist morphisms b∗
1(x) : B0(x) →B1(x), c∗
1 : C0(x) →C1(x) with b∗
1(x), c∗
1(x) ∈
M1, b1(x) ◦b∗
1(x) = b0(x), and c1(x) ◦c∗
1(x) = c0(x). Hence c1(x) satisﬁes (2) for
i = 1 and d′
1(x) = c∗
1(x). This means that c1 is one of the morphisms the limit C
was built of and there is a morphism c′
1 : C →C1 with c1◦c′
1 = c by construction
of the limit C.
B
B1
A
C
C1
D
B
A
B1
C
D
C1
b′
1
b1
c′
1
c1
a
a1
f
c
b
b
b1
c
c
a
a1
f
c′
1
b′
1
(3)
(5)
(6)
(5)
Since (5) is a pushout along M-morphisms, it is also a pullback, and f ◦b = c◦a =
c1 ◦c′
1 ◦a implies that there exists a unique b′
1 : B →B1 with b1 ◦b′
1 = b and
a1 ◦b′
1 = c′
1 ◦a. By M-decomposition, also b′
1 ∈M. Now using also c1 ∈M, the
M pushout–pullback decomposition property implies that also (6) is a pushout,
which shows the initiality of (3).
⊓⊔
B.4.4 Proof of Fact 4.56
Proof. 1. As shown in Lem. B.12, pushouts over M-morphisms in the general
comma category are constructed componentwise in the underlying categories.
The induced morphism is constructed from the induced morphisms in the un-
derlying components. Since also pullbacks over M-morphisms are constructed
componentwise, the eﬀective pushout property of the categories (Cj, Mj) implies
this property in (G, M).
2. This is obvious.
3.–6. This follows directly from Item 1, because all these categories are instantia-
tions of general comma categories.
7. Pushouts and pullbacks over M-morphisms as well as the induced morphisms are
constructed pointwise in the functor category; thus the eﬀective pushout property
is directly induced.
⊓⊔

B.5 Proofs for Sect. 6.2
433
B.5 Proofs for Sect. 6.2
B.5.1 Proof of Fact 6.10
Proof. Consider the colimits ( ˜Ls, (ti,L)i=0,...,n) of (si,L)i=1,...,n, ( ˜Ks, (ti,K)i=0,...,n) of
(si,K)i=1,...,n, and ( ˜Rs, (ti,R)i=0,...,n) of (si,R)i=1,...,n, with t0,∗= ti,∗◦si,∗for ∗∈{L, K, R}.
Since ti,L◦li◦si,K = ti,L◦si,L◦l0 = t0,L◦l0, we get an induced morphism ˜ls : ˜Ks →˜Ls
with ˜ls ◦ti,K = ti,L ◦li for i = 0, . . . , n. Similarly, we obtain ˜rs : ˜Ks →˜Rs with
˜rs ◦ti,K = ti,R ◦ri for i = 0, . . . , n.
K0
Ki
˜Ks
˜Ls
K0
Ki
˜Ks
˜Rs
si,K
t0,K
ti,K
t0,L◦l0
ti,L◦li
˜ls
si,K
t0,K
ti,K
t0,R◦r0
ti,R◦ri
˜rs
The colimit of a bundle of n
morphisms can be constructed by
iterated
pushout
constructions,
which means that we only have
to require pushouts over M-mor-
phisms. Since pushouts are closed
under M-morphisms, the iterated
pushout construction leads to t ∈
M.
It remains to show that (14i) (and (14i) + (1i)) and (15i) (and (15i) + (2i)) are
pullbacks, and (14i) (and (14i) + (1i)) has a pushout complement for ti,L ◦li. We
prove this by induction over j for (14i) (and (14i) + (1i)), the pullback property of
Ki
˜Kj
Li
˜Lj
li
(16i j)
K0
L0
K1
˜K1
L1
˜L1
l0
s1,K
s1,L
l1
(1611)
(11)
(15i) follows analogously.
We prove: Let ˜L j and ˜Kj
be
the
colimits
of
(si,L)i=1,..., j and (si,K)i=1,...,j,
respectively. Then (16ij) is
a pullback with pushout complement property for all i = 0, . . . , j.
Basis j = 1: The colimits of s1,L and s1,K are L1 and K1, respectively, which
means that (1601) = (1) + (1611) and (1611) are both pushouts and pullbacks.
K0
Kj+1
L0
Lj+1
˜Kj
˜Kj+1
˜Lj
˜Lj+1
sj+1,K
l0
lj+1
sj+1,L
Induction step j →
j + 1: Con-
struct ˜Lj+1 = ˜L j +L0 L j+1 and ˜Kj+1 =
˜Kj +K0 Kj+1 as pushouts, and we have
the right cube with the top and bot-
tom faces as pushouts, the back faces
as pullbacks, and by the M-van Kam-
pen property also the front faces are
pullbacks. Moreover, by Lem. B.3 the
front faces have the pushout comple-
ment property, and by Lem. B.4 this also holds for (160j) and (16i j) as composi-
tions. Thus, for a given n, (16in) is the required pullback (14i) (and (14i) + (1i))
with pushout complement property, using ˜Kn =
˜Ks and ˜Ln =
˜Ls. Obviously,
˜acs = V
i=1,...,n Shift(ti,L, aci) ⇒Shift(ti,L, aci) for all i = 1, . . . , n, which completes
the ﬁrst part of the proof.

434
B Proofs and Additional Properties for Parts II and III
If ac0 and aci are complement-compatible we have that aci  Shift(si,L, ac0) ∧
L(p∗
i , Shift(vi, ac′
i)). Consider the pullback (17i), which is a pushout by M-push-
out–pullback decomposition and the uniqueness of pushout complements, and the
pushout (18i). For ac′
i, it holds that Shift(ti,L, L(p∗
i , Shift(vi, ac′
i))))  L( ˜p∗
s, Shift(˜ki ◦
vi, ac′
i))  L( ˜p∗
s, Shift(˜v, Shift(˜li, ac′
i))). Deﬁne ac∗
i := Shift(˜li, ac′
i) as an application
condition on ˜L0. It follows that ˜acs = V
i=1,...,n Shift(ti,L, aci)  V
i=1,...,n(Shift(ti,L ◦
si,L, ac0) ∧Shift(ti,L, L(p∗
i , Shift(vi, ac′
i))))  Shift(t0,L, ac0) ∧V
i=1,...,n L( ˜p∗
s, Shift(˜v,
ac∗
i )).
ac0
aci
˜acs
L0
K0
R0
Li
Li0
Ei
˜Ls
˜L0
˜E
p0 :
p∗
i :
˜p∗
s :
l0
r0
ui
vi
˜u
˜v
si,L
wi
ei1
ti,L
˜li
˜ki
(1′
i)
(3i)
(17i)
(18i)
For i
=
0 deﬁne ac′
s0
=
V
j=1,...,n ac∗
j, and hence
˜
acs

Shift(t0,L, ac0)
∧
L( ˜p∗
s, Shift(˜v,
ac′
s0)) implies the complement-
compatibility of ac0 and ˜acs. For
i > 0, we have that Shift(t0,L, ac0)∧
L( ˜p∗
s, Shift(˜v, ac∗
i ))

Shift(ti,L,
aci). Deﬁne ac′
si = V
j=1,...,n\i ac∗
j,
and hence
˜
acs  Shift(ti,L, aci) ∧L( ˜p∗
s, Shift(˜v, ac′
si)) implies the complement-
compatibility of aci and ˜acs.
⊓⊔
B.5.2 Proof of Fact 6.16
Proof. From Fact 6.8 it follows that each single direct transformation G =
pi,mi
===⇒Gi
can be decomposed into a transformation G =
p0,mi
0
===⇒Gi
0 =
pi,mi
===⇒Gi with mi
0 = mi ◦si,L
and, since the bundle is s-amalgamable, m0 = mi ◦si,L = mi
0 and G0 := Gi
0 for all
i = 1, . . . , n.
It remains to show the pairwise parallel independence. From the constructions
of the complement rule and the Concurrency Theorem we obtain the following dia-
gram for all i = 1, . . . , n.
L0
K0
S i
R0
Li
Ki
Ri
Li
Ki
Ki
Ri0
Li0
Li
Ei
Ri0
Ri
Ki
G
D0
G0
Di
Gi
Di
l0
si1
si3
li
ri
li
vi1
wi
ui
ui1
ei2
ui
vi
li
li0
ri0
ri
si,L
si,K
si4
ui2
li0
li
ui
ei2
wi
ti
mi
xi0
ki0
xi
ni
ki
fi
di0
di
gi
f0
g0
fi
gi
(1i)
(6i)
(7i)
(8i)
(9i)
(9i)
(13i)

B.5 Proofs for Sect. 6.2
435
For i , j, from weakly independent matches it follows that we have a morphism
pij : Li0 →Dj with f j◦pij = mi◦ui. It follows that f j◦pi j◦wi = mi◦ui◦wi = mi◦si,L◦
l0 = m0◦l0 = mj◦s j,L◦l0 = mj◦uj◦wj = mj◦u j◦l j0◦sj,K = m j◦l j◦sj,K = fj◦k j◦s j,K
and with f j ∈M we have that pi j ◦wi = kj ◦s jk (∗).
K0
S i
Li0
Li
Dj
si1
li0◦si,K
li◦si4
ui1
x j◦uj2◦si3
qi j
dj◦pi j
(19i)
Now consider the pushout (19i) = (6i)+(8i) in
comparison with object Dj and morphisms dj ◦
pij and x j ◦uj2 ◦si3. We have that d j ◦pi j ◦li0 ◦
si,K = dj◦pij◦wi
(∗)= dj◦k j◦sj,K = xj◦r j0◦s j,K =
xj◦wj◦v j1◦s j,K = x j◦uj2◦sj3◦sj1 = x j◦u j2◦r0 =
xj ◦u j2 ◦si3 ◦si1. Now pushout (19i) induces a
unique morphism qij with qij ◦ui1 = dj ◦pi j and
qij ◦li ◦si4 = xj ◦u j2 ◦si3.
For the parallel independence of G0 =
pi,mi
===⇒Gi, G0 =
pj,mj
===⇒G j, we have to show
that qij : Li →Dj satisﬁes fj ◦qi j = ki0 ◦ei2 =: mi.
With f0 ∈M and f0 ◦d j0 ◦pi j = f j ◦pi j = mi ◦ui = f0 ◦ci0 it follows that
dj0 ◦pij = xi0 (∗∗). This means that fj ◦qi j ◦ui1 = f j ◦dj ◦pi j = g0 ◦d0 ◦pi j
(∗∗)
=
g0 ◦xi0 = ki0 ◦ei2 ◦ui1. In addition, we have that fj ◦qi j ◦li ◦si4 = f j ◦xj ◦uj2 ◦si3 =
kj0◦uj◦uj2◦si3 = ki0◦ui◦ui2◦si3 = ki0◦ei2◦li◦si4. Since (19i) is a pushout we have
that ui1 and li ◦si4 are jointly epimorphic and it follows that f j ◦qi j ◦ei2 = ki0 ◦ei2.
If ac0 and aci are not complement-compatible then aci = true and trivially gj ◦
qij |= aci for all j , i. Otherwise, we have that gj ◦pi j |= ac′
i, and with gj ◦pi j =
gj ◦dj ◦pij = gj ◦qij ◦ui1 it follows that gj ◦qi j ◦ui1 |= ac′
i, which is equivalent to
gj ◦qij |= Shift(ui1, ac′
1) = aci.
⊓⊔
B.5.3 Proof of Theorem 6.17
Proof. 1. We have to show that ˜ps is applicable to G leading to an amalgamated
transformation G =
˜ps, ˜m
===⇒H with mi = ˜m ◦ti,L, where ti : pi →˜pi are the kernel
morphisms constructed in Fact 6.10. Then we can apply Fact 6.8, which implies
ac0
aci
˜acs
L0
K0
R0
Li
Ki
Ri
˜Ls
˜Ks
˜Rs
l0
r0
li
ri
si,L
si,K
si,R
˜ls
˜rs
ti,L
ti,K
ti,R
(1i)
(2i)
(14i)
(15i)
the decomposition of G =
˜ps, ˜m
===⇒H
into G =
pi,mi
===⇒Gi =
qi=⇒H, where qi is
the (weak) complement rule of the
kernel morphism ti.
Given the kernel morphisms, the
amalgamated rule, and the bundle
of direct transformations, we have
pullbacks (1i), (2i), (14i), (15i) and
pushouts (20i), (21i).
Using Fact 6.16, we know that we can apply p0 via m0, leading to a direct
transformation G =
p0,m0
===⇒G0 given by pushouts (200) and (210). Moreover, we

436
B Proofs and Additional Properties for Parts II and III
ﬁnd decompositions of pushouts (200) and (20i) into pushouts (1′
i) + (22i) and
(22i) + (23i) by M-pushout–pullback decomposition and uniqueness of pushout
complements.
L0
K0
Li
Li0
Ki
G
D0
Di
L0
K0
R0
G
D0
G0
Li
Ki
Ri
G
Di
Gi
li
ri
fi
gi
mi
ki
ni
(20i)
(21i)
l0
si,K
ui
li0
si,L
wi
f0
di0
mi
qi
ki
l0
r0
f0
g0
m0
k0
n0
(1′
i)
(22i)
(23i)
(200)
(210)
L0
Li
˜Ls
G
Kj
D
Di
D0
si,L
t0,L
ti,L
mi
m0
˜m
di0
d0
di
i,j:pji◦lj0
i=j:ki
q j◦lj0
rj
(a)
(b)
Since we have consistent matches, mi ◦
si,L = m0 for all i = 1, . . . , n. Then
the colimit ˜Ls implies that there is a
unique morphism ˜m : ˜Ls →G with
˜m◦ti,L = mi and ˜m◦t0,L = m0 (a). More-
over, mi |= aci ⇒˜m ◦ti,L |= aci ⇒˜m |=
Shift(ti,L, aci) for all i = 1, . . . , n, and
thus ˜m |= ˜acs = V
i=1,...,n Shift(ti,L, aci).
Weakly independent matches means that there exist morphisms pi j with f j◦pi j =
mi ◦ui for i , j. Construct D as the limit of (di0)i=1,...,n with morphisms di. Now
f0 is a monomorphism with f0 ◦di0 ◦p ji = fi ◦p ji = mj ◦u j = f0 ◦qj, which
implies that di0 ◦p ji = qj. It follows that di0 ◦p ji ◦l j0 = q j ◦l j0 and, together
with di0 ◦ki = qi ◦li0, limit D implies that there exists a unique morphism rj with
di ◦r j = pji ◦l ji, di ◦ri = ki, and d0 ◦rj = q j ◦lj0 (b).
K0
Ki
˜Ks
Dj
˜Ks
D
Di
D0
si,K
t0,K
ti,K
i,j:pi j◦li0
i=j:ki
kj◦sj,K
˜rj
di0
d0
di
˜ri
˜r
˜k
(c)
(d)
Similarly, f j is a monomorphism with
f j ◦pij ◦li0 ◦si,K = mi ◦ui ◦wi =
mi ◦si,L ◦l0 = m0 ◦l0 = mj ◦sj,L ◦l0 =
mj ◦l j ◦sj,K = f j ◦kj ◦sj,K, which
implies that pij ◦li0 ◦si,K = kj ◦s j,K.
Now colimit ˜Ks implies that there is a
unique morphism ˜rj with ˜r j◦ti,K = pi j◦
li0, ˜r j ◦tj,K = kj, and ˜rj ◦t0,K = k j ◦s j,K
(c). Since di0 ◦˜ri ◦ti,K = di0 ◦ki = qi ◦li0 = d j0 ◦pi j ◦li0 = dj0 ◦˜r j ◦ti,K and
di0 ◦˜ri ◦t0,K = di0 ◦ki ◦si,K = k0 = d j0 ◦˜rj ◦t0,K, colimit ˜Ks implies that for all
i, j we have that di0 ◦˜ri = d j0 ◦˜rj =: ˜r. From limit D it now follows that there
exists a unique morphism ˜k with di ◦˜k = ˜ri and d0 ◦˜k = ˜r (d).
We have to show that (20s) with f = f0 ◦d0 is a pushout. With f ◦˜k ◦ti,K =
f0 ◦d0 ◦˜k ◦ti,K = f0 ◦˜r ◦ti,K = f0 ◦di0 ◦˜ri ◦ti,K = f0 ◦di0 ◦ki = fi ◦ki =
mi ◦li = ˜m ◦ti,L ◦li = ˜m ◦˜ls ◦ti,K, f ◦˜k ◦t0,K = f0 ◦d0 ◦˜k ◦t0,K = f0˜r ◦t0,K =
f0 ◦di0 ◦˜ri ◦t0,K = f0 ◦di0 ◦ki ◦si,K = f0 ◦k0 = m0 ◦l0 = ˜m◦t0,L ◦l0 = ˜m◦˜ls ◦t0,K,
and ˜Ks as colimit, it follows that f ◦˜k = ˜m ◦˜ls, thus the square commutes.

B.5 Proofs for Sect. 6.2
437
Ls
Ks
G
D
Ki
D
Li0
Pi
Di
D0
+Ki
+Li0
D
D0
˜ls
f
˜m
˜k
ri
xi0
li0
xi
di
yi0
di0
+li0
d0
r
d
(20s)
(24i)
(25i)
(25)
Pushout (23i) can be decomposed into pushouts (24i) and (25i). Using Lem. B.5
it follows that D0 is the colimit of (xi)i=1,...,n, because (23i) is a pushout, D is the
limit of (di0)i=1,...,n, and we have morphisms pi j with dj0◦pi j = qi. Then Lem. B.6
implies that also (25) is a pushout.
K0
K0
+Ki
+Li0
˜Ks
˜L0
K0
K0
D
D0
D
D0
+li0
r
d
˜k
d0
idD
idD0
d0
. . .
iKi◦si,K
. . .
iLi0◦wi
. . .
˜k◦t0,K
. . .
k0
K0
K0
K0
˜Ks
L0
˜L0
˜Ks
˜Ls
K0
K0
K0
D
L0
D0
D
G
˜ls
˜k
f
˜m
Now consider the coequalisers
˜Ks of (iKi ◦si,K
:
K0
→
+Ki)i=1,...,n (which is actually ˜Ks
by construction of colimits), ˜L0
of (iLi0 ◦wi : K0 →+Li0)i=1,...,n
(as
already
constructed
in
Fact 6.10), D of (˜k ◦t0,K : K0 →
D)i=1,...,n, and D0 of (k0 : K0 →
D0)i=1,...,n.
In the right cube, the top square
with identical morphisms is a
pushout, the top cube com-
mutes, and the middle square is
pushout (25). Using Lem. B.7
it follows that also the bottom
face (26) constructed of the four
coequalisers is a pushout.
In the cube below, the top and
middle squares are pushouts
and the two top cubes commute.
Using again Lem. B.7 it follows
that (20s) in the bottom face is
actually a pushout, where (27) = (1′
i) + (17i) is a pushout by composition.
Now we can construct pushout (21s), which completes the direct transforma-
tion G =
˜ps, ˜m
===⇒H.
˜Ks
˜L0
D
D0
K0
˜L0
L0
˜Ls
˜Ls
G
˜Ks
˜Rs
D
H
d0
˜k
t0,K
l0
˜ls
˜rs
f
g
˜m
˜k
˜n
(27)
(20s)
(21s)
(26)
2. Using the kernel morphisms ti we obtain transformations G =
pi,mi
===⇒Gi =
qi=⇒H from
Fact 6.8 with mi = ˜m ◦ti,L. We have to show that this bundle of transformations
is s-amalgamable. Applying again Fact 6.8 we obtain transformations G =
p0,mi
0
===⇒

438
B Proofs and Additional Properties for Parts II and III
Gi
0 =
pi=⇒Gi with mi
0 = mi ◦si,L. It follows that mi
0 = mi ◦si,L = ˜m ◦ti,L ◦si,L =
˜m ◦t0,L = ˜m ◦t j,L ◦s j,L = mj ◦s j,L and thus we have consistent matches with
m0 := mi
0 well deﬁned and G0 = Gi
0.
˜Ks
˜L0
˜Ls
K0
L0
D
D0
G
l0
˜u
d0
f0
k
t0,L
˜m
(26)
(28)
(27)
It remains to show the weakly indepen-
dent matches. Given the above transforma-
tions we have pushouts (200), (20i), (20s)
as above. Then we can ﬁnd decomposi-
tions of (200) and (20s) into pushouts (27) +
(28) and (26) + (28), respectively. Using
pushout (26) and Lem. B.8 it follows that
(25) is a pushout, since ˜Ks is the colimit of
(si,L)i=1,...,n, ˜L0 is the colimit of (wi)i=1,...,n, and idK0 is obviously an epimorphism.
Now Lem. B.6 implies that there is a decomposition into pushouts (24i) with
colimit D0 of (xi)i=1,...,n and pushout (25i) by M-pushout–pullback decompo-
sition. Since D0 is the colimit of (xi)i=1,...,n and (25j) is a pushout it follows
that Dj is the colimit of (xi)i=1,...,j−1, j+1,...,n with morphisms qi j : Pi →Dj and
dj0 ◦qij = yi0. Thus we obtain for all i , j a morphism pi j = qi j ◦xi0 and
f j ◦pij = f0 ◦d j0 ◦qij ◦xi0 = f0 ◦yi0 ◦xi0 = mi ◦ui.
K0
Li0
Pi
D0
Ki
D
Di
L0
Li
G
Pj
D0
D
Dj
Pi
Li0
wi
ri
di
xi0
yi0
si,L
mi
l0
li0
ui
xi
di0
f0
xj
dj
y j0
dj0
xi
qi j
xi0
yi0
(1′
i)
(24i)
(25i)
(25 j)
3. Because of the uniqueness of the used constructions, the above constructions are
inverse to each other up to isomorphism.
⊓⊔
B.5.4 Proof of Theorem 6.24
Proof. “if”: If G =
˜ps, ˜m
===⇒H and G =
˜ps′, ˜m′
====⇒H′ are parallel amalgamation independent
deﬁne rij = d′
j◦˜rs◦ti,L and r′
ji = di◦˜rs′ ◦t′
j,L. It follows that fi◦r′
ji = fi◦di◦˜rs′ ◦t′
j,L =
f ◦˜rs′ ◦t′
j,L = ˜m′ ◦t′
j,L = m′
j, f ′
j ◦ri j = f ′
j ◦d′
j ◦˜rs ◦ti,L = f ′ ◦˜rs ◦ti,L = ˜m ◦ti,L = mi,
and by precondition we have that gi ◦di ◦˜rs′ |= Shift(tj,L, ac′
j), which means that
gi ◦di ◦˜rs′ ◦t′
j,L = gi ◦r′
ji |= ac′
j. Similarly, g′
j ◦d′
j ◦˜rs |= Shift(ti,L, aci) implies that
g′
j ◦d′
j ◦˜rs ◦ti,L = g′
j ◦rij |= aci. This means that G =
pi,mi
===⇒Gi and G =
p′
j,m′
j
===⇒G′
j are
pairwise parallel independent for all i, j.
The induced morphisms ˜rs : ˜Ls →D′ and ˜rs′ : ˜Ls′ →D are exactly the mor-
phisms ˜rs and ˜rs′ given by parallel independence with g′ ◦˜rs |= ˜acs and g◦˜rs′ |= ˜acs′.

B.6 Proofs for Chap. 7
439
This means that (G =
pi,mi
===⇒Gi)i=1,...,n and (G =
p′
j,m′
j
===⇒G′
j) j=1,...,n′ are parallel bundle in-
dependent.
“only if”: Suppose (G =
pi,mi
===⇒Gi)i=1,...,n and (G =
p′
j,m′
j
===⇒G′
j)j=1,...,n′ are parallel bun-
dle independent. We have to show that the morphisms ˜rs and ˜rs′ actually exist. D is
the limit of (di0)i=1,...,n as already constructed in the proof of Theorem 6.17. f0 is an
M-morphism, and f0 ◦di0 ◦r′
ji = fi ◦r′
ji = mi = ˜m◦ti,L = mk = fk ◦r′
jk = f0 ◦dk0 ◦r′
jk
implies that di0 ◦r′
ji = dk0 ◦r′
jk =: r′
j0 for all i, k. Now the limit D implies that there
exists a unique morphism r′
js such that di ◦r′
js = r′
ji and d0 ◦r′
js = r′
j0 (a).
Lj
D
Di
D0
L′
0
L′
j
˜Ls′
D
s′
j,L
t′
0,L
t′
j,L
r′
js
r′
0s
˜rs′
di0
d0
di
r′
ji
r′
j0
r′
js
(a)
(b)
Similarly, M-morphism fi and fi ◦r′
ji ◦
sj,L = m′
j◦s j,L = m′
0 = m′
k◦s′
k,L = fi◦r′
ki◦s′
k,L
imply that r′
ji ◦s′
j,L = r′
ki ◦s′
k,L for all i, k. It
follows that di ◦r′
js ◦s j,L = r′
ji ◦s′
j,L = r′
ki ◦
s′
k,L = di ◦r′
ks ◦s′
k,L, and with M-morphism
di we have that r′
js ◦s j,L = r′
ks ◦sk,L =: r′
0s.
From colimit ˜Ls′ we obtain a morphism ˜rs′
with ˜rs′ ◦t′
j,L = r′
j,s and ˜rs′ ◦t′
0,L = r′
0,s (b).
It follows that f ◦˜rs′ ◦t′
0,L = fi ◦di ◦r′
0s =
fi ◦di ◦r′
js ◦s′
j,L = fi ◦r′
ji ◦s′
j,L = m′
j ◦sj,L = m′
0 = ˜m′ ◦t0,L and f ◦˜rs′ ◦tj,L =
fi ◦di ◦r′
js = fi ◦r′
ji = m′
j = ˜m′ ◦t′
j,L. The colimit property of ˜Ls′ implies now that
f ◦˜rs′ = ˜m′. Similarly, we obtain the required morphism ˜rs with f ′ ◦˜rs = ˜m.
Since we have already required that g ◦˜rs′ |= ˜acs′ and g′ ◦˜rs |= ˜acs, this means
that G =
˜ps, ˜m
===⇒H and G =
˜ps′, ˜m′
====⇒H′ are parallel independent. Moreover, from the
pairwise independence we know that gi ◦r′
ji = gi ◦di ◦r′
js = gi ◦di ◦˜rs′ ◦t′
j,L |= ac′
j,
which implies that gi ◦di ◦˜rs′ |= Shift(t′
j,Lac′
j). Similarly, g′
j ◦ri j |= aci implies that
g′
j ◦d′
j ◦˜rs |= Shift(ti,L, aci), which leads to parallel amalgamation independence of
the amalgamated transformations.
⊓⊔
B.6 Proofs for Chap. 7
In this section, we provide proofs for Lem. 7.9 and Facts 7.36 and 7.52 in Chap. 7.
B.6.1 Proof for Lem. 7.9
Proof. We show the result in two steps, starting with the data component (data nodes
VD and algebra D) and then handling the graph component (nodes V, edges E, at-
tribution edges ENA, EEA). Let us consider an application condition ac = ∃(L →
P, ∨i∈I ∃(P →Ci, true)). The result for application conditions with more nesting
structures and Boolean operators follows by induction while simpler conditions can
be equivalently represented using identities as morphisms.

440
B Proofs and Additional Properties for Parts II and III
Data component: Let us consider one element of the disjunction of the shift con-
struction. We derive the morphisms depicted in the commuting diagrams (3), (4)
below. Note that the vertical morphism VLS
D →VL
D is an identity by the deﬁnition
of toS (see Fig. 7.1). The further vertical morphisms are M-morphisms by the shift
construction, and thus isomorphisms on the data component. Note that the mapping
for the data nodes is induced by the mapping for the algebra (fVD(x) = fD(x)). With-
out loss of generality, we assume that the isomorphisms are identities as depicted
in diagrams (3D), (4D) for the data component. Moreover, we can create diagrams
(1), (2) for the original application condition, where Fig. 7.1 ensures that the vertical
morphisms are identities. By commutativity of (1D) and (2D) and neutrality of iden-
tities we derive that a = aS and ai = ai,S on the data component. By commutativity
of (3D) and (4D) and neutrality of identities we derive that aS = a′ and ai,S = a′
i on
the data component. Thus, a = a′ and ai = a′
i on the data component and we can
conclude that ac coincides with ac′ on the data component.
Ci
(2)
P
o
ai
o
L
o
a
o
Ci,S

c′
i 
(4)
O
ci,S
O
PS
o
ai,S
o

p′

(3)
O
pS
O
(1)
LS
o
aS
o
j 
Oj
O
C′
i
P′
a′
i
o
L
a′
o
VCi
D
(2D)
VP
D
o
ai
o
VL
D
o
a
o
VCi,S
D
id 
(4D)
O
id
O
VPS
D
o
ai,S
o

id 
(3D)
(1D)
O
id
O
VLS
D
o
aS
o

id 
O
id
O
V
C′
i
D
VP′
D
a′
i
o
VL
D
a′
o
Graph component: We derive diagrams (1), (2) below by the deﬁnition of toS (see
Fig. 7.1) and diagrams (3), (4) by the shift construction using the general assumption
that the application condition of the triple rule contains almost injective morphisms
only. We now consider each triple component and derive diagrams (1S )–(4S ) for the
source component, (1C)–(4C) for the correspondence component and (1T)–(4T) for
the target component.
Ci
(2)
P
o
ai
o
L
o
a
o
Ci,S

c′
i 
(4)
O
ci,S
O
PS
o
ai,S
o

p′

(3)
O
pS
O
(1)
LS
o
aS
o
j 
Oj
O
C′
i
P′
a′
i
o
L
a′
o
CS
i
(2S )
PS
o
aS
i
o
LS
o
aS
o
CS
i

c′S
i 
(4S )
id O
PS
o
aS
i
o

p′S 
(3S )
id
O
(1S )
LS
o
aS
o
id 
id
O
C′S
i
P′S
a′
i
o
LS
a′S
o
LC
(2C)
LC
o
id
o
LC
o
id
o
∅

∅
(4C)
∅
O
∅
o
id
o

∅
(3C)
∅
O
(1C)
∅
o
id
o
∅
∅
O
C′C
i
P′C
a′C
i
o
LC
a′C
o
LT
(2T)
LT
o
id
o
LT
o
id
o
∅

∅
(4T)
∅
O
∅
o
id
o

∅
(3T)
∅
O
(1T)
∅
o
id
o
∅
∅
O
C′T
i
P′T
a′C
i
o
LT
a′T
o
Source component: Note that p′S is injective and the morphism pair (p′S , a′S ) in
diagram (3S ) is jointly surjective due to the shift construction and jS = id is an iso-

B.6 Proofs for Chap. 7
441
morphism. This implies that p′S is an isomorphism. For diagram (4S ) we can apply
the same arguments and derive that c′S
i is an isomorphism. Therefore, we derive that
ac  ac′ on the source component for the graph component.
Correspondence component: We inspect the derived diagrams (1C)–(4C). Recall
that ac is an S -application condition, such that the C- and T-components consist of
identities (idC
L). The shift construction yields a disjunction with several solutions for
diagrams (3C) and (4C) (jointly surjective). One solution for diagram (3C) is given
by (1C) and one solution for diagram (4C) is given by (2C). Let m: L →G be a
match satisfying ac, i.e., we have M-morphims qC : PC = LC →GC and qC
i : CC
i =
LC →GC. Since (1C) and (2C) are solutions for (3C) and (4C) as explained above,
we know that morphisms qC and qC
i are compatible with m, such that m |= ac′. Vice
versa, let m: L →G be a match satisfying ac′, i.e., we have one sequence (L →
P′ →C′
i) of the disjunction by the shift construction and M-morphims qC : P′C →
GC, q′C
i : C′C
i
→GC compatible with m and (a′, a′
i). If a′C would not be injective, we
could conclude the contradiction that q′C ◦a′C , mC. Therefore, q′C is injective and
since a′C is surjective ((∅, a′C) is jointly surjective), we can conclude that a′C is an
isomorphism. Therefore, P′C  PC and we can obtain an isomorphism isoP : PC →
P′C, such that qC = q′C ◦isoP ∈M is compatible with mC. Since m |= ac′ we
have that q′C ◦a′C = mC and q′C
i ◦a′C
i
= q′C. If a′C
i
would not be injective, we could
conclude the contradiction q′C
i ◦a′C
i
, q′C. Therefore, q′C
i is injective and since a′C
i is
surjective ((∅, a′C
i ) is jointly surjective), we can conclude that a′C
i is an isomorphism.
Therefore, C′C
i
 CC
i and we can obtain an isomorphism isoC,i : CC
i →C′C
i , such
that qC
i = q′C
i
◦isoC,i ∈M is compatible with qC. Therefore, ac |= m. Combining
both cases we have that ac ≡ac on the correspondence component for the graph
component.
For the target component, we can perform the same steps as for the correpon-
dence component and derive that ac ≡ac′ on the target component for the graph
component. Thus, ac ≡ac′ for the graph component. Together with the proof for
the data component above, we derive that ac ≡ac′.
⊓⊔
In order to prove Fact 7.36, we use Def. B.14 and Lem. B.15 below concern-
ing the equivalence of single transformation steps using the on-the-ﬂy construc-
tion of model transformations based on forward rules presented in [EEHP09]. In
this context, forward sequences are constructed with an on-the-ﬂy check for partial
source consistency. Partial source consistency requires that the constructed forward
sequence G0 =
tr∗
F
==⇒Gk be partially match consistent, meaning that for each interme-
diate forward step Gk−1 =
trk,F
==⇒Gk the compatibility with the corresponding source
step Gk−1,0 =
trk,S
==⇒Gk,0 of the simultaneously created source sequence G00 =
tr∗
S=⇒Gk,0
be checked. Compatibility requires that the forward match mk,F be forward consis-
tent, which means that the co-match nk,S of the source step and the match mk,F of
the forward step coincide on the source component with respect to the inclusion
Gk−1,0 ,→G0 ,→Gk−1. The formal condition of a forward consistent match is given
in Def. B.14 by a pullback diagram where both matches satisfy the corresponding
NACs, and, intuitively, it speciﬁes that the eﬀective elements of the forward rule are
matched for the ﬁrst time in the forward sequence.

442
B Proofs and Additional Properties for Parts II and III
Deﬁnition B.14 (Forward-consistent match). Given a partially match-consistent
Ln,S  
/
mn,S 
Rn,S  
/ Ln,F
(1)
mn,F

Gn−1,0 
gn−1/ G0 
/ Gn−1
sequence ∅= G00 =
tr∗
S=⇒Gn−1,0 ,−
gn−→G0 =
tr∗
F=⇒Gn−1,
a match mn,F : Ln,F →Gn−1 for trn,F : Ln,F →
Rn,F is called forward-consistent if there is a source
match mn,S such that diagram (1) is a pullback and
the matches mn,F and mn,S satisfy the corresponding
target and source NACs, respectively.
△
Lemma B.15 (Forward translation step without ACs). Let TR be a set of triple
rules without ACs with tri ∈TR, and let TRF, TRFT be the derived sets of forward
and forward translation rules, repectively. Given a partially match consistent for-
ward sequence ∅= G00 =
tr∗
S=⇒Gi−1,0 ,−
gi−1
−−→G0 =
tr∗
F=⇒Gi−1 and a corresponding for-
ward translation sequence G′
0 =
tr∗
FT
==⇒G′
i−1, both with almost injective matches, such
that G′
i−1 = Gi−1 ⊕AttF
G0\Gi−1,0 ⊕AttT
Gi−1,0, the following are equivalent:
1. There is a TGT step Gi−1 =
tri,F,mi,F
=====⇒Gi with forward consistent match mi,F
2. There is a forward translation TGT step G′
i−1 =
tri,FT,mi,FT
=======⇒G′
i
and we have G′
i = Gi ⊕AttF
G0\Gi,0 ⊕AttT
Gi,0.
△
Proof. For simpler notation we assume w.l.o.g. that rule morphisms are inclusions
and matches are inclusions except for the data value component.
Constructions:
1. TGT step Gi−1 =
trF
==⇒Gi with forward consistent match is given by
Li,S  
tri,S
/
mi,S 
Ri,S
ni,S

(1)
 
/ Li,F
(2)
mi,F 
 
tri,F
/ Ri,F
ni,F

(3)
Gi−1,0 
ti,S
/ Gi,0 
gi
/ G0 
/ Gi−1 
ti,F
/ Gi
where (1) and (3) are pushouts and pullbacks, (2) commutes, and since mi,F is for-
ward consistent we have by Def. B.14 that (2) and therefore also (1+2) is a pullback.
(1 + 2) is a pullback
⇔mi,F(Li,F) ∩Gi−1,0 = mi,F(Li,S )
⇒mi,F(Li,F \ Li,S ) ∩Gi−1,0 = ∅.
2. Translation TGT step G′
i−1 =
tri,FT ,mi,FT
=======⇒G′
iis given by (PO1), (PO2)
Li,FT

(PO1)
Ki,FT

o
/
(PO2)
Ri,FT

G′
i−1
D′
i−1
o
/ G′
i
Li,FT = Li,F ⊕AttT
Li,S ⊕AttF
Ri,S \Li,S
Ki,FT = Li,F ⊕AttT
Li,S
Ri,FT = Ri,F ⊕AttT
Li,S ⊕AttT
Ri,S \Li,S = Ri,F ⊕AttT
Ri,S

B.6 Proofs for Chap. 7
443
Direction 1. ⇒2. : We construct (PO1), (PO2) as follows from diagrams (1)–(3):
Li,F ⊕AttT
Li,S ⊕AttF
Ri,S \Li,S
mi,F

(PO1)


Li,F ⊕AttT
Li,S
mi,F

(PO2)

trFT /
o
Ri,F ⊕AttT
Ri,S
ni,F


Gi−1 ⊕AttT
Gi−1,0 ⊕AttF
G0\Gi−1,0
Gi−1 ⊕AttT
Gi−1,0
⊕AttF
G0\Gi,0
/
o
Gi ⊕AttT
Gi,0
⊕AttF
G0\Gi,0
The match mi,FT is constructed as follows:
mi,FT(x) =

mi,F(x),
x ∈Li,F
tr_mi,F(y),
x = tr_y, srcLFT(x) = y
tr_mi,F(y)_a, x = tr_y_a, srcLFT(x) = y
The match mi,F is injective except for the data value nodes. For this reason, the
match mi,FT is an almost injective match, i.e., possibly noninjective on the data val-
ues.
Li,F

(0)
Li,F

id
o
/
(3)
Ri,F

Gi−1
Gi−1
id
o
/ Gi
Pushouts (PO1), (PO2) are equivalent
to pushouts (0), (3) without translation
attributes. Thus, the additional transla-
tion attributes are not involved in these
pushouts.
We now consider the translation attributes. Let Ei,0 = (G0 \Gi−1,0)\(ni,S (Ri,S \Li,S )),
constructed componentwise on the sets of nodes and edges. This implies that Ei,0 is
a family of sets and not necessarily a graph, because some edges could be dangling.
However, we only need to show the pushout properties for these sets, because the
boundary nodes and context are handled properly in pushouts (0), (3) earlier and
the translation attribute edges for the items in Ei,0 are derived uniquely according to
Def. 7.26. Thus, we have the following pushouts for the translation attributes:
Li,S

POT
1
Li,S
o

Gi−1,0
Gi−1,0
o
(Ri,S \ Li,S )

POF
1
∅
o

(G0 \ Gi−1,0)
Ei,0
o
Li,S
/

POT
2
Ri,S

Gi−1,0
/ Gi,0
∅
/

POF
2
∅

Ei,0
/ Ei,0
Pushout (POT
1 ) is a trivial pushout, (POF
1) is pushout by the deﬁnition of Ei,0,
(POT
2 ) is a pushout by (1) and (POF
2) is a trivial pushout. Using pushout (1)
for the source step we have Gi,0 = Gi−1,0 ∪(ni,S (Ri,S \ Li,S )), and thus Ei,0 =
(G0 \ Gi−1,0) \ (ni,S (Ri,S \ Li,S )) = G0 \ (Gi−1,0 ∪ni,S (Ri,S \ Li,S )) = (G0 \ Gi,0).
This implies G′
i = Gi ⊕AttT
Gi,0 ⊕AttF
G0\Gi,0.
Direction 2. ⇒1. :
We construct diagrams (1)–(3) from pushouts (PO1), (PO2). The pushouts (PO1)
and (PO2) without translation attributes are equivalent to the pushouts (0), (3) and
(POT
1 ), (POF
1), (POT
2 ), (POF
2) for families of sets. They do not overlap, because the
have diﬀerent types according to the construction of the type graph with attributes

444
B Proofs and Additional Properties for Parts II and III
by Def. 7.26. The match is a forward translation match, and thus it is injective on
all components except the data value nodes. It remains to construct diagrams (1)
and (2) for graphs with (1) as a pushout. Since the C- and T-components of (1)
and (2) are trivial it remains to construct the corresponding S -components, denoted
here by LS
i,S for Li,S , etc. The morphisms LS
i,S ,−
trS
i,S
−−→RS
i,S −
id−→LS
i,F −
mS
i,F
−−→GS
i−1are given
LS
i,S
 
/

(POT
2 )S
RS
i,S
id
/

(4)
LS
i,F

GS
i−1,0
/
6
GS
i,0
/
(5)
GS
i−1
GS
0
already as graph morphisms.
By (POT
2 ) we have a pushout
in a family of sets and GS
i−1,0
⊆GS
0 = GS
i−1 by assumption
leads to a unique GS
i−1,0 ,−
→
GS
i−1 = GS
0 , such that (4) and
(5) below commute for fami-
lies of sets, using the fact that (POT
2 )S is a pullback, and hence also (POT
2 )S + (4) is
a pullback for families of sets.
Since LS
i,S ,−
trS
i,S
−−→RS
i,S −
id−→LS
i,F −
mS
i,F
−−→GS
i−1 = GS
0 and GS
i−1,0 ,−
→GS
0 are graph mor-
phisms by assumption and GS
i−1,0 ,−
→GS
0 is injective, we also have that LS
i,S −
→GS
i−1
is a graph morphism such that (POT
2 )S becomes a pushout in Graphs with unique
source and target maps for GS
i,0. Finally, this implies that GS
i,0 −
→GS
i−1 = GS
0 is an in-
jective graph morphism and w.l.o.g. an inclusion. Hence, we obtain the diagrams (1)
and (2) for triple graphs from (POT
2 )S and (4) for graphs, where (4) is a pushout and
a pullback and (1)+(2) is a pullback by pullback (1) and injective Gi,0 ,−
→G0 ,−
→Gi−1.
Using pushout (1) for families of sets given by (POT
2 )S we have Gi,0 = Gi−1,0 ∪
ni,S (Ri,S \ Li,S ), and thus Ei,0 = (G0 \ Gi,0), implying G′
i = Gi ⊕AttT
Gi,0 ⊕AttF
G0\Gi,0.
⊓⊔
B.6.2 Proof for Fact 7.36
Proof. We ﬁrst show the equivalence of the sequences disregarding the NACs.
Item 1 is equivalent to the existence of the sequence G0 =
tr1,F,m1,F
======⇒G1 =
tr2,F,m2,F
======⇒
G2 . . . =
trn,F,mn,F
======⇒Gn with GS
n = GS , where each match is forward consistent ac-
cording to Def. B.14. Item 2 is equivalent to the existence of the complete forward
translation sequence G′
0 =
tr1,FT,m1,FT
=======⇒G′
1 =
tr2,FT,m2,FT
=======⇒G′
2 . . . =
trn,FT,mn,FT
=======⇒G′
n via TRFT.
Disregarding the NACs, it remains to show that G
′S
0
= AttF(GS ) and G
′S
n
=
AttT(GS ). We apply Lem. B.15 for i = 0 with G0,0 = ∅up to i = n with Gn,0 = G0,
and using GS
0 = GS we derive:
G
′S
0 = GS
0 ⊕AttT
G0,0 ⊕AttF
GS
0 \GS
0,0 = GS
0 ⊕AttF
GS
0 = GS ⊕AttF
GS = AttF(GS ).
G
′S
n = GS
n ⊕AttT
GS
n,0 ⊕AttF
GS
0 \GS
n,0 = GS
n ⊕AttT
GS
n,0 = GS ⊕AttT
GS = AttT(GS ).

B.6 Proofs for Chap. 7
445
Now, we show that the single steps are also NAC consistent. For each step, we
have transformations Gi−1,0 =
tri,S ,mi,S
=====⇒Gi,0, Gi−1 =
tri,F,mi,F
=====⇒Gi, G′
i−1 =
tri,FT ,mi,FT
=======⇒G′
i with
G′
i−1 = Gi−1 ⊕AttF
G0\Gi−1,0 ⊕AttT
Gi−1,0, G′
i = Gi ⊕AttF
G0\Gi,0 ⊕AttT
Gi,0, and mi,FT|Li,F = mi,F.
For a target NAC n : Li →N, we have to show that mi,F |= n iﬀmi,FT |= nFT,
where nFT is the corresponding forward translation NAC of n. If mi,FT ̸|= nFT , we
ﬁnd a monomorphism q′ with q′ ◦nFT = mi,FT. Since n = nFT|N, deﬁne q = q′|N,
and it follows that q ◦n = mi,F, i.e., mi,F ̸|= n. Vice versa, if mi,F ̸|= n, we ﬁnd a
monomorphism q with q ◦n = mi,F. Since NS = LS
i , we do not have any additional
translation attributes in NFT. Thus mi,FT can be extended by q to q′ : NFT →G′
i−1
such that mi,FT ̸|= nFT.
Similarly, we have to show that for a source NAC n : L →N, mi,S |= n iﬀ
mi,FT |= nFT. As for target NACs, if mi,FT ̸|= nFT, we ﬁnd a monomorphism q′ with
q′ ◦nFT = mi,FT and for the restriction to LS
i and NS it follows that qS ◦nS = mS
i,FT,
i.e., mi,S ̸|= n. Vice versa, if mi,S ̸|= n, we ﬁnd a monomorphism q with q ◦n = mi,S .
Now deﬁne q′ with q′(x) = mi,FT(x) for x ∈LFT and q′(x) = q(x) for x ∈N\Li, and
for each x ∈NS \LS
i we have that q(x) ∈Gi−1,0. From the above characterisation of
G′
i−1 it follows that the corresponding translation attributes tr_x and tr_x_a are set
to T in G′
i−1. Thus, q′ is well deﬁned and q′ ◦nFT = mi,FT, i.e., mi,FT ̸|= nFT.
The equality of the model transformation relations follows by the equality of the
pairs (GS ,GT) in the model transformation sequences in both cases.
⊓⊔
B.6.3 Proof for Fact 7.52
Proof. 1.
It is straightforward to show that F is a well-deﬁned functor F
:
L
(1)
r
/
m 
R
n
G
f
/ G′
F (L)
(2)
F (r)
/
F (m)

F (R)
F (n)

F (G)
F (f)
/ F (G′)
ATrGraphs →AGraphs. Given
pushout (1) in ATrGraphs we have
to show pushout (2) in AGraphs.
Pushout (1) in ATrGraphs is
equivalent to commutativity of dou-
ble cube (3) in AGraphs with three
vertical pushouts, because pushouts
in ATrGraphs are constructed componentwise as pushouts in AGraphs.
(3)
LS
rS
/
mS

RS
nS

LC
sL
i
tL
)
rC
/
mC

RC
sR
i
tR
)
nC

LT
rT
/
mT

RT
nT

GS
f S
/ G′S
GC
sG
i
tG
)
f C
/ G′C
sG′
i
tG′
)
GT
f T
/ G′T

446
B Proofs and Additional Properties for Parts II and III
Diagram (2) is a pushout in Graphs iﬀthe V- and E-components are pushouts in
Sets. In the following we show this for the E-component, while the proof for the V-
component is similar and even simpler, because we have no LinkS - and LinkT-parts.
The E-component of (2) is shown in diagram (4) in Sets.
F (L)E
= LS
E + LC
E + LT
E
+LinkS (L) + LinkT(L)
(4)
rS,E+rC,E+rT,E
+rLS +rLT
/
mS,E + mC,E + mT,E
+mLS + mLT

F (R)E
= RS
E + RC
E + RT
E
+LinkS (R) + LinkT(R)
nS
E + nC
E + nT
E
+nLS + nLT

F (G)E
= GS
E + GC
E + GT
E
+LinkS (G) + LinkT(G)
fS,E+ fC,E+ fT,E
+ fLS +fLT
/
F (G′)E
= G′S
E + G′C
E + G′T
E
+LinkS (G′) + LinkT(G′)
Diagram (4) is the disjoint union of ﬁve diagrams, where the S -, C- and T-part are
the E-components of corresponding pushouts in (3) in Graphs, and hence pushouts
in Sets. We will show that the LinkS -part (and similarly the LinkT-part) is pushout
in Sets. Since coproducts of pushouts are again pushouts (in any category) (4) is
a pushout in Sets. First of all, (5) commutes, because F is a functor and (5) is
the LS -part of (2). In order to show the universal properties we assume we have
h1 : LinkS (R) →X and h2 : LinkS (G) →X with h1 ◦rLS = h2 ◦mLS and we have to
construct a unique h : LinkS (G′) →X such that (6) and (7) commute.
LinkS (L)
rLS
/
mLS 
(5)
LinkS (R)
nLS

h1

(6)
LinkS (G)
fLS
/
h2
2
(7)
LinkS (G′)
h
+ X
Given (x, y) ∈LinkS (G′), we have x ∈G′C
V and y ∈G′S
V with sG′(x) = y. Since
G′C in (3) is a pushout object we have either x1 ∈RC with nC(x1) = x or x2 ∈GC
with f C(x2) = x, leading to h(x, y) deﬁned by
h(x, y) =
( h1(x1, y1), for nC(x1) = x and y1 = sR(x1)
h2(x2, y2), for f C(x2) = x and y2 = sG(x2).
h1(x1, y1) is well deﬁned and (6) commutes, because (x1, y1) ∈LinkS (R) and
nS (y1) = nS ◦sR(x1) = sG′(x) = y implies h ◦nLS (x1, y1) = h(nC(x1), nS (y1)) =
h(x, y). Similarly, h2(x2, y2) is well-deﬁned and (7) commutes. It remains to show
that h is well deﬁned. For this purpose it is suﬃcient to show that for x = nC(x1) =
f C(x2) with y1 = sR(x1) and y2 = sG(x2) we can show h1(x1, y1) = h2(x2, y2).
The pushout of the C-component and nC(x1) = f C(x2) imply existence of x0 ∈LC
with rC(x0) = x1 and mC(x0) = x2, if rC or nC are injective. If both are not in-

B.6 Proofs for Chap. 7
447
jective we have a chain x01, . . . , x0n connecting x1 and x2 and the proof is sim-
ilar. In the injective case we have y0 = sL(x0) with (x0, y0) ∈LinkS (L) and
rLS (x0, y0) = (rC(x0), rS (y0)) = (x1, y1), and similarly mLS (x0, y0) = (x2, y2). Us-
ing h1 ◦rLS = h2 ◦mLS this implies h1(x1, y1) = h1 ◦rLS (x0, y0) = h2 ◦mLS (x0, y0) =
h2(x2, y2).
2. F : ATrGraphs →AGraphs deﬁnes FTG : ATrGraphsTG →AGraphsF (TG)
because for each (G, t: G →TG) in ATrGraphsTG we have (F (G), F (t): F (G) →
F (TG)) in AGraphsF (TG) and for each morphism f
: (G, t) →(G′, t′) with
f : G →G′ and t′ ◦f = t we have F (f): (F (G), F (t)) →(F (G′), F (t′)) with
F (f): F (G) →F (G′) and F (t′) ◦F (f) = F (t).
3. First, we show that FTG is injective on objects. By construction of F (TG) we
have F (TG)V = TGS
V +TGC
V +TGT
V and F (TG)E = TGS
E +TGC
E +TGT
E +LinkS (TG)+
LinkT(TG) with sF (TG)(x, y) = x, tF (TG)(x, y) = y and TGC
E = ∅, and correspond-
ing coproduct embeddings in AGraphs and Sets. For (G, t) in TrGraphsTG with
t : G →TG we have the following pullbacks (1)–(3) in Graphs and (4)–(5) in Sets,
because F (t) = tS + tC + tT + tLS + tLT.
GS
(1)
 
/
tS 
F (G)
(2)
F (t)

GT
? _
o
tT
TGS  
/ F (TG)
TGT
? _
o
GC
(3)
 
/
tC 
F (G)
F (t)

TGC  
/ F (TG)
LinkS (G)
(4)
 
/
tLS 
F (G)E
(5)
F (t)E

LinkT(G)
? _
o
tLT

LinkS (TG)  
/ F (TG)E
LinkT(TG)
? _
o
These distinguished pullback constructions with inclusions in the upper and
lower rows determine completely (G, t) with G = (GS
sG←GC
tG→GT) and GC
E = ∅,
where for each e ∈LinkS (G) ⊆F (G)E with sF (G)(e) = x and tF (G)(e) = y
we have sG,V(x) = y. Vice versa, for each x ∈GC
V, y ∈GS
V with sG,V(x) = y
we have e = (x, y) ∈LinkS (G). Similarly, LinkT(G) completely determines tG,V,
while sG,E and tG,E are empty. This implies for (G, t), (G′, t′) ∈ATrGraphsTG with
(F (G), F (t)) = (F (G′), F (t′)) that (G, t) = (G′, t′), and hence the injectivity of FTG
on objects.
Next, we show that FTG is injective on morphisms and creates morphisms. Us-
ing F (L) = LS + LC + LT + LinkS (L) + LinkT(L) and F (G) = GS + GC + GT +
LinkS (G) + LinkT(G) we obtain unique mS : LS →GS , mC : LC →GC, mT : LT →
GT, mLS : LinkS (L) →LinkS (G), mLT : LinkT(L) →LinkT(G), which are type-
compatible. For example, concerning mS , graphs GS and LS are given by pullbacks
GS = F (typeG)−1(TGS ) ⊆F (G) and LS = F (typeL)−1(TGS ) ⊆F (L), and mS is the
unique induced morphism leading to type compatibility.

448
B Proofs and Additional Properties for Parts II and III
LS  
/
typeL,S

mS
)
F (L)
F (typeL)

m′
*
GS  
/
typeS
G
u
F (G)
F (typeG)
t
TGS  
/ F (TG)
LS
(1)
mS 
LC
(2)
sL
o
tL
/
mC

LT
mT

GS
GC
sG
o
tG
/ GT
The triple graph morphism m = (mS ,
mC, mT) is given by the right diagram,
where commutativity of (1) is shown be-
low for the V-component. It is trivial for
the E-component, because LC
E = GC
E = ∅.
This construction implies F (m)
=
mS +mC +mT +mLS +mLT = m′, because m′ : F (L) →F (G) is uniquely determined
by the S -, C-, T-, LinkS - and LinkT-components. This also implies uniqueness of
m with F (m) = m′. For commutativity of (1) (and similarly for (2)) we use the as-
sumption that m′ : F (L) →F (G) is a graph morphism in AGraphsF (TG) and hence
also in AGraphs. This implies commutativity of (3).
F (L)E
= LS
E + LC
E + LT
E
+LinkS (L) + LinkT(L)
(3)
sF (L)
/
tF (L)
/
mS
E + mC
E + mT
E
+mLS + mLT

F (L)V
= LS
V + LC
V + LT
V
nS
E + nC
E + nT
E
+nLS + nLT

F (G)E
= GS
E + GC
E + GT
E
+LinkS (G) + LinkT(G)
sF (G)
/
tF (G)
/
F (G)V
= GS
V + GC
V + GT
V
For all (x, y) ∈LinkS (L) we have mV ◦sF (L)(x, y) = sF (G) ◦mE(x, y). This im-
plies sF (G)(mLS (x, y)) = mC
V(x), because we have mV ◦sF (L)(x, y) = mV(x) = mC
V(x)
and sF (G) ◦mE(x, y) = sF (G)(mLS (x, y)). Similarly, tF (G)(mLS (x, y)) = mS
V(y), which
implies mLS (x, y) = (mC
V(x), mS
V(y)).
Now, we show that the V-component of (1) commutes. Given x ∈LC
V, we have
sL,V(x) = y and (x, y) ∈LinkS (L). For (x, y) ∈LinkS (L) we have mLS (x, y) =
(mC
V(x), mS
V(y)) ∈LinkS (G′). This implies sG,V ◦mC
V(x) = mS
V(y) = mS
V ◦sL,V(x).
By FTG(f) = FTG(g) we can conlude that f = g by the uniqueness of the creation
property, and hence the injectivity of FTG.
A  B implies FTG(A)  FTG(B), because FTG is a functor. Vice versa, FTG(A) 
FTG(B) implies isomorphisms m′
1 : FTG(A)
∼→FTG(B) and m′
2 : FTG(B)
∼→FTG(A)
leading to unique morphisms m1 : A →B and m2 : B →A with FTG(m1) = m′
1 and
FTG(m2) = m′
2, because FTG creates morphisms. Finally, m2 ◦m1 = idA (and simi-
larly m1◦m2 = idB), and hence A  B, because FTG(m2◦m1) = FTG(m2)◦FTG(m1) =

B.6 Proofs for Chap. 7
449
m′
2 ◦m′
1 = idFTG(A) = FTG(idA).
4.
FTG : ATrGraphsTG →AGraphsF (TG) preserves pushout (1), because
F
: ATrGraphs →AGraphs preserves pushouts by part 1 and pushouts in
ATrGraphsTG and AGraphsF (TG) are based on those in ATrGraphs and AGraphs,
respectively. Vice versa, if (2) is a pushout in ATrGraphsTG and we let (1′) be a
pushout in ATrGraphsTG, then also (2′) is a pushout in AGraphsF (TG).
L
(1′)
r
/
m 
R
n′

G
f ′
/ G′′
FTG(L)
(2′)
FTG(r)
/
FTG(m) 
FTG(R)
FTG(n′)

FTG(G)
FTG( f ′)
/ FTG(G′′)
Uniqueness of pushouts implies FTG(G′)  FTG(G′′) and hence G′  G′′ by part
3, where G′  G′′ is compatible with n, n′ and f, f ′, respectively, showing that also
(1) is pushout. Finally, we show that FTG creates pushouts, given r : L →R and
m : L →G in TrGraphsTG, and that H is the pushout object of FTG(r), FTG(m) in
(2).
L
r
/
m 
(1)
R
n
n′′

G
f
/
f ′′
3
G′
∼' G′′
FTG(L)
FTG(r)
/
FTG(m) 
(2)
FTG(R)
n′

FTG(n′′)

FTG(G)
f ′
/
FTG(f ′′)
1
H
∼)
FTG(G′′)
Let G′′ with n′′, f ′′ be pushout of r and m. Then FTG(G′′) is also pushout, and
hence H  FTG(G′′). According to the construction in part 3 we can construct
G′ in TrGraphsTG with FTG(G′)  H. Note that in this construction sG′,V and
tG′,V are functions deﬁned by LinkS (G′) = type−1
H (LinkS (TG)) and LinkT(G′) =
type−1
H (LinkT(TG)), respectively, because H  FTG(G′′) and this functional prop-
erty holds for FTG by construction. Hence, we have n′ : FTG(R) →FTG(G′) and
f ′ : FTG(G) →FTG(G′) and by part 3 we have unique n : R →G′ and f : G →G′
with FTG(n) = n′ and FTG(f) = f ′. Now reﬂection of pushouts implies that (1) is a
pushout in TrGraphsTG with G′  G′′.
5. Similarly to Item 1 we can show that F preserves pullbacks, because the
LinkS and LinkT diagrams can be shown to be pullbacks and the disjoint union of
pullbacks in Sets is again a pullback. This allows us to show preservation, reﬂection
and creation of pullbacks similar to those of pushouts in Item 4.
⊓⊔

References
ABJ+10.
T. Arendt, E. Biermann, S. Jurack, C. Krause, and G. Taentzer. Henshin: Advanced
concepts and tools for in-place EMF model transformations. In D. Petriu, N. Rou-
quette, and O. Haugen, editors, Proc. of the ACM/IEEE 13th Intern. Conf. on Model
Driven Engineering Languages and Systems (MoDELS’10), volume 6394 of LNCS,
pages 121–135, 2010.
ABV07.
Víctor Anaya, Giuseppe Berio, and Maria Jose Verdecho. Evaluating Quality of En-
terprise Modelling Languages: The UEML solution. In Ricardo Jardim-Gonçalves,
Jörg P. Müller, Kai Mertins, and Martin Zelm, editors, Enterprise Interoperability II
- New Challenges and Industrial Approaches, Proc. Int. Conf. on Interoperability for
Enterprise Software and Applications (IESA 2007), pages 237–240. Springer, 2007.
ACG+14.
Anthony Anjorin, Alcino Cunha, Holger Giese, Frank Hermann, Arend Rensink, and
Andy Schürr. Benchmarx. In Proceedings of the Workshops of the EDBT/ICDT 2014
Joint Conference (EDBT/ICDT 2014), Athens, Greece, March 28, 2014., volume 1133
of CEUR Workshop Proceedings, pages 82–86. CEUR-WS.org, 2014.
AGG14.
TFS-Group, TU Berlin. AGG, 2014. http://tfs.tu-berlin.de/agg.
AHRT14.
Thorsten Arendt, Annegret Habel, Hendrik Radke, and Gabriele Taentzer. From Core
OCL invariants to nested graph constraints. In Holger Giese and Barbara König, edi-
tors, Proc. Int. Conf. on Graph Transformation, ICGT 2014, volume 8571 of Lecture
Notes in Computer Science, pages 97–112. Springer, 2014.
AHS90.
J. Adámek, H. Herrlich, and G. Strecker. Abstract and Concrete Categories. Wiley,
1990.
ALMW09. Jesper Andersson, Rogério Lemos, Sam Malek, and Danny Weyns. Modeling dimen-
sions of self-adaptive software systems. In Software Engineering for Self-Adaptive
Systems, pages 27–47. Springer, 2009.
ALPS11.
A. Anjorin, M. Lauder, S. Patzina, and A. Schürr. eMoﬂon: Leveraging EMF and
Professional CASE Tools. In INFORMATIK 2011, volume 192 of Lecture Notes in
Informatics, page 281. Gesellschaft für Informatik, 2011. Extended abstract.
AR02.
Farhad Arbab and Jan J. M. M. Rutten. A coinductive calculus of component connec-
tors. In Martin Wirsing, Dirk Pattinson, and Rolf Hennicker, editors, WADT, volume
2755 of LNCS, pages 34–55. Springer, 2002.
Arb04.
Farhad Arbab. Reo: A Channel-based Coordination Model for Component Compo-
sition.
Mathematical Structures in Computer Science, 14(3):329–366, June 2004.
Preprint available at http://homepages.cwi.nl/~farhad/MSCS03Reo.pdf.
Arb05.
Farhad Arbab. Abstract Behavior Types: A Foundation Model for Components and
Their Composition. Science of Computer Programming, 55:3–52, March 2005.
ASLS14.
Anthony Anjorin, Karsten Saller, Malte Lochau, and Andy Schürr.
Modularizing
triple graph grammars using rule reﬁnement. In Stefania Gnesi and Arend Rensink,
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3
451

452
References
editors, Fundamental Approaches to Software Engineering - 17th International Con-
ference, FASE 2014, Held as Part of the European Joint Conferences on Theory and
Practice of Software, ETAPS 2014, Grenoble, France, April 5-13, 2014, Proceedings,
Lecture Notes in Computer Science, pages 340–354. Springer, 2014.
ASW09.
Kerstin Altmanninger, Martina Seidl, and Manuel Wimmer. A survey on model ver-
sioning approaches. IJWIS, 5(3):271–304, 2009.
AT13.
Thorsten Arendt and Gabriele Taentzer.
A tool environment for quality assur-
ance based on the Eclipse Modeling Framework. Automated Software Engineering,
20(2):141–184, 2013.
Bal00.
Paolo Baldan. Modelling Concurrent Computations: from Contextual Petri Nets to
Graph Grammars. PhD thesis, Computer Science Department - University of Pisa,
2000.
BB09.
Nelly Bencomo and Gordon S. Blair. Using architecture models to support the gener-
ation and operation of component-based adaptive systems. In Software Engineering
for Self-Adaptive Systems, pages 183–200, 2009.
BBCP04.
Paolo Baldan, Nadia Busi, Andrea Corradini, and G. Michele Pinna. Domain and
event structure semantics for Petri nets with read and inhibitor arcs. Theor. Comput.
Sci., 323(1-3):129–189, 2004.
BCDW04.
Jeremy S. Bradbury, James R. Cordy, Juergen Dingel, and Michel Wermelinger. A
survey of self-management in dynamic software architecture speciﬁcations. In Pro-
ceedings of the 1st ACM SIGSOFT workshop on Self-managed systems (WOSS ’04),
pages 28–33. ACM, 2004.
BCF+10.
Davi M. J. Barbosa, Julien Cretin, Nate Foster, Michael Greenberg, and Benjamin C.
Pierce. Matching lenses: alignment and view update. In Paul Hudak and Stephanie
Weirich, editors, Proceeding of the 15th ACM SIGPLAN international conference on
Functional programming, ICFP 2010, Baltimore, Maryland, USA, September 27-29,
2010, ICFP ’10, pages 193–204, New York, NY, USA, 2010. ACM.
BCG+12.
Roberto Bruni, Andrea Corradini, Fabio Gadducci, Alberto Lluch-Lafuente, and An-
drea Vandin. A conceptual framework for adaptation. In Fundamental Approaches to
Software Engineering - 15th International Conference, FASE 2012, pages 240–254,
Tallinn, Estonia, March 24 - April 1, 2012.
BCH+06.
Paolo Baldan, Andrea Corradini, Tobias Heindel, Barbara König, and Pawel Sobocin-
ski. Processes for adhesive rewriting systems. In Luca Aceto and Anna Ingólfsdóttir,
editors, FoSSaCS, volume 3921 of Lecture Notes in Computer Science, pages 202–
216. Springer, 2006.
BEdLT04.
R. Bardohl, H. Ehrig, J. de Lara, and G. Taentzer. Integrating Meta Modelling with
Graph Transformation for Eﬃcient Visual Language Deﬁnition and Model Manipula-
tion. In M. Wermelinger and T. Margaria-Steﬀen, editors, Proc. Fundamental Aspects
of Software Engineering 2004, volume 2984 of LNCS. Springer, 2004.
BEE+13.
Antonio Bucchiarone, Hartmut Ehrig, Claudia Ermel, Patrizio Pelliccione, and Olga
Runge. Modeling and analysis of self-adaptive systems based on graph transforma-
tion. Technical Report 2013/03, TU Berlin, 2013.
BEE+15.
Antonio Bucchiarone, Hartmut Ehrig, Claudia Ermel, Patrizio Pelliccione, and Olga
Runge. Rule-based modeling and static analysis of self-adaptive systems by graph
transformation. In Rocco De Nicola and Rolf Hennicker, editors, Software, Services,
and Systems, volume 8950 of Lecture Notes in Computer Science, pages 582–601.
Springer International Publishing, 2015.
BEGG10.
B. Braatz, H. Ehrig, K. Gabriel, and U. Golas. Finitary M-Adhesive Categories. In
H. Ehrig, A. Rensink, G. Rozenberg, and A. Schürr, editors, Proceedings of Intern.
Conf. on Graph Transformation ( ICGT’ 10), volume 6372 of LNCS, pages 234–249.
Springer, 2010.
BEJ10.
E. Biermann, C. Ermel, and S. Jurack. Modeling the "Ecore to GenModel" transfor-
mation with EMF Henshin. In Proc. Transformation Tool Contest 2010 (TTC’10),
2010.
http://planet-research20.org/ttc2010/index.php?option=com_
content&view=article&id=110&Itemid=152.

References
453
BEK+06.
E. Biermann, K. Ehrig, C. Köhler, G. Kuhns, G. Taentzer, and E. Weiss. Graphical
deﬁnition of in-place transformations in the Eclipse Modeling Framework. In O. Nier-
strasz, J. Whittle, D. Harel, and G. Reggio, editors, Proc. of the International Confer-
ence on Model Driven Engineering Languages and Systems (MoDELS’06), volume
4199 of LNCS, pages 425–439. Springer, Berlin, 2006.
BEL+10.
E. Biermann, C. Ermel, L. Lambers, U. Prange, and G. Taentzer. Introduction to
AGG and EMF Tiger by modeling a conference scheduling system. Int. Journal on
Software Tools for Technology Transfer, 12(3-4):245–261, July 2010.
BESW10.
E. Biermann, C. Ermel, J. Schmidt, and A. Warning. Visual modeling of controlled
EMF model transformation using Henshin. ECEASST, 32:1–14, 2010.
BET12.
E. Biermann, C. Ermel, and G. Taentzer. Formal foundation of consistent EMF model
transformations by algebraic graph transformation. Software and Systems Modeling
(SoSyM), 11(2):227–250, 2012.
Béz05.
Jean Bézivin. On the uniﬁcation power of models. Software and System Modeling,
4(2):171–188, 2005.
BFH87.
P. Böhm, H.-R. Fonio, and A. Habel.
Amalgamation of graph transformations: a
synchronization mechanism. Computer and System Sciences (JCSS), 34:377–408,
1987.
BFS00.
Peter Buneman, Mary Fernandez, and Dan Suciu. UnQL: a query language and alge-
bra for semistructured data based on structural recursion. The VLDB Journal, 9(1):76–
110, 2000.
BG08.
Antonio Bucchiarone and Juan Pablo Galeotti. Dynamic software architectures veri-
ﬁcation using DynAlloy. In GT-VMT 2008, 2008.
BGH+05.
S. Burmester, H. Giese, M. Hirsch, D. Schilling, and M. Tichy. The Fujaba real-time
tool suite: Model-driven development of safety-critical, real-time systems. In Proc.
27th Intern. Conf. on Software Engineering (ICSE), St. Louis, Missouri, USA, May
2005.
BGP07.
Luciano Baresi, Sam Guinea, and Liliana Pasquale. Self-healing BPEL processes
with Dynamo and the JBoss rule engine. In ESSPE’07, pages 11–20. ACM, 2007.
BH10.
Christoph Brandt and Frank Hermann. How Far Can Enterprise Modeling for Banking
Be Supported by Graph Transformation? In Hartmut Ehrig, Arend Rensink, Grzegorz
Rozenberg, and Andy Schürr, editors, Int. Conf. on Graph Transformation (ICGT
2010), volume 6372 of Lecture Notes in Computer Science, pages 3–26. Springer,
2010.
BHE09a.
Denes Bisztray, Reiko Heckel, and Hartmut Ehrig. Veriﬁcation of architectural refac-
torings: Rule extraction and tool support. Electronic Communications of the EASST,
16, 2009.
BHE09b.
Christoph Brandt, Frank Hermann, and Thomas Engel. Modeling and Reconﬁgura-
tion of critical Business Processes for the purpose of a Business Continuity Manage-
ment respecting Security, Risk and Compliance requirements at Credit Suisse using
Algebraic Graph Transformation. In Enterprise Distributed Object Computing Con-
ference Workshops, 2009. EDOCW 2009. 13th, Proc. International Workshop on Dy-
namic and Declarative Business Processes (DDBP 2009), pages 64–71. IEEE Xplore
Digital Library, 2009.
BHE09c.
Christoph Brandt, Frank Hermann, and Thomas Engel. Security and Consistency of
IT and Business Models at Credit Suisse realized by Graph Constraints, Transforma-
tion and Integration using Algebraic Graph Theory. In Proc. Int. Conf. on Exploring
Modeling Methods in Systems Analysis and Design 2009 (EMMSAD’09), volume 29
of LNBIP, pages 339–352, Heidelberg, 2009. Springer.
BHEE10.
Christoph Brandt, Frank Hermann, Hartmut Ehrig, and Thomas Engel. Enterprise
Modelling using Algebraic Graph Transformation - Extended Version. Technical Re-
port 2010/06, TU Berlin, Fak. IV, 2010.
BHG11.
Christoph Brandt, Frank Hermann, and Jan Friso Groote. Generation and Evalua-
tion of Business Continuity Processes; Using Algebraic Graph Transformation and

454
References
the mCRL2 Process Algebra. Journal of Research and Practice in Information Tech-
nology, pages 65–86, 2011.
BHTV05.
Luciano Baresi, Reiko Heckel, Sebastian Thöne, and Dániel Varró. Style-based mod-
eling and reﬁnement of service-oriented architectures. Journal of Software and Sys-
tems Modeling (SOSYM), 5(2):187–207, 2005.
BKM+12.
Antonio Bucchiarone, Nawaz Khurshid, Annapaola Marconi, Marco Pistore, and
Heorhi Raik. A car logistics scenario for context-aware adaptive service-based sys-
tems. In ICSE Workshop on Principles of Engineering Service Oriented Systems,
pages 65–66, 2012.
BKPPT00.
P. Bottoni, M. Koch, F. Parisi-Presicce, and G. Taentzer. Consistency Checking and
Visualization of OCL Constraints. In UML 2000 - The Uniﬁed Modeling Language,
volume 1939 of LNCS. Springer, 2000.
BMSG+09. Yuriy Brun, Giovanna Marzo Serugendo, Cristina Gacek, Holger Giese, Holger
Kienle, Marin Litoiu, Hausi Müller, Mauro Pezzè, and Mary Shaw. Engineering self-
adaptive systems through feedback loops. In Betty H.C. Cheng, Rogério de Lemos,
Holger Giese, Paola Inverardi, and JeﬀMagee, editors, Software Engineering for Self-
Adaptive Systems, volume 5525 of Lecture Notes in Computer Science, pages 48–70.
Springer, 2009.
BN89.
D. F. C. Brewer and M. J. Nash. The Chinese Wall Security Policy. In IEEE Sympo-
sium on Security and Privacy, pages 206–214, 1989.
BN96.
Peter Bernus and Laszlo Nemes. A framework to deﬁne a generic enterprise ref-
erence architecture and methodology. Computer Integrated Manufacturing Systems,
9(3):179 – 191, 1996.
BNS+05.
András Balogh, Attila Németh, András Schmidt, István Rath, Dávid Vágó, Dániel
Varró, and András Pataricza. The VIATRA2 model transformation framework. In
Proc. European Conference on Model Driven Architecture (ECMDA’05), 2005.
BNW08.
S. Becker, M. Nagl, and B. Westfechtel. Incremental and interactive integrator tools
for design product consistency. In Manfred Nagl and Wolfgang Marquardt, editors,
Collaborative and Distributed Chemical Engineering. From Understanding to Sub-
stantial Design Process Support, volume 4970 of LNCS, pages 224–267. Springer,
2008.
Bor07.
Artur Boronat. MOMENT: A Formal Framework for Model Management. PhD thesis,
Universitat Politècnica de València, 2007.
BP99.
Nadia Busi and G. Michele Pinna. Process semantics for Place/Transition nets with
inhibitor and read arcs. Fundamenta Informaticae, 40(2-3):165–197, 1999.
BPSR09.
Felix Böse, Jakub Piotrowski, and Bernd Scholz-Reiter. Autonomously controlled
storage management in vehicle logistics - applications of RFID and mobile comput-
ing systems. International Journal of RT Technologies: Research an Application,
1(1):57–76, 2009.
BPVR09.
Antonio Bucchiarone, Patrizio Pelliccione, Charlie Vattani, and Olga Runge. Self-
repairing systems modeling and veriﬁcation using AGG. In Joint Working IEEE/IFIP
Conference on Software Architecture 2009 & European Conference on Software Ar-
chitecture (WICSA’09), 2009.
Bra13.
Christoph Brandt. An Enterprise Modeling Framework for Banks using Algebraic
Graph Transformation. PhD thesis, TU Berlin, 2013.
CFH+09.
Krzysztof Czarnecki, J. Foster, Zhenjiang Hu, Ralf Lämmel, Andy Schürr, and James
Terwilliger. Bidirectional Transformations: A Cross-Discipline Perspective. In Proc.
ICMT’09, volume 5563 of LNCS, pages 260–283. Springer, 2009.
CH06.
Krzysztof Czarnecki and Simon Helsen. Feature-based survey of model transforma-
tion approaches. IBM Systems Journal, 45(3):621–645, 2006.
CHK+01.
Ned Chapin, Joanne E. Hale, Khaled Md. Kham, Juan F. Ramil, and Wui-Gee Tan.
Types of software evolution and software maintenance. Journal of Software Mainte-
nance, 13:3–30, January 2001.
CHS08.
Andrea Corradini, Frank Hermann, and Pawel Soboci´nski. Subobject Transformation
Systems. Applied Categorical Structures, 16(3):389–419, February 2008.

References
455
CIO99.
The Chief Information Oﬃcers Council. Federal Enterprise Architecture Framework
Version 1.1, September 1999. http://www.enterprise-architecture.info/
Images/Documents/Federal%20EA%20Framework.pdf.
CMR96.
Andrea Corradini, Ugo Montanari, and Francesca Rossi. Graph processes. Funda-
menta Informaticae, 26(3/4):241–265, 1996.
CNM06.
Massimiliano Colombo, Elisabetta Di Nitto, and Marco Mauri.
Scene: A service
composition execution environment supporting dynamic changes disciplined through
rules. In ICSOC, pages 191–202, 2006.
CPEV05.
Gerardo Canfora, Massimiliano Di Penta, Raﬀaele Esposito, and Maria Luisa Villani.
An approach for QoS-aware service composition based on genetic algorithms. In Pro-
ceedings of the 2005 Conference on Genetic and Evolutionary Computation (GECCO
’05), pages 1069–1075, 2005.
CSW08.
Tony Clark, Paul Sammut, and James Willans. Applied metamodelling: a foundation
for language driven development, volume 2005. Ceteva, 2008.
Dij65.
E.W. Dijkstra. Solution of a problem in concurrent programming control. Communi-
cations of the ACM, 8(9):569, 1965.
Dis08.
Zinovy Diskin.
Algebraic Models for Bidirectional Model Synchronization.
In
Krzysztof Czarnecki, Ileana Ober, Jean-Michel Bruel, Axel Uhl, and Markus Völter,
editors, Model Driven Engineering Languages and Systems, volume 5301 of Lecture
Notes in Computer Science, pages 21–36. Springer, 2008. 10.1007/978-3-540-87875-
9_2.
Dis11.
Zinovy Diskin. Model Synchronization: Mappings, Tiles, and Categories. In Gener-
ative and Transformational Techniques in Software Engineering III, volume 6491 of
LNCS, pages 92–165. Springer, 2011.
dLVA04.
J. de Lara, H. Vangheluwe, and M. Alfonseca. Meta-Modelling and Graph Grammars
for Multi-Paradigm Modelling in AToM3. Software and System Modeling: Special
Section on Graph Transformations and Visual Modeling Techniques, 3(3):194–209,
2004.
DXC11a.
Zinovy Diskin, Yingfei Xiong, and Krzysztof Czarnecki. From state- to delta-based
bidirectional model transformations: the asymmetric case. Journal of Object Technol-
ogy, 10:6: 1–25, 2011.
DXC+11b.
Zinovy Diskin, Yingfei Xiong, Krzysztof Czarnecki, Hartmut Ehrig, Frank Hermann,
and Fernando Orejas. From state- to delta-based bidirectional model transformations:
The symmetric case. In Jon Whittle, Tony Clark, and Thomas Kühne, editors, Model
Driven Engineering Languages and Systems, 14th International Conference, MOD-
ELS 2011, Wellington, New Zealand, October 16-21, 2011. Proceedings, volume 6981
of Lecture Notes in Computer Science, pages 304–318. Springer, 2011.
EDG+11.
Alexander Egyed, Andreas Demuth, Achraf Ghabi, Roberto Erick Lopez-Herrejon,
Patrick Mäder, Alexander Nöhrer, and Alexander Reder. Fine-tuning model trans-
formation: Change propagation in context of consistency, completeness, and human
guidance. In ICMT’11, volume 6707 of LNCS, pages 1–14. Springer, 2011.
EE05.
H. Ehrig and K. Ehrig. Overview of Formal Concepts for Model Transformations
based on Typed Attributed Graph Transformation. In Proc. Int. Workshop on Graph
and Model Transformation (GraMoT’05), volume 152 of ENTCS. Elsevier, Septem-
ber 2005.
EE08.
H. Ehrig and C. Ermel. Semantical Correctness and Completeness of Model Transfor-
mations using Graph and Rule Transformation. In Proc. International Conference on
Graph Transformation (ICGT’08), volume 5214 of LNCS, pages 194–210. Springer,
2008.
EE10.
C. Ermel and K. Ehrig. Graph modelling and transformation: Theory meets practice.
ECEASST, 30:1–22, 2010.
EEE+07.
Hartmut Ehrig, Karsten Ehrig, Claudia Ermel, Frank Hermann, and Gabriele Taentzer.
Information preserving bidirectional model transformations. In Matthew B. Dwyer
and Antónia Lopes, editors, Fundamental Approaches to Software Engineering, vol-
ume 4422 of LNCS, pages 72–86. Springer, 2007.

456
References
EEH08a.
H. Ehrig, K. Ehrig, and F. Hermann. From Model Transformation to Model Integra-
tion based on the Algebraic Approach to Triple Graph Grammars. ECEASST, 10,
2008.
EEH08b.
H. Ehrig, K. Ehrig, and F. Hermann. From Model Transformation to Model Inte-
gration based on the Algebraic Approach to Triple Graph Grammars (Long Version).
Technical Report 2008/03, Technische Universität Berlin, Fakultät IV, 2008.
EEH08c.
H. Ehrig, C. Ermel, and F. Hermann. On the Relationship of Model Transforma-
tions Based on Triple and Plain Graph Grammars. In G. Karsai and G. Taentzer,
editors, Proc. Third International Workshop on Graph and Model Transformation
(GraMoT’08), GRaMoT ’08, pages 9–16, New York, NY, USA, 2008. ACM.
EEH08d.
H. Ehrig, C. Ermel, and F. Hermann. On the Relationship of Model Transforma-
tions Based on Triple and Plain Graph Grammars (Long Version). Technical Report
2008/05, Technische Universität Berlin, Fakultät IV, 2008.
EEHP09.
H. Ehrig, C. Ermel, F. Hermann, and U. Prange. On-the-Fly Construction, Correctness
and Completeness of Model Transformations based on Triple Graph Grammars. In
A. Schürr and B. Selic, editors, ACM/IEEE 12th Int. Conf. on Model Driven Engineer-
ing Languages and Systems (MODELS’09), volume 5795 of LNCS, pages 241–255.
Springer, 2009.
EEKR99.
H. Ehrig, G. Engels, H.-J. Kreowski, and G. Rozenberg, editors. Handbook of Graph
Grammars and Computing by Graph Transformation, Volume 2: Applications, Lan-
guages and Tools. World Scientiﬁc, 1999.
EEPT05.
H. Ehrig, K. Ehrig, U. Prange, and G. Taentzer. Formal Integration of Inheritance
with Typed Attributed Graph Transformation for Eﬃcient VL Deﬁnition and Model
Manipulation. In Proc. IEEE Symposium on Visual Languages and Human-Centric
Computing (VL/HCC’05), IEEE Computer Society, Dallas, Texas, USA, September
2005.
EEPT06.
H. Ehrig, K. Ehrig, U. Prange, and G. Taentzer. Fundamentals of Algebraic Graph
Transformation. EATCS Monographs in Theor. Comp. Science. Springer, 2006.
EER+10.
H. Ehrig, C. Ermel, O. Runge, A. Bucchiarone, and P. Pelliccione. Formal analysis
and veriﬁcation of self-healing systems. In D. Rosenblum and G. Taentzer, editors,
Proc. Intern. Conf. on Fundamental Aspects of Software Engineering (FASE’10), vol-
ume 6013 of LNCS, pages 139–153. Springer, 2010.
EET11.
Hartmut Ehrig, Claudia Ermel, and Gabriele Taentzer.
A formal resolution strat-
egy for operation-based conﬂicts in model versioning using graph modiﬁcations. In
Dimitra Giannakopoulou and Fernando Orejas, editors, Int. Conf. on Fundamental
Approaches to Software Engineering (FASE’11), volume 6603 of Lecture Notes in
Computer Science, pages 202–216. Springer, 2011.
EGH10.
Hartmut Ehrig, Ulrike Golas, and Frank Hermann. Categorical Frameworks for Graph
Transformation and HLR Systems based on the DPO Approach.
Bulletin of the
EATCS, 102:111–121, 2010.
EGH+12.
Hartmut Ehrig, Ulrike Golas, Annegret Habel, Leen Lambers, and Fernando Ore-
jas. M-Adhesive Transformation Systems with Nested Application Conditions. Part
2: Embedding, Critical Pairs and Local Conﬂuence. Fundam. Inform., 118(1-2):35–
63, 2012.
EGH+14.
Hartmut Ehrig, Ulrike Golas, Annegret Habel, Leen Lambers, and Fernando Ore-
jas. M-adhesive transformation systems with nested application conditions. part 1:
parallelism, concurrency and amalgamation. Mathematical Structures in Computer
Science, 24(4):1–48, 2014.
EGLT11.
Claudia Ermel, Jürgen Gall, Leen Lambers, and Gabriele Taentzer. Modeling with
plausibility checking: Inspecting favorable and critical signs for consistency between
control ﬂow and functional behavior. Technical Report 2011/2, TU Berlin, 2011.
EGSW07.
Gregor Engels, Baris Güldali, Christian Soltenborn, and Heike Wehrheim. Assur-
ing consistency of business process models and web services using visual contracts.

References
457
In Applications of Graph Transformations with Industrial Relevance, Third Interna-
tional Symposium, AGTIVE 2007, Kassel, Germany, October 10-12, 2007, Revised
Selected and Invited Papers, volume 5088 of LNCS, pages 17–31. Springer, 2007.
EHGB12.
Claudia Ermel, Frank Hermann, Jürgen Gall, and Daniel Binanzer. Visual modeling
and analysis of EMF model transformations based on triple graph grammars. ECE-
ASST, 54:1–14, 2012.
EHK+96.
H. Ehrig, R. Heckel, M. Korﬀ, M. Löwe, L. Ribeiro, A. Wagner, and A. Corradini. Al-
gebraic approaches to graph transformation II: Single pushout approach and compar-
ison with double pushout approach. In G. Rozenberg, editor, The Handbook of Graph
Grammars and Computing by Graph Transformations, Volume 1: Foundations, pages
247–312. World Scientiﬁc, 1996.
EHKP91a.
H. Ehrig, A. Habel, H.-J. Kreowski, and F. Parisi-Presicce. From graph grammars to
high level replacement systems. In 4th Int. Workshop on Graph Grammars and their
Application to Computer Science, volume 532 of LNCS, pages 269–291. Springer,
1991.
EHKP91b.
H. Ehrig, A. Habel, H.-J. Kreowski, and F. Parisi-Presicce. Parallelism and concur-
rency in high-level replacement systems. Math. Struct. in Comp. Science, 1:361–404,
1991.
EHL10.
Hartmut Ehrig, Annegret Habel, and Leen Lambers. Parallelism and Concurrency
Theorems for Rules with Nested Application Conditions. Electr. Communications of
the EASST, 26:1–24, 2010.
EHPP04.
H. Ehrig, A. Habel, J. Padberg, and U. Prange.
Adhesive high-level replacement
categories and systems. In F. Parisi-Presicce, P. Bottoni, and G. Engels, editors, Proc.
2nd Int. Conference on Graph Transformation (ICGT’04), volume 3256 of LNCS,
pages 144–160, Rome, Italy, October 2004. Springer.
Ehr79.
H. Ehrig. Introduction to the Algebraic Theory of Graph Grammars (A Survey). In
Graph Grammars and their Application to Computer Science and Biology, volume 73
of LNCS, pages 1–69. Springer, 1979.
EHS09.
Hartmut Ehrig, Frank Hermann, and Christoph Sartorius. Completeness and Cor-
rectness of Model Transformations based on Triple Graph Grammars with Negative
Application Conditions. ECEASST, 18, 2009.
EHSB11.
H. Ehrig, F. Hermann, H. Schölzel, and C. Brandt. Propagation of Constraints along
Model Transformations Based on Triple Graph Grammars. ECEASST, 41, 2011.
EHSB13.
Hartmut Ehrig, Frank Hermann, Hanna Schölzel, and Christoph Brandt. Propagation
of constraints along model transformations using triple graph grammars and borrowed
context. Visual Languages and Computing, 24(5):365–388, 2013.
EKMR99.
H. Ehrig, H.-J. Kreowski, U. Montanari, and G. Rozenberg, editors. Handbook of
Graph Grammars and Computing by Graph Transformation. Vol 3: Concurrency,
Parallelism and Distribution. World Scientiﬁc, 1999.
EM85.
H. Ehrig and B. Mahr. Fundamentals of Algebraic Speciﬁcation 1: Equations and
Initial Semantics, volume 6 of EATCS Monographs on Theoretical Computer Science.
Springer, Berlin, 1985.
EM90.
H. Ehrig and B. Mahr. Fundamentals of Algebraic Speciﬁcation 2: Module Speciﬁ-
cations and Constraints, volume 21 of EATCS Monographs on Theoretical Computer
Science. Springer, Berlin, 1990.
EMC+01.
H. Ehrig, B. Mahr, F. Cornelius, M. Grosse-Rhode, P. Zeitz, G. Schröter, and
K. Robering. Mathematisch Strukturelle Grundlagen der Informatik, 2. überarbeitete
Auﬂage. Springer, 2001.
EMF14.
Eclipse Consortium.
Eclipse Modeling Framework (EMF) – Version 2.9.2, 2014.
http://www.eclipse.org/modeling/emf/.
EMT09.
TFS-Group, TU Berlin.
EMF Tiger, 2009.
http://tfs.cs.tu-berlin.de/
emftrans.
EPS73.
H. Ehrig, M. Pfender, and H.J. Schneider. Graph grammars: an algebraic approach.
In 14th Annual IEEE Symposium on Switching and Automata Theory, pages 167–180.
IEEE, 1973.

458
References
EPT04.
H. Ehrig, U. Prange, and G. Taentzer. Fundamental theory for typed attributed graph
transformation. In F. Parisi-Presicce, P. Bottoni, and G. Engels, editors, Proc. 2nd
Int. Conference on Graph Transformation (ICGT’04), Rome, Italy, volume 3256 of
LNCS. Springer, 2004.
ER76.
H. Ehrig and B.K. Rosen. Commutativity of independent transformations on complex
objects. Research Report RC 6251, IBM T. J. Watson Research Center, Yorktown
Heights, 1976.
Erm06.
C. Ermel. Simulation and Animation of Visual Languages based on Typed Algebraic
Graph Transformation. PhD thesis, Technische Universität Berlin, Fak. IV, Books on
Demand, Norderstedt, 2006.
Erm09.
Claudia Ermel. Visual modelling and analysis of model transformations based on
graph transformation. Bulletin of the EATCS, 99:135 – 152, 2009.
EW04.
R. Eshuis and R. Wieringa. Tool support for verifying uml activity diagrams. IEEE
Trans. on Software Eng., 7(30), 2004.
FG98.
Mark S. Fox and Michael Grüninger. Enterprise Modeling. AI Magazine, 19(3):109–
121, 1998.
FGM+07.
J. Nathan Foster, Michael B. Greenwald, Jonathan T. Moore, Benjamin C. Pierce,
and Alan Schmitt. Combinators for bidirectional tree transformations: A linguistic
approach to the view-update problem. ACM Trans. Program. Lang. Syst., 29(3), May
2007.
FNTZ98.
T. Fischer, Jörg Niere, L. Torunski, and Albert Zündorf. Story Diagrams: A new
Graph Rewrite Language based on the Uniﬁed Modeling Language. In G. Engels and
G. Rozenberg, editors, Proc. of the 6th Int. Workshop on Theory and Application of
Graph Transformation, LNCS 1764, pages 296–309. Springer, November 1998.
FNTZ00.
T. Fischer, Jörg Niere, L. Torunski, and Albert Zündorf.
Story diagrams: A new
graph rewrite language based on the Uniﬁed Modeling Language. In G. Engels and
G. Rozenberg, editors, Proc. of the 6th International Workshop on Theory and Ap-
plication of Graph Transformation (TAGT), volume 1764 of LNCS, pages 296–309.
Springer, Berlin, 2000.
FOT10.
FOTS-Group, University of Antwerp.
MoTMoT: Model driven, Template based,
Model Transformer, 2010. http://www.fots.ua.ac.be/motmot/index.php.
Fra02.
Ulrich Frank. Multi-perspective Enterprise Modeling (MEMO) - Conceptual Frame-
work and Modeling Languages.
In Proc. Hawaii Int. Conf. on System Sciences
(HICSS 2002), page 72, 2002.
Fuj07.
Software Engineering Group, University of Paderborn. Fujaba Tool Suite, 2007.
GBEE11.
Ulrike Golas, Enrico Biermann, Hartmut Ehrig, and Claudia Ermel. A Visual In-
terpreter Semantics for Statecharts Based on Amalgamated Graph Transformation.
ECEASST, 39, 2011.
GBEG14.
Karsten Gabriel, Benjamin Braatz, Hartmut Ehrig, and Ulrike Golas. Finitary M-
Adhesive Categories.
Mathematical Structures in Computer Science, 24(4):1–40,
2014.
GCH+04.
David Garlan, Shang-Wen Cheng, An-Cheng Huang, Bradley Schmerl, and Peter
Steenkiste. Rainbow: Architecture-based self-adaptation with reusable infrastructure.
Computer, 37(10):46–54, 2004.
GEH11.
Ulrike Golas, Hartmut Ehrig, and Frank Hermann. Formal Speciﬁcation of Model
Transformations by Triple Graph Grammars with Application Conditions. ECEASST,
39, 2011.
GH09.
H. Giese and S. Hildebrandt. Eﬃcient Model Synchronization of Large-Scale Models.
Technical Report 28, Hasso Plattner Institute at the University of Potsdam, 2009.
GHE14.
Ulrike Golas, Annegret Habel, and Hartmut Ehrig. Multi-amalgamation of rules with
application conditions in M-adhesive categories. Mathematical Structures in Com-
puter Science, 24(4):1–68, 2014.
GHL10.
Holger Giese, Stephan Hildebrandt, and Leen Lambers. Toward bridging the gap
between formal semantics and implementation of triple graph grammars. Technical
Report 37, Hasso Plattner Institute at the University of Potsdam, 0 2010.

References
459
GHL12.
Holger Giese, Stephan Hildebrandt, and Leen Lambers.
Bridging the gap be-
tween formal semantics and implementation of triple graph grammars.
Soft-
ware and Systems Modeling, pages 1–27, 2012. http://dx.doi.org/10.1007/
s10270-012-0247-y.
GHN+13.
Susann Gottmann, Frank Hermann, Nico Nachtigall, Braatz Benjamin, Claudia Er-
mel, Hartmut Ehrig, and Thomas Engel. Correctness and Completeness of Gener-
alised Concurrent Model Synchronisation Based on Triple Graph Grammars. In Proc.
Int. Workshop on Analysis of Model Transformations 2013 (AMT’13). CEUR-WS.
org, 2013.
GK08.
Rubino Gei¨s and Moritz Kroll. GrGen.net: A fast, expressive, and general purpose
graph rewrite tool. In A. Schürr, M. Nagl, and A. Zündorf, editors, Proc. 3rd Intl.
Workshop on Applications of Graph Transformation with Industrial Relevance (AG-
TIVE’07), volume 5088 of LNCS. Springer, 2008.
GK10.
J. Greenyer and E. Kindler. Comparing relational model transformation technologies:
implementing query/view/transformation with triple graph grammars. Software and
Systems Modeling (SoSyM), 9(1):21–46, 2010.
Gol10.
U. Golas. Multi-amalgamation in M-adhesive categories: Long version. Technical
Report 2010/05, Technical University of Berlin, 2010.
Gol11.
Ulrike Golas. Analysis and Correctness of Algebraic Graph and Model Transforma-
tions. PhD thesis, Technische Universität Berlin, 2011.
GPR11.
J. Greenyer, S. Pook, and J. Rieke. Preventing information loss in incremental model
synchronization by reusing elements. In Proc. ECMFA 2011, volume 6698 of LNCS,
pages 144–159. Springer, 2011.
GrG06.
Universität Karlsruhe. Graph Rewrite GENerator (GrGen), 2006. http://www.
info.uni-karlsruhe.de/software.php/id=7&lang=en.
Gro08.
GRaphs for Object-Oriented VEriﬁcation (GROOVE), 2008.
http://groove.
sourceforge.net/groove-index.html.
GW09.
Holger Giese and Robert Wagner. From model transformation to incremental bidirec-
tional model synchronization. Software and Systems Modeling, 8:21–43, 2009.
HCE14.
Frank Hermann, Andrea Corradini, and Hartmut Ehrig.
Analysis of Permutation
Equivalence in M-adhesive Transformation Systems with Negative Application Con-
ditions. Mathematical Structures in Computer Science, 24(4):1–47, 2014.
HCEK10.
Frank Hermann, Andrea Corradini, Hartmut Ehrig, and Barbara König.
Eﬃcient
Analysis of Permutation Equivalence of Graph Derivations Based on Petri Nets. ECE-
ASST, 29:1–15, 2010.
HEEO11.
Frank Hermann, Hartmut Ehrig, Claudia Ermel, and Fernando Orejas. Concurrent
model synchronization with conﬂict resolution based on triple graph grammars - ex-
tended version. Technical Report 2011/14, TU Berlin, Fak. IV, 2011.
HEEO12.
Frank Hermann, Hartmut Ehrig, Claudia Ermel, and Fernando Orejas. Concurrent
model synchronization with conﬂict resolution based on triple graph grammars. In
Juan de Lara and Andrea Zisman, editors, Int. Conf. on Fundamental Approaches to
Software Engineering (FASE’12), volume 7212 of Lecture Notes in Computer Sci-
ence, pages 178–193. Springer, 2012.
HEGO10.
Frank Hermann, Hartmut Ehrig, Ulrike Golas, and Fernando Orejas. Eﬃcient Anal-
ysis and Execution of Correct and Complete Model Transformations Based on Triple
Graph Grammars. In J. Bézivin, R.M. Soley, and A. Vallecillo, editors, Proc. Int.
Workshop on Model Driven Interoperability (MDI’10), MDI ’10, pages 22–31, New
York, NY, USA, 2010. ACM.
HEGO14.
Frank Hermann, Hartmut Ehrig, Ulrike Golas, and Fernando Orejas. Formal analysis
of model transformations based on triple graph grammars. Mathematical Structures
in Computer Science, 24(4):1–57, 2014.
Hei09.
Tobias Heindel.
A Category Theoretical Approach to the Concurrent Semantics
of Rewriting: Adhesive Categories and Related Concepts. PhD thesis, Universität
Duisburg-Essen, 2009.

460
References
Hei10.
T. Heindel. Hereditary Pushouts Reconsidered. In Proceedings of ICGT 2010, volume
6372 of LNCS, pages 250–265. Springer, 2010.
HEO+11a.
Frank Hermann, Hartmut Ehrig, Fernando Orejas, Krzysztof Czarnecki, Zinovy
Diskin, and Yingfei Xiong. Correctness of model synchronization based on triple
graph grammars. In Jon Whittle, Tony Clark, and Thomas Kühne, editors, ACM/IEEE
14th Int. Conf. on Model Driven Engineering Languages and Systems (MoDELS’11),
volume 6981 of LNCS, pages 668–682. Springer, 2011.
HEO+11b.
Frank Hermann, Hartmut Ehrig, Fernando Orejas, Krzysztof Czarnecki, Zinovy
Diskin, and Yingfei Xiong. Correctness of model synchronization based on triple
graph grammars - extended version. Technical Report 2011/07, TU Berlin, 2011.
HEO+13.
Frank Hermann, Hartmut Ehrig, Fernando Orejas, Krzysztof Czarnecki, Zinovy
Diskin, Yingfei Xiong, Susann Gottmann, and Thomas Engel. Model synchronization
based on triple graph grammars: correctness, completeness and invertibility. Software
& Systems Modeling, pages 1–29, 2013.
HEOG10a. F. Hermann, H. Ehrig, F. Orejas, and U. Golas. Formal analysis of functional be-
haviour for model transformations based on triple graph grammars - extended version.
Technical Report 2010/08, Technical University of Berlin, 2010.
HEOG10b. Frank Hermann, Hartmut Ehrig, Fernando Orejas, and Ulrike Golas. Formal Analysis
of Functional Behaviour of Model Transformations Based on Triple Graph Gram-
mars. In H. Ehrig, A. Rensink, G. Rozenberg, and A. Schürr, editors, Proceedings
of Intern. Conf. on Graph Transformation ( ICGT’ 10), volume 6372 of LNCS, pages
155–170. Springer, 2010.
Her09.
Frank Hermann. Permutation Equivalence of DPO Derivations with Negative Appli-
cation Conditions based on Subobject Transformation Systems. Electronic Commu-
nications of the EASST, 16, 2009.
Her11.
Frank Hermann. Analysis and Optimization of Visual Enterprise Models Based on
Graph and Model Transformation. PhD thesis, TU Berlin, 2011.
HGN+14.
Frank Hermann, Susann Gottmann, Nico Nachtigall, Hartmut Ehrig, Benjamin
Braatz, Gianluigi Morelli, Alain Pierre, Thomas Engel, and Claudia Ermel. Triple
graph grammars in the large for translating satellite procedures. In D. Di Ruscio
and D. Varro, editors, Proc. Int. Conf. on Model Transformations (ICMT 2014), num-
ber 8568 in Lecture Notes of Computer Science, pages 122–137, Switzerland, 2014.
Springer International Publishing.
HHI+10.
Soichiro Hidaka, Zhenjiang Hu, Kazuhiro Inaba, Hiroyuki Kato, Kazutaka Matsuda,
and Keisuke Nakano. Bidirectionalizing graph transformations. In Proceedings of
the 15th ACM SIGPLAN international conference on Functional programming, ICFP
2010, pages 205–216. ACM, 2010.
HHK10.
Frank Hermann, Mathias Hülsbusch, and Barbara König. Speciﬁcation and veriﬁca-
tion of model transformations. ECEASST, 30:1–21, 2010.
HHT96.
A. Habel, R. Heckel, and G. Taentzer. Graph Grammars with Negative Application
Conditions. Special issue of Fundamenta Informaticae, 26(3,4):287–313, 1996.
HHT02.
J.H. Hausmann, R. Heckel, and G. Taentzer. Detection of Conﬂicting Functional Re-
quirements in a Use Case-Driven Approach. In Proc. of Int. Conference on Software
Engineering 2002, pages 105 – 115, Orlando, USA, 2002.
HIM00.
Dan Hirsch, Paola Inverardi, and Ugo Montanari. Reconﬁguration of software ar-
chitecture styles with name mobility. In Proceedings of the 4th International Con-
ference on Coordination Languages and Models, COORDINATION ’00, pages 148–
163, London, UK, 2000. Springer.
HKT02.
R. Heckel, J. Küster, and G. Taentzer. Towards Automatic Translation of UML Mod-
els into Semantic Domains . In H.-J. Kreowski, editor, Proc. of APPLIGRAPH Work-
shop on Applied Graph Transformation (AGT 2002), pages 11 – 22, 2002.
HLG+13.
Stephan Hildebrandt, Leen Lambers, Holger Giese, Jan Rieke, Joel Greenyer, Wil-
helm Schäfer, Marius Lauder, Anthony Anjorin, and Andy Schürr. A survey of triple
graph grammar tools. ECEASST, 57, 2013.

References
461
HMT08.
Zhenjiang Hu, Shin-Cheng Mu, and Masato Takeichi. A programmable editor for de-
veloping structured documents based on bidirectional transformations. Higher-Order
and Symbolic Computation, 21(1-2):89–118, 2008.
HP05.
A. Habel and K.-H. Pennemann. Nested constraints and application conditions for
high-level structures.
In H.-J. Kreowski, U. Montanari, F. Orejas, G. Rozenberg,
and G. Taentzer, editors, Formal Methods in Software and Systems Modeling, volume
3393 of Lecture Notes in Computer Science, pages 294–308. Springer, 2005.
HP09.
Annegret Habel and Karl-Heinz Pennemann. Correctness of high-level transformation
systems relative to nested conditions. Mathematical Structures in Computer Science,
19:1–52, 2009.
HPW11.
Martin Hofmann, Benjamin C. Pierce, and Daniel Wagner. Symmetric lenses. In
Thomas Ball and Mooly Sagiv, editors, Proceedings of the 38th ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, POPL 2011, Austin,
TX, USA, January 26-28, 2011, pages 371–384. ACM, 2011.
HPW12.
Martin Hofmann, Benjamin Pierce, and Daniel Wagner. Edit lenses. SIGPLAN Not.,
47(1):495–508, January 2012.
ISO04.
ISO/IEC. ISO/IEC 15009-1:2004, Software and system engineering - High-level Petri
nets - Part 1: Concepts, deﬁnitions and graphical notation. ISO/IEC, 2004.
ISO06.
International Organization for Standardization (ISO). ISO Standard 19439:2006: En-
terprise integration – Framework for enterprise modelling, 2006.
JABK08.
Frédéric Jouault, Freddy Allilaire, Jean Bézivin, and Ivan Kurtev. ATL: A model
transformation tool. Science of Computer Programming, 72(1-2):31 – 39, 2008.
JK95.
Ryszard Janicki and Maciej Koutny.
Semantics of inhibitor nets.
Inf. Comput.,
123(1):1–16, 1995.
JK05.
F. Jouault and I. Kurtev. Transforming models with ATL. In MoDELS Satellite Events,
volume 3844 of LNCS, pages 128–138. Springer, Berlin, 2005.
JLM+09.
S. Jurack, L. Lambers, K. Mehner, G. Taentzer, and G. Wierse. Object Flow Deﬁ-
nition for Reﬁned Activity Diagrams. In M. Chechik and M. Wirsing, editors, Proc.
Fundamental Approaches to Software Engineering (FASE’09), volume 5503 of LNCS,
pages 49–63. Springer, 2009.
JLMT08.
S. Jurack, L. Lambers, K. Mehner, and G. Taentzer. Suﬃcient Criteria for Consistent
Behavior Modeling with Reﬁned Activity Diagrams. In K. Czarnecki, editor, Proc.
ACM/IEEE 11th International Conference on Model Driven Engineering Languages
and Systems (MoDELS’08), volume 5301 of LNCS, pages 341–355. Springer, 2008.
JLS07.
P.T. Johnstone, S. Lack, and P. Soboci´nski. Quasitoposes, Quasiadhesive Categories
and Artin Glueing. In T. Mossakowski, U. Montanari, and M. Haveraaen, editors,
Algebra and Coalgebra in Computer Science. Proceedings of CALCO 2007, volume
4626 of LNCS, pages 312–326. Springer, 2007.
JWEG07.
Praveen K. Jayaraman, Jon Whittle, Ahmed M. Elkhodary, and Hassan Gomaa. Model
composition in product lines and feature interaction detection using critical pair analy-
sis. In Model Driven Engineering Languages and Systems, 10th International Confer-
ence, MoDELS 2007, Nashville, USA, September 30 - October 5, 2007, Proceedings,
volume 4735 of LNCS, pages 151–165. Springer, 2007.
KB06.
Sascha Klüppelholz and Christel Baier. Symbolic model checking for channel-based
component connectors. In Proc. Int. Workshop on the Foundations of Coordination
Languages and Software Architectures (FOCLASA’06), 2006.
KC03.
Jeﬀrey O. Kephart and David M. Chess. The vision of autonomic computing. Com-
puter, 36(1):41–50, 2003.
Ken91.
R. Kennaway.
Graph Rewriting in Some Categories of Partial Morphisms.
In
H. Ehrig, H.-J. Kreowski, and G. Rozenberg, editors, Proceeding of Int. Workshop
Graph-Grammars and Their Application to Computer Science 1990, volume 532 of
LNCS, pages 490–504. Springer, 1991.
KHM06.
Harmen Kastenberg, Frank Hermann, and Tony Modica. Towards Translating Graph
Transformation Systems by Model Transformation. In Proc. International Workshop

462
References
on Graph and Model Transformation (GraMoT’06), Satellite Event of the IEEE Sym-
posium on Visual Languages and Human-Centric Computing, volume 4, Brighton,
UK, September 2006. Electronic Communications of the EASST.
KK04.
H. C. M. Kleijn and M. Koutny. Process semantics of general inhibitor nets. Infor-
mation and Computation, 190(1):18–69, 2004.
KKvT10.
Hans-Jörg Kreowski, Sabine Kuske, and Caroline von Totth. Stepping from graph
transformation units to model transformation units. ECEASST, 30, 2010.
KLKS10.
F. Klar, M. Lauder, A. Königs, and A. Schürr. Extended Triple Graph Grammars with
Eﬃcient and Compatible Graph Translators. In Graph Transformations and Model
Driven Enginering - Essays Dedicated to Manfred Nagl on the Occasion of his 65th
Birthday, volume 5765 of LNCS, pages 144–177. Springer, 2010.
KM07.
JeﬀKramer and JeﬀMagee. Self-managed systems: an architectural challenge. In
2007 Future of Software Engineering, FOSE ’07, pages 259–268, Washington, DC,
USA, 2007. IEEE Computer Society.
KPPR07.
D. Kolovos, R. Paige, F Polack, and L. Rose. Update transformations in the small
with Epsilon wizard language. Journal of Object Technology, 6(9):53–69, 2007.
KS06.
A. Königs and A. Schürr. Tool Integration with Triple Graph Grammars - A Survey.
In Proc. SegraVis School on Foundations of Visual Modelling Techniques, volume
148, pages 113–150, Amsterdam, 2006. Electronic Notes in Theoretical Computer
Science, Elsevier.
KW07.
E. Kindler and R. Wagner. Triple graph grammars: Concepts, extensions, implemen-
tations, and application scenarios. Technical Report TR-ri-07-284, Department of
Computer Science, University of Paderborn, Germany, 2007.
Lam10.
Leen Lambers. Certifying Rule-Based Models using Graph Transformation . PhD
thesis, Technische Universität Berlin, 2010. Also as book available: Südwestdeutscher
Verlag für Hochschulschriften, ISBN: 978-3-8381-1650-1.
LAS14a.
Erhan Leblebici, Anthony Anjorin, and Andy Schürr. A catalogue of optimization
techniques for triple graph grammars. In Hans-Georg Fill, Dimitris Karagiannis, and
Ulrich Reimer, editors, Modellierung 2014, 19.-21. March 2014, Vienna, Austria, vol-
ume 225 of LNI, pages 225–240. GI, 2014.
LAS+14b.
Erhan Leblebici, Anthony Anjorin, Andy Schürr, Stephan Hildebrandt, Jan Rieke, and
Joel Greenyer. A comparison of incremental triple graph grammar tools. ECEASST,
67, 2014.
LAVS12.
Marius Lauder, Anthony Anjorin, Gergely Varró, and Andy Schürr. Bidirectional
Model Transformation with Precedence Triple Graph Grammars. In Antonio Val-
lecillo, Juha-Pekka Tolvanen, Ekkart Kindler, Harald Störrle, and Dimitris Kolovos,
editors, Proc. of the 8th European Conf. on Modelling Foundations and Applications,
volume 7349 of LNCS, pages 287–302. Springer, 2012.
LB93.
M. Löwe and M. Beyer. AGG — an implementation of algebraic graph rewriting. In
Proc. Fifth Int. Conf. Rewriting Techniques and Applications, volume 690 of LNCS,
pages 451–456. Springer, 1993.
LBM10.
Ivan Lanese, Antonio Bucchiarone, and Fabrizio Montesi. A framework for rule-
based dynamic adaptation. In Trustworthly Global Computing - 5th International
Symposium, TGC 2010, Munich, Germany, February 24-26, 2010, Revised Selected
Papers, volume 6084 of Lecture Notes in Computer Science, pages 284–300. Springer,
2010.
LEOP08.
L. Lambers, H. Ehrig, F. Orejas, and U. Prange. Parallelism and Concurrency in
Adhesive High-Level Replacement Systems with Negative Application Conditions.
In H. Ehrig, J. Pfalzgraf, and U. Prange, editors, Proceedings of the ACCAT workshop
at ETAPS 2007, volume 203 / 6 of ENTCS, pages 43–66. Elsevier, 2008.
LMEP08.
L. Lambers, L. Mariani, H. Ehrig, and M. Pezze. A Formal Framework for Develop-
ing Adaptable Service-Based Applications. In J.L. Fiadeiro and P. Inverardi, editors,
Proc. Fundamental Approaches to Software Engineering (FASE’08), volume 4961 of
LNCS, pages 392–406. Springer, 2008.

References
463
LS04.
S. Lack and P. Soboci´nski. Adhesive Categories. In Proc. FOSSACS 2004, volume
2987 of LNCS, pages 273–288. Springer, 2004.
LS05a.
S. Lack and P. Soboci´nski. Adhesive and quasiadhesive categories. Theoretical Infor-
matics and Applications, 39(2):511–546, 2005.
LS05b.
M. Lawley and J. Steel. Practical declarative model transformation with Tefkat. In
MoDELS Satellite Events, volume 3844 of LNCS, pages 139–150. Springer, Berlin,
2005.
Mar00.
Chris Marshall.
Enterprise modeling with UML: designing successful software
through business analysis. Addison-Wesley Longman, 2000.
MDA15.
Object Management Group. MDA Speciﬁcations, 2015. http://www.omg.org/
mda/specs.htm.
MEE12.
Maria Maximova, Hartmut Ehrig, and Claudia Ermel. Transfer of Local Conﬂuence
and Termination between Petri Net and Graph Transformation Systems Based on M-
Functors. ECEASST, 51:1–12, 2012.
MEE13.
Maria Maximova, Hartmut Ehrig, and Claudia Ermel. Analysis of Hypergraph Trans-
formation Systems in AGG based on M-Functors. ECEASST, 58, 2013.
MG06.
Tom Mens and Pieter Van Gorp. A taxonomy of model transformation. Electr. Notes
Theor. Comput. Sci., 152:125–142, 2006.
MHMT13.
Katharina Mehner-Heindl, Mattia Monga, and Gabriele Taentzer. Analysis of aspect-
oriented models using graph transformation systems.
In Ana Moreira, Ruzanna
Chitchyan, João Araújo, and Awais Rashid, editors, Aspect-Oriented Requirements
Engineering, pages 243–270. Springer, 2013.
MM90.
J. Meseguer and U. Montanari. Petri Nets are Monoids. Information and Computa-
tion, 88(2):105–155, 1990.
MMT09.
Katharina Mehner, Mattia Monga, and Gabriele Taentzer. Analysis of aspect-oriented
model weaving.
In T. Aspect-Oriented Software Development V, volume 5490 of
LNCS, pages 235–263. Springer, 2009.
MOF15.
Object Management Group. Meta-Object Facility (MOF), Version 2.5, 2015. http:
//www.omg.org/spec/MOF/2.5/.
MOM12.
University of Leicester.
MOMENT2-MT, 2012.
http://www.cs.le.ac.uk/
people/aboronat/tools/moment2-gt/.
MSD06.
Tom Mens, Ragnhild Van Der Straeten, and Maja D’Hondt. Detecting and resolving
model inconsistencies using transformation dependency analysis. In Model Driven
Engineering Languages and Systems, 9th International Conference, MoDELS 2006,
Genova, Italy, October 1-6, 2006, Proceedings, volume 4199 of LNCS, pages 200–
214. Springer, 2006.
MV08.
B. Meyers and P. Van Gorp. Towards a hybrid transformation language: Implicit and
explicit rule scheduling in story diagrams. In Proceedings of the 6th International
Fujaba Days, 2008.
MVDJ05.
T. Mens, N. Van Eetvelde, S. Demeyer, and D. Janssens. Formalizing refactorings
with graph transformations. Software Tools for Technology Transfer, 17:247–276,
2005.
MVVK05.
T. Mens, P. Van Gorp, D. Varrò, and G. Karsai. Applying a Model Transformation
Taxonomy to Graph Transformation Technology. In Proc. International Workshop
on Graph and Model Transformation (GraMoT’05), volume 152 of ENTCS, pages
143–159. Elsevier, 2005.
Nag79.
Manfred Nagl.
Graph-Grammatiken: Theorie, Anwendungen, Implementierung.
Vieweg, 1979.
New42.
Maxwell Herman Alexander Newman. On theories with a combinatorial deﬁnition of
"equivalence". Annals of Mathematics, 43(2):223–243, 1942.
Obj14a.
Object Management Group. Meta Object Facility (MOF) Core Speciﬁcation Version
2.4.2. http://www.omg.org/spec/MOF/, 2014.
Obj14b.
Object Management Group. Object Constraint Language, Version 2.4, 2014.

464
References
OEP08.
F. Orejas, H. Ehrig, and U. Prange. A Logic of Graph Constraints. In J.L. Fiadeiro
and P. Inverardi, editors, Proc. Fundamental Approaches to Software Engineering
(FASE’08), volume 4961 of LNCS, pages 179–198. Springer, 2008.
OMG14.
Object Management Group. Business Process Model and Notation (BPMN), Version
2.0.2, 2014. formal/2013-12-09, http://www.omg.org/spec/BPMN/2.0.2/.
PE07.
U. Prange and H. Ehrig. From Algebraic Graph Transformation to Adhesive HLR
Categories and Systems. In S. Bozapalidis and G. Rahonis, editors, Algebraic Infor-
matics. Proceedings of CAI 2007, volume 4728 of LNCS, pages 122–146. Springer,
2007.
PEL08.
U. Prange, H. Ehrig, and L. Lambers. Construction and Properties of Adhesive and
Weak Adhesive High-Level Replacement Categories. Applied Categorical Structures,
16(3):365–388, 2008.
Pen08.
K.H. Pennemann.
An Algorithm for Approximating the Satisﬁability Problem of
High-level Conditions. In Proc. International Workshop on Graph Transformation
for Veriﬁcation and Concurrency (GT-VC’07), volume 213 of ENTCS, pages 75–94.
Elsevier Science, 2008.
PLS08.
Heiko Pfeﬀer, David Linner, and Stephan Steglich. Dynamic adaptation of workﬂow
based service compositions. In Proceedings of the 4th international conference on
Intelligent Computing: Advanced Intelligent Computing Theories and Applications -
with Aspects of Theoretical and Methodological Issues (ICIC ’08), pages 763–774.
Springer, 2008.
Plu93.
Detlef Plump. Hypergraph Rewriting: Critical Pairs and Undecidability of Conﬂu-
ence. In Term Graph Rewriting: Theory and Practice, pages 201–213. John Wiley,
1993.
Plu95.
D. Plump. On Termination of Graph Rewriting. In M. Nagl, editor, Graph-Theoretic
Concepts in Computer Science. Proceedings of WG 1995, volume 1017 of LNCS,
pages 88–100. Springer, 1995.
Plu05.
Detlef Plump. Conﬂuence of Graph Transformation Revisited. In Processes, Terms
and Cycles: Steps on the Road to Inﬁnity, volume 3838 of LNCS, pages 280–308.
Springer, 2005.
PM07.
Oscar Pastor and Juan Carlos Molina. Model-Driven Architecture in Practice: A Soft-
ware Production Environment Based on Conceptual Modeling. Springer, 2007.
PR69.
J.L. Pfaltz and A. Rosenfeld. Web grammars. In Proceedings of Int. Joint Conf. on
Artiﬁcial Intelligence 1969, pages 609–620, 1969.
Pra71.
T. W. Pratt.
Pair Grammars, Graph Languages and String-to-Graph Translations.
Journal of Computer and System Sciences, 5:560–595, 1971.
Pra07.
U. Prange. Algebraic High-Level Nets as Weak Adhesive HLR Categories. Electronic
Communications of the EASST, 2:1–13, 2007.
QVT15.
Object Management Group. Meta Object Facility (MOF) 2.0 Query/View/Transfor-
mation Speciﬁcation. Version 1.2, 2015. http://www.omg.org/spec/QVT/1.2/.
RE96.
G. Rozenberg and J. Engelfriet. Elementary Net Systems. In W. Reisig and G. Rozen-
berg, editors, Lectures on Petri Nets I: Basic Models, volume 1491 of LNCS, pages
12–121. Springer, 1996.
Rei85.
Wolfgang Reisig. Petri Nets: An Introduction, volume 4 of EATCS Monographs on
Theoretical Computer Science. Springer, 1985.
RET12.
O. Runge, C. Ermel, and G Taentzer.
AGG 2.0 – new features for specifying
and analyzing algebraic graph transformations. In Andy Schürr, Daniel Varro, and
Gergely Varro, editors, Applications of Graph Transformation with Industrial Rel-
evance, 4th International Symposium, (AGTIVE’11), Proceedings, volume 7233 of
LNCS. Springer, 2012.
RGSS09.
Gabi Dreo Rodosek, Kurt Geihs, Hartmut Schmeck, and Burkhard Stiller.
Self-
healing systems: Foundations and challenges. In Self-Healing and Self-Adaptive Sys-
tems, number 09201 in Dagstuhl Seminar Proceedings. Germany, 2009.
Roz97.
Grzegorz Rozenberg.
Handbook of Graph Grammars and Computing by Graph
Transformations, Volume 1: Foundations. World Scientiﬁc, 1997.

References
465
RRLW09.
Adrian Rutle, Alessandro Rossini, Yngve Lamo, and Uwe Wolter.
A Category-
Theoretical Approach to the Formalisation of Version Control in MDE. In Proc. of
Int. Conf. on Fundamental Approaches to Software Engineering (FASE’09), volume
5503 of LNCS, pages 64–78. Springer, 2009.
RV10.
A. Rensink and P. Van Gorp, editors. International Journal on Software Tools for
Technology Transfer (STTT), Special Section on Graph Transformation Tool Contest
2008, volume 12(3-4). Springer, 2010.
SAB98.
Monique Snoeck, Rakesh Agarwal, and Chiranjit Basu. Enterprise Modelling. In
Serge Demeyer and Jan Bosch, editors, Proc. Workshops at the Europ. Conf. on
Object-Oriented Programming (ECOOP 1998), volume 1543 of Lecture Notes in
Computer Science, pages 222–227. Springer, 1998.
SAL+03.
J. Sprinkle, A. Agrawal, T. Levendovszky, F. Shi, and G. Karsai. Domain model
translation using graph transformations. In Int. Conf. on Engineering of Computer-
Based Systems, pages 159–168, 2003.
Sch94.
A. Schürr. Speciﬁcation of Graph Translators with Triple Graph Grammars. In G. Tin-
hofer, editor, WG94 20th Int. Workshop on Graph-Theoretic Concepts in Computer
Science, volume 903 of Lecture Notes in Computer Science, pages 151–163, Heidel-
berg, 1994. Springer.
Sch06.
D. C. Schmidt. Model-driven engineering. IEEE Computer, 39(2):25–31, 2006.
Sel08.
Bran Selic. MDA manifestations. UPGRADE: The European Journal for Informatics
Professional, IX(2):12–16, 2008.
SK08.
Andy Schürr and Felix Klar. 15 years of triple graph grammars. In Intern. Conf. on
Graph Transformation (ICGT 2008), pages 411–425, 2008.
Ste10.
Perdita Stevens. Bidirectional Model Transformations in QVT: Semantic Issues and
Open Questions. Software and Systems Modeling, 9:7–20, 2010.
Sto04.
H. Stoerrle. Semantics of UML 2.0 activity diagrams. In International Conference
on Visual Languages and Human Centric Computing VLHCC. IEEE, 2004.
SWZ99.
A. Schürr, A. Winter, and A. Zündorf. The PROGRES-approach: Language and en-
vironment. In H. Ehrig, G. Engels, H.-J. Kreowski, and G. Rozenberg, editors, Hand-
book of Graph Grammars and Computing by Graph Transformation, Volume 2: Ap-
plications, Languages and Tools, pages 487 – 550. World Scientiﬁc, 1999.
Sys14.
SysML Open Source Speciﬁcation Project. SysML.org, 2014.
SZK05.
George Spanoudakis, Andrea Zisman, and Alexander Kozlenkov. A service discovery
framework for service centric systems. In Proceedings of the 2005 IEEE International
Conference on Services Computing (SCC ’05), pages 251–259, 2005.
Tae04.
G. Taentzer. AGG: A graph transformation environment for modeling and validation
of software. In J. Pfaltz, M. Nagl, and B. Boehlen, editors, Application of Graph
Transformations with Industrial Relevance (AGTIVE’03), volume 3062 of LNCS,
pages 446 – 456. Springer, Berlin, 2004.
Tae10.
Gabriele Taentzer. What algebraic graph transformations can do for model transfor-
mations. ECEASST, 30, 2010.
TELW10.
G. Taentzer, C. Ermel, P. Langer, and M. Wimmer.
Conﬂict detection for model
versioning based on graph modiﬁcations. In H. Ehrig, A. Rensink, G. Rozenberg, and
A. Schürr, editors, Proc. of Int. Conf. on Graph Transformations (ICGT’10), volume
6372 of LNCS, pages 171–186. Springer, 2010.
TER99.
G. Taentzer, C. Ermel, and M. Rudolf.
The AGG-Approach: Language and Tool
Environment. In H. Ehrig, G. Engels, H.-J. Kreowski, and G. Rozenberg, editors,
Handbook of Graph Grammars and Computing by Graph Transformation, volume 2:
Applications, Languages and Tools, pages 551–603. World Scientiﬁc, 1999.
TV10.
J. Troya and A. Vallecillo.
Towards a rewriting logic semantics for ATL.
In
L. Tratt and M. Gogolla, editors, Proc. of the Intern. Conf. on Model Transforma-
tion (ICMT’10), volume 6142 of LNCS, pages 230–244. Springer, 2010.
UML15.
Object Management Group. Uniﬁed Modeling Language (UML)—Version 2.5, 2015.
http://www.omg.org/spec/UML/.

466
References
Var02.
Dániel Varró. A formal semantics of UML Statecharts by model transition systems.
In Andrea Corradini, Hartmut Ehrig, Hans-Jörg Kreowski, and Grzegorz Rozenberg,
editors, Proc. ICGT 2002: 1st Int. Conf. on Graph Transformation, volume 2505 of
LNCS, pages 378–392. Springer, 2002.
VB07.
Dániel Varró and András Balogh. The model transformation language of the VIA-
TRA2 framework. Science of Computer Programming, 68(3):214–234, 2007.
Ver02.
F. Vernadat. UEML: Towards a Uniﬁed Enterprise Modelling Language. Interna-
tional Journal of Production Research, 40(17):4309 – 4321, 2002.
VGS+05.
Kunal Verma, Karthik Gomadam, Amit P. Sheth, John A. Miller, and Zixin Wu. The
METEOR-S approach for conﬁguring and executing dynamic web processes. Tech-
nical report, University of Georgia, Athens, 2005.
VIA14.
VIATRA2 developers.
VIATRA2 (VIsual Automated model TRAnsformations)
framework http://www.eclipse.org/viatra2/viatra2, 2014.
VMT14.
Budapest University of Technology and Economics, HUN.
Visual Modeling
and Transformation System (VMTS), 2014.
https://www.aut.bme.hu/Pages/
Research/VMTS/Introduction.
VSB+06.
Markus Völter, Thomas Stahl, Jorn Bettin, Arno Haase, and Simon Helsen. Model-
Driven Software Development: Technology, Engineering, Management. John Wiley,
2006.
WHW+06.
Steve R. White, James E. Hanson, Ian Whalley, David M. Chess, Alla Segal, and
Jeﬀrey O. Kephart. Autonomic computing: Architectural approach and prototype.
Integr. Comput.-Aided Eng., 13(2):173–188, 2006.
WTEK08.
J. Winkelmann, G. Taentzer, K. Ehrig, and J. Küster. Translation of Restricted OCL
Constraints into Graph Constraints for Generating Meta Model Instances by Graph
Grammars. ENTCS, 211:159–170, 2008.
WWW04.
WWW Consortium (W3C). XML Schema Part 1: Structures (Second Edition), 2004.
XMI08.
Object Management Group. MOF 2.0 / XMI Mapping Speciﬁcation, 2008. http:
//www.omg.org/technology/documents/formal/xmi.htm.
XSHT11.
Yingfei Xiong, Hui Song, Zhenjiang Hu, and Masato Takeichi. Synchronizing con-
current model updates based on bidirectional transformation. Software and Systems
Modeling, pages 1–16, 2011.

Index
AC consistency, 112
AC schema, 23, 94
satisfaction, 94
additional HLR property, 76
adhesive category, 70
adhesive HLR category, 70
AGraphs, 15
AGraphsATG, 15
almost injective match, 173
amalgamated rule, 34, 146
amalgamated transformation, 147
Amalgamation Theorem, 35
application condition, 17, 95
complement-compatible, 140
conﬂict-inducing, 39
derived, 36, 111
equivalence, 92
extension, 39
S - and T-consistent, 176
special ACs for TGGs, 173
T-extension, 195
translation for model transformation, 175
attributed graph, 15
attributed graph morphism, 15
attributed type graph, 15
basic HLR property, 75
binary coproduct, 76, 407
boundary consistency, 112
bundle, 139
multi-amalgamable, 148
category, 401
adhesive, 70
adhesive HLR, 70
AGraphs, 15
AGraphsATG, 15
Cﬁn, 83
comma, 409
coslice, 403
dual, 403
equivalent, 410
ﬁnitary M-adhesive, 79
functor, 409
general comma, 421
Graphs, 13
GraphsTG, 14
horizontal weak adhesive HLR, 70
isomorphic, 410
M-adhesive, 69
partial map, 72
partial map adhesive, 72
partial van Kampen square adhesive, 73
product, 402
Sets, 402
slice, 402
SubM(T), 128
triple graphs, 172
vertical weak adhesive HLR, 70
weak adhesive HLR, 70
codomain, 401
comma category, 409
compatibility
of concurrent with basic model synchronisa-
tion, 290
complement rule, 32, 142, 144
construction, 142
complement-compatible, 140
complete forward translation sequence, 198
Completeness Theorem, 40, 119
composition and decomposition
for model integration, 201
for TGGs (forward case), 187
Concurrency Theorem, 32, 110
© Springer
2015 
, Monographs in Theoretical
. 
 
 
-Verlag Berlin Heidelberg 
et al.,
H Ehrig
Graph and Model Transformation
Computer Science. An  EATCS Series, DOI 10.1007/978-3-662-47980-3
467

468
Index
concurrent rule, 30, 107
condition, 92
application, 17, 95
graph, 16
satisfaction, 92
conﬂuence, 38, 114
local, 38, 115
strict AC, 41, 120
conservative policy
suﬃcient condition, 242
consistency, 112
match, 185
source, 185
source–target, 201
AC, 112
boundary, 112
consistency creating sequences, 207
consistent matches, 148
constraint, 95
satisfaction, 95
Construction Theorem, 423
creating triple rule, 244
creation
pullbacks, 83
pushouts, 83
critical pair, 39, 119
signiﬁcant, 227
strict AC conﬂuence, 120
weak, 115
cube pushout–pullback property, 75
dependency net, 134
derived application condition, 36, 111
derived span, 36, 111
diagonal property, 87
direct derivation, 129
direct transformation, 17, 95
domain, 401
E′–M′ diagonal property, 87
E′–M′ pair factorisation, 76
strong, 87
E-concurrent rule, 30, 107
E-dependency relation, 30, 107
E-graph, 15
E-graph morphism, 15
E-related, 107
E-related sequence, 30
eﬀective pushout, 77, 88
elementary Petri net, 162
Embedding Theorem, 37, 113
epi–mono factorisation, 404
epi–M factorisation, 76, 86
epimorphism, 404
equivalence
of category, 410
of conditions, 92
of forward transformation and forward
translation sequences, 199
partial map and partial van Kampen square
adhesive categories, 73
PB and PO–PB compatibility, 73
permutation, 125
STS-switch, 132
switch, 124
transformations with and without ﬁlter
NACs, 226
extension diagram, 35
Extension Theorem, 37, 113
extremal E–M factorisation, 80
extremal morphism, 80
factorisation
E′–M′ pair, 76, 87
epi–M, 76, 86
extremal E–M, 80
strong E′–M′ pair, 87
family with translation attributes, 193
ﬁlter constraint, 228
relation to ﬁlter NAC, 228
ﬁlter NAC, 223
ﬁnal object, 408
ﬁnitary M-adhesive categories
additional HLR properties, 82
ﬁnitary M-adhesive category, 79
ﬁnitary restriction, 83
ﬁnite M-intersection, 79
ﬁnite object, 79
ﬁring sequence
transition-complete, 136
ﬂattening
model transformations, 212
properties of construction, 211
TGGs, 212
triple graphs, 209
forward translation rule, 196
functional behaviour
of model transformation, 221
of transformation system, 220
strong, 231
functor, 409
functor category, 409
general comma category, 421
generation of ﬁlter NACs
automated, 224
interactive, 225
gluing condition, 17, 96

Index
469
satisfaction for model transformation, 197
grammar
graph, 25
M-adhesive, 97
M-adhesive with amalgamation, 150
graph, 13
attributed, 15
attributed type, 15
E-, 15
type, 14
typed, 14
typed attributed, 15
graph condition, 16
satisfaction, 16
graph grammar, 25
graph morphism, 13
graph transformation system, 25
Graphs, 13
GraphsTG, 14
hereditary pushout, 72
HLR property
additional, 76
basic, 75
horizontal weak adhesive HLR category, 70
identic triple rule, 244
independence
parallel, 26, 101
parallel amalgamation, 152
parallel bundle, 152
sequential, 26, 102
information preservation, 237
complete, 238
initial object, 408
initial pushout, 76, 88
instantiation
rule, 126
transformation sequence, 126
interaction scheme, 158
inverse rule, 96
isomorphism, 403
of categories, 410
kernel morphism, 140
kernel rule, 140
kernel translation rule, 244
kernel-grounded, 245
language, 25, 97, 150
legal sequence, 133
Local Church–Rosser Theorem, 29, 104
with amalgamation, 156
local conﬂuence, 38, 115
Local Conﬂuence Theorem, 41, 120
M-adhesive category, 69
HLR properties, 75
M-adhesive grammar, 97
with amalgamation, 150
M-adhesive transformation system, 97
with amalgamation, 150
M-initial object, 77
M-intersection, 79
M-pushout–pullback decomposition, 75
M-subobject, 79
M-van Kampen square, 68
match, 17, 95
match consistency, 185
matches
consistent, 148
weakly independent, 148
matching
maximal weakly disjoint, 158
maximal weakly independent, 158
maximal matching
weakly disjoint, 158
weakly independent, 158
maximal weakly disjoint matching, 158
maximal weakly independent matching, 158
merge
over morphism, 20, 93
misleading graph, 222
model integration, 201
model synchronisation
correctness and completeness, 276
model transformation
based on forward rules, 190
based on forward translation rules, 198
equivalence of forward transformation and
forward translation sequences, 199
general concept, 51
monomorphism, 404
morphism, 401
attributed graph, 15
E-graph, 15
extremal, 80
graph, 13
kernel, 140
merge, 20, 93
shift, 20, 92
typed attributed graph, 15
typed graph, 14
multi rule, 140
multi-amalgamable, 148
multi-amalgamated rule, 146
Multi-amalgamation Theorem, 150

470
Index
natural transformation, 409
nested condition, 16, 92
object, 401
ﬁnite, 79
M-initial, 77
M-sub-, 79
operational rules
for model transformation
with application conditions, 178
without application conditions, 178
translation rules for TGGs, 206
parallel amalgamated rule, 154
parallel amalgamation independence, 152
parallel bundle independence, 152
parallel independence, 26, 101
amalgamation, 152
bundle, 152
characterisation, 153
parallel rule, 28, 103
amalgamated, 154
Parallelism Theorem, 29, 104
of maximal weakly independent matchings,
161
with amalgamation, 156
partial map adhesive category, 72
partial map category, 72
partial van Kampen square, 72
partial van Kampen square adhesive category,
73
PB compatibility, 71
permutation equivalence, 125
analysis, 137
PO–PB compatibility, 68
policy for operational translation rules, 241
preservation
pullbacks, 83
pushouts, 83
process of a transformation sequence, 131
property
E′–M′ diagonal, 87
additional HLR, 76
basic HLR, 75
van Kampen, 68
pullback, 406
pushout, 405
eﬀective, 77, 88
hereditary, 72
initial, 76, 88
pushout complement, 406
restriction
ﬁnitary, 83
rule, 17, 95
amalgamated, 34, 146
complement, 32, 142, 144
concurrent, 30, 107
E-concurrent, 30
inverse, 96
kernel, 140
kernel translation, 244
multi, 140
multi-amalgamated, 146
parallel, 28, 103
parallel amalgamated, 154
shift, 96
sub-, 32
weak complement, 144
s-amalgamable, 148
s-multi-amalgamable, 148
SAS-equivalent rules, 317
satisfaction
of AC schema, 94
of condition, 92
of constraint, 95
of graph condition, 16
schema
AC, 23, 94
self-adaptation
veriﬁcation, 317
self-adaptation classes
deﬁnition, 313
properties, 314
self-adaptive properties, 314
self-adaptive system, 310
semantics
for elementary Petri nets, 162
sequential independence, 26, 102
shift
over morphism, 20, 92
over rule, 25, 96
signiﬁcant critical pair, 227
source consistency, 185
source–target consistency, 201
splitting of triple rule
without AC, 181
strict AC conﬂuence, 41, 120
strong E′–M′ pair factorisation, 87
STS equivalence, 133
STS-switch equivalence, 132
SubM(T), 128
intersection, 129
union, 129
union for (AGraphsATG, M), 129
subobject, 128
subobject transformation system

Index
471
construction from transformation sequence,
130
derivation, 129
legal sequence, 133
relations on rules, 131
with NACs, 129
subrule, 32
switch eqivalence, 124
synchronisation
auxiliary TGG operations, 265
concurrent synchronisation framework, 282
concurrent synchronisation problem, 282
derived concurrent TGG synchronisation
framework, 288
derived TGG synchronisation framework,
268
framework, 256
problem, 256
syntactical correctness and completeness
of model integrations, 219
of model transformations, 217
terminating, 39
termination
condition for model transformations, 221
model transformation, 221
model transformation with ﬁlter NACs, 226
TGG
deterministic, 245
kernel-grounded, 245
model framework, 255
pure, 278
tight, 278
Theorem
additional HLR properties of ﬁnitary
M-adhesive categories, 82
Amalgamation, 35
characterisation of model integration, 204
characterisation of parallel independence,
153
compatibility of concurrent with basic
model synchronisation, 291
complement rule, 142
complete information preservation for
model transformations, 239
Completeness, 40, 119
composition and decomposition of model
integration, 202
composition and decomposition of model
transformation, 187
Concurrency, 32, 110
Construction, 423
correctness and completeness for
synchronisation, 276
correctness of concurrent synchronisation,
288
deterministic synchronisation operations,
272
Embedding, 37, 113
equivalence
PB and PO–PB compatibility, 73
equivalence of amalgamated transformation
and ﬁring step, 163
Extension, 37, 113
ﬁnitary restriction, 84
ﬂattening for TGGs, 212
functional behaviour of model transforma-
tions, 230
general properties for model transforma-
tions, 218
HLR properties of M-adhesive category, 75
information preservation for model
transformations, 237
invertibility, 278
Local Church–Rosser, 29, 104
Local Church–Rosser with amalgamation,
156
Local Conﬂuence, 41, 120
model synchronisation
correctness and completeness, 276
Multi-amalgamation, 150
Parallelism, 29, 104
Parallelism of maximal weakly independent
matchings, 161
Parallelism with amalgamation, 156
partial map and partial van Kampen square
adhesive categories, 73
partial van Kampen square adhesive
category, 74
permutation equivalence
analysis based on Petri nets, 137
analysis based on STSs, 133
properties of ﬂattening for TGGs, 212
self-adaptation, 317
self-adaptation classes
properties, 314
strong functional behaviour, 231
syntactical correctness and completeness
of model integration, 219
of model transformations based on forward
rules, 217
of model transformations based on forward
translation rules, 218
triple graphs are M-adhesive, 172
weak invertibility, 278
transformation, 17, 95
amalgamated, 147
natural, 409

472
Index
transformation system
graph, 25
M-adhesive, 97
M-adhesive with amalgamation, 150
transition-complete ﬁring sequence, 136
translation attributes
family, 193
graph, 193
triple graph grammar, 60
triple graphs, 172
base categories, 54
category ATrGraphsATG, 54
triple rule, 56
creating, 244
identic, 244
triple transformation, 56
type graph, 14
attributed, 15
typed attributed graph, 15
typed attributed graph morphism, 15
typed graph, 14
typed graph morphism, 14
unreachable pattern, 227
van Kampen property, 68
van Kampen square, 68
partial, 72
vertical weak adhesive HLR category, 70
weak adhesive HLR category, 70
weak complement rule, 144
weak critical pair, 115
weakly independent matches, 148

