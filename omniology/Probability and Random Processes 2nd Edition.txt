
Probability and
Random Processes
With Applications to Signal Processing
and Communications
Edition 2
Scott L.Miller
Professor
Department of Electrical and Computer Engineering
Texas A&M University
Donald Childers
Professor Emeritus
Department of Electrical and Computer Engineering
University of Florida

Academic Press is an imprint of Elsevier
225 Wyman Street, Waltham, MA 02451, USA
525 B Street, Suite 1900, San Diego, CA 92101-4495, USA
The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, UK 
Radarweg 29, PO Box 211, 1000 AE Amsterdam, The Netherlands
Copyright © 2012, Elsevier Inc. All rights reserved.
No part of this publication may be reproduced or transmitted in any form or by any means, 
electronic or mechanical, including photocopy, recording, or any information storage and retrieval 
system, without permission in writing from the publisher.
Permissions may be sought directly from Elsevier’s Science & Technology Rights Department in 
Oxford, UK: phone: (+44) 1865 843830, fax: (+44) 1865 853333, e-mail: permissions@elsevier.com.uk. 
You may also complete your request on-line via the Elsevier homepage (http://elsevier.com), 
by selecting “Customer Support” and then “Obtaining Permissions.”
Library of Congress Cataloging-in-Publication Data
Application submitted.
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
ISBN: 978-0-12-386981-4
For all information on all Academic Press Publications 
visit our Web site at www.elsevierdirect.com
Printed in the USA
12
13
14
15
16
9
8
7
6
5
4
3
2  1

xi
 Preface
This book is intended to be used as a text for either undergraduate level (junior/senior) courses 
in probability or introductory graduate level courses in random processes that are commonly 
found in Electrical Engineering curricula. While the subject matter is primarily mathematical, 
it is presented for engineers. Mathematics is much like a well crafted hammer. We can hang 
the tool on our wall and step back and admire the fine craftmanship used to construct the 
hammer, or we can pick it up and use it to pound a nail into the wall. Likewise, mathematics 
can be viewed as an art form or a tool. We can marvel at the elegance and rigor, or we can use 
it to solve problems. It is for this latter purpose that the mathematics is presented in this book. 
Instructors will note that there is no discussion of algebras, Borel fields or measure theory in 
this text. It is our belief that the vast majority of engineering problems regarding probability 
and random processes do not require this level of rigor. Rather, we focus on providing the 
student with the tools and skills needed to solve problems. Throughout the text we have gone 
to great effort to strike a balance between readability and sophistication. While the book 
provides enough depth to equip students with the necessary tools to study modern 
communication systems, control systems, signal processing techniques, and many other 
applications, concepts are explained in a clear and simple manner that makes the text 
accessible as well.
It has been our experience that most engineering students need to see how the mathematics 
they are learning relates to engineering practice. Towards that end, we have included 
numerous engineering application sections throughout the text to help the instructor tie the 
probability theory to engineering practice. Many of these application sections focus on various 
aspects of telecommunications since this community is one of the major users of probability 
theory, but there are applications to other fields as well. We feel that this aspect of the text can 
be very useful for accreditation purposes for many institutions. The Accreditation Board for 
Engineering and Technology (ABET) has stated that all electrical engineering programs 
should provide their graduates with a knowledge of probability and statistics including 
applications to electrical engineering. This text provides not only the probability theory, but 
also the applications to electrical engineering and a modest amount of statistics as applied to 
engineering.
A key feature of this text, not found in most texts on probability and random processes, is an 
entire chapter devoted to simulation techniques. With the advent of powerful, low-cost, 
computational facilities, simulations have become an integral part of both academic and 

xii    Preface
industrial research and development. Yet, many students have major misconceptions about 
how to run simulations. Armed with the material presented in our chapter on simulation, we 
believe students can perform simulations with confidence.
It is assumed that the readers of this text have a background consistent with typical junior level 
electrical engineering curricula. In particular, the reader should have a knowledge of 
differential and integral calculus, differential equations, linear algebra, complex variables, 
discrete math (set theory), linear time-invariant systems, and Fourier transform theory. In 
addition, there are a few sections in the text that require the reader to have a background in 
analytic function theory (e.g., parts of Section 4.10), but these sections can be skipped without 
loss of continuity. While some appendices have been provided with a review of some of these 
topics, these presentations are intended to provide a refresher for those who need to “brush up” 
and are not meant to be a substitute for a good course. 
For undergraduate courses in probability and random variables, we recommend instructors 
cover the following sections: 
Chapters 1-3: all sections, 
Chapter 4: sections 1-6, 
Chapter 5: sections 1-7 and 9, 
Chapter 6: sections 1-3, 
Chapter 7: sections 1-5. 
These sections, along with selected application sections, could be covered in a one semester 
course with a comfortable pace. For those using this text in graduate courses in random 
processes, we recommend that instructors briefly review Chapters 1-7 focussing on those 
concepts not typically taught in an undergraduate course (e.g., 4.7-4.10, 5.8, 5.10, 6.4-6.5, and 
7.6) and then cover selected topics of interest from Chapters 8-12. 
We consider the contents of this text to be appropriate background material for such follow-on 
courses as Digital Communications, Information Theory, Coding Theory, Image Processing, 
Speech Analysis, Synthesis and Recognition, and similar courses that are commonly found in 
many undergraduate and graduate programs in Electrical Engineering. Where possible, we 
have included engineering application examples from some of these topics.

1
CHAPTER 1
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00001-2
© 2012 by Elsevier Inc. All rights reserved.
Introduction
The study of probability, random variables, and random processes is fundamental to a wide
range of disciplines. For example, many concepts of basic probability can be motivated
through the study of games of chance. Indeed, the foundations of probability theory were
originally built by a mathematical study of games of chance. Today, a huge gambling industry
is built on a foundation of probability. Casinos have carefully designed games that allow the
players to win just enough to keep them hooked, while keeping the odds balanced slightly in
favor of the “house.” By nature, the outcomes of these games are random, but the casino
owners fully understand that as long as the players keep playing, the theory of probability
guarantees—with very high probability—that the casino will always come out ahead.
Likewise, those playing the games may be able to increase their chances of winning by
understanding and using probability.
In another application of probability theory, stock investors spend a great deal of time and
effort trying to predict the random fluctuations in the market. Day traders try to take advantage
of the random fluctuations that occur on a daily basis, while long-term investors try to benefit
from the gradual trends that unfold over a much longer time period. These trends and
fluctuations are random in nature and can only be described in a probabilistic fashion. Another
business built on managing random occurrences is the insurance industry. Insurance premiums
are calculated based on a careful study of the probabilities of various events happening. For
example, the car insurance salesmen have carefully evaluated the inherent risk of various
classes of drivers and will adjust the premiums of each class according to the probabilities that
those drivers will have an accident. In yet another application of probability theory, a
meteorologist tries to predict future weather events based on current and past meteorological
conditions. Since these events are quite random, the weather forecast will often be presented in
terms of probabilities (e.g., there is a 40% chance, or probability, of rain on Tuesday).
Since the theory of probability and random processes finds such a wide range of applications,
students require various levels of understanding depending on the particular field they are
preparing to enter. For those who wish to improve their proficiency at card games, a firm
understanding of discrete probability may be sufficient. Those going into operations
management need to understand queueing theory and therefore Markov and related random
processes. A telecommunications engineer needs to have a firm understanding of models of
noise and the design of systems to minimize the effects of noise.

2
Chapter 1
www.Academicpress.com
This book is not intended to serve the needs of all disciplines, but rather is focused on
preparing the students entering the fields of electrical and computer engineering. One of the
main goals of the text is to prepare the student to study random signals and systems. This
material is fundamental to the study of digital signal processing (voice, image, video, etc.),
communications systems and networks, radar systems, power systems, and many other
applications within the engineering community. With this readership in mind, a background
which is consistent with most electrical and computer engineering curricula is assumed. That
is, in addition to fundamental mathematics including calculus, differential equations, linear
algebra, and complex variables, the student is assumed to be familiar with the study of
deterministic signals and systems. We understand that some readers may be very strong in
these areas, while others may need to “brush up.” Accordingly, we have included a few
appendices which may help those that need a refresher and also provide a quick reference for
significant results.
Throughout the text, the reader will find many examples and exercises which utilize
MATLAB. MATLAB is a registered trademark of the MathWorks, Inc.; it is a technical
software computing environment. Our purpose for introducing computer-based examples and
problems is to expand our capabilities so that we may solve problems that might be too tedious
or complex to do via hand calculations. Furthermore, MATLAB has nice plotting capabilities
that can greatly assist the visualization of data. MATLAB is used extensively in practice
throughout the engineering community; therefore, we feel it is useful for engineering students
to gain exposure to this important software package. Examples in the text which use
MATLAB are clearly marked with a small computer logo.
Before diving into the theory of discrete probability in the next chapter, we first provide a few
illustrations of how the theory of probability and random processes is used in a few engineering
applications. At the end of each subsequent chapter, the reader will find engineering application
sections which illustrate how the material presented in that chapter is used in the real world.
These sections can be skipped without losing any continuity, but we recommend that the reader
at least skim through the material.
1.1 A Speech Recognition System
Many researchers are working on methods for computer recognition of speech. One
application is to recognize commands spoken to a computer. Such systems are presently
available from several vendors. A simple speech recognition system might use a procedure
called template matching, which may be described as follows. We define a vocabulary, or a set
of possible words for a computerized dictionary. This restricts the number of possible
alternatives that must be recognized. Then a template for each word is obtained by digitizing
the word as it is spoken. A simple dictionary of such templates is shown in Figure 1.1. The
template may be the time waveform, the spectrum of the word, or a vector of selected features

Introduction
3
www.Academicpress.com
of the word. Common features might include the envelope of the time waveform, the energy,
the number of zero crossings within a specified interval, and the like.
Speech recognition is a complicated task. Factors that make this task so difficult include
interference from the surroundings, variability in the amplitude and duration of the spoken
word, changes in other characteristics of the spoken word such as the speaker’s pitch, and the
size of the dictionary to name a few. In Figure 1.2, we have illustrated some of the variability
that may occur when various talkers speak the same word. Here, we see that the waveform
templates may vary considerably from speaker to speaker. This variability may be described
Vocabulary
Template
Hello
Yes
No
Bye
Figure 1.1
A simple dictionary of speech templates for speech recognition.
Vocabulary
Hello
Yes
No
Bye
Speaker 1
(male)
Speaker 2
(male)
Speaker 3
(female)
Templates
Speaker 4
(child)
Figure 1.2
Variations in speech templates for different speakers.

4
Chapter 1
www.Academicpress.com
by the theory of probability and random processes, which in turn may be used to develop
models for speech production and recognition. Such models may then be used to design
systems for speech recognition.
1.2 A Radar System
A classical problem drawing heavily on the theory of probability and random processes is that of
signal detection and estimation. One example of such a problem is a simple radar system, such as
might be used at an airport to track local air traffic. A known signal is converted to an
electromagnetic wave and propagated via an antenna. This wave will reflect off an aircraft and
return back to the antenna (as illustrated in Figure 1.3), where the signal is processed to gather
information about the aircraft. In addition to being corrupted by a random noise and interference
process, the returning signal itself may exhibit randomness as well. First, we must determine if
there is a reflected signal present. Usually, we attempt to maximize the probability of correctly
detecting an aircraft subject to a certain level of false alarms. Once we decide that the aircraft is
there, we attempt to estimate various random parameters of the reflected signal to obtain
information about the aircraft. From the time of arrival of the reflected signal, we can estimate
the distance of the aircraft from the radar site. The frequency of the returned signal will indicate
the speed of the aircraft. Since the desired signal is corrupted by noise and interference, we can
never estimate these various parameters exactly. Given sufficiently accurate models for these
random disturbances, however, we can devise procedures for providing the most accurate
estimates possible. We can also use the theory of probability and random processes to analyze
the performance of our system.
1.3 A Communication Network
Consider a node in a computer communication network, such as depicted in Figure 1.4, that
receives packets of information from various sources and must forward them along toward
their ultimate destinations. Typically, the node has a fixed, or at least a maximum, rate at
Figure 1.3
A radar system.

Introduction
5
www.Academicpress.com
which it can transmit data. Since the arrival of packets to a node will be quite random, the node
will usually have some buffering capability, allowing the node to temporarily store packets
which it cannot forward immediately. Given a random model of the arrival process of packets
at a node, the theory of probability and random processes developed in this text will allow the
network designer to determine how large a buffer is needed to insure a minimal probability of
buffer overflow (and a resulting loss of information). Or, conversely, given a set buffer size, a
limit on the amount of traffic (i.e., throughput) that the node can handle can be determined.
Other random quantities such as the delay a packet encounters at the node can also be
statistically characterized.
On a less local basis, when information is generated at one of the nodes with a specified
destination, a route must be determined to get the packet from the source to the destination.
Some nodes in the network may be more congested than others. Congestion throughout the
network tends to be very dynamic and so the routing decision must be made using
probability. Which route should the packet follow so that it is least likely to be dropped along
the way? Or, maybe we want to find the path that will lead to the smallest average delay.
Protocols for routing, flow control, and the likes are all based in the foundations of
probability theory.
These few examples illustrate the diversity of problems that probability and random processes
may model and thereby assist in the development of effective design solutions. By firmly
understanding the concepts in this text, the reader will open up a vast world of engineering
applications.
Figure 1.4
Nodes and links in a communications network.

7
CHAPTER 2
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00002-4
© 2012 by Elsevier Inc. All rights reserved.
Introduction to Probability Theory
Many electrical engineering students have studied, analyzed, and designed systems from the point
of view of steady-state and transient signals using time domain or frequency domain techniques.
However, these techniques do not provide a method for accounting for variability in the signal nor
for unwanted disturbances such as interference and noise. We will see that the theory of
probability and random processes is useful for modeling the uncertainty of various events (e.g., the
arrival of telephone calls and the failure of electronic components). We also know that the
performance of many systems is adversely affected by noise, which may often be present in the
form of an undesired signal that degrades the performance of the system. Thus, it becomes
necessary to design systems that can discriminate against noise and enhance a desired signal.
How do we distinguish between a deterministic signal or function and a stochastic or random
phenomenon such as noise? Usually, noise is defined to be any undesired signal, which often
occurs in the presence of a desired signal. This definition includes deterministic as well as
non-deterministic signals. A deterministic signal is one which may be represented by some
parameter values, such as a sinusoid, which may be perfectly reconstructed given an amplitude,
frequency, and phase. Stochastic signals, such as noise, do not have this property. While they
may be approximately represented by several parameters, stochastic signals have an element of
randomness which prevent them from being perfectly reconstructed from a past history. As we
saw in Chapter 1 (Figure 1.2), even the same word spoken by different speakers is not
deterministic; there is variability, which can be modeled as a random fluctuation. Likewise, the
amplitude and/or phase of a stochastic signal cannot be calculated for any specified future time
instant even though the entire past history of the signal may be known. However, the amplitude
and/or phase of a stochastic signal can be predicted to occur with a specified probability,
provided certain factors are known. The theory of probability provides a tool to model and
analyze phenomena that occur in many diverse fields, such as communications, signal
processing, control, and computers. Perhaps the major reason for studying probability and
random processes is to be able to model complex systems and phenomena.
2.1 Experiments, Sample Spaces, and Events
The relationship between probability and gambling has been known for some time. Over the
years, some famous scientists and mathematicians have devoted time to probability: Galileo
wrote on dice games; Laplace worked out the probabilities of some gambling games; and

8
Chapter 2
www.Academicpress.com
Pascal and Bernoulli, while studying games of chance, contributed to the basic theory of
probability. Since the time of this early work, the theory of probability has become a highly
developed branch of mathematics. Throughout these beginning sections on basic
probability theory, we will often use games of chance to illustrate basic ideas that will form
the foundation for more advanced concepts. To start with, a few simple definitions are
presented.
Definition 2.1: An experiment is a procedure we perform (quite often hypothetical)
that produces some result. Often the letter
is used to designate an experiment (e.g.,
the experiment
might consist of tossing a coin five times).
Definition 2.2: An outcome is a possible result of an experiment. The Greek letter xi
( ) is often used to represent outcomes (e.g., the outcome
of experiment
might
represent the sequence of tosses heads-heads-tails-heads-tails; however, the more con-
cise HHTHT might also be used).
Definition 2.3: An event is a certain set of outcomes of an experiment (e.g., the event
associated with experiment
might be
= {all outcomes consisting of an even
number of heads}).
Definition 2.4: The sample space is the collection or set of “all possible” distinct
(collectively exhaustive and mutually exclusive) outcomes of an experiment. The
letter
is used to designate the sample space, which is the universal set of outcomes
of an experiment. A sample space is called discrete if it is a finite or a countably
infinite set. It is called continuous or a continuum otherwise.
The reason we have placed quotes about the words all possible in Definition 2.4 is explained
by the following imaginary situation. Suppose we conduct the experiment of tossing a coin.
While it is conceivable that the coin may land on edge, experience has shown us that such a
result is highly unlikely to occur. Therefore, our sample space for such experiments typically
excludes such unlikely outcomes. We also require, for the present, that all outcomes be
distinct. Consequently, we are considering only the set of simple outcomes that are
collectively exhaustive and mutually exclusive.
Example 2.1:
Consider the example of flipping a fair coin once, where fair means that the coin is
not biased in weight to a particular side. There are two possible outcomes, namely, a
head or a tail. Thus, the sample space,
, consists of two outcomes,
to indicate
that the outcome of the coin toss was heads, and
to indicate that the outcome of
the coin toss was tails.
E
E5
ξ
ξ1
E5
C
E5
C
S
S
ξ1
H
=
ξ2
T
=



Introduction to Probability Theory
9
www.Academicpress.com
Example 2.2:
A cubical die with numbered faces is rolled and the result observed. The sample space
consists of six possible outcomes
,
, . . . ,
, indicating the possible
faces of the cubical die that may be observed.
Example 2.3:
As a third example, consider the experiment of rolling two dice and observing the results.
The sample space consists of 36 outcomes, which may be labeled by the ordered pairs
,
,
, . . . ,
,
,
, . . . ,
; the first component in the ordered pair indicates the result of the toss of the
first die and the second component indicates the result of the toss of the second die.
Many events can be defined from this experiment, such as:
= {the sum of the outcomes of the two rolls = 4},
= {the outcomes of the two rolls are identical},
= {the first roll was bigger than the second}.
An alternative way to consider this experiment is to imagine that we conduct two distinct
experiments, with each consisting of rolling a single die. The sample spaces (
and
)
for each of the two experiments are identical, namely, the same as Example 2.2. We may
now consider the sample space,
, of the original experiment to be the combination of
the sample spaces,
and
, which consist of all possible combinations of the elements
of both
and
. This is an example of a combined sample space.
Example 2.4:
For our fourth experiment, let us flip a coin until a tails occurs. The experiment is then
terminated. The sample space consists of a collection of sequences of coin tosses. Label
these outcomes as
,
. The final toss in any particular sequence is a tail
and terminates the sequence. The preceding tosses prior to the occurrence of the tail
must be heads. The possible outcomes that may occur are:
,
,
, ... .
Note that in this case,
can extend to infinity. This is another example of a combined
sample space resulting from conducting independent, but identical experiments. In this
example, the sample space is countably infinite, while the previous sample spaces were
finite.
ξ1
1
=
ξ2
2
=
ξ6
6
=
x1
1 1
,
(
)
=
x2
1 2
,
(
)
=
ξ3
1 3
,
(
)
=
x6
1 6
,
(
)
=
x7
2 1
,
(
)
=
x8
2 2
,
(
)
=
x36
6 6
,
(
)
=
A
B
C
S1
S2
S
S1
S2
S1
S2
xn
n
1 2 3 …
, , ,
=
x1
T
( )
=
x2
H T
,
(
)
=
x3
H H T
,
,
(
)
=
n







10
Chapter 2
www.Academicpress.com
Example 2.5:
As a last example, consider a random number generator which selects a number in an
arbitrary manner from the semi-closed interval
. The sample space consists of all
real numbers,
, for which
. This is an example of an experiment with a continuous
sample space. We can define events on a continuous space as well, such as:
,
,
.
Other examples of experiments with continuous sample spaces include the measurement
of the voltage of thermal noise in a resistor or the measurement of the
position of
an oxygen molecule in the atmosphere. Examples 2.1-2.4 illustrate discrete sample
spaces.
There are also infinite sets that are uncountable and that are not continuous, but these sets are
beyond the scope of this book. So for our purposes, we will consider only the preceding two
types of sample spaces. It is also possible to have a sample space that is a mixture of discrete
and continuous sample spaces. For the remainder of this chapter, we shall restrict ourselves to
the study of discrete sample spaces.
A particular experiment can often be represented by more than one sample space. The choice
of a particular sample space depends upon the questions that are to be answered concerning
the experiment. This is perhaps best explained by recalling Example 2.3 in which a pair of dice
was rolled. Suppose we were asked to record after each roll the sum of the numbers shown on
the two faces. Then, the sample space could be represented by only eleven outcomes,
,
,
, . . .,
. However, the original sample space is in some way, more
fundamental, since the sum of the die faces can be determined from the numbers on the die
faces. If the second representation is used, it is not sufficient to specify the sequence of
numbers that occurred from the sum of the numbers.
2.2 Axioms of Probability
Now that the concepts of experiments, outcomes, and events have been introduced, the next
step is to assign probabilities to various outcomes and events. This requires a careful definition
of probability. The words probability and probable are commonly used in everyday language.
The meteorologist on the evening news may say that rain is probable for tomorrow or he may
be more specific and state that the chance (or probability) of rain is 70%. Although this sounds
like a precise statement, we could interpret it in several ways. Perhaps, it means that about
70% of the listening audience will experience rain. Or, maybe if tomorrow could be repeated
many times, 70% of the tomorrows would have rain while the other 30% would not. Of course,
0 1)
,
[
x
0
x
1
<
≤
A
x
1 2
⁄
<
{
}
=
B
x
1 2
⁄
–
1 4
⁄
<
{
}
=
C
x
1 2
⁄
=
{
}
=
x y z
, ,
(
)
x1
2
=
x2
3
=
x3
4
=
x11
12
=



Introduction to Probability Theory
11
www.Academicpress.com
tomorrow cannot be repeated and this experiment can only be run once. The outcome will be
either rain or no rain. The meteorologist may like this interpretation since there is no way to
repeat the experiment enough times to test the accuracy of the prediction. However, there is a
similar interpretation that can be tested. We might say that any time a day with similar
meteorological conditions presents itself, the following day will have rain 70% of the time. In
fact, it may be his or her past experience with the given weather conditions that led the
meteorologist to the prediction of a 70% chance of rain.
It should be clear from our everyday usage of the word probability that it is a measure of the
likelihood of various events. So in general terms, probability is a function of an event that
produces a numerical quantity that measures the likelihood of that event. There are many ways
to define such a function, which we could then call probability. In fact, we will find several
ways to assign probabilities to various events, depending on the situation. Before we do that,
however, we start with three axioms that any method for assigning probabilities must satisfy:
Axiom 2.1: For any event
,
(a negative probability does not make sense).
Axiom 2.2: If
is the sample space for a given experiment,
(probabilities
are normalized so that the maximum value is unity).
Axiom 2.3a: If
, then
.
As the word axiom implies, these statements are taken to be self-evident and require no proof.
In fact, the first two axioms are really more of a self-imposed convention. We could have
allowed for probabilities to be negative or we could have normalized the maximum probability
to be something other than one. However, this would have greatly confused the subject and we
do not consider these possibilities. From these axioms (plus one more to be presented shortly),
the entire theory of probability can be developed. Before moving on to that task, a corollary to
Axiom 2.3a is given.
Corollary 2.1: Consider
sets
which are mutually exclusive,
for all
,
.
(2.1)
Proof: This statement can be proven using mathematical induction. For those students
who are unfamiliar with this concept, the idea behind induction is to show that if the
statement is true for
, then it must also hold for
. Once this is
A Pr A
(
)
0
≥
S
Pr S
( )
1
=
A
B
∩
∅
=
Pr A
B
∪
(
)
Pr A
(
)
Pr B
( )
+
=
M
A1 A2 … AM
,
,
,
Ai
A j
∩
∅
=
i
j
≠
Pr
Ai
i
1
=
M∪
⎝
⎠
⎜
⎟
⎛
⎞
Pr Ai
(
)
i
1
=
M
∑
=
M
m
=
M
m
1
+
=

12
Chapter 2
www.Academicpress.com
established, it is noted that by Axiom 2.3a, the statement applies for
, and hence
it must be true for
. Since it is true for
, it must also be true for
,
and so on. In this way, we can prove that Corollary 2.1 is true for any finite
. The
details of this proof are left as an exercise for the reader (see Exercise 2.7). 
Unfortunately, the proof just outlined is not sufficient to show that Corollary 2.1 is true for the
case of an infinite number of sets. That has to be accepted on faith and is listed here as the
second part of Axiom 2.3.
Axiom 2.3b: For an infinite number of mutually exclusive sets,
,
,
for all
,
.
(2.2)
It should be noted that Axiom 2.3a and Corollary 2.1 could be viewed as special cases of
Axiom 2.3b. So, a more concise development could be obtained by starting with Axioms 2.1,
2.2, and 2.3b. This may be more pleasing to some, but we believe the approach given here is
little easier to follow for the student learning the material for the first time.
The preceding axioms do not tell us directly how to deal with the probability of the union of
two sets that are not mutually exclusive. This can be determined from these axioms as is now
shown.
Theorem 2.1: For any sets
and
(not necessarily mutually exclusive),
.
(2.3)
Proof: We give a visual proof of this important result using the Venn diagram shown
in Figure 2.1. To aid the student in the type of reasoning needed to complete proofs of
this type, it is helpful to think of a pile of sand lying in the sample space shown in
Figure 2.1. The probability of the event
would then be analogous to the mass of that
subset of the sand pile that is above the region
and likewise for the probability of
the event
. For the union of the two events, if we simply added the mass of the sand
above
to the mass of the sand above
, we would double count that region which is
common to both sets. Hence, it is necessary to subtract the probability of
. We
freely admit that this proof is not very rigorous. It is possible to prove Theorem 2.1
without having to call on our sand analogy or even the use of Venn diagrams. The
logic of the proof will closely follow what we have done here. The reader is led
through that proof in Exercise 2.8.
M
2
=
M
3
=
M
3
=
M
4
=
M
Ai i
1 2 3…
, ,
=
Ai
A j
∩
∅
=
i
j
≠
Pr
Ai
i
1
=
∞∪
⎝
⎠
⎜
⎟
⎛
⎞
Pr Ai
(
)
i
1
=
∞∑
=
A
B
Pr A
B
∪
(
)
Pr A
(
)
Pr B
( )
Pr A
B
∩
(
)
–
+
=
A
A
B
A
B
A
B
∩

Introduction to Probability Theory
13
www.Academicpress.com
Many other fundamental results can also be obtained from the basic axioms of probability.
A few simple ones are presented here. More will be developed later in this chapter and in
subsequent chapters. As with Theorem 2.1, it might help the student to visualize these
proofs by drawing a Venn diagram.
Theorem 2.2:
.
Proof:
(by Axiom 2.2)
(by Axiom 2.3a)
. 
Theorem 2.3: If
, then
.
Proof: See Exercise 2.10. 
2.3 Assigning Probabilities
In the previous section, probability was defined as a measure of the likelihood of an event or of
events which satisfy Axioms 2.1-2.3. How probabilities are assigned to particular events was
not specified. Mathematically, any assignment that satisfies the given axioms is acceptable.
Practically speaking, we would like to assign probabilities to events in such a way that the
probability assignment actually represents the likelihood of occurrence of that event. Two
techniques are typically used for this purpose and are described in the following paragraphs.
In many experiments, it is possible to specify all of the outcomes of the experiment in terms of
some fundamental outcomes which we refer to as atomic outcomes. These are the most basic
S
A
B
A
B
∩
Figure 2.1
Venn diagram for proof of Theorem 2.1.
Pr A
(
)
1
Pr A
(
)
–
=
1
Pr S
( )
Pr A
A
∪
(
)
=
=
Pr A
(
)
Pr A
(
)
+
=
Pr A
(
)
∴
1
Pr A
(
)
–
=
A
B
⊂
Pr A
(
)
Pr B
( )
≤

14
Chapter 2
www.Academicpress.com
events that cannot be decomposed into simpler events. From these atomic outcomes, we can
build more complicated and more interesting events. Quite often we can justify assigning equal
probabilities to all atomic outcomes in an experiment. In that case, if there are
mutually
exclusive exhaustive atomic events, then each one should be assigned a probability of
.
Not only does this make perfect common sense, it also satisfies the mathematical requirements
of the three axioms which define probability. To see this, we label the
atomic outcomes of
an experiment
as
,
, . . .,
. These atomic events are taken to be mutually exclusive
and exhaustive. That is,
for all
, and
. Then by
Corollary 2.1 and Axiom 2.2,
.
(2.4)
If each atomic outcome is to be equally probable, then we must assign each a probability of
for there to be equality in the preceding equation. Once the probabilities of
these outcomes are assigned, the probabilities of some more complicated events can be
determined according to the rules set forth in Section 2.2. This approach to assigning
probabilities is referred to as the classical approach.
Example 2.6:
The simplest example of this procedure is the coin flipping experiment of Example 2.1. In
this case, there are only two atomic events,
and
. Provided the coin is fair
(again, not biased toward one side or the other), we have every reason to believe that
these two events should be equally probable. These outcomes are mutually exclusive and
collectively exhaustive (provided we rule out the possibility of the coin landing on end).
According to our theory of probability, these events should be assigned probabilities of
.
Example 2.7:
Next consider the dice rolling experiment of Example 2.2. If the die is not loaded, the six
possible faces of the cubicle die are reasonably taken to be equally likely to appear, in
which case, the probability assignment is
. From this
assignment, we can determine the probability of more complicated events, such as:
(by Corollary 2.1)
(by probability assignment)
.
M
1 M
⁄
M
E
x1 x2
xM
xi
x j
∩
∅
=
i
j
≠
x1
x2
…
xM
∪
∪
∪
S
=
Pr x1
x2
…
xM
∪
∪
∪
(
)
Pr x1
(
)
Pr x2
(
)
…
Pr xM
(
)
+
+
+
Pr S
( )
1
=
=
=
Pr xi
(
)
1 M
⁄
=
x1
H
=
x2
T
=
Pr H
(
)
Pr T
( )
1 2
⁄
=
=
Pr 1
( )
Pr 2
( )
…
Pr 6
( )
1 6
⁄
=
=
=
=
Pr even number is rolled
(
)
Pr 2
4
6
∪
∪
(
)
=
Pr 2
( )
Pr 4
( )
Pr 6
( )
+
+
=
1 6
⁄
1 6
⁄
1 6
⁄
+
+
=
1 2
⁄
=





Introduction to Probability Theory
15
www.Academicpress.com
Example 2.8:
In Example 2.3, a pair of dice were rolled. In this experiment, the most basic outcomes
are the 36 different combinations of the six atomic outcomes of the previous example.
Again, each of these atomic outcomes is assigned a probability of 1/36. Next, suppose
we want to find the probability of the event
. Then,
(by Corollary 2.1)
(by probability assignment)
.
Example 2.9:
In this example, we will use the MATLAB command rand to simulate the
flipping of coins and the rolling of dice. The command rand (m,n)
creates a matrix of m rows and n columns where each element of the
matrix is a randomly selected number equally likely to fall anywhere in the
interval
. By rounding this number to the nearest integer, we can
create a randomly selected number equally likely to be 0 or 1. This can be used to
simulate the flipping of a coin if we interpret 0 as “tails” and 1 as “heads” or vice versa.
Similarly, if we multiply rand(1) by 6 and round up to the nearest integer, we will get one
of the numbers 1,2,...,6 with equal probability. This can be used to simulate the rolling
of a die. Try running the following script in MATLAB.
%  Simulation of coin flipping and die tossing.
coin_flip=round(rand(1))
% simulate flip of a coin.
die_toss=ceil(6*rand(1))
% simulate toss of one die.
dice_toss=ceil(6*rand(1,2))
% simulate toss of two dice.
You should find that each time you run this script, you get different (random) looking
results. With any MATLAB command, if you want more information on what the
command does, type help followed by the command name at the MATLAB prompt
for detailed information on that command. For example, to get help on the rand
command, type help rand.
Care must be taken when using the classical approach to assigning probabilities. If we define
the set of atomic outcomes incorrectly, unsatisfactory results may occur. In Example 2.8, we
may be tempted to define the set of atomic outcomes as the different sums that can occur on
the two dice faces. If we assign equally likely probability to each of these outcomes, then we
arrive at the assignment
.
(2.5)
A
sum of two dice = 5
{
}
=
Pr A
(
)
Pr
1 4
,
(
)
2 3
,
(
)
3 2
,
(
)
4 1
,
(
)
∪
∪
∪
(
)
=
Pr 1 4
,
(
)
Pr 2 3
,
(
)
Pr 3 2
,
(
)
Pr 4 1
,
(
)
+
+
+
=
1 36
⁄
1 36
⁄
1 36
⁄
1 36
⁄
+
+
+
=
1 9
⁄
=
0 1
,
(
)
Pr sum=2
(
)
Pr sum=3
(
)
…
Pr sum=12
(
)
1 11
⁄
=
=
=
=





16
Chapter 2
www.Academicpress.com
Anyone with experience in games involving dice knows that the likelihood of rolling a 2 is
much less than the likelihood of rolling a 7. The problem here is that the atomic events we
have assigned are not the most basic outcomes and can be decomposed into simpler outcomes
as demonstrated in Example 2.8.
This is not the only problem encountered in the classical approach. Suppose we consider an
experiment that consists of measuring the height of an arbitrarily chosen student in your class
and rounding that measurement to the nearest inch. The atomic outcomes of this experiment
would consist of all the heights of the students in your class. However, it would not be
reasonable to assign an equal probability to each height. Those heights corresponding to very
tall or very short students would be expected to be less probable than those heights
corresponding to a medium height. So, how then do we assign probabilities to these events?
The problems associated with the classical approach to assigning probabilities can be
overcome by using the relative frequency approach.
The relative frequency approach requires that the experiment we are concerned with be
repeatable, in which case, the probability of an event,
, can be assigned by repeating the
experiment a large number of times and observing how many times the event
actually occurred.
If we let
be the number of times the experiment is repeated and
the number of times the
event
is observed, then the probability of the event
can be assigned according to
.
(2.6)
This approach to assigning probability is based on experimental results and thus has a more
practical flavor to it. It is left as an exercise for the reader (see Exercise 2.15) to confirm that this
method does indeed satisfy the axioms of probability, and is thereby mathematically correct as well.
Example 2.10:
Consider the dice rolling experiment of Examples 2.3 and 2.8. We will use the relative
frequency approach to assign the probability of the event
. We
simulated the tossing of two dice using the following MATLAB code. The results of this
dice tossing simulation are shown in Table 2.1.
Table 2.1: Simulation of Dice Tossing Experiment
1000
2000
3000
4000
5000
6000
7000
8000
9000
10,000
96
200
314
408
521
630
751
859
970
1095
0.096
0.100
0.105
0.102
0.104
0.105
0.107
0.107
0.108
0.110
A
A
n
nA
A
A
Pr A
(
)
nA
n------
n
∞
→
lim
=
A
sum of two dice = 5
{
}
=
n
nA
nA n
⁄


Introduction to Probability Theory
17
www.Academicpress.com
%  Simulation code for dice tossing experiment.
n=1000;
% number of times to toss the dice.
die1=ceil(6*rand(1,n));
% Toss first die n times.
die2=ceil(6*rand(1,n));
% Toss second die n times.
dice_sum=die1+die2;
% Compute sum of two tosses.
nA=sum(dice_sum==5);
% Count number of times sum = 5;
pA=nA/n
% Display relative frequency.
The next to last line of MATLAB code may need some explanation. The double equal sign
asks MATLAB to compare the two quantities to see if they are equal. MATLAB responds
with 1 for “yes” and 0 for “no.” Hence, the expression dice_sum==5 results in an n ele-
ment vector where each element of the vector is either 0 or 1 depending on whether the corre-
sponding element of dice_sum is equal to 5 or not. By summing all elements of this
vector, we obtain the number of times the sum 5 occurs in n tosses of the dice.
To get an exact measure of the probability of an event, we must be able to repeat the event an
infinite number of times—a serious drawback to this approach. In the dice rolling experiment
of Example 2.8, even after rolling the dice 10,000 times, the probability of observing a 5 was
measured to only two significant digits. Furthermore, many random phenomena in which we
might be interested are not repeatable. The situation may occur only once, and therefore we
cannot assign the probability according to the relative frequency approach.
2.4
Joint and Conditional Probabilities
Suppose that we have two events,
and
. We saw a few results in the previous section that
dealt with how to calculate the probability of the union of two events,
. At least as
frequently, we are interested in calculating the probability of the intersection of two events,
. This probability is referred to as the joint probability of the events
and
,
. Usually, we will use the simpler notation
. This definition and notation
extends to an arbitrary number of sets. The joint probability of the events,
, is
and we use the simpler notation
to represent the
same quantity.
Now that we have established what a joint probability is, how does one compute it? To start
with, by comparing Axiom 2.3a and Theorem 2.1, it is clear that if
and
are mutually
exclusive, then their joint probability is zero. This is intuitively pleasing, since if
and
are
mutually exclusive, then
, which we would expect to be zero. That is, an
impossible event should never happen. Of course, this case is of rather limited interest, and we
would be much more interested in calculating the joint probability of events that are not
mutually exclusive.
In the general case when
and
are not necessarily mutually exclusive, how can we
calculate the joint probability of
and
? From the general theory of probability, we can
A
B
A
B
∪
A
B
∩
A
B
Pr A
B
∩
(
)
Pr A B
,
(
)
A1 A2 … AM
,
,
,
Pr A1
A2
…
AM
∩
∩
∩
(
)
Pr A1 A2 … AM
,
,
,
(
)
A
B
A
B
Pr A B
,
(
)
Pr ∅
(
)
=
A
B
A
B


18
Chapter 2
www.Academicpress.com
easily see two ways to accomplish this. First, we can use the classical approach. Both events
and
can be expressed in terms of atomic outcomes. We then write
as the set of
those atomic outcomes that are common to both and calculate the probabilities of each of these
outcomes. Alternatively, we can use the relative frequency approach. Let
be the
number of times that
and
simultaneously occur in
trials. Then,
.
(2.7)
Example 2.11:
A standard deck of playing cards has 52 cards that can be divided in several manners.
There are four suits (spades, hearts, diamonds and clubs) each of which has 13 cards
(ace, 2, 3, 4,. . ., 10, jack, queen, king). There are two red suits (hearts and diamonds)
and two black suits (spades and clubs). Also, the jacks, queens and kings are referred to
as face cards, while the others are number cards. Suppose the cards are sufficiently
shuffled (randomized) and one card is drawn from the deck. The experiment has 52
atomic outcomes corresponding to the 52 individual cards that could have been selected.
Hence, each atomic outcome has a probability of 1/52. Define the events:
,
, and
. Since the event
consists of 26 atomic outcomes (there are 26 red cards), then
.
Likewise,
and
. Events
and
have 20
outcomes in common, hence
. Likewise,
and
. It is interesting to note that in this example,
.
This is because
and as a result
.
Often the occurrence of one event may be dependent upon the occurrence of another. In the
previous example, the event
= {a red card is selected} had a probability of
.
If it is known that event
= {a heart is selected} has occurred, then the event
is now
certain (probability equal to 1), since all cards in the heart suit are red. Likewise, if it is known
that the event
did not occur, then there are 39 cards remaining, 13 of which are red (all the
diamonds). Hence, the probability of event
in that case becomes 1/3. Clearly, the
probability of event
depends on the occurrence of event
. We say that the probability of
is conditional on
, and the probability of
given knowledge that the event
has
occurred is referred to as the conditional probability of
given
. The shorthand notation
is used to denote the probability of the event
given that the event
has occurred,
or simply the probability of
given
.
A
B
A
B
∩
nA B
,
A
B
n
Pr A B
,
(
)
nA B
,
n
------------
n
∞
→
lim
=
A
red card selected
{
}
=
B
number card selected
{
}
=
C
heart selected
{
}
=
A
Pr A
(
)
26 52
⁄
1 2
⁄
=
=
Pr B
( )
40 52
⁄
10 13
⁄
=
=
Pr C
(
)
13 52
⁄
1 4
⁄
=
=
A
B
Pr A B
,
(
)
20 52
⁄
5 13
⁄
=
=
Pr A C
,
(
)
13 52
⁄
1 4
⁄
=
=
Pr B C
,
(
)
10 52
⁄
5 26
⁄
=
=
Pr A C
,
(
)
Pr C
(
)
=
C
A
⊂
A
C
∩
C
=
A
Pr A
(
)
1 2
⁄
=
C
A
C
A
A
C
A
C
A
C
A
C
Pr A C
(
)
A
C
A
C



Introduction to Probability Theory
19
www.Academicpress.com
Definition 2.5: For two events
and
, the probability of
conditioned on
knowing that
has occurred is
.
(2.8)
The reader should be able to verify that this definition of conditional probability does indeed
satisfy the axioms of probability (see Exercise 2.21).
We may find in some cases that conditional probabilities are easier to compute than the
corresponding joint probabilities and hence, this formula offers a convenient way to compute
joint probabilities.
.
(2.9)
This idea can be extended to more than two events. Consider finding the joint probability of
three events,
,
, and
.
.
(2.10)
In general, for
events,
,
.
(2.11)
Example 2.12:
Return to the experiment of drawing cards from a deck as described in Example 2.11.
Suppose now that we select two cards at random from the deck. When we select the
second card, we do not return the first card to the deck. In this case, we say that we are
selecting cards without replacement. As a result, the probabilities associated with
selecting the second card are slightly different if we have knowledge of what card was
drawn on the first selection. To illustrate this let
and
. The probability of the event
can be calculated as in the
previous example to be
. Likewise, if we have no knowledge of what
was drawn on the first selection, the probability of the event
is the same,
.
To calculate the joint probability of
and
, we have to do some counting.
To begin with, when we select the first card there are 52 possible outcomes. Since this
card is not returned to the deck, there are only 51 possible outcomes for the second card.
Hence, this experiment of selecting two cards from the deck has 52*51 possible out-
comes each of which is equally likely and has a probability of
. Similarly,
A
B
A
B
Pr A B
(
)
Pr A B
,
(
)
Pr B
( )
---------------------
=
Pr A B
,
(
)
Pr B A
(
)Pr A
(
)
Pr A B
(
)Pr B
( )
=
=
A B
C
Pr A B C
,
,
(
)
Pr C A B
,
(
)Pr A B
,
(
)
Pr C A B
,
(
)Pr B A
(
)Pr A
(
)
=
=
M
A1 A2 … AM
,
,
,
Pr A1 A2 … AM
,
,
,
(
)
Pr AM A1 A2 … AM
1
–
,
,
,
(
)Pr AM
1
–
A1 … AM
2
–
,
,
(
)
…Pr A2 A1
(
)Pr A1
(
)
=
A
first card was a spade
{
}
=
B
second card was a spade
{
}
=
A
Pr A
(
)
13 52
⁄
1 4
⁄
=
=
B
Pr B
( )
1 4
⁄
=
A
B
1 52*51
⁄

(Continued)

20
Chapter 2
www.Academicpress.com
there are 13*12 outcomes that belong to the joint event
. Therefore, the joint
probability for
and
is
. The conditional
probability of the second card being a spade given that the first card is a spade is
then
=
. However, calculating this conditional
probability directly is probably easier than calculating the joint probability. Given that we
know the first card selected was a spade, there are now 51 cards left in the deck,
12 of which are spades, thus
. Once this is established, then the
joint probability can be calculated as
.
Example 2.13:
In a game of poker you are dealt 5 cards from a standard 52-card deck. What is the
probability you are dealt a flush in spades? (A flush is when you are dealt all five cards of
the same suit.) What is the probability of a flush in any suit? To answer this requires a
simple extension of the previous example. Let
be the event
,
. Then,
,
,
,
,
.
To find the probability of being dealt a flush in any suit, we proceed as follows:
.
Since all four events in the preceding expression have equal probability, then
.
So, we will be dealt a flush slightly less than two times in a thousand.
2.5 Basic Combinatorics
In many situations, the probability of each possible outcome of an experiment is taken to be
equally likely. Often, problems encountered in games of chance fall into this category as was
seen from the card drawing and dice rolling examples in the preceding sections. In these
cases, finding the probability of a certain event,
, reduces to an exercise in counting,
A
B
∩
A
B
Pr A B
,
(
)
13*12
(
)
52*51
(
)
⁄
1 17
⁄
=
=
Pr B A
(
)
Pr A B
,
(
) Pr A
(
)
⁄
=
1 17
⁄
(
)
1 4
⁄
(
)
⁄
4 17
⁄
=
Pr B A
(
)
12 51
⁄
4 17
⁄
=
=
Pr A B
,
(
)
Pr B A
(
)Pr A
(
)
4 17
⁄
(
)* 1 4
⁄
(
)
1 17
⁄
=
=
=
Ai
ith card dealt to us is a spade
{
}
i
1 2 … 5
, ,
,
=
Pr A1
(
)
1 4
⁄
=
Pr A1 A2
,
(
)
Pr A2 A1
(
)Pr A1
(
)
12 51
⁄
(
)* 1 4
⁄
(
)
1 17
⁄
=
=
=
Pr A1 A2 A3
,
,
(
)
Pr A3 A1 A2
,
(
)Pr A1 A2
,
(
)
11 50
⁄
(
)* 1 17
⁄
(
)
11 850
⁄
=
=
=
Pr A1 A2 A3 A4
,
,
,
(
)
Pr A4 A1 A2 A3
,
,
(
)Pr A1 A2 A3
,
,
(
)
10 49
⁄
(
)* 11 850
⁄
(
)
11 4165
⁄
=
=
=
Pr A1 A2 A3 A4 A5
,
,
,
,
(
)
Pr A5 A1 A2 A3 A4
,
,
,
(
)Pr A1 A2 A3 A4
,
,
,
(
)
9 48
⁄
(
)* 11 4165
⁄
(
)
33 66640
⁄
=
=
=
Pr flush
(
)
Pr
flush in spades
{
}
flush in hearts
{
}
flush in diamonds
{
}
flush in clubs
{
}
∪
∪
∪
(
)
=
Pr flush in spades
(
)
Pr flush in hearts
(
)
Pr flush in diamonds
(
)
Pr flush in clubs
(
)
+
+
+
=
Pr flush
(
)
4*Pr flush in spades
(
)
4*33
66640
---------------
33
16660
---------------
0.001981
=
=
=
=
A




Introduction to Probability Theory
21
www.Academicpress.com
.
(2.12)
Sometimes, when the scope of the experiment is fairly small, it is straightforward to count the
number of outcomes. On the other hand, for problems where the experiment is fairly
complicated, the number of outcomes involved can quickly become astronomical, and the
corresponding exercise in counting can be quite daunting. In this section, we present some fairly
simple tools that are helpful for counting the number of outcomes in a variety of commonly
encountered situations. Many students will have seen this material in their high school math
courses or perhaps in a freshmen or sophomore level discrete mathematics course. For those
who are familiar with combinatorics, this section can be skipped without any loss of continuity.
We start with a basic principle of counting from which the rest of our results will flow.
Principle of Counting: For a combined experiment,
where experiment
has
possible outcomes and experiment
has
possible outcomes, the total number of
possible outcomes in the combined experiment is
.
This can be seen through a simple example.
Example 2.14:
Suppose we form a two-digit word by selecting a letter from the set
followed by a number from the set
. All possible combinations are enumerated in
the following array.
Since the first experiment (select a letter) had
possible outcomes and the second
experiment (select a number) had
outcomes, there are a total of
possible outcomes in the combined experiment.
This result can easily be generalized to a combination of several experiments.
Theorem 2.4: A combined experiment,
, consisting of
experiments
each with
outcomes,
, has a total number of
possible outcomes given by
.
(2.13)
Pr A
(
)
Number of outcomes in A
Number of outcomes in entire sample space
---------------------------------------------------------------------------------------------------------
=
E
E1
E
×
2
=
E1
n1
E2
n2
n
n1n2
=
A B C D E F
,
,
,
,
,
{
}
0 1 2
, ,
{
}
A1 B1 C1 D1 E1 F1
A2 B2 C2 D2 E2 F2
A3 B3 C3 D3 E3 F3
n1
6
=
n2
3
=
n
n1n2
6 3
⋅
18
=
=
=
E
E1
E2
×
E3
×
…
Em
×
=
Ei
ni
i
1 2 3 … m
, , ,
,
=
n
n1n2n3…nm
ni
i
1
=
m
∏
=
=



22
Chapter 2
www.Academicpress.com
Proof: This can be proven through induction and is left as an exercise for the reader
(see Exercise 2.29). 
Example 2.15:
In a certain state, automobile license plates consist of three letters (drawn from the
26-letter English alphabet) followed by three numbers (drawn from the decimal set
0,1,2, ... , 9). For example, one such possible license plate would be “ABC 123.” This
can be viewed as a combined experiment with six sub-experiments. The experiment “draw
a letter” has 26 different outcomes and is repeated three times, while the experiment
“draw a number” has 10 outcomes and is also repeated three times. The total number of
possible license plates is then
.
Once this state has registered more than approximately 17.5 million cars, it will have to
adopt a new format for license plates.
In many problems of interest, we seek to find the number of different ways that we can
rearrange or order several items. The orderings of various items are referred to as
permutations. The number of permutations can easily be determined from the previous
theorem and is given as follows:
Theorem 2.5 (Permutations): The number of permutations of
distinct elements is
.
(2.14)
Proof: We can view this as an experiment where we have items, numbered 1 through
which we randomly draw (without replacing any previously drawn item) until all
items have been drawn. This is a combined experiment with
sub-experiments,
E = E1 × E2 × E3 ... En. The first experiment is
= “select one of the
items” and
clearly has n1 = n possible outcomes. The second experiment is
= “select one of
the remaining items not chosen in
.” This experiment has
outcomes.
Continuing in this manner,
has
outcomes, and so on, until we finally
get to the last experiment where there is only one item remaining left unchosen and
therefore the last experiment has only
outcome. Applying Theorem 2.4 to
this situation results in Equation (2.14). 
Example 2.16:
A certain professor creates an exam for his course consisting of six questions. In order to
discourage students from cheating off one another, he gives each student a different
exam in such a way that all students get an exam with the same six questions, but each
student is given the questions in a different order. In this manner, there are
different versions of the exam the professor could create.
n
26 26 26 10 10 10
⋅
⋅
⋅
⋅
⋅
263103
17 576 000
,
,
=
=
=
n
n!
n n
1
–
(
) n
2
–
(
)…3 2 1
⋅
⋅
=
n
n
n
E1
n
E2
E1
n2
n
1
–
=
E3
n3
n
2
–
=
nn
1
=
6!
720
=





Introduction to Probability Theory
23
www.Academicpress.com
A simple, but useful, extension to the number of permutations is the concept of
-permutations. In this scenario, there are
distinct elements and we would like to select a
subset of
of these elements (without replacement).
Theorem 2.6 ( -permutations): The number of
-permutations of
distinct
elements is given by
.
(2.15)
Proof: The proof proceeds just as in the previous theorem.
Example 2.17:
A certain padlock manufacturer creates locks whose combinations consist of a sequence
of three numbers from the set 0-39. The manufacturer creates combinations such that
the same number is never repeated in a combination. For example, 2-13-27 is a valid
combination while 27-13-27 is not (because the number 27 is repeated). How many
distinct padlock combinations can be created? A straightforward application of
Theorem 2.6 produces
.
Note, the company can make more than 59,280 padlocks. It would just have to start
re-using combinations at that point. There is no problem with having many padlocks
with the same combination. The company just needs to create enough possibilities that
it becomes too time consuming for someone to try to pick the lock by trying all possible
combinations.
In many situations, we wish to select a subset of
out of
items, but we are not concerned
about the order in which they are selected. In other words, we might be interested in the
number of subsets there are consisting of
out of
items. A common example of this occurs
in card games where there are 52 cards in a deck and we are dealt some subset of these
52 cards (e.g., 5 cards in a game of poker or 13 cards in a game of bridge). As far as the game
is concerned, the order in which we are given these cards is irrelevant. The set of cards is the
same regardless of what order they are given to us.
These subsets of
out of
items are referred to as combinations. The number of
combinations can be determined by slightly modifying our formula for the number of
-permutations. When counting combinations, every subset that consists of the same
k
n
k
k
k
n
n!
n
k
–
(
)!
------------------
n n
1
–
(
) n
2
–
(
)… n
k
–
1
+
(
)
=
n!
n
k
–
(
)!
------------------
40!
37!
--------
40 39 38
⋅
⋅
59 280
,
=
=
=
k
n
k
n
k
n
k



24
Chapter 2
www.Academicpress.com
elements is counted only once. Hence, the formula for the number of k-permutations has to
be divided by the number of permutations of
elements. This leads us to the following result:
Theorem 2.7 (Combinations): The number of distinct subsets (regardless of order)
consisting of
out of
distinct elements is
.
(2.16)
Example 2.18:
A certain lottery game requires players to select four numbers from the set 0-29. The
numbers cannot be repeated and the order in which they are selected does not matter.
The number of possible subsets of 4 numbers out of 30 is found from Theorem 2.7 as
.
Thus, the probability of a player selecting the winning set of numbers is
1/27,405 = 3.649 × 10–5.
The expression in Equation (2.16) for the number of combinations of
items out of
also goes by
the name of the binomial coefficient. It is called this because the same number shows up in the
power series representation of a binomial raised to a power. In particular,
is the coefficient of
the
term in the power series expansion of
(see Equation E.13 in Appendix E). A
number of properties of the binomial coefficient are studied in Exercise 2.31.
As a brief diversion, at this point it is worthwhile noting that sometimes the English usage of
certain words is much different than their mathematical usage. In Example 2.17, we talked
about padlocks and their combinations. We found that the formula for k-permutations was
used to count the number padlock combinations (English usage), whereas the formula for the
number of combinations (mathematical usage) actually applies to something quite different.
We are not trying to intentionally introduce confusion here, but rather desire to warn the reader
that sometimes the technical usage of a word may have a very specific meaning whereas the
non-technical usage of the same word may have a much broader or even different meaning. In
this case, it is probably pretty clear why the non-technical meaning of the word “combination”
is more relaxed than its technical meaning. Try explaining to your first grader why he needs to
know a 3-permutation in order to open his school locker.
The previous result dealing with combinations can be viewed in the context of partitioning
of sets. Suppose we have a set of
distinct elements and we wish to partition this set into
two groups. The first group will have
elements and the second group will then need to
have the remaining
elements. How many different ways can this partition be
k
k
k
n
n
k
⎝⎠
⎛⎞
n!
k! n
k
–
(
)!
------------------------
n n
1
–
(
) n
2
–
(
)… n
k
–
1
+
(
)
k k
1
–
(
) k
2
–
(
)…1
----------------------------------------------------------------------
=
=
30
4
⎝
⎠
⎛
⎞
30!
26!4!
-------------
30 29 28 27
⋅
⋅
⋅
4 3 2 1
⋅
⋅
⋅
-------------------------------------
27 405
,
=
=
=
k
n
n
k
⎝⎠
⎛⎞
xk yn
k
–
x
y
+
(
)n
n
k
n
k
–



Introduction to Probability Theory
25
www.Academicpress.com
accomplished? The answer is that it is just the number of combinations of
out of
elements,
. To see this, we form the first group in the partition by choosing
out of the
elements. There are
ways to do this. Since there are only two groups, all remaining
elements must go in the second group.
This result can then be extended to partitions with more than two groups. Suppose, for
example, we wanted to partition a set of
elements into three groups such that the first group
has
elements, the second group has
elements, and the third group has
elements,
where
. There are
ways in which we could choose the members of the
first group. After that, when choosing the members of the second group, we are selecting
elements from the remaining
elements that were not chosen to be in the first group.
There are
ways in which that can be accomplished. Finally, all remaining elements
must be in the third and last group. Therefore, the total number of ways to partition
elements into three groups with
elements, respectively, is
.
(2.17)
The last step was made by employing the constraint that
. Following the
same sort of logic, we can extend this result to an arbitrary number of partitions.
Theorem 2.8 (Partitions): Given a set of
distinct elements, the number of ways to
partition the set into
groups where the
th group has
elements is given by the
multinomial coefficient,
.
(2.18)
Proof: We have already established this result for the cases when
. We
leave it as an exercise for the reader (see Exercise 2.30) to complete the general proof.
This can be accomplished using a relatively straightforward application of the concept
of mathematical induction. 
Example 2.19:
In the game of bridge, a standard deck of cards is divided amongst four players such that
each player gets a hand of 13 cards. The number of different bridge games that could
occur is then
.
k
n
n
k
⎝⎠
⎛⎞
k
n
n
k
⎝⎠
⎛⎞
n
n1
n2
n3
n1
n2
n3
+
+
n
=
n
n1
⎝
⎠
⎛
⎞
n2
n
n1
–
n
n1
–
n2
⎝
⎠
⎛
⎞
n
n1 n2 n3
,
,
n
n1
⎝
⎠
⎛
⎞n
n1
–
n2
⎝
⎠
⎛
⎞
n!
n1! n
n1
–
(
)!
-----------------------------
⎝
⎠
⎛
⎞
n
n1
–
(
)!
n2! n
n1
n2
–
–
(
)!
-----------------------------------------
⎝
⎠
⎜
⎟
⎛
⎞
n!
n1!n2! n
n1
–
n2
–
(
)!
-------------------------------------------------
n!
n1!n2!n3!
-----------------------
=
=
=
n1
n2
n3
+
+
n
=
n
m
i
ni
n
n1 n2 … nm
,
,
,
⎝
⎠
⎛
⎞
n!
n1!n2!…nm!
-------------------------------
=
m
2 3
,
=
52
13 13 13 13
,
,
,
⎝
⎠
⎛
⎞
52!
13!
(
)4
---------------
5.365
28
×10
=
=

(Continued)

26
Chapter 2
www.Academicpress.com
Next, suppose I want to calculate the probability that when playing bridge, I get dealt a
hand that is completely void of spades. Assuming all hands are equally likely to occur, we
can calculate this as the ratio of the number of hands with no spades to the total number of
hands. In this case, I am only concerned about my hand and not how the remaining cards
are partitioned among the other players. There are
different sets of
13 cards that I could be dealt. If we want to calculate how many of those have no spades,
there are 39 cards in the deck that are not spades and we must be dealt a subset of 13 of
those 39 cards to get a hand with no spades. Therefore, there are
hands
with no spades. Thus, the probability of receiving a hand with no spades is
.
Naturally, there are many more formulas of this nature for more complicated scenarios. We
make no attempt to give any sort of exhaustive coverage here. Rather, we merely include
some of the more commonly encountered situations in the field of combinatorics. Table 2.2
summarizes the results we have developed and provides a convenient place to find relevant
formulas for future reference. In that table, we have also included the notation
to represent
the number of k-permutations of
items and
to represent the number of combinations of
out of
items. This notation, or some variation of it, is commonly used in many textbooks
as well as in many popularly used calculators.
Table 2.2: Summary of combinatorics formulas
Situation
Notation
Formula
Combined
Experiment
The number of outcomes in a combined experiment
consisting of
sub-experiments each with
outcomes.
Permutations
The number of ways to arrange
distinct objects.
n!
k-Permutations
The number ways to arrange
out of
distinct objects.
Combinations
The number of subsets of
out of
distinct objects,
,
Partitions
The number of ways to partition a set of
distinct
objects into
groups where the
th group has
items.
52
13
⎝
⎠
⎛
⎞
6.35
11
×10
=
39
13
⎝
⎠
⎛
⎞
8.12
9
×10
=
Pr no spades
(
)
# of hands with no spades
total # of hands
--------------------------------------------------------------
39
13
⎝
⎠
⎛
⎞
52
13
⎝
⎠
⎛
⎞
-----------
0.0128
=
=
=
Pk
n
n
Ck
n
k
n
m
ni
ni
i
1
=
m
∏
n
k
n
Pk
n
n!
n
k
–
(
)!
-------------------
k
n
Ck
n
n
k
⎝⎠
⎛⎞
n!
k! n
k
–
(
)!
------------------------
n
m
i
ni
n
n1 n2 … nm
,
,
,
⎝
⎠
⎛
⎞
n!
ni!
(
)
i
1
=
m
∏
---------------------


Introduction to Probability Theory
27
www.Academicpress.com
2.6 Bayes’s Theorem
In this section, we develop a few results related to the concept of conditional probability.
While these results are fairly simple, they are so useful that we felt it was appropriate to
devote an entire section to them. To start with, the following theorem was essentially
proved in the previous section and is a direct result of the definition of conditional
probability.
Theorem 2.9: For any events
and
such that
,
.
(2.19)
Proof: From Definition 2.5,
.
(2.20)
Theorem 2.9 follows directly by dividing the preceding equations by
. 
Theorem 2.9 is useful for calculating certain conditional probabilities since, in many
problems, it may be quite difficult to compute
directly, whereas calculating
may be straightforward.
Theorem 2.10 (Theorem of Total Probability): Let
be a set of
mutually exclusive and exhaustive events. That is,
for all
and
.
(2.21)
Then
(2.22)
Proof: As with Theorem 2.1, a Venn diagram (shown in Figure 2.2) is used here to aid
in the visualization of our result. From the diagram, it can be seen that the event
can
be written as
(2.23)
(2.24)
A
B
Pr B
( )
0
≠
Pr A B
(
)
Pr B A
(
)Pr A
(
)
Pr B
( )
-----------------------------------
=
Pr A B
,
(
)
Pr A B
(
)Pr B
( )
Pr B A
(
)Pr A
(
)
=
=
Pr B
( )
Pr A B
(
)
Pr B A
(
)
B1 B2 … Bn
,
,
,
Bi
B j
∩
∅
=
i
j
≠
Bi
i
1
=
n∪
S
=
Pr Bi
(
)
i
1
=
n
∑
⇒
1
=
Pr A
(
)
Pr A Bi
(
)Pr Bi
(
)
i
1
=
n
∑
=
A
A
A
B1
∩
{
}
A
B2
∩
{
}
…
A
Bn
∩
{
}
∪
∪
∪
=
Pr A
(
)
⇒
Pr
A
B1
∩
{
}
A
B2
∩
{
}
…
A
Bn
∩
{
}
∪
∪
∪
(
)
=

28
Chapter 2
www.Academicpress.com
Also, since the
are all mutually exclusive, then the
are also mutually
exclusive so that
(by Corollary 2.1),
(2.25)
(by Theorem 2.9). 
(2.26)
Finally by combining the results of Theorems 2.9 and 2.10, we get what has come to be know
as Bayes's theorem.
Theorem 2.11 (Bayes's Theorem): Let
be a set of mutually exclusive
and exhaustive events. Then,
.
(2.27)
As a matter of nomenclature,
is often referred to as the a priori1 probability of event
, while
is known as the a posteriori2 probability of event
given
. Section 2.9
presents an engineering application showing how Bayes's theorem is used in the field of signal
detection. We conclude here with an example showing how useful Bayes's theorem can be.
S
B1
B2
B3
B4
B5
A
Figure 2.2
Venn diagram used to help prove the Theorem of Total Probability.
Bi
A
Bi
∩
{
}
Pr A
(
)
Pr A Bi
,
(
)
i
1
=
n
∑
=
Pr A Bi
(
)Pr Bi
(
)
i
1
=
n
∑
=
B1 B2 … Bn
,
,
,
Pr Bi A
(
)
Pr A Bi
(
)Pr Bi
(
)
Pr A Bi
(
)Pr Bi
(
)
i
1
=
n
∑
-------------------------------------------------
=
Pr Bi
(
)
Bi
Pr Bi A
(
)
Bi
A
1 The term a priori is Latin and is literally translated “from the former.” In this context, it refers to
probabilities that are formed from self-evident or presupposed models.
2 The term a posteriori is also Latin and is literally translated “from the latter.” In this context, it
refers to probabilities that are derived or calculated after observing certain events.

Introduction to Probability Theory
29
www.Academicpress.com
Example 2.20:
A certain auditorium has 30 rows of seats. Row 1 has 11 seats, while Row 2 has 12
seats, Row 3 has 13 seats, and so on to the back of the auditorium where Row 30 has 40
seats. A door prize is to be given away by randomly selecting a row (with equal probabil-
ity of selecting any of the 30 rows) and then randomly selecting a seat within that row
(with each seat in the row equally likely to be selected). Find the probability that Seat 15
was selected given that Row 20 was selected and also find the probability that Row 20
was selected given that Seat 15 was selected. The first task is straightforward. Given that
Row 20 was selected, there are 30 possible seats in Row 20 that are equally likely to be
selected. Hence,
. Without the help of Bayes’s Theorem, find-
ing the probability that Row 20 was selected given that we know Seat 15 was selected
would seem to be a formidable problem. Using Bayes’s Theorem,
.
The two terms in the numerator on the right hand side are both equal to
. The term
in the denominator is calculated using the help of the theorem of total probability.
.
With this calculation completed, the a posteriori probability of Row 20 being selected
given seat 15 was selected is given by
.
Note that the a priori probability that Row 20 was selected is
. Therefore,
the additional information that Seat 15 was selected makes the event that Row 20 was
selected slightly less likely. In some sense, this may be counterintuitive, since we know
that if Seat 15 was selected, there are certain rows that could not have been selected (i.e.,
Rows 1-4 have less that 15 seats) and, therefore, we might expect Row 20 to have a
slightly higher probability of being selected compared to when we have no information
about what seat was selected. To see why the probability actually goes down, try
computing the probability that Row 5 was selected given the Seat 15 was selected. The
event that Seat 15 was selected makes some rows much more probable while it makes
others less probable and a few rows now impossible.
2.7 Independence
In Example 2.20, it was seen that observing one event can change the probability of the
occurrence of another event. In that particular case, the fact that it was known that Seat 15 was
selected lowered the probability that Row 20 was selected. We say that the event
= {Row
Pr Seat 15 Row 20
(
)
1 30
⁄
=
Pr Row 20 Seat 15
(
)
Pr Seat 15 Row 20
(
)Pr Row 20
(
) Pr Seat 15
(
)
⁄
=
1 30
⁄
Pr Seat 15
(
)
1
k
10
+
--------------- 1
30
------
k
5
=
30
∑
0.0342
=
=
Pr Row 20 Seat 15
(
)
1
30
------ 1
30
------
0.0342
----------------
0.0325
=
=
1 30
⁄
0.0333
=
A



30
Chapter 2
www.Academicpress.com
20 was selected} is statistically dependent on the event
= {Seat 15 was selected}. If the
description of the auditorium were changed so that each row had an equal number of seats
(e.g., say all 30 rows had 20 seats each), then observing the event
={Seat 15 was selected}
would not give us any new information about the likelihood of the event
= {Row 20 was
selected}. In that case, we say that the events
and
are statistically independent.
Mathematically, two events
and
are independent if
. That is, the a
priori probability of event
is identical to the a posteriori probability of
given
. Note that
if
, then the following two conditions also hold (see Exercise 2.22)
,
(2.28)
.
(2.29)
Furthermore, if
, then the other two conditions also do not hold. We can
thereby conclude that any of these three conditions can be used as a test for independence and
the other two forms must follow. We use the last form as a definition of independence since it
is symmetric relative to the events
and
.
Definition 2.6: Two events are statistically independent if and only if
.
(2.30)
Example 2.21:
Consider the experiment of tossing two numbered dice and observing the numbers that
appear on the two upper faces. For convenience, let the dice be distinguished by color,
with the first die tossed being red and the second being white. Let
= {number on the
red die is less than or equal to 2},
= {number on the white die is greater than or equal
to 4}, and
= {the sum of the numbers on the two dice is 3}. As mentioned in the
preceding text, there are several ways to establish independence (or lack thereof) of a pair
of events. One possible way is to compare
with
. Note that for the
events defined here,
,
, and
. Also, of the 36
possible atomic outcomes of the experiment, 6 belong to the event
and hence
. Since
as well, we conclude that the events
and
are
independent. This agrees with intuition since we would not expect the outcome of the
roll of one die to effect the outcome of the other. What about the events
and
? Of
the 36 possible atomic outcomes of the experiment, two belong to the event
and
hence
. Since
, the events
and
are not
independent. Again, this is intuitive since whenever the event
occurs, the event
must
also occur and so these two must be dependent. Finally, we look at the pair of events
and
. Clearly,
and
are mutually exclusive. If the white die shows a number greater
than or equal to 4, there is no way the sum can be 3. Hence
, and since
, these two events are also dependent.
B
B
A
A
B
A
B
Pr A B
(
)
Pr A
(
)
=
A
A
B
Pr A B
(
)
Pr A
(
)
=
Pr B A
(
)
Pr B
( )
=
Pr A B
,
(
)
Pr A
(
)Pr B
( )
=
Pr A B
(
)
Pr A
(
)
≠
A
B
Pr A B
,
(
)
Pr A
(
)Pr B
( )
=
A
B
C
Pr A B
,
(
)
Pr A
(
)Pr B
( )
Pr A
(
)
1 3
⁄
=
Pr B
( )
1 2
⁄
=
Pr C
(
)
1 18
⁄
=
A
B
∩
Pr A B
,
(
)
1 6
⁄
=
Pr A
(
)Pr B
( )
1 6
⁄
=
A
B
A
C
A
C
∩
Pr A C
,
(
)
1 18
⁄
=
Pr A
(
)Pr C
(
)
1 54
⁄
=
A
C
C
A
B
C
B
C
Pr B C
,
(
)
0
=
Pr B
( )Pr C
(
)
1 36
⁄
=



Introduction to Probability Theory
31
www.Academicpress.com
The previous example brings out a point that is worth repeating. It is a common mistake to
equate mutual exclusiveness with independence. Mutually exclusive events are not the same
thing as independent events. In fact, for two events
and
for which
and
,
and
can never be both independent and mutually exclusive. Thus, mutually
exclusive events are necessarily statistically dependent.
A few generalizations of this basic idea of independence are in order. First, what does it mean
for a set of three events to be independent? The following definition clarifies this and then we
generalize the definition to any number of events.
Definition 2.7: The events
,
, and
are mutually independent if each pair of
events is independent; that is
,
(2.31a)
,
(2.31b)
,
(2.31c)
and in addition,
.
(2.31d)
Definition 2.8: The events
are independent if any subset of
of
these events are independent, and in addition
.
(2.32)
There are basically two ways in which we can use this idea of independence. As was shown in
Example 2.21, we can compute joint or conditional probabilities and apply one of the
definitions as a test for independence. Alternatively, we can assume independence and use the
definitions to compute joint or conditional probabilities that otherwise may be difficult to find.
This latter approach is used extensively in engineering applications. For example, certain
types of noise signals can be modeled in this way. Suppose we have some time waveform
which represents a noisy signal which we wish to sample at various points in time,
. Perhaps, we are interested in the probabilities that these samples might exceed
some threshold, so we define the events
,
. How might we
calculate the joint probability
? In some cases, we have every reason to
believe that the value of the noise at one point in time does not effect the value of the noise at
another point in time. Hence, we assume that these events are independent and write
.
A
B
Pr A
(
)
0
≠
Pr B
( )
0
≠
A
B
A
B
C
Pr A B
,
(
)
Pr A
(
)Pr B
( )
=
Pr A C
,
(
)
Pr A
(
)Pr C
(
)
=
Pr B C
,
(
)
Pr B
( )Pr C
(
)
=
Pr A B C
,
,
(
)
Pr A
(
)Pr B
( )Pr C
(
)
=
A1 A2 … An
,
,
,
k
n
<
Pr A1 A2 … An
,
,
,
(
)
Pr A1
(
)Pr A2
(
)…Pr An
(
)
=
X t( )
t1 t2 … tn
,
,
,
Ai
Pr X ti
( )
T
>
(
)
=
i
1 2 … n
, ,
,
=
Pr A1 A2 … An
,
,
,
(
)
Pr A1 A2 … An
,
,
,
(
)
Pr A1
(
)Pr A2
(
)…Pr An
(
)
=

32
Chapter 2
www.Academicpress.com
Example 2.22:
Consider a communications network with nodes A,
B, C, and D and links
,
,
, and
, as shown
in the diagram. The probability of a link being
available at any time is
. In order to send a
messsage from node A to node D we must have a
path of available links from A to D. Assuming
independence of link availability, what is the
probability of being able to send a message? Let
be the event that link
is available. Then
.
2.8 Discrete Random Variables
Suppose we conduct an experiment,
, which has some sample space,
. Furthermore, let
be some outcome defined on the sample space,
. It is useful to define functions of the
outcome
,
. That is, the function
has as its domain all possible outcomes
associated with the experiment,
. The range of the function
will depend upon how it maps
outcomes to numerical values but in general will be the set of real numbers or some part of the
set of real numbers. Formally, we have the following definition.
Definition 2.9: A random variable is a real valued function of the elements of a
sample space,
. Given an experiment,
, with sample space,
, the random variable
maps each possible outcome,
, to a real number
as specified by some
rule. If the mapping
is such that the random variable
takes on a finite or
countably infinite number of values, then we refer to
as a discrete random variable;
whereas, if the range of
is an uncountably infinite number of points, we refer to
as a continuous random variable.
Since
is a random variable whose numerical value depends on the outcome of an
experiment, we cannot describe the random variable by stating its value; rather, we must give
it a probabilistic description by stating the probabilities that the variable
takes on a specific
value or values (e.g.,
or
). For now, we will focus on random variables
which take on discrete values and will describe these random variables in terms of
probabilities of the form
. In the next chapter when we study continuous random
variables, we will find this description to be insufficient and will introduce other probabilistic
descriptions as well.
A
B
C
D
a1
a2
a3
a4
a1
a2
a3
a4
p
Lk
ak
Pr A
D
→
(
)
Pr
L1
L2
L4
∩
∩
(
)
L3
L4
∩
(
)
∪
(
)
=
Pr L1
L2
L4
∩
∩
(
)
Pr L3
L4
∩
(
)
Pr L1
L2
L3
L4
∩
∩
∩
(
)
–
+
=
p3
p2
p4
–
+
=
E
S
x
S
x X
f x
( )
=
f
E
f
S
E
S
X
x
S
∈
X x
( )
X x
( )
X
X
X x
( )
X
X
f x
( )
=
X
Pr X =3
(
)
Pr X
8
>
(
)
Pr X =x
(
)



Introduction to Probability Theory
33
www.Academicpress.com
Definition 2.10:
The probability mass function (PMF),
, of a random
variable,
, is a function that assigns a probability to each possible value of the
random variable,
. The probability that the random variable
takes on the
specific value
is the value of the probability mass function for
. That is,
. We use the convention that upper case variables represent
random variables while lower case variables represent fixed values that the random
variable can assume.
Example 2.23:
A discrete random variable may be defined for the random experiment of flipping a
coin. The sample space of outcomes is
. We could define the random
variable
to be
and
. That is, the sample space
is mapped to
the set
by the random variable
. Assuming a fair coin, the resulting probability
mass function is
and
. Note that the mapping is not unique
and we could have just as easily mapped the sample space
to any other pair of
real numbers (e.g.,
).
Example 2.24:
Suppose we repeat the experiment of flipping a fair coin
times and observe the
sequence of heads and tails. A random variable,
, could be defined to be the number of
times tails occurs in
trials. It turns out that the probability mass function for this
random variable is
,
.
The details of how this PMF is obtained will be deferred until later in this section.
Example 2.25:
Again, let the experiment be the flipping of a coin, and this time we will continue
repeating the event until the first time a heads occurs. The random variable
will
represent the number of times until the first occurrence of a heads. In this case, the
random variable
can take on any positive integer value,
. The probability mass
function of the random variable
can be worked out as follows:
.
Hence,
,
.
PX x
( )
X
X
X
x
x
PX x
( )
Pr X =x
(
)
=
S
H T
,
{
}
=
X
X H
(
)
0
=
X T
( )
1
=
H T
,
0 1
,
{
}
X
PX 0
( )
1 2
⁄
=
PX 1
( )
1 2
⁄
=
H T
,
{
}
1 2
,
{
}
n
Y
n
PY k
( )
n
k
⎝⎠
⎛⎞1
2---
⎝⎠
⎛⎞n
=
k
0 1 … n
, ,
,
=
Z
Z
1
Z
∞
<
≤
Z
Pr Z=n
(
)
Pr n
1
– 
tails followed by one heads
(
)
Pr T
( )
(
)n
1
– Pr H
(
)
1
2---
⎝⎠
⎛⎞n
1
–
1
2---
⎝⎠
⎛⎞
2 n
–
=
=
=
=
PZ n
( )
2 n
–
=
n
1 2 3 …
, , ,
=







34
Chapter 2
www.Academicpress.com
Example 2.26:
In this example, we will estimate the PMF in Example 2.24 via MATLAB
simulation using the relative frequency approach. Suppose the
experiment consists of tossing the coin n = 10 times and counting the
number of tails. We then repeat this experiment a large number of times
and count the relative frequency of each number of tails to estimate the
PMF. The following MATLAB code can be used to accomplish this. Results of running this
code are shown in Figure 2.3.
% Simulation code to estimate PMF of Example 2.17.
n=10;
% Number of coin flips per experiment.
m=100;
% Number of times to repeat experiment.
X=round(rand(n,m));
% Simulate coin flipping.
Y=sum(X);
% Calculate number of tails per experiment.
Rel_Freq=hist(Y,[0:n])/m;
% Compute relative frequencies.
for k=0:n
% Compute actual PMF.
PMF(k+1)=nchoosek(n,k)*(2^(-n));
end
% Plot Results
plot([0:n],Rel_Freq,’o’,[0:n],PMF,’*’)
legend(‘Relative Frequency’,’True PMF’)
xlabel(‘k’)
ylabel(‘P_X(k)’)
title(‘Comparison of estimated and true PMF for Example 2.26’)
Try running this code using a larger value for m. You should see more accurate relative
frequency estimates as you increase m.
Figure 2.3
MATLAB Simulation results from Example 2.26.
0
2
4
6
8
10
0
0.05
0.1
0.15
0.2
0.25
k
PX(k)
Comparison of estimated and true PMF for Example 2.26
Relative frequency
True PMF



Introduction to Probability Theory
35
www.Academicpress.com
From the preceding examples, it should be clear that the probability mass function associated
with a random variable,
, must obey certain properties. First, since
is a probability it
must be non-negative and no greater than 1. Second, if we sum
over all
, then this is
the same as the sum of the probabilities of all outcomes in the sample space, which must be
equal to 1. Stated mathematically, we may conclude that
,
(2.33a)
.
(2.33b)
When developing the probability mass function for a random variable, it is useful to check that
the PMF satisfies these properties.
In the paragraphs that follow, we list some commonly used discrete random variables, along
with their probability mass functions, and some real-world applications in which each might
typically be used.
A. Bernoulli Random Variable This is the simplest possible random variable and is used to
represent experiments which have two possible outcomes. These experiments are called
Bernoulli trials and the resulting random variable is called a Bernoulli random variable. It is
most common to associate the values {0,1} with the two outcomes of the experiment. If
is
a Bernoulli random variable, its probability mass function is of the form
,
.
(2.34)
The coin tossing experiment would produce a Bernoulli random variable. In that case, we may
map the outcome
to the value
and
to
. Also, we would use the value
assuming that the coin is fair. Examples of engineering applications might include
radar systems where the random variable could indicate the presence (
) or absence
(
) of a target, or a digital communication system where
might indicate a bit was
transmitted in error while
would indicate that the bit was received correctly. In these
examples, we would probably expect that the value of
would be much smaller than 1/2.
B. Binomial Random Variable Consider repeating a Bernoulli trial
times, where the
outcome of each trial is independent of all others. The Bernoulli trial has a sample space of
and we say that the repeated experiment has a sample space of
,
which is referred to as a Cartesian space. That is, outcomes of the repeated trials are
represented as
element vectors whose elements are taken from
. Consider, for example,
the outcome
.
(2.35)
X
PX x
( )
PX x
( )
x
0
PX x
( )
1
≤
≤
PX x
( )
x∑
1
=
X
PX 0
( )
1
p
–
=
PX 1
( )
p
=
H
X
1
=
T
X
0
=
p
1 2
⁄
=
X
1
=
X
0
=
X
1
=
X
0
=
p
n
S
0 1
,
{
}
=
Sn
0 1
,
{
}n
=
n
S
ξk
k times
1 1 … 1,
, ,
,
(
=
n
k times
–
0 0 … 0
, ,
,
)

36
Chapter 2
www.Academicpress.com
The probability of this outcome occurring is
.
(2.36)
In fact, the order of the 1's and 0's in the sequence is irrelevant. Any outcome with exactly
1's and
0's would have the same probability. Now let the random variable
represent
the number of times the outcome 1 occurred in the sequence of
trials. This is known as a
binomial random variable and takes on integer values from 0 to
. To find the probability
mass function of the binomial random variable, let
be the set of all outcomes which have
exactly
1's and
0's. Note that all outcomes in this event occur with the same
probability. Furthermore, all outcomes in this event are mutually exclusive. Then,
,
.
(2.37)
The number of outcomes in the event
is just the number of combinations of
objects
taken
at a time. Referring to Theorem 2.7, this is the binomial coefficient,
.
(2.38)
As a check, we verify that this probability mass function is properly normalized:
.
(2.39)
In the above calculation, we have used the binomial expansion
.
(2.40)
Binomial random variables occur, in practice, any time Bernoulli trials are repeated. For
example, in a digital communication system, a packet of
bits may be transmitted and we
might be interested in the number of bits in the packet that are received in error. Or, perhaps a
bank manager might be interested in the number of tellers that are serving customers at a given
point in time. Similarly, a medical technician might want to know how many cells from a
blood sample are white and how many are red. In Example 2.23, the coin tossing experiment
was repeated
times and the random variable
represented the number of times tails
Pr xk
(
)
Pr 1 1 … 1 0 0 … 0
, ,
, , , ,
,
(
)
Pr 1
( )Pr 1
( )…Pr 1
( )Pr 0
( )Pr 0
( )…Pr 0
( )
=
=
Pr 1
( )
(
)k Pr 0
( )
(
)n
k
–
pk 1
p
–
(
)n
k
–
=
=
k
n
k
–
X
n
n
Ak
k
n
k
–
PX k
( )
Pr Ak
(
)
# of outcomes in Ak
(
)* probability of each outcome in Ak
(
)
=
=
n
k
⎝⎠
⎛⎞pk 1
p
–
(
)n
k
–
=
k
0 1 2 … n
, , ,
,
=
Ak
n
k
n
k
⎝⎠
⎛⎞
n!
k! n
k
–
(
)!
------------------------
=
n
k
⎝⎠
⎛⎞pk 1
p
–
(
)n
k
–
k
0
=
n
∑
p
1
p
–
+
(
)n
1n
1
=
=
=
a
b
+
(
)n
n
k
⎝⎠
⎛⎞akbn
k
–
k
0
=
n
∑
=
n
n
Y

Introduction to Probability Theory
37
www.Academicpress.com
occurred in the sequence of
tosses. This is a repetition of a Bernoulli trial, and hence the
random variable
should be a binomial random variable with
(assuming the coin
is fair).
C. Poisson Random Variable Consider a binomial random variable,
, where the number of
repeated trials,
, is very large. In that case, evaluating the binomial coefficients can pose
numerical problems. If the probability of success in each individual trial,
, is very small,
then the binomial random variable can be well approximated by a Poisson random variable.
That is, the Poisson random variable is a limiting case of the binomial random variable.
Formally, let
approach infinity and
approach 0 in such a way that
. Then,
the binomial probability mass function converges to the form
,
,
(2.41)
which is the probability mass function of a Poisson random variable. We see that the Poisson
random variable is properly normalized by noting that
,
(2.42)
(see Equation E.14 in Appendix E). The Poisson random variable is extremely important as it
describes the behavior of many physical phenomena. It is commonly used in queuing theory
and in communication networks. The number of customers arriving at a cashier in a store
during some time interval may be well modeled as a Poisson random variable as may the
number of data packets arriving at a node in a computer network. We will see increasingly in
later chapters that the Poisson random variable plays a fundamental role in our development of
a probabilistic description of noise.
D. Geometric Random Variable Consider repeating a Bernoulli trial until the first occurrence
of the outcome
. If
represents the number of times the outcome
occurs before the
first occurrence of
, then
is a geometric random variable whose probability mass
function is
,
.
(2.43)
We might also formulate the geometric random variable in a slightly different way. Suppose
counted the number of trials that were performed until the first occurrence of
. Then, the
probability mass function would take on the form,
,
.
(2.44)
n
Y
p
1 2
⁄
=
X
n
p
n
p
np
n
∞
→
lim
α
=
PX m
(
)
am
m!
-------e a
–
=
m
0 1 2 …
, , ,
=
am
m!
-------e a
–
m
0
=∑
e a
– ea
1
=
=
x0
X
x1
x0
X
PX k
( )
1
p
–
(
) pk
=
k
0 1 2 …
, , ,
=
X
x0
PX k
( )
1
p
–
(
) pk
1
–
=
k
1 2 3 …
, , ,
=

38
Chapter 2
www.Academicpress.com
The geometric random variable can also be generalized to the case where the outcome
must occur exactly
times. That is, the generalized geometric random variable counts the
number of Bernoulli trials that must be repeated until the
th occurrence of the outcome
.
We can derive the form of the probability mass function for the generalized geometric random
variable from what we know about binomial random variables. For the
th occurrence of
to occur on the
th trial, the first
trials must have had
occurrences of
and
occurrences of
. Then
,
(2.45)
This generalized geometric random variable sometimes goes by the name of a Pascal random
variable or the negative binomial random variable.
Of course, one can define many other random variables and develop the associated probability
mass functions. We have chosen to introduce some of the more important discrete random
variables here. In the next chapter, we will introduce some continuous random variables and
the appropriate probabilistic descriptions of these random variables. However, to close out this
chapter, we provide a section showing how some of the material covered herein can be used in
at least one engineering application.
2.9 Engineering Application—An Optical Communication System
Figure 2.4 shows a simplified block diagram of an optical communication system. Binary data
are transmitted by pulsing a laser or a light emitting diode (LED) that is coupled to an optical
fiber. To transmit a binary 1, we turn on the light source for
seconds, while a binary 0 is
represented by turning the source off for the same time period. Hence, the signal transmitted
down the optical fiber is a series of pulses (or absence of pulses) of duration
seconds which
represents the string of binary data to be transmitted. The receiver must convert this optical
x0
m
m
x0
m
x0
k
k
1
–
m
1
–
x0
k
m
–
x1
PX k
( )
Pr
m
1
–
(
) occurrences of ξ0 in k
1
–
(
) trials
{
}
x0 occurs on the kth trial
{
}
∩
(
)
=
k
1
–
m
1
–
⎝
⎠
⎛
⎞pk
m
–
1
p
–
(
)m
1
–
1
p
–
(
)
k
1
–
m
1
–
⎝
⎠
⎛
⎞pk
m
–
1
p
–
(
)m
=
=
k
m m
1 m
2
+
…
,
,
+
,
=
Laser
or
LED
Photodetector
(electron
counter)
Decision
Data
input
{0,1}
{0,1}
Figure 2.4
Block diagram of an optical communication system.
T
T

Introduction to Probability Theory
39
www.Academicpress.com
signal back into a string of binary numbers; it does this using a photodetector. The received light
wave strikes a photoemissive surface, which emits electrons in a random manner. While the
number of electrons emitted during a
second interval is random and thus needs to be described
by a random variable, the probability mass function of that random variable changes according to
the intensity of the light incident on the photoemissive surface during the
second interval.
Therefore, we define a random variable
to be the number of electrons counted during a
second interval, and we describe this random variable in terms of two conditional probability
mass functions,
and
. It can be
shown through a quantum mechanical argument that these two probability mass functions should
be those of Poisson random variables. When a binary 0 is sent, a relatively low number of
electrons are typically observed; whereas, when a 1 is sent, a higher number of electrons is
typically counted. In particular, suppose the two probability mass functions are given by
,
,
(2.46a)
,
.
(2.46b)
In these two PMFs, the parameters
and
are interpreted as the “average” number of
electrons observed when a 0 is sent and when a 1 is sent, respectively. Also, it is assumed that
, so when a 0 is sent we tend to observe fewer electrons than when a 1 is sent.
At the receiver, we count the number of electrons emitted during each
second interval and
then must decide whether a “0” or “1” was sent during each interval. Suppose that during a
certain bit interval it is observed that
electrons are emitted. A logical decision rule would be
to calculate
and
and choose according to whichever is
larger. That is, we calculate the a posteriori probabilities of each bit being sent, given the
observation of the number of electrons emitted and choose the data bit which maximizes the
a posteriori probability. This is referred to as a maximum a posteriori (MAP) decision rule and
we decide that a binary 1 was sent if
;
(2.47)
otherwise, we decide a 0 was sent. Note that these desired a posteriori probabilities are
backward relative to how the photodetector was statistically described. That is, we know the
probabilities of the form
but we want to know
. We call
upon Bayes’s theorem to help us convert what we know into what we desire to know. Using
the theorem of total probability,
.
(2.48)
T
T
X
T
PX 0 k
( )
Pr X =k 0 sent
(
)
=
PX 1 k
( )
Pr X =k 1 sent
(
)
=
PX 0 k
( )
R0
k
k!
------e R0
–
=
k
0 1 2 …
, , ,
=
PX 1 k
( )
R1
k
k!
------e R1
–
=
k
0 1 2 …
, , ,
=
R0
R1
R0
R1
<
T
k
Pr 0 sent X =k
(
)
Pr 1 sent X =k
(
)
Pr 1 sent X =k
(
)
Pr 0 sent X =k
(
)
>
Pr X =k 1 sent
(
)
Pr 1 sent X =k
(
)
PX k
( )
Pr X =k
(
)
PX 0 k
( )Pr 0 sent
(
)
PX 1 k
( )Pr 1 sent
(
)
+
=
=

40
Chapter 2
www.Academicpress.com
The a priori probabilities
and
are taken to be equal (to 1/2), so that
.
(2.49)
Therefore, applying Bayes’s theorem,
,
(2.50)
and
.
(2.51)
Since the denominators of both a posteriori probabilities are the same, we decide that a 1 was
sent if
.
(2.52)
After a little algebraic manipulation, this reduces down to choosing in favor of a 1 if
;
(2.53)
otherwise, we choose in favor of 0. That is, the receiver for our optical communication system
counts the number of electrons emitted and compares that number with a threshold. If the
number of electrons emitted is above the threshold, we decide that a 1 was sent; otherwise, we
decide a 0 was sent.
We might also be interested in evaluating how often our receiver makes a wrong decision. Ideally,
the answer is that errors are very rare, but still we would like to quantify this. Toward that end, we
note that errors can occur in two manners. First a 0 could be sent and the number of electrons
observed could fall above the threshold, causing us to decide that a 1 was sent. Likewise, if a 1 is
actually sent and the number of electrons observed is low, we would mistakenly decide that a 0 was
sent. Again, invoking concepts of conditional probability, we see that
.
(2.54)
Pr 0 sent
(
)
Pr 1 sent
(
)
PX k
( )
1
2---
R0
k
k!
------e R0
–
1
2---
R1
k
k!
------e R1
–
+
=
Pr 0 sent X =k
(
)
PX 0 k
( )Pr 0 sent
(
)
PX k
( )
---------------------------------------------
1
2---
R0
k
k!
------e R0
–
1
2---
R0
k
k!
------e R0
–
1
2---
R1
k
k!
------e R1
–
+
-------------------------------------------------
=
=
Pr 1 sent X =k
(
)
PX 1 k
( )Pr 1 sent
(
)
PX k
( )
----------------------------------------------
1
2---
R1
k
k!
------e R1
–
1
2---
R0
k
k!
------e R0
–
1
2---
R1
k
k!
------e R1
–
+
-------------------------------------------------
=
=
1
2---
R1
k
k!
------e R1
–
1
2---
R0
k
k!
------e R0
–
>
k
R1
R0
–
R1 R0
⁄
(
)
ln
---------------------------
>
Pr error
(
)
Pr error 0 sent
(
)Pr 0 sent
(
)
Pr error 1 sent
(
)Pr 1 sent
(
)
+
=

Introduction to Probability Theory
41
www.Academicpress.com
Let
be the threshold with which we compare
to decide which data bit was sent.
Specifically, let3
so that we decide a 1 was sent if
,
and we decide a 0 was sent if
. Then
.
(2.55)
Likewise,
.
(2.56)
Hence, the probability of error for our optical communication system is
.
(2.57)
Figure 2.5 shows a plot of the probability of error as a function of
with
as a parameter.
The parameter
is a characteristic of the photodetector used. We will see in later chapters
that
can be interpreted as the “average” number of electrons emitted during a bit interval
when there is no signal incident on the photodetector. This is sometimes referred to as the
“dark current.” The parameter
is controlled by the intensity of the incident light. Given a
certain photodetector, the value of the parameter
can be measured. The required value of
needed to achieve a desired probability of error can be found from Figure 2.5 (or from
Equation 2.57 which generated that figure). The intensity of the laser or LED can then be
adjusted to produce the required value for the parameter
.
x0
X
x0
R1
R0
–
(
)
R1 R0
⁄
(
)
ln
⁄
=
X
x0
>
X
x0
≤
Pr error 0 sent
(
)
Pr X
x0
>
0 sent
(
)
PX 0 k
( )
k
x0
1
+
=
∞
∑
=
=
R0
k
k!
------e R0
–
k
x0
1
+
=
∞∑
1
R0
k
k!
------e R0
–
k
0
=
x0∑
–
=
=
Pr error 1 sent
(
)
PX 0 k
( )
k
0
=
x0
∑
R1
k
k!
------e R1
–
k
0
=
x0∑
=
=
Pr error
(
)
1
2---
1
2---
R0
ke R0
–
R1
ke R1
–
–
k!
-----------------------------------------
k
0
=
x0∑
–
=
R1
R0
R0
R0
R1
R0
R1
R1
3 The notation
represents the integer part of
or the floor function. Mathematically,
is the
largest integer less than or equal to
.
x
x
x
x

42
Chapter 2
www.Academicpress.com
Equation 2.57 which generated that figure). The intensity of the laser or LED can then be
adjusted to produce the required value for the parameter .
0
5
10
15
20
25
30
35
40
10−8
10−6
10−4
10−2
100
Probability of error
R1
R0 = 1
R0 = 2
R0 = 4
R0 = 7
R0 = 10
Figure 2.5
Probability of error curves for an optical communication system; curves are parameterized
from bottom to top with
=1, 2, 4, 7, 10.
R0

43
CHAPTER 2
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 2.1: Experiments, Sample Spaces, and Events
2.1
An experiment consists of rolling n (six-sided) dice and recording the sum of the n rolls.
How many outcomes are there to this experiment?
2.2
(a)
An experiment consists of rolling a die and flipping a coin. If the coin flip is heads,
the value of the die is multiplied by -1, otherwise it is left as is. What are the
possible outcomes of this experiment?
(b)
Now, suppose we want to repeat the experiment in part (a) n times and record the
sum of the results of each experiment. How many outcomes are there in this
experiment and what are they?
2.3
An experiment consists of selecting a number x from the interval
and a number y
from the interval
to form a point
.
(a)
Describe the sample space of all points.
(b)
What fraction of the points in the space satisfy
?
(c)
What fraction of points in the sample space satisfy
?
2.4
An experiment consists of selecting a point
from the interior of the unit circle,
.
(a)
What fraction of the points in the space satisfy
?
(b)
What fraction of the points in the space satisfy
?
(c)
What fraction of the points in the space satisfy
?
(d)
What fraction of the points in the space satisfy
?
0 1)
,
[
0 2)
,
[
x y
,
(
)
x
y
>
x
y
=
x y
,
(
)
x2
y2
+
1
<
x
1
2---
>
x2
y2
+
1
2---
>
x
y
+
1
2---
>
x
y
+
1
2---
=

44
Chapter 2
www.Academicpress.com
2.5
An experiment consists of selecting two integers
such that
and
.
(a)
How many outcomes are in the sample space?
(b)
What fraction of the outcomes in the sample space satisfy
?
(c)
What fraction of the outcomes in the sample space satisfy
?
(d)
What fraction of the outcomes in the sample space satisfy
?
2.6
(a)
For each of the experiments described in Examples 2.1-2.5, state whether or not it is
reasonable to expect that each outcome of the experiment would occur equally often.
(b)
Create (a hypothethical) experiment of your own with a finite number of outcomes
where you would not expect the outcomes to occur equally often.
Section 2.2: Axioms of Probability
2.7
Using mathematical induction, prove Corollary 2.1. Recall, Corollary 2.1 states that for
events
,
, ...,
which are mutually exclusive (i.e.,
for all
),
.
2.8
Develop a careful proof of Theorem 2.1 which states that for any events
and
,
.
One way to approach this proof is to start by showing that the set
can be written
as the union of three mutually exclusive sets,
and hence by Corollary 2.1,
.
Next, show that
and likewise
.
(Hint: recall DeMorgan’s law) Put these results together to complete the desired proof.
n k
,
(
)
0
n
5
<
≤
0
k
10
<
≤
n
k
>
n
k
<
n
k
=
M
A1 A2
AM
Ai
A j
∩
∅
=
i
j
≠
Pr
Ai
i
1
=
M∪
⎝
⎠
⎛
⎞
Pr Ai
(
)
i
1
=
M
∑
=
A
B
Pr A
B
∪
(
)
Pr A
(
)
Pr B
( )
Pr A
B
∩
(
)
–
+
=
A
B
∪
A
B
∪
A
A
B
∩
(
)
∩
{
}
A
B
∩
{
}
B
A
B
∩
(
)
∩
{
}
∪
∪
=
Pr A
B
∪
(
)
Pr A
A
B
∩
(
)
∩
(
)
Pr A
B
∩
(
)
Pr B
A
B
∩
(
)
∩
(
)
+
+
=
Pr A
A
B
∩
(
)
∩
(
)
Pr A
(
)
Pr A
B
∩
(
)
–
=
Pr B
A
B
∩
(
)
∩
(
)
Pr B
( )
Pr A
B
∩
(
)
–
=

Exercises
45
www.Academicpress.com
2.9
Show that the above formula for the probability of the union of two events can be
generalized to three events as follows:
.   
2.10 Prove Theorem 2.3 which states that if
then
.
2.11 Formally prove the union bound which states that for any events
,
, ...,
(not
necessarily mutually exclusive),
.
2.12 An experiment consists of tossing a coin twice and observing the sequence of coin
tosses. The sample space consists of four outcomes
,
,
, and
. Suppose the coin is not evenly weighted such that we
expect a heads to occur more often than tails and as a result, we assign the following
probabilities to each of the four outcomes:
, 
, 
, 
.
(a)
Does this probability assignment satisfy the three axioms of probability?
(b)
Given this probability assignment, what is
?
(c)
Given this probability assignment, what is
?
2.13 Repeat Exercise 2.12 if the probability assignment is changed to:
, 
, 
, 
.
2.14 Consider the experiment of tossing a six-sided die as described in Example 2.2. Suppose
the die is loaded and as such we assign the following probabilities to each of the six
outcomes:
, 
, 
, 
, 
, 
.
Is this assignment consistent with the three axioms of probability?
Pr A
B
C
∪
∪
(
)
Pr A
(
)
Pr B
( )
Pr C
(
)
+
+
=
Pr A
B
∩
(
)
Pr A
C
∩
(
)
–
–
Pr B
C
∩
(
)
–
Pr A
B
C
∩
∩
(
)
+
A
B
⊂
Pr A
(
)
Pr B
( )
≤
A1 A2
AM
Pr
Ai
i
1
=
M∪
⎝
⎠
⎛
⎞
Pr Ai
(
)
i
1
=
M
∑
≤
ξ1
H H
,
(
)
=
ξ2
H T
,
(
)
=
x3
T H
,
(
)
=
x4
T T
,
(
)
=
Pr H H
,
(
)
3
8---
=
Pr H T
,
(
)
1
4---
=
Pr T H
,
(
)
1
4---
=
Pr T T
,
(
)
1
8---
=
Pr first toss is heads
(
)
Pr second toss is heads
(
)
Pr H H
,
(
)
25
64
------
=
Pr H T
,
(
)
15
64
------
=
Pr T H
,
(
)
15
64
------
=
Pr T T
,
(
)
9
64
------
=
Pr 1
( )
1
21
------
=
Pr 2
( )
2
21
------
=
Pr 3
( )
3
21
------
=
Pr 4
( )
4
21
------
=
Pr 5
( )
5
21
------
=
Pr 6
( )
6
21
------
=

46
Chapter 2
www.Academicpress.com
Section 2.3: Assigning Probabilities
2.15 Demonstrate that the relative frequency approach to assigning probabilities satisfies the
three axioms of probability.
2.16 We are given a number of darts. Suppose it is known that each time we throw a dart at a
target, we have a probability of
of hitting the target. An experiment consists of
throwing three darts at the target and observing the sequence of hits and misses (e.g., one
possible outcome might be (H,M,M)).
(a)
Find a probabilty assignment for the eight outcomes of this experiment that leads to
a probabilty of 1/4 of hitting the target on any toss. Note, your assignment must
satisfy the axioms of probability.
(b)
Is the probability assigment you chose unique? That is, are there other possible
probability assignments that lead to a probabilty of 1/4 of hitting the target on any
toss, or is yours the only valid assignment? Carefully prove your answer.
2.17 A spinner as shown in the figure selects a number from the set
. If we
select the outcomes
as atomic outcomes and use the
classical approach to assigning probabilities, then we would conclude that the spinner
selects all four numbers each with equal probability, 1/4. Show how to describe this
experiment in terms of more fundamental outcomes so that the classical approach leads
to a more reasonable probability assignment.
2.18 Consider a modified version of the experiment in Example 2.4 where we flip a coin until
the first occurence of tails or until we flip the coin four times, whichever comes first.
(a)
List the possible outcomes of this experiment. How many are there? Would you
expect each outcome to be equally probable?
(b)
Can you develop a method to use the classical approach to assign probabilities to
this experiment? Hint: You are going to have to define an atomic outcome which is
more fundamental than the outcomes listed in part (a).
1 4
⁄
1 2 3 4
, , ,
{
}
x1
1
=
x2
,
2 x3
,
3 x4
,
4
=
=
=
{
}
1
2
3
4

Exercises
47
www.Academicpress.com
(c)
Given the probability assigment you developed in part (b), find the probabilities of
each outcome listed in part (a).
2.19 Extend your solution to Exercise 2.18 to find the probability of each of the outcomes of
Example 2.4.
2.20 If we roll two dice and observe the sum, the most common outcome is 7 and occurs with
probability 1/6. But what if we roll more than 2 dice?
(a)
Suppose we roll three dice and observe the sum. What is the most likely sum and
what is the probability of its occurrence?
(b)
Repeat part (a) for the case of four dice?
Section 2.4: Joint and Conditional Probabilities
2.21 Demonstrate that the definition of conditional probability
satisfies the three axioms of probability.
2.22 Prove that if
, then it follows that
(a)
and
(b)
.
Furthermore, show that if
, then the two conditions above do not hold
as well.
2.23 A box of 30 diodes is known to contain five defective ones. If two diodes are selected at
random without replacement, what is the probability that at least one of these diodes is
defective?
2.24 Two balls are selected sequentially (without replacement) from an urn containing three
red, four white, and five blue balls.
(a)
What is the probability that the first is red and the second blue?
(b)
What is the probability of selecting a white ball on the second draw if the first ball
is replaced before the second is selected?
(c)
What is the probability of selecting a white ball on the second draw if the first ball
is not replaced before the second is selected?
2.25 Two six-sided (balanced) dice are thrown. Find the probabilities of each of the following
events:
(a)
a 5 does not occur on either throw;
(b)
the sum is 7;
Pr A B
(
)
Pr A B
,
(
)Pr B
( )
=
Pr B A
(
)
Pr B
( )
=
Pr A B
,
(
)
Pr A
(
)Pr B
( )
=
Pr A B
(
)
Pr A
(
)
=
Pr B A
(
)
Pr B
( )
≠

48
Chapter 2
www.Academicpress.com
(c)
a 5 and a 3 occur in any order;
(d)
the first throw is a 5 and the second throw is a 5 or a 4;
(e)
both throws are 5;
(f)
either throw is a 6.
2.26 Two six-sided (balanced) dice are thrown. Find the probabilities of each of the following
events:
(a)
only 2, 3, or 4 appear on both dice;
(b)
the value of the second roll subtracted from the value of the first roll is 2;
(c)
the sum is 10 given that one roll is 6;
(d)
the sum is 7 or 8 given one roll is 5;
(e)
one roll is a 4 given the sum is 7.
2.27 Consider two events
and
such that
. Determine if
is always true, sometimes true, or never true.
2.28 Prove that for any two events
and
,
.
Section 2.5: Basic Combinatorics
2.29 Use mathematical induction to prove Theorem 2.4. Recall that Theorem 2.4 states that a
combined experiment,
, consisting of experiments
each
with
outcomes,
, has a total number of possible outcomes given by
.
2.30 Use mathematical induction to prove Theorem 2.8. Recall that Theorem 2.8 states that
given a set of
distinct elements, the number of ways to partition the set into
groups
where the
th group has
elements is given by the multinomial coefficient,
.
2.31 Prove the following identities involving the binomial coefficient
.
(a)
(b)
A
B
Pr A
(
)
Pr B
( )
>
Pr A B
(
)
Pr B A
(
)
>
A
B Pr A
B
∩
(
)
Pr A
(
)
Pr A
B
∪
(
)
≤
≤
E
E1
E2
E3
×
×
…
×
Em
×
=
Ei
ni
i
1 2 3 … m
, , ,
,
=
n
n1n2n3…nm
ni
i
1
=
m
∏
=
=
n
m
i
ni
n
n1 n2 … nm
,
,
,
⎝
⎠
⎛
⎞
n!
n1!n2!…nm!
-----------------------------
=
n
k
⎝⎠
⎛⎞
n!
k! n
k
–
(
)!
------------------------
=
n
k
⎝⎠
⎛⎞
n
n
k
–
⎝
⎠
⎛
⎞
=
n
k
⎝⎠
⎛⎞
n
k
1
+
⎝
⎠
⎛
⎞
+
n
1
+
k
1
+
⎝
⎠
⎛
⎞
=

Exercises
49
www.Academicpress.com
(c)
(d)
(e)
(f)
2.32 I deal myself 3 cards from a standard 52-card deck. Find the probabilities of each of the
following events:
(a)
2 of a kind (e.g., 2 fives or 2 kings);
(b)
3 of a kind;
(c)
3 of the same suit (a.k.a a flush, e.g., 3 hearts or 3 clubs);
(d)
3 cards in consecutive order (a.k.a. a straight, e.g., 2-3-4 or 10-J-Q).
2.33 I deal myself 13 cards for a standard 52-card deck. Find the probabilities of each of the
following events:
(a)
exactly one heart appears in my hand (of 13 cards);
(b)
at least 7 cards from a single suit appear in my hand;
(c)
my hand is void (0 cards) of at least one suit.
2.34 For an alphabet consisting of 26 characters, find the following:
(a)
The number of possible 4-letter sequences (words) where the same letter can appear
in the word more than once.
(b)
The number of possible 4-letter sequences (words) where the same letter cannot
appear in the word more than once.
(c)
The number of different ways the 26 letters can be ordered.
2.35 In pulse-code modulation (PCM), a PCM word consists of a sequence of binary digits
(bits) of 1s and 0s.
(a)
Suppose the PCM word length is n bits long. How many distinct words are there?
(b)
If each PCM word, three bits long, is equally likely to occur, what is the probability
of a word with exactly two 1s to occur?
2.36 In pulse-amplitude modulation (PAM), a PAM word consists of a sequence of pulses,
where each pulse may take on a given number of amplitude levels. Suppose a PAM word
is n pulses long and each pulse may take on m different levels.
(a)
How many distinct PAM words are there?
(b)
If each PAM word, 4 pulses long, is equally likely to occur and each pulse can have
one of three levels, {0, 1, 2}, what is the probability of a PAM word occurring with
exactly two pulses of level 2?
n
k
⎝⎠
⎛⎞
k
0
=
n
∑
2n
=
n
k
⎝⎠
⎛⎞
1
–
(
)k
k
0
=
n
∑
0
=
n
k
⎝⎠
⎛⎞k
k
1
=
n
∑
n2n
1
–
=
n
k
⎝⎠
⎛⎞k
1
–
(
)k
k
0
=
n
∑
0
=

50
Chapter 2
www.Academicpress.com
2.37 A certain communication system transmits text messages by representing each character
with an
-bit binary codeword. Suppose it is necessary for this communication system
to operate in such a way that there are always an equal number of 0s and 1s transmitted.
Toward that end, the communication system uses a codebook consisting only of those
-bit words that have exactly
0s and
1s (where
is an even integer).
For example, in the case of
, there are exactly 6 four-bit codewords
consisting of exactly two 1s and two 0s resulting in the codebook
. Thus, with four bit codewords,
we could represent an alphabet of only six characters.
(a)
Find an expression for the number of codewords with half 1s and half 0s for an
arbitrary even integer
.
(b)
What is the minimum length of codeword we would need if the codebook needs to
represent at least 100 different characters?
2.38 Phone numbers in the United States consist of 10 digits, a three-digit area code followed
by a seven-digit number. Suppose there are several constraints that must be satisfied for
a phone number to be valid, such as:
(i)
Neither the first digit of any area code nor the first digit of a phone number can be 0,
(since 0 is reserved to connenct to an operator).
(ii)
The second digit of any valid area code must be either 0 or 1.
(iii)
The second digit of any valid phone number must not be either 0 or 1
(the second and third constraints are no longer in place but were once used so
that the phone company could easily determine whether you were making a
local or long distance call).
(iv)
The second and third digits of any valid area code cannot both be 1s.
(v)
The second and third digits of any valid phone number cannot both be 1s.
(three-digit numbers ending in 11 are reserved for special purposes,
e.g., emergency, 911, or information, 411).
(a)
Given the five constraints listed above, how many valid three-digit area codes are
there?
(b)
Given the five constraints listed above, how many valid seven-digit phone numbers
are there?
(c)
How many different 10-digit phone numbers can be constructed under these
constraints?
2.39 A balanced coin is tossed nine times. Find the probabilities of each of the following events:
(a)
exactly 3 heads occurred;
(b)
at least 3 heads occurred;
(c)
at least 3 heads and at least 2 tails occurred.
n
n
n 2
⁄
n 2
⁄
n
n
4
=
1100
(
)
1010
(
)
1001
(
)
0110
(
)
0101
(
)
0011
(
)
,
,
,
,
,
{
}
n

Exercises
51
www.Academicpress.com
2.40 A blackjack hand consists of 2 cards drawn from a 52-card deck. The order in which the
cards are drawn does not matter.
(a)
How many different blackjack hands are there?
(b)
In blackjack, the suit of the card is irrelevant to the game. If we do not make a
distinction between the different suits, now how many different blackjack hands are
there?
(c)
In blackjack, 10s, Jacks, Queens, and Kings are all worth 10 points and thus have
an identical function in the game. If we do not make a distinction between 10s,
Jacks, Queens, and Kings, nor between the different suits, now how many blackjack
hands are there?
2.41 In the game of blackjack, Aces are worth 11 points (or they can also be counted as 1
point, but for the sake of this problem, we will only count them as 11 points), 10s, Jacks,
Queens, and Kings are all worth 10 points and the other numbered cards are worth their
face values (i.e., 2s are worth two points, 3s are worth three points, etc.). The suit of the
card does not matter.
(a)
Find the probability of being dealt a two-card blackjack hand worth a total of 18 or
more points?
(b)
Find the probability of being dealt a two-card blackjack hand worth a total of no
less than 12 points and no more than 17 points?
Hint: Consider carefully the results of Problem 2.40 and think about what consists of an
atomic outcome in this experiment.
2.42 In a game of blackjack, the player and the dealer are both dealt two cards. One of the
dealer’s cards is dealt face up so that the player gets to see it. Suppose you (as a player)
are dealt a 10 and a 6 and you observe that one of the dealer’s cards is a 7. Given the
three observed cards, what is the probability that the dealers cards total more points than
yours (before any additional cards are drawn)? Refer to Exercise 2.41 for a description of
the point values of various cards in blackjack.
2.43 A poker hand consists of 5 cards drawn from a 52-card deck.
(a)
How many different poker hands are there?
(b)
How many different poker hands are there that contain all four aces? What then is
the probability of being dealt four aces? What is the probability of being dealt four
of a kind (i.e., four aces, or four kings, or four queens, etc.)?
(c)
How many different poker hands are there that contain exactly three aces?
What then is the probability of being dealt three aces? What is the
probability of being dealt three of a kind (i.e., three aces, or three kings, or three
queens, etc.)?

52
Chapter 2
www.Academicpress.com
2.44 A certain gym teacher has a class of 20 students. He wants to divide them into four teams
of five students each in order to have a class basketball tournament.
(a)
How many different ways can he divide the class into four teams?
(b)
Tommy and Bobby are two of the students in the class and are best friends.
Assuming the gym teacher assigns students in a completely random fashion, what
is the probability that they get selected to be on the same team?
(c)
Neither boy wants to be on a team with the class bully, Frank. What is the
probability that neither Tommy nor Bobby are on the same team as Frank?
Section 2.6: Bayes’s Theorem
2.45 Manufacturer X produces personal computers (PCs) at two different locations in the
world. Fifteen percent of the PCs produced at location A are delivered to a retail outlet
defective, while five percent of the PCs produced at location B are delivered defective to
the same retail store. If the manufacturing plant at A produces 1,000,000 PCs per year
and the plant at B produces 150,000 PCs per year, find the probability of purchasing a
defective PC.
2.46 A communication system sends binary data {0 or 1} which is then detected at the
receiver. The receiver occasionally makes mistakes and sometimes a 0 is sent and is
detected as a 1 or a 1 can be sent and detected as a 0. Suppose the communication system
is described by the following set of conditional probabilities:
,
,
,
.
(a)
Assuming 0s and 1s are equally likely to be transmitted (i.e.,
and
), find
and
.
(b)
Suppose a 0 is detected at the receiver. What is the probability that the transmitted bit
was actually a 1? Also, if a 1 was detected at the receiver, what is the probability that
the transmitted bit was actually a 0?
(c)
What is the probability that the detected bit is not equal to the transmitted bit. This
is the overall probability of error of the receiver.
2.47 In this problem, we will modify the communication system described in
Exercise 2.46 so that the detector at the receiver is allowed to make one of three
possible decisions:
“0”
the detector decides the received signal was a 0,
Pr 0 received 0 transmitted
(
)
0.95
=
Pr 1 received 0 transmitted
(
)
0.05
=
Pr 0 received 1 transmitted
(
)
0.10
=
Pr 1 received 1 transmitted
(
)
0.90
=
Pr 0 transmitted
(
)
1 2
⁄
=
Pr 1 transmitted
(
)
1 2
⁄
=
Pr 0 received
(
)
Pr 1 received
(
)

Exercises
53
www.Academicpress.com
“1”
the detector decides the received signal was a 1,
“E”
the detector is not sure and declares the received signal an erasure
(i.e., the receiver chooses not to choose).
The operation of the detector is described by the following set of conditional
probabilities:
,
,
,
,
,
.
Again, assume that 0s and 1s are equally likely to be transmitted.
(a)
What is the probability that a symbol is erased at the receiver?
(b)
Given that a received symbol is declared an erasure, what is the probability that a 0
was actually transmitted?
(c)
What is the probability of error of this receiver? That is, what is the probability that
a 0 was transmitted and it is detected as a 1 or a 1 was transmitted and it is detected
as a 0?
2.48 We are in possession of two coins, one which is fairly balanced and turns up heads with
probability 1/2, the other is weighted such that heads shows up with probability 3/4 and
tails with probability 1/4. The two coins are identical looking and feeling so we cannot
tell which is which. In order to determine which is the biased coin we toss the coin 10
times and observe the number of heads that occurred.
(a)
If 7 heads were observed, what is the probability that the coin flipped was the fair
coin?
(b)
If 3 heads were observed, what is the probability that the coin flipped was the fair
coin?
2.49 Researchers are investigating the physical development of children over time. In the
study, children are given a physical aptitude test at several stages in their development.
Let
be the event that the child passes the physical aptitude test. Furthermore, let
be the event that the child taking the test was a boy, and
be the event that the child
taking the test was a girl. The computer storing the data from this project experienced
hard drive failure and only some of the data was recovered resulting in the partial
database shown in the table. Use your knowledge of probability theory to fill in the
missing items in the table.
Pr 0 received 0 transmitted
(
)
0.90
=
Pr 0 received 1 transmitted
(
)
0.04
=
Pr 1 received 0 transmitted
(
)
0.01
=
Pr 1 received 1 transmitted
(
)
0.80
=
Pr E received 0 transmitted
(
)
0.09
=
Pr E received 1 transmitted
(
)
0.16
=
P
B
G

54
Chapter 2
www.Academicpress.com
Section 2.7: Independence
2.50 Compare the two probability assignments in Exercises 2.12 and 2.13. Which of these
two assignments corresponds to independent coin tosses?
2.51 Cards are drawn from a standard 52-card deck until an ace is drawn. After each card is
drawn, it is put back in the deck and the cards are reshuffled so that each card drawn is
independent of all others.
(a)
Find the probability that the first ace is drawn on the 5th selection.
(b)
Find the probability that at least 5 cards are drawn before the first ace appears.
(c)
Repeat parts (a) and (b) if the cards are drawn without replacement. That is, after
each card is drawn, the card is set aside and not replaced in the deck.
2.52 Cards are drawn from a standard 52-card deck until the third club is drawn. After each
card is drawn, it is put back in the deck and the cards are reshuffled so that each card
drawn is independent of all others.
(a)
Find the probability that the 3rd club is drawn on the 8th selection.
(b)
Find the probability that at least 8 cards are drawn before the 3rd club appears.
(c)
Repeat parts (a) and (b) if the cards are drawn without replacement. That is, after
each card is drawn, the card is set aside and not replaced in the deck.
2.53 A computer memory has the capability of storing
words. Due to outside forces, portions
of the memory are often erased. Therefore, words are stored redundantly in various areas of
the memory. If a particular word is stored in n different places in the memory, what is the
probability that this word cannot be recalled if one-half of the memory is erased by
electromagnetic radiation? Hint: Consider each word to be stored in a particular cell (or box).
106
Data for Exercise 2.49
Year in
School
2nd grade
0.45
0.25
0.30
4th grade
0.37
0.35
0.40
6th grade
0.50
0.50
0.52
8th grade
0.74
0.75
0.35
Pr P
( )
Pr B
( )
Pr G
(
)
Pr P B
(
)
Pr P G
(
)
Pr B P
(
)
Pr G P
(
)

Exercises
55
www.Academicpress.com
These cells (boxes) may be located anywhere, geometrically speaking, in memory. The
contents of each cell may be either erased or not erased. Assume n is small compared to the
memory capacity.
2.54 If two events A and B are such that Pr(A) is not zero and Pr(B) is not zero, what
combinations of independent (I ), not independent (NI ), mutually exclusive (M ), and not
mutually exclusive (NM ) are permissible? In other words, which of the four
combinations (I, M ), (NI, M ), (I, NM ), and (NI, NM ) are permissible? Construct an
example for those combinations that are permissible.
2.55 Suppose two events
and
are independent.
(a)
Is it true that
is independent of
? If yes, give a convincing proof, otherwise,
give a counterexample.
(b)
Is it true that
is independent of
? If yes, give a convincing proof, otherwise,
give a counterexample.
2.56 Suppose we modify the communications network of Example 2.22 as shown in the
diagram by adding a link from node B to node D. Assuming each link is available with
probability
independent of any other link, what is the probability of being able to send
a message from node A to D?
Section 2.8: Discrete Random Variables
2.57 A possible outcome of an experiment is the event A. The probability of this event is p.
The experiment is performed n times, the outcome of any trial is not affected by the
results of the previous trials. Define a random variable X to be the number of times the
event A occurs in n trials.
(a)
What is the PMF
?
(b)
Show that the sum of the PMF over all x is 1.
(c)
What is the name of this PMF?
A
B
A
B
A
B
p
A
B
C
D
a1
a2
a3
a4
a5
Pr X =x
(
)

56
Chapter 2
www.Academicpress.com
2.58 For each of the following probability mass functions, find the value of the constant
:
(a)
,
(b)
,
(c)
,
.
(d)
,
.
(e)
,
.
2.59 Consider a Bernoulli trial where
and
. Suppose this Bernoulli
trial is repeated
times.
(a)
Plot the probability mass function for a Binomial random variable,
, with
and
.
(b)
Plot the corresponding probability mass function for a Poisson random variable
with
.
(c)
Compare
as computed by both the Binomial and Poisson random
variables. Is the Poisson random variable a good approximation for the Binomial
random variable for this example?
2.60 Suppose the arrival of telephone calls at a switch can be modeled with a Poisson PMF.
That is, if
is the number of calls that arrive in
minutes, then
,  
,
where
is the average arrival rate in calls/minute. Suppose that the average rate of calls
is 10 min.
(a)
What is the probability that fewer than three calls will be received in the first 6 s?
(b)
What is the probability that fewer than three calls will be received in the first
6 min?
2.61 In a certain lottery, six numbers are randomly chosen from the set
(without replacement). To win the lottery, a player must guess correctly all six numbers
but it is not necessary to specify in which order the numbers are selected.
(a)
What is the probability of winning the lottery with only one ticket?
(b)
Suppose in a given week, 6 million lottery tickets are sold. Suppose further that
each player is equally likely to choose any of the possible number combinations
and does so independent of the selections of all other players. What is the
probability that exactly four players correctly select the winning combination?
c
PX k
( )
c 0.37
(
)k
=
k
0 1 2 …
, , ,
=
P X k
( )
c 0.82
(
)k
=
k
1 2 3 …
, , ,
=
P X k
( )
c 0.41
(
)k
=
k
0 1 2 … 24
, , ,
,
=
P X k
( )
c 0.91
(
)k
=
k
1 2 3 … 15
, , ,
,
=
P X k
( )
c 0.41
(
)k
=
k
0 2 4 … 12
, , ,
,
=
Pr 1
( )
p
=
Pr 0
( )
1
p
–
=
n
X
p
1 5
⁄
=
n
10
=
X
a
np
2
=
=
Pr X
5
≥
(
)
X
t
Pr X =k
(
)
lt
(
)k
k!
------------e lt
–
=
k
0 1 2 …
, , ,
=
l
0 1 2 … 49
, , ,
,
{
}

Exercises
57
www.Academicpress.com
(c)
Again assuming 6 million tickets sold, what is the most probable number of
winning tickets?
(d)
Repeat parts (b) and (c) using the Poisson approximation to the binomial
probability distribution. Is the Poisson distribution an accurate approximation in
this example?
2.62 Imagine an audio amplifier contains six transistors. Harry has determined that two
transistors are defective, but he does not know which two. Harry removes three
transistors at random and inspects them. Let X be the number of defective transistors that
Harry finds, where X may be 0, 1, or 2. Find the PMF for x.
2.63 A software manufacturer knows that l out of 10 software games that the company
markets will be a financial success. The manufacturer selects 10 new games to market.
What is the probability that exactly one game will be a financial success? What is the
probability that at least two games will be a success?
2.64 In a digital communication system, a block of
data bits is mapped into an
-bit
codeword that typically contains the
information bits as well as
redundant bits.
This is known as an
block code. The redundant bits are included to provide error
correction capability. Suppose that each transmitted bit in our digital communication
system is received in error with probability
. Furthermore, assume that the decoder is
capable of correcting any pattern of
or fewer errors in an
bit block. That is, if
or
less bits in an
bit block are received in error, then the codeword will be decoded
correctly, whereas if more than
errors occur, the decoder will decode the received word
incorrectly. Assuming each bit is received in error with probability
, find the
probability of decoder error for each of the following codes.
(a)
,
;
(b)
,
;
(c)
,
.
2.65 A roulette wheel consists of 38 numbers (18 are red, 18 are black, and 2 are green).
Assume that with each spin of the wheel, each number is equally likely to appear.
(a)
What is the probability of a gambler winning if he bets on a red number showing up?
(b)
Suppose the gambler keeps betting on red until he finally wins. Let
be the
number of times he plays/bets. Specify the probability mass function of the random
variable
. That is, find
.
(c)
Now, suppose the gambler keeps betting on red until he wins twice. Let
be the
number of times he plays/bets. Specify the probability mass function of the random
variable
. That is, find
.
k
n
k
n
k
–
n k
,
(
)
p
t
n
t
n
t
p
0.03
=
n k
,
(
)
7 4
,
(
)
=
t
1
=
n k
,
(
)
15 7
,
(
)
=
t
2
=
n k
,
(
)
31 16
,
(
)
=
t
3
=
N
N
PN k
( )
Pr N =k
(
)
=
M
M
PM k
( )
Pr M =k
(
)
=

58
Chapter 2
www.Academicpress.com
2.66 Cards are drawn from a standard 52-card deck. After each card is drawn, it is put back in
the deck and the cards are reshuffled so that each card drawn is independent of all others.
Let
be the random variable that represents the number of cards that are drawn before
the second appearance of an ace. For example, if the sequence of cards drawn was {2, 5,
K, 7, A, 5, 3, J, A, ...}, then
would take on a value of 8. Find the probability mass
function of
. That is, find
.
2.67 Highway A and Highway B merge to form Highway C as shown in the figure. Engineers
have studied the traffic patterns on the two merging roads and found that the number of
cars per minute that travel each road can be well modeled as Poisson random variables as
described below
Highway A:
=# cars per minute,
,
,
Highway B:
=# cars per minute,
,
.
Let
be the number of cars per minute on Highway C. Find the PMF of
,
. Is
also a Poisson random varialbe or does it follow some other
distribution? You may assume that in any interval of time, the number of cars on
Highway A and the number of cars on Highway B are independent of each other.
2.68 An experiment consists of rolling a pair of (six-sided) dice and observing the sum. This
experiment is repeated until the sum of 7 is observed at which point the experiment
stops. Let
be the random variable which represents the number of times the
experiment is repeated. That is, if the first occurrence of {sum=7} happens on the 5th
roll of the dice, then
.
(a)
Find the probability mass function for the random variable
. That is, find
for all
.
(b)
What is the probability that the experiment proceeds for at least 4 rolls? That is,
find
.
N
N
N
PN n
( )
Pr N =n
(
)
=
Hwy C
Hwy A
Hwy B
N
Pr N =n
(
)
l A
(
)ne lA
–
n!
-----------------------
=
n
0 1 2 3 …
, , , ,
=
M
Pr M =m
(
)
lB
(
)me lB
–
m!
-----------------------
=
m
0 1 2 3 …
, , , ,
=
K
M
N
+
=
K
PK k
( )
Pr K=k
(
)
=
K
N
N
5
=
N
PN k
( )
Pr N =k
(
)
=
k
Pr N
4
≥
(
)

Exercises
59
www.Academicpress.com
Miscellaneous Problems
2.69 I deal myself 5 cards from a standard 52-card deck. Find the probabilities of each of the
following events:
(a)
2 of a kind;
(b)
3 of a kind;
(c)
2 pair (e.g., 2 eights and 2 queens);
(d)
a flush (5 cards all of the same suit);
(e)
a full house (3 of one kind and 2 of another kind);
(f)
a straight (5 cards in consecutive order).
2.70 In the game of RISK, two players compete in a game of dice rolling for conquest of the
world. One player is on “offense” while the other is on “defense.” For this problem, the
player on offense is allowed to roll multiple dice while the player on defense rolls a
single die. Whoever rolls the higher number wins (i.e., the highest number rolled by the
offense is compared with the number rolled by the defense). In case of a tie, the defense
is declared the winner. The loser must remove one army from the board. Find the
probability of the offense winning and the probability of the defense winning in each of
the following scenarios:
(a)
Both players roll only a single die.
(b)
Offense rolls two dice while defense rolls one die.
(c)
Offense rolls three dice while defense rolls one die.
2.71 Now consider a modified version of Problem 2.70 where the defense is also allowed to
roll multiple dice. Each player’s highest roll is compared with the other player’s highest
roll, their second highest roll is compared with the other player’s second highest roll, etc.
As before, any ties go to the defense.
(a)
Suppose both players roll two dice. In this case, there are two armies to be lost
since there are two dice comparisons (highest vs. highest and lowest vs. lowest).
Find each of the following probabilities:
(i)
Offense wins both comparisons (and thus defense loses two armies).
(ii)
Offense wins one comparison and defense wins the other (and thus each lose
one army).
(iii)
Defense wins both comparisons (and thus offense loses two armies).
(b)
Repeat all the calculations in part (a) for the scenario where the offense rolls three
dice and the defense rolls two dice. As before, there are two comparisons to be
made in this scenario (highest vs. highest and second highest vs. second highest).

60
Chapter 2
www.Academicpress.com
2.72 (Adapted from the minigame “Hide and Go Boom” from Nintendo’s “Mario Party 4”) In
this game, 1 player competes against 3 other players. Players 2, 3, and 4 independently
select one of four slots (labeled A, B, X, and Y) in which to hide. More than one player
can hide in the same slot and none of these three “hiders” can co-ordinate their actions.
Once the three are hidden, player 1 gets to select 3 of the 4 slots in which to “find” the
other three players. If all three hidden players were located in the three slots chosen by
player 1, then player 1 wins. If any of the three hidden players are located in the slot not
selected by player 1, then the group of players 2, 3, and 4 win.
(a)
What is the probability that player 1 wins?
(b)
Suppose the three-player team was allowed to coordinate their hiding efforts and
they decided to all hide in the same slot. What then would be the probability that
player 1 wins?
(c)
Now, suppose the three-player team was allowed to coordinate their hiding efforts
and they decided to all hide in different slots. Now what is the probability that
player 1 wins?
2.73 (Adapted from the battle game “Bowser’s Bigger Blast” from Nintendo’s “Mario Party
4”) In this game, 4 players compete in a deadly game of chance against each other. On
a stage, there are 5 detonators. One is connected to a bomb while the other four are
disconnected and will have no effect. Player 1 must go first and push one of the five
detonators. If he is unlucky enough to choose the live detonator, he will set off the bomb
and lose the game (and his life). If he chooses one of the four “duds,” he is safe and will
remove that detonator from the game. At that point, player 2 must choose one of the four
remaining detonators, and so on. If all four players are lucky enough to survive their
choices, then the stage is reset (with the five detonators and one randomly selected to be
live) and the procedure is repeated, until a player eventually loses. Is this a fair game?
Or, is one player more likely to lose than the others? That is, find the probability of each
player losing the game.
2.74 A certain light bulb manufacturer makes two types of bulbs, a low-cost short-life (S-
type) bulb and a more expensive long-life (L-type) bulb. The two types of bulbs look
identical and so the company must be sure to carefully label the boxes of bulbs. A box of
bulbs is found on the floor of the manufacturing plant that (you guessed it) has not been
labeled. In order to determine which types of bulbs are in the box, a promising young
engineer suggested that they take one bulb from the box and run it until it burns out.
After observing how long the bulb remains lit, they should be able to make a good guess
as to which type of bulbs are in the box. It is known that the length of time (in hours), X,
that a bulb lasts can be described by a geometric random variable
,  
.
P X k
( )
1
a
–
(
)ak
=
k
0 1 2 …
, , ,
=

Exercises
61
www.Academicpress.com
The parameter
that appears in the above expression is
for the S-type bulbs
and
for the L-type bulbs. It is known that of all the light bulbs the company
manufactures 75% are S-type and 25% are L-type. Hence, before the experiment is run,
the box in question has a 75% chance of being S-type and 25% chance of being L-type.
(a)
If, after running the proposed experiment, it is observed that the bulb burned out
after 200 hours, which type of bulb is most likely in the unmarked box?
Mathematically justify your answer.
(b)
What is the probability that your decision in part (a) turns out to be wrong? That is,
if you decided that the box most likely contained L-type bulbs, what is the
probability that the box actually contains S-type bulbs (or if you decided the box
most likely contained S-type bulbs, what is the probability that the box actually
contains L-type bulbs)?
2.75 This classic problem was given widespread pop culture attention in 2008 by the movie
“21.” A form of this problem known as the Monty Hall problem appeared in the “Ask
Marilyn” column in Parade Magazine in 1990. Although the column’s author, Marilyn
vos Savant, provided the correct solution, many readers wrote the magazine insisting that
her solution was wrong. Can you get this tricky problem correct?
The Monty Hall Problem—You are on a game show where you are asked to
select one of three doors and you get to keep the prize behind the door.
Behind one of the three doors is a new car, while there are goats behind the
other two. After you select your door, the host, who knows where the car is,
will open one of the doors that you did not select, which he knows to contain a
goat. After the goat has been revealed, the host asks if you would like to
change your selection and choose instead the other unopened door. Are you
better off keeping your original selection, changing to the other unopend door,
or does it not matter?
MATLAB Exercises
2.76 Write MATLAB code to produce a randomly generated number which is equally likely
to produce any number from the set
.
2.77 Write MATLAB code to produce a randomly generated number that follows the
Bernoulli distribution for an arbitrary parameter,
.
2.78 Modify the MATLAB code in Example 2.26 to produce a random variable which follows
a Binomial distribution for arbitrary parameters
.
a
a
0.99
=
a
0.999
=
0 1 2 … 9
, , ,
,
{
}
p
n p
,

62
Chapter 2
www.Academicpress.com
2.79 Write MATLAB code to simulate a random variable,
, whose PMF is given by
,
. Hint: See Example 2.25 for specifics on how this
random variable arises and then follow the lead of Example 2.26.
2.80
(a)
Write and execute a MATLAB program to calculate
for an arbitrary n. Use your
program to calculate 64!.
(b)
What is the largest integer n for which your program gives a finite answer?
(c)
Sterling’s approximation for the factorial function is given by
.
Use your program to compare the true value of n! with Sterling’s approximation. For
what ranges of n is the approximation within 1% of the true value?
2.81 Write your own program to evaluate the binomial coefficient
. Create
your program in such a way so that it does not have to directly evaluate
. That way the
program will not crash if you use it to evaluate a binomial coefficient with
greater than
the value you found in Exercise 2.80b. Use your program to evaluate
.
2.82 Write a MATLAB program to simulate the dice rolling game described in Exercise 2.70.
Run your program a large number of times and use the relative frequency to verify that
your answers to Exercise 2.70 are correct.
2.83 Write a MATLAB program to simulate the dice rolling game described in Exercise 2.71.
Run your program a large number of times and use the relative frequency to verify that
your answers to Exercise 2.71 are correct.
2.84 Write a MATLAB program to simulate the Monty Hall problem described in Exercise
2.75. Run your program a large number of times and use the relative frequency to verify
that your answer to Exercise 2.75 is correct.
Z
Pz k
( )
2 k
–
=
k
1 2 3 …
, , ,
=
n!
n!
2p n
n
1
2---
+
⎝
⎠
⎛
⎞e n
–
1
1
12n
---------
–
⎝
⎠
⎛
⎞
≈
n
k
⎝⎠
⎛⎞
n!
k! n
k
–
(
)!
------------------------
=
n!
n
384
15
⎝
⎠
⎛
⎞

63
CHAPTER 3
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00003-6
© 2012 by Elsevier Inc. All rights reserved.
Random Variables, Distributions,
and Density Functions
At the end of the last chapter, we introduced the concept of a random variable and gave several
examples of common discrete random variables. These random variables were described by
their probability mass functions. While this description works fine for discrete random
variables, it is inadequate to describe random variables that take on a continuum of values.
We will illustrate this through an example shortly. In this chapter, we introduce the
cumulative distribution function (CDF) as an alternative description of random variables that
is appropriate for describing continuous as well as discrete random variables. A related
function, the probability density function (PDF), is also covered. With these tools in hand, the
concepts of random variables can be fully developed. Several examples of commonly used
continuous random variables are also discussed in this chapter.
To show the need for an alternative to the probability mass function, consider a discrete
random variable, X, that takes on values from the set {0, 1/N, 2/N, . . ., (N - 1)/N} with equal
probability. That is, the probability mass function of X is
,
.
(3.1)
This is the type of random variable that is produced by “random” number generators in high
level languages such as Fortran and C, as well as math packages such as MATLAB,
MathCAD, and Mathematica. In these cases, N is taken to be a fairly large number so that it
appears that the random number can be anything in the continuous range [0, 1). The reader is
referred to Chapter 12, for more details on how computer-generated random numbers work.
For now, consider the limiting case as
so that the random variable can truly fall
anywhere in the interval [0, 1). One curious result of passing to the limit is that now
.
(3.2)
That is, each point has zero probability of occurring. Yet, something has to occur! This
problem is common to continuous random variables, and it is clear that the probability mass
PX
k
N----
⎝
⎠
⎛
⎞
1
N----
=
k
0 1 2 … N
1
–
, , ,
,
=
N
∞
→
PX
k
N----
⎝
⎠
⎛
⎞
1
N----
N
∞
→
lim
0
=
=

64
Chapter 3
www.Academicpress.com
function is not a suitable description for such a random variable. The next sections develop
two alternative descriptions for continuous random variables, which will be used extensively
throughout the rest of the text.
3.1 The Cumulative Distribution Function
Since a continuous random variable will typically have a zero probability of taking on a
specific value, we avoid talking about such probabilities. Instead, events of the form
can be considered.
Definition 3.1: The CDF of a random variable,
, is
.
(3.3)
From this definition, several properties of the CDF can be inferred. First, since the CDF
is a probability, it must take on values between 0 and 1. Since random variables are real
valued, it is easy to conclude that
and
. That is, a real number
cannot be less than
and must be less than
. Next, if we consider two fixed values,
and
, such that
, then the event
is a subset of
. Hence,
. This implies that the CDF is a monotonic nondecreasing function. Also,
we can break the event
into the union of two mutually exclusive events,
. Hence,
, or
equivalently,
. Thus, the CDF can also be used to
measure the probability that a random variable takes on a value in a certain interval.
These properties of CDFs are summarized as follows:
(1)
,
,
(3.4a)
(2)
,
(3.4b)
(3) For
,
,
(3.4c)
(4) For
,
.
(3.4d)
Example 3.1:
Which of the following mathematical functions could be the CDF of some random
variable?
(a)
,
(b)
, (
is the unit step function),
X
x
≤
{
}
X
F X x
( )
Pr X
x
≤
(
)
=
F X
∞
–
(
)
0
=
F X ∞
(
)
1
=
∞
–
∞
x1
x2
x1
x2
<
X
x1
≤
{
}
X
x2
≤
{
}
F x x1
(
)
Fx x2
(
)
≤
X
x2
≤
{
}
X
x2
≤
{
}
X
x1
≤
{
}
x1
X
x2
≤
<
{
}
∪
=
F X x2
(
)
F X x1
(
)
Pr x1
X
x2
≤
<
(
)
+
=
Pr x1
X
x2
≤
<
(
)
F X x2
(
)
F X x1
(
)
–
=
F X
∞
–
(
)
0
=
F X ∞
(
)
1
=
0
F X x
( )
1
≤
≤
x1
x2
<
F X x1
(
)
F X x2
(
)
≤
x1
x2
<
Pr x1
X
x2
≤
<
(
)
F X x2
(
)
F X x1
(
)
–
=
F X x
( )
1
2---
1
p---tan 1
–
x
( )
+
=
F X x
( )
1
e x
–
–
[
]u x
( )
=
u x
( )


Random Variables, Distributions, and Density Functions
65
www.Academicpress.com
(c)
,
(d)
.
To determine this, we need to check that the function starts at zero when
, ends
at one when
, and is monotonic increasing in between. The first two functions
satisfy these properties and thus are valid CDFs while the last two do not. The function
in (c) is decreasing for positive values of
, while the function in (d) takes on values
greater than 1 and
.
To more carefully illustrate the behavior of the CDF, let us return to the computer random
number generator which generates N possible values from the set {0, 1/N, 2/N, ..., (N - 1)/N}
with equal probability. The CDF for this particular random variable can be described as
follows. First,
for all
, since the random variable cannot take on negative
values. Similarly,
for all
since the random variable cannot be
greater than (N-1)/N. Next, consider a value of x in the range
. In this case,
since the only value in the specified range that this random variable
can take on is
. Hence
for
. Similarly, for
,
.
Following this same reasoning, it is seen that, in general, for an integer k such that
and
,
. A plot of
as a function of x would
produce the general staircase-type function shown in Figure 3.1. In Figure 3.2a and b, the
CDF is shown for specific values of
and
, respectively. It should be clear
from these plots that in the limit as N passes to infinity, the CDF of Figure 3.2c results. The
functional form of this CDF is
(3.5)
F X x
( )
e x2
–
=
F X x
( )
x2u x
( )
=
x
∞
–
=
x
∞
=
x
F X ∞
(
)
1
≠
F X x
( )
0
=
x
0
<
F X x
( )
1
=
x
N
1
–
(
) N
⁄
≥
0
x
1 N
⁄
<
≤
Pr X
x
≤
(
)
Pr X = 0
(
)
=
X
0
=
F X x
( )
Pr X = 0
(
)
1 N
⁄
=
=
0
x
1 N
⁄
<
≤
1 N
⁄
x
2 N
⁄
<
≤
F X x
( )
Pr X
0
=
(
)
Pr X
1 N
⁄
=
(
)
+
2 N
⁄
=
=
1 N
⁄
2 N
⁄
N
1
–
N
1 N
⁄
2 N
⁄
3 N
⁄
N
2
–
N
. . .
1
FX(x)
x
Figure 3.1
General CDF of the random variable X.
0
k
N
<
<
k
1
–
(
) N
⁄
x
k N
⁄
<
≤
F X x
( )
k N
⁄
=
F X x
( )
N
10
=
N
50
=
F X x
( )
0,
x
0,
≤
x,      0
x
1,
≤
<
1,
x
1.
>
⎩
⎪
⎨
⎪
⎧
=


66
Chapter 3
www.Academicpress.com
In this limiting case, the random variable X is a continuous random variable and takes on
values in the range [0, 1) with equal probability. Later in the chapter, this will be referred
to as a uniform random variable. Note that when the random variable was discrete, the
CDF was discontinuous and had jumps at the specific values that the random variable
could take on whereas, for the continuous random variable, the CDF was a continuous
function (although its derivative was not always continuous). This last observation turns
out to be universal in that continuous random variables have a continuous CDF, while
discrete random variables have a discontinuous CDF with a staircase type of function.
(c)
(a)
(b)
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
x
Fx(x)
CDF of the random variable X for N= 10
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
x
CDF of the random variable X for N= 50
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
x
CDF of the  random variable X as N goes to infinity
FX(x)
FX(x)
Figure 3.2
CDF of the random variable X for (a) N = 10, (b) N = 50, and (c)
.
N
∞
→

Random Variables, Distributions, and Density Functions
67
www.Academicpress.com
Occasionally, one also needs to work with a random variable whose CDF is continuous in
some ranges and yet also has some discontinuities. Such a random variable is referred to
as a mixed random variable.
Example 3.2:
Suppose we are interested in observing the occurrence of certain events and noting the
time of first occurrence. The event might be the emission of a photon in our optical
photodetector at the end of Chapter 2, the arrival of a message at a certain node in a
computer communications network, or perhaps the arrival of a customer in a store.
Let
be a random variable that represents the time that the event first occurs. We
would like to find the CDF of such a random variable,
. Since the
event could happen at any point in time and time is continuous, we expect
to be a
continuous random variable. To formulate a reasonable CDF for this random
variable, suppose we divide the time interval
into many, tiny nonoverlapping time
intervals of length
. Assume that the probability that our event occurs in a time
interval of length
is proportional to
and take
to be the constant of
proportionality, That is
.
We also assume that the event occurring in one interval is independent of the event
occurring in another nonoverlapping time interval. With these rather simple
assumptions, we can develop the CDF of the random variable
as follows:
,
.
In this equation, it is assumed that the time interval
has been divided into
intervals of length
. Since each of the events in the expression are independent, the
probability of the intersection is just the product of the probabilities, so that
.
Finally, we pass to the limit as
or, equivalently,
to produce
.
X
F X t( )
Pr X
t
≤
(
)
=
X
0 t ]
,
(
Dt
Dt
Dt
l
Pr event occurs in kDt
k
1
+
(
)Dt
,
(
)
(
)
l
t
D
=
X
F X t( )
Pr X
t
≤
(
)
1
Pr X
t
>
(
)
–
=
=
Pr X
t
>
(
)
Pr X
0 t ]
,
(
∉
(
)
Pr
X
0
t
Δ ]
,
(
∉
{
}
X
t
Δ 2 t
Δ ]
,
(
∉
{
}
…
X
k
1
–
(
) t
Δ k t
Δ ]
,
(
∉
{
}
∩
∩
∩
(
)
=
=
0 t ]
,
(
k
Δt
Pr X
t
>
(
)
Pr X
0
t
Δ ]
,
(
∉
(
)Pr X
t
Δ 2 t
Δ ]
,
(
∉
(
)…Pr X
k
1
–
(
) t
Δ k t
Δ ]
,
(
∉
(
)
=
1
l t
Δ
–
(
)k
1
lt
k-----
–
⎝
⎠
⎛
⎞k
=
=
t
Δ
0
→
k
∞
→
Pr X
t
>
(
)
e lt
–
u t( )
=
F X t( )
⇒
1
e lt
–
–
(
)u t( )
=



68
Chapter 3
www.Academicpress.com
Example 3.3:
Suppose a random variable has a CDF given by
. Find the following
quantities:
(a)
,
(b)
,
(c)
,
(d)
.
For part (a), we note that
. In part (b), we note
that
gives us
, which is not quite what we want. However, we note that
.
Hence,
.
In this case, since
is a continuous random variable,
and so there is no need
to make a distinction between
and
; however, for discrete random
variables, we would need to be careful. Accordingly,
. For
part (c), we note that in general
. Again, for this continuous
random variable,
, so we can also write
.
Finally, for part (d) we invoke the definition of conditional probability to write the required
quantity in terms of the CDF of
:
.
For discrete random variables, the CDF can be written in terms of the probability mass
function defined in Chapter 2. Consider a general random variable, X, which can take on
values from the discrete set
. The CDF for this random variable is
, for
.
(3.6)
The constraint in this equation can be incorporated using unit step functions, in which case the
CDF of a discrete random variable can be written as
.
(3.7)
In conclusion, if we know the PMF of a discrete random variable, we can easily construct its CDF.
F X x
( )
1
e x
–
–
(
)u x
( )
=
Pr X
5
>
(
)
Pr X
5
<
(
)
Pr 3
X
7
<
<
(
)
Pr X
5
>
X
7
<
(
)
Pr X
5
>
(
)
1
Pr X
5
≤
(
)
–
1
F X 5
( )
–
e 5
–
=
=
=
F X 5
( )
Pr X
5
≤
(
)
F X 5
( )
Pr
X
5
<
{
}
X = 5
{
}
∪
(
)
Pr X
5
<
(
)
Pr X = 5
(
)
+
=
=
Pr X
5
<
(
)
F X 5
( )
Pr X = 5
(
)
–
=
X
Pr X
5
=
(
)
0
=
Pr X
5
<
(
)
Pr X
5
≤
(
)
Pr X
5
<
(
)
F X 5
( )
1
5
–
(
)
exp
–
=
=
F X 7
( )
F X 3
( )
–
Pr 3
X
7
≤
<
(
)
=
Pr X
7
=
(
)
0
=
Pr 3
X
7
<
<
(
)
F X 7
( )
F X 3
( )
–
e 3
–
e 7
–
–
=
=
X
Pr X
5
>
X
7
<
(
)
Pr
X
5
>
{
}
X
7
<
{
}
∩
(
)
Pr X
7
<
(
)
-----------------------------------------------------------
Pr 5
X
7
<
<
(
)
Pr X
7
<
(
)
---------------------------------
F X 7
( )
F X 5
( )
–
F X 7
( )
--------------------------------------
e 5
–
e 7
–
–
1
e 7
–
–
---------------------
=
=
=
=
x1 x2 x3 …
,
,
,
{
}
F X x
( )
PX xi
(
)
i
1
=
k
∑
=
xk
x
xk
1
+
<
≤
F X x
( )
PX xi
(
)u x
xi
–
(
)
i
1
=
k
∑
=



Random Variables, Distributions, and Density Functions
69
www.Academicpress.com
3.2 The Probability Density Function
While the CDF introduced in the last section represents a mathematical tool to statistically
describe a random variable, it is often quite cumbersome to work with CDFs. For example, we
will see later in this chapter that the most important and commonly used random variable, the
Gaussian random variable, has a CDF which cannot be expressed in closed form.
Furthermore, it can often be difficult to infer various properties of a random variable from its
CDF. To help circumvent these problems, an alternative and often more convenient
description known as the probability density function is often used.
Definition 3.2: The PDF of the random variable X evaluated at the point x is
.
(3.8)
As the name implies, the PDF is the probability that the random variable X lies in an
infinitesimal interval about the point X = x, normalized by the length of the interval.
Note that the probability of a random variable falling in an interval can be written in terms of
its CDF as specified in Equation (3.4d). For continuous random variables,
(3.9)
so that
.
(3.10)
Hence, it is seen that the PDF of a random variable is the derivative of its CDF. Conversely,
the CDF of a random variable can be expressed as the integral of its PDF. This property is
illustrated in Figure 3.3. From the definition of the PDF in Equation (3.8), it is apparent that
f X x
( )
Pr x
X
x
e
+
<
≤
(
)
e
-------------------------------------------
e
0
→
lim
=
Pr x
X
x
e
+
<
≤
(
)
F X x
e
+
(
)
F X x
( )
–
=
f X x
( )
F X x
e
+
(
)
F X x
( )
–
e
------------------------------------------------
e
0
→
lim
dF X x
( )
dx
-------------------
=
=
xo
x
fX(x)
FX(xo) = area
Figure 3.3
Relationship between the PDF and CDF of a random variable.

70
Chapter 3
www.Academicpress.com
the PDF is a nonnegative function although it is not restricted to be less than unity as with the
CDF. From the properties of the CDFs, we can also infer several important properties of
PDFs. Some properties of PDFs are
(1)
;
(3.11a)
(2)
;
(3.11b)
(3)
;
(3.11c)
(4)
;
(3.11d)
(5)
.
(3.11e)
Example 3.4:
Which of the following are valid PDFs?
(a)
;
(b)
;
(c)
(d)
(e)
.
To verify the validity of a potential PDF, we need to verify only that the function is
nonnegative and normalized so that the area underneath the function is equal to unity.
The function in part (c) takes on negative values, while the function in part (b) is not
properly normalized, and therefore these are not valid PDFs. The other three
functions are valid PDFs.
f X x
( )
0
≥
f X x
( )
dF X x
( )
dx
-------------------
=
F X x
( )
f X y
( ) y
d
∞
–
x
∫
=
f X x
( )
∞
–
∞∫
dx
1
=
f X x
( ) x
d
a
b
∫
Pr a
X
b
≤
<
(
)
=
f X x
( )
e x
– u x
( )
=
f X x
( )
e
x
–
=
f X x
( )
3
4--- x2
1
–
(
),
x
2,
<
0,      
otherwise;
⎩
⎪
⎨
⎪
⎧
=
f X x
( )
1,   0
x
1,
<
≤
0,    otherwise;
⎩
⎨
⎧
=
f X x
( )
2xe x2
– u x
( )
=



Random Variables, Distributions, and Density Functions
71
www.Academicpress.com
Example 3.5:
A random variable has a CDF given by
. Its PDF is then given by
.
Likewise, if a random variable has a PDF given by
, then its CDF is given by
.
Example 3.6:
The MATLAB function rand generates random numbers that are uniformly
distributed in the interval (0, 1) using an algorithm which is discussed in
Chapter 12. For the present, consider the algorithm to select a number from a
table in a random like manner. To construct a histogram for the random
numbers generated by rand we write a script that calls rand repeatedly. Since
we can do this only a finite number of times, we quantize the range of the random numbers into
increments of 0.1. We then calculate the number of times a random number falls in each
quantized interval and divide by the total number of numbers generated for the example. If we
plot this ratio of relative frequencies using a bar graph, the resulting plot is called a histogram.
The MATLAB script for this example follows and the histogram is shown in Figure 3.4, where the
total number of values generated is 10,000. Try changing the value of N or the number and
width of the bins in this example to see how results vary.
N=10,000;
% do N times
x=rand(1,N); 
% produce N random numbers
bins=[0.05:0.1:0.95]; 
% create 10 bins, 
% with centers at 0.05, 0.15, ...
[yvalues,xvalues]=hist(x,bins); 
% define xvalues and yvalues
yvalues=yvalues/N; 
% Normalize to produce 
% relative frequencis
bar(xvalues,yvalues); 
% plot bar graph
xlabel(‘x’)
ylabel(‘Relative Frequencies’)
3.3 The Gaussian Random Variable
In the study of random variables, the Gaussian random variable is the most commonly used
and of most importance. As will be seen later in the text, many physical phenomenon can be
modeled as Gaussian random variables, including the thermal noise encountered in electronic
F X x
( )
1
e lx
–
–
(
)u x
( )
=
f X x
( )
dF X x
( )
dx
-------------------
le lx
–
u x
( )
=
=
f X x
( )
2xe x2
– u x
( )
=
F X x
( )
f X y
( ) y
d
∞
–
x
∫
2ye y2
–
∞
–
x
∫
u y
( )dy
2ye y2
–
0
x
∫
dyu x
( )
1
e x2
–
–
(
)u x
( )
=
=
=
=





72
Chapter 3
www.Academicpress.com
circuits. Although many students may not realize it, they are probably quite familiar with the
Gaussian random variable, for it is this random variable which leads to the so-called curve on
which many students are graded.
Definition 3.3: A Gaussian random variable is one whose PDF can be written in the
general form
.
(3.12)
The PDF of the Gaussian random variable has two parameters,
and
, which have
the interpretation of the mean and standard deviation, respectively.1 The parameter
is referred to as the variance.
An example of a Guassian PDF is shown in Figure 3.5. In general, the Gaussian PDF is
centered about the point
and has a width that is proportional to
.
0
0.2
0.4
0.6
0.8
1
0
0.02
0.04
0.06
0.08
0.1
0.12
x
Relative frequencies
Figure 3.4
Histogram of relative frequencies for a uniform random variable generated by MATLAB’s
rand function using 10,000 trials.
f X x
( )
1
2ps 2
------------------
x
m
–
(
)2
2s 2
--------------------
–
⎝
⎠
⎛
⎞
exp
=
m
s
s 2
x
m
=
s
1 The terms mean, standard deviation, and variance will be defined and explained carefully in the next
chapter.

Random Variables, Distributions, and Density Functions
73
www.Academicpress.com
It should be pointed out that in the mathematics and statistics literature, this random variable is
referred to as a “normal” random variable. Furthermore, for the special case when
and
, it is called a “standard normal” random variable. However, in the engineering
literature the term Gaussian is much more common, so this nomenclature will be used
throughout this text.
Because Gaussian random variables are so commonly used in such a wide variety of
applications, it is standard practice to introduce a shorthand notation to describe a Gaussian
random variable,
. This is read “X is distributed normally (or Gaussian) with
mean, m, and variance,
.”
The first topic to be addressed in the study of Gaussian random variables is to find its CDF.
The CDF is required whenever we want to find the probability that a Gaussian random
variable lies above or below some threshold or in some interval. Using the relationship in
Equation (3.11c), the CDF of a Gaussian random variable is written as
.
(3.13)
It can be shown that it is impossible to express this integral in closed form. While this is
unfortunate, it does not stop us from extensively using the Gaussian random variable. Two
approaches can be taken to dealing with this problem. As with other important integrals that
cannot be expressed in closed form (e.g., Bessel functions), the Gaussian CDF has been
m
0
=
s
1
=
X
N m s 2
,
(
)
∼
s 2
−5
0
5
10
0
(a)
(b)
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
x
fX(x)
−5
0
5
10
0
0.2
0.4
0.6
0.8
1
x
FX(x)
Figure 3.5
(a) PDF and (b) CDF of a Gaussian random variable with
and
.
m
3
=
s
2
=
F X x
( )
1
2ps 2
------------------
y
m
–
(
)2
2s 2
---------------------
–
⎝
⎠
⎛
⎞
exp
y
d
∞
–
x
∫
=

74
Chapter 3
www.Academicpress.com
extensively tabulated and one can always look up values of the required CDF in a table, such
as the one provided in Appendix E. However, it is often a better option to use one of several
numerical routines which can approximate the desired integral to any desired accuracy.
The same sort of situation exists with many more commonly known mathematical functions. For
example, what if a student was asked to find the tangent of 1.23 radians? While the student could
look up the answer in a table of trig functions, that seems like a rather archaic approach. Any
scientific calculator, high-level programming language, or math package will have internally
generated functions to evaluate such standard mathematical functions. While not all scientific
calculators and high-level programming languages have internally generated functions for
evaluating Gaussian CDFs, most mathematical software packages do, and in any event, it is a fairly
simple thing to write short program to evaluate the required function. Some numerical techniques
for evaluating functions related to the Gaussian CDF are discussed specifically in Appendix F.
Whether the Gaussian CDF is to be evaluated by using a table or a program, the required CDF
must be converted into one of a few commonly used standard forms. A few of these common
forms are
•
error function integral,
,
•
complementary error function integral,
,
•
-function,
,
•
Q-function, 
.
The error function and its complement are most commonly used in the mathematics community;
however, in this text, we will primarily use the Q-function. Nevertheless, students at least need to
be familiar with the relationship between all of these functions because most math packages will
have internally defined routines for the error function integral and perhaps its complement as well,
but usually not the F-function or the Q-function. So, why not just use error functions? The reason
is that if one compares the integral expression for the Gaussian CDF in Equation (3.13) with the
integral functions defined in our list, it is a more straightforward thing to express the Gaussian CDF
in terms of a F-function or a Q-function. Also, the Q-function seems to be enjoying the most
common usage in the engineering literature in recent years.
Perhaps the advantage of not working with error function integrals is clearer if we note that the
F-function is simply the CDF of a standard normal random variable. For general Gaussian
random variables which are not in the normalized form, the CDF can be expressed in terms of a
F-function using a simple transformation. Starting with the Gaussian CDF in Equation (3.13),
make the transformation
, resulting in
erf x
( )
2
p
-------
t2
–
(
)
exp
td
0
x∫
=
erfc x
( )
1
erf x
( )
–
2
p
-------
t2
–
(
)
exp
td
x
∞∫
=
=
F
F x
( )
1
2p
-----------
t2
2----
–
⎝
⎠
⎛
⎞
exp
td
∞
–
x
∫
=
Q x
( )
1
2p
-----------
t2
2----
–
⎝
⎠
⎛
⎞
exp
td
x
∞∫
=
t
y
m
–
(
) s
⁄
=

Random Variables, Distributions, and Density Functions
75
www.Academicpress.com
. (3.14)
Hence, to evaluate the CDF of a Gaussian random variable, we just evaluate the F-function at
the points
.
The Q-function is more natural for evaluating probabilities of the form
. Following
a line of reasoning identical to the previous paragraph, it is seen that if
, then
.
(3.15)
Furthermore, since we have shown that
and
, it is apparent that the relationship between the F-function and
the Q-function is
.
(3.16)
This and other symmetry relationships can be visualized using the graphical definitions of the
F-function (phi function) and the
-function shown in Figure 3.6. Note that the CDF of a
Gaussian random variable can be written in terms of a Q-function as
.
(3.17)
F X x
( )
1
2ps 2
------------------
y
m
–
(
)2
2s 2
---------------------
–
⎝
⎠
⎛
⎞
exp
y
d
∞
–
x
∫
1
2p
-----------
t2
2----
–
⎝
⎠
⎛
⎞
exp
td
∞
–
x
m
–
s
-------------
∫
F x
m
–
s
-------------
⎝
⎠
⎛
⎞
=
=
=
x
m
–
(
) s
⁄
Pr X
x
>
(
)
X
N m s 2
,
(
)
∼
Pr X
x
>
(
)
1
2p
-----------
t2
2----
–
⎝
⎠
⎛
⎞
exp
td
x
m
–
s
-------------
∞∫
Q x
m
–
s
-------------
⎝
⎠
⎛
⎞
=
=
Pr X
x
>
(
)
Q
x
m
–
(
) s
⁄
(
)
=
Pr X
x
≤
(
)
F
x
m
–
(
) s
⁄
(
)
=
Q x
( )
1
F x
( )
–
=
1
2p
t2
2
−
exp
Q(x1)
(
(area under
right tail)
x1
F(x2)
(area under
left tail)
x2
)
Figure 3.6
Standardized integrals related to the Gaussian CDF: the
and
functions.
F .( )
Q .( )
Q
F X x
( )
1
Q x
m
–
s
-------------
⎝
⎠
⎛
⎞
–
=

76
Chapter 3
www.Academicpress.com
Once the desired CDF has been expressed in terms of a Q-function, the numerical value can be
looked up in a table or calculated with a numerical program. Other probabilities can be found in a
similar manner as shown in the next example. It should be noted that some internally defined
programs for Q and related functions may expect a positive argument. If it is required to evaluate
the Q-function at a negative value, the relationship
can be used. That is, to
evaluate
, for example,
can be evaluated and then use
.
Example 3.7:
A random variable has a PDF given by
Find each of the following probabilities and express the answers in terms of Q-functions.
(a)
,
(b)
,
(c)
,
(d)
.
For the given Gaussian PDF,
and
. For part (a),
.
This can be rewritten in terms of a Q-function as
.
The probability in part (b) is easier to express directly in terms of a Q-function.
.
In part (c), the probability of the random variable
falling in an interval is required. This
event can be rewritten as
=
-
=
=
.
We can proceed in a similar manner for part (d).
.
Example 3.8:
MATLAB has a built-in function, randn, which generates random variables
according to a Gaussian or normal distribution. In particular, randn(k,n)
creates an
matrix whose elements are randomly chosen according to a
standard normal distribution. This example constructs a histogram of the
numbers generated by the randn function similar to what was done in
Example 3.6 using the rand function. Note that by multiplying the output of the randn
Q x
( )
1
Q
x
–
(
)
–
=
Q
2
–
(
)
Q 2
( )
Q
2
–
(
)
1
Q 2
( )
–
=
f X x
( )
1
8p
-----------
x
3
+
(
)2
8
-------------------
–
⎝
⎠
⎛
⎞
exp
=
Pr X
0
≤
(
)
Pr X
4
>
(
)
Pr X
3
+
2
<
(
)
Pr X
2
–
1
>
(
)
m
3
–
=
s
2
=
Pr X
0
≤
(
)
F
0
3
–
(
)
–
(
) 2
⁄
(
)
F 1.5
(
)
=
=
Pr X
0
≤
(
)
1
Q 1.5
(
)
–
=
Pr X
4
>
(
)
Q
4
3
–
(
)
–
(
) 2
⁄
(
)
Q 3.5
(
)
=
=
X
Pr X
3
+
2
<
(
)
Pr
5
X
1
–
<
<
–
(
)
=
Pr X
5
–
>
(
)
Pr X
1
–
>
(
)
Q
1
–
(
)
Q 1
( )
–
1
2Q 1
( )
–
Pr X
2
–
1
>
(
)
Pr X
1
<
(
)
Pr X
3
>
(
)
+
F 2
( )
Q 3
( )
+
1
Q 2
( )
–
Q 3
( )
+
=
=
=
k
n
×




Random Variables, Distributions, and Density Functions
77
www.Academicpress.com
function by
and adding
, the Gaussian random variable produced by randn now has
mean
and variance
. We will elaborate on such transformations and others in the next
chapter. Note that the MATLAB code that follows is similar to that of Example 3.6 with the
exception that we are now using randn instead of rand. Also the Gaussian PDF has a
domain which is infinite and, thus, in principle we would need an infinite number of bins in
our histogram. Since this is impractical, we chose a sufficiently large number of bins such
that those not included would represent relatively insignificant values. Note also that in this
histogram we are plotting probability densities rather than relative frequencies so that a
direct comparison can be made between the histogram and the true PDF. The histogram
obtained using the following code is shown in Figure 3.7.
N=10,000;
% do N times
m=5; sigma=2;
% set mean and variance
x=m+sigma*randn(1,N); 
% produce N random numbers
left=-4.5; width=1; right=14.5;
% set bin parameters
bins=[left:width:right]; 
% create bins with centers at 
% left, left+width, ..., right
[yvalues,xvalues]=hist(x,bins); 
% define xvalues and yvalues
yvalues=yvalues/(N*width); 
% Normalize to produce 
% probability densities
bar(xvalues,yvalues); 
% plot bar graph
z=[left-width/2:width/10:right+width/2];
s
m
m
s 2
-5
0
5
10
15
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
x
fX(x)
Figure 3.7
Histogram of random numbers produces by randn along with a Gaussian PDF;
,
.
m
5
=
s
2
=
(Continued)

78
Chapter 3
www.Academicpress.com
pdf=exp(-(z-m).^2/(2*sigma^2));
% Compute true PDF.
pdf=pdf/sqrt(2*pi*sigma^2);
hold on
% place plot of true PDF on
plot(z,pdf)
% top of histogram.
xlabel(‘x’)
ylabel(‘f_X(x)’)  
3.4 Other Important Random Variables
This section provides a summary of some other important random variables that find use in
various engineering applications. For each random variable, an indication is given as to the
sorts of applications that find use for these random variables.
3.4.1 Uniform Random Variable
The uniform PDF is constant over an interval
. The PDF and its corresponding CDF are
(3.18a)
(3.18b)
Since this is a continuous random variable, the interval over which the PDF is nonzero
can be open or closed on either end. A plot of the PDF and CDF of a uniform random
variable is shown in Figure 3.8. Most computer random number generators will generate
1
b−a
x
a
b
fX(x)
x
a
b
FX(x)
1
(a)
(b)
Figure 3.8
(a) Probability density function and (b) cumulative distribution function of a uniform
random variable.
a b)
,
[
f X x
( )
1
b
a
–
------------, a
x
≤
b,
<
0,
elsewhere,
⎩
⎪
⎨
⎪
⎧
=
F X x
( )
0,
x
a,
<
x
a
–
b
a
–
------------,     a
x
≤
b,
<
1,
x
b.
≥
⎩
⎪
⎪
⎨
⎪
⎪
⎧
=


Random Variables, Distributions, and Density Functions
79
www.Academicpress.com
a random variable which closely approximates a uniform random variable over the
interval
. We will see in the next chapter that by performing a transformation on
this uniform random variable, we can create many other random variables of interest.
An example of a uniform random variable would be the phase of a radio frequency
sinusoid in a communication system. Although the transmitter knows the phase of the
sinusoid, the receiver may have no information about the phase. In this case, the phase at
the receiver could be modeled as a random variable uniformly distributed over the
interval
.
3.4.2 Exponential Random Variable
The exponential random variable has a PDF and CDF given by (for any
)
,
(3.19a)
.
(3.19b)
A plot of the PDF and the CDF of an exponential random variable is shown in Figure 3.9. The
parameter
is related to the width of the PDF and the PDF has a peak value of
which
occurs at
. The PDF and CDF are nonzero over the semi-infinite interval
, which
may be either open or closed on the left endpoint.
0 1
,
(
)
0 2p )
,
[
b
0
>
f X x
( )
1
b---
x
b---
–
⎝
⎠
⎛
⎞
exp
u x
( )
=
F X x
( )
1
x
b---
–
⎝
⎠
⎛
⎞
exp
–
u x
( )
=
0
5
10
0
(a)
(b)
0.1
0.2
0.3
0.4
0.5
0.6
x
fX(x)
0
5
10
0
0.2
0.4
0.6
0.8
1
x
FX(x)
Figure 3.9
(a) Probability density function and (b) cumulative distribution function of an
exponential random variable,
.
b
2
=
b
1 b
⁄
x
0
=
0 ∞
,
(
)

80
Chapter 3
www.Academicpress.com
Exponential random variables are commonly encountered in the study of queueing systems.
The time between arrivals of customers at a bank, for example, is commonly modeled as an
exponential random variable, as is the duration of voice conversations in a telephone network.
3.4.3 Laplace Random Variable
A Laplace random variable has a PDF which takes the form of a two-sided exponential. The
functional forms of the PDF and CDF are given by (for any
)
,
(3.20a)
(3.20b)
A plot of these functions is shown in Figure 3.10. The width of the PDF is determined by the
parameter
, while the peak value of the PDF is
. Note that this peak value is half of
what it is in the case of the (one-sided) exponential shown in Figure 3.9. This makes sense
since the Laplace random variable has two sides and the area under the curve must remain
constant (and equal to unity). The Laplace random variable has been used to model the
amplitude of a speech (voice) signal.
−10
0
10
0
0.05
0.1
0.15
0.2
0.25
x
fX(x)
−10
0
10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
FX(x)
(a)
(b)
Figure 3.10
(a) Probability density function and (b) cumulative distribution function of a Laplace
random variable,
.
b
2
=
b
0
>
f X x
( )
1
2b
------
x
b-----
–
⎝
⎠
⎛
⎞
exp
=
F X x
( )
1
2---
x
b---
⎝⎠
⎛⎞,
exp      
x
0,
<
1
1
2---
x
b---
–
⎝
⎠
⎛
⎞,
exp
–     
x
0.
≥
⎩
⎪
⎪
⎨
⎪
⎪
⎧
=
b
1 2b
⁄

Random Variables, Distributions, and Density Functions
81
www.Academicpress.com
3.4.4 Gamma Random Variable
A random variable that follows a gamma distribution has a PDF and CDF given (for any
and any
) by
,
(3.21a)
.
(3.21b)
In these two equations, the gamma function is a generalization of the factorial function
defined by
,
(3.22)
and the incomplete gamma function is given by
.
(3.23)
The gamma random variable is used in queueing theory and has several other random
variables as special cases. If the parameter
is an integer, the resulting random variable is
also known as an Erlang random variable, whereas, if
and
is a half integer, a chi-
squared (
) random variable results. Finally, if
, the gamma random variable reduces
to an exponential random variable.
3.4.5 Erlang Random Variable
As we have mentioned, the Erlang random variable is a special case of the gamma random
variable. The PDF and CDF are given (for positive integer
and any
) by
,
(3.24)
.
(3.25)
b
0
>
c
0
>
f X x
( )
x b
⁄
(
)c
1
–
x b
⁄
–
(
)
exp
bG c
( )
----------------------------------------------------u x
( )
=
F X x
( )
g c x b
⁄
,
(
)
G c
( )
------------------------u x
( )
=
G a
(
)
e t
– ta
1
–
td
0
∞
∫
=
g a b
,
(
)
e t
– ta
1
–
td
0
b
∫
=
c
b
2
=
c
c2
c
1
=
n
b
0
>
f X x
( )
x b
⁄
(
)n
1
–
x b
⁄
–
(
)
exp
b n
1
–
(
)!
----------------------------------------------------u x
( )
=
F X x
( )
1
x
b---
–
⎝
⎠
⎛
⎞
x b
⁄
(
)m
m!
------------------
m
0
=
n
1
–
∑
exp
–
u x
( )
=

82
Chapter 3
www.Academicpress.com
The Erlang distribution plays a fundamental role in the study of wireline telecommunication
networks. In fact, this random variable plays such an important role in the analysis of
trunked telephone systems that the amount of traffic on a telephone line is measured in
Erlangs.
3.4.6 Chi-Squared Random Variable
Another special case of the gamma random variable, the chi-squared (
) random variable has
a PDF and CDF given (for positive integer or half-integer values of
) by
,
(3.26)
.
(3.27)
Many engineering students are probably familiar with the
random variable from previous
studies of statistics. It also commonly appears in various detection problems.
3.4.7 Rayleigh Random Variable
A Rayleigh random variable, like the exponential random variable, has a one-sided PDF. The
functional form of the PDF and CDF is given (for any
) by
,
(3.28a)
.
(3.28b)
Plots of these functions are shown in Figure 3.11. The Rayleigh distribution is described by a
single parameter,
, which is related to the width of the Rayleigh PDF. In this case, the
parameter
is not to be interpreted as the variance of the Rayleigh random variable. It will
be shown later that the Rayleigh distribution arises when studying the magnitude of a complex
number whose real and imaginary parts both follow a zero-mean Gaussian distribution. The
Rayleigh distribution arises often in the study of noncoherent communication systems and also
in the study of wireless communication channels, where the phenomenon known as fading is
often modeled using Rayleigh random variables.
c2
c
f X x
( )
xc
1
–
x 2
⁄
–
(
)
exp
2cG c
( )
----------------------------------------u x
( )
=
F X x
( )
g c x 2
⁄
,
(
)
G c
( )
------------------------u x
( )
=
c2
s
0
>
f X x
( )
x
s 2
------
x2
2s 2
----------
–
⎝
⎠
⎛
⎞
exp
u x
( )
=
F X x
( )
1
x2
2s 2
----------
–
⎝
⎠
⎛
⎞
exp
–
⎝
⎠
⎛
⎞u x
( )
=
s 2
s 2

Random Variables, Distributions, and Density Functions
83
www.Academicpress.com
3.4.8 Rician Random Variable
A Rician random variable is closely related to the Rayleigh random variable (in fact the
Rayleigh distribution is a special case of the Rician distribution). The functional form of the
PDF for a Rician random variable is given (for any
and any
) by
.
(3.29)
In this expression, the function
is the modified Bessel function of the first kind of order
zero which is defined by
.
(3.30)
Like the Gaussian random variable, the CDF of a Rician random variable cannot be written in
closed form. Similar to the Q-function that is used to describe the Gaussian CDF, there is
another function known as Marcum’s Q-function which describes the CDF of a Rician
random variable. It is defined by
.
(3.31)
The CDF of the Rician random variable is then given by:
.
(3.32)
0
(a)
(b)
2
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
x
fX(x)
0
2
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
FX(x)
Figure 3.11
(a) Probability density function and (b) cumulative distribution function of a Rayleigh
random variable,
.
s2
1 2
⁄
=
a
0
>
s
0
>
f X x
( )
x
s 2
------
x2
a2
+
2s 2
------------------
–
⎝
⎠
⎛
⎞
exp
Io
ax
s 2
------
⎝
⎠
⎛
⎞u x
( )
=
Io x
( )
Io x
( )
1
2p
-------
ex
q
( )
cos
q
d
0
2p
∫
=
Q a b
,
(
)
z
z2
a2
+
(
)
2
-----------------------
–
⎝
⎠
⎛
⎞
exp
Io az
(
) z
d
b
∞
∫
=
F X x
( )
1
Q a
s---- x
s----
,
⎝
⎠
⎛
⎞
–
=

84
Chapter 3
www.Academicpress.com
Tables of the Marcum Q-function can be found as well as efficient numerical routines for
calculating it. A plot of the Rician PDF is shown in Figure 3.12. The Rician distribution is
described by two parameters,
and
, which are related to the center and width,
respectively, of the PDF. As with the Rayleigh random variable, the parameter
is not to be
interpreted as the variance of the Rician random variable. The Rician distribution arises in the
study of noncoherent communication systems and also in the study of satellite communication
channels, where fading is modeled using Rician random variables.
3.4.9 Cauchy Random Variable
The Cauchy random variable has a PDF and CDF given (for any
and any
) by
,
(3.33)
.
(3.34)
The Cauchy random variable occurs when observing the tangent of a random variable which is
uniformly distributed over
. The PDF is centered around
and its width is
determined by the parameter b. Unlike most of the other random variables where the PDFs
decrease exponentially in the tails, the Cauchy PDF decays quadratically as
increases.
Hence, there is a greater amount of probability in the tails of the Cauchy PDF than in many of
the other commonly used random variables. We say that this type of distribution is
“heavy-tailed.”
0
1
2
3
4
5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
x
fX(x)
a=1/2
a=1
a = 2
a = 3
Figure 3.12
PDF of a Rician random variable,
,
s2
1 2
⁄
=
a
1 2
⁄
1 2 3.
, , ,
=
a
s 2
s 2
a
b
0
>
f X x
( )
b p
⁄
b2
x
a
–
(
)2
+
-------------------------------
=
F X x
( )
1
2---
1
p---tan 1
–
x
a
–
b
-----------
⎝
⎠
⎛
⎞
+
=
0
[
2p )
,
x
a
=
x
a
–

Random Variables, Distributions, and Density Functions
85
www.Academicpress.com
Example 3.9:
One can construct many new types of random variables by making functions
of random variables. In this example, we construct a random variable which
is the sine of a uniform random phase. That is, we construct a random
variable
which is uniformly distributed over
and then form a new
random variable according to
. In the next chapter, we will
develop the tools to analytically figure out what the distribution of
should be, but for now
we will simply observe its PDF by plotting a histogram. The MATLAB code below was used
to accomplish this and the result is illustrated in Figure 3.13.
N=10000;
Theta=2*pi*rand(1,N);
% Uniform phase
X=sin(Theta);
% sinusoidal transformation
bins=[-0.95:0.1:0.95];
% histogram bins
[yvalues,xvalues]=hist(X,bins);
% histogram values
pdf_estimate=yvalues/(N*0.1);
% normalize prob. densities
bar(xvalues,pdf_estimate)
% plot PDF histogram
xlabel(‘x’); ylabel(‘f_X(x)’)
% label plot 
3.5 Conditional Distribution and Density Functions
In Chapter 2, we defined the notion of conditional probability. In a similar manner, it is quite
common to talk about the distribution or density of a random variable conditioned on some
event,
. As with the initial study of random variables in the beginning of this chapter, it is
convenient to start with the notion of a conditional CDF.
Q
0 2p )
,
[
X
Q
(
)
sin
=
X
−1
−0.5
0
0.5
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
x
fX(x)
Figure 3.13
Histogram from Example 3.10, sine of a uniform phase.
A



86
Chapter 3
www.Academicpress.com
Definition 3.4: The conditional CDF of a random variable,
, conditioned on the
event
having occurred is
.
(3.35)
Naturally, this definition requires the caveat that the probability of the event
must
not be zero.
The properties of CDFs listed in Equations (3.4a)–(3.4d) also apply to conditional CDFs,
resulting in the following properties of conditional CDFs:
(1)
,
,
(3.36a)
(2)
,
(3.36b)
(3)
For
,
,
(3.36c)
(4)
For
,
.
(3.36d)
It is left as an exercise for the reader (see Exercise 3.13) to prove that these properties of CDFs
do indeed apply to conditional CDFs as well.
Example 3.10:
Suppose a random variable
is uniformly distributed over the interval
so that its CDF
is given by
Suppose further that we want to find the conditional CDF of
given that
. Here, the
event
is related to a numerical condition on the random variable itself. From
the definition of a conditional CDF,
.
For
, the event
has probability zero and hence
for
. When
, the intersection of the events
and
is simply the event
, so that
for
.
X
A
F X A x
( )
Pr X
x
≤
A
(
)
Pr
X
x
≤
{
} A
,
(
)
Pr A
(
)
--------------------------------------
=
=
A
F X A
∞
–
(
)
0
=
F X A ∞
(
)
1
=
0
F X A x
( )
1
≤
≤
x1
x2
<
F X A x1
(
)
F X A x2
(
)
≤
x1
x2
<
Pr x1
X
x2
≤
<
A
(
)
F X A x2
(
)
F X A x1
(
)
–
=
X
0 1)
,
[
F X x
( )
0,
x
0,
<
x,      0
x
1,
≤
≤
1,
x
1.
>
⎩
⎪
⎨
⎪
⎧
=
X
X
1 2
⁄
<
A
X
1 2
⁄
<
{
}
=
F X
X
1 2
⁄
<
{
} x
( )
Pr X
x X
1 2
⁄
<
,
≤
(
)
Pr X
1 2
⁄
<
(
)
------------------------------------------------
=
x
0
<
X
x
≤
F X
X
1 2
⁄
<
{
} x
( )
0
=
x
0
<
0
x
1 2
⁄
≤
≤
X
x
≤
X
1 2
⁄
<
X
x
≤
F X
X
1 2
⁄
<
{
} x
( )
Pr X
x
≤
(
)
Pr X
1 2
⁄
<
(
)
-------------------------------
x
1 2
⁄
----------
2x
=
=
=
0
x
1 2
⁄
≤
≤


Random Variables, Distributions, and Density Functions
87
www.Academicpress.com
Finally, for
, the intersection of the events
and
is simply the event
and the conditional CDF reduces to one. Putting this all together, the desired conditional
CDF is
In order to generalize the result of the previous example, suppose that for some arbitrary random
variable
, the conditioning event is of the form
for some constants
. Then
.
(3.37)
If
, then the events
and
are mutually exclusive and the conditional
CDF is zero. For
the event
is a subset of
and hence
so that the conditional CDF is 1. When
,
then
and
. This
can be written in terms of the CDF (unconditional) of X as
.
Likewise,
. Putting these results together gives
(3.38)
This result could also be extended to conditioning events where
is conditioned on being in
more extravagant regions.
As with regular random variables, it is often more convenient to work with a conditional PDF
rather than a conditional CDF. The definition of the conditional PDF is a straightforward
extension of the previous definition given for a PDF.
Definition 3.5: The conditional PDF of a random variable
conditioned on some
event A is
.
(3.39)
As with the conditional CDF, it is not difficult to show that all of the properties of regular
PDFs apply to conditional PDFs as well. In particular,
x
1 2
⁄
>
X
x
≤
X
1 2
⁄
<
X
1 2
⁄
<
F X
X
1 2
⁄
<
{
} x
( )
0,
x
0,    
<
2x,
0
x
1 2,
⁄
≤
≤
1,
x
1 2.
⁄
>
.
⎩
⎪
⎨
⎪
⎧
=
X
A
a
X
b
≤
<
=
a
b
<
F X
a
X
b
≤
<
{
} x
( )
Pr X
x a
X
b
≤
<
,
≤
(
)
Pr a
X
b
≤
<
(
)
---------------------------------------------------
=
x
a
≤
X
x
≤
{
}
a
X
b
≤
<
x
b
>
a
X
b
≤
<
X
x
≤
{
}
Pr X
x a
X
b
≤
<
,
≤
(
)
Pr a
X
b
≤
<
(
)
=
a
x
b
≤
<
X
x
≤
{
}
a
X
b
≤
<
{
}
∩
a
X
x
≤
<
=
Pr X
x a
X
b
≤
<
,
≤
(
)
Pr a
X
<
x
≤
(
)
=
Pr a
X
<
x
≤
(
)
F X x
( )
F X a
( )
–
=
Pr a
X
b
≤
<
(
)
F X b
( )
F X a
( )
–
=
F X
a
X
b
<
≤
{
} x
( )
0,
x
a,
≤
F X x
( )
F X a
( )
–
F X b
( )
F X a
( )
–
---------------------------------------,     a
x
b,
≤
<
1,
x
b.
>
⎩
⎪
⎪
⎨
⎪
⎪
⎧
=
X
X
f X A x
( )
Pr x
X
x
e
+
<
≤
A
(
)
e
-------------------------------------------------
e
0
→
lim
=


88
Chapter 3
www.Academicpress.com
(1)
,
(3.40a)
(2)
,
(3.40b)
(3)
.
(3.40c)
(4)
,
(3.40d)
(5)
.
(3.40e)
Furthermore, the result in Equation (3.38) can be extended to the conditional PDF by applying
Equation (3.40b). This results in the following general formula for the conditional PDF of a
random variable,
, when the conditioning event is of the nature
:
(3.41)
To summarize, the conditional PDF takes on the same functional form (but is scaled by the
probability of the conditioning event) over the range of
where the condition is satisfied, and
the conditional PDF is zero wherever the conditioning event is not true. This result is
illustrated in Figure 3.14.
f X A x
( )
0
≥
f X A x
( )
dF X A x
( )
dx
-------------------------
=
F X A x
( )
f X A y
( ) y
d
∞
–
x
∫
=
f X A x
( )
∞
–
∞∫
dx
1
=
f X A x
( ) x
d
a
b
∫
Pr a
X
b
≤
<
A
(
)
=
X
A
a
X
b
<
≤
{
}
=
f X
a
X
b
<
≤
{
} x
( )
f X x
( )
Pr a
X
b
<
≤
(
)
---------------------------------,   
a
x
b,
<
≤
0,     
otherwise.
⎩
⎪
⎨
⎪
⎧
=
x
a
(a)
(b)
b
a
b
fX
fX(x)
x
x
{a<X<b}(x)
Figure 3.14
(a) A PDF and (b) the corresponding conditional PDF .

Random Variables, Distributions, and Density Functions
89
www.Academicpress.com
Example 3.11:
Let
be a random variable representing the length of time we spend waiting in the grocery
store checkout line. Suppose the random variable
has an exponential PDF given by
, where
min. What is the PDF for the amount of time we
spend waiting in line given that we have already been waiting for 2 min? Here the conditioning
event is of the form
. We can use the result in Equation (3.41) by taking
and
. The probability of the conditioning event is
.
Therefore, the conditional PDF is
.
It is curious to note that for this example,
. That is, given that we
have been waiting in line for 2 min, the PDF of the total time we must wait in line is simply
shifted by 2 min. This interesting behavior is unique to the exponential distribution and we
might not have seen the same result if we had started with a different distribution. For
example, try working the same problem starting with a Rayleigh distribution.
Up to this point, we have primarily looked at conditioning events that impose a numerical
constraint. It is also common to consider conditioning events of a qualitative, or nonnumerical,
nature. Consider, for example, a random variable
which represents a student’s score on a
certain standardized test (e.g., the SAT or GRE test). We might be interested in determining if
there is any gender bias in the test. To do so, we could compare the distribution of the variable
given that the student is female,
, with the distribution of the same variable given
that the student is male,
. If these distributions are substantially different, then we
might conclude a gender bias and work to fix the bias in the exam. Naturally, we could work
with conditional PDFs
and
as well. Here, the conditioning event is a
characteristic of the experiment that may affect the outcome rather than a restriction on the
outcome itself.
In general, consider a set of mutually exclusive and exhaustive conditioning events,
,
, ...,
. Suppose we had access to the conditional CDFs,
,
, and wanted to find the unconditional CDF,
. According to the
Theorem of Total Probability (Theorem 2.10),
.
(3.42)
X
X
f X x
( )
1 c
⁄
(
)
x c
⁄
–
(
)
exp
u x
( )
=
c
3
=
X
2
>
a
2
=
b
∞
=
Pr X
2
>
(
)
1
F X 2
( )
–
2 3
⁄
–
(
)
exp
=
=
f X
X
2
>
{
} x
( )
2 3
⁄
(
)
exp
f X x
( )u x
2
–
(
)
1
3---
x
2
–
3
-----------
–
⎝
⎠
⎛
⎞u x
2
–
(
)
exp
=
=
f X
X
2
>
{
} x
( )
f X x
2
–
(
)
=
X
X
F X F x
( )
F X M x
( )
f X F x
( )
f X M x
( )
A1 A2
AN
F X An x
( )
n
1 2 … N
, ,
,
=
F X x
( )
F X x
( )
Pr X
x
≤
(
)
Pr X
x
≤
An
(
)Pr An
(
)
n
1
=
N
∑
F X An x
( )Pr An
(
)
n
1
=
N
∑
=
=
=



90
Chapter 3
www.Academicpress.com
Hence, the CDF of
(unconditional) can be found by forming a weighted sum of the
conditional CDFs with the weights determined by the probabilities that each of the
conditioning events is true. By taking derivatives of both sides of the previous equation, a
similar result is obtained for conditional PDFs, namely
.
(3.43)
We might also be interested in looking at things in the reverse direction. That is, suppose we
observe that the random variable has taken on a value of
. Does the probability of the
event
change? To answer this we need to compute
. If
were a discrete
random variable, we could do this by invoking the results of Theorem 2.5
.
(3.44)
In the case of continuous random variables, greater care must be taken since both
and
will be zero, resulting in an indeterminate expression. To
avoid that problem, rewrite the event
as
and consider the result
in the limit as
:
.
(3.45)
Note that for infinitesimal
,
and similarly
. Hence,
.
(3.46)
Finally, passing to the limit as
gives the desired result:
.
(3.47)
We could also combine this result with Equation (3.43) to produce an extension to Bayes’s
theorem:
.
(3.48)
X
f X x
( )
f X An x
( )Pr An
(
)
n
1
=
N
∑
=
X
x
=
An
Pr An
X
x
=
(
)
(
)
X
Pr An X
x
=
(
)
Pr X
x
=
An
(
)Pr An
(
)
Pr X
x
=
(
)
----------------------------------------------------
=
Pr X
x
=
An
(
)
Pr X
x
=
(
)
X
x
=
{
}
x
X
x
e
+
<
≤
{
}
e
0
→
Pr An x
X
x
e
+
<
≤
(
)
Pr x
X
x
e
+
<
≤
An
(
)Pr An
(
)
Pr x
X
x
e
+
<
≤
(
)
---------------------------------------------------------------------
=
e
Pr x
X
x
e
+
<
≤
(
)
f X x
( )e
=
Pr x
X
x
e
+
<
≤
An
(
)
f X An x
( )e
=
Pr An x
X
x
e
+
<
≤
(
)
f X An x
( )ePr An
(
)
f X x
( )e
--------------------------------------------
f X An x
( )Pr An
(
)
f X x
( )
----------------------------------------
=
=
e
0
→
Pr An X
x
=
(
)
Pr An x
X
x
e
+
<
≤
(
)
e
0
→
lim
f X An x
( )Pr An
(
)
f X x
( )
----------------------------------------
=
=
Pr An X
x
=
(
)
f X An x
( )Pr An
(
)
f X An x
( )Pr An
(
)
n
1
=
N
∑
----------------------------------------------------
=

Random Variables, Distributions, and Density Functions
91
www.Academicpress.com
Example 3.12:
In a certain junior swimming competition, swimmers are placed into one of two categories
based on their previous times so that all children can compete against others of their own
abilities. The fastest swimmers are placed in the A category, while the slower swimmers
are put in the B group. Let
be a random variable representing a child’s time (in seconds)
in the 50-m freestyle race. Suppose that it is determined that for those swimmers in group
A, the PDF of a child’s time is given by
while for those in
the B group the PDF is given by
. Furthermore, assume
that 30% of the swimmers are in the A group and 70% are in the B group. If a child swims
the race with a time of 42 s, what is the probability that the child was in the B group?
Applying Equation (3.48) we get
.
Naturally, the probability of the child being from group A must then be
.
3.6 Engineering Application: Reliability and Failure Rates
The concepts of random variables presented in this chapter are used extensively in the study of
system reliability. Consider an electronic component that is to be assembled with other
components as part of a larger system. Given a probabilistic description of the lifetime of such
a component, what can we say about the lifetime of the system itself. The concepts of
reliability and failure rates are introduced in this section to provide tools to answer such
questions.
Definition 3.6: Let
be a random variable which represents the lifetime of a device.
That is, if the device is turned on at time zero,
would represent the time at which the
device fails. The reliability function of the device,
, is simply the probability
that the device is still functioning at time :
.
(3.49)
Note that the reliability function is just the complement of the CDF of the random variable.
That is,
. As it is often more convenient to work with PDFs rather than
CDFs, we note that the derivative of the reliability function can be related to the PDF of the
random variable
by
.
X
f X A x
( )
4p
(
) 1 2
⁄
–
x
40
–
(
)2 4
⁄
–
(
)
exp
=
f X B x
( )
4p
(
) 1 2
⁄
–
x
45
–
(
)2 4
⁄
–
(
)
exp
=
Pr B X
42
=
(
)
0.7 f X B 42
(
)
0.3 f X A 42
(
)
0.7 f X B 42
(
)
+
----------------------------------------------------------------------
0.7
9 4
⁄
–
(
)
exp
0.3
1
–
(
)
exp
0.7
9 4
⁄
–
(
)
exp
+
----------------------------------------------------------------------
0.4007
=
=
=
Pr A X
42
=
(
)
1
Pr B X
42
=
(
)
–
0.5993
=
=
X
X
RX t( )
t
RX t( )
Pr X
t
>
(
)
=
RX t( )
1
F X t( )
–
=
X
RX' t( )
f X t( )
–
=


:

92
Chapter 3
www.Academicpress.com
With many devices, the reliability changes as a function of how long the device has been
functioning. Suppose we observe that a particular device is still functioning at some point in time t.
The remaining lifetime of the device may behave (in a probabilistic sense) very differently from
when it was first turned on. The concept of failure rate is used to quantify this effect.
Definition 3.7: Let
be a random variable which represents the lifetime of a device.
The failure rate function is
.
(3.50)
To give this quantity some physical meaning, we note that
.
Thus,
is the probability that the device will fail in the next time instant of length
,
given the device has survived up to now (time
). Different types of “devices” have failure
rates that behave in different manners. Our pet goldfish, Elvis, might have an increasing
failure rate function (as do most biological creatures). That is, the chances of Elvis “going
belly up” in the next week is greater when Elvis is 6 months old than when he is just 1 month
old. We could also imagine devices that have a decreasing failure rate function (at least for
part of their lifetime). For example, an integrated circuit might be classified into one of two
types, those which are fabricated correctly and hence are expected to have a quite long lifetime
and those with defects which will generally fail fairly quickly. When we select an IC, we may
not know which type it is. Once the device lives beyond that initial period when the defective
ICs tend to fail, the failure rate may go down (at least for awhile). Finally, there may be some
devices whose failure rates remain constant with time.
The failure rate of a device can be related to its reliability function. From Equation (3.41) it is
noted that
.
(3.51)
The denominator in the above expression is the reliability function,
, while the PDF in
the numerator is simply
. Evaluating at
produces the failure rate function
.
(3.52)
Conversely, given a failure rate function,
, one can solve for the reliability function by
solving the first-order differential equation:
.
(3.53)
X
r t( )
f X
X
t
>
{
} x
( )
x
t
=
=
Pr t
X
t
dt
+
<
<
X
t
>
(
)
r t( )dt
=
r t( )dt
dt
t
f X
X
t
>
{
} x
( )
f X x
( )u x
t
–
(
)
1
F x t( )
–
-----------------------------------
=
RX t( )
RX' x
( )
–
x
t
=
r t( )
RX' t( )
–
RX t( )
-------------------
=
r t( )
d
dt
-----Rx t( )
r t( )
–
RX t( )
=

Random Variables, Distributions, and Density Functions
93
www.Academicpress.com
The general solution to this differential equation (subject to the initial condition
) is
.
(3.54)
It is interesting to note that a failure rate function completely specifies the PDF of a device’s
lifetime:
.
(3.55)
For example, suppose a device had a constant failure rate function,
. The PDF of the
device’s lifetime would then follow an exponential distribution,
.
The corresponding reliability function would also be exponential,
.
We say that the exponential random variable has the memoryless property. That is, it does not
matter how long the device has been functioning, the failure rate remains the same.
Example 3.13:
Suppose the lifetime of a certain device follows a Rayleigh distribution given by
. What are the reliability function and the failure rate function?
The reliability function is given by
.
A straightforward application of Equation (3.52) produces the failure rate function,
. In this case, the failure rate is linearly increasing in time.
Next, suppose we have a system which consists of
components, each of which has a
lifetime described by the random variable
,
. Furthermore, assume that for
the system to function, all
components must each be functioning. In other words, if any of
the individual components fail, the whole system fails. This is usually referred to as a series
connection of components. If we can characterize the reliability and failure rate functions of
each individual component, can we calculate the same functions for the entire system? The
answer is yes, under some mild assumptions. Define
to be the random variable representing
the lifetime of the system. Then
.
(3.56)
Furthermore,
.
(3.57)
Rx 0
( )
1
=
RX t( )
r u
( ) u
d
0
t∫
–
u t( )
exp
=
f X t( )
RX' t( )
–
r t( )
r u
( ) u
d
0
t∫
–
(
)u t( )
exp
=
=
r t( )
l
=
f X t( )
l
lt
–
(
)
exp
u t( )
=
RX t( )
lt
–
(
)
exp
u t( )
=
f X t( )
2bt
bt2
–
(
)
exp
u t( )
=
RX t( )
Pr X
t
>
(
)
2bu
bu2
–
(
)
exp
u
d
t
a∫
u t( )
bt2
–
(
)
exp
u t( )
=
=
=
r t( )
2btu t( )
=
N
X n n
1 2 … N
, ,
,
=
N
X
X
min X 1 X 2 … X N
,
,
,
(
)
=
RX t( )
Pr X
t
>
(
)
=
Pr
X 1
t
>
{
}
X 2
t
>
{
}
…
X N
t
>
{
}
∩
∩
∩
(
)
=



94
Chapter 3
www.Academicpress.com
We assume that all of the components fail independently. That is, the event
is taken
to be independent of
for all
. Under this assumption,
.
(3.58)
Furthermore, application of Equation (3.52) provides an expression for the failure rate function:
(3.59)
,
(3.60)
where
is the failure rate function of the
th component. We have shown that for a series
connection of components, the reliability function of the system is the product of the reliability
functions of each component and the failure rate function of the system is the sum of the
failure rate functions of the individual components.
We may also consider a system which consists of a parallel interconnection of components.
That is, the system will be functional as long as any of the components are functional. We can
follow a similar derivation to compute the reliability and failure rate functions for the parallel
interconnection system. First, the reliability function is written as
.
(3.61)
In this case, it is easier to work with the complement of the reliability function (the CDF of the
lifetime). Since the reliability function represents the probability that the system is still
functioning at time , the complement of the reliability function represents the probability that
the system is not working at time
. With the parallel interconnections, the system will fail
only if all the individual components fail. Hence,
.
(3.62)
As a result, the reliability function of the parallel interconnection system is given by
X i
t
>
{
}
X j
t
>
{
}
i
j
≠
RX t( )
Pr X 1
t
>
(
)Pr X 2
t
>
(
)…Pr X N
t
>
(
)
=
RX 1 t( )RX 2 t( )…RX N t( )
=
r t( )
RX' t( )
–
RX t( )
-------------------
d
dt
----- RX 1 t( )RX 2 t( )…RX N t( )
[
]
RX 1 t( )RX 2 t( )…RX N t( )
---------------------------------------------------------------------
–
=
=
RX n' t( )
RX n t( )
-----------------
n
1
=
N
∑
–
rn t( )
n
1
=
N
∑
=
=
rn t( )
n
RX t( )
Pr
X 1
t
>
{
}
X 2
t
>
{
}
…
X N
t
>
{
}
∪
∪
∪
(
)
=
t
t
1
RX t( )
–
Pr X
t
≤
(
)
Pr
X 1
t
≤
{
}
X 2
t
≤
{
}
…
X N
t
≤
{
}
∩
∩
∩
(
)
=
=
Pr X 1
t
≤
(
)Pr X 2
t
≤
(
)…Pr X N
t
≤
(
)
=
1
RX 1 t( )
–
(
) 1
RX 2 t( )
–
(
)… 1
RX N t( )
–
(
)
=

Random Variables, Distributions, and Density Functions
95
www.Academicpress.com
.
(3.63)
Unfortunately, the general formula for the failure rate function is not as simple as in the serial
interconnection case. Application of Equation (3.52) to our preceding equation gives (after
some straightforward manipulations)
,
(3.64)
or, equivalently,
.
(3.65)
Example 3.14:
Suppose a system consists of
components each with a constant failure rate,
,
. Find the reliability and failure rate functions for a series interconnection.
Then find the same functions for a parallel interconnection. It was shown previously
that a constant failure rate function corresponds to an exponential reliability function.
That is,
. For the serial interconnection we then have
,
.
For the parallel interconnection,
,
.
RX t( )
1
1
RX n t( )
–
(
)
n
1
=
N
∏
–
=
r t( )
1
RX t( )
–
Rx t( )
------------------------
RX n' t( )
1
RX n t( )
–
-------------------------
n
1
=
N∑
–
=
r t( )
1
RX t( )
---------------
1
–
rn t( )
1
RX n t( )
----------------
1
–
--------------------------
n
1
=
N
∑
=
N
rn t( )
ln
=
n
1 2 … N
, ,
,
=
RX n t( )
lnt
–
(
)
exp
u t( )
=
RX t( )
RX n t( )
n
1
=
N
∏
lnt
–
(
)
exp
u t( )
n
1
=
N
∏
ln
n
1
=
N
∑
t
–
⎝
⎠
⎜
⎟
⎛
⎞
exp
u t( )
=
=
=
r t( )
rn t( )
n
1
=
N
∑
ln
n
1
=
N
∑
=
=
RX t( )
1
1
lnt
–
(
)
exp
–
[
]
n
1
=
N
∏
–
⎩
⎭
⎨
⎬
⎧
⎫u t( )
=
r t( )
1
lnt
–
(
)
exp
–
[
]
n
1
=
N
∏
1
1
lnt
–
(
)
exp
–
[
]
n
1
=
N
∏
–
-----------------------------------------------------------
ln
lnt
(
)
exp
1
–
-------------------------------
n
1
=
N
∑
=



97
CHAPTER 3
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 3.1: The Cumulative Distribution Function
3.1
Which of the following mathematical functions could be the CDF of some random
variable?
(a)
(c)
(b)
(d)
.
3.2
Suppose a random variable has a CDF given by
.
Find the following quantities:
(a)
,
(b)
,
(c)
,
(d)
.
3.3
Repeat Exercise 3.2 for the case where the random variable has the CDF
.
F X x
( )
1
x ,
–
x
1,
≤
0,
x
1.
<
⎩
⎨
⎧
=
F X x
( )
1
2---ex,
x
0,
<
1
1
2---e x
– ,
–
x
0.
≥
⎩
⎪
⎪
⎨
⎪
⎪
⎧
=
F X x
( )
0,
x
0,
≤
x2, 0
x
1,
≤
<
1,
x
1.
>
⎩
⎪
⎨
⎪
⎧
=
F X x
( )
log x
( )u x
( )
=
F X x
( )
x2
1
x2
+
--------------u x
( )
=
Pr X
2
<
(
)
Pr X
4
>
(
)
Pr 1
X
3
<
<
(
)
Pr X
2
>
X
4
<
(
)
F X x
( )
1
2---
1
p---tan 1
–
x
( )
+
⎝
⎠
⎛
⎞u x
( )
=

98
Chapter 3
www.Academicpress.com
3.4
Suppose we flip a balanced coin five times and let the random variable
represent the
number of times heads occurs.
(a)
Sketch the CDF of
,
.
(b)
Write
analytically in terms of unit step functions.
3.5
A random variable is equally likely to take on any integer value in the set
.
(a)
Sketch the CDF of
,
.
(b)
Write
analytically in terms of unit step functions.
3.6
A certain discrete random variable has a CDF given by
.
(a)
Find the probability mass function,
, of this random variable.
(b)
For a positive integer
, find
.
(c)
For two positive integers,
and
, such that
, find
.
3.7
In this problem, we generalize the results of Exercise 3.6. Suppose a discrete random
variable takes on nonnegative integer values and has a CDF of the general form
.
(a)
What conditions must the sequence
satisfy for this to be a valid CDF.
(b)
For a positive integer
, find
in terms of the
.
3.8
A random variable has a CDF given by
.
(a)
Find
.
(b)
Find
.
(c)
Find
.
(d)
Find
.
X
X
F X x
( )
F X x
( )
0 1 2 3
, , ,
{
}
X F X x
( )
F X x
( )
F X x
( )
1
2---
⎝⎠
⎛⎞
k
1
+
u x
k
–
(
)
k
0
=
∞
∑
=
PX k
( )
n
Pr X
n
≥
(
)
n1
n2
n1
n2
<
Pr n1
X
≤
n2
<
(
)
F X x
( )
aku x
k
–
(
)
k
0
=
∞
∑
=
ak
n
Pr X
n
≤
(
)
ak
F X x
( )
1
e x
–
–
(
)u x
( )
=
Pr X
3
>
(
)
Pr X
5 X
3
>
<
(
)
Pr X
6 X
3
>
>
(
)
Pr X
5
–
4
<
X
6
–
2
>
(
)

Exercises
99
www.Academicpress.com
3.9
A random variable has a CDF given by
(a)
Find
and
.
(b)
Find
and
.
(c)
Find
.
Section 3.2: The Probability Density Function
3.10 Suppose a random variable is equally likely to fall anywhere in the interval
. Then
the PDF is of the form
Find and sketch the corresponding CDF.
3.11 Find and plot the CDFs corresponding to each of the following PDFs:
(a)
(b)
F X x
( )
0,
x
0,
<
1
x
+
2
------------,      0
x
1,
≤
≤
1,
x
1.
>
⎩
⎪
⎪
⎨
⎪
⎪
⎧
=
Pr X =0
(
)
Pr X =1
(
)
Pr X
0
<
(
)
Pr X
1
2---
>
⎝
⎠
⎛
⎞
Pr X
1
2---
>
X
0
>
⎝
⎠
⎛
⎞
a b
,
[
]
f X x
( )
1
b
a
–
------------, 
a
x
b,
≤
≤
0,   
otherwise.
⎩
⎪
⎨
⎪
⎧
=
f X x
( )
1,
0
x
1,
<
≤
0,   otherwise.
⎩
⎨
⎧
=
f X x
( )
x, 
0
x
1,
<
≤
2
x,
– 
1
x
2,
<
≤
0,   
otherwise.
⎩
⎪
⎨
⎪
⎧
=

100
Chapter 3
www.Academicpress.com
3.12 A random variable has the following exponential PDF:
where
and
are constants.
(a)
Determine the required relationship between
and
.
(b)
Determine the corresponding CDF.
3.13 A certain random variable has a probability density function of the form
. Find the following:
(a)
the constant
,
(b)
,
(c)
,
(d)
.
3.14 Repeat Exercise 3.13 using the PDF
.
3.15 Repeat Exercise 3.13 using the PDF
,  
.
3.16 The voltage of communication signal
is measured. However, the measurement
procedure is corrupted by noise resulting in a random measurement with the PDF shown
in the accompanying diagram. Find the probability that for any particular measurement,
the error will exceed
% of the correct value if this correct value is 10 V.
f X x
( )
a bx
– ,
x
0,   
≤
0,    
otherwise,
⎩
⎨
⎧
=
a
b
a
b
f X x
( )
ce 2x
– u x
( )
=
c
Pr X
2
>
(
)
Pr X
3
<
(
)
Pr X
3 X
2
>
<
(
)
f X x
( )
c
x2
4
+
--------------
=
f X x
( )
c
25
x2
–
---------------------
=
5
x
5
<
<
–
S
0.75
±
9.9
10.1
10
f S s
( )
s

Exercises
101
www.Academicpress.com
3.17 Which of the following mathematical functions could be the PDF of some random
variable?
(a)
(c)
.
(b)
(d)
3.18 Find the value of the constant
that makes each of the following functions a properly
normalized PDF.
(a)
(b)
(c)
(where
is an odd integer).
(d)
.
Section 3.3: The Gaussian Random Variable
3.19 Prove the integral identity,
. Hint: It may be easier to show
that
.
3.20 Using the normalization integral for a Gaussian random variable, find an analytical
expression for the following integral:
,
where
,
, and
are constants.
f X x
( )
1
x ,
–
x
1,
≤
0,
x
1.
>
⎩
⎨
⎧
=
f X x
( )
x3
x4
–
(
)u x
( )
exp
=
f X x
( )
1
x2,
–
x
1,
≤
0,
x
1.
>
⎩
⎨
⎧
=
f X x
( )
4x
3,
x
1,
≤
0,
x
1.
>
⎩
⎨
⎧
=
c
f X x
( )
c 1
x
2---
⎝⎠
⎛⎞
2
–
⎝
⎠
⎛
⎞, x
2,
≤
0,
x
2.
>
⎩
⎪
⎨
⎪
⎧
=
f X x
( )
c
πx
2------
⎝
⎠
⎛
⎞,
cos
x
1,
≤
0,
x
1.
>
⎩
⎪
⎨
⎪
⎧
=
f X x
( )
cxn
x2
–
(
)u x
( )
exp
=
n
f X x
( )
c
1
x2
+
(
)2
---------------------
=
I
x2
2-----
–
⎝
⎠
⎛
⎞
exp
x
d
∞
–
∞
∫
2p
=
=
I 2
2p
=
I
ax2
bx
c
+
+
(
)
–
(
)
exp
x
d
∞
–
∞
∫
=
a
0
>
b
c

102
Chapter 3
www.Academicpress.com
3.21 A Gaussian random variable has a probability density function of the form
. 
(a)
Find the value of the constant
.
(b)
Find the values of the parameters
and
for this Gaussian random variable.
3.22 A Gaussian random variable has a PDF of the form
.
Write each of the following probabilities in terms of Q-functions (with positive
arguments) and also give numerical evaluations:
(a)
,
(b)
,
(c)
,
(d)
,
(e)
,
(f)
,
(g)
,
(h)
.
3.23 A Gaussian random variable has a PDF of the form
.
Write each of the following probabilities in terms of Q-functions (with positive
arguments) and also give numerical evaluations:
(a)
,
(b)
,
(c)
,
(d)
,
(e)
,
(f)
,
(g)
,
(h)
.
3.24 Suppose we measure the noise in a resistor (with no applied voltage) and find that the
noise voltage exceeds 10 μV 5% of the time. We have reason to believe the noise is well
modeled as a Gaussian random variable, and furthermore, we expect the noise to be
positive and negative equally often so we take the parameter,
, in the Gaussian PDF to
be
. Find the value of the parameter,
. What units should be associated with
in this case.
f X x
( )
c
2x2
3x
1
+
+
(
)
–
(
)
exp
=
c
m
s
f X x
( )
1
50p
--------------
x
10
–
(
)2
50
---------------------
–
⎝
⎠
⎛
⎞
exp
=
Pr X
17
>
(
)
Pr X
4
>
(
)
Pr X
15
<
(
)
Pr X
2
–
<
(
)
Pr X
10
–
7
>
(
)
Pr X
10
–
3
<
(
)
Pr X
7
–
5
>
(
)
Pr X
4
–
7
<
(
)
f X x
( )
2
p---
2 x
1
+
(
)2
–
(
)
exp
=
Pr X
0
>
(
)
Pr X
2
>
(
)
Pr X
3
–
<
(
)
Pr X
4
–
<
(
)
Pr X
1
+
3
>
(
)
Pr X
1
+
2
<
(
)
Pr X
2
+
1
>
(
)
Pr X
1
–
2
<
(
)
m
m
0
=
s 2
s 2

Exercises
103
www.Academicpress.com
3.25 Now suppose we modify Exercise 3.24 so that in addition to noise in the resistor there is
also a weak (constant) signal present. Thus, when we measure the voltage across the
resistor, we do not necessarily expect positive and negative measurements equally often,
and therefore, we now allow the parameter
to be something other than zero. Suppose
now we observe that the measure voltage exceeds 10 μV 40% of the time and is below
−10 μV only 2% of the time. If we continue to model the voltage across the resistor as a
Gaussian random variable, what are the appropriate values of the parameters
and
.
Give proper units for each.
3.26 The IQ of a randomly chosen individual is modeled using a Gaussian random variable.
Given that 50% of the population have an IQ above 100 (and 50% have an IQ below 100)
and that 50% of the population have an IQ in the range 90-100, what percentage of the
population have an IQ of at least 140 and thereby are considered “genius?”
Section 3.4: Other Important Random Variables
3.27 The phase of a sinusoid, Q, is uniformly distributed over
so that its PDF is of the
form
(a)
Find
.
(b)
Find
.
(c)
Find
.
3.28 Let
be an exponential random variable with PDF,
.
(a)
Find
.
(b)
Generalize your answer to part (a) to find
for some arbitrary constant
.
(c)
Note that if we define a new random variable according to
, then your answer
to part (b) is the CDF of
,
. Given your answer to part (b), find
.
m
m
s 2
0 2p )
,
[
f Q q
( )
1
2p
-------, 0
q
2p,
<
≤
0,
otherwise.
⎩
⎪
⎨
⎪
⎧
=
Pr q
3p
4
-------
>
⎝
⎠
⎛
⎞
Pr Q
p
<
Q
3p
4
-------
>
⎝
⎠
⎛
⎞
Pr
Q
(
)
cos
1
2---
<
⎝
⎠
⎛
⎞
X
f X x
( )
e x
– u x
( )
=
Pr 3X
5
<
(
)
Pr 3X
y
<
(
)
y
Y
3X
=
Y F Y y
( )
f Y y
( )

104
Chapter 3
www.Academicpress.com
3.29 Let
be a Laplace random variable with a PDF given by
.
(a)
Find the value of the constant
.
(b)
Find
.
(c)
Find
.
3.30 Let
be a random variable whose PDF is given by
.
(a)
Find the value of the constant
.
(b)
Find the form of the CDF of
,
.
(c)
Find
.
3.31 Let
be a Rayleigh random variable whose PDF is
.
(a)
Find the value of the constant
.
(b)
Find
for an arbitrary constant
.
(c)
Find
.
3.32 A random variable,
, has a PDF given by
.
(a)
List all constraints on the constants
,
, and
that must be satisfied for this to be
a valid PDF.
(b)
In terms of the constants
,
, and
, find
.
3.33 Prove the following properties of the Gamma function.
(a)
for
(b)
,
(c)
.
Section 3.5: Conditional Distribution and Density Functions
3.34 Prove the following properties of conditional CDFs.
(a)
,
,
(b)
W
f W w
(
)
ce 2 w
–
=
c
Pr
1
–
W
2
<
<
(
)
Pr W
0
>
1
–
W
2
<
<
(
)
Z
f Z z
( )
cz2e z
– u z
( )
=
c
Z F Z z
( )
Pr
Z
2
<
{
}
Z
4
>
(
)
∪
(
)
R
R r( )
cr
r2
–
(
)u r( )
exp
=
c
Pr R
r
>
(
)
r
Pr R
1
>
R
2
<
(
)
Y
f Y y
( )
c
y2
ay
b
+
+
---------------------------
=
a b
c
a b
c
Pr Y
0
>
(
)
G n
( )
n
1
–
(
)!
=
n
1 2 3 …
, , ,
=
G x
1
+
(
)
xG x
( )
=
G 1 2
⁄
(
)
p
=
F X A
∞
–
(
)
0
=
F X A ∞
(
)
1
=
0
F X A x
( )
1,
≤
≤
f

Exercises
105
www.Academicpress.com
(c)
For
,
,
(d)
For
,
.
3.35 Let
be a Gaussian random variable such that
. Find and plot the
following conditional PDFs.
(a)
,
(b)
,
(c)
.
3.36 A digital communication system sends two messages,
or
, with equal
probability. A receiver observes a voltage which can be modeled as a Gaussian random
variable,
, whose PDFs conditioned on the transmitted message are given by
and
.
(a)
Find and plot
as a function of
for
. Repeat for
.
(b)
Repeat part (a) assuming that the a priori probabilities are
and
.
3.37 In Exercise 3.36, suppose our receiver must observe the random variable
and then
make a decision as to what message was sent. Furthermore, suppose the receiver makes a
three-level decision as follows:
Decide 0 was sent if
,
Decide 1 was sent if
,
Erase the symbol (decide not to decide) if both
and
.
Assuming the two messages are equally probable,
,
and that
, find
(a)
the range of
over which each of the three decisions should be made,
(b)
the probability that the receiver erases a symbol,
(c)
the probability that the receiver makes an error (i.e., decides a “0” was sent when a
“1” was actually sent, or vice versa).
x1
x2
<
F X A x1
(
)
F X A x2
(
)
≤
x1
x2
<
Pr x1
X
x2
≤
<
A
(
)
F X A x2
(
)
F X A x1
(
)
–
=
X
X
N 0 s 2
,
(
)
∼
f X X
0
>
x
( )
f X
X
3
<
x
( )
f X
X
3
>
x
( )
M
0
=
M
1
=
X
f X M = 0 x
( )
1
2ps 2
------------------
x2
2s 2
---------
–
⎝
⎠
⎛
⎞
exp
=
f X M = 1 x
( )
1
2ps 2
------------------
x
1
–
(
)2
2s 2
------------------
–
⎝
⎠
⎛
⎞
exp
=
Pr M = 0 X = x
(
)
x
s 2
1
=
s 2
5
=
Pr M = 0
(
)
1 4
⁄
=
Pr M = 1
(
)
3 4
⁄
=
X
Pr M = 0 X =x
(
)
0.9
≥
Pr M = 1 X =x
(
)
0.9
≥
Pr M = 0 X = x
(
)
0.9
<
Pr M = 1 X = x
(
)
0.9
<
Pr M = 0
(
)
Pr M = 1
(
)
1 2
⁄
=
=
s 2
1
=
x

106
Chapter 3
www.Academicpress.com
3.38 In this problem, we extend the results of Exercise 3.36 to the case when there are more
than two possible messages sent. Suppose now that the communication system sends
one of four possible messages
,
,
, and
, each with equal
probability. The corresponding conditional PDFs of the voltage measured at the receiver
are of the form
,
.
(a)
Find and plot
as a function of
for
.
(b)
Determine the range of
for which
for all
. This will be the range of
for which the receiver will decide in favor of the
message
.
(c)
Determine the range of
for which
for all
. This will be the range of
for which the receiver will decide in favor of the
message
.
(d)
Based on your results of parts (b) and (c) and the symmetry of the problem, can you
infer the ranges of
for which the receiver will decide in favor of the other two
messages,
and
?
3.39 Suppose
is a uniform random variable,
(a)
Find the conditional PDF,
.
(b)
Find the conditional PDF,
.
(c)
Find the conditional CDF,
.
3.40 Repeat Exercise 3.39 if
is a Rayleigh random variable with PDF,
.
M
0
=
M
1
=
M
2
=
M
3
=
f X M =m x
( )
1
2ps 2
------------------
x
m
–
(
)2
2s 2
--------------------
–
⎝
⎠
⎛
⎞
exp
=
m
0 1 2 3
, , ,
=
Pr M =m X = x
(
)
x
s 2
1
=
x
Pr M =0 X = x
(
)
Pr M =m X = x
(
)
>
m
0
≠
x
M
0
=
x
Pr M = 1 X = x
(
)
Pr M = m X = x
(
)
>
m
1
≠
x
M
1
=
x
M
2
=
M
3
=
V
f V v
( )
1
2---, 0
v
2,
<
≤
0, otherwise.
⎩
⎪
⎨
⎪
⎧
=
f V
V
1
>
{
} v
( )
f V
1 2
⁄
V
3 2
⁄
<
<
{
} v
( )
F V
1 2
⁄
V
3 2
⁄
<
<
{
} v
( )
V
f V v
( )
v
v2 2
⁄
–
(
)
exp
u v
( )
=

Exercises
107
www.Academicpress.com
Section 3.6: Reliability and Failure Rates
3.41 Recalling Example 3.14, suppose that a serial connection system has 10 components and
the failure rate function is the same constant for all components and is 1 per 100 days.
(a)
Determine the probability that the lifetime of the system exceeds 10 days.
(b)
What is the probability that the lifetime of one component exceeds 10 days?
(c)
What is the reliability function of each component and the system as a whole?
Miscellaneous Exercises
3.42 Mr. Hood is a good archer. He can regularly hit a target having a 3-ft. diameter and often
hits the bull’s-eye, which is 0.5 ft. in diameter, from 50 ft. away. Suppose the miss is
measured as the radial distance from the center of the target and, furthermore, that the
radial miss distance is a Rayleigh random variable with the constant in the Rayleigh PDF
being
(sq-ft).
(a)
Determine the probability of Mr. Hood’s hitting the target.
(b)
Determine the probability of Mr. Hood’s hitting the bull’s-eye.
(c)
Determine the probability of Mr. Hood’s hitting the bull’s-eye given that he hits the
target.
3.43 In this problem, we revisit the light bulb problem of Exercise 2.74. Recall that there
were two types of light bulbs, long-life (L) and short-life (S) and we were given an
unmarked bulb and needed to identify which type of bulb it was by observing how long it
functioned before it burned out. Suppose we modify the problem so that the lifetime of
the bulbs are modeled with a continuous random variable. In particular, suppose the two
conditional PDFs are now given by
and
,
where
is the random variable that measures the lifetime of the bulb in hours. The a
priori probabilities of the bulb type were
and
.
(a)
If a bulb is tested and it is observed that the bulb burns out after 200 h, which type
of bulb was most likely tested?
(b)
What is the probability that your decision in part (a) was incorrect?
3.44 Consider the light bulb problem in Exercise 3.43. Suppose we do not necessarily want
to wait for the light bulb to burn out before we make a decision as to which type of
bulb is being tested. Therefore, a modified experiment is proposed. The light bulb to be
s 2
4
=
f X S x
( )
1
100
---------
x
100
---------
–
⎝
⎠
⎛
⎞u x
( )
exp
=
f X L x
( )
1
1000
------------
x
1000
------------
–
⎝
⎠
⎛
⎞u x
( )
exp
=
X
Pr S
( )
0.75
=
Pr L
( )
0.25
=

108
Chapter 3
www.Academicpress.com
tested will be turned on at 5 pm on Friday and will be allowed to burn all weekend. We
will come back and check on it Monday morning at 8 am and at that point it will either
still be lit or it will have burned out. Note that since there are a total of 63 h between
the time we start and end the experiment and we will not be watching the bulb at any
point in time in between, there are only two possible observations in this experiment,
or
.
(a)
Given it is observed that the bulb burnt out over the weekend, what is the
probability that the bulb was an
-type bulb?
(b)
Given it is observed that the bulb is still lit at the end of the weekend, what is the
probability that the bulb was an
type bulb?
3.45 Suppose we are given samples of the CDF of a random variable. That is, we are given
at several points,
. After examining a plot of the
samples of the CDF, we determine that it appears to follow the functional form of a
Rayleigh CDF,
.
The object of this problem is to determine what value of the parameter,
, in the
Rayleigh CDF best fits the given data.
(a)
Define the error between the
th sample point and the model to be
.
Find an equation that the parameter
must satisfy if it is to minimize the sum of
the squared errors,
.
Note, you probably will not be able to solve this equation, you just need to set up
the equation.
(b)
Next, we will show that the optimization works out to be analytically simpler if we
do it in the log domain and if we work with the complement of the CDF. That is,
suppose we redefine the error between the
th sample point and the model to be
.
the bulb burnt out
X
63
<
{
}
⇔
(
)
the bulb is still lit
X
63
>
{
}
⇔
(
)
S
S
F n
F X xn
(
)
=
xn
x1 x2 x3 … xk
,
,
,
,
{
}
∈
F X x s 2
;
(
)
1
x2
2s 2
---------
–
⎝
⎠
⎛
⎞
exp
–
⎝
⎠
⎛
⎞u x
( )
=
s 2
n
en
F n
F X xn s 2
;
(
)
–
F n
1
xn2
2s 2
---------
–
⎝
⎠
⎛
⎞
exp
–
⎝
⎠
⎛
⎞
–
=
=
s 2
SSE
en2
n
1
=
k
∑
=
n
en
1
F n
–
(
)
log
1
F X xn s 2
;
(
)
–
(
)
log
–
1
F n
–
(
)
log
xn2
2s 2
---------
–
⎝
⎠
⎛
⎞
exp
+
=
=

Exercises
109
www.Academicpress.com
Find an equation that the parameter
must satisfy if it is to minimize the sum of
the squared errors. In this case, you should be able to solve the equation and find an
expression for the optimum value of
.
MATLAB Exercises
3.46 Write a MATLAB program to calculate the probability
if
is a
Gaussian random variable for an arbitrary
and
. Note you will have to specify the
mean and variance of the Gaussian random variable.
3.47 Write a MATLAB program to calculate the probability
if
is a
Gaussian random variable for an arbitrary
and
. Note you will have to specify
the mean and variance of the Gaussian random variable.
3.48 Use the MATLAB rand function to create a random variable
uniformly distributed
over
. Then create a new random variable according to
. Repeat this
procedure many times to create a large number of realizations of
. Using these
samples, estimate and plot the probability density function of
. Find an analytical
model that seems to fit your estimated PDF.
3.49 Use the MATLAB randn function to create a Gaussian distributed random variable
.
Repeat this procedure and form a new random variable
. Finally, form a random
variable
according to
. Repeat this procedure many times to create a
large number of realizations of
. Using these samples, estimate and plot the
probability density function of
. Find an analytical model that seems to fit your
estimated PDF.
3.50 Use the MATLAB randn function to generate a large number of samples generated
according to a Gaussian distribution. Let
be the event A = {the sample is greater than
1.5}. Of those samples that are members of the event
, what proportion (relative
frequency) is greater than 2. By computing this proportion you will have estimated the
conditional probability
. Calculate the exact conditional probability
analytically and compare it with the numerical results obtained through your MATLAB
program.
3.51 Write a MATLAB program to evaluate the inverse of a Q-function. That is, if the
program is input a number,
, subject to
, it will produce an output
which is the solution to
.
s 2
s 2
Pr x1
X
x2
≤
≤
(
)
X
x1
x2
Pr X
a
–
b
<
(
)
X
a
b
0
>
X
0 1
,
(
)
Y
X
(
)
ln
–
=
Y
Y
X
Y
Z
Z
X 2
Y 2
+
=
Z
Z
A
A
Pr X
2
>
X
1.5
>
(
)
x
0
x
1
≤
≤
y
Q 1
–
x
( )
=
Q y
( )
x
=

110
Chapter 3
www.Academicpress.com
3.52 Use the MATLAB function marcumq to write a program to plot the CDF of a Rician
random variable. Your program should take as inputs the two parameters
and
of the
Rician random variable and output a plot of the CDF. Be sure to correctly label the axes
on your plot.
a
s

111
CHAPTER 4
Probability and Random Processes. DOI: 10.116/B978-0-12-386981-4.00004-8
© 2012 by Elsevier Inc. All rights reserved.
Operations on a Single Random Variable
In our study of random variables, we use the probability density function (PDF), the 
cumulative distribution function (CDF), or the probability mass function (PMF) to provide a 
complete statistical description of the random variable. From these functions, we could, in 
theory, determine just about anything we might want to know about the random variable. In 
many cases, it is of interest to distill this information down to a few parameters which describe 
some of the important features of the random variable. For example, we saw in Chapter 3 that 
the Gaussian random variable is described by two parameters, which were referred to as the 
mean and variance. In this chapter, we look at these parameters as well as several others that 
describe various characteristics of random variables. We see that these parameters can be 
viewed as the results of performing various operations on a random variable. 
4.1 Expected Value of a Random Variable
To begin, we introduce the idea of an average or expected value of a random variable. This is 
perhaps the single most important characteristic of a random variable and also is a concept that 
is very familiar to most students. After taking a test, one of the most common questions a 
student will ask after they see their grade is “What was the average?” On the other hand, how 
often does a student ask “What was the PDF of the exam scores?” While the answer to the 
second question would provide the student with more information about how the class 
performed, the student may not want all that information. Just knowing the average may be 
sufficient to tell the student how he/she performed relative to the rest of the class.
Definition 4.1: The expected value of a random variable 
 which has a PDF,
, is
.
(4.1)
The terms average, mean, expectation, and first moment are all alternative names for 
the concept of expected value and will be used interchangeably throughout the text. 
Furthermore, an overbar is often used to denote expected value so that the symbol 
 
is to be interpreted as meaning the same thing as 
. Another commonly used 
notation is to write 
.
X
fX x
 
E X
 
xfX x
  x
d

–


X
E X
 
	X
E X
 


112    Chapter 4
www.Academicpress.com
For discrete random variables, the PDF can be written in terms of the PMF, 
.
(4.2)
In that case, using the properties of delta functions, the definition of expected values for 
discrete random variables reduces to
.
(4.3)
Hence, the expected value of a discrete random variable is simply a weighted average of the 
values that the random variable can take on, weighted by the probability mass of each value. 
Naturally, the expected value of a random variable only exists if the integral in Equation (4.1) 
or the series in Equation (4.3) converges. One can dream up many random variables for which 
the integral or series does not converge and hence their expected values don’t exist (or less 
formally, their expected value is infinite). To gain some physical insight into this concept of 
expected value, we may think of 
 as a mass distribution of an object along the  axis, 
then Equation (4.1) calculates the centroid or center of gravity of the mass.
Example 4.1:
Consider a random variable that has an exponential PDF given by 
. 
Its expected value is calculated as follows:
.
The last equality in the series is obtained by using integration by parts once. It is seen 
from this example that the parameter  which appears in this exponential distribution is 
in fact the mean (or expected value) of the random variable.
Example 4.2: 
Next, consider a Poisson random variable whose PMF is given by 
, 
. Its expected value is found in a similar manner.
.
Once again, we see that the parameter  in the Poisson distribution is equal to the mean. 
fX x
 
PX xk


 x
xk
–


k
=
E X
 
xkPX xk


k
=
fX x
 
x
fX x
 
1
b---
x
b---
–



 u x
 
exp
=
E X
 
x
b---
x
b---
–




exp
x
d
0

b
y
y
–


exp
y
d
0

b
=
=
=
b
PX k
 
ke 
–
k!

=
k
0 1 2 
  
=
E X
 
kke 
–
k!
--------------
k
0
=


e 
–
k
k
1
–

!
------------------
k
1
=


e 
–
k
1
–
k
1
–

!
------------------
k
1
=


e 
–
m
m!
-------
m
0
=


e 
– e

=
=
=
=
=
=






Operations on a Single Random Variable    113
www.Academicpress.com
Example 4.3: 
In the last two examples, we saw random variables whose PDF or PMF was described by a 
single parameter which in both cases turned out to be the mean. We work one more 
example here to show that this does not always have to be the case. Consider a Rayleigh 
random variable with PDF
.
The mean is calculated as follows:
.
The last equality is obtained using the fact that 
. Alternatively (for those 
students not familiar with the properties of  functions), one could obtain this result 
using integration by parts once on the original integral (setting 
 and 
). In this case, neither the parameter  nor 
 is equal to the 
expected value of the random variable. However, since the mean is proportional to , 
we could, if we wanted to, rewrite the Rayleigh PDF in terms of its expected value, 
, 
as follows:
.
4.2 Expected Values of Functions of Random Variables
The concept of expectation can be applied to the functions of random variables as well as to 
the random variable itself. This will allow us to define many other parameters that describe 
various aspects of a random variable.
Definition 4.2:  Given a random variable 
 with PDF 
, the expected value of a
function, 
, of that random variable is given by 
.
(4.4)
For a discrete random variable, this definition reduces to
.
(4.5)
fX x
 
x
2
------
x2
22
---------
–




exp
u x
 
=
E X
 
x2
2
------
x2
22
---------
–




exp
x
d
0

2
y1 2
/
y
–

 y
d
exp
0

2 3 2




2---
=
=
=
=
 3 2



 2

=
u
x
=
dv
x 2



=
x2
22



–


exp

2

	X
fX x
 
x
2	X
2
----------
x2
4	X
2
----------
–




exp
u x
 
=
X
fX x
 
g X
 
E g X
 


g x
 fX x
  x
d

=
E g X
 


g xk

PX xk


k
=



114    Chapter 4
www.Academicpress.com
To start with, we demonstrate one extremely useful property of expectations in the following 
theorem.
Theorem 4.1:  For any constants  and , 
.
(4.6)
Furthermore, for any function 
 which can be written as a sum of several other
functions (i.e., 
),
(4.7)
In other words, expectation is a linear operation and the expectation operator can be
exchanged (in order) with any other linear operation.
Proof: The proof follows directly from the linearity of the integration operator.
                                               
.
(4.8)
The second part of the theorem is proved in an identical manner:
.  
(4.9)
Different functional forms of 
 lead to various different parameters which describe 
the random variable and are known by special names. A few of the more common ones are 
listed in Table 4.1. In the following sections, selected parameters will be studied in more 
detail.
a
b
E aX
b
+


aE X
 
b
+
=
g x
 
g x
 
g1 x
 
g2 x
 

gN x
 
+
+
+
=
E
gk X
 
k
1
=
N

E gk X
 


k
1
=
N

=
E aX
b
+


ax
b
+

fX x
  x
d

–


=
a
xfX x
 

–


dx
b
+
aE X
 
b
+
=
=
E
gk X
 
k
1
=
N

gk x
 
k
1
=
N

fX x
  x
d

–


gk x
 fX x
  x
d

–


k
1
=
N

=
=
E gk X
 


k
1
=
N

=
g X
 

Operations on a Single Random Variable    115
www.Academicpress.com
4.3  Moments
Definition 4.3:  The nth moment of a random variable 
 is defined as
.
(4.10)
For a discrete random variable, this definition reduces to
.
(4.11)
The zeroth moment is simply the area under the PDF and must be one for any random variable. 
The most commonly used moments are the first and second moments. The first moment is what 
we previously referred to as the mean, while the second moment is the mean-squared value. 
For some random variables, the second moment might be a more meaningful characterization 
than the first. For example, suppose 
 is a sample of a noise waveform. We might expect that 
the distribution of the noise is symmetric about zero (i.e., just as likely to be positive as negative) 
Table 4.1: Expected values of various functions of random variables
Name
Function of X
Expected Value, Notation
Mean, average, expected value, 
expectation, first moment
nth moment
nth central moment
Variance
Coefficient of skewness
Coefficient of kurtosis
Characteristic function
Moment-generating function
Probability-generating function
g x
 
x
=
	X
X
E X
 
=
=
g x
 
xn
=
Xn
E Xn


=
g x
 
x
	X
–

n
=
x
	X
–

n
E
X
	X
–

n


=
g x
 
x
	X
–

2
=
X
2
E
X
	X
–

2


=
g x
 
x
	X
–
X
---------------





 3
=
cs
E
X
	X
–
X
----------------





 3
=
g x
 
x
	X
–
X
---------------





 4
=
ck
E
X
	X
–
X
----------------





 4
=
g x
 
ejx
=
X 


E ejX


=
g x
 
esx
=
MX s 
E esX


=
g x
 
zx
=
HX z 
E zX


=
X
E Xn


xnfX x
  x
d

=
E Xn


xk
nPX xk


k
=
X

116    Chapter 4
www.Academicpress.com
and hence the first moment will be zero. So if we are told that 
 has a zero mean, all this 
says is merely that the noise does not have a bias. However, the second moment of the random 
noise sample is in some sense a measure of the strength of the noise. In fact, in Chapter 10, we 
will associate the second moment of a noise process with the power in the process. Thus, 
specifying the second moment can give us some useful physical insight into the noise process. 
Example 4.4: 
Consider a discrete random variable that has a binomial distribution. Its probability mass 
function is given by
, 
.
The first moment is calculated as follows:
          
.
In this last expression, the summand is a valid PMF (i.e., that of a binomial random 
variable with parameters  and 
) and therfore must sum to unity. Thus, 
. 
To calculate the second moment, we employ a helpful little trick. Note that we can write 
. Then
.
The second sum is simply the first moment, which has already been calculated. The first 
sum is evaluated in a manner similar to that used to calculate the mean.
          
Putting these two results together gives
.
X
PX k
 
n
k
 
  pk 1
p
–

n
k
–
=
k
0 1 2  n
  

=
E X
 
k n
k
 
  pk 1
p
–

n
k
–
k
0
=
n

kn!
k! n
k
–

!
-----------------------pk 1
p
–

n
k
–
k
1
=
n

n!
k
1
–

! n
k
–

!
-------------------------------------pk 1
p
–

n
k
–
k
1
=
n

=
=
=
np
n
1
–

!
k
1
–

! n
k
–

!
-------------------------------------pk
1
–
1
p
–

n
k
–
k
1
=
n

np
n
1
–
k
1
–



 pk
1
–
1
p
–

n
k
–
k
1
=
n

np
n
1
–
m



 pm 1
p
–

n
1
–
m
–
m
0
=
n
1
–

=
=
=
p
n
1
–
E X
 
np
=
k2
k k
1
–


k
+
=
E X2


k2 n
k
 
  pk 1
p
–

n
k
–
k
0
=
n

k k
1
–

 n
k
 
  pk 1
p
–

n
k
–
k
0
=
n

k n
k
 
  pk 1
p
–

n
k
–
k
0
=
n

+
=
=
k k
1
–

 n
k
 
  pk 1
p
–

n
k
–
k
0
=
n

n!
k
2
–

! n
k
–

!
-------------------------------------pk 1
p
–

n
k
–
k
2
=
n

=
n n
1
–

p2
n
2
–

!
k
2
–

! n
k
–

!
-------------------------------------pk
2
–
1
p
–

n
k
–
k
2
=
n

n n
1
–

p2
n
2
–
k
2
–



 pk
2
–
1
p
–

n
k
–
k
2
=
n

=
=
n n
1
–

p2
n
2
–
m



 pm 1
p
–

n
2
–
m
–
m
0
=
n
2
–

n n
1
–

p2
=
=
E X2


n n
1
–

p2
np
+
n2p2
=
=
np 1
p
–


+



Operations on a Single Random Variable    117
www.Academicpress.com
Example 4.5:  
Consider a random variable with a uniform PDF given as
The mean is given by
,
while the second moment is
.
In fact, it is not hard to see that in general, the nth moment of this uniform random 
variable is given by
.
4.4 Central Moments
Consider a random variable 
 which could be expressed as the sum, 
 of a 
deterministic (i.e., not random) part  and a random part 
. Furthermore, suppose that the 
random part tends to be very small compared to the fixed part. That is, the random variable 
 
tends to take small fluctuations about a constant value, . Such might be the case in a situation 
where there is a fixed signal corrupted by noise. In this case, we might write 
. 
As such, the nth moment of 
 would be dominated by the fixed part. That is, it is difficult to 
characterize the randomness in 
 by looking at the moments. To overcome this, we can use 
the concept of central moments.
Definition 4.4:  The nth central moment of a random variable 
 is defined as
.
(4.12)
In the above equation, 
 is the mean (first moment) of the random variable. For 
discrete random variables, this definition reduces to
.
(4.13)
fX x
 
1 a,

0
x
a,


0,
otherwise.



=
E X
 
x
a--- x
d
0
a
x2
2a
------
0
a
a
2---
=
=
=
E X2


x2
a----- x
d
0
a
x3
3a
------
0
a
a2
3-----
=
=
=
E Xn


xn
a----- x
d
0
a
xn
1
+
n
1
+

a
--------------------
0
a
an
n
1
+
------------
=
=
=
Y
Y
a
X
+
=
a
X
Y
a
Yn
a
X
+

n
an

=
Y
Y
X
E
X
	X
–

n


x
	X
–

nfX x
  x
d

=
	X
E
X
	X
–

n


xk
	X
–

kPX xk


k
=



118    Chapter 4
www.Academicpress.com
With central moments, the mean is subtracted from the variable before the moment is taken in 
order to remove the bias in the higher moments due to the mean. Note that, like regular 
moments, the zeroth central moment is 
. Furthermore, the first 
central moment is 
. Hence, the lowest central 
moment of any real interest is the second central moment. This central moment is given a 
special name, the variance, and we quite often use the notation 
 to represent the variance of 
the random variable 
. Note that
.
(4.14)
In many cases, the best way to calculate the variance of a random variable is to calculate the 
first two moments and then form the second moment minus the first moment squared.
Example 4.6: 
For the binomial random variable in Example 4.4, recall that the mean was 
 
and the second moment was 
. Therefore, the variance is given by 
. Similarly, for the uniform random variable in Example 4.5, 
, 
, and therfore 
. Note that if the moments have not 
previously been calculated, it may be just as easy to compute the variance directly. In the 
case of the uniform random variable, once the mean has been calculated, the variance 
can be found as
.
Another common quantity related to the second central moment of a random variable is the 
standard deviation, which is defined as the square root of the variance, 
. 
(4.15)
Both the variance and the standard deviation serve as a measure of the width of the PDF 
of a random variable. Some of the higher-order central moments also have special names, 
although they are much less frequently used. The third central moment is known as the 
skewness and is a measure of the symmetry of the PDF about the mean. The fourth central 
moment is called the kurtosis and is a measure of the peakedness of a random variable near 
the mean. Note that not all random variables have finite moments and/or central moments. 
We give an example of this later for the Cauchy random variable. Some quantities related to 
these higher-order central moments are given in the following definition.
E
X
	X
–

0


E 1
 
1
=
=
E X
	X
–


E X
 
	X
–
	X
	X
–
0
=
=
=
X
2
X
X
2
E
X
	X
–

2


E X2
2	XX
–
	X
2
+


E X2


2	XE X
 
–
	X
2
+
=
=
=
E X2


	X
2
–
=
E X
 
np
=
E X2


n2p2
np 1
p
–


+
=
X
2
np 1
p
–


=
E X
 
a 2

=
E X2


a2 3

=
X
2
a2 3

a2 4

–
a2 12

=
=
X
2
x
a 2

–

21
a--- x
d
0
a
x2
a----- x
d
a
2---
–
a
2---

x3
3a
------
a 2

–
a 2

a2
12
------
=
=
=
=
X
E
X
	X
–

2


=



Operations on a Single Random Variable    119
www.Academicpress.com
Definition 4.5:  The coefficient of skewness is
.
(4.16)
This is a dimensionless quantity that is positive if the random variable has a PDF
skewed to the right and negative if skewed to the left. The coefficient of kurtosis is also
dimensionless and is given as
.
(4.17)
The more the PDF is concentrated near its mean, the larger the coefficient of kurtosis.
In other words, a random variable with a large coefficient of kurtosis will have a large
peak near the mean. 
Example 4.7: 
An exponential random variable has a PDF given by
.
The mean value of this random variable is 
. The nth central moment is given by
.
In the preceding expression, it is understood that 
. As expected, it is easily verified 
from the above expression that the 0th central moment is 1 and the first central moment 
is 0. Beyond these, the second central moment is 
, the third central moment is 
, and the fourth central moment is 
. The 
coefficients of skewness and kurtosis are given by 
,
.
The fact that the coefficient of skewness is negative shows that the exponential PDF is 
skewed to the left of its mean. 
cs
E
X
	X
–

3


X
3
--------------------------------
=
ck
E
X
	X
–

4


X
4
--------------------------------
=
fX x
 
b
bx
–


exp
u x
 
=
	X
1 b

=
E
X
	X
–

n


x
1 b

–

nb
bx
–


exp
x
d
0

=
b
e---
yn
by
–


exp
y
d
1 b

–

=
1
bn
-----
n!
m!
------
1
–

m
m
0
=
n

=
0!
1
=
X
2
1 b2

=
E
X
1 b

–

3


2
–
b3

=
E
X
1 b

–

4


9 b4

=
cs
E
X
	X
–

3


X
3
--------------------------------
2
–
b3

1 b3

---------------
2
–
=
=
=
ck
E
X
	X
–

4


X
4
--------------------------------
9 b4

1 b4

------------
9
=
=
=



120    Chapter 4
www.Academicpress.com
Example 4.8: 
Next consider a Laplace (two-sided exponential) random variable with a PDF given by
.
Since this PDF is symmetric about zero, its mean is zero and therefore in this case the 
central moments are simply the moments,
.
Since the two-sided exponential is an even function and 
 is an odd function for any odd 
n, the integrand is then an odd function for any odd n. The integral of any odd function 
over an interval symmetric about zero is equal to zero, and hence all odd moments of the 
Laplace random variable are zero. The even moments can be calculated individually:
,
.
The coefficient of skewness is zero (since the third central moment is zero) and the 
coefficient of kurtosis is
.
Note that the Laplace distribution has a sharp peak near its mean as evidenced by a large 
coefficient of kurtois. The fact that the coefficient of skewness is zero is consistent with 
the fact that the distribution is symmetric about its mean. 
Example 4.9: 
It is often the case that the PDF of random variables of practical interest may 
be too complicated to allow us to compute various moments and other 
important parameters of the distribution in an analytic fashion. In those 
cases, we can use a computer to calculate the needed quantities numerically. 
Take for example a Rician random variable whose PDF is given by 
.
Suppose we wanted to know the mean of this random variable. This requires us to evaluate
.
fX x
 
b
2---
b x
–


exp
=
E
X
	X
–

n


E Xn


bxn
2
--------
b x
–


exp
x
d

–

=
=
xn
X
2
E X2


bx2
2
--------
b x
–


exp
x
d

–

bx2
bx
–


exp
x
d
0

2
b2
-----
=
=
=
=
E
X
	X
–

4


E X4


bx4
2
--------
b x
–


exp
x
d

–

bx4
bx
–


exp
x
d
0

24
b4
------
=
=
=
=
ck
E
X
	X
–

4


X
4
--------------------------------
24 b4

4 b4

---------------
6
=
=
=
fX x
 
x
2
------
x2
a2
+
22
-----------------
–




exp
Io
ax
2
------



 u x
 
=
	X
x2
2
------
x2
a2
+
22
-----------------
–




exp
Io
ax
2
------



 x
d
0


=




Operations on a Single Random Variable    121
www.Academicpress.com
Note that the parameter 
 which shows up in the Rician PDF is not the variance of the 
Rician random variable. While analytical evaluation of this integral looks formidable, given 
numerical values for  and 
, this integral can be evaluated (at least approximately) using 
standard numerical integration techniques. In order to use the numerical integration 
routines built into MATLAB, we must first write a function which evaluates the integrand. 
For evaluating the mean of the Rician PDF, this can be accomplished as follows (see 
Appendix D, Equation (D.52) for an analytic expression for the mean):
function pdf=Rician_pdf(x,a,sigma)
% Evaluate the integrand needed for calculating the mean of a
% Rician random variable with parameters a and sigma.
pdf=(x./sigma).^2.*exp(-(x.^2+a^2)/(2*sigma^2));
pdf=pdf.*besseli(0,a*x/sigma^2);
Once this function is defined, the MATLAB function quad8 can be called upon to perform 
the numerical integration. For example, if 
 and 
, the mean could be calculated 
as follows:
a=2; sigma=3;
% set parameters
limit1=0; limit2=20;
% set limits of integration.
mean=quad8(‘Rician_pdf’,limit1,limit2,[],[],a,sigma);
Executing this code produced an answer of 
. Note that in order to calculate the 
mean, the upper limit of the integral should be infinite. However using limit2=Inf in the 
above code would have led MATLAB to produce a result of NaN (“not a number”). 
Instead, we must use an upper limit sufficiently large that for the purposes of evaluating 
the integral it is essentially infinite. This can be done by observing the integrand and 
seeing at what point the integrand dies off. The reader is encouraged to execute the code 
in this example using different values of the upper integration limit to see how large the 
upper limit must be to produce accurate results.
4.5  Conditional Expected Values
Another important concept involving expectation is that of conditional expected value. As 
specified in Definition 4.6, the conditional expected value of a random variable is a weighted 
average of the values the random variable can take on, weighted by the conditional PDF of the 
random variable.
Definition 4.6: The expected value of a random variable 
, conditioned on some
event 
 is
.
(4.18)
2
a
2
a
2
=

3
=
	X
4.1665
=
X
A
E X A


xfX A x
 

dx
=


122    Chapter 4
www.Academicpress.com
For a discrete random variable, this definition reduces to
.
(4.19)
Similarly, the conditional expectation of a function, 
, of a random variable,
conditioned on the event 
 is
 or 
,
(4.20)
depending on whether the random variable is continuous or discrete.
Conditional expected values are computed in the same manner as regular expected values with 
the PDF or PMF replaced by a conditional PDF or conditional PMF. 
Example 4.10: 
Consider a Gaussian random variable of the form
.
Suppose the event A is the event that the random variable  is positive, 
. Then
.
The conditional expected value of  given that 
 is then
.
4.6  Transformations of Random Variables
Consider a random variable 
 with a PDF and CDF given by 
 and 
, respectively.  
Define a new random variable 
 such that 
 for some function 
. What is the 
PDF, 
, (or CDF) of the new random variable? This problem is often encountered in the 
study of systems where the PDF for the input random variable 
 is known and the PDF for the 
output random variable  needs to be determined. In such a case, we say that the input random 
variable has undergone a transformation.
4.6.1 Monotonically Increasing Functions
To begin our exploration of transformations of random variables, let us assume that the 
function is continuous, one-to-one, and monotonically increasing. A typical function of this 
E X A


xkPX A xk


k
=
g . 
A
E g X
  A


g x
 fX A x
  x
d

=
E g X
  A


g xk

PX A xk


k
=
fX x
 
1
2
----------
x2
2-----
–




exp
=
X
A
X
0
 
!
"
=
fX A x
 
fX x
 
Pr X
0
 


-----------------------u x
 
2
---
x2
2-----
–




exp
u x
 
=
=
X
X
0
 
E X X
0
 


xfX X
0
 
x
  x
d

2
---
x
x2
2-----
–




exp
x
d
0


2
---
x2
2-----
–




exp
–
0

2
---
=
=
=
=
X
fX x
 
FX x
 
Y
Y
g X
 
=
g . 
fY y
 
X
Y



Operations on a Single Random Variable    123
www.Academicpress.com
form is illustrated in Figure 4.1a. This assumption will be lifted later when more general 
functions are considered, but for now this simpler case applies. Under these assumptions, the 
inverse function, 
, exists and is well behaved. In order to obtain the PDF of , we 
first calculate the CDF. Recall that 
. Since there is a one-to-one 
relationship between values of  and their corresponding values of 
, this CDF can be written 
in terms of 
 according to
.
(4.21)
Note, this can also be written as
.
(4.22)
Differentiating Equation (4.21) with respect to  produces 
,
(4.23)
while differentiating Equation (4.22) with respect to  gives
.
(4.24)
Either Equation (4.23) or (4.24) can be used (whichever is more convenient) to compute the 
PDF of the new random variable.
Figure 4.1
(a) A monotonic increasing function and (b) a monotonic decreasing function.
x
y= g(x)
x
y=g(x)
(a)
(b)
y
y
x
x
X
g 1
–
Y
 
=
Y
FY y
 
Pr Y
y



=
Y
X
X
FY y
 
Pr g X
 
y



Pr X
g 1
–
y
 



FX g 1
–
y
 


=
=
=
FX x
 
FY g x
 


=
y
fY y
 
fX g 1
–
y
 

dg 1
–
y
 
dy
-------------------
fX x
 dx
dy
------
x
g 1
–
y
 
=
=
=
x
fX x
 
fY g x
 

dy
dx
------
=
fY y
 
#
fX x
 
dy
dx
------
------------
x
g 1
–
y
 
=
=

124    Chapter 4
www.Academicpress.com
Example 4.11: 
Suppose  is a Gaussian random variable with mean, , and variance, 
. A new random 
variable is formed according to 
, where 
 (so that the transformation is 
monotonically increasing). Since 
, then applying Equation (4.24) produces
.
Furthermore, plugging in the Gaussian PDF of  results in
.
Note that the PDF of  still has a Gaussian form. In this example, the transformation did 
not change the form of the PDF; it merely changed the mean and variance.
Example 4.12: 
Let  be an exponential random variable with 
 and let the transformation 
be 
. Then 
 and
.
Example 4.13: 
Suppose a phase angle 
 is uniformly distributed over 
 and the transformation 
is 
. Note that in general 
 is not a monotonic transformation, but 
under the restriction 
, this transformation is indeed monotonically 
increasing. Also note that with this transformation the resulting random variable, , 
must take on values in the range 
. Therefore, whatever PDF is obtained for , it 
must be understood that the PDF is zero outside 
. Applying Equation (4.24) gives
, 
.
This is known as an arcsine distribution.
4.6.2  Monotonically Decreasing Functions
If the transformation is monotonically decreasing rather than increasing, a simple modification 
to the previous derivations can lead to a similar result. First, note that for monotonic 
decreasing functions, the event 
 is equivalent to the event 
, giving us
X
	
2
Y
aX
b
+
=
a
0
 
dy dx

a
=
fY y
 
1
a---f
X
y
b
–
a
-----------




=
X
fY y
 
1
a 22
--------------------
y
b
–
a
-----------
	
–



 2
22
-----------------------------
–










exp
1
2 a

2
-------------------------
y
b
a	
+


–

2
2 a

2
-------------------------------------
–




exp
=
=
Y
X
fX x
 
2e 2x
–
u x
 
=
Y
X3
=
dy dx

3x2
=
fY y
 
fX x
 
3x2
------------
x
y
3
=
2
3---y 2 3

–
2y1 3

–


exp
u y
 
=
=
$

–
2

 2




Y
$


sin
=
y
%
 
sin
=
 2

–
%
 2

&
&
Y
1 1

–


Y
1 1

–


fY y
 
f$ %
 
%
 
cos
----------------
%
sin 1
–
y
 
=
1

sin 1
–
y
 


cos
-------------------------------------
1
 1
y2
–
----------------------
=
=
=
1
y
1
&
&
–
Y
y

!
"
X
g 1
–
y
 
'







Operations on a Single Random Variable    125
www.Academicpress.com
.
(4.25)
Differentiating with respect to  gives
.
(4.26)
Similarly, writing 
 and differentiating with respect to  results in
.
(4.27)
Equations (4.23), (4.24), (4.26), and (4.27) can be consolidated into the following compact 
form:
,
(4.28)
where now the sign differences have been accounted for by the absolute value operation. This 
equation is valid for any monotonic function, either monotonic increasing or monotonic 
decreasing.
4.6.3  Nonmonotonic Functions
Finally, we consider a general function which is not necessarily monotonic. Figure 4.2 
illustrates one such example. In this case, we cannot associate the event 
 with events 
FY y
 
Pr Y
y



Pr X
g 1
–
y
 
'


1
FX g 1
–
y
 


–
=
=
=
y
fY y
 
f
– X x
 dx
dy
------
x
g 1
–
y
 
=
=
FY g x
 


1
FX x
 
–
=
x
fY y
 
fX x
 
dy
dx
------
------------
–
x
g 1
–
y
 
=
=
fY y
 
fX x
  dx
dy
------
x
g 1
–
y
 
=
fX x
 
dy
dx
------
------------
x
g 1
–
y
 
=
=
=
Figure 4.2
A nonmonotonic function; the inverse function may have multiple roots.
y
y + dy
x1 x1+dx1
x2+ dx2 x2
x3 x3+ dx3
x4+ dx4 x4
Y
y

!
"

126    Chapter 4
www.Academicpress.com
of the form 
 or 
 because the transformation is not monotonic. 
To avoid this problem, we calculate the PDF of 
 directly, rather than first finding the CDF. 
Consider an event of the form 
 for an infinitesimal 
. The probability of 
this event is 
. In order to relate the PDF of 
 to the PDF of 
, 
we relate the event 
 to events involving the random variable 
. Because the 
transformation is not monotonic, there may be several values of  which map to the same 
value of . These are the roots of the equation 
. Let us refer to these roots as 
. Furthermore, let 
  be the subset of these roots at which the function 
 
has a positive slope and similarly let 
 be the remaining roots for which the slope of the 
function is negative. Then
.
(4.29)
Since each of the events on the right-hand side is mutually exclusive, the probability of the 
union is simply the sum of the probabilities so that
(4.30)
Again, invoking absolute value signs to circumvent the need to have two separate sums and 
dividing by 
, the following result is obtained:
.
(4.31)
When it is more convenient, the equivalent expression
,
(4.32)
can also be used. The following theorem summarizes the general formula for transformations 
of random variables.
X
g 1
–
y
 

!
"
X
g 1
–
y
 
'
!
"
Y
y
Y
y
dy
+
&

!
"
dy
Pr y
Y
y
dy
+
&



fY y
 dy
=
Y
X
y
Y
y
dy
+
&

!
"
X
x
y
x
g 1
–
y
 
=
x1 x2  xN



X +
g x
 
X (
y
Y
y
dy
+
&

!
"
xi
X
xi
dxi
+
&

!
"
i:xi
X+
)*
xi
dxi
+
X
xi

&
!
"
i:xi
X-
)*
*
=
fY y
 dy
Pr xi
X
xi
dxi
+
&



xi
X+
)
Pr xi
dxi
+
X
xi

&


xi
X(
)
+
=
fX xi

dxi
xi
X+
)
fX xi


d
– xi


xi
X(
)
+
=
dy
fY y
 
fX x
  dx
dy
------
xi
g 1
–
y
 
=
xi
=
fY y
 
fX x
 
dy
dx
------
------------
xi
g 1
–
y
 
=
xi
=

Operations on a Single Random Variable    127
www.Academicpress.com
Theorem 4.2:  Given a random variable 
 with known PDF, 
, and a
transformation 
. The PDF of 
 is
,
(4.33)
where the 
 are the roots of the equation 
. The proof precedes the theorem.
Example 4.14: 
Suppose  is a Gaussian random variable with zero mean and variance 
 together with 
a quadratic transformation, 
. For any positive value of , 
 has two real 
roots, namely 
 (for negative values of y there are no real roots). Application of 
Equation (4.33) gives
.
For a zero-mean Gaussian PDF, 
 is an even function so that 
. 
Therefore,
.
Hence,  is a Gamma random variable.
Example 4.15: 
Suppose the same Gaussian random variable from the previous example is passed 
through a half-wave rectifier which is described by the input-output relationship
For 
, 
 so that 
. However, when 
, 
, which will 
create a problem if we try to insert this directly into Equation (4.33). To treat this case, 
we note that the event 
 is equivalent to the event 
; therefore, 
. 
Since the input Gaussian PDF is symmetric about zero, 
. Basically, the 
random variable  is a mixed random variable. It has a continuous part over the region 
 and a discrete part at 
. Using a delta function, we can write the PDF of  as
.
X
fX x
 
Y
g X
 
=
Y
fY y
 
fX x
  dx
dy
------
xi
g 1
–
y
 
=
xi
fX x
 
dy
dx
------
------------
xi
g 1
–
y
 
=
xi
=
=
xi
y
g x
 
=
X
2
Y
X2
=
y
y
x2
=
x
y
+
=
fY y
 
fX + y


2 + y
--------------------
fX
y
–


2
y
–
--------------------
+
u y
 
fX + y


fX
y
–


+
2 y
-----------------------------------------------u y
 
=
=
fX x
 
fX + y


fX
y
–


=
fY y
 
1
y
------fX
y

u y
 
1
2y2
----------------
y
22
---------
–



 u y
 
exp
=
=
Y
y
g x
 
x
   x
0
'
0
   x
0.




=
=
x
0
 
dy dx

1
=
fY y
 
fX y
 
=
x
0
&
dy dx

0
=
X
0
&
Y
0
=
Pr Y = 0


Pr X
0
&


=
Pr X
0
&


1 2

=
Y
y
0
 
y
0
=
Y
fY y
 
1
22
-----------------
y2
22
---------
–




exp
u y
 
1
2---
 y
 
+
=





128    Chapter 4
www.Academicpress.com
Example 4.15 illustrates how to deal with transformations that are flat over some interval of 
nonzero length. In general, suppose the transformation 
 is such that 
 for 
any  in the interval 
. Then the PDF of 
 will include a discrete component (a  
delta function) of height 
 at the point 
. One often 
encounters transformations that have several different flat regions. One such “staircase” 
function is shown in Figure 4.3. Hence, a random variable 
 that may be continuous will be 
converted into a discrete random variable. The classical example of this is analog-to-digital 
conversion of signals. Suppose the transformation is of a general staircase form,
(4.34)
Then 
 will be a discrete random variable whose PMF is
(4.35)
x1
x2
x3
x4
x5
y1
y2
y3
y4
y5
y = g(x)
x
Figure 4.3
A staircase (quantizer) transformation: a continuous random variable will be converted into a 
discrete random variable.
y
g x
 
=
g x
 
yo
=
x
x1
x
x2


Y
Pr Y = yo


Pr x1
x
x2




=
y
yo
=
X
y
y0,
x
x1,
&
yi,            xi
x
xi
1
+ ,
&

   i= 1, 2, ..., N
1,
–
yN,
x
xN.
'

,
,

,
,

=
Y
P Y = yi


Pr X
x1
&

,         
i= 0,              
Pr xi
x
xi
1
+
&


,    i = 1, 2, ..., N
1,
–
Pr X
xN
'

,         
i =N.             

,
,

,
,

=

Operations on a Single Random Variable    129
www.Academicpress.com
Example 4.16: 
Suppose  is an exponential random variable with a PDF 
 and we 
form a new random variable  by rounding  down to the nearest integer. That is, 
, 
.
Then, the PMF of  is
, 
.
Hence, quantization of an exponential random variable produces a geometric random 
variable.
Example 4.17: 
Let  be a random variable uniformly distributed over 
. 
Accordingly, its PDF is of the form
.
A new random variable is to be formed according to the square law 
transformation 
. Applying the theory developed in this section you should be able 
to demonstrate that the new random variable has a PDF given by
.
Using MATLAB, we create a large number of samples of the uniform random variable, 
pass these samples through the square law transformation, and then construct a 
histogram of the resulting probability densities. The MATLAB code to do so follows and 
the results of running this code are shown in Figure 4.4. 
clear
N=10000;
a=5; ymax=a^2/4;
% set parameters.
x=a*(rand(1,N)-0.5);
% generate uniform RVs
y=x.^2;
% square law transformation
bw=0.25;
% bin width
bins=[bw/2:bw:ymax];
% histogram bins.
[yvals,xvals]=hist(y,bins);
% compute histogram values
pdf_est=yvals/(N*bw);
% convert to prob. densities
bar(xvals,pdf_est)
% plot histogram
% Compare true PDF with histogram.
y=[0.01:0.01:ymax];
pdf=1./(a*sqrt(y));
hold on
plot(y,pdf)
xlabel('y'); ylabel('f_Y(y)')
hold off
X
fX x
 
x
–


exp
u x
 
=
Y
X
Y
g X
 
floor X
 
k
=
=
=
k
X
k
1
+
&

Y
P Y = k


Pr k
X
k
1
+
&



e x
–
x
d
k
k
1
+

e k
–
e
k
1
+


–
–
e k
–
1
1 e

–


=
=
=
=
k
0 1 2 
  
=
X
a 2

–
a 2




fX x
 
1
a--- u x
a
2---
+




u x
a
2---
–




–




=
Y
X2
=
fY y
 
1
a y
---------- u y
 
u y
a2 4

–


–


=



(Continued)

130    Chapter 4
www.Academicpress.com
4.7. Characteristic Functions
In this section, we introduce the concept of a characteristic function. The characteristic 
function of a random variable is closely related to the Fourier transform of the PDF of that 
random variable. Thus, the characteristic function provides a sort of “frequency domain” 
representation of a random variable, although in this context there is no connection between 
our frequency variable 
 and any physical frequency. In studies of deterministic signals, it 
was found that the use of Fourier transforms greatly simplified many problems, especially 
those involving convolutions. We will see in future chapters the need for performing 
convolution operations on PDFs of random variables, and hence frequency domain tools will 
become quite useful. Furthermore, we will find that characteristic functions have many other 
uses. For example, the characteristic function is quite useful for finding moments of a random 
variable. In addition to the characteristic function, two other related functions, namely, the 
moment-generating function (analogous to the Laplace transform) and the probability-
generating function (analogous to the z-transform), will also be studied in the following 
sections. 
Definition 4.7:  The characteristic function of a random variable, 
, is given by
.
(4.36)

0
1
2
3
4
5
6
7
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
y
fY(y)
Figure 4.4
 Comparison of estimated and true PDF for Example 4.17. (For color version of this 
figure, the reader is refered to the web version of this chapter).
X
X 


E ejX


ejxfX x
  x
d

–


=
=


Operations on a Single Random Variable    131
www.Academicpress.com
Note the similarity between this integral and the Fourier transform. In most of the electrical 
engineering literature, the Fourier transform of the function 
 would be 
. Given 
this relationship between the PDF and the characteristic function, it should be clear that one 
can get the PDF of a random variable from its characteristic function through an inverse 
Fourier transform operation:
.
(4.37)
The characteristic functions associated with various random variables can be easily found 
using tables of commonly used Fourier transforms, but one must be careful since the Fourier 
integral used in Equation (4.36) may be different from the definition used to generate common 
tables of Fourier transforms. In addition, various properties of Fourier transforms can also be 
used to help calculate characteristic functions as shown in the following example.
Example 4.18: 
An exponential random variable has a PDF given by 
. Its characteristic 
function is found to be
.
This result assumes that 
 is a real quantity. Now suppose another random variable  
has a PDF given by 
. Note that 
, thus using the scaling 
property of Fourier transforms, the characteristic function associated with the random 
variable  is given by
,
assuming  is a positive constant (which it must be for  to have a valid PDF). Finally, 
suppose that  has a PDF given by 
. Since 
, 
the shifting property of Fourier transforms can be used to help find the characteristic 
function associated with the random variable :
.
The next example demonstrates that the characteristic function can also be computed for 
discrete random variables. In Section 4.8, the probability-generating function will be 
introduced which is preferred by some when dealing with discrete random variables.
fX x
 


–


fX x
 
1
2
------
e j x
–
X 

 
d

–


=
fX x
 
x
–


exp
u x
 
=
X 


ejxfX x
  x
d

–


ejxe x
–
x
d
0


e
1
j
–

x
–
1
j
–
-----------------------
–
0

1
1
j
–
---------------
=
=
=
=

Y
fY y
 
a
ay
–


exp
u y
 
=
fY y
 
afX ay


=
Y
Y 


a 1
a-----X

a----
 
 
1
1
j a

–
----------------------
a
a
j
–
---------------
=
=
=
a
Y
Z
fZ z 
a
a z
b
–


–


exp
u z
b
–


=
fZ z 
fY z
b
–


=
Z
Z 


Y 

e jb
–
ae j
– b
a
j
–
----------------
=
=



132    Chapter 4
www.Academicpress.com
Example 4.19: 
A binomial random variable has a PDF which can be expressed as
.
Its characteristic function is computed as follows:
.
Since the Gaussian random variable plays such an important role in so many studies, we derive 
its characteristic function in Example 4.20. We recommend that the student commit the result 
of this example to memory. The techniques used to arrive at this result are also important and 
should be carefully understood.
Example 4.20: 
For a standard normal random variable, the characteristic function can be found as follows:
.
To evaluate this integral, we complete the square in the exponent.
.
The integrand in the above expression looks like the properly normalized PDF of a Gaussian 
random variable, and since the integral is over all values of , the integral must be unity. 
However, close examination of the integrand reveals that the “mean” of this Gaussian 
integrand is complex. It is left to the student to rigorously verify that this integral still 
evaluates to unity even though the integrand is not truly a Gaussian PDF (since it is a 
complex function and hence not a PDF at all). The resulting characteristic function is then
.
For a Gaussian random variable whose mean is not zero or whose standard deviation is 
not unity (or both), the shifting and scaling properties of Fourier transforms can be used 
to show that
.
fX x
 
n
k
 
  pk 1
p
–

n
k
– 
 x
k
–


k
0
=
n

=
X 


ejx
n
k
 
  pk 1
p
–

n
k
– 
 x
k
–


k
0
=
n









x
d

–


n
k
 
  pk 1
p
–

n
k
–

 x
k
–

ejx x
d

–


k
0
=
n

=
=
n
k
 
  pk 1
p
–

n
k
– ejk
k
0
=
n

n
k
 
  pej

k 1
p
–

n
k
–
k
0
=
n

1
p
–
pej
+

n
=
=
=
X 


1
2
----------e
x2
2-----
–
e
jx x
d

–


1
2
----------
x2
2jx
–


2
----------------------------
–




exp
x
d

–


=
=
X 


2
2
------
–




exp
1
2
----------
x2
2jx
–
2
–


2
-----------------------------------------
–




exp
x
d

–


2
2
------
–




exp
1
2
----------
x
j
–

2
2
----------------------
–




exp
x
d

–


=
=
x
X 


2
2
------
–




exp
=
fX x
 
1
22
-----------------e
x
	
–

2
22
-------------------
–
=
X 


-
j	 22
2
-------------
–




exp
=





Operations on a Single Random Variable    133
www.Academicpress.com
Theorem 4.3: For any random variable whose characteristic function is differentiable
at 
,
.
(4.38)
Proof: The proof follows directly from the fact that the expectation and differentiation
operations are both linear and consequently the order of these operations can be
exchanged.
.
Multiplying both sides by 
 and evaluating at 
 produces the desired result.  
Theorem 4.3 demonstrates a very powerful use of the characteristic function. Once the 
characteristic function of a random variable has been found, it is generally a very 
straightforward thing to produce the mean of the random variable. Furthermore, by taking 
the kth derivative of the characteristic function and evaluating at 
, an expression 
proportional to the kth moment of the random variable is produced. In particular, 
.
(4.39)
Hence, the characteristic function represents a convenient tool to easily determine the 
moments of a random variable.
Example 4.21: 
Consider the exponential random variable of Example 4.18 where 
. 
The characteristic function was found to be
.
The derivative of the characteristic function is
,
and thus the first moment of  is 
.

0
=
E X
 
j d
d
-------X 


–

0
=
=
d
d
-------X 


d
d
------- E ejX


(
)
E
d
d
------- ejX
(
)
E jXejX


jE XejX


=
=
=
=
j
–

0
=

0
=
E Xk


j
–

k dk
d k
---------
X 



0
=
=
fY y
 
a
ay
–


exp
u y
 
=
Y 


a
a
j
–
---------------
=
d
d
-------Y 


ja
a
j
–

2
----------------------
=
Y
E Y
 
j d
d
-------Y 


–

0
=
a
a
j
–

2
----------------------

0
=
1
a---
=
=
=

(Continued)

134    Chapter 4
www.Academicpress.com
For this example, it is not difficult to show that the kth derivative of the characteristic 
function is
,
and from this, the kth moment of the random variable is found to be
.
For random variables that have a more complicated characteristic function, evaluating the kth 
derivative in general may not be an easy task. However, Equation (4.39) only calls for the kth 
derivative evaluated at a single point (
), which can be extracted from the Taylor series 
expansion of the characteristic function. To see this, note that from Taylor’s theorem, the 
characteristic function can be expanded in a power series as
.
(4.40)
If one can obtain a power series expansion of the characteristic function, then the required 
derivatives are proportional to the coefficients of the power series. Specifically, suppose an 
expansion of the form
,
(4.41)
is obtained. Then the derivatives of the characteristic function are given by
.
(4.42)
The moments of the random variable are then given by
.
(4.43)
This procedure is illustrated using a Gaussian random variable in the next example.
dk
d k
----------Y 


jkk!a
a
j
–

k
1
+
-----------------------------
=
E Yk


j
–

k dk
d k
----------
Y 



0
=
k!a
a
j
–

k
1
+
-----------------------------

0
=
k!
ak
-----
=
=
=

0
=
X 


1
k!----
dk
d k
---------X 



0
=





  k
k
0
=


=
X 


.kk
k
0
=


=
dk
d k
---------X 



0
=
k!.k
=
E Xk


j
–

kk!.k
=


Operations on a Single Random Variable    135
www.Academicpress.com
Example 4.22: 
Consider a Gaussian random variable with a mean of 
 and variance 
. Using the 
result of Example 4.20, the characteristic function is 
. Using the 
well-known Taylor series expansion of the exponential function, the characteristic 
function is expressed as
.
The coefficients of the general power series as expressed in Equation (4.41) are given by
Hence, the moments of the zero-mean Gaussian random variable are 
As expected, 
, 
 (since it was specified that 
), and 
 
(since in the case of zero-mean variables, the second moment and variance are one and 
the same). Now, we also see that 
 (as are all odd moments), 
, 
, and so on. We can also conclude from this that for Gaussian random 
variables, the coefficient of skewness is 
 while the coefficient of kurtosis is 
. 
In many cases of interest, the characteristic function has an exponential form. The Gaussian 
random variable is a typical example. In such cases, it is convenient to deal with the natural 
logarithm of the characteristic function.
Definition 4. 8:  In general, we can write a series expansion of 
 as
,
(4.44)
where the coefficients, 
, are called the cumulants and are given as
, 
(4.45)
	
0
=
2
X 


22 2

–


exp
=
X 


22 2

–

n
n!
-------------------------------
n
0
=


1
–

n2n
2nn!
-----------------------2n
n
0
=


=
=
.k
jk 
2


k
k 2


!
--------------------------,     k  even,
0,
    k  odd. 

,

,

=
E Xk


k!
k 2


!
----------------

2
-------



 k,     k  even,
0,
    k  odd. 

,

,

=
E X0


1
=
E X
 
0
=
	
0
=
E X2


2
=
E X3


0
=
E X4


34
=
E X6


156
=
cs
0
=
ck
3
=
X 




ln
X 




ln
/n
j

n
n!
-------------
n
1
=


=
/n
/n
j

n
n
d
d
X 




ln
!
"

0
=
=
n
1 2 3 
  
=



136    Chapter 4
www.Academicpress.com
The cumulants are related to the moments of the random variable. By taking the derivatives 
specified in Equation (4.45) we obtain
,
(4.46)
,
(4.47)
.
(4.48)
Thus, 
 is the mean, 
 is the second central moment (or the variance), and 
 is the third 
central moment. However, higher-order cumulants are not as simply related to the central 
moments.
4.8. Probability-Generating Functions
In the world of signal analysis, we often use Fourier transforms to describe continuous time 
signals, but when we deal with discrete time signals, it is common to use a z-transform instead. 
In the same way, the characteristic function is a useful tool for working with continuous 
random variables, but when discrete random variables are concerned, it is often more 
convenient to use a device similar to the z-transform which is known as the probability-
generating function.
Definition 4.9:  For a discrete random variable with a PMF, 
, defined on the
nonnegative integers,1 
, the probability-generating function, 
, is
defined as
.
(4.49)
Note the similarity between the probability-generating function and the unilateral
z-transform of the PMF. 
Since the PMF is seen as the coefficients of the Taylor series expansion of 
, it should be 
apparent that the PMF can be obtained from the probability-generating function through
.
(4.50)
/1
	X
=
/2
E X2


	X
2
–
X
2
=
=
/3
E X3


3	XE X2


–
2	X
3
+
E
X
	X
–

3


=
=
/1
/2
/3
PX k
 
k
0 1 2 
  
=
HX z 
HX z 
PX k
 zk
k
0
=


=
HX z 
PX k
 
1
k!---- dk
dz k
-------H
X z 
z
0
=
=
1 Note that this definition assumes that the discrete random variable, 
, is defined on nonnegative integer 
values, . One could also define a probability-generating function based on a bilateral z-transform 
which would allow for random variables which can take on negative integer values as well. However, 
since this is less common, we do not consider it further here.
X
k

Operations on a Single Random Variable    137
www.Academicpress.com
The derivatives of the probability-generating function evaluated at zero return the PMF and 
not the moments as with the characteristic function. However, the moments of the random 
variable can be obtained from the derivatives of the probability-generating function at 
. 
Theorem 4.4: The mean of a discrete random variable can be found from its
probability-generating function according to
.
(4.51)
Furthermore, the higher-order derivatives of the probability-generating function
evaluated at 
 lead to quantities which are known as the factorial moments,
.
(4.52)
Proof: The result follows directly from differentiating Equation (4.49). The details are
left to the reader.  
It is a little unfortunate that these derivatives do not produce the moments directly, but the 
moments can be calculated from the factorial moments. For example,
,
.
(4.53)
Hence, the second moment is simply the sum of the first two factorial moments. Furthermore, 
if we were interested in the variance as well, we would obtain
.
(4.54)
Example 4.23: 
Consider the binomial random variable of Example 4.4 whose PMF is
, 
.
The corresponding probability-generating function is
.
z
1
=
E X
 
d
dz
-----HX z 
z
1
=
=
z
1
=
hk
dk
dz k
-------HX z 
z
1
=
E X X
1
–

 X
2
–

 X
k
–
1
+



=
=
h2
E X X
1
–




E X2


E X
 
–
E X2


h1
–
=
=
=
E X2


#
h2
h1
+
=
X
2
E X2


	X
2
–
h2
h1
h1
2
–
+
=
=
PX k
 
n
k
 
  pk 1
p
–

n
k
–
=
k
0 1 2  n
  

=
HX z 
n
k
 
  pk 1
p
–

n
k
– zk
k
0
=
n

n
k
 
  pz

k 1
p
–

n
k
–
k
0
=
n

1
p
–
pz
+

n
=
=
=

(Continued)

138    Chapter 4
www.Academicpress.com
Evaluating the first few derivatives at 
 produces
,
.
From these factorial moments, we calculate the mean, second moment, and variance of a 
binomial random variable as
, 
, 
.
In order to gain an appreciation for the power of these “frequency domain” tools, compare the 
amount of work used to calculate the mean and variance of the binomial random variable using 
the probability-generating function in Example 4.23 with the direct method used in Example 4.4.
As was the case with the characteristic function, we can compute higher-order factorial 
moments without having to take many derivatives, by expanding the probability-generating 
function into a Taylor series. In this case, the Taylor series must be about the point 
. 
.
(4.55)
Once this series is obtained, one can easily identify all of the factorial moments. This is 
illustrated using a geometric random variable in Example 4.24.
Example 4.24: 
A geometric random variable has a PMF given by 
, 
 The 
probability-generating function is found to be
.
In order to facilitate forming a Taylor series expansion of this function about the point 
, it is written explicitly as a function of 
. From there, the power series expansion 
is fairly simple.
.
Comparing the coefficients of this series with the coefficients given in Equation (4.55) 
leads to immediate identification of the factorial moments,
.
z
1
=
h1
d
dz
-----HX z 
z
1
=
np 1
p
–
pz
+

n
1
–
z
1
=
np
=
=
=
h2
d
2
dz2
--------HX z 
z
1
=
n n
1
–

p2 1
p
–
pz
+

n
2
–
z
1
=
n n
1
–

p2
=
=
=
	X
h1
np
=
=
E X2


h1
h2
+
np

2
np 1
p
–


+
=
=
X
2
h2
h1
h1
2
–
+
np 1
p
–


=
=
z
1
=
HX z 
1
k!---- dk
dz k
-------HX z 
z
1
=





 z
1
–

k
k
0
=


1
k!----hk z
1
–

k
k
0
=


=
=
PX k
 
1
p
–

pk
=
k
0 1 2 
  
=
HX z 
1
p
–

 pz

k
k
0
=


1
p
–
1
pz
–
--------------
=
=
z
1
=
z
1
–
HX z 
1
p
–
1
p
–
p z
1
–


–
-------------------------------------
1
1
p
1
p
–
------------ z
1
–


–
-------------------------------------
p
1
p
–
------------



 k
z
1
–

k
k
0
=


=
=
=
hk
k!pk
1
p
–

k
-------------------
=




Operations on a Single Random Variable    139
www.Academicpress.com
4.9  Moment-Generating Functions
In many problems, the random quantities we are studying are often inherently nonnegative. 
Examples include the magnitude of a random signal, the time between arrivals of successive 
customers in a queueing system, or the number of points scored by your favorite football team. 
The resulting PDFs of these quantities are naturally one-sided. For such one-sided waveforms, 
it is common to use Laplace transforms as a frequency domain tool. The moment-generating 
function is the equivalent tool for studying random variables.
Definition 4.10:  The moment-generating function, 
, of a nonnegative2 random
variable, 
, is 
.
(4.56)
Note the similarity between the moment-generating function and the Laplace
transform of the PDF.
The PDF can in principle be retrieved from the moment-generating function through an 
operation similar to an inverse Laplace transform,
.
(4.57)
Because the sign in the exponential term in the integral in Equation (4.56) is the opposite of 
the traditional Laplace transform, the contour of integration (the so-called Bromwich contour) 
in the integral specified in Equation (4.57) must now be placed to the left of all poles of the 
moment-generating function. As with the characteristic function, the moments of the random 
variable can be found from the derivatives of the moment-generating function (hence, its 
name) according to
.
(4.58)
MX u
 
X
MX u
 
E euX


fX x
 eux x
d
0


=
=
fX x
 
1
2j
--------
MX u
 e ux
–
u
d
c
j
–
c
j
+

=
E Xk


dk
du k
--------MX u
 
u
0
=
=
2 One may also define a moment-generating function for random variables which are not necessarily
nonnegative. In that case, a two-sided Laplace transform would be appropriate. This would be identi-
cal to the characteristic function with the association 
.
u
j
=

140    Chapter 4
www.Academicpress.com
It is also noted that if the moment-generating function is expanded in a power series of 
the form
,
(4.59)
then the moments of the random variable are given by 
.
Example 4.25: 
Consider an Erlang random variable with a PDF of the form
The moment-generating function is calculated according to
.
To evaluate this function, we note that the integral looks like the Laplace transform of the 
function 
 evaluated at 
. Using standard tables of Laplace transforms 
(or using integration by parts several times) we get
.
The first two moments are then found as follows:
,
.
From this, we could also infer that the variance is 
. If we wanted 
a general expression for the kth moment, it is not hard to see that
.
4.10  Evaluating Tail Probabilities
A common problem encountered in a variety of applications is the need to compute the 
probability that a random variable exceeds a threshold, 
. Alternatively we might want 
to know, 
. These quantities are referred to as tail probabilities. That is, we are 
asking, what is the probability that the random variable takes on a value that is in the tail of the 
distribution? While this can be found directly from the CDF of the random variable, quite often, 
the CDF may be difficult or even impossible to find. In those cases, one can always resort to 
numerical integration of the PDF. However, this involves a numerical integration over a 
MX u
 
mkuk
k
0
=


=
E Xk


k!mk
=
fX x
 
xn
1
–
x
–


exp
u x
 
n
1
–

!
--------------------------------------------
=
MX u
 
fX x
 eux x
d
0


xn
1
–
1
u
–

x
–


exp
n
1
–

!
-------------------------------------------------- x
d
0


=
=
xn
1
–
n
1
–

!

s
1
u
–
=
MX u
 
1
1
u
–

n
-------------------
=
E X
 
u
d
d 1
u
–

 n
–
u
0
=
n 1
u
–


n
1
+


–
u
0
=
n
=
=
=
E X2


u2
2
d
d
1
u
–

 n
–
u
0
=
n n
1
+

 1
u
–


n
2
+


–
u
0
=
n n
1
+


=
=
=
X
2
n n
1
+


n2
–
n
=
=
E Xk


uk
k
d
d
1
u
–

 n
–
u
0
=
n n
1
+

 n
k
1
–
+


n
k
1
–
+

!
n
1
–

!
---------------------------
=
=
=
Pr X
xo
 


Pr X
	X
–
xo
 





Operations on a Single Random Variable    141
www.Academicpress.com
semi-infinite region, which in some cases may be problematic. Then, too, in some situations, we 
might not even have the PDF of the random variable, but rather the random variable may be 
described in some other fashion. For example, we may only know the mean, or the mean and 
variance, or the random variable may be described by one of the frequency domain functions 
discussed in the previous sections. Obviously, if we are only given partial information about the 
random variable, we would not expect to be able to perfectly evaluate the tail probabilities, but 
we can obtain bounds on these probabilities. In this section, we present several techniques for 
obtaining various bounds on tail probabilities based on different information about the random 
variable. We then conclude the section by showing how to exactly evaluate the tail probabilities 
directly from one of the frequency domain descriptions of the random variables. 
Theorem 4.5 (Markov’s inequality): Suppose that 
 is a nonnegative random
variable (i.e., one whose PDF is nonzero only over the range 
). Then,
.
(4.60)
Proof: For nonnegative random variables, the expected value is 
 . (4.61)
Dividing both sides by 
 gives the desired result.   
Markov’s inequality provides a bound on the tail probability. The bound requires only 
knowledge of the mean of the random variable. Because the bound uses such limited 
information, it has the potential of being very loose. In fact, if 
, then the Markov 
inequality states that 
 is bounded by a number that is greater than 1. While this is 
true, in this case the Markov inequality gives us no useful information. Even in less extreme 
cases, the result can still be very loose as shown by the next example.
Example 4.26: 
Suppose the average life span of a person was 78 years. The probability of a human living 
to be 110 years would then be bounded by
.
Of course, we know that in fact very few people live to be 110 years old, and hence this 
bound is almost useless to us.
X
0 


Pr X
xo
'


E X
 
xo
------------

E X
 
xfX x
  x
d
0


xfX x
  x
d
0
xo

xfX x
  x
d
xo


+
xfX x
  x
d
xo


xo
fX x
  x
d
xo


'
'
=
=
xo
xo
E X
 
&
Pr X
xo
'


Pr X
110
'


78
110
---------

0.7091
=



142    Chapter 4
www.Academicpress.com
If we know more about the random variable than just its mean, we can obtain a more precise 
estimate of its tail probability. In Example 4.26, we know that the bound given by the 
Markov’s inequality is ridiculously loose because we know something about the variability of 
the human life span. The next result allows us to use the variance as well as the mean of a 
random variable to form a different bound on the tail probability.
Theorem 4.6 (Chebyshev’s inequality):  Suppose that 
 is a random variable with
mean, 
, and variance, 
. The probability that the random variable takes on a
value that is removed from the mean by more than 
 is given by
.
(4.62)
Proof: Chebyshev’s inequality is a direct result of Markov’s inequality. Note that the
event 
 is equivalent to the event 
. Applying Markov’s
inequality to the later event results in
.  
(4.63)
Chebyshev’s inequality gives a bound on the two-sided tail probability, whereas the Markov 
inequality applies to the one-sided tail probability. Also, the Chebyshev inequality can be 
applied to any random variable, not just those that are nonnegative.
Example 4.27: 
Continuing the previous example, suppose that in addition to a mean of 78 years, the 
human life span had a standard deviation of 15 years. In this case
.
Now the Chebyshev inequality can be applied to give
.
While this result may still be quite loose, by using the extra piece of information provided 
by the variance, a better bound is obtained.
Theorem 4.7 (Chernoff bound): Suppose 
 is a random variable whose moment
generating function is 
. Then 
.
(4.64)
X
	X
X
2
xo
Pr X
	X
–
xo
'


X
2
xo
2
-------

X
	X
–
xo
'
!
"
X
	X
–

2
xo
2
'
!
"
Pr
X
	X
–

2
xo
2
'


E
X
	X
–

2


xo
2
--------------------------------

X
2
xo
2
-------
=
Pr X
110
'


Pr X
110
'


Pr X
46



+

Pr X
78
–
32
'


=
Pr X
78
–
32
'


15
32
------



 2

0.2197
=
X
MX s 
Pr X
xo
'


  e sxo
–
MX s 
s
0
'
min




Operations on a Single Random Variable    143
www.Academicpress.com
Proof: First, note that
.
(4.65)
Next, upper bound the unit step function in the above integrand by an exponential 
function of the form 
. This bound is illustrated in Figure 4.5. 
Note that the bound is valid for any real 
. The tail probability is then upper 
bounded by
.
(4.66)
Since this bound is valid for any 
, it can be tightened by finding the value of 
that minimizes the right-hand side. In this expression, a two-sided Laplace transform
must be used to obtain the moment-generating function if the random variable is not
nonnegative (see footnote 2 associated with Definition 4.10).  
Example 4.28: 
Consider a standard normal random variable whose moment-generating function is given 
by 
 (see the result of Example 4.20, where the characteristic function is 
found and replace 
 with 
). The tail probability, 
, in this case is simply the 
Q-function, 
. According to (4.66), this tail probability can be bounded by
for any 
. Minimizing with respect to , we get
.
Pr X
xo
'


fX x
  x
d
xo


fX x
 u x
xo
–

 x
d

–


=
=
u x
xo
–


s x
xo
–




exp

Figure 4.5  
The unit step function and an exponential upper bound.
(s(x-xo))
u(x-xo)
exp
x
xo
s
0
'
Pr X
xo
'


e sxo
–
fX x
 esx x
d

–



e sxo
–
MX s 
=
s
0
'
s
MX u
 
u2 2



exp
=

ju
–
Pr X
xo
'


Q xo


Q xo


uxo
–
u2
2-----
+




exp

u
0
'
u
u
d
d
uxo
–
u2
2-----
+




exp
xo
–
u
+


uxo
–
u2
2-----
+




exp
0
=
=
u
#
xo
=

(Continued)

144    Chapter 4
www.Academicpress.com
Hence, the Chernoff bound on the tail probability for a standard normal random 
variable is
.
The result of this example provides a convenient upper bound on the Q-function.
Evaluating the Chernoff bound requires knowledge of the moment-generating function of the 
random variable. This information is sufficient to calculate the tail probability exactly since, in 
theory, one can obtain the PDF from the moment-generating function, and from there the exact 
tail probability can be obtained. However, in cases where the moment-generating function is 
of a complicated analytical form determining the PDF may be exceedingly difficult. Indeed, in 
some cases, it may not be possible to express the tail probability in closed form (like with the 
Gaussian random variable). In these cases, the Chernoff bound will often provide an 
analytically tractable expression which can give a crude bound on the tail probability. If a 
precise expression for the tail probability is required, the result of Theorem 4.8 will show how 
this can be obtained directly from the moment-generating function (without having to 
explicitly find the PDF).
Theorem 4.8: For a random variable, 
, with a moment-generating function, 
,
an exact expression for the tail probability, 
, is given by
,
(4.67)
where the contour of integration is to the right of the origin, but to the left of all
singularities of the moment-generating function in the right half plane.
Proof: The right tail probability is given in general by
.
(4.68)
Then, replace the PDF in this integral, with an inverse transform of the moment-
generating function as specified in Equation (4.57).
. (4.69)
Q xo


xo
2
2-----
–




exp

X
MX u
 
Pr X
xo
'


Pr X
xo
'


1
2j
--------
MX u
 
u
----------------e uxo
–
u
d
c
j
–
c
j
+

=
Pr X
xo
'


fX x
  x
d
xo


=
Pr X
xo
'


1
2j
--------
MX u
 e ux
–
u
d
x
d
c
j
–
c
j
+

xo


1
2j
--------
MX u
 
e ux
–
xo


x
d
u
d
c
j
–
c
j
+

=
=


Operations on a Single Random Variable    145
www.Academicpress.com
Evaluating the inner integral results in
, for 
.  
(4.70)
The integral specified in Equation (4.67) can be evaluated numerically or, when convenient to 
do so, it can also be evaluated by computing the appropriate residues.3 For 
 the contour 
of integration can be closed to the right. The resulting closed contour will encompass all the 
singularities of the moment-generating function in the right half plane. According to Cauchy’s 
residue theorem, the value of the integral will then be 
 times the sum of the residues of all 
the singularities encompassed by the contour. Hence,
.
(4.71)
If a precise evaluation of the tail probability is not necessary, several approximations to the 
integral in Equation (4.67) are available. Perhaps the simplest and most useful is known as 
the saddle point approximation. To develop the saddle point approximation, define 
 and 
.
(4.72)
Furthermore, consider a Taylor series expansion of the function 
 about some point 
,
.
(4.73)
In particular, if 
 is chosen so that 
, then near the point 
, the integrand in 
Equation (4.67) behaves approximately like
.
(4.74)
In general, the point 
 will be a minima of the integrand as viewed along the real axis. 
This follows from the fact that the integrand is a concave function of . A useful property of 
complex (analytic) functions tells us that if the function has a minima at some point 
 as  
Pr X
xo
'


1
2j
--------
MX u
 
u
----------------e uxo
–
u
d
c
j
–
c
j
+

=
Re u
 
0
 
xo
0
 
2j
–
Pr X
xo
'


Residues
MX u
 
u
----------------e uxo
–

0

1

2
right half plane

=
3 u
 
MX u
 


ln
=
/ u
 
MX u
 
u
----------------e uxo
–




ln
3 u
 
uxo
–
u
 
ln
–
=
=
/ u
 
u
uo
=
/ u
 
/ uo


/' uo

 u
uo
–


1
2---/'' uo

 u
uo
–

2

+
+
+
=
uo
/' uo


0
=
u
uo
=
MX u
 
u
----------------e uxo
–
e/ u
 
/ uo




exp
1
2---/'' uo

 u
uo
–

2




exp

=
u
uo
=
u
uo
u
3 The remainder of this section assumes the student is familiar with the concepts of contour integration 
and residue calculus. For those students not familiar with these topics, the remainder of this section 
can be skipped without any loss in continuity.

146    Chapter 4
www.Academicpress.com
passes through it in one direction, the function will also have a maxima as  passes through 
the same point in the orthogonal direction. Such a point is called a “saddle point” since the 
shape of the function resembles a saddle near that point. If the contour of integration is 
selected to pass through the saddle point, the integrand will reach a local maximum at the 
saddle point. As just seen in Equation (4.74), the integrand also has a Gaussian behavior at and 
around the saddle point. Hence, using the approximation of (4.74) and running the contour of 
integration through the saddle point so that 
 along the integration contour, the tail 
probability is approximated by
                                         
                        
.
(4.75)
The third step is accomplished using the normalization integral for Gaussian PDFs.
The saddle point approximation is usually quite accurate provided that 
. That is, the 
farther we go out into the tail of the distribution, the better the approximation. If it is required 
to calculate 
 for 
, it is usually better to calculate the left tail probability 
in which case the saddle point approximation is
,
(4.76)
where in this case, the saddle point, 
, must be negative.
Example 4.29: 
In this example, we form the saddle point approximation to the Q-function which is the 
right tail probability for a standard normal random variable. The corresponding 
moment-generating function is 
. To find the saddle point, we note that
.
u
u
uo
j
+
=
Pr X
xo
'


/ uo




exp
2j
----------------------------
1
2---/'' uo

 u
uo
–

2




exp
u
d
uo
j
–
uo
j
+


/ uo




exp
2
----------------------------
1
2---
– /'' uo

2




exp

d

–


=
/ uo




exp
2/'' uo


----------------------------
=
MX uo


uoxo
–


exp
uo 2/'' uo


------------------------------------------------
=
xo
E X
 
»
Pr X
xo
'


xo
E X
 
&
Pr X
xo



MX uo


uoxo
–


exp
uo 2/'' uo


------------------------------------------------
–

uo
MX u
 
u2 2



exp
=
/ u
 
u2
2-----
u
 
ln
–
uxo
–
=


Operations on a Single Random Variable    147
www.Academicpress.com
We will need the first two derivatives of this function:
, 
.
The saddle point is the solution to 
. This results in a quadratic equation whose 
roots are
.
When calculating the right tail probability, the saddle point must be to the right of the 
imaginary axis, hence the positive root must be used:
.
The saddle point approximation then becomes
.
The exact value of the Q-function and the saddle point approximation are compared in 
Figure 4.6. As long as 
 is not close to zero, this approximation is quite accurate.
/' u
 
u
1
u---
–
xo
–
=
/'' u
 
1
1
u2
-----
+
=
/' uo


0
=
uo
xo
xo
2
4
+
+
2
------------------------------
=
uo
xo
xo
2
4
+
+
2
------------------------------
=
Q xo


Mx uo


uoxo
–


exp
uo 2/'' uo


-----------------------------------------------

uo
2
2-----
uoxo
–




exp
2 1
uo
2
+


--------------------------------------
=
0
1
2
3
4
10-5
10-4
10-3
10-2
10-1
100
xo
Pr(X> xo)
Saddlepoint approximation
Q-function
Figure 4.6  
The Q-function and its saddle point approximation.
xo


148    Chapter 4
www.Academicpress.com
4.11  Engineering Application—Scalar Quantization
In many applications, it is convenient to convert a signal which is analog in nature to a digital 
one. This is typically done in three steps. First, the signal is sampled, which converts the signal 
from continuous time to discrete time. Then samples of the signal are quantized. This second 
action converts the signal from one with a continuous amplitude to one whose amplitude can 
only take on discrete values. Once the signal is converted to discrete time/discrete amplitude, 
the signal can then easily be represented by a sequence of bits. In this third step, each discrete 
amplitude level is represented by a binary codeword. While the first step (sampling) and the 
third step (encoding) are invertible, the second step (quantization) is not. That is, we can 
perfectly recover the analog signal from its discrete time samples (provided the samples are 
taken at a rate above the Nyquist rate), and the discrete amplitude levels can easily be 
recovered from the codewords which represent them (provided a lossless source code is used). 
However, the act of quantization causes distortion of the signal which cannot be undone. Given 
the discrete amplitude of a sample, it is not possible to determine the exact value of the 
original (continuous amplitude) sample. For this reason, careful attention is paid to the 
quantization process in order to minimize the amount of distortion. 
In order to determine efficient ways to quantize signals, we must first quantify this concept of 
signal distortion. Suppose a signal is sampled and we focus attention on one of those samples. 
Let the random variable 
 represent the value of that sample, which in general will draw from 
a continuous sample space. Now suppose that sample is quantized (using some quantization 
function 
) to form a new (discrete) random variable 
. The difference between 
the original sample value and its quantized value, 
, is the error caused by the 
quantizer, or the quantizer noise. It is common to measure signal distortion as the mean-
squared quantizer error,
. 
(4.77)
We will see in Chapter 10 that the mean-squared value of a signal has the physical 
interpretation of the signal’s power. Thus, the quantity  can be interpreted as the quantization 
noise power. Often the fidelity of a quantized signal is measured in terms of the ratio of the 
original signal power, 
, to the quantization noise power. This is referred to as the signal-
to-quantization-noise power ratio (SQNR)
.
(4.78)
The goal of the quantizer design is to choose a quantization function which minimizes the 
distortion, . Normally, the quantizer maps the sample space of 
 into one of 
 levels. 
Then each quantization level can be represented by a unique n-bit codeword. We refer to this 
X
q x
 
Y
q X
 
=
X
q X
 
–
d
E
X
q X
 
–

2


x
q x
 
–

2fX x
  x
d

–


=
=
d
E X2


SQNR
E X2


E
X
q X
 
–

2


--------------------------------------
=
d
X
M
2n
=

Operations on a Single Random Variable    149
www.Academicpress.com
as an n-bit quantizer. As indicated in Equation (4.77), the expected value is with respect to the 
PDF of 
. Hence, the function 
 that minimizes the distortion will depend on the 
distribution of 
. 
To start with consider a random variable 
 which is uniformly distributed over the interval 
. Since the sample 
 is equally likely to fall anywhere in the region, it would 
make sense for the quantizer to divide that region into 
 equally spaced subintervals of width 
. For each subinterval, the quantization level (i.e., the value of 
 for that 
subinterval) should be chosen as the midpoint of the subinterval. This is referred to as a 
uniform quantizer. A 3-bit uniform quantizer is illustrated in Figure 4.7. For example, if 
, then 
. To measure the distortion for this signal together with the 
uniform quantizer, condition on the event that the signal falls within one of the quantization 
intervals, and then use the theorem of total probability:
,
(4.79)
where 
 refers to the kth quantization interval. Consider, for example, 
, 
so that
.
(4.80)
X
q x
 
X
X
a 2

a 2


–


X
M
4
a M

=
q x
 
Figure 4.7 
A 3-bit uniform quantizer on the interval (-a/2,a/2).
a/2
a/2
-a/4
-a/4
-a/2
-a/2
q(x)
x
a/4
a/4
X
0 a 8




)
q X
 
a 16

=
d
E
X
q X
 
–

2


E
X
q X
 
–

2 X
Xk
)

Pr X
Xk
)


k
1
=


=
=
Xk
X5
0 a 8




=
E
X
q X
 
–

2 X
X5
)


E
X
a 16

–

2 X
0 a 8




)


=

150    Chapter 4
www.Academicpress.com
To calculate this conditional expected value requires the conditional PDF of 
. From 
Equation (3.41) this is 
, 
.
(4.81)
Not surprisingly, conditioned on 
, 
 is uniformly distributed over 
. 
The conditional expected value is then
.
(4.82)
Due to the symmetry of the uniform distribution, this conditional distortion is the same 
regardless of what quantization interval the signal falls in. Hence, Equation (4.82) is also the 
unconditional distortion. Note that the power of the original signal is
.
(4.83)
The resulting SQNR is then
.
(4.84)
The preceding result for the three-bit uniform quantizer can be generalized to any uniform 
quantizer. In general, for an n-bit uniform quantizer, there will be 
 quantization 
intervals of width 
. Consider the quantization interval 
 and suppose the 
quantization level for that interval is chosen to be the midpoint, 
. Then the distortion for 
that interval (and hence the distortion for the quantizer) is
.
(4.85)
The SQNR for an n-bit uniform quantizer with a uniformly distributed input is
 or 
.(4.86)
This is the so-called 6 dB rule whereby the SQNR is increased by approximately 6 dB for each 
extra bit added to the quantizer. For example, in wireline digital telephony, 8-bit quantization 
is used which would result in an SQNR of approximately 48 dB. 
X
fX x X
0 a 8




)


fX x
 
Pr X
0 a 8




)


------------------------------------------
1 a

1 8

----------
8
a---
=
=
=
x
0 a 8




)
X
0 a 8




)
X
0 a 8




E
X
a 16

–

2 X
0 a 8




)


8
a---
x
a 16

–

2 x
d
0
a 8


a2
768
---------
=
=
E X2


1
a---
x2 x
d
a 2

–
a 2


a2
12
------
=
=
SQNR
E X2


d
---------------
a2 12

a2 768

------------------
64
18.06 dB
=
=
=
=
M
2n
=
4
a M

=
0 4



4 2

E
X
q X
 
–

2 X
0 4



)


1
4---
x
4 2

–

2 x
d
0
4

42 12

=
=
SQNR
E X2


d
---------------
a2 12

42 12

----------------
M2
22n
=
=
=
=
SQNR (dB)
2nlog10 2
 
6.02n dB
=
=

Operations on a Single Random Variable    151
www.Academicpress.com
The previous results assumed that the input to the quantizer followed a uniform probability 
distribution. This is rarely the case. Speech signals, for example, are commonly modeled using 
a Laplace (two-sided exponential) distribution. For such signals, small sample values are 
much more frequent than larger values. In such a situation, it would make sense to use finer 
resolution (i.e., narrower quantization intervals) for the most frequent smaller amplitudes in 
order to keep the distortion minimized in those regions, at the cost of more distortion in the 
less frequent larger amplitude regions. 
Given that an n-bit quantizer is to be used, the design of an optimum quantizer involves two 
separate problems. First, the ranges for each quantization interval must be specified; then the 
quantization level for each interval must be chosen. The following theorem specifies how each 
of these two tasks should be accomplished.
Theorem 4.9: A random variable 
 with PDF 
 is to be quantized with an 
M-level quantizer that produces a discrete random variable 
 according to
, for 
, 
,
(4.87)
where it is assumed that the lower limit of the first quantization interval is 
 
and the upper limit of the last quantization interval is 
. The (mean-squared) 
distortion is minimized by choosing the quantization intervals (i.e., the 
) and the 
quantization levels (i.e., the 
) according to
(i) 
, 
, (the conditional mean criterion), (4.88)
(ii) 
, 
,
(the midpoint criterion).  
(4.89)
These two criteria provide a system of 
 equations with which to solve for
the
quantities (
) which specify the optimum
M-level quantizer.
Proof: The distortion is given by
.
(4.90)
To minimize 
 with respect to 
, 
.
(4.91)
X
fX x
 
Y
y
q x
 
yi
=
=
xi
1
–
x
xi
&
&
i
1 2  M
 

=
x0

–
=
xM

=
xi
yi
yi
E X xi
1
–
X
xi
&
&


=
i
1 2  M
 

=
xi
yi
yi
1
+
+
2
----------------------
=
i
1 2  M
1
–
 

=
2M
1
–
2M
1
–
x1 x2  xM
1
–
y1 y2  yM







d
x
yi
–

2fX x
  x
d
xi
1
–
xi
i
1
=
M

=
d
yj
yj
5
5d
2
x
yi
–

fX x
  x
d
xi
1
–
xi
–
0
=
=

152    Chapter 4
www.Academicpress.com
Solving for 
 in this equation establishes the conditional mean criterion. Similarly
differentiating with respect to 
 gives
.
(4.92)
Solving for 
 produces the midpoint criterion.  
Example 4.30: 
Using the criteria set forth in Theorem 4.9, an ideal nonuniform 2-bit quantizer will be 
designed for a signal whose samples have a Laplace distribution, 
. 
A 2-bit quantizer will have four quantization levels, 
, and four corresponding 
quantization intervals which can be specified by three boundary points, 
. The 
generic form of the 2-bit quantizer is illustrated in Figure 4.8. Due to the symmetry of the 
Laplace distribution, it seems reasonable to expect that the quantizer should have a neg-
ative symmetry about the y-axis. That is, 
, 
, 
, and 
. Hence, 
it is sufficient to determine just three unknowns, such as 
. The rest can be 
inferred from the symmetry. Application of the conditional mean criterion and the mid-
point criterion leads to the following set of three equations:
,
,
.
yj
xj
xj
5
5d
xj
yj
–

2fX xj


xj
yj
1
+
–

2
–
fX xj


0
=
=
xj
fX x
 
1 2



x
–


exp
=
y1 y2 y3 y4



!
"
x1 x2 x3


!
"
y1
y2
y3
y4
x1
x3
x
y
Figure 4.8  
A 2-bit quantizer.
x1
x3
–
=
x2
0
=
y1
y4
–
=
y2
y3
–
=
x3 y3 y4


!
"
y3
E X 0
X
x3
&
&


x
2---
x
–


exp
x
d
0
x3
1
2---
x
–


exp
x
d
0
x3
-------------------------------------
1
x3
ex3
1
–
---------------
–
=
=
=
y4
E X X
x3
 


x
2---
x
–


exp
x
d
x3

1
2---
x
–


exp
x
d
x3

-------------------------------------
x3
1
+
=
=
=
x3
y3
y4
+
2
----------------
=


Operations on a Single Random Variable    153
www.Academicpress.com
Plugging the expressions for 
 and 
 into the last equation results in a single equation 
to solve for the variable 
. Unfortunately, the equation is transcendental and must be 
solved numerically. Doing so results in the solution 
. The 
(mean-squared) distortion of this 2-bit quantizer is given by
.
Note that the power in the original (unquantized) signal is 
 so that the SQNR of 
this quantizer is
.
Example 4.31: 
In this example, we generalize the results of the last example for an 
arbitrary number of quantization levels. When the number of quantization 
levels get large, the number of equations to solve becomes too difficult to 
do by hand, so we use MATLAB to help us with this task. Again, we assume 
that the random variable  follows a Laplace distribution given by 
. Because of the symmetry of this distribution, we again take 
advantage of the fact that the optimum quantizer will be symmetric. We design a 
quantizer with 
 levels for positive  (and hence 
 levels for negative  as well, for a 
total of 
 levels). The 
 quantization levels are at 
 and the quantization bin 
edges are at 
. We compute the optimum quantizer in an 
iterative fashion. We start by arbitrarily setting the quantization bins in a uniform 
fashion. We choose to start with 
. We then iterate between computing new 
quantization levels according to Equation (4.88) and new quantization bin edges 
according to Equation (4.89). After going back and forth between these two equations 
several times, the results converge toward a final optimum quantizer. For the Laplace 
distribution, the conditional mean criterion results in
.
At each iteration stage (after computing new quantization levels), we also compute the 
the SQNR. By observing the SQNR at each stage, we can verify that this iterative process 
is in fact improving the quantizer design at each iteration. For this example, the SQNR is 
computed according to (see Exercise 4.82).
, 
.
y3
y4
x3
x3 y3 y4


!
"
1.594 0.594 2.594


!
"
=
d
2
x
y3
–

2fX x
  x
d
0
x3
2
x
y4
–

2fX x
  x
d
x3


+
0.3524
=
=
E X2


2
=
SQNR
E X2


d
---------------
2
0.3524
----------------
5.675
7.54 dB
=
=
=
=
X
fX x
 
1 2



x
–


exp
=
M
X
M
X
2M
M
y1 y2  yM



x0= 0 x1 x2  xN
1
–
xN =





xi
2i M

=
yi
xi
1
–
1
+


xi
1
–
–


exp
xi
1
+


xi
–


exp
–
xi
1
–
–


exp
xi
–


exp
–
-----------------------------------------------------------------------------------------------------
=
SQNR
1
1
1
2---
piyi
2
i
1
=
M

–
--------------------------------
=
pi
xi
1
–
–


exp
xi
–


exp
–
=


(Continued)

154    Chapter 4
www.Academicpress.com
The MATLAB code we used to implement this process is included below. Figure 4.9 
shows the results of running this code for the case of 
 (16 level, 4-bit quantizer). 
M=8;
x=[0 2*[1:M-1]/M];
% Initialize quantization bin edges
iterations=50;
for k=1:iterations
   % Update quantization levels
   x1=x(1:M-1);
   x2=x(2:M);
   y=(x1+1).*exp(-x1)-(x2+1).*exp(-x2);
   y=y./(exp(-x1)-exp(-x2));
   y=[y x(length(x))+1];
   % Calculate SQNR
   p=exp(-x1)-exp(-x2);
   p=[p exp(-x(length(x)))];
   SQNR(k)=1/(1-(y.^2)*p'/2);
   % Update quantization bin edges
   y1=y(1:M-1);
   y2=y(2:M);
   x=[0 (y1+y2)/2];  
end
plot(10*log10(SQNR),'o')
M
8
=
0
5
10
15
20
25
30
35
40
45
50
10
11
12
13
14
15
16
17
18
Iteration number
SQNR (dB)
Figure 4.9  
SQNR measurements for the iterative quantizer design in Example 4.31. (For color version of this 
figure, the reader is refered to the web version of this chapter).


Operations on a Single Random Variable    155
www.Academicpress.com
4.12 Engineering Application—Entropy and Source Coding
The concept of information is something we hear about frequently. After all, we supposedly 
live in the “information age” with the internet is often referred to as the “information 
superhighway.” But, what is information? In this section, we give a quantitative definition of 
information and show how this concept is used in the world of digital communications. 
To motivate the forthcoming definition, imagine a situation where we had a genie who could 
tell us about certain future events. Suppose that this genie told us that on July 15th of next year, 
the high temperature in the state of Texas would be above 
. Anyone familiar with the 
weather trends in Texas would know that our genie has actually given us very little 
information. Since we know that the temperature in July in Texas is above 
 with 
probability approaching one, the statement made by the genie does not tell us anything new. 
Next, suppose that the genie tells us that on July 15th of next year, the high temperature in the 
state of Texas would be below 
. Since this event is improbable, in this case the genie 
would be giving us a great deal of information. 
To define a numerical quantity which we will call information, we note from the previous 
discussion that
•
Information should be a function of various events. Observing (or being told) that 
some event 
 occurs (or will occur) provides a certain amount of information, 
.
•
The amount of information associated with an event should be inversely related to the 
probability of the event. Observing highly probable events provides very little 
information, while observing very unlikely events gives a large amount of information.
At this point, there are many definitions which could satisfy the two previous bullet items. 
We include one more observation that will limit the possibilities:
•
If it is observed that two events, 
 and 
, have occurred and if those two events are 
independent, then we expect that the information 
. 
Since we observed that information should be a function of the probability of an event, the last 
bullet item requires us to define information as a function of probability that satisfies
.
(4.93)
Since a logarithmic function satisfies this property, we obtain the following definition.
Definition 4.11:  If some event 
 occurs with probability 
, then observing the
event 
 provides an amount of information given by
.
(4.94)
90F
90F
80F
A
I A
 
A
B
I A
B



I A
 
I B
 
+
=
I pApB


I pA


I pB


+
=
A
pA
A
I A
 
pA


log
–
=

156    Chapter 4
www.Academicpress.com
The units associated with this measure of information depend on the base of the logarithm
used. If base 2 logs are used, then the unit of information is a “bit”; if natural logs are
used, the unit of information is the “nat.”
Note that with this definition, an event which is sure to happen (
) provides 
bits of information. This makes sense since if we know the event must happen, 
observing that it does happen provides us with no information. 
Next, suppose we conduct some experiment which has a finite number of outcomes. 
The random variable 
 will be used to map those outcomes into the set of integers, 
. How much information do we obtain when we observe the outcome of the 
experiment? Since information is a function of the probability of each outcome, the amount of 
information is random and depends on which outcome occurs. We can, however, talk about 
the average information associated with the observation of the experiment.
Definition 4.12: Suppose a discrete random variable 
 takes on the values
 with probabilities 
. The average information or
(Shannon) entropy associated with observing a realization of 
 is
.
(4.95)
Entropy provides a numerical measure of how much randomness or uncertainty there is in a 
random variable. In the context of a digital communication system, the random variable might 
represent the output of a data source. For example, suppose a binary source outputs the letters 
 and 
 with probabilities  and 
, respectively. The entropy associated with 
each letter the source outputs is
.
(4.96)
The function 
 is known as the binary entropy function and is plotted in Figure 4.10. Note 
that this function has a maximum value of 1 bit when 
. Consequently, to maximize 
the information content of a binary source, the source symbols should be equally likely.
Next, suppose a digital source described by a discrete random variable 
 periodically outputs 
symbols. Then the information rate of the source is given by 
 bits/source symbol. 
Furthermore, suppose we wish to represent the source symbols with binary codewords such 
that the resulting binary representation of the source outputs uses  bits/symbol. A 
fundamental result of source coding, which we will not attempt to prove here, is that if we 
desire the source code to be lossless (that is, we can always recover the original source 
pA
1
=
I A
 
0
=
X
0 1 2  n
1
–
  

X
0 1 2  n
1
–
  

p0 p1  pn
1
–



X
H X
 
Pr X =k

I X= k


k
0
=
n
1
–

pk
1
pk
-----
	



log
k
0
=
n
1
–

=
=
X
0
=
X
1
=
p
1
p
–
H X
 
p
1
p---
	 
 
log
1
p
–


1
1
p
–
------------
	



log
+
p
 
=
=
p
 
p
1 2

=
X
H X
 
r

Operations on a Single Random Variable    157
www.Academicpress.com
symbols from their binary representation), then the source code rate must satisfy 
. In 
other words, the entropy of a source provides a lower bound on the average number of bits that 
are needed to represent each source output.
Example 4.32: 
Consider a source that outputs symbols from a four-letter alphabet. That is, suppose 
. Let 
, 
, and 
 be the probability of each of the 
four source symbols. Given this source distribution, the source has an entropy of
.
Table 4.2 shows several different possible binary representations of this source. This first 
code is the simplest and most obvious representation. Since there are four letters, we can 
always assign a unique 2-bit codeword to represent each source letter. This results in a 
code rate of 
bits/symbol which is indeed greater than the entropy of the source. 
The second code uses variable length codewords. The average codeword length is
.
Therefore, this code produces the most efficient representation of any lossless source 
coded since the code rate is equal to the source entropy. Note that Code 3 from 
Table 4.2 produces a code rate of
r
H X
 

0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
H(p)
p
Figure 4.10  
The binary entropy function.
X
a b c d
  



pa
1 2

=
pb
1 4

=
pc
pd
1 8

=
=
H X
 
1
2---
2
 
log
1
4---
4
 
log
2*1
8---
8
 
log
+
+
1.75bits/source symbol
=
=
r1
2
=
r2
1
2---*1
1
4---*2
1
4---*3
+
+
1.75 bits/symbol
=
=

(Continued)

158    Chapter 4
www.Academicpress.com
,
which is lower than the entropy, but this code is not lossless. This can easily be seen by 
noting that the source sequences “d” and “a,b” both lead to the same encoded sequence 
“01.” 
Table 4.2: Three possible codes for a four-letter source
Source Letters
Code 1
00
01
10
11
Code 2
0
10
110
111
Code 3
0
1
10
01
r3
3
4---*1
1
4---*2
+
1.25 bits/symbol
=
=
a
b
c
d


159
CHAPTER 4
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
 Exercises
Section 4.1:  Expected Values of a Random Variable
4.1
Find the mean of the random variables described by each of the following probability 
density functions:
(a) 
fW w


1
b
a
–
------------
=
, a
w
b


;  (c) 
fY y
 
y 1
y
–


=
, 0
y
1


;
(b) 
fX x
 
3x2
=
,  0
x
1


;
(d) 
fZ z 
2
---
1
1
z2
+
--------------
=
, z
0

.
Note:  Each of the PDFs described above is zero outside the intervals indicated.
4.2
Find the mean of the random variables described by each of the following probability 
mass functions:
(a)
PK k
 
1
k0
1
+
--------------
=
,  k
0 1 2  k0
  

=
;
(b)
PM m


2m
m0 m0
1
+


----------------------------
=
,  m
0 1 2  m0
  

=
;
(c)
PN n
 
1
2---
	 
  n
=
,  n
1 2 3 
  
=
;
(d)
PQ q
 
q
1
–
q0
1
–
	


 1
2---
	 
  q
=
,  q
q0 q0
1
+
q0
2
+




=
 .
Note:  Each of the PMFs described above is zero outside the intervals indicated.
4.3
Find the mean of the random variables described by each of the following cumulative 
distribution functions:
(a)
FW w


0,
w
0,

w 10,

       0
w
10


1,
  w
10;






=
   (c) 
FY y
 
0,
y
0,

1
4---y2,      0
y
2,


1,
y
2;






=
(b)
FX x
 
1
2x
–


exp
–

u x
 
=
;        (d) 
FZ z 
1
z2
–


exp
–

u z 
=
.

160    Chapter 4
www.Academicpress.com
4.4
In each of the following cases, find the value of the parameter a  which causes the 
indicated random variable to have a mean value of 10.
(a)
PDF: fW w


2
a---, a
2---
w
a,


0, otherwise





=
(b)
PMF: PM m


1
2---
	 
  m
a
–
1
+
=
,  m
a a
1
+
a
2
+




=
(c)
CDF: FX x
 
0,
x
0,

ax2,
        0
x
10,


1
a
–
10
------------x
2a
1,
–
+
          10
x
20,


1,
   x
20.








=
4.5
Suppose a random variable X  has a PDF which is nonzero only on the interval 0 


.  
That is, the random variable cannot take on negative values. Prove that
E X
 
1
FX x
 
–

 x
d
0


=
.
Section 4.2: Expected Values of Functions of a Random Variable
4.6
Two players compete against each other in a game of chance where Player A wins with 
probability 1/3 and Player B wins with probability 2/3. Every time Player A loses he 
must pay Player B $1, while every time Player B loses he must pay Player A $3. Each 
time the two play the game, the results are independent of any other game. If the two 
players repeat the game 10 times, what is the expected value of Player A’s winnings?
4.7
The current flowing through a 75   resistor is modelled as a Gaussian random variable 
with parameters, m
0A
=
 and 
15 mA
=
. Find the average value of the power 
consumed in the resistor.
4.8
The received voltage in a 75   antenna of a wireless communication system is 
modeled as a Rayleigh random variable, fV v
 
v
 2
------
v2
22
---------
–
	



exp
u v
 
=
.  What does the 
value of the parameter   need to be for the received power to be 10W ?

Exercises    161
www.Academicpress.com
4.9
Suppose X  is a Gaussian random variable with a mean of   and a variance of 2  
(i.e., X
N  2




). Find an expression for E X

 .
4.10 Prove Jensen’s inequality, which states that for any convex function g x
   and any 
random variable X ,
E g X
 


g E X
 



.
Section 4.3:  Moments
4.11 Find an expression for the m th moment of an Erlang random variable whose PDF is
given by fX x
 
bn
n
1
–

!
------------------xn
1
– e bx
–
u x
 
=
n
 for some positive integer  and positive 
constant b .
4.12 Find an expression for the even moments of a Rayleigh random variable. That is, find 
E Y2m

  for any positive integer m  if the random variable, Y , has a PDF given by 
fY y
 
y
2
------
y2
22
---------
–
	


 u y
 
exp
=
.
4.13 Find the first three moments of a geometric random variable whose PMF is 
PN n
 
1
p
–

pn
=
, n
0 1 2 
  
=
.
4.14 Find the first three moments of a Poisson random variable whose PMF is 
PM m


me 
–
m!
---------------
=
, m
0 1 2 
  
=
.
4.15 For the Rayleigh random variable described in Exercise 4.12, find a relationship 
between the n th moment, E Yn

 , and the n th moment of a standard normal random 
variable.
4.16 Suppose X  is a random variable whose n th moment is gn , n
1 2 3.
 
=
  In terms of 
the gn , find an expression for the m th moment of the random variable Y
aX
b
+
=
 for 
constants a  and b .  
4.17 Suppose X  is a random variable whose n th moment is gn , n
1 2 3.
 
=
.  In terms 
of the gn , find an expression for E eX

 .

162    Chapter 4
www.Academicpress.com
Section 4.4: Central Moments
4.18 Calculate the mean value, second moment, and variance of each of the following 
random variables:
(a)
Binomial, PX k
 
n
k
	 
  pk 1
p
–

n
k
–
=
,  k
0 1 2  n
  

=
;
(b)
Poisson, PX k
 
 k
k!
------e 
–
=
,  k
0 1 2 
  
=
;
(c)
Laplace, fX x
 
1
2b
------
x
b-----
–
	



exp
=
;
(d)
Gamma, fX x
 
x b


c
1
–
x
b---
–
	



exp
b c
 
---------------------------------------------u x
 
=
;
4.19 For a Gaussian random variable, derive expressions for the coefficient of skewness and 
the coefficient of kurtosis in terms of the mean and variance,   and 2 .
4.20 Prove that all odd central moments of a Gaussian random variable are equal to zero.  
Furthermore, develop an expression for all even central moments of a Gaussian random 
variable.
4.21 Show that the variance of a Cauchy random variable is undefined (infinite).
4.22 Let cn  be the n th central moment of a random variable and n  be its n th moment.  
Find a relationship between cn  and k , k
0 1 2  n
  

=
.
4.23 Let X  be a random variable with E X
 
1
=
 and var X
 
4
=
.  Find the following:
(a)  E 2X
4
–

 ;
(b)  E X2

 ;
(c)  E
2X
4
–

2

 .
4.24 A random variable X  has a uniform distribution over the interval 
a 2

–
a 2



  for 
some positive constant a .
(a)
Find the coefficient of skewness for X ;
(b)
Find the coefficient of kurtosis for X ;
(c)
Compare the results of (a) and (b) with the same quantities for a standard normal 
random variable.

Exercises    163
www.Academicpress.com
4.25 Suppose   is a random variable uniformly distributed over the interval 0 2 


.  
(a)
Find the PDF of Y



sin
=
.
(b)
Find the PDF of Z



cos
=
.
(c)
Find the PDF of W



tan
=
.
4.26 A random variable has a CDF given by 
(a)
Find the mean of X ;
(b)
Find the variance of X ;
(c)
Find the coefficient of skewness of X ;
(d)
Find the coefficient of kurtosis of X .
4.27 Find the variance and coefficient of skewness for a geometric random variable whose 
PMF is PN n
 
1
p
–

pn
=
, n
0 1 2 
  
=
.  Hint: You may want to use the results of 
Exercise 4.13.
4.28 Find the variance and coefficient of skewness for a Poisson random variable whose 
PMF is PM m


me 
–
m!
---------------
=
, m
0 1 2 
  
=
.  Hint: You may want to use the results of 
Exercise 4.14.
Section 4.5: Conditional Expected Values
4.29 Show that the concept of total probability can be extended to expected values. That is, if 
Ai
 
! , i
1 2 3  n
  

=
 is a set of mutually exclusive and exhaustive events, then
E X
 
E X Ak

Pr Ak


k
1
=
n
"
=
.
4.30 An exponential random variable has a PDF given by fX x
 
x
–

u x
 
exp
=
.
(a)
Find the mean and variance of X .
(b)
Find the conditional mean and the conditional variance given that X
1

.
FX x
 
0,
x
0,

x2,      0
x
1,


1,
x
1






=

164    Chapter 4
www.Academicpress.com
4.31 A uniform random variable has a PDF given by fX x
 
u x
 
u x
1
–


–
=
.
(a)
Find the mean and variance of X .
(b)
Find the conditional mean and the conditional variance given that 1
2---
X
3
4---


.
4.32 Consider a Gaussian random variable, X , with mean   and variance 2 .  
(a)
Find E X X


+


 .
(b)
Find E X X

–



 .
4.33 A professor is studying the performance of various student groups in his class.  Let the 
random variable X  represent a students final score in the class and define the following 
conditioning events:
•
F = {student is a freshman}
•
So = {student is a sophomore}
•
J = {student is a junior}
•
Se = {student is a senior}
•
M = {student is a male}
•
F = {student is a female}
(a)
Suppose the average score among males is E X M


73.2
=
 and the average score 
among females is E X F


75.8
=
.  If the overall class average score is 
E X
 
74.6
=
, what percentage of the class is female?
(b)
Suppose the conditional average scores by class are E X F


65.8
=
, 
E X So


71.2
=
, E X J


75.4
=
, E X Se


79.1
=
.  If the overall class average 
score is E X
 
72.4
=
, what can we say about the percentage of freshmen, 
sophomore, juniors and seniors in the class?
(c)
Given the class statistics in part (b). If it is known that there are 10 freshmen, 
12 sophomores, and 9 juniors in the class, how many seniors are in the class?
Section 4.6: Transformations of Random Variables
4.34 Suppose X  is uniformly distributed over 
a a

–

 , where a  is some positive constant.  
Find the PDF of Y
X2
=
.
4.35 Suppose X  is a random variable with an exponential PDF of the form 
fX x
 
2e 2x
–
u x
 
=
.  A new random variable is created according to the transformation 
Y
1
X
–
=
. 
(a)
Find the domain for X  and Y . 
(b)
Find fY y
  . 

Exercises    165
www.Academicpress.com
4.36 Let X  be a standard normal random variable (i.e., X
N 0 1




).  Find the PDF of 
Y
X
=
.
4.37 Repeat Exercise 4.36 if the transformation is 
Y
X,    X
0,

0,    X
0.




=
4.38 Suppose a random variable, X , has a Gaussian PDF with zero mean and variance X2 . The 
random variable is transformed by the device whose input–output relationship is shown in 
the accompanying figure. Find and sketch the PDF of the transformed random variable, Y . 
1
-1
2
-2
x
y
g x
 
=
4.39 Let X  be a Gaussian random variable with zero mean and arbitrary variance, 2 .  Given 
the transformation Y
X3
=
,  find fY y
  . 
4.40 A real number between 0 and l00 is randomly selected according to a uniform 
distribution and rounded off to the nearest integer. For example, 36.5001 is rounded off 
to 37; 3  is rounded off to 2; and 69.49 is rounded off to 69. Define a random variable 
to be X
number selected


nearest integer


–
=
. 
(a)
What is the domain of this random variable? 
(b)
Determine the PDF for X . 
(c)
Determine the mean square value of X .
4.41 A Gaussian random variable with zero mean and variance X2  is applied to a device that 
has only two possible outputs, 0 or 1. The output 0 occurs when the input is negative, 
and the output 1 occurs when the input is nonnegative. 
(a)
What is the probability mass function of the output? 
(b)
Rework the problem when X
1 2

=
 and X2
1
=
. 

166    Chapter 4
www.Academicpress.com
4.42 Let X  be a Cauchy random variable whose PDF is given by
fX x
 
b 

b2
x2
+
-----------------
=
Find the PDF of Y
1 X

=
.
4.43 Let X  be a Chi-square random variable with a PDF given by
fX x
 
xc
1
–
x 2

–

u x
 
exp
2c c
 
--------------------------------------------------
=
,
where c
n 2

=
 for any positive integer n .  Find the PDF of Y
X
=
.
4.44 Suppose a random variable has some PDF given by fX x
  .  Find a function g x
   such 
that Y
g X
 
=
 is a uniform random variable over the interval 0 1


 .  Next, suppose 
that X  is a uniform random variable.  Find a function g x
   such that Y
g X
 
=
 has 
some specified PDF, fY y
  .
4.45 Suppose X  is uniformly distributed over 0 1


 .  Using the results of Exercise 4.44, find 
transformations Y
g X
 
=
 to produce random variables with the following distributions:
(a)
Exponential,
(b)
Rayleigh,
(c)
Cauchy,
(d)
Geometric,
(e)
Poisson.
4.46 Suppose X  is a binomial random variable with parameters n  and p .  That is, the PMF 
of X  is given by
,  
.
Find the PMF of a new random variable generated through the transformation, Y
n
X
–
=
.
4.47 Suppose X  is a Gaussian random variable with mean X  and variance X2 .  Suppose we 
form a new random variable according to Y
aX
b
+
=
 for constants a  and b .  
(a)
Prove that Y  is also Gaussian for any a
0
#
.  
(b)
What values for the constants a  and b  will lead to the new random variable Y  
having zero mean and unit variance?
(c) 
What values for the constants a  and b  will lead to the new random variable Y   
having a mean of Y  and a variance of Y2 ?
PX k
 
n
k
	 
  pk 1
p
–

n
k
–
=
k
0 1 2  n
  

=

Exercises    167
www.Academicpress.com
4.48 The amplitude, A , of a received signal in a wireless communication system is often modelled
 as a Rayleigh random variable whose PDF is of the form, fA a
 
a
2
------
a2
22
---------
–
	


 u a
 
exp
=
.  
The (normalized) power of the same signal is given by P
A2
=
.  Find the PDF of P .
4.49 Suppose X  is an exponential random variable with PDF, fX x
 
x
–


exp
u x
 
=
. Find a 
transformation, Y
g X
 
=
 so that the new random variable Y  has a Cauchy PDF given 
by fY y
 
1 

1
x2
+
--------------
=
.  Hint: Use the results of Exercise 4.44.
Section 4.7:  Characteristic Functions
4.50 A random variable X  has a characteristic function, $X %

 .  Write the characteristic 
function of Y
aX
b
+
=
 in terms of $X %

  and the constants a  and b .  
4.51 Prove that the characteristic function of any random variable must satisfy the following 
properties.
(a)
$X* %


$X
%
–


=
.
(b)
$X 0
 
1
=
.
(c)
For real % , $X %


1

.
(d)
If the PDF is symmetric about the origin (i.e, an even function), then $X %

  is real.
(e)
$X %

  cannot be purely imaginary.
4.52 Suppose X  is an integer-valued random variable.  Show that in this case, $X 2n


1
=
 
for any integer, n .  Likewise, prove the reverse is also true.  That is, show that if 
$X 2n


1
=
 for any integer, n , the random variable X  must be integer-valued.
4.53 For a Laplace random variable whose PDF is given by fX x
 
1
2b
------
x
b-----
–
	



exp
=
, find the 
following:
(a)
the characteristic function, $X %

 ,
(b)
the Taylor series expansion of $X %

 ,
(c)
a general expression for the k th moment of X .
4.54 An Erlang Random variable has a PDF of the form fX x
 
bn
n
1
–

!
------------------xn
1
– e bx
–
u x
 
=
.  
(a)
Find the characteristic function, $X %

 .
(b)
Find the Taylor series expansion of $X %

 .
(c)
Find a general expression for the k th moment of X .

168    Chapter 4
www.Academicpress.com
4.55 A Cauchy random variable has a PDF fX x
 
b 

b2
x2
+
-----------------
=
.
(a)
Find the characteristic function, $X %

 .
(b)
Show that the derivatives dk
d%k
--------- $X %


(
)  do not exist at %
0
=
.  What does this 
mean?
4.56 A Poisson random variable has a PMF of the form PX k
 
k
k!
------

–


exp
=
,  
k
0 1 2 
  
=
.
(a)
Find the characteristic function, $X %

 .
(b)
Find the first three nonzero terms in the Taylor series expansion of 
$X %




ln
.
(c)
Use the results of part (b) to find the mean, variance, and skewness of the Poisson 
random variable.
4.57 A certain random variable has a characteristic function given by
.
Find the PDF of this random variable.
4.58 Which of the following functions could be the characteristic function of a random 
variable?  See Appendix E, Section 5 for definitions of these functions.
(a)
$a %


rect %


=
.
(b)
$b %


tri %


=
.
(c)
$c %


sinc %


=
.
(d)
$d %


sinc2 %


=
.
Section 4.8:  Probability-Generating Functions
4.59 Derive a formula expressing the variance of a random variable in terms of its factorial 
moments.
4.60 Derive a relationship between the k th factorial moment for a nonnegative, integer-
valued random variable and the coefficients of the Taylor series expansion of its 
probability-generating function, HX z  , about the point z
1
=
.
$X %


sin3 %


%

3
----------------------
=

Exercises    169
www.Academicpress.com
4.61 For a Poisson random variable whose PMF is given by PX k
 
k
k!
------e 
–
=
, 
k
0 1 2 
  
=
, find the following:
(a)
the probability-generating function, HX z  ,
(b)
the Taylor series expansion of HX z   about the point z
1
=
,
(c)
a general expression for the k th factorial moment.
4.62 A certain random variable has a probability-generating function given by
HX z 
1
n---1
zn
–
1
z
–
-------------
=
.
Find the PMF for this random variable.
4.63 Show that for any probability-generating function, H z  , H 1
 
1
=
.
4.64 Suppose HX z   is the probability-generating function of some random variable X  with 
PMF PX k
  . In terms of PX k
  , find the PMF of the random variable Y  if its 
probability-generating function is given as in each of the following cases.
(a)
HY z 
HX z
2---
	 
 
=
.
(b)
HY z 
HX2 z 
=
.
(c)
HY z 
zmHX z 
=
.
(d)
HY z 
HX z 1
–


=
.
Section 4.9:  Moment-Generating Functions
4.65 Derive an expression for the moment-generating function of a Rayleigh random 
variable whose PDF is 
fX x
 
x
x2
2-----
–
	



exp
u x
 
=
.
4.66 Suppose X  is a Rician random variable with a PDF given by
fX x
 
x
x2
a2
+
2
-----------------
–
	



exp
Io ax

u x
 
=
.
Derive an expression for E euX2

 .  Note that this is not quite the moment-generating 
function, but it can be used in a similar way.

170    Chapter 4
www.Academicpress.com
4.67 A Gaussian mixture is a random variable whose PDF is a linear combination of two 
Gaussian PDFs,
.
(a)
Find the moment-generating function, MX u
  , of the Gaussian mixture.
(b)
Use the moment-generating function to find the mean of the Gaussian mixture.
4.68 A random variable has a moment-generating function given by
.
(a)
Find the PDF of the random variable.
(b)
Use the moment-generating function to find an expression for the k th moment of 
the random variable.
4.69 Consider a moment-generating function of the general form
,
for constants a , b , and c .  Find constraints that the constants a , b , and c  must satisfy 
so that MX u
   is the MGF of a valid random variable.
4.70 Prove the following properties of moment-generating functions.
(a)
MX 0
 
1
=
.
(b)
For a nonnegative random variable X , and for real u
0

, MX u
 
1

.
4.71 Find the mean of the random variable whose  moment-generating function is
.
Section 4.10:  Evaluating Tail Probabilities
4.72 Prove that for a random variable X  with mean X ,
Pr X
X
–
&



E X
X
–
n


&n
------------------------------

,
where n  is any positive integer.
fX x
 
p
212
-----------------
x
1
–

2
212
---------------------
–
	



exp
1
p
–
222
-----------------
x
2
–

2
222
---------------------
–
	



exp
+
=
MX u
 
2
1
u
–

 2
u
–


----------------------------------
=
MX u
 
c
au2
bu
c
+
+
------------------------------
=
MX u
 
6
1
u
–

2 2
u
–

 3
u
–


-----------------------------------------------------
=

Exercises    171
www.Academicpress.com
4.73 Suppose we are interested in finding the left tail probability for a random variable, X .  
That is, we want to find Pr X
xo


 .  Rederive an expression for the Chernoff bound 
for the left tail probability.
4.74 Suppose X  is a Poisson random variable with PMF, PX k
 
k
k!
------

–


exp
=
, 
k
0 1 2 
  
=
.  Find the Chernoff bound for the tail probability, Pr X
no


 .
4.75 Suppose X  is a Gamma random variable with PDF, 
fX x
 
x b


c
1
–
x b

–


exp
b c
 
---------------------------------------------------u x
 
=
.  Find the Chernoff bound for the tail probability, 
Pr X
xo


 .
4.76 Let X  be an Erlang random variable with PDF, fX x
 
xn
1
– e x
– u x
 
n
1
–

!
------------------------------
=
.  Derive a saddle 
point approximation for the left tail probability, Pr X
xo


 .  Compare your result with 
the exact value for 0
xo
E X
 


.  
4.77 In Exercise 4.66, an expression was derived for E euX2

  for a Rician random variable.  
Use this function to obtain a saddle point approximation for the tail probability of a 
Rician random variable, Pr X
xo


 .  
Hint: For one-sided random variables, Pr X
xo



Pr X2
xo2



=
.
4.78 The average number of cars per hour arriving at a toll booth is 57 while the standard 
deviation is 15.  
(a)
Use Markov’s inequality to find an upper bound on the probability of having more 
than 200 cars arrive in an hour.
(b)
Use Chebyshev’s inequality to find an upper bound on the probability of having 
more than 200 cars arrive in an hour.
4.79 In a certain communication system, bits are encoded into blocks of length 128 bits.  
Error correction techniques are used such that the block will be decoded correctly as 
long as no more than 7 of the 128 bits are received in error.  We observe that 2% of our 
blocks are decoded incorrectly.  From Markov’s inequality, what can we say about the 
average number of bit errors that occur in each 128 bit block?
4.80 A nonnegative random variable X  has moments which are known to be E X
 
1
=
, 
E X2


2
=
, E X3


5
=
, E X4


9
=
, E X5


14
=
, E X6


33
=
.  
(a)
Show that for any nonnegative random variable, Pr X
x0



E Xn


xon
---------------

.

172    Chapter 4
www.Academicpress.com
(b)
Using the result of part (a) and the values of the moments given, find the tightest 
bound on Pr X
2


 .
(c)
Using the result of part (a) and the values of the moments given, find the tightest 
bound on Pr X
3


 .
4.81 Since the Q-function represents the tail probability of a Gaussian random variable, we 
can use the various bounds on tail probabilities to produce bounds on the Q-function.
(a)
Use Markov’s inequality to produce an upper bound on the Q-function.  Hint: a 
Gaussian random variable has a two-sided PDF, and Markov’s inequality requires 
the random variable to be one-sided.  You will need to work with absolute values to 
resolve this issue.
(b)
Use Chebyshev’s inequality to produce an upper bound on the Q-function.
(c) 
Plot your results from parts (a) and (b) along with the bound obtained from the 
Chernoff bound from Example 4.28.  In order to determine how tight (or loose) these 
various bounds are, also include on your plot the exact value of the Q-function.  
Section 4.11:  Scalar Quantization
4.82 Consider a quantizer that is designed to minimize the mean square quantization error.  
That is, the quantization levels, yi , are chosen according to the conditional mean 
criterion and the bin edges, xi , are chosen according to the midpoint criterion.  Show 
that the distortion is given by
d
E
X
q X
 
–

2


E X2


piyi2
i
1
=
M
"
–
=
=
,
and therefore the SQNR can be written as 
SQNR
E X2


d
---------------
1
piyi2
i
1
=
M
"
E X2


-------------------
–
	

'
(
'
(
'
(
'
(
'
(
'
(


1
–
=
=
.
4.83 Following the lead of Example 4.30, design an optimum 2-bit quantizer for  a signal 
whose samples follow a triangular PDF, 
fX x
 
1
x
–
, x
1,

0,
x
1.




=

Exercises    173
www.Academicpress.com
(a)
Find the four quantization levels, y1 y2 y3 y4



 
! , and the three boundary points, 
x1 x2 x3


 
! .
(b)
Find the mean-squared distortion, d .
(c)
Find the signal-to-quantization-noise ratio in dB.
Section 4.12:  Entropy and Source Coding
4.84 Suppose a source sends symbols from a three letter alphabet with X
a b c
 
 
!
)
 and 
pa
1 2

=
, pb
1 4

=
, pc
1 4

=
 are the source symbol probabilities.  
(a)
Determine the entropy of this source.
(b)
Give a source code that has an average codeword length that matches the entropy. 
4.85 Suppose a random variable, X , has N
2n
=
 equally likely outcomes.  What is the 
entropy of X  in bits?
4.86 Suppose a fair coin is flipped n  times and the random variable Y  counts the number of 
times heads occurs. What is the entropy of Y  in bits? Compare your answer to that of 
Exercise 4.85 and explain any difference.
4.87 Consider an N -letter source with probabilities, pi , i
1 2 3  N
  

=
.  The entropy of 
the source is given by H p
 
pi
pi


log
i
1
=
N
"
–
=
.  Prove that the discrete distribution that 
maximizes the entropy is a uniform distribution.  Hint: You need to perform a 
constrained optimization since the source probabilities must form a valid probability 
mass function, and thus p1
p2

pN
+
+
+
1
=
.
4.88 Consider a geometric random variable, Z , whose PMF is PZ k
 
1
p
–

pk
=
, 
k
0 1 2 
  
=
.  Find the entropy of this random variable as a function of p .  
Miscellaneous Exercises
4.89 Imagine that you are trapped in a circular room with three doors symmetrically placed 
around the perimeter. You are told by a mysterious voice that one door leads to the 
outside after a 2-h trip through a maze. However, the other two doors lead to mazes that 
terminate back in the room after a 2-h trip at which time you are unable to tell through 

174    Chapter 4
www.Academicpress.com
which door you exited or entered. What is the average time for escape to the outside? 
Can you guess the answer ahead of time? If not, can you provide a physical explanation 
for the answer you calculate?
4.90 A communication system sends data in the form of packets of fixed length.  Noise in the 
communication channel may cause a packet to be received incorrectly. If this happens, 
then the packet is retransmitted. Let the probability that a packet is received incorrectly 
be q . Determine the average number of transmissions that are necessary before a packet 
is received correctly. 
4.91 In Exercise 4.90 let the transmission time be Tt  seconds for a packet.  If the packet was 
received incorrectly, then a message is sent back to the transmitter that states that the 
message was received incorrectly. Let the time for sending such a message be Ti . 
Assume that if the packet is received correctly that we do not send an acknowledgement. 
What is the average time for a successful transmission?
4.92 Use the characteristic function (or the moment-generating function or the probability-
generating function) to show that a Poisson PMF is the limit of a binomial PMF with n  
approaching infinity and p  approaching zero in such a way that np

constant
=
=
. 
MATLAB Exercises
4.93 Let X  be a random variable that is uniformly distributed over the interval 0 100


 .  
Form a new random variable Y  by rounding X  to the nearest integer.  In MATLAB 
code, this could be represented by Y=round(X).  Finally, form the random roundoff 
error according to Z
X
Y
–
=
.  
(a) 
Using analytical methods, find the PDF of Z  as well as the mean-squared value, 
E Z2

 .
(b) Using MATLAB, create a histogram for the probability densities for the random 
variable Z . Compare with the PDF found analytically in part (a).
4.94 Suppose you have a random variable X  with PDF, fX x
 
2x u x
 
u x
1
–


–


=
 and 
that this random variable is transformed as Y
2
X
–
=
.  Calculate fY y
  .  Repeat 
this problem using MATLAB.  Compare the estimate of the PDF from MATLAB 
with the analytically determined PDF.  Note that for this problem there is no function 
in MATLAB that provides a sequence of data samples that has the PDF specified in 
this problem for X .  Thus you must find an appropriate way to transform a uniform 
random variable to produce the desired X .  The results of Exercise 4.44 will be 
helpful here.

Exercises    175
www.Academicpress.com
4.95 Use MATLAB to generate a large number of samples from a Gaussian distribution 
with mean 
20
=
 and variance 
4
=
.  Hint: the MATLAB command 
sigma*randn(1,N)+mu will create N such numbers with mean mu and standard deviation 
sigma.  Let x1 x2  xN



 represent the samples you generated.  Compute each of the 
following “mean” values:
(a)
Sample mean, ˆ sm
1
N----
xk
k
1
=
N
"
=
;
(b)
Geometric mean, ˆ gm
xk
k
1
=
N
*
	

'
(
'
(

 1 N

=
;
(c)
Harmonic mean, ˆ hm
1
N----
1
xk
----
k
1
=
N
"
	

'
(
'
(

 1
–
=
;
(d) Quadratic mean (root mean square), ˆ qm
1
N----
xk2
k
1
=
N
"
=
.
Which of these “estimates” give a decent estimate of the true mean?
4.96 Write a MATLAB program to simulate the problem described in Exercise 4.89.  
Estimate the average time until escape. Do your MATLAB results agree with your 
analytically determined results in Exercise 4.89?
4.97 Copy a segment of text into MATLAB as a string (you choose the source of the text).  
Then write a MATLAB program to count the relative frequency of each character 
(ignore all characters that do not correspond to one of the 26 letters and do not make a 
distinction between upper and lower case). Using the results of your program, calculate 
the entropy of a source that outputs the 26 English characters with the probabilities you 
calculated.
4.98 Suppose a random variable has a PDF given by 
fX x
 
1+x,        1
x
0,


–
1
x,
–
     0
x

1,

0,
x
1.






=
Following the procedure laid out in Example 4.31, write a MATLAB program to design 
an optimum 4-bit (16 level) quantizer for this random variable. Compute the SQNR in 
decibels of the quantizer you designed. How does this SQNR compare with that obtained 
in Example 4.31. Can you explain any differences?

177
CHAPTER 5
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00005-X
© 2012 by Elsevier Inc. All rights reserved.
Pairs of Random Variables
The previous two chapters dealt with the theory of single random variables. However, many 
problems of practical interest require the modeling of random phenomenon using two or 
maybe even more random variables. This chapter extends the theory of Chapters 3 and 4 to 
consider pairs of random variables. Chapter 6 then generalizes these results to include an 
arbitrary number of random variables. A common example that involves two random variables 
is the study of a system with a random input. Due to the randomness of the input, the output 
will naturally be random as well. Quite often it is necessary to characterize the relationship 
between the input and the output. A pair of random variables can be used to characterize this 
relationship: one for the input and another for the output. 
Another class of examples involving random variables are those involving spatial coordinates 
in two dimensions. A pair of random variables can be used to probabilistically describe the 
position of an object which is subject to various random forces. There are endless examples of 
situations where we are interested in two random quantities that may or may not be related to 
one another, for example, the height and weight of a student, or the grade point average and 
GRE scores of a student, or the temperature and relative humidity at a certain place and time.
To start with, consider an experiment 
 whose outcomes lie in a sample space, . A two-
dimensional random variable is a mapping of the points in the sample space to ordered pairs 
. Usually, when dealing with a pair of random variables, the sample space naturally 
partitions itself so that it can be viewed as a combination of two simpler sample spaces. For 
example, suppose the experiment was to observe the height and weight of a typical student. The 
range of student heights could fall within some set which we call sample space 
, while the 
range of student weights could fall within the space 
. The overall sample space of the 
experiment could then be viewed as 
. For any outcome 
 of this experiment, the 
pair of random variables 
 is merely a mapping of the outcome  to a pair of numerical 
values 
. In the case of our height/weight experiment, it would be natural to choose 
 to be the height of the student (in inches perhaps), while 
 is the weight of the student 
(in pounds). Note that it is probably not sufficient to consider two separate experiments, one 
where the student’s height is measured and assigned to the random variable 
 and another where 
a student’s weight is measured and assigned to the random variable 
.  
While the density functions 
 and 
 do partially characterize the experiment, they 
do not completely describe the situation. It would be natural to expect that the height and 
E
S
x y



S1
S2
S
S1
S2

=
s
S

X Y



s
x s  y s 



x s 
y s 
X
Y
fX x
 
fY y
 

178    Chapter 5
www.Academicpress.com
weight are somehow related to each other. While it may not be very rare to have a student 74 
in. tall nor unusual to have a student who weighs 120 pounds, it is probably rare indeed to have 
a student who is both 74 in. tall and weighs 120 pounds. A careful reading of the wording in 
the previous sentence makes it clear that in order to characterize the relationship between a 
pair of random variables, it is necessary to look at the joint probabilities of events relating to 
both random variables. We accomplish this through the joint cumulative distribution function 
(CDF) and the joint probability density function (PDF) in the next two sections.
5.1  Joint Cumulative Distribution Functions
When introducing the idea of random variables in Chapter 3, we started with the notion of a 
CDF. In the same way, to probabilistically describe a pair of random variables, 
, we 
start with the notion of a joint CDF.
Definition 5.1: The joint CDF of a pair of random variables, 
, is
. That is, the joint CDF is the joint probability of the two
events 
 and 
.
As with the CDF of a single random variable, not any function can be a joint CDF. The joint 
CDF of a pair of random variables will satisfy properties similar to those satisfied by the CDFs of 
single random variables. First of all, since the joint CDF is a probability, it must take on a value 
between 0 and 1. Also, since the random variables 
 and 
 are real valued, it is impossible for 
either to take on a value less than 
 and both must be less than . Hence, 
 
evaluated at either 
 or 
 (or both) must be zero and 
 must be one. 
Next, for 
 and 
, 
 is a subset of 
 so that 
. That is, the CDF is a monotonic, nondecreasing function of both  
and . Note that since the event 
 must happen, then 
 so 
that 
. Likewise, 
. In the context of joint CDFs, 
 
and 
 are referred to as the marginal CDFs of 
 and 
, respectively.  
Finally, consider using a joint CDF to evaluate the probability that the pair of random 
variables 
 falls into a rectangular region bounded by the points 
, 
, 
, and 
. This calculation is illustrated in Figure 5.1. The desired rectangular 
region is the lightly shaded area. Evaluating 
  gives the probability that the 
random variable falls anywhere below or to the left of the point 
; this includes all of 
the area in the desired rectangle, but it also includes everything below and to the left of the 
desired rectangle. The probability of the random variable falling to the left of the rectangle can 
be subtracted off using 
. Similarly, the region below the rectangle can be 
subtracted off using 
; these are the two medium-shaded regions in Figure 5.1. In 
subtracting off these two quantities, we have subtracted twice the probability of the pair falling 
both below and to the left of the desired rectangle (the dark-shaded region). Hence we must 
X Y



X Y



FX Y

x y



Pr X
x
	
Y
y
	



=
X
x
	


Y
y
	


X
Y

–

FX Y

x y



x

–
=
y

–
=
FX Y


 



x1
x2
	
y1
y2
	
X
x1
	


Y
y1
	



X
x2
	


Y
y2
	



FX Y

x1 y1



FX Y

x2 y2



	
x
y
X

	




X

	


Y
y
	



Y
y
	


=
FX Y


 y



FY y
 
=
FX Y

x 



FX x
 
=
FX x
 
FY y
 
X
Y
X Y



x1 y1



x2 y1



x1 y2



x2 y2



FX Y

x2 y2



x2 y2



FX Y

x1 y2



FX Y

x2 y1




Pairs of Random Variables    179
www.Academicpress.com
add back this probability using 
. All of these properties of joint CDFs are 
summarized as follows:
(1)
;
(5.1a)
(2)
;
(5.1b)
(3)
;
(5.1c)
(4)
,  
;
(5.1d)
(5)
(5.1e)
With the exception of property (4), all of these properties are analogous to the ones listed in 
Equation (3.3) for CDFs of single random variables.  
Property (5) tells us how to calculate the probability of the pair of random variables falling in a 
rectangular region. Often, we are interested in also calculating the probability of the pair of 
random variables falling in a region which is not rectangular (e.g., a circle or triangle). This 
can be done by forming the required region using many infinitesimal rectangles and then 
repeatedly applying property (5). In practice, however, this task is somewhat overwhelming, 
and hence we do not go into the details here.  
FX Y

x1 y1



FX Y


–

–



FX Y


–
y



FX Y

x

–



0
=
=
=
FX Y


 



1
=
0
FX Y

x y



1
	
	
FX Y

x 



FX x
 
=
FX Y


 y



FY y
 
=
Pr x1
X1
x2
	

y1
Y1
y2
	




FX Y

x2 y2



FX Y

x1 y2



FX Y

x2 y1



–
–
FX Y

x1 y1



+
0.

=
(x2, y2)
(x2, y1)
(x1, y2)
(x1, y1)
Figure 5.1 
Illustrating the evaluation of the probability of a pair of random variables 
falling in a rectangular region.

180    Chapter 5
www.Academicpress.com
Example 5.1:
One of the simplest examples (conceptually) of a pair of random variables is one which 
is uniformly distributed over the unit square (i.e., 
, 
). The CDF of such 
a random variable is
Even this very simple example leads to a rather cumbersome function. Nevertheless, it is 
straightforward to verify that this function does indeed satisfy all the properties of a 
joint CDF. From this joint CDF, the marginal CDF of  can be found to be
Hence, the marginal CDF of  is also a uniform distribution. The same statement holds 
for  as well.
5.2 Joint Probability Density Functions
As seen in Example 5.1, even the simplest joint random variables can lead to CDFs which are 
quite unwieldy. As a result, working with joint CDFs can be difficult. In order to avoid extensive 
use of joint CDFs, attention is now turned to the two dimensional equivalent of the PDF.  
Definition 5.2: The joint probability density function of a pair of random variables
 evaluated at the point 
 is 
.
(5.2)
Similar to the one-dimensional case, the joint PDF is the probability that the pair of
random variables 
 lies in an infinitesimal region defined by the point 
normalized by the area of the region.
For a single random variable, the PDF was the derivative of the CDF. By applying Equation 
(5.1e) to the definition of the joint PDF, a similar relationship is obtained.
0
x
1
 
0
y
1
 
FX Y
x y



0,
x
0 or y
0,      


x,
0
x
1 y
1,    


	 	
y,
x
1

0
y
1,    
	 	

xy,
0
x
1 0
y
1,
	 	

	 	
1,
x
1 y
1.          










=
X
FX x
 
FX Y

x 



0,
x
0,     

x,
0
x
1,
	 	
1,
x
1.      






=
=
X
Y
X Y



x y



fX Y

x y



Pr x
X
x
x
+

	
y
Y
y
y
+

	



xy
------------------------------------------------------------------------
x
0

y
0


lim
=
X Y



x y






Pairs of Random Variables    181
www.Academicpress.com
Theorem 5.1: The joint PDF 
 can be obtained from the joint CDF
 by taking a partial derivative with respect to each variable. That is,
.
(5.3)
Proof: Using Equation (5.1e),
(5.4)
Dividing by 
 and taking the limit as 
 results in
  (5.5)
Then dividing by 
 and taking the limit as 
 gives the desired result:
(5.6)
This theorem shows that we can obtain a joint PDF from a joint CDF by differentiating with 
respect to each variable. The converse of this statement would be that we could obtain a joint 
CDF from a joint PDF by integrating with respect to each variable. Specifically,
.
(5.7)
fX Y

x y



FX Y
x y



fX Y
x y



x y

2


FX Y
x y



=
Pr x
X
x
x
+

	
y
Y
y
y
+

	



FX Y

x
x
+
y
y
+



FX Y

x y
y
+



–
FX Y

x
x
+
y



–
FX Y

x y



+
FX Y

x
x
+
y
y
+



FX Y

x y
y
+



–


FX Y

x
x
+
y



FX Y

x y



–

.
–
=
=
x
x
0

Pr x
X
x
x
+

	
y
Y
y
y
+

	



x
------------------------------------------------------------------------
x
0

lim
FX Y

x
x
+
y
y
+



FX Y

x y
y
+



–
x
-------------------------------------------------------------------------------------
x
0

lim
FX Y

x
x
+
y



FX Y

x y



–
x
----------------------------------------------------------------
x
0

lim
–
x

 FX Y

x y
y
+



x

 FX Y

x y


.
–
=
=
y
y
0

fX Y

x y



Pr x
X
x
x
+

	
y
Y
y
y
+

	



xy
------------------------------------------------------------------------
x
0

y
0


lim
x

 FX Y

x y
y
+



x

 FX Y

x y



–
y
----------------------------------------------------------------------------
y
0

lim
x y

2


FX Y

x y


.
=
=
=
FX Y

x y



fX Y

u v


 u
d
v
d

–
x


–
y

=

182    Chapter 5
www.Academicpress.com
Example 5.2:
From the joint CDF given in Example 5.1, it is found (by differentiating the joint CDF 
with respect to both  and ) that the joint PDF for a pair of random variables 
uniformly distributed over the unit square is
Note how much simpler the joint PDF is to specify than is the joint CDF.
From the definition of the joint PDF in Equation (5.2) as well as the relationships specified in 
Equations (5.3) and (5.7), several properties of joint PDFs can be inferred. These properties 
are summarized as follows:
(1)
;
(5.8a)
(2)
;
(5.8b)
(3)
;
(5.8c)
(4)
;
(5.8d)
(5)
,   
;
(5.8e)
(6)
. 
(5.8f)
Property (1) follows directly from the definition of the joint PDF in Equation (5.2) since both the 
numerator and denominator there are nonnegative. Property (2) results from the relationship in 
Equation (5.7) together with the fact that 
. This is the normalization integral for 
joint PDFs. These first two properties form a set of sufficient conditions for a function of two 
variables to be a valid joint PDF. Properties (3) and (4) have already been developed.  Property 
(5) is obtained by first noting that the marginal CDF of 
 is 
. Using 
Equation (5.7) then results in 
. Differentiating this expression 
with respect to  produces the expression in property (5) for the marginal PDF 
x
y
fX Y

x y



1,
0
x
1
 
0
y
1,
 

0,
otherwise.               



=
fX Y

x y



0

fX Y

x y


 x
d
y
d

–



–


1
=
FX Y

x y



fX Y

u v


 u
d
v
d

–
x


–
y

=
fX Y

x y



x y

2


FX Y

x y



=
fX x
 
fX Y

x y


 y
d

–


=
fY y
 
fX Y

x y


 x
d

–


=
Pr x1
X1
x2
	

y1
Y1
y2
	




fX Y

x y


 x
d
y
d
x1
x2
y1
y2
=
FX Y


 



1
=
X
FX x
 
FX Y

x 



=
FX x
 
fX Y

u y


 u
d
y
d

–
x

–


=
x



Pairs of Random Variables    183
www.Academicpress.com
of . A similar derivation produces the marginal PDF of . Hence, the marginal PDFs are 
obtained by integrating out the unwanted variable in the joint PDF. The last property is 
obtained by combining Equations (5.1e) and (5.7). 
Example 5.3:
Suppose two random variables are jointly uniformly distributed over the unit circle. That 
is, the joint PDF 
 is constant anywhere such that 
:
The constant  can be determined using the normalization integral for joint PDFs:
.
The marginal PDF of  is found by integrating  out of the joint PDF:
, for 
.
By symmetry, the marginal PDF of  would have the same functional form:
, for 
.
Although  and  were jointly uniformly distributed, the marginal distributions are not 
uniform. Stated another way, suppose we are given just the marginal PDFs of  and  as 
just specified. This information alone is not enough to determine the joint PDF. One may 
be able to form many joint PDFs that produce the same marginal PDFs. For example, 
suppose we form
It is easy to verify that this is a valid joint PDF and leads to the same marginal PDFs. Yet, 
this is clearly a completely different joint PDF than the uniform distribution with which 
we started. This reemphasizes the need to specify the joint distributions of random 
variables and not just their marginal distributions.
x
y
fX Y

x y



x2
y2
+
1

fX Y

x y



c,
x2
y2
+
1,

0,
otherwise.  



=
c
c x
d
y
d

x2
y2
+
1


1
c

1
---
=
=
X
y
fX x
 
fX Y

x y


 y
d

–


1
--- y
d
1
x2
–
–
1
x2
–

2
--- 1
x2
–
=
=
=
1
x
1
	 	
–
Y
fY y
 
2
--- 1
y2
–
=
1
y
1
	 	
–
X
Y
X
Y
fX Y

x y



4
2
-----
1
x2
–

 1
y2
–

,
1
x
1
1
y
1,
	 	
–

	 	
–
0,                                 
otherwise.                 





=



184    Chapter 5
www.Academicpress.com
Property (6) of joint PDFs given in Equation (5.8f) specifies how to compute the probability that 
a pair of random variables takes on a value in a rectangular region. Often, we are interested in 
computing the probability that the pair of random variables falls in a region which is not 
rectangularly shaped. In general, suppose we wish to compute 
, where 
 is the 
region illustrated in Figure 5.2. This general region can be approximated as a union of many 
nonoverlapping rectangular regions as shown in the figure. In fact, as we make the rectangles 
ever smaller, the approximation improves to the point where the representation becomes exact in 
the limit as the rectangles get infinitely small. That is, any region can be represented as an 
infinite number of infinitesimal rectangular regions so that 
, where 
 represents the 
ith rectangular region. The probability that the random pair falls in 
 is then computed as
.
(5.9)
The sum of the integrals over the rectangular regions can be replaced by an integral over the 
original region 
:
.
(5.10)
This important result shows that the probability of a pair of random variables falling in some 
two-dimensional region A is found by integrating the joint PDF of the two random variables 
over the region A.
Pr
X Y



A



A
A
Ri

=
Ri
A
x
y
Figure 5.2  
Approximation of an arbitrary region by a series of infinitesimal rectangles.
Pr
X Y



A



Pr
X Y



Ri



i
fX Y

x y


 x
d
y
d

Ri
i
=
=
A
Pr
X Y



A



fX Y

x y


 x
d
y
d

A
=

Pairs of Random Variables    185
www.Academicpress.com
Example 5.4:
 Suppose a pair of random variables has the joint PDF given by
.
The probability that the point 
 falls inside the unit circle is given by
.
Converting this integral to polar coordinates results in
.
Example 5.5:
Now suppose that a pair of random variables has the joint PDF given by
.
First, the constant c is found using the normalization integral
.
Next, suppose we wish to determine the probability of the event 
. This can be 
viewed as finding the probability of the pair 
 falling in the region A that is now 
defined as 
. This probability is calculated as
.
Example 5.6:
In many cases, evaluating the probability of a pair a random variables falling 
in some region may be quite difficult to calculate analytically. For example, 
suppose we modify Example 5.4 so that the joint PDF is now of the form
.
Again, we would like to evaluate the probability that the pair 
 falls in the unit 
circle. To do this analytically we must evaluate
(Continued)
fX Y

x y



1
2
------
x2
y2
+
2
---------------
–



 
exp
=
X Y



Pr X2
Y2
+
1



1
2
------
x2
y2
+
2
---------------
–



 
exp
x
d
y
d

x2
y2
+
1

=
Pr X2
Y2
+
1



r
2
------
r2
2----
–



 
exp
r
d
!
d
0
1

0
2

r
r2
2----
–



 
exp
r
d
0
1

r2
2----
–



 
exp
–
0
1
1
1
2---
–



 
exp
–
=
=
=
=
fX Y

x y



c
x
–
y
2---
–



 u x
 u y
 
exp
=
c
x
–
y
2---
–



 
exp
x
d
y
d
0


0


1
=
c

1
2---
=
X
Y



X Y



A
x y


:x
y



=
Pr X
Y



fX Y

x y


 x
d
y
d

x
y

1
2---
x
–
y
2---
–



 
exp
x
d
y
d
y


0


1
2---
3y
2-----
–



 
exp
y
d
0


1
3---
=
=
=
=
fX Y
x y



1
2
------
x
2
–

2
y
3
–

2
+


2
---------------------------------------------
–



 
exp
=
X Y









186    Chapter 5
www.Academicpress.com
.
Converting to polar coordinates the integral becomes
.
Either way the double integral looks formidable. We can enlist MATLAB to help in one of 
two ways. First, we could randomly generate many samples of the pair of random 
variables according to the specified distribution and count the relative frequency of the 
number that falls within the unit circle. Alternatively, we can get MATLAB to calculate 
one of the preceding double integrals numerically. We will take the latter approach here 
and evaluate the double integral in polar coordinates. First, we must define a MATLAB 
function to evaluate the integrand:
function out=dblintegrand(q,r)
out=r.*exp(-((r*cos(q)-2).^2+(r*sin(q)-3).^2)/2);
MATLAB will then evaluate the integral by executing the command
dblquad('dblintegrand',0,2*pi,0,1)/(2*pi).
By executing these MATLAB commands, we find the value of the integral to be 0.002072.
5.3  Joint Probability Mass Functions
When the random variables are discrete rather than continuous, it is often more convenient to 
work with probability mass functions (PMFs) rather than PDFs or CDFs. It is straightforward 
to extend the concept of the PMF to a pair of random variables.
Definition 5.3: The joint PMF for a pair of discrete random variables 
 and 
 is
given by 
.
In particular, suppose the random variable 
 takes on values from the set 
 
and the random variable 
 takes on values from the set 
. Here, either M or N 
could be potentially infinite, or both could be finite. Several properties of the joint PMF 
analogous to those developed for joint PDFs should be apparent.
(1)
;
(5.11a)
(2)
;
(5.11b)
1
2
------
x
2
–

2
y
3
–

2
+


2
---------------------------------------------
–



 
exp
x
d
y
d
x2
y2
+
1


r
2
------
r
!
 
cos
2
–

2
r
!
 
sin
3
–

2
+


2
-----------------------------------------------------------------------------
–



 
exp
!
d
r
d
0
2

0
1

X
Y
PX Y

x y



Pr
X= x


Y = y





=
X
x1 x2 " xM





Y
y1 y2 " yN





0
P
	
X Y

xm yn



1
	
PX Y

xm yn



n
1
=
N

m
1
=
M

1
=


Pairs of Random Variables    187
www.Academicpress.com
(3)
,  
;
(5.11c)
(4)
.
(5.11d)
Furthermore, the joint PDF or the joint CDF of a pair of discrete random variables can be 
related to the joint PMF through the use of delta functions or step functions by
,
(5.12)
.
(5.13)
Usually, it is most convenient to work with PMFs when the random variables are discrete.  
However, if the random variables are mixed (i.e., one is discrete and one is continuous), then it 
becomes necessary to work with PDFs or CDFs since the PMF will not be meaningful for the 
continuous random variable.
Example 5.7:
Two discrete random variables N and M have a joint PMF given by
,  
 
.
The marginal PMF of N can be found by summing over m in the joint PMF:
.
To evaluate this series, the following identity is used: 
.
The marginal PMF then reduces to
(Continued)
PX Y

xm yn



n
1
=
N

PX xm


=
PX Y

xm yn



m
1
=
M

PY yn


=
Pr
X Y



A



PX Y

x y




x y



A


=
fX Y
x y



PX Y
xm yn


# x
xm
–

# y
ym
–


n
1
=
N

m
1
=
M

=
FX Y
x y



PX Y
xm yn


u x
xm
–

u y
ym
–


n
1
=
N

m
1
=
M

=
PN M

n m



n
m
+

!
n!m!
-------------------
anbm
a
b
1
+
+

n
m
1
+
+
-----------------------------------------
=
m
0 1 2 3 "
   

=
n
0 1 2 3 "
   
=
PN n
 
PN M

n m



m
0
=


n
m
+

!
n!m!
-------------------
anbm
a
b
1
+
+

n
m
1
+
+
-----------------------------------------
m
0
=


=
=
n
m
+

!
n!m!
-------------------xm
m
0
=


1
1
x
–
----------



 n
1
+
=


188    Chapter 5
www.Academicpress.com
.
Likewise, by symmetry, the marginal PMF of M is 
.
Hence, the random variables M and N both follow a geometric distribution.
5.4  Conditional Distribution, Density, and Mass Functions
The notion of conditional distribution functions and conditional density functions was first 
introduced in Chapter 3. In this section, those ideas are extended to the case where the 
conditioning event is related to another random variable. For example, we might want to know 
the distribution of a random variable representing the score a student achieves on a test given 
the value of another random variable representing the number of hours the student studied for 
the test. Or, perhaps we want to know the probability density function of the outside 
temperature given that the humidity is known to be below 50%.
To start with, consider a pair of discrete random variables X and Y with a PMF, 
. 
Suppose we would like to know the PMF of the random variable X given that the value of Y 
has been observed. Then, according to the definition of conditional probability
.
(5.14)
We refer to this as the conditional PMF of X given Y. By way of notation we write 
.
Example 5.8:
Using the joint PMF given in Example 5.7 along with the marginal PMF found in that 
example, it is found that
.
Note that the conditional PMF of N given M is quite different than the marginal PMF 
of N. That is, knowing M changes the distribution of N.
The simple result developed in Equation (5.14) can be extended to the case of continuous 
random variables and PDFs. The following theorem shows that the PMFs in (5.14) can simply 
be replaced by PDFs.
PN n
 
an
a
b
1
+
+

n
1
+
---------------------------------
n
m
+

!
n!m!
-------------------
bm
a
b
1
+
+

m
----------------------------
m
0
=


an
a
b
1
+
+

n
1
+
---------------------------------
1
1
b
a
b
1
+
+
-------------------
–
----------------------------


$
%
$
%

 n
1
+
an
1
a
+

n
1
+
-------------------------
=
=
=
PM m


bm
1
b
+

m
1
+
--------------------------
=
PX Y

x y



Pr X=x Y=y


Pr X=x Y=y



Pr Y = y


--------------------------------
PX Y

x y



PY y
 
------------------------
=
=
PX Y x y


PX Y

x y


 PY y
 
&
=
PN M n m


PM N

m n



PM m


---------------------------
n
m
+

!
n!m!
-------------------
anbm
a
b
1
+
+

n
m
1
+
+
----------------------------------------- 1
b
+

m
1
+
bm
--------------------------
n
m
+

!
n!m!
-------------------
an 1
b
+

m
1
+
a
b
1
+
+

n
m
1
+
+
-----------------------------------------
=
=
=




Pairs of Random Variables    189
www.Academicpress.com
Theorem 5.2: The conditional PDF of a random variable X given that Y = y is
.
(5.15)
Proof: Consider the conditioning event 
. Then
.
Passing to the limit as 
, the event A becomes the event 
, producing
the desired result.
Integrating both sides of this equation with respect to x produces the appropriate result for CDFs:
.
(5.16)
Usually, the conditional PDF is much easier to work with, so the conditional CDF will not be 
discussed further.
Example 5.9:
A certain pair of random variables has a joint PDF given by
for some positive constants a, b, and c. The marginal PDFs are easily found to be
 and 
.
The conditional PDF of X given Y then works out to be
.
The conditional PDF of Y given X could also be determined in a similar way:
.
fX Y x y


fX Y

x y



fY y
 
----------------------
=
A= y
Y
y
dy
+

	
fX A x
 dx
Pr x
X
x
dx
+

	
y
Y
y
dy
+

	


Pr x
X
x
dx
+

	
y
Y
y
dy
+

	



Pr y
Y
y
dy
+

	


--------------------------------------------------------------------------
=
=
fX Y

x y


dxdy
fY y
 dy
----------------------------------
fX Y

x y


dx
fY y
 
----------------------------
=
=
dy
0

Y
y
=


FX Y x y


fX Y

x' y


 x'
d

–
x
fY y
 
----------------------------------------
=
fX Y

x y



2abc
ax
by
c
+
+

3
--------------------------------u x
 u y
 
=
fX x
 
fX Y

x y


 y
d
0


ac
ax
c
+

2
---------------------u x
 
=
=
fY y
 
fX Y

x y


 x
d
0


bc
by
c
+

2
---------------------u y
 
=
=
fX Y x y


fX Y

x y



fY y
 
---------------------
2a by
c
+

2
ax
by
c
+
+

3
--------------------------------u x
 
=
=
fY X y x


fX Y

x y



fX x
 
---------------------
2b ax
c
+

2
ax
by
c
+
+

3
--------------------------------u y
 
=
=



190    Chapter 5
www.Academicpress.com
Example 5.10:
This example involves two Gaussian random variables. Suppose X and Y have a joint PDF 
given by
.
The marginal PDF is found as follows:
.
In order to evaluate the integral, complete the square in the exponent:
.
Now the integrand is a Gaussian-looking function. If the appropriate constant is added 
to the integrand, the integrand will be a valid PDF and hence must integrate out to one. 
In this case, the constant we need to add to the integrand to make the integral unity is 
. Stated another way, the integral as just written must evaluate to 
. 
Hence, the marginal PDF of X is
,
and we see that X is a zero-mean, unit-variance, Gaussian (i.e., standard normal) 
random variable. By symmetry, the marginal PDF of Y must also be of the same form. 
The conditional PDF of X given Y is 
So, the conditional PDF of X given Y is also Gaussian. But, given that it is known that 
Y = y, the mean of X is now y/2 (instead of zero), and the variance of X is 3/4 (instead of 
one). In this example, knowledge of Y has shifted the mean and reduced the variance of X.
In addition to conditioning on a random variable taking on a point value such as Y = y, the 
conditioning can also occur on an interval of the form 
. To simplify notation, let 
the conditioning event A be 
. The relevant conditional PMF, PDF, and CDF 
are then given, respectively, by
fX Y

x y



1
 3
----------
2
3--- x2
xy
–
y2
+


–



 
exp
=
fX x
 
fX Y

x y


 y
d

–


1
 3
----------
2
3---x2
–



 
2
3--- y2
xy
–


–



 
exp
y
d

–


exp
=
=
fX x
 
1
 3
----------
2
3---x2
–



 
x2
6-----



 
2
3--- y2
xy
–
x2
4-----
+



 
–



 
exp
y
d

–


exp
exp
1
 3
----------
x2
2-----
–



 
2
3--- y
x
2---
–



 2
–



 
exp
y
d

–


exp
=
=
2
3


&
3 2
&
fX x
 
1
2
----------
x2
2-----
–



 
exp
=
fX Y x y


fX Y

x y



fY y
 
---------------------
1
 3
----------
2
3--- x2
xy
–
y2
+


–



 
exp
1
2
----------
y2
2-----
–



 
exp
---------------------------------------------------------------
2
3
------
2
3--- x2
xy
–
y2
4-----
+



 
–



 
exp
2
3
------
2
3--- x
y
2---
–



 2
–



 
exp
=
=
=
=
y1
Y
y2
	
	
A
y1
Y
y2
	
	


=



Pairs of Random Variables    191
www.Academicpress.com
;
(5.17)
;
(5.18)
.
(5.19)
It is left as an exercise for the reader to derive these expressions.
Example 5.11:
Using the joint PDF of Example 5.10, suppose we want to determine the conditional 
PDF of X given that 
. The numerator in Equation (5.18) is calculated according to
Since the marginal PDF of Y is a zero-mean, unit-variance Gaussian PDF, the denominator 
of Equation (5.18) becomes
.
Therefore, the PDF of X conditioned on 
 is
.
Note that when the conditioning event was a point condition on Y, the conditional PDF 
of X was Gaussian; yet, when the conditioning event is an interval condition on Y, the 
resulting conditional PDF of X is not Gaussian at all.
PX A x
 
PX Y

x y



y
y1
=
y2

PY y
 
y
y1
=
y2

-----------------------------------
=
fX A x
 
fX Y

x y


 y
d
y1
y2
fY y
  y
d
y1
y2
-----------------------------------
=
FX A x
 
FX Y

x y2



FX Y

x y1



–
FY y2


FY y1


–
-----------------------------------------------------------
=
Y
yo

fX Y

x y


 y
d
yo


1
 3
----------
2
3--- x2
xy
–
y2
+


–



 
exp
y
d
yo


1
2
----------
x2
2-----
–



 
2
3
------
2
3--- y
x
2---
–



 2
–



 
exp
y
d
yo


exp
=
=
1
2
----------
x2
2-----
–



 Q
2yo
x
–
3
----------------



 
exp
=
fY y
  y
d
yo


1
2
----------
y2
2-----
–



 
exp
y
d
yo


Q yo


=
=
Y
yo

fX Y
yo

x
 
1
2
----------
x2
2-----
–



 
Q
2yo
x
–
3
----------------



 
Q yo


--------------------------
exp
=



192    Chapter 5
www.Academicpress.com
5.5  Expected Values Involving Pairs of Random Variables
The notion of expected value is easily generalized to pairs of random variables. To begin, we 
define the expected value of an arbitrary function of two random variables.
Definition 5.4: Let 
 be an arbitrary two-dimensional function. The expected
value of 
, where X and Y are random variables, is
.
(5.20)
For discrete random variables, the equivalent expression in terms of the joint PMF is
.
(5.21)
If the function 
 is actually a function of only a single variable, say x, then this 
definition reduces to the definition of expected values for functions of a single random 
variable as given in Definition 4.2.  
 
(5.22)
To start with, consider an arbitrary linear function of the two variables 
, 
where a and b are constants. Then
 
.
(5.23)
This result merely states that expectation is a linear operation.
In addition to the functions considered in Chapter 4 which led to statistics such as means, 
variances, and the like, functions involving both variables x and y will be considered here. 
g x y



g X Y



E g X Y





g x y


fX Y

x y


 x
d
y
d

=
E g X Y





g xm yn


PX Y

xm yn



n
m
=
g x y



E g X
 


g x
 fX Y

x y


 x
d
y
d

–



–


g x
 
fX Y

x y


 y
d

–


x
d

–


.
=
=
g x
 fX x
  x
d

–


=
g x y



ax
by
+
=
E aX
bY
+


ax
by
+

fX Y

x y


 x
d
y
d

–



–


=
a
xfX Y

x y


 x
d
y
d

–



–


b
yfX Y

x y


 x
d
y
d

–



–


+
=
aE X
 
bE Y
 
+
=

Pairs of Random Variables    193
www.Academicpress.com
These new functions will lead to statistics that will partially characterize the relationships 
between the two random variables.
Definition 5.5: The correlation between two random variables is defined as
.
(5.24)
Furthermore, two random variables which have a correlation of zero are said to be
orthogonal.
One instance in which the correlation appears is in calculating the second moment of a sum of 
two random variables. That is, consider finding the expected value of 
.
.
(5.25)
Hence the second moment of the sum is the sum of the second moments plus twice the 
correlation.
Definition 5.6: The covariance between two random variables is
.
(5.26)
If two random variables have a covariance of zero, they are said to be uncorrelated.
The correlation and covariance are strongly related to one another as shown by the following 
theorem.
Theorem 5.3:  
.
(5.27)
Proof: 
.
As a result, if either X or Y (or both) has a mean of zero, correlation and covariance are equivalent. 
The covariance function occurs when calculating the variance of a sum of two random variables.
.
(5.28)
This result can be obtained from Equation (5.25) by replacing X with 
 and Y 
with 
. 
RX Y

E XY


xyfX Y

x y


 x
d
y
d

=
=
g X Y



X
Y
+

2
=
E
X
Y
+

2


E X2
2XY
Y2
+
+


E X2


E Y2


2E XY


+
+
=
=
Cov X Y



E
X
'X
–

 Y
'Y
–




x
'X
–

 y
'Y
–

fX Y

x y


 x
d
y
d

=
=
Cov X Y



RX Y

'X'Y
–
=
Cov X Y



E
X
'X
–

 Y
'Y
–




E XY
'XY
–
'YX
–
'X'Y
+


=
=
E XY


'XE Y
 
–
'YE X
 
–
'X'Y
+
E XY


'X'Y
–
=
=
Var X
Y
+


Var X
 
Var Y
 
2Cov X Y



+
+
=
X
'X
–
Y
'Y
–

194    Chapter 5
www.Academicpress.com
Another statistical parameter related to a pair of random variables is the correlation 
coefficient, which is nothing more than a normalized version of the covariance.
Definition 5.7: The correlation coefficient of two random variables X and Y, 
, is
defined as
.
(5.29)
The next theorem quantifies the nature of the normalization. In particular, it shows that a 
correlation coefficient can never be more than 1 in absolute value. 
Theorem 5.4: The correlation coefficient is less than 1 in magnitude.
Proof: Consider taking the second moment of X + aY, where a is a real constant:
.
Since this is true for any a, we can tighten the bound by choosing the value of a that
minimizes the left-hand side. This value of a turns out to be
.
Plugging in this value gives
If we replace X with 
 and Y with 
 the result is
.
Rearranging terms then gives the desired result:
.   
(5.30)
(XY
(XY
Cov X Y



Var X
 Var Y
 
--------------------------------------
E
X
'X
–

 Y
'Y
–




)X)Y
------------------------------------------------
=
=
E
X
aY
+

2


E X2


2aE XY


a2E Y2


+
+
0

=
a
E XY


–
E Y2


------------------
=
E X2


E XY



2
E Y2


-----------------------
2 E XY



2
E Y2


--------------------------
–
+
0

E XY



2
E X2

E Y2


	

X
'X
–
Y
'Y
–
Cov X Y




2
Var X
 Var Y
 
	
(XY
Cov X Y



Var X
 Var Y
 
--------------------------------------
1
	
=

Pairs of Random Variables    195
www.Academicpress.com
Note that we can also infer from the proof that equality holds if Y is a constant times X. That is, 
a correlation coefficient of 1 (or -1) implies that X and Y are completely correlated (knowing Y 
determines X). Furthermore, uncorrelated random variables will have a correlation coefficient 
of zero. Therefore, as its name implies, the correlation coefficient is a quantitative measure of 
the correlation between two random variables. It should be emphasized at this point that zero 
correlation is not to be confused with independence. These two concepts are not the same 
(more on this later).
The significance of the correlation, covariance, and correlation coefficient will be discussed 
further in the next two sections. For now, we present an example showing how to compute 
these parameters.
Example 5.12:
Consider once again the joint PDF of Example 5.10. The correlation for these random 
variables is
.
In order to evaluate this integral, the joint PDF is rewritten 
 and 
then those terms involving only  are pulled outside the inner integral over y.
.
The inner integral (in square brackets) is the expected value of a Gaussian random 
variable with a mean of 
 and variance of 3/4 which thus evaluates to 
. Hence,
.
The remaining integral is the second moment of a Gaussian random variable with zero-
mean and unit variance which integrates to 1. The correlation of these two random 
variables is therefore 
. Since both X and Y have zero means, 
 is also 
equal to 1/2. Finally, the correlation coefficient is also 
 due to the fact that 
both X and Y have unit variance.
The concepts of correlation and covariance can be generalized to higher-order moments as 
given in the following definition.
Definition 5.8: The (m, n)th joint moment of two random variables X and Y is
.
(5.31)
E XY


xy
 3
----------
2
3--- x2
xy
–
y2
+


–



 
exp
y
d
x
d

–



–


=
fX Y

x y



fY X y x

fX x
 
=
x &
E XY


x
2
----------
x2
2-----
–



 
exp
y
2
3
------
2
3--- y
x
2---
–



 2
–



 
exp
y
d

–


x
d

–


=
x 2
&
x 2
&
E XY


1
2---
x2
2
----------
x2
2-----
–



 
exp
x
d

–


=
E XY


1 2
&
=
Cov X Y



(XY
1 2
&
=
E XmYn


xmynfX Y

x y


 x
d
y
d

=



196    Chapter 5
www.Academicpress.com
The (m, n)th joint central moment is similarly defined as
.
(5.32)
These higher-order joint moments are not frequently used and therefore are not considered 
further here.
As with single random variables, a conditional expected value can also be defined for which 
the expectation is carried out with respect to the appropriate conditional density function.
Definition 5.9: The conditional expected value of a function 
 of a random
variable X given that Y = y is
.
(5.33)
Conditional expected values can be particularly useful in calculating expected values of 
functions of two random variables that can be factored into the product of two one-
dimensional functions. That is, consider a function of the form 
. Then
.
(5.34)
From Equation (5.15) the joint PDF is rewritten as 
, resulting in
.
(5.35)
Here, the subscripts on the expectation operator have been included for clarity to emphasize 
that the outer expectation is with respect to the random variable X, while the inner 
expectation is with respect to the random variable Y (conditioned on X). This result allows 
us to break a two-dimensional expectation into two one-dimensional expectations. This 
technique was used in Example 5.12, where the correlation between two variables was 
essentially written as
.
(5.36)
E
X
'X
–

m Y
'Y
–

n


x
'X
–

m y
'Y
–

nfX Y

x y


 x
d
y
d

=
g X
 
E g X
  Y


g x
 fX Y x y

 x
d

–


=
g x y



g1 x
 g2 y
 
=
E g1 X
 g2 Y
 


g1 x
 g2 y
 fX Y

x y


 x
d
y
d

–



–


=
fX Y

x y



fY X y x

fX x
 
=
E g1 X
 g2 Y
 


g1 x
 fX x
 
g2 y
 fY X y x

 y
d

–


x
d

–


=
g1 x
 fX x
 EY g2 Y
  X

 x
d

–


EX g1 X
 EY g2 Y
  X




=
=
RX Y

EX XEY Y X




=

Pairs of Random Variables    197
www.Academicpress.com
In that example, the conditional PDF of Y given X was Gaussian, thus finding the conditional 
mean was accomplished by inspection. The outer expectation then required finding the second 
moment of a Gaussian random variable, which is also straightforward. 
5.6  Independent Random Variables
The concept of independent events was introduced in Chapter 2. In this section, we extend this 
concept to the realm of random variables. To make that extension, consider the events 
 and 
 related to the random variables X and Y. The two events A and 
B are statistically independent if 
. Restated in terms of the random 
variables, this condition becomes
.
(5.37)
Hence, two random variables are statistically independent if their joint CDF factors into a 
product of the marginal CDFs. Differentiating both sides of this equation with respect to both 
x and y reveals that the same statement applies to the PDF as well. That is, for statistically 
independent random variables, the joint PDF factors into a product of the marginal PDFs:
.
(5.38)
It is not difficult to show that the same statement applies to PMFs as well. The preceding 
condition can also be restated in terms of conditional PDFs. Dividing both sides of Equation 
(5.38) by 
 results in
.
(5.39)
A similar result involving the conditional PDF of X given Y could have been obtained by 
dividing both sides by the PDF of Y. In other words, if X and Y are independent, knowing the 
value of the random variable X should not change the distribution of Y and vice versa. 
Example 5.13:
Returning once again to the joint PDF of Example 5.10, we saw in that example that the 
marginal PDF of X is
,
while the conditional PDF of X given Y is
.
Clearly, these two random variables are not independent.
A
X
x
	


=
B
Y
y
	


=
Pr A B



Pr A
 Pr B
 
=
Pr X
x
	
Y
y
	



Pr X
x
	

Pr Y
y
	

    
=
    FX Y

x y




FX x
 FY y
 
=
fX Y

x y



fX x
 fY y
 
=
fX x
 
fY X y x


fY y
 
=
fX x
 
1
2
----------
x2
2-----
–



 
exp
=
fX Y x y


2
3
------
2
3--- x
y
2---
–



 2
–



 
exp
=



198    Chapter 5
www.Academicpress.com
Example 5.14:
Suppose the random variables X and Y are uniformly distributed on the square defined 
by 
. That is
The marginal PDFs of X and Y work out to be
     
These random variables are statistically independent since 
.
Theorem 5.5: Let X and Y be two independent random variables and consider forming
two new random variables 
 and 
. These new random variables 
U and V are also independent.  
Proof: To show that U and V are independent, consider the events 
 and
. Next define the region 
 to be the set of all points x such that
. Similarly, define 
 to be the set of all points y such that 
. Then
.
Since X and Y are independent, their joint PDF can be factored into a product of
marginal PDFs resulting in
.
Since we have shown that 
, the random variables U and V
must be independent.   
Another important result deals with the correlation, covariance, and correlation coefficients of 
independent random variables.
Theorem 5.6: If X and Y are independent random variables, then 
,
, and 
.  
Proof: 
.   
The conditions involving covariance and correlation coefficient follow directly from
this result.
0
x y
1
	

	
fX Y

x y



1,     0
x y
1,
	

	
0,   otherwise.



=
fX x
 
1,  0
x
1
	 	 ,
0,   otherwise,



=
fY y
 
1,  0
y
1
	 	 ,
0,   otherwise.



=
fX Y

x y



fX x
 fY y
 
=
U
g1 X
 
=
V
g2 Y
 
=
A
U
u
	


=
B
V
v
	


=
Ru
g1 x
 
u
	
Rv
g2 y
 
v
	
Pr U
u
	
V
v
	



Pr X
Ru

Y
Rv




fX Y

x y


 x
d
y
d
Ru
Rv
=
=
Pr U
u
	
V
v
	



fX x
 
Ru
dx
fY y
 
Rv
dy
Pr X
Ru


Pr Y
Rv



=
=
Pr U
u
	

Pr V
v
	


=
FU V

u v



FU u
 FV v
 
=
E XY


'X'Y
=
Cov X Y



0
=
(X Y

0
=
E XY


xyfX Y

x y


 x
d
y
d

xfX x
  x y fY y
  y
d

d

'X'Y
=
=
=



Pairs of Random Variables    199
www.Academicpress.com
Therefore, independent random variables are necessarily uncorrelated, but the converse is not 
always true. Uncorrelated random variables do not have to be independent as demonstrated by 
the next example.
Example 5.15:
Consider a pair of random variables X and Y that are uniformly distributed over the unit 
circle so that
The marginal PDF of X can be found as follows:
,  
.
By symmetry, the marginal PDF of Y must take on the same functional form. Hence, the 
product of the marginal PDFs is
,   
.
Clearly, this is not equal to the joint PDF, and therefore, the two random variables are 
dependent. This conclusion could have been determined in a simpler manner. Note that 
if we are told that X = 1, then necessarily Y = 0, whereas if we know that X = 0, then Y can 
range anywhere from -1 to 1. Therefore, conditioning on different values of X leads to 
different distributions for Y.
Next, the correlation between X and Y is calculated.
.
Since the inner integrand is an odd function (of y) and the limits of integration are 
symmetric about zero, the integral is zero. Hence, 
. Note from the marginal 
PDFs just found that both X and Y are zero-mean. So, it is seen for this example that 
while the two random variables are uncorrelated, they are not independent.
fX Y

x y



1
---,    x2
y2
+
1,
	
0,   otherwise.





=
fX x
 
fX Y

x y


 y
d

–


1
--- y
d
1
x2
–
–
1
x2
–

2
--- 1
x2
–
=
=
=
1
x
1
	 	
–
fX x
 fY y
 
4
2
-----
1
x2
–

 1
y2
–


=
1
x y

1
	
	
–
E XY


xy
----- x
d
y
d
x2
y2
+
1
	

1
---
x
y y
d
1
x2
–
–
1
x2
–

x
d
1
–
1
=
=
E XY


0
=



200    Chapter 5
www.Academicpress.com
Example 5.16:
Suppose we wish to use MATLAB to generate samples of a pair of random 
variables 
 that are uniformly distributed over the unit circle. That is, 
the joint PDF is 
If we generated two random variables independently according to the MATLAB code: 
X=rand(1); Y=rand(1); this would produce a pair of random variables uniformly 
distributed over the square 
. One way to achieve the desired result is to 
generate random variables uniformly over some region which includes the unit circle and 
then only keep those pairs of samples which fall inside the unit circle. In this case, it is 
straightforward to generate random variables which are uniformly distributed over the 
square, 
, which circumscribes the unit circle. Then we keep only those 
samples drawn from within this square that also fall within the unit circle. The code that 
follows illustrates this technique. We also show how to generate a three-dimensional 
plot of an estimate of the joint PDF from the random data generated. To get a decent 
estimate of the joint PDF, we need to generate a rather large number of samples (we 
found that 100,000 worked pretty well). This requires that we create and perform 
several operations on some very large vectors. Doing so tends to make the program run 
slowly. In order to speed up the operation of the program, we choose to create shorter 
vectors of random variables (1000 in this case) and then repeat the procedure several 
times (100 in this case). Although this makes the code a little longer and probably a little 
harder to follow, by avoiding the creation of very long vectors, it substantially speeds up 
the program. The results of this program are shown in Figure 5.3.
clear
N=1000;
% number of samples per iteration
bw=0.1;
% bin widths for histogram
xbins=[-1.4:bw:1.4]; 
ybins=[-1.4:bw:1.4];
% histogram bins
iterations=100;
% number of iterations
M=length(xbins);
Nsamples=zeros(M);
% initialize matrix for storing data
count=0;
% initialize counter.
for ii=1:iterations
x=2*rand(1,N)-1; y=2*rand(1,N)-1;
% generate variables over square
% keep only those within the unit circle.
X=[]; Y=[];
X Y



fX Y

x y



1
--- ,      x2
y2
+
1,

0,
  otherwise.





=
0
x
1
 
0
y
1
 

1
x
1
1
–
y
1
 

 
–


Pairs of Random Variables    201
www.Academicpress.com
for k=1:N
   if x(k)^2+y(k)^2<1
      X=[X x(k)];
      Y=[Y y(k)];
   end 
% end if statement
end 
% end k loop
count=count+length(X);
% count random samples generated
% Compute number of samples that fall within each bin.
for m=1:length(xbins)
   for n=1:length(ybins)
      temp1=(abs(X-xbins(m))<bw/2);
      temp2=(abs(Y-ybins(n))<bw/2);
      Nsamples(m,n)=Nsamples(m,n)+sum(temp1.*temp2);
   end 
% end n loop
end 
% end m loop
end 
% end iterations
PDFest=Nsamples/(count*bw^2); 
% convert to prob. densities
mesh(xbins,ybins,PDFest)
% plot estimate of joint PDF
xlabel('x'); ylabel('y'); 
% label plot axes
zlabel('Joint PDF'); 
−1.5
−1
−0.5
0
0.5
1
1.5
−2
−1
0
1
2
0
0.1
0.2
0.3
0.4
x
y
Joint PDF
Figure 5.3
Estimate of the joint PDF of a pair of random variables uniformly distributed over the unit circle 
from the data generated in Example 5.16. (For color version of this figure, the reader is referred 
to the web version of this chapter.)


202    Chapter 5
www.Academicpress.com
5.7  Jointly Gaussian Random Variables
As with single random variables, the most common and important example of a two-
dimensional probability distribution is that of a joint Gaussian distribution. We begin by 
defining what is meant by a joint Gaussian distribution.
Definition 5.10: A pair of random variables X and Y is said to be jointly Gaussian if
their joint PDF is of the general form
,
(5.40)
where 
 and 
 are the means of X and Y, respectively; 
 and 
 are the standard
deviations of X and Y, respectively; and 
 is the correlation coefficient of X and Y.  
It is left as an exercise for the reader (see Exercise 5.35) to verify that this joint PDF results in 
marginal PDFs that are Gaussian. That is, 
,
.
(5.41)
It is also left as an exercise for the reader (see Exercise 5.36) to demonstrate that if X and Y are 
jointly Gaussian, then the conditional PDF of X given Y = y is also Gaussian, with a mean of 
 and a variance of 
. An example of this was shown in 
Example 5.10, and the general case can be proven following the same steps shown in that 
example.
Figure 5.4 shows the joint Gaussian PDF for three different values of the correlation 
coefficient. In Figure 5.4a, the correlation coefficient is 
 and thus the two random 
variables are uncorrelated (and as we will see shortly, independent). Figure 5.4b shows the 
fX Y

x y



1
2)X)Y 1
(XY
2
–
--------------------------------------------
x
'X
–
)X
---------------


$
%

 2
2
– (XY
x
'X
–
)X
---------------


$
%

 y
'Y
–
)Y
--------------


$
%

 
y
'Y
–
)Y
--------------


$
%

 2
+
2 1
(XY
2
–


--------------------------------------------------------------------------------------------------------------
–


$
%
$
%
$
%
$
%
$
%

 
exp
=
'X
'Y
)X
)Y
(XY
fX x
 
fX Y

x y


 y
d

–


1
2)X
2
-----------------
x
'X
–

2
2)X
2
---------------------
–


$
%

 
exp
=
=
fY y
 
fX Y

x y


 x
d

–


1
2)Y
2
-----------------
y
'Y
–

2
2)Y
2
---------------------
–


$
%

 
exp
=
=
'X
(XY )X )Y
&

 y
'Y
–


+
)X
2 1
(XY
2
–


(XY
0
=

Pairs of Random Variables    203
www.Academicpress.com
joint PDF when the correlation coefficient is large and positive, 
. Note how the 
surface has become taller and thinner and largely lies above the line 
. In Figure 5.4c, the 
correlation is now large and negative, 
. Note that this is the same picture as in 
Figure 5.4b, except that it has been rotated by 
. Now the surface lies largely above the line 
. In all three figures, the means of both X and Y are zero and the variances of both X and 
Y are 1. Changing the means would simply translate the surface but would not change the 
shape. Changing the variances would expand or contract the surface along either the X- or 
Y-axis depending on which variance was changed.
(XY
0.9
=
y
x
=
(XY
0.9
–
=
90*
y
x
–
=
-5
0
5
-5
0
5
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
x
y
(a)
fX, Y(x, y)
fX, Y(x, y)
-5
0
5
-5
0
5
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
x
y
x
(b)
Figure 5.4 
The joint Gaussian PDF: (a) 
, 
, 
; (b) 
, 
, 
;
'X
'Y
0
=
=
)X
)Y
1
=
=
(XY
0
=
'X
'Y
0
=
=
)X
)Y
1
=
=
(XY
0.9
=
(Continued)

204    Chapter 5
www.Academicpress.com
Example 5.17:
The joint Gaussian PDF is given by
.
Suppose we equate the portion of this equation that is within the square brackets to a 
constant. That is, 
.
This is the equation for an ellipse. Plotting these ellipses for different values of  results 
in what is known as a contour plot. Figure 5.5 shows such plots for the two-dimensional 
joint Gaussian PDF. The following code can be used to generate such plots. The reader is 
encouraged to try creating similar plots for different values of the parameters in the 
Gaussian distribution.
clear
[X,Y]=meshgrid(-8:0.1:8); 
% generate x and y array to 
% be used for contour plot
mux=0; muy=0;
% set means
stdx=3; stdy=3;
% set standard deviations
fX, Y(x, y)
-5
0
5
-5
0
5
0
0.1
0.15
0.2
0.25
0.5
0.35
0.4
y
x
0.05
(c)
Figure 5.4 (Continued) 
 (c) 
, 
, 
.
X
Y
0
=
=
X
Y
1
=
=
XY
0.9
–
=
fX Y

x y



1
2XY 1
XY
2
–
-----------------------------------------
=
1
2 1
XY
2
–


-------------------------
x
X
–
X
--------------
	



2
2
– XY
x
X
–
X
--------------
	


 y
Y
–
Y
-------------
	



y
Y
–
Y
-------------
	



2
+
–
	





exp
x
X
–
X
--------------
	



2
2
– XY
x
X
–
X
--------------
	


 y
Y
–
Y
-------------
	



y
Y
–
Y
-------------
	



2
+
c2
=
c


Pairs of Random Variables    205
www.Academicpress.com
varx=stdx^2; vary=stdy^2;
% compute variances
rho=0.5;
% set correlation coefficient
% Compute exponent of 2-D Gaussian PDF.
X1=(X-mux)/stdx;
Y1=(Y-muy)/stdy;
Z=X1.^2-2*rho*X1.*Y1+Y1.^2;
c=[1/16 1/4 1 2 4];
% set contour levels
contour(X,Y,Z,c)
% produce contour plot grid
% turn on grid lines
xlabel('x'); ylabel('y')
% label axes  
Theorem 5.7: Uncorrelated Gaussian random variables are independent.
Proof: Uncorrelated Gaussian random variables have a correlation coefficient of zero.
Plugging 
 into the general joint Gaussian PDF results in
x
y
−8
−6
−4
−2
0
2
4
6
8
−8
−6
−4
−2
0
2
4
6
8
Figure 5.5  
Contour plots for Example 5.17. (For color version of this figure, the reader is referred to the 
web version of this chapter.)
XY
0
=


206    Chapter 5
www.Academicpress.com
.
This clearly factors into the product of the marginal Gaussian PDFs.
.  
While Example 5.15 demonstrated that this property does not hold for all random 
variables, it is true for Gaussian random variables. This allows us to give a stronger 
interpretation to the correlation coefficient when dealing with Gaussian random variables. 
Previously, it was stated that the correlation coefficient is a quantitative measure of the 
amount of correlation between two variables. While this is true, it is a rather vague 
statement. After all, what does “correlation” mean? In general, we cannot equate 
correlation and statistical dependence. Now, however, we see that in the case of Gaussian 
random variables, we can make the connection between correlation and statistical 
dependence. Hence, for jointly Gaussian random variables, the correlation coefficient can 
indeed be viewed as a quantitative measure of statistical dependence. This relationship is 
illustrated in Figure 5.6.  
5.8  Joint Characteristic and Related Functions
When computing the joint moments of random variables, it is often convenient to use 
characteristic functions, moment-generating functions, or probability-generating functions.  
Since a pair of random variables is involved, the “frequency domain” function must now be 
two dimensional. We start with a description of the joint characteristic function which is 
similar to a two-dimensional Fourier transform of the joint PDF.
fX Y

x y



1
2XY
--------------------
x
X
–
X
--------------
	




2
y
Y
–
Y
--------------
	




2
+
2
--------------------------------------------------
–
	













exp
=
fX Y

x y



1
2x
2
-----------------exp
x
x
–

2
2x
2
--------------------
–
	





1
2y
2
-----------------exp
y
y
–

2
2y
2
--------------------
–
	





fX x
 fY y
 
=
=
0
1
−1
rXY
Statistical
independence
Linear
dependence
Y = aX + b
a positive
Linear
dependence
Y = aX + b
a negative
Figure 5.6
Interpretation of the correlation coefficient for jointly Gaussian random variables.

Pairs of Random Variables    207
www.Academicpress.com
Definition 5.11: Given a pair of random variables X and Y with a joint PDF, 
, the joint characteristic function is 
(5.42)
The various joint moments can be evaluated from the joint characteristic function using 
techniques similar to those used for single random variables. It is left as an exercise for the 
reader to establish the following relationship:
.
(5.43)
Example 5.18:
Consider a pair of zero-mean, unit-variance, jointly Gaussian random variables whose 
joint PDF is
.
One way to calculate the joint characteristic function is to break the problem into two 
one-dimensional problems.
.
Conditioned on Y, X is a Gaussian random variable with a mean of  
 and a variance of 
. The general form of the characteristic function (one-dimensional) of a Gaussian 
random variable with mean 
 and variance 
 is (see Example 4.20)
.
Therefore, the inner expectation above evaluates to
.
The joint characteristic function is then
.
The remaining expectation is the characteristic function of a zero-mean, unit-variance 
Gaussian random variable evaluated at 
. The resulting joint characteristic 
function is then found to be
.
fX Y

x y



X Y

1 2



E ej 1X
2Y
+




ej 1x
2y
+

fX Y

x y


 x
d
y
d

–



–


=
=
E XmYn


j
–

m
n
+
1
m
m


2
n
n

 X Y

1 2



1
2
0
=
=
=
fX Y

x y



1
2 1
2
–
------------------------
x2
2xy
–
y2
+


2 1
2
–


-------------------------------------
–
	



exp
=
X Y

1 2



E e j 1X
2Y
+




EY e j2YEX e j1X Y




=
=
Y
1
2
–
X
X
2
X 
 
jX
2X
2
2
-------------
–
	



exp
=
EX ej1X Y


jY1
1
2 1
2
–


2
-------------------------
–
	



exp
=
X Y

1 2



EY
j2Y
jY1
1
2 1
2
–


2
-------------------------
–
+
	



exp
1
2 1
2
–


2
-------------------------
–
	


EY ej 1
2
+

Y


exp
=
=

1
2
+
=
X Y

1 2



1
2 1
2
–


2
-------------------------
–
	



1
2
+

2
2
-----------------------------
–
	



exp
exp
1
2
212
2
2
+
+
2
--------------------------------------------
–
	



exp
=
=

(Continued)

208    Chapter 5
www.Academicpress.com
From this expression, various joint moments can be found. For example, the correlation is
.
Since the two random variables were zero mean, 
. Furthermore, since the 
two random variables were unit variance,  is also the correlation coefficient. We have 
proved therefore that the parameter  that shows up in the joint Gaussian PDF is indeed 
the correlation coefficient.  
We could easily compute higher-order moments as well. For example, suppose we 
needed to compute 
. It can be computed in a similar manner to the preceding:
.
Definition 5.12: For a pair of discrete random variables defined on a two-dimensional
lattice of nonnegative integers, one can define a joint probability-generating function as
.
(5.44)
The reader should be able to show that the joint partial derivatives of the joint probability-
generating function evaluated at zero are related to the terms in the joint PMF, whereas those 
same derivatives evaluated at 1 lead to joint factorial moments. Specifically:
,
(5.45)
.
(5.46)
Example 5.19:
Consider the joint PMF given in Example 5.7:
.
It is not too difficult to work out the joint probability-generating function for this pair of 
discrete random variables.
E XY


1


2


1
2
212
2
2
+
+
2
--------------------------------------------
–
	



exp
–
1
2
0
=
=
2

 2
2
2
2
------
–
	



exp
2
0
=

=
=
=
Cov X Y




=


E X2Y2


E X2Y2


1
2
2


2
2
2


1
2
212
2
2
+
+
2
--------------------------------------------
–
	



exp
1
2
0
=
=
2
2
2


1
2

2
–


2
2
2
------
–
	



exp
2
0
=
–
1
22
+
=
=
=
HX Y

z1 z2



E z1
Xz2
Y


PX Y

m n


z1
mz2
n
n
0
=


m
0
=


=
=
PX Y

k l


1
k!l!
--------
z1
k
k


z2
l
l

 HX Y

z1 z2



z1
z2
0
=
=
=
E X X
1
–

 X
k
–
1
+

Y Y
1
–

 Y
l
–
1
+




z1
k
k


z2
l
l

 HX Y

z1 z2



z1
z2
1
=
=
=
PN M

n m



n
m
+

!
n!m!
-------------------
anbm
a
b
1
+
+

n
m
1
+
+
-----------------------------------------
=



Pairs of Random Variables    209
www.Academicpress.com
.
It should be noted that the closed form expression used for the various series preceding 
limits the range in the 
 plane for which these expressions are valid; thus, care 
must be taken when evaluating this function and its derivatives at various points. 
However, for this example, the expression is valid in and around the points of interest 
(i.e., 
 and 
).  
Now that the joint probability-generating function has been found, joint moments are 
fairly easy to compute. For example,
,
.
Putting these two results together, it is found that
.
By symmetry, we can also conclude that 
 and 
.  
As one last example, we note that
.
From this and the previous results, we can find 
 as follows:
.
The moment-generating function can also be generalized in a manner virtually identical to 
what was done for the characteristic function. We leave the details of this extension to the 
reader.
HN M

z1 z2



n
m
+

!
n!m!
-------------------
az1

n bz2

m
a
b
1
+
+

n
m
1
+
+
-----------------------------------------
m
0
=

n
0
=


az1

n
a
b
1
+
+

n
1
+
---------------------------------
n
m
+

!
n!m!
-------------------
bz2
a
b
1
+
+
-------------------
	



m
m
0
=


n
0
=


=
=
az1

n
a
b
1
+
+

n
1
+
---------------------------------
1
1
bz2
a
b
1
+
+
-------------------
–
----------------------------
	








n
1
+
n
0
=


az1

n
a
b 1
z2
–


1
+
+

n
1
+
---------------------------------------------------
n
0
=


=
=
1
a
b 1
z2
–


1
+
+
-------------------------------------
az1
a
b 1
z2
–


1
+
+
-------------------------------------
	



n
n
0
=


1
1
a 1
z1
–


b 1
z2
–


+
+
-------------------------------------------------------
=
=
z1 z2



z1 z2



0 0



=
z1 z2



1 1



=
E NM


z1


z2


1
1
a 1
z1
–


b 1
z2
–


+
+
-------------------------------------------------------
z1
z2
1
=
=
z1


b
1
a 1
z1
–


+

2
------------------------------------
z1
1
=
2ab
=
=
=
E N N
1
–

M


z1
2
2


z2


1
1
a 1
z1
–


b 1
z2
–


+
+
-------------------------------------------------------
z1
z2
1
=
=
z1
2
2


b
1
a 1
z1
–


+

2
------------------------------------
z1
1
=
6a2b
=
=
=
E N2M


E N N
1
–

M


E NM


+
6a2b
=
=
2ab
+
E NM M
1
–




6ab2
=
E NM2


6ab2
=
2ab
+
E N N
1
–

M M
1
–




z1
2
2


z2
2
2


1
1
a 1
z1
–


b 1
z2
–


+
+
-------------------------------------------------------
z1
z2
1
=
=
z1
2
2


2b2
1
a 1
z1
–


+

3
------------------------------------
z1
1
=
24a2b2
=
=
=
E N2M2


E N2M2


E N N
1
–

M M
1
–




E NM2


E N2M


E NM


–
+
+
24a2b2
6ab2
6a2b
2ab
–
+
+
=
=


210    Chapter 5
www.Academicpress.com
5.9  Transformations of Pairs of Random Variables
In this section, we consider forming a new random variable as a function of a pair of random 
variables. When a pair of random variables is involved, there are two classes of such 
transformations. The first class of problems deals with the case when a single new variable is 
created as a function of two random variables. The second class of problems involves creating 
two new random variables as two functions of two random variables. These two distinct, but 
related, problems are treated in this section.
Consider first a single function of two random variables, 
. If the joint PDF of X 
and Y is known, can the PDF of the new random variable Z be found? Of course, the answer is 
yes, and there are a variety of techniques to solve these types of problems depending on the 
nature of the function 
. The first technique to be developed is an extension of the approach 
we used in Chapter 4 for functions of a single random variable.
The CDF of Z can be expressed in terms of the variables X and Y as
.
(5.47)
The inequality 
 defines a region in the 
 plane. By integrating the joint PDF of 
X and Y over that region, the CDF of Z is found. The PDF can then be found by differentiating 
with respect to z. In principle, one can use this technique with any transformation; however, 
the integral to be computed may or may not be analytically tractable, depending on the specific 
joint PDF and the transformation.  
To illustrate, consider a simple, yet very important example where the transformation is just 
the sum of the random variables, 
. Then, 
.
(5.48)
Differentiating to form the PDF results in
.
(5.49)
The last step in the previous equation is completed using Liebnitz’s rule.1 An important 
special case results when X and Y are independent. In that case, the joint PDF factors into the 
product of the marginals producing
Z
g X Y



=
g . 
FZ z 
Pr Z
z



Pr g X Y



z



 fX Y

x y


 x
d
y
d

g x y



z

=
=
=
g x y



z

x y



Z
X
Y
+
=
FZ z 
 fX Y

x y


 x
d
y
d

x
y
+
z

fX Y

x y


 x
d
y
d

–
z
y
–


–


=
=
fZ z 
z
d
d
fX Y

x y


 x
d
y
d

–
z
y
–


–


fX Y

z
y
–
y


 y
d

–


=
=
1 Liebnitz’s rule states that: 
.
x


f x y


dy
a x
 
b x
 

x

b f x b x
 



x

a f x a x
 



–
x

 f x y


dy
a x
 
b x
 

+
=

Pairs of Random Variables    211
www.Academicpress.com
.
(5.50)
Note that this integral is a convolution. Thus, the following important result has been proven:
Theorem 5.8: If X and Y are statistically independent random variables, then the 
PDF of 
 is given by the convolution of the PDFs of X and Y,
.
Example 5.20:
Suppose X and Y are independent and both have exponential distributions,
,  
.
The PDF of 
 is then found by performing the necessary convolution:
.
The above result is valid assuming that 
. If 
, then the convolution works 
out to be
.
Students familiar with the study of signals and systems should recall that the convolution 
integral appears in the context of passing signals through linear time invariant systems. In that 
context, most students develop a healthy respect for the convolution and will realize that quite 
often the convolution can be a cumbersome operation. To avoid difficult convolutions, these 
problems can often by solved using a frequency domain approach in which a Fourier or 
Laplace transform is invoked to replace the convolution with a much simpler multiplication. In 
the context of probability, the characteristic function or the moment generating function can 
fulfill the same role. Instead of finding the PDF of 
 directly via convolution, 
suppose we first find the characteristic function of Z:
.
(5.51)
If X and Y are independent, then the expected value of the product of a function of X times a 
function of Y factors into the product of expected values:
.
(5.52)
fZ z 
fX z
y
–

fY y
  y
d

–


=
Z
X
Y
+
=
fZ z 
fX z *fY z 
=
fX x
 
a
ax
–


exp
u x
 
=
fY y
 
b
by
–


exp
u y
 
=
Z
X
Y
+
=
fZ z 
fX z
y
–

fY y
  y
d

–


ab
a z
y
–


–


exp
by
–

u z
y
–

u y
 
exp
y
d

–


=
=
abe az
–
a
b
–

y


exp
yu z 
d
0
z

ab
a
b
–
----------- e az
– e a
b
–

y
y
0
=
y=z u z 
ab
a
b
–
----------- e bz
–
e az
–
–

u z 
=
=
=
a
b

a
b
=
fZ z 
a2ze az
– u z 
=
Z
X
Y
+
=
Z 
 
E e jZ


E e j X
Y
+




E e jXejY


=
=
=
Z 
 
E e jX

E e jY


X 
 Y 
 
=
=



212    Chapter 5
www.Academicpress.com
Once the characteristic function of Z is found, the PDF can be found using an inverse Fourier 
Transform.
Again, the characteristic function can be used to simplify the amount of computation involved 
in calculating PDFs of sums of independent random variables. Furthermore, we have also 
developed a new approach to find the PDFs of a general function of two random variables. 
Returning to a general transformation of the form 
, one can first find the 
characteristic function of Z according to
.
(5.53)
An inverse transform of this characteristic function will then produce the desired PDF. In 
some cases, this method will provide a simpler approach to the problem, while in other cases 
the direct method may be easier.
Example 5.21:
Suppose X and Y are independent, zero-mean, unit-variance Gaussian random variables. 
The PDF of 
 can be found using either of the methods described thus far. 
Using characteristic functions,
.
The expected values are evaluated as follows:
.
The last step is accomplished using the normalization integral for Gaussian functions. 
The other expected value is identical to the first since X and Y have identical 
distributions. Hence,
.
The PDF is found from the inverse Fourier transform to be
.
The other approach is to find the CDF as follows:
.
Z
g X Y



=
Z 
 
E ejg X Y





ejg x y


fX Y

x y


 x
d
y
d

–



–


=
=
Z
X2
Y2
+
=
Z 
 
E ej X2
Y2
+




E ejX2

E ejY2


=
=
E e j X2


1
2
----------e
jx2
e x2 2

–
x
d

–


1
1
2j
–
---------------------
1
2j
–
2
-----------------e
1
2j
–

x2 2

–
x
d

–


1
1
2j
–
---------------------
=
=
=
Z 
 
1
1
2j
–
---------------------
	


2
1
1
2j
–
-----------------
=
=
fZ z 
1
2---
z
2---
–
	



exp
u z 
=
FZ z 
Pr X2
Y2
+
z



1
2
------
x2
y2
+
2
---------------
–
	



exp
x
d
y
d

x2
y2
+
z

=
=


Pairs of Random Variables    213
www.Academicpress.com
Converting to polar coordinates, 
.
Finally, differentiating with respect to z results in
.
Another approach to solving these types of problems uses conditional distributions. Consider a 
general transformation, 
. Next, suppose we condition on one of the two variables, 
say 
. Conditioned on 
, 
 is now a single variable transformation. 
Hence, the conditional PDF of Z given X can be found using the general techniques presented 
in Chapter 4. Once 
 is known, the desired (unconditional) PDF of Z can be found 
according to
.
(5.54)
Example 5.22:
Suppose X and Y are independent zero-mean, unit-variance Gaussian random variables 
and we want to find the PDF of 
. Conditioned on 
, the transformation 
 is a simple linear transformation and
.
Multiplying the conditional PDF by the marginal PDF of X and integrating out x gives the 
desired marginal PDF of Z.
                   
.
Evaluating the integral in the last step can be accomplished by making the substitution 
. Thus, the quotient of two independent Gaussian random variables 
follows a Cauchy distribution.
FZ z 
r
2
------
r2
2
-------
–
	



exp

d
ru z 
d
0
2

0
z

r
r2
2
-------
–
	



exp
ru z 
d
0
z

1
z
2---
–
	



exp
–
u z 
=
=
=
fZ z 
z
d
d 1
z
2---
–
	



exp
–
u z 
1
2---
z
2---
–
	



exp
u z 
=
=
Z
g X Y



=
X
x
=
X
x
=
Z
g x Y



=
fZ X z x


fZ z 
fZ X

z x




dx
fZ X z x

fX x
  x
d

=
=
Z
Y X

=
X
x
=
Z
Y x
=
fZ X z x


x fY xz


x
2
----------
x2z2
2
----------
–
	



exp
=
=
fZ z 
fZ X z x

fX x
  x
d

–


x
2
----------
x2z2
2
----------
–
	



exp
1
2
----------
x2
2-----
–
	



exp
x
d

–


=
=
1
2
------
x
1
x2
+

z2
2
-----------------------
–
	



exp
x
d

–


1
---
x
1
z2
+

x2
2
-----------------------
–
	



exp
x
d
0


1
---
1
1
z2
+
-------------
=
=
=
u
1
z2
+

x2 2

=




214    Chapter 5
www.Academicpress.com
Up to this point, three methods have been developed for finding the PDF of 
 
given the joint PDF of X and Y. They can be summarized as follows:
•
Method 1—CDF approach
Define a set 
. The CDF of Z is the integral of the joint
PDF of X and Y over the region 
. The PDF is then found by differentiating the
expression for the CDF:
.
(5.55)
•
Method 2—Characteristic function approach
First, find the characteristic function of Z according to:
.
(5.56)
Then compute the inverse transform to get the PDF of Z.
•
Method 3—Conditional PDF approach
Fix either X = x or Y = y (whichever is more convenient). The conditional PDF of 
Z can then be found using the techniques developed for single random variables 
in Chapter 4. Once the conditional PDF of Z is found, the unconditional PDF is 
given by
   or   
.
(5.57)
Next, our attention moves to solving a slightly more general class of problems. Given two 
random variables X and Y, suppose we now create two new random variables W and Z 
according to some 2 × 2 transformation of the general form
(5.58)
The most common example of this type of problem involves changing coordinate systems. 
Suppose, for example, the variables X and Y represent the random position of some object in 
Cartesian coordinates. In some problems, it may be easier to view the object in a polar 
coordinate system, in which case, two new variables 
 and 
 could be created to describe the 
location of the object in polar coordinates. Given the joint PDF of X and Y, how can we find 
the joint PDF of 
 and 
?  
The procedure for finding the joint PDF of 
 and 
 for a general transformation of the form 
given in Equation (5.58) is an extension of the technique used for a 1 × 1 transformation. First, 
Z
g X Y



=
R z 
x y


:g x y



z



=
R z 
fZ z 
d
dz
-----
fX Y

x y


 x
d
y
d
z 
R
=
Z 
 
E ejg X Y





=
fZ z 
fZ Y z y

fY y
  y
d

=
fZ z 
fZ X z x

fX x
  x
d

=
Z
g1 X Y


,
=
W
g2 X Y


.
=
R

R

Z
W

Pairs of Random Variables    215
www.Academicpress.com
recall the definition of the joint PDF given in Equation (5.2) which says that for an infinitesimal 
region 
, the joint PDF, 
, has the interpretation
.
(5.59)
Assume for now that the transformation is invertible. In that case, the transformation maps the 
region 
 into a corresponding region 
 in the (z, w)-plane. Furthermore,
.
(5.60)
Putting the two previous equations together results in
.
(5.61)
A fundamental result of multi-variable calculus states that if a transformation of the form in 
Equation (5.58) maps an infinitesimal region 
, to a region 
, then the ratio of the 
areas of these regions is given by the absolute value of the Jacobian of the transformation,
.
(5.62)
The PDF of Z and W is then given by
.
(5.63)
If it is more convenient to take derivatives of z and w with respect to x and y rather than 
vice-versa, we can alternatively use
,
(5.64)
.
(5.65)
Ax y

x x
x
+



y y
y
+



 
=
fX Y

x y



Pr
X Y



Ax y

!


fX Y

x y


xy
fX Y

x y


 Area of Ax y



=
=
Ax y

Az w

Pr
X Y



Ax y

!


Pr
Z W



Az w

!


fZ W

z w


 Area of Az w



=
=
fZ W

z w



fX Y

x y



Area of Ax y

Area of Az w

-------------------------------
=
Ax y

Az w

Area of Ax y

Area of Az w

-------------------------------
J
x y
z w
	





det
x
z
----- y
z
-----
x
w
------- y
w
-------
=
=
fZ W

z w



fX Y

x y


 J
x y
z w
	





=
Area of Az w

Area of Ax y

-------------------------------
J
z w
x y
	





det
z
x
----- z
y
-----
w
x
------- w
y
-------
=
=
fZ W

z w



fX Y

x y



J
z w
x y
	





----------------------
=

216    Chapter 5
www.Academicpress.com
Whether Equation (5.63) or (5.65) is used, any expressions involving x or y must be replaced 
with the corresponding functions of z and w. Let the inverse transformation of Equation (5.58) 
be written as
.
(5.66)
Then these results can be summarized as
.
(5.67)
If the original transformation is not invertible, then the inverse transformation may have 
multiple roots. In this case, as with transformations involving single random variables, the 
expression in Equation (5.67) must be evaluated at each root of the inverse transformation and 
the results summed together. This general procedure for transforming pairs of random 
variables is demonstrated next through a few examples.
Example 5.23:
A classical example of this type of problem involves the transformation of two 
independent Gaussian random variables from cartesian to polar coordinates. Suppose
.
We seek the PDF of the polar magnitude and phase given by
.
The inverse transformation is
.
In this case, the inverse transformation takes on a simpler functional form and so we 
elect to use this form to compute the Jacobian.
.
The joint PDF of  and 
 is then
X
h1 Z W



=
Y
h2 Z W



=
fZ W

z w



fX Y

x y



J
z w
x y
	





----------------------
=
x
h1 z w



=
y
h2 z w



=
fX Y

x y


 J
x y
z w
	





x
h1 z w



=
y
h2 z w



=
=
fX Y

x y



1
22
------------
x2
y2
+
22
---------------
–
	



exp
=
R
X2
Y2
+
=


tan 1
–
Y X



=
X
R



cos
=
Y
R



sin
=
J
x y
r 
	





det
x
r
----- x

------
y
r
----- y

------
det

 
cos
r

 
sin
–

 
sin
r

 
cos
rcos2 
 
rsin2 
 
+
r
=
=
=
=
R



Pairs of Random Variables    217
www.Academicpress.com
 
,
.
Note that in these calculations, we do not have to worry about taking the absolute value 
of the Jacobian since for this problem the Jacobian (=r) is always nonnegative. If we were 
interested, we could also find the marginal distributions of  and 
 to be
 and 
,  
.
The magnitude follows a Rayleigh distribution while the phase is uniformly distributed 
over 
.
Example 5.24:
Suppose X and Y are independent and both uniformly distributed over 
, so that
Consider forming the two new random variables
The inverse transformation in this case is found to be
In this example, we compute the Jacobian by taking derivatives of z and w with respect to 
x and y to produce
.
Note that since x is always nonnegative, the absolute value of the Jacobian will just be 
. The joint PDF of Z and W is then found to be
fR 

r 



fX Y

x y


 J x y
r 
	





x
h1 r 



=
y
h2 r 



=
r
22
------------
x2
y2
+
22
---------------
–
	



exp
x
r

 
cos
=
y
r

 
sin
=
=
=
r
22
------------
r2
22
---------
–
	



exp
=
r
0
"
0

2
#

R

fR r 
r
2
------
r2
22
---------
–
	


u r 
exp
=
f 
 
1
2
------
=
0

2
#

0 2



0 1



fX Y

x y



1,   0
x y
1,
#


0, otherwise.
$
%
&
=
Z
2
X
 
ln
–
2Y

,
cos
=
W
2
X
 
ln
–
2Y

.
sin
=
X
Z2
W2
+
2
------------------
	



exp
=
Y
1
2
------tan 1
–
W
Z-----
	


 ·
=
J
z w
x y
	





det
z
x
----- z
y
-----
w
x
------- w
y
-------
det
1
x---
–
2y


cos
2
x
 
ln
–
-----------------------
2
2
X
 
ln
–
2Y


sin
–
1
x---
–
2y


sin
2
x
 
ln
–
----------------------- 2
2
X
 
ln
–
2Y


cos
=
=
2
x------ cos2 2y


sin2 2y


+


–
2
x------
–
=
	



=
2 x


(Continued)

218    Chapter 5
www.Academicpress.com
.
This transformation is known as the Box-Muller transformation. It transforms a pair of 
independent uniform random variables into a pair of independent Gaussian random 
variables. This transformation has application in the world of computer simulations.  
Techniques for generating uniform random variables are well known. This 
transformation then allows us to generate Gaussian random variables as well. More 
material on this subject is given in Chapter 12.
Example 5.25:
Suppose X and Y are independent Gaussian random variables, both with zero-mean 
and unit variance. Two new random variables Z and W are formed through a linear 
transformation of the form
.
The inverse transformation is given by
With this general linear transformation, the various partial derivatives are trivial to 
compute and the resulting Jacobian is
.
Plugging these results into the general formula results in
fZ W

z w



fX Y

x y



J
z w
x y
	





----------------------
=
x
h1 z w



=
y
h2 z w



=
x
2
------
x
z2
w2
+
2
----------------
–
	



exp
=
y
1
2
------tan 1
–
w
z----
	 
 
=
1
2
------
z2
w2
+
2
----------------
–
	



exp
=
=
Z
aX
bY
+
=
W
cX
dY
+
=
X
d
ad
bc
–
-----------------Z
b
ad
bc
–
-----------------W,
–
=
Y
c
ad
bc
–
-----------------
–
Z
a
ad
bc
–
-----------------W.
+
=
J
z w
x y
	





det a b
c d
ad
bc
–
=
=
fZ W

z w



fX Y

x y



J
z w
x y
	





----------------------
=
x
h1 z w



=
y
h2 z w



=
1
2
------
x2
y2
+
2
---------------
–
	



exp
ad
bc
–
---------------------------------------- x
d
ad
bc
–
-----------------z
b
ad
bc
–
-----------------w
–
=
y
c
ad
bc
–
-----------------
–
z
a
ad
bc
–
-----------------w
+
=
=
1
2
ad
bc
–

2
-----------------------------------
c2
d2
+

z2
2 bd
ac
+

zw
–
a2
b2
+

w

2
+
2 ad
bc
–

2
-----------------------------------------------------------------------------------------------------
–
	



exp
=



Pairs of Random Variables    219
www.Academicpress.com
With a little algebraic manipulation, it can be shown that this joint PDF fits the general 
form of a joint Gaussian PDF. In particular, 
,
where 
, 
, and 
. 
A few remarks about the significance of the result of Example 5.25 are appropriate. First, we 
have performed an arbitrary linear transformation on a pair of independent Gaussian random 
variables and produced a new pair of Gaussian random variables (which are no longer 
independent). In the next chapter, it will be shown that a linear transformation of any number of 
jointly Gaussian random variables always produces jointly Gaussian random variables. Second, 
if we look at this problem in reverse, two correlated Gaussian random variables Z and W can be 
transformed into a pair of uncorrelated Gaussian random variables X and Y using an appropriate 
linear transformation. More information will be given on this topic in the next chapter as well.
5.10  Complex Random Variables
In engineering practice, it is common to work with quantities which are complex. Usually, a 
complex quantity is just a convenient shorthand notation for working with two real quantities. For 
example, a sinusoidal signal with amplitude, A, frequency, , and phase, , can be written as
,
(5.68)
where 
. The complex number 
 is known as a phasor representation of the 
sinusoidal signal. It is a complex number with real part of 
 and 
imaginary part of 
. The phasor Z can be constructed from two real 
quantities (either 
 and  or X and Y).
Suppose a complex quantity we are studying is composed of two real quantities which happen 
to be random. For example, the sinusoidal signal above might have a random amplitude and/or 
a random phase. In either case, the complex number Z will also be random. Unfortunately, our 
formulation of random variables does not allow for complex quantities. When we began to 
describe a random variable via its CDF in the beginning of Chapter 3, the CDF was defined as 
. This definition makes no sense if Z is a complex number: what does it 
mean for a complex number to be less that another number? Nevertheless, the engineering 
literature is filled with complex random variables and their distributions. 
The concept of a complex random variable can often be the source of great confusion to many 
students, but it does not have to be as long as we realize that a complex random variable is nothing 
more than a shorthand representation of two real random variables. To motivate the concept of a 
fZ W

z w



1
2ZW 1

–
ZW
2
-------------------------------------------
z Z


2
2ZW z Z


 w w



–
w w


2
+
2 1

–
ZW
2


---------------------------------------------------------------------------------------------------
–
	





exp
=
Z
2
a2
b2
+
=
W
2
c2
d2
+
=
WZ
2
ac
bd
+

2 a2
b2
+

 1
–
c2
d2
+

 1
–
=


s t 
A
t

+


cos
Re Aejejt


=
=
j
1
–
=
Z
Aej
=
X
Re Z
 
A

 
cos
=
=
Y
Im Z
 
A

 
sin
=
=
A

FZ z 
Pr Z
z



=


220    Chapter 5
www.Academicpress.com
complex random variable, we use the most common example of a pair of independent, equal 
variance, jointly Gaussian random variables, X and Y. The joint PDF is of the form
.
(5.69)
This joint PDF (of two real random variables) naturally lends itself to be written in terms of 
some complex variables. Define 
, 
 and 
. Then,
.
(5.70)
We reemphasize at this point that this is not to be interpreted as the PDF of a complex random 
variable (since such an interpretation would make no sense); rather, this is just a compact 
representation of the joint PDF of two real random variables. This density is known as the 
circular Gaussian density function (since the contours of 
 form circles in the 
complex z-plane).
Note that the PDF in Equation (5.70) has two parameters, 
 and 
. The parameter 
 is 
interpreted as the mean of the complex quantity, 
,
.
(5.71)
But what about 
? We would like to be able to interpret it as the variance of 
. To 
do so, we need to redefine what we mean by variance of a complex quantity. If we used the 
definition we are used to (for real quantities) we would find
.
(5.72)
In the case of our independent Gaussian random variables, since 
 and 
, this would lead to 
. To overcome this inconsistency, we 
redefine the variance for a complex quantity as follows.
Definition 5.13: For a complex random quantity, 
, the variance is defined as
.
(5.73)
We emphasize at this point that this definition is somewhat arbitrary and was chosen so that 
the parameter 
 which shows up in Equation (5.70) can be interpreted as the variance of Z. 
Many textbooks do not include the factor of 1/2 in the definition, while many others 
fX Y

x y



1
22
-------------
x
X
–

2
y
Y
–

2
+
22
------------------------------------------------
–
	





exp
=
Z
X
jY
+
=
z
x
jy
+
=
Z
X
jY
+
=
fX Y

x y



fZ z 
1
22
-------------
z
Z
–
2
22
------------------
–
	





exp
=
=
fZ z 
constant
=
Z

Z
Z
X
jY
+
=
Z
E Z
 
E X
jY
+


x
jy
+

fX Y

x y


 x
d
y
d

X
jY
+
=
=
=
=
2
Z
X
jY
+
=
E
Z
Z
–

2


E
X
X
–


j Y
Y
–


+

2


Var X
 
Var Y
 
–
2jCov X Y



+
=
=
Cov X Y



0
=
Var X
 
Var Y
 
=
E
Z
Z
–

2


0
=
Z
X
jY
+
=
Var Z
 
1
2---E Z
Z
–
2


1
2---Var X
 
1
2---Var Y
 
+
=
=
2

Pairs of Random Variables    221
www.Academicpress.com
(besides this one) do include the 1/2. Hence, there seems to be no way to avoid a little bit 
of confusion here. The student just needs to be aware that there are two inconsistent 
definitions prevalent in the literature.
Definition 5.14: For two complex random variables 
 and 
, the correlation and covariance are defined as
,
(5.74)
.
(5.75)
As with real random variables, complex quantities are said to be orthogonal if their
correlation is zero, whereas they are uncorrelated if their covariance is zero.
5.11  Engineering Application: Mutual Information, Channel 
Capacity, and Channel Coding
In Section 4.12, we introduced the idea of the entropy of a random variable which is a 
quantitative measure of how much randomness there is in a specific random variable. If the 
random variable represents the output of a source, the entropy tells us how much mathematical 
information there is in each source symbol. We can also construct similar quantities to 
describe the relationships between random variables. Consider two random variables 
 and  
that are statistically dependent upon one another. Each random variable has a certain entropy 
associated with it, 
 and 
, respectively. Suppose it is observed that 
. Since 
 and 
 are related, knowing 
 will tell us something about 
 and hence the amount of 
randomness in 
 will be changed. This could be quantified using the concept of conditional 
entropy.
Definition 5.15: The conditional entropy of a discrete random variable 
 given 
knowledge of a particular realization of a related random variable 
 is
.
(5.76)
Averaging over all possible conditioning events produces
.
(5.77)
Z1
X1
jY1
+
=
Z2
X2
jY2
+
=
R1 2

1
2---E Z1Z2
*


1
2--- E X1X2


E Y1Y2


jE X1Y2


–
jE X2Y1


+
+


=
=
C1 2

1
2---E
Z1
Z1
–

 Z2
Z2
–

*


=
X
Y
H X
 
H Y
 
Y
y
=
X
Y
Y
X
X
X
Y
y
=
H X Y = y


Pr X = x Y = y


1
Pr X = x Y = y


-----------------------------------
	



log
x
=
H X Y


Pr Y = y

Pr X = x Y = y


1
Pr X = x Y = y


-----------------------------------
	



log
y
x
=
Pr X = x Y = y



1
Pr X = x Y = y


-----------------------------------
	



log
y
x
=

222    Chapter 5
www.Academicpress.com
The conditional entropy tells how much uncertainty remains in the random variable 
 after 
we observe the random variable 
. The amount of information provided about 
 by 
observing 
 can be determined by forming the difference between the entropy in 
 before 
and after observing 
.
Definition 5.16: The mutual information between two discrete random variables 
and 
 is 
.
(5.78)
We leave it as an exercise for the reader to prove the following properties of mutual 
information:
•
Nonnegative: 
.
•
Independence: 
 if and only if 
 and 
 are independent.
•
Symmetry: 
.
Now we apply the concept of mutual information to a digital communication system. 
Suppose we have some digital communication system which takes digital symbols from 
some source (or from the output of a source encoder) and transmits them via some 
modulation format over some communications medium. At the receiver, a signal is received 
and processed and ultimately a decision is made as to what symbol(s) was most likely sent. 
We will not concern ourselves with the details of how the system operates, but rather we 
will model the entire process in a probabilistic sense. Let 
 represent the symbol to be sent, 
which is randomly drawn from some -letter alphabet according to some distribution 
p = (p0, p1, …, pn–1). Furthermore, let 
 represent the decision made by the receiver, with 
 taken to be a random variable on an 
-letter alphabet. It is not unusual to have 
, but 
in order to keep this discussion as simple as possible, we will only consider the case where 
 so that the input and output of our communication system are taken from the same 
alphabet. Also, we assume the system to be memoryless so that decisions made on one 
symbol are not affected by previous decisions nor do they affect future decisions. In that 
case, we can describe the operation of the digital communication system using a transition 
diagram as illustrated in Figure 5.7 for a three-letter alphabet. Mathematically, the operation 
of this communication system can be described by a matrix 
 whose elements are 
.    
X
Y
X
Y
X
Y
X
Y
I X Y
;


H X
 
H X Y


–
Pr X = x Y = y



Pr X = x Y = y


Pr X = x


-----------------------------------
	



log
y
x
=
=
I X Y
;


0
"
I X Y
;


0
=
X
Y
I X Y
;


I Y  X
;


=
X
n
Y
Y
m
m
n

m
n
=
Q
qi j
Pr Y = i X = j


=

Pairs of Random Variables    223
www.Academicpress.com
We can now ask ourselves how much information does the communication system carry? 
Or, in other words, if we observe the output of the system, how much information does this 
give us about what was really sent? The mutual information answers this question. In terms 
of the channel (as described by Q) and the input (as described by p), the mutual 
information is
.
(5.79)
Note that the amount of information carried by the system is a function not only of the channel 
but also of the source. As an extreme example, suppose the input distribution were 
. In that case it is easy to show that 
; that is, the communication 
system carries no information. This is not because the communication system is incapable of 
carrying information, but because what we are feeding into the system contains no information. 
To describe the information carrying capability of a communication channel, we need a quantity 
which is a function of the channel only and not of the input to the channel. 
Definition 5.17: Given a discrete communications channel described by a transition
probability matrix Q, the channel capacity is given by
.
(5.80)
The maximization of the mutual information is with respect to any valid probability
distribution p. 
0
1
2
0
1
2
q0,0
q0,1
q0,2
q1,0
q1,1
q1,2
q2,0
q2,1
q2,2
Q
q0,0 q0,1 q0,2
q1,0 q1,1 q1,2
q2,0 q2,1 q2,2
=
Figure 5.7  
A transition diagram for a ternary (three-letter) communication channel.
I X Y



pjqi j
qi j
'
k qi k
 pk
--------------------
	





log
j
i
=
p
1 0  0
 



=
I X Y



0
=
C
I X Y
;


p
max
pjqi j
qi j
'
k qi k
 pk
--------------------
	





log
j
i
p
max
=
=

224    Chapter 5
www.Academicpress.com
Example 5.26:
As a simple example, consider the so-called binary symmetric channel (BSC) described 
by the transition probability matrix 
.
The BSC is described by a single parameter , which has the interpretation of the 
probability of bit error of the binary communications system. That is,  is the 
probability of the receiver deciding a 0 was sent when a 1 was actually sent and it is also 
the probability of the receiver deciding a 1 was sent when a 0 was actually sent. Since the 
input to this channel is binary, its distribution can also be described by a single 
parameter.  That is, 
. Likewise, the output of the channel is also binary and 
thus can be described in terms of a single parameter,
 where 
. The mutual information for the BSC is
.
Some straightforward algebraic manipulations reveal that the above expression can be 
simplified to 
, where 
 is the binary entropy function. Maximization 
with respect to  is now straightforward. The mutual information is maximized when the 
output distribution is 
 and the resulting capacity is
.
Due to the symmetry of the channel, the output distribution will be symmetric when the 
input distribution is also symmetric, 
.This function is illustrated in Figure 5.8.  
Q
1
q
–
q
q
1
q
–
=
q
q
p
p 1
p
–



=
r
r 1
r
–



=
r
P
=
r Y
0
=


p 1
q
–


q 1
p
–


+
=
I X Y
;


p 1
q
–


1
q
–
r
-----------
	



log
pq
q
r---
	 
 
log
1
p
–

 1
q
–


1
q
–
1
r
–
-----------
	



log
1
p
–

q
q
1
r
–
----------
	



log
+
+
+
=
I X Y
;


r 
q
 
–
=
. 
p
r
0.5 0.5



=
C
1
q
 
–
=
p
0.5 0.5



=
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
q
C= 1 −H(q)
Figure 5.8  
Capacity of a binary symmetric channel.



Pairs of Random Variables    225
www.Academicpress.com
The channel capacity provides a fundamental limitation on the amount of information that can 
reliably be sent over a channel. For example, suppose we wanted to transmit information 
across the BSC of Example 5.26. Furthermore, suppose the error probability of the channel 
was 
. Then the capacity is 
bits. That is, every physical bit that is 
transmitted across the channel must contain less than 0.53 bits of mathematical information. 
This is achieved through the use of redundancy via channel coding. Consider the block 
diagram of the digital communication system in Figure 5.9. The binary source produces 
independent bits which are equally likely to be “0” or “1.” This source has an entropy of 1 bit/
source symbol. Since the channel has a capacity of 0.53 bits, the information content of the 
source must be reduced before these symbols are sent across the channel. This is achieved by 
the channel coder which takes blocks of  information bits and maps them to  bit code 
words where 
. Each code word contains  bits of information and so each coded bit 
contains 
 bits of mathematical information. By choosing the code rate, 
, to be less than 
the channel capacity, 
, we can assure that the information content of the symbols being input 
to the channel is no greater than the information carrying capability of the channel.  
Viewed from a little more concrete perspective, the channel used to transmit physical bits has 
an error rate of 10%. The purpose of the channel code is to add redundancy to the data stream 
to provide the ability to correct the occasional errors caused by the channel. A fundamental 
result of information theory known as the channel coding theorem states that as  and  go to 
infinity in such a way that 
, it is possible to construct a channel code (along with the 
appropriate decoder) which will provide error-free communication. That is, the original 
information bits will be provided to the destination with arbitrarily small probability of error. 
The channel coding theorem does not tell us how to construct such a code, but significant 
progress has been made in recent years towards finding practical techniques to achieve what 
information theory promises is possible.
q
0.1
=
C
1
0.1


–
0.53
=
=
k
n
n
k
(
k
k n

k n

C
Binary
Source
(n,k)
Encoder
BSC
q = 0.1
Decoder
Destination
Figure 5.9 
A functional block diagram of a digital communication system.
k
n
k n

C
#

CHAPTER 5
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
227
Exercises
Section 5.1:  Joint CDFs
5.1
Recall the joint CDF given in Example 5.1, 
(a)
Find 
.
(b)
Find 
.
(c)
Find 
.
(d)
Find 
.
5.2
A colleague of your proposes that a certain pair of random variables be modeled with a 
joint CDF of the form
.
(a)
Find any restrictions on the constants , , and  needed for this to be a valid 
joint CDF.
(b)
Find the marginal CDFs, 
 and 
 under the restrictions found in part (a).
5.3
Consider again the joint CDF given in Exercise 5.2.
(a)
For constants  and , such that 
, 
 and 
, find 
.
(b)
For constants  and , such that 
, 
 and 
, find 
.
(c)
Find 
.  Are the events 
 and 
 
statistically independent?
FX Y
,
x y
,
(
)
0,
x
0 or y
0,      
<
<
x,
0
x
1 y
1,    
>
,
≤
≤
y,
x
1
>
0
y
1,    
≤
≤
,
xy,
0
x
1 0
y
1,
≤
≤
,
≤
≤
1,
x
1 y
1.          
>
,
>







=
Pr X
3 4
⁄
<
(
)
Pr X
1 2
⁄
>
(
)
Pr Y
1 4
⁄
>
(
)
Pr 1 4
X
<
⁄
1 2
⁄
<
1 2
⁄
Y
1
<
<
,
(
)
FX Y
,
x y
,
(
)
1
ae x
–
–
be y
–
–
ce
x
y
+
(
)
–
+
[
]u x
( )u y
( )
=
a b
c
FX x
( )
FY y
( )
a
b
0
a
1
<
<
0
b
1
<
<
a
b
<
Pr a
X
b
<
<
(
)
c
d
0
c
1
<
<
0
d
1
<
<
c
d
<
Pr c
Y
d
<
<
(
)
Pr a
X
b c
Y
d
<
<
<
<
(
)
a
X
b
<
<
{
}
c
Y
d
<
<
{
}

228    Chapter 5
www.Academicpress.com
5.4
Suppose a random variable 
 has a CDF given by 
 and similarly, a random variable 
 has a CDF, 
.  Prove that the function 
 satisfies all the 
properties required of joint CDFs and hence will always be a valid joint CDF.
5.5
For the joint CDF that is the product of two marginal CDFs, 
, 
as described in Exercise 5.4, show that the events 
 and 
 are always 
independent for any constants 
 and 
.
Section 5.2:  Joint PDFs
5.6
For positive constants  and , a pair of random variables has a joint PDF specified by 
.  
(a)
Find the joint CDF, 
.
(b)
Find the marginal PDFs, 
 and 
.  
(c)
Find 
.
(d)
Find 
.
5.7
For positive constants , , , and positive integer , a pair of random variables has a 
joint PDF specified by 
.
(a)
Find the constant  in terms of , , , and . 
(b)
Find the marginal PDFs, 
 and 
.  
(c)
Find 
.
5.8
A pair of random variables has a joint PDF specified by 
.
(a)
Find the constant  in terms of , , and .  Also, find any restrictions needed for 
, , and  themselves for this to be a valid PDF.
(b)
Find the marginal PDFs, 
 and 
.  
(c)
Find 
.
5.9
A pair of random variables has a joint PDF specified by
X
FX x
( )
Y
FY y
( )
F x y
,
(
)
FX x
( )FY y
( )
=
FX Y
,
x y
,
(
)
FX x
( )FY y
( )
=
a
X
b
<
<
{
}
c
Y
d
<
<
{
}
a
b
<
c
d
<
a
b
fX Y
,
x y
,
(
)
abe
ax
by
+
(
)
–
u x
( )u y
( )
=
FX Y
,
x y
,
(
)
fX x
( )
fY y
( )
Pr X
Y
>
(
)
Pr X
Y2
>
(
)
a b c
n
fX Y
,
x y
,
(
)
d
ax
by
c
+
+
(
)n
-----------------------------------u x
( )u y
( )
=
d
a b c
n
fX x
( )
fY y
( )
Pr X
Y
>
(
)
fX Y
,
x y
,
(
)
d
ax2
bxy
cy2
+
+
(
)
–
(
)
exp
=
d
a b
c
a b
c
fX x
( )
fY y
( )
Pr X
Y
>
(
)
fX Y
,
x y
,
(
)
c 1
x2
–
y2
–
,    x2
y2
+
1,
≤
0,
   otherwise.





=

Exercises    229
www.Academicpress.com
(a)
Find the constant .
(b)
Find 
.
(c)
Find 
.
5.10 A pair of random variables has a joint PDF specified by
.
(a)
Find 
.
(b)
Find 
.
(c)
Find 
  Hint: Set up the appropriate double integral and then use the 
change of variables: 
, 
.
5.11 A pair of random variables, 
, is equally likely to fall anywhere in the ellipse 
described by 
.
(a)
Write the form of the joint PDF, 
.
(b)
Find the marginal PDFs, 
 and 
.
(c)
Find 
 and 
(d)
Find 
.  Are the events 
 and 
 independent?
5.12 A pair of random variables, 
, is equally likely to fall anywhere within the region 
defined by 
.
(a)
Write the form of the joint PDF, 
.
(b)
Find the marginal PDFs, 
 and 
.
(c)
Find 
 and 
(d)
Find 
.  Are the events 
 and 
 
independent?
Section 5.3:  Joint PMFs
5.13 For some integer 
 and constant , two discrete random variables have a joint PMF 
given by
(a)
Find the value of the constant  in terms of 
.
(b)
Find the marginal PMFs, 
 and 
.
(c)
Find 
.
c
Pr X2
Y2
+
1 4
⁄
>
(
)
Pr X
Y
>
(
)
fX Y
,
x y
,
(
)
1
8π
------
x
1
–
(
)2
y
1
+
(
)2
+
8
---------------------------------------------
–



	
exp
=
Pr X
2
>
Y
0
<
,
(
)
Pr 0
X
2
<
<
Y
1
+
2
>
,
(
)
Pr Y
X
>
(
)
u
x
y
–
=
v
x
y
+
=
X Y
,
(
)
9X2
4Y2
+
36
<
fX Y
,
x y
,
(
)
fX x
( )
fY y
( )
Pr X
1
>
(
)
Pr Y
1
<
(
)
Pr Y
1
<
X
1
>
(
)
X
1
>
{
}
Y
1
<
{
}
X Y
,
(
)
X
Y
+
1
≤
fX Y
,
x y
,
(
)
fX x
( )
fY y
( )
Pr X
1 2
⁄
>
(
)
Pr Y
1 2
⁄
<
(
)
Pr Y
1 2
⁄
<
X
1 2
⁄
>
(
)
X
1 2
⁄
>
{
}
Y
1 2
⁄
<
{
}
L
c
PM N
,
m n
,
(
)
c,     m
0 n
0 m
n
L,
<
+
,
≥
,
≥
0,
otherwise.                



=
c
L
PM m
(
)
PN n
( )
Pr M
N
+
L 2
⁄
<
(
)

230    Chapter 5
www.Academicpress.com
5.14 Two discrete random variables have a joint PMF as described in the following table.
(a)
Find the marginal PDFs, 
 and 
.
(b)
Find 
.
(c)
Find 
.
(d)
Find 
.
5.15 For a constant , two discrete random variables have a joint PMF given by
(a)
Find the value of the constant  in terms of .
(b)
Find the marginal PMFs, 
 and 
.  
(c)
Find 
.
5.16 Let 
 be a random variable that follows a Poisson distribution, so that for some constant 
, its PMF is 
,  
.
Let 
 be another random variable that, given 
, is equally likely to take on any 
value in the set 
.
(a)
Find the joint PMF of 
 and 
.
(b)
Find the marginal PMF of 
, 
. Plot your result for 
.
1/5
7/45
1/9
8/45
4/45
2/45
2/15
1/15
1/45
PM N
,
m n
,
(
)
m
1
=
m
2
=
m
3
=
n
1
=
n
2
=
n
3
=
PM m
(
)
PN n
( )
Pr N = 1 M = 2
(
)
Pr M =N
(
)
Pr M
N
>
(
)
k
PM N
,
m n
,
(
)
c,     m n
,
= 0 1 2 … k
1,
–
, , ,
,
0,
otherwise.                



=
c
k
PM m
(
)
PN n
( )
Pr M
N
+
k 2
⁄
<
(
)
M
α
PM m
(
)
αm
m!
-------e α
–
=
m
0 1 2 …
, , ,
=
N
M
m
=
0 1 2 … m
, , ,
,
{
}
M
N
N
PN n
( )
α
1
=

Exercises    231
www.Academicpress.com
Section 5.4:  Conditional Distribution, Density and Mass Functions
5.17 For the discrete random variables whose joint PMF is described by the table in Exercise 
5.14, find the following conditional PMFs:
(a)
;
(b)
;
(c)
.
5.18 Consider again the random variables in Exercise 5.11 that are uniformly distributed over 
an ellipse.
(a)
Find the conditional PDFs, 
 and 
.
(b)
Find 
.
(c)
Find 
.
5.19 Recall the random variables of Exercise 5.12 that are uniformly distributed over the 
region 
.
(a)
Find the conditional PDFs, 
 and 
.
(b)
Find the conditional CDFs, 
 and 
.
(c)
Find 
 and 
.
5.20 Suppose a pair of random variables 
 is 
uniformly distributed over a rectangular 
region, A: 
, 
.  Find the 
conditional PDF of 
 given the 
conditioning event 
, where the 
region 
 is an arbitrary region completely 
contained within the rectangle 
 as shown in 
the accompanying figure.  
Section 5.5: Expected Values Involving Pairs of Random Variables
5.21   A pair of random variables has a joint PDF specified by
.
(a)
Find the marginal PDFs, 
 and 
.
(b)
Based on the results of part (a), find 
, 
, 
, and 
.
(c)
Find the conditional PDF, 
.
(d)
Based on the results of part (c), find 
, 
, and 
.
PM m N
2
=
(
)
PM m N
2
≥
(
)
PN n M
2
≠
(
)
fX Y x y
(
)
fY X y x
(
)
fX Y
1
>
x
( )
fY
X
1
<
{
} y
( )
X
Y
+
1
≤
fX Y x y
(
)
fY X y x
(
)
FX Y x y
(
)
FY X y x
(
)
fX
Y
1 2
⁄
>
{
} x
( )
FX
Y
1 2
⁄
>
{
} x
( )
x
y
x1
x2
y1
y2
A
B
X Y
,
(
)
x1
X
x2
<
<
y1
Y
y2
<
<
X Y
,
(
)
X Y
,
(
)
B
∈
B
A
fX Y
,
x y
,
(
)
1
2π 3
--------------
x2
2xy
4y2
+
+
6
------------------------------------
–



	
exp
=
fX x
( )
fY y
( )
E X
[ ] E Y
[ ] Var X
( )
Var Y
( )
fX Y x y
(
)
E XY
[
] Cov X Y
,
(
)
ρX Y
,

232    Chapter 5
www.Academicpress.com
5.22 A pair of random variables is uniformly distributed over the ellipse defined by 
.  
(a)
Find the marginal PDFs, 
 and 
.
(b)
Based on the results of part (a), find 
, 
, 
, and 
.
(c)
Find the conditional PDFs, 
 and 
.
(d)
Based on the results of part (c), find 
, 
, and 
.
5.23 Prove that if two random variables are linearly related (i.e., 
 for constants 
 and ), then 
Also, prove that if two random variables have 
, then they are linearly related.
5.24 Prove the triangle inequality which states that
.
5.25 Two random variables 
 and 
 have, 
, 
, 
, 
, and 
.  Let 
 and 
.  Find the following quantities:
(a)
 and 
;
(b)
, 
, 
, and 
;
(c)
, 
, and 
.
5.26 Suppose two random variables are related by 
 and assume that 
 is 
symmetric about the origin.  Show that 
.
5.27 Let 
 and 
 be random variables with means 
 and 
, variances 
 and 
, and 
correlation coefficient 
.  
(a)
Find the value of the constant  which minimizes 
.
(b)
Find the value of 
 when  is given as determined in part (a).
5.28 For the discrete random variables whose joint PMF is described by the table in Exercise 
5.14, compute the following quantities:
(a)
;
(b)
;
(c)
;
(d)
.
x2
4y2
+
1
≤
fX x
( )
fY y
( )
E X
[ ] E Y
[ ] Var X
( )
Var Y
( )
fX Y x y
(
)
fY X y x
(
)
E XY
[
] Cov X Y
,
(
)
ρX Y
,
Y
aX
b
+
=
a
0
≠
b
ρX Y
,
a
( )
sgn
1,   if a
0,
>
1,
–
  if a
0.
<



=
=
ρX Y
,
1
=
E
X
Y
+
(
)2
[
]
E X2
[
]
E Y2
[
]
+
≤
X
Y
μX
2
=
μY
1
–
=
σX
1
=
σY
4
=
ρX Y
,
1 4
⁄
=
U
X
2Y
+
=
V
2X
Y
–
=
E U
[
]
E V
[ ]
E U2
[
] E V2
[
] Var U
(
)
Var V
( )
E UV
[
] Cov U V
,
(
)
ρU V
,
Y
aX2
=
fX x
( )
ρX Y
,
0
=
X
Y
μX
μY
σX
2
σY
2
ρX Y
,
a
E
Y
aX
–
(
)2
[
]
E
Y
aX
–
(
)2
[
]
a
E XY
[
]
Cov X Y
,
(
)
ρX Y
,
E Y X
[
]

Exercises    233
www.Academicpress.com
5.29 Let 
 be a phase angle which is uniformly distributed over 
.  Suppose we form 
two new random variables according to 
 and 
 for some 
constant .  
(a)
For what values of the constant  are the two random variables 
 and 
 
orthogonal?
(b)
For what values of the constant  are the two random variables 
 and 
 
uncorrelated?
5.30 Suppose two random variables 
 and 
 are both zero mean and unit variance.  
Furthermore, assume they have a correlation coefficient of 
.  Two new random 
variables are formed according to:
,
.
Determine under what conditions on the constants , , , and  the random variables 
 and 
 are uncorrelated.
Section 5.6: Independent Random Variables
5.31 Find an example (other than the one given in Example 5.15) of two random variables that 
are uncorrelated but not independent.
5.32 Determine whether or not each of the following pairs of random variables are 
independent:
(a)
The random variables described in Exercise 5.6;
(b)
The random variables described in Exercise 5.7;
(c)
The random variables described in Exercise 5.14;
(d)
The random variables described in Exercise 5.13.
5.33 Consider two discrete random variables 
 and 
 which take on values from the set 
.  Suppose we construct an 
 matrix 
 whose elements comprise the 
joint PMF of the two random variables.  That is, if 
 is the element in the th row and 
th column of 
, then 
.  
(a)
Show that if 
 and 
 are independent random variables, then the matrix 
 can be 
written as an outer product of two vectors.  What are the components of the outer 
product?
(b)
Show that the converse is also true. That is, show that if 
 can be factored as an 
outer product, the two random variables are independent.
Θ
0 2π
,
(
)
X
aΘ
(
)
cos
=
Y
aΘ
(
)
sin
=
a
a
X
Y
a
X
Y
X
Y
ρ
W
aX
bY
+
=
Z
cX
dY
+
=
a b c
d
W
Z
X
Y
1 2 3 … k
, , ,
,
{
}
n
n
×
P
pi j,
i
j
P
pi j,
PX Y
,
i j,
(
)
Pr X=i Y=j
,
(
)
=
=
X
Y
P
P

234    Chapter 5
www.Academicpress.com
5.34 Two fair dice are rolled.  Let one of the dice be red and the other green so that we can tell 
them apart.  Let 
 be the sum of the two values shown on the dice and 
 be the 
difference (red minus green) of the two values shown on the dice.  Determine whether 
these two random variables are independent or not.  Does you answer make sense?  
Section 5.7:  Joint Gaussian Random Variables
5.35 Starting from the general form of the joint Gaussian PDF in Equation (5.40), show that 
the resulting marginal PDFs are both Gaussian.
5.36 Starting from the general form of the joint Gaussian PDF in Equation (5.40) and using 
the results of Exercise 5.35, show that conditioned on 
, 
 is Gaussian with a 
mean of 
 and a variance of 
.
5.37 Two random variables are jointly Gaussian with means of 
, 
, variances 
of 
, 
, and a covariance of 
.  
(a)
Write the form of the joint PDF of these jointly Gaussian random variables.
(b)
Find the marginal PDFs, 
 and 
.
(c)
Find 
 and 
 and write both in terms of Q-functions.
5.38 Two random variables have a joint Gaussian PDF given by
.
(a)
Identify 
, 
, and 
.
(b)
Find the marginal PDFs, 
 and 
.
(c)
Find the conditional PDFs, 
 and 
.
5.39 Two random variables have a joint Gaussian PDF given by
.
Find 
, 
, 
, 
, 
, 
, and 
.
X
Y
Y
y
=
X
μX
ρXY σX σY
⁄
(
) y
μY
–
(
)
+
σX
2 1
ρXY
2
–
(
)
μX
2
=
μY
3
–
=
σX
2
1
=
σY
2
4
=
Cov X Y
,
(
)
1
–
=
fX x
( )
fY y
( )
Pr X
0
<
(
)
Pr Y
0
>
(
)
fX Y
,
x y
,
(
)
9
2π 2
--------------
36x2
36xy
–
81y2
+
16
------------------------------------------------
–



	
exp
=
σX
2
σY
2
ρX Y
,
fX x
( )
fY y
( )
fX Y x y
(
)
fY X y x
(
)
fX Y
,
x y
,
(
)
1
6π 5
--------------
3x3
3y2
4xy
–
14x
16y
–
7
+
+
+
30
------------------------------------------------------------------------------
–



	
exp
=
E X
[ ] E Y
[ ] Var X
( ) Var Y
( ) ρX Y
,
Cov X Y
,
(
)
E XY
[
]

Exercises    235
www.Academicpress.com
Section 5.8:  Joint Characteristic and Related Functions
5.40 Let 
 and 
 be zero-mean jointly Gaussian random variables with a correlation 
coefficient of 
 and unequal variances of 
 and 
.  
(a)
Find the joint characteristic function, 
.
(b)
Using the joint characteristic function, find the correlation, 
.
(c)
Find 
.
5.41 Find the general form of the joint characteristic function of two jointly Gaussian random 
variables.
5.42 A pair of random variables has a joint characteristic function given by
.
(a)
Find 
 and 
.
(b)
Find 
 and 
.
(c)
Find 
 and 
.
5.43 A pair of random variables has a joint characteristic function given by
.
(a)
Find 
 and 
.
(b)
Find 
 and 
.
(c)
Find 
and 
.
5.44
(a)
Find the joint PGF for the pair of discrete random variables given in Exercise 5.13.
(b)
From the result of part (a), find 
 and 
.
(c)
From the result of part (a), find 
.
5.45 A pair of discrete random variables has a PGF given by
.
(a)
Find the means, 
 and 
.
(b)
Find the correlation, 
.
(c)
Find the joint PMF, 
.
X
Y
ρ
σX
2
σY
2
ΦX Y
,
ω1 ω2
,
(
)
E XY
[
]
E X2Y2
[
]
ΦX Y
,
ω1 ω2
,
(
)
1
1
2jω1
–
(
) 1
2jω2
–
(
)
----------------------------------------------------
=
E X
[ ]
E Y
[ ]
E XY
[
]
Cov X Y
,
(
)
E X2Y2
[
]
E XY3
[
]
ΦX Y
,
ω1 ω2
,
(
)
1
2--- 4ω1
2
ω1ω2
–
9ω2
2
+
(
)
–



	
exp
=
E X
[ ]
E Y
[ ]
E XY
[
]
Cov X Y
,
(
)
E X2Y2
[
]
E XY3
[
]
E M
[
]
E N
[
]
E MN
[
]
HM N
,
z1 z2
,
(
)
4
4
z1
–
z2
–
(
)2
--------------------------------
=
E M
[
]
E N
[
]
E MN
[
]
PM N
,
m n
,
(
)

236    Chapter 5
www.Academicpress.com
5.46 The joint moment-generating function (MGF) for two random variables, 
 and 
, is 
defined as
.
Develop an equation to find the mixed moment 
 from the joint MGF.
5.47
(a)
Given the joint characteristic function of a pair of random variables, 
.  
How do we get a marginal characteristic function of one of the random variables, say 
, from the joint characteristic function?
(b)
Repeat part (a) for the joint PGF, 
.
Section 5.9: Transformations of Pairs of Random Variables
5.48 A quarterback throws a football at a target marked out on the ground 40 yards from his 
position. Assume that the PDF for the football’s hitting the target is Gaussian within the 
plane of the target. Let the coordinates of the plane of the target be denoted by the  and 
 axes. Thus, the joint PDF of 
 is a two-dimensional Gaussian PDF. The average 
location of the hits is at the origin of the target, and the standard deviation in each 
direction is the same and is denoted as 
.  Assuming 
 and 
 are independent, find the 
probability that the hits will be located within an annular ring of width 
 located a 
distance  from the origin; that is, find the probability density function for hits as a 
function of the radius from the origin. 
5.49 Let 
 and 
 be independent and both exponentially distributed with 
.
Find the PDF of 
.
5.50 Let 
 and 
 be jointly Gaussian random variables.  Show that 
 is also a 
Gaussian random variable.  Hence, any linear transformation of two Gaussian random 
variables produces a Gaussian random variable.
5.51 Let 
 and 
 be jointly Gaussian random variables with 
, 
, 
, 
, and 
. Find the PDF of 
.   
Hint: To simplify this problem, use the result of Exercise 5.50.
X
Y
MX Y
,
u1 u2
,
(
)
E
u1X
u2Y
+
(
)
exp
[
]
fX Y
,
x y
,
(
)
u1X
u2Y
+
(
)
exp
x
d
y
d
∞
–
∞

∞
–
∞

=
=
E XnYm
[
]
ΦX Y
,
ω1 ω2
,
(
)
ΦX ω
(
)
HX Y
,
z1 z2
,
(
)
x
y
X Y
,
(
)
σ
X
Y
dr
r
X
Y
fX v
( )
fY v
( )
be bv
–
u v
( )
=
=
Z
X
Y
–
=
X
Y
Z
aX
bY
+
=
X
Y
E X
[ ]
1
=
E Y
[ ]
2
–
=
Var X
( )
4
=
Var Y
( )
9
=
ρX Y
,
1 3
⁄
=
Z
2X
3Y
–
5
–
=

Exercises    237
www.Academicpress.com
5.52 Let 
 and 
 be independent Rayleigh random variables such that
.
(a)
Find the PDF of 
.
(b)
Find the PDF of 
.
5.53 Suppose 
 is a Rayleigh random variable and 
 is an arcsine random variable, so that
  and   
,  
.
Furthermore, assume 
 and 
 are independent.  Find the PDF of 
.
5.54 Let 
 and 
 be independent and both uniformly distributed over 
.  Find the PDF 
of 
.
5.55 Let 
 be a Gaussian random variable and let 
 be a Bernoulli random variable with 
 and 
.  If 
 and 
 are independent, find the PDF of 
.  Under what conditions is 
 a Gaussian random variable?
5.56 Let 
 and 
 be independent zero-mean, unit-variance Gaussian random variables.  
Consider forming the new random variable 
 according to
,
.
Note that this transformation produces a coordinate rotation through an angle of .  Find 
the joint PDF of 
 and 
.  Hint: The result of Example 5.25 will be helpful here.
5.57 Let 
 and 
 be zero-mean, unit-variance Gaussian random variables with correlation 
coefficient, 
.  Suppose we form two new random variables using a linear 
transformation:
,
.
Find constraints on the constants , , , and  such that 
 and 
 are independent.
5.58 Suppose 
 and 
 are independent and Gaussian with means of 
 and 
, respectively, 
and equal variances of 
.  The polar variables are formed according to 
 
and 
.
(a)
Find the joint PDF of 
 and 
.
(b)
Show that the marginal PDF of 
 follows a Rician distribution.
X
Y
fX v
( )
fY v
( )
v
v2
2-----
–



	 u v
( )
exp
=
=
Z
max X Y
,
(
)
=
W
min X Y
,
(
)
=
X
Y
fX x
( )
x
σ2
------
x2
2σ2
---------
–



	
exp
u x
( )
=
fY y
( )
1
π 1
y2
–
----------------------
=
y
1
<
X
Y
Z
XY
=
X
Y
0 2π
,
(
)
Z
X
Y
+
(
) mod 2π
=
X
Y
Pr Y=1
(
)
p
=
Pr Y=-1
(
)
1
p
–
=
X
Y
Z
XY
=
Z
X
Y
U V
,
U
X
θ
( )
cos
Y
θ
( )
sin
–
=
V
X
θ
( )
sin
Y
θ
( )
cos
+
=
θ
U
V
X
Y
ρ
U
aX
bY
+
=
V
cX
dY
+
=
a b c
d
U
V
X
Y
μX
μY
σ2
R
X2
Y2
+
=
Θ
tan 1
–
Y X
⁄
(
)
=
R
Θ
R

238    Chapter 5
www.Academicpress.com
5.59 Suppose 
 and  are independent, zero-mean Gaussian random variables with variances 
of 
 and 
 respectively.  Find the joint PDF of
 and 
.
5.60 Suppose 
 and 
 are independent, Cauchy random variables with PDFs specified by
.
Find the joint PDF of
 and 
.
5.61 Suppose 
 and 
 are independent discrete random variables.  Find the PMF of 
 for each of the following cases:
(a)
 and 
 both follow a uniform distribution, 
, 
.
(b)
 and 
 follow different geometric distributions, 
,  
,
,  
.
(c)
 and 
 both follow the same geometric distribution, 
, 
.
5.62 Suppose 
 and 
 are independent discrete random variables with identical Poisson 
distributions,
, 
.
Find the PMF of 
.  Hint:  For this problem, you may find the series 
expansion for the modified Bessel function helpful:
.
Section 5.10:  Complex Random Variables
5.63 A complex random variable is defined by 
, where 
 and 
 are independent 
and 
 is uniformly distributed over 
.
X
Y
σX
2
σY
2
Z
X2
Y2
+
=
W
X2
Y2
–
=
X
Y
fX u
( )
fy u
( )
1 π
⁄
1
u2
+
---------------
=
=
Z
X2
Y2
+
=
W
XY
=
M
N
L
M
N
+
=
M
N
PM k
( )
PN k
( )
1 K
⁄
=
=
k
0 1 2 … K
1
–
, , ,
,
=
M
N
PM m
(
)
1
p
–
(
)pm
=
m
0 1 2 …
, , ,
=
PN n
( )
1
q
–
(
)qn
=
n
0 1 2 …
, , ,
=
M
N
PM m
(
)
PN m
(
)
1
p
–
(
)pm
=
=
m
0 1 2 …
, , ,
=
M
N
PM k
( )
PN k
( )
αk
k!
------e α
–
=
=
k
0 1 2 …
, , ,
=
L
M
N
–
=
Ip x
( )
x 2
⁄
(
)2k
p
+
k! k
p
+
(
)!
---------------------------
k
0
=
∞

=
Z
AejΘ
=
A
Θ
Θ
0 2π
,
(
)

Exercises    239
www.Academicpress.com
(a)
Find 
.
(b)
Find 
.  For this part, leave your answer in terms of the moments of 
.
5.64 Suppose 
 is a circular Gaussian random variable whose PDF is described by 
Equation (5.70),
.
Find the characteristic function associated with this complex Gaussian random variable, 
.  Do you get the same (or different) results as with a real 
Gaussian random variable.
5.65 Suppose 
 is a circular Gaussian random variable whose PDF is described by 
Equation (5.70),
.
(a) 
Find the PDF of the magnitude, 
, and phase angle, 
, for the 
special case when 
.
(b)
Find the PDF of the magnitude, 
, and phase angle, 
, for the 
general case when 
.  Hint:  In this case, you will have to leave the PDF of the 
phase angle in terms of a Q-function.
(c)
For the case when 
, show that the PDF of the phase angle is well 
approximated by a Gaussian PDF. What is the variance of the Gaussian PDF that 
approximates the PDF of the phase angle?
Section 5.11: Mutual Information, Channel Capacity, 
and Channel Coding
5.66 Suppose 
 in Figure 5.7 and 
, 
.  Determine the 
mutual information for this channel.
5.67 Repeat Exercise 5.66 if 
.
E Z
[ ]
Var Z
( )
A
Z
X
jY
+
=
fZ z( )
1
2πσ2
-------------
z
μZ
–
2
2σ2
--------------------
–





	
exp
=
ΦZ ω
(
)
E
jωZ
(
)
exp
[
]
=
Z
X
jY
+
=
fZ z( )
1
2πσ2
-------------
z
μZ
–
2
2σ2
--------------------
–





	
exp
=
R
Z
=
Θ
Z
∠
=
μZ
0
=
R
Z
=
Θ
Z
∠
=
μZ
0
≠
μZ
σ
»
Q
0.8 0.1 0.1
0.1 0.8 0.1
0.1 0.1 0.8
=
pi
1 3
⁄
=
i
1 2 3
, ,
=
Q
0.9 0.1 0
0 0.9 0.1
0 0.1 0.9
=

240    Chapter 5
www.Academicpress.com
5.68 Repeat Exercise 5.66 if 
.  Can you give an interpretation for 
your result.
5.69 Find the capacity of the channel described by the transition matrix ,
.
5.70 For the transition matrix 
 given in Exercise 5.66, prove that the equally likely source 
distribution, 
, 
, is the one that maximizes mutual information and 
hence the mutual information found in Exercise 5.66 is the capacity associated with the 
channel described by 
.
Miscellaneous Problems
5.71 Suppose 
 and 
 are independent and exponentially distributed both with unit-mean.  
Consider the roots of the quadratic equation 
.
(a)
Find the probability that the roots are real.
(b)
Find the probability that the roots are complex.
(c)
Find the probability that the roots are equal.
5.72 In this problem, we revisit the light bulb problem of Exercises 3.43.  Recall that there were 
two types of bulbs, long-life (L) and short-life (S) and we were given a box of unmarked 
bulbs and needed to identify which type of bulbs are in the box.  In Exercise 3.43, we 
chose to run one of the bulbs until it burned out in order to help us identify which type of 
bulbs are in the box.  This time, in order to obtain a more reliable decision, we are going to 
burn two different bulbs from the box, observe how long it takes each bulb to burn out, 
and then make a decision as to what type of bulbs are in the box.  Let 
 represent the time 
that it takes the first bulb to burn out and let 
 represent the time it takes the second bulb 
to burn out.  It would seem reasonable to assume that 
 and 
 are independent and since 
both bulbs are taken from the same box, the PDFs of there lifetimes should be the same.  
Modeling the conditional PDFs as in Exercise 3.43, we have
Q
1 3
⁄
1 3
⁄
1 3
⁄
1 3
⁄
1 3
⁄
1 3
⁄
1 3
⁄
1 3
⁄
1 3
⁄
=
Q
0.8 0.2
0.1 0.9
=
Q
pi
1 3
⁄
=
i
1 2 3
, ,
=
Q
X
Y
z2
Xz
Y
+
+
0
=
X
Y
X
Y

Exercises    241
www.Academicpress.com
 and 
.
The a priori probability of the bulb types were 
 and 
.  
(a)
If the two bulbs are tested and it is observed that the first bulb burns out after 200 h 
and the second bulb burns out after 75 h, which type of bulb was most likely tested?
(b) What is the probability that your decision in part (b) was incorrect?
(c)
Determine what decision should be made for each possible observation pair, 
.  That is, divide the first quadrant of the 
-plane into two 
regions, one including all sets of points for which we would decide that the bulbs 
are S-type and its complement where we decide the bulbs are L-type.
5.73 Once again, we will modify the light bulb problem of Exercise 5.72 in a manner similar 
to what was done in Exercise 3.44.  Suppose we select two light bulbs to turn on when 
we leave the office for the weekend on Friday at 5 pm.  On Monday morning at 8 am we 
will observe which of the light bulbs have burned out, if any.  Let 
 be the lifetime of the 
first bulb and 
 the lifetime of the second bulb.  When we arrive at the office on Monday 
morning, there are four possible outcomes of the experiment:
(i)
,
(ii)
,
(iii)
,
(iv)
.
For each of the four cases, determine what decision should be made regarding the type of 
bulbs that were in the box (i.e., L-type or S-type) and calculate the probability that the 
decision is wrong.  As before, assume a priori probabilities of 
 and 
.  
5.74
(a)
Repeat Exercise 5.73 if we run the experiment over a 3-day weekend so that the 
experiment runs for 87 hours instead of 63.  
(b)
If we could choose the length of the experiment described in Exercise 5.73 to be 
anything we wanted, how long should we run the experiment in order to maximize 
our chances of correctly identifying the bulb type?
fX S z( )
fY S z( )
1
100
---------
z
100
---------
–



	 u z( )
exp
=
=
fX L z( )
fY L z( )
1
1000
------------
z
1000
------------
–



	 u z( )
exp
=
=
Pr S
( )
0.75
=
Pr L
( )
0.25
=
X= x Y= y
,
{
}
x y
,
(
)
X
Y
both bulbs burned out
X
63
<
{
}
Y
63
<
{
}
∩
⇔
the first bulb burned out while the second did not
X
63
<
{
}
Y
63
>
{
}
∩
⇔
the second bulb burned out while the first did not
X
63
>
{
}
Y
63
<
{
}
∩
⇔
neither bulb burned out
X
63
>
{
}
Y
63
>
{
}
∩
⇔
Pr S
( )
0.75
=
Pr L
( )
0.25
=

242    Chapter 5
www.Academicpress.com
MATLAB Exercises
5.75 Provide contour plots for the ellipses discussed in Example 5.17.  Consider the following 
cases:
(a)  
 and 
;
(b) 
 and 
;
(c) 
 and 
;
(d) 
 and 
.
Let 
 be the same for each case.  Discuss the effect 
, 
 and 
 have on the shape 
of the contour.  Now select one of the cases and let 
 increase and decrease.  What is 
the significance of 
.
5.76 Let 
 and 
 have a joint PDF given by 
as in Example 5.6.  Write a MATLAB program to generate many samples of this pair of 
random variables.  Note that 
 and 
 are independent, Gaussian random variables with 
unit variances and means of 2 and 3, respectively. After a large number of sample pairs 
have been generated, compute the relative frequency of the number of pairs that fall 
within the unit circle, 
.  Compare your answer with that obtained in Example 
5.6.  How many random samples must you generate in order to get a decent estimate of 
the probability?
5.77 Let 
 and 
 have a joint PDF given by
.
5.78 Write a MATLAB program to evaluate 
, where 
 is the shaded region 
bounded by the lines 
 and 
 as shown in 
the accompanying figure.  You should set up the 
appropriate double integral and use MATLAB to 
evaluate the integral numerically.  Note in this case that 
one of the limits of integration is infinit How will you 
deal with this?
σX
σY
=
ρXY
0
=
σX
σY
<
ρXY
0
=
σX
σY
>
ρXY
0
=
σX
σY
=
ρXY
0
≠
c2
σX σY
ρXY
c2
c2
X
Y
fX Y
,
x y
,
(
)
1
2π
------
x
2
–
(
)2
y
3
–
(
)2
+
(
)
2
-------------------------------------------------
–



	
exp
=
X
Y
X2
Y2
+
1
<
X
Y
fX Y
,
x y
,
(
)
1
2π
------
x
1
–
(
)2
y2
+
(
)
2
-----------------------------------
–



	
exp
=
x
y
ℜ
y
x
=
y
x
–
=
Pr
X Y
,
ℜ
∈
(
)
(
)
ℜ
y
x
=
y
x
–
=

Exercises    243
www.Academicpress.com
5.79 Write a MATLAB program to generate pairs of random variables that are uniformly 
distributed over the ellipse 
.  Use the technique employed in Example 5.16.  
Also, create a three-dimensional plot of an estimate of the PDF obtained from the 
random data you generated.
x2
4y2
+
1
<

245
CHAPTER 6
Probability and Random Processes. DOI: 10.116/B978-0-12-386981-4.00005-X
© 2012 by Elsevier Inc. All rights reserved.
Multiple Random Variables
In many applications, it is necessary to deal with a large numbers of random variables. Often, 
the number of variables can be arbitrary. In this chapter, the concepts developed previously for 
single random variables and pairs of random variables are extended to allow for an arbitrary 
number of random variables. Much of the focus of this chapter is on multidimensional 
Gaussian random variables, since most non-Gaussian random variables are difficult to deal 
with in many dimensions. One of the main goals here is to develop a vector/matrix notation 
which will allow us to represent potentially large sequences of random variables with a 
compact notation. Many of the concepts developed in Chapter 5 can be extended to multiple 
dimensions in a very straightforward manner; thus we will devote minimal time to those 
concepts in our current discussion. Rather, attention is focussed on those ideas that require 
more than a trivial extension to the work done in previous chapters.
6.1 Joint and Conditional PMFs, CDFs, and PDFs
The concepts of probability mass function (PMF), conditional distribution function (CDF), 
and probability density function (PDF) are easily extended to an arbitrary number of random 
variables. Their definitions follow.
Definition 6.1:  For a set of N random variables 
, the joint PMF, CDF,
and PDF are given, respectively, by
;
(6.1)
;
(6.2)
.
(6.3)
When large numbers of random variables are involved, this notation can get cumbersome, so it 
is convenient to introduce a vector notation to write these quantities in a more compact 
fashion. Let 
 be a column vector1 consisting of the N random variables 
X1 X2  XN



PX1 X2  XN



xk1 xk2  xkN





Pr X1= xk1 X2 = xk2  XN = xkN





=
FX1 X2  XN



x1 x2  xN





Pr X1
x1

X2
x2

 XN
xN






=
fX1 X2  XN



x1 x2  xN





x1 x2

 xN

N


FX1 X2  XN



x1 x2  xN





=
X
X1 X2  XN




	T
=
1 We use 
 to represent the matrix transpose operation so that if  is a row vector, then 
 is a column 
vector. Also, to avoid confusion throughout the text, we use boldface variables to represent vector and 
matrix quantities and regular face variables for scalar quantities.
T
v
vT

246    Chapter 6
www.Academicpress.com
and similarly define 
. Then the preceding functions can be expressed, 
respectively, as 
, 
, and 
.
Marginal CDFs can be found for a subset of the variables by evaluating the joint CDF at 
infinity for the unwanted variables. For example,
.
(6.4)
Marginal PDFs are found from the joint PDF by integrating out the unwanted variables. Similarly, 
marginal PMFs are obtained from the joint PMF by summing out the unwanted variables.
 
(6.5)
.
(6.6)
Similar to that done for pairs of random variables in Chapter 5, we can also establish 
conditional PMFs and PDFs. 
Definition 6.2: For a set of N random variables 
, the conditional PMF 
and PDF of 
 conditioned on 
 are given by
, (6.7)
.
(6.8)
Using conditional PDFs, many interesting factorization results can be established for joint 
PDFs involving multiple random variables. For example, consider four random variables, 
.
                                                     
                     
. (6.9)
Almost endless other possibilities exist as well. 
x
x1 x2  xN




	T
=
PX x
  FX x
 
fX x
 
FX1 X2  XM



x1 x2  xM





FX1 X2  XN



x1 x2  xM 
 
  









=
fX1 X2  XM



x1 x2  xM






fX1 X2  XN



x1 x2  xN




 xM
1
+
d
xM
2
+
d
 xN
d
,

–



–



–


=
PX1 X2  XM



xk1 xk2  xkM






PX1 X2  XN



xk1 xk2  xkN





kN
kM
2
+
kM
1
+
=
X1 X2  XN



X1 X2  XM



XM
1
+
XM
2
+
 XN



PX1  XM


XM
1
+
 XN


xk1  xkM


xkM
1
+
 xkN




Pr X1= xk1  XN = xkN




Pr XM
1
+ = xkM
1
+
 XN = xkN




--------------------------------------------------------------------------
=
fX1  XM


XM
1
+
 XN


x1  xM


xM
1
+
 xN




fX1  XN


x1  xN




fXM
1
+
 XN


xM
1
+
 xN




------------------------------------------------------------------
=
X1 X2 X3 X4



fX1 X2 X3 X4



x1 x2 x3 x4





fX1 X2 X3 X4


x1 x2 x3 x4



fX2 X3 X4


x2 x3 x4




=
fX1 X2 X3 X4


x1 x2 x3 x4



fX2 X3 X4

x2 x3 x4


fX3 X4

x3 x4



=
fX1 X2 X3 X4


x1 x2 x3 x4



fX2 X3 X4

x2 x3 x4


fX3 X4 x3 x4

fX4 x4


=

Multiple Random Variables    247
www.Academicpress.com
Definition 6.3: A set of N random variables are statistically independent if any subset 
of the random variables are independent of any other disjoint subset. In particular, any 
joint PDF of 
 variables should factor into a product of the corresponding 
marginal PDFs.
As an example, consider three random variables, 
. For these three random variables to 
be independent, we must have each pair independent. This implies that
,  
, 
.
(6.10)
In addition, the joint PDF of all three must also factor into a product of the marginals,
.
(6.11)
Note that all three conditions in Equation (6.10) follow directly from the single condition in 
Equation (6.11). Hence, Equation (6.11) is a necessary and sufficient condition for three 
variables to be statistically independent. Naturally, this result can be extended to any 
number of variables. That is, the elements of a random vector 
 are 
independent if
.
(6.12)
6.2  Expectations Involving Multiple Random Variables
For a vector of random variables 
, we can construct a corresponding 
mean vector that is a column vector of the same dimension and whose components are the means 
of the elements of 
. Mathematically, we say 
. 
Two other important quantities associated with the random vector are the correlation and 
covariance matrices.
Definition 6.4:  For a random vector 
, the correlation matrix is 
defined as 
. That is, the 
th element of the N  N matrix 
 is 
. Similarly, the covariance matrix is defined as 
 
so that the 
th element of 
 is 
.
Theorem 6.1:  Correlation matrices and covariance matrices are symmetric and 
positive definite.
M
N

X Y Z


fX Y

x y



fX x
 fY y
 
=
fX Z

x z



fX x
 fZ z 
=
fY Z

y z



fY y
 fZ z 
=
fX Y Z


x y z
 


fX x
 fY y
 fZ z 
=
X
X1 X2  XN




	T
=
fX x
 
fXn xn


n
1
=
N

=
X
X1 X2  XN




	T
=
X

E X

	
E X1

	 E X2

	  E XN

	




	T
=
=
X
X1 X2  XN




	T
=
RXX
E XXT

	
=
i j


RXX
E XiXj

	
CXX
E
X

–

 X

–

T

	
=
i j


CXX
Cov Xi Xj




248    Chapter 6
www.Academicpress.com
Proof:  Recall that a square matrix, 
, is symmetric if 
. Equivalently, 
the 
th element must be the same as the 
th element. This is clearly the case 
here since 
. Recall that the matrix 
 is positive definite if 
 for any vector  such that 
. 
.
(6.13)
Note that 
 is a scalar random variable (a linear combination of the components of 
). 
Since the second moment of any random variable is positive (except for the 
pathological case of a random variable which is identically equal to zero), then the 
correlation matrix is positive definite. As an aside, this also implies that the 
eigenvalues of the correlation matrix are all positive. Identical steps can be followed to 
prove the same properties hold for the covariance matrix.
Next, consider a linear transformation of a vector random variable. That is, create a new set of 
M random variables, 
, according to 
(6.14)
The number of new variables, M, does not have to be the same as the number of original 
variables, N. To write this type of linear transformation in a compact fashion, define a matrix 
 
whose 
th element is the coefficient 
 and a column vector, 
. 
Then the linear transformation of Equation (6.14) is written in vector/matrix form as 
. The next theorem describes the relationship between the means of X and Y and 
the correlation matrices of X and Y.
Theorem 6.2:  For a linear transformation of vector random variables of the form 
, the means of X and Y are related by 
.
(6.15)
Also, the correlation matrices of X and Y are related by 
,
(6.16)
RXX
RXX
RXX
T
=
i j


j i


E XiXj

	
E XjXi

	
=
RXX
zTRXXz
0

z
z
0

zTRXXz
zTE XXT

	z
E zTXXTz

	
E
zTX

2

	
=
=
=
zTX
X
Y
Y1 Y2  YM




	T
=
Y1
a1 1
 X1
a1 2
 X2

a1 N

XN
b1
+
+
+
+
,
=
Y2
a2 1
 X1
a2 2
 X2

a2 N

XN
b2
+
+
+
+
,
=

YM
aM 1
 X1
aM 2
 X2

aM N

XN
bM
+
+
+
+
.
=
A
i j


ai j
b
b1 b2  bM




	T
=
Y
AX
b
+
=
Y
AX
b
+
=
mY
AmX
b
+
=
RYY
ARXXAT
AmXbT
bmXTAT
bbT
+
+
+
=

Multiple Random Variables    249
www.Academicpress.com
and the covariance matrices of X and Y are related by 
.
(6.17)
Proof:  For the mean vector,
.
(6.18)
Similarly, for the correlation matrix,
.
(6.19)
To prove the result for the covariance matrix, write 
 as
.
(6.20)
Then, 
.
(6.21)
6.3  Gaussian Random Variables in Multiple Dimensions
Recall from the study of two-dimensional random variables in the previous chapter that the 
functional form of the joint Gaussian PDF was fairly complicated. It would seem that the 
prospects of forming a joint Gaussian PDF for an arbitrary number of dimensions are grim. 
However, the vector/matrix notation developed in the previous sections make this task 
manageable and, in fact, the resulting joint Gaussian PDF is quite simple.
CYY
ACXXAT
=
mY
E Y
 	
E AX
b
+

	
AE X

	
b
+
AmX
b
+
=
=
=
=
RYY
E YYT

	
E
AX
b
+

 AX
b
+

T

	
=
=
E AXXTAT

	
E bXTAT

	
E AXbT

	
E bbT

	
+
+
+
=
AE XXT

	AT
bE XT

	AT
AE X

	bT
bbT
+
+
+
=
ARXXAT
AmXbT
bmXTAT
bbT
+
+
+
=
Y
mY
–
Y
mY
–
AX
b
+


AmX
b
+


–
A X
mX
–


=
=
CYY
E
Y
mY
–

 Y
mY
–

T

	
E
A X
mX
–



 A X
mX
–



T

	
=
=
E A X
mX
–

 X
mX
–

TAT

	
AE
X
mX
–

 X
mX
–

T

	AT
ACXXAT
=
=
=

250    Chapter 6
www.Academicpress.com
Definition 6.5:  The joint Gaussian PDF for a vector of N random variables, 
, with 
mean vector, 
, and covariance matrix, 
, is given by2
.
(6.22)
Example 6.1: 
To demonstrate the use of this matrix notation, suppose 
 is a two-element vector and 
the mean vector and covariance matrix are given by their general forms
 and 
.
The determinant of the covariance matrix is
,
while the inverse is
.
The quadratic form in the exponent then works out to be
.
Plugging all these results into the general form for the joint Gaussian PDF gives
.
This is exactly the form of the two-dimensional joint Gaussian PDF given in the Definition 5.10.
X
mX
CXX
fX x
 
1
2

Ndet CXX


-------------------------------------------
1
2--- x
mX
–

TCXX1
–
x
mX
–


–




exp
=
X
mX
 1
 2
=
CXX
1
2
12
12
2
2
=
det CXX


1
22
2
12

2
–
1
22
2 1
2
–


=
=
CXX
1
–
2
2

– 12

– 12
1
2
1
22
2 1
2
–


----------------------------------------------
1
2
–

– 1
1
– 2
1
–

– 1
1
– 2
1
–
2
2
–
1
2
–


---------------------------------------------------------
=
=
x
mX
–

TCXX
1
–
x
mX
–


x1
 1
–
x2
 2
–
1
2
–

– 1
1
– 2
1
–

– 1
1
– 2
1
–
2
2
–
1
2
–


--------------------------------------------------------- x1
 1
–
x2
 2
–
=
x1
 1
–
1
-----------------




2
2
x1
 1
–
1
-----------------



 x2
 2
–
2
-----------------




–
x2
 2
–
2
-----------------




2
+
1
2
–


--------------------------------------------------------------------------------------------------------------------
=
fX1 X2

x1 x2



1
2

21
22
2 1
2
–


----------------------------------------------------
x1
 1
–
1
-----------------




2
2
x1
 1
–
1
-----------------



 x2

–
2
--------------




–
x2
 2
–
2
-----------------




2
+
2 1
2
–


------------------------------------------------------------------------------------------------------------------
–










exp
=


2 The notation 
 refers to the determinant of the matrix A, while 
 is the inverse of A. 
det A


A 1
–

Multiple Random Variables    251
www.Academicpress.com
Example 6.2:
As a special case, suppose a vector of N jointly Gaussian random variables are all 
mutually uncorrelated. This means that 
 for all 
. A direct result of this 
is that all of the off-diagonal elements of the covariance matrix of 
 are zero. In other 
words, 
 is a diagonal matrix of the general form
.
The determinant of a diagonal matrix is the product of the diagonal entries so that in this 
case 
. The inverse is also trivial to compute and takes on the form
.
The quadratic form that appears in the exponent of the Gaussian PDF becomes,
.
The joint Gaussian PDF for a vector of uncorrelated random variables is then
.
This shows that for any number of uncorrelated Gaussian random variables, the joint 
PDF factors into the product of marginal PDFs and hence uncorrelated Gaussian 
random variables are independent. This is a generalization of the same result that was 
proven in Chapter 5 for two Gaussian random variables.
Example 6.3:
In this example, we use MATLAB’s symbolic capabilities to compute the 
form of a three-dimensional Gaussian PDF. Suppose we have three jointly 
Gaussian random variables 
 with a mean vector 
 and 
covariance matrix
(Continued)
Cov Xi Xj



0
=
i
j

X
CXX
CXX
1
2 0  0
0 2
2  0
 

0
0  N
2
=
det CXX


1
22
2N
2
=
CXX
1
–
1
2
–
0

0
0
2
2
–

0



0
0
 N
2
–
=
x
X
–

TCXX
1
–
x
X
–


x1
1
–
x2
2
–
 xN
N
–
1
2
–
0

0
0
2
2
–

0



0
0
 N
2
–
x1
1
–
x2
2
–

xN
N
–
xn
n
–
n
-----------------




2
n
1
=
N

=
=
fX x
 
1
2

N1
22
2N
2
----------------------------------------------
1
2---
xn
n
–
n
-----------------




2
n
1
=
N

–








exp
1
2n
2
-----------------
xn
n
–

2
2n
2
------------------------
–






exp
n
1
=
N

=
=
X Y Z



	T
m
1 2 3
 

	T
=




252    Chapter 6
www.Academicpress.com
.
The three-dimensional joint PDF, 
, can be found with the following MATLAB code:
x=sym('x','real'); 
% Define x, y, and z as symbolic.
y=sym('y','real'); 
z=sym('z','real'); 
pi=sym('pi');
% Disable numeric definition of pi.
C=[9 4 1; 4 9 4; 1 4 9];
% Covariance matrix.
mu=[1; 2; 3];
% mean vector
% Compute PDF symbolically.
v=[x; y; z]-mu;
f=exp(-v'*(inv(C))*v/2)/sqrt((2*pi)^3*det(C));
simplify(f)
Executing this program, MATLAB finds the joint PDF to be
The reader is encouraged to try different mean vectors and covariance matrices in the 
preceding program.
6.4  Transformations Involving Multiple Random Variables
In this section, we discuss various transformations of vector random variables. To exhaustively 
cover this topic would require much more space than we can devote to it here. Instead, we chose 
to cover some of the more common transformations encountered in engineering practice. To 
start with, we extend the formula for 2  2 transformations developed in the previous chapter to 
the case of NxN transforms. Let 
 be a vector transformation,
(6.23)
and let 
 be the inverse transformation. Given the PDF of 
, the PDF of 
 is found by
.(6.24)
C
9 4 1
4 9 4
1 4 9
=
fX Y Z


x y z
 


fX Y Z
,
,
x y z
 


1
464 583
--------------------------
65
928
---------x2
–
11
232
---------x
125
232
---------
–
2
29
------xy
2
29
------y
7
464
---------xz
–
69
232
---------z
5
58
------y2
–
2
29
------yz
65
928
---------z2
–
+
+
+
+
+




exp
=
Y
g X


=
Y1
g1 X1 X2  XN




,
=
Y2
g2 X1 X2  XN




,
=

YN
gN X1 X2  XN




,
=
X
h Y
 
=
X
Y
fY y
 
fX x
 
det J
y1 y2  yN
x1 x2  xN






-----------------------------------------------------------
x
h y
 
=
fX x
  det J
x1 x2  xN
y1 y2  yN






x
h y
 
=
=
=


Multiple Random Variables    253
www.Academicpress.com
As in Chapter 5, it needs to be understood that if the transformation is not one-to-one, the 
preceding expression must be evaluated at each root and summed together. This result can be 
proved using the same sort of derivation that was used for the case of 2  2 transformations. 
6.4.1 Linear Transformations
Perhaps the single most important class of transformations is that involving linear transformations 
of Gaussian random variables. Consider a linear transformation of the general form 
 
when the random vector 
 has a joint Gaussian PDF as given in Equation (6.22). To begin, 
consider the case where the dimensionality of 
 and 
 are the same (i.e., both are N element 
vectors). In that case, the matrix 
 is a square matrix. Furthermore, it is assumed that the matrix A 
is invertible (
). Then, the Jacobian of the linear transformation is
.
(6.25)
Also, the inverse transformation is linear and can be written as 
. The joint 
PDF for the vector 
 is then
.
(6.26)
Plugging in the form of the Gaussian PDF for 
 results in
.
(6.27)
To simplify this result, write 
.
(6.28)
Y
AX
b
+
=
X
X
Y
A
det A


0

J
y1 y2  yN
x1 x2  xN






x1

y1
x2

y1 
xN

y1
x1

y2
x2

y2 
xN

y2



x1

yN
x2

yN 
xN

yN
a1 1

a1 2

 a1 N

a2 1

a2 2

 a2 N




aN 1

aN 2

 aN N

A
=
=
=
X
A 1
–
Y
b
–


=
Y
fY y
 
fX x
 
det A


-------------------
x
A 1
–
y
b
–


=
=
fX x
 
fY y
 
1
det A


2

Ndet CXX


---------------------------------------------------------------
1
2--- x
X
–

TCXX1
–
x
X
–


–




exp
x
A 1
–
y
b
–


=
=
x
mX
–
x
A 1
–
y
b
–


=
A 1
–
y
b
–


mX
–
A 1
–
y
b
AmX
+


–


A 1
–
y
mY
–


=
=
=

254    Chapter 6
www.Academicpress.com
The quadratic form in the exponent is then
.
(6.29)
In addition, we can write 
.
(6.30)
The steps above are carried out using the fact that for a square matrix, 
 and 
also that the determinant of a product of matrices is equal to the product of the determinants. 
At this point we have established that 
.
(6.31)
Finally, recall that for a linear transformation, 
. Furthermore, from this 
relationship, we can also determine that 
. 
Hence, the PDF for 
 can be written as
.
(6.32)
This is the general form of a joint Gaussian PDF. Thus, we have shown that any linear 
transformation of any number of jointly Gaussian random variables produces more jointly 
Gaussian random variables. Note that this statement applies to more than just N  N linear 
transformations. Suppose we wanted to transform N jointly Gaussian random variables to 
M (
) new random variables through a linear transformation. We could always form an 
N  N transformation producing N new jointly Gaussian random variables. Any subset of M 
out of N of these random variables will also be jointly Gaussian. In summary, we have proved 
the following theorem.
Theorem 6.3:  Given a vector 
 of N jointly Gaussian random variables, any linear 
transformation to a set of M (
) new variables, 
, will produce jointly Gaussian 
random variables.
Next, suppose we want to create a set of N jointly Gaussian random variables, 
, with a 
specified covariance matrix, 
. We could start with a set of uncorrelated Gaussian random 
x
mX
–

TCXX
1
–
x
mX
–


x
A 1
–
y
b
–


=
A 1
–
y
mY
–



	TCXX
1
–
A 1
–
y
mY
–



	
=
y
mY
–

T A 1
–

TCXX
1
– A 1
–
y
mY
–


=
det A


det CXX


det A



	2det CXX


=
det A

det CXX

det AT


det ACXXAT


=
=
det A


det AT


=
fY y
 
1
2

Ndet ACXXAT


-------------------------------------------------------
1
2--- y
mY
–

T A 1
–

TCXX
1
– A 1
–
y
mY
–


–




exp
=
CYY
ACXXAT
=
CYY1
–
ACXXAT

 1
–
AT

 1
– CXX1
– A 1
–
=
=
A 1
–

TCXX
1
– A 1
–
=
Y
fY y
 
1
2

Ndet CYY


------------------------------------------
1
2--- y
mY
–

TCYY
1
–
y
mY
–


–




exp
=
M
N

X
M
N

Y
Y
C

Multiple Random Variables    255
www.Academicpress.com
variables (as might be generated by a typical Gaussian random number generator) and then 
perform a linear transformation to produce a new set of Gaussian random variables with the 
desired covariance matrix. But, how should the transformation be selected to produce the 
desired covariance matrix?  To answer that question, recall that any covariance matrix is 
symmetric and any symmetric matrix can be decomposed into
,
(6.33)
where 
 is a diagonal matrix of the eigenvalues of 
, and 
 is an orthogonal matrix whose 
columns are the corresponding eigenvectors of 
. Note also that 
 is positive definite and 
therefore its eigenvalues are all positive. Thus, the matrix 
 is not only diagonal, but its 
diagonal elements are all positive, and as a result, the matrix 
 is a valid covariance matrix. 
That is, suppose we create a set of N uncorrelated Gaussian random variables, 
, with a 
covariance matrix 
. Then, the matrix 
 will transform this set of uncorrelated 
Gaussian random variables to a new set of Gaussian random variables with the desired 
covariance matrix. If we form 
, then according to Theorem 6.2, the covariance 
matrix of Y will be of the form
.
(6.34)
At this point, the problem has been reduced from creating a set of random variables with an 
arbitrary covariance matrix to creating a set of random variables with a diagonal covariance 
matrix. Typical Gaussian random number generators create random variables with a unit variance. 
To create random variables with unequal variances, simply scale each component by the 
appropriate value. In particular, suppose3 
. Given a set of unit variance 
uncorrelated Gaussian random variables 
, one could form 
 with the 
desired variance according to 
, 
. In matrix notation, we write
,
(6.35)
where 
 is understood to mean 
. 
In summary, we have a two-step linear transformation. Given a vector of uncorrelated, unit 
variance Gaussian random variables, we form 
 and then 
 to produce the 
vector of Gaussian random variables with the desired covariance matrix. Naturally, these two 
consecutive linear transformations can be combined into a single transformation
.
(6.36)
It is common to write the matrix 
 as 
 since 
. 
C
QDQT
=
D
C
Q
C
C
D
D
X
CXX
D
=
Q
Y
QX
=
CYY
QCXXQT
QDQT
C
=
=
=
D
diag d1 d2  dN





=
Z
Z1 Z2  ZN




	T
=
X
Xi
diZi
=
i
1 2  N
 

=
X
DZ
=
D
D
diag
d1
d2 
dN





=
X
DZ
=
Y
QX
=
Y
QX
Q DZ
=
=
A
Q D
=
C
AAT
Q D DTQT
QDQT
C
=
=
=
3 The notation 
 means that 
 is a diagonal matrix with diagonal elements 
, 
, ..., 
.
A
diag a1 a2  aN





=
A
a1
a2
aN

256    Chapter 6
www.Academicpress.com
Finally, note that if 
 is zero-mean, then 
 will be zero-mean as well. If it is desired to create 
 with a nonzero mean, then a constant term can be added to the transformation to shift the 
mean to the specified value. This will not alter the covariance matrix of 
. In summary, we 
have the following result: 
Theorem 6.4:  Given a vector 
 of zero-mean, unit-variance, uncorrelated random 
variables, then a new set of random variables, 
, with arbitrary mean vector, 
, and 
covariance matrix, 
, can be formed using the linear transformation
.
(6.37)
Furthermore, if 
 is a Gaussian random vector, then  
 will be a Gaussian random 
vector as well.
If a Gaussian random number generator is not available,4 one can always use a uniform 
random number generator together with the Box-Muller transformation described in Example 
5.24 to produce Gaussian random variables.
Sometimes it is desired to transform a set of correlated random variables into a new set of 
uncorrelated random variables. Later in the text, when studying noise, this process will be 
referred to as “whitening.”  For now, it is seen that this process is just the opposite of the problem 
just solved. That is, given a random vector 
 with mean, 
, and covariance matrix, 
, a vector 
of zero-mean, unit-variance, uncorrelated random variables can be formed according to
.
(6.38)
Here, the expression 
 is interpreted as5
.
(6.39)
Example 6.4:
Let us suppose we desire to create a vector of four random variables with a 
mean vector of 
 and covariance matrix of
.
Z
Y
Y
Y
Z
Y
m
C
Y
CZ
=
m
+
Z
Y
Y
m
C
Z
C

 1
–
Y
m
–


=
C

 1
–
C

 1
–
Q D

 1
–
D

 1
– Q 1
–
D 1 2

–
QT
=
=
=
m
1 0 3
2
–
  

	T
=
C
30
10
–
20
–
4
10
–
30
4
20
–
20
–
4
30
10
–
4
20
–
10
–
30
=

4 Many high-level programming languages come with a built-in uniform random number generator, 
but not a Gaussian random number generator. See Chapter 12 for more details on random number 
generators.
5 Since 
 is an orthogonal matrix, 
. Also, 
.
Q
Q 1
–
QT
=
D 1 2

–
diag d1
1 2

–
d2
1 2

–
 dN
1 2

–





=

Multiple Random Variables    257
www.Academicpress.com
The eigenvalue matrix and eigenvector matrix are calculated to be (we performed this 
calculation using MATLAB).
 and 
.
Thus, the appropriate transformation matrix is
.
Therefore, given a vector of zero-mean, unit-variance, uncorrelated random variables, , 
the required transformation is
.
The MATLAB code to perform the necessary eigendecomposition of this example is very 
straightforward and is as follows:
C=[30 -10 -20 4; -10 30 4 -20; -20 4 30 -10; 4 -20 -10 30]
[Q, D]=eig(C)
A=Q*sqrt(D)
6.4.2  Quadratic Transformations of Gaussian Random Vectors
In this section, we show how to calculate the PDFs of various quadratic forms of Gaussian 
random vectors. In particular, given a vector of N zero-mean Gaussian random variables, 
, 
with an arbitrary covariance matrix, 
, we form a scalar quadratic function of the vector 
 
of the general form
, 
(6.40)
where 
 is an arbitrary N  N matrix. We would then like to find the PDF of the random 
variable, 
. These types of problem occur frequently in the study of noncoherent 
communication systems. 
One approach to this problem would be to first form the CDF, 
. This 
could be accomplished by computing
D
4 0
0
0
0 16 0
0
0 0 36 0
0 0
0 64
=
Q
1
2---
1
1
–
1
1
1 1
1
1
–
1
1
–
1
–
1
–
1 1
1
–
1
=
A
Q D
1
2---
1
1
–
1
1
1 1
1
1
–
1
1
–
1
–
1
–
1 1
1
–
1
2 0 0 0
0 4 0 0
0 0 6 0
0 0 0 8
1
2
–
3
4
1 2
3
4
–
1
2
–
3
–
4
–
1 2
3
–
4
=
=
=
Z
Y
1
2
–
3
4
1 2
3
4
–
1
2
–
3
–
4
–
1 2
3
–
4
Z
1
0
3
2
–
+
=
X
CXX
X
Z
XTBX
=
B
Z
FZ z 
Pr XTBX
z



=


258    Chapter 6
www.Academicpress.com
,
(6.41)
where 
 is the region defined by 
. While conceptually straightforward, defining 
the regions and performing the required integration can get quite involved. Instead, we elect to 
calculate the PDF of Z by first finding its characteristic function. Once the characteristic 
function is found, the PDF can be found through an inverse transformation.
For the case of Gaussian random vectors, finding the characteristic function of a quadratic 
form turns out to be surprisingly manageable.
.
(6.42)
This integral is understood to be over the entire N-dimensional -plane. To evaluate this 
integral, we simply manipulate the integrand into the standard form of a N-dimensional 
Gaussian distribution and then use the normalization integral for Gaussian PDFs. Toward that 
end, define the matrix 
 according to 
. Then
.
(6.43)
The last step is accomplished using the fact that the integral of a multidimensional Gaussian 
PDF is unity. In addition, using the matrix property that 
, this can be 
rewritten in the more convenient form
.
(6.44)
To get a feel for the functional form of the characteristic function, note that the determinant of 
a matrix can be written as the product of its eigenvalues. Furthermore, for a matrix of the form 
FZ z 
fX x
  x
d
A z 
=
A z 
xTBx
z

Z  


E ej XTBX

	
1
2

Ndet CXX


-------------------------------------------
1
2--- xT CXX1
–
2j B
–

	x


–




exp
x
d

=
=
x
F
F 1
–
CXX
1
–
2j B
–
=
Z  


1
2

Ndet CXX


-------------------------------------------
1
2--- xTF 1
– x


–




exp
x
d

=
det F


det CXX


-----------------------
1
2

Ndet F


------------------------------------
1
2--- xTF 1
– x


–




exp
x
d

det F


det CXX


-----------------------
=
=
det F 1
–


det F



 1
–
=
Z  


det F


det CXX


-----------------------
1
det F 1
–

det CXX


--------------------------------------------------
=
=
1
det F 1
– CXX


-------------------------------------
1
det I
2j BCXX
–


--------------------------------------------------
=
=

Multiple Random Variables    259
www.Academicpress.com
, for a constant , the eigenvalues of 
, 
, can be written in terms of the 
eigenvalues of the matrix 
, 
, according to 
. Therefore,
,
(6.45)
where the 
s are the eigenvalues of the matrix 
. The particular functional form of the 
resulting PDF depends on the specific eigenvalues. Two special cases are considered as 
examples next.
Example 6.5:
In this example, we consider the case where the matrix 
 is an identity so that  is the 
sum of the squares of Gaussian random variables, 
. Further, let us 
assume that the 
 are uncorrelated and equal variance so that 
. Then, the 
matrix 
has N repeated eigenvalues all equal to 
. The resulting characteristic 
function is
.
This is the characteristic function of a chi-square random variable with N degrees of 
freedom. The corresponding PDF is
.
Example 6.6:
For this example, suppose we need to find the PDF of 
. In this case, the 
quantity  can be expreesed in the general quadratic form of Equation (6.40) if we 
choose the matrix 
 according to
.
Again, we take the 
 to be uncorrelated with equal variance so that 
. In this 
case, the product matrix 
 has two pairs of repeated eigenvalues of values 
. 
The resulting characteristic function is
(Continued)
A
I
cD
+
=
c
A
!A


D
!D


!A
1
c!D
+
=
Z  


1
1
2j !n
–
-----------------------------
n
1
=
N

=
!n
BCXX
B
Z
B
I
=
Z
"
Xn
2
n
1
=
N

=
Xn
CXX
2I
=
BCXX
2
Z  


1
2j 2
–

 N 2

–
=
fZ z 
z N 2



1
–
22

N 2
 # N 2



-------------------------------------------
z
22
---------
–




exp
u z 
=
Z
X1X2
X3X4
+
=
Z
B
B
1
2---
0 1 0 0
1 0 0 0
0 0 0 1
0 0 1 0
=
Xi
CXX
2I
=
BCXX
2 2

$




260    Chapter 6
www.Academicpress.com
.
This is the characteristic function of a two-sided exponential (Laplace) random variable,
.
6.4.3  Order Statistics
Suppose a vector of random variables has elements that are independent and identically 
distributed. In many applications, we need to find the PDF of the largest element in the vector. 
Or, as a more general problem, we might be interested in the PDF of the mth largest. Let, 
 be a sequence of random variables. We create a new set of random variables 
 such that 
 is the smallest of the Xns, 
 is the second smallest, and so on. 
The sequence of Yns are referred to as order statistics of the sequence of Xns. Given that each 
of the Xns follows a common PDF, 
, we seek to find the PDF of the Yns. 
First, we find the PDF of 
 by first finding its CDF.
.
(6.46)
This expression follows from the observation that if the smallest of a sequence is larger than 
some threshold, than all elements in the sequence must be above that threshold. Next, using 
the fact that the 
 are independent and all have the same distribution the previous expression 
simplifies to
.
(6.47)
Differentiating with respect to  then produces the desired PDF,
.
(6.48)
A similar procedure can be followed to determine the PDF of the mth smallest, 
. First, we 
work out an expression for the CDF.
(6.49)
Z  


1
1
j 2
+
----------------------
1
1 j
–  2
-------------------
1
1
 2

2
+
---------------------------
=
=
fZ z 
1
22
---------
z
2
------
–




exp
=
X1 X2  XN



Y1 Y2  YN



Y1
Y2
fX x
 
Y1
FY1 y
 
Pr Y1
y



1
Pr Y1
y
%


–
1
Pr X1
y
%
X2
y
%
 XN
y
%





–
=
=
=
Xn
FY1 y
 
1
Pr X1
y
%

Pr X2
y
%

Pr XN
y
%


–
1
1
F
–
X y
 

N
–
=
=
y
fY1 y
 
NfX y
  1
F
–
X y
 

N
1
–
=
Ym
FYm y
 
Pr Ym
y



Pr m or more of the Xns are less than y


=
=
Pr k of the Xns are less than y


k
m
=
N

=


Multiple Random Variables    261
www.Academicpress.com
To evaluate the probability of the event 
, it is noted that one 
way for this event to occur is if 
, 
, ..., 
, 
, ..., 
. The 
probability of this event is
.
(6.50)
Of course, we do not have to have the first k elements of the sequence smaller than y. We are 
looking for the probability that any k of the N elements are below y. Thus, we need to count the 
number of combinations of k out of N variables. This is merely the binomial coefficient. 
Hence, 
.
(6.51)
Summing over k gives the desired CDF:
.
(6.52)
Differentiating with respect to  then gives the expression
.
(6.53)
It is left as an exercise to the reader (see Exercise 6.22) to show that this expression reduces to 
the form 
.
(6.54)
An alternative approach to deriving this expression is outlined in Exercise 6.23. The next 
example illustrates one possible use of order statistics.
Example 6.7:
Suppose we observe a sequence of 
 independent and identically distributed 
random variables, 
, and we wish to estimate the mean of the common 
distribution. One method to do this would be to use the median (middle) element in the 
sequence as an estimate of the mean. In terms of order statistics, the median is simply 
. 
k of the Xns are less than y


X1
y

X2
y

Xk
y

Xk
1
+
y

XN
y

Pr X1
y

X2
y

 Xk
y

Xk
1
+
y

 XN
y









FX y
 

k 1
FX y
 
–

N
k
–
=
Pr k of the Xns are less than y


N
k
 
  FX y
 

k 1
FX y
 
–

N
k
–
=
FYm y
 
N
k
 
  FX y
 

k 1
FX y
 
–

N
k
–
k
m
=
N

=
y
fYm y
 
fX y
 
N
k
 
  k FX y
 

k
1
–
1
FX y
 
–

N
k
–
k
m
=
N

=
fX y
 
N
k
 
  N
k
–

 FX y
 

k 1
FX y
 
–

N
k
–
1
–
k
m
=
N

–
fYm y
 
N!
m
1
–

! N
m
–

!
-----------------------------------------fX y
  FX y
 

m
1
–
1
FX y
 
–

N
m
–
=
N
2k
1
–
=
X1  X2k
1
–


Yk


262    Chapter 6
www.Academicpress.com
.
For example, if the 
 are all uniformly distributed over 
, then
,  
.
Some straightforward calculations reveal that this distribution has a mean of 
 and a variance of 
. Note that, “on the average,” the 
median is equal to the true mean of the distribution. We say that this estimator is 
unbiased. Furthermore, we also see that as we observe more samples (k gets larger), the 
variance of the median gets smaller. In other words, as the sample size increases, the 
median becomes increasingly more precise as an estimator of the mean. In fact, in the 
limit as 
, the variance goes to zero which means that the median becomes equal to 
the mean. We will discuss this problem of estimating means of sequences of random 
variables in the next chapter.
6.4.4  Coordinate Systems in Three Dimensions
Coordinate system transformations in three dimensions follow the same procedure as was 
derived for the two-dimensional problems. Given a random vector 
 and a corresponding 
joint PDF 
, the joint PDF of 
 is given by the general formula expressed in 
Equation (6.24). An example is included below to illustrate the procedure.
Example 6.8: (Cartesian-to-spherical coordinates)
Let the random variables , , and  in Cartesian coordinates be transformed to 
spherical coordinates according to
The inverse transformation is probably more familiar to most readers and is given by
The Jacobian of this transformation is 
,
fYk y
 
2k
1
–

!
k
1
–

!

	2
--------------------------fX y
  FX y
 

	k
1
–
1
F
–
X y
 

	k
1
–
=
Xn
0 1



fYk y
 
2k
1
+

!
k
1
–

!

	2
-------------------------- y 1
y
–



	k
1
–
=
0
y
1


E Yk

	
1 2

=
Yk
2
1
4 2k
1
+





=
k

&
X
fX x
 
Y
g X


=
X
Y
Z
R
X2
Y2
Z2
+
+
=
,
'
cos 1
–
Z
X2
Y2
Z2
+
+
-----------------------------------



 ,
=

tan 1
–
Y
X---
 
  ·
=
X
R
'


sin



cos
,
=
Y
R
'


sin


,
sin
=
Z
R
'

 ·
cos
=
J
x x z
r ( )






( 
sin
) 
cos
( 
sin
) 
sin
( 
cos
r
( 
cos
) 
cos
r
( 
cos
) 
sin
r
( 
sin
–
r
( 
sin
) 
sin
–
r
( 
sin
) 
cos
0
=



Multiple Random Variables    263
www.Academicpress.com
and the determinant of this matrix works out to be
.
Suppose , , and  are jointly Gaussian with a joint PDF given by
.
Then, the joint PDF of , 
, and 
 is found to be
,  
.
The marginal PDFs are found by integrating the unwanted variables out of this joint 
PDF. In this case, the required integrations are fairly straightforward, resulting in
,
,  
,
,  
.
Note also that for this example, 
 so that , 
, and 
 are 
all independent. These PDFs are plotted in Figure 6.1. 
det J
x y z
r ( )






r2
(
 
sin
=
X
Y
Z
fX Y Z


x y z
 


1
22

3 2

--------------------------
x2
y2
z2
+
+
22
----------------------------
–




exp
=
R
'

fR ' 


r ( )
 


fX Y Z


x y z
 

 det J
x y z
r ( )






x
r
(
 
sin
)
 
cos
=
y
r
(
 
sin
)
 
sin
=
z
r
(
 
cos
=
r2
(
 
sin
22

3 2

--------------------------
r2
22
---------
–




exp
=
=
r
0
%
0
(



0
)
2


fR r 
2
--- r2
3
------
r2
22
---------
–




exp
u r 
=
f' (
 
1
2---
(
 
sin
=
0
(



f )
 
1
2
------
=
0
)
2


fR ' 


r ( )
 


fR r f' (
 f )
 
=
R
'

-1
0
1
2
3
4
5
6
7
8
9
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability density
fQ(u)
fR(u)
fF(u)
u
Figure 6.1  
PDFs of spherical coordinate variables for Example 6.6. (For  color version 
of this figure, the reader is refered to the web version of this chapter.)


264    Chapter 6
www.Academicpress.com
6.5  Estimation and Detection
In this section, we introduce a broad class of problems whereby we are able to observe some 
random quantities and based on those obervations we must try to infer something about some 
related quantity. For example, suppose we are able to observe a set of random variables 
 and then based on that observation we wish to provide the best 
estimate that we can of some related random variable, 
. Some examples of these types of 
problems include the following:
•
Prediction problems: In this case, the 
 may be samples of some signal and 
represents some future value. We would like to predict the future based on observations
of the past. 
•
Interpolation problems: Once again, the 
 may be samples of some signal but in
this case, 
 may represent some intermediate value of the signal. Thus, given
samples of a signal, we wish to interpolate to some in-between point in time. 
•
Filtering problems: In many problems of interest, we are able to observe noisy
measurements of some random quantity in which case we may have a model of the
form 
 where 
 represents the quantity we are trying to measure and the
 represents the noise corrupting the th measurement. In this case, we wish to
filter the noise out of the sequence of observations to provide our best estimate of
the desired quantity, 
.
In another class of problems, the quantity that we wish to estimate is not a random variable, 
but rather a deterministic parameter that is somehow associated with the distribution of the 
observed samples, 
. For example, if the 
 are independent 
observations and all follow some common distribution described by an underlying PDF, 
. We might want to estimate the mean or variance associated with 
. Or, perhaps 
we might want to estimate a tail probability of the form, 
.
In the preceding examples, the quantity that we were trying to estimate was continuous (i.e., 
can take on any of a continuium of values). Sometimes, we are interesting in estimating a 
quantity that is discrete in nature. One classic example of this type of problem is radar 
systems where we are merely trying to decide whether or not a target is present based on 
observing radar returns. Another example is digital communication systems where we are 
trying to determine whether bits take on values of 0 or 1 based on samples of some receive 
signal. These types of problems where the quantity to be estimated takes on discrete values 
are generally referred to as detection problems. One fundamental difference between 
estimation and detection problems involves how we measure success. In a detection problem, 
we might ask how often our guess is correct; however, in an estimation problem, such a 
measure would be meaningless and thus in estimation problems it is more common to 
measure an error between the true value and the estimated value.
X
X1 X2  Xn




	T
=
Y
Xi
Y
Xi
Y
Xi
Y
Ni
+
=
Y
Ni
i
Y
X
X1 X2  Xn




	T
=
Xi
fX x
 
fX x
 
Pr X
xo
%



Multiple Random Variables    265
www.Academicpress.com
6.5.1  Maximum a Posteriori Estimation
The application section at the end of Chapter 2 gave an example of a detection problem where 
we tried to determine whether or not there was light incident on a photodetector based on 
observation of the number of photons emitted. In that example, the choice was made according 
to the a posteriori probabilities of the two options. Following this approach is known as 
maximum a posteriori (MAP) detection. In general, suppose we are trying to detect which of a 
discrete number of possible values 
 the random variable  has taken on given 
observation of 
. The MAP detector will choose6 
 if 
(6.55)
That is, given the observation 
, the MAP detector chooses the most probable value of 
. 
For estimation problems where 
 is continuous, the probability in the previous equation is 
replaced with a PDF and the resulting MAP estimator is 
, where 
.
(6.56)
In other words, the MAP estimator for 
 will be the value which maximizes the conditional 
PDF of 
 given 
.
Example 6.9:
 Suppose  and  are jointly Gaussian with a joint PDF
.
In this case, the conditional PDF works out to be
.
For a given observation, 
, the value of  that maximizes the conditional PDF is 
. Therefore, the MAP estimator for this example is 
.
y1 y2  ym





Y
X
x
=
Yˆ
yk
=
k
max 
i
Pr Y=yi X=x

 ·
arg
=
X
x
=
Y
Y
Yˆ
yMAP
=
yMAP
arg
=
max 
u
fY X u x


Y
Y
X
X
Y
fX Y

x y



1
2 1
2
–
--------------------------
x2
2xy
–
y2
+
2 1
2
–


-----------------------------------
–




exp
=
fY X y x


1
2 1
2
–


-------------------------------
y
x
–

2
2 1
2
–


-----------------------
–




exp
=
X
x
=
y
y
x
=
Yˆ
X
=


6 We use the “hat” notation to represent an estimate so that 
 is an estimate of 
.
Yˆ
Y

266    Chapter 6
www.Academicpress.com
Example 6.10:
Suppose we wish to accurately measure the temperature in a room. We have available to 
us a number of thermometers which will provide us with a temperature reading which is 
equal to the true temperature plus an error which is modeled as a Gaussian random 
variable with zero-mean and some variance 
. Each thermometer provides a reading 
whose error is independent of all other thermometers. If it is known that the true 
temperature has a Gaussian PDF with mean 
 and variance 
, what is the MAP 
estimate of the temperature given the readings of  thermometers?
In this case, we can model each thermometer reading, 
, according to
,  
,
where  is the actual temperature and 
 is the error in the th reading. Conditioned on 
, each thermometer reading will be an independent Gaussian random variable with 
mean  and variance 
. Therefore,
.
The conditional PDF of  given 
 can be found according to Bayes’s theorem,
.
The MAP estimator for the temperature will then be the value of  that maximizes the 
previous conditional PDF. Note that the denominator is not a function of  and so for 
the purposes of finding the MAP estimator, we can simplify the problem by finding the 
value of  that maximizes the numerator. The numerator works out to be
.
Differentiating with respect to  and setting the result equal to zero will show that the 
value of  which optimizes the previous expresion is the solution to the linear equation
.
e
2
t
t
2
n
Xi
Xi
Y
Ni
+
=
i
1 2  n
 

=
Y
Ni
i
Y
y
=
y
e
2
fX Y x y


1
2e
2

n 2

--------------------------
1
2e
2
---------
xi
y
–

2
i
1
=
n

–








exp
=
Y
X
fY X y x


fX Y x y

fY y
 
fX x
 
-----------------------------------
=
y
y
y
fX Y x y

fY y
 
1
2e
2

n 2

--------------------------
1
2e
2
---------
xi
y
–

2
i
1
=
n

–








exp
1
2t
2
-----------------
y
t
–

2
2t
2
---------------------
–






exp
=
1
2

 n
1
+

 2
 e
nt
-------------------------------------------
1
2---
n
e
2
------
1
t
2
------
+



 y2
2
1
e
2
------
xi
i
1
=
n

t
t
2
------
+








y
–
1
e
2
------
xi
2
i
1
=
n

t
2
t
2
------
+








+








–








exp
=
y
y
n
e
2
------
1
t
2
------
+



 y
1
e
2
------
xi
i
1
=
n

t
t
2
------
+








–
0
=


Multiple Random Variables    267
www.Academicpress.com
In other words, for this example, the MAP estimator is given by
.
In the previous expression, the term 
 is the average of all the thermometer 
readings. It is interesting to note that our MAP estimate of the temperature is not just 
the average of the individual readings. Instead, the MAP estimate is skewed by our prior 
knowledge about the temperature as provided by the a priori distribution, 
. 
6.5.2  Maximum Likelihood Estimation
In the previous section, we presented the MAP estimator which is chosen to maximize the 
conditional PDF, 
. Proceeding as in Example 6.8 and using Bayes’s theorem, this 
conditional PDF can be rewritten as
.
(6.57)
As was pointed out in the previous example, the denominator is not a function of  and hence 
has no bearing on the optimization. It is sufficient to find the value of  which maximizes the 
numerator. Furthermore, in many problems of interest, the a priori distribution for 
 may be 
modeled using a uniform distribution. In that case, 
 also does not depend on  (it is 
constant over all allowable values of ) so that the MAP estimator can be found by 
maximizing 
. The estimator that maximizes 
 is known as a maximum 
likelihood (ML) estimator. That is, the ML estimator of 
 given observations 
 is 
, where 
.
(6.58)
In this case, the same formulation can be used when 
 is a discrete random variable. 
Example 6.11:
Consider forming the ML estimator for the temperature estimation in Example 6.8. 
As before, the joint conditional PDF of the set of temperature measurements is 
given by
.
(Continued)
Yˆ
1
e
2
------
Xi
i
1
=
n









t
t
2
------
+
n
e
2
------
1
t
2
------
+
----------------------------------------
1
n---
Xi
i
1
=
n









te
2
nt
2
-----------
+
1
e
2
nt
2
---------
+
------------------------------------------
=
=
1
n---
Xi
i
1
=
n

fY y
 
fY X y x


fY X y x


fX Y x y

fY y
 
fX x
 
------------------------------------
=
y
y
Y
fY y
 
y
y
fX Y x y


fX Y x y


Y
X
x
=
Yˆ
yML
=
yML
arg
=
max
u
fX Y x u


Y
fX Y x y


1
2e
2

n 2

--------------------------
1
2e
2
---------
xi
y
–

2
i
1
=
n

–








exp
=



268    Chapter 6
www.Academicpress.com
The difference in this example is that this time we do not have any prior knowledge 
about the distribution of the true temperature . In that case, we use an ML estimator 
since we do not have enough information to form a MAP estimator. The ML estimator is 
simply the value of  that maximizes the previous joint conditional PDF. Differentiating 
with respect to  and setting equal to zero results in the equation
.
Therefore, the ML estimator is given by
.
In this case, since we have no prior information about the distribution of the 
temperature, the best thing to do is to form a temperature estimate which is simply the 
average of the readings on each thermometer.
6.5.3  Minimum Mean Square Error Estimation
Another common approach to estimation is to construct an estimator that will in some sense 
minimize the error in the estimator. Define the estimation error, 
, to be the difference 
between the true value, 
, and the estimated value, 
,  
.
(6.59)
The error is itself a random variable, so it does not make much sense to try to minimize the 
error. Instead, we might want to choose our estimator such that certain statistics associated 
with the error have desireable properties. Consider, for example the mean of the error, 
. Certainly, we would like this mean to be small, but even if the mean of the error is 
zero, the estimator may still not be very good. Consider an estimator where the error is large 
and positive half the time and large and negative the other half of the time. On the average, the 
error is zero, but the estimator still can have quite large errors. For that reason, it is more 
common to look at the mean-square value of the error, 
. An estimator that 
minimizes this quantity is known as a minimum mean square error (MMSE) estimator. The 
following theorem will simplify the problem of finding the MMSE estimator.
Theorem 6.5: Given an observation, 
, the function 
 which minimizes the 
mean square error, 
 is the conditional expected value, 
.
Proof: Once we condition on 
, the function 
 is simply a scalar constant. 
This optimization problem can then be viewed as finding a value of a constant, , 
Y
y
y
xi
y
–


i
1
=
n

0
=
Yˆ
1
n---
Xi
i
1
=
n

=
Z
Y
Yˆ
Z
Y
Yˆ
–
=
E Y
Yˆ
–

	
E
Y
Yˆ
–

2

	
X
x
=
g X


E
Y
g x
 
–

2 X =x

	
g x
 
E Y X =x

	
=
X = x


g x
 
c


Multiple Random Variables    269
www.Academicpress.com
which minimizes the MSE, 
. Differentiating (with respect to ) and 
setting equal to zero results in 
 and therefore the optimum value of 
the constant is 
.
Example 6.12:
Consider a set of observations, 
, 
, whose PDFs conditioned on 
 are 
each independent and exponentially distributed with means of 
, 
.
Furthermore, suppose  is also an exponential random variable with a mean of 1 so that
.
In order to find the MMSE estimator of  given observation of 
, we need to find 
the conditional expectation. Toward that end, we find the conditional PDF of  given  
,
.
The marginal PDF needed in the denominator is found as
.
The last step in the preceding equation was acomplished using the normalization 
integral for an Erlang PDF. The conditional PDF is then
.
The mean of this conditional distribution works out to be
.
Therfore, the MMSE estimator is
.
(Continued)
E
Y
c
–

2

	
c
E 2 Y
c
–



	
0
=
c
E Y
 	
=
Xi
i
1 2  n
 

=
Y
y
=
1 y

fX Y x y


y
yxi
–


exp
u xi


i
1
=
n

=
Y
fY y
 
y
–


exp
u y
 
=
Y
X = x


Y
X = x


fY X y x


fX Y x y

fY y
 
fX x
 
-----------------------------------
=
fX x
 
fX Y x y

fY y
  y
d
0


yn
1
xi
i
1
=
n

+








y
–








exp
y
d
0


n!
1
xi
i
1
=
n

+







 n
1
+
--------------------------------------
=
=
=
fY X y x


1
xi
i
1
=
n

+







 n
1
+
n!
--------------------------------------yn
1
xi
i
1
=
n

+








y
–








exp
=
E Y X =x

	
n
1
+
1
xi
i
1
=
n

+
-----------------------
=
Yˆ MMSE
n
1
+
1
Xi
i
1
=
n

+
------------------------
=


270    Chapter 6
www.Academicpress.com
We could also work out the ML and MAP estimators for this problem. The ML estimator 
would be the value of  that maximizes 
, while the MAP estimator maximizes 
. Since expressions for both of these conditional PDFs have already been given, it 
is only a matter of some straighforward calculus to produce
 and 
All three estimators have a similar functional form but yet are all slightly different.
Quite often, the MMSE estimator can be difficult to find. In such cases, it is common to 
restrict ourselves to linear estimators. Given an observation, 
, a linear estimator of 
 
will be of the form 
 for constants 
, 
. With a linear estimator, the MSE becomes
.
(6.60)
Optimizing with respect to the th of these constants (i.e., differentiating with respect to 
 
and setting equal to zero) produces
.
(6.61)
This produces a result known as the orthogonality principle which states that for linear MMSE 
(LMMSE) estimators, the estimator must be chosen so that the error in the estimator must be 
orthogonal to each observation. Noting that the orthogonality principle must hold for each 
observation (i.e., each 
) and combining all the results in vector form produces
,
(6.62)
where 
 is the vector of LMMSE coefficients. This is a set of linear 
equations for the unknown coefficients. Define the vector of correlations between the 
observations and the value to be estimated as
,
(6.63)
and define the correlation matrix of the observations as
y
fX Y x y


fY X y x


Yˆ
ML
1
n---
Xi
i
1
=
n








 1
–
=
Yˆ
MAP
n
1
Xi
i
1
=
n

+
------------------------
=
X = x


Y
Yˆ
g X


a1X1
a2X2

anXn
+
+
+
=
=
ai
i
1 2  n
 

=
E
Y
Yˆ
–

2

	
E
Y
a1X1
a2X2

anXn
+
+
+


–

2

	
=
k
ak
E Xk Y
a1X1
a2X2

anXn
+
+
+


–



	
0
=
Xk
E X Y
XTa
–



	
0
=
a
a1 a2  an




	T
=
p
E XY

	
E X1Y

	
E X2Y

	

E XnY

	
=
=


Multiple Random Variables    271
www.Academicpress.com
.
(6.64)
Then the coefficients of the LMMSE estimator are the solution to the linear equations
,
(6.65)
which is given by
.
(6.66)
Example 6.13:
Suppose we try to find the LMMSE estimator for the temperature measuring problem of 
Example 6.8. It is interesting to note that, for this example, both the MAP estimator 
(found in Example 6.8) and the ML estimator (found in Example 6.9) were linear. That 
is, both estimators formed a linear combination of the obervations, 
. In order to find 
the LMMSE coefficients, we will need to evaluate the correlations indicated in Equations 
(6.63) and (6.64). Fortunately, for this example, these correlations are fairly simple to 
work out.
.
In the previous calculations, we have used the fact that  is independent of the noise 
terms, 
, and that 
. Note that 
 is the same for all  so that the vector, , 
of correlations takes the form of a constant times a column vector of all ones, 
, where we use the notation 
 to represent an -element column vector 
of all ones. Similarly, the correlation matrix, 
, can be written as a constant times a 
matrix of all ones plus another constant times an identity matrix, 
, 
where  is an identity matrix. Putting all of these computations into the matrix equation 
indicated in Equation (6.65) results in
.
(Continued)
RXX
E XXT

	
E X1
2

	
E X1X2

	  E X1Xn

	
E X2X1

	
E X2
2

	
 E X2Xn

	



E XnX1

	 E XnX2

	 
E Xn2

	
=
=
RXXa
p
=
a
RXX1
– p
=
Xi
E XiY

	
E
Y
Ni
+

Y

	
E Y2

	
E NiY

	
+
E Y2

	
E Ni

	E Y
 	
+
E Y2

	
t
2
t
2
+
=
=
=
=
=
E XiXj

	
E
Y
Ni
+

 Y
Nj
+



	
E Y2

	
E YNi

	
E YNj

	
E NiNj

	
+
+
+
t
2
t
2
+
,
  i
j,

t
2
t
2
e
2
+
+
,  i
j
= .
*
+
,
+
-
=
=
=
Y
Ni
E Ni

	
0
=
E XiY

	
i
p
p
t
2
t
2
+

1n
=
1n
n
RXX
RXX
t
2
t
2
+

1n1n
T
e
2I
+
=
I
t
2
t
2
+

1n1n
T
e
2I
+

	a
t
2
t
2
+

1n
=


272    Chapter 6
www.Academicpress.com
It turns out that the solution to this matrix equation is proportional to the all ones 
vector. To demonstrate this, assume a solution of the form 
 for some constant . 
Plugging this proposed solution into the previous equation produces
.
Here, we have used the fact that the inner product 
 is equal to  and that 
. Therefore, we get equality in the previous equation if the constant is selected 
according to
.
Therefore, the LMMSE estimator for this problem is
.
In this case, the LMMSE estimate of the temperature is a scaled version of the average of 
the individual temperature readings.
In the next sections, an engineering application is presented which demonstrates how LMMSE 
estimation is used to predict future values of a speech waveform and how that is used in a 
simple speech coder. In the next chapter, we will turn our attention to problems involving 
estimation of various parameters of a distribution.
6.6  Engineering Application: Linear Prediction of Speech
In many applications, we are interested in predicting future values of a waveform given current 
and past samples. This is used extensively in speech coders where the signal-to-quantization 
noise associated with a quantizer can be greatly increased if only the prediction error is 
quantized. A fairly simple speech coder which utilizes this idea is illustrated in Figure 6.2. In 
Section 4.11, we introduced the idea of scalar quantization. The process of sampling (at or 
above the Nyquist rate), quantizing, and then encoding each quantization level with some 
binary codeword is known as pulse code modulation (PCM). In Figure 6.2, we consider a 
slight modification to the basic PCM technique known as differential PCM (or DPCM). The 
basic idea here is that if we can reduce the range of the signal that is being quantized, then we 
can either reduce the number of quantization levels needed (and hence reduce the bit rate of 
the speech coder) or reduce the amount of quantization noise and hence increase the SQNR. 
a
c1n
=
c
t
2
t
2
+

1n1n
T
e
2I
+

	c1n
t
2
t
2
+

1n
=
t
2
t
2
+

n
e
2
+

	c1n
t
2
t
2
+

1n
=
1n
T1n
n
I1n
1n
=
c
t
2
t
2
+
t
2
t
2
+

n
e
2
+
----------------------------------------
=
Yˆ
LMMSE
t
2
t
2
+
t
2
t
2
+

n
e
2
+
----------------------------------------
Xi
i
1
=
n

1
n---
Xi
i
1
=
n

1
e
2
t
2
t
2
+

n
---------------------------
+
-------------------------------------
=
=


Multiple Random Variables    273
www.Academicpress.com
A typical speech signal has a frequency content in the range from about 300 to 3500 Hz. In 
order to be able to recover the signal from its samples, a typical sampling rate of 8 kHz is used 
which is slightly higher than the Nyquist rate. However, much of the energy content of a 
speech signal lies in a frequency band below about 1 kHz; thus, when sampled at 8 kHz, a 
great deal of the speech signal does not change substantially from one sample to the next. 
Stated another way, when the speech signal is sampled at 8 kHz, we should be able to predict 
future sample values from current and past samples with pretty good accuracy. The DPCM 
encoder does exactly that and then only quantizes and encodes the portion of the signal that it 
is not able to predict.
In Figure 6.2, the 
 represent samples of a speech waveform. These samples are input to the 
predictor whose job is to make its best estimate of 
 given 
 as 
inputs. It is common to use linear prediction, in which case the predictor output is a linear 
combination of the inputs. That is, assuming the predictor uses the last 
 samples to form its 
estimate, the predictor output is of the form
,
(6.67)
where the 
 are constants that we select to optimize the performance of the predictor. The 
quantity 
 is the predictor error, which we want to make as small as possible. 
This error is quantized with a scalar quantizer which uses 
 levels and each level is encoded 
with a  bit codeword. The overall bit rate of the speech coder is 
 bits/second, where 
 
is the rate (in Hz) at which the speech is sampled. For example, if a 16-level quantizer were 
used with a speech sampling rate of 8 kHz, the DPCM speech coder would have a bit rate of 
32 kbits/second. 
An important question is “Can the original samples be recovered from the binary 
representation of the signal?”  Given the encoded bit stream, we can construct the sequence of 
quantizer outputs, 
. As with any quantization scheme, we can never recover the exact quantizer 
input from the quantizer output, but if we use enough levels in the quantizer, the quantization 
noise can be kept fairly small. The speech samples are reconstructed according to 
. Since we do not have 
 we use 
 in its place and form
,
(6.68)
+
Predictor
Quantizer
Encoder
+-
Xn
Yn
Zn
Qn
Binary
data
output
Figure 6.2  
Block diagram of a simple speech coder using differential pulse code modulation.
Xn
Xn
Xn
1
–
Xn
2
–
Xn
3
–




m
Yn
aiXn
i
–
i
1
=
m

=
ai
Zn
Xn
Yn
–
=
2b
b
b*fs
fs
Qn
Xn
Yn
Zn
+
=
Zn
Qn
Xˆ n
Yn
Qn
+
Xn
n
+
=
=

274    Chapter 6
www.Academicpress.com
where 
 is the quantization noise in the th sample. To complete the process of 
recovering the sample values, the decoder must also form the 
. It can do this by employing 
an identical predictor as used at the encoder. Unfortunately, the predictor at the decoder does 
not have access to the same input as the predictor at the encoder. That is, at the decoder we 
cannot use the true values of the past speech samples, but rather must use the quantized (noisy) 
versions. This can be problematic since the predictor at the decoder will now form
.
(6.69)
If the 
 are noisy versions of the 
, then the 
 will also be noisy. Now, not only do we 
have quantization noise, but that noise propagates from one sample to the next through the 
predictor. This leads to the possibility of a snowballing effect, where the noise in our 
recovered samples gets progressively larger from one sample to the next.  
The above problem is circumvented using the modified DPCM encoder shown in Figure 6.3;  
the corresponding decoder is shown in the figure as well. The difference between this DPCM 
system and the one in Figure 6.2 is that now the predictor used in the encoder bases its 
predictions on the quantized samples rather than on the true samples. By doing this, the 
predicted value may be slightly degraded (but not much if the number of quantization levels is 
sufficient), but there will be no propagation of errors in the decoder, since the predictor at the 
decoder now uses the same inputs as the predictor at the encoder. 
Now that we have the design of the speech encoder and decoder squared away, we shift our 
attention to the problem of designing the predictor. Assuming a linear predictor, the problem is 
essentially to choose the coefficients 
 in Equation (6.67) to minimize the prediction error:
.
(6.70)
n
Qn
Zn
–
=
n
Yn
Yˆ n
aiXˆ n
i
–
i
1
=
m

=
Xˆ n
Xn
Yˆ n
+
Predictor
Quantizer
Encoder
+-
Xn
Yn
ˆ
Zn
Qn
Binary
data
output
DPCM encoder
+
Predictor
Decoder
+
Xn
ˆ
Yn
ˆ
Qn
Binary
data
input
DPCM decoder
+
Figure 6.3  
Block diagram of a modified speech coder using differential pulse code modulation.
ai
Zn
Xn
Yn
–
Xn
aiXn
i
–
i
1
=
m

–
=
=

Multiple Random Variables    275
www.Academicpress.com
Following the theory developed in Section 6.5.3, we choose the predictor coefficients to 
minimize the MSE:
.
(6.71)
Define the correlation parameter 
 to be the correlation between two samples 
spaced by  sampling intervals. Then the system of equations in Equation (6.65) can be 
expressed in matrix form as
,
(6.72)
and the predictor coefficients are simply the solution to this set of linear equations.
Example 6.14:
Figure 6.4 shows a segment of speech that has a duration of about 2 s, which was 
sampled at a rate of 8 kHz. From this data, (using MATLAB) we estimated the 
correlation parameters 
; found the linear prediction coefficients, 
, 
, and then calculated the mean squared estimation error, 
. 
The results are shown in Table 6.1. We should note a couple of observations. First, even 
with a simple one-tap predictor, the size of the error signal is much smaller than the 
original signal (compare the values of MSE with 
 in the table). Second, we note that 
(for this example) there does not seem to be much benefit gained from using more than 
two previous samples to form the predictor. 
Finally, in Figure 6.5 we compare the quality of the encoded speech as measured by the 
SQNR for PCM and the DPCM scheme of Figure 6.3 using the two-tap predictor 
specified in Table 6.1. For an equal number of bits per sample, the DPCM scheme 
improves the SQNR by more than 20 dB. Alternatively, the DPCM scheme can use 3 
bits/sample fewer than the PCM scheme and still provide better SQNR.
Table 6.1: Results of linear prediction of speech segment form Figure 6.4
 
 
  
 
E Zn
2


E
Xn
aiXn
i
–
i
1
=
m

–

	





 2
=
rk
E XnXn
k
–


=
k
r0
r1
r2
 rm
1
–
r1
r0
r1
 rm
2
–
r2
r1
r0
 rm
3
–




rm
1
–
rm
2
–
rm
3
–

r0
a1
a2
a3

am
r1
r2
r3

rm
=
rk
E XnXn
k
+


=
ai
i
1 2  m
 

=
MSE
E
Xn
Yn
–

2


=
r0
r0
0.0591
=
r1
0.0568
=
r2
0.0514
=
r3
0.0442
=
r4
0.0360
=
m
1
=
a1
0.9615
=
MSE
0.004473
=
m
2
=
a1
1.6564
=
a2
0.7228
–
=
MSE
0.002144
=
m
3
=
a1
1.7166
=
a2
0.8492
–
=
a3
0.0763
=
MSE
0.002132
=
m
4
=
a1
1.7272
=
a2
1.0235
–
=
a3
0.4276
=
a4
0.2052
–
=
MSE
0.002044
=


276    Chapter 6
www.Academicpress.com
  
0
0.5
1
1.5
2
-1
-0.8
-0.6
−0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
X(t)
Figure 6.4  
Speech segment used in Example 6.7.
(For color version of this figure, the reader is refered to the web version of this chapter.)
1
2
3
4
5
6
7
8
−10
0
10
20
30
40
50
60
70
Number of bits per sample
SQNR
DPCM
PCM 
Figure 6.5  
SQNR comparison of PCM and DPCM speech coders for the speech segment in Figure 6.4.
(For color version of this figure, the reader is refered to the web version of this chapter.)


277
CHAPTER 6
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 6.1:  Joint and Conditional PMFs, CDFs, and PDFs
6.1
Suppose we flip a coin three times, thereby forming a sequence of heads and tails. Form 
a random vector by mapping each outcome in the sequence to 0 if a head occurs or to 1 if 
a tail occurs. 
(a)
How many realizations of the vector may be generated? List them. 
(b)
Are the realizations independent of one another? 
6.2
Let 
 represent a three-dimensional vector of random variables that is 
uniformly distributed over a cubical region 
(a)
Find the constant .
(b)
Find the marginal PDF for a subset of two of the three random variables.  For 
example, find 
.
(c)
Find the marginal PDF for one of the three random variables.  That is, find 
.
(d)
Find the conditional PDFs 
 and 
.
(e)
Are the 
 independent?
6.3
Suppose a point in two-dimensional Cartesian space, 
, is equally likely to 
fall anywhere on the semicircle defined by 
 and 
.  Find the PDF 
of 
, 
.
6.4
Suppose a point in three-dimensional Cartesian space, 
, is equally likely to fall 
anywhere on the surface of the hemisphere defined by 
 and 
.
(a)
Find the PDF of 
, 
.
(b)
Find the joint PDF of 
 and 
, 
.
6.5
Suppose 
 is a discrete random variable equally likely to take on any integer in the set 
.  Given that 
, the random variable 
 is equally likely to take on any 
X
X1 X2 X3



T
=
fX x
 
c,    x1
1

x2
1

x3
1

,


0,
otherwise.

	

=
c
fX1 X2

x1 x2



fX1 x1


fX1 X2 X3

x1 x2 x3



fX1 X2

X3 x1 x2

x3


Xi
X Y



X2
Y2
+
1
=
Y
0

Y
fY y
 
X Y Z




X2
Y2
Z2
+
+
1
=
Z
0

Z
fZ z 
X
Y
fX Y

x y



N1
1 2 3
 


N1
n1
=
N2

278    Chapter 6
www.Academicpress.com
integer in the set 
.  Finally, given that 
, the random variable 
 
is equally likely to take on any integer in the set 
.
(a)
Find the two-dimensional joint PMF, 
.
(b)
Find the three-dimensional joint PDF, 
.
(c)
Find the marginal PDFs, 
 and 
.
(d)
What are the chances that none of the three random variables are equal to 1?
6.6
Let 
 represent a three-dimensional vector of random variables that is 
uniformly distributed over the unit sphere.  That is, 
(a)
Find the constant .
(b)
Find the marginal PDF for a subset of two of the three random variables.  For 
example, find 
.
(c)
Find the marginal PDF for one of the three random variables.  That is, find 
.
(d)
Find the conditional PDFs 
 and 
.
Extra:  Can you extend this problem to 
-dimensions?
6.7
Let 
 represent an N-dimensional vector of random variables that 
is uniformly distributed over the region 
, 
, 
. 
That is
(a)
Find the constant .
(b)
Find the marginal PDF for a subset of 
 of the 
 random variables.  
(c)
Are the 
 independent?  Are the 
 identically distributed?
1 2  n1
 



N2
n2
=
N3
1 2  n2
 



PN1 N2

n1 n2



PN1 N2 N3


n1 n2 n3




PN2 n2


PN3 n3


X
X1 X2 X3



T
=
fX x
 
c,
x
1,

0, x
1.


	

=
c
fX1 X2

x1 x2



fX1 x1


fX1 X2 X3

x1 x2 x3



fX1 X2

X3 x1 x2

x3


N
X
X1 X2  XN




T
=
x1
x2

xN
+
+
+
1

xi
0

i
1 2  N
 

=
fX x
 
c,      
xi
i
1
=
N

1

xi
0,


0,
otherwise.         


	


=
c
M
N
Xi
Xi

Exercises    279
www.Academicpress.com
Section 6.2:  Expectations Involving Multiple Random Variables
6.8
Consider a vector of 
 random variables, 
.  Suppose we form a 
new random variable  by performing a weighted average of the components of 
.  That is,
, 
where 
 and 
.  Find the values of the constants 
 such that the variance 
of 
 is minimized.
6.9
A random vector is generated by rolling a die and observing the outcome.  The 
components of the random vector are determined by successive rolls of the die.  If the die 
is rolled two times:
(a)
List the possible realizations of the random vector;
(b)
Determine the probability of each realization;
(c)
Determine the mean vector;
(d)
Determine the covariance matrix.
6.10 Repeat parts (c) and (d) of Exercise 6.9 if a three-element vector is formed from three 
rolls of a die.
6.11 Let 
 be a vector of random variables where each component is 
independent of the others and uniformly distributed over the interval 
.
(a)
Find the mean vector, 
.
(b)
Find the correlation matrix, 
.
(c)
Find the covariance matrix, 
.
6.12 A vector random variable, 
, has a mean vector and correlation matrix given by 
 
 and 
. 
A new random vector is formed according to
 where the matrix 
 is given by
.
Find the mean vector, correlation matrix and covariance matrix of 
.
N
X
X1 X2  XN




T
=
Z
X
Z
biXi
i
1
=
N

=
bi
0

bi
i
1
=
N

1
=
bi
Z
X
X1 X2  Xn




T
=
0 1



E X


RXX
E XXT


=
CXX
E
X
E X


–

 X
E X


–

T


=
X
E X


2
1
–
1
=
RXX
13 2
3
2 10 3
3
3 10
=
Y
AX
=
A
A
1
0
1
–
0
1
–
1
1
–
1
0
=
Y

280    Chapter 6
www.Academicpress.com
6.13 A vector random variable, 
, has a covariance matrix and a correlation matrix given by
 and 
.
Find the mean vector, 
.
6.14 Three zero-mean random variables 
 have  a covariance matrix given by
.
Find the value of the constants  and  so that the variance of  
 is 
minimized.
Section 6.3:  Gaussian Random Variables in Muliple Dimensions
6.15 Let 
 be a zero-mean Gaussian random vector with covariance matrix,
.
Write out the joint PDF, 
.
6.16 Let 
, 
, and 
 be a set of three zero-mean Gaussian random variables with a 
covariance matrix of the form
.
X
CXX
5
1
–
2
1
–
5
2
–
2
2
–
8
=
RXX
6 1
1
1 9
4
–
1
4
–
9
=
E X


X Y Z




C
E
X
Y
Z
X Y Z
1
1 2

1 4

1 2

1
1 2

1 4

1 2

1
=
=
a
b
Z
aX
–
bY
–
X
Y
Z
C
2
1
–
1
1
–
4 1
1
–
1 3
=
fX Y Z


x y z
 


X1 X2
X3
C
2
1  
 1 
  1
=

Exercises    281
www.Academicpress.com
Find the following expected values:
(a)
,
(b)
,
(c)
.
6.17 Define the 
-dimensional characteristic function for a random vector, 
, according to 
 where 
.  Show that the 
-dimensional characteristic function for a 
zero-mean Gaussian random vector is given by
.
6.18 For any four zero-mean Gaussian random variables 
, 
, 
, and 
, show that
.
Hint: You might want to use the result of the previous exercise.
Note: This useful result is referred to as the Gaussian moment-factoring theorem and 
allows us to decompose fourth-order moments into a series of simpler second-order 
moments.
Section 6.4:  Transformations Involving Multiple Random Variables
6.19 Let 
 be a two-element zero-mean random vector.  Suppose we construct a new random 
vector 
 according to a linear transformation, 
.  Find the transformation 
matrix, 
, such that 
 has a covariance matrix of
.
For this problem, assume that the covariance matrix of the vector 
 is an identity matrix.
6.20 A three-dimensional vector random variable, 
, has a covariance matrix of 
.
Find a transformation matrix 
 such that the new random variables 
 will be 
uncorrelated.
E X1 X2 = x2 X3 = x3



E X1X2 X3 = x3


E X1X2X3


N
X
X1 X2  XN




T
=
X W


E ejW TX


=
W
1 2  N




T
=
N
XW
WTCXXW
2
------------------------
–




exp
=
X1 X2 X3
X4
E X1X2X3X4


E X1X2

E X3X4


E X1X3

E X2X4


E X1X4

E X2X3


+
+
=
X
Y
Y
TX
=
T
Y
CYY
5 1
1 2
=
X
X
C
3
1
1
–
1
5
1
–
1
–
1
–
3
=
A
Y
AX
=

282    Chapter 6
www.Academicpress.com
6.21 Suppose 
, 
 are a sequence of independent and exponentially 
distributed random variables with
.
Assuming that  is an odd number (
 for some integer ):
(a)
Find the PDF of the median of the sequence.
(b)
Find the expected value of the median of the sequence.  Is the median an unbiased 
estimate of the mean of the underlying exponential distribution?
(c)
Find the variance of the median of the sequence.  
6.22   Show that the derivative of 
reduces to the form
.
6.23 In this problem, we formulate an alternative derivation of Equation (6.58) which gives 
the PDF of the order statistic, 
, which is the 
th largest of a sequence of 
 random 
variables, 
.  Start by writing 
.  Then 
note that
    
    
.
Find the probability of the above event and by doing so, prove that the PDF of 
 is as 
given by Equation (6.58).
6.24 Suppose 
, 
, and 
 are independent, zero-mean, unit-variance Gaussian random 
variables.  
(a)
Using the techniques outlined in Section 6.4.2, find the characteristic function of 
.
(b)
From the characteristic function found in part (a), find the mean and variance of 
.
(c)
Confirm your answer in part (b) by finding the mean and variance of 
 directly.  In 
this part, you may want to use the result of the Gaussian moment factoring theorem 
developed in Exercise 6.18.
Xm
m
1 2  n
 

=
fXm x
 
1
---
x 

–


exp
u x
 
=
n
n
2k
1
–
=
k
FYm y
 
N
k
 
  FX y
 

k 1
FX y
 
–

N
k
–
k
m
=
N

=
fYm y
 
N!
m
1
–

! N
m
–

!
-----------------------------------------fX y
  FX y
 

m
1
–
1
FX y
 
–

N
m
–
=
Ym
m
N
X1 X2  XN



fYm y
 dy
Pr y
Ym
y
dy
+




=
Pr y
Ym
y
dy
+




Pr
m
1 of the Xs are less than y
–

 

=
1 X is between y and y
dy
+


n
m of the Xs are greater than y
–





Ym
X Y
Z
W
XY
XZ
YZ
+
+
=
W
W

Exercises    283
www.Academicpress.com
6.25 Find the PDF of 
 assuming that all of the 
 are 
independent zero-mean, unit-variance, Gaussian random variables.  Hint:  Use the result 
of Special Case #2 in Section 6.4.2.1 to help.
6.26 Let 
 be a sequence of five independent discrete random variables, each 
with a distribution described by:
(a) 
Find the probability mass function of the median (third largest) of these five 
samples.
(b) For this random variable, is the median an unbiased estimate of the mean?  That is, 
does the expected value of the median equal the mean of the 
?  Prove your 
answer.
(c) 
Find the variance of the median.
6.27 A set of  random variables, 
, 
, 
, . . ., 
, are independent and each uniformly 
distributed over (0, 1).  
(a) 
Find the probability density function of  
.
(b) With 
 defined as in part (a) above, let 
 be the event 
 and find 
.  That is, find the conditional PDF of 
 given 
.
Section 6.5:  Estimation and Detection
6.28 Let the random variables 
 and 
 be as described in Exercise 6.40.
(a)
Find the MAP estimator of 
 given the observation 
.
(b)
Find the ML estimator of 
 given the observation 
.
(c)
Find the LMMSE estimator of 
 given the observation 
.
(d)
Find the MSE of each estimator in (a), (b), and (c).
6.29 Repeat Exercise 6.28 assuming we wish to find an estimate of 
 given the observation 
.
6.30 Let the random variables 
, 
, and 
 be as described in Exercise 6.40.
(a)
Find the MAP estimator of 
 given the observation 
.
(b)
Find the ML estimator of 
 given the observation 
.
Z
X1X2
X3X4
X5X6
X7X8
+
+
+
=
Xi
X1 X2  X5



Pr Xk=m


0.8
     m = 0,
0.1
m = 
1,

0
 m
1.



	


=
Xi
n
X1 X2 X3
Xn
Z
max X1 X2  Xn





=
Z
A
X1
1 2

=


fZ A z 
Z
X1
1 2

=


U
V
U
V
v
=
U
V
v
=
U
V
v
=
V
U
u
=
U V
W
U
V
v
=
W=w



U
V
v
=
W=w




284    Chapter 6
www.Academicpress.com
(c) 
Find the LMMSE estimator of 
 given the observation 
.
(d)
Find the MSE of each estimator in (a), (b), and (c).
6.31 Let 
 be the random vector described in Exercise 6.12.  
(a)
Find the LMMSE estimator of 
 given observation of 
.
(b)
Find the MSE of the estimator in part (a).
(c)
Explain why we cannot find the MAP or ML estimators in this case.
6.32 Let 
, 
, and 
 be the random vectors described in Exercise 6.35.
(a)
Find the LMMSE estimator of 
 given 
.
(b)
Find the LMMSE estimator of 
 given 
.
(c)
Find the LMMSE estimator of 
 given 
.
6.33 Repeat Exercise 6.32 using ML estimators.
6.34 Repeat Exercise 6.32 using MAP estimators.
Miscellaneous Exercises
6.35 Suppose 
, 
, and 
 are jointly Gaussian random variables with mean vector and 
covariance matrix given by
 and 
.
Find 
.
6.36 The traffic managers of toll roads and toll bridges need specific information to 
properly staff the toll booths so that the queues are minimized (i.e., the waiting 
time is minimized). 
(a) 
Assume that there is one toll booth on a busy interstate highway and that  the 
number of cars per minute approaching the toll booth follows a Poisson  PMF with 
. The traffic manager wants you to determine the probability that exactly 
11 cars approach this toll booth in the minute from noon to 1 min  past noon. 
(b)
 Now assume that there are 
 toll booths at a toll plaza and that the number of 
cars per minute approaching the plaza follows the same Poisson PMF with 
. The traffic manager wants you to calculate the minimum number 
U
V
v
=
W=w



X
X1
X2=x2 X3=x3



X Y
Z
X
Y = y Z = z



Y
X =x Z = z



Z
X =x Y = y



X Y
Z
E
X
Y
Z
3
1
–
2
–
=
C
E
X
Y
Z
X Y Z
4
1
–
1
1
–
4 1
1
1 4
=
=
Pr X
2Y
3X
–




10
=
N

30
=

Exercises    285
www.Academicpress.com
of toll booths that need to be staffed if the probability that more than five cars 
approach any toll booth in one minute is no more than 0.05. For this part, 
assume the traffic approaching the plaza divides evenly among the 
 booths 
such that the traffic approaching each booth is independent and follows 
a Poisson PMF with 
.
6.37 A sequence of zero mean unit variance independent random variables, 
, 
 are input to a filter that produces an output sequence according to 
, for 
.  For initialization purposes, 
 is 
taken to be zero.  
(a)
Find the covariance (correlation) matrix of the 
. 
(b)
Now let the variance of the 
 be 
.  Find the covariance (correlation) matrix of 
the 
.
6.38 Repeat Exercise 6.37 with the filter is changed to 
.
6.39 Suppose a zero mean random sequence 
 has correlation parameters given by 
.  An estimate of a future value of 
 is 
 which is a special case of Equation (6.67).  
(a)
Use Equation (6.72) to find the 
.  
(b)
What is the mean squared error, 
?
6.40 Let 
, 
, and 
 be a set of independent, zero-mean, unit-variance, Gaussian random 
variables.  Form a new set of random variables according to
,
,
.
(a) 
Find the three one-dimensional marginal PDFs, 
, 
, and 
.
(b)
Find the three two-dimensional joint PDFs, 
, 
, and 
.
(c)
Find the three-dimensional joint PDF of 
, 
, and 
, 
.
6.41 A radio astronomer is attempting to measure radio frequency (RF) emmisions from a 
certain star.  However, these emissions are corrupted by a variety of independent noise 
sources including thermal noise in his receiving equipment, interference from local RF 
N

30 N

=
Xn
n
0 1 2  N
1
–
  

=
Yn
Xn
Xn
1
–
+

 2

=
n
0 1 2  N
1
–
  

=
X 1
–
Yn
Xn
X
2
Yn
Yn
Xn
Xn
1
–
–
=
Xn
rk
E XnXn
k
+


c k
=
=
Xn
Xˆ
n
a1Xn
1
–
a2Xn
2
–
+
=
ai
E
Xn
Xˆ
n
–

2


X Y
Z
U
X
=
V
X
Y
+
=
W
X
Y
Z
+
+
=
fU u
 
fV v
 
fW w


fU V

u v



fV W

v w



fU W

u w



U V
W
fU V W


u v w
 



286    Chapter 6
www.Academicpress.com
sources, and galactic noise.  The astronomer has studied each of these sources and found 
them all to be well modeled as zero-mean Gaussian random variables with the following 
standard deviations:
, thermal noise, 
,
, interference, 
,
, galactic noise, 
.
Let 
 represent the combined effect of all three noise sources, that is 
.  
Suppose the desired emissions from the star are received at a level of 10 V.  What is  the 
probability that the combined noise is larger than the desired emissions?  Hint:  First find 
the relevant PDF of 
 and then find the probability that 
 is bigger  than 10 V.
6.42 A certain system we have designed needs to be powered by a 24-V dc supply. 
Available to us in our lab are each of the following types of batteries whose statistical 
characteristics (and quantities available) are as shown in the table. The system can 
tolerate variations in the supply voltage that are within 1 V of the designed 24 V level.  
Anything outside that range will damage the system.  Your job is to come up with 
a combination of the batteries that will lead to the highest probability that the 
combined supply voltage will remain within the range 23-25 V.  Assume the voltage 
of each battery is a Gaussian random variable and is independent of the others and 
the means and standard deviations of each battery are as shown in the table.  State 
how you would form some combination of the batteries available to produce the 
desired supply voltage.  Also specify what is the probability that your combination 
of batteries falls within the desired range.  
T
T
5V
=
I
I
2V
=
G
G
1V
=
N
N
T
I
G
+
+
=
N
N
Battery characteristics
“Nominal” 
Voltage (V)
Number 
Available (V)
Average 
Voltage (V)
Standard 
Deviation (V)
24
  1
23.5
1
12
  2
11.8
0.5
6
  4
5.9
0.3 
1.5
12
1.45
0.2 
0.5
30
0.475
0.1

Exercises    287
www.Academicpress.com
6.43 Let 
 be a pair of independent random variables with the same exponential PDF,  
,  
.
Define 
 to be the order statistics associated with the 
.  That is, 
 and 
.  
(a)
Find the marginal PDFs of 
 and 
, 
 and 
.
(b)
Find the joint PDFs of 
 and 
, 
.
(c)
Find the MAP estimator of 
 given 
.
(d)
Find the ML estimator of 
 given 
.
(e)
Find the LMMSE estimator of 
 given 
.
(f)
Find the MSE of each estimator in (c), (d), and (e).
MATLAB Exercises
6.44 Three jointly Gaussian random variables 
 have a mean vector 
 and covariance matrix
.
Use MATLAB to help you find the form of the three-dimensional joint PDF, 
.
6.45 For each of the following matrices, determine if the matrix is a valid correlation matrix.  
In some cases, you may want to use MATLAB to check if the matrix is positive definite.
(a) 
,
(b) 
, 
(c) 
,
(d)
, 
(e) 
, 
(f) 
.
X1 X2

fXi x
 
x
–

u x
 
exp
=
i
1 2

=
Y1 Y2

Xi
Y1
min X1 X2



=
Y2
max X1 X2



=
Y1
Y2
fY1 y1


fY2 y2


Y1
Y2
fY1 Y2

y1 y2



Y2
Y1
y1
=
Y2
Y1
y1
=
Y2
Y1
y1
=
X Y Z



T
m
1 0
1
–
 

T
=
C
4 2
1
–
2 4 2
1
–
2 4
=
fX Y Z
,
,
x y z
 


Ca
3
2
–
1
2
6 0
1
–
0 2
=
Cb
3
2
–
3
2
–
6 0
3
0 2
=
Cc
3
2
–
1
2
–
6 0
1
0 2
=
Cd
1
1
2---
–
1
4---
1
8---
–
1
2---
–
1
1
2---
–
1
4---
1
4---
1
2---
–
1
1
2---
–
1
8---
–
1
4---
1
2---
–
1
=
Ce
11
3
–
7
5
3
–
11 5
7
7
5 11
3
–
5
7
3
–
11
=
Cf
5
1
3
1
–
1
5
1
–
3
3
1
–
5
1
1
–
3
1
5
=

288    Chapter 6
www.Academicpress.com
6.46 For each matrix in Exercise 6.45 that is a valid correlation matrix, find a transformation 
matrix that will transform a set of independent, zero-mean, unit variance random 
variables into ones with the specified correlation matrix.
6.47 Given a random sequence 
 with a covariance matrix
,
find a linear transformation that will produce a random sequence 
 
with a covariance matrix
.
X
X1 X2 X3 X4





=
CX
1
0.3 0.09 0.027
0.3
1
0.3 0.027
0.09
0.3
1
0.3
0.0027 0.09 0.3
1
=
Y
Y1 Y2 Y3 Y4





=
CY
1 0.1 0.2 0.3
0.1 1 0.1 0.2
0.2 0.1 1 0.1
0.3 0.2 0.1 1
=

289
CHAPTER 7
Probability and Random Processes. DOI: 10.116/B978-0-12-386981-4.00007-3
© 2012 by Elsevier Inc. All rights reserved.
Random Sums and Sequences
This chapter forms a bridge between the study of random variables in the previous chapters 
and the study of random processes to follow.  A random process is simply a random function 
of time.  If time is discrete, then such a random function could be viewed as a sequence of 
random variables.  Even when time is continuous, we often choose to sample waveforms 
(whether they are deterministic or random) in order to work with discrete time sequences 
rather than continuous time waveforms.  Thus, sequences of random variables will naturally 
occur in the study of random processes.  In this chapter, we will develop some basic results 
regarding both finite and infinite sequences of random variables and random series.
7.1 Independent and Identically Distributed Random Variables
In many applications, we are able to observe an experiment repeatedly.  Each new observation 
can occur with an independent realization of whatever random phenomena control the 
experiment.  This sort of situation gives rise to independent and identically distributed 
(IID or i.i.d.) random variables.
Definition 7.1: A sequence of random variables 
, 
, . . ., 
 is IID if
 
 (identically distributed),
(7.1)
and
 (independent).
(7.2)
For continuous random variables, the CDFs can be replaced with PDFs in Equations
(7.1) and (7.2), while for discrete random variables, the CDFs can be replaced by
PMFs.
Suppose, for example, we wish to measure the voltage produced by a certain sensor. The 
sensor might be measuring the relative humidity outside. Our sensor converts the humidity 
X1 X2
Xn
FXi x
 
FX x
 
=
i

1 2  n
 

=
FX1 X2  Xn



x1 x2  xn





FXi xi


i
1
=
n

=

290    Chapter 7
www.Academicpress.com
to a voltage level which we can then easily measure. However, as with any measuring 
equipment, the voltage we measure is random due to noise generated in the sensor as well as in 
the measuring equipment.  Suppose the voltage we measure is represented by a random 
variable X given by 
, where 
 is the true voltage that should be presented by 
the sensor when the humidity is h, and N is the noise in the measurement.  Assuming that the 
noise is zero-mean, then 
.  That is, on the average, the measurement will be 
equal to the true voltage 
.  Furthermore, if the variance of the noise is sufficiently small, 
then the measurement will tend to be close to the true value we are trying to measure.  But 
what if the variance is not small?  Then the noise will tend to distort our measurement making 
our system unreliable.  In such a case, we might be able to improve our measurement system 
by taking several measurements.  This will allow us to “average out” the effects of the noise.
Suppose we have the ability to make several measurements and observe a sequence of 
measurements 
.  It might be reasonable to expect that the noise that corrupts 
a given measurement has the same distribution each time (and hence the 
 are identically 
distributed) and is independent of the noise in any other measurement (so that the 
 are 
independent).  Then the n measurements form a sequence of IID random variables.  A 
fundamental question is then: How do we process an IID sequence to extract the desired 
information from it?  In the preceding case, the parameter of interest, 
, happens to be the 
mean of the distribution of the 
.  This turns out to be a fairly common problem and so we 
start by examining in some detail the problem of estimating the mean from a sequence of IID 
random variables.
7.1.1 Estimating the Mean of IID Random Variables
Suppose the 
 have some common PDF, 
, which has some mean value, 
.  Given 
a set of IID observations, we wish to form some function,
,
(7.3)
which will serve as an estimate of the mean.  But what function should we choose?  Even more 
fundamentally, what criterion should we use to select a function?  
There are many criteria that are commonly used.  To start with we would like the average 
value of the estimate of the mean to be equal to the true mean.  That is, we want 
.  
If this criterion is met, we say that 
 is an unbiased estimate of 
. Given that the estimate 
is unbiased, we would also like the error in the estimate to be as small as possible.  Define the 
estimation error to be 
.  A common criterion is to choose the estimator which 
minimizes the second moment of the error (mean-square error), 
.  If 
this criterion is met, we say that 
 is an efficient estimator of 
.  To start with a relatively 
simple approach, suppose we desire to find a linear estimator.  That is, we will limit ourselves 
to estimators of the form
X
v h
 
N
+
=
v h
 
E X
 	
v h
 
=
v h
 
X1 X2  Xn



Xi
Xi
v h
 
Xi
Xi
fX x
 

X

ˆ
g X1 X2  Xn





=
E 
ˆ
 	

X
=

ˆ

X


ˆ

X
–
=
E 2

	
E

ˆ

X
–

2

	
=

ˆ

X

Random Sums and Sequences    291
www.Academicpress.com
.
(7.4)
Then, we seek to find the constants, 
, such that the estimator (1) is unbiased and 
(2) minimizes the mean-square error.  Such an estimator is referred to as the best linear 
unbiased estimator (BLUE).  
To simplify notation  in this problem, we write 
 and 
.  The linear estimator 
 can then be written as 
.  First, for 
the estimator to be unbiased, we need
.
(7.5)
Since the 
 are all IID, they all have means equal to 
.  Hence, the mean vector for 
 is 
just 
 where 
 is an n-element column vector of all ones.  The linear estimator will then 
be unbiased if
.
(7.6)
The mean square error is given by
(7.7)
In this expression, 
 is the correlation matrix for the vector 
.  Using the 
constraint of (7.6), the mean square error simplifies to
.
(7.8)
The problem then reduces to minimizing the function 
 subject to the constraint 
.
To solve this multidimensional optimization problem, we use standard Lagrange multiplier 
techniques.  Form the auxiliary function 
.
(7.9)
Then solve the equation 
.  It is not difficult to show that the gradient of the function  
works out to be 
.  Therefore, the optimum vector  will satisfy
. 
(7.10)

ˆ
a1X1
a2X2

anXn
+
+
+
aiXi
i
1
=
n

=
=
a1 a2  an



X
X1 X2  Xn




	T
=
a
a1 a2  an




	T
=

ˆ

ˆ
aTX
=

X
E 
ˆ
 	
E aTX

	
aTE X

	
=
=
=
Xi

X
X

X1n
1n
ai
i
1
=
n
aT1n
1
=
=
E 2

	
E
aTX

X
–

2

	
aTE XXT

	a
2
XaTE X

	
–

X2
+
=
=
aTRa
2
X2 aT1n
–

X2
+
=
R
E XXT

	
=
X
E 2

	
aTRa

X2
–
=
aTRa
aT1n
1
=
h 
 
aTRa
aT1n
+
=
h

0
=
h
h

2Ra
1n
+
=
a
Ra

2---
–



 1n
=

292    Chapter 7
www.Academicpress.com
Solving for  in this equation and then applying the constraint 
 results in the 
solution
.
(7.11)
Due to the fact that the 
 are IID, the form of the correlation matrix can easily be shown to be
,
(7.12)
where I is an identity matrix and 
 is the variance of the IID random variables.  It can be 
shown using the matrix inversion lemma1 that the inverse of this correlation matrix is
.
(7.13)
From here, it is easy to demonstrate that 
 is proportional to 
, and therefore the 
resulting vector of optimum coefficients is
.
(7.14)
In terms of the estimator 
, the best linear unbiased estimator of the mean of an IID 
sequence is
.
(7.15)
This estimator is commonly referred to as the sample mean.  The preceding derivation proves 
Theorem 7.1 which follows.
Theorem 7.1:  Given a sequence of IID random variables 
, 
, . . ., 
, the sample 
mean is BLUE.
Another possible approach to estimating various parameters of a distribution is to use the 
maximum likelihood (ML) approach introduced in Chapter 6 (Section 6.5.2).  In the ML 
a
aT1n
1
=
a
R 1
– 1n
1nTR 1
– 1n
----------------------
=
Xi
R

X2 1n1nT
X2 I
+
=
X2
R 1
–
X2
–
I

X2 X2

1
n
X2 X2

+
------------------------------1n1nT
–
=
R 1
– 1n
1n
a
1
n---1n
=

ˆ

ˆ
1
n---1nTX
1
n---
Xi
i
1
=
n

=
=
X1 X2
Xn
1 The matrix inversion lemma gives a formula to find the inverse of a rank one update of another matrix 
whose inverse is known.  In particular, suppose 
 where  is a column vector and the 
inverse of 
 is known.  Then,.
.
A
B
xxT
+
=
x
B
A 1
–
B 1
–
B 1
– xxTB 1
–
1
xTB 1
– x
+
---------------------------
–
=

Random Sums and Sequences    293
www.Academicpress.com
approach, the distribution parameters are chosen to maximize the probability of the observed 
sample values occurring.  Suppose, as in the preceding discussion, we are interested in 
estimating the mean of a distribution.  Given a set of observations, 
, 
, . . ., 
, the ML estimate of 
 would be the value of 
 which maximizes 
.  A few 
examples will clarify this concept.  
Example 7.1:  
Suppose the 
 are jointly Gaussian so that
.
The value of  which maximizes this expression will minimize
.
Differentiating and setting equal to zero gives the equation
.
The solution to this equation works out to be
.
Hence, the sample mean is also the ML estimate of the mean when the random variables 
follow a Gaussian distribution.
Example 7.2:  
Now suppose the random variables have an exponential distribution,
.
Differentiating with respect to  and setting equal to zero results in
.
(Continued)
X1
x1
=
X2
x2
=
Xn
xn
=

X

X
fX x
 
Xi
fX x
 
1
22

n 2

------------------------
1
22
---------
xi

–

2
i
1
=
n

–








exp
=

xi

–

2
i
1
=
n
2
xi

–


i
1
=
n

–
0
=

ˆ
ML
1
n---
xi
i
1
=
n

=
fX x
 
1

---
xi

----
–



u xi
 
exp
i
1
=
n

1

n
------
1

---
xi
i
1
=
n

–








u xi
 
i
1
=
n

exp
=
=

n

n
1
+
------------
1

---
xi
i
1
=
n

–








exp
–
 + 1

2
------
xi
i
1
=
n








 1

n
------
1

---
xi
i
1
=
n

–








exp
0
=




294    Chapter 7
www.Academicpress.com
Solving for  results in
.
Once again, the sample mean is the maximum likelihood estimate of the mean of the 
distribution.
Since the sample mean occurs so frequently, it is beneficial to study this estimator in a little 
more detail.  First, we note that the sample mean is itself a random variable since it is a 
function of the n IID random variables. We have already seen that the sample mean is an 
unbiased estimate of the true mean; that is, 
.  It is instructive to also look at the 
variance of this random variable.
.
(7.16)
All terms in the double series in the previous equation are zero except for the ones where 
 since 
 and 
 are uncorrelated for all 
.  Therefore, the variance of the sample 
mean is
.
(7.17)
This means that if we use n samples to estimate the mean, the variance of the resulting 
estimate is reduced by a factor of n relative to what the variance would be if we used only 
one sample.
Consider what happens in the limit as 
.  As long as the variance of each of the samples 
is finite, the variance of the sample mean approaches zero. Of course, we never have an 
infinite number of samples in practice, but this does mean that the sample mean can achieve 
any level of precision (i.e., arbitrarily small variance) if a sufficient number of samples is 


ˆ
ML
1
n---
xi
i
1
=
n

=
E 
ˆ
 	

X
=
Var 
ˆ
 
E
1
n---
Xi
i
1
=
n










X
–







 2
E
1
n---
Xi

X
–


i
1
=
n








 2
=
=
1
n2
-----
E
Xi

X
–

 Xj

X
–



	
j
1
=
n

i
1
=
n

=
1
n2
-----
Cov Xi Xj



j
1
=
n

i
1
=
n

=
i
j
=
Xi
Xj
i
j

Var 
ˆ
 
1
n2
-----
Var Xi


i
1
=
n

1
n2
-----
X2
i
1
=
n

X2
n
-------
=
=
=
n




Random Sums and Sequences    295
www.Academicpress.com
taken.  We will study this limiting behavior in more detail in a later section.  For now, we turn 
our attention to estimating other parameters of a distribution.
7.1.2 Estimating the Variance of IID Random Variables
Now that we have a handle on how to estimate the mean of IID random variables, suppose we 
would like to also estimate the variance (or equivalently, the standard deviation).  Since the 
variance is not a linear function of the random variables, it would not make much sense to try 
to form a linear estimator. That is, to talk about an estimator of the variance being BLUE is 
meaningless. Hence, we take the ML approach here. As with the problem of estimating the 
mean, we seek the value of the variance which maximizes the joint PDF of the IID random 
variables evaluated at their observed values.  
Example 7.3:  
Suppose that the random variables are jointly Gaussian so that
.
Differentiating the joint PDF with respect to  results in
.
Setting this expression equal to zero and solving results in
.
The result of Example 7.3 seems to make sense. The only problem with this estimate is that it 
requires knowledge of the mean in order to form the estimate. What if we do not know the 
mean? One obvious approach would be to replace the true mean in the previous result with 
the sample mean. That is, one could estimate the variance of an IID sequence using
,
   
.
(7.18)
This approach, however, can lead to problems.  It is left as an exercise for the reader to show 
that this estimator is biased; that is, in this case, 
. To overcome this problem, it is 
fX x
 
1
22

n 2

------------------------
1
22
---------
xi

–

2
i
1
=
n

–








exp
=


d
d fX x
 
n
---
1
3
------
+
–
xi

–

2
i
1
=
n








1
22

n 2

------------------------
1
22
---------
xi

–

2
i
1
=
n
–








exp
=
ˆ
ML
2
1
n---
xi

–

2
i
1
=
n

=
sˆ2
1
n---
xi

ˆ
–

2
i
1
=
n

=

ˆ
1
n---
xi
i
1
=
n

=
E sˆ2

	
2




296    Chapter 7
www.Academicpress.com
common to adjust the previous form. The following estimator turns out to be an unbiased 
estimate of the variance:
.
(7.19)
This is known as the sample variance and is the most commonly used estimate for the variance 
of IID random variables. In the previous expression, 
 is the usual sample mean.
In summary, given a set of IID random variables, the variance of the distribution is estimated 
according to:
(7.20)
Example 7.4:  
Suppose we form a random variable  according to 
 where  
and  are independent Gaussian random variables with means of  and 
variances of 
.  In this example, we will estimate the mean and variance 
of  using the sample mean and sample variance of a large number of 
MATLAB-generated realizations of the random variable . The MATLAB 
code to accomplish this follows.  Upon running this code, we obtained a sample mean of 
 and a sample variance of 
.  Note that the true mean and variance of 
the Rician random variable  can be found analytically (with some effort).  For this 
example, the PDF of the random variable  is found to take on a Rician form
.
Using the expressions given in Appendix D (see equations (D.52) and (D.53)) for the 
mean and variance of a Rician random variable, it is determined that the true mean and 
variance should be
, 
.
sˆ2
1
n
1
–
------------
xi

ˆ
–

2
i
1
=
n

=

ˆ
sˆ2
1
n---
xi

–

2
i
1
=
n

,
if 
 is known,
1
n
1
–
------------
xi

ˆ
–

2,
i
1
=
n

    if 
 is unknown.









=
Z
Z
X2
Y2
+
=
X
Y

2
Z
Z

ˆ
5.6336
=
sˆ2
8.5029
=
Z
Z
fZ z 
z
2
------
z2
2
2
+
22
-------------------
–




exp
I0
2
z
2
-------------



u z 
=

Z
2
2
---------

2
22
---------
–




1

2
2
------
+



Io

2
22
---------





2
2
------I1

2
22
---------




+
exp
=
Z
2
22
2
2

Z
2
–
+
=


Random Sums and Sequences    297
www.Academicpress.com
For the values of 
 and 
 used in the following program, the resulting mean and 
variance of the Rician random variable should be 
 and 
.
N=10000;
mu=2; sigma=4;
% set mean and std. dev. of X
  and Y.
X=sigma*randn(1,N)+mu;
% generate samples of X
Y=sigma*randn(1,N)+mu;
% generate samples of Y
Z=sqrt(X.^2+Y.^2);
% Create Z (Rician RVs)
mu_hat=sum(Z)/N
% sample mean.
s_hat2=sum((Z-mu_hat).^2)/(N-1)
% sample variance
7.1.3 Estimating the CDF of IID Random Variables
Suppose instead of estimating the parameters of a distribution, we were interested in 
estimating the distribution itself.  This can be done using some of the previous results.  The 
CDF of the underlying distribution is 
.  For any specific value of , define 
a set of related variables 
, 
, . . ., 
 such that
(7.21)
It should be fairly evident that if the 
 are IID, then the 
 must be IID as well.  Note that for 
these Bernoulli random variables, the mean is 
.  Hence, estimating the 
CDF of the 
 is equivalent to estimating the mean of the 
 which is done using the sample 
mean
.
(7.22)
This estimator is nothing more than the relative frequency interpretation of probability.  To 
estimate 
 from a sequence of n IID observations, we merely count the number of 
observations that satisfy 
.  
Example 7.5:  
To illustrate this procedure of estimating the CDF of IID random variables, 
suppose the 
 are all uniformly distributed over 
.  The plot in 
Figure 7.1 shows the results of one realization of estimating this CDF using 
n IID random variables for n = 10, n = 100, and n = 1000.  Clearly, as n gets 
larger, the estimate gets better.  The MATLAB code that follows can be 
(Continued)

2
=

4
=

Z
5.6211
=
Z
2
8.4031
=
FX x
 
Pr X
x



=
x
Y1 Y2
Yn
Yi
1, if Xi
x,

0, if Xi
x.
 



=
Xi
Yi
E Yi

	
Pr Xi
x



=
Xi
Yi
Fˆ X x
 
1
n---
Yi
i
1
=
n

1
n---
1
u Xi
x
–


–

	
i
1
=
n

=
=
FX x
 
Xi
x

Xi
0 1







298    Chapter 7
www.Academicpress.com
used to generate a plot similar to the one in Figure 7.1.  The reader is encouraged to try 
different types of random variables in this program as well.
N=100;
% Set number of samples
z=[-0.5:0.01:1.5];
% define variable for horizontal axis
x=rand(1,N);
% generate uniform random samples
F=zeros(1,length(z));
% initialize CDF estimate
for n=1:N
% estimate CDF
   F=F+(x(n)<z);
end
F=F/N;
plot(z,F)
% plot results
xlabel('x'); ylabel('F_X(x)')
7.2 Convergence Modes of Random Sequences
In many engineering applications, it is common to use various iterative procedures. In such 
cases, it is often important to know under what circumstances an iterative algorithm converges 
to the desired result. The reader is no doubt familiar with many such applications in the 
deterministic world. For example, suppose we wish to solve for the root of some equation 
.  One could do this with a variety of iterative algorithms (e.g., Newton’s method).  
The convergence of these algorithms is a quite important topic. That is, suppose 
 is the 
estimate of the root at the ith iteration of Newton’s method.  Does the sequence 
 
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
n=10
n=100
n=1000
FX(x)
Figure 7.1 
Estimate of the CDF of a uniform random variable obtained from 
 IID random variables, 
=10, 100, and 1000.
n
n
g x
 
0
=
xi
x1 x2 x3 





Random Sums and Sequences    299
www.Academicpress.com
converge to the true root of the equation?  In this section, we study the topic of random 
sequences and in particular the issue of convergence of random sequences.
As an example of a random sequence, suppose we started with a set of IID random variables, 
, and then formed the sample mean according to
.
(7.23)
The sequence 
 is a sequence of random variables.  It is desirable that this 
sequence converges to the true mean of the underlying distribution.  An estimator satisfying 
this condition is called consistent.  But in what sense can we say that the sequence converges?  
If a sequence of deterministic numbers 
 was being considered, the sequence 
would be convergent to a fixed value s if
.
(7.24)
More specifically, if for any 
, there exists an 
 such that  
 for all 
, then 
the sequence is said to converge to .
Example 7.6: 
Which of the following sequences converge in the limit as 
?
(a)
,  
;
(b)
, 
;
(c)
, 
.
For the sequence 
, 
 will be satisfied provided that 
.
Thus, the sequence 
 converges to 
.  Likewise, for the sequence 
, 
 
will be satisfied provided that
.
In this case, the sequence 
 converges to 
.  Finally, since the sequence 
 
oscillates, there is no convergence.
X1 X2  Xn



Sn
1
n---
Xi
i
1
=
n

=
S1 S2 S3 



s1 s2 s3 



si
i


lim
s
=

0
 
i
si
s
–

!
i
i
 
s
n


xn
1
1
n2
+
--------------
=
n
1 2 3 
  
=
yn
n
n
1
+
-----------
=
n
1 2 3 
  
=
zn
n
4------




cos
=
n
1 2 3 
  
=
xn
xn
0
–

!
1
1
n2
+
--------------

!
n
1
---
1
–
 
"
xn
xn
n


lim
0
=
yn
yn
1
–

!
n
n
1
+
-----------
1
–

!
n
1
---
1
–
 
"
yn
yn
n


lim
1
=
zn



300    Chapter 7
www.Academicpress.com
Suppose an experiment, E, is run resulting in a realization, .  Each realization is mapped to a 
particular sequence of numbers.  For example, the experiment might be to observe a sequence 
of IID random variables 
 and then map them into a sequence of sample means 
.  Each realization, , leads to a specific deterministic sequence, some of which 
might converge (in the previous sense), while others might not converge.  Convergence for a 
sequence of random variables is not straightforward to define and can occur in a variety of 
different manners.
7.2.1 Convergence Everywhere
The first and strictest form of convergence is what is referred to as convergence everywhere 
(a.k.a. sure convergence).  A sequence is said to converge everywhere if every realization, , 
leads to a sequence, 
, which converges to 
.  Note that the limit may depend on the 
particular realization.  That is, the limit of the random sequence may be a random variable.
Example 7.7: 
Suppose we modify the deterministic sequence in part (a) of Example 7.6 to create a 
sequence of random variables.  Let  be a random variable uniformly distributed over 
.  Then define the random sequence
, 
.
In this case, for any realization 
, a deterministic sequence is produced of the form
which converges to 
.  We say that the sequence converges everywhere 
(or surely) to 
.
Example 7.8:  
Suppose we tried to modify the deterministic sequence in part (b) of Example 7.6 in a 
manner similar to what was done in Example 7.7. That is, let  be a random variable 
uniformly distributed over 
. Then define the random sequence
, 
.
Now, for any realization 
, the deterministic sequence
#
X1 X2 X3 



S1 S2 S3 



#
#
sn #
 
s #
 
X
0 1


Xn
X
1
n2
+
--------------
=
n
1 2 3 
  
=
X
x
=
xn
x
1
n2
+
--------------
=
xn
n


lim
0
=
Xn
n


lim
0
=
Y
0 1


Yn
nY
n
1
+
-----------
=
n
1 2 3 
  
=
Y
y
=
yn
ny
n
1
+
-----------
=




Random Sums and Sequences    301
www.Academicpress.com
converges to 
.  In this case, the value that the sequence converges to depends on 
the particular realization of the random variable .  In other words, the random 
sequence converges to a random variable, 
.
7.2.2 Convergence Almost Everywhere
In many examples, it may be possible to find one or several realizations of the random 
sequence which do not converge, in which case the sequence (obviously) does not converge 
everywhere.  However, it may be the case that such realizations are so rare that we might not 
want to concern ourselves with such cases.  In particular, suppose that the only realizations 
that lead to a sequence which does not converge occur with probability zero.  Then we say the 
random sequence converges almost everywhere (a.k.a. almost sure convergence or 
convergence with probability 1).  Mathematically, let A be the set of all realizations that lead 
to a convergent sequence.  Then the sequence converges almost everywhere if 
.
Example 7.9:  
As an example of a sequence that converges almost everywhere, consider the random 
sequence
,  
,
where  is a random variable uniformly distributed over 
.  For almost every 
realization 
, the deterministic sequence 
converges to 
.  The one exception is the realization 
 in which case the 
sequence becomes 
 which converges, but not to the same value.  Therefore, we say 
that the sequence 
 converges almost everywhere (or almost surely) to 
 since 
the one exception to this convergence occurs with zero probability; that is, 
.
7.2.3 Convergence in Probability
A random sequence 
 converges in probability to a random variable  if for any 
, 
.
(7.25)
yn
n


lim
y
=
Y
Yn
n


lim
Y
=
Pr A
 
1
=
Zn
nZ


sin
nZ
----------------------
=
n
1 2 3 
  
=
Z
0 1


Z
z
=
zn
nz


sin
nz
---------------------
=
zn
n


lim
0
=
Z
0
=
zn
1
=
Zn
Zn
n


lim
0
=
Pr Z = 0


0
=
S1 S2 S3 



S

0
 
Pr Sn
S
–

 


n


lim
0
=




302    Chapter 7
www.Academicpress.com
Example 7.10: 
Let 
, 
 be a sequence of IID Gaussian random variables with mean  and 
variance 
.  Suppose we form the sequence of sample means
,  
.
Since the 
 are linear combinations of Gaussian random variables, then they are also 
Gaussian with 
 and 
.  Therefore, the probability that the sample 
mean is removed from the true mean by more than  is
.
As 
, this quantity clearly approaches zero, so that this sequence of sample means 
converges in probability to the true mean.
7.2.4 Convergence in the Mean Square Sense
A random sequence 
 converges in the mean square (MS) sense to a random 
variable  if
.
(7.26)
Example 7.11:  
Consider the sequence of sample means of IID Gaussian random variables described in 
Example 7.10.  This sequence also converges in the MS sense since
.
This sequence of sample variances converges to 0 as 
, thus producing convergence 
of the random sequence in the MS sense.
7.2.5 Convergence in Distribution
Suppose the sequence of random variables 
 has CDFs given by 
 and the 
random variable  has a CDF, 
.  Then, the sequence converges in distribution if
(7.27)
for any  which is a point of continuity of 
.  
Xk
k
1 2 3 
  

=

2
Sn
1
n---
Xk
k
1
=
n

=
n
1 2 3 
  
=
Sn
E Sn



=
Var Sn
	

2 n

=

Pr Sn

–


	

2Q
n
2
------






=
n


S1 S2 S3 



S
E Sn
S
–
2


n


lim
0
=
E
Sn

–
	

2


Var Sn
	

2
n------
=
=
n


S1 S2 S3 



FSn s	 
S
FS s	 
FSn s	 
n


lim
FS s	 
=
s
FS s	 





Random Sums and Sequences    303
www.Academicpress.com
Example 7.12:  
Consider once again the sequence of sample means of IID Gaussian random variables 
described in Example 7.10.  Since 
 is Gaussian with mean  and variance 
, its CDF 
takes the form
.
For any 
, 
, while for any 
, 
.  Thus, the limiting form of 
the CDF is
,
where 
 is the unit step function.  Note that the point 
 is not a point of continuity 
of 
 and therefore we do not worry about it for this proof.
It should be noted, as was seen in the previous sequence of examples, that some random 
sequences converge in many of the different senses.  In fact, one form of convergence may 
necessarily imply convergence in several other forms.  Table 7.1 illustrates these relationships.  
For example, convergence in distribution is the weakest form of convergence and does not 
necessarily imply any of the other forms of convergence.  Conversely, if a sequence converges 
in any of the other modes presented, it will also converge in distribution. The reader will find a 
number of exercises at the end of the chapter which will illustrate and/or prove some of the 
relationships in Table 7.1. 
Table 7.1: Relationships between convergence modes
Everywhere
Almost 
Everywhere
Probability
Mean Square
Distribution
Everywhere
X
Yes
Yes
No
Yes
Almost
Everywhere
No
X
Yes
No
Yes
Probability
No
No
X
No
Yes
Mean Square
No
No
Yes
X
Yes
Distribution
No
No
No
No
X
Sn

2 n

FSn s	 
1
Q s

–

n

-------------




–
=
s


FSn s	 
n


lim
1
=
s


FSn s	 
n


lim
0
=
FSn s	 
n


lim
u s

–
	

=
u s	 
s

=
FS s	 


This 
convergence
Implies this  
convergence

304    Chapter 7
www.Academicpress.com
7.3 The Law of Large Numbers
Having described the various ways in which a random sequence can converge, we return now 
to the study of sums of random variables.  In particular, we look in more detail at the sample 
mean.  The following very well-known result is known as the weak law of large numbers.
Theorem 7.2 (The Weak Law of Large Numbers): Let 
 be the sample mean com-
puted from  IID random variables, 
.  The sequence of sample means, 
, converges in probability to the true mean of the underlying distribution, 
.
Proof:  Recall that if the distribution 
 has a mean of 
 and variance 
, then 
the sample mean, 
, has mean 
 and variance 
.  Applying Chebyshev’s 
inequality,
.
(7.28)
Hence, 
 for any 
.  Thus, the sample mean converges
in probability to the true mean.  
The implication of this result is that we can estimate the mean of a random variable with any 
amount of precision with arbitrary probability if we use a sufficiently large number of samples. 
A stronger result known as the strong law of large numbers shows that the convergence of the 
sample mean is not just in probability but also almost everywhere.  We do not give a proof of 
this result in this text.
As was demonstrated in Section 7.1.3, the sample mean can be used to estimate more than just 
means.  Suppose we are interested in calculating the probability that some event A results from 
a given experiment.  Assuming that the experiment is repeatable and each time the results of 
the experiment are independent of all other trials, then 
 can easily be estimated.  
Simply define a random variable 
 that is an indicator function for the event A on the ith trial.  
That is, if the event A occurs on the ith trial, then 
, otherwise 
. Then
 
.  
(7.29)
The sample mean,
,
(7.30)
will give an unbiased estimate of the true probability, 
.  Furthermore, the law of large 
numbers tells us that as the sample size gets large, the estimate will converge to the true value.  
Sn
n
X1 X2  Xn



Sn
FX x
	 
FX x
	 

2
Sn

2 n

Pr Sn

–


	

Var Sn
	

2
-------------------

2
n2
--------
=
Pr Sn

–


	

n


lim
0
=

0

Pr A
	 
Xi
Xi
1
=
Xi
0
=
Pr A
	 
Pr Xi = 1
	

E Xi


=
=
ˆ n
1
n---
Xi
i
1
=
n

=
Pr A
	 

Random Sums and Sequences    305
www.Academicpress.com
The weak law of large numbers tells us that the convergence is in probability while the strong 
law of large numbers tells us that the convergence is also almost everywhere.
The technique we have described for estimating the probability of events is known as Monte 
Carlo simulation.  It is commonly used, for example, to estimate the bit error probability of a 
digital communication system.  A program is written to simulate transmission and detection of 
data bits.  After a large number of data bits have been simulated, the number of errors are 
counted and divided by the total number of bits transmitted. This gives an estimate of the true 
probability of bit error of the system.  If a sufficiently large number of bits are simulated, 
arbitrary precision of the estimate can be obtained.
Example 7.13:  
This example shows how the sample mean and sample variance converges 
to the true mean for a few different random variables. The results of 
running the MATLAB code that follows are shown in Figure 7.2.  Plot (a) 
shows the results for a Gaussian distribution, whereas plot (b) shows the 
same results for an arcsine random variable.  In each case, the parameters 
have been set so that the true mean is 
 and the variance of each sample is .  Since 
0
10
20
30
40
50
60
70
80
90
100
0
A
B
1
2
3
4
5
6
Samples, n 
Sample mean
Gaussian
0
10
20
30
40
50
60
70
80
90
100
0
1
2
3
4
5
6
Samples, n
Sample mean
Arcsine
Figure 7.2  
Convergence of the sample mean for (a) Gaussian and (b) Arcsine random variables.
(Continued)

3
=
1


306    Chapter 7
www.Academicpress.com
the variance of the sample mean depends only on the variance of the samples and the 
number of samples, crudely speaking the “speed” of convergence should be about the 
same in both cases.
N=100;
% Create Gaussian random variables
mu1=3; sigma1=1;
X1=sigma1*randn(1,N)+mu1;
mu_hat1=cumsum(X1)./[1:N];
% sample means.
% Create Arcsine random variables
mu2=3; b=sqrt(2); sigma2=b^2/2;
X2=b*cos(2*pi*rand(1,N))+mu2;
mu_hat2=cumsum(X2)./[1:N];
% sample means.
subplot(2,1,1)
plot([1:N],mu_hat1,'-',[1:N], mu1, '--')
xlabel('n'); ylabel('S_n'); title('Gaussian')
axis([0,N,0,2*mu1])
subplot(2,1,2)
plot([1:N],mu_hat2,'-',[1:N], mu2, '--')
xlabel('n'); ylabel('S_n'); title('Arcsine')
axis([0,N,0,2*mu2])
7.4 The Central Limit Theorem
Probably the most important result dealing with sums of random variables is the central limit 
theorem which states that under some mild conditions, these sums converge to a Gaussian 
random variable in distribution. This result provides the basis for many theoretical models of 
random phenomena. It also explains why the Gaussian random variable is of such great 
importance and why it occurs so frequently. In this section, we prove a simple version of the 
Central Limit Theorem and then discuss some of the generalizations.
Theorem 7.3 (The Central Limit Theorem):  Let 
 be a sequence of IID random 
variables with mean 
 and variance 
.  Define a new random variable, 
, as a 
(shifted and scaled) sum of the 
:
.
(7.31)
Note that 
 has been constructed such that 
 and 
.  In the limit 
as n approaches infinity, the random variable 
 converges in distribution to a standard 
normal random variable.
Xi
X
X2
Z
Xi
Z
1
n
-------
Xi
X
–
x
-----------------
i
1
=
n

=
Z
E Z
 
0
=
Var Z
	 
1
=
Z


Random Sums and Sequences    307
www.Academicpress.com
Proof: The most straightforward approach to prove this important theorem is using 
characteristic functions.  Define the random variable 
 as 
.  The 
characteristic function of 
 is computed as
.
(7.32)
Next, recall Taylor’s theorem2 which states that any function 
 can be expanded in 
a power series of the form
, (7.33)
where the remainder 
 is small compared to 
 as 
.  Applying 
the Taylor series expansion about the point 
 to the characteristic function of 
 
results in
,
(7.34)
where 
 is small compared to 
 as 
.  Furthermore, we note that 
, 
, and 
.  Therefore, 
Equation (7.34) reduces to
.
(7.35)
The characteristic function of 
 is then
.
(7.36)
X˜ i
X˜ i
Xi
X
–
	

 X

=
Z
Z 
	

E ejZ


E
j
n
-------
X˜ i
i
1
=
n









exp
E
jX˜ i
n
-----------




exp
i
1
=
n

=
=
=
E
jX˜ i
n
-----------




exp
i
1
=
n

X˜

n
-------




i
1
=
n

X˜

n
-------



 n
=
=
=
g x
	 
g x
	 
g xo
	

x
d
dg
x
xo
=
x
xo
–
	


1
k!----
xk
k
d
d g
x
xo
=
x
xo
–
	

k
rk x xo

	

+
+
+
+
=
rk x xo

	

x
xo
–
	

k
x
xo


0
=
X˜
X˜ 
	

X˜ 0
	 
X˜' 0
	 

1
2---X˜'' 0
	 
2
r3 
	

+
+
+
=
r3 
	

2

0

X˜ 0
	 
1
=
X˜' 0
	 
jX X˜
 
0
=
=
X˜'' 0
	 
E X˜ 2


–
1
–
=
=
X˜ 
	

1
2
2
------
–
r3 
	

+
=
Z
Z 
	

1
2
2n
------
–
r3

n
-------




+



 n
=
2 See for example Marsden, Tromba, Vector Calculus, 2nd ed., 1976, W. H. Freeman and Co,.

308    Chapter 7
www.Academicpress.com
Note that as 
, the argument of 
 goes to zero for any finite 
.  Thus, as 
, 
 becomes negligible compared to 
.  Therefore, in the limit, the 
characteristic function of 
 approaches3
.
(7.37)
This is the characteristic function of a standard normal random variable. 
Several remarks about this theorem are in order at this point.  First, no restrictions were put on 
the distribution of the 
.  The preceding proof applies to any infinite sum of IID random 
variables, regardless of the distribution.  Also, the central limit theorem guarantees that the 
sum converges in distribution to Gaussian, but this does not necessarily imply convergence in 
density.  As a counter example, suppose that the 
 are discrete random variables,  then the 
sum must also be a discrete random variable.  Strictly speaking, the density of 
 would then 
not exist, and it would not be meaningful to say that the density of 
 is Gaussian.  From a 
practical standpoint, the probability density of 
 would be a series of impulses.  While the 
envelope of these impulses would have a Gaussian shape to it, the density is clearly not 
Gaussian.  If the 
 are continuous random variables, the convergence in density generally 
occurs as well.  
The proof of the central limit theorem given above assumes that the 
 are IID.  This 
assumption is not needed in many cases.  The central limit theorem also applies to independent 
random variables that are not necessarily identically distributed.  Loosely speaking4, all that is 
required is that no term (or small number of terms) dominates the sum, and the resulting 
infinite sum of independent random variables will approach a Gaussian distribution in the 
limit as the number of terms in the sum goes to infinity. The central limit theorem also applies 
to some cases of dependent random variables, but we will not consider such cases here.
From a practical standpoint, the central limit theorem implies that for the sum of a sufficiently 
large (but finite) number of random variables, the sum is approximately Gaussian distributed.  
Of course, the goodness of this approximation depends on how many terms are in the sum and 
also the distribution of the individual terms in the sum.  The next examples show some 
illustrations to give the reader a feel for the Gaussian approximation.
n


r3	 

n


r3

n
-------




2 n

Z
Z 
	

n


lim
1
2
2n
------
–



 n
n


lim
2
2
------
–




exp
=
=
Xi
Xi
Z
Z
Z
Xi
Xi
3 Here we have used the well-known fact that 
.  To establish this result, the interested 
reader is encouraged to expand both sides in a Taylor series and show that in the limit, the two expan-
sions become equivalent.
4 Formal conditions can be found in Papoulis, Probability, Random Variables, and Stochastic 
Processes, 3rd ed., 1991, McGraw-Hill.
1
x
n---
+



n
n


lim
ex
=

Random Sums and Sequences    309
www.Academicpress.com
Example 7.14:  
Suppose the 
 are all independent and uniformly distributed over 
.  Consider 
the sum
.
The sum has been normalized so that  has zero-mean and unit variance.  It was shown 
previously that the PDF of the sum of independent random variables is just the convolu-
tion of the individual PDFs.  Hence, if we define  
 then
, and  
.
The results of performing this n-fold convolution are shown in Figure 7.3 for several 
values of n.  Note that for as few as n = 4 or n = 5 terms in the series, the resulting PDF 
of the sum looks very much like the Gaussian PDF.  
Xi
1 2

–
1 2


	

Z
12
n------
Xi
i
1
=
n

=
Z
Y
X1
X2

Xn
+
+
+
=
fY z	 
fX z	 
*fX z	 
**fX z	 
=
fZ z	 
n
12
------f
Y z
n
12
------




=
-5
0
5
0
(a)
(b)
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
fZ(z)
z
Gaussian
n=2    
-5
0
5
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
fZ(z)
fZ(z)
z
Gaussian
n=3    
-5
0
5
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
fZ(z)
z
Gaussian
n=4    
-5
0
5
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
z
Gaussian
n=5    
(c)
(d)
Figure 7.3  
PDF of the sum of independent uniform random variables: (a) 
, (b) 
, 
(c) 
, and (d)
.
n
2
=
n
3
=
n
4
=
n
5
=



310    Chapter 7
www.Academicpress.com
Example 7.15:
In this example, suppose the 
 are now discrete Bernoulli distributed random variables 
such that 
.  In this case, the sum 
 is a 
binomial random variable with PMF given by
,  
.
The corresponding CDF is
.
The random variable  has a mean of 
 and variance of 
.  In 
Figure 7.4, this binomial distribution is compared to a Gaussian distribution with the 
same mean and variance.  It is seen that for this discrete random variable, many more 
terms are needed in the sum before good convergence to a Gaussian distribution is 
achieved.
7.5 Confidence Intervals
Consider once again the problem of estimating the mean of a distribution from n IID 
observations.  When the sample mean 
 is formed, what have we actually learned?  Loosely 
speaking, we might say that our best guess of the true mean is 
.  However, in most cases, we 
know that the event 
 occurs with zero probability (since if 
 is a continuous random 
variable, the probability of it taking on any point value is zero).  Alternatively, it could be said 
Xi
Pr Xi = 1
	

Pr Xi = 0
	

0.5
=
=
Y
X1
X2

Xn
+
+
+
=
Pr Y=k
	

n
k
 
  1
2---
 
 n
=
k
0 1 2  n
  

=
FY y
	 
n
k
 
  1
2---
 
 n
u y
k
–
	

k
0
=
n

=
Y
E Y
 
n 2

=
Var Y
	 
n 4

=
-1
0
1
2
3
4
5
6
0
0.2
0.4
0.6
0.8
1
y
Y(y)
Gaussian
n=5     
-5
0
5
10
15
20
25
30
0
0.2
0.4
0.6
0.8
1
y
FY(y)
Gaussian
n=25    
Figure 7.4  
CDF of the sum of independent Bernoulli random variables; n = 5, 25.
ˆ
ˆ
ˆ

=


ˆ



Random Sums and Sequences    311
www.Academicpress.com
that (hopefully) the true mean is “close” to the sample mean.  While this is a vague statement, 
with the help of the central limit theorem, we can make the statement mathematically precise.
If a sufficient number of samples are taken, the sample mean can be well approximated by a 
Gaussian random variable with a mean of 
 and 
.  Using the 
Gaussian distribution, the probability of the sample mean being within some amount  of the 
true mean can be easily calculated,
.
(7.38)
Stated another way, let 
 be the value of  such that the right hand side of the above 
equation is 
; that is,
,
(7.39)
where 
 is the inverse of the Q-function.  Then, given  samples which lead to a 
sample mean 
, the true mean will fall in the interval 
 with probability 
.  The interval 
 is referred to as the confidence interval while the 
probability 
 is the confidence level or, alternatively, 
 is the level of significance.  
The confidence level and level of significance are usually expressed as percentages.  The 
corresponding values of the quantity 
 are provided in Table 7.2 for several 
typical values of 
.  Other values not included in the table can be found from tables of the 
Q-function (such as provided in Appendix E).
Table 7.2: Constants used to calculate confidence intervals
Percentage of 
Confidence Level
(1-a)*100%
Percentage of Level of 
Significance
a*100%
90
10
1.64
95
5
1.96
99
1
2.58
99.9
0.1
3.29
99.99
0.01
3.89
E ˆ
 
x
=
Var ˆ
	 
X2 n

=

Pr ˆ
X
–


	

Pr X

–
ˆ
X

+


	

1
2Q  n X

	

–
=
=


1

–

X
n
-------Q 1
–

2---
 
 
=
Q 1
– 	 
n
ˆ
ˆ

–
ˆ

+

	

1

–
ˆ

–
ˆ

+

	

1

–

c
Q 1
–
 2

	

=

c
Q 1
–

2---
 
 
=

312    Chapter 7
www.Academicpress.com
Example 7.16:  
Suppose the IID random variables each have a variance of 
.  A sample of 
 
values is taken and the sample mean is found to be 
.  Determine the 95% confi-
dence interval for the true mean 
.  In this case, 
 and the appropriate value 
of 
 is 
 from Table 7.2.  The 95% confidence interval is then
.
Example 7.17:  
Looking again at Example 7.16, suppose we want to be 99 % confident that the true mean 
falls within a factor of 
 of the sample mean. How many samples need to be taken in 
forming the sample mean? To ensure this level of confidence, it is required that
and therefore
.
Since  must be an integer, it is concluded that at least 107 samples must be taken.
In summary, to achieve a level of significance specified by 
, we note that by virtue of the 
central limit theorem, the sum
,
(7.40)
approximately follows a standard normal distribution.  We can then easily specify a symmetric 
interval about zero in which a standard normal random variable will fall with probability 
.  As long as  is sufficiently large, the original distribution of the IID random variables 
does not matter.
Note that in order to form the confidence interval as specified, the standard deviation of the 
 
must be known.  While in some cases, this may be a reasonable assumption, in many 
applications, the standard deviation is also unknown.  The most obvious thing to do in that 
case would be to replace the true standard deviation in Equation (7.40) with the sample 
standard deviation.  That is, we form a statistic 
X
2
4
=
n
100
=
ˆ
10.2
=
X
X
n
	
0.2
=
c
c0.05
1.96
=
ˆ
X
n
-------c0.05
–
ˆ
X
n
-------c0.05
+





9.808 10.592



=
0.5

X
n
-------c0.01
0.5
=
n
c0.01X
0.5
-----------------




2
2.58*2
0.5
----------------



2
106.5
=
=
=
n

Zˆ n
ˆ
X
–
X
n
	
------------------
=
1

–
n
Xi





Random Sums and Sequences    313
www.Academicpress.com
,
(7.41)
and then seek a symmetric interval about zero 
 such that the probability that 
 falls 
in that interval is 
.  For very large , the sample standard deviation will converge to the 
true standard deviation and hence 
 will approach 
. Hence, in the limit as 
, 
 can 
be treated as having a standard normal distribution, and the confidence interval is found in the 
same manner we have described.  That is, as 
, 
.  For values of  that are not 
very large, the actual distribution of the statistic 
 must be calculated in order to form the 
appropriate confidence interval.  
Naturally, the distribution of 
 will depend on the distribution of the 
.  One case where 
this distribution has been calculated for finite  is when the 
 are Gaussian random 
variables.  In this case, the statistic 
 follows the so-called Student’s t-distribution5 with 
 degrees of freedom:
,
(7.42)
where 
 is the gamma function (see Chapter 3, Equation (3.22) or Appendix E, Equation 
(E.39)).  
From this PDF, one can easily find the appropriate confidence interval for a given level of 
significance, 
, and sample size, . Tables of the appropriate confidence interval, 
, can be 
found in any text on statistics. It is common to use the t-distribution to form confidence 
intervals even if the samples are not Gaussian distributed.  Hence, the t-distribution is very 
commonly used for statistical calculations.
Many other statistics associated with related parameter estimation problems are 
encountered and have been carefully expounded in the statistics literature.  We believe 
that with the probability theory developed to this point, the motivated student can now 
easily understand the motivation and justification for the variety of statistical tests that 
appear in the literature. Several exercises at the end of this chapter walk the reader 
through some of the more commonly used statistical distributions including the 
t-distribution of Equation (7.42), the chi-square distribution (see Chapter 3, Section 
3.4.6), and the F-distribution (see Appendix D).
Tˆ n
ˆ
X
–
sˆ
n
	
----------------
=
t
–  t



Tˆ n
1

–
n
Tˆ n
Zˆ n
n


Tˆ n
n


t
c

n
Tˆ n
Tˆ n
Xi
n
Xi
Tˆ n
n
1
–
fTˆ n t 
1
t2 n
	
+


n
1
+

 2
	
–

n
1
+

 2
	


n n 2
	


---------------------------------------------------------------------------------
=
 

n
t
5 The Student’s -distribution was developed by the English mathematician W. S. Gossett who 
published under the pseudonym “A. Student.”
t

314    Chapter 7
www.Academicpress.com
Example 7.18:  
Suppose we wish to estimate the failure probability of some system.  We 
might design a simulator for our system and count the number of times the 
system fails during a long sequence of operations of the system.  Examples 
might include bit errors in a communication system, defective products in 
an assembly line, etc.  The failure probability can then be estimated as 
discussed at the end of Section 7.3.  Suppose the true failure probability is  (which of 
course is unknown to us).  We simulate operation of the system  times and count the 
number of errors observed, 
.  The estimate of the true failure probability is then just 
the relative frequency,
.
If errors occur independently, then the number of errors we observe in  trials is a 
binomial random variable with parameters  and .  That is, 
,  
.
From this, we infer that the mean and variance of the estimated failure probability is 
 and 
.  From this, we can develop confidence intervals for 
our failure probability estimates.  The MATLAB code that follows creates estimates as 
described and plots the results, along with error bars indicating the confidence intervals 
associated with each estimate.  The plot resulting from running this code is shown in 
Figure 7.5. 
p
n
Ne
pˆ
Ne
n------
=
n
n
p
0
0.1
0.2
0.3
0.4
0.5
10−2
10−1
p
p-hat
Figure 7.5  
Estimates of failure probabilities along with confidence intervals.  The solid line is the true 
probability while the circles represent the estimates.
PNe k
 
n
k
 
 pk 1
p
–

n
k
–
=
k
0 1 2  n

 
 

=
E pˆ
 
p
=
Var pˆ 
n 1
– p 1
p
–


=


Random Sums and Sequences    315
www.Academicpress.com
N=1000;
% Number of samples generated.
c=1.64;
% For 90% confidence level.
points=[0.025:0.025:0.5];
% values of p
for k=1:length(points)
   p=points(k);
   X=rand(1,N)<p;
% 1=error, 0=no error
   p_hat(k)=sum(X)/N;
% relative frequency
   sigma=sqrt(p*(1-p)/N);
   eps(k)=sigma*c;
% compute confidence interval
end
% plot results
semilogy(points,points,'-')
% true values
axis([0 0.55 0.01 0.55])
grid on
xlabel('p')
ylabel('p-hat')
hold on
errorbar(points,p_hat,eps,'o')
% estimated values with
hold off
% confidence intervals.
7.6 Random Sums of Random Variables
The sums of random variables considered up to this point have always had a fixed number of 
terms.  Occasionally, one also encounters sums of random variables where the number of terms 
in the sum is also random.  For example, a node in a communication network may queue packets 
of variable length while they are waiting to be transmitted.  The number of bytes in each packet, 
, might be random as well as the number of packets in the queue at any given time, 
.  The 
total number of bytes stored in the queue would then be a random sum of the form
.
(7.43)
Theorem 7.4:  Given a set of IID random variables 
 with mean 
 and variance 
 and an independent random integer 
, the mean and variance of the random sum 
of the form given in Equation (7.43) are given by
,
(7.44)
.
(7.45)
Proof:  To calculate the statistics of , it is easier to first condition on 
 and then average 
the resulting conditional statistics with respect to 
.  To start with, consider the mean:
Xi
N
S
Xi
i
1
=
N

=
Xi
X
X2
N
E S
 
XE N


=
Var S
 
E N

X2
Var N

X2
+
=
S
N
N


316    Chapter 7
www.Academicpress.com
.
(7.46)
The variance is found following a similar procedure. The second moment of  is 
found according to
(7.47)
Note that 
 and 
 are uncorrelated unless 
.  Therefore, this expected value 
works out to be
.
(7.48)
Finally, using 
 results in
.
(7.49)
One could also derive formulas for higher order moments in a similar manner.  
Theorem 7.5:  Given a set of IID random variables 
 with a characteristic function 
 and an independent random integer 
 with a probability generating function 
, the characteristic function of the random sum of the form given in Equation 
(7.43) is given by
.
(7.50)
Proof:  Following a derivation similar to the last theorem,
.  
(7.51)
E S
 
EN E S N




EN E
Xi
i
1
=
N

N
EN NX


XE N


=
=
=
=
S
E S2


EN E S2 N




EN E
XiXj
j
1
=
N

i
1
=
N

N
EN
E XiXj


j
1
=
N

i
1
=
N

=
=
=
Xi
Xj
i
j
=
E S2


EN
N2
N
–

X2
NE Xi2


+


E N2

X2
E N

X2
+
=
=
Var S
 
E S2


E S
 

2
–
=
Var S
 
E N2

X2
E N

X2
E N



2X2
–
+
Var N

X2
E N

X2
+
=
=
Xi
X 


N
HN z 
S 


HN X 




=
S 


E ejS


EN E ejS N




EN E
j
Xi
i
1
=
N









exp
N
=
=
=
EN E
jXi


exp
i
1
=
N

N
EN
X 



N


=
=
Pr N=k

 X 



k
k
HN X 




=
=

Random Sums and Sequences    317
www.Academicpress.com
Example 7.19:  
Suppose the 
 are Gaussian random variables with zero mean and unit variance and  is 
a binomial random variable with a PMF,
.
The mean and variance of this discrete distribution are 
 and 
, 
respectively.  From the results of Theorem 7.4, it is found that
 and 
.
The corresponding characteristic function of 
 and probability-generating function of  
are given by 
 and 
.
The characteristic function of the random sum is then
.
It is interesting to note that the sum of any (fixed) number of Gaussian random variables 
produces a Gaussian random variable.  Yet, the preceding characteristic function is 
clearly not that of a Gaussian random variable, and hence, a random sum of Gaussian 
random variables is not Gaussian.
All of the results presented thus far in this section have made the assumption that the IID 
variables, 
, and the number of terms in the series, 
, are statistically independent.  Quite 
often, these two quantities are dependent.  For example, one might be interested in 
accumulating terms in the sum until the sum exhibits a specified characteristic (e.g., until the 
sample standard deviation falls below some threshold).  Then, the number of terms in the sum 
would clearly be dependent on the values of the terms themselves.  In such a case, the 
preceding results would not apply, and similar results for dependent variables would have to 
be developed.  The following application section considers such a situation.
7.7 Engineering Application: A Radar System
In this section, we consider a simple radar system like that depicted in Figure 1.3.  At known 
instants of time, the system transmits a known pulse and then waits for a reflection.  Suppose 
the system is looking for a target at a known range so the system can determine exactly when 
the reflection should appear at the radar receiver.  To make this discussion as simple as 
possible, suppose that the system has the ability to “sample” the received signal at the 
appropriate time instant and further that each sample is a random variable 
 that is modeled 
as a Gaussian random variable with variance 
.  Let 
 be the event that there is indeed a 
Xi
N
Pr N =k


n
k
 
 pk 1
p
–

n
k
–
=
E N
 
np
=
Var N
 
np 1
p
–


=
E S
 
XE N
 
0
=
=
Var S
 
Var N
 X
2
E N
 X
2
+
np
=
=
Xi
N
X 
 
2
2
------
–




exp
=
HN z 
1
p
–
pz
+

n
=
S 
 
1
p
–
p
2
2
------
–




exp
+




n
=
Xi
N
Xj
2
A1



318    Chapter 7
www.Academicpress.com
target present in which case 
 is taken to have a mean of 
, whereas 
 is the event that 
there is no target present and the resulting mean is zero.  That is, our received sample consists 
of a signal part (if it is present) that is some fixed voltage, 
, plus a noise part which we model 
as Gaussian and zero-mean.  As with many radar systems, we assume that the reflection is 
fairly weak (
 is not large compared to 
), and hence, if we try to decide whether or not a 
target is present based on a single observation, we will likely end up with a very unreliable 
decision.  As a result, our system is designed to transmit several pulses (at nonoverlapping 
time instants) and observe several returns, 
, 
, that we take to be IID. The 
problem is to determine how to process these returns in order to make the best decision and 
also to determine how many returns we need to collect in order to have our decisions attain 
a prescribed reliability.  
We consider two possible approaches.  In the first approach, we decide ahead of time how 
many returns to collect and call that fixed number, .  We then process that random vector 
 and form a decision.  While there are many ways to process the 
returns, we will use what is known as a probability ratio test.  That is, given 
, we want 
to determine if the ratio 
 is greater or less than 1.  Recall that
,  
.
(7.52)
Thus, the probability ratio test makes the following comparison
.
(7.53)
This can be written in terms of an equivalent likelihood ratio test:
,
(7.54)
where 
 is the likelihood ratio and the threshold 
 depends on the a priori probabilities. In practice, we may have no idea 
about the a priori probabilities of whether or not a target is present. However, we can still 
proceed by choosing the threshold for the likelihood ratio test to provide some prescribed 
level of performance.  
Let the false alarm probability be defined as 
.  This is the probability 
that the system declares a target is present when in fact there is none.  Similarly, define the 
correct detection probability as 
.  This is the probability that the 
system correctly identifies a target as being present.  These two quantities, 
 and 
, will 
Xj

A0



Xj j
1 2  n

 

=
n
X
X1 X2  Xn




T
=
X
x
=
Pr A1 x

 Pr A0 x


	
Pr Ai x


fX x Ai

Pr Ai

fX x
 
------------------------------------
=
i
0 1

=
Pr A1 x


Pr A0 x


----------------------
fX x A1

Pr A1


fX x A0

Pr A0


---------------------------------------  
?><?
  1
=
 x
   
?><?
  
 x
 
fX x A1

 fX x A0


	
=

Pr A0

 Pr A1


	
=
Pfa
Pr  X




A0


=
Pd
Pr  X




A1


=
Pfa
Pd

Random Sums and Sequences    319
www.Academicpress.com
specify the performance of our radar system.  Given that the 
 are IID Gaussian as described 
above, the likelihood ratio works out to be
.
(7.55)
Clearly, comparing this with a threshold is equivalent to comparing the sample mean with a 
threshold.  That is, for IID Gaussian returns, the likelihood ratio test simplifies to
,
(7.56)
where the threshold 
 is set to produce the desired system performance.  Since the 
 are 
Gaussian, the sample mean is also Gaussian.  Hence, when there is no target present 
 and when there is a target present 
.  With these distributions, 
the false alarm and detection probabilities work out to be
 and 
.
(7.57)
By adjusting the threshold, we can trade off false alarms for missed detections.  Since the two 
probabilities are related, it is common to write the detection probability in terms of the false 
alarm probability as
.
(7.58)
From this equation, we can determine how many returns need to be collected in order to attain 
a prescribed system performance specified by 
.  In particular,
.
(7.59)
Xj
 x
 
fX x A1


fX x A0


----------------------
22

 n 2
	
–
1
22
---------
xj

–

2
j
1
=
n

–








exp
22

 n 2
	
–
1
22
---------
xj2
j
1
=
n

–








exp
------------------------------------------------------------------------------------------
=
=
n
2
------
1
n---
xj
j
1
=
n










2---
–








exp
=
ˆ
1
n---
xj
j
1
=
n

  
?><?
  0
=
0
Xj
ˆ
N 0 2 n
	




ˆ
N  2 n
	




Pfa
Q
n0

-------------




=
1
Pd
–
Q
n 
0
–



----------------------------




=
1
Pd
–
Q
n

-----------
Q 1
–
Pfa


–




=
Pfa Pd



n
Q 1
–
1
Pd
–


Q 1
–
Pfa


+

2
2 2
	
-------------------------------------------------------------------
=

320    Chapter 7
www.Academicpress.com
The quantity 
 has the physical interpretation of the strength of the signal (when it is 
present) divided by the strength of the noise, or simply the signal-to-noise ratio.
Since the radar system must search at many different ranges and many different angles of 
azimuth, we would like to minimize the amount of time it has to spend collecting returns at 
each point.  Presumably, the amount of time we spend observing each point in space depends 
on the number of returns we need to collect.  We can often reduce the number of returns 
needed by noting that the number of returns required to attain a prescribed reliability as 
specified by 
 will depend on the particular realization of returns encountered.  For 
example, if the first few returns come back such that the sample mean is very large, we may be 
very certain that a target is present and hence there is no real need to collect more returns.  In 
other instances, the first few returns may produce a sample mean near 
.  This inconclusive 
data would lead us to wait and collect more data before making a decision.  Using a variable 
number of returns whose number depends on the data themselves is known as sequential 
detection.  
The second approach we consider will use a sequential detection procedure whereby after 
collecting  returns, we compare the likelihood ratio with two thresholds, 
 and 
, and 
decide according to
(7.60)
The performance of a sequential detection scheme can be determined as follows.  Define the 
region 
 to be the set of data points 
 which lead to a decision in favor 
of 
 after collecting exactly  data points.  That is, 
 and 
 for 
.  Similarly define the region 
 to be the set of data points 
 which 
lead to a decision in favor of 
 after collecting exactly  data points.  Let 
 be the 
probability of a false alarm occurring after collecting exactly  returns and 
 the probability 
of making a correct detection after collecting exactly  returns.  The overall false alarm and 
detection probabilities are then
 and 
.
(7.61)
2 2
	
Pfa Pd



 2
	
n
0
1
 x
   
1,

     decide a target is present,
           
0 1


,

collect another return,
0,
 
       decide no target is present.
!
"
#
"
$
R1n
 
x n
 
x1 x2  xn





=
A1
n
 x n
 


1

0
 x j 


1
%
%
j
1 2  n
1
–

 

=
R0n
 
x n
 
A0
n
Pfan
 
n
Pdn
 
n
Pfa
Pfan
 
n
1
=


=
Pd
Pdn
 
n
1
=


=

Random Sums and Sequences    321
www.Academicpress.com
We are now in a position to establish the following fundamental result which will instruct us in 
how to set the decision thresholds in order to obtain the desired performance.
Theorem 7.6 (Wald’s Inequalities): For a sequential detection strategy, the false 
alarm and detection strategies satisfy
,
(7.62)
.
(7.63)
Proof: First note that 
(7.64)
and similarly
.
(7.65)
For all 
, 
 and therefore
.
(7.66)
Summing over all 
 then produces Equation (7.62). Equation (7.63) is derived in a
similar manner.  
 
Since the likelihood ratio is often exponential in form, it is common to work with the log of the 
likelihood ratio, 
.  For the case of Gaussian IID data, we get
.
(7.67)
In terms of log-likelihood ratios, the sequential decision mechanism is
(7.68)
Pd
1Pfa

1
Pd
–


0 1
Pfa
–


 
Pfan
 
Pr x n
 
R1n
 

A0


fX n
  x n
  A0

 x n
 
d
R1n
 &
=
=
Pdn
 
Pr x n
 
R1n
 

A1


fX n
  x n
  A1

 x n
 
d
R1n
 &
=
=
x n
 
R1n
 

fX n
  x n
  A1


1fX n
  x n
  A0



Pdn
 
1
fX n
  x n
  A0

 x n
 
d
R1n
 &

1Pfan
 
=
n
' x
 
 x
 


ln
=
' x n
 


n
2
------
1
n---
xj
j
1
=
n










2---
–
' x n
1
–





2
------xn
2
22
---------
–
+
=
=
' x
   
'1,

     decide a target is present,
           
'0 '1


,

collect another return,
'0,
 
       decide no target is present,
!
"
#
"
$

322    Chapter 7
www.Academicpress.com
where 
, 
. The corresponding versions of Wald’s Inequalities are then 
,
(7.69a)
.
(7.70b)
For the case when the signal-to-noise ratio is small, each new datum collected adds a small 
amount to the sum in Equation (7.67), and it will typically take a large number of terms before 
the sum will cross one of the thresholds, 
 or 
.  As a result, when the requisite number of 
data are collected so that the log-likelihood ratio crosses a threshold, it will usually be only 
incrementally above the threshold.  Hence, Wald’s inequalities will be approximate equalities 
and the decision thresholds that lead to (approximately) the desired performance can be found 
according to
 and 
.
(7.71)
Now that the sequential detection strategy can be designed to give any desired performance, 
we are interested in determining how much effort we save relative to the fixed sample size test.  
Let 
 be the instant at which the test terminates, and to simplify notation, define 
,
(7.72)
where from Equation (7.67) 
.  Note that 
 is a random sum of IID 
random variables as studied in section 7.6, except that now the random variable 
 is not 
independent of the 
.  Even with this dependence, for this example it is still true that
.
(7.73)
The reader is led through a proof of this in Exercise 7.39. Note that when the test terminates:
(7.74)
and therefore,
.
(7.75)
'j
j


ln
=
j
0 1

=
Pd


ln
'1
Pfa


ln
+

1
Pd
–


ln
'0
1
Pfa
–


ln
+
 
'0
'1
'1
Pd
Pfa
--------




ln
=
'0
1
Pd
–
1
Pfa
–
-----------------




ln
=
N
SN
' X N




Zi
i
1
=
N

=
=
Zi
 Xi
 2
	
–

 2
	
=
SN
N
Zi
E SN


E N

E Zi


=
SN
'1,   if the test terminates in A1,
'0,   if the test terminates in A0,
!
#
$
(
E SN


'1Pr(test terminates in A1)
'0Pr(test terminates in A0)
+
(

Random Sums and Sequences    323
www.Academicpress.com
Suppose that 
 is true.  Then the event that the test terminates in 
 is simply a false alarm.  
Combining Equations (7.73) and (7.75) results in
.
(7.76)
Similarly, when 
 is true:
.
(7.77)
It is noted that not only is the number of returns collected a random variable, but the statistics 
of this random variable depend on whether or not a target is present. This may work to our 
advantage in that the average number of returns we need to observe might be significantly 
smaller in the more common case when there is no target present.
Example 7.20:  
Suppose we want to achieve a system performance specified by 
 and 
.  
Furthermore, suppose the signal-to-noise ratio for each return is 
.  
Then the fixed sample size test will use a number of returns given by
.
Since  must be an integer, 502 samples must be taken to attain the desired performance.  
For the sequential test, the two thresholds for the log-likelihood test are set according to 
Wald’s inequalities,
 and 
.
With these thresholds set, the average number of samples needed for the test to 
terminate is
when there is no target present, and
when a target is present.  Clearly, for this example, the sequential test saves us significantly 
in terms of the amount of data that needs to be collected to make a reliable decision.
A0
A1
E N A0


E SN A0


E Zi A0


------------------------
(
'1Pfa
'0 1
Pfa
–


+
2 22
	
------------------------------------------------
–
=
A1
E N A1


E SN A1


E Zi A1


------------------------
(
'1Pd
'0 1
Pd
–


+
2 22
	
---------------------------------------------
=
Pfa
10 6
–
=
Pd
0.99
=
2 2
	
0.1
10dB
–
=
=
n
Q 1
–
1
Pd
–


Q 1
–
Pfa


+

2
2 2
	
--------------------------------------------------------------
2.326
4.755
+

2
0.1
---------------------------------------
501.4
=
=
=
n
'0
1
Pd
–
1
Pfa
–
---------------




ln
4.6
–
=
=
'1
Pd
Pfa
-------




ln
13.8
=
=
E N A0


'1Pfa
'0 1
Pfa
–


+
2 22
	
---------------------------------------------
–
92.1
=
=
E N A1


'1Pd
'0 1
Pd
–


+
2 22
	
------------------------------------------
272.4
=
=



325
CHAPTER 7
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 7.1:  IID Random Variables
7.1
A random variable, 
, has a Gaussian PDF with mean 5 and unit variance.  We measure 
10 independent samples of the random variable.
(a)
Determine the expected value of the sample mean.
(b)
Determine the variance of the sample mean.
(c)
Determine the expected value of the unbiased sample variance.
7.2
Two independent samples of a random variable 
 are taken. Determine the expected 
value and variance of the sample mean estimate of 
 if the PDF is exponential, (i.e., 
).
7.3
The noise level in a room is measured  times. The error 
 for each measurement is 
independent of the others and is normally distributed with zero-mean and standard 
deviation  
. In terms of the true mean, 
, determine the PDF of the sample 
mean, 
, for 
.
7.4
Suppose 
 is a vector of 
 IID random variables where each element has some PDF, 
.  Find an example PDF such that the median is a better estimate of the mean than 
the sample mean.
7.5
Suppose the variance of an IID sequence of random variables is formed according to 
,
where 
 is the sample mean.  Find the expected value of this estimate and show that it is 
biased. 
7.6
Find the variance of the sample standard deviation, 
,
assuming that the 
 are IID Gaussian random variables with mean 
 and variance 
.
X
X
X
fX x
 
x
–


exp
u x
 
=
n


0.1
=

ˆ
n
100
=
X
N
fX x
 
ˆ 2
1
n---
Xm
ˆ
–

2
m
1
=
n

=
ˆ
sˆ2
1
n
1
–
------------
Xm
ˆ
–

2
m
1
=
n

=
Xi

2

326    Chapter 7
www.Academicpress.com
7.7
Show that if 
, 
, is a sequence of IID Gaussian random variables, the 
sample mean and sample variance are statistically independent.
7.8
A sequence of random variables, 
, is to be approximated by a straight line using the 
estimate, 
. Determine the least squares (i.e., minimum mean squared error) 
estimates for  and  if 
 samples of the sequence are observed.
Section 7.2:  Convergence Modes of Random Sequences
7.9
 (a)    Prove that any sequence that converges in the mean square sense must also 
converge in probability.  Hint: Use Markov’s inequality.
(b)
Prove by counterexample that convergence in probability does not necessarily 
imply convergence in the mean square sense.
7.10 Consider a sequence of IID random variables, 
, 
, each with CDF 
.  This sequence clearly converges in distribution since 
 is equal to 
 for all .  Show that this sequence does not converge in any 
other sense and therefore convergence in distribution does not imply convergence in any 
other form.
7.11 (a)    Show by counterexample that convergence almost everywhere does not imply 
convergence in the MS sense.
(b)
Show by counterexample that convergence in the MS sense does not imply 
convergence almost everywhere.
7.12 Prove that convergence almost everywhere implies convergence in probability.
7.13 Consider the random sequence 
, where 
 is a Cauchy random 
variable with PDF, 
.
Determine which forms of convergence apply to this random sequence.
7.14 Let 
 be a sequence of IID Gaussian random variables.  Form a new sequence 
according to
.
Determine which forms of convergence apply to the random sequence, 
.
Xn n
1 2 3 
	 	 	
=
Xn
Xˆ n
a
bn
+
=
a
b
N
Xn n
1 2 3 
	 	 	
=
FXn x
 
FX x
 
1
Q x

–

------------




–
=
=
FXn x
 
FX x
 
n
Xn
X
1
n2
+



=
X
fX x
 
1 

1
x2
+
--------------
=
Xn
Yn
1
2---Xn
1
–
Xn
–
1
2---Xn
1
+
+
=
Yn

Exercises    327
www.Academicpress.com
7.15 Let 
 be a sequence of IID Gaussian random variables.  Form a new sequence 
according to
.
Determine which forms of convergence apply to the random sequence, 
.
7.16 Let 
, 
, be a sequence of IID random variables with finite mean and 
variance.  Show that the sequence of sample means
converges in the MS sense.
7.17 Suppose 
 is a sequence of zero-mean Gaussian random variables with covariances 
described by 
 for some 
.  Form the sequence of sample 
means
, 
.
Note that in this case we are forming the sequence of sample means of dependent 
random variables.
(a)
Determine if the sequence 
 converges in distribution.
(b)
Determine if the sequence 
 converges in probability.
(c)
Determine if the sequence 
 converges in the MS sense.
Section 7.3:  The Law of Large Numbers
7.18 Suppose 
, 
, . . ., 
 is a sequence of IID positive random variables.  Define
.
Show that as 
, 
 converges in distribution, and find the distribution to which it 
converges.
7.19 Let 
, 
, be a sequence of IID random variables with finite mean, 
, and 
let 
 be the sequence of sample means,
, 
.
Xn
Zn
1
2---

 
  n
i
–
Xi
i
1
=
n

=
Zn
Xk k
1 2 3 
	 	 	
=
Sn
Xk
k
1
=
n

=
Xk
Cov Xk Xm
	


 k
m
–
=

1

Sn
Xk
k
1
=
n
=
n
1 2 3 
	 	 	
=
Sn
Sn
Sn
X1 X2
Xn
Yn
Xi
i
1
=
n

=
n


Yn
Xk k
1 2 3 
	 	 	
=

Sn
Sn
Xk
k
1
=
n

=
n
1 2 3 
	 	 	
=

328    Chapter 7
www.Academicpress.com
(a)
Show that the characteristic function of 
 can be written as
.
(b)
Use Taylor’s theorem to write the characteristic function of the 
 as
,
where the remainder term 
 is small compared to 
 as 
.  Find the 
constants 
 and 
.
(c)
Writing the characteristic function of the sample mean as
,
show that as 
.
In so doing, you have proved that the distribution of the sample mean is that of a constant 
in the limit as 
.  Thus, the sample mean converges in distribution.
7.20 Prove that if a sequence converges in distribution to a constant value, then it also 
converges in probability.  Note: The results of Exercise 7.19 and this one together 
constitute an alternative proof to the weak law of large numbers.  
7.21 Prove that the sequence of sample means of IID random variables converges in the MS 
sense.  What conditions are required on the IID random variables for this convergence to 
occur?
7.22 Let 
, 
, be a sequence of IID Cauchy random variables with 
,
and let 
 be the sequence of sample means,
, 
.
(a)
Show that 
 also follows a Cauchy distribution.
(b)
Prove that in this case, the sample mean does not converge in probability and 
therefore the weak law of large numbers does not apply.  What assumption has been 
violated in this case that makes the weak law of large numbers not applicable?
Sn
Sn 


X

n----

 
 



 n
=
Xk
X 


c0
c1
r2 


+
+
=
r2 




0

c0
c1
Sn 


c0
c1

n----
r2

n----

 
 
+
+



 n
=
n


Sn 


n


lim
j


exp
=
n


Xk k
1 2 3 
	 	 	
=
fX x
 
1 

1
x2
+
--------------
=
Sn
Sn
Xk
k
1
=
n

=
n
1 2 3 
	 	 	
=
Sn

Exercises    329
www.Academicpress.com
Section 7.4:  The Central Limit Theorem
7.23 Independent samples are taken of a random variable 
. If the PDF of 
 is uniform over 
the interval 
 and zero elsewhere, then approximate the density of the 
sample mean with a normal density, assuming the number of samples is large.  Write the 
approximation as an equation.
7.24 Consider the lottery described in Exercise 2.61.  
(a)
Assuming six million tickets are sold and that each player selects his/her number 
independent of all others, find the exact probability of fewer than 3 players winning 
the lottery.
(b)
Approximate the probability in part (a) using the Poisson approximation to the 
binomial distribution.
(c)
Approximate the probability in part (a) using the central limit theorem.  In this 
example, which approximation is more accurate?
7.25 A communication system transmits bits over a channel such that the probability of being 
received in error is 
.  Bits are transmitted in blocks of length 1023 bits and an 
error correction scheme is used such that bit errors can be corrected provided that no 
more than 30 errors occur in a 1023 bit block.  Use the central limit theorem to 
approximate the probability that no more than 30 errors occur in a 1023 bit block.
7.26 A certain class of students takes a standardized test where each student’s score is 
modeled as a random variable with mean, 
, and standard deviation, 
.  The 
school will be put on probationary status if the class average falls below 75.  If there are 
100 students in the class, use the central limit theorem to approximate the probability that 
the class average falls below 75.
7.27 Let 
 be a sequence of IID exponential random variables with mean of 1.  We wish to
 compute 
 for some constant  (such that >25).  
(a)
Find a bound to the probability using Markov’s inequality.
(b)
Find a bound to the probability using Chebyshev’s inequality.
(c)
Find a bound to the probability using the Chernoff bound.
(d)
Find an approximation to the probability using the central limit theorem.
(e)
Find the exact probability.
(f)
Plot all five results from (a) through (e) for 
 and determine for what range of 
 the central limit theorem gives the most accurate approximation compared with 
the 3 bounds.
X
X
1
12

–
1
12


	

p
0.02
=

85
=

5
=
Xk
Pr
Xk
k
1
=
n

y









y
y
y
25

y

330    Chapter 7
www.Academicpress.com
Section 7.5: Confidence Intervals
7.28 Suppose we wish to estimate the probability, 
,  of some event, 
.  We do so by 
repeating an experiment  times and observing whether or not the event 
 occurs during 
each experiment.  In particular, let 
We then estimate 
 using the sample mean of the 
,
.
(a)
Assuming  is large enough so that the central limit theorem applies, find an 
expression for 
.
(b)
Suppose we want to be 95% certain that our estimate is within 
 of the true 
value.  That is, we want 
.  How large does  need to 
be?  In other words, how many time do we need to run the experiment?
(c)
Let 
 be the number of times that we observe the event 
 during our  
repetitions of the experiment.  That is, let 
.  Assuming that 
 is chosen according to the results of part (b), find an expression for the average 
number of times the event 
 is observed, 
.  Show that for rare events (i.e., 
) 
 is essential independent of 
.  Thus, even if we have no idea about 
the true value of 
, we can run the experiment until we observe the event 
 for a 
predetermined number of times and be assured of a certain degree of accuracy in 
our estimate of 
.
7.29 Suppose we wish to estimate the probability, 
,  of some event 
 as outlined in 
Exercise 7.28.  As motivated by the result of part (c) of Exercise 7.28, suppose we repeat 
our experiment for a random number of trials, 
.  In particular, we run the experiment 
until we observe the event 
 exactly 
 times and then form the estimate of 
 
according to
.
Here, the random variable 
 represents the number of trials until the 
th occurrence of 
.  
(a)
Find 
.  Is this estimate unbiased?
(b)
Would it be better to use 
 as an estimate?
pA
A
n
A
Xi
1,   A occured during ith experiment,
0,
otherwise.                                   



=
pA
Xi
pˆA
1
n---
Xi
i
1
=
n

=
n
Pr pˆ A
pA
–




10%

Pr pˆA
pA
–
0.1pA



0.95
=
n
Yn
A
n
Yn
X1
X2

Xn
+
+
+
=
n
A
E Yn


pA
1
«
E Yn


pA
pA
A
pA
pA
A
N
A
m
pA
pˆA
m
1
–
N
1
–
-------------
=
N
m
A
E pˆA


pˆA
m
N----
=

Exercises    331
www.Academicpress.com
7.30 A company manufactures five-volt power supplies. However, since there are 
manufacturing tolerances, there are variations in the voltage design. The standard 
deviation in the design voltage is 5%. Using a 99% confidence level, determine whether 
or not the following samples fall within the confidence interval:
(a)
 100 samples, the estimate of 
(b)
 100 samples, the estimate of 
(c)
 100 samples, the estimate of 
Hint: refer to Equation (7.39)
7.31 You collect a sample size 
 of data and find that a 90% confidence level has width, 
. 
What should the sample size 
 be to increase the confidence level to 99.9% and yet 
maintain the same interval width, 
?
7.32 Company A manufactures computer applications boards.  They are concerned with the 
mean time before failures (MTBF), which they regularly measure.  Denote the sample 
MTBF as 
 and the true MTBF as 
.  Determine the number of failures that must be 
measured before  
 lies within 20 % of the true 
 with a 90% probability. Assume 
the PDF is exponential, i.e., 
.
7.33 A political polling firm is conducting a poll in order to determine which candidate is 
likely to win an upcoming election.  The polling firm interviews  likely voters and asks 
each whether or not they will vote for the republican (R) or the democrat (D) candidate.  
They then tabulate the percentage that respond R and D.
(a)
How many voters should the firm poll in order to correctly estimate the correct 
proportion of R and D respondents in the general population to within 
 
percentage points with 90% probability?
(b)
Repeat part (a) if we want 95% confidence in our polling data.
Section 7.6: Random Sums of Random Variables
7.34 A node in a communication network receives data packets of variable length.  Each 
packet has a random number of bits that is uniformly distributed over the integers 
. The number of packet arrivals per minute is a Poisson random 
variable with a mean of 50.
(a)
What is the average number of data bits per minute arriving at the node?
(b)
What is the variance of the number of data bits per minute arriving at the node?
7.35 The number of cars approaching a toll booth in a minute follows a geometric random 
variable with a mean of 2 cars/minute.  The time it takes the toll collector to serve each 
car is an exponential random variable with a mean of 20 seconds.
(a)
Find the mean time that the toll collector will require to serve cars that arrive in a 
one-minute interval.
X
4.7
=
X
4.9
=
X
5.4
=
N1
w
N2
w
ˆ M
M
ˆ M
M
fM x
 
1 M



x M

–

u x
 
exp
=
n
3

100 101 102  999
	
	
	
	
 
!

332    Chapter 7
www.Academicpress.com
(b)
Find the PDF of the time that the toll collector will require to serve cars that arrive 
in a one-minute interval.
(c)
What is the probability that the toll collector will require more than one minute to 
serve the cars that arrive during a one-minute interval, thereby causing a queue to 
form?
7.36 Let 
 be a random sum of discrete IID random variables.  Further, let 
 and 
 be the probability-generating functions of 
 and 
, respectively.  
Find the probability-generating function of  assuming that 
 is independent of the 
.  
7.37 A gambler plays a game of chance where he wins $1 with probability  and loses $1 
with probability 
 each time he plays.  The number of games he plays in an hour, 
, 
is a random variable with a geometric PMF, 
, 
.  
(a)
What is the PGF of the gambler’s total winnings after playing for an hour?
(b)
What is the probability that the gambler has not lost any money after an hour if 
 and 
?
Miscellaneous Exercises
7.38 In this exercise, a proof of equation (7.73) is constructed. Write the random sum as 
,
where 
 is a Bernoulli random variable in which 
 if 
 and 
 if 
.  
(a)
Prove that 
 and 
 are independent and hence
.
(b)
Prove that the equation of part (a) simplifies to
.
7.39 Suppose that  
 is a sequence of IID Gaussian random variables. Recall that the sample 
variance is given by
 
where 
.
S
Xk
k
1
=
N

=
HN z 
HX z 
N
X
S
N
Xk
p
1
p
–
N
PN n
 
1
q
–

qn
1
–
=
n
1 2 3 
	 	 	
=
p
0.48
=
q
7 8

=
SN
Zi
i
1
=
N

YiZi
i
1
=


=
=
Yi
Yi
1
=
N
i
"
Yi
0
=
N
i

Yi
Zi
E SN


E Yi

E Zi


i
1
=


=
E SN


E Zi

E N


=
Xk
sˆ2
1
n
1
–
------------
Xk
ˆ
–

2
k
1
=
n

=
ˆ
1
n---
Xk
k
1
=
n

=

Exercises    333
www.Academicpress.com
(a)
Show that the sample variance can be written as a quadratic form 
 and 
find the corresponding form of the matrix 
.
(b)
Use the techniques outlined in Section 6.4.2 to show that the characteristic function 
of 
 is
.
(c)
Show that the PDF of 
 is that of a chi-square random variable.
7.40 Let 
 be a zero-mean, unit-variance, Gaussian random variable and let 
 be a 
chi-square random variable with 
 degrees of freedom (see Appendix D, section 
D.1.4).  If 
 and 
 are independent, find the PDF of
.
Hint: One way to accomplish this is to define an auxiliary random variable, 
, and 
then find the joint PDF of  and 
 using the 2 × 2 transformation techniques outlined in 
Section 5.9.  Once the joint PDF is found, the marginal PDF of 
 can be found by 
integrating out the unwanted variable 
.  
Note: This is the form of the statistic
 
of Equation (7.41) where the sample mean is Gaussian and the sample variance is 
chi-square (by virtue of the results of Exercise 7.39) assuming that the underlying 
 are 
Gaussian.
7.41 Suppose we form a sample variance 
 from a sequence of IID 
Gaussian random variables and then form another sample variance
 
 from a different sequence of IID Gaussian random variables
 that are independent from the first set. We wish to determine if the true variances of the 
two sets of Gaussian random variables are the same or if they are significantly different, 
so we form the ratio of the sample variances
sˆ2
XTBX
=
B
sˆ2
sˆ2 


1
1
2j 2
n
1
–
------------
–




n
1
–
2
------------
----------------------------------------------
=
sˆ2
X
Y
n
1
–
X
Y
T
X
Y n

--------------
=
U
Y
=
T
U
T
U
Tˆ
ˆ
X
–
sˆ
n

----------------
=
Xk
sˆ12
1
n
1
–
------------
Xk
Xˆ
–

2
k
1
=
n

=
sˆs2
1
m
1
–
-------------
Yk
Yˆ
–

2
k
1
=
m

=
F
sˆ12
sˆ22
-----
=

334    Chapter 7
www.Academicpress.com
to see if this quantity is either large or small compared to 1.  Assuming that the 
 and 
the 
 are both standard normal, find the PDF of the statistic 
 and show that it follows 
an F distribution (see Appendix D, Section D.1.7).  Hint: Use the conditional PDF 
approach outlined in Section 5.9.
MATLAB Exercises
7.42 Let 
, , and  be independent Gaussian random variables with equal means of 
 
and variances of 
.  Estimate the mean and variance of 
 by 
constructing a large number of realizations of this random variable in MATLAB and then 
computing the sample mean and sample variance.  How many samples of the random 
variable were needed before the sample mean and sample variance seemed to converge 
to a fairly accurate estimate.  (To answer this, you must define what you mean by “fairly 
accurate.”)
7.43 For the random variable 
 described in Exercise 7.42, form an estimate of the CDF by 
following the procedure outlined in Example 7.5.  Also, form an estimate of the PDF of 
this random variable.  Explain the procedure you used to estimate the PDF.  
7.44 A player engages in the following dice tossing game (“craps”).  Two dice are rolled.  If 
the player rolls the dice such that the sum is either 7 or 11, he immediately wins the 
game.  If the sum is 2, 3, or 12, he immediately loses.  If he rolls a 4, 5, 6, 8, 9, or 10, this 
number is called the “point” and the player continues to roll the dice.  If he is able to roll 
the point again before he rolls a 7, he wins.  If he rolls a 7 before he rolls the point again, 
he loses.  Write a MATLAB program to simulate this dice game and estimate the 
probability of winning.
7.45 Let 
, 
, be a sequence of IID random variables uniformly distributed 
over (0, 1).  Suppose we form the sum 
.  First, find the mean and variance 
of 
.  Then write a MATLAB program to estimate the PDF of 
.  Compare the 
estimated PDF with a Gaussian PDF of the same mean and variance.  Over what range of 
 is the Gaussian approximation of the PDF within 1% of the true PDF?  Repeat this 
problem for 
.
7.46 Suppose you are given an observation of sample values of a sequence of random 
variables, 
, 
.  Write a MATLAB program to plot these data points 
along with a least squares curve fit to the data (see the results of Exercise 7.8).  Run your 
program using the following sequence:
.
Xk
Yk
F
X Y
Z

3
=
2
4
=
W
X2
Y2
Z2
+
+
=
W
Xi i
1 2  n
	 	
	
=
Z
Xi
i
1
=
n

=
Z
Z
Z
n
5 10 20 50 and100
	
	
	
	
=
xn n
1 2 3  m
	 	 	
	
=
0 1 0
1
–
2
3
–
5 0
7
–
8
	 	 	
	 	
	 	 	
	



335
CHAPTER 8
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4-00008-5
© 2012 by Elsevier Inc. All rights reserved.
Random Processes
This chapter introduces the concept of a random process. Most of the treatment in this text 
views a random process as a random function of time. However, time need not be the 
independent variable.  We can also talk about a random function of position, in which case 
there may be two or even three independent variables and the function is more commonly 
referred to as a random field.  The concept of a random process allows us to study systems 
involving signals which are not entirely predictable.  These random signals play fundamental 
roles in the fields of communications, signal processing, and control systems, and many other 
engineering disciplines.  This and the following chapters will extend the study of signal and 
system theory to include randomness.  In this chapter, we introduce some basic concepts, 
terminologies, notations, and tools for studying random processes and present several 
important examples of random processes as well.
8.1  Definition and Classification of Processes
In the study of deterministic signals, we often encounter four types or classes of signals:
•
Continuous time and continuous amplitude signals are a function of a continuous 
independent variable, time.  The amplitude of the function is also continuous.
•
Continuous time and discrete amplitude signals are a function of a continuous independent 
variable, time—but the amplitude is discrete.  
•
Discrete time and continuous amplitude signals are functions of a quantized or discrete 
independent time variable, while amplitude is continuous.
•
Discrete time and discrete amplitude signals are functions where both the independent 
time variable and the amplitude are discrete.
In this text, we write a continuous function of time as 
, where  is the continuous time 
variable.  For discrete-time signals, the time variable is typically limited to regularly spaced 
discrete points in time, 
.  In this case, we use the notation 
 to represent 
the discrete sequence of numbers.  Most of the discussion that follows is presented in terms of 
continuous time signals, but the conversion to the discrete-time case will be straightforward in 
most cases.
Recall from Chapter 3 that a random variable, 
, is a function of the possible outcomes, , of 
an experiment.  Now, we would like to extend this concept so that a function of time 
 (or 
 in the discrete-time case) is assigned to every outcome, , of an experiment.  The 
x t 
t
t
nto
=
x n
 
x nto


=
X

x t 
x n
 


336    Chapter 8 
www.Academicpress.com
function, 
, may be real or complex and it can be discrete or continuous in amplitude.  
Strictly speaking, the function is really a function of two variables, 
, but to keep the 
notation simple, we typically do not explicitly show the dependence on the outcome, just as 
we have not in the case of random variables.  The function 
 may have the same general 
dependence on time for every outcome of the experiment or each outcome could produce a 
completely different waveform.  In general, the function 
 is a member of an ensemble 
(family, set, collection) of functions.  Just as we did for random variables, an ensemble of 
member functions, 
, is denoted with an upper case letter.  Thus, 
 represents the 
random process, while 
 is one particular member or realization of the random process.  In 
summary, we have the following definition of a random process:
Definition 8.1:  A random process is a function of the elements of a sample space, ,
as well as another independent variable, . Given an experiment, 
, with sample
space, 
, the random process, 
, maps each possible outcome, 
, to a
function of , 
, as specified by some rule.
Example 8.1:
Suppose an experiment consists of flipping a coin.  If the outcome is heads, 
, the 
random process takes on the functional form 
; whereas, if the outcome is 
tails, 
, the realization 
 occurs, where 
 is some fixed frequency.  
The two realizations of this random process are illustrated in Figure 8.1.  
x t 
x t 



x t 
x t 
X t 
X t 
x t 
S
t
E
S
X t 

S

t
x t 




H
=
xH t 
	ot


sin
=

T
=
xT t 
2	ot


sin
=
	o
0
0.5
1
1.5
2
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Time, t 
X(t)
Figure 8.1 
Member functions for the random process of Example 8.1.



Random Processes    337
www.Academicpress.com
The random process in Example 8.1 actually has very little randomness.  There are only two 
possible realizations of the random process.  Furthermore, given an observation of the 
realization of the random process at one point in time, 
, one could determine the rest of 
the realization (as long as 
).  The next example shows that a random process could 
have this last property, even if the number of realizations were infinite.
Example 8.2:
Now suppose that an experiment results in a random variable  that is uniformly distributed 
over 
.  A random process is then constructed according to 
.  Since the 
random variable is continuous, there are an uncountably infinite number of realizations of 
the random process.  A few are shown in Figure 8.2.  As with the previous example, given an 
observation of the realization of the random process at one point in time, 
, one could 
determine the rest of the realization (as long as 
).
Example 8.3:
This example is a generalization of that given in Example 8.1.  Suppose now the experiment 
consists of flipping a coin repeatedly and observing the sequence of outcomes.  The random 
process 
 is then constructed as 
, 
, where 
 if the ith 
flip of the coin results in “heads” and 
 if the ith flip of the coin results in “tails.”  
One possible realization of this random process is illustrated in Figure 8.3.  This is the sort 
of signal that might be produced by a frequency shift keying modem.  In that application, 
the frequencies are not determined by coin tosses, but by random data bits instead.
X t1


	ot1
n

A
0 1


X t 
A
	ot


sin
=
X t1


	ot1
n

0
2
4
6
8
10
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Time, t 
X(t)
Figure 8.2  
Some member functions for the random process of Example 8.2.
X t 
X t 
it


sin
=
i
1
–

T
t
iT


i
	o
=
i
2	o
=



(Continued)

338    Chapter 8 
www.Academicpress.com
Example 8.4:
As an example of a random process that is discrete in amplitude but 
continuous in time, we present the so-called “random telegraph” process.  
Let 
be a sequence of IID random variables, each with an 
exponential distribution,
.
At any time instant, the random telegraph signal, 
, takes on one of two possible 
states, 
 or 
.  Suppose the process starts (at time 
) in the zero state.  
It then remains in that state for a time interval equal to 
 at which point it switches to 
the state 
.  The process remains in that state for another interval of time equal in 
length to 
 and then switches states again.  The process then continues to switch after 
waiting for time intervals specified by the sequence of exponential random variables.  
One possible realization is shown in Figure 8.4.  The MATLAB code for generating such a 
process follows.
N=10;
% number of switches in realization
Fs=100;
% Sample rate (samples per second)
lambda=1/2;
% switching rate (switches per second)
X=[];
S=rand(1,N);
% uniform random variables.
T=-log(S)/lambda;
% transform to exponential RVs.
V=cumsum(T);
% switching times.
state=0; Nsold=1;
0
1
2
3
4
5
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
t/T
X(t)
Figure 8.3  
One possible realization for the random process of Example 8.3.
T1 T2 T3 



fT s 
e s
–
u s 
=
X t 
X t 
0
=
X t 
1
=
t
0
=
T1
X t 
1
=
T2



Random Processes    339
www.Academicpress.com
for k=1:N
   Nsnew=ceil(V(k)*Fs);
% new switching time
   Ns=Nsnew-Nsold;
% number of samples in current 
% switching interval
   X=[X state*ones(1,Ns)];
   state=1-state;
% switch state
   Nsold=Nsnew;
end
t=[1:length(X)]/Fs;
% time axis
plot(t,X)
% plot results
xlabel('time, t'); ylabel('X(t)')
axis([0 max(t) -0.1 1.1])
% manual scale of axes
Example 8.5:
As an example of a discrete-time random process, suppose each 
outcome of an experiment produces a sequence of IID, zero-mean 
Gaussian random variables, 
.  A discrete-time random 
process 
 could be constructed according to:
,
with the initial condition 
.  The value of the process at each point in time is 
equal to the value of the process at the previous point in time plus a random increase 
(decrease) which follows a Gaussian distribution.  Note also that 
 is just the sum of 
the first  terms in the sequence 
.  A sample realization of this random process is 
shown in Figure 8.5.  The MATLAB code for generating this process is provided here.  
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
Time, t 
X(t)
T1
T2
T3
Figure 8.4  
One possible realization for the random telegraph signal of Example 8.4.
W1 W2 W3 



X n
 
X n
 
X n
1
–


Wn
+
=
X 0
 
0
=
X n
 
n
Wi


(Continued)

340    Chapter 8 
www.Academicpress.com
The reader is encouraged to run this program several times to see several different 
realizations of the same random process.
N=25;
% number of time instants in process.
W=randn(1,N);
% Gaussian random variables.
X=[0 cumsum(W)];
% Samples of X[n]
stem([0:N],X,'o')
% plot realization of X[n]
xlabel('time, n'); ylabel('X[n]');
8.2   Mathematical Tools for Studying Random Processes
As with random variables, we can mathematically describe a random process in terms of a 
cumulative distribution function, probability density function, or a probability mass function.   
In fact, given a random process, 
, which is sampled at some specified point in time, 
, the result is a random variable, 
.  This random variable can then be 
described in terms of its PDF, 
.  Note that an additional time variable has been added 
to the PDF.  This is necessary due to the fact that the PDF of the sample of the random process 
may depend on when the process is sampled.  If desired, the CDF or PMF can be used rather 
than the PDF to describe the sample of the random process.
Example 8.6:
Consider the random telegraph signal of Example 8.4.  Since this process is binary 
valued, any sample will be a Bernoulli random variable.  The only question is, what is the 
probability that 
 is equal to 1 (or 0)?  Suppose that there are exactly  switches 
0
5
10
15
20
25
-3
-2
-1
0
1
2
3
4
Time, n
X[n]
Figure 8.5  
One possible realization for the discrete-time random process of Example 8.5.
X t 
t
tk
=
Xk
X tk


=
fX xk tk
;


Xk
X tk


=
n



Random Processes    341
www.Academicpress.com
in the time interval 
.  Then 
.  Stated another way, define 
.  There will be exactly  switches in the time interval 
 provided 
that 
.  Therefore, 
.
Since the 
 are IID and exponential, 
 will follow a Gamma distribution.  Using the 
Gamma PDF for 
 and the fact that 
 results in
.
So, it is seen that the number of switches in the interval 
 follows a Poisson 
distribution.  The sample of the random process will be equal to 0 if the number of 
switches is even.  Thus,
.
Likewise,
.
The behavior of this distribution as it depends on time is shown in Figure 8.6 and should 
make intuitive sense.  For very small values of 
, it is most likely that there are no 
switches in the interval 
, in which case 
 should be close to one.  On the 
other hand, for large 
, many switches will likely occur and it should be almost equally 
likely that the process take on the values of 0 or 1.
Example 8.7:
Now consider the PDF of a sample of the discrete-time process of Example 8.5.  Note 
that since 
 is formed by summing  IID Gaussian random variables, 
 will itself 
be a Gaussian random variable with mean of 
 and variance 
.  
In this case, since the Wi’s were taken to be zero-mean, the PDF of 
 is
.
Once again, we see that for this example, the form of the PDF does indeed depend on 
when the sample is taken.
0 tk


X tk


n mod 2
=
Sn
T1
T2

Tn
+
+
+
=
n
0 tk


Sn
tk
Sn
1
+


Pr n switches in 0 tk




Pr Sn
tk
Sn
1
+




Pr Sn
tk
Sn
1
+
Sn=s



fSn s  s
d

=
=
Pr tk
Sn
1
+
Sn=s


fSn s  s
d
0
tk
Pr Tn
1
+
tk
s
–


fSn s  s
d
0
tk
=
=
Ti
Sn
fSn s 
Pr Tn
1
+
tk
s
–



 tk
s
–


–


exp
=
Pr n switches in 0 tk




e  tk
s
–


–
nsn
1
–
n
1
–

!
------------------e s
–
s
d
0
tk

ne tk
–
n
1
–

!
------------------
sn
1
–
s
d
0
tk

tk

n
n!
---------------e tk
–
=
=
=
0 tk


Pr X tk

=0


Pr n switches in 0 tk




n even

tk

n
n!
---------------e tk
–
n even

e tk
–
tk


cosh
1
2---
1
2---e 2tk
–
+
=
=
=
=
Pr X tk

=1


Pr n switches in 0 tk




n odd

tk

n
n!
---------------e tk
–
n odd

e tk
–
sinh tk


1
2---  1
2---
–
e 2tk
–
=
=
=
=
tk
0 tk


Pr X tk

=0


tk
X n
 
n
X n
 
E X n
 


nW
=
Var X n
 


nW
2
=
X n
 
fX x n;


1
2
nW
2
----------------------
x2
2nW
2
--------------
–




exp
=




342    Chapter 8 
www.Academicpress.com
The PDF (or CDF or PMF) of a sample of a random process taken at an arbitrary point in time 
goes a long way toward describing the random process, but it is not a complete description.  
To see this, consider two samples, 
 and 
, taken at two arbitrary points 
in time.  The PDF, 
, describes both 
 and 
, but it does not describe the 
relationship between 
 and 
.  For some random processes, it might be reasonable to 
expect that 
 and 
 would be highly correlated if 
 is near 
, while 
 and 
 might be 
virtually uncorrelated if 
 and 
 are far apart.  To characterize relationships of this sort, a 
joint PDF of the two samples would be needed.  That is, it would be necessary to construct a 
joint PDF of the form 
.  This is referred to as a second-order PDF of the 
random process 
.  
Continuing with this reasoning, in order to completely describe the random process, it is necessary 
to specify an th order PDF for an arbitrary .  That is, suppose the random process is sampled at 
time instants 
, 
, ..., 
, producing the random variables 
, 
, ..., 
.  The joint PDF of the  samples, 
, for an 
arbitrary  and arbitrary sampling times will give a complete description of the random process.  
In order to make this notation more compact, the vectors 
, 
, and 
are introduced and the th order joint PDF is 
written as 
.  
Unfortunately, for many realistic random processes, the prospects of writing down an -th 
order PDF are rather daunting.  One notable exception is the Gaussian random process which 
will be described in detail in Section 8.5.  However, for most other cases, specifying a joint 
0
0.5
1
1.5
2
2.5
3
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Time, t 
Probability
Pr(X(t) = 0)
Pr(X(t) = 1)
Figure 8.6 
 Time dependence of the PMF for the random telegraph signal.
X1
X t1


=
X2
X t2


=
fX x;t


X1
X2
X1
X2
X1
X2
t1
t2
X1
X2
t1
t2
fX1 X2

x1 x2

;t1 t2



X t 
n
n
t1 t2
tn
X1
X t1


=
X2
X t2


=
Xn
X tn


=
n
fX1 X2  Xn



x1 x2  xn



;t1 t2  tn





n
X
X1 X2  Xn




T
=
x
x1 x2  xn




T
=
t
t1 t2  tn




T
=
n
fX x;t


n

Random Processes    343
www.Academicpress.com
PDF of  samples may be exceedingly difficult, and hence it is necessary to resort to a simpler 
but less complete description of the random process.  The simplest is the mean function of the 
process.
Definition 8.2:   The mean function of a random process is simply the expected value 
of the process.  For continuous time processes, this is written as
,
(8.1)
while for discrete-time processes, the following notation is used:
.
(8.2)
In general, the mean of a random process may change with time, but in many cases, this 
function is constant.  Also, it is noted that only the first-order PDF of the process is needed to 
compute the mean function.
Example 8.8:
Consider the random telegraph process of Example 8.4.  It was shown in Example 
8.6 that the first-order PMF of this process was described by a Bernoulli distribution 
with
.
The mean function then follows as
.
Example 8.9:
Next, consider the sinusoidal random process of Example 8.2 where 
 and 
 was a uniform random variable over 
.  In this case,
.
This example illustrates a very important concept in that quite often it is not necessary 
to explicitly evaluate the first-order PDF of a random process in order to evaluate its 
mean function.
n
X t 
E X t 


xfX x;t

 x
d

=
=
X n
 
E X n
 


xfX x;n

 x
d

=
=
Pr X t  = 1


1
2---
1
2---
t
–


exp
–
=
X t 
E X t 


1*Pr X t  = 1


0*Pr X t  = 0


+
1
2---
1
2---
t
–


exp
–
=
=
=
X t 
A
	ot


sin
=
A
0 1


X t 
E X t 


E A
	ot


sin


E A
 
	ot


sin
1
2---
	ot


sin
=
=
=
=





344    Chapter 8 
www.Academicpress.com
Example 8.10:
Now suppose the random process of the previous example is slightly modified.  In 
particular, consider a sine-wave process where the random variable is the phase, 
, 
which is uniformly distributed over 
.  That is, 
.  For this 
example, the amplitude of the sine wave, , is taken to be fixed (not random).  The 
mean function is then
,
which is a constant.  Why is the mean function of the previous example a function of 
time and this one is not?  Consider the member functions of the respective ensembles for 
the two random processes.
Example 8.11:
Now consider a sinusoid with a random frequency 
, where 
 is a random variable uniformly distributed over some interval 
.  
The mean function can be readily determined to be
.
We can also estimate the mean function through simulation.  Below we provide some 
MATLAB code to produce many realizations of this random process.  The mean function 
is then found by taking the sample mean of all the realizations created.  The sample 
mean and the ensemble mean are shown in Figure 8.7.  Naturally, more or less accuracy 
in the sample mean can be obtained by varying the number of realizations generated.
fo=2;
% max frequency
N=1000;
% number of realizations
t=[-4.995:0.01:4.995];
% time axis
F=fo*rand(N,1);
% uniform frequencies
x=cos(2*pi*F*t);
% each row is a 
% realization of process
sample_mean=sum(x)/N;
% compute sample mean
true_mean=sin(2*pi*fo*t)./(2*pi*fo*t); % compute ensemble mean
plot(t,sample_mean,'-',t,true_mean,'--')% plot results
xlabel('t (seconds)'); ylabel('mu(t)');
To partially describe the second-order characteristics of a random process, the autocorrelation 
function is introduced. 

0 2
 


X t 
a
	ot

+


sin
=
a
X t 
E X t 


E a
	ot

+


sin


a f 
 
	ot

+


sin

d

a
2
------
	ot

+


sin

d
0
2

0
=
=
=
=
=
X t 
2
Ft


cos
=
F
0 fo



X t 
E
2
Ft


cos


1
fo
----
2
ft


cos
fd
0
fo
2
fot


sin
2
fot
--------------------------
sinc 2fot


=
=
=
=





Random Processes    345
www.Academicpress.com
Definition 8.3:  The autocorrelation function, 
, of a continuous-time 
random process, 
, is defined as the expected value of the product 
:
.
(8.3)
For discrete-time processes, the autocorrelation function is 
.
(8.4)
Naturally, the autocorrelation function describes the relationship (correlation) between 
two samples of a random process.  This correlation will depend on when the samples are 
taken; thus, the autocorrelation function is, in general, a function of two time variables.  
Quite often we are interested in how the correlation between two samples depends on 
how far apart the samples are spaced.  To explicitly draw out this relationship, define a 
time difference variable, 
, and the autocorrelation function can then be 
expressed as
,
(8.5)
where we have replaced 
 with  to simplify the notation even further.  
-5
-4
-3
-2
-1
0
1
2
3
4
5
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
t (seconds)
m(t)
Figure 8.7  
Comparison of the sample mean and ensemble mean for the sinusoid with random frequency of 
Example 8.11.  The solid line is the sample mean while the dashed line is the ensemble mean.
RXX t1 t2



X t 
X t1

X t2


RXX t1 t2



E X t1

X t2




x1x2fX1 X2

x1 x2

;t1 t2


 x1
d
x2
d

–



–


=
=
RXX n1 n2



E X n1

X n2




x1x2fX1 X2

x1 x2

;n1 n2


 x1
d
x2
d

–



–


=
=
	
t2
t1
–
=
RXX t t
	
+



E X t X t
	
+




=
t1
t

346    Chapter 8 
www.Academicpress.com
Example 8.12:
Consider the sine wave process with a uniformly distributed amplitude as described in 
Examples 8.2 and 8.9, where 
.  The autocorrelation function is found as
or
.
Example 8.13:
Now consider the sine wave process with random phase of Example 8.10 where 
.  Then
.
To aid in calculating this expected value, we use the trigonometric identity 
.
The autocorrelation then simplifies to
or
.
Note that in this case, the autocorrelation function is only a function of the difference 
between the two sampling times.  That is, it does not matter where the samples are 
taken, only how far apart they are.
Example 8.14:
Recall the random process of Example 8.5 where 
, 
 and the 
 were a sequence of IID, zero-mean Gaussian random variables.  In this case, it is 
easier to calculate the autocorrelation function using the alternative expression,
X t 
A

ot


sin
=
RXX t1 t2



E X t1

X t2




E A2

ot1


sin

ot2


sin


1
3---

ot1


sin

ot2


sin
=
=
=
RXX t t
	
+



1
3---

ot


sin

o t
	
+




sin
=
X t 
a

ot

+


sin
=
RXX t1 t2



E X t1

X t2




E a2

ot1

+



ot2

+


sin
sin


=
=
x
 
sin
y
 
sin
1
2---
x
y
–


cos
1
2---
x
y
+


cos
–
=
RXX t1 t2



a2
2-----E

o t2
t1
–




cos


a2
2-----E

o t1
t2
2
+
+




cos


+
a2
2-----

o t2
t1
–




cos
=
=
RXX t t
	
+



a2
2-----

o	


cos
=
X n
 
X n
1
–


Wn
+
=
X 0
 
0
=
Wn
X n
 
Wi
i
1
=
n

=






Random Processes    347
www.Academicpress.com
Then,
.
Since the 
 are IID and zero-mean, 
 unless 
.  Therefore,
.
Definition 8.4:  The autocovariance function, 
, of a continuous time 
random process, 
, is defined as the covariance of 
 and 
:
.
(8.6)
The definition is easily extended to discrete-time random processes.
As with the covariance function for random variables, the autocovariance function can be 
written in terms of the autocorrelation function and the mean function:
.
(8.7)
Once the mean and autocorrelation functions of a random process have been computed, the 
autocovariance function is trivial to find.  
The autocovariance function is helpful when studying random processes which can be 
represented as the sum of a deterministic signal, 
, plus a zero-mean noise process, 
.  
If 
, then the autocorrelation function of 
 is 
,
(8.8)
using the fact that 
.  If the signal is strong compared to the noise, the deterministic 
part will dominate the autocorrelation function, and thus 
 will not tell us much 
about the randomness in the process 
.  On the other hand, the autocovariance function is
.
(8.9)
Therefore, the autocovariance function allows us to isolate the noise which is the source of 
randomness in the process.
Definition 8.5:  For a pair of random processes 
 and 
, the cross-correlation 
function is defined as
.
(8.10)
RXX n1 n2



E X n1

X n2




E
Wi
Wj
j
1
=
n2
i
1
=
n1
E WiWj


j
1
=
n2
i
1
=
n1
=
=
=
Wi
E WiWj


0
=
i
j
=
RXX n1 n2



min n1 n2


W
2
=
CXX t1 t2



X t 
X t1


X t2


CXX t1 t2



Cov X t1

 X t2





E
X t1


X t1


–

 X t2


X t2


–




=
=
CXX t1 t2



RXX t1 t2



X t1

X t2


–
=
s t 
N t 
X t 
s t 
N t 
+
=
X t 
RXX t1 t2



E
s t1


N t1


+

 s t2


N t2


+




s t1

s t2


RNN t1 t2



+
=
=
N t 
0
=
RXX t1 t2



X t 
CXX t1 t2



RXX t1 t2



s t1

s t2


–
RNN t1 t2



CNN t1 t2



=
=
=
X t 
Y t 
RXY t1 t2



E X t1

Y t2




=


348    Chapter 8 
www.Academicpress.com
Likewise, the cross-covariance function is
.
(8.11)
Example 8.15:
Suppose 
 is a zero-mean random process with autocorrelation function 
.  A 
new process 
 is formed by delaying 
 by some amount 
.  That is, 
.  
Then the cross-correlation function is
.
In a similar fashion, it is seen that 
 and 
.
8.3  Stationary and Ergodic Random Processes
From the few simple examples given in the preceding section, we conclude that the mean 
function and the autocorrelation (or autocovariance) function can provide information about 
the temporal structure of a random process.  We will delve into the properties of the 
autocorrelation function in more detail later in this chapter, but first the concepts of 
stationarity and ergodicity must be introduced.
Definition 8.6:  A continuous time random process 
 is strict sense stationary if 
the statistics of the process are invariant to a time shift.  Specifically, for any time shift 
 and any integer 
,
.
(8.12)
In general, it is quite difficult to show that a random process is strict sense stationary since to 
do so, one needs to be able to express the general th order PDF.  On the other hand, to show 
that a process is not strict sense stationary, one needs to show only that one PDF of any order 
is not invariant to a time shift.  One example of a process that can be shown to be stationary in 
the strict sense is an IID process.  That is, suppose 
 is a random process that has the 
property that 
 has an identical distribution for any  and that 
 and 
 are 
independent for any 
.  In this case,
.
(8.13)
CXY t1 t2



E
X t1


X t1


–

 Y t2


Y t2


–




=
X t 
RXX t1 t2



Y t 
X t 
td
Y t 
X t
td
–


=
RXY t1 t2



E X t1

Y t2




E X t1

X t2
td
–




RXX t1 t2
td
–



=
=
=
RYX t1 t2



RXX t1
td
–
t2



=
RYY t1 t2



RXX t1
td
–
t2
td
–



=
X t 
	
n
1

fX1 X2  Xn



x1 x2  xn



;t1 t2  tn




 =
fX1 X2  Xn



x1 x2  xn



;t1
	
+
t2
	
+
 tn
	
+





n
X t 
X t 
t
X t1


X t2


t1
t2

fX1 X2  Xn



x1 x2  xn



;t1 t2  tn





fXi xi;ti


i
1
=
n

=



Random Processes    349
www.Academicpress.com
Since the th order PDF is the product of first order PDFs and the first-order PDF is invariant 
to a time shift, then the th order PDF must be invariant to a time shift.
Example 8.16:
Consider the sinusoidal process with random amplitude from Example 8.2, where 
.  This process is clearly not stationary since if we take any realization of 
the process, 
, then a time shift 
 would not be a 
realization in the original ensemble.  Now suppose the process has a random phase 
rather than a random amplitude as in Example 8.10, resulting in 
.  It 
was already shown in Example 8.10 that 
 for this process, and therefore the 
mean function is invariant to a time shift.  Furthermore, in Example 8.13, it was shown 
that 
, and thus the autocorrelation function is also invariant 
to a time shift.  It is not difficult to show that the first-order PDF follows an arcsine 
distribution
,
  
,
and it is also independent of time and thus invariant to a time shift.  It seems that this 
process might be stationary in the strict sense, but it would be rather cumbersome to 
prove it because the th order PDF is difficult to specify.
As was seen in Example 8.16, it may be possible in some examples to determine that some of 
the statistics of a random process are invariant to time shifts, but determining stationarity in 
the strict sense may be too big of a burden.  In those cases, we often settle for a looser form of 
stationarity.
Definition 8.7:  A random process is wide sense stationary (WSS) if the mean 
function and autocorrelation function are invariant to a time shift.  In particular, this 
implies that
,
(8.14)
 (function only of ).
(8.15)
All strict sense stationary random processes are also WSS, provided that the mean and 
autocorrelation function exist.  The converse is not true. A WSS process does not necessarily 
need to be stationary in the strict sense.  We refer to a process which is not WSS as 
non-stationary. 
n
n
X t 
A

ot


sin
=
x t 
a

ot


sin
=
x t
	
+


a

o t
	
+




sin
=
X t 
a

ot

+


sin
=
X t 
0
=
RXX t t
	
+



a2 2




o	


cos
=
fX x;t


1
 1
x2
–
----------------------
=
1
x
1


–
n
X t 
X
constant
=
=
RXX t t
	
+



RXX 	
 
=
	



350    Chapter 8 
www.Academicpress.com
Example 8.17:
Suppose we form a random process 
 by modulating a carrier with another random 
process, 
.  That is, let 
 where 
 is uniformly distributed over 
 and independent of 
. Under what conditions is 
 WSS?  To answer this, we 
calculate the mean and autocorrelation function of 
.
,
.
While the mean function is a constant, the autocorrelation is not necessarily only a 
function of .  The process 
 will be WSS provided that 
.  
Certainly if 
 is WSS, then 
 will be as well.
Example 8.18:
Let 
 where  and  are independent random variables, both uniformly 
distributed over the interval 
.  To determine whether this process is WSS, calculate 
the mean and autocorrelation functions:
,
.
Clearly, this process is not WSS.
Many of the processes we deal with are WSS and hence have a constant mean function and an 
autocorrelation function that depends only on a single time variable.  Hence, in the remainder 
of the text, when a process is known to be WSS or if we are assuming it to be WSS, then we 
will represent its autocorrelation function by 
.  If a process is non-stationary or if we 
do not know if the process is WSS, then we will explicitly write the autocorrelation function as 
a function of two variables, 
.  For example, if we say that a process has a mean 
function of 
, and an autocorrelation function, 
, then the reader 
can infer that the process is WSS, even if it is not explicitly stated.  
In order to calculate the mean or autocorrelation function of a random process, it is necessary to 
perform an ensemble average.  In many cases, this may not be possible as we may not be able to 
observe all realizations (or a large number of realizations) of a random process.  In fact, quite often 
Y t 
X t 
Y t 
X t 

ot

+


cos
=

0 2


X t 
Y t 
Y t 
Y t 
E X t 

ot

+


cos


E X t 

E

ot

+


cos


0
=
=
=
RYY t t
	
+



E X t X t
	
+



ot

+


cos

o t
	
+



+


cos


=
E X t X t
	
+



 1
2---

o	


cos
1
2---E

o 2t
	
+


2
+


cos


+






=
1
2---R
XX t t
	
+




o	


cos
=
	
Y t 
RXX t t
	
+



RXX 	
 
=
X t 
Y t 
X t 
At
B
+
=
A
B
1 1

–


X t 
E At
B
+


E A
 t
E B
 
+
0
=
=
=
RXX t t
	
+



E
At
B
+

 A t
	
+


B
+




E A2

t t
	
+


E B2


E AB

 2t
	
+


+
+
1
3---t t
	
+


1
3---
+
=
=
=
RXX 	
 
RXX t t
	
+



X
1
=
RXX 	
 
	
–


exp
=





Random Processes    351
www.Academicpress.com
we may be able to observe only a single realization.  This would occur in situations where the 
conditions of an experiment cannot be duplicated and therefore the experiment is not repeatable.  
Is it possible to calculate the mean and/or autocorrelation function from a single realization of a 
random process?  The answer is sometimes, depending on the nature of the process.  
To start with, consider the mean.  Suppose a WSS random process 
 has a mean 
.  We 
are able to observe one realization of the random process, 
, and wish to try to determine 
 from this realization.  One obvious approach would be to calculate the time average1 of 
the realization:
.
(8.16)
However, it is not obvious if the time average of one realization is necessarily equal to the 
ensemble average.  If the two averages are the same, then we say that the random process is 
ergodic in the mean.
One could take the same approach for the autocorrelation function.  Given a single realization, 
, form the time-average autocorrelation function:
.
(8.17)
If 
 for any realization, 
, then the random process is said to be ergodic 
in the autocorrelation.  In summary, we have the following definition of ergodicity:
Definition 8.8:  A WSS random process is ergodic if ensemble averages involving the 
process can be calculated using time averages of any realization of the process.  Two 
limited forms of ergodicity are:
• Ergodic in the mean - 
,
• Ergodic in the autocorrelation - 
.
Example 8.19:
As a simple example, suppose 
 where  is a random variable with some 
arbitrary PDF 
.  Note that this process is stationary in the strict sense since for any 
realization, 
.  That is, not only are the statistics of the process invariant to 
X t 
X
x t 
X
x t 


1
2to
-------
to


lim
x t  td
to
–
to

=
x t 
 xx 	
 
x t x t
	
+




1
2to
-------
to


lim
x t x t
	
+

 td
to
–
to

=
=
 xx 	
 
RXX 	
 
=
x t 
x t 


E X t 


=
x t x t
	
+




E X t X t
	
+




=
X t 
A
=
A
fA a
 
x t 
x t
	
+


=

1 Throughout the text, angular brackets 
 are used as a shorthand notation to represent the time-
average operator.
 
(Continued)

352    Chapter 8 
www.Academicpress.com
time shifts, but every realization is also invariant to any time shift.  If we take the time 
average of a single realization, 
, we get 
.  Hence, each different 
realization will lead to a different time average and will not necessarily give the ensemble 
mean, 
.  Although this process is stationary in the strict sense, it is not ergodic in any 
sense.
Example 8.20:
Now consider the sinusoid with random phase 
, where 
 is uniform 
over 
.  It was demonstrated in Example 8.13 that this process is WSS.  But is it 
ergodic?  Given any realization 
, the time average is 
.  That is, the average value of any sinusoid is zero.  So, this 
process is ergodic in the mean since the ensemble average of this process was also zero.  
Next, consider the sample autocorrelation function:
.
This also is exactly the same expression obtained for the ensemble averaged 
autocorrelation function.  Therefore, this process is also ergodic in the autocorrelation.
Example 8.21:
For a process that is known to be ergodic, the autocorrelation function 
can be estimated by taking a sufficiently long time average of the 
autocorrelation function of a single realization.  We demonstrate this via 
MATLAB for a process that consists of a sum of sinusoids of fixed 
frequencies and random phases,
,
where the 
 are IID and uniform over 
.  For an arbitrary signal 
, we note the 
similarity between the time-averaged autocorrelation function and the convolution of 
 and 
.  If we are given a single realization, 
, which lasts only for the time 
interval, 
, then these two expressions are given by
,
x t 
a
=
x t 


a
=
A
X t 
a

ot

+


sin
=

0 2 


x t 
a

ot

+


sin
=
x t 


a

ot

+


sin


0
=
=
x t x t
	
+




a2

ot

+



ot

o	

+
+


sin
sin


=
a2
2-----

o	


cos


a2
2-----
2
ot

+
o	
2
+


cos


–
=
a2
2-----

o	


cos
=
X t 
2fkt
k
+


cos
k
1
=
n

=
K
0 2



x t 
x t 
x
t
–


x t 
to
–
to



x t x t
	
+




1
2to
	
–
----------------
x t x t
	
+

 td
to
–
to
	
–

=





Random Processes    353
www.Academicpress.com
,
for 
.  In general, we have the relationship
.
By using the MATLAB convolution function, conv, the time-averaged autocorrelation 
can easily be computed.  This is demonstrated in the code that follows.  Figure 8.8 
shows a comparison between the ensemble averaged autocorrelation and the time-
averaged autocorrelation taken from a single realization.  From the figure, it is noted 
that the agreement between the two is good for 
, but not good when 
.  This is 
due to the fact that when  approaches 
, the time window over which the time average 
is computed gets too small to produce an accurate estimate.
N=4;
% number of sinusoids
to=5;
% time duration
Ts=0.01;
% sample interval
t=[-to:Ts:to];
% time axis
tau=[-2*to:Ts:2*to];
% tau axis
theta=rand(1,N);
% random phases
f=1./[1:N];
% frequencies (not random)
x=zeros(size(t));
x t *x
t
–


x t x t
	
+

 td
to
–
to
	
–

=
	
0
!
x t x t
	
+




x t *x
t
–


2to
	
–
--------------------------
=
	
to
«
	
to
"
	
to
-10
-8
-6
-4
-2
0
2
4
6
8
10
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
t
RXX(t)
Figure 8.8  
Comparison of the time-average autocorrelation and the ensemble-average autocorrelation for 
the sum of sinusoids process of Example 8.21.  The solid line is the time-average autocorrelation 
while the dashed line is the ensemble-average autocorrelation.
(Continued)

354    Chapter 8 
www.Academicpress.com
True_Rxx=zeros(size(tau));
for k=1:N
   x=x+cos(2*pi*f(k)*t+2*pi*theta(k));
% construct process
   True_Rxx=True_Rxx+cos(2*pi*f(k)*tau)/2;
% compute Rxx(tau)
end
z=conv(x,fliplr(x));
% x(t)*x(-t)
Rxx=Ts*z./(2*to-abs(tau));
% time averaged Rxx
plot(tau,Rxx,'-',tau,True_Rxx,'--')
% plot results
xlabel('tau'); ylabel('R_X_X(tau)')
axis([-2*to 2*to -1.1*N/2 1.1*N/2])
The previous examples show two different random processes, one that is ergodic and one that 
is not.  What characteristics of a random process make it ergodic?  To get some better insight 
toward answering this question, consider a discrete-time process, 
, where each random 
variable in the sequence is IID and consider forming the time average,
.
(8.18)
The right hand side of the previous equation is nothing more than the sample mean.  By virtue 
of the law of large numbers, the limit will indeed converge to the ensemble mean of the 
random process, 
, and thus this process is ergodic in the mean.  In this case, the time 
average converges to the ensemble average because each time sample of the random process 
gives an independent observation of the underlying randomness.  If the samples were highly 
correlated, then taking more samples would not necessarily cause the sample mean to 
converge to the ensemble mean.   So, it seems that the form of the autocorrelation function will 
play some role in determining if a random process is ergodic in the mean.
To formalize this concept, consider the time average of an arbitrary WSS random process.
where  
.
(8.19)
Note that 
 is a random variable with an expected value given by2
.
(8.20)
Therefore, 
 is an unbiased estimate of the true mean, but for the process to be ergodic in the 
mean, it is required that 
 converges to 
 as 
.  This convergence will occur (in the 
X n
 
X n
 


1
m----
X n
 
n
1
=
m

m


lim
=
X
X t 


Xto
to


lim
=
Xto
1
2to
-------
X t  td
to
–
to

=
Xto
E Xto


E
1
2to
-------
X t  td
to
–
to

1
2to
-------
E X t 

 td
to
–
to

1
2to
-------
X td
to
–
to

X
=
=
=
=
Xto
Xto
X
to


2 We exchange the order of expectation and integration since they are both linear operators.


Random Processes    355
www.Academicpress.com
mean square sense) if the variance of 
 goes to zero in the limit as 
.  To see under 
what conditions this occurs, we calculate the variance.
.
(8.21)
Since the random process 
 is WSS, the autocovariance is only a function of 
.  
As a result, the double integral can be converted to a single integral.3  The result is
.
(8.22)
Thus, the random process will be ergodic in the mean if this expression goes to zero in the 
limit as 
.  This proves the following theorem.
Theorem 8.1:  A continuous WSS random process 
 will be ergodic in the mean if
.
(8.23)
One implication of Theorem 8.1 is that if 
 tends to a constant as 
, then that 
constant must be zero for the process to be ergodic.  Stated in terms of the autocorrelation 
function, a sufficient condition for a process to be ergodic in the mean is that
.
(8.24)
Similar relationships can be developed to determine when a process is ergodic in the 
autocorrelation, but that topic is beyond the intended scope of this text.
Example 8.22:
Consider the process 
 of Example 8.19.  It is easily found that the 
autocovariance function of this process is 
 for all .  Plugging this into the 
left-hand side of Equation (8.23) results in
.
Xto
to


Var Xto


E
Xto
X
–

2


E
1
2to
-------
X t 
X
–

 td
to
–
to

#
$
%
&
'
( 2
=
=
1
4to
2
--------
E
X t 
X
–

 X s 
X
–



 td
to
–
to

s
d
to
–
to

1
4to
2
--------
CXX t s


 td
to
–
to

s
d
to
–
to

=
=
X t 
	
t
s
–
=
Var Xto


1
2to
-------
1
	
2to
-------
–
#
$
'
( CXX 	
  	
d
2to
–
2to

1
to
----
1
	
2to
-------
–
#
$
'
( CXX 	
  	
d
0
2to

=
=
to


X t 
1
to
----
1
	
2to
-------
–
#
$
'
( CXX 	
  	
d
0
2to

to


lim
0
=
CXX 	
 
	


RXX 	
 
	


lim
X
2
=
X t 
A
=
CXX 	
 
A
2
=
	
1
to
----
1
	
2to
-------
–
#
$
'
( CXX 	
  	
d
0
2to

to


lim
A
2
to
-------
1
	
2to
-------
–
#
$
'
( 	
d
0
2to

to


lim
A
2
to
-------to
to


lim
A
2
=
=
=

3 The procedure for doing this conversion will be described in detail in Chapter 10, where a similar inte-
gral will be encountered in the proof of the Wiener-Khintchine-Einstein theorem.
(Continued)

356    Chapter 8 
www.Academicpress.com
Since this limit is not equal to zero, the process clearly does not meet the condition for 
ergodicity.  Next, consider the sinusoidal process of Example 8.20.  In that case, the 
autocovariance function is 
 and the left hand side of Equation 
(8.23) produces
.
So, even though this autocorrelation function does not approach zero in the limit as 
 (it oscillates), it still meets the condition for ergodicity.
8.4  Properties of the Autocorrelation Function
Since the autocorrelation function, along with the mean, is considered to be a principal 
statistical descriptor of a WSS random process, we will now consider some properties of the 
autocorrelation function. It should quickly become apparent that not just any function of  can 
be a valid autocorrelation function.
Property 8.4.1:  The autocorrelation function evaluated at 
, 
, is the 
average normalized power in the random process, 
.
To clarify this, note that 
.  Now suppose the random process 
 was a 
voltage measured at some point in a system.  For a particular realization, 
, the 
instantaneous power would be 
, where  is the impedance in Ohms (
).  
The average power (averaged over all realizations in the ensemble) would then be 
.  If, on the other hand, 
 were a current rather than a 
voltage, then the average power would be 
.  From a systems level, it is often 
desirable not to concern ourselves with whether a signal is a voltage or a current.  
Accordingly, it is common to speak of a normalized power, which is the power measured 
using a 
 impedance.  With 
, the two expression for average power are the same and 
equal to the autocorrelation function evaluated at zero.
Property 8.4.2:  The autocorrelation function of a WSS random process is an even 
function; that is, 
.  
This property can easily be established from the definition of autocorrelation.  Note that 
.  Since 
 is WSS, this expression is the same for any 
value of .  In particular, replace  in the previous expression with 
 so that 
.  As a result of this property, any function of  
which is not even cannot be a valid autocorrelation function.
CXX 	
 
a2 2




o	


cos
=
1
to
----
1
	
2to
-------
–
#
$
'
( CXX 	
  	
d
0
2to

to


lim
a2
2to
-------
1
	
2to
-------
–
#
$
'
(

o	

 	
d
cos
0
2to

to


lim
a2 1
2
oto


cos
–
2
oto

2
-------------------------------------
#
$
%
&
'
(
to


lim
0
=
=
=
	
0

	
	
0
=
RXX 0
 
X t 
RXX 0
 
E X2 t 


=
X t 
x t 
p t 
x2 t  r

=
r
)
Pavg
E X2 t 

 r

RXX 0
  r

=
=
X t 
Pavg
RXX 0
 r
=
1)
r
1
=
RXX 	
 
RXX
	
–


=
RXX
	
–


E X t X t
	
–




=
X t 
t
t
t
	
+
RXX
	
–


E X t
	
+

X t 


RXX 	
 
=
=
	


Random Processes    357
www.Academicpress.com
Property 8.4.3:  The autocorrelation function of a WSS random process is maximum 
at the origin; that is, 
 for all .
This property is established using the fact that for any two random variables, 
 and 
, 
.
(8.25)
This fact was previously demonstrated in the proof of Theorem 5.4.  Letting 
 and 
 results in
.
(8.26)
Taking square roots of both sides results in Property 8.4.3.  
Property 8.4.4:  If 
 is ergodic and has no periodic components, then 
.
Property 8.4.5:  If 
 has a periodic component, then 
 will have a periodic 
component with the same period.
From these properties, it is seen that an autocorrelation function can oscillate, can decay 
slowly or rapidly, and can have a non-zero constant component.  As the name implies, the 
autocorrelation function is intended to measure the extent of correlation of samples of a 
random process as a function of how far apart the samples are taken.  
8.5  Gaussian Random Processes
One of the most important classes of random processes is the Gaussian random process which 
is defined as follows.
Definition 8.9:  A random process, 
, for which any  samples, 
, 
, . . ., 
, taken at arbitrary points in time 
, 
, . . ., 
, form a 
set of jointly Gaussian random variables for any 
 is a Gaussian 
random process.
In vector notation, the vector of  samples, 
, will have a joint PDF 
given by
.
(8.27)
As with any joint Gaussian PDF, all that is needed to specify the PDF is the mean vector and 
the covariance matrix.  When the vector of random variables consists of samples of a random 
RXX 	
 
RXX 0
 
*
	
X
Y
E XY



2
E X2

E Y2


*
X
X t 
=
Y
X t
	
+


=
RXX
2
	
 
E X t X t
	
+




+
,2
=
E X2 t 

E X2 t
	
+




*
RXX
2
0
 
=
X t 
RXX 	
 
	


lim
X
2
=
X t 
RXX 	
 
X t 
n
X1
X t1


=
X2
X t2


=
Xn
X tn


=
t1 t2
tn
n
1 2 3 
  
=
n
X
X1 X2  Xn




T
=
fX x
 
1
2

ndet CXX


------------------------------------------
1
2--- x
X
–

TCXX
1
–
x
X
–


–
#
$
'
(
exp
=

358    Chapter 8 
www.Academicpress.com
process, to specify the mean vector, all that is needed is the mean function of the random 
process, 
, since that will give the mean for any sample time.  Similarly, all that is needed 
to specify the elements of the covariance matrix, 
, would be the 
autocovariance function of the random process, 
, or equivalently the 
autocorrelation function, 
, together with the mean function.  Therefore, the mean 
and autocorrelation functions provide sufficient information to specify the joint PDF for any 
number of samples of a Gaussian random process.  Note that since any th order PDF is 
completely specified by 
 and 
, if a Gaussian random process is WSS, then 
the mean and autocorrelation functions will be invariant to a time shift and therefore any PDF 
will be invariant to a time shift.  Hence, any WSS Gaussian random process is also stationary 
in the strict sense.
Example 8.23:
Consider the random process 
, where  and  are 
independent, zero-mean Gaussian random variables with equal variances of 
.  This 
random process is formed as a linear combination of two Gaussian random variables, 
and therefore samples of this process are also Gaussian random variables.  The mean 
and autocorrelation functions of this process are found as
,
.
Note that this process is WSS since the mean is constant and the autocorrelation 
function depends only on the time difference.  Since the process is zero-mean, the first-
order PDF is that of a zero-mean Gaussian random variable:
.
This PDF is independent of time as would be expected for a stationary random process.  
Now consider the joint PDF of two samples, 
 and 
.  Since the 
process is zero-mean, the mean vector is simply the all-zeros vector.  The covariance 
matrix is then of the form
.
X t 
Ci j
Cov X ti
  X tj
 



=
CXX t1 t2



RXX t1 t2



n
X t 
RXX t1 t2



X t 
A

ot


cos
B

ot


sin
+
=
A
B
2
X t 
E A

ot


cos
B

ot


sin
+


E A
 

ot


cos
E B
 

ot


sin
+
0
=
=
=
RXX t1 t2



E
A

ot1


cos
B

ot1


sin
+

 A

ot2


cos
B

ot2


sin
+




=
E A2



ot1



ot2


cos
cos
E B2



ot1



ot2


sin
sin
E AB



ot1



ot2


sin
cos

ot1



ot2


cos
sin
+
+
,
+
+
=
2

ot1



ot2


cos
cos

ot1



ot2


sin
sin
+
+
,
2

o t2
t1
–




cos
=
=
fX x;t


1
22
-----------------
x2
22
---------
–
#
$
'
(
exp
=
X1
X t 
=
X2
X t
	
+


=
CXX
RXX 0
  RXX 	
 
RXX 	
  RXX 0
 
2
1

o	


cos

o	


cos
1
=
=


Random Processes    359
www.Academicpress.com
The joint PDF of the two samples would then be
.
Note once again that this joint PDF is dependent only on time difference, , and not on 
absolute time .  Higher order joint PDFs could be worked out in a similar manner.
Suppose we create a random process that jumps by an amount of 
 units every 
 seconds.  
One possible realization of such a random process is illustrated in Figure 8.9.  This proces is 
often referred to as a random walk.  Mathematically, we can express this process as
,
(8.28)
where the 
 are IID Bernoulli random variables with
 
and 
.  Note that the mean of this process is
.
(8.29)
Next, consider a limiting form of the random walk where we let both the time between jumps, 
, and the size of the jumps, , simultaneously go to zero.  Then the process consists of an 
infinite number of infinitesimal jumps.  As 
, the number of terms in the series in 
Equation (8.28) becomes infinite, and by virtue of the central limit theorem, 
 will follow a 
Gaussian distribution.  Thus, we have created a zero-mean Gaussian random process.
Since the process is Gaussain, to complete the statistical characterization of this process, we 
merely need to find the covariance (or correlation) function.  Assuming 
, 
.
(8.30)
fX1 X2

x1 x2

;t t
	
+



1
22

o	


sin
---------------------------------------
x1
2
2x1x2

o	


cos
–
x2
2
+
22sin2 
o	


-------------------------------------------------------------
–
#
$
%
&
'
(
exp
=
	
t
x(t)
t
Δ
2 t
Δ
3 t
Δ
d
2d
t
Figure 8.9  
One possible realization of a random walk process.
-
.
t
/
X t 
-
Wk
k
1
=
n

=
Wk
Pr Wk=1


Pr Wk= -1


1 2

=
=
n
t
t
/

=
X t 
E X t 


E -
Wk
k
1
=
n

-
E Wk


k
1
=
n

0
=
=
=
=
t
/
-
t
0

/
X t 
t2
t
! 1
RX X

t1 t2



E X t1

X t2




E X t1

 X t1


X t2


X t1


–


+




=
=
E X2 t1




E X t1

 X t2


X t1


–




+
=


360    Chapter 8 
www.Academicpress.com
To simplify the second term in the preceding equation, note that 
 represents the 
accumulation of jumps in the time interval 
 while 
 represents the 
accumulation of jumps in the time interval 
.  Due to the manner in which the process is 
constructed, these terms are independent, thus
.
(8.31)
Therefore, 
  for  
. Similarly, if 
, we would find that 
.  From Equation (8.28), the variance of the process works out to be
.
(8.32)
If we let 
 and 
 in such a way that 
 for some constant 
, then
,
(8.33)
and the covariance function is
.
(8.34)
In principle, knowing the mean function and the covariance function of this Gaussian random 
process will allow us to specify the joint PDF of any number of samples.
This mathematical process is known as a Wiener process and finds applications in many 
different fields.  It is perhaps most famously used to model Brownian motion which is the 
random fluctuation of minute particles suspended in fluids due to impact with neighboring 
atomic particles.  It has also been used in the fields of finance, quantum mechanics, physical 
cosmology, and as will be seen in future chapters; in electrical engineering, the Weiner 
process is closely related to the commonly used white noise model of noise in electronic 
equipment.
8.6  Poisson Processes
Consider a process 
 which counts the number of occurrences of some event in the time 
interval 
.  The event might be the telephone calls arriving at a certain switch in a public 
telephone network, customers entering a certain store, or the birth of a certain species of 
animal under study.  Since the random process is discrete (in amplitude), we will describe it in 
terms of a probability mass function, 
.  Each occurrence of the event 
being counted is referred to as an arrival or a point.  These types of processes are referred to as 
counting processes or birth processes.  Suppose this random process has the following general 
properties:
X t1


0 t1


X t2


X t1


–
t1 t2


E X t1

 X t2


X t1


–




E X t1



E X t2


X t1


–


0
=
=
RX X

t1 t2



E X2 t1




=
t2
t
 1
t1
t
 2
RX X

t1 t2



E X2 t2




=
E X2 t 


Var X t 


2
Var Wk


k
1
=
n
	
2n
2t
t

-------
=
=
=
=

0

t
0



 t

=

E X2 t 


t
=
CX X

t1 t2



RX X

t1 t2



min t1 t2



=
=
X t 
0 t


PX i;t


Pr X t  =i


=

Random Processes    361
www.Academicpress.com
•
Independent Increments  The number of arrivals in two non-overlapping intervals are 
independent.  That is, for two intervals 
 and 
 such that 
, 
the number of arrivals in 
 is statistically independent of the number of arrivals in 
.
•
Stationary Increments  The number of arrivals in an interval 
 depends only on the 
length of the interval  and not on where the interval occurs, .  
•
Distribution of Infinitesimal Increments  For an interval of infinitesimal length, 
, the probability of a single arrival is proportional to 
, and the probability of 
having more than one arrival in the interval is negligible compared to 
.  
Mathematically, we say that for some arbitrary constant 
:4
,
(8.35)
,
(8.36)
.
(8.37)
Surprisingly enough, these rather general properties are enough to exactly specify the 
distribution of the counting process as shown next.
Consider the PMF of the counting process at time 
.  In particular, consider finding the 
probability of the event 
.
.
(8.38)
Subtracting 
 from both sides and dividing by 
 results in
.
(8.39)
Passing to the limit as 
 gives the first-order differential equation
.
(8.40)
t1 t2


t3 t4


t1
t2
t3
t4



t1 t2


t3 t4


t t

+




t
t t
t

+



t

t


Pr no arrivals in t t
t

+





1
 t

–
o
t



+
=
Pr one arrival in t t
t

+





 t

o
t



+
=
Pr more than one arrival in t t
t

+





o
t



=
t
t

+
X t
t

+


0
=


PX 0;t
t

+


Pr no arrivals in 0 t
t

+





=
Pr no arrivals in 0 t



Pr no arrivals in t t
t

+





=
PX 0;t

 1
 t

–
o
t



+


=
PX 0;t


t

PX 0;t
t

+


PX 0;t


–
t

--------------------------------------------------------
PX 0;t


–
o
t



t

-------------PX 0;t


+
=
t
0


d
dt
-----PX 0;t


PX 0;t


–
=
4 The notation 
 refers to an arbitrary function of  which goes to zero as 
 in a faster than lin-
ear fashion.  That is, some function 
 is said to be 
 if 
. 
o x
 
x
x
0

g x
 
o x
 
g x
 
x
----------
x
0

lim
0
=

362    Chapter 8 
www.Academicpress.com
The solution to this equation is of the general form
(8.41)
for some constant .  The constant  is found to be equal to unity by using the fact that at time 
zero, the number of arrivals must be zero.  That is 
.  Therefore,
.
(8.42)
The rest of the PMF for the random process 
 can be specified in a similar manner.  We 
find the probability of the general event 
 for some integer 
.  
 
(8.43)
As before, subtracting 
 from both sides and dividing by 
 results in
.
(8.44)
Passing to the limit as 
 gives another first-order differential equation,
.
(8.45)
It is fairly straightforward to solve this set of differential equations. For example, for 
 
we have
,
(8.46)
together with the initial condition that 
. The solution to this equation can be 
shown to be 
.
(8.47)
It is left as an exercise for the reader (see Exercise 8.32) to verify that the general solution to 
the family of differential equations specified in (8.45) is
PX 0;t


c
t
–


exp
u t 
=
c
c
PX 0;0


1
=
PX 0;t


t
–


exp
u t 
=
X t 
X t
t

+


i
=


i
0

PX i;t
t

+


Pr i arrivals in 0 t



Pr no arrivals in t t
t

+





Pr i
1
–
 arrivals in 0 t



Pr one arrival in t t
t

+





Pr less than i
1
–
 arrivals in 0 t



Pr more than one arrival in t t
t

+





+
+
=
PX i;t

 1
 t

–
o
t



+


PX i
1
–
;t

  t

o
t



+


PX i;t

o
t



j
0
=
i
2
–
	
+
+
=
PX i;t


t

PX i;t
t

+


PX i;t


–
t

-----------------------------------------------------
PX i;t


–
PX i
1
–
;t


PX i;t

o
t



t

-------------
j
0
=
i
	
+
+
=
t
0


d
dt
-----PX i;t
(
)
PX i;t


+
PX i
1
–
;t


=
i
1
=
d
dt
-----PX 1;t
(
)
PX 1;t


+
PX 0;t


e t
–
u t 
=
=
PX 1;0


0
=
PX 1;t


te t
–
u t 
=

Random Processes    363
www.Academicpress.com
.
(8.48)
Starting with the three mild assumptions made about the nature of this counting process at 
the start of this section, we have demonstrated that 
 follows a Poisson distribution, 
hence this process is referred to as a Poisson counting process.  Starting with the PMF for 
the Poisson counting process specified in Equation (8.48), one can easily find the mean and 
autocorrelation functions for this process.  First, the mean function is given by
.
(8.49)
In other words, the average number of arrivals in the interval 
 is 
.  This gives the 
parameter 
 the physical interpretation of the average rate of arrivals, or as it is more 
commonly referred to the arrival rate of the Poisson process.  Another observation we can 
make from the mean process is that the Poisson counting process is not stationary.  
The autocorrelation function can be calculated as follows:
.
(8.50)
To simplify the second expression, we use the independent increments property of the Poisson 
counting process.  Assuming that 
, then 
 represents the number of arrivals in the 
interval 
, while 
 is the number of arrivals in the interval 
.  Since 
these two intervals are non-overlapping, the number of arrivals in the two intervals are 
independent.  Therefore,
.
(8.51)
This can be written more concisely in terms of the autocovariance function,
.
(8.52)
If 
, then the roles of 
 and 
 need to be reversed.  In general for the Poisson counting 
process, we have
.
(8.53)
Another feature that can be extracted from the PMF of the Poisson counting process is 
the distribution of the inter-arrival time.  That is, let 
 be the time at which the first 
arrival occurs.  We seek the distribution of the random variable 
.  The CDF of 
 can be 
found as
PX i;t


t

i
i!
-----------
=
e t
–
u t 
X t 
X t 
E X t 


i t

i
i!
-----------e t
–
u t 
i
0
=

	
tu t 
=
=
=
0 t


t

RXX t1 t2



E X t1

X t2




E X t1

 X t1


X t2


X t1


–


+




=
=
E X2 t1




E X t1

 X t2


X t1


–




+
=
t1
t2

X t1


0 t1


X t2


X t1


–
t1 t2


RXX t1 t2



E X2 t1




E X t1



E X t2


X t1


–


+
Var X t1




X t1

X t2


+
t1
2t1t2
+
=
=
=
CXX t1 t2



Var X t1




t1
=
=
t2
t1

t1
t2
CXX t1 t2



min t1 t2



=
T
T
T

364    Chapter 8 
www.Academicpress.com
.
(8.54)
Therefore, it follows that the arrival time is an exponential random variable with a mean value 
of 
.  The PDF of 
 is 
.
(8.55)
We could get the same result starting from any point in time.  That is, we do not need to measure 
the time to the next arrival starting from time zero.  Picking any arbitrary point in time 
, we 
could define 
 to be the time until the first arrival after time 
.  Using the same reasoning as 
above we would arrive at the same exponential distribution.  If we pick 
 to be the time of a 
specific arrival, and then define 
 to be the time to the next arrival, then 
 is interpreted as an 
inter-arrival time.  Hence, we conclude that the time between successive arrivals in the Poisson 
counting process follows an exponential distribution with a mean of 
.  
The Poisson counting process can be represented as a sum of randomly shifted unit step 
functions.  That  is, let 
 be the time of the th arrival.  Then,
.
(8.56)
The random variables, 
, are sometimes referred to as points of the Poisson process.  Many 
other related random processes can be constructed by replacing the unit step functions with 
alternative functions.  For example, if the step function is replaced by a delta function, the 
Poisson impulse process results, which is expressed as
.
(8.57)
A sample realization of this process is shown in Figure 8.10.  
FT t 
Pr T
t



Pr at least one arrival in 0 t




=
=
1
Pr no arrivals in 0 t




–
1
e t
–
–

u t 
=
=
E T
 
1 

=
T
fT t 
e t
–
u t 
=
to
T
to
to
T
T
1 

Si
i
X t 
u t
Si
–


i
1
=

	
=
Si
X t 
 t
Si
–


i
1
=

	
=
x(t)
s1
s2 s3
s4
s5
s6
t
Figure 8.10  
A sample realization of the Poisson impulse process.

Random Processes    365
www.Academicpress.com
8.7  Engineering Application—Shot Noise in a p–n Junction Diode
Both the Poisson counting process and the Poisson impulse process can be viewed as 
special cases of a general class of processes referred to as shot noise processes.  Given an 
arbitrary waveform 
 and a set of Poisson points, 
, the shot noise process is 
constructed as
.
(8.58)
As an example of the physical origin of such a process, consider the operation of a p–n 
junction diode.  When a forward bias voltage is applied to the junction, a current is 
generated.  This current is not constant, but actually consists of discrete holes from the p 
region and electrons from the n region which have sufficient energy to overcome the 
potential barrier at the junction.  Carriers do not cross the junction in a steady deterministic 
fashion; rather, each passage is a random event which might be modeled as a Poisson point 
process.  The arrival rate of that Poisson process would be dependent on the bias voltage 
across the junction.  As a carrier crosses the junction, it produces a current pulse, which we 
represent with some pulse shape 
, such that the total area under 
 is equal to the 
charge in an electron, .  Thus, the total current produced by the p–n junction diode can be 
modeled as a shot noise process.
To start with, we compute the mean function of a shot noise process.  However, upon 
examining Equation (8.58), it is not immediately obvious how to take the expected value for 
an arbitrary pulse shape 
.  There are several ways to achieve the goal.  One approach is to 
divide the time axis into infinitesimal intervals of length 
.  Then, define a sequence of 
Bernoulli random variables 
 such that 
 if a point occurred within the interval 
 and 
 if no points occurred in the same interval.  Since the intervals 
are taken to be infinitesimal, the probability of having more than one point in a single interval 
is negligible.  Furthermore, from the initial assumptions that led to the Poisson process, the 
distribution of the 
 is given by
 and 
.
(8.59)
The shot noise process can be approximated by
.
(8.60)
In the limit as 
, the approximation becomes exact.  Using this alternative 
representation of the shot noise process, calculation of the mean function is straightforward.
h t 
Si
X t 
h t
Si
–


i
1
=

	
=
h t 
h t 
q
h t 
t

Vn
Vn
1
=
n t

n
1
+

 t

 


Vn
0
=
Vn
Pr Vn=1


 t

=
Pr Vn=0


1
 t

–
=
X t 
Vnh t
n t

–


n
0
=

	

t
0



366    Chapter 8 
www.Academicpress.com
.
(8.61)
Note that in this calculation, the fact that 
 was used.   Passing to the limit as 
 results in
.
(8.62)
Strictly speaking, the mean function of the shot noise process is not a constant, and therefore 
the process is not stationary.  However, in practice, the current pulse will be time limited.  
Suppose the current pulse, 
, has a time duration of 
.  That is, for 
, 
 is 
essentially equal to zero.  For the example of the p–n junction diode, the time duration of the 
current pulse is the time it takes the carrier to pass through the depletion region.  For most 
devices, this number may be a small fraction of a nanosecond.  Then for any 
, 
.
(8.63)
For example, using the fact that the charge on an electron is 
, if carriers made 
transitions at an average rate of 
 per second (1 per femtosecond), then the average current 
produced in the diode would be 
.  
Next, we seek the autocorrelation (or autocovariance) function of the shot noise process.  The 
same procedure used to calculate the mean function can also be used here.  
(8.64)
E X t 


E Vn

h t
n t

–


n
0
=

	


h t
n t

–

 t

n
0
=

	
=
E Vn


 t

=
t
0


X t 

h t
u
–

 u
d
0



h v
  v
d
0
t

=
=
h t 
th
t
th

h t 
t
th

X t 

h v
  v
d
0


q
constant
=
=
=
1.6
10 19
–

C
1015
0.16 mA
RXX t t

+



E X t X t

+




E VnVm

h t
n t

–

h t

m t

–
+


m
0
=

	
n
0
=

	
=
=
E Vn
2

h t
n t

–

h t

n t

–
+


n
0
=

	
E Vn

h t
n t

–


E Vm

h t

m t

–
+


m
n


	
n
0
=

	
+
=

h t
n t

–

h t

n t

–
+

 t

n
0
=

	
2
h t
n t

–

 t
h t

m t

–
+

 t

m
n


	

n
0
=

	
+
=
h t
n t

–

h t

n t

–
+

  t

 t


2
–


n
0
=

	
2
h t
n t

–

 t
h t

m t

–
+

 t

m
0
=

	

n
0
=

	
+
=

Random Processes    367
www.Academicpress.com
Passing to the limit as 
, we note that the term involving 
 is negligible 
compared to 
.  The resulting limit then takes the form
.
(8.65)
Note that the last term (involving the product of integrals) is just the product of the mean 
function evaluated at time  and the mean function evaluated at time 
.  Thus, we have,
,
(8.66)
or equivalently, in terms of the autocovariance function, 
.
(8.67)
As with the mean function, it is seen that the autocovariance function is a function of not only 
 but also .  Again, for sufficiently large , the upper limit in the preceding integral will be 
much longer than the time duration of the pulse, 
.  Hence, for 
,
,
(8.68)
or
.
(8.69)
We say that the shot noise process is asymptotically WSS.  That is, after waiting a sufficiently 
long period of time, the mean and autocorrelation functions will be invariant to time shifts.  In 
this case, the phrase “sufficiently long time” may mean a small fraction of a nanosecond!  So 
for all practical purposes, the process is WSS.  Also, it is noted that the width of the 
autocovariance function is 
.  That is, if 
 is time limited to a duration of 
, then 
 
is zero for 
.  This relationship is illustrated in Figure 8.11, assuming 
 is a square 
pulse, and implies that any samples of the shot noise process that are separated by more than 
 will be uncorrelated.  
Finally, in order to characterize the PDF of the shot noise process, consider the approximation 
to the shot noise process given in Equation (8.60).  At any fixed point in time, the process 
t
0


 t


2
 t

RXX t t

+




h t
u
–

h t

u
–
+


0


du
2
h t
u
–

 u
h t

u
–
+

 u
d
0


d
0


+
=

h v
 h v

+


0
t

dv
2
h v
  v
h v
  v
d
0
t

+

d
0
t

+
=
t
t

+
RXX t t

+




h v
 h v

+


0
t

dv
X t X t

+


+
=
CXX t t

+




h v
 h v

+


0
t

dv
=

t
t
h t 
t
th

CXX t t

+



CXX 
 

h v
 h v

+


0


dv
=
=
RXX t t

+



RXX 
 

h v
 h v

+


0


dv
X
2
+
=
=
th
h t 
th
CXX 
 

th

h t 
th

368    Chapter 8 
www.Academicpress.com
 can be viewed as the linear combination of a large number of independent Bernoulli 
random variables.  By virtue of the central limit theorem, this sum can be very well 
approximated by a Gaussian random variable.  Since the shot noise process is WSS (at least in 
the asymptotic sense) and is a Gaussian random process, then the process is also stationary in 
the strict sense.  Also, samples spaced by more than 
 are independent.
Example 8.24:
Consider a shot noise process in a p–n junction diode where the pulse shape is square 
as illustrated in Figure 8.11.  The mean current is 
, which is presumably the 
desired signal we are trying to measure.  The fluctuation of the shot noise process 
about the mean, we view as the unwanted disturbance, or noise.  It would be 
interesting to measure the ratio of the power in the desired part of the signal to the 
power in the noise part of the signal.  The desired part has a time-average power of 
, while the noise part has a power of 
.  The signal-to-
noise ratio (SNR) is then
.
We write this in a slightly different form,
.
For example, if the pulse duration were 
, the SNR as it depends on the 
strength of the desired part of the signal would be as illustrated in Figure 8.12.  It is 
noted that the SNR is fairly strong until we try to measure signals which are below a 
microamp .  
X t 
th
X
q
=
X
2
q

2
=
X
2
CXX 0
 
q2 th

=
=
SNR
X
2
X
2
-------
q

2
q2 th

-----------------
th
=
=
=
SNR
th
q
th
q----
 
 
x
th
q----
 
 
=
=
=
th
10picoseconds
=
th
q/th
h(t)
t
CXX(t)
t
th
-th
lq2/ th
(a)
(b)
Figure 8.11 
 (a) A square current pulse and (b) the corresponding autocovariance function.


Random Processes    369
www.Academicpress.com
In Chapter 10, we will view random processes in the frequency domain.  Using the 
frequency domain tools we will develop in that chapter, it will become apparent that the 
noise power in the shot noise process is distributed over a very wide bandwidth (about 100 
GHz for the previous example).  Typically, our measuring equipment would not respond to 
that wide of a frequency range, and so the amount of noise power we actually see would be 
much less than that presented in Example 8.24 and would be limited by the bandwidth of our 
equipment.  
Example 8.25:
In this example, we provide some MATLAB code to generate a sample 
realization of a shot noise process.  We chose to use a current pulse shape 
of the form, 
, but the reader could easily modify this to use 
other pulse shapes as well.  A typical realization is shown in Figure 8.13.  
Note that after a short initial transient period, the process settles into a 
steady-state behavior.
10−10
10−8
10−6
10−4
10−2
100
102
−40
−20
0
20
40
60
80
100
mX (Amps)
SNR (dB)
Figure 8.12  
Signal-to-noise ratio in a shot noise process for an example p–n junction diode.
h t 
t
t2
–


exp
=

(Continued)


370    Chapter 8 
www.Academicpress.com
dt=0.001;
% time sample interval
t=[0:dt:20];
% time axis
v=rand(size(t))<0.2;
% impulse process
h=t.*exp(-t.^2);
% pulse shape
x=conv(v,h);
% shot noise process
plot(t,x(1:length(t)))
% plot results
xlabel('time, t'); ylabel('X(t)')
0
2
4
6
8
10
12
14
16
18
20
0
20
40
60
80
100
120
Time, t
X(t)
Figure 8.13  
A typical realization of a shot noise process.



371
CHAPTER 8
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 8.2:  Mathematical Tools for Studying Random Processes
8.1
A discrete random process, 
, is generated by repeated tosses of a coin. Let the 
occurrence of a head be denoted by 1 and that of a tail by 1. A new discrete random 
process is generated by 
 for 
 and 
 
for  odd (either positive or negative). Find the autocorrelation function for 
.
8.2
Let 
 be an IID sequence of zero-mean Gaussian random variables with variance 
.  
Define a discrete-time random process 
, 
, 
where 
 and  is a constant.  
(a)
Find the mean function, 
.
(b)
Find the autocorrelation function, 
.
8.3
Let 
, 
, be a sequence of IID random variables with mean 
 and 
variance 
.  Form the sample mean process
,  
.
(a)
Find the mean function, 
.
(b)
Find the autocorrelation function, 
.
8.4
Define a random process according to
,  
,
where 
 and 
 is a sequence of IID Bernoulli random variables with 
 and 
.
(a)
Find the PMF, 
.
(b)
Find the joint PMF, 
.
(c)
Find the mean function, 
.
(d)
Find the autocorrelation function, 
.
X n
 
Y 2n


X n
 
=
n
0
1

2





=
Y n
 
X n
1
+


=
n
Y n
 
Wn
W
2
X n
 
pX n
1
–


Wn
+
=
n
1 2 3 
  
=
X 0
 
W0
=
p
	X n
 
RX X

n1 n2



Xk k
1 2 3 
  
=
	X
X
2
S n
 
1
n---
Xk
k
1
=
n

=
n
1 2 3 
  
=
	S n
 
E S n
 


=
RS S

k n



E S k
 S n
 


=
X n
 
X n
1
–


Wn
+
=
n
1 2 3 
  
=
X 0
 
0
=
Wn
Pr Wn=1


p
=
Pr Wn= 0


1
p
–
=
PX k n;


Pr X k
  = n


=
PX1 X2

k1 k2

 n1 n2

;


Pr X k1

= n1 X k2

= n2



=
	X n
 
E X n
 


=
RX X

k n



E X k
 X n
 


=

372    Chapter 8
www.Academicpress.com
8.5
Consider the random process defined in Example 8.5.  The PDF, 
, and the mean 
function, 
, were found in Example 8.7. 
(a)
Find the joint PDF, 
.
(b)
Find the autocorrelation function, 
.
Section 8.3:  Stationary and Ergodic Random Processes
8.6
A random process 
 consists of three-member functions: 
, 
, 
and 
.  Each member function occurs with equal probability. 
(a)
Find the mean function, 
.
(b)
Find the autocorrelation function, 
.
(c)
Is the process WSS?  Is it stationary in the strict sense?
8.7
A random process X(t) has the following member functions: 
, 
, 
, 
, 
.  Each member function occurs with equal probability.
(a)
Find the mean function, 
.
(b)
Find the autocorrelation function, 
.
(c)
Is the process WSS?  Is it stationary in the strict sense?
8.8
Let a discrete random process 
 be generated by repeated tosses of a fair die.  Let the 
values of the random process be equal to the results of each toss. 
(a)
Find the mean function, 
.
(b)
Find the autocorrelation function, 
.
(c)
Is the process WSS?  Is it stationary in the strict sense?
8.9
Let 
 be a wide sense stationary, discrete random process with autocorrelation 
function 
, and let  be a constant. 
(a)
Find the autocorrelation function for the discrete random process 
. 
(b)
Are 
 and 
 independent? Uncorrelated? Orthogonal?
8.10 A wide sense stationary, discrete random process, 
, has an autocorrelation function 
of 
. Find the expected value of 
, where 
 is an 
arbitrary integer.
8.11 A random process is given by 
, where 
 and 
 are 
independent zero-mean random variables.
(a)
Find the mean function, 
.
(b)
Find the autocorrelation function, 
.
(c)
Under what conditons (on the variances of 
 and 
) is 
 WSS?
fX x n;


	X n
 
fX1 X2

x1 x2

 n1 n2

;


RX X

k n



E X k
 X n
 


=
X t 
x1 t 
1
=
x2 t 
3
–
=
x3 t 
2t


sin
=
	X t 
RX X

t1 t2



x1 t 
2
t 
cos
–
=
x2 t 
2
t 
sin
–
=
x3 t 
2
t 
cos
t 
sin
+


=
x4 t 
t 
cos
t 
sin
–


=
x5 t 
t 
sin
t 
cos
–


=
	X t 
RX X

t1 t2



X n
 
	X n
 
RX X

k1 k2



X n
 
RXX n
 
c
Y n
 
X n
 
c
+
=
X n
 
Y n
 
X n
 
RXX k
 
Y n
 
X n
m
+


X n
m
–


–

2
=
m
X t 
A
t


cos
B
t


sin
+
=
A
B
	X t 
RX X

t1 t2



A
B
X t 

Exercises    373
www.Academicpress.com
8.12 Show by example that the random process 
 may be a wide sense 
stationary process even though the random processes 
 and 
 are not. Hint: Let 
 and 
 be independent, wide sense stationary random processes with zero-means 
and identical autocorrelation functions. Then let 
 and 
. Show that 
 and 
 are not wide sense stationary. Then show 
that 
 is wide sense stationary.
8.13 Let 
, where 
 is a wide sense stationary random process 
independent of 
 and let 
 be a random variable distributed uniformly over 
. 
Define a related process 
.  Show that 
 and 
 
are stationary in the wide sense but that the cross-correlation 
, between 
 and 
, is not a function of  only and, therefore, 
 is not 
stationary in the wide sense.
8.14 Let 
 be a modified version  of the random telegraph process. The process switches 
between the two states 
 and 
 with the time between switches 
following exponential distributions, 
.  Also, the starting state is 
determined by flipping a biased coin so that 
 and 
.
(a)
Find 
 and 
.
(b)
Find the mean function, 
.
(c)
Find the autocorrelation function, 
.
(d)
Is this process WSS?
8.15 Let 
 be a periodic 
square wave as illustrated 
in the accompanying figure.  
Suppose a random process 
is created according to 
, where 
 
is a random variable 
uniformly distributed over 
.  
(a)
Find the probability mass function of 
.
(b)
Find the mean function, 
.
(c)
Find the autocorrelation function, 
.
(d)
Is this process WSS?
Z t 
X t 
Y t 
+
=
X t 
Y t 
A t 
B t 
X t 
A t 
t 
sin
=
Y t 
B t 
t 
cos
=
X t 
Y t 
Z t 
X t 
A t 
0t

+


cos
=
A t 


0 2


Y t 
A t 
0
1
+

t

+


cos
=
X t 
Y t 
RXY t t

+



X t 
Y t 

Z t 
X t 
Y t 
+
=
X t 
X t 
1
=
X t 
1
–
=
fT s 

s
–


exp
u s 
=
Pr X 0
  = 1


p
=
Pr X 0
 = 1
–


1
p
–
=
Pr X t  = 1


Pr X t = 1
–


	X t 
RX X

t1 t2



. . .
. . .
. . .
s(t)
t
1
1
−1
2
s t 
X t 
s t
T
–


=
T
0 1



X t 
	X t 
RX X

t1 t2




374    Chapter 8
www.Academicpress.com
8.16 Let 
 be a periodic 
triangle wave as illustrated 
in the accompanying figure.  
Suppose a random process 
is created according to 
, where 
 
is a random variable 
uniformly distributed over 
.  
(a)
Find the probability mass function of 
.
(b)
Find the mean function, 
.
(c)
Find the autocorrelation function, 
.
(d)
Is this process WSS?
8.17 Let a random process consist of a sequence of pulses with the following properties:  (i) 
the pulses are rectangular of equal duration, 
 (with no “dead” space in between pulses), 
(ii) the pulse amplitudes are equally likely to be 
, (iii) all pulses amplitudes are 
statistically independent, and (iv) the various members of the ensemble are not 
synchronized.
(a)
Find the mean function, 
.
(b)
Find the autocorrelation function, 
.
(c)
Is this process WSS?
8.18 A random process is defined by 
 where 
 is a random variable 
with PDF, 
. 
(a)
Find the PDF of 
 in terms of 
.
(b)
If 
 is an exponential random variable, with 
, find 
 and 
.  Is the process WSS?
8.19 Two zero-mean discrete-time random processes, 
 and 
, are statistically 
independent. Let a new random process be 
. Let the autocorrelation 
functions for 
 and 
 be
          
,  
.
Find 
. Plot all three autocorrelation functions (you may want to use MATLAB to 
help). 
8.20 Consider a discrete-time wide sense stationary random processes whose autocorrelation 
function is of the form 
       
, 
where 
.
Assume this process has zero-mean. Is the process ergodic in the mean?
. . .
. . .
s(t)
t
1
−1
1
2
s t 
X t 
s t
T
–


=
T
0 1



X t 
	X t 
RX X

t1 t2




1

	X t 
RX X

t1 t2



X t 
At
–


exp
u t 
=
A
fA a
 
X t 
fA a
 
A
fA a
 
e a
– u a
 
=
	X t 
RX X

t1 t2



X n
 
Y n
 
Z n
 
X n
 
Y n
 
+
=
X n
 
Y n
 
RXX k
 
1
2---
 
  k
=
RYY k
 
1
3---
 
  k
=
RZZ k
 
RXX k
 
a k
=
a
1


Exercises    375
www.Academicpress.com
8.21 Let 
 be a wide sense stationary random process that is ergodic in the mean and the 
autocorrelation. However, 
 is not zero-mean. Let 
, where 
 is a 
random variable independent of 
 and 
 is not zero-mean. Show that 
 is not 
ergodic in the mean or the autocorrelation.
8.22 Let 
 be a WSS random process with mean 
 and autocorrelation function 
.  Consider forming a new process according to
.
(a)
Find the mean function of 
.
(b)
Find the autocorrelation function of 
.  Is 
 WSS?
Section 8.4:  Properties of the Autocorrelation Function
8.23 Which of the following could be the correlation function of a stationary random process?
(a)
.
(d)
.
(b)
.
(e)
.
(c)
.
(f)
.
8.24 A stationary random process, 
, has a mean of 
 and correlation function, 
.  A new process is formed according to 
 for constants  and 
.  Find the correlation function 
 in terms of 
 and 
. 
8.25 An ergodic random process has a correlation function given by
.
What is the mean of this process?
8.26 For each of the functions in Exercise 8.23 that represents a valid correlation function, 
construct a random process that possesses that function as its correlation function.
Section 8.5:  Gaussian Random Processes
8.27 Let 
 and 
 be two jointly wide sense stationary Gaussian random processes with 
zero-means and with autocorrelation and cross-correlation functions denoted as 
, 
, and  
.  Determine the cross-correlation function between 
 and 
.
X t 
X t 
Y t 
CX t 
=
C
X t 
C
Y t 
X t 
	X
RXX 
 
Y t 
X t
to
+


X t 
–
to
-------------------------------------
=
Y t 
Y t 
Y t 
Ra 
 

–


exp
=
Rd 
 
sin 
 
=
Rb 
 

–

u 
 
exp
=
Re 
 

 
cos
=
Rc 
 



exp
=
Rf 
 
sinc 
 
=
X t 
	X
RX X


 
Y t 
aX t 
b
+
=
a
b
RY Y


 
	X
RX X


 
R 
 
3
2
+
2
22
+
------------------
=
X t 
Y t 
RXX 
 
RYY 
 
RXY 
 
X2 t 
Y2 t 

376    Chapter 8
www.Academicpress.com
8.28 If 
 is a wide sense stationary Gaussian random process, find the cross-correlation 
between 
 and 
 in terms of the autocorrelation function 
.
8.29 Suppose 
 is a Weiner process with diffusion parameter 
 as described in 
Section 8.5.  
(a)
Write the joint PDF of 
 and 
 for 
 by evaluating the 
covariance matrix of 
 and using the general form of the joint 
Gaussian PDF in Equation 6.22.
(b)
Evaluate the joint PDF of 
 and 
 for 
 indirectly by 
defining the related random variables 
 and 
.  Noting that 
 and 
 are independent and Gaussian, write down the joint PDF of 
 and 
 
and then form the joint PDF of 
 and 
 be performing the appropriate 
  
transformation.
(c)
Using the technique outlined in part (b), find the joint PDF of three samples of a 
Wiener process, 
, 
, and 
 for 
.
8.30 Let 
 be a wide sense stationary Gaussian random process and form a new process 
according to 
 where 
 and  are constants.
(a)
Is 
 wide sense stationary?
(b)
Is 
 a Gaussian random process?
8.31 Let 
 be a wide sense stationary Gaussian random process and form a new process 
according to 
 where 
 is a constant and 
 is a random 
variable uniformly distributed over 
 and independent of 
.
(a)
Is 
 wide sense stationary?
(b)
Is 
 a Gaussian random process?
Section 8.6:  Poisson Processes
8.32 Prove that the family of differential equations,
,
,  
,
leads to the Poisson distribution,
.
X t 
X t 
X3 t 
RXX 
 
X t 

1
=
X1
X t1


=
X2
X t2


=
t2
t1

X
X1 X2


T
=
X1
X t1


=
X2
X t2


=
t2
t1

Y1
X1
=
Y2
X2
X1
–
=
Y1
Y2
Y1
Y2
X1
X2
2
2

X1
X t1


=
X2
X t2


=
X3
X t3


=
t1
t2
t3


X t 
Y t 
X t 
t

+


cos
=


Y t 
Y t 
X t 
Y t 
X t 
t

+


cos
=


0 2


X t 
Y t 
Y t 
t
d
d PX 0;t


PX 0;t


+
0
=
t
d
d PX i;t


PX i;t


+
PX i
1
–
;t


=
i
1 2 3 
  
=
PX i;t


t

i
i!
-----------e t
–
=

Exercises    377
www.Academicpress.com
8.33 Consider a Poisson counting process with arrival rate 
.  
(a)
Suppose it is observed that there is exactly one arrival in the time interval 
.  
Find the PDF of that arrival time.
(b)
Now suppose there were exactly two arrivals in the time interval 
.  Find the 
joint PDF of those two arrival times.
(c)
Extend these results to an arbitrary number, , of arrivals? 
8.34 Let 
 be a Poisson counting process with arrival rate .  Find 
 
where 
 and 
.
8.35 Let 
, 
, be a sequence of independent Poisson counting processes 
with arrival rates, 
.  Show that the sum of all of these Poisson processes,
,
is itself a Poisson process.  What is the arrival rate of the sum process?
8.36 A workstation is used until it fails and then it is sent out for repair. The time between 
failures, or the length of time the workstation functions until it needs repair, is a random 
variable 
. Assume the times between failures, 
, 
, ..., 
 of the workstations 
available are independent random variables that are identically distributed. For 
, let 
the number of workstations that have failed be 
. 
(a)
If the time between failures of each workstation has an exponential PDF, then what 
type of process is 
?  
(b)
Assume that you have just purchased 10 new workstations and that each has a 
90-day warranty. If the mean time between failures (MTBF) is 250 days, what is the 
probability that at least one workstation will fail before the end of the warranty 
period?
8.37 Suppose the arrival of calls at a switchboard is modeled as a Poisson process with the 
rate of calls per minute being  
. 
(a)
What is the probability that the number of calls arriving in a 10-minute interval is 
less than 10? 
(b)
What is the probability that the number of calls arriving in a 10-minute interval is 
less than 10 if 
?
(c)
Assuming 
, what is the probability that one call arrives during the first 
10-minute interval and two calls arrive during the second 10-minute interval?
8.38 Let 
 be a Poisson counting process with arrival rate, 
.  We form two related 
counting processes, 
 and 
, by deterministically splitting the Poisson process, 

0 to



0 to



n
N t 

Pr N t  =k N t

+

=m



0

m
k

Xi t  i
1 2  n
 

=
i
X t 
Xi t 
i
1
=
n

=
T
T1 T2
Tn
t
0

N t 
N t 
a
0.1
=
a
10
=
a
0.1
=
X t 

Y1 t 
Y2 t 

378    Chapter 8
www.Academicpress.com
.  Each arrival associated with 
 is alternately assigned to one of the two new 
processes.  That is, if 
 is the th arrival time of 
, then
,
.
Find the PMFs of the two split processes, 
 and 
.  Are the split processes also Poisson processes?
8.39 Let 
 be a Poisson counting process with arrival rate, 
.  We form two related 
counting processes, 
 and 
, by randomly splitting the Poisson process, 
.  
In random splitting, the th arrival associated with 
 will become an arrival in 
process 
 with probability  and will become an arrival in process 
 with 
probability 
.  That is, let 
 be the th arrival time of 
 and define 
 to be a 
sequence of IID Bernoulli random variables with 
 and 
.  Then the split processes are formed according to
,
.
Find the PMFs of the two split processes, 
 and 
.  Are the split processes also Poisson processes?
8.40 Consider a Poisson counting process with arrival rate, 
.  Suppose it is observed that there 
have been exactly  arrivals in 
 and let 
 be the times of those  arrivals.  
Next, define 
 to be a sequence of IID random variables uniformly distributed 
over 
 and let 
 be the order statistics associated with the 
.  Show that 
the joint PDF of the order statistics, 
, is identical to the joint PDF of the Poisson 
arrival times, 
.  Hence, the order statistics are statistically identical to the arrival times.
Section 8.7:  Shot Noise in a p–n Junction Diode
8.41 Model lightning strikes to a power line during a thunderstorm as a Poisson impulse 
process. Suppose the number of lightning strikes in time interval  has a mean rate of 
arrival given by , which is one strike per 3 minutes. 
(a)
What is the expected number of lightning strikes in 1 minute? in 10 minutes? 
(b)
What is the average time between lightning strikes? 
X t 
X t 
Si
i
X t 
Y1 t 
u t
Si
–


i odd

=
Y2 t 
u t
Si
–


i even

=
PY1 k; t


Pr Y1 t  = k


=
PY2 k;t


Pr Y2 t  = k


=
X t 

Y1 t 
Y2 t 
X t 
i
X t 
Y1 t 
p
Y2 t 
1
p
–
Si
i
X t 
Wi
Pr Wi = 1


p
=
Pr Wi = 0


1
p
–
=
Y1 t 
Wiu t
Si
–


i
1
=


=
Y2 t 
1
Wi
–

u t
Si
–


i
1
=


=
PY1 k t;


Pr Y1 t  = k


=
PY2 k;t


Pr Y2 t  = k


=

n
0 t


S1 S2  Sn



n
X1 X2  Xn



0 t


Y1 Y2  Yn



Xi
fY y
 
fS s 
t
s

Exercises    379
www.Academicpress.com
8.42 Suppose the power line in the previous problem has an impulse response that may be 
approximated by 
, where 
. 
(a)
What does the shot noise on the power line look like? Sketch a possible member 
function of the shot noise process.
(b)
Find the mean function of the shot noise process.
(c)
Find the autocorrelation function of the shot noise process.
8.43 A shot noise process with random amplitudes is defined by
,
where the 
 are a sequence of points from a Poisson process and the 
 are IID random 
variables which are also indpendent of the Poisson points.
(a)
Find the mean function of 
.
(b)
Find the autocorrelation function of 
.
8.44 In this problem, we develop an alternative derivation for the mean function of the shot 
noise process described in Section 8.7,
,
where the 
 are the arrival times of a Poisson process with arrival rate, , and 
 is an 
arbitrary pulse shape which we take to be causal. That is, 
 for 
.  In order to 
find the mean function, 
, we condition on the event that there were 
exactly  arrivals in 
.  Then, the conditional mean function is
.
(a)
Use the results of Exercise 8.40 to justify that
,
where the 
 are a sequence of IID random variables uniformly distributed over 
.
(b)
Show that the expectation in part (a) reduces to
.
(c)
Finally, average over the Poisson distribution of the number of arrivals to show that
.
h t 
te at
– u t 
=
a
10s 1
–
=
X t 
Aih t
Si
–


i
1
=


=
Si
Ai
X t 
X t 
X t 
h t
Si
–


i
1
=


=
Si

h t 
h t 
0
=
t
0

	X t 
E X t 


=
n
0 t


E X t  n arrivals in 0 t




E h t
Si
–

 n arrivals in 0 t




i
1
=
n

=
E X t  n arrivals in 0 t




E h t
Xi
–




i
1
=
n

=
Xi
0 t


E X t  n arrivals in 0 t




n
t---
h t
u
–

 u
d
0
t

=
E X t 



h t  td
0
t

=

380    Chapter 8
www.Academicpress.com
8.45 Use the technique outlined in Exercise 8.44 to derive the autocovariance function of the 
shot noise process.
Miscellaneous Exercises
8.46 A random process 
 is said to be mean square continuous at some point in time , if
.
(a)
Prove that 
 is mean square continuous at time  if its correlation function, 
 is continuous at the point 
, 
.
(b)
Prove that if 
 is mean square continuous at time , then the mean function 
 must be continuous at time .  Hint: Consider 
 and 
note that any variance must be non-negative.
(c)
Prove that for a WSS process 
, if 
 is continuous at 
, then 
 
is mean square continuous at all points in time.
8.47 Let 
 be a Poisson counting process with arrival rate, 
.  Determine whether or not 
 is mean square continuous.  Hint: See the definition of mean square continuity and 
the associated results in Exercise 8.46.
8.48 Let 
 be a Weiner process with diffusion parameter 
 as described in Section 8.5.  
Determine whether or not 
 is mean square continuous.  Hint: See the definition of 
mean square continuity and the associated results in Exercise 8.46.
8.49 Let 
 be a sequence of IID Bernoulli 
random variables with 
 
and form a random process according 
to
where
X t 
t
E
X t
to
+


X t 
–

2


to
0

lim
0
=
X t 
t
RX X

t1 t2



t1
t
=
t2
t
=
X t 
t
	X t 
t
Var X t
to
+


X t 
–


X t 
RX X


 

0
=
X t 
N t 

N t 
X t 

X t 
X(t)
t
to
Wk
Pr Wk = 1


Pr Wk= 1
–


1 2

=
=
X t 
Wkp t
kto
–


k

–
=


=
p t 
1,
to
2----
–
t
to
2----,

 
0, otherwise.
!
"
#
"
$
=

Exercises    381
www.Academicpress.com
A sample realization of this process is shown in the accompanying figure.  Is this process 
mean square continuous?  Hint: See the definition of mean square continuity and the 
associated results in Exercise 8.46.
MATLAB Exercises
8.50 You are given a member function of a random process as 
 
where the amplitude is in volts.  Quantize the amplitude of 
 into 21 levels with the 
intervals ranging from 10.5 to 10.5 in 1-volt steps.  Consider 100 periods of 
 and let 
 take on discrete values given by 
 where 
.  Construct a histogram of 
.
8.51 Write a MATLAB program to generate a Bernoulli process 
 for which each time 
instant of the process is a Bernoulli random variable with 
 and 
.  Also, the process is IID (i.e., 
 is independent of 
 for all 
).  Once you have created the program to simulate 
, then create a counting 
process 
 which counts the number of occurrences of 
 in the interval 
.  Plot member functions of each of the two processes.
8.52 Let 
, 
, be a sequence of IID zero-mean Gaussian random variables 
with variance 
.  
(a)
Write a MATLAB program to generate the process 
,
where 
, and 
 for 
.
(b)
Estimate the mean function of this process by generating a large number of 
realizations of the random process and computing the sample mean.
(c)
Compute the time-averaged mean of the process from a single realization.  Does 
this seem to give the same result as the ensemble mean estimated in part (b)?
8.53 A certain random process is created as a sum of a large number, , of sinusoids with 
random frequencies and random phases,
,
where the random phases 
 are IID and uniformly distributed over 
 and the 
random frequencies are given by 
, where the 
 are IID and 
uniformly distributed over 
.  (Note: These types of processes occur in the study of 
wireless commuincation systems.)  For this exercise, we will take the constants 
 and 
y t 
10
2t
 2

+


sin
=
y t 
y t 
t
nts
ts
5ms
=
y t 
X n
 
Pr X n
  = 1


0.1
=
Pr X n
  = 0


0.9
=
X n
 
X m


m
n
%
X n
 
Y n
 
X m


1
=
m
0 n



&
Wn n
0 1 2 3 
   
=
W
2
1
=
X n
 
1
2---X n
1
–


1
4---X n
2
–


–
1
4---X n
3
–


–
Wn
+
=
X 0
 
W0
=
X n
 
0
=
n
0

n
X t 
2Fkt
k
+


cos
k
1
=
n

=
k
0 2



Fk
fo
fd
'k


cos
+
=
'k
0 1



fo

382    Chapter 8
www.Academicpress.com
 to be 
 and 
, while we will let the number of terms in the sum 
be 
.
(a)
Write a MATLAB program to generate realizations of this random process.
(b)
Assuming the process is stationary and ergodic, use a single realization to estimate 
the first-order PDF of the process, 
.
(c)
Assuming the process is stationary and ergodic, use a single realization to estimate 
the mean of the process, 
.
(d)
Assuming the process is stationary and ergodic, use a single realization to estimate 
the autocorrelation function of the process, 
.
8.54 Write a MATLAB program to generate a  shot noise process with
 
, 
where 
 and the constant  is chosen so that 
.  For this 
program, assume that carriers cross the depletion region at a rate of 
 per second.  
Plot a member function of this random process.
fd
fo
25Hz
=
fd
10 Hz
=
n
32
=
fX x
 
	X
RXX 
 
h t 
b at


at
–


exp
u t 
=
a
1012s 1
–
=
b
q
h t  td

=
1013

383
CHAPTER 9
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00009-7
© 2012 by Elsevier Inc. All rights reserved.
Markov Processes
In  this chapter, we study a class of random processes that possess a certain characteristic that 
could crudely be described as memoryless.  These processes appear in numerous applications 
including queuing systems, computer communication networks, biological systems, and a 
wide variety of other applications.  As a result of their frequent occurrence, these processes 
have been studied extensively, and a wealth of theory exists to solve problems related to these 
processes.  We make no attempt to give an exhaustive treatment here, but rather present some 
of the fundamental concepts involving Markov processes.
9.1 Definition and Examples of Markov Processes
Definition 9.1:  A random process, 
, is said to be a Markov process if for any
time instants, 
, the random process satisfies
.
(9.1)
To understand this definition, we interpret 
 as the present time so that 
 represents 
some point in the future and 
 represent various points in the past.  
The Markovian property then states that given the present, the future is independent 
of the past.  Or, in other words, the future of the random process only depends on 
where it is now and not on how it got there.
Example 9.1:  
A classical example of a continuous time Markov process is the Poisson counting process 
studied in the previous chapter. Let 
 be a Poisson counting process with rate .  
Then its probability mass function  satisfies
X t 
t1
t2

tn
tn
1
+




FX X tn
1
+


xn
1
+

X tn

 = xn X tn
1
–

 = xn
1
–
 X t1

 = x1





FX X tn
1
+


xn
1
+

X tn

 = xn


=
tn
tn
1
+
t1 t2  tn
1
–



X t 

Pr X tn
1
+

 = xn
1
+
X tn

 = xn X tn
1
–

 = xn
1
–
 X t1

 = x1







384    Chapter 9
www.Academicpress.com
Clearly this is independent of 
.  In fact, the Markovian 
property must be satisfied because of the independent increments assumption of the 
Poisson process.
To start with, we will focus our attention on discrete-valued Markov processes in discrete 
time, better known as Markov chains.  Let 
 be the value of the process at time instant .  
Since the process is discrete-valued, 
 and we say that if 
 
then the process is in state  at time .   A Markov chain is described statistically by its 
transition probabilities which are defined as follows.
Definition 9.2:  Let 
 be a Markov chain with states 
.  Then, the
probability of transitioning from state  to state  in one time instant is
.
(9.2)
If the Markov chain has a finite number of states, 
, then it is convenient to define a
transition probability matrix,
.
(9.3)
One can encounter processes where the transition probabilities vary with time and therefore need to 
be explicitly written as a function of  (e.g., 
) but we do not consider such processes in this 
text and henceforth it is assumed that transition probabilities are independent of time.  
Example 9.2:  
Suppose every time a child buys a kid’s meal at his favorite fast food restaurant he 
receives one of four superhero action figures.  Naturally, the child wants to collect all 
four action figures and so he regularly eats lunch at this restaurant in order to complete 
the collection.  This process can be described by a Markov chain.  In this case, let 
 be the number of different action figures that the child has collected 
0,
xn
1
+
xn

,
 tn
1
+
tn
–



xn
1
+
xn
–
xn
1
+
xn
–

!
-----------------------------------------------------e  tn
1
+
tn
–


–
,
xn
1
+
xn
	
.







=
X tn
1
–

 = xn
1
–
 X t1

 = x1




X k
 
k
X k
 
x1 x2 x3 






X k
 
xn
=
n
k
X k
 
x1 x2 x3 





i
j
pi j
Pr X k
1
+

 = j X k
  = i


=
n
P
p1 1

p1 2

 p1 n

p2 1

p2 2

 p2 n

pn 1

pn 2

 pn n

=
k
pi j k
 
X k
 
0 1 2 3 4
   






Markov Processes    385
www.Academicpress.com
after purchasing  meals.  Assuming each meal contains one of the four superheroes 
with equal probability and that the action figure in any meal is independent of what is 
contained in any previous or future meals, then the transition probability matrix easily 
works out to be
.
Initially (before any meals are bought), the process starts in state 0 (the child has no 
action figures).  When the first meal is bought, the Markov chain must move to state 1 
since no matter which action figure is contained in the meal, the child will now have 
one superhero.  Therefore, 
 and 
 for all 
.  If the child has one dis-
tinct action figure, when he buys the next meal he has a 25 % chance of receiving a 
duplicate and a 75% chance of getting a new action figure.  Thus, 
, 
, and 
 for 
.  Similar logic is used to complete the rest of the 
matrix.  The child might be interested in knowing the average number of lunches he 
needs to buy until his collection is completed.  Or, maybe the child has saved up only 
enough money to buy 10 lunches and wants to know what are his chances of complet-
ing the set before running out of money.  We will develop the theory needed to answer 
such questions.
The transition process of a Markov chain can also be illustrated graphically using a state 
diagram.  Such a diagram is illustrated in Figure 9.1 for the Markov chain in Example 9.2.  
In the figure, each directed arrow represents a possible transition and the label on each arrow 
represents the probability of making that transition.  Note that for this Markov chain, 
once we reach state 4, we remain there forever.  This type a state is referred to as 
an absorbing state.
k
P
0
1
0
0
0
0 1 4

3 4

0
0
0
0
1 2

1 2

0
0
0
0
3 4

1 4

0
0
0
0
1
=
p0 1

1
=
p0 j
0
=
j
1

p1 1

1 4

=
p1 2

3 4

=
p1 j
0
=
j
1 2


0
1
2
3
4
1
1/4
3/4
1/2
1/2
3/4
1/4
1
Figure 9.1 
 State diagram for the Markov chain of Example 9.2.


386    Chapter 9
www.Academicpress.com
Example 9.3 (The Gambler’s Ruin Problem): 
Suppose a gambler plays a certain game of chance (e.g., blackjack) against the “house.”  
Every time the gambler wins the game, he increases his fortune by one unit (say, a dollar) 
and every time he loses, his fortune decreases by one unit.  Suppose the gambler wins 
each game with probability  and loses with probability 
.  Let 
 represent the 
amount of the gambler’s fortune after playing the game  times.  If the gambler ever 
reaches the state 
, the gambler is said to be “ruined” (he has lost all of his money).  
Assuming that the outcome of each game is independent of all others, the sequence 
, 
, forms a Markov chain.  The state transition matrix is of the form
.
The state transition diagram for the gambler’s ruin problem is shown in Figure 9.2a.  
One might then be interested in determining how long it might take before the gambler 
is ruined (enters the zero state).  Is ruin inevitable for any , or if the gambler is 
sufficiently proficient at the game, can he avoid ruin indefinitely?  A more realistic 
alternative to this model is one where the house also has a finite amount of money.  
Suppose the gambler initially starts with  dollars and the house has 
 dollars so that 
between the two competitors there is a total of  dollars in the game.  Now if the 
gambler ever gets to the state 0, he is ruined, while if he gets to the state , he has 
“broken the bank” (i.e., the house is ruined).  Now the Markov chain has two absorbing 
states as shown in Figure 9.2b.  It would seem that sooner or later the gambler must 
have a run of bad luck sufficient to send him to the 0 state (i.e., ruin) or a run of good 
luck which will cause him to enter the state  (i.e., break the bank).  It would be interesting 
to find the probabilities of each of these events.
p
q
1
p
–
=
Xn
n
Xn
0
=
xn
n
0 1 2 
  
=
P
1 0 0 0 0 
q 0 p 0 0 
0 q 0 p 0 
0 0 q 0 p 



=
p
d
b
d
–
b
b
b
0
1
2
3
4
5
. . .
1
(a)
(b)
q
q
q
q
q
q
p
p
p
p
p
0
1
2
3
4
5
. . .
1
q
q
q
q
q
q
p
p
p
p
p
b
b-1
1
p
q
p
Figure 9.2  
State transition diagram for Example 9.3 (The Gamblers Ruin Problem) with 
(a) one absorbing state and (b) with two absorbing states.



Markov Processes    387
www.Academicpress.com
The previous example is one of a class of Markov chains known as random walks.  Random 
walks are often used to describe the motion of a particle.  There are many applications that can 
be described by a random walk that do not involve the movement of a particle, but it is helpful 
to think of such a particle when describing random walks.  In one dimension, a random walk is 
a Markov chain whose states are the integers and whose transition probabilities satisfy 
 for any 
.  In other words, at each time instant, the state of the Markov 
chain can either increase by one, stay the same,  or decrease by one.  If 
, then 
the random walk is said to be symmetric, whereas, if 
, the random walk is said 
to have drift.  Often the state space of the random walk will be a finite range of integers, 
 (for 
), in which case the states  and 
 are said to be 
boundaries or barriers.  The gamblers ruin problem is an example of a random walk with 
absorbing boundaries, where 
.  Once the particle reaches the boundary, it is 
absorbed and remains there forever.  We could also construct a random walk with reflecting 
boundaries, in which case 
.  That is, whenever the particle reaches the 
boundary, it is always reflected back to the adjacent state.
Example 9.4 (A Queueing System): 
A common example of Markov chains (and Markov processes in general) is that of 
queueing systems.  Consider, for example, a taxi stand at a busy airport.  A line of taxis, 
which for all practical purposes can be taken to be infinitely long, is available to serve 
travelers.  Customers wanting a taxi enter a queue and are given a taxi on a first come, 
first serve basis.  Suppose it takes one unit of time (say, a minute) for the customer at 
the head of the queue to load himself and his luggage into a taxi.  Hence, during each 
unit of time, one customer in the queue receives service and leaves the queue while some 
random number of new customers enter the end of the queue.  Suppose at each time 
instant, the number of new customers arriving for service is described by a discrete 
distribution 
, where 
 is the probability of  new customers.  For such a 
system, the transition probability matrix of the Markov chain would look like
.
The manager of the taxi stand might be interested in knowing the probability distribution 
of the queue length.  If customers have to wait too long, they may get dissatisfied and 
seek other forms of transportation.
pi j
0
=
j
i
1
–
i i
1
+
 

pi i
1
+

pi i
1
–

=
pi i
1
+

pi i
1
–


n n
1 n
2  m
1
–
m



+

+

m
n

n
m
pn n

pm m

1
=
=
pn n
1
+

pm m
1
–

1
=
=
p0 p1 p2 





pk
k
P
p0 p1 p2 p3 
p0 p1 p2 p3 
0 p0 p1 p2 
0
0 p0 p1 



=



388    Chapter 9
www.Academicpress.com
Example 9.5 (A Branching Process): 
Branching processes are commonly used in biological studies.  Suppose a certain species 
of organism has a fixed lifespan (one time unit).  At the end of its lifespan, the th 
organism in the species produces a number of offspring described by some random 
variable, 
, whose sample space is the set of non-negative integers.  Also, assume that 
the number of offspring produced by each organism is independent and identically 
distributed (IID).  Then, 
, the number of species in the organism during the th 
generation is a random variable which depends only on the number of organisms in the 
previous generation.  In particular, if 
, then 
.  The transition 
probability is then
.
Let 
 be the probability-generating function of the random variable 
 (i.e., 
).  Then, due to the IID nature of the 
, 
 will have a 
probability-generating function given by 
.  Hence, the transition probability, 
, 
will be given by the coefficient of 
 in the power series expansion of 
.
Example 9.6 (A Genetic Model): 
Suppose a gene contains  units.  Of these units,  are mutant and 
 are normal.  
Every time a cell doubles, the  units double and each of the two cells receives a gene 
composed of  units.  After doubling, there is a pool of 
 units of which 
 are mutant.  
These 
 units are grouped into two sets of  units randomly.  As we trace a single line 
of descent, the number of mutant units in each gene forms a Markov chain.  Define the 
th gene to be in state  (
) if it is composed of  mutant and 
 normal units.  
It is not difficult to show that, given 
,
.
9.2 Calculating Transition and State Probabilities in Markov Chains
The state transition probability matrix of a Markov chain gives the probabilities of 
transitioning from one state to another in a single time unit.  It will be useful to extend this 
concept to longer time intervals.
n
Yn
Xk
k
Xk
i
=
Xk
1
+
Yn
n
1
=
i

=
pi j
Pr Xk
1
+ =j Xk=i


Pr
Yn
n
1
=
i

 = j


=
=
HY z 
Yn
HY z 
Pr Yn=i

zi
i
0
=


=
Yn
Yn
n
1
=
i

HY z 

i
pi j
zj
HY z 

i
n
i
n
i
–
n
n
2n
2i
2n
n
k
i
Xk
i
=
i
n
i
–
Xk
i
=
pi j
Pr Xk
1
+ =j Xk=i


2i
j



 2n
2i
–
n
j
–




2n
n




---------------------------------
=
=





Markov Processes    389
www.Academicpress.com
Definition 9.3: The -step transition probability for a Markov chain is 
.
(9.4)
Also, define an -step transition probability matrix 
 whose elements are the 
-step transition probabilities in Equation (9.4).
Given the one-step transition probabilities, it is straightforward to calculate higher order 
transition probabilities using the following result.
Theorem 9.1 (Chapman–Kolmogorov Equation):
,     for any  
.
(9.5)
Proof: First, condition on the event that in the process of transitioning from state  to
state , the Markov chain passes through state  at some intermediate point in time.
Then using the principle of total probability
.
(9.6)
Using the Markov property, the expression reduces to the desired form:
.  
(9.7)
This result can be written in a more compact form using transition probability matrices.  It is 
easily seen that the Chapman–Kolmogorov equations can be written in terms of the -step 
transition probability matrices as
.
(9.8)
Then, starting with the fact that 
, it follows that 
, and using 
induction, it is established that
.
(9.9)
Hence, we can find the -step transition probability matrix through matrix multiplication.  If  
is large, it may be more convenient to compute 
 via eigendecomposition. In many cases1 the 
n
pi j
n
 
Pr Xk
n
+
= j Xk = i


=
n
P n
 
n
pi j
n
 
pi k

m

pk j
n
m
–


k
=
m
0 1 2  n
  

=
i
j
k
Pr Xl
n
+ =j Xl=i


Pr Xl
n
+ =j Xl=i Xl
m
+
=k


Pr Xl
m
+
=k Xk=i


k
=
Pr Xl
n
+ =j Xl=i


Pr Xl
n
+ =j Xl
m
+
=k

Pr Xl
m
+
=k Xk=i


k
=
n
P n
 
P m

P n
m
–


=
P 1
 
P
=
P 2
 
P 1
 P 1
 
P2
=
=
P n
 
Pn
=
n
n
Pn
1 It is noted that not all transition matrices are diagonalizable. For those that are not, this approach will 
not work.

390    Chapter 9
www.Academicpress.com
matrix 
 can be expanded as 
, where 
 is the diagonal matrix of eigenvalues and 
 is the matrix whose columns are the corresponding eigenvectors.  Then,
.
(9.10)
Another quantity of interest is the probability distribution of the Markov chain at some time 
instant .  If the initial probability distribution of the Markov chain is known, then the 
distribution at some later point in time can easily be found.  Let 
 and 
 be the row vector whose th element is 
.  Then
,
(9.11)
or in vector form,
.
(9.12)
Example 9.7 (continuation of Example 9.2): 
Recall in Example 9.2, the child who purchased kid’s meals at his favorite restaurant in 
order to collect a set of four superhero action figures.  Initially, before any meals are 
purchased, the child has no action figures and so the initial probability distribution is 
.  Repeated application of Equation (9.12) with the probability 
transition matrix given in Example 9.2 results in
,
,
,
,
,
,
and so on.  It is to be expected that if the child buys enough meals, he will eventually 
complete the collection (i.e., get to state 4) with probability approaching unity.  This can 
easily be verified analytically by calculating the limiting form of 
 as 
.  Recall that 
for this example,  is a triangular matrix and hence its eigenvalues are simply the 
diagonal entries.  Hence, the diagonal matrix of eigenvalues is
P
P
ULU 1
–
=
L
U
Pn
ULnU 1
–
=
k
j k
 
Pr Xk = j


=
p k
 
j
j k
 
j k
 
Pr Xk=j


Pr Xk= j X0=i

Pr X0 = i


i
pi j
k
 i 0
 
i
=
=
=
p k
 
p 0
 Pk
=
p 0
 
1 0 0 0 0
   


=
p 1
 
0 1 0 0 0
   


=
p 2
 
0 1 4

3 4

0 0


 


=
p 3
 
0 1 16

9 16

3 8

0






=
p 4
 
0 1 64

21 64

9 16

3 32







=
p 5
 
0 1 256

45 256

75 128

15 64







=
p 6
 
0 1 1024

93 1024

135 256

195 512







=
Pk
k


P


Markov Processes    391
www.Academicpress.com
.
It should be clear that 
 is a matrix with all zero entries except the one in the lower 
right corner, which is equal to one.  Using MATLAB (or some other math package) to 
calculate the corresponding matrix of eigenvectors, it is found that
.
Then, using the initial distribution of 
, the state distribution as 
 
works out to be
.
In Example 9.6, it was seen that as 
, the -step transition probability matrix approached 
that of a matrix whose rows were all identical.  In that case, the limiting product 
 
is the same regardless of the initial distribution 
.  Such a Markov chain is said to have a 
unique steady-state distribution, 
.  It should be emphasized that not all Markov chains have a 
steady-state distribution.  For example, the Poisson counting process of Example 9.1 clearly 
does not, since any counting process is a monotonic non-decreasing function of time and, 
therefore, it is expected that the distribution should skew toward larger values as time 
progresses.  
This concept of a steady-state distribution can be viewed from the perspective of stationarity.  
Suppose at time , the process has some distribution, 
.  The distribution at the next time 
instant is then 
.  If 
, then the process has reached a point 
where the distribution is stationary (independent of time). This stationary distribution, 
, 
must satisfy the relationship
.
(9.13)
In other words, 
 (if it exists) is the left eigenvector of the transition probability matrix 
, 
that corresponds to the eigenvalue 
.  The next example shows that this eigenvector is 
not always  unique.
L
0
0
0
0
0
0 1 4

0
0
0
0
0
1 2

0
0
0
0
0
3 4

0
0
0
0
0
1
=
Lk
k


lim
Pk
k


lim
U
Lk
k


lim

U 1
–
0 0 0 0 1
0 0 0 0 1
0 0 0 0 1
0 0 0 0 1
0 0 0 0 1
=
=
p 0
 
1 0 0 0 0
   


=
k


p
 k
 
k


lim
p 0
 Pk
k


lim
0 0 0 0 1
=
=
=
k


k
p 0
 Pk
k


lim
p 0
 
p
k
p k
 
p k
1
+


p k
 P
=
p k
 
p k
1
+


=
p
p
p P
=
p
P

1
=


392    Chapter 9
www.Academicpress.com
Example 9.8  (The Gambler’s Ruin revisited): 
Suppose a certain gambler has $5 and plays against another player (the house).  The 
gambler decides that he will play until he either doubles his money or loses it all.  
Suppose the house has designed this game of chance so that the gambler will win with 
probability 
 and the house will win with probability 
.  Let 
 be the 
amount of money the gambler has after playing the game  times.  The transition 
probability matrix for this Markov chain is
.
This matrix has (two) repeated eigenvalues of 
, and the corresponding eigenvectors 
are 
 and 
.  Note that any linear combination of 
these will also be an eigenvector.  Therefore, any vector of the form 
 
is a left eigenvector of  and hence there is no unique stationary distribution for this 
Markov chain.  For this example, the limiting form of the state distribution of the Markov 
chain depends on the initial distribution.  The limiting form of 
 can easily be found to be
Using the initial distribution 
 (that is, the gambler starts off 
in state 5), then it is seen that the steady-state distribution is 
 
.  So, when the gambler starts with $5, he has about a 73% 
chance of losing all of his money and about a 27% chance of doubling his money.
p
0.45
=
q
0.55
=
Xk
k
P
1
0
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0.55
0
0.45
0
0
0
0
0
0
0
0
0
0
1
'
=

1
=
1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1
p 0 0 0 0 0 0 0 0 0 1
p
–
P
Pk
Pk
k


lim
1
0 0 0 0 0 0 0 0 0
0
0.9655 0 0 0 0 0 0 0 0 0 0.0345
0.9233 0 0 0 0 0 0 0 0 0 0.0767
0.8717 0 0 0 0 0 0 0 0 0 0.1283
0.8087 0 0 0 0 0 0 0 0 0 0.1913
0.7317 0 0 0 0 0 0 0 0 0 0.2683
0.6376 0 0 0 0 0 0 0 0 0 0.3624
0.5225 0 0 0 0 0 0 0 0 0 0.4775
0.3819 0 0 0 0 0 0 0 0 0 0.6181
0.2101 0 0 0 0 0 0 0 0 0 0.7899
0
0 0 0 0 0 0 0 0 0
1
=
 0
 
0 0 0 0 0 1 0 0 0 0 0
=
p k
 
k


lim
=
0.7317 0 0 0 0 0 0 0 0 0 0.2683



Markov Processes    393
www.Academicpress.com
As seen in Example 9.7, with some Markov chains, the limiting form of 
 (as 
) does 
not necessarily converge to a matrix whose rows are all identical.  In that case, the limiting 
form of the state distribution will depend on the starting distribution.  In the case of the 
gambler’s ruin problem, we probably could have guessed this behavior.  If the gambler had 
started with very little money, we would expect him to end up in the state of ruin with very 
high probability; whereas, if the gambler was very wealthy and the house had very little 
money, we would expect a much greater chance of the gambler eventually breaking the house.  
Accordingly, our intuition tells us that the probability distribution of the gamblers ultimate 
state should depend on the starting state.  
In general, there are several different manners in which a Markov chain’s state distribution can 
behave as 
.  In some cases, 
 does not exist.  Such would be the case when the 
process tends to oscillate between two or more states.  A second possibility, as in Example 9.7, 
is that 
 does in fact converge to a fixed distribution, but the form of this limiting 
distribution depends on the starting distribution.  The last case is when 
.  That 
is the state distribution converges to some fixed distribution, 
, and the form of 
 is 
independent of the starting distribution.  Here, the transition probability matrix, 
, will have a 
single (not repeated) eigenvalue at 
, and the corresponding eigenvector (properly 
normalized) will be the steady-state distribution, 
.  Furthermore, the limiting form of 
 
will be one whose rows are all identical and equal to the steady-state distribution, 
.  In the 
next section, we look at some conditions that must be satisfied for the Markov chain to achieve 
a unique steady-state distribution.
Example 9.9:  
In this example, we provide the MATLAB code to simulate the distribution 
of the queue length of the taxi stand described in Example 9.4.  For this 
example, we take the number of arrivals per time unit, , to be a Poisson 
random variable whose PMF is
.
Recall that in the taxi stand, one customer is served per time unit (assuming there is a 
least one customer in the queue waiting to be served).  The following code can be used 
to estimate and plot the PMF of the queue length.  The average queue length was also 
calculalted to be 3.36 customers for an arrival rate of 
 customers per time unit.  
Figure 9.3 shows a histogram of the PMF of the queue length for the same arrival rate.
N=10000;
% Length of simulation.
a=0.85;
% arrival rate.
k=[0:10];
Poisson=zeros(size(k));
% Calculate Poisson PMF
for m=k
Pk
k


k


p k
 
k


lim
p k
 
k


lim
p k
 
k


lim
p
=
p
p
P

1
=
p
Pk
p
X
PX k
 
ke 
–
k!
--------------
=

0.85
=

(Continued)

394    Chapter 9
www.Academicpress.com
   Poisson(m+1)=a.^m*exp(-a)./factorial(m);
end
queue(1)=0;
% Initial queue size.
for n=1:N
   x=rand(1);
   arrivals=sum(x>cumsum(Poisson));
% Poisson RV
   departures=queue(n)>0;
   queue(n+1)=queue(n)+arrivals-departures;
% current queue length
end
mean_queue_length=sum(queue)/length(queue)
% compute avg. queue length
bins=[0:25]
y=hist(queue,bins);
PMF=y/N;
% estimate PMF
bar(bins,PMF) 
% plot results
axis([min(bins)-1 max(bins)+1 0 1.1*max(PMF)])
9.3 Characterization of Markov Chains
Using the methods presented in the previous sections, calculating the steady-state distribution 
of a Markov chain requires performing an eigendecomposition of the transition probability 
matrix, 
.  If the number of states in the Markov chain is large (or infinite), performing the 
required linear algebra may be difficult (or impossible).  Thus, it would be useful to seek 
0
5
10
15
20
25
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
Queue length
Probability mass function
Figure 9.3  
Histogram of the queue length for the taxi stand of Example 9.4 assuming a Poisson arrival 
process with an average arrival rate of 0.85 arrivals per time unit.
P


Markov Processes    395
www.Academicpress.com
alternative methods to determine if a steady-state distribution exists, and if so, to calculate it.  
To develop the necessary theory, we must first proceed through a sequence of definitions and 
classifications of the states of a Markov chain.
Definition 9.4:  State  is accessible from state  if for some finite , 
.  This 
simply means that if the process is in state , it is possible for the process to get to 
state  in a finite amount of time.  Furthermore, if state  is accessible from state  and 
state  is accessible from state , then the states  and  are said to communicate.  It is 
common to use the shorthand notation 
 to represent the relationship “state  
communicates with state .”
The states of any Markov chain can be divided into sets or classes of states where all the states 
in a given class communicate with each other.  It is possible for the process to move from one 
communicating class of states to another, but once that transition is made, the process can 
never return to the original class.  If it did, the two classes would communicate with each other 
and hence would be a part of a single class.  
Definition 9.5: A Markov chain for which all of the states are part of a single 
communicating class is called an irreducible Markov chain.  Also, the corresponding 
transition probability matrix is called an irreducible matrix.
The examples in Section 9.1 can be used to help illustrate these concepts.  For both processes 
in Examples 9.1 and 9.2, none of the states communicate with any other states.  This is a result 
of the fact that both processes are counting processes and as a result, it is impossible to go 
backward in the chain of states.  Therefore, if 
, state  is accessible from state  but state 
 is not accessible from state .  As a result, for any counting process, all states form a 
communication class of their own.  That is, the number of classes is identical to the number of 
states.  In the gambler’s ruin problem of Example 9.3, the two absorbing states do not 
communicate with any other state since it is impossible to ever leave an absorbing state, while 
all the states in between communicate with each other.  Therefore, this Markov chain has three 
communicating classes; the two absorbing states each form of class to themselves, while the 
third class consists of all the states in between.  
The queueing system (taxi stand) of Example 9.4 represents a Markov chain where all states 
communicate with each other, and therefore that Markov chain is irreducible.  For the 
branching process of Example 9.5, all states communicate with each other except the state 0, 
which represents the extinction of the species, which presumably is an absorbing state.  The 
genetic model of Example 9.6 is similar to the gambler’s ruin problem in that the Markov 
chain has two absorbing states at the end points, while everything in between forms a single 
communicating class.  
j
i
n pi j
n
 
0

i
j
j
i
i
j
i
j
i
j

i
j
j
i

j
i
i
j

396    Chapter 9
www.Academicpress.com
Definition 9.6:  The period of state , 
, is the greatest common divisor of all 
integers 
 such that 
.  Stated another way, 
 is the period of state  if 
any transition from state  to itself must occur in a number of steps that is a multiple 
of 
.  Furthermore, a Markov chain for which all states have a period of 
 
is called an aperiodic Markov chain.
Most Markov chains are aperiodic.  The class of random walks is an exception.  Suppose a 
Markov chain defined on the set of integers has transition probabilities that satisfy
(9.14)
Then each state will have a period of 2.  If we add absorbing boundaries to the random walk, 
then the absorbing states are not periodic because for the absorbing states, 
 for all  
and thus the period of an absorbing state is 1.  It is left as an exercise for the reader (see 
Exercise 9.26) to establish the fact that the period is a property of a class of communicating 
states.  That is, if 
, then 
 and therefore all states in the same class must have 
the same period.  
Definition 9.7:  Let 
 be the probability that given a process is in state , the first
return to state  will occur in exactly  steps.  Mathematically,
.
(9.15)
Also, define 
 to be the probability that the process will eventually return to state .
The probability of eventual return is related to the first return probabilities by
.
(9.16)
It should be noted that the first return probability 
 is not the same thing as the -step 
transition probability, but the two quantities are related.  To develop this relationship, it is 
observed that
i d i 
n
1
	
pi i
n
 
0

d i 
i
i
d i 
d i 
1
=
pi j
p,
j = i
1,
+
1
p,
–
j = i
1,
–
0,
   otherwise.




	
=
pi i
n
 
1
=
n
i
j

d i 
d j 
=
fi i
n
 
i
i
n
fi i
n
 
Pr Xk
n
+ =i Xk
m
+
i for m=1 2  n
1
–
 



Xk=i


=
fi i
i
fi i
fi i
n
 
n
1
=


=
fi i
n
 
n

Markov Processes    397
www.Academicpress.com
             
   
,   
.
(9.17)
In Equation (9.17), 
 is taken to be equal to 1 and 
 is taken to be equal to 0.  Given the 
-step transition probabilities, 
, one could solve the preceding system of equations for the 
first return probabilities.  However, since the previous equation is a convolution, this set of 
equations may be easier to solve using frequency domain techniques.  Define the generating 
functions1,
,
(9.18)
.
(9.19)
It is left as an exercise for the reader (see Exercise 9.27) to demonstrate that these two 
generating functions are related by
.
(9.20)
This relationship provides an easy way to compute the first return probabilities from the 
-step transition probabilities.  Note that if the transition probability matrix is known, then 
calculating the generating function, 
, is straightforward.  Recall that 
 
and therefore if 
 is the element in the th row and th column of 
, then 
.
(9.21)
pi i
n
 
Pr
Xk
n
+ =i


first return to state i occurs in m steps



Xk=i


m
0
=
n

=
Pr Xk
n
+ =i Xk
m
+
=i

Pr first return to state i occurs in m steps Xk
m
+
=i


m
0
=
n

=
pi i
n
m
–

fi i
m


m
0
=
n

=
n
1 2 3 
  
=
pi i
0
 
fi i
0
 
n
pii
n
 
Pi i
z 
pi i
n
 zn
n
0
=


=
Fi i
z 
fi i
n
 zn
n
0
=

=
Pi i
z 
1
–
Pi i
z Fi i
z 
=
n
Pi i
z 
Pn
ULnU 1
–
=
U

i j
i
j
U
pi i
n
 
U

i j Ln U 1
–

j i
j
=
1 Note that these generating functions are not necessarily probability-generating functions as the 
sequences involved are not necessarily probability distributions.

398    Chapter 9
www.Academicpress.com
Forming the generating function from this equation results in
.
(9.22)
In other words,  
 is the element in the th row and th column of the matrix 
.
Definition 9.8:  The th state of a Markov chain is transient if 
 and recurrent if
.  Since 
 represents the probability of the process eventually returning to
state  given that it is in state , the state is transient if there is some non-zero proba-
bility that it will never return, and the state is recurrent if the process must eventually
return with probability 1.
Theorem 9.2:  State  of a Markov chain is recurrent if and only if 
.  
(9.23)
Since this sum represents the expected number of returns to state , it follows that a
state is recurrent if and only if the expected number of returns is infinite.
Proof: First, note that 
.  From Equation (9.20), this
would imply that  
.  
(9.24)
Pi i
z 
pi i
n
 zn
n
0
=


U

i j
Lz

n U 1
–

j i
j
n
0
=


=
=
U

i j
Lz

n
n
0
=









U 1
–

j i
j
U

i j
I
Lz
–

 1
–
U 1
–

j i ·
j
=
=
Pi i
z 
i
i
U I
Lz
–

 1
– U 1
–
i
fi i
1

fi i
1
=
fi i
i
i
i
pi i
n
 
n
1
=



=
i
fi i
fi i
n
 
n
1
=


Fi i
z 
z
1

lim
=
=
Pi i
z 
z
1

lim
1
–
Pi i
z 
z
1

lim
fi i
=

Markov Processes    399
www.Academicpress.com
As a result, 
.
(9.25)
If state  is transient, then 
 and hence, 
, whereas if state  is
recurrent, 
 and 
.  
We leave it to the reader (see Exercise 9.29) to verify that recurrence is a class property. That 
is, if one state in a communicating class is recurrent, then all are recurrent, and if one is 
transient, then all are transient.  
Example 9.10:  
Consider a random walk on the integers (both positive and negative) that initially starts 
at the origin (
).  At each time instant, the process either increases by 1 with 
probability  or decreases by 1 with probability 
:
First note that this Markov chain is periodic with period 2 and hence 
 for any 
odd .  For even , given the process is in state , the process will be in state  again  
time instants later if during those time instants the process increases 
 times and 
decreases 
 times.  This probability follows a binomial distribution so that
,  for even .
To determine if the states of this random walk are recurrent or transient, we must 
determine whether or not the series 
 
converges. To help make this determination, the identity
,   
,
Pi i
z 
z
1

lim
pi i
n
 
n
1
=


1
1
fi i
–
----------------
=
=
i
fi i
1

pi i
n
 
n
1
=




i
fi i
1
=
pi i
n
 
n
1
=



=
X0
0
=
p
1
p
–
pi j
p,
if j=i
1,
+
1
p,
–
if j=i
1,
–
0,
otherwise.




	
=
pi i
n
 
0
=
n
n
i
i
n
n 2

n 2

pi i
n
 
n
n 2




 pn 2

1
p
–

n 2

=
n
pi i
2n


n
1
=

2n
n



 p 1
p
–



n
n
1
=

=
2n
n



 xn
n
1
=

1
1
4x
–
-------------------
1
–
=
x
1 4



(Continued)

400    Chapter 9
www.Academicpress.com
is used. This identity can easily be verified by expanding the binomial on the right hand 
side in powers of  and confirming (after a little algebra) that the coefficients of the 
power series expansion do take on the desired form.  Applying this identity results in
.
Note that for a probability , 
 with equality if and only if 
.  Therefore, 
the series converges and all states are transient if 
, while if 
, the series 
diverges and all states are recurrent.
Definition 9.9:  The mean time to first return for a recurrent state  of a Markov chain is
.
(9.26)
If the state is transient, then the mean time to first return must be infinite, since with
some non-zero probability, the process will never return.
Definition 9.10: A recurrent state is referred to as null recurrent if 
, while the
state is positive recurrent if 
.
The mean time to first return of a recurrent state is related to the steady-state probability of the 
process being in that state.  To see this, define a sequence of random variables 
, 
, 
, ... 
where 
 represents the time between the 
th and 
th returns to the state .  That is, 
suppose that 
 for some time instant  which is sufficiently large so that the process has 
pretty much reached steady state.  The process then returns to state  at time instants 
, 
, 
, and so on.  Over some period of time where the process visits 
state  exactly  times, the fraction of time the process spends in state  can be written as
.
(9.27)
As 
 (assuming the process is ergodic), the left hand side of the previous equation 
becomes the steady-state probability that the process is in state , 
. Furthermore, due to the 
law of large numbers, the denominator of the right hand side converges to 
.  This proves the 
following key result.
x
pi i
2n


n
1
=

1
1
4p 1
p
–


–
------------------------------------
1
–
=
p
4p 1
p
–


1

p
1 2

=
p
1 2


p
1 2

=
i
i
nfi i
n
 
n
1
=


=
i

=
i


T1 T2 T3
Tm
m
1
–
m
i
Xk
i
=
k
i
k
T1
+
k
T1
T2
+
+
k
T1
T2
T3
+
+
+
i
n
i
fraction of time process is in state i
n
Tj
j
1
=
n

---------------
1
1
n---
Tj
j
1
=
n

------------------
=
=
n


i i
i


Markov Processes    401
www.Academicpress.com
Theorem 9.3:  For an irreducible, aperiodic, recurrent Markov chain, the steady-state
distribution is unique and is given by
.
(9.28)
Note that if a state is positive recurrent, then 
, while if a state is null recurrent, then 
.  Note that for any transient state, 
 and as a result, 
.
Example 9.11:  
Continuing with the random walk from the previous example, the generating function 
for the -step transition probabilities is found to be
.
Using the relationship 
, the generating function for the first 
return probabilities is
.
Since the random walk is only recurrent for 
, we consider only that case so that 
.  The mean time to first return can be found directly from the 
generating function.
.
Thus, when the transition probabilities of the random walk are balanced so that all 
states are recurrent, then the mean time to first return is infinite and, in fact, all states 
are null recurrent.  
9.4 Continuous Time Markov Processes
In this section, we investigate Markov processes where the time variable is continuous.  In 
particular, most of our attention will be devoted to the so-called birth–death processes which 
are a generalization of the Poisson counting process studied in the previous chapter.  To start 
with, consider a random process 
 whose state space is either finite or countably infinite so 
that we can represent the states of the process by the set of integers, 
.  Any process of this sort that is a Markov process has 
the interesting property that the time between any change of states is an exponential random 
variable.  To see this, define 
 to be the time between the th and the 
th change of state 
and let 
 be the complement to its CDF, 
.  Then, for 
i
1
i
-----
=
i
0

i
0
=
i

=
i
0
=
n
Pi i
z 
pi i
n
 zn
n
0
=


2n
n



 p 1
p
–



nz2n
n
0
=

1
1
4p 1
p
–

z2
–
------------------------------------------
=
=
=
Pi i
z 
1
–
Pi i
z Fi i
z 
=
Fi i
z 
1
1
4p 1
p
–

z2
–
–
=
p
1 2

=
Fi i
z 
1
1
z2
–
–
=
i
nfi i
n
 
n
1
=

z
d
d Fi i
z 
z
1

lim
z
1
z2
–
------------------
z
1

lim

=
=
=
=
X t 
X t 

3
2
1
–
0 1 2 3 

    
–

–




Ti
i
i
1
+
hi t 
hi t 
Pr Ti
t



=
t
0

s
0





402    Chapter 9
www.Academicpress.com
. (9.29)
Due to the Markovian nature of the process, 
 and hence the 
previous equation simplifies to
.
(9.30)
The only function which satisfies this type of relationship for arbitrary  and  is an 
exponential function of the form 
 for some constant 
.  Furthermore, for this 
function to be a valid probability, the constant 
 must not be negative.  From this, the PDF of 
the time between change of states is easily found to be 
.  
As with  discrete-time Markov chains, the continuous-time Markov process can be described 
by its transition probabilities.  
Definition 9.11:  Define 
 to be the transition 
probability for a continuous time Markov process.  If this probability does not depend 
on 
, then the process is said to be a homogeneous Markov process.  
Unless otherwise stated, we assume for the rest of this chapter that all continuous time Markov 
processes are homogeneous.  The transition probabilities, 
, are somewhat analogous to 
the -step transition probabilities used in the study of discrete-time processes and as a result, 
these probabilities satisfy a continuous time version of the Chapman–Kolmogorov equations:
,   for  
.
(9.31)
One of the most commonly studied class of continuous time Markov processes is the birth–
death process.  These processes get their name from applications in the study of biological 
systems, but they are also commonly used in the study of queueing theory, and many other 
applications.  The birth–death process is similar to the discrete-time random walk studied in 
the previous section in that when the process changes states, it either increases by 1 or 
decreases by 1.  As with the Poisson counting process, the general class of birth–death 
processes can be described by the transition probabilities over an infinitesimal period of time, 
.  For a birth–death process,
(9.32)
hi t
s
+


Pr Ti
t
s
+



Pr Ti
t
s
+

Ti
s




Pr Ti
t
s
+

Ti
s


Pr Ti
s



=
=
=
Pr Ti
t
s
+

Ti
s



Pr Ti
t



=
hi t
s
+


hi t hi s 
=
t
s
hi t 
e  
–
it
=
 i
 i
fTi t 
 ie  it
–
u t 
=
pi j
t 
Pr X to
t
+

 = j X to

 = i


=
to
pi j
t 
n
pi j
t
s
+


pi k

t pk j
s 
k
=
t s
0


t
!
pi j
t
!


"i t
o
t
!

,
+
!
if j = i
1,
+
i t
o
t
!

,
+
!
if j = i
1,
–
1
"i
i
+

 t
o
t
!

,
+
!
–
if j = i,
o
t
!

,
if j
i
1 i i
1.
+
 
–







	
=

Markov Processes    403
www.Academicpress.com
The parameter 
 is called the birth rate while 
 is the death rate when the process is in state .  
In the context of queueing theory, 
 and 
 are referred to as the arrival and departure rates, 
respectively.  
Similar to what was done with the Poisson counting process, by letting 
 in Equation 
(9.31) and then applying the infinitesimal transition probabilities, a set of differential 
equations can be developed that will allow us to solve for the general transition probabilities.  
From Equation (9.31),
. (9.33)
Rearranging terms and dividing by 
 produces
.
(9.34)
Finally, passing to the limit as 
 results in
.
(9.35)
This set of equations is referred to as the forward Kolmogorov equations.  One can follow a 
similar procedure (see Exercise 9.32) to develop a slightly different set of equations known as 
the backward Kolmogorov equations,
.
(9.36)
For all but the simplest examples, it is very difficult to find a closed-form solution for this 
system of equations.  However, the Kolmogorov equations can lend some insight into the 
behavior of the system.  For example, consider the steady-state distribution of the Markov 
process.  If a steady state exists, we would expect that as 
, 
 independent of
  and also that 
.  Plugging these simplifications into the forward 
Kolmogorov equations leads to
.
(9.37)
These equations are known as the global balance equations.  From them, the steady-state 
distribution can be found (if it exists).  The solution to the balance equations is surprisingly 
easy to obtain.  First, we rewrite the difference equation in the more symmetric form
.
(9.38)
"i
i
i
"i
i
s
t
!
=
pi j
t
t
!
+


pi k

t pk j
t
!


k
"j
1
–
t
!

pi j
1
–

t 
1
"j
j
+

 t
!
–

pi j
t 
j
1
+
t
!

pi j
1
+

t 
o
t
!


+
+
+
=
=
t
!
pi j
t
t
!
+


pi j
t 
–
t
!
------------------------------------------------
"j
1
– pi j
1
–

t 
"j
j
+


–
pi j
t 
j
1
+ pi j
1
+

t 
o
t
!


t
!
-------------
+
+
=
t
!
0

t
d
d pi j
t 
"j
1
– pi j
1
–

t 
"j
j
+


–
pi j
t 
j
1
+ pi j
1
+

t 
+
=
t
d
d pi j
t 
"ipi
1
+
j
t 
"i
i
+

pi j
t 
–
ipi
1
–
j
t 
+
=
t


pi j
t 
j

i
dpi j
t  dt

0

"j
1
– j
1
–
"j
j
+


–
j
j
1
+ j
1
+
+
0
=
"jj
j
1
+ j
1
+
–
"j
1
– j
1
–
jj
–
=

404    Chapter 9
www.Academicpress.com
Next, assume that the Markov process is defined on the states 
.  Then the 
previous equation must be adjusted for the end point 
 according to (assuming 
 
which merely states that there can be no deaths when the population size is zero)
.
(9.39)
Combining Equations (9.38) and (9.39) results in 
,   
,
(9.40)
which leads to the simple recursion
,   
,
(9.41)
whose solution is given by
,   
.
(9.42)
This gives the 
 in terms of 
.  In order to determine 
, the constraint that the 
 must 
form a distribution is imposed.
.
(9.43)
This completes the proof of the following theorem.
Theorem 9.4:  For a Markov birth–death process with birth rate 
, 
,
and death rate 
, 
, the steady-state distribution is given by
.
(9.44)
If the series in the denominator diverges, then 
 for any finite .  This indicates
that a steady-state distribution does not exist.  Likewise, if the series converges, the 
will be non-zero resulting in a well-behaved steady-state distribution.
j
0 1 2 
  
=
j
0
=
0
0
=
"00
11
–
0
=
"jj
j
1
+ j
1
+
–
0
=
j
0 1 2 
  
=
j
1
+
"j
j
1
+
------------j
=
j
0 1 2 
  
=
j
0
"i
1
–
i
------------
i
1
=
j
#
=
j
1 2 3 
  
=
j
0
0
j
j
j
0
=


1
0
$
1
1
"i
1
–
i
------------
i
1
=
j
#
j
1
=


+
------------------------------------------
=
=
"n n
0 1 2 
  
=
n n
1 2 3 
  
=
k
pi k

t 
t


lim
"i
1
–
i
------------
i
1
=
k
#
1
"i
1
–
i
------------
i
1
=
j
#
j
1
=


+
------------------------------------------
=
=
k
0
=
k
k

Markov Processes    405
www.Academicpress.com
Example 9.12 (The M/M/1 Queue): 
In this example, we consider the birth–death process with constant birth rate and 
constant death rate.  In particular, we take
, 
 and 
, 
, 
.
This model is commonly used in the study of queueing systems and, in that context, is 
referred to as the 
 queue.  In this nomenclature, the first “M” refers to the arrival 
process as being Markovian, the second “M” refers to the departure process as being 
Markovian,  and the “1” is the number of servers.  So this is a single server queue, where 
the interarrival time of new customers is an exponential random variable with mean 
 and the service time for each customer is exponential with mean 
.  For the 
 queueing system, 
 for all  so that 
 
for 
.
The resulting steady-state distribution of the queue size is then
,    
,  for 
.
Hence, if the arrival rate is less than the departure rate, the queue size will have a steady 
state.  It makes sense that if the arrival rate is greater than the departure rate, then the 
queue size will tend to grow without bound.  
Example 9.13 (The 
 Queue):  
Next suppose the last example is modified so that there are an infinite number of servers 
available to simultaneously provide service to all customers in the system.  In that case, 
there are no customers ever waiting in line, and the process 
 now counts the number 
of customers in the system (receiving service) at time .  As before, we take the arrival 
rate to be constant 
, but now the departure rate needs to be proportional to the 
number of customers in service, 
.  In this case, 
 and
.
Note that the series converges for any  and , and hence the 
 queue will always 
have a steady-state distribution given by
.
"n
"
=
n
0 1 2 
  
=
0
0
=
n

=
n
1 2 3 
  
=
M/M/1
1 "

1 

M/M/1
"i
1
–
i

" 

=
i
1
"i
1
–
i
-----------
i
1
=
j
#
j
1
=

+
"
---
 
  j
j
0
=

1
1
" 

–
-------------------
=
=
"


k
" 


k
1
1
" 

–
-------------------
--------------------
1
" 

–

 " 


k
=
=
k
0 1 2 
  
=
"


M/M/
X t 
t
"n
"
=
n
n
=
"i
1
–
i

"
i



=
1
"i
1
–
i
-----------
i
1
=
j
#
j
1
=

+
1
"
i
-----
i
1
=
j
#
j
1
=

+
1
" 


j
j!
-----------------
j
1
=

+
e" 

=
=
=
"

M/M/
k
" 


k
k!
-----------------e "
–


=





406    Chapter 9
www.Academicpress.com
Example 9.14:  
This example demonstrates one way to simulate the M/M/1 queueing 
system of Example 9.12.  One realization of this process as produced by 
the code that follows is illustrated in Figure 9.4.  In generating the figure, 
we use an average arrival rate of 
 customers per hour and an average 
service time of 
 minutes.  This leads to the condition 
 and 
the M/M/1 queue exhibits stable behavior.  The reader is encouraged to run the 
program for the case when 
 to observe the unstable behavior (the queue size will 
tend to grow continuously over time).
a=20;
% arrival rate (customers/hour)
b=30;
% departure rate (1/b=avg service time)
N=25;
% no. of arrivals in simulation
X=-log(rand(1,N))/a;
% random interarrival times
X=cumsum(X);
% random arrival times
Y=-log(rand(1,N))/b;
% service times for each customer
serv_start=X(1);
% first customer starts service 
% immediately upon arrival.
Z(1)=serv_start+Y(1);
% departure time of first customer
for k=2:N
% kth customer
"
20
=
1 

2
=
"


"


0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
0.5
1
1.5
2
2.5
3
3.5
4
Time (hours)
Queue size
Figure 9.4 
Simulated realization of the birth/death process for an M/M/1 queueing system 
of Example 9.12.


Markov Processes    407
www.Academicpress.com
   serv_start=max([Z(k-1), X(k)]);
% beginning of service time
   Z(k)=serv_start+Y(k);
% end of service time
end
% Construct data to plot graph of queue size vs time
xaxis=[0, X(1)];
% vector of points for the MM1 
% birth/death process
yaxis=[0, 0];
% vector of queue sizes at points 
% in above vector
qs=1;
% current queue size
X=X(2:length(X));
while length(X)>0
   if X(1)<Z(1)
% next point is arrival
      qs=qs+1;
% increase queue size
      xaxis=[xaxis xaxis(length(xaxis)) X(1)];
      yaxis=[yaxis qs qs];
      X=X(2:length(X)); 
   else
% next point is departure
      qs=qs-1; % decrease queue size
      xaxis=[xaxis xaxis(length(xaxis)) Z(1)];
      yaxis=[yaxis qs qs];
      Z=Z(2:length(Z));
   end
end
plot(xaxis,yaxis)
% plot realization of birth/death 
% process
xlabel('time (hours)');
ylabel('queue size')
If the birth–death process is truly modeling the size of a population of some organism, then it 
would be reasonable to consider the case when 
.  That is, when the population size 
reaches zero, no further births can occur.  In that case, the species is extinct and the state 
 is an absorbing state.  A fundamental question would then be, is extinction a certain 
event and if not what is the probability of the process being absorbed into the state of 
extinction?  Naturally, the answer to these questions would depend on the starting population 
size.  Let 
 be the probability that the process eventually enters the absorbing state, given that 
it is initially in state .  Note that if the process is currently in state , after the next transition, 
the birth–death process must be either in state 
 or state 
.  The time to the next birth, 
, is a random variable with an exponential distribution with a mean of 
, while the time 
to the next death is an exponential random variable, 
, with a mean of 
.  Thus, the 
process will transition to state 
 if 
, otherwise it will transition to state 
.  The 
reader can easily verify that 
.  The absorption probability can then 
be written as
"0
0
=
X t 
0
=
qi
i
i
i
1
–
i
1
+
Bi
1 "i

Di
1 i

i
1
+
Bi
Di

i
1
–
Pr Bi
Di



"i
"i
i
+



=


408    Chapter 9
www.Academicpress.com
(9.45)
This provides a recursive set of equations that can be solved to find the absorption 
probabilities. To solve this set of equations, we rewrite them as
, 
.
(9.46)
After applying this recursion repeatedly and using the fact that 
,
.
(9.47)
Summing this equation from 
 results in
.
(9.48)
Next, suppose that the series on the right hand side of the previous equation diverges as 
.  Since the 
 are probabilities, the left hand side of the equation must be bounded, 
which implies that 
. Then from Equation (9.47), it is determined that 
 must be equal 
to 1 for all .  That is, if
,
(9.49)
then absorption will eventually occur with probability 1 regardless of the starting state.  If 
 (absorption is not certain), then the preceding series must converge to a finite number.  
qi
Pr absorbtion in state i


=
Pr absorbtion next state is i
1
+

in state i


=
Pr absorbtion next state is i
1
–

in state i


+
Pr absorbtion in state i
1
+

Pr next state is i
1
+
in state i


Pr absorbtion in state i
1
–

Pr next state is i
1
–
in state i


+
qi
1
+
"i
"i
i
+
----------------
qi
1
–
i
"i
i
+
----------------
+
  i = 1 2 3  .
  

=
=
qi
1
+
qi
–
i
"i
----- qi
qi
1
–
–


=
i
1 2 3 
  
=
q0
1
=
qi
1
+
qi
–
q1
1
–


j
"j
-----
j
1
=
i
#
=
i
1 2  n
 

=
qn
1
+
q1
–
q1
1
–


j
"j
-----
j
1
=
i
#
i
1
=
n

=
n


qi
q1
1
=
qn
n
j
"j
-----
j
1
=
i
#
i
1
=



=
q1
1


Markov Processes    409
www.Academicpress.com
It is expected in that case that as 
, 
.  Passing to the limit as 
 in Equation 
(9.48) then allows a solution for 
 of the form
.
(9.50)
Furthermore, the general solution for the absorption probability is
.
(9.51)
Example 9.15:  
Consider a population model where both the birth and death rates are proportional to 
the population, 
, 
.  For this model,
 for 
.
Therefore, if 
, the series diverges and the species will eventually reach extinction 
with probability 1.  If 
, 
,
and the absorption (extinction) probabilities are
, 
.
Continuous time Markov processes do not necessarily need to have a discrete amplitude as in 
the previous examples.  In the following, we discuss a class of continuous time, continuous 
amplitude Markov processes.  To start with, it is noted that for any time instants 
, 
the conditional PDF of a Markov process must satisfy the Chapman–Kolmogorov equation
.
(9.52)
n


qn
0

n


q1
q1
j
"j
-----
j
1
=
i
#
i
1
=


1
j
"j
-----
j
1
=
i
#
i
1
=


+
-----------------------------------
=
qn
j
"j
-----
j
1
=
i
#
i
n
=


1
j
"j
-----
j
1
=
i
#
i
1
=


+
-----------------------------------
=
"n
n"
=
n
n
=
j
"j
----
j
1
=
i
#
i
1
=



"---
j
1
=
i
#
i
1
=



"---
 
  i
i
1
=


 "

1
 "

–
-------------------

"

–
------------
=
=
=
=
"


"


"


j
"j
----
j
1
=
i
#
i
n
=


"---
 
  i
i
n
=

 "


n
1
 "

–
-------------------
=
=
qn

"---
 
  n
=
n
1 2 3 
  
=
t0
t1
t2


f x2 t2

x0 t0



f x2 t2

x1 t1


f x1 t1

x0 t0


 x1
d

–

%
=



410    Chapter 9
www.Academicpress.com
This is just the continuous amplitude version of Equation (9.31).  Here, we use the notation 
 to represent the conditional probability density of the process 
 at the 
point 
 conditioned on 
.  Next, suppose we interpret these time instants as 
, 
, and 
.  In this case, we interpret 
 as the the 
infinitesimal change in the process that occurs during the infinitesimal time instant 
 and 
 is the PDF of that increment.  
Define 
 to be the characteristic function of 
:
.
(9.53)
We note that the characteristric function can be expressed in a Taylor series as
,
(9.54)
where 
 is the kth moment of the increment 
.  Taking 
inverse transforms of this expression, the conditional PDF can be expressed as
.
(9.55)
Inserting this result into the Chapman–Kolmogorov equation, Equation (9.52), results in
.
(9.56)
Subtracting 
 from both sides of this equation and dividing by 
 results in
.
(9.57)
f x2 t2

x1 t1



X t2


x2
X t1


x1
=
t0
0
=
t1
t
=
t2
t
t
!
+
=
x2
x1
–
x
!
=
t
!
f x2 t2

x1 t1



& x
!
'


x
!
x2
x1
–
=
& x
!
'


E ej' x
!


ej' x2
x1
–

f x2 t
t
!
+

x1 t

 x2
d

–

%
=
=
& x
!
'


Mk x1 t


k!
---------------------- j'

k
k
0
=

=
Mk x1 t


E
x2
x1
–

k
x1 t




=
x
!
f x2 t
t
!
+

x1 t


Mk x1 t


k!
----------------------
1
–

k
x2
k
k
(
(
) x2
x1
–


(
)
k
0
=

=
f x2 t
t
!
+

x0 t0



1
–

k
k!
-------------
k
0
=

Mk x1 t


x2
k
k
(
( ) x2
x1
–

f x1 t
x0 t0


 x1
d

–

%
=
1
–

k
k!
-------------
x2
k
k
(
(
Mk x2 t

f x2 t
x0 t0





k
0
=

=
f x2 t
x0 t0



1
–

k
k!
-------------
x2
k
k
(
(
Mk x2 t

f x2 t
x0 t0





k
1
=

+
=
f x2 t
x0 t0



t
!
f x2 t
t
!
+

x0 t0



f x2 t
x0 t0



–
t
!
---------------------------------------------------------------------------------
1
–

k
k!
-------------
x2
k
k
(
(
Mk x2 t


t
!
----------------------f x2 t
x0 t0



k
1
=

=

Markov Processes    411
www.Academicpress.com
Finally, passing to the limit as 
 results in the partial differential equation
,
(9.58)
where the function 
 is defined as
.
(9.59)
For many processes of interest, the PDF of an infinitesimal increment can be accurately 
approximated from its first few moments and hence we take 
 for 
.  For such 
processes, the PDF must satisfy 
.
(9.60)
This is known as the (one-dimensional) Fokker–Planck equation and is used extensively in 
diffusion theory to model the dispersion of fumes, smoke, and similar phenomenon.  
In general, the Fokker–Planck equation is notoriously difficult to solve and doing such is well 
beyond the scope of this text.  Instead, we consider a simple special case where the functions 
 and 
 are constants, in which case the Fokker–Planck equation reduces to
,
(9.61)
where in diffusion theory, 
 is known as the coefficient of diffusion and  is the drift.  This 
equation is used in models that involve the diffusion of smoke or other pollutants in the 
atmosphere, the diffusion of electrons in a conductive medium, the diffusion of liquid 
pollutants in water and soil, and the difussion of plasmas.  This equation can be solved in 
several ways.  Perhaps one of the easiest methods is to use Fourier transforms.  This is 
explored further in the exercises where the reader is asked to show that (taking 
 and 
) the solution to this diffusion equation is
.
(9.62)
That is, the PDF is Gaussian with a mean and variance which changes linearly with time.  For 
the case when 
, this is the Wiener process discussed in Section 8.5.  The behavior of 
this process is explored in the next example.
t
0

!
t
(
( f x t
x0 t0



1
–

k
k!
-------------
xk
k
(
(
Kk x t

f x t
x0 t0





k
1
=

=
Kk x t


Kk x t


E
X t
t
!
+


X t 
–

k X t 


t
!
--------------------------------------------------------------------
t
!
0

lim
=
Kk x t


0
=
k
2

t
(
( f x t
x0 t0



x
(
(
–
K1 x t

f x t
x0 t0



(
)
1
2---
x2
2
(
(
K2 x t

f x t
x0 t0



(
)
+
=
K1 x t


K2 x t


t
(
( f x t
x0 t0



2c x
(
( f x t
x0 t0



–
D
x2
2
(
( f x t
x0 t0



+
=
D
c
x0
0
=
t0
0
=
f x t
x0= 0 t0= 0



1
4Dt
-----------------
x
2ct
–

2
4Dt
------------------------
–




exp
=
c
0
=

412    Chapter 9
www.Academicpress.com
Example 9.16:  
In this example, we model the diffusion of smoke from a forest fire that 
starts in a National Park at time 
 and location 
.  The smoke 
from the fire drifts in the positive  directioin due to wind blowing at 10 
miles per hour, and the diffusion coefficient is 1 square mile per hour.  The 
probability density function is given in Equation (9.62).  We provide a 
three-dimensional rendition of this function in Figure 9.5 using the following MATLAB 
program.  
c=10;
% drift
D=1;
% Diffusion coefficient
tpoints=[0.25, 0.5, 1, 1.5, 2];
% time samples
x=[0:0.1:50];
% x-axis
for k=1:length(tpoints)
   t=tpoints(k);
% set t
   pdf(k,:)=exp(-(x-2*c*t).^2/(4*D*t))/sqrt(4*pi*D*t);
%f(x,t)
t
0
=
x
0
=
x
0
5
10
15
20
25
30
35
40
45
50
0
0.5
f(x,0.25)
0
5
10
15
20
25
30
35
40
45
50
0
0.5
f(x,0.5)
0
5
10
15
20
25
30
35
40
45
50
0
0.5
f(x,1)
0
5
10
15
20
25
30
35
40
45
50
0
0.5
f(x,1.5)
0
5
10
15
20
25
30
35
40
45
50
0
0.5
f(x,2)
x (miles)
Figure 9.5 
Observations of the PDF at different time instants showing the drift and dispersion of smoke 
for Example 9.16.


Markov Processes    413
www.Academicpress.com
   subplot(5,1,k)
   plot(x,pdf(k,:))
% plot PDF
   axis([0 max(x) 0 1.1*max(max(pdf))])
   s=num2str(t);
   leftstr='f(x,';
   rightstr=')';
   txt=[leftstr s rightstr];
   ylabel(txt)
end
xlabel('x (miles)')
9.5 Engineering Application: A Computer Communication Network
Consider a local area computer network where a cluster of nodes are connected by a common 
communication line.  Suppose for simplicity that these nodes occasionally need to transmit a 
message of some fixed length (referred to as a packet).  Also, assume that the nodes are 
synchronized so that time is divided into slots, each of which is sufficiently long to support 
one packet.  In this example, we consider a random access protocol known as slotted Aloha.  
Messages (packets) are assumed to arrive at each node according to a Poisson process.  
Assuming there are a total of  nodes, the packet arrival rate at each node is assumed to be 
 so that the total arrival rate of packets is fixed at 
 packets/slot.  In slotted Aloha, every 
time a new packet arrives at a node, that node attempts to transmit that packet during the next 
slot.  During each slot, one of three events can occur:(1) no node attempts to transmit a packet, 
in which case the slot is said to be idle; (2) exactly one node attempts to transmit a packet, in 
which case the transmission is successful; (3) more than one node attempts to transmit a 
packet, in which case a collision is said to have occurred.  All nodes involved in a collision 
will need to retransmit their packets, but if they all retransmit during the next slot, then they 
will continue to collide and the packets will never be successfully transmitted.  All nodes 
involved in a collision are said to be backlogged until their packet is successfully transmitted.  
In the slotted Aloha protocol, each backlogged node chooses to transmit during the next slot 
with probability  (and hence chooses not to transmit during the next slot with probability 
).  Viewed in an alternative manner, every time a collision occurs, each node involved 
waits a random amount of time until they attempt retransmission, where that random time 
follows a geometric distribution.  
This computer network can be described by a Markov chain, 
 = number of backlogged 
nodes at the end of the th slot.  To start with, we evaluate the transition probabilities of the 
Markov chain, 
.  Assuming that there are an infinite number of nodes (or a finite number 
of nodes each of which could store an arbitrary number of backlogged packets in a buffer), we 
note that
,
(9.63)
n
" n

"
p
1
p
–
Xk
k
pi j
Pr m backlogged nodes attempt to transmit Xk=n


n
m
 
  pm 1
p
–

n
m
–
=


414    Chapter 9
www.Academicpress.com
.
(9.64)
Using these equations, it is straightforward to determine that the transition probabilities are 
given by
(9.65)
In order to get a feeling for the steady-state behavior of this Markov chain, we define the drift 
of the chain in state  as
.
(9.66)
Given that the chain is in state , if the drift is positive, then the number of backlogged nodes 
will tend to increase; whereas, if the drift is negative, the number of backlogged nodes will 
tend to decrease.  Crudely speaking, a drift of zero represents some sort of equilibrium for the 
Markov chain.  Given the preceding transition probabilities, the drift works out to be
.
(9.67)
Assuming that 
, then we can use the approximations 
 and 
 to 
simplify the expression for the drift,
,  
where 
.
(9.68)
The parameter 
 has the physilcal interpretation of the average number of transmissions 
per slot given there are  backlogged states.  To understand the significance of this result, the 
two terms in the expression for the drift are plotted in Figure 9.6.  The first term, 
, has the 
interpretation of the average number of new arrivals per slot, while the second term, 
, is the average number of successful transmissions per slot or the average departure 
rate.  For a very small number of backlogged states, the arrival rate is greater than the 
departure rate and the number of backlogged states tends to increase.  For moderate values of 
, the departure rate is greater than the arrival rate and the number of backlogged states tends 
to decrease.  Hence, the drift of the Markov chain is such that the system tends to stabilize 
Pr m new arrivals Xk=n


"m
m!
-------e "
–
=
pi j
0,
for j
i
1,
–

ip i
p
–

i
1
– e "
– ,
for j=i
1,
–
1
" 1
p
–

i
ip 1
p
–

i
1
–
–
+

e "
– , for j=i,
1
1
p
–

i
–

"e "
– ,
for j=i
1,
+
"j
i
–
j
i
–

!
----------------e "
– ,
for j
i
1.
+











	
=
i
di
E Xk
1
+
Xk = i


i
–
=
i
di
"
1
p
–

i
1
– e "
–
ip
" 1
p
–


+


–
=
p
1
«
1
p
–


1
*
1
p
–

i
e ip
–
*
di
"
g i e g i 
–
–
*
g i 
"
ip
+
=
g i 
i
"
g
g
–


exp
i

Markov Processes    415
www.Academicpress.com
around the point marked stable equilibrium in Figure 9.6.  This is the first point where the two 
curves cross.  Note, however, that for very large , the drift becomes positive again.  If the 
number of backlogged states ever becomes large enough to push the system to the right of the 
point marked unstable equilibrium in the figure, then the number of backlogged nodes will 
tend to grow without bound and the system will become unstabe.  
Note that the value of 
 represents the throughput of the system.  If we try to use a value of 
 
which is greater than the peak value of 
, then the drift will always be positive and 
the system will be unstable from the beginning.  This maximum throughput occurs when 
 and has a value of 
.  By choosing an arrival rate less than 
, we 
can get the system to operate near the stable equilibrium, but sooner or later, we will get a 
string of bad luck and the system will drift into the unstable region.  The lower the arrival rate, 
the longer it will take (on average) for the system to become unstable, but at any arrival rate, 
the system will eventually reach the unstable region.  Thus, slotted Aloha is inherently an 
unstable protocol.  As a result, various modifications have been proposed which exhibit stable 
behavior.  
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
g(i)
Stable equilibrium
Unstable equilibrium
λ
ge–g
i = 0
Figure 9.6 
Arrival rate and successful transmission rate for a slotted Aloha system.
i
"
"
g
g
–


exp
g i 
1
=
"max
1 e

=
"max

416    Chapter 9
www.Academicpress.com
9.6 Engineering Application: A Telephone Exchange
Consider a base station in a cellular phone system.  Suppose calls arrive at the base station 
according to a Poisson process with some arrival rate 
.  These calls are initiated by mobile 
units within the cell served by that base station.  Furthermore, suppose each call has a duration 
that is an exponential random variable with some mean, 
.  The base station has some 
fixed number of channels, 
, that can be used to service the demands of the mobiles in its cell.  
If all 
 channels are being used, any new call that is initiated cannot be served and the call is 
said to be blocked.  We are interested in calculating the probability that when a mobile initiates 
a call, the customer is blocked.  
Since the arrival process is memoryless and the departure process is memoryless, the number 
of calls being serviced by the base station at time , 
, is a birth–death Markov process.  
Here, the arrival rate and departure rates (given there are  channels currently being used) 
are given by
  
,  
.
(9.69)
The steady-state distribution of this Markov process is given by Equation (9.44).  For this 
example, the distribution is found to be
. 
(9.70)
The blocking probability is just the probability that when a call is initiated, it finds the system 
in state 
.  In steady state, this is given by 
 and the resulting blocking probability is the 
so-called Erlang-B formula,
.  
(9.71)
This equation is plotted in Figure 9.7 for several values of 
.  The horizontal axis is the ratio 
of 
 which is referred to in the telephony literature as the traffic intensity.  As an example 
of the use of this equation, suppose a certain base station had 60 channels available to service 
incoming calls.  Furthermore, suppose each user initiated calls at a rate of 1 call per 3 hours 
"
1 

m
m
t X t 
n
"n
",      0
n
m,


0,
n = m,


	
=
n
n
=
0
n
m


n
"i
1
–
i
------------
i
1
=
n
#
1
"i
1
–
i
------------
i
1
=
j
#
j
1
=
m

+
------------------------------------------
1
n!
----- "
---
 
  n
1
j!--- "
---
 
  j
j
0
=
m

-------------------------
=
=
m
m
Pr blocked call


1
m!
------ "
---
 
  m
1
j!--- "
---
 
  j
j
0
=
m

-------------------------
=
m
" 


Markov Processes    417
www.Academicpress.com
and calls had an average duration of 3 minutes (0.05 hours).  If a 2% probability of blocking is 
desired, then from Figure 9.7 we determine that the system can handle a traffic intensity of 
approximately 50 Erlangs.  Note that each user generates an intensity of
.
(9.72)
Hence, a total of 50*60 = 3000 mobile users per cell could be supported while still 
maintaining a 2% blocking probability.
10-1
100
101
102
10-3
10-2
10-1
100
Traffic intensity (Erlangs)
Blocking probability
From left to right m=1, 2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90, 100
Figure 9.7  
The Erlang-B formula.
"
---
1
3 hour



1
0.05 hour



-----------------------------------
1
60
------  Erlangs
=
=

419
CHAPTER 9
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 9.1:  Definition and Examples of Markov Processes
9.1
For a Markov chain, prove or disprove the following statement:
9.2
A Diffusion Model - Model the diffusion of electrons and holes across a potential barrier 
in an electronic device as follows. We have  black balls (electrons) in urn A and  
whiteballs (holes) in urn B. An experimental outcome selects randomly one ball from 
each urn. The ball from urn A is placed in urn B and that from urn B is placed in A. Let 
the state of the process be the number of black balls in urn A. (By knowing the number of 
black balls in urn A, we know the composition of both urns.) Let  denote the state of 
the process.  Find the transition probabilities, 
.
9.3
Let 
 be the sum of  independent rolls of a fair (cubicle) die.
(a)
Is 
 a Markov chain?
(b)
Define a new process according to 
.  That is, 
 is related to 
 by 
 for a non-negative 
integer .  Find the transition probability matrix for the process 
.
(c)
Now suppose 
.  Find the transition matrix for 
.  
9.4
Suppose we label the spaces on a monopoly board as 
 where,
0 = Go,
1 = Mediterranean Ave.,
2 = Community Chest,
3 = Baltic Ave.,
...
39 = Boardwalk.
Let 
 be the location of a player after  turns.  On each turn, a player moves by 
rolling two (six-sided) dice and moving forward the number of places indicated by the 
sum of the two dice.  Any time the roll of the dice causes the player to land on space 30 
(Go to Jail) the player’s token is immediately moved to space 10 (Jail).  Describe the 
elements of the transition probability matrix, 
, for the monopoly Markov chain 
.
Pr Xk = ik Xk
1
+
= ik
1
+
Xk
2
+
= ik
2
+
 Xk
m
+
= ik
m
+





Pr Xk = ik Xk
1
+
= ik
1
+


=
n
n
k
pi j
X n
 
n
X n
 
Y n
 
X n
  mod 3
=
Y n
 
0 1 2
 

	

X n
 
X n
 
3q
Y n
 
+
=
q
Y n
 
Z n
 
X n
  mod 5
=
Z n
 
0 1 2  39
  


	
X k
 
k
pi j
X k
 

420    Chapter 9
www.Academicpress.com
9.5
 balls labeled 1 through 
 are placed in Box 1 while a Box 2 is initially empty.  At 
each time instant, one of the 
 balls is chosen (with equally probability) and moved to 
the other box.  Let 
 be the number of balls in Box 1 at time instant .  Draw a state 
diagram and find the transition probability matrix for this Markov chain.  Note:  This is 
known as the Ehrenfest chain and was developed by the dutch Physicist Paul Ehrenfest 
for the study of molecular dynamics.
9.6
An Inventory Model - A hot dog vendor operates a stand where the number of hot dogs 
he sells each day is modeled as a Poisson random variable with a mean value of 100.  Let 
 represent the number of hot dogs the vendor has at the beginning of each day.  At 
the end of the day, if his inventory of hot dogs on hand falls below some minimum value, 
, then the vendor goes out that evening and purchses enough hot dogs to bring the total 
of his inventory to 
.  Write an equation to describe the elements of the transition 
probability matrix, 
, for this inventory process.
9.7
A Web Search Engine Model - Suppose after we enter some keywords into our web 
search engine it finds five pages that contain those keywords.  We will call these pages A, 
B, C, D, and E.  The engine would like to rank the pages according to some measure of 
importance.  To do so, we make note of which pages contain links to which other pages.  
Suppose we find the following links.
We then create a random walk where the initial state is equally likely to be any one of the 
five pages.  At each time instant, the state changes with equal probabilty to one of the 
pages for which a link exists.  For example, if we are currently in state A, then at the next 
time instant we will transition to either state B or state C with equal probability.  If we 
Page
Has links to 
pages
A
B, C
B
C, D, E
C
A,E
D
A, B, C, E
E
B, D
N
N
N
X k
 
k
X k
 


pi j

Exercises    421
www.Academicpress.com
are currently in state B, we will transition to state C, D, or E with equal probability, and 
so on.  Draw a transition diagram and find the probability transition matrix for this 
Markov chain.  Note: This process forms the basis for the PageRank algorithm used by 
Google.
Section 9.2:  Calculating Transition and State Probabilities
9.8
Consider a two-state Markov chain with a general transition probability matrix
,
where 
.  Find an expression for the -step transition probability matrix, 
.
9.9
For the general two-state Markov chain of Exercise 9.8, suppose the states are called 0 
and 1.  Furthermore, suppose 
 and 
.  
(a)
Find 
.
(b)
Find 
.
(c)
Find 
.  Is it the same as 
?
9.10 A square matrix 
 is called a stochastic matrix if all of its elements satisfy 
 
and, furthermore, 
 for all .  Every stochastic matrix is the transition 
probability matrix for some Markov chain; however, not every stochastic matrix is a 
valid two-step transition probability matrix.  Prove that a 2 2 stochastic matrix is a 
valid two-step transition probability matrix for a two-state Markov chain if and only if 
the sum of the diagonal elements is greater than or equal to 1.
9.11 A PCM waveform has the two states +1 and 0. Suppose the transition matrix is
.
The initial value of the waveform is determined by the flip of a coin, with the outcome of 
a head corresponding to +1 and a tail to 0. 
(a)
What is the probability that the waveform will be at +1 after one step if the coin is a 
fair coin? 
(b)
Find the same probability if the coin is biased such that a head occurs with 
probability 
. 
(c)
Repeat the problem for two steps.
P
1
p
–
p
q
1
q
–
=
0
p q
1



n
Pn
Pr X0=0


s
=
Pr X0=1


1
s
–
=
Pr X1= 0 X2= 1



Pr X1= 1 X0= 0 X2= 0



Pr X2 = X1


Pr X1 = X0


P
0
pi j
1


pi j
j

1
=
i
P
0.5
0.5
0.25 0.75
=
1 3


422    Chapter 9
www.Academicpress.com
9.12 A three-state Markov chain has the following transition matrix:
.
(a)
Does this Markov chain have a unique steady-state probability vector? If so, find it. 
(b)
What is the approximate value of 
?  What interpretation do you give to this 
result?
(c)
What is the probability that after the third step you are in state 3 if the initial state 
probability vector is (1/3 1/3 1/3)?
9.13 The three letters C, A, and T represent the states of a word-generating system. Let the 
initial state probability vector be (1/3 1/3 1/3) for the three letters, respectively. The 
transition matrix is given as
.
What is the probability of generating a proper three-letter English dictionary word after 
two transitions from the initial state?
9.14 Two students play the following game. Two dice are tossed. If the sum of the numbers 
showing is less than 7, student A collects a dollar from student B. If the total is greater 
than 7, then student B collects a dollar from student A. If a 7 appears, then the student 
with the fewest dollars collects a dollar from the other. If the students have the same 
amount, then no dollars are exchanged. The game continues until one student runs out of 
dollars. Let student A's number of dollars represent the states. Let each student start with 
3 dollars. 
(a)
What is the transition matrix, 
? 
(b)
If student A reaches state 0 or 6, then he stays there with probability 1.  What is the 
probability that student B loses in 3 tosses of the dice? 
(c)
What is the probability that student A loses in 5 or fewer tosses ?
9.15 A biologist would like to estimate the size of a certain population of fish.  A sequential 
approach is proposed whereby a member of the population is sampled at random, tagged 
and then returned.  This process is repeated until a member is drawn that has been 
previously tagged.  If desired, we could then begin tagging again with a new kind of tag.  
Let 
 be the trial at which the first previously tagged fish is sampled and 
 be the total 
P
0.25 0.5 0.25
0.4 0.6
0
1
0
0
=
p1 3

100


P
C
A
T
 C  A  T 
0.1 0.7 0.2
0.6 0.1 0.3
0.1 0.8 0.1
=
P
M
N

Exercises    423
www.Academicpress.com
population size.  This process can be described in terms of a Markov chain where 
 is 
the number of successive untagged members observed.  That is, 
 for 
 and 
.
(a)
For a fixed 
, find the form of the transition probability matrix.
(b)
Find 
 for 
.
9.16 A person with a contagious disease enters the population.  Every day he either infects a 
new person (which occurs with probability ) or his symptoms appear and he is 
discovered by health officials (which occurs with probability 
).  Assuming all 
infected persons behave in the same manner, compute the probability distribution of the 
number of infected but undiscovered people in the population at the time of first 
discovery of the disease.
9.17 A certain three-state Markov chain has a transition probability matrix given by
.
Determine if the Markov chain has a unique steady-state distribution or not.  If it does, 
find that distribution.
9.18 Suppose a process can be considered to be in one of two states (let’s call them state A 
and state B), but the next state of the process depends not only on the current state but 
also on the previous state as well.  We can still describe this process using a Markov 
chain, but we will now need four states.  The chain will be in state 
, 
 if the process is currently in state 
 and was previously in state 
.  
(a)
Show that the transition probability matrix of such a four-state Markov chain must 
have zeros in at least half of its entries.
(b)
Suppose that the transition probability matrix is given by
.
Find the steady-state distribution of the Markov chain.
(c)
What is the steady-state probability that the underlying process is in state A?
Xk
Xk
k
=
k
1 2  M
1
–
 

=
XM
0
=
N
n
=
Pr M = m X0= 0


m
2 3 4  n
  

=
p
1
p
–
P
0.4 0.5 0.1
0.05 0.7 0.25
0.05 0.5 0.45
=
X Y



X Y
A B


	


X
Y
P
A A



A B



B A



B B



A A



A B



B A



B B



0.8      0.2      0      
0      
0      
0      0.4      0.6      
0.6      0.4      0      
0      
0      
0      0.1      0.9      
=

424    Chapter 9
www.Academicpress.com
9.19 A communication system sends data in the form of packets of fixed length.  Noise in the 
communication channel may cause a packet to be received incorrectly.   If this happens, then 
the packet is retransmitted.  Let the probability that a packet is received incorrectly be .   
(a)
Determine the average number of transmissions that are necessary before a packet 
is  received correctly. Draw a state diagram for this problem.
(b)
Let the the transmission time be 
 seconds for a packet.  If the packet is received 
incorrectly, then a message is sent back to the transmitter stating that the message 
was received incorrectly. Let the time for sending such a message be 
. Assume 
that if the packet is received correctly that we do not send an acknowledgment.   
What is the average time for a successful transmission ? Draw a state diagram for 
this problem.
(c)
Now suppose there are three nodes. The packet is to be sent from node 1 to node 2 
to node 3 without an error. The probability of the packets being received incorrectly 
at each node is the same and is . The transmission time is 
 and the time to 
acknowledge that a packet is received incorrectly is 
. Draw a state diagram for 
this problem. Determine the average time for the packet to reach node 3 correctly.
9.20 Consider the scenario of Example 9.2 where a child buys kid’s meals at a local restaurant 
in order to complete his collection of superhero action figures.  Recall the states were 
 where 
 represents the number of distinct action figures 
collected after  meals are purchased.
(a)
Find an expression for 
, the probability of having a complete set if  meals are 
purchased.
(b)
Find the probability that the set is first completed after purchasing  meals.
(c)
Find the average number of meals that must be purchased to complete the set.
9.21 Find the steady-state probability distribution for the web search engine model of 
Exercise 9.7.  It is this distibution that is used as the ranking for the each web page and 
ultimately determines which pages show up on the top of your list when your search 
results are displayed.
Section 9.3:  Characterization of Markov Chains
9.22 A random waveform is generated as follows. The waveform starts at 0 voltage. Every 
 
seconds, the waveform switches to a new voltage level.  If the waveform is at a voltage 
level of 0 volts, it may move to +1 volt with probability  or it may move to 1 volt with 
probability 
.  Once the waveform is at +1 (or 1), the waveform will return 
(with probability 1) to 0 volts at the next switching instant. 
(a)
Model this process as a Markov chain.  Describe the states of the system and give 
the transition probability matrix.
q
Tt
Ta
q
Tt
Ta
X k
 
0 1 2 3 4
   

	

X k
 
k
p0 4

n
 
n
n
ts
p
q
1
p
–
=

Exercises    425
www.Academicpress.com
(b)
Determine whether each state is periodic or aperiodic.  If periodic, determine the 
period of each state.
(c)
For each instant of time, determine the PMF for the value of the waveform.
9.23 A student takes this course at period 1 on Monday, Wednesday, and Friday. Period 1 
starts at 7:25 A.M. Consequently, the student sometimes misses class.  The student’s 
attendance behavior is such that she attends class depending only on whether or not she 
went to the last class. If she attended class on one day, then she will go to class the next 
time it meets with probability 1/2. If she did not go to one class, then she will go to the 
next class with probability 3/4. 
(a)
Find the transition matrix 
. 
(b)
Find the probability that if she went to class on Wednesday that she will attend class 
on Friday.
(c)
Find the probability that if she went to class on Monday that she will attend class on 
Friday.
(d)
Does the Markov chain described by this transition matrix have a steady-state 
distribution?  If so, find that distribution.
9.24 Let 
 be the sum of  independent rolls of a fair (cubicle) die.  
(a)
Find 
.
(b)
Find 
.
9.25 For a Markov chain with each of the transition probability matrices in (a)–(c), find the 
communicating classes and the periodicity of the various states.
(a)
,
(b)
, 
(c)
.
9.26 Prove that if 
, then 
 and hence all states in the same class must have 
the same period.
9.27 Demonstrate that the two generating functions defined in Equations (9.18) and (9.19) are 
related by
.
P
Xn
n
Pr Xn is a multiple of 3


n


lim
Pr Xn is a multiple of 5


n


lim
0 0 1 0
1 0 0 0
1
2--- 1
2--- 0 0
1
3--- 1
3--- 1
3--- 0
0 1 0 0
0 0 0 1
0 1 0 0
1
3--- 0 2
3--- 0
0 1 0 0
1
2--- 0 0 1
2---
0 0 0 1
0 1
2--- 1
2--- 0
i
j

d i 
d j 
=
Pi i
z 
1
–
Pi i
z Fi i
z 
=

426    Chapter 9
www.Academicpress.com
9.28 Define the generating functions
 and 
.
(a) 
Show that 
.
(b) Prove that if state  is a transient state, then for all ,
.
9.29 Verify that recurrence is a class property.  That is, if one state in a communicating class is 
recurrent then all are recurrent, and if one is transient then all are transient.
9.30 Suppose a Bernoulli trial results in a success with probability  and a failure with 
probability 
.  Suppose the Bernoulli trial is repeated indefinitely with each 
repitition independent of all others.  Let 
 be a “success runs” Markov chain where 
 
represents the number of most recent consecutive successes that have been observed at 
the th trial.  That is, 
 if trial numbers 
 were all 
successes but trial number 
 was a failure.  Note that 
 if the th trial was a 
failure.
(a)
Find an expression for the one-step transition probabilities, 
.
(b)
Find an expression for the -step first return probabilities for state 0, 
.
(c)
Prove that state 0 is recurrent for any 
.  Note that since all states 
communicate with one another, this result together with the result of Exercise 9.29 
is sufficient to show that all states are recurrent.
9.31 Find the steady-state distribution of the success runs Markov chain described in 
Exercise 9.30.
Section 9.4:  Continuous Time Markov Processes
9.32 Derive the backward Kolmogorov equations,
.
9.33 In this problem, you will demonstrate that the Gaussian PDF in Equation (9.64) is in fact 
the solution to the diffusion Equation (9.63).  To do this, we will use frequency domain 
Pi j
z 
pi j
n
 zn
n
0
=


=
Fi j
z 
fi j
n
 zn
n
0
=


=
Pi j
z 
Fi j
z Pjj z 
=
j
i
pi j
n
 
n
1
=




p
1
p
–
Xn
Xn
n
Xn
m
=
n n
1
–
n
2
–
 n
m
–
1
+




n
m
–
Xn
0
=
n
pi j
n
f0 0

n
 
0
p
1


d
dt
-----pi j
t 
ipi
1
+
j
t 
i
i
+

pi j
t 
–
ipi
1
–
j
t 
+
=

Exercises    427
www.Academicpress.com
methods.  Define 
 to be the 
time-varying characteristic function of the random process 
.  
(a) 
Starting from the diffusion Equation (9.63), show that the characteristic function 
must satisfy
.
Also, determine the appropriate initial condition for this differential equation.  That 
is, find 
.
(b)
Solve the first-order differential equation in part (a) and show that the characteristic 
function is of the form
.
(c)
From the characteristic function, find the resulting PDF given by Equation (9.62).
MATLAB Exercises
9.34 On the first day of the new year it is cloudy.  What is the probability that it is sunny on 
July 4 if the following transition matrix applies?
.
How much does your answer change if it is a leap year?
9.35 Determine which of the following transition matrices (a)–(g) represents a regular 
Markov chain.  Find the steady-state distribution for the regular matrices. Note a Markov 
chain is regular if some power of the transition matrix has only positive (non-zero) 
entries. This implies that a regular chain has no periodic states.
(a)  
,
(b)  
,
(c)  
,
(d)  
,
(e)  
,
(f)  
,
(g)  
.
  t


E ejX t 


f x t
x0= 0 t0= 0


ejx x
d

–


=
=
X t 
t

   t


2cj
D2
–

  t


=
  0



  t


D2
–
2cj
+


exp
=
sunny
cloudy
rainy
sunny cloudy rainy
0.7       0.2       0.1
0.3       0.2       0.5
0.3       0.3       0.4
1 3

2 3

5 6

1 6

0
1
1 4

3 4

0 1
1 0
1 5

4 5

1
0
1 2

1 2

0
0
1 2

1 2

1 3

1 3

1 3

1 3

0
2 3

0
1
0
0
1 5

4 5

1 2

1 4

1 4

1 3

2 3

0
0
1 4

3 4


428    Chapter 9
www.Academicpress.com
9.36 Write a MATLAB program to simulate a three-state Markov chain with the following 
transition probability matrix
.
Assuming that the process starts in the third state, generate a sequence of 500 states.  
Estimate the steady-state probability distribution, 
, using the sequence you generated.  
Does it agree with the theoretical answer? Does the steady-state distribution depend on 
the starting state of the process?
9.37 Write a MATLAB program to simulate the M/M/1 queueing system.  If you like, you 
may use the program provided in Example 9.14.  Use your program to estimate the 
average amount of time a customer spends waiting in line for service.  Assume an arrival 
rate of 
 customers/hour and an average service time of 
min.  Note, that 
if a customer arrives to find no others in the system, the waiting time is zero.  
9.38 Modify the program of Example 9.14 to simulate the M/M/
 queue of Example 9.13.  
Based on your simulation results, estimate the PMF of the number of customers in the 
system.  Compare your results with the analytical results found in Example 9.13.  
9.39 For the monopoly Markov chain described in Exercise 9.4, write a MATLAB program to 
construct the transition probability matrix.  Find the steady-state probability of being on 
each of the following spaces:
(a)
Go—space 0,
(b)
Jail—Space 10,
(c)
New York Ave.—Space 19,
(d)
Park Place—Space 37.
9.40 For the monopoly Markov chain described in Exercise 9.4, write a MATLAB program to 
simulate the movement of a token around the board keeping track of each space visited.  
Using your program estimate the relative frequency of visiting each of the spaces listed in 
Exercise 9.39.  Do your simulation results agree with the analytical results of Exercise 9.39.
P
1 2

1 4

1 4

1 2

0
1 2

1 4

1 4

1 2

=
p

15
=
1 

3
=


429
CHAPTER 10
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4-00010-3
© 2012 by Elsevier Inc. All rights reserved.
Power Spectral Density
In the study of deterministic signals and systems, frequency domain techniques (e.g., Fourier 
transforms) provide a valuable tool that allows the engineer to gain significant insights into a 
variety of problems.  In this chapter, we develop frequency domain tools for studying random 
processes.  This will prepare us for the study of random processes in linear systems in the next 
chapter.  
For a deterministic continuous signal, 
, the Fourier transform is used to describe its 
spectral content.  In this text, we write the Fourier transform as1
,
(10.1)
and the corresponding inverse transform is
.
(10.2)
For discrete-time signals, we could use a discrete Fourier transform or a z-transform.  The 
Fourier transform, 
, is referred to as the spectrum of 
 since it describes the spectral 
contents of the signal.  In general, 
 is a complex function of frequency and hence we also 
speak of an amplitude (magnitude) spectrum, 
, and a phase spectrum, 
.  In order 
to study random processes in the frequency domain, we seek a similar quantity which will 
describe the spectral characteristics of a random process.
The most obvious thing to do would be to try to define the Fourier transform of a random 
process as perhaps
x t 
X f 
x t 


x t e j2 ft
–
td

–


=
=
x t 
1
–
X f 


X f ej2ft fd

–


=
=
X f 
x t 
X f 
X f 
X f 
	
1 Even though we use an upper case letter to represent a Fourier transform, it is not necessarily random.  
Clearly, the Fourier transform of a non-random signal is also not random.  While this is inconsistent 
with our previous notation of using upper case letters to represent random quantities, this notation of 
using upper case letters to represent Fourier Transforms is so common in the literature, we felt it 
necessary to retain this convention.  The context should make it clear whether a function of frequency 
is random or not.

430    Chapter 10
www.Academicpress.com
;
(10.3)
however, this leads to several problems.  First of all, there are problems with existence.  Since 
 is a random process, there is not necessarily any guarantee that the integral exists for 
every possible realization, 
.  That is, not every realization of the random process may have 
a Fourier transform.  Even for processes that are well-behaved in the sense that every 
realization has a well-defined Fourier transform, we are still left with the problem that 
 is 
itself a random process.  In Chapter 8, we described the temporal characteristics of random 
processes in terms of deterministic functions such as the mean function and the autocorrelation 
function.  In a similar way, we seek a deterministic description of the spectral characteristics 
of a random process.  The power spectral density (PSD) function, which is defined in the next 
section, will play that role.  
10.1  Definition of PSD
To start with, for a random process 
, define a truncated version of the random process as
(10.4)
The energy of this random process is 
,
(10.5)
and hence the time-averaged power is
.
(10.6)
The last equality is obtained using Parseval’s theorem. The quantity 
 is the Fourier 
transform of 
. Since the random process has been truncated to a finite time interval, there 
will generally not be any problem with the existence of the Fourier transform. Note that 
 is a 
random variable and so to get the ensemble averaged power, we must take an expectation,
.
(10.7)
X f 
X t e j2ft
–
td

–


X t 


=
=
X t 
x t 
X f 
X t 
Xto t 
X t , t
to,

0,
t
to.






=
EXto
X2 t  td
to
–
to
Xto
2 t  td

–


=
=
PXto
1
2to
-------
Xto
2 t  td

–


1
2to
-------
Xto f  2 fd

–


=
=
Xto f 
Xto t 
PXto
PXto
E PXto


1
2to
-------
E Xto f  2

 fd

–


=
=

Power Spectral Density    431
www.Academicpress.com
The power in the (untruncated) random process 
 is then found by passing to the limit as 
,
.
(10.8)
Define 
 to be the integrand in equation (10.8). That is, let
.
(10.9)
Then, the average power in the process can be expressed as 
.
(10.10)
Therefore, this function of frequency which we have simply referred to as 
 has the 
property that when integrated over all frequency, the total power in the process is obtained.  In 
other words, 
 has the units of power per unit frequency and so it is the power density 
function of the random process in the frequency domain.  Hence, the quantity 
 is given 
the name PSD.  In summary, we have the following definition of PSD.
Definition 10.1:  For a random process 
, the power spectral density (PSD) is defined as 
,
(10.11)
where 
 is the Fourier transform of the truncated version of the process as 
described in equation (10.4)
Several properties of the PSD function should be evident from Definition 10.1 and from the 
development that lead to that definition:
(1) 
 is a real function.
(10.12a)
(2) 
 is a non-negative function.
(10.12b)
(3) 
 is an even function.
(10.12c)
(4) The average power in a random process is given by 
.
(10.12d)
X t 
to


PX
1
2to
-------
E Xto f  2

 fd

–


to


lim
E Xto f  2


2to
----------------------------
to


lim
fd

–


=
=
SXX f 
SXX f 
E Xto f  2


2to
----------------------------
to


lim
=
PX
SXX f  fd

–


=
SXX f 
SXX f 
SXX f 
X t 
SXX f 
E Xto f  2


2to
----------------------------
to


lim
=
Xto f 
SXX f 
SXX f 
SXX f 
PX
SXX f  fd

–


=

432    Chapter 10
www.Academicpress.com
Example 10.1:
As a simple example, consider a sinusoidal process 
 with random 
amplitude and phase.  Assume the phase is uniform over 
 and independent of the 
amplitude which we take to have an arbitrary distribution.  Since each realization of this 
process is a sinusoid at frequency 
, we would expect that all of the power in this 
process should be located at 
 (and 
).  Mathematically we have 
,
where 
 is a square pulse of unit height and unit width and centered at 
.  The 
Fourier transform of this truncated sinusoid works out to be
,
where the “sinc” function is 
.  We next calculate the expected value 
of the magnitude squared of this function.
.
The PSD function for this random process is then
.
To calculate this limit, we observe that as 
 gets large, the function 
 
becomes increasingly narrower and taller.  Thus, we could view the limit as an infinitely 
tall, infinitely narrow pulse. This is one way to define a delta function. One property of a 
delta function that is not necessarily shared by the function under consideration is that 
. Therefore, the limiting form of 
 will have to be a scaled (in amplitude) 
delta function.  To figure out what the scale factor needs to be, the integral of 
 is 
calculated:
.
Therefore, 
.
The resulting PSD is then simplified to
.
This is consistent with our intuition.  The power in a sinusoid with amplitude  is 
.  
Thus, the average power in the sinusoidal process is 
.  This power is evenly split 
between the two points 
 and 
.  
X t 
A
ot

+


sin
=
0 2


fo
f
fo
=
f
fo
–
=
Xto t 
A
ot

+

rect
t
2to
-------




sin
=
rect t 
t
0
=
Xto f 
jto
–
Aejsinc 2 f
fo
–

to


jtoAe j
– sinc 2 f
fo
+

to


+
=
sinc x
 
x


sin
x



=
E Xto f  2


E A2

to
2 sinc2 2 f
fo
–

to


sinc2 2 f
fo
+

to


+


=
SXX f 
E Xto f  2


2to
----------------------------
to


lim
E A2

to
2
------------------- sinc2 2 f
fo
–

to


sinc2 2 f
fo
+

to


+


to


lim
=
=
to
g f 
tosinc2 2fto


=
 f  fd

1
=
g t 
g f 
g f  fd

–


tosinc2 2fto

 fd

–


1
2---
sinc2 u
  u
d

–


1
2---
=
=
=
tosinc2 2fto


to


lim
1
2--- f 
=
SXX f 
E A2


4
---------------
f
fo
–



f
fo
+



+


=
A
A2 2

E A2

 2

f
fo
=
f
fo
–
=



Power Spectral Density    433
www.Academicpress.com
One important lesson to learn from the previous example is that even for very simplistic 
random processes, it can be quite complicated to evaluate the PSD using the definition given 
in Example 10.11.  The next section presents a very important result that allows us to greatly 
simplify the process of finding the PSD of many random processes.
10.2  The Wiener–Khintchine–Einstein Theorem
Theorem 10.1 (Wiener–Khintchine–Einstein): For a wide sense stationary (WSS) 
random process 
 whose autocorrelation function is given by 
, the PSD of 
the process is
.
(10.13)
In other words, the autocorrelation function and PSD form a Fourier transform pair.  
Proof: Starting from the definition of PSD,
(10.14)
Using the assumption that the process is WSS, the autocorrelation function is only 
a function of a single time variable, 
.  Hence, the expression above is 
rewritten as
.
(10.15)
It is noted that the preceding integrand is only a function of a single variable; 
therefore, with the appropriate change of variables, the double integral can be reduced 
to a single integral.  The details are given in the following.  
The region of integration is a square in the s-t plane of width 
 centered at the 
origin.  Consider an infinitesimal strip bounded by the lines 
 and 
. This strip is illustrated in Figure 10.1.  Let 
 be the area of that 
X t 
RXX 
 
SXX f 
RXX 
 


RXX 
 e j2f
–

d

–


=
=
E Xto f  2


E
X t X s e j2f t
s
–


–
td
s
d
to
–
to

to
–
to

E X t X s 

e j2 f t
s
–


–
td
s
d
to
–
to
to
–
to
RXX t s


e j2f t
s
–


–
td
s ·
d
to
–
to
to
–
to
=
=
=
t
s
–
E Xto f  2


RXX t
s
–

e j2 f t
s
–


–
td
s
d
to
–
to

to
–
to

=
2to
t
s
–

=
t
s
–

d
+
=
a 
 
 

434    Chapter 10
www.Academicpress.com
strip which falls within the square region of integration.  A little elementary geometry 
reveals that
(10.16)
To obtain the preceding result, one must neglect edge terms that contribute 
expressions which are quadratic in the infinitesimal 
.  Since the integrand in 
Equation (10.15) is a function only of 
, it is constant (and equal to 
) 
over the entire strip.  The double integral over the strip can therefore be written as the 
value of the integrand multiplied by the area of the strip.  The double integral over the 
entire square can be written as a sum of the integrals over all the strips which intersect 
the square:
.
(10.17)
Passing to the limit as 
, the sum becomes an integral resulting in
.
(10.18)
t
s
t – s = t
t – s = τ + dt
to
to
–to
–to
t
Figure 10.1  
Illustration of the change of variables for the double integral in Equation (10.15).
a 
 
2to 1

2to
-------
–



 d,   for  
2to,

0,
  for  
2to.






=
d
t
s
–
RXX 
 e j2 
–
RXX t
s
–

e j2 f t
s
–


–
td
s
d
to
–
to
to
–
to
RXX 
 e j2
–
a 
 
strips

=
d
0

E Xto f  2


2to
RXX 
 e j2
–
1

2to
-------
–



 d
2to
–
2to

=

Power Spectral Density    435
www.Academicpress.com
The PSD function for the random process 
 is then
.
(10.19)
Passing to the limit as 
 then gives the desired result in Equation (10.13).  
While most of the random processes we deal with are WSS, for those that are not, Theorem 
10.1 needs to be adjusted since the autocorrelation function for a non-stationary process would 
be a function of two time variables.  For non-stationary processes, the Wiener–Khintchine–
Einstein theorem is written as
,
(10.20)
where in this case, 
 represents a time average with respect to the time variable .  We 
leave it as an exercise to the reader to prove this more general version of the theorem.
Example 10.2:
Let us revisit the random sinusoidal process, 
, of Example 10.1.  This 
time the PSD function will be calculated by first finding the autocorrelation function.
.
The autocorrelation function is only a function of  and thus the PSD is simply the 
Fourier transform of the autocorrelation function, 
.
This is exactly the same result that was obtained in Example 10.1 using the definition of 
PSD, but in this case, the result was obtained with much less work.  
Example 10.3:
Now suppose we have a sinusoid with a random amplitude, but a fixed phase, 
.  Here, the autocorrelation function is
X t 
SXX f 
E Xto f  2


2to
----------------------------
to


lim
1

2to
-------
–



 RXX 
 e j2
–
d
2to
–
2to

to


lim
=
=
to


SXX f 
RXX t t

+




 e j2f
–

d

–


=
  
t
X t 
A
ot

+


sin
=
RXX t t

+



E X t X t

+




E A2
ot

+


o t

+



+


sin
sin


=
=
1
2---E A2

E
o


cos
o 2t

+


2
+


cos
–


1
2---E A2


o


cos
=
=

SXX f 
RXX 
 e j2f
–

d

–


1
2---E A2


o


cos


1
4---E A2


f
fo
–



f
fo
+



+


=
=
=
X t 
A
ot
!
+


sin
=
RXX t t

+



E X t X t

+




E A2
ot
!
+


o t

+


!
+


sin
sin


=
=



(Continued)

436    Chapter 10
www.Academicpress.com
.
In this case, the process is not WSS and so we must take a time average of the 
autocorrelation before we take the Fourier transform.
.
The time-averaged autocorrelation is exactly the same as the autocorrelation in the 
previous example, and hence, the PSD of the sinusoid with random amplitude and fixed 
phase is exactly the same as the PSD of the sinusoid with random amplitude and 
random phase.  
Example 10.4:
Next, consider a modified version of the random telegraph signal of Example 8.4.  In this 
case, the process starts at 
 and switches back and forth between 
 and 
, with the switching times being dictated by a Poisson point process with rate .  
A sample realization is shown in Figure 10.2.  To find the PSD, we first find the 
autocorrelation function.
.
The number of switches in a contiguous interval follows a Poisson distribution, 
and therefore
1
2---E A2

E
o


cos
o 2t

+


2!
+


cos
–


1
2---E A2


o


cos
1
2---E A2


o 2t

+


2!
+


cos
+
=
=
RXX t t

+




 
1
2---E A2


o


cos
1
2---E A2


o 2t

+


2!
+


cos
+

 
=
1
2---E A2


o


cos
1
2---E A2


o 2t

+


2!
+


cos

 
+
1
2---E A2


o


cos
=
=
X 0
 
1
=
X t 
1
=
X t 
1
–
=
"
X(t)
t
1
−1
Figure 10.2  
A sample realization for the random telegraph signal of Example 10.4.  
RXX t t

+



E X t X t

+




#
1
 Pr even number of switches in t t

+





#
1
–

Pr odd number of switches in t t

+





+



Power Spectral Density    437
www.Academicpress.com
.
Since this is a function only of , we directly take the Fourier transform to find the PSD:
.
The autocorrelation function and PSD for this random telegraph signal are illustrated in 
Figure 10.3.  
Example 10.5:
To illustrate how some minor changes in a process can affect its autocorrelation and 
PSD, let us return to the random telegraph process as it was originally described in 
Example 8.4.  As in the previous example, the process switches back and forth between 
two values as dictated by an underlying Poisson point process; however, now the two 
values of the process are 
 instead of 
.  Also, the process starts 
at 
 instead of 
.  Noting that the product 
 is equal to zero 
unless both 
 and 
 are true, the autocorrelation function is 
calculated as
RXX t t

+



" 

m
m!
-----------------e " 
–
m even

" 

m
m!
-----------------e " 
–
m odd

–
"
–


m
m!
--------------------e " 
–
m
0
=


e 2" 
–
=
=
=

SXX f 
e 2" 
–


1 "

1
 f "


2
+
-----------------------------
"
"2
 f

2
+
-------------------------
=
=
=
-2
0
2
0
(a)
0.2
0.4
0.6
0.8
1
t
RXX(t)
-2
0
2
0
0.2
0.4
0.6
0.8
1
f
SXX(f )
(b)
Figure 10.3  
(a) Autocorrelation function and (b) PSD for the random telegraph signal of Example 10.4.
X t 
0 1



$
X t 
+1
1
–



$
X 0
 
0
=
X 0
 
1
=
X t X t

+


X t =1


X t

+

=1


RXX t t

+



E X t X t

+




Pr
X t =1


X t

+

=1


%


Pr odd number of switches in 0 t



Pr even number of switches in t t

+





=
=
=


(Continued)

438    Chapter 10
www.Academicpress.com
.
The last step was accomplished using some of the results obtained in Example 8.6 and 
assumes that  is positive.  If, on the other hand,  is negative, then it turns out that
.
Clearly, this process is not stationary since the autocorrelation function is a function of 
both  and .  Thus, before the Fourier transform is taken, the time average of the 
autocorrelation function must be computed.
,  for 
,
, for 
.
In summary, the autocorrelation function can be concisely expressed as
.
The PSD function is then found to be
.
There are two differences between this result and that of Example 10.4.  First, the total 
power (integral of PSD) in this process is 1/2 the total power in the process of the previous 
example.  This is easy to see since when 
, 
, while when 
, 
.  Second, in this example, there is a delta function in the PSD 
which was not present in the previous example. This is due to the fact that the mean of the 
process in this example was (asymptotically) equal to 1/2, whereas in the previous example 
it was zero.  It is left as an exercise for the reader to determine if the initial conditions of the 
random process would have any effect on the PSD.  That is, if the process started at 
 and everything else remained the same, would the PSD change?
Definition 10.2:  The cross spectral density between two random processes, 
 and 
, is the Fourier transform of the cross correlation function:
.
(10.21)
The cross spectral density does not have a physical interpretation nor does it share the same 
properties of the PSD function.  For example, 
 is not necessarily real since 
 is
t

m
m!
-------------e t
–
m odd




	




m
m!
--------------e 
–
m even




	


1
2---
1
2---e 2t
–
–



 1
2---
1
2---e 2
–
+




=
=


RXX t t

+



1
2---
1
2---e 2 t

+


–
–



 1
2---
1
2---e2
+




=
t

RXX t t

+





1
2---
1
2---e 2t
–
–

 1
2---
1
2---e 2
–
+




1
4---
1
4---e 2
–
+
=
=

0

RXX t t

+





1
2---
1
2---e 2 t

+


–
–

 1
2---
1
2---e2
+




1
4---
1
4---e2
+
=
=

0

RXX t t

+





1
4---
1
4---e 2 
–
+
=
SXX f 
1
4---
1
4---e 2 
–
+
=




1
4---
f 

1
4---

2
f

2
+
-------------------------
+
=
X t 
0 1




E X2 t 


1 2

=
X t 
+1
1
–




E X2 t 


1
=
X 0
 
1
=
X t 
Y t 
SXY f 
RXY 
 


RXY 
 e j2f
–

d

–


=
=
SXY f 
RXY 
 


Power Spectral Density    439
www.Academicpress.com
 not necessarily even.  The cross spectral density function does possess a form of symmetry 
known as Hermitian symmetry2,
.
(10.22)
This property follows from the fact that 
.  The proof of this property is 
left to the reader.
10.3  Bandwidth of a Random Process
Now that we have an analytical function which describes the spectral content of a signal, it is 
appropriate to talk about the bandwidth of a random process.  As with deterministic signals, 
there are many definitions of bandwidth. Which definition is used depends on the application 
and sometimes on personal preference. Several definitions of bandwidth are given next. To 
understand these definitions, it is helpful to remember that when measuring the bandwidth of a 
signal (whether random or deterministic), only positive frequencies are measured.  Also, we 
tend to classify signals according to where their spectral contents lies. Those signals for which 
most of the power is at or near direct current (d.c.) are referred to as lowpass signals, while 
those signals whose PSD is centered around some non-zero frequency, 
 are referred to 
as bandpass processes.   
Definition 10.3:  For a lowpass process, the absolute bandwidth, 
, is the largest 
frequency for which the PSD is non-zero.  That is, 
 is the smallest value of 
 
such that 
 for all 
.  For a bandpass process, let 
 be the largest 
value of 
 such that 
 for all 
 and similarly let 
 be the 
smallest value of 
 such that 
 for all 
.  Then 
.  In 
summary, the absolute bandwidth of a random process is the width of the band which 
contains all frequency components.  The concept of absolute bandwidth is illustrated 
in Figure 10.4.       
SXY f 
SYX
f
–


SXY
*
f
–


=
=
RXY 
 
RYX

–


=
f
fo
=
Babs
Babs
B
SXX f 
0
=
f
B

BL
B
SXX f 
0
=
0
f
B
 
BR
B
SXX f 
0
=
B
f

Babs
BR
BL
–
=
SXX(f)
f
Babs
SXX(f )
f
fo
−fo
Lowpass process
Bandpass process
Babs
(a)
(b)
Figure 10.4  
Measuring the absolute bandwidth of (a) a lowpass and (b) a bandpass process.
2 Here and throughout the text, the superscript * refers to the complex conjugate.

440    Chapter 10
www.Academicpress.com
Definition 10.4:   The 3 dB bandwidth (or half-power bandwidth), 
, is the width 
of the frequency band where the PSD is within 3 dB of its peak value everywhere 
within the band.  Let 
 be the maximum value of the PSD.  Then for a lowpass 
signal, 
 is the largest value of 
 for which 
 for all 
frequencies such that 
.  For a bandpass process, 
, where 
 for all frequencies such that 
, and it is assumed that the 
peak value occurs within the band.  The concept of 3 dB bandwidth is illustrated in 
Figure 10.5. 
Definition 10.5:  The root-mean-square (RMS) bandwidth, 
, of a lowpass 
random process is given by
.
(10.23)
This measure of bandwidth is analogous to using standard deviation as a measure of 
the width of a PDF.  For bandpass processes, this definition is modified according to
,
(10.24)
where
.
(10.25)
It is left as an exercise to the reader to figure out why the factor of 4 appears in the 
preceding definition.
B3dB
Speak
B3dB
B
SXX f 
Speak 2


0
f
B
 
B3dB
BR
BL
–
=
SXX f 
Speak 2


BL
f
BR
 
SXX(f)
SXX(f)
f
f
fo
−fo
Lowpass process
Speak/2
Speak/2
B3 dB
B3 dB
Bandpass process
(a)
(b)
Figure 10.5  
Measuring the 3 dB bandwidth of (a) a lowpass and (b) a bandpass process.
Brms
Brms
2
f2SXX f  fd
0

SXX f  fd
0

---------------------------------
=
Brms
2
4
f
fo
–

2SXX f  fd
0

SXX f  fd
0

---------------------------------------------------
=
fo
fSXX f  fd
0

SXX f  fd
0

------------------------------
=

Power Spectral Density    441
www.Academicpress.com
Example 10.6:
Consider the random telegraph process of Example 10.4 where the PSD was found to be
.
The absolute bandwidth of this process is 
.  This can be seen from the picture of 
the PSD in Figure 10.2.  To find the 3 dB bandwidth, it is noted that the peak of the PSD 
occurs at 
 and has a value of 
.  The 3 dB bandwidth is then the value of  
for which 
.  This is easily found to be 
.  Finally, the RMS 
bandwidth of this process is infinite since 
.
10.4  Spectral Estimation
The problem of estimating the PSD of a random process has been the topic of extensive 
research over the past several decades. Many books are dedicated to this topic alone and 
hence we cannot hope to give a complete treatment of the subject here; however, some 
fundamental concepts are introduced in this section that will provide the reader with a basic 
understanding of the problem and some rudimentary solutions. Spectral estimators are 
generally grouped into two classes, parametric and non-parametric. A parametric estimator 
assumes a certain model for the random process with several unknown parameters and then 
attempts to estimate the parameters. Given the model parameters, the PSD is then computed 
analytically from the model. On the other hand, a non-parametric estimator makes no 
assumptions about the nature of the random process and estimates the PSD directly. Since 
parametric estimators take advantage of some prior knowledge of the nature of the process, 
it would be expected that these estimators are more accurate. However, in some cases, prior 
knowledge may not be available, in which case a non-parametric estimator may be more 
appropriate. We start with a description of some basic techniques for non-parametric 
spectral estimation.
10.4.1 Non-parametric Spectral Estimation
Suppose we observe a random process, 
, over some time interval 
 (or a discrete-time 
process 
 over some time interval 
) and we wish to estimate its PSD function.  
Two approaches immediately come to mind.  The first method we will refer to as the direct method 
or the periodogram.  It is based on the definition of PSD in Equation (10.11).  The second method 
we will refer to as the indirect method or the correlation method.  The basic idea here is to estimate 
SXX f 

2
f

2
+
-------------------------
=
Babs

=
f
0
=
Speak
 1
–
=
f
SXX f 
1
2



=
B3dB
 

=
f2
2
f

2
+
------------------------- fd
0



=
X t 
to
–
to



X n
 
0 no
1
–






442    Chapter 10
www.Academicpress.com
the autocorrelation function and then take the Fourier transform of the estimated autocorrelation to 
form an estimate of the PSD.  We first describe the correlation method.  In all of the discussion on 
spectral estimation to follow, it is assumed that the random processes are WSS.
An estimate of the autocorrelation function of a continuous time random process can be 
formed by taking a time average of the particular realization observed:
.
(10.26)
It is not difficult to show that this estimator is unbiased (i.e., 
), but at 
times, it is not a particularly good estimator, especially for large values of .  The next 
example illustrates this fact.
Example 10.7:
Consider the random telegraph process of Example 10.4.  A sample realization of this 
process is shown in Figure 10.6, along with the estimate of the autocorrelation function.  
For convenience, the true autocorrelation is shown as well.  Note that the estimate 
matches quite well for small values of , but as 
, the estimate becomes very poor. 
Rˆ
XX 
 
X t

2---
–



 X t

2---
+






1
2to

–
-------------------
X t

2---
–



 X t

2---
+



 td
t
– o

2-----
+
to

2-----
–

=
=
E Rˆ XX 
 


RXX 
 
=



to

0
(a)
5
10
15
20
25
−1
−0.5
0
0.5
1
Time, t 
X(t)
−25
−20
−15
−10
−5
0
5
10
15
20
25
−1
−0.5
0
0.5
1
Estimate of RXX(t)
t
(b)
Figure 10.6 
(a) A sample realization of the random telegraph signal and (b) the estimate of the autocorrela-
tion function based on that realization.  The dotted line is the true autocorrelation function.



Power Spectral Density    443
www.Academicpress.com
In order to improve the quality of the autocorrelation estimate, it is common to introduce a 
windowing function to suppress the erratic behavior of the estimate at large values of .  This 
is particularly important when estimating the PSD since the wild behavior at large values of 
 will distort the estimate of the PSD at all frequencies once the Fourier transform of the 
autocorrelation estimate is taken.  
Definition 10.6:  For a WSS random process 
, the windowed estimate of the 
autocorrelation function using a windowing function 
 is given by
.
(10.27)
There are many possible windowing functions that can be used.  The previous autocorrelation 
estimate (without the windowing function) can be viewed as a windowed estimate with a 
rectangular window,
.
(10.28)
Another option would be to use a triangular window,
(10.29)
This would lead to the autocorrelation estimate,
.
(10.30)
While this estimator is biased, the mean-squared error in the estimate will generally be smaller 
than when the rectangular window is used. Much of the classical spectral estimation theory 
focuses on how to choose an appropriate window function to satisfy various criteria.
Example 10.8:
The autocorrelation function of the random telegraph signal is once again estimated, this 
time with the windowed autocorrelation estimator using the triangular window. The 
sample realization as well as the autocorrelation estimate are shown in Figure 10.7.  Note 
this time that the behavior of the estimate for large values of  is more controlled.


X t 
w t 
Rˆ
XX
w

 
 
w t 
2to

–
-------------------
X t

2---
–



 X t

2---
+



 td
t
– o

2-----
+
to

2-----
–

=
w t 
rect
t
4to
-------




=
w t 
tri
t
2to
-------




1
t
2to
-------,
–
t
to,

0,
t
to.





 
=
=
Rˆ
XX
tri

 
 
1
2to
-------
X t

2---
–



 X t

2---
+



 td
t
– o

2-----
+
to

2-----
–

=


(Continued)

444    Chapter 10
www.Academicpress.com
Once an estimate of the autocorrelation can be found, the estimate of the PSD is obtained 
through Fourier transformation.
Definition 10.7:  For a WSS random process 
, the correlation-based estimate 
(with windowing function 
) of the PSD is given by
.
(10.31)
Example 10.9:
The PSD estimates corresponding to the autocorrelation estimates of the previous 
example are illustrated in Figure 10.8. There the correlation-based PSD estimates are 
plotted and compared with the true PSD. Note that when no windowing is used, the 
PSD estimate tends to overestimate the true PSD. Another observation is that it appears 
from these results that the PSD estimates could be improved by smoothing.  We will 
elaborate on that shortly.
0
5
10
15
20
25
−1
−0.5
0
0.5
1
Time, t 
X(t)
−25
−20
−15
−10
−5
0
t
5
10
15
20
25
−0.2
0
0.2
0.4
0.6
0.8
1
Estimate of RXX(t)
(a)
(b)
Figure 10.7  
(a) A sample realization of the random telegraph signal and (b) the windowed estimate of the 
autocorrelation function (using a triangular window) based on that realization.
X t 
w t 
Sˆ
XX
w

 f 
Rˆ
XX
w

 
 


Rˆ
XX
w

 
 e j2f
–

d

–


Rˆ
XX
w

 
 e j2f
–

d
2to
–
2to

=
=
=



Power Spectral Density    445
www.Academicpress.com
The next approach we consider for estimating the PSD of a random process is to directly use 
the definition of PSD in Equation (10.11).  This approach is referred to as the periodogram 
estimate.
Definition 10.8:  Given an observation of the process 
 over an interval 
, 
, the periodogram estimate of the PSD is 
.
(10.32)
Theorem 10.2:  The periodogram estimate of the PSD is equivalent to the 
autocorrelation-based estimate with a triangular window.  That is,
.
(10.33)
0
(a)
(b)
(c)
1
2
3
4
5
6
7
8
-1
-0.5
0
0.5
1
Time (seconds)
X(t)
-40
-30
-20
-10
0
10
20
30
40
-40
-30
-20
-10
0
Frequency (Hz)
PSD (dB)
-40
-30
-20
-10
0
10
20
30
40
-40
-30
-20
-10
0
Frequency (Hz)
PSD (dB)
Figure 10.8
  (a) A sample realization of the random telegraph signal and (b, c) the estimate of the PSD func-
tion. Plot (b) is for the unwindowed estimator while the plot (c) is for the triangular windowed 
estimator.  For both PSD plots, the smooth thick line is the true PSD.
X t 
to
–
to



Xto t 
Sˆ
XX
p
  f 
1
2to
------- Xto f  2
=
Sˆ
XX
p
  f 
Sˆ
XX
tri

 f 
=


446    Chapter 10
www.Academicpress.com
Proof:  The proof of this theorem is a fairly elementary exercise in manipulating the 
properties of Fourier transforms.  Recall that for any two signals, 
 and 
, the 
product of their spectra form a transform pair with the convolution of the two 
signals. That is, 
. Applying this to Equation (10.32) 
results in 
. 
(10.34)
An example of the periodogram was given in Figure 10.8c. At the time, it was referred to as 
the correlation-based estimate with a triangular windowing function. Now, it is clear that the 
two are the same. It was mentioned in Example 10.9, that the quality of the periodogram might 
be improved by smoothing the PSD estimate. This can be accomplished by convolving 
 with some smoothing function, 
.  
Definition 10.9:  The smoothed periodogram with smoothing function 
 is 
given by
.
(10.35)
The smoothed periodogram can be viewed in terms of the correlation-based estimate as well.  
Note that if 
, then 
.
(10.36)
Therefore, the smoothed periodogram is nothing more than the windowed correlation-based 
estimate with a window that is the product of 
 and the triangular window.  This seems to 
indicate that there would be some potential benefit to using windowing functions other than 
what has been presented here.  The reader is referred to the many books on spectral estimation 
for discussions of other possibilities.
In all of the spectral estimators presented thus far, an ensemble average was estimated using 
a single realization.  A better estimate could be obtained if several independent realizations 
of the random process were observed and a sample average were used to replace the 
ensemble average.  Even though we may be able to observe only a single realization, it may 
x t 
y t 
x t *y t 


X f Y f 
=
Xto f  2
Xto 
 *Xto

–




Xto u
 Xto u

–

 u
d

–


Xto t Xto t

+

 td
to
–
to
,
=
=
=
1
2to
------- Xto f  2
1
2to
-------
Xto t Xto t

+

 td
to
–
to
Rˆ
XX
tri

 
 


Sˆ
XX
tri

 f 
=
=
=
SˆXX
p
  f 
w˜ f 
w˜ f 
SˆXX
wp

 f 
w˜ f *Sˆ
XX
p
  f 
=
w 
 
F 1
–
w˜ f 


=
SˆXX
wp

 f 
w 
 

*
Rˆ
XX
tri

 
 


w 
 Rˆ
XX
tri

 
 


=
=
w t 

Power Spectral Density    447
www.Academicpress.com
still be possible to achieve the same effect. This is done by breaking the observed time 
waveform into segments and treating each segment as an independent realization of the 
random process. The periodogram is computed on each segment and then the resulting 
estimates are averaged. 
Example 10.10:
Figure 10.9 compares the periodogram estimate of the PSD of the 
random telegraph signal with and without segmentation.  In plot (b), no 
segmentation is used, while in plot (c), the data are segmented into 
 frames.  A periodogram is computed for each frame and the 
results are then averaged.  Note the improvement in the PSD estimate 
when the segmentation is used.  Also note that there is a slight bias appearing in the 
segmented estimate.  This is most noticeable at the higher frequencies.  This bias will get 
worse as more segments are used.  There is a trade-off in wanting to use a large value of 
 to reduce the “jitter” in the estimate and wanting to use a small value of 
 to keep 
the bias to a minimum.  The following MATLAB functions were used to implement the 
periodogram estimates with and without segmentation. This same functions can be used 
to estimate the PSD of any input signal.
function [Shat, f]=Periodogram(x,dx)
% This function computes the periodogram estimate of the PSD of the 
% input signal. The vector x contains the samples of the input while 
% dx indicates the time interval between samples.
Nx=length(x);
Rhat=conv(x,fliplr(x))/Nx;
Nr=length(Rhat);
Shat=fft(Rhat); 
Shat=fftshift(dx*abs(Shat)); 
Nf=(Nr-1)/2;  df=1/(dx*Nr);
f=[-Nf:Nf]*df;
function [S,f]=EPrdgm(x,dx,M)
% This function computes the periodogram estimate of the PSD of the 
% input signal by breaking the signal into M frames and performing a 
% periodogram estimate on each frame then averaging the results.  The 
% vector x contains the samples of the signal while dx is the sampling 
% interval.  S is the estimated PSD and f is a vector of frequency  
% samples which gives the frequency scale to be used when plotting S.
Nx=length(x);
M
8
=
M
M

(Continued)

448    Chapter 10
www.Academicpress.com
Nframe=floor(Nx/M);
% frame length
S=zeros(1,2*Nframe-1);
for m=1:M
   xm=x(((m-1)*Nframe+1):(m*Nframe));
   [Stemp,f]=Periodogram(xm,dx);
   S=S+Stemp;
end
S=S/M;
10.4.2 Parametric Spectral Estimation
In parametric spectral estimation, a general model of the data is assumed, which usually 
contains one or more unknown parameters. Given the general model, the PSD can be 
calculated analytically. The problem then becomes one of estimating the unknown parameters 
0
1
2
3
4
5
6
7
8
9
-1
-0.5
0
0.5
1
Time (seconds)
X(t)
-40
-30
-20
-10
0
10
20
30
40
-40
-30
-20
-10
0
Frequency (Hz)
PSD (dB)
-40
-30
-20
-10
0
10
20
30
40
−40
−30
−20
−10
Frequency (Hz)
PSD (dB)
(a)
(b)
(c)
Figure 10.9  
(a) A sample realization of the random telegraph signal and (b,c) the periodogram estimate 
of the PSD function. Plot (b) is for the unsegmented data while plot (c) is for when the data 
are segmented into 
 frames. For both PSD plots, the smooth thick line is the true PSD.
M
8
=


Power Spectral Density    449
www.Academicpress.com
and plugging the result into the analytic form of the PSD.  To provide an example of how this 
general approach works, we present a specific class of random process models.
Definition 10.10:  Given a process 
 with known statistics, a new process, 
, 
is formed according to the difference equation
.
(10.37)
This process is referred to as an autoregressive moving average process (ARMA).  As 
special cases, if all of the 
 are equal to zero (except 
, which is usually set equal to 
unity), then Equation (10.37) simplifies to 
.
(10.38)
and the process is referred to as a moving average (MA) process.  The notation MA(q) 
is used to refer to a qth order MA process.  If all of the 
 are equal to zero except for 
, then the difference equation becomes
.
(10.39)
and the process is referred to as an autoregressive (AR) process.  The notation AR(p) 
is used to refer to a pth order AR process.  For the general case, the notation 
ARMA(p,q) is used.
To demonstrate the basic principles of parametric estimation, suppose it was determined that a 
certain random process, 
, is well modeled by an AR(1) model,
,
(10.40)
where 
 is an IID random process with zero-mean and a variance of 
.  It is noted that
,
(10.41)
,
(10.42)
,
(10.43)
X n
 
Y n
 
a0Y n
 
aiY n
i
–


i
1
=
p

biX n
i
–


i
0
=
q

+
=
ai
a0
Y n
 
biX n
i
–


i
0
=
q

=
bi
b0
a0Y n
 
aiY n
i
–


i
0
=
p

b0
+
X n
 
=
Y n
 
Y n
 
a1Y n
1
–


X n
 
+
=
X n
 
X
2
Y n
1
+


a1Y n
 
X n
1
+


+
=
Y n
2
+


a1
2Y n
 
a1X n
1
+


X n
2
+


+
+
=
Y n
3
+


a1
3Y n
 
a1
2X n
 
a1X n
1
+


X n
2
+


+
+
+
=

450    Chapter 10
www.Academicpress.com
and in general,
.
(10.44)
Using this expression, the autocorrelation function of the AR(1) process can be 
computed.
.
(10.45)
The last step is accomplished using the fact that 
 is independent of 
 for 
.  
The expression 
 is calculated according to
.
(10.46)
Assuming that the process 
 is WSS3, this recursion becomes
.
(10.47)
Therefore, the autocorrelation function of the AR(1) process is 
.
(10.48)
Assuming that the samples of this discrete-time process are taken at a sampling interval of 
, 
the PSD of this process works out to be
.
(10.49)
For this simple AR(1) model, the PSD can be expressed as a function of two unknown 
parameters, 
 and 
.  The problem of estimating the PSD then becomes one of estimating 
the two parameters and then plugging the result into the general expression for the PSD.  In 
many cases, the total power in the process may be known, which eliminates the need to 
Y n
k
+


a1
kY n
 
a1
k
1
–
i
– X n
i
+


i
0
=
k
1
–

+
=
RYY n n
k
+



E Y n
 Y n
k
+




a1
kE Y2 n
 


a1
k
1
–
i
– E Y n
 X n
i
+




i
0
=
k
1
–

+
a1
kRYY n n



=
=
=
Y n
 
X n
i
+


i
0

RYY n n



RYY n n



E
a1Y n
1
–


X n
 
+

	2


a1
2RYY n
1
–
n
1
–



X
2
+
=
=
Y n
 
RYY 0
 
a1
2RYY 0
 
X
2
+
=
RYY 0
 

X
2
1
a1
2
–
--------------
=
RYY k
 
X
2
1
a1
2
–
--------------a1
k
=
t

SYY f 	
tX
2

1
a1e j2f t

–
–
2
---------------------------------------
=
a1
X
2
3 It will be shown in the next chapter that this is the case provided that 
 is WSS.
X n
 

Power Spectral Density    451
www.Academicpress.com
estimate 
.  Even if that is not the case, the value of 
 is just a multiplicative factor in the 
expression for PSD and does not change the shape of the curve.  Hence, in the following, we 
focus attention on estimating the parameter, 
.  
Since we know the AR(1) model satisfies the recursion of Equation (10.40), the next value of 
the process can be predicted from the current value according to 
.
(10.50)
This is known as linear prediction since the predictor of the next value is a linear function of 
the current value.  The error in this estimate is
.
(10.51)
Typically, we choose as an estimate of 
 the value of 
 that makes the linear predictor as 
good as possible. Usually, “good” is interpreted as minimizing the mean-square error, which is 
given by
.
(10.52)
Differentiating the mean-square error with respect to 
 and setting equal to zero results in
.
(10.53)
Of course, we do not know what the autocorrelation function is. If we did, we would not need to 
estimate the PSD. So, the preceding ensemble averages must be replaced with sample averages, 
and the minimum mean-square error (MMSE) linear prediction coefficient is given by
. 
(10.54)
Note that we have used a lower case 
 in Equation (10.54) since we are dealing with a 
single realization rather than the ensemble 
.
Example 10.11:
In this example, we use the AR(1) model to estimate the PSD of the random telegraph 
process.  Clearly, the AR(1) model does not describe the random telegraph process; 
however, the autocorrelation function of the random telegraph signal is a two-sided 
X
2
X
2
a1
Yˆ n
1
+


a1
ˆ Y n
 
=

Y n
1
+


Yˆ n
1
+


–
Y n
1
+


aˆ1Y n
 
–
=
=
a1
aˆ1
E  2


E
Y n
1
+


aˆ 1Y n
 
–

	2


RYY 0
 	 1
aˆ1
2
+

	
2aˆ1RYY 1
 	
–
=
=
aˆ1
2aˆ1RYY 0
 	
2RYY 1
 	
–
0
=
aˆ 1

RYY 1
 	
RYY 0
 	
-----------------
=
aˆ 1
Rˆ YY 1
 	
Rˆ YY 0
 	
-----------------
y n
 y n
1
+


n
n0
–
=
n0
1
–

y2 n
 
n
n0
–
=
n0
-----------------------------------------------
=
=
y n
 
Y n
 

(Continued)

452    Chapter 10
www.Academicpress.com
exponential, as is the autocorrelation function of the AR(1) process.  As a consequence, 
we expect this model to give good results.  The results are shown in Figure 10.10.  Notice 
how nicely the estimated PSD matches the actual PSD. 
In the previous example, the results were quite good because the functional form of the PSD of 
the AR(1) process nicely matched the functional form of the true PSD.  If the fit had not been 
so good, it might have been necessary to move to a higher order AR(p) model.  In the exercises 
at the end of the chapter (see Exercises 10.19 and 10.20), the reader is led through the problem 
of finding the MMSE linear prediction coefficients for a general AR(p) model.  The problem 
of analytically finding the PSD of the AR(p) process is dealt with in the next chapter (also see 
Exercise 10.18). 
10.5  Thermal Noise
The most commonly encountered source of noise in electronic systems is that caused by 
thermal agitation of electrons in any conductive material, which is commonly referred to 
as thermal noise.  Unlike shot noise, thermal noise does not require the presence of a 
direct current and hence is always present.  We will not delve into the underlying 
thermodynamics to derive a model for this type of noise, but rather will just summarize 
0
(a)
(b)
2
4
6
8
10
12
14
16
-1
-0.5
0
0.5
1
Time (seconds)
X(t)
-40
-30
-20
-10
0
10
20
30
40
-40
-30
-20
-10
0
Frequency (Hz)
PSD (dB)
Estimated PSD
Actual PSD   
Figure 10.10  
(a) A sample realization of the random telegraph signal and (b) the parametric estimate 
of the PSD function based on the AR(1) model. 


Power Spectral Density    453
www.Academicpress.com
some of the important results.  Nyquist’s theorem states that for a resistive element with 
an impedance of  ohms, at a temperature of 
 (measured in Kelvin), the mean-square 
voltage of the thermal noise measured in a incremental frequency band of width 
 
centered at frequency  is found to be 
  
,
(10.55)
where
;
;
.
Typically, a practical resistor is modeled as a Thevenin equivalent circuit, as illustrated in 
Figure 10.11, consisting of a noiseless resistor in series with a noise source with a mean-
square value as specified in the previous equation.  If this noisy resistor was connected to a 
resistive load of impedance 
, the average power delivered to the load would be
.
(10.56)
The power delivered to the load is maximized when the source and the load impedance are 
matched (i.e., 
).  It is common to refer to the maximum power that can be 
delivered to a load as the available power.  For a noisy resistor, the available power (in a 
bandwidth of 
) is
.
(10.57)
The PSD of the thermal noise in the resistor is then
.
(10.58)
r
tk
f

f
E V2 t 	


vrms
2
4ktkr f

h f
ktk

h f
ktk


	
exp
1
–
--------------------------------------------  volts2
=
=
h
Planck's constant
6.2
34
–
10
J-s
=
=
k
Boltzman's constant
1.38
23
–
10
J K

=
=
tk
absolute temperature
273
C
+
=
=
~
vrms
r (noiseless)
Figure 10.11  
A Thevenin equivalent circuit for a noisy resistor.
rL
PL
vrms
2
rL
r
rL
+

	2
---------------------
=
rL
r
=
f

P
vrms
2
4r
-----------
ktk f

h f
ktk

h f
ktk


	
exp
1
–
--------------------------------------------  watts
=
=
SNN f 	
1
2---ktk
h f
ktk

h f
ktk


	
exp
1
–
--------------------------------------------
=

454    Chapter 10
www.Academicpress.com
The extra factor of 
 is due to the fact that our PSD function is a two-sided function of 
frequency, and so the actual power in a given frequency band is evenly split between the 
positive and negative frequencies.  Note that the power available to a load and the resulting 
PSD are independent of the impedance of the resistor, .  
This PSD function is plotted in Figure 10.12 for several different temperatures.  Note that for 
frequencies that are of interest in most applications (except optical, infrared, etc.), the PSD 
function is essentially constant. It is straightforward (and left as an exercise to the reader) to 
show that this constant is given by
,
(10.59)
where we have defined the constant 
.  At 
4, the parameter 
 takes on 
a value of
.  
It is common to use this simpler function as a model for the PSD of thermal noise.  Because 
the PSD contains equal power at all frequencies, this noise model is referred to as white noise 
(analogous to white light, which contains all frequencies).  The corresponding autocorrelation 
function is
.
(10.60)
1 2

r
SNN f 	
1
2---ktk
No
2
------
=
=
No
ktf
=
tk
298K
=
No
4.11
21
–
10
W/Hz
173.86 dBm/Hz
–
=
=
106
108
1010
1012
1014
−210
−205
−200
−195
−190
−185
−180
−175
−170
Frequency (Hz)
PSD (dBm/Hz)
tk = 3 K
tk = 30 K
tk = 300 K
Figure 10.12  
PSD of thermal noise in a resistor.
RNN 
 	
No
2
------

 	

=
4 Most texts use 
 as “room temperature”; however, this corresponds to a fairly chilly room 
(
).  On the other hand, 
 is a more balmy (
) environment.  These 
differences would only change the value of 
 by a small fraction of a dB.
tk
290K
=
17C
63F

tk
298K
=
25C
77F

No

Power Spectral Density    455
www.Academicpress.com
It should be pointed out that the noise model of Equation (10.59) is a mathematical 
approximation to the actual PSD.  There is no such thing as truly white noise, since such a 
process (if it existed) would have infinite power and would destroy any device we tried to 
measure it with.  However, this mathematical model is simple, easy to work with, and serves 
as a good approximation to thermal noise for most applications.
In addition to modeling thermal noise as having a flat PSD, it can also be shown that the first- 
order characteristics of thermal noise can be well approximated with a zero-mean Gaussian 
process.  We say that thermal noise is zero-mean white Gaussian noise (WGN) with a (two-
sided) PSD of 
.  While thermal noise is the most common source of noise in electronic 
devices, there are other sources as well.  Shot noise was discussed at the end of Chapter 8.  
In addition, one may encounter flicker noise, which occurs primarily in active devices; burst or 
popcorn noise, which is found in integrated circuits and some discrete transistors; avalanche 
noise, which is produced by avalanche breakdown in a p–n junction; as well as several other 
types of noise.  For the purposes of this text, we will stick with the white Gaussian model of 
thermal noise.  
10.6  Engineering Application: PSDs of Digital Modulation Formats
In this section, we evaluate the PSD of a class of signals that might be used in a digital 
communication system.  Suppose we have a sequence of data symbols 
 that we wish to 
convey across some communication medium.  We can use the data symbols to determine the 
amplitude of a sequence of pulses which we would then transmit across the medium (e.g., a 
twisted copper pair, or an optical fiber).  This is know as pulse amplitude modulation (PAM).  
If the pulse amplitudes are represented by the sequence of random variables 
 and the basic pulse shape is given by the waveform 
, then 
the transmitted signal might be of the form
,
(10.61)
where 
 is the symbol interval (that is, one pulse is launched every 
 seconds) and 
 is a 
random delay, which we take to be uniformly distributed over 
 and independent of the 
pulse amplitudes.  The addition of the random delay in the model makes the process 
 
WSS.  This is not necessary and the result we will obtain would not change if we did not add 
this delay, but it does simplify slightly the derivation.  
If the data symbols are drawn from an alphabet of size 
 symbols, then each symbol can be 
represented by an -bit word, and thus the data rate of the digital communication system is 
 bits/second.  The random process 
 used to represent this data has a certain 
No 2

Bk


 A 2
–
A 1
–
A0 A1 A2 








p t 	
S t 	
Akp t
kts
–

–

	
k

–
=


=
ts
ts

0 ts	


S t 	
2n
n
r
n ts

=
S t 	

456    Chapter 10
www.Academicpress.com
spectral content, and thus requires a communications channel with a bandwidth adequate to 
carry that spectral content.  It would be interesting to see how the required bandwidth relates to 
the data rate.  Toward that end, we seek to determine the PSD of the PAM signal 
.  We 
will find the PSD by first computing the autocorrelation function of 
 and then converting 
this to PSD via the Wiener–Khintchine–Einstein Theorem.
Using the definition of autocorrelation, the autocorrelation function of the PAM signal is 
given by
.
(10.62)
To simplify notation, we define 
 to be the autocorrelation function of the sequence of 
pulse amplitudes.  Note that we are assuming the sequence is stationary (at least in the wide 
sense).  Going through a simple change of variables (
) then results in
.
(10.63)
Finally, we go through one last change of variables (
) to produce
.
(10.64)
S t 	
S t 	
RSS t t

+


	
E S t 	S t

+

	


E
AkAmp t
kts
–

–

	 p t

mts
–

–
+

	

	
m

–
=


k

–
=


=
=
E AkAm

E p t
kts
–

–

	p t

mts
–

–
+

	


m

–
=


k

–
=


=
1
ts
---
E AkAm


p t
kts
–

–

	p t

mts
–

–
+

	 
d
0
ts
m

–
=


k

–
=


=
RAA n
 
v
t
kts
–

–
=
RSS t t

+


	
1
ts
---
RAA m
k
–


p v
 	p v

m
k
–

	ts
–
+

	 v
d
t
k
1
+

	ts
–
t
kts
–

m

–
=


k

–
=


=
n
m
k
–
=
RSS t t

+


	
1
ts
---
RAA n
 
p v
 	p v

nts
–
+

	 v
d
t
k
1
+

	ts
–
t
kts
–

n

–
=


k

–
=


=
1
ts
---
RAA n
 
p v
 	p v

nts
–
+

	 v
d
t
k
1
+

	ts
–
t
kts
–

k

–
=


n

–
=


=
1
ts
---
RAA n
 
p v
 	p v

nts
–
+

	 v
d

–


n

–
=


=

Power Spectral Density    457
www.Academicpress.com
To aid in taking the Fourier transform of this expression, we note that the integral in the 
previous equation can be written as a convolution of 
 with 
,
.
(10.65)
Using the fact that convolution in the time domain becomes multiplication in the frequency 
domain along with the time reversal and time shifting properties of Fourier transforms (see 
Appendix C), the transform of this convolution works out to be
,
(10.66)
where 
 is the Fourier transform of the pulse shape used.  With this 
result, the PSD of the PAM signal is found by taking the transform of Equation (10.64), 
resulting in
.
(10.67)
It is seen from the previous equation that the PSD of a PAM signal is the product of two 
terms, the first of which is the magnitude squared of the pulse shape’s spectrum, while the 
second term is essentially the PSD of the discrete sequence of amplitudes. As a result, we 
can control the spectral content of our PAM signal by carefully designing a pulse shape 
with a compact spectrum and also by introducing memory into the sequence of pulse 
amplitudes.
Example 10.12:
To start with, suppose the pulse amplitudes are an IID sequence of random variables 
which are equally likely to be +1 or 1. In that case, 
 and the PSD of the 
sequence of amplitudes is 
.
In this case, 
 and the spectral shape of the PAM signal is completely 
determined by the spectral content of the pulse shape.  Suppose we use as a pulse shape 
a square pulse of height  and width ,
p t 	
p
t
–

	
p v
 	p v

nts
–
+

	 v
d

–


p t 	*p
t
–

	 t

nts
–
=
=
p v
 	p v

nts
–
+

	 v
d

–


P f 	 2e j2nfts
–
=
P f 	
p t 	


=
SSS f 	
P f 	 2
ts
----------------
RAA n
 e j2nfts
–
n

–
=


=
RAA n
 
 n
 
=
RAA n
 e j2nfts
–
n

–
=

1
=
SSS f 	
P f 	 2 ts

=
a
ts

(Continued)

458    Chapter 10
www.Academicpress.com
.
The PSD of the resulting PAM signal is then 
.  Note that the factor 
 is the energy in each pulse sent, 
.  A sample realization of this PAM process along 
with a plot of the PSD is given in Figure 10.13.  Most of the power in the process is 
contained in the main lobe, which has a bandwidth of 
 (equal to the data rate), but 
there is also a non-trivial amount of power in the sidelobes, which die off very slowly.  
This high-frequency content can be attributed to the instantaneous jumps in the 
process.  These frequency sidelobes can be suppressed by using a pulse with a smoother 
shape.  Suppose, for example, we used a pulse which was a half-cycle of a sinusoid of 
height ,
.
The resulting PSD of the PAM signal with half-sinusoidal pulse shapes is then 
.
In this case, the energy in each pulse is 
.  As shown in Figure 10.14, the main 
lobe is now 50 % wider than it was with square pulses, but the sidelobes decay much 
more rapidly. 
p t 	
arect t ts


	
=
P f 	

atssinc fts

	
=
SSS f 	
a2tssinc2 fts

	
=
a2ts
p
0
(a)
(b)
5
10
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
t/ts
S(t)
-5
0
5
-40
-35
-30
-25
-20
-15
-10
−5
0
5
f*ts
PSD/Ep (dB)
Figure 10.13  
(a) A sample realization and (b) the PSD of a PAM signal with square pulses.
1 ts

a
p t 	
acos  t
ts
-----


 
! rect t
ts
---
 
 !
P f 	

ats
2
------- sinc fts
1
2---
–


 
!
sinc fts
1
2---
+


 
!
+
ats
2
-------
 fts

	
cos
1
4---
fts

	2
–
-----------------------
=
=
=
SSS f 	
a2ts
4 2
--------- cos2  fts

	
1
4---
fts

	2
–
2
------------------------------
=
p
a2ts 2

=

Power Spectral Density    459
www.Academicpress.com
Example 10.13:
In this example, we show how the spectrum of the PAM signal can also be manipulated 
by adding memory to the sequence of pulse amplitudes.  Suppose the data to be 
transmitted 
 is an IID sequence of Bernoulli random variables, 
. In the previous example, we formed the pulse amplitudes according to 
.  Suppose instead we formed these amplitudes according to 
.  
Now the pulse amplitudes can take on three values (even though each pulse still only 
carries one bit of information). This is known as duobinary precoding. The resulting 
autocorrelation function for the sequence of pulse amplitudes is
The PSD of this sequence of pulse amplitudes is then
.
This expression then multiplies whatever spectral shape results from the pulse shape 
chosen.  The PSD of duobinary PAM with square pulses is illustrated in Figure 10.15.  In 
this case, the duobinary precoding has the benefit of suppressing the frequency 
sidelobes without broadening the main lobe.       
0
5
10
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
t/ts
S(t)
−5
0
5
−40
−35
−30
−25
−20
−15
−10
-5
0
5
f*ts
PSD/Ep (dB)
(b)
(a)
Figure 10.14  
(a) A sample realization and (b) the PSD of a PAM signal with half-sinusoidal pulses.
 B 2
–
B 1
–
B0 B1 B2 








Bk
+1
1
–



"
Ak
Bk
=
Ak
Bk
Bk
1
–
+
=
RAA n
 
E AkAk
n
+


E
Bk
Bk
1
–
+

	 Bk
n
+
Bk
n
1
–
+
+

	


2,
n = 0,
1,
    n =
1
#
,
0,          otherwise.
$
%
&
%
'
=
=
=
RAA n
 e j2nfts
–
n

–
=

2
ej2fts
e j2fts
–
+
+
2
2
2fts

	
cos
+
4cos2 fts

	
=
=
=


(Continued)

460    Chapter 10
www.Academicpress.com
Example 10.14:
The following MATLAB code creates a realization of a binary PAM signal 
where the pulse amplitudes are either +1 or 1. In this example, a half-
sinusoidal pulse shape is used, but the code is written so that it is easy to 
change the pulse shape (just change the 6th line where the pulse shape is 
assigned to the variable p). After a realization of the PAM signal is 
created, the PSD of the resulting signal is estimated using the segmented periodogram 
technique given in Example 10.10. The resulting PSD estimate is shown in Figure 10.16.  
Note the agreement between the estimate and the actual PSD shown in Figure 10.14.  
The reader is encouraged to try running this program with different pulse shapes to see 
how the pulse shape changes the spectrum of the PAM signal.
N=100;
% No. of bit intervals in realization.
Ns=19;
% No. of time samples per bit.
Rb=9600;
% bit rate (bits/sec)
dt=1/(Rb*Ns);
% time between samples
t=([1:Ns]-0.5)/Ns;
% time axis for pulse shape
p=sin(pi*t);
% pulse shape
Ep=p*p'*dt;
% energy per pulse
X(1:Ns:(Ns*(N-1)+1))=sign(rand(1,N)-0.5);% random data bits
X=conv(X,p);
% PAM signal with pulse shape added
0
5
10
-2
-1.5
-1
-0.5
0
0.5
1
1.5
2
t/ts
S(t)
-5
0
5
-40
-35
-30
-25
-20
-15
-10
-5
0
5
f*ts
PSD/Ep (dB)
(a)
(b)
Figure 10.15 
(a) A sample realization and (b) the PSD of a PAM signal with duobinary precoding 
and square pulses.



Power Spectral Density    461
www.Academicpress.com
M=10;
% No. of segments
[S,f]=EPrdgm(X,dt,M);
% (Normalized) PSD estimate
plot(f/1000,10*log10(abs(S/Ep)))
% plot results
axis([-5*Rb/1000 5*Rb/1000 -60 10])
xlabel('frequency (kHz)')
ylabel('PSD (dB)')
−40
−30
−20
−10
0
10
20
30
40
−60
−50
−40
−30
−20
−10
0
10
Frequency (kHz)
PSD (dB)
Figure 10.16  
An estimate of the PSD of a PAM signal with half-sinusoidal pulse shapes.


463
CHAPTER 10
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 10.1:  Definition of PSD
10.1 Find the PSD of the process described in Exercise 8.1.
10.2 Find the PSD of the process described in Exercise 8.2.
10.3 Consider a constant random process, 
, where 
 is a random variable.  Use 
Definition 10.1 to calculate the PSD of 
.
Section 10.2:  Wiener–Khintchine–Einstein Theorem
10.4 Consider a random process of the form
,
where  is a constant, 
 is a uniform random variable over 
, and 
 is a random 
variable which is independent of 
 and has a PDF, 
.  Find the PSD, 
 in 
terms of 
.  In so doing, prove that for any 
 which is a valid PSD function, we 
can always construct a random process with PSD equal to 
.
10.5 Let 
 where 
 and 
 are independent, zero-mean, 
identically distributed, non-Gaussian random variables. 
(a)
Show that 
 is WSS, but not strict sense stationary. Hint: For the latter case 
consider 
.  Note: If 
 and 
 are Gaussian, then 
 is also stationary in 
the strict sense.
(b)
Find the PSD of this process.
10.6 Let 
 where all of the 
 are non-zero constants, the 
 
are constants, and the 
 are IID random variables, each uniformly distributed over 
.   
(a) Determine the autocorrelation function of 
.
(b) Determine the PSD of 
.
X t 
A
=
A
X t 
X t 
b
2t

+


cos
=
b

0 2





f 	


SXX f 
f 	


S f 
S f 
X t 
A

t


cos
B

t


sin
+
=
A
B
X t 
E X3 t 


A
B
X t 
X t 
an

nt
n
+


cos
n
1
=
N

=

n
an
n
0 2 


X t 
X t 

464    Chapter 10
www.Academicpress.com
10.7
Let 
 be a random process, where 
 and 
 are random variables such that 
, 
, 
, and 
 for all 
 and , where 
 is the Kronecker delta function.  This process is sometimes used as a model for 
random noise.
(a) Find the time-varying autocorrelation function 
.  
(b) If 
, is this process WSS? 
(c) Find the PSD of this process.
10.8
Find the PSD for a process for which 
 for all .
10.9
Suppose 
 is a stationary zero-mean Gaussian random process with PSD, 
.  
(a) Find the PSD of 
 in terms of 
.
(b) Sketch the resulting PSD if 
.
(c) Is 
 WSS?
10.10
Consider a random sinusoidal process of the form 
, where 
 
has an arbitrary PDF, 
.  Analytically determine how the PSD of 
 depends 
on 
.  Give an intuitive explanation for your result.
10.11
Let 
 be a deterministic periodic waveform with period 
.  A random process is 
constructed according to 
 where 
 is a random variable uniformly 
distributed over 
.  Show that the random process 
 has a line spectrum 
and write the PSD of 
 in terms of the Fourier Series coefficients of the periodic 
signal 
.
10.12
A sinusoidal signal of the form 
 is transmitted from a fixed 
platform.  The signal is received by an antenna which is on a mobile platform that is in 
motion relative to the transmitter, with a velocity of 
 relative to the direction of 
signal propagation between the transmitter and receiver.  Therefore, the received signal 
experiences a Doppler shift and (ignoring noise in the receiver) is of the form
,
where  is the speed of light.  Find the PSD of the received signal if 
 is uniformly 
distributed over 
.  Qualitatively, what does the Doppler effect do to the PSD 
of the sinusoidal signal?
X t 
An
n
t


cos
Bn
n
t


sin
+


n
1
=


=
An
Bn
E An


E Bn


0
=
=
E AnBm


0
=
E AnAm


n m

E An
2


=
E BnBm


n m

E Bn
2


=
m
n
n m

RXX t t

+



E Bn
2


E An
2


=
RXX 
 
1
=

X t 
SXX f 
Y t 
X2 t 
=
SXX f 
SXX f 
rect
f
2B
-------




=
Y t 
X t 
b
2ft

+


cos
=

f 
 
X t 
f 
 
s t 
to
X t 
s t
T
–


=
T
0 to


X t 
X t 
s t 
X t 
b
2fot

+


cos
=
V
Y t 
b
2fo 1
V
c---
+



 t

+




cos
=
c
V
vo
–
vo




Exercises    465
www.Academicpress.com
10.13
Two zero-mean discrete random processes, 
 and 
, are statistically 
independent and have autocorrelation functions given by 
 and 
. Let a new random process be 
. 
(a) Find 
. Plot all three autocorrelation functions. 
(b) Determine all three PSD functions analytically and plot the PSDs.
10.14
Let 
 be the PSD function of a WSS discrete-time process 
.  Recall that one 
way to obtain this PSD function is to compute 
 and then 
take the DFT of the resulting autocorrelation function.  Determine how to find the average 
power in a discrete-time random process directly from the PSD function, 
.
10.15
A binary phase shift keying signal is defined according to 
         
  for  
, 
for all , and 
 is a discrete-time Bernoulli random process that has values of +1 
or 1.  
(a) Determine the autocorrelation function for the random process 
.  Is the 
process WSS?  
(b) Determine the PSD of 
.
10.16
Let 
 be a random process whose PSD is shown in the accompanying figure.  A 
new process is formed by multiplying 
 by a carrier to produce
,
where 
 is uniform over 
 and independent of 
.  Find and sketch the PSD 
of the process 
. 
10.17
Consider a random process 
.  
(a) Find an expression for 
 in terms of 
, 
, and 
.
(b) Under what conditions does 
?
Section 10.3:  Bandwidth of a Random Process
10.18
Develop a formula to compute the RMS bandwidth of a random process, 
, 
directly from its autocorrelation function, 
.
X n
 
Y n
 
RXX k
 
1 2


k
=
RYY k
 
1 3


k
=
Z n
 
X n
 
Y n
 
+
=
RZZ k
 
SXX f 
X n
 
RXX n
 
E X k
 X k
n
+




=
SXX f 
X t 
2fct
B n
 
2---
+




cos
=
nT
t
n
1
+

T


n
B n
 
X t 
X t 
X t 
X t 
Y t 
X t 

ot

+


cos
=

0 2



X t 
Y t 
f
SXX f 
fo
B
+
fo
1
Z t 
X t 
Y t 
+
=
SZZ f 
SXX f  SYY f 
SXY f 
SZZ f 
SXX f 
SYY f 
+
=
X t 
RXX 
 

466    Chapter 10
www.Academicpress.com
10.19
A random process has a PSD function given by
.
(a) Find the absolute bandwidth.
(b) Find the 3 dB bandwidth.
(c) Find the RMS bandwidth.
Can you generalize your result to a spectrum of the form
,
where 
 is an integer greater than 1?
10.20
A random process has a PSD function given by
.
(a) Find the absolute bandwidth.
(b) Find the 3 dB bandwidth.
(c) Find the RMS bandwidth.
Can you generalize your result to a spectrum of the form
,
where 
 is an integer greater than 2?
Section 10.4:  Spectral Estimation
10.21
Consider the linear prediction random process 
, 
, where 
 and 
 is a zero-mean, IID random process. 
(a) Find the mean and autocorrelation functions for 
. Is 
 WSS?
(b) Find the PSD of 
.
10.22
Consider an AR(2) process which is described by the recursion
where 
 is an IID random process with zero-mean and variance 
.
(a) Show that the autocorrelation function of the AR(2) process satisfies the 
difference equation,
,  
.
S f 
1
1
f
B---
 
  2
+



 3
-----------------------------
=
S f 
1
1
f
B---
 
  2
+



 N
------------------------------
=
N
S f 
f2
1
f
B---
 
  2
+



 3
-----------------------------
=
S f 
f2
1
f
B---
 
  2
+



 N
------------------------------
=
N
X n
 
1 2


X n
1
–


E n
 
+
=
n
1 2 3 
  
=
X 0
 
0
=
E n
 
X n
 
X n
 
X n
 
Y n
 
a1Y n
1
–


a2Y n
2
–


X n
 
+
+
=
X n
 
X
2
RYY k
 
a1RYY k
1
–


a2RYY k
2
–


+
=
k
2 3 4 
  
=

Exercises    467
www.Academicpress.com
(b) Show that the first two terms in the autocorrelation function satisfy
,
and 
.
From these two equations, solve for 
 and 
 in terms of 
, 
, and 
.
(c) Using the difference equation in part (a) together with the initial conditions in part (b), 
find a general expression for the autocorrelation function of an AR(2) process.
(d) Use your result in part (c) to find the PSD of an AR(2) process.
10.23
Suppose we use an AR(2) model to predict the next value of a random process based 
on observations of the two most recent samples.  That is, we form
.
(a) Derive an expression for the mean-square estimation error, 
.
(b) Find the values of the prediction coefficients, 
 and 
, that minimize the mean-
square error.
10.24
Extend the results of Exercise 10.23 to a general AR( ) model.  That is, suppose we 
wish to predict the next value of a random process by forming a linear combination of 
the  most recent samples:
.
Find an expression for the values of the prediction coefficients which minimize the 
mean-square prediction error.
10.25
Show that the estimator for the autocorrelation function, 
, described in 
Equation (10.26) is unbiased.  That is, show that 
.
10.26
Suppose 
 is a zero-mean, WSS, Gaussian random process.  Find an expression for 
the variance of the estimate of the autocorrelation function, 
, given in Equation 
(10.26). That is, find 
. Hint: Remember 
 is unbiased (see 
Exercise 10.25) and you might find the Gaussian moment factoring theorem (see 
Exercise 6.18) useful.
1
a1
2
–
a2
2
–

RYY 0
 
2a1a2RYY 1
 
–
X
2
=
1
a2
–

RYY 1
 
a1RYY 0
 
=
RYY 0
 
RYY 1
 
a1 a2
X
2
Yˆ n
1
+


a1Y n
 
a2Y n
1
–


+
=
E 2


E
Y n
1
+


Yˆ n
1
+


–

2


=
a1
a2
p
p
Yˆ n
1
+


akY n
k
–
1
+


k
1
=
p

=
Rˆ XX 
 
E Rˆ XX 
 


RXX 
 
=
X t 
Rˆ XX 
 
Var Rˆ XX 
 


Rˆ XX 
 

468    Chapter 10
www.Academicpress.com
10.27
Using the expression for 
 found in Exercise 10.26, show that as 
, 
 and therefore, the estimate of the 
autocorrelation function is at least as noisy as the process itself as 
.
10.28
Determine whether or not the periodogram is an unbiased estimate of the PSD.
10.29
Suppose we form a smoothed periodogram of the PSD, 
, as defined in 
Equation (10.35), using a rectangular smoothing function,
,
where 
 is the width of the rectangle.  If we want to form the same estimator using a 
windowed correlation-based estimate, what window function (in the time domain) 
should we use?
Section 10.5:  Thermal Noise
10.30
(a)
Prove that the expression for the PSD of thermal noise in a resistor converges to  
the constant 
 as 
.
(b) Assuming a temperature of 
, find the range of frequencies over which 
thermal noise has a PSD which is within 99% of its value at 
. 
(c) Suppose we had a very sensitive piece of equipment which was able to accurately 
measure the thermal noise across a resistive element.  Furthermore, suppose our 
equipment could respond to a range of frequencies which spanned 50 MHz.  Find 
the power (in watts) and the RMS voltage (in volts) that we would measure across a 
75  resistor.  Assume the equipment had a load impedance matched to the resistor.  
10.31
Suppose two resistors of impedance 
 and 
 are placed in series and held at 
different physical temperatures, 
 and 
.  We would like to model this series 
combination of noisy resistors as a single noiseless resistor with an impedance of 
, together with a noise source with an effective temperature of 
.  In 
short, we want the two models shown in the accompanying figure to be equivalent.  
Assuming the noise produced by the two resistors is independent, what should 
, the 
effective noise temperature of the series combination of resistors, be?  If the two 
resistors are held at the same physical temperature, is the effective temperature equal 
to the true common temperature of the resistors?  
Var Rˆ XX 
 



2to

Var Rˆ XX 
 


Var X t 




2to

Sˆ
XX
wp

 f 
w˜ f 
1
f
----rect
f
f
----




=
f
No 2

ktk 2

=
f
0

298 K
f
0
=
r1
r2
t1
t2
r
r1
r2
+
=
te
te

Exercises    469
www.Academicpress.com
10.32
Repeat Exercise 10.31 for a parallel combination of resistors.
MATLAB Exercises
10.33
(a) Create a random process 
 where each sample of the random process is an 
IID, Bernoulli random variable equally likely to be 
.  Form a new process 
according to the MA(2) model 
.  Assume 
 for 
.
(b) Compute the time-average autocorrelation function 
 from a single 
realization of this process.  
(c) Compute the ensemble average autocorrelation function 
 from 
several realizations of this process. Does the process appear to be ergodic in the 
autocorrelation?
(d) Estimate the PSD of this process using the periodogram method.
10.34
(a) Create a random process 
 where each sample of the random process is an 
IID, Bernoulli random variable equally likely to be 
.  Form a new process 
according to the AR(2) model 
.  Assume 
 for 
.
(b) Compute the time-average autocorrelation function 
 from a single 
realization of this process.  
~
vrms
4kter f

=
r
r1
r2 (noiseless)
+
=
~
~
vrms 1

4kt1r1 f

=
vrms 2

4kt2r2 f

=
r1 (noiseless)
r2 (noiseless)
X n
 
1
!
Y n
 
X n
 
1
2---X n
1
–


1
4---X n
2
–


+
–
=
X n
 
0
=
n
0

Y n
 Y n
k
+


"
#
E Y n
 Y n
k
+




X n
 
1
!
Y n
 
1
2---Y n
1
–


1
4---Y n
2
–


–
X n
 
+
=
Y n
 
0
=
n
0

Y n
 Y n
k
+


"
#

470    Chapter 10
www.Academicpress.com
(c) Compute the ensemble average autocorrelation function 
 from 
several realizations of this process. Does the process appear to be ergodic in the 
autocorrelation?
(d) Estimate the PSD of this process using the periodogram method.
10.35
(a) For the process in Exercise 10.34, find a parametric estimate of the PSD by using 
an AR(1) model.  Compare the resulting PSD estimate with the non-parametric 
estimate found in Exercise 10.34(d).  Explain any differences you see.
(b) Again, referring to the process in Exercise 10.34, find a parametric estimate of the 
PSD this time using an AR(2) model.  Compare the resulting PSD estimate with the 
non-parametric estimate found in Exercise 10.34(d).  Explain any differences you see.
10.36
(a) Write a MATLAB program to create a realization of a binary PAM signal with 
square pulses.  You can accomplish this with a simple modification to the program 
given in Example 10.14.    Call this signal 
.  
(b) We can create a frequency shift keying (FSK) signal according to
,
where 
 is the duration of the square pulses in 
 and 
 is the carrier frequency.  
Write a MATLAB program to create a 10 ms realization of this FSK signal assuming 
 and 
.
(c) Using the segmented periodogram, estimate the PSD of the FSK signal you 
created in part (b).
(d) Estimate the 30 dB bandwidth of the FSK signal.  That is, find the bandwidth 
where the PSD is down 30 dB from its peak value.  
10.37
Construct a signal plus noise random sequence using 10 samples of the following:
,
where 
 is a sequence of zero-mean, unit variance, IID Gaussian random variables, 
, and 
 is the time between samples of the process.
(a) Calculate the periodogram estimate of the PSD, 
.
(b) Calculate a parametric estimate of the PSD using AR models with  = 1, 2, 3, and 5.  
Compare the parametric estimates with the periodogram.  In your opinion, which 
order AR model is the best fit.
(c) Repeat parts (a) and (b) using 100 samples instead of 10.
E Y n
 Y n
k
+




x t 
y t 
2fct

2ts
-------
x u
  u
d
0
t$
+




cos
=
ts
x t 
fc
ts
100 %s
=
fc
20 kHz
=
X n
 
2nf0ts


cos
N n
 
+
=
N n
 
f0
0.1 ts

100kHz
=
=
ts
1%s
=
SXX f 
p

Exercises    471
www.Academicpress.com
10.38
Construct a signal plus noise random sequence using 10 samples of:
,
where 
 is a sequence of zero-mean, unit variance, IID Gaussian random 
variables, and 
, 
, and 
 is 
the time between samples of the process.
(a) Calculate the periodogram estimate of the PSD, 
.
(b) Calculate a parametric estimate of the PSD using AR models with  = 3, 4, 5, 6, 
and 7.  Compare the parametric estimates with the periodogram.  In your opinion, 
which order AR model is the best fit.
(c) Repeat parts (a) and (b) using 100 samples instead of 10.
X n
 
2nf1ts


cos
2nf2ts


cos
N n
 
+
+
=
N n
 
f1
0.1 ts

100 kHz
=
=
f2
0.4 ts

400 kHz
=
=
ts
1%s
=
SXX f 
p

473
CHAPTER 11
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00011-5
© 2012 by Elsevier Inc. All rights reserved.
Random Processes in Linear Systems
In this chapter, we consider the response of both continuous time and discrete-time linear 
systems to random processes, such as a signal plus noise.  We develop statistical descriptions 
of the output of linear systems with random inputs by viewing the systems in both the time 
domain and the frequency domain. An engineering application section at the end of this 
chapter demonstrates how filters can be optimized for the purpose of enhancing signal-to-
noise ratios. It is assumed that the reader is familiar with the study of linear time-invariant 
(LTI) systems. A brief overview is provided in Appendix C for those needing 
a refresher.
11.1 Continuous Time Linear Systems
Consider a linear time-invariant (LTI) system described by an impulse response 
 or a 
transfer function 
.  If a random process, 
, is the input to this system, the output will 
also be random and is given by the convolution integral
.
(11.1)
We would like to statistically describe the output of the system.  Ultimately, the joint PDF of 
any number of samples of the output would be nice.  In general, this is a very difficult problem 
and hence we have to be satisfied with a simpler description.  However, if the input process is 
Gaussian, then the output process will also be Gaussian, since any linear processing of 
Gaussian random variables (processes) produces new Gaussian random variables (processes).  
In that case, to completely describe the output of the system, we need merely to compute the 
mean and the autocovariance (or autocorrelation) function of the output.  Even if the 
processes involved are not Gaussian, the mean and autocorrelation functions will serve 
as a good start toward describing the process.  Therefore, our first goal will be to specify 
the mean and autocorrelation functions of the output of an LTI system with a random 
input.
h t 
H f 
X t 
Y t 
X u
 h t
u
–



–


du
=

474    Chapter 11
www.Academicpress.com
To start with, consider the mean function of the output:
(11.2)
Therefore, the output mean is the convolution of the input mean process with the impulse 
response of the system.  For the special case when the input is wide sense stationary (WSS) 
and the input mean function is thereby constant, the output mean function becomes
.
(11.3)
Note that the mean function of the output is also constant provided the input mean is constant.  
The autocorrelation function of the output is calculated in a similar manner.
(11.4)
For WSS inputs, this expression can be simplified a little by using the fact that 
.  The output autocorrelation function is then
.
(11.5)
Although it may not appear like it from this expression, here, the output autocorrelation 
function is also a function of time difference only.  To see this, perform the change of 
variables 
 and 
.  Then Equation (11.5) becomes
.
(11.6)
Now it is clear that 
.  To write this result in a more compact form, 
note that the inner integral in Equation (11.6) can be expressed as
Y t 
E Y t 


E
X u
 h t
u
–



–


du
E X u
 

h t
u
–



–


du
X u
 h t
u
–



–


du.
=
=
=
=
Y t 
X
h t
u
–



–


du
X
h s 

–


ds
XH 0
 
=
=
=
RYY t1 t2
	


E Y t1

Y t2




E
X u
 h t1
u
–



–


du






X v
 h t2
v
–



–


dv






E X u
 X v
 

h t1
u
–



–


h t2
v
–



–


dudv
RXX u v
	

h t1
u
–



–


h t2
v
–



–


dudv .
=
=
=
=
RXX u v
	


RXX v
u
–


=
RYY t1 t2
	


RXX v
u
–

h t1
u
–



–


h t2
v
–



–


dudv
=
s
t1
u
–
=
w
t2
v
–
=
RYY t1 t2
	


RXX t2
t1
–
s
w
–
+

h s 

–


h w



–


dwds
=
RYY t1 t2
	


RYY t2
t1
–


=

Random Processes in Linear Systems    475
www.Academicpress.com
,
(11.7)
where  denotes convolution.  Let 
, then the output autocorrelation can 
be expressed as
.
(11.8)
Putting all these results together, we get
.
(11.9)
Thus, the output autocorrelation function is found by a double convolution. The presence of 
the double convolution in the previous equation begs for an equivalent frequency domain 
representation.  Taking Fourier transforms of both sides gives an expression for the power 
spectral density (PSD) of the output of the filter in terms of the input PSD:
.
(11.10)
The term 
 is sometimes referred to as the power transfer function because it describes 
how the power is transferred from the input to the output of the system.  In summary, we have 
shown the following results.
Theorem 11.1:  Given an LTI system with impulse response 
 or transfer function
 and a random input process 
, the mean and autocorrelation functions of the
output process, 
, can be described by
,
(11.11a)
.
(11.11b)
Furthermore, if 
 is WSS, then 
 is also WSS with
,
(11.12a)
,
(11.12b)
.
(11.12c)
At times, it is desirable to specify the relationship between the input and output of a filter.  
Toward that end, we can calculate the cross-correlation function between the input and output.
RXX t2
t1
–
s
w
–
+



–


h w

dw
RXX t *h t 
t
t2
t1
–
s
+
=
=
*
g t 
RXX t *h t 
=
RYY t2
t1
–


g t2
t1
–
s
+

h s  s
d

–


g t *h
t
–

 t
t2
t1
–
=
=
=
RYY 
 
RXX 
 *h 
 *h

–


=
SYY f 
SXX f H f H* f 
SXX f  H f  2
=
=
H f  2
h t 
H f 
X t 
Y t 
Y t 
X t *h t 
=
RYY t1 t2
	


RXX u v
	

h t1
u
–



–


h t2
v
–



–


dudv
=
X t 
Y t 
Y
XH 0
 
=
RYY 
 
RXX 
 *h 
 *h

–


=
SYY f 
SXX f  H f  2
=

476    Chapter 11
www.Academicpress.com
(11.13)
If 
 is WSS, then this simplifies to
.
(11.14)
In a similar manner, it can be shown that
.
(11.15)
In terms of cross-spectral densities, these equations can be written as
 and 
.
(11.16)
Example 11.1:  
White Gaussian noise, 
, with a PSD of 
 is input to an RC lowpass filter 
(LPF).  Such a filter will have a transfer function and impulse response given by
 and 
,
respectively.  If the input noise is zero-mean, 
, then the output process will also be 
zero-mean, 
.  Also
.
Using inverse Fourier transforms, the output autocorrelation is found to be
.
Example 11.2:  
Suppose we wish to convert a white noise process from continuous time to discrete time 
using a sampler.  Since white noise has infinite power, it cannot be sampled directly and 
must be filtered first.  Suppose for simplicity we use an ideal LPF of bandwidth  to 
RXY t1 t2
	


E X t1

Y t2




E X t1


X u
 h t2
u
–



–


du
=
=
E X t1

X u
 

h t2
u
–



–


du
RXX t1 u
	

h t2
u
–



–


du
RXX t1 t2
v
–
	

h v
 

–


dv.
=
=
=
X t 
RXY 
 
RXX 
v
–

h v
 

–


dv
RXX 
 *h 
 
=
=
RYX 
 
RXX 
 *h

–


=
SXY f 
SXX f H f 
=
SYX f 
SXX f H* f 
=
N t 
SNN f 
No 2

=
H f 
1
1
j2fRC
+
----------------------------
=
h t 
1
RC
--------
t
RC
--------
–




exp
u t 
=
N
0
=
Y
0
=
SYY f 
SNN f  H f  2
No 2

1
2fRC

2
+
---------------------------------
=
=
RYY 
 
No
4RC
-----------

RC
--------
–




exp
=
B




Random Processes in Linear Systems    477
www.Academicpress.com
perform the sampling so that the system is as illustrated in Figure 11.1.  Let 
 be the 
random process at the output of the LPF.  This process has a PSD of
The corresponding autocorrelation function is
.
If the output of the filter is sampled every 
 seconds, the discrete-time noise process will 
have an autocorrelation of 
.  If the discrete-time output process 
 is to be white, then we want all samples to be uncorrelated.  That is, we want 
 for all 
.  Recall that the sinc function has nulls whenever its argument is 
an integer.  Thus, the discrete-time process will be white if (and only if) 
 is an integer.  
In terms of the sampling rate, 
, for the discrete-time process to be white, the 
sampling rate must be 
 for some integer 
.  
11.2 Discrete-Time Linear Systems
The response of a discrete-time linear system to a (discrete-time) random process is found 
using virtually identical techniques to those used with continuous time systems.  As such, we 
do not repeat the derivations here, but rather summarize the relevant results.  We start with a 
linear system described by the difference equation
,
(11.17)
where 
 is the input to the system and 
 is the output.  The reader might recognize this 
system as producing an autoregressive moving average process as described in Section 10.4.  
This system can be described by a transfer function expressed using either z-transforms or 
discrete-time Fourier transforms (DTFT) as
H(f )
B
−B
f
Ideal LPF
t = nto
N(t)
N[n]
1
Sampler
Figure 11.1  
Block diagram of a sampling system to convert white noise from continuous 
time to discrete time.
Nf t 
SNfNf f 
No
2------rect
f
2B
-------




No 2,

f
B,

0,
     otherwise.



=
=
RNfNf 
 
NoBsinc 2B


=
to
RNN k
 
NoBsinc 2kBto


=
N n
 
RNN k
 
0
=
k
0

2Bto
fo
1 to

=
fo
2B m

=
m
aiY n
i
–


i
0
=
p

bkX n
k
–


k
0
=
q

=
X n
 
Y n
 


478    Chapter 11
www.Academicpress.com
 or 
.
(11.18)
If the DTFT is used, it is understood that the frequency variable  is actually a normalized 
frequency (normalized by the sampling rate).  The system can also be described in terms of 
a discrete-time impulse response, 
, which can be found through either an inverse 
z-transform or an inverse DTFT.  The following results apply to any discrete-time system 
described by an impulse response, 
, and transfer function, 
.
Theorem 11.2:  Given a discrete-time LTI system with impulse response 
 and
transfer function 
, and a random input process 
, the mean and autocorrelation
functions of the output process, 
, can be described by
,
(11.19a)
.
(11.19b)
Furthermore, if 
 is WSS, then 
 is also WSS with
,
(11.20a)
,
(11.20b)
.
(11.20c)
Again, it is emphasized that the frequency variable in the PSD of a discrete-time
process is to be interpreted as frequency normalized by the sampling rate.  
Example 11.3:  
A discrete-time Gaussian white noise process has zero-mean and an autocorrelation 
function of 
.  This process is input to a system described by the difference 
equation
.
Note that this produces an AR(1) process at the output.  The transfer function and 
impulse response of this system are
H z 
bkz k
–
k
0
=
q

aiz i
–
i
0
=
p

------------------------
=
H f 
bke j2kf
–
k
0
=
q

aie j2if
–
i
0
=
p

---------------------------------
=
f
h n
 
h n
 
H f 
h n
 
H f 
X n
 
Y n
 
Y n
 
X n
 *h n
 
=
RYY n1 n2
	


RXX k1 k2
	

h n1
k1
–

h n2
k2
–


k2

–
=


k1

–
=


=
X n
 
Y n
 
Y
XH 0
 
=
RYY n
 
RXX n
 *h n
 *h
n
–


=
SYY f 
SXX f  H f  2
=
RXX n
 
2 n
 
=
Y n
 
aY n
1
–


bX n
 
+
=


Random Processes in Linear Systems    479
www.Academicpress.com
 and 
,
respectively, assuming that 
.  The autocorrelation and PSD functions of the output 
process are
 and 
,
respectively.
11.3 Noise Equivalent Bandwidth
Consider an ideal LPF with a bandwidth 
 whose transfer function is shown in Figure 11.2.  
Suppose white Gaussian noise with PSD 
 is passed through this filter.  The total output 
power would be 
.  For an arbitrary LPF, the output noise power would be 
.
(11.21)
One way to define the bandwidth of an arbitrary filter is to construct an ideal LPF that 
produces the same output power as the actual filter.  This results in the following definition of 
bandwidth known as noise equivalent bandwidth.  
Definition 11.1:  The noise equivalent bandwidth of a LPF with transfer function
 is
.
(11.22)
H f 
b
1 a
– e j2f
–
------------------------
=
h n
 
banu n
 
=
a
1

RYY n
 
b2a n
1
a2
–
--------------
=
SYY f 
2b2
1 a
– e j2f
–
2
-----------------------------
2b2
1
a2
2acos 2f


–
+
-------------------------------------------------
=
=
B
B
f
H(f ) 2
Figure 11.2  
Power transfer function of an arbitrary and ideal LPF.  
 if areas under the 
two curves are equal.
B
Bneq
=
No 2

Po
NoB
=
Po
No
2
------
H f  2 fd

–


=
H f 
Bneq
1
2 H 0
  2
---------------------
H f  2 fd

–


1
H 0
  2
------------------
H f  2 fd
0


=
=


480    Chapter 11
www.Academicpress.com
This definition needs to be slightly adjusted for bandpass filters (BPFs).  If the center
of the passband is taken to be at some frequency, 
, then the noise equivalent
bandwidth is
.
(11.23)
Example 11.4:  
Consider the RC LPF whose transfer function is
.
The noise equivalent bandwidth of this filter is
.
In addition to using the noise equivalent bandwidth, the definitions in Section 10.3 
presented for calculating the bandwidth of a random process can also be applied to find 
the bandwidth of a filter.  For example, the absolute bandwidth and the RMS bandwidth 
of this filter are both infinite while the 3 dB (half power) bandwidth of this filter is
,
which for this example is slightly smaller than the noise equivalent bandwidth.
11.4 Signal-to-Noise Ratios
Often the input to a linear system will consist of signal plus noise, namely,
,
(11.24)
where the signal part can be deterministic or a random process.  We can invoke linearity to 
show that the mean process of the output can be viewed as a sum of the mean due to the signal 
input alone plus the mean due to the noise input alone.  That is,
.
(11.25)
In most cases, the noise is taken to be zero-mean, in which case the mean at the output is due 
to the signal part alone.  
When calculating the autocorrelation function of the output, we cannot invoke superposition 
since autocorrelation is not a linear operation.  First, we calculate the autocorrelation function 
of the signal plus noise input.
fo
Bneq
1
2 H fo

 2
----------------------
H f  2 fd

–


1
H fo

 2
-------------------
H f  2 fd
0


=
=
H f 
1
1
j2fRC
+
----------------------------
=
Bneq
1
1
2fRC

2
+
--------------------------------- fd
0


1
2RC
---------------tan 1
–
u
 
0

1
4RC
-----------
=
=
=
B3dB
1
2RC
---------------
=
X t 
S t 
N t 
+
=
Y t 
S t *h t 
N t *h t 
+
=



Random Processes in Linear Systems    481
www.Academicpress.com
.
(11.26)
If the signal and noise part are independent, which is generally a reasonable assumption, and 
the noise is zero-mean, then this autocorrelation becomes
,
(11.27)
or, assuming all processes involved are WSS,
.
(11.28)
As a result, the PSD of the output can be written as
,
(11.29)
which is composed of two terms, namely that due to the signal and that due to the noise.  
We can then calculate the output power due to the signal part and the output power due to 
the noise part.
Definition 11.2:  The signal-to-noise ratio (SNR) for a signal comprises the sum of a
desired (signal) part and a noise part is defined as the ratio of the power of the signal
part to the power (variance) of the noise part.  That is, for 
,
.
(11.30)
Example 11.5: 
Suppose the input to the RC LPF of the previous example consists of a sinusoidal signal 
plus white noise.  That is, let the input be 
, where 
 is white Gaussian 
noise as in the previous example and 
, where 
 is a uniform random 
variable over 
 that is independent of the noise.  The output can be written as 
, where 
 is the output due to the sinusoidal signal input and 
 
is the output due to the noise.  The signal output can be expressed as
,
and the power in this sinusoidal signal is
.
(Continued)
RXX t1 t2
	


E
S t1


N t1


+

 S t2


N t2


+




=
RXX t1 t2
	


RSS t1 t2
	


RNN t1 t2
	


+
=
RXX 
 
RSS 
 
RNN 
 
+
=
SYY f 
SXX f  H f  2
SSS f  H f  2
SNN f  H f  2
+
=
=
X t 
S t 
N t 
+
=
SNR
E S2 t 


E N2 t 


----------------------
RSS 0
 
RNN 0
 
------------------
SSS f  fd

–


SNN f  fd

–


-------------------------------
=
=
=
X t 
S t 
N t 
+
=
N t 
S t 
a
ot

+


cos
=

0 2 
	

Y t 
So t 
No t 
+
=
So t 
No t 
So t 
a H fo


ot
H fo




+
+


cos
=
RSoSo 0
 
a2 H fo

 2
2
-------------------------
=


482    Chapter 11
www.Academicpress.com
From the results of Example 11.1, the noise power at the output is
.
Therefore, the SNR of the output of the RC LPF is
.
Suppose we desire to adjust the RC time constant (or, equivalently, adjust the bandwidth) 
of the filter so that the output SNR is optimized.  Differentiating with respect to the 
quantity 
, setting equal to zero and solving the resulting equation produces the 
optimum time constant
.
Stated another way, the 3 dB frequency of the RC filter is set equal to the frequency of 
the input sinusoid in order to optimize output SNR.  The resulting optimum SNR is
.
11.5 The Matched Filter
Suppose we are given an input process consisting of a (known, deterministic) signal plus an 
independent white noise process (with a PSD of 
).  It is desired to filter out as much of 
the noise as possible while retaining the desired signal.  The general system is shown in 
Figure 11.3.  The input process 
 is to be passed through a filter with 
impulse response 
 that produces an output process 
.  The goal here is to design the 
filter to maximize the SNR at the filter output.  Due to the fact that the input process is not 
necessarily stationary, the output process may not be stationary and therefore the output SNR 
may be time varying.  Hence, we must specify at what point in time we want the SNR to be 
maximized.  Picking an arbitrary sampling time, 
, for the output process, we desire to design 
the filter such that the SNR is maximized at time 
.  
Let 
 be the value of the output of the filter at time 
.  This random variable can be 
expressed as
,
(11.31)
RNoNo 0
 
No
4RC
-----------
=
SNR
2a2RC H fo

 2
No
-------------------------------------
2a2RC
No 1
2foRC

2
+


------------------------------------------------
=
=
RC
RCopt
1
2fo
-----------
=
SNRopt
a2
2Nofo
------------------
=
No 2

s(t)
N(t)
+
h(t)
t = to
Y(t)
Yo= Y(t)o
Figure 11.3  
Linear system for filtering noise from a desired signal.
X t 
s t 
N t 
+
=
h t 
Y t 
to
t
to
=
Yo
to
Yo
Y to


s t *h t  t
to
=
NY to


+
=
=


Random Processes in Linear Systems    483
www.Academicpress.com
where 
 is the noise process out of the filter.  The powers in the signal and noise parts, 
respectively, are given by
,
(11.32)
.
(11.33)
The SNR is then expressed as the ratio of these two quantities,
.
(11.34)
We seek the impulse response (or equivalently the transfer function) of the filter that 
maximizes the SNR as given in Equation (11.34).  To simplify this optimization problem, 
we use Schwarz’s inequality, which states that
,
(11.35)
where equality holds if and only if 
1.  Applying this result to the expression for 
SNR produces an upper bound on the SNR:
,
(11.36)
where 
 is the energy in the signal 
.  Furthermore, this maximum SNR is achieved when 
.  In terms of the transfer function, this relationship is expressed as 
.  The filter that maximizes the SNR is referred to as a matched filter 
NY t 
signal power
s t *h t  t
to
=

2
h u
 s to
u
–

 u
d

–


2
=
=
noise power
No
2
------
H f  2

–


df
No
2
------
h2 t 

–


dt
=
=
SNR
2
No
------
h u
 s to
u
–

 u
d

–


2
h2 t 

–


dt
--------------------------------------------------------
=
x t y t  td

–


2
x t  2 t
y t  2 td

–


d

–



x t 
y t 

SNR
2
No
------
h t  2 t
s to
t
–

 2 td

–


d

–


h2 t 

–


dt
----------------------------------------------------------------------

2
No
------
s to
t
–

 2 td

–


=
2
No
------
s t  2 td

–


2Es
No
---------
=
=
Es
s t 
h t 
s to
t
–



H f 
S* f e j
– 2fto

1 The notation 
 means that 
 is proportional to 
.
x t 
y t 

x t 
y t 

484    Chapter 11
www.Academicpress.com
since the impulse response is matched to that of the desired signal.  These results are 
summarized in the following theorem.
Theorem 11.3:  If an input to an LTI system characterized by an impulse response,
,  is given by 
 where 
 is a white noise process, then a
matched filter will maximize the output SNR at time 
.  The impulse response and
transfer function of the matched filter are given by
 and 
.
(11.37)
Furthermore, if the white noise at the input has a PSD of 
, then the
optimum SNR produced by the matched filter is
,
(11.38)
where 
 is the energy in the signal 
.
Example 11.6:  
A certain communication system transmits a square pulse given by
This signal is received in the presence of white noise at a receiver producing the received 
process 
.  The matched filter that produces the optimum SNR at time 
 
for this signal has an impulse response of the form
The output of the matched filter is then given by
.
Therefore, the matched filter for a square pulse is just a finite time integrator.  The 
matched filter simply integrates the received signal for a period of time equal to the 
width of the pulse.  When sampled at the correct point in time, the output of this 
integrator will produce the maximum SNR.  The operation of this filter is illustrated 
in Figure 11.4.  
h t 
X t 
s t 
N t 
+
=
N t 
to
h t 
s to
t
–


=
H f 
S* f e j
– 2fto
=
SNN f 
No 2

=
SNRmax
2Es
No
---------
=
Es
s t 
s t 
1,    0
t
t1,


0,     otherwise.



=
R t 
s t 
N t 
+
=
to
h t 
s to
t
–


1,       to
t1
–
t

to,

0,
otherwise.



=
=
Y t 
h t *R t 
h t
u
–

R u
  u
d

–


s u
to
t
–
+

R u
  u
d

–


R u
  u
d
t
to
–
t
to
–
t1
+

=
=
=
=


Random Processes in Linear Systems    485
www.Academicpress.com
Example 11.7:  
In this example, we expand on the results of the previous example and 
consider a sequence of square pulses with random (binary) amplitudes 
as might be transmitted in a typical communication system.  Suppose this 
signal is corrupted by white Gaussian noise and we must detect the 
transmitted bits.  That is, we must determine whether each pulse sent has 
a positive or negative amplitude.  Figure 11.5a shows both the square pulse train and the 
same signal corrupted by noise.  Note that by visually observing the signals, it is very 
difficult to make out the original signal from the noisy version.  We attempt to clean up 
this signal by passing it through the matched filter from Example 11.6.  In the absence of 
noise, we would expect to see a sequence of overlapping triangular pulses.  The matched 
filter output both with and without noise is illustrated in Figure 11.5b.  Notice that a 
great deal of noise has been eliminated by the matched filter.  To detect the data bits, we 
would sample the matched filter output at the end of each bit interval (shown by circles 
in the plot) and use the sign of the sample to be the estimate of the transmitted data bit.  
In this example, all of our decisions would be correct.  The MATLAB code used to generate 
these signals follows.  This is just a modified version of the code used to generate the 
PAM signal in Example 10.14.
N=10;
% No. of bit intervals.
Ns=25;
% No. of time samples per bit.
t=([1:Ns]-0.5)/Ns;
% time axis for pulse shape
p=ones(size(t));
% square pulse shape
d=sign(rand(1,N)-0.5); 
% random data bits
X(1:Ns:(Ns*(N-1)+1))=d;
X=conv(X,p);
% PAM signal with pulse shape.
sigma=sqrt(Ns/10);
% noise strength
noise=sigma*randn(size(X)); 
% Gaussian noise
t1
1
s(t)
t
(  )du
t−to+t1
to- t1
to + t1
to
t
Y(t)
òt−to
(a)
(b)
(c)
Figure 11.4  
(a) A square pulse, (b) the corresponding matched filter, and (c) the response of the matched 
filter to the square pulse.


(Continued)

486    Chapter 11
www.Academicpress.com
R=X+noise;
subplot(2,1,1)
% plot clean and noisy signal
x_axis=[1:length(R)]/Ns;
plot(x_axis,R, x_axis,X)
axis([0 N -3 3])
h=fliplr(p);
% 
matched 
filter 
impulse
response
z=conv(R,h);
% noisy output of matched fil-
ter
z2=conv(X,h);
% noise free MF output
zs=z(Ns*[1:N]);
% sample matched filter out-
puts
subplot(2,1,2)
% plot matched filter output
x_axis=[1:length(z)]/Ns;
plot(x_axis,z,'-',x_axis,z2,'-',[1:N],zs,'o')
11.6 The Wiener Filter
In this section, we consider another filter design problem that involves removing the noise 
from a sum of a desired signal plus noise.  In this case, the desired signal is also a random 
process (rather than a known, deterministic signal as in the last section) and the goal here is to 
estimate the desired part of the signal plus noise.  In its most general form, the problem is 
0
(a)
(b)
1
2
3
4
5
6
7
8
9
10
-3
-2
-1
0
1
2
3
PAM signal
0
1
2
3
4
5
6
7
8
9
10
-50
0
50
Matched filter output
Time (bit intervals)
1
−1
1
1
−1
1
1
−1
1
1
Transmitted sequence
1
-1
1
1
-1
1
  −1
1
1
Detected sequence
1
-
Figure 11.5  
(a) A binary PAM signal with and without additive noise along with (b) the result of passing 
both signals through a matched filter.


Random Processes in Linear Systems    487
www.Academicpress.com
stated as follows.  Given a random process 
, we want to form an estimate 
 of some 
other zero-mean process 
 based on observation of some portion of 
.  We require the 
estimator to be linear.  That is, we will obtain 
 by filtering 
.  Hence, 
.
(11.39)
We want to design the filter to minimize the mean square error
.
(11.40)
In this section, we will consider the special case where the observation consists of the process 
we are trying to estimate plus independent noise.  That is  
.  We observe 
 for some time interval 
 and based on that observation, we will form an 
estimate of 
.  Consider a few special cases:
•
Case I: If 
, then we have a filtering problem in which we must 
estimate the present based on the entire past.  We may also have 
 
in which case we have a filtering problem where we must estimate the present based 
on the most recent past.
•
Case II: If 
, then we have a smoothing problem where we must 
estimate the present based on a noisy version of the past, present, and future.
•
Case III: If 
, then we have a prediction problem where we must 
estimate the future based on the past and present.  
All of these cases can be cast in the same general framework, and a single result will describe 
the optimal filter for all cases.  In order to derive the optimal filter, it is easier to view the 
problem in discrete time and then ultimately pass to the limit of continuous time.  Thus, we 
reformulate the problem in discrete time.  Given an observation of the discrete-time process 
 over some time interval 
, we wish to design a filter 
 
such that the linear estimate
(11.41)
minimizes the mean square error 
.
The filter 
 can be viewed as a sequence of variables.  We seek to jointly optimize with 
respect to each variable in that sequence.  This can be done by differentiating with respect to 
each variable and setting the resulting equations equal to zero:
,  
.
(11.42)
X t 
Y t 
Z t 
X t 
Y t 
X t 
Y t 
h t
u
–

X u
  u
d

–


=
E 2 t 


E
Z t 
Y t 
–

2


=
X t 
Z t 
N t 
+
=
X t 
t
t1 t2
	



Z t 
t1 t2
	



–
t	


=
t1 t2
	


t
to
–
t	


=
t1 t2
	



–

	


=
t1 t2
	



–
t
to
–
	


=
X n
 
Z n
 
N n
 
+
=
n
n1 n2
	



h n
 
Y n
 
h n
k
–

X k
 
k
n1
=
n2
=
E 2 n
 


E
Z n
 
Y n
 
–

2


=
h n
 
d
dh m


---------------E 2 n
 


2E  n
 
d
dh m


--------------- n
 
0
=
=
m
n
n2
–
n
n1
–
	




488    Chapter 11
www.Academicpress.com
Noting that 
, 
(11.43)
the system of equations to solve becomes
, 
for 
.
(11.44)
Equivalently, this can be rewritten as
, 
for 
.
(11.45)
In summary, the filter that minimizes the mean square error will cause the observed data to be 
orthogonal to the error.  This is the orthogonality principle that was previously developed in 
Chapter 6, Section 6.5.3.  Applying the orthogonality principle, we have
.
(11.46)
Assuming all the processes involved are jointly WSS, these expectations can be written in 
terms of autocorrelation and cross-correlation functions as
, 
,
(11.47)
or equivalently (making the change of variables 
 and 
),
, 
.
(11.48)
These equations are known as the Wiener–Hopf equations, the normal equations, or the Yule–
Walker equations.  The resulting filter found by solving this system of equations is known as 
the Wiener filter.
A similar result can be found for continuous time systems by applying the orthogonality principle 
in continuous time.  Given an observation of 
 over the time interval 
, the orthogonality 
principle states that the filter which minimizes the mean square prediction error will satisfy
, 
for  
.
(11.49)
This produces the continuous time version of the Wiener–Hopf equation
d
dh m


--------------- n
 
d
dh m


--------------- Z n
 
Y n
 
–


d
dh m


---------------Y n
 
–
X n
m
–


–
=
=
=
E  n
 X n
m
–




0
=
m
n
n1
–
n
n2
–
	



E  n
 X m




0
=
m
n1 n2
	



E  n
 X m




E X m

 Z n
 
h n
k
–

X k
 
k
n1
=
n2
–








0
=
=
h n
k
–

RXX k
m
–


k
n1
=
n2
RXZ n
m
–


=
m
n1 n2
	



i
n
k
–
=
j
n
m
–
=
h i RXX j
i
–


i
n
n2
–
=
n
n1
–

RXZ j 
=
j
n
n2
–
n
n1
–
	



X t 
t1 t2
	


E  t X s 


0
=
s
t1 t2
	




Random Processes in Linear Systems    489
www.Academicpress.com
, 
.
(11.50)
The techniques used to solve the Wiener–Hopf equation depend on the nature of the 
observation interval.  For example, consider the smoothing problem where the observation 
interval is 
.  In that case, the Wiener–Hopf equation becomes
.
(11.51)
The left hand side of the equation is a convolution and the integral equation can easily be solved 
using Fourier transforms.  Taking a Fourier transform of both sides of the equation results in
.
(11.52)
Note also that if the noise is zero-mean and independent of 
, then 
 and 
.  The transfer function of the Wiener filter for the smoothing 
problem then becomes
.
(11.53)
Example 11.8:  
Suppose the desired signal 
 has a spectral density of 
and the noise is white with a PSD of 
.  Then the Wiener filter for the smoothing 
problem has the form
.
The corresponding impulse response is
.
Note that this filter is not causal.  This is due to the nature of the smoothing problem, 
whereby we estimate the present based on past, present, and future.  
h v
 RXX 
v
–

 v
d
t
t2
–
t
t1
–

RXZ 
 
=

t
t2
–
t
t1
–
	



t1 t2
	



–

	


=
h v
 RXX 
v
–

 v
d

–


RXZ 
 
=
H f SXX f 
SXZ f 
=
H f 

SXZ f 
SXX f 
----------------
=
Z t 
RXZ 
 
RZZ 
 
=
RXX 
 
RZZ 
 
RNN 
 
+
=
H f 
SZZ f 
SZZ f 
SNN f 
+
---------------------------------------
=
Z t 
SZZ f 
1
1
f2
+
-------------
=
SNN f 
1
=
H f 
1
1
f2
+
-------------
1
1
f2
+
-------------
1
+
-----------------------
1
2
f2
+
-------------
=
=
h t 

2
-------
8 t
–


exp
=



490    Chapter 11
www.Academicpress.com
Next, consider the filtering problem where the observation interval is 
.  In 
this case, the Wiener–Hopf equation becomes
,  
.
(11.54)
It is emphasized now that the left hand side of the equation is not a convolution since the lower 
limit of the integral is not 
.  The resulting integral equation is much trickier to solve than in 
the case of the smoothing problem.  In order to develop a procedure for solving this general 
equation, consider the special case when 
.  In that case, the above integral 
equation becomes
, 
for 
.
(11.55)
Because we are estimating the present based on observing the past, the filter must be causal 
and thus its impulse response must be zero for negative time.  Therefore, for the special case 
when 
, the Wiener filter is 
.  
This example in itself is not very interesting since we would not expect 
 to be white, but it 
does help to find the general solution to the Wiener–Hopf equation.  First, before estimating 
, suppose we pass the input 
 through a causal filter with a transfer function 
.  
Call the output 
.  If 
 is chosen such that 
, then the process 
 
will be a white process and the filter is called a whitening filter.  We can then use the result of 
the previous special case to estimate 
 based on the white process 
.  Hence, we are 
designing the Wiener filter in two stages as illustrated in Figure 11.6.
To find the impulse response of the second filter, we start with the result that 
.  Also, since 
 can be written as 
, then 
.
(11.56)
The resulting quantities needed to form the second filter are then
.
(11.57)
t1 t2
	



–
t	


=
h v
 RXX 
v
–

 v
d
0


RXZ 
 
=

0 
	




–
RXX 
 
 
 
=
h 
 
RXZ 
 
=

0

RXX 
 
 
 
=
h 
 
RXZ 
 u 
 
=
X t 
Z t 
X t 
1 G f 

X˜ t 
G f 
G f  2
SXX f 
=
X˜ t 
Z t 
X˜ t 
H1(f)
1
G(f)
=
H2(f)
X(t)
X(t)
˜
Y(t)
Whitening
filter
Wiener filter
for white input
Figure 11.6  
Constructing the Wiener filter for the filtering problem as a cascade of two filters.
h2 
 
RX˜ Z 
 u 
 
=
X˜ t 
X˜ t 
X t *h1 t 
=
SX˜ Z f 
SXZ f H1
* f 
=
SX˜ Z f 
SXZ f 
G* f 
----------------
=
RX˜ Z 
 

1
–
SXZ f 
G* f 
----------------






=

Random Processes in Linear Systems    491
www.Academicpress.com
To construct the whitening filter, we need to find a 
 such that (1) 
 is 
causal and (2) 
.  The procedure for doing this is known as spectral 
factorization.  Since 
 is a PSD and thus is an even function of , it will factor in the form
,
(11.58)
where half of the poles and zeros are assigned to 
 and the other half are assigned to 
.  In order to be sure that 
  is causal, we assign to 
 those zeros in the upper 
half plane.  As will be shown in the next example, it is also important to assign poles from the 
upper half plane to 
 as well.  
Example 11.9:  
For this example, let 
, where 
 is white noise with a spectral density of 
 and independent of 
, which has a spectral density of 
.
Note also that
 and 
.
A pole–zero plot for the PSD function 
 is shown in Figure 11.7.  We assign the 
poles and zeros in the upper–half plane to the function 
 (and hence the poles and 
zeros in the lower half plane go to 
).  This results in
.
The corresponding impulse response is
.
As desired, the whitening filter is causal.  To find the form of the second filter, we first 
calculate the cross-spectral density between 
 and 
,
G f 
H1 f 
1 G f 

=
G f  2
SXX f 
=
SXX f 
f
SXX f 
G f G* f 
=
G f 
G* f 
H1 f 
G f 
G f 
X t 
Z t 
N t 
+
=
N t 
SNN f 
1
=
Z t 
SZZ f 
3
1
2f

2
+
-------------------------
=
SXZ f 
SZZ f 
=
SXX f 
SZZ f 
SNN f 
+
3
1
2f

2
+
-------------------------
1
+
4
2f

2
+
1
2f

2
+
-------------------------
2
j2f
+

 2
j2f
–


1
j2f
+

 1
j2f
–


-------------------------------------------------
=
=
=
=
SXX f 
*
*
o
o
Im(f)
Re(f)
* = Pole
o = Zero
Figure 11.7  
Pole–zero plot for the PSD function of Example 11.9.
G f 
G* f 
G f 
2
j2f
+
1
j2f
+
--------------------
=
H1 f 

1
j2f
+
2
j2f
+
--------------------
1
1
2
j2f
+
--------------------
–
=
=
h1 t 
 t 
e 2t
– u t 
–
=
X˜ t 
Z t 

(Continued)

492    Chapter 11
www.Academicpress.com
.
Taking an inverse Fourier transform, the cross-correlation function is
.
The impulse response of the second filter is then given by
.
When the actual Wiener filter is implemented, there is no reason the filter has to be 
implemented as a cascade of two filters.  We did this for ease of determining the filter.  
Combining these two filters into one produces
.
It can be easily verified that this filter does indeed satisfy the Wiener–Hopf equation.
Note, we could have also chosen 
, and 
 would 
still have been causal:
.
In this case, 
.
This leads to 
!!  Thus, we see it is important to assign both poles and zeros from 
the upper half plane to 
.
Finally, we consider the prediction problem where we wish to estimate the value of 
 based 
on observing 
 over the time interval 
.  Applying the orthogonality principle, the 
appropriate form of the Wiener–Hopf equation for the prediction problem becomes
,  
.
(11.59)
SX˜ Z f 
SXZ f H1
* f 
3
1
2f

2
+
-------------------------1
j2f
–
2
j2f
–
-------------------
3
1
j2f
+

 2
j2f
–


-------------------------------------------------
1
1
j2f
+
--------------------
1
2
j2f
–
-------------------
+
=
=
=
=
RX˜ Z 
 
e 
– u 
 
e2u

–


+
=
h2 
 
RX˜ Z 
 u 
 
e 
– u 
 
=
=
H f 
H1 f H2 f 
1
j2f
+
2
j2f
+
--------------------




1
1
j2f
+
--------------------




1
2
j2f
+
--------------------
=
=
=
h t 

e 2t
– u t 
=
G f 
2
j2f
+


1
j2f
–



=
H1 f 
1 G f 

=
H1 f 
1
j2f
–
2
j2f
+
--------------------
1
–
3
2
j2f
+
--------------------
+
=
=
h1 t 

 t 
–
3e 2t
– u t 
+
=
SX˜ Z f 
SXZ f H1
* f 
3
1
2f

2
+
-------------------------1
j2f
+
2
j2f
–
--------------------
3
1
j2f
–

 2
j2f
–


-------------------------------------------------
3
1
j2f
–
-------------------
3
–
2
j2f
–
-------------------
+
RX˜ Z 
 

3eu

–


3e2u

–


–
=
=
=
=
=
h2 t 
0
=
G f 
Z t 
X t 

–
t
to
–
	


h v
 RXX 
v
–

 v
d
to


RXZ 
 
=

to 
	





Random Processes in Linear Systems    493
www.Academicpress.com
This equation is solved using the same technique as with the filtering problem.  First, the input 
is passed through a whitening filter and then Equation (11.59) for the case when the input 
process is white.  The procedure for finding the whitening filter is exactly the same as before.  
The solution to Equation (11.59) when 
 is
.
(11.60)
In summary, the solution to the prediction problem is found by following these steps:
•
Step 1. Factor the input PSD according to 
, where 
 contains 
all poles and zeros of 
 that are in the upper half plane.  The whitening filter is then 
specified by 
.  Call 
 the output of the whitening filter when 
 is 
input.
•
Step 2. Calculate the cross-correlation function, 
.  The second stage of the 
Wiener filter is then specified by 
.  
•
Step 3. The overall Wiener filter is found by combining these two filters, 
.
It should be noted that the filtering problem can be viewed as a special case of the prediction 
problem when 
 and so this summary applies to the filtering problem as well.
Example 11.10:  
In this example, we repeat the filter design of Example 11.9 for the case of the prediction 
problem.  As before, we pick the whitening filter to be of the form
.
Again, the resulting cross-correlation function is then  
.
Assuming that 
 so that the problem is indeed one of prediction, the impulse 
response of the second filter is
.
(Continued)
RXX 
 
 
 
=
h 
 
RXZ 
 u 
to
–


=
SXX f 
1
G f G* f 
-------------------------
=
G f 
SXX f 
H1 f 
1 G f 

=
X˜ t 
X t 
RX˜ Z 
 
h2 
 
RX˜ Z 
 u 
to
–


=
H f 
H1 f H2 f 
=
to
0
=
H1 f 
1
j2f
+
2
j2f
+
--------------------   
   h1 t 
 t 
e 2t
– u t 
–
=

=
RX˜ Z 
 
e 
– u 
 
e2u

–


+
=
to
0

h2 t 
RX˜ Z t u t
to
–


e t
– u t
to
–


=
=


494    Chapter 11
www.Academicpress.com
The impulse response of the Wiener prediction filter is then
.
This agrees with the result of the previous example when 
.  Figure 11.8 illustrates 
the impulse response of the Wiener prediction filter for several values of 
.
11.7 Bandlimited and Narrowband Random Processes
A random processes is said to be bandlimited if all of its frequency components are limited 
to some bandwidth, 
.  Specifically, if a random process 
 has a PSD function with an 
absolute bandwidth of 
, then the process is said to be bandlimited to 
 Hz.  For many 
bandlimited random processes, the  frequency components are clustered at or near direct 
current (d.c.)  Such a process is referred to as a lowpass random process.   If, on the other hand, 
the frequency components of a random process are removed from d.c. and reside in some 
non-zero frequency band, the process is called a bandpass process.  These distinctions are 
illustrated in Figure 11.9.  For a bandpass process, in addition to the bandwidth, the location 
of the frequency band where the PSD is non-zero must also be specified.  In the figure, the 
parameter 
 describes that location.  While often 
 is taken to be the center of the band as 
illustrated in the figure, this does not have to be the case.  The parameter 
 can be chosen 
to be any convenient frequency within the band.  In any event, 
 is referred to as the 
center frequency of the band (even though it may not really be in the center).  Finally, if a 
bandpass random process has a center frequency that is large compared to its bandwidth, 
, then the process is said to be narrowband.
h t 
h1 t *h2 t 
 t 
e 2t
– u t 
–

* e t
– u t
to
–




e
2t
–
to
+ u t
to
–


=
=
=
to
0
=
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
time, t 
h(t)
to = 0
to = 1
to = 2
to = 3
Figure 11.8  
Impulse response of the Wiener prediction filter for Example 11.10.
to
B
X t 
B
B
fo
fo
fo
fo
fo
B
»


Random Processes in Linear Systems    495
www.Academicpress.com
Narrowband random processes frequently are found in the study of communication systems.  
For example, a commercial FM radio broadcast system uses channels with bandwidths of 
200 kHz which are located near 100 MHz.  Thus, the center frequency of an FM radio signal is 
about 500 times greater than its bandwidth.  In the US digital cellular system, 30 kHz channels 
are used at frequencies near 900 MHz.  In that case, the center frequencies are on the order of 
30,000 times the bandwidth.  
From studies of deterministic signals, the reader is probably aware that working with bandpass 
signals can be rather cumbersome.  Trigonometric functions pop up everywhere and lead to 
seemingly endless usage of various identities.  On the other hand, working with lowpass 
signals is often much simpler.  To ease the complexity of working with bandpass signals, 
various representations have been formulated that allow bandpass signals to be decomposed 
into combinations of related lowpass signals.  In this section, we focus on the most common of 
those decompositions, which is valid for narrowband signals.  Generalizations of the following 
results are available for signals that are bandpass but not necessarily narrowband but will not 
be covered here.  
Suppose a random process 
 is narrowband.  Then 
 can be expressed in terms of two 
lowpass processes 
 and 
 according to 
.
(11.61)
The two processes 
 and 
 are referred to as the inphase (I) and quadrature (Q) 
components of 
.  Although it is not proven here, the equality in the previous equation is 
in the mean-square sense.  That is, 
.
(11.62)
This Cartesian representation of the narrowband random process can also be replaced by a 
polar representation of the form
SXX(f)
f
SXX(f)
f
B
−B
fo
-fo
B
(a)
(b)
Figure 11.9  
The PSD functions of (a) a lowpass and (b) a bandpass random process.
Z t 
Z t 
X t 
Y t 
Z t 
X t 
ot


cos
Y t 
ot


sin
–
=
X t 
Y t 
Z t 
E
Z t 
X t 
ot


cos
Y t 
ot


sin
–


–
 
!2


0
=

496    Chapter 11
www.Academicpress.com
,
(11.63)
where 
 is called the real envelope of 
 and 
 is the excess phase.  We next 
describe the relationship between the statistics of the I and Q components and the statistics of 
the original random process.
The I and Q components of a signal can be extracted using the system shown in Figure 11.10. 
The passbands of the LPF need to be large enough to pass the desired components (i.e., >B/2 Hz) 
but not so large as to pass the double frequency components produced by the mixers (at and 
around 2
 Hz).  For narrowband signals where 
, the filters can be very loosely 
designed and hence we do not need to worry too much about the particular forms of these 
filters.  To see how this network functions, consider the output of the upper mixer.
.
(11.64)
After passing this through the LPF, the terms involving the double frequencies will be 
attenuated and the output of the upper LPF is indeed 
.  Similar calculations reveal that 
 is indeed the output of the lower branch. 
Next, we calculate  PSDs involving the I and Q components.  Consider first, multiplication of 
the process 
 by a sinusoid.  Let 
.  The autocorrelation function of 
 is easily calculated to be
.
(11.65)
Note that the process 
 is not WSS.  In order to compute the PSD of a process which is not 
stationary, we must first take the time average of the autocorrelation function (with respect to ) 
Z t 
R t 
ot
" t 
+


cos
=
R t 
Z t 
" t 
X
2cos(wot)
Lowpass
filter 
X
−2sin(wot)
Lowpass
filter
Z(t)
X(t)
Y(t)
Figure 11.10
Network for decomposing a narrowband process into its I and Q components.
fo
fo
B
»
2Z t 
ot


cos
2 X t 
ot


cos
Y t 
ot


sin
–
 
!
ot


cos
=
X t  1
2ot


cos
+
 
!
Y t 
2ot


sin
–
=
X t 
Y t 
Z t 
A t 
2Z t 
ot


cos
=
A t 
RAA t t

+
	


2RZZ 
 
o


cos
2ot
o
+


cos
+
 
!
=
A t 
t

Random Processes in Linear Systems    497
www.Academicpress.com
so that the result will be a function of  only.  This time-averaged autocorrelation function 
works out to be
.(11.66)
At this point, the PSD of 
 can then be found through Fourier transformation to be
.
(11.67)
Recall that the process 
 was assumed to be narrowband.   That is, its PSD has components 
near 
 and 
.  After shifting by 
, the term 
 has components near d.c. and also 
near 
.  The components near d.c. will pass through the filter, while those at and around 
 
will be attenuated.  Similarly, 
 will have terms near d.c. that will pass through the 
filter and terms near 
 which will not.  This is illustrated in Figure 11.11.  For notational 
convenience, let L.P.{ } denote the lowpass part of a quantity. Then the PSD of the inphase 
component of a narrowband process can be written in terms of the PSD of the original process as
.
(11.68)
Following a similar set of steps, the PSD of the Q component is found to be identical to the 
I component.  That is,
.
(11.69)
The cross-spectral density can also be calculated in a manner similar to the PSDs found above.  
The result is 
.
(11.70)

RAA t t

+
	


#
$
2RZZ 
 
o


cos
2ot
o
+


cos
#
$
+
 
!
2RZZ 
 
o


cos
=
=
A t 
SAA f 
SZZ f
fo
–


SZZ f
fo
+


+
=
Z t 
fo
fo
–
fo
SZZ f
fo
–


2fo
2fo
SZZ f
fo
+


2fo
–
SAA(f )
f
2fo
−2fo
B
LPF
B
2
B
2
−
Figure 11.11  
PSD of the input to the LPF in the I branch.
SXX f 
L.P. SZZ f
fo
–


SZZ f
fo
+


+
 
!
=
SYY f 
SXX f 
L.P. SZZ f
fo
–


SZZ f
fo
+


+
 
!
=
=
SXY f 
jL.P. SZZ f
fo
–

 SZZ
–
f
fo
+


 
!
=

498    Chapter 11
www.Academicpress.com
It is noted that if the PSD function 
 is symmetric about 
, then the cross-spectral 
density works out to be zero.  In that case, the I and Q components are orthogonal (since 
).  Furthermore, if the process 
 is zero-mean, then the I and Q components 
will also be zero-mean.  In this case, the I and Q components are then uncorrelated.  Finally, 
if in addition, 
 is a Gaussian random process, then the I and Q components are also 
statistically independent.  In summary, we have proven the results of the following theorem.  
Theorem 11.4:  For a narrowband process 
, the PSDs involving the I and Q
components 
 and 
 are given by
,
(11.71a)
.
(11.71b)
If 
 is a zero-mean Gaussian random process and its PSD is symmetric about
, then the I and Q components are statistically independent.
Example 11.11:  
Suppose zero-mean white Gaussian noise with a PSD of 
 is passed through an ideal 
BPF with a bandwidth of B Hz to produce the narrowband noise process 
 as shown 
in Figure 11.12.  The I and Q components will then have a PSD which is given by
.
The corresponding autocorrelation functions are
.
Since the PSD of 
 is symmetric about 
, the cross PSD is zero and therefore the I 
and Q components are independent.  
SZZ f 
f
fo
=
RXY 
 
0
=
Z t 
Z t 
Z t 
X t 
Y t 
SYY f 
SXX f 
L.P. SZZ f
fo
–


SZZ f
fo
+


+
 
!
=
=
SXY f 
jL.P. SZZ f
fo
–

 SZZ
–
f
fo
+


 
!
=
Z t 
f
fo
=
No 2

Z t 
SYY f 
SXX f 
Norect f B



=
=
RXX 
 
RYY 
 
NoBsinc B


=
=
Z t 
f
fo
=
Ideal BPF 
BW=B
White
noise
(a)
(b)
(c)
Z(t)
No/2
fo
-fo
SZZ(f)
B
No
SXX(f )
SYY(f)
=
f
f
B
2---
B
2---
–
Figure 11.12  
(a) Generation of a narrowband noise process, (b) its PSD function, and (c) the PSD function 
of the I and Q components.



Random Processes in Linear Systems    499
www.Academicpress.com
11.8 Complex Envelopes
When working with narrowband random processes, it is convenient to combine the I and Q 
components into a single lowpass random process whose real part is the I component and 
whose imaginary part is the Q component.  The resulting random process is a complex 
lowpass random process.
Definition 11.3:  For a narrowband process, 
, with I and Q components, 
 and
, respectively, the complex envelope, 
, is defined as
.
(11.72)
With this definition, the random process is written in terms of its complex envelope
according to
.
(11.73)
The properties developed in the previous section for the I and Q components of a narrowband 
random process can be used to determine equivalent properties for the complex envelope.  To 
be consistent with the definitions for complex random variables given in Chapter 5, we define 
the autocorrelation function of a complex random process as follows.
Definition 11.4:  For any complex random process 
, the autocorrelation function
is defined as2
.
(11.74)
If 
 represents the complex envelope of a narrowband random process and the
I and Q components are jointly WSS, then this autocorrelation function will be a
function only of 
.  Also, the corresponding PSD can be found through Fourier
transformation:
.
(11.75)
Using this definition together with the properties developed in the previous section, the 
autocorrelation function for a complex envelope is found to be
Z t 
X t 
Y t 
Gz t 
Gz t 
X t 
jY t 
+
=
Z t 
Re Gz t ejot


=
G t 
RGG t t

+



1
2---E G t G* t

+




=
G t 

SGG f 
RGG 
 


=
2 The same disclaimer must be made here as in Definition 5.13.  Many texts do not include the factor of 
 in the definition of the autocorrelation function for complex random processes, and therefore the 
reader should be aware that there are two different definitions prevalent in the literature.
1 2
	

500    Chapter 11
www.Academicpress.com
.
(11.76)
For the case where the I and Q components are orthogonal, this reduces to
.
(11.77)
The corresponding PSD is then
.
(11.78)
Hence, the complex envelope has the same PSD and autocorrelation function as the I and Q 
components.  It is left as an exercise for the reader to show that the autocorrelation and PSD 
functions of the original narrowband process can be found from those of the complex envelope 
according to
,
(11.79)
.
(11.80)
11.9 Engineering Application: An Analog Communication System
A block diagram of a simple amplitude modulation (AM) analog communication system is 
shown in Figure 11.13.  A message (usually voice or music) is represented as a random 
process 
 with some bandwidth 
.  This message is modulated onto a carrier using AM.  
The resulting AM signal is of the form
.
(11.81)
RGG 
 
1
2---E
X t 
jY t 
+

 X t

+

 j
– Y t

+






=
1
2---RXX 
 
1
2---RYY 
 
j
2---RYX 
 
j
2---RXY 
 
–
+
+
=
RGG 
 
1
2---RXX 
 
1
2---RYY 
 
+
RXX 
 
RYY 
 
=
=
=
SGG f 
SXX f 
SYY f 
L.P. SZZ f
fo
–


SZZ f
fo
+


+


=
=
=
SZZ f 
1
2---SGG f
fo
–


1
2---SGG
f
–
fo
–


+
=
RZZ 
 
Re RGG 
 ejo


=
Message 
source
Modulator
(AM)
+
Ideal
BPF
Envelope
detector
Nw(t)
X(t)
SAM(t)
R(t)
Z(t)
Xd(t)
Figure 11.13  
A block diagram of an amplitude modulation (AM) communication system.
X t 
B
SAM t 
Ao
X t 
+


ct

+


cos
=

Random Processes in Linear Systems    501
www.Academicpress.com
In AM, a bias, 
, is added to the message and the result forms the time-varying amplitude of 
a radio frequency (RF) carrier.  In order to allow for envelope detection at the receiver, the 
bias must satisfy 
.  Some example waveforms are shown in Figure 11.14.  
Note that due to the process of modulation, the AM signal now occupies a bandwidth of 
.  
The modulated RF signal is transmitted using an antenna and propagates through the 
environment to the receiver where it is picked up with a receiving antenna.  
To study the effects of noise on the AM system, we ignore other sources of corruption (e.g., 
interference, distortion) and model the received signal as simply a noisy version of the 
transmitted signal,
,
(11.82)
where 
 is a Gaussian white noise process with a PSD of 
.  To limit the effects of 
noise, the received signal is passed through a BPF whose passband is chosen to allow the AM 
Ao
Ao
max X t 

2B
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−3
−2
−1
0
1
2
3
Message, X(t)
Time
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−6
−4
−2
0
2
4
6
AM signal,SAM(t)
Time
Figure 11.14  
A sample message and the corresponding AM signal.
R t 
SAM t 
Nw t 
+
=
Nw t 
No 2
	

502    Chapter 11
www.Academicpress.com
signal to pass, while removing as much of the noise as possible.  This receiver filter is taken to 
be an ideal BPF whose bandwidth is 
.  The output of the filter is then modeled as an AM 
signal plus narrowband noise:   
.
(11.83)
The envelope detector is a device that outputs the real envelope of the input.  Hence, for the 
preceding input, the demodulated output will be
.
(11.84)
In its normal operating mode, the desired portion of the filter output will generally be much 
stronger than the noise.  In that case, we observe that most of the time 
 so that the demodulated output can be well approximated by
.
(11.85)
The d.c. component can easily be removed and hence 
 represents the desired component 
of the demodulated output and 
 is the undesired (noise) component.  The power in the 
desired component depends on the message and we simply write it as 
.  The 
I component of the narrowband noise has a spectral density which is equal to 
 for 
 
(and zero otherwise).  Therefore, the noise power at the demodulator output is 
.  The 
resulting SNR at the output of the AM system is
.
(11.86)
It is common to express this SNR in terms of the transmitted power required to support the 
AM modulator.  For an AM signal of the form in Equation (11.81), the transmitted power is 
,
(11.87)
assuming the carrier phase is independent of the message.  If the message is a zero-mean 
random process (which is usually the case), this expression simplifies to
.
(11.88)
Using this relationship, the SNR of the AM system can then be expressed as
2B
Z t 
SAM t 
Nx t 
ct

+


cos
Ny t 
ct

+


sin
–
+
=
Ao
X t 
Nx t 
+
+


ct

+


cos
Ny t 
ct

+


sin
–
=
Xd t 
Ao
X t 
Nx t 
+
+

2
Ny t 

2
+
=
Ao
X t 
Nx t 
+
+
Ny t 
»
Xd t 
Ao
X t 
Nx t 
+
+

X t 
Nx t 
E X2 t 


No
f
B

2NoB
SNR
E X2 t 


2NoB
----------------------
=
PT
E
Ao
X t 
+

2cos2 ct

+




=
E
Ao
X t 
+

2

E cos2 ct

+




=
PT
Ao
2
E X2 t 


+
2
-----------------------------------
=

Random Processes in Linear Systems    503
www.Academicpress.com
.
(11.89)
The factor, 
,
(11.90)
is known as the modulation efficiency of AM and is usually expressed as a percentage.  Note 
that due to the requirement that 
, the modulation efficiency of AM must be 
less than 50% (which would occur for square wave messages).  For a sinusoidal message, the 
modulation efficiency would be no more than 33%, while for a typical voice or music signal, 
the modulation efficiency might be much smaller.
Example 11.12:  
The MATLAB code that follows simulates the modulation and demodulation 
of an AM signal.  The message signal is the sum of two sinusoids (one at 
100 Hz and one at 250 Hz).  For this example, the carrier frequency is 
taken to be 
.  We have added noise to the AM signal to produce 
a typical received signal as shown in Figure 11.15a.  To demodulate the 
signal, we decompose the received signal into its I and Q components using the technique 
illustrated in Figure 11.9.  The LPF we used was a second-order Butterworth filter with a 
cutoff frequency of 400 Hz, but the particular form of the filter is not crucial.  Once 
these components are found, the real envelope is computed according to 
.  Our estimate of the message is then a scaled version of this 
envelope with the d.c. component removed.  Figure 11.15b shows the original message 
(dashed) and the recovered message (solid).  
fc=100000;
% carrier freq.
dt=1/(4*fc);
% sampling interval.
t=[0:dt:0.025];
f1=100; f2=250;
m=sin(2*pi*f1*t)+2*cos(2*pi*f2*t);
% message signal (two tones)
s=(m+1+max(abs(m))).*cos(2*pi*(fc*t+rand(1))); % AM signal
s=s+randn(1,length(s));
% Noisy AM signal
subplot(2,1,1)
plot(t,s); ylabel('AM signal');
f0=400;
a=2*pi*f0/sqrt(2);
h=exp(-a*t).*sin(a*t);
% Second order lowpass filter
% with cutoff freq at f0.
temp=s.*cos(2*pi*fc*t);
SNR
E X2 t 


Ao
2
E X2 t 


+
-----------------------------------
PT
NoB
----------
=
AM
E X2 t 


Ao
2
E X2 t 


+
-----------------------------------
=
Ao
max X t 

fc
100 kHz
=
R t 
X2 t 
Y2 t 
+
=

(Continued)

504    Chapter 11
www.Academicpress.com
x=conv(temp,h)*dt;
% I component
temp=s.*sin(2*pi*fc*t);
y=conv(temp,h)*dt;
% Q component
r=sqrt(x.^2+y.^2);
% real envelope
r=r(1:length(t));
mhat=r-sum(r)/length(r);
subplot(2,1,2)
plot(t,mhat/max(mhat),'b',t,m/max(m),'g--')
axis([0 max(t) -1.1 1.1])
ylabel('Message'); xlabel('time (sec)')
0
0.005
0.01
0.015
0.02
0.025
-10
-5
0
5
10
AM signal
0
0.005
0.01
0.015
0.02
0.025
−1
−0.5
0
0.5
1
Message
Time (sec)
(a)
(b)
Figure 11.15  
(a) An AM signal corrupted by noise along with (b) a comparison of the original message 
and the demodulated message.


505
CHAPTER 11
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 11.1: Continuous Time Linear Systems
11.1 A white noise process, 
, with a PSD of 
 is passed through a finite 
time integrator whose output is given by
.
Find the following:
(a)
the PSD of the output process,
(b)
the total power in the output process,
(c)
the noise equivalent bandwidth of the integrator (filter).
11.2 A certain LTI system has an input/output relationship given by
.
(a)
Find the output autocorrelation, 
, in terms of the input autocorrelation, 
.
(b)
Find the output PSD, 
, in terms of the input PSD, 
.
(c)
Does your answer to part (b) make sense in the limit as 
?
11.3 The output 
 of a linear filter is  times the input 
. Show that 
.
11.4 The output 
 of a filter is given in terms of its input 
 by
 
. 
(a)
Determine 
 as a function of 
. 
(b)
Find 
.
11.5 Consider a non-linear device such that the output is 
, where the input 
 consists of a signal plus a noise component, 
. Determine the 
mean and autocorrelation function for 
 when the signal 
 and the noise 
 are 
both Gaussian random processes and wide sense stationary (WSS) with zero-mean, and 
 is independent of 
.
X t 
SXX f 
No 2

=
Y t 
X u
  u
d
t
to
–
t
=
Y t 
X t 
X t
to
–


–
to
-------------------------------------
=
RYY 
 
RXX 
 
SYY f 
SXX f 
to
0

Y t 
c
X t 
RYY 
 
c2RXX 
 
=
Y t 
X t 
Y t 
X t 
X t
to
–


X t
2to
–


+
+
=
RYY 
 
RXX 
 
E Y2 t 

	
Y t 
aX2 t 
=
X t 
X t 
S t 
N t 
+
=
Y t 
S t 
N t 
S t 
N t 

506    Chapter 11
www.Academicpress.com
11.6 Calculate the spectrum for 
 in Exercise 11.5 if
and
11.7 If the input to a linear filter is a random telegraph process with  zero-crossings per 
second and an amplitude 
, determine the output PSD. The filter impulse response is 
.
11.8 The input to a linear filter is a random process with the following autocorrelation 
function:
.
The impulse response of the filter is of the same form and is
.
Determine the autocorrelation function of the filter output for 
 and for 
.
11.9 The power spectrum at the input to an ideal BPF is
Let the transfer function for the ideal BPF be
Determine the autocorrelation function of the output. You may have to make a 
reasonable approximation to obtain a simplified form. Assume that 
.
Y t 
SSS f 
A2
4------ 
 f
fc
+



 f
fc
–


+

	
=
SNN f 
No
2
------,     fc
B
2---
–
f
fc
B
2---
+


,
0,
   otherwise.





=
c
A
h t 
b
at
–


exp
u t 
=
RXX 
 
Ao

----------
o


sin
o
----------------------
=
h t 
1

------
1t


sin
1t
---------------------
=
o
1

o
1

SXX f 
a
1
f fo


2
+
---------------------------
=
H f 
b,    for f1
f
f2


,
0,    otherwise.



=
f2
f1
–
1
«

Exercises    507
www.Academicpress.com
11.10
A random process with a PSD of 
 is input to a filter.  The filter is to 
be designed such that the output process is white (constant PSD).  This filter is called a 
whitening filter.  
(a) Find the transfer function of the whitening filter for this input process.  Be sure 
that the filter is causal.
(b) Sketch a circuit which will realize this transfer function.
11.11
White Gaussian noise is input to an RC LPF.  
(a) At what sampling instants is the output independent of the input at time 
?
(b) At what sampling instants is the output independent of the output at time 
?
(c) Repeat parts (a) and (b) if the filter is replaced by the finite time integrator of 
Exercise 11.1.
11.12
A white Gaussian noise process, 
, is input to two filters with impulse responses, 
 and 
, as shown in the accompanying figure.  The corresponding outputs 
are 
 and 
, respectively.  
(a) Derive an expression for the cross-correlation function of the two outputs, 
.
(b) Derive an expression for the cross-spectral density of the two outputs, 
.
(c) Under what conditions (on the filters) are the two outputs independent when 
sampled at the same instants in time?  That is, when are 
 and 
 
independent?  Express your constraints in terms of the impulse responses of the 
filters and also in terms of their transfer functions.
(d) Under what conditions (on the filters) are the two outputs independent when 
sampled at different instants in time.  That is, when are 
 and 
 
independent for arbitrary 
 and 
?  Express your constraints in terms of the 
impulse responses of the filters and also in terms of their transfer functions.
11.13
If the inputs to two linear filters 
 and 
 are 
 and 
, respectively, 
show that the cross-correlation between the outputs 
 and 
 of the two filters is
.
SXX f 
1
1
f2
+
-------------
=
t
t1
=
t
t1
=
h1 t 
h2 t 
N t 
Y1 t 
Y2 t 
N t 
h1 t 
h2 t 
Y1 t 
Y2 t 
RY1Y2 
 
SY1Y2 
 
Y1 to


Y2 to


Y1 t1


Y2 t2


t1
t2
h1 t 
h2 t 
X1 t 
X2 t 
Y1 t 
Y2 t 
RY1Y2 
 
h1 
 h2 
 RX1X2 


–
+

 
d

d

–



–


=

508    Chapter 11
www.Academicpress.com
Section 11.2: Discrete-Time Systems
11.14
Is the following function a valid discrete-time autocorrelation function?  Justify your 
answer.
         
11.15
A discrete random sequence 
 is the input to a discrete linear filter 
. The 
output is 
. Let 
. Find 
 in terms of the 
autocorrelation functions for 
 and 
 and the cross-correlation function 
between 
 and 
.
11.16
The unit impulse response of a discrete linear filter is 
, where 
. 
The autocorrelation function for the input random sequence is 
 
Determine the cross-correlation function between the input and output random 
sequences.
11.17
Find the PSD of a discrete random sequence with the following autocorrelation 
function: 
, where 
.
11.18
A discrete-time linear filter has a unit pulse response 
. The input to this filter is a 
random sequence with uncorrelated samples. Show that the output PSD is real and 
non-negative.
11.19
The input, 
, to a filter is a discrete-time zero-mean random process whose 
autocorrelation function is 
.  The input/output relationship of the filter 
is given by
.
(a) Find the autocorrelation function of the output, 
.
(b) Find the PSD of the output, 
.
RXX k
 	
1,    k = 1,
3
4---,    k = 
3,

0,    otherwise.







=
X n
 	
h n
 	
Y n
 	
Z n
 	
X n
i
+

	
Y n
 	
–
=
E Z2 n
 	

	
X n
 	
Y n
 	
X n
 	
Y n
 	
h n
 	
anu n
 	
=
a
1

RXX k
 	
1,   k = 0,
0,   otherwise.



=
RXX k
 	
a b k


=
b
1

h n
 	
X k
 	
RXX n
 	

 n
 	
=
Y k
 	
1
n---
X k
m
–

	
m
0
=
n
1
–

=
RYY n
 	
SYY f 

Exercises    509
www.Academicpress.com
11.20
The input to a filter is a discrete-time, zero-mean, random process whose 
autocorrelation function is
,
for some constant  such that 
.  We wish to filter this process so that the output 
of the filter is white.  That is, we want the output, 
, to have an autocorrelation 
function, 
.
(a) Find the transfer function of the filter.  You may express your answer in terms of 
either a DTFT or a z-transform.
(b) Find the impulse response of the filter.
For both parts, make sure your answer results in a causal filter.
Section 11.3: Noise Equivalent Bandwidth
11.21
Determine the noise equivalent bandwidth for a filter with impulse response
 
.
11.22
A filter has the following transfer function:
.
Determine the ratio of the noise equivalent bandwidth for this filter to its 3-dB 
bandwidth.
11.23
Suppose you want to learn the characteristics of a certain filter. A white noise source 
with an amplitude of 15 watts/Hz is connected to the input of the filter. The power 
spectrum of the filter output is measured and found to be
.
(a) What is the bandwidth (3 dB) of the filter? 
(b) What is the attenuation (or gain) at zero frequency? 
(c) Show one possible (i.e., real, causal) filter that could have produced this output 
PSD.
11.24
A filter has an impulse response of 
.  Find the noise equivalent 
bandwidth of the filter.
RXX n
 	
a n
=
a
a
1

Y k
 	
RYY n
 	

 n
 	
=
h t 
b
at
–


exp
u t 
=
H f 
4
10
j2f
+
-----------------------
=
SYY f 
30
2f

2
102
+
-------------------------------
=
h t 
te t
– u t 
=

510    Chapter 11
www.Academicpress.com
11.25
A filter has a transfer function given by
.
(a) Is this filter, lowpass, highpass, or bandpass?
(b) Find the noise equivalent bandwidth of this filter.
11.26
The definition for the noise equivalent bandwidth of a filter was given in terms of the 
transfer function of the filter in Definition 11.1.  Derive an equivalent expression for the 
noise equivalent bandwidth of a filter in terms of the impulse response of the filter, 
.
11.27
Suppose a filter has a transfer function given by 
.  Find the noise 
equivalent bandwidth of the filter.  Hint: You might want to use the result of Exercise 
11.26.
Section 11.4: Signal-to-Noise Ratios
11.28
For the high-pass RC network shown, let 
, where 
 is white, 
WSS, Gaussian noise and  
 is a random variable 
uniformly distributed over 
.  Assuming zero 
initial conditions: 
(a) Find the output mean and variance.
(b) Find and plot the autocorrelation function of the 
output. 
(c) Find and plot the output PSD.
(d) Find the output SNR.
11.29
A parallel RLC network is driven by an input current source of 
,  where 
 is white, WSS noise with zero-mean. 
The output is the voltage across the network. The phase 
 is a random variable 
uniformly distributed over 
.  
(a) Find the output power spectrum by first computing the output autocorrelation 
function and then transforming. 
(b) Check the result of part (a) by using (11.12c). 
(c) Determine the output SNR and optimize the bandwidth to maximize the SNR. 
Assume 
 differs from the center frequency of the RLC filter. 
Hints: You may have to calculate the autocorrelation function as a function of  and  
and then let  go to infinity to find the steady-state output. There are several conditions 
you may want to consider; for example, the filter may be overdamped, critically 
H f 
1
j2f
+
1
j2f
+

2
2000

2
+
---------------------------------------------------------
=
h t 
H f 
sinc2 f 
=
X(t)
Y(t)
+
+
−
−
X t 
A
ct

+


sin
N t 
+
=
N t 

0 2


X t 
A
ct

+


sin
N t 
+
=
N t 

0 2


c
t

t

Exercises    511
www.Academicpress.com
damped, or under damped. It may also have an initial voltage on the capacitor and a 
current through the inductor.  State your assumption about these conditions.
11.30
A one-sided exponential pulse, 
, plus white noise is input to the 
finite time integrator of Exercise 11.1.  Adjust the width of the integrator, 
, so that 
the output SNR is maximized at 
.
11.31
A square pulse of width 
 plus zero-mean white Gaussian noise is input to a 
filter with impulse response, 
.  
(a) Find the value of the constant 
 such that the SNR at the output of the filter will 
be maximum.
(b) Assuming the square pulse is non-zero over the time interval 
, at what 
sampling time will the SNR at the output of the filter be maximized?
11.32
The input to a filter consists of a half-sinusoidal pulse
plus zero-mean white Gaussian noise.
(a) Suppose the impulse response of the filter is rectangular, 
.  
What should the width of the rectangle, 
, be in order to maximize the SNR at 
the output?  At what point in time does that maximum occur?
(b) Suppose the impulse response of the filter is triangular, 
.  What 
should the width of the triangle, 
, be in order to maximize the SNR at the 
output?  At what point in time does that maximum occur?
(c) Which filter (rectangle or triangle) produces the larger SNR and by how much?  
Specify your answer in decibels (dBs).
Section 11.5: The Matched Filter
11.33
(a) Determine the impulse response of the filter matched 
to the pulse shape shown in the accompanying figure.  
Assume that the filter is designed to maximize the 
output SNR at time 
.  
(b) Sketch the output of the matched filter designed in part 
(a) when the signal 
 is at the input.
s t 
t
–


exp
u t 
=
to
t
to
=
to
1s
=
h t 
t t1

–


exp
u t 
=
t1
0 to



s t 
t


sin
, 0
t
1,


0,
otherwise,



=
h t 
rect t ta



=
ta
h t 
tri t tb



=
tb
s(t)
1
−1
to
3to
t
t
3to
=
s t 

512    Chapter 11
www.Academicpress.com
11.34
Find the impulse response and transfer function of a filter 
matched to a triangular waveform as shown in the 
accompanying figure when the noise is stationary and 
white with a power spectrum of 
.
11.35
A known deterministic signal, 
, plus colored (not white) noise, 
, with a PSD 
of 
 is input to a filter.  Derive the form of the filter that maximizes the SNR at 
the output of the filter at time 
.  To make this problem simpler, you do not need 
to insist that the filter is causal.
11.36
Consider the system described in Example 11.6 where a communication system 
transmits a square pulse of width 
.  In that example, it was found that the 
matched filter can be implemented as a finite time integrator which integrates over 
a time duration to 
 seconds.  For the sake of this problem, suppose 
.  
Suppose that due to imperfections in the construction of this filter, we actually 
implement a filter which integrates over a time interval of 
 seconds.  Determine 
what range of values of 
 would produce an output SNR which is within 0.25 dB 
of the optimal value (when 
).  The answer to this question will give you an 
idea of how precise the design of the match filter needs to be (or how impercise it 
can be).
Section 11.6: The Wiener Filter
11.37
Suppose we observe a random process 
 (without any noise) over a time interval 
.  Based on this observation, we wish to predict the value of the same random 
process at time 
.  That is, we desire to design a filter with impulse response, 
, whose output will be an estimate of 
:
.
(a) Find the Wiener–Hopf equation for the optimum (in the minimum mean square 
error (MMSE) sense) filter.
(b) Find the form of the Wiener filter if 
.
(c) Find an expression for the mean square error 
.
11.38
Suppose we are allowed to observe a random process 
 at two points in time, 
 
and 
.  Based on those observations we would like to estimate 
 at time 
 
where 
.  We can view this as an interpolation problem.  Let our estimator be 
a linear combination of the two observations,
.
to
to
2
so
s(t)
t
No 2

s t 
N t 
SNN f 
t
to
=
t1
t1
t1
100s
=
t2
t2
t2
t1
=
Z t 

–
t


t
to
+
h t 
Z t
to
+


Y t 
Zˆ t
to
+


h u
 Z t
u
–

 u
d
0


=
=
RZZ 
 

–


exp
=
E 2 t 

	
E
Z t
to
+


Y t 
–

2

	
=
Z t 
t0
t2
Z t 
t
t1
=
t0
t1
t2


Y t1


Zˆ t1


aZ t0


bZ t2


+
=
=

Exercises    513
www.Academicpress.com
(a) Use the orthogonality principle to find the MMSE estimator.
(b) Find an expression for the mean square error of the MMSE estimator.
11.39
Suppose we are allowed to observe a random process 
 at two points in time, 
 
and 
.  Based on those observations we would like to estimate 
 at time 
 
where 
.  We can view this as a prediction problem.  Let our estimator be a 
linear combination of the two observations,
.
(a) Use the orthogonality principle to find the MMSE estimator.
(b) Suppose that 
 for positive constants  and .  Show that 
in this case, the sample at time 
 is not useful for predicting the value of the 
process at time 
 (given we have observed the process at time 
).  
In other words, show that 
.
11.40
The sum of two independent random processes with PSDs
 and 
are input to a LTI filter.
(a) Determine the Wiener smoothing filter.  That is, find the impulse response of the 
filter that produces an output that is an MMSE estimate of 
.
(b) Find the PSD of the filtered signal plus noise.
11.41
The sum of two independent random sequences with autocorrelation functions
 and 
is input to an LTI filter.
(a) Determine the Wiener smoothing filter.  That is, find the impulse response of the 
filter which produces an output which is an MMSE estimate of 
.
(b) Find the PSD of the filtered signal plus noise.
(c) Find the input SNR and an estimate of the output SNR.  Discuss whether or not 
the Wiener filter improves the SNR.
Hint: Compare the spectra of the Wiener filter, the signal, and the noise by plotting 
each on the same graph.
Z t 
t0
t1
Z t 
t
t2
=
t0
t1
t2


Y t2


Zˆ t2


aZ t0


bZ t1


+
=
=
RZZ 
 
c
b 
–


exp
=
b
c
t
t0
=
t
t2
=
t
t1
t0

=
a
0
=
SSS f 
2
50
2f

2
+
----------------------------
=
SNN f 
40
=
S t 
RSS k
 	
10
1
1
10
------


 
! 2
–
-----------------------
1
10
------


 
! k
=
RNN k
 	
100
1
1
4---
 
 ! 2
–
-------------------- 1
4---
 
 ! k
=
S n
 	

514    Chapter 11
www.Academicpress.com
Sections 11.7 and 11.8: Narrowband Random Processes 
and Complex Envelopes
11.42
The PSD of a narrowband Gaussian noise 
process, 
, is as shown in the accompanying 
figure.
(a) Find and sketch the PSD of the 
I and Q components of the narrowband noise 
process.
(b) Find and sketch the cross-spectral density of 
the I and Q components.
11.43
The narrowband noise process of Exercise 11.42 is passed through the system shown 
in the accompanying figure. In the system, the LPF has a bandwidth which is large 
compared to 
 but small compared to 
.
(a) Show that the output of the system is proportional to 
, where 
 is 
the complex envelope of 
.
(b) Find and sketch the autocorrelation function of the output of the system. 
(Hint: You might find the Gaussian moment factoring theorem useful, see 
Exercise 6.18.)
11.44
Let 
 be a zero-mean, stationary, narrowband process whose I and Q components 
are 
 and 
, respectively.  Show that the complex envelope, 
, satisfies 
.
MATLAB Exercises
11.45
(a) Construct a signal plus noise random sequence using 10 samples of
,
where 
 is generated using randn in MATLAB and 
.  Design a 
discrete-time matched filter for the cosine signal.  Filter the signal plus noise 
sequence with the matched filter.  At what sample value does the filter output peak.
(b) Construct a signal plus noise random sequence using 10 samples of the following
,
where 
 is generated using randn in MATLAB, 
, and 
.  
Design a discrete-time matched filter for the 
 cosine signal.  Filter the signal plus noise 
sequence with the matched filter. At what sample value does the filter output peak.
fo
fo – B
SNN(f)
f
(  )2
N(t)
LPF
N t 
B
fo
GN t  2
GN t 
N t 
Z t 
X t 
Y t 
GZ t 
X t 
jY t 
+
=
E GZ t GZ t

+



	
0
=
X n
 	
2fonts


cos
N n
 	
+
=
N n
 	
fo
0.1 ts

=
X n
 	
2f1nts


cos
10
2f2nts


cos
N n
 	
+
+
=
N n
 	
f1
0.1 ts

=
f2
0.4 ts

=
f2

Exercises    515
www.Academicpress.com
11.46
If a random sequence has an autocorrelation function 
, find the 
discrete-time, pure prediction Wiener filter.  That is, find the filter 
 such that 
when 
 is input the output, 
, will be an MMSE estimate of 
.  
Determine and plot the PSD for the random sequence and the power transfer function, 
, of the filter.
11.47
You have a random process with the following correlation matrix,
.
Determine the pure prediction Wiener filter.  That is, find the coefficients of the 
impulse response, 
.  Then determine the power spectrum 
of the Wiener filter.  Are the results what you expected?
11.48
Generate a 100-point random sequence using randn(1,100) in MATLAB.  Use a 
first-order AR filter to filter this random process.  That is, the filter is
.
Let 
.  Use the filtered data to obtain an estimate for the first-order 
prediction Wiener filter.  Compare the estimated filter coefficient with the true value.
RXX k
 	
10 0.8 k


=
h n
 	
X n
 	
Y n
 	
X n
1
+

	
H f  2
1.0
0.3 0.09 0.027
0.3
1.0
0.3
0.09
0.09
0.3
1.0
0.3
0.027 0.09 0.3
1.0
h
h0 h1 h2 0 0 0 "


   

	
=
A z 
1
1
a1z 1
–
+
-----------------------
=
a1
0.1
–
=

517
CHAPTER 12
Probability and Random Processes. DOI: 10.1016\B978-0-12-386981-4-00012-7
© 2012 by Elsevier Inc. All rights reserved.
Simulation Techniques
With the increasing computational power of very inexpensive computers, simulation of various 
systems is becoming very common. Even when a problem is analytically tractable, sometimes 
it is easier to write a quick program to simulate the desired results. However, there is a certain 
art to building good simulations, and many times avoidable mistakes have led to incorrect 
simulation results. This chapter aims at helping the reader to build a basic knowledge of some 
common techniques used for simulation purposes. Most of the results presented in this chapter 
are just applications of material covered in previous chapters, so there is nothing 
fundamentally new here. Nevertheless, armed with some of the basic simulation principles 
presented in this chapter, the reader should be able to develop simulation tools with 
confidence.
12.1 Computer Generation of Random Variables
In this section, we study techniques used to generate random numbers.  However, we must  
start with a disclaimer.  Most of the techniques used in practice to generate so-called random 
numbers will actually generate a completely deterministic sequence of numbers. So, what is 
actually random about these random number generators? Strictly speaking, nothing!  Rather, 
when we speak of computer-generated random numbers, we are usually creating a sequence of 
numbers that have certain statistical properties that make them behave like random numbers, 
but in fact they are not really random at all.  Such sequences of numbers are more 
appropriately referred to as pseudorandom numbers.
12.1.1 Binary Pseudorandom Number Generators
To start with, suppose we would like to simulate a sequence of independent identically 
distributed (IID) Bernoulli random variables, 
. One way to do this would be to 
grab a coin and start flipping it and observe the sequence of heads and tails, which could then 
be mapped to a sequence of 1s and 0 s.  One drawback to this approach is that it is very time 
consuming.  If our application demanded a sequence of length 1 million, not many of us would 
have the patience to flip the coin that many times. Therefore, we seek to assign this task to a 
computer.  So, to simulate an IID sequence of random variables, essentially we would like to 
create a computer program that will output a binary sequence with the desired statistical 
X1 X2 X3 




518    Chapter 12
www.Academicpress.com
properties.  For example, in addition to having the various bits in the sequence be statistically 
independent, we might also want 0 s and 1s to be equally likely.
Consider the binary sequence generated by the linear feedback shift register (LFSR) structure 
illustrated in Figure 12.1.  In that figure, the square boxes represent binary storage elements 
(i.e., flip-flops) while the adder is modulo-2 (i.e., an exclusive OR gate).  Suppose the shift 
register is initially loaded with the sequence 1, 1, 1, 1.  It is not difficult to show that the shift 
register will output the sequence
.
(12.1)
If the shift register were clocked longer, it would become apparent that the output sequence 
would be periodic with a period of 15 bits. While periodicity is not a desirable property for a 
pseudorandom number generator, if we are interested in generating short sequences (of length 
less than 15 bits), then the periodicity of this sequence generator would not come into play.  If 
we are interested in generating longer sequences, we could construct a shift register with more 
stages so that the period of the resulting sequence would be sufficiently long so that its 
periodicity would not be of concern.
The sequence generated by our LFSR does possess several desirable properties. First, the 
number of 1s and 0 s is almost equal (eight 1s and seven 0 s is as close as we can get to equally 
likely with a sequence of length 15). Second, the autocorrelation function of this sequence is 
nearly equal to that of a truly random binary IID sequence (again, it is as close as we can 
possibly get with a sequence of period 15; see Exercise 12.1). Practically speaking, the 
sequence output by this completely deterministic device does a pretty good job of mimicking 
the behavior of an IID binary sequence. It also has the advantage of being repeatable. That is, 
if we load the shift register with the same initial contents, we can always reproduce the exact 
same sequence.
It should be noted that not all LFSRs will serve as good pseudorandom number generators.  
Consider for example the four-stage LFSR in Figure 12.2.  This shift register is only a slightly 
modified version of the one in Figure 12.1, yet when loaded with the sequence 1, 1, 1, 1, this 
shift register outputs a repeating sequence of all 1s (i.e., the period of the output sequence is 1). 
The only difference between the two shift registers is in the placement of the feedback tap 
+
Output
Figure 12.1
A four-stage, binary linear feedback shift register.
1 1 1 1 0 0 0 1 0 0 1 1 0 1 0 
              

Simulation Techniques    519
www.Academicpress.com
connections.  Clearly, the placement of these tap connections is crucial in creating a good 
pseudorandom sequence generator. 
A general N-stage LFSR is shown in Figure 12.3. The feedback tap gains, 
, 
, are each either 0 or 1. A 1 represents the presence of a tap connection, while 
a 0 represents the absence of a tap connection. It is also understood that 
.  That is, 
there must always be connections at the first and last position.  A specific LFSR can then be 
described by the sequence of tap connections.  For example, the four stage LFSR in Figure 12.1 
can be described by the sequence of tap connections 
.  It is 
also common to further simplify this shorthand description of the LFSR by converting the 
binary sequence of tap connections to an octal number.  For example, the sequence 
 becomes the octal number 23.  Likewise, the LFSR in Figure 12.2 is described 
by 
.
An N-stage LFSR must necessarily generate a periodic sequence of numbers. At any point in 
time, the N-bit contents of the shift register can take on only one of 
 possibilities.  Given 
any starting state, the LFSR could at best cycle through all possible states, but sooner or later 
must return to its initial state (or some other state it has already been in). At that point, the 
output will then begin to repeat itself. Also, note that if the LFSR ever gets into the all zero 
state, it will remain in that state and output a sequence of all 0 s from that point on. Therefore, 
to get the maximum period out of a LFSR, we would like the shift register to cycle through all 
possible non-zero states exactly once before returning to its initial state.  This will produce a 
+
Output
+
Figure 12.2  
Another four-stage, binary linear feedback shift register.
+
Output
+
+
+
. . .
. . .
g1
g2
gN −1
gN −2
g0
gN
Figure 12.3  
A general N-stage, binary linear feedback shift register.
gi
i
0 1 2  N
  

=
g0
gN
1
=
=
g0 g1 g2 g3 g4






1 0 0 1 1
   


=
1 0 0 1 1
   


g0 g1 g2 g3 g4






1 0 1 1 1
   


27

=
2N

520    Chapter 12
www.Academicpress.com
periodic output sequence with period of 
.  Such a sequence is referred to as a maximal 
length linear feedback shift register (MLLFSR) sequence, or an m-sequence, for short.
To study the question of how to connect the feedback taps of an LFSR in order to produce an 
m-sequence requires a background in abstract algebra beyond the scope of this book.  Instead, 
we include a short list in Table 12.1 describing a few feedback connections, in the octal format 
described, which will produce m-sequences. This list is not exhaustive in that it does not list 
all possible feedback connections for a given shift register length that lead to m-sequences.
As mentioned, m-sequences have several desirable properties in that they mimic those 
properties exhibited by truly random IID binary sequences. Some of the properties of 
m-sequences generated by an N-stage LFSR are summarized as follows:
•
m-sequences are periodic with a period of 
.
•
In one period, an m-sequence contains 
 1s and 
 0 s.  Hence, 0 s and 1s 
are almost equally likely.
•
The autocorrelation function of m-sequences is almost identical to that of an IID 
sequence. 
•
Define a run of length n to be a sequence of either n consecutive 1s or n consecutive 0 s.  
An m-sequence will have one run of length N, one run of length N – 1, two runs of 
length 
, four runs of length 
, eight runs of length  
, ..., and 
 runs 
of length 1.
m-sequences possess many other interesting properties that are not as relevant to their use as 
random number generators.
Example 12.1:
Suppose we wish to construct an m-sequence of length 31.  Since the period of an 
m-sequence is 
, we will need an 
 stage shift register to do the job.  From 
Table 12.1, there are three different feedback connections listed, any of which will 
work.  Using the first entry in the table, the octal number 45 translates to the feedback 
tap connections (1, 0, 0, 1, 0, 1).  This describes the LFSR shown in Figure 12.4.  
2N
1
–
2N
1
–
2N 2

2N 2

1
–
N
2
–
N
3
–
N
4
–
2N
2
–
2N
1
–
N
5
=
Table 12.1 LFSR feedback connections for m-sequences
SR Length, N
Feedback Connections (in Octal Format)
2
7
3
13
4
23
5
45, 67, 75
6
103, 147, 155
7
203, 211, 217, 235, 277, 313, 325, 345, 367
8
435, 453, 537, 543, 545, 551, 703, 747


Simulation Techniques    521
www.Academicpress.com
Assuming this LFSR is initially loaded with the sequence (1, 0, 0, 0, 0), the resulting 
m-sequence will be
(0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1).
12.1.2 Nonbinary Pseudorandom Number Generators
Next suppose that it is desired to generate a sequence of pseudorandom numbers drawn from a 
nonbinary alphabet.  One simple way to do this is to modify the output of the binary LFSRs 
discussed previously.  For example, suppose we want a pseudorandom number generator that 
produces octal numbers (i.e, from an alphabet of size 8) that simulates a sequence of IID octal 
random variables where the eight possible outcomes are equally probable.  One possible 
approach would be to take the five-stage LFSR of Example 12.1, group the output bits in triplets 
(i.e., three at a time), and then convert each triplet to an octal number.  Doing so (assuming the 
LFSR is loaded initially as in Example 12.1), one period of the resulting octal sequence is
(0  2  2  6  3  7  0  6  7  2  4  1  1  3  1  7  4  3  3  5  2  0  4  5  4  7  6  1  5  6  5). (12.2)
Note that each of the octal numbers 0, 1, 2, ..., 7 occurs exactly four times in this sequence 
except the number 0, which occurs three times. This is as close as we can get to equally likely 
octal numbers with a sequence of length 31. The number of runs of various lengths in this 
sequence also matches what we might expect from a truly random IID sequence of equally 
likely octal numbers.  For example, the probability of a run of length two occurring in a 
random sequence of octal numbers is 1/8.  Given a random sequence of length 31, the 
expected number of runs of length 2 is 31/8 = 3.875. This pseudorandom sequence has three 
runs of length 2.  The expected number of runs of length 3 is 31/64 = 0.4844. The 
pseudorandom sequence has no runs of length 3.  
It should be noted that since the octal sequence in Equation (12.2) is generated by the 
underlying feedback structure of Example 12.1, there should be a recursive formula that can 
be used to generate the sequence.  In this case, the recursion is fairly complicated and not very 
instructive, but this leads us to the idea of generating pseudorandom sequences of nonbinary 
numbers using some recursive formula.  One commonly used technique is the power residue 
method whereby a pseudorandom sequence is generated through a recursion of the form
,    
,
(12.3)
Output
+
Figure 12.4  
A five-stage LFSR with feedback tap connections specified by the octal number 45.
xk
axk
1
–  mod q
=
k
1 2 3 
  
=


522    Chapter 12
www.Academicpress.com
where  and  are suitably chosen constants.  Due to the modulo-  operation, the elements of 
the sequence are from the set 
.  The first element of the sequence 
 is 
called the seed and given the set 
, the resulting sequence is completely deterministic.  
Note also that the resulting sequence must be periodic since once any element appears a 
second time in the sequence, the sequence will then repeat itself.  Furthermore, since the 
elements of the sequence are from a finite alphabet with  symbols, the maximum period of 
the sequence is 
 (the period  is not  because the element 0 must never appear or the 
sequence will produce all 0 s after that and therefore be of period 1).  The next example shows 
that the desireable statistical properties of the sequence are dependent upon a careful selection 
of the numbers  and .
Example 12.2:
First suppose that 
.  Then the sequence produced has a period of 3 and 
assuming that the seed is 
, the sequence is given by
.
This is not a particularly good result since with the selection of 
, we would hope for 
a period of 
.  However, if we make a slight change so that 
, 
with the seed of 
, the sequence becomes
.
Now, as desired, the sequence has the maximal period of 6 and cycles through each of 
the integers from 1 through 6 exactly once each.  As another example of a choice of 
 which leads to a bad sequence, suppose we selected 
.  Then the 
sequence produced (assuming 
) would be 
.
Clearly, we can get pseudorandom sequences with very different statistical properties 
depending on how we choose 
.  By choosing the number  to be very large, the 
resulting period of the pseudorandom sequence will also be very large and thus the periodicity 
of the sequence will not become an issue.  Most math packages and high-level programming 
languages have built in random number generators that use this method.  Commonly, the 
parameters 
 are used.  This produces a sequence of length 
, 
which is over 2 billion.  Furthermore, by normalizing the elements of the sequence by , the 
resulting pseudorandom sequence has elements from the set 
.  
With a very large choice for the value of , for almost all practical purposes, the elements will 
appear to be drawn from the continuous interval 
.  Therefore, we have constructed a 
simple method to simulate random variables drawn from a uniform distribution.
a
q
q
0 1 2  q
1
–
  


	
x0
a q x0
 

	
q
q
1
–
q
a
q
a q


	
4 7


	
=
x0
1
=
x0 x1 x2 





1 4 2 1 4 2 1 4 2 
        


=
q
7
=
q
1
–
6
=
a q


	
3 7


	
=
x0
1
=
x0 x1 x2 





1 3 2 6 4 5 1 3 2 6 4 5 
           


=
a q


	
a q


	
4 8


	
=
x0
1
=
x0 x1 x2 





1 4 0 0 0 
    


=
a q


	
q
a q


	
75 231
1
–


	
=
231
2
–
q
1 q

2 q


q
1
–

 q





	
q
0 1






Simulation Techniques    523
www.Academicpress.com
12.1.3 Generation of Random Numbers from a Specified Distribution
Quite often, we are interested in generating random variables that obey some distribution other 
than a uniform distribution.  In this case, it is generally a fairly simple task to transform a 
uniform random number generator into one that follows some other distribution.  Consider 
forming a monotonic increasing transformation 
 on a random variable 
 to form a new 
random variable 
.  From the results of Chapter 4, the PDFs of the random variables involved 
are related by
.
(12.4)
Given an arbitrary PDF, 
, the transformation 
 will produce a uniform random 
variable 
 if 
 or equivalently 
.  Viewing this result in reverse, 
if 
 is uniformly distributed over 
 and we want to create a new random variable,  with 
a specified distribution, 
, the transformation 
 will do the job.
Example 12.3:
Suppose we want to transform a uniform random variable into an exponential random 
variable with a PDF of the form
.
The corresponding CDF is
.
Therefore, to transform a uniform random variable into an exponential random variable, 
we can use the transformation
.
Note that if  is uniformly distributed over 
, then 
 will be uniformly 
distributed as well so that the slightly simpler transformation
will also work.
This approach for generation of random variables works well provided that the CDF of the 
desired distribution is invertible. One notable exception where this approach will be difficult is 
the Gaussian random variable. Suppose, for example, we wanted to transform a uniform 
random variable, 
, into a standard normal random variable, 
. The CDF in this case is the 
g
 
X
Y
fY y

 
fX x

 
dg dx

----------------
=
fX x

 
Y
g X

 
=
Y
dg dx

fX x

 
=
g x

 
FX x

 
=
X
0 1



Y
FY y

 
Y
FY1
–
X

 
=
fY y

 
a
ay
–


exp
u y

 
=
FY y

 
1
ay
–


exp
–

u y

 
=
Y
FY
1
–
X

 
 
1
X
–


ln
a
-----------------------
–
=
=
X
0 1



1
X
–
Y
 
X

 
ln
a
--------------
–
=
X
Y



524    Chapter 12
www.Academicpress.com
complement of a Q-function, 
.  The inverse of this function would then 
provide the appropriate transformation, 
, or as with the previous example, we 
could simplify this to 
.  The problem here lies with the inverse Q-function which 
can not be expressed in a closed form.  One could devise efficient numerical routines to 
compute the inverse Q-function, but fortunately there is an easier approach.
An efficient method to generate Gaussian random variables from uniform random variables is 
based on the following 2  2 transformation. Let 
 and 
 be two independent uniform 
random variables (over the interval (0, 1)). Then if two new random variables, 
 and 
 are 
created according to
,
(12.5a)
,
(12.5b)
then 
 and 
 will be independent standard normal random variables (see Example 5.24).  
This famous result is known as the Box–Muller transformation and is commonly used to 
generate Gaussian random variables.  If a pair of Gaussian random variables is not needed, one 
of the two can be discarded.  This method is particularly convenient for generating complex 
Gaussian random variables since it naturally generates pairs of independent Gaussian random 
variables.  Note that if Gaussian random variables are needed with different means or 
variances, this can easily be accomplished through an appropriate linear transformation.  That 
is, if 
, then 
 will produce 
.
12.1.4  Generation of Correlated Random Variables
Quite often, it is desirable to create a sequence of random variables that are not independent, 
but rather have some specified correlation.  Suppose we have a Gaussian random number 
generator that generates a sequence of IID standard normal random variables, 
 and it is desired to transform this set of random variables into a set of 
Gaussian random variables, 
 with some specified covariance matrix, 
.  
By using a linear transformation of the form 
, the joint Gaussian distribution will be 
preserved.  The problem of how to choose the transformation to produce the desired 
covariance matrix was covered in Chapter 6, Section 6.4.1.  Recall that to specify this 
transformation, an eigendecomposition of the covariance matrix is performed to produce 
, where 
 is the diagonal matrix of eigenvalues of 
 and 
 is the 
corresponding matrix of eigenvectors.  Then the matrix 
 will produce the vector 
 
with the correct covariance matrix 
.  Once again, if a random vector with a nonzero mean 
vector is desired, the above approach can be augmented as 
, where 
 is the 
vector of appropriate means.
FY y

 
1
Q y

 
–
=
y
Q 1
–
1
x
–


=
y
Q 1
–
x

 
=
X1
X2
Y1
Y2
Y1
2
X1


ln
–
2X2


cos
=
Y2
2
X1


ln
–
2X2


sin
=
Y1
Y2
Y
N 0 1




Z
Y

+
=
Z
N  2




X
X1 X2  XN





=
T
Y
Y1 Y2  YN





=
T
CY
Y
AX
=
CY
QLQT
=
L
CY
Q
A
Q L
=
Y
CY
Y
AX
B
+
=
B

Simulation Techniques    525
www.Academicpress.com
12.2  Generation of Random Processes
Next consider the problem of simulating a random process, 
, with a desired PSD, 
.  
It is not feasible to create a continuous time random process with a computer.  Fortunately, we 
can invoke the sampling theorem to represent the continuous time random process by its 
samples.  Let 
 be the kth sample of the random process taken at a sampling rate 
of 
.   Then provided the sampling rate is chosen to be at least twice the absolute 
bandwidth of 
 (i.e., twice the largest nonzero frequency component of 
), the 
random process can be reproduced from its samples.  Thus, the problem of generating a 
random process can be translated into one of creating a sequence of random variables.  The 
question is how should the random variables be correlated in order to produce the correct PSD?  
Of course, the autocorrelation function, 
, provides the answer to this question.  If the 
random process is sampled at a rate of 
, then the kth and mth sample will have a 
correlation specified by 
. Hence, if 
 is a 
sequence of samples of the random process 
, the correlation matrix of these samples will 
have a Toeplitz structure (assuming 
 is stationary) of the form
. (12.6)
Once the appropriate correlation matrix is specified, the procedure developed in the last 
section can be used to generate the samples with the appropriate correlation matrix.  
This approach will work fine provided that the number of samples desired is not too large.  
However in many cases, we need to simulate a random process for a large time duration.  
In that case, the number of samples, 
, needed becomes large and hence the matrix 
 is 
also large.  Performing the necessary eigendecomposition on this matrix then becomes a 
computationally intensive problem.  The following subsections look at some alternative 
approaches to this general problem that offer some computational advantages.
12.2.1 Frequency Domain Approach
If the random process to be simulated is a Gaussian random process, we can approach the 
problem by creating samples of the random process in the frequency domain.  Suppose we wish 
to create a realization of the random process, 
, of time duration 
, say over the interval 
, and that we do not much care what happens to the process outside this interval.  
X t
 
SXX f
 
Xk
X kTs


=
Rs
1 Ts

=
X t
 
SXX f
 
RXX 

 
Rs
1 Ts

=
E XkXm


RXX
k
m
–

Ts


=
X
X1 X2  XN





=
X t
 
X t
 
RXX
RXX 0

 
RXX Ts


RXX 2Ts



RXX NTs


RXX
T
–
s


RXX 0

 
RXX Ts


 RXX
N
1
–

Ts


RXX
2
– Ts


RXX
T
–
s


RXX 0

 
 RXX
N
2
–

Ts






RXX
N
– Ts

 RXX
N
1
–


–
Ts

 RXX
N
2
–


–
Ts

 
RXX 0

 
=
N
RXX
X t
 
Td
0 Td




526    Chapter 12
www.Academicpress.com
To start with we produce a periodic signal 
 by repeating 
 every 
 seconds as 
illustrated in Figure 12.5.   Since 
 is periodic it has a Fourier series representation
,   
.
(12.7)
Note that due to the linearity of the Fourier series construction, if the 
 are zero mean 
Gaussian random variables, then the resulting process 
 will be a zero mean Gaussian 
random process.  Furthermore, the periodic random process 
 has a line spectrum given by
,  
.
(12.8)
The 
 can be chosen to shape the spectrum to any desired form.  If the desired PSD of the 
random process is 
 then we could pick 
.  The constant of proportionality 
can be chosen so that the total power in the process 
 matches that of 
.  In particular, 
suppose that 
 is bandlimited so that 
 for 
.  Then the number of terms in 
the Fourier series in Equation (12.7) is finite.  Let 
.
(12.9)
Then 
 will be nonzero only for 
.  Hence, we need to generate a total of 
 
random variables, 
, 
, ..., 
, 
, 
, ..., 
. The variances of these random 
variables are chosen such that 
,    
.
(12.10)
X˜ t
 
X t
 
Td
X(t)
˜
X(t)
Td
Td
2Td
3Td
Figure 12.5  
A realization of the random process 
 along with its periodic extension 
.
X t
 
X t
 
X˜ t
 
X˜ t
 
Xkej2kfot
k
=
fo
1
Td
-----
=
Xk
X˜ t
 
X˜ t
 
SX˜ X˜

f
 
sk2 f
kfo
–


k
=
sk2
E Xk 2


=
sk
SXX f
 
sk2
Sxx kfo



X˜ t
 
X t
 
X t
 
SXX f
 
0
=
f
W

M
W
fo
-----
WTd
=
=
sk
k
M

2M
1
+
X M
–
X
M
–
1
+
X 1
–
X0 X1
XM
sk2
E Xk 2


SXX kfo


=
=

SXX f
  fd
W
–
W

SXX kfo


k
M
–
=
M

--------------------------------
=

Simulation Techniques    527
www.Academicpress.com
In summary, the random process can be simulated by first generating a sequence of 
 
zero-mean complex Gaussian random variables.  Each random variable should be scaled so 
that the variances are as specified in Equation (12.10).  Samples of the random process in the 
time domain can be constructed for any desired time resolution, 
, according to
.
(12.11)
If the random process is real, it is sufficient to generate the 
 random variables 
 independently and then form the remaining random variables 
 
using the conjugate symmetry relationship 
.  In this case, 
 must also be real so 
that a total of 
 real Gaussian random variables are needed (one for 
 and two each for 
, 
) to construct the random process, 
.
Example 12.4:
Suppose we wish to generate a 5-ms segment of a real zero-mean Gaussian 
random process with a PSD given by
,
where 
 is the 3 dB frequency of the PSD.  Strictly speaking, this process has an 
infinite absolute bandwidth.  However, for sufficiently high frequencies there is minimal 
power present.  For the purposes of this example, we (somewhat arbitrarily) take the 
bandwidth to be 
 so that approximately 99.9% of the total power in the process 
is contained within 
.  Since we want to simulate a time duration of 
, the 
number of Fourier series coefficients needed is given by 
.  Figure 12.6 
shows a comparison of the actual PSD, 
, with the discrete line spectrum 
approximation.  Also, one realization of the random process generated by this method is 
shown in Figure 12.7. The MATLAB code used to create these plots follows.
% Set parameters
I=sqrt(-1);
Td=5e-3; fo=1/Td; f3=1e3; dt=1e-5;
M=floor(6*f3*Td); m=[-M:M];
% Construct discrete samples of PSD
x=[0:0.01:10]; psd=1./(1+x.^4);
power=2*f3*sum(psd)*0.01;
s=1./(1+((m*fo)/f3).^4);
beta=power/sum(s);
s=beta*s;
% Construct "continuous" PSD
f=[-8:0.01:8]*f3;
2M
1
+
t

X i 
X i t



Xk ej2fo t


ik
k
M
–
=
M

=
=
M
1
+
X0 X1  XM



X 1
–
X 2
–
 X M
–



X k
–
Xk*
=
X0
2M
1
+
X0
Xk k
1 2  M
 

=
X t
 
SXX f
 
1
1
f f3


4
+
---------------------------
=
f3
1kHz
=
W
6f3
=
f
W

Td
5 ms
=
M
WTd
30
=
=
SXX f
 

(Continued)

528    Chapter 12
www.Academicpress.com
psd=1./(1+(f/f3).^4);
% Plot results
subplot(2,1,1)
stem(m*fo,s/fo); hold on
plot(f,psd,'g'); hold off
axis([-8*f3 8*f3 0 1.2])
xlabel('frequency (Hz)'); ylabel('PSD');
% Generate Frequency domain samples
z0=randn(1); z0=z0*sqrt(s(M+1));
zplus=sqrt(s(M+2:2*M+1)/2).*(randn(1,M)+I*randn(1,M));
zminus=conj(fliplr(zplus));
z=[zminus z0 zplus];
% Create time domain process
t=[0:dt:Td];
rp=zeros(1,length(t));
for m=-M:M
   rp=rp+z(m+M+1)*exp(I*2*pi*m*fo*t);
−6000
−4000
−2000
0
2000
4000
6000
0
0.2
0.4
0.6
0.8
1
Frequency (Hz)
PSD
Figure 12.6  
A comparison of the exact PSD along with the discrete approximation for Example 12.4. 
(For color verssion of this figure, the reader is referred to web verssion of this chapter.)
0
1
2
3
4
5
−150
−100
−50
0
50
100
150
t (ms)
X(t)
Figure 12.7 
 A realization of the random process of Example 12.4.


Simulation Techniques    529
www.Academicpress.com
12.2.2 Time Domain Approach
A simple alternative to the previous frequency domain approach is to perform time domain 
filtering on a white Gaussian noise process as illustrated in Figure 12.8.  Suppose white 
Gaussian noise with PSD, 
 is input to an LTI filter that can be described by the 
transfer function, 
.  Then, from the results in Chapter 11, it is known that the PSD of the 
output process is 
.  Therefore, in order to create a Gaussian random process, 
, with a prescribed PSD, 
, we can construct a white process and pass this process 
through an appropriately designed filter.  The filter should have a magnitude response which 
satisfies
. 
(12.12)
The phase response of the filter is irrelevant, and hence, any convenient phase response can be 
given to the filter. 
This technique is particularly convenient when the prescribed PSD, 
, can be written as 
the ratio of two polynomials in .  Then the appropriate transfer function can be found through 
spectral factorization techniques.  If the desired PSD is a more complicated function of , then 
designing and/or implementing a filter to produce that PSD may be difficult.  In that case, it 
may be necessary to use an approximate filter design.
Example 12.5:
In this example, we design the filter needed to generate the random process specified in 
Example 12.4 using the time domain method. The PSD is factored as follows:
.
If the first two poles are associated with 
 (and the last two with 
), then the 
filter has a transfer function of
SXX f
 
1
=
H f
 
SYY f
 
H f
  2
=
Y t
 
SYY f
 
H f
 
SYY f
 
=
SYY f
 
f
f
h(t)
X(t)
Y(t)
White noise
Colored
noise
Figure 12.8  
Time domain filtering to create a colored Gaussian random process.
S f
 
1
1
f f3


4
+
--------------------------
f34
f
f3ej
4
–

 f
f3ej3
4
–

 f
f3ej5 4

–

 f
f3ej7
4
–


----------------------------------------------------------------------------------------------------------------------------------------
=
=
H f
 
H* f
 

(Continued)

530    Chapter 12
www.Academicpress.com
which can be represented in the time domain as
,
where 
.  For the purposes of creating a random process with the desired 
spectrum, the negative sign in front of this impulse response is irrelevant and can be ignored.  
Therefore, to produce the desired random process, we start by generating a white Gaussian 
random process and then convolve the input with the impulse response specified above.
Once an appropriate analog filter has been designed, the filter must be converted to a discrete 
time form.  If the sampling rate is taken to be sufficiently high, then the impulse response of the 
discrete time filter can be found by simply sampling the impulse response of the continuous 
time filter.  This is the so-called impulse invariance transformation. However, because of 
aliasing that occurs in the process of sampling the impulse response, the frequency response of 
the digital filter will not be identical to that of the original analog filter unless the analog filter 
is absolutely bandlimited.  Of course, if the analog filter is approximately bandlimited and if 
the sampling rate is sufficiently large, this aliasing can be kept to a minimum and the resulting 
digital filter will produce a very good approximation to the desired frequency response.
An alternative popular approach for producing a digital filter from an analog design is to use a 
bilinear transformation.  That is, suppose we have an analog filter with transfer function 
. A digital approximation to this filter, 
, can be obtained (assuming a sampling 
frequency of 
) according to
.
(12.13)
One advantage of the bilinear transformation is that if the analog filter is stable, then the digital 
filter will be stable as well.  Note also that if the analog filter is an nth order filter, then the 
order of the digital filter will be no more than n as well.
Example 12.6:  
In this example, we find the digital approximation to the analog filter 
designed in Example 12.5 using the bilinear approximation.  From the 
results of that example, the analog filter was a second-order Butterworth 
filter whose transfer function (in terms of s) was given by
H f
 
f32
f
f3ej
4
–

 f
f3ej3
4
–


-----------------------------------------------------------------
f32
f2
j 2f3f
–
f32
–
-----------------------------------
=
=
h t
 
2oe
ot
–
ot


sin
–
u t
 
=
o
2f3
=
Ha s
 
Hd z
 
fs
Hd z
 
Ha s
 
s
2fs
1
z 1
–
–
1
z 1
–
+
-----------------




=
=



Simulation Techniques    531
www.Academicpress.com
,
where 
 is the 3-dB frequency of the filter in radians per second.  After a little 
bit of algebraic manipulation, application of the bilinear transformation in Equation 
(12.13) results in
,
where 
, 
, 
, 
, 
, 
, 
and 
.  Figure 12.9 shows a plot of the impulse response of this filter as well 
as one realization of the random process created by passing white Gaussian noise 
through this filter.  Note that for this example, the impulse response of the filter lasts for 
about 1 ms (this makes sense since the bandwidth was 1 kHz).  Therefore, when creating 
the filtered process, at least the first millisecond of output data should be discarded 
since the contents of the digital filter have not reached a statistical steady state until that 
point. The relevant MATLAB code follows
Ha s
 
32
s2
23s
32
+
+
----------------------------------------
=
3
2f3
=
0
(a)
1
2
3
4
5
0
0.05
0.1
Time (ms) = n/fs
h[n]
0
1
2
3
4
5
−1
−0.5
0
0.5
Time (ms)
X(t)
(b)
Figure 12.9  
(a) Impulse response and (b) a single realization of the output 
of the filter designed in Example 12.6.  
(Continued)
Hd z
 
b0
b1z 1
–
b2z 2
–
+
+
a0
a1z 1
–
a2z 2
–
+
+
-------------------------------------------
=
b0
1
=
b1
2
=
b2
1
=
a0
1
2 
 2
+
+
=
a1
2
2 2
–
=
a2
1
2 
–
 2
+
=
 
fs
f3



=

532    Chapter 12
www.Academicpress.com
I=sqrt(-1);
imp_len=150;
% length of impulse response in 
  samples
sim_len=150;
% length of simulation in samples
f3=1000;
% 3dB frequency of desired PSD
fs=30000;
% sampling rate
g=fs/(pi*f3);
% compute filter coefficients
b0=1; b1=2; b2=1; b=[b0 b1 b2];
a0=1+sqrt(2)*g+g^2; a1=2-2*g^2; 
a2=1-sqrt(2)*g+g^2; a=[a0 a1 a2];
x=zeros(1,imp_len); x(1)=1;
% impulse
y=filter(b,a,x);
% impulse response of filter
time_scale=[1:length(y)]/fs;
subplot(2,1,1)
% plot impulse response
stem(time_scale*1000,y,'o')
xlabel('time(msec)=n/f_s')
ylabel('h[n]')
x=randn(1,sim_len);
% white Gaussian random process
y=filter(b,a,x);
% filtered process
time_scale=[1:length(y)]/fs;
subplot(2,1,2)
% plot realization
plot(time_scale*1000,y);
xlabel('time (msec)'); ylabel('X(t)');
One advantage of the time domain approach is that it is convenient for generating very 
long realizations of the random process.  Once the filter is designed, the output process is 
created by performing a convolution of the impulse response of the filter with a white 
input sequence.  The complexity of this operation is linear in the length of the sequence.  
Furthermore, the process of creating a long sequence can be broken into several smaller 
sequences.  The smaller sequences can then be concatenated together to create a long 
sequence.  There will be no discontinuities at the points of concatenation if the contents of 
the filter are stored after each realization and used as the starting contents for the next 
realization.
Some care must be taken when using the time domain method if the desired sampling rate of 
the process is much larger than the bandwidth of the filter.  In this case, the poles of the digital 
filter will be close to the unit circle and the filter might exhibit stability problems.  This is 
illustrated in Figure 12.10 where the magnitude of the poles of the digital filter from Example 12.6 
is plotted as a function of the sampling rate.  Note that when the rate at which the process is 
sampled becomes a few hundred times the bandwidth of the filter, the poles of the digital filter 
become very close to the unit circle.  This problem can easily be avoided by creating a digital 
filter to create samples of the process at a lower rate (perhaps at several times the bandwidth of 
the filter so as to avoid aliasing) and then upsampling (through interpolation) the resulting 
process to any desired rate. 


Simulation Techniques    533
www.Academicpress.com
12.2.3 Generation of Gaussian White Noise
Generation of a white noise process is exceedingly common and also is very simple.  However, 
it is often the source of frequent mistakes among engineers, so we felt it worth making a few 
comments about computer generation of white Gaussian noise processes.  The source of 
confusion in the generation of white noise is that one cannot represent white noise from its 
time domain samples.  White noise has infinite power; therefore, samples of a white noise 
process would require infinite variance.  Alternatively, white noise has infinite bandwidth, so 
the Nyquist rate for recovering white noise from its samples would be infinite.  In order to 
represent a “white” process in discrete time, we must invoke some form of prefiltering before 
sampling.  This will limit the bandwidth so that a finite sampling rate can be used, and at the 
same time, it will limit the power of the process so that the resulting samples of the filtered 
white process will have a finite variance.  
Strictly speaking, once we filter the white noise it is no longer white, but this should not be of 
too much concern.  In practice, there is no such thing as truly white noise.  Recall that the 
white noise model was an approximation to a noise process which had a constant PSD over a 
very large (but not infinite) bandwidth.  Furthermore, any equipment we use to measure or 
receive the noise will automatically filter the process.  With this in mind, we imagine a 
prefilter that has a bandwidth that is much larger than any bandwidth we are concerned with in 
the specific system we are simulating.  The noise we create, although not truly white, will 
behave as though it were white for all practical purposes.
In order to simplify the process of creating the samples of the prefiltered white noise, it is 
common to employ an ideal lowpass prefilter with bandwidth 
 as illustrated in Figure 12.11.  
Now that the process is bandlimited, it can be represented by samples at any rate that satisfies 
103
104
105
106
107
0.4
0.5
0.6
0.7
0.8
0.9
1
fs (Hz)
|zp|
Figure 12.10  
Magnitude of the filter poles as a function of sampling 
frequency for the filter designed in Example 12.6.
W

534    Chapter 12
www.Academicpress.com
.  Since the prefilter is ideal, the autocorrelation function of the filter output is easily 
calculated to be
.
(12.14)
Note that since this sinc function has nulls at multiples of 
, the samples of the filtered 
process will be uncorrelated provided that the samples are spaced by any integer multiple of 
.  In other words, if the sampling rate satisfies 
 for any integer , then the 
samples of the prefiltered white noise will be uncorrelated.  By choosing 
 so that the 
sampling rate is exactly the Nyquist rate, 
, the process can be recovered from the 
discrete samples and the samples are uncorrelated.  For Gaussian noise, this implies that the 
filtered white noise can be represented by a sequence of independent, zero-mean, Gaussian 
random variables with variance of 
.  Note that the variance of the samples and the 
rate at which they are taken are related by 
.  
The lesson to be learned here is that if we wish to represent Gaussian white noise as a 
sequence of independent Gaussian random variables, then there is an implicit assumption 
about the nature of the prefiltering.  Furthermore, to be consistent with this assumption, the 
variance of the samples must be adjusted when the sampling rate is changed.  The variance and 
sampling rate cannot be selected independently.  
12.3  Simulation of Rare Events
Quite often, we are interested in estimating the probability of some event, 
.  If analytically 
calculating this probability is too cumbersome, we can design a computer program to simulate 
the system in question and then observe whether or not the event occurs.  By repeating this 
procedure many times, we can observe how often the event 
 occurs and hence get an 
estimate of its probability through a relative frequency approach.  The event 
 could be a bit 
error in a digital communications system—in which case we are interested in calculating bit 
error probability—or it could be a buffer overflow in a computer network or even something as 
extravagant as breaking the bank at the blackjack table.  
fs
2W
!
Ideal LPF
BW=W
Sampler
rate = fs
White
noise
PSD=No  ⁄ 2
Discrete time
noise process
Figure 12.11  
A/D conversion process for white noise.
R 

 
NoWsinc 2W


=
1 2W

1 2W

fs
2W n

=
n
n
1
=
fs
2W
=
2
NoW
=
2
Nofs 2

=
A
A
A

Simulation Techniques    535
www.Academicpress.com
12.3.1 Monte Carlo Simulations
In general, suppose we have the ability to recreate (simulate) the experiment an arbitrary 
number of times and define a sequence of Bernoulli random variables, 
, that are defined 
according to
(12.15)
Hence, 
 is simply an indicator function for the event 
.  If the experiments are independent, 
then the probability of the event 
, 
, can be estimated according to
.
(12.16)
This is nothing more than estimating the mean of an IID sequence of random variables.  From 
the development of Chapter 7, we know that this estimator is unbiased and that as 
 the 
estimate converges (almost everywhere via the strong law of large numbers) to the true 
probability.
In practice, we do not have the patience to run our simulation an infinite number of times nor 
do we need to.  At some point, the accuracy of our estimate should be “good enough,” but how 
many trials is enough?  Some very concrete answers to this question can be obtained using the 
theory developed in Chapter 7.  If the event 
 is fairly probable, then it will not take too many 
trials to get a good estimate of the probability, in which case runtime of the simulation is not 
really too much of an issue.  However, if the event 
 is rare, then we will need to run many 
trials to get a good estimate of 
.  In the case when  gets large, we want to be sure not to 
make it any larger than necessary so that our simulation runtimes do not get excessive.  Thus, 
the question of how many trials to run becomes important when simulating rare events.  
Assuming  is large, the random variable 
 can be approximated as a Gaussian random 
variable via the central limit theorem.  The mean and variance are 
 and 
, respectively.  One can then set up a confidence interval based on the 
desired accuracy.  For example, suppose we wish to obtain an estimate that is within 1% of the 
true value with 90% probability.  That is, we want to run enough trials to insure that
.
(12.17)
From the results of Chapter 7, Section 7.5, we get
,
(12.18)
Xi
Xi
1,   if A occurs during the ith experiment,
0,
otherwise.                                           
"
#
$
=
Xi
A
A pA
pˆ A
1
n---
Xi
i
1
=
n

=
n
%

A
A
pA
n
n
pˆ A
E pˆ A


pA
=
pˆA
2
n 1
– pA 1
pA
–


=
Pr pˆ A
pA
–
0.01pA



0.9
1
&
–
=
=
'0.1
0.01pA
X
n
-------c0.1
pA 1
pA
–


n
-------------------------c0.1
=
=
=

536    Chapter 12
www.Academicpress.com
where the value of 
 is taken from Table 7.1 as 
.  Solving for  gives us an 
answer for how long to run the simulation:
.
(12.19)
Or in general, if we want the estimate, 
, to be within 
 percent of the true value (i.e., 
) with probability 
, then the number of trials in the simulation should 
be chosen according to
.
(12.20)
This result is somewhat unfortunate because in order to know how long to run the simulation, 
we have to know the value of the probability we are trying to estimate in the first place.  In 
practice, we may have a crude idea of what to expect for 
 which we could then use to guide 
us in selecting the number of trials in the simulation.  However, we can use this result to give 
us very specific guidance in how to choose the number of trials to run, even when 
 is 
completely unknown to us.  Define the random variable 
 to be the number of occurrences 
of the event 
 in  trials, that is, 
.
(12.21)
Note that 
.  That is, the quantity 
 can be interpreted as the expected number 
of occurrences of the event 
 in  trials.  Multiplying both sides of Equation (12.20) by 
 
then produces
.
(12.22)
Hence, one possible procedure to determine how many trials to run is to repeat the experiment 
for a random number of trials until the event 
 occurs some fixed number of times as specified 
by Equation (12.22).  Let 
 be the random variable which represents the trial number of the 
th occurrence of the event 
.  Then, one could form an estimate of 
 according to
.
(12.23)
It turns out that this produces a biased estimate; however, a slightly modified form,
,
(12.24)
produces an unbiased estimate (see Exercise 7.12).  
c0.1
c0.1
1.64
=
n
n
100c0.1

2 1
pA
–


pA
-------------------------------------------
164

2 1
pA
–


pA
-----------------------------------
164

2
pA
----------------
(
=
=
pˆ
A

pˆ
A
pA
–
pA 100


&
n
100c&

--------------




2
1
pA
–


pA
------------------------------------------
100c&

--------------




2
pA
----------------------
(
=
pA
pA
NA
A
n
NA
Xi
i
1
=
n

=
E NA


npA
=
npA
A
n
pA
E NA


100c&

--------------




2
1
pA
–


100c&

--------------




2
(
=
A
Mk
k
A
pA
pˆ
A
k
Mk
------
=
pˆ
A
k
1
–
Mk
1
–
---------------
=

Simulation Techniques    537
www.Academicpress.com
Example 12.7:  
Suppose we wish to estimate the probability of an event that we expect to be roughly on 
the order of 
.  Assuming we want 1% accuracy with a 90 % confidence level, the 
number of trials needed will be
.
Alternatively, we need to repeat the simulation experiment until we observe the event
times.  Assuming we do not have enough time available to repeat our simulation over 
1/4 of a billion times, we would have to accept less accuracy.  Suppose that due to time 
limitations we decide that we can only repeat our experiment 1 million times, then we 
can be sure that with 90% confidence, the estimate will be within the interval 
, if  is chosen according to
.
With 1 million trials we can only be 90% sure that the estimate is within 16.4% of the 
true value.
The preceding example demonstrates that using the Monte Carlo approach to simulating rare 
events can be very time consuming in that we may need to repeat our simulation experiments 
many times to get a high degree of accuracy.  If our simulations are complicated, this may put a 
serious strain on our computational resources.  The next subsection presents a novel technique, 
which when applied intelligently can substantially reduce the number of trials we may need to run.
12.3.2 Importance Sampling
The general idea behind importance sampling is fairly simple.  In the Monte Carlo approach, 
we spend a large amount of time with many repetitions of an experiment while we are waiting 
for an event to occur which may happen only very rarely.  In importance sampling, we skew 
the distribution of the underlying randomness in our experiment so that the “important” 
events happen more frequently.  We can then use analytical tools to convert our distorted 
simulation results into an unbiased estimate of the probability of the event in which we are 
interested.  To help present this technique, we first generalize the problem treated in Section 
12.3.1.  Suppose the simulation experiment consisted of creating a sequence of random 
p
10 4
–

n
1
p--- 100c&

--------------




2
104 100*1.64
1
-----------------------




2
268 960 000


=
=
=
NA
100c&

--------------




2
26 896

=
=
p
'
–
p
'
+



'
'
p 1
p
–


n
------------------------c&
p
n
-------c&
(
1.6410 2
–
103
----------
1.64
5
–
10
0.164p
=
=
=
=



538    Chapter 12
www.Academicpress.com
variables, 
 according to some density, 
, and then observing 
whether or not some event 
 occurred which could be defined in terms of the 
.  For 
example, suppose 
 represents the number of messages that arrive at a certain node in a 
computer communications network at time instant .  Furthermore, suppose that it is known 
that the node requires a fixed amount of time to forward each message along to its intended 
destination and that the node has some finite buffer capacity for storing messages.  The event 
 might represent the event that the node’s buffer overflows, and thus a message is lost 
during the time interval 
.  Ideally, the communication network has been 
designed so that this event is fairly uncommon, but it is desirable to quantify how often this 
overflow will occur.  While it may be fairly straightforward to determine whether or not a 
buffer overflow has occurred given a specific sequence of arrivals, 
, determining 
analytically the probability of buffer overflow may be difficult, so we decide to approach this 
via simulation.  Let  
 be an indicator function for the event 
.  That is, let 
 
if  is such that the event 
 occurs and 
 otherwise.  Also, let 
 be the 
realization of the random vector 
 that occurs on the th trial of the simulation experiment.  
Then the Monte Carlo approach to estimating 
 is
.
(12.25)
Now suppose instead we generate a sequence of random variables 
 
according to a different distribution 
 and form the estimate
.
(12.26)
It is pretty straightforward (see Exercise 12.11) to establish that this estimator is also unbiased.  
By carefully choosing the density function, 
, we may be able to drastically speed up the 
convergence of the series in Equation (12.26) relative to that in Equation (12.25).  
The important step here is to decide how to choose the distribution of 
.  In general, the idea 
is to choose a distribution of 
 so that the event 
 occurs more frequently than 
the event 
.  In other words, we want to choose a distribution so that the 
“important” event is sampled more often.  It is common to employ the so-called twisted 
distribution, which calls on concepts taken from large deviation theory.  But using these 
techniques is beyond the scope of this book. Instead, we take an admittedly ad hoc approach 
here and on a case-by-case basis we try to find a good (but not necessarily optimal) 
distribution.  An example of using importance sampling is provided in the following 
application section.
X
X1 X2  Xm





=
fX x

 
A
Xi
Xi
i
A
i
1 2  m
 

=
X
x
=
)A X


A
)A x

 
1
=
x
A
)A x

 
0
=
x i
 
X
i
pA
pˆ
A MC

1
n---
)A x i
 


i
1
=
n

=
Y
Y1 Y2  Ym





=
fY y

 
pˆ
A IS

1
n---
fX y i
 


fY y i
 


----------------)A y i
 


i
1
=
n

=
fY y

 
Y
Y
)A Y

 
1
=

	
)A X


1
=

	

Simulation Techniques    539
www.Academicpress.com
12.4  Engineering Application: Simulation of a Coded Digital 
Communication System
In this section, we demonstrate use of the importance sampling technique outlined in the 
previous section in the simulation of a digital communication system with convolutional 
coding.  A basic block diagram of the system is illustrated in Figure 12.12.  A source outputs 
binary data, 
, which is input to an encoder that adds redundancy to the data stream for the 
purposes of error protection.  For this particular example, an encoder with a code rate of 1/2 is 
used.  Simply put, this means that for every one bit input, the convolutional encoder outputs 
two coded bits, 
.  To keep this example simple, the channel is modeled as one 
which randomly inverts bits with some probability  in a memoryless fashion.  That is, what 
happens to one bit on the channel is independent of any of the other bits.  Given a vector of bits 
input to the channel, 
, the probability of observing a certain output of the 
channel 
 is given by
,
(12.27)
where
(12.28)
The decoder then takes the received sequence output from the channel and determines what 
was the most likely data sequence.  
For this example, it is not necessary to understand the workings of the encoder and decoder.  
We will just assume the existence of some computer subroutines which simulate their 
functions.  Each trial of our simulation experiment will consist of randomly generating an IID 
sequence of equally likely data bits, passing them through the encoder, randomly corrupting 
some of the encoded bits according to the channel model we have developed, and then 
Xi
Y2i
1
–
Y2i


	
p
Y
Y1 Y2  Yn





=
R
R1 R2  Rn





=
Binary
data
source
Convolutional
encoder
Channel
Convolutional
decoder
Xi
Yi
Ri
Xiˆ
Figure 12.12  
Block diagram of a digital communication system.
Pr R Y


Pr Ri Yi


i
1
=
n
*
=
Pr Ri Yi


1
p
–
, if Ri=Yi,
p,
if Ri=Yi.
"
+
#
+
$
=

540    Chapter 12
www.Academicpress.com
decoding the received sequence.  The decoded bits are then compared with the original bits to 
measure the decoded bit error probability.  For the purposes of this example, it is assumed that 
data are transmitted in blocks of 50 information bits (which are encoded into blocks of 100 
coded bits).  We refer to each of these blocks as a frame.  The channel is simulated by creating 
an error pattern 
 where the 
 are a sequence of IID random variables 
with 
 and 
.  Then
.
(12.29)
The event 
 implies that the th bit is inverted in the process of going through the 
channel while 
 means that the th bit is received correctly.  
Using the standard Monte Carlo approach, the decoded bit error rate is estimated according to
,
(12.30)
where 
 is the number of packets transmitted in the simulation;  is the number of bits per 
packet; and the function 
 counts the number of bit errors that occurred in the th 
packet.  If the channel error rate, , is fairly high (e.g., a noisy channel), then the Monte Carlo 
approach will work quite nicely.  However, if 
, then channel errors will be infrequent and 
the decoder will usually correct them.  Thus, the decoded error probability will be very small 
and the Monte Carlo approach will require us to simulate an astronomical number of packets.
Alternatively, consider a simple importance sampling approach.  To avoid simulating endless 
packets which ultimately end up error free, we now create IID error patterns with 
, where  is some suitably chosen value which is larger than .  Note that any 
pattern 
 that contains exactly 
 1s and 100 – w zeros will be generated 
with probability 
.  Let 
 be the number of 1s in a particular error 
pattern, .  Then, our importance sampling estimate of the decoded error probability will be
.
(12.31)
Simulation results are shown in Figure 12.13 where the channel bit error probability is 
.  Note that there are theoretical bounds that tell us that for this example, the actual 
probability of decoded bit error should be bounded by 
.  To 
get fairly accurate results via the Monte Carlo approach, we would expect to have to simulate 
on the order of several hundred thousand packets.  It is seen in Figure 12.13 that indeed, even 
after simulating 10,000 packets, the estimated error probability has still not converged well.  
For the importance sampling results, we used 
 so that important error events 
E
E1 E2  E100





=
Ei
Pr Ei=1


p
=
Pr Ei= 0


1
p
–
=
R
Y
E
,
=
Ei= 1

	
i
Ei= 0

	
i
Pˆ
e MC

1
mn
-------
) x j
  xˆ j
  e




j
1
=
m

=
m
n
) x j
  xˆ j
  e




j
p
p
1
«
Pr Ei = 1


q
=
q
p
e
e1 e2  e100





=
w
Pr e

 
qw 1
q
–

100
w
–
=
w e

 
e
Pˆ
e IS

1
mn
-------
pw e

  1
p
–

100
w e

 
–
qw e

  1
q
–

100
w e

 
–
---------------------------------------------) x j
  xˆ j
  e




j
1
=
m

=
p
0.01
=
1.97
5
–
10
Pe
6.84
5
–
10


q
0.05
=

Simulation Techniques    541
www.Academicpress.com
occurred much more frequently.  As seen in the figure, the estimated error probability has 
converged rather nicely after simulating only a few thousand packets.  Therefore, for this 
example, using the importance sampling method has sped up the simulation time by a few 
orders of magnitude.
0
2000
4000
6000
8000
10000
10−6
10−5
10−4
10−3
Packets
Estimated probability of bit error
Importance sampling
Standard Monte Carlo
Figure 12.13  
Simulation results for a coded digital communication system 
using standard Monte Carlo and importance sampling techniques.

543
CHAPTER 12
Probability and Random Processes.
© 2012 by Elsevier Inc. All rights reserved.
Exercises
Section 12.1:  Computer Generation of Random Variables
12.1 Consider the periodic sequence generated by the four-stage shift register in Figure 12.1. 
Suppose the sequence is converted to 
-valued sequence by mapping all 1’s to –1’s and 
all 0’s to 1’s. One period of the resulting sequence is:
.
Calculate the autocorrelation function of this periodic sequence. Note: Do not just treat 
this sequence as having finite length. The sequence is infinite in both directions. The 
finite sequence shown above is just one period of the infinite periodic sequence.
12.2 Sketch the shift register described by the octal number 75. Find the sequence output by 
this shift register assuming that the shift register is initially loaded with all ones.
12.3 A certain 
-stage shift register has its tap connections configured so that it produces an 
m-sequence. The shift register is initially loaded with the contents 
 
resulting in a periodic sequence of period 
. Prove that if the shift register is loaded 
with some other contents 
, the new output sequence will be a cyclic shift of the 
original output sequence. Hint: Recall that for an m-sequence, the shift register must cycle 
through all nonzero states.
12.4 Suppose we create a binary
-valued sequence of length 
 by drawing 
 independent 
realizations of a Bernoulli random variable to form one period of the sequence. Compute 
the autocorrelation function of this random Bernoulli sequence.
12.5 Suppose a pseudorandom sequence is constructed using the power residue method as 
described by
, 
.
Find the period and the sequence which results for the following values of 
. For 
each case, assume the seed is 
.
(a)
, 
,
(b)
,
,
(c)
,
,
(d)
,
.
1

1
–
1
–
1
–
1
–
1 1 1
1
–
1 1
1
–
1
–
1
1
–
1



   
  

 

N
c
c0 c1  cN
1
–





=
2N
1
–
c
0

1

N
N
xk
axk
1
–  mod q
=
k
1 2 3 
  
=
a q



xo
1
=
a
4
=
q
9
=
a
5
=
q
9
=
a
2
=
q
5
=
a
5
=
q
11
=

544    Chapter 12
www.Academicpress.com
12.6 Suppose a pseudorandom sequence is constructed using the power residue method as 
discussed in Exercise 12.5. If 
, find a value of  that leads to a sequence with 
maximum possible period.
12.7 Find a transformation which will change a uniform random variable into each of the 
following distributions (see Appendix D for the definitions of these distributions if 
necessary):
(a)
arcsine,
(b)
Cauchy,
(c)
Rayleigh,
(d)
Geometric.
Section 12.2:  Generation of Random Processes
12.8 Suppose we wish to generate a 10-ms realization of a zero-mean Gaussian random 
process with a PSD of
.
(a)
Find the bandwidth that contains 99% of the total power in the random process.
(b)
Determine how many frequency samples are needed for the frequency domain 
method described in Section 12.2.1.
12.9 Suppose we wanted to generate the random process whose PSD is given in Exercise 12.8 
using the time domain method discussed in Section 12.2.2.
(a)
Find the transfer function of the analog filter which will produce the desired output 
PSD when the input is a zero-mean, white Gaussian random process.
(b)
Use a bilinear transformation to convert the analog filter to a digital filter.
(c)
What is the approximate duration of the impulse response of the digital filter if the 
3-dB frequency of the random process is 
.
12.10 Suppose a zero-mean Gaussian random process, 
,  has a PSD given by 
,
where 
.We desire to simulate a 5-ms segment of this process sampled at a 
rate of 2 kHz. Therefore, 10 samples will need to be created in our simulation. We will 
create the samples of the process by first generating 10 uncorrelated Gaussian random 
variables and then pass those variables through an appropriate transformation matrix, 
. 
(a) Find the correlation matrix of the 10 samples.
(b) Find the form of the matrix 
 that will produce samples with the desired 
correlation matrix.
q
11
=
a
S f 
1
1
f f3
	

2
+
---------------------------
=
f3
1kHz
=
X t 
SXX f 
rect f
fo
----




=
fo
1 kHz
=
A
A

Exercises    545
www.Academicpress.com
Section 12.3:  Simulation of Rare Events
12.11
Suppose we use a Monte Carlo simulation approach to simulate the probability of 
some rare event 
.  It is decided that we will repeat the simulation until the event 
 
occurs 35 times. With what accuracy will we estimate 
 to within a 90% confidence 
level?
12.12
Prove that the importance sampling (IS) estimator of Equation (12.26) is unbiased. 
That is, show that
.
12.13
Show that the variance of the IS estimator of Equation (12.26) is given by
.
12.14
Suppose the random variable 
 has an exponential distribution, 
.  We wish to estimate the probability of the event 
 via simulation.  We will compare the standard Monte Carlo estimate, 
,
where the random variables 
 are chosen according to the exponential distribution 
specifed by PDF 
, with an importance sampling estimate,
,
where the random variables 
 are chosen from a suitable distribution specified by its 
PDF, 
.  Note that both estimators are unbiased, so we will compare these 
estimators by examining their variances.
(a) Find the variance of the Monte Carlo estimate.
(b) Find the variance of the IS estimator assuming that the random variables 
 are 
chosen from a scaled exponential distribution, 
.
(c) Assuming that 
, find the value of  that minimizes the variance of the IS 
estimator using the scale exponential distribution.
(d) How much faster do you expect the IS simulation to run as compared to the MC 
simulation?
A
A
pA
E pˆ
A IS



pA
=
Var pˆ
A IS



1
n--- EX A X


fX X


fY X


--------------
pA
2
–






=
X
fX x
 
x
–


exp
u x
 
=
A
X
xo



=
pˆ
A MC

1
n---
u Xi
xo
–


k
1
=
n

=
Xi
fX x
 
pˆ
A IS

1
n---
u Yi
xo
–


fX Yi


fY Yi


---------------
k
1
=
n

=
Yi
fY y
 
Yi
fY y
 
a
ay
–


exp
u y
 
=
xo
20
=
a

546    Chapter 12
www.Academicpress.com
12.15
Repeat Exercise 12.14  using random variables 
 that follow a Gaussian distribution 
.  Also, for parts (b)–(d) use a shifted distribution for the 
importance sampling estimator of the form 
. Also, for this 
problem, use 
.
MATLAB Exercises
12.16
We wish to generate a periodic sequence of numbers that cycles through the integers 
from 1 to 100 in a pseudorandom fashion.  Choose a pair of integers 
 that can be 
used in the power residue method to produce a sequence of the desired form.  Write a 
MATLAB program to verify that the sequence produced does in fact cycle through 
each of the integers 1–100 exactly once each before the sequence repeats.
12.17
Let 
, 
, 
, and 
. We desire to 
find 
. Write a MATLAB program to estimate this probability through 
Monte Carlo simulation techniques. If we want to be 90% sure that our estimate is 
within 5% of the true value, about how many times should we observe the event 
? Run your program and provide the estimate of the desired probability. Can 
you find the probability analytically?
12.18
Write a MATLAB program to generate a realization of the random process from 
Exercise 12.8 (using the frequency domain method). Use a periodogram to estimate 
the PSD of the process using the realization of the process you generated. Does your 
PSD estimate agree with the PSD that the process is designed to possess?
12.19
Write a MATLAB program to generate a realization of the random process from 
Exercise 12.9 (using the time domain method). Use a periodogram to estimate the PSD 
of the process using the realization of the process you generated. Does your PSD 
estimate agree with the PSD that the process is designed to possess?
X
fX x
 
x2 2
	
–


exp
=
fY y
 
x
a
–

2 2
	
–


exp
=
xo
6
=
a q



X
N 2 1




Y
N 0 1




Z
N 0 1




W
X2
Y2
Z2
+
+
=
Pr W
3



W
3




547
APPENDIX A
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00014-0
© 2012 by Elsevier Inc. All rights reserved.
Review of Set Theory
The purpose for reviewing set theory is to provide a mathematical structure for organizing 
methods for counting and grouping objects.  Set theory may be used to define the probabilities 
of possible outcomes of experiments.  There are two common methods for defining a set.  The 
first method, known as the roster method, is to list the elements of a set.  Synonyms for sets 
include class, aggregate, and collection.  We will denote sets by capital letters, 
, etc.  
The elements or objects of a set will be indicated by lowercase letters, such as 
, etc.  If 
 is an element (or object or member or point) of 
, then we denote this as 
.  If  is not 
an element of 
, this is denoted as 
.  A second way of defining a set is called the 
property method, which describes some property held by all elements of the set, but is not held 
by objects that do not belong to the set.  
Definition A.1: A set 
 is said to be a subset of another set 
 if all elements of 
 are
also in 
.  In which case we write 
.  With this definition, it is possible that the
two sets are equal (i.e., they have all the same elements) in which case 
 and at
the same time 
.  If on the other hand, 
 is a subset of 
 and there are some ele-
ments of 
 which are not in 
, then we say that 
 is a proper subset of 
 and we
write 
.
Definition A.2:  The universal set, , is the set of all objects under consideration in a
given problem, while the empty set, 
, is the set that contains no elements.
Definition A.3:  The complement of a set 
, written 
, is the set of all elements in 
which are not in 
.  For two sets 
 and 
 which satisfy 
, the difference set,
written 
, is the set of elements in 
 which are not in 
.  
Note that for any set 
, 
 and 
.  Also, if 
 and 
, then 
.  
Finally, we also note the relationship 
.
Definition A.4:  For any two sets 
 and 
, the union of the two sets, 
, is the set
of all elements which are contained in either 
 or 
 and the intersection of the two
sets, 
, is the set of all elements which are contained in both 
 and 
.  In the
algebra of sets, the union operation plays the role of addition and so sometimes the
A B C


a b c
 
a
A
a
A

a
A
a
A

A
B
A
B
A
B

A
B

B
A

A
B
B
A
A
B
A
B

S

A
A
S
A
A
B
A
B

B
A
–
B
A
A 
A
S


A
A

A
B

B
C

A
C

S

=
A
B
A
B

A
B
A
B
	
A
B

548    Appendix A
www.Academicpress.com
notation 
 is used while the intersection operation plays the role of multiplication
and hence the alternative notations 
 or 
 are common.  
Some of the concepts just presented are illustrated using a Venn diagram in Figure A.1.  The 
set 
 is contained within the thick solid line, the set 
 within the dashed line, the set 
 is 
the set of points inside either line and the set 
 is the set of points inside both.  The set 
 is the set of points inside the solid line but not inside the dashed line, while the set 
 is the set of points inside the dashed line but not inside the solid line.  The set 
 is 
the set of all points outside of both lines.    
Definition A.5:  Two sets 
 and 
 are said to be mutually exclusive, or disjoint, if
and only if they have no common elements, in which case 
.  A collection
of sets 
, 
, . . ., 
 are said to be exhaustive if each element in the universal set is
contained in at least one of the sets in the collection. For exhaustive sets,
.
The following laws are consequences of the definitions we have just introduced.  The reader 
should verify these laws to gain familiarity with the algebra of sets.
•
Idempotent: 
, 
, for all sets 
.
•
Commutative: 
, 
, for all sets 
 and 
.
•
Associative: 
, 
 for all sets 
, 
, and 
.
•
Distributive: 
, 
 for all sets 
, 
, and 
.
•
Consistency: The three conditions 
, 
, and 
 are all con-
sistent or mutually equivalent.
•
Universal bounds: 
 for all sets 
.
•
Product: 
, 
 for all sets 
.
•
Sum: 
, 
 for all sets 
.
A
B
+
A
B

AB
A
B
A
B
+
AB
A
AB
–
B
AB
–
A
B
+
S
A
B
AB
A
B
+
A
AB
–
B
AB
–
Figure A.1
A Venn diagram illustrating some of the concepts of sets.
A
B
+
A
B
A
B
	

=
A1 A2
An
A1
A2

An



S
=
A
A

A
=
A
A
	
A
=
A
A
B

B
A

=
A
B
	
B
A
	
=
A
B
A
B
C




A
B



C

A
B
C


=
=
A
B
C
	


	
A
B
	


C
	
A
B
C
	
	
=
=
A B
C
A
B
C



	
A
B
	


A
C
	



=
A
B
C
	



A
B



A
C



	
=
A B
C
A
B

A
B
	
A
=
A
B

B
=

A
S


A

A
	

=
S
A
	
A
=
A

A

A
=
S
A

S
=
A

Review of Set Theory    549
www.Academicpress.com
•
Involution: 
 for all sets 
.
•
Complementarity: 
, 
 for all sets 
.
•
De Morgan’s first law: 
 for all sets 
 and 
.
•
De Morgan’s second law: 
 for all sets 
 and 
.
De Morgan’s laws can be stated in the following way.  To find the complement of an 
expression replace each set by its complement and interchange additions with multiplications 
and multiplications with additions.
A
 
A
=
A
A
A

S
=
A
A
	

=
A
A
B

A
B
	
=
A
B
A
B
	
A
B

=
A
B

551
APPENDIX B
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00015-2
© 2012 by Elsevier Inc. All rights reserved.
Review of Linear Algebra
The study of probability and random processes draws heavily upon concepts and results from 
elementary linear algebra.  In the text, we assume that the reader has a working knowledge 
of undergraduate level linear algebra. The aim of this appendix is to provide a review for 
those who need to brush up on these concepts. This review is not intended to be an exhaustive 
treatment of the topic, but rather is a summary of selected concepts that are used within the text.  
Definition B.1: A matrix is a two-dimensional array of numbers. We say that a matrix
has size 
 if the array has 
 rows and 
 columns.  If the matrix has only one
row, then we refer to it as a row vector while if there is only one column it is a column
vector.  A matrix with one row and one column is called a scalar. The elements of a
matrix, 
, are written as 
, where the first subscript represents the row number and
the second subscript gives the column number.
Definition B.2: The transpose of a matrix is obtained by exchanging the row and
column number of each element.  That is, if matrix 
 has elements 
, then the
element in the th row and th column of 
 is 
.  Hence if a matrix has size
, then its transpose has size 
.  Also, the transpose of a column vector is a
row vector and the transpose of a row vector is a column vector. A matrix 
 is said to
be symmetric if 
.
Definition B.3:  The Hermitian transpose (or just Hermitian) of a matrix 
 is written
 and is formed by taking the complex conjugate of the transpose.  That is, if matrix
 has elements 
, then the element in the th row and th column of 
 is 
.
A matrix 
 is said to be Hermitian symmetric if 
.  Sometimes such a matrix
is simply called a Hermitian matrix.
Definition B.4:  Addition and multiplication of matrices is defined as follows.  If two
matrices 
 and 
 have the same size (same number of rows and columns), then their
sum is defined as 
 where 
.  That is, matrix addition is done
on an element-by-element basis.  If the two matrices do not have the same dimensions,
they cannot be added.  If 
 has size 
 and 
 has size 
, then their product
 will be an 
 matrix whose elements are given by
m
n

m
n
B
bi j
B
bi j
i
j
BT
bj i
m
n

n
m

B
BT
B
=
B
BH
B
bi j
i
j
BH
bj i
*
B
BH
B
=
A
B
C
A
B
+
=
ci j
ai j
bi j
+
=
A
m
k

B
k
n

C
AB
=
m
n


552    Appendix B
www.Academicpress.com
.
(B.1)
In order for the matrix product 
 to be defined, the number of columns in 
 must
equal the number of rows in 
.  
It is also common to define two different products involving vectors, the so-called scalar (or 
dot) product and the matrix (or cross) product.  We have no occasion to use the cross product 
in this text and so we do not consider it here.  For two column vectors  and  (both with the 
same number of elements), the dot product is defined as 
 where the standard 
definition of matrix multiplication as it applies to vectors is used.  Two vectors are said to be 
orthogonal if their dot product is zero.  Finally, the norm of a vector is 
.
With these definitions in place, the reader should be able to verify the following properties of 
matrix arithmetic:
•
Commutative: 
 for matrices for which the addition is defined.  However, 
the same property does not usually hold for multiplication.  That is, 
 does not 
necessarily equal 
.  In fact, 
 may not even be defined.
•
Associative: 
 and 
.
•
Distributive: 
.
•
Transposes of Sums: 
 and 
.
•
Transposes of Products: 
 and 
.
In much of this text, many of the matrices we deal with are square.  The following definition 
identifies some characteristics which can be applied to square matrices.
Definition B.5: A matrix 
 is diagonal if its elements satisfy 
 for all 
.
A matrix is upper triangular if 
 for all 
 and lower triangular if 
for all 
.  Note that a diagonal matrix is simultaneously upper and lower triangular.
Finally, a matrix is an 
 identity matrix if it is a diagonal matrix whose diagonal
entries are all equal to one.  The letter  is reserved to represent an identity matrix.  
An identity matrix has the form
.
(B.2)
ci j
ai l bl j
l
1
=
k

=
AB
A
B
a
b
a
b

aHb
=
b
bHb
=
A
B
+
B
A
+
=
AB
BA
BA
A
B
C
+


+
A
B
+


C
+
=
A BC


AB

C
=
A B
C
+


AB
AC
+
=
A
B
+

T
AT
BT
+
=
A
B
+

H
AH
BH
+
=
AB

T
BTAT
=
AB

H
BHAH
=
B
bi j
0
=
i
j

bi j
0
=
i
j
	
bi j
0
=
i
j

m
m

I
I
1
0
0  0
0
1
0  0
0
0
1  0
  

0
0
0  1
=

Review of Linear Algebra    553
www.Academicpress.com
Sometimes we use a subscript to indicate the dimensions of the identity matrix.  For example, 
 would represent an identity matrix with 
 rows and columns.  Note that the identity 
matrix is the identity with respect to matrix multiplication.  That is, for any 
 matrix 
, 
.  The identity with respect to matrix addition would be a matrix of 
all zeros.  
Definition B.6:  The inverse of a square matrix 
, written 
 (if it exists), is a
matrix which satisfies 
.  If the matrix 
 is not square, then it may
have a left inverse which satisfies 
 and a different right inverse which
satisfies 
.  In fact, for non-square matrices, the left inverse and right inverse
will not have the same dimensions.  
The inverse of a square matrix need not exist, but if it does, it is unique and the left and right 
inverses are identical.  If the inverse of a matrix does not exist, then the matrix is said to be 
singular, while if the inverse exists, the matrix is non-singular or invertible.
The inverse of a matrix plays an important role in the solutions of simultaneous linear 
equations.  Consider the following system of  linear equations in  unknowns, 
.
,
,
.
(B.3)
By defining 
 as the 
 matrix of coefficients whose elements are 
 and the column 
vectors 
 and 
, this system of equations can be 
written in matrix form as
.
(B.4)
Multiplying both sides by the inverse of 
 leads us to the solution 
.
(B.5)
Hence if the coefficient matrix is invertible, the system has a unique solution.  On the other 
hand, if the coefficient matrix is singular, then 
 does not exist and the set of equations 
does not have a unique solution.  This would be the case if some of the equations in (B.3) were 
linearly dependent (redundant), in which case the system would have more than one solution, 
or if some of the equations were inconsistent which would lead to no solution.  In either case 
of redundant or inconsistent equations, the rows of the 
 matrix will be linearly dependent 
Im
m

m
m
n

B
Im
m

B
BIn
n

B
=
=
B
B 1
–
BB 1
–
B 1
– B
I
=
=
B
B 1
– B
I
=
BB 1
–
I
=
n
n
x1 x2  xn



a1 1
 x1
a1 2
 x2

a1 n
 xn
+
+
+
b1
=
a2 1
 x1
a2 2
 x2

a2 n
 xn
+
+
+
b2
=

an 1
 x1
an 2
 x2

an n
 xn
+
+
+
bn
=
A
n
n

ai j
x
x1 x2  xn




T
=
b
b1 b2  bn




T
=
Ax
b
=
A
x
A 1
– b
=
A 1
–
A

554    Appendix B
www.Academicpress.com
and the inverse will not exist.  Conversely, if the rows of 
 are linearly independent, the 
matrix will be invertible.
A few properties of matrices that are related to the inverse are listed below:
•
Inverse of Transposes: 
.
•
Inverse of Hermitian Transposes: 
.
•
Inverse of Products: 
.
•
Inverse of Identities: 
.
A single quantity that is extremely useful in characterizing the invertibility of a matrix is its 
determinant.  The determinant can be rather difficult to define in a simple manner, but it has 
many useful properties. We use a recursive definition which may seem rather cryptic, but is 
probably the simplest definition and is also consistent with how determinants are often 
calculated.
Definition B.7:  Let 
 be an 
 matrix with elements 
. Define 
 to be the
 matrix obtained by removing the th row and th column from 
.
Then, the determinant of 
 is defined recursively according to
, 
for any 
.
(B.6)
This recursion, together with the definition that for a 
 matrix 
,
, is sufficient to calculate the determinant of any 
 matrix.  
To see how this works, consider a 
 matrix.
.
(B.7)
This was obtained using 
 in (B.6).  We could have also used 
 and achieved the 
same result
.
(B.8)
A
AT

 1
–
A 1
–

T
=
AH

 1
–
A 1
–

H
=
AB

 1
–
B 1
– A 1
–
=
I 1
–
I
=
B
n
n

bi j
B i j


n
1
–

 n
1
–


i
j
B
B
det B


1
–

i
j
+ det B i j




j
1
=
n

=
i
1 2  n
 

=
1 1

B
b
 
=
det B


b
=
n
n

2 2

det
a b
c d






adet
d
 


bdet
c
 


–
ad
bc
–
=
=
i
1
=
i
2
=
det
a b
c d






cdet
b
 


–
ddet
a
 


+
cb
–
da
+
=
=

Review of Linear Algebra    555
www.Academicpress.com
For a general 
 matrix, the determinant works out to be
(B.9)
Probably the most important property of determinants is that if 
 then the matrix 
 
is singular and conversely if 
, then 
 is invertible. This, along with some other 
important properties, are listed below.  We will not prove any of these properties in this 
review.
•
Invertibility: 
.
•
Row Exchange: If the matrix 
 is formed by exchanging any two rows in the matrix 
, then 
.
•
Identity Matrices: For any identity matrix, 
.
•
Triangular Matrices: If 
 is a triangular matrix, 
.  
That is, the determinant is the product of the diagonal elements.  Note that diagonal 
matrices are a special case and this property applies to them as well.
•
Products of Matrices: 
.
•
Inverses: 
.
•
Transposes: 
.
•
Hermitian Transposes: 
.
In addition to computing determinants of matrices, we will also find need throughout the text 
to compute eigenvalues and eigenvectors of square matrices.  
Definition B.8:  For a square matrix 
, the scalar 
 is an eigenvalue and the vector 
is a corresponding eigenvector if 
.
(B.10)
Note that the previous equation can be written in the slightly different form 
.  
The eigenvector  will be non-zero only if the matrix 
 is singular.  If it were non-
singular, we could multiply both sides by its inverse to obtain the trivial solution 
.  
Hence, the eigenvalues of the matrix 
 must be solutions to the equation
3
3

det
a b c
d e f
g h i










adet
e f
h i






bdet
d f
g i






–
cdet
d e
g h






+
a ei
fh
–


b di
fg
–


–
c dh
eg
–

 ·
+
=
=
det B


0
=
B
det B


0

B
det B


0
=


B is singular



A
B
det A


det B


–
=
det I 
1
=
B
det B


bi i
i
1
=
n

=
det AB


det A

det B


=
det B 1
–


1 det B



=
det BT


det B


=
det BH


det B




=
*
B

x
Bx
x
=
B
I
–

x
0
=
x
B
I
–
x
0
=
B

556    Appendix B
www.Academicpress.com
.
(B.11)
This is the so-called characteristic equation for the matrix 
.  For an 
 matrix, 
, the 
characteristic equation will be an th order polynomial equation in 
 and hence an 
 
matrix will have  eigenvalues (although some of them may be repeated).  Corresponding to 
each eigenvalue, 
,  is an eigenvector, 
.  Note that the eigenvector is not unique since if 
 satisfies (B.10) then any multiple of 
 will also satisfy the same equation and hence will 
also be an eigenvector.  In order to resolve this ambiguity, it is common to normalize the 
eigenvectors so that 
, but the vector is still an eigenvector even if it is not 
normalized.  In the case of repeated eigenvalues, there may also be corresponding 
eigenvectors which differ by more than just a scale constant.  
Before listing the important properties of eigenvalues and eigenvectors, it is necessary to 
include one more definition.
Definition B.9 :  A matrix 
 is positive definite if 
 for any vector  and it is
negative definite if 
 for all .  If 
, then the matrix is referred to as
positive semi-definite and if 
, the matrix is negative semi-definite.
With this definition in place, we now list the following properties of eigenvalues and 
eigenvectors.
•
Trace of a matrix: 
. That is, the sum of the eigen-
values is equal to the sum of the diagonal elements of a matrix, also known as its trace.
•
Determinant of a matrix:
 
.  
That is, the product of the eigenvalues is the determinant of a matrix.  As a result, any 
singular matrix must have at least one eigenvalue which is zero.  
•
Triangular matrices: If a matrix 
 is triangular (or diagonal), the eigenvalues are just 
the diagonal entries, 
.
•
Positive and Negative Definite Matrices: If 
 is positive definite, then its eigenvalues 
are all real and positive while if 
 is positive semi-definite, all its eigenvalues are non-
negative.  Similarly if 
 is negative definite than the eigenvalues are negative while if 
 is negative semi-definite, the eigenvalues are non-positive.
•
Linear Independence: If the eigenvectors 
 are non-zero and correspond 
to distinct (not repeated) eigenvalues 
, then the eigenvectors are linearly 
independent.  
•
Diagonal Form: Suppose 
 is an 
 matrix and has  linearly independent 
eigenvectors.  Construct a matrix 
 whose columns are the  eigenvectors and a 
det B
I
–


0
=
B
n n

B
n

n n

n
k
xk
xk
xk
x 2
1
=
B
zHBz
0
	
z
zHBz
0

z
zHBz
0

zHBz
0

trace B


bk k
k
1
=
n

k
k 1
=
n

=
=
det B


k
k
1
=
n

=
B
k
bk k

=
B
B
B
B
x1 x2  xn



1 2  n



B
n
n

n
S
n

Review of Linear Algebra    557
www.Academicpress.com
diagonal matrix 
 whose diagonal entries are the eigenvalues.  Then the matrix 
 can 
be factored as 
.
•
Powers of a Matrix: A direct result of the previous property is that for matrices with 
linearly independent eigenvectors, 
.  Furthermore, since 
 is diagonal, 
 is computed by raising each diagonal entry to the kth power.
In many of the applications encountered in this text, the matrices we are dealing with are 
Hermitian.  These matrices possess further properties which are not necessarily shared by all 
matrices.  These additional properties make Hermitian matrices particularly convenient to 
work with.
•
Positive Semi-definite: Any Hermitian matrix has all real eigenvalues and is at least 
positive semi-definite.  Furthermore, if the matrix is also non-singular, then it will be 
positive definite.
•
Orthogonal Eigenvectors: Eigenvectors of a Hermitian matrix which correspond to 
different eigenvalues are orthogonal.
•
Spectral Decomposition: Any Hermitian matrix can be decomposed into the form
,
(B.12)
where 
 is the matrix whose columns are the eigenvectors (normalized).  
L
B
B
SLS 1
–
=
Bk
SLkS 1
–
=
L
Lk
B
UUH
kxkxk
H
k
1
=
n

=
=
U

559
APPENDIX C
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00016-4
© 2012 by Elsevier Inc. All rights reserved.
Review of Signals and Systems
This appendix provides a summary of some important results in the area of signal 
representation and linear time invariant systems.  Any engineering student embarking on a 
serious study of probability and random processes should be familiar with these concepts and 
hence a rigorous development is not attempted here.  Rather, this review is intended as a brief 
refresher for those who need it and also as a quick reference for some important results that are 
used throughout the text.  In this appendix, attention is focused on deterministic signals and 
systems in both continuous  and discrete time.
Definition C.1:  Consider a periodic signal 
 whose period is 
. That is,
 for all .  The inverse of the period 
 is called the 
fundamental frequency of 
 and any frequency, 
, which is a multiple of
the fundamental frequency is called a harmonic.
Any periodic signal (subject to some mild constraints known as the Dirichlet conditions) can 
be represented as a linear combination of complex exponential signals, 
, whose 
frequencies are at the harmonics of the signal.  That is, if 
 is periodic with period 
, then
.
(C.1)
This is known as the Fourier Series expansion and the series coefficients can be computed 
according to
.
(C.2)
Since the signal is periodic, the integral in the previous expression can be taken over any 
convenient interval of length 
.  In general, the series coefficients are complex numbers, and 
it is common to express them in terms of their magnitude and phase, 
.  
The Fourier series coefficients display the frequency content of periodic signals.  
x t 
To
x t 
x t
To
+


=
t
fo
1 To

=
x t 
fn
nfo
=
j2fnt


exp
x t 
To
x t 
xnej2nfot
k

–
=


=
xn
1
To
------
x t e j2nfot
–
td
To
=
To
xn
xn
j
xn
	


exp
=

560    Appendix C
www.Academicpress.com
For signals which are not periodic, the Fourier transform can be used to display the frequency 
content of a signal.  The Fourier transform of a signal is given by
,
(C.3)
and the inverse Fourier Transform is
.
(C.4)
Sometimes we use the notation 
 to indicate that 
 and 
 are a Fourier 
Transform pair.  A table of some common Fourier Transform pairs is provided in Table E.1.  
Some of the more important properties of Fourier Transforms are listed below.
•
Linearity: If 
 and 
, then 
 for 
any constants  and .
•
Symmetry: If 
 is real valued, then 
.  As a result 
 must then 
be an even function of 
 and 
 must be an odd function of 
.  In addition, if 
 is both real and even, then 
 will be real and even.
•
Time Shifting: If 
, then 
.  As a consequence, 
shifting a signal in time does not alter the magnitude of its Fourier Transform.
•
Differentiation: If 
, then 
.
•
Integration: If 
, then 
.  The term 
 
that appears in this expression is the direct current (d.c.) value of the signal.
•
Time and Frequency Scaling: If 
, then 
 for any constant 
.
•
Parseval’s Relation: If 
, then 
.  This is a 
statement of conservation of energy.  That is, the energy in the time domain is equal to 
the energy in the frequency domain.
•
Convolution:  If 
 and 
, then
 
.
For signals in discrete time, 
, a Discrete-time Fourier Transform (DTFT) is defined 
according to:
,
(C.5)
X f 
x t e j2ft
–
td

–


=
x t 
X f ej2ft fd

–


=
x t 
X f 

x t 
X f 
x t 
X f 

y t 
Y f 

ax t 
by t 
+
aX f 
bY f 
+

a
b
x t 
X
f
–


X* f 
=
X f 
f
X f 
	
f
x t 
X f 
x t 
X f 

x t
to
–


e j2fto
–
X f 

x t 
X f 

dx t 
dt
------------
j2fX f 

x t 
X f 

x u
  u
d

–
t
X f 
j2f
----------
1
2---X 0
 
f 

+

X 0
 
x t 
X f 

x at


1
a-----X f
a---
 
 
=
a
0

x t 
X f 

x t  2 td

–

X f  2 fd

–

=
x t 
X f 

y t 
Y f 

x t *y t 
x u
 y t
u
–

 td

–


=
X f Y f 

x n
 
X f 
x n
 e j2fn
–
n

–
=

=

Review of Signals and Systems    561
www.Academicpress.com
and the inverse DTFT is
.
(C.6)
Since 
 is periodic with period of 1, the integral in the previous equation can be taken 
over any interval of length 1. It is common to view the DTFT using discrete frequency samples 
as well.  In that case, the definition of the DTFT and its inverse is modified to give the 
-point DTFT:
,
(C.7)
.
(C.8)
Alternatively, by replacing 
 with z in the definition of the DFT, we get the
 z-transform:
.
(C.9)
The inverse -transform is given by a complex contour integral,
,
(C.10)
where the contour of integration is any closed contour which encircles the origin in the 
counterclockwise direction and is within the region of convergence of 
.  Because of the 
complicated nature of the inverse transform, it is common to compute these inverse transforms 
via tables. A table of some common z-transform pairs is provided in Table E.2.
These various transform representations of signals are particularly useful when studying the 
passage of signals through linear time-invariant (LTI) systems.  
Definition C.2:  Suppose when 
 is input to a system, the output is 
. The
system is said to be time-invariant if the input 
 produces an output of
.  That is, a time delay in the input produces the same time delay on the
output but no other changes to the output.  Furthermore, suppose the two inputs 
and 
 produce the two outputs 
 and 
, respectively.  Then, the system is
linear if the input 
 produces the output 
 for any
constants  and .  Identical definitions apply to discrete time systems as well.
x n
 
X f ej2fn fd
1 2

–
1 2

=
X f 
N
X m


x n
 e j2mn N

–
n
0
=
N
1
–

=
x n
 
1
N----
X m

ej2mn N

m
0
=
N
1
–

=
j2f


exp
X z 
x n
 z n
–
n

–
=

=
z
x n
 
1
2j
-------- X z zn
1
– dz

=
X z 
x t 
y t 
x t
to
–


y t
to
–


x1 t 
x2 t 
y1 t 
y2 t 
ax1 t 
bx2 t 
+
ay1 t 
by2 t 
+
a
b

562    Appendix C
www.Academicpress.com
A direct consequence of the linearity of a system is the concept of superposition which states 
that if the input can be written as a linear combination of several terms 
 
, then the corresponding output can be written as the same linear 
combination of the corresponding outputs 
.  
Any LTI system can be described in terms of its impulse response, 
.  If the input is a delta 
(impulse) function, 
, the output is then the impulse response 
.  For any LTI 
system, the input/output relationship is given in terms of the impulse response according to the 
convolution integral
.
(C.11)
If the input is a complex exponential at some frequency 
, i.e., 
, then the 
corresponding output is then 
.
(C.12)
That is, the output will also be a complex exponential whose magnitude and phase have been 
adjusted according to the complex number 
.  This function of frequency is called the 
transfer function of the system and is the Fourier Transform of the impulse response. Since 
complex exponentials form eigenfunctions of any LTI system, when studying LTI systems, it 
is convenient to decompose signals into linear combinations of complex exponentials.  If 
 
is a periodic signal it can be written as a linear combination of complex exponentials through 
its Fourier Series representation, 
.
(C.13)
Then using the concept of superposition together with the previous result, we find that the 
output of an LTI system, when 
 is input is
.
(C.14)
Hence the Fourier series coefficients of the input and output of an LTI system are related by 
the simple form
.
(C.15)
x t 
a1x1 t  +
=
a2x2 t 

anxn t 
+
+
y t 
a1y1 t 
a2y2 t 

anyn t 
+
+
+
=
h t 
t 

y t 
h t 
=
y t 
x t *h t 
x u
 h t
u
–

 u
d

–


x t
u
–

h u
  u
d

–


=
=
=
f
x t 
j2ft


exp
=
y t 
ej2ft
h u
 e j2fu
–
u
d

–


ej2ftH f 
=
=
H f 
x t 
x t 
xkej2kfot
k
=
x t 
y t 
xkH kfo

ej2kfot
k
ykej2kfot
k
=
=
yk
xkH kfo


=

Review of Signals and Systems    563
www.Academicpress.com
A similar relationship holds for the Fourier transforms of non-periodic signals. Taking Fourier 
Transforms of both sides of (C.11) and using the convolution property of Fourier Transforms 
results in
. 
(C.16)
Identical relationships hold for the DFT and z-transforms as well.
Y f 
X f H f 
=

565
APPENDIX D
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00017-6
© 2012 by Elsevier Inc. All rights reserved.
Summary of Common Random Variables
This appendix provides a quick reference of some of the most common random variables.  
Special functions that are used in this appendix are defined in the following list:
•
Gamma function: 
, 
.
•
Incomplete Gamma function: 
,  
. 
•
Beta function: 
.
•
Incomplete Beta function: 
, 
.
•
Modified Bessel function of order 
: 
.
•
Q-function: 
.
•
Marcum’s Q-function: 
.
Continuous Random Variables
Arcsine
For any 
, 
.
(D.1)
(D.2)
, 
.
(D.3)
 
 
u
1
– e u
–
u
d
0


=
Re 
 	
0

  



u
1
– e u
–
u
d
0


=
Re 
 	
0

B a b



ua
1
–
1
u
–

b
1
–
u
d
0
1

 a
  b
 
 a
b
+


------------------------
=
=
 a b x
 


ua
1
–
1
u
–

b
1
–
u
d
0
x

=
0
x
1


m
Im x
 
1
2
------
ex

 
cos
m


cos

d
0
2

=
Q x
 
1
2
----------
u2
2-----
–




exp
u
d
x


=
Q  



u
2
u2
+
2
------------------
–




exp
I0 u

 u
d



=
b
0

fX x
 
1
 b2
x2
–
-------------------------
=
b
–
x
b


FX x
 
0
x
b
–

1
2---
1
---sin 1
–
x
b---
 
 
+
b
–
x
b


1
x
b ·








=
X
0
=
X2
b2
2-----
=

566    Appendix D
www.Academicpress.com
Note: 
1)
Formed by a transformation 
 where  and  are constants and 
 is a uniform random variable over 
.
Beta
For any 
 and 
,  
.
(D.4)
(D.5)
, 
.
(D.6)
Cauchy
For any 
.
(D.7)
.
(D.8)
.
(D.9)
Notes:
1)
Both the mean and variance are undefined.
2)
Formed by a transformation of the form 
 where 
 is uniform over 
.
X
b
2U

+


cos
=
b

U
0 1


a
0

b
0

fX x
 
1
B a b



-----------------xa
1
–
1
x
–

b
1
–
=
0
x
1


FX x
 
0
x
0

 a b x
 


B a b



-----------------------
0
x
1


1
x
1.







=
X
a
a
b
+
------------
=
X2
ab
a
b
+

2 a
b
1
+
+


-----------------------------------------------
=
b
0

fX x
 
b 

b2
x2
+
-----------------
=
FX x
 
1
2---
1
---tan 1
–
x
b---
 
 
+
=
X 


e b 
–
=
X
btan 2U


=
U
0 1



Summary of Common Random Variables    567
www.Academicpress.com
Chi-Square
For integer 
,
  
.
(D.10)
(D.11)
.
(D.12)
, 
.
(D.13)
Notes: 
1)
The Chi-Square random variable is a special case of the Gamma random variable.
2)
The parameter  is referred to as the number of degrees of freedom of the chi-square 
random variable.
3)
The Chi-Square random variable is formed by a transformation of the form 
, where the 
 are IID zero-mean, unit variance, Gaussian random 
variables.
Erlang
For any integer 
 and any 
, 
 
.
(D.14)
(D.15)
.
(D.16)
,  
.
(D.17)
n
0

fX x
 
xn 2

1
–
2n 2
  n 2



------------------------------e x 2

–
=
x
0

FX x
 
0
x
0

 n 2

x 2




 n 2



------------------------------ 
x
0.






=
X 


1
1
2j
–

n 2

-------------------------------
=
X
n
=
X2
2n
=
n
X
Zk2
k
1
=
n
 
=
Zk
n
0

b
0

fX x
 
bnxn
1
– e bx
–
n
1
–

!
-----------------------------
=
x
0

FX x
 
0
x
0

 n bx



n
1
–

!
------------------- 
x
0.






=
X 


1
1
j b

–

n
-----------------------------
=
X
n b

=
X
2
n b2

=

568    Appendix D
www.Academicpress.com
Notes:
1)
The Erlang random variable is a special case of the Gamma random variable.  
2)
The Erlang random variable is formed by summing  IID exponential random 
variables.
3)
The CDF can also be written as a finite series
, 
 
.
(D.18)
Exponential
For any 
,
 
.
(D.19)
(D.20)
.
(D.21)
, 
.
(D.22)
Notes:
1)
The Exponential random variable is a special case of the Erlang and Gamma random 
variables.
2)
The Exponential random variable possesses the memoryless property, 
.
(D.23)
For any integers 
 and 
,
 
.
(D.24)
n
 n bx



n
1
–

!
-------------------
1
ebx
bx

k
k!
-------------
k
0
=
n
1
–
 
–
=
x
0

b
0

fX x
 
be bx
–
=
x
0

FX x
 
0
x
0

1
e bx
– ,
–
x
0.




=
X 


1
1
j b

–
----------------------
=
X
1 b

=
X2
1 b2

=
fX x X
a



fX x
a
–


=
F
n
0

m
0

fX x
 
n
m----



 n 2
/
B n
2--- m
2----





--------------------x
n
2---
1
–
1
n
m----x
+




n
m
+
2
-------------
–
=
x
0


Summary of Common Random Variables    569
www.Academicpress.com
 for 
,
  
 for 
.
(D.25)
Note:
1)
If 
 and 
 are independent Chi-square random variables with  and 
 degrees of 
freedom respectively, then 
 will be an 
 random variable with  
and 
 degrees of freedom.
Gamma
For any 
 and 
,
  
.
(D.26)
.
(D.27)
.
(D.28)
, 
.
(D.29)
Note:
1)
The Gamma random variable contains the Chi-Square, Erlang, and Exponential 
random variables as special cases.
Gaussian
For any 
 and any 
.
(D.30)
.
(D.31)
.
(D.32)
, 
.
(D.33)
X
m
m
2
–
-------------
=
m
2

X2
m2 2n
2m
4
–
+


n m
2
–

2 m
4
–


------------------------------------------
=
m
4

U
V
n
m
F
U n



V m




=
F
n
m
a
0

b
0

fX x
 
baxa
1
– e bx
–
 a
 
-----------------------------
=
x
0

FX x
 
 a bx



 a
 
-------------------
=
X 


1
1
j b

–

a
-----------------------------
=
X
a b

=
X2
a b2

=


0

fX x
 
1
22
-----------------
x

–

2
22
-------------------
–




exp
=
FX x
 
1
Q x

–

------------




–
=
X 


j
1
2---22
–




exp
=
X

=
X2
2
=

570    Appendix D
www.Academicpress.com
Gaussian-Multivariate
For any  element column vector 
 and any valid 
 covariance matrix 
.
(D.34)
.
(D.35)
,
  
.
(D.36)
Laplace
For any 
.
(D.37)
(D.38)
.
(D.39)
,
  
.
(D.40)
Log-Normal
For any 
 and any 
,
  
.
(D.41)
(D.42)
, 
.
(D.43)
n
m
n
n
!
C
fX x
 
1
2

n 2
 det C


------------------------------------
1
2--- X
m
–

TC 1
–
X
m
–


–




exp
=
X 


jmT
1
2---TC
–




exp
=
E X

	
m
=
E
X
m
–

 X
m
–

T

	
C
=
b
0

fX x
 
b
2---
b x
–


exp
=
FX x
 
1
2---ebx
x
0
 
1
1
2---e bx
–
–

+
x
0.






=
X 


1
1
 b


2
+
----------------------------
=
X
0
=
X
2
2 b2

=


0

fX x
 
1
x 22
--------------------
x
 
ln

–

2
22
------------------------------
–




exp
=
x
0

FX x
 
0
x
0
 
1
Q
x
 
ln

–

----------------------




–
x
0.






=
X

2
2------
+




exp
=
X2
2


exp
1
–

	
2
2
+


exp
=

Summary of Common Random Variables    571
www.Academicpress.com
Notes:
1)
The log-normal random variable is formed by a transformation of the form 
, where 
 is a Gaussian random variable with mean 
 and variance 
.
2)
It is common to find instances in the literature where 
 is referred to as the standard 
deviation of the log-normal random variable.  This is a misnomer.  The quantity 
 is 
not the standard deviation of the log-normal random variable but rather is the standard 
deviation of the underlying Gaussian random variable. 
Nakagami
For any 
 and 
,
  
.
(D.44)
(D.45)
,
  
.
(D.46)
Rayleigh
For any 
,
 
.
(D.47)
(D.48)
, 
 
.
(D.49)
X
Z
 
exp
=
Z

2


b
0

m
0

fX x
 
2mm
 m

bm
--------------------x2m
1
–
m
b----x2
–




exp
=
x
0

FX x
 
0
x
0
 
 m m
b----x2





 m


-------------------------
x
0.








=
X
 m
1 2

+


 m


-----------------------------
b
m----
=
X2
b
X2
–
=

0

fX x
 
x
2
------
x2
22
---------
–




exp
=
x
0

FX x
 
0
x
0
 
1
x2
22
---------
–




exp
–
x
0.






=
X
2
2
----------
=
 
X2
4

–

2
2
-----------------------
=

572    Appendix D
www.Academicpress.com
Notes:
1)
The Rayleigh random variable arises when performing a Cartesian to Polar 
transformation of two independent zero-mean Gaussian random variables.  That is, if 
 
and 
 are independent zero-mean Gaussian random variables with variances of 
, 
then 
 follows a Rayleigh distribution.
2)
The Rayleigh random variable is a special case of the Rician random variable.
Rician
For any 
 and any 
,
  
.
(D.50)
(D.51)
.
(D.52)
.
(D.53)
Notes:
1)
The Rician random variable arises when performing a Cartesian to Polar 
transformation of two independent Gaussian random variables.  That is, if 
 and 
 
are independent Gaussian random variables with means of 
 and 
, respectively 
and equal variances of 
, then 
 follows a Rician distribution, with 
.
2)
The ratio 
 is often referred to as the Rician parameter or the Rice factor.  As the 
Rice factor goes to zero, the Rician random variable becomes a Rayleigh random 
variable.
Student t 
For any integer 
 
.
(D.54)
, 
 
 for 
.
(D.55)
Y1
Y2
2
X
Y12
Y22
+
=
a
0


0

fX x
 
x
2
------
x2
a2
+
22
-----------------
–




exp
Io
ax
2
------




=
x
0

FX x
 
0
x
0

1
Q a
--- x
---





–
x
0.






=
X
2
2
----------
a2
42
---------
–




1
a2
22
---------
+



 Io
a2
42
---------




a2
22
---------I1
a2
42
---------




+
exp
=
X
2
22
a2
X
2
–
+
=
Y1
Y2
1
2
2
X
Y12
Y22
+
=
a
12
22
+
=
a2 2

n
0

fX x
 
1
B n 2

1 2



 n
--------------------------------------- 1
x2
n-----
+




n
1
+
2
------------
–
=
X
0
=
X
2
n
n
2
–
------------
=
n
2


Summary of Common Random Variables    573
www.Academicpress.com
Notes:
1)
This distribution was first published by W. S. Gosset in 1908 under the pseudonym 
“Student.”  Hence this distribution has come to be known as the Student’s t-distribution.
2)
The parameter  is referred to as the number of degrees of freedom.
3)
If 
, 
, is a sequence of IID Gaussian random variables and 
 and 
 
are the sample mean and sample variance, respectively, then the ratio 
 will have a t-distribution with 
 degrees of freedom.
Uniform
For any 
,
 
.
(D.56)
(D.57)
.
(D.58)
,
  
.
(D.59)
Weibull
For any 
 and any 
,
 
.
(D.60)
(D.61)
, 
.
(D.62)
n
Xi i
1 2 " n
 

=
ˆ
s2ˆ
T
ˆ

–


s2ˆ
n


=
n
1
–
a
b

fX x
 
1
b
a
–
------------
=
a
x
b


FX x
 
0
x
a

x
a
–
b
a
–
------------
a
x
b


1
x
b·






=
X 


ejb
eja
–
j b
a
–


---------------------------
=
x
a
b
+
2
------------
=
X
2
b
a
–

2
12
-------------------
=
a
0

b
0

fX x
 
abxb
1
–
axb
–


exp
=
x
0

FX x
 
0
x
0
 
1
axb
–


exp
–
x
0.




=
X
 1
1
b---
+




a1 b

----------------------
=
X2
 1
2
b---
+




 1
1
b---
+



 2
–
a2 b

----------------------------------------------------------
=

574    Appendix D
www.Academicpress.com
Note:
1)
The Weibull random variable is a generalization of the Rayleigh random variable and 
reduces to a Rayleigh random variable when 
.  
Discrete Random Variables
Bernoulli
For 
(D.63)
 
for all .
(D.64)
, 
.
(D.65)
Binomial
For 
 and any integer 
(D.66)
 
for any .
(D.67)
,
  
.
(D.68)
Note:
1)
The binomial random variable is formed as the sum of  independent Bernoulli 
random variables.
Geometric
For 
(D.69)
b
2
=
0
p
1


PX k
 
1
p
–
k = 0,
p
k = 1,
0
otherwise.





=
HX z 
1
p 1
z
–


–
=
z
X
p
=
X2
p 1
p
–


=
0
p
1


n
0

PX k
 
n
k
 
  pk 1
p
–

n
k
– 
   k = 0 1 2 " n
  
 
0
otherwise.





=
HX z 
1
p 1
z
–


–

n
=
z
x
np
=
X2
np 1
p
–


=
n
0
p
1


PX k
 
1
p
–

pk
k
0

0
k
0.




=

Summary of Common Random Variables    575
www.Academicpress.com
, 
for 
.
(D.70)
,
  
.
(D.71)
Pascal (or Negative Binomial)
For 
 and any integer 
.
(D.72)
, 
for 
.
(D.73)
, 
.
(D.74)
Poisson
For any 
(D.75)
, for all .
(D.76)
, 
.
(D.77)
HX z 
1
p
–
1
pz
–
--------------
=
z
1 p


X
p
1
p
–
------------
=
X
2
p
1
p
–

2
-------------------
=
0
q
1


n
0

PX k
 
0
k
n

k
1
–
n
1
–



 1
q
–

nqk
n
– 
   k =n n
1 n
2 "

+

+






=
HX z 
1
q
–

z
1
qz
–
-------------------



 n
=
z
1 q


X
n
1
q
–
------------
=
X
2
nq
1
q
–

2
-------------------
=
b
0

PX k
 
bk
k!
-----e b
– 
k
0
 
0
k
0.






=
HX z 
b z
1
–




exp
=
z
X
b
=
X2
b
=

577
APPENDIX E
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00018-8
© 2012 by Elsevier Inc. All rights reserved.
Mathematical Tables
A.  Trigonometric Identities
.
(E.1)
.
(E.2)
.
(E.3)
.
(E.4)
.
(E.5)
.
(E.6)
.
(E.7)
.
(E.8)
.
(E.9)
B.  Series Expansions
,  
for 
.
(E.10)
,
for all .
(E.11)
sin2 x
 
cos2 x
 
+
1
=
x
y



cos
x
 
cos
y
 
cos
x
 
sin

y
 
sin
=
x
y



sin
x
 
sin
y
 
cos
x
 
cos
y
 
sin

=
x
 
cos
y
 
cos
1
2---
x
y
+


cos
1
2---
x
y
–


cos
+
=
x
 
sin
y
 
sin
1
2---
x
y
–


cos
1
2---
x
y
+


cos
–
=
x
 
sin
y
 
cos
1
2---
x
y
+


sin
1
2---
x
y
–


sin
+
=
jx


exp
x
 
cos
j
x
 
sin
+
=
x
 
cos
ejx
e jx
–
+
2
----------------------
=
x
 
sin
ejx
e jx
–
–
2j
----------------------
=
1
1
x
–
-----------
xk
k
0
=


=
x
1
	
1
xn
1
+
–
1
x
–
----------------------
xk
k
0
=
n

=
x

578    Appendix E
www.Academicpress.com
,
for 
.
(E.12)
,
for all , .
(E.13)
,
for all .
(E.14)
,
for all .
(E.15)
,
for all .
(E.16)
,
for 
.
(E.17)
,
for all .
(E.18)
,
for all .
(E.19)
C.  Some Common Indefinite Integrals 
Note: For each of the indefinite integrals, an arbitrary constant may be added to the result.
(E.20)
,  
.
(E.21)
1
1
x
–

n
1
+
--------------------------
k
n

 
  xk
n
–
k
n
=


k
n
+
n



 xk
k
0
=


=
=
x
1
	
x
y
+

n
n
k

 
  xkyn
k
–
k
0
=
n

=
x y
x
 
exp
1
k!----xk
k
0
=


=
x
x
 
cos
1
–

k
2k

!
-------------x2k
k
0
=


=
x
x
 
sin
1
–

k
2k
1
+

!
----------------------x2k
1
+
k
0
=


=
x
1
x
–


ln
1
k---xk
k
1
=


–
=
x
1
	
Q x
 
1
2---
1
2
----------
1
–

k
1
+
k!2k 2k
1
+


-------------------------------x2k
1
+
k
0
=


+
=
x
Im x
 
1
k! k
m
+

!
------------------------- x
2---

 
 
2k
m
+
k
0
=


=
x
xn x
d

xn
1
+
n
1
+
-------------
     n
1
–


x
 
ln

       n = 
1.
–





=
bx x
d

bx
b
 
ln
-------------
=
b
1


Mathematical Tables    579
www.Academicpress.com
.
(E.22)
.
(E.23)
.
(E.24)
.
(E.25)
.
(E.26)
.
(E.27)
.
(E.28)
.
(E.29)
.
(E.30)
 
(
).
(E.31)
(
).
(E.32)
(
).
(E.33)
(
).
(E.34)
(
).
(E.35)
(
).
(E.36)
x
 
ln
x
d

x
x
 
ln
x
–
=
x
 
sin
x
d

x
 
cos
–
=
x
 
cos
x
d

x
 
sin
=
x
 
tan
x
d

x
 
cos


ln
–
=
x
 
sinh
x
d

x
 
cosh
=
x
 
cosh
x
d

x
 
sinh
=
x
 
tanh
x
d

x
 
cosh


ln
=
eax
bx


sin
x
d

eax asin bx


b
bx


cos
–
a2
b2
+
--------------------------------------------------




=
eax
bx


cos
x
d

eax bsin bx


a
bx


cos
+
a2
b2
+
---------------------------------------------------




=
xnebx x
d

ebx
1
–

k
bk
1
+
-------------
n!
n
k
–

!
------------------xn
k
–
k
0
=
n

=
n
0

xn
bx


ln
x
d

xn
1
+
bx


ln
n
1
+
----------------
1
n
1
+

2
--------------------
–






=
n
1
–

1
x2
b2
+
----------------- x
d

1
b---tan 1
–
x
b---

 
 
=
b
0

1
b2
x2
–
--------------------- x
d

sin 1
–
x
b---

 
 
=
b
0

1
x2
b2
+
--------------------- x
d

x
x2
b2
+
+


log
sinh 1
–
x
b---

 
 
=
=
b
0

1
x2
b2
–
--------------------- x
d

x
x2
b2
–
+
log
cosh 1
–
x
b---

 
 
=
=
b
0


580    Appendix E
www.Academicpress.com
(E.37)
(E.38)
D.  Some Common Definite Integrals
for integer 
.
(E.39)
.
(E.40)
,
for integer 
.
(E.41)
.
(E.42)
(E.43)
,
.
(E.44)
,
.
(E.45)
1
ax2
bx
c
+
+
------------------------------ x
d

1
b2
4ac
–
-------------------------
2ax
b
b2
4ac
–
–
+
2ax
b
b2
4ac
–
+
+
--------------------------------------------------
ln

     b2
4ac


2
4ac
b2
–
-------------------------tan 1
–
2ax
b
+
4ac
b2
–
-------------------------




     b2
4ac ·
	







=
1
ax2
bx
c
+
+
---------------------------------- x
d

1
a
-------
2ax
b
2 a ax2
bx
c
+
+


+
+
ln

     a
0
 
1
a
–
----------sin 1
–
2ax
–
b
–
b2
4ac
–
-------------------------






     a
0.
	









=
xne x
–
x
d
0


 n
1
+


n!
=
=
n
0

e x2
–
x
d

–


x 1 2

–
e x
–
x
d
0


 1 2




=
=
=
xn 1 2

–
e x
–
x
d
0


 n
1 2

+


2n

!
22nn!
------------- 
=
=
n
1

sinc x
  x
d

–


sinc2 x
  x
d

–


1
=
=
1
2
------
cosn x
  x
d
0
2

1
2
------
sinn x
  x
d
0
2

0
   n odd
n
n 2




 1
2n
-----
     n even.





=
=
1
x2
b2
+
----------------- x
d

–

2
1
x2
b2
+
----------------- x
d
0


b---
=
=
b
0

1
b2
x2
–
--------------------- x
d
b
–
b
2
1
b2
x2
–
--------------------- x
d
0
b

=
=
b
0


Mathematical Tables    581
www.Academicpress.com
E.  Definitions of Some Common Continuous Time Signals
Step function: 
(E.46)
Rectangle function: 
(E.47)
Triangle function: 
(E.48)
Sinc function: 
.
(E.49)
F.  Fourier Transforms  
Table E.1: Common Fourier transform pairs
Signal (Time Domain)
Transform (Frequency Domain)
  
  
u x
 
1
x
0

0
x
0.
	



=
rect x
 
1
x
1 2

	
0
x
1 2.





=
tri x
 
1
x 
–
x
1

0
x
1.




=
c
sin
x
 
x


sin
x
-------------------
=
rect t to



tosinc fto


tri t to



tosinc2 fto


t
to
----
–




exp
u t 
to
1
j2fto
+
------------------------
t
to
----
–




exp
2to
1
2fto

2
+
------------------------------
sinc t to



torect fto


sinc2 t to



totri fto


(Continued)

582    Appendix E
www.Academicpress.com
G.  z-Transforms  
Table E.2: Common z-transform pairs
Signal
Transform
Region of 
Convergence
1
All 
Table E.1: Common Fourier transform pairs
Signal (Time Domain)
Transform (Frequency Domain)
j2fot


exp
f
fo
–



2fot

+


cos
1
2---
f
fo
–

ej

1
2---
f
fo
+

e j
–

+
t
to
–



j2fto
–


exp
t 
sgn
1
jf
-------
u t 
1
2---
f 

1
j2f
----------
+
t to


2
–


exp
to
2
fto

2
–


exp
n
  

z
u n
  
1
1
z 1
–
–
----------------
z
1

nu n
  
z 1
–
1
z 1
–
–

2
------------------------
z
1

n2u n
  
z 1
–
1
z 1
–
+


1
z 1
–
–

3
------------------------------
z
1

---- Cont’d

Mathematical Tables    583
www.Academicpress.com
All 
Table E.2: Common z-transform pairs
Signal
Transform
Region of 
Convergence
n3u n
  
z 1
–
1
4z 1
–
z 2
–
+
+


1
z 1
–
–

4
-----------------------------------------------
z
1

bnu n
  
1
1
bz 1
–
–
--------------------
z
b

nbnu n
  
bz 1
–
1
bz 1
–
–

2
---------------------------
z
b

n2bnu n
  
bz 1
–
1
bz 1
–
+


1
bz 1
–
–

3
------------------------------------
z
b

bn
!on

 
cos
u n
  
1 b
–
!o


cos
z 1
–
1
2b
!o


cos
z 1
–
–
bz 2
–
+
--------------------------------------------------------------
z
b

bn
!on

 
sin
u n
  
b
!o


sin
z 1
–
1
2b
!o


cos
z 1
–
–
bz 2
–
+
--------------------------------------------------------------
z
b

u n
1
–

 
n
--------------------
1
1
z 1
–
–
----------------




ln
z
1

n
m
+
m



 bnu n
  
1
1
bz 1
–
–

m
1
+
------------------------------------
z
b

bn
n!
-----u n
  
bz 1
–


exp
z
---- Cont’d

584    Appendix E
www.Academicpress.com
H.  Laplace Transforms   
I. Table of the Q-function
The following table lists values of the function 
 for 
 in increments of 0.05.  To 
find the appropriate value of , add the value at the beginning of the row to the value at the top 
Table E.3: Common Laplace transform pairs
Function
Transform
Region of 
Convergence
1
All 
All 
,  
,  
u t 
1 s

Re s  
0

bt
–


exp
u t 
1
s
b
+
-----------
Re s  
b
–

bt

u t 
sin
b
s2
b2
+
-----------------
Re s  
0

bt


cos
u t 
s
s2
b2
+
-----------------
Re s  
0

e at
–
bt


sin
u t 
b
s
a
+

2
b2
+
-------------------------------
Re s  
a
–

e at
–
bt


cos
u t 
s
a
+
s
a
+

2
b2
+
-------------------------------
Re s  
a
–

t 

s
t
d
d
t 

s
s
tnu t 
n
0

n!
sn
1
+
------------
Re s  
0

tne bt
– u t 
n
0

n!
s
b
+

n
1
+
---------------------------
Re s  
b
–

Q x
 
0
x
4
	

x

Mathematical Tables    585
www.Academicpress.com
of the column.  For example, to find 
 find the entry from the column headed by 1.00 
and the row headed by 0.75 to get 
.
Table E.4: Values of Q(x) for 0  x < 4 (in increaments of 0.05)
0.00  
1.00  
2.00  
3.00
0.00   
0.50000000   
0.15865525   
0.02275013   
0.00134990
0.05  
0.48006119   
0.14685906   
0.02018222   
0.00114421
0.10   
0.46017216   
0.13566606   
0.01786442   
0.00096760
0.15   
0.44038231   
0.12507194   
0.01577761   
0.00081635
0.20   
0.42074029   
0.11506967   
0.01390345   
0.00068714
0.25   
0.40129367   
0.10564977   
0.01222447   
0.00057703
0.30   
0.38208858   
0.09680048   
0.01072411   
0.00048342
0.35   
0.36316935   
0.08850799   
0.00938671   
0.00040406
0.40   
0.34457826   
0.08075666   
0.00819754   
0.00033693
0.45   
0.32635522   
0.07352926   
0.00714281   
0.00028029
0.50   
0.30853754   
0.06680720   
0.00620967   
0.00023263
0.55   
0.29115969   
0.06057076   
0.00538615   
0.00019262
0.60   
0.27425312   
0.05479929   
0.00466119   
0.00015911
0.65   
0.25784611   
0.04947147   
0.00402459   
0.00013112
0.70   
0.24196365   
0.04456546   
0.00346697   
0.00010780
0.75   
0.22662735   
0.04005916   
0.00297976   
0.00008842
0.80   
0.21185540   
0.03593032   
0.00255513   
0.00007235
0.85   
0.19766254   
0.03215677   
0.00218596   
0.00005906
0.90   
0.18406013   
0.02871656   
0.00186581   
0.00004810
0.95   
0.17105613   
0.02558806   
0.00158887   
0.00003908
Q 1.75


Q 1.75


0.04005916
=
Q x
 

587
APPENDIX F
Probability and Random Processes. DOI: 10.1016/B978-0-12-386981-4.00019-X
© 2012 by Elsevier Inc. All rights reserved.
Numerical Methods for Evaluating
the Q-Function
In this appendix, we give an overview of several methods available for numerically evaluating 
the CDF of a Gaussian random variable and related integrals.  Recall that for a zero-mean unit 
variance Gaussian random variable, the CDF is given by the integral
.
(F.1)
The Q-function is the complement of this integral
.
(F.2)
Many math packages have internal routines for evaluating related integrals, usually the error 
function or complementary error function.  Given the most common definitions of these 
functions,
,
(F.3)
,
(F.4)
the Q-function can then be written in terms of these functions as
.
(F.5)
For situations where internally defined functions are not available, several numerical 
techniques are available for efficiently evaluating the Q-function.  To start with, recall the 
symmetry relationship
.
(F.6)
FX x
 
1
2
----------
t2
2----
–




exp
td
	
–
x

=
Q x
 
1
2
----------
t2
2----
–




exp
td
x
	

=
erf x
 
2

-------
t2
–


exp
td
0
x

=
erfc x
 
2

-------
t2
–


exp
td
x
	

=
Q x
 
1
2---erfc
x
2
-------




1
2---
1
2---erf
x
2
-------




–
=
=
Q x
 
1
Q
x
–


–
=

588    Appendix F
www.Academicpress.com
Hence any routine for evaluating the Q-function only needs to work on positive values of .  
To start with, we consider the Taylor series expansion of the Q-function about the point 
,
.
(F.7)
This series is convergent for all 
 but will converge faster for smaller values of .  A good 
approximation can be obtained by truncating the series to a sufficient number of terms.  Since 
the series is alternating, the truncation error is bounded by the first term neglected.  Figure F.1 
shows the Q-function along with its approximations using the Taylor series truncated to 
various numbers of terms.  It is seen from this figure that for 
, a large number of terms 
may be needed for the Taylor series to converge.
For larger values of , it is common to use the following asymptotic series expansion
,  for 
.
(F.8)
x
x
0
=
Q x
 
1
2---
1
2
----------
1
–

k
1
+
k!2k 2k
1
+


-------------------------------x2k
1
+
k
0
=
	

+
=
x
0

x
x
2

0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
100
x
Q(x)
1 term 
2 terms 
3 terms 
4 terms 
5 terms 
Q(x) 
10−1
10−2
Figure F.1
The Q-function and its truncated Taylor series approximation.
x
Q x
 
1
2x
-------------
x2
2-----
–



 1
1
–

n 2n

!
2nn!
---------------------------x 2n
–
n
1
=
	

+










exp
=
x
0


Numerical Methods for Evaluating the Q-Function    589
www.Academicpress.com
Since the series has negative powers of , the larger  is, the faster the series will converge.  
Also, as with the Taylor series expansion, since this is a convergent alternating series, the 
truncation error will be bounded by the first neglected term.  Also, the sign of the error will be 
the same as that of the first neglected term.  As a result, for large values of , the 
-function 
can be upper and lower bounded by
.
(F.9)
These two bounds are shown in Figure F.2.  From the figure as well as from the expressions in 
the previous equation, it is clear that as 
 both bounds are asymptotically tight.  Hence it 
is seen that
.
(F.10)
From the figure, it appears that this approximation is fairly accurate for 
.  If more 
accuracy is desired, more terms can be included in the asymptotic expansion.
x
x
x
Q
1
2x
------------- 1
1
x2
-----
–




x2
2-----
–




exp
Q x
 
1
2x
-------------
x2
2-----
–




exp


x
	

1
1.5
2
2.5
3
3.5
4
100
10−1
10−2
10−3
10−4
10−5
x
Q(x)
1 term 
2 terms 
Q(x) 
Figure F.2
Upper and lower bounds on the Q-function.
Q x
 
1
2x
-------------
x2
2-----
–




exp

x
4


590    Appendix F
www.Academicpress.com
In addition to the Taylor series and asymptotic series expansions, there are also a few 
continued fraction expansions for the Q-function. These are listed below:
, 
for 
,
(F.11)
, 
for 
.
(F.12)
A number of polynomial and rational approximations of the Q-function are available.  Among 
them, the following seems to offer the best accuracy:
,
  
,
(F.13)
where,
, 
, 
, 
, 
, 
.  
Q x
 
1
2
----------
x2
2-----
–




1
x
1
x
2
x
3
x
4
x

+
---------------
+
------------------------
+
---------------------------------
+
------------------------------------------
+
----------------------------------------------------


























exp
=
x
0

Q x
 
1
2---
1
2
----------
x2
2-----
–




x
1
x2
3
2x2
5
3x2
7
4x2
9

–
---------------
+
------------------------
–
---------------------------------
+
-------------------------------------------
–
----------------------------------------------------






























exp
–
=
x
0

Q x
 
1
2
----------
x2
2-----
–



 b1t
b2t2
b3t3
b4t4
b5t5
+
+
+
+


exp
=
t
1
1
px
+
---------------
=
p
0.2316419
=
b1
0.319381530
=
b2
0.35656378
–
=
b3
1.7814779
=
b4
1.821256
–
=
b5
1.3302744
=

Numerical Methods for Evaluating the Q-Function    591
www.Academicpress.com
The error in this approximation is less than 
 for all 
.
Finally, we note that any desired accuracy can be obtained by computing the Q-function via 
numerical integration.  Using the definition directly, the Q-function has an infinite limit which 
is inconvenient for performing numerical integration.  For small to moderate values of , this 
problem can be circumvented by rewriting the Q-function as
.
(F.14)
For large values of  it may be more efficient to work with the standard definition and 
truncate the upper limit to form the approximation
,
(F.15)
where the constant  is chosen to insure the desired accuracy.  For 
 and 
 the 
relative error in this approximation can be shown to be bounded by
.
(F.16)
For example, choosing 
 will guarantee a relative accuracy of less than 
 (i.e., four 
digits of accuracy).  Finally, we note an alternative form of the Q-function which has finite 
limits,
.
(F.17)
Since the integrand is fairly well behaved and the limits of integration are finite, numerical 
integration on this form is particularly convenient and can be performed to any desired 
accuracy.
7.5
8
–
10
0
x
	


x
Q x
 
1
2---
1
2
----------
t2
2----
–




exp
td
0
x

–
=
x
Q x
 
1
2
----------
t2
2----
–




exp
td
x
x
c
+


c
c
2

x
1.5

 x
 
Q x
 
------------
Q x
c
+


Q x
 
---------------------
c2
2-----
3
+




–




exp

=
c
3.5
=
10 4
–
Q x
 
1
---
x2
2sin2
----------------
–



 
d
exp
0
 2

=

593
Index
A
a posteriori probability, 28, 28n2
auditorium seat probability, 29
in optical communication 
system, 39–40
in statistical independence, 30
a priori probability, 28, 28n1
auditorium seat probability, 29
in optical communication system, 
40
for radar system, 318
in statistical independence, 30
Absorbing state, 385–386, 386f
Absorption probability, 407–409
Accessible state, 395
AM. See Amplitude modulation
Amplitude, of stochastic signals, 7
Amplitude modulation (AM), 
500–503
MATLAB for, 503–504, 504f
Analog communication system, 
500–504, 500f, 501f, 504f
Aperiodic Markov chain, 396
AR. See Autoregressive process
Arcsine distribution, 124
Arcsine random variable, 565–566
ARMA. See Autoregressive moving 
average process
Arrival, 360
Arrival state, 403, 416
Atomic outcomes, 13–14
of coin flipping, 14
of dice rolling, 15
of die rolling, 14
exercises for, 46–47
MATLAB rand command and, 
15
probability, 14
Auditorium seat probability, 
Bayes's theorem and, 29
Autocorrelation function, 344–345
of AR process, 450
autocovariance function and, 347
average normalized power, 356
for complex envelope, 499–500
of continuous time processes, 
344–345
of discrete-time processes, 
344–347
ergodic in, 351
estimation of, 352–354, 353f
influence of, 354–355
sinusoidal random processes, 
352
estimation of, 441–445, 442f, 
444f, 445f
random telegraph process, 
442–444, 442f, 444f
windowing function for, 443
exercises for, 375
Fourier transform pair of PSD 
and, 433
of Gaussian random processes, 
358–359
of LTI system, 473–475
of PAM, 456–457
of Poisson processes, 363
properties of, 356–357
for PSD spectral estimation, 
correlation method, 
441–445, 442f, 444f, 445f
of shot noise processes, 
366–367
of signal-to-noise ratios, 
480–481
for sinusoidal random processes, 
346
for thermal noise, 454
wide sense stationary and, 
349–351, 356–357
Autocovariance function, 347
of Poisson processes, 363
of shot noise processes, 
366–367
Autoregressive moving average 
process (ARMA), for PSD 
estimation, 449
Autoregressive process (AR)
autocorrelation function of, 450
for PSD estimation, 449–450
random telegraph process, 
451–452, 452f
Available power, 453
Average. See Expected values
Average information, 156
Average normalized power, 356
Average power, in random process, 
431
Axioms of probability, 10–13, 13f
exercises for, 44–45
B
Backward Kolmogorov equations, 
403
Bandlimited random processes, 
494–498, 495f, 496f, 497f, 
498f
Bandpass filters (BPFs), noise 
equivalent bandwidth of, 
480
Bandpass process, 439
bandwidth of, 439, 439f, 
440f
Bandpass random process, 494
PSD of, 494–495, 495f
Bandwidth
of random processes, 439–441, 
439f, 440f
exercises for, 465–466
of random telegraph process, 441
Note: Page numbers followed by f indicate figures, t indicate tables and n indicate notes.

594    Index
www.Academicpress.com
Bayes's theorem, 27–29, 28f
a posteriori probability, 28, 28n2
a priori probability, 28, 28n1
auditorium seat probability, 29
conditional, 90
for estimation and detection 
problems, 266–267
exercises for, 52–54
in optical communication system, 
39–40
theorem of total probability, 
27–28, 28f
Bernoulli, 8
Bernoulli random variable, 35, 574
CDF of, 310, 310f
mean of, 297
PMF of, 310
random telegraph signal, 340–341
Bernoulli trial
binomial random variable and, 36
Cartesian space for, 35
exercises for, 56
Bernoulli trials, 35
Bessel function, 565
Rician random variables and, 83
Best linear unbiased estimator 
(BLUE), 291
for mean IID random variables, 
291–292
Beta function, 565
Beta random variable, 566
Bilinear transformation, 530
Binary data, in optical 
communication system, 
38–41, 38f
Binary entropy function, 156, 157f
Binary pseudorandom number 
generators, 517–521, 500f, 
519f, 520t, 521f
Binary symmetric channel (BSC), 
224, 224f
Binomial coefficient, 23–24. See 
also Combinations
binomial random variable and, 36
exercises for, 48–49
MATLAB exercise for, 62
Binomial random variable, 35–37, 
574
central moments of, 118
in failure probability, 314
moments of, 116
PMF of, 36
Poisson random variable for, 37
probability-generating functions 
of, 137–138
Binomial random variables, 
characteristic function of, 
132
Birth processes, 360–361
Birth–death processes, 401–411
MATLAB exercise for, 
406–407, 406f, 412–413, 
412f
M/M/ queue, 405
M/M/1 queue, 405–407, 406f
population modeling with, 
407–409
telephone exchange described by, 
416–417, 417f
BLUE. See Best linear unbiased 
estimator
Bounds, on tail probabilities, 
140–147, 143f, 147f
Box-Muller transformation, 218, 524
BPFs. See Bandpass filters
Branching process, 388
Bridge, partitioning in, 25–26
BSC. See Binary symmetric 
channel
C
Cartesian coordinates
transformation into polar 
coordinates, 216–217
transformation into spherical 
coordinates, 262–263, 263f
Cartesian space, for Bernoulli trial, 
35
Cauchy distribution, 213
Cauchy random variables, 84, 566
CDF. See Cumulative distribution 
function
Central limit theorem, 306–310
exercises for, 329
Gaussian distribution and, 
308–310
proof of, 307–308
Central moments
of random variables, exercises 
for, 162–163
of single random variables, 
117–121
MATLAB exercise for, 
120–121
Channel capacity, 221–225, 223f, 
224f, 225f
exercises for, 239–240
Channel coding, 221–225, 223f, 
224f, 225f
exercises for, 239–240
Channel coding theorem, 225
Chapman–Kolmogorov equation, 
389, 409–410
continuous time version of, 402
Characteristic functions
of chi-squared random variables, 
259
joint, for pairs of random 
variables, 206–209, 
235–236
of Laplace random variables, 260
in quadratic transformations of 
Gaussian random vectors, 
258–260
of single random variables, 
130–136
exercises for, 167–168
moments and, 133–135
natural logarithm of, 
135–136
PDFs and, 130–131
transformations of pairs of 
random variables using, 
211–212, 214
Chebyshev's inequality, 142
in law of large numbers, 304
Chernoff bound, 142–144, 143f
Chi-squared (2) random variables, 
81–82, 567
characteristic function of, 259
Circular Gaussian density function, 
220
Classical approach
of assigning probabilities, 14
exercises for, 46–47
relative frequency approach to, 
16
unsatisfactory results with, 
15–16
for joint probability, 18
Coded digital communication 
system, simulation of, 
539–541, 539f, 541f

Index    595
www.Academicpress.com
Coefficient of kurtosis, 119–120
for Gaussian random variables, 
135
Coefficient of skewness, 119–120
for Gaussian random variables, 
135
Coin flipping
MATLAB simulation of, 15
PMF for, 33
probability assignment for, 14
random process of, 336–338, 
336f, 338f
sample space and outcomes of, 
8–9
Column vector, 551
Combinations, 23–24, 26t
English v. mathematical usage 
of, 24
in lottery game, 24
Combinatorics, 20–26, 26t
combinations, 23–24
exercises for, 48–52
k-permutations, 23
partitions, 24–26
permutations, 22
principle of counting, 21
Combined experiment, 21–22, 26t
Communicating states, 395
Communication system, 4–5, 5f. 
See also Digital modulation 
formats
analog, 500–504, 500f, 501f, 504f
Erlang random variable in, 82
matched filter for SNR for, 
484–485, 485f
optical, 38–41, 38f, 42f
Rayleigh random variables in, 82
Rician distribution in, 84
simulation of coded digital, 
539–541, 539f, 541f
sinusoid in, 79
statistical independence and, 32
Complement, 545, 546f
Complementary error function 
integral, for CDF of Gaussian 
random variable, 74
Complex envelopes
exercises for, 514
for I and Q components, 499–500
Complex numbers, Rayleigh 
distribution and, 82
Complex random variables, 
219–221
exercises for, 238–239
Computer communication network, 
Markov processes 
describing, 413–415, 415f
Computer generation
of random processes, 525–534
exercises for, 544
frequency domain approach to, 
525–528, 526f, 528f
of Gaussian white noise, 
533–534, 534f
time domain approach, 
529–532, 529f, 531f, 533f
of random variables, 517–524
binary pseudorandom number 
generators, 517–521, 518f, 
519f, 520t, 521f
correlated, 524
exercises for, 543–544
nonbinary pseudorandom 
number generators, 521–522
from specified distribution, 
521–522
Conditional cumulative distribution 
function, 86–87
exercises for, 104–106
for pairs of random variables, 
188–191
exercises for, 231
Conditional entropy, 221–222
Conditional expected values
exercises for, 163–164
of functions of single random 
variables, 122
of pairs of random variables, 
196–197
of single random variables, 
121–122
Conditional probability, 18–20
deck of playing cards and, 19–20
definition of, 18–19
exercises for, 47–48
independence and, 31
joint probability compared with, 
19
in optical communication system, 
40–41
Conditional probability density 
function, 87–89, 88f
exercises for, 104–106
for multiple random variables, 
245–247
exercises for, 277–278
for pairs of random variables, 
188–191
exercises for, 231
properties of, 87–88
transformations of pairs of 
random variables using, 
213–214
Conditional probability mass 
functions
for multiple random variables, 
245–247
exercises for, 277–278
for pairs of random variables, 
188–191
exercises for, 231
Confidence intervals, 310–315
constants used to calculate, 311t
exercises for, 330–331
for failure probability, 314
for IID random variables, 312
sample mean and, 312
Student's t-distribution, 313
Confidence level, 311, 311t
Continuous random variables, 
565–574
CDF of, 65–67, 65f, 66f
PDF for, 289
conditional, 90
PDF of, 69
PMF and, 63
staircase transformations of, 128, 
128f
Continuous sample space, 10
events on, 10
mix with discrete, 10
Continuous time and discrete 
amplitude signals, 335
PDF of, 341
random process of, 338–339, 339f
Continuous time linear systems
exercises for, 505–507
random processes in, 473–477
Continuous time Markov processes, 
401–411, 409–413
exercises for, 426–427
MATLAB exercise for, 406–407, 
406f, 412–413, 412f

596    Index
www.Academicpress.com
Continuous time Markov processes
(continued)
M/M/ queue, 405
M/M/1 queue, 405–407, 406f
population modeling with, 
407–409
Continuous time processes
autocorrelation function of, 
344–345
mean function of, 343
strict sense stationary, 
348–349
Continuous time signals, 335, 581
Convergence almost everywhere
exercises for, 326–327
of random sequences, 301, 303t
strong law of large numbers and, 
305
Convergence everywhere
exercises for, 326–327
of random sequences, 300–301, 
303t
Convergence in distribution
of central limit theorem, 308
exercises for, 326–327
of random sequences, 
302–303, 303t
Convergence in mean square sense
exercises for, 326–327
of random sequences, 302, 303t
Convergence in probability
exercises for, 326–327
of random sequences, 
301–302, 303t
weak law of large numbers and, 
305
Convergence modes
law of large numbers and, 
304–305
of random sequences, 
298–303, 303t convergence 
almost everywhere, 301, 
303t convergence 
everywhere, 300–301, 303t
convergence in distribution, 
302–303, 303t
convergence in mean square 
sense, 302, 303t
convergence in probability, 
301–302, 303t
exercises for, 326–327
Convolution, transformations of 
pairs of random variables 
using, 211
Convolution function, MATLAB, 
352–354, 353f
Coordinate systems
three-dimensional 
transformations of, 
262–263, 263f
transformation of pairs of random 
variables for changes of, 
214–217
Corollary of probability, 11–12
Correlation
of complex random variables, 
221
independence and, 195, 198–199
for Gaussian random variables 
in multiple dimensions, 251
for jointly Gaussian random 
variables, 205–206, 206f
of pairs of random variables, 
193–195
Correlation coefficient
independence and, 198
for jointly Gaussian random 
variables, 206
of pairs of random variables, 
194–195
Correlation matrix
for IID random variables, 
291–292
of multiple random variables, 
247–249
Correlation method, for PSD 
spectral estimation, 
441–445, 442f, 444f, 445f
Counting processes, 362. See also 
Poisson counting processes
PMF of, 361–362
properties of, 360–361
Covariance
of complex random variables, 
221
independence and, 198
of pairs of random variables, 
193–195
Covariance function, of random 
walk, 360
Covariance matrix, of multiple 
random variables, 247–249
Cross spectral density
of I and Q components, 497–498
between random processes, 
438–439
Cross-correlation function, 
347–348
Fourier transform of, 438–439
of LTI system, 475–476
Cross-covariance function, 348
Cumulants, 135–136
Cumulative distribution function 
(CDF), 64–68, 65f, 66f
of Bernoulli random variable, 
310, 310f
of Cauchy random variables, 84
of chi-squared (2) random 
variables, 81–82
conditional, 86–87
exercises for, 104–106
for pairs of random variables, 
188–191, 231
of continuous random variables, 
65–67, 65f, 66f
PDF for, 289
of discrete random variables, 68
PMF for, 289
of Erlang random variable, 81–82
estimating of IID random 
variables, 297–298
exercises for, 97–99
of exponential random variables, 
79–80, 79f
of gamma random variables, 81
of Gaussian random variable, 69, 
73–76, 75f
evaluation of, 75
in Q-function terms, 75–76
standard forms of, 74
transformation of, 74–75
joint
exercises for, 227–228
for multiple random variables, 
245–247, 277–278
for pairs of random variables, 
178–180, 179f
of Laplace random variables, 
80, 80f
PDF compared with, 69–71, 69f
PMF and, 68
properties of, 64
of random processes, 340, 342

Index    597
www.Academicpress.com
Cumulative distribution function 
(CDF) (continued)
of random variables, 65–66, 65f, 
66f
conditional, 86–87
reliability function, 91
of Rayleigh random variables, 
82, 83f
of Rician random variables, 
83–84, 84f
of standard normal random 
variables, 74
transformations of pairs of 
random variables using, 
210, 212–214
unconditional, 89–90
of uniform random variables, 
78–79, 78f
Customer arrivals, exponential 
random variables in, 80
D
Dark current, 41
De Morgan's laws, 549
Deck of playing cards
conditional probability and, 19–20
joint probability and, 18–20
Definite integrals, 580
Departure state, 403, 416
Detection, 264
exercises for, 283–284
MAP detection, 265–267
Detection probability
for radar system, 318–323
sequential detection and, 320
thresholds for, 319–320
Determinant of matrix, 554–555
Deterministic signal, 7
continuous, Fourier transform 
for, 429
noise compared with, 7
Diagonal matrix, 552
Dice rolling
MATLAB exercise for, 62
probability assignment of, 15
relative frequency approach for, 
16–17, 16t
sample space and outcomes of, 9
statistical independence and, 30–31
Die rolling
probability assignment of, 14
sample space and outcomes of, 9
Difference set, 545–546, 546f
Differential pulse code modulation 
(DPCM), 272–275, 273f, 
274f, 275f, 276f
Diffusion modeling, 411–413, 412f
Digital communication systems, 
mutual information of, 
222–225, 223f, 224f, 225f
Digital modulation formats, PSDs 
of, 455–461, 458f, 459f, 
460f, 461f
Discrete Fourier transform, for 
discrete-time processes, 429
Discrete random variables, 32–38, 
34f, 574–575
Bernoulli, 35
binomial, 35–37
CDF of, 68
PMF for, 289
central moments of, 117
characteristic function of, 
131–132
for coin flipping, 33
conditional expected values of, 
122
conditional PMF for, 188
exercises for, 55–59
expected value of, 112
expected value of functions of, 
113
expected values for, 192
geometric, 37–38
joint PMFs for, 186–188
joint probability-generating 
function for, 208–209
moments of, 115–116
PMF of, 33
Poisson, 37
probability-generating functions 
of, 136–138
staircase transformations of 
continuous random 
variables into, 128, 128f
Discrete time and continuous 
amplitude signals, 335
random process of, 339–340, 340f
Discrete time and discrete 
amplitude signals, 335
Discrete-time Fourier transform 
(DTFT), 560–561
for discrete-time linear systems, 
477–478
Discrete-time linear systems
exercises for, 477–479, 508–509
Gaussian white noise in, 
478–479
random processes in, 477–479
Discrete-time processes
autocorrelation function of, 
344–347
autocovariance function of, 347
discrete Fourier transform for, 
429
mean function of, 343
Discrete-valued Markov processes. 
See Markov chains
Disjoint, 546
Distortion, signal quantization 
causing, 148–153, 149f, 
152f
Distribution
arcsine, 124
Cauchy, 213
Laplace, quantization of, 
151–154, 152f
random sequence convergence 
in, 302–303, 303t
Distribution of infinitesimal 
increments, of Poisson 
processes, 361
Domain, of functions, 32
DPCM. See Differential pulse code 
modulation
Drift, of Markov chain, 414–415, 
415f
DTFT. See Discrete-time Fourier 
transform
E
Efficient estimator, 290
Eigenvalue, 555–557
Eigenvector, 555–557
Empty set, 545, 546f
Energy, of random process, 430
Ensemble averaged power, 430
Ensemble of functions, 336
Entropy
conditional, 221–222
of single random variables, 
155–158, 157f, 158t
exercises for, 173

598    Index
www.Academicpress.com
Envelope detector, for AM, 
501–502
Ergodic in autocorrelation, 
sinusoidal random 
processes, 351
Ergodic in mean, 351
Ergodicity
autocorrelation function
and estimation of, 352–354, 
353f
influence of, 354–355
of random processes, 351–356
of sinusoidal random processes, 
352
strict sense stationary and, 
351–352
two limited forms of, 351
of WSS, 351–356
Erlang random variable, 81–82, 
567–568
moment-generating functions of, 
140
Erlang-B formula, 416, 417f
Error function integral, for CDF 
of Gaussian random 
variable, 74
Errors, in optical communication 
system, 40–41, 42f
Estimation, 264
exercises for, 283–284
MAP, 265–267
ML, 267–268
MMSE, 268–272
Events, 7–10
of CDF, 64
on continuous space, 10
definition of, 8
exercises for, 43–44
intersection of, 17
probability as function of, 11
of random number generator, 10
Exam permutations, 22
Expected values. See also Mean
conditional
exercises for, 163–164
of functions of single random 
variables, 122
of pairs of random variables, 
196–197
of single random variables, 
121–122
of functions of random variables, 
113–114, 115t
exercises for, 160–161
of multiple random variables, 
247–249
exercises for, 279–280
for pairs of random variables, 
192–197
conditional expected values, 
196–197
correlation, 193–195
covariance, 193–195
exercises for, 231–233
(m, n)th joint moment, 195–196
of single random variables, 
111–113
exercises for, 159–160
Experiments, 7–10
combined, 21–22, 26t
definition of, 8
exercises for, 43–44
function domains of, 32
sample spaces for, 10
Exponential random variables, 
79–80, 79f, 568
central moments of, 119
characteristic function of, 131, 
133–134
expected value of, 112
failure rate and, 93
gamma random variable and, 81
memoryless property of, 93
transformation of, 124, 129
Extinction probability, 407–409
F
F random variable, 568–569
Factorial function, gamma function 
and, 81
Factorial moments, 137–138
joint, 208
Fading
Rayleigh random variables in, 82
Rician distribution in, 84
Failure probability, MATLAB 
example for, 314–315, 314f
Failure rates, 91–95
changes in, 92
Failure rate function, 92
exponential distribution of, 93
of Rayleigh distribution, 93
reliability function and, 92
of system
parallel interconnection, 94–95
series interconnection, 93–95
False alarm probability
for radar system, 318–323
sequential detection and, 320
thresholds for, 319–320
Filtering problems, 264
First central moment, 118
First moment, 115–117. See also 
Expected values; Mean
First return probability, 396–397
Fokker–Planck equation, 411
Forward Kolmogorov equations, 403
Fourier Series, 559–560
Fourier Transform. See also 
Discrete Fourier transform
of cross-correlation function, 
438–439
for deterministic continuous 
signal, 429
for PAM, 457
in PSD, 430
review of, 560–561
Fourier Transform pairs, 560, 
581–582t
autocorrelation function and PSD 
as, 433
Fourth central moment, 118
Frequency domain techniques, 7
for computer generation of 
random processes, 
525–528, 526f, 528f
MATLAB example for, 
527–528, 528f
for random processes, 429
Frequency shift keying modem, 
337–338, 338f
Function(s). See also specific 
functions
ensemble of, 336
moment-generating
of single random variables, 
139–140, 169–170
tail probability evaluations 
using, 142–147, 143f, 147f
of outcomes, 32
probability-generating, of single 
random variables, 136–138, 
168–169

Index    599
www.Academicpress.com
Function(s) (continued)
of random sum of Gaussian 
random variables, 317
of random sum of IID random 
variables, 316
of random variables
conditional expected value of, 
122
exercises for, 160–161
expected value of, 
113–114, 115t
transformations with
monotonically decreasing 
functions, 123f, 124–125
monotonically increasing 
functions, 122–124, 123f
nonmonotonic functions, 
125–129, 125f, 128f, 130f
staircase functions, 128, 128f
Fundamental frequency, 559
G
Galileo, 7
Gambler's ruin problem, 386, 386f, 
392
Gambling, probability and, 7–8
Gamma distribution, random 
telegraph signal, 341
Gamma function, 81, 565
exercise for, 104
Gamma random variables, 81, 127, 
569
Gaussian distribution
central limit theorem and, 
308–310
zero-mean, 82
Gaussian random processes, 342, 
357–360, 359f
autocorrelation function of, 
346–347
definition of, 357
exercises for, 375–376
PDF of, 357–359
random walk, 359–360, 359f
simulation of, 525–527, 526f
MATLAB example for, 
527–528, 528f
Gaussian random variables, 71–78, 
73f, 75f, 569. See also 
Jointly Gaussian random 
variables
Box-Muller transformation for 
generation of, 218
CDF of, 69, 73–76, 75f
evaluation of, 75
in Q-function terms, 75–76
standard forms of, 74
transformation of, 74–75
characteristic function of, 132, 
135
continuous time and discrete 
amplitude signals as, 341
exercises for, 101–103
generation of, 523–524
correlated, 524
likelihood ratio test for, 319–321
linear transformations of, 
253–257
MATLAB exercise for, 109
in multiple dimensions, 
249–251
exercises for, 280–281
MATLAB exercise for, 
251–252
pairs of, conditional PMF, PDF, 
and CDF for, 
190–191
PDF of, 72–73, 73f
for radar system, 317–318
random sum of, 317
shorthand notation for, 73
transformation of, 124, 127
transformations of pairs of, 
212–213, 216–219
Gaussian random vectors, quadratic 
transformations of, 257–260
Gaussian white noise
computer generation of, 
533–534, 534f
in discrete-time linear systems, 
478–479
in LTI system, 476
Gaussian-Multivariate random 
variables, 570
Genetic models, Markov chains in, 
388
Geometric random variable, 37–38, 
129, 574–575
PMF of, 37
probability-generating functions 
of, 138
Global balance equations, 403
H
Half-power bandwidth, 440, 440f
Harmonic frequency, 559
Heavy-tailed distribution, Cauchy 
PDF as, 84
Hermitian symmetry, 439, 551, 557
Histogram, for MATLAB random 
number generation, 71, 72f
Homogenous Markov process, 402
I
I components
complex envelopes for, 499–500
cross spectral density of, 
497–498
extraction of, 496, 496f
PSD of, 496–497, 497f
Identity matrix, 552
IID random variables. See 
Independent and identically 
distributed random variables
Importance sampling, 537–538
for simulation of coded digital 
communication system, 
539–541, 539f, 541f
Impulse invariance transformation, 
530
Indefinite integrals, 578–580
Independence, 29–32
communication network and, 32
correlation and, 195, 198–199
for Gaussian random variables 
in multiple dimensions, 251
for jointly Gaussian random 
variables, 205–206, 206f
dice rolling and, 30–31
exercises for, 54–55
mutual exclusiveness compared 
with, 31
of random variables, 197–199
exercises for, 233–234
MATLAB exercise for, 
200–201, 201f
of set of N random variables, 247
test for, 30
Independent and identically 
distributed (IID) random 
variables, 289–298
in central limit theorem, 306–308
confidence intervals for, 312
estimating CDF of, 297–298

600    Index
www.Academicpress.com
Independent and identically 
distributed (IID) random 
variables (continued)
estimating mean of, 290–295
BLUE for, 291–292
confidence intervals for, 
310–315, 311t
ML for, 292–294
estimating variance of, 295–297
exercises for, 325–326
likelihood ratio test for, 319
PAM with, 457–459, 458f, 459f
PDF of, 289
random sum of, 315–317
function of, 316
mean and variance of, 315–316
sample mean of, 299
Independent increments, of Poisson 
processes, 361
Information
mutual, 221–225, 223f, 224f, 225f
exercises for, 239–240
quantitative definition of, 
155–158, 157f, 158t
Integrals
definite, 580
indefinite, 578–580
Interference, accounting for, 7
Interpolation problems, 264
Intersection, 545, 546f
Interval. See also Confidence 
intervals
CDF and random variable in, 
64, 69
of exponential random variables, 
79, 79f
of uniform random variables, 
78–79, 78f
Inverse of matrix, 553–554
Inverse transform, for deterministic 
continuous signal, 429
Irreducible Markov chain, 395
J
Joint CDFs
for multiple random variables, 
245–247
exercises for, 277–278
for pairs of random variables, 
178–180, 179f
exercises for, 227–228
Joint characteristic functions, for 
pairs of random variables, 
206–209
exercises for, 235–236
Joint factorial moments, 208
Joint moments, 192–197, 208–209
Joint moment-generating functions, 
209
Joint PDFs
exercises for, 228–229
for Gaussian random variables in 
multiple dimensions, 
250–252
for multiple random variables, 
245–247
exercises for, 277–278
for pairs of random variables, 
180–185, 184f
MATLAB exercise for, 
185–186
Joint PMFs
for multiple random variables, 
245–247
exercises for, 277–278
for pairs of random variables, 
186–188
exercises for, 229–230
Joint probability, 17–20
computation of, 17–18
conditional probability compared 
with, 19
deck of playing cards and, 18–20
exercises for, 47–48
independence and, 31
of three events, 19
Joint probability-generating 
functions, 208–209
Jointly Gaussian random variables, 
202–206, 203–204f, 205f, 
206f
exercises for, 234
joint characteristic functions for, 
207–208
linear transformation of, 
218–219, 254
MAP estimator for, 265
p-n Junction diode
operation of, 365
shot noise processes in, 365–370
with current pulse shape, 
369–370, 370f
exercises for, 378–380
with square wave, 
368–369, 368f, 369f
K
k-permutations, 23, 26t
of padlock combinations, 23
Kurtosis, 118. See also Coefficient 
of kurtosis
L
Lagrange multiplier techniques, for 
IID random variables, 291
Laplace, 7
Laplace distribution, signals with, 
151–153, 152f
Laplace random variables, 80, 80f, 
570
central moments of, 120
characteristic function of, 260
exercise for, 104
Laplace transforms,  584t
Law of large numbers, 304–306
exercises for, 327–328
strong, 304–305
weak, 304–305
Level of significance, 311, 311t
LFSR. See Linear feedback shift 
register
License plates, principle of 
counting and, 22
Likelihood ratio test
for IID Gaussian random 
variables, 319–321
for radar system, 318, 321–322
Linear algebra, 551–557
Linear estimator, 290–292
Linear feedback shift register (LFSR), 
for binary pseudorandom 
number generators, 518–521, 
518f, 519f, 520t
Linear minimum mean square error 
(LMMSE) estimator, 
270–272
Linear prediction
of PSD, 451
of speech, 272–275, 273f, 274f, 
275f, 276f

Index    601
www.Academicpress.com
Linear systems, random processes 
in, 473–504
analog communication system, 
500–504, 500f, 501f, 504f
bandlimited and narrowband, 
494–498, 495f, 496f, 497f, 
498f
complex envelopes, 499–500
exercises for, 514
continuous time, 473–477
exercises for, 505–507
discrete-time, 477–479
exercises for, 508–509
matched filter, 482–486, 482f, 
485f, 486f
exercises for, 482–486, 482f, 
485f, 486f, 511–512
MATLAB exercises for, 
514–515
noise equivalent bandwidth, 
479–480, 479f, 509–510
exercises for, 509–510
signal-to-noise ratios, 480–482
exercises for, 480–482, 
510–511
Wiener filter, 486–494, 490f, 
491f, 494f
exercises for, 486–494, 490f, 
491f, 494f, 512–513
Linear time-invariant (LTI) system
autocorrelation function of, 
473–475
cross-correlation function of, 
475–476
mean function of, 473–475
passage of signals through, 
561–563
random processes in, 473–477
white Gaussian noise in, 476
white noise conversion, 
476–477, 477f
Linear transformations
of Gaussian random variables, 
253–257
of jointly Gaussian random 
variables, 218–219, 254
of multiple random variables, 
253–257
of pairs of random variables, 
218–219
of vector random variable, 
248–249
LMMSE estimator. See Linear 
minimum mean square error 
estimator
Log-likelihood ratio test, for radar 
system, 321–322
Log-normal random variables, 
570–571
Lottery game, combinations in, 24
Lower triangular, 552
Lowpass filter (LPF)
Gaussian white noise in, 476
noise equivalent bandwidth of, 
479–480, 479f
SNR and, 481–482
white noise conversion in, 
476–477, 477f
Lowpass process, 439
bandwidth of, 439, 439f, 440f
Lowpass random process, 494
PSD of, 494–495, 495f
LPF. See Lowpass filter
LTI system. See Linear time-
invariant system
M
(m, n)th joint moment of two 
random variables, 195–196
MA. See Moving average process
MAP. See Maximum a posteriori
marcumq, MATLAB, 110
Marcum's Q-function, 83–84, 84f, 
565
Marginal CDFs, 178, 180, 246
Marginal PDFs, 182–183, 246
Marginal PMFs, 187–188, 246
Markov chains, 384
characterization of, 394–401
exercises for, 424–426
computer communication 
network described by, 
413–415, 415f
definitions and examples of, 
384–385, 385f, 390–391
gambler's ruin problem, 386, 
386f, 392
genetic models, 388
queuing system, 387, 393–394, 
394f
random walks, 387, 396, 399–401
transition and state probability 
calculations in, 388–393
Markov processes, 383
computer communication 
network described by, 
413–415, 415f
continuous time, 401–411
exercises for, 426–427
MATLAB exercise for, 
406–407, 406f, 
412–413, 412f
M/M/ queue, 405
M/M/1 queue, 405–407, 406f
population modeling with, 
407–409
continuous time and continuous 
amplitude, 409–411
definitions and examples of, 
383–388
branching process, 388
exercises for, 419–421
gambler's ruin problem, 386, 
386f, 392
genetic models, 388
Markov chains, 384–385, 385f, 
390–391
Poisson counting process, 
383–384
queuing system, 387, 393–394, 
394f
random walks, 387, 396, 
399–401
telephone exchange described by, 
416–417, 417f
transition and state probability 
calculations in, 388–393
exercises for, 421–424
MATLAB exercise for, 
393–394, 394f
Markov's inequality, 141
Matched filter
exercises for, 482–486, 482f, 
485f, 486f, 511–512
for SNR, 482–486, 482f, 485f, 
486f
for binary PAM signal, 
485–486, 486f
for communication system, 
484–485, 485f

602    Index
www.Academicpress.com
Mathematical tables, 577–585, 
581–582t, 582–583t, 584t, 
585t
Mathematical tools
random telegraph process, 
340–341
for studying random processes, 
340–348, 342f, 345f
autocorrelation function, 
344–345
autocovariance function, 347
cross-correlation function, 
347–348
cross-covariance function, 348
exercises for, 371–372
MATLAB, 2
for amplitude modulation, 
503–504, 504f
for bilinear approximation of 
random processes, 
530–532, 531f
binomial coefficient exercise 
for, 62
central moment exercise for, 
120–121
continuous time Markov process 
exercise for, 406–407, 406f, 
412–413, 412f
convolution function, 
352–354, 353f
dice rolling exercise for, 62
for ergodicity and autocorrelation 
function estimation, 
352–354, 353f
for estimating CDF of IID 
random variables, 297–298
for failure probability, 314–315, 
314f
for Gaussian random processes 
simulation, 527–528, 528f
for Gaussian random variable, 
109
in multiple dimensions, 
251–252
help, 15
histogram of randn, 76–78, 77f
independent random variable 
exercise for, 200–201, 201f
joint PDF exercise for, 
185–186
marcumq function, 110
Markov chain transition and state 
probability calculation 
exercise for, 393–394, 394f
Markov process exercises for, 
427–428
mean function of sinusoidal 
random processes, 344, 345f
multiple random variables 
exercises for, 287–288
multiple random variables 
transformation exercise for, 
256–257
pairs of random variables 
exercises for, 242–243
for periodogram estimate of PSD 
in random telegraph 
process, 447–448, 448f
for PMF, 34, 34f
PSD exercises, 469–471
of PAM, 460–461, 461f
for Q-function, 110
random generation, 15
exercises for, 61–62
histogram construction for, 
71, 72f
random process exercises, 
381–382
of continuous time and discrete 
amplitude signals, 338–339, 
339f
of discrete time and continuous 
amplitude signals, 339–340, 
340f
in linear systems, 514–515
relative frequency approach 
simulation, 16–17, 16t
for Rician random variable, 110
for sample mean convergence, 
305–306, 305f
scalar quantization exercise for, 
153–154, 154f
of shot noise processes, 369–370, 
370f
simulation technique exercises, 
546
sine of uniform random 
variables, 85, 85f
single random variable operation 
exercises for, 174–175
single random variable 
transformation exercise for, 
129, 130f
for uniform random variables, 
109
for variance of IID random 
variable estimation, 296–297
Matrices, 551–557
Maximal length linear feedback 
shift register (MLLFSR), 
520–521, 521f
Maximum a posteriori (MAP), 39
in estimation and detection 
problems, 265–267
Maximum likelihood (ML)
for estimation problems, 
267–268
for mean of IID random variable 
estimation, 292–294
for variance of IID random 
variable estimation, 
295–296
Mean
of Bernoulli random variable, 
297
of complex random variables, 
220
conditional
exercises for, 163–164
of functions of single random 
variables, 122
of single random variables, 
121–122
ergodic in, 351
estimating of IID random 
variables, 290–295
BLUE for, 291–292
confidence intervals for, 
310–315, 311t
ML for, 292–294
of failure probability, 314
of functions of random variables, 
113–114, 115t
exercises for, 160–161
of Gaussian random variables, 
72–73, 72n1, 73f, 317–318
in law of large numbers, 304
of multiple random variables, 
247–249
order statistics and, 261–262

Index    603
www.Academicpress.com
Mean (continued)
for pairs of random variables, 
192–197
probability-generating functions 
and, 137–138
of random processes, 343
of random sum of Gaussian 
random variables, 317
of random sum of IID random 
variables, 315–316
of random variables, estimation 
of, 304
of Rician random variables, 
296–297
sample, 292
of single random variables, 
111–113
characteristic functions and, 
133
exercises for, 159–160
tail probability evaluations using, 
141–142
of WSS random processes, 351
Mean function
autocovariance function and, 347
of Gaussian random processes, 
358–359
of LTI system, 473–475
of random processes, 343
of random telegraph process, 343
of shot noise processes, 365–366
of sinusoidal random processes, 
343–344
MATLAB for, 344, 345f
wide sense stationary and, 
349–351
Mean square error
for IID random variables, 291
for PSD estimation, 451
Wiener filter to minimize, 487–489
Mean square (MS) sense, random 
sequence convergence in, 
302, 303f
Mean time to first return, 400–401
Mean vector, for IID random 
variables, 291
Median, order statistics and, 
261–262
Memoryless property, of 
exponential random 
variables, 93
Minimum mean square error 
(MMSE), for estimation 
problems, 268–272
Mixed random variables, 67
transformation of, 127
MLLFSR. See Maximal length 
linear feedback shift register
M/M/ queue, 405
M/M/1 queue, 405–407, 404f
MMSE. See Minimum mean square 
error
Modulation efficiency, 503
Moment-generating functions
joint, 209
of single random variables, 
139–140
exercises for, 169–170
tail probability evaluations using, 
142–147, 143f, 147f
Moments. See also Central 
moments
joint, 192–197, 208–209
of single random variables, 
115–117
characteristic functions and, 
133–135
exercises for, 161
probability-generating 
functions and, 
136–138
Monotonically decreasing function 
transformations, 123f, 
124–125
Monotonically increasing function 
transformations, 122–124, 
123f
Monte Carlo simulations, 535–537
for simulation of coded digital 
communication system, 
539–541, 539f, 541f
Monty Hall problem, 61–62
Moving average process (MA), for 
PSD estimation, 449
m-sequences. See Maximal length 
linear feedback shift register
Multinomial coefficient, 25. See 
also Partitions
exercises for, 48
Multiple random variables, 245
conditional PMF and PDF for, 
245–247
exercises for, 277–278
in estimation and detection 
problems, 264
exercises for, 283–284
MAP estimation, 265–267
ML estimation, 267–268
MMSE estimation, 
268–272
expected values of, 247–249
exercises for, 279–280
Gaussian, 249–251
exercises for, 280–281
MATLAB exercise for, 
251–252
independence of, 247
joint PMF, CDF, and PDF for, 
245–247
exercises for, 277–278
in linear prediction of speech, 
272–275, 273f, 274f, 275f, 
276f
transformations involving, 
252–253
coordinate systems in three 
dimensions, 262–263, 263f
exercises for, 281–283
linear, 253–257
MATLAB exercise for, 
256–257
order statistics, 260–262
quadratic, 257–260
Mutual exclusiveness, 31
independence compared with, 31
of PMF of binomial random 
variable, 36
Mutual information
exercises for, 239–240
of pairs of random variables, 
221–225, 223f, 224f, 225f
Mutually exclusive, 546
N
Nakagami random variable, 571
Narrowband random processes, 
494–498, 495f, 496f, 497f, 
498f
exercises for, 514
n-bit quantizer, 149–153, 149f, 152f
Negative binomial random variable. 
See Pascal random variable
Negative definite, 556–557

604    Index
www.Academicpress.com
Noise, 7. See also Gaussian white 
noise; Stochastic signals
accounting for, 7
autocovariance function and, 347
deterministic signal or function 
compared with, 7
Poisson random variable for, 37
sensor voltage and, 289–290
thermal, 452–454
variance of, 290
white, 454
Noise equivalent bandwidth, 
479–480, 479f
exercises for, 509–510
Nonbinary pseudorandom number 
generators, 521–522
Noncoherent systems
Rayleigh random variables in, 82
Rician distribution in, 84
Nonmonotonic function 
transformations, 125–129, 
125f, 128f, 130f
Non-singular matrix, 553–554
Non-stationary
Wiener–Khintchine–Einstein 
theorem for, 435
WSS and, 349
Normal equations, 488
Normal random variables, 73
n-step transition probability, 
389–391, 396–397
nth central moment, 117
nth moment, of single random 
variables, 115
nth order PDF, of random 
processes, 342
Null recurrent, 400–401
Numerical routines, for CDF of 
Gaussian random variable, 74
Nyquist's theorem, thermal noise 
and, 453
O
Optical communication system, 
38–41, 38f, 42f
Bayes's theorem for, 39–40
conditional probability for, 
40–41
overview of, 38–39, 38f
PMFs of, 39
probability of error for, 41, 42f
Order statistics, 260–262
Orthogonal variables, 193
complex, 221
Orthogonal vectors, 552
Orthogonality principle, 270, 488
Outcomes. See also Atomic 
outcomes
of coin flipping, 8
definition of, 8
of dice rolling, 9
of die rolling, 9
exercises for, 43–44
functions of, 32
of random number generator, 10
total number of possible, 21–22
P
Padlock combinations, k-
permutations of, 23
Pairs of random variables, 
177–178
channel capacity and channel 
coding, 221–225, 223f, 224f, 
225f
exercises for, 239–240
complex random variables, 
219–221
exercises for, 238–239
conditional CDFs for, 188–191
exercises for, 231
conditional PDFs for, 188–191
exercises for, 231
conditional PMFs for, 188–191
exercises for, 231
expected values for, 192–197
conditional expected values, 
196–197
correlation, 193–195
covariance, 193–195
exercises for, 231–233
(m, n)th joint moment, 
195–196
independence of, 197–199
exercises for, 233–234
MATLAB exercise for, 
200–201, 201f
joint CDFs for, 178–180, 179f
exercises for, 227–228
joint characteristic functions for, 
206–209
exercises for, 235–236
joint moment-generating 
functions for, 209
joint PDFs for, 180–185, 184f
exercises for, 228–229
MATLAB exercise for, 
185–186
joint PMFs for, 186–188
exercises for, 229–230
joint probability-generating 
functions for, 208–209
jointly Gaussian, 202–206, 
203–204f, 205f, 206f
exercises for, 234
joint characteristic functions 
for, 207–208
linear transformation of, 
218–219, 254
MAP estimator for, 265
mutual information of, 
221–225, 223f, 224f, 225f
exercises for, 239–240
transformations of, 210–219
exercises for, 236–238
PAM. See Pulse amplitude 
modulation
Parallel interconnection, system, 
reliability function and 
failure rate function of, 
94–95
Parametric estimation, of PSD, 
448–452, 452f
Parseval's theorem, in PSD, 430
Partitions, 24–26, 26t
of bridge, 25–26
three groups, 25
two groups, 24–25
Pascal, 8
Pascal random variable, 38, 575. 
See also Geometric random 
variable
PCM. See Pulse code modulation
PDF. See Probability density 
function
Period of states, 396
Periodogram
for PSD spectral estimation, 441, 
445–448, 448f
random telegraph process, 
447–448, 448f
Permutations, 22, 26t
k-permutations, 23

Index    605
www.Academicpress.com
Phase, of stochastic signals, 7
-function
for CDF of Gaussian random 
variable, 74
evaluation of, 75
Q-function relation with, 75, 75f
Photodetector, in optical 
communication system, 
38–39
Photoemissive surface, in optical 
communication system, 39
PMF. See Probability mass function
Points, 360
of Poisson counting processes, 
364
Poisson counting processes, 
360–364, 364f, 383–384
autocorrelation function of, 363
PMF of, 360, 363
points of, 364
Poisson distribution, random 
telegraph signal, 341
Poisson impulse processes, 364, 
364f
Poisson processes
autocovariance function of, 363
exercises for, 376–378
Poisson random variable, 37, 575
exercises for, 56–58
expected value of, 112
in optical communication system, 
39
Polar coordinates, Cartesian 
coordinate transformation 
into, 216–217
Population modeling, with birth–
death processes, 407–409
Positive definite, 556–557
Positive recurrent, 400–401
Power, in random process, 431
Power residue method, 521–522
Power spectral density (PSD), 430
AR process for, 449–450
random telegraph process, 
451–452, 452f
of bandpass random process, 
494–495, 495f
bandwidth of random processes, 
439–441, 439f, 440f
exercises for, 465–466
for complex envelope, 500
cross spectral density, 438–439
definition of, 430–433
exercises for, 463
of digital modulation formats, 
455–461, 458f, 459f, 460f, 
461f
autocorrelation of PAM, 
456–457
Fourier transform for, 457
with IID sequence of random 
variables, 457–459, 458f, 
459f
MATLAB example for, 
460–461, 461f
with memory, 459–460, 460f
Fourier transform in, 430
Fourier transform pair of 
autocorrelation function 
and, 433
of I and Q components, 
496–497, 497f
of lowpass random process, 
494–495, 495f
MATLAB exercises for, 469–471
Parseval's theorem in, 430
properties of, 431
of sinusoidal random processes, 
432
spectral estimation, 441–452
exercises for, 466–468
non-parametric, 441–448, 
442f, 444f, 445f, 448f
parametric, 448–452, 452f
thermal noise, 452–455, 453f, 454f
exercises for, 468–469
Wiener–Khintchine–Einstein 
theorem, 433–439, 434f, 
436f, 437f
exercises for, 463–465
of WSS, 433
Power transfer function, 475
of LPF, 479, 479f
Prediction problems, 264
Principle of counting, 21
Probability. See also Conditional 
probability; Joint probability
a posteriori, 28, 28n2
a priori, 28, 28n1
applications of, 1–5, 3f, 4f, 5f
assignment of, 13–17, 16t
classical approach to, 14
of coin flipping, 14
of dice rolling, 15
of die rolling, 14
exercises for, 46–47
MATLAB rand command and, 
15
relative frequency approach 
for, 16
of atomic outcomes, 14
axioms of, 10–13, 13f
exercises for, 44–45
definition of, 10–11
gambling and, 7–8
random sequence convergence 
in, 301–302, 303t
relative frequency interpretation 
of, 297
theorem of total probability, 
27–28, 28f
Probability densities, of randn 
function, 76–78, 77f
Probability density function (PDF), 
69–71, 69f
of Cauchy random variables, 84
CDF compared with, 69–71, 69f
of chi-squared (2) random 
variables, 81–82
conditional, 87–89, 88f
exercises for, 104–106
for multiple random variables, 
245–247, 277–278
for pairs of random variables, 
188–191, 231
properties of, 87–88
transformations of pairs of 
random variables using, 
213–214
of continuous random variables, 
for CDF, 289
of continuous time and discrete 
amplitude signals, 341
of Erlang random variable, 81–82
of exponential random variables, 
79–80, 79f
of gamma random variables, 81
of Gaussian random processes, 
357–359
of Gaussian random variables, 
72–73, 73f
histogram of randn function, 
76–78, 77f

606    Index
www.Academicpress.com
Probability density function (PDF)
(continued)
of IID random variables, 289
joint
exercises for, 228–229
for Gaussian random variables 
in multiple dimensions, 
250–252
for multiple random variables, 
245–247, 277–278
for pairs of random variables, 
180–186, 184f
joint Gaussian, 202–206, 
203–204f, 205f
of Laplace random variables, 80, 
80f
properties of, 70
of random processes, 340, 342
nth order, 342
second-order, 342
of random variables, 69, 76
characteristic functions and, 
130–131
conditional, 87–89, 88f
exercises for, 99–101
reliability function, 91
of Rayleigh random variables, 
82, 83f
of Rician random variables, 
83–84, 84f
of shot noise processes, 
367–368
of uniform random variables, 
78–79, 78f, 309, 309f
verify validity of, 70
Probability mass function (PMF), 
33
of Bernoulli random variable, 35, 
310, 310f
binomial random variable, 35–37
CDF and, 68
for coin flipping, 33
conditional
for multiple random variables, 
245–247, 277–278
for pairs of random variables, 
188–191, 231
of continuous random variables, 
63
on counting processes, 361–362
of discrete random variables, for 
CDF, 289
exercises for, 55–59
geometric random variable, 
37–38
joint
exercises for, 229–230
for multiple random variables, 
245–247, 277–278
for pairs of random variables, 
186–188
MATLAB for, 34, 34f
in optical communication system, 
39
of Poisson processes, 360, 363
Poisson random variable, 37
problems with, 63–64
of random processes, 340, 342, 
342f
of random telegraph process, 
342f
Probability of error, for optical 
communication system, 
40–41, 42f
Probability ratio test, for radar 
system, 318
Probability theory, 7
assigning probabilities, 13–17, 16t
axioms of probability, 10–13, 13f
basic combinatorics, 20–26, 26t
Bayes's theorem, 27–29, 28f
conditional probability, 18–20
development of, 11
discrete random variables, 
32–38, 34f
exercises for, 43–62
experiments, samples spaces, and 
events, 7–10
joint probability, 17–20
statistical independence, 29–32
Probability-generating functions
joint, 208–209
of single random variables, 
136–138
exercises for, 168–169
PSD. See Power spectral density
Pseudorandom number generators
binary, 517–521, 518f, 519f, 
520t, 521f
nonbinary, 521–522
Pulse amplitude modulation 
(PAM), 455–456
autocorrelation function of, 
456–457
Fourier transform for, 457
with IID sequence of random 
variables, 457–459, 458f, 
459f
matched filter for SNR in, 
485–486, 486f
MATLAB example for, 
460–461, 461f
with memory, 459–460, 460f
Pulse code modulation (PCM), 
differential, 272–275, 273f, 
274f, 275f, 276f
Q
Q components
complex envelopes for, 499–500
cross spectral density of, 497–498
extraction of, 496, 496f
PSD of, 497
Q-function, 565
for CDF of Gaussian random 
variable, 74
evaluation of, 74
expression of, 75–76
Marcum's, 83–84
MATLAB exercise for, 110
numerical methods for 
evaluating, 587–591, 588f, 
589f
-function relation with, 75, 75f
probabilities in terms of, 76
values of, 584–585, 585t
Quadratic transformations, of 
multiple random variables, 
257–260
Quantization
of single random variables, 
148–153, 149f, 152f
exercises for, 172–173
MATLAB exercise for, 
153–154, 154f
of speech, 272–275, 273f, 274f, 
275f, 276f
Queuing systems, 387, 393–394, 
394f
conditional PDF in, 89

Index    607
www.Academicpress.com
Queuing systems (continued)
exponential random variables in, 
80
gamma random variables in, 81
M/M/ queue, 405
M/M/1 queue, 405–407, 406f
Queuing theory, 402–403
R
Radar system, 4, 4f, 317–323
approaches to, 318
false alarm and detection 
probabilities for, 318–319
probability ratio test for, 318
sequential detection, 320
signal-to-noise ratio for, 323
system performance for, 323
thresholds for, 319–320
Wald's inequalities for, 321–322
Radio frequency, phase of, 79
rand, MATLAB, probability 
assignment and, 15
exercises for, 61–62
histogram construction for, 71, 72f
randn, MATLAB, histogram of, 
76–78, 77f
Random number generator
with MATLAB, 15
exercises for, 61–62
histogram creation for, 71, 72f
PMF and, 63
sample space, events, and 
outcomes of, 10
Random processes, 335–370
average normalized power, 356
bandpass, 494
bandwidth of, 439–441, 439f, 
440f
exercises for, 465–466
CDF of, 340, 342
of coin flipping, 336–338, 336f, 
338f
computer generation of, 525–534
exercises for, 544
frequency domain approach to, 
525–528, 526f, 528f
of Gaussian white noise, 
533–534, 534f
time domain approach, 
529–532, 529f, 531f, 533f
of continuous time and discrete 
amplitude signals, 
338–339, 339f
cross spectral density between, 
438–439
definition of, 336
of discrete time and continuous 
amplitude signals, 
339–340, 340f
ergodic in autocorrelation, 351
ergodic in mean, 351
ergodicity of, 351–356
frequency domain techniques for, 
429
Gaussian, 342, 357–360, 359f
autocorrelation function of, 
346–347
definition of, 357
exercises for, 375–376
PDF of, 357–359
in linear systems, 473–504
analog communication system, 
500–504, 500f, 501f, 504f
bandlimited and narrowband, 
494–498, 495f, 496f, 497f, 
498f
complex envelopes, 499–500, 
514
continuous time, 
473–477, 505–507
discrete-time, 477–479, 
508–509
matched filter, 482–486, 482f, 
485f, 486f, 511–512
MATLAB exercises for, 
514–515
noise equivalent bandwidth, 
479–480, 479f
signal-to-noise ratios, 
480–482, 510–511
Wiener filter, 486–494, 490f, 
491f, 495f, 512–513
lowpass, 494
mathematical tools for studying, 
340–348, 342f, 345f
autocorrelation function, 
344–345
autocovariance function, 347
cross-correlation function, 
347–348
cross-covariance function, 348
exercises for, 371–372
MATLAB exercises for, 381–382
mean function of, 343
mean of, 343
PDF of, 340, 342
nth order, 342–343
second-order, 342
PMF of, 340, 342, 342f
Poisson processes, 360–364, 364f
exercises for, 376–378
PSD for
definition of, 430–433
Wiener–Khintchine–Einstein 
theorem, 433–439, 434f, 
436f, 437f
of random variable, 337, 337f
autocorrelation function for, 
346
ergodicity of, 352
MATLAB for, 344, 345f
mean function of, 343–344
strict sense stationary, 349
realization of, 336
shot noise processes, 365–370, 
368f, 369f, 370f
spectral characteristics of, 
429–430
strict sense stationary, 348–349
exercises for, 372–375
wide sense stationary, 349–351
exercises for, 372–375
Wiener process, 360
Random sequences
convergence modes of, 
298–303, 303t
convergence almost 
everywhere, 301, 303t
convergence everywhere, 
300–301, 303t
convergence in distribution, 
302–303, 303t
convergence in mean square 
sense, 302, 303t
convergence in probability, 
301–302, 303t
exercises for, 326–327
IID random variables, 289–298
estimating CDF of, 297–298
estimating mean of, 290–295

608    Index
www.Academicpress.com
Random sequences (continued)
estimating variance of, 
295–297
PDF of, 289
sample mean of, 299
radar system, 317–323
approaches to, 318
false alarm and detection 
probabilities for, 318–319
probability ratio test for, 318
sequential detection, 320
system performance for, 323
thresholds for, 319–320
Wald's inequalities, 321–322
Random sums
central limit theorem, 306–310
Bernoulli random variables, 
310, 310f
exercises for, 329
proof of, 307–308
uniform random variables, 
309, 309f
of Gaussian random variables, 317
law of large numbers, 304–306
exercises for, 327–328
of random variables, 315–317
exercises for, 331–332
function of, 316
mean and variance of, 315–316
Random telegraph process
autocorrelation estimate for, 442, 
442f
with windowing function, 
443–445, 444f, 445f
bandwidth of, 441
mathematical study of, 
340–341
MATLAB, 338–339, 339f
mean function of, 343
periodogram estimate of PSD for, 
447–448, 448f
PMF of, 342f
Wiener–Khintchine–Einstein 
theorem for, 436–438, 436f, 
437f
Random variables. See also specific 
types
CDF of, 65–66, 65f, 66f
conditional, 86–87
exercises for, 97–99
reliability function, 91
central moments of, 117–121
exercises for, 162–163
MATLAB exercise for, 
120–121
characteristic functions of, 
130–136
exercises for, 167–168
moments and, 133–135
natural logarithm of, 135–136
PDFs and, 130–131
for coin flipping, 33
computer generation of, 517–524
binary pseudorandom number 
generators, 517–521, 518f, 
519f, 520t, 521f
correlated, 524
exercises for, 543–544
nonbinary pseudorandom 
number generators, 521–522
from specified distribution, 
521–522
conditional expected values of, 
121–122
exercises for, 163–164
entropy associated with, 
155–158, 157f, 158t
exercises for, 173
expected value of, 111–113
exercises for, 159–160
functions of, 113–114, 115t
functions of, 85, 85f
conditional expected value of, 
122
exercises for, 160–161
expected value of, 
113–114, 115t
independence of, 197–199
exercises for, 233–234
MATLAB exercise for, 
200–201, 201f
in interval, CDF and, 64, 69
list of common, 565–575
MATLAB histogram of randn, 
76–78, 77f
mean of, estimation of, 304
moment-generating functions of, 
139–140
exercises for, 169–170
moments of, 115–117
characteristic functions and, 
133–135
exercises for, 161
probability-generating 
functions and, 136–138
PDF of, 69, 76
characteristic functions and, 
130–131
conditional, 87–89, 88f
exercises for, 99–101
reliability function, 91
PMF of, 33
probability-generating functions 
of, 136–138
exercises for, 168–169
random process of, 337, 337f
autocorrelation function for, 346
ergodicity of, 352
MATLAB for, 344, 345f
mean function of, 343–344
strict sense stationary, 349
random sums of, 315–317
exercises for, 331–332
function of, 316
mean and variance of, 315–316
scalar quantization of, 
148–153, 149f, 152f
exercises for, 172–173
MATLAB exercise for, 
153–154, 154f
tail probability evaluations, 
140–147, 143f, 147f
exercises for, 170–172
tangent of, 84
transformations of, 122
exercises for, 164–167
MATLAB exercise for, 129, 
130f
monotonically decreasing 
functions, 123f, 124–125
monotonically increasing 
functions, 122–124, 123f
nonmonotonic functions, 
125–129, 125f, 128f, 130f
Random walks, 359–360, 359f, 387, 
396, 399–401
Rare events, simulation of, 534–538
exercises for, 545–546
importance sampling, 537–538
Monte Carlo simulations, 535–537
Rayleigh distribution, 82
reliability function and failure 
rate function of, 93

Index    609
www.Academicpress.com
Rayleigh random variables, 82, 83f, 
571–572
exercise for, 104
expected value of, 113
Rician random variables and, 83
Realization, of random process, 336
Recurrent state, 398–401
Relative frequency approach
to assigning probabilities, 16
for dice rolling, 16–17, 16t
for joint probability, 18
Relative frequency interpretation of 
probability, 297
Reliability function, 91
derivative of, 91
exponential distribution of, 93
failure rate function and, 92
of Rayleigh distribution, 93
of system
parallel interconnection, 94–95
series interconnection, 93–95
Reliability rates, 91–95
Rician distribution, 84
Rician random variables, 83–84, 
84f, 572
central moments of, 120–121
MATLAB exercise for, 110
mean of, 296–297
variance of, 296–297
RMS bandwidth. See Root-mean-
square
Root-mean-square (RMS) 
bandwidth, 440
Row vector, 551
S
Saddle point approximation, 
145–147, 147f
Sample mean, 292
confidence intervals and, 312
of IID random variables, 299
in law of large numbers, 304
MATLAB example for, 
305–306, 305f
of Rician random variables, 
296–297
Sample spaces, 7–10
choice of, 10
of coin flipping, 8–9
continuous, 10
mix with discrete, 10
definition of, 8
of dice rolling, 9
of die rolling, 9
exercises for, 43–44
of random number generator, 10
random variables of, 32
Sample variance, 296
MATLAB example for, 
305–306, 305f
of Rician random variables, 
296–297
Satellite communication channels, 
Rician distribution in, 84
Scalar, 551
Scalar quantization, of single 
random variables, 148–153, 
149f, 152f
exercises for, 172–173
MATLAB exercise for, 153–154, 
154f
Second central moment, 118. See 
also Variance
Second moment, 115–117
Second-order PDF, of random 
processes, 342
Sensor, voltage of, noise and, 
289–290
Sequential detection
performance of, 320–322
for radar system, 320
Series expansions, 577–578
Series interconnection, system, 
reliability function and 
failure rate function of, 
93–95
Set theory, 545–549, 548f
Shannon entropy, 156
Shot noise processes, 365–370, 
368f, 369f, 370f
autocorrelation function of, 
366–367
in p-n junction diode, 365–370
with current pulse shape, 
369–370, 370f
exercises for, 378–380
with square wave, 
368–369, 368f, 369f
mean function of, 365–366
PDF of, 367–368
Poisson counting processes, 365
Poisson impulse processes, 365
as strict sense stationary, 368
as WSS, 367
Signals
review of, 559–563
scalar quantization of, 148–153, 
149f, 152f
sinusoidal, 219
types of, 335
Signal-to-noise ratio, of radar 
system, 323
Signal-to-noise ratios (SNR)
for AM, 502–503
exercises for, 480–482, 510–511
in linear systems, 480–482
LPF and, 481–482
matched filter for, 482–486, 482f, 
485f, 486f
for binary PAM signal, 
485–486, 486f
for communication system, 
484–485, 485f
of radar system, 323
Signal-to-quantization-noise power 
ratio (SQNR), 148–150, 
153–154, 154f
for DPCM speech coders, 275, 
276f
Simulation techniques, 517–541
for coded digital communication 
system, 539–541, 539f, 541f
computer generation of random 
processes, 525–534
exercises for, 544
frequency domain approach to, 
525–528, 526f, 528f
of Gaussian white noise, 
533–534, 534f
time domain approach, 
529–532, 529f, 531f, 533f
computer generation of random 
variables, 517–524
binary pseudorandom number 
generators, 517–521, 518f, 
519f, 520t, 521f
correlated, 524
exercises for, 543–544
nonbinary pseudorandom 
number generators, 
521–522
from specified distribution, 
521–522

610    Index
www.Academicpress.com
Simulation techniques (continued)
MATLAB exercises for, 546
of rare events, 534–538
exercises for, 545–546
importance sampling, 537–538
Monte Carlo simulations, 
535–537
Single random variables. See 
Random variables
Singular matrix, 553–554
Sinusoidal random processes, 337, 
337f
autocorrelation function for, 346
ergodicity of, 352
mean function of, 343–344
MATLAB for, 344, 345f
PSD of, 432
strict sense stationary, 349
Wiener–Khintchine–Einstein 
theorem for, 435–436
Sinusoidal signals, 219
6 dB rule, 150
Skewness, 118. See also Coefficient 
of skewness
Slotted Aloha, 413–415, 415f
Smoothing function, for 
periodogram, 446
SNR. See Signal-to-noise ratios
Source coding, entropy and, 
155–158, 157f, 158t
exercises for, 173
Spectral estimation
exercises for, 466–468
of PSD, 441–452
non-parametric, 441–448, 
442f, 444f, 445f, 448f
parametric, 448–452, 452f
Speech, linear prediction of, 
272–275, 273f, 274f, 275f, 
276f
Speech recognition system, 2–4, 3f
Speech signal amplitude, Laplace 
random variables in, 80
Spherical coordinates, Cartesian 
coordinate transformation 
into, 262–263, 263f
SQNR. See Signal-to-quantization-
noise power ratio
Staircase function transformation, 
128, 128f
Standard deviation
estimating of IID random 
variables, 295–297
of Gaussian random variables, 
72–73, 72n1, 73f
second central moment of 
random variables and, 118
Standard normal random variables, 
73
CDF of, 74
central limit theorem and, 307–308
State transition probability matrix, 
calculation of, 388–393
exercises for, 421–424
MATLAB exercise for, 393–394, 
394f
Stationary
strict sense, random processes, 
348–349
wide sense, random processes, 
349–351
Stationary increments, of Poisson 
processes, 361
Statistical independence. See 
Independence
Steady-state distribution, 391, 393, 
401
for continuous time Markov 
processes, 403–405
Stochastic signals, 7
Strict sense stationary
ergodicity and, 351–352
exercises for, 372–375
of random processes, 348–349
shot noise processes as, 368
sinusoidal random processes, 349
Strong law of large numbers, 
304–305
convergence almost everywhere 
and, 305
Student's t-distribution, 313, 315n5, 
572–573
Subset, 545, 548f
Symmetric matrix, 551
Systems, review of, 559–563
T
Tail probabilities, evaluation of, 
140–147, 143f, 147f
exercises for, 170–172
Taylor series expansion of 
Q-function, 588–589, 588f
Telephone exchange, Markov 
processes describing, 
416–417, 417f
Telephone traffic, Erlang random 
variable in, 82
Theorem of Total Probability, 
27–28, 28f
unconditional cumulative 
distribution function and, 
89–90
Thermal noise, 452–454
exercises for, 468–469
PSD of, 452–455, 453f, 454f
Thevenin equivalent circuit, 453, 
453f
Third central moment, 118
Three dimensions. See Multiple 
random variables
3 dB bandwidth, 440, 440f
Time, continuous function of, 335
Time difference variable, 
autocorrelation function 
and, 345
Time domain techniques, 7
for computer generation of 
random processes, 529–532, 
529f, 531f, 533f
MATLAB example for, 
530–532, 531f
Time-averaged power, of random 
process, 430
Total probability, theorem of, 
27–28, 28f
Transfer function, 562
Transformations
of multiple random variables, 
252–253
coordinate systems in three 
dimensions, 262–263, 263f
exercises for, 281–283
linear, 253–257
MATLAB exercise for, 
256–257
order statistics, 260–262
quadratic, 257–260
of pairs of random variables, 
210–219
exercises for, 236–238

Index    611
www.Academicpress.com
Transformations (continued)
of single random variables, 122
exercises for, 164–167
MATLAB exercise for, 129, 
130f
monotonically decreasing 
functions, 123f, 124–125
monotonically increasing 
functions, 122–124, 123f
nonmonotonic functions, 
125–129, 125f, 128f, 130f
on uniform random variables, 79
of vector random variable, 
248–249
Transient state, 398–401
Transition probability matrix, 
384–385
calculation of, 388–393
exercises for, 421–424
MATLAB exercise for, 
393–394, 394f
for continuous time Markov 
processes, 402
Transpose, 551
Trigonometric identities, 577
Two dimensions. See Pairs of 
random variables
U
Unbiased estimate, 262, 290
Unconditional cumulative 
distribution function, 89–90
Uncorrelated random variables, 193
complex, 221
independence and, 195, 199, 251
Uniform quantizer, 149–150, 149f
Uniform random variables, 78–79, 
78f, 573
central moments of, 118
histogram of MATLAB 
generation of, 71, 72f
MATLAB exercise for, 109
moments of, 117
PDF of, 309, 309f
sine of, 85, 85f
transformation on, 79
WSS and, 350
Union, 545, 546f
Universal set, 545, 546f
Upper triangular, 552
V
Variability, accounting for, 7
Variance, 118
of complex random variables, 
220–221
estimating of IID random 
variables, 295–297
MATLAB example for, 
296–297
ML for, 295–296
of failure probability, 314
of Gaussian random variables, 
72–73, 72n1, 317–318
of IID random variables, 292
in law of large numbers, 304
of noise, 290
probability-generating functions 
and, 137–138
of random sum of Gaussian 
random variables, 317
of random sum of IID random 
variables, 315–316
of Rician random variables, 
296–297
sample, 296
tail probability evaluations using, 
142
Vector random variable. See 
Multiple random variables
Voice conversation duration, 
exponential random 
variables in, 80
W
Wald's inequalities, for radar 
system, 321–323
Weak law of large numbers, 304–305
convergence in probability and, 
305
Weibull random variable, 573–574
White noise, 454
LTI system conversion of, 
476–477, 477f
Whitening, 256
Whitening filter, 490–491, 490f
Wide sense stationary (WSS)
autocorrelation function and, 
349–351, 356–357
ergodicity of, 351–356
exercises for, 372–375
Gaussian random processes, 
358–359
PSD of, 433
random processes, 349–351
shot noise processes as, 367
Wiener filter, 486–494, 490f, 491f, 
494f
exercises for, 486–494, 490f, 
491f, 494f, 512–513
impulse response with, 489
to minimize mean square error, 
487–489
for prediction, 492–494, 494f
with two filters, 490–492
Wiener process, 360
Wiener–Hopf equations, 488–489
for prediction, 492–494, 494f
for two filters, 490–491
Wiener–Khintchine–Einstein 
theorem, 433–439, 434f, 
436f, 437f
exercises for, 463–465
for random telegraph process, 
436–438, 436f, 437f
for sinusoidal random processes, 
435–436
Windowing function, for 
autocorrelation function 
estimation, 443
random telegraph process, 
443–445, 444f, 445f
Wireless communication channels, 
Rayleigh random variables 
in, 82
Wireline telecommunication 
networks, Erlang random 
variable in, 82
WSS. See Wide sense stationary
Y
Yule-Walker equations, 488
Z
Zero-mean Gaussian distribution, 82
Zeroth central moment, 118
Zeroth moment, 115
Z-transform, 561, 582–583t
for discrete-time linear systems, 
477–478
for discrete-time processes, 429

