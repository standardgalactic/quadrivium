
Battery Management Systems
Volume I
Battery Modeling

For a listing of recent titles in the 
Artech House Power Engineering and Power Electronics, 
turn to the back of this book.

Gregory L. Plett
Battery Management Systems
Volume I
Battery Modeling

Library of Congress Cataloging-in-Publication Data
A catalog record for this book is available from the U.S. Library of Congress.
British Library Cataloguing in Publication Data
A catalog record for this book is available from the British Library.
ISBN-13: 978-1-63081-023-8
Cover design by John Gomes
© 2015 Artech House
685 Canton Street
Norwood, MA 02062
All rights reserved. Printed and bound in the United States of America. No part of this book may be 
reproduced or utilized in any form or by any means, electronic or mechanical, including photocopy-
ing, recording, or by any information storage and retrieval system, without permission in writing from 
the publisher.
All terms mentioned in this book that are known to be trademarks or service marks have been ap-
propriately capitalized. Artech House cannot attest to the accuracy of this information. Use of a term 
in this book should not be regarded as affecting the validity of any trademark or service mark.
10 9 8 7 6 5 4 3 2 1

Contents
Preface
ix
1
Battery Boot Camp
1
1.1
Preliminaries
2
1.2
How cells work
4
1.3
Materials choice
8
1.4
Insertion electrode cells
11
1.5
Lithium-ion cell preview
12
1.6
Manufacturing
20
1.7
Failure modes
24
1.8
Where to from here?
28
2
Equivalent-Circuit Models
29
2.1
Open-circuit voltage (OCV)
30
2.2
State-of-charge dependence
30
2.3
Equivalent series resistance
33
2.4
Diffusion voltages
34
2.5
Rough parameter values
38
2.6
Warburg impedance
40
2.7
Hysteresis voltages
41
2.8
Enhanced self-correcting cell model
44
2.9
Laboratory equipment for cell-data collection
44
2.10 Lab tests to determine OCV relationship
45
2.11 Lab tests to determine dynamic relationship
53
2.12 Example results
57
2.13 Where to from here?
59
2.14 Chapter appendix: MATLAB ESC model toolbox
59
3
Microscale Cell Models
65
3.1
Chapter goal: Derive microscale model equations
67
v

vi
battery management systems: volume i, battery modeling
3.2
Charge conservation in the solid
68
3.3
Mass conservation in the solid
75
3.4
Thermodynamics
80
3.5
Physical chemistry
86
3.6
Basic characteristics of binary electrolytes
91
3.7
Concentrated solution theory: Electrolyte mass conservation
94
3.8
Concentrated solution theory: Electrolyte charge conservation
106
3.9
Butler–Volmer equation
110
3.10 Implementing the model
119
3.11 Cell-level quantities
122
3.12 Where to from here?
130
3.13 Chapter appendix: OCP sources
130
3.14 Partial glossary
132
4
Continuum-Scale Cell Models
135
4.1
Chapter goal: The continuum-scale cell model
136
4.2
Preliminaries
137
4.3
Volume-averaging theorem 1
146
4.4
Volume-averaging theorem 2
148
4.5
Volume-averaging theorem 3
149
4.6
Charge conservation in the solid
152
4.7
Mass conservation in the solid
156
4.8
Mass conservation in the electrolyte
157
4.9
Charge conservation in the electrolyte
160
4.10 Lithium movement between the solid and electrolyte phases
161
4.11 Boundary conditions for pseudo 2D model
161
4.12 Cell-level quantities
163
4.13 Model simulations
164
4.14 Running COMSOL
169
4.15 Where to from here?
169
4.16 Partial glossary
170
5
State-Space Models and the Discrete-Time Realization Algorithm
173
5.1
A quick introduction to state-space models
174
5.2
Equations describing the solid dynamics
182
5.3
State-space realization
186
5.4
Discrete-time realization algorithm (DRA)
195
5.5
Step-by-step examples of the DRA
198
5.6
Eigensystem realization algorithm (ERA)
208
5.7
Where to from here?
212

contents
vii
5.8
Partial glossary
213
6
Reduced-Order Models
217
6.1
A one-dimensional model of jneg(z, t)
217
6.2
A one-dimensional model of ˜cneg
s,e (z, t)
225
6.3
A one-dimensional model of ˜φneg
s
(z, t)
226
6.4
Positive-electrode variables jpos(z, t), ˜cpos
s,e (z, t) and ˜φpos
s (z, t)
227
6.5
A one-dimensional model of ce(x, t)
229
6.6
A one-dimensional model of ˜φe(x, t)
241
6.7
Summary of transfer functions
244
6.8
Computing cell voltage
246
6.9
Frequency response and cell impedance
248
6.10 Multioutput DRA
249
6.11 Full cell model
252
6.12 Simulation example
253
6.13 Model blending
256
6.14 Where to from here?
266
6.15 Modal-solution code
266
6.16 Partial glossary
269
7
Thermal Modeling
271
7.1
Preliminary deﬁnitions
272
7.2
Microscale thermal model
273
7.3
Continuum thermal model
277
7.4
Parameter temperature variation
280
7.5
Reduced-order model
281
7.6
Gradient transfer functions
281
7.7
Heat-generation terms
285
7.8
Heat-ﬂux terms
292
7.9
Uncoupled model results
296
7.10 Coupled model results
297
7.11 Where to from here?
298
7.12 Partial glossary
300
A
Supercapacitors
303
A.1
The same but different
303
A.2
Charge storage
304
A.3
Continuum model
305
A.4
A one-dimensional model of ˜φneg
s-e (z, t)
307
A.5
A one-dimensional model of ˜φneg
s
(z, t)
310

viii
battery management systems: volume i, battery modeling
A.6
A one-dimensional model of ˜φneg
e
(z, t)
311
A.7
Positive-electrode variables ˜φpos
s-e (z, t), ˜φpos
s (z, t) and ˜φpos
e (z, t)
312
A.8
Supercapacitor voltage
313
A.9
Implementing the full-order model
314
A.10 Implementing the reduced-order model
315
A.11 Simulation results
316
A.12 Identifying parameters
317
A.13 Partial glossary
322
About the Author
323
Index
325

1 Certainly, what is meant by “best
practices” is at least somewhat subjec-
tive, and I may well have overlooked
approaches and methodologies that are
better in some applications than those
described herein. Perhaps I should
say “best” from my own point of view,
given what I happen to have tried, in
application domains and problems I
have attempted to address.
Preface
This book constitutes the ﬁrst volume in what is planned to be a
three-volume series describing battery management systems. The
intent of the series is not to be encyclopedic; rather, it is to put for-
ward only the current best practices, with sufﬁcient fundamental
background to understand them thoroughly.1
This ﬁrst volume focuses on deriving mathematical sets of equa-
tions or models that describe how battery cells work, inside and out.
The second volume applies equivalent-circuit style models to solve
problems in battery management and control. The third volume
shows how physics-based models can also be used to solve problems
in battery management and control, leading to better results.
This particular volume is organized in the following way:
• Chapter 1 introduces the fundamental deﬁnitions pertaining to
battery systems and gives an overview of how they work.
• Chapter 2 derives empirical models based on using linear circuits
as an analog to input–output battery-cell behaviors.
• Chapter 3 presents the fundamental physics needed to under-
stand physics-based internal battery-cell behaviors and derives
microscale models.
• Chapter 4 introduces volume averaging as a means to convert
microscale models to continuum-scale models, leading to the well-
known pseudo-two-dimensional porous-electrode model.
• Chapter 5 reviews state-space models as the ultimate form of our
development and develops the “discrete-time realization algo-
rithm” (DRA) as a method for creating a state-space model.
• Chapter 6 derives cell-level discrete-time physics-based state-space
models of similar computational complexity to the circuit models
in Chapter 2, but able to predict internal cell behaviors in addition
to input–output behaviors.
• Chapter 7 shows how a coupled electrochemical–thermal model
can be derived—introducing concepts in heat generation and heat
ﬂux—leading to a physics-based reduced-order model of thermal
effects.
ix

x
battery management systems: volume i, battery modeling
• Appendix A is a bonus chapter that applies the techniques from
Chapters 3 through 7 to create a discrete-time physics-based state-
space model of a supercapacitor.
The intended audience for this material is someone with an under-
graduate degree in engineering—principally electrical or mechanical.
Readers having a different background may ﬁnd some of the material
too basic (because they have studied it before, whereas engineering
students have not) or not descriptive enough (because they are miss-
ing some background that would typically be encountered in an en-
gineering degree program). Both problems have a remedy, although
the solution to the second involves background research to become
proﬁcient in an unfamiliar discipline—not an easy undertaking.
The mathematical intensity—particularly for the topics presented
in Chapters 3 through 7—can be intimidating even to someone hav-
ing the intended background. However, I have found that the student
who is willing to take the time to work the equations by hand, side
by side with the derivations in the book, is able to validate every step
and thus conquer the material. For the reader who is interested pri-
marily in a higher-level understanding, the main derivation results
to be proven are shared at the beginnings of the most mathematical
chapters (i.e., Chapters 3, 4, and 7). The derivations themselves are
necessary to understand the genesis of these results, but not to be
able to implement the ﬁnal equations in a simulation or some other
application, and so may be skimmed on a preliminary reading.
The content in this book has been taught multiple times to stu-
dents of diverse backgrounds in ECE5710: Battery Modeling, Sim-
ulation, and Identiﬁcation at the University of Colorado Colorado
Springs. Lecture videos are available at http://mocha-java.uccs.
edu/ECE5710/index.html. As the lecture videos sometimes explain
the concepts of this book in a somewhat different way, the additional
perspective may be an advantage to the learner.
I am greatly indebted to a number of my students and colleagues
who have assisted me over the years in understanding and devel-
oping the theory and methods presented in this work. Dr. Kan-
Hao Xue prepared the ﬁrst draft of the derivations in Chapter 3.
Drs. Amit Gupta and Xiangchun Zhang explained to me the con-
cepts of volume-averaging that are presented in Chapter 4. Dr. Mark
Verbrugge introduced me to the pioneering work of Dr. Kandler
Smith, which is the foundation of the work presented in Chapters 5
through 7 (and Dr. Smith himself was kind enough to answer ques-
tions I had on his work). Dr. Jim Lee developed the DRA presented
in Chapter 5 and was the ﬁrst to implement cell-scale optimum
reduced-order models using the DRA, as presented in Chapter 6.
Mr. Matt Aldrich developed the reduced-order thermal models in

preface
xi
Chapter 7. Finally, Dr. Al Mundy was the ﬁrst to implement reduced-
order supercapacitor models using the DRA techniques presented
in Appendix A. My colleague and friend Dr. M. Scott Trimboli has
also been a great encourager of this work and a true pleasure to work
with.
Despite my best intentions, there are certain to be errors and con-
fusing statements in this book. Please feel free to send me corrections
and suggestions for improvements.


1.1
Preliminaries . . . . . . . . . . . 2
1.2
How cells work . . . . . . . . . . 4
1.3
Materials choice. . . . . . . . . . 8
1.4
Insertion electrode cells . . . . 11
1.5
Lithium-ion cell preview. . . . 12
1.6
Manufacturing . . . . . . . . . 20
1.7
Failure modes . . . . . . . . . . 24
1.8
Where to from here? . . . . . . 28
1
Battery Boot Camp
This book is all about developing a mathematical understanding of
how electrochemical—and especially lithium-ion—battery cells work.
This kind of knowledge is helpful when designing cells, when select-
ing cells to be used in an application, and for knowing how to use
cells properly in an application. For some of these tasks, a high-level
qualitative understanding is sufﬁcient; however, for others, detailed
quantitative insight into cell operation is critical. Here, we’re inter-
ested in both levels, with the ultimate goal of being able to predict
both internal and external cell operational variables to a degree that
enables optimized battery-pack controls.
This book has mission-critical single-cell or large battery-pack ap-
plications in mind, as these applications justify both the complexity
of the models to be developed and an investment in advanced con-
trol methods that use the models, since such methods can prolong
battery-pack life and improve total system performance. Example
applications include battery systems for hybrid and electric vehicles
or for utility-scale grid storage, backup, and frequency regulation.
However, much of the material that is covered also applies to smaller
battery packs, such as for personal electronics, and much of the mate-
rial can also be applied to chemistries different from lithium-ion.
The three main foci of the book are:
1. Modeling: Deriving mathematical expressions that describe how
battery cells work, both internally and externally. After several
stages of development, the ﬁnal models will comprise coupled
sets of discrete-time ordinary difference equations (ODEs) that
are functions of unknown but measurable or identiﬁable pa-
rameter values. The input to the models will be the cell current;
the output will include cell voltage and possibly cell internal
electrochemical states as well.
2. Simulation: Using computer tools to predict how a battery cell
will respond to an input stimulus. The equations of the battery
model are used to predict cell voltage and possibly internal
1

2
battery management systems: volume i, battery modeling
1 COMSOL Multiphysics is a registered
trademark of The COMSOL Group, and
MATLAB is a registered trademark of
The MathWorks. From now on, these
products will be referred to simply as
COMSOL and MATLAB, respectively.
2 Much of the content of this chapter
is adapted from the excellent Web site:
http://www.mpoweruk.com/.
3 The National Electrical Code, docu-
ment NFPA-70 deﬁnes a cell as “The
basic electrochemical unit, characterized
by an anode [i.e., negative electrode]
and a cathode [i.e., positive electrode],
used to receive, store, and deliver
electrical energy.”
4 IEEE standard 446 deﬁnes a battery
as “Two or more cells electrically con-
nected for producing electric energy.”
Cell
Battery
Figure 1.1: Schematic symbols for a cell
and a battery.
5 Cells deliver a range of voltage de-
pending on conditions such as temper-
ature and how much charge they are
holding. Table 1.1 lists the voltage of a
single lead-acid cell as 2.1 V, which is
more accurate under many conditions
than the more commonly cited ﬁgure of
2 V, but either ﬁgure is roughly correct
unless more speciﬁc operational fac-
tors are speciﬁed. One purpose of the
models developed in this book is to be
able to predict cell voltage under very
general operating conditions.
6 From the National Electrical Code,
document NFPA-70.
battery-cell states. We will see simulations involving different
degrees of ﬁdelity applied to different cell-length scales. We
will describe simulations that use the ﬁnite-element software
platform COMSOL Multiphysics®, and we will give code to
implement cell models in MATLAB®.1
3. Identiﬁcation: Determining the values of model parameters, us-
ing data obtained via lab tests, to cause the model simulated
predictions to match measured performance as closely as possi-
ble.
This chapter very quickly covers a lot of background material relat-
ing to battery terminology, function, and general application.2 Later
chapters will systematically develop models of battery-cell dynam-
ics at different length scales for different kinds of application and
show how to use these models to simulate performance and how to
identify model parameters.
1.1
Preliminaries
Cells are the smallest individual electrochemical unit and deliver
a voltage that depends on the combination of chemicals and com-
pounds chosen to make the cell.3 Single-use cells are called primary
cells and rechargeable cells are called secondary cells. Batteries or bat-
tery packs are made up from groups of cells.4 The schematic symbols
for a cell and a battery are shown in Fig. 1.1.
Technically, a cell is different from a battery, but many people
(including me, at times) use the term battery to describe any electro-
chemical energy source, even if it is a single cell, and this can lead
to confusion. I will attempt to use the terms cell or battery cell consis-
tently to refer to an individual electrochemical unit, and reserve the
terms battery (used by itself) and battery pack to refer to an electrically
connected group of cells. Note that it is not always obvious whether
the correct term should be cell or battery since batteries are sometimes
packaged in a single physical unit. For example, automotive “12 V”
lead-acid batteries internally comprise six “2 V” cells wired in series;5
also, many high-capacity lithium-ion batteries consist of a number of
cells wired in parallel in a single package.
Cell voltage depends a number of factors, as we will ﬁnd out. The
manufacturer-speciﬁed nominal voltage is “The value assigned to a cell
or battery of a given voltage class for the purpose of convenient des-
ignation. The operating voltage of the cell or battery may vary above
or below this value.”6 Cells with lead-acid (PbA) chemistry have a
nominal voltage of 2.1 V; nickel-cadmium (NiCd) cells have a nomi-
nal voltage of 1.35 V; and nickel-metal-hydride (NiMH) chemistries

1. battery boot camp
3
7 Note that the SI unit for charge is the
coulomb (C) and that 1 Ah = 3, 600 C,
which is quite a lot of charge! The SI
unit is not often used, probably because
it is such a small amount of charge
relative to the capacity of most cells.
8 The SI unit for energy is the joule (J),
where 1 J = 1 W s. A joule is a pretty
tiny unit of energy compared to what a
typical battery holds, which is probably
why the SI unit is not usually used
when working with batteries.
have a nominal voltage of 1.2 V (cf. Table 1.1). Most lithium-based
cells have nominal voltages over 3 V.
Cells store and are able to deliver electrical charge to power a
load circuit. The cell nominal charge capacity speciﬁes the quantity of
charge, in ampere-hours (Ah) or milliampere-hours (mAh), that a cell
is rated to hold.7 The cell’s nominal energy capacity (see below) is a
different quantity. Both deﬁnitions of capacity have merit and can be
computed from one another. However, as our focus in this book is on
creating models that relate a cell’s input current (i.e., rate of change
of charge) to its internal electrochemical state and output voltage,
charge capacity turns out to be the more relevant concept. Unless
otherwise mentioned, the term capacity will refer to charge capacity
and not to energy capacity in this book.
Related to the cell’s charge capacity, the C rate is a relative mea-
sure of cell current. It is the constant-current charge or discharge
rate that the cell can sustain for 1 hour—it is simply the nominal am-
pere hour rating of the cell multiplied by 1 h−1. For example, a fully
charged 20-Ah cell should be able to deliver 20 A (a “1C” rate) for 1 h
or 2 A (a “C/10” rate) for about 10 h before the cell is completely dis-
charged. If the cell is discharged at a 10C rate, it will be completely
discharged in about 6 minutes. Note that the relationship between
C rate and discharge time is not strictly linear, primarily because of
the internal resistance of the battery cell and incomplete utilization
of the active materials when the cell is exercised at high rates. In fact,
a cell discharged at a 10C rate will reach a minimum operational
voltage before 6 minutes has elapsed, but a cell discharged at a C/10
rate may be operated somewhat more than 10 h before reaching the
minimum voltage.
A cell stores energy in electrochemical form, which it can later
release to do work. The cell nominal energy capacity is the quantity of
electrical energy in watt hours (Wh) or kilowatt hours (kWh) that the
cell is rated to hold and is computed as the cell’s nominal voltage
multiplied by its nominal charge capacity.8 For example, a 2 V, 10-Ah
lead-acid cell has an energy storage capacity of roughly 20 Wh. It is
important to note that energy and power are different quantities for a
particular rate of discharge. Power is the instantaneous rate at which
energy is being released. Power is measured in watts (W) or kilowatts
(kW). The maximum power that a cell can deliver is limited by the
cell’s internal resistance and is not an easy value to quantify. Power
is usually regulated by enforcing minimum and maximum limits on
cell terminal voltage.

4
battery management systems: volume i, battery modeling
Figure 1.2: Three cells connected in
series.
Figure 1.3: Five cells connected in
parallel.
When cells are connected in series, the battery voltage is the sum
of the individual cell voltages, by Kirchhoff’s voltage law. How-
ever, by Kirchhoff’s current law, the charge capacity of the series-
connected battery is the same as the charge capacity of an individual
cell since the same current passes through all of the cells. As an ex-
ample, consider the battery in Fig. 1.2, which is constructed from
three 2 V, 20-Ah cells connected in series. The battery voltage will be
6 V, the battery charge capacity will be 20 Ah, and the battery energy
capacity will be 120 Wh.
When cells are connected in parallel, the battery voltage is equal
to the cells’ voltage, by Kirchhoff’s voltage law. However, by Kirch-
hoff’s current law, the charge capacity is the sum of the cells’ charge
capacities since the battery current is the sum of all the cell currents.
For example, consider the battery in Fig. 1.3, which is constructed
from ﬁve 2 V, 20-Ah cells connected in parallel. The battery will have
a voltage of 2 V, a charge capacity of 100 Ah, and energy capacity of
200 Wh.
Speciﬁc energy and energy density are measures of the maximum
amount of stored energy per unit weight or volume, respectively. For
a given weight, a higher speciﬁc energy cell design will store more
energy, and for a given storage capacity, a higher speciﬁc energy cell
will be lighter. For a given volume, a higher energy density cell chem-
istry will store more energy, and for a given storage capacity, a higher
energy density cell will be smaller.
In general, higher energy densities and higher speciﬁc energies
are obtained by using more reactive chemicals. The downside is that
more reactive chemicals tend to be less stable and may require special
safety precautions. Further, the quality of the active materials used in
cell construction matters, with impurities limiting cell performance
that can be achieved and with construction ﬂaws reducing safety.
Cells from different manufacturers with similar cell chemistries and
similar construction may yield different performance. Cell construc-
tion also matters: overhead from packaging decreases the energy
densities.
1.2
How cells work
Cells are built from a number of principal components. These in-
clude a negative electrode, a positive electrode, the electrolyte, and
a separator. Certain types of cells also have current collectors that are
distinct from the electrodes themselves. Fig. 1.4 shows a schematic of
a lithium-ion cell, but the basic idea applies generally.

1. battery boot camp
5
Electrons
Charge
Charge
Discharge
Discharge
Positive ions
Current
Current
collector
collector
Load
Negative electrode (anode)
Positive electrode (cathode)
Negative ions (if present)
go opposite direction
Separator
Figure 1.4: Schematic diagram of
lithium-ion cell.
(Based on Fig. 1 of Stetzel, K., Aldrich,
L., Trimboli, M.S., and Plett, G., “Elec-
trochemical state and internal variables
estimation using a reduced-order
physics-based model of a lithium-ion
cell and an extended Kalman ﬁlter,”
Journal of Power Sources, 278, 2015, pp.
490–505.)
9 This is realized in a practical lead-acid
cell by spreading a lead paste on a
lead-alloy grid.
10 A mnemonic that may be helpful is
“OIL RIG,” which stands for “oxidation
is loss (of electrons) and reduction is
gain (of electrons).” Not a very “green”
acronym for a “green” subject!
The negative electrode in an electrochemical cell is often a pure metal,
or an alloy, or even hydrogen. For example, the negative electrode
of a lead-acid cell is pure lead.9 Table 1.1 lists negative-electrode
materials for common types of cells.
Electrochemistry
Negative
electrode
Positive
electrode
Electrolyte Nominal
voltage
Lead acid
Pb
PbO2
H2SO4
2.1 V
Dry cell
Zn
MnO2
ZnCl2
1.6 V
Alkaline
Zn
MnO2
KOH
1.5 V
Nickel cadmium
Cd
NiOOH
KOH
1.35 V
Nickel hydrogen
H2
NiOOH
KOH
1.5 V
Nickel zinc
Zn
NiOOH
KOH
1.73 V
Silver zinc
Zn
Ag2O
KOH
1.6 V
Zinc air
Zn
O2
KOH
1.65 V
Table 1.1: Components of some com-
mon electrochemical cells.
(Adapted from Table 1.2 in Linden,
D., Handbook of Batteries, Linden, D.
and Reddy, T.B. eds., 3d, McGraw-
Hill, 2002.) The nominal voltages are
representative only. For example, the
open-circuit voltage of a lead-acid cell
is related to the speciﬁc gravity of its
electrolyte. Most vented lead-acid cells
have a speciﬁc gravity of 1.215 and an
open-circuit voltage of 2.05 V. Most
valve-regulated lead-acid (VRLA) cells
have a speciﬁc gravity of 1.3 and an
open-circuit voltage of 2.15 V.
During discharge, the negative electrode gives up electrons to the
external circuit, a process by which the electrode is oxidized: oxida-
tion of a species involves the loss of electrons or, equivalently, an
increase in the oxidation state of the species (it becomes more posi-
tively charged). During charge, the negative electrode accepts elec-
trons from the external circuit and is reduced: reduction of a species
involves the gain of electrons or, equivalently, a decrease in its oxida-
tion state (it becomes more negatively charged). Thus, the chemical
processes that occur in an electrochemical cell are sometimes called
reduction–oxidation or redox reactions.10
The negative electrode is often called the anode. Technically, the

6
battery management systems: volume i, battery modeling
11 The electrolyte must be an electronic
insulator (it cannot conduct electrons).
If it were an electronic conductor, a
complete circuit would form internal to
the cell, which would cause the cell to
self-discharge or short-circuit.
anode is the electrode where oxidation occurs. So, the negative elec-
trode is really the anode only when the cell is discharging and is
actually the cathode when the cell is charging! But this gets pretty
confusing, so most people call it the anode regardless of whether the
cell is being charged or discharged. To minimize this confusion, this
book will avoid the term anode and will use the term negative electrode
instead.
The positive electrode in an electrochemical cell is often a metallic
oxide, sulﬁde, or oxygen. For example, the positive electrode of a
lead-acid cell is made from pure lead dioxide, often formed from a
lead-oxide paste applied to a lead-alloy grid. Table 1.1 lists positive-
electrode materials for common types of cells.
During discharge, the positive electrode accepts electrons from the
external circuit, a process by which the electrode is reduced. During
charge, the positive electrode gives up electrons to the external circuit
and is oxidized.
The positive electrode is often called the cathode, but again, there
are problems with this description. Technically, the cathode is the
electrode where reduction occurs. So, the positive electrode is re-
ally the cathode only when the cell is discharging and is actually
the anode when the cell is charging! Again, to minimize confusion,
this book will avoid the term cathode and will use the term positive
electrode instead.
The electrolyte is an ionic conductor that provides the medium for
internal ionic charge transfer between the electrodes.11 The elec-
trolyte most often comprises a liquid solvent containing dissolved
chemicals (the solute) that provide this ionic conductivity (although
solid polymer electrolytes are also possible). The chemistries listed
in Table 1.1 use aqueous electrolytes, where the solvent is water, and
the ionic charge transfer is accomplished via either an acid (H2SO4),
a base (KOH), or a salt (ZnCl2). Cells using aqueous electrolytes have
terminal voltages limited to less than about 2 V because the oxygen
and hydrogen in water dissociate in the presence of higher voltages.
Lithium-ion cells must use nonaqueous electrolytes as their overall
voltages are well above 2 V.
During discharge, positively charged ions or cations move through
the electrolyte toward the positive electrode, and negatively charged
ions or anions (if present) move through the electrolyte toward the
negative electrode. During charge, the opposite occurs: cations move
toward the negative electrode and anions move toward the positive
electrode.

1. battery boot camp
7
12 Dry cells are sometimes called zinc
carbon cells, and the positive electrode
is sometimes identiﬁed as carbon. But,
this is not actually true, as carbon
takes no part in the chemical reaction—
it serves only to collect current and
reduce resistance of the manganese
dioxide mix.
The separator physically isolates the positive and negative electrodes.
It is an ionic conductor but an electronic insulator. Its function is to
prevent internal short circuiting between the two electrodes, which
would cause the cell to rapidly self-discharge and become useless.
Current collectors, if present, are electronic conductors onto which the
electrode materials are adhered or with which the electrode materials
are mixed. The current collectors take no part in the chemical reac-
tions of the cell, but instead either allow simple electronic connection
to materials that may otherwise be very difﬁcult to connect to a cell
terminal, or are included to reduce the electronic resistance of an
electrode. In a lithium-ion cell, for example, the negative-electrode
current collector is usually made from copper foil, and the positive-
electrode current collector is usually made from aluminum foil. The
current collector in the positive electrode of a dry cell is carbon.12
The observant reader will note the conspicuous absence of two very
important chemistries in Table 1.1—nickel-metal hydride and lithium-
ion cells. The principle of operation of these two advanced types of
cell is somewhat different from the chemical processes that we are
describing in this section, and so detailed discussion is reserved until
Sections 1.4 and 1.5. For now, it is sufﬁcient to note that these cells
also have negative electrodes, positive electrodes, electrolyte, and
a separator.
1.2.1
The discharge process
Electrochemical potential energy at the negative electrode favors a
chemical process that would release electrons into the external circuit
and positively charged ions into the electrolyte. Also, electrochemical
potential energy at the positive electrode favors a chemical process
that would accept electrons from the external circuit and positively
charged ions from the electrolyte. The resulting electrical pressure or
potential difference between the terminals of the cell is called the cell
voltage or electromotive force (EMF).
This stored potential energy can be released and converted to
useful work only when pathways are available for electrons and pos-
itively charged ions to travel from the negative electrode to the posi-
tive electrode. The electrolyte provides an always-available medium
for positive-ion movement, but the separator prevents electron move-
ment within the cell (hence preventing an internal short circuit). In
order for electrons to move, an external electrical circuit must be com-
pleted, connecting the negative and positive electrodes electronically.
When a circuit is completed, the cell discharges its energy through the

8
battery management systems: volume i, battery modeling
13 Although, we will see that with
lithium-ion cells, the reference is often
chosen to be with respect to Li+/Li,
or the potential at which Li+ + e−
spontaneously converts to Li(s).
circuit, or load, and converts the stored chemical potential energy into
electrical energy.
1.2.2
The charge process
In primary cells, this electrochemical reaction is not reversible. Dur-
ing discharge, the chemical compounds are permanently changed
and electrical energy is released until the original compounds are
completely exhausted. Primary cells can be used only once.
In secondary or rechargeable cells, the electrochemical reaction is
reversible. The original chemical compounds can be reconstituted by
the application of an electrical potential across the electrodes that is
higher than the cell’s own electrical potential. This injects energy into
the cell, causing electrons and positive ions to move from the positive
electrode back to the negative electrode, thus storing charge.
Secondary cells can be discharged and recharged many times.
During charge, cations move from the positive to the negative elec-
trode through the electrolyte, and electrons move from the positive
to the negative electrode through the external circuit. The energy in-
jected into the cell transforms the active chemicals to their original
state.
1.3
Materials choice
The voltage generated across the terminals of a cell is directly related
to the types of materials used in the positive and negative electrodes.
When designing and analyzing a cell, it is often convenient to con-
sider the electrodes separately. However, it doesn’t make sense to talk
about the voltage of an electrode by itself. Voltage is a difference in po-
tential, and when dealing with a single electrode, what two potentials
are being differenced?
There is a similar problem in the ﬁeld of electrical circuit analysis.
The solution in that case is to arbitrarily select a point in the circuit
whose potential is deﬁned to be “zero volts” or “ground,” against
which all other potentials in the circuit are measured. We apply the
same basic solution when analyzing an electrochemical electrode. We
consider a potential difference between the electrode under study
and a hypothetical reference electrode, which may or may not be a
part of the actual cell being designed or analyzed. Often, this refer-
ence is chosen to be in terms of the standard hydrogen electrode, and
the potential at which 2H+ + 2e−spontaneously converts to H2(g) is
deﬁned to be zero volts.13
The electrode potentials of some common electrode half reactions,
known as an electrochemical series, are shown in Table 1.2. Compounds

1. battery boot camp
9
Reducing elements
C
H
Oxidizing elements
Solid
Liquid
Gas
Unknown
Atomic #
Rf
Hg
Symbol
Atomic weight
Name
State at room temperature
1
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
2
3
4
5
6
7
Groups
Periods
Copper
63.546
18 
1 
2 
8 
18 
32 
1 
79
Au
Gold
196.966569
18 
2 
8 
18 
1 
30
Zn
65.38
Zinc
2 
8 
18 
32 
18 
80
Hg
Mercury
200.59
2 
2 
8 
18 
32 
18 
81
Tl
Thallium
204.3833
3 
2 
6
C
Carbon
12.0107
4 
8 
2 
14
Si
Silicon
28.0855
4 
2 
8 
18 
32 
18 
82
Pb
Lead
207.2
4 
2 
7
5 
N
Nitrogen
14.0067
8 
2 
15
P
Phosphorus
30.973762
5 
2 
8
O
Oxygen
15.9994
6 
8 
2 
16
S
Sulfur
32.065
6 
2 
8 
18 
34
Se
78.96
Selenium
6 
2 
8 
18 
32 
18 
84
Po
Polonium
(209)
6 
2 
9
7 
F
Fluorine
18.9984032
8 
2 
17
Chlorine
35.453
7 
Cl
2 
8 
18 
35
Bromine
79.904
7 
Br
2 
8 
18 
32 
18 
85
At
Astatine
(210)
7 
2 
8 
18 
32 
18 
86
Rn
Radon
(222)
8 
2 
8 
18 
54
Xe
Xenon
131.293
18 
8 
2 
8 
18 
36
Kr
Krypton
83.798
8 
8 
2 
18
Ar
Argon
39.948
8 
2 
10
Ne
Neon
20.1797
8 
2 
He
2
Helium
4.002602
2 
8 
18 
32 
32 
18 
(294)
118
Uuo
Ununoctium
8 
2 
8 
18 
32 
32 
18 
117
Uus
Ununseptium
(294)
7 
2 
8 
18 
32 
32 
18 
116
Lv
Livermorium
(293)
6 
2 
8 
18 
32 
32 
115
Uup
(288)
18 
5 
Ununpentium
2 
8 
18 
32 
32 
18 
112
Cn
Copernicium
(285)
2 
2 
8 
18 
32 
32 
1 
111
Rg
Roentgenium
(280)
18 
2 
8 
18 
32 
2 
32 
107
Bh
(272)
13 
Bohrium
2 
8 
18 
32 
2 
106
Sg
(271)
12 
32 
Seaborgium
2 
8 
18 
32 
2 
105
Db
Dubnium
(268)
32 
11 
2 
8 
18 
32 
18 
8 
88
Ra
Radium
(226)
2 
2 
8 
18 
32 
18 
8 
1 
87
Fr
Francium
(223)
1
1
H
Hydrogen
1.00794
8 
13
Al
26.9815386
3 
2 
Aluminum
2 
8 
1 
11
Na
Sodium
22.9897693
2 
1 
8 
18 
18 
8 
55
Cs
Cesium
132.90545
12
Mg
2 
8 
2 
Magnesium
24.3050
2 
8 
21
Sc
Scandium
44.955912
9 
2 
2 
8 
22
Ti
Titanium
47.867
10 
2 
2 
8 
18 
32 
2 
104
Rf
32 
10 
Rutherfordium
(265)
2 
8 
18 
2 
57
La
Lanthanum
138.90547
18 
9 
2 
8 
18 
2 
9 
58
Ce
Cerium
140.116
19 
2 
8 
18 
2 
59
Pr
140.90765
21 
8 
Praseodymium
2 
8 
18 
2 
60
Nd
Neodymium
144.242
22 
8 
2 
8 
18 
32 
2 
8 
101
Md
Mendelevium
(258)
31 
2 
8 
18 
32 
2 
32 
103
Lr
Lawrencium
(262)
9 
2 
8 
18 
32 
2 
32 
108
Hs
Hassium
14 
(277)
2 
8 
2 
Ni
Nickel
58.6934
16 
28
2 
8 
18 
32 
32 
110
Ds
(281)
17 
1 
Darmstadtium
2 
8 
18 
32
Ge
4 
Germanium
72.64
2 
8 
18 
33
As
Arsenic
5 
74.92160
2 
8 
18 
32 
18 
83
Bi
Bismuth
5 
208.98040
2 
8 
18 
31
Ga
69.723
3 
Gallium
2 
8 
18 
18 
49
In
114.818
3 
Indium
2 
8 
18 
18 
50
Sn
Tin
4 
118.710
2 
8 
18 
18 
51
Sb
5 
121.760
Antimony
2 
8 
18 
18 
52
Te
6 
127.60
Tellurium
2 
8 
18 
18 
53
I
126.90447
7 
Iodine
2 
8 
18 
2 
32 
71
Lu
174.9668
9 
Lutetium
2 
8 
18 
2 
8 
70
Yb
173.054
32 
Ytterbium
2 
8 
18 
2 
8 
Tm
168.93421
31 
69
Thulium
2 
8 
18 
32 
2 
8 
102
No
(259)
32 
Nobelium
2 
8 
18 
2 
8 
68
Er
167.259
30 
Erbium
2 
8 
18 
32 
2 
8 
100
Fm
(257)
30 
Fermium
2 
8 
18 
2 
8 
67
Ho
164.93032
29 
Holmium
2 
8 
18 
2 
65
Tb
158.92535
27 
8 
Terbium
2 
8 
18 
32 
2 
25 
96
Cm
(247)
9 
Curium
2 
8 
18 
32 
2 
(247)
97
Bk
27 
8 
Berkelium
2 
8 
18 
32 
2 
8 
98
Cf
(251)
28 
Californium
2 
8 
18 
2 
8 
66
Dy
28 
162.500
Dysprosium
2 
8 
18 
2 
25 
64
Gd
157.25
9 
Gadolinium
2 
8 
18 
32 
2 
8 
99
Es
(252)
29 
Einsteinium
2 
8 
18 
46
Pd
106.42
18 
Palladium
2 
8 
18 
18 
47
Ag
107.8682
1 
Silver
2 
8 
18 
18 
48
Cd
112.411
2 
Cadmium
2 
8 
18 
32 
32 
18 
113
Uut
(284)
3 
Ununtrium
2 
8 
18 
32 
32 
18 
114
Fl
(289)
4 
Flerovium
2 
8 
18 
32 
2 
8 
95
Am
(243)
25 
Americium
2 
8 
18 
2 
8 
63
Eu
151.964
25 
Europium
2 
8 
18 
2 
8 
62
Sm
150.36
24 
Samarium
2 
8 
18 
32 
2 
94
Pu
(244)
24 
8 
Plutonium
2 
8 
18 
2 
8 
61
Pm
(145)
23 
Promethium
2 
8 
18 
32 
2 
9 
93
Np
(237)
22 
Neptunium
2 
8 
18 
32 
2 
9 
92
U
238.02891
21 
Uranium
2 
8 
18 
32 
2 
32 
109
Mt
(276)
15 
Meitnerium
2 
8 
18 
13 
43
Tc
(98)
2 
Technetium
2 
8 
18 
1 
44
Ru
101.07
14 
Ruthenium
2 
8 
18 
1 
45
Rh
16 
102.90550
Rhodium
2 
8 
18 
32 
2 
89
Ac
(227)
18 
9 
Actinium
2 
8 
18 
32 
2 
90
Th
18 
10 
232.0381
Thorium
2 
8 
18 
32 
2 
91
Pa
231.03588
20 
9 
Protactinium
Metalloids
Other
Halogens
Noble
gases
transition
metals
Transition
Nonmetals
89 ⌧ 103
57 − 71
nonmetals
Metals
Post−
metals
Actinoids
Lanthanoids
earth
metals
Alkali
metals
For elements with no stable isotopes, the mass number of the isotope with the longest half−life is in parentheses.
Alkali
3 
8 
18 
8 
1 
37
Rb
Rubidium
85.4678
2 
8 
8 
 1 
19
K
Potassium
39.0983
2 
1 
3
Li
Lithium
6.941
4
Be
Beryllium
9.012182
2 
2 
2 
8 
18 
38
Sr
Strontium
87.62
8 
2 
2 
8 
18 
56
Ba
Barium
137.327
18 
8 
2 
2 
8 
18 
39
Y
Yttrium
88.90585
9 
2 
2 
8 
18 
40
Zr
Zirconium
91.224
10 
2 
2 
8 
18 
32 
72
Hf
Hafnium
178.49
10 
2 
2 
8 
23
V
Vanadium
50.9415
11 
2 
2 
8 
18 
41
Nb
Niobium
92.90638
12 
1 
2 
8 
18 
32 
73
Ta
Tantalum
180.94788
11 
2 
2 
8 
24
Cr
Chromium
51.9961
13 
1 
2 
8 
18 
42
Mo
Molybdenum
95.96
13 
1 
2 
8 
18 
32 
74
W
Tungsten
183.84
12 
2 
2 
8 
13 
25
Mn
Manganese
54.938045
2 
2 
8 
18 
32 
2 
75
Re
Rhenium
186.207
13 
2 
8 
26
Fe
Iron
55.845
14 
2 
2 
8 
18 
32 
2 
76
Os
Osmium
190.23
14 
2 
8 
27
Co
Cobalt
58.933195
15 
2 
2 
8 
18 
32 
2 
77
Ir
Iridium
192.217
15 
2 
8 
18 
32 
78
Pt
Platinum
195.084
17 
1 
2 
8 
20
Ca
Calcium
40.078
8 
2 
2 
8 
29
Cu
2 
2 
5
B
Boron
10.811
Figure 1.5: Periodic table of the elements.

10
battery management systems: volume i, battery modeling
14 It is still common to speak of shells
despite the advances in understanding
of the quantum-mechanical nature of
electrons. For the purpose of this book,
an understanding of the Bohr model is
sufﬁcient.
with more negative electrode potentials are used for negative elec-
trodes and those with more positive electrode potentials for positive
electrodes. The larger the difference between the electrode potentials
of the negative and positive electrodes, the greater the cell voltage.
The values for the table entries are reduction potentials. Fluorine,
F2(g), has the most positive number in the table, indicating that it re-
duces most easily, and therefore is the best oxidizing agent of those
listed. Lithium, Li(s), has the most negative number in the table, in-
dicating that it would rather undergo oxidation (and hence is the
strongest reducing agent of those listed). If we were to create a cell
combining the top and bottom reactions, the cell voltage would be
2.87 V −(−3.04 V) = 5.91 V (but so far we cannot, since there is no
known electrolyte that will withstand that high a voltage without
decomposing).
The electrochemical series is good for quantitative analysis, but
an exhaustive table of all possible oxidation/reduction reactions is
unwieldy and not necessarily intuitive. For qualitative analysis, we
may consider the periodic table of the elements, such as in Fig. 1.5,
where the relative reducing and oxidizing capabilities of the elements
are indicated by the arrow below the table.
Each box in the periodic table corresponds to a particular element.
The number in the top-left of each box is the element’s atomic number
(the number of protons in the nucleus of the atom). The number
in the bottom-left of the box is the atomic weight, or the ratio of the
average mass per atom of the element to 1/12 of the mass of an atom
of 12C. The series of numbers to the right of each box is arrangement
of electrons in orbitals or shells in a Bohr or classical model of the
atom.14 Some examples of the electron orbital occupancies are shown
in Fig. 1.6.
Cathode (reduction) half-reaction
Standard potential E0 (volts)
Li+ + e−⇒Li(s)
−3.01
K+ + e−⇒K(s)
−2.92
Ca2+ + 2e−⇒Ca(s)
−2.84
Na+ + e−⇒Na(s)
−2.71
Zn2+ + 2e−⇒Zn(s)
−0.76
2H+ + 2e−⇒H2(g)
0.00
Cu2+ + 2e−⇒Cu(s)
0.34
O3(g) + 2H+ + 2e−⇒O2(g) + H2O(l)
2.07
F2(g) + 2e−⇒2F−
2.87
Table 1.2: Standard potentials of elec-
trode reactions at 25 ◦C.
(Condensed from Table 2.2 in Broad-
head, J. and Kuo, H.C., Handbook of
Batteries, D. Linden and T.B. Reddy, eds.,
3d, McGraw-Hill, 2002.)

1. battery boot camp
11
Lithium: 1 valence electron
+3
+6
+27
Carbon: 4 valence electrons
Cobalt: 2 valence electrons
Figure 1.6: Schematic of some elements,
showing electron conﬁgurations in
different shells, and highlighting the
number of valence electrons.
The elements in the table are color-coded to highlight elements
that behave in similar ways to each other. For example, we see that
the strong reducing elements are grouped to the left, while the strong
oxidizing elements are grouped to the right. Elements within each
individual group (generally) have the same number of valence electrons,
or number of electrons in their outer valence shell (but, transition met-
als are a little strange). Because the number of valence electrons de-
termines how the atom reacts chemically with other atoms, elements
within a particular group tend to have similar chemical properties.
All the elements in any one period have the same number of electron
shells or orbits, which corresponds to the number of possible energy
levels of the electrons in the atom. The period number corresponds to
the number of electron shells.
Atoms with one or two valence electrons more than a closed shell
are highly reactive because the extra electrons are easily removed to
form positive ions. Reducing agents have a surplus of valence-shell
electrons, which they donate in a redox reaction, becoming oxidized.
Alkaline metals, group 1, have only one valence electron, and alkaline
earth metals, group 2, have only two valence electrons, so elements in
these groups are highly reactive.
Atoms with one or two valence electrons fewer than a closed shell
are also highly reactive because of a tendency either to gain the miss-
ing electrons and form negative ions, or to share electrons and form
covalent bonds. Oxidizing agents have a deﬁcit of valence-shell elec-
trons and accept electrons in a redox reaction, becoming reduced.
Halogens, group 17, are short only one valence electron, and so are
highly reactive.
When the outer electron shell is full, as in the noble gases in group 18,
there are no “free” electrons available to take part in chemical reac-
tions. This is the lowest energy state for a species, and hence these
atoms tend to be chemically nonreactive or inert.
1.4
Insertion electrode cells
Relatively recently, new cell chemistries have been developed us-
ing alternative chemical reactions to the traditional redox scheme.
Metal hydride cells, such as nickel-metal hydride, depend on the abil-
ity of some metals to absorb large quantities of hydrogen without
chemically changing the composition of the metal itself (much like a
sponge absorbs water without undergoing a chemical change). These
metallic alloys, termed hydrides, can provide a storage sink for hydro-
gen, which can reversibly react in battery-cell chemistry. Such metals
or alloys are used for the negative electrodes. The positive electrode
is nickel hydroxide (NiOOH) as in NiCd batteries. The electrolyte,

12
battery management systems: volume i, battery modeling
15 Note that the Energizer® “e2 Lithium”
is not a lithium-ion cell. It is a standard
nonrechargeable 1.5 V galvanic cell
with lithium/iron-disulﬁde (Li/FeS2)
chemistry.
which is also a hydrogen-absorbent aqueous solution such as potas-
sium hydroxide (KOH), takes no part in the reaction but serves to
transport hydrogen H+ ions (protons) between the electrodes. As we
will see in the next section, lithium-ion cells work in a similar way.
1.5
Lithium-ion cell preview
This book focuses on lithium-ion cells (although much that we cover
is quite general and could be applied to other chemistries). Lithium-
ion cells have several advantages over other chemistries:
• They operate at higher voltages than other rechargeable cells,
typically about 3.7 V for lithium-ion versus 1.2 V for NiMH or
NiCd. Because of this, they tend to have higher energy density
also.
• The higher voltage means that a single cell can often be used in a
particular application rather than multiple NiMH or NiCd cells in
series. While NiCd and NiMH do not require battery management
circuitry for safe operation, all battery packs can potentially beneﬁt
from battery management: the battery management circuitry for
lithium-ion can be simpliﬁed by this reduced cell count.
• Lithium-ion cells also have a lower self-discharge rate than other
types of rechargeable cells. NiMH and NiCd cells can lose any-
where from 1–5 % of their charge per day, even if they are not
installed in a device. Lithium-ion cells, on the other hand, will
retain most of their charge even after months of storage.
Lithium-ion cells are at a disadvantage to other chemistries in other
respects:
• Lithium-ion cells are more expensive than similar capacity NiMH
or NiCd cells. This is in part because they are presently manufac-
tured in much smaller numbers than NiMH or NiCd. As volumes
increase, prices are expected to come down.
• Lithium-ion cells are very sensitive to overcharge and often in-
clude special circuitry that prevents damage by disconnecting
the cell from the circuit if an attempt is made to operate the cell
outside of its design voltage range. This adds to the cost and com-
plexity of manufacture, and to the complexity of battery chargers.
The cost of the protection circuitry may not scale as favorably with
volume as the cost of the manufacturing process itself, and as it is
possible for the circuitry itself to fail, the reliability of the overall
battery system can be degraded.
• Lithium-ion cells are not available in standard cells sizes (AA, C,
and D) like NiMH and NiCd cells.15 And, different lithium-ion

1. battery boot camp
13
16 In some applications, such as station-
ary battery systems for the telecom
industry, standard chargers are spec-
iﬁed, which largely mitigates this
disadvantage.
cells in the reasonably common “18650” or “26650” form factors
may internally comprise different types of lithium-ion electrochem-
istry that are not compatible with each other. So, because of their
different shapes and sizes and internal chemistries, each type of
lithium-ion cell tends to require a speciﬁc matching charger de-
signed to accommodate it. This means that lithium-ion battery
chargers are more expensive and more difﬁcult to ﬁnd than NiMH
and NiCd battery chargers.16
Lithium-ion cells work differently from the electrochemical cells
that we looked at earlier in this chapter. Traditional electrochemical
cells depend on redox reactions that chemically change the reacting
species at the electrode surfaces. Consider, for example, a lead-acid
cell. On discharge, lead (Pb) from the negative electrode reacts with
HSO−
4 in the electrolyte, producing hydrogen ions (protons), emitting
two electrons to the external circuit, and forming solid lead sulfate
(PbSO4) crystals on the surface of the negative electrode. We can
write,
Pb(s) + HSO−
4(aq) ⇒PbSO4(s) + H+
(aq) + 2e−.
In the positive electrode, lead oxide (PbO2) and HSO−
4 from the elec-
trolyte react with hydrogen ions, consuming electrons and forming
solid lead sulfate crystals on the surface of the positive electrode. We
can write,
PbO2(s) + HSO−
4(aq) + 3H+
(aq) + 2e−⇒PbSO4(s) + 2H2O(l).
Lithium-ion cells work differently. Like NiMH cells, they are
insertion-electrode cells. Lithium does not react with the electrode
materials, per se. Instead, lithium is either absorbed from the elec-
trolyte and inserted into the structure of the electrode material (a
process called intercalation), or is expelled from the electrode material
into the electrolyte (deintercalation), depending on the direction of
current ﬂow.
For this to work, the electrodes must have two key properties.
First, they must have open-crystal structures, pervaded with empty
pathways or “corridors” that are large enough for lithium to move
through freely. Thus, lithium can be inserted into the vacancies in
the structure from the electrolyte, can be removed from the vacancies
in the structure, and is free to move among the vacant spaces within
the crystalline structure. Second, the electrodes must also be able to
deliver or accept compensating electrons to/from the external circuit
at the same time.
The crystal structure itself is not changed chemically by the inser-
tion or removal of lithium. However, structural changes of the crystal
lattice can occur. For example, small volume changes, generally on

14
battery management systems: volume i, battery modeling
Negative electrode
(e.g., graphite)
Discharge
Charge
Positive electrode
(e.g., LiCoO2)
Separator
Figure 1.7: Simpliﬁed schematic of
lithium-ion cell operation.
the order of about 10 % or less, are observed as lithium is added or
removed. The presence of lithium can also cause nonuniform dis-
tortions to the shape of the crystalline structure, and these phase
transitions can sometimes result in permanent damage to the material.
To compensate, the cell is designed to be operated in regimes where
these distortions are minimized.
We begin describing lithium-ion cell operation using the simpliﬁed
schematic of Fig. 1.7. (We will reﬁne this understanding as the chap-
ter proceeds.) In the ﬁgure, the negative and positive electrodes are
drawn as crystal structures comprising layers of electrode material.
Lithium, drawn as small spheres, can be added to or removed from
the spaces between the layers.
Within the electrodes, lithium is stored as independent charge-
neutral atoms. Each lithium atom’s valence electron is very loosely
shared with neighboring atoms in the crystal structure. As such, the
lithium is not tightly bonded in one place and is actually quite free
to move around. Lithium enters and exits the surface of the electrode,
but diffuses within the layered open crystal structure to equalize the
concentration of lithium within the vacant spaces of the electrode.
During discharge, lithium atoms at the surface of the negative elec-
trode give up electrons—which travel through the external circuit—
and become positive lithium ions, Li+—which exit the crystal struc-
ture of the electrode and dissolve into the electrolyte. We can write,
Li ⇒Li+ + e−. Conversely, lithium ions proximate to the surface of
the positive electrode receive electrons from the external circuit, and
the resulting charge-neutral lithium atoms enter the crystal structure
of the electrode. We can write, Li+ + e−⇒Li.
The process is completely reversible. Thus the lithium ions pass
back and forth between the electrodes during charging and discharg-
ing. This has given rise to the terms rocking chair, swing, or shuttlecock
cells to describe lithium-ion cells. The intercalation mechanism is
much gentler than an electrochemical reaction, so lithium-ion cells
have much longer lives than other secondary cells.
Until now, we have treated lithium-ion cell electrodes as homo-
geneous crystalline blocks. However, this is not actually the case.
Instead, the electrodes are manufactured from millions of small elec-
trode particles. This is done to increase the surface area of the elec-
trodes, allowing easier lithium entrance/egress, decreasing overall
cell resistance, and enhancing power delivery capability. For exam-
ple, Fig. 1.8 shows a scanning electron microscope (SEM) image of
a lithium-ion cell’s negative electrode comprising graphite particles.
The two images are of the same material at different magniﬁcations.

1. battery boot camp
15
Figure 1.8: Scanning electron micro-
scope (SEM) images of MTI-brand
mesophase carbonaceous spheres
(graphite).
(Images courtesy Sangwoo Han.)
17 The images shown above are of an
electrode with a 90:5:5 ratio of active
material to carbon black to PVdF.
Fig. 1.9 shows an SEM image of a positive electrode comprising
lithium-manganese-oxide particles. The two images are of the same
material at different magniﬁcations. We see that the particles have
distinctly different shape and size from the graphite particles.
Figure 1.9: SEM images of Aldrich-
brand lithium manganese oxide (LMO).
(Images courtesy Sangwoo Han.)
Fig. 1.10 shows cross-sections of an electrode. On the left, the
electrode has been sliced by a razor blade; on the right, a focused
ion beam (FIB) was used to mill a more precise cross-section, cutting
through particles in the process. We see that the electrode structure is
quite porous—electrolyte ﬁlls the pores between particles.
Figure 1.10: Focused ion beam (FIB)
image of proﬁle of LMO electrode (left)
and FIB milled slice of LMO (right).
(Images courtesy Sangwoo Han.)
Mixed in with the primary electrode materials are binders, such as
polyvinylidene ﬂuoride (PVdF), to adhere the particles together, and
conductive additives, such as carbon black, to enhance electron con-
duction, which is otherwise poor, especially in positive electrode ma-
terials. These additives are not “active” portions of the cell chemistry,
and so are not always mentioned when discussing the composition of
lithium-ion cells, but they are always present.17

16
battery management systems: volume i, battery modeling
Figure 1.11: Atomic structure of lithi-
ated graphite.
(Drawn with VESTA. See, Momma,
K. and Izumi, F., “VESTA 3 for three-
dimensional visualization of crystal,
volumetric and morphology data,”
Journal of Applied Crystallography, 44,
1272–1276 (2011).)
Figure 1.12: Microstructure of natu-
ral graphite (top) and hard carbon
(bottom).
(Adapted from Fig. 4 in Wakihara,
M. “Recent developments in lithium
ion batteries,” Materials Science and
Engineering R33, 2001, 109–134, with
permission from Elsevier.)
1.5.1
Negative electrodes
We now begin to describe the materials that are commonly used
as electrodes for lithium-ion cells. Presently, the vast majority of
commercial lithium-ion cells use some form of graphite (C6) for the
negative-electrode material. Graphite comprises multiple graphene
layers, in which hexagonal C6 structures are tightly bonded together.
The graphene layers are stacked loosely on top of each other, held
together only by weak van der Waals forces; lithium intercalates be-
tween these layers. This is shown in Fig. 1.11, where carbon atoms
are drawn as gray spheres joined by covalent bonds to neighbor-
ing carbon atoms in the graphene layers, and the lithium atoms
are drawn as purple spheres. There is sufﬁcient room between the
graphene layers for the lithium atoms to be able to move freely.
Several different forms of graphite are used in lithium-ion cells.
Two examples are illustrated in Fig. 1.12, where the lines depict
graphene segments, and lithium is able to reside in the voids between
graphene layers. The difference is in the degree of uniformity of the
graphene layers within the microstructures of the particles. Natural
and synthetic graphite tends to be the most uniform; natural “hard”
or disordered carbons are less uniform, having many small pockets
of graphene layers, arranged in random conﬁgurations. The different
types of graphite have different voltage properties, capacities, and
aging characteristics, but operate in essentially the same fashion.
The maximum amount of lithium that can be stored in graphite is
one atom of lithium per six atoms of carbon; the minimum amount
is zero. Therefore, when talking about the degree of lithiation of a
graphite electrode, we use notation LixC6, where 0 ≤x ≤1. Clearly,
when viewed at the atomistic level, there is either a single lithium
atom or no lithium atom at all for any given C6 site. But, when the
entire electrode is considered, some fraction of the total number of C6
sites is occupied, and that fraction is the value of x. When the cell is
charged, the negative electrode is highly lithiated, and x is close to 1.
When the cell is discharged, the negative electrode is largely depleted
of lithium, and x is close to zero.
Alternative materials are being investigated for use as negative
electrodes. Lithium titanate (Li4Ti5O12, also known as lithium titanate
oxide or LTO) allows much faster charging—without harmful side
reactions—than graphite. The suppression of side reactions also
yields cell lifetimes of many tens of thousands of charge/discharge
cycles. However, the use of LTO also results in a cell voltages being
reduced by about 1.4 V with respect to an equivalent cell having a
graphite negative electrode and thus yields lower energy density.
Silicon structures are also being researched, with the potential of

1. battery boot camp
17
Figure 1.13: Crystal structure of lithium
cobalt oxide (LCO).
(Drawn with VESTA. See, Momma,
K. and Izumi, F., “VESTA 3 for three-
dimensional visualization of crystal,
volumetric and morphology data,”
Journal of Applied Crystallography, 44,
1272–1276 (2011).)
Figure 1.14: Crystal structure of lithium
manganese oxide (LMO).
(Drawn with VESTA. See, Momma,
K. and Izumi, F., “VESTA 3 for three-
dimensional visualization of crystal,
volumetric and morphology data,”
Journal of Applied Crystallography, 44,
1272–1276 (2011).)
much higher energy densities than graphite since up to four atoms of
lithium can be stored per atom of silicon. However, this causes very
large changes in the volume of the silicon structures when lithium
intercalates, leading to rapid structural breakdown and poor cell
lifetimes. At this point it remains to be seen what technology will
replace graphite negative electrodes in the future.
1.5.2
Positive electrodes
There is much more variability in the choice of materials to be used
in positive electrodes for lithium-ion cells. In 1980, John B. Goodenough
discovered that lithium cobalt oxide (LixCoO2, also known as LCO)
was a viable intercalation compound. Fig. 1.13 shows the crystal
structure of LCO. The blue spheres represent cobalt atoms, the red
spheres represent oxygen atoms, and the purple spheres represent
lithium atoms. The amount of lithium in the structure is variable, but
the cobalt-oxygen structures are ﬁxed, and these are drawn as linked
blue polyhedra (speciﬁcally, octahedra) to highlight the fact that the
layers of cobalt oxide do not change—only the degree of lithiation of
the structure can change. It is because of these layers, which behave
somewhat like graphene in graphite, that this material is often called
a layered cathode. A difference is that the lithium atoms in LCO act
like pillars in the structure, keeping the cobalt-oxide layers apart. If
too much lithium is removed, then the crystal structure collapses, and
lithium can no longer enter between the layers. To avoid this collapse,
only about half the theoretic capacity is usable (“x” in LixCoO2 is
permitted to use only about half of its theoretic range of 0 to 1).
LCO is commonly used in lithium-ion cells for portable electronics
but suffers some problems when trying to scale up to larger cells for
grid storage and vehicular applications. The principal problem is that
cobalt is rare, toxic, and expensive. Nickel can be substituted for the
cobalt sites, resulting in higher energy density (higher voltages at
same capacity), but the resulting cell is not very stable thermally (it
tends to catch ﬁre). Aluminum, chromium, and manganese can be
substituted as well, resulting in somewhat different properties. Often,
a combination of transition metals is used. For example, a lithium
nickel manganese cobalt oxide (NMC) electrode comprises a blend
of nickel, manganese, and cobalt, which retains the layered structure,
and has properties from all three constituent metals. A lithium nickel
cobalt aluminum oxide (NCA) electrode blends nickel, cobalt, and
aluminum.
In 1983, Goodenough and Thackery proposed lithium manganese
oxide (LixMn2O4, or LMO) as an alternate intercalation compound.
This structure is drawn in Fig. 1.14. Manganese is drawn as blue

18
battery management systems: volume i, battery modeling
18 For this reason, this material is said
to have a “three-dimensional” or 3D
structure. By referring back to Fig. 1.13,
we see that LCO has a two-dimensional
structure, and by looking forward to
Fig. 1.15, we see that LFP has a one-
dimensional structure.
Figure 1.15: Crystal structure of lithium
iron phosphate (LFP).
(Drawn with VESTA. See, Momma,
K. and Izumi, F., “VESTA 3 for three-
dimensional visualization of crystal,
volumetric and morphology data,”
Journal of Applied Crystallography, 44,
1272–1276 (2011).)
spheres, oxygen as red spheres, and lithium as purple spheres. The
manganese oxide forms octahedral crystals in a pattern known as
a cubic spinel structure, which is quite complicated and difﬁcult to
view in a two-dimensional projection. An interesting feature of this
structure is that there are tunnels through it from each side, allowing
lithium movement from front to back, from left to right, and from top
to bottom.18 These degrees of freedom make it easy for lithium to
move within the structure, decreasing the resistance of the cell.
The value of “x” in LixMn2O4 typically varies between 0 and 1,
but can go as high as 2. Values of x greater than one are usually
avoided because the structure of LMO becomes unstable in acidic
conditions when highly lithiated—the crystal structure disintegrates
as manganese is attacked by the acid and dissolves into the elec-
trolyte. Additives can be introduced to the electrolyte to neutral-
ize acidity to help prevent this, but the “art” of additive design is
presently in the realm of black magic and trade secrets. Despite this
serious limitation, LMO is common because it is less expensive and
safer than LCO and has similar energy-storage densities.
More recently, in 1997, Goodenough proposed olivine style phos-
phates as a third major category of positive-electrode material. Lithium
iron phosphate (LixFePO4, or LFP) is the most common in this fam-
ily. Its crystal structure is drawn in Fig. 1.15, where iron is repre-
sented by brown spheres, phosphorus by gray spheres, oxygen by red
spheres, and lithium by purple spheres. Within this overall crystal
structure, FeO6 forms the brown octahedra, and PO4 forms the gray
tetrahedra.
Lithium is free to move only in one-dimensional linear tunnels,
which makes this material quite resistive. In order to compensate for
this high resistance, the electrode particle size is usually chosen to be
very small, minimizing the diffusion length (and hence resistance).
LFP is quite popular due to the material’s low-cost, low-toxicity, and
very stable voltage proﬁle. However, it also produces a lower cell
voltage—by about 0.5 V—than other common positive-electrode ma-
terials and hence also a lower energy density. The amount of lithium
by mass in LFP is also low, resulting in lower speciﬁc energies.
Alternative materials are being investigated for use as positive
electrodes. Many of these are doped with vanadium, which tends
to yield higher cell voltages. However, at present, the challenge is to
develop an electrolyte that will function properly as a lithium ion
conductor, but will not break down at the higher voltages.

1. battery boot camp
19
Figure 1.16: SEM image of raw separa-
tor material.
(Image courtesy Colorado State Univer-
sity.)
1.5.3
Electrolyte: Salt and solvent
The electrolyte is the media that conducts ions between electrodes.
It comprises either a salt, an acid, or a base that is dissolved in a
solvent. Since lithium reacts violently with water, the electrolyte in
a lithium-ion cell is composed of nonaqueous organic solvents plus
a lithium salt and acts purely as an ionic conducting medium, not
taking part in the chemical reaction. The most commonly used salt
is lithium hexaﬂuorophosphate (LiPF6), which disassociates in the
solvent into Li+ and PF−
6 , but other candidates include LiBF4 and
LiClO4.
Common solvents include ethylene carbonate (EC), propylene
carbonate (PC), dimethyl carbonate (DMC), ethyl methyl carbonate
(EMC), and diethyl carbonate (DEC). The chemical structure of each
of these is drawn in Table 1.3. A distinguishing feature of each is the
double-bonded oxygen at the top of the molecule, which has a slight
negative charge. To compensate, the remainder of the molecule has a
slight positive charge. This polarization is what supports ionizing the
salt in the solution and conduction of an ionic current.
EC
PC
DMC
EMC
DEC
CH2
O
C
O
O
C
H2
CH
CH3
O
C
O
O
C
H2
CH3
O
C
O
O
CH3
CH3
O
C
O
O
CH2
C
H3
CH2
CH3
O
C
O
O
CH2
CH3
Table 1.3: Formulation of solvents
commonly found in lithium-ion cells.
The solvent does not participate in the chemical processes of the
cell, so we typically ignore it in our models (different solvents have
different properties with regard to aging, low-temperature perfor-
mance, and so forth, so the choice is important, but it doesn’t factor
in directly). So, we often talk about the salt as being the same thing
as the electrolyte, even though the electrolyte also includes the sol-
vent.
1.5.4
Separator
The separator in a lithium-ion cell is a permeable membrane with
holes large enough to let lithium ions pass through unimpeded, but
small enough that the negative- and positive-electrode particles do
not make contact through the holes (which would short-circuit the
cell). It is also an electronic insulator. An SEM image of a separator
is shown in Fig. 1.16. To get a feel for the relative size of the pore

20
battery management systems: volume i, battery modeling
Figure 1.17: Lithium-manganese-oxide
particle on top of separator material.
(Image courtesy Sangwoo Han.)
openings in the separator compared to an active-material particle, an
atomic force microscopy (AFM) image of a lithium-manganese-oxide
particle on top of a typical separator material is shown in Fig. 1.17.
The ﬁbrous nature of this particular type of separator is evident,
where the pores are smaller than the most obvious depressions be-
tween the ﬁbers. The vast scale differences between particle size and
pore size of the separator material is also quite apparent. The separa-
tor is typically on the order of 20 µm thick; pore size is on the order
of 50 Å; and this particular particle’s size is on the order of 5 µm in
diameter.
1.6
Manufacturing
Some idea of how lithium-ion cells are manufactured can aid un-
derstanding how they work. The basic elements are the same for all
kinds of lithium-ion cell, but there are some variations based on form
factor:
• Cylindrical cells are . . . cylindrical, and are encased in metal cans.
• Prismatic cells are . . . prismatic, and are also encased in metal cans.
• Pouch cells are also ﬂat and are encased in soft pouches.
Some examples of each form factor are shown in Fig. 1.18. In each
case, the cells all contain one or more negative and positive electrodes
(which are electrically connected inside the cell, forming a single log-
ical negative and positive electrode), separator(s), and electrolyte (as
previously discussed). Cylindrical cells are historically most common,
but prismatic and pouch cells are ﬁnding heavy use for high-capacity
battery applications to optimize the use of volume in high-capacity
battery packs, since the more rectangular shapes pack together better.
Cylindrical cells
Prismatic cells
Pouch cells
Figure 1.18: Different common form
factors for lithium-ion cells.

1. battery boot camp
21
19 Green and purple coloring for the
negative- and positive-electrode active
materials, respectively, is used in this
book purely for illustrative purposes.
Orange and gray are used to repre-
sent copper and aluminum current
collectors, respectively.
1.6.1
Electrode coating
The negative and positive electrodes in lithium-ion cells are of sim-
ilar form and are made by similar processes on similar or identical
equipment. The active electrode materials are coated on both sides of
thin metallic foils (the foils are on the order of 20 µm thick) that act as
the current collectors, conducting the current into and out of the cell.
This is illustrated in Fig. 1.19.
Positive current collector
Positive-electrode active material
Negative current collector
Negative-electrode active material
Figure 1.19: Electrode active material
coats both sides of metal foil current
collector.
Both negative- and positive-electrode active materials are deliv-
ered to the factory in the form of black powder.19 To the untrained
eye they are nearly indistinguishable. Because contamination be-
tween negative- and positive-electrode materials would ruin a cell,
great care must be taken to prevent these materials from coming into
contact with each other. For this reason the different electrodes are
usually processed in different rooms.
The metal electrode foils are delivered on large reels, typically
about 0.5 m wide, with copper for the negative-electrode current
collector and aluminum for the positive-electrode current collector.
These reels are mounted directly on the coating machines where the
foil is unreeled as it is fed into the machine through precision rollers.
The electrode active materials are mixed with a conductive binder
and a solvent to form a slurry that is spread on the surface of the foil.
A knife edge is located just above the foil, and the thickness of the
electrode coating is controlled by adjusting the gap between the knife
edge and the foil. (The thickness of the two electrodes will generally
be different as the volumetric energy densities of the materials is
generally different.) After being coated on both sides, the foil is fed
directly into a long drying oven to evaporate the solvent from the
slurry and to bake the electrode material onto the foil. As the coated
foil exits the oven it is re-reeled. The process as described so far is
accomplished by an electrode coating machine, which might look
something like the illustration in Fig. 1.20.
The coated foils are subsequently fed into a calendaring (i.e., press-
ing) and slitting machine. Calendaring is done to compress the
electrode active material, compacting the spaces between particles,
pressing out porosity. Slitting cuts the foil into narrower strips of the
desired width. Later they are cut to length. Any burrs on the edges

22
battery management systems: volume i, battery modeling
Unwinder
Two-sided coater
Dryers
Winder
Figure 1.20: Electrode coating machine.
Mandrel
Positive
Negative
Separator
electrode
electrode
Figure 1.22: Construction of a cylindri-
cal cell.
Mandrel Positive
Negative
Separator
electrode
electrode
Figure 1.23: Construction of a prismatic
cell.
of the foil strips could give rise to internal short circuits in the cells so
the slitting machine must be very precisely manufactured and main-
tained. The calendaring and slitting is accomplished by a machine
that might look something like the illustration in Fig. 1.21.
Unwinder
Roll press
Slitter
Winder
Thickness
inspection
Figure 1.21: Calendaring and slitting
machine.
1.6.2
Cell assembly
The electrodes are now ready to be assembled into cells. For cylin-
drical cells, the negative- and positive-electrode foils are cut into two
long strips that are wound on a cylindrical mandrel, together with
the separator that keeps them apart, to form a structure called a jelly
roll. A cutaway diagram of a cylindrical cell is illustrated in Fig. 1.22.
The mandrel is attached directly to the positive-electrode current col-
lector and becomes the cell’s positive terminal; the negative-electrode
current collector is attached to the cell’s negative terminal.
Prismatic cells are constructed similarly, but by winding the
electrode-coated current-collector foils on a ﬂat mandrel instead of
a cylindrical mandrel. This is illustrated in Fig. 1.23. The ﬂat mandrel
causes the jelly-roll structure to be more prismatic than cylindrical in
shape; once inserted into its can, the external appearance is prismatic.
The next stage is to connect the electrode structure to the terminals

1. battery boot camp
23
Positive
Negative
Separator
electrode
electrode
Figure 1.25: Stacked construction of a
pouch cell.
and any internal electronic safety devices, and to insert this sub-
assembly into a metal can. The can is then sealed via laser welding or
ultrasonic heating, retaining a small opening. Electrolyte is injected
into this opening, and the opening is closed. Addition of the elec-
trolyte must be carried out in a dry room since the electrolyte reacts
with water. Lithium hexaﬂuorophosphate (LiPF6), for instance, one of
the most commonly used electrolyte salts, reacts with water to form
toxic hydroﬂuoric acid (HF), which can attack the positive-electrode
active materials and lead to premature cell failure. Afterward, the
cell is given an identiﬁcation code with a label or by printing a batch
or serial number directly on the case. The ﬁnal assembly is accom-
plished by a machine that might look something like the illustration
in Fig. 1.24.
Unwinder
Roller/
cutter
Canning
process
process
Inspection
Cap welding
Electrolyte
ﬁll
Sealed
welding
Packing to
formation
Figure 1.24: Cell construction machine.
Construction of pouch cells is somewhat different. Instead of
winding long electrode strips around a mandrel, electrode plates
are stamped out of the reels of electrode-coated foil. Negative- and
positive-electrode plates are alternately stacked, with separator ma-
terial between them, as shown in Fig. 1.25. All negative-electrode
tabs are welded in parallel and to the cell’s negative terminal; all
positive-electrode tabs are welded in parallel and to the cell’s positive
terminal.
1.6.3
Formation
Lithium-ion cells are fabricated in a completely discharged state (all
of the lithium is in the positive electrode). So, once the cell assembly
is complete, the cell must be put through at least one precisely con-
trolled charge cycle to activate the working materials, transforming
them into their usable form. This ﬁrst charge begins with a low volt-
age and builds up gradually until the cell is fully charged. This is
called the formation process.

24
battery management systems: volume i, battery modeling
The organic solvents used in most lithium-ion cells naturally tend
to react violently with graphitic negative electrodes. This would
appear to be a “deal breaker,” but it turns out that the reaction is
self-limiting. The process can be compared to what happens when
aluminum is exposed to air. Aluminum reacts rapidly with oxygen to
form a ﬁlm of aluminum oxide on its surface. This aluminum oxide
prevents oxygen from reaching the underlying aluminum metal and
so inhibits further reaction. In lithium-ion cells, the reaction of the
solvent with the graphite in the negative electrode creates a passivat-
ing ﬁlm on the surface of the graphite, known as the solid electrolyte
interphase (SEI) layer, which is electrically insulating yet provides
sufﬁcient ionic conductivity for lithium to intercalate into and dein-
tercalate out of the electrode particles readily. This SEI layer inhibits
solvents from reaching the underlying graphite and so protects the
graphite from further reaction.
The SEI is both a blessing and a curse. It is necessary for the
proper safe operation of the cell, but it also increases the resistance
of the cell and consumes lithium when being formed, decreasing
the cell’s capacity. Fortunately, once the SEI ﬁlm is formed during
the ﬁrst charge cycle, it remains fairly stable and tends to grow only
slowly as the cell is used. Even so, SEI growth is considered one of
the principal aging mechanisms that lead to the cell wearing out.
During cell formation, data are also collected from the charger
and recorded. The spread of the performance measurements across
many cells gives an indication of whether the manufacturing process
is under control. Although not the prime purpose of formation, the
process allows a signiﬁcant percentage of early-life cell failures due
to manufacturing defects to occur in the manufacturer’s plant rather
than in the customers’ products.
Tight tolerances and strict process controls are essential through-
out the manufacturing process. Contamination, physical damage,
and burrs on the electrodes are particularly dangerous because they
can cause penetration of the separator and give rise to internal short
circuits in the cell. There are no protection methods that can prevent
or control this. Cleanliness is essential to prevent contamination, and
cells are normally manufactured in clean-room conditions, with con-
trolled access to the assembly facilities via air showers.
1.7
Failure modes
This book focuses on the operation of ideal cells, with the ultimate
direction leading toward battery controls. To be able to effect opti-
mal battery controls, however, an understanding of the potential cell

1. battery boot camp
25
failure modes is essential. Failures occur because of cell design faults,
poorly controlled manufacturing processes, aging, uncontrolled oper-
ations, and abuse. Battery controls can’t do too much about the ﬁrst
two (it’s too late!), but can do something about the others. Here, we
brieﬂy look at some qualitative aspects relating to postmanufacture
cell failure.
1.7.1
“Normal” aging
Cell performance naturally deteriorates gradually with time due to
unwanted chemical side reactions and physical changes to the active
chemicals. Aging is generally irreversible and eventually results
in cell failure. The following are some examples of causes (not all
chemistries are susceptible to all of these mechanisms).
Corrosion refers to deterioration due to chemical interaction with
the environment. It is a catch-all term for any number of undesirable
side reactions that can occur within a cell. Some examples include
reaction between the solvent and the current collectors and reaction
between the solvent and the electrode active and inactive materials.
In some cases, products of these reactions can themselves have a
corrosive effect on other cell components.
Lithium-ion cells having graphitic negative electrodes are prone to
a particular kind of corrosion known as passivation. The solvent in the
electrolyte is not chemically stable at the high voltages found in most
lithium-ion cells, and it reacts with the graphite particles. This forms
a passivation layer of reaction products on the surface of the particles,
which is known as the solid–electrolyte interphase or SEI ﬁlm. This ﬁlm
protects the graphite against further reaction, greatly slowing down
the process of passivation. However, SEI continues to grow at a slow
rate throughout the cell’s lifetime.
Some chemistries naturally produce gaseous products when charg-
ing, which ideally return to their prior aqueous state when discharg-
ing. However, if the gases leak due to a breach in the cell enclosure,
capacity is lost. In many cases this can also be dangerous as in some
cells the released gases are explosive (e.g., lead-acid cells give off
oxygen and hydrogen when overcharged). In sealed cells, pressure
buildup can lead to the rupture or explosion of the cell, unless the
cell has a release vent to allow the escape of the gasses.
Chemical redox cells are also naturally susceptible to crystal for-
mation. When material is removed from an electrode during dis-
charge, it will not generally return to the same location when the cell
is recharged. Instead, crystal structures will tend to form on the elec-
trode surfaces. As the crystals grow, this reduces the effective surface

26
battery management systems: volume i, battery modeling
20 A good rule of thumb for lithium-ion
chemistries is that if you are comfort-
able at a certain temperature, the cell is
also “comfortable” at that temperature.
If it’s too hot or too cold for your tastes,
it’s probably too hot or too cold for the
cell as well.
area of the electrodes, increasing resistance and hence decreasing
their ability to deliver high power.
A particular example of crystal growth is when metallic dendrites
form at the surface of an electrode. These treelike structures can
grow through the separator, causing an increase in the cell’s self-
discharge rate or even a short circuit. For example, in lithium-ion
cells, low-temperature operation or overcurrent during charging can
cause deposition of lithium metal on the negative-electrode particles,
leading to the growth of lithium dendrites.
Charging and discharging intercalation-based electrodes causes
volume changes, which stress the electrodes and can lead to crack-
ing of the active materials. In some lithium-ion positive-electrode
materials, it can cause structural collapse, which prevents the elec-
trode from intercalating or deintercalating lithium. Strains on the
binder materials and conductive additives can lead to loss of contact
between particles, increasing resistance.
Any of these causes lead to one or more of the following undesir-
able effects:
• Increased internal impedance: The resistance of the cell tends to
increase as it ages. This limits the power that the cell is capable
of delivering, leading to power fade.
• Reduced capacity: The capacity of a cell tends to decline as it ages.
In some chemistries, some capacity can be recovered through
reconditioning the cell by subjecting the cell to one or more deep
discharges, but the general trend is in the downward direction.
The decline of capacity over time is known as capacity fade.
• Increased self-discharge: Due to electrode swelling, which puts pres-
sure on the separator; dendritic growth, which penetrates the sepa-
rator; or local overheating, which melts and thins the separator, the
self-discharge rate of a cell tends to increase as it ages as well.
Aging processes are generally accelerated by elevated temperatures.
The best way to extend a cell’s life is to maintain its temperature in
an acceptable range.20
1.7.2
Uncontrolled operating conditions and abuse
Good battery cells are not immune to failure, which can be provoked
by the way they are used or abused. “Bad things” to do to a cell
include using an unsuitable charging proﬁle and/or overcharging,
and exposing it to high ambient or storage temperatures.
Cells will also fail when subjected to physical abuse such as
dropping, crushing, puncture, impact, immersion in ﬂuids, freez-
ing, or contact with ﬁre, any of which could happen to an automotive

1. battery boot camp
27
battery during an accident, for instance. It is generally accepted that
a cell is not required to survive all these trials; however, it should not
itself cause an increased hazard or safety problem in these circum-
stances.
There are several possible failure modes associated with the com-
plete breakdown of the cell, but it is rarely possible to predict which
one will occur. It depends very much on the circumstances.
• Open-circuit failure: This is a fail-safe mode for the cell but possibly
not for the application. Once the current path is cut and the cell
is isolated, further damage to the cell is limited. This may not
suit the user, however. If one cell of a multicell series-connected
battery fails open-circuit, then the whole battery will be out of
commission.
• Short-circuit failure: If one cell of a series-connected battery fails
because of a short circuit, the rest of the cells may be slightly over-
loaded, but the battery will continue to provide power to its load.
This may be important in emergency situations.
Short circuits may be external to the cell or internal within the
cell. The battery management system (BMS) should be able to isolate
cells from an external short, but there’s not much the BMS can do
to rescue a cell from an internal short circuit. However, the BMS
and pack design must be able to prevent a single-cell failure from
spreading to other cells; precautions include, for example, careful
fusing, contactor control, and venting.
Within the cell there are different degrees of failure.
• Hard short circuit: Solid connection between electrodes causes
extremely high current ﬂow and complete discharge, resulting in
permanent damage to the cell. The cell voltage collapses to 0 V,
and the cell effectively acts as a resistor in the overall circuit.
• Soft short circuit: This is caused by small localized contact between
electrodes. It may be self-correcting due to melting of the small
regions in contact caused by the high current ﬂow, acting as a local
fuse, and interrupting the short-circuit current. A cell with a soft
short is still operational, but has a high self-discharge rate.
• Explosion and/or ﬁre: The rate of chemical reactions tends to double
for every 10 ◦C increase in temperature. If the heat generated by
these reactions cannot be removed as quickly as it is generated,
this can lead to a further increase in temperature and set up a
self-sustaining uncontrolled positive feedback known as thermal
runaway, leading to a destructive result (ﬁre/explosion). This is
to be avoided at all costs, and the battery pack must incorporate
protection circuits or devices to prevent it.

28
battery management systems: volume i, battery modeling
21 It is not the intention of this book
to cover every common chemistry.
However, the phenomenological
models discussed in Chap. 2 can be
applied readily to any chemistry. The
microscale models in Chap. 3 can also
apply to any chemistry, with the un-
derstanding that the equations that
describe intercalation compounds are
not needed when modeling cells that
do not have insertion electrodes. The
continuum-scale models in Chap. 4
and the thermal models in Chap. 7
apply to any porous-electrode type cell,
including NiMH. The methods pre-
sented in Chaps. 5 and 6 for reducing
model-order complexity could be used
on other similar sets of equations mod-
eling different chemistries. In fact, this
is illustrated in the appendix, which
shows how to model the operation of
a supercapacitor using the methods of
this book.
1.8
Where to from here?
In this chapter, we have covered a lot of fundamental background
topics relating to how electrochemical cells—and especially lithium-
ion cells—work at the level of the chemistry.21 We are now ready to
begin looking at how a cell behaves electrically, making mathematical
models that can predict the voltage response of a cell to an input-
current stimulus.
The ﬁrst model type that we look at is designed from a phe-
nomenological point of view, using electric circuit elements as analogs
to observed behaviors of cells. Later models will “look inside” the
cell, using sophisticated analysis of the internal electrochemistry, to
predict both internal and external behaviors.
Both types of model are useful, but the electrochemical models
provide more physical insight than the circuit models and can be
used by advanced battery control methods to derive an optimal trade-
off between the performance delivered by a cell and the amount of in-
cremental degradation experienced by the cell in doing so. However,
the electrochemical models are computationally very complex. To
overcome this limitation, we introduce reduced-order physics-based
cell models that approximate the electrochemical model predictions
very closely but have computational complexity similar to circuit
models.
In the ﬁnal chapter, we look at thermal aspects: how is heat gener-
ated or sunk in a cell? How does the temperature of the cell evolve
over time? By the end of the book, we will have developed a solid
understanding of how to model battery-cell operation with a high
degree of accuracy.

2.1
Open-circuit voltage . . . . . . 30
2.2
SOC dependence . . . . . . . . 30
2.3
Equivalent series resistance . . 33
2.4
Diffusion voltages . . . . . . . 34
2.5
Rough parameter values. . . . 38
2.6
Warburg impedance . . . . . . 40
2.7
Hysteresis voltages . . . . . . . 41
2.8
ESC cell model . . . . . . . . . 44
2.9
Laboratory equipment . . . . . 44
2.10 OCV-relationship lab tests . . 45
2.11 Dynamic-relationship tests . . 53
2.12 Example results. . . . . . . . . 57
2.13 Where to from here? . . . . . . 59
2.14 MATLAB ESC toolbox . . . . 59
2
Equivalent-Circuit Models
In this book, we will study two fundamentally different kinds of cell
model. One is based on understanding the underlying physics that
govern the cell’s operation and building a model of the cell dynam-
ics from the inside out. We will look at such physics-based models
starting in Chap. 3.
In this chapter, we investigate the second, simpler approach to
modeling cell operation, which uses electrical-circuit analogs to de-
ﬁne a behavioral or phenomenological approximation to how a cell’s
voltage responds to different input-current stimuli. That is, we invoke
knowledge of common electronic elements to deﬁne a circuit that
has behavior that closely matches the observed behavior of the bat-
tery cell. The equations that describe the circuit therefore also closely
describe the observed operation of the cell.
Such models are called equivalent-circuit models. We recognize
that the circuit elements in the model are not meant to describe the
construction of the cell. If we were to open up a cell, we should not
expect to ﬁnd voltage sources, resistors, capacitors, or the like! Rather,
the circuit acts as a description of the cell’s behavior, and the various
circuit elements act as analogs to some of the internal processes.
Because there is a great deal of knowledge relating to how circuit
elements behave, circuit models leverage that knowledge to give a
better “feel” for how cells will respond to different usage scenarios.
At present, the majority (if not all) of battery management sys-
tems for large battery packs use some ﬂavor of equivalent-circuit cell
model as a basis for maintaining the proper operating boundaries for
the cells and for estimating critical internal cell states. The simplicity
and robustness of equivalent-circuit models are the main reasons for
this. Equivalent-circuit cell models don’t have all of the features of
physics-based models but are adequate for many applications.
29

30
battery management systems: volume i, battery modeling
−
−
+
+
OCV
i(t)
v(t)
Figure 2.1: Trivial cell model having
constant output voltage.
2.1
Open-circuit voltage (OCV)
We take the approach of building up a circuit model element by
element, starting with an explanation of the predominant observed
behavior. Any difference between predictions by the circuit model
and observed cell behavior is therefore deemed modeling error. This
modeling error is analyzed, and circuit elements are proposed to
reﬁne the model to reduce this modeling error, until only a small
level of error remains—small enough that we are satisﬁed to accept
the model as “good enough.”
We start by explaining the most fundamental observed behavior
of a battery cell: cells deliver a voltage at their terminals. If you place
a voltmeter across the terminals of a cell, it will register some value.
So, the ﬁrst model we build represents the cell simply as an ideal
voltage source. The schematic for this model is drawn in Fig. 2.1. In
the model, cell terminal voltage v(t) is not a function of load current
i(t), nor is it a function of past cell usage. In fact, voltage is constant.
Period.
This is a pretty poor model of a battery cell because terminal volt-
age of a real cell is dependent on load current, recent usage, and
other factors. However, this model provides a starting point for our
development. Cells do supply a voltage to a load. And, when the cell
is unloaded and in complete equilibrium (a condition that is termed
open circuit), the voltage of the cell is fairly predictable. Hence, the
voltage source in the model is labeled “OCV.” We’ll see that an ideal
voltage source will remain a component of our ﬁnal equivalent-circuit
model.
2.2
State-of-charge dependence
The ﬁrst improvement we make to the simple cell model is a result of
recognizing that the voltage of a fully charged cell is generally higher
than the voltage of a discharged cell. This is not, in fact, always the
case, since the terminal voltage of the cell also depends on dynamic
factors relating to how the cell has been used in the recent past. We
can state, however, that the equilibrium unloaded rest voltage—or
open-circuit voltage—of a fully charged cell is higher than that of a
discharged cell.
So, we can improve our model by including a relationship between
the open-circuit voltage and the charge status of the cell. To do so, we
must ﬁrst deﬁne what we mean by this “charge status.” We therefore
deﬁne the state of charge (SOC) of a cell to be 100 % (or 1.0) when the
cell is fully charged and 0 % (or 0.0) when the cell is fully discharged.
If the cell is at an intermediate state between being fully charged and

2. equivalent-circuit models
31
1 Yes, a “fully discharged” cell still has
charge in it! But, we don’t (intention-
ally) discharge a cell beyond a certain
point because that can cause damage
and possibly a safety concern.
2 Note that total capacity is different
from a cell’s discharge capacity. The
latter is deﬁned as the total amount of
charge removed when discharging a
cell at a constant rate from z = 100 %
until the cell terminal voltage reaches
some minimum cutoff voltage. This
will occur before z = 0 % because
real cells have internal resistance
(and hence, a voltage drop across
the internal resistance). So, a cell’s
discharge capacities are always lower
than its total capacity, unless discharge
occurs at an inﬁnitesimally slow rate.
3 Note that coulombic efﬁciency is
different from energy efﬁciency of a
cell. Coulombic efﬁciency in a typ-
ical lithium-ion cell is around 99 %
or higher and is equal to (charge
out)/(charge in). Energy efﬁciency is
closer to 95 % and is equal to (energy
out)/(energy in). Energy is lost in
resistive heating on both charge and
discharge.
fully discharged, its state of charge is somewhere between 0 % and
100 %. State of charge is a unitless quantity and is denoted in this
book by the symbol z.
To quantify state of charge, we need to know how much charge a
cell holds when it is fully charged versus how much charge remains
when it is fully discharged.1 So, we deﬁne the total charge capacity—
or more simply the total capacity—of a cell to be the total amount of
charge removed when discharging a cell from z = 100 % to z = 0 %.
(This is different from the cell’s total energy capacity, as is discussed
in Chap. 1.) Total capacity is usually measured in ampere-hours (Ah)
or milliampere-hours (mAh), and is denoted by the symbol Q. The
value of total capacity is a parameter of the cell model; that is, it is
a constant that may differ from cell to cell. Total capacity is not a
function of temperature or current, although the total capacity of
a cell does tend to decrease very gradually as the cell ages due to
undesired parasitic chemical side reactions and structural breakdown
of the cell’s electrode materials.2
We can model changes to state of charge using an ordinary differ-
ential equation as
.z(t) = −η(t)i(t)/Q,
(2.1)
where we use the “dot” symbol in this book to indicate a time deriva-
tive (e.g., .z(t) = dz(t)/dt), and where the sign of i(t) is positive on
discharge. Hence, positive (discharge) current lowers the cell’s state
of charge, and negative (charge) current increases the cell’s state of
charge. Care must be taken with units: i(t) is measured in amperes,
and to be compatible, Q must be converted to ampere-seconds (i.e.,
coulombs). Both z(t) and η(t) are unitless.
The term η(t) is the coulombic efﬁciency or charge efﬁciency of the
cell.3 We model η(t) = 1 at time instants when the sign of current
is positive (discharging), but η(t) ≤1 at time instants when the sign
of current is negative (charging). When charging, most of the charge
that passes through the cell participates in the desired chemical reac-
tions that raise the cell’s state of charge; however, a small fraction of
the charge passing through the cell instead participates in unwanted
side reactions, which do not increase the cell’s state of charge (and
often cause irreversible degradation to the cell as well). Creating an
accurate model of coulombic efﬁciency is a very challenging task,
as its value depends on state of charge, charging rate, temperature,
and the internal electrochemical state of the cell. However, due to
the high coulombic efﬁciencies of lithium-ion cells, the ﬁrst-order
assumption that η is always equal to unity often gives reasonable
overall model ﬁdelity.
We can integrate the instantaneous relationship of Eq. (2.1) to

32
battery management systems: volume i, battery modeling
4 This assumption is often reasonable
if the sampling interval ∆t is short. If
means are available to measure average
current ¯i(k∆t) over the sampling inter-
val, then this equation is exact if i(k∆t)
is replaced by ¯i(k∆t).
0
20
40
60
80
100
2.5
2.75
3
3.25
3.5
3.75
4
4.25
OCV (V)
SOC (%)
OCV for different chemistries at 25°C 
Figure 2.2: Open-circuit voltage as a
function of state of charge for several
common lithium-ion cell chemistries.
−
−
+
+
OCV(z(t))
i(t)
v(t)
Figure 2.3: Improved cell model, with
SOC-dependent voltage.
obtain an aggregate equation for a change in state of charge over
some time interval. Given known state of charge at initial time t0 < t,
and known current between times t0 and t, we get
z(t) = z(t0) −1
Q
ˆ t
t0
η(τ)i(τ) dτ.
(2.2)
In this equation, we use τ as a placeholder for the time variable in-
side the integral so that we do not confuse the dummy variable of
integration (which should disappear from the ﬁnal result when the
integral is performed) with the upper limit of integration (which
should be retained in the ﬁnal result).
Many times, we are more interested in a discrete-time model than
a continuous-time model. Discrete-time models assume that the
cell inputs and outputs are measured or sampled at a regular rate
with period ∆t seconds and frequency 1/∆t hertz. Such models are
ready to be used inside inexpensive microcontrollers directly for
battery management systems. To convert Eq. (2.2) to discrete time, let
t0 = k∆t and t = (k + 1)∆t. Then, if we assume that the cell’s input
current is constant over the sampling interval ∆t, we have4
z
!(k + 1)∆t
" = z
!
k∆t
" −∆t
Q η
!
k∆t
"
i
!
k∆t
"
.
(2.3)
Noting that it is cumbersome to carry around the “∆t” factor in the
time index of the model, we deﬁne a new notation. Square brack-
ets “[·]” will be used to denote a discrete-time sample number, and
parenthesis “(·)” will be used to denote an actual time. Then, for ex-
ample, “[k]” is equivalent to “(k∆t).” Rewriting Eq. (2.3) using this
notation, we arrive at
z[k + 1] = z[k] −∆t
Q η[k]i[k].
(2.4)
Having a mathematical model for state of charge, we are now
ready to revise our circuit model. We ﬁrst recognize that a cell’s open-
circuit voltage is a function of its state of charge. Some examples
are drawn in Fig. 2.2. There is some temperature dependence to this
relationship—these curves are drawn for room temperature (25 ◦C).
Also, while these curves are drawn as functions of the cell’s state
of charge, it is also common to see them expressed in terms of the
cell’s depth of discharge (DOD). Depth of discharge is the converse
of state of charge and is expressed either as a fraction or in ampere-
hours. DOD = 1 −z(t) if it is being expressed as a fraction, and
DOD = Q(1 −z(t)) if being expressed in ampere-hours.
The improved cell model, including open-circuit-voltage depen-
dence on the cell’s state of charge, is then depicted in Fig. 2.3. The
ideal voltage source is replaced by a controlled voltage source having

2. equivalent-circuit models
33
−
−
+
+
OCV(z(t))
v(t)
R0
Figure 2.4: Improved cell model, with
SOC-dependent voltage and equivalent
series resistance R0.
5 It is important to understand that
the model comprises both of these
equations together. The model is not a
single stand-alone equation.
value equal to OCV(z(t)). If temperature dependence is required, we
instead use OCV(z(t), T(t)), where T(t) is the cell’s internal tempera-
ture at time t.
The OCV values for a cell are determined empirically at numerous
SOC points via laboratory procedures described in Sec. 2.10. These
values can be stored in a lookup table, such that the OCV function is
evaluated via interpolation between table entries. Alternatively, an
analytic function such as a polynomial could be ﬁt to the data using a
regression technique. The OCV at some given SOC point would then
be computed by evaluating this analytic function.
2.3
Equivalent series resistance
Up until this point, the cell model that we have developed is essen-
tially static. It describes the rest behavior of the cell. Now, we begin
to add dynamic features to the model to describe what happens
when the cell is subjected to a time-varying input current.
The ﬁrst observation that we would like the model to describe is
that the cell’s terminal voltage drops below the open-circuit voltage
when the cell is subjected to a load, and the terminal voltage rises
above the open-circuit voltage when the cell is being charged. This
phenomenon can be explained in part by placing a resistance in se-
ries with the controlled voltage source. The revised model is drawn
in Fig. 2.4. The added circuit component represents the so-called
equivalent series resistance (ESR) of the cell.
In the revised model, the state-of-charge equation remains un-
changed. However, we add a second equation to the model to de-
scribe how to compute the terminal voltage.5 In continuous time, we
have
.z(t) = −η(t)i(t)/Q
v(t) = OCV
!
z(t)
" −i
!
t
"
R0.
With this model, we see that v(t) > OCV
!
z(t)
"
when i(t) < 0 (i.e.,
when charging) and v(t) < OCV
!
z(t)
"
when i(t) > 0 (i.e., when
discharging). This is in agreement with our observation of real cell
performance. In discrete time, the equivalent model is
z[k + 1] = z[k] −∆t
Q η[k]i[k]
v[k] = OCV
!
z[k]
" −i[k]R0.
Note that the presence of this series resistance in the model also
implies that power is dissipated by the cell internal resistance as
heat, and therefore the energy efﬁciency of the cell is not perfect. The

34
battery management systems: volume i, battery modeling
0
10
20
30
40
50
60
3.90
3.95
4.00
4.05
4.10
4.15
Time (min)
Voltage (V)
Response to discharge pulse
Figure 2.5: Polarization evident when
a cell is subjected to a discharge pulse
followed by a rest.
power dissipated by the equivalent series resistance can be expressed
as i2(t) × R0.
Finally, we note that the cell’s resistance is often a function of the
cell’s state of charge and is always a function of the cell’s internal
temperature. The ﬁdelity of the model’s predictions will be enhanced
if these dependencies are taken into account in R0.
This model of a cell is sufﬁcient for many simple electronic-circuit
designs. However, it is not yet adequate for applications in large-scale
battery packs, such as for electric-drive vehicles and grid-storage
systems. There are several other dynamic features that must be
addressed.
2.4
Diffusion voltages
Polarization refers to any departure of the cell’s terminal voltage away
from open-circuit voltage due to a passage of current through the cell.
In the equivalent-circuit model that we have developed so far, we
have modeled instantaneous polarization via the i(t) × R0 term. Real
cells have more complex behavior, where the voltage polarization
slowly develops over time as current is demanded from the cell and
then slowly decays over time when the cell is allowed to rest.
Fig. 2.5 illustrates this slower behavior. The voltage plotted in the
ﬁgure corresponds to the following scenario: (1) the cell is at rest
for the ﬁrst 5 min, and the voltage is constant; (2) the cell is then
subjected to a discharge current pulse of constant magnitude from
t = 5 min until t = 20 min; (3) the load is removed, and the cell is
allowed to rest for the remainder of the test.
The model we have developed so far explains the cell behavior
during the initial rest. It also explains the immediate voltage drop
when current is applied and the immediate voltage recovery when
the current is removed. It is difﬁcult to predict, without further analy-
sis, whether the cell model accurately predicts the voltage during the
discharge interval, since we know that state of charge is decreasing,
and so too the open-circuit voltage is decreasing. But we know for
certain that the third section of the test is not being well modeled. In
this section, we see that voltage is constantly changing, but we also
know that the cell state of charge is not changing since the cell cur-
rent is zero. There is something going on here that is not yet part of
our model.
If you’ve ever played with a ﬂashlight, you are certain to have seen
this phenomenon in action. What happens when your battery is just
about empty? The light produced by the ﬂashlight grows dimmer
and dimmer and becomes indiscernible. But turn the ﬂashlight off
and wait a minute or two. Then turn the ﬂashlight back on—the bulb

2. equivalent-circuit models
35
−
−
+
+
OCV(z(t))
v(t)
C1
R1
R0
Figure 2.6: Circuit that now models
diffusion voltages.
is brighter again! Did the battery magically recharge? No, but its
voltage recovered somewhat from the slow decay in polarization that
we observed in Fig. 2.5, and we are able to get (a little) more light
from the ﬂashlight with nearly empty batteries.
We will ﬁnd out later that this phenomenon is caused by slow dif-
fusion processes of lithium in a lithium-ion cell, so we will refer to
this slowly changing voltage as a diffusion voltage. Its effect can be
approximated closely in a circuit using one or more parallel resistor–
capacitor subcircuits. In Fig. 2.6, the combination of R1 and C1 per-
form this function. In the model, the state-of-charge equation remains
the same as before, but the voltage equation changes to
v(t) = OCV(z(t)) −vC1(t) −vR0(t)
for a continuous-time model and
v[k] = OCV(z[k]) −vC1[k] −vR0[k]
for a discrete-time model. When using data to identify model parameters,
it turns out to be simpler if we write these expressions in terms of ele-
ment currents instead:
v(t) = OCV(z(t)) −R1iR1(t) −R0i(t)
v[k] = OCV(z[k]) −R1iR1[k] −R0i[k].
We ﬁnd an expression for the resistor current iR1(t) as follows.
First, we recognize that the current through R1 plus the current
through C1 must equal i(t). Further, iC1(t) = C1 .vC1(t), which gives
iR1(t) + C1 .vC1(t) = i(t).
Then, since vC1(t) = R1iR1(t),
iR1(t) + R1C1
diR1(t)
dt
= i(t)
diR1(t)
dt
= −
1
R1C1
iR1(t) +
1
R1C1
i(t).
(2.5)
This differential equation can be simulated as is to determine
iR1(t). Alternatively, we can convert it to a discrete-time form. It
turns out that we’ll have to make a similar conversion in the next
section, so to encompass both cases we’ll consider transforming a
generic ordinary differential equation from continuous time to dis-
crete time. Deﬁne
.x(t) = ax(t) + bu(t).
(2.6)
Then, we wish to evaluate x(t) at discrete times t = k∆t, where
x[k] = x(k∆t). We assume that the input u(t) is constant over the

36
battery management systems: volume i, battery modeling
6 The reason for doing this is not imme-
diately apparent. However, it does take
us quickly to the ﬁnal form we desire.
sampling interval. The general solution to Eq. (2.6) turns out to be
x(t) = eatx(0) +
ˆ t
0
ea(t−τ)bu(τ) dτ
#
$%
&
convolution
.
(2.7)
This says that the time response of the ordinary differential equation
comprises a portion depending on the initial condition x(0), and an-
other portion that depends on the input signal u(t). If the ordinary
differential equation is stable, then a < 0 and the contribution of
the initial condition decays. The contribution due to the input sig-
nal dominates in steady state, and the integral that computes that
contribution is known as a convolution integral.
But, where did Eq. (2.7) come from? First, we rearrange Eq. (2.6) as
.x(t) −ax(t) = bu(t).
Then, we multiply both sides of this equation by e−at.6
e−at ' .x(t) −ax(t)
(
= e−atbu(t).
We notice that the left-hand side of this equation can also be written
as
d
dt
)
e−atx(t)
*
,
so we can then write
d
dt[e−atx(t)] = e−atbu(t).
Now, we integrate both sides of this equation between times 0 and t,
being careful to replace t inside the integral with a dummy variable
of integration τ.
ˆ t
0
d
dτ [e−aτx(τ)] dτ =
ˆ t
0
e−aτbu(τ) dτ
ˆ t
0
d [e−aτx(τ)] =
ˆ t
0
e−aτbu(τ) dτ.
Note that the left-hand side of this equation becomes
e−aτx(τ)
++t
0 = e−atx(t) −x(0),
so we have
e−atx(t) −x(0) =
ˆ t
0
e−aτbu(τ) dτ.
Moving x(0) to the right-hand side and multiplying both sides by eat
gives the desired result in Eq. (2.7).

2. equivalent-circuit models
37
Now, beginning with this result, we seek to ﬁnd a discrete-time
relationship. We substitute
x[k + 1] = x((k + 1)∆t)
= ea(k+1)∆tx(0) +
ˆ (k+1)∆t
0
ea((k+1)∆t−τ)bu(τ) dτ.
With malice aforethought, break up the integral into two pieces
x[k + 1] = ea(k+1)∆tx(0) +
ˆ k∆t
0
ea((k+1)∆t−τ)bu(τ) dτ
+
ˆ (k+1)∆t
k∆t
ea((k+1)∆t−τ)bu(τ) dτ.
We factor ea∆t out of the ﬁrst two terms
x[k + 1] = ea∆teak∆tx(0) + ea∆t
ˆ k∆t
0
ea(k∆t−τ)bu(τ) dτ
+
ˆ (k+1)∆t
k∆t
ea((k+1)∆t−τ)bu(τ) dτ.
We can then write this as
x[k + 1] = ea∆t
,
eak∆tx(0) +
ˆ k∆t
0
ea(k∆t−τ)bu(τ) dτ
-
+
ˆ (k+1)∆t
k∆t
ea((k+1)∆t−τ)bu(τ) dτ
= ea∆tx(k∆t) +
ˆ (k+1)∆t
k∆t
ea((k+1)∆t−τ)bu(τ) dτ.
Finally, we write the result using discrete-time notation
x[k + 1] = ea∆tx[k] + ea(k+1)∆t
ˆ (k+1)∆t
k∆t
e−aτbu(τ) dτ.
In the integral that remains, we assume that u(t) is constant from
k∆t to (k + 1)∆t and equal to u(k∆t)
x[k + 1] = ea∆tx[k] + ea(k+1)∆t
,ˆ (k+1)∆t
k∆t
e−aτ dτ
-
bu[k]
= ea∆tx[k] + ea(k+1)∆t
,
−1
a e−aτ
++++
(k+1)∆t
k∆t
-
bu[k]
= ea∆tx[k] + 1
aea(k+1)∆t '
e−ak∆t −e−a(k+1)∆t(
bu[k]
= ea∆tx[k] + 1
a
'
ea∆t −1
(
bu[k].
This is the generic discrete-time ordinary difference equation (ODE) that
is equivalent to the continuous-time ordinary differential equation of

38
battery management systems: volume i, battery modeling
7 Continuous-time ordinary differential
equations and the discrete-time ordi-
nary difference equations both have the
acronym ODE. We reserve the use
of ODE in this book to describe the
discrete-time equations only.
8 This same basic procedure also works
with vector signals, but the exponential
operator in the solution is then the
matrix exponential function, which is
different from the scalar exponential
function.
Eq. (2.6).7,8 To use this result in our battery-cell model, we note the
correspondences between constants in Eqs. (2.5) and (2.6)
a = −
1
R1C1
and
b =
1
R1C1
,
and the correspondences between signals
x[k] = iR1[k]
and
u[k] = i[k].
Substituting these values into the generic result, we get the following
discrete-time equation for the resistor current
iR1[k + 1] = exp
.
−∆t
R1C1
/
iR1[k]
+ (−R1C1)
.
exp
.
−∆t
R1C1
/
−1
/ .
1
R1C1
/
i[k]
= exp
.
−∆t
R1C1
/
iR1[k] +
.
1 −exp
.
−∆t
R1C1
//
i[k].
Summarizing to date, the continuous-time model that describes
the circuit in Fig. 2.6 is
.z(t) = −η(t)i(t)/Q
diR1(t)
dt
= −
1
R1C1
iR1(t) +
1
R1C1
i(t)
v(t) = OCV
!
z(t)
" −R1iR1(t) −R0i
!
t
"
.
The discrete-time model that describes the circuit comprises the fol-
lowing three coupled equations:
z[k + 1] = z[k] −∆t
Q η[k]i[k]
iR1[k + 1] = exp
.
−∆t
R1C1
/
iR1[k] +
.
1 −exp
.
−∆t
R1C1
//
i[k]
v[k] = OCV
!
z[k]
" −R1iR1[k] −R0i[k].
(2.8)
Finally, we note that a cell’s diffusion-voltage response is generally
a function of the cell’s state of charge and its internal temperature.
If R1 and C1 are modeled as functions of z(t) and T(t), the model
predictions can be improved.
2.5
Rough parameter values
We have not yet ﬁnished developing the ﬁnal version of the equivalent-
circuit model of a lithium-ion cell. However, before proceeding, we
spend a short time discussing how one might be able to discern pa-
rameter values for the unknown constants in the model equations.

2. equivalent-circuit models
39
0
10
20
30
40
50
60
3.90
3.95
4.00
4.05
4.10
4.15
Time (min)
Voltage (V)
Response to discharge pulse
∆v0=R0∆i
∆v∞=(R0+R1)∆i
≈4R1C1
Figure 2.7: Measuring parameter values
from a pulse response.
We give a more general procedure later on, but at this point we can
introduce a simple method that helps us understand how the parame-
ters of the equations describe cell responses.
In this section, we assume a model type of the sort developed
to this point, having a single parallel resistor–capacitor subcircuit,
exactly as drawn in Fig. 2.6. To identify the model parameters, we
subject the cell to a constant-current discharge pulse and then allow
the cell to rest while recording the cell’s voltage response (such as is
shown in Fig. 2.7).
At the instant when the discharge current pulse is removed, at
time 20 min, and considering Eq. (2.8), the instantaneous change in
voltage must be equal to the instantaneous change in current multi-
plied by the series resistance R0 because the capacitor voltage cannot
change instantly, and state of charge is not changing when current is
zero. This gives us ∆v0 = R0∆i (with signs computed such that R0
is positive). We know the change in current ∆i because we controlled
its value during the test, and we measure the change in voltage; there-
fore, we can compute the value R0 = |∆v0/∆i|.
Then, we look at the steady-state change in voltage, which we
can approximate by the value around time 60 min. The overall
steady-state voltage change can be found from Eq. (2.8) to be ∆v∞=
(R0 + R1)∆i, again with signs computed so that R0 and R1 are both
positive, knowing that the capacitor voltage will converge to zero in
steady state. Since we know ∆i (it’s the same as when we were com-
puting R0), we measure this new value of ∆v, and as we have already
computed R0, we can compute R1 = |∆v∞/∆i| −R0.
For the cell test conducted to gather the data plotted in Fig. 2.7,
∆i = 5 A, the change in voltage at time 20 min was |∆v| = 41 mV, and
the change in voltage at time 60 min was |∆v| = 120 mV. From these
values, we compute R0 ≈8.2 mΩand R1 ≈15.8 mΩ.
Finally, the pulse response converges to a value close to steady
state in about four time constants of the R–C circuit, where the time
constant of the exponential decay is τ = R1C1. In the example, the
time to convergence is about 60 min −20 min = 40 min = 2, 400 s. So,
for this example, we might estimate
4τ ≈2, 400 s
and
C1 ≈2, 400
4R1
.
Using our prior result for R1, we can compute C1 ≈38 kF.
This method is designed to give rough estimates of the parameters.
Fine-tuning can be done using the approach described in Sec. 2.11.
Further, if the model uses multiple parallel resistor–capacitor subcir-
cuits, themselves connected in series, this simple approach will not
work, and the method of Sec. 2.11 must be used instead.

40
battery management systems: volume i, battery modeling
9 Randles, J.E.B., “Kinetics of rapid
electrode reactions,” Discussions of the
Faraday Society, 1, 1947, pp. 11–19.
Cdl
Rct
Rs
ZW
Figure 2.8: The Randles circuit.
0
3
6
9
12
15
0
2
4
6
8
10
Cell impedance
Real(Z), (mΩ)
−Imag(Z), (mΩ)
Figure 2.9: Nyquist plot of cell
impedance.
2.6
Warburg impedance
In the literature, it is not uncommon to see equivalent-circuit models
containing a so-called Warburg impedance element. For example, the
Randles circuit in Fig. 2.8 is a frequently seen equivalent-circuit model
of a cell (less the open-circuit voltage) that is inspired by electrochem-
ical principles, somewhat like we will see in later chapters.9
In the circuit, Rs models the electrolyte resistance, Rct is the charge-
transfer resistance that models the voltage drop over the electrode–
electrolyte interface due to a load, Cdl is the double-layer capacitance
that models the effect of charges building up in the electrolyte at the
electrode surface, and ZW is the Warburg impedance.
The Warburg impedance models diffusion of lithium ions in the
electrodes. It is frequency dependent, modeled as ZW = AW/
0
jω,
where the constant AW is called the Warburg coefﬁcient, j = √−1,
and ω is the applied frequency in radians per second. The phase
contributed to the circuit by this element is 45◦, which is most eas-
ily observed in a Nyquist plot of a cell’s electrochemical impedance
spectrum as a straight line at 45◦at low frequency. Fig. 2.9 shows a
simulated electrochemical impedance spectrum representing a realis-
tic cell. The equivalent series resistance R0 for this cell is on the order
of 1.5 mΩ, found by the intersection of the curve and the real axis;
this point is the inﬁnite-frequency impedance. The low-frequency
impedance is represented by the straight line at 45◦and models
solid diffusion. At intermediate frequencies, the semicircular loop is
dominated by charge-transfer dynamics, which are modeled in the
equivalent circuit as a single resistor–capacitor pair.
There is no simple ordinary-differential equation for a Warburg
impedance, which makes precise circuit simulation intractable. How-
ever, its effect can be approximated via multiple resistor–capacitor
networks in series, as illustrated in Fig. 2.10.
C1
C2
C3
R1
R2
R3
ZW
=
. . .
Figure 2.10: Approximating a Warburg
impedance with multiple resistor–
capacitor subcircuits.
For an exact equivalence, an inﬁnite number of resistor–capacitor
networks are needed; but, the circuit can often be modeled very
well over some frequency range of interest using a small number
of resistor–capacitor pairs. Also, since the double-layer capacitance
has very little impact on the Randles circuit performance except at
very high frequencies, it is often omitted. With the double-layer ca-
pacitor removed from the circuit, and with the Warburg impedance

2. equivalent-circuit models
41
0
20
40
60
80
100
2.4
2.6
2.8
3.0
3.2
3.4
3.6
3.8
Cell voltage (V)
SOC (%)
Evidence of hysteresis
Figure 2.11: Cell test data giving evi-
dence of hysteresis.
10 Note that this particular cell is a
lithium-ion chemistry with an iron-
phosphate positive electrode. The
very ﬂat OCV characteristics of this
type of cell amplify the importance
of a good hysteresis model. Other
lithium-ion chemistries also exhibit
hysteresis, but the higher slope to their
OCV relationships dilutes the errors
introduced by a poor hysteresis model.
replaced by a small ﬁnite number of parallel resistor–capacitor cir-
cuits, themselves wired in series, the cell model collapses to the one
in Fig. 2.6, with additional resistor–capacitor pairs.
When we discuss implementation of physics-based models, which
have a Warburg-type impedance relationship built in intrinsically, we
will see how to automatically create ordinary-difference equations
that very accurately model the diffusion.
2.7
Hysteresis voltages
With the model we have developed so far, if the cell current is set to
zero, the voltage drop across R0 will immediately fall to zero, and the
voltage drop across the capacitor C1 will decay to zero over time as
the capacitor discharges through R1. That is, the cell terminal voltage
will converge to open-circuit voltage.
However, what we see in practice is different from this. The cell
voltage decays to a value that is somewhat different from OCV, and
the difference depends on the recent history of cell usage. For ex-
ample, we ﬁnd that if we discharge a cell to 50 % SOC and allow the
cell to rest, the equilibrium voltage is lower than OCV. If we charge a
cell to 50 % SOC and allow the cell to rest, the equilibrium voltage is
higher than OCV. These observations indicate that there is hysteresis
in the cell terminal voltage.
Fig. 2.11 shows data collected from a laboratory experiment de-
signed to capture the nature of this hysteresis. The cell is ﬁrst fully
charged before the test begins. Then, the cell is very slowly dis-
charged, at a C/30 rate, down to 0 % SOC. At this slow rate, the
i(t) × R0 and diffusion voltages are very small, so the recorded volt-
age is very close to the equilibrium rest voltage of the cell. This volt-
age trace is the lowest line on the plot.
Then, the cell is very slowly charged, at a C/30 rate, to 95 % SOC;
then the cell is discharged to 5 %, and so forth. Each point on the plot
represents (at least approximately) an equilibrium point. Because of
the space between the lower and upper curves, we discover that for
every SOC there is a range of possible stable rest voltage values.
Vol. II in this book series addresses methods of estimating cell
state of charge using equivalent-circuit cell models. To do this well,
the cell model must be as accurate as possible. From the ﬁgure, we
see that omitting hysteresis in our cell models can lead to large SOC
estimation errors. For example, if we measure a fully rested terminal
voltage of 3.3 V, that could correspond to any SOC between about
20 % and 90 %. We require a good model of hysteresis to know how
different we expect the fully rested terminal voltage to be from open-
circuit voltage.10

42
battery management systems: volume i, battery modeling
Note the distinction between hysteresis and diffusion voltages:
diffusion voltages change with time but hysteresis voltages change
only when SOC changes. They are not directly a function of time.
If a cell is allowed to rest, diffusion voltages will decay to zero, but
hysteresis voltages will not change at all. Any model of hysteresis
must capture this behavior.
The challenge when modeling hysteresis is that it is not very well
understood. A simple model jumps immediately from the lower to
the upper branch of the plot in Fig. 2.11 when current changes from
a discharge to a charge. A somewhat more advanced model changes
hysteresis voltage linearly with a change in SOC. We introduce a
combination of these two approaches here; however, the resulting
model still struggles to explain hysteresis accurately.
2.7.1
SOC-varying hysteresis
Let h(z, t) be the dynamic hysteresis voltage as a function of SOC and
time, and let .z = dz/dt. Then, we model the change in hysteresis
voltage as a function of change in SOC as
dh(z, t)
dz
= γ sgn(.z)
!
M(z, .z) −h(z, t)
"
,
where M(z, .z) is a function that gives the maximum polarization due
to hysteresis as a function of SOC and the rate-of-change of SOC.
Speciﬁcally, we require that M(z, .z) be positive for charge (.z > 0)
and negative for discharge (.z < 0). The M(z, .z) −h(z, t) term in
the differential equation states that the rate-of-change of hysteresis
voltage is proportional to the distance of the present hysteresis value
away from the major hysteresis loop, leading to a kind of exponential
decay of voltage to the major loop. The term in front of this has a
positive constant γ, which tunes the rate of decay, and sgn( .z), which
forces the equation to be stable both for charge and discharge.
To ﬁt the differential equation for h(z, t) into our model, we must
manipulate it to be a differential equation with respect to time, not
with respect to SOC. We accomplish this by multiplying both sides of
the equation by dz/dt.
dh(z, t)
dz
dz
dt = γ sgn(.z)
!
M(z, .z) −h(z, t)
"dz
dt .
We use the chain rule to write the left-hand side of the equation as
dh(z, t)/dt, and we substitute dz/dt = −η(t)i(t)/Q into the right-
hand side, noting that .z sgn(.z) = | .z|. Thus,
.
h(t) = −
++++
η(t)i(t)γ
Q
++++ h(t) +
++++
η(t)i(t)γ
Q
++++ M(z, .z).

2. equivalent-circuit models
43
This may be converted into a difference equation for our discrete-
time application using the technique from Sec. 2.4 (assuming that i(t)
and M(z, .z) are constant over the sample period):
h[k + 1] = exp
.
−
++++
η[k]i[k]γ∆t
Q
++++
/
h[k]
+
.
1 −exp
.
−
++++
η[k]i[k]γ∆t
Q
++++
//
M(z, .z).
Note that this is a nonlinear time-varying system as the factors multi-
plying the state and input change with i[k].
The simplest representation is when M(z, .z) = −M sgn(i[k]), when
h[k + 1] = exp
.
−
++++
η[k]i[k]γ∆t
Q
++++
/
h[k]
−
.
1 −exp
.
−
++++
η[k]i[k]γ∆t
Q
++++
//
M sgn(i[k]).
With this representation −M ≤h[k] ≤M at all times, and h[k]
has units of volts. When attempting to ﬁnd the model parameters,
we will ﬁnd it valuable to rewrite this in an equivalent but slightly
different representation, which has unitless hysteresis state −1 ≤
h[k] ≤1,
h[k + 1] = exp
.
−
++++
η[k]i[k]γ∆t
Q
++++
/
h[k]
−
.
1 −exp
.
−
++++
η[k]i[k]γ∆t
Q
++++
//
sgn(i[k])
Hysteresis voltage = Mh[k].
This makes the output equation linear in M, which will make estimat-
ing M from lab-test data easier.
2.7.2
Instantaneous hysteresis
In addition to the type of dynamic hysteresis that changes as SOC
changes, we also often see beneﬁt in modeling an instantaneous
change in hysteresis voltage when the sign of current changes. Deﬁne
s[k] =
⎧
⎨
⎩
sgn(i[k]),
|i[k]| > 0;
s[k −1],
otherwise.
Then, the instantaneous hysteresis is modeled as
Instantaneous hysteresis voltage = M0s[k],
and overall hysteresis is
Hysteresis voltage = M0s[k] + Mh[k].

44
battery management systems: volume i, battery modeling
−
−
+
+
OCV(z(t))
v(t)
hyst
R1
C1
R0
Figure 2.12: The enhanced self-
correcting cell model equivalent circuit.
Figure 2.13: Sample cell-test equipment.
2.8
Enhanced self-correcting cell model
The enhanced self-correcting (ESC) cell model combines all the afore-
mentioned elements. The model is called enhanced because it includes
a description of hysteresis, unlike some earlier models. The model is
called self-correcting because the model’s predicted terminal voltage
converges to OCV plus hysteresis when the cell rests, and converges
to OCV plus hysteresis minus all the current times resistance terms
on a constant-current event. The ﬁnal circuit diagram for this model
is shown in Fig. 2.12.
The ﬁgure shows an example with a single parallel resistor–
capacitor pair, but the model easily accommodates multiple paral-
lel resistor–capacitor pairs. To compact notation, deﬁne a resistor–
capacitor subcircuit rate factor Fj = exp
'
−∆t
RjCj
(
, and we have
iR[k + 1] =
⎡
⎢⎢⎣
F1
0
· · ·
0
F2
...
...
⎤
⎥⎥⎦
#
$%
&
ARC
iR[k] +
⎡
⎢⎢⎣
(1 −F1)
(1 −F2)
...
⎤
⎥⎥⎦
#
$%
&
BRC
i[k].
Then, if we deﬁne AH[k] = exp
'
−
+++ η[k]i[k]γ∆t
Q
+++
(
, we have the dynamic
aspects of the model described by the matrix-vector relationship
⎡
⎢⎣
z[k + 1]
iR[k + 1]
h[k + 1]
⎤
⎥⎦=
⎡
⎢⎣
1
0
0
0
ARC
0
0
0
AH[k]
⎤
⎥⎦
⎡
⎢⎣
z[k]
iR[k]
h[k]
⎤
⎥⎦
+
⎡
⎢⎣
−η[k]∆t
Q
0
BRC
0
0
(AH[k] −1)
⎤
⎥⎦
:
i[k]
sgn(i[k])
;
.
This is the ESC model state equation. The model’s output equation is
v[k] = OCV(z[k], T[k]) + M0s[k] + Mh[k] −∑
j
RjiRj[k] −R0i[k].
The ESC model comprises these two equations with associated
parameter values ﬁlled in. Note that all model parameters must be
nonnegative.
2.9
Laboratory equipment for cell-data collection
Parameter values for the ESC model are found by ﬁtting the model
equations to data collected from experiments performed on the cells
of interest. These experiments are conducted with the aid of spe-
cially designed laboratory equipment known as battery-cell cyclers

2. equivalent-circuit models
45
Figure 2.14: Sample environmental
chamber.
or battery-cell test equipment. An example cell cycler, manufactured
by Arbin Instruments and resident in the University of Colorado
Colorado Springs’ High-Capacity Battery Research and Test Lab-
oratory, is shown in Fig. 2.13. This particular cycler can perform
independent experiments on up to 12 different cells simultaneously,
controlling each cell’s current according to a user-speciﬁed proﬁle
of demanded current versus time and recording actual cell current,
voltage, and temperature. Each of the 10 thick white cables shown in
the ﬁgure corresponds to a single test channel—the power electronics
designed to conduct an independent test. Each cable contains four
wires internally (two to carry current and two to measure voltage via
a Kelvin connection) and can be connected to a single 0 V to 5 V cell,
commanding current up to ±20 A per test channel. The thinner white
cables are connected to thermistors to measure cell temperature. The
two pairs of thick black cables correspond to two high-current test
channels, capable of commanding current up to ±200 A each. Test
channels may be connected in parallel if more current is needed than
can be supplied or sunk from a single channel.
Battery-cell test equipment is generally custom designed to the
user’s speciﬁcations, so the cycler shown in Fig. 2.13 is discussed
as a representative example only. Systems can be conﬁgured with
more or fewer independent test channels, higher or lower maximum
current, specialized measurement circuitry for three-terminal cells or
for impedance-spectroscopy measurements, and more.
In addition, most tests must be conducted in controlled tempera-
ture settings. Fig. 2.14 shows an environmental chamber manufactured
by Cincinnati Sub-Zero. This particular unit has 8 ft3 of interior space
and is capable of maintaining constant temperatures between −45 ◦C
and 190 ◦C and commanding proﬁles of temperature versus time.
Systems can be conﬁgured with humidity control, wider temperature
ranges, rapid cooling for thermal-shock testing, and more.
2.10
Lab tests to determine OCV relationship
A cell’s open-circuit voltage is a static function of its state of charge
and temperature. All other aspects of a cell’s performance are dy-
namic in some sense. So, we perform separate experiments to collect
data for the OCV versus SOC relationship and for the dynamic rela-
tionship. We ﬁrst discuss experiments to determine the OCV relation-
ship.
The general idea is straightforward. Before the cell test begins, the
cell must be fully charged. Then, the cell is very slowly discharged to
a minimum operating voltage while continuously measuring cell volt-
age and accumulated ampere-hours discharged. The cell is then very

46
battery management systems: volume i, battery modeling
slowly charged to a maximum operating voltage while continuously
measuring cell voltage and accumulated ampere-hours charged.
The purpose of the slow rate is to minimize the excitation of the
dynamic parts of the cell model. We desire to keep the cell in a quasi-
equilibrium state at all times. So, we generally use a C/30 rate, which
is a compromise between the desire to have zero current to have a
true equilibrium and the practical realization that the test will al-
ready require on the order of 60 h to complete with a C/30 discharge
followed by a C/30 charge.
The collected data allow us to create a curve of “discharge OCV”
versus discharge ampere-hours and a curve of “charge OCV” versus
charge ampere-hours. With appropriate conversion between ampere-
hours and state of charge, we then have discharge OCV and charge
OCV versus SOC. These curves are different because (1) the test
is not conducted at zero current, so there will still be some ohmic
and diffusion polarization, and (2) hysteresis is present in the cell
voltage response. We assume that the deviation from true OCV to the
discharge OCV and charge OCV curves is equal in magnitude, so we
approximate the cell’s true OCV as the average of these two values.
When multiple temperatures are considered, there are some impor-
tant subtle issues that must be addressed, which somewhat modiﬁes
how we collect and process data. The ﬁrst is that the initial step of
fully charging a cell is generally deﬁned by a process that is valid
only at a speciﬁc temperature. Often, the manufacturer will state
that the cell must be charged at 25 ◦C (i.e., “room temperature”) at
a speciﬁc constant-current rate (e.g., 1C) until a particular voltage
vmax is reached. Then, the cell must be held at vmax until the charging
current drops below some threshold (e.g., C/30).
So, to charge a cell, we ﬁrst soak the cell at 25 ◦C for at least 2 h to
ensure a uniform temperature throughout the cell. We then charge
the cell according to manufacturer speciﬁcations, using a cutoff cur-
rent of C/30. The cell is now at 100 % state of charge at 25 ◦C. Then
we run experiments at a number of temperatures spread over the
operational range of the cell. These experiments are divided into
four subexperiments, which we denote as test scripts (as different test
programs or scripts must be implemented at different points in the
overall experiment).
OCV test script #1 (at test temperature)
1. Soak the fully charged cell at the test temperature for at least
2 h to ensure a uniform temperature throughout the cell.
2. Discharge the cell at a constant-current rate of C/30 until cell
terminal voltage equals manufacturer-speciﬁed vmin.

2. equivalent-circuit models
47
0
5
10
15
20
25
30
3.0
3.2
3.4
3.6
3.8
4.0
4.2
Time (h)
Voltage (V)
Measured voltage for test script 1  
0
5
10
15
20
25
30
3.0
3.2
3.4
3.6
3.8
4.0
4.2
Time (h)
Voltage (V)
Measured voltage for test script 3  
Figure 2.15: Unprocessed voltage data
from slow-discharge and slow-charge
test, used to determine OCV.
OCV test script #2 (at 25 ◦C)
3. Soak the cell at 25 ◦C for at least 2 h to ensure a uniform temper-
ature throughout the cell.
4. If the cell voltage is below vmin, then charge the cell at a C/30
rate until the voltage is equal to vmin. If the cell voltage is above
vmin, then discharge the cell at a C/30 rate until the voltage is
equal to vmin.
OCV test script #3 (at test temperature)
5. Soak the cell at the test temperature for at least 2 h to ensure a
uniform temperature throughout the cell.
6. Charge the cell at a constant-current rate of C/30 until the cell
terminal voltage equals vmax.
OCV test script #4 (at 25 ◦C)
7. Soak the cell at 25 ◦C for at least 2 h to ensure a uniform temper-
ature throughout the cell.
8. If the cell voltage is below vmax, then charge the cell at a C/30
rate until the voltage is equal to vmax. If the cell voltage is above
vmax, then discharge the cell at a C/30 rate until the voltage is
equal to vmax.
Voltage, accumulated ampere-hours discharged, and accumulated
ampere-hours charged are recorded periodically (e.g., once per sec-
ond) during every step. Because a very low current rate is used, there
is negligible heat generation in the cell, and we can consider all data-
points to be collected at the ambient test temperature for every script
(though temperature data can be measured as well to verify this
assumption).
Sample measured data from test scripts 1 and 3 for a lithium-
ion cell having a lithium-manganese-oxide positive electrode are
plotted in Fig. 2.15. These data were collected at −15 ◦C, where the
cell has a very high resistance. This resistance causes a signiﬁcant
ohmic voltage drop, so cutoff voltages are achieved at the end of
test scripts 1 and 3 far before the cell is fully discharged or charged,
respectively (which is why these tests lasted for less than 30 hours
although a C/30 rate was used). The data processing methods must
take this into account.
There are some subtle points if the test temperature is not 25 ◦C.
Before step 2, the cell is still at 100 % state of charge, but its voltage
will no longer be equal to vmax because OCV is temperature depen-
dent. At the end of step 2, the cell will be at 0 % state of charge only

48
battery management systems: volume i, battery modeling
−25 −15
−5
5
15
25
35
45
0.97
0.98
0.99
1.00
Temperature (°C)
Efficiency (unitless)
Coulombic efficiency
Figure 2.16: Sample coulombic efﬁ-
ciencies for six different lithium-ion
cells.
if the test temperature is 25 ◦C because, again, OCV is temperature
dependent, and the vmin speciﬁcation deﬁnes 0 % SOC only for 25 ◦C.
At other temperatures, the actual state of charge may be above or
below 0 % at the end of step 2. Similarly, at the end of step 6, the cell
will be at 100 % state of charge only if the test temperature is 25 ◦C. At
other temperatures, the actual state of charge may be above or below
100 % at the end of step 6. This is why we must execute test scripts 2
and 4, to ensure that the cell is fully discharged and charged, respec-
tively, before starting test scripts 3 and 1 (for the next temperature to
be tested).
2.10.1
Determining coulombic efﬁciency
These factors impose a requirement that data must be very carefully
processed. Let’s consider processing data for test temperature equal
to 25 ◦C ﬁrst. This is the easiest case because all four scripts are then
executed at 25 ◦C—no other temperatures are involved. And, because
voltages vmax and vmin are calibrated to 25 ◦C, the net ampere-hours
discharged over all steps is equal to the total capacity Q of the cell.
The net number of ampere-hours charged over all steps turns out
to be slightly higher than Q since the coulombic efﬁciency of the cell
is not perfect. We compute the coulombic efﬁciency at 25 ◦C as
η(25 ◦C) = total ampere-hours discharged in all steps at 25 ◦C
total ampere-hours charged in all steps at 25 ◦C .
At a test temperature T different from 25 ◦C, we must follow a
somewhat different approach. We don’t know a priori the cell state of
charge at the end of steps 2 and 6. However, we do know that the cell
is at 0 % SOC at the end of step 4 and is 100 % at the end of step 8.
We use this information to compute ﬁrst the coulombic efﬁciency at
test temperature T:
η(T) =
total ampere-hours discharged
total ampere-hours charged at temperature T
−η(25 ◦C)
total ampere-hours charged at 25 ◦C
total ampere-hours charged at temperature T .
Fig. 2.16 shows coulombic efﬁciency calculations for six different
lithium-ion cells as a function of temperature. The efﬁciency should
always be less than 1, but experimental accuracy of accumulated
ampere-hours is inexact, and these calculations are reasonable, within
experimental error. The ﬁgure shows that the quality of manufacture
of different lithium-ion cells is by no means the same—some have
efﬁciencies consistently above 99.5 %, while others have efﬁciencies as
low as 98 %.

2. equivalent-circuit models
49
0
20
40
60
80
100
3.0
3.2
3.4
3.6
3.8
4.0
4.2
State of charge (%)
Voltage (V)
Voltages versus SOC
 
 
Discharge voltage
Charge voltage
Approximate OCV
Figure 2.17: Unprocessed voltage data
from slow-discharge and slow-charge
test, used to determine OCV.
2.10.2
Determining charge and discharge voltage versus SOC
Now, we can compute a state of charge corresponding to every data
sample in every test. The depth of discharge (in ampere-hours) at
every point in time is calculated as
depth of discharge(t) =
total ampere-hours discharged until t
−η(25 ◦C) × total ampere-hours charged at 25 ◦C until t
−η(T) × total ampere-hours charged at temperature T until t.
Using this metric, the cell capacity Q (measured at temperature T)
is equal to the depth-of-discharge at the end of step 4. Likewise, the
state of charge corresponding to every data sample is then
state of charge(t) = 1 −depth of discharge(t)
Q
.
As a check, the state of charge at the end of step 4 must be 0 %, and
the state of charge at the end of step 8 must be 100 %.
Fig. 2.17 plots discharge voltage from step 2 versus state of charge
(lower solid curve) and charge voltage from step 6 versus state of
charge (upper solid curve). These are the same data as shown in
Fig. 2.15, but are now presented as functions of state of charge rather
than test time. This example shows that there is a challenge in deter-
mining the open-circuit-voltage relationship at all states of charge;
namely, we don’t have discharge voltages at low states of charge be-
cause the test encountered a cutoff voltage of vmin in step 2 before
0 % state of charge was reached, and we don’t have charge voltages at
high states of charge because the test encountered a cutoff voltage of
vmax in step 6 before 100 % state of charge was reached.
2.10.3
Determining approximate OCV at one temperature
There are perhaps many ways to use the available data to produce an
approximate open-circuit-voltage relationship, but here we present
one that has worked well for a number of different cells of different
lithium-ion chemistries. First, we note that we are forced to base
the open-circuit-voltage estimate on the discharge-voltage curve at
high states of charge simply because there is no charge voltage in-
formation available. Similarly, we are forced to base it on the charge-
voltage curve at low states of charge because there is no discharge-
voltage information available. At intermediate states of charge, we
could use both curves, but there should be no abrupt transitions be-
cause neither the discharge- nor charge-voltage curves have sharp
transitions.

50
battery management systems: volume i, battery modeling
We can estimate the cell’s ohmic resistance R0 at high state of
charge by looking at the instantaneous voltage change when the test
moves from step 1 to step 2. We can similarly estimate the ohmic
resistance at low state of charge by looking at the voltage change
when the test moves from step 5 to step 6. Also, we can approximate
the steady-state resistance at 50 % state of charge by considering the
voltage change between the discharge voltage curve and the charge
voltage curve at the 50 % state of charge point.
Then, suppose that we assume that the resistance changes linearly
from its 0 % state of charge value to its 50 % state of charge value,
and then linearly again from its 50 % state of charge value to its 100 %
state of charge value. At states of charge lower than 50 %, the approx-
imate open-circuit voltage is estimated as the charge voltage plus
charge current times resistance at that state of charge, and at states
of charge higher than 50 %, the approximate open-circuit voltage
is estimated as the discharge voltage plus discharge current times
resistance at that state of charge.
Fig. 2.17 shows this approximate open-circuit-voltage estimate as
a dashed line. It is between the charge and discharge voltages, as
it should be, and it also passes through a point exactly in the mid-
dle of these curves at 50 % state of charge, by design. Note that the
curves in the ﬁgure are more widely separated than we would see at
warmer temperatures, because cell resistance is much higher at cold
temperatures, so the effects are more exaggerated than typical.
2.10.4
Determining ﬁnal open-circuit-voltage relationship
Once we have an approximate open-circuit-voltage relationship at
every test temperature, we further process these results to make a
ﬁnal model of the form
OCV(z(t), T(t)) = OCV0(z(t)) + T(t) × OCVrel(z(t)),
where OCV(z(t), T(t)) is the open-circuit-voltage relationship as
a function of present state of charge and temperature, OCV0(z(t))
is the open-circuit-voltage relationship at 0 ◦C , and OCVrel(z(t))
(V/◦C) is the linear temperature-correction factor at each state
of charge. Once OCV0(z(t)) and OCVrel(z(t)) are determined,
OCV(z(t), T(t)) can be computed via two one-dimensional table
lookups, which is very efﬁcient computationally.

2. equivalent-circuit models
51
0
20
40
60
80
100
2.5
3.0
3.5
4.0
State of charge (%)
Open-circuit voltage (V)
OCV versus SOC for six cells at 0°C
0
20
40
60
80
100
−0.5
0
0.5
State of charge (%)
OCV variation (mV/°C)
Per-degree OCV temp. variation
Figure 2.18: Final OCV relationships
for six lithium-ion cells having different
internal chemistries, stored as two
table-lookup functions each.
To make OCV0(z(t)) and OCVrel(z(t)), note that we can write
⎡
⎢⎢⎢⎢⎣
Approx. OCV at SOC z, temp. T1
Approx. OCV at SOC z, temp. T2
...
Approx. OCV at SOC z, temp. Tn
⎤
⎥⎥⎥⎥⎦
#
$%
&
Y
=
⎡
⎢⎢⎢⎢⎣
1
T1
1
T2
...
...
1
Tn
⎤
⎥⎥⎥⎥⎦
#
$%
&
A
:
OCV0(z)
OCVrel(z)
;
#
$%
&
X
at every state of charge z. We have already computed all values in Y
and in A; it remains only to determine the values in X. One way to
do so is to use the least-squares solution, which is written mathemati-
cally as
X = A†Y,
where the dagger symbol (†) represents a matrix pseudo-inverse and
is computed in MATLAB as
X=A\Y;
We ﬁnd that the approximate open-circuit-voltage relationships
are more reliable for temperatures above about 0 ◦C, so we tend
to include only data from those temperatures in the calculation of
OCV0(z) and OCVrel(z).
Fig. 2.18 plots the outcome of this overall process for six different
lithium-ion cells. The top frame shows the OCV0(z) relationship, and
the bottom frame shows the OCVrel(z) relationship. We can see that
different choices in the active materials of the cells can produce signif-
icantly different OCV curves. The two lower-voltage cells have posi-
tive electrodes made from lithium-iron-phosphate (LFP); the higher-
voltage cells have positive electrodes that are made from different
combinations of lithium-manganese-oxide (LMO), lithium-cobalt-
oxide (LCO), and lithium nickel-manganese-cobalt oxide (NMC). The
negative electrodes of these cells are different mixtures of synthetic
and natural graphites.
2.10.5
Modiﬁcation to minimize impact of hysteresis
The procedure for collecting and analyzing data given so far can
produce very accurate open-circuit-voltage curves. However, it does
not take into account the fact that we know that voltage hysteresis
exists. Therefore, unless hysteresis voltage is canceled somehow, the
state of charge at the end of step 2 will not be exactly 0 %, and the
state of charge at the end of step 6 will not be exactly 100 %.
While the mechanism of hysteresis is not well understood (and is
probably different for different lithium-ion electrode chemistries), we
ﬁnd that a modiﬁcation to the above testing methodology based on
analogy to magnetic hysteresis seems to work to eliminate hysteresis

52
battery management systems: volume i, battery modeling
0
5
10
15
20
25
30
2.99
3
3.01
Dither ‘‘chirp’’ signal
Time (min)
Voltage (V)
Figure 2.19: Sample frequency sweep
around vmin appended to step 4.
−25 −15
−5
5
15
25
35
45
0.4
0.6
0.8
1.0
Temperature (°C)
Relative capacity (unitless)
Q(T)/mean total capacity
 
 
Discharge capacity
Charge capacity
Total capacity
Figure 2.20: Illustrating different
measures of capacity.
voltage to a large degree. When a magnetic material is subjected to a
frequency sweep, it tends to become demagnetized as its hysteresis
proﬁle follows a collapsing spiral to zero. Similarly, we propose,
when the hysteretic phenomena in a lithium-ion cell is subjected to a
frequency sweep, the hysteresis voltage is reduced or eliminated.
Fig. 2.19 shows a sample frequency sweep around vmin = 3 V that
could be executed at the end of step 4 to ensure that the cell was fully
discharged before beginning step 5. A similar frequency sweep could
be executed around vmax at the end of step 8 before beginning the
next test at step 1.
This frequency sweep is sometimes called a chirp signal in signal-
processing literature and a dither signal in control-systems literature.
It must have low-enough amplitude such that no damage is caused
to the cell by slightly exceeding the cell’s prescribed voltage limits.
It may also be necessary to execute multiple iterations of this proﬁle
to achieve the desired state of charge. The rest voltage must stabilize
very close to the desired voltage (e.g., to within about a millivolt)
when the proﬁle is complete. (All the prior examples included this
dither approach in the test procedures.)
2.10.6
Illustrating difference between discharge and total capacity
Before leaving this section, we brieﬂy discuss different measures
of capacity. Fig. 2.20 shows three different measures of capacity for
the six cells illustrated in this chapter. The blue solid lines show
discharge capacity at the C/30 rate for the six cells, normalized by
dividing by the cell’s mean total capacity estimate Q. This is equal
to the normalized number of ampere-hours discharged in step 2 and
is not equal to the total capacity of the cell as additional ampere-
hours are discharged in step 4. The green dashed lines show the
normalized charge capacity at the C/30 rate for the six cells. This is
equal to the normalized number of ampere-hours charged in step 6.
This is not equal to the total capacity of the cell as additional ampere-
hours are charged in step 8. Note that because cell resistance is a
function of temperature, the discharge and charge capacities are also
functions of temperature.
Total capacity is shown as the six red lines in the ﬁgure. Total ca-
pacity Q is calculated as the net ampere-hours discharged in steps 2
and 4. We see that (to within experimental error) total capacity is not
a function of temperature. We point out this distinction since most
cell data sheets will give discharge capacity at different discharge
rates, but will not give total capacity; however, the ESC model re-
quires total capacity Q.

2. equivalent-circuit models
53
0
4
8
12
16
20
24
−0.8
−0.4
 0.0
 0.4
 0.8
 1.2
Normalized current for UDDS profile 
Current (×1C)
Time (min)
Figure 2.21: Proﬁle of current versus
time, representative of a UDDS cycle
normalized for a passenger vehicle.
2.11
Lab tests to determine dynamic relationship
Now that we have determined the cell’s OCV relationship, we turn
our attention to ﬁnding the parameters of the dynamic parts of the
ESC cell model. Different cell tests are performed to collect data to
be used to determine these dynamic parameters. The cell must be
exercised with proﬁles of current versus time that are representative
of the ﬁnal application for the resulting model to work best in that
application. Fig. 2.21 shows a sample normalized proﬁle for an auto-
motive application: the urban dynamometer drive schedule (UDDS)
proﬁle. In practice, this proﬁle is multiplied by the C-rate of the cell
to convert to current in amperes.
Before any dynamic testing, the cell is ﬁrst fully charged until it
is at 100 % state of charge at 25 ◦C. Then we run experiments at a
number of temperatures spread over the operational range of the cell.
These experiments are divided into three subexperiments, which we
denote as test scripts (as different test programs or scripts must be
implemented at different points in the overall experiment).
Dynamic test script #1 (at test temperature)
1. Soak the fully charged cell at the test temperature for at least
2 h to ensure a uniform temperature throughout the cell.
2. Discharge the cell using a constant current at a C/1 rate long
enough to deplete about 10 % of capacity (helping ensure we
avoid over-voltage conditions during random charging portions
of the dynamic proﬁle).
3. Execute dynamic proﬁles over the SOC range of interest, nomi-
nally from 90 % SOC down to 10 % SOC.
Dynamic test script #2 (at 25 ◦C)
4. Soak the cell at 25 ◦C for at least 2 h to ensure a uniform temper-
ature throughout the cell.
5. If the cell voltage is below vmin, then charge the cell at a C/30
rate until the voltage is equal to vmin. If the cell voltage is above
vmin, then discharge the cell at a C/30 rate until the voltage is
equal to vmin. Follow-on dither proﬁle(s) can be used to elimi-
nate hysteresis to the greatest degree possible.
Dynamic test script #3 (at 25 ◦C)
6. Charge the cell using a constant current at a C/1 rate until
voltage is equal to vmax. Then, maintain voltage constant at

54
battery management systems: volume i, battery modeling
0
100
200
300
400
500
600
700
3.0
3.5
4.0
Time (min)
Voltage (V)
Output from test script 1
310
320
330
340
3.6
3.7
3.8
3.9
4.0
4.1
Time (min)
Voltage (V)
Zoom on output from test script 1
0
50
100
150
200
250
300
350
3.0
3.1
3.2
3.3
3.4
Time (min)
Voltage (V)
Output from test script 2
0
50
100
150
200
250
300
350
3.0
3.2
3.4
3.6
3.8
4.0
4.2
Time (min)
Voltage (V)
Output from test script 3
Figure 2.22: Dynamic test data.
11 Jackey, R., Plett, G.L., and Klein,
M., “Parameterization of a Battery
Simulation Model Using Numerical
Optimization Methods,” in CD-ROM
Proc. SAE World Congress 2009, Detroit,
MI (April 2009).
vmax until current drops below C/30. Follow-on dither proﬁle(s)
at the end can be used to help eliminate hysteresis.
Voltage, current, temperature, ampere-hours charged, and ampere-
hours discharged are recorded every second. These data are used to
identify all ESC-model parameters, except for the OCV versus SOC
relationship, which has already been described.
Sample output from this process is shown in Fig. 2.22. The top
plot displays voltage versus time for 19 repetitions of the UDDS
proﬁle (with rests in between). The second plot shows a zoom on
to one of those proﬁles. The third plot shows the output from test
script 2 (with six repetitions of a dither proﬁle), and the bottom plot
shows the output from test script 3 (with six repetitions of a dither
proﬁle).
With these data, we wish to ﬁnd parameter values for cell capac-
ity Q, coulombic efﬁciency η, hysteresis rate constant γ, hysteresis
parameters M0 and M, equivalent-series resistance R0, and resistor–
capacitor values for one or more parallel resistor–capacitor subcir-
cuits. Most of these parameters cannot be computed directly from
the measured data; instead, the parameter values must be found us-
ing some kind of optimization approach. This process, in general, is
known as system identiﬁcation.
The basic idea is to (1) choose a set of parameter values, somehow;
(2) simulate the ESC model having those parameter values with the
same input current as was measured during the cell test; (3) compare
the ESC model voltage prediction to the measured voltage proﬁle;
and (4) intelligently modify the parameter values to improve the
model prediction, going back to (2) until optimization is considered
complete.
2.11.1
Simulink design optimization
One approach to this optimization is to use a commercial optimiza-
tion toolbox, and one such example is the MathWorks’ Simulink
Design Optimization toolbox.11 To use this automated approach, one
must ﬁrst create a block diagram to implement the model equations.
Fig. 2.23 shows subsystems that compute the ESC-model state and
output equations, assuming two parallel resistor–capacitor circuits,
η = 1, γ = 3600, and M0 = 0 (different block diagrams could be
generated for different assumptions).
The toolbox automatically generates values for the cell capacity,
resistor–capacitor time constants, the resistor values, and the max-
imum hysteresis value, then runs the model to see how well the
voltage predictions agree with measured data, updates the parameter
estimates, and iterates until it converges on a solution.

2. equivalent-circuit models
55
State equation
i(k)
Note: 1/z blocks are 
"unit delay" operators
iR2(k)
iR2(k+1)
iR1(k+1)
iR1(k)
Hysteresis factor: exp(-abs(i(k)/Q))
h(k)
h(k+1)
z(k)
z(k+1)
4
iR2
3
iR1
2
Hyst
1
SOC
z
1
z
1
z
1
z
1
-u
Sign
eu
1/3600
Delta t
1
|u|
4
Capacity
3
RC-factor2
2
RC-factor1
1
Current
1
1
Output equation
OCV(z(k))
vC2(k)
vC1(k)
M*h(k)
i(k)*R0
1
Voltage
Temperature
SOC
OCV
OCV from SOC
10
R1
9
R2
8
maxHyst
7
R0
6
iR1
5
iR2
4
Hyst
3
SOC
2
Temperature
1
Current
Figure 2.23: Simulink implementation
of ESC model.
Nonlinear system identiﬁcation—such as is implemented in the
Simulink Design Optimization toolbox—is very powerful, but must
be used with a great deal of care. There is no guarantee of arriving
at the “globally optimal” solution; instead, the ﬁnal parameter values
may instead be only “locally optimal.” That is, small modiﬁcations
to the parameter values will not result in a better match between
measured and predicted voltage; however, large modiﬁcations may.
Therefore, it is important to initialize the optimization with parame-
ter values that are already quite good.
This is tricky—how do we ﬁnd good initial guesses for the param-
eter values? The next sections give some guidance, which may in fact
give the ﬁnal answers that are wanted. Reﬁnement is always possible
using nonlinear optimization.
2.11.2
Direct measurement of capacity
One maxim of system identiﬁcation is “Don’t estimate what you
already know.” This is in part an efﬁciency concern: for every new
parameter that must be estimated, computation increases. It is also
an accuracy concern: system identiﬁcation tries to match a model
to an input–output dataset, but cannot guarantee that the internal
states of the model make sense. If you know the actual value of a

56
battery management systems: volume i, battery modeling
12 van Overschee, P., and De Moor,
B., Subspace Identiﬁcation for Linear
Systems—Theory, Implementation, Applica-
tions, Springer (softcover reprint of the
original 1st ed. 1996 edition), 2011.
13 Speciﬁcally, the function subid.m in
“Subspace Identiﬁcation for Linear Sys-
tems” toolbox on MATLAB CENTRAL
ﬁle exchange, by P. Van Overschee,
1995.
parameter, you can remove the parameter from the list of those being
estimated, speeding the process and ensuring that at least that one
parameter value is accurate.
For the dynamic tests, cell coulombic efﬁciency and capacity can
be computed using the same approach as in Sects. 2.10.1 and 2.10.2,
recognizing that the dynamic tests also all start at 100 % SOC and
end at 0 % SOC after the completion of test script 2. This eliminates
two variables from the list of unknown parameters, simplifying the
remaining computations.
2.11.3
Direct computation of resistor–capacitor time constants
Once the cell coulombic efﬁciencies and capacity are known, the
cell state of charge can be computed for every point in time using
Eq. (2.4). Then, the cell open-circuit voltage for every point can be
computed, which leaves the following unexplained part of the mea-
sured cell voltage
˜v[k] = v[k] −OCV(z[k], T[k])
= Mh[k] + M0s[k] −∑
j
RjiRj[k] −R0i[k].
(2.9)
Note that we can compute s[k] directly from the current proﬁle. To
compute h[k] we also require γ; for now, we assume that we know γ
and will ﬁnd a way to optimize its value later. Then, the unexplained
part of the voltage is a linear-time-invariant system with input signals
h[k], s[k], and i[k], and methods exist to ﬁnd the remaining parame-
ters.
The trickiest part is in determining the time constants of the
resistor–capacitor circuits. A method called subspace system identiﬁ-
cation is able to do so using only linear algebra techniques, which
are very fast and have a unique solution.12 It is beyond our scope to
detail these methods here. However, we do note that there is code on
the MathWorks web site that implements what we need.13
2.11.4
Direct computation of M, M0, R0, and Rj
Once we know these time constants, we can compute iRj[k]. Then,
Eq. (2.9) becomes linear in the parameters. That is, we can assemble
matrix
[ ˜v[k]]
# $% &
Y
=
<
h[k]
s[k]
−i[k]
−iRj[k]
=
#
$%
&
A
⎡
⎢⎢⎢⎣
M
M0
R0
Rj
⎤
⎥⎥⎥⎦
#
$%
&
X
.

2. equivalent-circuit models
57
0
50
100
150
200
250
5.2
5.5
5.8
6.0
6.2
Trial value of γ
RMS model error (mV)
Modeling error versus γ
Figure 2.24: Finding optimum value of
hysteresis parameter γ.
0
100
200
300
400
500
600
3.2
3.4
3.6
3.8
4.0
4.2
Time (min)
Terminal voltage (V)
Comparing model to measured
 
 
Measured
Model
275
280
285
290
295
300
305
3.5
3.6
3.7
3.8
Time (min)
Terminal voltage (V)
Comparing model to meas. (zoom)
 
 
Measured
Model
Figure 2.25: ESC-model comparison to
measured voltage for a 25-Ah automo-
tive battery cell at 25 ◦C.
Then, we can ﬁnd the unknown parameter vector via least-squares
solution X = A†Y.
2.11.5
Optimization of γ
The only parameter we haven’t actually computed from the data is
the hysteresis rate constant γ. In Sec. 2.11.3, we assumed that this
value was known, but in fact it is not. What we can do is to bound
γ in some range, and then compute the goodness of ﬁt for the mod-
els optimized to every γ in that range, keeping only the model that
yields the best goodness of ﬁt. Fig. 2.24 shows an example of the root-
mean-squared modeling error resulting from different trial values of
γ for one particular cell test. The data in this ﬁgure were determined
by trying values of γ from 1 to 250, then optimizing all other model
parameters based on that value of γ, and then computing the mod-
eling error. In this case, a value of γ ≈90 gives the best modeling
results overall.
Because of the nonlinearities in the hysteresis model, and because
subspace system identiﬁcation does not necessarily provide a result
that optimizes root-mean-squared error (but nonetheless provides
a very good result), the output of optimizing γ, M0, M, R0, and Rj
can then be used as a good initial guess for a nonlinear optimization,
such as mentioned in Sec. 2.11.1.
2.12
Example results
To give a better feel for the capabilities of an equivalent-circuit type
model, we present some modeling results in this section. Data were
collected from a 25-Ah automotive battery cell using the procedures
outlined in this chapter, and open-circuit voltage and dynamic mod-
eling parameters were estimated from the data (using one resistor–
capacitor subcircuit in the model). Here, we concentrate on simulat-
ing the optimized model open-loop, and comparing its predictions
against the measured voltage data for a test conducted at 25 ◦C.
The top frame of Fig. 2.25 shows an overlay of true and model-
predicted voltage over the entire 10-hour test. The root-mean-squared
difference between the true and model results was 5.37 mV in this
case. The lower frame of the ﬁgure zooms in to one UDDS cycle,
more clearly showing that the circuit model captures the cell perfor-
mance quite well.
Fig. 2.26 shows the optimized parameter values for this cell (as
well as ﬁve others of different size and manufacture) as functions
of test temperature (tests were conducted from −25 ◦C to 45 ◦C in

58
battery management systems: volume i, battery modeling
−25 −15
−5
5
15
25
35
45
0
50
100
150
200
Resistance R0
Temperature (°C)
Resistance (mΩ)
−25 −15
−5
5
15
25
35
45
0
50
100
Resistance Rj
Temperature (°C)
Resistance (mΩ)
−25 −15
−5
5
15
25
35
45
1
2
3
4
5
R−C time constants
Temperature (°C)
Time constants (s)
−25 −15
−5
5
15
25
35
45
0
50
100
Hysteresis M0 parameter
Temperature (°C)
M0 parameter (mV)
−25 −15
−5
5
15
25
35
45
0
100
200
300
400
Hysteresis M parameter
Temperature (°C)
M parameter (mV)
−25 −15
−5
5
15
25
35
45
0
50
100
150
200
250
Hysteresis γ parameter
Temperature (°C)
γ (unitless)
−25 −15
−5
5
15
25
35
45
0
10
20
30
Cell total capacity
Temperature (°C)
Capacity (Ah)
Figure 2.26: Temperature-dependent
ESC-model parameter values identiﬁed
for a sample cell.
14 Lee, J.L., Aldrich, L., Stetzel, K., and
Plett, G.L., “Extended Operating Range
for Reduced-Order Model of Lithium-
Ion Cells,” Journal of Power Sources, 255,
2014, pp. 85–100.
increments of 10 C◦). These particular results are characteristic, in a
variety of ways.
• Equivalent-series resistance R0 decreases exponentially as temper-
ature increases. This is a near-universal result. Any model lacking
this feature is suspect.
• Resistor–capacitor resistances Rj also decrease (roughly) exponen-
tially as temperature increases. This is also expected.
• Resistor–capacitor time constants tend to increase with tempera-
ture. This might actually seem a surprising result, as we would
expect the cell dynamics to speed up at warmer temperatures.
However, results published by Lee et al. (based on physics mod-
els) show that at some states of charge the cell speeds up while
at other states of charge the cell slows down overall. The result in
Fig. 2.26 shows a single optimized time constant over all SOC, so it
is not necessarily a surprising result. Moreover, Lee’s results lead
us to realize that this relationship should not be expected to be
monotonic.14
• Hysteresis is generally “speeding up” (i.e., a smaller change in

2. equivalent-circuit models
59
SOC is required to effect a large change in the hysteresis state)
and decreasing in magnitude as temperature increases. Hysteresis
levels generally decrease as temperature increases.
• The measured capacity is very nearly constant across temperature
(as it should be).
In practice, the model will need to be evaluated at temperatures
not included in the testing protocol. To look up a parameter at an
intermediate temperature, linear interpolation into the tables made
via the system-identiﬁcation process can be used to approximate the
parameter values.
This assumes a smoothness in the functions as temperature varies.
We don’t always (i.e., rarely) see this from the initial system-identiﬁcation
output. In practice, some hand-smoothing of parameter relation-
ships is usually necessary to make models that match measured data
nearly as well as the automatically tuned versions, but which work
better at intermediate temperatures.
2.13
Where to from here?
In this chapter, we have examined equivalent-circuit models of
battery cells. We have seen that with optimized parameter values,
there can be very good agreement between measured and predicted
cell voltage to the same input stimulus. Therefore, they are sufﬁ-
ciently powerful for many circuit designs and for control algorithm
development.
So, are we done? (No.) Circuit models lack predictive power over
the long term. They do not answer the questions “How will a cell
behave if it is subjected to stimuli quite different from that used
during training of the model?” or “How will a cell behave as it ages?”
or “Can we predict cell aging or impending failure?” or “How can
we control a cell to maximize its utility while maximizing its life?”
So, we now start to look at physics-based models of cells, which
enable us to increase the predictive power of our models. These
physics-based models are mathematically very complex, but ulti-
mately we will be able to reduce them to models of similar computa-
tional complexity to the equivalent-circuit models we have studied in
this chapter.
2.14
Chapter appendix: MATLAB ESC model toolbox
Sec. 2.10 discussed how to collect and process cell-test data in order
to make an open-circuit-voltage relationship for a cell. Sec. 2.11 then
discussed how to collect and process cell-test data to determine the

60
battery management systems: volume i, battery modeling
15 http://mocha-java.uccs.edu/BMS1/
CH02/ESCtoolbox.zip
16 If a different brand of cell-test equip-
ment is used, the user will need to
implement new code to convert the
testing output into a format compat-
ible with the processing macros. The
code and data on the web site should
provide a template and an example for
how this could be accomplished.
remaining parameters of a complete dynamic ESC model. A MAT-
LAB toolbox and dataset comprising code implementing these steps
and companion cell-test data collected from a number of cells are
available on the book web site.15 In this appendix, we quickly in-
troduce the main code components of the toolbox. A great deal of
learning is possible if this discussion is coupled with a diligent exami-
nation of the code itself to see how the steps are implemented.
2.14.1
Creating the model
Fig. 2.27 depicts the overall process for creating an enhanced self-
correcting (ESC) cell model. The blue boxes indicate laboratory
processes; the yellow boxes indicate data ﬁles; and the green boxes
indicate processing by MATLAB functions. The “OCV testing” box
denotes cell tests of the sort described in Sec. 2.10, run at a number
of temperatures. The “Dynamic testing” box denotes cell tests of
the sort described in Sec. 2.11, also run at a number of temperatures.
Later processing requires that 25 ◦C be one of those temperatures in
both cases.
testing
Dynamic
testing
OCV
data
Test
data
Test
relationship
OCV
model
ESC cell
processOCV.m
processDynamic.m
Figure 2.27: Process of creating an ESC
cell model from cell-test data.
The “Test data” boxes abstractly denote the output of the lab-
oratory testing. However, some format conversions are required
for efﬁciency purposes. For example, cell-test equipment by Arbin
Instruments produces a “.res” ﬁle as its output. Arbin also provides
a Microsoft Excel macro that converts the “.res” format into an “.xlsx”
format. The makeMATfiles.m code on the web site (one script each for
the OCV and dynamic processing) then converts the “.xlsx” format
into a MATLAB “.mat” ﬁle. The “.mat” ﬁles have variables properly
set up for further processing.16
The processOCV.m function processes the raw cell-test data to
produce an OCV relationship. In the toolbox, processOCV.m is called
by the wrapper function runProcessOCV.m, which loads the raw cell-
test data, organizes it into the prescribed format, calls processOCV.m,
and saves the results to a ﬁle.
The processDynamic.m function likewise processes the raw cell-test
data to produce the ﬁnal ESC cell model. In the toolbox, processDynamic.m
is called by the wrapper function runProcessDynamic.m, which loads

2. equivalent-circuit models
61
0
100
200
300
400
500
600
3.00
3.25
3.50
3.75
4.00
4.25
Time (min)
Voltage (V)
Example of simCell.m
 
 
Truth
Model
Figure 2.29: Output of simCell.m
example.
the OCV relationship and raw cell-test data, organizes it into the pre-
scribed format, calls processDynamic.m, and saves the results to a
ﬁle. Note that processDynamic.m requires MATLAB’s optimization
toolbox—if this is not available, the functionality of the line search
performed by fminbnd.m will need to be rewritten by the user.
2.14.2
Using the model
Once the model is created, it is ready to be used. Fig. 2.28 depicts the
process.
current
Cell
state
Initial
model
ESC cell
voltage
Predicted
simCell.m
Figure 2.28: Process of using an ESC
cell model to predict cell response.
The ESC cell model produced from cell-test data is loaded. An
initial state comprising the initial cell state of charge, initial resistor
currents, and initial normalized hysteresis value is assembled. Then
the function simCell.m is called, along with the proﬁle of cell current
versus time to be simulated. The output of the function comprises
predicted cell voltage, as well as the internal model states as func-
tions of time.
The following code illustrates how to use the simCell.m function.
The output of this code is presented in Fig. 2.29.
load DYN_Files/E2_DYN/E2_DYN_35_P25.mat % load data file
load DYN_Files/E2model.mat % load model file
time
= DYNData.script1.time; % make variables easier to access
voltage = DYNData.script1.voltage;
current = DYNData.script1.current;
ind = find(diff(time)<=0); % get rid of duplicate time steps
time(ind+1)=[]; voltage(ind+1)=[]; current(ind+1)=[];
t1=time(1); t2=time(end); % make sure evenly sampled in time
deltaT = 1; t = (t1:deltaT:t2) - t1; % one-second sampling
current = interp1(time,current,t1:deltaT:t2);
voltage = interp1(time,voltage,t1:deltaT:t2);
% change [0;0] to have same number of zeros as you have R-C states in
model
vest = simCell(current,25,deltaT,model,1,[0;0],0); % simulate cell
figure(1); clf; plot(t/60,voltage,t/60,vest); % plot some results
legend('Truth','Model','location','southwest');

62
battery management systems: volume i, battery modeling
xlabel('Time (min)'); ylabel('Voltage (V)');
title('Example of simCell.m');
2.14.3
Model internals
Sometimes, it may be important to query the parameters of the
model. This may be done by accessing the ﬁelds in the MATLAB
structure “model” directly. However, this is generally not considered
good programming practice. Instead, the toolbox provides data acces-
sor functions that do this task for you.
To determine the open-circuit voltage at one or more states of
charge, the OCVfromSOCtemp.m function may be used. The inputs to
this function are a vector of states of charge for which voltages are
required, a temperature variable (either a scalar, which is applied to
all outputs, or a vector of the same size as the state-of-charge input
vector, where a different temperature is applied to each output), and
the model data structure. For example:
load DYN_Files/E2model.mat % load model file
z = 0:0.01:1; % make SOC input vector
T = 25; % set temperature value
plot(z,OCVfromSOCtemp(z,T,model));
To determine the state of charge from one or more at-rest open-
circuit-voltage values, the SOCfromOCVtemp.m function may be used.
Its calling parameters are similar to those used for OCVfromSOCtemp.m.
For example:
load DYN_Files/E2model.mat % load model file
v = 2.5:0.01:4.2; % make voltage input vector
T = 25; % set temperature value
plot(v,SOCfromOCVtemp(v,T,model));
Finally, to determine a model dynamic parameter value, the
getParamESC.m function may be used. For example:
load DYN_Files/E2model.mat % load model file
T = 25; % set temperature value
gamma = getParamESC('GParam',T,model); % hysteresis rate factor
This requires that the user have some knowledge of the internal
structure of the model data structure. (Again, it is not recommended
that the user access the ﬁelds of this data structure directly. However,
the ﬁeld name is required as input to the getParamESC.m function.)
These ﬁelds are listed in Table 2.1.

2. equivalent-circuit models
63
Identiﬁer ﬁeld
name
An identifying string storing a name for the cell type
Fields pertaining to the OCV versus SOC relationship:
OCV0
Vector of OCV versus SOC at 0 ◦C [V]
OCVrel
Vector of change in OCV versus SOC per ◦C [V/◦C]
SOC
SOC vector at which OCV0 and OCVrel are stored
SOC0
Vector of SOC versus OCV at 0 ◦C (unitless)
SOCrel
Vector of change in SOC versus OCV per ◦C [1/◦C]
OCV
OCV vector at which SOC0 and SOCrel are stored
Fields pertaining to the dynamic relationship:
temps
Temperatures at which dynamic parameters are stored [◦C]
QParam
Capacity Q at each temperature [Ah]
etaParam Coulombic efﬁciency η at each temperature (unitless)
GParam
Hysteresis “gamma” parameter γ (unitless)
MParam
Hysteresis M parameter [V]
M0Param
Hysteresis M0 parameter [V]
R0Param
Series resistance parameter R0 [Ω]
RCParam
The R–C time constant parameter RjCj [s]
RParam
Resistance Rj of the R–C parameter [Ω]
Table 2.1: Fields in the model data
structure.


3.1
Chapter goal: Microscale . . . 67
3.2
Solid charge conservation . . . 68
3.3
Solid mass conservation . . . . 75
3.4
Thermodynamics . . . . . . . . 80
3.5
Physical chemistry . . . . . . . 86
3.6
Binary electrolytes . . . . . . . 91
3.7
Electrolyte mass conserv. . . . 94
3.8
Electrolyte charge conserv. . 106
3.9
Butler–Volmer equation . . . 110
3.10 Implementing the model . . . 119
3.11 Cell-level quantities . . . . . 122
3.12 Where to from here? . . . . . 130
3.13 Appendix: OCP sources . . . 130
3.14 Partial glossary . . . . . . . . 132
3
Microscale Cell Models
The focus of this book is on creating mathematical models of lithium-
ion cells, ﬁnding values for the parameters in the models, and simu-
lating the models to predict cell performance. We have already seen
a phenomenological (equivalent-circuit) approach to modeling, and
we now turn to exploring physics-based models. The two different
approaches are compared and contrasted in Fig. 3.1.
Empirical models, such as the equivalent-circuit models we looked at
in Chap. 2, are noted in the top of the ﬁgure. They comprise simple
systems of cell-scale ordinary-difference equations (ODEs) that can be
implemented readily on an inexpensive microprocessor. They are
easily incorporated in battery-state estimation and control algorithms
in battery management systems. The equations that make up these
models can predict cell voltage accurately from measurements of cell
input current, and the parameters of the model can be tuned to adapt
to changing cell characteristics as the cell ages.
measurement
Direct parameter
measurement
Direct parameter
averaging
Volume
order reduction
Created via model-
Empirical system ID
ODEs
Cell-scale
ODEs
Cell-scale
scale PDEs
Molecular-
scale PDEs
(particle-)
Micro-
scale PDEs
Continuum-
predictions
based
Empirically
predictions
based
Physics-
modeling
Empirical
modeling
based
Physics-
Figure 3.1: Different approaches to
making models of lithium-ion cells.
65

66
battery management systems: volume i, battery modeling
1 Curve ﬁtting is good for interpolating
data—predicting performance in an
operating scenario similar to and
within the operating regimes of the
data-generating testing—but is bad
for extrapolating data—predicting
performance in scenarios outside the
scope of the scenarios used to generate
the model.
2 These models are sometimes referred
to as “microscale,” but as they operate
at the atomic level, they might more
appropriately be called “nanoscale.” We
will refer to them as “molecular scale,”
sidestepping the issue.
However, these models are limited. Most important, they can-
not predict cell internal dynamics, which is of critical importance
to being able to predict how a cell will age and to being able to for-
mulate battery-control algorithms to minimize cell aging due to out-
of-bounds internal states. Further, the process of determining the
parameter values for an empirical cell model uses empirical system
identiﬁcation, which is essentially a curve-ﬁtting process, and so has
its own limitations. In particular, the resulting model must not be
used in scenarios that are very different from the ones from which
data were collected to tune the model parameter values.1
Physics-based models are more difﬁcult to formulate but allow en-
hanced monitoring and prediction of individual mechanisms internal
to the cell. Further, just as Newton’s laws of motion allow accurate
predictions of an object’s acceleration over a very wide range of ini-
tial velocities given only measurements of its mass—so too physics-
based models of cell dynamics allow accurate predictions of cell
behaviors using only a small set of measured physical cell parame-
ters. There is no concern of “extrapolation versus interpolation” as
there is for empirical models.
The process for creating and using a physics-based model is il-
lustrated in the bottom of Fig. 3.1. We see that there are multiple
stages involved, starting at very short length scales and progressively
moving up to the ﬁnal cell-scale model.
Some physics-based models describe processes at the molecular
scale.2 Parameter values for these equations can be measured directly,
replacing the need for empirical system identiﬁcation. The resulting
models are useful primarily for predicting diffusion rates of lithium
within the crystalline structures of the solid particles that comprise
the electrode active materials and for predicting open-circuit poten-
tial relationships for these materials. However, there are laboratory
techniques for measuring diffusivity and open-circuit potentials
directly without need of molecular-scale models, so we omit any
further discussion of modeling cell dynamics at this scale.
The next higher scale is the particle-scale or microscale, where
we look at homogeneous materials. These models predict what hap-
pens inside the solid electrode particles and what happens in the
electrolyte, as considered separately. We can think of this scale as a
volume average of the molecular scale, where impurities and imper-
fections are blended in, to create a homogeneous material. Model
parameters are also measured directly via lab tests at this level.
The next higher scale is the continuum scale, where the solid and
electrolyte are no longer considered separately. Continuum models
are volume-averaged simpliﬁcations of the microscale, where each

3. microscale cell models
67
3 We can extrapolate beyond the data
used to create the model, as the physics
allows us to do so. Further, the equa-
tions can predict internal cell dynamics
in addition to external cell voltage.
4 Special thanks to Dr. Kan-Hao Xue,
who helped to derive many of the
proofs of equations given in this
chapter.
sample volume is assumed to contain a portion of the solid electrode
material and a portion of the electrolyte. Activity in the solid and
activity in the electrolyte are still thought of separately, but the equa-
tions take into account the interactions between the two regions.
The ﬁnal scale converts the partial-differential equations from
the continuum scale into a coupled set of ordinary difference equa-
tions at the cell scale, suitable for rapid simulation and controls
purposes. The ﬁnal complexity of these cell-scale ODEs is similar
to those created via empirical modeling, but the predictive power is
much greater.3 The physics-based path is much harder to develop
and understand, but the ﬁnal results are worth the effort.
Fig. 3.1 can be seen as a roadmap for the bulk of this book. Chap. 2
has already considered equivalent-circuit type empirical models.
Chap. 3 focuses on developing microscale models. Chap. 4 will show
how to invoke volume-averaging techniques to create continuum-
scale models. Chaps. 5 and 6 will give the background and methods
to convert continuum-scale models into low-complexity cell-scale
models automatically. Finally, Chap. 7 will consider how thermal
effects can be incorporated in physics-based models.
3.1
Chapter goal: Derive microscale model equations
The road ahead in this chapter involves concepts from vector calculus,
thermodynamics, and physical chemistry that may not be familiar to
all readers. Sufﬁcient background in these ﬁelds will be developed
to be able to derive the equations of the microscale model, but it will
take time to do so. It’s easy to get lost in the details and to miss the
main results. So, before embarking on these topics, we present in
summary the main results that we intend to develop.4 The reader can
use these results as “mile markers” for the chapter, giving some sense
of the progress that is being made.
In particular, our goal in this chapter is to develop the microscale
model, which comprises a set of ﬁve coupled equations:
1. Charge conservation in the homogeneous solid:
∇· is = ∇· (−σ∇φs) = 0.
(3.1)
2. Mass conservation in the homogeneous solid:
∂cs
∂t = ∇· (Ds∇cs).
(3.2)
3. Mass conservation in the homogeneous electrolyte:
∂ce
∂t = ∇· (De∇ce) −ie · ∇t0
+
F
−∇· (cev0) .
(3.3)

68
battery management systems: volume i, battery modeling
Solid particle
Electron movement
Diffusion of Li
Electrolyte
Figure 3.2: Dynamics in the solid.
5 NA is known as Avogadro’s number.
4. Charge conservation in the homogeneous electrolyte:
∇· ie = ∇·
.
−κ∇φe −2κRT
F
.
1 + ∂ln f±
∂ln ce
/ '
t0
+ −1
(
∇ln ce
/
= 0.
(3.4)
5. Lithium movement between the solid and electrolyte phases:
j = i0
F
>
exp
.(1 −α)F
RT
η
/
−exp
.
−αF
RT η
/?
.
(3.5)
At this point, none of the variables in the equations will have mean-
ing to the reader. However, note that a glossary of the most impor-
tant variables used in this chapter can be found in Sect. 3.14. Vector-
calculus gradient (∇) and divergence (∇·) operators will also be
reviewed when they ﬁrst appear in the derivations.
3.2
Charge conservation in the solid
We begin by deriving the microscale equations for a lithium-ion cell
that describe charge and mass conservation in the solid: Eqs. (3.1)
and (3.2), respectively. These derivations are fairly straightforward,
starting with basic physics laws, but do require some knowledge
of vector calculus, which we will review. We’ll then need to look at
some concepts from thermodynamics and physical chemistry before
proceeding to develop the remaining three model equations.
Fig. 3.2 illustrates activity in the solid particles of the electrode
active material. Our ﬁnal model will describe electron movement
via conduction due to local differences in the electric potential and
lithium-atom movement between vacancies in the crystalline struc-
ture of the active material via diffusion due to local differences in
concentration. But ﬁrst, we need to deﬁne terminology that allows us
to quantify material and charge, and we need to discuss how we will
deﬁne movement of material mathematically.
3.2.1
Moles and coulombs
For any appreciable current to ﬂow in a battery cell, a lot of lithium
must move. So, instead of counting individual lithium atoms, it is
customary to count moles of lithium instead. A mole is a unit of mea-
surement used in chemistry to express quantities of a chemical sub-
stance, equal to NA = 6.02214 × 1023 molecules of that substance.5
The mole is one of the base units in the International System of Units
and has the unit symbol mol. The number of molecules in a mole
is deﬁned so that the mass of one mole of a substance, expressed in
grams, is exactly equal to the substance’s mean molecular weight. For

3. microscale cell models
69
6 F is known as Faraday’s constant.
7 In the literature, it is common to see
ﬂux density referred to as ﬂux. The key
is to look at the units to see what the
author is really considering.
example, the mean molecular weight of natural water (H2O) is about
18.015, so one mole of water is about 18.015 g.
The mole is widely used in chemistry—instead of units of mass
or volume—as a convenient way to express the amounts of reac-
tants and products of chemical reactions. For example, the reaction
2 H2 + O2 →2 H2O implies that 2 mol of dihydrogen and 1 mol of
dioxygen react to form 2 mol of water. The mole may also be used
to express the number of atoms, ions, or other elementary entities in
some sample.
Similarly, for any appreciable current to ﬂow in a battery cell, a lot
of electrons must move. So, instead of counting individual electrons,
we also count moles of electrons. However, we’re usually less inter-
ested in the quantity of electrons moving than we are in the quantity
of charge moving. We express charge in coulombs or C, where there
are F = 96, 485 coulombs per mole of elementary charges.6 Electrical
current is the ﬂow of charge and is measured in amperes, where one
ampere equals one coulomb per second (1 A = 1 C s−1).
3.2.2
Flux density
We are about to discuss movement of electrons and lithium atoms
and ions. More formally, we are going to consider their ﬂux. Flux
is the rate of something crossing a surface. Note that ﬂux is a total
quantity per unit time. If we are concerned with the movement of
electrons, the ﬂux will be measured in coulombs per second, or A. If
we are considering the movement of lithium ions or atoms, the ﬂux
will be measured in moles per second, or mol s−1. Later on, we’ll be
more interested in ﬂux density, which is ﬂux normalized per unit area
or volume.7 When considering charge, we will measure ﬂux density
in A m−2; when considering lithium, we will measure ﬂux density in
mol m−2 s−1.
The surface across which the movement occurs can be a physical
boundary, such as when considering the movement of lithium be-
tween the solid electrode particles and the electrolyte. However, the
surface can also be a nonphysical boundary, such as some concep-
tual plane separating (x, y, z) and (x + δx, y, z). In the latter case, we
would be considering how much lithium is traveling in the x direc-
tion near the point (x, y, z).
To measure the ﬂux of electrons or lithium passing through a
surface, we need to know
• The shape, size, and orientation of the surface,
• The strength and direction of the ﬂow at any point in space
The latter is known as a vector ﬁeld, which is a function of space that
results in computing a vector value at every (x, y, z) location. Each

70
battery management systems: volume i, battery modeling
−4
−2
0
2
4
−4
−3
−2
−1
0
1
2
3
4
x
y
Example vector ﬁeld
Figure 3.3: An example generic vector
ﬁeld in two dimensions.
n
F
^
Figure 3.4: Orientation dependence of
ﬂux.
(Adapted from
http://en.wikipedia.org/
wiki/File:General_flux_diagram.svg.)
vector has a length, which says how quickly material is ﬂowing at
that point, and an orientation, which says in which direction the
material is ﬂowing. Fig. 3.3 shows how we might draw a vector ﬁeld
in two dimensions: every (x, y) point is associated with a vector
indicating rate and direction of ﬂow.
The local strength of the vector ﬁeld has a direct impact on the
ﬂux. Doubling the strength will double the ﬂux passing through a
surface. Flux also depends on the orientation of the ﬁeld and the
surface. When the ﬁeld passes directly through the surface (is at
right angles to the surface), the ﬂux is maximized. As the surface tilts
away from the ﬁeld, the ﬂux decreases as less and less ﬂux crosses
the surface. Eventually, we get zero ﬂux when the source and surface
are parallel—the ﬂux passes over the boundary but does not cross
through it.
As an analogy, imagine wind (the source of ﬂux) blowing past a
window frame (the surface). If the wind is pointed straight at the
window, the airﬂow through the window frame is maximized. If the
wind is at an angle to the window, the airﬂow through the window
frame is reduced. If the wind is blowing across the window, then no
airﬂow will pass through the window frame.
This is illustrated in Fig. 3.4. The blue lines indicate the vector
ﬁeld F(x, y, z). The surface is illustrated in green, and a vector normal
to the surface is denoted as ˆn. The components of the vector ﬁeld
that make up the ﬂux are illustrated by the orange lines—these are
the parts of F that are parallel to ˆn and perpendicular to the surface.
In this example, ﬂux is positive because it is in the same direction
as ˆn. If it were in the opposite direction, it would have a negative
sign. When the surface is physical, this has meaning. We deﬁne the
normal vector ˆn pointing outward from the object. Then, positive ﬂux
means that the ﬂow is out of the object, and the object is a source of
the ﬂux. Negative ﬂux means that the ﬂow is into the object, and the
object is a sink to the ﬂux.
Expressing this mathematically, if F(x, y, z) is the vector ﬁeld and
ˆn is the normal vector to a surface, then the dot product of these two
vectors, F(x, y, z) · ˆn, gives the component of the vector ﬁeld that is
perpendicular to the surface. The total ﬂux is the integral of this dot
product over the surface. We can write
ﬂux =
¨
S
F(x, y, z) · ˆn dS,
where
˜
S means that we are integrating over the entire (generic)
surface S. For a speciﬁc computation, the limits of integration would
need to be supplied explicitly in order to be able to evaluate the
integral and dS would need to be written in terms of the geometric
variables describing the surface (e.g., perhaps dx and dy).

3. microscale cell models
71
8 Gradients tell us the rate of change of
a function with respect to space. The
gradient is a vector that points in the
direction of greatest increase of a func-
tion, considered locally. Mathematically,
the gradient symbol is an upside-down
delta and is called “dell.” We can write
out the gradient of a function F(x, y, z)
as
∇F = ∂F
∂x
ˆi + ∂F
∂y
ˆj + ∂F
∂z
ˆk,
where ˆi, ˆj, and ˆk are the standard unit
vectors in the x, y, and z directions,
respectively.
Also note that sometimes we make the distinction between an
open surface and a closed surface. An open surface does not completely
enclose a volume and therefore has a distinct edge or boundary. A
closed surface completely encloses some volume (e.g., the outer sur-
face of a cube or a sphere). When talking about closed surfaces, we
more correctly write ﬂux as
ﬂux =
"
S
F(x, y, z) · ˆn dS,
where
‚
S means that we are integrating over the entire closed surface
S. When the surface under consideration might either be open or
closed, we write
˜
S.
3.2.3
Point form of Ohm’s law
We are now ready to derive a relationship that models the movement
of charge through the homogeneous solid crystalline structures of the
electrodes. We will assume that the electron movement arises from
drift motion of charges in a linear media, where Ohm’s law applies.
In this scenario, current density is proportional to the applied
electric ﬁeld: i = σE, where
• i(x, y, z, t) [A m−2] is the (vector) current density ﬂowing through
a representative cross-sectional area centered at a given location.
By convention, i represents the ﬂow of positive charges; negatively
charged electrons ﬂow in the direction opposite to i.
• σ(x, y, z, t) [S m−1] is a material-dependent conductivity value. A
high value of σ means that it is easy for current to ﬂow, and a low
value of σ means that it is difﬁcult for current to ﬂow. Conductiv-
ity is inversely proportional to resistivity.
• E(x, y, z, t) [V m−1] is the (vector) electric ﬁeld at that location.
If we assume that magnetic effects are negligible, the electric ﬁeld can
be written in terms of the local gradient of the electric potential8
E = −∇φ,
where φ(x, y, z, t) [V] is the scalar ﬁeld (scalar function of space) repre-
senting the electric potential at each point. Substituting, we have
i = −σ∇φ.
(3.6)
Note that this relationship is a microscopic (point-form) version of
Ohm’s law, which states that I = ∆V/R for homogeneous linear
media. Here we have had to introduce the negative sign to accommo-
date the different sign convention of the gradient operator ∇φ versus
the difference operator ∆V.

72
battery management systems: volume i, battery modeling
As an example, consider the scenario depicted in Fig. 3.5. The left
frame is an example scalar ﬁeld, such as the local electric potential φ
as a function of spatial coordinates x and y. The middle frame shows
contours of equal function value as circles and local gradient values
as vector symbols. We see that toward the center of the diagram,
the gradient points upward toward the peak. Moving out from the
center, after the valley is reached, the gradient vectors point toward
the lower ridge-line of the function (i.e., the gradient does not point
toward the globally maximum function value; it points upward in
a local sense only). The right plot shows the ﬂux density vectors.
The ﬂux density is of opposite sign to the gradient, implying that
movement is “downhill.” That is, positive charges move from a high
potential to a low potential under the effect of the electric ﬁeld.
−8
−4
0
4
8
−8
−4
0
4
8
0
0.5
1
x
y
φ
Electric potential
−8
−4
0
4
8
−8
−4
0
4
8
x
y
Contours and gradient vectors
−8
−4
0
4
8
−8
−4
0
4
8
x
y
Contours, ﬂux density vectors
Figure 3.5: Example of gradient and
ﬂux density.
3.2.4
The continuity equation (Kirchhoff’s current law)
Comparing Eq. (3.6) with Eq. (3.1), we see that we are beginning to
develop the terms needed for the ﬁrst microscale model equation,
but that we do not yet have the desired ﬁnal form. So far we have
computed only a way to represent the ﬂow of charge; we have not yet
enforced conservation of charge. We do that now.
Consider representing a solid particle as a lot of tiny volumes.
Now, consider one of those volumes V, where the material properties
within that volume are homogeneous, the volume has closed bound-
ary surface S, and current density i is directed into the volume. Then,
the net current i [A] into the region is
i = −
"
S
i · ˆn dS,
the minus sign arising because of our usual convention that the nor-
mal ˆn points out of the volume.

3. microscale cell models
73
A net charge dQ [C] is supplied to volume V by the current within
a time dt, so we can write
i = dQ
dt .
Thus, the net charge in the volume changes in time dt by an amount
dQ = d
˝
V ρV dV where ρV [C m−3] is the charge density (of positive
charges) within volume V and hence
"
S
i · ˆn dS = −d
dt
˚
V
ρV dV.
(3.7)
Note that we’ve implicitly assumed that charge within V can be
changed only by allowing it to enter or exit through the boundary.
Charge already contained in V is neither created nor destroyed while
this occurs. Thus, Eq. (3.7) is (the integral form of) the so-called equa-
tion of continuity. It is equivalent to a statement of conservation of
charge.
3.2.5
Divergence
We’re ultimately interested in converting the integral form of the
charge-conservation relationship into a (differential) point form. To
do so, we’ll need to be able to take the limit of Eq. (3.7) as the volume
V becomes vanishingly small.
To aid in this effort, we recognize that the divergence of a vector
ﬁeld F is deﬁned as
∇· F = lim
∆V→0
1
∆V
"
S
F · ˆn dS.
(3.8)
We can come up with a way of understanding the notation ∇· F
used to represent divergence if we write F = Fxˆi + Fyˆj + Fz ˆk, where
Fx is the x component of F, Fy is the y component of F, and Fz is the
z component of F. Then, shrinking the volume of ∆V down to an
inﬁnitesimal cube, where the value of F is constant on each face of
the cube (but possibly different on different faces), Eq. (3.8) becomes
the normalized summation of F · ˆn on the six different faces of the
cube, multiplied by each face area
∇· F = lim
∆V→0
1
∆V
:
(Fx(x + δx) −Fx(x)) Ayz
+
!
Fy(y + δy) −Fy(y)
"
Axz + (Fz(z + δz) −Fz(z)) Axy
;
,
where Ayz is the area of the y–z planar side of the cube, Axz is the
area of the x–z side of the cube, and Axy is the area of the x–y side of

74
battery management systems: volume i, battery modeling
−4
−2
0
2
4
−4
−2
0
2
4
 x
 y
Example vector field
Figure 3.6: Illustrating positive (top,
red region), zero (middle, blue region),
and negative (bottom, green region)
divergence.
the cube. Then, realizing that ∆V = Ayzδx = Axzδy = Axyδz,
∇· F =
lim
δx,δy,δz→0
:
Fx(x + δx) −Fx(x)
δx
+ Fy(y + δy) −Fy(y)
δy
+ Fz(z + δz) −Fz(z)
δz
;
= ∂Fx
∂x + ∂Fy
∂y + ∂Fz
∂z ,
which is how divergence is computed in practice in rectangular coor-
dinates.
Notice that the notation for divergence combines the ideas of a
gradient and a dot product:
∇· F =
. ∂
∂x
ˆi + ∂
∂y
ˆj + ∂
∂z
ˆk
/
·
.
Fxˆi + Fyˆj + Fz ˆk
/
= ∂Fx
∂x + ∂Fy
∂y + ∂Fz
∂z .
By careful change of variables, divergence can also be expressed in
other coordinate systems. For example, in cylindrical (ρ, φ, z) coordi-
nates, divergence can be written as
∇· F = 1
ρ
∂(ρFρ)
∂ρ
+ 1
ρ
∂Fφ
∂φ + ∂Fz
∂z .
In spherical (r, θ, φ) coordinates, we have
∇· F = 1
r2
∂(r2Fr)
∂r
+
1
r sin θ
∂(sin θFθ)
∂θ
+
1
r sin θ
∂Fφ
∂φ .
By examining Eq. (3.8), we can arrive at an intuitive sense of the
meaning of divergence. The divergence of a vector ﬁeld is a scalar
quantity denoting the net ﬂux density out of a volume through the
enclosing surface. Positive divergence means that we have a point
source; negative divergence means that we have a point sink. Con-
sidering that the term “to diverge” means “to move away from,” this
mathematical deﬁnition is in agreement with standard understanding
of how the word is used in other contexts as well. Positive divergence
means that material is moving away from a point; negative diver-
gence means that material is moving toward a point.
Fig. 3.6 illustrates this concept. A vector ﬁeld is drawn, and three
different regions (two-dimensional “volumes”) are highlighted. We
see that more arrows point out of the top (red) volume than point
into it. Hence this volume is acting as a net source, and divergence
is positive. The same number of arrows point into and out of the
middle (blue) volume, so this volume is neither a source nor a sink,
so its divergence is zero. More arrows point into the bottom (green)
volume than out of it, so this volume is acting as a net sink.

3. microscale cell models
75
9 Liebnitz’ rule for differentiating an
integral is
d
dθ
ˆ b(θ)
a(θ)
f (x, θ) dx =
ˆ b(θ)
a(θ)
∂f (x, θ)
∂θ
dx
+ f (b(θ), θ) ∂b(θ)
∂θ
−f (a(θ), θ) ∂a(θ)
∂θ
,
assuming that f (x, θ) is continuous and
that the integral exists.
10 In this book, we use “s” to refer to the
solid and “e” to refer to the electrolyte.
It is also very common in the literature
to use subscript “1” for the solid and
“2” for the electrolyte. We feel that the
alphabetic subscript is less confusing,
but the reader should be prepared to
encounter both conventions.
3.2.6
Point form of charge conservation
We are now ready to convert the integral form of the equation of
charge continuity to a point form. Starting with the integral form,
"
S
i · ˆn dS = −d
dt
˚
V
ρV dV,
we employ Liebnitz’s rule for differentiating an integral9 and get
"
S
i · ˆn dS = −
˚
V
.∂ρV
∂t
/
dV,
assuming that charge density is continuous and that the volume V is
not time varying.
We then divide both sides of the equation by the region’s volume
and take the limit as the volume shrinks to zero:
lim
V→0
1
V
"
S
i · ˆn dS = lim
V→0 −1
V
˚
V
.∂ρV
∂t
/
dV
∇· i = −∂ρV
∂t .
Applying Ohm’s law to this identity, we get
∇· i = ∇· (−σ∇φ) = −∂ρV
∂t .
At this point, we assume that the rate of electron movement in
the solid lattice is much faster than the rate of other processes in
the electrochemical cell. Therefore, ρV reaches an equilibrium state
relatively quickly and so can be treated as being essentially constant
over the time scales of the other processes. Then, ∂ρV/∂t ≈0. This
gives us ∇· (−σ∇φ) = 0.
To emphasize that this relationship applies to the solid particles in
the cell and not to the electrolyte, we employ the subscript “s” on i
and φ:10
∇· is = ∇· (−σ∇φs) = 0.
In words, this says that the divergence of the current density out
of any sample volume within the homogeneous solid is zero. This
means that the same amount of charge must exit the volume as en-
ters it; that is, charge is neither created nor destroyed nor stored
within any sample volume in the homogeneous solid.
We have now derived Eq. (3.1).
3.3
Mass conservation in the solid
We now set out to derive Eq. (3.2); that is, to develop an equation
that deﬁnes mass conservation in the homogeneous solid electrode

76
battery management systems: volume i, battery modeling
materials. In many ways, this derivation is parallel to the one we
have just completed.
Again, we start with a relationship that models movement of the
quantity of interest. This time, instead of being interested in the
movement of charge, we are interested in the movement of lithium
atoms within either the negative- or positive-electrode active mate-
rial crystalline structures. We assume that movement occurs due to
interstitial diffusion only, in a linear media.
That is, we assume that molar ﬂux density is proportional to the
concentration gradient via Fick’s ﬁrst law
N = −D∇c,
(3.9)
where
• N(x, y, z, t) [mol m−2 s−1] is the (vector) molar ﬂux density of lithium
ﬂowing through a representative cross-sectional area of the solid
that is centered at a given location.
• D(x, y, z, t) [m2 s−1] is a material-dependent parameter called the
diffusivity. A large value for D means that it is easy for lithium to
move; a small value for D means that it is difﬁcult for lithium to
move.
• c(x, y, z, t) [mol m−3] is the concentration of lithium in the neigh-
borhood of a given location.
This is illustrated in Fig. 3.7. The left frame shows an example plot of
concentration versus space. The gradient vector ﬁeld of the concen-
tration, as shown in the middle frame, points locally in the direction
of increasing concentration. The material ﬂux density points in the
opposite direction from the gradient as seen in the right frame, as
lithium moves from a high-concentration to a low-concentration re-
gion.
−4
−2
0
2
4
−4
−2
0
2
4
0
1
2
3
4
x
y
c
Example concentration ﬁeld
−4
−2
0
2
4
−4
−3
−2
−1
0
1
2
3
4
x
y
Gradient ﬁeld
−4
−2
0
2
4
−4
−3
−2
−1
0
1
2
3
4
x
y
Flux-density ﬁeld
Figure 3.7: Movement of lithium atoms
due to a concentration gradient.

3. microscale cell models
77
3.3.1
The continuity equation
Eq. (3.9) describes the ﬂow of lithium; we now proceed to derive
from it a relationship that enforces conservation of mass.
As before, we consider representing a solid particle as many small
volumes and examine a representative homogeneous volume V with
boundary surface S and with lithium molar ﬂux density N directed
into it. The net molar ﬂux j [mol s−1] into the region is
j = −
"
S
N · ˆn dS,
where the minus sign arises because of the convention that the nor-
mal ˆn points out of the region. The ﬂux can also be written as
j = dn
dt ,
where n is the number of moles of lithium in the volume V. There-
fore, a net quantity of lithium dn is supplied to V by the molar ﬂux j
within a time dt. But, we can write dn = d
˝
V c dV, where c is the
concentration of lithium within volume V, measured in moles per
cubic meter. So, we conclude that
"
S
N · ˆn dS = −d
dt
˚
V
c dV.
This is the integral form of the so-called equation of continuity and
is equivalent to a statement of conservation of mass. Note that we’ve
implicitly made the same assumption as before; that is, that the mass
within V can be changed only by allowing it to enter or exit through
the boundary. Mass already contained in V is neither created nor
destroyed while this occurs.
3.3.2
Point form of mass conservation
We are now ready to convert the integral form of the equation of
continuity to a point form. Starting with the integral form
"
S
N · ˆn dS = −d
dt
˚
V
c dV,
we employ Liebnitz’s rule for differentiating an integral and get
"
S
N · ˆn dS = −
˚
V
.∂c
∂t
/
dV,
assuming that concentration is continuous and that V is not time
varying.

78
battery management systems: volume i, battery modeling
11 To see this more clearly, we can
write ∂cs
∂t = −∇· (−Ds∇cs) and note
that −Ds∇cs is ﬂux density. Then,
−∇· (ﬂux) is negative divergence and
actually represents net ﬂux density into
a point rather than ﬂux density out of a
point.
We then divide both sides of the equation by the region’s volume
and take the limit as the volume shrinks to zero:
lim
V→0
1
V
"
S
N · ˆn dS = lim
V→0 −1
V
˚
V
.∂c
∂t
/
dV
∇· N = −∂c
∂t .
Applying Fick’s ﬁrst law to this identity, we get
∂c
∂t = ∇· (D∇c).
This is known as Fick’s second law. Finally, adding subscript “s” to
c and D to denote that these variables correspond to the solid phase,
we get
∂cs
∂t = ∇· (Ds∇cs).
In words, this says that the total lithium ﬂux density into any
sample volume within the homogeneous solid is equal to the rate of
change of concentration of lithium in that volume.11 This means that
any lithium entering a sample volume must either be compensated
for by lithium exiting that volume or by an increasing concentration
of lithium in that volume. That is, lithium is neither created nor
destroyed within any sample volume in the homogeneous solid.
We have now derived Eq. (3.2).
3.3.3
1D example of linear diffusion
Eqs. (3.1) and (3.2) are diffusion equations. Furthermore, Eq. (3.3)
has a dominant diffusion component. To understand the operation
of lithium-ion cells, it is therefore very important to have an intuitive
feel for how diffusion works.
To help visualize diffusion, we create a simulator for the special
case of one-dimensional diffusion with constant Ds. In this case, the
diffusion PDE reduces to
∂cs(x, t)
∂t
= Ds
∂2cs(x, t)
∂x2
.
We will partition time and space into small uniform divisions
and use the ﬁnite-difference method to simulate the dynamics of the
equation. That is, we ﬁrst approximate the time derivative using
Euler’s forward rule
∂cs(x, t)
∂t
≈cs(x, t + ∆t) −cs(x, t)
∆t
.
We can approximate the second spatial derivative using the forward
or backward rule (repeated), or the central-difference (CD) rule
∂cs(x, t)
∂x
≈cs(x + ∆x, t) −cs(x, t)
∆x
(Forward)

3. microscale cell models
79
∂cs(x, t)
∂x
≈cs(x, t) −cs(x −∆x, t)
∆x
(Backward)
∂2cs(x, t)
∂x2
≈cs(x + ∆x, t) −2cs(x, t) + cs(x −∆x, t)
(∆x)2
.
(CD)
Putting the equations together, using the central-difference rule, we
get
cs(x, t + ∆t) = cs(x, t) + Ds∆tcs(x + ∆x, t) −2cs(x, t) + cs(x −∆x, t)
(∆x)2
.
(3.10)
To implement this method, we must take time steps of ∆t seconds.
Every time step, we compute cs at every x location using this relation-
ship. Selection of ∆t and ∆x cannot be done arbitrarily—this method
is stable only for certain combinations of ∆t and ∆x. However, it is
the simplest way to approximate a PDE in discrete time and space,
so it is the method we choose to implement ﬁrst. Other methods in-
clude the ﬁnite-volume method (introduced later in this chapter) and
the ﬁnite-element method (introduced in Chap. 4). Either of these is
generally preferred over ﬁnite difference for stability and accuracy,
but is more complicated to explain.
The following MATLAB code implements the central-difference
method, mirroring at edges.
D = 2;
% diffusivity (m^2/s)
dt = 0.1; % time step (s)
dx = 1;
% x step (m)
c = 1:32; % initial concentration profile (mol/(m^3))
figure(1); clf; colormap(jet(31));
for k = 0:1000,
% implement finite-difference diffusion equation using
% explicit method and central differences
c = c + D*dt/(dx^2)*([c(2:end),c(end)] - 2*c + [c(1),c(1:end-1)]);
if mod(k,100) == 0, % plot a snapshot
subplot(11,1,k/100+1); image(c); grid on
set(gca,'ytick',[],'xticklabel',[],'ticklength',[0 0]);
set(gca,'xtick',1.5:1:100,'gridlinestyle','-','linewidth',4);
h = ylabel(sprintf('t = %g (s)',k*dt));
set(h,'rotation',0,'horizontal','right','vertical','middle')
end
end
xlabel('x location');
text(16,-14.25,'Diffusion example','horizontal','center');
In the code, the ﬁrst three lines set up the simulation constants,
and the fourth line creates a vector c that represents cs at different
points in space at this particular moment in time. This vector is
initialized as a concentration proﬁle ranging from 1 to 32 mol m−3
across the x dimension. That is, the leftmost of the 32 spatial points
being simulated has concentration 1 mol m−3, the rightmost point has
concentration 32 mol m−3, and points in between vary linearly.

80
battery management systems: volume i, battery modeling
t = 0 (s)
t = 10 (s)
t = 20 (s)
t = 30 (s)
t = 40 (s)
t = 50 (s)
t = 60 (s)
t = 70 (s)
t = 80 (s)
t = 90 (s)
t = 100 (s)
x location
Diffusion example
Figure 3.8: Diffusion example using the
ﬁnite-difference method.
The majority of the remainder of the code is concerned with plot-
ting the concentration vector at different moments in time, resulting
in Fig. 3.8. Besides plotting, the code implements a “for” loop, which
steps from the zeroth time step to the 1, 000th time step, and the con-
centration update equation:
c = c + D*dt/(dx^2)*([c(2:end),c(end)] - 2*c + [c(1),c(1:end-1)]);
In this MATLAB vector equation, [c(2:end),c(end)] implements the
cs(x + ∆x, t) term, substituting the “mirrored” cs(31∆x, t) for the
unknown cs(32∆x, t) and [c(1),c(1:end-1)] implements cs(x −∆x, t),
substituting the “mirrored” cs(0, t) for the unknown cs(−∆x, t). Over-
all, this line implements Eq. (3.10) once per time iteration.
Fig. 3.8 illustrates the results of running this code, showing diffu-
sion in action. At time t = 0, the ﬁgure shows a proﬁle of concen-
tration versus space ranging from 1 mol m−3 to 32 mol m−3 across
the x dimension. The dark blue colors indicate low concentration,
and the dark red colors indicate high concentration. Even as soon as
time t = 10, the blues and reds are not as dark, indicating that there
has been some material ﬂux from a higher concentration region to a
lower concentration region via diffusion, with the result being that
the proﬁle of concentration versus space is becoming more uniform.
By time t = 100, the concentration is almost entirely uniform across
the width of the simulated space, as illustrated by the nearly constant
midrange green color.
We see that diffusion is actually pretty simple—explaining how
material ﬂows due to a concentration gradient—even though the
PDE may look daunting at ﬁrst. Soon, you’ll be able to glance at an
equation that looks like
∂c(x, t)
∂t
= ∇· (D∇c(x, t)) + r(x, t)
and say to yourself, “That’s just a diffusion equation” and
1. Know what you’re talking about;
2. Really think of it as pretty simple.
The good news is that battery-physics equations are predominantly
diffusion equations. So we can look at the ﬁnal forms and under-
stand the internal cell processes as being dominated by diffusion
effects similar to what we have seen illustrated in this example.
3.4
Thermodynamics
Now that we have addressed conservation of charge and mass in the
solid particles of the electrode active material, we move on to estab-
lishing parallel conservation of charge and mass relationships for

3. microscale cell models
81
Solid particle
Potential
Flux of Li +
Electrolyte
Figure 3.9: Dynamics in the electrolyte.
12 Newman, J., and Thomas-Alyea, K.E.,
Electrochemical Systems, 3d, Chapter 12,
Wiley-Interscience, 2004.
Table 3.1: Energy relationships.
(Adapted from Schroeder, D.V., An
Introduction to Thermal Physics, Chap-
ter 5, Addison Wesley, 2000.)
➠Subtract TS
➠Add pV
Internal
energy U
(energy
needed to
create a
system)
Helmholtz free
energy
A = U −TS
(energy needed
to create a
system minus
energy you can
get from the
environment)
Enthalpy
H=U+pV
(energy
needed to
create a
system plus
the work
needed to
make room
for it)
Gibbs free
energy
G=U+pV−TS
(energy needed
to create a
system and
make room for
it minus the
energy you can
get from the
environment)
the electrolyte. Fig. 3.9 illustrates our new focus. Positively charged
lithium ions move through the electrolyte due to diffusion, migra-
tion, and convection. In doing so, they set up an ionic current, which
inﬂuences the electric potential in the electrolyte.
The derivation of electrolyte equations involves a topic of study
known as concentrated solution theory. We follow the general outline
of Newman’s book, ﬁlling in some of the gaps that were left between
equation steps.12 However, before we can leap right into the deriva-
tion, we must ﬁrst cover a number of critical foundational topics.
The ﬁrst broad topic that we look at is a subject area known as
thermodynamics, which looks at energy relationships in systems, in-
cluding (but not limited to) heat/temperature aspects. Thermody-
namics tells us whether or not a process or a reaction is able to occur
by looking at energy states before and after the presumed reaction. It
is applicable to systems in stable or metastable equilibrium.
We will eventually also look at kinetics, which concerns the rate
of chemical reactions. How quickly or how slowly will the process
occur? Kinetics is applicable to systems in transition from nonequi-
librium to equilibrium or between two equilibrium states. Kinetics
addresses how to overcome the energy barrier to ﬁnish the transfor-
mation from the starting (reactant) state to the ﬁnal (product) state.
We postpone any further discussion of kinetics until Sect. 3.9, where
we consider the derivation of Eq. (3.5).
3.4.1
Energy
In thermodynamics, we deﬁne a system to be whatever part of the
universe we select for study. Adjacent to the system is the environ-
ment. Thermodynamics is about energy relationships between and
among systems and the environment.
It turns out that we can think about a system’s energy in a num-
ber of different ways. Four quantities called thermodynamic potentials
are useful. They are internal energy U, enthalpy H, Helmholtz free en-
ergy A, and Gibbs free energy G. All have units of joules (J), and the
relationships between them are illustrated in Table 3.1.
The most basic of these is the internal energy U. Internal energy is
deﬁned as the energy associated with the random, disordered motion
of molecules. It is separated in scale from the macroscopic ordered
energy associated with moving objects; it refers to the invisible mi-
croscopic energy on the atomic and molecular scale. This includes
translational, rotational, and vibrational kinetic energy of atoms and
molecules, and potential energy associated with the static rest mass
energy of the constituents of matter, static electric energy of atoms
within molecules or crystals, and the static energy of chemical bonds.

82
battery management systems: volume i, battery modeling
13 Here, and in the rest of this book, T
is absolute temperature, measured in
kelvin (K).
Volume
V
Area
A
Atmospheric
pressure
p
∆x
Figure 3.10: Atmospheric work.
The internal energy then is the energy needed to create the system
but excludes the energy required to displace the system’s surround-
ings, any energy associated with a move as a whole, or energy due to
external force ﬁelds.
To bring a system to internal energy U, we don’t need to start
from zero. For example, if the system is created in an environment
of temperature T, then some of the energy can be obtained by spon-
taneous heat transfer from the environment to the system.13 The
amount of this spontaneous energy transfer is TS where S is the ﬁnal
entropy of the system (deﬁned in Sect. 3.4.3). The bottom line is that
if you accept energy from the environment when creating the sys-
tem, you don’t have to put in as much energy as if you didn’t. Note
that if a more disordered (higher entropy) ﬁnal state is created, less
work is required to create the system. The Helmholtz free energy,
computed as A = U −TS (where A is from the German arbeit, or
work), is then a measure of the amount of energy you have to put in
to create a system once the spontaneous energy transfer to the system
from the environment is accounted for. Note also that if the system
is subjected to an external force ﬁeld (e.g., an electric ﬁeld), any en-
ergy received from that ﬁeld is considered to be a part of A. The best
way to think about Helmholtz free energy is that it is the maximum
amount of work that a system can perform at constant temperature.
To understand enthalpy, ﬁrst consider Fig. 3.10. In this example,
constant air pressure p of the atmosphere is acting on surface area A
of the system with force F = pA and is compressing the volume V of
the system of interest. The work that the atmosphere has done to the
cylinder system is
∆w = F ∆x = (pA) ∆x = p(A ∆x) = p(−∆V) = −p ∆V,
noting that ∆V < 0 and so ∆w > 0.
Enthalpy is deﬁned as H = U + pV. The internal energy U might
be thought of as the energy required to create a system in the absence
of changes in temperature or volume. But if the process changes the
volume, as in a chemical reaction that produces a gaseous product,
then work must be done to produce the change in volume. For a
constant-pressure process, the work you must do to produce a vol-
ume change ∆V is p∆V. Then the term pV can be interpreted as the
extra work you must do to “create room” for the system if you pre-
sume it started at zero volume. Since it turns out that heat and work
change internal energy in equivalent ways (see Sect. 3.4.2), enthalpy
can also be thought of as the total amount of energy stored by the
system that could be released as heat. We will ﬁnd the concept of
enthalpy important when considering thermal effects in Chap. 7.
The Gibbs free energy is deﬁned as G = U + pV −TS. This is the net

3. microscale cell models
83
14 Note also that if the system is sub-
jected to an external force ﬁeld (e.g., an
electric ﬁeld), any energy received from
that ﬁeld is considered to be a part of
G.
15 Other common examples of state
functions are pressure p, volume V,
enthalpy H, Helmholtz free energy A,
entropy S, and Gibbs free energy G.
16 From Blundell, S.J. and Blundell,
K.M., Concepts in Thermal Physics,
chapter 11, Oxford University Press,
2009.
energy required to create a system in an environment having temper-
ature T, starting from a negligible initial volume. It can be thought
of as the maximum amount of work obtainable from a reaction in a
constant-temperature, constant-volume scenario.14 We will see that
the change in Gibbs free energy, ∆G, in a reaction is a very useful
parameter: it predicts the direction in which a chemical reaction will
proceed spontaneously.
3.4.2
The ﬁrst law of thermodynamics
The ﬁrst law of thermodynamics deals with the internal energy of a
system. An important property of the internal energy is that it is is
a state function. A state function is a precisely measurable physical
property such as temperature that characterizes the state of a system,
independently of how the system was brought to that state.15 For ex-
ample, you might increase the temperature of an object and arrive at
the same ﬁnal temperature either by performing work (e.g., via fric-
tion), or by adding heat (e.g., by subjecting to a warm environment),
or both. All that matters is the ﬁnal temperature, which is a function
of the system state.
We can deﬁne what we mean by a state function mathematically.
Let the state of the system be deﬁned by the vector x of parameters,
and let f(x) be some state function. Then, if the change in parameters
is from an initial state xi to a ﬁnal state x f , then the change in f is
∆f =
ˆ x f
xi
df = f(x f ) −f(xi).
This relationship depends only on the initial and ﬁnal points xi
and x f . It does not depend on the path taken between these two end-
points. We say that df is an exact differential. In contrast, a quantity
that is represented by an inexact differential is not a function of state.
A simple example of an exact differential is the function16 f = xy.
Then, df = d(xy) = y dx + x dy. Integrating d f from any initial
(xi, yi) point to any ﬁnal (x f , y f ) point will give the same answer of
(x f × y f ) −(xi × yi) regardless of the path taken.
On the other hand, a simple example of an inexact differential is
the function dg = y dx. (The strikeout through the d is used to show
that this is an inexact differential.) Then, for example, integrating
from (0, 0) to (1, 1) along a straight line y = x gives
∆g1 =
ˆ (1,1)
(0,0)
y dx =
ˆ 1
0
x dx = 1.
However, integrating from (0, 0) to (1, 0) along y = 0 and then to

84
battery management systems: volume i, battery modeling
17 This understanding is oversimpliﬁed
but is sufﬁcient for our purposes.
(1, 1) along x = 1 gives
∆g2 =
ˆ (1,0)
(0,0)
y dx +
ˆ (1,1)
(1,0)
y dx = 0.
The calculations for ∆g1 and ∆g2 had the same initial and ﬁnal points,
but yielded different results.
Returning to the problem at hand, the ﬁrst law of thermodynamics
states that dU = dq + dw, where dq is the amount of heat added to
a system and dw is the amount of work done on the system during
an inﬁnitesimal procedure. We use dq and dw rather than dq and
dw because they turn out not to be exact differentials—they merely
denote some inﬁnitesimal amount.
Thus, heat added to a system and mechanical work done on the
system are two equivalent ways to increase its internal energy, and
the total energy is conserved. If the system is isolated from its envi-
ronment, its internal energy does not change. Also, both heat and
work are forms of energy. For example, considering inﬁnitesimal
changes rather than macroscopic changes now, the work that the
atmosphere has done to the cylinder system in Fig. 3.10 is
dw = F dx = (pA) dx = p(A dx) = p(−dV) = −p dV.
3.4.3
The second law of thermodynamics
The second law of thermodynamics points out the spontaneous direction
of chemical reactions, using a concept called entropy. The easiest
way to understand entropy S is to deﬁne it as follows: S is a state
function such that during an isothermal reversible (inﬁnitesimally
slow) process, we have
dq = T dS,
where temperature T is kept constant. Therefore dS = dq/T during
isothermal reversible processes.
The second law of thermodynamics simply states that for any
system:
dS ≥dq
T ,
where equality is possible only in reversible processes.
Entropy can be intuitively understood as the amount of disorder
in a system.17 If heat is applied to the system and temperature kept
constant, entropy increases. If heat is removed from the system at
constant temperature, entropy has an opportunity to decrease.
The second law of thermodynamics can also consider the system
(denoted here by subscript 1) and the environment (denoted by sub-
script 2) together. Assume they are both at temperature T. The heat

3. microscale cell models
85
18 This example deals with macroscopic
energy, not internal energy, but the
same kind of idea applies.
transfer process (from 1 to 2, or vice versa) must follow dq1 = −dq2.
According to the second law of thermodynamics,
dS1 ≥dq1
T
and
dS2 ≥dq2
T .
Therefore, dS1 + dS2 ≥dq1+dq2
T
= 0 and dS = dS1 + dS2 ≥0.
This equation is another form of the second law of thermodynam-
ics, which states that a closed system’s entropy never decreases.
3.4.4
Gibbs free energy
We return to discuss Gibbs free energy, as it turns out to be the most
important measure of energy for our modeling purposes. The Gibbs
function is deﬁned to be: G = U + pV −TS. Free energy is how much
energy a system contains that can be harnessed to do work—we
cannot always bring energy down to zero.
Considering the different deﬁnitions of energies from Sect. 3.4.1,
this is not too hard to understand. If we are able to shrink the vol-
ume of the system down to zero, we can release the pV component
of G to do useful work. However, we cannot remove more than the
Helmholtz energy from the system. If we were to try to bring the
internal energy U down to zero, the environment would be ﬁghting
against us, wanting to add in its TS contribution. So, the minimum
energy state of a system is U = TS and G tells us the maximum
amount of energy that can be removed from the system.
As an analogy, consider a rock on the top of a cliff.18 It has the
potential to provide useful work (e.g., via a pulley). From elementary
physics, we know that the gravitational potential energy is equal
to mass times the acceleration of gravity times height. But, height
can never become zero (i.e., at the center of Earth). The rock can be
lowered only until it rests at the bottom of the cliff (not yet at zero
energy because not yet at the center of Earth). The environment
places a constraint on how much energy is free/available.
When pressure and temperature are held constant, the Gibbs
function can be interpreted as Gibbs free energy. The sign of G de-
termines in which direction a reaction will proceed spontaneously.
Spontaneous reactions always cause a decrease in G (i.e., dG < 0).
For a reaction to occur for which dG > 0, energy must be added to
the system.
The tendency of spontaneous decrease of G derives from the ten-
dency of increasing the total entropy of the system plus the environ-
ment. To show this, we need to write G = U1 + pV1 −TS1 with
the subscript “1” emphasizing that the entropy associated with G
is only S1, the entropy of the system. We denote the entropy of the

86
battery management systems: volume i, battery modeling
environment as S2. So, for system 1
dG = dU1 + pdV1 −TdS1
= dq1 + dw1 + pdV1 −TdS1
= dq1 −pdV1 + pdV1 −TdS1
= dq1 −TdS1.
We assume that the environment has reversible process dq2 =
T dS2 and recall dq1 = −dq2,
dG = −dq2 −T dS1 = −T dS2 −T dS1 = −T dS ≤0.
This is the sense in which we will use Gibbs free energy. It will be
a tool for us to understand the spontaneous direction of a chemical
reaction, from one equilibrium state to another.
3.5
Physical chemistry
We now take the background topics we have reviewed from thermal
physics and link them to topics in chemistry, yielding results gen-
erally considered to belong to the domain of the ﬁeld of physical
chemistry. This will prepare us to talk about electrolyte solutions
generally, and concentrated solution theory speciﬁcally.
To begin, we reﬂect on an attribute that was the same between
some of the physical parameters that we encountered while consider-
ing thermodynamics and was different between others. Speciﬁcally,
some of the parameters were normalized or relative quantities; others
were total or absolute quantities.
We say that a property is intensive if it is a normalized quantity. If
everything in a system is doubled, the value of an intensive property
remains unchanged. Examples of intensive properties are pressure,
temperature, concentration, and density.
We say that a property is extensive if it is a total quantity. If every-
thing in a system is doubled, the value of an extensive property also
doubles. Examples of extensive properties are internal energy, Gibbs
free energy, volume, and mass.
It is preferable to work with intensive properties, if possible. Then,
the absolute size of the system is not a factor of the models, and the
equations apply directly to any scale. To do so, we must normalize
extensive properties, possibly by dividing by volume or possibly by
dividing by mass.

3. microscale cell models
87
3.5.1
Molarity and molality
The electrolyte is a solution—a mixture created by dissolving a solute
in a solvent. There are two primary ways of creating an intensive
property out of the amount of solute in the solution:
• The concentration of a solution is commonly expressed by its
molarity, which is the number of moles of the dissolved solute per
liter of solution (not per liter of the solvent). The molarity of a
solution is deﬁned as
ci = nsolute i
Vsolution
.
(3.11)
We will use units of mol m−3 when describing concentrations, but
it is also common to see units of mol L−1. To convert from one unit
system to the other, note that 1 mol L−1 = 1, 000 mol m−3.
• This is not to be confused with the molality, which is the number
of moles of the dissolved solute per kilogram of solvent (not per
kilogram of solution). We compute molality as
mi = nsolute i
msolvent
(3.12)
in units of mol kg−1.
We will ﬁnd a need to understand both molarity and molality in the
derivation of the electrolyte models. Molarity is the more readily
understood conceptual framework, but molality provides an easier
experimental approach (it’s easier to measure a mass of solute and
a mass of solvent before mixing than it is to measure a mass and a
volume after mixing). At the appropriate time, we’ll discuss how to
convert between molarity and molality.
3.5.2
Electrochemical potential
To convert an extensive property of a substance to an intensive prop-
erty, we recognize that the extensive property must be proportional
to the total molar amount of the substance. But if there are multi-
ple species in the solution, the relationship between the extensive
property and the individual intensive properties is not immediately
obvious.
For example, suppose that there are n1 mol of species 1 and n2 mol
of species 2 in a solution. If we double only one of these quantities,
will the Gibbs free energy of the system double? The answer is no.
You must double the quantities of all species in the system for the
Gibbs free energy of the system to double.
Consequently, in multispecies systems, one has to deﬁne partial
molar quantities. Partial molar quantities describe how much an

88
battery management systems: volume i, battery modeling
19 Note that there is inconsistent usage
of terminology between physics, elec-
trochemistry, semiconductor physics,
and solid-state physics. Some ﬁelds
would name the quantity we have com-
puted as ¯µi to be chemical potential or
total chemical potential. We use the con-
ventions of electrochemistry, denoting
this term as electrochemical potential
instead, and reserving the term chem-
ical potential for the internal chemical
potential.
20 For example, z = −1 for an electron
and z = +2 for Cu2+.
extensive property changes if we add one mole of one species to the
system or solution.
Electrochemical potential ¯µ is deﬁned to be the partial molar Gibbs
free energy in a multispecies system. For species i, we deﬁne:
¯µi =
. ∂G
∂ni
/
T,p,nj(j̸=i)
,
where ni is the molar amount of species i, and the subscript nota-
tion indicates that we are keeping temperature, pressure, and molar
amounts of all other species constant. The electrochemical poten-
tial represents how easy or difﬁcult it is to add more of species i at
this particular location. If it is easy to add more of species i, then ¯µi
will be small (or negative)—either it requires only a small amount
of energy to do so, or energy is actually released by doing so. If it is
difﬁcult, then ¯µi will be large—it requires signiﬁcant energy to do so.
The units of ¯µi are J mol−1.
The electrochemical potential ¯µi can be thought of as the summa-
tion of two parts:
¯µi = ¯µi,internal + ¯µi,external,
where ¯µi,external refers to the sum of electric potential, magnetic poten-
tial, gravitational potential, and other forces from external ﬁelds, and
¯µi,internal includes everything else, such as density, temperature, and
enthalpy. In electrochemistry, we deﬁne chemical potential, denoted
as µi (without the overline), to be equal to the internal portion, and
electrochemical potential ¯µi as the total amount, including effects from
external ﬁelds.19
Assuming that gravitational and magnetic potentials are negligible,
chemical and electrochemical potentials are related via
¯µi = µi + ziFφ,
(3.13)
where zi is the valency (charge number) of the species,20 F is Fara-
day’s constant, and φ is the local electrostatic potential.
So, we can express a species’ electrochemical potential from the
Gibbs free energy of the system. But, can we express the Gibbs free
energy of a system in terms of the electrochemical potentials of all
its species? The key question here is whether G is a ﬁrst-order homo-
geneous function of ni (i.e., whether G(αn) = αG(n) for vector n).
If temperature and pressure are kept constant, this is true because
Gibbs free energy is an extensive quantity in thermodynamics. For
example, if only two species are present, G(2n1, 2n2) = 2G(n1, n2).
Therefore at constant temperature and pressure, Gibbs free energy is
a ﬁrst-order homogeneous function of ni.

3. microscale cell models
89
According to Euler’s theorem for homogeneous functions, we can
then state
G(n) = n · ∇G(n) = ∑
i
ni
∂G
∂ni
,
where n = (n1, n2, · · · ) is treated as a vector for convenience. Apply-
ing the deﬁnition of electrochemical potential, we have
G = ∑
i
ni ¯µi.
(3.14)
3.5.3
Gibbs–Duhem equation
The intensive quantities of a solution are not all independent: one can
be derived from the others. This result will be helpful, as it allows us
to remove one equation from the simultaneous set of equations we
must later solve.
We start with the prior deﬁnition of the Gibbs function,
G = U + pV −TS
dG = dU + d(pV) −d(TS)
= dq + dw + pdV + Vdp −TdS −SdT.
We know that dw = −pdV, and if we choose a reversible process,
then dq = TdS, giving
dG = Vdp −SdT
r
∑
i=1
nid ¯µi = Vdp −SdT.
This can be rearranged to be the Gibbs–Duhem equation:
S dT −V dp +
r
∑
i=1
ni d ¯µi = 0.
(3.15)
To understand the Gibbs–Duhem equation, it is easiest to con-
sider the simplest case. Assume that temperature and pressure are
constant and that there are only two species. Then
n1 d ¯µ1 + n2 d ¯µ2 = 0.
The Gibbs–Duhem equation states that in an isothermal and constant
pressure two-species solution, if the electrochemical potential of one
species increases, then it must decrease for the other species.
We will use the Gibbs–Duhem equation for a multispecies solution
at constant temperature and pressure. This result can be written as
r
∑
i=1
ni d ¯µi = 0.

90
battery management systems: volume i, battery modeling
Figure 3.11: Nonrandom grouping of
anions and cations in solution.
21 Oldham, K., Myland, J., and Bond, A.,
Electrochemical Science and Technology:
Fundamentals and Applications, Wiley,
2011.
If we divide both sides of this equation by volume, we get the equiva-
lent relationship
r
∑
i=1
ci d ¯µi = 0.
(3.16)
The key point to remember is this: if we know ci for i = 1 . . . r and
d ¯µi for i = 1 . . . r −1, then we can compute d ¯µr from that information.
This will eliminate one equation from the set of equations that we
need to solve.
3.5.4
Activity
In a solution, cations and anions are not located completely randomly.
The positive charge of a cation tends to attract anions around it and
to repel other cations. Similarly, the negative charge of an anion
tends to attract cations around it and to repel other anions. This is
illustrated in Fig. 3.11.
As a consequence, it is not as easy for an ion to move through
solution as it would be for an uncharged particle. The ion appears
to be larger than it truly is, since it attempts to drag other ions with
it and to push apart other groups of charged particles that are in its
way.
So, if we look at the ionic conductivity of a solution, it is lower
than expected. Ions do not move as quickly from a region of high
concentration to a region of low concentration as would be predicted
by a naïve model. It is as if the concentration gradient of the solute
has been diminished.
To reﬂect this phenomenon, you can introduce an “effective con-
centration” or activity ai < ci for each species i. We can think about
the activity of a species in a certain location as its “restlessness”
there.21 The greater the activity, the more eager the species is to
leave.
You can deﬁne a molar activity coefﬁcient fi such that for species i,
the activity
ai = ci fi,
where 0 ≤fi ≤1 characterizes how activity differs from concentra-
tion. We call it the “molar” activity coefﬁcient because the concentra-
tion used here is the molar concentration ci.
3.5.5
Absolute activity based on molarity
Activity of species i is also related to the chemical potential µi for
that species. Guggenheim deﬁned an absolute activity λi for species i
as
λi = exp
' µi
RT
(
.

3. microscale cell models
91
Conversely, we have
µi = RT ln λi.
(3.17)
This is related to the prior deﬁnition of activity via
λi = aia⊖
i ,
where a⊖
i is a constant of proportionality, independent of the concen-
tration or the electric potential, but dependent on the material types
of solute and solvent, and on temperature as well as pressure (if there
are gases). So it is deﬁned at standard temperature and pressure (STP)
T = 0 ◦C and p = 100 kPa. This also allows us a different way to
write relative activity if we deﬁne
a⊖
i = exp
,
µ⊖
i
RT
-
,
which gives us
ai = exp
,
µi −µ⊖
i
RT
-
.
Combining results, we see that λi can be broken down into three
terms:
λi = ci fia⊖
i ,
(3.18)
and so
µi = RT ln
!
aia⊖
i
" = RT ln
!
ci fia⊖
i
"
.
3.5.6
Absolute activity based on molality
To deﬁne absolute activity, we have used concentration ci (also
known as molarity) of the species as a basis. It is also possible to
deﬁne absolute activity in terms of molality mi.
To do so, we must use the dimensionless “molal” activity coefﬁ-
cient, which is denoted by γi. The new relation is
λi = miγiλ⊖
i .
(3.19)
Again, λ⊖
i is a proportionality constant with units kg mol−1.
No matter whether one uses molarity or molality, the computation
will give exactly the same value of λi (dimensionless).
3.6
Basic characteristics of binary electrolytes
Our ﬁnal major topic before beginning to derive the electrolyte con-
servation of mass and charge equations is that of understanding the
electrolyte. We are particularly concerned with a binary electrolyte,
that is, one having exactly two charged constituents. The electrolyte
then comprises the solvent, the positively charged ions (cations), and
the negatively charged ions (anions).

92
battery management systems: volume i, battery modeling
3.6.1
Stoichiometric coefﬁcient ν
The electrolyte is formulated by dissolving either a charge-neutral
acid, base, or salt into a charge-neutral solvent. Regardless of the
choice of solute, the resulting solution has a ﬁxed ratio of anions
and cations corresponding to the ratio in the originating solute. The
stoichiometric coefﬁcients of the ions specify this ratio.
For a salt such as Na2SO4, we deﬁne unsigned (positive) integer
stoichiometric coefﬁcients ν for both species (Na+ and SO2−
4 ). Since
Na2SO4 →2Na+ + SO2−
4 , we have νNa+ = 2 and νSO2−
4
= 1. Similarly,
for LiPF6 →Li+ + PF−
6 , we have νLi+ = 1 and νPF−
6 = 1. We also
sometimes use ν = ∑i νi.
Note that the symbol “ν” is not the letter “v”. It is the Greek letter
“nu.” A memory mnemonic is to think “n” is for “number” (of each
species), where ν is the Greek equivalent of “n.”
3.6.2
Charge number z
The charge number carried by an ion is represented by the signed
integer z. In Na2SO4, we have zNa+ = 1 and zSO2−
4
= −2 because the
sodium ion has a charge of +1, and the sulphate ion has a charge of
−2. Similarly, in LiPF6, zLi+ = 1 and zPF−
6 = −1. Notice that a cation
has z > 0 while an anion has z < 0.
3.6.3
Electroneutrality in binary electrolytes
Since the electrolyte is formulated by combining a charge-neutral
solute with a charge-neutral solvent, a macroscopic solution must
satisfy the electroneutrality condition that q = 0, where q is the total
charge. In an electrolyte, one must then have
∑
i
ziνi = 0.
(3.20)
If the electrolyte is a binary electrolyte, then we use subscripts “+”
for the cation, “−” for the anion, and “0” for the solvent. This gives
z+ν+ + z−ν−+ z0ν0 = 0.
However, the solvent is uncharged. Therefore, this expression
reduces to
z+ν+ + z−ν−= 0.
(3.21)
There is another way of stating the same concept. In a binary elec-
trolyte, the concentration of an ion is proportional to its stoichiomet-
ric coefﬁcient. That is, ci ∝νi. Further, if we use “+” for the cation
and “−” for the anion, then
c+
ν+ = c−
ν−
.

3. microscale cell models
93
The ratio is the concentration of the solute. We particularly use sym-
bol c (no subscript) for this ratio and obtain the following:
c = c+
ν+ = c−
ν−
,
(3.22)
where c is the concentration of the solute in the electrolyte.
By extension, we can rewrite Eq. (3.20) as
∑
i
zici = 0.
In particular, for a binary electrolyte,
z+c+ + z−c−= 0.
(3.23)
The charge-neutrality and solute-concentration equations (3.21),
(3.22), and (3.23) in this section are the characteristic equations for
a binary electrolyte and will be used frequently in the forthcoming
derivations.
3.6.4
An expression for current
Flux density N, at a particular point, through an inﬁnitesimal cross-
sectional area, can be expressed as velocity v multiplied by concentra-
tion c
N = cv mol m−2 s−1.
We are particularly interested in the ﬂux density of charged particles,
which support the movement of electrical current.
An electrolyte contains both positively charged cations and neg-
atively charged anions. The total current includes the contribution
from both
i = i+ + i−,
where i+ and i−represent contributions from the cations and anions,
respectively.
We can immediately write the expression for the currents:
i+ = z+FN+ = z+Fc+v+
i−= z−FN−= z−Fc−v−,
and
i = z+Fc+v+ + z−Fc−v−
= F∑
i
ziNi.
(3.24)

94
battery management systems: volume i, battery modeling
3.6.5
Continuity equations for mass and charge
The mass continuity equation states that at any point in the solution,
∂ci
∂t = −∇· Ni + Ri,
(3.25)
where Ri is the generation rate of species i at that particular point.
Note that ∇· Ni is the net ﬂux density out of the point; thus, it is
with a minus sign that it represents the contribution to the net in-
crease of the concentration at that particular point.
This equation is written for only one species. One can ﬁrst multi-
ply both sides by ziF:
F ∂zici
∂t
= −∇· (ziFNi) + ziFRi,
and then sum over all the species to obtain
∂
∂t F∑
i
zici = −∇·
,
F∑
i
ziNi
-
+ F∑
i
ziRi.
We here allow “generation” because chemical reactions may generate
new species. However, the species generated are charge balanced.
That is, if a cation is generated, there would be certain number of
anion(s) generated to balance the positive charge. Therefore, even if
we have Ri ̸= 0, we always have ∑
i
ziRi = 0. Hence, this equation
simpliﬁes to
∂
∂t F∑
i
zici = −∇·
,
F∑
i
ziNi
-
.
In fact, both sides of this equation are zero. The left-hand side is
zero because ∑i zici = 0 (as we have already shown, per Eq. (3.23)).
We recognize the right-hand side to be −∇· i. Hence
∇· i = 0.
(3.26)
This equation implies that charge can neither be stored nor cre-
ated nor destroyed in an electrolyte solution. It can be regarded as
a charge continuity equation.
3.7
Concentrated solution theory: Electrolyte mass conservation
The goal of the next major section is to derive the mass-balance equa-
tion for the electrolyte
∂c
∂t = ∇·
@
D
.
1 −d ln c0
d ln c
/
∇c
A
−i · ∇t0
+
z+ν+F −∇· (cv0).
This equation states that concentration changes occur due to three
causes:

3. microscale cell models
95
22 For dense gases, liquids, and poly-
mers, the (concentration-dependent)
diffusivities are not the same binary dif-
fusivities as for an ideal-gas deﬁnition,
however. See:
• Curtiss, C.F. and Bird, R.B., “Mul-
ticomponent diffusion,” Industrial
Engineering Chemical Research, 38,
1999, pp. 2,515–2,522; (Correction in
40, 2001, p. 1,791).
• Curtiss, C.F., and Bird, R.B.,
“Diffusion-stress relations in poly-
mer mixtures,” Journal of Chemical
Physics, 111, 1999, pp. 10,362–10,370.
• Diffusion: The ﬁrst term on the right-hand side of the equation is
a diffusion term, and models ions moving because of a concentra-
tion gradient.
• Migration: The second term models movement of ions due to ef-
fects of an electric ﬁeld. This effect is known as “migration.”
• Convection: The third term is a convection term, modeling move-
ment due to a pressure gradient—solute ions are pulled along by
the movement of the solvent.
The derivation is quite long, even with the background that we have
developed in thermodynamics, physical chemistry, and binary elec-
trolyte relationships. But, with patience we will arrive at our des-
tination. In the process, we will discuss some important topics in
solution theory, and speciﬁcally concentrated solution theory, which
describes the electrolyte of a lithium-ion cell better than the simpler
dilute solution theory approach.
As “mile-markers” to note progress in the deﬁnition, it may be
helpful to know in advance that we will proceed by taking the follow-
ing steps:
1. First, we look at the net force of collisions between species in
the electrolyte. The result of this section is the Maxwell–Stefan
relationship.
2. Then, we make a connection between the net force of collisions
and the electrochemical potential of the species. The result is a
multicomponent diffusion equation.
3. Third, we show how ion ﬂux can be expressed in terms of the
gradient of the chemical potential of the electrolyte.
4. Next, we ﬁnd an expression for the gradient of the chemical
potential in terms of the measurable quantities of interest.
5. Last, we derive the ﬁnal relationship of mass balance via diver-
gence of ﬂux density.
3.7.1
Step 1. The Maxwell–Stefan relationship
We begin by looking at Maxwell–Stefan theory, which tells us about
changes in momentum (and thus velocity) of multispecies systems
due to collisions of the particles that make up those systems. The
same basic result can be derived (differently) for ideal gases, dense
gases, liquids, and polymers.22 Because the proof is clearer and
more straightforward for ideal gases, we’ll proceed in that way, even
though we recognize that the electrolyte of a lithium-ion cell is most
frequently some kind of liquid or gel, and is sometimes even a solid
polymer.

96
battery management systems: volume i, battery modeling
23 Fun factoid: Maxwell wrote and was
known to sing,
“Gin a body meet a body,
ﬂyin’ through the air;
Gin a body hit a body,
will it ﬂy, and where? . . . ”
(From http://www.haverford.edu/
astronomy/songs/rigid.htm)
24 Present, R.D., Kinetic Theory of Gases,
Section 8.2, McGraw-Hill, 1958.
We start by considering collisions of particles in a two-species sys-
tem and subsequently extend the result to a multispecies system. In
particular, consider a unit volume containing two species of gas. Fur-
ther, consider a single species-1 molecule with mass m1 and original
velocity vm1, colliding with a single species-2 molecule with mass m2
and original velocity vm2. What happens?23 What can we say about
the velocity vectors of the particles after the collision?
We assume that the particle masses are not affected by the col-
lision, and we denote the postcollision velocity of the species-1
molecule as v′
m1 and the postcollision velocity of the species-2 molecule
as v′
m2. We know that the total momentum must be conserved. So,
we can write
m1vm1 + m2vm2 = m1v′
m1 + m2v′
m2.
Considering only the species-1 molecule, we can write its momen-
tum loss as
∆(m1vm1) = m1
!
vm1 −v′
m1
"
.
But, because of randomness, we cannot predict exactly what v′
m1 will
be. For example, if the particles collide “head on,” then the postcolli-
sion velocity vectors will be quite different from the case where one
particle strikes the other with a glancing blow. Proceeding down the
path of considering individual particle collisions appears to be a dead
end.
However, we can make progress if we concern ourselves with the
average velocities of the subsystems comprising species-1 and species-
2 particles, instead of considering the individual particle velocities
within those subsystems. Accordingly, we will change our notation
slightly: v1 denotes the precollision velocity of the mass center of all
particles of species-1, and v′
1 denotes the postcollision velocity of the
mass center of all particles of species-1. We will use v2 and v′
2 in a
similar way for the species-2 particles.
Next, we assume that the collisions are elastic; that is, that kinetic
energy is conserved before and after the collision, implying that
there is neither breakage, nor deformation, nor loss of energy due to
heat, for example. This turns out to be a reasonable assumption for
collisions between gas molecules in most cases.
Then, it is possible to derive the relationship24
v′
1 = m1v1 + m2v2
m1 + m2
.
The average momentum loss of the species-1 molecule is then:
∆(m1v1) = m1
!
v1 −v′
1
"
= m1
.
v1 −m1v1 + m2v2
m1 + m2
/

3. microscale cell models
97
25 Notation can be confusing, and care is
needed: p denotes the vector-quantity
momentum; p is, however, the scalar-
quantity pressure.
= m1
m2v1 −m2v2
m1 + m2
=
m1m2
m1 + m2
(v1 −v2) .
This result tells us that the average momentum transfer during a
collision is proportional to the original average velocity difference
between the two subsystems of molecules. If we consider the sub-
system of species-1 molecules only or the subsystem of species-2
molecules only, we ﬁnd that collisions within either subsystem do not
cause a change to the total momentum of that subsystem—because of
momentum conservation.
Therefore, considering subsystem-1, the only possibility to change
its total momentum is when one (or more) of its molecules undergoes
a collision with one (or more) of the species-2 molecules. That is, only
the inter-subsystem collisions transfer momentum from species-1 to
species-2, or vice versa.
Momentum change rate
The rate of change of momentum in a unit volume depends on
• The momentum change per collision, as just found;
• The frequency of collisions, which we now consider.
This frequency must be proportional to the concentration of species-
1, as well as the concentration of species-2. Hence, we can write the
momentum change rate of species-1 as
.dp
dt
/species-1
V
∝c1c2 (v1 −v2) ,
(3.27)
where c1 and c2 are the concentrations of species-1 and species-2,
respectively; p denotes momentum,25 and the subscript V on the
left-hand side denotes “per unit volume.” Their values are deﬁned by
c1 = n1/V and c2 = n2/V, where n1 and n2 are the number of moles
of species-1 and species-2, respectively, and V is the volume of the
system.
Next, we deﬁne the mole fraction of species i as xi = ni/n. So,
x1 = n1/n and x2 = n2/n. For a two-species system, we have that
x1 + x2 = 1; for a multispecies system, we have ∑i xi = 1.
We also deﬁne a new quantity called total concentration as
cT = ∑
i
ci,
(3.28)
where for a two-species system cT = c1 + c2. Total concentration is
the sum of the number of moles of all species, divided by the volume,
n/V.

98
battery management systems: volume i, battery modeling
Then, we can write
xi = ni
n = ni/V
n/V = ci
cT
.
So, for example, x1 = c1/cT and x2 = c2/cT.
Combining, we modify Eq. (3.27) to be
.dp
dt
/species-1
V
∝x1x2 (v1 −v2) .
According to Newton’s second law, F = dp/dt, and thus
F1,V ∝x1x2 (v1 −v2) ,
where the subscript V, again, denotes “per unit volume,” and F1,V
has units of newtons per cubic meter.
A problem remains: what is the coefﬁcient of proportionality?
From our latest result, one can argue that F1,V is a kind of friction
force since it is proportional to the difference between two velocities.
So, we deﬁne the Maxwell–Stefan friction coefﬁcient K12 so that F1,V =
K12 (v1 −v2).
We will ﬁnd that working with equations written in terms of Kij is
straightforward. However, ﬁnal models written in terms of Kij are not
desired, because this new proportionality “constant” is not constant.
It depends on speciﬁc values of x1 and x2. That is, K12 = constant ×
x1x2. The problem with this is that the equations are not written in
terms of intrinsic material properties (which can be measured), but in
terms of material properties weighted by the quantity of materials.
So, we will ultimately eliminate x1 and x2 by deﬁning the Maxwell–
Stefan diffusion coefﬁcient or Maxwell–Stefan diffusivity,
Dij = xixj
Kij
p,
where Dij is inversely proportional to the friction coefﬁcient Kij. Since
Kij characterizes how difﬁcult it is for the species to diffuse (because
of drag forces), Dij must characterize how easy it is for the species to
diffuse.
Solving for K12 in terms of D12, we then have
K12 = x1x2
D12
p = n
V
RTx1x2
D12
,
where we have used the ideal gas law, pV = nRT. Since cT = n/V,
x1 = c1/cT, and x2 = c2/cT, we can write
K12 = cT
RT c1
cT
c2
cT
D12
= RTc1c2
cTD12
.

3. microscale cell models
99
26 We use the product rule from calcu-
lus:
∂G1
∂x = ∂G1
∂¯µ1
∂¯µ1
∂x
∂G1
∂y = ∂G1
∂¯µ1
∂¯µ1
∂y
∂G1
∂z = ∂G1
∂¯µ1
∂¯µ1
∂z ,
and so can conclude that
∇G1 = ∂G1
∂¯µ1
∇¯µ1.
If there are more than two species, we need to use subscripts i and
j to denote species. In that case we can rewrite this as
Kij = RTcicj
cTDij
.
(3.29)
Note that this relationship uses the ideal gas law, but the same result
can be developed for liquids using electrochemical potentials instead.
According to Newton’s third law, the friction forces must be mu-
tual: Kij = Kji. Therefore, we must also have Dij = Dji. Finally, we
substitute Eq. (3.29) for K12 into the force equation to write the force
per unit volume as
F1,V = RTc1c2
cTD12
(v1 −v2) ,
(3.30)
which is also the momentum change rate of species-1.
We have actually stopped short of deriving the full Maxwell–
Stefan relationship, which states
∇xi = −∑
j
xixj
Dij
!
vi −vj
"
.
We won’t need this equation in our further development, but it is
still interesting. The velocity of species-i is positively related to the
velocity of the other species (they push species-i in the direction that
they are going) and negatively related to the concentration gradient
of species-i (the species’ own concentration tends to equalize due to
self-diffusion).
3.7.2
Step 2. Multicomponent diffusion equation
In deriving the Maxwell–Stefan relation, we assumed that the rate of
change of momentum of species-1 (that is, the net force experienced
by species-1) was due to collisions with other species. This is true
at a microscopic level. Now, we relate that force to the gradient of
electrochemical potential for charged species, which is how we would
describe it at a macroscopic level.
Force is equal to the negative gradient of Gibbs free energy26
F1 = −∇G1 = −∂G1
∂¯µ1
∇¯µ1 = −n1∇¯µ1,
where we have implied that ni = ∂G/∂¯µi from Eq. (3.14). The force
per unit volume is then
F1,V = F1
V = −n1
V ∇¯µ1 = −c1∇¯µ1.
Combining with Eq. (3.30), we now have
c1∇¯µ1 = RT c1c2
cTD12
(v2 −v1) .

100
battery management systems: volume i, battery modeling
We can generalize to the multicomponent case, giving
ci∇¯µi = RT ∑
j
cicj
cTDij
!
vj −vi
" = ∑
j
Kij
!
vj −vi
"
.
(3.31)
A sum over all the species gives
∑
i
ci∇¯µi = ∑
i ∑
j
Kij
!
vj −vi
"
.
3.7.3
Step 3. Concentrated binary electrolyte theory: Ion ﬂuxes
Our next goal is to prove the following relationship regarding ﬂux
density of cations (and the corresponding relationship for anions),
where c0 is the concentration of the solvent
N+ = c+v+ = −ν+D
νRT
cT
c0
c∇µe + it0+
z+F + c+v0.
(3.32)
Note that there are three new symbols in this equation:
• The electrolyte chemical potential µe;
• The electrolyte average diffusivity D;
• The transference number t0+.
The next subsections deﬁne these quantities, after which we prove
Eq. (3.32), which is the ﬂux-density equation that we will ultimately
associate with Li+ in the electrolyte.
Chemical potential of electrolyte
The chemical potential of a binary electrolyte represents how much
its Gibbs free energy changes when 1 mol of salt is added. We deﬁne
the chemical potential of the electrolyte as
µe = ν+ ¯µ+ + ν−¯µ−,
(3.33)
where the subscript “+” indicates the positively charged species and
the subscript “−” indicates the negatively charged species.
Note that we refer to the chemical potential of the electrolyte and
not the electrochemical potential because they turn out to be the same,
as the salt as a whole is neutral.
µe = ν+ ¯µ+ + ν−¯µ−
= ν+ (µ+ + z+Fφ) + ν−(µ−+ z−Fφ)
= ν+µ+ + ν−µ−+ (ν+z+ + ν−z−) Fφ
= ν+µ+ + ν−µ−
(3.34)
by Eqs. (3.13) and (3.21).

3. microscale cell models
101
An example will illustrate the meaning of µe. Suppose we have
an electrolyte comprising a solvent plus the salt Na2SO4, which has
ν+ = 2 and ν−= 1. According to the deﬁnition of electrochemical
potential, if one mole of Na+ is added, the Gibbs free energy of the
system increases by ¯µ+. If one mole of SO2−
4
is added, the Gibbs
free energy of the system increases by ¯µ−. So, if one mole of the
whole salt Na2SO4 is added, then the Gibbs free energy of the system
increases by 2 ¯µ+ + ¯µ−, or by, ν+ ¯µ+ + ν−¯µ−.
Eq. (3.32) requires the gradient of µe, which can be computed from
Eq. (3.33) to be
∇µe = ν+∇¯µ+ + ν−∇¯µ−.
We can compute the c∇µe term in Eq. (3.32) if we can ﬁrst compute
cν+∇¯µ+ = c+∇¯µ+ and cν−∇¯µ−= c−∇¯µ−terms.
We get these by evaluating terms from Eq. (3.31):
c+∇¯µ+ = K+0 (v0 −v+) + K+−(v−−v+)
c−∇¯µ−= K−0 (v0 −v−) + K−+ (v+ −v−) .
Adding these two equations together and using Eq. (3.22) gives
c∇µe = [K0+ (v0 −v+) + K+−(v−−v+)]
+ [K0−(v0 −v−) + K+−(v+ −v−)]
= K0+ (v0 −v+) + K0−(v0 −v−) .
(3.35)
This result will be used in the future.
Electrolyte average diffusivity
The electrolyte average diffusivity D is a weighted average of the
diffusivities of the anion and cation with respect to the solvent. It
will be convenient to express this average diffusivity in terms of the
Maxwell–Stefan friction coefﬁcients.
When deﬁning a weighted average diffusivity, it is important to
recognize that diffusivities add like conductivities; that is, they add
in reciprocal form. Accordingly, we deﬁne the weighted average
diffusion coefﬁcient D in terms of the stoichiometric coefﬁcients via
the relationship
ν
D = ν+
D0+
+ ν−
D0−
,
where we recall that ν = ν+ + ν−. Multiplying both sides of this
expression by c and recalling Eq. (3.22) gives D in terms of concentra-
tions, which allows us to write it also in terms of the Maxwell–Stefan
friction coefﬁcients using Eq. (3.29)
D =
νc
c+
D0+ +
c−
D0−

102
battery management systems: volume i, battery modeling
= RTc0
cT
⎛
⎝
νc
RTc0c+
cTD0+ + RTc0c−
cTD0−
⎞
⎠
= RTc0
cT
.
νc
K0+ + K0−
/
=
νRTc0c
cT (K0+ + K0−).
(3.36)
Transference numbers
A transference number states the fraction of ionic current i that is car-
ried by a certain species when there is no gradient in chemical potential.
We use the symbol t0
+ to denote the transference number of the
cation with respect to the solvent, and t0
−to denote the transference
number of the anion with respect to the solvent. Since we are looking
at a binary electrolyte, the transference number of the cation is pro-
portional to the drag experienced by the anion, and vice versa. That
is,
t0
+ ∝K0−
and
t0
−∝K0+.
To ﬁnd the constants of proportionality, we recognize that the
transference numbers must sum to one. So, we have
t0
+ =
K0−
K0−+ K0+
and
t0
−=
K0+
K0−+ K0+
.
(3.37)
Proving the ion-ﬂux equation
We are now ready to prove Eq. (3.32). We repeat it here and highlight
different parts of the equation for separate consideration:
N+ = c+v+ = −ν+D
νRT
cT
c0
#
$%
&
A
c∇µe
# $% &
B
+ it0+
z+F
#$%&
C
+ c+v0
#$%&
D
.
We ﬁrst look at the term identiﬁed as “A” and use Eq. (3.36)
−ν+DcT
νRTc0
= −ν+cT
νRTc0
νRTc0c
cT(K0+ + K0−)
= −
cν+
K0+ + K0−
= −
c+
K0+ + K0−
.
We now recall the value of the term identiﬁed as “B” from Eq. (3.35)
c∇µe = K0+ (v0 −v+) + K0−(v0 −v−) .
Multiplying terms “A” and “B” together gives
−ν+DcT
νRTc0
c∇µe = −
c+
K0+ + K0−
(K0+ (v0 −v+) + K0−(v0 −v−))

3. microscale cell models
103
= −c+v0 +
c+
K0+ + K0−
(K0+v+ + K0−v−) .
Adding term “D” gives
−ν+DcT
νRTc0
c∇µe + c+v0 =
c+
K0+ + K0−
(K0+v+ + K0−v−) .
Using Eq. (3.37), we write term “C” as
it0
+
z+F = z+Fc+v+ + z−Fc−v−
z+F
K0−
K0−+ K0+
= z+c+v+ −z+c+v−
z+
K0−
K0−+ K0+
=
c+
K0+ + K0−
(K0−v+ −K0−v−) .
Adding this term to the prior result gives
−ν+D
νRT
cT
c0
c∇µe + it0
+
z+F + c+v0 =
c+
K0+ + K0−
(K0+v+ + K0−v−)
+
c+
K0+ + K0−
(K0−v+ −K0−v−)
= c+v+.
So, we have now shown
N+ = c+v+ = −ν+D
νRT
cT
c0
c∇µe + it0+
z+F + c+v0.
(3.38)
Using the same approach, we can obtain the ﬂux density of the
anion as well:
N−= c−v−= −ν−D
νRT
cT
c0
c∇µe + it0
−
z−F + c−v0.
(3.39)
3.7.4
Step 4. An expression for the gradient of the chemical potential
We have nearly reached our desired result—the derivation of Eq. (3.3).
Before we ﬁnish, though, we need to express ∇µe in terms of concen-
trations.
Note that by the chain rule of calculus ∇µe = ∂µe
∂c ∇c. To achieve
the standard form of the result, we further break up the ﬁrst term
into
∂µe
∂c =
∂µe
∂ln m
∂ln m
∂c
,
where m is the molality of the solution. It is helpful to note that m =
m+
ν+ = m−
ν−and that the molality is related to molarity via mi =
ci
c0M0 ,
where M0 is the molar mass of the solvent.
Recall from our discussion of absolute activity (Eqs. (3.17) and (3.19))
that we can write µi = RT ln(λi), where λi = miγiλ⊖
i , and from

104
battery management systems: volume i, battery modeling
Eq. (3.34) that the chemical potential of the electrolyte can be written
as µe = ν+µ+ + ν−µ−, so we can write
µe = ν+RT ln(m+γ+λ⊖
+) + ν−RT ln(m−γ−λ⊖
−)
= ν+RT ln
!
mν+γ+λ⊖
+
" + ν−RT ln
!
mν−γ−λ⊖
−
"
= ν+RT
!
ln m + ln γ+ + ln(ν+λ⊖
+)
"
+ ν−RT
!
ln m + ln γ−+ ln(ν−λ⊖
−)
"
= (ν+ + ν−)RT ln m + RT
!
ln γν+
+ + ln γν−
−
"
+ ν+RT ln(ν+λ⊖
+) + ν−RT ln(ν−λ⊖
−)
= νRT (ln m + ln γ±) + ν+RT ln(ν+λ⊖
+) + ν−RT ln(ν−λ⊖
−),
where we deﬁne γν± = γν+
+ γν−
−, and γ± is known as the mean molal
activity coefﬁcient.
Therefore, we compute the ﬁrst term to be
∂µe
∂ln m = νRT
.
1 + ∂ln γ±
∂ln m
/
,
since none of the other terms are functions of m.
We now focus on the second term. We start by writing
m = m+
ν+ =
c+
ν+c0M0
=
c
c0M0
ln m = ln c −ln c0 −ln M0
∂ln m
∂ln c = 1 −∂ln c0
∂ln c
∂ln m
∂c
= 1
c
.
1 −∂ln c0
∂ln c
/
.
Putting the two results together, we get
∇µe = νRT
c
.
1 + d ln γ±
d ln m
/ .
1 −d ln c0
d ln c
/
∇c.
(3.40)
3.7.5
Step 5. Mass balance equation
We are now ready to prove Eq. (3.3). We begin with Eq. (3.32), which
we repeat here:
N+ = −ν+D
νRT
cT
c0
c∇µe + it0+
z+F + c+v0.
We now substitute in the value for ∇µe from Eq. (3.40),
N+ = −ν+D
νRT
cTc
c0
νRT
c
.
1 + d ln γ±
d ln m
/ .
1 −d ln c0
d ln c
/
∇c + it0
+
z+F + c+v0
= −ν+
DcT
c0
.
1 + d ln γ±
d ln m
/ .
1 −d ln c0
d ln c
/
∇c + it0
+
z+F + c+v0.

3. microscale cell models
105
27 Newman, J., Bennion, D., and Tobias,
C.W., “Mass Transfer in Concentrated
Binary Electrolytes,” Berichte der Bun-
sengesellschaft, 69, 1965, pp. 608–612.
Corrections, ibid., 70, 1966, p. 493.
28 See Doyle, M., Fuller, T.F., and New-
man, J., “Modeling the Galvanostatic
Charge and Discharge of the Lithi-
um/Polymer/Insertion Cell,” Journal
of the Electrochemical Society, 140, 1993,
pp. 1526–1533. However, note that this
assumption implies that the partial
molar volume of the salt is zero, which
is true only in dilute solutions, not in
concentrated solutions. To see how to
handle this term a different way for
concentrated solutions, refer to Xue,
K-H, and Plett, G.L., “A convective
transport theory for high rate discharge
in lithium ion batteries,” Electrochimica
Acta, 87, 2013, pp. 575–590.
Newman comments that the Maxwell–Stephan diffusivity (which
he refers to as the “thermodynamic diffusion coefﬁcient”) is not
usually what is measured in a laboratory test, but rather the value D
in27
D = D cT
c0
.
1 + d ln γ±
d ln m
/
,
where the difference between D and D is due to the choice of the
driving force and to the choice of the reference velocity in their deﬁni-
tions. Therefore, we can write
N+ = −ν+D
.
1 −d ln c0
d ln c
/
∇c + it0
+
z+F + c+v0.
This can be put into the continuity equation, Eq. (3.25)
∂c+
∂t = −∇· N+,
(assuming that no species are generated and that mass is conserved)
to obtain
∂c+
∂t = ∇·
@
ν+D
.
1 −d ln c0
d ln c
/
∇c
A
−∇·
,
it0+
z+F
-
−∇· (c+v0) .
Apply the identity that c+ = cν+,
ν+
∂c
∂t = ν+∇·
@
D
.
1 −d ln c0
d ln c
/
∇c
A
−ν+
∇·
!
it0
+
"
z+ν+F
−ν+∇· (cv0) ,
which can be rearranged to be
∂c
∂t = ∇·
@
D
.
1 −d ln c0
d ln c
/
∇c
A
−∇·
!
it0+
"
z+ν+F
−∇· (cv0) .
Note that
∇·
'
it0
+
(
= i · ∇
'
t0
+
(
+ t0
+∇· i,
and according to the charge continuity equation ∇· i = 0, we can
obtain
∇·
'
it0
+
(
= i · ∇t0
+.
Finally, we get:
∂c
∂t = ∇·
@
D
.
1 −d ln c0
d ln c
/
∇c
A
−i · ∇t0
+
z+ν+F −∇· (cv0) ,
which is the material-balance equation.
In practice, it is usually assumed that the concentration of the
solvent is insensitive to the concentration of the salt , so28
d ln c0
d ln c ≈0.

106
battery management systems: volume i, battery modeling
The simpliﬁed version is then
∂c
∂t = ∇· (D∇c) −i · ∇t0
+
z+ν+F −∇· (cv0) .
Specializing to a lithium-ion cell: the salt in the electrolyte is
typically LiPF6. This disassociates into Li+ and PF−
6 . Therefore,
ν+ = z+ = 1 (which is often true even if the salt is not LiPF6).
Further, we use subscripts “e” to distinguish between solid and elec-
trolyte phases, which gives mass conservation equation:
∂ce
∂t = ∇· (De∇ce) −ie · ∇t0+
F
−∇· (cev0) .
We have now derived Eq. (3.3).
3.8
Concentrated solution theory: Electrolyte charge conservation
We next develop an expression for charge conservation in the elec-
trolyte. Much of the background work has been done, so this deriva-
tion will go much more quickly.
First, we will ﬁnd an expression for current i in the electrolyte.
Then, we apply Eq. (3.26), which states that ∇· i = 0 to enforce
charge conservation. Finally, we make some substitutions to put the
equation in the ﬁnal form of Eq. (3.4).
Our ﬁrst step is to prove that
i = −κ∇φ −κ
F
,
s+
nν+ +
t0+
z+ν+ −s0c
nc0
-
∇µe,
(3.41)
where the parameters si represent the signed stoichiometric coefﬁcient
of species i in the electrode reaction
s−Mz−
−+ s+Mz+
+ + s0M0
−⇀
↽−ne−,
(3.42)
where Mzi
i is some “material” that takes place in the reaction, and
for generality, we assume that the solvent may participate in the
electrode reaction.
Note that si is different from νi. An example may help to illustrate
this. Specializing to a lithium-ion cell, the negative-electrode reaction
is
LiC6 −⇀
↽−C6 + Li+ + e−.
Putting this reaction into the form of Eq. (3.42) gives
LiC6 −C6 −Li+ −⇀
↽−e−.

3. microscale cell models
107
From this, we conclude that s−= 0 as no negatively charged
species participate, s+ = −1 because the coefﬁcient of Li+ is −1,
s0 = 0 because the solvent does not participate in the reaction, and
n = 1 because one electron is produced.
The positive-electrode reaction in a lithium-ion cell is
M + Li+ + e−
−⇀
↽−LiM,
where the “M” in LiM stands for some metal oxide in the positive-
electrode active material. Putting this reaction into the form of
Eq. (3.42) gives
LiM −M −Li+
−⇀
↽−e−.
Again, s−= 0, s+ = −1, s0 = 0, and n = 1.
The potential is introduced by recognizing that the Gibbs free en-
ergy of the n moles of electrons on the right-hand side of Eq. (3.42) is
equal to −nFφ, where φ is the local electrical potential. Since the en-
ergy of the product electrons must equal the energy of the reactants,
we have the energy balance
∑
i
si ¯µi = −nFφ
(where the summation includes the solvent), and we therefore must
also have
∑
i
si∇¯µi = −nF∇φ.
We have seen expressions involving ¯µ−and ¯µ+ before, but never
any relating to ¯µ0. We create an expression for ¯µ0 by recalling the
Gibbs–Duhem relationship of Eq. (3.16)
c+∇¯µ+ + c−∇¯µ−+ c0∇¯µ0 = 0
∇¯µ0 = −1
c0
(c+∇¯µ+ + c−∇¯µ−)
= −c
c0
(ν+∇¯µ+ + ν−∇¯µ−)
= −c
c0
∇µe.
So, we now have
s+∇¯µ+ + s−∇¯µ−−s0
c
c0
∇µe = −nF∇φ.
(3.43)
For charge balance in the original reaction, we must have
s+z+ + s−z−= −n
s−= −
. z+
z−
s+ + n
z−
/
,

108
battery management systems: volume i, battery modeling
so the ﬁrst terms in Eq. (3.43) can be found to be
s+∇¯µ+ + s−∇¯µ−= s+∇¯µ+ −z+
z−
s+∇¯µ−−n
z−∇¯µ−
= s+
ν+
.
ν+∇¯µ+ −z+ν+
z−∇¯µ−
/
−n
z−∇¯µ−
= s+
ν+ (ν+∇¯µ+ + ν−∇¯µ−) −n
z−∇¯µ−
= s+
ν+ ∇µe −n
z−∇¯µ−.
Putting these results together, we now have
s+
ν+ ∇µe −n
z−∇¯µ−−s0
c
c0
∇µe = −nF∇φ
. s+
nν+ −s0c
nc0
/
∇µe −1
z−∇¯µ−= −F∇φ.
(3.44)
The next step is to ﬁnd a relationship for ∇¯µ−, in terms of ∇µe
and i. We start with a familiar result, via Eq. (3.31),
c−∇¯µ−= K0−(v0 −v−) + K+−(v+ −v−) .
To ﬁnd the terms (v0 −v−) and (v+ −v−), we look at the (slightly
rearranged) ﬂux-density equations, Eqs. (3.38) and (3.39),
c+(v+ −v0) = −ν+D
νRT
cT
c0
c∇µe + it0
+
z+F
c−(v−−v0) = −ν−D
νRT
cT
c0
c∇µe + it0−
z−F.
We simplify these slightly before substitution by rewriting the D
term from Eq. (3.36) as
D =
νRTc0c
cT(K0+ + K0−),
giving revised but equivalent equations
v+ −v0 = −
c
K0+ + K0−
∇µe +
it0+
c+z+F
v−−v0 = −
c
K0+ + K0−
∇µe +
it0
−
c−z−F.
Subtracting the second equation from the ﬁrst gives
v+ −v−= i
F
,
t0+
c+z+ −
t0−
c−z−
-
=
i
c+z+F
'
t0
+ + (1 −t0
+)
(
=
i
c+z+F.

3. microscale cell models
109
We can now ﬁnd our expression for ∇¯µ−/z−
1
z−∇¯µ−=
1
c−z−[K0−(v0 −v−) + K+−(v+ −v−)]
=
1
c−z−
:
K0−
,
c
K0+ + K0−
∇µe +
it0
−
c+z+F
-
+ K+−
.
i
c+z+F
/;
=
c
c−z−
K0−
K0+ + K0−
∇µe + i
,
K0−t0−
c−z−c+z+F +
K+−
c−z−c+z+F
-
= −
c+
ν+c+z+
t0
+∇µe −Fi
,
−K0−t0−−K+−
c−z−c+z+F2
-
= −t0
+
ν+z+ ∇µe −Fi
κ ,
where we have recognized that the term multiplying i has units recip-
rocal to molar conductivity, and we deﬁne
1
κ = −K0−t0
−−K+−
c−z−c+z+F2
,
where κ is the ionic conductivity of the electrolyte and has units of
S m−1.
We are nearly done: we simply substitute this result for ∇¯µ−/z−
into Eq. (3.44)
−F∇φ =
. s+
nν+ −s0c
nc0
/
∇µe −1
z−∇¯µ−
−F∇φ =
,
s+
nν+ −s0c
nc0
+
t0+
ν+z+
-
∇µe + Fi
κ
i = −κ∇φ −κ
F
,
s+
nν+ −s0c
nc0
+
t0
+
ν+z+
-
∇µe.
We have now derived Eq. (3.41). However, in the literature, this
equation is usually expressed in terms of ∇ln c instead of ∇µe. We
proceed by recognizing that
∇µe = ∂µe
∂ln c∇ln c
and that µe = ν+ ¯µ+ + ν−¯µ−.
According to Eqs. (3.17) and (3.18), which connect the chemical
potential to absolute activity,
µ+ = RT ln
!
c+ f+a⊖
+
" = RT ln
!
ν+c f+a⊖
+
"
= RT ln (ν+) + RT ln (c) + RT ln ( f+) + RT ln
!
a⊖
+
"
.
Also, ¯µ+ = µ+ + z+Fφ. So,
∂¯µ+
∂ln c = RT + RT ∂ln f+
∂ln c + z+F ∂φ
∂ln c,

110
battery management systems: volume i, battery modeling
as the remaining terms are not functions of c. Similarly,
∂¯µ−
∂ln c = RT + RT ∂ln f−
∂ln c + z−F ∂φ
∂ln c.
Therefore,
∂µe
∂ln c = ν+
∂¯µ+
∂ln c + ν−
∂¯µ−
∂ln c
= (ν+ + ν−)RT + RT ∂ln
!
f ν+
+ f ν−
−
"
∂ln c
+ (ν+z+ + ν−z−)
#
$%
&
0
F ∂φ
∂ln c.
If we deﬁne f ν+
+ f ν−
−
= f ν± (where f± is known as the mean molar
activity coefﬁcient) and recall that ν = ν+ + ν−, then,
∂µe
∂ln c = νRT + RT ∂ln f ν±
∂ln c
= νRT
.
1 + ∂ln f±
∂ln c
/
.
Therefore, our expression for ionic current Eq. (3.41) becomes
i = −κ∇φ −νκRT
F
,
s+
nν+ −s0c
nc0
+
t0
+
ν+z+
- .
1 + ∂ln f±
∂ln c
/
∇ln c.
The conservation of charge equation says ∇· i = 0, which gives us
∇·
,
−κ∇φ −νκRT
F
,
s+
nν+ −s0c
nc0
+
t0
+
ν+z+
- .
1 + ∂ln f±
∂ln c
/
∇ln c
-
= 0.
Specializing to a lithium-ion cell, we have already found that
s−= 0, s+ = −1, s0 = 0, and n = 1. Also, ν+ = ν−= z+ = 1
for most electrolyte salts, so the charge conservation equation for a
lithium-ion cell is
∇· ie = ∇·
.
−κ∇φe −2κRT
F
.
1 + ∂ln f±
∂ln ce
/ '
t0
+ −1
(
∇ln ce
/
= 0,
where we have added the subscript “e” to denote the electrolyte.
We have now derived Eq. (3.4). Note that it is common to assume
that ∂ln f±/∂ln ce = 0 and to lump κD = 2κRT(t0+ −1)/F, giving
∇· (−κ∇φe −κD∇ln ce) = 0.
3.9
Butler–Volmer equation
We have now developed the four microscale model partial-differential
equations that describe the dynamics of a lithium-ion cell. We now
develop the ﬁfth equation, which couples the four PDEs together.

3. microscale cell models
111
Solid particle
Li
Li
+
Electrolyte
Figure 3.12: Dynamics at the particle
surface.
This ﬁnal model equation computes the rate of lithium moving be-
tween solid and electrolyte. As it deals with reaction rate, it is often
called the kinetics equation of the model.
Fig. 3.12 illustrates activity at the particle surface. In one direction,
positively charged lithium ions from the electrolyte combine with
an electron to become uncharged lithium, which intercalates into
the crystalline structure of the solid active material. In the other
direction, uncharged lithium deintercalates from the solid active
material, giving up an electron to the outside circuit, and becoming
positively charged lithium in the electrolyte.
3.9.1
Reaction rate
For a chemical reaction, reactants −⇀
↽−products, the reaction rate can
be deﬁned using the rate of overall product concentration change,
r =
d ∏i cproduct,i
dt
,
where the ∏i operation multiplies all of the reaction product concen-
trations together. For “ﬁrst-order” processes—ones that happen in a
single step—we can model this as
r = k∏
i
creactant,i
where k is the reaction rate constant for this chemical reaction.
For now, we think about a single reactant species and a single
product species, and later we generalize to the multispecies case, so
r =
dcproduct
dt
= kcreactant.
The reaction rate “constant” k generally depends on temperature, and
this temperature dependence is usually modeled via an Arrhenius
relationship,
k = k0
f exp
.
−Ea
RT
/
,
or
r = k0
f creactant exp
.
−Ea
RT
/
,
where Ea is the activation energy of the forward reaction. Both Ea and
k0
f are constants that are determined by experiments.
3.9.2
Activated complex theory
Reaction kinetics deal with nonequilibrium dynamics. The forward
direction of a reaction from reactants to products is favored if the
Gibbs free energy of the products is lower than the Gibbs free energy
of the reactants. However, there is generally an energy barrier to

112
battery management systems: volume i, battery modeling
Ea
∆E
Reaction coordinate
Reactants
Activated
complex
Products
Gibbs free energy
Figure 3.13: Progress of a chemical
reaction in terms of energy.
Low-energy collision
time
High-energy collision
Figure 3.14: Results of low-energy and
high-energy collisions.
overcome in order for the reaction to actually occur. This energy
barrier is equal to the activation energy Ea of the chemical reaction.
Fig. 3.13 illustrates the forward direction of a reaction in schematic
form.
Activated complex theory states that there is a transition state
(sometimes called the activated complex) in chemical reactions, where
the activated complex is neither the same as the reactants, nor is it
the same as the products. For example, in the reaction with reactants
A and B, products C and D, and forward and reverse activation
energies Ea,1 and Ea,2 respectively,
A + B
Ea,1
−⇀
↽−
Ea,2
C + D,
there is a transition state (AB)‡ where
A + B
Ea,3
−⇀
↽−
Ea,4
(AB)‡
Ea,5
−⇀
↽−
Ea,6
C + D.
The idea is that not every collision between reactants has enough
energy to break the original chemical bonds and allow a reaction to
occur. Most collisions result in elastic scattering events. Only when
there is sufﬁcient energy will the transition state form and the reac-
tion continue.
This is illustrated in Fig. 3.14. In the upper part of the ﬁgure, blue
and red reactants approach each other at a slow speed, with low
kinetic energy. They collide, but with insufﬁcient energy to break
their chemical bonds, so the reactants simply “bounce” off each other
without any change in chemical composition.
In the lower part of the ﬁgure, reactants approach each other at
a high speed, with high kinetic energy. When they collide, the en-
ergy is sufﬁcient to form the activated complex, and chemical bonds
are broken and reformed as product species. When the molecules
separate, they are now chemically altered.
3.9.3
Energy relationships in electrode reactions
Electrode reactions are different from standard chemical reactions
because they produce or consume electrons. An electrode reaction
has the form
o + ne−
reduction
−⇀
↽−
oxidization r,
(3.45)
where the forward reaction states that an oxidant o plus electron(s)
forms a product r, and where the reverse reaction states that a reduc-
tant r forms a product o plus product electron(s).
The application of an external electric ﬁeld can change the en-
ergy state of the electrons and hence can make the reaction more or

3. microscale cell models
113
less favorable. The progress of electrode reactions, where the elec-
trons are subjected to an arbitrary original electric potential φ0 and a
second electric potential φ < φ0, is shown in Fig. 3.15, where the orig-
inal progress plot is drawn in green (the lower plot) and the second
progress plot is drawn in blue (the upper plot).
Gibbs free energy
Reaction coordinate
Ea,r
∆Go
= −nF(φ −φ0)
E0a,r
∆Ea,o = ∆G‡
complex
E0a,o
Ea,o
−nFφ0
Figure 3.15: Energy relationships in an
electrode reaction where potential φ is
less than φ0.
In the ﬁgure, the activation energies for reduction and oxidation
under the original potential φ0 are denoted by E0
a,r and E0
a,o, respec-
tively. The modiﬁed activation energies under the lower potential φ
are denoted by by Ea,r and Ea,o, respectively. As drawn, we see that
the activation energies of the reaction are functions of the potential of
the electrode.
When the potential of the electrode is changed from φ0 to φ, the
total Gibbs free energy of the left-hand side of Eq. (3.45) changes
because there are electrons on the left-hand side; the total Gibbs free
energy of the right-hand side remains unchanged, as there are no
electrons. The change in the Gibbs free energy of the oxidants is
∆Go = −nF (φ −φ0) ,
where −nF is the total charge of the electrons. The Gibbs free energy
of the activated complex changes as well, but not as much as ∆Go:
0 <
+++∆G‡
complex
+++ < |∆Go| .
We see from the ﬁgure that ∆Go + Ea,r = ∆G‡
complex + E0a,r =
∆Ea,o + E0
a,r, or
∆Ea,o = Ea,r −E0
a,r −nF(φ −φ0)
= ∆Ea,r −nF(φ −φ0),
where we have deﬁned ∆Ea,r = Ea,r −E0
a,r.
We deduce that decreasing electrode potential from φ0 to φ < φ0
results in a change in ∆Ea,o that is greater than the change in ∆Ea,r.

114
battery management systems: volume i, battery modeling
We see this in the ﬁgure: Ea,o increases, and Ea,r actually decreases.
This makes the forward reaction much more favorable than before.
We run into a problem when trying to solve for speciﬁc values of
∆Ea,o and ∆Ea,r. By rearranging our result we further derive that
∆Ea,o −∆Ea,r = −nF(φ −φ0) = ∆Go,
implying that neither quantity is found uniquely from only (φ −φ0).
To be able to specify how much of the energy change is spent on
decreasing Ea,r while how much (the rest) is spent on increasing Ea,o,
we deﬁne an asymmetric charge-transfer coefﬁcient 0 < α < 1 such that
α =
++++
∆Ea,r
∆Go
++++ ,
and
1 −α =
++++
∆Ea,o
∆Go
++++ .
Then, we have ∆Ea,r = αnF(φ −φ0) and ∆Ea,o = −(1 −α)nF(φ −φ0).
Putting all our results to date together,
1. Rate of reduction:
rr = k0
oco exp
.
−Ea,r
RT
/
= k0
oco exp
,
−E0a,r + αnF(φ−φ0)
RT
-
.
2. Rate of oxidization:
ro = k0
rcr exp
.
−Ea,o
RT
/
= k0
rcr exp
,
−E0
a,o −(1−α)nF(φ−φ0)
RT
-
.
In a charge-balanced reaction, the production rate of e−is the same
as the production rate of positive charge, and hence: ir = −nFrr and
io = nFro. This gives
ir = −nFk0
oco exp
,
−E0
a,r + αnF(φ −φ0)
RT
-
io = nFk0
rcr exp
,
−E0
a,o −(1 −α)nF(φ −φ0)
RT
-
.
3.9.4
Specifying a neutral potential
Until now, we have assumed that the initial potential φ0 was arbitrary.
We now clean up our notation by setting φ0 = 0. Then, E0a,r and E0a,o
correspond speciﬁcally to φ0 = 0, and
ir = −nFk0
oco exp
,
−E0
a,r + αnFφ
RT
-

3. microscale cell models
115
io = nFk0
rcr exp
,
−E0a,o −(1 −α)nFφ
RT
-
.
Note that at equilibrium, φ = φrest. We deﬁne a new quantity, the
overpotential η = φ −φrest, so that
ir = −nFk0
oco exp
,
−E0
a,r + αnF(φrest + η)
RT
-
io = nFk0
rcr exp
,
−E0a,o −(1 −α)nF(φrest + η)
RT
-
.
Now, at equilibrium, η = 0 and we have
ir = −nFk0
oco exp
,
−E0a,r
RT
-
exp
.
−αnFφrest
RT
/
io = nFk0
rcr exp
,
−E0a,o
RT
-
exp
.(1 −α)nFφrest
RT
/
.
Further, i = io + ir = 0. We may deﬁne a quantity i0 (note that the
subscript is the numeral “0” and not the letter “o”) such that
i0 = nFk0
oco exp
,
−E0
a,r
RT
-
exp
.
−αnFφrest
RT
/
= nFk0
rcr exp
,
−E0
a,o
RT
-
exp
.(1 −α)nFφrest
RT
/
.
Then, even when not at rest,
ir = −i0 exp
.
−αnFη
RT
/
io = i0 exp
.(1 −α)nFη
RT
/
.
The total electrode current density is then
i = io + ir = i0
>
exp
.(1 −α)nFη
RT
/
−exp
.
−αnFη
RT
/?
,
which is the Butler–Volmer equation. Converting i from units of
A m−2 to mol m−2 s−1 by dividing both sides of this relationship by
Faraday’s constant gives
j = i0
F
>
exp
.(1 −α)nFη
RT
/
−exp
.
−αnFη
RT
/?
.
We have now derived Eq. (3.5). But we’re not quite ﬁnished yet.

116
battery management systems: volume i, battery modeling
3.9.5
Exchange current density
The quantity i0 is called the exchange current density. It is the value of
oxidation and reduction currents when the electrode is at rest. That
is, it is the rate at which electrons are continuously exchanged back
and forth in a dynamic equilibrium.
Note that its value depends on the concentration of various species
involved in the chemical reaction. Recall that we can write i0 as
i0 = nFk0
oco exp
,
−E0
a,r
RT
-
exp
.
−αnFφrest
RT
/
= nFk0
rcr exp
,
−E0a,o
RT
-
exp
.(1 −α)nFφrest
RT
/
.
Setting E 0a,r = exp
.
−E0a,r
RT
/
and E 0a,o = exp
.
−E0a,o
RT
/
and equating
these two equivalent versions of i0 gives
k0
rcrE 0
a,o exp
.(1 −α)nFφrest
RT
/
= k0
ocoE 0
a,r exp
.
−αnFφrest
RT
/
exp
' (1−α)nFφrest
RT
(
exp
'
−αnFφrest
RT
(
= k0ocoE 0a,r
k0rcrE 0a,o
(1 −α)nFφrest
RT
+ αnFφrest
RT
= ln
,
k0oE 0a,r
k0rE 0a,o
-
+ ln co
cr
φrest = RT
nF ln
,
k0oE 0a,r
k0rE 0a,o
-
#
$%
&
φ⊖
+ RT
nF ln co
cr
φrest = φ⊖+ RT
nF ln co
cr
.
This is the Nernst equation and describes the concentration depen-
dence of the rest potential. Substituting φrest back into i0 gives
i0 = nFk0
ocoE 0
a,r exp
.
−αnF
RT
.
φ⊖+ RT
nF ln co
cr
//
= nFk0
ocoE 0
a,r exp
.
−αnFφ⊖
RT
/
cα
r c−α
o
= nFk0
oc1−α
o
cα
r E 0
a,r exp
.
−αnFφ⊖
RT
/
,
and
i0 = nFk0
rcrE 0
a,o exp
.(1 −α)nF
RT
.
φ⊖+ RT
nF ln co
cr
//
= nFk0
rcrE 0
a,o exp
.(1 −α)nFφ⊖
RT
/
c1−α
o
cα−1
r

3. microscale cell models
117
= nFk0
rc1−α
o
cα
r E 0
a,o exp
.(1 −α)nFφ⊖
RT
/
.
Since these two equations are equal, we can deﬁne an effective
reaction rate constant
k0 = k0
oE 0
a,r exp
.
−αnFφ⊖
RT
/
= k0
rE 0
a,o exp
.(1 −α)nFφ⊖
RT
/
,
so we end up with the ﬁnal result
i0 = nFk0c1−α
o
cα
r .
(3.46)
It is interesting to investigate the form of k0 further, starting with
either side of the equation. For example,
k0 = k0
oE 0
a,r exp
.
−αnFφ⊖
RT
/
= k0
o exp
,
−E0a,r
RT
−αnFφ⊖
RT
-
= k0
o exp
,
−E0a,r
RT
−αnF
RT
. RT
nF
.
ln
.k0
o
k0r
/
+ ln E 0
a,r −ln E 0
a,o
//-
= k0
o exp
,
−E0
a,r
RT
−α
,
ln
.k0
o
k0r
/
−E0
a,r
RT + E0
a,o
RT
--
= k0
o
.k0o
k0r
/−α
exp
.
−1
RT
'
(1 −α)E0
a,r + αE0
a,o
(/
=
'
k0
o
(1−α '
k0
r
(α
exp
.
−1
RT
'
(1 −α)E0
a,r + αE0
a,o
(/
.
So, we see that the reaction-rate “constant” is a function of the
charge-transfer coefﬁcient α and furthermore a function of temper-
ature. It obeys an Arrhenius relationship, where the temperature-
independent rate constant is (k0
o)1−α(k0
r)α and the activation energy is
(1 −α)E0a,r + αE0a,o.
Generalizing Eq. (3.46) to the case where there are multiple reac-
tants and products, we have
i0 = nFk0
,
∏
i
co,i
-1−α ,
∏
i
cr,i
-α
.
For a lithium-ion cell, n = 1. Lithium ions in the electrolyte are
reduced to give lithium atoms in the solid. We then have
∏
i
co,i = ce(cs,max −cs,e),
where ce is the concentration of lithium in the electrolyte, cs,max is
the maximum concentration of lithium in the solid, and cs,e is the

118
battery management systems: volume i, battery modeling
29 For symmetry, one might expect to
have cr = cs,e(ce,max −ce), but that
form is rarely found in the literature.
It could be used if the electrolyte
salt concentration were approaching
saturation.
surface concentration of lithium in the solid. So (cs,max −cs,e) is the
concentration of available spaces for lithium atoms to enter.
For a lithium-ion cell, we also have cr = cs,e, and we typically de-
note φrest by Uocp, where “ocp” stands for “open-circuit potential.”29
The direction of lithium ﬂux depends on whether the potential differ-
ence between solid and electrolyte is above or below Uocp, so,
η = (φs −φe) −Uocp.
The ﬁnal Butler–Volmer relationship for a lithium-ion cell in
A m−2 is then
i = Fk0c1−α
e
(cs,max −cs,e)1−αcα
s,e
>
exp
.(1−α)F
RT
η
/
−exp
.
−αF
RT η
/?
.
We prefer using units of mol m−2 s−1, which gives
j = k0c1−α
e
(cs,max −cs,e)1−αcα
s,e
>
exp
.(1−α)F
RT
η
/
−exp
.
−αF
RT η
/?
.
Note that the sign of j is positive when lithium is moving from the
solid to the electrolyte and is negative when lithium is moving from
the electrolyte into the solid.
3.9.6
Normalizing units of k0
Notice that the units of k0 are rather awkward. The exponential
terms of the Butler–Volmer equation are unitless, and j has units
mol m−2 s−1. Therefore, k0 must have units of molα−1 m4−3α s−1.
Some computing platforms struggle with units having noninteger
powers, so this poses a problem.
A solution is to deﬁne a normalized version of the exchange cur-
rent density
i0 = Fk0c1−α
e
(cs,max −cs,e)1−αcα
s,e
= F k0c1−α
e,0 cs,max
#
$%
&
knorm
0
. ce
ce,0
/1−α .cs,max −cs,e
cs,max
/1−α . cs,e
cs,max
/α
,
where ce,0 is the at-rest equilibrium concentration of lithium in the
electrolyte. We see that rearranging the exchange current density in
this form makes the terms raised to noninteger powers themselves
unitless, and gives knorm
0
units of mol m−2 s−1, which is much easier
to work with. We can rewrite the Butler–Volmer equation as
j = knorm
0
.. ce
ce,0
/ .cs,max −cs,e
cs,max
//1−α . cs,e
cs,max
/α
×
>
exp
.(1 −α)F
RT
η
/
−exp
.
−αF
RT η
/?
.

3. microscale cell models
119
30 These equations can also apply to
any chemistry, with the understanding
that the equations that describe solid
diffusion in intercalation compounds
are not needed when modeling pure
chemical cells that do not have insertion
electrodes.
Figure 3.16: Example particle geome-
try in a small volume (colors are for
illustrative purposes only).
Also note that most articles that discuss simulation of lithium-ion
cells do not give values for k0. Instead, they give values of i0 that ap-
ply at the beginning of the simulation, from which you must derive
k0 or knorm
0
.
3.10
Implementing the model
We have now developed the ﬁve equations that describe conservation
of mass in the solid and electrolyte, conservation of charge in the
solid and electrolyte, and the ﬂux density of lithium between solid
and electrolyte, corresponding to the microscale dynamics that occur
within a lithium-ion cell.30
At this point in history, computational power is not sufﬁcient for
it to be feasible to simulate an entire cell using these equations—
the complexity is too high. Instead, some small volume, such as
depicted in Fig. 3.16, comprising both particles and electrolyte is
usually simulated instead. In the ﬁgure, the solid particles are drawn,
and the electrolyte is assumed to ﬁll the void between the particles.
To simulate this geometry, we need a PDE solver. We’re not going
to discuss the simulation process in detail in this chapter, but we will
look at it in the next chapter. We will see that, generally, the process
is to
1. Deﬁne the three-dimensional geometries of every solid particle,
the electrolyte, and the overall system. This is very challenging
if anything but very simple shapes are used. For example, even
the relatively simple truncated ellipsoids in Fig. 3.16 are quite
difﬁcult to describe. Usually, a computer-aided-design (CAD)
tool is used to help draw the geometries, and these geometries
are imported into the PDE solver.
2. Specify the PDEs and algebraic equations that operate in each
geometry. Eqs. (3.1) and (3.2) apply to parts of the geometry
describing the interior of solid particles, and Eqs. (3.3) and (3.4)
apply to parts of the geometry describing voids between the
particles that are ﬁlled with electrolyte.
3. Enter all parameters (such as conductivities, diffusivities, and
so forth) and functions (such as open-circuit potential functions)
for each geometry.
4. Deﬁne initial conditions, forcing functions, and boundary condi-
tions.
We have not yet looked at boundary conditions, but these are crit-
ical to being able to simulate a system. Boundary conditions are
equations that specify concentrations and potentials at the interface

120
battery management systems: volume i, battery modeling
between solid and electrolyte and at the edges of the simulation vol-
ume.
A boundary condition equation can be one of three generic types.
Dirichlet boundary conditions specify a constant value or a function
of time that is associated with a position on a boundary. Neumann
boundary conditions give values to the normal derivative of the
problem at positions on the boundary. Cauchy boundary conditions
are a combination of Dirichlet and Neumann boundary conditions.
It turns out that the boundary conditions for the four PDEs that
make up the microscale model are all of the Neumann type. We
derive them here, and they will be important in the next chapter as
well.
3.10.1
Boundary condition for charge conservation in the solid
We ﬁnd a boundary condition on the solid charge-conservation equa-
tion by starting with the expression for current in the solid from
Eq. (3.6):
σ∇φs = −is.
We notice that the left-hand side of this expression is a derivative,
so we expect a Neumann-style boundary condition. So, we take the
dot product of both sides of the equation with the normal vector,
which points out from the solid into the electrolyte
ˆns · ∇φs = −is · ˆns
σ
ˆns · ∇φs = −Fj
σ .
(3.47)
This is the Neumann-style boundary condition that applies to the
PDE that describes charge conservation in the solid.
3.10.2
Boundary condition for mass conservation in the solid
We ﬁnd the boundary condition on the solid mass-conservation equa-
tion in a very similar way. We start with the expression for lithium
ﬂux density in the solid from Eq. (3.9):
Ds∇cs = −N.
We take the dot product of both sides of the equation with the
normal vector, which points out from the solid into the electrolyte
ˆns · ∇cs = −N · ˆns
Ds
ˆns · ∇cs = −j
Ds
.
This is the Neumann-style boundary condition that applies to the
PDE that describes mass conservation in the solid.

3. microscale cell models
121
3.10.3
Boundary condition for mass conservation in the electrolyte
Finding the boundary conditions for the electrolyte PDEs is a little
more complex but still very manageable. Material ﬂux entering and
exiting the particle must be equal on both sides of the boundary. Flux
densities of cations, anions, and solvent at the interface between the
particle and the electrolyte are
N+ · ˆne = cv+ · ˆne = −j,
N0 · ˆne = cv0 · ˆne = 0,
N−· ˆne = cv−· ˆne = 0,
where N+ · ˆne = −j as j is ﬂux density from solid to electrolyte. The
sign is negative because ˆne points outward from the electrolyte into
the solid (that is, in the opposite direction from ˆns).
Evaluating these equations using Eq. (3.32) for N+ (and corre-
sponding result for N−)
−j = −ν+De
.
1 −d ln c0
d ln ce
/
∇ce · ˆne + ie · ˆnet0+
z+F
+ ν+cev0 · ˆne
0 = −ν−De
.
1 −d ln c0
d ln ce
/
∇ce · ˆne + ie · ˆnet0
−
z−F
+ ν−cev0 · ˆne.
Specializing to the lithium-ion case, ν+ = ν−= 1, z+ = −z−= 1, and
assuming that solvent velocity v0 = 0:
−j = −De
.
1 −d ln c0
d ln ce
/
∇ce · ˆne + ie · ˆnet0
+
F
0 = −De
.
1 −d ln c0
d ln ce
/
∇ce · ˆne −ie · ˆnet0−
F
.
To eliminate ie, we add t0
+/t0
−times the second equation to the ﬁrst
−j = −De
.
1 −d ln c0
d ln ce
/ ,
1 + t0+
t0
−
-
∇ce · ˆne
−t0
−j = −De
.
1 −d ln c0
d ln ce
/
∇ce · ˆne.
This gives us the Neumann-style boundary condition for ∇ce
ˆne · ∇ce =
1 −t0+
De
'
1 −d ln c0
d ln ce
( j.
(3.48)
3.10.4
Boundary condition for charge conservation in the electrolyte
To ﬁnd the ﬁnal boundary condition, we can substitute this value for
ˆne · ∇ce into the ﬂux-density equation to solve for ie at the boundary
−j = −De
.
1 −d ln c0
d ln ce
/
(1 −t0+)j
De
'
1 −d ln c0
d ln ce
( + ie · ˆnet0+
F

122
battery management systems: volume i, battery modeling
31 While the naming convention is a
little arbitrary, we use the term open-
circuit voltage for the cell-level quantity,
as voltage refers to a difference be-
tween two potentials. We use the term
open-circuit potential to refer to an
electrode-level quantity: in actual fact,
the potential of the electrode material
is determined by constructing a cell
whose negative electrode is lithium
metal and whose positive electrode is
the electrode material under consid-
eration. Therefore, the open-circuit
potential is the potential difference with
respect to a lithium metal electrode,
which may or may not be the electrode
used in the ﬁnal cell being considered.
0 = −De
.
1 −d ln c0
d ln ce
/
t0
−j
De
'
1 −d ln c0
d ln ce
( −ie · ˆnet0
−
F
.
Both expressions give identical results:
ie · ˆne = −jF.
(3.49)
Substituting this and the prior boundary condition into the ie
equation gives
−κ∇φe −κD∇ln ce = ie
ˆne ·
.
−κ∇φe −κD
ce ∇ce
/
= ˆne · ie
∇φe · ˆne =
⎛
⎝F
κ −κD
κce
t0
−
De
'
1 −d ln c0
d ln ce
(
⎞
⎠j
at the interface between the particle and the electrolyte.
In addition, ion ﬂux density is zero at external boundaries of the
cell.
3.11
Cell-level quantities
While simulating an entire cell using the equations developed in
this chapter is unreasonable given present-day computing power,
there are some cell-level variables that can be understood quite easily
from these lower-level equations. We describe these in the following
subsections.
3.11.1
Cell open-circuit voltage
As we saw in Chap. 2, the open-circuit voltage of a cell is the steady-
state terminal voltage when the cell is allowed to rest. In terms of
the model equations we have seen to date, this steady-state condition
means that concentration of lithium is uniform in all solid particles
in both electrodes, and the concentration of lithium is uniform in the
electrolyte.
The cell open-circuit voltage can then be related to the open-circuit
potentials of the two electrodes31
Ucell
ocv = Upos
ocp −Uneg
ocp.
To develop high cell voltages (for high energy-density), the positive-
electrode active material is chosen to have a high potential (versus a
lithium metal reference), and the negative-electrode active material is
chosen to have a low potential.

3. microscale cell models
123
0
0.2
0.4
0.6
0.8
1.0
0
0.5
1.0
1.5
2.0
Open-circuit potential of common
negative-electrode materials
OCP vs. Li/Li+ (V)
Stoichiometry (unitless)
 
 
LTO
Hard carbon
Coke
MCMB
Figure 3.17: Open-circuit potential of
two negative-electrode materials.
0
0.2
0.4
0.6
0.8
1.0
2.8
3.2
3.6
4.0
4.4
Open-circuit potential of common
positive-electrode materials
OCP vs. Li/Li+ (V)
Stoichiometry (unitless)
 
 
LMO
LCO
NMC
NCA
LFP
Figure 3.18: Open-circuit potential of
common positive-electrode materials.
Fig. 3.17 shows the open-circuit potential relationships of four ma-
terials commonly used for negative electrodes. Lithiated graphite
of some kind is found in nearly all current lithium-ion cells. The
chemical composition is LixC6, where x is a value between 0 and 1
indicating the stoichiometry of lithium in the electrode. (We compute
x = cneg
s
/cneg
s,max, where cneg
s,max is the total storage capability of the elec-
trode solid material when the crystal lattice structure is completely
full of lithium.)
The plot labeled “MCMB” is for “meso-carbon micro-beads,” or
very nearly spherical particles of graphite. However, there are vari-
ations between the open-circuit potential relationships for different
kinds of graphite (natural, synthetic) and hard or soft carbons with
the same generic chemical composition, depending on the relative
order or disorder of the layers. To illustrate this, we’ve also included
plots of the open-circuit potential of petroleum coke and hard carbon
(also having chemical composition LixC6).
The other material shown in the ﬁgure is lithium-titanate oxide
(LTO), with chemical composition Li4+3xTi5O12. While the high po-
tential of LTO makes it less attractive as a negative-electrode active
material, it is also relatively indestructible. Graphite electrodes tend
to degrade relatively quickly due to the formation of a surface ﬁlm
known as the solid-electrolyte interphase (SEI); however, LTO elec-
trodes do not appear to suffer from this same phenomenon and can
be cycled tens of thousands of times.
Fig. 3.18 shows the open-circuit potential relationships of several
materials commonly used for positive electrodes. Lithium-iron phos-
phate (LFP) has low voltage but long life, and has chemical composi-
tion LiyFePO4, where y is a value between 0 and 1 indicating the stoi-
chiometry of lithium in the electrode. (We compute y = cpos
s
/cpos
s,max.)
Lithium-manganese oxide (LMO) has higher voltage than LFP,
but suffers from rapid capacity degradation at high temperatures as
the manganese tends to dissolve into the electrolyte. It has chemical
composition LiyMn2O4.
Lithium-cobalt oxide (LCO) is more robust than LMO and has
higher energy than LFP, but tends to be used mostly for small cells
(such as used in portable electronics) as cobalt is expensive. The
chemical formulation of LCO is LiyCoO2.
There are other oxides that replace some of the cobalt in LCO
with different transition metals in order to reduce cost but main-
tain the otherwise desirable qualities of LCO. For example, some
of the cobalt may be substituted with nickel (which tends to make
the cell have a higher voltage but be less thermally stable), alu-
minum, or manganese. So-called NCA cells replace some cobalt
with nickel and some with aluminum: a common formulation is

124
battery management systems: volume i, battery modeling
32 Karthikeyan, D.K., Sikha, G., and
White, R.E., “Thermodynamic model
development for lithium intercalation
electrodes,” Journal of Power Sources, 185,
2008, pp. 1,398–1,407.
33 Prausnitz, J.M., Molecular Thermody-
namics of Fluid Phase Equilibria, Prentice
Hall, NJ, 3d, 1999.
LiyNi0.8Co0.15Al0.05O2. Also, NMC cells replace some cobalt with
nickel and some with manganese. Different relative amounts of
nickel and manganese can be used, but a reasonably common for-
mulation is LiyNi1/3Mn1/3Co1/3O2.
Open-circuit potentials of an electrode material are measured by
constructing a test cell whose negative electrode is lithium metal and
whose positive electrode material is the material under consideration.
The test cell is very slowly charged and discharged, carefully taking
into account the stoichiometry based on known amounts of material,
and the voltages are recorded. This process is much the same as
for measuring the open-circuit voltage of a full cell, as described in
Chap. 2.
The data can be stored as table lookup, but most often the litera-
ture reports closed-form analytic curve ﬁts based on approximating
the data with different kinds of functions. Ad hoc ﬁts with exponen-
tials and hyperbolic tangents can be found; others based on polyno-
mials or cubic splines are also popular. However, while these ﬁts can
describe the data well mathematically, they do not explain the under-
lying phenomena. Perhaps the ﬁrst article that proposed a general ﬁt-
ting function with some theoretic interpretation was by Karthikeyan
et al.32 In this work, a so-called Redlich–Kister expansion is used
to create a ﬁtting function. Here, we generalize their work by incor-
porating an empirical skew factor K into the expansion.33 With this
modiﬁcation, the cell open-circuit potential is computed as
U(x) = U0 + RT
F ln
.1 −x
x
/
+
1
(K(2x −1) + 1)2 ×
:
N
∑
k=0
Ak
F
.
(2x −1)k+1 −2kx(1 −x)
(2x −1)1−k
/
+ K
N
∑
k=0
Ak
F (2x −1)k '
2(k + 1)x2 −2(k + 1)x + 1
(;
.
In this equation, U0, K, and Ak for k = 0 . . . N are the free ﬁtting
parameters. Curve ﬁts for a number of commonly found electrodes
are tabulated in Table 3.2. These coefﬁcients were found by using a
Levenberg–Marquardt method to minimize the summed least-squares
error between the ﬁtting function and data from numerous sources,
cited in the chapter appendix.
3.11.2
Cell total capacity
Another cell-level quantity that can be quickly explained is the
ampere-hour total capacity of the cell. We develop a relationship
to compute this quantity in a sequence of steps, starting with expres-
sions for capacity of each electrode.

3. microscale cell models
125
MCMB
Petroleum
coke
Hard
carbon
LTO
LFP
LCO
LMO
NCA
NMC
K
1.000052×100
1.015189×10−5
9.896854×10−1
1.291628×10−1
3.932999×10−2 −2.369024×10−4 −9.996536×10−1
1.046644×10−4 −6.359610×10−1
U0
−4.894122×10−1
1.737471×101
5.839445×10−1
1.596152×100
3.407141×100
−2.276828×101
4.004463×100
−4.419803×100
3.755472×100
A1
1.115732×103
3.257341×106
6.433323×102
−2.730278×103
−2.244923×103
5.166082×106
2.888073×101
1.545979×106
−1.306411×103
A2
−1.144052×105
3.324795×106
9.277734×104
5.232911×103
−2.090675×103
−5.191279×106
−1.928965×104
−1.598187×106
−5.799521×104
A3
−9.895551×104
3.293786×106
1.208039×105
−8.075451×103
−6.045274×103
5.232986×106
2.751693×104
1.595170×106
1.285906×105
A4
−8.472647×104
3.305070×106
3.909709×104
−4.993786×103
−6.046354×103
−5.257083×106
2.599759×104
−1.605545×106
−1.418605×105
A5
−2.676083×105
3.341687×106
7.042733×104
3.643875×104
−1.395210×104
5.010583×106
4.795929×104
1.521194×106
1.281969×105
A6
−4.761692×105
3.286297×106
4.527821×105
1.105087×105
4.928595×104
−4.520614×106
−2.773488×105
−1.645695×106
−3.281283×105
A7
6.032508×105
2.786389×106
9.259981×105
−3.613702×105
5.768895×104
7.306952×106
−3.211625×105
1.809373×106
8.176398×102
A8
1.867866×106
2.943793×106
1.111642×102
−5.025253×105
−2.706196×105
−1.463426×107
9.984391×105
−1.578053×106
1.373879×106
A9
−1.698309×106
6.028857×106
−1.853447×106
1.401392×106
−2.623973×105
6.705611×106
1.227530×106
2.032672×106
6.511414×105
A10
−5.707850×106
8.242393×106
−3.232663×105
1.148841×106
6.954912×105
3.389416×107
−2.722189×106
−2.281842×106
−7.315831×106
A11
8.739993×105
1.365959×106
3.899277×106
−2.857197×106
4.805390×105
−6.352811×107
−1.973511×106
−1.678912×106
4.983891×106
A12
7.780654×106
−1.036909×107
2.862780×106
−1.211581×106
−8.818037×105
3.048793×107
4.613775×106
2.858489×106
6.925178×106
A13
1.486486×106
−1.328733×107
−2.837527×106
2.819998×106
−4.500675×105
2.144002×107
8.188394×105
5.443521×106
−6.123714×106
A14
−4.703010×106
−6.890890×106
−4.199996×106
4.791029×105
4.255778×105
−2.773199×107
−4.157314×106
−9.459781×106
−3.595215×106
A15
−2.275145×106
−1.366119×106
−1.406372×106
−1.091785×106
1.278146×105
8.206452×106
1.709075×106
3.600413×106
3.340694×106
Table 3.2: Modiﬁed Redlich–Kister expansion coefﬁcients for OCP ﬁts corresponding to commonly found electrode materials.

126
battery management systems: volume i, battery modeling
To compute the ampere-hour capacity of an electrode, we must
ﬁrst determine the capacity of the electrode in moles of lithium per
unit volume. In an extreme case, this might be equal to cs,max. How-
ever, practical cells don’t use this entire capacity (to stay away from
boundaries which either lead to rapid cell degradation or power
depletion)—we use only from x0% to x100% in the negative electrode
and from y0% to y100% in the positive electrode, where x is the value
between 0 and 1 in LixC6, for example, and y is the value between 0
and 1 in LiyCoO2, for example. By combining the cs,max and x0%,
x100%, y0%, and y100% values, we can ﬁnd the total used capacities of
the negative and positive electrodes, in moles per volume:
Qneg
V
= cneg
s,max |x100% −x0%| mol m−3
Qpos
V
= cpos
s,max |y100% −y0%| mol m−3.
Next, we need to determine the total volume of the solid material
in each electrode. We start with the total volume of the electrode,
which equals electrode plate area A multiplied by electrode thickness
L. However, not all of this volume is ﬁlled with solid—some is ﬁlled
with electrolyte, some with ﬁller, some with binder or other non-
active materials. The value εs is the fraction of the total electrode
volume that is occupied by the solid electrode material. Knowing this,
we can now compute the total used capacities of each electrode in
moles:
Qneg = ALnegεneg
s
cneg
s,max |x100% −x0%| mol
Qpos = ALposεpos
s
cpos
s,max |y100% −y0%| mol.
Finally, making use of Faraday’s constant and knowing that there
are 3, 600 s in 1 h, we can ﬁnd ampere-hour capacity.
Qneg = AFLnegεneg
s
cneg
s,max |x100% −x0%| /3600 Ah
(3.50)
Qpos = AFLposεpos
s
cpos
s,max |y100% −y0%| /3600 Ah.
(3.51)
Often, one electrode has somewhat more capacity than the other,
usually to minimize the occurrence of mechanisms that lead to cell
degradation. The overall cell capacity is the minimum of the two
electrode capacities:
Q = min (Qneg, Qpos) Ah.
(3.52)
3.11.3
Cell state of charge
Cell state of charge can be related either to the total amount of
lithium in the negative electrode or to the total amount in the positive
electrode. Similarly, by dividing the total amount of lithium in either

3. microscale cell models
127
electrode by the total volume of the solid active material in which it
resides, we can also relate state of charge to the average concentration
of lithium in the negative electrode or to the average concentration of
lithium in the positive electrode, where the average is computed over
the entire electrode.
When the cell is fully charged, the amount of lithium in the nega-
tive electrode is at its maximum allowable level, and the amount of
lithium in the positive electrode is at its minimum allowable level. In
terms of stoichiometries, cneg
s,avg/cneg
s,max = x100% and cpos
s,avg/cpos
s,max =
y100%.
Similarly, when the cell is fully discharged, the amount of lithium
in the negative electrode is at its minimum allowable level, and the
amount of lithium in the positive electrode is at its maximum allow-
able level. In terms of stoichiometries, cneg
s,avg/cneg
s,max = x0% (where
x0% < x100%) and cpos
s,avg/cpos
s,max = y0% (where y0% > y100%).
State of charge varies linearly as the stoichiometry of the negative
electrode varies between x0% and x100% (or, equivalently, as the sto-
ichiometry of the positive electrode varies between y0% and y100%).
Therefore, we can compute cell-level state of charge as:
z = cneg
s,avg/cneg
s,max −x0%
x100% −x0%
(3.53)
= cpos
s,avg/cpos
s,max −y0%
y100% −y0%
.
(3.54)
3.11.4
Single-particle model
As we have learned to date, there are ﬁve coupled equations in a
microscale cell model. These describe the movement of lithium in the
solid and electrolyte, voltage (potential) of the solid and electrolyte,
and the rate of reaction at the solid–electrolyte boundary at different
points in the cell.
It turns out that the diffusion of lithium inside the solid particles
is the slowest process, so its dynamic contribution dominates over
the others. Hence, we can consider a single-particle model (SPM)
of a cell, which simpliﬁes each electrode by modeling it as a single
spherical particle of active material representative of a typical particle
within the electrode. The dynamics of electrolyte concentration and
potential are ignored. While crude, the SPM is a good learning tool
for understanding how lithium-ion cells should respond to different
input stimuli, and they can be used within control designs to give
good estimates of state of charge.
To simulate diffusion of lithium within a single solid particle, we
might try several different approaches. Here, we introduce a ﬁnite-
volume method for discretizing the diffusion equation. A single solid

128
battery management systems: volume i, battery modeling
0
0.5
1.0
1.5
2.0
2.5
3.0
2
4
6
8
10
12Surface concentration of particle
Time (h)
Concentration (kmol m−3)
Figure 3.19: Output of code simulating
a single particle.
particle is divided into spherical shells having equal thickness (like
an idealized onion). At each time step the total ﬂux of lithium from
one shell to another is calculated, and the concentration of lithium
within each shell is then updated. Lithium is forced into or out of the
outermost shell via an imposed cell current.
Consider the following code for simulating a single particle, as the
particle is discharged, rested, charged, and rested (the output of this
code is plotted in Fig. 3.19).
% Replace constants below with relevant values for your problem
R = 10e-6;
% particle radius [m]
Cmax = 12000; % [mol/m^3]
c0 = 9500;
% initial concentration [mol/m^3]
j0 = 5000*R/3/1800; % lithium flux [mol/m^2/sec]
D = 1e-14;
% solid diffusivity, [m^2/s]
jk = [j0*ones(1,1800), zeros(1,3600)]; % discharge and rest
jk = [jk -jk]; % discharge and rest, then charge and rest
% Simulation control
Nr = 20;
% number of "shells" radially
dR = R/Nr; % width of each "shell"
Sa = 4*pi*(R*(1:Nr)/Nr).^2; % outer surface area of each shell
dV = (4/3)*pi*((R*(1:Nr)/Nr).^3-(R*(0:Nr-1)/Nr).^3); % vol. of ea. shell
dt = 1; % time steps of 1 second
c = c0*ones(1,Nr);
% concentration profile versus "r" dimension
cse = zeros(size(jk)); % concentration at surface
cse(1) = c0;
for timestep = 1:length(jk),
N = -D*diff(c)/dR;
% flux density at surfaces between "bins"
M = N.*Sa(1:end-1); % total moles crossing surface between bins
c = c + ([0 M] - [M 0])*dt./dV; % conc. change via diffusion
c(end) = c(end) - jk(timestep)*Sa(end)*dt/dV(end); % at boundary
cse(timestep+1) = c(end);
end
figure(1); clf; plot((0:length(jk))/3600,cse/1000);
title('Surface concentration of particle')
xlabel('Time (h)'); ylabel('Concentration (kmol m^{-3})')
In the code, the spherical particle is assumed to have Nr equal-
thickness onion-like “shells.” Thus, the thickness of any given shell
is dR = Rs/Nr. We will also need to know the outer surface area of
each shell and the volume of each shell:
• The innermost shell has volume dV1 = 4
3π(dR)3 and outer surface
area Sa1 = 4π(dR)2.
• The next shell has volume dV2 =
4
3π(2dR)3 −dV1 and outer
surface area Sa2 = 4π(2dR)2.
• By extension, the nth shell has volume
dVn = 4
3π(ndR)3 −4
3π((n −1)dR)3
and surface area San = 4π(ndR)2.

3. microscale cell models
129
The variables dV and Sa in the code are vectors containing the vol-
umes and outer surface areas of all shells, respectively.
Now, consider converting molar ﬂux density from a continuous
function of distance r to a discrete function at the shell boundaries.
N = −Ds∇cs = −Ds
∂cs
∂r ≈−Ds
∆cs
∆r .
The ﬂux density at the nth boundary between shell n and shell n + 1
can then be written as
Nn ≈−Ds
cn+1 −cn
dR
.
When the sign of Nn is negative, then ﬂux is entering the nth shell
from the (n + 1)st shell; when the sign is positive, ﬂux is leaving the
nth shell to the (n + 1)st shell. The vector N in the code computes
this ﬂux density at all shell boundaries, except at the outer surface
of the particle, which is computed separately. This ﬂux has units
mol m−2 s−1.
In the code, we then multiply N by the surface area of the shell
through which the ﬂux is passing to get a rate of material transfer.
This is the M variable in the code, in units mol s−1.
Considering any shell, there are two boundaries through which
this ﬂux can come: the inner surface and the outer surface. The total
increase in the number of moles in the nth shell is equal to SanNn −
San−1Nn−1 in units mol s−1. To get a change in concentration, we
must multiply by ∆t in seconds and divide by the volume of the nth
shell. The concentration update equation uses this logic to implement
the diffusion.
How about boundary conditions? We have an applied ﬂux density
j in mol m−2 s−1. Multiplying j by San∆t/Vn gives the change in
concentration of the outer shell because of the applied ﬂux every ∆t
seconds.
To ﬁnd the average interphase lithium ﬂux density in mol m−2s−1
for a given cell current in A, we must ﬁrst convert the cell current
from amperes to mol s−1. Faraday’s constant will help with this.
Next, we need to know how many square meters of interphase
area can be found in each electrode. To arrive at this answer, we must
ﬁrst calculate the speciﬁc interfacial area in m2 m−3. If we assume
that all electrode particles are spherical with radius Rs and that we
have solid-phase volume fraction εs, then
as = total surface area
total volume
= volume of solid
total volume
#
$%
&
εs
total surface area/particle
volume of solid/particle
= εs
4πR2s
4
3πR3s
= 3εs
Rs
.

130
battery management systems: volume i, battery modeling
This result computes how many square meters of particle surface
area there are per cubic meter of total electrode volume. So, asAL
gives the total square meters of particle surface area in an electrode,
and
j =
iapp
asFAL mol m−2 s−1.
Finally, while state of charge is dependent on the average con-
centration of lithium in the electrode, voltage is dependent on the
surface concentration of lithium (i.e., at the interface between the
solid and electrolyte). The code deﬁnes a variable cse, which is what
we denote cs,e elsewhere. When simulating an entire cell using the
single-particle method, one particle models the negative electrode
and a second particle (using a copy of the above code) models the
positive electrode. Cell voltage is equal to positive-electrode po-
tential minus negative-electrode potential. The positive-electrode
potential is determined by evaluating the Upos
ocp(y) function at the
value of y corresponding to the present surface concentration of
lithium of the positive-electrode particle, where y = cs,e/cs,max. The
negative-electrode potential is similarly determined by evaluating the
Uneg
ocp(x) function at the value of x corresponding to the present sur-
face concentration of lithium of the negative-electrode particle, where
x = cs,e/cs,max.
3.12
Where to from here?
We have now completed the most difﬁcult derivations in the book!
From now on, we depart from topics in thermodynamics, physical
chemistry, and electrochemistry and work from the model we have
now developed, successively bringing it up in scale until we arrive at
ordinary-difference equations.
But, the microscale model is the most accurate set of model equa-
tions we will have in the book. From now on, our goal is to approxi-
mate these equations with versions that are simpler to implement. At
the same time, we will attempt to minimize the error that we intro-
duce into the models by the approximations.
3.13
Chapter appendix: OCP sources
This appendix offers citations to the original sources of the data from
which Table 3.2 was constructed and from which Figs. 3.17 and 3.18
were plotted.
The MCMB data were digitized from Fig. A–1 in: S. Santhanagopalan,

3. microscale cell models
131
Q. Guo, and R.E. White, “Parameter Estimation and Model Discrim-
ination for a Lithium-Ion Cell,” Journal of the Electrochemical Society,
154(3), 2007, pp. A198–A206.
The petroleum-coke data were digitized from Fig. B–2 in: M.
Doyle, J. Newman, A.S. Gozdz, C.N. Schmutz, and J-M Tarascon,
“Comparison of Modeling Predictions with Experimental Data from
Plastic Lithium Ion Cells,” Journal of the Electrochemical Society, 143(6),
1996, pp. 1,890–1,903.
The hard carbon data were digitized from Fig. 1 in: D.K. Karthikeyan,
G. Sikha, R.E. White, “Thermodynamic Model Development for
Lithium Intercalation Electrodes,” Journal of Power Sources, 185, 2008,
pp. 1,398–1,407.
The LTO data were digitized from Fig. 4 in: S. Stewart, P. Alber-
tus, V. Srinivasan, I. Plitz, N. Pereira, G. Amatucci, and J. Newman,
“Optimizing the Performance of Lithium Titanate Spinel Paired with
Activated Carbon or Iron Phosphate,” Journal of the Electrochemical
Society, 155(3), 2008, pp. A253–A261.
The LFP data were digitized from Fig. 3 in: M. Safari and C. Dela-
court, “Modeling of a Commercial Graphite LiFePO4 Cell,” Journal
of the Electrochemical Society, 158(5), 2011, pp. A562–A571. From these
(depth-of-discharge) data alone, it is not possible to determine the sto-
ichiometric coefﬁcient y; this was found by calibrating the discharge
curve against Safari’s own curve ﬁt
ULFP
ocp = 3.4323 −0.8428 exp
'
−80.2493(1 −y)1.3198(
−3.2474 × 10−6 exp
'
20.2645(1 −y)3.8003(
+ 3.2482 × 10−6 exp
'
20.2646(1 −y)3.7995(
to determine the correct stoichiometric range of y corresponding to
the discharge curve.
The LCO data were digitized from Fig. A–2 in: S. Santhanagopalan,
Q. Guo, and R.E. White, “Parameter Estimation and Model Discrim-
ination for a Lithium-Ion Cell,” Journal of the Electrochemical Society,
154(3), 2007, pp. A198–A206.
The LMO data were digitized from Fig. B–1 in: M. Doyle, J. New-
man, A.S. Gozdz, C.N. Schmutz, and J-M Tarascon, “Comparison of
Modeling Predictions with Experimental Data from Plastic Lithium
Ion Cells,” Journal of the Electrochemical Society, 143(6), 1996, pp. 1,890–
1,903.
The NCA data were digitized from Fig. 2 in: D.K. Karthikeyan, G.
Sikha, R.E. White, “Thermodynamic Model Development for Lithium
Intercalation Electrodes,” Journal of Power Sources, 185, 2008, pp. 1,398–
1,407.

132
battery management systems: volume i, battery modeling
The NMC data were digitized from Fig. 6 in: S.G. Stewart, V. Srini-
vasan, and J. Newman, “Modeling the Performance of Lithium-Ion
Batteries and Capacitors during Hybrid-Electric-Vehicle Operation,”
Journal of the Electrochemical Society, 155(9), 2008, pp. A664–A671.
From these (depth-of-discharge) data alone, it is not possible to de-
termine the stoichiometric coefﬁcient y; this was found by calibrating
the discharge curve against the paper’s own curve ﬁt
UNMC
ocp
= 6.0826 −6.9922y + 7.1062y2
−0.54549 × 10−4 exp(124.23y −114.2593) −2.5947y3
to determine the correct stoichiometric range of y corresponding to
the discharge curve.
3.14
Partial glossary
This section gives a glossary of the most important variables deﬁned
in this chapter. Units are also given—the notation [u/l] is speciﬁed
for a unitless quantity. Note that all variables are at least potentially
functions of space and time.
• α [u/l] is the asymmetric charge-transfer coefﬁcient 0 ≤α ≤1
(cf. p. 114).
• a [mol m−3] is the activity of a species (cf. p. 90).
• as [m2 m−3] is the speciﬁc interfacial surface area (cf. p. 129).
• A [J] is the Helmholtz free energy (cf. p. 82).
• A [m2] is the cell current-collector plate area (cf. p. 126).
• c [mol m−3] is the concentration of lithium in the neighborhood
of a given location. cs is used to denote concentration in the solid,
and ce is used to denote concentration in the electrolyte (cf. pp. 76
and 93). c0 is the concentration of the solvent, and cT is the total
concentration (cf. pp. 100 and 97). cs,e is the surface concentra-
tion, and cs,max is the theoretic maximum lithium concentration
(cf. pp. 130 and 126).
• c+ and c−[mol m−3] are the concentrations of the cation and anion
in the electrolyte, respectively (cf. p. 92).
• D [m2 s−1] is a material-dependent diffusivity. Ds is used to denote
diffusivity in the solid, and De is used to denote diffusivity in the
electrolyte (cf. pp. 76 and 105).
• D [m2 s−1] is the Maxwell–Stefan diffusivity of a concentrated
solution (cf. pp. 98 and 101).
• εs [u/l] is the volume fraction of the solid in an electrode (cf. p. 126).
• E [V m−1] is the (vector) electric ﬁeld at a point (cf. p. 71).

3. microscale cell models
133
• F = 96,485 [C mol−1] is Faraday’s constant.
• f± [u/l] is the mean molar activity coefﬁcient (cf. p. 110).
• G [J] is the Gibbs free energy of a system or subsystem (cf. pp. 82
and 85).
• γ± [u/l] is the mean molal activity coefﬁcient (cf. p. 104).
• H [J] is the enthalpy of a system; dH is the heat added to or re-
moved from a system by a chemical reaction (cf. p. 82).
• η [V] is the reaction overpotential (cf. p. 115).
• i [A m−2] is the (vector) current density ﬂowing through a rep-
resentative cross-sectional area centered at a given location. is is
used to denote current density in the solid, and ie is used to de-
note current density in the electrolyte (cf. pp. 71 and 93).
• i0 [A m−2] is the exchange current density (cf. p. 116).
• j [mol m−2 s−1] is the rate of positive charge ﬂowing out of a
particle across a boundary between the solid and the electrolyte
(cf. p. 118).
• k0 [molα−1 m4−3α s−1] is the effective reaction-rate constant (cf. p. 117).
• knorm
0
[mol m−2 s−1] is a normalized version of the effective reac-
tion rate constant with less awkward units (cf. p. 118).
• Kab [J s m−4] is the Maxwell–Stefan friction coefﬁcient between
species a and b (cf. p. 98).
• κ [S m−1] is the ionic conductivity (cf. p. 109).
• κD [V] is an abbreviation of part of the electrolyte-potential equa-
tion: κD = 2RTκ(t0
+ −1)/F (cf. p. 110).
• λ [u/l] is the absolute activity of a species and can be written in
terms of molarity and molality (cf. pp. 90 and 91).
• L [m] is the electrode thickness (cf. p. 126).
• µ [J mol−1] is the chemical potential of a system (cf. p. 88).
• ¯µ [J mol−1] is the electrochemical potential of a system (cf. p. 88).
• m [kg] is mass of a species (cf. p. 87).
• n [u/l] is number of moles of a species (cf. p. 87).
• ˆn [u/l] is a unit vector pointing in an outward direction from a
surface, away from the phase of interest.
• N(x, y, z, t) [mol m−2 s−1] is the (vector) molar ﬂux density of
lithium ﬂowing through a representative cross-sectional area of
the solid centered at a given location (cf. pp. 76 and 93).
• NA = 6.02214 × 1023 [mol−1] is Avagadro’s number.

134
battery management systems: volume i, battery modeling
• ν+ and ν−[u/l] are the unsigned stoichiometric coefﬁcients of the
cation and anion, respectively (cf. p. 92).
• p(t) [kg m s−1] is the (vector) momentum of an object.
• p [Pa] is the pressure experienced by a system.
• φ [V] is the scalar ﬁeld representing the electrostatic potential at
a given point. φs is used to denote electric potential in the solid
and φe is used to denote electric ﬁeld in the electrolyte (cf. pp. 71
and 88).
• Q [C] is the charge in the vicinity of a given point (cf. p. 73).
• Q [Ah] is the total capacity of a battery cell (cf. p. 126).
• q [J] is the heat, usually considered as a delta dq of added/re-
moved heat to a system (cf. p. 84).
• R = 8.314 [J mol−1 K−1] is the universal gas constant.
• Rs [m] is electrode particle average radius (cf. p. 129).
• ρV(x, y, z, t) [C/m3] is the charge density (of positive charges) in the
vicinity of a given point (cf. p. 73).
• S [J K−1] is the entropy of a system (cf. p. 84).
• s+, s−, s0 [u/l] are the signed stoichiometric coefﬁcients of cation,
anion, and solvent, respectively (cf. p. 106).
• σ [S m−1] is a material-dependent parameter called the bulk conduc-
tivity of homogeneous materials without inclusions in the vicinity
of a given point (cf. p. 71).
• T [K] is the temperature at a point.
• t0
+ and t0
−[u/l] are the transference numbers of the cation and
anion with respect to the solvent, respectively (cf. p. 102).
• U [J] is the internal energy of a system (cf. p. 81).
• v [m s−1] is the (vector) velocity of a species.
• V [m3] is volume.
• w [J] is the work, usually considered as a delta dw of work done
on or by a system (cf. p. 84).
• x [u/l] is the mole fraction of a species (cf. p. 97).
• z+ and z−[u/l] are the signed charge numbers of the cation and
anion, respectively (cf. p. 92).
• z [u/l] is cell state-of-charge (cf. p. 127).

4.1
Chap. goal: Continuum . . . 136
4.2
Preliminaries . . . . . . . . . 137
4.3
Averaging theorem 1. . . . . 146
4.4
Averaging theorem 2. . . . . 148
4.5
Averaging theorem 3. . . . . 149
4.6
Solid charge conservation . . 152
4.7
Solid mass conservation . . . 156
4.8
Electrolyte mass conserv. . . 157
4.9
Electrolyte charge conserv. . 160
4.10 Butler–Volmer equation . . . 161
4.11 Boundary conditions . . . . . 161
4.12 Cell-level quantities . . . . . 163
4.13 Model simulations . . . . . . 164
4.14 Running COMSOL . . . . . 169
4.15 Where to from here? . . . . . 169
4.16 Partial glossary . . . . . . . . 170
Figure 4.1: A small volume inside an
electrode.
4
Continuum-Scale Cell Models
Mathematical models of physical phenomena are expressed most
readily at the microscopic scale. In Chap. 3, we saw that microscale
models of lithium-ion cell dynamics describe, in three dimensions,
the charge and mass balance within the solid particles and within the
electrolyte, separately. They can be used to simulate small volumes
inside electrodes, comprising small clusters of particles, in order to
get ideas of how particle sizes and mixtures of geometries, and so
forth, interact. However, it is infeasible with present technology to
simulate an entire cell using microscale models. For cell-level models,
we require reduced-complexity macroscale models that capture the
dominant physics of the microscale.
We refer back to Fig. 3.1 to help gauge our progress in model
development. We have completed deriving the microscale PDE model
of lithium-ion dynamics. In this chapter, we consider deriving the
next higher scale—the continuum-scale PDE model.
One approach to creating a macroscale model is by volume-
averaging microscopic quantities over a ﬁnite but small unit of vol-
ume. The resultant model is called a continuum model. Modeling
an object as a continuum assumes that the substance of the object
completely ﬁlls the space it occupies. So, modeling the electrode’s
solid particles in this way ignores the details of the pores in between
the particles, by which the solid electrode material is not contin-
uous. Modeling the electrolyte this way ignores the details of the
geometries of the particles that ﬁll it. However, on length scales much
greater than that of a particle’s radius, such models can be highly
accurate.
Any speciﬁc (x, y, z) coordinate inside an electrode corresponds
either to a position inside a solid particle or to a position inside the
electrolyte (or inside some inactive material such as a conductive
additive or binder), but it cannot correspond to a point both in the
solid and electrolyte. This is illustrated in Fig. 4.1, where particles
are depicted by (truncated and artiﬁcially colored) ellipsoid shapes,
135

136
battery management systems: volume i, battery modeling
1 The derivations rely heavily on: Gray,
W.G., and Lee, P.C.Y., “On the Theo-
rems for Local Volume Averaging of
Multiphase Systems,” International
Journal on Multiphase Flow, 3, 1977,
pp. 333–40.
and electrolyte ﬁlls the voids between the particles. To simulate this
portion of a lithium-ion cell’s electrode most accurately, we use the
microscale models from Chap. 3, which require complex geometric
maps of the electrodes to be able to determine which points belong to
the solid and which belong to the electrolyte. Equations of mass- and
charge-conservation in the solid dynamics are applied to the solid
regions; equations of mass- and charge-conservation in the electrolyte
dynamics are applied to the electrolyte regions. The Butler–Volmer
equation applies to the boundaries between regions.
Continuum models work differently. Because of the volume aver-
aging performed to develop a continuum-scale model, the resulting
equations assume that any (x, y, z) coordinate inside the electrode cor-
responds, in some sense, to a point both in the solid and electrolyte.
That is, continuum models tell you what is the typical or average
behavior inside the solid and electrolyte in the vicinity of a speciﬁc
point. Solid and electrolyte phases are still considered separately, but
their interactions within the volume must be factored in. Microscale
geometries need not be known—an average geometry is assumed.
Referring again to Fig. 4.1, the solid potential equation deﬁning
φs(x, y, z, t) is no longer concerned about whether (x, y, z) corre-
sponds to a point in the solid; the equation simply predicts the solid
potential of particles in the neighborhood of (x, y, z). Similarly, the
equations deﬁning solid lithium concentration, electrolyte potential,
electrolyte lithium concentration, and solid–electrolyte ﬂux density
describe quantities that are representative of the true variables in a
neighborhood of a speciﬁed point.
4.1
Chapter goal: The continuum-scale cell model
With all this in mind, the goal of this chapter is to derive the continuum-
scale cell model from the microscale model that has already been
developed. To be able to do so, we will need to ﬁrst derive three
theorems related to volume averaging:1
1. Volume-averaging theorem 1 for scalar ﬁeld ψ:
εα∇ψα = ∇(εα ¯ψα) + 1
V
¨
Aαβ(x,t)
ψα ˆnα dA.
(4.1)
2. Volume-averaging theorem 2 for vector ﬁeld ψ:
εα∇· ψα = ∇· (εα ¯ψα) + 1
V
¨
Aαβ(x,t)
ψα · ˆnα dA.
(4.2)
3. Volume-averaging theorem 3 for scalar ﬁeld ψ:
εα
@∂ψα
∂t
A
= ∂(εα ¯ψα)
∂t
−1
V
¨
Aαβ(x,t)
ψαvαβ · ˆnα dA.
(4.3)

4. continuum-scale cell models
137
The over-line notation “x” will be explained at the appropriate time,
as will the subscripts α and β.
Then, we will apply these volume-averaging theorems to the mi-
croscale model equations from Chap. 3 to derive
1. The volume-average approximation for charge conservation in
the solid phase of the porous electrode, which is
∇· (σeff∇¯φs) = asF¯j.
(4.4)
2. The solid-phase mass conservation equation, which is
∂cs
∂t = 1
r2
∂
∂r
.
Dsr2 ∂cs
∂r
/
.
(4.5)
3. The volume-average approximation for charge conservation in
the electrolyte phase of the porous electrode, which is
∇· (κeff∇¯φe + κD,eff∇ln ¯ce) + asF¯j = 0.
(4.6)
4. The volume-average approximation for mass conservation in
the electrolyte phase of the porous electrode, which is
∂(εe ¯ce)
∂t
= ∇· (De,eff∇¯ce) + as(1 −t0
+)¯j.
(4.7)
5. The volume-average approximation to the microscopic Butler–
Volmer kinetics relationship, which is
¯j = j(¯cs,e, ¯ce, ¯φs, ¯φe).
(4.8)
4.2
Preliminaries
Our ﬁrst goal is to derive the volume-averaging theorems of Eqs. (4.1)
through (4.3). To do so, we start by introducing some preliminary
concepts.
4.2.1
The α and β phases
A helpful abstraction is to divide the sample volume into two phases:
the phase-of-interest is denoted α; all other phase(s) are lumped into
β. When considering solid mass- and charge-conservation equations,
the solid is denoted as phase α and everything else is phase β. When
considering the electrolyte mass- and charge-conservation equations,
the electrolyte is denoted as phase α and everything else is phase β.

138
battery management systems: volume i, battery modeling
Candidate δ(t)
−ϵ/2
ϵ/2
1/ϵ
Figure 4.2: Sample one-dimensional
Dirac delta candidate function.
4.2.2
The indicator function
Our interest then will be in ﬁnding the average value of some quan-
tity in phase α. To help with notation, we deﬁne an indicator function
for phase α as
γα(x, y, z, t) =
⎧
⎨
⎩
1,
if point (x, y, z) is in phase α at time t;
0,
otherwise.
We will need to take derivatives of this function, which we might
imagine are zero everywhere except at the boundaries between phase
α and phase β. But what is the value of the derivative right on the
boundary?
4.2.3
The Dirac delta function
The derivative of the indicator function is known as a Dirac delta
function δ(x, y, z, t). This function is unusual—it is deﬁned in terms
of its properties rather than by stating exactly its value. These proper-
ties are
δ(x, y, z, t) = 0,
(x, y, z) ̸= 0.
˚
V
δ(x, y, z, t) dV = 1.
We see that this function must have unit volume but zero extent. This
is not an ordinary kind of function. It is a generalized function, which
can have many different but equivalent equations that describe it.
In one dimension, an example Dirac delta function is drawn in
Fig. 4.2 and is deﬁned by
δ(x) = lim
ϵ→0
F
1
ϵ,
|x| ≤ϵ/2;
0,
otherwise.
(4.9)
This has an integral of 1 for all values of ϵ, and as ϵ approaches zero,
it has zero width. We can make a more compact notation for this if
we deﬁne the “pulse function”
Π(x) =
⎧
⎨
⎩
1,
|x| < 1/2;
0,
otherwise.
Then, we can write
δ(x) = lim
ϵ→0
1
ϵ Π
'x
ϵ
(
.
Sifting property of δ(x, y, z, t)
The Dirac delta function has several properties that are important to
know. The ﬁrst we look at is the sifting property, which states that in

4. continuum-scale cell models
139
one dimension
ˆ ∞
−∞
f(x, t)δ(x −x0, t) dx = f(x0, t).
The value of the function at the location of the Dirac delta is “sifted
out,” and the integral of a function is replaced by the value of that
function at a speciﬁc point. In three dimensions, using vector form, if
x = (x, y, z), and x0 = (x0, y0, z0) we can write
˚
V
f(x, t)δ(x −x0, t) dV =
⎧
⎨
⎩
f(x0, t),
if x0 is inside V;
0,
otherwise.
We will sketch a proof of this relationship in one dimension for
x0 = 0. Consider using Eq. (4.9) as our candidate Dirac delta function,
and consider also Fig. 4.3. We write
ˆ ∞
−∞
f(x)δ(x) dx = lim
ϵ→0
ˆ ∞
−∞
1
ϵ Π
'x
ϵ
(
f (x) dx.
This operation is illustrated in Fig. 4.3.
ϵ
Height: f (0); width: ϵ
Π
! x
ϵ
"
f (x)
1
ϵ Π
! x
ϵ
"
f (x)
f (x)
Integrand is shaded
area divided by ϵ
Figure 4.3: Illustrating the sifting
property of the Dirac delta function.
From the ﬁgure, we see that f(x) is being multiplied by zero at
nearly every point inside the integral. In the ϵ neighborhood of x = 0,
however, it is being multiplied by 1/ϵ. If f(x) is continuous around
x0 = 0, then it will approach a constant value over the interval −ϵ/2
to ϵ/2, and that value will be f(0). So, the integral becomes f(0)
times the ϵ width of the Dirac delta multiplied by the 1/ϵ height of
the Dirac delta. That is,
ˆ ∞
−∞
f(x)δ(x) dx = 1
ϵϵ f(0) = f(0).
This proof sketch can be generalized to x0 ̸= 0 and higher dimensions
quite readily.

140
battery management systems: volume i, battery modeling
2 However, for other candidate Dirac
delta functions, this is not necessarily
the case. So, the integral is actually
undeﬁned but ﬁnite at x = 0.
Integrating a Dirac delta
Consider integrating a one-dimensional Dirac delta from −∞to x.
That is, we wish to compute
ˆ x
−∞
δ(χ) dχ.
This is illustrated in Fig. 4.4. The left frame of the ﬁgure shows three
candidate Dirac delta functions in different colors, starting with a
short and wide function, and ending with a tall and narrow function.
The taller and narrower the approximation, the closer it is to the true
Dirac delta function that it is approximating.
x
1
ϵΠ
! x
ϵ
"
x
´ x
−∞
1
ϵΠ
! χ
ϵ
"
dχ
Figure 4.4: Integrating approximate
Dirac delta functions of decreasing
width.
In the integral, if the point x is to the left of the rectangle, the in-
tegral is summing up a lot of zero values, and the result is zero. If
the point x is to the right of the rectangle, the integral contains the
entire Dirac delta function inside of its limits, so the result must be
one. If the point x falls in the middle of the rectangle, then the result
is somewhere between zero and one.2 This is illustrated in the right
frame of the ﬁgure, where the colors of the integrated approximate
Dirac delta functions correspond to the input functions in the left
frame. We see that the more closely the approximate Dirac delta func-
tion approaches the true Dirac delta, the more closely the integral
approaches a step function. In the limit, we have
ˆ x
−∞
δ(χ) dχ
=
F
0,
x < 0
1,
x > 0.
This tells us that the running integral of a Dirac delta function is a
step function. Furthermore, the derivative of a step function is the
Dirac delta function.
4.2.4
Gradient of the indicator function
Recalling that the indicator function is a steplike function, we expect
that its gradient will involve the Dirac delta function.
Consider the simple one-dimensional example plotted in Fig. 4.5.
The top of both frames shows segments of a sample volume, where

4. continuum-scale cell models
141
the shaded segments are phase β, and the clear segments are phase
α. The indicator function γα is one for values of x1 corresponding to
phase α or else it is zero. This is plotted in the left frame of the ﬁgure.
γα
∂γα
∂x1
x1
x1
β
β
β
β
β
β
α
α
α
α
α
α
1
a0
a0
a1
a2
a2
a3 a4
a4
a1
a3
Figure 4.5: Representing a two-phase
volume.
(Adapted from Fig. 1 in Gray, W.G.,
and Lee, P.C.Y., “On the Theorems for
Local Volume Averaging of Multiphase
Systems,” International Journal on Mul-
tiphase Flow, 3, 1977, pp. 333–40, with
permission from Elsevier.)
The right frame of the ﬁgure considers the gradient of the indica-
tor function. Speciﬁcally, the spatial derivative ∂γα/∂x1 comprises
Dirac delta functions, which are drawn as arrows in the ﬁgure.
∂γα(x1, t)
∂x1
= δ
!
x1 −a0(t)
" −δ
!
x1 −a1(t)
" + δ
!
x1 −a2(t)
"
−δ
!
x1 −a3(t)
" + δ
!
x1 −a4(t)
"
.
We now deﬁne a unit-normal vector ˆnα, which points outward from
the α phase toward the β phase at all α–β interfaces. This allows us to
write a more compact notation
∂γα(x1, t)
∂x1
= −
4
∑
k=0
ˆnα · ˆi δ
!
x1 −ak(t)
"
,
where ˆi is a unit vector in the positive x1 direction.
Now, consider a two-dimensional example, such as shown in
Fig 4.6. In the left frame, the α phase is unshaded, and the β phase
is shaded. In this instance, the spatial derivatives in the x1 and x2
directions are
∂γα(x1, x2, t)
∂x1
= −ˆnα · ˆi δ(x −xαβ, t)
∂γα(x1, x2, t)
∂x2
= −ˆnα · ˆj δ(x −xαβ, t),
where x is a position vector, ˆj is a unit vector in the positive x2 direc-
tion, and xαβ is the position vector of the α–β interface. The middle
and right frames of the ﬁgure show the partial derivatives in the x1
and x2 directions, respectively.
Note that the varying heights of the impulse functions are due
to the dot product between ˆnα and either ˆi or ˆj. When these vectors
are aligned, the dot product will be one; when they are at right an-
gles, the dot product will be zero; otherwise, the dot product will be
somewhere in between (by the law of cosines).

142
battery management systems: volume i, battery modeling
β-phase
α-phase
γα
1
x1
x2
β-phase
α-phase
x1
x2
∂γα
x1
β-phase
α-phase
x1
x2
∂γα
x2
Figure 4.6: Two-dimensional example of
a two-phase volume.
(Adapted from Fig. 2 in Gray, W.G.,
and Lee, P.C.Y., “On the Theorems for
Local Volume Averaging of Multiphase
Systems,” International Journal on Mul-
tiphase Flow, 3, 1977, pp. 333–40, with
permission from Elsevier.)
x1
x2
x3
x
ξ1
ξ2
ξ3
ˆn
Figure 4.7: Coordinate system for
volume-averaging theorems.
(Adapted from Fig. 3 in Gray, W.G.,
and Lee, P.C.Y., “On the Theorems for
Local Volume Averaging of Multiphase
Systems,” International Journal on Mul-
tiphase Flow, 3, 1977, pp. 333–40, with
permission from Elsevier.)
We generalize to three dimensions by deﬁning the gradient opera-
tor over some scalar ﬁeld ψ(x, y, z, t) as
∇ψ(x, y, z, t)
△= ∂ψ
∂x
ˆi + ∂ψ
∂y
ˆj + ∂ψ
∂z
ˆk.
Then, ∇γα(x, t) = −ˆnαδ(x −xαβ, t).
4.2.5
Deﬁnitions for averaging
When applying averaging techniques to obtain continuum equations
for porous media, it is necessary to select an averaging volume that
will result in meaningful averages. This can be met when the char-
acteristic length of the averaging volume is much greater than the
dimension of the pore openings (between particles) in the medium,
but much less than the characteristic length of the medium. In addi-
tion, the shape, size, and orientation of the averaging volume should
be independent of space and time.
We deﬁne a local coordinate system ξ1, ξ2, ξ3, which has axes
parallel with the x1, x2, x3 system, but whose origin is located at
position x. The x1, x2, x3 coordinate system is the ﬁxed reference
frame of the electrode under consideration. The vector x determines
the location of the averaging volume under consideration. The local
coordinate system moves its origin with x, and ξ1, ξ2, and ξ3 denote a
position within that averaging volume. This is depicted in Fig. 4.7.
This double coordinate system representation allows us to deﬁne
points inside the averaging volume with respect to the ξ coordinate
system independently of x. For example, we may set the centroid of
the averaging volume to the origin of the ξ system.
With this in mind, we deﬁne two different kinds of volume aver-
ages. The phase average ⟨θα⟩of a property θ over phase α is deﬁned
as
⟨θα(x, t)⟩= 1
V
˚
V
θ(x + ξ, t)γα(x + ξ, t) dVξ,

4. continuum-scale cell models
143
where volume V = Vα + Vβ is independent of space and time. How-
ever, Vα and Vβ themselves will depend on x and will also depend on
t if the medium is deformable (i.e., the phase boundary moves).
Physically, the phase average is a property of only the α phase
averaged over the entire volume occupied by both the α and β phases
in the averaging volume. Note that we could also write this integral
as
⟨θα(x, t)⟩= 1
V
˚
Vα(x,t)
θ(x + ξ, t) dVξ,
but this is less useful because the limits of integration depend on
spatial location and on time if the medium deforms.
The intrinsic phase average ¯θα of some property θ with respect to
phase α is given by
¯θα(x, t) =
1
Vα(x, t)
˚
Vα(x,t)
θ(x + ξ, t) dVξ.
This type of average describes a property of the α phase averaged
over the volume occupied by that phase only. Comparing the two
types of phase average, we see
⟨θα(x, t)⟩= εα(x, t) ¯θα(x, t),
or
¯θα(x, t) =
1
εα(x, t) ⟨θα(x, t)⟩,
(4.10)
where the volume fraction of the α-phase in the medium is deﬁned as
εα(x, t) = Vα(x, t)
V
= 1
V
˚
V
γα(x + ξ, t) dVξ.
As an example to illustrate the difference between the phase av-
erage ⟨θα⟩and the intrinsic phase average ¯θα, consider a beaker
ﬁlled with rocks, where the porosity εs = 0.5. We have a second
beaker ﬁlled with electrolyte solution where the salt concentration is
1, 000 mol m−3. We pour the solution into the ﬁrst beaker until it is
full, so that εe = 0.5.
Taking a phase average of salt concentration in the porous media,
⟨ce⟩= 1
V
˚
Ve
ce(x + ξ, t) dVξ
= ce
Ve
V = 0.5ce = 500 mol m−3.
Taking an intrinsic phase average of the salt concentration instead,
¯ce = 1
Ve
˚
Ve
ce(x + ξ, t) dVξ
= ce
Ve
Ve = ce = 1, 000 mol m−3.
The phase average tells us, from the perspective of the entire vol-
ume, what is the concentration of salt in the volume (i.e., the total

144
battery management systems: volume i, battery modeling
number of moles of salt divided by the total volume). The intrin-
sic phase average tells us, from the perspective of the solution itself
within the volume, what is the concentration of salt in the solution
(i.e., the total number of moles of salt divided by the volume of the
solution).
The intrinsic phase average is more readily related to the mi-
croscale models where physical measurements are made, so it is
the one we will use. But, we will derive our equations in terms of
the phase average ﬁrst (because this is easier to do) and convert to
intrinsic phase averages when ﬁnished.
4.2.6
Two equivalent forms of gradient operator
Because we have deﬁned two coordinate systems, there will be an
opportunity to take gradients of quantities with respect to either one
or the other. Deﬁne ∇x to refer to the gradient taken with respect to
the x coordinates, holding ξ1, ξ2, and ξ3 constant; deﬁne ∇ξ to refer
to the gradient taken with respect to the ξ coordinates, holding x1, x2,
and x3 constant; and deﬁne ∇to refer either to ∇x or ∇ξ.
A result that we will need is this: if a function is symmetrically
dependent on x and ξ (i.e., it depends on the sum x + ξ rather than
on x and ξ individually or in some other combination), the gradient
in the x coordinate system is equal to the gradient in the ξ coordinate
system:
∇xθ(x + ξ, t) = ∇ξθ(x + ξ, t) = ∇θ(x + ξ, t)
(4.11)
∇xγα(x + ξ, t) = ∇ξγα(x + ξ, t) = ∇γα(x + ξ, t).
(4.12)
To prove this result, ﬁrst consider the gradient with respect to the
x coordinate system
∇xθ(x + ξ, t) = ∇xθ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
= ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂x1
ˆi
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂x2
ˆj
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂x3
ˆk.
We invoke the chain rule of calculus to introduce partials with respect
to the symmetric dependencies (x1 + ξ1), (x2 + ξ2), and (x3 + ξ3).
∇xθ(x + ξ, t) = ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x1 + ξ1)
∂(x1 + ξ1)
∂x1
#
$%
&
1
ˆi

4. continuum-scale cell models
145
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x2 + ξ2)
∂(x2 + ξ2)
∂x2
#
$%
&
1
ˆj
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x3 + ξ3)
∂(x3 + ξ3)
∂x3
#
$%
&
1
ˆk.
This simpliﬁes to
∇xθ(x + ξ, t) = ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x1 + ξ1)
ˆi
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x2 + ξ2)
ˆj
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x3 + ξ3)
ˆk.
We then repeat the procedure, starting with the gradient with
respect to the ξ coordinate system. Again, we ﬁrst take the gradient
with respect to ξ
∇ξθ(x + ξ, t) = ∇ξθ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
= ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂ξ1
ˆi
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂ξ2
ˆj
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂ξ3
ˆk.
We expand this as
∇ξθ(x + ξ, t) = ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x1 + ξ1)
∂(x1 + ξ1)
∂ξ1
#
$%
&
1
ˆi
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x2 + ξ2)
∂(x2 + ξ2)
∂ξ2
#
$%
&
1
ˆj
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x3 + ξ3)
∂(x3 + ξ3)
∂ξ3
#
$%
&
1
ˆk.
Finally, this simpliﬁes to
∇ξθ(x + ξ, t) = ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x1 + ξ1)
ˆi
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x2 + ξ2)
ˆj
+ ∂θ(x1 + ξ1, x2 + ξ2, x3 + ξ3, t)
∂(x3 + ξ3)
ˆk.

146
battery management systems: volume i, battery modeling
By comparing the ﬁnal forms for ∇xθ(x + ξ) and ∇ξθ(x + ξ), we
see that the two are equal. By the same argument, ∇xγα(x + ξ) =
∇ξγα(x + ξ) and ∇x · ψ(x + ξ, t) = ∇ξ · ψ(x + ξ, t) = ∇· ψ(x + ξ, t).
4.3
Volume-averaging theorem 1
We are now ready to prove the three volume-averaging theorems. We
begin by deriving Eq. (4.1), which states that for scalar ﬁeld ψ, if ψ is
continuous in the α phase,
εα∇ψα = ∇(εα ¯ψα) + 1
V
¨
Aαβ(x,t)
ψα ˆnα dA.
We start with the deﬁnition of phase average of some general
quantity θ
⟨θα(x, t)⟩= 1
V
˚
V
θ(x + ξ, t)γα(x + ξ, t) dVξ.
Then, the phase average of the gradient must be, by direct substitu-
tion of θα = ∇ψα,
⟨∇ψα(x, t)⟩= 1
V
˚
V
[∇ψ(x + ξ, t)]γα(x + ξ, t) dVξ.
Recall the product rule from calculus: ∇(AB) = (∇A)B + A(∇B),
and let A = ψ(x + ξ, t) and B = γα(x + ξ, t). Noticing that the
integrand is of the form (∇A)B, we can then write
⟨∇ψα(x, t)⟩= 1
V
˚
V
∇[ψ(x + ξ, t)γα(x + ξ, t)] dVξ
−1
V
˚
V
ψ(x + ξ, t)[∇γα(x + ξ, t)] dVξ.
Substituting the known gradient of the indicator function ∇γα(x, t) =
−ˆnαδ(x −xαβ, t) gives
⟨∇ψα(x, t)⟩= 1
V
˚
V
∇[ψ(x + ξ, t)γα(x + ξ, t)] dVξ
+ 1
V
˚
V
ψ(x + ξ, t) ˆnαδ(x + ξ −xαβ, t) dVξ.
The second integral involves the Dirac delta function, which is zero
everywhere except at the α–β phase interface. By the sifting property
of the Dirac delta function, this volume integral drops to a surface
integral over the α–β phase interface
1
V
˚
V
ψ(x + ξ, t) ˆnαδ(x + ξ −xαβ, t) dVξ = 1
V
¨
Aαβ(x,t)
ψα(x + ξ, t) ˆnα dA,

4. continuum-scale cell models
147
and we get
⟨∇ψα(x, t)⟩= 1
V
˚
V
∇[ψ(x + ξ, t)γα(x + ξ, t)] dVξ
+ 1
V
¨
Aαβ(x,t)
ψα(x + ξ, t) ˆnα dA.
By Eqs. (4.11) and (4.12), we know that we are free to consider the
gradient operator as either ∇= ∇x or ∇= ∇ξ. We choose to use
∇= ∇x in the ﬁrst integral on the right-hand side of this equation,
so that the gradient operator may be removed from the integral: we
can do so because the volume of integration has been speciﬁed to be
independent of x. Thus, we obtain
⟨∇ψα⟩= ∇
@ 1
V
˚
V
ψ(x + ξ, t)γα(x + ξ, t) dVξ
A
+ 1
V
¨
Aαβ(x,t)
ψα(x + ξ, t) ˆnα dA
⟨∇ψα⟩= ∇⟨ψα⟩+ 1
V
¨
Aαβ(x,t)
ψα ˆnα dA.
In words, it says that the phase average of the gradient is equal to the
gradient of the phase average plus a correction term. The correction
term sums up vectors pointing outward from the α phase into the β
phase at every location on the α–β interface, scaling the vectors by the
size of the ﬁeld ψα at that point. Overall, this correction term points
in the direction of largest surface ﬁeld.
By extension, using Eq. (4.10), we can ﬁnd the intrinsic phase
average
∇ψα = 1
εα ⟨∇ψα⟩
= 1
εα
:
∇⟨ψα⟩+ 1
V
¨
Aαβ(x,t)
ψα ˆnα dA
;
= 1
εα
:
∇(εα ¯ψα) + 1
V
¨
Aαβ(x,t)
ψα ˆnα dA
;
.
Rearranging this expression gives
εα∇ψα = ∇(εα ¯ψα) + 1
V
¨
Aαβ(x,t)
ψα ˆnα dA,
which proves volume-averaging theorem 1, Eq. (4.1). Be careful to
note that εα is inside the gradient operator on the right-hand side,
which is important if εα is a function of x.

148
battery management systems: volume i, battery modeling
4.4
Volume-averaging theorem 2
The second volume-averaging theorem, Eq. (4.2), is very similar to
the ﬁrst, but the average operates on the divergence of a vector ﬁeld
rather than on the gradient of a scalar ﬁeld. Here, we wish to show
that, for vector ﬁeld ψ, if ψ is continuous in the α phase,
εα∇· ψα = ∇· (εα ¯ψα) + 1
V
¨
Aαβ(x,t)
ψα · ˆnα dA.
The steps in the proof parallel the steps in the derivation of the ﬁrst
volume-averaging theorem directly.
We start with the generic deﬁnition of phase average:
⟨θα(x, t)⟩= 1
V
˚
V
θ(x + ξ, t)γα(x + ξ, t) dVξ.
Then, the phase average of the divergence operation must be (by
substituting θα = ∇· ψα)
⟨∇· ψα(x, t)⟩= 1
V
˚
V
[∇· ψ(x + ξ, t)]γα(x + ξ, t) dVξ.
The divergence operator also satisﬁes a product rule ∇· (γF) =
(∇γ) · F + γ(∇· F). Let F = ψ(x + ξ, t) and γ = γα(x + ξ, t). Noticing
that the integrand is of the form γ(∇· F), we can write
⟨∇· ψα(x, t)⟩= 1
V
˚
V
∇· [ψ(x + ξ, t)γα(x + ξ, t)] dVξ
−1
V
˚
V
ψ(x + ξ, t) · [∇γα(x + ξ, t)] dVξ.
Substituting the known gradient of the indicator function ∇γα(x, t) =
−ˆnαδ(x −xαβ, t) gives
⟨∇· ψα(x, t)⟩= 1
V
˚
V
∇· [ψ(x + ξ, t)γα(x + ξ, t)] dVξ
+ 1
V
˚
V
ψ(x + ξ, t) · ˆnαδ(x + ξ −xαβ, t) dVξ.
As before, the second volume integral drops to a surface integral
over the α–β phase interface
1
V
˚
V
ψ(x + ξ, t) · ˆnαδ(x + ξ −xαβ, t) dVξ = 1
V
¨
Aαβ(x,t)
ψα(x + ξ, t) · ˆnα dA,
and we get
⟨∇· ψα(x, t)⟩= 1
V
˚
V
∇· [ψ(x + ξ, t)γα(x + ξ, t)] dVξ
+ 1
V
¨
Aαβ(x,t)
ψα(x + ξ, t) · ˆnα dA.

4. continuum-scale cell models
149
By extension to Eqs. (4.11) and (4.12), we are free to consider the
divergence operator as either ∇· = ∇x· or ∇= ∇ξ· . We choose
to use ∇· = ∇x· on the equation’s right-hand side so that the diver-
gence operator may be removed from the integral because the vol-
ume of integration has been speciﬁed to be independent of x. Thus,
we obtain
⟨∇· ψα⟩= ∇·
@ 1
V
˚
V
ψ(x + ξ, t)γα(x + ξ, t) dVξ
A
+ 1
V
¨
Aαβ(x,t)
ψα(x + ξ, t) · ˆnα dA
⟨∇· ψα⟩= ∇· ⟨ψα⟩+ 1
V
¨
Aαβ(x,t)
ψα · ˆnα dA.
In words, this says that the phase average of the divergence is equal
to the divergence of the phase average plus a correction term. The
correction term is the volume-averaged total ﬂux out of the surface
of the α phase into the β phase within the volume V. That is, the
divergence, which represents the rate at which something is leaving
the α phase within a volume, must consider not only the ﬂux through
the surface of V, but must also consider the ﬂux from α to β within V,
which is happening at the α–β phase boundary inside of V.
By extension, using Eq. (4.10), the intrinsic phase average is
εα∇· ψα = ∇· (εα ¯ψα) + 1
V
¨
Aαβ(x,t)
ψα · ˆnα dA,
which proves volume-averaging theorem 2.
4.5
Volume-averaging theorem 3
The derivation of the third volume-averaging theorem, Eq. (4.3), pro-
ceeds in a similar way to the ﬁrst two, up to a point. However, we
will see that the correction term is handled differently and requires
some careful thought.
Here, we wish to show that, for scalar ﬁeld ψ, if ψ is continuous in
the α phase,
εα
@∂ψα
∂t
A
= ∂(εα ¯ψα)
∂t
−1
V
¨
Aαβ(x,t)
ψαvαβ · ˆnα dA,
where vαβ is the velocity of displacement of the α–β interface.
We start with the deﬁnition of phase average
⟨θα(x, t)⟩= 1
V
˚
V
θ(x + ξ, t)γα(x + ξ, t) dVξ.

150
battery management systems: volume i, battery modeling
Then, we substitute the time derivative that we would like to average
into the deﬁnition (θα = ∂ψα/∂t):
G ∂ψα
∂t
H
= 1
V
˚
V
[∂ψα(x + ξ, t)/∂t]γα(x + ξ, t) dVξ.
Recall the product rule from calculus: ∂(AB)/∂t = (∂A/∂t)B +
A(∂B/∂t), and let A = ψ(x + ξ, t) and B = γα(x + ξ, t). Noticing that
the integrand is of the form (∂A/∂t)B, we can write
G∂ψα
∂t
H
= 1
V
˚
V
∂[ψα(x + ξ, t)γα(x + ξ, t)]/∂t dVξ
−1
V
˚
V
ψα(x + ξ, t)[∂γα(x + ξ, t)/∂t] dVξ.
Because V is independent of time, the order of differentiation or
integration in the ﬁrst term may be reversed, and we obtain
G ∂ψα
∂t
H
= ∂⟨ψα⟩
∂t
−1
V
˚
V
ψα(x + ξ, t)[∂γα(x + ξ, t)/∂t] dVξ.
Now we consider the correction term—the remaining integral.
First note that if the α phase is not deforming, the partial derivative of
the indicator function will be zero, and the integral term will be zero.
This turns out to be the case we are most interested in.
However, for completeness, we also consider the more general case
where the α phase is deforming. Then, γα will be a function of time,
and the integral term will be nonzero in general.
We will use the chain rule of the total derivative of γα to write
dγα
dt = ∂γα
∂t + dx1
dt
∂γα
∂x1
+ dx2
dt
∂γα
∂x2
+ dx3
dt
∂γα
∂x3
= ∂γα
∂t + dx
dt · ∇γα.
(4.13)
In this equation, ∂γα/∂t states how the indicator function is chang-
ing as a function of time only. The term dγα/dt instead states how
an observer’s measurement of the indicator function is changing as
a function of all variables, including that observer’s own velocity
dx/dt.
To understand this, ﬁrst suppose that ∂γα/∂t = 0. This means
that the γα function is not itself changing as a function of time. If
we as an observer are located at some stationary (x1, x2, x3) point
within volume V, our velocity dx/dt is equal to zero, and we will
look around and see that nothing is changing, so the (total) derivative
will also be zero.
However, if we are moving around the function at some nonzero
velocity dx/dt, then we will experience a change in the value of γα
that we measure, even when the function itself isn’t changing, simply

4. continuum-scale cell models
151
γa
vαβ
Figure 4.8: An observer “surﬁng on”
the phase-boundary interface will
observe no change in the indicator
function as the observer is moving at
the same rate that the indicator-function
boundary is moving.
because we are evaluating it at different points. Thus, dγα/dt ̸= 0 in
general, even when ∂γα/∂t = 0. Further, we will get different values
for dγα/dt when we move around the space at different velocities
dx/dt.
Here, we choose to move our observation point at the same veloc-
ity as the α–β phase boundary movement: dx/dt = vαβ, so rearrang-
ing Eq. (4.13) to solve for the partial derivative gives
∂γα
∂t = dγα
dt −vαβ · ∇γα.
For this choice of dx/dt, the total derivative becomes what is known
as a substantial derivative that moves with the interface.
This velocity choice is a special case that simpliﬁes the problem.
As depicted in Fig. 4.8, an observer riding on (“surﬁng on”) the in-
terfacial boundary and moving at the same velocity as the boundary
movement will notice no change in γα versus time. It remains a step
function that shifts with the moving boundary. The value of the func-
tion measured by the observer moving at velocity vαβ doesn’t vary
with time.
So, the total derivative is zero when dx/dt = vαβ, and we can
write
∂γα
∂t = −vαβ · ∇γα.
This yields, when we substitute ∂γα/∂t = −vαβ · ∇γα,
G∂ψα
∂t
H
= ∂⟨ψα⟩
∂t
−1
V
˚
V
ψα(x+ξ, t)[∂γα(x+ξ, t)/∂t] dVξ
= ∂⟨ψα⟩
∂t
+ 1
V
˚
V
ψα(x+ξ, t)vαβ(x+ξ, t) · ∇γα(x+ξ, t) dVξ
= ∂⟨ψα⟩
∂t
+ 1
V
˚
V
ψα(x+ξ, t)vαβ(x+ξ, t) · (−ˆnαδ(x+ξ−xαβ)) dVξ
G∂ψα
∂t
H
= ∂⟨ψα⟩
∂t
−1
V
¨
Aαβ(x,t)
ψαvαβ · ˆnα dA.
In words, the phase average of a time derivative is equal to the time
derivative of the phase average plus a correction term. The correc-
tion term accounts for a net dilution of the ﬁeld ψα if the volume is
expanding (phase interface is moving in the same direction as ˆnα)
or a concentration of the ﬁeld ψa if the volume is contracting (phase
interface is moving in the opposite direction as ˆnα).
By extension, using Eq. (4.10),
εα
@∂ψα
∂t
A
= ∂(εα ¯ψα)
∂t
−1
V
¨
Aαβ(x,t)
ψαvαβ · ˆnα dA,
which proves volume-averaging theorem 3. Here we note that if
vαβ ̸= 0, then εα is time varying, and we must be very careful to keep
it inside the time derivative on the right-hand side of the equation.

152
battery management systems: volume i, battery modeling
4.6
Charge conservation in the solid
With this rather long introduction, we are now ready to develop the
volume-averaged continuum-scale lithium-ion cell model. This model
can be used in three dimensions, but we will specialize to a one-
dimensional description of cell dynamics, with an added “pseudo-
dimension” that describes lithium concentration inside the solid. Ac-
cordingly, this model is often referred to as the pseudo-two-dimensional
model in the literature.
Fig. 4.9 helps to illustrate this concept. The diagram shows, roughly
to typical scale, the actual geometry of a lithium-ion cell cross section.
Instead of using spatial x, y, and z coordinates, we will now special-
ize to an x coordinate only, where x = 0 at the negative-electrode
current collector, and x takes on its maximum value at the positive-
electrode current collector.
Negative electrode
Positive electrode
Current collector
Current collector
Separator
x
r
Figure 4.9: Schematic of a cell, from a
continuum model perspective.
(Reproduced from Fig. 1 of Stetzel,
K., Aldrich, L., Trimboli, M.S., and
Plett, G., “Electrochemical State and
Internal Variables Estimation using a
Reduced-Order Physics-Based Model
of a Lithium-Ion Cell and an Extended
Kalman Filter,” Journal of Power Sources,
278, 2015, pp. 490–505.)
As we saw in the SEM and FIB images of electrodes in Figs. 1.8–
1.10 of Chap. 1, true particle geometry is very complex. However,
here we will simplify by assuming that all particles are perfect
spheres, all having the same radius. This is an imperfect abstrac-
tion, but it helps us to make tractable models. In this abstraction,
every x location corresponding to a point either in the negative- or
positive-electrode is modeled as being the center of a spherical parti-
cle of radius Rs. The variable r such that 0 ≤r ≤Rs is the coordinate
inside of this sphere and is referred to as the pseudo-dimension of the
model.
Note that the ﬁgure shows a number of circular particles side by
side in the negative-electrode region and another number of circu-
lar particles side-by-side in the positive-electrode region. This may
mislead the reader into thinking that a discrete number of particles
are being modeled. This is not the case; rather, there is assumed to
be a particle for every real-valued x corresponding to a position in
either the positive or negative electrode. The circular particles over-
lap inﬁnitely in the model. This corresponds to the idea of contin-
uum modeling, where every x location identiﬁes a sample-volume

4. continuum-scale cell models
153
3 Notice that we have chosen the α
phase to correspond to the solid,
denoted as “s,” and the β phase to
correspond to everything else. “Every-
thing else” includes electrolyte plus
inert materials, but we denote β as “e”
for “electrolyte” as it is the dominant
contributor to phase β.
center, where the model predicts the average dynamics in the sample-
volume-neighborhood of that x location, rather than the precise dy-
namics at that absolute location.
We now apply the volume-averaging theorems to develop contin-
uum model equivalents of the ﬁve microscale model equations. We
start with Eq. (3.1), the microscale model of charge conservation in
the solid, which was
∇· is = ∇· (−σ∇φs) = 0.
Using intrinsic averages and volume-averaging theorem 2 on the
∇· (−σ∇φs) term3
εs∇· (−σ∇φs) = ∇·
'
εs(−σ∇φs)
(
+ 1
V
¨
Ase
(−σ∇φs) · ˆns dA.
But, ∇· is = 0 so we must also have ∇· is = 0.
0 = ∇·
'
εs(−σ∇φs)
(
+ 1
V
¨
Ase
(−σ∇φs) · ˆns dA.
We look at the integral term ﬁrst. Notice that the surface integral
is over the boundary between the solid electrode particles and the
electrolyte. The integrand, then, can be found from the boundary
conditions on the φs equation that were developed in Chap. 3. Speciﬁ-
cally, we found in Eq. (3.47) that
ˆns · σ∇φs = −Fj.
We know that the Butler–Volmer ﬂux density j is a function of cs,
ce, φs, and φe at the particle surface. We will assume that our sample
volume V is small enough that ce, φs, and φe are relatively uniform
and that cs at the surface of particles in V is relatively uniform. This
allows us to write
1
V
¨
Ase
(−σ∇φs) · ˆns dA ≈1
V
¨
Ase
Fj(¯cs,e, ¯ce, ¯φs, ¯φe) dA,
where cs,e is the surface concentration of lithium in the solid (i.e., at
the solid–electrolyte interface; hence, the notation “s, e”). Because j
is now using volume-averaged inputs, its value is constant over the
sample volume, and we have
1
V
¨
Ase
Fj(¯cs,e, ¯ce, ¯φs, ¯φe) dA = Ase
V Fj(¯cs,e, ¯ce, ¯φs, ¯φe)
= asFj(¯cs,e, ¯ce, ¯φs, ¯φe)
= asF¯j,
where ¯j = j(¯cs,e, ¯ce, ¯φs, ¯φe), and we deﬁne as to be the speciﬁc interfacial
surface area of the particles, equal to the total surface area of the solid

154
battery management systems: volume i, battery modeling
4 See, for example, Gupta, A., Seo,
J.H., Zhang, X., Du, W., Sastry, A.M.,
and Shyy, W., “Effective Transport
Properties of LiMn2O4 Electrode via
Particle-Scale Modeling,” Journal of
the Electrochemical Society, 158(5), 2011,
pp. A487–A497.
particles within the volume V divided by the volume of V. It has
units of m2 m−3, which can be shortened to m−1, but the reduced
form loses the intuitive meaning of the variable.
For spherical particles with radius Rs and volume fraction εs, we
can calculate as as
as = total surface area
total volume
= volume of solid
total volume
#
$%
&
εs
total surface area/particle
volume of solid/particle
= εs
4πR2
s
4
3πR3s
= 3εs
Rs
.
So, we now have the result
0 = ∇·
'
εs(−σ∇φs)
(
+ asF¯j
∇·
'
εs(−σ∇φs)
(
= −asF¯j.
But, what to do with the (−σ∇φs) term? We might consider using
volume-averaging theorem 1, but note that we don’t know what φs ˆns
is at the boundary, and so we are unable to evaluate the correction
term in Eq. (4.1).
Instead, the common approach is to model εs(−σ∇φs) ≈−σeff∇¯φs.
The effective conductivity σeff is modeled as σeff = εsσδ
τ , where δ < 1 is
the constrictivity of the media and τ ≥1 is the tortuosity of the media.
That is, σ is the bulk conductivity of homogeneous materials without
inclusions and σeff is the effective conductivity of the solid matrix in
the porous media.
Note that σeff < σ since there are restrictions to ﬂow of current.
The constrictivity δ models the fact that the entire volume is not
available for current to ﬂow; instead, current must in some places
ﬂow through restricted paths due to the porosity of the media, with
restriction being a factor of δ compared to the nonporous media. The
tortuosity models the fact that the path from one side of the volume
to the other is not direct, but must wind around a tortuous pathway
with length greater than the dimension of the volume by a factor τ.
Values of δ and τ are rarely known precisely. Based on experimen-
tal results of a variety of porous media, it is frequently assumed that
σeff = σεbrug
s
, where “brug” is Bruggeman’s exponent. This coefﬁcient
is normally assumed to take on the value of 1.5, although there is
considerable evidence that this value can be quite inaccurate in real
electrode materials. To get better values for “brug” we would either
need to do microscale simulations with realistic particle geometries4
or create experiments to measure the value directly.
Collecting the above results, we now have the ﬁnal continuum
model of charge conservation in the solid,
∇· (−σeff∇¯φs) = −asF¯j.

4. continuum-scale cell models
155
Also note for future reference that
εs¯is = εs(−σ∇φs)
= −σeff∇¯φs.
(4.14)
4.6.1
How well does the Bruggeman relationship work?
We now illustrate with an example how well an effective property
in a volume-average equation can represent the effect of an intrinsic
property in a microscale equation. We will use the PDE simulation
software system COMSOL to help ﬁnd results, and the example is
adapted from the COMSOL documentation.
We’re going to use a concentration model for this example, which
corresponds closely to Eq. (4.7)—which we have yet to prove but will
do so shortly—when there is no ﬂux j between solid and electrolyte.
The equation that models the microscale is Eq. (3.3), which when
migration and convection terms are ignored becomes
∂c
∂t + ∇· (−D∇c) = 0.
The geometry that we consider is shown in Fig. 4.10. The rectangular
objects are obstacles, which are similar in a sense to the solid par-
ticles in an electrode. The space between the rectangular objects is
open, and material can ﬂow through these voids. This space is simi-
lar in a sense to the pores in an electrode through which electrolyte
can move.
Figure 4.10: Microscale simulation of
diffusion through a porous medium.
At the beginning of the simulation (left frame of ﬁgure), there is
a high concentration of material at the left boundary of the porous
lattice, but zero concentration of the material elsewhere. By time
0.1 s (right frame of ﬁgure), there is a uniform concentration gradient

156
battery management systems: volume i, battery modeling
0
0.025
0.05
0.075
0.1
0
2
4
6
8
Time (s)
Average flux through right barrier
 
 
Exact solution
Approximate, brug = 1.58
Approximate, brug = 1.60
Flux (kmol m−2 s−1)
Figure 4.11: Flux-density comparison
between microscale and continuum
model.
established through the porous structure, as indicated by the colored
shading.
We’re interested in modeling the ﬂux density of material out of the
right edge of the structure. It is zero at time t = 0 and increases to
some steady-state value over time. We can simulate the high-ﬁdelity
PDE model over the complex geometry, and we can also make a one-
dimensional continuum model via
ε∂¯c
∂t + ∇· (−Deff∇¯c) = 0,
where Deff = Dεbrug (see Eq. (4.17) for the case where there is no
reaction ﬂux j).
Results are plotted in Fig. 4.11. The microscale solution is drawn
as the solid blue line. Continuum-model solutions are drawn using
dashed and dash-dot lines for brug = 1.58 and brug = 1.60, respec-
tively. We see that with the correct choice of the Bruggeman constant,
the continuum model gives predictions that are very close to the ex-
act solution. The two models produce nearly indistinguishable results
when brug = 1.59.
So, this example shows us that representing an effective property
as a constant times the intrinsic property can produce very good
results. However, the Bruggeman constant may need to be different
from the commonly used value of 1.5 to achieve the best match.
4.7
Mass conservation in the solid
As mentioned earlier, the continuum-scale cell model has spatial
dimension(s) plus a pseudo-dimension r. This pseudo-dimension is a
coordinate used in the solid mass-conservation equation to specify a
radial point inside a solid particle presumed to reside at some spatial
location.
We could make a continuum model with three spatial dimensions
plus an additional pseudo-dimension, resulting in a pseudo-four-
dimensional model. The math we develop here is general enough
to encompass this case, but in this book we ultimately specialize
to a model with one spatial dimension plus the additional pseudo-
dimension, resulting in a pseudo-two-dimensional model.
We assume that there is a particle centered at every spatial location
in the electrode, that the particle is spherical, and that the concen-
tration of lithium within the particle is spherically symmetric. So, to
create the continuum equation for mass conservation within the solid,
we don’t need to use any volume-averaging theorems, because we
are not volume averaging! Instead, we’re specializing the microscale
equation to these assumptions.

4. continuum-scale cell models
157
5 However, for high-rate operation,
these terms should be considered. See
Xue, K-H, and Plett, G.L., “A Convec-
tive Transport Theory for High Rate
Discharge in Lithium Ion Batteries,”
Electrochimica Acta, 87, 2013, pp. 575–
590.
Recall the microscale model, from Eq. (3.2)
∂cs
∂t = ∇· (Ds∇cs).
Also recall that the divergence of a vector ﬁeld can be written in
spherical coordinates as
∇· F = 1
r2
∂(r2Fr)
∂r
+
1
r sin θ
∂(sin θFθ)
∂θ
+
1
r sin θ
∂Fφ
∂φ .
If we assume spherical particles, with symmetry in both the θ and
φ axes, this reduces to
∇· F = 1
r2
∂(r2Fr)
∂r
.
Applying this to the right-hand side of the microscale model equa-
tion gives
∂cs
∂t = 1
r2
∂
∂r
.
Dsr2 ∂cs
∂r
/
.
We have now “proven” Eq. (4.5).
4.8
Mass conservation in the electrolyte
We next proceed to develop a continuum-scale equation for mass
conservation in the electrolyte. We begin with the corresponding
microscale Eq. (3.3)
∂ce
∂t = ∇· (De∇ce) −ie · ∇t0+
F
−∇· (cev0) .
(4.15)
We will specialize immediately to consider the case where we
assume that ∇t0
+ = 0 and v0 = 0, as is commonly done.5 We also
assume that the phases do not deform, so vse = 0.
Taking the intrinsic volume average of the left-hand side of Eq. (4.15)
using volume-averaging theorem 3 gives
@∂ce
∂t
A
= 1
εe
. ∂(εe ¯ce)
∂t
/
.
Taking the intrinsic volume average of the right-hand side of Eq. (4.15)
using volume-averaging theorem 2 gives
∇· (De∇ce) = 1
εe
.
∇·
!
εeDe∇ce
" + 1
V
¨
Ase
De∇ce · ˆne dA
/
.
(4.16)
We ﬁrst address the integral on the right-hand side of Eq. (4.16).
Recall from the boundary conditions in Eq. (3.48) that ˆne · (De∇ce) =

158
battery management systems: volume i, battery modeling
(1 −t0+)j. Using the same approach as with charge conservation in
the solid, we assume uniform ﬂux over the solid–electrolyte interface
and write
1
V
¨
Ase
De∇ce · ˆne dA = 1
V
¨
Ase
(1 −t0
+)j(cs, ce, φs, φe) dA
= Ase
V (1 −t0
+)¯j
= as(1 −t0
+)¯j.
Therefore, the intrinsic volume average of the right-hand side of
Eq. (4.15) becomes
∇· (De∇ce) = 1
εe
'
∇·
!
εeDe∇ce
" + as(1 −t0
+)¯j
(
.
We now address the ∇· (εeDe∇ce) term. Following the same kind
of reasoning as before, we write this as
∇· (εeDe∇ce) ≈∇· (De,eff∇¯ce),
where the effective diffusivity is deﬁned as De,eff = εeDeδ/τ, and we
often assume De,eff = Deεbrug
e
where “brug” is frequently taken to be
equal to 1.5.
So, combining all results,
1
εe
.∂(εe ¯ce)
∂t
/
= 1
εe
'
∇· (De,eff∇¯ce) + as(1 −t0
+)¯j
(
.
Rewriting this gives our mass balance equation for the electrolyte,
∂(εe ¯ce)
∂t
= ∇· (De,eff∇¯ce) + as(1 −t0
+)¯j.
(4.17)
We have now proven Eq. (4.7). In words, this says that the local
volume-average concentration of lithium in the electrolyte can in-
crease due to a concentration gradient if material ﬂows into the vol-
ume or if there is a local ﬂux from the solid into the electrolyte in the
volume.
4.8.1
Commenting on the (1 −t0
+) term
The (1 −t0
+) term in this result may seem a little odd. Why is only a
fraction of the lithium ﬂux from the solid to the electrolyte contribut-
ing to increasing the local lithium concentration in the electrolyte?
We brieﬂy look at an intuitive explanation of what is happening.
Consider a volume element having an interface between a solid par-
ticle and the electrolyte, such as is drawn in Fig. 4.12. Lithium ﬂux
density j is out of the particle, across the solid–electrolyte boundary,
which denotes the particle’s surface.

4. continuum-scale cell models
159
Electrolyte
Solid particle
iin
e
iout
e
j
Electrolyte
Solid particle
iin
e
iout
e
as(1 −λ)¯j stored
asλ¯j
leaves
as(1 −λ)¯j PF−
6
Figure 4.12: Explaining the (1 −t0
+)
factor.
Per our earlier assumptions, the total volume-averaged lithium
ﬂux density from the solid to the electrolyte is
as ¯j = 1
V
¨
Ase
j(cs, ce, φs, φe) dA.
It turns out that not all of this total ﬂux density remains in the vol-
ume element being considered (which would cause the concentration
to increase by as ¯j). Some of the lithium escapes the local volume el-
ement into an adjacent volume element. But, neither does all of the
ﬂux escape the volume (which would keep ce the same).
Let λ be the fraction of the ﬂux density that escapes the local vol-
ume and 1 −λ be the fraction that remains. This is depicted in the
right frame of the ﬁgure. To determine λ, we need to remember our
assumption that the electrolyte must maintain macroscopic charge
neutrality. This requires an anion ﬂux density of as(1 −λ)¯j (e.g., of
PF−
6 ions) into the local volume from a neighboring volume in order
to balance the cation ﬂux density of as(1 −λ)¯j positively charged
lithium ions that is stored in the local volume.
The fraction of electrolyte current in the volume element that is
added by the the anion ﬂux density required to maintain charge
neutrality is (1 −λ) times the added ﬂux density; the fraction of
the electrolyte current in the volume element that is added by the
cation ﬂux density that leaves the volume element is λ times the
added ﬂux density. Recognizing that the transference number t0
+ is
deﬁned to be the fraction of current carried by the cation and that
t0−= 1 −t0+ is the fraction of the current carried by the anion, then
we must have λ = t0
+. Therefore, the amount of lithium that stays in
the local volume and contributes to changing the local concentration
is as(1 −t0
+)¯j.

160
battery management systems: volume i, battery modeling
4.9
Charge conservation in the electrolyte
The fourth continuum-scale model equation that we consider is the
one describing charge conservation in the electrolyte. Recall the
microscale Eq. (3.4)
∇· ie = ∇·
.
−κ∇φe −2κRT
F
.
1 + ∂ln f±
∂ln ce
/ '
t0
+ −1
(
∇ln ce
/
= 0.
For simplicity, we rewrite this as
∇· ie = ∇· (−κ∇φe −κD∇ln ce) = 0,
where we have deﬁned
κD = 2κRT
F
.
1 + ∂ln f±
∂ln ce
/ '
t0
+ −1
(
.
Using volume-averaging theorem 2 on the left-hand side gives
∇· ie
=
1
εe
.
∇· (εe¯ie) + 1
V
¨
Ase
ie · ˆne dA
/
.
We can compute the value of the integral by recalling from Eq. (3.49)
that ie · ˆne = −jF on the interface. Therefore, we approximate the
integral by −asF¯j.
∇· ie = 1
εe
!∇· (εe¯ie) −asF¯j
" = 0
0 = ∇· (εe¯ie) −asF¯j.
Now, considering the right-hand side, note that
εe¯ie = εe
'
−κ∇φe + −κD∇ln ce
(
.
As before, we approximate
−εeκ∇φe ≈−κeff∇¯φe
−εeκD∇ln ce ≈−κD,eff∇ln ¯ce,
where κeff = κεbrug
e
and κD,eff = κDεbrug
e
.
Combining, we get two results:
εe¯ie = −κeff∇¯φe −κD,eff∇ln ¯ce,
(4.18)
and
∇· (κeff∇¯φe + κD,eff∇ln ¯ce) + as ¯jF = 0.
We have now proven Eq. (4.7).

4. continuum-scale cell models
161
4.10
Lithium movement between the solid and electrolyte phases
Finally, we consider the continuum-scale equation of ﬂux across the
solid–electrolyte interface. We have already used this result, but for
completeness we recall the Butler–Volmer equation
j = k0c1−α
e
(cmax −cs,e)1−αcα
s,e
>
exp
.(1 −α)F
RT
η
/
−exp
.
−αF
RT η
/?
.
(4.19)
This shows up in models as
1
V
¨
Ase
j(cs, ce, φs, φe) dA ≈Ase
V j(¯cs,e, ¯ce, ¯φs, ¯φe)
≈asj(¯cs,e, ¯ce, ¯φs, ¯φe) = as ¯j.
If we choose to use normalized units for the exchange current density
¯i0 = F k0c1−α
e,0 cs,max
#
$%
&
k0,norm
. ¯ce
ce,0
/1−α .cs,max −¯cs,e
cs,max
/1−α .
¯cs,e
cs,max
/α
,
and
¯j =
¯i0
F
>
exp
.(1 −α)F
RT
¯η
/
−exp
.
−αF
RT ¯η
/?
,
where ¯η = ¯φs −¯φe −Uocp(¯cs,e). We note that in continuum models
it is common to add a term to the overpotential to model the ionic
resistance of a solid–electrolyte interphase ﬁlm layer on the surface of
the particle, and so we replace ¯η with the calculation
¯η = ¯φs −¯φe −Uocp(¯cs,e) −FRﬁlm ¯j.
We have now derived Eq. (4.8).
4.11
Boundary conditions for pseudo 2D model
As with the partial-differential equations that we derived for the mi-
croscale, we must also specify boundary conditions for the continuum-
scale PDEs. These boundary conditions are deﬁned based on a physi-
cal understanding of movement of charge and mass at the boundaries
of each region.
4.11.1
Charge conservation in the solid
At the current-collector–electrode boundary, charge is transferred
between the current collector and the solid particles via electron
movement; charge is not transferred between the current collector

162
battery management systems: volume i, battery modeling
and the electrolyte, since the electrolyte supports ionic currents only.
Therefore, the electrical current through the solid at the current col-
lector boundary must equal the total current entering/exiting the cell.
That is,
εs¯is = −σeff∇¯φs = iapp
A ,
where iapp is the total cell applied current in amperes, and A is the
current-collector plate area in m2.
By similar reasoning, at the electrode–separator boundary current
is supported by movement of ions between the electrode region and
the separator region. Electronic current is zero, and ionic current is
equal to iapp/A.
Summarizing, for the positive electrode, we have
∂¯φs
∂x
++++
x=Lneg+Lsep = 0,
and
∂¯φs
∂x
++++
x=Ltot = −iapp
Aσeff
,
and for the negative electrode we have
∂¯φs
∂x
++++
x=Lneg = 0.
It is also true that in the negative electrode ∂¯φs
∂x
+++
x=0 = −iapp
Aσeff , but when
all PDEs of the battery model are integrated together, this condition
is redundant and is not implemented.
Since voltage is a potential difference, we must deﬁne a “ground
reference” point against which to measure all internal cell voltages.
We deﬁne
¯φs|x=0 = 0,
although other choices of reference voltage are possible.
4.11.2
Charge conservation in the electrolyte
At the electrode–separator boundaries, the ionic current must equal
the total current entering/exiting the cell.
εe¯ie = −κeff∇¯φe −κD,eff∇ln ¯ce = iapp
A .
And, the ionic current must be zero at the current collectors.
κeff
∂¯φe
∂x + κD,eff
∂ln ¯ce
∂x
++++
x=0
= κeff
∂¯φe
∂x + κD,eff
∂ln ¯ce
∂x
++++
x=Ltot = 0.
As before, we have boundary conditions at the separator interfaces,
but these are redundant and not implemented.
−κeff
∂¯φe
∂x −κD,eff
∂ln ¯ce
∂x
++++
x=Lneg = −κeff
∂¯φe
∂x −κD,eff
∂ln ¯ce
∂x
++++
x=Lneg+Lsep= iapp
A .

4. continuum-scale cell models
163
6 Lithium ﬂowing through the particle
center would end up on the other side
of the particle, but at the same radial
location; hence, the net ﬂux through the
center would be zero.
4.11.3
Mass conservation in the solid
At the particle surface, the ﬂux of lithium out of the particle has been
denoted by ¯j. Therefore, we must have
Ds
∂cs
∂r
++++
r=Rs
= −¯j.
Because we have assumed radial symmetry in the lithium concen-
tration in the particles, there can be no net ﬂux through the particle
center.6 This gives an internal “boundary” condition
∂cs
∂r
++++
r=0
= 0.
4.11.4
Mass conservation in the electrolyte
There must be no ﬂux of lithium through the electrolyte at the cell
boundaries. This gives
∂¯ce
∂x
++++
x=0
= ∂¯ce
∂x
++++
x=Ltot = 0.
4.12
Cell-level quantities
As we did with the microscale model in Chap. 3, we would now like
to extract several cell-level quantities from the continuum model
developed in this chapter. These include: cell voltage, total capacity,
and state of charge.
4.12.1
Cell voltage
The cell voltage is equal to the positive current-collector’s potential
minus the negative current-collector’s potential. Since the solid phase
is in direct electrical contact with the current collector, we then com-
pute the cell voltage as
v(t) = ¯φs(Ltot, t) −¯φs(0, t).
Because we have deﬁned ¯φs(0, t) = 0, we can further simplify to
v(t) = ¯φs(Ltot, t).
4.12.2
Cell total capacity
Cell total capacity is determined in the same manner as in Chap. 3,
using Eqs. (3.50), (3.51), and (3.52). For reference, we repeat the equa-
tions here:
Qneg = AFLnegεneg
s
cneg
s,max |x100% −x0%| /3600 Ah,

164
battery management systems: volume i, battery modeling
7 These methods are discussed in more
detail, and applied to the battery-model
simulation problem, in: Christopher
D. Rahn and Chao-Yang Wang, Battery
Systems Engineering, Wiley, 2013.
0
0.2
0.4
0.6
0.8
1
0
0.25
0.5
0.75
1.0 Example FEM basis functions
Normalized spatial coordinate x/L
Value
Figure 4.13: Example basis functions for
the ﬁnite-element method.
Qpos = AFLposεpos
s
cpos
s,max |y100% −y0%| /3600 Ah,
and
Q = min (Qneg, Qpos) Ah.
4.12.3
Cell state of charge
Similarly, cell state of charge is determined in the same manner as in
Chap. 3, using Eqs. (3.53), and (3.54). For convenient reference, we
repeat the equations here:
z = cneg
s,avg/cneg
s,max −x0%
x100% −x0%
= cpos
s,avg/cpos
s,max −y0%
y100% −y0%
.
4.13
Model simulations
We are now at the point where we have derived the full set of continuum-
scale model equations, which is great, but not especially useful unless
we can do something with them. One very important application of
the model is to use it in simulation to help understand how a cell
works, and then use that to inform how a cell should be built and/or
how a cell should be operated.
Digital simulation of continuous phenomena require discretiz-
ing the problem in time and space. There are three commonly used
approaches to numeric solution:7
• Finite difference: Divide the spatial and temporal dimensions into
small segments. Discretize the derivatives in the equations using
Euler’s rule or similar over these segments (some discretization
methods work better than others: being more stable, resulting in
less modeling error, etc.). Write the resulting system of equations,
and solve using a linear algebra solver at each time step. The lin-
ear diffusion example in Sect. 3.3.3 introduced this method.
• Finite volume: Time is still divided up into small segments, but
space is divided into volumes. Flux terms at volume boundaries
are evaluated, and concentrations are updated to reﬂect the mate-
rial ﬂuxes. This method enforces mass balance: because the ﬂux
entering a given volume is identical to that leaving the adjacent
volume, these methods are conservative. Another advantage of
the ﬁnite volume method is that it is easily formulated to allow
for unstructured meshes. The method is used in many computa-
tional ﬂuid dynamics packages. The spherical diffusion example in
Sect. 3.11.4 introduced this method.

4. continuum-scale cell models
165
8 V. Ramadesigan, P.W.C. Northrop, S.
De, S. Santhanagopalan, R.D. Braatz,
and V.R. Subramanian, “Modeling and
Simulation of Lithium-Ion Batteries
from a Systems Engineering Perspec-
tive,” Journal of the Electrochemical
Society, 159(3), 2012, pp. R31–R45.
9 See http://mocha-java.uccs.edu/
BMS1/CH04/LiIon.mph.
• Finite element: Time is discretized as with the other two methods.
The spatial dimension, however, is formulated as a summation
over N quadratic or linear basis or ﬁnite-element functions ψm(x)
for 1 ≤m ≤N. One example is shown in Fig. 4.13, where each
color represents a linear (triangular-shaped) basis function such
that the summation of these N = 11 functions is equal to 1 at
every x location. Then, the variable being studied is written as a
weighted sum. For example, if we are interested in some variable
θ(x, t), we write it as
θ(x, t) =
N
∑
m=1
θm(t)ψm(x).
This simpliﬁes the problem since the ψm(x) are ﬁxed—we con-
vert a two-dimensional problem θ(x, t) into N one-dimensional
problems θm(t), which are then evaluated by rewriting the PDEs
in vector form for these one-dimensional variables, and solving.
The shape and spacing of the elements can be varied to improve
simulation accuracy in speciﬁc areas, as long as they always sum
to 1.
Each method has advantages and disadvantages, and each has been
used to simulate models of battery cells.8 Here, we introduce COM-
SOL, a commercial ﬁnite element multiphysics solver code, primarily
because it is driven by a graphical user interface that makes it rela-
tively straightforward to implement and modify model equations,
allowing for very ﬂexible exploration of battery dynamics (and many
other applications as well).
We have implemented a “pseudo 2D” battery model in COMSOL
and introduce it here. This model can be downloaded from the book
web site, but will be useful only if you have a license to the COMSOL
software.9 We describe this model in the following subsections.
4.13.1
Charge conservation in the solid
When entering a model into a PDE solver such as COMSOL for sim-
ulation, one must ﬁrst specify the geometry of the object being simu-
lated. The continuum model is primarily a one-dimensional construct
where x represents the cross-sectional dimension of the cell. This di-
mension is itself divided into three regions: the negative-electrode,
separator, and positive-electrode regions.
It would be most natural for us to specify geometries and to en-
ter equations with physical lengths, so that the negative electrode
spanned the range from x = 0 to x = Lneg, the separator spanned the
range from x = Lneg to x = Lneg + Lsep, and the positive electrode
spanned the range from x = Lneg + Lsep to x = Ltot . However, if we

166
battery management systems: volume i, battery modeling
enter a model into COMSOL this way, we would have to “start from
scratch” every time we wished to simulate a cell having different di-
mensions, as it is not possible to resize a geometry in COMSOL once
it is deﬁned.
So, instead of using natural lengths, we use normalized lengths.
We will use symbol ¯x to represent position with respect to normal-
ized length, and x to denote physical position. In the negative elec-
trode we have ¯x = x/Lneg, in the separator we have ¯x = (x −
Lneg)/Lsep , and in the positive electrode we have ¯x = (x −Lneg −
Lsep)/Lpos. Generically, we see that ¯xregion = x/Lregion + constant.
Using normalized variables, each region’s length is ﬁxed at 1.0,
regardless of the values of Lneg, Lsep, and Lpos. We can change the
effective dimensions by changing the variables Lneg, Lsep, and Lpos
without needing to change the COMSOL geometries of the different
cell regions.
However, this requires that we modify the equations to use the
normalized lengths rather than physical lengths. Starting with
¯xregion = x/Lregion + constant, we have
∂(·)
∂¯x = ∂(·)
∂x
∂x
∂¯x = Lregion ∂(·)
∂x
∂(·)
∂x = ∂(·)
∂¯x
∂¯x
∂x =
1
Lregion
∂(·)
∂¯x .
For the solid charge-conservation equation, we start with
∇x · (σeff∇x ¯φs) = asF¯j,
where the subscript x on the ∇operators indicates the quantity with
respect to which the derivative is being taken. Rewriting this equa-
tion in terms of ¯x instead of x gives
1
Lregion ∇¯x ·
'
σeff
Lregion ∇¯x ¯φs
(
= asF¯j.
Beyond the mechanical need to rescale equations to normalized ge-
ometries, there is an art to making PDE simulations work reliably. To
solve the coupled nonlinear equations, a PDE solver uses nonlinear
optimization at every time step to make the left-hand and right-hand
sides of all equations match as closely as possible, within some tol-
erance. Coupling equations where some have very large values and
others have very small values causes problems, as the PDE solver will
tend to place more emphasis on making the large-valued equations
match than on making the small-valued equations match (to reduce
the total error).
Noting that as and F are rather large values, and L is a rather
small value, we get better numeric performance if we instead imple-
ment
∇¯x ·
'
σeff
Lregion ∇¯x ¯φs
(
= LregionasF¯j.

4. continuum-scale cell models
167
Figure 4.14: Visualizing solid concentra-
tion.
In COMSOL, we input this equation into a predeﬁned PDE form
as
∇· (sigma_eff/L ∗phi_sx) = L ∗as ∗F ∗j,
where the following variables are deﬁned:
σeff
as
¯j
Lregion
¯φs
F
sigma_eff
as
j
L
phi_s
F
Note that in COMSOL syntax,
phi_sx = d
dxphi_s,
and recall that COMSOL’s “x” is our normalized dimension “ ¯x”.
4.13.2
Mass conservation in the solid
Mass conservation in the solid is described by the equation
∂
∂t cs = 1
r2
∂
∂r
.
Dsr2 ∂cs
∂r
/
,
which operates in the “pseudo” dimension, r, instead of the linear
dimension, x. That is, at every “x” location, a copy of this radial
equation operates, representing the radially symmetric concentration
proﬁle of lithium in a representative spherical particle located at that
“x” location.
To implement this equation, we also normalize the radial dimen-
sion: let ¯r = r/Rs. Then, r2 = ¯r2R2s and ∂(·)
∂r =
1
Rs
∂(·)
∂¯r . This allows us
to rewrite the PDE as
∂
∂tcs =
.
1
¯r2R2s
/ 1
Rs
∂
∂¯r
.
Ds
'
¯r2R2
s
( 1
Rs
∂cs
∂¯r
/
.
We multiply both sides of the equation by ¯r2Rs and rearrange to get
the actual equation implemented in COMSOL:
¯r2Rs
∂
∂tcs + ∂
∂¯r
.
−Ds
¯r2
Rs
∂cs
∂¯r
/
= 0,
except that COMSOL uses y instead of ¯r as the name of its radial
coordinate.
When visualizing solid concentration, we are presented with an
image like the one shown in Fig. 4.14. In this ﬁgure, the horizontal
dimension is the cell “x” spatial dimension; the vertical dimension
is the radial “r” pseudo-dimension (particle surface r = Rs is at
top; particle center r = 0 is at bottom); the left block represents the
negative electrode and the right block represents the positive elec-
trode. The color at any location indicates lithium concentration at

168
battery management systems: volume i, battery modeling
that spatial and radial coordinate: dark red is high concentration;
dark blue is low concentration. In this example, we see a snapshot of
the concentrations where the cell is at a low state-of-charge immedi-
ately following a long discharge (so the solid concentrations are not
yet in equilibrium). Hence particle surface concentration in the nega-
tive electrode is low, while the particle interior concentrations in the
negative electrode are still relatively high. And, for this simulation,
the positive-electrode parameters were such that it was easier for
the particles near the separator to “ﬁll up” than it was for lithium to
diffuse through the electrolyte to ﬁll up other particles closer to the
current collector.
Note that there is no diffusion of lithium in the solid in the hori-
zontal x dimension. Lithium diffusion in the horizontal dimension
happens only in the electrolyte. In the solid, lithium diffuses only in
the “vertical” or radial dimension. This is represented in COMSOL
by parameterizing a built-in PDE as
yˆ2 ∗Rs∗∂cs
∂t + ∇· (−
:
0,
0
0,
yˆ2 ∗Ds/Rs
;
∗∇cs) = 0,
where ∇=
<
∂
∂x,
∂
∂y
=
and where the following variables are de-
ﬁned:
Rs
Ds
Rs
Ds
4.13.3
Charge conservation in the electrolyte
To represent charge conservation in the electrolyte, we desire to im-
plement
∇· (κeff∇¯φe + κD,eff∇ln ¯ce) + asF¯j = 0.
Once again, we use normalized lengths, which converts the equation
to
1
Lregion ∇·
'
κeff
Lregion ∇¯φe + κD,eff
Lregion ∇ln ¯ce
(
= −asF¯j.
We implement ∇ln ¯ce as 1
¯ce ∇¯ce and multiply both sides of the
equation by Lregion (for better convergence), so the equation that is
actually implemented is
∇· (kappa_eff/L ∗(phi_ex + kappa_D ∗1/c_e ∗c_ex))
= −L ∗as ∗F ∗j,
where the following variables are deﬁned:
κeff
κD,eff/κeff
as
¯j
Lregion
¯φe
ce
F
kappa_eff
kappa_D
as
j
L
phi_e
c_e
F

4. continuum-scale cell models
169
Note again that in COMSOL syntax,
phi_ex = d
dx phi_e
and
c_ex = d
dxc_e,
and COMSOL’s “x” is our normalized dimension “ ¯x”.
4.13.4
Mass conservation in the electrolyte
The ﬁnal PDE that we wish to implement describes mass conserva-
tion in the electrolyte
∂(εe ¯ce)
∂t
= ∇· (De,eff∇¯ce) + as(1 −t0
+)¯j.
Once again, we normalize lengths, which converts the equation to
∂(εe ¯ce)
∂t
=
1
Lregion ∇· (De,eff
1
Lregion ∇¯ce) + as(1 −t0
+)¯j.
What is actually implemented is
eps_e ∗L ∗∂ce
∂t + ∇· (−De_eff/L ∗∇ce) = L ∗as ∗(1 −t_plus) ∗j,
where the following variables are deﬁned
De,eff
t0
+
as
¯j
Lregion
εe
De_eff
t_plus
as
j
L
eps_e
4.14
Running COMSOL
It is beyond the scope of this book to describe in detail how to use
COMSOL or any other battery solver. However, we do show a screen-
shot taken when running COMSOL in Fig. 4.15. The left frame con-
tains selectable elements that deﬁne constants, equations, meshes,
and so forth. The details of the currently selected element are shown
in the middle frame. The right frame shows simulation output: in
this case, the voltage response of a cell that is subjected to a rest
followed by a constant-current charge pulse, followed by a rest, fol-
lowed by a constant-current discharge pulse, followed by a rest.
4.15
Where to from here?
We’re making excellent progress. We’re now at a point where we
can fairly readily simulate cell performance and behavior. But, the
equations are still far too complicated to implement in a real-time em-
bedded system, which would be needed for battery controls. So, our

170
battery management systems: volume i, battery modeling
Figure 4.15: Screenshot of COMSOL
user interface.
next step is to look at ways to reduce the complexity of the model
equations, while still retaining the physics behind them. We devote
the next two chapters of this book to doing so.
In Chap. 5, we introduce the discrete-time state-space model form,
which is how our ﬁnal equations will be expressed. We also intro-
duce a method that can convert Laplace-domain transfer functions
into the state-space model form. Then, in Chap. 6, we convert the
PDEs from this chapter into transfer functions and create a reduced-
order version of the continuum equations. The resulting model is of
similar computational complexity to the equivalent-circuit models
that we investigated in Chap. 2, but capable of predicting both the
internal dynamics of the cell as well as the cell’s voltage.
4.16
Partial glossary
This section gives a glossary of the most important variables deﬁned
in this chapter. Units are also given—the notation [u/l] is speciﬁed
for a unitless quantity. Note that all variables are at least potentially
functions of space and time.

4. continuum-scale cell models
171
• ⟨ψ⟩denotes the phase average of quantity ψ and has the same units
as ψ (cf. p. 142).
• ψ denotes the intrinsic phase average of quantity ψ and has the same
units as ψ (cf. p. 143).
• as(x, y, z, t) [m2 m−3] is the speciﬁc interfacial area: the area of
the boundary between solid and electrolyte per unit volume
(cf. p. 154).
• brug [u/l] is Bruggeman’s exponent for computing effective material
properties. Often, we approximate brug = 1.5 (cf. p. 154).
• δ(x, y, z, t) [u/l] is the constrictivity of a porous media in the vicin-
ity of a point. δ < 1 (cf. p. 154).
• δ(x, y, z, t) [u/l] is also the symbol for the Dirac delta function
(cf. p. 138).
• εα(x, y, z, t) [u/l] is the volume fraction of phase α in the vicinity of
a point (cf. p. 143).
• De,eff(x, y, z, t) [m2 s−1] is a short form for De,eff ≈Deεbrug
e
= Deε1.5
e
(cf. p. 158).
• γα(x, y, z, t) [u/l] denotes the indicator function for phase α (cf. p. 138).
• κeff(x, y, z, t) [S m−1] is the effective conductivity of the electrolyte,
representing a volume-averaged conductivity of the electrolyte
phase in a porous media in the vicinity of a given point. We often
model κeff ≈κεbrug
e
= κε1.5
e
(cf. p. 160).
• κD,eff(x, y, z, t) [V] is a short form for κD,eff ≈κDεbrug
e
= κDε1.5
e ,
where κD = 2RTκ(t0
+ −1)/F (cf. p. 160).
• σeff(x, y, z, t) [S m−1] is an electrode-dependent parameter called
the effective conductivity, representing a volume-averaged conductiv-
ity of the solid matrix in a porous media in the vicinity of a given
point. We often model σeff ≈σεbrug
s
= σε1.5
s
(cf. p. 154).
• τ(x, y, z, t) [u/l] is the tortuosity of the porous media in the vicinity
of a point. τ ≥1 (cf. p. 154).


5.1
Intro. to state-space models . 174
5.2
Solid-dynamics equations . . 182
5.3
State-space realization . . . . 186
5.4
Discrete-time realization algo. 195
5.5
Examples of the DRA . . . . 198
5.6
Eigensystem realization algo. 208
5.7
Where to from here? . . . . . 212
5.8
Partial glossary . . . . . . . . 213
5
State-Space Models and the
Discrete-Time Realization Algorithm
The coupled PDE models derived in earlier chapters are useful for
understanding how a cell works and (via a suitable design of exper-
iments) can be used to explore design factors that might limit the
cell’s performance. Cell geometries, particle sizes, and material prop-
erties can be varied, in simulation, to optimize a cell’s characteristics
without the need to build numerous experimental cells.
For the purpose of real-time battery management, however, these
models are too complex. For example, they are “inﬁnite dimensional.”
For every point in time t, there are an inﬁnite number of x- and r-
dimension variables to solve for. That is, cs(x, r, t), ¯ce(x, t), ¯φs(x, t),
and ¯φe(x, t) must be found for every x and r location.
We desire to create cell-scale ordinary difference equations (ODEs)
that retain, as much as possible, the ﬁdelity of the continuum-scale
PDEs, but which reduce their order from inﬁnite order to some
(small) ﬁnite order. The result is a compact coupled set of ODEs,
similar in computational complexity to the equivalent-circuit mod-
els developed in Chap. 2, which can be simulated very easily and
quickly. This is the ﬁnal step in the physics-based modeling approach
of Fig. 3.1.
In this chapter, we introduce discrete-time state-space models,
which are the ﬁnal form of the physics-based reduced-order models
that we will develop. We then preview the approach we will use
to generate the state-space models from the PDEs of the variables
of interest: we start by generating transfer functions for each PDE;
we then use the discrete-time realization algorithm (DRA) to convert
transfer functions to state-space form. In this chapter, we develop the
DRA and give an important example to illustrate its behavior.
173

174
battery management systems: volume i, battery modeling
1 We will see that the state itself is
not necessarily unique; in general,
different linear combinations of one
state description form a second state
description that encodes the same
information.
2 Boldfaced lowercase characters are
used to denote quantities that may
be vectors, and boldfaced uppercase
characters are used to denote quantities
that may be matrices.
3 The subscript “c” is used to refer
to a continuous-time system and to
underscore the fact that the A, B,
C, and D matrices are different for
continuous-time and discrete-time
representations of the same system.
5.1
A quick introduction to state-space models
5.1.1
Continuous-time LTI system models
A linear-time-invariant (LTI) system’s dynamics may be captured in
(at least) three different ways. First, if we know the system’s time re-
sponse h(t) to a Dirac delta impulse function δ(t) (i.e., its continuous-
time impulse response), then we can compute the system’s output
corresponding to any input signal u(t) via convolution as
y(t) =
ˆ ∞
−∞
u(τ)h(t −τ) dτ.
(5.1)
Second, if we know the system’s transfer function H(s) or its frequency
response H(jω), then we can compute the output via Laplace or
Fourier-transform techniques.
Third, we may write the system dynamics in a state-space form.
While impulse responses, transfer functions, and frequency responses
provide a system’s input–output mapping only, state-space models
provide access to what is going on inside the system in addition to the
input–output mapping. These internal dynamics are summarized by
the system’s state.
We deﬁne the internal state of a system at time t0 as a minimum
amount of information at t0 that, together with the input u(t), t ≥t0,
uniquely determines the behavior of the system for all t ≥t0.1 Past
inputs do not need to be stored as they do when computing system
output using Eq. (5.1). Instead, the total net effect of all past inputs is
captured by the present system state.
State-space models comprise two coupled equations. A linear-time-
invariant continuous-time state-space model has the form
.x(t) = Acx(t) + Bcu(t)
(5.2)
y(t) = Ccx(t) + Dcu(t),
(5.3)
where u(t) ∈Rm is the input, y(t) ∈Rp is the output, and x(t) ∈Rn
is the state vector.2 Eq. (5.2) is called the state equation and describes
how the input u(t) inﬂuences the state x(t). The matrix Ac is called
the state transition matrix, and the matrix Bc is called the input matrix.
Eq. (5.3) is called the output equation and describes how the state and
input both directly inﬂuence the output. The matrix Cc is called the
output matrix, and the matrix Dc is called the feedthrough matrix.3
Different linear systems have different Ac, Bc, Cc, and Dc matrices
(all of which may be time-varying) and different state dimension n.

5. state-space models and the discrete-time realization algorithm
175
4 If not, then B =
´ ∆t
0
eAcτBc dτ, which
must generally be evaluated manually
to ﬁnd a solution.
5 The deﬁnitive summary can be found
in: Moler, C., and Van Loan, C., “Nine-
teen Dubious Ways to Compute the
Exponential of a Matrix, Twenty-Five
Years Later,” SIAM Review, 45(1), 2003,
pp. 3–49.
u[k]
y[k]
x[k]
x[k+1]
z−1
A
B
C
D
Figure 5.1: Block diagram implement-
ing discrete-time state-space system.
5.1.2
Discrete-time LTI system models
Linear-time-invariant (LTI) discrete-time state-space models have a
very similar basic form:
x[k + 1] = Ax[k] + Bu[k]
(5.4)
y[k] = Cx[k] + Du[k],
(5.5)
where u[k] ∈Rm is the input, y[k] ∈Rp is the output, and x[k] ∈Rn
is the state vector. Similar to before, Eq. (5.4) is the discrete-time
model’s state equation, and Eq. (5.5) is its output equation. It is im-
portant to note that the A and B matrices of the continuous-time and
discrete-time models are not the same, even if describing the same
system. As previewed in Chap. 2, we can convert from a continuous-
time state-space model to a discrete-time model via
A = eAc∆t
B = A−1
c
'
eAc∆t −I
(
Bc
C = Cc
D = Dc,
provided that A−1
c
exists.4 Note that the exponential operation in the
A and B equations is a matrix exponential, which can be evaluated as
eAc∆t = L−1 <
(sI −Ac)−1=
t=∆t .
That is, one ﬁrst computes the matrix function (sI −Ac)−1, then
the inverse Laplace transform of this function, which is evaluated at
the time instant t = ∆t. There are other ways to evaluate a matrix
exponential, including inﬁnite series expansion, which are generally
well described in introductory textbooks to multivariable control
systems.5 In MATLAB, the expm command is used.
A block diagram can help visualize the signal ﬂows. Consider
Fig. 5.1. In the diagram, the z−1 block represents a unit delay; the
input to this block is x[k + 1] = Ax[k] + Bu[k], and the output is x[k],
which is used to compute y[k] = Cx[k] + Du[k]. A MATLAB Simulink
block diagram can be created that looks exactly like this ﬁgure in
order to implement a discrete-time state-space system, providing that
the A, B, C, and D blocks are matrix-multiply blocks.
5.1.3
Converting transfer function to state space
As an example of working with different discrete-time model forms,
we consider how we might transform the following single-input
single-output difference equation into a state-space form:
y[k]+a1y[k−1]+a2y[k−2]+a3y[k−3] = b1u[k−1]+b2u[k−2]+b3u[k−3].

176
battery management systems: volume i, battery modeling
6 This is called a rational-polynomial form
transfer function (in z), because it com-
prises a quotient of two polynomials (in
the variable z).
7 This is a choice. There are other
equally valid choices, as we will see.
First, we take the z-transform of both sides of the equation (assuming
that initial conditions are zero) to get
<
1 + a1z−1 + a2z−2 + a3z−3=
Y(z) =
<
b1z−1 + b2z−2 + b3z−3=
U(z).
Rearranging gives6
G(z) =
b1z2 + b2z + b3
z3 + a1z2 + a2z + a3
= Y(z)
U(z).
(5.6)
We break up the transfer function into two parts:
G(z) = Gz(z)Gp(z),
where Gz(z) contains the “zeros” of the system and Gp(z) contains
the “poles.” That is
Gz(z) = b1z2 + b2z + b3
Gp(z) =
1
z3 + a1z2 + a2z + a3
.
Let V(z) = Gp(z)U(z). Then
v[k + 3] + a1v[k + 2] + a2v[k + 1] + a3v[k] = u[k].
For this example, we will choose the present and two advanced
versions of v[k] to be the model’s state vector.7
x[k] =
<
v[k + 2]
v[k + 1]
v[k]
=T
.
Then
⎡
⎢⎣
v[k + 3]
v[k + 2]
v[k + 1]
⎤
⎥⎦
#
$%
&
x[k+1]
=
⎡
⎢⎣
−a1
−a2
−a3
1
0
0
0
1
0
⎤
⎥⎦
#
$%
&
A
⎡
⎢⎣
v[k + 2]
v[k + 1]
v[k]
⎤
⎥⎦
#
$%
&
x[k]
+
⎡
⎢⎣
1
0
0
⎤
⎥⎦
# $% &
B
u[k].
This is the state equation for this system for this choice of state.
We now add a description of the system’s zeros:
Y(z) = Gz(z)V(z)
=
<
b1z2 + b2z + b3
=
V(z),
or
y[k] = b1v[k + 2] + b2v[k + 1] + b3v[k]
=
<
b1
b2
b3
=
#
$%
&
C
x[k].

5. state-space models and the discrete-time realization algorithm
177
In summary, we have the state-space model:
x[k + 1] =
⎡
⎢⎣
−a1
−a2
−a3
1
0
0
0
1
0
⎤
⎥⎦x[k] +
⎡
⎢⎣
1
0
0
⎤
⎥⎦u[k]
y[k] =
<
b1
b2
b3
=
x[k] +
<
0
=
u[k].
Note that there are many other equally valid state-space models
of this particular transfer function. We will soon see how they are
related.
Also, this particular example was for a transfer function that had
fewer zeros than poles. If the transfer function had an equal number
of zeros and poles, we would have started the example by perform-
ing polynomial long division. For example, consider
G(z) = dz3 + (da1 + b1)z2 + (da2 + b2)z + (da3 + b3)
z3 + a1z2 + a2z + a3
.
We ﬁrst perform polynomial long division and ﬁnd
G(z) = d +
b1z2 + b2z + b3
z3 + a1z2 + a2z + a3
= Y(z)
U(z).
Following essentially the same steps as before,
x[k + 1] =
⎡
⎢⎣
−a1
−a2
−a3
1
0
0
0
1
0
⎤
⎥⎦x[k] +
⎡
⎢⎣
1
0
0
⎤
⎥⎦u[k]
y[k] =
<
b1
b2
b3
=
x[k] +
<
d
=
u[k].
We see that systems having an equal number of poles and zeros have
a nonzero state-space D matrix. In our battery models, this direct-
feedthrough term represents an equivalent-series-resistance term, as
the output has a component that is instantaneously related to the
input.
While it can be instructive to work through an example like this by
hand, it is cumbersome to do so routinely. The MathWorks’ Control
System Toolbox for MATLAB provides the command [A,B,C,D] = tf2ss
(num,den,Ts) to convert a rational-polynomial transfer function form to
a state-space form.
5.1.4
Converting state space to transfer function
In the prior example, we saw that it is possible to convert from a
difference equation (or transfer function) to a state-space form quite
easily. Now, we’ll see that translating in the reverse direction is also
straightforward.

178
battery management systems: volume i, battery modeling
8 We have to be careful when factoring
X(z) from the two terms in which it
appears since z is a scalar and A is a
matrix. We must write zI −A instead
of z −A to have compatible dimensions
for the subtraction.
9 The entire ﬁrst term (including U(z))
is sometimes called the zero-state solu-
tion, and the second term is sometimes
called the zero-input solution.
We start with the state-space equations
x[k + 1] = Ax[k] + Bu[k]
y[k] = Cx[k] + Du[k].
Next, take the z-transform of both sides of both equations
zX(z) −zx[0] = AX(z) + BU(z)
Y(z) = CX(z) + DU(z).
Rearranging the state equation to solve for X(z) gives8
(zI −A)X(z) = BU(z) + zx[0]
X(z) = (zI −A)−1BU(z) + (zI −A)−1zx[0].
Substituting X(z) into the output equation gives9
Y(z) = [C(zI −A)−1B + D]
#
$%
&
transfer function of system
U(z) + C(zI −A)−1zx[0]
#
$%
&
response to initial conditions
.
By deﬁnition, the transfer function of a system assumes that the
initial conditions are zero. For this assumption,
G(z) = Y(z)
U(z) = C(zI −A)−1B + D.
Note that (zI −A)−1 = adj(zI−A)
det(zI−A), so we can write a system’s transfer
function as
G(z) = C adj(zI −A)B + D det(zI −A)
det(zI −A)
.
From this, we make an extremely important observation: the poles
of the system are where det(zI −A) = 0, which (by deﬁnition) are
the eigenvalues of A. Since the poles determine stability, character
of response, and speed of response, we can learn a lot about system
behavior from only the A matrix.
5.1.5
Transformation of state-space models
As alluded to earlier, state-space representations of a particular sys-
tem’s dynamics are not unique. The selection of the state vector x[k]
is somewhat arbitrary. To see this, let’s analyze a transformation of
Eqs. (5.4) and (5.5), where we let x[k] = Tw[k], and where T is a
constant square invertible (similarity) transformation matrix. Then,
(Tw[k + 1]) = A (Tw[k]) + Bu[k]
y[k] = C (Tw[k]) + Du[k].

5. state-space models and the discrete-time realization algorithm
179
Multiplying the ﬁrst equation by T−1 gives
w[k + 1] = T−1AT
# $% &
A
w[k] + T−1B
# $% &
B
u[k]
y[k] = CT
#$%&
C
w[k] + D
#$%&
D
u[k].
So, we have a revised discrete-time state-space form with the state
w[k] and matrices A, B, C, and D.
w[k + 1] = Aw[k] + Bu[k]
(5.7)
y[k] = Cw[k] + Du[k].
(5.8)
The input-to-state behavior of Eq. (5.7) is different from Eq. (5.4),
but the overall coupled input-to-output behavior of Eqs. (5.7) and (5.8)
is the same as that of Eqs. (5.4) and (5.5). We can see this by comput-
ing the transfer functions of the two representations, where we use
H1(z) to denote the transfer function of the x-state system and H2(z)
to denote the transfer function of the w-state system
H1(z) = C(zI −A)−1B + D
= CTT−1(zI −A)−1TT−1B + D
= (CT)[T−1(zI −A)T]−1(T−1B) + D
= C(zI −A)−1B + D = H2(z).
So, the transfer function has not been changed by the similarity
transform.
From this exercise, we conclude that it is possible to arrive at mul-
tiple state-space representations having identical input-output rela-
tionships but different (A, B, C, D) matrices. As an example, consider
the transformation of
A =
⎡
⎢⎣
−a1
−a2
−a3
1
0
0
0
1
0
⎤
⎥⎦,
B =
⎡
⎢⎣
1
0
0
⎤
⎥⎦,
C =
<
b1
b2
b3
=
,
D =
<
0
=
with
T = T−1 =
⎡
⎢⎣
0
0
1
0
1
0
1
0
0
⎤
⎥⎦.
Note that multiplying on the right by T ﬂips the original entries
left to right; multiplying on the left ﬂips the original entries top to
bottom.

180
battery management systems: volume i, battery modeling
For this transformation matrix, we ﬁrst compute the transformed
state-transition matrix
A = T−1AT =
⎡
⎢⎣
0
0
1
0
1
0
1
0
0
⎤
⎥⎦
⎡
⎢⎣
−a1
−a2
−a3
1
0
0
0
1
0
⎤
⎥⎦
⎡
⎢⎣
0
0
1
0
1
0
1
0
0
⎤
⎥⎦
=
⎡
⎢⎣
0
1
0
0
0
1
−a3
−a2
−a1
⎤
⎥⎦.
Next, consider the transformed input matrix
B = T−1B =
⎡
⎢⎣
0
0
1
0
1
0
1
0
0
⎤
⎥⎦
⎡
⎢⎣
1
0
0
⎤
⎥⎦=
⎡
⎢⎣
0
0
1
⎤
⎥⎦,
output matrix
C = CT =
<
b1
b2
b3
=
⎡
⎢⎣
0
0
1
0
1
0
1
0
0
⎤
⎥⎦=
<
b3
b2
b1
=
,
and direct feedthrough term D = D = 0.
To verify that we arrive at the same transfer function, we evaluate
G(z) = C(zI −A)−1B + D
=
<
b3
b2
b1
=
⎛
⎜
⎝
⎡
⎢⎣
z
0
0
0
z
0
0
0
z
⎤
⎥⎦−
⎡
⎢⎣
0
1
0
0
0
1
−a3
−a2
−a1
⎤
⎥⎦
⎞
⎟
⎠
−1⎡
⎢⎣
0
0
1
⎤
⎥⎦
=
<
b3
b2
b1
=
⎛
⎜
⎝
⎡
⎢⎣
z
−1
0
0
z
−1
a3
a2
z + a1
⎤
⎥⎦
⎞
⎟
⎠
−1 ⎡
⎢⎣
0
0
1
⎤
⎥⎦
=
<
b3
b2
b1
=
⎡
⎢⎣
z2 + a1z + a2
a1 + z
1
−a3
z2 + a1z
z
−a3z
−a2z −a3
z2
⎤
⎥⎦
⎡
⎢⎣
0
0
1
⎤
⎥⎦
z3 + a1z2 + a2z + a3
=
<
b3
b2
b1
=
⎡
⎢⎣
1
z
z2
⎤
⎥⎦
z3 + a1z2 + a2z + a3
=
b1z2 + b2z + b3
z3 + a1z2 + a2z + a3
,
which is the same transfer function as in Eq. (5.6), which is what we
started with before the transformations.
5.1.6
Discrete-time Markov parameters
It turns out that the discrete unit-pulse response of a state-space sys-
tem has a special form that will be important to us later. For example,

5. state-space models and the discrete-time realization algorithm
181
10 Note that, by deﬁnition, x[0] = 0
when ﬁnding a unit-pulse response.
let’s look at the unit-pulse response of a single-input state-space sys-
tem.10 The unit-pulse input is deﬁned as
u[k] =
⎧
⎨
⎩
1,
k = 0;
0,
k ̸= 0.
The system response to the unit-pulse input can be found by evaluat-
ing the state and output equations recursively
y[0] = Cx[0] + Du[0] = D,
x[1] = Ax[0] + Bu[0] = B
y[1] = Cx[1] + Du[1] = CB,
x[2] = Ax[1] + Bu[1] = AB
y[2] = Cx[2] + Du[2] = CAB,
x[3] = Ax[2] + Bu[2] = A2B
...
...
y[k] = CAk−1B,
k ≥1.
These pulse-response values, {D, CB, CAB, CA2B, CA3B, . . .} are
called the Markov parameters of the system. They turn out to be of
critical importance to realizing our transfer functions, as we will see.
Speciﬁcally, we deﬁne the Markov parameters to be:
gk =
⎧
⎨
⎩
D,
k = 0;
CAk−1B,
k > 0.
To be clear:
• For single-input single-output (SISO) systems, the Markov parameters
are scalars.
• For a single-input multioutput (SIMO) system, the Markov param-
eters are (column) vectors.
– The ith entry (row) of each Markov parameter is computed as
the unit-pulse response from the input to the ith output.
– Equivalently, the entire vector Markov parameter is the unit-
pulse response from the input to the vector output.
• For multi-input single-output (MISO) systems, the above results
can be generalized, and the Markov parameters are row vectors.
– The jth entry (column) of each Markov parameter is computed
via the unit-pulse response from the jth input to the output.
• For multi-input multioutput (MIMO) systems, the Markov parame-
ters are matrices.
– The (i, j)th entries yield the the unit-pulse response from the jth
input to the ith output.
– Equivalently, the jth column of each Markov parameter is a
vector (as in the SIMO case), which is computed as the unit-
pulse response from the jth input to the vector output.

182
battery management systems: volume i, battery modeling
0
5
10
15
0
0.5
1.0
Time (samples)
Value
Unit-pulse response of sample system 
Figure 5.2: Discrete unit-pulse response.
11 Jacobsen, T., and West, K., “Diffusion
Impedance in Planar, Cylindrical and
Spherical Symmetry,” Electrochimica
Acta, 40(2), 1995, pp. 255–62.
As an example, consider ﬁnding the discrete unit-pulse response for
a state-space system deﬁned by
A =
:
0.5
0
0
1
;
,
B =
:
1
0
;
,
C =
<
1
−1
=
,
D = 0.
The Markov parameters are given by
gk = {D, CB, CAB, CA2B, CA3B, . . .}
= {0, 1, 0.5, 0.25, . . .}.
This is illustrated in Fig. 5.2, where MATLAB’s impulse command
(from the Control System Toolbox) is used to conﬁrm this result:
A = [0.5 0; 0 1]; B = [1; 0]; C = [1 -1]; D = 0;
sys = ss(A,B,C,D,-1); % "-1" = discrete-time model with unknown T
[y,k] = impulse(sys,0:15);
stem(k,y,'filled');
5.2
Equations describing the solid dynamics
We have now quickly previewed state-space models, with the claim
that there will be a method to represent our battery models in that
particular form. We continue by beginning to investigate that claim,
with the ﬁrst step being to create transfer-function models for the
variables of interest. In this chapter, we look at representing cs as a
transfer function; in the next chapter we look at the remainder of the
model equations.
Note that in Chap. 3, we used symbols without an over-line to indi-
cate point-wise values for variables of interest (i.e., cs, ce, φs, φe, and
j). Then, in Chap. 4 we used symbols with an over-line to indicate
volume-average versions of these point-wise variables (i.e., ¯ce, ¯φs, ¯φe,
and ¯j). We now drop the over-line notation, because otherwise the
equations get so highly decorated that they are impossible to parse.
We are still talking about the volume-average quantities of Chap. 4.
5.2.1
Finding the transfer function KCs,e(s)/J(s)
To ﬁnd the transfer function for cs, we follow the approach by Ja-
cobsen and West.11 We start with the underlying partial-differential
equation
∂cs(r, t)
∂t
= 1
r2
∂
∂r
.
Dsr2 ∂cs(r, t)
∂r
/
,
with standard boundary conditions
Ds
∂cs(0, t)
∂r
= 0,
and
Ds
∂cs(Rs, t)
∂r
= −j(t),
t ≥0,

5. state-space models and the discrete-time realization algorithm
183
and with initial equilibrium concentration,
cs(r, 0) = cs,0,
0 ≤r ≤Rs.
Note that we run into problems solving this PDE directly if cs,0 ̸=
0. To enforce a homogeneous PDE in later steps, we deﬁne ˜cs(r, t) =
cs(r, t) −cs,0. The “tilde” notation denotes the difference between an
absolute quantity and its equilibrium set-point, resulting in a debiased
variable.
We also assume that Ds is constant, and so the differential equa-
tions for ˜cs become
∂˜cs(r, t)
∂t
= Ds
r2
∂
∂r
.
r2 ∂˜cs(r, t)
∂r
/
,
with boundary conditions,
Ds
∂˜cs(0, t)
∂r
= 0,
and
Ds
∂˜cs(Rs, t)
∂r
= −j(t),
t ≥0,
and with initial equilibrium concentration,
˜cs(r, 0) = 0,
0 ≤r ≤Rs.
We proceed by taking the Laplace transform of the underlying
equation
s KCs(r, s) −˜cs(r, 0) = Ds
r2
∂
∂r
.
r2 ∂
∂r
KCs(r, s)
/
s KCs(r, s) = Ds
r2
,
2r ∂KCs(r, s)
∂r
+ r2 ∂2 KCs(r, s)
∂r2
-
.
This is a second-order differential equation in r, which may be writ-
ten as
∂2 KCs(r, s)
∂r2
+ 2
r
∂KCs(r, s)
∂r
−s
Ds
KCs(r, s) = 0.
The solution to this homogeneous differential equation has the form
KCs(r, s) = A
r exp
.
r
L s
Ds
/
+ B
r exp
.
−r
L s
Ds
/
= A
r exp(β(r)) + B
r exp(−β(r)),
where we deﬁne β(r) = r√
s/Ds. We note that β(r) is also a function
of s, but we omit this dependence in the notation for compactness.
The constants A and B are chosen to satisfy the boundary condi-
tions of the problem. Consider ﬁrst the outer boundary condition at
r = Rs, which is
Ds
∂˜cs(r, t)
∂r
++++
r=Rs
= −j(t).

184
battery management systems: volume i, battery modeling
The equivalent Laplace-domain boundary condition is
Ds
∂KCs(r, s)
∂r
+++++
r=Rs
= −J(s).
To substitute this into our result, we will need to compute ∂KCs(r, s)/∂r,
which is
∂KCs(r, s)
∂r
=
A
M
s
Ds r exp(β(r)) −B exp(−β(r))
r2
−
A exp(β(r)) + B
M
s
Ds r exp(−β(r))
r2
= A(β(r) −1) exp(β(r)) −B(1 + β(r)) exp(−β(r))
r2
.
We substitute r = Rs and the boundary condition
∂KCs(r, s)
∂r
+++++
r=Rs
= A(β(Rs)−1) exp(β(Rs)) −B(1+β(Rs)) exp(−β(Rs))
R2s
−J(s)
Ds = A(β(Rs)−1) exp(β(Rs)) −B(1+β(Rs)) exp(−β(Rs))
R2s
.
This gives us an expression for J(s),
J(s) = −Ds
R2s
(A(β(Rs) −1) exp(β(Rs)) −B(1 + β(Rs)) exp(−β(Rs))) .
If we immediately substitute the second boundary condition at r =
0, we run into some divide-by-zero issues. So, instead, we substitute
r = rδ, which we think of as a very small value. We will then later
take the limit as rδ →0.
0 = A(β(rδ) −1) exp(β(rδ)) −B(1 + β(rδ)) exp(−β(rδ))
r2
δ
.
This allows us to write
A(β(rδ) −1) exp(β(rδ))
r2
δ
= B(1 + β(rδ)) exp(−β(rδ))
r2
δ
A = B(1 + β(rδ)) exp(−β(rδ))
(β(rδ) −1) exp(β(rδ)) .
We take the limit as rδ →0, and ﬁnd that A = −B.
We are now ready to construct the transfer function KCs(s, r)/J(s)
KCs(r, s)
J(s)
= −R2
s
Dsr
@
A exp(β(r))+B exp(−β(r))
A(β(Rs)−1) exp(β(Rs))−B(1+β(Rs)) exp(−β(Rs))
A
= −R2
s
Dsr
@ A
−A
A@
exp(β(r))−exp(−β(r))
(1−β(Rs)) exp(β(Rs))−(1+β(Rs)) exp(−β(Rs))
A
= R2
s
Dsr
@
exp(β(r))−exp(−β(r))
(1−β(Rs)) exp(β(Rs))−(1+β(Rs)) exp(−β(Rs))
A
.

5. state-space models and the discrete-time realization algorithm
185
12 We call KCs,e(s)/J(s) a transcendental
form transfer function (in s), since it is
not represented by a quotient of two
polynomials (in the variable s). That
is, it is not a rational-polynomial transfer
function.
13 This result is perfectly general. We
made no assumptions on how the
lithium concentration is distributed
inside the particle.
This expression can be used to determine the lithium concentra-
tion anywhere within the particle. However, we are most interested
in determining the concentration at the surface of the particle, where
r = Rs. So we substitute r = Rs and denote KCs,e(s) = KCs(Rs, s)
KCs,e(s)
J(s)
= Rs
Ds
@
exp(β(Rs)) −exp(−β(Rs))
(1 −β(Rs)) exp(β(Rs)) −(1 + β(Rs)) exp(−β(Rs))
A
.
To compact the notation yet again, write β(Rs) as simply β,
KCs,e(s)
J(s)
= Rs
Ds
@
exp(β) −exp(−β)
(1 −β) exp(β) −(1 + β) exp(−β)
A
= Rs
Ds
⎡
⎣
exp(β)−exp(−β)
exp(β)−exp(−β)
exp(β)−exp(−β)
exp(β)−exp(−β) −β exp(β)+exp(−β)
exp(β)−exp(−β)
⎤
⎦
= Rs
Ds
@
1
1 −β coth(β)
A
.
To recap to this point, re-expanding notation,12
KCs,e(s) = Rs
Ds
@
1
1 −Rs
√
s/Ds coth(Rs
√
s/Ds)
A
J(s).
(5.9)
5.2.2
Removing the integrator pole
While not immediately obvious by looking at the transfer function, it
turns out that KCs,e(s)/J(s) is unstable: it has a pole at s = 0, which
corresponds to integration dynamics. This is intuitively clear, how-
ever, because we know that a constant inﬂux of lithium to a particle
will result in an ever-increasing concentration of lithium within that
particle.
This will be important when we look at how to convert the trans-
fer function to a state-space model. To make a stable transfer func-
tion, deﬁne ∆KCs,e(s) = KCs,e(s) −KCs,avg(s), where KCs,avg(s) is the bulk
(average) concentration in the solid, less cs,0.
Note that we can write ˜cs,avg(t1) for arbitrary time t1 as
˜cs,avg(t1) =
ˆ t1
0
Inﬂux of Li, [mol s−1]
Volume of particle [m3] dt.
The volume of a sphere of radius Rs is 4
3πR3
s [m3] and the inﬂux of
lithium is −j(t) [mol m−2 s−1], occurring over the surface area of
4πR2
s [m2]. This gives13
˜cs,avg(t1) =
ˆ t1
0
−j(t) · 4πR2s
4
3πR3s
dt = −3
Rs
ˆ t1
0
j(t) dt
d
dt ˜cs,avg(t) = −3
Rs
j(t).

186
battery management systems: volume i, battery modeling
14 Smith, K., Electrochemical Modeling,
Estimation and Control of Lithium Ion
Batteries, Ph.D. dissertation, The Penn-
sylvania State University, 2006.
Taking Laplace transforms, we ﬁnd:
KCs,avg(s)
J(s)
= −3
Rs
1
s .
Therefore,
∆KCs,e(s)
J(s)
=
KCs,e(s)
J(s)
−
KCs,avg(s)
J(s)
= Rs
Ds
@
1
1 −β coth(β)
A
+
3
Rss
= Rs
Ds
⎡
⎣
1 + 3Ds
sR2s (1 −β coth(β))
1 −β coth(β)
⎤
⎦
= Rs
Ds
⎡
⎣
1 + 3
β2 (1 −β coth(β))
1 −β coth(β)
⎤
⎦
= Rs
Ds
@ β2 + 3 (1 −β coth(β))
β2 (1 −β coth(β))
A
= Rs
Ds
@(β2 + 3) −3β coth(β)
β2 (1 −β coth(β))
A
.
Finally, expanding notation, we have
∆KCs,e(s)
J(s)
=
sR2s
Ds + 3 −3Rs
M
s
Ds coth
'
Rs
M
s
Ds
(
sRs
'
1 −Rs
M
s
Ds coth
'
Rs
M
s
Ds
(( .
(5.10)
5.3
State-space realization
At this point, we have found a transfer-function model that relates in-
put ﬂux to transient variations in the surface concentration of lithium
around some average value. For this speciﬁc case, it turns out to be
possible to ﬁnd all the poles and zeros of the transfer function us-
ing a simple numeric method, and to use that information to make
a discrete-time state-space model.14 However, for the transfer func-
tions we develop in Chap. 6, this cannot be done. So, we must turn to
alternative implementation approaches.
One method is to use nonlinear optimization to select poles and
zeros of a rational-polynomial transfer function to attempt to match
its frequency response to that of the transcendental transfer function.
Then, standard methods for converting rational-polynomial transfer
functions to state-space models can be used. Unfortunately, however,
this approach is fraught with problems. In particular, nonlinear opti-
mization is very sensitive to the initial model guess, is unbounded in
time and computation, and is not guaranteed to converge to a global
optimum.

5. state-space models and the discrete-time realization algorithm
187
15 Ho, B.L., and Kalman, R.E., “Effective
Construction of Linear State Variable
Models from Input/Output Functions,”
Regelungstechnik, 14(12), 1966, pp. 545–8.
16 It should be evident from the equa-
tion, but we point out for clarity, that
the controllability matrix C and the
output matrix C are different quantities,
even though the notation looks quite
similar.
We introduce another approach, which gives us a discrete-time
state-space approximate model directly from our transfer functions.
This system-identiﬁcation problem for state-space systems is some-
times called the “realization problem.” That is, we wish to ﬁnd a
realization (a set of A, B, C, and D matrices) that describes a system’s
dynamics. For now, we assume that we are able to ﬁnd the Markov
parameters of our transfer functions.
The problem is then: given a system’s Markov parameters, ﬁnd the
system dimension n and (A, B, C, D), up to a similarity transform.
5.3.1
The Ho–Kalman state-space realization method
An early (maybe the ﬁrst) state-space realization method was intro-
duced by Ho and Kalman.15 It is key to the discrete-time realization
algorithm we will develop. To derive the Ho–Kalman method, notice
that something curious happens when we multiply the following
matrices together
⎡
⎢⎢⎢⎢⎢⎢⎣
C
CA
CA2
...
CAn−1
⎤
⎥⎥⎥⎥⎥⎥⎦
#
$%
&
O
<
B
AB
A2B
· · ·
An−1B
=
#
$%
&
C
=
⎡
⎢⎢⎢⎢⎢⎢⎣
CB
CAB
CA2B
· · ·
CAn−1B
CAB
CA2B
CA3B
CA2B
CA3B
CA4B
...
...
...
CAn−1B
· · ·
CA2n−2B
⎤
⎥⎥⎥⎥⎥⎥⎦
.
For reasons beyond the scope of our discussion here, O is called
the observability matrix and C is called the controllability matrix of our
state-space system.16
Notice that the product of O and C is a block Hankel matrix—a
matrix having constant skew diagonals (i.e., it is an upside-down
block Toeplitz matrix). Note also that the values on the skew diago-
nals are the Markov parameters of the system (excluding g0 and gk
for k > 2n −1). That is,
H = OC =
⎡
⎢⎢⎢⎢⎣
g1
g2
· · ·
gn
g2
g3
...
...
...
gn
· · ·
g2n−1
⎤
⎥⎥⎥⎥⎦
.

188
battery management systems: volume i, battery modeling
The Ho–Kalman method assumes that we know the Markov pa-
rameters. Knowledge of g0 gives us D directly. Knowledge of the rest
of the Markov parameters will ultimately result in A, B, and C.
To use Ho–Kalman, we must ﬁrst form the Hankel matrix H. The
next step is to factor H = OC into its O and C components. The
third step is to use O and C to ﬁnd A, B, and C.
issue i: We don’t know n. So, how do we form H in the ﬁrst place?
That is, when do we stop adding pulse-response values to H?
preliminary answer: The rank of H is equal to the system order
n. Keep adding data until the rank doesn’t increase.
issue ii: How do we compute A, B, and C from O and C?
answer: Our estimate NC of C is extracted as the ﬁrst block row of
O; our estimate NB of B is extracted as the ﬁrst block column of
C. We’ll see how to get our estimate NA of A shortly.
issue iii: How do we factor H into O and C?
answer: It doesn’t matter, at least in principle. Any matrices O
and C such that OC = H are okay.
To see this latter point, consider what happens to O and C when
the state-space model undergoes a similarity transformation. Recall
that A = T−1AT, B = T−1B, and C = CT. The observability and
controllability matrices of the new representation are
O =
⎡
⎢⎢⎢⎢⎣
C
CA
...
CAn−1
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎣
CT
CTT−1AT
...
CT(T−1AT)n−1
⎤
⎥⎥⎥⎥⎦
= OT
C =
<
B
AB
· · ·
An−1B
=
=
<
T−1B
T−1ATT−1B
· · ·
(T−1AT)n−1T−1B
=
= T−1C.
Therefore, OC = (OT)(T−1C) = OC. If we factor H one way,
we end up with a representation that has one set of O and C. If we
factor H any other way, we end up with a representation that has an
alternate set of O and C. But, these representations are related via a
similarity transformation T.
That is, no matter how we factor H, we end up with different A,
B, and C matrices, but the same input–output relationship (same
transfer function, same unit-pulse response, but different state de-
scriptions). For example, we could choose to let O = I, and then
C = H. This will result in an A, B, and C that are in observability
canonical form. Or, we could choose to let C = I, and then O = H.

5. state-space models and the discrete-time realization algorithm
189
This will result in an A, B, and C that are in controllability canonical
form.
issue iv: Is there a “best” way to factor H?
answer: Yes, using the singular value decomposition (SVD). We
now review this critical tool.
5.3.2
Singular value decomposition (SVD)
An important result from linear algebra is that any rectangular matrix
A ∈Rm×n, where rank(A) = r, can be factored into the form
A = UΣV T,
(5.11)
where
• U = [u1, . . . , um] ∈Rm×m, and UTU = I, and ui are the left or
output singular vectors of A.
• V = [v1, . . . , vn] ∈Rn×n, and V TV = I, and vi are the right or input
singular vectors of A.
• The matrix Σ ∈Rm×n is a (zero-padded) diagonal matrix contain-
ing the singular values σi of the matrix A. That is,
Σ =
⎡
⎢⎢⎣
σ1
0
0
...
0
0
σm
0
⎤
⎥⎥⎦,
or
Σ =
⎡
⎢⎢⎣
σ1
0
...
0
σn
⎤
⎥⎥⎦,
or
Σ =
⎡
⎢⎢⎢⎢⎣
σ1
0
...
0
σn
0
0
0
⎤
⎥⎥⎥⎥⎦
,
when m < n, m = n, and m > n, respectively, where σ1 ≥· · · ≥
σr > 0, and σi = 0 for i > r.
The factored form of Eq. (5.11) is called the (full) singular value decom-
position of the matrix A. In MATLAB, the singular value decomposi-
tion is computed via svd or svds.
We often write the full SVD in partitioned form, with matrix parti-
tions based on the rank r of A:
A =
<
U1
U2
= :
Σ1
0r×(n−r)
0(m−r)×r
0(m−r)×(n−r)
; :
V T
1
V T
2
;
,
where A = U1Σ1V T
1 is known as the compact SVD.
We can view the operation y = Ax as y = (UΣV T)x by decompos-
ing the operation into (1) computing coefﬁcients of x along the input
directions v1, . . . , vr (rotating by V T); (2) scaling the coefﬁcients by σi

190
battery management systems: volume i, battery modeling
x
Ax
ΣV Tx
V Tx
V T
Σ
U
Figure 5.3: Visualizing a matrix multi-
plication via the SVD of the matrix.
(dilation); and (3) reconstituting the output along output directions
u1, . . . , ur. This is illustrated in Fig. 5.3. Note that v1 is the most sen-
sitive (highest gain) input direction and u1 is the highest gain output
direction. We have Av1 = σ1u1.
An important result is that the singular values themselves are
related to the matrix norm. In particular, the two-norm of a matrix is
equal to the maximum singular value of the matrix: ∥A∥2 = σ1. Thus,
overall, the SVD gives a picture of gain as a function of input/output
directions.
As an example, consider A ∈R4×4 with Σ = diag(10, 7, 0.1, 0.05).
Then, input components along directions v1 and v2 are ampliﬁed (by
a factor of about 10) and come out mostly along the plane spanned
by u1 and u2. Input components along directions v3 and v4 are at-
tenuated (by a factor of about 10). The gain ∥Ax∥2 / ∥x∥2 can range
between 10 and 0.05. Because the gain is always greater than zero,
we can also conclude that A is nonsingular. For some applications
you might say that A is effectively rank 2 (this will be important for us
later).
5.3.3
Low-rank approximations via the SVD
Suppose that A ∈Rm×n has rank(A) = r, with SVD A = UΣV T =
∑r
i=1 σiuivT
i . We want to approximate A by NA, where rank(NA) ≤p <
r such that NA ≈A in the sense that
OOOA −NA
OOO
2 is minimized. Then,
the optimal rank p approximant to A is NA = ∑
p
i=1 σiuivT
i and hence
OOOA −NA
OOO
2 =
OOOOO
r
∑
i=p+1
σiuivT
i
OOOOO
2
= σp+1
because σp+1 is the maximum remaining singular value.
interpretation: SVD dyads uivT
i are ranked in order of “impor-
tance”; we take p of them to get a rank p approximant.
application: We can use this idea to simplify models.
This latter point is very useful. For example, suppose that y = Ax +
w where A ∈R100×30 has singular values 10, 7, 2, 0.5, 0.01, . . . , 0.0001.
If ∥x∥2 is on the order of 1, and the unknown error or noise w has
norm on the order of 0.1, then the terms σiuivT
i x for i = 5, . . . , 30 are
substantially smaller than the noise term w. So, we can approximate
y = Ax + w by the much simpliﬁed model y = ∑4
i=1 σiuivT
i x + w.
5.3.4
Implementing the Ho–Kalman method
Recall state-space realization “issue i,” how do we form the Hankel
matrix H if we don’t know the dimension of the system state n? To

5. state-space models and the discrete-time realization algorithm
191
address this issue, consider the inﬁnite, skew-diagonal matrix H∞
where
H∞=
⎡
⎢⎢⎢⎢⎢⎢⎣
g1
g2
g3
g4
· · ·
g2
g3
g4
g5
· · ·
g3
g4
g5
g6
· · ·
g4
g5
g6
g7
· · ·
...
...
...
...
...
⎤
⎥⎥⎥⎥⎥⎥⎦
,
where the entries gk correspond to the Markov parameters for the
given system. This form is called an inﬁnite Hankel matrix, or the
Hankel operator.
We can also deﬁne a ﬁnite Hankel matrix, formed by the ﬁrst k
block rows and l block columns of H
Hk,l =
⎡
⎢⎢⎢⎢⎢⎢⎣
g1
g2
g3
· · ·
gl
g2
g3
g4
· · ·
gl+1
g3
g4
g5
· · ·
gl+2
...
...
...
...
gk
gk+1
gk+2
· · ·
gk+l−1
⎤
⎥⎥⎥⎥⎥⎥⎦
.
This ﬁnite Hankel matrix can be factored into Hk,l = OkCl where
Ok =
⎡
⎢⎢⎢⎢⎣
C
CA
...
CAk−1
⎤
⎥⎥⎥⎥⎦
,
Cl =
<
B
AB
A2B
· · ·
Al−1B
=
.
The approach we will take is to make a Hk,l of larger size than we
expect to need for a hypothesized value of n. That is, k > n and l > n.
Therefore Ok ̸= O and Cl ̸= C even though the matrices have the
same general form. We call Ok the extended observability matrix and Cl
the extended controllability matrix.
We then apply the SVD to Hk,l
Hk,l = UΣV T = UΣ1/2Σ1/2V T
= UΣ1/2TT−1Σ1/2V T
= (UΣ1/2T)
#
$%
&
Ok
(T−1Σ1/2V T)
#
$%
&
Cl
.
The factoring of Hk,l into Ok and Cl depends on the choice of trans-
formation matrix T, but the input–output behavior of the resulting
model does not depend on T. The only restriction is that T must be
invertible; we generally choose T to be the identity matrix, T = I, for
simplicity. This solves “issue iii” and “issue iv.”
The system order n can be determined by the number of nonzero
singular values. However, “noise” on the unit-pulse response values

192
battery management systems: volume i, battery modeling
that make up Hk,l (even numeric roundoff noise) cause the SVD
to have more than n nonzero singular values. So, in practice, we
look at the ﬁrst several singular values and make a judgment where
there is a signiﬁcant drop-off in the magnitude of the singular values,
choosing to retain a model having a number of states equal to the
number of signiﬁcant singular values.
We are left with the ﬁnal question: How to decompose further into
(A, B, C) to solve “issue ii”?
Note the shift property of a Hankel matrix. If we shift H up by
one block row, we get H↑
k+1,l = OkACl.
H↑
k+1,l =
⎡
⎢⎢⎢⎢⎢⎢⎣
g2
g3
g4
· · ·
gl+1
g3
g4
g5
· · ·
gl+2
...
...
...
...
gk
gk+1
gk+2
· · ·
gk+l−1
gk+1
gk+2
gk+3
· · ·
gk+l
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
CAB
CA2B
CA3B
· · ·
CAlB
CA2B
CA3B
CA4B
CAl+1B
...
...
...
...
...
CAk−1B
CAkB
CAk+1B
· · ·
CAk+l−2B
CAkB
CAk+1B
CAk+2B
· · ·
CAk+l−1B
⎤
⎥⎥⎥⎥⎥⎥⎦
= O↑
k+1Cl = OkC←
l+1 = OkACl.
There are a variety of ways that we can use these relationships to
solve for our estimate NA of A. One of these uses the matrix pseudo-
inverse operation, giving NA = O†
kH↑
k+1,lC†
l .
In MATLAB, if Ok is the extended observability matrix, Cl is the
extended controllability matrix, and HankelUp is the shifted Hankel
matrix H↑
k+1,l, we can compute either
Ahat = pinv(Ok)*HankelUp*pinv(Cl);
or
Ahat = (Ok\HankelUp)/Cl;
As before, we extract our estimate NB of B from the ﬁrst block col-
umn of the extended controllability matrix Cl, we extract our esti-
mate NC of C from the ﬁrst block row of the extended observability
matrix Ok, and we set our estimate ND of D to ND = g0.
5.3.5
Summary: Algorithm steps for the Ho–Kalman method
The following steps comprise the Ho–Kalman method for converting
a discrete unit-pulse response to a state-space representation.

5. state-space models and the discrete-time realization algorithm
193
step i: Collect the discrete unit-pulse response values into two Han-
kel matrices: (1) an original ﬁnite Hankel matrix Hk,l, and (2) a
shifted version H↑
k+1,l of the original Hankel matrix.
step ii: Compute the SVD of the (unshifted) Hankel matrix Hk,l,
and identify the system order n as the number of “large” singular
values.
step iii: Compute the extended observability and controllability
matrices, using appropriately dimensioned SVD components. (We
typically use T = I.)
step iv: Identify estimates (NA, NB, NC) of the system matrices (A, B, C).
Set estimate ND of D to ND = g0.
As an example, suppose that a unit-pulse input to some single-input
single-output system yields the following response:
y = (0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, · · ·).
We recognize this output as the Fibonacci sequence generated by
gk = gk−1 + gk−2 with initial conditions g0 = 0 and g1 = 1.
A typical realization for this sequence is given by the state-space
system
A =
:
0
1
1
1
;
,
B =
:
1
1
;
,
C =
<
1
0
=
,
D = 0.
(5.12)
We’ll try to come up with an equivalent realization based on only
the unit-pulse response. In MATLAB, we can deﬁne this state-space
system and ﬁnd the unit-pulse response as
% Define true system, compute the Markov parameters as "y"
A
= [0 1; 1 1]; B
= [1; 1]; C
= [1 0]; D
= 0; dt = 1;
sysTrue = ss(A,B,C,D,dt);
% "typical" Fibonacci ss model
y = dt*impulse(sysTrue);
% scale by dt to get unit-pulse response
Next, we form the required Hankel matrices, which turn out to be
H4,4 =
⎡
⎢⎢⎢⎣
1
1
2
3
1
2
3
5
2
3
5
8
3
5
8
13
⎤
⎥⎥⎥⎦,
H↑
5,4 =
⎡
⎢⎢⎢⎣
1
2
3
5
2
3
5
8
3
5
8
13
5
8
13
21
⎤
⎥⎥⎥⎦.
This was accomplished using the MATLAB code
% Form H{4,4} and shifted H{5,4}. Note:
Do not include "zero-th"
% parameter (first element of y), which corresponds to the matrix D.
bigHankel = hankel(y(2:end)); % don't forget to omit h(0) term = y(1)
H = bigHankel(1:4,1:4);
% for this example, keep only 4x4 portion
Hup = bigHankel(2:5,1:4);
% shifted H{5,4}
The SVD of H4,4 yields
σ1 = 54.56,
σ2 = 0.43988,
σi = 0, i ≥3
which indicates that n = 2. In MATLAB,

194
battery management systems: volume i, battery modeling
−1
0
1
2
−1
−0.5
0
0.5
1
Pole−zero map
Real axis
Imaginary axis
Figure 5.4: Pole-zero map of true
and estimated systems for Fibonacci
example.
1
2
3
4
5
6
7
8
0
5
10
15
20
25
Time step k
Output
Unit-pulse responses
 
 
True system
Estimated system
Figure 5.5: Fibonacci sequence example
using the Ho–Kalman method.
% Compute singular values of Hankel matrix
[U,S,V] = svd(H);
% Identify system order off-line as n = 2 based on values of S
n = 2;
We now extract the two left columns of U and V
U = V =
⎡
⎢⎢⎢⎣
−0.1876
0.7947
−0.3035
−0.4911
−0.4911
0.3035
−0.7947
−0.1876
⎤
⎥⎥⎥⎦.
We compute the extended controllability and observability matri-
ces
Cl = Σ1/2V T =
:
−0.8507
−1.3764
−2.2270
−3.6034
0.5257
−0.3249
0.2008
−0.1241
;
Ok = UΣ1/2 = CT
l .
In MATLAB,
% Compute extended observability and controllability matrices, sized to
% the order for the system inferred by the singular values.
Us = U(:,1:n); Ss = S(1:n,1:n); Vs = V(:,1:n);
Ok = Us*sqrtm(Ss); Cl = sqrtm(Ss)*Vs';
Finally, we identify the system matrices (NA, NB, NC) up to similarity
transform, and ND from g0
NA = O†
kH↑
k+1,lC†
l =
:
1.6180
0
0
−0.6180
;
NB = Cl(1 : n, 1 : m) = Cl(1 : 2, 1) =
:
−0.8057
0.5257
;
NC = Ok(1 : p, 1 : n) = Ok(1, 1 : 2) =
<
−0.8057
0.5257
=
ND = g0 = 0.
The numeric results above were found using the following MATLAB
code:
% Identify system assuming p = m = 1 (SISO), using shifted Hankel matrix
Ahat = (Ok\Hup)/Cl; Bhat = Cl(:,1); Chat = Ok(1,:); Dhat = y(1);
sysEst = ss(Ahat, Bhat, Chat, Dhat, dt);
Now, let’s compare the true system of Eq. (5.12) and the identi-
ﬁed (“estimated”) system. Fig. 5.4 shows the poles and zeros of the
true and estimated systems. Both systems have two poles and one
zero, and the locations of the estimated system’s dynamics are in-
distinguishable from those of the true system. In Fig. 5.5, we see the
unit-pulse responses of the true and estimated system. Again, the
two responses cannot be told apart.

5. state-space models and the discrete-time realization algorithm
195
17 This method was ﬁrst published in
Lee, J.L., Chemistruck, A., and Plett,
G.L., “Discrete-Time Realization of
Transcendental Impedance Functions,
with Application to Modeling Spherical
Solid Diffusion,” Journal of Power
Sources, 206, 2012, pp. 367–377. The
method developed in this book is
identical in all major respects, but varies
slightly in some of the details with the
aim of improving clarity.
comments: Selecting an appropriate amount of output data to store
may require iteration (“how big an H do I need?”). Generally, we
would add data until rank(Hk,l)= rank(Hk−1,l−1), or until the
next singular value is “insigniﬁcant.”
remaining question: If we start with a generic continuous-time
transfer function, from whence come the gk? The answer to this
question turns out to be the key to applying the Ho–Kalman
method to ﬁnding a state-space realization for our battery trans-
fer functions. We explore it next.
5.4
Discrete-time realization algorithm (DRA)
Given a (possibly multi-input multioutput) continuous-time transfer
function H(s) in the Laplace domain such that Y(s) = H(s)U(s), and
a sampling period, Ts, we want to derive a reduced-order discrete-
time state-space realization of the form
x[k + 1] = Ax[k] + Bu[k]
y[k] = Cx[k] + Du[k].
The method that we develop is called the discrete-time realization algo-
rithm, or DRA.17
A sufﬁcient condition for the DRA to operate is that H(s) be an
element of the Hardy space H∞, which implies that it is a strictly
stable and proper system. This is not a necessary condition to be able
to ﬁnd a state-space realization, however, as we will later generalize
the method to work with systems having an isolated pole at the
origin of the s-plane (i.e., an integrator).
Note that we do not restrict H(s) to be formulated as a quotient
of polynomials in the Laplace variable “s” (for which well-known
methods exist to ﬁnd the discrete-time system). This is important for
us to be able to ﬁnd realizations for transcendental transfer functions
like those in Eqs. (5.9) and (5.10).
For simplicity, we describe the DRA for single-input single-output
H(s), but the result may be generalized to multi-input and/or multioutput
H(s), as will be needed in the next chapter. We will describe the ad-
ditional considerations for multi-input multioutput systems in the
examples presented then.
The overall DRA process, starting with the continuous-time trans-
fer function H(s) is:
step 1: Sample the continuous-time transfer function H(s) in the
frequency domain at a high rate, and take the inverse discrete
Fourier transform (IDFT) of the samples to get an approximation
to the continuous-time impulse response h(t).

196
battery management systems: volume i, battery modeling
step 2: Use h(t) to approximate the continuous-time step response
hstep(t), also sampled at the high rate.
step 3: Compute the discrete-time unit-pulse response values gk with
inter-sample period Ts from the continuous-time step response
hstep(t), assuming a sample and hold circuit connected to the
system input.
step 4: Generate a discrete-time state-space realization using the
deterministic Ho–Kalman algorithm. This algorithm returns the
reduced order NA, NB, and NC matrices from the discrete-time unit-
pulse response sequence in Step 3. The order of the system is
determined from the ordered singular values of the Hankel matrix
computed as part of the algorithm. The ND matrix is found by the
initial value theorem.
We note that a transfer function having a pole at the origin does not
meet the strictly stable requirement. However, we will also show that
this pole can be accounted for automatically.
We now proceed to discuss the sample-and-hold framework, the
Ho–Kalman method, and accounting for a possible pole at s = 0 in
more detail.
5.4.1
Building the DRA from the end to the beginning
step 4: We now build the discrete-time realization algorithm in back-
ward order. We start by recognizing that if we know a system’s unit-
pulse response, we can use the Ho–Kalman algorithm to ﬁnd its state-
space representation. Therefore, we focus on ﬁnding the unit-pulse
response.
step 3: How do we ﬁnd the unit-pulse response? Let’s assume that
we know the system’s continuous-time step response hstep(t). Then,
we can ﬁnd the unit-pulse response as illustrated in Fig. 5.6. Notice
that if a unit-step input results in a unit-step response, then (because
of time invariance) a time-shifted unit-step input will result in a time-
shifted unit-step response. Here, we consider a time shift equal to
Ts, the desired sampling period of the ﬁnal discrete-time state-space
system.
Then, if we use an input equal to the difference between the unit-
step function and the time-shifted unit-step function, the output
will be the difference between the unit-step response and the time-
shifted unit-step response (because of linearity). This modiﬁed input
is the unit-pulse function of duration Ts, so the modiﬁed output must
be the unit-pulse response. We sample this continuous-time unit-
pulse response every Ts seconds to ﬁnd the discrete-time unit-pulse
response.

5. state-space models and the discrete-time realization algorithm
197
Step function
Step response
Shifted step function
Shifted step response
Unit-pulse function
Unit-pulse response
subtract
Ts
Figure 5.6: Converting a continuous-
time step response to a discrete-time
unit-pulse response.
18 Franklin, G.F., Powell, J.D., and
Workman, M., Digital Control of Dynamic
Systems, 3rd ed., Addison-Wesley, 1998,
pp. 187–210.
19 To arrive at an accurate estimation of
the continuous-time transfer function,
the sampling frequency F1 = 1/T1 must
be high enough to capture the system
dynamics. As a rule of thumb, the
sampling frequency must be at least 20
times as great as the bandwidth of the
system to get a rough approximation
in the frequency domain. A higher
emulation sampling frequency gives
more accurate results.
That is, the continuous-time response to a unit pulse of length Ts
seconds is
hpulse(t) = hstep(t) −hstep(t −Ts),
and the discrete-time unit-pulse response is then gk = hpulse(kTs).
step 2: So, if we can ﬁnd the system’s continuous-time step response,
we can ﬁnd a discrete-time state-space realization. But, how do we
ﬁnd the continuous-time step response? Let’s assume that we know
the continuous-time impulse response h(t). Then,
hstep(t) =
ˆ t
0
h(τ) dτ.
In fact, since the DRA is a numeric algorithm, we can’t deal with
continuous time directly. Instead, we select a fast sample frequency
F1 such that T1 =
1
F1 ≪Ts. Then, the ﬁnely sampled continuous-time
step response is
hstep(kT1) = T1
k−1
∑
i=0
h(iT1).
step 1: So, if we can ﬁnd the system’s ﬁnely sampled continuous-
time impulse response, we can ﬁnd a state-space representation.
But, how do we ﬁnd the ﬁnely sampled continuous-time impulse
response?
One approach is to approximate the continuous-time impulse
response via a “discrete equivalent” method.18 We use the bilinear
transform to write a high-sample-rate discrete-time approximation to
the original continuous-time transfer function
H(z) ≈H (s)|s= 2
T1
z−1
z+1 ,
where T1 is the same emulation sampling period as before.19
We now recognize that the discrete Fourier transform (DFT) of a
sequence is related to its z-transform via the relationship
H[ f] = H(z)
+++z=exp(j2π f /N) = H (s)|
s= 2
T1
@
ej2π f /N−1
ej2π f /N+1
A

198
battery management systems: volume i, battery modeling
= H (s)|s= 2j
T1 tan(π f /N) ,
0 ≤f < N,
where N is the number of points chosen for the underlying sequence
and is usually chosen to be a power of 2 for efﬁcient computations.
The inverse DFT of H[ f] gives h(nT1), which is the approximation
of the continuous-time impulse response at the emulation sampling
period, T1
h(nT1) = 1
N
N−1
∑
f =0
H[ f]ej2π f n/N,
which is indexed from n = 0 to n = N −1.
We can now do the complete conversion from H(s) to a state-space
model. We note, though, that while the ﬁnal discrete-time state-space
D matrix is the ﬁrst Markov parameter, it can often be better found
numerically by using the initial value theorem,
D = g0 = h[0] = lim
s→∞H(s).
5.5
Step-by-step examples of the DRA
In this section, we look at three examples to illustrate the operation
of the DRA. The ﬁrst two are rational-polynomial transfer functions,
which we use because we can calculate the exact solution using other
methods. We can then compare the exact solutions to the approx-
imate solutions obtained by the DRA. The third does not have a
closed-form solution, but we can use a 1D parabolic-elliptic partial-
differential-equation solver to ﬁnd an accurate near-exact solution
against which to compare the DRA solution. We ﬁnd excellent agree-
ment between the exact solutions and DRA solutions in all cases.
5.5.1
Example 1: Rational-polynomial transfer function
We ﬁrst apply the DRA method to a simple second-order system:
H1(s) = s2 + 20s + 80
s2 + 2s + 8 .
We require a discrete-time realization with a sampling period of
Ts = 0.1 seconds.
To begin, we compute the Bode plot for H1(s) to estimate the
system bandwidth, to select an appropriate fast sampling rate T1. In
MATLAB, we use the following code:
omega = logspace(-1,3,100);
% create freq. axis in rad/sec
s = 1j*omega;
% create s = j*omega
H = (s.^2+20*s+80)./(s.^2+2*s+8);
% compute cplx. freq. response
semilogx(omega,20*log10(abs(H)));
% display the magnitude response

5. state-space models and the discrete-time realization algorithm
199
10
−1
10
0
10
1
10
2
10
3
0
5
10
15
20
25
Magnitude (dB)
Bode magnitude plot for H1(s)
Frequency (rad s−1)
Figure 5.7: Bode magnitude plot for
H1(s).
0
1
2
3
4
5
0
10
20
Time (s)
Response
 
 
Exact
Approximate
Continuous-time impulse responses
Figure 5.8: Exact and approximate (via
DRA Step 1) continuous-time impulse
responses for H1(s).
0
1
2
3
4
5
0
5
10
15
Time (s)
Response
 
 
Exact
Approximate
Continuous-time step responses
Figure 5.9: Exact and approximate
(via DRA Step 2) continuous-time step
responses for H1(s).
The magnitude response of H1(s) is shown in Fig. 5.7. We note that
the bandwidth is on the order of 3 rad s−1, or about 0.5 Hz.
step 1: We select the high-rate sampling frequency F1 = 256 Hz,
which is (much) greater than 20 times the system bandwidth. The
following code samples the transfer function at discrete frequencies,
and the inverse DFT yields an approximate continuous-time impulse
response.
F1 = 256; T1 = 1/F1;
% Interp. freq. of 256 Hz
minTlen = 6.5;
% min. h(t) length in sec.
N = 2^(ceil(log2(minTlen*F1)));
% # of samples at rate F1
f = 0:N-1;
% normalized freq. vector
s = (2j/T1)*tan(pi*f/N);
% substitution to get Hd[f]
Hd = (s.^2+20*s+80)./(s.^2+2*s+8);
% Hd[f]
hd = real(ifft(Hd)) * F1;
% approximation to h(t)
td = T1*(0:N-1);
% time vector for h(t)
plot(td,hd,'bx','markersize',8); hold on % plot h(t)
H1 = tf([1 20 80],[1 2 8]);
% true transfer function
[himpTrue,timpTrue] = impulse(H1,5);
% true impulse response
plot(timpTrue,himpTrue,'r'); axis([0 5 -8 23]); % plot on top
Fig. 5.8 compares the approximate continuous-time impulse response
computed via the inverse DFT to the exact continuous-time impulse
response of H1(s). The two solutions are coincident, showing that the
DFT method gives a good approximation to the impulse response.
step 2: The approximation to the continuous-time step response is
found by doing a cumulative summation of the impulse response.
This is accomplished via the MATLAB code:
hstep = T1*cumsum(hd);
% h_s(t)
plot(td,hstep,'bx','markersize',8); hold on
% plot h_s(t)
[hstepTrue,tstepTrue] = step(H1,5);
% true step resp.
plot(tstepTrue,hstepTrue,'r'); axis([0 5 0 15]);
% plot on top
Fig. 5.9 shows a comparison between the DRA-approximated step
response and the true step response of the system. Again, we see
excellent agreement between the two signals.
step 3: We now resample the continuous-time approximate step re-
sponse at the ﬁnal sample rate Ts and compute the discrete-time
pulse response as hstep[k] −hstep[k −1]. The MATLAB code to accom-
plish this is:
Ts = 0.1; tdisc = 0:Ts:6.5;
% final time vector
hdisc = [0 diff(interp1(td,hstep,tdisc))];
% h[k]
stem(tdisc,hdisc,'filled'); hold on

200
battery management systems: volume i, battery modeling
0
1
2
3
4
5
0
1
2
Time (s)
Response
 
 
Exact
Approximate
Discrete-time unit-pulse responses
Figure 5.10: Exact and approximate (via
DRA Step 3) discrete-time unit-pulse
responses for H1(s).
0
10
20
30
−15
−10
−5
0
Hankel matrix singular values
n
log10(σn)
Figure 5.11: The 32 singular values of
H32,32 for H1(s).
20 For this example, we know that
the system order is two, so why are
the singular values for n > 2 not
equal to zero as they were for the
Fibonacci example? There are two
reasons: (1) we are approximating the
discrete-time unit-pulse response using
the DFT method, and some noise is
introduced in this approximation, and
(2) numeric precision is not exact, so
we would expect some “noise ﬂoor” in
the computed singular values simply
due to roundoff error in ﬂoating-point
mathematics. Here, reason 1 is most
likely the dominant effect, but reason 2
can become more signiﬁcant when the
size of the Hankel matrix is large.
[himpDiscTrue,timpDiscTrue] = impulse(c2d(H1,Ts),5);
% next line scales IMPULSE in new MATLAB to give unit-pulse resp.
himpDiscTrue = Ts*himpDiscTrue;
plot(timpDiscTrue,himpDiscTrue,'r.','markersize',8);
axis([-0.01 5 -0.8 2.3]);
Note that in older versions of MATLAB the impulse command com-
putes unit-pulse responses for discrete-time systems; for newer ver-
sions of MATLAB, it attempts to approximate a continuous-time
impulse response in discrete time, and its output must be scaled by
the sampling period Ts to achieve the true unit-pulse response.
Fig. 5.10 shows the comparison between the unit-pulse responses
produced by the DRA approximate method and MATLAB’s exact
method. Again, there is excellent agreement, except at the single
point t = 0. This is often the case because of some properties of the
inverse DFT, but it causes no problems since the unit-pulse response
value at t = 0 is not used by the Ho–Kalman algorithm in Step 3,
and the D matrix (which is equal to the unit-pulse response value at
t = 0) is computed analytically from H1(s) as
D = g0 = lim
s→∞H1(s) = 1.
step 4: The deterministic Ho–Kalman algorithm is used to ﬁnd a
state-space realization from the approximate discrete-time unit-pulse
response from Step 2. Sixty-ﬁve points from the discrete-time unit-
pulse response are used, which allows a maximum Hankel matrix of
32 × 32 (allowing for the need to shift one Hankel matrix up by one
row). That is, we form H32,32 and H↑
33,32, and then compute and plot
the singular values of the Hankel matrix H32,32. Fig. 5.11 shows the
singular values on a logarithmic scale, and the following MATLAB
code does the computation.
bigHankel = hankel(hdisc(2:66));
% don't forget to omit h(0) term!
% for this example, keep only 32x32 portion
Hankel = bigHankel(1:32,1:32);
HankelUp = bigHankel(2:33,1:32);
% shifted Hankel matrix
[U, S, V] = svd(Hankel);
% compute singular values
plot(log10(diag(S)),'bx','markersize',8); axis([0 33 -20 5]);
The SVD of the Hankel matrix gives insight into the order of the
system. We see from the ﬁgure that the ﬁrst two singular values are
more than three orders of magnitude greater than the third singular
value, so we select a reduced-order model dimension n = 2.20
n = 2;
% select via singular values
Us = U(:,1:n);
% Compute extended observability, controllability
Ss = S(1:n,1:n); % matrices, sized to the order for the system

5. state-space models and the discrete-time realization algorithm
201
0
1
2
3
4
5
0
1
2
Time (s)
Response
 
 
Exact
Approximate
Discrete-time unit-pulse responses
Figure 5.12: Exact and ﬁnal-model
approximate (via DRA Step 4) discrete-
time unit-pulse responses for H1(s).
Vs = V(:,1:n);
% inferred by the singular values.
Ok = Us*sqrtm(Ss); Cl = sqrtm(Ss)*Vs';
Ahat = (Ok\HankelUp)/Cl;
% calculate A from Ok and Cl
Bhat = Cl(1:n,1); Chat = Ok(1,1:n);
% calculate B and C
Dhat = 1;
% calculated manually
sysDRA = ss(Ahat,Bhat,Chat,Dhat,Ts);
% final DRA state-space sys.
Truncating to the ﬁrst two states only, the Ho–Kalman algorithm
gives a state-space realization with the following estimated NA, NB, and
NC matrices
NA =
:
0.8529
−0.2375
0.2375
0.8938
;
,
NB =
:
−1.53
0.6254
;
,
NC =
<
−1.53
−0.6254
=
.
An estimate of the D matrix is found from the initial value theorem
and, for this example, ND = lims→∞H1(s) = [1]. We verify this
by examining the high-frequency magnitude response of H1(s) in
Fig. 5.7, which is 0 dB, or 1 in linear units.
We validate the DRA-produced model by looking at the true
discrete-time unit-pulse response and the ﬁnal DRA-model unit-
pulse response, as plotted in Fig. 5.12 using the following code:
% next line scales IMPULSE in new MATLAB to give unit-pulse resp.
[himpDRA,timpDRA] = impulse(sysDRA,5); himpDRA = Ts*himpDRA;
stem(timpDRA,himpDRA,'filled'); hold on
plot(timpDiscTrue,himpDiscTrue,'r.','markersize',8);
axis([-0.01 5 -0.8 2.3]);
The ﬁgure shows that the ﬁnal DRA model unit-pulse response
agrees very well with the exact unit-pulse response (note that h[0] has
been corrected by the explicit calculation of the ND matrix in Step 4).
Because the unit-pulse responses agree very well, the response of
the reduced-order model to any input signal u[k] will also agree well
with the exact response.
5.5.2
Dealing with one or more poles in H(s) at the origin
The DRA does not work, without modiﬁcation, for unstable systems.
The problem is in Step 1: the continuous-time impulse response must
decay to (very close to) zero in the period NT1, or else the inverse
DFT will seriously alias its approximation to the impulse response.
So, an unstable system must be stabilized by removal of the unstable
dynamics prior to Step 1; these unstable dynamics can be added back
into the ﬁnal model.
Here, we consider a common case where H(s) has a pole at s = 0.
This corresponds to integration dynamics, which appear in a number

202
battery management systems: volume i, battery modeling
10
−2
10
−1
10
0
10
1
−60
−40
−20
0
20
40
Magnitude (dB)
Bode magnitude plot for H2(s)
Frequency (rad s−1)
Figure 5.13: Bode magnitude plot for
H2(s).
of our battery transfer functions. We can separate the stable part of
H(s) from the integration dynamics by writing
H(s) = H∗(s) + res0
s .
We can ﬁnd res0 as res0 = lims→0 sH(s). This limit can often be found
analytically (we can do so for all our transfer functions, as we have
closed-form representations of them) or numerically by substituting a
very small value of s in sH(s).
Then, H∗(s) no longer has the pole at the origin, and we can exe-
cute the DRA using it as the starting transfer function. Afterward, we
take the state-space system deﬁned by NA, NB, NC, and ND from the DRA
and augment it with dynamics that describe the integration pole that
was previously removed.
The discrete-time equivalent to an integrator can be implemented
as
xi[k + 1] = xi[k] + Tsu[k].
We combine this with the DRA-produced state-space form
:
x[k + 1]
xi[k + 1]
;
#
$%
&
xaug[k+1]
=
:
NA
0
0
1
;
#
$%
&
NAaug
:
x[k]
xi[k]
;
#
$%
&
xaug[k]
+
:
NB
Ts
;
# $% &
NBaug
u[k]
y[k] =
<
NC
res0
=
#
$%
&
NCaug
:
x[k]
xi[k]
;
+ Du[k]
where the dotted lines delineate boundaries between block sub-
matrices of the overall augmented state-space matrices NAaug, NBaug,
and NCaug.
5.5.3
Example 2: Rational-polynomial transfer function with pole at ori-
gin
We illustrate this process with a second example. Here, we consider
the continuous-time transfer function
H2(s) = 1
s
.
1
s2 + 6s + 2
/
.
This example is very similar to the ﬁrst one—so we include MAT-
LAB code only for the steps that are signiﬁcantly different—but is
dissimilar in the sense that it has an unstable integrator pole at s = 0.
Fig. 5.13 shows the Bode magnitude plot for H2(s), where the inte-
gration dynamics can be observed in that the low-frequency response
not converge to a constant value.

5. state-space models and the discrete-time realization algorithm
203
10
−2
10
−1
10
0
10
1
−30
−20
−10
0
Magnitude (dB)
Bode magnitude plot for H∗
2(s)
Frequency (rad s−1)
Figure 5.14: Bode magnitude plot for
H∗
2(s).
21 If we use the ﬁrst method, we will
ﬁnd that the ﬁrst element in the vector
Hd will be NaN (not-a-number) due to
the division by zero when s = 0. This
has to be speciﬁcally corrected by the
statement Hd(1) = -6/64.
0
5
10
15
20
25
−0.4
−0.2
0
Time (s)
Response
 
 
Exact
Approximate
Continuous-time impulse responses
Figure 5.15: Exact and approximate (via
DRA Step 1) continuous-time impulse
responses for H∗
2(s).
0
5
10
15
20
25
−1.5
−1
−0.5
0
Time (s)
Response  
 
 
Exact
Approximate
Continuous-time step responses
Figure 5.16: Exact and approximate (via
DRA Step 2) continuous-time impulse
responses for H∗
2(s).
We desire to create a discrete-time state-space model with a ﬁnal
sampling period of Ts = 0.5 s. However, prior to DRA Step 1, we
must remove the pole at the origin. This is accomplished by ﬁrst
calculating the residue for this pole. In this example, the residue can
be computed analytically as
res0 = lim
s→0 sH(s) = 0.5.
The reduced transfer function H∗
2(s) with the pole at the origin re-
moved is
H∗
2(s) = 1
s
.
1
s2 + 6s + 2
/
−0.5
s .
(5.13)
Fig. 5.14 shows the Bode magnitude response of H∗
2(s), where the
low-frequency response shows that the integrator has been success-
fully removed.
step 1: H∗
2(s) is sampled at 256 Hz, which is (much) more than 50
times greater than the system bandwidth. When performing this
sampling, we have a choice. We could implement it as Eq. (5.13) or
via analytically reducing it as
H∗
2(s) = 1
s
.
1
s2 + 6s + 2
/
−0.5
s
.s2 + 6s + 2
s2 + 6s + 2
/
= −0.5
s
.
s2 + 6s
s2 + 6s + 2
/
= −0.5
.
s + 6
s2 + 6s + 2
/
,
(5.14)
and then implementing Eq. (5.14). That is, in DRA Step 1, we could
implement either21
Hd = 1./(s.^3+6*s.^2+2*s) - 0.5./s;
% Hd[f]
Hd(1) = -6/4;
% analytic solution
where lims→0 H∗
2(s) = −6/64, or
Hd = -0.5*(s+6)./(s.^2+6*s+2);
% Hd[f]
Fig. 5.15 compares the approximate continuous-time impulse
response computed via the inverse DFT to the exact continuous-
time impulse response of H∗
2(s). The two solutions are coincident,
except at time t = 0, showing that the DFT method gives a good
approximation to the impulse response. The spurious single point
(which is a property of the DFT when there is a discontinuity in
a response) is not of great concern, since the integration in Step 2
eliminates this deviation.
step 2: The approximation to the continuous-time step response of
H∗
2(s) is calculated as in the ﬁrst example and plotted in Fig. 5.16.

204
battery management systems: volume i, battery modeling
0
5
10
15
20
25
−0.2
−0.1
0
Time (s)
 
 
Exact
Approximate
Discrete-time unit-pulse responses
Response
Figure 5.17: Exact and approximate (via
DRA Step 3) discrete-time unit-pulse
responses for H∗
2(s).
0
10
20
30
−20
−15
−10
−5
0 Hankel matrix singular values
n
log10(σn)
Figure 5.18: The 32 singular values of
H32,32 for H∗
2(s).
0
5
10
15
20
0
0.1
0.2
Time (s)
 
 
Exact
Approximate
Discrete-time unit-pulse responses
Response
Figure 5.19: Exact and ﬁnal-model
approximate (via DRA Step 4) discrete-
time unit-pulse responses for H2(s).
step 3: This step response is sampled at Ts = 0.1 seconds and dif-
ferenced to yield the discrete-time unit-pulse response, plotted in
Fig. 5.17.
step 4: The system Hankel matrix is generated from the discrete-time
unit-pulse response found in Step 3. Sixty-four discrete time points
are used, resulting in a 32×32 Hankel matrix.
Fig. 5.18 depicts the 32 singular values of the system Hankel
matrix. The ﬁrst two singular values are two orders of magnitude
greater than the third, indicating that H∗
2(s) is a second-order system.
The Ho–Kalman algorithm generates the NA, NB, and NC matrices
after truncating all but the ﬁrst two states. We ﬁnd that
NA =
:
0.8394
0.03663
−0.03663
0.05771
;
,
NB =
:
0.4913
−0.05112
;
,
NC =
<
−0.4913
0.05112
=
.
In this example, we also compute ND = lims→∞H∗
2(s) = 0, which can
also be quite easily seen in the high-frequency response of Fig. 5.14.
This state-space representation for H∗
2(s) is augmented to include
the pole at the origin. This is accomplished using the MATLAB code
Aaug = [Ahat zeros(n,1); 1 zeros(1,n)];
Baug = [Bhat; Ts];
Caug = [Chat, res0];
sysDRA = ss(Aaug,Baug,Caug,Dhat,Ts)
% final DRA state-space sys.
The resulting discrete-time realization of H2(s) is
NAaug =
⎡
⎢⎣
0.8394
0.03663
0
−0.03663
0.05771
0
0
0
1
⎤
⎥⎦,
NBaug =
⎡
⎢⎣
0.4913
0.05112
0.5
⎤
⎥⎦,
NCaug =
<
−0.4913
0.05112
0.5
=
,
ND = [0].
Fig. 5.19 shows a close comparison of the unit-pulse response found
from the DRA-produced model and the exact solution.
5.5.4
Example 3: Transcendental transfer function
In the ﬁrst two examples, we approximated rational-polynomial
transfer functions using the DRA method to illustrate its behavior.
For those examples, the order of the system was known a priori,
and the exact answer could be calculated analytically. We will now
demonstrate the DRA with an inﬁnite-order distributed-parameter
system, for which the exact answer cannot be calculated analytically,
but for which the DRA works just as well.
Speciﬁcally we model the Jacobsen–West transfer function of
lithium diffusion in a single particle, Eq. (5.9). This transfer function

5. state-space models and the discrete-time realization algorithm
205
10
−5
10
−3
10
−1
10
1
10
3
100
150
200
Magnitude (dB)
Bode magnitude plot for H3(s)
Frequency (rad s−1)
Figure 5.20: Bode magnitude plot for
H3(s).
10
−5
10
−3
10
−1
10
1
10
3
90
100
110
120
130
Magnitude (dB)
Bode magnitude plot for H∗
3(s)
Frequency (rad s−1)
Figure 5.21: Bode magnitude plot for
H∗
3(s).
has a pole at the origin, which can be removed analytically, as given
by Eq. (5.10). We repeat these equations here: the Jacobsen–West
transfer function is
H3(s) =
KCs,e(s)
J(s)
= Rs
Ds
@
1
1 −Rs
√
s/Ds coth(Rs
√
s/Ds)
A
,
and the integrator-removed transfer function is
H∗
3(s) = ∆KCs,e(s)
J(s)
=
KCs,e(s)
J(s)
−
KCs,avg(s)
J(s)
=
sR2s
Ds + 3 −3Rs
M
s
Ds coth
'
Rs
M
s
Ds
(
sRs
'
1 −Rs
M
s
Ds coth
'
Rs
M
s
Ds
(( ,
where
KCs,avg(s)
J(s)
= −res0
s
=
−3/Rs
s
.
Parameter values for the transfer functions used in this example are
listed in Table 5.1, from which we can compute that res0 = 3 × 105.
Parameter name
Interpretation
Value
Ts
Sampling period
1 s
Rs
Particle radius
8 × 10−6 m
Ds
Diffusivity
10−12 m2 s−1
cs,e(0)
Initial lithium concentration
10,000 mol m−3
Table 5.1: Parameter values used in
example 3.
The Bode magnitude plot of H3(s) is shown in Fig. 5.20. We see
that this transfer function has an integrator (pole at s = 0) by the low-
frequency behavior that does not converge to a ﬂat line, but rather
to a slope of −20 dB per decade. We also see curious high-frequency
behavior, where the slope is −10 dB per decade. This slope cannot
be implemented by a ﬁnite number of poles (whose slopes would all
be −20 dB per decade) or zeros (whose slopes would all be +20 dB
per decade), but instead by some combination of poles and zeros
that add together in a stair-step method to approximate the slope of
−10 dB per decade.
This slope of −10 dB per decade is characteristic of distributed-
parameter systems such as diffusion equations. We will see a num-
ber of other examples of this in the next chapter, when we develop
transfer-function models of lithium-ion battery cells.
The Bode magnitude plot of H∗
3(s) is shown in Fig. 5.21. We see
that the integrator has been successfully removed (but that the high-
frequency behavior is still characterized by a slope of −10 dB per
decade).

206
battery management systems: volume i, battery modeling
0
2
4
6
8
10
−6
−4
−2
0
Time (s)
Continuous-time impulse response
Response (×106)
Figure 5.22: DRA-approximated im-
pulse response for H∗
3(s).
0
10
20
30
40
50
−1.5
−1
−0.5
0
Time (s)
Continuous-time step response
Response (×106)
Figure 5.23: DRA-approximated step
response for H∗
3(s).
0
5
10
15
20
25
−0.8
−0.6
−0.4
−0.2
0
Time (s)
Discrete-time unit-pulse response
Response (×106)
Figure 5.24: DRA-approximated unit-
pulse response for H∗
3(s).
step 1: In the ﬁrst DRA step, we choose the fast sample rate to be
256 Hz, and we sample H∗
3(s) to give an approximate continuous-
time impulse response of length 256 s. The frequency vector for H∗
3(s)
can be calculated using Eq. (5.9) as
beta = Rs*sqrt(s/Ds);
Hd = (Rs/Ds)*(1./(1-beta.*coth(beta))) + (3/Rs)./s;
Hd(1) = -Rs/(5*Ds); % analytic solution
where MATLAB numerically removes the integrator pole, or using
Eq. (5.10)
beta = Rs*sqrt(s/Ds);
Hd = (beta.^2+3-3*beta.*coth(beta))./(s.*Rs.*(1-beta.*coth(beta)));
Hd(1) = -Rs/(5*Ds); % analytic solution
Note that both computations of Hd initially produce NaN for s = 0
due to numeric attempts to evaluate zero divided by zero. This entry
must be manually replaced by a value computed analytically
lim
s→0 H∗
3(s) = lim
s→0
sR2s
Ds + 3 −3Rs
M
s
Ds coth
'
Rs
M
s
Ds
(
sRs
'
1 −Rs
M
s
Ds coth
'
Rs
M
s
Ds
(( = −Rs
5Ds
.
This limit is quite difﬁcult to ﬁnd by hand, as a direct computation
returns 0/0. We must use l’Hôpital’s rule repeatedly (in this case, ﬁve
times) until an answer is reached. When using transcendental trans-
fer functions, we recommend computer tools such as Mathematica for
symbolic manipulation.
This approximate continuous-time impulse response is shown in
Fig. 5.22. Note that since there is no way to solve for this impulse
response exactly, we can show only the DRA-approximated response.
step 2: The approximate continuous-time step response is calcu-
lated by performing a cumulative sum of the impulse response of
Step 1. Fig. 5.23 shows the approximation of the continuous-time step
response. Again, there is no known exact solution to the continuous-
time step response for this system against which to compare this
result.
step 3: The approximate continuous-time step response is sampled at
Ts = 1 second and differenced to produce the discrete-time unit-pulse
response, shown in Fig. 5.24.
step 4: The Hankel matrix is formed, and its singular values are
plotted in Fig. 5.25. H∗
3(s) represents a distributed-parameter system
that actually has an inﬁnite number of poles. However, we see from
this plot that only a few of these poles are signiﬁcant to the solution.
In particular, we choose to use a reduced-order model dimension

5. state-space models and the discrete-time realization algorithm
207
0
50
100
−10
−5
0
5
Hankel matrix singular values
n
log10(σn)
Figure 5.25: The 128 singular values of
H128,128 for H∗
3(s).
p = 2 in the results we present here. This demonstrates a tradeoff
between the complexity and accuracy of the solution.
The Ho–Kalman algorithm generates the NA, NB, and NC matrices to
approximate H∗
3(s) after truncating all but the ﬁrst two states. We
ﬁnd that
NA =
:
0.3808
0.3073
0.3073
0.4091
;
,
NB =
:
909.4
−145.3
;
,
NC =
<
−909.4
145.3
=
.
In this example, we also compute ND = lims→∞H∗
3(s) = 0, which can
also be quite easily seen in the high-frequency response of Fig. 5.21.
This state-space realization is augmented with the integrator state
to give the ﬁnal third-order state-space model of the diffusion equa-
tion H3(s). The ﬁnal realization is given by
NAaug =
⎡
⎢⎣
0.3808
0.3073
0
0.3073
0.4091
0
0
0
1
⎤
⎥⎦,
NBaug =
⎡
⎢⎣
909.4
−145.3
1
⎤
⎥⎦,
NCaug =
<
−909.4
145.3
−3.75 × 105 =
,
ND = [0].
We demonstrate the accuracy of the DRA-produced model by
simulating a 10-second discharge pulse where the surface lithium
ﬂux (leaving the particle) was j = 1 × 10−5 mol m−2 s−1, followed by
a 10-second rest. The augmented state-space model was simulated
with this input to produce ˜cs,e[k], and cs,e[k] was computed as cs,e[k] =
˜cs,e[k] + cs,0. The following MATLAB code was used:
cs0 = 10000;
uk = 1e-5*[ones(1,10),zeros(1,10)];
[cseTilde,tk] = lsim(sysDRA,uk);
cse = cseTilde + cs0;
We compare this approximate result against a “true” result pro-
duced by simulating the differential equation using MATLAB’s 1D
parabolic-elliptic partial differential equation solver. The following
code was used:
function [cse,t] = simCsePDE
dr = 0.1e-6; % Radial resolution = 0.1 micro-meter
dt = 0.001;
% Time step in simulation, s
Tfinal = 20; % Length of simulation, s
Rp = 8e-6;
% Radius of particle = 10 micro-meters
Ds = 1e-12;
% Solid diffusivity, m^2/s
j = 1e-5;
% mol/m^2/s
x = 0:dr:Rp;
% locations for solution
t = 0:dt:Tfinal; % time steps for solution
options = odeset('RelTol',1e-8,'AbsTol',1e-10);
sol = pdepe(2,@csefun,@cseic,@csebc,x,t,options);

208
battery management systems: volume i, battery modeling
0
5
10
15
20
9,940
9,960
9,980
10,000
Time (s)
 
 
Exact PDE solution
DRA model with order=3
Concentration (mol m−3)
Surface concentration cs,e(t)
Figure 5.26: Comparing reduced-
order DRA ﬁnal model to exact PDE
simulation.
cse = sol(:,end,1);
function[c,f,s] = csefun(~,~,~,DuDx)
c = 1/Ds; f = DuDx; s = 0;
end
function u0 = cseic(~,~)
c0 = 10000; u0 = c0;
end
function[pl,ql,pr,qr] = csebc(~,~,~,~,t)
pl = 0; ql = 1; qr = Ds; pr = 0;
if t<Tfinal/2, pr=j; end
end
end
The code comprises nested functions, where the main function ini-
tializes variables and calls MATLAB’s solver with pointers (function
handles) to nested helper functions: csefun implements the param-
eter values of the PDE; cseic implements the initial conditions; and
csebc implements the boundary conditions. Note that we achieve
good results with the PDE solver only if a ﬁne time step is used: here,
we have used a 1 ms step size, which makes the PDE solver execute
much more slowly than the DRA-produced model.
Fig. 5.26 compares the exact PDE solution with the DRA-model
solution. We see that the third-order DRA model results agree very
closely with the PDE solution at the sampling points. Somewhat
greater accuracy could be obtained from the DRA model by retain-
ing more singular values from the Hankel matrix, but at the cost of
higher computational complexity of the ﬁnal model.
5.6
Eigensystem realization algorithm (ERA)
We have seen that the DRA is a very effective way to convert a
continuous-time transfer function into an approximate reduced-order
discrete-time state-space model. With some practice in selecting T1,
N, Ts, and the number of singular values retained by the Ho–Kalman
method, the discrete-time model can produce results indistinguish-
able from the original continuous-time counterpart.
In some situations, however, we ﬁnd that the required ﬁnal sam-
ple period Ts is quite small relative to the duration of the impulse
response of the system being modeled. This requires that T1 be
similarly small for the interpolation in Step 3 to be accurate, and
it requires N to be large to capture the duration of the impulse re-
sponse. The effect of these is that the Hankel matrices produced in
Step 4 can be very large, and the process of ﬁnding the singular val-
ues of the unshifted Hankel matrix can become intractable.

5. state-space models and the discrete-time realization algorithm
209
22 Juang, J.N., and Pappa, R.S., “Eigen-
system Realization Algorithm for
Modal Parameter Identiﬁcation and
Model Reduction,” Journal of Guid-
ance, Control, and Dynamics, 8(5), 1985,
pp. 620–27.
This problem can be alleviated, in part, by using the svds com-
mand in MATLAB instead of the svd command to ﬁnd the singular
values of the Hankel matrix. While svd ﬁnds all of the singular val-
ues of the matrix (most of which we end up discarding), svds ﬁnds
only the n most signiﬁcant singular values, where n is a parameter
speciﬁed by the user. This speeds up the operation greatly when an
idea of the maximum model size that might be of interest is known a
priori.
This modiﬁcation may still not be enough; that is, MATLAB may
run out of memory when computing the singular values, or the com-
putation may take too long to be tractable.
The solution to this problem can be found in an extension to the
Ho–Kalman method, ﬁrst applied to the identiﬁcation of the dynam-
ics of ﬂexible structures by Juang and Pappa.22 In their application,
they wished to identify a realization (NA, NB, NC, and ND) and then to
determine a continuous-time model of the modes (eigenvalues of the
continuous-time NA matrix) from that. They called their algorithm
the Eigensystem Realization Algorithm (ERA) because it results in an
eigensystem (i.e., a modal description of the system). Here, we are
interested in only the ﬁrst part of the algorithm, the realization part,
but we still refer to only the ﬁrst part as the ERA.
The major feature of the ERA that is of interest to us is that it is
able to deal with faulty sensors or incomplete unit-pulse-response
data. In the original application, the authors were concerned with
cases where the measured unit-pulse response was corrupted by sat-
uration of the sensors, data dropout from a communications link, an
intermittent bit failure, or an external noise source that temporar-
ily affected the data measured by the system. Their ERA still uses a
Hankel-matrix approach that bears a great deal of similarity to Ho–
Kalman, but it allows removing rows and columns from the Hankel
matrix that correspond to “bad” data. In our application, we don’t
need to remove corrupted unit-pulse-response data; however, the
ERA allows us to remove from the Hankel matrices long segments
of the unit-pulse response that don’t contain much information, thus
greatly reducing the size of the matrices and making the computa-
tions possible.
To deﬁne the ERA, we begin by forming an r × s generalized
Hankel matrix
Hr,s[k −1] =
⎡
⎢⎢⎢⎢⎣
gk
gk+t1
· · ·
gk+ts−1
gj1+k
gj1+k+t1
· · ·
gj1+k+ts−1
...
...
...
gjr−1+k
gjr−1+k+t1
· · ·
gjr−1+k+ts−1
⎤
⎥⎥⎥⎥⎦
rp×ms
where jk (k = 1, . . . , r −1) and tk (k = 1, . . . , s −1) are arbitrary

210
battery management systems: volume i, battery modeling
integers. Note that this is the same as the Hankel matrix used by the
Ho–Kalman method, except that we have deleted all block rows and
all block columns that have “bad” data in them. We will assume that
Hr,s[0] (which starts with g1) and Hr,s[1] (which starts with g2) are
available.
We now deﬁne generalized controllability and observability matrices
Cs =
<
B,
At1B,
· · · ,
Ats−1B
=
n×ms ,
Or =
⎡
⎢⎢⎢⎢⎣
C
CAj1
...
CAjr−1
⎤
⎥⎥⎥⎥⎦
rp×n
.
With these deﬁnitions, we note that Hr,s[k] = OrAkCs. In particular,
Hr,s[0] = OrCs and Hr,s[1] = OrACs.
The method for ﬁnding a realization is similar to Ho–Kalman. We
ﬁst take the compact SVD of Hr,s[0]:
Hr,s[0] = UΣV T,
where U ∈Rrp×n, V ∈Rms×n, and Σ = diag(σ1, . . . , σn). As with
Ho–Kalman, we set Or = UΣ1/2 and Cs = Σ1/2V T.
We then set NB to be the left block column of Cs, NC to be the top
block row of Or, and ND = g0. Finally, we set NA = O†
r Hr,s[1]C†
s .
As an example consider again the Fibonacci sequence from page 193.
This time, the pulse-response experiment yields the following out-
puts
y = (0, 1, 1, 2, 32.12, 724.1, 87.4, 13, 21, 34, 55, 89, 144, 233, 377, 610 · · ·)
The ﬂoat-valued quantities in entries y4, y5, y6 are suspicious (all
others are integers) and thus will be discarded (label them ∗).
y = (0, 1, 1, 2, ∗, ∗, ∗, 13, 21, 34, 55, 89, 144, 233, 377, 610 · · ·)
We can immediately set ND = g0 = 0. We can then form a 7 × 9
Hankel matrix from gk, k > 0:
H7,9 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
1
2
∗
∗
∗
13
21
34
1
2
∗
∗
∗
13
21
34
55
2
∗
∗
∗
13
21
34
55
89
∗
∗
∗
13
21
34
55
89
144
∗
∗
13
21
34
55
89
144
233
∗
13
21
34
55
89
144
233
377
13
21
34
55
89
144
233
377
610
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
To remove the suspect data, we could delete rows 2 through 6 and
columns 3 through 6. This corresponds to index sets: jk = {6, 7, 8}
and tk = {1, 6, 7}.

5. state-space models and the discrete-time realization algorithm
211
23 Note that H↑
r+1,s[0] ̸= Hr,s[1], which
is why we needed to change how we
denote of the Hankel matrix from that
used when describing the Ho–Kalman
method.
This deletion leaves us with 4 × 4 Hankel matrices23
Hr,s[0] =
⎡
⎢⎢⎢⎣
g1
g2
g7
g8
g7
g8
g13
g14
g8
g9
g14
g15
g9
g10
g15
g16
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
1
1
13
21
13
21
233
377
21
34
377
610
34
55
610
987
⎤
⎥⎥⎥⎦
Hr,s[1] =
⎡
⎢⎢⎢⎣
g2
g3
g8
g9
g8
g9
g14
g15
g9
g10
g15
g16
g10
g11
g16
g17
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
1
2
21
34
21
34
377
610
34
55
610
987
55
89
987
1,597
⎤
⎥⎥⎥⎦.
The following MATLAB code also produces these matrices
% Store the Markov parameters
y = [0,1,1,2,32.12,724.1,87.4,13,21,34,55,89,144,233,377,610,987,1597];
% Form modified Hankel matrices.
% Note:
Do not include "zero-th" parameter (first element of y).
%
Corresponds to the matrix D.
j = [0 6 7 8]; % Pad "j" and "t" with "0" at front to make loop
t = [0 1 6 7]; % that makes Hankel matrices easier to code
H0 = zeros(length(j),length(t)); H1 = H0;
for ind1 = 1:length(t)
for ind2 = 1:length(j)
H0(ind2,ind1) = y(t(ind1)+j(ind2)+2);
H1(ind2,ind1) = y(t(ind1)+j(ind2)+3);
end
end
Once the modiﬁed Hankel matrices are formed, they are processed
as follows:
% Step 1: Compute singular values of Hankel matrix
[U,S,V] = svd(H0);
% [Identify system order off-line as n = 2 based on values of S]
n = 2;
% Step 2: Compute extended observability and controllability matrices,
% sized to the order for the system inferred by the singular values.
Us = U(:,1:n); Ss = S(1:n,1:n); Vs = V(:,1:n);
Or = Us*sqrtm(Ss); Cs = sqrtm(Ss)*Vs';
% Step 3:
Identify the system assuming p = m
= 1 (SISO), using the
% shifted Hankel matrix
Ahat = (Or\H1)/Cs; Bhat = Cs(:,1); Chat = Or(1,:); Dhat = y(1);
When this code is executed, the SVD of Hr,s[0] yields
σ1 = 1,436.6
σ2 = 0.326
σi = 0, i ≥3,
which indicates that n = 2. Note that the split of SVD magnitude has
dramatically changed.

212
battery management systems: volume i, battery modeling
1
2
3
4
5
6
7
8
0
5
10
15
20
25
Time step k
Output
Unit-pulse responses
 
 
True system
Estimated system
Figure 5.27: Fibonacci sequence exam-
ple using ERA algorithm.
We now extract the two left columns of U and V
U =
⎡
⎢⎢⎢⎣
−0.0172
0.9976
−0.3090
0.0450
−0.4999
−0.0516
−0.8089
−0.0066
⎤
⎥⎥⎥⎦,
V =
⎡
⎢⎢⎢⎣
−0.0293
0.8493
−0.0473
−0.5249
−0.5249
0.0473
−0.8493
−0.0293
⎤
⎥⎥⎥⎦.
Again, note that U no longer equals V.
The generalized observability and controllability matrices are
Or = UΣ1/2 =
⎡
⎢⎢⎢⎣
−0.6526
0.5696
−11.7109
0.0257
−18.9487
−0.0294
−30.6596
−0.0037
⎤
⎥⎥⎥⎦
Cs = Σ1/2V T =
:
−1.1090
−1.7939
−19.8959
−32.1922
0.4849
−0.2997
0.0270
−0.0167
;
.
Using this result, we identify the system matrices NA, NB, and NC
NA = O†
r Hr,s[1]C†
s =
:
1.6180
0.0012
2.6275 × 10−7
−0.6180
;
NB = Cs(1 : n, 1 : m) = Cs(1 : 2, 1) =
:
−1.1090
0.4849
;
NC = Or(1 : p, 1 : n) = Or(1, 1 : 2) =
<
−0.6526
0.5696
=
.
These system matrices are quite different from those computed in the
Ho–Kalman example, but give identical transfer function, unit-pulse
response, and pole-zero mapping. This is illustrated in Fig. 5.27,
where the unit-pulse responses of the true and estimated (using the
ERA) system are drawn. Note that this ﬁgure is indistinguishable
from Fig. 5.5, which was created using the Ho–Kalman algorithm
instead.
When using the ERA as part of the DRA, the only change is to
replace the Ho–Kalman code in Step 4 with code to implement the
ERA instead. The index vectors jk and tk must be chosen to capture
the essence of the unit-pulse response without requiring all samples.
In our experience that means keeping all the ﬁrst samples until the
response decays to a nearly exponential shape, and then short seg-
ments of the response until it becomes vanishingly small.
5.7
Where to from here?
We have now introduced the discrete-time state-space form, which is
the form that our ﬁnal model of a battery cell will take. We have also
seen our ﬁrst example of a battery-related transcendental transfer

5. state-space models and the discrete-time realization algorithm
213
function, and have developed the discrete-time realization algorithm
as a method for converting from a continuous-time transcendental
transfer function into a discrete-time state-space form. An example
of a diffusion equation, which will also be important in the next
chapter, shows that the DRA-produced ﬁnal model very accurately
approximates the PDE solution, but at a much lower computational
complexity.
The next step is to develop transfer function models for all cell
variables of interest. We will then use the DRA to convert these into
a lithium-ion cell model that can predict cell voltage as well as cell
internal variables. We will then show, via simulation, that the DRA-
produced ﬁnal reduced-order model of a lithium-ion cell agrees very
closely with the full-order model simulated in COMSOL.
5.8
Partial glossary
This section gives a glossary of the most important variables deﬁned
in this chapter.
• 0k×l is a matrix comprising k rows and l columns, where every
matrix entry is zero.
• A is the state transition matrix of a discrete-time state-space model
form (cf. p. 175).
• NA is an estimate of A.
• Ac is the state transition matrix of a continuous-time state-space
model form (cf. p. 174).
• B is the input matrix of a discrete-time state-space model form
(cf. p. 175).
• NB is an estimate of B.
• Bc is the input matrix of a continuous-time state-space model form
(cf. p. 174).
• C is the output matrix of a discrete-time state-space model form
(cf. p. 175).
• C is the controllability matrix of a state-space model form. It has 1
block row and n block columns, where n is the dimension of the
state vector x (cf. p. 187).
• NC is an estimate of C.
• Cc is the output matrix of a continuous-time state-space model
form (cf. p. 174).
• Cl is the extended controllability matrix of a state-space model
form. It has 1 block row and l block columns, where l is gener-
ally greater than the dimension of the state vector x (cf. p. 191).

214
battery management systems: volume i, battery modeling
• cs,0 is the initial equilibrium set-point value for lithium concentra-
tion in a solid particle (cf. p. 183).
• ˜cs(r, t) is the debiased lithium concentration: ˜cs(r, t) = cs(r, t) −cs,0
(cf. p. 183).
• D is the feedthrough matrix of a discrete-time state-space model
form (cf. p. 175).
• ND is an estimate of D.
• Dc is the feedthrough matrix of a continuous-time state-space model
form (cf. p. 174).
• gk are the Markov parameters of a discrete-time state-space model
form. For single-input single-output systems, they comprise
the set of discrete-time pulse-response values. For multi-input
and/or multioutput systems, they are generalized versions of
pulse-response values (cf. p. 181).
• H(s) is the Laplace-domain transfer function of a continuous-time
linear time-invariant system.
• H(z) is the z-domain transfer function of a discrete-time linear time-
invariant system.
• H is the Hankel matrix of a state-space model form. It has n block
rows and n block columns (cf. p. 187).
• Hk,l is an extended Hankel matrix of a state-space model form. It
has k block rows and l block columns (cf. p. 191).
• H∞is the inﬁnite Hankel matrix or Hankel operator of a state-space
model form. It has an inﬁnite number of block rows and block
columns (cf. p. 191).
• h(t) is the impulse response of a continuous-time system (cf. p. 174).
• hpulse(t) is the unit-pulse response of a continuous-time system for a
pulse duration of Ts (cf. p. 197).
• hstep(t) is the step response of a continuous-time system (cf. p. 197).
• I is the identity matrix. It is always square.
• O is the observability matrix of a state-space model form. It has n
block rows and 1 block column, where n is the dimension of the
state vector x (cf. p. 187).
• Ok is the extended observability matrix of a state-space model form.
It has k block rows and 1 block column, where k is generally
greater than the dimension of the state vector x (cf. p. 191).
• Σ is a matrix containing the singular values of a singular-value
decomposition of a matrix (cf. p. 189).
• σi is the ith singular value of a matrix (cf. p. 189).

5. state-space models and the discrete-time realization algorithm
215
• U is a matrix containing the left or output singular vectors of a
singular-value decomposition of a matrix (cf. p. 189).
• u is the input signal to a state-space model form (cf. p. 175).
• V is a matrix containing the right or input singular vectors of a
singular-value decomposition of a matrix (cf. p. 189).
• x is the state vector of a state-space model form (cf. p. 175).
• y is the output signal from a state-space model form (cf. p. 175).


6.1
1D model of jneg(z, t) . . . . 217
6.2
1D model of ˜cneg
s,e (z, t) . . . . 225
6.3
1D model of ˜φneg
s
(z, t) . . . . 226
6.4
jpos, ˜cpos
s,e , and ˜φpos
s
. . . . . . 227
6.5
1D model of ce(x, t) . . . . . 229
6.6
1D model of ˜φe(x, t) . . . . . 241
6.7
T.F. summary . . . . . . . . . 244
6.8
Computing cell voltage . . . 246
6.9
Frequency response. . . . . . 248
6.10 Multioutput DRA . . . . . . 249
6.11 Full cell model. . . . . . . . . 252
6.12 Simulation example . . . . . 253
6.13 Model blending . . . . . . . . 256
6.14 Where to from here? . . . . . 266
6.15 Modal-solution code . . . . . 266
6.16 Partial glossary . . . . . . . . 269
6
Reduced-Order Models
To see the progress we’ve made, we encourage you to look back to
Fig. 3.1. We’ve studied equivalent-circuit-based empirical models,
which had the advantage of simplicity, but had the disadvantage
of not being able to produce predictions of internal cell behaviors.
Turning to physics-based modeling approaches, we’ve developed
microscale homogeneous-material models, and we’ve used volume-
averaging techniques to convert them to continuum-scale coupled
PDE models.
These models are still too complex to use in an embedded-system
type of application. They must be simpliﬁed. But, now we know an
approach to doing so: we’ve seen how to convert a continuous-time
and space PDE to a discrete-time ODE via ﬁnding transfer functions
and using the discrete-time realization algorithm. We will now ex-
tend this method to make a simple coupled ODE model of all the
internal cell behaviors that we might care to monitor.
The focus of this chapter, then, is to develop transfer functions for
all internal cell variables of interest, run the DRA on these transfer
functions, and verify the results.
6.1
A one-dimensional model of jneg(z, t)
In Chap. 5, we derived a transfer function, KCs,e(s)/J(s), that allows us
to compute the lithium surface concentration cs,e(t) for a single par-
ticle if we know the local value of lithium ﬂux at that point, j(t). By
implementing this transfer function in a reduced-order model created
by the DRA, we have transformed the inﬁnite-order radial pseudo
dimension into a small ﬁnite-order ODE. However, we still need an
inﬁnite set of these ODEs if we are to solve for lithium surface con-
centration at every x coordinate in the cell!
In this chapter, we look at ways to make a one-dimensional reduced-
order cell model. The outcome of this process will be a small ﬁnite-
order ODE that is able to compute all cell variables of interest at
217

218
battery management systems: volume i, battery modeling
1 Lee, J.L., Chemistruck, A., and Plett,
G.L., “One-Dimensional Physics-Based
Reduced-Order Model of Lithium-Ion
Dynamics,” Journal of Power Sources, 220,
2012, pp. 430–448.
2 Smith, K., Rahn, C.D., and Wang, C-Y,
“Control Oriented 1D Electrochemical
Model of Lithium Ion Battery,” Energy
Conversion and Management, 48, 2007,
pp. 2,565–78.
any desired set of x locations in the cell. To do so, we will ﬁrst ﬁnd
transfer functions for each variable since, once we have the transfer
functions, we already know how to convert them to a discrete-time
reduced-order state-space system using the DRA.
We follow the approach ﬁrst proposed by Lee et al.,1 with some
minor modiﬁcations to the nomenclature to clarify presentation.
Lee’s work, in turn, was inspired by the pioneering work of Smith
et al., who derived transfer functions for the ﬁrst several variables of
interest.2 Lee et al. developed additional transfer functions for the
variables that were not considered by Smith, and showed how all
transfer functions could be implemented via the DRA.
Because we are now considering a model for the entire cell rather
than a single electrode or point in an electrode, we must be very
careful to specify the cell region for which a particular result applies
and the cell region from which a particular parameter value is taken.
When appropriate in the equations we develop, we will use super-
script “neg” to denote a negative-electrode quantity; “sep” to denote
a separator quantity; and “pos” to denote a positive-electrode quan-
tity.
We will initially focus on modeling the cell’s internal variables
for the negative electrode. We will omit the superscript “neg” until
the ﬁnal result is obtained so that the presentation is not overly clut-
tered. However, the reader should understand that all variables and
constants in the next sections refer to negative-electrode quantities.
We will later see that it is quite simple to generalize results to the
positive electrode.
We make two fundamental assumptions when creating the reduced-
order models:
1. We assume locally linear behavior. Since the actual equations
are nonlinear, we linearize the nonlinear equations using Taylor
series;
2. We assume that electrolyte potential φe(x, t) is predominantly
a function of the reaction ﬂux density j(x, t) and, consequently,
that the effect of electrolyte concentration ce(x, t) on φe(x, t) is
minimal.
We begin by linearizing the Butler–Volmer kinetic relationship. Recall
Eq. (4.19):
j = k0c1−α
e
(cs,max −cs,e)1−αcα
s,e
>
exp
.(1 −α)F
RT
η
/
−exp
.
−αF
RT η
/?
,
where η = φs −φe −Uocp(cs,e) −FRﬁlmj. Note the new term in the
overpotential calculation, FRﬁlmj, which models the voltage drop due
to lithium ﬂux through the ionic resistance of the electrode’s surface
ﬁlm.

6. reduced-order models
219
We rearrange the Butler–Volmer equation, expanding the overpo-
tential term and deﬁning φs-e = φs −φe,
j
k0 (ce)1−α (cs,max −cs,e)1−α (cs,e)α
= exp
.(1 −α)F
RT
!
φs-e −Uocp(cs,e) −FRﬁlmj
"/
−exp
.
−αF
RT
!
φs-e −Uocp(cs,e) −FRﬁlmj
"/
.
(6.1)
We see that j appears on both sides of this expression, and because of
the nonlinear nature of the right-hand side, we cannot solve for j in
closed form, in general.
Our approach is to ﬁnd separate Taylor-series expansions of
both sides of Eq. (6.1), then equate them to make an overall lin-
ear approximation to it. The linearization setpoint p∗is deﬁned as:
p∗= {cs,e = cs,0, ce = ce,0, φs-e = Uocp(cs,0), j = 0}, where cs,0 is
the initial equilibrium bulk-average concentration of lithium in the
solid, ce,0 is the electrolyte average concentration of lithium, and Uocp
is the open-circuit-potential relationship of the electrode material at
the given concentration.
Linearizing the left-hand side (LHS) of Eq. (6.1), we get:
LHS ≈LHS(p∗)
#
$%
&
0
+ ∂LHS
∂cs,e
++++
p∗
#
$%
&
0
(cs,e−cs,0) + ∂LHS
∂ce
++++
p∗
#
$%
&
0
(ce−ce,0) + ∂LHS
∂j
++++
p∗j
=
1
k0 (ce,0)1−α (cs,max −cs,0)1−α (cs,0)α j
= j/j0,
where we have deﬁned the constant
j0 = k0 (ce,0)1−α (cs,max −cs,0)1−α (cs,0)α .
Linearizing the right-hand side (RHS) of Eq. (6.1), we get:
RHS ≈RHS(p∗)
#
$%
&
0
+ ∂RHS
∂φs-e
++++
p∗(φs-e −Uocp(cs,0))
+ ∂RHS
∂cs,e
++++
p∗(cs,e −cs,0) + ∂RHS
∂j
++++
p∗j
=
F
RT
!
φs-e −Uocp(cs,0)
" −F
RT
:
∂Uocp
∂cs,e
++++
cs,0
;
(cs,e −cs,0)
−F2Rﬁlm
RT
j.

220
battery management systems: volume i, battery modeling
Equating the linearized LHS = RHS and deﬁning debiased variables
˜cs,e = cs,e −cs,0 and ˜φs-e = φs-e −Uocp(cs,0), we get
j
j0
=
F
RT
˜φs-e −F
RT
:
∂Uocp
∂cs,e
++++
cs,0
;
˜cs,e −F2Rﬁlm
RT
j.
Rearranging allows us to solve for ˜φs-e
˜φs-e =
. RT
j0F + FRﬁlm
/
j +
:
∂Uocp
∂cs,e
++++
cs,0
;
˜cs,e
= F(Rct + Rﬁlm)j +
:
∂Uocp
∂cs,e
++++
cs,0
;
˜cs,e,
(6.2)
if we deﬁne the charge-transfer resistance
Rct = RT
j0F2 .
(6.3)
Before proceeding, we take a brief diversion that will give us some
insight into the function of Rct. Rearranging the prior result gives
F(Rct + Rﬁlm)j = φs −φe −Uocp(cs,0) −
:
∂Uocp
∂cs,e
++++
cs,0
;
˜cs,e.
Notice that the last two terms are a Taylor-series linearization of
Uocp(cs,e), so we rewrite as
F(Rct + Rﬁlm)j = φs −φe −Uocp(cs,e)
FRctj = φs −φe −Uocp(cs,e) −FRﬁlmj
= η.
So, the linearized model has
η = FRctj.
(6.4)
This helps explain the charge-transfer resistance terminology. Since η
is a voltage and Fj is current density in A m−2, Rct in Ωm2 is the lin-
earized resistance of the activation polarization of the Butler–Volmer
equation that models the voltage drop beyond open-circuit-potential
over the interface between solid and electrolyte. Note that this resis-
tance is a function of state of charge since j0 is a function of cs,0.
Based on this understanding, we can also deﬁne a total solid–
electrolyte interfacial resistance
Rs,e = Rct + Rﬁlm,
so Eq. (6.2) becomes
˜φs-e = FRs,ej +
:
∂Uocp
∂cs,e
++++
cs,0
;
˜cs,e,
(6.5)

6. reduced-order models
221
3 In the transformation, we have re-
placed ∂(·)/∂x with (1/L)∂(·)/∂z, via
change of variables. We have also as-
sumed that σeff is uniform throughout
the electrode.
We’ll lay these results aside for now, and proceed to examine the
cell potentials φs and φe. Our ﬁrst step is to deﬁne a dimensionless
spatial variable z = x/L, where L is the electrode thickness.
• The location z = 0 represents the current-collector interface;
• The location z = 1 represents the separator interface.
This dimensionless variable makes the equations somewhat more
compact than if we were to proceed using x, makes it easier to in-
terpret the equations since the length scale is normalized between
zero and one (i.e., we don’t need to remember L), and will ultimately
make the equations for the positive electrode very similar to the equa-
tions for the negative electrode.
Recall the solid-phase charge conservation equation from Eq. (4.4),
specialized to one spatial dimension and transformed to normalized
variable z,3
σeff
L2
∂2
∂z2 φs = asFj,
(6.6)
with boundary conditions from Sect. 4.11.1
σeff
L
∂φs
∂z
++++
z=0
= −iapp
A
and
∂φs
∂z
++++
z=1
= 0,
where iapp is the cell applied current in amperes. Also recall the
electrolyte-phase charge conservation equation from Eq. (4.6), also
specialized to one spatial dimension and normalized
κeff
L2
∂2
∂z2 φe + κD,eff
L2
∂2
∂z2 ln ce = −asFj,
with boundary conditions from Sect. 4.11.2
κeff
∂φe
∂z + κD,eff
∂ln ce
∂z
++++
z=0
= 0
κeff
L
∂φe
∂z + κD,eff
L
∂ln ce
∂z
++++
z=1
= iapp
A .
By assumption 2, we ignore the electrolyte concentration in these
last equations, giving
κeff
L2
∂2
∂z2 φe = −asFj,
(6.7)
with boundary conditions
∂φe
∂z
++++
z=0
= 0
and
κeff
L
∂φe
∂z
++++
z=1
= iapp
A .
We subtract Eq. (6.7) from Eq. (6.6) to arrive at a single static PDE
for phase potential difference φs-e = φs −φe,
∂2
∂z2 φs-e = asFL2
. 1
σeff
+ 1
κeff
/
j
(6.8)

222
battery management systems: volume i, battery modeling
with boundary conditions
σeff
L
∂φs-e
∂z
++++
z=0
= −κeff
L
∂φs-e
∂z
++++
z=1
= −iapp
A
.
This PDE expresses φs-e in terms of j. If we were able to eliminate
j from the equation, we would have a homogeneous PDE for φs-e,
which we could then solve. This, in turn, would allow us to solve for
the other variables using the equations in which it appears.
In an effort to eliminate j, we take the Laplace transform of Eq. (6.5),
noticing that all signals are functions of both time and space, to get
KΦs-e(z, s) = FRs,eJ(z, s) +
:
∂Uocp
∂cs,e
++++
cs,0
;
KCs,e(z, s).
To treat the rightmost term, write
KCs,e(z, s) =
KCs,e(z, s)
J(z, s) J(z, s).
In Chap. 5, we determined the transfer function KCs,e(s)/J(s) for a
single spatial location using the PDEs developed from the Jacobsen–
West paper (cf. Eq. (5.9)). But, in the solid, we are assuming that
diffusion happens along only the r dimension (not the z dimension),
so transfer functions at any location z = z1 have the same form as
any other location z = z2, and so we can write KCs,e(z, s)/J(z, s) =
KCs,e(s)/J(s). This gives (remembering that β = Rs
√
s/Ds)
KΦs-e(z, s) =
,
FRs,e +
:
∂Uocp
∂cs,e
++++
cs,0
; KCs,e(s)
J(s)
-
J(z, s)
= F
,
Rs,e +
:
∂Uocp
∂cs,e
++++
cs,0
;
Rs
FDs
@
1
1 −β coth(β)
A-
J(z, s).
Note that since ˜φs-e = φs-e −Uocp(cs,0), we also have ∂2 ˜φs-e
∂z2
= ∂2φs-e
∂z2 ,
so we can write Eq. (6.8) as
∂2 ˜φs-e(z, t)
∂z2
= asFL2
. 1
σeff
+ 1
κeff
/
j(z, t)
∂2 KΦs-e(z, s)
∂z2
= asFL2
. 1
σeff
+ 1
κeff
/
J(z, s)
=
asL2 '
1
σeff +
1
κeff
(
Rs,e +
Rs
FDs
@
∂Uocp
∂cs,e
+++
cs,0
A <
1
1−β coth(β)
= KΦs-e(z, s)
with boundary conditions
σeff
L
∂KΦs-e(z, s)
∂z
+++++
z=0
= −κeff
L
∂KΦs-e(z, s)
∂z
+++++
z=1
= −Iapp(s)
A
.

6. reduced-order models
223
4 This is the Greek letter “nu” and
not the English letter “v”. We use
this notation to be consistent with
Smith et al. (cf. reference in foot-
note 2). We can interpret ν2(s) as a
ratio of frequency-dependent and
SOC-dependent impedances, where the
numerator represents the impedance
in the x dimension across the electrode,
and the denominator represents the
impedance in the r dimension across
the solid–electrolyte interface and via
diffusion into the particle.
For convenience of notation, we deﬁne dimensionless variable
νneg(s) (to which we will refer simply as ν(s) in the remainder of the
sections describing transfer functions in the negative electrode) as4
νneg(s) =
Lneg
L
aneg
s
σneg
eff + aneg
s
κneg
eff
P
Q
Q
RRneg
s,e +
Rneg
s
FDneg
s
:
∂Uneg
ocp
∂cneg
s,e
++++
cneg
s,0
;@
1
1−Rneg
s
√
s/Dneg
s
coth(Rneg
s
√
s/Dneg
s
)
A,
(6.9)
which gives us the homogeneous PDE
∂2 KΦs-e(z, s)
∂z2
−ν2(s)KΦs-e(z, s) = 0.
The generic solution to this PDE is
KΦs-e(z, s) = k1 cosh(ν(s)z) + k2 sinh(ν(s)z),
where k1 and k2 are chosen to satisfy the boundary conditions. Since
our boundary conditions are expressed as gradients, we compute
∂KΦs-e(z, s)
∂z
= k1ν(s) sinh(ν(s)z) + k2ν(s) cosh(ν(s)z).
From the boundary condition at z = 0, we have
σeff
L
∂KΦs-e(z, s)
∂z
+++++
z=0
= σeff
L k2ν(s) = −Iapp(s)
A
k2 = −Iapp(s)L
Aσeffν(s) .
(6.10)
From the boundary condition at z = 1, we have
−κeff
L
∂KΦs-e(z, s)
∂z
+++++
z=1
= −κeff
L
@
k1ν(s) sinh(ν(s)) −Iapp(s)L
Aσeff
cosh(ν(s))
A
−Iapp(s)
A
= −κeff
L
@
k1ν(s) sinh(ν(s)) −Iapp(s)L
Aσeff
cosh(ν(s))
A
k1ν(s) sinh(ν(s)) = Iapp(s)L
Aκeff
@
1 + κeff
σeff
cosh(ν(s))
A
k1 =
Iapp(s)L
Aν(s) sinh(ν(s))
@ 1
κeff
+ 1
σeff
cosh(ν(s))
A
.
(6.11)
Substituting these values of k1 and k2 into KΦs-e(z, s) gives
KΦs-e(z, s) =
Iapp(s)L
Aν(s) sinh(ν(s))
@ 1
κeff
+ 1
σeff
cosh(ν(s))
A
cosh(ν(s)z)
+ −Iapp(s)L
Aσeffν(s) sinh(ν(s)z)

224
battery management systems: volume i, battery modeling
5 All of the tricky trigonometric ma-
nipulations and integrals involving
hyperbolic functions in this chapter
were performed with the aid of Mathe-
matica.
10
−6
10
−4
10
−2
10
0
10
2
−128
−126
−124
−122
−120
−118
−116
 
 
  0
0.2
0.4
0.6
0.8
  1
Magnitude (dB)
Magnitude of Jneg(z, s)/Iapp(s)
Frequency (rad sec−1)
Figure 6.1: Example magnitude re-
sponses of Jneg(z, s)/Iapp(s) at six
different z locations across the negative
electrode.
(Adapted from Fig. 3 in Lee, J.L.,
Chemistruck, A., and Plett, G.L.,
“One-Dimensional Physics-Based
Reduced-Order Model of Lithium-Ion
Dynamics,” Journal of Power Sources, 220,
2012, pp. 430–448.)
KΦs-e(z, s)
Iapp(s)
=
L
Aν(s) sinh(ν(s))
@ 1
κeff
cosh(ν(s)z)
+ 1
σeff
(cosh(ν(s)) cosh(ν(s)z) −sinh(ν(s)) sinh(ν(s)z))
A
.
Some trigonometric manipulations give us the following ﬁnal form
KΦneg
s-e (z, s)
Iapp(s)
=
Lneg <
σneg
eff cosh(νneg(s)z) + κneg
eff cosh(νneg(s)(z −1))
=
Aσneg
eff κneg
eff νneg(s) sinh(νneg(s))
,
(6.12)
where the superscript “neg” for KΦs-e reminds us that this transfer
function applies to the negative-electrode region only.5
We can now write
J(z, s)
Iapp(s) =
J(z, s)
KΦs-e(z, s)
KΦs-e(z, s)
Iapp(s)
=
ν2(s)
asFL2
'
1
κeff +
1
σeff
(
KΦs-e(z, s)
Iapp(s) .
Expanding gives
Jneg(z, s)
Iapp(s)
= νneg(s)σneg
eff cosh(νneg(s)z) + κneg
eff cosh(νneg(s)(z −1))
aneg
s
FLnegA(κneg
eff + σneg
eff ) sinh(νneg(s))
.
(6.13)
Summarizing to this point, we have now developed a transfer-
function that relates the applied cell current iapp(t) to the reaction
ﬂux j(z, t) at any z location in the negative electrode. Much like the
Jacobsen–West transfer function from the previous chapter, this result
also involves transcendental functions of s. However, we have seen
that the DRA is able to make high-ﬁdelity low-order discrete-time
ODE approximate versions of transcendental transfer functions: the
same will be true here as well.
Later in the chapter we’ll see examples that illustrate that a low-
order DRA model based on this transfer function J(z, s)/Iapp(s) can
accurately predict reaction ﬂux at any location in the electrode. To
see why this is possible, Fig. 6.1 plots the magnitude responses of
J(z, s)/Iapp (s) for several normalized z locations in the negative elec-
trode. Parameter values used by the transfer functions in these plots
are the same as those used in the full-cell example later in this chap-
ter. Note that while the transfer functions appear very complicated
mathematically, the magnitude responses are actually quite simple in
nature. So, it turns out to be possible to approximate their behavior
closely with a low-order state-space model.
The transfer function for KΦneg
s-e (z, s) in Eq. (6.12) turns out to have
integrator dynamics (a pole at s = 0). Referring back to Eq. (6.2),
we see why this is the case: ˜φs-e(z, t) has a component based on
˜cs,e(z, t), which we have already seen has an integrator (in Exam-
ple 3 in Chap. 5). When running the DRA with Eq. (6.12), we must

6. reduced-order models
225
10
−6
10
−4
10
−2
10
0
10
2
−60
−55
−50
−45
 
 
  0
0.2
0.4
0.6
0.8
  1
Magnitude (dB)
Magnitude of [KΦneg
s-e (z, s)]∗/Iapp(s)
Frequency (rad sec−1)
Figure 6.2: Example magnitude re-
sponses of [KΦneg
s-e (z, s)]∗/Iapp(s) at six
different z locations across the negative
electrode.
10
−5
10
−3
10
−1
10
1
0
50
100
 
 
  0
0.2
0.4
0.6
0.8
  1
Magnitude (dB)
Magnitude of KCneg
s,e (z, s)/Iapp(s)
Frequency (rad sec−1)
Figure 6.3: Example magnitude re-
sponses of KCneg
s,e (z, s)/Iapp(s) at six
different z locations across the negative
electrode.
10
−5
10
−3
10
−1
10
1
0
10
20
30
40
 
 
  0
0.2
0.4
0.6
0.8
  1
Magnitude (dB)
Magnitude of [ KCneg
s,e (z, s)]∗/Iapp(s)
Frequency (rad sec−1)
Figure 6.4: Example magnitude re-
sponses of [ KCneg
s,e (z, s)]∗/Iapp(s) at six
different z locations across the negative
electrode.
(Adapted from Fig. 1 in Lee, J.L.,
Chemistruck, A., and Plett, G.L.,
“One-Dimensional Physics-Based
Reduced-Order Model of Lithium-Ion
Dynamics,” Journal of Power Sources, 220,
2012, pp. 430–448.)
ﬁrst subtract the integrator dynamics
[KΦneg
s-e (z, s)]∗
Iapp(s)
=
KΦneg
s-e (z, s)
Iapp(s)
−res0
s
=
KΦneg
s-e (z, s)
Iapp(s)
+
1
εneg
s
AFLnegs
:
∂Uocp
∂cs,e
++++
cs,0
;
.
(6.14)
The resulting magnitude response is plotted in Fig. 6.2. As with
Fig. 6.1, the plot shows the simplicity of the transfer function despite
the apparent complexity of Eq. (6.12).
6.2
A one-dimensional model of ˜cneg
s,e (z, t)
Using the transfer function for J(z, s)/Iapp(s), it is straightforward
to develop a transfer function relating iapp(t) to ˜cs,e(z, t). We start by
writing
KCs,e(z, s)
Iapp(s) =
KCs,e(z, s)
J(z, s)
J(z, s)
Iapp(s)
= Rs
Ds
@
1
1 −Rs
√
s/Ds coth(Rs
√
s/Ds)
A J(z, s)
Iapp(s).
Substituting Eq. (6.13), we get our ﬁnal form:
KCneg
s,e (z, s)
Iapp(s)
=
:
σneg
eff cosh(νneg(s)z) + κneg
eff cosh(νneg(s)(z −1))
aneg
s
FLnegADneg
s
(κneg
eff + σneg
eff ) sinh(νneg(s))
;
×
⎡
⎣
Rneg
s
νneg(s)
1 −Rneg
s
M
s/Dneg
s
coth(Rneg
s
M
s/Dneg
s
)
⎤
⎦.
(6.15)
As before, this is a transcendental transfer function, which has an
inﬁnite number of poles and zeros. However, also as before, we’ll
be able to use this transfer function via the DRA to make excellent
low-order models of ˜cs,e(z, t). Fig. 6.3 plots the magnitude responses
of KCs,e(z, s)/Iapp(s) for several normalized z locations in the negative
electrode. We see again that while the transfer functions appear very
complicated, the magnitude responses are actually quite simple.
We also recognize from the magnitude response that there is an
integrator pole at s = 0 in this transfer function. Fig. 6.4 shows the
magnitude response with this pole removed via
[ KCneg
s,e (z, s)]∗
Iapp(s)
=
KCneg
s,e (z, s)
Iapp(s)
−res0
s
=
KCneg
s,e (z, s)
Iapp(s)
+
1
εneg
s
AFLnegs
.
(6.16)

226
battery management systems: volume i, battery modeling
6.3
A one-dimensional model of ˜φneg
s
(z, t)
We now wish to develop an independent transfer function for φs(z, t).
We begin by recalling Eq. (6.6):
σeff
L2
∂2
∂z2 φs(z, t) = asFj(z, t).
(6.17)
We will arrive at a transfer function for φs(z, t) by integrating this
expression twice.
First, recall from Eq. (4.14) that we have a deﬁnition for the elec-
tronic current is ﬂowing through the solid: εsis = −σeff∇φs. Specializ-
ing to the one-dimensional case, we have
εsis(x, t) = −σeff
∂φs(x, t)
∂x
.
(6.18)
Then, changing variables from absolute position x to relative position
z = x/L gives
εsis(z, t) = −σeff
L
∂φs(z, t)
∂z
.
This allows us to rewrite Eq. (6.17) as
−εs
L
∂is(z, t)
∂z
= asFj(z, t),
with limiting cases is(0, t) = iapp(t)/(εsA) and is(1, t) = 0. Taking
Laplace transforms gives
−εs
L
∂Is(z, s)
∂z
= asFJ(z, s).
We then integrate from zero to z to get an expression for Is(z, s)
−εs
L
ˆ z
0
∂Is(ζ, s)
∂ζ
dζ = asF
ˆ z
0
J(ζ, s) dζ
−εs
L (Is(z, s) −Is(0, s)) = asF
ˆ z
0
J(ζ, s) dζ
Is(z, s) = Is(0, s) −asFL
εs
ˆ z
0
J(ζ, s) dζ
Is(z, s)
Iapp(s) =
1
εsA −asFL
εs
ˆ z
0
J(ζ, s)
Iapp(s) dζ.
Substituting J(z, s)/Iapp(s) from Eq. (6.13) and integrating gives
Is(z, s)
Iapp(s) = σeff (sinh(ν(s)) −sinh(zν(s))) −κeff sinh((z −1)ν(s))
εsA(κeff + σeff) sinh(ν(s))
.
We now wish to ﬁnd φs(z, t) from is(z, t). We start with the Laplace
transform of Eq. (6.18)
∂Φs(z, s)
∂z
= −εsL
σeff
Is(z, s).

6. reduced-order models
227
10
−6
10
−4
10
−2
10
0
10
2
−125
−120
−115
 
 
0.2
0.4
0.6
0.8
  1
Magnitude (dB)
Magnitude of KΦneg
s
(z, s)/Iapp(s)
Frequency (rad sec−1)
Figure 6.5: Example magnitude re-
sponses of KΦneg
s
(z, s)/Iapp(s) for ﬁve
different z locations across the negative
electrode.
We then integrate from zero to z to get an expression for Φs(z, s)
∂Φs(z, s)
∂z
= −εsL
σeff
Is(z, s)
ˆ z
0
∂Φ(ζ, s)
∂ζ
dζ = −εsL
σeff
ˆ z
0
Is(ζ, s) dζ
Φ(z, s) −Φ(0, s) = −εsL
σeff
ˆ z
0
Is(ζ, s) dζ.
We deﬁne ˜φs(z, t) = φs(z, t) −φs(0, t), which then gives, in the
negative electrode
KΦneg
s
(z, s)
Iapp(s)
= −Lneg
:
κneg
eff (cosh(νneg(s)) −cosh((z −1)νneg(s)))
Aσneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
+ σneg
eff (1 −cosh(zνneg(s)) + zνneg(s) sinh(νneg(s)))
Aσneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
;
.
(6.19)
In the negative electrode, we deﬁne φs(0, t) = 0, so we have
˜φs(z, t) = φs(z, t). (In the positive electrode, it is somewhat more
complicated, as we will see in Sect. 6.4.) Fig. 6.5 shows the magnitude
response of Eq. (6.19) at several z locations. As we’ve seen before,
even though the transfer function is quite complicated, the magni-
tude response is quite simple, which leads to a relatively simple
reduced-order model.
6.4
Positive-electrode variables jpos(z, t), ˜cpos
s,e (z, t), and ˜φpos
s (z, t)
We have so far focused on deriving transfer functions of variables
of interest for the negative electrode: j, cs,e, and φs. Now, we look at
deriving the same transfer functions for the positive electrode.
Starting with KΦs-e(z, s), the derivation for the positive electrode
remains unchanged up until the point where we ﬁnd that
∂2 KΦs-e(z, s)
∂z2
−ν2(s)KΦs-e(z, s) = 0,
where we now think of ν(s) as describing the positive-electrode vari-
ables. That is, ν(s) = νpos(s) where
νpos(s) =
Lpos
L
apos
s
σpos
eff + apos
s
κpos
eff
P
Q
Q
RRpos
s,e +
Rpos
s
FDpos
s
:
∂Upos
ocp
∂cpos
s,e
++++
cpos
s,0
;@
1
1−Rpos
s
√
s/Dpos
s
coth(Rpos
s
√
s/Dpos
s
)
A.
(6.20)

228
battery management systems: volume i, battery modeling
However, the boundary conditions are different. To be careful, we
write them in terms of x rather than z:
σeff
∂KΦs-e(x, s)
∂x
+++++
x=Ltot
= −κeff
∂KΦs-e(x, s)
∂x
+++++
x=Ltot−Lpos
= −Iapp(s)
A
.
As for the negative electrode, we deﬁne z = 0 to be the location of
the current collector, and z = 1 to be at the separator boundary. That
gives the relationship
x = Ltot −zLpos.
To rewrite these boundary conditions in terms of z, note that
∂KΦs-e
∂z
= ∂KΦs-e
∂x
∂x
∂z = −Lpos ∂KΦs-e
∂x .
This allows us to write
σeff
Lpos
∂KΦs-e(z, s)
∂z
+++++
z=0
= −κeff
Lpos
∂KΦs-e(z, s)
∂z
+++++
z=1
= +Iapp(s)
A
.
Note the sign changes from before, which cause us to solve the PDE
with k1 and k2 constants having equal magnitude to those found
before, but opposite sign. This has the net effect that all positive-
electrode transfer functions are of the same form as their negative-
electrode counterparts except:
1. We use νpos(s) instead of νneg(s).
2. We use Lpos, apos
s
, κpos
eff , σpos
eff instead of Lneg, aneg
s
, κneg
eff , and σeng
eff ,
respectively.
3. We multiply the transfer function by −1.
Therefore, for the positive electrode,
KΦpos
s-e (z, s)
Iapp(s)
=
−Lpos <
σpos
eff cosh(νpos(s)z) + κpos
eff cosh(νpos(s)(z −1))
=
Aσpos
eff κpos
eff νpos(s) sinh(νpos(s))
.
(6.21)
We can compute Φpos
s-e (z, s) = KΦpos
s-e (z, s) + Upos
ocp(cpos
s,0 ), where we
are now considering the OCP function for the positive-electrode ma-
terial, not the negative-electrode material, and cs,0 as the linearization
setpoint concentration for the positive electrode.
Likewise, since all the transfer functions we have studied so far
depend on KΦs-e(z, s),
Jpos(z, s)
Iapp(s)
= −νpos(s)σpos
eff cosh(νpos(s)z) + κpos
eff cosh(νpos(s)(z −1))
apos
s
FLposA(κpos
eff + σpos
eff ) sinh(νpos(s))
,
(6.22)

6. reduced-order models
229
and
KCpos
s,e (z, s)
Iapp(s)
= −
:
σpos
eff cosh(νpos(s)z) + κpos
eff cosh(νpos(s)(z −1))
apos
s
FLposADpos
s
(κpos
eff + σpos
eff ) sinh(νpos(s))
;
×
⎡
⎣
Rpos
s
νpos(s)
1 −Rpos
s
M
s/Dpos
s
coth(Rpos
s
M
s/Dpos
s
)
⎤
⎦.
(6.23)
We can compute Cpos
s,e (z, s) = KCpos
s,e (z, s) + cpos
s,0 , where cpos
s,0 is the
linearization setpoint value for the positive electrode.
Finally,
KΦpos
s
(z, s)
Iapp(s)
= Lpos
:
κpos
eff (cosh(νpos(s)) −cosh((z −1)νpos(s)))
Aσpos
eff (κpos
eff + σpos
eff )νpos(s) sinh(νpos(s))
+ σpos
eff (1 −cosh(zνpos(s)) + zνpos(s) sinh(νpos(s)))
Aσpos
eff (κpos
eff + σpos
eff )νpos(s) sinh(νpos(s))
;
.
(6.24)
We could compute φpos
s
(z, t) = ˜φpos
s
(z, t) + φpos
s
(0, t) if we knew how
to compute φpos
s
(0, t). However, φpos
s
(0, t) = v(t), the overall cell
voltage, which we do not yet know how to compute. We will see how
to do so in Sect. 6.8. Then, we compute φs(z, t) = ˜φs(z, t) + v(t) in the
positive electrode.
6.5
A one-dimensional model of ce(x, t)
6.5.1
An outline of the approach
The next variable that we tackle is ce(x, t) over the entire cell width.
We will begin by deriving an ordinary-differential equation solution
to the PDE equation of lithium concentration in the electrolyte:
∂εe(x)ce(x, t)
∂t
= ∇· (De,eff(x)∇ce(x, t)) + as(x)(1 −t0
+)j
(6.25)
where the boundary conditions are
∂ce(0, t)
∂x
= 0
and
∂ce(Ltot, t)
∂x
= 0,
and the initial distribution is ce(x, 0) = ce,0.
assume: We assume that De,eff and εe are uniform (constant) over
each region of the cell, but may have different values in the nega-
tive electrode, separator, and positive electrode, respectively.
We also deﬁne ˜ce(x, t) = ce(x, t) −ce,0. This converts Eq. (6.25) into
the following form, which is solvable via transfer functions:
∂εe(x)˜ce(x, t)
∂t
= ∇· (De,eff(x)∇˜ce(x, t)) + as(x)(1 −t0
+)j
(6.26)

230
battery management systems: volume i, battery modeling
where the boundary conditions are
∂˜ce(0, t)
∂x
= 0
and
∂˜ce(Ltot, t)
∂x
= 0,
and the initial distribution is ˜ce(x, 0) = 0.
We desire to show the following intermediate result: the reduced-
order solution involves ﬁrst-order ordinary-differential equation
“modes,” each having the form:
d
dt ˜ce,n(t) = −λn ˜ce,n(t) + jn(t),
where the electrolyte concentration is the weighted summation of the
solution to each of these differential equations:
˜ce(x, t) =
∞
∑
n=0
˜ce,n(t)Ψ(x; λn).
We then derive a transfer-function solution KCe(x, s)/Iapp(s) based on
˜ce(x, t).
6.5.2
Sturm–Liouville problem and Green’s identity
In the course of ﬁnding a representation for ˜ce(x, t) that can be
converted into a transfer function, we will ﬁnd that we can write
Eq. (6.25) in terms of a Sturm–Liouville problem, which is an ordinary
differential equation having the generic form
d
dx
@
p(x)dΨ(x)
dx
A
+ q(x)Ψ(x) + λw(x)Ψ(x) = 0
(6.27)
over a ﬁnite closed interval [a, b]. We don’t prove it here, but it is
important to note that
1. There are an inﬁnite number of solutions to the Sturm–Liouville
problem, each of which is indexed by a distinct real eigenvalue
λ. The set of solutions can be ordered such that
λ0 < λ1 < λ2 < · · · < λn < · · · →∞.
2. Corresponding to each eigenvalue λn is a unique (up to a nor-
malization constant) eigenfunction Ψ(x; λn) that has exactly n
zero crossings in (a, b).
3. The normalized eigenfunctions form a basis that is orthonormal
with respect to the weighting function w(x) such that
ˆ b
a
Ψ(x; λn)Ψ(x; λm)w(x) dx = δmn,
(6.28)
where δmn = 0 if m ̸= n and δmn = 1 if m = n.

6. reduced-order models
231
We will also need Green’s identity, which we can quickly derive. De-
ﬁne a linear operator, L,
L ≡d
dx
@
p(x) d
dx
A
+ q(x).
Then, the Sturm–Liouville problem can be rewritten as
L(Ψ(x)) + λw(x)Ψ(x) = 0.
For any two functions, v and u, we can write
L(v) = d
dx
@
p(x)dv
dx
A
+ q(x)v
L(u) = d
dx
@
p(x)du
dx
A
+ q(x)u.
Multiplying the ﬁrst equation by u, the second equation by v, and
subtracting gives
uL(v) −vL(u) = u d
dx
.
p dv
dx
/
+ uqv −v d
dx
.
pdu
dx
/
−vqu
= u d
dx
.
p dv
dx
/
−v d
dx
.
pdu
dx
/
.
We integrate by parts to get
ˆ b
a
@
u d
dx
.
p dv
dx
/
−v d
dx
.
pdu
dx
/A
dx
=
ˆ b
a
u d
dx
.
p dv
dx
/
dx −
ˆ b
a
v d
dx
.
pdu
dx
/
dx
=
:
p dv
dx u
++++
b
a
−
ˆ b
a
p
.du
dx
/ .dv
dx
/
dx
;
−
:
pdu
dx v
++++
b
a
−
ˆ b
a
p
.du
dx
/ .dv
dx
/
dx
;
.
The integrals in the right-hand side cancel, yielding Green’s iden-
tity
ˆ b
a
[uL(v) −vL(u)] dx = p
.
udv
dx −vdu
dx
/++++
b
a
.
(6.29)
6.5.3
Solution to the homogeneous PDE
Having reviewed these fundamental mathematical results, we now
use the separation of variables approach to solve the electrolyte-concentration
PDE. To do so, we ﬁrst ﬁnd the solution in terms of an inﬁnite series
of eigenfunctions, and then truncate the solution to use only the ﬁrst
few terms of the expansion.

232
battery management systems: volume i, battery modeling
We begin by solving the homogeneous PDE (that is, with j =
0). Solving the homogeneous boundary value problem gives the
eigenvalues λn and the eigenfunctions Ψ(x; λn) that will be used
for both the homogeneous and inhomogeneous solutions. We then
generalize this solution to ﬁnd the forced PDE solution.
The homogeneous problem is given by
∂˜ce(x, t)
∂t
=
1
εe(x)
∂
∂x De,eff(x)∂˜ce(x, t)
∂x
,
(6.30)
with boundary conditions
∂˜ce(0, t)
∂x
= 0
and
∂˜ce(Ltot, t)
∂x
= 0,
and the initial condition, ˜ce(x, 0) = 0.
There are also internal boundary conditions where the three re-
gions of the cell join. First, we assume continuity:
˜ce((Lneg)−, t) = ˜ce((Lneg)+, t)
˜ce((Lneg + Lsep)−, t) = ˜ce((Lneg + Lsep)+, t),
where the superscripts “−” and “+” indicate that the function is
evaluated slightly to the left or right of the boundary, respectively.
We also need to say something about the slope of the concentra-
tion function on either side of an internal boundary. Notice what
happens when we use the product rule on the right-hand side of the
PDE:
∂
∂x De,eff(x)∂˜ce(x, t)
∂x
= De,eff(x)∂2 ˜ce(x, t)
∂x2
+
. ∂˜ce(x, t)
∂x
/ .∂De,eff(x)
∂x
/
.
There is no physical problem with the ﬁrst term in this expression,
but the second term evaluates to scaled Dirac delta functions at re-
gion boundaries in general because of the discontinuity in De,eff(x).
This doesn’t make physical sense, so we constrain the solution to
eliminate these delta functions by effectively multiplying them by
zero
∂
∂x De,eff(x)∂˜ce(x, t)
∂x
=
lim
x+−x−→0
1
x+ −x−
:
De,eff(x+)
@ ∂˜ce(x, t)
∂x
++++
x=x+
A
−De,eff(x−)
@ ∂˜ce(x, t)
∂x
++++
x=x−
A;
= 0
at the boundaries where x = Lneg or x = Lneg + Lsep. This gives:
Dneg
e,eff
∂˜ce(x, t)
∂x
++++
x=(Lneg)−= Dsep
e,eff
∂˜ce(x, t)
∂x
++++
x=(Lneg)+
Dsep
e,eff
∂˜ce(x, t)
∂x
++++
x=(Lneg+Lsep)−= Dpos
e,eff
∂˜ce(x, t)
∂x
++++
x=(Lneg+Lsep)+ .

6. reduced-order models
233
6 λ has units s−1 and so is a kind of
frequency. λ = 0 corresponds to dc;
small λ correspond to low frequencies;
large λ correspond to high frequencies.
The separation-of-variables method assumes that the solution can
be broken up into the product of a function of time only, h(t), and a
function of position only, Ψ(x); that is,
˜ce(x, t) = h(t)Ψ(x).
It remains to ﬁnd h(t) and Ψ(x). Substituting the assumed form into
the original PDE gives
dh(t)
dt
Ψ(x) =
1
εe(x)
∂
∂x De,eff(x)h(t)∂Ψ(x)
∂x
.
We separate time-dependent variables on one side, and position
dependent variables on the other as
1
h(t)
dh(t)
dt
=
1
εe(x)Ψ(x)
∂
∂x De,eff(x)∂Ψ(x)
∂x
.
Since the left-hand side is a function of time only, and the right-hand
side is a function of position only, and they are equal for all time and
all position, they must both be equal to a constant, which we will
label as −λ.6
dh(t)
dt
= −λh(t)
∂
∂x De,eff
∂Ψ(x)
∂x
= −λεe(x)Ψ(x).
Note that there are an inﬁnite number of λ that solve these equa-
tions, and each distinct value of λ yields different h(t) and Ψ(x).
So, we rethink the notation and change h(t) 8→h(t; λ) and change
Ψ(t) 8→Ψ(t; λ), which means that both h and Ψ are parameterized by a
particular value of λ. Rewriting gives
dh(t; λ)
dt
= −λh(t; λ)
(6.31)
∂
∂x De,eff(x)∂Ψ(x; λ)
∂x
= −λεe(x)Ψ(x; λ).
(6.32)
The solution to Eq. (6.31) has the form
h(t; λ) = h(0; λ)e−λt.
The solution to Eq. (6.32) determines the eigenfunctions Ψ(x; λ),
each of which is divided into three parts: one each for the negative-
electrode, separator, and positive-electrode regions. For the negative
electrode region, we have (where k1 and k2 are (possibly) functions of
λ, but this dependence has been omitted for brevity)
Ψneg(x; λ) = k1 cos(
M
λεneg
e
/Dneg
e,effx) + k2 sin(
M
λεneg
e
/Dneg
e,effx).

234
battery management systems: volume i, battery modeling
The boundary condition at x = 0 eliminates the sin(·) term, leaving
us with
Ψneg(x; λ) = k1 cos
.M
λεneg
e
/Dneg
e,effx
/
.
For the separator region, we have
Ψsep(x; λ) = k3 cos
.M
λεsep
e
/Dsep
e,effx
/
+ k4 sin
.M
λεsep
e
/Dsep
e,effx
/
.
For this region, the sin(·) term is not automatically eliminated, and
the two functions must be scaled so that the interior boundary condi-
tions are met automatically. To compact notation, we deﬁne
ω1 = Lneg
P
Q
Q
Rλεneg
e
Dneg
e,eff
and
ω2 = Lneg
P
Q
Q
Rλεsep
e
Dsep
e,eff
.
Then, for continuity,
k1 cos (ω1) = k3 cos (ω2) + k4 sin (ω2) .
For the ﬁrst derivative criterion:
Dneg
e,eff
<
−k1
ω1
Lneg sin (ω1)
=
= Dsep
e,eff
<
−k3
ω2
Lneg sin (ω2) + k4
ω2
Lneg cos (ω2)
=
.
We now have two equations and two unknowns (k3 and k4), which
can be solved in terms of the unknown k1, which we will determine
later
:
cos (ω2)
sin (ω2)
−Dsep
e,effω2 sin (ω2)
Dsep
e,effω2 cos (ω2)
; :
k3
k4
;
= k1
:
cos (ω1)
−Dneg
e,effω1 sin (ω1)
;
.
Finally, for the positive-electrode region, we have
Ψpos(x; λ) = k5 cos
.M
λεpos
e
/Dpos
e,effx
/
+ k6 sin
.M
λεpos
e
/Dpos
e,effx
/
.
We deﬁne
ω3 = (Lneg + Lsep)
P
Q
Q
Rλεsep
e
Dsep
e,eff
and
ω4 = (Lneg + Lsep)
P
Q
Q
Rλεpos
e
Dpos
e,eff
.
Then, for continuity,
k3 cos (ω3) + k4 sin (ω3) = k5 cos (ω4) + k6 sin (ω4) .

6. reduced-order models
235
0
0.1
0.2
0.3
0.4
0.5
−1
−0.5
0
0.5
1
Slope of Ψ(Ltot; λ)
Slope (×105)
Eigenvalue guess λ
Figure 6.6: Finding eigenvalues by
locating zero crossings.
For the ﬁrst derivative criterion,
Dsep
e,eff
@
−k3
ω3
Lneg + Lsep sin (ω3) + k4
ω3
Lneg + Lsep cos (ω3)
A
= Dpos
e,eff
@
−k5
ω4
Lneg + Lsep sin (ω4) + k6
ω4
Lneg + Lsep cos (ω4)
A
.
We again have two equations and two unknowns (now in k5 and k6),
which can be solved in terms of k3 and k4
:
cos (ω4)
sin (ω4)
−Dpos
e,effω4 sin (ω4)
Dpos
e,effω4 cos (ω4)
; :
k5
k6
;
=
:
cos (ω3)
sin (ω3)
−Dsep
e,effω3 sin (ω3)
Dsep
e,effω3 cos (ω3)
; :
k3
k4
;
.
So, assuming that we can ﬁnd k1, we now have
Ψ(x; λ) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
Ψneg(x; λ),
0 ≤x < Lneg;
Ψsep(x; λ),
Lneg ≤x < Lneg + Lsep;
Ψpos(x; λ),
Lneg + Lsep ≤x ≤Ltot.
(6.33)
We ﬁnd k1 via the third property of Sturm–Liouville theory in Sect. 6.5.2.
We choose its value to force the eigenfunctions to be orthonormal
with respect to the weighting function εe(x). That is, we select k1
such that
ˆ Ltot
0
Ψ2(x; λ)εe(x) dx = 1.
The ﬁnal boundary condition ∂Ψ(Ltot; λ)/∂x = 0 imposes the con-
dition that allows us to solve for λn. Generally, this cannot be done
in closed form. So, we use numeric methods to search an interval for
zero crossings of dΨ(Ltot; λ)/dx as a function of λ. An example is
shown in Fig. 6.6. In this example, the ﬁrst 10 roots are located at
{λn} = { 0,
0.0039,
0.0106,
0.0298,
0.0538,
0.0782,
0.1151,
0.1620,
0.1936,
0.2676 },
where we denote the ordered set of eigenvalues as {λn}. Then, the
solution to the homogeneous problem is the superposition
˜ce(x, t) =
∞
∑
n=0
h(0; λ)Ψ (x; λn) e−λnt.
6.5.4
Solution to the forced PDE
We now generalize the solution from the homogeneous case to the
inhomogeneous case to solve
∂˜ce(x, t)
∂t
=
1
εe(x)
∂
∂x De,eff(x)∂˜ce(x, t)
∂x
+ as(x)(1 −t0+)
εe(x)
j(x, t).
(6.34)

236
battery management systems: volume i, battery modeling
Our approach is to transform ˜ce(x, t) into a series expansion using
the eigenfunctions of the homogeneous solution Ψ(x; λn) as a basis
set.
We rely on the fact that any piecewise smooth function can be
expanded in terms of the eigenfunctions.
˜ce(x, t) =
∞
∑
n=0
˜ce,n(t)Ψ(x; λn),
(6.35)
where ˜ce,n(t) are the generalized Fourier coefﬁcients of ˜ce(x, t).
Taking the partial derivative of Eq. (6.35) with respect to time gives
∂˜ce(x, t)
∂t
=
∞
∑
n=0
d˜ce,n(t)
dt
Ψ(x; λn).
(6.36)
Then, substituting into the original PDE gives
∞
∑
n=0
d˜ce,n(t)
dt
Ψ(x; λn) =
1
εe(x)
∂
∂x De,eff(x)∂˜ce(x, t)
∂x
+ as(x)(1 −t0
+)
εe(x)
j(x, t).
(6.37)
To reduce the left-hand side of Eq. (6.37), we multiply both sides
by Ψ(x; λm)εe(x) and integrate from 0 to Ltot.
ˆ Ltot
0
∞
∑
n=0
d˜ce,n(t)
dt
Ψ(x; λn)Ψ(x; λm)εe(x) dx
=
ˆ Ltot
0
Ψ(x; λm) ∂
∂x De,eff(x)∂˜ce(x, t)
∂x
dx
+
ˆ Ltot
0
as(x)(1 −t0
+)j(x, t)Ψ(x; λm) dx.
Because
´ Ltot
0
Ψ(x; λn)Ψ(x; λm)εe(x) dx = δmn, the integral on the left
is nonzero only when m = n. Therefore,
d˜ce,n(t)
dt
=
ˆ Ltot
0
Ψ(x; λn) ∂
∂x De,eff(x)∂˜ce(x, t)
∂x
dx
+
ˆ Ltot
0
as(x)(1 −t0
+)j(x, t)Ψ(x; λn) dx.
(6.38)
We want to simplify the ﬁrst term on the right-hand side, and we
do this by using Green’s identity. Note that Ψ(x; λ) are the solutions
to a Sturm–Liouville problem with p(x) = 1, q(x) = 0, and w(x) =
εe(x).
We focus again on the ﬁrst term:
ˆ Ltot
0
Ψ(x; λn) ∂
∂x De,eff(x)∂˜ce(x, t)
∂x
dx.
We use Green’s identity with v = Ψ(x), u = ˜ce(x, t), and p = De,eff(x)
ˆ Ltot
0
@
˜ce(x, t) ∂
∂x De,eff(x)∂Ψ(x)
∂x
−Ψ(x; λn) ∂
∂x De,eff(x)∂˜ce(x, t)
∂x
A
dx

6. reduced-order models
237
= De,eff(x)
.
˜ce(x, t)∂Ψ(x; λn)
∂x
−Ψ(x; λn)∂˜ce(x, t)
∂x
/++++
Ltot
0
.
(6.39)
In our problem, the right-hand side goes to zero because of bound-
ary conditions
∂Ψ(x; λn)
∂x
++++
x∈{0,Ltot}
= ∂˜ce(x, t)
∂x
++++
x∈{0,Ltot}
= 0.
Therefore,
ˆ Ltot
0
˜ce(x, t) ∂
∂x De,eff(x)∂Ψ(x)
∂x
dx =
ˆ Ltot
0
Ψ(x; λn) ∂
∂x De,eff(x)∂˜ce(x, t)
∂x
dx.
The left-hand side can be written as
ˆ Ltot
0
˜ce(x, t) ∂
∂x De,eff(x)∂Ψ(x)
∂x
dx = −λn
ˆ Ltot
0
˜ce(x, t)Ψ(x; λn)εe(x) dx,
(6.40)
via Eq. (6.32).
Substituting, we get
ˆ Ltot
0
Ψ(x) ∂
∂x De,eff(x)∂˜ce(x, t)
∂x
dx = −λn
ˆ Ltot
0
˜ce(x, t)Ψ(x; λn)εe(x) dx.
Using this in Eq. (6.38),
d˜ce,n(t)
dt
= −λn
ˆ Ltot
0
˜ce(x, t)Ψ(x; λn)εe(x) dx
+
ˆ Ltot
0
as(x)(1 −t0
+)j(x, t)Ψn(x) dx
= −λn ˜ce,n(t) +
ˆ Ltot
0
as(x)(1 −t0
+)j(x, t)Ψn(x) dx
#
$%
&
jn(t)
,
(6.41)
where jn(t) is the modal input to ˜ce,n(t).
6.5.5
Example of ˜ce(x, t) using eigenfunction method
To illustrate the results to date, consider a cell with the following
properties.
Lneg = 128 µm
εneg
e
= 0.357
Dneg
e,eff = 1.60 × 10−11 m2/s
Lsep = 76 µm
εsep
e
= 0.724
Dsep
e,eff = 4.62 × 10−11 m2/s
Lpos = 190 µm
εpos
e
= 0.444
Dpos
e,eff = 2.22 × 10−11 m2/s
We look for a solution to the electrolyte concentration as a function
of position when the concentration is initially uniform at 1,000 mol m−3,
and a 10-A step of current has been applied to the cell for 3 s, where

238
battery management systems: volume i, battery modeling
0
100
200
300
−200
−100
0
100
200
Eigenfunctions 0 through 5
Position across cell (µm)
Value (m−1)
Figure 6.7: Eigenfunctions for the
example.
(Adapted from Fig. 4 in Lee, J.L.,
Chemistruck, A., and Plett, G.L.,
“One-Dimensional Physics-Based
Reduced-Order Model of Lithium-Ion
Dynamics,” Journal of Power Sources, 220,
2012, pp. 430–448.)
0
100
200
300
990
995
1000
1005
1010
1015
Final concentration profile
 
 
PDE solution
Solution for modes 0:10
Concentration (mol m−3)
Position across cell (µm)
Figure 6.8: Solution for electrolyte
concentration.
j is assumed to be uniform in each electrode region and zero in the
separator.
First, we ﬁnd the eigenfunctions. The ﬁrst six, Ψ(x; λ0) through
Ψ(x; λ5), are shown in Fig. 6.7. We can quickly double-check to see
if we have found the right ones (since the numeric search to ﬁnd λn
might miss some if the search parameters are not initialized with
good initial guesses) by counting the number of zero crossings of
each eigenfunction. Per property 2 of the Sturm–Liouville theory
in Sect. 6.5.2, we know that Ψ(x; λ0) should have no zero crossings,
Ψ(x; λ1) should have one zero crossing, and so forth. Also, the slope
of every eigenfunction should be zero at both cell boundaries. The
ﬁgure shows that this is indeed the case.
Next, having identiﬁed the eigenfunctions, we use them with
Eq. (6.41) to solve for the generalized Fourier coefﬁcients ˜ce,n(t) for
0 ≤n ≤10. Finally, we compute ˜ce(x, t) using Eq. (6.35).
Results are shown in Fig. 6.8. The red line shows the exact PDE
solution, and the blue line shows the approximate solution using
eigenfunctions zero through 10. It is possible to improve the solution
by using additional eigenfunctions but there is a point of diminishing
returns. (MATLAB code for this example is listed in Sect. 6.15.)
6.5.6
A transfer-function model for ˜ce,n(x, t)
To compute ˜ce(x, t) via transfer-function methods, we note that
˜ce(x, t) is formed from a summation of ˜ce,n(t) terms. So, we can com-
pute ˜ce(x, t) if we know ˜ce,n(t); therefore, we proceed by ﬁnding a
transfer function for ˜ce,n(t).
We begin by taking Laplace transforms of Eq. (6.41), rewritten here
d
dt ˜ce,n(t) = −λn ˜ce,n(t) + jn(t)
s KCe,n(s) −˜ce,n(0) = −λn KCe,n(s) + Jn(s).
Because debiased variable ˜ce(x, t) has zero initial value, so too does
˜ce,n(t) and
s KCe,n(s) = −λn KCe,n(s) + Jn(s)
KCe,n(s)
Iapp(s) =
1
s + λn
Jn(s)
Iapp(s).
To solve this, we need to ﬁnd a transfer function for jn(t) ﬁrst.
We begin by writing,
jn(t) =
ˆ Ltot
0
as(x)(1 −t0
+)j(x, t)Ψ(x; λn) dx
=
ˆ Lneg
0
aneg
s
(1 −t0
+)jneg(x, t)Ψ(x; λn) dx

6. reduced-order models
239
+
ˆ Ltot
Lneg+Lsep apos
s
(1 −t0
+)jpos(x, t)Ψ(x; λn) dx
= jneg
n
(t) + jpos
n
(t).
Looking at the negative-electrode term ﬁrst:
jneg
n
(t) = aneg
s
(1 −t0
+)
ˆ Lneg
0
jneg(x, t)Ψ(x; λn) dx
Jneg
n
(s)
Iapp(s) = aneg
s
(1 −t0
+)
ˆ Lneg
0
Jneg(x/Lneg, s)
Iapp(s)
Ψ(x; λn) dx,
where the integrand evaluates Jneg(z, s)/Iapp(s) from Eq. (6.13) at
z = x/Lneg.
The transfer function is (computed in Mathematica)
Jneg
n
(s)
Iapp(s) =
k1(1 −t0
+)ωneg
n
sin(ωneg
n
)
'
κneg
eff + σneg
eff cosh(νneg(s))
(
νneg(s)
AF(κneg
eff + σneg
eff )
'
(ωneg
n
)2 + (νneg(s))2
(
sinh(νneg(s))
+
k1(1 −t0
+)
'
κneg
eff + σneg
eff cos(ωneg
n
)
(
(νneg(s))2
AF(κneg
eff + σneg
eff )
'
(ωneg
n
)2 + (νneg(s))
(
,
(6.42)
where ωneg
n
= LnegM
λnεneg
e
/Dneg
e,eff.
Looking at the positive electrode now,
jpos
n
(t) = apos
s
(1 −t0
+)
ˆ Ltot
Ltot−Lpos jpos(x, t)Ψ(x; λn) dx
Jpos
n
(s)
Iapp(s) = apos
s
(1 −t0
+)
ˆ Ltot
Ltot−Lpos
Jpos((Ltot −x)/Lpos, s)
Iapp(s)
Ψ(x; λn) dx,
where the integrand evaluates Jpos(z, s)/Iapp(s) from Eq. (6.22) at
z = (Ltot −x)/Lpos.
The transfer function is (computed in Mathematica)
Jpos
n
(s)
Iapp(s) =
k5(1−t0
+)ωpos
n
sin(ωsep
n )
'
κpos
eff +σpos
eff cosh(νpos(s))
(
νpos(s)
AF(κpos
eff + σpos
eff )
'
(ωpos
n )2 + (νpos(s))2
(
sinh(νpos(s))
−
k5(1−t0+)ωpos
n
sin(ωtot
n )
'
σpos
eff + κpos
eff cosh(νpos(s))
(
νpos(s)
AF(κpos
eff + σpos
eff )
'
(ωpos
n
)2 + (νpos(s))2
(
sinh(νpos(s))
−
k5(1−t0+)
'
σpos
eff cos(ωsep
n ) + κpos
eff cos(ωtot
n )
(
(νpos(s))2
AF(κpos
eff + σpos
eff )
'
(ωpos
n )2 + (νpos(s))2
(
+
k6(1−t0+)ωpos
n
cos(ωtot
n )
'
σpos
eff +κpos
eff cosh(νpos(s))
(
νpos(s)
AF(κpos
eff + σpos
eff )
'
(ωpos
n )2 + (νpos(s))2
(
sinh(νpos(s))

240
battery management systems: volume i, battery modeling
10
−6
10
−4
10
−2
10
0
10
2
−80
−60
−40
−20
0
20
40
 
 
  0
 50
100
150
200
250
300
350
Magnitude (dB)
Magnitude of KCe(x, s)/Iapp(s)
Frequency (rad sec−1)
Figure 6.9: Example magnitude plots
for KCe(x, s)/Iapp(s) at eight different x
locations (in µm) across the cell.
−
k6(1−t0
+)ωpos
n
cos(ωsep
n )
'
κpos
eff +σpos
eff cosh(νpos(s))
(
νpos(s)
AF(κpos
eff + σpos
eff )
'
(ωpos
n )2 + (νpos(s))2
(
sinh(νpos(s))
−
k6(1−t0
+)
'
σpos
eff sin(ωsep
n ) + κpos
eff sin(ωtot
n )
(
(νpos(s))2
AF(κpos
eff + σpos
eff )
'
(ωpos
n
)2 + (νpos(s))2
(
,
(6.43)
where ωpos
n
= LposM
εpos
e
λn/Dpos
e,eff, ωtot
n
= LtotM
εpos
e
λn/Dpos
e,eff, and
ωsep
n
= ωtot
n −ωpos
n
.
Overall, we have
KCe,n(s)
Iapp(s) =
1
s + λn
:
Jneg
n
(s)
Iapp(s) + Jpos
n
(s)
Iapp(s)
;
.
(6.44)
Yes, this is a mess. The good news is that we’ll develop tools that
deal with the mess quite nicely.
6.5.7
A transfer function model for ˜ce(x, t)
Our ﬁnal step is to take the results developed so far in this section
and turn them into a transfer function for ˜ce(x, t). Recall that
˜ce(x, t) =
∞
∑
n=0
˜ce,n(t)Ψ(x; λn).
The ﬁrst mode in this solution, n = 0, is the dc term and is zero
because ˜ce,0 = 0. We further truncate the summation to M terms for a
computable approximate result
˜ce(x, t) ≈
M
∑
n=1
˜ce,n(t)Ψ(x; λn).
Then, we can arrive at a transfer function for any desired x loca-
tion of the cell as
KCe(x, s)
Iapp(s) =
M
∑
n=1
KCe,n(s)
Iapp(s)Ψ(x; λn),
(6.45)
where KCe,n(s)/Iapp(s) is deﬁned in Eq. (6.44). The value for M is
chosen as a tradeoff between computation and accuracy. Note,
however, that the summation is performed only when computing
KCe(x, s)/Iapp(s) as part of the DRA process. It is not performed dur-
ing the implementation of the ﬁnal ODE. Therefore, M can be chosen
to be quite large without incurring substantial delay in executing
the DRA algorithm; it can be chosen to be any value at all without
incurring any real-time processing delay in the ﬁnal ODE.

6. reduced-order models
241
Fig. 6.9 shows an example magnitude-response plot for the trans-
fer function KCe(x, s)/Iapp(s). Once again we note the simplicity of the
function despite the mathematical complexity involved in its deriva-
tion.
6.6
A one-dimensional model of ˜φe(x, t)
We now wish to develop an independent transfer function for φe(x, t).
We begin by recalling the differential equation, Eq. (4.6), that governs
φe, which in one dimension is
κeff
∂2
∂x2 φe(x, t) + κD,eff
∂2
∂x2 ln ˜ce(x, t) = −asFj(x, t).
(6.46)
We will arrive at a transfer function for φe(x, t) by integrating this
expression twice.
First, recall from Eq. (4.18) that we have a deﬁnition for the ionic
current ie ﬂowing through the electrolyte: εeie = −κeff∇φe −
κD,eff∇ln ce. Again, specializing to one dimension, we have
εeie(x, t) = −κeff
∂
∂x φe(x, t) −κD,eff
∂
∂x ln ce(x, t).
(6.47)
This allows us to rewrite Eq. (6.46) as
εe
∂
∂x ie(x, t) = asFj(x, t).
Integrating from zero to x and noting that ie(0, t) = 0 gives
ie(x, t) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
´ x
0
aneg
s
F
εneg
e
jneg(ξ, t) dξ,
0 ≤x ≤Lneg;
iapp(t)
εsep
e
A ,
Lneg ≤x ≤Lneg + Lsep;
iapp(t)
εpos
e
A +
´ x
Lneg+Lsepapos
s
F
εpos
e
jpos(ξ, t) dξ ,
Lneg + Lsep ≤x ≤Ltot.
A transfer function for ie(x, t) in the negative electrode is
Ie(x, s)
Iapp(s) = aneg
s
F
εneg
e
ˆ x
0
Jneg(ξ/Lneg, s)
Iapp(s)
dξ,
=
κneg
eff
'
sinh(νneg(s)) −sinh
' (Lneg−x)νneg(s)
Lneg
((
εneg
e
A(κneg
eff + σneg
eff ) sinh(νneg(s))
+
σneg
eff sinh
' xνneg(s)
Lneg
(
εneg
e
A(κneg
eff + σneg
eff ) sinh(νneg(s))
.
A transfer function for ie(x, t) in the separator is
Ie(x, s)
Iapp(s) =
1
εsep
e
A
.

242
battery management systems: volume i, battery modeling
A transfer function for ie(x, t) in the positive electrode is
Ie(x, s)
Iapp(s) =
1
εpos
e
A + apos
s
F
εpos
e
ˆ x
Lneg+Lsep
Jpos((Ltot −ξ)/Lpos, s)
Iapp(s)
dξ
=
κpos
eff
'
sinh(νpos(s)) −sinh
' (x−Lneg−Lsep)
Lpos
νpos(s)
((
εpos
e
A(κpos
eff + σpos
eff ) sinh(νpos(s))
+
σpos
eff sinh
' (Ltot−x)
Lpos
νpos(s)
(
εpos
e
A(κpos
eff + σpos
eff ) sinh(νpos(s))
.
We now integrate Eq. (6.47) from zero to x to obtain φe:
φe(x, t) −φe(0, t) =
ˆ x
0
−εeie(ξ, t)
κeff
+ 2RT
F (1 −t0
+)∂ln ce(ξ, t)
∂ξ
dξ.
Deﬁne ˜φe(x, t) = φe(x, t) −φe(0, t). Then, ˜φe(x, t) comprises two parts:
[ ˜φe(x, t)]1 =
ˆ x
0
−εeie(ξ, t)
κeff
dξ.
[ ˜φe(x, t)]2 =
ˆ x
0
2RT
F (1 −t0
+)∂ln ce(ξ, t)
∂ξ
dξ.
The ﬁrst part, [ ˜φe(x, t)]1, can be determined via transfer functions; the
second part, [ ˜φe(x, t)]2, can be determined via known ce(x, t).
Let’s continue to look at the ﬁrst part. In the negative electrode,
[KΦe(x, s)]1
Iapp(s)
=
ˆ x
0
−εneg
e
Ie(ξ, s)
κneg
eff Iapp(s)
dξ
=−
Lnegσneg
eff
!
cosh
!
x
Lneg νneg(s)
" −1
"
Aκneg
eff (κneg
eff +σneg
eff )νneg(s) sinh(νneg(s))−
x
A(κneg
eff +σneg
eff )
−
Lnegκneg
eff
'
cosh
' (Lneg−x)
Lneg
νneg(s)
(
−cosh(νneg(s))
(
Aκneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
.
(6.48)
At the negative-electrode/separator boundary, we have
[KΦe(Lneg, s)]1
Iapp(s)
=−
Lneg '
(σneg
eff −κneg
eff ) tanh
' νneg(s)
2
((
Aκneg
eff (κneg
eff +σneg
eff )νneg(s)
−
Lneg
A(κneg
eff +σneg
eff )
.
In the separator, we then have
[KΦe(x, s)]1
Iapp(s)
= −
Lneg '
(σneg
eff −κneg
eff ) tanh
' νneg(s)
2
((
Aκneg
eff (κneg
eff + σneg
eff )νneg(s)
−
Lneg
A(κneg
eff + σneg
eff ) −x −Lneg
Aκsep
eff
.
(6.49)

6. reduced-order models
243
10
−6
10
−4
10
−2
10
0
10
2
−80
−70
−60
−50
−40
 
 
 50
100
150
200
250
300
350
Magnitude (dB)
Magnitude of [KΦe(x, s)]1/Iapp(s)
Frequency (rad sec−1)
Figure 6.10: Example magnitude re-
sponses of [KΦe(x, s)]1/Iapp(s) at seven
different x locations (in µm) across the
cell.
At the separator/positive-electrode boundary, we have
[KΦe(Lneg + Lsep, s)]1
Iapp(s)
= −
Lneg '
(σneg
eff −κneg
eff ) tanh
' νneg(s)
2
((
Aκneg
eff (κneg
eff + σneg
eff )νneg(s)
−
Lneg
A(κneg
eff + σneg
eff ) −Lsep
Aκsep
eff
.
In the positive electrode, we have
[KΦe(x, s)]1
Iapp(s)
= −
Lneg '
(σneg
eff −κneg
eff ) tanh
' νneg(s)
2
((
Aκneg
eff (κneg
eff +σneg
eff )νneg(s)
−
Lneg
A(κneg
eff +σneg
eff )
−Lsep
Aκsep
eff
−
Lpos '
1 −cosh
' (Lneg+Lsep−x)
Lpos
νpos(s)
((
A(κpos
eff + σpos
eff ) sinh(νpos(s))νpos(s)
−
Lposσpos
eff
'
cosh (νpos(s)) −cosh
' (Ltot−x)
Lpos
νpos(s)
((
Aκpos
eff (κpos
eff + σpos
eff ) sinh(νpos(s))νpos(s)
−(x −Lneg −Lsep)
A(κpos
eff + σpos
eff )
.
(6.50)
Finally, at the cell boundary, we have
[KΦe(Ltot, s)]1
Iapp(s)
= −
Lneg '
(σneg
eff −κneg
eff ) tanh
' νneg(s)
2
((
Aκneg
eff (κneg
eff + σneg
eff )νneg(s)
−
Lneg
A(κneg
eff +σneg
eff )
−Lsep
Aκsep
eff
−
Lpos '
(σpos
eff −κpos
eff ) tanh
' νpos(s)
2
((
Aκpos
eff (κpos
eff + σpos
eff )νpos(s)
−
Lpos
A(κpos
eff + σpos
eff )
.
An example magnitude response, at different x locations spanning
the cell, is shown in Fig. 6.10.
Now, we focus on the second term of ˜φe(x, t).
[ ˜φe(x, t)]2 = 2RT(1 −t0
+)
F
ˆ x
0
∂ln ce(ξ, t)
∂ξ
dξ
= 2RT(1 −t0+)
F
[ln ce(x, t) −ln ce(0, t)] .
To compute ˜φe(x, t), we must compute its two parts and add them.
Then, to recover φe(x, t) from ˜φe(x, t), we must compute φe(0, t):
φe(0, t) = φneg
s
(0, t) −φneg
s-e (0, t)
= 0 −( ˜φneg
s-e (0, t) + Uneg
ocp(cs,0))
φe(x, t) = ˜φe(x, t) −˜φneg
s-e (0, t) −Uneg
ocp(cs,0).

244
battery management systems: volume i, battery modeling
6.7
Summary of transfer functions
We have now deﬁned all the transfer functions of a linearized pseudo-
2D porous-electrode model. This has been an intense process, with
mathematically complex results. Before proceeding, we take a brief
step back to summarize the transfer functions of the model. Recall
that z is a normalized unitless spatial variable in the electrodes
that takes on value zero at the current collectors and one at the elec-
trode/separator interface, and that x is the spatial variable across the
cell and takes on value zero at the negative-electrode current collector
and Ltot at the positive-electrode current collector. The electrode-
domain transfer functions are written in terms of z and the cell-wide
transfer functions are written in terms of x. This is illustrated in
Fig. 6.11.
x = 0
x = Ltot
x = Lneg
x = Lneg+Lsep
z = 0
z = 1
z = 0
z = 1
Negative electrode
Positive electrode
Separator
φneg
s
(z, t)
cneg
s,e (z, t)
jneg(z, t)
φneg
s-e (z, t)
φe(x, t)
ce(x, t)
φpos
s
(z, t)
cpos
s,e (z, t)
jpos(z, t)
φpos
s-e (z, t)
φe(x, t)
ce(x, t)
φe(x, t)
ce(x, t)
Figure 6.11: Summary of notation
describing cell variables in reduced-
order model.
(Adapted from Fig. 4 in Lee, J.L.,
Chemistruck, A., and Plett, G.L.,
“One-Dimensional Physics-Based
Reduced-Order Model of Lithium-Ion
Dynamics,” Journal of Power Sources, 220,
2012, pp. 430–448.)
Common to all of the transfer functions is the dimensionless func-
tion ν(s), which is given in Eq. (6.9) for the negative electrode and
in Eq. (6.20) for the positive electrode. In the following, we assume
that the discrete-time realization algorithm from Chap. 5 will be used
to convert the transcendental transfer functions into a discrete-time
multioutput state-space model that can then compute the correspond-
ing time-domain quantities in real time. Since the majority of these
transfer functions have been linearized and debiased (by removing a
constant offset) in their development, the following discussion also
shows how to add the correct bias back into the computed signals.
Reaction ﬂux: The local reaction-ﬂux transfer function J(z, s)/Iapp(s)
is given by Eq. (6.13) for the negative electrode and Eq. (6.22) for
the positive electrode.
Solid surface concentration: Lithium concentration in the solid is de-
noted as cs(r, z, t). Here, we are concerned only with the concen-
tration of lithium at the surface of the particles, as that is what de-
termines reaction rate and cell voltage. The surface concentration
is denoted as cs,e(z, t). Furthermore, we deﬁne a debiased surface
concentration that subtracts out the equilibrium concentration:

6. reduced-order models
245
˜cs,e(z, t) = cs,e(z, t) −cs,0. The transfer function of the debiased
surface concentration KCs,e(z, s)/Iapp(s) is given by Eq. (6.15) in the
negative electrode and by Eq. (6.23) in the positive electrode. Once
the debiased surface concentration is computed, the true surface
concentration can be found as cs,e(z, t) = ˜cs,e(z, t) + cs,0.
Potential in solid: Solid potential in an electrode is denoted as φs(z, t).
We deﬁne a debiased solid potential that subtracts out the poten-
tial at the electrode’s current collector where z = 0: ˜φs(z, t) =
φs(z, t) −φs(0, t). The transfer function KΦs(z, s)/Iapp(s) of the debi-
ased solid potential is given by Eq. (6.19) for the negative electrode
and by Eq. (6.24) for the positive electrode. And, since we deﬁne
the potential of the negative-electrode current collector to be zero,
we have φs(z, t) = ˜φs(z, t) in the negative electrode. In the positive
electrode, we have that φs(z, t) = ˜φs(z, t) + v(t), where v(t) is the
cell voltage and can be found as described in Sect. 6.8.
Potential in electrolyte: Electrolyte potential is denoted as φe(x, t).
We deﬁne a debiased electrolyte potential that subtracts out the
potential at the negative current collector where x = 0: ˜φe(x, t) =
φe(x, t) −φe(0, t). Furthermore, we break up ˜φe(x, t) into two
parts: ˜φe(x, t) = [ ˜φe(x, t)]1 + [ ˜φe(x, t)]2. The transfer function
[KΦe(x, s)]1/Iapp(s) for x locations in the negative electrode is given
by Eq. (6.48). For x locations in the separator, this transfer function
is given by Eq. (6.49), and for x locations in the positive electrode,
this transfer function is given by Eq. (6.50).
Once the appropriate [ ˜φe(x, t)]1 is computed, we further calcu-
late
˜φe(x, t) = [ ˜φe(x, t)]1 + 2RT(1 −t0
+)
F
ln
.ce(x, t)
ce(0, t)
/
,
where ce(x, t) is computed as described in the “concentration in
electrolyte” summary item. Finally:
φe(x, t) = ˜φe(x, t) + φe(0, t)
= ˜φe(x, t) −φneg
s-e (0, t),
where (debiased) ˜φs-e(0, t) at x = 0 is found via the transfer func-
tion in Eq. (6.12). Note that the transfer function KΦneg
s-e (z, s)/Iapp(s)
has a pole at the origin, which is removed prior to using the DRA
to give the [KΦneg
s-e (z, s)]∗/Iapp(s) transfer function in Eq. (6.14).
The integrator response could be added back manually, as in
˜φs-e(t) = ˜φ∗s-e(t) +
! ˜φres0
s-e
"
xi(t), where xi(t) is the integrator state
of the DRA model, but better performance is obtained by looking
deeper at what is actually happening.
Recall that
cs,avg(t) =
'
˜cres0
s,e
(
xi(t) + cs,0,

246
battery management systems: volume i, battery modeling
and note that
˜φres0
s-e
= ∂Uocp
∂cs,e
++++
cs,0
× ˜cres0
s,e .
Therefore, we can write
φneg
s-e = [ ˜φneg
s-e ]∗+
⎛
⎝Uneg
ocp(cneg
s,0 ) +
⎡
⎣∂Uneg
ocp
∂cneg
s,e
+++++
cneg
s,0
⎤
⎦
'
˜cneg
s,avg −cneg
s,0
(
⎞
⎠,
where the second term on the right-hand side is equal to the ﬁrst
two terms of the Taylor-series expansion of Uneg
ocp(cneg
s,avg) around
the starting average concentration cneg
s,0 . Therefore, we ﬁnd that we
achieve more accurate results if we implement [KΦneg
s-e (z, s)]∗/Iapp(s)
and then compute
φneg
s-e (0, t) = [ ˜φneg
s-e (0, t)]∗+ Uneg
ocp(cneg
s,avg(t)).
Finally:
φe(x, t) = ˜φe(x, t) −[ ˜φneg
s-e (0, t)]∗−Uneg
ocp(cneg
s,avg(t)).
Concentration in electrolyte: Lithium concentration in the electrolyte
is denoted ce(x, t). We deﬁne a debiased electrolyte concentra-
tion that subtracts out the average concentration: ˜ce(x, t) =
ce(x, t) −ce,0. We use an eigenfunction expansion to express the
transfer function of ˜ce(x, t) in terms of M weighted partial transfer
functions, per Eq. (6.45), where M is at least as large as the antic-
ipated reduced-order-model system order. Details of ﬁnding the
eigenfunctions Ψ(x; λk) are given in Sect. 6.5.3. The individual par-
tial transfer functions are expressed in Eq. (6.44). The two parts of
this transfer function are found in Eqs. (6.42) and (6.43).
6.8
Computing cell voltage
One of the more important applications of a cell model is to be
able to predict cell voltage response to variations in input current.
Cell terminal voltage can be written (in z coordinates) as v(t) =
φpos
s
(0, t) −φ neg
s
(0, t). To implement this equation, however, we run
into a problem: to compute φpos
s
(0, t), we must already know v(t) to
debias ˜φpos
s
(0, t)!
The solution to this dilemma is to write the local overpotential
as η = φs −φe −Uocp −FRﬁlmj. Thus, we can write (mixing x
coordinates and z coordinates as appropriate, and treating η as a
z-coordinate variable):
v(t) = ηpos(0, t) + φpos
e
(Ltot, t) + Upos
ocp(cpos
s,e (0, t)) + FRpos
ﬁlmjpos(0, t)
−ηneg(0, t) −φneg
e
(0, t) −Uneg
ocp(cneg
s,e (0, t)) −FRneg
ﬁlmjneg(0, t).

6. reduced-order models
247
This is an improvement, because we already know how to compute
most of these terms. One that we have not discussed, however, is
η(z, t). One possible method to compute its value is
ηpos(z, t) = FRpos
ct jpos(z, t)
ηneg(z, t) = FRneg
ct jneg(z, t),
using Eq. (6.4). This can be an adequate small-signal approximation,
but, the true nonlinear nature of the overpotential can most easily be
seen via the Butler–Volmer equation. Recall that
j = k0ce1−α(cs,max −cs,e)1−αcs,eα
×
.
exp
.(1 −α)F
RT
η
/
−exp
.
−αF
RT η
//
.
If we assume that the charge-transfer coefﬁcient α = 0.5, as is often
the case, we can then write
j = 2k0
M
ce(cs,max −cs,e)cs,e sinh
. F
2RT η
/
.
This can be inverted to solve for the overpotential
η = 2RT
F
asinh
,
j
2k0
0
ce(cs,max −cs,e)cs,e
-
.
(6.51)
A linearization of Eq. (6.51) gives Eq. (6.4). However, computing the
overpotential directly using the nonlinear relationship in Eq. (6.51)
results in better voltage predictions. Speciﬁcally,
ηpos(z, t) = 2RT
F
asinh
⎛
⎝
jpos(z, t)
2kpos
0
M
ce(z, t)(cpos
s,max −cpos
s,e (z, t))cpos
s,e (z, t)
⎞
⎠
ηneg(z, t) = 2RT
F
asinh
⎛
⎝
jneg(z, t)
2kneg
0
M
ce(z, t)(cneg
s,max −cneg
s,e (z, t))cneg
s,e (z, t)
⎞
⎠.
With either of these deﬁnitions, then, we can write cell voltage as
v(t) = F[Rpos
ﬁlmjpos(0, t) −Rneg
ﬁlmjneg(0, t)] +
) ˜φe(Ltot, t)
*
1
+ [ηpos(0, t) −ηneg(0, t)] +
) ˜φe(Ltot, t)
*
2
+ [Upos
ocp(cpos
s,e (0, t)) −Uneg
ocp(cneg
s,e (0, t))],
(6.52)
where the ﬁrst line of the equation comprises the linear portion of
the voltage equation, and the following two lines comprise the terms
computed as nonlinear functions of linear model outputs.

248
battery management systems: volume i, battery modeling
6.9
Frequency response and cell impedance
The voltage equation can also be manipulated to form the linearized
small-signal frequency response of the cell, which is the negative of
the impedance spectrum. We start with Eq. (6.52), using an already
linearized overpotential, and note that the remaining nonlinear terms
are
) ˜φe(Ltot, t)
*
2
and
<
Upos
ocp(cpos
s,e (0, t)) −Uneg
ocp(cneg
s,e (0, t))
=
.
Writing out the ﬁrst term, we have
) ˜φe(Ltot, t)
*
2 = 2RT(1 −t0
+)
F
)
ln(ce(Ltot, t) −ln(ce(0, t))
*
.
Linearizing the logarithm via Taylor-series expansion gives
ln(ce) ≈ln(ce,0) +
@∂ln ce
∂ce
++++
ce,0
(ce −ce,0)
= ln(ce,0) +
.ce −ce,0
ce,0
/
= ln(ce,0) + ˜ce
ce,0
.
So
) ˜φe(Ltot, t)
*
2 ≈2RT(1 −t0
+)
F
@ ˜ce(Ltot, t) −˜ce(0, t)
ce,0
A
.
Using a similar means, the open-circuit-potential relationships can
be linearized
Uocp(cs,e) ≈Uocp(cs,0) +
@∂Uocp(cs,e)
∂cs,e
++++
cs,0
(cs,e −cs,0)
= Uocp(cs,0) +
@∂Uocp(cs,e)
∂cs,e
++++
cs,0
˜cs,e.
So a linearized model of cell voltage is then
v(t) ≈FRpos
s,e jpos(0, t) −FRneg
s,e jneg(0, t) +
) ˜φe(Ltot, t)
*
1
+ 2RT(1 −t0
+)
F
@ ˜ce(Ltot, t) −˜ce(0, t)
ce,0
A
+
<
Upos
ocp(cpos
s,0 ) −Uneg
ocp(cneg
s,0 )
=
+
:
∂Upos
ocp(cpos
s,e )
∂cpos
s,e
+++++
cpos
s,0
˜cpos
s,e (0, t) −
:
∂Uneg
ocp(cneg
s,e )
∂cneg
s,e
+++++
cneg
s,0
˜cneg
s,e (0, t).
We deﬁne a debiased voltage
˜v(t) = v(t) −
<
Upos
ocp(cpos
s,0 ) −Uneg
ocp(cneg
s,0 )
=
.

6. reduced-order models
249
7 The “hat” symbol on the state matrices
reminds us that the DRA produces
a reduced-order approximate system
description to an inﬁnite-order ideal
description.
Then the transfer function from applied current to variations in cell
voltage around its equilibrium setpoint (with the open-circuit voltage
offset removed) is
KV(s)
Iapp(s) = FRpos
s,e
Jpos(0, s)
Iapp(s) −FRneg
s,e
Jneg(0, s)
Iapp(s) + [KΦe(Ltot, s)]1
Iapp(s)
+ 2RT(1 −t0
+)
Fce,0
: KCe(Ltot, s)
Iapp(s)
−
KCe(0, s)
Iapp(s)
;
+
:
∂Upos
ocp(cpos
s,e )
∂cpos
s,e
+++++
cpos
s,0
KCpos
s,e (0, s)
Iapp(s)
−
:
∂Uneg
ocp(cneg
s,e )
∂cneg
s,e
+++++
cneg
s,0
KCneg
s,e (0, s)
Iapp(s) ,
(6.53)
where the individual transfer functions are as deﬁned earlier in this
chapter.
Note that since cell voltage is equal to open-circuit voltage minus
current times generalized impedance,
v(t) = OCV(z(t)) −Ziapp(t),
we have ˜v(t) = −Ziapp (t), and
Z(s) = −
KV(s)
Iapp(s).
This relationship produces the impedance spectrum, which can be
compared with results from laboratory electrochemical impedance
spectroscopy (EIS) tests.
6.10
Multioutput DRA
We have now derived all of the necessary continuous-time transfer
functions required to model the internal dynamics of a lithium-ion
cell. Proceeding, our goal is to approximate these transfer functions
with a reduced-order discrete-time state-space model of the form7
x[k + 1] = NAx[k] + NBiapp[k]
y[k] = NCx[k] + NDiapp[k].
We will use the DRA from Chap. 5 to ﬁnd the state-space matrices
from the transfer functions derived in this chapter.
So far, the only examples of using the DRA that we have seen have
been for single-input single-output systems. However, the DRA can
also work with multi-input single-output, single-input multioutput,
or multi-input multioutput transfer functions. Here, we are consid-
ering the case of a single input iapp(t) and multiple outputs, where
the outputs comprise the set of transfer functions that the user would

250
battery management systems: volume i, battery modeling
8 The only two transfer functions
derived in this chapter that have a
pole at s = 0 are for cs,e and φs-e. The
“starred” integrator-removed versions of
these transfer functions are given in the
sections where they are derived.
9 The attentive reader will have ob-
served that we don’t need to compute
all of these: ˜φs(0, t) = 0 (at both cur-
rent collectors) and we also ﬁnd that
[ ˜φe(0, t)]1 is zero as well. We can reduce
y(t) to a 21-vector and will still be able
to compute the same quantities.
like to implement. The overall multioutput transfer function being
implemented by the DRA is then the vertical concatenation of all
single-output subtransfer functions. For example, if the user would
like to determine jneg(0, t) and cpos
s,e (1, t), the overall transfer function
would be
H(s) =
⎡
⎣
Jneg(0,s)
Iapp(s)
KCpos
s,e (1,s)
Iapp(s)
⎤
⎦.
Before implementing DRA Step 1, H(s) must be strictly stable (e.g.,
it may not contain a pole at s = 0, which corresponds to integra-
tion dynamics). If H(s) has a pole at s = 0, this pole must ﬁrst be
removed, resulting in H∗(s).8 In the ﬁnal state-space representation,
we augment the realization with an integrator state to account for
removal of the pole in the DRA. The reduced-order approximation
to the original system via the augmented discrete-time state-space
model is:
:
x[k + 1]
xi[k + 1]
;
#
$%
&
xaug[k+1]
=
:
NA
0
0
1
;
#
$%
&
NAaug
:
x[k]
xi[k]
;
#
$%
&
xaug[k]
+
:
NB
Ts
;
# $% &
NBaug
iapp[k]
y[k] =
<
NC
res0
=
#
$%
&
NCaug
:
x[k]
xi[k]
;
+ Diapp[k]
where res0 is a column vector containing the residues of the transfer
functions with a pole at the origin.
The length of the output vector depends on the number of z loca-
tions (for the electrode-domain properties) and x locations (for the
cell-scale properties) chosen by the user for evaluation. For exam-
ple, solving for the six variables [ ˜φs-e]∗, j, ˜cs,e, ˜φs, [ ˜φe]1, and ˜ce at four
spatial locations each (e.g., both current collectors and both electrode–
separator interfaces) produces a total of 24 outputs. The output y(t)
then has the following structure:
y(t) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
[ ˜φs-e(z, t)]∗
j(z, t)
˜cs,e(z, t)
˜φs(z, t)
[ ˜φe(x, t)]1
˜ce(x, t)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
(6.54)
where each variable is a four-vector corresponding to the four spatial
locations evaluated.9
DRA Step 1 requires we select a high-rate sampling frequency F1
to approximate the impulse response of the continuous-time system.

6. reduced-order models
251
We ﬁnd that the results are not very sensitive to F1, but that it is
important that the duration of the truncated impulse response is long
enough to capture the slow time constants in the model.
While the elements of the output vector y(t) of the DRA have
physical meaning, the only state variable within the state vector x(t)
that has independent physical interpretation is the integrator state.
If this state is xi(t), then we have that the average concentration of
lithium in the solid is equal to
cs,avg(t) = cs,0 +
'
˜cres0
s,e
(
xi(t).
In the two electrodes, via Eq. (6.16), this becomes
cneg
s,avg(t) = cneg
s,0 −
.
1
εneg
s
AFLneg
/
xi(t)
cpos
s,avg(t) = cpos
s,0 +
.
1
εpos
s
AFLpos
/
xi(t).
As the average concentration of lithium in an electrode is related to
the state of charge of the electrode via an afﬁne transformation, the
value of the integrator state is key to being able to estimate cell SOC.
Fig. 6.12 illustrates the process to generate a linearized state-space
model of cell dynamics. The PDE models were derived in Chap. 3
and 4. This chapter described how to linearize the model to create
transfer functions. The DRA from Chap. 5 uses these transfer func-
tions to produce the state-space model.
model
PDE
model
Linearize
function
Transfer
Lab process
Data
Analytic derivations
Computational process
Legend
model
Linear SS
DRA
Execute
ID/tests
System
parameters
Physics
Step 1:
H(s) to h(t)
Step 2:
h(t) to hstep(t)
Step 3:
hstep(t) to h[n]
Step 4: h[n] to
NA, NB, NC, ND
Figure 6.12: Depiction of procedural
steps used to compute linear state-space
model of linearized debiased variables.
(Adapted from Fig. 1 in Lee, J.L.,
Aldrich, L., Stetzel, K., and Plett,
G.L., “Extended Operating Range
for Reduced-Order Model of Lithium-
Ion Cells,” Journal of Power Sources, 255,
2014, pp. 85–100.)
Comparing this ﬁgure to the corresponding diagram for creating
an equivalent-circuit model (Fig. 2.27), we see signiﬁcant differences.
The equivalent-circuit model was created via nonlinear optimization
and current–voltage cell-test data; the physics-based reduced-order

252
battery management systems: volume i, battery modeling
model is created via considerable (one-time) mathematical work to
obtain transfer-function derivations, but then by a linear-algebra
optimal order-reduction methodology.
6.11
Full cell model
The state-space model produced by the DRA can undergo some
mathematical transformations to put in a standard form. Sect. 6.13.2
describes how to do so, within a context we will soon encounter
where it is a requirement to do so. For now, we simply assume that it
is possible to convert the DRA output to a state-space system having
a diagonal NA matrix and a NB matrix comprising only units values. We
furthermore sort the diagonal of the NA matrix so that the integrator
state is the bottom entry of the xaug[x] vector. With these transfor-
mations, the model state equation can be visualized as drawn in
Fig. 6.13, which shows a model having four states plus an integrator
state. With this conﬁguration, which we ﬁnd works quite well in prac-
tice, a state update is performed with four multiplications (we don’t
need to multiply by one for the integrator state) and ﬁve additions,
which is computationally very fast.
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
Integrator state
Four general−purpose
states modeling all
nonintegral internal
cell dynamics
Model input = current
Input
matrix
Prior
states
New
states
1
1
1
1
Figure 6.13: Visualizing the state
equation.
The linear output equation can be visualized as drawn in Fig. 6.14.
The number of rows in y[k] depends on the number of transfer func-
tions the user has requested that the DRA produce. The example
represented in Eq. (6.54) had 24 outputs, so the NC matrix would be
24 × 5 in size. The NC matrix is generally full, without structure, ex-
cept that we know that the column associated with the integrator
state is zero except for outputs that have an integration component.
These multiply-by-zeros could be skipped in an implementation.
Also, the ND matrix is generally full; however, we know that rows cor-
responding to outputs computing either ˜cs,e or ˜ce have zero entries, so
these multiplications could be skipped.
Model input = current
Linear outputs
Figure 6.14: Visualizing the output
equation.

6. reduced-order models
253
10 Doyle, M., Newman, J., Gozdz, A.S.,
Schmutz, C.N., and Tarascon, J-M,
“Comparison of Modeling Predic-
tions with Experimental Data from
Plastic Lithium Ion Cells,” Journal of
the Electrochemical Society, 143, 1996,
pp. 1890–1903.
0
300
600
900
1,200
1,500 
−20
0
20
40
Iapp(t) for UDDS proﬁle
Time (s)
Current (A)
Figure 6.16: Proﬁle of cell current
versus time for the UDDS cycle.
Overall, the process for simulating a reduced-order model is
visualized in Fig. 6.15. It is somewhat more complicated than the
equivalent-circuit-model counterpart in Fig. 2.28 but has the great
advantage of being able to compute all internal cell variables in ad-
dition to the cell voltage, whereas the equivalent-circuit model can
compute the cell voltage only.
current
Input
state
Initial
model
Linear SS
linear model
Simulate
physics variables
Linearized
parameters
Physics
corrections
Make nonlinear
cell voltage
variables and
Internal cell
Data
Computational process
Legend:
Figure 6.15: Depiction of procedural
steps used to simulate physics-based
reduced-order model.
(Adapted from Fig. 2 in Lee, J.L.,
Aldrich, L., Stetzel, K., and Plett,
G.L., “Extended Operating Range
for Reduced-Order Model of Lithium-
Ion Cells,” Journal of Power Sources, 255,
2014, pp. 85–100.)
6.12
Simulation example
In this section, we use simulation to demonstrate the performance
of the reduced-order model as compared to the full-order PDEs
describing the porous-electrode model. The parameters of the cell
being simulated are those published by Doyle et al.10 and are listed
in Table 6.1. The cell input current for the simulation is based on the
Environmental Protection Agency’s (EPA) Urban Dynamometer Driv-
ing Schedule (UDDS), which was developed to represent city driving
conditions for light-duty vehicles. Fig. 6.16 shows the UDDS proﬁle
of current versus time, scaled to achieve a maximum absolute rate of
2C, which for this cell corresponds to 41 A.
We compare the ROM results to full-order model (FOM) simu-
lations of the pseudo-2D porous-electrode model, which we imple-
mented in COMSOL Multiphysics. In all cases, the simulation is
initialized with a cell SOC of 60 %. We compute DRA outputs and
PDE outputs for the ﬁve main cell variables (j, cs,e, ce, φs, and φe) at
four different spatial locations across the cell (at both current collec-
tors and at both electrode/separator interfaces). The reduced-order
state-space model therefore has one input (cell current) and 18 linear
outputs (one for [ ˜φs-e(0, t)], two for the nonzero ˜φs(1, t) transfer func-
tions, three for the nonzero [ ˜φe(x, t)]1 transfer functions, and four for
each of the others).
When approximating the electrolyte concentration, we use eigen-
value/eigenfunction pairs λk and Ψ(x; λk) for k = 1, . . . , 10. For

254
battery management systems: volume i, battery modeling
Symbol
Units
Negative electrode
Separator
Positive electrode
L
µm
128
76
190
Rs
µm
12.5
—
8.5
A
m2
1
1
1
σ
S m−1
100
—
3.8
εs
m3 m−3
0.471
—
0.297
εe
m3 m−3
0.357
0.724
0.444
brug
—
1.5
—
1.5
cs,max
mol m−3
26,390
—
22,860
ce,0
mol m−3
2,000
2,000
2,000
θmin
—
0.05
—
0.78
θmax
—
0.53
—
0.17
Ds
m2 s−1
3.9 × 10−14
—
1.0 × 10−13
De
m2 s−1
7.5 × 10−11
7.5 × 10−11
7.5 × 10−11
t0
+
—
0.363
0.363
0.363
k
mol−1/2 m5/2 s−1
1.94 × 10−11
—
2.16 × 10−11
α
—
0.5
—
0.5
Rﬁlm
Ωm2
0.0
—
—
We compute σeff = σεbrug
s
, κeff = κεbrug
e
, De,eff = Deεbrug
e
.
In the electrolyte, conductivity is a function of concentration:
κ(ce) = 4.1253 × 10−2 + 5.007 × 10−4ce −4.7212 × 10−7c2
e
+ 1.5094 × 10−10c3
e −1.6018 × 10−14c4
e.
For the negative electrode, the open-circuit potential function is:
Uneg
ocp(θ) = −0.16 + 1.32 exp(−3.0θ) + 10.0 exp(−2,000.0θ) .
For the positive electrode, the open-circuit potential function is:
Upos
ocp(θ) = 4.19829 + 0.0565661 tanh(−14.5546θ + 8.60942)
−0.0275479
@
1
(0.998432 −θ)0.4924656 −1.90111
A
−0.157123 exp(−0.04738θ6) + 0.810239 exp[−40(θ −0.133875)].
Table 6.1: Cell parameters for simula-
tion.
(From: Doyle, M., Newman, J., Gozdz,
A.S., Schmutz, C.N., and Tarascon,
J-M, “Comparison of Modeling Pre-
dictions with Experimental Data from
Plastic Lithium Ion Cells,” Journal of
the Electrochemical Society, 143, 1996,
pp. 1890–1903.)

6. reduced-order models
255
the simulation runs presented here, the DRA high-rate sampling fre-
quency was chosen as F1 = 2 Hz and the sampling period of the com-
puted discrete-time reduced-order model was chosen as Ts = 1 s. The
computational complexity required to run the DRA and the accuracy
of the resulting reduced-order model predictions are not sensitive to
either of these parameters. We use a ROM having exactly ﬁve state
variables in its state vector xaug(t).
The ERA was used in Step 4 of the DRA (replacing the Ho–Kalman
algorithm), with the jk index set comprising
jk = { 0 . . . 4,000,
5,000 . . . 5,100,
6,000 . . .6,050,
7,000 . . .7,050,
8,000 . . .8,050,
10,000 . . .10,050,
12,000 . . .12,050,
14,000 . . . 14,050,
16,000 . . .16,050,
18,000 . . .18,050,
19,000 . . . 19,050,
20,000 . . .20,050 },
and tk = jk. This index set was not optimized, but chosen to place
a good deal of emphasis on early time samples in the unit-pulse
responses, but to also include some time samples at signiﬁcant time
delays to capture some of the slower time constants. With such a
large index set, the DRA requires signiﬁcant memory resources (to
compute the SVD) and takes considerable time. A shorter index set
could be used to reduce memory and time requirements, with some
loss in accuracy.
Results of comparing ﬂux-density predictions of this ROM to those
of the FOM at the electrode/separator interfaces are presented in
Fig. 6.17. The electrochemical reactions at the electrode/separator
interface are more dynamic than at the current collectors and are
therefore more difﬁcult for the ROM to match. Even so, the ROM and
FOM results match very well.
0
300
600
900
1,200
1,500
−40
−20
0
20
40
60
80
 
 
FOM
ROM
j at neg.-electrode/separator boundary
Time (s)
Flux density (µmol m−2 s−1)
0
300
600
900
1,200
1,500
−80
−60
−40
−20
0
20
40
 
 
FOM
ROM
j at pos.-electrode/separator boundary
Time (s)
Flux density (µmol m−2 s−1)
Figure 6.17: Butler–Volmer ﬂux at
electrode/separator boundaries.
(Adapted from Fig. 8 in Lee et al.,
Journal of Power Sources, 220, 2012,
pp. 430–448.)
Likewise, ROM versus FOM comparisons for the internal cell
potentials are presented in Fig. 6.18. They also match well.

256
battery management systems: volume i, battery modeling
0
300
600
900
1,200
1,500
−80
−60
−40
−20
0
20
40
 
 
FOM
ROM
φs at neg.-electrode/separator boundary
Time (s)
Potential (µV)
0
300
600
900
1,200
1,500
3.5
3.6
3.7
3.8
3.9
4
 
 
FOM
ROM
φs at pos.-electrode/separator boundary
Time (s)
Potential (V)
0
300
600
900
1,200
1,500
−0.45
−0.4
−0.35
−0.3
−0.25
 
 
FOM
ROM
Time (s)
Potential (V)
φe at neg.-electrode/separator boundary
0
300
600
900
1,200
1,500
−0.5
−0.45
−0.4
−0.35
−0.3
−0.25
−0.2
 
 
FOM
ROM
Time (s)
Potential (V)
φe at pos.-electrode/separator boundary
Figure 6.18: Solid- and electrolyte-phase
potentials.
(Adapted from Fig. 8 in Lee et al.,
Journal of Power Sources, 220, 2012,
pp. 430–448.)
11 This section is based on Lee, J.L.,
Aldrich, L., Stetzel, K., and Plett,
G.L., “Extended Operating Range
for Reduced-Order Model of Lithium-
Ion Cells,” Journal of Power Sources, 255,
2014, pp. 85–100.
Finally, ROM versus FOM comparisons for internal concentrations
are presented in Fig. 6.19. These do not match quite as well as the
other variables, but they match well enough to be useful.
The output cell voltage for the ROM is calculated from the elec-
trochemical variables using Eq. (6.52). The results of the ﬁfth-order
ROM and the rigorous PDE model are shown in Fig. 6.20. The cell
voltage RMS error between the FOM and the ROM is about 1 mV.
The right frame shows a detailed view of the simulation during the
period of the greatest mismatch.
6.13
Model blending
The ROM we’ve developed to this point was derived by lineariz-
ing the pseudo-2D porous-electrode PDE model around a speciﬁc
operational setpoint. However, as model dynamics can vary with
temperature and SOC, we ﬁnd that a single model is often not sufﬁ-
cient. To model the cell over a wide range of both temperature and
SOC, we use a model-blending approach.11 The basic idea is to pre-
compute ROMs at multiple state-of-charge and temperature setpoints
and then—during operation—use these to generate a best “average”
ROM specialized for the present instantaneous SOC and temperature.

6. reduced-order models
257
0
300
600
900
1,200
1,500
8,000
8,200
8,400
8,600
8,800
9,000
9,200
 
 
FOM
ROM
cs,e at neg.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
0
300
600
900
1,200
1,500
9,200
9,400
9,600
9,800
10,000
 
 
FOM
ROM
cs,e at pos.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
0
300
600
900
1,200
1,500
1,990
2,000
2,010
2,020
2,030
 
 
FOM
ROM
ce at neg.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
0
300
600
900
1,200
1,500 
1,975
1,980
1,985
1,990
1,995
2,000
2,005
2,010
 
 
FOM
ROM
ce at pos.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
Figure 6.19: Solid-surface- and
electrolyte-phase lithium concentra-
tions.
(Adapted from Figs. 8 and 9 in Lee,
J.L., Chemistruck, A., and Plett, G.L.,
“One-Dimensional Physics-Based
Reduced-Order Model of Lithium-Ion
Dynamics,” Journal of Power Sources, 220,
2012, pp. 430–448.)
0
300
600
900
1,200
1,500
3.5
3.6
3.7
3.8
3.9
4
 
 
FOM
ROM
Cell voltage
Time (s)
Voltage (V)
  0
 25
 50
 75
100
125
150
175
200
225
250
3.5
3.6
3.7
3.8
3.9
4
 
 
FOM
ROM
Cell voltage (zoom)
Time (s)
Voltage (V)
Figure 6.20: Cell voltage for UDDS test.
(Left frame adapted from Fig. 10 in
Lee, J.L., Chemistruck, A., and Plett,
G.L., “One-Dimensional Physics-Based
Reduced-Order Model of Lithium-Ion
Dynamics,” Journal of Power Sources, 220,
2012, pp. 430–448.)

258
battery management systems: volume i, battery modeling
NAk
NA0,0
NA0,1
NA1,0
NA1,1
SOC0
SOC1
T0
T1
T
SOC
Figure 6.21: Bilinear interpolation of the
NA matrix.
(Adapted from Fig. 3 in Lee, J.L.,
Aldrich, L., Stetzel, K., and Plett,
G.L., “Extended Operating Range
for Reduced-Order Model of Lithium-
Ion Cells,” Journal of Power Sources, 255,
2014, pp. 85–100.)
12 We drop the “aug” subscript in the
following, assuming that all matrices
and vectors correspond to an aug-
mented system when an integrator state
is needed.
Note that the computational requirements of creating a ROM from
a speciﬁc SOC and temperature setpoint is high; the computation
requirement of averaging precomputed ROMs is low—this approach
avoids executing the DRA to generate a ROM in real time during
operation. In this chapter we desire to use model blending to extend
the ROM’s useful SOC operating range. In Chap. 7, we will investi-
gate how models change as functions of temperature: for now, we
assume that it is possible to produce ROMs indicative of operation in
the neighborhood of a particular SOC and temperature linearization
setpoint.
Although it is considered an ad hoc method, model blending is
one of the most popular approaches to modeling nonlinear systems.
This method typically works well when the scheduling variables
change slowly during operation, as is the case with cell SOC and
temperature and when the variation in model parameter values is
smooth with respect to a change in the scheduling variables.
6.13.1
Blending the models
Individual reduced-order models are generated a priori using the
DRA over the expected operating range of temperatures and states of
charge. For simplicity, we assume that the setpoints are generated as
the Cartesian product of a temperature vector and an SOC vector, so
that they fall on a rectangular grid.
These precomputed models are blended in real time using bilinear
interpolation to generate a time-varying state-space model, as illus-
trated in Fig. 6.21. We deﬁne SOC0 to be the nearest SOC setpoint
value among the precomputed models that is less than or equal to
the cell’s present operating SOC value, and SOC1 to be the nearest
SOC setpoint that exceeds the cell’s present operating SOC value.
Similarly, we deﬁne T0 to be the nearest temperature setpoint value
among the precomputed models that is less than or equal to the cell’s
present operating temperature, and T1 to be the nearest temperature
setpoint value that exceeds the cell’s present operating temperature.
We then deﬁne blending factors θz and θT as
θz = SOC −SOC0
SOC1 −SOC0
and
θT = T −T0
T1 −T0
.
The value of the time-varying blended NAk matrix is found from12
NAk = (1 −θT)
'
(1 −θz)NA0,0 + θz NA1,0
(
+ θT
'
(1 −θz)NA0,1 + θz NA1,1
(
,
where NA0,0 is the NA matrix of the precomputed model at SOC0 and
T0, NA0,1 at SOC0 and T1, NA1,0 at SOC1 and T0, and NA1,1 at SOC1 and
T1. The time-varying blended NBk, NCk, and NDk matrices can be found

6. reduced-order models
259
in the same manner (although we see some simpliﬁcations in the
next section, which make it unnecessary to blend NBk). The state-
space equations are then modiﬁed with these time-varying blended
matrices to become
x[k + 1] = NAkx[k] + NBkiapp[k]
(6.55)
y[k] = NCkx[k] + NDkiapp[k].
(6.56)
Fig. 6.22 illustrates the real-time aspect of the overall model-
blending approach. During operation, the present cell SOC and
temperature are used to generate blended state-space matrices. The
model state vector x[k] is updated using these time-varying matrices,
and the linearized outputs y[k] are computed from the updated state
vector. The SOC calculated at each time step from the internal states
is fed back into the linear model as an input to this blending process.
current
Input
state
Initial
physics variables
Linearized
parameters
Physics
corrections
Make nonlinear
cell voltage
variables and
Internal cell
Data
Computational process
Legend:
models
linear SS
Multiple
model
Make blended
blended model
Simulate
State of charge
Figure 6.22: Simulating a cell using
model-blending approach.
(Adapted from Fig. 4 in Lee, J.L.,
Aldrich, L., Stetzel, K., and Plett,
G.L., “Extended Operating Range
for Reduced-Order Model of Lithium-
Ion Cells,” Journal of Power Sources, 255,
2014, pp. 85–100.)
6.13.2
Sorting the model
One complication when implementing the model-blending scheme
arises from the fact that state-space models are not unique. An in-
ﬁnite number of different state descriptions with corresponding
{NA, NB, NC, ND} represent the same input–output relationship. This fact
poses a potential problem when model blending because for the
method to work all elements of the matrix NA0,0 must be consistent in
meaning with the corresponding elements of the matrices NA1,0, NA0,1,
and NA1,1. If not, unrelated elements will be averaged together, pro-
ducing a meaningless result. The DRA itself does not guarantee that
models generated at different temperature and SOC setpoints will
exhibit a consistent state-space description.
There is a simple remedy, however, which is to transform all pre-
computed models into a common framework. We do so as follows.
We begin by supposing that a linear discrete-time state-space model
produced by the DRA is of the form
x(0)[k + 1] = NA
(0)x(0)[k] + NB
(0)iapp[k]

260
battery management systems: volume i, battery modeling
13 For this to be possible, the NA
(0) matrix
must be diagonalizable, requiring that
the eigenvectors in V be linearly inde-
pendent. In our experience, the output
of the DRA has always resulted in a
diagonalizable NA
(0) matrix; however,
we know of no guarantee of this. In
cases where the eigenvectors are lin-
early dependent, it is always possible
to choose a transformation to put the
NA
(1) matrix into a Jordan form, which is
what should be done instead.
y[k] = NC
(0)x(0)[k] + NDiapp[k].
The superscript “(0)” on several of the model terms indicates that
these matrices and signals arise from the untransformed model
produced directly from the DRA. We will use superscripts “(1),”
“(2),” and “(3)” in the following to indicate different stages of model
transformation.
For the ﬁrst transformation, we deﬁne a new state vector x(1)[k],
such that x(0)[k] = T(1)x(1)[k], where T(1) is some square invertible
matrix. We have an equivalent input–output relationship between
iapp[k] and y[k] if we write
x(1)[k + 1] = (T(1))−1 NA
(0)T(1)
#
$%
&
NA(1)
x(1)[k] + (T(1))−1NB
(0)
#
$%
&
NB(1)
iapp[k]
y[k] = NC
(0)T(1)
#
$%
&
NC(1)
x(1)[k] + NDiapp[k].
We have great freedom in choosing the transformation matrix T(1), so
long as it is invertible.
Consider ﬁrst choosing T(1) = V, where V is a matrix whose
columns are the eigenvectors of NA
(0). The resulting NA
(1) matrix will
be diagonal.13 The diagonal elements of NA
(1) are called the poles of
the system and represent the dynamic time constants. Already, this
ﬁrst transformation has uncovered some physical meaning in the
model. Also, the storage requirements of the transformed model
are reduced, as the n × n dimension NA
(1) matrix will contain only
n nonzero values (on its diagonal), and computation requirements
will be reduced, since only the diagonal elements of the NA matrices
need to be blended and fewer multiplies are needed to implement
NA
(1)x(1)[k] than to implement NA
(0)x(0)[k].
Since eigenvectors are unique only up to a scaling factor, we can
use this remaining degree of freedom to simplify our matrices further.
Here, we elect to normalize the NB matrix to have units value elements.
This, of course, presupposes that there are no zero elements in NB,
which is guaranteed if the system is completely controllable. The
Ho–Kalman algorithm used in the DRA always produces a minimal
state-space description, so we have this guarantee.
Thus, we then apply a second transformation, choosing T(2) =
diag(NB
(1)). In the resulting transformed model, NB
(2) contains only
ones, and NA
(2) will be unchanged from NA
(1). This transformation has
resulted in NB
(2) and NC
(2) matrices that are all scaled in a consistent
way. It also reduces storage requirements, as NB
(2) is known to always
contain only ones, which do not need to be stored. Computation has

6. reduced-order models
261
also been reduced, as the NB matrices do not need to be blended (they
are all the same) and because the multiplication NBkiapp[k] is simply a
repetition of the elements of iapp[k], without multiplication.
Finally, we choose a third transformation matrix T(3) to permute
the elements of NA
(2) such that NA
(3) remains diagonal, but its elements
appear in order of ascending magnitude. The NB
(3) matrix remains all
ones. For any particular temperature and SOC setpoint, we deﬁne
the ﬁnal scaled and sorted precomputed model as having NA = NA
(3),
NB = NB
(3) = 1n×1, and NC = NC
(3). The model ND matrix is unchanged
from the one produced by the DRA.
6.13.3
Stability of the blended model
Another concern to address is whether the model-blending method
guarantees a stable time-varying model. It is intuitively appealing
that linear time-varying combinations of stable time-invariant sys-
tems should be stable, but this is not always the case, depending on
how the systems are connected.
With the method we propose, the model blending will always
result in a stable system. To see this, consider the following. The
blended model is computed using a weighted sum of the four nearest
DRA matrices using bilinear interpolation. The state-space model can
be written
x[k + 1] = NAkx[k] + NBkiapp[k]
y[k] = NCkx[k] + NDkiapp[k]
where NAk is diagonal with diagonal entries 0 ≤aii < 1 except for
the integrator pole where aii = 1. The NBk matrix of each ROM is
<
1
1
. . .
1
=T
. The state vector, x[k], can be found as
x[k] =
,
k−1
∏
j=0
NAk−1−j
-
x[0] +
k−1
∑
i=0
,
k−i−2
∏
j=0
NAk−1−j
-
NBiiapp[i]
where NAk ≡I for k < 0. Using the triangle inequality, the inﬁnity
norm of the state vector is
∥x[k]∥∞≤
OOOOO
,
k−1
∏
j=0
NAk−1−j
-
x[0]
OOOOO
∞
+
OOOOO
k−1
∑
i=0
,
k−i−2
∏
j=0
NAk−1−j
-
NBiiapp[i]
OOOOO
∞
.
(6.57)
To demonstrate bounded-input bounded-output (BIBO) stability, we
require that the input be bounded:
OOiapp[k]
OO
∞< γ < ∞, where γ is
some arbitrary ﬁnite bounding value.

262
battery management systems: volume i, battery modeling
Note that by the operations performed in Sect. 6.13.2, the diagonal-
ization of the NAk matrix has caused the individual states to become
decoupled. In particular, every model will have the exact same inte-
grator pole value where aii = 1, which does not then require blend-
ing between models. To ensure that the time-varying model is stable,
we need look only at the nonintegrator dynamics, where 0 ≤aii < 1.
To show that a bounded input always results in a bounded output,
we look at the terms on the right-hand side of Eq. (6.57). Taking
advantage of the fact that we have diagonalized all NAk matrices, the
ﬁrst term is bounded by
OOOOO
,
k−1
∏
j=0
NAk−1−j
-
x[0]
OOOOO
∞
≤(maxa)k ∥x[0]∥∞,
where maxa = maxi,k(ak,ii) < 1. Thus, this term is always ﬁnite if
∥x0∥∞< ∞. Turning to the second term on the right-hand side of
Eq. (6.57) we have
OOOOO
k−1
∑
i=0
,
k−i−2
∏
j=0
NAk−1−j
-
NBiiapp[i]
OOOOO
∞
≤
k−1
∑
i=0
OOOOO
,
k−i−2
∏
j=0
NAk−1−j
-OOOOO
∞
OOONBiiapp[i]
OOO
∞.
(6.58)
Because all of the values in the NA matrix are less than 1, we can write
OOOOO
,
k−i−2
∏
j=0
NAk−1−j
-OOOOO
∞
≤(maxa)k−i−1 .
Eq. (6.58) is simpliﬁed to
OOOOO
k−1
∑
i=0
,
k−i−2
∏
j=0
NAk−1−j
-
NBiiapp[i]
OOOOO
∞
≤γ(maxa)k−1 k−1
∑
i=0
.
1
maxa
/i
.
The formula for the geometric series is used to give
OOOOO
k−1
∑
i=0
,
k−i−2
∏
j=0
NAk−1−j
-
NBiiapp[i]
OOOOO
∞
≤γ(maxa)k−1
⎡
⎢⎣
1 −
'
1
maxa
(k
1 −
'
1
maxa
(
⎤
⎥⎦
≤γ
⎡
⎣(maxa)k−1 −
'
1
maxa
(
1 −
1
maxa
⎤
⎦< ∞.
Both terms on the right-hand side of Eq. (6.57) are ﬁnite. Therefore,
∥x[k]∥∞< ∞.
The inﬁnity norm of the output equation is deﬁned as
∥y[k]∥∞=
OOONCkx[k] + NDkiapp[k]
OOO
∞.

6. reduced-order models
263
0
20
40
60
80
100
0.6
0.7
0.8
0.9
1.0
SOC (%)
Value
NA-matrix pole locations
0
20
40
60
80
100
−4
−2
0
2
SOC (%)
Value
NC-matrix values
0
20
40
60
80
100
−0.01
−0.005
0
0.005
0.01
SOC (%)
ND-matrix values
Value
Figure 6.23: SOC-dependent model
values.
14 Note that two ND-matrix values have
noticeably larger value at low SOC. The
blended model is capturing the SOC
dependence of the equivalent series
resistance term.
15 To reproduce these results, see http:
//mocha-java.uccs.edu/BMS1/CH06/
ROM.zip.
To show BIBO stability, this norm must be ﬁnite. Using the triangle
inequality gives
∥y[k]∥∞≤
OOONCkx[k]
OOO
∞+
OOO NDkiapp[k]
OOO
∞
≤
OOONCk
OOO
∞∥x[k]∥∞+
OOONDk
OOO
∞
OOiapp[k]
OO
∞.
Since ∥x[k]∥∞< ∞and the NCk and NDk matrices are ﬁnite, we have
that ∥y[k]∥∞< ∞, which shows BIBO stability.
6.13.4
Smoothness of the model matrices versus SOC
For the model-blending approach to work, the reduced-order state-
space model matrices must have smoothly changing parameters over
the expected SOC range. Then, blending model values via interpola-
tion between setpoints for any speciﬁc operational SOC will compute
a numeric result that is close to what would have been computed if
a dedicated ROM had been precomputed at that SOC via the DRA.
In effect, the smoothness (or lack thereof) of the model parameters
dictates the number of precomputed setpoint ROMs needed to be
able to capture the changing dynamics of the system accurately with
a blended model.
The setpoint model matrices do vary in a sufﬁciently smooth man-
ner. This is shown in Fig. 6.23 for the cell described by Table 6.1. For
each setpoint ROM, the diagonal NA matrix has one integrator term
(with “pole” equal to 1.0 in every case); the value of the remaining
four “poles” are plotted in the ﬁrst frame as a functions of SOC. We
see that all demonstrate smooth variation, such that we would expect
model blending to yield good intermediate models in-between stored
precomputed models. Similar results are shown in the ﬁgure for the
model NC- and ND-matrix values.14
6.13.5
Results from the blended model
This section presents simulation results to provide insight into the im-
pact of changing SOC.15 For this scenario, we use a charge-depleting

264
battery management systems: volume i, battery modeling
UDDS cycle, which reduces cell SOC by about 5.5 %. The cell is run
through 10 consecutive repetitions of this charge-depleting UDDS
cycle. This input is shown in the left frame of Fig. 6.24.
0
3,000
6,000
9,000
12,000
15,000
−20
−10
0
10
20
30
40
Current (A)
Proﬁle of current for repeated UDDS
Time (s)
0
3,000
6,000
9,000
12,000
15,000
3.2
3.4
3.6
3.8
4
 
 
FOM
ROM
Cell voltage
Time (s)
Voltage (V)
Figure 6.24: Cell voltage for UDDS test.
(Right frame adapted from Fig. 10 in
Lee, J.L., Aldrich, L., Stetzel, K., and
Plett, G.L., “Extended Operating Range
for Reduced-Order Model of Lithium-
Ion Cells,” Journal of Power Sources, 255,
2014, pp. 85–100.)
During the simulation, the cell discharges from 80 % to about
25 % SOC. The right frame of Fig. 6.24 depicts the ROM and FOM
predictions of cell voltage. Root-mean-squared error was 2.47 mV.
We also show cell internal variables for this simulation. Reaction
ﬂux density at the electrode/separator interfaces are presented in
Fig. 6.25. The electrochemical reactions at the electrode/separator
interface are more dynamic than at the current collectors and are
therefore more difﬁcult for the ROM to match. Even so, the ROM and
FOM results match very well.
0
3,000
6,000
9,000
12,000
15,000
−40
−20
0
20
40
60
80
 
 
FOM
ROM
j at neg.-electrode/separator boundary
Time (s)
Flux density (µmol m−2 s−1)
0
3,000
6,000
9,000
12,000
15,000
−80
−60
−40
−20
0
20
40
 
 
FOM
ROM
j at pos.-electrode/separator boundary
Time (s)
Flux density (µmol m−2 s−1)
Figure 6.25: Butler–Volmer ﬂux density
at electrode/separator boundaries.
Likewise, ROM versus FOM comparisons for the internal cell
potentials are presented in Fig. 6.26. They also match well.
Finally, ROM versus FOM comparisons for internal concentrations
are presented in Fig. 6.27. These do not match quite as well as the
other variables, but they match well enough to be useful.
Adding more states to the reduced-order model (increasing from
ﬁve states to 10 states) does not have a signiﬁcant impact on any of

6. reduced-order models
265
0
3,000
6,000
9,000
12,000
15,000
−80
−60
−40
−20
0
20
40
 
 
FOM
ROM
φs at neg.-electrode/separator boundary
Time (s)
Potential (µV)
0
3,000
6,000
9,000
12,000
15,000
3.2
3.4
3.6
3.8
4
 
 
FOM
ROM
φs at pos.-electrode/separator boundary
Time (s)
Potential (V)
0
3,000
6,000
9,000
12,000
15,000
−0.8
−0.7
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
 
 
FOM
ROM
Time (s)
Potential (V)
φe at neg.-electrode/separator boundary
0
3,000
6,000
9,000
12,000
15,000
−0.8
−0.7
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
 
 
FOM
ROM
Time (s)
Potential (V)
φe at pos.-electrode/separator boundary
Figure 6.26: Solid- and electrolyte-phase
potentials.
0
3,000
6,000
9,000
12,000
15,000
4,000
6,000
8,000
10,000
12,000
 
 
FOM
ROM
cs,e at neg.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
0
3,000
6,000
9,000
12,000
15,000
6,000
8,000
10,000
12,000
14,000
 
 
FOM
ROM
cs,e at pos.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
0
3,000
6,000
9,000
12,000
15,000
2,000
2,010
2,020
2,030
2,040
2,050
2,060
2,070
 
 
FOM
ROM
ce at neg.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
0
3,000
6,000
9,000
12,000
15,000
1,970
1,980
1,990
2,000
2,010
2,020
 
 
FOM
ROM
ce at pos.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
Figure 6.27: Solid-surface- and
electrolyte-phase lithium concentra-
tions.

266
battery management systems: volume i, battery modeling
the results except for the electrolyte concentration. Fig. 6.28 shows
simulations of these variables, which have improved greatly over the
center part of the simulation. However, despite this improvement, the
cell voltage prediction (and error) stays very nearly the same, as it is
not very sensitive to electrolyte concentration.
0
3,000
6,000
9,000
12,000
15,000
2,000
2,010
2,020
2,030
2,040
2,050
2,060
2,070
 
 
FOM
ROM
ce at neg.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
0
3,000
6,000
9,000
12,000
15,000
1,970
1,980
1,990
2,000
2,010
2,020
 
 
FOM
ROM
ce at pos.-electrode/separator boundary
Time (s)
Concentration (mol m−3)
Figure 6.28: Electrolyte-phase lithium
concentrations for a 10-state ROM.
6.14
Where to from here?
We now have a reduced-order physics-based model of cell dynamics
that agrees very closely with the continuum-scale predictions. This
model executes in very reasonable time, having only ﬁve states.
However, this model operates only around a single temperature
setpoint: we require a thermal model for lithium-ion cells. This is
what we look at next.
6.15
Modal-solution code
Perhaps the most challenging of the transfer functions to develop and
understand is the one for concentration of lithium in the electrolyte.
This section contains MATLAB code to ﬁnd eigenvalues (it produces
Fig. 6.6), eigenfunctions (it produces Fig. 6.7), and a solution assum-
ing simpliﬁed uniform reaction ﬂux density (it produces Fig. 6.8).
While we do not devote space to explaining the code, the hope is that
it can be illustrative by comparing to the equations in this chapter.
function eigenFunctions
% --------------------------------------------------------------------
% Simulate electrolyte concentration equation:
% Declare simulation parameters
Tfinal = 10; % total length of current pulse [s]
dt = 0.001;
% time step for PDE solution [s]
i_app = 10;
% cell applied current [A]
modes = 10;
% number of eigenvalue terms in modal solution

6. reduced-order models
267
% Declare cell parameters (Doyle cell)
La = 128; Ls = 76; Lc = 190; L = La+Ls+Lc; % widths, in micro-meters
dx = 1e-6; % 1 micro-meter
La_abs = La*dx; Lc_abs = Lc*dx; Ls_abs = Ls*dx; L_abs = L*dx;
L1 = La_abs; L2 = La_abs+Ls_abs;
A = 1; % cell area of 1 m^2
eps1 = 0.357; eps2 = 0.724; eps3 = 0.444; % vol frac, D per region
D = 7.5e-11; D1 = D*eps1^1.5; D2 = D*eps2^1.5; D3=D*eps3^1.5;
tplus = 0.363; % transference number [u/l]
c0 = 1000; % initial electrolyte concentration [mol/m3]
Far = 96485; % Faraday's constant
% --------------------------------------------------------------------
% First, simulate PDE solution using built-in MATLAB solver
x = 0:dx:L_abs; t = 0:dt:Tfinal;
ce = pdepe(0,@pdepde,@pdeic,@pdebc,x,t);
% --------------------------------------------------------------------
% Now, find eigenfns: Compute y3prime(lambda) at x=L to find lambda
lambda = 0:1e-4:0.5;
y3prime = lambdaFn(lambda); % get derivative of y3prime at x=L
% Search for the roots of y3prime == 0: Initialize 'theRoots' to known
% eigenvalue of zero, search for eigenvalues k=2 and following
theRoots = 0; k = 2; dL=0.0001;
while 1,
if lambdaFn((k-1)*dL)*lambdaFn(k*dL)<0, % sign change!
theRoots = [theRoots,fzero(@lambdaFn,[(k-1)*dL k*dL])]; %#ok<AGROW>
if length(theRoots)>modes, break; end
end
k = k+1;
end
% compute the eigenfunctions for these eigenvalues, then normalize
Psi = eigenFunction(theRoots(1:modes+1)');
epsX = zeros(1,L+1); epsX((0:La)+1) = eps1;
epsX((La:La+Ls)+1) = eps2; epsX((La+Ls:L)+1) = eps3;
for k = 1:modes+1, % normalize
Psi(k,:) = Psi(k,:)/sqrt(trapz((0:L)*dx,Psi(k,:).^2.*epsX));
end
% --------------------------------------------------------------------
% Next, find the modal solution
c_en = zeros([modes+1 Tfinal/dt+1]);
Afact = theRoots(1:modes+1)'; Bfact = 0*Afact;
for k = 1:length(Afact),
v1 = zeros(size(epsX));
v1((0:La)+1) = (1-tplus)/(Far*A*La_abs);
v1((La+Ls:L)+1) = -(1-tplus)/(Far*A*Lc_abs);
Bfact(k) = trapz((0:L)*dx,Psi(k,:).*v1);
end
c_en(1,1) = c0*trapz((0:L)*dx,Psi(1,:).*epsX);
% Simulate the c_{e,n} ODEs using Euler's forward method
for t = 2:size(c_en,2),
c_en(:,t) = c_en(:,t-1) + dt*(-Afact.*c_en(:,t-1)) + dt*i_app*Bfact;
end
tstep = size(c_en,2); % time step at which to examine solution
modeApprox = c0 + c_en(2:end,tstep)'*Psi(2:modes+1,:);

268
battery management systems: volume i, battery modeling
% --------------------------------------------------------------------
% Plot results
figure(1); clf; plot(lambda,y3prime/1e5,'-',[0 0.5],[0 0],'k:');
title('Slope of PSI(Ltot,L)');
xlabel('Eigenvalue guess L'); ylabel('Slope (x1e5)');
figure(2); clf; plot(0:L,c0+ce(tstep,:),'r',0:L,modeApprox,'b--');
yl = ylim; xlim([0 L]); hold on;
title('Final concentration profile');
xlabel('Position across cell (um)'); ylabel('Conc. (mol/m3)');
legend('PDE solution',sprintf('Solution for modes 0:%d',modes));
plot([0 L],[1000 1000],'k:',[La La],yl,'k:',[La+Ls La+Ls],yl,'k:');
if modes > 5,
figure(3); clf; plot(0:L,Psi(1:6,:)'); yl = ylim; xlim([0 L]);
title('Eigenfunctions 0 through 5'); hold on;
xlabel('Position across cell (um)'); ylabel('Value (m^{-1})');
plot([La La],yl,'k:',[La+Ls La+Ls],yl,'k:'[0 L],[0 0],'k:');
end
% --------------------------------------------------------------
% Eigenfunction solver helper functions
function y3prime = lambdaFn(lambda)
% "k" values solved symbolically based on normalizing constant k1
k1 = 1; sle1 = sqrt(lambda*eps1/D1);
sle2 = sqrt(lambda*eps2/D2); sle3 = sqrt(lambda*eps3/D3);
k3 = k1.*(cos(sle1*L1).*cos(sle2*L1) + ...
D1*sle1.*sin(sle1*L1).*sin(sle2*L1)./(D2*sle2));
k4 = k1.*(cos(sle1*L1).*sin(sle2*L1) - ...
D1*sle1.*cos(sle2*L1).*sin(sle1*L1)./(D2*sle2));
k5 = k3.*(cos(sle2*L2).*cos(sle3*L2) + ...
D2*sle2.*sin(sle2*L2).*sin(sle3*L2)./(D3*sle3)) + ...
k4.*(sin(sle2*L2).*cos(sle3*L2) - ...
D2*sle2.*cos(sle2*L2).*sin(sle3*L2)./(D3*sle3));
k6 = k3.*(cos(sle2*L2).*sin(sle3*L2) - ...
D2*sle2.*sin(sle2*L2).*cos(sle3*L2)./(D3*sle3)) + ...
k4.*(sin(sle2*L2).*sin(sle3*L2) + ...
D2*sle2.*cos(sle2*L2).*cos(sle3*L2)./(D3*sle3));
y3prime = -k5.*sle3.*sin(sle3*L_abs) + k6.*sle3.*cos(sle3*L_abs);
y3prime(lambda == 0) = 0;
end
function Psi = eigenFunction(lambda)
% "k" values solved symbolically based on normalizing constant k1
k1 = 1; sle1 = sqrt(lambda*eps1/D1);
sle2 = sqrt(lambda*eps2/D2); sle3 = sqrt(lambda*eps3/D3);
k3 = k1.*(cos(sle1*L1).*cos(sle2*L1) + ...
D1*sle1.*sin(sle1*L1).*sin(sle2*L1)./(D2*sle2));
k4 = k1.*(cos(sle1*L1).*sin(sle2*L1) - ...
D1*sle1.*cos(sle2*L1).*sin(sle1*L1)./(D2*sle2));
k5 = k3.*(cos(sle2*L2).*cos(sle3*L2) + ...
D2*sle2.*sin(sle2*L2).*sin(sle3*L2)./(D3*sle3)) + ...
k4.*(sin(sle2*L2).*cos(sle3*L2) - ...
D2*sle2.*cos(sle2*L2).*sin(sle3*L2)./(D3*sle3));
k6 = k3.*(cos(sle2*L2).*sin(sle3*L2) - ...
D2*sle2.*sin(sle2*L2).*cos(sle3*L2)./(D3*sle3)) + ...
k4.*(sin(sle2*L2).*sin(sle3*L2) + ...
D2*sle2.*cos(sle2*L2).*cos(sle3*L2)./(D3*sle3));
Psi = zeros(length(lambda),L+1);

6. reduced-order models
269
x = 0:La;
Psi(:,x+1) = k1.*cos(sle1*x*dx);
x = La:La+Ls;
Psi(:,x+1) = k3(:,ones(size(x))).*cos(sle2*x*dx) + ...
k4(:,ones(size(x))).*sin(sle2*x*dx);
x = La+Ls:L;
Psi(:,x+1) = k5(:,ones(size(x))).*cos(sle3*x*dx) + ...
k6(:,ones(size(x))).*sin(sle3*x*dx);
Psi(lambda == 0,:) = k1;
end
% --------------------------------------------------------------
% PDE solver helper functions
function [c,f,s] = pdepde(x,~,~,DuDx)
if x <= La_abs,
c = eps1; f = D1*DuDx; s = (1-tplus)*i_app/(Far*A*La_abs);
elseif x <= La_abs+Ls_abs,
c = eps2; f = D2*DuDx; s = 0;
else
c = eps3; f = D3*DuDx; s = -(1-tplus)*i_app/(Far*A*Lc_abs);
end
end
function u0 = pdeic(~) % initial conditions
u0 = 0; % initialize to 0, and add in c0 later for better numerics
end
function [pl,ql,pr,qr] = pdebc(~,~,~,~,~) % boundary conditions
pl = 0; ql = 1; pr = 0; qr = 1;
end
end
6.16
Partial glossary
This section provides a glossary of the most important variables
deﬁned in this chapter.
• ce,0 [mol m3] is the steady-state concentration of lithium in the
electrolyte when the cell is at rest (cf. p. 219).
• ˜ce(x, t) [mol m3] is the debiased concentration of lithium in the
electrolyte: ˜ce = ce −ce,0 (cf. p. 229).
• cs,avg(t) [mol m3] is the average concentration of lithium in an
electrode (cf. p. 245).
• cs,0 [mol m3] is the steady-state concentration of lithium in the
electrode solid particles at a particular setpoint cell state-of-charge
(cf. p. 219).
• ˜cs,e(x, t) [mol m3] is the debiased solid-surface concentration of an
electrode particle: ˜cs,e = cs,e −cs,0 (cf. p. 220).
• [˜cs,e(x, t)]∗[mol m3] is the debiased solid-surface concentration of
an electrode particle, with its integrator term removed (cf. p. 225).
• h(t; λ) [mol m−2] is the time-varying part of a separation-of-
variables PDE solution (cf. p. 233).

270
battery management systems: volume i, battery modeling
• iapp(t) [A] is the cell applied current (cf. p. 221).
• j0 [mol m2 s−1] is the steady-state exchange ﬂux density of lithium
between solid and electrolyte when the cell is at rest (cf. p. 219).
• jn(t) [mol m−3 s−1] is the modal input to ˜ce,n(t) (cf. p. 237).
• λ [s−1] is an eigenvalue relating to one solution of a Sturm–
Liouville problem, used in a separation-of-variables PDE solution
(cf. p. 233).
• ν(s) [u/l] is a square-root impedance ratio that is common to all
the electrochemical-variable transfer functions (cf. p. 223).
•
˜φe(x, t) [V] is the debiased electrolyte potential: ˜φe(x, t) = φe(x, t) −
φe(0, t) (cf. p. 242).
• [ ˜φe(x, t)]1 [V] is the linear portion of ˜φe(x, t) (cf. p. 242).
• [ ˜φe(x, t)]2 [V] is the nonlinear portion of ˜φe(x, t) (cf. p. 242).
•
˜φs(x, t) [V] is the debiased solid potential: ˜φs = φs −φs(0) where
φs(0) is the potential of the solid at the current-collector interface:
φneg
s
(0) = 0 and φpos
s
(0) = v(t) (cf. p. 227).
• φs-e(x, t) [V] is the solid–electrolyte potential difference (cf. p. 219).
•
˜φs-e(x, t) [V] is the debiased solid–electrolyte potential difference:
˜φs-e = φs-e −Uocp(cs,0) (cf. p. 220).
• [ ˜φs-e(x, t)]∗[V] is the debiased solid–electrolyte potential differ-
ence, with its integrator term removed (cf. p. 225).
• Ψ(x; λ) [m−1] is the spatially varying part of a separation-of-
variables PDE solution (cf. p. 233).
• Rct [Ωm2] is the charge-transfer resistance of an electrode particle
(cf. p. 220).
• Rﬁlm [Ωm2] is the resistance of a surface ﬁlm on an electrode parti-
cle (cf. p. 218).
• Rs,e [Ωm2] is the total solid–electrolyte interfacial resistance of an
electrode particle (cf. p. 220).
• z [u/l] is a dimensionless value between 0 and 1 indicating a spa-
tial location in an electrode. z = 0 at the current collector and
z = 1 at the electrode/separator interface (cf. p. 221).

7.1
Preliminary deﬁnitions . . . 272
7.2
Microscale model . . . . . . . 273
7.3
Continuum model . . . . . . 277
7.4
Parameter variation . . . . . 280
7.5
Reduced-order model. . . . . 281
7.6
New transfer functions . . . 281
7.7
Heat-generation terms . . . . 285
7.8
Heat-ﬂux terms . . . . . . . . 292
7.9
Uncoupled model results . . 296
7.10 Coupled model results . . . . 297
7.11 Where to from here? . . . . . 298
7.12 Partial glossary . . . . . . . . 300
7
Thermal Modeling
Up until now we have assumed that the cell we are modeling is at
a constant temperature, which is rarely the case in reality. When
considering thermal aspects of real cells, we must account for how
usage of the cell generates (or sinks) heat, how local temperature
changes due to heat generation or consumption, ﬂow of heat within
the cell and to/from the environment at cell boundaries, and how cell
operational parameters change as a function of cell temperature.
In this chapter, we consider thermal aspects of battery-cell perfor-
mance, resulting in a reduced-order coupled electrochemical–thermal
model. We start by deﬁning some important fundamental terms and
then develop a microscale thermal model. We will not go back to
ﬁrst principles quite the same way we did in Chap. 3, as that would
require far more development than we’re willing to discuss in this
book. However, we will point the reader to references that can help
with the underlying thermal physics.
In particular, we ﬁrst derive an equation that describes thermal
activity in a single phase k at the microscale
ρkcP,k
∂Tk
∂t = ∇· (λk∇Tk) −ik · ∇φk.
(7.1)
We then use volume-averaging techniques to describe thermal activity
at the continuum scale, which is modeled as
∂(ρcPT)
∂t
= ∇· (λ∇T) + q.
(7.2)
The heat-generation terms are also discussed in some detail.
After these PDE models are derived, we show how to make
reduced-order models of the heat-generation terms by leveraging
some of the same techniques already seen in Chaps. 5–6 and how to
make a reduced-order model of Eq. (7.2) with q as its input. Last, we
look at how to make a dynamic cell model that operates over a wide
temperature range.
271

272
battery management systems: volume i, battery modeling
1 Schroeder, D., An Introduction to Ther-
mal Physics, Addison Wesley, Chap. 1,
2000.
2 Blundell, S.J., and Blundell, K.M.,
Concepts in Thermal Physics, Oxford
University Press, 2d, Chap. 2, 2010.
7.1
Preliminary deﬁnitions
According to thermodynamic theory, temperature is a measure of the
tendency of an object to give up energy to its surroundings sponta-
neously. When two objects are in thermal contact, the one that tends
to lose energy spontaneously is at the higher temperature.1 If we are
precise, we can write
1
T =
. dS
dU
/
n,V
,
relating temperature T to entropy S and internal energy U when the
number of particles and volume are held constant.
A simpler (but less precise) deﬁnition of temperature relates it
to the translational kinetic energy associated with the disordered
microscopic translational motion of atoms or molecules in a system.
(It does not consider the potential energy of the system.) According
to this deﬁnition of kinetic temperature,
@1
2mv2
A
average
= 3
2kT,
where k is the Boltzmann constant. While this conceptual deﬁnition
of temperature has some problems, it will be sufﬁcient to understand
this chapter.
Heat can be deﬁned as “thermal energy in transit.”2 We talk about
heat ﬂux and mean that thermal energy is moving from one place to
another, tending to change the temperatures of the source and desti-
nation. We talk about heat generation and mean that thermal energy
is being added to a system, tending to increase its temperature. We
talk about a heat sink and mean that thermal energy is being removed
from a system, tending to decrease its temperature.
There are various mechanisms by which thermal energy can travel:
conduction, convection, and radiation. Conduction is the transfer
of thermal energy within a system, molecule by molecule, as one
molecule imparts energy to its neighbor. If you hold a metal cooking
pot over a ﬁre, it will absorb the energy from the ﬂame (via radia-
tion energy transfer). The molecules absorbing the energy will begin
to vibrate more quickly, bumping into the molecules next to them,
increasing their energy, and so forth. As this process continues, the
heat is transferred from the part directly over the ﬁre to the extremi-
ties of the pot.
The ability of a material to conduct heat depends on its macro-
scopic and microscopic structure. Styrofoam cups and double-paned
windows are good thermal insulators because air pockets captured by
the styrofoam beads and gas pockets between window panes do not

7. thermal modeling
273
3 For ordinary temperatures—less
than “red hot”—the radiation is in the
infrared region of the electromagnetic
spectrum.
conduct heat very well. On the other hand, metals are good thermal
conductors due to the tight internal bonding of their atoms. This is
why a metal plate seems cold when you touch it—it conducts body
heat away from your hand quickly.
Convection is the transfer of thermal energy due to the mass move-
ment of a ﬂuid (liquid or gas) arising from a pressure gradient. Natu-
ral convection is a function of density: warm ﬂuids are less dense than
cold ﬂuids, so warm ﬂuids tend to rise while cold ﬂuids fall. Forced
convection relies on a fan or pump to augment the natural pressure
gradient to speed ﬂuid movement. To extend the prior example, wa-
ter in the metal cooking pot that is being held over a ﬁre will begin to
move via convection, transferring heat.
An object is cooled via convection when a thin layer of ﬂuid in
contact with it is ﬁrst heated via conduction. Conduction alone does
not account for the cooling, however, as ﬂuids are generally poor
conductors of thermal energy. Instead, the thin layer of ﬂuid heated
by conduction carries the heat away from the system by convection;
this cycle repeats when a new cooler layer of ﬂuid takes its place.
Different ﬂuids have different abilities to remove heat, with liquids
generally having a greater capacity than gases.
Radiation is the transfer of thermal energy via electromagnetic
waves.3 Radiation does not rely upon any contact between the heat
source and the heated object as is the case with both conduction and
convection. No mass is exchanged and no medium is required in the
process of radiation: heat can be transmitted though empty space.
This energy is absorbed when these waves encounter an object. For
example, energy traveling from the sun to your skin: you can feel
your skin getting warmer as energy is absorbed.
7.2
Microscale thermal model
7.2.1
Enthalpy
Before deriving the microscale thermal model, a concept that needs
further development is that of enthalpy. This was introduced in
Chap. 3 as one of the four quantities known as the thermodynamic
potentials of a system. Enthalpy is particularly useful here as it can be
thought of as the total amount of energy stored by the system that
could be released as heat.
For example, if enthalpy H increases, then ∆H > 0, and the sys-
tem has received energy that could be released as heat. If enthalpy
decreases, ∆H < 0, and the system has released energy in the form of
heat. So, ∆H must be proportional to a change in internal energy due
to heat, ∆q.

274
battery management systems: volume i, battery modeling
4 Gu, W.B., and Wang, C.Y., “Thermal-
Electrochemical Modeling of Battery
Systems,” Journal of the Electrochemical
Society, 147(8), 2000, pp. 2910–2922.
5 Bird, R.B., Stewart, W.E., and Lightfoot,
E.N., Transport Phenomena, 2d, John
Wiley and Sons, 2002. This result is
from Table 19.2-4, entry (F) in Bird’s
book, combined with Bird 19.3-6, as
derived in Gu and Wang.
1,000
0.01
0.1
1
10
100
Thermal conductivity (W m−1 K−1)
Gases
Liquids
Insulation
Nonmetallic solids
Alloys
Metals
Figure 7.1: Range of thermal conductivi-
ties for different kinds of materials.
Enthalpy is related to internal energy but is not equal to internal
energy because the ﬁrst law of thermodynamics states
∆U = ∆q + ∆w ̸= ∆q.
To remove the ∆w term, enthalpy is deﬁned as H ≡U + pV and is
most useful for constant-pressure calculations. This is not a major
constraint as many chemical reactions may be considered to occur
under (constant) atmospheric pressure, so we may regard them as
constant pressure processes.
The change in enthalpy due to a chemical reaction is then the heat
released by the reaction, as we show in the following sketch:
dH = dU + d(pV) = dU + p dV + V dp = dU + p dV
= dq + dw + p dV = dq −p dV + p dV = dq.
7.2.2
General thermal energy equation
With this introduction, we are ready to proceed to the rest of the
derivation, based on a paper by Gu and Wang.4 We begin with a
general differential equation result for thermal energy balance that
considers multiple species in multiple phases (such as in a battery
cell with solid and electrolyte phases, and having electronic and ionic
species), based on ﬁrst principles:5
ρkcP,k
.∂Tk
∂t + vk · ∇Tk
/
= ∇· (λk∇Tk) −∑
species i
jk,i · ∇Hk,i.
(7.3)
Heat generation is apparently absent from this PDE because it is a
phenomena that occurs at the boundary between phases due to chem-
ical reactions occurring there. We will introduce its impact when we
consider boundary conditions in the continuum-scale model.
The ﬁrst term on the left-hand side of Eq. (7.3) models energy
storage in phase k as an increase in temperature, where ρk is the
density of phase k, cP,k is the speciﬁc heat of phase k, and Tk is the
temperature of phase k.
The second term on the left-hand side of Eq. (7.3) is a convection
term—local energy changes because warmer or colder materials ﬂow
into the region of interest. In this term, vk is the average velocity of
the mixture.
The ﬁrst term on the right-hand side models heat ﬂux due to ther-
mal diffusion, where λk is the thermal conductivity of phase k. Conduc-
tivities of some materials are illustrated in Fig. 7.1. Battery materials
have typical thermal conductivities around 5 W m−1 K−1.
The second term on the right-hand side models heat ﬂux due to
material ﬂux, where jk,i is the molar ﬂux density due to diffusion and

7. thermal modeling
275
6 The type of convection being consid-
ered here is movement of a species
within a particular phase internal to the
battery cell due to a pressure gradient.
This is different from convective heat
transfer, which occurs at the bound-
ary of the cell (and will be considered
later).
migration of species i in phase k, relative to the mixture’s average
velocity vk, and Hk is the partial molar enthalpy of species i in phase
k, where Hk = Uk + pVk.
We assume that convection within a phase is negligible and drop it
from the equation, giving6
ρkcP,k
∂Tk
∂t = ∇· (λk∇Tk) −∑
species i
jk,i · ∇Hk,i.
7.2.3
Evaluating the partial molar enthalpy term
To proceed, we need to be able to work with the Hk term. Starting
with the deﬁnition of partial molar enthalpy, we write (cf. Table 3.1)
Hk,i =
. dH
dnk,i
/
T,p,nj̸=k,i
=
.d(G + TS)
dnk,i
/
T,p,nj̸=k,i
=
. dG
dnk,i
/
T,p,nj̸=k,i
+ T
. dS
dnk,i
/
T,p,nj̸=k,i
.
Recall that the ﬁrst term is equal to the electrochemical potential
¯µi. To evaluate the second term, we need the Gibbs–Duhem relation-
ship via Eq. (3.15):
SdT −Vdp = −
r
∑
i=1
nid ¯µi
S = V dp
dT −
r
∑
i=1
ni
d ¯µi
dT
. dS
dnk,i
/
T,p,nj̸=k,i
= −d ¯µk,i
dT .
Combining, we have
Hk,i = ¯µk,i −T
.d ¯µk,i
dT
/
p,nj
.
Now, recall one deﬁnition of the electrochemical potential, via
Eqs. (3.13) and (3.17):
¯µk = RT ln(λk) + zkFφk
Hk,i = RT ln(λk,i) + zk,iFφk,i −T d(RT ln(λk,i) + zk,iFφk,i)
dT
= RT ln(λk,i) + zk,iFφk,i −T dRT ln(λk,i)
dT
−zk,iFT dφk,i
dT
= RT ln(λk,i) −T
.
R ln(λk,i) + RT d ln(λk,i)
dT
/
+ zk,iF
.
φk,i −Tdφk,i
dT
/

276
battery management systems: volume i, battery modeling
7 Newman, J., “Thermoelectric Effects in
Electrochemical Systems,” Industrial &
Engineering Chemical Research, 24, 1995,
pp. 3208–3216.
= −RT2 d ln(λk,i)
dT
+ zk,iF
.
φk,i −T dφk,i
dT
/
.
Continuing with the gradient term that we need,
∇Hk,i = −R∇
.
T2 d ln(λk,i)
dT
/
+ zk,iF∇
.
φk,i −T dφk,i
dT
/
.
The ﬁrst term is closely related to the enthalpy of mixing and is gen-
erally ignored in practice. We also ignore the temperature depen-
dence of phase potential. So, we approximate
∇Hk,i = zk,iF∇φk.
Substituting this into the prior relationship,
ρkcP,k
∂Tk
∂t = ∇· (λk∇Tk) −∑
species i
zk,iFjk,i · ∇φk.
Noting that the current through phase k results from diffusion and
migration of ionic species in the phase under the assumption of elec-
troneutrality where
ik =
∑
species i
zk,iFjk,i,
we can rewrite the relationship as
ρkcP,k
∂Tk
∂t = ∇· (λk∇Tk) −ik · ∇φk.
We have now derived Eq. (7.1).
7.2.4
Boundary conditions
As we have seen before, any PDE must be accompanied by suitable
boundary conditions in order to simulate its dynamics. Here, we
are concerned about the boundary between the electrolyte and solid
phases.
In a nontrivial derivation, it can be shown that:7
λe∇Te · ˆne + λs∇Ts · ˆns = Fjη + FjΠ,
(7.4)
where ˆne is a unit normal vector pointing from the electrolyte into
the solid at the boundary, and ˆns is a unit normal vector pointing
from the solid into the electrolyte at the boundary. Subscript “e”
refers to electrolyte and subscript “s” refers to solid. The terms j and
η are the Butler–Volmer ﬂux density and Butler–Volmer overpotential,
as we have seen previously, and Π is the Peltier coefﬁcient, which is
equal to
Πj = T ∂Uocp,j
∂T
.

7. thermal modeling
277
0
0.2
0.4
0.6
0.8
1.0
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
Entropy of electrode materials
Electrode SOC
 
 
Graphite
LFP
LMO
∂Uocp/∂T (mV K−1)
Figure 7.2: Partial molar entropy of
some common electrode materials.
The partial molar entropy term ∂Uocp,j/∂T has to do with change
in open-circuit potential as temperature varies. At different stages
of lithiation, more or less order is produced by lithiation, so heat is
either generated or sunk. Some representative curves for different
materials are shown in Fig. 7.2.
The left-hand side of Eq. (7.4) is the sum of the heat ﬂux into the
solid and into the electrolyte. This heat must be generated at the
solid–electrolyte interface. The jη term models irreversible heat gener-
ation due to chemical reactions at the interface and is always positive.
The jΠ term models reversible heat generation and can either be
positive or negative. We will see how to evaluate these terms in the
next section.
7.3
Continuum thermal model
Now that the microscale thermal model has been developed, our
next goal is to use volume averaging over the phases to arrive at
a continuum-scale model. Starting with Eq. (7.1), we use volume-
averaging theorem 3 on the left-hand side of the equation. We as-
sume that the solid–electrolyte phase boundary is not moving, and
get
ρkcP,k
@∂Tk
∂t
A
= 1
εk
ρkcP,k
∂(εk ¯Tk)
∂t
.
We then use volume-averaging theorem 2 on the ﬁrst term of the
right-hand side of the equation:
∇· (λk∇Tk) = 1
εk
@
∇· (εkλk∇Tk) + 1
V
ˆ
Ase
(λk∇Tk) · ˆnk dA
A
.
We will model εkλk∇Tk ≈λeff,k∇Tk, where λeff,k = λkεbrug
k
, and
will assume that the integrand is constant within the small volume V,
giving
∇· (λk∇Tk) ≈1
εk
@
∇· (λeff,k∇Tk) + Ase(λk∇Tk) · ˆnk
V
A
= 1
εk
[∇· (λeff,k∇Tk) + as(λk∇Tk) · ˆnk] .
The second term on the right-hand side of Eq. (7.1) is more tricky,
because we don’t have a volume-averaging theorem to help with it.
Gu and Wang handle it by “completing the square.” Consider:
(ik −¯ik) · (∇(φk −¯φk)) = [ik · ∇φk] −[ik · ∇¯φk] −[¯ik · ∇φk] + [¯ik · ∇¯φk].
This allows us to write the term of interest as
[ik · ∇φk] = [ik · ∇¯φk] + [¯ik · ∇(φk −¯φk)] + (ik −¯ik) · (∇(φk −¯φk)).

278
battery management systems: volume i, battery modeling
We take volume averages of this equation term by term. Because
∇¯φk is a constant, the volume average of the ﬁrst term is
[ik · ∇¯φk] = 1
Vk
ˆ
Vk
[ik · ∇¯φk] dV
=
. 1
Vk
ˆ
Vk
ik dV
/
· ∇¯φk
= ¯ik · ∇¯φk.
For the second term, we use volume-averaging theorem 1:
[¯ik · ∇(φk −¯φk)] = ¯ik · ∇( ¯φk −¯φk)
#
$%
&
0
+¯ik · 1
V
ˆ
Ase
(φk −¯φk) ˆnk dA,
where Gu and Wang show that the integral term is small compared
to the other terms, and so this entire expression is dropped.
For the third term, we use the deﬁnition of volume averaging:
(ik −¯ik) · (∇(φk −¯φk)) = 1
Vk
ˆ
Vk
(ik −¯ik) · (∇(φk −¯φk)) dV.
Gu and Wang did not give any advice for how to evaluate this term
but omitted it from their ﬁnal result, assuming it was negligible.
Combining all results to date:
1
εk
ρkcpk
∂(εkTk)
∂t
= 1
εk
[∇· (λeff,k∇Tk) + as(λk∇Tk) · ˆnk] −¯ik · ∇¯φk.
We now assume that local thermal equilibrium exists in the sys-
tem, meaning that
Ts = Te = T,
and sum the above equation over the solid and electrolyte phases,
giving Eq. (7.2):
∂(ρcPT)
∂t
= ∇· (λ∇T) + q
where
ρcP = ∑
k∈{s,e}
εkρkcP,k
λ = ∑
k∈{s,e}
λeff,k,
and the heat-generation term q is given by
q =
∑
reaction j
asF¯j( ¯ηj + ¯Πj) −
∑
species k
εk¯ik · ∇¯φk.
Recall from Eq. (4.18) that the volume-averaged current density
through the electrolyte phase is
εe¯ie = −κeff∇¯φe −κD,eff∇ln ¯ce.

7. thermal modeling
279
8 Note the different units: qc had units
W m−2. This heat-generation term
applies only to current-collector to
electrode contact region, and is speci-
ﬁed per unit area rather than per unit
volume.
Similarly, recall from Eq. (4.14) that the volume-averaged current
density through the solid phase is
εs¯is = −σeff∇¯φs.
Summarizing (and removing overlines from volume-averaged quan-
tities to clean up notation), heat-generation terms that can be consid-
ered in a model (with units W m−3) include:
• Irreversible heat generation due to chemical reactions: qi = asFjjηj
for each chemical reaction j that takes place at the interface,
• Reversible heat generation due to change in entropy: qr = asFjjT
∂Uocp,j
∂T
for each chemical reaction j that takes place at the interface,
• Joule heating due to electrical potential gradient in the solid:
qs = σeff(∇φs · ∇φs), and
• Joule heating due to electrochemical potential gradient in elec-
trolyte: qe = κeff(∇φe · ∇φe) + κD,eff(∇ln ce · ∇φe).
Sometimes, we also include heat generation due to contact resistance,
qc = i2appRcontact.8 Heat generation within the current collectors
themselves due to electrical resistance of the aluminum or copper
sheets is small but can be included by simply lumping it in with the
contact resistance.
7.3.1
Transfer of heat at boundaries
At the cell boundaries, there are three methods we consider by which
heat can be conducted into or out of the cell: convection, conduction,
and radiation. Conduction can be modeled as a ﬁxed temperature
speciﬁed at surface. In one dimension, we can write
T(x, t)|x=0 = T0,
and
T(x, t)|x=L = TL.
It can also be modeled as a ﬁxed heat ﬂux at the surface:
−λ ∂T(x, t)
∂x
++++
x=0
= q0,
and
λ ∂T(x, t)
∂x
++++
x=L
= qL,
where the sign of the derivatives ﬂip at x = L to reﬂect the conven-
tion of heat ﬂux into the surface as positive. A special case is the
adiabatic (or insulated) surface for which
∂T(x, t)
∂x
++++
x=0
= 0
and/or
∂T(x, t)
∂x
++++
x=L
= 0.
The second type of boundary condition is convection, in which
the heat ﬂux to/from the surface is proportional to the difference

280
battery management systems: volume i, battery modeling
between the surface temperature and an ambient ﬂuid temperature,
which we denote as T∞
−λ ∂T(x, t)
∂x
++++
x=0
= h
,
T∞−T(0, t)
-
λ ∂T(x, t)
∂x
++++
x=L
= h
,
T∞−T(L, t)
-
,
where h is the heat-transfer (or convection) coefﬁcient. The value of h
is a property of the ﬂow conditions of the ﬂuid in contact with the
surface and not a property of the surface itself.
A third type of boundary condition is radiation, which can become
signiﬁcant when the surface temperatures are relatively high. Heat
transfer to the surface via radiation can be expressed as
−λeff ∂T(x, t)
∂x
++++
x=0
= ϵσ
,
T4
∞−T4(0, t)
-
λeff ∂T(x, t)
∂x
++++
x=L
= ϵσ
,
T4
∞−T4(L, t)
-
,
where ϵ [unitless] is the surface emissivity, and σ = 5.670373 ×
10−8 W m−2 K−4 is the Stefan–Boltzmann constant.
The challenge created by this boundary condition is that tempera-
ture appears in the fourth power, which makes the problem nonlinear
in T and eliminates most hopes of ﬁnding an analytical solution. One
way to deal with this is to linearize the radiation rate law via a ﬁrst-
order Taylor-series expansion, giving
T4
∞−T4
s ≈4T3
∞(T∞−Ts),
where Ts represents the temperature of either surface. The quantity
4ϵσT3
∞can now be viewed as a linearized radiation heat transfer
coefﬁcient, denoted hrad.
7.4
Parameter temperature variation
Many parameters in the cell model we have developed so far have
values that are temperature dependent. This is usually modeled by
the (empirical) Arrhenius relationship, which relates some property
of the cell at present temperature T, Φ(T), to that property at a refer-
ence temperature Tref, Φref via an exponential function with activation
energy E0:
Φ(T) = Φref exp
@ E0
R
. 1
Tref
−1
T
/A
.
(7.5)

7. thermal modeling
281
9 Special thanks to Matt Aldrich for
helping to develop and verify the
reduced-order model equations and for
providing data for the examples.
7.5
Reduced-order model
To create a reduced-order thermal model, we must be able to do three
things:9
1. Accurately approximate the four heat-generation terms listed at
the end of Sect. 7.3, resulting in a total heat-generation term q.
2. Use the predicted value of q in an approximation to Eq. (7.2) to
model change in cell average temperature.
3. Blend models created at different temperature setpoints to
approximate the true model having parameters determined by
Eq. (7.5).
These are described in the following sections.
7.6
Gradient transfer functions
Our ﬁrst approach to ﬁnding a reduced-order model of the heat-
generation terms might be to attempt to ﬁnd transfer functions be-
tween the applied current and the desired quantities, so that the DRA
could be used to generate a state-space model. However, there is a
fundamental problem with this approach: all four heat-generation
terms are nonlinear, so transfer functions don’t exist. Further, they
are products of terms which themselves are functions of iapp(t), and
so are essentially functions of i2
app(t), and truncating a Taylor-series
expansion will not give linearized models that are very helpful.
An approach that we ﬁnd does work well is to individually com-
pute the quantities that are ultimately multiplied together to predict
heat generation. We already know how to compute reduced-order
estimates of j(z, t) and η(z, t). We further need to be able to compute
∇φs(z, t), ∇ln ce(x, t), and ∇φe(x, t). We can ﬁnd these terms via a
transfer-function approach, as we will show in the next subsections.
7.6.1
Gradient of φs(z, t)
Recall from Chap. 6 that we deﬁned ˜φs(z, t) = φs(z, t) −φs(0, t). Then
the gradient with respect to the spatial coordinate z can be written as
∇z ˜φs(z, t) = ∇zφs(z, t) −∇zφs(0, t)
∇zφs(z, t) = ∇z ˜φs(z, t),
since φs(0, t) is not a function of a spatial dimension. Therefore, if
we can ﬁnd a transfer function for ∇z ˜φs(z, t), we can compute the
gradient we need for computing Joule heat generation in the solid.

282
battery management systems: volume i, battery modeling
Recall also from Chap. 6 the transfer function we developed for
KΦs(z, s) in the negative electrode:
KΦneg
s
(z, s)
Iapp(s)
= −Lnegκneg
eff (cosh(νneg(s)) −cosh((z −1)νneg(s)))
Aσneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
−Lnegσneg
eff (1 −cosh(zνneg(s)) + zνneg(s) sinh(νneg(s)))
Aσneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
.
Taking the derivative of this function with respect to z gives
∇z KΦneg
s
(z, s)
Iapp(s)
= Lnegσneg
eff (sinh(zvneg(s)) −sinh(vneg(s)))
Aσneg
eff (κneg
eff + σneg
eff ) sinh(νneg(s))
+
Lnegκneg
eff sinh((z −1)vneg(s))
Aσneg
eff (κneg
eff + σneg
eff ) sinh(νneg(s))
.
The gradient with respect to x can be found as
∇x KΦneg
s
(z, s)
Iapp(s)
+++++ x
L
=
. ∂z
∂x
/ ,
∇z KΦneg
s
(x/Lneg, s)
Iapp(s)
-
=
1
Lneg
,
∇z KΦneg
s
(x/Lneg, s)
Iapp(s)
-
=
:
σneg
eff (sinh(zvneg(s)) −sinh(vneg(s)))
Aσneg
eff (κneg
eff + σneg
eff ) sinh(νneg(s))
+
κneg
eff sinh((z −1)vneg(s))
Aσneg
eff (κneg
eff + σneg
eff ) sinh(νneg(s))
+++++
x
Lneg
.
In the positive electrode, the transfer function for KΦs(z, s) must
be multiplied by −1, and the gradient with respect to x must also
be multiplied by −1, so the net effect is nil. The same basic transfer
function is used for both electrodes, with the substitution of constants
appropriate for each electrode, and with z = (Ltot −x)/Lpos substi-
tuted in the positive electrode.
7.6.2
Gradient of ln ce(x, t)
We need to be able to compute ∇ln ce(x, t) to ﬁnd qe. Note that
∇ln ce(x, t) = ∇ce(x, t)
ce(x, t) ,
and as we already compute ce(x, t) as an output of the ROM, we
need only to learn how to compute ∇ce(x, t).
Recall that ce(x, t) = ˜ce(x, t) + ce,0, so ∇ce(x, t) = ∇˜ce(x, t).
We have already derived a transfer function for ˜ce(x, t), which we
wrote as
KCe(x, s)
Iapp(s) =
M
∑
n=1
KCe,n(s)
Iapp(s)Ψ(x; λn).

7. thermal modeling
283
As only the eigenfunctions in this summation are a function of x, the
gradient can be found as
∇KCe(x, s)
Iapp(s)
=
M
∑
n=1
KCe,n(s)
Iapp(s) (∇Ψ(x; λn)) .
All of the hard work computing KCe,n(s) is reused; the only change
is that we must multiply these terms by the gradients of the origi-
nal eigenfunctions inside the summation, not by the eigenfunctions
themselves.
Recall that the eigenfunctions were deﬁned by Eq. (6.33):
Ψ(x; λ) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
Ψneg(x; λ),
0 ≤x < Lneg;
Ψsep(x; λ),
Lneg ≤x < Lneg + Lsep;
Ψpos(x; λ),
Lneg + Lsep ≤x ≤Ltot;
where
Ψneg(x; λ) = k1 cos
.M
λεneg
e
/Dneg
e,effx
/
Ψsep(x; λ) = k3 cos
.M
λεsep
e
/Dsep
e,effx
/
+ k4 sin
.M
λεsep
e
/Dsep
e,effx
/
Ψpos(x; λ) = k5 cos
.M
λεpos
e
/Dpos
e,effx
/
+ k6 sin
.M
λεpos
e
/Dpos
e,effx
/
.
Then,
∇Ψneg(x; λ) = −k1
P
Q
Q
Rλεneg
e
Dneg
e,eff
sin
⎛
⎝
P
Q
Q
Rλεneg
e
Dneg
e,eff
x
⎞
⎠
∇Ψsep(x; λ) = k4
P
Q
Q
Rλεsep
e
Dsep
e,eff
cos
⎛
⎝
P
Q
Q
Rλεsep
e
Dsep
e,eff
x
⎞
⎠−k3
P
Q
Q
Rλεsep
e
Dsep
e,eff
sin
⎛
⎝
P
Q
Q
Rλεsep
e
Dsep
e,eff
x
⎞
⎠
∇Ψpos(x; λ) = k6
P
Q
Q
Rλεpos
e
Dpos
e,eff
cos
⎛
⎝
P
Q
Q
Rλεpos
e
Dpos
e,eff
x
⎞
⎠−k5
P
Q
Q
Rλεpos
e
Dpos
e,eff
sin
⎛
⎝
P
Q
Q
Rλεpos
e
Dpos
e,eff
x
⎞
⎠.
7.6.3
Gradient of φe(x, t)
To compute the gradient of φe(x, t), recall that we have previously de-
ﬁned ˜φe(x, t) = φe(x, t) −φe(0, t). Therefore, ∇˜φe(x, t) = ∇φe(x, t) −
∇φe(0, t), or
∇φe(x, t) = ∇˜φe(x, t).
Recall also that we wrote ˜φe(x, t) as having two parts:
˜φe(x, t) = [ ˜φe(x, t)]1 + [ ˜φe(x, t)]2 .
The ﬁrst part, [ ˜φe(x, t)]1, can be determined via transfer functions;
the second part, [ ˜φe(x, t)]2, can be determined via known ce(x, t).

284
battery management systems: volume i, battery modeling
Similarly, the gradient of the ﬁrst part can also be found via trans-
fer functions, and the gradient of the second part will furthermore
require ce(x, t).
Let’s continue to look at the ﬁrst part. In the negative electrode, we
had Eq. (6.48), which was
[KΦe(x, s)]1
Iapp(s)
=−
Lnegσneg
eff
!
cosh
!
x
Lneg νneg(s)
" −1
"
Aκneg
eff (κneg
eff +σneg
eff )νneg(s) sinh(νneg(s))−
x
A(κneg
eff +σneg
eff )
−
Lnegκneg
eff
'
cosh
' (Lneg−x)
Lneg
νneg(s)
(
−cosh(νneg(s))
(
Aκneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
.
The corresponding gradient, computed with the aid of Mathematica,
is
∇[KΦe(x, s)]1
Iapp(s)
=
κneg
eff
'
sinh
' (Lneg−x)νneg(s)
Lneg
(
−sinh(νneg(s))
(
Aκneg
eff (κneg
eff + σneg
eff ) sinh(νneg(s))
−
σneg
eff sinh
' xνneg(s)
Lneg
(
Aκneg
eff (κneg
eff + σneg
eff ) sinh(νneg(s))
.
In the separator, we had Eq. (6.49), which was
[KΦe(x, s)]1
Iapp(s)
= −
Lneg '
(σneg
eff −κneg
eff ) tanh
' νneg(s)
2
((
Aκneg
eff (κneg
eff + σneg
eff )νneg(s)
−
Lneg
A(κneg
eff + σneg
eff ) −x −Lneg
Aκsep
eff
.
The corresponding gradient is
∇[KΦe(x, s)]1
Iapp(s)
= −
1
Aκsep
eff
.
In the positive electrode, we had Eq. (6.50), which was
[KΦe(x, s)]1
Iapp(s)
= −
Lneg '
(σneg
eff −κneg
eff ) tanh
' νneg(s)
2
((
Aκneg
eff (κneg
eff +σneg
eff )νneg(s)
−
Lneg
A(κneg
eff +σneg
eff )
−Lsep
Aκsep
eff
−
Lpos '
1 −cosh
' (Lneg+Lsep−x)
Lpos
νpos(s)
((
A(κpos
eff + σpos
eff ) sinh(νpos(s))νpos(s)
−
Lposσpos
eff
'
cosh (νpos(s)) −cosh
' (Ltot−x)
Lpos
νpos(s)
((
Aκpos
eff (κpos
eff + σpos
eff ) sinh(νpos(s))νpos(s)
−(x −Lneg −Lsep)
A(κpos
eff + σpos
eff )
.
The corresponding gradient is
∇[KΦe(x, s)]1
Iapp(s)
=
κpos
eff
'
sinh
' νpos(s)(Lpos−Ltot+x)
Lpos
(
−sinh(νpos(s))
(
Aκpos
eff (κpos
eff + σpos
eff ) sinh(νpos(s))

7. thermal modeling
285
10 From: Srinivasan, V., and Wang,
C.Y., “Analysis of Electrochemical and
Thermal Behavior of Li-Ion Cells,”
Journal of The Electrochemical Society,
150(1), 2003, pp. A98–A106.
−
σpos
eff sinh
' (Ltot−x)νpos(s)
Lpos
(
Aκpos
eff (κpos
eff + σpos
eff ) sinh(νpos(s))
.
Now we focus on the second term of ˜φe(x, t):
[ ˜φe(x, t)]2 = 2RT(1 −t0+)
F
[ln ce(x, t) −ln ce(0, t)]
∇[ ˜φe(x, t)]2 = 2RT(1 −t0+)
F
@∇ce(x, t)
ce(x, t) −∇ce(0, t)
ce(0, t)
A
= 2RT(1 −t0
+)
F
∇ce(x, t)
ce(x, t) .
As we already compute ce(x, t) as an output of the ROM and have
seen how to compute ∇ce(x, t), we have all the terms necessary to
compute ∇[ ˜φe(x, t)]2, and therefore we can compute ∇φe(x, t).
7.7
Heat-generation terms
We are now ready to investigate different reduced-order approxi-
mations to the heat-generation terms of Sect. 7.3. Depending on the
accuracy requirements of an application, we can take different ap-
proaches, with different computational demands. So, to illustrate the
tradeoffs, we will use several examples throughout this section to
compare the results predicted by the different approaches. The differ-
ent reduced-order models are labeled ROM1 through ROM4, and the
equations used as their basis are listed in Table 7.1 for reference.
Heat-gen. term:
¯qr
¯qi
¯qs
¯qe
ROM1
Eq. (7.6)
Eq. (7.8)
Eq. (7.11)
Eq. (7.13)
ROM2
Eq. (7.6)
Eq. (7.9)
Eq. (7.11)
Eq. (7.14)
ROM3
Eq. (7.6)
Eq. (7.10)
Eq. (7.12)
Eq. (7.15)
ROM4
Eq. (7.7)
Eq. (7.10)
Eq. (7.12)
Eq. (7.15)
Table 7.1: Equations deﬁning the
different heat-generation reduced-order
models.
We use the same basic cell as was used in the examples in Chap. 6,
where the cell parameters are listed in Table 6.1. To compute the
heat-generation terms, we must also know the partial molar entropy
relationships. For the negative electrode, we use the graphite curve in
Fig. 7.2, and for the positive electrode, we use the LMO curve. These
relationships are10
∂Uneg
ocp(θ)
∂θ
=
344.1347148 exp(−32.9633287θ + 8.316711484)
1 + 749.0756003 exp(−34.79099646θ + 8.887143624)
−0.8520278805θ + 0.36229929θ2 + 0.2698001697.

286
battery management systems: volume i, battery modeling
0
20
40
60
80
100
−20
−10
0
10
20
Pulse current profile
Time (s)
Current (A)
0
900
1,800 2,700 3,600 4,500 5,400
0
5
10
15
20
1C discharge profile
Time (s)
Current (A)
0
500
1,000
1,500
−20
0
20
40
UDDS current profile
Time (s)
Current (A)
Figure 7.3: Cell input current proﬁles
used to illustrate thermal model results.
∂Upos
ocp(θ)
∂θ
= 4.31274309 exp(0.571536523θ)−4.14532933
+ 1.281681122 sin(−4.9916739θ)
−0.090453431 sin(−20.9669665θ + 12.5788250)
−0.0313472974 sin(31.7663338θ −22.4295664)
+ 8.147113434θ −26.064581θ2 + 12.7660158θ3
−0.184274863 exp
,
−
.θ −0.5169435168
0.04628266783
/2-
.
The three examples that we consider are (1) a simple discharge
pulse followed by a charge pulse, around 50 % state of charge; (2) a
full 1C discharge starting at 100 %; and (3) a charge-neutral UDDS
proﬁle, around 60 % (the same proﬁle used in Chap. 6). These proﬁles
are drawn in Fig. 7.3.
7.7.1
Reversible heat-generation term qr[z, k]
We ﬁrst consider the reversible heat-generation term, specialized to a
single chemical reaction occurring at the solid–electrolyte boundary:
qr[z, k] = asFTj[z, k]∂Uocp(cs,e[z, k])
∂T
,
assuming that temperature is relatively constant across an electrode.
From Chap. 6, we have already found transfer functions for j[z, k] and
cs,e[z, k]. We can approximate the average reversible heat generation
across the electrode as
¯qr[k] =
ˆ 1
0
asFTj[z, k]∂Uocp(cs,e[z, k])
∂T
dz
≈asFT∑
i
j[zi, k]∂Uocp(cs,e[zi, k])
∂T
∆zi.
(7.6)
That is, j[z, k] and cs,e[z, k] are evaluated at a number of z locations
across the electrode, the entropy function is evaluated at each cs,e
point, and an approximation is made to the integral to compute the
average heat generation using a rectangular integration summation.
For an even better approximation, a trapezoidal integration can be
performed, which amounts to using different weighting constants for
every zi point. In the simulations that follow, we will use the set of
zi ∈{0, 0.25, 0.5, 0.75, 1} with trapezoidal integration in the results
labeled ROM1 through ROM3.
Computing j[z, k] and cs,e[z, k] at multiple z locations incurs a
fair amount of real-time computation in the Cxk + Diapp step. It
is possible to make a cruder approximation to ¯qr and reduce the
amount of computation required. That is, if we assume cs,e ≈cavg

7. thermal modeling
287
across the electrode, then we have
¯qr =
ˆ 1
0
asFTj[z, k]∂Uocp(cavg[k])
∂T
dz
= asFT ∂Uocp(cavg[k])
∂T
ˆ 1
0
j[z, k] dz
= iapp[k]T
A
∂Uocp(cavg[k])
∂T
.
(7.7)
In the simulations that follow, we will use this method in results
labeled ROM4.
0
20
40
60
80
100
−4
−2
0
2
4
Time (s)
Heat (W)
 
 
FOM
ROM1
ROM4
Heat-generation term ¯qr(t)
Figure 7.4: Reversible heat generated
via pulses: blue lines are for negative
electrode; red lines are for positive
electrode.
Fig. 7.4 shows sample results when the cell input current is the se-
quence of discharge and charge pulses. The solid line shows the full-
order model result, and the decorated lines show different reduced-
order model results. In this case, both ROM1 and ROM4 gave similar
predictions that were quite close to the truth, primarily because the
simulation was not long enough for signiﬁcant gradients in the solid
surface concentration to arise. Had they done so (as we shall see
later), we would ﬁnd ROM1 to be noticeably better than ROM4. The
choice of which ROM to use depends on the application.
7.7.2
Irreversible heat-generation term qi[z, k]
We next consider the irreversible heat-generation term, specialized to
a single chemical reaction occurring at the solid–electrolyte boundary,
qi[z, k] = asFj[z, k]η[z, k].
From Chap. 6, we have already found a transfer function for j[z, k]
and have seen how to compute η[z, k] from a nonlinear relationship.
We can approximate the average irreversible heat generation across
the electrode as
¯qi[k] =
ˆ 1
0
asFTj[z, k]η[z, k] dz

288
battery management systems: volume i, battery modeling
≈asFT ∑
i
j[zi, k]η[zi, k]∆zi.
(7.8)
As before, we can also use a trapezoidal integration approxima-
tion. In the simulations that follow, we will use the set of zi ∈
{0, 0.25, 0.5, 0.75, 1} with trapezoidal integration in the results labeled
ROM1.
For a reduction in computational complexity that incurs only a
modest loss of accuracy, we can linearize the η(z, t) term and recall
η[z, k] ≈Rctj[z, k]. This allows us to write
¯qi[k] ≈asFTRct ∑
i
j2[zi, k]∆zi.
The advantage of this form is that it is the product of two terms
found via fully linear transfer functions. We will see this form in the
other heat-generation terms as well, so we take some time to examine
it in general.
Consider a generic heat-generation term, in discrete time
q[z, k] = y1[z, k] y2[z, k]
where y1[z, k] and y2[z, k] are both purely linear terms computed as
output from the state-space reduced-order model (that is, there are
no nonlinear corrections applied to the terms). Then,
¯q[k] =
ˆ 1
0
y1[z, k] y2[z, k] dz
=
ˆ 1
0
[C1x[k] + D1u[k]] [C2x[k] + D2u[k]] dz.
The terms written inside square brackets are scalars and so are
equal to their own transpose. This allows us to write
¯q[k] =
ˆ 1
0
<
xT[k]CT
1 + uT[k]DT
1
=
[C2x[k] + D2u[k]] dz
= xT[k]
Fˆ 1
0
CT
1 C2 dz
T
#
$%
&
{CC}
x[k] + uT[k]
Fˆ 1
0
DT
1 D2 dz
T
#
$%
&
{DD}
u[k]
+ xT[k]
Fˆ 1
0
CT
1 D2 + CT
2 D1 dz
T
#
$%
&
{CD}
u[k]
= xT[k] {CC} x[k] + xT[k] {CD} u[k] + uT[k] {DD} u[k]
The C and D matrices are produced by the DRA from the appro-
priate transfer functions, and the integrals are approximated from
these matrices using a one-time computation, resulting in constant
precomputed {CC}, {CD}, and {DD} matrices.

7. thermal modeling
289
Expressing the heat generation in this form allows us to consider a
number of different approximations to the original result, at different
levels of complexity. The integral involving CT
1 C2 requires the most
computations, resulting in an n × n output at every z value. The
integral involving CT
i Dj has fewer computations, resulting in an n × 1
vector for every z value. The integral involving DT
1 D2 has the fewest
computations, resulting in a 1 × 1 scalar at every z value. If we are
able to drop terms from the approximation without losing too much
ﬁdelity, we can reduce the real-time computation load of estimating a
heat-generation term.
In the following simulations, results labeled ROM2 use the full
expression
¯qi[k] = xT[k] {CC} x[k] + xT[k] {CD} iapp[k] + {DD} i2
app[k].
(7.9)
Results labeled ROM3 and ROM4 use a simpler computation
¯qi[k] = {DD} i2
app[k].
(7.10)
Note that this corresponds to an “i2 × R” type of heat generation
we would expect from a lumped resistance. The other scenarios give
better approximations to the heat generation within an electrode,
which is a distributed system.
In the ROM2 through ROM4 results that follow for the irreversible
heat-generation term, we selected y1[z, k] = y2[z, k] = j[z, k] and
computed
¯qi[k] ≈asFTRct
ˆ 1
0
y1[z, k] y2[z, k] dz
using the three different approaches above.
0
20
40
60
80
100
0
0.2
0.4
0.6
0.8
1.0
Time (s)
Heat (W)
 
 
FOM
ROM1
ROM2
ROM3
Heat-generation term ¯qi(t)
Figure 7.5: Irreversible heat generated
via pulses: blue lines are for negative
electrode; red lines are for positive
electrode.
Fig. 7.5 shows sample results when the cell input current is the
sequence of discharge and charge pulses. As before, the solid line

290
battery management systems: volume i, battery modeling
shows the full-order model result, and the decorated lines show
different reduced-order model results. In this case, ROM1 is signif-
icantly better than ROM2, which itself is signiﬁcantly better than
ROM3. The ﬁdelity of predictions required by the application will
dictate which ROM to use.
7.7.3
Joule heating in solid term qs[z, k]
We now consider the heat-generation term corresponding to Joule
heating in the solid, expressed as qs = σeff(∇φs · ∇φs). We have
already seen that we can express ∇φs as a purely linear transfer func-
tion, so we can use the same approaches as we did with irreversible
heat generation.
In the simulations that follow, we select y1[z, k] = y2[z, k] =
√σeff∇φs[z, k] and compute
¯qs[k] =
ˆ 1
0
y1[z, k] y2[z, k] dz
where results labeled ROM1 or ROM2 use the full expression
¯qs[k] = xT[k] {CC} x[k] + xT[k] {CD} iapp[k] + {DD} i2
app[k].
(7.11)
Results labeled ROM3 and ROM4 use a simpler computation:
¯qs[k] = {DD} i2
app[k].
(7.12)
0
20
40
60
80
100
0
0.01
0.02
0.03
0.04
Time (s)
Heat (W)
 
 
FOM
ROM1
ROM3
Heat-generation term ¯qs(t)
Figure 7.6: Heat generated via Joule
heating in solid from pulses: blue lines
are for negative electrode; red lines are
for positive electrode.
Fig. 7.6 shows sample results when the cell input current is the se-
quence of discharge and charge pulses. The solid line shows the full-
order model result, and the decorated lines show different reduced-
order model results. In this case, all reduced-order models produce
nearly indistinguishable results. Further, a close examination of the
vertical scale shows that the ¯qs[k] term is by far the smallest heat-
generation term, so even large relative errors are not signiﬁcant when

7. thermal modeling
291
total heat generation is computed. Therefore, ROM3 is probably sufﬁ-
cient for most applications.
7.7.4
Joule heating in electrolyte term qe[x, k]
Finally, we consider the heat-generation term corresponding to Joule
heating in the electrolyte. We take a few steps to convert it into a
combination of signals at our disposal:
qe = κeff(∇φe · ∇φe) + κD,eff(∇ln ce · ∇φe)
= κeff
'
(∇[ ˜φe]1)2 + 2 (∇[ ˜φe]1∇[ ˜φe]2) + (∇[ ˜φe]2)2(
+ κD,eff
.∇˜ce
ce (∇[ ˜φe]1 + ∇[ ˜φe]2)
/
= κeff
⎛
⎝(∇[ ˜φe]1)2 + 4RT(1−t0+)
Fce
(∇[ ˜φe]1∇˜ce) +
,
2RT(1−t0+)∇˜ce
Fce
-2⎞
⎠
+ κeff
,
2RT(t0+−1)
F
∇˜ce
ce
,
∇[ ˜φe]1 + 2RT(1−t0+)∇˜ce
Fce
--
= κeff (∇[ ˜φe]1)2 −κD,eff
ce
∇[ ˜φe]1∇˜ce.
To compute this result, we will need to have the DRA produce
a ROM that can generate ∇[ ˜φe]1, ˜ce, and ∇˜ce at different locations
across the cell to create proper averages. For best results, we use
κeff(ce(x, t)) instead of the κeff(ce,0) that we usually use. Further, we
recognize that the denominator of the transfer function for ∇[ ˜φe]1 in
all regions of the cell includes a κeff term. The DRA-produced ROM
uses κeff(ce,0) when making the linearized transfer function. How-
ever for best results, the output of the ROM should be multiplied by
κeff(ce,0)/κeff(ce(x, t)) since κeff is a strong function of ce and ∇[ ˜φe]1
is a strong function of κeff. Writing this out more explicitly, the heat-
generation terms used for ROM1 results presented below use
qe[x, k] = κeff(ce[x, k])
. κeff (ce,0)
κeff(ce[x, k])∇[ ˜φe]1
/2
−κD,eff
ce[x, k]∇[ ˜φe]1∇˜ce.
(7.13)
A simpler version assumes that ce[x, k] ≈ce,0. Results for ROM2
through ROM4 assume linearized results:
qe[x, k] = κeff (∇[ ˜φe]1)2 −κD,eff
ce,0
∇[ ˜φe]1∇˜ce.
Then, the method from Sect. 7.7.2 can be used on both parts of this
expression. Results for ROM2 use the full linearized expression;
results for ROM3 and ROM4 retain only the {DD} terms.
That is, for the ﬁrst term we select y1[x, k] = y2[x, k] =
0
κeff/Ltot∇[ ˜φe[x, k]]1
and for the second term we select y3[x, k] =
0
κD,eff/(ce,0Ltot)∇[ ˜φe[x, k]]1

292
battery management systems: volume i, battery modeling
11 The 1C discharge simulations use
model blending, as discussed brieﬂy
in Sect. 7.10. Results for UDDS simula-
tions are not shown as the plots are too
“busy”; however, all ROMs match the
FOM quite well.
and y4[x, k] = ∇˜ce[x, k] and compute
¯qe[k] = κeff
Ltot
ˆ Ltot
0
y1[x, k] y2[x, k] dx −κD,eff
ce,0Ltot
ˆ Ltot
0
y3[x, k] y4[x, k] dx
where results labeled ROM1 or ROM2 use the full expression
¯qe[k] = xT[k] {CC1 −CC2} x[k] + xT[k] {CD1 −CD2} iapp[k]
+ {DD1 −DD2} i2
app[k],
(7.14)
where the matrix subscripts indicate the integral from which they
were computed. Results labeled ROM3 and ROM4 use a simpler
computation:
¯qe[k] = {DD1 −DD2} i2
app[k].
(7.15)
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Time (s)
Heat (W)
 
 
FOM
ROM1
ROM2
ROM3
Heat-generation term ¯qe(t)
Figure 7.7: Heat generated via Joule
heating in electrolyte from pulses:
blue lines are for negative electrode;
magenta are for separator; red lines are
for positive electrode.
Fig. 7.7 shows sample results when the cell input current is the
sequence of discharge and charge pulses. The solid line shows
the full-order model result, and the decorated lines show different
reduced-order model results. In this case, all ROMs gave fairly sim-
ilar predictions to one another, although ROM1 appears to be more
robust over a variety of simulation scenarios.
As a point of comparison, the total heat generated is modeled and
displayed in Fig. 7.8 for the pulses and 1C discharge scenarios.11 We
see that the predictions of the ROMs are quite similar. The only large
discrepancy is with ROM4 for the 1C discharge case, and this error is
due to the crude model of ¯qr(t).
7.8
Heat-ﬂux terms
Now that we have seen how to approximate the heat-generation
terms of the thermal model, we turn our attention to modeling heat

7. thermal modeling
293
0
20
40
60
80
100
−2
−1
0
1
2
3
4
5
Time (s)
Heat (W)
 
 
FOM
ROM1
ROM2
ROM3
ROM4
Total heat generation, ¯qi(t) + ¯qr(t) + ¯qs(t) + ¯qe(t)
0
900
1,800
2,700
3,600
4,500
5,400
0
1
2
3
4
5
6
Time (s)
Heat (W)
 
 
FOM
ROM1
ROM2
ROM3
ROM4
Total heat generation, ¯qi(t) + ¯qr(t) + ¯qs(t) + ¯qe(t)
Figure 7.8: Total heat generated from
1C pulses (left) and a full 1C discharge
(right): blue lines are for negative
electrode; magenta are for separator;
red lines are for positive electrode.
ﬂux, leading to an expression for average cell temperature. We start
with the underlying PDE
ρcP
∂T(x, t)
∂t
= ∇· (λ∇T(x, t)) + q(x, t)
(7.16)
having convective boundary conditions
−λ ∂T(x, t)
∂x
++++
x=0
= h(T∞−T(0, t))
(7.17)
λ ∂T(x, t)
∂x
++++
x=L
= h
,
T∞−T(L, t)
-
.
(7.18)
The constants ρ, cP, and λ may be different in the three regions of the
cell, but are assumed to be homogeneous within each region. Also, a
radiative boundary condition may be approximated using
T4
∞−T4
s ≈4T3
∞(T∞−Ts)
as discussed earlier.
To solve this PDE, we might consider using separation of variables,
as we did when exploring the PDE governing the concentration of
lithium in the electrolyte, ce(x, t) in Chap. 6. However, since tempera-
ture tends to be fairly uniform across the x dimension of the cell, we
use a simpler approach here, which is sufﬁcient if all we want is av-
erage temperature of the cell and not an accurate model of the entire
proﬁle of T(x, t).
Assume that we can closely approximate T(x, t) as
T(x, t) ≈T∞+ a(t) + b(t) sin
' πx
Ltot
(
.
This allows for a fairly ﬂat temperature proﬁle over the cell cross
section—which we observe in full-order-model simulations—but
retains some curvature, as needed to satisfy the boundary conditions

294
battery management systems: volume i, battery modeling
in Eqs. (7.17) and (7.18). The a(t) term primarily models the overall
temperature bias versus the ambient temperature T∞, and b(t) the
nonuniformity of temperature versus cross-sectional position x.
For this assumed model, the derivatives that we need to solve the
PDE can be written as
∂T(x, t)
∂t
= da(t)
dt
+ db(t)
dt
sin
' πx
Ltot
(
∂T(x, t)
∂x
=
π
Ltot b(t) cos
' πx
Ltot
(
∂2T(x, t)
∂x2
= −
' π
Ltot
(2
b(t) sin
' πx
Ltot
(
.
Inserting the assumed form of solution into the boundary condi-
tion of Eq. (7.17) at x = 0 gives
−λ
π
Ltot b(t) cos
' πx
Ltot
(+++
x=0 = h(T∞−(T∞+ a(t)))
−λ π
Ltot b(t) = −ha(t)
b(t) = hLtot
λπ a(t).
Evaluating the PDE of Eq. (7.16) with the assumed form of solu-
tion gives
ρcP
@da(t)
dt +hLtot
λπ
da(t)
dt
sin
' πx
Ltot
(A
= −λ
' π
Ltot
(2. hLtot
λπ
/
a(t) sin
' πx
Ltot
(
+ q(x, t)
ρcP
@
1 + hLtot
λπ sin
' πx
Ltot
(A da(t)
dt
= −
. πh
Ltot
/
a(t) sin
' πx
Ltot
(
+ q(x, t).
(7.19)
We will use this functional form as a basis for ﬁnding average cell
temperature. To do so, we average both sides of the equation
1
Ltot
ˆ Ltot
0
ρcP
@
1 + hLtot
λπ sin
' πx
Ltot
(A
dx da(t)
dt
= −
. πh
Ltot
2
π
/
a(t) + ¯q(t),
where
¯q(t) =
1
Ltot
ˆ Ltot
0
q(x, t) dx,
and we have used
1
Ltot
ˆ Ltot
0
sin
' πx
Ltot
(
dx = 2
π .
We rewrite this as
da(t)
dt
= −
.
2h
kqLtot
/
a(t) + 1
kq
¯q(t),

7. thermal modeling
295
where the constant
kq =
1
Ltot
ˆ Ltot
0
ρcP
@
1 + hLtot
λπ sin
' πx
Ltot
(A
dx
=
1
Ltot
:
ρnegcneg
P
.h(Ltot)2
λnegπ2
.
1 −cos
.πLneg
Ltot
///
+ ρsepcsep
P
.h(Ltot)2
λsepπ2
.
cos
.πLneg
Ltot
/
−cos
.π(Lneg + Lsep)
Ltot
///
+ ρposcpos
P
.h(Ltot)2
λposπ2
.
1 + cos
.π(Lneg + Lsep)
Ltot
///
+ ρnegcneg
P
Lneg + ρsepcsep
P Lsep + ρposcpos
P Lpos
;
.
Recalling that
T(x, t) ≈T∞+ a(t) + b(t) sin
' πx
Ltot
(
= T∞+ a(t)
@
1 + hLtot
λπ sin
' πx
Ltot
(A
,
we can compute an average temperature
Tavg(t) = T∞+ a(t)
Ltot
ˆ Ltot
0
1 + hLtot
λπ sin
' πx
Ltot
(
dx
= T∞+ Cqa(t)
where the constant
Cq =
1
Ltot
ˆ Ltot
0
1 + hLtot
λπ sin
' πx
Ltot
(
dx
=
1
Ltot
:.
Lneg + h(Ltot)2
λnegπ2
.
1 −cos
.πLneg
Ltot
///
+
.
Lsep + h(Ltot)2
λsepπ2
.
cos
.πLneg
Ltot
/
−cos
.π(Lneg + Lsep)
Ltot
///
+
.
Lpos + h(Ltot)2
λposπ2
.
1 + cos
.π(Lneg + Lsep)
Ltot
///;
= 1 + hLtot
π2
:
1
λneg
.
1 −cos
.πLneg
Ltot
//
+
1
λsep
.
cos
.πLneg
Ltot
/
−cos
.π(Lneg + Lsep)
Ltot
//
+
1
λpos
.
1 + cos
.π(Lneg + Lsep)
Ltot
//;
.
Converting to discrete time using the result from Sect. 2.4, we have
the one-state ODE model for cell average temperature
a[k + 1] = Aqa[k] + Bq ¯q[k]

296
battery management systems: volume i, battery modeling
Tavg[k] = Cqa[k] + T∞,
where
Aq = exp
.
−
2h
kqLtot ∆t
/
Bq =
⎧
⎨
⎩
−Ltot
2h
!
Aq −1
"
,
h ̸= 0
∆t
kq
h = 0.
7.9
Uncoupled model results
We demonstrate the heat-ﬂux model ﬁrst using an uncoupled electro-
chemical–thermal model. In this scenario, the electrochemical model
(artiﬁcially) operates at a constant temperature of 298.15 K (i.e., 25 ◦C),
independent of the thermal model. The thermal model computes
heat-generation terms and predicts temperature change, but the
temperature change is not an input to the electrochemical simulation.
In Sect. 7.10 we will show results for a coupled electrochemical–
thermal model instead.
Results of these simulations to test the heat-ﬂux ROM are shown
in Figs. 7.9 through 7.11. In each ﬁgure, three different simulation
scenarios are shown: one for convection coefﬁcient h = 0 (modeling
the perfectly insulated or adiabatic case, with no heat transfer to or
from the environment), one with h = 5 (modeling natural convection),
and one with h = 25 (modeling forced-air convection).
In Fig. 7.9, we see the results for the pulse test. All ROMs agree
with the FOM results to within less than one degree over the entire
simulation. ROM1 is somewhat better than the others, but they are
all similar.
0
20
40
60
80
100
298.2
298.3
298.4
298.5
298.6
Time (s)
Temperature (K)
Pulse current profile, h=0
 
 
FOM
ROM1
ROM2
ROM3
ROM4
0
20
40
60
80
100
298.2
298.3
298.4
298.5
Time (s)
Temperature (K)
Pulse current profile, h=5
 
 
FOM
ROM1
ROM2
ROM3
ROM4
0
20
40
60
80
100
298.15
298.2
298.25
298.3
Time (s)
Temperature (K)
Pulse current profile, h=25
 
 
FOM
ROM1
ROM2
ROM3
ROM4
Figure 7.9: Cell average temperature as
predicted by the uncoupled FOM and
ROMs for the pulse proﬁle and several
convection coefﬁcients h.
In Fig. 7.10, we see the results for the 1C discharge test. Here, all
ROMs do quite well again, although ROM4 is noticeably worse than
the others. This is due to the crude approximation of ¯qr(t).
Finally, Fig. 7.11 shows results for the charge-balanced UDDS
test. Again, all ROMs do quite well. ROM1 slightly outperforms the

7. thermal modeling
297
0
900
1,800 2,700 3,600 4,500 5,400
300
310
320
330
340
350
Time (s)
Temperature (K)
1C discharge profile, h=0
 
 
FOM
ROM1
ROM2
ROM3
ROM4
0
900
1,800 2,700 3,600 4,500 5,400
298.2
298.4
298.6
298.8
299
Time (s)
Temperature (K)
1C discharge profile, h=5
 
 
FOM
ROM1
ROM2
ROM3
ROM4
0
900
1,800 2,700 3,600 4,500 5,400
298.15
298.2
298.25
298.3
298.35
Time (s)
Temperature (K)
1C discharge profile, h=25
 
 
FOM
ROM1
ROM2
ROM3
ROM4
Figure 7.10: Cell average temperature as
predicted by the uncoupled FOM and
ROMs for the 1C discharge proﬁle and
several convection coefﬁcients h.
others, but perhaps not enough to justify the additional complexity.
0
500
1,000
1,500
298
298.5
299
299.5
300
Time (s)
Temperature (K)
UDDS current profile, h=0
 
 
FOM
ROM1
ROM2
ROM3
ROM4
0
500
1,000
1,500
298.1
298.2
298.3
298.4
298.5
Time (s)
Temperature (K)
UDDS current profile, h=5
 
 
FOM
ROM1
ROM2
ROM3
ROM4
0
500
1,000
1,500
298.15
298.2
298.25
298.3
Time (s)
Temperature (K)
UDDS current profile, h=25
 
 
FOM
ROM1
ROM2
ROM3
ROM4
Figure 7.11: Cell average temperature
as predicted by the uncoupled FOM
and ROMs for the charge-balanced
UDDS proﬁle and several convection
coefﬁcients h.
7.10
Coupled model results
For our next results, we consider a coupled electrochemical–thermal
model, where temperature from the thermal model is fed back into
the electrochemical model on a sample-by-sample basis. In the elec-
trochemical model, parameter values change according to an Ar-
rhenius relationship via Eq. (7.5). The reference temperature for all
parameter values was taken to be 25 ◦C, the reference values for
temperature-varying quantities were the standard values from Ta-
ble 6.1, and the activation energies for those parameters were those
listed in Table 7.2.
kneg
kpos
Dneg
s
Dpos
s
De
κ
Activation energy [kJ mol−1]
30
30
4
20
10
20
Table 7.2: Activation energies for
Arrhenius relationship for coupled
electrochemical–thermal model
simulation.
Full-order model results were from a coupled electrochemical–
thermal model implemented in COMSOL. Reduced-order model re-
sults were created via blending ROMs created at multiple temperature–
SOC setpoints. That is, ﬁrst, the Arrhenius equation (Eq. (7.5)) was
used to ﬁnd parameter values at different temperature setpoints, and

298
battery management systems: volume i, battery modeling
the DRA was executed off-line to produce reduced-order models at
different state-of-charge and temperature setpoints. Then, while the
cell model is operating, the electrochemical model updates state of
charge, and the thermal model updates temperature. Model blending
continuously updates the A, B, C, and D matrices that are used in
real time.
For the parameters and proﬁles used in these simulations there is
very little difference between most uncoupled and coupled results.
The biggest difference is seen in the adiabatic (h = 0) case for the full
1C discharge proﬁle. This is shown in Fig. 7.12.
0
900
1,800
2,700
3,600
4,500
5,400
0
1
2
3
4
5
6
Time (s)
Heat (W)
 
 
FOM
ROM1
ROM2
ROM3
ROM4
Total heat gen. (coupled), ¯qi(t)+ ¯qr(t)+ ¯qs(t)+ ¯qe(t)
0
900
1,800
2,700
3,600
4,500
5,400
300
310
320
330
340
350
Time (s)
Temperature (K)
1C discharge profile, h=0 (coupled)
 
 
ROM1
ROM2
ROM3
ROM4
 
 
Uncoupled FOM
Coupled FOM
Figure 7.12: Cell average temperature
as predicted by the coupled FOM and
ROMs for the 1C discharge proﬁle and
h = 0.
The left frame shows a comparison between heat-generation pre-
dictions by the FOM and the ROMs. (The comparable uncoupled
result is in the right frame of Fig. 7.8.) Again, all ROMs except ROM4
predict heat generation in the negative electrode well; all ROMs pre-
dict heat generation in the separator nearly equally well; and ROM 1
and ROM 2 do the best at predicting heat generation in the positive
electrode.
The right frame shows temperature change versus time. (The
comparable uncoupled result is in the left frame of Fig. 7.10.) First,
notice the signiﬁcant difference between the uncoupled and coupled
“truth” results predicted by the two different FOMs. Next, we see
that ROMs 1 and 2 predict temperature change nearly equally well;
ROMs 3 and 4 are not quite as good but may be adequate for many
applications.
7.11
Where to from here?
We have now reached the end of this volume on battery modeling.
We’ve come a long way in our understanding!
• We have explored empirical equivalent-circuit type models. These

7. thermal modeling
299
are both conceptually and computationally simple and can predict
cell input–output behaviors well. They provide robust simulations
for cell voltage for scenarios similar to those that generated the
data that were used to train the models. System identiﬁcation
of model parameters is straightforward using voltage–current
input–output data gathered using standard battery-laboratory
equipment.
• We have derived microscale physics-based models that describe
the internal dynamics of lithium-ion cells at very small length
scales. These models apply directly to simulating mass and charge
conservation in homogeneous solid active materials and in homo-
geneous electrolyte, separately. Parameters for these models (e.g.,
conductivities, diffusivities) are found by electrochemical labora-
tory tests on the raw materials that make up the cell. Simulations
of cells using microscale models are intractable due to the vast
amount of computation required.
• We have seen how to create volume-averaged continuum-scale
models from the microscale models. These consider the average be-
havior of lithium concentration and potential in the solid and elec-
trolyte over small neighborhoods and are simpliﬁed enough to be
suitable for simulating full cells on a desktop computer. However,
simulations are still too computationally complex to be considered
on an embedded-systems battery-management system.
• We have also seen how to convert the continuum-scale models into
linearized transfer functions, from which the discrete-time realiza-
tion algorithm can compute physics-based reduced-order models.
These models incorporate all the best features of the empirical
and physics-based approaches: they are computationally simple,
fast, and robust; further, they use physics to be able to predict cell
behaviors outside of typical operating regimes; and they can fur-
thermore compute cell electrochemical internal variables. The last
is very useful to be able to predict (and control) aging.
• Finally, we have studied thermal effects at the microscale, continuum-
scale, and reduced-order cell scale levels. The physics-based
reduced-order models can compute all the terms needed to eval-
uate heat generation and temperature change in a cell. This can
either improve the ﬁdelity of an open-loop simulation or be used
in a battery-management system to assist with thermal manage-
ment and control.
These models are now ready to be used. In the second volume of
this series, we discuss practical applications of battery models to the
problems of proper battery management and control, focusing on

300
battery management systems: volume i, battery modeling
methods that use equivalent-circuit type models. The general outline
of the book is
• An introduction to battery-management systems and the hardware
and software requirements. There is some discussion of the kinds
of electronics needed, but the focus of the book is on software
methods, or algorithms.
• Generalizing from the battery-cell models seen in this volume to
discover how to simulate battery packs of interconnected cells. It
also considers simulating the load to which the battery pack is
connected.
• The largest single section of the book explores how to estimate the
internal state of all cells in a battery pack using only a cell model
and voltage–current–temperature measured data. The particular
focus is on state-of-charge estimation using some simple methods,
as well as some methods based on nonlinear Kalman ﬁltering. It
also addresses practical robustness concerns and computational-
complexity issues.
• An additional substantial section of the book considers state-of-
health estimation for all cells in the battery pack. We show why
estimating resistance is “easy” and why estimating total capacity is
“hard.” Some simple methods for estimating health are considered,
and then an optimal method for total-capacity estimation.
• We consider cell balancing: why is it needed, how can it be done,
and what balancing speed is necessary.
• Finally, we examine power-limits estimation. We ﬁrst consider
power limits based on maintaining all cells within some prescribed
voltage operating window, and then explain how power limits
based on cell electrochemistry can improve on these greatly.
7.12
Partial glossary
This section gives a glossary of the most important variables deﬁned
in this chapter.
• cP [J kg−1 K−1] is the speciﬁc heat of a material (cf. p. 274).
• h [W m−2 K−1] is a heat-transfer coefﬁcient describing heat transfer
at a boundary (cf. p. 280).
• Hk [J mol−1] is the partial molar enthalpy of a material (cf. p. 275).
• λ [W K−1] is the thermal conductivity of a material (cf. p. 274).
• Π [V K−1] is the Peltier coefﬁcient of a material (cf. p. 276).
• q [W m−3] is a heat-generation term (cf. p. 278).

7. thermal modeling
301
• ρ [kg m−3] is the density of a material (cf. p. 274).
• T∞[K] is the ambient temperature (cf. p. 280).


A.1 The same but different . . . . 303
A.2 Charge storage . . . . . . . . 304
A.3 Continuum model . . . . . . 305
A.4 1D model of ˜φneg
s-e (z, t) . . . . 307
A.5 1D model of ˜φneg
s
(z, t) . . . . 310
A.6 1D model of ˜φneg
e
(z, t) . . . . 311
A.7
˜φpos
s-e , ˜φpos
s
and ˜φpos
e
. . . . . . 312
A.8 Supercapacitor voltage. . . . 313
A.9 Implement FOM . . . . . . . 314
A.10 Implement ROM . . . . . . . 315
A.11 Simulation results . . . . . . 316
A.12 Identifying parameters. . . . 317
A.13 Partial glossary . . . . . . . . 322
A
Supercapacitors
A.1
The same but different
Supercapacitors, sometimes known as ultracapacitors or electrochemical
double-layer capacitors (EDLC), are electrochemical energy storage
devices that share some similarities to the lithium-ion cells we have
studied in this book. They have energy density about one tenth that
of lithium-ion cells but power density of 10 or more times that of
lithium-ion. In addition, they will tolerate many more charge and
discharge cycles than most batteries. They are especially well suited
for applications requiring long life and high power but low energy.
The structure of a supercapacitor is essentially the same as that
of a lithium-ion battery cell and is depicted in Fig. A.1. There are
negative and positive electrodes, current collectors, and a separator.
The electrodes are composed of small particles, with the voids ﬁlled
by an electrolyte solution.
Negative electrode
Positive electrode
Current collector
Current collector
Separator
x
Figure A.1: Schematic of a superca-
pacitor, from a continuum-model
perspective.
Because of these similarities, we can leverage the math required
to develop PDE full-order models and discrete-time reduced-order
models of lithium-ion cells and apply it to understanding supercapac-
itors as well. So, enjoy this bonus appendix chapter!
303

304
battery management systems: volume i, battery modeling
A.2
Charge storage
Charge can be stored in a supercapacitor via two mechanisms:
• With the so-called nonfaradaic mechanism, charge is stored electro-
statically across the solid–electrolyte boundary. The solid particles
develop a positive or negative charge, and the ions in the elec-
trolyte immediately adjacent to the particles develop an opposite
charge. No chemical reaction occurs at the particle surface.
The region in the electrolyte adjacent to the particle develops
two layers of ordered charges, hence this region is called the “dou-
ble layer.” The separation of charge is generally less than 1 nm,
which is much smaller than in a conventional capacitor. This, com-
bined with the enormous surface area of the particles in a porous
electrode, leads to a very high capacitance value.
Fig. A.2 shows a particle and surrounding electrolyte in dis-
charged and charged conﬁgurations. When discharged, positive
and negative charges are disordered, with no net charge storage.
When charged, positive (or negative) charges build up on the sur-
face of the solid, and negative (or positive) charges build up in the
electrolyte immediately adjacent to the particle.
Discharged
Electrolyte
Pore
0 V
Activated carbon
Charged
Electrolyte
Pore
V
Activated carbon
Figure A.2: Electrostatic charge stor-
age in an electric double layer via a
nonfaradaic mechanism.
• With the faradaic mechanism, charge is stored electrochemically
with electron charge transfer, which can occur because of a redox
reaction (as with a traditional electrochemical battery cell) or via
intercalation (as with a lithium-ion battery cell). This is not truly a
capacitor (since charge is not stored electrostatically), so this mech-
anism is sometimes termed pseudocapacitance. Faradaic-mechanism
supercapacitors can store much more charge than nonfaradaic-
mechanism supercapacitors, but with reduced life expectancy and
reduced power capabilities.
At present, most supercapacitors available for sale are nonfaradaic,
relying on a double-layer mechanism for charge storage. Some are

a. supercapacitors
305
1 To consider pseudocapacitors having
an intercalation faradaic mechanism,
the techniques from Chap. 6 can be
employed directly to make a model.
2 Nonfaradaic from: Srinivasan, V., and
Weidner, J.W., “Mathematical Modeling
of Electrochemical Capacitors,” Journal
of the Electrochemical Society, 146(5), 1999,
pp. 1,650–1,658. Faradaic from: Lin,
C., Ritter, J.A., Popov, B.N., and White,
R.E., “A Mathematical Model of an
Electrochemical Capacitor with Double-
Layer and Faradaic Processes,” Journal
of the Electrochemical Society, 146(9), 1999,
pp. 3,168–3,175.
pseudocapacitors, and some are hybrids having one nonfaradaic
electrode and one faradaic electrode. Generally, positive and negative
electrodes can be of different geometry and composition, but most
often they are identical to each other. The most commonly used
material for the solid particles in a double-layer capacitor is activated
carbon; pseudocapacitors are often made with at least one electrode
comprising a metal oxide or a conducting polymer.
A.3
Continuum model
Our goal is to develop equations describing the internal and external
behaviors of a supercapacitor, much as we have already done for a
lithium-ion battery cell. We omit the microscale derivations and jump
directly to the continuum-scale model by employing analogies to our
experience with lithium-ion battery cells. From the continuum model,
we will develop transfer functions to describe the supercapacitor
internal variables. Then, the DRA will be used to build discrete-time
state-space approximate models.
As with the lithium-ion cell model, the supercapacitor model has
equations describing potential in its solid particles and potential in
its electrolyte. Unlike a lithium-ion battery cell, the supercapacitor
models assume constant concentration of charge carriers in the elec-
trolyte, so electrolyte concentration variation ce(x, t) does not need to
be modeled. Also, we do not consider intercalation, so solid concen-
tration cs,e(x, t) does not need to be modeled.1
The derivation of the supercapacitor continuum-scale model in
this appendix merges elements of the nonfaradaic approach of Srini-
vasan and Weidner and the faradaic approach of Lin et al., although
a slightly different path is taken, and notation is modiﬁed to be com-
patible with what we’ve used throughout this book.2 We begin with
derivations for the negative-electrode quantities and later generalize
to the positive-electrode quantities as well. We start by assuming the
continuum-scale models of electronic current through the solid and
ionic current through the electrolyte:
εneg
s
ineg
s
(x, y, z, t) = −σneg
eff ∇φneg
s
(x, y, z, t)
(A.1)
εneg
e
ineg
e
(x, y, z, t) = −κneg
eff ∇φneg
e
(x, y, z, t).
(A.2)
Note the similarities to Eqs. (4.14) and (4.18). However, because
of the assumption of uniform electrolyte concentration, we omit the
term from Eq. (4.18) that is dependent on the concentration gradient.
We specialize to a one-dimensional model, so we can write
εneg
s
ineg
s
(x, t) = −σneg
eff
∂φneg
s
(x, t)
∂x
(A.3)

306
battery management systems: volume i, battery modeling
εneg
e
ineg
e
(x, t) = −κneg
eff
∂φneg
e
(x, t)
∂x
.
(A.4)
We next deﬁne a normalized spatial dimension z = x/Lneg in the
negative electrode. Then, by change of variables,
εneg
s
ineg
s
(z, t) = −σneg
eff
Lneg
∂φneg
s
(z, t)
∂z
(A.5)
εneg
e
ineg
e
(z, t) = −κneg
eff
Lneg
∂φneg
e
(z, t)
∂z
,
(A.6)
where the total current at any z location is the sum
iapp(t)
A
= εsis(z, t) + εeie(z, t).
(A.7)
The solid-current equation has boundary conditions
σneg
eff
Lneg
∂φneg
s
(z, t)
∂z
+++++
z=0
= −iapp(t)
A
and
∂φneg
s
(z, t)
∂z
+++++
z=1
= 0.
Likewise, the electrolyte-current equation has boundary conditions
∂φneg
e
(z, t)
∂z
+++++
z=0
= 0
and
κneg
eff
Lneg
∂φe(z, t)
∂z
+++++
z=1
= iapp(t)
A
.
We deﬁne the solid–electrolyte potential difference as
φs-e(z, t) = φs(z, t) −φe(z, t),
and ﬁnd that its boundary conditions are
σneg
eff
Lneg
∂φneg
s-e (z, t)
∂z
+++++
z=0
= −κneg
eff
Lneg
∂φneg
s-e (z, t)
∂z
+++++
z=1
= −iapp(t)
A
.
Charge ﬂux out of the electrolyte and into the surface layer is
denoted as in, such that
∇· (εsis) = −asin
or
εs
∂is
∂x = −asin
(A.8)
∇· (εeie) = asin
or
εe
∂ie
∂x = asin
(A.9)
for uniform εs and εe, and where in is the sum of the nonfaradaic cur-
rent density ﬂowing into the double layer plus the faradaic current
density ﬂowing into the surface-layer chemical reaction.
The double layer is modeled using a standard capacitor equation
as an analogy:
idl = C ∂φs-e
∂t ,
(A.10)

a. supercapacitors
307
where idl is the double-layer current density, and C is the speciﬁc capac-
itance of the active materials.
To model the faradaic process, we begin by deﬁning faradaic cur-
rent density i f ﬂowing into the surface layer and faradaic charge Q f
stored by the surface layer such that electrode faradaic state of charge
θ f can be written as
θ f =
Q f −Q f ,0%
Q f ,100% −Q f ,0%
,
where Q f ,0% is the faradaic charge of a fully discharged (fully re-
duced) electrode, and Q f ,100% is the faradaic charge of a fully charged
(fully oxidized) electrode. The charge varies according to
∂Q f
∂t
= asi f ,
where i f is the faradaic current density. Then, we model the kinetics of
i f using a Butler–Volmer equation.
i f = i0
@
exp
.(1−α)F
RT
'
φs-e−Uf (Q f )
(/
−exp
.
−αF
RT
'
φs-e−Uf (Q f )
(/A
,
(A.11)
where Uf (Q f ) models the state-of-charge dependent rest voltage of
the faradaic process.
In the model, if there is no nonfaradaic process one simply sets
C = 0 so that idl = 0 in Eq. (A.10). Similarly, if there is no nonfaradaic
process, one sets i0 = 0 so that i f = 0 in Eq. (A.11).
A.4
A one-dimensional model of ˜φneg
s-e (z, t)
We desire to make a reduced-order discrete-time approximation to
this continuum PDE model of a supercapacitor. We will use a very
similar approach to the one taken in Chap. 6 to make a ROM of a
lithium-ion cell. In particular, we will start by linearizing the PDEs
and making transfer functions.
Beginning with Eq. (A.11), we deﬁne a linearization setpoint p∗=
{Q f = Q0, φs-e = φs-e,0} and write
i f ≈i f (p∗)
# $% &
0
+
∂i f
∂φs-e
++++
p∗(φs-e −φs-e,0) +
∂i f
∂Q f
+++++
p∗
(Q f −Q0)
i f ≈i0F
RT
˜φs-e −i0F
RT
⎡
⎣∂Uf
∂Q f
+++++
Q0
⎤
⎦KQ f
where we have deﬁned ˜φs-e = φs-e −φs-e,0 and KQ f = Q f −Q0. Note
that the initial solid–electrolyte potential difference is the sum of the

308
battery management systems: volume i, battery modeling
3 If there is no faradaic process, Zf is
inﬁnite. In the equations that follow,
this is accomplished by setting i0 = 0
and ∂Uf /∂Q f = ∞in the limit.
potential across the double layer plus the potential caused by the
faradaic storage. Therefore, we can write φs-e,0 = Udl,0 + Uf (Q0), and
˜φs-e = φs-e −Udl,0 −Uf (Q0).
We rearrange to solve for ˜φs-e in time and Laplace domains
˜φs-e(z, t) = RT
i0Fi f (z, t) +
⎡
⎣∂Uf
∂Q f
+++++
Q0
⎤
⎦KQ f (z, t)
KΦs-e(z, s) = RT
i0F If (z, s) +
⎡
⎣∂Uf
∂Q f
+++++
Q0
⎤
⎦KQ f (z, s).
Note also that in the time and Laplace domains we have
∂KQ f (z, t)
∂t
= asi f (z, t)
s KQ f (z, s) = asIf (z, s).
Combining these results, we can write
KΦs-e(z, s) =
⎡
⎣RT
i0F + as
s
⎡
⎣∂Uf
∂Q f
+++++
Q0
⎤
⎦
⎤
⎦If (z, s).
(A.12)
In this equation, we observe a charge-transfer resistance
Rct = RT
i0F,
which is equivalent to what we saw in Eq. (6.3) for a lithium-ion
battery, and an overall faradaic impedance3
Zf =
⎡
⎣RT
i0F + as
s
⎡
⎣∂Uf
∂Q f
+++++
Q0
⎤
⎦
⎤
⎦.
The total current density entering the surface layer is in(z, t) =
idl(z, t) + i f (z, t). Using Eqs. (A.10) and (A.11), we have
In(z, s) = sCKΦs-e(z, s) +
1
@
RT
i0F + as
s
@
∂Uf
∂Q f
+++
Q0
AA KΦs-e(z, s).
(A.13)
Note that this is a current-divider equation. The impedance of the
double-layer process is Zdl = 1/sC and the impedance of the faradaic
process is Zf . The total current density entering the surface layer
is split between current densities entering due to the two different
mechanisms.
We set this result aside for now and refer back to Eqs. (A.8) and (A.9).
Subtracting κeff times Eq. (A.8) from σeff times (A.9) gives
as(κeff + σeff)in = −κeffεs
∂is
∂x + σeffεe
∂ie
∂x .

a. supercapacitors
309
4 Note, we can rearrange this as
ν2(s) =
L2 '
as
κeff +
as
σeff
(
.
1
Z−1
dl +Z−1
f
/ .
We recognize the numerator to be in
the same form as for ν2(s) for a battery
cell. The denominator is the generalized
impedance of a capacitor in parallel
with the impedance of the faradaic
process. Thus, ν2(s) has the same basic
interpretation as for a battery: it is the
ratio of the impedance of the electrode
in the x dimension to the impedance
of the electrode in the r dimension (the
impedance of charging the double-
layer/faradaic process in this case).
Then, by Eqs. (A.3) and (A.4),
as(κeff + σeff)in = κeffσeff
∂2φs
∂x2 −κeffσeff
∂2φe
∂x2
= κeffσeff
∂2 ˜φs-e
∂x2 .
Changing from the x coordinate system to the z coordinate system,
we get
as(κeff + σeff)in = κeffσeff
L2
∂2 ˜φs-e
∂z2 ,
and taking the Laplace transform, we ﬁnd
as(κeff + σeff)In(z, s) = κeffσeff
L2
∂2 KΦs-e(z, s)
∂z2
.
(A.14)
Combining Eqs. (A.13) and (A.14), we arrive at
asL2(κeff+σeff)
κeffσeff
⎛
⎜
⎝sC+
⎡
⎣RT
i0F+ as
s
⎡
⎣∂Uf
∂Q f
+++++
Q0
⎤
⎦
⎤
⎦
−1⎞
⎟
⎠KΦs-e(z, s) = ∂2 KΦs-e(z, s)
∂z2
.
Deﬁne, for the negative electrode,4
νneg(s) = Lneg
U
aneg
s
κneg
eff
+ aneg
s
σneg
eff
×
P
Q
Q
Q
RsCneg +
⎡
⎣RT
ineg
0
F + aneg
s
s
⎡
⎣∂Uneg
f
∂Qneg
f
+++++
Qneg
0
⎤
⎦
⎤
⎦
−1
.
Then,
∂2 KΦs-e(z, s)
∂z2
−ν2(s)KΦs-e(z, s) = 0.
(A.15)
The generic solution to this PDE is
KΦs-e(z, s) = k1 cosh(ν(s)z) + k2 sinh(ν(s)z),
where k1 and k2 are chosen to satisfy the boundary conditions. Since
our boundary conditions are expressed as gradients, we differentiate
∂KΦs-e(z, s)
∂z
= k1ν(s) sinh(ν(s)z) + k2ν(s) cosh(ν(s)z).
From our boundary condition at z = 0, we have
σeff
L
∂KΦs-e(z, s)
∂z
+++++
z=0
= σeff
L k2ν(s) = −Iapp(s)
A
k2 = −Iapp(s)L
Aσeffν(s) .

310
battery management systems: volume i, battery modeling
From our boundary condition at z = 1, we have
−κeff
L
∂KΦs-e(z, s)
∂z
+++++
z=1
= −κeff
L
@
k1ν(s) sinh(ν(s))−Iapp(s)L
Aσeff
cosh(ν(s))
A
−Iapp(s)
A
= −κeff
L
@
k1ν(s) sinh(ν(s))−Iapp(s)L
Aσeff
cosh(ν(s))
A
k1ν(s) sinh(ν(s)) = Iapp(s)L
Aκeff
@
1 + κeff
σeff
cosh(ν(s))
A
k1 =
Iapp(s)L
Aν(s) sinh(ν(s))
@ 1
κeff
+ 1
σeff
cosh(ν(s))
A
.
Note that these are exactly the same as Eqs. (6.10) and (6.11) for the
corresponding development for batteries.
Substituting these values of k1 and k2 into KΦs-e(z, s) gives
KΦs-e(z, s) =
Iapp(s)L
Aν(s) sinh(ν(s))
@ 1
κeff
+ 1
σeff
cosh(ν(s))
A
cosh(ν(s)z)
+ −Iapp(s)L
Aσeffν(s) sinh(ν(s)z)
KΦs-e(z, s)
Iapp(s)
=
L
Aν(s) sinh(ν(s))
@ 1
κeff
cosh(ν(s)z)
+ 1
σeff
(cosh(ν(s)) cosh(ν(s)z) −sinh(ν(s)) sinh(ν(s)z))
A
.
Some trigonometric manipulations give us the following ﬁnal form
KΦneg
s-e (z, s)
Iapp(s)
= Lneg σneg
eff cosh(νneg(s)z) + κneg
eff cosh(νneg(s)(z −1))
Aσneg
eff κneg
eff νneg(s) sinh(νneg(s))
.
(A.16)
This has exactly the same form as for a lithium-ion cell, as we saw
in Eq. (6.12), but with a different deﬁnition of ν(s).
A.5
A one-dimensional model of ˜φneg
s
(z, t)
To ﬁnd a transfer function for φneg
s
(z, t), we ﬁrst ﬁnd a transfer func-
tion for ineg
s
(z, t). We begin by multiplying Eq. (A.5) by κeff:
εsκeffis(z, t) = −κeffσeff
L
∂φs(z, t)
∂z
.
Now, we multiply Eq. (A.7) by σeff , after substituting Eq. (A.6), to get
σeff
iapp(t)
A
= εsσeffis(z, t) −κeff σeff
L
∂φe(z, t)
∂z
.
Adding these two equations gives
εs(κeff + σeff)is(z, t) = σeff
iapp(t)
A
+ κeffσeff
L
∂φs-e(z, t)
∂z
.

a. supercapacitors
311
We take Laplace transforms:
εsIs(z, s) =
σeff
κeff + σeff
Iapp(s)
A
+ 1
L
. κeffσeff
κeff + σeff
/ ∂KΦs-e(z, s)
∂z
.
After substituting Eq. (A.16) and performing symbolic manipulations
(using Mathematica), we arrive at the following transfer function:
εs
Ineg
s
(z, s)
Iapp(s)
= κneg
eff sinh(νneg(s)(1 −z)) −σneg
eff sinh(νneg(s)z)
A(κneg
eff + σneg
eff ) sinh(νneg(s))
+
σneg
eff
A(κneg
eff + σneg
eff )
.
(A.17)
Now, starting with Eq. (A.5), we can write
∂φs(z, t)
∂z
= −Lεs
σeff
is(z, t)
φs(z, t) −φs(0, t) = −Lεs
σeff
ˆ z
0
is(ζ, t) dζ.
Deﬁne ˜φs(z, t) = φs(z, t) −φs(0, t). In the negative electrode, φs(z, t) =
˜φs(z, t); in the positive electrode, φs(z, t) = ˜φs(z, t) + v(t).
˜φs(z, t) = −Lεs
σeff
ˆ z
0
is(ζ, t) dζ
KΦs(z, s) = −Lεs
σeff
ˆ z
0
Is(ζ, s) dζ.
Substituting Eq. (A.17) and simplifying gives
KΦneg
s
(z, s)
Iapp(s)
= −Lneg σneg
eff +κneg
eff cosh(νneg(s))+zνneg(s)σneg
eff sinh(νneg(s))
Aσneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
+ Lneg σneg
eff cosh(νneg(s)z)+κneg
eff cosh(νneg(s)(1 −z))
Aσneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
.
(A.18)
This has exactly the same form as for a lithium-ion cell, as we saw
in Eq. (6.19) but with a different deﬁnition of ν(s).
A.6
A one-dimensional model of ˜φneg
e
(z, t)
To ﬁnd a transfer function for φneg
e
(z, t), we begin by ﬁnding a trans-
fer function for ineg
e
(z, t). Rearrange Eq. (A.7) to get
εeie(z, t) = iapp(t)
A
−εsis(z, t).
Therefore,
εe
Ineg
e
(z, s)
Iapp(s)
= 1
A −εs
Ineg
s
(z, s)
Iapp(s) .

312
battery management systems: volume i, battery modeling
Substituting Eq. (A.17) and simplifying gives
εe
Ineg
e
(z, s)
Iapp(s)
= σneg
eff sinh(νneg(s)z) −κneg
eff sinh(νneg(s)(1 −z))
A(κneg
eff + σneg
eff ) sinh(νneg(s))
+
κneg
eff
A(κneg
eff + σneg
eff )
.
(A.19)
To ﬁnd φe(z, t) in an electrode, write
φe(z, t) = φs(z, t) −φs-e(z, t)
= ˜φs(z, t) + φs(0, t) −˜φs-e(z, t) −Udl,0 −Uf (Q0).
Deﬁne
˜φe(z, t) = φe(z, t) −φs(0, t) + Udl,0 + Uf (Q0).
(A.20)
Then,
KΦe(z, s)
Iapp(s) =
KΦs(z, s)
Iapp(s) −
KΦs-e(z, s)
Iapp(s) .
After substitution and simpliﬁcation, this yields
KΦneg
e
(z, s)
Iapp(s)
= −Lneg (κneg
eff )2 cosh(νneg(s)) + (σneg
eff )2 cosh(νneg(s)z)
Aσneg
eff κneg
eff (κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
−Lneg 1 + cosh(νneg(s)(1 −z)) + zνneg(s) sinh(νneg(s))
A(κneg
eff + σneg
eff )νneg(s) sinh(νneg(s))
.
(A.21)
A.7
Positive-electrode variables ˜φpos
s-e , ˜φpos
s
and ˜φpos
e
Following the same approach as we used for the model of the lithium-
ion cell, we ﬁnd that all positive-electrode transfer functions are of
the same form as their negative-electrode counterparts except:
1. We use νpos(s) instead of νneg(s).
2. We use Lpos, apos
s
, κpos
eff , σpos
eff (etc.) instead of Lneg, aneg
s
, κneg
eff , and
σeng
eff (etc.), respectively.
3. We multiply the transfer function by −1.
Therefore, for the positive electrode, we have impedance ratio
νpos(s) = Lpos
U
apos
s
κpos
eff
+ apos
s
σpos
eff
×
P
Q
Q
Q
RsCpos +
⎡
⎣RT
ipos
0
F + apos
s
s
⎡
⎣∂Upos
f
∂Qpos
f
+++++
Qpos
0
⎤
⎦
⎤
⎦
−1

a. supercapacitors
313
0
1
2
3
0
0.2
0.4
0.6
0.8
Normalized spatial dimension
Potential (V)
Potentials when charging
 
 
Negative
electrode
Separator
Positive
electrode
φs
φe
Figure A.3: Illustration of potentials
inside supercapacitor while charging.
and
KΦpos
s-e (z, s)
Iapp(s)
= −Lpos σpos
eff cosh(νpos(s)z) + κpos
eff cosh(νpos(s)(z −1))
Aσpos
eff κpos
eff νpos(s) sinh(νpos(s))
(A.22)
KΦpos
s
(z, s)
Iapp(s)
= Lpos σpos
eff +κpos
eff cosh(νpos(s))+zνpos(s)σpos
eff sinh(νpos(s))
Aσpos
eff (κpos
eff + σpos
eff )νpos(s) sinh(νpos(s))
−Lpos σpos
eff cosh(νpos(s)z) + κpos
eff cosh(νpos(s)(1 −z))
Aσpos
eff (κpos
eff + σpos
eff )νpos(s) sinh(νpos(s))
(A.23)
KΦpos
e
(z, s)
Iapp(s)
= Lpos (κpos
eff )2 cosh(νpos(s)) + (σpos
eff )2 cosh(νpos(s)z)
Aσpos
eff κpos
eff (κpos
eff + σpos
eff )νpos(s) sinh(νpos(s))
+ Lpos 1 + cosh(νpos(s)(1 −z)) + zνpos(s) sinh(νpos(s))
A(κpos
eff + σpos
eff )νpos(s) sinh(νpos(s))
.
(A.24)
A.8
Supercapacitor voltage
Fig. A.3 illustrates the supercapacitor internal potentials while the
device is experiencing a constant-current charge proﬁle. This ﬁgure
gives insight into how we can use the expressions we have developed
already to compute a supercapacitor voltage signal.
Notice that the overall supercapacitor voltage can be written as the
sum of the voltages over every region of the device. That is,
v(t) = vneg(t) + vsep(t) + vpos(t).
We can write
vneg(t) = φneg
e
(1, t) −φneg
s
(0, t)
#
$%
&
0
= ˜φneg
e
(1, t) + φneg
s
(0, t)
#
$%
&
0
−Uneg
dl,0 −Uneg
f
(Qneg
0
),
where we have substituted Eq. (A.20). Similarly,
vpos(t) = φpos
s
(0, t) −φpos
e
(1, t) = −˜φpos
e
(1, t) + Upos
dl,0 + Upos
f
(Qpos
0
),
where we have again substituted Eq. (A.20). Finally,
vsep(t) = −iapp(t) Lsep
Aκsep
eff
.
Overall, then, we have
v(t) = ˜φneg
e
(1, t) −˜φpos
e
(1, t) −iapp(t) Lsep
Aκsep
eff
−Uneg
f
(Qneg
0
) + Upos
f
(Qpos
0
) −Uneg
dl,0 + Upos
dl,0.

314
battery management systems: volume i, battery modeling
If we deﬁne a debiased voltage
˜v(t) = ˜φneg
e
(1, t) −˜φpos
e
(1, t) −iapp(t) Lsep
Aκsep
eff
,
then we can make a transfer function for the supercapacitor voltage
as
KV(s)
Iapp(s) =
KΦneg
e
(1, s)
Iapp(s)
−
KΦpos
e
(1, s)
Iapp(s)
−Lsep
Aκsep
eff
,
where we reuse transfer functions from Eqs. (A.21) and (A.24), evalu-
ated at z = 1, to compute the electrolyte potentials.
A.9
Implementing the full-order model
Recalling Eqs. (A.1) through (A.11), we can construct PDEs suitable
for implementation in COMSOL or a similar PDE solver. Starting
with Eqs. (A.8) and (A.1),
∇· (εsis) = −asin
∇· (σeff∇φs) = asin,
we substitute in = idl + i f via Eqs. (A.10) and (A.11), which give
in = C
@∂φs
∂t −∂φe
∂t
A
+ i0
:
exp
.(1 −α)F
RT
'
φs-e −Uf (Q f )
(/
−exp
.
−αF
RT
'
φs-e −Uf (Q f )
(/;
,
to yield the overall relationship
∂φs
∂t = ∇· (σeff∇φs)
asCL2
+ ∂φe
∂t −i0
C
:
exp
.(1 −α)F
RT
'
φs-e −Uf (Q f )
(/
−exp
.
−αF
RT
'
φs-e −Uf (Q f )
(/;
,
where the divergence and gradient operators are with respect to
normalized length z.
We follow similar steps to ﬁnd a PDE for φe. Starting with Eqs. (A.9)
and (A.2),
∇· (εsie) = asin
∇· (κeff∇φe) = −asin,
we substitute in = idl + i f , to yield the overall relationship:
∂φe
∂t = ∇· (κeff∇φe)
asCL2
+ ∂φs
∂t + i0
C
:
exp
.(1 −α)F
RT
'
φs-e −Uf (Q f )
(/

a. supercapacitors
315
−exp
.
−αF
RT
'
φs-e −Uf (Q f )
(/;
,
where the divergence and gradient operators are again with respect
to normalized length z.
For boundary conditions in the negative electrode, we know that
at the current collector
iapp(t)
A
= εneg
s
ineg
s
(0, t) = −σneg
eff ∇φneg
s
(0, t).
So,
∂φneg
s
(x, t)
∂x
+++++
x=0
= −iapp(t)
σneg
eff A
or
∂φneg
s
(z, t)
∂z
+++++
z=0
= −iapp(t)Lneg
σneg
eff A
.
We also know
εneg
e
ineg
e
(0, t) = 0 = −κneg
eff ∇φneg
e
(0, t)
so
∂φneg
e
(x, t)
∂x
+++++
x=0
= ∂φneg
e
(z, t)
∂z
+++++
z=0
= 0.
At the separator boundary,
iapp(t)
A
= εneg
e
ineg
e
(Lneg, t) = −κneg
eff ∇φneg
e
(Lneg, t).
So
∂φneg
e
(x, t)
∂x
+++++
x=Lneg
= −iapp(t)
κneg
eff A
or
∂φneg
e
(z, t)
∂z
+++++
z=1
= −iapp(t)Lneg
κneg
eff A
.
We also know
εneg
s
ineg
s
(Lneg, t) = 0 = −σneg
eff ∇φneg
s
(Lneg, t)
so
∂φneg
s
(x, t)
∂x
+++++
x=Lneg
= ∂φneg
s
(z, t)
∂z
+++++
z=1
= 0.
In the positive electrode, we must multiply the boundary conditions
by −1 and replace the “neg” parameters and variables with “pos”
equivalents.
Finally, we set φneg
s
(0, t) = 0 and φpos
s
(z = 0, t) = v(t).
A.10
Implementing the reduced-order model
A reduced-order model can be created using the DRA to implement
any set of transfer functions at any set of locations in the supercapac-
itor. There are no special considerations needed for supercapacitors
versus lithium-ion battery cells.

316
battery management systems: volume i, battery modeling
A.11
Simulation results
To demonstrate the effectiveness of the reduced-order supercapacitor
models, this section presents results for both a nonfaradaic example
and a faradaic example. The parameters for the nonfaradaic example
are listed in Table A.1 and are taken from Srinivasan and Weidner.
The parameters for the faradaic example are listed in Table A.2 and
are taken from Lin et al. The reduced-order models had four dy-
namic states plus one integrator state.
Parameter
Units
Electrode
Separator
as
m2 m−3
3 × 108
—
C
F m−2
0.3
—
L
µm
150
100
εe
—
0.25
0.7
εs
—
0.75
—
κeff
S m−1
8.4
39.2
σeff
S m−1
107
—
Table A.1: Parameters for nonfaradaic
simulation (A = 1 m2).
(From: Srinivasan, V., and Weidner,
J.W., “Mathematical Modeling of
Electrochemical Capacitors,” Journal of
the Electrochemical Society, 146(5), 1999,
pp. 1,650–1,658.)
Parameter
Units
Electrode
Separator
as
m2 m−3
4.5 × 108
—
C
F m−2
0.2
—
L
µm
50
25
εe
—
0.25
0.25
εs
—
0.7
—
κeff
S m−1
10
47
σeff
S m−1
107
—
i0
A m−2
0.1
—
Q f ,0%
C m−3
0
—
Q f ,100%
C m−3
4.51 × 106
—
α
—
0.5
—
Uneg
f
(θ f )
V
0.5θ f
—
Upos
f
(θ f )
V
0.5(1 + θ f )
—
Table A.2: Parameters for faradaic
simulation (A = 1 m2).
(From: Lin, C., Ritter, J.A., Popov, B.N.,
and White, R.E., “A Mathematical
Model of an Electrochemical Capaci-
tor with Double-Layer and Faradaic
Processes,” Journal of the Electrochemical
Society, 146(9), 1999, pp. 3,168–3,175.)
In both cases, the initial supercapacitor voltage was set to 0.5 V.
In the nonfaradaic case, this was accomplished by setting Uneg
dl
=
−0.25 V and Upos
dl
= 0.25 V. In the faradaic case, this was accom-
plished by setting Uneg
dl
= Upos
dl
= 0 V, θneg
f ,0 = 0.5, and θpos
f ,0 = 0.5. The
supercapacitor was initially at rest. It was then exercised with a 1,000-
A charge pulse, followed by a brief rest to allow voltage relaxation,
followed by a 1,000-A discharge pulse.

a. supercapacitors
317
Results for the nonfaradaic case are shown in Fig. A.4, and results
for the faradaic case are shown in Fig. A.5. In both cases, the ROM
and FOM results are nearly indistinguishable. Zooming in on the ﬁne
details shows that there is some imprecision at the discontinuities in
current, as the ROM has a ﬁnite number of time constants versus the
inﬁnite number of time constants for the FOM. Adding states to the
ROM would improve this, but there is a point of diminishing return.
A.12
Identifying parameters
Before concluding this appendix, we would like to be able to identify
all the parameters of a supercapacitor simply from current–voltage
input–output data. For example, we would like to determine the
parameters listed in Table A.1 for a nonfaradaic supercapacitor and
the parameters listed in Table A.2 for a faradaic supercapacitor. Here,
we describe an approach to doing so, which does not provide the full
list of parameters, but which does provide all parameters needed to
evaluate any of the transfer functions considered in this appendix.
For brevity, we consider only the commonly encountered non-
faradaic case where negative and positive electrodes are identical.
Then, cell voltage can be written as
KV(s)
Iapp(s) = 2
KΦneg
e
(1, s)
Iapp(s)
−Lsep
Aκsep
eff
.
We deﬁne the following constants:
Rsep = Lsep
Aκsep
eff
R0 =
2Lneg
A(κneg
eff + σneg
eff ) + Rsep
Rss = 2Lneg(κneg
eff + σneg
eff )
3A(κneg
eff σneg
eff )
+ Rsep
Ctot = aneg
s
ACnegLneg.
These values correspond to the separator ohmic resistance and to
terms that can be measured from a step-response test, such as de-
picted in Fig. A.6. We see that R0 is the resistance describing the
instantaneous change in voltage due to the step input, Rss is the re-
sistance describing the steady-state difference in voltage between an
ideal capacitor response to a step input (drawn as a dashed green
line) and the actual response, and Ctot is the total capacitance of
one electrode in the supercapacitor. We ﬁnd that we can then write

318
battery management systems: volume i, battery modeling
0
0.2
0.4
0.6
0.8
1.0
−1,000
−500
0
500
1,000
Current (A)
Time (s)
Supercapacitor current
0
0.2
0.4
0.6
0.8
1.0
0.48
0.49
0.5
0.51
0.52
0.53
0.54
0.55
 
 
FOM
ROM
Voltage (V)
Time (s)
Supercapacitor voltage
0
0.2
0.4
0.6
0.8
1.0
−15
−10
−5
0
5
10
15
 
 
FOM
ROM
φs at negative-electrode–separator boundary
Time (s)
Potential (nV)
0
0.2
0.4
0.6
0.8
1.0
0.48
0.49
0.5
0.51
0.52
0.53
0.54
0.55
 
 
FOM
ROM
φs at positive-electrode–separator boundary
Time (s)
Potential (V)
0
0.2
0.4
0.6
0.8
1.0
0.245
0.25
0.255
0.26
0.265
0.27
 
 
FOM
ROM
φe at negative-electrode current collector
Time (s)
Potential (V)
0
0.2
0.4
0.6
0.8
1.0
0.24
0.25
0.26
0.27
0.28
 
 
FOM
ROM
φe at negative-electrode–separator boundary
Time (s)
Potential (V)
0
0.2
0.4
0.6
0.8
1.0
0.24
0.25
0.26
0.27
0.28
 
 
FOM
ROM
φe at positive-electrode–separator boundary
Time (s)
Potential (V)
0
0.2
0.4
0.6
0.8
1.0
0.23
0.24
0.25
0.26
0.27
0.28
0.29
 
 
FOM
ROM
Time (s)
Potential (V)
φe at positive-electrode current collector
Figure A.4: Nonfaradaic results.

a. supercapacitors
319
0
0.1
0.2
0.3
0.4
0.5
−1,000
−500
0
500
1,000
Current (A)
Time (s)
Supercapacitor current
0
0.1
0.2
0.3
0.4
0.5
0.49
0.5
0.51
0.52
0.53
0.54
0.55
 
 
FOM
ROM
Voltage (V)
Time (s)
Supercapacitor voltage
0
0.1
0.2
0.3
0.4
0.5
−6
−4
−2
0
2
4
6
 
 
FOM
ROM
φs at negative-electrode–separator boundary
Time (s)
Potential (nV)
0
0.1
0.2
0.3
0.4
0.5
0.49
0.5
0.51
0.52
0.53
0.54
0.55
 
 
FOM
ROM
φs at positive-electrode–separator boundary
Time (s)
Potential (V)
0
0.1
0.2
0.3
0.4
0.5
−0.255
−0.25
−0.245
−0.24
−0.235
−0.23
−0.225
 
 
FOM
ROM
φe at negative-electrode current collector
Time (s)
Potential (V)
0
0.1
0.2
0.3
0.4
0.5
−0.255
−0.25
−0.245
−0.24
−0.235
−0.23
−0.225
 
 
FOM
ROM
φe at negative-electrode–separator boundary
Time (s)
Potential (V)
0
0.1
0.2
0.3
0.4
0.5
−0.255
−0.25
−0.245
−0.24
−0.235
−0.23
−0.225
 
 
FOM
ROM
φe at positive-electrode–separator boundary
Time (s)
Potential (V)
0
0.1
0.2
0.3
0.4
0.5
−0.255
−0.25
−0.245
−0.24
−0.235
−0.23
−0.225
 
 
FOM
ROM
Time (s)
Potential (V)
φe at positive-electrode current collector
Figure A.5: Faradaic results.

320
battery management systems: volume i, battery modeling
0
0.1
0.2
0.3
0.4
0.5
0.6
0.5
0.55
0.6
Identifying supercapacitor parameters 
Time (s)
Voltage (V)
iappR0
iappRss
2iapp
Ctot
Figure A.6: Measurements made from
step response.
νneg(s) in terms of these quantities:
νneg(s) = Lneg
P
Q
Q
RsCneg
,
aneg
s
κneg
eff
+ aneg
s
σneg
eff
-
=
L
3s
2 Ctot (Rss −Rsep).
After some further manipulation, we ﬁnd that we can write
KΦneg
e
(1, s)
Iapp(s)
=
.
R0 −3
2 Rss + 1
2 Rsep
/ coth(νneg(s))
νneg(s)
−1
2 (R0 −Rsep)
.
1 +
2
νneg(s) sinh(νneg )
/
.
That is, the cell voltage can be written uniquely in terms of the four
quantities Rsep, R0, Rss, and Ctot
KV(s)
Iapp(s) = (2R0 −3Rss + Rsep) coth(νneg(s))
νneg(s)
−(R0 −Rsep)
.
1 +
2
νneg(s) sinh(νneg )
/
−Lsep
Aκsep
eff
. (A.25)
This poses a problem. Table A.1 lists 11 independent parameters
(including A) that determine a supercapacitor’s dynamics. However,
we can determine at most four from current–voltage measurements.
The step-response test itself can supply only three of these values—
Rss can be determined via ﬁtting a measured frequency response to
Eq. (A.25).
There is a solution, however. If we are willing to consider groups
of parameters, we can rewrite all the transfer functions of this ap-
pendix in terms of the four identiﬁable quantities. First, we further
deﬁne
κneg
tot =
A
Lneg κneg
eff ,
κsep
tot =
A
Lsep κsep
eff ,
and
σneg
tot =
A
Lneg σneg
eff .
Then, we rewrite
R0 =
2
κneg
tot + σneg
tot
+ Rsep
(A.26)
Rss = 2(κneg
tot + σneg
tot )
3(κneg
tot σneg
tot )
+ Rsep.
(A.27)
The transfer functions in this appendix can be written in terms of
these new variables. Consider, for example, the negative electrode
KΦneg
s-e (z, s)
Iapp(s)
= σneg
tot cosh(νneg(s)z) + κneg
tot cosh(νneg(s)(z −1))
σneg
tot κneg
tot νneg(s) sinh(νneg(s))
(A.28)

a. supercapacitors
321
KΦneg
s
(z, s)
Iapp(s)
= −σneg
tot + κneg
tot cosh(νneg(s)) + zνneg(s)σneg
tot sinh(νneg(s))
σneg
tot (κneg
tot + σneg
tot )νneg(s) sinh(νneg(s))
+ σneg
tot cosh(νneg(s)z) + κneg
tot cosh(νneg(s)(1 −z))
σneg
tot (κneg
tot + σneg
tot )νneg(s) sinh(νneg(s))
(A.29)
KΦneg
e
(z, s)
Iapp(s)
= −(κneg
tot )2 cosh(νneg(s)) + (σneg
tot )2 cosh(νneg(s)z)
σneg
tot κneg
tot (κneg
tot + σneg
tot )νneg(s) sinh(νneg(s))
−1 + cosh(νneg(s)(1 −z)) + zνneg(s) sinh(νneg(s))
(κneg
tot + σneg
tot )νneg(s) sinh(νneg(s))
.
(A.30)
So, if we are able to derive κneg
tot and σneg
tot
from the four known
quantities, we can compute all the transfer functions. Rearranging
Eqs. (A.26) and (A.27), we have
1
κneg
tot
+
1
σneg
tot
= 3
2(Rss −Rsep)
1
κneg
tot + σneg
tot
= 1
2(R0 −Rsep).
Combining these equations, we have that
(κneg
tot )2 −c1κneg
tot + c2 = 0
(σneg
tot )2 −c1σneg
tot + c2 = 0,
where
c1 =
2
R0 −Rsep
and
c2 =
2c1
3(Rss −Rsep).
Since the equations describing κneg
tot and σneg
tot are identical, we must
assign the two solutions of the quadratic equation to the two vari-
ables using side information. For any realistic supercapacitor, the
electronic conductivity will be much higher than the ionic conductiv-
ity, which makes this choice for us.
So while we have not been able to identify all parameters in
Table A.1 from cell-test data, we have identiﬁed a sufﬁcient subset
of quantities to be able to compute any signal of interest. Table A.3
lists the true and estimated parameter values using only data from
the step response to initialize estimates and data from the noise-free
frequency response to reﬁne the estimates. The estimated parameter
values match the true parameter values to many signiﬁcant digits. If
any speciﬁc nonlumped parameter value from the table is needed,
the supercapacitor will have to be opened, and independent electro-
chemical laboratory measurements taken on the internals to deter-
mine the missing information.
Before concluding, we make one ﬁnal comment based on observ-
ing Eq. (A.26). In practice, σneg
tot tends to be a very large value such

322
battery management systems: volume i, battery modeling
Parameter
True value
Estimated value
Ctot
1.350000×104
1.350000×104
Rsep
2.548462×10−6
2.548462×10−6
Rss
1.448877×10−5
1.448877×10−5
R0 −Rsep
2.999997×10−11
2.999992×10−11
κtot
sep
3.923936×105
3.923936×105
κtot
neg
5.583333×104
5.583333×104
σtot
neg
6.666667×1010
6.666679×1010
Table A.3: Results of parameter
estimation.
that R0 ≈Rsep to many signiﬁcant decimal places. The frequency-
response data collected to disambiguate these two quantities will
need to be very accurate.
A.13
Partial glossary
This section gives a glossary of the most important variables deﬁned
in this appendix, which builds on the deﬁnitions given in earlier
chapters. Units are also given—the notation [u/l] is speciﬁed for
a unitless quantity. Note that all variables are at least potentially
functions of space and time.
• C [F m−2] is the double-layer speciﬁc capacitance (cf. p. 307).
• Ctot [F] is an electrode’s total capacitance (cf. p. 317).
• idl [A m−2] is the double-layer current density (cf. p. 307).
• i f [A m−2] is the faradaic current density (cf. p. 307).
• Q f [C m−3] is the faradaic charge density (cf. p. 307).
• R0 [Ω] is the series resistance of the capacitor (cf. p. 317).
• Rsep [Ω] is the separator resistance (cf. p. 317).
• Rss [Ω] is the steady-state resistance of the capacitor to a steplike
input (cf. p. 317).
• θ f [u/l] is the faradaic state-of-charge of an electrode. For a sym-
metric cell, θneg
f
= 1 −θpos
f
(cf. p. 307).

About the Author
Gregory L. Plett is a professor of electrical and computer engi-
neering at the University of Colorado Colorado Springs (UCCS).
His research since 2001 has been focused on applications of control-
systems theory to the management and control of high-capacity bat-
tery systems such as found in hybrid and electric vehicles. Current
investigations include physics-based reduced-order modeling of
ideal lithium-ion dynamics, system identiﬁcation of physics-based
model parameters using only current–voltage input–output data,
physics-based reduced-order modeling of degradation mechanisms
in electrochemical cells, estimation of cell internal state and degrada-
tion state, state-of-charge, state-of-health and state-of-life estimation,
power and energy prediction to extend life, and battery pack fast
charging. Research is both theoretical and empirical: the UCCS High-
Capacity Battery Research and Test Laboratory houses equipment to
test cells, modules, and battery packs and is home to custom battery-
management system and hardware battery-pack simulator projects,
which together enable cutting-edge research in advanced but prac-
tical algorithm prototyping. He offers courses in control systems
and in battery modeling and management to support this research.
Dr. Plett holds a bachelor of engineering in computer systems en-
gineering degree from Carleton University (Ontario, Canada) and
master of science and Ph.D. degrees in electrical engineering from
Stanford University (Stanford, California). He is a senior member of
the Institute of Electrical and Electronic Engineers and life member of
the Electrochemical Society.
323


Index
⟨·⟩notation, 142
· notation, 143
(·) notation, 32
[·] notation, 32
Activated complex, 112
Activation energy, 111, 280
Activity, 90
Absolute (via molality), 91
Absolute (via molarity), 90
Mean molal coefﬁcient, 104
Mean molar coefﬁcient, 110
Anion, 6
Anode, see Negative electrode
Arrhenius relationship, 111, 280
Atomic number, 10
Atomic weight, 10
Avagadro’s number NA, 68
Battery, 2
Bruggeman’s exponent, 154
C-rate, 3
Capacity
Charge, 52
Discharge, 31, 52
Energy, 3
Nominal, 3
Total, 31, 52, 124, 163
Cathode, see Positive electrode
Cation, 6
Cell, 2
Cylindrical, 20
Pouch, 20
Primary, 2, 8
Prismatic, 20
Rechargeable, see Cell, secondary
Secondary, 2, 8
Charge number, 92
Charge-transfer coefﬁcient α, 114
Charge-transfer resistance, 220
Chemical potential, 88
Concentrated solution theory, 81
Conduction, 272
Conductivity, 71, 109
Effective, 154, 160
Constrictivity, 154
Controllability matrix, 187
Extended, 191
Generalized, 210
Convection, 95, 273
Forced, 273
Natural, 273
Corrosion, 25
Coulombic efﬁciency, 31, 48
Current collector, 7
Density, 274
Depth of discharge, 32
Diffusion, 95
Diffusivity, 76
Effective, 158
Maxwell–Stefan, 98
Dirac delta function δ(x, t), 138
Integrating, 140
Sifting property, 138
Dither, 52
Divergence (∇·), 73
Electrochemical double-layer capaci-
tor, see Supercapacitor
Electrochemical potential, 88
Electrochemical series, 8
Electrolyte, 6, 19
Binary, 91
Salt, 19
Electrolyte concentration ce
Continuum scale, 137
Microscale, 67
Reduced-order model (debiased),
240
Reduced-order model modal term,
240
Electrolyte current density ie
Continuum scale, 160
Microscale, 110
Reduced-order model, 241
Electrolyte potential φe
Continuum scale, 137
Microscale, 68
Reduced-order model (debiased),
242
Electromotive force, see Voltage, cell
Energy, 3
Energy density, 4
Energy efﬁciency, 31
Enthalpy, 81, 273
Partial molar, 275
Entropy, 84
Partial molar, 277
Environment, 81
Equivalent circuit model, see Model,
equivalent circuit
Equivalent series resistance, 33, 177
Exact differential, 83
Exchange current density i0, 116
Extensive variable, 86
Faradaic capacitance, 304
Faraday’s constant F, 69
Film resistance, 218
Finite difference method, 78, 164
Finite element method, 165
Finite volume method, 127, 164
Flux density, 69, 76
Formation, 23
Frequency response, 174, 248
325

326
battery management systems: volume i, battery modeling
Gibbs free energy, 81, 85
Gibbs–Duhem equation, 89
Gradient, 142, 144
Gradient (∇), 71
Green’s identity, 231
Heat, 272
Flux, 272
Generation, 272
Sink, 272
Heat generation, 278
Contact resistance, 279
Irreversible, 279
Joule heating, 279
Reversible, 279
Heat-transfer coefﬁcient, 280
Helmholtz free energy, 81
Hysteresis, 41, 51
ˆi unit vector, 71
Impedance
Reduced-order model, 249
Impedance ratio ν2(s)
Lithium-ion cell, 223
Supercapacitor, 309
Impulse response, 174
Indicator function γα(x, t), 138
Gradient, 140
Inexact differential, 83
Insertion electrode, 11, 13
Intensive variable, 86
Intercalation, 13, 16
Internal energy, 81
Intrinsic phase average, 143
ˆj unit vector, 71
Jacobsen–West transfer function
KCs,e(s)/J(s), 185
ˆk unit vector, 71
Kinetics, 81, 111
Liebnitz’ rule, 75
Lithium ﬂux density j
Continuum scale, 137
Microscale, 68
Reduced-order model, 224, 228
Markov parameter, 181
Maxwell–Stefan theory, 95
Migration, 95
Model
Cell scale, 67
Continuum scale, 66, 135
Empirical, see Model, equivalent
circuit
Enhanced self-correcting, 44
Equivalent circuit, 29, 65
Microscale, 66
Molecular scale, 66
Physics-based, 65
Pseudo-two-dimensional, 152
Single particle, 127
State space, 174
Molality, 87
Molarity, 87
Mole, 68
Mole fraction, 97
Negative electrode, 5, 16
Graphite, 16, 51, 123
Lithium titanate oxide, 16, 123
Silicon, 16
Nonfaradaic capacitance, 304
Observability matrix, 187
Extended, 191
Generalized, 210
Ohm’s law, 71
Open-circuit potential, 118, 122
Open-circuit voltage, see Voltage,
open circuit
Output equation, 174
Overpotential η, 115, 118, 220
Oxidant, 112
Oxidation reaction, 5
Peltier coefﬁcient, 276
Periodic table, 10
Phase, 136
Phase average, 142
Phase transition, 14
Polarization, 34
Positive electrode, 6, 17
Lithium cobalt oxide, 17, 51, 123
Lithium iron phosphate, 18, 51, 123
Lithium manganese oxide, 17, 51,
123
Lithium nickel cobalt aluminum
oxide, 17, 124
Lithium nickel manganese cobalt
oxide, 17, 51, 124
Power, 3
Pseudocapacitance, see Faradaic ca-
pacitance
Radiation, 273
Randles circuit, 40
Reaction rate constant k0, 117
Normalized knorm
0
, 118
Redox reaction, 5
Reductant, 112
Reduction reaction, 5
Reversible process, 84
Room temperature, 32
Separator, 7, 19
Singular value decomposition, 189
Solid concentration cs
Continuum scale, 137
Microscale, 67
Solid current density is
Continuum scale, 155
Microscale, 75
Reduced-order model, 226
Solid electrolyte interphase, 24, 25,
123
Solid potential φs
Continuum scale, 137
Microscale, 67
Reduced-order model (debiased),
227, 229
Solid surface concentration cs,e
Reduced-order model (debiased),
225, 229
Reduced-order model (debiased,
integrator-removed), 225
Solid–electrolyte interfacial resistance,
220
Solute, 6
Solvent, 6, 19
Speciﬁc energy, 4
Speciﬁc heat, 274
State (of model), 174
State equation, 174
State function, 83
State of charge, 30, 126, 164
Stoichiometric coefﬁcient, 92
Sturm–Liouville problem, 230
Supercapacitor, 303
System, 81
System identiﬁcation, 54, 66
Subspace, 56

index
327
Temperature, 272
Kinetic, 272
Reference, 280
Thermodynamic potential, 81, 273
Thermodynamics, 81
First law, 83
Second law, 84
Tortuosity, 154
Total concentration, 97
Transfer function, 174, 178
Rational polynomial, 176, 185
Transcendental, 185
Transference number, 102
Ultracapacitor, see Supercapacitor
Vector ﬁeld, 69
Voltage
Cell, 7
Diffusion, 34
Nominal, 2
Open circuit, 30, 45, 122
Reduced-order model, 247
Volume fraction, 143
Volume-averaging
Theorem 1, 136
Theorem 2, 136
Theorem 3, 136
Warburg impedance, 40


Recent Artech House Titles in Power Engineering
Dr. Jianhui Wang, Series Editor
The Advanced Smart Grid: Edge Power Driving Sustainability, Second Edition, Andres Carvallo 
and John Cooper
Battery Management Systems, Volume I: Battery Modeling, Gregory L. Plett
Battery Management Systems for Large Lithium Ion Battery Packs, Davide Andrea
Battery Power Management for Portable Devices, Yevgen Barsukov and Jinrong Qian
Design and Analysis of Large Lithium-Ion Battery Systems, Shriram Santhanagopalan, 
Kandler Smith, Jeremy Neubauer, Gi-Heon Kim, Matthew Keyser, and Ahmad Pesaran
Designing Control Loops for Linear and Switching Power Supplies: A Tutorial Guide, 
Christophe Basso
Electric Systems Operations: Evolving to the Modern Grid, Mani Vadari
Energy Harvesting for Autonomous Systems, Stephen Beeby and Neil White
GIS for Enhanced Electric Utility Performance, Bill Meehan
Introduction to Power Electronics, Paul H. Chappell
Power Line Communications in Practice, Xavier Carcelle
Power System State Estimation, Mukhtar Ahmad
A Systems Approach to Lithium-Ion Battery Management, Phil Weicker
Signal Processing for RF Circuit Impairment Mitigation in Wireless Communications, 
Huang, Zhu, Leung
Synergies for Sustainable Energy, Elvin Yüzügüllü
For further information on these and other Artech House titles,including previously considered 
out-of-print books now available through our In-Print-Forever® (IPF®) program, contact:
Artech House 
Artech House
685 Canton Street 
16 Sussex Street 
Norwood, MA 02062 
London SW1V 4RW UK
Phone: 781-769-9750 
Phone: +44 (0)20 7596-8750
Fax: 781-769-6334 
Fax: +44 (0)20 7630-0166
e-mail: artech@artechhouse.com 
e-mail: artech-uk@artechhouse.com
Find us on the World Wide Web at: www.artechhouse.com


